{"sha": "04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDRlMWQwNmI3OTVkYzdkZmExMWJlNWUwZWUwNDQ2N2EyOGUxMDVkZA==", "commit": {"author": {"name": "Michael Meissner", "email": "meissner@gcc.gnu.org", "date": "2007-09-13T02:17:51Z"}, "committer": {"name": "Michael Meissner", "email": "meissner@gcc.gnu.org", "date": "2007-09-13T02:17:51Z"}, "message": "Add AMD SSE5 support; Add iterator over function arguments; Add stdarg_p, prototype_p, function_args_count functions\n\nFrom-SVN: r128455", "tree": {"sha": "2550bf2be428ffb45e9bcb30a6c3186b44ebdc0d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2550bf2be428ffb45e9bcb30a6c3186b44ebdc0d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/comments", "author": null, "committer": null, "parents": [{"sha": "ceaa2d5019c290d814e0856531e9b45cbff6b90b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ceaa2d5019c290d814e0856531e9b45cbff6b90b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ceaa2d5019c290d814e0856531e9b45cbff6b90b"}], "stats": {"total": 7413, "additions": 7134, "deletions": 279}, "files": [{"sha": "2db9c0e54ab246ad5eb36092c6f4874b94eb0293", "filename": "gcc/ChangeLog", "status": "modified", "additions": 465, "deletions": 0, "changes": 465, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -1,3 +1,468 @@\n+2007-09-12  Michael Meissner  <michael.meissner@amd.com>\n+\t    Dwarakanath Rajagopal  <dwarak.rajagopal@amd.com>\n+\t    Tony Linthicum  <tony.linthicum@amd.com>\n+\n+\t* tree.h (function_args_iterator): New type to iterate over\n+\tfunction arguments.\n+\t(FOREACH_FUNCTION_ARGS_PTR): Iterator macros for iterating over\n+\tfunction arguments providing a pointer to the argument.\n+\t(FOREACH_FUNCTION_ARGS): Iterator macros for iterating over\n+\tfunction arguments providing the argument.\n+\t(function_args_iter_init): Inline function to initialize\n+\tfunction_args_iterator.\n+\t(function_args_iter_cond_ptr): Inline function to return the next\n+\tpointer to hold the argument.\n+\t(function_args_iter_cond): Inline function to return the next\n+\targument.\n+\t(function_args_iter_cond_next): Advance the function args\n+\titerator.\n+\t(stdarg_p): New function, return true if variable argument\n+\tfunction.\n+\t(prototype_p): New function, return true if function is\n+\tprototyped.\n+\t(function_args_count): New function, count the number of arguments\n+\tof a function.\n+\n+\t* tree.c (stdarg_p): New function, return true if variable\n+\targument function.\n+\t(prototype_p): New function, return true if function is\n+\tprototyped.\n+\n+\t* config/i386/i386.h (TARGET_SSE5): New macro for SSE5.\n+\t(TARGET_ROUND): New macro for the round/ptest instructions which\n+\tare shared between SSE4.1 and SSE5.\n+\t(OPTION_MASK_ISA_ROUND): Ditto.\n+\t(OPTION_ISA_ROUND): Ditto.\n+\t(TARGET_FUSED_MADD): New macro for -mfused-madd swtich.\n+\t(TARGET_CPU_CPP_BUILTINS): Add SSE5 support.\n+\n+\t* config/i386/i386.opt (-msse5): New switch for SSE5 support.\n+\t(-mfused-madd): New switch to give users control over whether the\n+\tcompiler optimizes to use the multiply/add SSE5 instructions.\n+\n+\t* config/i386/i386.c (m_AMD_MULTIPLE): Rename from\n+\tm_ATHLON_K8_AMDFAM10, and change all uses.\n+\t(enum pta_flags): Add PTA_SSE5.\n+\t(ix86_handle_option): Turn off 3dnow if -msse5.\n+\t(override_options): Add SSE5 support.\n+\t(print_operand): %Y prints comparison codes for SSE5 com/pcom\n+\tinstructions.\n+\t(ix86_expand_sse_movcc): Add SSE5 support.\n+\t(ix86_expand_sse5_unpack): New function to use pperm to unpack a\n+\tvector type to the next largest size.\n+\t(ix86_expand_sse5_pack): New function to use pperm to pack a\n+\tvector type to the next smallest size.\n+\t(IX86_BUILTIN_FMADDSS): New for SSE5 intrinsic.\n+\t(IX86_BUILTIN_FMADDSD): Ditto.\n+\t(IX86_BUILTIN_FMADDPS): Ditto.\n+\t(IX86_BUILTIN_FMADDPD): Ditto.\n+\t(IX86_BUILTIN_FMSUBSS): Ditto.\n+\t(IX86_BUILTIN_FMSUBSD): Ditto.\n+\t(IX86_BUILTIN_FMSUBPS): Ditto.\n+\t(IX86_BUILTIN_FMSUBPD): Ditto.\n+\t(IX86_BUILTIN_FNMADDSS): Ditto.\n+\t(IX86_BUILTIN_FNMADDSD): Ditto.\n+\t(IX86_BUILTIN_FNMADDPS): Ditto.\n+\t(IX86_BUILTIN_FNMADDPD): Ditto.\n+\t(IX86_BUILTIN_FNMSUBSS): Ditto.\n+\t(IX86_BUILTIN_FNMSUBSD): Ditto.\n+\t(IX86_BUILTIN_FNMSUBPS): Ditto.\n+\t(IX86_BUILTIN_FNMSUBPD): Ditto.\n+\t(IX86_BUILTIN_PCMOV_V2DI): Ditto.\n+\t(IX86_BUILTIN_PCMOV_V4SI): Ditto.\n+\t(IX86_BUILTIN_PCMOV_V8HI): Ditto.\n+\t(IX86_BUILTIN_PCMOV_V16QI): Ditto.\n+\t(IX86_BUILTIN_PCMOV_V4SF): Ditto.\n+\t(IX86_BUILTIN_PCMOV_V2DF): Ditto.\n+\t(IX86_BUILTIN_PPERM): Ditto.\n+\t(IX86_BUILTIN_PERMPS): Ditto.\n+\t(IX86_BUILTIN_PERMPD): Ditto.\n+\t(IX86_BUILTIN_PMACSSWW): Ditto.\n+\t(IX86_BUILTIN_PMACSWW): Ditto.\n+\t(IX86_BUILTIN_PMACSSWD): Ditto.\n+\t(IX86_BUILTIN_PMACSWD): Ditto.\n+\t(IX86_BUILTIN_PMACSSDD): Ditto.\n+\t(IX86_BUILTIN_PMACSDD): Ditto.\n+\t(IX86_BUILTIN_PMACSSDQL): Ditto.\n+\t(IX86_BUILTIN_PMACSSDQH): Ditto.\n+\t(IX86_BUILTIN_PMACSDQL): Ditto.\n+\t(IX86_BUILTIN_PMACSDQH): Ditto.\n+\t(IX86_BUILTIN_PMADCSSWD): Ditto.\n+\t(IX86_BUILTIN_PMADCSWD): Ditto.\n+\t(IX86_BUILTIN_PHADDBW): Ditto.\n+\t(IX86_BUILTIN_PHADDBD): Ditto.\n+\t(IX86_BUILTIN_PHADDBQ): Ditto.\n+\t(IX86_BUILTIN_PHADDWD): Ditto.\n+\t(IX86_BUILTIN_PHADDWQ): Ditto.\n+\t(IX86_BUILTIN_PHADDDQ): Ditto.\n+\t(IX86_BUILTIN_PHADDUBW): Ditto.\n+\t(IX86_BUILTIN_PHADDUBD): Ditto.\n+\t(IX86_BUILTIN_PHADDUBQ): Ditto.\n+\t(IX86_BUILTIN_PHADDUWD): Ditto.\n+\t(IX86_BUILTIN_PHADDUWQ): Ditto.\n+\t(IX86_BUILTIN_PHADDUDQ): Ditto.\n+\t(IX86_BUILTIN_PHSUBBW): Ditto.\n+\t(IX86_BUILTIN_PHSUBWD): Ditto.\n+\t(IX86_BUILTIN_PHSUBDQ): Ditto.\n+\t(IX86_BUILTIN_PROTB): Ditto.\n+\t(IX86_BUILTIN_PROTW): Ditto.\n+\t(IX86_BUILTIN_PROTD): Ditto.\n+\t(IX86_BUILTIN_PROTQ): Ditto.\n+\t(IX86_BUILTIN_PROTB_IMM): Ditto.\n+\t(IX86_BUILTIN_PROTW_IMM): Ditto.\n+\t(IX86_BUILTIN_PROTD_IMM): Ditto.\n+\t(IX86_BUILTIN_PROTQ_IMM): Ditto.\n+\t(IX86_BUILTIN_PSHLB): Ditto.\n+\t(IX86_BUILTIN_PSHLW): Ditto.\n+\t(IX86_BUILTIN_PSHLD): Ditto.\n+\t(IX86_BUILTIN_PSHLQ): Ditto.\n+\t(IX86_BUILTIN_PSHAB): Ditto.\n+\t(IX86_BUILTIN_PSHAW): Ditto.\n+\t(IX86_BUILTIN_PSHAD): Ditto.\n+\t(IX86_BUILTIN_PSHAQ): Ditto.\n+\t(IX86_BUILTIN_FRCZSS): Ditto.\n+\t(IX86_BUILTIN_FRCZSD): Ditto.\n+\t(IX86_BUILTIN_FRCZPS): Ditto.\n+\t(IX86_BUILTIN_FRCZPD): Ditto.\n+\t(IX86_BUILTIN_CVTPH2PS): Ditto.\n+\t(IX86_BUILTIN_CVTPS2PH): Ditto.\n+\t(IX86_BUILTIN_COMEQSS): Ditto.\n+\t(IX86_BUILTIN_COMNESS): Ditto.\n+\t(IX86_BUILTIN_COMLTSS): Ditto.\n+\t(IX86_BUILTIN_COMLESS): Ditto.\n+\t(IX86_BUILTIN_COMGTSS): Ditto.\n+\t(IX86_BUILTIN_COMGESS): Ditto.\n+\t(IX86_BUILTIN_COMUEQSS): Ditto.\n+\t(IX86_BUILTIN_COMUNESS): Ditto.\n+\t(IX86_BUILTIN_COMULTSS): Ditto.\n+\t(IX86_BUILTIN_COMULESS): Ditto.\n+\t(IX86_BUILTIN_COMUGTSS): Ditto.\n+\t(IX86_BUILTIN_COMUGESS): Ditto.\n+\t(IX86_BUILTIN_COMORDSS): Ditto.\n+\t(IX86_BUILTIN_COMUNORDSS): Ditto.\n+\t(IX86_BUILTIN_COMFALSESS): Ditto.\n+\t(IX86_BUILTIN_COMTRUESS): Ditto.\n+\t(IX86_BUILTIN_COMEQSD): Ditto.\n+\t(IX86_BUILTIN_COMNESD): Ditto.\n+\t(IX86_BUILTIN_COMLTSD): Ditto.\n+\t(IX86_BUILTIN_COMLESD): Ditto.\n+\t(IX86_BUILTIN_COMGTSD): Ditto.\n+\t(IX86_BUILTIN_COMGESD): Ditto.\n+\t(IX86_BUILTIN_COMUEQSD): Ditto.\n+\t(IX86_BUILTIN_COMUNESD): Ditto.\n+\t(IX86_BUILTIN_COMULTSD): Ditto.\n+\t(IX86_BUILTIN_COMULESD): Ditto.\n+\t(IX86_BUILTIN_COMUGTSD): Ditto.\n+\t(IX86_BUILTIN_COMUGESD): Ditto.\n+\t(IX86_BUILTIN_COMORDSD): Ditto.\n+\t(IX86_BUILTIN_COMUNORDSD): Ditto.\n+\t(IX86_BUILTIN_COMFALSESD): Ditto.\n+\t(IX86_BUILTIN_COMTRUESD): Ditto.\n+\t(IX86_BUILTIN_COMEQPS): Ditto.\n+\t(IX86_BUILTIN_COMNEPS): Ditto.\n+\t(IX86_BUILTIN_COMLTPS): Ditto.\n+\t(IX86_BUILTIN_COMLEPS): Ditto.\n+\t(IX86_BUILTIN_COMGTPS): Ditto.\n+\t(IX86_BUILTIN_COMGEPS): Ditto.\n+\t(IX86_BUILTIN_COMUEQPS): Ditto.\n+\t(IX86_BUILTIN_COMUNEPS): Ditto.\n+\t(IX86_BUILTIN_COMULTPS): Ditto.\n+\t(IX86_BUILTIN_COMULEPS): Ditto.\n+\t(IX86_BUILTIN_COMUGTPS): Ditto.\n+\t(IX86_BUILTIN_COMUGEPS): Ditto.\n+\t(IX86_BUILTIN_COMORDPS): Ditto.\n+\t(IX86_BUILTIN_COMUNORDPS): Ditto.\n+\t(IX86_BUILTIN_COMFALSEPS): Ditto.\n+\t(IX86_BUILTIN_COMTRUEPS): Ditto.\n+\t(IX86_BUILTIN_COMEQPD): Ditto.\n+\t(IX86_BUILTIN_COMNEPD): Ditto.\n+\t(IX86_BUILTIN_COMLTPD): Ditto.\n+\t(IX86_BUILTIN_COMLEPD): Ditto.\n+\t(IX86_BUILTIN_COMGTPD): Ditto.\n+\t(IX86_BUILTIN_COMGEPD): Ditto.\n+\t(IX86_BUILTIN_COMUEQPD): Ditto.\n+\t(IX86_BUILTIN_COMUNEPD): Ditto.\n+\t(IX86_BUILTIN_COMULTPD): Ditto.\n+\t(IX86_BUILTIN_COMULEPD): Ditto.\n+\t(IX86_BUILTIN_COMUGTPD): Ditto.\n+\t(IX86_BUILTIN_COMUGEPD): Ditto.\n+\t(IX86_BUILTIN_COMORDPD): Ditto.\n+\t(IX86_BUILTIN_COMUNORDPD): Ditto.\n+\t(IX86_BUILTIN_COMFALSEPD): Ditto.\n+\t(IX86_BUILTIN_COMTRUEPD): Ditto.\n+\t(IX86_BUILTIN_PCOMEQUB): Ditto.\n+\t(IX86_BUILTIN_PCOMNEUB): Ditto.\n+\t(IX86_BUILTIN_PCOMLTUB): Ditto.\n+\t(IX86_BUILTIN_PCOMLEUB): Ditto.\n+\t(IX86_BUILTIN_PCOMGTUB): Ditto.\n+\t(IX86_BUILTIN_PCOMGEUB): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSEUB): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUEUB): Ditto.\n+\t(IX86_BUILTIN_PCOMEQUW): Ditto.\n+\t(IX86_BUILTIN_PCOMNEUW): Ditto.\n+\t(IX86_BUILTIN_PCOMLTUW): Ditto.\n+\t(IX86_BUILTIN_PCOMLEUW): Ditto.\n+\t(IX86_BUILTIN_PCOMGTUW): Ditto.\n+\t(IX86_BUILTIN_PCOMGEUW): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSEUW): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUEUW): Ditto.\n+\t(IX86_BUILTIN_PCOMEQUD): Ditto.\n+\t(IX86_BUILTIN_PCOMNEUD): Ditto.\n+\t(IX86_BUILTIN_PCOMLTUD): Ditto.\n+\t(IX86_BUILTIN_PCOMLEUD): Ditto.\n+\t(IX86_BUILTIN_PCOMGTUD): Ditto.\n+\t(IX86_BUILTIN_PCOMGEUD): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSEUD): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUEUD): Ditto.\n+\t(IX86_BUILTIN_PCOMEQUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMNEUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMLTUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMLEUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMGTUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMGEUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSEUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUEUQ): Ditto.\n+\t(IX86_BUILTIN_PCOMEQB): Ditto.\n+\t(IX86_BUILTIN_PCOMNEB): Ditto.\n+\t(IX86_BUILTIN_PCOMLTB): Ditto.\n+\t(IX86_BUILTIN_PCOMLEB): Ditto.\n+\t(IX86_BUILTIN_PCOMGTB): Ditto.\n+\t(IX86_BUILTIN_PCOMGEB): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSEB): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUEB): Ditto.\n+\t(IX86_BUILTIN_PCOMEQW): Ditto.\n+\t(IX86_BUILTIN_PCOMNEW): Ditto.\n+\t(IX86_BUILTIN_PCOMLTW): Ditto.\n+\t(IX86_BUILTIN_PCOMLEW): Ditto.\n+\t(IX86_BUILTIN_PCOMGTW): Ditto.\n+\t(IX86_BUILTIN_PCOMGEW): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSEW): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUEW): Ditto.\n+\t(IX86_BUILTIN_PCOMEQD): Ditto.\n+\t(IX86_BUILTIN_PCOMNED): Ditto.\n+\t(IX86_BUILTIN_PCOMLTD): Ditto.\n+\t(IX86_BUILTIN_PCOMLED): Ditto.\n+\t(IX86_BUILTIN_PCOMGTD): Ditto.\n+\t(IX86_BUILTIN_PCOMGED): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSED): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUED): Ditto.\n+\t(IX86_BUILTIN_PCOMEQQ): Ditto.\n+\t(IX86_BUILTIN_PCOMNEQ): Ditto.\n+\t(IX86_BUILTIN_PCOMLTQ): Ditto.\n+\t(IX86_BUILTIN_PCOMLEQ): Ditto.\n+\t(IX86_BUILTIN_PCOMGTQ): Ditto.\n+\t(IX86_BUILTIN_PCOMGEQ): Ditto.\n+\t(IX86_BUILTIN_PCOMFALSEQ): Ditto.\n+\t(IX86_BUILTIN_PCOMTRUEQ): Ditto.\n+\t(bdesc_ptest): Change OPTION_MASK_ISA_SSE4_1 to\n+\tOPTION_MASK_ISA_ROUND for instructions that are shared between\n+\tSSE4.1 and SSE5.\n+\t(bdesc_2arg): Ditto.\n+\t(bdesc_sse_3arg): Ditto.\n+\t(enum multi_arg_type): New enum for describing the various SSE5\n+\tintrinsic argument types.\n+\t(bdesc_multi_arg): New table for SSE5 intrinsics.\n+\t(ix86_init_mmx_sse_builtins): Add SSE5 intrinsic support.\n+\t(ix86_expand_multi_arg_builtin): New function for creating SSE5\n+\tintrinsics.\n+\t(ix86_expand_builtin): Add SSE5 intrinsic support.\n+\t(ix86_sse5_valid_op_p): New function to validate SSE5 3 and 4\n+\toperand instructions.\n+\t(ix86_expand_sse5_multiple_memory): New function to split the\n+\tsecond memory reference from SSE5 instructions.\n+\t(type_has_variadic_args_p): Delete in favor of stdarg_p.\n+\t(ix86_return_pops_args): Use stdarg_p to determine if the function\n+\thas variable arguments.\n+\t(ix86_setup_incoming_varargs): Ditto.\n+\t(x86_this_parameter): Ditto.\n+\n+\t* config/i386/i386-protos.h (ix86_expand_sse5_unpack): Add\n+\tdeclaration.\n+\t(ix86_expand_sse5_pack): Ditto.\n+\t(ix86_sse5_valid_op_p): Ditto.\n+\t(ix86_expand_sse5_multiple_memory): Ditto.\n+\n+\t* config/i386/i386.md (UNSPEC_SSE5_INTRINSIC): Add new UNSPEC\n+\tconstant for SSE5 support.\n+\t(UNSPEC_SSE5_UNSIGNED_CMP): Ditto.\n+\t(UNSPEC_SSE5_TRUEFALSE): Ditto.\n+\t(UNSPEC_SSE5_PERMUTE): Ditto.\n+\t(UNSPEC_SSE5_ASHIFT): Ditto.\n+\t(UNSPEC_SSE5_LSHIFT): Ditto.\n+\t(UNSPEC_FRCZ): Ditto.\n+\t(UNSPEC_CVTPH2PS): Ditto.\n+\t(UNSPEC_CVTPS2PH): Ditto.\n+\t(PCOM_FALSE): Add new constant for true/false SSE5 comparisons.\n+\t(PCOM_TRUE): Ditto.\n+\t(COM_FALSE_S): Ditto.\n+\t(COM_FALSE_P): Ditto.\n+\t(COM_TRUE_S): Ditto.\n+\t(COM_TRUE_P): Ditto.\n+\t(type attribute): Add ssemuladd, sseiadd1, ssecvt1, sse4arg types.\n+\t(unit attribute): Add support for ssemuladd, ssecvt1, sseiadd1 sse4arg\n+\ttypes.\n+\t(memory attribute): Ditto.\n+\t(sse4_1_round<mode>2): Use TARGET_ROUND instead of TARGET_SSE4_1.\n+\tUse SSE4_1_ROUND_* constants instead of hard coded numbers.\n+\t(rint<mode>2): Use TARGET_ROUND instead of TARGET_SSE4_1.\n+\t(floor<mode>2): Ditto.\n+\t(ceil<mode>2): Ditto.\n+\t(btrunc<mode>2): Ditto.\n+\t(nearbyintdf2): Ditto.\n+\t(nearbyintsf2): Ditto.\n+\t(sse_setccsf): Disable if SSE5.\n+\t(sse_setccdf): Ditto.\n+\t(sse5_setcc<mode>): New support for SSE5 conditional move.\n+\t(sse5_pcmov_<mode>): Ditto.\n+\n+\t* config/i386/sse.md (SSEMODE1248): New mode iterator for SSE5.\n+\t(SSEMODEF4): Ditto.\n+\t(SSEMODEF2P): Ditto.\n+\t(ssemodesuffixf4): New mode attribute for SSE5.\n+\t(ssemodesuffixf2s): Ditto.\n+\t(ssemodesuffixf2c): Ditto.\n+\t(sserotatemax): Ditto.\n+\t(ssescalarmode): Ditto.\n+\t(sse_maskcmpv4sf3): Disable if SSE5.\n+\t(sse_maskcmpv2df3): Ditto.\n+\t(sse_vmmaskcmpv4sf3): Ditto.\n+\t(sse5_fmadd<mode>4): Add SSE5 floating point multiply/add\n+\tinstructions.\n+\t(sse5_vmfmadd<mode>4): Ditto.\n+\t(sse5_fmsub<mode>4): Ditto.\n+\t(sse5_vmfmsub<mode>4): Ditto.\n+\t(sse5_fnmadd<mode>4): Ditto.\n+\t(sse5_vmfnmadd<mode>4): Ditto.\n+\t(sse5_fnmsub<mode>4): Ditto.\n+\t(sse5_vmfnmsub<mode>4): Ditto.\n+\t(sse5i_fmadd<mode>4): Ditto.\n+\t(sse5i_fmsub<mode>4): Ditto.\n+\t(sse5i_fnmadd<mode>4): Ditto.\n+\t(sse5i_fnmsub<mode>4): Ditto.\n+\t(sse5i_vmfmadd<mode>4): Ditto.\n+\t(sse5i_vmfmsub<mode>4): Ditto.\n+\t(sse5i_vmfnmadd<mode>4): Ditto.\n+\t(sse5i_vmfnmsub<mode>4): Ditto.\n+\t(mulv16qi3): Add SSE5 support.\n+\t(mulv4si3): Ditto.\n+\t(sse5_mulv4si3): New insn for 32-bit multiply support on SSE5.\n+\t(sse2_mulv4si3): Disable if SSE5.\n+\t(sse4_1_roundpd): Use TARGET_ROUND instead of TARGET_SSE4_1.\n+\t(sse4_1_roundps): Ditto.\n+\t(sse4_1_roundsd): Ditto.\n+\t(sse4_1_roundss): Ditto.\n+\t(sse_maskcmpv4sf3): Disable if SSE5 so the SSE5 instruction will\n+\tbe generated.\n+\t(sse_maskcmpsf3): Ditto.\n+\t(sse_vmmaskcmpv4sf3): Ditto.\n+\t(sse2_maskcmpv2df3): Ditto.\n+\t(sse2_maskcmpdf3): Ditto.\n+\t(sse2_vmmaskcmpv2df3): Ditto.\n+\t(sse2_eq<mode>3): Ditto.\n+\t(sse2_gt<mode>3): Ditto.\n+\t(sse5_pcmov_<mode>): Add SSE5 support.\n+\t(vec_unpacku_hi_v16qi): Ditto.\n+\t(vec_unpacks_hi_v16qi): Ditto.\n+\t(vec_unpacku_lo_v16qi): Ditto.\n+\t(vec_unpacks_lo_v16qi): Ditto.\n+\t(vec_unpacku_hi_v8hi): Ditto.\n+\t(vec_unpacks_hi_v8hi): Ditto.\n+\t(vec_unpacku_lo_v8hi): Ditto.\n+\t(vec_unpacks_lo_v8hi): Ditto.\n+\t(vec_unpacku_hi_v4si): Ditto.\n+\t(vec_unpacks_hi_v4si): Ditto.\n+\t(vec_unpacku_lo_v4si): Ditto.\n+\t(vec_unpacks_lo_v4si): Ditto.\n+\t(sse5_pmacsww): New SSE5 intrinsic insn.\n+\t(sse5_pmacssww): Ditto.\n+\t(sse5_pmacsdd): Ditto.\n+\t(sse5_pmacssdd): Ditto.\n+\t(sse5_pmacssdql): Ditto.\n+\t(sse5_pmacssdqh): Ditto.\n+\t(sse5_pmacsdqh): Ditto.\n+\t(sse5_pmacsswd): Ditto.\n+\t(sse5_pmacswd): Ditto.\n+\t(sse5_pmadcsswd): Ditto.\n+\t(sse5_pmadcswd): Ditto.\n+\t(sse5_pcmov_<move>): Conditional move support on SSE5.\n+\t(sse5_phaddbw): New SSE5 intrinsic insn.\n+\t(sse5_phaddbd): Ditto.\n+\t(sse5_phaddbq): Ditto.\n+\t(sse5_phaddwd): Ditto.\n+\t(sse5_phaddwq): Ditto.\n+\t(sse5_phadddq): Ditto.\n+\t(sse5_phaddubw): Ditto.\n+\t(sse5_phaddubd): Ditto.\n+\t(sse5_phaddubq): Ditto.\n+\t(sse5_phadduwd): Ditto.\n+\t(sse5_phadduwq): Ditto.\n+\t(sse5_phaddudq): Ditto.\n+\t(sse5_phsubbw): Ditto.\n+\t(sse5_phsubwd): Ditto.\n+\t(sse5_phsubdq): Ditto.\n+\t(sse5_pperm): Ditto.\n+\t(sse5_pperm_sign_v16qi_v8hi): New insns for pack/unpack with SSE5.\n+\t(sse5_pperm_zero_v16qi_v8hi): Ditto.\n+\t(sse5_pperm_sign_v8hi_v4si): Ditto.\n+\t(sse5_pperm_zero_v8hi_v4si): Ditto.\n+\t(sse5_pperm_sign_v4si_v2di): Ditto.\n+\t(sse5_pperm_sign_v4si_v2di): Ditto.\n+\t(sse5_pperm_pack_v2di_v4si): Ditto.\n+\t(sse5_pperm_pack_v4si_v8hi): Ditto.\n+\t(sse5_pperm_pack_v8hi_v16qi): Ditto.\n+\t(sse5_perm<mode>): New SSE5 intrinsic insn.\n+\t(rotl<mode>3): Ditto.\n+\t(sse5_rotl<mode>3): Ditto.\n+\t(sse5_ashl<mode>3): Ditto.\n+\t(sse5_lshl<mode>3): Ditto.\n+\t(sse5_frcz<mode>2): Ditto.\n+\t(sse5s_frcz<mode>2): Ditto.\n+\t(sse5_cvtph2ps): Ditto.\n+\t(sse5_cvtps2ph): Ditto.\n+\t(sse5_vmmaskcmp<mode>3): Ditto.\n+\t(sse5_com_tf<mode>3): Ditto.\n+\t(sse5_maskcmp<mode>3): Ditto.\n+\t(sse5_maskcmp_uns<mode>3): Ditto.\n+\t(sse5_maskcmp_uns2<mode>3): Ditto.\n+\t(sse5_pcom_tf<mode>3): Ditto.\n+\t\n+\t* config/i386/predicates.md (const_0_to_31_operand): New predicate\n+\tto match 0..31.\n+\t(sse5_comparison_float_operator): New predicate to match the\n+\tcomparison operators supported by the SSE5 com instruction.\n+\t(ix86_comparison_int_operator): New predicate to match just the\n+\tsigned int comparisons.\n+\t(ix86_comparison_uns_operator): New predicate to match just the\n+\tunsigned int comparisons.\n+\n+\t* doc/invoke.texi (-msse5): Add documentation.\n+\t(-mfused-madd): Ditto.\n+\n+\t* doc/extend.texi (x86 intrinsics): Document new SSE5 intrinsics.\n+\n+\t* config.gcc (i[34567]86-*-*): Include bmmintrin.h and\n+\tmmintrin-common.h.\n+\t(x86_64-*-*): Ditto.\n+\n+\t* config/i386/cpuid.h (bit_SSE5): Define SSE5 bit.\n+\n+\t* config/i386/bmmintrin.h: New file, provide common x86 compiler\n+\tintrinisics for SSE5.\n+\n+\t* config/i386/smmintrin.h: Move instructions shared with SSE5 to\n+\tmmintrin-common.h.\n+\n+\t* config/i386/mmintrin-common.h: New file, to contain common\n+\tinstructions between SSE4.1 and SSE5.\n+\n+\t* config/i386/netware.c (gen_stdcall_or_fastcall_decoration): Use\n+\tFOREACH_FUNCTION_ARGS to iterate over the argument list.\n+\t(gen_regparm_prefix): Ditto.\n+\n+\t* config/i386/winnt.c (gen_stdcall_or_fastcall_suffix): Use\n+\tFOREACH_FUNCTION_ARGS to iterate over the argument list.  Use\n+\tprototype_p to determine if a function is prototyped.\n+\n 2007-09-12  Janis Johnson  <janis187@us.ibm.com\n \n \t* config/dfp-bit.c (dfp_conversion_exception): New function."}, {"sha": "6101365138cc96a9e5a0a9718b629aac578ca806", "filename": "gcc/config.gcc", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -280,13 +280,13 @@ i[34567]86-*-*)\n \tcpu_type=i386\n \textra_headers=\"cpuid.h mmintrin.h mm3dnow.h xmmintrin.h emmintrin.h\n \t\t       pmmintrin.h tmmintrin.h ammintrin.h smmintrin.h\n-\t\t       nmmintrin.h\"\n+\t\t       nmmintrin.h bmmintrin.h mmintrin-common.h\"\n \t;;\n x86_64-*-*)\n \tcpu_type=i386\n \textra_headers=\"cpuid.h mmintrin.h mm3dnow.h xmmintrin.h emmintrin.h\n \t\t       pmmintrin.h tmmintrin.h ammintrin.h smmintrin.h\n-\t\t       nmmintrin.h\"\n+\t\t       nmmintrin.h bmmintrin.h mmintrin-common.h\"\n \tneed_64bit_hwint=yes\n \t;;\n ia64-*-*)"}, {"sha": "f321cee0d3631718653976291168153911676d7d", "filename": "gcc/config/i386/bmmintrin.h", "status": "added", "additions": 1260, "deletions": 0, "changes": 1260, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fbmmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fbmmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fbmmintrin.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,1260 @@\n+/* Copyright (C) 2007 Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify\n+   it under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 2, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING.  If not, write to\n+   the Free Software Foundation, 51 Franklin Street, Fifth Floor,\n+   Boston, MA 02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source\n+   files compiled by GCC, this header file does not by itself cause\n+   the resulting executable to be covered by the GNU General Public\n+   License.  This exception does not however invalidate any other\n+   reasons why the executable file might be covered by the GNU General\n+   Public License.  */\n+\n+#ifndef _BMMINTRIN_H_INCLUDED\n+#define _BMMINTRIN_H_INCLUDED\n+\n+#ifndef __SSE5__\n+# error \"SSE5 instruction set not enabled\"\n+#else\n+\n+/* We need definitions from the SSE4A, SSE3, SSE2 and SSE header files.  */\n+#include <ammintrin.h>\n+#include <mmintrin-common.h>\n+\n+/* Floating point multiply/add type instructions */\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_macc_ps(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return (__m128) __builtin_ia32_fmaddps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_macc_pd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fmaddpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_macc_ss(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return  (__m128) __builtin_ia32_fmaddss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_macc_sd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fmaddsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_msub_ps(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return (__m128) __builtin_ia32_fmsubps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_msub_pd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fmsubpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_msub_ss(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return (__m128) __builtin_ia32_fmsubss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_msub_sd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fmsubsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_nmacc_ps(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return (__m128) __builtin_ia32_fnmaddps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_nmacc_pd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fnmaddpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_nmacc_ss(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return (__m128) __builtin_ia32_fnmaddss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_nmacc_sd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fnmaddsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_nmsub_ps(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return (__m128) __builtin_ia32_fnmsubps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_nmsub_pd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fnmsubpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_nmsub_ss(__m128 __A, __m128 __B, __m128 __C)\n+{\n+  return (__m128) __builtin_ia32_fnmsubss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_nmsub_sd(__m128d __A, __m128d __B, __m128d __C)\n+{\n+  return (__m128d) __builtin_ia32_fnmsubsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+}\n+\n+/* Integer multiply/add intructions. */\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maccs_epi16(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return (__m128i) __builtin_ia32_pmacssww ((__v8hi)__A,(__v8hi)__B, (__v8hi)__C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_macc_epi16(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return (__m128i) __builtin_ia32_pmacsww ((__v8hi)__A, (__v8hi)__B, (__v8hi)__C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maccsd_epi16(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacsswd ((__v8hi)__A, (__v8hi)__B, (__v4si)__C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maccd_epi16(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacswd ((__v8hi)__A, (__v8hi)__B, (__v4si)__C); \n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maccs_epi32(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacssdd ((__v4si)__A, (__v4si)__B, (__v4si)__C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_macc_epi32(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacsdd ((__v4si)__A, (__v4si)__B, (__v4si)__C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maccslo_epi32(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacssdql ((__v4si)__A, (__v4si)__B, (__v2di)__C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_macclo_epi32(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacsdql ((__v4si)__A, (__v4si)__B, (__v2di)__C); \n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maccshi_epi32(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacssdqh ((__v4si)__A, (__v4si)__B, (__v2di)__C); \n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_macchi_epi32(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmacsdqh ((__v4si)__A, (__v4si)__B, (__v2di)__C); \n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maddsd_epi16(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmadcsswd ((__v8hi)__A,(__v8hi)__B,(__v4si)__C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_maddd_epi16(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pmadcswd ((__v8hi)__A,(__v8hi)__B,(__v4si)__C);\n+}\n+\n+/* Packed Integer Horizontal Add and Subtract */\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddw_epi8(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddbw ((__v16qi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddd_epi8(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddbd ((__v16qi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddq_epi8(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddbq ((__v16qi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddd_epi16(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddwd ((__v8hi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddq_epi16(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddwq ((__v8hi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddq_epi32(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phadddq ((__v4si)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddw_epu8(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddubw ((__v16qi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddd_epu8(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddubd ((__v16qi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddq_epu8(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddubq ((__v16qi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddd_epu16(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phadduwd ((__v8hi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddq_epu16(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phadduwq ((__v8hi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_haddq_epu32(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phaddudq ((__v4si)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_hsubw_epi8(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phsubbw ((__v16qi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_hsubd_epi16(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phsubwd ((__v8hi)__A);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_hsubq_epi32(__m128i __A)\n+{\n+  return  (__m128i) __builtin_ia32_phsubdq ((__v4si)__A);\n+}\n+\n+/* Vector conditional move and permute */\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_cmov_si128(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pcmov (__A, __B, __C);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_perm_epi8(__m128i __A, __m128i __B, __m128i __C)\n+{\n+  return  (__m128i) __builtin_ia32_pperm ((__v16qi)__A, (__v16qi)__B, (__v16qi)__C);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_perm_ps(__m128 __A, __m128 __B, __m128i __C)\n+{\n+  return  (__m128) __builtin_ia32_permps ((__m128)__A, (__m128)__B, (__v16qi)__C);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_perm_pd(__m128d __A, __m128d __B, __m128i __C)\n+{\n+  return  (__m128d) __builtin_ia32_permpd ((__m128d)__A, (__m128d)__B, (__v16qi)__C);\n+}\n+\n+/* Packed Integer Rotates and Shifts */\n+\n+/* Rotates - Non-Immediate form */\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_rot_epi8(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_protb ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_rot_epi16(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_protw ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_rot_epi32(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_protd ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_rot_epi64(__m128i __A,  __m128i __B)\n+{\n+  return (__m128i)  __builtin_ia32_protq ((__v2di)__A, (__v2di)__B);\n+}\n+\n+\n+/* Rotates - Immediate form */\n+#ifdef __OPTIMIZE__\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_roti_epi8(__m128i __A,  int __B)\n+{\n+  return  (__m128i) __builtin_ia32_protbi ((__v16qi)__A, __B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_roti_epi16(__m128i __A, int __B)\n+{\n+  return  (__m128i) __builtin_ia32_protwi ((__v8hi)__A, __B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_roti_epi32(__m128i __A, int __B)\n+{\n+  return  (__m128i) __builtin_ia32_protdi ((__v4si)__A, __B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_roti_epi64(__m128i __A, int __B)\n+{\n+  return  (__m128i) __builtin_ia32_protqi ((__v2di)__A, __B);\n+}\n+#else\n+#define _mm_roti_epi8(A, B) ((_m128i) __builtin_ia32_protbi ((__v16qi)(A), B)\n+#define _mm_roti_epi16(A, B) ((_m128i) __builtin_ia32_protwi ((__v8hi)(A), B)\n+#define _mm_roti_epi32(A, B) ((_m128i) __builtin_ia32_protdi ((__v4si)(A), B)\n+#define _mm_roti_epi64(A, B) ((_m128i) __builtin_ia32_protqi ((__v2di)(A), B)\n+#endif\n+\n+/* pshl */\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_shl_epi8(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshlb ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_shl_epi16(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshlw ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_shl_epi32(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshld ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_shl_epi64(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshlq ((__v2di)__A, (__v2di)__B);\n+}\n+\n+/* psha */\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_sha_epi8(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshab ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_sha_epi16(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshaw ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_sha_epi32(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshad ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i __attribute__((__always_inline__)) \n+_mm_sha_epi64(__m128i __A,  __m128i __B)\n+{\n+  return  (__m128i) __builtin_ia32_pshaq ((__v2di)__A, (__v2di)__B);\n+}\n+\n+/* Compare and Predicate Generation */\n+\n+/* com (floating point, packed single) */\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comeq_ps(__m128 __A, __m128 __B)\n+{\n+  return  (__m128) __builtin_ia32_comeqps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comlt_ps(__m128 __A, __m128 __B)\n+{\n+  return  (__m128) __builtin_ia32_comltps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comle_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comleps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comunord_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comunordps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comneq_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comuneqps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comnlt_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comunltps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comnle_ps(__m128 __A, __m128 __B) \n+{\n+  return (__m128)  __builtin_ia32_comunleps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comord_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comordps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comueq_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comueqps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comnge_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comungeps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comngt_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comungtps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comfalse_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comfalseps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comoneq_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comneqps ((__v4sf)__A, (__v4sf)__B); \n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comge_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comgeps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comgt_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comgtps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comtrue_ps(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comtrueps ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+/* com (floating point, packed double) */\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comeq_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comeqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comlt_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comltpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comle_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comlepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comunord_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comunordpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comneq_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comuneqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comnlt_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comunltpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comnle_pd(__m128d __A, __m128d __B) \n+{\n+  return (__m128d) __builtin_ia32_comunlepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comord_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comordpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comueq_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comueqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comnge_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comungepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comngt_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comungtpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comfalse_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comfalsepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comoneq_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comneqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comge_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comgepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comgt_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comgtpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comtrue_pd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comtruepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+/* com (floating point, scalar single) */\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comeq_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128)  __builtin_ia32_comeqss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comlt_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comltss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comle_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comless ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comunord_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comunordss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comneq_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comuneqss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comnlt_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comunltss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comnle_ss(__m128 __A, __m128 __B) \n+{\n+  return (__m128) __builtin_ia32_comunless ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comord_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comordss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_comueq_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comueqss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comnge_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comungess ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comngt_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comungtss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comfalse_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comfalsess ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comoneq_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comneqss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comge_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comgess ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comgt_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comgtss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__)) \n+_mm_comtrue_ss(__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_comtruess ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+/* com (floating point, scalar double) */\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comeq_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comeqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comlt_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comltsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comle_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comlesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comunord_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comunordsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comneq_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comuneqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comnlt_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comunltsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comnle_sd(__m128d __A, __m128d __B) \n+{\n+  return (__m128d) __builtin_ia32_comunlesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comord_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comordsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comueq_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comueqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comnge_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comungesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comngt_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comungtsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comfalse_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comfalsesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_comoneq_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comneqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comge_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comgesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comgt_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comgtsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__)) \n+_mm_comtrue_sd(__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_comtruesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+\n+/*pcom (integer, unsinged bytes) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltub ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomleub ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtub ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgeub ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomequb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomnequb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalseub ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epu8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtrueub ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+/*pcom (integer, unsinged words) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltuw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomleuw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtuw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgeuw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomequw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomnequw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalseuw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epu16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtrueuw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+/*pcom (integer, unsinged double words) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltud ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomleud ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtud ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgeud ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomequd ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomnequd ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalseud ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epu32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtrueud ((__v4si)__A, (__v4si)__B);\n+} \n+\n+/*pcom (integer, unsinged quad words) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltuq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomleuq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtuq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgeuq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomequq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomnequq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalseuq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epu64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtrueuq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+/*pcom (integer, signed bytes) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomleb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgeb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomeqb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomneqb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalseb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epi8(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtrueb ((__v16qi)__A, (__v16qi)__B);\n+} \n+\n+/*pcom (integer, signed words) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomlew ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgew ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomeqw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomneqw ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalsew ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epi16(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtruew ((__v8hi)__A, (__v8hi)__B);\n+} \n+\n+/*pcom (integer, signed double words) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltd ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomled ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtd ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomged ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomeqd ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomneqd ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalsed ((__v4si)__A, (__v4si)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epi32(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtrued ((__v4si)__A, (__v4si)__B);\n+} \n+\n+/*pcom (integer, signed quad words) */\n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comlt_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomltq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comle_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomleq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comgt_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgtq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comge_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomgeq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comeq_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomeqq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comneq_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomneqq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comfalse_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomfalseq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+static __inline __m128i __attribute__((__always_inline__))\n+_mm_comtrue_epi64(__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pcomtrueq ((__v2di)__A, (__v2di)__B);\n+} \n+\n+/* FRCZ */\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_frcz_ps (__m128 __A)\n+{\n+  return (__m128) __builtin_ia32_frczps ((__v4sf)__A);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_frcz_pd (__m128d __A)\n+{\n+  return (__m128d) __builtin_ia32_frczpd ((__v2df)__A);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_frcz_ss (__m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_frczss ((__v4sf)__A, (__v4sf)__B);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_frcz_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_frczsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+#endif /* __SSE5__ */\n+\n+#endif /* _BMMINTRIN_H_INCLUDED */"}, {"sha": "aaad1b1679f848f042995ee65ff06140a2e54ba5", "filename": "gcc/config/i386/cpuid.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fcpuid.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fcpuid.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fcpuid.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -51,6 +51,7 @@\n /* %ecx */\n #define bit_LAHF_LM\t(1 << 0)\n #define bit_SSE4a\t(1 << 6)\n+#define bit_SSE5\t(1 << 11)\n \n /* %edx */\n #define bit_LM\t\t(1 << 29)"}, {"sha": "bb40af936e4fe4aae724367d1ce4c79ec745eb2a", "filename": "gcc/config/i386/i386-protos.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-protos.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -112,6 +112,8 @@ extern bool ix86_expand_fp_vcond (rtx[]);\n extern bool ix86_expand_int_vcond (rtx[]);\n extern void ix86_expand_sse_unpack (rtx[], bool, bool);\n extern void ix86_expand_sse4_unpack (rtx[], bool, bool);\n+extern void ix86_expand_sse5_unpack (rtx[], bool, bool);\n+extern void ix86_expand_sse5_pack (rtx[]);\n extern int ix86_expand_int_addcc (rtx[]);\n extern void ix86_expand_call (rtx, rtx, rtx, rtx, rtx, int);\n extern void x86_initialize_trampoline (rtx, rtx, rtx);\n@@ -205,6 +207,9 @@ extern void ix86_expand_vector_set (bool, rtx, rtx, int);\n extern void ix86_expand_vector_extract (bool, rtx, rtx, int);\n extern void ix86_expand_reduc_v4sf (rtx (*)(rtx, rtx, rtx), rtx, rtx);\n \n+extern bool ix86_sse5_valid_op_p (rtx [], rtx, int, bool, int);\n+extern void ix86_expand_sse5_multiple_memory (rtx [], int, enum machine_mode);\n+\n /* In winnt.c  */\n extern void i386_pe_unique_section (tree, int);\n extern void i386_pe_declare_function_type (FILE *, const char *, int);"}, {"sha": "0ec93f3680453f42ddca1a0e21360ec4cef4bb71", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 1326, "deletions": 61, "changes": 1387, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -1197,7 +1197,7 @@ const struct processor_costs *ix86_cost = &pentium_cost;\n #define m_ATHLON  (1<<PROCESSOR_ATHLON)\n #define m_ATHLON_K8  (m_K8 | m_ATHLON)\n #define m_AMDFAM10  (1<<PROCESSOR_AMDFAM10)\n-#define m_ATHLON_K8_AMDFAM10  (m_K8 | m_ATHLON | m_AMDFAM10)\n+#define m_AMD_MULTIPLE  (m_K8 | m_ATHLON | m_AMDFAM10)\n \n #define m_GENERIC32 (1<<PROCESSOR_GENERIC32)\n #define m_GENERIC64 (1<<PROCESSOR_GENERIC64)\n@@ -1212,10 +1212,10 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n      negatively, so enabling for Generic64 seems like good code size\n      tradeoff.  We can't enable it for 32bit generic because it does not\n      work well with PPro base chips.  */\n-  m_386 | m_K6_GEODE | m_ATHLON_K8_AMDFAM10 | m_CORE2 | m_GENERIC64,\n+  m_386 | m_K6_GEODE | m_AMD_MULTIPLE | m_CORE2 | m_GENERIC64,\n \n   /* X86_TUNE_PUSH_MEMORY */\n-  m_386 | m_K6_GEODE | m_ATHLON_K8_AMDFAM10 | m_PENT4\n+  m_386 | m_K6_GEODE | m_AMD_MULTIPLE | m_PENT4\n   | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_ZERO_EXTEND_WITH_AND */\n@@ -1225,10 +1225,10 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n   m_386,\n \n   /* X86_TUNE_UNROLL_STRLEN */\n-  m_486 | m_PENT | m_PPRO | m_ATHLON_K8_AMDFAM10 | m_K6 | m_CORE2 | m_GENERIC,\n+  m_486 | m_PENT | m_PPRO | m_AMD_MULTIPLE | m_K6 | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_DEEP_BRANCH_PREDICTION */\n-  m_PPRO | m_K6_GEODE | m_ATHLON_K8_AMDFAM10 | m_PENT4 | m_GENERIC,\n+  m_PPRO | m_K6_GEODE | m_AMD_MULTIPLE | m_PENT4 | m_GENERIC,\n \n   /* X86_TUNE_BRANCH_PREDICTION_HINTS: Branch hints were put in P4 based\n      on simulation result. But after P4 was made, no performance benefit\n@@ -1245,7 +1245,7 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n \n   /* X86_TUNE_MOVX: Enable to zero extend integer registers to avoid\n      partial dependencies.  */\n-  m_ATHLON_K8_AMDFAM10 | m_PPRO | m_PENT4 | m_NOCONA\n+  m_AMD_MULTIPLE | m_PPRO | m_PENT4 | m_NOCONA\n   | m_CORE2 | m_GENERIC | m_GEODE /* m_386 | m_K6 */,\n \n   /* X86_TUNE_PARTIAL_REG_STALL: We probably ought to watch for partial\n@@ -1265,7 +1265,7 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n   m_386 | m_486 | m_K6_GEODE,\n \n   /* X86_TUNE_USE_SIMODE_FIOP */\n-  ~(m_PPRO | m_ATHLON_K8_AMDFAM10 | m_PENT | m_CORE2 | m_GENERIC),\n+  ~(m_PPRO | m_AMD_MULTIPLE | m_PENT | m_CORE2 | m_GENERIC),\n \n   /* X86_TUNE_USE_MOV0 */\n   m_K6,\n@@ -1286,7 +1286,7 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n   ~(m_PENT | m_PPRO),\n \n   /* X86_TUNE_PROMOTE_QIMODE */\n-  m_K6_GEODE | m_PENT | m_386 | m_486 | m_ATHLON_K8_AMDFAM10 | m_CORE2\n+  m_K6_GEODE | m_PENT | m_386 | m_486 | m_AMD_MULTIPLE | m_CORE2\n   | m_GENERIC /* | m_PENT4 ? */,\n \n   /* X86_TUNE_FAST_PREFIX */\n@@ -1311,26 +1311,26 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n   m_PPRO,\n \n   /* X86_TUNE_ADD_ESP_4: Enable if add/sub is preferred over 1/2 push/pop.  */\n-  m_ATHLON_K8_AMDFAM10 | m_K6_GEODE | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_K6_GEODE | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_ADD_ESP_8 */\n-  m_ATHLON_K8_AMDFAM10 | m_PPRO | m_K6_GEODE | m_386\n+  m_AMD_MULTIPLE | m_PPRO | m_K6_GEODE | m_386\n   | m_486 | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_SUB_ESP_4 */\n-  m_ATHLON_K8_AMDFAM10 | m_PPRO | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_PPRO | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_SUB_ESP_8 */\n-  m_ATHLON_K8_AMDFAM10 | m_PPRO | m_386 | m_486\n+  m_AMD_MULTIPLE | m_PPRO | m_386 | m_486\n   | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_INTEGER_DFMODE_MOVES: Enable if integer moves are preferred\n      for DFmode copies */\n-  ~(m_ATHLON_K8_AMDFAM10 | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2\n+  ~(m_AMD_MULTIPLE | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2\n     | m_GENERIC | m_GEODE),\n \n   /* X86_TUNE_PARTIAL_REG_DEPENDENCY */\n-  m_ATHLON_K8_AMDFAM10 | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_SSE_PARTIAL_REG_DEPENDENCY: In the Generic model we have a\n      conflict here in between PPro/Pentium4 based chips that thread 128bit\n@@ -1353,13 +1353,13 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n   m_ATHLON_K8,\n \n   /* X86_TUNE_SSE_TYPELESS_STORES */\n-  m_ATHLON_K8_AMDFAM10,\n+  m_AMD_MULTIPLE,\n \n   /* X86_TUNE_SSE_LOAD0_BY_PXOR */\n   m_PPRO | m_PENT4 | m_NOCONA,\n \n   /* X86_TUNE_MEMORY_MISMATCH_STALL */\n-  m_ATHLON_K8_AMDFAM10 | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_PROLOGUE_USING_MOVE */\n   m_ATHLON_K8 | m_PPRO | m_CORE2 | m_GENERIC,\n@@ -1371,29 +1371,29 @@ unsigned int ix86_tune_features[X86_TUNE_LAST] = {\n   ~m_486,\n \n   /* X86_TUNE_USE_FFREEP */\n-  m_ATHLON_K8_AMDFAM10,\n+  m_AMD_MULTIPLE,\n \n   /* X86_TUNE_INTER_UNIT_MOVES */\n-  ~(m_ATHLON_K8_AMDFAM10 | m_GENERIC),\n+  ~(m_AMD_MULTIPLE | m_GENERIC),\n \n   /* X86_TUNE_INTER_UNIT_CONVERSIONS */\n   ~(m_AMDFAM10),\n \n   /* X86_TUNE_FOUR_JUMP_LIMIT: Some CPU cores are not able to predict more\n      than 4 branch instructions in the 16 byte window.  */\n-  m_PPRO | m_ATHLON_K8_AMDFAM10 | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n+  m_PPRO | m_AMD_MULTIPLE | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_SCHEDULE */\n-  m_PPRO | m_ATHLON_K8_AMDFAM10 | m_K6_GEODE | m_PENT | m_CORE2 | m_GENERIC,\n+  m_PPRO | m_AMD_MULTIPLE | m_K6_GEODE | m_PENT | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_USE_BT */\n-  m_ATHLON_K8_AMDFAM10,\n+  m_AMD_MULTIPLE,\n \n   /* X86_TUNE_USE_INCDEC */\n   ~(m_PENT4 | m_NOCONA | m_GENERIC),\n \n   /* X86_TUNE_PAD_RETURNS */\n-  m_ATHLON_K8_AMDFAM10 | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_CORE2 | m_GENERIC,\n \n   /* X86_TUNE_EXT_80387_CONSTANTS */\n   m_K6_GEODE | m_ATHLON_K8 | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2 | m_GENERIC,\n@@ -1453,10 +1453,10 @@ unsigned int ix86_arch_features[X86_ARCH_LAST] = {\n };\n \n static const unsigned int x86_accumulate_outgoing_args\n-  = m_ATHLON_K8_AMDFAM10 | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2 | m_GENERIC;\n+  = m_AMD_MULTIPLE | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2 | m_GENERIC;\n \n static const unsigned int x86_arch_always_fancy_math_387\n-  = m_PENT | m_PPRO | m_ATHLON_K8_AMDFAM10 | m_PENT4\n+  = m_PENT | m_PPRO | m_AMD_MULTIPLE | m_PENT4\n     | m_NOCONA | m_CORE2 | m_GENERIC;\n \n static enum stringop_alg stringop_alg = no_stringop;\n@@ -1794,6 +1794,9 @@ static int ix86_isa_flags_explicit;\n \n #define OPTION_MASK_ISA_SSE4A_UNSET OPTION_MASK_ISA_SSE4\n \n+#define OPTION_MASK_ISA_SSE5_UNSET \\\n+  (OPTION_MASK_ISA_3DNOW | OPTION_MASK_ISA_3DNOW_UNSET)\n+\n /* Vectorization library interface and handlers.  */\n tree (*ix86_veclib_handler)(enum built_in_function, tree, tree) = NULL;\n static tree ix86_veclibabi_acml (enum built_in_function, tree, tree);\n@@ -1899,6 +1902,15 @@ ix86_handle_option (size_t code, const char *arg ATTRIBUTE_UNUSED, int value)\n \t}\n       return true;\n \n+    case OPT_msse5:\n+      ix86_isa_flags_explicit |= OPTION_MASK_ISA_SSE5;\n+      if (!value)\n+\t{\n+\t  ix86_isa_flags &= ~OPTION_MASK_ISA_SSE5_UNSET;\n+\t  ix86_isa_flags_explicit |= OPTION_MASK_ISA_SSE5_UNSET;\n+\t}\n+      return true;\n+\n     default:\n       return true;\n     }\n@@ -1969,7 +1981,8 @@ override_options (void)\n       PTA_SSE4A = 1 << 12,\n       PTA_NO_SAHF = 1 << 13,\n       PTA_SSE4_1 = 1 << 14,\n-      PTA_SSE4_2 = 1 << 15\n+      PTA_SSE4_2 = 1 << 15,\n+      PTA_SSE5 = 1 << 16\n     };\n \n   static struct pta\n@@ -2262,6 +2275,9 @@ override_options (void)\n \tif (processor_alias_table[i].flags & PTA_SSE4A\n \t    && !(ix86_isa_flags_explicit & OPTION_MASK_ISA_SSE4A))\n \t  ix86_isa_flags |= OPTION_MASK_ISA_SSE4A;\n+\tif (processor_alias_table[i].flags & PTA_SSE5\n+\t    && !(ix86_isa_flags_explicit & OPTION_MASK_ISA_SSE5))\n+\t  ix86_isa_flags |= OPTION_MASK_ISA_SSE5;\n \n \tif (processor_alias_table[i].flags & PTA_ABM)\n \t  x86_abm = true;\n@@ -2489,6 +2505,10 @@ override_options (void)\n   if (!TARGET_80387)\n     target_flags |= MASK_NO_FANCY_MATH_387;\n \n+  /* Turn on SSE4A bultins for -msse5.  */\n+  if (TARGET_SSE5)\n+    ix86_isa_flags |= OPTION_MASK_ISA_SSE4A;\n+\n   /* Turn on SSE4.1 builtins for -msse4.2.  */\n   if (TARGET_SSE4_2)\n     ix86_isa_flags |= OPTION_MASK_ISA_SSE4_1;\n@@ -3252,22 +3272,6 @@ ix86_eax_live_at_start_p (void)\n   return REGNO_REG_SET_P (df_get_live_out (ENTRY_BLOCK_PTR), 0);\n }\n \n-/* Return true if TYPE has a variable argument list.  */\n-\n-static bool\n-type_has_variadic_args_p (tree type)\n-{\n-  tree n, t = TYPE_ARG_TYPES (type);\n-\n-  if (t == NULL)\n-    return false;\n-\n-  while ((n = TREE_CHAIN (t)) != NULL)\n-    t = n;\n-\n-  return TREE_VALUE (t) != void_type_node;\n-}\n-\n /* Value is the number of bytes of arguments automatically\n    popped when returning from a subroutine call.\n    FUNDECL is the declaration node of the function (as a tree),\n@@ -3305,7 +3309,7 @@ ix86_return_pops_args (tree fundecl, tree funtype, int size)\n           || lookup_attribute (\"fastcall\", TYPE_ATTRIBUTES (funtype)))\n \trtd = 1;\n \n-      if (rtd && ! type_has_variadic_args_p (funtype))\n+      if (rtd && ! stdarg_p (funtype))\n \treturn size;\n     }\n \n@@ -3405,8 +3409,7 @@ init_cumulative_args (CUMULATIVE_ARGS *cum,  /* Argument info to initialize */\n   cum->warn_sse = true;\n   cum->warn_mmx = true;\n   cum->maybe_vaarg = (fntype\n-\t\t      ? (!TYPE_ARG_TYPES (fntype)\n-\t\t\t || type_has_variadic_args_p (fntype))\n+\t\t      ? (!prototype_p (fntype) || stdarg_p (fntype))\n \t\t      : !libname);\n \n   if (!TARGET_64BIT)\n@@ -4984,7 +4987,6 @@ ix86_setup_incoming_varargs (CUMULATIVE_ARGS *cum, enum machine_mode mode,\n {\n   CUMULATIVE_ARGS next_cum;\n   tree fntype;\n-  int stdarg_p;\n \n   /* This argument doesn't appear to be used anymore.  Which is good,\n      because the old code here didn't suppress rtl generation.  */\n@@ -4994,14 +4996,11 @@ ix86_setup_incoming_varargs (CUMULATIVE_ARGS *cum, enum machine_mode mode,\n     return;\n \n   fntype = TREE_TYPE (current_function_decl);\n-  stdarg_p = (TYPE_ARG_TYPES (fntype) != 0\n-\t      && (TREE_VALUE (tree_last (TYPE_ARG_TYPES (fntype)))\n-\t\t  != void_type_node));\n \n   /* For varargs, we do not want to skip the dummy va_dcl argument.\n      For stdargs, we do want to skip the last named argument.  */\n   next_cum = *cum;\n-  if (stdarg_p)\n+  if (stdarg_p (fntype))\n     function_arg_advance (&next_cum, mode, type, 1);\n \n   if (TARGET_64BIT_MS_ABI)\n@@ -8678,6 +8677,7 @@ get_some_local_dynamic_name (void)\n    X -- don't print any sort of PIC '@' suffix for a symbol.\n    & -- print some in-use local-dynamic symbol name.\n    H -- print a memory address offset by 8; used for sse high-parts\n+   Y -- print condition for SSE5 com* instruction.\n    + -- print a branch hint as 'cs' or 'ds' prefix\n    ; -- print a semicolon (after prefixes due to bug in older gas).\n  */\n@@ -8962,6 +8962,60 @@ print_operand (FILE *file, rtx x, int code)\n \t    return;\n \t  }\n \n+\tcase 'Y':\n+\t  switch (GET_CODE (x))\n+\t    {\n+\t    case NE:\n+\t      fputs (\"neq\", file);\n+\t      break;\n+\t    case EQ:\n+\t      fputs (\"eq\", file);\n+\t      break;\n+\t    case GE:\n+\t    case GEU:\n+\t      fputs (INTEGRAL_MODE_P (GET_MODE (x)) ? \"ge\" : \"unlt\", file);\n+\t      break;\n+\t    case GT:\n+\t    case GTU:\n+\t      fputs (INTEGRAL_MODE_P (GET_MODE (x)) ? \"gt\" : \"unle\", file);\n+\t      break;\n+\t    case LE:\n+\t    case LEU:\n+\t      fputs (\"le\", file);\n+\t      break;\n+\t    case LT:\n+\t    case LTU:\n+\t      fputs (\"lt\", file);\n+\t      break;\n+\t    case UNORDERED:\n+\t      fputs (\"unord\", file);\n+\t      break;\n+\t    case ORDERED:\n+\t      fputs (\"ord\", file);\n+\t      break;\n+\t    case UNEQ:\n+\t      fputs (\"ueq\", file);\n+\t      break;\n+\t    case UNGE:\n+\t      fputs (\"nlt\", file);\n+\t      break;\n+\t    case UNGT:\n+\t      fputs (\"nle\", file);\n+\t      break;\n+\t    case UNLE:\n+\t      fputs (\"ule\", file);\n+\t      break;\n+\t    case UNLT:\n+\t      fputs (\"ult\", file);\n+\t      break;\n+\t    case LTGT:\n+\t      fputs (\"une\", file);\n+\t      break;\n+\t    default:\n+\t      gcc_unreachable ();\n+\t    }\n+\t  return;\n+\n \tcase ';':\n #if TARGET_MACHO\n \t  fputs (\" ; \", file);\n@@ -13000,7 +13054,15 @@ ix86_expand_sse_movcc (rtx dest, rtx cmp, rtx op_true, rtx op_false)\n   enum machine_mode mode = GET_MODE (dest);\n   rtx t2, t3, x;\n \n-  if (op_false == CONST0_RTX (mode))\n+  if (TARGET_SSE5)\n+    {\n+      rtx pcmov = gen_rtx_SET (mode, dest,\n+\t\t\t       gen_rtx_IF_THEN_ELSE (mode, cmp,\n+\t\t\t\t\t\t     op_true,\n+\t\t\t\t\t\t     op_false));\n+      emit_insn (pcmov);\n+    }\n+  else if (op_false == CONST0_RTX (mode))\n     {\n       op_true = force_reg (mode, op_true);\n       x = gen_rtx_AND (mode, cmp, op_true);\n@@ -13372,6 +13434,202 @@ ix86_expand_sse4_unpack (rtx operands[2], bool unsigned_p, bool high_p)\n   emit_insn (unpack (dest, src));\n }\n \n+/* This function performs the same task as ix86_expand_sse_unpack,\n+   but with amdfam15 instructions.  */\n+\n+#define PPERM_SRC\t0x00\t\t/* copy source */\n+#define PPERM_INVERT\t0x20\t\t/* invert source */\n+#define PPERM_REVERSE\t0x40\t\t/* bit reverse source */\n+#define PPERM_REV_INV\t0x60\t\t/* bit reverse & invert src */\n+#define PPERM_ZERO\t0x80\t\t/* all 0's */\n+#define PPERM_ONES\t0xa0\t\t/* all 1's */\n+#define PPERM_SIGN\t0xc0\t\t/* propigate sign bit */\n+#define PPERM_INV_SIGN\t0xe0\t\t/* invert & propigate sign */\n+\n+#define PPERM_SRC1\t0x00\t\t/* use first source byte */\n+#define PPERM_SRC2\t0x10\t\t/* use second source byte */\n+\n+void\n+ix86_expand_sse5_unpack (rtx operands[2], bool unsigned_p, bool high_p)\n+{\n+  enum machine_mode imode = GET_MODE (operands[1]);\n+  int pperm_bytes[16];\n+  int i;\n+  int h = (high_p) ? 8 : 0;\n+  int h2;\n+  int sign_extend;\n+  rtvec v = rtvec_alloc (16);\n+  rtvec vs;\n+  rtx x, p;\n+  rtx op0 = operands[0], op1 = operands[1];\n+\n+  switch (imode)\n+    {\n+    case V16QImode:\n+      vs = rtvec_alloc (8);\n+      h2 = (high_p) ? 8 : 0;\n+      for (i = 0; i < 8; i++)\n+\t{\n+\t  pperm_bytes[2*i+0] = PPERM_SRC | PPERM_SRC2 | i | h;\n+\t  pperm_bytes[2*i+1] = ((unsigned_p)\n+\t\t\t\t? PPERM_ZERO\n+\t\t\t\t: PPERM_SIGN | PPERM_SRC2 | i | h);\n+\t}\n+\n+      for (i = 0; i < 16; i++)\n+\tRTVEC_ELT (v, i) = GEN_INT (pperm_bytes[i]);\n+\n+      for (i = 0; i < 8; i++)\n+\tRTVEC_ELT (vs, i) = GEN_INT (i + h2);\n+\n+      p = gen_rtx_PARALLEL (VOIDmode, vs);\n+      x = force_reg (V16QImode, gen_rtx_CONST_VECTOR (V16QImode, v));\n+      if (unsigned_p)\n+\temit_insn (gen_sse5_pperm_zero_v16qi_v8hi (op0, op1, p, x));\n+      else\n+\temit_insn (gen_sse5_pperm_sign_v16qi_v8hi (op0, op1, p, x));\n+      break;\n+\n+    case V8HImode:\n+      vs = rtvec_alloc (4);\n+      h2 = (high_p) ? 4 : 0;\n+      for (i = 0; i < 4; i++)\n+\t{\n+\t  sign_extend = ((unsigned_p)\n+\t\t\t ? PPERM_ZERO\n+\t\t\t : PPERM_SIGN | PPERM_SRC2 | ((2*i) + 1 + h));\n+\t  pperm_bytes[4*i+0] = PPERM_SRC | PPERM_SRC2 | ((2*i) + 0 + h);\n+\t  pperm_bytes[4*i+1] = PPERM_SRC | PPERM_SRC2 | ((2*i) + 1 + h);\n+\t  pperm_bytes[4*i+2] = sign_extend;\n+\t  pperm_bytes[4*i+3] = sign_extend;\n+\t}\n+\n+      for (i = 0; i < 16; i++)\n+\tRTVEC_ELT (v, i) = GEN_INT (pperm_bytes[i]);\n+\n+      for (i = 0; i < 4; i++)\n+\tRTVEC_ELT (vs, i) = GEN_INT (i + h2);\n+\n+      p = gen_rtx_PARALLEL (VOIDmode, vs);\n+      x = force_reg (V16QImode, gen_rtx_CONST_VECTOR (V16QImode, v));\n+      if (unsigned_p)\n+\temit_insn (gen_sse5_pperm_zero_v8hi_v4si (op0, op1, p, x));\n+      else\n+\temit_insn (gen_sse5_pperm_sign_v8hi_v4si (op0, op1, p, x));\n+      break;\n+\n+    case V4SImode:\n+      vs = rtvec_alloc (2);\n+      h2 = (high_p) ? 2 : 0;\n+      for (i = 0; i < 2; i++)\n+\t{\n+\t  sign_extend = ((unsigned_p)\n+\t\t\t ? PPERM_ZERO\n+\t\t\t : PPERM_SIGN | PPERM_SRC2 | ((4*i) + 3 + h));\n+\t  pperm_bytes[8*i+0] = PPERM_SRC | PPERM_SRC2 | ((4*i) + 0 + h);\n+\t  pperm_bytes[8*i+1] = PPERM_SRC | PPERM_SRC2 | ((4*i) + 1 + h);\n+\t  pperm_bytes[8*i+2] = PPERM_SRC | PPERM_SRC2 | ((4*i) + 2 + h);\n+\t  pperm_bytes[8*i+3] = PPERM_SRC | PPERM_SRC2 | ((4*i) + 3 + h);\n+\t  pperm_bytes[8*i+4] = sign_extend;\n+\t  pperm_bytes[8*i+5] = sign_extend;\n+\t  pperm_bytes[8*i+6] = sign_extend;\n+\t  pperm_bytes[8*i+7] = sign_extend;\n+\t}\n+\n+      for (i = 0; i < 16; i++)\n+\tRTVEC_ELT (v, i) = GEN_INT (pperm_bytes[i]);\n+\n+      for (i = 0; i < 4; i++)\n+\tRTVEC_ELT (vs, i) = GEN_INT (i + h2);\n+\n+      p = gen_rtx_PARALLEL (VOIDmode, vs);\n+      x = force_reg (V16QImode, gen_rtx_CONST_VECTOR (V16QImode, v));\n+      if (unsigned_p)\n+\temit_insn (gen_sse5_pperm_zero_v8hi_v4si (op0, op1, p, x));\n+      else\n+\temit_insn (gen_sse5_pperm_sign_v8hi_v4si (op0, op1, p, x));\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  return;\n+}\n+\n+/* Pack the high bits from OPERANDS[1] and low bits from OPERANDS[2] into the\n+   next narrower integer vector type */\n+void\n+ix86_expand_sse5_pack (rtx operands[3])\n+{\n+  enum machine_mode imode = GET_MODE (operands[0]);\n+  int pperm_bytes[16];\n+  int i;\n+  rtvec v = rtvec_alloc (16);\n+  rtx x;\n+  rtx op0 = operands[0];\n+  rtx op1 = operands[1];\n+  rtx op2 = operands[2];\n+\n+  switch (imode)\n+    {\n+    case V16QImode:\n+      for (i = 0; i < 8; i++)\n+\t{\n+\t  pperm_bytes[i+0] = PPERM_SRC | PPERM_SRC1 | (i*2);\n+\t  pperm_bytes[i+8] = PPERM_SRC | PPERM_SRC2 | (i*2);\n+\t}\n+\n+      for (i = 0; i < 16; i++)\n+\tRTVEC_ELT (v, i) = GEN_INT (pperm_bytes[i]);\n+\n+      x = force_reg (V16QImode, gen_rtx_CONST_VECTOR (V16QImode, v));\n+      emit_insn (gen_sse5_pperm_pack_v8hi_v16qi (op0, op1, op2, x));\n+      break;\n+\n+    case V8HImode:\n+      for (i = 0; i < 4; i++)\n+\t{\n+\t  pperm_bytes[(2*i)+0] = PPERM_SRC | PPERM_SRC1 | ((i*4) + 0);\n+\t  pperm_bytes[(2*i)+1] = PPERM_SRC | PPERM_SRC1 | ((i*4) + 1);\n+\t  pperm_bytes[(2*i)+8] = PPERM_SRC | PPERM_SRC2 | ((i*4) + 0);\n+\t  pperm_bytes[(2*i)+9] = PPERM_SRC | PPERM_SRC2 | ((i*4) + 1);\n+\t}\n+\n+      for (i = 0; i < 16; i++)\n+\tRTVEC_ELT (v, i) = GEN_INT (pperm_bytes[i]);\n+\n+      x = force_reg (V16QImode, gen_rtx_CONST_VECTOR (V16QImode, v));\n+      emit_insn (gen_sse5_pperm_pack_v4si_v8hi (op0, op1, op2, x));\n+      break;\n+\n+    case V4SImode:\n+      for (i = 0; i < 2; i++)\n+\t{\n+\t  pperm_bytes[(4*i)+0]  = PPERM_SRC | PPERM_SRC1 | ((i*8) + 0);\n+\t  pperm_bytes[(4*i)+1]  = PPERM_SRC | PPERM_SRC1 | ((i*8) + 1);\n+\t  pperm_bytes[(4*i)+2]  = PPERM_SRC | PPERM_SRC1 | ((i*8) + 2);\n+\t  pperm_bytes[(4*i)+3]  = PPERM_SRC | PPERM_SRC1 | ((i*8) + 3);\n+\t  pperm_bytes[(4*i)+8]  = PPERM_SRC | PPERM_SRC2 | ((i*8) + 0);\n+\t  pperm_bytes[(4*i)+9]  = PPERM_SRC | PPERM_SRC2 | ((i*8) + 1);\n+\t  pperm_bytes[(4*i)+10] = PPERM_SRC | PPERM_SRC2 | ((i*8) + 2);\n+\t  pperm_bytes[(4*i)+11] = PPERM_SRC | PPERM_SRC2 | ((i*8) + 3);\n+\t}\n+\n+      for (i = 0; i < 16; i++)\n+\tRTVEC_ELT (v, i) = GEN_INT (pperm_bytes[i]);\n+\n+      x = force_reg (V16QImode, gen_rtx_CONST_VECTOR (V16QImode, v));\n+      emit_insn (gen_sse5_pperm_pack_v2di_v4si (op0, op1, op2, x));\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  return;\n+}\n+\n /* Expand conditional increment or decrement using adb/sbb instructions.\n    The default case using setcc followed by the conditional move can be\n    done by generic code.  */\n@@ -17105,6 +17363,216 @@ enum ix86_builtins\n   IX86_BUILTIN_FABSQ,\n   IX86_BUILTIN_COPYSIGNQ,\n \n+  /* SSE5 instructions */\n+  IX86_BUILTIN_FMADDSS,\n+  IX86_BUILTIN_FMADDSD,\n+  IX86_BUILTIN_FMADDPS,\n+  IX86_BUILTIN_FMADDPD,\n+  IX86_BUILTIN_FMSUBSS,\n+  IX86_BUILTIN_FMSUBSD,\n+  IX86_BUILTIN_FMSUBPS,\n+  IX86_BUILTIN_FMSUBPD,\n+  IX86_BUILTIN_FNMADDSS,\n+  IX86_BUILTIN_FNMADDSD,\n+  IX86_BUILTIN_FNMADDPS,\n+  IX86_BUILTIN_FNMADDPD,\n+  IX86_BUILTIN_FNMSUBSS,\n+  IX86_BUILTIN_FNMSUBSD,\n+  IX86_BUILTIN_FNMSUBPS,\n+  IX86_BUILTIN_FNMSUBPD,\n+  IX86_BUILTIN_PCMOV_V2DI,\n+  IX86_BUILTIN_PCMOV_V4SI,\n+  IX86_BUILTIN_PCMOV_V8HI,\n+  IX86_BUILTIN_PCMOV_V16QI,\n+  IX86_BUILTIN_PCMOV_V4SF,\n+  IX86_BUILTIN_PCMOV_V2DF,\n+  IX86_BUILTIN_PPERM,\n+  IX86_BUILTIN_PERMPS,\n+  IX86_BUILTIN_PERMPD,\n+  IX86_BUILTIN_PMACSSWW,\n+  IX86_BUILTIN_PMACSWW,\n+  IX86_BUILTIN_PMACSSWD,\n+  IX86_BUILTIN_PMACSWD,\n+  IX86_BUILTIN_PMACSSDD,\n+  IX86_BUILTIN_PMACSDD,\n+  IX86_BUILTIN_PMACSSDQL,\n+  IX86_BUILTIN_PMACSSDQH,\n+  IX86_BUILTIN_PMACSDQL,\n+  IX86_BUILTIN_PMACSDQH,\n+  IX86_BUILTIN_PMADCSSWD,\n+  IX86_BUILTIN_PMADCSWD,\n+  IX86_BUILTIN_PHADDBW,\n+  IX86_BUILTIN_PHADDBD,\n+  IX86_BUILTIN_PHADDBQ,\n+  IX86_BUILTIN_PHADDWD,\n+  IX86_BUILTIN_PHADDWQ,\n+  IX86_BUILTIN_PHADDDQ,\n+  IX86_BUILTIN_PHADDUBW,\n+  IX86_BUILTIN_PHADDUBD,\n+  IX86_BUILTIN_PHADDUBQ,\n+  IX86_BUILTIN_PHADDUWD,\n+  IX86_BUILTIN_PHADDUWQ,\n+  IX86_BUILTIN_PHADDUDQ,\n+  IX86_BUILTIN_PHSUBBW,\n+  IX86_BUILTIN_PHSUBWD,\n+  IX86_BUILTIN_PHSUBDQ,\n+  IX86_BUILTIN_PROTB,\n+  IX86_BUILTIN_PROTW,\n+  IX86_BUILTIN_PROTD,\n+  IX86_BUILTIN_PROTQ,\n+  IX86_BUILTIN_PROTB_IMM,\n+  IX86_BUILTIN_PROTW_IMM,\n+  IX86_BUILTIN_PROTD_IMM,\n+  IX86_BUILTIN_PROTQ_IMM,\n+  IX86_BUILTIN_PSHLB,\n+  IX86_BUILTIN_PSHLW,\n+  IX86_BUILTIN_PSHLD,\n+  IX86_BUILTIN_PSHLQ,\n+  IX86_BUILTIN_PSHAB,\n+  IX86_BUILTIN_PSHAW,\n+  IX86_BUILTIN_PSHAD,\n+  IX86_BUILTIN_PSHAQ,\n+  IX86_BUILTIN_FRCZSS,\n+  IX86_BUILTIN_FRCZSD,\n+  IX86_BUILTIN_FRCZPS,\n+  IX86_BUILTIN_FRCZPD,\n+  IX86_BUILTIN_CVTPH2PS,\n+  IX86_BUILTIN_CVTPS2PH,\n+\n+  IX86_BUILTIN_COMEQSS,\n+  IX86_BUILTIN_COMNESS,\n+  IX86_BUILTIN_COMLTSS,\n+  IX86_BUILTIN_COMLESS,\n+  IX86_BUILTIN_COMGTSS,\n+  IX86_BUILTIN_COMGESS,\n+  IX86_BUILTIN_COMUEQSS,\n+  IX86_BUILTIN_COMUNESS,\n+  IX86_BUILTIN_COMULTSS,\n+  IX86_BUILTIN_COMULESS,\n+  IX86_BUILTIN_COMUGTSS,\n+  IX86_BUILTIN_COMUGESS,\n+  IX86_BUILTIN_COMORDSS,\n+  IX86_BUILTIN_COMUNORDSS,\n+  IX86_BUILTIN_COMFALSESS,\n+  IX86_BUILTIN_COMTRUESS,\n+\n+  IX86_BUILTIN_COMEQSD,\n+  IX86_BUILTIN_COMNESD,\n+  IX86_BUILTIN_COMLTSD,\n+  IX86_BUILTIN_COMLESD,\n+  IX86_BUILTIN_COMGTSD,\n+  IX86_BUILTIN_COMGESD,\n+  IX86_BUILTIN_COMUEQSD,\n+  IX86_BUILTIN_COMUNESD,\n+  IX86_BUILTIN_COMULTSD,\n+  IX86_BUILTIN_COMULESD,\n+  IX86_BUILTIN_COMUGTSD,\n+  IX86_BUILTIN_COMUGESD,\n+  IX86_BUILTIN_COMORDSD,\n+  IX86_BUILTIN_COMUNORDSD,\n+  IX86_BUILTIN_COMFALSESD,\n+  IX86_BUILTIN_COMTRUESD,\n+\n+  IX86_BUILTIN_COMEQPS,\n+  IX86_BUILTIN_COMNEPS,\n+  IX86_BUILTIN_COMLTPS,\n+  IX86_BUILTIN_COMLEPS,\n+  IX86_BUILTIN_COMGTPS,\n+  IX86_BUILTIN_COMGEPS,\n+  IX86_BUILTIN_COMUEQPS,\n+  IX86_BUILTIN_COMUNEPS,\n+  IX86_BUILTIN_COMULTPS,\n+  IX86_BUILTIN_COMULEPS,\n+  IX86_BUILTIN_COMUGTPS,\n+  IX86_BUILTIN_COMUGEPS,\n+  IX86_BUILTIN_COMORDPS,\n+  IX86_BUILTIN_COMUNORDPS,\n+  IX86_BUILTIN_COMFALSEPS,\n+  IX86_BUILTIN_COMTRUEPS,\n+\n+  IX86_BUILTIN_COMEQPD,\n+  IX86_BUILTIN_COMNEPD,\n+  IX86_BUILTIN_COMLTPD,\n+  IX86_BUILTIN_COMLEPD,\n+  IX86_BUILTIN_COMGTPD,\n+  IX86_BUILTIN_COMGEPD,\n+  IX86_BUILTIN_COMUEQPD,\n+  IX86_BUILTIN_COMUNEPD,\n+  IX86_BUILTIN_COMULTPD,\n+  IX86_BUILTIN_COMULEPD,\n+  IX86_BUILTIN_COMUGTPD,\n+  IX86_BUILTIN_COMUGEPD,\n+  IX86_BUILTIN_COMORDPD,\n+  IX86_BUILTIN_COMUNORDPD,\n+  IX86_BUILTIN_COMFALSEPD,\n+  IX86_BUILTIN_COMTRUEPD,\n+\n+  IX86_BUILTIN_PCOMEQUB,\n+  IX86_BUILTIN_PCOMNEUB,\n+  IX86_BUILTIN_PCOMLTUB,\n+  IX86_BUILTIN_PCOMLEUB,\n+  IX86_BUILTIN_PCOMGTUB,\n+  IX86_BUILTIN_PCOMGEUB,\n+  IX86_BUILTIN_PCOMFALSEUB,\n+  IX86_BUILTIN_PCOMTRUEUB,\n+  IX86_BUILTIN_PCOMEQUW,\n+  IX86_BUILTIN_PCOMNEUW,\n+  IX86_BUILTIN_PCOMLTUW,\n+  IX86_BUILTIN_PCOMLEUW,\n+  IX86_BUILTIN_PCOMGTUW,\n+  IX86_BUILTIN_PCOMGEUW,\n+  IX86_BUILTIN_PCOMFALSEUW,\n+  IX86_BUILTIN_PCOMTRUEUW,\n+  IX86_BUILTIN_PCOMEQUD,\n+  IX86_BUILTIN_PCOMNEUD,\n+  IX86_BUILTIN_PCOMLTUD,\n+  IX86_BUILTIN_PCOMLEUD,\n+  IX86_BUILTIN_PCOMGTUD,\n+  IX86_BUILTIN_PCOMGEUD,\n+  IX86_BUILTIN_PCOMFALSEUD,\n+  IX86_BUILTIN_PCOMTRUEUD,\n+  IX86_BUILTIN_PCOMEQUQ,\n+  IX86_BUILTIN_PCOMNEUQ,\n+  IX86_BUILTIN_PCOMLTUQ,\n+  IX86_BUILTIN_PCOMLEUQ,\n+  IX86_BUILTIN_PCOMGTUQ,\n+  IX86_BUILTIN_PCOMGEUQ,\n+  IX86_BUILTIN_PCOMFALSEUQ,\n+  IX86_BUILTIN_PCOMTRUEUQ,\n+\n+  IX86_BUILTIN_PCOMEQB,\n+  IX86_BUILTIN_PCOMNEB,\n+  IX86_BUILTIN_PCOMLTB,\n+  IX86_BUILTIN_PCOMLEB,\n+  IX86_BUILTIN_PCOMGTB,\n+  IX86_BUILTIN_PCOMGEB,\n+  IX86_BUILTIN_PCOMFALSEB,\n+  IX86_BUILTIN_PCOMTRUEB,\n+  IX86_BUILTIN_PCOMEQW,\n+  IX86_BUILTIN_PCOMNEW,\n+  IX86_BUILTIN_PCOMLTW,\n+  IX86_BUILTIN_PCOMLEW,\n+  IX86_BUILTIN_PCOMGTW,\n+  IX86_BUILTIN_PCOMGEW,\n+  IX86_BUILTIN_PCOMFALSEW,\n+  IX86_BUILTIN_PCOMTRUEW,\n+  IX86_BUILTIN_PCOMEQD,\n+  IX86_BUILTIN_PCOMNED,\n+  IX86_BUILTIN_PCOMLTD,\n+  IX86_BUILTIN_PCOMLED,\n+  IX86_BUILTIN_PCOMGTD,\n+  IX86_BUILTIN_PCOMGED,\n+  IX86_BUILTIN_PCOMFALSED,\n+  IX86_BUILTIN_PCOMTRUED,\n+  IX86_BUILTIN_PCOMEQQ,\n+  IX86_BUILTIN_PCOMNEQ,\n+  IX86_BUILTIN_PCOMLTQ,\n+  IX86_BUILTIN_PCOMLEQ,\n+  IX86_BUILTIN_PCOMGTQ,\n+  IX86_BUILTIN_PCOMGEQ,\n+  IX86_BUILTIN_PCOMFALSEQ,\n+  IX86_BUILTIN_PCOMTRUEQ,\n+\n   IX86_BUILTIN_MAX\n };\n \n@@ -17191,9 +17659,9 @@ static const struct builtin_description bdesc_comi[] =\n static const struct builtin_description bdesc_ptest[] =\n {\n   /* SSE4.1 */\n-  { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestz128\", IX86_BUILTIN_PTESTZ, EQ, 0 },\n-  { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestc128\", IX86_BUILTIN_PTESTC, LTU, 0 },\n-  { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestnzc128\", IX86_BUILTIN_PTESTNZC, GTU, 0 },\n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestz128\", IX86_BUILTIN_PTESTZ, EQ, 0 },\n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestc128\", IX86_BUILTIN_PTESTC, LTU, 0 },\n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestnzc128\", IX86_BUILTIN_PTESTNZC, GTU, 0 },\n };\n \n static const struct builtin_description bdesc_pcmpestr[] =\n@@ -17243,8 +17711,8 @@ static const struct builtin_description bdesc_sse_3arg[] =\n   { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_mpsadbw, \"__builtin_ia32_mpsadbw128\", IX86_BUILTIN_MPSADBW128, UNKNOWN, 0 },\n   { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_pblendvb, \"__builtin_ia32_pblendvb128\", IX86_BUILTIN_PBLENDVB128, UNKNOWN, 0 },\n   { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_pblendw, \"__builtin_ia32_pblendw128\", IX86_BUILTIN_PBLENDW128, UNKNOWN, 0 },\n-  { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_roundsd, 0, IX86_BUILTIN_ROUNDSD, UNKNOWN, 0 },\n-  { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_roundss, 0, IX86_BUILTIN_ROUNDSS, UNKNOWN, 0 },\n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_roundsd, 0, IX86_BUILTIN_ROUNDSD, UNKNOWN, 0 },\n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_roundss, 0, IX86_BUILTIN_ROUNDSS, UNKNOWN, 0 },\n };\n \n static const struct builtin_description bdesc_2arg[] =\n@@ -17630,6 +18098,295 @@ static const struct builtin_description bdesc_1arg[] =\n   { OPTION_MASK_ISA_SSE4_1, CODE_FOR_sse4_1_roundps, 0, IX86_BUILTIN_ROUNDPS, UNKNOWN, 0 },\n };\n \n+/* SSE5 */\n+enum multi_arg_type {\n+  MULTI_ARG_UNKNOWN,\n+  MULTI_ARG_3_SF,\n+  MULTI_ARG_3_DF,\n+  MULTI_ARG_3_DI,\n+  MULTI_ARG_3_SI,\n+  MULTI_ARG_3_SI_DI,\n+  MULTI_ARG_3_HI,\n+  MULTI_ARG_3_HI_SI,\n+  MULTI_ARG_3_QI,\n+  MULTI_ARG_3_PERMPS,\n+  MULTI_ARG_3_PERMPD,\n+  MULTI_ARG_2_SF,\n+  MULTI_ARG_2_DF,\n+  MULTI_ARG_2_DI,\n+  MULTI_ARG_2_SI,\n+  MULTI_ARG_2_HI,\n+  MULTI_ARG_2_QI,\n+  MULTI_ARG_2_DI_IMM,\n+  MULTI_ARG_2_SI_IMM,\n+  MULTI_ARG_2_HI_IMM,\n+  MULTI_ARG_2_QI_IMM,\n+  MULTI_ARG_2_SF_CMP,\n+  MULTI_ARG_2_DF_CMP,\n+  MULTI_ARG_2_DI_CMP,\n+  MULTI_ARG_2_SI_CMP,\n+  MULTI_ARG_2_HI_CMP,\n+  MULTI_ARG_2_QI_CMP,\n+  MULTI_ARG_2_DI_TF,\n+  MULTI_ARG_2_SI_TF,\n+  MULTI_ARG_2_HI_TF,\n+  MULTI_ARG_2_QI_TF,\n+  MULTI_ARG_2_SF_TF,\n+  MULTI_ARG_2_DF_TF,\n+  MULTI_ARG_1_SF,\n+  MULTI_ARG_1_DF,\n+  MULTI_ARG_1_DI,\n+  MULTI_ARG_1_SI,\n+  MULTI_ARG_1_HI,\n+  MULTI_ARG_1_QI,\n+  MULTI_ARG_1_SI_DI,\n+  MULTI_ARG_1_HI_DI,\n+  MULTI_ARG_1_HI_SI,\n+  MULTI_ARG_1_QI_DI,\n+  MULTI_ARG_1_QI_SI,\n+  MULTI_ARG_1_QI_HI,\n+  MULTI_ARG_1_PH2PS,\n+  MULTI_ARG_1_PS2PH\n+};\n+\n+static const struct builtin_description bdesc_multi_arg[] =\n+{\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfmaddv4sf4,     \"__builtin_ia32_fmaddss\",    IX86_BUILTIN_FMADDSS,    0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfmaddv2df4,     \"__builtin_ia32_fmaddsd\",    IX86_BUILTIN_FMADDSD,    0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fmaddv4sf4,       \"__builtin_ia32_fmaddps\",    IX86_BUILTIN_FMADDPS,    0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fmaddv2df4,       \"__builtin_ia32_fmaddpd\",    IX86_BUILTIN_FMADDPD,    0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfmsubv4sf4,     \"__builtin_ia32_fmsubss\",    IX86_BUILTIN_FMSUBSS,    0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfmsubv2df4,     \"__builtin_ia32_fmsubsd\",    IX86_BUILTIN_FMSUBSD,    0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fmsubv4sf4,       \"__builtin_ia32_fmsubps\",    IX86_BUILTIN_FMSUBPS,    0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fmsubv2df4,       \"__builtin_ia32_fmsubpd\",    IX86_BUILTIN_FMSUBPD,    0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfnmaddv4sf4,    \"__builtin_ia32_fnmaddss\",   IX86_BUILTIN_FNMADDSS,   0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfnmaddv2df4,    \"__builtin_ia32_fnmaddsd\",   IX86_BUILTIN_FNMADDSD,   0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fnmaddv4sf4,      \"__builtin_ia32_fnmaddps\",   IX86_BUILTIN_FNMADDPS,   0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fnmaddv2df4,      \"__builtin_ia32_fnmaddpd\",   IX86_BUILTIN_FNMADDPD,   0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfnmsubv4sf4,    \"__builtin_ia32_fnmsubss\",   IX86_BUILTIN_FNMSUBSS,   0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_vmfnmsubv2df4,    \"__builtin_ia32_fnmsubsd\",   IX86_BUILTIN_FNMSUBSD,   0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fnmsubv4sf4,      \"__builtin_ia32_fnmsubps\",   IX86_BUILTIN_FNMSUBPS,   0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5i_fnmsubv2df4,      \"__builtin_ia32_fnmsubpd\",   IX86_BUILTIN_FNMSUBPD,   0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcmov_v2di,        \"__builtin_ia32_pcmov\",      IX86_BUILTIN_PCMOV_V2DI, 0,            (int)MULTI_ARG_3_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcmov_v2di,        \"__builtin_ia32_pcmov_v2di\", IX86_BUILTIN_PCMOV_V2DI, 0,            (int)MULTI_ARG_3_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcmov_v4si,        \"__builtin_ia32_pcmov_v4si\", IX86_BUILTIN_PCMOV_V4SI, 0,            (int)MULTI_ARG_3_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcmov_v8hi,        \"__builtin_ia32_pcmov_v8hi\", IX86_BUILTIN_PCMOV_V8HI, 0,            (int)MULTI_ARG_3_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcmov_v16qi,       \"__builtin_ia32_pcmov_v16qi\",IX86_BUILTIN_PCMOV_V16QI,0,            (int)MULTI_ARG_3_QI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcmov_v2df,        \"__builtin_ia32_pcmov_v2df\", IX86_BUILTIN_PCMOV_V2DF, 0,            (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcmov_v4sf,        \"__builtin_ia32_pcmov_v4sf\", IX86_BUILTIN_PCMOV_V4SF, 0,            (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pperm,             \"__builtin_ia32_pperm\",      IX86_BUILTIN_PPERM,      0,            (int)MULTI_ARG_3_QI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_permv4sf,          \"__builtin_ia32_permps\",     IX86_BUILTIN_PERMPS,     0,            (int)MULTI_ARG_3_PERMPS },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_permv2df,          \"__builtin_ia32_permpd\",     IX86_BUILTIN_PERMPD,     0,            (int)MULTI_ARG_3_PERMPD },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacssww,          \"__builtin_ia32_pmacssww\",   IX86_BUILTIN_PMACSSWW,   0,            (int)MULTI_ARG_3_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacsww,           \"__builtin_ia32_pmacsww\",    IX86_BUILTIN_PMACSWW,    0,            (int)MULTI_ARG_3_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacsswd,          \"__builtin_ia32_pmacsswd\",   IX86_BUILTIN_PMACSSWD,   0,            (int)MULTI_ARG_3_HI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacswd,           \"__builtin_ia32_pmacswd\",    IX86_BUILTIN_PMACSWD,    0,            (int)MULTI_ARG_3_HI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacssdd,          \"__builtin_ia32_pmacssdd\",   IX86_BUILTIN_PMACSSDD,   0,            (int)MULTI_ARG_3_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacsdd,           \"__builtin_ia32_pmacsdd\",    IX86_BUILTIN_PMACSDD,    0,            (int)MULTI_ARG_3_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacssdql,         \"__builtin_ia32_pmacssdql\",  IX86_BUILTIN_PMACSSDQL,  0,            (int)MULTI_ARG_3_SI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacssdqh,         \"__builtin_ia32_pmacssdqh\",  IX86_BUILTIN_PMACSSDQH,  0,            (int)MULTI_ARG_3_SI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacsdql,          \"__builtin_ia32_pmacsdql\",   IX86_BUILTIN_PMACSDQL,   0,            (int)MULTI_ARG_3_SI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacsdqh,          \"__builtin_ia32_pmacsdqh\",   IX86_BUILTIN_PMACSDQH,   0,            (int)MULTI_ARG_3_SI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmadcsswd,         \"__builtin_ia32_pmadcsswd\",  IX86_BUILTIN_PMADCSSWD,  0,            (int)MULTI_ARG_3_HI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmadcswd,          \"__builtin_ia32_pmadcswd\",   IX86_BUILTIN_PMADCSWD,   0,            (int)MULTI_ARG_3_HI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv2di3,         \"__builtin_ia32_protq\",      IX86_BUILTIN_PROTQ,      0,            (int)MULTI_ARG_2_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv4si3,         \"__builtin_ia32_protd\",      IX86_BUILTIN_PROTD,      0,            (int)MULTI_ARG_2_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv8hi3,         \"__builtin_ia32_protw\",      IX86_BUILTIN_PROTW,      0,            (int)MULTI_ARG_2_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv16qi3,        \"__builtin_ia32_protb\",      IX86_BUILTIN_PROTB,      0,            (int)MULTI_ARG_2_QI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv2di3,              \"__builtin_ia32_protqi\",     IX86_BUILTIN_PROTQ_IMM,  0,            (int)MULTI_ARG_2_DI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv4si3,              \"__builtin_ia32_protdi\",     IX86_BUILTIN_PROTD_IMM,  0,            (int)MULTI_ARG_2_SI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv8hi3,              \"__builtin_ia32_protwi\",     IX86_BUILTIN_PROTW_IMM,  0,            (int)MULTI_ARG_2_HI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv16qi3,             \"__builtin_ia32_protbi\",     IX86_BUILTIN_PROTB_IMM,  0,            (int)MULTI_ARG_2_QI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_ashlv2di3,         \"__builtin_ia32_pshaq\",      IX86_BUILTIN_PSHAQ,      0,            (int)MULTI_ARG_2_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_ashlv4si3,         \"__builtin_ia32_pshad\",      IX86_BUILTIN_PSHAD,      0,            (int)MULTI_ARG_2_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_ashlv8hi3,         \"__builtin_ia32_pshaw\",      IX86_BUILTIN_PSHAW,      0,            (int)MULTI_ARG_2_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_ashlv16qi3,        \"__builtin_ia32_pshab\",      IX86_BUILTIN_PSHAB,      0,            (int)MULTI_ARG_2_QI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_lshlv2di3,         \"__builtin_ia32_pshlq\",      IX86_BUILTIN_PSHLQ,      0,            (int)MULTI_ARG_2_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_lshlv4si3,         \"__builtin_ia32_pshld\",      IX86_BUILTIN_PSHLD,      0,            (int)MULTI_ARG_2_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_lshlv8hi3,         \"__builtin_ia32_pshlw\",      IX86_BUILTIN_PSHLW,      0,            (int)MULTI_ARG_2_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_lshlv16qi3,        \"__builtin_ia32_pshlb\",      IX86_BUILTIN_PSHLB,      0,            (int)MULTI_ARG_2_QI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmfrczv4sf2,       \"__builtin_ia32_frczss\",     IX86_BUILTIN_FRCZSS,     0,            (int)MULTI_ARG_2_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmfrczv2df2,       \"__builtin_ia32_frczsd\",     IX86_BUILTIN_FRCZSD,     0,            (int)MULTI_ARG_2_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_frczv4sf2,         \"__builtin_ia32_frczps\",     IX86_BUILTIN_FRCZPS,     0,            (int)MULTI_ARG_1_SF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_frczv2df2,         \"__builtin_ia32_frczpd\",     IX86_BUILTIN_FRCZPD,     0,            (int)MULTI_ARG_1_DF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_cvtph2ps,          \"__builtin_ia32_cvtph2ps\",   IX86_BUILTIN_CVTPH2PS,   0,            (int)MULTI_ARG_1_PH2PS },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_cvtps2ph,          \"__builtin_ia32_cvtps2ph\",   IX86_BUILTIN_CVTPS2PH,   0,            (int)MULTI_ARG_1_PS2PH },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddbw,           \"__builtin_ia32_phaddbw\",    IX86_BUILTIN_PHADDBW,    0,            (int)MULTI_ARG_1_QI_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddbd,           \"__builtin_ia32_phaddbd\",    IX86_BUILTIN_PHADDBD,    0,            (int)MULTI_ARG_1_QI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddbq,           \"__builtin_ia32_phaddbq\",    IX86_BUILTIN_PHADDBQ,    0,            (int)MULTI_ARG_1_QI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddwd,           \"__builtin_ia32_phaddwd\",    IX86_BUILTIN_PHADDWD,    0,            (int)MULTI_ARG_1_HI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddwq,           \"__builtin_ia32_phaddwq\",    IX86_BUILTIN_PHADDWQ,    0,            (int)MULTI_ARG_1_HI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phadddq,           \"__builtin_ia32_phadddq\",    IX86_BUILTIN_PHADDDQ,    0,            (int)MULTI_ARG_1_SI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddubw,          \"__builtin_ia32_phaddubw\",   IX86_BUILTIN_PHADDUBW,   0,            (int)MULTI_ARG_1_QI_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddubd,          \"__builtin_ia32_phaddubd\",   IX86_BUILTIN_PHADDUBD,   0,            (int)MULTI_ARG_1_QI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddubq,          \"__builtin_ia32_phaddubq\",   IX86_BUILTIN_PHADDUBQ,   0,            (int)MULTI_ARG_1_QI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phadduwd,          \"__builtin_ia32_phadduwd\",   IX86_BUILTIN_PHADDUWD,   0,            (int)MULTI_ARG_1_HI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phadduwq,          \"__builtin_ia32_phadduwq\",   IX86_BUILTIN_PHADDUWQ,   0,            (int)MULTI_ARG_1_HI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phaddudq,          \"__builtin_ia32_phaddudq\",   IX86_BUILTIN_PHADDUDQ,   0,            (int)MULTI_ARG_1_SI_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phsubbw,           \"__builtin_ia32_phsubbw\",    IX86_BUILTIN_PHSUBBW,    0,            (int)MULTI_ARG_1_QI_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phsubwd,           \"__builtin_ia32_phsubwd\",    IX86_BUILTIN_PHSUBWD,    0,            (int)MULTI_ARG_1_HI_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_phsubdq,           \"__builtin_ia32_phsubdq\",    IX86_BUILTIN_PHSUBDQ,    0,            (int)MULTI_ARG_1_SI_DI },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comeqss\",    IX86_BUILTIN_COMEQSS,    EQ,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comness\",    IX86_BUILTIN_COMNESS,    NE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comneqss\",   IX86_BUILTIN_COMNESS,    NE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comltss\",    IX86_BUILTIN_COMLTSS,    LT,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comless\",    IX86_BUILTIN_COMLESS,    LE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comgtss\",    IX86_BUILTIN_COMGTSS,    GT,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comgess\",    IX86_BUILTIN_COMGESS,    GE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comueqss\",   IX86_BUILTIN_COMUEQSS,   UNEQ,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comuness\",   IX86_BUILTIN_COMUNESS,   LTGT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comuneqss\",  IX86_BUILTIN_COMUNESS,   LTGT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comunltss\",  IX86_BUILTIN_COMULTSS,   UNLT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comunless\",  IX86_BUILTIN_COMULESS,   UNLE,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comungtss\",  IX86_BUILTIN_COMUGTSS,   UNGT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comungess\",  IX86_BUILTIN_COMUGESS,   UNGE,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comordss\",   IX86_BUILTIN_COMORDSS,   ORDERED,      (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv4sf3,    \"__builtin_ia32_comunordss\", IX86_BUILTIN_COMUNORDSS, UNORDERED,    (int)MULTI_ARG_2_SF_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comeqsd\",    IX86_BUILTIN_COMEQSD,    EQ,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comnesd\",    IX86_BUILTIN_COMNESD,    NE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comneqsd\",   IX86_BUILTIN_COMNESD,    NE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comltsd\",    IX86_BUILTIN_COMLTSD,    LT,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comlesd\",    IX86_BUILTIN_COMLESD,    LE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comgtsd\",    IX86_BUILTIN_COMGTSD,    GT,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comgesd\",    IX86_BUILTIN_COMGESD,    GE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comueqsd\",   IX86_BUILTIN_COMUEQSD,   UNEQ,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comunesd\",   IX86_BUILTIN_COMUNESD,   LTGT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comuneqsd\",  IX86_BUILTIN_COMUNESD,   LTGT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comunltsd\",  IX86_BUILTIN_COMULTSD,   UNLT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comunlesd\",  IX86_BUILTIN_COMULESD,   UNLE,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comungtsd\",  IX86_BUILTIN_COMUGTSD,   UNGT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comungesd\",  IX86_BUILTIN_COMUGESD,   UNGE,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comordsd\",   IX86_BUILTIN_COMORDSD,   ORDERED,      (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vmmaskcmpv2df3,    \"__builtin_ia32_comunordsd\", IX86_BUILTIN_COMUNORDSD, UNORDERED,    (int)MULTI_ARG_2_DF_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comeqps\",    IX86_BUILTIN_COMEQPS,    EQ,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comneps\",    IX86_BUILTIN_COMNEPS,    NE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comneqps\",   IX86_BUILTIN_COMNEPS,    NE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comltps\",    IX86_BUILTIN_COMLTPS,    LT,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comleps\",    IX86_BUILTIN_COMLEPS,    LE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comgtps\",    IX86_BUILTIN_COMGTPS,    GT,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comgeps\",    IX86_BUILTIN_COMGEPS,    GE,           (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comueqps\",   IX86_BUILTIN_COMUEQPS,   UNEQ,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comuneps\",   IX86_BUILTIN_COMUNEPS,   LTGT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comuneqps\",  IX86_BUILTIN_COMUNEPS,   LTGT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comunltps\",  IX86_BUILTIN_COMULTPS,   UNLT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comunleps\",  IX86_BUILTIN_COMULEPS,   UNLE,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comungtps\",  IX86_BUILTIN_COMUGTPS,   UNGT,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comungeps\",  IX86_BUILTIN_COMUGEPS,   UNGE,         (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comordps\",   IX86_BUILTIN_COMORDPS,   ORDERED,      (int)MULTI_ARG_2_SF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4sf3,      \"__builtin_ia32_comunordps\", IX86_BUILTIN_COMUNORDPS, UNORDERED,    (int)MULTI_ARG_2_SF_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comeqpd\",    IX86_BUILTIN_COMEQPD,    EQ,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comnepd\",    IX86_BUILTIN_COMNEPD,    NE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comneqpd\",   IX86_BUILTIN_COMNEPD,    NE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comltpd\",    IX86_BUILTIN_COMLTPD,    LT,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comlepd\",    IX86_BUILTIN_COMLEPD,    LE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comgtpd\",    IX86_BUILTIN_COMGTPD,    GT,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comgepd\",    IX86_BUILTIN_COMGEPD,    GE,           (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comueqpd\",   IX86_BUILTIN_COMUEQPD,   UNEQ,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comunepd\",   IX86_BUILTIN_COMUNEPD,   LTGT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comuneqpd\",  IX86_BUILTIN_COMUNEPD,   LTGT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comunltpd\",  IX86_BUILTIN_COMULTPD,   UNLT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comunlepd\",  IX86_BUILTIN_COMULEPD,   UNLE,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comungtpd\",  IX86_BUILTIN_COMUGTPD,   UNGT,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comungepd\",  IX86_BUILTIN_COMUGEPD,   UNGE,         (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comordpd\",   IX86_BUILTIN_COMORDPD,   ORDERED,      (int)MULTI_ARG_2_DF_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2df3,      \"__builtin_ia32_comunordpd\", IX86_BUILTIN_COMUNORDPD, UNORDERED,    (int)MULTI_ARG_2_DF_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv16qi3,     \"__builtin_ia32_pcomeqb\",    IX86_BUILTIN_PCOMEQB,    EQ,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv16qi3,     \"__builtin_ia32_pcomneb\",    IX86_BUILTIN_PCOMNEB,    NE,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv16qi3,     \"__builtin_ia32_pcomneqb\",   IX86_BUILTIN_PCOMNEB,    NE,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv16qi3,     \"__builtin_ia32_pcomltb\",    IX86_BUILTIN_PCOMLTB,    LT,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv16qi3,     \"__builtin_ia32_pcomleb\",    IX86_BUILTIN_PCOMLEB,    LE,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv16qi3,     \"__builtin_ia32_pcomgtb\",    IX86_BUILTIN_PCOMGTB,    GT,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv16qi3,     \"__builtin_ia32_pcomgeb\",    IX86_BUILTIN_PCOMGEB,    GE,           (int)MULTI_ARG_2_QI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv8hi3,      \"__builtin_ia32_pcomeqw\",    IX86_BUILTIN_PCOMEQW,    EQ,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv8hi3,      \"__builtin_ia32_pcomnew\",    IX86_BUILTIN_PCOMNEW,    NE,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv8hi3,      \"__builtin_ia32_pcomneqw\",   IX86_BUILTIN_PCOMNEW,    NE,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv8hi3,      \"__builtin_ia32_pcomltw\",    IX86_BUILTIN_PCOMLTW,    LT,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv8hi3,      \"__builtin_ia32_pcomlew\",    IX86_BUILTIN_PCOMLEW,    LE,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv8hi3,      \"__builtin_ia32_pcomgtw\",    IX86_BUILTIN_PCOMGTW,    GT,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv8hi3,      \"__builtin_ia32_pcomgew\",    IX86_BUILTIN_PCOMGEW,    GE,           (int)MULTI_ARG_2_HI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4si3,      \"__builtin_ia32_pcomeqd\",    IX86_BUILTIN_PCOMEQD,    EQ,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4si3,      \"__builtin_ia32_pcomned\",    IX86_BUILTIN_PCOMNED,    NE,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4si3,      \"__builtin_ia32_pcomneqd\",   IX86_BUILTIN_PCOMNED,    NE,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4si3,      \"__builtin_ia32_pcomltd\",    IX86_BUILTIN_PCOMLTD,    LT,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4si3,      \"__builtin_ia32_pcomled\",    IX86_BUILTIN_PCOMLED,    LE,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4si3,      \"__builtin_ia32_pcomgtd\",    IX86_BUILTIN_PCOMGTD,    GT,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv4si3,      \"__builtin_ia32_pcomged\",    IX86_BUILTIN_PCOMGED,    GE,           (int)MULTI_ARG_2_SI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2di3,      \"__builtin_ia32_pcomeqq\",    IX86_BUILTIN_PCOMEQQ,    EQ,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2di3,      \"__builtin_ia32_pcomneq\",    IX86_BUILTIN_PCOMNEQ,    NE,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2di3,      \"__builtin_ia32_pcomneqq\",   IX86_BUILTIN_PCOMNEQ,    NE,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2di3,      \"__builtin_ia32_pcomltq\",    IX86_BUILTIN_PCOMLTQ,    LT,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2di3,      \"__builtin_ia32_pcomleq\",    IX86_BUILTIN_PCOMLEQ,    LE,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2di3,      \"__builtin_ia32_pcomgtq\",    IX86_BUILTIN_PCOMGTQ,    GT,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmpv2di3,      \"__builtin_ia32_pcomgeq\",    IX86_BUILTIN_PCOMGEQ,    GE,           (int)MULTI_ARG_2_DI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v16qi3,\"__builtin_ia32_pcomequb\",   IX86_BUILTIN_PCOMEQUB,   EQ,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v16qi3,\"__builtin_ia32_pcomneub\",   IX86_BUILTIN_PCOMNEUB,   NE,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v16qi3,\"__builtin_ia32_pcomnequb\",  IX86_BUILTIN_PCOMNEUB,   NE,           (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv16qi3, \"__builtin_ia32_pcomltub\",   IX86_BUILTIN_PCOMLTUB,   LTU,          (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv16qi3, \"__builtin_ia32_pcomleub\",   IX86_BUILTIN_PCOMLEUB,   LEU,          (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv16qi3, \"__builtin_ia32_pcomgtub\",   IX86_BUILTIN_PCOMGTUB,   GTU,          (int)MULTI_ARG_2_QI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv16qi3, \"__builtin_ia32_pcomgeub\",   IX86_BUILTIN_PCOMGEUB,   GEU,          (int)MULTI_ARG_2_QI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v8hi3, \"__builtin_ia32_pcomequw\",   IX86_BUILTIN_PCOMEQUW,   EQ,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v8hi3, \"__builtin_ia32_pcomneuw\",   IX86_BUILTIN_PCOMNEUW,   NE,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v8hi3, \"__builtin_ia32_pcomnequw\",  IX86_BUILTIN_PCOMNEUW,   NE,           (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv8hi3,  \"__builtin_ia32_pcomltuw\",   IX86_BUILTIN_PCOMLTUW,   LTU,          (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv8hi3,  \"__builtin_ia32_pcomleuw\",   IX86_BUILTIN_PCOMLEUW,   LEU,          (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv8hi3,  \"__builtin_ia32_pcomgtuw\",   IX86_BUILTIN_PCOMGTUW,   GTU,          (int)MULTI_ARG_2_HI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv8hi3,  \"__builtin_ia32_pcomgeuw\",   IX86_BUILTIN_PCOMGEUW,   GEU,          (int)MULTI_ARG_2_HI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v4si3, \"__builtin_ia32_pcomequd\",   IX86_BUILTIN_PCOMEQUD,   EQ,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v4si3, \"__builtin_ia32_pcomneud\",   IX86_BUILTIN_PCOMNEUD,   NE,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v4si3, \"__builtin_ia32_pcomnequd\",  IX86_BUILTIN_PCOMNEUD,   NE,           (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv4si3,  \"__builtin_ia32_pcomltud\",   IX86_BUILTIN_PCOMLTUD,   LTU,          (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv4si3,  \"__builtin_ia32_pcomleud\",   IX86_BUILTIN_PCOMLEUD,   LEU,          (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv4si3,  \"__builtin_ia32_pcomgtud\",   IX86_BUILTIN_PCOMGTUD,   GTU,          (int)MULTI_ARG_2_SI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv4si3,  \"__builtin_ia32_pcomgeud\",   IX86_BUILTIN_PCOMGEUD,   GEU,          (int)MULTI_ARG_2_SI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v2di3, \"__builtin_ia32_pcomequq\",   IX86_BUILTIN_PCOMEQUQ,   EQ,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v2di3, \"__builtin_ia32_pcomneuq\",   IX86_BUILTIN_PCOMNEUQ,   NE,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_uns2v2di3, \"__builtin_ia32_pcomnequq\",  IX86_BUILTIN_PCOMNEUQ,   NE,           (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv2di3,  \"__builtin_ia32_pcomltuq\",   IX86_BUILTIN_PCOMLTUQ,   LTU,          (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv2di3,  \"__builtin_ia32_pcomleuq\",   IX86_BUILTIN_PCOMLEUQ,   LEU,          (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv2di3,  \"__builtin_ia32_pcomgtuq\",   IX86_BUILTIN_PCOMGTUQ,   GTU,          (int)MULTI_ARG_2_DI_CMP },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_maskcmp_unsv2di3,  \"__builtin_ia32_pcomgeuq\",   IX86_BUILTIN_PCOMGEUQ,   GEU,          (int)MULTI_ARG_2_DI_CMP },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv4sf3,       \"__builtin_ia32_comfalsess\", IX86_BUILTIN_COMFALSESS, COM_FALSE_S,  (int)MULTI_ARG_2_SF_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv4sf3,       \"__builtin_ia32_comtruess\",  IX86_BUILTIN_COMTRUESS,  COM_TRUE_S,   (int)MULTI_ARG_2_SF_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv4sf3,       \"__builtin_ia32_comfalseps\", IX86_BUILTIN_COMFALSEPS, COM_FALSE_P,  (int)MULTI_ARG_2_SF_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv4sf3,       \"__builtin_ia32_comtrueps\",  IX86_BUILTIN_COMTRUEPS,  COM_TRUE_P,   (int)MULTI_ARG_2_SF_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv2df3,       \"__builtin_ia32_comfalsesd\", IX86_BUILTIN_COMFALSESD, COM_FALSE_S,  (int)MULTI_ARG_2_DF_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv2df3,       \"__builtin_ia32_comtruesd\",  IX86_BUILTIN_COMTRUESD,  COM_TRUE_S,   (int)MULTI_ARG_2_DF_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv2df3,       \"__builtin_ia32_comfalsepd\", IX86_BUILTIN_COMFALSEPD, COM_FALSE_P,  (int)MULTI_ARG_2_DF_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_com_tfv2df3,       \"__builtin_ia32_comtruepd\",  IX86_BUILTIN_COMTRUEPD,  COM_TRUE_P,   (int)MULTI_ARG_2_DF_TF },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv16qi3,     \"__builtin_ia32_pcomfalseb\", IX86_BUILTIN_PCOMFALSEB, PCOM_FALSE,   (int)MULTI_ARG_2_QI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv8hi3,      \"__builtin_ia32_pcomfalsew\", IX86_BUILTIN_PCOMFALSEW, PCOM_FALSE,   (int)MULTI_ARG_2_HI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv4si3,      \"__builtin_ia32_pcomfalsed\", IX86_BUILTIN_PCOMFALSED, PCOM_FALSE,   (int)MULTI_ARG_2_SI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv2di3,      \"__builtin_ia32_pcomfalseq\", IX86_BUILTIN_PCOMFALSEQ, PCOM_FALSE,   (int)MULTI_ARG_2_DI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv16qi3,     \"__builtin_ia32_pcomfalseub\",IX86_BUILTIN_PCOMFALSEUB,PCOM_FALSE,   (int)MULTI_ARG_2_QI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv8hi3,      \"__builtin_ia32_pcomfalseuw\",IX86_BUILTIN_PCOMFALSEUW,PCOM_FALSE,   (int)MULTI_ARG_2_HI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv4si3,      \"__builtin_ia32_pcomfalseud\",IX86_BUILTIN_PCOMFALSEUD,PCOM_FALSE,   (int)MULTI_ARG_2_SI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv2di3,      \"__builtin_ia32_pcomfalseuq\",IX86_BUILTIN_PCOMFALSEUQ,PCOM_FALSE,   (int)MULTI_ARG_2_DI_TF },\n+\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv16qi3,     \"__builtin_ia32_pcomtrueb\",  IX86_BUILTIN_PCOMTRUEB,  PCOM_TRUE,    (int)MULTI_ARG_2_QI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv8hi3,      \"__builtin_ia32_pcomtruew\",  IX86_BUILTIN_PCOMTRUEW,  PCOM_TRUE,    (int)MULTI_ARG_2_HI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv4si3,      \"__builtin_ia32_pcomtrued\",  IX86_BUILTIN_PCOMTRUED,  PCOM_TRUE,    (int)MULTI_ARG_2_SI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv2di3,      \"__builtin_ia32_pcomtrueq\",  IX86_BUILTIN_PCOMTRUEQ,  PCOM_TRUE,    (int)MULTI_ARG_2_DI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv16qi3,     \"__builtin_ia32_pcomtrueub\", IX86_BUILTIN_PCOMTRUEUB, PCOM_TRUE,    (int)MULTI_ARG_2_QI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv8hi3,      \"__builtin_ia32_pcomtrueuw\", IX86_BUILTIN_PCOMTRUEUW, PCOM_TRUE,    (int)MULTI_ARG_2_HI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv4si3,      \"__builtin_ia32_pcomtrueud\", IX86_BUILTIN_PCOMTRUEUD, PCOM_TRUE,    (int)MULTI_ARG_2_SI_TF },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pcom_tfv2di3,      \"__builtin_ia32_pcomtrueuq\", IX86_BUILTIN_PCOMTRUEUQ, PCOM_TRUE,    (int)MULTI_ARG_2_DI_TF },\n+};\n+\n /* Set up all the MMX/SSE builtins.  This is not called if TARGET_MMX\n    is zero.  Otherwise, if TARGET_SSE is not set, only expand the MMX\n    builtins.  */\n@@ -18008,6 +18765,93 @@ ix86_init_mmx_sse_builtins (void)\n \t\t\t\tV16QI_type_node,\n \t\t\t\tinteger_type_node,\n \t\t\t\tNULL_TREE);\n+\n+  /* SSE5 instructions */\n+  tree v2di_ftype_v2di_v2di_v2di\n+    = build_function_type_list (V2DI_type_node,\n+\t\t\t\tV2DI_type_node,\n+\t\t\t\tV2DI_type_node,\n+\t\t\t\tV2DI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v4si_ftype_v4si_v4si_v4si\n+    = build_function_type_list (V4SI_type_node,\n+\t\t\t\tV4SI_type_node,\n+\t\t\t\tV4SI_type_node,\n+\t\t\t\tV4SI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v4si_ftype_v4si_v4si_v2di\n+    = build_function_type_list (V4SI_type_node,\n+\t\t\t\tV4SI_type_node,\n+\t\t\t\tV4SI_type_node,\n+\t\t\t\tV2DI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v8hi_ftype_v8hi_v8hi_v8hi\n+    = build_function_type_list (V8HI_type_node,\n+\t\t\t\tV8HI_type_node,\n+\t\t\t\tV8HI_type_node,\n+\t\t\t\tV8HI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v8hi_ftype_v8hi_v8hi_v4si\n+    = build_function_type_list (V8HI_type_node,\n+\t\t\t\tV8HI_type_node,\n+\t\t\t\tV8HI_type_node,\n+\t\t\t\tV4SI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v2df_ftype_v2df_v2df_v16qi\n+    = build_function_type_list (V2DF_type_node,\n+\t\t\t\tV2DF_type_node,\n+\t\t\t\tV2DF_type_node,\n+\t\t\t\tV16QI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v4sf_ftype_v4sf_v4sf_v16qi\n+    = build_function_type_list (V4SF_type_node,\n+\t\t\t\tV4SF_type_node,\n+\t\t\t\tV4SF_type_node,\n+\t\t\t\tV16QI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v2di_ftype_v2di_si\n+    = build_function_type_list (V2DI_type_node,\n+\t\t\t\tV2DI_type_node,\n+\t\t\t\tinteger_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v4si_ftype_v4si_si\n+    = build_function_type_list (V4SI_type_node,\n+\t\t\t\tV4SI_type_node,\n+\t\t\t\tinteger_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v8hi_ftype_v8hi_si\n+    = build_function_type_list (V8HI_type_node,\n+\t\t\t\tV8HI_type_node,\n+\t\t\t\tinteger_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v16qi_ftype_v16qi_si\n+    = build_function_type_list (V16QI_type_node,\n+\t\t\t\tV16QI_type_node,\n+\t\t\t\tinteger_type_node,\n+\t\t\t\tNULL_TREE);\n+  tree v4sf_ftype_v4hi\n+    = build_function_type_list (V4SF_type_node,\n+\t\t\t\tV4HI_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v4hi_ftype_v4sf\n+    = build_function_type_list (V4HI_type_node,\n+\t\t\t\tV4SF_type_node,\n+\t\t\t\tNULL_TREE);\n+\n+  tree v2di_ftype_v2di\n+    = build_function_type_list (V2DI_type_node, V2DI_type_node, NULL_TREE);\n+\n   tree ftype;\n \n   /* The __float80 type.  */\n@@ -18454,10 +19298,12 @@ ix86_init_mmx_sse_builtins (void)\n   def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_pmovzxwq128\", v2di_ftype_v8hi, IX86_BUILTIN_PMOVZXWQ128);\n   def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_pmovzxdq128\", v2di_ftype_v4si, IX86_BUILTIN_PMOVZXDQ128);\n   def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_pmuldq128\", v2di_ftype_v4si_v4si, IX86_BUILTIN_PMULDQ128);\n-  def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_roundpd\", v2df_ftype_v2df_int, IX86_BUILTIN_ROUNDPD);\n-  def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_roundps\", v4sf_ftype_v4sf_int, IX86_BUILTIN_ROUNDPS);\n-  def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_roundsd\", v2df_ftype_v2df_v2df_int, IX86_BUILTIN_ROUNDSD);\n-  def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_roundss\", v4sf_ftype_v4sf_v4sf_int, IX86_BUILTIN_ROUNDSS);\n+\n+  /* SSE4.1 and SSE5 */\n+  def_builtin_const (OPTION_MASK_ISA_ROUND, \"__builtin_ia32_roundpd\", v2df_ftype_v2df_int, IX86_BUILTIN_ROUNDPD);\n+  def_builtin_const (OPTION_MASK_ISA_ROUND, \"__builtin_ia32_roundps\", v4sf_ftype_v4sf_int, IX86_BUILTIN_ROUNDPS);\n+  def_builtin_const (OPTION_MASK_ISA_ROUND, \"__builtin_ia32_roundsd\", v2df_ftype_v2df_v2df_int, IX86_BUILTIN_ROUNDSD);\n+  def_builtin_const (OPTION_MASK_ISA_ROUND, \"__builtin_ia32_roundss\", v4sf_ftype_v4sf_v4sf_int, IX86_BUILTIN_ROUNDSS);\n \n   /* SSE4.2. */\n   ftype = build_function_type_list (unsigned_type_node,\n@@ -18571,6 +19417,71 @@ ix86_init_mmx_sse_builtins (void)\n \t\t\t\t    intQI_type_node,\n \t\t\t\t    integer_type_node, NULL_TREE);\n   def_builtin_const (OPTION_MASK_ISA_SSE4_1, \"__builtin_ia32_vec_set_v16qi\", ftype, IX86_BUILTIN_VEC_SET_V16QI);\n+\n+  /* Add SSE5 multi-arg argument instructions */\n+  for (i = 0, d = bdesc_multi_arg; i < ARRAY_SIZE (bdesc_multi_arg); i++, d++)\n+    {\n+      tree mtype = NULL_TREE;\n+\n+      if (d->name == 0)\n+\tcontinue;\n+\n+      switch ((enum multi_arg_type)d->flag)\n+\t{\n+\tcase MULTI_ARG_3_SF:     mtype = v4sf_ftype_v4sf_v4sf_v4sf; \tbreak;\n+\tcase MULTI_ARG_3_DF:     mtype = v2df_ftype_v2df_v2df_v2df; \tbreak;\n+\tcase MULTI_ARG_3_DI:     mtype = v2di_ftype_v2di_v2di_v2di; \tbreak;\n+\tcase MULTI_ARG_3_SI:     mtype = v4si_ftype_v4si_v4si_v4si; \tbreak;\n+\tcase MULTI_ARG_3_SI_DI:  mtype = v4si_ftype_v4si_v4si_v2di; \tbreak;\n+\tcase MULTI_ARG_3_HI:     mtype = v8hi_ftype_v8hi_v8hi_v8hi; \tbreak;\n+\tcase MULTI_ARG_3_HI_SI:  mtype = v8hi_ftype_v8hi_v8hi_v4si; \tbreak;\n+\tcase MULTI_ARG_3_QI:     mtype = v16qi_ftype_v16qi_v16qi_v16qi; break;\n+\tcase MULTI_ARG_3_PERMPS: mtype = v4sf_ftype_v4sf_v4sf_v16qi; \tbreak;\n+\tcase MULTI_ARG_3_PERMPD: mtype = v2df_ftype_v2df_v2df_v16qi; \tbreak;\n+\tcase MULTI_ARG_2_SF:     mtype = v4sf_ftype_v4sf_v4sf;      \tbreak;\n+\tcase MULTI_ARG_2_DF:     mtype = v2df_ftype_v2df_v2df;      \tbreak;\n+\tcase MULTI_ARG_2_DI:     mtype = v2di_ftype_v2di_v2di;      \tbreak;\n+\tcase MULTI_ARG_2_SI:     mtype = v4si_ftype_v4si_v4si;      \tbreak;\n+\tcase MULTI_ARG_2_HI:     mtype = v8hi_ftype_v8hi_v8hi;      \tbreak;\n+\tcase MULTI_ARG_2_QI:     mtype = v16qi_ftype_v16qi_v16qi;      \tbreak;\n+\tcase MULTI_ARG_2_DI_IMM: mtype = v2di_ftype_v2di_si;        \tbreak;\n+\tcase MULTI_ARG_2_SI_IMM: mtype = v4si_ftype_v4si_si;        \tbreak;\n+\tcase MULTI_ARG_2_HI_IMM: mtype = v8hi_ftype_v8hi_si;        \tbreak;\n+\tcase MULTI_ARG_2_QI_IMM: mtype = v16qi_ftype_v16qi_si;        \tbreak;\n+\tcase MULTI_ARG_2_SF_CMP: mtype = v4sf_ftype_v4sf_v4sf;      \tbreak;\n+\tcase MULTI_ARG_2_DF_CMP: mtype = v2df_ftype_v2df_v2df;      \tbreak;\n+\tcase MULTI_ARG_2_DI_CMP: mtype = v2di_ftype_v2di_v2di;      \tbreak;\n+\tcase MULTI_ARG_2_SI_CMP: mtype = v4si_ftype_v4si_v4si;      \tbreak;\n+\tcase MULTI_ARG_2_HI_CMP: mtype = v8hi_ftype_v8hi_v8hi;      \tbreak;\n+\tcase MULTI_ARG_2_QI_CMP: mtype = v16qi_ftype_v16qi_v16qi;      \tbreak;\n+\tcase MULTI_ARG_2_SF_TF:  mtype = v4sf_ftype_v4sf_v4sf;      \tbreak;\n+\tcase MULTI_ARG_2_DF_TF:  mtype = v2df_ftype_v2df_v2df;      \tbreak;\n+\tcase MULTI_ARG_2_DI_TF:  mtype = v2di_ftype_v2di_v2di;      \tbreak;\n+\tcase MULTI_ARG_2_SI_TF:  mtype = v4si_ftype_v4si_v4si;      \tbreak;\n+\tcase MULTI_ARG_2_HI_TF:  mtype = v8hi_ftype_v8hi_v8hi;      \tbreak;\n+\tcase MULTI_ARG_2_QI_TF:  mtype = v16qi_ftype_v16qi_v16qi;      \tbreak;\n+\tcase MULTI_ARG_1_SF:     mtype = v4sf_ftype_v4sf;           \tbreak;\n+\tcase MULTI_ARG_1_DF:     mtype = v2df_ftype_v2df;           \tbreak;\n+\tcase MULTI_ARG_1_DI:     mtype = v2di_ftype_v2di;           \tbreak;\n+\tcase MULTI_ARG_1_SI:     mtype = v4si_ftype_v4si;           \tbreak;\n+\tcase MULTI_ARG_1_HI:     mtype = v8hi_ftype_v8hi;           \tbreak;\n+\tcase MULTI_ARG_1_QI:     mtype = v16qi_ftype_v16qi;           \tbreak;\n+\tcase MULTI_ARG_1_SI_DI:  mtype = v2di_ftype_v4si;           \tbreak;\n+\tcase MULTI_ARG_1_HI_DI:  mtype = v2di_ftype_v8hi;           \tbreak;\n+\tcase MULTI_ARG_1_HI_SI:  mtype = v4si_ftype_v8hi;           \tbreak;\n+\tcase MULTI_ARG_1_QI_DI:  mtype = v2di_ftype_v16qi;           \tbreak;\n+\tcase MULTI_ARG_1_QI_SI:  mtype = v4si_ftype_v16qi;           \tbreak;\n+\tcase MULTI_ARG_1_QI_HI:  mtype = v8hi_ftype_v16qi;           \tbreak;\n+\tcase MULTI_ARG_1_PH2PS:  mtype = v4sf_ftype_v4hi;\t\tbreak;\n+\tcase MULTI_ARG_1_PS2PH:  mtype = v4hi_ftype_v4sf;\t\tbreak;\n+\tcase MULTI_ARG_UNKNOWN:\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+\n+      if (mtype)\n+\tdef_builtin_const (d->mask, d->name, mtype, d->code);\n+    }\n }\n \n static void\n@@ -18754,6 +19665,182 @@ ix86_expand_binop_builtin (enum insn_code icode, tree exp, rtx target)\n   return target;\n }\n \n+/* Subroutine of ix86_expand_builtin to take care of 2-4 argument insns.  */\n+\n+static rtx\n+ix86_expand_multi_arg_builtin (enum insn_code icode, tree exp, rtx target,\n+\t\t\t       enum multi_arg_type m_type,\n+\t\t\t       enum insn_code sub_code)\n+{\n+  rtx pat;\n+  int i;\n+  int nargs;\n+  bool comparison_p = false;\n+  bool tf_p = false;\n+  bool last_arg_constant = false;\n+  int num_memory = 0;\n+  struct {\n+    rtx op;\n+    enum machine_mode mode;\n+  } args[4];\n+\n+  enum machine_mode tmode = insn_data[icode].operand[0].mode;\n+\n+  switch (m_type)\n+    {\n+    case MULTI_ARG_3_SF:\n+    case MULTI_ARG_3_DF:\n+    case MULTI_ARG_3_DI:\n+    case MULTI_ARG_3_SI:\n+    case MULTI_ARG_3_SI_DI:\n+    case MULTI_ARG_3_HI:\n+    case MULTI_ARG_3_HI_SI:\n+    case MULTI_ARG_3_QI:\n+    case MULTI_ARG_3_PERMPS:\n+    case MULTI_ARG_3_PERMPD:\n+      nargs = 3;\n+      break;\n+\n+    case MULTI_ARG_2_SF:\n+    case MULTI_ARG_2_DF:\n+    case MULTI_ARG_2_DI:\n+    case MULTI_ARG_2_SI:\n+    case MULTI_ARG_2_HI:\n+    case MULTI_ARG_2_QI:\n+      nargs = 2;\n+      break;\n+\n+    case MULTI_ARG_2_DI_IMM:\n+    case MULTI_ARG_2_SI_IMM:\n+    case MULTI_ARG_2_HI_IMM:\n+    case MULTI_ARG_2_QI_IMM:\n+      nargs = 2;\n+      last_arg_constant = true;\n+      break;\n+\n+    case MULTI_ARG_1_SF:\n+    case MULTI_ARG_1_DF:\n+    case MULTI_ARG_1_DI:\n+    case MULTI_ARG_1_SI:\n+    case MULTI_ARG_1_HI:\n+    case MULTI_ARG_1_QI:\n+    case MULTI_ARG_1_SI_DI:\n+    case MULTI_ARG_1_HI_DI:\n+    case MULTI_ARG_1_HI_SI:\n+    case MULTI_ARG_1_QI_DI:\n+    case MULTI_ARG_1_QI_SI:\n+    case MULTI_ARG_1_QI_HI:\n+    case MULTI_ARG_1_PH2PS:\n+    case MULTI_ARG_1_PS2PH:\n+      nargs = 1;\n+      break;\n+\n+    case MULTI_ARG_2_SF_CMP:\n+    case MULTI_ARG_2_DF_CMP:\n+    case MULTI_ARG_2_DI_CMP:\n+    case MULTI_ARG_2_SI_CMP:\n+    case MULTI_ARG_2_HI_CMP:\n+    case MULTI_ARG_2_QI_CMP:\n+      nargs = 2;\n+      comparison_p = true;\n+      break;\n+\n+    case MULTI_ARG_2_SF_TF:\n+    case MULTI_ARG_2_DF_TF:\n+    case MULTI_ARG_2_DI_TF:\n+    case MULTI_ARG_2_SI_TF:\n+    case MULTI_ARG_2_HI_TF:\n+    case MULTI_ARG_2_QI_TF:\n+      nargs = 2;\n+      tf_p = true;\n+      break;\n+\n+    case MULTI_ARG_UNKNOWN:\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  if (optimize || !target\n+      || GET_MODE (target) != tmode\n+      || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n+    target = gen_reg_rtx (tmode);\n+\n+  gcc_assert (nargs <= 4);\n+\n+  for (i = 0; i < nargs; i++)\n+    {\n+      tree arg = CALL_EXPR_ARG (exp, i);\n+      rtx op = expand_normal (arg);\n+      int adjust = (comparison_p) ? 1 : 0;\n+      enum machine_mode mode = insn_data[icode].operand[i+adjust+1].mode;\n+\n+      if (last_arg_constant && i == nargs-1)\n+\t{\n+\t  if (GET_CODE (op) != CONST_INT)\n+\t    {\n+\t      error (\"last argument must be an immediate\");\n+\t      return gen_reg_rtx (tmode);\n+\t    }\n+\t}\n+      else\n+\t{\n+\t  if (VECTOR_MODE_P (mode))\n+\t    op = safe_vector_operand (op, mode);\n+\n+\t  /* If we aren't optimizing, only allow one memory operand to be\n+\t     generated.  */\n+\t  if (memory_operand (op, mode))\n+\t    num_memory++;\n+\n+\t  gcc_assert (GET_MODE (op) == mode || GET_MODE (op) == VOIDmode);\n+\n+\t  if (optimize \n+\t      || ! (*insn_data[icode].operand[i+adjust+1].predicate) (op, mode)\n+\t      || num_memory > 1)\n+\t    op = force_reg (mode, op);\n+\t}\n+\n+      args[i].op = op;\n+      args[i].mode = mode;\n+    }\n+\n+  switch (nargs)\n+    {\n+    case 1:\n+      pat = GEN_FCN (icode) (target, args[0].op);\n+      break;\n+\n+    case 2:\n+      if (tf_p)\n+\tpat = GEN_FCN (icode) (target, args[0].op, args[1].op,\n+\t\t\t       GEN_INT ((int)sub_code));\n+      else if (! comparison_p)\n+\tpat = GEN_FCN (icode) (target, args[0].op, args[1].op);\n+      else\n+\t{\n+\t  rtx cmp_op = gen_rtx_fmt_ee (sub_code, GET_MODE (target),\n+\t\t\t\t       args[0].op,\n+\t\t\t\t       args[1].op);\n+\n+\t  pat = GEN_FCN (icode) (target, cmp_op, args[0].op, args[1].op);\n+\t}\n+      break;\n+\n+    case 3:\n+      pat = GEN_FCN (icode) (target, args[0].op, args[1].op, args[2].op);\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  if (! pat)\n+    return 0;\n+\n+  emit_insn (pat);\n+  return target;\n+}\n+\n /* Subroutine of ix86_expand_builtin to take care of stores.  */\n \n static rtx\n@@ -20086,6 +21173,12 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n     if (d->code == fcode)\n       return ix86_expand_sse_pcmpistr (d, exp, target);\n \n+  for (i = 0, d = bdesc_multi_arg; i < ARRAY_SIZE (bdesc_multi_arg); i++, d++)\n+    if (d->code == fcode)\n+      return ix86_expand_multi_arg_builtin (d->icode, exp, target,\n+\t\t\t\t\t    (enum multi_arg_type)d->flag,\n+\t\t\t\t\t    d->comparison);\n+\n   gcc_unreachable ();\n }\n \n@@ -21450,8 +22543,7 @@ x86_this_parameter (tree function)\n       return gen_rtx_REG (DImode, parm_regs[aggr]);\n     }\n \n-  if (ix86_function_regparm (type, function) > 0\n-      && !type_has_variadic_args_p (type))\n+  if (ix86_function_regparm (type, function) > 0 && !stdarg_p (type))\n     {\n       int regno = 0;\n       if (lookup_attribute (\"fastcall\", TYPE_ATTRIBUTES (type)))\n@@ -23743,6 +24835,179 @@ ix86_expand_round (rtx operand0, rtx operand1)\n   emit_move_insn (operand0, res);\n }\n \n+\f\n+/* Validate whether a SSE5 instruction is valid or not.\n+   OPERANDS is the array of operands.\n+   NUM is the number of operands.\n+   USES_OC0 is true if the instruction uses OC0 and provides 4 varients.\n+   NUM_MEMORY is the maximum number of memory operands to accept.  */\n+bool ix86_sse5_valid_op_p (rtx operands[], rtx insn, int num, bool uses_oc0, int num_memory)\n+{\n+  int mem_mask;\n+  int mem_count;\n+  int i;\n+\n+  /* Count the number of memory arguments */\n+  mem_mask = 0;\n+  mem_count = 0;\n+  for (i = 0; i < num; i++)\n+    {\n+      enum machine_mode mode = GET_MODE (operands[i]);\n+      if (register_operand (operands[i], mode))\n+\t;\n+\n+      else if (memory_operand (operands[i], mode))\n+\t{\n+\t  mem_mask |= (1 << i);\n+\t  mem_count++;\n+\t}\n+\n+      else\n+\t{\n+\t  rtx pattern = PATTERN (insn);\n+\n+\t  /* allow 0 for pcmov */\n+\t  if (GET_CODE (pattern) != SET\n+\t      || GET_CODE (SET_SRC (pattern)) != IF_THEN_ELSE\n+\t      || i < 2\n+\t      || operands[i] != CONST0_RTX (mode))\n+\t    return false;\n+\t}\n+    }\n+\n+  /* If there were no memory operations, allow the insn */\n+  if (mem_mask == 0)\n+    return true;\n+\n+  /* Do not allow the destination register to be a memory operand.  */\n+  else if (mem_mask & (1 << 0))\n+    return false;\n+\n+  /* If there are too many memory operations, disallow the instruction.  While\n+     the hardware only allows 1 memory reference, before register allocation\n+     for some insns, we allow two memory operations sometimes in order to allow\n+     code like the following to be optimized:\n+\n+\tfloat fmadd (float *a, float *b, float *c) { return (*a * *b) + *c; }\n+\n+    or similar cases that are vectorized into using the fmaddss\n+    instruction.  */\n+  else if (mem_count > num_memory)\n+    return false;\n+\n+  /* Don't allow more than one memory operation if not optimizing.  */\n+  else if (mem_count > 1 && !optimize)\n+    return false;\n+\n+  else if (num == 4 && mem_count == 1)\n+    {\n+      /* formats (destination is the first argument), example fmaddss:\n+\t xmm1, xmm1, xmm2, xmm3/mem\n+\t xmm1, xmm1, xmm2/mem, xmm3\n+\t xmm1, xmm2, xmm3/mem, xmm1\n+\t xmm1, xmm2/mem, xmm3, xmm1 */\n+      if (uses_oc0)\n+\treturn ((mem_mask == (1 << 1))\n+\t\t|| (mem_mask == (1 << 2))\n+\t\t|| (mem_mask == (1 << 3)));\n+\n+      /* format, example pmacsdd:\n+\t xmm1, xmm2, xmm3/mem, xmm1 */\n+      else\n+\treturn (mem_mask == (1 << 2));\n+    }\n+\n+  else if (num == 4 && num_memory == 2)\n+    {\n+      /* If there are two memory operations, we can load one of the memory ops\n+\t into the destination register.  This is for optimizating the\n+\t multiply/add ops, which the combiner has optimized both the multiply\n+\t and the add insns to have a memory operation.  We have to be careful\n+\t that the destination doesn't overlap with the inputs.  */\n+      rtx op0 = operands[0];\n+\n+      if (reg_mentioned_p (op0, operands[1])\n+\t  || reg_mentioned_p (op0, operands[2])\n+\t  || reg_mentioned_p (op0, operands[3]))\n+\treturn false;\n+\n+      /* formats (destination is the first argument), example fmaddss:\n+\t xmm1, xmm1, xmm2, xmm3/mem\n+\t xmm1, xmm1, xmm2/mem, xmm3\n+\t xmm1, xmm2, xmm3/mem, xmm1\n+\t xmm1, xmm2/mem, xmm3, xmm1\n+\n+         For the oc0 case, we will load either operands[1] or operands[3] into\n+         operands[0], so any combination of 2 memory operands is ok.  */\n+      if (uses_oc0)\n+\treturn true;\n+\n+      /* format, example pmacsdd:\n+\t xmm1, xmm2, xmm3/mem, xmm1\n+      \n+         For the integer multiply/add instructions be more restrictive and\n+         require operands[2] and operands[3] to be the memory operands.  */\n+      else\n+\treturn (mem_mask == ((1 << 2) | (1 << 3)));\n+    }\n+\n+  else if (num == 3 && num_memory == 1)\n+    {\n+      /* formats, example protb:\n+\t xmm1, xmm2, xmm3/mem\n+\t xmm1, xmm2/mem, xmm3 */\n+      if (uses_oc0)\n+\treturn ((mem_mask == (1 << 1)) || (mem_mask == (1 << 2)));\n+\n+      /* format, example comeq:\n+\t xmm1, xmm2, xmm3/mem */\n+      else\n+\treturn (mem_mask == (1 << 2));\n+    }\n+\n+  else\n+    gcc_unreachable ();\n+\n+  return false;\n+}\n+\n+\f\n+/* Fixup an SSE5 instruction that has 2 memory input references into a form the\n+   hardware will allow by using the destination register to load one of the\n+   memory operations.  Presently this is used by the multiply/add routines to\n+   allow 2 memory references.  */\n+\n+void\n+ix86_expand_sse5_multiple_memory (rtx operands[],\n+\t\t\t\t  int num,\n+\t\t\t\t  enum machine_mode mode)\n+{\n+  rtx op0 = operands[0];\n+  if (num != 4\n+      || memory_operand (op0, mode)\n+      || reg_mentioned_p (op0, operands[1])\n+      || reg_mentioned_p (op0, operands[2])\n+      || reg_mentioned_p (op0, operands[3]))\n+    gcc_unreachable ();\n+\n+  /* For 2 memory operands, pick either operands[1] or operands[3] to move into\n+     the destination register.  */\n+  if (memory_operand (operands[1], mode))\n+    {\n+      emit_move_insn (op0, operands[1]);\n+      operands[1] = op0;\n+    }\n+  else if (memory_operand (operands[3], mode))\n+    {\n+      emit_move_insn (op0, operands[3]);\n+      operands[3] = op0;\n+    }\n+  else\n+    gcc_unreachable ();\n+\n+  return;\n+}\n+\n \f\n /* Table of valid machine attributes.  */\n static const struct attribute_spec ix86_attribute_table[] ="}, {"sha": "cca89e30753999768e44314847bf080b8dbe6e40", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -47,6 +47,12 @@ along with GCC; see the file COPYING3.  If not see\n #define TARGET_SSE4_1\tOPTION_ISA_SSE4_1\n #define TARGET_SSE4_2\tOPTION_ISA_SSE4_2\n #define TARGET_SSE4A\tOPTION_ISA_SSE4A\n+#define TARGET_SSE5\tOPTION_ISA_SSE5\n+#define TARGET_ROUND\tOPTION_ISA_ROUND\n+\n+/* SSE5 and SSE4.1 define the same round instructions */\n+#define\tOPTION_MASK_ISA_ROUND\t(OPTION_MASK_ISA_SSE4_1 | OPTION_MASK_ISA_SSE5)\n+#define\tOPTION_ISA_ROUND\t((ix86_isa_flags & OPTION_MASK_ISA_ROUND) != 0)\n \n #include \"config/vxworks-dummy.h\"\n \n@@ -388,6 +394,7 @@ extern int x86_prefetch_sse;\n #define TARGET_PREFETCH_SSE\tx86_prefetch_sse\n #define TARGET_SAHF\t\tx86_sahf\n #define TARGET_RECIP\t\tx86_recip\n+#define TARGET_FUSED_MADD\tx86_fused_muladd\n \n #define ASSEMBLER_DIALECT\t(ix86_asm_dialect)\n \n@@ -601,6 +608,8 @@ extern const char *host_detect_local_cpu (int argc, const char **argv);\n \tbuiltin_define (\"__SSE4_2__\");\t\t\t\t\\\n       if (TARGET_SSE4A)\t\t\t\t\t\t\\\n  \tbuiltin_define (\"__SSE4A__\");\t\t                \\\n+      if (TARGET_SSE5)\t\t\t\t\t\t\\\n+\tbuiltin_define (\"__SSE5__\");\t\t\t\t\\\n       if (TARGET_SSE_MATH && TARGET_SSE)\t\t\t\\\n \tbuiltin_define (\"__SSE_MATH__\");\t\t\t\\\n       if (TARGET_SSE_MATH && TARGET_SSE2)\t\t\t\\"}, {"sha": "a0e0c8217050864850b26765b2129501cf2a7c51", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 71, "deletions": 23, "changes": 94, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -176,6 +176,17 @@\n    (UNSPEC_CRC32\t\t143)\n    (UNSPEC_PCMPESTR\t\t144)\n    (UNSPEC_PCMPISTR\t\t145)\n+\n+   ;; For SSE5\n+   (UNSPEC_SSE5_INTRINSIC\t150)\n+   (UNSPEC_SSE5_UNSIGNED_CMP\t151)\n+   (UNSPEC_SSE5_TRUEFALSE\t152)\n+   (UNSPEC_SSE5_PERMUTE\t\t153)\n+   (UNSPEC_SSE5_ASHIFT\t\t154)\n+   (UNSPEC_SSE5_LSHIFT\t\t155)\n+   (UNSPEC_FRCZ\t\t\t156)\n+   (UNSPEC_CVTPH2PS\t\t157)\n+   (UNSPEC_CVTPS2PH\t\t158)\n   ])\n \n (define_constants\n@@ -196,6 +207,16 @@\n    (UNSPECV_PROLOGUE_USE\t14)\n   ])\n \n+;; Constants to represent pcomtrue/pcomfalse varients\n+(define_constants\n+  [(PCOM_FALSE\t\t\t0)\n+   (PCOM_TRUE\t\t\t1)\n+   (COM_FALSE_S\t\t\t2)\n+   (COM_FALSE_P\t\t\t3)\n+   (COM_TRUE_S\t\t\t4)\n+   (COM_TRUE_P\t\t\t5)\n+  ])\n+\n ;; Registers by name.\n (define_constants\n   [(BP_REG\t\t\t 6)\n@@ -232,8 +253,9 @@\n    push,pop,call,callv,leave,\n    str,bitmanip,\n    fmov,fop,fsgn,fmul,fdiv,fpspc,fcmov,fcmp,fxch,fistp,fisttp,frndint,\n-   sselog,sselog1,sseiadd,sseishft,sseimul,\n-   sse,ssemov,sseadd,ssemul,ssecmp,ssecomi,ssecvt,sseicvt,ssediv,sseins,\n+   sselog,sselog1,sseiadd,sseiadd1,sseishft,sseimul,\n+   sse,ssemov,sseadd,ssemul,ssecmp,ssecomi,ssecvt,ssecvt1,sseicvt,ssediv,sseins,\n+   ssemuladd,sse4arg,\n    mmx,mmxmov,mmxadd,mmxmul,mmxcmp,mmxcvt,mmxshft\"\n   (const_string \"other\"))\n \n@@ -246,8 +268,9 @@\n (define_attr \"unit\" \"integer,i387,sse,mmx,unknown\"\n   (cond [(eq_attr \"type\" \"fmov,fop,fsgn,fmul,fdiv,fpspc,fcmov,fcmp,fxch,fistp,fisttp,frndint\")\n \t   (const_string \"i387\")\n-\t (eq_attr \"type\" \"sselog,sselog1,sseiadd,sseishft,sseimul,\n-\t\t\t  sse,ssemov,sseadd,ssemul,ssecmp,ssecomi,ssecvt,sseicvt,ssediv,sseins\")\n+\t (eq_attr \"type\" \"sselog,sselog1,sseiadd,sseiadd1,sseishft,sseimul,\n+\t\t\t  sse,ssemov,sseadd,ssemul,ssecmp,ssecomi,ssecvt,\n+\t\t\t  ssecvt1,sseicvt,ssediv,sseins,ssemuladd,sse4arg\")\n \t   (const_string \"sse\")\n \t (eq_attr \"type\" \"mmx,mmxmov,mmxadd,mmxmul,mmxcmp,mmxcvt,mmxshft\")\n \t   (const_string \"mmx\")\n@@ -447,11 +470,11 @@\n \t\t \"!alu1,negnot,ishift1,\n \t\t   imov,imovx,icmp,test,bitmanip,\n \t\t   fmov,fcmp,fsgn,\n-\t\t   sse,ssemov,ssecmp,ssecomi,ssecvt,sseicvt,sselog1,\n-\t\t   mmx,mmxmov,mmxcmp,mmxcvt\")\n+\t\t   sse,ssemov,ssecmp,ssecomi,ssecvt,ssecvt1,sseicvt,sselog1,\n+\t\t   sseiadd1,mmx,mmxmov,mmxcmp,mmxcvt\")\n \t      (match_operand 2 \"memory_operand\" \"\"))\n \t   (const_string \"load\")\n-\t (and (eq_attr \"type\" \"icmov\")\n+\t (and (eq_attr \"type\" \"icmov,ssemuladd,sse4arg\")\n \t      (match_operand 3 \"memory_operand\" \"\"))\n \t   (const_string \"load\")\n \t]\n@@ -7662,7 +7685,7 @@\n      (if_then_else (eq_attr \"cpu\" \"athlon\")\n         (const_string \"vector\")\n         (const_string \"direct\")))\n-   (set_attr \"amdfam10_decode\" \"direct\")        \n+   (set_attr \"amdfam10_decode\" \"direct\")\n    (set_attr \"mode\" \"QI\")])\n \n (define_expand \"mulqihi3\"\n@@ -8003,6 +8026,9 @@\n \t\t    (match_operand:MODEF 2 \"nonimmediate_operand\" \"\")))]\n   \"TARGET_80387 || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH)\"\n   \"\")\n+\n+;; SSE5 scalar multiply/add instructions are defined in sse.md.\n+\n \f\n ;; Divide instructions\n \n@@ -14059,7 +14085,7 @@\n \t(match_operator:SF 1 \"sse_comparison_operator\"\n \t  [(match_operand:SF 2 \"register_operand\" \"0\")\n \t   (match_operand:SF 3 \"nonimmediate_operand\" \"xm\")]))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && !TARGET_SSE5\"\n   \"cmp%D1ss\\t{%3, %0|%0, %3}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"SF\")])\n@@ -14069,10 +14095,21 @@\n \t(match_operator:DF 1 \"sse_comparison_operator\"\n \t  [(match_operand:DF 2 \"register_operand\" \"0\")\n \t   (match_operand:DF 3 \"nonimmediate_operand\" \"xm\")]))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && !TARGET_SSE5\"\n   \"cmp%D1sd\\t{%3, %0|%0, %3}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"DF\")])\n+\n+(define_insn \"*sse5_setcc<mode>\"\n+  [(set (match_operand:MODEF 0 \"register_operand\" \"=x\")\n+\t(match_operator:MODEF 1 \"sse5_comparison_float_operator\"\n+\t  [(match_operand:MODEF 2 \"register_operand\" \"x\")\n+\t   (match_operand:MODEF 3 \"nonimmediate_operand\" \"xm\")]))]\n+  \"TARGET_SSE5\"\n+  \"com%Y1ss\\t{%3, %2, %0|%0, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n \f\n ;; Basic conditional jump instructions.\n ;; We ignore the overflow flag for signed branch instructions.\n@@ -17645,7 +17682,7 @@\n \t(unspec:MODEF [(match_operand:MODEF 1 \"register_operand\" \"x\")\n \t\t       (match_operand:SI 2 \"const_0_to_15_operand\" \"n\")]\n \t\t      UNSPEC_ROUND))]\n-  \"TARGET_SSE4_1\"\n+  \"TARGET_ROUND\"\n   \"rounds<ssemodefsuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -17670,13 +17707,13 @@\n     && flag_unsafe_math_optimizations)\n    || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n        && !flag_trapping_math\n-       && (TARGET_SSE4_1 || !optimize_size))\"\n+       && (TARGET_ROUND || !optimize_size))\"\n {\n   if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n       && !flag_trapping_math\n-      && (TARGET_SSE4_1 || !optimize_size))\n+      && (TARGET_ROUND || !optimize_size))\n     {\n-      if (TARGET_SSE4_1)\n+      if (TARGET_ROUND)\n \temit_insn (gen_sse4_1_round<mode>2\n \t\t   (operands[0], operands[1], GEN_INT (0x04)));\n       else\n@@ -17917,13 +17954,13 @@\n     && flag_unsafe_math_optimizations && !optimize_size)\n    || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n        && !flag_trapping_math\n-       && (TARGET_SSE4_1 || !optimize_size))\"\n+       && (TARGET_ROUND || !optimize_size))\"\n {\n   if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n       && !flag_trapping_math\n-      && (TARGET_SSE4_1 || !optimize_size))\n+      && (TARGET_ROUND || !optimize_size))\n     {\n-      if (TARGET_SSE4_1)\n+      if (TARGET_ROUND)\n \temit_insn (gen_sse4_1_round<mode>2\n \t\t   (operands[0], operands[1], GEN_INT (0x01)));\n       else if (TARGET_64BIT || (<MODE>mode != DFmode))\n@@ -18182,13 +18219,13 @@\n     && flag_unsafe_math_optimizations && !optimize_size)\n    || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n        && !flag_trapping_math\n-       && (TARGET_SSE4_1 || !optimize_size))\"\n+       && (TARGET_ROUND || !optimize_size))\"\n {\n   if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n       && !flag_trapping_math\n-      && (TARGET_SSE4_1 || !optimize_size))\n+      && (TARGET_ROUND || !optimize_size))\n     {\n-      if (TARGET_SSE4_1)\n+      if (TARGET_ROUND)\n \temit_insn (gen_sse4_1_round<mode>2\n \t\t   (operands[0], operands[1], GEN_INT (0x02)));\n       else if (TARGET_64BIT || (<MODE>mode != DFmode))\n@@ -18445,13 +18482,13 @@\n     && flag_unsafe_math_optimizations && !optimize_size)\n    || (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n        && !flag_trapping_math\n-       && (TARGET_SSE4_1 || !optimize_size))\"\n+       && (TARGET_ROUND || !optimize_size))\"\n {\n   if (SSE_FLOAT_MODE_P (<MODE>mode) && TARGET_SSE_MATH\n       && !flag_trapping_math\n-      && (TARGET_SSE4_1 || !optimize_size))\n+      && (TARGET_ROUND || !optimize_size))\n     {\n-      if (TARGET_SSE4_1)\n+      if (TARGET_ROUND)\n \temit_insn (gen_sse4_1_round<mode>2\n \t\t   (operands[0], operands[1], GEN_INT (0x03)));\n       else if (TARGET_64BIT || (<MODE>mode != DFmode))\n@@ -19677,6 +19714,17 @@\n   [(set_attr \"type\" \"fcmov\")\n    (set_attr \"mode\" \"XF\")])\n \n+;; SSE5 conditional move\n+(define_insn \"*sse5_pcmov_<mode>\"\n+  [(set (match_operand:MODEF 0 \"register_operand\" \"=x,x,x,x\")\n+\t(if_then_else:MODEF \n+\t  (match_operand:MODEF 1 \"nonimmediate_operand\" \"xm,x,0,0\")\n+\t  (match_operand:MODEF 2 \"nonimmediate_operand\" \"0,0,x,xm\")\n+\t  (match_operand:MODEF 3 \"vector_move_operand\" \"x,xm,xm,x\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"pcmov\\t{%1, %3, %2, %0|%0, %2, %3, %1}\"\n+  [(set_attr \"type\" \"sse4arg\")])\n+\n ;; These versions of the min/max patterns are intentionally ignorant of\n ;; their behavior wrt -0.0 and NaN (via the commutative operand mark).\n ;; Since both the tree-level MAX_EXPR and the rtl-level SMAX operator"}, {"sha": "69d57bd9fa113765a656dc58cfee4f603f4ef170", "filename": "gcc/config/i386/i386.opt", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fi386.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.opt?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -244,6 +244,10 @@ msse4a\n Target Report Mask(ISA_SSE4A) Var(ix86_isa_flags) VarExists\n Support MMX, SSE, SSE2, SSE3 and SSE4A built-in functions and code generation\n \n+msse5\n+Target Report Mask(ISA_SSE5) Var(ix86_isa_flags) VarExists\n+Support SSE5 built-in functions and code generation\n+\n ;; Instruction support\n \n mabm\n@@ -265,3 +269,9 @@ Support code generation of sahf instruction in 64bit x86-64 code.\n mrecip\n Target Report RejectNegative Var(x86_recip)\n Generate reciprocals instead of divss and sqrtss.\n+\n+mfused-madd\n+Target Report Var(x86_fused_muladd) Init(1)\n+Enable automatic generation of fused floating point multiply-add instructions\n+if the ISA supports such instructions.  The -mfused-madd option is on by\n+default."}, {"sha": "02721f5f07c6611da46e37096d908b6ed2d58fbf", "filename": "gcc/config/i386/mmintrin-common.h", "status": "added", "additions": 156, "deletions": 0, "changes": 156, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fmmintrin-common.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fmmintrin-common.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fmmintrin-common.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,156 @@\n+/* Copyright (C) 2007 Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify\n+   it under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 2, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING.  If not, write to\n+   the Free Software Foundation, 51 Franklin Street, Fifth Floor,\n+   Boston, MA 02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source\n+   files compiled by GCC, this header file does not by itself cause\n+   the resulting executable to be covered by the GNU General Public\n+   License.  This exception does not however invalidate any other\n+   reasons why the executable file might be covered by the GNU General\n+   Public License.  */\n+\n+/* Common definition of the ROUND and PTEST intrinsics that are shared\n+   between SSE4.1 and SSE5.  */\n+\n+#ifndef _MMINTRIN_COMMON_H_INCLUDED\n+#define _MMINTRIN_COMMON_H_INCLUDED\n+\n+#if !defined(__SSE5__) && !defined(__SSE4_1__)\n+# error \"SSE5 or SSE4.1 instruction set not enabled\"\n+#else\n+\n+/* Rounding mode macros. */\n+#define _MM_FROUND_TO_NEAREST_INT\t0x00\n+#define _MM_FROUND_TO_NEG_INF\t\t0x01\n+#define _MM_FROUND_TO_POS_INF\t\t0x02\n+#define _MM_FROUND_TO_ZERO\t\t0x03\n+#define _MM_FROUND_CUR_DIRECTION\t0x04\n+\n+#define _MM_FROUND_RAISE_EXC\t\t0x00\n+#define _MM_FROUND_NO_EXC\t\t0x08\n+\n+#define _MM_FROUND_NINT\t\t\\\n+  (_MM_FROUND_TO_NEAREST_INT | _MM_FROUND_RAISE_EXC)\n+#define _MM_FROUND_FLOOR\t\\\n+  (_MM_FROUND_TO_NEG_INF | _MM_FROUND_RAISE_EXC)\n+#define _MM_FROUND_CEIL\t\t\\\n+  (_MM_FROUND_TO_POS_INF | _MM_FROUND_RAISE_EXC)\n+#define _MM_FROUND_TRUNC\t\\\n+  (_MM_FROUND_TO_ZERO | _MM_FROUND_RAISE_EXC)\n+#define _MM_FROUND_RINT\t\t\\\n+  (_MM_FROUND_CUR_DIRECTION | _MM_FROUND_RAISE_EXC)\n+#define _MM_FROUND_NEARBYINT\t\\\n+  (_MM_FROUND_CUR_DIRECTION | _MM_FROUND_NO_EXC)\n+\n+/* Test Instruction */\n+/* Packed integer 128-bit bitwise comparison. Return 1 if\n+   (__V & __M) == 0.  */\n+static __inline int __attribute__((__always_inline__))\n+_mm_testz_si128 (__m128i __M, __m128i __V)\n+{\n+  return __builtin_ia32_ptestz128 ((__v2di)__M, (__v2di)__V);\n+}\n+\n+/* Packed integer 128-bit bitwise comparison. Return 1 if\n+   (__V & ~__M) == 0.  */\n+static __inline int __attribute__((__always_inline__))\n+_mm_testc_si128 (__m128i __M, __m128i __V)\n+{\n+  return __builtin_ia32_ptestc128 ((__v2di)__M, (__v2di)__V);\n+}\n+\n+/* Packed integer 128-bit bitwise comparison. Return 1 if\n+   (__V & __M) != 0 && (__V & ~__M) != 0.  */\n+static __inline int __attribute__((__always_inline__))\n+_mm_testnzc_si128 (__m128i __M, __m128i __V)\n+{\n+  return __builtin_ia32_ptestnzc128 ((__v2di)__M, (__v2di)__V);\n+}\n+\n+/* Macros for packed integer 128-bit comparison intrinsics.  */\n+#define _mm_test_all_zeros(M, V) _mm_testz_si128 ((M), (V))\n+\n+#define _mm_test_all_ones(V) \\\n+  _mm_testc_si128 ((V), _mm_cmpeq_epi32 ((V), (V)))\n+\n+#define _mm_test_mix_ones_zeros(M, V) _mm_testnzc_si128 ((M), (V))\n+\n+/* Packed/scalar double precision floating point rounding.  */\n+\n+#ifdef __OPTIMIZE__\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_round_pd (__m128d __V, const int __M)\n+{\n+  return (__m128d) __builtin_ia32_roundpd ((__v2df)__V, __M);\n+}\n+\n+static __inline __m128d __attribute__((__always_inline__))\n+_mm_round_sd(__m128d __D, __m128d __V, const int __M)\n+{\n+  return (__m128d) __builtin_ia32_roundsd ((__v2df)__D,\n+\t\t\t\t\t   (__v2df)__V,\n+\t\t\t\t\t   __M);\n+}\n+#else\n+#define _mm_round_pd(V, M) \\\n+  ((__m128d) __builtin_ia32_roundpd ((__v2df)(V), (M)))\n+\n+#define _mm_round_sd(D, V, M) \\\n+  ((__m128d) __builtin_ia32_roundsd ((__v2df)(D), (__v2df)(V), (M)))\n+#endif\n+\n+/* Packed/scalar single precision floating point rounding.  */\n+\n+#ifdef __OPTIMIZE__\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_round_ps (__m128 __V, const int __M)\n+{\n+  return (__m128) __builtin_ia32_roundps ((__v4sf)__V, __M);\n+}\n+\n+static __inline __m128 __attribute__((__always_inline__))\n+_mm_round_ss (__m128 __D, __m128 __V, const int __M)\n+{\n+  return (__m128) __builtin_ia32_roundss ((__v4sf)__D,\n+\t\t\t\t\t  (__v4sf)__V,\n+\t\t\t\t\t  __M);\n+}\n+#else\n+#define _mm_round_ps(V, M) \\\n+  ((__m128) __builtin_ia32_roundps ((__v4sf)(V), (M)))\n+\n+#define _mm_round_ss(D, V, M) \\\n+  ((__m128) __builtin_ia32_roundss ((__v4sf)(D), (__v4sf)(V), (M)))\n+#endif\n+\n+/* Macros for ceil/floor intrinsics.  */\n+#define _mm_ceil_pd(V)\t   _mm_round_pd ((V), _MM_FROUND_CEIL)\n+#define _mm_ceil_sd(D, V)  _mm_round_sd ((D), (V), _MM_FROUND_CEIL)\n+\n+#define _mm_floor_pd(V)\t   _mm_round_pd((V), _MM_FROUND_FLOOR)\n+#define _mm_floor_sd(D, V) _mm_round_sd ((D), (V), _MM_FROUND_FLOOR)\n+\n+#define _mm_ceil_ps(V)\t   _mm_round_ps ((V), _MM_FROUND_CEIL)\n+#define _mm_ceil_ss(D, V)  _mm_round_ss ((D), (V), _MM_FROUND_CEIL)\n+\n+#define _mm_floor_ps(V)\t   _mm_round_ps ((V), _MM_FROUND_FLOOR)\n+#define _mm_floor_ss(D, V) _mm_round_ss ((D), (V), _MM_FROUND_FLOOR)\n+\n+#endif /* __SSE5__/__SSE4_1__ */\n+\n+#endif /* _MMINTRIN_COMMON_H_INCLUDED */"}, {"sha": "0357baff1692123c0b4b77064372804699716c50", "filename": "gcc/config/i386/netware.c", "status": "modified", "additions": 28, "deletions": 18, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fnetware.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fnetware.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fnetware.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -45,30 +45,36 @@ gen_stdcall_or_fastcall_decoration (tree decl, char prefix)\n      of DECL_ASSEMBLER_NAME.  */\n   const char *asmname = IDENTIFIER_POINTER (DECL_ASSEMBLER_NAME (decl));\n   char *newsym;\n-  tree formal_type = TYPE_ARG_TYPES (TREE_TYPE (decl));\n+  tree type = TREE_TYPE (decl);\n+  tree arg;\n+  function_args_iterator args_iter;\n \n-  if (formal_type != NULL_TREE)\n+  if (prototype_p (type))\n     {\n       /* These attributes are ignored for variadic functions in\n \t i386.c:ix86_return_pops_args. For compatibility with MS\n \t compiler do not add @0 suffix here.  */ \n-      if (TREE_VALUE (tree_last (formal_type)) != void_type_node)\n+      if (stdarg_p (type))\n \treturn NULL_TREE;\n \n       /* Quit if we hit an incomplete type.  Error is reported\n \t by convert_arguments in c-typeck.c or cp/typeck.c.  */\n-      while (TREE_VALUE (formal_type) != void_type_node\n-\t     && COMPLETE_TYPE_P (TREE_VALUE (formal_type)))\t\n+      FOREACH_FUNCTION_ARGS(type, arg, args_iter)\n \t{\n-\t  unsigned parm_size\n-\t    = TREE_INT_CST_LOW (TYPE_SIZE (TREE_VALUE (formal_type)));\n+\t  unsigned parm_size;\n+\n+\t  if (! COMPLETE_TYPE_P (arg))\n+\t    break;\n+\n+\t  parm_size = int_size_in_bytes (TYPE_SIZE (arg));\n+\t  if (parm_size < 0)\n+\t    break;\n \n \t  /* Must round up to include padding.  This is done the same\n \t     way as in store_one_arg.  */\n \t  parm_size = ((parm_size + PARM_BOUNDARY - 1)\n \t\t       / PARM_BOUNDARY * PARM_BOUNDARY);\n \t  total += parm_size;\n-\t  formal_type = TREE_CHAIN (formal_type);\n \t}\n     }\n \n@@ -93,28 +99,32 @@ gen_regparm_prefix (tree decl, unsigned nregs)\n      of DECL_ASSEMBLER_NAME.  */\n   const char *asmname = IDENTIFIER_POINTER (DECL_ASSEMBLER_NAME (decl));\n   char *newsym;\n-  tree formal_type = TYPE_ARG_TYPES (TREE_TYPE (decl));\n+  tree type = TREE_TYPE (decl);\n+  tree arg;\n+  function_args_iterator args_iter;\n \n-  if (formal_type != NULL_TREE)\n+  if (prototype_p (type))\n     {\n       /* This attribute is ignored for variadic functions.  */ \n-      if (TREE_VALUE (tree_last (formal_type)) != void_type_node)\n+      if (stdarg_p (type))\n \treturn NULL_TREE;\n \n       /* Quit if we hit an incomplete type.  Error is reported\n \t by convert_arguments in c-typeck.c or cp/typeck.c.  */\n-      while (TREE_VALUE (formal_type) != void_type_node\n-\t     && COMPLETE_TYPE_P (TREE_VALUE (formal_type)))\t\n+      FOREACH_FUNCTION_ARGS(type, arg, args_iter)\n \t{\n-\t  unsigned parm_size\n-\t    = TREE_INT_CST_LOW (TYPE_SIZE (TREE_VALUE (formal_type)));\n+\t  unsigned parm_size;\n+\n+\t  if (! COMPLETE_TYPE_P (arg))\n+\t    break;\n+\n+\t  parm_size = int_size_in_bytes (arg);\n+\t  if (parm_size < 0)\n+\t    break;\n \n-\t  /* Must round up to include padding.  This is done the same\n-\t     way as in store_one_arg.  */\n \t  parm_size = ((parm_size + PARM_BOUNDARY - 1)\n \t\t       / PARM_BOUNDARY * PARM_BOUNDARY);\n \t  total += parm_size;\n-\t  formal_type = TREE_CHAIN (formal_type);\n \t}\n     }\n "}, {"sha": "7ba7289922496149b787f078bd3c994487b77118", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -600,6 +600,11 @@\n   (and (match_code \"const_int\")\n        (match_test \"IN_RANGE (INTVAL (op), 0, 15)\")))\n \n+;; Match 0 to 31.\n+(define_predicate \"const_0_to_31_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"IN_RANGE (INTVAL (op), 0, 31)\")))\n+\n ;; Match 0 to 63.\n (define_predicate \"const_0_to_63_operand\"\n   (and (match_code \"const_int\")\n@@ -903,6 +908,18 @@\n (define_special_predicate \"sse_comparison_operator\"\n   (match_code \"eq,lt,le,unordered,ne,unge,ungt,ordered\"))\n \n+;; Return 1 if OP is a comparison operator that can be issued by sse predicate\n+;; generation instructions\n+(define_predicate \"sse5_comparison_float_operator\"\n+  (and (match_test \"TARGET_SSE5\")\n+       (match_code \"ne,eq,ge,gt,le,lt,unordered,ordered,uneq,unge,ungt,unle,unlt,ltgt\")))\n+\n+(define_predicate \"ix86_comparison_int_operator\"\n+  (match_code \"ne,eq,ge,gt,le,lt\"))\n+\n+(define_predicate \"ix86_comparison_uns_operator\"\n+  (match_code \"ne,eq,geu,gtu,leu,ltu\"))\n+\n ;; Return 1 if OP is a valid comparison operator in valid mode.\n (define_predicate \"ix86_comparison_operator\"\n   (match_operand 0 \"comparison_operator\")"}, {"sha": "fc20d1cf99078e74cbb1af820e2ef7b10b0f6f3f", "filename": "gcc/config/i386/smmintrin.h", "status": "modified", "additions": 1, "deletions": 116, "changes": 117, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fsmmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fsmmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsmmintrin.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -37,32 +37,10 @@\n /* We need definitions from the SSSE3, SSE3, SSE2 and SSE header\n    files.  */\n #include <tmmintrin.h>\n+#include <mmintrin-common.h>\n \n /* SSE4.1 */\n \n-/* Rounding mode macros. */\n-#define _MM_FROUND_TO_NEAREST_INT\t0x00\n-#define _MM_FROUND_TO_NEG_INF\t\t0x01\n-#define _MM_FROUND_TO_POS_INF\t\t0x02\n-#define _MM_FROUND_TO_ZERO\t\t0x03\n-#define _MM_FROUND_CUR_DIRECTION\t0x04\n-\n-#define _MM_FROUND_RAISE_EXC\t\t0x00\n-#define _MM_FROUND_NO_EXC\t\t0x08\n-\n-#define _MM_FROUND_NINT\t\t\\\n-  (_MM_FROUND_TO_NEAREST_INT | _MM_FROUND_RAISE_EXC)\n-#define _MM_FROUND_FLOOR\t\\\n-  (_MM_FROUND_TO_NEG_INF | _MM_FROUND_RAISE_EXC)\n-#define _MM_FROUND_CEIL\t\t\\\n-  (_MM_FROUND_TO_POS_INF | _MM_FROUND_RAISE_EXC)\n-#define _MM_FROUND_TRUNC\t\\\n-  (_MM_FROUND_TO_ZERO | _MM_FROUND_RAISE_EXC)\n-#define _MM_FROUND_RINT\t\t\\\n-  (_MM_FROUND_CUR_DIRECTION | _MM_FROUND_RAISE_EXC)\n-#define _MM_FROUND_NEARBYINT\t\\\n-  (_MM_FROUND_CUR_DIRECTION | _MM_FROUND_NO_EXC)\n-\n /* Integer blend instructions - select data from 2 sources using\n    constant/variable mask.  */\n \n@@ -236,38 +214,6 @@ _mm_mul_epi32 (__m128i __X, __m128i __Y)\n   return (__m128i) __builtin_ia32_pmuldq128 ((__v4si)__X, (__v4si)__Y);\n }\n \n-/* Packed integer 128-bit bitwise comparison. Return 1 if\n-   (__V & __M) == 0.  */\n-static __inline int __attribute__((__always_inline__))\n-_mm_testz_si128 (__m128i __M, __m128i __V)\n-{\n-  return __builtin_ia32_ptestz128 ((__v2di)__M, (__v2di)__V);\n-}\n-\n-/* Packed integer 128-bit bitwise comparison. Return 1 if\n-   (__V & ~__M) == 0.  */\n-static __inline int __attribute__((__always_inline__))\n-_mm_testc_si128 (__m128i __M, __m128i __V)\n-{\n-  return __builtin_ia32_ptestc128 ((__v2di)__M, (__v2di)__V);\n-}\n-\n-/* Packed integer 128-bit bitwise comparison. Return 1 if\n-   (__V & __M) != 0 && (__V & ~__M) != 0.  */\n-static __inline int __attribute__((__always_inline__))\n-_mm_testnzc_si128 (__m128i __M, __m128i __V)\n-{\n-  return __builtin_ia32_ptestnzc128 ((__v2di)__M, (__v2di)__V);\n-}\n-\n-/* Macros for packed integer 128-bit comparison intrinsics.  */\n-#define _mm_test_all_zeros(M, V) _mm_testz_si128 ((M), (V))\n-\n-#define _mm_test_all_ones(V) \\\n-  _mm_testc_si128 ((V), _mm_cmpeq_epi32 ((V), (V)))\n-\n-#define _mm_test_mix_ones_zeros(M, V) _mm_testnzc_si128 ((M), (V))\n-\n /* Insert single precision float into packed single precision array\n    element selected by index N.  The bits [7-6] of N define S\n    index, the bits [5-4] define D index, and bits [3-0] define\n@@ -405,67 +351,6 @@ _mm_minpos_epu16 (__m128i __X)\n   return (__m128i) __builtin_ia32_phminposuw128 ((__v8hi)__X);\n }\n \n-/* Packed/scalar double precision floating point rounding.  */\n-\n-#ifdef __OPTIMIZE__\n-static __inline __m128d __attribute__((__always_inline__))\n-_mm_round_pd (__m128d __V, const int __M)\n-{\n-  return (__m128d) __builtin_ia32_roundpd ((__v2df)__V, __M);\n-}\n-\n-static __inline __m128d __attribute__((__always_inline__))\n-_mm_round_sd(__m128d __D, __m128d __V, const int __M)\n-{\n-  return (__m128d) __builtin_ia32_roundsd ((__v2df)__D,\n-\t\t\t\t\t   (__v2df)__V,\n-\t\t\t\t\t   __M);\n-}\n-#else\n-#define _mm_round_pd(V, M) \\\n-  ((__m128d) __builtin_ia32_roundpd ((__v2df)(V), (M)))\n-\n-#define _mm_round_sd(D, V, M) \\\n-  ((__m128d) __builtin_ia32_roundsd ((__v2df)(D), (__v2df)(V), (M)))\n-#endif\n-\n-/* Packed/scalar single precision floating point rounding.  */\n-\n-#ifdef __OPTIMIZE__\n-static __inline __m128 __attribute__((__always_inline__))\n-_mm_round_ps (__m128 __V, const int __M)\n-{\n-  return (__m128) __builtin_ia32_roundps ((__v4sf)__V, __M);\n-}\n-\n-static __inline __m128 __attribute__((__always_inline__))\n-_mm_round_ss (__m128 __D, __m128 __V, const int __M)\n-{\n-  return (__m128) __builtin_ia32_roundss ((__v4sf)__D,\n-\t\t\t\t\t  (__v4sf)__V,\n-\t\t\t\t\t  __M);\n-}\n-#else\n-#define _mm_round_ps(V, M) \\\n-  ((__m128) __builtin_ia32_roundps ((__v4sf)(V), (M)))\n-\n-#define _mm_round_ss(D, V, M) \\\n-  ((__m128) __builtin_ia32_roundss ((__v4sf)(D), (__v4sf)(V), (M)))\n-#endif\n-\n-/* Macros for ceil/floor intrinsics.  */\n-#define _mm_ceil_pd(V)\t   _mm_round_pd ((V), _MM_FROUND_CEIL)\n-#define _mm_ceil_sd(D, V)  _mm_round_sd ((D), (V), _MM_FROUND_CEIL)\n-\n-#define _mm_floor_pd(V)\t   _mm_round_pd((V), _MM_FROUND_FLOOR)\n-#define _mm_floor_sd(D, V) _mm_round_sd ((D), (V), _MM_FROUND_FLOOR)\n-\n-#define _mm_ceil_ps(V)\t   _mm_round_ps ((V), _MM_FROUND_CEIL)\n-#define _mm_ceil_ss(D, V)  _mm_round_ss ((D), (V), _MM_FROUND_CEIL)\n-\n-#define _mm_floor_ps(V)\t   _mm_round_ps ((V), _MM_FROUND_FLOOR)\n-#define _mm_floor_ss(D, V) _mm_round_ss ((D), (V), _MM_FROUND_FLOOR)\n-\n /* Packed integer sign-extension.  */\n \n static __inline __m128i __attribute__((__always_inline__))"}, {"sha": "e92ac733c994ae6e91e66b7614aa734b03d8384e", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 1850, "deletions": 15, "changes": 1865, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -32,10 +32,24 @@\n (define_mode_iterator SSEMODE14 [V16QI V4SI])\n (define_mode_iterator SSEMODE124 [V16QI V8HI V4SI])\n (define_mode_iterator SSEMODE248 [V8HI V4SI V2DI])\n+(define_mode_iterator SSEMODE1248 [V16QI V8HI V4SI V2DI])\n+(define_mode_iterator SSEMODEF4 [SF DF V4SF V2DF])\n+(define_mode_iterator SSEMODEF2P [V4SF V2DF])\n \n ;; Mapping from integer vector mode to mnemonic suffix\n (define_mode_attr ssevecsize [(V16QI \"b\") (V8HI \"w\") (V4SI \"d\") (V2DI \"q\")])\n \n+;; Mapping of the sse5 suffix\n+(define_mode_attr ssemodesuffixf4 [(SF \"ss\") (DF \"sd\") (V4SF \"ps\") (V2DF \"pd\")])\n+(define_mode_attr ssemodesuffixf2s [(SF \"ss\") (DF \"sd\") (V4SF \"ss\") (V2DF \"sd\")])\n+(define_mode_attr ssemodesuffixf2c [(V4SF \"s\") (V2DF \"d\")])\n+\n+;; Mapping of the max integer size for sse5 rotate immediate constraint\n+(define_mode_attr sserotatemax [(V16QI \"7\") (V8HI \"15\") (V4SI \"31\") (V2DI \"63\")])\n+\n+;; Mapping of vector modes back to the scalar modes\n+(define_mode_attr ssescalarmode [(V4SF \"SF\") (V2DF \"DF\")])\n+\n ;; Patterns whose name begins with \"sse{,2,3}_\" are invoked by intrinsics.\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n@@ -834,7 +848,7 @@\n \t(match_operator:V4SF 3 \"sse_comparison_operator\"\n \t\t[(match_operand:V4SF 1 \"register_operand\" \"0\")\n \t\t (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\")]))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && !TARGET_SSE5\"\n   \"cmp%D3ps\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"V4SF\")])\n@@ -844,7 +858,7 @@\n \t(match_operator:SF 3 \"sse_comparison_operator\"\n \t\t[(match_operand:SF 1 \"register_operand\" \"0\")\n \t\t (match_operand:SF 2 \"nonimmediate_operand\" \"xm\")]))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && !TARGET_SSE5\"\n   \"cmp%D3ss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"SF\")])\n@@ -857,7 +871,7 @@\n \t\t (match_operand:V4SF 2 \"register_operand\" \"x\")])\n \t (match_dup 1)\n \t (const_int 1)))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && !TARGET_SSE5\"\n   \"cmp%D3ss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"SF\")])\n@@ -1569,6 +1583,563 @@\n   DONE;\n })\n \n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;;\n+;; SSE5 floating point multiply/accumulate instructions This includes the\n+;; scalar version of the instructions as well as the vector\n+;;\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; In order to match (*a * *b) + *c, particularly when vectorizing, allow\n+;; combine to generate a multiply/add with two memory references.  We then\n+;; split this insn, into loading up the destination register with one of the\n+;; memory operations.  If we don't manage to split the insn, reload will\n+;; generate the appropriate moves.  The reason this is needed, is that combine\n+;; has already folded one of the memory references into both the multiply and\n+;; add insns, and it can't generate a new pseudo.  I.e.:\n+;;\t(set (reg1) (mem (addr1)))\n+;;\t(set (reg2) (mult (reg1) (mem (addr2))))\n+;;\t(set (reg3) (plus (reg2) (mem (addr3))))\n+\n+(define_insn \"sse5_fmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x,x,x\")\n+\t(plus:SSEMODEF4\n+\t (mult:SSEMODEF4\n+\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"%0,0,x,xm\")\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,xm,xm,x\"))\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x,0,0\")))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\"\n+  \"fmadd<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Split fmadd with two memory operands into a load and the fmadd.\n+(define_split\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"\")\n+\t(plus:SSEMODEF4\n+\t (mult:SSEMODEF4\n+\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"\")\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"\"))\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"\")))]\n+  \"TARGET_SSE5\n+   && !ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\n+   && !reg_mentioned_p (operands[0], operands[1])\n+   && !reg_mentioned_p (operands[0], operands[2])\n+   && !reg_mentioned_p (operands[0], operands[3])\"\n+  [(const_int 0)]\n+{\n+  ix86_expand_sse5_multiple_memory (operands, 4, <MODE>mode);\n+  emit_insn (gen_sse5_fmadd<mode>4 (operands[0], operands[1],\n+\t\t\t\t    operands[2], operands[3]));\n+  DONE;\n+})\n+\n+;; For the scalar operations, use operand1 for the upper words that aren't\n+;; modified, so restrict the forms that are generated.\n+;; Scalar version of fmadd\n+(define_insn \"sse5_vmfmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(vec_merge:SSEMODEF2P\n+\t (plus:SSEMODEF2P\n+\t  (mult:SSEMODEF2P\n+\t   (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0\")\n+\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\"))\n+\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fmadd<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Floating multiply and subtract\n+;; Allow two memory operands the same as fmadd\n+(define_insn \"sse5_fmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x,x,x\")\n+\t(minus:SSEMODEF4\n+\t (mult:SSEMODEF4\n+\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"%0,0,x,xm\")\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,xm,xm,x\"))\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x,0,0\")))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\"\n+  \"fmsub<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Split fmsub with two memory operands into a load and the fmsub.\n+(define_split\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"\")\n+\t(minus:SSEMODEF4\n+\t (mult:SSEMODEF4\n+\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"\")\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"\"))\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"\")))]\n+  \"TARGET_SSE5\n+   && !ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\n+   && !reg_mentioned_p (operands[0], operands[1])\n+   && !reg_mentioned_p (operands[0], operands[2])\n+   && !reg_mentioned_p (operands[0], operands[3])\"\n+  [(const_int 0)]\n+{\n+  ix86_expand_sse5_multiple_memory (operands, 4, <MODE>mode);\n+  emit_insn (gen_sse5_fmsub<mode>4 (operands[0], operands[1],\n+\t\t\t\t    operands[2], operands[3]));\n+  DONE;\n+})\n+\n+;; For the scalar operations, use operand1 for the upper words that aren't\n+;; modified, so restrict the forms that are generated.\n+;; Scalar version of fmsub\n+(define_insn \"sse5_vmfmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(vec_merge:SSEMODEF2P\n+\t (minus:SSEMODEF2P\n+\t  (mult:SSEMODEF2P\n+\t   (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0\")\n+\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\"))\n+\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fmsub<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Floating point negative multiply and add\n+;; Rewrite (- (a * b) + c) into the canonical form: c - (a * b)\n+;; Note operands are out of order to simplify call to ix86_sse5_valid_p\n+;; Allow two memory operands to help in optimizing.\n+(define_insn \"sse5_fnmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x,x,x\")\n+\t(minus:SSEMODEF4\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x,0,0\")\n+\t (mult:SSEMODEF4\n+\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"%0,0,x,xm\")\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,xm,xm,x\"))))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\"\n+  \"fnmadd<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Split fnmadd with two memory operands into a load and the fnmadd.\n+(define_split\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"\")\n+\t(minus:SSEMODEF4\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"\")\n+\t (mult:SSEMODEF4\n+\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"\")\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"\"))))]\n+  \"TARGET_SSE5\n+   && !ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\n+   && !reg_mentioned_p (operands[0], operands[1])\n+   && !reg_mentioned_p (operands[0], operands[2])\n+   && !reg_mentioned_p (operands[0], operands[3])\"\n+  [(const_int 0)]\n+{\n+  ix86_expand_sse5_multiple_memory (operands, 4, <MODE>mode);\n+  emit_insn (gen_sse5_fnmadd<mode>4 (operands[0], operands[1],\n+\t\t\t\t     operands[2], operands[3]));\n+  DONE;\n+})\n+\n+;; For the scalar operations, use operand1 for the upper words that aren't\n+;; modified, so restrict the forms that are generated.\n+;; Scalar version of fnmadd\n+(define_insn \"sse5_vmfnmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(vec_merge:SSEMODEF2P\n+\t (minus:SSEMODEF2P\n+\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\")\n+\t  (mult:SSEMODEF2P\n+\t   (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0\")\n+\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\")))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fnmadd<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Floating point negative multiply and subtract\n+;; Rewrite (- (a * b) - c) into the canonical form: ((-a) * b) - c\n+;; Allow 2 memory operands to help with optimization\n+(define_insn \"sse5_fnmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x\")\n+\t(minus:SSEMODEF4\n+\t (mult:SSEMODEF4\n+\t  (neg:SSEMODEF4\n+\t   (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"0,0\"))\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,xm\"))\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x\")))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\"\n+  \"fnmsub<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Split fnmsub with two memory operands into a load and the fmsub.\n+(define_split\n+  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"\")\n+\t(minus:SSEMODEF4\n+\t (mult:SSEMODEF4\n+\t  (neg:SSEMODEF4\n+\t   (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"\"))\n+\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"\"))\n+\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"\")))]\n+  \"TARGET_SSE5\n+   && !ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\n+   && !reg_mentioned_p (operands[0], operands[1])\n+   && !reg_mentioned_p (operands[0], operands[2])\n+   && !reg_mentioned_p (operands[0], operands[3])\"\n+  [(const_int 0)]\n+{\n+  ix86_expand_sse5_multiple_memory (operands, 4, <MODE>mode);\n+  emit_insn (gen_sse5_fnmsub<mode>4 (operands[0], operands[1],\n+\t\t\t\t     operands[2], operands[3]));\n+  DONE;\n+})\n+\n+;; For the scalar operations, use operand1 for the upper words that aren't\n+;; modified, so restrict the forms that are generated.\n+;; Scalar version of fnmsub\n+(define_insn \"sse5_vmfnmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(vec_merge:SSEMODEF2P\n+\t (minus:SSEMODEF2P\n+\t  (mult:SSEMODEF2P\n+\t   (neg:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0\"))\n+\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\"))\n+\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n+  \"TARGET_SSE5 && TARGET_FUSED_MADD\n+   && ix86_sse5_valid_op_p (operands, insn, 4, true, 2)\"\n+  \"fnmsub<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; The same instructions using an UNSPEC to allow the intrinsic to be used\n+;; even if the user used -mno-fused-madd\n+;; Parallel instructions.  During instruction generation, just default\n+;; to registers, and let combine later build the appropriate instruction.\n+(define_expand \"sse5i_fmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(plus:SSEMODEF2P\n+\t   (mult:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"register_operand\" \"\")\n+\t    (match_operand:SSEMODEF2P 2 \"register_operand\" \"\"))\n+\t   (match_operand:SSEMODEF2P 3 \"register_operand\" \"\"))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_fmadd<mode>4 (operands[0], operands[1],\n+\t\t\t\t\toperands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*sse5i_fmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x,x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(plus:SSEMODEF2P\n+\t   (mult:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%0,0,x,xm\")\n+\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm,xm,x\"))\n+\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x,0,0\"))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fmadd<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_expand \"sse5i_fmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(minus:SSEMODEF2P\n+\t   (mult:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"register_operand\" \"\")\n+\t    (match_operand:SSEMODEF2P 2 \"register_operand\" \"\"))\n+\t   (match_operand:SSEMODEF2P 3 \"register_operand\" \"\"))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_fmsub<mode>4 (operands[0], operands[1],\n+\t\t\t\t\toperands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*sse5i_fmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x,x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(minus:SSEMODEF2P\n+\t   (mult:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"register_operand\" \"%0,0,x,xm\")\n+\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm,xm,x\"))\n+\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x,0,0\"))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fmsub<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Rewrite (- (a * b) + c) into the canonical form: c - (a * b)\n+;; Note operands are out of order to simplify call to ix86_sse5_valid_p\n+(define_expand \"sse5i_fnmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(minus:SSEMODEF2P\n+\t   (match_operand:SSEMODEF2P 3 \"register_operand\" \"\")\n+\t   (mult:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"register_operand\" \"\")\n+\t    (match_operand:SSEMODEF2P 2 \"register_operand\" \"\")))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_fnmadd<mode>4 (operands[0], operands[1],\n+\t\t\t\t\t operands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*sse5i_fnmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x,x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(minus:SSEMODEF2P\n+\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x,0,0\")\n+\t   (mult:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%0,0,x,xm\")\n+\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm,xm,x\")))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fnmadd<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Rewrite (- (a * b) - c) into the canonical form: ((-a) * b) - c\n+(define_expand \"sse5i_fnmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(minus:SSEMODEF2P\n+\t   (mult:SSEMODEF2P\n+\t    (neg:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"register_operand\" \"\"))\n+\t    (match_operand:SSEMODEF2P 2 \"register_operand\" \"\"))\n+\t   (match_operand:SSEMODEF2P 3 \"register_operand\" \"\"))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_fnmsub<mode>4 (operands[0], operands[1],\n+\t\t\t\t\t operands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*sse5i_fnmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x,x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(minus:SSEMODEF2P\n+\t   (mult:SSEMODEF2P\n+\t    (neg:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%0,0,x,xm\"))\n+\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm,xm,x\"))\n+\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x,0,0\"))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fnmsub<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; Scalar instructions\n+(define_expand \"sse5i_vmfmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (plus:SSEMODEF2P\n+\t    (mult:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"register_operand\" \"\")\n+\t     (match_operand:SSEMODEF2P 2 \"register_operand\" \"\"))\n+\t    (match_operand:SSEMODEF2P 3 \"register_operand\" \"\"))\n+\t   (match_dup 1)\n+\t   (const_int 0))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_vmfmadd<mode>4 (operands[0], operands[1],\n+\t\t\t\t\t  operands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+;; For the scalar operations, use operand1 for the upper words that aren't\n+;; modified, so restrict the forms that are accepted.\n+(define_insn \"*sse5i_vmfmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (plus:SSEMODEF2P\n+\t    (mult:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"register_operand\" \"0,0\")\n+\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\"))\n+\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n+\t   (match_dup 0)\n+\t   (const_int 0))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fmadd<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<ssescalarmode>\")])\n+\n+(define_expand \"sse5i_vmfmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (minus:SSEMODEF2P\n+\t    (mult:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"register_operand\" \"\")\n+\t     (match_operand:SSEMODEF2P 2 \"register_operand\" \"\"))\n+\t    (match_operand:SSEMODEF2P 3 \"register_operand\" \"\"))\n+\t   (match_dup 0)\n+\t   (const_int 1))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_vmfmsub<mode>4 (operands[0], operands[1],\n+\t\t\t\t\t  operands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*sse5i_vmfmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (minus:SSEMODEF2P\n+\t    (mult:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0\")\n+\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\"))\n+\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n+\t   (match_dup 1)\n+\t   (const_int 1))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fmsub<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<ssescalarmode>\")])\n+\n+;; Note operands are out of order to simplify call to ix86_sse5_valid_p\n+(define_expand \"sse5i_vmfnmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (minus:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 3 \"register_operand\" \"\")\n+\t    (mult:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"register_operand\" \"\")\n+\t     (match_operand:SSEMODEF2P 2 \"register_operand\" \"\")))\n+\t   (match_dup 1)\n+\t   (const_int 1))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_vmfnmadd<mode>4 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*sse5i_vmfnmadd<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (minus:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\")\n+\t    (mult:SSEMODEF2P\n+\t     (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0\")\n+\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\")))\n+\t   (match_dup 1)\n+\t   (const_int 1))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fnmadd<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<ssescalarmode>\")])\n+\n+(define_expand \"sse5i_vmfnmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (minus:SSEMODEF2P\n+\t    (mult:SSEMODEF2P\n+\t     (neg:SSEMODEF2P\n+\t      (match_operand:SSEMODEF2P 1 \"register_operand\" \"\"))\n+\t     (match_operand:SSEMODEF2P 2 \"register_operand\" \"\"))\n+\t    (match_operand:SSEMODEF2P 3 \"register_operand\" \"\"))\n+\t   (match_dup 1)\n+\t   (const_int 1))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we have -mfused-madd, emit the normal insn rather than the UNSPEC */\n+  if (TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_sse5_vmfnmsub<mode>4 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*sse5i_vmfnmsub<mode>4\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(vec_merge:SSEMODEF2P\n+\t   (minus:SSEMODEF2P\n+\t    (mult:SSEMODEF2P\n+\t     (neg:SSEMODEF2P\n+\t      (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0\"))\n+\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm\"))\n+\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n+\t   (match_dup 1)\n+\t   (const_int 1))]\n+\t UNSPEC_SSE5_INTRINSIC))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"fnmsub<ssemodesuffixf2s>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<ssescalarmode>\")])\n+\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n ;; Parallel double-precision floating point arithmetic\n@@ -1875,7 +2446,7 @@\n \t(match_operator:V2DF 3 \"sse_comparison_operator\"\n \t\t[(match_operand:V2DF 1 \"register_operand\" \"0\")\n \t\t (match_operand:V2DF 2 \"nonimmediate_operand\" \"xm\")]))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && !TARGET_SSE5\"\n   \"cmp%D3pd\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"V2DF\")])\n@@ -1885,7 +2456,7 @@\n \t(match_operator:DF 3 \"sse_comparison_operator\"\n \t\t[(match_operand:DF 1 \"register_operand\" \"0\")\n \t\t (match_operand:DF 2 \"nonimmediate_operand\" \"xm\")]))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && !TARGET_SSE5\"\n   \"cmp%D3sd\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"DF\")])\n@@ -1898,7 +2469,7 @@\n \t\t (match_operand:V2DF 2 \"nonimmediate_operand\" \"xm\")])\n \t  (match_dup 1)\n \t  (const_int 1)))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && !TARGET_SSE5\"\n   \"cmp%D3sd\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"mode\" \"DF\")])\n@@ -2909,9 +3480,40 @@\n   \"&& 1\"\n   [(const_int 0)]\n {\n-  rtx t[12], op0;\n+  rtx t[12], op0, op[3];\n   int i;\n \n+  if (TARGET_SSE5)\n+    {\n+      /* On SSE5, we can take advantage of the pperm instruction to pack and\n+\t unpack the bytes.  Unpack data such that we've got a source byte in\n+\t each low byte of each word.  We don't care what goes into the high\n+\t byte, so put 0 there.  */\n+      for (i = 0; i < 6; ++i)\n+        t[i] = gen_reg_rtx (V8HImode);\n+\n+      for (i = 0; i < 2; i++)\n+        {\n+          op[0] = t[i];\n+          op[1] = operands[i+1];\n+          ix86_expand_sse5_unpack (op, true, true);\t\t/* high bytes */\n+\n+          op[0] = t[i+2];\n+          ix86_expand_sse5_unpack (op, true, false);\t\t/* low bytes */\n+        }\n+\n+      /* Multiply words.  */\n+      emit_insn (gen_mulv8hi3 (t[4], t[0], t[1]));\t\t/* high bytes */\n+      emit_insn (gen_mulv8hi3 (t[5], t[2], t[3]));\t\t/* low  bytes */\n+\n+      /* Pack the low byte of each word back into a single xmm */\n+      op[0] = operands[0];\n+      op[1] = t[5];\n+      op[2] = t[4];\n+      ix86_expand_sse5_pack (op);\n+      DONE;\n+    }\n+\n   for (i = 0; i < 12; ++i)\n     t[i] = gen_reg_rtx (V16QImode);\n \n@@ -3099,7 +3701,7 @@\n \t\t   (match_operand:V4SI 2 \"register_operand\" \"\")))]\n   \"TARGET_SSE2\"\n {\n-  if (TARGET_SSE4_1)\n+  if (TARGET_SSE4_1 || TARGET_SSE5)\n     ix86_fixup_binary_operands_no_copy (MULT, V4SImode, operands);\n })\n \n@@ -3113,11 +3715,36 @@\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"mode\" \"TI\")])\n \n+;; We don't have a straight 32-bit parallel multiply on SSE5, so fake it with a\n+;; multiply/add.  In general, we expect the define_split to occur before\n+;; register allocation, so we have to handle the corner case where the target\n+;; is used as the base or index register in operands 1/2.\n+(define_insn_and_split \"*sse5_mulv4si3\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=&x\")\n+\t(mult:V4SI (match_operand:V4SI 1 \"register_operand\" \"%x\")\n+\t\t   (match_operand:V4SI 2 \"nonimmediate_operand\" \"xm\")))]\n+  \"TARGET_SSE5\"\n+  \"#\"\n+  \"&& (reload_completed\n+       || (!reg_mentioned_p (operands[0], operands[1])\n+\t   && !reg_mentioned_p (operands[0], operands[2])))\"\n+  [(set (match_dup 0)\n+\t(match_dup 3))\n+   (set (match_dup 0)\n+\t(plus:V4SI (mult:V4SI (match_dup 1)\n+\t\t\t      (match_dup 2))\n+\t\t   (match_dup 0)))]\n+{\n+  operands[3] = CONST0_RTX (V4SImode);\n+}\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n (define_insn_and_split \"*sse2_mulv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"\")\n \t(mult:V4SI (match_operand:V4SI 1 \"register_operand\" \"\")\n \t\t   (match_operand:V4SI 2 \"register_operand\" \"\")))]\n-  \"TARGET_SSE2 && !TARGET_SSE4_1\n+  \"TARGET_SSE2 && !TARGET_SSE4_1 && !TARGET_SSE5\n    && !(reload_completed || reload_in_progress)\"\n   \"#\"\n   \"&& 1\"\n@@ -3707,7 +4334,8 @@\n \t(eq:SSEMODE124\n \t  (match_operand:SSEMODE124 1 \"nonimmediate_operand\" \"%0\")\n \t  (match_operand:SSEMODE124 2 \"nonimmediate_operand\" \"xm\")))]\n-  \"TARGET_SSE2 && ix86_binary_operator_ok (EQ, <MODE>mode, operands)\"\n+  \"TARGET_SSE2 && !TARGET_SSE5\n+   && ix86_binary_operator_ok (EQ, <MODE>mode, operands)\"\n   \"pcmpeq<ssevecsize>\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"prefix_data16\" \"1\")\n@@ -3729,7 +4357,7 @@\n \t(gt:SSEMODE124\n \t  (match_operand:SSEMODE124 1 \"register_operand\" \"0\")\n \t  (match_operand:SSEMODE124 2 \"nonimmediate_operand\" \"xm\")))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && !TARGET_SSE5\"\n   \"pcmpgt<ssevecsize>\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"ssecmp\")\n    (set_attr \"prefix_data16\" \"1\")\n@@ -4998,6 +5626,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, true, true);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, true, true);\n   else\n     ix86_expand_sse_unpack (operands, true, true);\n   DONE;\n@@ -5010,6 +5640,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, false, true);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, false, true);\n   else\n     ix86_expand_sse_unpack (operands, false, true);\n   DONE;\n@@ -5022,6 +5654,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, true, false);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, true, false);\n   else\n     ix86_expand_sse_unpack (operands, true, false);\n   DONE;\n@@ -5034,6 +5668,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, false, false);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, false, false);\n   else\n     ix86_expand_sse_unpack (operands, false, false);\n   DONE;\n@@ -5046,6 +5682,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, true, true);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, true, true);\n   else\n     ix86_expand_sse_unpack (operands, true, true);\n   DONE;\n@@ -5058,6 +5696,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, false, true);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, false, true);\n   else\n     ix86_expand_sse_unpack (operands, false, true);\n   DONE;\n@@ -5070,6 +5710,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, true, false);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, true, false);\n   else\n     ix86_expand_sse_unpack (operands, true, false);\n   DONE;\n@@ -5082,6 +5724,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, false, false);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, false, false);\n   else\n     ix86_expand_sse_unpack (operands, false, false);\n   DONE;\n@@ -5094,6 +5738,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, true, true);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, true, true);\n   else\n     ix86_expand_sse_unpack (operands, true, true);\n   DONE;\n@@ -5106,6 +5752,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, false, true);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, false, true);\n   else\n     ix86_expand_sse_unpack (operands, false, true);\n   DONE;\n@@ -5118,6 +5766,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, true, false);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, true, false);\n   else\n     ix86_expand_sse_unpack (operands, true, false);\n   DONE;\n@@ -5130,6 +5780,8 @@\n {\n   if (TARGET_SSE4_1)\n     ix86_expand_sse4_unpack (operands, false, false);\n+  else if (TARGET_SSE5)\n+    ix86_expand_sse5_unpack (operands, false, false);\n   else\n     ix86_expand_sse_unpack (operands, false, false);\n   DONE;\n@@ -6603,7 +7255,7 @@\n \t(unspec:V2DF [(match_operand:V2DF 1 \"nonimmediate_operand\" \"xm\")\n \t\t      (match_operand:SI 2 \"const_0_to_15_operand\" \"n\")]\n \t\t     UNSPEC_ROUND))]\n-  \"TARGET_SSE4_1\"\n+  \"TARGET_ROUND\"\n   \"roundpd\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -6614,7 +7266,7 @@\n \t(unspec:V4SF [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")\n \t\t      (match_operand:SI 2 \"const_0_to_15_operand\" \"n\")]\n \t\t     UNSPEC_ROUND))]\n-  \"TARGET_SSE4_1\"\n+  \"TARGET_ROUND\"\n   \"roundps\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -6628,7 +7280,7 @@\n \t\t       UNSPEC_ROUND)\n \t  (match_operand:V2DF 1 \"register_operand\" \"0\")\n \t  (const_int 1)))]\n-  \"TARGET_SSE4_1\"\n+  \"TARGET_ROUND\"\n   \"roundsd\\t{%3, %2, %0|%0, %2, %3}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -6642,7 +7294,7 @@\n \t\t       UNSPEC_ROUND)\n \t  (match_operand:V4SF 1 \"register_operand\" \"0\")\n \t  (const_int 1)))]\n-  \"TARGET_SSE4_1\"\n+  \"TARGET_ROUND\"\n   \"roundss\\t{%3, %2, %0|%0, %2, %3}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -6890,3 +7542,1186 @@\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"memory\" \"none,load,none,load\")\n    (set_attr \"mode\" \"TI\")])\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;;\n+;; SSE5 instructions\n+;;\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; SSE5 parallel integer multiply/add instructions.\n+;; Note the instruction does not allow the value being added to be a memory\n+;; operation.  However by pretending via the nonimmediate_operand predicate\n+;; that it does and splitting it later allows the following to be recognized:\n+;;\ta[i] = b[i] * c[i] + d[i];\n+(define_insn \"sse5_pmacsww\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x,x,x\")\n+        (plus:V8HI\n+\t (mult:V8HI\n+\t  (match_operand:V8HI 1 \"nonimmediate_operand\" \"%x,x,m\")\n+\t  (match_operand:V8HI 2 \"nonimmediate_operand\" \"x,m,x\"))\n+\t (match_operand:V8HI 3 \"nonimmediate_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 2)\"\n+  \"@\n+   pmacsww\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsww\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsww\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; Split pmacsww with two memory operands into a load and the pmacsww.\n+(define_split\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"\")\n+\t(plus:V8HI\n+\t (mult:V8HI (match_operand:V8HI 1 \"nonimmediate_operand\" \"\")\n+\t\t    (match_operand:V8HI 2 \"nonimmediate_operand\" \"\"))\n+\t (match_operand:V8HI 3 \"nonimmediate_operand\" \"\")))]\n+  \"TARGET_SSE5\n+   && !ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\n+   && ix86_sse5_valid_op_p (operands, insn, 4, false, 2)\n+   && !reg_mentioned_p (operands[0], operands[1])\n+   && !reg_mentioned_p (operands[0], operands[2])\n+   && !reg_mentioned_p (operands[0], operands[3])\"\n+  [(const_int 0)]\n+{\n+  ix86_expand_sse5_multiple_memory (operands, 4, V8HImode);\n+  emit_insn (gen_sse5_pmacsww (operands[0], operands[1], operands[2],\n+\t\t\t       operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"sse5_pmacssww\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x,x,x\")\n+        (ss_plus:V8HI\n+\t (mult:V8HI (match_operand:V8HI 1 \"nonimmediate_operand\" \"%x,x,m\")\n+\t\t    (match_operand:V8HI 2 \"nonimmediate_operand\" \"x,m,x\"))\n+\t (match_operand:V8HI 3 \"nonimmediate_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacssww\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssww\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssww\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; Note the instruction does not allow the value being added to be a memory\n+;; operation.  However by pretending via the nonimmediate_operand predicate\n+;; that it does and splitting it later allows the following to be recognized:\n+;;\ta[i] = b[i] * c[i] + d[i];\n+(define_insn \"sse5_pmacsdd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x\")\n+        (plus:V4SI\n+\t (mult:V4SI\n+\t  (match_operand:V4SI 1 \"nonimmediate_operand\" \"%x,x,m\")\n+\t  (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\"))\n+\t (match_operand:V4SI 3 \"nonimmediate_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 2)\"\n+  \"@\n+   pmacsdd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsdd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsdd\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; Split pmacsdd with two memory operands into a load and the pmacsdd.\n+(define_split\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"\")\n+\t(plus:V4SI\n+\t (mult:V4SI (match_operand:V4SI 1 \"nonimmediate_operand\" \"\")\n+\t\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"\"))\n+\t (match_operand:V4SI 3 \"nonimmediate_operand\" \"\")))]\n+  \"TARGET_SSE5\n+   && !ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\n+   && ix86_sse5_valid_op_p (operands, insn, 4, false, 2)\n+   && !reg_mentioned_p (operands[0], operands[1])\n+   && !reg_mentioned_p (operands[0], operands[2])\n+   && !reg_mentioned_p (operands[0], operands[3])\"\n+  [(const_int 0)]\n+{\n+  ix86_expand_sse5_multiple_memory (operands, 4, V4SImode);\n+  emit_insn (gen_sse5_pmacsdd (operands[0], operands[1], operands[2],\n+\t\t\t       operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"sse5_pmacssdd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x\")\n+        (ss_plus:V4SI\n+\t (mult:V4SI (match_operand:V4SI 1 \"nonimmediate_operand\" \"%x,x,m\")\n+\t\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\"))\n+\t (match_operand:V4SI 3 \"nonimmediate_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacssdd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssdd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssdd\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pmacssdql\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x,x,x\")\n+\t(ss_plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)])))\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)])))\n+\t (match_operand:V2DI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacssdql\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssdql\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssdql\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pmacssdqh\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x,x,x\")\n+\t(ss_plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)]))))\n+\t (match_operand:V2DI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacssdqh\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssdqh\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacssdqh\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pmacsdql\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x,x,x\")\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)]))))\n+\t (match_operand:V2DI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacsdql\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsdql\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsdql\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pmacsdqh\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x,x,x\")\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)]))))\n+\t (match_operand:V2DI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacsdqh\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsdqh\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsdqh\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; SSE5 parallel integer mutliply/add instructions for the intrinisics\n+(define_insn \"sse5_pmacsswd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x\")\n+\t(ss_plus:V4SI\n+\t (mult:V4SI\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4HI\n+\t    (match_operand:V8HI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)\n+\t\t       (const_int 5)\n+\t\t       (const_int 7)])))\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4HI\n+\t    (match_operand:V8HI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)\n+\t\t       (const_int 5)\n+\t\t       (const_int 7)]))))\n+\t (match_operand:V4SI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacsswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacsswd\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pmacswd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x\")\n+\t(plus:V4SI\n+\t (mult:V4SI\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4HI\n+\t    (match_operand:V8HI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)\n+\t\t       (const_int 5)\n+\t\t       (const_int 7)])))\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4HI\n+\t    (match_operand:V8HI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)\n+\t\t       (const_int 5)\n+\t\t       (const_int 7)]))))\n+\t (match_operand:V4SI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmacswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmacswd\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pmadcsswd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x\")\n+\t(ss_plus:V4SI\n+\t (plus:V4SI\n+\t  (mult:V4SI\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_operand:V8HI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t     (parallel [(const_int 0)\n+\t\t\t(const_int 2)\n+\t\t\t(const_int 4)\n+\t\t\t(const_int 6)])))\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_operand:V8HI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t     (parallel [(const_int 0)\n+\t\t\t(const_int 2)\n+\t\t\t(const_int 4)\n+\t\t\t(const_int 6)]))))\n+\t  (mult:V4SI\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 1)\n+\t\t\t(const_int 3)\n+\t\t\t(const_int 5)\n+\t\t\t(const_int 7)])))\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_dup 2)\n+\t     (parallel [(const_int 1)\n+\t\t\t(const_int 3)\n+\t\t\t(const_int 5)\n+\t\t\t(const_int 7)])))))\n+\t (match_operand:V4SI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmadcsswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmadcsswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmadcsswd\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pmadcswd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x\")\n+\t(plus:V4SI\n+\t (plus:V4SI\n+\t  (mult:V4SI\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_operand:V8HI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t     (parallel [(const_int 0)\n+\t\t\t(const_int 2)\n+\t\t\t(const_int 4)\n+\t\t\t(const_int 6)])))\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_operand:V8HI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t     (parallel [(const_int 0)\n+\t\t\t(const_int 2)\n+\t\t\t(const_int 4)\n+\t\t\t(const_int 6)]))))\n+\t  (mult:V4SI\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 1)\n+\t\t\t(const_int 3)\n+\t\t\t(const_int 5)\n+\t\t\t(const_int 7)])))\n+\t   (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t     (match_dup 2)\n+\t     (parallel [(const_int 1)\n+\t\t\t(const_int 3)\n+\t\t\t(const_int 5)\n+\t\t\t(const_int 7)])))))\n+\t (match_operand:V4SI 3 \"register_operand\" \"0,0,0\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, 1)\"\n+  \"@\n+   pmadcswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmadcswd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n+   pmadcswd\\t{%3, %1, %2, %0|%0, %2, %1, %3}\"\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; SSE5 parallel XMM conditional moves\n+(define_insn \"sse5_pcmov_<mode>\"\n+  [(set (match_operand:SSEMODE 0 \"register_operand\" \"=x,x,x,x,x,x\")\n+\t(if_then_else:SSEMODE \n+\t  (match_operand:SSEMODE 3 \"nonimmediate_operand\" \"0,0,xm,xm,0,0\")\n+\t  (match_operand:SSEMODE 1 \"vector_move_operand\" \"x,xm,0,x,C,x\")\n+\t  (match_operand:SSEMODE 2 \"vector_move_operand\" \"xm,x,x,0,x,C\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"@\n+   pcmov\\t{%3, %2, %1, %0|%3, %1, %2, %0}\n+   pcmov\\t{%3, %2, %1, %0|%3, %1, %2, %0}\n+   pcmov\\t{%3, %2, %1, %0|%3, %1, %2, %0}\n+   pcmov\\t{%3, %2, %1, %0|%3, %1, %2, %0}\n+   andps\\t{%2, %0|%0, %2}\n+   andnps\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sse4arg\")])\n+\n+;; SSE5 horizontal add/subtract instructions\n+(define_insn \"sse5_phaddbw\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n+\t(plus:V8HI\n+\t (sign_extend:V8HI\n+\t  (vec_select:V8QI\n+\t   (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)\n+\t\t      (const_int 4)\n+\t\t      (const_int 6)\n+\t\t      (const_int 8)\n+\t\t      (const_int 10)\n+\t\t      (const_int 12)\n+\t\t      (const_int 14)])))\n+\t (sign_extend:V8HI\n+\t  (vec_select:V8QI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)\n+\t\t      (const_int 5)\n+\t\t      (const_int 7)\n+\t\t      (const_int 9)\n+\t\t      (const_int 11)\n+\t\t      (const_int 13)\n+\t\t      (const_int 15)])))))]\n+  \"TARGET_SSE5\"\n+  \"phaddbw\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddbd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+\t(plus:V4SI\n+\t (plus:V4SI\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 4)\n+\t\t       (const_int 8)\n+\t\t       (const_int 12)])))\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 5)\n+\t\t       (const_int 9)\n+\t\t       (const_int 13)]))))\n+\t (plus:V4SI\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 2)\n+\t\t       (const_int 6)\n+\t\t       (const_int 10)\n+\t\t       (const_int 14)])))\n+\t  (sign_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 3)\n+\t\t       (const_int 7)\n+\t\t       (const_int 11)\n+\t\t       (const_int 15)]))))))]\n+  \"TARGET_SSE5\"\n+  \"phaddbd\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddbq\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+\t(plus:V2DI\n+\t (plus:V2DI\n+\t  (plus:V2DI\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm\")\n+\t     (parallel [(const_int 0)\n+\t\t\t(const_int 4)])))\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 1)\n+\t\t\t(const_int 5)]))))\n+\t  (plus:V2DI\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 2)\n+\t\t\t(const_int 6)])))\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 3)\n+\t\t\t(const_int 7)])))))\n+\t (plus:V2DI\n+\t  (plus:V2DI\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 8)\n+\t\t\t(const_int 12)])))\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 9)\n+\t\t\t(const_int 13)]))))\n+\t  (plus:V2DI\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 10)\n+\t\t\t(const_int 14)])))\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 11)\n+\t\t\t(const_int 15)])))))))]\n+  \"TARGET_SSE5\"\n+  \"phaddbq\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddwd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+\t(plus:V4SI\n+\t (sign_extend:V4SI\n+\t  (vec_select:V4HI\n+\t   (match_operand:V8HI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)\n+\t\t      (const_int 4)\n+\t\t      (const_int 6)])))\n+\t (sign_extend:V4SI\n+\t  (vec_select:V4HI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)\n+\t\t      (const_int 5)\n+\t\t      (const_int 7)])))))]\n+  \"TARGET_SSE5\"\n+  \"phaddwd\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddwq\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+\t(plus:V2DI\n+\t (plus:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_operand:V8HI 1 \"nonimmediate_operand\" \"xm\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 4)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 5)]))))\n+\t (plus:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 2)\n+\t\t       (const_int 6)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 3)\n+\t\t       (const_int 7)]))))))]\n+  \"TARGET_SSE5\"\n+  \"phaddwq\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phadddq\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+\t(plus:V2DI\n+\t (sign_extend:V2DI\n+\t  (vec_select:V2SI\n+\t   (match_operand:V4SI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)])))\n+\t (sign_extend:V2DI\n+\t  (vec_select:V2SI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)])))))]\n+  \"TARGET_SSE5\"\n+  \"phadddq\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddubw\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n+\t(plus:V8HI\n+\t (zero_extend:V8HI\n+\t  (vec_select:V8QI\n+\t   (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)\n+\t\t      (const_int 4)\n+\t\t      (const_int 6)\n+\t\t      (const_int 8)\n+\t\t      (const_int 10)\n+\t\t      (const_int 12)\n+\t\t      (const_int 14)])))\n+\t (zero_extend:V8HI\n+\t  (vec_select:V8QI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)\n+\t\t      (const_int 5)\n+\t\t      (const_int 7)\n+\t\t      (const_int 9)\n+\t\t      (const_int 11)\n+\t\t      (const_int 13)\n+\t\t      (const_int 15)])))))]\n+  \"TARGET_SSE5\"\n+  \"phaddubw\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddubd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+\t(plus:V4SI\n+\t (plus:V4SI\n+\t  (zero_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 4)\n+\t\t       (const_int 8)\n+\t\t       (const_int 12)])))\n+\t  (zero_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 5)\n+\t\t       (const_int 9)\n+\t\t       (const_int 13)]))))\n+\t (plus:V4SI\n+\t  (zero_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 2)\n+\t\t       (const_int 6)\n+\t\t       (const_int 10)\n+\t\t       (const_int 14)])))\n+\t  (zero_extend:V4SI\n+\t   (vec_select:V4QI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 3)\n+\t\t       (const_int 7)\n+\t\t       (const_int 11)\n+\t\t       (const_int 15)]))))))]\n+  \"TARGET_SSE5\"\n+  \"phaddubd\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddubq\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+\t(plus:V2DI\n+\t (plus:V2DI\n+\t  (plus:V2DI\n+\t   (zero_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm\")\n+\t     (parallel [(const_int 0)\n+\t\t\t(const_int 4)])))\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 1)\n+\t\t\t(const_int 5)]))))\n+\t  (plus:V2DI\n+\t   (zero_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 2)\n+\t\t\t(const_int 6)])))\n+\t   (zero_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 3)\n+\t\t\t(const_int 7)])))))\n+\t (plus:V2DI\n+\t  (plus:V2DI\n+\t   (zero_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 8)\n+\t\t\t(const_int 12)])))\n+\t   (sign_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 9)\n+\t\t\t(const_int 13)]))))\n+\t  (plus:V2DI\n+\t   (zero_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 10)\n+\t\t\t(const_int 14)])))\n+\t   (zero_extend:V2DI\n+\t    (vec_select:V2QI\n+\t     (match_dup 1)\n+\t     (parallel [(const_int 11)\n+\t\t\t(const_int 15)])))))))]\n+  \"TARGET_SSE5\"\n+  \"phaddubq\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phadduwd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+\t(plus:V4SI\n+\t (zero_extend:V4SI\n+\t  (vec_select:V4HI\n+\t   (match_operand:V8HI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)\n+\t\t      (const_int 4)\n+\t\t      (const_int 6)])))\n+\t (zero_extend:V4SI\n+\t  (vec_select:V4HI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)\n+\t\t      (const_int 5)\n+\t\t      (const_int 7)])))))]\n+  \"TARGET_SSE5\"\n+  \"phadduwd\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phadduwq\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+\t(plus:V2DI\n+\t (plus:V2DI\n+\t  (zero_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_operand:V8HI 1 \"nonimmediate_operand\" \"xm\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 4)])))\n+\t  (zero_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 5)]))))\n+\t (plus:V2DI\n+\t  (zero_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 2)\n+\t\t       (const_int 6)])))\n+\t  (zero_extend:V2DI\n+\t   (vec_select:V2HI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 3)\n+\t\t       (const_int 7)]))))))]\n+  \"TARGET_SSE5\"\n+  \"phadduwq\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phaddudq\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+\t(plus:V2DI\n+\t (zero_extend:V2DI\n+\t  (vec_select:V2SI\n+\t   (match_operand:V4SI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)])))\n+\t (zero_extend:V2DI\n+\t  (vec_select:V2SI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)])))))]\n+  \"TARGET_SSE5\"\n+  \"phaddudq\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phsubbw\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n+\t(minus:V8HI\n+\t (sign_extend:V8HI\n+\t  (vec_select:V8QI\n+\t   (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)\n+\t\t      (const_int 4)\n+\t\t      (const_int 6)\n+\t\t      (const_int 8)\n+\t\t      (const_int 10)\n+\t\t      (const_int 12)\n+\t\t      (const_int 14)])))\n+\t (sign_extend:V8HI\n+\t  (vec_select:V8QI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)\n+\t\t      (const_int 5)\n+\t\t      (const_int 7)\n+\t\t      (const_int 9)\n+\t\t      (const_int 11)\n+\t\t      (const_int 13)\n+\t\t      (const_int 15)])))))]\n+  \"TARGET_SSE5\"\n+  \"phsubbw\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phsubwd\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+\t(minus:V4SI\n+\t (sign_extend:V4SI\n+\t  (vec_select:V4HI\n+\t   (match_operand:V8HI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)\n+\t\t      (const_int 4)\n+\t\t      (const_int 6)])))\n+\t (sign_extend:V4SI\n+\t  (vec_select:V4HI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)\n+\t\t      (const_int 5)\n+\t\t      (const_int 7)])))))]\n+  \"TARGET_SSE5\"\n+  \"phsubwd\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+(define_insn \"sse5_phsubdq\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+\t(minus:V2DI\n+\t (sign_extend:V2DI\n+\t  (vec_select:V2SI\n+\t   (match_operand:V4SI 1 \"nonimmediate_operand\" \"xm\")\n+\t   (parallel [(const_int 0)\n+\t\t      (const_int 2)])))\n+\t (sign_extend:V2DI\n+\t  (vec_select:V2SI\n+\t   (match_dup 1)\n+\t   (parallel [(const_int 1)\n+\t\t      (const_int 3)])))))]\n+  \"TARGET_SSE5\"\n+  \"phsubdq\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sseiadd1\")])\n+\n+;; SSE5 permute instructions\n+(define_insn \"sse5_pperm\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=x,x,x,x\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"nonimmediate_operand\" \"0,0,xm,xm\")\n+\t\t       (match_operand:V16QI 2 \"nonimmediate_operand\" \"x,xm,0,x\")\n+\t\t       (match_operand:V16QI 3 \"nonimmediate_operand\" \"xm,x,x,0\")]\n+\t\t     UNSPEC_SSE5_PERMUTE))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"pperm\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; The following are for the various unpack insns which doesn't need the first\n+;; source operand, so we can just use the output operand for the first operand.\n+;; This allows either of the other two operands to be a memory operand.  We\n+;; can't just use the first operand as an argument to the normal pperm because\n+;; then an output only argument, suddenly becomes an input operand.\n+(define_insn \"sse5_pperm_zero_v16qi_v8hi\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x,x\")\n+\t(zero_extend:V8HI\n+\t (vec_select:V8QI\n+\t  (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm,x\")\n+\t  (match_operand 2 \"\" \"\"))))\t;; parallel with const_int's\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"x,xm\"))]\n+  \"TARGET_SSE5\n+   && (register_operand (operands[1], V16QImode)\n+       || register_operand (operands[2], V16QImode))\"\n+  \"pperm\\t{%3, %1, %0, %0|%0, %0, %1, %3}\"\n+  [(set_attr \"type\" \"sseadd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pperm_sign_v16qi_v8hi\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x,x\")\n+\t(sign_extend:V8HI\n+\t (vec_select:V8QI\n+\t  (match_operand:V16QI 1 \"nonimmediate_operand\" \"xm,x\")\n+\t  (match_operand 2 \"\" \"\"))))\t;; parallel with const_int's\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"x,xm\"))]\n+  \"TARGET_SSE5\n+   && (register_operand (operands[1], V16QImode)\n+       || register_operand (operands[2], V16QImode))\"\n+  \"pperm\\t{%3, %1, %0, %0|%0, %0, %1, %3}\"\n+  [(set_attr \"type\" \"sseadd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pperm_zero_v8hi_v4si\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x\")\n+\t(zero_extend:V4SI\n+\t (vec_select:V4HI\n+\t  (match_operand:V8HI 1 \"nonimmediate_operand\" \"xm,x\")\n+\t  (match_operand 2 \"\" \"\"))))\t;; parallel with const_int's\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"x,xm\"))]\n+  \"TARGET_SSE5\n+   && (register_operand (operands[1], V8HImode)\n+       || register_operand (operands[2], V16QImode))\"\n+  \"pperm\\t{%3, %1, %0, %0|%0, %0, %1, %3}\"\n+  [(set_attr \"type\" \"sseadd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pperm_sign_v8hi_v4si\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x\")\n+\t(sign_extend:V4SI\n+\t (vec_select:V4HI\n+\t  (match_operand:V8HI 1 \"nonimmediate_operand\" \"xm,x\")\n+\t  (match_operand 2 \"\" \"\"))))\t;; parallel with const_int's\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"x,xm\"))]\n+  \"TARGET_SSE5\n+   && (register_operand (operands[1], V8HImode)\n+       || register_operand (operands[2], V16QImode))\"\n+  \"pperm\\t{%3, %1, %0, %0|%0, %0, %1, %3}\"\n+  [(set_attr \"type\" \"sseadd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pperm_zero_v4si_v2di\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x,x\")\n+\t(zero_extend:V2DI\n+\t (vec_select:V2SI\n+\t  (match_operand:V4SI 1 \"nonimmediate_operand\" \"xm,x\")\n+\t  (match_operand 2 \"\" \"\"))))\t;; parallel with const_int's\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"x,xm\"))]\n+  \"TARGET_SSE5\n+   && (register_operand (operands[1], V4SImode)\n+       || register_operand (operands[2], V16QImode))\"\n+  \"pperm\\t{%3, %1, %0, %0|%0, %0, %1, %3}\"\n+  [(set_attr \"type\" \"sseadd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pperm_sign_v4si_v2di\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x,x\")\n+\t(sign_extend:V2DI\n+\t (vec_select:V2SI\n+\t  (match_operand:V4SI 1 \"nonimmediate_operand\" \"xm,x\")\n+\t  (match_operand 2 \"\" \"\"))))\t;; parallel with const_int's\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"x,xm\"))]\n+  \"TARGET_SSE5\n+   && (register_operand (operands[1], V4SImode)\n+       || register_operand (operands[2], V16QImode))\"\n+  \"pperm\\t{%3, %1, %0, %0|%0, %0, %1, %3}\"\n+  [(set_attr \"type\" \"sseadd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; SSE5 pack instructions that combine two vectors into a smaller vector\n+(define_insn \"sse5_pperm_pack_v2di_v4si\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x,x\")\n+\t(vec_concat:V4SI\n+\t (truncate:V2SI\n+\t  (match_operand:V2DI 1 \"nonimmediate_operand\" \"0,0,xm,xm\"))\n+\t (truncate:V2SI\n+\t  (match_operand:V2DI 2 \"nonimmediate_operand\" \"x,xm,0,x\"))))\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"xm,x,x,0\"))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"pperm\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pperm_pack_v4si_v8hi\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x,x,x,x\")\n+\t(vec_concat:V8HI\n+\t (truncate:V4HI\n+\t  (match_operand:V4SI 1 \"nonimmediate_operand\" \"0,0,xm,xm\"))\n+\t (truncate:V4HI\n+\t  (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,xm,0,x\"))))\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"xm,x,x,0\"))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"pperm\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_pperm_pack_v8hi_v16qi\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=x,x,x,x\")\n+\t(vec_concat:V16QI\n+\t (truncate:V8QI\n+\t  (match_operand:V8HI 1 \"nonimmediate_operand\" \"0,0,xm,xm\"))\n+\t (truncate:V8QI\n+\t  (match_operand:V8HI 2 \"nonimmediate_operand\" \"x,xm,0,x\"))))\n+   (use (match_operand:V16QI 3 \"nonimmediate_operand\" \"xm,x,x,0\"))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"pperm\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; Floating point permutation (permps, permpd)\n+(define_insn \"sse5_perm<mode>\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x,x,x\")\n+\t(unspec:SSEMODEF2P\n+\t [(match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"0,0,xm,xm\")\n+\t  (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,xm,0,x\")\n+\t  (match_operand:V16QI 3 \"nonimmediate_operand\" \"xm,x,x,0\")]\n+\t UNSPEC_SSE5_PERMUTE))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n+  \"perm<ssemodesuffixf4>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; SSE5 packed rotate instructions\n+(define_insn \"rotl<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x\")\n+\t(rotate:SSEMODE1248\n+\t (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"xm\")\n+\t (match_operand:SI 2 \"const_0_to_<sserotatemax>_operand\" \"n\")))]\n+  \"TARGET_SSE5\"\n+  \"prot<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n+  [(set_attr \"type\" \"sseishft\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_rotl<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x,x\")\n+\t(rotate:SSEMODE1248\n+\t (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n+\t (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 3, true, 1)\"\n+  \"prot<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n+  [(set_attr \"type\" \"sseishft\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; SSE5 packed shift instructions.  Note negative values for the shift amount\n+;; convert this into a right shift instead of left shift.  For now, model this\n+;; with an UNSPEC instead of using ashift/lshift since the rest of the x86 does\n+;; not have the concept of negating the shift amount.  Also, there is no LSHIFT\n+(define_insn \"sse5_ashl<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x,x\")\n+\t(unspec:SSEMODE1248\n+\t [(match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n+\t  (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")]\n+\t UNSPEC_SSE5_ASHIFT))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 3, true, 1)\"\n+  \"psha<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n+  [(set_attr \"type\" \"sseishft\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_lshl<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x,x\")\n+\t(unspec:SSEMODE1248\n+\t [(match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n+\t  (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")]\n+\t UNSPEC_SSE5_LSHIFT))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 3, true, 1)\"\n+  \"pshl<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n+  [(set_attr \"type\" \"sseishft\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; SSE5 FRCZ support\n+;; parallel insns\n+(define_insn \"sse5_frcz<mode>2\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n+\t(unspec:SSEMODEF2P\n+\t [(match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"xm\")]\n+\t UNSPEC_FRCZ))]\n+  \"TARGET_SSE5\"\n+  \"frcz<ssesuffixf4>\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"ssecvt1\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; scalar insns\n+(define_insn \"sse5_vmfrcz<mode>2\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n+\t(vec_merge:SSEMODEF2P\n+\t  (unspec:SSEMODEF2P\n+\t   [(match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"xm\")]\n+\t   UNSPEC_FRCZ)\n+\t  (match_operand:SSEMODEF2P 1 \"register_operand\" \"0\")\n+\t  (const_int 1)))]\n+  \"TARGET_ROUND\"\n+  \"frcz<ssesuffixf2s>\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"ssecvt1\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"sse5_cvtph2ps\"\n+  [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n+\t(unspec:V4SF [(match_operand:V4HI 1 \"nonimmediate_operand\" \"xm\")]\n+\t\t     UNSPEC_CVTPH2PS))]\n+  \"TARGET_SSE5\"\n+  \"cvtph2ps\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"ssecvt\")\n+   (set_attr \"mode\" \"V4SF\")])\n+\n+(define_insn \"sse5_cvtps2ph\"\n+  [(set (match_operand:V4HI 0 \"nonimmediate_operand\" \"=xm\")\n+\t(unspec:V4HI [(match_operand:V4SF 1 \"register_operand\" \"x\")]\n+\t\t     UNSPEC_CVTPS2PH))]\n+  \"TARGET_SSE5\"\n+  \"cvtps2ph\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"ssecvt\")\n+   (set_attr \"mode\" \"V4SF\")])\n+\n+;; Scalar versions of the com instructions that use vector types that are\n+;; called from the intrinsics.  Unlike the the other s{s,d} instructions, the\n+;; com instructions fill in 0's in the upper bits instead of leaving them\n+;; unmodified, so we use const_vector of 0 instead of match_dup.\n+(define_expand \"sse5_vmmaskcmp<mode>3\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n+\t(vec_merge:SSEMODEF2P\n+\t (match_operator:SSEMODEF2P 1 \"sse5_comparison_float_operator\"\n+\t  [(match_operand:SSEMODEF2P 2 \"register_operand\" \"\")\n+\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"\")])\n+\t (match_dup 4)\n+\t (const_int 1)))]\n+  \"TARGET_SSE5\"\n+{\n+  operands[4] = CONST0_RTX (<MODE>mode);\n+})\n+\n+(define_insn \"*sse5_vmmaskcmp<mode>3\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n+\t(vec_merge:SSEMODEF2P\n+\t (match_operator:SSEMODEF2P 1 \"sse5_comparison_float_operator\"\n+\t  [(match_operand:SSEMODEF2P 2 \"register_operand\" \"x\")\n+\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm\")])\n+\t  (match_operand:SSEMODEF2P 4 \"\")\n+\t  (const_int 1)))]\n+  \"TARGET_SSE5\"\n+  \"com%Y1<ssemodesuffixf2s>\\t{%3, %2, %0|%0, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"<ssescalarmode>\")])\n+\n+;; We don't have a comparison operator that always returns true/false, so\n+;; handle comfalse and comtrue specially.\n+(define_insn \"sse5_com_tf<mode>3\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n+\t(unspec:SSEMODEF2P\n+\t [(match_operand:SSEMODEF2P 1 \"register_operand\" \"x\")\n+\t  (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"xm\")\n+\t  (match_operand:SI 3 \"const_int_operand\" \"n\")]\n+\t UNSPEC_SSE5_TRUEFALSE))]\n+  \"TARGET_SSE5\"\n+{\n+  const char *ret = NULL;\n+\n+  switch (INTVAL (operands[3]))\n+    {\n+    case COM_FALSE_S:\n+      ret = \\\"comfalses<ssemodesuffixf2c>\\t{%2, %1, %0|%0, %1, %2}\\\";\n+      break;\n+\n+    case COM_FALSE_P:\n+      ret = \\\"comfalsep<ssemodesuffixf2c>\\t{%2, %1, %0|%0, %1, %2}\\\";\n+      break;\n+\n+    case COM_TRUE_S:\n+      ret = \\\"comfalses<ssemodesuffixf2c>\\t{%2, %1, %0|%0, %1, %2}\\\";\n+      break;\n+\n+    case COM_TRUE_P:\n+      ret = \\\"comfalsep<ssemodesuffixf2c>\\t{%2, %1, %0|%0, %1, %2}\\\";\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  return ret;\n+}\n+  [(set_attr \"type\" \"ssecmp\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"sse5_maskcmp<mode>3\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n+\t(match_operator:SSEMODEF2P 1 \"sse5_comparison_float_operator\"\n+\t [(match_operand:SSEMODEF2P 2 \"register_operand\" \"x\")\n+\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm\")]))]\n+  \"TARGET_SSE5\"\n+  \"com%Y1<ssemodesuffixf4>\\t{%3, %2, %0|%0, %2, %3}\"\n+  [(set_attr \"type\" \"ssecmp\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"sse5_maskcmp<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x\")\n+\t(match_operator:SSEMODE1248 1 \"ix86_comparison_int_operator\"\n+\t [(match_operand:SSEMODE1248 2 \"register_operand\" \"x\")\n+\t  (match_operand:SSEMODE1248 3 \"nonimmediate_operand\" \"xm\")]))]\n+  \"TARGET_SSE5\"\n+  \"pcom%Y1<ssevecsize>\\t{%3, %2, %0|%0, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"sse5_maskcmp_uns<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x\")\n+\t(match_operator:SSEMODE1248 1 \"ix86_comparison_uns_operator\"\n+\t [(match_operand:SSEMODE1248 2 \"register_operand\" \"x\")\n+\t  (match_operand:SSEMODE1248 3 \"nonimmediate_operand\" \"xm\")]))]\n+  \"TARGET_SSE5\"\n+  \"pcom%Y1u<ssevecsize>\\t{%3, %2, %0|%0, %2, %3}\"\n+  [(set_attr \"type\" \"ssecmp\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; Version of pcom*u* that is called from the intrinsics that allows pcomequ*\n+;; and pcomneu* not to be converted to the signed ones in case somebody needs\n+;; the exact instruction generated for the intrinsic.\n+(define_insn \"sse5_maskcmp_uns2<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x\")\n+\t(unspec:SSEMODE1248\n+\t [(match_operator:SSEMODE1248 1 \"ix86_comparison_uns_operator\"\n+\t  [(match_operand:SSEMODE1248 2 \"register_operand\" \"x\")\n+\t   (match_operand:SSEMODE1248 3 \"nonimmediate_operand\" \"xm\")])]\n+\t UNSPEC_SSE5_UNSIGNED_CMP))]\n+  \"TARGET_SSE5\"\n+  \"pcom%Y1u<ssevecsize>\\t{%3, %2, %0|%0, %2, %3}\"\n+  [(set_attr \"type\" \"ssecmp\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+;; Pcomtrue and pcomfalse support.  These are useless instructions, but are\n+;; being added here to be complete.\n+(define_insn \"sse5_pcom_tf<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x\")\n+\t(unspec:SSEMODE1248 [(match_operand:SSEMODE1248 1 \"register_operand\" \"x\")\n+\t\t\t     (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm\")\n+\t\t\t     (match_operand:SI 3 \"const_int_operand\" \"n\")]\n+\t\t\t    UNSPEC_SSE5_TRUEFALSE))]\n+  \"TARGET_SSE5\"\n+{\n+  return ((INTVAL (operands[3]) != 0)\n+\t  ? \"pcomtrue<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n+\t  : \"pcomfalse<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\");\n+}\n+  [(set_attr \"type\" \"ssecmp\")\n+   (set_attr \"mode\" \"TI\")])"}, {"sha": "4d93573506ee6b67c754ce19053ac38738d91fcd", "filename": "gcc/config/i386/winnt.c", "status": "modified", "additions": 29, "deletions": 31, "changes": 60, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fwinnt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fconfig%2Fi386%2Fwinnt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fwinnt.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -165,40 +165,38 @@ gen_stdcall_or_fastcall_suffix (tree decl, tree id, bool fastcall)\n   HOST_WIDE_INT total = 0;\n   const char *old_str = IDENTIFIER_POINTER (id != NULL_TREE ? id : DECL_NAME (decl));\n   char *new_str, *p;\n-  tree formal_type;\n+  tree type = TREE_TYPE (decl);\n+  tree arg;\n+  function_args_iterator args_iter;\n \n   gcc_assert (TREE_CODE (decl) == FUNCTION_DECL);  \n \n-  formal_type = TYPE_ARG_TYPES (TREE_TYPE (decl));\n-  if (formal_type != NULL_TREE)\n-    while (1)\n-      {\n-\tHOST_WIDE_INT parm_size;\n-\tHOST_WIDE_INT parm_boundary_bytes = PARM_BOUNDARY / BITS_PER_UNIT;\n-\n-\t/* We got to the end of the list without seeing void_list_node,\n-\t   which means the function is variadic.  The suffix is to be\n-\t   ignored in that case.  */\n-\tif (formal_type == NULL_TREE)\n-\t  return NULL_TREE;\n-\n-\t/* End of arguments, non-varargs marker.  */\n-        if (formal_type == void_list_node)\n-\t  break;\n-\n-        /* Quit if we hit an incomplete type.  Error is reported\n-\t   by convert_arguments in c-typeck.c or cp/typeck.c.  */\n-\tparm_size = int_size_in_bytes (TREE_VALUE (formal_type));\n-\tif (parm_size < 0)\n-\t  break;\n-\n-\t/* Must round up to include padding.  This is done the same\n-\t   way as in store_one_arg.  */\n-\tparm_size = ((parm_size + parm_boundary_bytes - 1)\n-\t\t     / parm_boundary_bytes * parm_boundary_bytes);\n-\ttotal += parm_size;\n-\n-\tformal_type = TREE_CHAIN (formal_type);\n+  if (prototype_p (type))\n+    {\n+      /* This attribute is ignored for variadic functions.  */ \n+      if (stdarg_p (type))\n+\treturn NULL_TREE;\n+\n+      /* Quit if we hit an incomplete type.  Error is reported\n+\t by convert_arguments in c-typeck.c or cp/typeck.c.  */\n+      FOREACH_FUNCTION_ARGS(type, arg, args_iter)\n+\t{\n+\t  HOST_WIDE_INT parm_size;\n+\t  HOST_WIDE_INT parm_boundary_bytes = PARM_BOUNDARY / BITS_PER_UNIT;\n+\n+\t  if (! COMPLETE_TYPE_P (arg))\n+\t    break;\n+\n+\t  parm_size = int_size_in_bytes (arg);\n+\t  if (parm_size < 0)\n+\t    break;\n+\n+\t  /* Must round up to include padding.  This is done the same\n+\t     way as in store_one_arg.  */\n+\t  parm_size = ((parm_size + parm_boundary_bytes - 1)\n+\t\t       / parm_boundary_bytes * parm_boundary_bytes);\n+\t  total += parm_size;\n+\t}\n       }\n   /* Assume max of 8 base 10 digits in the suffix.  */\n   p = new_str = alloca (1 + strlen (old_str) + 1 + 8 + 1);"}, {"sha": "9f207cfa2ecf64edd992d7ce368d9b371939d233", "filename": "gcc/doc/extend.texi", "status": "modified", "additions": 217, "deletions": 0, "changes": 217, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fdoc%2Fextend.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fdoc%2Fextend.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fextend.texi?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -7919,6 +7919,223 @@ v2di __builtin_ia32_insertq (v2di, v2di)\n v2di __builtin_ia32_insertqi (v2di, v2di, const unsigned int, const unsigned int)\n @end smallexample\n \n+The following built-in functions are available when @option{-msse5} is used.\n+All of them generate the machine instruction that is part of the name\n+with MMX registers.\n+\n+@smallexample\n+v2df __builtin_ia32_comeqpd (v2df, v2df)\n+v2df __builtin_ia32_comeqps (v2df, v2df)\n+v4sf __builtin_ia32_comeqsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comeqss (v4sf, v4sf)\n+v2df __builtin_ia32_comfalsepd (v2df, v2df)\n+v2df __builtin_ia32_comfalseps (v2df, v2df)\n+v4sf __builtin_ia32_comfalsesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comfalsess (v4sf, v4sf)\n+v2df __builtin_ia32_comgepd (v2df, v2df)\n+v2df __builtin_ia32_comgeps (v2df, v2df)\n+v4sf __builtin_ia32_comgesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comgess (v4sf, v4sf)\n+v2df __builtin_ia32_comgtpd (v2df, v2df)\n+v2df __builtin_ia32_comgtps (v2df, v2df)\n+v4sf __builtin_ia32_comgtsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comgtss (v4sf, v4sf)\n+v2df __builtin_ia32_comlepd (v2df, v2df)\n+v2df __builtin_ia32_comleps (v2df, v2df)\n+v4sf __builtin_ia32_comlesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comless (v4sf, v4sf)\n+v2df __builtin_ia32_comltpd (v2df, v2df)\n+v2df __builtin_ia32_comltps (v2df, v2df)\n+v4sf __builtin_ia32_comltsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comltss (v4sf, v4sf)\n+v2df __builtin_ia32_comnepd (v2df, v2df)\n+v2df __builtin_ia32_comneps (v2df, v2df)\n+v4sf __builtin_ia32_comnesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comness (v4sf, v4sf)\n+v2df __builtin_ia32_comordpd (v2df, v2df)\n+v2df __builtin_ia32_comordps (v2df, v2df)\n+v4sf __builtin_ia32_comordsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comordss (v4sf, v4sf)\n+v2df __builtin_ia32_comtruepd (v2df, v2df)\n+v2df __builtin_ia32_comtrueps (v2df, v2df)\n+v4sf __builtin_ia32_comtruesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comtruess (v4sf, v4sf)\n+v2df __builtin_ia32_comueqpd (v2df, v2df)\n+v2df __builtin_ia32_comueqps (v2df, v2df)\n+v4sf __builtin_ia32_comueqsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comueqss (v4sf, v4sf)\n+v2df __builtin_ia32_comugepd (v2df, v2df)\n+v2df __builtin_ia32_comugeps (v2df, v2df)\n+v4sf __builtin_ia32_comugesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comugess (v4sf, v4sf)\n+v2df __builtin_ia32_comugtpd (v2df, v2df)\n+v2df __builtin_ia32_comugtps (v2df, v2df)\n+v4sf __builtin_ia32_comugtsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comugtss (v4sf, v4sf)\n+v2df __builtin_ia32_comulepd (v2df, v2df)\n+v2df __builtin_ia32_comuleps (v2df, v2df)\n+v4sf __builtin_ia32_comulesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comuless (v4sf, v4sf)\n+v2df __builtin_ia32_comultpd (v2df, v2df)\n+v2df __builtin_ia32_comultps (v2df, v2df)\n+v4sf __builtin_ia32_comultsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comultss (v4sf, v4sf)\n+v2df __builtin_ia32_comunepd (v2df, v2df)\n+v2df __builtin_ia32_comuneps (v2df, v2df)\n+v4sf __builtin_ia32_comunesd (v4sf, v4sf)\n+v4sf __builtin_ia32_comuness (v4sf, v4sf)\n+v2df __builtin_ia32_comunordpd (v2df, v2df)\n+v2df __builtin_ia32_comunordps (v2df, v2df)\n+v4sf __builtin_ia32_comunordsd (v4sf, v4sf)\n+v4sf __builtin_ia32_comunordss (v4sf, v4sf)\n+v2df __builtin_ia32_fmaddpd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fmaddps (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_fmaddsd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fmaddss (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_fmsubpd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fmsubps (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_fmsubsd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fmsubss (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_fnmaddpd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fnmaddps (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_fnmaddsd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fnmaddss (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_fnmsubpd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fnmsubps (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_fnmsubsd (v2df, v2df, v2df)\n+v4sf __builtin_ia32_fnmsubss (v4sf, v4sf, v4sf)\n+v2df __builtin_ia32_frczpd (v2df)\n+v4sf __builtin_ia32_frczps (v4sf)\n+v2df __builtin_ia32_frczsd (v2df, v2df)\n+v4sf __builtin_ia32_frczss (v4sf, v4sf)\n+v2di __builtin_ia32_pcmov (v2di, v2di, v2di)\n+v2di __builtin_ia32_pcmov_v2di (v2di, v2di, v2di)\n+v4si __builtin_ia32_pcmov_v4si (v4si, v4si, v4si)\n+v8hi __builtin_ia32_pcmov_v8hi (v8hi, v8hi, v8hi)\n+v16qi __builtin_ia32_pcmov_v16qi (v16qi, v16qi, v16qi)\n+v2df __builtin_ia32_pcmov_v2df (v2df, v2df, v2df)\n+v4sf __builtin_ia32_pcmov_v4sf (v4sf, v4sf, v4sf)\n+v16qi __builtin_ia32_pcomeqb (v16qi, v16qi)\n+v8hi __builtin_ia32_pcomeqw (v8hi, v8hi)\n+v4si __builtin_ia32_pcomeqd (v4si, v4si)\n+v2di __builtin_ia32_pcomeqq (v2di, v2di)\n+v16qi __builtin_ia32_pcomequb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomequd (v4si, v4si)\n+v2di __builtin_ia32_pcomequq (v2di, v2di)\n+v8hi __builtin_ia32_pcomequw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomeqw (v8hi, v8hi)\n+v16qi __builtin_ia32_pcomfalseb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomfalsed (v4si, v4si)\n+v2di __builtin_ia32_pcomfalseq (v2di, v2di)\n+v16qi __builtin_ia32_pcomfalseub (v16qi, v16qi)\n+v4si __builtin_ia32_pcomfalseud (v4si, v4si)\n+v2di __builtin_ia32_pcomfalseuq (v2di, v2di)\n+v8hi __builtin_ia32_pcomfalseuw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomfalsew (v8hi, v8hi)\n+v16qi __builtin_ia32_pcomgeb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomged (v4si, v4si)\n+v2di __builtin_ia32_pcomgeq (v2di, v2di)\n+v16qi __builtin_ia32_pcomgeub (v16qi, v16qi)\n+v4si __builtin_ia32_pcomgeud (v4si, v4si)\n+v2di __builtin_ia32_pcomgeuq (v2di, v2di)\n+v8hi __builtin_ia32_pcomgeuw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomgew (v8hi, v8hi)\n+v16qi __builtin_ia32_pcomgtb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomgtd (v4si, v4si)\n+v2di __builtin_ia32_pcomgtq (v2di, v2di)\n+v16qi __builtin_ia32_pcomgtub (v16qi, v16qi)\n+v4si __builtin_ia32_pcomgtud (v4si, v4si)\n+v2di __builtin_ia32_pcomgtuq (v2di, v2di)\n+v8hi __builtin_ia32_pcomgtuw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomgtw (v8hi, v8hi)\n+v16qi __builtin_ia32_pcomleb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomled (v4si, v4si)\n+v2di __builtin_ia32_pcomleq (v2di, v2di)\n+v16qi __builtin_ia32_pcomleub (v16qi, v16qi)\n+v4si __builtin_ia32_pcomleud (v4si, v4si)\n+v2di __builtin_ia32_pcomleuq (v2di, v2di)\n+v8hi __builtin_ia32_pcomleuw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomlew (v8hi, v8hi)\n+v16qi __builtin_ia32_pcomltb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomltd (v4si, v4si)\n+v2di __builtin_ia32_pcomltq (v2di, v2di)\n+v16qi __builtin_ia32_pcomltub (v16qi, v16qi)\n+v4si __builtin_ia32_pcomltud (v4si, v4si)\n+v2di __builtin_ia32_pcomltuq (v2di, v2di)\n+v8hi __builtin_ia32_pcomltuw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomltw (v8hi, v8hi)\n+v16qi __builtin_ia32_pcomneb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomned (v4si, v4si)\n+v2di __builtin_ia32_pcomneq (v2di, v2di)\n+v16qi __builtin_ia32_pcomneub (v16qi, v16qi)\n+v4si __builtin_ia32_pcomneud (v4si, v4si)\n+v2di __builtin_ia32_pcomneuq (v2di, v2di)\n+v8hi __builtin_ia32_pcomneuw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomnew (v8hi, v8hi)\n+v16qi __builtin_ia32_pcomtrueb (v16qi, v16qi)\n+v4si __builtin_ia32_pcomtrued (v4si, v4si)\n+v2di __builtin_ia32_pcomtrueq (v2di, v2di)\n+v16qi __builtin_ia32_pcomtrueub (v16qi, v16qi)\n+v4si __builtin_ia32_pcomtrueud (v4si, v4si)\n+v2di __builtin_ia32_pcomtrueuq (v2di, v2di)\n+v8hi __builtin_ia32_pcomtrueuw (v8hi, v8hi)\n+v8hi __builtin_ia32_pcomtruew (v8hi, v8hi)\n+v4df __builtin_ia32_permpd (v2df, v2df, v16qi)\n+v4sf __builtin_ia32_permps (v4sf, v4sf, v16qi)\n+v4si __builtin_ia32_phaddbd (v16qi)\n+v2di __builtin_ia32_phaddbq (v16qi)\n+v8hi __builtin_ia32_phaddbw (v16qi)\n+v2di __builtin_ia32_phadddq (v4si)\n+v4si __builtin_ia32_phaddubd (v16qi)\n+v2di __builtin_ia32_phaddubq (v16qi)\n+v8hi __builtin_ia32_phaddubw (v16qi)\n+v2di __builtin_ia32_phaddudq (v4si)\n+v4si __builtin_ia32_phadduwd (v8hi)\n+v2di __builtin_ia32_phadduwq (v8hi)\n+v4si __builtin_ia32_phaddwd (v8hi)\n+v2di __builtin_ia32_phaddwq (v8hi)\n+v8hi __builtin_ia32_phsubbw (v16qi)\n+v2di __builtin_ia32_phsubdq (v4si)\n+v4si __builtin_ia32_phsubwd (v8hi)\n+v4si __builtin_ia32_pmacsdd (v4si, v4si, v4si)\n+v2di __builtin_ia32_pmacsdqh (v4si, v4si, v2di)\n+v2di __builtin_ia32_pmacsdql (v4si, v4si, v2di)\n+v4si __builtin_ia32_pmacssdd (v4si, v4si, v4si)\n+v2di __builtin_ia32_pmacssdqh (v4si, v4si, v2di)\n+v2di __builtin_ia32_pmacssdql (v4si, v4si, v2di)\n+v4si __builtin_ia32_pmacsswd (v8hi, v8hi, v4si)\n+v8hi __builtin_ia32_pmacssww (v8hi, v8hi, v8hi)\n+v4si __builtin_ia32_pmacswd (v8hi, v8hi, v4si)\n+v8hi __builtin_ia32_pmacsww (v8hi, v8hi, v8hi)\n+v4si __builtin_ia32_pmadcsswd (v8hi, v8hi, v4si)\n+v4si __builtin_ia32_pmadcswd (v8hi, v8hi, v4si)\n+v16qi __builtin_ia32_pperm (v16qi, v16qi, v16qi)\n+v16qi __builtin_ia32_protb (v16qi, v16qi)\n+v4si __builtin_ia32_protd (v4si, v4si)\n+v2di __builtin_ia32_protq (v2di, v2di)\n+v8hi __builtin_ia32_protw (v8hi, v8hi)\n+v16qi __builtin_ia32_pshab (v16qi, v16qi)\n+v4si __builtin_ia32_pshad (v4si, v4si)\n+v2di __builtin_ia32_pshaq (v2di, v2di)\n+v8hi __builtin_ia32_pshaw (v8hi, v8hi)\n+v16qi __builtin_ia32_pshlb (v16qi, v16qi)\n+v4si __builtin_ia32_pshld (v4si, v4si)\n+v2di __builtin_ia32_pshlq (v2di, v2di)\n+v8hi __builtin_ia32_pshlw (v8hi, v8hi)\n+@end smallexample\n+\n+The following builtin-in functions are avaialble when @option{-msse5}\n+is used.  The second argument must be an integer constant and generate\n+the machine instruction that is part of the name with the @samp{_imm}\n+suffix removed.\n+\n+@smallexample\n+v16qi __builtin_ia32_protb_imm (v16qi, int)\n+v4si __builtin_ia32_protd_imm (v4si, int)\n+v2di __builtin_ia32_protq_imm (v2di, int)\n+v8hi __builtin_ia32_protw_imm (v8hi, int)\n+@end smallexample\n+\n The following built-in functions are available when @option{-m3dnow} is used.\n All of them generate the machine instruction that is part of the name.\n "}, {"sha": "af58bfeb86e5a3288300bc1f8925ffbde87d4fc2", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 14, "deletions": 3, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -553,14 +553,15 @@ Objective-C and Objective-C++ Dialects}.\n -mno-wide-multiply  -mrtd  -malign-double @gol\n -mpreferred-stack-boundary=@var{num} -mcx16 -msahf -mrecip @gol\n -mmmx  -msse  -msse2 -msse3 -mssse3 -msse4.1 -msse4.2 -msse4 @gol\n--msse4a -m3dnow -mpopcnt -mabm @gol\n+-msse4a -m3dnow -mpopcnt -mabm -msse5 @gol\n -mthreads  -mno-align-stringops  -minline-all-stringops @gol\n -mpush-args  -maccumulate-outgoing-args  -m128bit-long-double @gol\n -m96bit-long-double  -mregparm=@var{num}  -msseregparm @gol\n -mveclibabi=@var{type} -mpc32 -mpc64 -mpc80 -mstackrealign @gol\n -momit-leaf-frame-pointer  -mno-red-zone -mno-tls-direct-seg-refs @gol\n -mcmodel=@var{code-model} @gol\n--m32  -m64 -mlarge-data-threshold=@var{num}}\n+-m32  -m64 -mlarge-data-threshold=@var{num} @gol\n+-mfused-madd -mno-fused-madd}\n \n @emph{IA-64 Options}\n @gccoptlist{-mbig-endian  -mlittle-endian  -mgnu-as  -mgnu-ld  -mno-pic @gol\n@@ -10438,6 +10439,8 @@ preferred alignment to @option{-mpreferred-stack-boundary=2}.\n @itemx -mno-sse4\n @item -msse4a\n @item -mno-sse4a\n+@item -msse5\n+@itemx -mno-sse5\n @item -m3dnow\n @itemx -mno-3dnow\n @item -mpopcnt\n@@ -10451,7 +10454,7 @@ preferred alignment to @option{-mpreferred-stack-boundary=2}.\n @opindex m3dnow\n @opindex mno-3dnow\n These switches enable or disable the use of instructions in the MMX,\n-SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4A, ABM or 3DNow! extended\n+SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4A, SSE5, ABM or 3DNow! extended\n instruction sets.\n These extensions are also available as built-in functions: see\n @ref{X86 Built-in Functions}, for details of the functions enabled and\n@@ -10573,6 +10576,14 @@ is legal depends on the operating system, and whether it maps the\n segment to cover the entire TLS area.\n \n For systems that use GNU libc, the default is on.\n+\n+@item -mfused-madd\n+@itemx -mno-fused-madd\n+@opindex mfused-madd\n+Enable automatic generation of fused floating point multiply-add instructions\n+if the ISA supports such instructions.  The -mfused-madd option is on by\n+default.  The fused multiply-add instructions have a different\n+rounding behavior compared to executing a multiply followed by an add.\n @end table\n \n These @samp{-m} switches are supported in addition to the above"}, {"sha": "35894f0de32088b071743ebea2f6a91567cf6001", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -1,3 +1,41 @@\n+2007-09-12  Dwarakanath Rajagopal  <dwarak.rajagopal@amd.com>\n+\t    Michael Meissner  <michael.meissner@amd.com>\n+\n+\t* gcc.target/i386/sse5-hadduX.c: Add support for SSE5 tests.\n+\t* gcc.target/i386/sse5-hsubX.c: Ditto.\n+\t* gcc.target/i386/sse5-permpX.c: Ditto.\n+\t* gcc.target/i386/sse5-haddX.c: Ditto.\n+\t* gcc.target/i386/sse5-maccXX.c: Ditto.\n+\t* gcc.target/i386/sse5-msubXX.c: Ditto.\n+\t* gcc.target/i386/sse5-nmaccXX.c: Ditto.\n+\t* gcc.target/i386/sse5-nmsubXX.c: Ditto.\n+\n+\t* gcc.target/i386/sse5-pcmov.c: New file to make sure the compiler\n+\toptimizes floating point conditional moves into the pcmov\n+\tinstruction on SSE5.\n+\t* gcc.target/i386/sse5-pcmov2.c: Ditto.\n+\n+\t* gcc.target/i386/sse5-ima-vector.c: New file to make sure the\n+\tcompiler optimizes vector 32-bit int (a*b)+c into pmacsdd on\n+\tSSE5.\n+\n+\t* gcc.target/i386/sse5-fma-vector.c: New file to make sure the\n+\tcompiler optimizes vector (a*b)+c into fmadd on SSE5.\n+\n+\t* gcc.target/i386/sse5-fma.c: New file to make sure the compiler\n+\toptimizes (a*b)+c into fmadd on SSE5.\n+\n+\t* gcc.target/i386/i386.exp (check_effective_target_sse5): Check\n+\twhether the SSE5 instructions can be generated.\n+\n+\t* gcc.target/i386/sse5-check.h: New. Add support for \n+\tSSE5 tests.\n+\n+\t* gcc.target/i386/sse-12.c: Include bmmintrin.h instead of\n+\tammintrin.h, and turn on -msse5 option instead of -msse4a.\n+\t* gcc.target/i386/sse-13.c: Ditto.\n+\t* gcc.target/i386/sse-14.c: Ditto.\n+\n 2007-09-12  John David Anglin  <dave.anglin@nrc-crnc.gc.ca>\n \n \tPR testsuite/33153"}, {"sha": "7cf13ab74438397ecc43f57ab450a2ace8d978ef", "filename": "gcc/testsuite/gcc.target/i386/i386.exp", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fi386.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fi386.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fi386.exp?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -64,6 +64,21 @@ proc check_effective_target_sse4a { } {\n     } \"-O2 -msse4a\" ]\n }\n \n+# Return 1 if sse5 instructions can be compiled.\n+proc check_effective_target_sse5 { } {\n+    return [check_no_compiler_messages sse5 object {\n+\ttypedef long long __m128i __attribute__ ((__vector_size__ (16)));\n+\ttypedef long long __v2di __attribute__ ((__vector_size__ (16)));\n+\n+\t__m128i _mm_maccs_epi16(__m128i __A, __m128i __B, __m128i __C)\n+\t{\n+\t    return (__m128i) __builtin_ia32_pmacssww ((__v2di)__A,\n+\t\t\t\t\t\t      (__v2di)__B,\n+\t\t\t\t\t\t      (__v2di)__C);\n+\t}\n+    } \"-O2 -msse5\" ]\n+}\n+\n # If a testcase doesn't have special options, use these.\n global DEFAULT_CFLAGS\n if ![info exists DEFAULT_CFLAGS] then {"}, {"sha": "395cdf7ed71b77712df4be4c716c4328ceff30f2", "filename": "gcc/testsuite/gcc.target/i386/sse-12.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-12.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-12.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-12.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -1,9 +1,9 @@\n /* Test that {,x,e,p,t,s,a}mmintrin.h, mm3dnow.h and mm_malloc.h are\n    usable with -O -std=c89 -pedantic-errors.  */\n-/* { dg-do compile } */\n-/* { dg-options \"-O -std=c89 -pedantic-errors -march=k8 -m3dnow -msse4.1 -msse4a\" } */\n+/* { dg-do compile { target i?86-*-* x86_64-*-* } } */\n+/* { dg-options \"-O -std=c89 -pedantic-errors -march=k8 -m3dnow -msse4.1 -msse5\" } */\n \n-#include <ammintrin.h>\n+#include <bmmintrin.h>\n #include <smmintrin.h>\n #include <mm3dnow.h>\n "}, {"sha": "b6c34e2447cf83773e34248707802bb62f709316", "filename": "gcc/testsuite/gcc.target/i386/sse-13.c", "status": "modified", "additions": 10, "deletions": 4, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -1,8 +1,8 @@\n-/* { dg-do compile } */\n-/* { dg-options \"-O2 -msse4.1 -msse4a\" } */\n+/* { dg-do compile { target i?86-*-* x86_64-*-* } } */\n+/* { dg-options \"-O2 -msse4.1 -msse5 \" } */\n \n /* Test that the intrinsics compile with optimization.  All of them are\n-   defined as inline functions in {,x,e,p,t,s,a}mmintrin.h that reference\n+   defined as inline functions in {,x,e,p,t,s,a,b}mmintrin.h that reference\n    the proper builtin functions.  Defining away \"static\" and \"__inline\"\n    results in all of them being compiled as proper functions.  */\n \n@@ -66,5 +66,11 @@\n #define __builtin_ia32_vec_ext_v4hi(A, N) __builtin_ia32_vec_ext_v4hi(A, 0)\n #define __builtin_ia32_shufps(A, B, N) __builtin_ia32_shufps(A, B, 0)\n \n-#include <ammintrin.h>\n+/* bmmintrin.h */\n+#define __builtin_ia32_protbi(A, B) __builtin_ia32_protbi(A,1)\n+#define __builtin_ia32_protwi(A, B) __builtin_ia32_protwi(A,1)\n+#define __builtin_ia32_protdi(A, B) __builtin_ia32_protdi(A,1)\n+#define __builtin_ia32_protqi(A, B) __builtin_ia32_protqi(A,1)\n+\n+#include <bmmintrin.h>\n #include <smmintrin.h>"}, {"sha": "bb51c20ddccd0c5b67887a76a67343c58baf7c31", "filename": "gcc/testsuite/gcc.target/i386/sse-14.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -1,5 +1,5 @@\n-/* { dg-do compile } */\n-/* { dg-options \"-O0 -msse4.1 -msse4a\" } */\n+/* { dg-do compile { target i?86-*-* x86_64-*-* } } */\n+/* { dg-options \"-O0 -msse4.1 -msse5\" } */\n \n /* Test that the intrinsics compile without optimization.  All of them are\n    defined as inline functions in {,x,e,p,t,s,a}mmintrin.h that reference\n@@ -9,5 +9,5 @@\n #define static\n #define __inline\n \n-#include <ammintrin.h>\n+#include <bmmintrin.h>\n #include <smmintrin.h>"}, {"sha": "e133ed884fa1beb6d3fc2c1a0f30837eacc25168", "filename": "gcc/testsuite/gcc.target/i386/sse5-check.h", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-check.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-check.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-check.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,20 @@\n+#include <stdlib.h>\n+\n+#include \"cpuid.h\"\n+\n+static void sse5_test (void);\n+\n+int\n+main ()\n+{\n+  unsigned int eax, ebx, ecx, edx;\n+ \n+  if (!__get_cpuid (0x80000001, &eax, &ebx, &ecx, &edx))\n+    return 0;\n+\n+  /* Run SSE5 test only if host has SSE5 support.  */\n+  if (ecx & bit_SSE5)\n+    sse5_test ();\n+\n+  exit (0);\n+}"}, {"sha": "59dc76515684f3af6d4e0678617ffbf770f35e93", "filename": "gcc/testsuite/gcc.target/i386/sse5-fma-vector.c", "status": "added", "additions": 92, "deletions": 0, "changes": 92, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-fma-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-fma-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-fma-vector.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,92 @@\n+/* Test that the compiler properly optimizes floating point multiply and add\n+   instructions vector into fmaddps on SSE5 systems.  */\n+\n+/* { dg-do compile { target x86_64-*-*} } */\n+/* { dg-options \"-O2 -msse5 -mfused-madd -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef float     __m128  __attribute__ ((__vector_size__ (16), __may_alias__));\n+typedef double    __m128d __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128 f_align;\n+  __m128d d_align;\n+  float f[SIZE];\n+  double d[SIZE];\n+} a, b, c, d;\n+\n+void\n+flt_mul_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.f[i] = (b.f[i] * c.f[i]) + d.f[i];\n+}\n+\n+void\n+dbl_mul_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.d[i] = (b.d[i] * c.d[i]) + d.d[i];\n+}\n+\n+void\n+flt_mul_sub (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.f[i] = (b.f[i] * c.f[i]) - d.f[i];\n+}\n+\n+void\n+dbl_mul_sub (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.d[i] = (b.d[i] * c.d[i]) - d.d[i];\n+}\n+\n+void\n+flt_neg_mul_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.f[i] = (-(b.f[i] * c.f[i])) + d.f[i];\n+}\n+\n+void\n+dbl_neg_mul_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.d[i] = (-(b.d[i] * c.d[i])) + d.d[i];\n+}\n+\n+int main ()\n+{\n+  flt_mul_add ();\n+  flt_mul_sub ();\n+  flt_neg_mul_add ();\n+\n+  dbl_mul_add ();\n+  dbl_mul_sub ();\n+  dbl_neg_mul_add ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"fmaddps\" } } */\n+/* { dg-final { scan-assembler \"fmaddpd\" } } */\n+/* { dg-final { scan-assembler \"fmsubps\" } } */\n+/* { dg-final { scan-assembler \"fmsubpd\" } } */\n+/* { dg-final { scan-assembler \"fnmaddps\" } } */\n+/* { dg-final { scan-assembler \"fnmaddpd\" } } */"}, {"sha": "598cda03c04c1b19108ca418b4d34909ad51d85f", "filename": "gcc/testsuite/gcc.target/i386/sse5-fma.c", "status": "added", "additions": 81, "deletions": 0, "changes": 81, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-fma.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-fma.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-fma.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,81 @@\n+/* Test that the compiler properly optimizes floating point multiply and add\n+   instructions into fmaddss, fmsubss, fnmaddss, fnmsubss on SSE5 systems.  */\n+\n+/* { dg-do compile { target x86_64-*-*} } */\n+/* { dg-options \"-O2 -msse5 -mfused-madd\" } */\n+\n+extern void exit (int);\n+\n+float\n+flt_mul_add (float a, float b, float c)\n+{\n+  return (a * b) + c;\n+}\n+\n+double\n+dbl_mul_add (double a, double b, double c)\n+{\n+  return (a * b) + c;\n+}\n+\n+float\n+flt_mul_sub (float a, float b, float c)\n+{\n+  return (a * b) - c;\n+}\n+\n+double\n+dbl_mul_sub (double a, double b, double c)\n+{\n+  return (a * b) - c;\n+}\n+\n+float\n+flt_neg_mul_add (float a, float b, float c)\n+{\n+  return (-(a * b)) + c;\n+}\n+\n+double\n+dbl_neg_mul_add (double a, double b, double c)\n+{\n+  return (-(a * b)) + c;\n+}\n+\n+float\n+flt_neg_mul_sub (float a, float b, float c)\n+{\n+  return (-(a * b)) - c;\n+}\n+\n+double\n+dbl_neg_mul_sub (double a, double b, double c)\n+{\n+  return (-(a * b)) - c;\n+}\n+\n+float  f[10] = { 2, 3, 4 };\n+double d[10] = { 2, 3, 4 };\n+\n+int main ()\n+{\n+  f[3] = flt_mul_add (f[0], f[1], f[2]);\n+  f[4] = flt_mul_sub (f[0], f[1], f[2]);\n+  f[5] = flt_neg_mul_add (f[0], f[1], f[2]);\n+  f[6] = flt_neg_mul_sub (f[0], f[1], f[2]);\n+\n+  d[3] = dbl_mul_add (d[0], d[1], d[2]);\n+  d[4] = dbl_mul_sub (d[0], d[1], d[2]);\n+  d[5] = dbl_neg_mul_add (d[0], d[1], d[2]);\n+  d[6] = dbl_neg_mul_sub (d[0], d[1], d[2]);\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"fmaddss\" } } */\n+/* { dg-final { scan-assembler \"fmaddsd\" } } */\n+/* { dg-final { scan-assembler \"fmsubss\" } } */\n+/* { dg-final { scan-assembler \"fmsubsd\" } } */\n+/* { dg-final { scan-assembler \"fnmaddss\" } } */\n+/* { dg-final { scan-assembler \"fnmaddsd\" } } */\n+/* { dg-final { scan-assembler \"fnmsubss\" } } */\n+/* { dg-final { scan-assembler \"fnmsubsd\" } } */"}, {"sha": "e605e070c126fe392ce5bc98a23708602f3a99d7", "filename": "gcc/testsuite/gcc.target/i386/sse5-haddX.c", "status": "added", "additions": 208, "deletions": 0, "changes": 208, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-haddX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-haddX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-haddX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,208 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+#define NUM 10\n+\n+union\n+{\n+  __m128i x[NUM];\n+  int8_t ssi[NUM * 16];\n+  int16_t si[NUM * 8];\n+  int32_t li[NUM * 4];\n+  int64_t lli[NUM * 2];\n+} dst, res, src1;\n+\n+static void\n+init_sbyte ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 16; i++)\n+    src1.ssi[i] = i;\n+}\n+\n+static void\n+init_sword ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 8; i++)\n+    src1.si[i] = i;\n+}\n+\n+\n+static void\n+init_sdword ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 4; i++)\n+    src1.li[i] = i;\n+}\n+\n+static int \n+check_sbyte2word ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 16; i = i + 16)\n+    {\n+      for (j = 0; j < 8; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.si[s] = src1.ssi[t] + src1.ssi[t + 1] ;\n+\t  if (res.si[s] != dst.si[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static int \n+check_sbyte2dword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 16; i = i + 16)\n+    {\n+      for (j = 0; j < 4; j++)\n+\t{\n+\t  t = i + (4 * j);\n+\t  s = (i / 4) + j;\n+\t  res.li[s] = (src1.ssi[t] + src1.ssi[t + 1]) + (src1.ssi[t + 2]\n+\t              + src1.ssi[t + 3]); \n+\t  if (res.li[s] != dst.li[s]) \n+\t    check_fails++;\n+\t}\n+    }\n+  return check_fails++;\n+}\n+\n+static int\n+check_sbyte2qword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 16; i = i + 16)\n+    {\n+      for (j = 0; j < 2; j++)\n+\t{\n+\t  t = i + (8 * j);\n+\t  s = (i / 8) + j;\n+\t  res.lli[s] = ((src1.ssi[t] + src1.ssi[t + 1]) + (src1.ssi[t + 2] \n+\t\t       + src1.ssi[t + 3])) + ((src1.ssi[t + 4] + src1.ssi[t +5])\n+\t               + (src1.ssi[t + 6] + src1.ssi[t + 7])); \n+\t  if (res.lli[s] != dst.lli[s]) \n+\t    check_fails++;\n+\t}\n+    }\n+  return check_fails++;\n+}\n+\n+static int\n+check_sword2dword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < (NUM * 8); i = i + 8)\n+    {\n+      for (j = 0; j < 4; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.li[s] = src1.si[t] + src1.si[t + 1] ;\n+\t  if (res.li[s] != dst.li[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static int \n+check_sword2qword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 8; i = i + 8)\n+    {\n+      for (j = 0; j < 2; j++)\n+\t{\n+\t  t = i + (4 * j);\n+\t  s = (i / 4) + j;\n+\t  res.lli[s] = (src1.si[t] + src1.si[t + 1]) + (src1.si[t + 2]\n+\t               + src1.si[t + 3]); \n+\t  if (res.lli[s] != dst.lli[s]) \n+\t    check_fails++;\n+\t}\n+    }\n+  return check_fails++;\n+}\n+\n+static int\n+check_dword2qword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < (NUM * 4); i = i + 4)\n+    {\n+      for (j = 0; j < 2; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.lli[s] = src1.li[t] + src1.li[t + 1] ;\n+\t  if (res.lli[s] != dst.lli[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  \n+  /* Check haddbw */\n+  init_sbyte ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddw_epi8 (src1.x[i]);\n+  \n+  if (check_sbyte2word())\n+  abort ();\n+  \n+  /* Check haddbd */\n+  for (i = 0; i < (NUM ); i++)\n+    dst.x[i] = _mm_haddd_epi8 (src1.x[i]);\n+  \n+  if (check_sbyte2dword())\n+    abort (); \n+  \n+  /* Check haddbq */\n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddq_epi8 (src1.x[i]);\n+  \n+  if (check_sbyte2qword())\n+    abort ();\n+\n+  /* Check haddwd */\n+  init_sword ();\n+\n+  for (i = 0; i < (NUM ); i++)\n+    dst.x[i] = _mm_haddd_epi16 (src1.x[i]);\n+  \n+  if (check_sword2dword())\n+    abort (); \n+   \n+  /* Check haddbwq */\n+ \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddq_epi16 (src1.x[i]);\n+  \n+  if (check_sword2qword())\n+    abort ();\n+ \n+  /* Check haddq */\n+  init_sdword ();\n+\n+    for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddq_epi32 (src1.x[i]);\n+  \n+  if (check_dword2qword())\n+    abort ();\n+}"}, {"sha": "a55fb8a527d5ed7762a777e4c1c56f79a768702c", "filename": "gcc/testsuite/gcc.target/i386/sse5-hadduX.c", "status": "added", "additions": 207, "deletions": 0, "changes": 207, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-hadduX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-hadduX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-hadduX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,207 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+#define NUM 10\n+\n+union\n+{\n+  __m128i x[NUM];\n+  unsigned char  ssi[NUM * 16];\n+  unsigned short si[NUM * 8];\n+  unsigned int li[NUM * 4];\n+  unsigned long long  lli[NUM * 2];\n+} dst, res, src1;\n+\n+static void\n+init_byte ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 16; i++)\n+    src1.ssi[i] = i;\n+}\n+\n+static void\n+init_word ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 8; i++)\n+    src1.si[i] = i;\n+}\n+\n+\n+static void\n+init_dword ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 4; i++)\n+    src1.li[i] = i;\n+}\n+\n+static int \n+check_byte2word ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 16; i = i + 16)\n+    {\n+      for (j = 0; j < 8; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.si[s] = src1.ssi[t] + src1.ssi[t + 1] ;\n+\t  if (res.si[s] != dst.si[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static int \n+check_byte2dword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 16; i = i + 16)\n+    {\n+      for (j = 0; j < 4; j++)\n+\t{\n+\t  t = i + (4 * j);\n+\t  s = (i / 4) + j;\n+\t  res.li[s] = (src1.ssi[t] + src1.ssi[t + 1]) + (src1.ssi[t + 2]\n+\t              + src1.ssi[t + 3]); \n+\t  if (res.li[s] != dst.li[s]) \n+\t    check_fails++;\n+\t}\n+    }\n+  return check_fails++;\n+}\n+\n+static int\n+check_byte2qword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 16; i = i + 16)\n+    {\n+      for (j = 0; j < 2; j++)\n+\t{\n+\t  t = i + (8 * j);\n+\t  s = (i / 8) + j;\n+\t  res.lli[s] = ((src1.ssi[t] + src1.ssi[t + 1]) + (src1.ssi[t + 2] \n+\t\t       + src1.ssi[t + 3])) + ((src1.ssi[t + 4] + src1.ssi[t +5])\n+\t               + (src1.ssi[t + 6] + src1.ssi[t + 7])); \n+\t  if (res.lli[s] != dst.lli[s]) \n+\t    check_fails++;\n+\t}\n+    }\n+  return check_fails++;\n+}\n+\n+static int\n+check_word2dword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < (NUM * 8); i = i + 8)\n+    {\n+      for (j = 0; j < 4; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.li[s] = src1.si[t] + src1.si[t + 1] ;\n+\t  if (res.li[s] != dst.li[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static int \n+check_word2qword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 8; i = i + 8)\n+    {\n+      for (j = 0; j < 2; j++)\n+\t{\n+\t  t = i + (4 * j);\n+\t  s = (i / 4) + j;\n+\t  res.lli[s] = (src1.si[t] + src1.si[t + 1]) + (src1.si[t + 2]\n+\t               + src1.si[t + 3]); \n+\t  if (res.lli[s] != dst.lli[s]) \n+\t    check_fails++;\n+\t}\n+    }\n+  return check_fails++;\n+}\n+\n+static int\n+check_dword2qword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < (NUM * 4); i = i + 4)\n+    {\n+      for (j = 0; j < 2; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.lli[s] = src1.li[t] + src1.li[t + 1] ;\n+\t  if (res.lli[s] != dst.lli[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  \n+  /* Check haddubw */\n+  init_byte ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddw_epu8 (src1.x[i]);\n+  \n+  if (check_byte2word())\n+  abort ();\n+  \n+  /* Check haddubd */\n+  for (i = 0; i < (NUM ); i++)\n+    dst.x[i] = _mm_haddd_epu8 (src1.x[i]);\n+  \n+  if (check_byte2dword())\n+    abort (); \n+  \n+  /* Check haddubq */\n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddq_epu8 (src1.x[i]);\n+  \n+  if (check_byte2qword())\n+    abort ();\n+\n+  /* Check hadduwd */\n+  init_word ();\n+\n+  for (i = 0; i < (NUM ); i++)\n+    dst.x[i] = _mm_haddd_epu16 (src1.x[i]);\n+  \n+  if (check_word2dword())\n+    abort (); \n+   \n+  /* Check haddbuwq */\n+ \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddq_epu16 (src1.x[i]);\n+  \n+  if (check_word2qword())\n+    abort ();\n+ \n+  /* Check hadudq */\n+  init_dword ();\n+    for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_haddq_epu32 (src1.x[i]);\n+  \n+  if (check_dword2qword())\n+    abort ();\n+}"}, {"sha": "03c7f79084e9f94b7c296af9aed2f1650b910d2f", "filename": "gcc/testsuite/gcc.target/i386/sse5-hsubX.c", "status": "added", "additions": 128, "deletions": 0, "changes": 128, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-hsubX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-hsubX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-hsubX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,128 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+#define NUM 10\n+\n+union\n+{\n+  __m128i x[NUM];\n+  int8_t ssi[NUM * 16];\n+  int16_t si[NUM * 8];\n+  int32_t li[NUM * 4];\n+  int64_t lli[NUM * 2];\n+} dst, res, src1;\n+\n+static void\n+init_sbyte ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 16; i++)\n+    src1.ssi[i] = i;\n+}\n+\n+static void\n+init_sword ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 8; i++)\n+    src1.si[i] = i;\n+}\n+\n+\n+static void\n+init_sdword ()\n+{\n+  int i;\n+  for (i=0; i < NUM * 4; i++)\n+    src1.li[i] = i;\n+}\n+\n+static int \n+check_sbyte2word ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < NUM * 16; i = i + 16)\n+    {\n+      for (j = 0; j < 8; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.si[s] = src1.ssi[t] - src1.ssi[t + 1] ;\n+\t  if (res.si[s] != dst.si[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static int\n+check_sword2dword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < (NUM * 8); i = i + 8)\n+    {\n+      for (j = 0; j < 4; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.li[s] = src1.si[t] - src1.si[t + 1] ;\n+\t  if (res.li[s] != dst.li[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static int\n+check_dword2qword ()\n+{\n+  int i, j, s, t, check_fails = 0;\n+  for (i = 0; i < (NUM * 4); i = i + 4)\n+    {\n+      for (j = 0; j < 2; j++)\n+\t{\n+\t  t = i + (2 * j);\n+\t  s = (i / 2) + j;\n+\t  res.lli[s] = src1.li[t] - src1.li[t + 1] ;\n+\t  if (res.lli[s] != dst.lli[s]) \n+\t    check_fails++;\t\n+\t}\n+    }\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  \n+  /* Check hsubbw */\n+  init_sbyte ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_hsubw_epi8 (src1.x[i]);\n+  \n+  if (check_sbyte2word())\n+  abort ();\n+  \n+\n+  /* Check hsubwd */\n+  init_sword ();\n+\n+  for (i = 0; i < (NUM ); i++)\n+    dst.x[i] = _mm_hsubd_epi16 (src1.x[i]);\n+  \n+  if (check_sword2dword())\n+    abort (); \n+   \n+   /* Check hsubdq */\n+  init_sdword ();\n+    for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_hsubq_epi32 (src1.x[i]);\n+  \n+  if (check_dword2qword())\n+    abort ();\n+}"}, {"sha": "260291d2985ddb84868ae8e7d9749eeec1f57ca5", "filename": "gcc/testsuite/gcc.target/i386/sse5-ima-vector.c", "status": "added", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-ima-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-ima-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-ima-vector.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,33 @@\n+/* Test that the compiler properly optimizes vector 32-bit integer point\n+   multiply and add instructions vector into pmacsdd on SSE5 systems.  */\n+\n+/* { dg-do compile { target x86_64-*-*} } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long long __m128i __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i align;\n+  int i[SIZE];\n+} a, b, c, d;\n+\n+void\n+int_mul_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.i[i] = (b.i[i] * c.i[i]) + d.i[i];\n+}\n+\n+int main ()\n+{\n+  int_mul_add ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pmacsdd\" } } */"}, {"sha": "9603d53ea68c71e73413c9b18469e7a9b0b55a4e", "filename": "gcc/testsuite/gcc.target/i386/sse5-maccXX.c", "status": "added", "additions": 140, "deletions": 0, "changes": 140, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-maccXX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-maccXX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-maccXX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,140 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+#define NUM 20\n+\n+union\n+{\n+  __m128 x[NUM];\n+  float f[NUM * 4];\n+  __m128d y[NUM];\n+  double d[NUM * 2];\n+} dst, res, src1, src2, src3;\n+\n+\n+/* Note that in macc*,msub*,mnmacc* and mnsub* instructions, the intermdediate \n+   product is not rounded, only the addition is rounded. */\n+\n+static void\n+init_maccps ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.f[i] = i;\n+      src2.f[i] = i + 10;\n+      src3.f[i] = i + 20;\n+    }\n+}\n+\n+static void\n+init_maccpd ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.d[i] = i;\n+      src2.d[i] = i + 10;\n+      src3.d[i] = i + 20;\n+    }\n+}\n+\n+static int\n+check_maccps ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i = i + 4)\n+    for (j = 0; j < 4; j++)\n+      {\n+\tres.f[i + j] = (src1.f[i + j] * src2.f[i + j]) + src3.f[i + j];\n+\tif (dst.f[i + j] != res.f[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+static int\n+check_maccpd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    for (j = 0; j < 2; j++)\n+      {\n+\tres.d[i + j] = (src1.d[i + j] * src2.d[i + j]) + src3.d[i + j];\n+\tif (dst.d[i + j] != res.d[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+\n+static int\n+check_maccss ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i= i + 4)\n+    {\n+      res.f[i] = (src1.f[i] * src2.f[i]) + src3.f[i];\n+      if (dst.f[i] != res.f[i]) \n+\tcheck_fails++;\n+    }\t\n+  return check_fails++;\n+}\n+\n+static int\n+check_maccsd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    {\n+      res.d[i] = (src1.d[i] * src2.d[i]) + src3.d[i];\n+      if (dst.d[i] != res.d[i]) \n+\tcheck_fails++;\n+    }\n+  return check_fails++;\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  \n+  /* Check maccps */\n+  init_maccps ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_macc_ps (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_maccps ()) \n+    abort ();\n+  \n+  /* check maccss */\n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_macc_ss (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_maccss ()) \n+    abort ();\n+  \n+  /* Check maccpd */\n+  init_maccpd ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_macc_pd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_maccpd ()) \n+    abort ();\n+  \n+  /* Check maccps */\n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_macc_sd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_maccsd ()) \n+    abort ();\n+  \n+}"}, {"sha": "151e8c6e51f04500b09dfb30f23b3d7f5f31a5f5", "filename": "gcc/testsuite/gcc.target/i386/sse5-msubXX.c", "status": "added", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-msubXX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-msubXX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-msubXX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,139 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+#define NUM 20\n+\n+union\n+{\n+  __m128 x[NUM];\n+  float f[NUM * 4];\n+  __m128d y[NUM];\n+  double d[NUM * 2];\n+} dst, res, src1, src2, src3;\n+\n+/* Note that in macc*,msub*,mnmacc* and mnsub* instructions, the intermdediate \n+   product is not rounded, only the addition is rounded. */\n+\n+static void\n+init_msubps ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.f[i] = i;\n+      src2.f[i] = i + 10;\n+      src3.f[i] = i + 20;\n+    }\n+}\n+\n+static void\n+init_msubpd ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.d[i] = i;\n+      src2.d[i] = i + 10;\n+      src3.d[i] = i + 20;\n+    }\n+}\n+\n+static int\n+check_msubps ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i = i + 4)\n+    for (j = 0; j < 4; j++)\n+      {\n+\tres.f[i + j] = (src1.f[i + j] * src2.f[i + j]) - src3.f[i + j];\n+\tif (dst.f[i + j] != res.f[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+static int\n+check_msubpd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    for (j = 0; j < 2; j++)\n+      {\n+\tres.d[i + j] = (src1.d[i + j] * src2.d[i + j]) - src3.d[i + j];\n+\tif (dst.d[i + j] != res.d[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+\n+static int\n+check_msubss ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i = i + 4)\n+    {\n+      res.f[i] = (src1.f[i] * src2.f[i]) - src3.f[i];\n+      if (dst.f[i] != res.f[i]) \n+\tcheck_fails++;\n+    }\t\n+  return check_fails++;\n+}\n+\n+static int\n+check_msubsd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    {\n+      res.d[i] = (src1.d[i] * src2.d[i]) - src3.d[i];\n+      if (dst.d[i] != res.d[i]) \n+\tcheck_fails++;\n+    }\n+  return check_fails++;\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  \n+  /* Check msubps */\n+  init_msubps ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_msub_ps (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_msubps ()) \n+    abort ();\n+  \n+  /* check msubss */\n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_msub_ss (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_msubss ()) \n+    abort ();\n+  \n+  /* Check msubpd */\n+  init_msubpd ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_msub_pd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_msubpd ()) \n+    abort ();\n+  \n+  /* Check msubps */\n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_msub_sd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_msubsd ()) \n+    abort ();\n+  \n+}"}, {"sha": "c5ca2bf7d1eb425d09b04fec1ca2f2c5fcf9411c", "filename": "gcc/testsuite/gcc.target/i386/sse5-nmaccXX.c", "status": "added", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-nmaccXX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-nmaccXX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-nmaccXX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,139 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+#define NUM 20\n+\n+union\n+{\n+  __m128 x[NUM];\n+  float f[NUM * 4];\n+  __m128d y[NUM];\n+  double d[NUM * 2];\n+} dst, res, src1, src2, src3;\n+\n+/* Note that in macc*,msub*,mnmacc* and mnsub* instructions, the intermdediate \n+   product is not rounded, only the addition is rounded. */\n+\n+static void\n+init_nmaccps ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.f[i] = i;\n+      src2.f[i] = i + 10;\n+      src3.f[i] = i + 20;\n+    }\n+}\n+\n+static void\n+init_nmaccpd ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.d[i] = i;\n+      src2.d[i] = i + 10;\n+      src3.d[i] = i + 20;\n+    }\n+}\n+\n+static int\n+check_nmaccps ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i = i + 4)\n+    for (j = 0; j < 4; j++)\n+      {\n+\tres.f[i + j] = - (src1.f[i + j] * src2.f[i + j]) + src3.f[i + j];\n+\tif (dst.f[i + j] != res.f[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+static int\n+check_nmaccpd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    for (j = 0; j < 2; j++)\n+      {\n+\tres.d[i + j] = - (src1.d[i + j] * src2.d[i + j]) + src3.d[i + j];\n+\tif (dst.d[i + j] != res.d[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+\n+static int\n+check_nmaccss ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i = i + 4)\n+    {\n+      res.f[i] = - (src1.f[i] * src2.f[i]) + src3.f[i];\n+      if (dst.f[i] != res.f[i]) \n+\tcheck_fails++;\n+    }\t\n+  return check_fails++;\n+}\n+\n+static int\n+check_nmaccsd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    {\n+      res.d[i] = - (src1.d[i] * src2.d[i]) + src3.d[i];\n+      if (dst.d[i] != res.d[i]) \n+\tcheck_fails++;\n+    }\n+  return check_fails++;\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  \n+  /* Check nmaccps */\n+  init_nmaccps ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_nmacc_ps (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_nmaccps ()) \n+    abort ();\n+  \n+  /* check nmaccss */\n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_nmacc_ss (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_nmaccss ()) \n+    abort ();\n+  \n+  /* Check nmaccpd */\n+  init_nmaccpd ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_nmacc_pd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_nmaccpd ()) \n+    abort ();\n+  \n+  /* Check nmaccps */\n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_nmacc_sd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_nmaccsd ()) \n+    abort ();\n+  \n+}"}, {"sha": "acf19f9742df82112b22f2953f094ec6d6e363ad", "filename": "gcc/testsuite/gcc.target/i386/sse5-nmsubXX.c", "status": "added", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-nmsubXX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-nmsubXX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-nmsubXX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,139 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+#define NUM 20\n+\n+union\n+{\n+  __m128 x[NUM];\n+  float f[NUM * 4];\n+  __m128d y[NUM];\n+  double d[NUM * 2];\n+} dst, res, src1, src2, src3;\n+\n+/* Note that in macc*,msub*,mnmacc* and mnsub* instructions, the intermdediate \n+   product is not rounded, only the addition is rounded. */\n+\n+static void\n+init_nmsubps ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.f[i] = i;\n+      src2.f[i] = i + 10;\n+      src3.f[i] = i + 20;\n+    }\n+}\n+\n+static void\n+init_nmsubpd ()\n+{\n+  int i;\n+  for (i = 0; i < NUM * 4; i++)\n+    {\n+      src1.d[i] = i;\n+      src2.d[i] = i + 10;\n+      src3.d[i] = i + 20;\n+    }\n+}\n+\n+static int\n+check_nmsubps ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i = i + 4)\n+    for (j = 0; j < 4; j++)\n+      {\n+\tres.f[i + j] = - (src1.f[i + j] * src2.f[i + j]) - src3.f[i + j];\n+\tif (dst.f[i + j] != res.f[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+static int\n+check_nmsubpd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    for (j = 0; j < 2; j++)\n+      {\n+\tres.d[i + j] = - (src1.d[i + j] * src2.d[i + j]) - src3.d[i + j];\n+\tif (dst.d[i + j] != res.d[i + j]) \n+\t  check_fails++;\n+      }\n+  return check_fails++;\n+}\n+\n+\n+static int\n+check_nmsubss ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 4; i = i + 4)\n+    {\n+      res.f[i] = - (src1.f[i] * src2.f[i]) - src3.f[i];\n+      if (dst.f[i] != res.f[i]) \n+\tcheck_fails++;\n+    }\t\n+  return check_fails++;\n+}\n+\n+static int\n+check_nmsubsd ()\n+{\n+  int i, j, check_fails = 0;\n+  for (i = 0; i < NUM * 2; i = i + 2)\n+    {\n+      res.d[i] = - (src1.d[i] * src2.d[i]) - src3.d[i];\n+      if (dst.d[i] != res.d[i]) \n+\tcheck_fails++;\n+    }\n+  return check_fails++;\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  \n+  /* Check nmsubps */\n+  init_nmsubps ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_nmsub_ps (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_nmsubps (&dst.x[i], &src1.f[i * 4], &src2.f[i * 4], &src3.f[i * 4])) \n+    abort ();\n+  \n+  /* check nmsubss */\n+  for (i = 0; i < NUM; i++)\n+    dst.x[i] = _mm_nmsub_ss (src1.x[i], src2.x[i], src3.x[i]);\n+  \n+  if (check_nmsubss (&dst.x[i], &src1.f[i * 4], &src2.f[i * 4], &src3.f[i * 4])) \n+    abort ();\n+  \n+  /* Check nmsubpd */\n+  init_nmsubpd ();\n+  \n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_nmsub_pd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_nmsubpd (&dst.y[i], &src1.d[i * 2], &src2.d[i * 2], &src3.d[i * 2])) \n+    abort ();\n+  \n+  /* Check nmsubps */\n+  for (i = 0; i < NUM; i++)\n+    dst.y[i] = _mm_nmsub_sd (src1.y[i], src2.y[i], src3.y[i]);\n+  \n+  if (check_nmsubsd (&dst.y[i], &src1.d[i * 2], &src2.d[i * 2], &src3.d[i * 2])) \n+    abort ();\n+  \n+}"}, {"sha": "3bc2e5dbbda0bd8b753a58d10a70fa87d20870e4", "filename": "gcc/testsuite/gcc.target/i386/sse5-pcmov.c", "status": "added", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-pcmov.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-pcmov.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-pcmov.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,22 @@\n+/* Test that the compiler properly optimizes conditional floating point moves\n+   into the pcmov instruction on SSE5 systems.  */\n+\n+/* { dg-do compile { target x86_64-*-*} } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+extern void exit (int);\n+\n+double dbl_test (double a, double b, double c, double d)\n+{\n+  return (a > b) ? c : d;\n+}\n+\n+double dbl_a = 1, dbl_b = 2, dbl_c = 3, dbl_d = 4, dbl_e;\n+\n+int main()\n+{\n+  dbl_e = dbl_test (dbl_a, dbl_b, dbl_c, dbl_d);\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pcmov\" } } */"}, {"sha": "0bb366ce0c96708026bee7f4520472a5151a5e91", "filename": "gcc/testsuite/gcc.target/i386/sse5-pcmov2.c", "status": "added", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-pcmov2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-pcmov2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-pcmov2.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,22 @@\n+/* Test that the compiler properly optimizes conditional floating point moves\n+   into the pcmov instruction on SSE5 systems.  */\n+\n+/* { dg-do compile { target x86_64-*-*} } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+extern void exit (int);\n+\n+float flt_test (float a, float b, float c, float d)\n+{\n+  return (a > b) ? c : d;\n+}\n+\n+float flt_a = 1, flt_b = 2, flt_c = 3, flt_d = 4, flt_e;\n+\n+int main()\n+{\n+  flt_e = flt_test (flt_a, flt_b, flt_c, flt_d);\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pcmov\" } } */"}, {"sha": "d83aa58338e288a43d3a45541153fefb550b1300", "filename": "gcc/testsuite/gcc.target/i386/sse5-permpX.c", "status": "added", "additions": 120, "deletions": 0, "changes": 120, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-permpX.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-permpX.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-permpX.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -0,0 +1,120 @@\n+/* { dg-do run { target i?86-*-* x86_64-*-* } } */\n+/* { dg-require-effective-target sse5 } */\n+/* { dg-options \"-O2 -msse5\" } */\n+\n+#include \"sse5-check.h\"\n+\n+#include <bmmintrin.h>\n+#include <string.h>\n+\n+union\n+{\n+  __m128 x[2];\n+  __m128d y[2];\n+  __m128i z[2];\n+  float f[8];\n+  double d[4];\n+  int i[8];\n+  long li[4];\n+} dst, res, src1, src2, src3;\n+\n+\n+static void\n+init_ddata ()\n+{\n+  int i;\n+  for (i = 0; i < 4; i++)\n+    {\n+      src1.d[i] = i;\n+      src2.d[i] = i + 2;\n+    }\n+ \n+  src3.li[0] = 3;\n+  src3.li[1] = 0;\n+  src3.li[2] = 1;\n+  src3.li[3] = 2;\n+\n+  res.d[0] = 3.0;\n+  res.d[1] = 0.0;\n+  res.d[2] = 3.0;\n+  res.d[3] = 4.0;\n+}\n+\n+\n+static void \n+init_fdata ()\n+{\n+  int i;\n+  for (i = 0; i < 8; i++)\n+    {\n+      src1.f[i] = i;\n+      src2.f[i] = i + 2;\n+    }\n+\n+  src3.i[0] = 7;\n+  src3.i[1] = 5;\n+  src3.i[2] = 1;\n+  src3.i[3] = 2;\n+  src3.i[4] = 0;\n+  src3.i[5] = 4;\n+  src3.i[6] = 3;\n+  src3.i[7] = 6; \n+\n+  res.f[0] = 5.0;\n+  res.f[1] = 3.0;\n+  res.f[2] = 1.0;\n+  res.f[3] = 2.0;\n+  res.f[4] = 4.0;\n+  res.f[5] = 6.0;\n+  res.f[6] = 7.0;\n+  res.f[7] = 8.0;\n+}\n+\n+static int\n+check_permpd ()\n+{\n+  int i, check_fails = 0;\n+\n+  for (i = 0; i < 4; i++)\n+    {\n+      if (res.d[i] != dst.d[i])\n+\tcheck_fails++;\n+    }\n+  return check_fails++;\n+}\n+\n+static int\n+check_permps ()\n+{\n+  int i, check_fails = 0;\n+\n+  for (i = 0; i < 8; i++)\n+    {\n+      if (res.f[i] != dst.f[i])\n+\tcheck_fails++;\n+    }\n+  return check_fails++;\n+}\n+\n+static void\n+sse5_test (void)\n+{\n+  int i;\n+  init_ddata();\n+\n+  for (i = 0; i < 2; i++)\n+    dst.y[i] = _mm_perm_pd (src1.y[i], src2.y[i], src3.z[i]);\n+  \n+  if (check_permpd ())\n+    abort ();\n+  \n+  init_fdata();\n+  \n+  for (i = 0; i < 2; i++)\n+    dst.x[i] = _mm_perm_ps (src1.x[i], src2.x[i], src3.z[i]);\n+   \n+  if (check_permps ())\n+    abort (); \n+}\n+\n+"}, {"sha": "59c17c7e10a1800f409430bbde660ac6a5cd3b84", "filename": "gcc/tree.c", "status": "modified", "additions": 52, "deletions": 0, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -8700,4 +8700,56 @@ call_expr_arglist (tree exp)\n   return arglist;\n }\n \n+/* Return true if TYPE has a variable argument list.  */\n+\n+bool\n+stdarg_p (tree fntype)\n+{\n+  function_args_iterator args_iter;\n+  tree n = NULL_TREE, t;\n+\n+  if (!fntype)\n+    return false;\n+\n+  FOREACH_FUNCTION_ARGS(fntype, t, args_iter)\n+    {\n+      n = t;\n+    }\n+\n+  return n != NULL_TREE && n != void_type_node;\n+}\n+\n+/* Return true if TYPE has a prototype.  */\n+\n+bool\n+prototype_p (tree fntype)\n+{\n+  tree t;\n+\n+  gcc_assert (fntype != NULL_TREE);\n+\n+  t = TYPE_ARG_TYPES (fntype);\n+  return (t != NULL_TREE);\n+}\n+\n+/* Return the number of arguments that a function has.  */\n+\n+int\n+function_args_count (tree fntype)\n+{\n+  function_args_iterator args_iter;\n+  tree t;\n+  int num = 0;\n+\n+  if (fntype)\n+    {\n+      FOREACH_FUNCTION_ARGS(fntype, t, args_iter)\n+\t{\n+\t  num++;\n+\t}\n+    }\n+\n+  return num;\n+}\n+\n #include \"gt-tree.h\""}, {"sha": "11a74f3c2244e9ca6c22b5653db9fd353d158993", "filename": "gcc/tree.h", "status": "modified", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04e1d06b795dc7dfa11be5e0ee04467a28e105dd/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=04e1d06b795dc7dfa11be5e0ee04467a28e105dd", "patch": "@@ -4610,6 +4610,65 @@ extern GTY(()) tree current_function_decl;\n \n /* Nonzero means a FUNC_BEGIN label was emitted.  */\n extern GTY(()) const char * current_function_func_begin_label;\n+\f\n+/* Iterator for going through the function arguments.  */\n+typedef struct {\n+  tree fntype;\t\t\t/* function type declaration */\n+  tree next;\t\t\t/* TREE_LIST pointing to the next argument */\n+} function_args_iterator;\n+\n+/* Initialize the iterator I with arguments from function FNDECL  */\n+\n+static inline void\n+function_args_iter_init (function_args_iterator *i, tree fntype)\n+{\n+  i->fntype = fntype;\n+  i->next = TYPE_ARG_TYPES (fntype);\n+}\n+\n+/* Return a pointer that holds the next argument if there are more arguments to\n+   handle, otherwise return NULL.  */\n+\n+static inline tree *\n+function_args_iter_cond_ptr (function_args_iterator *i)\n+{\n+  return (i->next) ? &TREE_VALUE (i->next) : NULL;\n+}\n+\n+/* Return the next argument if there are more arguments to handle, otherwise\n+   return NULL.  */\n+\n+static inline tree\n+function_args_iter_cond (function_args_iterator *i)\n+{\n+  return (i->next) ? TREE_VALUE (i->next) : NULL_TREE;\n+}\n+\n+/* Advance to the next argument.  */\n+static inline void\n+function_args_iter_next (function_args_iterator *i)\n+{\n+  gcc_assert (i->next != NULL_TREE);\n+  i->next = TREE_CHAIN (i->next);\n+}\n+\n+/* Loop over all function arguments of FNTYPE.  In each iteration, PTR is set\n+   to point to the next tree element.  ITER is an instance of\n+   function_args_iterator used to iterate the arguments.  */\n+#define FOREACH_FUNCTION_ARGS_PTR(FNTYPE, PTR, ITER)\t\t\t\\\n+  for (function_args_iter_init (&(ITER), (FNTYPE));\t\t\t\\\n+       (PTR = function_args_iter_cond_ptr (&(ITER))) != NULL;\t\t\\\n+       function_args_iter_next (&(ITER)))\n+\n+/* Loop over all function arguments of FNTYPE.  In each iteration, TREE is set\n+   to the next tree element.  ITER is an instance of function_args_iterator\n+   used to iterate the arguments.  */\n+#define FOREACH_FUNCTION_ARGS(FNTYPE, TREE, ITER)\t\t\t\\\n+  for (function_args_iter_init (&(ITER), (FNTYPE));\t\t\t\\\n+       (TREE = function_args_iter_cond (&(ITER))) != NULL_TREE;\t\t\\\n+       function_args_iter_next (&(ITER)))\n+\n+\n \f\n /* In tree.c */\n extern unsigned crc32_string (unsigned, const char *);\n@@ -4627,6 +4686,9 @@ extern bool empty_body_p (tree);\n extern tree call_expr_arg (tree, int);\n extern tree *call_expr_argp (tree, int);\n extern tree call_expr_arglist (tree);\n+extern bool stdarg_p (tree);\n+extern bool prototype_p (tree);\n+extern int function_args_count (tree);\n extern bool auto_var_in_fn_p (const_tree, const_tree);\n \f\n /* In stmt.c */"}]}