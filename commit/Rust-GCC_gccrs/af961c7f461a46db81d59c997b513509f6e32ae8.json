{"sha": "af961c7f461a46db81d59c997b513509f6e32ae8", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWY5NjFjN2Y0NjFhNDZkYjgxZDU5Yzk5N2I1MTM1MDlmNmUzMmFlOA==", "commit": {"author": {"name": "Richard Guenther", "email": "rguenther@suse.de", "date": "2010-04-12T13:37:32Z"}, "committer": {"name": "Richard Biener", "email": "rguenth@gcc.gnu.org", "date": "2010-04-12T13:37:32Z"}, "message": "ipa.c (cgraph_postorder): Adjust postorder to guarantee single-iteration always-inline inlining.\n\n2010-04-12  Richard Guenther  <rguenther@suse.de>\n\n\t* ipa.c (cgraph_postorder): Adjust postorder to guarantee\n\tsingle-iteration always-inline inlining.\n\t* ipa-inline.c (cgraph_mark_inline): Do not return anything.\n\t(cgraph_decide_inlining): Do not handle always-inline\n\tspecially.\n\t(try_inline): Remove always-inline cycle detection special case.\n\tDo not recurse on always-inlines.\n\t(cgraph_early_inlining): Do not iterate if not optimizing.\n\t(cgraph_gate_early_inlining): remove.\n\t(pass_early_inline): Run unconditionally.\n\t(gate_cgraph_decide_inlining): New function.\n\t(pass_ipa_inline): Use it.  Do not run the IPA inliner if\n\tnot inlining or optimizing.\n\t(cgraph_decide_inlining_of_small_functions): Also consider\n\talways-inline functions.\n\t(cgraph_default_inline_p): Return true for nodes which should\n\tdisregard inline limits.\n\t(estimate_function_body_sizes): Assume zero size and time for\n\tnodes which are marked as disregarding inline limits.\n\t(cgraph_decide_recursive_inlining): Do not perform recursive\n\tinlining on always-inline nodes.\n\n\t* gcc.dg/torture/inline-2.c: New testcase.\n\nFrom-SVN: r158225", "tree": {"sha": "0fc12cc23e959d8fab2d03cc1f2bb306af12a14a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0fc12cc23e959d8fab2d03cc1f2bb306af12a14a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/af961c7f461a46db81d59c997b513509f6e32ae8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/af961c7f461a46db81d59c997b513509f6e32ae8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/af961c7f461a46db81d59c997b513509f6e32ae8", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/af961c7f461a46db81d59c997b513509f6e32ae8/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "fa8351f8d807ec9cde27984171670438295bc7b4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fa8351f8d807ec9cde27984171670438295bc7b4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fa8351f8d807ec9cde27984171670438295bc7b4"}], "stats": {"total": 519, "additions": 277, "deletions": 242}, "files": [{"sha": "91a18dca295e10cbd6d8b5ec7dc0851f8f88ecc6", "filename": "gcc/ChangeLog", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=af961c7f461a46db81d59c997b513509f6e32ae8", "patch": "@@ -1,3 +1,27 @@\n+2010-04-12  Richard Guenther  <rguenther@suse.de>\n+\n+\t* ipa.c (cgraph_postorder): Adjust postorder to guarantee\n+\tsingle-iteration always-inline inlining.\n+\t* ipa-inline.c (cgraph_mark_inline): Do not return anything.\n+\t(cgraph_decide_inlining): Do not handle always-inline\n+\tspecially.\n+\t(try_inline): Remove always-inline cycle detection special case.\n+\tDo not recurse on always-inlines.\n+\t(cgraph_early_inlining): Do not iterate if not optimizing.\n+\t(cgraph_gate_early_inlining): remove.\n+\t(pass_early_inline): Run unconditionally.\n+\t(gate_cgraph_decide_inlining): New function.\n+\t(pass_ipa_inline): Use it.  Do not run the IPA inliner if\n+\tnot inlining or optimizing.\n+\t(cgraph_decide_inlining_of_small_functions): Also consider\n+\talways-inline functions.\n+\t(cgraph_default_inline_p): Return true for nodes which should\n+\tdisregard inline limits.\n+\t(estimate_function_body_sizes): Assume zero size and time for\n+\tnodes which are marked as disregarding inline limits.\n+\t(cgraph_decide_recursive_inlining): Do not perform recursive\n+\tinlining on always-inline nodes.\n+\n 2010-04-12  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR bootstrap/43699"}, {"sha": "e9ba04b371c380226d2c1ab84371ffc94b791d9b", "filename": "gcc/ipa-inline.c", "status": "modified", "additions": 208, "deletions": 242, "changes": 450, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Fipa-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Fipa-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-inline.c?ref=af961c7f461a46db81d59c997b513509f6e32ae8", "patch": "@@ -160,9 +160,10 @@ enum inlining_mode {\n   INLINE_SIZE,\n   INLINE_ALL\n };\n+\n static bool\n-cgraph_decide_inlining_incrementally (struct cgraph_node *, enum inlining_mode,\n-\t\t\t\t      int);\n+cgraph_decide_inlining_incrementally (struct cgraph_node *, enum inlining_mode);\n+static void cgraph_flatten (struct cgraph_node *node);\n \n \n /* Statistics we collect about inlining algorithm.  */\n@@ -346,11 +347,9 @@ cgraph_mark_inline_edge (struct cgraph_edge *e, bool update_original,\n     return false;\n }\n \n-/* Mark all calls of EDGE->CALLEE inlined into EDGE->CALLER.\n-   Return following unredirected edge in the list of callers\n-   of EDGE->CALLEE  */\n+/* Mark all calls of EDGE->CALLEE inlined into EDGE->CALLER.  */\n \n-static struct cgraph_edge *\n+static void\n cgraph_mark_inline (struct cgraph_edge *edge)\n {\n   struct cgraph_node *to = edge->caller;\n@@ -370,8 +369,6 @@ cgraph_mark_inline (struct cgraph_edge *edge)\n \t    edge = next;\n \t}\n     }\n-\n-  return edge;\n }\n \n /* Estimate the growth caused by inlining NODE into all callees.  */\n@@ -479,6 +476,9 @@ cgraph_default_inline_p (struct cgraph_node *n, cgraph_inline_failed_t *reason)\n {\n   tree decl = n->decl;\n \n+  if (n->local.disregard_inline_limits)\n+    return true;\n+\n   if (!flag_inline_small_functions && !DECL_DECLARED_INLINE_P (decl))\n     {\n       if (reason)\n@@ -727,6 +727,12 @@ cgraph_decide_recursive_inlining (struct cgraph_node *node,\n   int depth = 0;\n   int n = 0;\n \n+  /* It does not make sense to recursively inline always-inline functions\n+     as we are going to sorry() on the remaining calls anyway.  */\n+  if (node->local.disregard_inline_limits\n+      && lookup_attribute (\"always_inline\", DECL_ATTRIBUTES (node->decl)))\n+    return false;\n+\n   if (optimize_function_for_size_p (DECL_STRUCT_FUNCTION (node->decl))\n       || (!flag_inline_functions && !DECL_DECLARED_INLINE_P (node->decl)))\n     return false;\n@@ -916,8 +922,7 @@ cgraph_decide_inlining_of_small_functions (void)\n \n   for (node = cgraph_nodes; node; node = node->next)\n     {\n-      if (!node->local.inlinable || !node->callers\n-\t  || node->local.disregard_inline_limits)\n+      if (!node->local.inlinable || !node->callers)\n \tcontinue;\n       if (dump_file)\n \tfprintf (dump_file, \"Considering inline candidate %s.\\n\", cgraph_node_name (node));\n@@ -1128,6 +1133,86 @@ cgraph_decide_inlining_of_small_functions (void)\n   BITMAP_FREE (updated_nodes);\n }\n \n+/* Flatten NODE from the IPA inliner.  */\n+\n+static void\n+cgraph_flatten (struct cgraph_node *node)\n+{\n+  struct cgraph_edge *e;\n+\n+  /* We shouldn't be called recursively when we are being processed.  */\n+  gcc_assert (node->aux == NULL);\n+\n+  node->aux = (void *)(size_t) INLINE_ALL;\n+\n+  for (e = node->callees; e; e = e->next_callee)\n+    {\n+      struct cgraph_node *orig_callee;\n+\n+      if (e->call_stmt_cannot_inline_p)\n+\tcontinue;\n+\n+      if (!e->callee->analyzed)\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file,\n+\t\t     \"Not inlining: Function body not available.\\n\");\n+\t  continue;\n+\t}\n+\n+      /* We've hit cycle?  It is time to give up.  */\n+      if (e->callee->aux)\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file,\n+\t\t     \"Not inlining %s into %s to avoid cycle.\\n\",\n+\t\t     cgraph_node_name (e->callee),\n+\t\t     cgraph_node_name (e->caller));\n+\t  e->inline_failed = CIF_RECURSIVE_INLINING;\n+\t  continue;\n+\t}\n+\n+      /* When the edge is already inlined, we just need to recurse into\n+\t it in order to fully flatten the leaves.  */\n+      if (!e->inline_failed)\n+\t{\n+\t  cgraph_flatten (e->callee);\n+\t  continue;\n+\t}\n+\n+      if (cgraph_recursive_inlining_p (node, e->callee, &e->inline_failed))\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \"Not inlining: recursive call.\\n\");\n+\t  continue;\n+\t}\n+\n+      if (!tree_can_inline_p (e))\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \"Not inlining: %s\",\n+\t\t     cgraph_inline_failed_string (e->inline_failed));\n+\t  continue;\n+\t}\n+\n+      /* Inline the edge and flatten the inline clone.  Avoid\n+         recursing through the original node if the node was cloned.  */\n+      if (dump_file)\n+\tfprintf (dump_file, \" Inlining %s into %s.\\n\",\n+\t\t cgraph_node_name (e->callee),\n+\t\t cgraph_node_name (e->caller));\n+      orig_callee = e->callee;\n+      cgraph_mark_inline_edge (e, true, NULL);\n+      if (e->callee != orig_callee)\n+\torig_callee->aux = (void *)(size_t) INLINE_ALL;\n+      cgraph_flatten (e->callee);\n+      if (e->callee != orig_callee)\n+\torig_callee->aux = NULL;\n+    }\n+\n+  node->aux = NULL;\n+}\n+\n /* Decide on the inlining.  We do so in the topological order to avoid\n    expenses on updating data structures.  */\n \n@@ -1140,7 +1225,6 @@ cgraph_decide_inlining (void)\n     XCNEWVEC (struct cgraph_node *, cgraph_n_nodes);\n   int old_size = 0;\n   int i;\n-  bool redo_always_inline = true;\n   int initial_size = 0;\n \n   cgraph_remove_function_insertion_hook (function_insertion_hook_holder);\n@@ -1178,65 +1262,29 @@ cgraph_decide_inlining (void)\n     node->aux = 0;\n \n   if (dump_file)\n-    fprintf (dump_file, \"\\nInlining always_inline functions:\\n\");\n+    fprintf (dump_file, \"\\nFlattening functions:\\n\");\n \n-  /* In the first pass mark all always_inline edges.  Do this with a priority\n-     so none of our later choices will make this impossible.  */\n-  while (redo_always_inline)\n+  /* In the first pass handle functions to be flattened.  Do this with\n+     a priority so none of our later choices will make this impossible.  */\n+  for (i = nnodes - 1; i >= 0; i--)\n     {\n-      redo_always_inline = false;\n-      for (i = nnodes - 1; i >= 0; i--)\n+      node = order[i];\n+\n+      /* Handle nodes to be flattened, but don't update overall unit\n+\t size.  Calling the incremental inliner here is lame,\n+\t a simple worklist should be enough.  What should be left\n+\t here from the early inliner (if it runs) is cyclic cases.\n+\t Ideally when processing callees we stop inlining at the\n+\t entry of cycles, possibly cloning that entry point and\n+\t try to flatten itself turning it into a self-recursive\n+\t function.  */\n+      if (lookup_attribute (\"flatten\",\n+\t\t\t    DECL_ATTRIBUTES (node->decl)) != NULL)\n \t{\n-\t  struct cgraph_edge *e, *next;\n-\n-\t  node = order[i];\n-\n-\t  /* Handle nodes to be flattened, but don't update overall unit\n-\t     size.  */\n-\t  if (lookup_attribute (\"flatten\",\n-\t\t\t\tDECL_ATTRIBUTES (node->decl)) != NULL)\n-\t    {\n-\t      if (dump_file)\n-\t\tfprintf (dump_file,\n-\t\t\t \"Flattening %s\\n\", cgraph_node_name (node));\n-\t      cgraph_decide_inlining_incrementally (node, INLINE_ALL, 0);\n-\t    }\n-\n-\t  if (!node->local.disregard_inline_limits)\n-\t    continue;\n-\t  if (dump_file)\n-\t    fprintf (dump_file,\n-\t\t     \"\\nConsidering %s size:%i (always inline)\\n\",\n-\t\t     cgraph_node_name (node), node->global.size);\n-\t  old_size = overall_size;\n-\t  for (e = node->callers; e; e = next)\n-\t    {\n-\t      next = e->next_caller;\n-\t      if (!e->inline_failed || e->call_stmt_cannot_inline_p)\n-\t\tcontinue;\n-\t      if (cgraph_recursive_inlining_p (e->caller, e->callee,\n-\t\t\t\t\t       &e->inline_failed))\n-\t\tcontinue;\n-\t      if (!tree_can_inline_p (e))\n-                continue;\n-\t      if (cgraph_mark_inline_edge (e, true, NULL))\n-\t\tredo_always_inline = true;\n-\t      if (dump_file)\n-\t\tfprintf (dump_file,\n-\t\t\t \" Inlined into %s which now has size %i.\\n\",\n-\t\t\t cgraph_node_name (e->caller),\n-\t\t\t e->caller->global.size);\n-\t    }\n-\t  /* Inlining self recursive function might introduce new calls to\n-\t     themselves we didn't see in the loop above.  Fill in the proper\n-\t     reason why inline failed.  */\n-\t  for (e = node->callers; e; e = e->next_caller)\n-\t    if (e->inline_failed)\n-\t      e->inline_failed = CIF_RECURSIVE_INLINING;\n \t  if (dump_file)\n \t    fprintf (dump_file,\n-\t\t     \" Inlined for a net change of %+i size.\\n\",\n-\t\t     overall_size - old_size);\n+\t\t     \"Flattening %s\\n\", cgraph_node_name (node));\n+\t  cgraph_flatten (node);\n \t}\n     }\n \n@@ -1313,86 +1361,6 @@ cgraph_decide_inlining (void)\n   return 0;\n }\n \n-/* Try to inline edge E from incremental inliner.  MODE specifies mode\n-   of inliner.\n-\n-   We are detecting cycles by storing mode of inliner into cgraph_node last\n-   time we visited it in the recursion.  In general when mode is set, we have\n-   recursive inlining, but as an special case, we want to try harder inline\n-   ALWAYS_INLINE functions: consider callgraph a->b->c->b, with a being\n-   flatten, b being always inline.  Flattening 'a' will collapse\n-   a->b->c before hitting cycle.  To accommodate always inline, we however\n-   need to inline a->b->c->b.\n-\n-   So after hitting cycle first time, we switch into ALWAYS_INLINE mode and\n-   stop inlining only after hitting ALWAYS_INLINE in ALWAY_INLINE mode.  */\n-static bool\n-try_inline (struct cgraph_edge *e, enum inlining_mode mode, int depth)\n-{\n-  struct cgraph_node *callee = e->callee;\n-  enum inlining_mode callee_mode = (enum inlining_mode) (size_t) callee->aux;\n-  bool always_inline = e->callee->local.disregard_inline_limits;\n-  bool inlined = false;\n-\n-  /* We've hit cycle?  */\n-  if (callee_mode)\n-    {\n-      /* It is first time we see it and we are not in ALWAY_INLINE only\n-\t mode yet.  and the function in question is always_inline.  */\n-      if (always_inline && mode != INLINE_ALWAYS_INLINE)\n-\t{\n-\t  if (dump_file)\n-\t    {\n-\t      indent_to (dump_file, depth);\n-\t      fprintf (dump_file,\n-\t\t       \"Hit cycle in %s, switching to always inline only.\\n\",\n-\t\t       cgraph_node_name (callee));\n-\t    }\n-\t  mode = INLINE_ALWAYS_INLINE;\n-\t}\n-      /* Otherwise it is time to give up.  */\n-      else\n-\t{\n-\t  if (dump_file)\n-\t    {\n-\t      indent_to (dump_file, depth);\n-\t      fprintf (dump_file,\n-\t\t       \"Not inlining %s into %s to avoid cycle.\\n\",\n-\t\t       cgraph_node_name (callee),\n-\t\t       cgraph_node_name (e->caller));\n-\t    }\n-\t  e->inline_failed = (e->callee->local.disregard_inline_limits\n-\t\t              ? CIF_RECURSIVE_INLINING : CIF_UNSPECIFIED);\n-          return false;\n-\t}\n-    }\n-\n-  callee->aux = (void *)(size_t) mode;\n-  if (dump_file)\n-    {\n-      indent_to (dump_file, depth);\n-      fprintf (dump_file, \" Inlining %s into %s.\\n\",\n-\t       cgraph_node_name (e->callee),\n-\t       cgraph_node_name (e->caller));\n-    }\n-  if (e->inline_failed)\n-    {\n-      cgraph_mark_inline (e);\n-\n-      /* In order to fully inline always_inline functions, we need to\n-\t recurse here, since the inlined functions might not be processed by\n-\t incremental inlining at all yet.\n-\n-\t Also flattening needs to be done recursively.  */\n-\n-      if (mode == INLINE_ALL || always_inline)\n-\tcgraph_decide_inlining_incrementally (e->callee, mode, depth + 1);\n-      inlined = true;\n-    }\n-  callee->aux = (void *)(size_t) callee_mode;\n-  return inlined;\n-}\n-\n /* Return true when N is leaf function.  Accept cheap (pure&const) builtins\n    in leaf functions.  */\n static bool\n@@ -1408,38 +1376,29 @@ leaf_node_p (struct cgraph_node *n)\n }\n \n /* Decide on the inlining.  We do so in the topological order to avoid\n-   expenses on updating data structures.\n-   DEPTH is depth of recursion, used only for debug output.  */\n+   expenses on updating data structures.  */\n \n static bool\n cgraph_decide_inlining_incrementally (struct cgraph_node *node,\n-\t\t\t\t      enum inlining_mode mode,\n-\t\t\t\t      int depth)\n+\t\t\t\t      enum inlining_mode mode)\n {\n   struct cgraph_edge *e;\n   bool inlined = false;\n   cgraph_inline_failed_t failed_reason;\n-  enum inlining_mode old_mode;\n \n #ifdef ENABLE_CHECKING\n   verify_cgraph_node (node);\n #endif\n \n-  old_mode = (enum inlining_mode) (size_t)node->aux;\n-\n   if (mode != INLINE_ALWAYS_INLINE && mode != INLINE_SIZE_NORECURSIVE\n       && lookup_attribute (\"flatten\", DECL_ATTRIBUTES (node->decl)) != NULL)\n     {\n       if (dump_file)\n-\t{\n-\t  indent_to (dump_file, depth);\n-\t  fprintf (dump_file, \"Flattening %s\\n\", cgraph_node_name (node));\n-\t}\n+\tfprintf (dump_file, \"Incrementally flattening %s\\n\",\n+\t\t cgraph_node_name (node));\n       mode = INLINE_ALL;\n     }\n \n-  node->aux = (void *)(size_t) mode;\n-\n   /* First of all look for always inline functions.  */\n   if (mode != INLINE_SIZE_NORECURSIVE)\n     for (e = node->callees; e; e = e->next_callee)\n@@ -1449,61 +1408,45 @@ cgraph_decide_inlining_incrementally (struct cgraph_node *node,\n \t  continue;\n \tif (e->call_stmt_cannot_inline_p)\n \t  continue;\n-\t/* When the edge is already inlined, we just need to recurse into\n-\t   it in order to fully flatten the leaves.  */\n-\tif (!e->inline_failed && mode == INLINE_ALL)\n-\t  {\n-\t    inlined |= try_inline (e, mode, depth);\n-\t    continue;\n-\t  }\n \tif (dump_file)\n-\t  {\n-\t    indent_to (dump_file, depth);\n-\t    fprintf (dump_file,\n-\t\t     \"Considering to always inline inline candidate %s.\\n\",\n-\t\t     cgraph_node_name (e->callee));\n-\t  }\n+\t  fprintf (dump_file,\n+\t\t   \"Considering to always inline inline candidate %s.\\n\",\n+\t\t   cgraph_node_name (e->callee));\n \tif (cgraph_recursive_inlining_p (node, e->callee, &e->inline_failed))\n \t  {\n \t    if (dump_file)\n-\t      {\n-\t\tindent_to (dump_file, depth);\n-\t\tfprintf (dump_file, \"Not inlining: recursive call.\\n\");\n-\t      }\n+\t      fprintf (dump_file, \"Not inlining: recursive call.\\n\");\n \t    continue;\n \t  }\n \tif (!tree_can_inline_p (e))\n \t  {\n \t    if (dump_file)\n-\t      {\n-\t\tindent_to (dump_file, depth);\n-\t\tfprintf (dump_file,\n-\t\t\t \"Not inlining: %s\",\n-                         cgraph_inline_failed_string (e->inline_failed));\n-\t      }\n+\t      fprintf (dump_file,\n+\t\t       \"Not inlining: %s\",\n+\t\t       cgraph_inline_failed_string (e->inline_failed));\n \t    continue;\n \t  }\n \tif (gimple_in_ssa_p (DECL_STRUCT_FUNCTION (node->decl))\n \t    != gimple_in_ssa_p (DECL_STRUCT_FUNCTION (e->callee->decl)))\n \t  {\n \t    if (dump_file)\n-\t      {\n-\t\tindent_to (dump_file, depth);\n-\t\tfprintf (dump_file, \"Not inlining: SSA form does not match.\\n\");\n-\t      }\n+\t      fprintf (dump_file, \"Not inlining: SSA form does not match.\\n\");\n \t    continue;\n \t  }\n \tif (!e->callee->analyzed)\n \t  {\n \t    if (dump_file)\n-\t      {\n-\t\tindent_to (dump_file, depth);\n-\t\tfprintf (dump_file,\n-\t\t\t \"Not inlining: Function body no longer available.\\n\");\n-\t      }\n+\t      fprintf (dump_file,\n+\t\t       \"Not inlining: Function body no longer available.\\n\");\n \t    continue;\n \t  }\n-\tinlined |= try_inline (e, mode, depth);\n+\n+\tif (dump_file)\n+\t  fprintf (dump_file, \" Inlining %s into %s.\\n\",\n+\t\t   cgraph_node_name (e->callee),\n+\t\t   cgraph_node_name (e->caller));\n+\tcgraph_mark_inline (e);\n+\tinlined = true;\n       }\n \n   /* Now do the automatic inlining.  */\n@@ -1530,21 +1473,15 @@ cgraph_decide_inlining_incrementally (struct cgraph_node *node,\n \t  if (cgraph_recursive_inlining_p (node, e->callee, &e->inline_failed))\n \t    {\n \t      if (dump_file)\n-\t\t{\n-\t\t  indent_to (dump_file, depth);\n-\t\t  fprintf (dump_file, \"Not inlining: recursive call.\\n\");\n-\t\t}\n+\t\tfprintf (dump_file, \"Not inlining: recursive call.\\n\");\n \t      continue;\n \t    }\n \t  if (gimple_in_ssa_p (DECL_STRUCT_FUNCTION (node->decl))\n \t      != gimple_in_ssa_p (DECL_STRUCT_FUNCTION (e->callee->decl)))\n \t    {\n \t      if (dump_file)\n-\t\t{\n-\t\t  indent_to (dump_file, depth);\n-\t\t  fprintf (dump_file,\n-\t\t\t   \"Not inlining: SSA form does not match.\\n\");\n-\t\t}\n+\t\tfprintf (dump_file,\n+\t\t\t \"Not inlining: SSA form does not match.\\n\");\n \t      continue;\n \t    }\n \n@@ -1563,55 +1500,49 @@ cgraph_decide_inlining_incrementally (struct cgraph_node *node,\n \t      && cgraph_estimate_growth (e->callee) > allowed_growth)\n \t    {\n \t      if (dump_file)\n-\t\t{\n-\t\t  indent_to (dump_file, depth);\n-\t\t  fprintf (dump_file,\n-\t\t\t   \"Not inlining: code size would grow by %i.\\n\",\n-\t\t\t   cgraph_estimate_size_after_inlining (1, e->caller,\n-\t\t\t\t\t\t\t\te->callee)\n-\t\t\t   - e->caller->global.size);\n-\t\t}\n+\t\tfprintf (dump_file,\n+\t\t\t \"Not inlining: code size would grow by %i.\\n\",\n+\t\t\t cgraph_estimate_size_after_inlining (1, e->caller,\n+\t\t\t\t\t\t\t      e->callee)\n+\t\t\t - e->caller->global.size);\n \t      continue;\n \t    }\n \t  if (!cgraph_check_inline_limits (node, e->callee, &e->inline_failed,\n \t\t\t\t\t   false)\n \t      || e->call_stmt_cannot_inline_p)\n \t    {\n \t      if (dump_file)\n-\t\t{\n-\t\t  indent_to (dump_file, depth);\n-\t\t  fprintf (dump_file, \"Not inlining: %s.\\n\",\n-\t\t\t   cgraph_inline_failed_string (e->inline_failed));\n-\t\t}\n+\t\tfprintf (dump_file, \"Not inlining: %s.\\n\",\n+\t\t\t cgraph_inline_failed_string (e->inline_failed));\n \t      continue;\n \t    }\n \t  if (!e->callee->analyzed)\n \t    {\n \t      if (dump_file)\n-\t\t{\n-\t\t  indent_to (dump_file, depth);\n-\t\t  fprintf (dump_file,\n-\t\t\t   \"Not inlining: Function body no longer available.\\n\");\n-\t\t}\n+\t\tfprintf (dump_file,\n+\t\t\t \"Not inlining: Function body no longer available.\\n\");\n \t      continue;\n \t    }\n \t  if (!tree_can_inline_p (e))\n \t    {\n \t      if (dump_file)\n-\t\t{\n-\t\t  indent_to (dump_file, depth);\n-\t\t  fprintf (dump_file,\n-\t\t\t   \"Not inlining: %s.\",\n-\t\t\t   cgraph_inline_failed_string (e->inline_failed));\n-\t\t}\n+\t\tfprintf (dump_file,\n+\t\t\t \"Not inlining: %s.\",\n+\t\t\t cgraph_inline_failed_string (e->inline_failed));\n \t      continue;\n \t    }\n \t  if (cgraph_default_inline_p (e->callee, &failed_reason))\n-\t    inlined |= try_inline (e, mode, depth);\n+\t    {\n+\t      if (dump_file)\n+\t\tfprintf (dump_file, \" Inlining %s into %s.\\n\",\n+\t\t\t cgraph_node_name (e->callee),\n+\t\t\t cgraph_node_name (e->caller));\n+\t      cgraph_mark_inline (e);\n+\t      inlined = true;\n+\t    }\n \t}\n       BITMAP_FREE (visited);\n     }\n-  node->aux = (void *)(size_t) old_mode;\n   return inlined;\n }\n \n@@ -1633,35 +1564,48 @@ cgraph_early_inlining (void)\n \n   if (sorrycount || errorcount)\n     return 0;\n-  while (iterations < PARAM_VALUE (PARAM_EARLY_INLINER_MAX_ITERATIONS)\n-         && cgraph_decide_inlining_incrementally (node,\n-  \t\t\t\t\t          iterations\n-\t\t\t\t\t          ? INLINE_SIZE_NORECURSIVE : INLINE_SIZE, 0))\n+\n+  if (!optimize\n+      || flag_no_inline\n+      || !flag_early_inlining)\n     {\n+      /* When not optimizing or not inlining inline only always-inline\n+\t functions.  */\n+      cgraph_decide_inlining_incrementally (node, INLINE_ALWAYS_INLINE);\n       timevar_push (TV_INTEGRATION);\n       todo |= optimize_inline_calls (current_function_decl);\n-      iterations++;\n       timevar_pop (TV_INTEGRATION);\n     }\n-  if (dump_file)\n-    fprintf (dump_file, \"Iterations: %i\\n\", iterations);\n+  else\n+    {\n+      /* We iterate incremental inlining to get trivial cases of indirect\n+\t inlining.  */\n+      while (iterations < PARAM_VALUE (PARAM_EARLY_INLINER_MAX_ITERATIONS)\n+\t     && cgraph_decide_inlining_incrementally (node,\n+\t\t\t\t\t\t      iterations\n+\t\t\t\t\t\t      ? INLINE_SIZE_NORECURSIVE\n+\t\t\t\t\t\t      : INLINE_SIZE))\n+\t{\n+\t  timevar_push (TV_INTEGRATION);\n+\t  todo |= optimize_inline_calls (current_function_decl);\n+\t  iterations++;\n+\t  timevar_pop (TV_INTEGRATION);\n+\t}\n+      if (dump_file)\n+\tfprintf (dump_file, \"Iterations: %i\\n\", iterations);\n+    }\n+\n   cfun->always_inline_functions_inlined = true;\n-  return todo;\n-}\n \n-/* When inlining shall be performed.  */\n-static bool\n-cgraph_gate_early_inlining (void)\n-{\n-  return flag_early_inlining;\n+  return todo;\n }\n \n struct gimple_opt_pass pass_early_inline =\n {\n  {\n   GIMPLE_PASS,\n   \"einline\",\t \t\t\t/* name */\n-  cgraph_gate_early_inlining,\t\t/* gate */\n+  NULL,\t\t\t\t\t/* gate */\n   cgraph_early_inlining,\t\t/* execute */\n   NULL,\t\t\t\t\t/* sub */\n   NULL,\t\t\t\t\t/* next */\n@@ -1786,6 +1730,14 @@ estimate_function_body_sizes (struct cgraph_node *node)\n   int freq;\n   tree funtype = TREE_TYPE (node->decl);\n \n+  if (node->local.disregard_inline_limits)\n+    {\n+      inline_summary (node)->self_time = 0;\n+      inline_summary (node)->self_size = 0;\n+      inline_summary (node)->time_inlining_benefit = 0;\n+      inline_summary (node)->size_inlining_benefit = 0;\n+    }\n+\n   if (dump_file)\n     fprintf (dump_file, \"Analyzing function body size: %s\\n\",\n \t     cgraph_node_name (node));\n@@ -2045,12 +1997,26 @@ inline_write_summary (cgraph_node_set set)\n     ipa_prop_write_jump_functions (set);\n }\n \n+/* When to run IPA inlining.  Inlining of always-inline functions\n+   happens during early inlining.  */\n+\n+static bool\n+gate_cgraph_decide_inlining (void)\n+{\n+  /* ???  We'd like to skip this if not optimizing or not inlining as\n+     all always-inline functions have been processed by early\n+     inlining already.  But this at least breaks EH with C++ as\n+     we need to unconditionally run fixup_cfg even at -O0.\n+     So leave it on unconditionally for now.  */\n+  return 1;\n+}\n+\n struct ipa_opt_pass_d pass_ipa_inline =\n {\n  {\n   IPA_PASS,\n   \"inline\",\t\t\t\t/* name */\n-  NULL,\t\t\t\t\t/* gate */\n+  gate_cgraph_decide_inlining,\t\t/* gate */\n   cgraph_decide_inlining,\t\t/* execute */\n   NULL,\t\t\t\t\t/* sub */\n   NULL,\t\t\t\t\t/* next */"}, {"sha": "d559ab2f285f6fd6421b243238439ba3e3552181", "filename": "gcc/ipa.c", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Fipa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Fipa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa.c?ref=af961c7f461a46db81d59c997b513509f6e32ae8", "patch": "@@ -70,6 +70,12 @@ cgraph_postorder (struct cgraph_node **order)\n \t\t    node2->aux = edge->next_caller;\n \t\t  else\n \t\t    node2->aux = &last;\n+\t\t  /* Break possible cycles involving always-inline\n+\t\t     functions by ignoring edges from always-inline\n+\t\t     functions to non-always-inline functions.  */\n+\t\t  if (edge->caller->local.disregard_inline_limits\n+\t\t      && !edge->callee->local.disregard_inline_limits)\n+\t\t    continue;\n \t\t  if (!edge->caller->aux)\n \t\t    {\n \t\t      if (!edge->caller->callers)"}, {"sha": "21cf512010880f9e86437908a0ac09205b50bedc", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=af961c7f461a46db81d59c997b513509f6e32ae8", "patch": "@@ -1,3 +1,7 @@\n+2010-04-12  Richard Guenther  <rguenther@suse.de>\n+\n+\t* gcc.dg/torture/inline-2.c: New testcase.\n+\n 2010-04-12  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR bootstrap/43699"}, {"sha": "0d341bfadcc1a97ce58b6ef71f66281c08d55275", "filename": "gcc/testsuite/gcc.dg/torture/inline-2.c", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Finline-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/af961c7f461a46db81d59c997b513509f6e32ae8/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Finline-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Finline-2.c?ref=af961c7f461a46db81d59c997b513509f6e32ae8", "patch": "@@ -0,0 +1,35 @@\n+/* { dg-do link } */\n+\n+extern inline void foo2 (void) __attribute__((always_inline,gnu_inline));\n+extern inline void foo1 (void) __attribute__((always_inline,gnu_inline));\n+void bar1 (void);\n+void bar2 (void);\n+\n+extern inline void __attribute__((always_inline,gnu_inline))\n+foo2 (void)\n+{\n+  bar2 ();\n+}\n+\n+void\n+bar1 (void)\n+{\n+  foo2 ();\n+}\n+\n+void\n+bar2 (void)\n+{\n+  foo1 ();\n+}\n+\n+extern inline void __attribute__((always_inline,gnu_inline))\n+foo1 (void)\n+{\n+  bar1 ();\n+}\n+\n+int main()\n+{\n+  return 0;\n+}"}]}