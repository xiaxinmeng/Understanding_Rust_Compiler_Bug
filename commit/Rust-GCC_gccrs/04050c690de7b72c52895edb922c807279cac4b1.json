{"sha": "04050c690de7b72c52895edb922c807279cac4b1", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDQwNTBjNjkwZGU3YjcyYzUyODk1ZWRiOTIyYzgwNzI3OWNhYzRiMQ==", "commit": {"author": {"name": "Richard Kenner", "email": "kenner@vlsi1.ultra.nyu.edu", "date": "2001-11-11T11:02:26Z"}, "committer": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "2001-11-11T11:02:26Z"}, "message": "expmed.c (extract_bit_field): No longer pass in alignment.\n\n\t* expmed.c (extract_bit_field): No longer pass in alignment.\n\t(extract_fixed_bit_field, extract_split_bit_field): Likewise.\n\t(store_bit_field, store_fixed_bit_field, store_split_bit_field):\n\tLikewise.\n\t* expr.c (store_constructor, store_constructor_field): Likewise.\n\t(store_field, emit_group_load, emit_group_store): Likewise.\n\t* expr.h (emit_group_load, emit_group_store): Delete ALIGN parm.\n\t(store_bit_field, extract_bit_field): Likewise.\n\t* calls.c, expr.c, function.c: Change calls to above functions.\n\t* ifcvt.c, stmt.c: Likewise.\n\nFrom-SVN: r46926", "tree": {"sha": "7505cb28fd2ea0a6dee73c00724fe0ab8515303b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7505cb28fd2ea0a6dee73c00724fe0ab8515303b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/04050c690de7b72c52895edb922c807279cac4b1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/04050c690de7b72c52895edb922c807279cac4b1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/04050c690de7b72c52895edb922c807279cac4b1", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/04050c690de7b72c52895edb922c807279cac4b1/comments", "author": null, "committer": null, "parents": [{"sha": "d746694a4593b1401b9638d605f59083d488af1e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d746694a4593b1401b9638d605f59083d488af1e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d746694a4593b1401b9638d605f59083d488af1e"}], "stats": {"total": 457, "additions": 179, "deletions": 278}, "files": [{"sha": "b57061f5dca296ba825c52e7884dea00c1225991", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -1,5 +1,16 @@\n Sun Nov 11 05:56:01 2001  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n \n+\t* expmed.c (extract_bit_field): No longer pass in alignment.\n+\t(extract_fixed_bit_field, extract_split_bit_field): Likewise.\n+\t(store_bit_field, store_fixed_bit_field, store_split_bit_field):\n+\tLikewise.\n+\t* expr.c (store_constructor, store_constructor_field): Likewise.\n+\t(store_field, emit_group_load, emit_group_store): Likewise.\n+\t* expr.h (emit_group_load, emit_group_store): Delete ALIGN parm.\n+\t(store_bit_field, extract_bit_field): Likewise.\n+\t* calls.c, expr.c, function.c: Change calls to above functions.\n+\t* ifcvt.c, stmt.c: Likewise.\n+\t\n \t* alias.c (nonoverlapping_memrefs_p): Not overlapping if one base is\n \tconstant and one is on frame.\n \tIf know memref offset, adjust size from decl."}, {"sha": "d86b0e0aac3a6657010927ee13173c066300764c", "filename": "gcc/calls.c", "status": "modified", "additions": 5, "deletions": 10, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -1037,7 +1037,6 @@ store_unaligned_arguments_into_pseudos (args, num_actuals)\n \t    rtx reg = gen_reg_rtx (word_mode);\n \t    rtx word = operand_subword_force (args[i].value, j, BLKmode);\n \t    int bitsize = MIN (bytes * BITS_PER_UNIT, BITS_PER_WORD);\n-\t    int bitalign = TYPE_ALIGN (TREE_TYPE (args[i].tree_value));\n \n \t    args[i].aligned_regs[j] = reg;\n \n@@ -1057,9 +1056,9 @@ store_unaligned_arguments_into_pseudos (args, num_actuals)\n \t    bytes -= bitsize / BITS_PER_UNIT;\n \t    store_bit_field (reg, bitsize, big_endian_correction, word_mode,\n \t\t\t     extract_bit_field (word, bitsize, 0, 1, NULL_RTX,\n-\t\t\t\t\t\tword_mode, word_mode, bitalign,\n+\t\t\t\t\t\tword_mode, word_mode,\n \t\t\t\t\t\tBITS_PER_WORD),\n-\t\t\t     bitalign, BITS_PER_WORD);\n+\t\t\t     BITS_PER_WORD);\n \t  }\n       }\n }\n@@ -1736,8 +1735,7 @@ load_register_parameters (args, num_actuals, call_fusage, flags)\n \n \t  if (GET_CODE (reg) == PARALLEL)\n \t    emit_group_load (reg, args[i].value,\n-\t\t\t     int_size_in_bytes (TREE_TYPE (args[i].tree_value)),\n-\t\t\t     TYPE_ALIGN (TREE_TYPE (args[i].tree_value)));\n+\t\t\t     int_size_in_bytes (TREE_TYPE (args[i].tree_value)));\n \n \t  /* If simple case, just do move.  If normal partial, store_one_arg\n \t     has already loaded the register for us.  In all other cases,\n@@ -3225,8 +3223,7 @@ expand_call (exp, target, ignore)\n \n \t  if (! rtx_equal_p (target, valreg))\n \t    emit_group_store (target, valreg,\n-\t\t\t      int_size_in_bytes (TREE_TYPE (exp)),\n-\t\t\t      TYPE_ALIGN (TREE_TYPE (exp)));\n+\t\t\t      int_size_in_bytes (TREE_TYPE (exp)));\n \n \t  /* We can not support sibling calls for this case.  */\n \t  sibcall_failure = 1;\n@@ -4004,9 +4001,7 @@ emit_library_call_value_1 (retval, orgfun, value, fn_type, outmode, nargs, p)\n       /* Handle calls that pass values in multiple non-contiguous\n \t locations.  The PA64 has examples of this for library calls.  */\n       if (reg != 0 && GET_CODE (reg) == PARALLEL)\n-\temit_group_load (reg, val,\n-\t\t\t GET_MODE_SIZE (GET_MODE (val)),\n-\t\t\t GET_MODE_ALIGNMENT (GET_MODE (val)));\n+\temit_group_load (reg, val, GET_MODE_SIZE (GET_MODE (val)));\n       else if (reg != 0 && partial == 0)\n \temit_move_insn (reg, val);\n "}, {"sha": "42394a9e9d2806fdcad8062e57c22d3911b13105", "filename": "gcc/expmed.c", "status": "modified", "additions": 79, "deletions": 126, "changes": 205, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -36,23 +36,20 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n \n static void store_fixed_bit_field\tPARAMS ((rtx, unsigned HOST_WIDE_INT,\n \t\t\t\t\t\t unsigned HOST_WIDE_INT,\n-\t\t\t\t\t\t unsigned HOST_WIDE_INT, rtx,\n-\t\t\t\t\t\t unsigned int));\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT, rtx));\n static void store_split_bit_field\tPARAMS ((rtx, unsigned HOST_WIDE_INT,\n-\t\t\t\t\t\t unsigned HOST_WIDE_INT, rtx,\n-\t\t\t\t\t\t unsigned int));\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT, rtx));\n static rtx extract_fixed_bit_field\tPARAMS ((enum machine_mode, rtx,\n \t\t\t\t\t\t unsigned HOST_WIDE_INT,\n \t\t\t\t\t\t unsigned HOST_WIDE_INT,\n \t\t\t\t\t\t unsigned HOST_WIDE_INT,\n-\t\t\t\t\t\t rtx, int, unsigned int));\n+\t\t\t\t\t\t rtx, int));\n static rtx mask_rtx\t\t\tPARAMS ((enum machine_mode, int,\n \t\t\t\t\t\t int, int));\n static rtx lshift_value\t\t\tPARAMS ((enum machine_mode, rtx,\n \t\t\t\t\t\t int, int));\n static rtx extract_split_bit_field\tPARAMS ((rtx, unsigned HOST_WIDE_INT,\n-\t\t\t\t\t\t unsigned HOST_WIDE_INT, int,\n-\t\t\t\t\t\t unsigned int));\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT, int));\n static void do_cmp_and_jump\t\tPARAMS ((rtx, rtx, enum rtx_code,\n \t\t\t\t\t\t enum machine_mode, rtx));\n \n@@ -289,13 +286,12 @@ mode_for_extraction (pattern, opno)\n    else, we use the mode of operand 3.  */\n \n rtx\n-store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n+store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, total_size)\n      rtx str_rtx;\n      unsigned HOST_WIDE_INT bitsize;\n      unsigned HOST_WIDE_INT bitnum;\n      enum machine_mode fieldmode;\n      rtx value;\n-     unsigned int align;\n      HOST_WIDE_INT total_size;\n {\n   unsigned int unit\n@@ -306,11 +302,6 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \n   enum machine_mode op_mode = mode_for_extraction (EP_insv, 3);\n \n-  /* It is wrong to have align==0, since every object is aligned at\n-     least at a bit boundary.  This usually means a bug elsewhere.  */\n-  if (align == 0)\n-    abort ();\n-\n   /* Discount the part of the structure before the desired byte.\n      We need to know how many bytes are safe to reference after it.  */\n   if (total_size >= 0)\n@@ -347,9 +338,9 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n       && (GET_CODE (op0) != MEM\n \t  ? (GET_MODE_SIZE (fieldmode) >= UNITS_PER_WORD\n \t     || GET_MODE_SIZE (GET_MODE (op0)) == GET_MODE_SIZE (fieldmode))\n-\t  : (! SLOW_UNALIGNED_ACCESS (fieldmode, align)\n+\t  : (! SLOW_UNALIGNED_ACCESS (fieldmode, MEM_ALIGN (op0))\n \t     || (offset * BITS_PER_UNIT % bitsize == 0\n-\t\t && align % GET_MODE_BITSIZE (fieldmode) == 0))))\n+\t\t && MEM_ALIGN (op0) % GET_MODE_BITSIZE (fieldmode) == 0))))\n     {\n       if (GET_MODE (op0) != fieldmode)\n \t{\n@@ -472,10 +463,10 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \t     if I is 1, use the next to lowest word; and so on.  */\n \t  unsigned int wordnum = (backwards ? nwords - i - 1 : i);\n \t  unsigned int bit_offset = (backwards\n-\t\t\t    ? MAX ((int) bitsize - ((int) i + 1)\n-\t\t\t\t   * BITS_PER_WORD,\n-\t\t\t\t   0)\n-\t\t\t    : (int) i * BITS_PER_WORD);\n+\t\t\t\t     ? MAX ((int) bitsize - ((int) i + 1)\n+\t\t\t\t\t    * BITS_PER_WORD,\n+\t\t\t\t\t    0)\n+\t\t\t\t     : (int) i * BITS_PER_WORD);\n \n \t  store_bit_field (op0, MIN (BITS_PER_WORD,\n \t\t\t\t     bitsize - i * BITS_PER_WORD),\n@@ -484,7 +475,7 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \t\t\t\t\t\t  (GET_MODE (value) == VOIDmode\n \t\t\t\t\t\t   ? fieldmode\n \t\t\t\t\t\t   : GET_MODE (value))),\n-\t\t\t   align, total_size);\n+\t\t\t   total_size);\n \t}\n       return value;\n     }\n@@ -519,9 +510,7 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n       offset = 0;\n     }\n   else\n-    {\n-      op0 = protect_from_queue (op0, 1);\n-    }\n+    op0 = protect_from_queue (op0, 1);\n \n   /* If VALUE is a floating-point mode, access it as an integer of the\n      corresponding size.  This can occur on a machine with 64 bit registers\n@@ -574,19 +563,19 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \t  if (GET_MODE (op0) == BLKmode\n \t      || GET_MODE_SIZE (GET_MODE (op0)) > GET_MODE_SIZE (maxmode))\n \t    bestmode\n-\t      = get_best_mode (bitsize, bitnum, align, maxmode,\n+\t      = get_best_mode (bitsize, bitnum, MEM_ALIGN (op0), maxmode,\n \t\t\t       MEM_VOLATILE_P (op0));\n \t  else\n \t    bestmode = GET_MODE (op0);\n \n \t  if (bestmode == VOIDmode\n-\t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t  && GET_MODE_BITSIZE (bestmode) > align))\n+\t      || (SLOW_UNALIGNED_ACCESS (bestmode, MEM_ALIGN (op0))\n+\t\t  && GET_MODE_BITSIZE (bestmode) > MEM_ALIGN (op0)))\n \t    goto insv_loses;\n \n-\t  /* Adjust address to point to the containing unit of that mode.  */\n+\t  /* Adjust address to point to the containing unit of that mode. \n+\t     Compute offset as multiple of this unit, counting in bytes.  */\n \t  unit = GET_MODE_BITSIZE (bestmode);\n-\t  /* Compute offset as multiple of this unit, counting in bytes.  */\n \t  offset = (bitnum / unit) * GET_MODE_SIZE (bestmode);\n \t  bitpos = bitnum % unit;\n \t  op0 = adjust_address (op0, bestmode,  offset);\n@@ -595,7 +584,7 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \t     the unit.  */\n \t  tempreg = copy_to_reg (op0);\n \t  store_bit_field (tempreg, bitsize, bitpos, fieldmode, value,\n-\t\t\t   align, total_size);\n+\t\t\t   total_size);\n \t  emit_move_insn (op0, tempreg);\n \t  return value;\n \t}\n@@ -638,7 +627,8 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \t\t if we must narrow it, be sure we do it correctly.  */\n \n \t      if (GET_MODE_SIZE (GET_MODE (value)) < GET_MODE_SIZE (maxmode))\n-\t\tvalue1 = simplify_gen_subreg (maxmode, value1, GET_MODE (value1), 0);\n+\t\tvalue1 = simplify_gen_subreg (maxmode, value1,\n+\t\t\t\t\t      GET_MODE (value1), 0);\n \t      else\n \t\tvalue1 = gen_lowpart (maxmode, value1);\n \t    }\n@@ -664,13 +654,13 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n       else\n         {\n \t  delete_insns_since (last);\n-\t  store_fixed_bit_field (op0, offset, bitsize, bitpos, value, align);\n+\t  store_fixed_bit_field (op0, offset, bitsize, bitpos, value);\n \t}\n     }\n   else\n     insv_loses:\n     /* Insv is not available; store using shifts and boolean ops.  */\n-    store_fixed_bit_field (op0, offset, bitsize, bitpos, value, align);\n+    store_fixed_bit_field (op0, offset, bitsize, bitpos, value);\n   return value;\n }\n \f\n@@ -682,26 +672,21 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n     (If OP0 is a register, it may be a full word or a narrower mode,\n      but BITPOS still counts within a full word,\n      which is significant on bigendian machines.)\n-   STRUCT_ALIGN is the alignment the structure is known to have.\n \n    Note that protect_from_queue has already been done on OP0 and VALUE.  */\n \n static void\n-store_fixed_bit_field (op0, offset, bitsize, bitpos, value, struct_align)\n+store_fixed_bit_field (op0, offset, bitsize, bitpos, value)\n      rtx op0;\n      unsigned HOST_WIDE_INT offset, bitsize, bitpos;\n      rtx value;\n-     unsigned int struct_align;\n {\n   enum machine_mode mode;\n   unsigned int total_bits = BITS_PER_WORD;\n   rtx subtarget, temp;\n   int all_zero = 0;\n   int all_one = 0;\n \n-  if (! SLOW_UNALIGNED_ACCESS (word_mode, struct_align))\n-    struct_align = BIGGEST_ALIGNMENT;\n-    \n   /* There is a case not handled here:\n      a structure with a known alignment of just a halfword\n      and a field split across two aligned halfwords within the structure.\n@@ -716,8 +701,7 @@ store_fixed_bit_field (op0, offset, bitsize, bitpos, value, struct_align)\n       /* Special treatment for a bit field split across two registers.  */\n       if (bitsize + bitpos > BITS_PER_WORD)\n \t{\n-\t  store_split_bit_field (op0, bitsize, bitpos,\n-\t\t\t\t value, BITS_PER_WORD);\n+\t  store_split_bit_field (op0, bitsize, bitpos, value);\n \t  return;\n \t}\n     }\n@@ -733,16 +717,14 @@ store_fixed_bit_field (op0, offset, bitsize, bitpos, value, struct_align)\n           || GET_MODE_BITSIZE (mode) > GET_MODE_BITSIZE (word_mode))\n         mode = word_mode;\n       mode = get_best_mode (bitsize, bitpos + offset * BITS_PER_UNIT,\n-\t\t\t    struct_align, mode,\n-\t\t\t    GET_CODE (op0) == MEM && MEM_VOLATILE_P (op0));\n+\t\t\t    MEM_ALIGN (op0), mode, MEM_VOLATILE_P (op0));\n \n       if (mode == VOIDmode)\n \t{\n \t  /* The only way this should occur is if the field spans word\n \t     boundaries.  */\n-\t  store_split_bit_field (op0,\n-\t\t\t\t bitsize, bitpos + offset * BITS_PER_UNIT,\n-\t\t\t\t value, struct_align);\n+\t  store_split_bit_field (op0, bitsize, bitpos + offset * BITS_PER_UNIT,\n+\t\t\t\t value);\n \t  return;\n \t}\n \n@@ -856,17 +838,14 @@ store_fixed_bit_field (op0, offset, bitsize, bitpos, value, struct_align)\n    BITSIZE is the field width; BITPOS the position of its first bit\n    (within the word).\n    VALUE is the value to store.\n-   ALIGN is the known alignment of OP0.\n-   This is also the size of the memory objects to be used.\n \n    This does not yet handle fields wider than BITS_PER_WORD.  */\n \n static void\n-store_split_bit_field (op0, bitsize, bitpos, value, align)\n+store_split_bit_field (op0, bitsize, bitpos, value)\n      rtx op0;\n      unsigned HOST_WIDE_INT bitsize, bitpos;\n      rtx value;\n-     unsigned int align;\n {\n   unsigned int unit;\n   unsigned int bitsdone = 0;\n@@ -876,7 +855,7 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n   if (GET_CODE (op0) == REG || GET_CODE (op0) == SUBREG)\n     unit = BITS_PER_WORD;\n   else\n-    unit = MIN (align, BITS_PER_WORD);\n+    unit = MIN (MEM_ALIGN (op0), BITS_PER_WORD);\n \n   /* If VALUE is a constant other than a CONST_INT, get it into a register in\n      WORD_MODE.  If we can do this using gen_lowpart_common, do so.  Note\n@@ -932,18 +911,10 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n \t  else\n \t    /* The args are chosen so that the last part includes the\n \t       lsb.  Give extract_bit_field the value it needs (with\n-\t       endianness compensation) to fetch the piece we want.\n-\n-\t       ??? We have no idea what the alignment of VALUE is, so\n-\t       we have to use a guess.  */\n-\t    part\n-\t      = extract_fixed_bit_field\n-\t\t(word_mode, value, 0, thissize,\n-\t\t total_bits - bitsize + bitsdone, NULL_RTX, 1,\n-\t\t GET_MODE (value) == VOIDmode\n-\t\t ? UNITS_PER_WORD\n-\t\t : (GET_MODE (value) == BLKmode\n-\t\t    ? 1 : GET_MODE_ALIGNMENT (GET_MODE (value))));\n+\t       endianness compensation) to fetch the piece we want.  */\n+\t    part = extract_fixed_bit_field (word_mode, value, 0, thissize,\n+\t\t\t\t\t    total_bits - bitsize + bitsdone,\n+\t\t\t\t\t    NULL_RTX, 1);\n \t}\n       else\n \t{\n@@ -953,13 +924,8 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n \t\t\t     >> bitsdone)\n \t\t\t    & (((HOST_WIDE_INT) 1 << thissize) - 1));\n \t  else\n-\t    part\n-\t      = extract_fixed_bit_field\n-\t\t(word_mode, value, 0, thissize, bitsdone, NULL_RTX, 1,\n-\t\t GET_MODE (value) == VOIDmode\n-\t\t ? UNITS_PER_WORD\n-\t\t : (GET_MODE (value) == BLKmode\n-\t\t    ? 1 : GET_MODE_ALIGNMENT (GET_MODE (value))));\n+\t    part = extract_fixed_bit_field (word_mode, value, 0, thissize,\n+\t\t\t\t\t    bitsdone, NULL_RTX, 1);\n \t}\n \n       /* If OP0 is a register, then handle OFFSET here.\n@@ -985,8 +951,8 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n \n       /* OFFSET is in UNITs, and UNIT is in bits.\n          store_fixed_bit_field wants offset in bytes.  */\n-      store_fixed_bit_field (word, offset * unit / BITS_PER_UNIT,\n-\t\t\t     thissize, thispos, part, align);\n+      store_fixed_bit_field (word, offset * unit / BITS_PER_UNIT, thissize,\n+\t\t\t     thispos, part);\n       bitsdone += thissize;\n     }\n }\n@@ -1003,7 +969,6 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n    TMODE is the mode the caller would like the value to have;\n    but the value may be returned with type MODE instead.\n \n-   ALIGN is the alignment that STR_RTX is known to have.\n    TOTAL_SIZE is the size in bytes of the containing structure,\n    or -1 if varying.\n \n@@ -1014,14 +979,13 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n \n rtx\n extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n-\t\t   target, mode, tmode, align, total_size)\n+\t\t   target, mode, tmode, total_size)\n      rtx str_rtx;\n      unsigned HOST_WIDE_INT bitsize;\n      unsigned HOST_WIDE_INT bitnum;\n      int unsignedp;\n      rtx target;\n      enum machine_mode mode, tmode;\n-     unsigned int align;\n      HOST_WIDE_INT total_size;\n {\n   unsigned int unit\n@@ -1111,9 +1075,9 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t&& TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (mode),\n \t\t\t\t  GET_MODE_BITSIZE (GET_MODE (op0))))\n        || (GET_CODE (op0) == MEM\n-\t   && (! SLOW_UNALIGNED_ACCESS (mode, align)\n+\t   && (! SLOW_UNALIGNED_ACCESS (mode, MEM_ALIGN (op0))\n \t       || (offset * BITS_PER_UNIT % bitsize == 0\n-\t\t   && align % bitsize == 0))))\n+\t\t   && MEM_ALIGN (op0) % bitsize == 0))))\n       && ((bitsize >= BITS_PER_WORD && bitsize == GET_MODE_BITSIZE (mode)\n \t   && bitpos % BITS_PER_WORD == 0)\n \t  || (mode_for_size (bitsize, GET_MODE_CLASS (tmode), 0) != BLKmode\n@@ -1192,7 +1156,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t    = extract_bit_field (op0, MIN (BITS_PER_WORD,\n \t\t\t\t\t   bitsize - i * BITS_PER_WORD),\n \t\t\t\t bitnum + bit_offset, 1, target_part, mode,\n-\t\t\t\t word_mode, align, total_size);\n+\t\t\t\t word_mode, total_size);\n \n \t  if (target_part == 0)\n \t    abort ();\n@@ -1211,11 +1175,11 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \n \t      total_words = GET_MODE_SIZE (GET_MODE (target)) / UNITS_PER_WORD;\n \t      for (i = nwords; i < total_words; i++)\n-\t\t{\n-\t\t  int wordnum = WORDS_BIG_ENDIAN ? total_words - i - 1 : i;\n-\t\t  rtx target_part = operand_subword (target, wordnum, 1, VOIDmode);\n-\t\t  emit_move_insn (target_part, const0_rtx);\n-\t\t}\n+\t\temit_move_insn\n+\t\t  (operand_subword (target,\n+\t\t\t\t    WORDS_BIG_ENDIAN ? total_words - i - 1 : i,\n+\t\t\t\t    1, VOIDmode),\n+\t\t   const0_rtx);\n \t    }\n \t  return target;\n \t}\n@@ -1259,9 +1223,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n       offset = 0;\n     }\n   else\n-    {\n-      op0 = protect_from_queue (str_rtx, 1);\n-    }\n+    op0 = protect_from_queue (str_rtx, 1);\n \n   /* Now OFFSET is nonzero only for memory operands.  */\n \n@@ -1303,14 +1265,15 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t\t  if (GET_MODE (xop0) == BLKmode\n \t\t      || (GET_MODE_SIZE (GET_MODE (op0))\n \t\t\t  > GET_MODE_SIZE (maxmode)))\n-\t\t    bestmode = get_best_mode (bitsize, bitnum, align, maxmode,\n+\t\t    bestmode = get_best_mode (bitsize, bitnum,\n+\t\t\t\t\t      MEM_ALIGN (xop0), maxmode,\n \t\t\t\t\t      MEM_VOLATILE_P (xop0));\n \t\t  else\n \t\t    bestmode = GET_MODE (xop0);\n \n \t\t  if (bestmode == VOIDmode\n-\t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t\t  && GET_MODE_BITSIZE (bestmode) > align))\n+\t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, MEM_ALIGN (xop0))\n+\t\t\t  && GET_MODE_BITSIZE (bestmode) > MEM_ALIGN (xop0)))\n \t\t    goto extzv_loses;\n \n \t\t  /* Compute offset as multiple of this unit,\n@@ -1390,13 +1353,13 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t    {\n \t      delete_insns_since (last);\n \t      target = extract_fixed_bit_field (int_mode, op0, offset, bitsize,\n-\t\t\t\t\t\tbitpos, target, 1, align);\n+\t\t\t\t\t\tbitpos, target, 1);\n \t    }\n \t}\n       else\n-        extzv_loses:\n-      target = extract_fixed_bit_field (int_mode, op0, offset, bitsize, \n-\t\t\t\t\tbitpos, target, 1, align);\n+      extzv_loses:\n+\ttarget = extract_fixed_bit_field (int_mode, op0, offset, bitsize, \n+\t\t\t\t\t  bitpos, target, 1);\n     }\n   else\n     {\n@@ -1432,14 +1395,15 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t\t  if (GET_MODE (xop0) == BLKmode\n \t\t      || (GET_MODE_SIZE (GET_MODE (op0))\n \t\t\t  > GET_MODE_SIZE (maxmode)))\n-\t\t    bestmode = get_best_mode (bitsize, bitnum, align, maxmode,\n+\t\t    bestmode = get_best_mode (bitsize, bitnum,\n+\t\t\t\t\t      MEM_ALIGN (xop0), maxmode,\n \t\t\t\t\t      MEM_VOLATILE_P (xop0));\n \t\t  else\n \t\t    bestmode = GET_MODE (xop0);\n \n \t\t  if (bestmode == VOIDmode\n-\t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t\t  && GET_MODE_BITSIZE (bestmode) > align))\n+\t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, MEM_ALIGN (xop0))\n+\t\t\t  && GET_MODE_BITSIZE (bestmode) > MEM_ALIGN (xop0)))\n \t\t    goto extv_loses;\n \n \t\t  /* Compute offset as multiple of this unit,\n@@ -1518,13 +1482,13 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t    {\n \t      delete_insns_since (last);\n \t      target = extract_fixed_bit_field (int_mode, op0, offset, bitsize,\n-\t\t\t\t\t\tbitpos, target, 0, align);\n+\t\t\t\t\t\tbitpos, target, 0);\n \t    }\n \t} \n       else\n-\textv_loses:\n-      target = extract_fixed_bit_field (int_mode, op0, offset, bitsize, \n-\t\t\t\t\tbitpos, target, 0, align);\n+      extv_loses:\n+\ttarget = extract_fixed_bit_field (int_mode, op0, offset, bitsize, \n+\t\t\t\t\t  bitpos, target, 0);\n     }\n   if (target == spec_target)\n     return target;\n@@ -1564,18 +1528,15 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n    UNSIGNEDP is nonzero for an unsigned bit field (don't sign-extend value).\n    If TARGET is nonzero, attempts to store the value there\n    and return TARGET, but this is not guaranteed.\n-   If TARGET is not used, create a pseudo-reg of mode TMODE for the value.\n-\n-   ALIGN is the alignment that STR_RTX is known to have.  */\n+   If TARGET is not used, create a pseudo-reg of mode TMODE for the value.  */\n \n static rtx\n extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n-\t\t\t target, unsignedp, align)\n+\t\t\t target, unsignedp)\n      enum machine_mode tmode;\n      rtx op0, target;\n      unsigned HOST_WIDE_INT offset, bitsize, bitpos;\n      int unsignedp;\n-     unsigned int align;\n {\n   unsigned int total_bits = BITS_PER_WORD;\n   enum machine_mode mode;\n@@ -1584,25 +1545,23 @@ extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n     {\n       /* Special treatment for a bit field split across two registers.  */\n       if (bitsize + bitpos > BITS_PER_WORD)\n-\treturn extract_split_bit_field (op0, bitsize, bitpos,\n-\t\t\t\t\tunsignedp, align);\n+\treturn extract_split_bit_field (op0, bitsize, bitpos, unsignedp);\n     }\n   else\n     {\n       /* Get the proper mode to use for this field.  We want a mode that\n \t includes the entire field.  If such a mode would be larger than\n \t a word, we won't be doing the extraction the normal way.  */\n \n-      mode = get_best_mode (bitsize, bitpos + offset * BITS_PER_UNIT, align,\n-\t\t\t    word_mode,\n-\t\t\t    GET_CODE (op0) == MEM && MEM_VOLATILE_P (op0));\n+      mode = get_best_mode (bitsize, bitpos + offset * BITS_PER_UNIT,\n+\t\t\t    MEM_ALIGN (op0), word_mode, MEM_VOLATILE_P (op0));\n \n       if (mode == VOIDmode)\n \t/* The only way this should occur is if the field spans word\n \t   boundaries.  */\n \treturn extract_split_bit_field (op0, bitsize,\n \t\t\t\t\tbitpos + offset * BITS_PER_UNIT,\n-\t\t\t\t\tunsignedp, align);\n+\t\t\t\t\tunsignedp);\n \n       total_bits = GET_MODE_BITSIZE (mode);\n \n@@ -1628,12 +1587,9 @@ extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n   mode = GET_MODE (op0);\n \n   if (BYTES_BIG_ENDIAN)\n-    {\n-      /* BITPOS is the distance between our msb and that of OP0.\n-\t Convert it to the distance from the lsb.  */\n-\n-      bitpos = total_bits - bitsize - bitpos;\n-    }\n+    /* BITPOS is the distance between our msb and that of OP0.\n+       Convert it to the distance from the lsb.  */\n+    bitpos = total_bits - bitsize - bitpos;\n \n   /* Now BITPOS is always the distance between the field's lsb and that of OP0.\n      We have reduced the big-endian case to the little-endian case.  */\n@@ -1694,7 +1650,8 @@ extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n \n   if (GET_MODE_BITSIZE (mode) != (bitsize + bitpos))\n     {\n-      tree amount = build_int_2 (GET_MODE_BITSIZE (mode) - (bitsize + bitpos), 0);\n+      tree amount\n+\t= build_int_2 (GET_MODE_BITSIZE (mode) - (bitsize + bitpos), 0);\n       /* Maybe propagate the target for the shift.  */\n       /* But not if we will return the result--could confuse integrate.c.  */\n       rtx subtarget = (target != 0 && GET_CODE (target) == REG\n@@ -1784,17 +1741,13 @@ lshift_value (mode, value, bitpos, bitsize)\n \n    OP0 is the REG, SUBREG or MEM rtx for the first of the two words.\n    BITSIZE is the field width; BITPOS, position of its first bit, in the word.\n-   UNSIGNEDP is 1 if should zero-extend the contents; else sign-extend.\n-\n-   ALIGN is the known alignment of OP0.  This is also the size of the\n-   memory objects to be used.  */\n+   UNSIGNEDP is 1 if should zero-extend the contents; else sign-extend.  */\n \n static rtx\n-extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n+extract_split_bit_field (op0, bitsize, bitpos, unsignedp)\n      rtx op0;\n      unsigned HOST_WIDE_INT bitsize, bitpos;\n      int unsignedp;\n-     unsigned int align;\n {\n   unsigned int unit;\n   unsigned int bitsdone = 0;\n@@ -1806,7 +1759,7 @@ extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n   if (GET_CODE (op0) == REG || GET_CODE (op0) == SUBREG)\n     unit = BITS_PER_WORD;\n   else\n-    unit = MIN (align, BITS_PER_WORD);\n+    unit = MIN (MEM_ALIGN (op0), BITS_PER_WORD);\n \n   while (bitsdone < bitsize)\n     {\n@@ -1851,7 +1804,7 @@ extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n \t extract_fixed_bit_field wants offset in bytes.  */\n       part = extract_fixed_bit_field (word_mode, word,\n \t\t\t\t      offset * unit / BITS_PER_UNIT,\n-\t\t\t\t      thissize, thispos, 0, 1, align);\n+\t\t\t\t      thissize, thispos, 0, 1);\n       bitsdone += thissize;\n \n       /* Shift this part into place for the result.  */"}, {"sha": "33a290f200a6504c96528372e382569b3b984ffe", "filename": "gcc/expr.c", "status": "modified", "additions": 72, "deletions": 122, "changes": 194, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -153,14 +153,12 @@ static int is_zeros_p\t\tPARAMS ((tree));\n static int mostly_zeros_p\tPARAMS ((tree));\n static void store_constructor_field PARAMS ((rtx, unsigned HOST_WIDE_INT,\n \t\t\t\t\t     HOST_WIDE_INT, enum machine_mode,\n-\t\t\t\t\t     tree, tree, unsigned int, int,\n-\t\t\t\t\t     int));\n-static void store_constructor\tPARAMS ((tree, rtx, unsigned int, int,\n-\t\t\t\t\t HOST_WIDE_INT));\n+\t\t\t\t\t     tree, tree, int, int));\n+static void store_constructor\tPARAMS ((tree, rtx, int, HOST_WIDE_INT));\n static rtx store_field\t\tPARAMS ((rtx, HOST_WIDE_INT,\n \t\t\t\t\t HOST_WIDE_INT, enum machine_mode,\n \t\t\t\t\t tree, enum machine_mode, int,\n-\t\t\t\t\t unsigned int, HOST_WIDE_INT, int));\n+\t\t\t\t\t HOST_WIDE_INT, int));\n static enum memory_use_mode\n   get_memory_usage_from_modifier PARAMS ((enum expand_modifier));\n static rtx var_rtx\t\tPARAMS ((tree));\n@@ -1946,8 +1944,7 @@ move_block_from_reg (regno, x, nregs, size)\n \n /* Emit code to move a block SRC to a block DST, where DST is non-consecutive\n    registers represented by a PARALLEL.  SSIZE represents the total size of\n-   block SRC in bytes, or -1 if not known.  ALIGN is the known alignment of\n-   SRC in bits.  */\n+   block SRC in bytes, or -1 if not known.  */\n /* ??? If SSIZE % UNITS_PER_WORD != 0, we make the blatent assumption that\n    the balance will be in what would be the low-order memory addresses, i.e.\n    left justified for big endian, right justified for little endian.  This\n@@ -1956,9 +1953,8 @@ move_block_from_reg (regno, x, nregs, size)\n    would be needed.  */\n \n void\n-emit_group_load (dst, orig_src, ssize, align)\n+emit_group_load (dst, orig_src, ssize)\n      rtx dst, orig_src;\n-     unsigned int align;\n      int ssize;\n {\n   rtx *tmps, src;\n@@ -2006,12 +2002,13 @@ emit_group_load (dst, orig_src, ssize, align)\n \t    src = gen_reg_rtx (mode);\n \t  else\n \t    src = gen_reg_rtx (GET_MODE (orig_src));\n+\n \t  emit_move_insn (src, orig_src);\n \t}\n \n       /* Optimize the access just a bit.  */\n       if (GET_CODE (src) == MEM\n-\t  && align >= GET_MODE_ALIGNMENT (mode)\n+\t  && MEM_ALIGN (src) >= GET_MODE_ALIGNMENT (mode)\n \t  && bytepos * BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n \t  && bytelen == GET_MODE_SIZE (mode))\n \t{\n@@ -2028,11 +2025,10 @@ emit_group_load (dst, orig_src, ssize, align)\n \t    tmps[i] = XEXP (src, 1);\n \t  else if (bytepos == 0)\n \t    {\n-\t      rtx mem;\n-\t      mem = assign_stack_temp (GET_MODE (src),\n-\t\t\t\t       GET_MODE_SIZE (GET_MODE (src)), 0);\n+\t      rtx mem = assign_stack_temp (GET_MODE (src),\n+\t\t\t\t\t   GET_MODE_SIZE (GET_MODE (src)), 0);\n \t      emit_move_insn (mem, src);\n-\t      tmps[i] = change_address (mem, mode, XEXP (mem, 0));\n+\t      tmps[i] = adjust_address (mem, mode, 0);\n \t    }\n \t  else\n \t    abort ();\n@@ -2043,7 +2039,7 @@ emit_group_load (dst, orig_src, ssize, align)\n       else\n \ttmps[i] = extract_bit_field (src, bytelen * BITS_PER_UNIT,\n \t\t\t\t     bytepos * BITS_PER_UNIT, 1, NULL_RTX,\n-\t\t\t\t     mode, mode, align, ssize);\n+\t\t\t\t     mode, mode, ssize);\n \n       if (BYTES_BIG_ENDIAN && shift)\n \texpand_binop (mode, ashl_optab, tmps[i], GEN_INT (shift),\n@@ -2059,13 +2055,12 @@ emit_group_load (dst, orig_src, ssize, align)\n \n /* Emit code to move a block SRC to a block DST, where SRC is non-consecutive\n    registers represented by a PARALLEL.  SSIZE represents the total size of\n-   block DST, or -1 if not known.  ALIGN is the known alignment of DST.  */\n+   block DST, or -1 if not known.  */\n \n void\n-emit_group_store (orig_dst, src, ssize, align)\n+emit_group_store (orig_dst, src, ssize)\n      rtx orig_dst, src;\n      int ssize;\n-     unsigned int align;\n {\n   rtx *tmps, dst;\n   int start, i;\n@@ -2109,8 +2104,8 @@ emit_group_store (orig_dst, src, ssize, align)\n \t the temporary.  */\n \n       temp = assign_stack_temp (GET_MODE (dst), ssize, 0);\n-      emit_group_store (temp, src, ssize, align);\n-      emit_group_load (dst, temp, ssize, align);\n+      emit_group_store (temp, src, ssize);\n+      emit_group_load (dst, temp, ssize);\n       return;\n     }\n   else if (GET_CODE (dst) != MEM)\n@@ -2141,13 +2136,13 @@ emit_group_store (orig_dst, src, ssize, align)\n \n       /* Optimize the access just a bit.  */\n       if (GET_CODE (dst) == MEM\n-\t  && align >= GET_MODE_ALIGNMENT (mode)\n+\t  && MEM_ALIGN (dst) >= GET_MODE_ALIGNMENT (mode)\n \t  && bytepos * BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n \t  && bytelen == GET_MODE_SIZE (mode))\n \temit_move_insn (adjust_address (dst, mode, bytepos), tmps[i]);\n       else\n \tstore_bit_field (dst, bytelen * BITS_PER_UNIT, bytepos * BITS_PER_UNIT,\n-\t\t\t mode, tmps[i], align, ssize);\n+\t\t\t mode, tmps[i], ssize);\n     }\n \n   emit_queue ();\n@@ -2228,8 +2223,8 @@ copy_blkmode_from_reg (tgtblk, srcreg, type)\n \t\t       extract_bit_field (src, bitsize,\n \t\t\t\t\t  xbitpos % BITS_PER_WORD, 1,\n \t\t\t\t\t  NULL_RTX, word_mode, word_mode,\n-\t\t\t\t\t  bitsize, BITS_PER_WORD),\n-\t\t       bitsize, BITS_PER_WORD);\n+\t\t\t\t\t  BITS_PER_WORD),\n+\t\t       BITS_PER_WORD);\n     }\n \n   return tgtblk;\n@@ -3655,7 +3650,7 @@ emit_push_insn (x, mode, type, size, align, partial, reg, extra,\n       /* Handle calls that pass values in multiple non-contiguous locations.\n \t The Irix 6 ABI has examples of this.  */\n       if (GET_CODE (reg) == PARALLEL)\n-\temit_group_load (reg, x, -1, align);  /* ??? size? */\n+\temit_group_load (reg, x, -1);  /* ??? size? */\n       else\n \tmove_block_to_reg (REGNO (reg), x, partial, mode);\n     }\n@@ -3872,9 +3867,7 @@ expand_assignment (to, from, want_value, suggest_reg)\n \t\t\t\t ? ((enum machine_mode)\n \t\t\t\t    TYPE_MODE (TREE_TYPE (to)))\n \t\t\t\t : VOIDmode),\n-\t\t\t\tunsignedp,\n-\t\t\t\talignment,\n-\t\t\t\tint_size_in_bytes (TREE_TYPE (tem)),\n+\t\t\t\tunsignedp, int_size_in_bytes (TREE_TYPE (tem)),\n \t\t\t\tget_alias_set (to));\n \n \t  preserve_temp_slots (result);\n@@ -3916,8 +3909,7 @@ expand_assignment (to, from, want_value, suggest_reg)\n       /* Handle calls that return values in multiple non-contiguous locations.\n \t The Irix 6 ABI has examples of this.  */\n       if (GET_CODE (to_rtx) == PARALLEL)\n-\temit_group_load (to_rtx, value, int_size_in_bytes (TREE_TYPE (from)),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (from)));\n+\temit_group_load (to_rtx, value, int_size_in_bytes (TREE_TYPE (from)));\n       else if (GET_MODE (to_rtx) == BLKmode)\n \temit_block_move (to_rtx, value, expr_size (from));\n       else\n@@ -3951,8 +3943,7 @@ expand_assignment (to, from, want_value, suggest_reg)\n       temp = expand_expr (from, 0, GET_MODE (to_rtx), 0);\n \n       if (GET_CODE (to_rtx) == PARALLEL)\n-\temit_group_load (to_rtx, temp, int_size_in_bytes (TREE_TYPE (from)),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (from)));\n+\temit_group_load (to_rtx, temp, int_size_in_bytes (TREE_TYPE (from)));\n       else\n \temit_move_insn (to_rtx, temp);\n \n@@ -4362,8 +4353,7 @@ store_expr (exp, target, want_value)\n       /* Handle calls that return values in multiple non-contiguous locations.\n \t The Irix 6 ABI has examples of this.  */\n       else if (GET_CODE (target) == PARALLEL)\n-\temit_group_load (target, temp, int_size_in_bytes (TREE_TYPE (exp)),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (exp)));\n+\temit_group_load (target, temp, int_size_in_bytes (TREE_TYPE (exp)));\n       else if (GET_MODE (temp) == BLKmode)\n \temit_block_move (target, temp, expr_size (exp));\n       else\n@@ -4464,7 +4454,7 @@ mostly_zeros_p (exp)\n /* Helper function for store_constructor.\n    TARGET, BITSIZE, BITPOS, MODE, EXP are as for store_field.\n    TYPE is the type of the CONSTRUCTOR, not the element type.\n-   ALIGN and CLEARED are as for store_constructor.\n+   CLEARED is as for store_constructor.\n    ALIAS_SET is the alias set to use for any stores.\n \n    This provides a recursive shortcut back to store_constructor when it isn't\n@@ -4473,14 +4463,13 @@ mostly_zeros_p (exp)\n    clear a substructure if the outer structure has already been cleared.  */\n \n static void\n-store_constructor_field (target, bitsize, bitpos,\n-\t\t\t mode, exp, type, align, cleared, alias_set)\n+store_constructor_field (target, bitsize, bitpos, mode, exp, type, cleared,\n+\t\t\t alias_set)\n      rtx target;\n      unsigned HOST_WIDE_INT bitsize;\n      HOST_WIDE_INT bitpos;\n      enum machine_mode mode;\n      tree exp, type;\n-     unsigned int align;\n      int cleared;\n      int alias_set;\n {\n@@ -4500,38 +4489,33 @@ store_constructor_field (target, bitsize, bitpos,\n \t\t\t    ? BLKmode : VOIDmode, bitpos / BITS_PER_UNIT);\n \n \n-      /* Show the alignment may no longer be what it was and update the alias\n-\t set, if required.  */\n-      if (bitpos != 0)\n-\talign = MIN (align, (unsigned int) bitpos & - bitpos);\n-\n+      /* Update the alias set, if required.  */\n       if (GET_CODE (target) == MEM && ! MEM_KEEP_ALIAS_SET_P (target)\n \t  && MEM_ALIAS_SET (target) != 0)\n \t{\n \t  target = copy_rtx (target);\n \t  set_mem_alias_set (target, alias_set);\n \t}\n \n-      store_constructor (exp, target, align, cleared, bitsize / BITS_PER_UNIT);\n+      store_constructor (exp, target, cleared, bitsize / BITS_PER_UNIT);\n     }\n   else\n-    store_field (target, bitsize, bitpos, mode, exp, VOIDmode, 0, align,\n+    store_field (target, bitsize, bitpos, mode, exp, VOIDmode, 0,\n \t\t int_size_in_bytes (type), alias_set);\n }\n \n /* Store the value of constructor EXP into the rtx TARGET.\n-   TARGET is either a REG or a MEM.\n-   ALIGN is the maximum known alignment for TARGET.\n+   TARGET is either a REG or a MEM; we know it cannot conflict, since\n+   safe_from_p has been called.\n    CLEARED is true if TARGET is known to have been zero'd.\n    SIZE is the number of bytes of TARGET we are allowed to modify: this\n    may not be the same as the size of EXP if we are assigning to a field\n    which has been packed to exclude padding bits.  */\n \n static void\n-store_constructor (exp, target, align, cleared, size)\n+store_constructor (exp, target, cleared, size)\n      tree exp;\n      rtx target;\n-     unsigned int align;\n      int cleared;\n      HOST_WIDE_INT size;\n {\n@@ -4540,47 +4524,30 @@ store_constructor (exp, target, align, cleared, size)\n   HOST_WIDE_INT exp_size = int_size_in_bytes (type);\n #endif\n \n-  /* We know our target cannot conflict, since safe_from_p has been called.  */\n-#if 0\n-  /* Don't try copying piece by piece into a hard register\n-     since that is vulnerable to being clobbered by EXP.\n-     Instead, construct in a pseudo register and then copy it all.  */\n-  if (GET_CODE (target) == REG && REGNO (target) < FIRST_PSEUDO_REGISTER)\n-    {\n-      rtx temp = gen_reg_rtx (GET_MODE (target));\n-      store_constructor (exp, temp, align, cleared, size);\n-      emit_move_insn (target, temp);\n-      return;\n-    }\n-#endif\n-\n   if (TREE_CODE (type) == RECORD_TYPE || TREE_CODE (type) == UNION_TYPE\n       || TREE_CODE (type) == QUAL_UNION_TYPE)\n     {\n       tree elt;\n \n-      /* Inform later passes that the whole union value is dead.  */\n+      /* We either clear the aggregate or indicate the value is dead.  */\n       if ((TREE_CODE (type) == UNION_TYPE\n \t   || TREE_CODE (type) == QUAL_UNION_TYPE)\n-\t  && ! cleared)\n+\t  && ! cleared\n+\t  && ! CONSTRUCTOR_ELTS (exp))\n+\t/* If the constructor is empty, clear the union.  */\n \t{\n-\t  emit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n-\n-\t  /* If the constructor is empty, clear the union.  */\n-\t  if (! CONSTRUCTOR_ELTS (exp)  && ! cleared)\n-\t    clear_storage (target, expr_size (exp));\n+\t  clear_storage (target, expr_size (exp));\n+\t  cleared = 1;\n \t}\n \n       /* If we are building a static constructor into a register,\n \t set the initial value as zero so we can fold the value into\n \t a constant.  But if more than one register is involved,\n \t this probably loses.  */\n-      else if (GET_CODE (target) == REG && TREE_STATIC (exp)\n+      else if (! cleared && GET_CODE (target) == REG && TREE_STATIC (exp)\n \t       && GET_MODE_SIZE (GET_MODE (target)) <= UNITS_PER_WORD)\n \t{\n-\t  if (! cleared)\n-\t    emit_move_insn (target, CONST0_RTX (GET_MODE (target)));\n-\n+\t  emit_move_insn (target, CONST0_RTX (GET_MODE (target)));\n \t  cleared = 1;\n \t}\n \n@@ -4589,20 +4556,19 @@ store_constructor (exp, target, align, cleared, size)\n \t clear the whole structure first.  Don't do this if TARGET is a\n \t register whose mode size isn't equal to SIZE since clear_storage\n \t can't handle this case.  */\n-      else if (size > 0\n+      else if (! cleared && size > 0\n \t       && ((list_length (CONSTRUCTOR_ELTS (exp))\n \t\t    != fields_length (type))\n \t\t   || mostly_zeros_p (exp))\n \t       && (GET_CODE (target) != REG\n-\t\t   || (HOST_WIDE_INT) GET_MODE_SIZE (GET_MODE (target)) == size))\n+\t\t   || ((HOST_WIDE_INT) GET_MODE_SIZE (GET_MODE (target))\n+\t\t       == size)))\n \t{\n-\t  if (! cleared)\n-\t    clear_storage (target, GEN_INT (size));\n-\n+\t  clear_storage (target, GEN_INT (size));\n \t  cleared = 1;\n \t}\n-      else if (! cleared)\n-\t/* Inform later passes that the old value is dead.  */\n+\n+      if (! cleared)\n \temit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n \n       /* Store each element of the constructor into\n@@ -4672,8 +4638,6 @@ store_constructor (exp, target, align, cleared, size)\n \n \t      to_rtx = offset_address (to_rtx, offset_rtx,\n \t\t\t\t       highest_pow2_factor (offset));\n-\n-\t      align = DECL_OFFSET_ALIGN (field);\n \t    }\n \n \t  if (TREE_READONLY (field))\n@@ -4698,11 +4662,13 @@ store_constructor (exp, target, align, cleared, size)\n \t      && bitpos + BITS_PER_WORD <= exp_size * BITS_PER_UNIT)\n \t    {\n \t      tree type = TREE_TYPE (value);\n+\n \t      if (TYPE_PRECISION (type) < BITS_PER_WORD)\n \t\t{\n \t\t  type = type_for_size (BITS_PER_WORD, TREE_UNSIGNED (type));\n \t\t  value = convert (type, value);\n \t\t}\n+\n \t      if (BYTES_BIG_ENDIAN)\n \t\tvalue\n \t\t  = fold (build (LSHIFT_EXPR, type, value,\n@@ -4720,7 +4686,7 @@ store_constructor (exp, target, align, cleared, size)\n \t    }\n \n \t  store_constructor_field (to_rtx, bitsize, bitpos, mode,\n-\t\t\t\t   TREE_VALUE (elt), type, align, cleared,\n+\t\t\t\t   TREE_VALUE (elt), type, cleared,\n \t\t\t\t   get_alias_set (TREE_TYPE (field)));\n \t}\n     }\n@@ -4817,7 +4783,6 @@ store_constructor (exp, target, align, cleared, size)\n \t  HOST_WIDE_INT bitpos;\n \t  int unsignedp;\n \t  tree value = TREE_VALUE (elt);\n-\t  unsigned int align = TYPE_ALIGN (TREE_TYPE (value));\n \t  tree index = TREE_PURPOSE (elt);\n \t  rtx xtarget = target;\n \n@@ -4869,8 +4834,8 @@ store_constructor (exp, target, align, cleared, size)\n \t\t\t}\n \n \t\t      store_constructor_field\n-\t\t\t(target, bitsize, bitpos, mode, value, type, align,\n-\t\t\t cleared, get_alias_set (elttype));\n+\t\t\t(target, bitsize, bitpos, mode, value, type, cleared,\n+\t\t\t get_alias_set (elttype));\n \t\t    }\n \t\t}\n \t      else\n@@ -4912,7 +4877,7 @@ store_constructor (exp, target, align, cleared, size)\n \t\t\t\t\t    highest_pow2_factor (position));\n \t\t  xtarget = adjust_address (xtarget, mode, 0);\n \t\t  if (TREE_CODE (value) == CONSTRUCTOR)\n-\t\t    store_constructor (value, xtarget, align, cleared,\n+\t\t    store_constructor (value, xtarget, cleared,\n \t\t\t\t       bitsize / BITS_PER_UNIT);\n \t\t  else\n \t\t    store_expr (value, xtarget, 0);\n@@ -4966,8 +4931,7 @@ store_constructor (exp, target, align, cleared, size)\n \t\t}\n \n \t      store_constructor_field (target, bitsize, bitpos, mode, value,\n-\t\t\t\t       type, align, cleared,\n-\t\t\t\t       get_alias_set (elttype));\n+\t\t\t\t       type, cleared, get_alias_set (elttype));\n \n \t    }\n \t}\n@@ -5167,24 +5131,22 @@ store_constructor (exp, target, align, cleared, size)\n    has mode VALUE_MODE if that is convenient to do.\n    In this case, UNSIGNEDP must be nonzero if the value is an unsigned type.\n \n-   ALIGN is the alignment that TARGET is known to have.\n    TOTAL_SIZE is the size in bytes of the structure, or -1 if varying.\n \n    ALIAS_SET is the alias set for the destination.  This value will\n    (in general) be different from that for TARGET, since TARGET is a\n    reference to the containing structure.  */\n \n static rtx\n-store_field (target, bitsize, bitpos, mode, exp, value_mode,\n-\t     unsignedp, align, total_size, alias_set)\n+store_field (target, bitsize, bitpos, mode, exp, value_mode, unsignedp,\n+\t     total_size, alias_set)\n      rtx target;\n      HOST_WIDE_INT bitsize;\n      HOST_WIDE_INT bitpos;\n      enum machine_mode mode;\n      tree exp;\n      enum machine_mode value_mode;\n      int unsignedp;\n-     unsigned int align;\n      HOST_WIDE_INT total_size;\n      int alias_set;\n {\n@@ -5229,7 +5191,7 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n \temit_move_insn (object, target);\n \n       store_field (blk_object, bitsize, bitpos, mode, exp, VOIDmode, 0,\n-\t\t   align, total_size, alias_set);\n+\t\t   total_size, alias_set);\n \n       /* Even though we aren't returning target, we need to\n \t give it the updated value.  */\n@@ -5259,11 +5221,11 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n       || GET_CODE (target) == SUBREG\n       /* If the field isn't aligned enough to store as an ordinary memref,\n \t store it as a bit field.  */\n-      || (mode != BLKmode && SLOW_UNALIGNED_ACCESS (mode, align)\n-\t  && (align < GET_MODE_ALIGNMENT (mode)\n+      || (mode != BLKmode && SLOW_UNALIGNED_ACCESS (mode, MEM_ALIGN (target))\n+\t  && (MEM_ALIGN (target) < GET_MODE_ALIGNMENT (mode)\n \t      || bitpos % GET_MODE_ALIGNMENT (mode)))\n-      || (mode == BLKmode && SLOW_UNALIGNED_ACCESS (mode, align)\n-\t  && (TYPE_ALIGN (TREE_TYPE (exp)) > align\n+      || (mode == BLKmode && SLOW_UNALIGNED_ACCESS (mode, MEM_ALIGN (target))\n+\t  && (TYPE_ALIGN (TREE_TYPE (exp)) > MEM_ALIGN (target)\n \t      || bitpos % TYPE_ALIGN (TREE_TYPE (exp)) != 0))\n       /* If the RHS and field are a constant size and the size of the\n \t RHS isn't the same size as the bitfield, we must use bitfield\n@@ -5297,21 +5259,11 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n \t boundary.  If so, we simply do a block copy.  */\n       if (GET_MODE (target) == BLKmode && GET_MODE (temp) == BLKmode)\n \t{\n-\t  unsigned int exp_align = expr_align (exp);\n-\n \t  if (GET_CODE (target) != MEM || GET_CODE (temp) != MEM\n \t      || bitpos % BITS_PER_UNIT != 0)\n \t    abort ();\n \n \t  target = adjust_address (target, VOIDmode, bitpos / BITS_PER_UNIT);\n-\n-\t  /* Make sure that ALIGN is no stricter than the alignment of EXP.  */\n-\t  align = MIN (exp_align, align);\n-\n-\t  /* Find an alignment that is consistent with the bit position.  */\n-\t  while ((bitpos % align) != 0)\n-\t    align >>= 1;\n-\n \t  emit_block_move (target, temp,\n \t\t\t   bitsize == -1 ? expr_size (exp)\n \t\t\t   : GEN_INT ((bitsize + BITS_PER_UNIT - 1)\n@@ -5321,11 +5273,11 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n \t}\n \n       /* Store the value in the bitfield.  */\n-      store_bit_field (target, bitsize, bitpos, mode, temp, align, total_size);\n+      store_bit_field (target, bitsize, bitpos, mode, temp, total_size);\n       if (value_mode != VOIDmode)\n \t{\n-\t  /* The caller wants an rtx for the value.  */\n-\t  /* If possible, avoid refetching from the bitfield itself.  */\n+\t  /* The caller wants an rtx for the value.\n+\t     If possible, avoid refetching from the bitfield itself.  */\n \t  if (width_mask != 0\n \t      && ! (GET_CODE (target) == MEM && MEM_VOLATILE_P (target)))\n \t    {\n@@ -5340,15 +5292,17 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n \t\t\t\t     GET_MODE (temp) == VOIDmode\n \t\t\t\t     ? value_mode\n \t\t\t\t     : GET_MODE (temp))), NULL_RTX);\n+\n \t      tmode = GET_MODE (temp);\n \t      if (tmode == VOIDmode)\n \t\ttmode = value_mode;\n \t      count = build_int_2 (GET_MODE_BITSIZE (tmode) - bitsize, 0);\n \t      temp = expand_shift (LSHIFT_EXPR, tmode, temp, count, 0, 0);\n \t      return expand_shift (RSHIFT_EXPR, tmode, temp, count, 0, 0);\n \t    }\n+\n \t  return extract_bit_field (target, bitsize, bitpos, unsignedp,\n-\t\t\t\t    NULL_RTX, value_mode, 0, align,\n+\t\t\t\t    NULL_RTX, value_mode, VOIDmode,\n \t\t\t\t    total_size);\n \t}\n       return const0_rtx;\n@@ -6823,7 +6777,7 @@ expand_expr (exp, target, tmode, modifier)\n \t\t\t\t\t\t       * TYPE_QUAL_CONST))),\n \t\t\t     TREE_ADDRESSABLE (exp), 1, 1);\n \n-\t  store_constructor (exp, target, TYPE_ALIGN (TREE_TYPE (exp)), 0,\n+\t  store_constructor (exp, target, 0,\n \t\t\t     int_size_in_bytes (TREE_TYPE (exp)));\n \t  return target;\n \t}\n@@ -7256,11 +7210,10 @@ expand_expr (exp, target, tmode, modifier)\n \t    op0 = validize_mem (op0);\n \n \t    if (GET_CODE (op0) == MEM && GET_CODE (XEXP (op0, 0)) == REG)\n-\t      mark_reg_pointer (XEXP (op0, 0), alignment);\n+\t      mark_reg_pointer (XEXP (op0, 0), MEM_ALIGN (op0));\n \n \t    op0 = extract_bit_field (op0, bitsize, bitpos,\n \t\t\t\t     unsignedp, target, ext_mode, ext_mode,\n-\t\t\t\t     alignment,\n \t\t\t\t     int_size_in_bytes (TREE_TYPE (tem)));\n \n \t    /* If the result is a record type and BITSIZE is narrower than\n@@ -7548,8 +7501,7 @@ expand_expr (exp, target, tmode, modifier)\n \t\t\t       * BITS_PER_UNIT),\n \t\t\t      (HOST_WIDE_INT) GET_MODE_BITSIZE (mode)),\n \t\t\t 0, TYPE_MODE (valtype), TREE_OPERAND (exp, 0),\n-\t\t\t VOIDmode, 0, BITS_PER_UNIT,\n-\t\t\t int_size_in_bytes (type), 0);\n+\t\t\t VOIDmode, 0, int_size_in_bytes (type), 0);\n \t  else\n \t    abort ();\n \n@@ -8740,9 +8692,7 @@ expand_expr (exp, target, tmode, modifier)\n \t      if (GET_CODE (op0) == PARALLEL)\n \t\t/* Handle calls that pass values in multiple non-contiguous\n \t\t   locations.  The Irix 6 ABI has examples of this.  */\n-\t\temit_group_store (memloc, op0,\n-\t\t\t\t  int_size_in_bytes (inner_type),\n-\t\t\t\t  TYPE_ALIGN (inner_type));\n+\t\temit_group_store (memloc, op0, int_size_in_bytes (inner_type));\n \t      else\n \t\temit_move_insn (memloc, op0);\n \t      op0 = memloc;\n@@ -9215,7 +9165,7 @@ expand_expr_unaligned (exp, palign)\n \n \t\top0 = extract_bit_field (validize_mem (op0), bitsize, bitpos,\n \t\t\t\t\t unsignedp, NULL_RTX, ext_mode,\n-\t\t\t\t\t ext_mode, alignment,\n+\t\t\t\t\t ext_mode,\n \t\t\t\t\t int_size_in_bytes (TREE_TYPE (tem)));\n \n \t\t/* If the result is a record type and BITSIZE is narrower than"}, {"sha": "24029a99a0a1adaf45034788cc9e3d56a26276c0", "filename": "gcc/expr.h", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -423,11 +423,11 @@ extern void move_block_from_reg PARAMS ((int, rtx, int, int));\n \n /* Load a BLKmode value into non-consecutive registers represented by a\n    PARALLEL.  */\n-extern void emit_group_load PARAMS ((rtx, rtx, int, unsigned int));\n+extern void emit_group_load PARAMS ((rtx, rtx, int));\n \n /* Store a BLKmode value from non-consecutive registers represented by a\n    PARALLEL.  */\n-extern void emit_group_store PARAMS ((rtx, rtx, int, unsigned int));\n+extern void emit_group_store PARAMS ((rtx, rtx, int));\n \n #ifdef TREE_CODE\n /* Copy BLKmode object from a set of registers.  */\n@@ -746,12 +746,11 @@ mode_for_extraction PARAMS ((enum extraction_pattern, int));\n \n extern rtx store_bit_field PARAMS ((rtx, unsigned HOST_WIDE_INT,\n \t\t\t\t    unsigned HOST_WIDE_INT,\n-\t\t\t\t    enum machine_mode, rtx,\n-\t\t\t\t    unsigned int, HOST_WIDE_INT));\n+\t\t\t\t    enum machine_mode, rtx, HOST_WIDE_INT));\n extern rtx extract_bit_field PARAMS ((rtx, unsigned HOST_WIDE_INT,\n \t\t\t\t      unsigned HOST_WIDE_INT, int, rtx,\n \t\t\t\t      enum machine_mode, enum machine_mode,\n-\t\t\t\t      unsigned int, HOST_WIDE_INT));\n+\t\t\t\t      HOST_WIDE_INT));\n extern rtx expand_mult PARAMS ((enum machine_mode, rtx, rtx, rtx, int));\n extern rtx expand_mult_add PARAMS ((rtx, rtx, rtx, rtx,enum machine_mode, int));\n extern rtx expand_mult_highpart_adjust PARAMS ((enum machine_mode, rtx, rtx, rtx, rtx, int));"}, {"sha": "3f3f11c302ff86f0c94d6747570d7ea67c7c61ec", "filename": "gcc/function.c", "status": "modified", "additions": 4, "deletions": 9, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -3117,8 +3117,7 @@ purge_addressof_1 (loc, insn, force, store, ht)\n \n \t\t  start_sequence ();\n \t\t  store_bit_field (sub, size_x, 0, GET_MODE (x),\n-\t\t\t\t   val, GET_MODE_SIZE (GET_MODE (sub)),\n-\t\t\t\t   GET_MODE_ALIGNMENT (GET_MODE (sub)));\n+\t\t\t\t   val, GET_MODE_SIZE (GET_MODE (sub)));\n \n \t\t  /* Make sure to unshare any shared rtl that store_bit_field\n \t\t     might have created.  */\n@@ -3139,7 +3138,6 @@ purge_addressof_1 (loc, insn, force, store, ht)\n \t\t  start_sequence ();\n \t\t  val = extract_bit_field (sub, size_x, 0, 1, NULL_RTX,\n \t\t\t\t\t   GET_MODE (x), GET_MODE (x),\n-\t\t\t\t\t   GET_MODE_SIZE (GET_MODE (sub)),\n \t\t\t\t\t   GET_MODE_SIZE (GET_MODE (sub)));\n \n \t\t  if (! validate_change (insn, loc, val, 0))\n@@ -4493,8 +4491,7 @@ assign_parms (fndecl)\n \t\t locations.  The Irix 6 ABI has examples of this.  */\n \t      if (GET_CODE (entry_parm) == PARALLEL)\n \t\temit_group_store (validize_mem (stack_parm), entry_parm,\n-\t\t\t\t  int_size_in_bytes (TREE_TYPE (parm)),\n-\t\t\t\t  TYPE_ALIGN (TREE_TYPE (parm)));\n+\t\t\t\t  int_size_in_bytes (TREE_TYPE (parm)));\n \n \t      else\n \t\tmove_block_from_reg (REGNO (entry_parm),\n@@ -4635,8 +4632,7 @@ assign_parms (fndecl)\n \t\t locations.  The Irix 6 ABI has examples of this.  */\n \t      if (GET_CODE (entry_parm) == PARALLEL)\n \t\temit_group_store (validize_mem (stack_parm), entry_parm,\n-\t\t\t\t  int_size_in_bytes (TREE_TYPE (parm)),\n-\t\t\t\t  TYPE_ALIGN (TREE_TYPE (parm)));\n+\t\t\t\t  int_size_in_bytes (TREE_TYPE (parm)));\n \t      else\n \t\tmove_block_from_reg (REGNO (entry_parm),\n \t\t\t\t     validize_mem (stack_parm),\n@@ -6909,8 +6905,7 @@ expand_function_end (filename, line, end_bindings)\n \t    }\n \t  else if (GET_CODE (real_decl_rtl) == PARALLEL)\n \t    emit_group_load (real_decl_rtl, decl_rtl,\n-\t\t\t     int_size_in_bytes (TREE_TYPE (decl_result)),\n-\t\t\t     TYPE_ALIGN (TREE_TYPE (decl_result)));\n+\t\t\t     int_size_in_bytes (TREE_TYPE (decl_result)));\n \t  else\n \t    emit_move_insn (real_decl_rtl, decl_rtl);\n "}, {"sha": "e056cad6dc672a8b235867fb7d35732f914deaa6", "filename": "gcc/ifcvt.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fifcvt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fifcvt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fifcvt.c?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -580,8 +580,7 @@ noce_emit_move_insn (x, y)\n   outmode = GET_MODE (outer);\n   inmode = GET_MODE (inner);\n   bitpos = SUBREG_BYTE (outer) * BITS_PER_UNIT;\n-  store_bit_field (inner, GET_MODE_BITSIZE (outmode),\n-\t\t   bitpos, outmode, y, GET_MODE_BITSIZE (inmode),\n+  store_bit_field (inner, GET_MODE_BITSIZE (outmode), bitpos, outmode, y,\n \t\t   GET_MODE_BITSIZE (inmode));\n }\n "}, {"sha": "53e1477842274b53166c18f2fc1169e0fbf7bf82", "filename": "gcc/stmt.c", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fstmt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/04050c690de7b72c52895edb922c807279cac4b1/gcc%2Fstmt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstmt.c?ref=04050c690de7b72c52895edb922c807279cac4b1", "patch": "@@ -3071,8 +3071,7 @@ expand_value_return (val)\n \tval = convert_modes (mode, old_mode, val, unsignedp);\n #endif\n       if (GET_CODE (return_reg) == PARALLEL)\n-\temit_group_load (return_reg, val, int_size_in_bytes (type),\n-\t\t\t TYPE_ALIGN (type));\n+\temit_group_load (return_reg, val, int_size_in_bytes (type));\n       else\n \temit_move_insn (return_reg, val);\n     }\n@@ -3253,8 +3252,8 @@ expand_return (retval)\n \t\t\t   extract_bit_field (src, bitsize,\n \t\t\t\t\t      bitpos % BITS_PER_WORD, 1,\n \t\t\t\t\t      NULL_RTX, word_mode, word_mode,\n-\t\t\t\t\t      bitsize, BITS_PER_WORD),\n-\t\t\t   bitsize, BITS_PER_WORD);\n+\t\t\t\t\t      BITS_PER_WORD),\n+\t\t\t   BITS_PER_WORD);\n \t}\n \n       /* Find the smallest integer mode large enough to hold the"}]}