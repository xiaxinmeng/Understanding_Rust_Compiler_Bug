{"sha": "19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTllZDlkN2JiNWNhOTJhM2U3MGY1ZTU5MGRlMjY0NzAzNmIxYWIxMw==", "commit": {"author": {"name": "Uros Bizjak", "email": "uros@gcc.gnu.org", "date": "2010-09-08T17:56:11Z"}, "committer": {"name": "Uros Bizjak", "email": "uros@gcc.gnu.org", "date": "2010-09-08T17:56:11Z"}, "message": "i386-protos.h (ix86_can_use_return_insn_p, [...]): Change function prototype to bool.\n\n\t* config/i386/i386-protos.h (ix86_can_use_return_insn_p,\n\tsymbolic_reference_mentioned_p, ix86_expand_movmem, ix86_expand_setmem,\n\tix86_expand_strlen, legitimate_pic_address_disp_p,\n\tix86_binary_operator_ok, ix86_unary_operator_ok, ix86_match_ccmode,\n\tix86_expand_int_movcc, ix86_expand_fp_movcc, ix86_expand_int_addcc,\n\tix86_check_movabs, ix86_secondary_memory_needed): Change function\n\tprototype to bool.\n\t* config/i386/i386.c (return_in_memory_32, return_in_memory_64,\n\treturn_in_memory_ms_64, ix86_check_movabs,\n\tsymbolic_reference_mentioned_p, ix86_can_use_return_insn_p,\n\tlegitimate_pic_address_disp_p, ix86_binary_operator_ok,\n\tix86_unary_operator_ok, ix86_match_ccmode, ix86_expand_int_movcc,\n\tix86_expand_fp_movcc, ix86_expand_int_addcc, ix86_expand_movmem,\n\tix86_expand_setmem, ix86_expand_strlen, inline_secondary_memory_needed,\n\tix86_secondary_memory_needed): Change to bool.  Return\n\ttrue and false values.\n\t* config/i386/i386.md: Return true and false values.\n\nFrom-SVN: r164013", "tree": {"sha": "aeb3a5718f73c479a9eecf149d63660002ed4180", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/aeb3a5718f73c479a9eecf149d63660002ed4180"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "html_url": "https://github.com/Rust-GCC/gccrs/commit/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/comments", "author": null, "committer": null, "parents": [{"sha": "0fa3d594710f2b29223207bf6dfc035f310c5e4a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0fa3d594710f2b29223207bf6dfc035f310c5e4a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0fa3d594710f2b29223207bf6dfc035f310c5e4a"}], "stats": {"total": 515, "additions": 266, "deletions": 249}, "files": [{"sha": "408f11bd7c58ba14998d351107978673ba285fcf", "filename": "gcc/ChangeLog", "status": "modified", "additions": 28, "deletions": 8, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "patch": "@@ -1,12 +1,31 @@\n+2010-09-08  Uros Bizjak  <ubizjak@gmail.com>\n+\n+\t* config/i386/i386-protos.h (ix86_can_use_return_insn_p,\n+\tsymbolic_reference_mentioned_p, ix86_expand_movmem, ix86_expand_setmem,\n+\tix86_expand_strlen, legitimate_pic_address_disp_p,\n+\tix86_binary_operator_ok, ix86_unary_operator_ok, ix86_match_ccmode,\n+\tix86_expand_int_movcc, ix86_expand_fp_movcc, ix86_expand_int_addcc,\n+\tix86_check_movabs, ix86_secondary_memory_needed): Change function\n+\tprototype to bool.\n+\t* config/i386/i386.c (return_in_memory_32, return_in_memory_64,\n+\treturn_in_memory_ms_64, ix86_check_movabs,\n+\tsymbolic_reference_mentioned_p, ix86_can_use_return_insn_p,\n+\tlegitimate_pic_address_disp_p, ix86_binary_operator_ok,\n+\tix86_unary_operator_ok, ix86_match_ccmode, ix86_expand_int_movcc,\n+\tix86_expand_fp_movcc, ix86_expand_int_addcc, ix86_expand_movmem,\n+\tix86_expand_setmem, ix86_expand_strlen, inline_secondary_memory_needed,\n+\tix86_secondary_memory_needed): Change to bool.  Return\n+\t\"true\" and \"false\" values.\n+\t* config/i386/i386.md: Return \"true\" and \"false\" values.\n+\n 2010-09-08  Rainer Orth  <ro@CeBiTec.Uni-Bielefeld.DE>\n \n \t* doc/sourcebuild.texi (Effective-Target Keywords): Document\n \trun_expensive_tests.\n \n 2010-09-08  Rainer Orth  <ro@CeBiTec.Uni-Bielefeld.DE>\n \n-\t* toplev.c (output_stack_usage): Use lbasename instead of\n-\tbasename.\n+\t* toplev.c (output_stack_usage): Use lbasename instead of basename.\n \n 2010-09-08  Martin Jambor  <mjambor@suse.cz>\n \n@@ -47,15 +66,15 @@\n 2010-09-08  Richard Guenther  <rguenther@suse.de>\n \n \t* tree.h (TYPE_ORIG_SIZE_TYPE): Remove.\n-\t* c-typeck.c (comptypes_internal): Remove TYPE_ORIG_SIZE_TYPE\n-\tchecks.\n+\t* c-typeck.c (comptypes_internal): Remove TYPE_ORIG_SIZE_TYPE checks.\n \n 2010-09-08  Arnaud Charlet  <charlet@adacore.com>\n \n \t* c-tree.h, c-decl.c (build_enumerator): Add location parameter.\n \t* c-parser.c (c_parser_enum_specifier): Adjust call to build_enumerator.\n \n 2010-09-08  Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n \tPR doc/45587\n \t* doc/md.texi: Fixed modes on several standard pattern names.\n \n@@ -83,14 +102,15 @@\n \n 2010-09-07  Richard Henderson  <rth@redhat.com>\n \n-\t* final.c (rest_of_handle_final): Unconditionally do \n+\t* final.c (rest_of_handle_final): Unconditionally do\n \toutput_function_exception_table before assemble_end_function.\n \n 2010-09-07  Jan Hubicka  <jh@suse.cz>\n \n-\t* tree-inline.c (tree_inlinable_function_p): Do not test DECL_REPLACEABLE_P.\n-\t* ipa-inline.c (cgraph_default_inline_p, update_caller_keys, update_callee_keys,\n-\tcgraph_decide_inlining): Test function availability.\n+\t* tree-inline.c (tree_inlinable_function_p): Do not test\n+\tDECL_REPLACEABLE_P.\n+\t* ipa-inline.c (cgraph_default_inline_p, update_caller_keys,\n+\tupdate_callee_keys, cgraph_decide_inlining): Test function availability.\n \t* cif-code.def (OVERWRITABLE): New code.\n \n 2010-09-07  H.J. Lu  <hjl.tools@gmail.com>"}, {"sha": "900b4242ec89fa6ef8eb2c1f42220895c09faeb1", "filename": "gcc/config/i386/i386-protos.h", "status": "modified", "additions": 15, "deletions": 16, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-protos.h?ref=19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "patch": "@@ -25,7 +25,7 @@ extern void optimization_options (int, int);\n extern void ix86_conditional_register_usage (void);\n \n extern bool ix86_target_stack_probe (void);\n-extern int ix86_can_use_return_insn_p (void);\n+extern bool ix86_can_use_return_insn_p (void);\n extern void ix86_setup_frame_addresses (void);\n \n extern HOST_WIDE_INT ix86_initial_elimination_offset (int, int);\n@@ -44,7 +44,7 @@ extern const char *standard_80387_constant_opcode (rtx);\n extern rtx standard_80387_constant_rtx (int);\n extern int standard_sse_constant_p (rtx);\n extern const char *standard_sse_constant_opcode (rtx, rtx);\n-extern int symbolic_reference_mentioned_p (rtx);\n+extern bool symbolic_reference_mentioned_p (rtx);\n extern bool extended_reg_mentioned_p (rtx);\n extern bool x86_extended_QIreg_mentioned_p (rtx);\n extern bool x86_extended_reg_mentioned_p (rtx);\n@@ -54,14 +54,14 @@ extern enum machine_mode ix86_cc_mode (enum rtx_code, rtx, rtx);\n extern int avx_vpermilp_parallel (rtx par, enum machine_mode mode);\n extern int avx_vperm2f128_parallel (rtx par, enum machine_mode mode);\n \n-extern int ix86_expand_movmem (rtx, rtx, rtx, rtx, rtx, rtx);\n-extern int ix86_expand_setmem (rtx, rtx, rtx, rtx, rtx, rtx);\n-extern int ix86_expand_strlen (rtx, rtx, rtx, rtx);\n+extern bool ix86_expand_movmem (rtx, rtx, rtx, rtx, rtx, rtx);\n+extern bool ix86_expand_setmem (rtx, rtx, rtx, rtx, rtx, rtx);\n+extern bool ix86_expand_strlen (rtx, rtx, rtx, rtx);\n \n extern bool legitimate_constant_p (rtx);\n extern bool constant_address_p (rtx);\n extern bool legitimate_pic_operand_p (rtx);\n-extern int legitimate_pic_address_disp_p (rtx);\n+extern bool legitimate_pic_address_disp_p (rtx);\n \n extern void print_reg (rtx, int, FILE*);\n extern void ix86_print_operand (FILE *, rtx, int);\n@@ -88,7 +88,7 @@ extern void ix86_fixup_binary_operands_no_copy (enum rtx_code,\n \t\t\t\t\t\tenum machine_mode, rtx[]);\n extern void ix86_expand_binary_operator (enum rtx_code,\n \t\t\t\t\t enum machine_mode, rtx[]);\n-extern int ix86_binary_operator_ok (enum rtx_code, enum machine_mode, rtx[]);\n+extern bool ix86_binary_operator_ok (enum rtx_code, enum machine_mode, rtx[]);\n extern bool ix86_lea_for_add_ok (rtx, rtx[]);\n extern bool ix86_vec_interleave_v2df_operator_ok (rtx operands[3], bool high);\n extern bool ix86_dep_by_shift_count (const_rtx set_insn, const_rtx use_insn);\n@@ -109,18 +109,17 @@ extern void ix86_expand_fp_absneg_operator (enum rtx_code, enum machine_mode,\n extern void ix86_expand_copysign (rtx []);\n extern void ix86_split_copysign_const (rtx []);\n extern void ix86_split_copysign_var (rtx []);\n-extern int ix86_unary_operator_ok (enum rtx_code, enum machine_mode, rtx[]);\n-extern int ix86_match_ccmode (rtx, enum machine_mode);\n-extern int ix86_use_fcomi_compare (enum rtx_code);\n+extern bool ix86_unary_operator_ok (enum rtx_code, enum machine_mode, rtx[]);\n+extern bool ix86_match_ccmode (rtx, enum machine_mode);\n extern void ix86_expand_branch (enum rtx_code, rtx, rtx, rtx);\n extern void ix86_expand_setcc (rtx, enum rtx_code, rtx, rtx);\n-extern int ix86_expand_int_movcc (rtx[]);\n-extern int ix86_expand_fp_movcc (rtx[]);\n+extern bool ix86_expand_int_movcc (rtx[]);\n+extern bool ix86_expand_fp_movcc (rtx[]);\n extern bool ix86_expand_fp_vcond (rtx[]);\n extern bool ix86_expand_int_vcond (rtx[]);\n extern void ix86_expand_sse_unpack (rtx[], bool, bool);\n extern void ix86_expand_sse4_unpack (rtx[], bool, bool);\n-extern int ix86_expand_int_addcc (rtx[]);\n+extern bool ix86_expand_int_addcc (rtx[]);\n extern void ix86_expand_call (rtx, rtx, rtx, rtx, rtx, int);\n extern void x86_initialize_trampoline (rtx, rtx, rtx);\n extern rtx ix86_zero_extend_to_Pmode (rtx);\n@@ -129,7 +128,7 @@ extern void ix86_split_ashl (rtx *, rtx, enum machine_mode);\n extern void ix86_split_ashr (rtx *, rtx, enum machine_mode);\n extern void ix86_split_lshr (rtx *, rtx, enum machine_mode);\n extern rtx ix86_find_base_term (rtx);\n-extern int ix86_check_movabs (rtx, int);\n+extern bool ix86_check_movabs (rtx, int);\n \n extern rtx assign_386_stack_local (enum machine_mode, enum ix86_stack_slot);\n extern int ix86_attr_length_immediate_default (rtx, int);\n@@ -152,8 +151,8 @@ extern void ix86_split_fp_branch (enum rtx_code code, rtx, rtx,\n \t\t\t\t  rtx, rtx, rtx, rtx);\n extern bool ix86_hard_regno_mode_ok (int, enum machine_mode);\n extern bool ix86_modes_tieable_p (enum machine_mode, enum machine_mode);\n-extern int ix86_secondary_memory_needed (enum reg_class, enum reg_class,\n-\t\t\t\t\t enum machine_mode, int);\n+extern bool ix86_secondary_memory_needed (enum reg_class, enum reg_class,\n+\t\t\t\t\t  enum machine_mode, int);\n extern bool ix86_cannot_change_mode_class (enum machine_mode,\n \t\t\t\t\t   enum machine_mode, enum reg_class);\n extern enum reg_class ix86_preferred_reload_class (rtx, enum reg_class);"}, {"sha": "a3f0567ae4f506f440a1d5de95203f20591e12f2", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 90, "deletions": 91, "changes": 181, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "patch": "@@ -6812,70 +6812,70 @@ ix86_libcall_value (enum machine_mode mode)\n \n /* Return true iff type is returned in memory.  */\n \n-static int ATTRIBUTE_UNUSED\n+static bool ATTRIBUTE_UNUSED\n return_in_memory_32 (const_tree type, enum machine_mode mode)\n {\n   HOST_WIDE_INT size;\n \n   if (mode == BLKmode)\n-    return 1;\n+    return true;\n \n   size = int_size_in_bytes (type);\n \n   if (MS_AGGREGATE_RETURN && AGGREGATE_TYPE_P (type) && size <= 8)\n-    return 0;\n+    return false;\n \n   if (VECTOR_MODE_P (mode) || mode == TImode)\n     {\n       /* User-created vectors small enough to fit in EAX.  */\n       if (size < 8)\n-\treturn 0;\n+\treturn false;\n \n       /* MMX/3dNow values are returned in MM0,\n \t except when it doesn't exits.  */\n       if (size == 8)\n-\treturn (TARGET_MMX ? 0 : 1);\n+\treturn !TARGET_MMX;\n \n       /* SSE values are returned in XMM0, except when it doesn't exist.  */\n       if (size == 16)\n-\treturn (TARGET_SSE ? 0 : 1);\n+\treturn !TARGET_SSE;\n \n       /* AVX values are returned in YMM0, except when it doesn't exist.  */\n       if (size == 32)\n-\treturn TARGET_AVX ? 0 : 1;\n+\treturn !TARGET_AVX;\n     }\n \n   if (mode == XFmode)\n-    return 0;\n+    return false;\n \n   if (size > 12)\n-    return 1;\n+    return true;\n \n   /* OImode shouldn't be used directly.  */\n   gcc_assert (mode != OImode);\n \n-  return 0;\n+  return false;\n }\n \n-static int ATTRIBUTE_UNUSED\n+static bool ATTRIBUTE_UNUSED\n return_in_memory_64 (const_tree type, enum machine_mode mode)\n {\n   int needed_intregs, needed_sseregs;\n   return !examine_argument (mode, type, 1, &needed_intregs, &needed_sseregs);\n }\n \n-static int ATTRIBUTE_UNUSED\n+static bool ATTRIBUTE_UNUSED\n return_in_memory_ms_64 (const_tree type, enum machine_mode mode)\n {\n   HOST_WIDE_INT size = int_size_in_bytes (type);\n \n   /* __m128 is returned in xmm0.  */\n   if ((SCALAR_INT_MODE_P (mode) || VECTOR_MODE_P (mode))\n       && !COMPLEX_MODE_P (mode) && (GET_MODE_SIZE (mode) == 16 || size == 16))\n-    return 0;\n+    return false;\n \n   /* Otherwise, the size must be exactly in [1248]. */\n-  return (size != 1 && size != 2 && size != 4 && size != 8);\n+  return size != 1 && size != 2 && size != 4 && size != 8;\n }\n \n static bool\n@@ -7604,10 +7604,10 @@ ix86_gimplify_va_arg (tree valist, tree type, gimple_seq *pre_p,\n   return build_va_arg_indirect_ref (addr);\n }\n \f\n-/* Return nonzero if OPNUM's MEM should be matched\n+/* Return true if OPNUM's MEM should be matched\n    in movabs* patterns.  */\n \n-int\n+bool\n ix86_check_movabs (rtx insn, int opnum)\n {\n   rtx set, mem;\n@@ -7620,7 +7620,7 @@ ix86_check_movabs (rtx insn, int opnum)\n   while (GET_CODE (mem) == SUBREG)\n     mem = SUBREG_REG (mem);\n   gcc_assert (MEM_P (mem));\n-  return (volatile_ok || !MEM_VOLATILE_P (mem));\n+  return volatile_ok || !MEM_VOLATILE_P (mem);\n }\n \f\n /* Initialize the table of extra 80387 mathematical constants.  */\n@@ -7649,8 +7649,8 @@ init_ext_80387_constants (void)\n   ext_80387_constants_init = 1;\n }\n \n-/* Return true if the constant is something that can be loaded with\n-   a special instruction.  */\n+/* Return non-zero if the constant is something that\n+   can be loaded with a special instruction.  */\n \n int\n standard_80387_constant_p (rtx x)\n@@ -7826,16 +7826,16 @@ standard_sse_constant_opcode (rtx insn, rtx x)\n   gcc_unreachable ();\n }\n \n-/* Returns 1 if OP contains a symbol reference */\n+/* Returns true if OP contains a symbol reference */\n \n-int\n+bool\n symbolic_reference_mentioned_p (rtx op)\n {\n   const char *fmt;\n   int i;\n \n   if (GET_CODE (op) == SYMBOL_REF || GET_CODE (op) == LABEL_REF)\n-    return 1;\n+    return true;\n \n   fmt = GET_RTX_FORMAT (GET_CODE (op));\n   for (i = GET_RTX_LENGTH (GET_CODE (op)) - 1; i >= 0; i--)\n@@ -7846,23 +7846,23 @@ symbolic_reference_mentioned_p (rtx op)\n \n \t  for (j = XVECLEN (op, i) - 1; j >= 0; j--)\n \t    if (symbolic_reference_mentioned_p (XVECEXP (op, i, j)))\n-\t      return 1;\n+\t      return true;\n \t}\n \n       else if (fmt[i] == 'e' && symbolic_reference_mentioned_p (XEXP (op, i)))\n-\treturn 1;\n+\treturn true;\n     }\n \n-  return 0;\n+  return false;\n }\n \n-/* Return 1 if it is appropriate to emit `ret' instructions in the\n+/* Return true if it is appropriate to emit `ret' instructions in the\n    body of a function.  Do this only if the epilogue is simple, needing a\n    couple of insns.  Prior to reloading, we can't tell how many registers\n-   must be saved, so return 0 then.  Return 0 if there is no frame\n+   must be saved, so return false then.  Return false if there is no frame\n    marker to de-allocate.  */\n \n-int\n+bool\n ix86_can_use_return_insn_p (void)\n {\n   struct ix86_frame frame;\n@@ -10684,7 +10684,7 @@ legitimate_pic_operand_p (rtx x)\n /* Determine if a given CONST RTX is a valid memory displacement\n    in PIC mode.  */\n \n-int\n+bool\n legitimate_pic_address_disp_p (rtx disp)\n {\n   bool saw_plus;\n@@ -10729,7 +10729,7 @@ legitimate_pic_address_disp_p (rtx disp)\n \t}\n     }\n   if (GET_CODE (disp) != CONST)\n-    return 0;\n+    return false;\n   disp = XEXP (disp, 0);\n \n   if (TARGET_64BIT)\n@@ -10740,28 +10740,28 @@ legitimate_pic_address_disp_p (rtx disp)\n \t  || (XINT (disp, 1) != UNSPEC_GOTPCREL\n \t      && XINT (disp, 1) != UNSPEC_GOTOFF\n \t      && XINT (disp, 1) != UNSPEC_PLTOFF))\n-\treturn 0;\n+\treturn false;\n \n       if (GET_CODE (XVECEXP (disp, 0, 0)) != SYMBOL_REF\n \t  && GET_CODE (XVECEXP (disp, 0, 0)) != LABEL_REF)\n-\treturn 0;\n-      return 1;\n+\treturn false;\n+      return true;\n     }\n \n   saw_plus = false;\n   if (GET_CODE (disp) == PLUS)\n     {\n       if (!CONST_INT_P (XEXP (disp, 1)))\n-\treturn 0;\n+\treturn false;\n       disp = XEXP (disp, 0);\n       saw_plus = true;\n     }\n \n   if (TARGET_MACHO && darwin_local_data_pic (disp))\n-    return 1;\n+    return true;\n \n   if (GET_CODE (disp) != UNSPEC)\n-    return 0;\n+    return false;\n \n   switch (XINT (disp, 1))\n     {\n@@ -10800,7 +10800,7 @@ legitimate_pic_address_disp_p (rtx disp)\n \t      && SYMBOL_REF_TLS_MODEL (disp) == TLS_MODEL_LOCAL_DYNAMIC);\n     }\n \n-  return 0;\n+  return false;\n }\n \n /* Recognizes RTL expressions that are valid memory addresses for an\n@@ -11663,7 +11663,7 @@ ix86_legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED,\n \t    }\n \t}\n \n-      if (changed && ix86_legitimate_address_p (mode, x, FALSE))\n+      if (changed && ix86_legitimate_address_p (mode, x, false))\n \treturn x;\n \n       if (GET_CODE (XEXP (x, 0)) == MULT)\n@@ -11689,7 +11689,7 @@ ix86_legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED,\n \t  x = legitimize_pic_address (x, 0);\n \t}\n \n-      if (changed && ix86_legitimate_address_p (mode, x, FALSE))\n+      if (changed && ix86_legitimate_address_p (mode, x, false))\n \treturn x;\n \n       if (REG_P (XEXP (x, 0)))\n@@ -14562,7 +14562,7 @@ ix86_expand_binary_operator (enum rtx_code code, enum machine_mode mode,\n /* Return TRUE or FALSE depending on whether the binary operator meets the\n    appropriate constraints.  */\n \n-int\n+bool\n ix86_binary_operator_ok (enum rtx_code code, enum machine_mode mode,\n \t\t\t rtx operands[3])\n {\n@@ -14572,7 +14572,7 @@ ix86_binary_operator_ok (enum rtx_code code, enum machine_mode mode,\n \n   /* Both source operands cannot be in memory.  */\n   if (MEM_P (src1) && MEM_P (src2))\n-    return 0;\n+    return false;\n \n   /* Canonicalize operand order for commutative operators.  */\n   if (ix86_swap_binary_operands_p (code, mode, operands))\n@@ -14584,17 +14584,17 @@ ix86_binary_operator_ok (enum rtx_code code, enum machine_mode mode,\n \n   /* If the destination is memory, we must have a matching source operand.  */\n   if (MEM_P (dst) && !rtx_equal_p (dst, src1))\n-      return 0;\n+      return false;\n \n   /* Source 1 cannot be a constant.  */\n   if (CONSTANT_P (src1))\n-    return 0;\n+    return false;\n \n   /* Source 1 cannot be a non-matching memory.  */\n   if (MEM_P (src1) && !rtx_equal_p (dst, src1))\n-    return 0;\n+    return false;\n \n-  return 1;\n+  return true;\n }\n \n /* Attempt to expand a unary operator.  Make the expansion closer to the\n@@ -14957,7 +14957,7 @@ ix86_dep_by_shift_count (const_rtx set_insn, const_rtx use_insn)\n /* Return TRUE or FALSE depending on whether the unary operator meets the\n    appropriate constraints.  */\n \n-int\n+bool\n ix86_unary_operator_ok (enum rtx_code code ATTRIBUTE_UNUSED,\n \t\t\tenum machine_mode mode ATTRIBUTE_UNUSED,\n \t\t\trtx operands[2] ATTRIBUTE_UNUSED)\n@@ -14966,8 +14966,8 @@ ix86_unary_operator_ok (enum rtx_code code ATTRIBUTE_UNUSED,\n   if ((MEM_P (operands[0])\n        || MEM_P (operands[1]))\n       && ! rtx_equal_p (operands[0], operands[1]))\n-    return FALSE;\n-  return TRUE;\n+    return false;\n+  return true;\n }\n \n /* Return TRUE if the operands to a vec_interleave_{high,low}v2df\n@@ -15545,7 +15545,7 @@ ix86_split_copysign_var (rtx operands[])\n    has source and destination with matching CC modes, and that the\n    CC mode is at least as constrained as REQ_MODE.  */\n \n-int\n+bool\n ix86_match_ccmode (rtx insn, enum machine_mode req_mode)\n {\n   rtx set;\n@@ -15564,19 +15564,19 @@ ix86_match_ccmode (rtx insn, enum machine_mode req_mode)\n       if (req_mode != CCNOmode\n \t  && (req_mode != CCmode\n \t      || XEXP (SET_SRC (set), 1) != const0_rtx))\n-\treturn 0;\n+\treturn false;\n       break;\n     case CCmode:\n       if (req_mode == CCGCmode)\n-\treturn 0;\n+\treturn false;\n       /* FALLTHRU */\n     case CCGCmode:\n       if (req_mode == CCGOCmode || req_mode == CCNOmode)\n-\treturn 0;\n+\treturn false;\n       /* FALLTHRU */\n     case CCGOCmode:\n       if (req_mode == CCZmode)\n-\treturn 0;\n+\treturn false;\n       /* FALLTHRU */\n     case CCAmode:\n     case CCCmode:\n@@ -15589,7 +15589,7 @@ ix86_match_ccmode (rtx insn, enum machine_mode req_mode)\n       gcc_unreachable ();\n     }\n \n-  return (GET_MODE (SET_SRC (set)) == set_mode);\n+  return GET_MODE (SET_SRC (set)) == set_mode;\n }\n \n /* Generate insn patterns to do an integer compare of OPERANDS.  */\n@@ -16473,7 +16473,7 @@ ix86_expand_carry_flag_compare (enum rtx_code code, rtx op0, rtx op1, rtx *pop)\n   return true;\n }\n \n-int\n+bool\n ix86_expand_int_movcc (rtx operands[])\n {\n   enum rtx_code code = GET_CODE (operands[1]), compare_code;\n@@ -16653,7 +16653,7 @@ ix86_expand_int_movcc (rtx operands[])\n \t  if (!rtx_equal_p (tmp, out))\n \t    emit_move_insn (copy_rtx (out), copy_rtx (tmp));\n \n-\t  return 1; /* DONE */\n+\t  return true;\n \t}\n \n       if (diff < 0)\n@@ -16731,7 +16731,7 @@ ix86_expand_int_movcc (rtx operands[])\n \t      if (out != operands[0])\n \t\temit_move_insn (operands[0], out);\n \n-\t      return 1; /* DONE */\n+\t      return true;\n \t    }\n \t}\n \n@@ -16790,7 +16790,7 @@ ix86_expand_int_movcc (rtx operands[])\n \t  if (!rtx_equal_p (out, operands[0]))\n \t    emit_move_insn (operands[0], copy_rtx (out));\n \n-\t  return 1; /* DONE */\n+\t  return true;\n \t}\n \n       /*\n@@ -16884,7 +16884,7 @@ ix86_expand_int_movcc (rtx operands[])\n \t  if (!rtx_equal_p (out, operands[0]))\n \t    emit_move_insn (operands[0], copy_rtx (out));\n \n-\t  return 1; /* DONE */\n+\t  return true;\n \t}\n     }\n \n@@ -16896,7 +16896,7 @@ ix86_expand_int_movcc (rtx operands[])\n       rtx var, orig_out, out, tmp;\n \n       if (BRANCH_COST (optimize_insn_for_speed_p (), false) <= 2)\n-\treturn 0; /* FAIL */\n+\treturn false;\n \n       /* If one of the two operands is an interesting constant, load a\n \t constant with the above and mask it in with a logical operation.  */\n@@ -16909,7 +16909,7 @@ ix86_expand_int_movcc (rtx operands[])\n \t  else if (INTVAL (operands[2]) == -1 && operands[3] != const0_rtx)\n \t    operands[3] = const0_rtx, op = ior_optab;\n \t  else\n-\t    return 0; /* FAIL */\n+\t    return false;\n \t}\n       else if (CONST_INT_P (operands[3]))\n \t{\n@@ -16919,26 +16919,26 @@ ix86_expand_int_movcc (rtx operands[])\n \t  else if (INTVAL (operands[3]) == -1 && operands[3] != const0_rtx)\n \t    operands[2] = const0_rtx, op = ior_optab;\n \t  else\n-\t    return 0; /* FAIL */\n+\t    return false;\n \t}\n       else\n-        return 0; /* FAIL */\n+        return false;\n \n       orig_out = operands[0];\n       tmp = gen_reg_rtx (mode);\n       operands[0] = tmp;\n \n       /* Recurse to get the constant loaded.  */\n       if (ix86_expand_int_movcc (operands) == 0)\n-        return 0; /* FAIL */\n+        return false;\n \n       /* Mask in the interesting variable.  */\n       out = expand_binop (mode, op, var, tmp, orig_out, 0,\n \t\t\t  OPTAB_WIDEN);\n       if (!rtx_equal_p (out, orig_out))\n \temit_move_insn (copy_rtx (orig_out), copy_rtx (out));\n \n-      return 1; /* DONE */\n+      return true;\n     }\n \n   /*\n@@ -16971,8 +16971,7 @@ ix86_expand_int_movcc (rtx operands[])\n \t\t\t  gen_rtx_IF_THEN_ELSE (mode,\n \t\t\t\t\t\tcompare_op, operands[2],\n \t\t\t\t\t\toperands[3])));\n-\n-  return 1; /* DONE */\n+  return true;\n }\n \n /* Swap, force into registers, or otherwise massage the two operands\n@@ -17170,7 +17169,7 @@ ix86_expand_sse_movcc (rtx dest, rtx cmp, rtx op_true, rtx op_false)\n \n /* Expand a floating-point conditional move.  Return true if successful.  */\n \n-int\n+bool\n ix86_expand_fp_movcc (rtx operands[])\n {\n   enum machine_mode mode = GET_MODE (operands[0]);\n@@ -17190,20 +17189,20 @@ ix86_expand_fp_movcc (rtx operands[])\n       if (cmode == VOIDmode)\n \tcmode = GET_MODE (op1);\n       if (cmode != mode)\n-\treturn 0;\n+\treturn false;\n \n       code = ix86_prepare_sse_fp_compare_args (operands[0], code, &op0, &op1);\n       if (code == UNKNOWN)\n-\treturn 0;\n+\treturn false;\n \n       if (ix86_expand_sse_fp_minmax (operands[0], code, op0, op1,\n \t\t\t\t     operands[2], operands[3]))\n-\treturn 1;\n+\treturn true;\n \n       tmp = ix86_expand_sse_cmp (operands[0], code, op0, op1,\n \t\t\t\t operands[2], operands[3]);\n       ix86_expand_sse_movcc (operands[0], tmp, operands[2], operands[3]);\n-      return 1;\n+      return true;\n     }\n \n   /* The floating point conditional move instructions don't directly\n@@ -17222,7 +17221,7 @@ ix86_expand_fp_movcc (rtx operands[])\n \t\t\t  gen_rtx_IF_THEN_ELSE (mode, compare_op,\n \t\t\t\t\t\toperands[2], operands[3])));\n \n-  return 1;\n+  return true;\n }\n \n /* Expand a floating-point vector conditional move; a vcond operation\n@@ -17477,7 +17476,7 @@ ix86_expand_sse4_unpack (rtx operands[2], bool unsigned_p, bool high_p)\n /* Expand conditional increment or decrement using adb/sbb instructions.\n    The default case using setcc followed by the conditional move can be\n    done by generic code.  */\n-int\n+bool\n ix86_expand_int_addcc (rtx operands[])\n {\n   enum rtx_code code = GET_CODE (operands[1]);\n@@ -17492,9 +17491,9 @@ ix86_expand_int_addcc (rtx operands[])\n \n   if (operands[3] != const1_rtx\n       && operands[3] != constm1_rtx)\n-    return 0;\n+    return false;\n   if (!ix86_expand_carry_flag_compare (code, op0, op1, &compare_op))\n-     return 0;\n+     return false;\n   code = GET_CODE (compare_op);\n \n   flags = XEXP (compare_op, 0);\n@@ -17562,7 +17561,7 @@ ix86_expand_int_addcc (rtx operands[])\n     }\n   emit_insn (insn (operands[0], operands[2], val, flags, compare_op));\n \n-  return 1; /* DONE */\n+  return true;\n }\n \n \n@@ -19269,7 +19268,7 @@ smallest_pow2_greater_than (int val)\n    4) Epilogue: code copying tail of the block that is too small to be\n       handled by main body (or up to size guarded by prologue guard).  */\n \n-int\n+bool\n ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n \t\t    rtx expected_align_exp, rtx expected_size_exp)\n {\n@@ -19305,7 +19304,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n \n   /* Make sure we don't need to care about overflow later on.  */\n   if (count > ((unsigned HOST_WIDE_INT) 1 << 30))\n-    return 0;\n+    return false;\n \n   /* Step 0: Decide on preferred algorithm, desired alignment and\n      size of chunks to be copied by main loop.  */\n@@ -19317,7 +19316,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n     align = desired_align;\n \n   if (alg == libcall)\n-    return 0;\n+    return false;\n   gcc_assert (alg != no_stringop);\n   if (!count)\n     count_exp = copy_to_mode_reg (GET_MODE (count_exp), count_exp);\n@@ -19563,7 +19562,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n \t\t\t    epilogue_size_needed);\n   if (jump_around_label)\n     emit_label (jump_around_label);\n-  return 1;\n+  return true;\n }\n \n /* Helper function for memcpy.  For QImode value 0xXY produce\n@@ -19662,7 +19661,7 @@ promote_duplicated_reg_to_size (rtx val, int size_needed, int desired_align, int\n /* Expand string clear operation (bzero).  Use i386 string operations when\n    profitable.  See expand_movmem comment for explanation of individual\n    steps performed.  */\n-int\n+bool\n ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n \t\t    rtx expected_align_exp, rtx expected_size_exp)\n {\n@@ -19694,7 +19693,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n \n   /* Make sure we don't need to care about overflow later on.  */\n   if (count > ((unsigned HOST_WIDE_INT) 1 << 30))\n-    return 0;\n+    return false;\n \n   /* Step 0: Decide on preferred algorithm, desired alignment and\n      size of chunks to be copied by main loop.  */\n@@ -19706,7 +19705,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n     align = desired_align;\n \n   if (alg == libcall)\n-    return 0;\n+    return false;\n   gcc_assert (alg != no_stringop);\n   if (!count)\n     count_exp = copy_to_mode_reg (counter_mode (count_exp), count_exp);\n@@ -19952,7 +19951,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n     }\n   if (jump_around_label)\n     emit_label (jump_around_label);\n-  return 1;\n+  return true;\n }\n \n /* Expand the appropriate insns for doing strlen if not just doing\n@@ -20130,7 +20129,7 @@ ix86_expand_strlensi_unroll_1 (rtx out, rtx src, rtx align_rtx)\n \n /* Expand strlen.  */\n \n-int\n+bool\n ix86_expand_strlen (rtx out, rtx src, rtx eoschar, rtx align)\n {\n   rtx addr, scratch1, scratch2, scratch3, scratch4;\n@@ -20142,7 +20141,7 @@ ix86_expand_strlen (rtx out, rtx src, rtx eoschar, rtx align)\n       && !TARGET_INLINE_ALL_STRINGOPS\n       && !optimize_insn_for_size_p ()\n       && (!CONST_INT_P (align) || INTVAL (align) < 4))\n-    return 0;\n+    return false;\n \n   addr = force_reg (Pmode, XEXP (src, 0));\n   scratch1 = gen_reg_rtx (Pmode);\n@@ -20191,7 +20190,7 @@ ix86_expand_strlen (rtx out, rtx src, rtx eoschar, rtx align)\n       emit_insn (ix86_gen_one_cmpl2 (scratch2, scratch1));\n       emit_insn (ix86_gen_add3 (out, scratch2, constm1_rtx));\n     }\n-  return 1;\n+  return true;\n }\n \n /* For given symbol (function) construct code to compute address of it's PLT\n@@ -26267,9 +26266,9 @@ ix86_class_likely_spilled_p (reg_class_t rclass)\n    When STRICT is false, we are being called from REGISTER_MOVE_COST, so do not\n    enforce these sanity checks.  */\n \n-static inline int\n+static inline bool\n inline_secondary_memory_needed (enum reg_class class1, enum reg_class class2,\n-\t\t\t      enum machine_mode mode, int strict)\n+\t\t\t\tenum machine_mode mode, int strict)\n {\n   if (MAYBE_FLOAT_CLASS_P (class1) != FLOAT_CLASS_P (class1)\n       || MAYBE_FLOAT_CLASS_P (class2) != FLOAT_CLASS_P (class2)\n@@ -26310,7 +26309,7 @@ inline_secondary_memory_needed (enum reg_class class1, enum reg_class class2,\n   return false;\n }\n \n-int\n+bool\n ix86_secondary_memory_needed (enum reg_class class1, enum reg_class class2,\n \t\t\t      enum machine_mode mode, int strict)\n {"}, {"sha": "8fe0f345ef79b5cb4a108c964c90bf8294f0e708", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 133, "deletions": 134, "changes": 267, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19ed9d7bb5ca92a3e70f5e590de2647036b1ab13/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=19ed9d7bb5ca92a3e70f5e590de2647036b1ab13", "patch": "@@ -18,22 +18,22 @@\n ;; along with GCC; see the file COPYING3.  If not see\n ;; <http://www.gnu.org/licenses/>.\n \n-;; Return nonzero if OP is either a i387 or SSE fp register.\n+;; Return true if OP is either a i387 or SSE fp register.\n (define_predicate \"any_fp_register_operand\"\n   (and (match_code \"reg\")\n        (match_test \"ANY_FP_REGNO_P (REGNO (op))\")))\n \n-;; Return nonzero if OP is an i387 fp register.\n+;; Return true if OP is an i387 fp register.\n (define_predicate \"fp_register_operand\"\n   (and (match_code \"reg\")\n        (match_test \"FP_REGNO_P (REGNO (op))\")))\n \n-;; Return nonzero if OP is a non-fp register_operand.\n+;; Return true if OP is a non-fp register_operand.\n (define_predicate \"register_and_not_any_fp_reg_operand\"\n   (and (match_code \"reg\")\n        (not (match_test \"ANY_FP_REGNO_P (REGNO (op))\"))))\n \n-;; Return nonzero if OP is a register operand other than an i387 fp register.\n+;; Return true if OP is a register operand other than an i387 fp register.\n (define_predicate \"register_and_not_fp_reg_operand\"\n   (and (match_code \"reg\")\n        (not (match_test \"FP_REGNO_P (REGNO (op))\"))))\n@@ -63,18 +63,18 @@\n {\n   if ((!TARGET_64BIT || GET_MODE (op) != DImode)\n       && GET_MODE (op) != SImode && GET_MODE (op) != HImode)\n-    return 0;\n+    return false;\n   if (GET_CODE (op) == SUBREG)\n     op = SUBREG_REG (op);\n \n   /* Be careful to accept only registers having upper parts.  */\n-  return REGNO (op) > LAST_VIRTUAL_REGISTER || REGNO (op) < 4;\n+  return REGNO (op) > LAST_VIRTUAL_REGISTER || REGNO (op) <= BX_REG;\n })\n \n ;; Return true if op is the AX register.\n (define_predicate \"ax_reg_operand\"\n   (and (match_code \"reg\")\n-       (match_test \"REGNO (op) == 0\")))\n+       (match_test \"REGNO (op) == AX_REG\")))\n \n ;; Return true if op is the flags register.\n (define_predicate \"flags_reg_operand\"\n@@ -98,16 +98,14 @@\n ;; Return true if op is not xmm0 register.\n (define_predicate \"reg_not_xmm0_operand\"\n    (and (match_operand 0 \"register_operand\")\n-\t(match_test \"!REG_P (op) \n-\t\t     || REGNO (op) != FIRST_SSE_REG\")))\n+\t(match_test \"REGNO (op) != FIRST_SSE_REG\")))\n \n ;; As above, but allow nonimmediate operands.\n (define_predicate \"nonimm_not_xmm0_operand\"\n-   (and (match_operand 0 \"nonimmediate_operand\")\n-\t(match_test \"!REG_P (op) \n-\t\t     || REGNO (op) != FIRST_SSE_REG\")))\n+   (ior (match_operand 0 \"memory_operand\")\n+\t(match_operand 0 \"reg_not_xmm0_operand\")))\n \n-;; Return 1 if VALUE can be stored in a sign extended immediate field.\n+;; Return true if VALUE can be stored in a sign extended immediate field.\n (define_predicate \"x86_64_immediate_operand\"\n   (match_code \"const_int,symbol_ref,label_ref,const\")\n {\n@@ -121,7 +119,7 @@\n          to be at least 32 and this all acceptable constants are\n \t represented as CONST_INT.  */\n       if (HOST_BITS_PER_WIDE_INT == 32)\n-\treturn 1;\n+\treturn true;\n       else\n \t{\n \t  HOST_WIDE_INT val = trunc_int_for_mode (INTVAL (op), DImode);\n@@ -155,7 +153,7 @@\n \t  case UNSPEC_DTPOFF:\n \t  case UNSPEC_GOTNTPOFF:\n \t  case UNSPEC_NTPOFF:\n-\t    return 1;\n+\t    return true;\n \t  default:\n \t    break;\n \t  }\n@@ -167,16 +165,16 @@\n \t  HOST_WIDE_INT offset;\n \n \t  if (ix86_cmodel == CM_LARGE)\n-\t    return 0;\n+\t    return false;\n \t  if (!CONST_INT_P (op2))\n-\t    return 0;\n+\t    return false;\n \t  offset = trunc_int_for_mode (INTVAL (op2), DImode);\n \t  switch (GET_CODE (op1))\n \t    {\n \t    case SYMBOL_REF:\n \t      /* TLS symbols are not constant.  */\n \t      if (SYMBOL_REF_TLS_MODEL (op1))\n-\t\treturn 0;\n+\t\treturn false;\n \t      /* For CM_SMALL assume that latest object is 16MB before\n \t\t end of 31bits boundary.  We may also accept pretty\n \t\t large negative constants knowing that all objects are\n@@ -186,15 +184,15 @@\n \t\t       && !SYMBOL_REF_FAR_ADDR_P (op1)))\n \t\t  && offset < 16*1024*1024\n \t\t  && trunc_int_for_mode (offset, SImode) == offset)\n-\t\treturn 1;\n+\t\treturn true;\n \t      /* For CM_KERNEL we know that all object resist in the\n \t\t negative half of 32bits address space.  We may not\n \t\t accept negative offsets, since they may be just off\n \t\t and we may accept pretty large positive ones.  */\n \t      if (ix86_cmodel == CM_KERNEL\n \t\t  && offset > 0\n \t\t  && trunc_int_for_mode (offset, SImode) == offset)\n-\t\treturn 1;\n+\t\treturn true;\n \t      break;\n \n \t    case LABEL_REF:\n@@ -203,11 +201,11 @@\n \t      if ((ix86_cmodel == CM_SMALL || ix86_cmodel == CM_MEDIUM)\n \t\t  && offset < 16*1024*1024\n \t\t  && trunc_int_for_mode (offset, SImode) == offset)\n-\t\treturn 1;\n+\t\treturn true;\n \t      if (ix86_cmodel == CM_KERNEL\n \t\t  && offset > 0\n \t\t  && trunc_int_for_mode (offset, SImode) == offset)\n-\t\treturn 1;\n+\t\treturn true;\n \t      break;\n \n \t    case UNSPEC:\n@@ -217,7 +215,7 @@\n \t\tcase UNSPEC_NTPOFF:\n \t\t  if (offset > 0\n \t\t      && trunc_int_for_mode (offset, SImode) == offset)\n-\t\t    return 1;\n+\t\t    return true;\n \t\t}\n \t      break;\n \n@@ -231,10 +229,10 @@\n \tgcc_unreachable ();\n     }\n \n-  return 0;\n+  return false;\n })\n \n-;; Return 1 if VALUE can be stored in the zero extended immediate field.\n+;; Return true if VALUE can be stored in the zero extended immediate field.\n (define_predicate \"x86_64_zext_immediate_operand\"\n   (match_code \"const_double,const_int,symbol_ref,label_ref,const\")\n {\n@@ -244,7 +242,7 @@\n       if (HOST_BITS_PER_WIDE_INT == 32)\n \treturn (GET_MODE (op) == VOIDmode && !CONST_DOUBLE_HIGH (op));\n       else\n-\treturn 0;\n+\treturn false;\n \n     case CONST_INT:\n       if (HOST_BITS_PER_WIDE_INT == 32)\n@@ -274,13 +272,13 @@\n \t  rtx op2 = XEXP (XEXP (op, 0), 1);\n \n \t  if (ix86_cmodel == CM_LARGE)\n-\t    return 0;\n+\t    return false;\n \t  switch (GET_CODE (op1))\n \t    {\n \t    case SYMBOL_REF:\n \t      /* TLS symbols are not constant.  */\n \t      if (SYMBOL_REF_TLS_MODEL (op1))\n-\t\treturn 0;\n+\t\treturn false;\n \t      /* For small code model we may accept pretty large positive\n \t\t offsets, since one bit is available for free.  Negative\n \t\t offsets are limited by the size of NULL pointer area\n@@ -291,7 +289,7 @@\n \t\t  && CONST_INT_P (op2)\n \t\t  && trunc_int_for_mode (INTVAL (op2), DImode) > -0x10000\n \t\t  && trunc_int_for_mode (INTVAL (op2), SImode) == INTVAL (op2))\n-\t\treturn 1;\n+\t\treturn true;\n \t      /* ??? For the kernel, we may accept adjustment of\n \t\t -0x10000000, since we know that it will just convert\n \t\t negative address space to positive, but perhaps this\n@@ -305,29 +303,29 @@\n \t\t  && CONST_INT_P (op2)\n \t\t  && trunc_int_for_mode (INTVAL (op2), DImode) > -0x10000\n \t\t  && trunc_int_for_mode (INTVAL (op2), SImode) == INTVAL (op2))\n-\t\treturn 1;\n+\t\treturn true;\n \t      break;\n \n \t    default:\n-\t      return 0;\n+\t      return false;\n \t    }\n \t}\n       break;\n \n     default:\n       gcc_unreachable ();\n     }\n-  return 0;\n+  return false;\n })\n \n-;; Return nonzero if OP is general operand representable on x86_64.\n+;; Return true if OP is general operand representable on x86_64.\n (define_predicate \"x86_64_general_operand\"\n   (if_then_else (match_test \"TARGET_64BIT\")\n     (ior (match_operand 0 \"nonimmediate_operand\")\n \t (match_operand 0 \"x86_64_immediate_operand\"))\n     (match_operand 0 \"general_operand\")))\n \n-;; Return nonzero if OP is general operand representable on x86_64\n+;; Return true if OP is general operand representable on x86_64\n ;; as either sign extended or zero extended constant.\n (define_predicate \"x86_64_szext_general_operand\"\n   (if_then_else (match_test \"TARGET_64BIT\")\n@@ -336,14 +334,14 @@\n \t (match_operand 0 \"x86_64_zext_immediate_operand\"))\n     (match_operand 0 \"general_operand\")))\n \n-;; Return nonzero if OP is nonmemory operand representable on x86_64.\n+;; Return true if OP is nonmemory operand representable on x86_64.\n (define_predicate \"x86_64_nonmemory_operand\"\n   (if_then_else (match_test \"TARGET_64BIT\")\n     (ior (match_operand 0 \"register_operand\")\n \t (match_operand 0 \"x86_64_immediate_operand\"))\n     (match_operand 0 \"nonmemory_operand\")))\n \n-;; Return nonzero if OP is nonmemory operand representable on x86_64.\n+;; Return true if OP is nonmemory operand representable on x86_64.\n (define_predicate \"x86_64_szext_nonmemory_operand\"\n   (if_then_else (match_test \"TARGET_64BIT\")\n     (ior (match_operand 0 \"register_operand\")\n@@ -357,7 +355,7 @@\n   (match_code \"const,symbol_ref,label_ref\")\n {\n   if (!flag_pic)\n-    return 0;\n+    return false;\n   /* Rule out relocations that translate into 64bit constants.  */\n   if (TARGET_64BIT && GET_CODE (op) == CONST)\n     {\n@@ -367,21 +365,21 @@\n       if (GET_CODE (op) == UNSPEC\n \t  && (XINT (op, 1) == UNSPEC_GOTOFF\n \t      || XINT (op, 1) == UNSPEC_GOT))\n-\treturn 0;\n+\treturn false;\n     }\n   return symbolic_operand (op, mode);\n })\n \n \n-;; Return nonzero if OP is nonmemory operand acceptable by movabs patterns.\n+;; Return true if OP is nonmemory operand acceptable by movabs patterns.\n (define_predicate \"x86_64_movabs_operand\"\n   (if_then_else (match_test \"!TARGET_64BIT || !flag_pic\")\n     (match_operand 0 \"nonmemory_operand\")\n     (ior (match_operand 0 \"register_operand\")\n \t (and (match_operand 0 \"const_double_operand\")\n \t      (match_test \"GET_MODE_SIZE (mode) <= 8\")))))\n \n-;; Returns nonzero if OP is either a symbol reference or a sum of a symbol\n+;; Return true if OP is either a symbol reference or a sum of a symbol\n ;; reference and a constant.\n (define_predicate \"symbolic_operand\"\n   (match_code \"symbol_ref,label_ref,const\")\n@@ -390,7 +388,7 @@\n     {\n     case SYMBOL_REF:\n     case LABEL_REF:\n-      return 1;\n+      return true;\n \n     case CONST:\n       op = XEXP (op, 0);\n@@ -400,25 +398,25 @@\n \t      && (XINT (op, 1) == UNSPEC_GOT\n \t\t  || XINT (op, 1) == UNSPEC_GOTOFF\n \t\t  || XINT (op, 1) == UNSPEC_GOTPCREL)))\n-\treturn 1;\n+\treturn true;\n       if (GET_CODE (op) != PLUS\n \t  || !CONST_INT_P (XEXP (op, 1)))\n-\treturn 0;\n+\treturn false;\n \n       op = XEXP (op, 0);\n       if (GET_CODE (op) == SYMBOL_REF\n \t  || GET_CODE (op) == LABEL_REF)\n-\treturn 1;\n+\treturn true;\n       /* Only @GOTOFF gets offsets.  */\n       if (GET_CODE (op) != UNSPEC\n \t  || XINT (op, 1) != UNSPEC_GOTOFF)\n-\treturn 0;\n+\treturn false;\n \n       op = XVECEXP (op, 0, 0);\n       if (GET_CODE (op) == SYMBOL_REF\n \t  || GET_CODE (op) == LABEL_REF)\n-\treturn 1;\n-      return 0;\n+\treturn true;\n+      return false;\n \n     default:\n       gcc_unreachable ();\n@@ -435,16 +433,16 @@\n     op = XEXP (XEXP (op, 0), 0);\n \n   if (GET_CODE (op) == LABEL_REF)\n-    return 1;\n+    return true;\n \n   if (GET_CODE (op) != SYMBOL_REF)\n-    return 0;\n+    return false;\n \n-  if (SYMBOL_REF_TLS_MODEL (op) != 0)\n-    return 0;\n+  if (SYMBOL_REF_TLS_MODEL (op))\n+    return false;\n \n   if (SYMBOL_REF_LOCAL_P (op))\n-    return 1;\n+    return true;\n \n   /* There is, however, a not insubstantial body of code in the rest of\n      the compiler that assumes it can just stick the results of\n@@ -453,9 +451,9 @@\n      always create a DECL an invoke targetm.encode_section_info.  */\n   if (strncmp (XSTR (op, 0), internal_label_prefix,\n \t       internal_label_prefix_len) == 0)\n-    return 1;\n+    return true;\n \n-  return 0;\n+  return false;\n })\n \n ;; Test for a legitimate @GOTOFF operand.\n@@ -473,7 +471,7 @@\n ;; Test for various thread-local symbols.\n (define_predicate \"tls_symbolic_operand\"\n   (and (match_code \"symbol_ref\")\n-       (match_test \"SYMBOL_REF_TLS_MODEL (op) != 0\")))\n+       (match_test \"SYMBOL_REF_TLS_MODEL (op)\")))\n \n (define_predicate \"tls_modbase_operand\"\n   (and (match_code \"symbol_ref\")\n@@ -519,7 +517,7 @@\n     op = SUBREG_REG (op);\n \n   if (!TARGET_64BIT && op == stack_pointer_rtx)\n-    return 0;\n+    return false;\n \n   return register_no_elim_operand (op, mode);\n })\n@@ -635,13 +633,13 @@\n   return val <= 255*8 && val % 8 == 0;\n })\n \n-;; Return nonzero if OP is CONST_INT >= 1 and <= 31 (a valid operand\n+;; Return true if OP is CONST_INT >= 1 and <= 31 (a valid operand\n ;; for shift & compare patterns, as shifting by 0 does not change flags).\n (define_predicate \"const_1_to_31_operand\"\n   (and (match_code \"const_int\")\n        (match_test \"IN_RANGE (INTVAL (op), 1, 31)\")))\n \n-;; Return nonzero if OP is CONST_INT >= 1 and <= 63 (a valid operand\n+;; Return true if OP is CONST_INT >= 1 and <= 63 (a valid operand\n ;; for 64bit shift & compare patterns, as shifting by 0 does not change flags).\n (define_predicate \"const_1_to_63_operand\"\n   (and (match_code \"const_int\")\n@@ -713,7 +711,7 @@\n   /* On Pentium4, the inc and dec operations causes extra dependency on flag\n      registers, since carry flag is not set.  */\n   if (!TARGET_USE_INCDEC && !optimize_insn_for_size_p ())\n-    return 0;\n+    return false;\n   return op == const1_rtx || op == constm1_rtx;\n })\n \n@@ -743,17 +741,17 @@\n   op = maybe_get_pool_constant (op);\n \n   if (!(op && GET_CODE (op) == CONST_VECTOR))\n-    return 0;\n+    return false;\n \n   n_elts = CONST_VECTOR_NUNITS (op);\n \n   for (n_elts--; n_elts > 0; n_elts--)\n     {\n       rtx elt = CONST_VECTOR_ELT (op, n_elts);\n       if (elt != CONST0_RTX (GET_MODE_INNER (GET_MODE (op))))\n-\treturn 0;\n+\treturn false;\n     }\n-  return 1;\n+  return true;\n })\n \n /* Return true if operand is a vector constant that is all ones. */\n@@ -770,28 +768,28 @@\n         {\n           rtx x = CONST_VECTOR_ELT (op, i);\n           if (x != constm1_rtx)\n-            return 0;\n+            return false;\n         }\n-      return 1;\n+      return true;\n     }\n \n-  return 0;\n+  return false;\n })\n \n-; Return 1 when OP is operand acceptable for standard SSE move.\n+; Return true when OP is operand acceptable for standard SSE move.\n (define_predicate \"vector_move_operand\"\n   (ior (match_operand 0 \"nonimmediate_operand\")\n        (match_operand 0 \"const0_operand\")))\n \n-;; Return 1 when OP is nonimmediate or standard SSE constant.\n+;; Return true when OP is nonimmediate or standard SSE constant.\n (define_predicate \"nonimmediate_or_sse_const_operand\"\n   (match_operand 0 \"general_operand\")\n {\n   if (nonimmediate_operand (op, mode))\n-    return 1;\n+    return true;\n   if (standard_sse_constant_p (op) > 0)\n-    return 1;\n-  return 0;\n+    return true;\n+  return false;\n })\n \n ;; Return true if OP is a register or a zero.\n@@ -812,7 +810,7 @@\n   return parts.seg == SEG_DEFAULT;\n })\n \n-;; Return nonzero if the rtx is known to be at least 32 bits aligned.\n+;; Return true if the rtx is known to be at least 32 bits aligned.\n (define_predicate \"aligned_operand\"\n   (match_operand 0 \"general_operand\")\n {\n@@ -821,26 +819,26 @@\n \n   /* Registers and immediate operands are always \"aligned\".  */\n   if (!MEM_P (op))\n-    return 1;\n+    return true;\n \n   /* All patterns using aligned_operand on memory operands ends up\n      in promoting memory operand to 64bit and thus causing memory mismatch.  */\n   if (TARGET_MEMORY_MISMATCH_STALL && !optimize_insn_for_size_p ())\n-    return 0;\n+    return false;\n \n   /* Don't even try to do any aligned optimizations with volatiles.  */\n   if (MEM_VOLATILE_P (op))\n-    return 0;\n+    return false;\n \n   if (MEM_ALIGN (op) >= 32)\n-    return 1;\n+    return true;\n \n   op = XEXP (op, 0);\n \n   /* Pushes and pops are only valid on the stack pointer.  */\n   if (GET_CODE (op) == PRE_DEC\n       || GET_CODE (op) == POST_INC)\n-    return 1;\n+    return true;\n \n   /* Decode the address.  */\n   ok = ix86_decompose_address (op, &parts);\n@@ -850,25 +848,25 @@\n   if (parts.index)\n     {\n       if (REGNO_POINTER_ALIGN (REGNO (parts.index)) * parts.scale < 32)\n-\treturn 0;\n+\treturn false;\n     }\n   if (parts.base)\n     {\n       if (REGNO_POINTER_ALIGN (REGNO (parts.base)) < 32)\n-\treturn 0;\n+\treturn false;\n     }\n   if (parts.disp)\n     {\n       if (!CONST_INT_P (parts.disp)\n-\t  || (INTVAL (parts.disp) & 3) != 0)\n-\treturn 0;\n+\t  || (INTVAL (parts.disp) & 3))\n+\treturn false;\n     }\n \n   /* Didn't find one -- this must be an aligned address.  */\n-  return 1;\n+  return true;\n })\n \n-;; Returns 1 if OP is memory operand with a displacement.\n+;; Return true if OP is memory operand with a displacement.\n (define_predicate \"memory_displacement_operand\"\n   (match_operand 0 \"memory_operand\")\n {\n@@ -880,26 +878,26 @@\n   return parts.disp != NULL_RTX;\n })\n \n-;; Returns 1 if OP is memory operand with a displacement only.\n+;; Return true if OP is memory operand with a displacement only.\n (define_predicate \"memory_displacement_only_operand\"\n   (match_operand 0 \"memory_operand\")\n {\n   struct ix86_address parts;\n   int ok;\n \n   if (TARGET_64BIT)\n-    return 0;\n+    return false;\n \n   ok = ix86_decompose_address (XEXP (op, 0), &parts);\n   gcc_assert (ok);\n \n   if (parts.base || parts.index)\n-    return 0;\n+    return false;\n \n   return parts.disp != NULL_RTX;\n })\n \n-;; Returns 1 if OP is memory operand which will need zero or\n+;; Return true if OP is memory operand which will need zero or\n ;; one register at most, not counting stack pointer or frame pointer.\n (define_predicate \"cmpxchg8b_pic_memory_operand\"\n   (match_operand 0 \"memory_operand\")\n@@ -914,26 +912,26 @@\n       || parts.base == frame_pointer_rtx\n       || parts.base == hard_frame_pointer_rtx\n       || parts.base == stack_pointer_rtx)\n-    return 1;\n+    return true;\n \n   if (parts.index == NULL_RTX\n       || parts.index == arg_pointer_rtx\n       || parts.index == frame_pointer_rtx\n       || parts.index == hard_frame_pointer_rtx\n       || parts.index == stack_pointer_rtx)\n-    return 1;\n+    return true;\n \n-  return 0;\n+  return false;\n })\n \n \n-;; Returns 1 if OP is memory operand that cannot be represented\n+;; Return true if OP is memory operand that cannot be represented\n ;; by the modRM array.\n (define_predicate \"long_memory_operand\"\n   (and (match_operand 0 \"memory_operand\")\n-       (match_test \"memory_address_length (op) != 0\")))\n+       (match_test \"memory_address_length (op)\")))\n \n-;; Return 1 if OP is a comparison operator that can be issued by fcmov.\n+;; Return true if OP is a comparison operator that can be issued by fcmov.\n (define_predicate \"fcmov_comparison_operator\"\n   (match_operand 0 \"comparison_operator\")\n {\n@@ -943,7 +941,7 @@\n   if (inmode == CCFPmode || inmode == CCFPUmode)\n     {\n       if (!ix86_trivial_fp_comparison_operator (op, mode))\n-\treturn 0;\n+\treturn false;\n       code = ix86_fp_compare_code_to_integer (code);\n     }\n   /* i387 supports just limited amount of conditional codes.  */\n@@ -952,17 +950,17 @@\n     case LTU: case GTU: case LEU: case GEU:\n       if (inmode == CCmode || inmode == CCFPmode || inmode == CCFPUmode\n \t  || inmode == CCCmode)\n-\treturn 1;\n-      return 0;\n+\treturn true;\n+      return false;\n     case ORDERED: case UNORDERED:\n     case EQ: case NE:\n-      return 1;\n+      return true;\n     default:\n-      return 0;\n+      return false;\n     }\n })\n \n-;; Return 1 if OP is a comparison that can be used in the CMPSS/CMPPS insns.\n+;; Return true if OP is a comparison that can be used in the CMPSS/CMPPS insns.\n ;; The first set are supported directly; the second set can't be done with\n ;; full IEEE support, i.e. NaNs.\n ;;\n@@ -974,7 +972,7 @@\n (define_special_predicate \"sse_comparison_operator\"\n   (match_code \"eq,lt,le,unordered,ne,unge,ungt,ordered\"))\n \n-;; Return 1 if OP is a comparison operator that can be issued by\n+;; Return true if OP is a comparison operator that can be issued by\n ;; avx predicate generation instructions\n (define_predicate \"avx_comparison_float_operator\"\n   (match_code \"ne,eq,ge,gt,le,lt,unordered,ordered,uneq,unge,ungt,unle,unlt,ltgt\"))\n@@ -988,7 +986,7 @@\n (define_predicate \"bt_comparison_operator\"\n   (match_code \"ne,eq\"))\n \n-;; Return 1 if OP is a valid comparison operator in valid mode.\n+;; Return true if OP is a valid comparison operator in valid mode.\n (define_predicate \"ix86_comparison_operator\"\n   (match_operand 0 \"comparison_operator\")\n {\n@@ -1001,30 +999,31 @@\n   switch (code)\n     {\n     case EQ: case NE:\n-      return 1;\n+      return true;\n     case LT: case GE:\n       if (inmode == CCmode || inmode == CCGCmode\n \t  || inmode == CCGOCmode || inmode == CCNOmode)\n-\treturn 1;\n-      return 0;\n+\treturn true;\n+      return false;\n     case LTU: case GTU: case LEU: case GEU:\n       if (inmode == CCmode || inmode == CCCmode)\n-\treturn 1;\n-      return 0;\n+\treturn true;\n+      return false;\n     case ORDERED: case UNORDERED:\n       if (inmode == CCmode)\n-\treturn 1;\n-      return 0;\n+\treturn true;\n+      return false;\n     case GT: case LE:\n       if (inmode == CCmode || inmode == CCGCmode || inmode == CCNOmode)\n-\treturn 1;\n-      return 0;\n+\treturn true;\n+      return false;\n     default:\n-      return 0;\n+      return false;\n     }\n })\n \n-;; Return 1 if OP is a valid comparison operator testing carry flag to be set.\n+;; Return true if OP is a valid comparison operator\n+;; testing carry flag to be set.\n (define_predicate \"ix86_carry_flag_operator\"\n   (match_code \"ltu,lt,unlt,gtu,gt,ungt,le,unle,ge,unge,ltgt,uneq\")\n {\n@@ -1034,22 +1033,22 @@\n   if (inmode == CCFPmode || inmode == CCFPUmode)\n     {\n       if (!ix86_trivial_fp_comparison_operator (op, mode))\n-\treturn 0;\n+\treturn false;\n       code = ix86_fp_compare_code_to_integer (code);\n     }\n   else if (inmode == CCCmode)\n    return code == LTU || code == GTU;\n   else if (inmode != CCmode)\n-    return 0;\n+    return false;\n \n   return code == LTU;\n })\n \n-;; Return 1 if this comparison only requires testing one flag bit.\n+;; Return true if this comparison only requires testing one flag bit.\n (define_predicate \"ix86_trivial_fp_comparison_operator\"\n   (match_code \"gt,ge,unlt,unle,uneq,ltgt,ordered,unordered\"))\n \n-;; Return 1 if we know how to do this comparison.  Others require\n+;; Return true if we know how to do this comparison.  Others require\n ;; testing more than one flag bit, and we let the generic middle-end\n ;; code do that.\n (define_predicate \"ix86_fp_comparison_operator\"\n@@ -1063,7 +1062,7 @@\n   (match_operand 0 \"comparison_operator\")\n {\n   enum rtx_code code = GET_CODE (op);\n-  int ret;\n+  bool ret;\n \n   PUT_CODE (op, swap_condition (code));\n   ret = ix86_fp_comparison_operator (op, mode);\n@@ -1103,7 +1102,7 @@\n (define_predicate \"commutative_operator\"\n   (match_code \"plus,mult,and,ior,xor,smin,smax,umin,umax\"))\n \n-;; Return 1 if OP is a binary operator that can be promoted to wider mode.\n+;; Return true if OP is a binary operator that can be promoted to wider mode.\n (define_predicate \"promotable_binary_operator\"\n   (ior (match_code \"plus,and,ior,xor,ashift\")\n        (and (match_code \"mult\")\n@@ -1115,19 +1114,19 @@\n (define_predicate \"absneg_operator\"\n   (match_code \"abs,neg\"))\n \n-;; Return 1 if OP is misaligned memory operand\n+;; Return true if OP is misaligned memory operand\n (define_predicate \"misaligned_operand\"\n   (and (match_code \"mem\")\n        (match_test \"MEM_ALIGN (op) < GET_MODE_ALIGNMENT (mode)\")))\n \n-;; Return 1 if OP is a emms operation, known to be a PARALLEL.\n+;; Return true if OP is a emms operation, known to be a PARALLEL.\n (define_predicate \"emms_operation\"\n   (match_code \"parallel\")\n {\n   unsigned i;\n \n   if (XVECLEN (op, 0) != 17)\n-    return 0;\n+    return false;\n \n   for (i = 0; i < 8; i++)\n     {\n@@ -1137,27 +1136,27 @@\n \t  || GET_CODE (SET_DEST (elt)) != REG\n \t  || GET_MODE (SET_DEST (elt)) != XFmode\n \t  || REGNO (SET_DEST (elt)) != FIRST_STACK_REG + i)\n-        return 0;\n+        return false;\n \n       elt = XVECEXP (op, 0, i+9);\n \n       if (GET_CODE (elt) != CLOBBER\n \t  || GET_CODE (SET_DEST (elt)) != REG\n \t  || GET_MODE (SET_DEST (elt)) != DImode\n \t  || REGNO (SET_DEST (elt)) != FIRST_MMX_REG + i)\n-\treturn 0;\n+\treturn false;\n     }\n-  return 1;\n+  return true;\n })\n \n-;; Return 1 if OP is a vzeroall operation, known to be a PARALLEL.\n+;; Return true if OP is a vzeroall operation, known to be a PARALLEL.\n (define_predicate \"vzeroall_operation\"\n   (match_code \"parallel\")\n {\n   unsigned i, nregs = TARGET_64BIT ? 16 : 8;\n \n   if ((unsigned) XVECLEN (op, 0) != 1 + nregs)\n-    return 0;\n+    return false;\n \n   for (i = 0; i < nregs; i++)\n     {\n@@ -1168,19 +1167,19 @@\n \t  || GET_MODE (SET_DEST (elt)) != V8SImode\n \t  || REGNO (SET_DEST (elt)) != SSE_REGNO (i)\n \t  || SET_SRC (elt) != CONST0_RTX (V8SImode))\n-\treturn 0;\n+\treturn false;\n     }\n-  return 1;\n+  return true;\n })\n \n-;; Return 1 if OP is a vzeroupper operation, known to be a PARALLEL.\n+;; Return true if OP is a vzeroupper operation, known to be a PARALLEL.\n (define_predicate \"vzeroupper_operation\"\n   (match_code \"parallel\")\n {\n   unsigned i, nregs = TARGET_64BIT ? 16 : 8;\n  \n   if ((unsigned) XVECLEN (op, 0) != 1 + nregs)\n-    return 0;\n+    return false;\n \n   for (i = 0; i < nregs; i++)\n     {\n@@ -1190,12 +1189,12 @@\n \t  || GET_CODE (SET_DEST (elt)) != REG\n \t  || GET_MODE (SET_DEST (elt)) != V8SImode\n \t  || REGNO (SET_DEST (elt)) != SSE_REGNO (i))\n-\treturn 0;\n+\treturn false;\n     }\n-  return 1;\n+  return true;\n })\n \n-;; Return 1 if OP is a parallel for a vpermilp[ds] permute.\n+;; Return true if OP is a parallel for a vpermilp[ds] permute.\n ;; ??? It would be much easier if the PARALLEL for a VEC_SELECT\n ;; had a mode, but it doesn't.  So we have 4 copies and install\n ;; the mode by hand.\n@@ -1216,7 +1215,7 @@\n   (and (match_code \"parallel\")\n        (match_test \"avx_vpermilp_parallel (op, V2DFmode)\")))\n \n-;; Return 1 if OP is a parallel for a vperm2f128 permute.\n+;; Return true if OP is a parallel for a vperm2f128 permute.\n \n (define_predicate \"avx_vperm2f128_v8sf_operand\"\n   (and (match_code \"parallel\")\n@@ -1230,7 +1229,7 @@\n   (and (match_code \"parallel\")\n        (match_test \"avx_vperm2f128_parallel (op, V4DFmode)\")))\n \n-;; Return 1 if OP is a parallel for a vbroadcast permute.\n+;; Return true if OP is a parallel for a vbroadcast permute.\n \n (define_predicate \"avx_vbroadcast_operand\"\n   (and (match_code \"parallel\")"}]}