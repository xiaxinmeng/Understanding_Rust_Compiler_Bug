{"sha": "099e9712f166092364e51630f3e5138f3ff81811", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDk5ZTk3MTJmMTY2MDkyMzY0ZTUxNjMwZjNlNTEzOGYzZmY4MTgxMQ==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2000-05-15T19:12:54Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2000-05-15T19:12:54Z"}, "message": "calls.c: Re-install both patches reverted by last patch.\n\n\t* calls.c: Re-install both patches reverted by last patch.\n\t(struct arg_data): New field tail_call_reg.\n\t(initialize_argument_information): Initialize tail_call_reg\n\t(load_register_parameters): New argument flags, use\n\ttail_call_reg when emiting tail call sequence.\n\t(expand_call): Update call of load_register_parameters;\n\tcopy unadjusted_args_size to adjusted_args_size.\n\nFrom-SVN: r33913", "tree": {"sha": "8a9bac26103d9a0299e10a31fd58fd9bea2ae99b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8a9bac26103d9a0299e10a31fd58fd9bea2ae99b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/099e9712f166092364e51630f3e5138f3ff81811", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/099e9712f166092364e51630f3e5138f3ff81811", "html_url": "https://github.com/Rust-GCC/gccrs/commit/099e9712f166092364e51630f3e5138f3ff81811", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/099e9712f166092364e51630f3e5138f3ff81811/comments", "author": null, "committer": null, "parents": [{"sha": "1bf14ad7a469ad3816146cf31c11d0bcc36d5220", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1bf14ad7a469ad3816146cf31c11d0bcc36d5220", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1bf14ad7a469ad3816146cf31c11d0bcc36d5220"}], "stats": {"total": 517, "additions": 280, "deletions": 237}, "files": [{"sha": "684cf11937ef40f619fa4d97932587c15f60be97", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/099e9712f166092364e51630f3e5138f3ff81811/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/099e9712f166092364e51630f3e5138f3ff81811/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=099e9712f166092364e51630f3e5138f3ff81811", "patch": "@@ -1,3 +1,13 @@\n+Mon May 15 21:07:20 MET DST 2000  Jan Hubicka  <jh@suse.cz>\n+\n+\t* calls.c: Re-install both patches reverted by last patch.\n+\t(struct arg_data): New field tail_call_reg.\n+\t(initialize_argument_information): Initialize tail_call_reg\n+\t(load_register_parameters): New argument flags, use\n+\ttail_call_reg when emiting tail call sequence.\n+\t(expand_call): Update call of load_register_parameters;\n+\tcopy unadjusted_args_size to adjusted_args_size.\n+\n Mon May 15 19:01:42 MET DST 2000  Jan Hubicka  <jh@suse.cz>\n \n \t* loop.c (scan_loop, strength_reduce, loop_optimize): Change unroll_p"}, {"sha": "7cf8971307f4b28dc8c604b9a1be2272d9eaed90", "filename": "gcc/calls.c", "status": "modified", "additions": 270, "deletions": 237, "changes": 507, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/099e9712f166092364e51630f3e5138f3ff81811/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/099e9712f166092364e51630f3e5138f3ff81811/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=099e9712f166092364e51630f3e5138f3ff81811", "patch": "@@ -90,6 +90,10 @@ struct arg_data\n      PARALLEL if the arg is to be copied into multiple non-contiguous\n      registers.  */\n   rtx reg;\n+  /* Register to pass this argument in when generating tail call sequence.\n+     This is not the same register as for normal calls on machines with\n+     register windows.  */\n+  rtx tail_call_reg;\n   /* If REG was promoted from the actual mode of the argument expression,\n      indicates whether the promotion is sign- or zero-extended.  */\n   int unsignedp;\n@@ -201,7 +205,7 @@ static void compute_argument_addresses\t\tPARAMS ((struct arg_data *,\n \t\t\t\t\t\t\t rtx, int));\n static rtx rtx_for_function_call\t\tPARAMS ((tree, tree));\n static void load_register_parameters\t\tPARAMS ((struct arg_data *,\n-\t\t\t\t\t\t\t int, rtx *));\n+\t\t\t\t\t\t\t int, rtx *, int));\n static int libfunc_nothrow\t\t\tPARAMS ((rtx));\n static rtx emit_library_call_value_1 \t\tPARAMS ((int, rtx, rtx, int,\n \t\t\t\t\t\t\t enum machine_mode,\n@@ -1232,17 +1236,17 @@ initialize_argument_information (num_actuals, args, args_size, n_named_args,\n       args[i].unsignedp = unsignedp;\n       args[i].mode = mode;\n \n+      args[i].reg = FUNCTION_ARG (*args_so_far, mode, type,\n+\t\t\t\t  argpos < n_named_args);\n #ifdef FUNCTION_INCOMING_ARG\n       /* If this is a sibling call and the machine has register windows, the\n \t register window has to be unwinded before calling the routine, so\n \t arguments have to go into the incoming registers.  */\n-      if (*ecf_flags & ECF_SIBCALL)\n-\targs[i].reg = FUNCTION_INCOMING_ARG (*args_so_far, mode, type,\n+      args[i].tail_call_reg = FUNCTION_INCOMING_ARG (*args_so_far, mode, type,\n \t\t\t\t\t     argpos < n_named_args);\n-      else\n+#else\n+      args[i].tail_call_reg = args[i].reg;\n #endif\n-\targs[i].reg = FUNCTION_ARG (*args_so_far, mode, type,\n-\t\t\t\t    argpos < n_named_args);\n \n #ifdef FUNCTION_ARG_PARTIAL_NREGS\n       if (args[i].reg)\n@@ -1673,10 +1677,11 @@ rtx_for_function_call (fndecl, exp)\n    insns in the CALL_INSN_FUNCTION_USAGE field.  */\n \n static void\n-load_register_parameters (args, num_actuals, call_fusage)\n+load_register_parameters (args, num_actuals, call_fusage, flags)\n      struct arg_data *args;\n      int num_actuals;\n      rtx *call_fusage;\n+     int flags;\n {\n   int i, j;\n \n@@ -1686,7 +1691,8 @@ load_register_parameters (args, num_actuals, call_fusage)\n   for (i = 0; i < num_actuals; i++)\n #endif\n     {\n-      rtx reg = args[i].reg;\n+      rtx reg = ((flags & ECF_SIBCALL)\n+\t\t ? args[i].tail_call_reg : args[i].reg);\n       int partial = args[i].partial;\n       int nregs;\n \n@@ -1946,7 +1952,8 @@ expand_call (exp, target, ignore)\n   tree fndecl = 0;\n   char *name = 0;\n   rtx insn;\n-  int try_tail_call;\n+  int try_tail_call = 1;\n+  int try_tail_recursion = 1;\n   int pass;\n \n   /* Register in which non-BLKmode value will be returned,\n@@ -1980,6 +1987,7 @@ expand_call (exp, target, ignore)\n \n   /* Total size in bytes of all the stack-parms scanned so far.  */\n   struct args_size args_size;\n+  struct args_size adjusted_args_size;\n   /* Size of arguments before any adjustments (such as rounding).  */\n   int unadjusted_args_size;\n   /* Data on reg parms scanned so far.  */\n@@ -2162,7 +2170,135 @@ expand_call (exp, target, ignore)\n \treturn temp;\n     }\n \n-  currently_expanding_call++;\n+  if (fndecl && DECL_NAME (fndecl))\n+    name = IDENTIFIER_POINTER (DECL_NAME (fndecl));\n+\n+  /* Figure out the amount to which the stack should be aligned.  */\n+#ifdef PREFERRED_STACK_BOUNDARY\n+  preferred_stack_boundary = PREFERRED_STACK_BOUNDARY;\n+#else\n+  preferred_stack_boundary = STACK_BOUNDARY;\n+#endif\n+\n+  /* Operand 0 is a pointer-to-function; get the type of the function.  */\n+  funtype = TREE_TYPE (TREE_OPERAND (exp, 0));\n+  if (! POINTER_TYPE_P (funtype))\n+    abort ();\n+  funtype = TREE_TYPE (funtype);\n+\n+  /* See if this is a call to a function that can return more than once\n+     or a call to longjmp or malloc.  */\n+  flags |= special_function_p (fndecl, flags);\n+\n+  if (flags & ECF_MAY_BE_ALLOCA)\n+    current_function_calls_alloca = 1;\n+\n+  /* If struct_value_rtx is 0, it means pass the address\n+     as if it were an extra parameter.  */\n+  if (structure_value_addr && struct_value_rtx == 0)\n+    {\n+      /* If structure_value_addr is a REG other than\n+\t virtual_outgoing_args_rtx, we can use always use it.  If it\n+\t is not a REG, we must always copy it into a register.\n+\t If it is virtual_outgoing_args_rtx, we must copy it to another\n+\t register in some cases.  */\n+      rtx temp = (GET_CODE (structure_value_addr) != REG\n+\t\t  || (ACCUMULATE_OUTGOING_ARGS\n+\t\t      && stack_arg_under_construction\n+\t\t      && structure_value_addr == virtual_outgoing_args_rtx)\n+\t\t  ? copy_addr_to_reg (structure_value_addr)\n+\t\t  : structure_value_addr);\n+\n+      actparms\n+\t= tree_cons (error_mark_node,\n+\t\t     make_tree (build_pointer_type (TREE_TYPE (funtype)),\n+\t\t\t\ttemp),\n+\t\t     actparms);\n+      structure_value_addr_parm = 1;\n+    }\n+\n+  /* Count the arguments and set NUM_ACTUALS.  */\n+  for (p = actparms, num_actuals = 0; p; p = TREE_CHAIN (p))\n+    num_actuals++;\n+\n+  /* Compute number of named args.\n+     Normally, don't include the last named arg if anonymous args follow.\n+     We do include the last named arg if STRICT_ARGUMENT_NAMING is nonzero.\n+     (If no anonymous args follow, the result of list_length is actually\n+     one too large.  This is harmless.)\n+\n+     If PRETEND_OUTGOING_VARARGS_NAMED is set and STRICT_ARGUMENT_NAMING is\n+     zero, this machine will be able to place unnamed args that were\n+     passed in registers into the stack.  So treat all args as named.\n+     This allows the insns emitting for a specific argument list to be\n+     independent of the function declaration.\n+\n+     If PRETEND_OUTGOING_VARARGS_NAMED is not set, we do not have any\n+     reliable way to pass unnamed args in registers, so we must force\n+     them into memory.  */\n+\n+  if ((STRICT_ARGUMENT_NAMING\n+       || ! PRETEND_OUTGOING_VARARGS_NAMED)\n+      && TYPE_ARG_TYPES (funtype) != 0)\n+    n_named_args\n+      = (list_length (TYPE_ARG_TYPES (funtype))\n+\t /* Don't include the last named arg.  */\n+\t - (STRICT_ARGUMENT_NAMING ? 0 : 1)\n+\t /* Count the struct value address, if it is passed as a parm.  */\n+\t + structure_value_addr_parm);\n+  else\n+    /* If we know nothing, treat all args as named.  */\n+    n_named_args = num_actuals;\n+\n+  /* Start updating where the next arg would go.\n+\n+     On some machines (such as the PA) indirect calls have a different\n+     calling convention than normal calls.  The last argument in\n+     INIT_CUMULATIVE_ARGS tells the backend if this is an indirect call\n+     or not.  */\n+  INIT_CUMULATIVE_ARGS (args_so_far, funtype, NULL_RTX, (fndecl == 0));\n+\n+\n+  /* Make a vector to hold all the information about each arg.  */\n+  args = (struct arg_data *) alloca (num_actuals\n+\t\t\t\t     * sizeof (struct arg_data));\n+  bzero ((char *) args, num_actuals * sizeof (struct arg_data));\n+\n+  /* Build up entries inthe ARGS array, compute the size of the arguments\n+     into ARGS_SIZE, etc.  */\n+  initialize_argument_information (num_actuals, args, &args_size,\n+\t\t\t\t   n_named_args, actparms, fndecl,\n+\t\t\t\t   &args_so_far, reg_parm_stack_space,\n+\t\t\t\t   &old_stack_level, &old_pending_adj,\n+\t\t\t\t   &must_preallocate, &flags);\n+\n+  if (args_size.var)\n+    {\n+      /* If this function requires a variable-sized argument list, don't\n+\t try to make a cse'able block for this call.  We may be able to\n+\t do this eventually, but it is too complicated to keep track of\n+\t what insns go in the cse'able block and which don't.   */\n+\n+      flags &= ~(ECF_CONST | ECF_PURE);\n+      must_preallocate = 1;\n+    }\n+\n+  /* Now make final decision about preallocating stack space.  */\n+  must_preallocate = finalize_must_preallocate (must_preallocate,\n+\t\t\t\t\t\tnum_actuals, args,\n+\t\t\t\t\t\t&args_size);\n+\n+  /* If the structure value address will reference the stack pointer, we\n+     must stabilize it.  We don't need to do this if we know that we are\n+     not going to adjust the stack pointer in processing this call.  */\n+\n+  if (structure_value_addr\n+      && (reg_mentioned_p (virtual_stack_dynamic_rtx, structure_value_addr)\n+\t  || reg_mentioned_p (virtual_outgoing_args_rtx,\n+\t\t\t      structure_value_addr))\n+      && (args_size.var\n+\t  || (!ACCUMULATE_OUTGOING_ARGS && args_size.constant)))\n+    structure_value_addr = copy_to_reg (structure_value_addr);\n \n   /* Tail calls can make things harder to debug, and we're traditionally\n      pushed these optimizations into -O2.  Don't try if we're already\n@@ -2176,15 +2312,58 @@ expand_call (exp, target, ignore)\n      This is most often true of sjlj-exceptions, which we couldn't\n      tail-call to anyway.  */\n \n+  if (currently_expanding_call++ != 0\n+      || !flag_optimize_sibling_calls\n+      || !rtx_equal_function_value_matters\n+      || !stmt_loop_nest_empty ()\n+      || any_pending_cleanups (1)\n+      || args_size.var)\n+    try_tail_call = try_tail_recursion = 0;\n+\n+  /* Tail recursion fails, when we are not dealing with recursive calls.  */\n+  if (!try_tail_recursion\n+      || TREE_CODE (TREE_OPERAND (exp, 0)) != ADDR_EXPR\n+      || TREE_OPERAND (TREE_OPERAND (exp, 0), 0) != current_function_decl)\n+    try_tail_recursion = 0;\n+\n+  /*  Rest of purposes for tail call optimizations to fail.  */\n+  if (\n+#ifdef HAVE_sibcall_epilogue\n+      !HAVE_sibcall_epilogue\n+#else\n+      1\n+#endif\n+      || !try_tail_call\n+      /* Doing sibling call optimization needs some work, since\n+\t structure_value_addr can be allocated on the stack.\n+\t It does not seem worth the effort since few optimizable\n+\t sibling calls will return a structure.  */\n+      || structure_value_addr != NULL_RTX\n+      /* If the register holding the address is a callee saved\n+\t register, then we lose.  We have no way to prevent that,\n+\t so we only allow calls to named functions.  */\n+      /* ??? This could be done by having the insn constraints\n+\t use a register class that is all call-clobbered.  Any\n+\t reload insns generated to fix things up would appear\n+\t before the sibcall_epilogue.  */\n+      || fndecl == NULL_TREE\n+      || (flags & (ECF_RETURNS_TWICE | ECF_LONGJMP))\n+      || !FUNCTION_OK_FOR_SIBCALL (fndecl)\n+      /* If this function requires more stack slots than the current\n+\t function, we cannot change it into a sibling call.  */\n+      || args_size.constant > current_function_args_size\n+      /* If the callee pops its own arguments, then it must pop exactly\n+\t the same number of arguments as the current function.  */\n+      || RETURN_POPS_ARGS (fndecl, funtype, args_size.constant)\n+\t != RETURN_POPS_ARGS (current_function_decl,\n+\t\t\t      TREE_TYPE (current_function_decl),\n+\t\t\t      current_function_args_size))\n   try_tail_call = 0;\n-  if (flag_optimize_sibling_calls\n-      && currently_expanding_call == 1\n-      && rtx_equal_function_value_matters\n-      && stmt_loop_nest_empty ()\n-      && ! any_pending_cleanups (1))\n-    {\n-      tree new_actparms = NULL_TREE;\n \n+  if (try_tail_call || try_tail_recursion)\n+    {\n+      int end, inc;\n+      actparms = NULL_TREE;\n       /* Ok, we're going to give the tail call the old college try.\n \t This means we're going to evaluate the function arguments\n \t up to three times.  There are two degrees of badness we can\n@@ -2194,49 +2373,64 @@ expand_call (exp, target, ignore)\n \t Generate a new argument list.  Pass safe arguments through\n \t unchanged.  For the easy badness wrap them in UNSAVE_EXPRs.  \n \t For hard badness, evaluate them now and put their resulting\n-\t rtx in a temporary VAR_DECL.  */\n+\t rtx in a temporary VAR_DECL.\n+\n+\t initialize_argument_information has ordered the array for the\n+\t order to be pushed, and we must remember this when reconstructing\n+\t the original argument orde.  */\n \n-      for (p = actparms; p; p = TREE_CHAIN (p))\n-\tswitch (unsafe_for_reeval (TREE_VALUE (p)))\n+      if (PUSH_ARGS_REVERSED)\n+\t{\n+\t  inc = 1;\n+\t  i = 0;\n+\t  end = num_actuals;\n+\t}\n+      else\n \t  {\n+\t  inc = -1;\n+\t  i = num_actuals - 1;\n+\t  end = -1;\n+\t}\n+\n+      for (; i != end; i += inc)\n+\t{\n+\t  switch (unsafe_for_reeval (args[i].tree_value))\n+\t    {\n \t  case 0: /* Safe.  */\n-\t    new_actparms = tree_cons (TREE_PURPOSE (p), TREE_VALUE (p),\n-\t\t\t\t      new_actparms);\n \t    break;\n \n \t  case 1: /* Mildly unsafe.  */\n-\t    new_actparms = tree_cons (TREE_PURPOSE (p),\n-\t\t\t\t      unsave_expr (TREE_VALUE (p)),\n-\t\t\t\t      new_actparms);\n+\t      args[i].tree_value = unsave_expr (args[i].tree_value);\n \t    break;\n \n \t  case 2: /* Wildly unsafe.  */\n \t    {\n \t      tree var = build_decl (VAR_DECL, NULL_TREE,\n-\t\t\t\t     TREE_TYPE (TREE_VALUE (p)));\n-\t      DECL_RTL (var) = expand_expr (TREE_VALUE (p), NULL_RTX,\n+\t\t\t\t       TREE_TYPE (args[i].tree_value));\n+\t\tDECL_RTL (var) = expand_expr (args[i].tree_value, NULL_RTX,\n \t\t\t\t\t    VOIDmode, EXPAND_NORMAL);\n-\t      new_actparms = tree_cons (TREE_PURPOSE (p), var, new_actparms);\n+\t\targs[i].tree_value = var;\n \t    }\n \t    break;\n \n \t  default:\n \t    abort ();\n \t  }\n-\n-      /* We built the new argument chain backwards.  */\n-      actparms = nreverse (new_actparms);\n-\n+\t  /* We need to build actparms for optimize_tail_recursion.  We can\n+\t     safely trash away TREE_PURPOSE, since it is unused by this\n+\t     function.  */\n+\t  if (try_tail_recursion)\n+\t    actparms = tree_cons (NULL_TREE, args[i].tree_value, actparms);\n+\t}\n       /* Expanding one of those dangerous arguments could have added\n \t cleanups, but otherwise give it a whirl.  */\n-      try_tail_call = ! any_pending_cleanups (1);\n+      if (any_pending_cleanups (1))\n+\ttry_tail_call = try_tail_recursion = 0;\n     }\n \n   /* Generate a tail recursion sequence when calling ourselves.  */\n \n-  if (try_tail_call\n-      && TREE_CODE (TREE_OPERAND (exp, 0)) == ADDR_EXPR\n-      && TREE_OPERAND (TREE_OPERAND (exp, 0), 0) == current_function_decl)\n+  if (try_tail_recursion)\n     {\n       /* We want to emit any pending stack adjustments before the tail\n \t recursion \"call\".  That way we know any adjustment after the tail\n@@ -2251,9 +2445,6 @@ expand_call (exp, target, ignore)\n \t complete.  */\n       start_sequence ();\n \n-      /* Emit the pending stack adjustments before we expand any arguments.  */\n-      do_pending_stack_adjust ();\n-\n       if (optimize_tail_recursion (actparms, get_last_insn ()))\n         tail_recursion_insns = get_insns ();\n       end_sequence ();\n@@ -2264,18 +2455,18 @@ expand_call (exp, target, ignore)\n       stack_pointer_delta = save_stack_pointer_delta;\n     }\n \n-  function_call_count++;\n-\n-  if (fndecl && DECL_NAME (fndecl))\n-    name = IDENTIFIER_POINTER (DECL_NAME (fndecl));\n-\n-  /* Figure out the amount to which the stack should be aligned.  */\n-#ifdef PREFERRED_STACK_BOUNDARY\n-  preferred_stack_boundary = PREFERRED_STACK_BOUNDARY;\n-#else\n-  preferred_stack_boundary = STACK_BOUNDARY;\n-#endif\n-  preferred_unit_stack_boundary = preferred_stack_boundary / BITS_PER_UNIT;\n+  if (profile_arc_flag && (flags & ECF_FORK_OR_EXEC))\n+    {\n+      /* A fork duplicates the profile information, and an exec discards\n+\t it.  We can't rely on fork/exec to be paired.  So write out the\n+\t profile information we have gathered so far, and clear it.  */\n+      /* ??? When Linux's __clone is called with CLONE_VM set, profiling\n+\t is subject to race conditions, just as with multithreaded\n+\t programs.  */\n+\n+      emit_library_call (gen_rtx_SYMBOL_REF (Pmode, \"__bb_fork_func\"), 0,\n+\t\t\t VOIDmode, 0);\n+    }\n \n   /* Ensure current function's preferred stack boundary is at least\n      what we need.  We don't have to increase alignment for recursive\n@@ -2284,18 +2475,9 @@ expand_call (exp, target, ignore)\n       && fndecl != current_function_decl)\n     cfun->preferred_stack_boundary = preferred_stack_boundary;\n \n-  /* See if this is a call to a function that can return more than once\n-     or a call to longjmp or malloc.  */\n-  flags |= special_function_p (fndecl, flags);\n-\n-  if (flags & ECF_MAY_BE_ALLOCA)\n-    current_function_calls_alloca = 1;\n+  preferred_unit_stack_boundary = preferred_stack_boundary / BITS_PER_UNIT;\n \n-  /* Operand 0 is a pointer-to-function; get the type of the function.  */\n-  funtype = TREE_TYPE (TREE_OPERAND (exp, 0));\n-  if (! POINTER_TYPE_P (funtype))\n-    abort ();\n-  funtype = TREE_TYPE (funtype);\n+  function_call_count++;\n \n   /* We want to make two insn chains; one for a sibling call, the other\n      for a normal call.  We will select one of the two chains after\n@@ -2314,27 +2496,7 @@ expand_call (exp, target, ignore)\n \n       if (pass == 0)\n \t{\n-\t  /* Various reasons we can not use a sibling call.  */\n-\t  if (! try_tail_call \n-#ifdef HAVE_sibcall_epilogue\n-\t      || ! HAVE_sibcall_epilogue\n-#else\n-\t      || 1\n-#endif\n-\t      /* The structure value address is used and modified in the\n-\t\t loop below.  It does not seem worth the effort to save and\n-\t\t restore it as a state variable since few optimizable\n-\t\t sibling calls will return a structure.  */\n-\t      || structure_value_addr != NULL_RTX\n-\t      /* If the register holding the address is a callee saved\n-\t\t register, then we lose.  We have no way to prevent that,\n-\t\t so we only allow calls to named functions.  */\n-\t      /* ??? This could be done by having the insn constraints\n-\t\t use a register class that is all call-clobbered.  Any\n-\t\t reload insns generated to fix things up would appear\n-\t\t before the sibcall_epilogue.  */\n-\t      || fndecl == NULL_TREE\n-\t      || ! FUNCTION_OK_FOR_SIBCALL (fndecl))\n+\t  if (! try_tail_call)\n \t    continue;\n \n \t  /* Emit any queued insns now; otherwise they would end up in\n@@ -2385,152 +2547,15 @@ expand_call (exp, target, ignore)\n \t  || pass == 0)\n \tdo_pending_stack_adjust ();\n \n-      if (profile_arc_flag && (flags & ECF_FORK_OR_EXEC))\n-\t{\n-\t  /* A fork duplicates the profile information, and an exec discards\n-\t     it.  We can't rely on fork/exec to be paired.  So write out the\n-\t     profile information we have gathered so far, and clear it.  */\n-\t  /* ??? When Linux's __clone is called with CLONE_VM set, profiling\n-\t     is subject to race conditions, just as with multithreaded\n-\t     programs.  */\n-\n-\t  emit_library_call (gen_rtx_SYMBOL_REF (Pmode, \"__bb_fork_func\"), 0,\n-\t\t\t     VOIDmode, 0);\n-\t}\n-\n       /* Push the temporary stack slot level so that we can free any\n \t temporaries we make.  */\n       push_temp_slots ();\n \n-      /* Start updating where the next arg would go.\n-\n-\t On some machines (such as the PA) indirect calls have a different\n-\t calling convention than normal calls.  The last argument in\n-\t INIT_CUMULATIVE_ARGS tells the backend if this is an indirect call\n-\t or not.  */\n-      INIT_CUMULATIVE_ARGS (args_so_far, funtype, NULL_RTX, (fndecl == 0));\n-\n-      /* If struct_value_rtx is 0, it means pass the address\n-\t as if it were an extra parameter.  */\n-      if (structure_value_addr && struct_value_rtx == 0)\n-\t{\n-\t  /* If structure_value_addr is a REG other than\n-\t     virtual_outgoing_args_rtx, we can use always use it.  If it\n-\t     is not a REG, we must always copy it into a register.\n-\t     If it is virtual_outgoing_args_rtx, we must copy it to another\n-\t     register in some cases.  */\n-\t  rtx temp = (GET_CODE (structure_value_addr) != REG\n-\t\t      || (ACCUMULATE_OUTGOING_ARGS\n-\t\t\t  && stack_arg_under_construction\n-\t\t\t  && structure_value_addr == virtual_outgoing_args_rtx)\n-\t\t      ? copy_addr_to_reg (structure_value_addr)\n-\t\t      : structure_value_addr);\n-\n-\t  actparms\n-\t    = tree_cons (error_mark_node,\n-\t\t\t make_tree (build_pointer_type (TREE_TYPE (funtype)),\n-\t\t\t\t    temp),\n-\t\t\t actparms);\n-\t  structure_value_addr_parm = 1;\n-\t}\n-\n-      /* Count the arguments and set NUM_ACTUALS.  */\n-      for (p = actparms, i = 0; p; p = TREE_CHAIN (p)) i++;\n-      num_actuals = i;\n-\n-      /* Compute number of named args.\n-\t Normally, don't include the last named arg if anonymous args follow.\n-\t We do include the last named arg if STRICT_ARGUMENT_NAMING is nonzero.\n-\t (If no anonymous args follow, the result of list_length is actually\n-\t one too large.  This is harmless.)\n-\n-\t If PRETEND_OUTGOING_VARARGS_NAMED is set and STRICT_ARGUMENT_NAMING is\n-\t zero, this machine will be able to place unnamed args that were\n-\t passed in registers into the stack.  So treat all args as named.\n-\t This allows the insns emitting for a specific argument list to be\n-\t independent of the function declaration.\n-\n-\t If PRETEND_OUTGOING_VARARGS_NAMED is not set, we do not have any\n-\t reliable way to pass unnamed args in registers, so we must force\n-\t them into memory.  */\n-\n-      if ((STRICT_ARGUMENT_NAMING\n-\t   || ! PRETEND_OUTGOING_VARARGS_NAMED)\n-\t  && TYPE_ARG_TYPES (funtype) != 0)\n-\tn_named_args\n-\t  = (list_length (TYPE_ARG_TYPES (funtype))\n-\t     /* Don't include the last named arg.  */\n-\t     - (STRICT_ARGUMENT_NAMING ? 0 : 1)\n-\t     /* Count the struct value address, if it is passed as a parm.  */\n-\t     + structure_value_addr_parm);\n-      else\n-\t/* If we know nothing, treat all args as named.  */\n-\tn_named_args = num_actuals;\n-\n-      /* Make a vector to hold all the information about each arg.  */\n-      args = (struct arg_data *) alloca (num_actuals\n-\t\t\t\t\t * sizeof (struct arg_data));\n-      bzero ((char *) args, num_actuals * sizeof (struct arg_data));\n-\n-      /* Build up entries inthe ARGS array, compute the size of the arguments\n-\t into ARGS_SIZE, etc.  */\n-      initialize_argument_information (num_actuals, args, &args_size,\n-\t\t\t\t       n_named_args, actparms, fndecl,\n-\t\t\t\t       &args_so_far, reg_parm_stack_space,\n-\t\t\t\t       &old_stack_level, &old_pending_adj,\n-\t\t\t\t       &must_preallocate, &flags);\n \n #ifdef FINAL_REG_PARM_STACK_SPACE\n       reg_parm_stack_space = FINAL_REG_PARM_STACK_SPACE (args_size.constant,\n \t\t\t\t\t\t\t args_size.var);\n #endif\n-      \n-      if (args_size.var)\n-\t{\n-\t  /* If this function requires a variable-sized argument list, don't\n-\t     try to make a cse'able block for this call.  We may be able to\n-\t     do this eventually, but it is too complicated to keep track of\n-\t     what insns go in the cse'able block and which don't. \n-\n-\t     Also do not make a sibling call.  */\n-\n-\t  flags &= ~(ECF_CONST | ECF_PURE);\n-\t  must_preallocate = 1;\n-\t  sibcall_failure = 1;\n-\t}\n-\n-      if (args_size.constant > current_function_args_size)\n-\t{\n-\t  /* If this function requires more stack slots than the current\n-\t     function, we cannot change it into a sibling call.  */\n-\t  sibcall_failure = 1;\n-\t}\n-\n-      /* If the callee pops its own arguments, then it must pop exactly\n-\t the same number of arguments as the current function.  */\n-      if (RETURN_POPS_ARGS (fndecl, funtype, args_size.constant)\n-\t  != RETURN_POPS_ARGS (current_function_decl,\n-\t\t\t       TREE_TYPE (current_function_decl),\n-\t\t\t       current_function_args_size))\n-\tsibcall_failure = 1;\n-\n-      /* Now make final decision about preallocating stack space.  */\n-      must_preallocate = finalize_must_preallocate (must_preallocate,\n-\t\t\t\t\t\t    num_actuals, args,\n-\t\t\t\t\t\t    &args_size);\n-\n-      /* If the structure value address will reference the stack pointer, we\n-\t must stabilize it.  We don't need to do this if we know that we are\n-\t not going to adjust the stack pointer in processing this call.  */\n-\n-      if (structure_value_addr\n-\t  && (reg_mentioned_p (virtual_stack_dynamic_rtx, structure_value_addr)\n-\t      || reg_mentioned_p (virtual_outgoing_args_rtx,\n-\t\t\t\t  structure_value_addr))\n-\t  && (args_size.var\n-\t      || (!ACCUMULATE_OUTGOING_ARGS && args_size.constant)))\n-\tstructure_value_addr = copy_to_reg (structure_value_addr);\n-\n       /* Precompute any arguments as needed.  */\n       if (pass)\n \tprecompute_arguments (flags, num_actuals, args);\n@@ -2540,13 +2565,14 @@ expand_call (exp, target, ignore)\n       if (flags & (ECF_CONST | ECF_PURE | ECF_MALLOC))\n \tstart_sequence ();\n \n+      adjusted_args_size = args_size;\n       /* Compute the actual size of the argument block required.  The variable\n \t and constant sizes must be combined, the size may have to be rounded,\n \t and there may be a minimum required size.  When generating a sibcall\n \t pattern, do not round up, since we'll be re-using whatever space our\n \t caller provided.  */\n       unadjusted_args_size\n-\t= compute_argument_block_size (reg_parm_stack_space, &args_size,\n+\t= compute_argument_block_size (reg_parm_stack_space, &adjusted_args_size,\n \t\t\t\t       (pass == 0 ? 0\n \t\t\t\t\t: preferred_stack_boundary));\n \n@@ -2559,7 +2585,7 @@ expand_call (exp, target, ignore)\n \n       /* If we have no actual push instructions, or shouldn't use them,\n \t make space for all args right now.  */\n-      else if (args_size.var != 0)\n+      else if (adjusted_args_size.var != 0)\n \t{\n \t  if (old_stack_level == 0)\n \t    {\n@@ -2572,7 +2598,7 @@ expand_call (exp, target, ignore)\n \t      old_stack_arg_under_construction = stack_arg_under_construction;\n \t      stack_arg_under_construction = 0;\n \t    }\n-\t  argblock = push_block (ARGS_SIZE_RTX (args_size), 0, 0);\n+\t  argblock = push_block (ARGS_SIZE_RTX (adjusted_args_size), 0, 0);\n \t}\n       else\n \t{\n@@ -2581,7 +2607,7 @@ expand_call (exp, target, ignore)\n \t     in the area reserved for register arguments, which may be part of\n \t     the stack frame.  */\n \n-\t  int needed = args_size.constant;\n+\t  int needed = adjusted_args_size.constant;\n \n \t  /* Store the maximum argument space used.  It will be pushed by\n \t     the prologue (if ACCUMULATE_OUTGOING_ARGS, or stack overflow\n@@ -2651,7 +2677,7 @@ expand_call (exp, target, ignore)\n \t\t      needed\n \t\t\t= (combine_pending_stack_adjustment_and_call \n \t\t\t   (unadjusted_args_size,\n-\t\t\t    &args_size,\n+\t\t\t    &adjusted_args_size,\n \t\t\t    preferred_unit_stack_boundary));\n \n \t\t      /* combine_pending_stack_adjustment_and_call computes\n@@ -2699,9 +2725,9 @@ expand_call (exp, target, ignore)\n \t\t    {\n #ifndef OUTGOING_REG_PARM_STACK_SPACE\n \t\t      rtx push_size = GEN_INT (reg_parm_stack_space\n-\t\t\t\t\t       + args_size.constant);\n+\t\t\t\t\t       + adjusted_args_size.constant);\n #else\n-\t\t      rtx push_size = GEN_INT (args_size.constant);\n+\t\t      rtx push_size = GEN_INT (adjusted_args_size.constant);\n #endif\n \t\t      if (old_stack_level == 0)\n \t\t\t{\n@@ -2743,7 +2769,7 @@ expand_call (exp, target, ignore)\n       /* If we push args individually in reverse order, perform stack alignment\n \t before the first push (the last arg).  */\n       if (PUSH_ARGS_REVERSED && argblock == 0\n-\t  && args_size.constant != unadjusted_args_size)\n+\t  && adjusted_args_size.constant != unadjusted_args_size)\n \t{\n \t  /* When the stack adjustment is pending, we get better code\n \t     by combining the adjustments.  */\n@@ -2754,12 +2780,12 @@ expand_call (exp, target, ignore)\n \t      pending_stack_adjust\n \t\t= (combine_pending_stack_adjustment_and_call \n \t\t   (unadjusted_args_size,\n-\t\t    &args_size,\n+\t\t    &adjusted_args_size,\n \t\t    preferred_unit_stack_boundary));\n \t      do_pending_stack_adjust ();\n \t    }\n \t  else if (argblock == 0)\n-\t    anti_adjust_stack (GEN_INT (args_size.constant\n+\t    anti_adjust_stack (GEN_INT (adjusted_args_size.constant\n \t\t\t\t\t- unadjusted_args_size));\n \t}\n       /* Now that the stack is properly aligned, pops can't safely\n@@ -2807,7 +2833,7 @@ expand_call (exp, target, ignore)\n       for (i = 0; i < num_actuals; i++)\n \tif (args[i].reg == 0 || args[i].pass_on_stack)\n \t  store_one_arg (&args[i], argblock, flags,\n-\t\t\t args_size.var != 0, reg_parm_stack_space);\n+\t\t\t adjusted_args_size.var != 0, reg_parm_stack_space);\n \n       /* If we have a parm that is passed in registers but not in memory\n \t and whose alignment does not permit a direct copy into registers,\n@@ -2822,13 +2848,13 @@ expand_call (exp, target, ignore)\n \tfor (i = 0; i < num_actuals; i++)\n \t  if (args[i].partial != 0 && ! args[i].pass_on_stack)\n \t    store_one_arg (&args[i], argblock, flags,\n-\t\t\t   args_size.var != 0, reg_parm_stack_space);\n+\t\t\t   adjusted_args_size.var != 0, reg_parm_stack_space);\n \n #ifdef PREFERRED_STACK_BOUNDARY\n       /* If we pushed args in forward order, perform stack alignment\n \t after pushing the last arg.  */\n       if (!PUSH_ARGS_REVERSED && argblock == 0)\n-\tanti_adjust_stack (GEN_INT (args_size.constant\n+\tanti_adjust_stack (GEN_INT (adjusted_args_size.constant\n \t\t\t\t    - unadjusted_args_size));\n #endif\n \n@@ -2867,7 +2893,7 @@ expand_call (exp, target, ignore)\n       funexp = prepare_call_address (funexp, fndecl, &call_fusage,\n \t\t\t\t     reg_parm_seen);\n \n-      load_register_parameters (args, num_actuals, &call_fusage);\n+      load_register_parameters (args, num_actuals, &call_fusage, flags);\n      \n       /* Perform postincrements before actually calling the function.  */\n       emit_queue ();\n@@ -2898,7 +2924,7 @@ expand_call (exp, target, ignore)\n \n       /* Generate the actual call instruction.  */\n       emit_call_1 (funexp, fndecl, funtype, unadjusted_args_size,\n-\t\t   args_size.constant, struct_value_size,\n+\t\t   adjusted_args_size.constant, struct_value_size,\n \t\t   next_arg_reg, valreg, old_inhibit_defer_pop, call_fusage,\n \t\t   flags);\n \n@@ -2997,14 +3023,13 @@ expand_call (exp, target, ignore)\n \t    {\n \t      emit_note_after (NOTE_INSN_SETJMP, last);\n \t      current_function_calls_setjmp = 1;\n-\t      sibcall_failure = 1;\n \t    }\n \t  else\n \t    emit_barrier_after (last);\n \t}\n \n       if (flags & ECF_LONGJMP)\n-\tcurrent_function_calls_longjmp = 1, sibcall_failure = 1;\n+\tcurrent_function_calls_longjmp = 1;\n \n       /* If this function is returning into a memory location marked as\n \t readonly, it means it is initializing that location.  But we normally\n@@ -3193,6 +3218,14 @@ expand_call (exp, target, ignore)\n \n \t  pending_stack_adjust = save_pending_stack_adjust;\n \t  stack_pointer_delta = save_stack_pointer_delta;\n+\n+\t  /* Prepare arg structure for next iteration.  */\n+\t  for (i = 0 ; i < num_actuals ; i++)\n+\t    {\n+\t      args[i].value = 0;\n+\t      args[i].aligned_regs = 0;\n+\t      args[i].stack = 0;\n+\t    }\n \t}\n       else\n \tnormal_call_insns = insns;"}]}