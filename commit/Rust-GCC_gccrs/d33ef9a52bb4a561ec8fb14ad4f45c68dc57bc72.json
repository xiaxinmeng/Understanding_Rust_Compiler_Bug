{"sha": "d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDMzZWY5YTUyYmI0YTU2MWVjOGZiMTRhZDRmNDVjNjhkYzU3YmM3Mg==", "commit": {"author": {"name": "Andi Kleen", "email": "ak@linux.intel.com", "date": "2011-10-29T01:01:54Z"}, "committer": {"name": "Andi Kleen", "email": "ak@gcc.gnu.org", "date": "2011-10-29T01:01:54Z"}, "message": "Free large chunks in ggc v2\n\nThis implements the freeing back of large chunks in the ggc madvise path\nRichard Guenther asked for.  This way on systems with limited\naddress space malloc() and other allocators still have\na chance to get back at some of the memory ggc freed. The\nfragmented pages are still just given back, but the address space\nstays allocated.\n\nI tried freeing only aligned 2MB areas to optimize for 2MB huge\npages, but the hit rate was quite low, so I switched to 1MB+\nunaligned areas.\n\nv2: Hardcode free unit size instead of param\n\ngcc/:\n2011-10-18  Andi Kleen  <ak@linux.intel.com>\n\n\t* ggc-page (release_pages): First free large continuous\n\tchunks in the madvise path.\n\nFrom-SVN: r180648", "tree": {"sha": "2071cd9a9389dac958320f1bd9ae2bb9c110cc2b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2071cd9a9389dac958320f1bd9ae2bb9c110cc2b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72/comments", "author": null, "committer": null, "parents": [{"sha": "bf72b0094aa097ec23fdac68b33d2f86274bfd1d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bf72b0094aa097ec23fdac68b33d2f86274bfd1d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bf72b0094aa097ec23fdac68b33d2f86274bfd1d"}], "stats": {"total": 53, "additions": 53, "deletions": 0}, "files": [{"sha": "3b2473463b54a4018b6f6dc879b032a5a9945df5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72", "patch": "@@ -1,3 +1,8 @@\n+2011-10-18  Andi Kleen  <ak@linux.intel.com>\n+\n+\t* ggc-page (release_pages): First free large continuous\n+\tchunks in the madvise path.\n+\n 2011-10-18  Andi Kleen  <ak@linux.intel.com>\n \n \t* ggc-page.c (alloc_pages): Always round up entry_size."}, {"sha": "7bef4c02d34854a6e55674ac4c51f3553752bd90", "filename": "gcc/ggc-page.c", "status": "modified", "additions": 48, "deletions": 0, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72/gcc%2Fggc-page.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72/gcc%2Fggc-page.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc-page.c?ref=d33ef9a52bb4a561ec8fb14ad4f45c68dc57bc72", "patch": "@@ -973,6 +973,54 @@ release_pages (void)\n   page_entry *p, *start_p;\n   char *start;\n   size_t len;\n+  size_t mapped_len;\n+  page_entry *next, *prev, *newprev;\n+  size_t free_unit = (GGC_QUIRE_SIZE/2) * G.pagesize;\n+\n+  /* First free larger continuous areas to the OS.\n+     This allows other allocators to grab these areas if needed.\n+     This is only done on larger chunks to avoid fragmentation. \n+     This does not always work because the free_pages list is only\n+     approximately sorted. */\n+\n+  p = G.free_pages;\n+  prev = NULL;\n+  while (p)\n+    {\n+      start = p->page;\n+      start_p = p;\n+      len = 0;\n+      mapped_len = 0;\n+      newprev = prev;\n+      while (p && p->page == start + len)\n+        {\n+          len += p->bytes;\n+\t  if (!p->discarded)\n+\t      mapped_len += p->bytes;\n+\t  newprev = p;\n+          p = p->next;\n+        }\n+      if (len >= free_unit)\n+        {\n+          while (start_p != p)\n+            {\n+              next = start_p->next;\n+              free (start_p);\n+              start_p = next;\n+            }\n+          munmap (start, len);\n+\t  if (prev)\n+\t    prev->next = p;\n+          else\n+            G.free_pages = p;\n+          G.bytes_mapped -= mapped_len;\n+\t  continue;\n+        }\n+      prev = newprev;\n+   }\n+\n+  /* Now give back the fragmented pages to the OS, but keep the address \n+     space to reuse it next time. */\n \n   for (p = G.free_pages; p; )\n     {"}]}