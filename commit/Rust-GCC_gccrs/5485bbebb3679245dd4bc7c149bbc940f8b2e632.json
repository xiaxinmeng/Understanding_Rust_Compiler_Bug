{"sha": "5485bbebb3679245dd4bc7c149bbc940f8b2e632", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTQ4NWJiZWJiMzY3OTI0NWRkNGJjN2MxNDliYmM5NDBmOGIyZTYzMg==", "commit": {"author": {"name": "Aldy Hernandez", "email": "aldyh@redhat.com", "date": "2021-09-11T07:37:39Z"}, "committer": {"name": "Aldy Hernandez", "email": "aldyh@redhat.com", "date": "2021-09-11T17:51:30Z"}, "message": "Refactor jump_thread_path_registry.\n\nIn an attempt to refactor thread_through_all_blocks(), I've realized\nthat there is a mess of code dealing with coexisting forward and\nbackward thread types.  However, this is an impossible scenario, as\nthe registry contains either forward/old-style threads, or backward\nthreads (EDGE_FSM_THREADs), never both.\n\nThe fact that both types of threads cannot coexist, simplifies the\ncode considerably.  For that matter, it splits things up nicely\nbecause there are some common bits that can go into a base class, and\nsome differing code that can go into derived classes.\n\nDiving things in this way makes it very obvious which parts belong in\nthe old-style copier and which parts belong to the generic copier.\nDoing all this provided some nice cleanups, as well as fixing a latent\nbug in adjust_paths_after_duplication.\n\nThe diff is somewhat hard to read, so perhaps looking at the final\noutput would be easier.\n\nA general overview of what this patch achieves can be seen by just\nlooking at this simplified class layout:\n\n// Abstract class for the jump thread registry.\n\nclass jt_path_registry\n{\npublic:\n  jt_path_registry ();\n  virtual ~jt_path_registry ();\n  bool register_jump_thread (vec<jump_thread_edge *> *);\n  bool thread_through_all_blocks (bool peel_loop_headers);\n  jump_thread_edge *allocate_thread_edge (edge e, jump_thread_edge_type t);\n  vec<jump_thread_edge *> *allocate_thread_path ();\nprotected:\n  vec<vec<jump_thread_edge *> *> m_paths;\n  unsigned long m_num_threaded_edges;\nprivate:\n  virtual bool update_cfg (bool peel_loop_headers) = 0;\n};\n\n// Forward threader path registry using a custom BB copier.\n\nclass fwd_jt_path_registry : public jt_path_registry\n{\npublic:\n  fwd_jt_path_registry ();\n  ~fwd_jt_path_registry ();\n  void remove_jump_threads_including (edge);\nprivate:\n  bool update_cfg (bool peel_loop_headers) override;\n  void mark_threaded_blocks (bitmap threaded_blocks);\n  bool thread_block_1 (basic_block, bool noloop_only, bool joiners);\n  bool thread_block (basic_block, bool noloop_only);\n  bool thread_through_loop_header (class loop *loop,\n                                   bool may_peel_loop_headers);\n  class redirection_data *lookup_redirection_data (edge e, enum insert_option);\n  hash_table<struct removed_edges> *m_removed_edges;\n  hash_table<redirection_data> *m_redirection_data;\n};\n\n// Backward threader path registry using a generic BB copier.\n\nclass back_jt_path_registry : public jt_path_registry\n{\nprivate:\n  bool update_cfg (bool peel_loop_headers) override;\n  void adjust_paths_after_duplication (unsigned curr_path_num);\n  bool duplicate_thread_path (edge entry, edge exit, basic_block *region,\n                              unsigned n_region, unsigned current_path_no);\n  bool rewire_first_differing_edge (unsigned path_num, unsigned edge_num);\n};\n\nThat is, the forward and backward bits have been completely split,\nwhile deriving from a base class for the common functionality.\n\nMost everything is mechanical, but there are a few gotchas:\n\na) back_jt_path_registry::update_cfg(), which contains the backward\nthreading specific bits, is rather simple, since most of the code in\nthe original thread_through_all_blocks() only applied to the forward\nthreader: removed edges, mark_threaded_blocks,\nthread_through_loop_header, the copy tables (*).\n\n(*) The back threader has its own copy tables in\nduplicate_thread_path.\n\nb) In some cases, adjust_paths_after_duplication() was commoning out\nso many blocks that it was removing the initial EDGE_FSM_THREAD\nmarker.  I've fixed this.\n\nc) AFAICT, when run from the forward threader,\nthread_through_all_blocks() attempts to remove threads starting with\nan edge already seen, but it would never see anything because the loop\ndoing the checking only has a visited_starting_edges.contains(), and\nno corresponding visited_starting_edges.add().  The add() method in\nthread_through_all_blocks belongs to the backward threading bits, and\nas I've explained, both types cannot coexist.  I've removed the checks\nin the forward bits since they don't appear to do anything.  If this\nwas an oversight, and we want to avoid threading already seen edges in\nthe forward threader, I can move this functionality to the base class.\n\nUltimately I would like to move all the registry code to\ntree-ssa-threadregistry.*.  I've avoided this in this patch to aid in\nreview.\n\nMy apologies for this longass explanation, but I want to make sure\nwe're covering all of our bases.\n\nTested on x86-64 Linux by a very tedious process of moving chunks\naround, running \"make check-gcc RUNTESTFLAGS=tree-ssa.exp\", and\nrepeating ad-nauseum.  And of course, by running a full bootstrap and\ntests.\n\nOK?\n\np.s. In a follow-up patch I will rename the confusing EDGE_FSM_THREAD\ntype.\n\ngcc/ChangeLog:\n\n\t* tree-ssa-threadbackward.c (class back_threader_registry): Use\n\tback_jt_path_registry.\n\t* tree-ssa-threadedge.c (jump_threader::jump_threader): Use\n\tfwd_jt_path_registry.\n\t* tree-ssa-threadedge.h (class jump_threader): Same..\n\t* tree-ssa-threadupdate.c\n\t(jump_thread_path_registry::jump_thread_path_registry): Rename...\n\t(jt_path_registry::jt_path_registry): ...to this.\n\t(jump_thread_path_registry::~jump_thread_path_registry): Rename...\n\t(jt_path_registry::~jt_path_registry): ...this.\n\t(fwd_jt_path_registry::fwd_jt_path_registry): New.\n\t(fwd_jt_path_registry::~fwd_jt_path_registry): New.\n\t(jump_thread_path_registry::allocate_thread_edge): Rename...\n\t(jt_path_registry::allocate_thread_edge): ...to this.\n\t(jump_thread_path_registry::allocate_thread_path): Rename...\n\t(jt_path_registry::allocate_thread_path): ...to this.\n\t(jump_thread_path_registry::lookup_redirection_data): Rename...\n\t(fwd_jt_path_registry::lookup_redirection_data): ...to this.\n\t(jump_thread_path_registry::thread_block_1): Rename...\n\t(fwd_jt_path_registry::thread_block_1): ...to this.\n\t(jump_thread_path_registry::thread_block): Rename...\n\t(fwd_jt_path_registry::thread_block): ...to this.\n\t(jt_path_registry::thread_through_loop_header): Rename...\n\t(fwd_jt_path_registry::thread_through_loop_header): ...to this.\n\t(jump_thread_path_registry::mark_threaded_blocks): Rename...\n\t(fwd_jt_path_registry::mark_threaded_blocks): ...to this.\n\t(jump_thread_path_registry::debug_path): Rename...\n\t(jt_path_registry::debug_path): ...to this.\n\t(jump_thread_path_registry::dump): Rename...\n\t(jt_path_registry::debug): ...to this.\n\t(jump_thread_path_registry::rewire_first_differing_edge): Rename...\n\t(back_jt_path_registry::rewire_first_differing_edge): ...to this.\n\t(jump_thread_path_registry::adjust_paths_after_duplication): Rename...\n\t(back_jt_path_registry::adjust_paths_after_duplication): ...to this.\n\t(jump_thread_path_registry::duplicate_thread_path): Rename...\n\t(back_jt_path_registry::duplicate_thread_path): ...to this.  Also,\n\tdrop ill-formed candidates.\n\t(jump_thread_path_registry::remove_jump_threads_including): Rename...\n\t(fwd_jt_path_registry::remove_jump_threads_including): ...to this.\n\t(jt_path_registry::thread_through_all_blocks): New.\n\t(back_jt_path_registry::update_cfg): New.\n\t(fwd_jt_path_registry::update_cfg): New.\n\t(jump_thread_path_registry::register_jump_thread): Rename...\n\t(jt_path_registry::register_jump_thread): ...to this.\n\t* tree-ssa-threadupdate.h (class jump_thread_path_registry):\n\tAbstract to...\n\t(class jt_path_registry): ...here.\n\t(class fwd_jt_path_registry): New.\n\t(class back_jt_path_registry): New.", "tree": {"sha": "0a316d2bf8b66281897bd7d6db5d24fb06e17c2e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0a316d2bf8b66281897bd7d6db5d24fb06e17c2e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5485bbebb3679245dd4bc7c149bbc940f8b2e632", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5485bbebb3679245dd4bc7c149bbc940f8b2e632", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5485bbebb3679245dd4bc7c149bbc940f8b2e632", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5485bbebb3679245dd4bc7c149bbc940f8b2e632/comments", "author": {"login": "aldyh", "id": 12937877, "node_id": "MDQ6VXNlcjEyOTM3ODc3", "avatar_url": "https://avatars.githubusercontent.com/u/12937877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aldyh", "html_url": "https://github.com/aldyh", "followers_url": "https://api.github.com/users/aldyh/followers", "following_url": "https://api.github.com/users/aldyh/following{/other_user}", "gists_url": "https://api.github.com/users/aldyh/gists{/gist_id}", "starred_url": "https://api.github.com/users/aldyh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aldyh/subscriptions", "organizations_url": "https://api.github.com/users/aldyh/orgs", "repos_url": "https://api.github.com/users/aldyh/repos", "events_url": "https://api.github.com/users/aldyh/events{/privacy}", "received_events_url": "https://api.github.com/users/aldyh/received_events", "type": "User", "site_admin": false}, "committer": {"login": "aldyh", "id": 12937877, "node_id": "MDQ6VXNlcjEyOTM3ODc3", "avatar_url": "https://avatars.githubusercontent.com/u/12937877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aldyh", "html_url": "https://github.com/aldyh", "followers_url": "https://api.github.com/users/aldyh/followers", "following_url": "https://api.github.com/users/aldyh/following{/other_user}", "gists_url": "https://api.github.com/users/aldyh/gists{/gist_id}", "starred_url": "https://api.github.com/users/aldyh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aldyh/subscriptions", "organizations_url": "https://api.github.com/users/aldyh/orgs", "repos_url": "https://api.github.com/users/aldyh/repos", "events_url": "https://api.github.com/users/aldyh/events{/privacy}", "received_events_url": "https://api.github.com/users/aldyh/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3fca63b0b6faf6a30ed735b86b8eb59944701fc1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3fca63b0b6faf6a30ed735b86b8eb59944701fc1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3fca63b0b6faf6a30ed735b86b8eb59944701fc1"}], "stats": {"total": 279, "additions": 149, "deletions": 130}, "files": [{"sha": "7ff5cecbdab12281f892a6fcbe800b2d77b1137c", "filename": "gcc/tree-ssa-threadbackward.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadbackward.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadbackward.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadbackward.c?ref=5485bbebb3679245dd4bc7c149bbc940f8b2e632", "patch": "@@ -56,7 +56,7 @@ class back_threader_registry\n   bool register_path (const vec<basic_block> &, edge taken);\n   bool thread_through_all_blocks (bool may_peel_loop_headers);\n private:\n-  jump_thread_path_registry m_lowlevel_registry;\n+  back_jt_path_registry m_lowlevel_registry;\n   const int m_max_allowable_paths;\n   int m_threaded_paths;\n };"}, {"sha": "422cb89401bcef062367e428e96ffbadfcc0134c", "filename": "gcc/tree-ssa-threadedge.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadedge.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadedge.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadedge.c?ref=5485bbebb3679245dd4bc7c149bbc940f8b2e632", "patch": "@@ -71,7 +71,7 @@ jump_threader::jump_threader (jump_threader_simplifier *simplifier,\n   dummy_cond = gimple_build_cond (NE_EXPR, integer_zero_node,\n \t\t\t\t  integer_zero_node, NULL, NULL);\n \n-  m_registry = new jump_thread_path_registry ();\n+  m_registry = new fwd_jt_path_registry ();\n   m_simplifier = simplifier;\n   m_state = state;\n }"}, {"sha": "18e6bd41aaa7c5198c54c75a002670664746b2e4", "filename": "gcc/tree-ssa-threadedge.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadedge.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadedge.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadedge.h?ref=5485bbebb3679245dd4bc7c149bbc940f8b2e632", "patch": "@@ -75,7 +75,7 @@ class jump_threader\n   // Dummy condition to avoid creating lots of throw away statements.\n   gcond *dummy_cond;\n \n-  class jump_thread_path_registry *m_registry;\n+  class fwd_jt_path_registry *m_registry;\n   jump_threader_simplifier *m_simplifier;\n   jt_state *m_state;\n };"}, {"sha": "93538104fdfa0bdc9286811a89dfe3c497c3e924", "filename": "gcc/tree-ssa-threadupdate.c", "status": "modified", "additions": 108, "deletions": 105, "changes": 213, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadupdate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadupdate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadupdate.c?ref=5485bbebb3679245dd4bc7c149bbc940f8b2e632", "patch": "@@ -167,29 +167,36 @@ jump_thread_path_allocator::allocate_thread_path ()\n   return new (r) vec<jump_thread_edge *> ();\n }\n \n-jump_thread_path_registry::jump_thread_path_registry ()\n+jt_path_registry::jt_path_registry ()\n {\n   m_paths.create (5);\n-  m_removed_edges = new hash_table<struct removed_edges> (17);\n   m_num_threaded_edges = 0;\n-  m_redirection_data = NULL;\n }\n \n-jump_thread_path_registry::~jump_thread_path_registry ()\n+jt_path_registry::~jt_path_registry ()\n {\n   m_paths.release ();\n+}\n+\n+fwd_jt_path_registry::fwd_jt_path_registry ()\n+{\n+  m_removed_edges = new hash_table<struct removed_edges> (17);\n+  m_redirection_data = NULL;\n+}\n+\n+fwd_jt_path_registry::~fwd_jt_path_registry ()\n+{\n   delete m_removed_edges;\n }\n \n jump_thread_edge *\n-jump_thread_path_registry::allocate_thread_edge (edge e,\n-\t\t\t\t\t\t jump_thread_edge_type t)\n+jt_path_registry::allocate_thread_edge (edge e, jump_thread_edge_type t)\n {\n   return m_allocator.allocate_thread_edge (e, t);\n }\n \n vec<jump_thread_edge *> *\n-jump_thread_path_registry::allocate_thread_path ()\n+jt_path_registry::allocate_thread_path ()\n {\n   return m_allocator.allocate_thread_path ();\n }\n@@ -426,8 +433,7 @@ create_block_for_threading (basic_block bb,\n    edges associated with E in the hash table.  */\n \n redirection_data *\n-jump_thread_path_registry::lookup_redirection_data (edge e,\n-\t\t\t\t\t\t    enum insert_option insert)\n+fwd_jt_path_registry::lookup_redirection_data (edge e, insert_option insert)\n {\n   struct redirection_data **slot;\n   struct redirection_data *elt;\n@@ -1413,9 +1419,9 @@ redirection_block_p (basic_block bb)\n    If JOINERS is true, then thread through joiner blocks as well.  */\n \n bool\n-jump_thread_path_registry::thread_block_1 (basic_block bb,\n-\t\t\t\t\t   bool noloop_only,\n-\t\t\t\t\t   bool joiners)\n+fwd_jt_path_registry::thread_block_1 (basic_block bb,\n+\t\t\t\t      bool noloop_only,\n+\t\t\t\t      bool joiners)\n {\n   /* E is an incoming edge into BB that we may or may not want to\n      redirect to a duplicate of BB.  */\n@@ -1594,7 +1600,7 @@ jump_thread_path_registry::thread_block_1 (basic_block bb,\n    opportunity.  */\n \n bool\n-jump_thread_path_registry::thread_block (basic_block bb, bool noloop_only)\n+fwd_jt_path_registry::thread_block (basic_block bb, bool noloop_only)\n {\n   bool retval;\n   retval = thread_block_1 (bb, noloop_only, false);\n@@ -1675,9 +1681,8 @@ determine_bb_domination_status (class loop *loop, basic_block bb)\n    to the inside of the loop.  */\n \n bool\n-jump_thread_path_registry::thread_through_loop_header\n-\t\t\t\t(class loop *loop,\n-\t\t\t\t bool may_peel_loop_headers)\n+fwd_jt_path_registry::thread_through_loop_header (class loop *loop,\n+\t\t\t\t\t\t  bool may_peel_loop_headers)\n {\n   basic_block header = loop->header;\n   edge e, tgt_edge, latch = loop_latch_edge (loop);\n@@ -1932,7 +1937,7 @@ count_stmts_and_phis_in_block (basic_block bb)\n    hash table lookups to map from threaded edge to new target.  */\n \n void\n-jump_thread_path_registry::mark_threaded_blocks (bitmap threaded_blocks)\n+fwd_jt_path_registry::mark_threaded_blocks (bitmap threaded_blocks)\n {\n   unsigned int i;\n   bitmap_iterator bi;\n@@ -2197,7 +2202,7 @@ bb_in_bbs (basic_block bb, basic_block *bbs, int n)\n }\n \n void\n-jump_thread_path_registry::debug_path (FILE *dump_file, int pathno)\n+jt_path_registry::debug_path (FILE *dump_file, int pathno)\n {\n   vec<jump_thread_edge *> *p = m_paths[pathno];\n   fprintf (dump_file, \"path: \");\n@@ -2208,7 +2213,7 @@ jump_thread_path_registry::debug_path (FILE *dump_file, int pathno)\n }\n \n void\n-jump_thread_path_registry::dump ()\n+jt_path_registry::debug ()\n {\n   for (unsigned i = 0; i < m_paths.length (); ++i)\n     debug_path (stderr, i);\n@@ -2223,8 +2228,8 @@ jump_thread_path_registry::dump ()\n    Returns TRUE if we were able to successfully rewire the edge.  */\n \n bool\n-jump_thread_path_registry::rewire_first_differing_edge (unsigned path_num,\n-\t\t\t\t\t\t\tunsigned edge_num)\n+back_jt_path_registry::rewire_first_differing_edge (unsigned path_num,\n+\t\t\t\t\t\t    unsigned edge_num)\n {\n   vec<jump_thread_edge *> *path = m_paths[path_num];\n   edge &e = (*path)[edge_num]->e;\n@@ -2269,11 +2274,9 @@ jump_thread_path_registry::rewire_first_differing_edge (unsigned path_num,\n    specifies the path that was just threaded.  */\n \n void\n-jump_thread_path_registry::adjust_paths_after_duplication\n-\t(unsigned curr_path_num)\n+back_jt_path_registry::adjust_paths_after_duplication (unsigned curr_path_num)\n {\n   vec<jump_thread_edge *> *curr_path = m_paths[curr_path_num];\n-  gcc_assert ((*curr_path)[0]->type == EDGE_FSM_THREAD);\n \n   if (dump_file && (dump_flags & TDF_DETAILS))\n     {\n@@ -2347,8 +2350,16 @@ jump_thread_path_registry::adjust_paths_after_duplication\n \t      m_paths.unordered_remove (cand_path_num);\n \t      continue;\n \t    }\n-\t  /* Otherwise, just remove the redundant sub-path.  */\n-\t  cand_path->block_remove (0, j);\n+\t  if ((*cand_path)[j]->type != EDGE_FSM_THREAD)\n+\t    {\n+\t      /* If all the EDGE_FSM_THREADs are common, all that's\n+\t\t left is the final EDGE_NO_COPY_SRC_BLOCK.  */\n+\t      if (dump_file && (dump_flags & TDF_DETAILS))\n+\t\tfprintf (dump_file, \"Dropping illformed candidate.\\n\");\n+\t    }\n+\t  else\n+\t    /* Otherwise, just remove the redundant sub-path.  */\n+\t    cand_path->block_remove (0, j);\n \t}\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \t{\n@@ -2372,11 +2383,11 @@ jump_thread_path_registry::adjust_paths_after_duplication\n    Returns false if it is unable to copy the region, true otherwise.  */\n \n bool\n-jump_thread_path_registry::duplicate_thread_path (edge entry,\n-\t\t\t\t\t\t  edge exit,\n-\t\t\t\t\t\t  basic_block *region,\n-\t\t\t\t\t\t  unsigned n_region,\n-\t\t\t\t\t\t  unsigned current_path_no)\n+back_jt_path_registry::duplicate_thread_path (edge entry,\n+\t\t\t\t\t      edge exit,\n+\t\t\t\t\t      basic_block *region,\n+\t\t\t\t\t      unsigned n_region,\n+\t\t\t\t\t      unsigned current_path_no)\n {\n   unsigned i;\n   class loop *loop = entry->dest->loop_father;\n@@ -2551,7 +2562,7 @@ valid_jump_thread_path (vec<jump_thread_edge *> *path)\n    DOM/VRP rather than for every case where DOM optimizes away a COND_EXPR.  */\n \n void\n-jump_thread_path_registry::remove_jump_threads_including (edge_def *e)\n+fwd_jt_path_registry::remove_jump_threads_including (edge_def *e)\n {\n   if (!m_paths.exists ())\n     return;\n@@ -2560,69 +2571,52 @@ jump_thread_path_registry::remove_jump_threads_including (edge_def *e)\n   *slot = e;\n }\n \n-/* Walk through all blocks and thread incoming edges to the appropriate\n-   outgoing edge for each edge pair recorded in THREADED_EDGES.\n+/* Thread all paths that have been queued for jump threading, and\n+   update the CFG accordingly.\n \n    It is the caller's responsibility to fix the dominance information\n    and rewrite duplicated SSA_NAMEs back into SSA form.\n \n-   If MAY_PEEL_LOOP_HEADERS is false, we avoid threading edges through\n-   loop headers if it does not simplify the loop.\n+   If PEEL_LOOP_HEADERS is false, avoid threading edges through loop\n+   headers if it does not simplify the loop.\n \n-   Returns true if one or more edges were threaded, false otherwise.  */\n+   Returns true if one or more edges were threaded.  */\n \n bool\n-jump_thread_path_registry::thread_through_all_blocks\n-\t(bool may_peel_loop_headers)\n+jt_path_registry::thread_through_all_blocks (bool peel_loop_headers)\n {\n-  bool retval = false;\n-  unsigned int i;\n-  auto_bitmap threaded_blocks;\n-  hash_set<edge> visited_starting_edges;\n-\n-  if (!m_paths.exists ())\n-    {\n-      retval = false;\n-      goto out;\n-    }\n+  if (m_paths.length () == 0)\n+    return false;\n \n   m_num_threaded_edges = 0;\n \n-  /* Remove any paths that referenced removed edges.  */\n-  if (m_removed_edges)\n-    for (i = 0; i < m_paths.length (); )\n-      {\n-\tunsigned int j;\n-\tvec<jump_thread_edge *> *path = m_paths[i];\n+  bool retval = update_cfg (peel_loop_headers);\n \n-\tfor (j = 0; j < path->length (); j++)\n-\t  {\n-\t    edge e = (*path)[j]->e;\n-\t    if (m_removed_edges->find_slot (e, NO_INSERT))\n-\t      break;\n-\t  }\n+  statistics_counter_event (cfun, \"Jumps threaded\", m_num_threaded_edges);\n \n-\tif (j != path->length ())\n-\t  {\n-\t    cancel_thread (path, \"Thread references removed edge\");\n-\t    m_paths.unordered_remove (i);\n-\t    continue;\n-\t  }\n-\ti++;\n-      }\n+  if (retval)\n+    {\n+      loops_state_set (LOOPS_NEED_FIXUP);\n+      return true;\n+    }\n+  return false;\n+}\n \n-  /* Jump-thread all FSM threads before other jump-threads.  */\n-  for (i = 0; i < m_paths.length ();)\n+/* This is the backward threader version of thread_through_all_blocks\n+   using a generic BB copier.  */\n+\n+bool\n+back_jt_path_registry::update_cfg (bool /*peel_loop_headers*/)\n+{\n+  bool retval = false;\n+  hash_set<edge> visited_starting_edges;\n+\n+  while (m_paths.length ())\n     {\n-      vec<jump_thread_edge *> *path = m_paths[i];\n+      vec<jump_thread_edge *> *path = m_paths[0];\n       edge entry = (*path)[0]->e;\n \n-      /* Only code-generate FSM jump-threads in this loop.  */\n-      if ((*path)[0]->type != EDGE_FSM_THREAD)\n-\t{\n-\t  i++;\n-\t  continue;\n-\t}\n+      gcc_checking_assert ((*path)[0]->type == EDGE_FSM_THREAD);\n \n       /* Do not jump-thread twice from the same starting edge.\n \n@@ -2638,8 +2632,8 @@ jump_thread_path_registry::thread_through_all_blocks\n \t  || !valid_jump_thread_path (path))\n \t{\n \t  /* Remove invalid FSM jump-thread paths.  */\n-\t  cancel_thread (path, \"Invalid FSM jump-thread path\");\n-\t  m_paths.unordered_remove (i);\n+\t  cancel_thread (path, \"Avoiding threading twice from same edge\");\n+\t  m_paths.unordered_remove (0);\n \t  continue;\n \t}\n \n@@ -2650,7 +2644,7 @@ jump_thread_path_registry::thread_through_all_blocks\n       for (unsigned int j = 0; j < len - 1; j++)\n \tregion[j] = (*path)[j]->e->dest;\n \n-      if (duplicate_thread_path (entry, exit, region, len - 1, i))\n+      if (duplicate_thread_path (entry, exit, region, len - 1, 0))\n \t{\n \t  /* We do not update dominance info.  */\n \t  free_dominance_info (CDI_DOMINATORS);\n@@ -2660,27 +2654,44 @@ jump_thread_path_registry::thread_through_all_blocks\n \t}\n \n       path->release ();\n-      m_paths.unordered_remove (i);\n+      m_paths.unordered_remove (0);\n       free (region);\n     }\n+  return retval;\n+}\n \n-  /* Remove from PATHS all the jump-threads starting with an edge already\n-     jump-threaded.  */\n-  for (i = 0; i < m_paths.length ();)\n-    {\n-      vec<jump_thread_edge *> *path = m_paths[i];\n-      edge entry = (*path)[0]->e;\n+/* This is the forward threader version of thread_through_all_blocks,\n+   using a custom BB copier.  */\n \n-      /* Do not jump-thread twice from the same block.  */\n-      if (visited_starting_edges.contains (entry))\n-\t{\n-\t  cancel_thread (path, \"Avoiding threading twice from same BB\");\n-\t  m_paths.unordered_remove (i);\n-\t}\n-      else\n+bool\n+fwd_jt_path_registry::update_cfg (bool may_peel_loop_headers)\n+{\n+  bool retval = false;\n+\n+  /* Remove any paths that referenced removed edges.  */\n+  if (m_removed_edges)\n+    for (unsigned i = 0; i < m_paths.length (); )\n+      {\n+\tunsigned int j;\n+\tvec<jump_thread_edge *> *path = m_paths[i];\n+\n+\tfor (j = 0; j < path->length (); j++)\n+\t  {\n+\t    edge e = (*path)[j]->e;\n+\t    if (m_removed_edges->find_slot (e, NO_INSERT))\n+\t      break;\n+\t  }\n+\n+\tif (j != path->length ())\n+\t  {\n+\t    cancel_thread (path, \"Thread references removed edge\");\n+\t    m_paths.unordered_remove (i);\n+\t    continue;\n+\t  }\n \ti++;\n-    }\n+      }\n \n+  auto_bitmap threaded_blocks;\n   mark_threaded_blocks (threaded_blocks);\n \n   initialize_original_copy_tables ();\n@@ -2737,16 +2748,8 @@ jump_thread_path_registry::thread_through_all_blocks\n \tgcc_assert (e->aux == NULL);\n     }\n \n-  statistics_counter_event (cfun, \"Jumps threaded\", m_num_threaded_edges);\n-\n   free_original_copy_tables ();\n \n-  m_paths.release ();\n-\n-  if (retval)\n-    loops_state_set (LOOPS_NEED_FIXUP);\n-\n- out:\n   return retval;\n }\n \n@@ -2761,7 +2764,7 @@ jump_thread_path_registry::thread_through_all_blocks\n    Return TRUE if PATH was successfully threaded.  */\n \n bool\n-jump_thread_path_registry::register_jump_thread (vec<jump_thread_edge *> *path)\n+jt_path_registry::register_jump_thread (vec<jump_thread_edge *> *path)\n {\n   if (!dbg_cnt (registered_jump_thread))\n     {"}, {"sha": "58e3a38e0c5dfcb725facba3123ccfbdb0a24733", "filename": "gcc/tree-ssa-threadupdate.h", "status": "modified", "additions": 38, "deletions": 22, "changes": 60, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadupdate.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5485bbebb3679245dd4bc7c149bbc940f8b2e632/gcc%2Ftree-ssa-threadupdate.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadupdate.h?ref=5485bbebb3679245dd4bc7c149bbc940f8b2e632", "patch": "@@ -54,49 +54,65 @@ class jump_thread_path_allocator\n   obstack m_obstack;\n };\n \n-// This is the underlying jump thread registry.  When all candidates\n-// have been registered with register_jump_thread(),\n-// thread_through_all_blocks() is called to actually change the CFG.\n+// Abstract class for the jump thread registry.\n+//\n+// When all candidates have been registered with\n+// register_jump_thread(), thread_through_all_blocks() is called to\n+// update the CFG.\n \n-class jump_thread_path_registry\n+class jt_path_registry\n {\n public:\n-  jump_thread_path_registry ();\n-  ~jump_thread_path_registry ();\n+  jt_path_registry ();\n+  virtual ~jt_path_registry ();\n   bool register_jump_thread (vec<jump_thread_edge *> *);\n-  void remove_jump_threads_including (edge);\n-  bool thread_through_all_blocks (bool);\n+  bool thread_through_all_blocks (bool peel_loop_headers);\n   jump_thread_edge *allocate_thread_edge (edge e, jump_thread_edge_type t);\n   vec<jump_thread_edge *> *allocate_thread_path ();\n-  void dump ();\n+  void debug ();\n+protected:\n+  void debug_path (FILE *, int pathno);\n+  vec<vec<jump_thread_edge *> *> m_paths;\n+  unsigned long m_num_threaded_edges;\n+private:\n+  virtual bool update_cfg (bool peel_loop_headers) = 0;\n+  jump_thread_path_allocator m_allocator;\n+  DISABLE_COPY_AND_ASSIGN (jt_path_registry);\n+};\n+\n+// Forward threader path registry using a custom BB copier.\n \n+class fwd_jt_path_registry : public jt_path_registry\n+{\n+public:\n+  fwd_jt_path_registry ();\n+  ~fwd_jt_path_registry ();\n+  void remove_jump_threads_including (edge);\n private:\n-  void debug_path (FILE *, int pathno);\n+  bool update_cfg (bool peel_loop_headers) override;\n   void mark_threaded_blocks (bitmap threaded_blocks);\n-  bool rewire_first_differing_edge (unsigned path_num, unsigned edge_num);\n-  void adjust_paths_after_duplication (unsigned curr_path_num);\n-  bool duplicate_thread_path (edge entry,\n-\t\t\t      edge exit,\n-\t\t\t      basic_block *region,\n-\t\t\t      unsigned n_region,\n-\t\t\t      unsigned current_path_no);\n   bool thread_block_1 (basic_block, bool noloop_only, bool joiners);\n   bool thread_block (basic_block, bool noloop_only);\n   bool thread_through_loop_header (class loop *loop,\n \t\t\t\t   bool may_peel_loop_headers);\n   class redirection_data *lookup_redirection_data (edge e, enum insert_option);\n \n-  vec<vec<jump_thread_edge *> *> m_paths;\n-\n   hash_table<struct removed_edges> *m_removed_edges;\n \n   // Main data structure to hold information for duplicates of BB.\n   hash_table<redirection_data> *m_redirection_data;\n+};\n \n-  // Jump threading statistics.\n-  unsigned long m_num_threaded_edges;\n+// Backward threader path registry using a generic BB copier.\n \n-  jump_thread_path_allocator m_allocator;\n+class back_jt_path_registry : public jt_path_registry\n+{\n+private:\n+  bool update_cfg (bool peel_loop_headers) override;\n+  void adjust_paths_after_duplication (unsigned curr_path_num);\n+  bool duplicate_thread_path (edge entry, edge exit, basic_block *region,\n+\t\t\t      unsigned n_region, unsigned current_path_no);\n+  bool rewire_first_differing_edge (unsigned path_num, unsigned edge_num);\n };\n \n // Rather than search all the edges in jump thread paths each time DOM"}]}