{"sha": "939cf90f620b91441180aacb7a3c290f1a53aa10", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTM5Y2Y5MGY2MjBiOTE0NDExODBhYWNiN2EzYzI5MGYxYTUzYWExMA==", "commit": {"author": {"name": "Bin Cheng", "email": "bin.cheng@arm.com", "date": "2017-10-12T14:33:30Z"}, "committer": {"name": "Bin Cheng", "email": "amker@gcc.gnu.org", "date": "2017-10-12T14:33:30Z"}, "message": "tree-loop-distribution.c (struct builtin_info): New struct.\n\n\t* tree-loop-distribution.c (struct builtin_info): New struct.\n\t(struct partition): Refactor fields into struct builtin_info.\n\t(partition_free): Free struct builtin_info.\n\t(build_size_arg_loc, build_addr_arg_loc): Delete.\n\t(generate_memset_builtin, generate_memcpy_builtin): Get memory range\n\tinformation from struct builtin_info.\n\t(find_single_drs): New function refactored from classify_partition.\n\tAlso moved builtin validity checks to this function.\n\t(compute_access_range, alloc_builtin): New functions.\n\t(classify_builtin_st, classify_builtin_ldst): New functions.\n\t(classify_partition): Refactor code into functions find_single_drs,\n\tclassify_builtin_st and classify_builtin_ldst.\n\t(distribute_loop): Don't do runtime alias check when distributing\n\tloop nest.\n\t(find_seed_stmts_for_distribution): New function.\n\t(pass_loop_distribution::execute): Refactor code finding seed\n\tstmts into above function.  Support distribution for the innermost\n\ttwo-level loop nest.  Adjust dump information.\n\n\tgcc/testsuite\n\t* gcc.dg/tree-ssa/ldist-28.c: New test.\n\t* gcc.dg/tree-ssa/ldist-29.c: New test.\n\t* gcc.dg/tree-ssa/ldist-30.c: New test.\n\t* gcc.dg/tree-ssa/ldist-31.c: New test.\n\nFrom-SVN: r253680", "tree": {"sha": "2d52e40fa2837c0e2d43c2dd8dd15d61cf52ba1f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2d52e40fa2837c0e2d43c2dd8dd15d61cf52ba1f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/939cf90f620b91441180aacb7a3c290f1a53aa10", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/939cf90f620b91441180aacb7a3c290f1a53aa10", "html_url": "https://github.com/Rust-GCC/gccrs/commit/939cf90f620b91441180aacb7a3c290f1a53aa10", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/939cf90f620b91441180aacb7a3c290f1a53aa10/comments", "author": null, "committer": null, "parents": [{"sha": "163aa51b706a50c86b639d7827803550706bef78", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/163aa51b706a50c86b639d7827803550706bef78", "html_url": "https://github.com/Rust-GCC/gccrs/commit/163aa51b706a50c86b639d7827803550706bef78"}], "stats": {"total": 603, "additions": 405, "deletions": 198}, "files": [{"sha": "488a40db8a1827cb3010deb393de05f27446237a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=939cf90f620b91441180aacb7a3c290f1a53aa10", "patch": "@@ -1,3 +1,24 @@\n+2017-10-12  Bin Cheng  <bin.cheng@arm.com>\n+\n+\t* tree-loop-distribution.c (struct builtin_info): New struct.\n+\t(struct partition): Refactor fields into struct builtin_info.\n+\t(partition_free): Free struct builtin_info.\n+\t(build_size_arg_loc, build_addr_arg_loc): Delete.\n+\t(generate_memset_builtin, generate_memcpy_builtin): Get memory range\n+\tinformation from struct builtin_info.\n+\t(find_single_drs): New function refactored from classify_partition.\n+\tAlso moved builtin validity checks to this function.\n+\t(compute_access_range, alloc_builtin): New functions.\n+\t(classify_builtin_st, classify_builtin_ldst): New functions.\n+\t(classify_partition): Refactor code into functions find_single_drs,\n+\tclassify_builtin_st and classify_builtin_ldst.\n+\t(distribute_loop): Don't do runtime alias check when distributing\n+\tloop nest.\n+\t(find_seed_stmts_for_distribution): New function.\n+\t(pass_loop_distribution::execute): Refactor code finding seed\n+\tstmts into above function.  Support distribution for the innermost\n+\ttwo-level loop nest.  Adjust dump information.\n+\n 2017-10-12  Bin Cheng  <bin.cheng@arm.com>\n \n \t* tree-loop-distribution.c: Adjust the general comment."}, {"sha": "2fa01d469d5fee43b90a23c89294980cfe173bc2", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=939cf90f620b91441180aacb7a3c290f1a53aa10", "patch": "@@ -1,3 +1,10 @@\n+2017-10-12  Bin Cheng  <bin.cheng@arm.com>\n+\n+\t* gcc.dg/tree-ssa/ldist-28.c: New test.\n+\t* gcc.dg/tree-ssa/ldist-29.c: New test.\n+\t* gcc.dg/tree-ssa/ldist-30.c: New test.\n+\t* gcc.dg/tree-ssa/ldist-31.c: New test.\n+\n 2017-10-12  Bin Cheng  <bin.cheng@arm.com>\n \n \t* gcc.dg/tree-ssa/ldist-7.c: Adjust test string."}, {"sha": "4420139dedb85b348955487209f6923d8def1fb9", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ldist-28.c", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-28.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-28.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-28.c?ref=939cf90f620b91441180aacb7a3c290f1a53aa10", "patch": "@@ -0,0 +1,16 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -ftree-loop-distribution -ftree-loop-distribute-patterns -fdump-tree-ldist-details\" } */\n+\n+#define M (256)\n+#define N (1024)\n+int arr[M][N];\n+\n+void\n+foo (void)\n+{\n+  for (unsigned i = 0; i < M; ++i)\n+    for (unsigned j = 0; j < N; ++j)\n+      arr[i][j] = 0;\n+}\n+\n+/* { dg-final { scan-tree-dump \"Loop nest . distributed: split to 0 loops and 1 library\" \"ldist\" } } */"}, {"sha": "9ce93e80b07a110a6b0ea2d1ba4bdcc676682612", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ldist-29.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-29.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-29.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-29.c?ref=939cf90f620b91441180aacb7a3c290f1a53aa10", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -ftree-loop-distribution -ftree-loop-distribute-patterns -fdump-tree-ldist-details\" } */\n+\n+#define M (256)\n+#define N (512)\n+int arr[M][N];\n+\n+void\n+foo (void)\n+{\n+  for (unsigned i = 0; i < M; ++i)\n+    for (unsigned j = 0; j < N - 1; ++j)\n+      arr[i][j] = 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-not \"Loop nest . distributed: split to\" \"ldist\" } } */\n+/* { dg-final { scan-tree-dump-times \"Loop . distributed: split to 0 loops and 1 library\" 1 \"ldist\" } } */"}, {"sha": "f31860a574ed3d3931f1ac889fadf98e44a976cc", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ldist-30.c", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-30.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-30.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-30.c?ref=939cf90f620b91441180aacb7a3c290f1a53aa10", "patch": "@@ -0,0 +1,16 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -ftree-loop-distribution -ftree-loop-distribute-patterns -fdump-tree-ldist-details\" } */\n+\n+#define M (256)\n+#define N (512)\n+int a[M][N], b[M][N];\n+\n+void\n+foo (void)\n+{\n+  for (unsigned i = 0; i < M; ++i)\n+    for (unsigned j = N; j > 0; --j)\n+      a[i][j - 1] = b[i][j - 1];\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"Loop nest . distributed: split to\" 1 \"ldist\" } } */"}, {"sha": "60a9f743b1b15021c451ff66663bd54548c0bb9c", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ldist-31.c", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-31.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-31.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fldist-31.c?ref=939cf90f620b91441180aacb7a3c290f1a53aa10", "patch": "@@ -0,0 +1,19 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -ftree-loop-distribution -ftree-loop-distribute-patterns -fdump-tree-ldist-details\" } */\n+\n+#define M (256)\n+#define N (512)\n+int a[M][N], b[M][N], c[M];\n+\n+void\n+foo (void)\n+{\n+  for (int i = M - 1; i >= 0; --i)\n+    {\n+      c[i] = 0;\n+      for (unsigned j = N; j > 0; --j)\n+\ta[i][j - 1] = b[i][j - 1];\n+    }\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"Loop nest . distributed: split to 0 loops and 2 library\" 1 \"ldist\" } } */"}, {"sha": "5e835be779da44d838eee787267e4ee6a75ab4c7", "filename": "gcc/tree-loop-distribution.c", "status": "modified", "additions": 309, "deletions": 198, "changes": 507, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftree-loop-distribution.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/939cf90f620b91441180aacb7a3c290f1a53aa10/gcc%2Ftree-loop-distribution.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-loop-distribution.c?ref=939cf90f620b91441180aacb7a3c290f1a53aa10", "patch": "@@ -593,25 +593,32 @@ enum partition_type {\n     PTYPE_SEQUENTIAL\n };\n \n+/* Builtin info for loop distribution.  */\n+struct builtin_info\n+{\n+  /* data-references a kind != PKIND_NORMAL partition is about.  */\n+  data_reference_p dst_dr;\n+  data_reference_p src_dr;\n+  /* Base address and size of memory objects operated by the builtin.  Note\n+     both dest and source memory objects must have the same size.  */\n+  tree dst_base;\n+  tree src_base;\n+  tree size;\n+};\n+\n /* Partition for loop distribution.  */\n struct partition\n {\n   /* Statements of the partition.  */\n   bitmap stmts;\n   /* True if the partition defines variable which is used outside of loop.  */\n   bool reduction_p;\n-  /* For builtin partition, true if it executes one iteration more than\n-     number of loop (latch) iterations.  */\n-  bool plus_one;\n   enum partition_kind kind;\n   enum partition_type type;\n-  /* data-references a kind != PKIND_NORMAL partition is about.  */\n-  data_reference_p main_dr;\n-  data_reference_p secondary_dr;\n-  /* Number of loop (latch) iterations.  */\n-  tree niter;\n   /* Data references in the partition.  */\n   bitmap datarefs;\n+  /* Information of builtin parition.  */\n+  struct builtin_info *builtin;\n };\n \n \n@@ -635,6 +642,9 @@ partition_free (partition *partition)\n {\n   BITMAP_FREE (partition->stmts);\n   BITMAP_FREE (partition->datarefs);\n+  if (partition->builtin)\n+    free (partition->builtin);\n+\n   free (partition);\n }\n \n@@ -894,43 +904,6 @@ generate_loops_for_partition (struct loop *loop, partition *partition,\n   free (bbs);\n }\n \n-/* Build the size argument for a memory operation call.  */\n-\n-static tree\n-build_size_arg_loc (location_t loc, data_reference_p dr, tree nb_iter,\n-\t\t    bool plus_one)\n-{\n-  tree size = fold_convert_loc (loc, sizetype, nb_iter);\n-  if (plus_one)\n-    size = size_binop (PLUS_EXPR, size, size_one_node);\n-  size = fold_build2_loc (loc, MULT_EXPR, sizetype, size,\n-\t\t\t  TYPE_SIZE_UNIT (TREE_TYPE (DR_REF (dr))));\n-  size = fold_convert_loc (loc, size_type_node, size);\n-  return size;\n-}\n-\n-/* Build an address argument for a memory operation call.  */\n-\n-static tree\n-build_addr_arg_loc (location_t loc, data_reference_p dr, tree nb_bytes)\n-{\n-  tree addr_base;\n-\n-  addr_base = size_binop_loc (loc, PLUS_EXPR, DR_OFFSET (dr), DR_INIT (dr));\n-  addr_base = fold_convert_loc (loc, sizetype, addr_base);\n-\n-  /* Test for a negative stride, iterating over every element.  */\n-  if (tree_int_cst_sgn (DR_STEP (dr)) == -1)\n-    {\n-      addr_base = size_binop_loc (loc, MINUS_EXPR, addr_base,\n-\t\t\t\t  fold_convert_loc (loc, sizetype, nb_bytes));\n-      addr_base = size_binop_loc (loc, PLUS_EXPR, addr_base,\n-\t\t\t\t  TYPE_SIZE_UNIT (TREE_TYPE (DR_REF (dr))));\n-    }\n-\n-  return fold_build_pointer_plus_loc (loc, DR_BASE_ADDRESS (dr), addr_base);\n-}\n-\n /* If VAL memory representation contains the same value in all bytes,\n    return that value, otherwise return -1.\n    E.g. for 0x24242424 return 0x24, for IEEE double\n@@ -995,27 +968,23 @@ static void\n generate_memset_builtin (struct loop *loop, partition *partition)\n {\n   gimple_stmt_iterator gsi;\n-  gimple *stmt, *fn_call;\n   tree mem, fn, nb_bytes;\n-  location_t loc;\n   tree val;\n-\n-  stmt = DR_STMT (partition->main_dr);\n-  loc = gimple_location (stmt);\n+  struct builtin_info *builtin = partition->builtin;\n+  gimple *fn_call;\n \n   /* The new statements will be placed before LOOP.  */\n   gsi = gsi_last_bb (loop_preheader_edge (loop)->src);\n \n-  nb_bytes = build_size_arg_loc (loc, partition->main_dr, partition->niter,\n-\t\t\t\t partition->plus_one);\n+  nb_bytes = builtin->size;\n   nb_bytes = force_gimple_operand_gsi (&gsi, nb_bytes, true, NULL_TREE,\n \t\t\t\t       false, GSI_CONTINUE_LINKING);\n-  mem = build_addr_arg_loc (loc, partition->main_dr, nb_bytes);\n+  mem = builtin->dst_base;\n   mem = force_gimple_operand_gsi (&gsi, mem, true, NULL_TREE,\n \t\t\t\t  false, GSI_CONTINUE_LINKING);\n \n   /* This exactly matches the pattern recognition in classify_partition.  */\n-  val = gimple_assign_rhs1 (stmt);\n+  val = gimple_assign_rhs1 (DR_STMT (builtin->dst_dr));\n   /* Handle constants like 0x15151515 and similarly\n      floating point constants etc. where all bytes are the same.  */\n   int bytev = const_with_all_bytes_same (val);\n@@ -1051,23 +1020,19 @@ static void\n generate_memcpy_builtin (struct loop *loop, partition *partition)\n {\n   gimple_stmt_iterator gsi;\n-  gimple *stmt, *fn_call;\n+  gimple *fn_call;\n   tree dest, src, fn, nb_bytes;\n-  location_t loc;\n   enum built_in_function kind;\n-\n-  stmt = DR_STMT (partition->main_dr);\n-  loc = gimple_location (stmt);\n+  struct builtin_info *builtin = partition->builtin;\n \n   /* The new statements will be placed before LOOP.  */\n   gsi = gsi_last_bb (loop_preheader_edge (loop)->src);\n \n-  nb_bytes = build_size_arg_loc (loc, partition->main_dr, partition->niter,\n-\t\t\t\t partition->plus_one);\n+  nb_bytes = builtin->size;\n   nb_bytes = force_gimple_operand_gsi (&gsi, nb_bytes, true, NULL_TREE,\n \t\t\t\t       false, GSI_CONTINUE_LINKING);\n-  dest = build_addr_arg_loc (loc, partition->main_dr, nb_bytes);\n-  src = build_addr_arg_loc (loc, partition->secondary_dr, nb_bytes);\n+  dest = builtin->dst_base;\n+  src = builtin->src_base;\n   if (partition->kind == PKIND_MEMCPY\n       || ! ptr_derefs_may_alias_p (dest, src))\n     kind = BUILT_IN_MEMCPY;\n@@ -1318,69 +1283,22 @@ build_rdg_partition_for_vertex (struct graph *rdg, int v)\n   return partition;\n }\n \n-/* Classifies the builtin kind we can generate for PARTITION of RDG and LOOP.\n-   For the moment we detect memset, memcpy and memmove patterns.  Bitmap\n-   STMT_IN_ALL_PARTITIONS contains statements belonging to all partitions.  */\n+/* Given PARTITION of RDG, record single load/store data references for\n+   builtin partition in SRC_DR/DST_DR, return false if there is no such\n+   data references.  */\n \n-static void\n-classify_partition (loop_p loop, struct graph *rdg, partition *partition,\n-\t\t    bitmap stmt_in_all_partitions)\n+static bool\n+find_single_drs (struct graph *rdg, partition *partition,\n+\t\t data_reference_p *dst_dr, data_reference_p *src_dr)\n {\n-  bitmap_iterator bi;\n   unsigned i;\n-  tree nb_iter;\n-  data_reference_p single_load, single_store;\n-  bool volatiles_p = false, plus_one = false, has_reduction = false;\n-\n-  partition->kind = PKIND_NORMAL;\n-  partition->main_dr = NULL;\n-  partition->secondary_dr = NULL;\n-  partition->niter = NULL_TREE;\n-  partition->plus_one = false;\n-\n-  EXECUTE_IF_SET_IN_BITMAP (partition->stmts, 0, i, bi)\n-    {\n-      gimple *stmt = RDG_STMT (rdg, i);\n-\n-      if (gimple_has_volatile_ops (stmt))\n-\tvolatiles_p = true;\n-\n-      /* If the stmt is not included by all partitions and there is uses\n-\t outside of the loop, then mark the partition as reduction.  */\n-      if (stmt_has_scalar_dependences_outside_loop (loop, stmt))\n-\t{\n-\t  /* Due to limitation in the transform phase we have to fuse all\n-\t     reduction partitions.  As a result, this could cancel valid\n-\t     loop distribution especially for loop that induction variable\n-\t     is used outside of loop.  To workaround this issue, we skip\n-\t     marking partition as reudction if the reduction stmt belongs\n-\t     to all partitions.  In such case, reduction will be computed\n-\t     correctly no matter how partitions are fused/distributed.  */\n-\t  if (!bitmap_bit_p (stmt_in_all_partitions, i))\n-\t    {\n-\t      partition->reduction_p = true;\n-\t      return;\n-\t    }\n-\t  has_reduction = true;\n-\t}\n-    }\n-\n-  /* Perform general partition disqualification for builtins.  */\n-  if (volatiles_p\n-      /* Simple workaround to prevent classifying the partition as builtin\n-\t if it contains any use outside of loop.  */\n-      || has_reduction\n-      || !flag_tree_loop_distribute_patterns)\n-    return;\n+  data_reference_p single_ld = NULL, single_st = NULL;\n+  bitmap_iterator bi;\n \n-  /* Detect memset and memcpy.  */\n-  single_load = NULL;\n-  single_store = NULL;\n   EXECUTE_IF_SET_IN_BITMAP (partition->stmts, 0, i, bi)\n     {\n       gimple *stmt = RDG_STMT (rdg, i);\n       data_reference_p dr;\n-      unsigned j;\n \n       if (gimple_code (stmt) == GIMPLE_PHI)\n \tcontinue;\n@@ -1391,123 +1309,316 @@ classify_partition (loop_p loop, struct graph *rdg, partition *partition,\n \n       /* Otherwise just regular loads/stores.  */\n       if (!gimple_assign_single_p (stmt))\n-\treturn;\n+\treturn false;\n \n       /* But exactly one store and/or load.  */\n-      for (j = 0; RDG_DATAREFS (rdg, i).iterate (j, &dr); ++j)\n+      for (unsigned j = 0; RDG_DATAREFS (rdg, i).iterate (j, &dr); ++j)\n \t{\n \t  tree type = TREE_TYPE (DR_REF (dr));\n \n \t  /* The memset, memcpy and memmove library calls are only\n \t     able to deal with generic address space.  */\n \t  if (!ADDR_SPACE_GENERIC_P (TYPE_ADDR_SPACE (type)))\n-\t    return;\n+\t    return false;\n \n \t  if (DR_IS_READ (dr))\n \t    {\n-\t      if (single_load != NULL)\n-\t\treturn;\n-\t      single_load = dr;\n+\t      if (single_ld != NULL)\n+\t\treturn false;\n+\t      single_ld = dr;\n \t    }\n \t  else\n \t    {\n-\t      if (single_store != NULL)\n-\t\treturn;\n-\t      single_store = dr;\n+\t      if (single_st != NULL)\n+\t\treturn false;\n+\t      single_st = dr;\n \t    }\n \t}\n     }\n \n-  if (!single_store)\n-    return;\n+  if (!single_st)\n+    return false;\n+\n+  /* Bail out if this is a bitfield memory reference.  */\n+  if (TREE_CODE (DR_REF (single_st)) == COMPONENT_REF\n+      && DECL_BIT_FIELD (TREE_OPERAND (DR_REF (single_st), 1)))\n+    return false;\n \n-  /* TODO: We don't support memset/memcpy distribution for loop nest yet.  */\n-  if (loop->inner)\n+  /* Data reference must be executed exactly once per iteration.  */\n+  basic_block bb_st = gimple_bb (DR_STMT (single_st));\n+  struct loop *inner = bb_st->loop_father;\n+  if (!dominated_by_p (CDI_DOMINATORS, inner->latch, bb_st))\n+    return false;\n+\n+  if (single_ld)\n     {\n-      basic_block bb = gimple_bb (DR_STMT (single_store));\n+      gimple *store = DR_STMT (single_st), *load = DR_STMT (single_ld);\n+      /* Direct aggregate copy or via an SSA name temporary.  */\n+      if (load != store\n+\t  && gimple_assign_lhs (load) != gimple_assign_rhs1 (store))\n+\treturn false;\n \n-      if (bb->loop_father != loop)\n-\treturn;\n+      /* Bail out if this is a bitfield memory reference.  */\n+      if (TREE_CODE (DR_REF (single_ld)) == COMPONENT_REF\n+\t  && DECL_BIT_FIELD (TREE_OPERAND (DR_REF (single_ld), 1)))\n+\treturn false;\n+\n+      /* Load and store must be in the same loop nest.  */\n+      basic_block bb_ld = gimple_bb (DR_STMT (single_ld));\n+      if (inner != bb_ld->loop_father)\n+\treturn false;\n+\n+      /* Data reference must be executed exactly once per iteration.  */\n+      if (!dominated_by_p (CDI_DOMINATORS, inner->latch, bb_ld))\n+\treturn false;\n \n-      if (single_load)\n+      edge e = single_exit (inner);\n+      bool dom_ld = dominated_by_p (CDI_DOMINATORS, e->src, bb_ld);\n+      bool dom_st = dominated_by_p (CDI_DOMINATORS, e->src, bb_st);\n+      if (dom_ld != dom_st)\n+\treturn false;\n+    }\n+\n+  *src_dr = single_ld;\n+  *dst_dr = single_st;\n+  return true;\n+}\n+\n+/* Given data reference DR in LOOP_NEST, this function checks the enclosing\n+   loops from inner to outer to see if loop's step equals to access size at\n+   each level of loop.  Return true if yes; record access base and size in\n+   BASE and SIZE; save loop's step at each level of loop in STEPS if it is\n+   not null.  For example:\n+\n+     int arr[100][100][100];\n+     for (i = 0; i < 100; i++)       ;steps[2] = 40000\n+       for (j = 100; j > 0; j--)     ;steps[1] = -400\n+\t for (k = 0; k < 100; k++)   ;steps[0] = 4\n+\t   arr[i][j - 1][k] = 0;     ;base = &arr, size = 4000000.  */\n+\n+static bool\n+compute_access_range (loop_p loop_nest, data_reference_p dr, tree *base,\n+\t\t      tree *size, vec<tree> *steps = NULL)\n+{\n+  location_t loc = gimple_location (DR_STMT (dr));\n+  basic_block bb = gimple_bb (DR_STMT (dr));\n+  struct loop *loop = bb->loop_father;\n+  tree ref = DR_REF (dr);\n+  tree access_base = build_fold_addr_expr (ref);\n+  tree access_size = TYPE_SIZE_UNIT (TREE_TYPE (ref));\n+\n+  do {\n+      tree scev_fn = analyze_scalar_evolution (loop, access_base);\n+      if (TREE_CODE (scev_fn) != POLYNOMIAL_CHREC)\n+\treturn false;\n+\n+      access_base = CHREC_LEFT (scev_fn);\n+      if (tree_contains_chrecs (access_base, NULL))\n+\treturn false;\n+\n+      tree scev_step = CHREC_RIGHT (scev_fn);\n+      /* Only support constant steps.  */\n+      if (TREE_CODE (scev_step) != INTEGER_CST)\n+\treturn false;\n+\n+      enum ev_direction access_dir = scev_direction (scev_fn);\n+      if (access_dir == EV_DIR_UNKNOWN)\n+\treturn false;\n+\n+      if (steps != NULL)\n+\tsteps->safe_push (scev_step);\n+\n+      scev_step = fold_convert_loc (loc, sizetype, scev_step);\n+      /* Compute absolute value of scev step.  */\n+      if (access_dir == EV_DIR_DECREASES)\n+\tscev_step = fold_build1_loc (loc, NEGATE_EXPR, sizetype, scev_step);\n+\n+      /* At each level of loop, scev step must equal to access size.  In other\n+\t words, DR must access consecutive memory between loop iterations.  */\n+      if (!operand_equal_p (scev_step, access_size, 0))\n+\treturn false;\n+\n+      /* Compute DR's execution times in loop.  */\n+      tree niters = number_of_latch_executions (loop);\n+      niters = fold_convert_loc (loc, sizetype, niters);\n+      if (dominated_by_p (CDI_DOMINATORS, single_exit (loop)->src, bb))\n+\tniters = size_binop_loc (loc, PLUS_EXPR, niters, size_one_node);\n+\n+      /* Compute DR's overall access size in loop.  */\n+      access_size = fold_build2_loc (loc, MULT_EXPR, sizetype,\n+\t\t\t\t     niters, scev_step);\n+      /* Adjust base address in case of negative step.  */\n+      if (access_dir == EV_DIR_DECREASES)\n \t{\n-\t  bb = gimple_bb (DR_STMT (single_load));\n-\t  if (bb->loop_father != loop)\n-\t    return;\n+\t  tree adj = fold_build2_loc (loc, MINUS_EXPR, sizetype,\n+\t\t\t\t      scev_step, access_size);\n+\t  access_base = fold_build_pointer_plus_loc (loc, access_base, adj);\n \t}\n+  } while (loop != loop_nest && (loop = loop_outer (loop)) != NULL);\n+\n+  *base = access_base;\n+  *size = access_size;\n+  return true;\n+}\n+\n+/* Allocate and return builtin struct.  Record information like DST_DR,\n+   SRC_DR, DST_BASE, SRC_BASE and SIZE in the allocated struct.  */\n+\n+static struct builtin_info *\n+alloc_builtin (data_reference_p dst_dr, data_reference_p src_dr,\n+\t       tree dst_base, tree src_base, tree size)\n+{\n+  struct builtin_info *builtin = XNEW (struct builtin_info);\n+  builtin->dst_dr = dst_dr;\n+  builtin->src_dr = src_dr;\n+  builtin->dst_base = dst_base;\n+  builtin->src_base = src_base;\n+  builtin->size = size;\n+  return builtin;\n+}\n+\n+/* Given data reference DR in loop nest LOOP, classify if it forms builtin\n+   memset call.  */\n+\n+static void\n+classify_builtin_st (loop_p loop, partition *partition, data_reference_p dr)\n+{\n+  gimple *stmt = DR_STMT (dr);\n+  tree base, size, rhs = gimple_assign_rhs1 (stmt);\n+\n+  if (const_with_all_bytes_same (rhs) == -1\n+      && (!INTEGRAL_TYPE_P (TREE_TYPE (rhs))\n+\t  || (TYPE_MODE (TREE_TYPE (rhs))\n+\t      != TYPE_MODE (unsigned_char_type_node))))\n+    return;\n+\n+  if (TREE_CODE (rhs) == SSA_NAME\n+      && !SSA_NAME_IS_DEFAULT_DEF (rhs)\n+      && flow_bb_inside_loop_p (loop, gimple_bb (SSA_NAME_DEF_STMT (rhs))))\n+    return;\n+\n+  if (!compute_access_range (loop, dr, &base, &size))\n+    return;\n+\n+  partition->builtin = alloc_builtin (dr, NULL, base, NULL_TREE, size);\n+  partition->kind = PKIND_MEMSET;\n+}\n+\n+/* Given data references DST_DR and SRC_DR in loop nest LOOP and RDG, classify\n+   if it forms builtin memcpy or memmove call.  */\n+\n+static void\n+classify_builtin_ldst (loop_p loop, struct graph *rdg, partition *partition,\n+\t\t       data_reference_p dst_dr, data_reference_p src_dr)\n+{\n+  tree base, size, src_base, src_size;\n+  auto_vec<tree> dst_steps, src_steps;\n+\n+  /* Compute access range of both load and store.  They much have the same\n+     access size.  */\n+  if (!compute_access_range (loop, dst_dr, &base, &size, &dst_steps)\n+      || !compute_access_range (loop, src_dr, &src_base, &src_size, &src_steps)\n+      || !operand_equal_p (size, src_size, 0))\n+    return;\n+\n+  /* Load and store in loop nest must access memory in the same way, i.e,\n+     their must have the same steps in each loop of the nest.  */\n+  if (dst_steps.length () != src_steps.length ())\n+    return;\n+  for (unsigned i = 0; i < dst_steps.length (); ++i)\n+    if (!operand_equal_p (dst_steps[i], src_steps[i], 0))\n+      return;\n+\n+  /* Now check that if there is a dependence.  */\n+  ddr_p ddr = get_data_dependence (rdg, src_dr, dst_dr);\n+\n+  /* Classify as memcpy if no dependence between load and store.  */\n+  if (DDR_ARE_DEPENDENT (ddr) == chrec_known)\n+    {\n+      partition->builtin = alloc_builtin (dst_dr, src_dr, base, src_base, size);\n+      partition->kind = PKIND_MEMCPY;\n+      return;\n     }\n \n-  nb_iter = number_of_latch_executions (loop);\n-  gcc_assert (nb_iter && nb_iter != chrec_dont_know);\n-  if (dominated_by_p (CDI_DOMINATORS, single_exit (loop)->src,\n-\t\t      gimple_bb (DR_STMT (single_store))))\n-    plus_one = true;\n+  /* Can't do memmove in case of unknown dependence or dependence without\n+     classical distance vector.  */\n+  if (DDR_ARE_DEPENDENT (ddr) == chrec_dont_know\n+      || DDR_NUM_DIST_VECTS (ddr) == 0)\n+    return;\n \n-  if (single_store && !single_load)\n+  unsigned i;\n+  lambda_vector dist_v;\n+  int num_lev = (DDR_LOOP_NEST (ddr)).length ();\n+  FOR_EACH_VEC_ELT (DDR_DIST_VECTS (ddr), i, dist_v)\n     {\n-      gimple *stmt = DR_STMT (single_store);\n-      tree rhs = gimple_assign_rhs1 (stmt);\n-      if (const_with_all_bytes_same (rhs) == -1\n-\t  && (!INTEGRAL_TYPE_P (TREE_TYPE (rhs))\n-\t      || (TYPE_MODE (TREE_TYPE (rhs))\n-\t\t  != TYPE_MODE (unsigned_char_type_node))))\n+      unsigned dep_lev = dependence_level (dist_v, num_lev);\n+      /* Can't do memmove if load depends on store.  */\n+      if (dep_lev > 0 && dist_v[dep_lev - 1] > 0 && !DDR_REVERSED_P (ddr))\n \treturn;\n-      if (TREE_CODE (rhs) == SSA_NAME\n-\t  && !SSA_NAME_IS_DEFAULT_DEF (rhs)\n-\t  && flow_bb_inside_loop_p (loop, gimple_bb (SSA_NAME_DEF_STMT (rhs))))\n-\treturn;\n-      if (!adjacent_dr_p (single_store)\n-\t  || !dominated_by_p (CDI_DOMINATORS,\n-\t\t\t      loop->latch, gimple_bb (stmt)))\n-\treturn;\n-      partition->kind = PKIND_MEMSET;\n-      partition->main_dr = single_store;\n-      partition->niter = nb_iter;\n-      partition->plus_one = plus_one;\n     }\n-  else if (single_store && single_load)\n+\n+  partition->builtin = alloc_builtin (dst_dr, src_dr, base, src_base, size);\n+  partition->kind = PKIND_MEMMOVE;\n+  return;\n+}\n+\n+/* Classifies the builtin kind we can generate for PARTITION of RDG and LOOP.\n+   For the moment we detect memset, memcpy and memmove patterns.  Bitmap\n+   STMT_IN_ALL_PARTITIONS contains statements belonging to all partitions.  */\n+\n+static void\n+classify_partition (loop_p loop, struct graph *rdg, partition *partition,\n+\t\t    bitmap stmt_in_all_partitions)\n+{\n+  bitmap_iterator bi;\n+  unsigned i;\n+  data_reference_p single_ld = NULL, single_st = NULL;\n+  bool volatiles_p = false, has_reduction = false;\n+\n+  EXECUTE_IF_SET_IN_BITMAP (partition->stmts, 0, i, bi)\n     {\n-      gimple *store = DR_STMT (single_store);\n-      gimple *load = DR_STMT (single_load);\n-      /* Direct aggregate copy or via an SSA name temporary.  */\n-      if (load != store\n-\t  && gimple_assign_lhs (load) != gimple_assign_rhs1 (store))\n-\treturn;\n-      if (!adjacent_dr_p (single_store)\n-\t  || !adjacent_dr_p (single_load)\n-\t  || !operand_equal_p (DR_STEP (single_store),\n-\t\t\t       DR_STEP (single_load), 0)\n-\t  || !dominated_by_p (CDI_DOMINATORS,\n-\t\t\t      loop->latch, gimple_bb (store)))\n-\treturn;\n-      /* Now check that if there is a dependence this dependence is\n-         of a suitable form for memmove.  */\n-      ddr_p ddr = get_data_dependence (rdg, single_load, single_store);\n-      if (DDR_ARE_DEPENDENT (ddr) == chrec_dont_know)\n-\treturn;\n+      gimple *stmt = RDG_STMT (rdg, i);\n \n-      if (DDR_ARE_DEPENDENT (ddr) != chrec_known)\n-\t{\n-\t  if (DDR_NUM_DIST_VECTS (ddr) == 0)\n-\t    return;\n+      if (gimple_has_volatile_ops (stmt))\n+\tvolatiles_p = true;\n \n-\t  lambda_vector dist_v;\n-\t  FOR_EACH_VEC_ELT (DDR_DIST_VECTS (ddr), i, dist_v)\n+      /* If the stmt is not included by all partitions and there is uses\n+\t outside of the loop, then mark the partition as reduction.  */\n+      if (stmt_has_scalar_dependences_outside_loop (loop, stmt))\n+\t{\n+\t  /* Due to limitation in the transform phase we have to fuse all\n+\t     reduction partitions.  As a result, this could cancel valid\n+\t     loop distribution especially for loop that induction variable\n+\t     is used outside of loop.  To workaround this issue, we skip\n+\t     marking partition as reudction if the reduction stmt belongs\n+\t     to all partitions.  In such case, reduction will be computed\n+\t     correctly no matter how partitions are fused/distributed.  */\n+\t  if (!bitmap_bit_p (stmt_in_all_partitions, i))\n \t    {\n-\t      int dist = dist_v[index_in_loop_nest (loop->num,\n-\t\t\t\t\t\t    DDR_LOOP_NEST (ddr))];\n-\t      if (dist > 0 && !DDR_REVERSED_P (ddr))\n-\t\treturn;\n+\t      partition->reduction_p = true;\n+\t      return;\n \t    }\n-\t  partition->kind = PKIND_MEMMOVE;\n+\t  has_reduction = true;\n \t}\n-      else\n-\tpartition->kind = PKIND_MEMCPY;\n-      partition->main_dr = single_store;\n-      partition->secondary_dr = single_load;\n-      partition->niter = nb_iter;\n-      partition->plus_one = plus_one;\n     }\n+\n+  /* Perform general partition disqualification for builtins.  */\n+  if (volatiles_p\n+      /* Simple workaround to prevent classifying the partition as builtin\n+\t if it contains any use outside of loop.  */\n+      || has_reduction\n+      || !flag_tree_loop_distribute_patterns)\n+    return;\n+\n+  /* Find single load/store data references for builtin partition.  */\n+  if (!find_single_drs (rdg, partition, &single_st, &single_ld))\n+    return;\n+\n+  /* Classify the builtin kind.  */\n+  if (single_ld == NULL)\n+    classify_builtin_st (loop, partition, single_st);\n+  else\n+    classify_builtin_ldst (loop, rdg, partition, single_st, single_ld);\n }\n \n /* Returns true when PARTITION1 and PARTITION2 access the same memory"}]}