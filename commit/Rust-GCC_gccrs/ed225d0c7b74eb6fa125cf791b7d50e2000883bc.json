{"sha": "ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZWQyMjVkMGM3Yjc0ZWI2ZmExMjVjZjc5MWI3ZDUwZTIwMDA4ODNiYw==", "commit": {"author": {"name": "Alan Lawrence", "email": "alan.lawrence@arm.com", "date": "2014-12-09T20:23:36Z"}, "committer": {"name": "Alan Lawrence", "email": "alalaw01@gcc.gnu.org", "date": "2014-12-09T20:23:36Z"}, "message": "[AArch64]Remove be_checked_get_lane, check bounds with __builtin_aarch64_im_lane_boundsi.\n\ngcc/:\n\n\tPR target/63870\n\t* config/aarch64/aarch64-simd-builtins.def (be_checked_get_lane):\n\tDelete.\n\t* config/aarch64/aarch64-simd.md (aarch64_be_checked_get_lane<mode\\>):\n\tDelete.\n\t* config/aarch64/arm_neon.h (aarch64_vget_lane_any): Use GCC\n\tvector extensions, __aarch64_lane, __builtin_aarch64_im_lane_boundsi.\n\t(__aarch64_vget_lane_f32, __aarch64_vget_lane_f64,\n\t__aarch64_vget_lane_p8, __aarch64_vget_lane_p16,\n\t__aarch64_vget_lane_s8, __aarch64_vget_lane_s16,\n\t__aarch64_vget_lane_s32, __aarch64_vget_lane_s64,\n\t__aarch64_vget_lane_u8, __aarch64_vget_lane_u16,\n\t__aarch64_vget_lane_u32, __aarch64_vget_lane_u64,\n\t__aarch64_vgetq_lane_f32, __aarch64_vgetq_lane_f64,\n\t__aarch64_vgetq_lane_p8, __aarch64_vgetq_lane_p16,\n\t__aarch64_vgetq_lane_s8, __aarch64_vgetq_lane_s16,\n\t__aarch64_vgetq_lane_s32, __aarch64_vgetq_lane_s64,\n\t__aarch64_vgetq_lane_u8, __aarch64_vgetq_lane_u16,\n\t__aarch64_vgetq_lane_u32, __aarch64_vgetq_lane_u64): Delete.\n\t(__aarch64_vdup_lane_any): Use __aarch64_vget_lane_any, remove\n\t'q2' argument.\n\t(__aarch64_vdup_lane_f32, __aarch64_vdup_lane_f64,\n\t__aarch64_vdup_lane_p8, __aarch64_vdup_lane_p16,\n\t__aarch64_vdup_lane_s8, __aarch64_vdup_lane_s16,\n\t__aarch64_vdup_lane_s32, __aarch64_vdup_lane_s64,\n\t__aarch64_vdup_lane_u8, __aarch64_vdup_lane_u16,\n\t__aarch64_vdup_lane_u32, __aarch64_vdup_lane_u64,\n\t__aarch64_vdup_laneq_f32, __aarch64_vdup_laneq_f64,\n\t__aarch64_vdup_laneq_p8, __aarch64_vdup_laneq_p16,\n\t__aarch64_vdup_laneq_s8, __aarch64_vdup_laneq_s16,\n\t__aarch64_vdup_laneq_s32, __aarch64_vdup_laneq_s64,\n\t__aarch64_vdup_laneq_u8, __aarch64_vdup_laneq_u16,\n\t__aarch64_vdup_laneq_u32, __aarch64_vdup_laneq_u64): Remove argument\n\tto __aarch64_vdup_lane_any.\n\t(vget_lane_f32, vget_lane_f64, vget_lane_p8, vget_lane_p16,\n\tvget_lane_s8, vget_lane_s16, vget_lane_s32, vget_lane_s64,\n\tvget_lane_u8, vget_lane_u16, vget_lane_u32, vget_lane_u64,\n\tvgetq_lane_f32, vgetq_lane_f64, vgetq_lane_p8, vgetq_lane_p16,\n\tvgetq_lane_s8, vgetq_lane_s16, vgetq_lane_s32, vgetq_lane_s64,\n\tvgetq_lane_u8, vgetq_lane_u16, vgetq_lane_u32, vgetq_lane_u64,\n\tvdupb_lane_p8, vdupb_lane_s8, vdupb_lane_u8, vduph_lane_p16,\n\tvduph_lane_s16, vduph_lane_u16, vdups_lane_f32, vdups_lane_s32,\n\tvdups_lane_u32, vdupb_laneq_p8, vdupb_laneq_s8, vdupb_laneq_u8,\n\tvduph_laneq_p16, vduph_laneq_s16, vduph_laneq_u16, vdups_laneq_f32,\n\tvdups_laneq_s32, vdups_laneq_u32, vdupd_laneq_f64, vdupd_laneq_s64,\n\tvdupd_laneq_u64, vfmas_lane_f32, vfma_laneq_f64, vfmad_laneq_f64,\n\tvfmas_laneq_f32, vfmss_lane_f32, vfms_laneq_f64, vfmsd_laneq_f64,\n\tvfmss_laneq_f32, vmla_lane_f32, vmla_lane_s16, vmla_lane_s32,\n\tvmla_lane_u16, vmla_lane_u32, vmla_laneq_f32, vmla_laneq_s16,\n\tvmla_laneq_s32, vmla_laneq_u16, vmla_laneq_u32, vmlaq_lane_f32,\n\tvmlaq_lane_s16, vmlaq_lane_s32, vmlaq_lane_u16, vmlaq_lane_u32,\n\tvmlaq_laneq_f32, vmlaq_laneq_s16, vmlaq_laneq_s32, vmlaq_laneq_u16,\n\tvmlaq_laneq_u32, vmls_lane_f32, vmls_lane_s16, vmls_lane_s32,\n\tvmls_lane_u16, vmls_lane_u32, vmls_laneq_f32, vmls_laneq_s16,\n\tvmls_laneq_s32, vmls_laneq_u16, vmls_laneq_u32, vmlsq_lane_f32,\n\tvmlsq_lane_s16, vmlsq_lane_s32, vmlsq_lane_u16, vmlsq_lane_u32,\n\tvmlsq_laneq_f32, vmlsq_laneq_s16, vmlsq_laneq_s32, vmlsq_laneq_u16,\n\tvmlsq_laneq_u32, vmul_lane_f32, vmul_lane_s16, vmul_lane_s32,\n\tvmul_lane_u16, vmul_lane_u32, vmuld_lane_f64, vmuld_laneq_f64,\n\tvmuls_lane_f32, vmuls_laneq_f32, vmul_laneq_f32, vmul_laneq_f64,\n\tvmul_laneq_s16, vmul_laneq_s32, vmul_laneq_u16, vmul_laneq_u32,\n\tvmulq_lane_f32, vmulq_lane_s16, vmulq_lane_s32, vmulq_lane_u16,\n\tvmulq_lane_u32, vmulq_laneq_f32, vmulq_laneq_f64, vmulq_laneq_s16,\n\tvmulq_laneq_s32, vmulq_laneq_u16, vmulq_laneq_u32) : Use\n\t__aarch64_vget_lane_any.\n\ngcc/testsuite/:\n\n\t* gcc.target/aarch64/simd/vget_lane_f32_indices_1.c: New test.\n\t* gcc.target/aarch64/simd/vget_lane_f64_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_p16_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_p8_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_s16_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_s32_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_s64_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_s8_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_u16_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_u32_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_u64_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vget_lane_u8_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_f32_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_f64_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_p16_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_p8_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_s16_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_s32_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_s64_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_s8_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_u16_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_u32_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_u64_indices_1.c: Likewise.\n\t* gcc.target/aarch64/simd/vgetq_lane_u8_indices_1.c: Likewise.\n\nFrom-SVN: r218536", "tree": {"sha": "e0a9bed07673fdb9c44244b194dc83235216209a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e0a9bed07673fdb9c44244b194dc83235216209a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/comments", "author": null, "committer": null, "parents": [{"sha": "fdead6a4b4a8e3efe04c9546f2619e3426d2fb51", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdead6a4b4a8e3efe04c9546f2619e3426d2fb51", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fdead6a4b4a8e3efe04c9546f2619e3426d2fb51"}], "stats": {"total": 965, "additions": 682, "deletions": 283}, "files": [{"sha": "6612cbbdc9d52306d6796bf3ac582a40425e409a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 68, "deletions": 0, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -1,3 +1,71 @@\n+2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\tPR target/63870\n+\t* config/aarch64/aarch64-simd-builtins.def (be_checked_get_lane):\n+\tDelete.\n+\t* config/aarch64/aarch64-simd.md (aarch64_be_checked_get_lane<mode\\>):\n+\tDelete.\n+\t* config/aarch64/arm_neon.h (aarch64_vget_lane_any): Use GCC\n+\tvector extensions, __aarch64_lane, __builtin_aarch64_im_lane_boundsi.\n+\t(__aarch64_vget_lane_f32, __aarch64_vget_lane_f64,\n+\t__aarch64_vget_lane_p8, __aarch64_vget_lane_p16,\n+\t__aarch64_vget_lane_s8, __aarch64_vget_lane_s16,\n+\t__aarch64_vget_lane_s32, __aarch64_vget_lane_s64,\n+\t__aarch64_vget_lane_u8, __aarch64_vget_lane_u16,\n+\t__aarch64_vget_lane_u32, __aarch64_vget_lane_u64,\n+\t__aarch64_vgetq_lane_f32, __aarch64_vgetq_lane_f64,\n+\t__aarch64_vgetq_lane_p8, __aarch64_vgetq_lane_p16,\n+\t__aarch64_vgetq_lane_s8, __aarch64_vgetq_lane_s16,\n+\t__aarch64_vgetq_lane_s32, __aarch64_vgetq_lane_s64,\n+\t__aarch64_vgetq_lane_u8, __aarch64_vgetq_lane_u16,\n+\t__aarch64_vgetq_lane_u32, __aarch64_vgetq_lane_u64): Delete.\n+\t(__aarch64_vdup_lane_any): Use __aarch64_vget_lane_any, remove\n+\t'q2' argument.\n+\t(__aarch64_vdup_lane_f32, __aarch64_vdup_lane_f64,\n+\t__aarch64_vdup_lane_p8, __aarch64_vdup_lane_p16,\n+\t__aarch64_vdup_lane_s8, __aarch64_vdup_lane_s16,\n+\t__aarch64_vdup_lane_s32, __aarch64_vdup_lane_s64,\n+\t__aarch64_vdup_lane_u8, __aarch64_vdup_lane_u16,\n+\t__aarch64_vdup_lane_u32, __aarch64_vdup_lane_u64,\n+\t__aarch64_vdup_laneq_f32, __aarch64_vdup_laneq_f64,\n+\t__aarch64_vdup_laneq_p8, __aarch64_vdup_laneq_p16,\n+\t__aarch64_vdup_laneq_s8, __aarch64_vdup_laneq_s16,\n+\t__aarch64_vdup_laneq_s32, __aarch64_vdup_laneq_s64,\n+\t__aarch64_vdup_laneq_u8, __aarch64_vdup_laneq_u16,\n+\t__aarch64_vdup_laneq_u32, __aarch64_vdup_laneq_u64): Remove argument\n+\tto __aarch64_vdup_lane_any.\n+\t(vget_lane_f32, vget_lane_f64, vget_lane_p8, vget_lane_p16,\n+\tvget_lane_s8, vget_lane_s16, vget_lane_s32, vget_lane_s64,\n+\tvget_lane_u8, vget_lane_u16, vget_lane_u32, vget_lane_u64,\n+\tvgetq_lane_f32, vgetq_lane_f64, vgetq_lane_p8, vgetq_lane_p16,\n+\tvgetq_lane_s8, vgetq_lane_s16, vgetq_lane_s32, vgetq_lane_s64,\n+\tvgetq_lane_u8, vgetq_lane_u16, vgetq_lane_u32, vgetq_lane_u64,\n+\tvdupb_lane_p8, vdupb_lane_s8, vdupb_lane_u8, vduph_lane_p16,\n+\tvduph_lane_s16, vduph_lane_u16, vdups_lane_f32, vdups_lane_s32,\n+\tvdups_lane_u32, vdupb_laneq_p8, vdupb_laneq_s8, vdupb_laneq_u8,\n+\tvduph_laneq_p16, vduph_laneq_s16, vduph_laneq_u16, vdups_laneq_f32,\n+\tvdups_laneq_s32, vdups_laneq_u32, vdupd_laneq_f64, vdupd_laneq_s64,\n+\tvdupd_laneq_u64, vfmas_lane_f32, vfma_laneq_f64, vfmad_laneq_f64,\n+\tvfmas_laneq_f32, vfmss_lane_f32, vfms_laneq_f64, vfmsd_laneq_f64,\n+\tvfmss_laneq_f32, vmla_lane_f32, vmla_lane_s16, vmla_lane_s32,\n+\tvmla_lane_u16, vmla_lane_u32, vmla_laneq_f32, vmla_laneq_s16,\n+\tvmla_laneq_s32, vmla_laneq_u16, vmla_laneq_u32, vmlaq_lane_f32,\n+\tvmlaq_lane_s16, vmlaq_lane_s32, vmlaq_lane_u16, vmlaq_lane_u32,\n+\tvmlaq_laneq_f32, vmlaq_laneq_s16, vmlaq_laneq_s32, vmlaq_laneq_u16,\n+\tvmlaq_laneq_u32, vmls_lane_f32, vmls_lane_s16, vmls_lane_s32,\n+\tvmls_lane_u16, vmls_lane_u32, vmls_laneq_f32, vmls_laneq_s16,\n+\tvmls_laneq_s32, vmls_laneq_u16, vmls_laneq_u32, vmlsq_lane_f32,\n+\tvmlsq_lane_s16, vmlsq_lane_s32, vmlsq_lane_u16, vmlsq_lane_u32,\n+\tvmlsq_laneq_f32, vmlsq_laneq_s16, vmlsq_laneq_s32, vmlsq_laneq_u16,\n+\tvmlsq_laneq_u32, vmul_lane_f32, vmul_lane_s16, vmul_lane_s32,\n+\tvmul_lane_u16, vmul_lane_u32, vmuld_lane_f64, vmuld_laneq_f64,\n+\tvmuls_lane_f32, vmuls_laneq_f32, vmul_laneq_f32, vmul_laneq_f64,\n+\tvmul_laneq_s16, vmul_laneq_s32, vmul_laneq_u16, vmul_laneq_u32,\n+\tvmulq_lane_f32, vmulq_lane_s16, vmulq_lane_s32, vmulq_lane_u16,\n+\tvmulq_lane_u32, vmulq_laneq_f32, vmulq_laneq_f64, vmulq_laneq_s16,\n+\tvmulq_laneq_s32, vmulq_laneq_u16, vmulq_laneq_u32) : Use\n+\t__aarch64_vget_lane_any.\n+\n 2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n \n \tPR target/63870"}, {"sha": "16fdb5a59e0b06fd2ecdbd02acf8291cc3ec32fa", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -49,9 +49,6 @@\n   BUILTIN_VS (UNOP, ctz, 2)\n   BUILTIN_VB (UNOP, popcount, 2)\n \n-  /* be_checked_get_lane does its own lane swapping, so not a lane index.  */\n-  BUILTIN_VALL (GETREG, be_checked_get_lane, 0)\n-\n   /* Implemented by aarch64_<sur>q<r>shl<mode>.  */\n   BUILTIN_VSDQ_I (BINOP, sqshl, 0)\n   BUILTIN_VSDQ_I (BINOP_UUS, uqshl, 0)"}, {"sha": "78c9df0d27ca909d0b1b4d6c0d97961780dce9b9", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 1, "deletions": 14, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -2438,22 +2438,9 @@\n   [(set_attr \"type\" \"neon_to_gp<q>\")]\n )\n \n-(define_expand \"aarch64_be_checked_get_lane<mode>\"\n-  [(match_operand:<VEL> 0 \"aarch64_simd_nonimmediate_operand\")\n-   (match_operand:VALL 1 \"register_operand\")\n-   (match_operand:SI 2 \"immediate_operand\")]\n-  \"TARGET_SIMD\"\n-  {\n-    operands[2] = GEN_INT (ENDIAN_LANE_N (<MODE>mode, INTVAL (operands[2])));\n-    emit_insn (gen_aarch64_get_lane<mode> (operands[0],\n-\t\t\t\t\t   operands[1],\n-\t\t\t\t\t   operands[2]));\n-    DONE;\n-  }\n-)\n-\n ;; Lane extraction of a value, neither sign nor zero extension\n ;; is guaranteed so upper bits should be considered undefined.\n+;; RTL uses GCC vector extension indices throughout so flip only for assembly.\n (define_insn \"aarch64_get_lane<mode>\"\n   [(set (match_operand:<VEL> 0 \"aarch64_simd_nonimmediate_operand\" \"=r, w, Utv\")\n \t(vec_select:<VEL>"}, {"sha": "319cd8c1a0a441831a037e9c063badce7565f97c", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 177, "deletions": 266, "changes": 443, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -426,183 +426,112 @@ typedef struct poly16x8x4_t\n   poly16x8_t val[4];\n } poly16x8x4_t;\n \n-/* vget_lane internal macros.  */\n-\n-#define __aarch64_vget_lane_any(__size, __cast_ret, __cast_a, __a, __b) \\\n-  (__cast_ret\t\t\t\t\t\t\t\t\\\n-     __builtin_aarch64_be_checked_get_lane##__size (__cast_a __a, __b))\n-\n-#define __aarch64_vget_lane_f32(__a, __b) \\\n-  __aarch64_vget_lane_any (v2sf, , , __a, __b)\n-#define __aarch64_vget_lane_f64(__a, __b) __extension__\t\\\n-  ({\t\t\t\t\t\t\t\\\n-    __AARCH64_LANE_CHECK (__a, __b);\t\t\\\n-    __a[0];\t\t\t\t\t\t\\\n-  })\n-\n-#define __aarch64_vget_lane_p8(__a, __b) \\\n-  __aarch64_vget_lane_any (v8qi, (poly8_t), (int8x8_t), __a, __b)\n-#define __aarch64_vget_lane_p16(__a, __b) \\\n-  __aarch64_vget_lane_any (v4hi, (poly16_t), (int16x4_t), __a, __b)\n-\n-#define __aarch64_vget_lane_s8(__a, __b) \\\n-  __aarch64_vget_lane_any (v8qi, , ,__a, __b)\n-#define __aarch64_vget_lane_s16(__a, __b) \\\n-  __aarch64_vget_lane_any (v4hi, , ,__a, __b)\n-#define __aarch64_vget_lane_s32(__a, __b) \\\n-  __aarch64_vget_lane_any (v2si, , ,__a, __b)\n-#define __aarch64_vget_lane_s64(__a, __b) __extension__\t\\\n-  ({\t\t\t\t\t\t\t\\\n-    __AARCH64_LANE_CHECK (__a, __b);\t\t\\\n-    __a[0];\t\t\t\t\t\t\\\n-  })\n-\n-#define __aarch64_vget_lane_u8(__a, __b) \\\n-  __aarch64_vget_lane_any (v8qi, (uint8_t), (int8x8_t), __a, __b)\n-#define __aarch64_vget_lane_u16(__a, __b) \\\n-  __aarch64_vget_lane_any (v4hi, (uint16_t), (int16x4_t), __a, __b)\n-#define __aarch64_vget_lane_u32(__a, __b) \\\n-  __aarch64_vget_lane_any (v2si, (uint32_t), (int32x2_t), __a, __b)\n-#define __aarch64_vget_lane_u64(__a, __b) __extension__\t\\\n-  ({\t\t\t\t\t\t\t\\\n-    __AARCH64_LANE_CHECK (__a, __b);\t\t\\\n-    __a[0];\t\t\t\t\t\t\\\n-  })\n-\n-#define __aarch64_vgetq_lane_f32(__a, __b) \\\n-  __aarch64_vget_lane_any (v4sf, , , __a, __b)\n-#define __aarch64_vgetq_lane_f64(__a, __b) \\\n-  __aarch64_vget_lane_any (v2df, , , __a, __b)\n-\n-#define __aarch64_vgetq_lane_p8(__a, __b) \\\n-  __aarch64_vget_lane_any (v16qi, (poly8_t), (int8x16_t), __a, __b)\n-#define __aarch64_vgetq_lane_p16(__a, __b) \\\n-  __aarch64_vget_lane_any (v8hi, (poly16_t), (int16x8_t), __a, __b)\n-\n-#define __aarch64_vgetq_lane_s8(__a, __b) \\\n-  __aarch64_vget_lane_any (v16qi, , ,__a, __b)\n-#define __aarch64_vgetq_lane_s16(__a, __b) \\\n-  __aarch64_vget_lane_any (v8hi, , ,__a, __b)\n-#define __aarch64_vgetq_lane_s32(__a, __b) \\\n-  __aarch64_vget_lane_any (v4si, , ,__a, __b)\n-#define __aarch64_vgetq_lane_s64(__a, __b) \\\n-  __aarch64_vget_lane_any (v2di, , ,__a, __b)\n-\n-#define __aarch64_vgetq_lane_u8(__a, __b) \\\n-  __aarch64_vget_lane_any (v16qi, (uint8_t), (int8x16_t), __a, __b)\n-#define __aarch64_vgetq_lane_u16(__a, __b) \\\n-  __aarch64_vget_lane_any (v8hi, (uint16_t), (int16x8_t), __a, __b)\n-#define __aarch64_vgetq_lane_u32(__a, __b) \\\n-  __aarch64_vget_lane_any (v4si, (uint32_t), (int32x4_t), __a, __b)\n-#define __aarch64_vgetq_lane_u64(__a, __b) \\\n-  __aarch64_vget_lane_any (v2di, (uint64_t), (int64x2_t), __a, __b)\n-\n /* __aarch64_vdup_lane internal macros.  */\n-#define __aarch64_vdup_lane_any(__size, __q1, __q2, __a, __b) \\\n-  vdup##__q1##_n_##__size (__aarch64_vget##__q2##_lane_##__size (__a, __b))\n+#define __aarch64_vdup_lane_any(__size, __q, __a, __b) \\\n+  vdup##__q##_n_##__size (__aarch64_vget_lane_any (__a, __b))\n \n #define __aarch64_vdup_lane_f32(__a, __b) \\\n-   __aarch64_vdup_lane_any (f32, , , __a, __b)\n+   __aarch64_vdup_lane_any (f32, , __a, __b)\n #define __aarch64_vdup_lane_f64(__a, __b) \\\n-   __aarch64_vdup_lane_any (f64, , , __a, __b)\n+   __aarch64_vdup_lane_any (f64, , __a, __b)\n #define __aarch64_vdup_lane_p8(__a, __b) \\\n-   __aarch64_vdup_lane_any (p8, , , __a, __b)\n+   __aarch64_vdup_lane_any (p8, , __a, __b)\n #define __aarch64_vdup_lane_p16(__a, __b) \\\n-   __aarch64_vdup_lane_any (p16, , , __a, __b)\n+   __aarch64_vdup_lane_any (p16, , __a, __b)\n #define __aarch64_vdup_lane_s8(__a, __b) \\\n-   __aarch64_vdup_lane_any (s8, , , __a, __b)\n+   __aarch64_vdup_lane_any (s8, , __a, __b)\n #define __aarch64_vdup_lane_s16(__a, __b) \\\n-   __aarch64_vdup_lane_any (s16, , , __a, __b)\n+   __aarch64_vdup_lane_any (s16, , __a, __b)\n #define __aarch64_vdup_lane_s32(__a, __b) \\\n-   __aarch64_vdup_lane_any (s32, , , __a, __b)\n+   __aarch64_vdup_lane_any (s32, , __a, __b)\n #define __aarch64_vdup_lane_s64(__a, __b) \\\n-  __aarch64_vdup_lane_any (s64, , , __a, __b)\n+  __aarch64_vdup_lane_any (s64, , __a, __b)\n #define __aarch64_vdup_lane_u8(__a, __b) \\\n-   __aarch64_vdup_lane_any (u8, , , __a, __b)\n+   __aarch64_vdup_lane_any (u8, , __a, __b)\n #define __aarch64_vdup_lane_u16(__a, __b) \\\n-   __aarch64_vdup_lane_any (u16, , , __a, __b)\n+   __aarch64_vdup_lane_any (u16, , __a, __b)\n #define __aarch64_vdup_lane_u32(__a, __b) \\\n-   __aarch64_vdup_lane_any (u32, , , __a, __b)\n+   __aarch64_vdup_lane_any (u32, , __a, __b)\n #define __aarch64_vdup_lane_u64(__a, __b) \\\n-   __aarch64_vdup_lane_any (u64, , , __a, __b)\n+   __aarch64_vdup_lane_any (u64, , __a, __b)\n \n /* __aarch64_vdup_laneq internal macros.  */\n #define __aarch64_vdup_laneq_f32(__a, __b) \\\n-   __aarch64_vdup_lane_any (f32, , q, __a, __b)\n+   __aarch64_vdup_lane_any (f32, , __a, __b)\n #define __aarch64_vdup_laneq_f64(__a, __b) \\\n-   __aarch64_vdup_lane_any (f64, , q, __a, __b)\n+   __aarch64_vdup_lane_any (f64, , __a, __b)\n #define __aarch64_vdup_laneq_p8(__a, __b) \\\n-   __aarch64_vdup_lane_any (p8, , q, __a, __b)\n+   __aarch64_vdup_lane_any (p8, , __a, __b)\n #define __aarch64_vdup_laneq_p16(__a, __b) \\\n-   __aarch64_vdup_lane_any (p16, , q, __a, __b)\n+   __aarch64_vdup_lane_any (p16, , __a, __b)\n #define __aarch64_vdup_laneq_s8(__a, __b) \\\n-   __aarch64_vdup_lane_any (s8, , q, __a, __b)\n+   __aarch64_vdup_lane_any (s8, , __a, __b)\n #define __aarch64_vdup_laneq_s16(__a, __b) \\\n-   __aarch64_vdup_lane_any (s16, , q, __a, __b)\n+   __aarch64_vdup_lane_any (s16, , __a, __b)\n #define __aarch64_vdup_laneq_s32(__a, __b) \\\n-   __aarch64_vdup_lane_any (s32, , q, __a, __b)\n+   __aarch64_vdup_lane_any (s32, , __a, __b)\n #define __aarch64_vdup_laneq_s64(__a, __b) \\\n-   __aarch64_vdup_lane_any (s64, , q, __a, __b)\n+   __aarch64_vdup_lane_any (s64, , __a, __b)\n #define __aarch64_vdup_laneq_u8(__a, __b) \\\n-   __aarch64_vdup_lane_any (u8, , q, __a, __b)\n+   __aarch64_vdup_lane_any (u8, , __a, __b)\n #define __aarch64_vdup_laneq_u16(__a, __b) \\\n-   __aarch64_vdup_lane_any (u16, , q, __a, __b)\n+   __aarch64_vdup_lane_any (u16, , __a, __b)\n #define __aarch64_vdup_laneq_u32(__a, __b) \\\n-   __aarch64_vdup_lane_any (u32, , q, __a, __b)\n+   __aarch64_vdup_lane_any (u32, , __a, __b)\n #define __aarch64_vdup_laneq_u64(__a, __b) \\\n-   __aarch64_vdup_lane_any (u64, , q, __a, __b)\n+   __aarch64_vdup_lane_any (u64, , __a, __b)\n \n /* __aarch64_vdupq_lane internal macros.  */\n #define __aarch64_vdupq_lane_f32(__a, __b) \\\n-   __aarch64_vdup_lane_any (f32, q, , __a, __b)\n+   __aarch64_vdup_lane_any (f32, q, __a, __b)\n #define __aarch64_vdupq_lane_f64(__a, __b) \\\n-   __aarch64_vdup_lane_any (f64, q, , __a, __b)\n+   __aarch64_vdup_lane_any (f64, q, __a, __b)\n #define __aarch64_vdupq_lane_p8(__a, __b) \\\n-   __aarch64_vdup_lane_any (p8, q, , __a, __b)\n+   __aarch64_vdup_lane_any (p8, q, __a, __b)\n #define __aarch64_vdupq_lane_p16(__a, __b) \\\n-   __aarch64_vdup_lane_any (p16, q, , __a, __b)\n+   __aarch64_vdup_lane_any (p16, q, __a, __b)\n #define __aarch64_vdupq_lane_s8(__a, __b) \\\n-   __aarch64_vdup_lane_any (s8, q, , __a, __b)\n+   __aarch64_vdup_lane_any (s8, q, __a, __b)\n #define __aarch64_vdupq_lane_s16(__a, __b) \\\n-   __aarch64_vdup_lane_any (s16, q, , __a, __b)\n+   __aarch64_vdup_lane_any (s16, q, __a, __b)\n #define __aarch64_vdupq_lane_s32(__a, __b) \\\n-   __aarch64_vdup_lane_any (s32, q, , __a, __b)\n+   __aarch64_vdup_lane_any (s32, q, __a, __b)\n #define __aarch64_vdupq_lane_s64(__a, __b) \\\n-   __aarch64_vdup_lane_any (s64, q, , __a, __b)\n+   __aarch64_vdup_lane_any (s64, q, __a, __b)\n #define __aarch64_vdupq_lane_u8(__a, __b) \\\n-   __aarch64_vdup_lane_any (u8, q, , __a, __b)\n+   __aarch64_vdup_lane_any (u8, q, __a, __b)\n #define __aarch64_vdupq_lane_u16(__a, __b) \\\n-   __aarch64_vdup_lane_any (u16, q, , __a, __b)\n+   __aarch64_vdup_lane_any (u16, q, __a, __b)\n #define __aarch64_vdupq_lane_u32(__a, __b) \\\n-   __aarch64_vdup_lane_any (u32, q, , __a, __b)\n+   __aarch64_vdup_lane_any (u32, q, __a, __b)\n #define __aarch64_vdupq_lane_u64(__a, __b) \\\n-   __aarch64_vdup_lane_any (u64, q, , __a, __b)\n+   __aarch64_vdup_lane_any (u64, q, __a, __b)\n \n /* __aarch64_vdupq_laneq internal macros.  */\n #define __aarch64_vdupq_laneq_f32(__a, __b) \\\n-   __aarch64_vdup_lane_any (f32, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (f32, q, __a, __b)\n #define __aarch64_vdupq_laneq_f64(__a, __b) \\\n-   __aarch64_vdup_lane_any (f64, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (f64, q, __a, __b)\n #define __aarch64_vdupq_laneq_p8(__a, __b) \\\n-   __aarch64_vdup_lane_any (p8, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (p8, q, __a, __b)\n #define __aarch64_vdupq_laneq_p16(__a, __b) \\\n-   __aarch64_vdup_lane_any (p16, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (p16, q, __a, __b)\n #define __aarch64_vdupq_laneq_s8(__a, __b) \\\n-   __aarch64_vdup_lane_any (s8, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (s8, q, __a, __b)\n #define __aarch64_vdupq_laneq_s16(__a, __b) \\\n-   __aarch64_vdup_lane_any (s16, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (s16, q, __a, __b)\n #define __aarch64_vdupq_laneq_s32(__a, __b) \\\n-   __aarch64_vdup_lane_any (s32, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (s32, q, __a, __b)\n #define __aarch64_vdupq_laneq_s64(__a, __b) \\\n-   __aarch64_vdup_lane_any (s64, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (s64, q, __a, __b)\n #define __aarch64_vdupq_laneq_u8(__a, __b) \\\n-   __aarch64_vdup_lane_any (u8, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (u8, q, __a, __b)\n #define __aarch64_vdupq_laneq_u16(__a, __b) \\\n-   __aarch64_vdup_lane_any (u16, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (u16, q, __a, __b)\n #define __aarch64_vdupq_laneq_u32(__a, __b) \\\n-   __aarch64_vdup_lane_any (u32, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (u32, q, __a, __b)\n #define __aarch64_vdupq_laneq_u64(__a, __b) \\\n-   __aarch64_vdup_lane_any (u64, q, q, __a, __b)\n+   __aarch64_vdup_lane_any (u64, q, __a, __b)\n \n /* Internal macro for lane indices.  */\n \n@@ -618,8 +547,15 @@ typedef struct poly16x8x4_t\n #define __aarch64_lane(__vec, __idx) __idx\n #endif\n \n-/* vset_lane and vld1_lane internal macro.  */\n+/* vget_lane internal macro.  */\n+#define __aarch64_vget_lane_any(__vec, __index)\t\t\t\t\\\n+  __extension__\t\t\t\t\t\t\t\t\\\n+  ({\t\t\t\t\t\t\t\t\t\\\n+    __AARCH64_LANE_CHECK (__vec, __index);\t\t\t\t\\\n+    __vec[__aarch64_lane (__vec, __index)];\t\t\t\t\\\n+  })\n \n+/* vset_lane and vld1_lane internal macro.  */\n #define __aarch64_vset_lane_any(__elem, __vec, __index)\t\t\t\\\n   __extension__\t\t\t\t\t\t\t\t\\\n   ({\t\t\t\t\t\t\t\t\t\\\n@@ -2754,147 +2690,147 @@ vcreate_p16 (uint64_t __a)\n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vget_lane_f32 (float32x2_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_f32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vget_lane_f64 (float64x1_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_f64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n vget_lane_p8 (poly8x8_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_p8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n vget_lane_p16 (poly16x4_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_p16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int8_t __attribute__ ((__always_inline__))\n vget_lane_s8 (int8x8_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_s8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int16_t __attribute__ ((__always_inline__))\n vget_lane_s16 (int16x4_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_s16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int32_t __attribute__ ((__always_inline__))\n vget_lane_s32 (int32x2_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_s32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int64_t __attribute__ ((__always_inline__))\n vget_lane_s64 (int64x1_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_s64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint8_t __attribute__ ((__always_inline__))\n vget_lane_u8 (uint8x8_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_u8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint16_t __attribute__ ((__always_inline__))\n vget_lane_u16 (uint16x4_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_u16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint32_t __attribute__ ((__always_inline__))\n vget_lane_u32 (uint32x2_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_u32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint64_t __attribute__ ((__always_inline__))\n vget_lane_u64 (uint64x1_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_u64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vgetq_lane  */\n \n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vgetq_lane_f32 (float32x4_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_f32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vgetq_lane_f64 (float64x2_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_f64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n vgetq_lane_p8 (poly8x16_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_p8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n vgetq_lane_p16 (poly16x8_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_p16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int8_t __attribute__ ((__always_inline__))\n vgetq_lane_s8 (int8x16_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_s8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int16_t __attribute__ ((__always_inline__))\n vgetq_lane_s16 (int16x8_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_s16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int32_t __attribute__ ((__always_inline__))\n vgetq_lane_s32 (int32x4_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_s32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int64_t __attribute__ ((__always_inline__))\n vgetq_lane_s64 (int64x2_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_s64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint8_t __attribute__ ((__always_inline__))\n vgetq_lane_u8 (uint8x16_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint16_t __attribute__ ((__always_inline__))\n vgetq_lane_u16 (uint16x8_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint32_t __attribute__ ((__always_inline__))\n vgetq_lane_u32 (uint32x4_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint64_t __attribute__ ((__always_inline__))\n vgetq_lane_u64 (uint64x2_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vreinterpret  */\n@@ -14708,57 +14644,57 @@ vdupq_laneq_u64 (uint64x2_t __a, const int __b)\n __extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n vdupb_lane_p8 (poly8x8_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_p8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int8_t __attribute__ ((__always_inline__))\n vdupb_lane_s8 (int8x8_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_s8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint8_t __attribute__ ((__always_inline__))\n vdupb_lane_u8 (uint8x8_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_u8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vduph_lane  */\n __extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n vduph_lane_p16 (poly16x4_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_p16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int16_t __attribute__ ((__always_inline__))\n vduph_lane_s16 (int16x4_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_s16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint16_t __attribute__ ((__always_inline__))\n vduph_lane_u16 (uint16x4_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_u16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vdups_lane  */\n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vdups_lane_f32 (float32x2_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_f32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int32_t __attribute__ ((__always_inline__))\n vdups_lane_s32 (int32x2_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_s32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint32_t __attribute__ ((__always_inline__))\n vdups_lane_u32 (uint32x2_t __a, const int __b)\n {\n-  return __aarch64_vget_lane_u32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vdupd_lane  */\n@@ -14787,76 +14723,76 @@ vdupd_lane_u64 (uint64x1_t __a, const int __b)\n __extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n vdupb_laneq_p8 (poly8x16_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_p8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int8_t __attribute__ ((__always_inline__))\n vdupb_laneq_s8 (int8x16_t __a, const int __attribute__ ((unused)) __b)\n {\n-  return __aarch64_vgetq_lane_s8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint8_t __attribute__ ((__always_inline__))\n vdupb_laneq_u8 (uint8x16_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u8 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vduph_laneq  */\n __extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n vduph_laneq_p16 (poly16x8_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_p16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int16_t __attribute__ ((__always_inline__))\n vduph_laneq_s16 (int16x8_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_s16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint16_t __attribute__ ((__always_inline__))\n vduph_laneq_u16 (uint16x8_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u16 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vdups_laneq  */\n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vdups_laneq_f32 (float32x4_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_f32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int32_t __attribute__ ((__always_inline__))\n vdups_laneq_s32 (int32x4_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_s32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint32_t __attribute__ ((__always_inline__))\n vdups_laneq_u32 (uint32x4_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u32 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vdupd_laneq  */\n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vdupd_laneq_f64 (float64x2_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_f64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline int64_t __attribute__ ((__always_inline__))\n vdupd_laneq_s64 (int64x2_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_s64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n __extension__ static __inline uint64_t __attribute__ ((__always_inline__))\n vdupd_laneq_u64 (uint64x2_t __a, const int __b)\n {\n-  return __aarch64_vgetq_lane_u64 (__a, __b);\n+  return __aarch64_vget_lane_any (__a, __b);\n }\n \n /* vext  */\n@@ -15218,7 +15154,7 @@ __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vfmas_lane_f32 (float32_t __a, float32_t __b,\n \t        float32x2_t __c, const int __lane)\n {\n-  return __builtin_fmaf (__b, __aarch64_vget_lane_f32 (__c, __lane), __a);\n+  return __builtin_fmaf (__b, __aarch64_vget_lane_any (__c, __lane), __a);\n }\n \n /* vfma_laneq  */\n@@ -15236,22 +15172,22 @@ __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vfma_laneq_f64 (float64x1_t __a, float64x1_t __b,\n \t        float64x2_t __c, const int __lane)\n {\n-  float64_t __c0 = __aarch64_vgetq_lane_f64 (__c, __lane);\n+  float64_t __c0 = __aarch64_vget_lane_any (__c, __lane);\n   return (float64x1_t) {__builtin_fma (__b[0], __c0, __a[0])};\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vfmad_laneq_f64 (float64_t __a, float64_t __b,\n \t         float64x2_t __c, const int __lane)\n {\n-  return __builtin_fma (__b, __aarch64_vgetq_lane_f64 (__c, __lane), __a);\n+  return __builtin_fma (__b, __aarch64_vget_lane_any (__c, __lane), __a);\n }\n \n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vfmas_laneq_f32 (float32_t __a, float32_t __b,\n \t\t float32x4_t __c, const int __lane)\n {\n-  return __builtin_fmaf (__b, __aarch64_vgetq_lane_f32 (__c, __lane), __a);\n+  return __builtin_fmaf (__b, __aarch64_vget_lane_any (__c, __lane), __a);\n }\n \n /* vfmaq_lane  */\n@@ -15348,7 +15284,7 @@ __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vfmss_lane_f32 (float32_t __a, float32_t __b,\n \t        float32x2_t __c, const int __lane)\n {\n-  return __builtin_fmaf (-__b, __aarch64_vget_lane_f32 (__c, __lane), __a);\n+  return __builtin_fmaf (-__b, __aarch64_vget_lane_any (__c, __lane), __a);\n }\n \n /* vfms_laneq  */\n@@ -15366,22 +15302,22 @@ __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vfms_laneq_f64 (float64x1_t __a, float64x1_t __b,\n \t        float64x2_t __c, const int __lane)\n {\n-  float64_t __c0 = __aarch64_vgetq_lane_f64 (__c, __lane);\n+  float64_t __c0 = __aarch64_vget_lane_any (__c, __lane);\n   return (float64x1_t) {__builtin_fma (-__b[0], __c0, __a[0])};\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vfmsd_laneq_f64 (float64_t __a, float64_t __b,\n \t         float64x2_t __c, const int __lane)\n {\n-  return __builtin_fma (-__b, __aarch64_vgetq_lane_f64 (__c, __lane), __a);\n+  return __builtin_fma (-__b, __aarch64_vget_lane_any (__c, __lane), __a);\n }\n \n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vfmss_laneq_f32 (float32_t __a, float32_t __b,\n \t\t float32x4_t __c, const int __lane)\n {\n-  return __builtin_fmaf (-__b, __aarch64_vgetq_lane_f32 (__c, __lane), __a);\n+  return __builtin_fmaf (-__b, __aarch64_vget_lane_any (__c, __lane), __a);\n }\n \n /* vfmsq_lane  */\n@@ -18382,35 +18318,35 @@ __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmla_lane_f32 (float32x2_t __a, float32x2_t __b,\n \t       float32x2_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_f32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vmla_lane_s16 (int16x4_t __a, int16x4_t __b,\n \t\tint16x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_s16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vmla_lane_s32 (int32x2_t __a, int32x2_t __b,\n \t\tint32x2_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_s32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vmla_lane_u16 (uint16x4_t __a, uint16x4_t __b,\n \t\tuint16x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_u16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vmla_lane_u32 (uint32x2_t __a, uint32x2_t __b,\n \t       uint32x2_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_u32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n /* vmla_laneq  */\n@@ -18419,35 +18355,35 @@ __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmla_laneq_f32 (float32x2_t __a, float32x2_t __b,\n \t        float32x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_f32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vmla_laneq_s16 (int16x4_t __a, int16x4_t __b,\n \t\tint16x8_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_s16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vmla_laneq_s32 (int32x2_t __a, int32x2_t __b,\n \t\tint32x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_s32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vmla_laneq_u16 (uint16x4_t __a, uint16x4_t __b,\n \t\tuint16x8_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_u16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vmla_laneq_u32 (uint32x2_t __a, uint32x2_t __b,\n \t\tuint32x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_u32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n /* vmlaq_lane  */\n@@ -18456,35 +18392,35 @@ __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmlaq_lane_f32 (float32x4_t __a, float32x4_t __b,\n \t\tfloat32x2_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_f32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmlaq_lane_s16 (int16x8_t __a, int16x8_t __b,\n \t\tint16x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_s16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vmlaq_lane_s32 (int32x4_t __a, int32x4_t __b,\n \t\tint32x2_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_s32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vmlaq_lane_u16 (uint16x8_t __a, uint16x8_t __b,\n \t\tuint16x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_u16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vmlaq_lane_u32 (uint32x4_t __a, uint32x4_t __b,\n \t\tuint32x2_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vget_lane_u32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n   /* vmlaq_laneq  */\n@@ -18493,35 +18429,35 @@ __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmlaq_laneq_f32 (float32x4_t __a, float32x4_t __b,\n \t\t float32x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_f32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmlaq_laneq_s16 (int16x8_t __a, int16x8_t __b,\n \t\tint16x8_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_s16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vmlaq_laneq_s32 (int32x4_t __a, int32x4_t __b,\n \t\tint32x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_s32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vmlaq_laneq_u16 (uint16x8_t __a, uint16x8_t __b,\n \t\tuint16x8_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_u16 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vmlaq_laneq_u32 (uint32x4_t __a, uint32x4_t __b,\n \t\tuint32x4_t __c, const int __lane)\n {\n-  return (__a + (__b * __aarch64_vgetq_lane_u32 (__c, __lane)));\n+  return (__a + (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n /* vmls  */\n@@ -18556,35 +18492,35 @@ __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmls_lane_f32 (float32x2_t __a, float32x2_t __b,\n \t       float32x2_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_f32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vmls_lane_s16 (int16x4_t __a, int16x4_t __b,\n \t\tint16x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_s16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vmls_lane_s32 (int32x2_t __a, int32x2_t __b,\n \t\tint32x2_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_s32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vmls_lane_u16 (uint16x4_t __a, uint16x4_t __b,\n \t\tuint16x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_u16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vmls_lane_u32 (uint32x2_t __a, uint32x2_t __b,\n \t       uint32x2_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_u32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n /* vmls_laneq  */\n@@ -18593,35 +18529,35 @@ __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmls_laneq_f32 (float32x2_t __a, float32x2_t __b,\n \t       float32x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_f32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vmls_laneq_s16 (int16x4_t __a, int16x4_t __b,\n \t\tint16x8_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_s16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vmls_laneq_s32 (int32x2_t __a, int32x2_t __b,\n \t\tint32x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_s32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vmls_laneq_u16 (uint16x4_t __a, uint16x4_t __b,\n \t\tuint16x8_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_u16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vmls_laneq_u32 (uint32x2_t __a, uint32x2_t __b,\n \t\tuint32x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_u32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n /* vmlsq_lane  */\n@@ -18630,35 +18566,35 @@ __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmlsq_lane_f32 (float32x4_t __a, float32x4_t __b,\n \t\tfloat32x2_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_f32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmlsq_lane_s16 (int16x8_t __a, int16x8_t __b,\n \t\tint16x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_s16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vmlsq_lane_s32 (int32x4_t __a, int32x4_t __b,\n \t\tint32x2_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_s32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vmlsq_lane_u16 (uint16x8_t __a, uint16x8_t __b,\n \t\tuint16x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_u16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vmlsq_lane_u32 (uint32x4_t __a, uint32x4_t __b,\n \t\tuint32x2_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vget_lane_u32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n   /* vmlsq_laneq  */\n@@ -18667,34 +18603,34 @@ __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmlsq_laneq_f32 (float32x4_t __a, float32x4_t __b,\n \t\tfloat32x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_f32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmlsq_laneq_s16 (int16x8_t __a, int16x8_t __b,\n \t\tint16x8_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_s16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vmlsq_laneq_s32 (int32x4_t __a, int32x4_t __b,\n \t\tint32x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_s32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vmlsq_laneq_u16 (uint16x8_t __a, uint16x8_t __b,\n \t\tuint16x8_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_u16 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vmlsq_laneq_u32 (uint32x4_t __a, uint32x4_t __b,\n \t\tuint32x4_t __c, const int __lane)\n {\n-  return (__a - (__b * __aarch64_vgetq_lane_u32 (__c, __lane)));\n+  return (__a - (__b * __aarch64_vget_lane_any (__c, __lane)));\n }\n \n /* vmov_n_  */\n@@ -18848,7 +18784,7 @@ vmovq_n_u64 (uint64_t __a)\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmul_lane_f32 (float32x2_t __a, float32x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_f32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n@@ -18860,91 +18796,91 @@ vmul_lane_f64 (float64x1_t __a, float64x1_t __b, const int __lane)\n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vmul_lane_s16 (int16x4_t __a, int16x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_s16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vmul_lane_s32 (int32x2_t __a, int32x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_s32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vmul_lane_u16 (uint16x4_t __a, uint16x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_u16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vmul_lane_u32 (uint32x2_t __a, uint32x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_u32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n /* vmuld_lane  */\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vmuld_lane_f64 (float64_t __a, float64x1_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_f64 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vmuld_laneq_f64 (float64_t __a, float64x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_f64 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n /* vmuls_lane  */\n \n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vmuls_lane_f32 (float32_t __a, float32x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_f32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n vmuls_laneq_f32 (float32_t __a, float32x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_f32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n /* vmul_laneq  */\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmul_laneq_f32 (float32x2_t __a, float32x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_f32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vmul_laneq_f64 (float64x1_t __a, float64x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_f64 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vmul_laneq_s16 (int16x4_t __a, int16x8_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_s16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vmul_laneq_s32 (int32x2_t __a, int32x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_s32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vmul_laneq_u16 (uint16x4_t __a, uint16x8_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_u16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vmul_laneq_u32 (uint32x2_t __a, uint32x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_u32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n /* vmul_n  */\n@@ -18960,7 +18896,7 @@ vmul_n_f64  (float64x1_t __a, float64_t __b)\n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmulq_lane_f32 (float32x4_t __a, float32x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_f32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n@@ -18973,63 +18909,63 @@ vmulq_lane_f64 (float64x2_t __a, float64x1_t __b, const int __lane)\n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmulq_lane_s16 (int16x8_t __a, int16x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_s16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vmulq_lane_s32 (int32x4_t __a, int32x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_s32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vmulq_lane_u16 (uint16x8_t __a, uint16x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_u16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vmulq_lane_u32 (uint32x4_t __a, uint32x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vget_lane_u32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n /* vmulq_laneq  */\n \n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmulq_laneq_f32 (float32x4_t __a, float32x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_f32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n vmulq_laneq_f64 (float64x2_t __a, float64x2_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_f64 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmulq_laneq_s16 (int16x8_t __a, int16x8_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_s16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vmulq_laneq_s32 (int32x4_t __a, int32x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_s32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vmulq_laneq_u16 (uint16x8_t __a, uint16x8_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_u16 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vmulq_laneq_u32 (uint32x4_t __a, uint32x4_t __b, const int __lane)\n {\n-  return __a * __aarch64_vgetq_lane_u32 (__b, __lane);\n+  return __a * __aarch64_vget_lane_any (__b, __lane);\n }\n \n /* vneg  */\n@@ -25221,31 +25157,6 @@ __INTERLEAVE_LIST (zip)\n /* End of optimal implementations in approved order.  */\n \n #undef __aarch64_vget_lane_any\n-#undef __aarch64_vget_lane_f32\n-#undef __aarch64_vget_lane_f64\n-#undef __aarch64_vget_lane_p8\n-#undef __aarch64_vget_lane_p16\n-#undef __aarch64_vget_lane_s8\n-#undef __aarch64_vget_lane_s16\n-#undef __aarch64_vget_lane_s32\n-#undef __aarch64_vget_lane_s64\n-#undef __aarch64_vget_lane_u8\n-#undef __aarch64_vget_lane_u16\n-#undef __aarch64_vget_lane_u32\n-#undef __aarch64_vget_lane_u64\n-\n-#undef __aarch64_vgetq_lane_f32\n-#undef __aarch64_vgetq_lane_f64\n-#undef __aarch64_vgetq_lane_p8\n-#undef __aarch64_vgetq_lane_p16\n-#undef __aarch64_vgetq_lane_s8\n-#undef __aarch64_vgetq_lane_s16\n-#undef __aarch64_vgetq_lane_s32\n-#undef __aarch64_vgetq_lane_s64\n-#undef __aarch64_vgetq_lane_u8\n-#undef __aarch64_vgetq_lane_u16\n-#undef __aarch64_vgetq_lane_u32\n-#undef __aarch64_vgetq_lane_u64\n \n #undef __aarch64_vdup_lane_any\n #undef __aarch64_vdup_lane_f32"}, {"sha": "9d03fb8e852798337392ac4efcfe75f8739f66a3", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -1,3 +1,31 @@\n+2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\tPR target/63870\n+\t* gcc.target/aarch64/simd/vget_lane_f32_indices_1.c: New test.\n+\t* gcc.target/aarch64/simd/vget_lane_f64_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_p16_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_p8_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_s16_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_s32_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_s64_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_s8_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_u16_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_u32_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_u64_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vget_lane_u8_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_f32_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_f64_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_p16_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_p8_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_s16_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_s32_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_s64_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_s8_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_u16_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_u32_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_u64_indices_1.c: Likewise.\n+\t* gcc.target/aarch64/simd/vgetq_lane_u8_indices_1.c: Likewise.\n+\n 2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n \n \tPR target/63870"}, {"sha": "d16a3e882d5265f74083be0d6c83abc42f9d8b85", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_f32_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_f32_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_f32_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_f32_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+float32_t\n+test_vget_lane_f32_before (float32x2_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_f32 (in, -1);\n+}\n+\n+float32_t\n+test_vget_lane_f32_beyond (float32x2_t in)\n+{\n+  /* { dg-error \"lane 2 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_f32 (in, 2);\n+}"}, {"sha": "0e90429ae964d77495f87669db200c6f6bbbadb2", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_f64_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_f64_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_f64_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_f64_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+float64_t\n+test_vget_lane_f64_before (float64x1_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 0\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_f64 (in, -1);\n+}\n+\n+float64_t\n+test_vget_lane_f64_beyond (float64x1_t in)\n+{\n+  /* { dg-error \"lane 1 out of range 0 - 0\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_f64 (in, 1);\n+}"}, {"sha": "bcf25394519378afc30d85c2b26f3913ee8bef69", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_p16_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_p16_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_p16_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_p16_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+poly16_t\n+test_vget_lane_p16_before (poly16x4_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_p16 (in, -1);\n+}\n+\n+poly16_t\n+test_vget_lane_p16_beyond (poly16x4_t in)\n+{\n+  /* { dg-error \"lane 4 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_p16 (in, 4);\n+}"}, {"sha": "5dc8dc47afef8099e2040bb146e82b5feafeb54a", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_p8_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_p8_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_p8_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_p8_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+poly8_t\n+test_vget_lane_p8_before (poly8x8_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_p8 (in, -1);\n+}\n+\n+poly8_t\n+test_vget_lane_p8_beyond (poly8x8_t in)\n+{\n+  /* { dg-error \"lane 8 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_p8 (in, 8);\n+}"}, {"sha": "c65fb40721a2cf4a3de6d5958779fdf0bf530587", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_s16_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s16_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s16_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s16_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int16_t\n+test_vget_lane_s16_before (int16x4_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s16 (in, -1);\n+}\n+\n+int16_t\n+test_vget_lane_s16_beyond (int16x4_t in)\n+{\n+  /* { dg-error \"lane 4 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s16 (in, 4);\n+}"}, {"sha": "1f95137832dcc7df53f678ff42961ae0f93305d8", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_s32_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s32_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s32_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s32_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int32_t\n+test_vget_lane_s32_before (int32x2_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s32 (in, -1);\n+}\n+\n+int32_t\n+test_vget_lane_s32_beyond (int32x2_t in)\n+{\n+  /* { dg-error \"lane 2 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s32 (in, 2);\n+}"}, {"sha": "e449797fe54c56e32d80b78783adbbf66713388b", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_s64_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s64_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s64_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s64_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int64_t\n+test_vget_lane_s64_before (int64x1_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 0\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s64 (in, -1);\n+}\n+\n+int64_t\n+test_vget_lane_s64_beyond (int64x1_t in)\n+{\n+  /* { dg-error \"lane 1 out of range 0 - 0\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s64 (in, 1);\n+}"}, {"sha": "77e94860f1d09e41b41a0b087c42bff4689d6eeb", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_s8_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s8_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s8_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_s8_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int8_t\n+test_vget_lane_s8_before (int8x8_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s8 (in, -1);\n+}\n+\n+int8_t\n+test_vget_lane_s8_beyond (int8x8_t in)\n+{\n+  /* { dg-error \"lane 8 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_s8 (in, 8);\n+}"}, {"sha": "77fb3c8057c3e63b14ba6aac78caec1038936dcc", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_u16_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u16_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u16_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u16_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint16_t\n+test_vget_lane_u16_before (uint16x4_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u16 (in, -1);\n+}\n+\n+uint16_t\n+test_vget_lane_u16_beyond (uint16x4_t in)\n+{\n+  /* { dg-error \"lane 4 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u16 (in, 4);\n+}"}, {"sha": "e670626a060e2dfb9dbf3583687e0c6f0cb0d935", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_u32_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u32_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u32_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u32_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint32_t\n+test_vget_lane_u32_before (uint32x2_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u32 (in, -1);\n+}\n+\n+uint32_t\n+test_vget_lane_u32_beyond (uint32x2_t in)\n+{\n+  /* { dg-error \"lane 2 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u32 (in, 2);\n+}"}, {"sha": "44d5a4d9e01690b4d334431f0a200b08dfecc582", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_u64_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u64_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u64_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u64_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint64_t\n+test_vget_lane_u64_before (uint64x1_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 0\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u64 (in, -1);\n+}\n+\n+uint64_t\n+test_vget_lane_u64_beyond (uint64x1_t in)\n+{\n+  /* { dg-error \"lane 1 out of range 0 - 0\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u64 (in, 1);\n+}"}, {"sha": "b452d56c9c13fb6712fc8f177097e890774996d5", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vget_lane_u8_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u8_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u8_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvget_lane_u8_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint8_t\n+test_vget_lane_u8_before (uint8x8_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u8 (in, -1);\n+}\n+\n+uint8_t\n+test_vget_lane_u8_beyond (uint8x8_t in)\n+{\n+  /* { dg-error \"lane 8 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vget_lane_u8 (in, 8);\n+}"}, {"sha": "8a50ed2ac11702aed42606f361b48052101254ae", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_f32_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_f32_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_f32_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_f32_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+float32_t\n+test_vgetq_lane_f32_before (float32x4_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_f32 (in, -1);\n+}\n+\n+float32_t\n+test_vgetq_lane_f32_beyond (float32x4_t in)\n+{\n+  /* { dg-error \"lane 4 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_f32 (in, 4);\n+}"}, {"sha": "492b1ae66b903ead9a480d6915a1714cbd22281b", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_f64_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_f64_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_f64_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_f64_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+float64_t\n+test_vgetq_lane_f64_before (float64x2_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_f64 (in, -1);\n+}\n+\n+float64_t\n+test_vgetq_lane_f64_beyond (float64x2_t in)\n+{\n+  /* { dg-error \"lane 2 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_f64 (in, 2);\n+}"}, {"sha": "caa41b269c3df173b463ca9a434b3b08b3706c88", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_p16_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_p16_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_p16_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_p16_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+poly16_t\n+test_vgetq_lane_p16_before (poly16x8_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_p16 (in, -1);\n+}\n+\n+poly16_t\n+test_vgetq_lane_p16_beyond (poly16x8_t in)\n+{\n+  /* { dg-error \"lane 8 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_p16 (in, 8);\n+}"}, {"sha": "38caa27e1081587a910847d2432f3403107bf38a", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_p8_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_p8_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_p8_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_p8_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+poly8_t\n+test_vgetq_lane_p8_before (poly8x16_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 15\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_p8 (in, -1);\n+}\n+\n+poly8_t\n+test_vgetq_lane_p8_beyond (poly8x16_t in)\n+{\n+  /* { dg-error \"lane 16 out of range 0 - 15\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_p8 (in, 16);\n+}"}, {"sha": "0f4e4f58253b5de5aca0409428c48b316fec4d2b", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_s16_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s16_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s16_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s16_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int16_t\n+test_vgetq_lane_s16_before (int16x8_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s16 (in, -1);\n+}\n+\n+int16_t\n+test_vgetq_lane_s16_beyond (int16x8_t in)\n+{\n+  /* { dg-error \"lane 8 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s16 (in, 8);\n+}"}, {"sha": "68133b4bdcaca29918a9342818a221e495dee02d", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_s32_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s32_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s32_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s32_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int32_t\n+test_vgetq_lane_s32_before (int32x4_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s32 (in, -1);\n+}\n+\n+int32_t\n+test_vgetq_lane_s32_beyond (int32x4_t in)\n+{\n+  /* { dg-error \"lane 4 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s32 (in, 4);\n+}"}, {"sha": "4ac607fe2cc86228ea5a731dc4874d2feb0167f3", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_s64_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s64_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s64_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s64_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int64_t\n+test_vgetq_lane_s64_before (int64x2_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s64 (in, -1);\n+}\n+\n+int64_t\n+test_vgetq_lane_s64_beyond (int64x2_t in)\n+{\n+  /* { dg-error \"lane 2 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s64 (in, 2);\n+}"}, {"sha": "0e44dbc1851cc306356db61a359959b2df1dded9", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_s8_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s8_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s8_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_s8_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+int8_t\n+test_vgetq_lane_s8_before (int8x16_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 15\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s8 (in, -1);\n+}\n+\n+int8_t\n+test_vgetq_lane_s8_beyond (int8x16_t in)\n+{\n+  /* { dg-error \"lane 16 out of range 0 - 15\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_s8 (in, 16);\n+}"}, {"sha": "5ccea06f9ee7b4b7d0783ee0bd3b9695c57169f5", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_u16_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u16_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u16_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u16_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint16_t\n+test_vgetq_lane_u16_before (uint16x8_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u16 (in, -1);\n+}\n+\n+uint16_t\n+test_vgetq_lane_u16_beyond (uint16x8_t in)\n+{\n+  /* { dg-error \"lane 8 out of range 0 - 7\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u16 (in, 8);\n+}"}, {"sha": "bfbf081cbe2525b346ce8069c7970235c6db8bf2", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_u32_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u32_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u32_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u32_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint32_t\n+test_vgetq_lane_u32_before (uint32x4_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u32 (in, -1);\n+}\n+\n+uint32_t\n+test_vgetq_lane_u32_beyond (uint32x4_t in)\n+{\n+  /* { dg-error \"lane 4 out of range 0 - 3\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u32 (in, 4);\n+}"}, {"sha": "a0d426e84adbea82d30a40ab348e7efba873b109", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_u64_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u64_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u64_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u64_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint64_t\n+test_vgetq_lane_u64_before (uint64x2_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u64 (in, -1);\n+}\n+\n+uint64_t\n+test_vgetq_lane_u64_beyond (uint64x2_t in)\n+{\n+  /* { dg-error \"lane 2 out of range 0 - 1\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u64 (in, 2);\n+}"}, {"sha": "c9ad6634d7bfbd2d1291624a1974ee0e09e0ec30", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vgetq_lane_u8_indices_1.c", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u8_indices_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ed225d0c7b74eb6fa125cf791b7d50e2000883bc/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u8_indices_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvgetq_lane_u8_indices_1.c?ref=ed225d0c7b74eb6fa125cf791b7d50e2000883bc", "patch": "@@ -0,0 +1,17 @@\n+/* { dg-do assemble } */\n+\n+#include <arm_neon.h>\n+\n+uint8_t\n+test_vgetq_lane_u8_before (uint8x16_t in)\n+{\n+  /* { dg-error \"lane -1 out of range 0 - 15\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u8 (in, -1);\n+}\n+\n+uint8_t\n+test_vgetq_lane_u8_beyond (uint8x16_t in)\n+{\n+  /* { dg-error \"lane 16 out of range 0 - 15\" \"\" {target *-*-*} 0 } */\n+  return vgetq_lane_u8 (in, 16);\n+}"}]}