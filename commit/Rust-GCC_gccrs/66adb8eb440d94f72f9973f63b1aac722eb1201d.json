{"sha": "66adb8eb440d94f72f9973f63b1aac722eb1201d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NjZhZGI4ZWI0NDBkOTRmNzJmOTk3M2Y2M2IxYWFjNzIyZWIxMjAxZA==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2013-08-09T09:28:51Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2013-08-09T09:28:51Z"}, "message": "[AArch64] Fixup the vget_lane RTL patterns and intrinsics\n\ngcc/\n\t* config/aarch64/aarch64-simd-builtins.def (get_lane_signed): Remove.\n\t(get_lane_unsigned): Likewise.\n\t(dup_lane_scalar): Likewise.\n\t(get_lane): enable for VALL.\n\t* config/aarch64/aarch64-simd.md\n\t(aarch64_dup_lane_scalar<mode>): Remove.\n\t(aarch64_get_lane_signed<mode>): Likewise.\n\t(aarch64_get_lane_unsigned<mode>): Likewise.\n\t(aarch64_get_lane_extend<GPI:mode><VDQQH:mode>): New.\n\t(aarch64_get_lane_zero_extendsi<mode>): Likewise.\n\t(aarch64_get_lane<mode>): Enable for all vector modes.\n\t(aarch64_get_lanedi): Remove misleading constraints.\n\t* config/aarch64/arm_neon.h\n\t(__aarch64_vget_lane_any): Define.\n\t(__aarch64_vget<q>_lane_<fpsu><8,16,32,64>): Likewise.\n\t(vget<q>_lane_<fpsu><8,16,32,64>): Use __aarch64_vget_lane macros.\n\t(vdup<bhsd>_lane_<su><8,16,32,64>): Likewise.\n\t* config/aarch64/iterators.md (VDQQH): New.\n\t(VDQQHS): Likewise.\n\t(vwcore): Likewise.\n\ngcc/testsuite/\n\t* gcc.target/aarch64/scalar_intrinsics.c: Update expected\n\toutput of vdup intrinsics.\n\nFrom-SVN: r201624", "tree": {"sha": "443565ab356338f6e52228994fadec8e90fe9233", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/443565ab356338f6e52228994fadec8e90fe9233"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/66adb8eb440d94f72f9973f63b1aac722eb1201d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/66adb8eb440d94f72f9973f63b1aac722eb1201d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/66adb8eb440d94f72f9973f63b1aac722eb1201d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/66adb8eb440d94f72f9973f63b1aac722eb1201d/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "23a6cb7838f73aca404e5cc25a1cfbe1064db068", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/23a6cb7838f73aca404e5cc25a1cfbe1064db068", "html_url": "https://github.com/Rust-GCC/gccrs/commit/23a6cb7838f73aca404e5cc25a1cfbe1064db068"}], "stats": {"total": 365, "additions": 236, "deletions": 129}, "files": [{"sha": "8d80204803eb5416433b529f36a97a406618b705", "filename": "gcc/ChangeLog", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=66adb8eb440d94f72f9973f63b1aac722eb1201d", "patch": "@@ -1,3 +1,26 @@\n+2013-08-09  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/aarch64/aarch64-simd-builtins.def (get_lane_signed): Remove.\n+\t(get_lane_unsigned): Likewise.\n+\t(dup_lane_scalar): Likewise.\n+\t(get_lane): enable for VALL.\n+\t* config/aarch64/aarch64-simd.md\n+\t(aarch64_dup_lane_scalar<mode>): Remove.\n+\t(aarch64_get_lane_signed<mode>): Likewise.\n+\t(aarch64_get_lane_unsigned<mode>): Likewise.\n+\t(aarch64_get_lane_extend<GPI:mode><VDQQH:mode>): New.\n+\t(aarch64_get_lane_zero_extendsi<mode>): Likewise.\n+\t(aarch64_get_lane<mode>): Enable for all vector modes.\n+\t(aarch64_get_lanedi): Remove misleading constraints.\n+\t* config/aarch64/arm_neon.h\n+\t(__aarch64_vget_lane_any): Define.\n+\t(__aarch64_vget<q>_lane_<fpsu><8,16,32,64>): Likewise.\n+\t(vget<q>_lane_<fpsu><8,16,32,64>): Use __aarch64_vget_lane macros.\n+\t(vdup<bhsd>_lane_<su><8,16,32,64>): Likewise.\n+\t* config/aarch64/iterators.md (VDQQH): New.\n+\t(VDQQHS): Likewise.\n+\t(vwcore): Likewise.\n+\n 2013-08-09  Eric Botcazou  <ebotcazou@adacore.com>\n \n \t* configure.ac: Add GAS check for LEON instructions on SPARC."}, {"sha": "4046d7a7001c1eb81e79ae59a8a639312e1e7e6b", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=66adb8eb440d94f72f9973f63b1aac722eb1201d", "patch": "@@ -40,17 +40,16 @@\n    10 - CODE_FOR_<name><mode>.  */\n \n   BUILTIN_VD_RE (CREATE, create, 0)\n-  BUILTIN_VQ_S (GETLANE, get_lane_signed, 0)\n-  BUILTIN_VDQ (GETLANE, get_lane_unsigned, 0)\n-  BUILTIN_VDQF (GETLANE, get_lane, 0)\n-  VAR1 (GETLANE, get_lane, 0, di)\n   BUILTIN_VDC (COMBINE, combine, 0)\n   BUILTIN_VB (BINOP, pmul, 0)\n   BUILTIN_VDQF (UNOP, sqrt, 2)\n   BUILTIN_VD_BHSI (BINOP, addp, 0)\n   VAR1 (UNOP, addp, 0, di)\n   VAR1 (UNOP, clz, 2, v4si)\n \n+  BUILTIN_VALL (GETLANE, get_lane, 0)\n+  VAR1 (GETLANE, get_lane, 0, di)\n+\n   BUILTIN_VD_RE (REINTERP, reinterpretdi, 0)\n   BUILTIN_VDC (REINTERP, reinterpretv8qi, 0)\n   BUILTIN_VDC (REINTERP, reinterpretv4hi, 0)\n@@ -64,7 +63,6 @@\n   BUILTIN_VQ (REINTERP, reinterpretv2df, 0)\n \n   BUILTIN_VDQ_I (BINOP, dup_lane, 0)\n-  BUILTIN_VDQ_I (BINOP, dup_lane_scalar, 0)\n   /* Implemented by aarch64_<sur>q<r>shl<mode>.  */\n   BUILTIN_VSDQ_I (BINOP, sqshl, 0)\n   BUILTIN_VSDQ_I (BINOP, uqshl, 0)"}, {"sha": "982373099f714ee4694b9918ec93bb2724713195", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 24, "deletions": 33, "changes": 57, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=66adb8eb440d94f72f9973f63b1aac722eb1201d", "patch": "@@ -357,20 +357,6 @@\n    (set_attr \"simd_mode\" \"<MODE>\")]\n )\n \n-(define_insn \"aarch64_dup_lane_scalar<mode>\"\n-  [(set (match_operand:<VEL> 0 \"register_operand\" \"=w, r\")\n-\t(vec_select:<VEL>\n-\t  (match_operand:VDQ 1 \"register_operand\" \"w, w\")\n-\t  (parallel [(match_operand:SI 2 \"immediate_operand\" \"i, i\")])\n-        ))]\n-  \"TARGET_SIMD\"\n-  \"@\n-   dup\\\\t%<Vetype>0, %1.<Vetype>[%2]\n-   umov\\\\t%<vw>0, %1.<Vetype>[%2]\"\n-  [(set_attr \"simd_type\" \"simd_dup, simd_movgp\")\n-   (set_attr \"simd_mode\" \"<MODE>\")]\n-)\n-\n (define_insn \"aarch64_simd_dup<mode>\"\n   [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n         (vec_duplicate:VDQF (match_operand:<VEL> 1 \"register_operand\" \"w\")))]\n@@ -2147,45 +2133,50 @@\n   DONE;\n })\n \n-(define_insn \"aarch64_get_lane_signed<mode>\"\n-  [(set (match_operand:<VEL> 0 \"register_operand\" \"=r\")\n-\t(sign_extend:<VEL>\n+;; Lane extraction with sign extension to general purpose register.\n+(define_insn \"*aarch64_get_lane_extend<GPI:mode><VDQQH:mode>\"\n+  [(set (match_operand:GPI 0 \"register_operand\" \"=r\")\n+\t(sign_extend:GPI\n \t  (vec_select:<VEL>\n-\t    (match_operand:VQ_S 1 \"register_operand\" \"w\")\n+\t    (match_operand:VDQQH 1 \"register_operand\" \"w\")\n \t    (parallel [(match_operand:SI 2 \"immediate_operand\" \"i\")]))))]\n   \"TARGET_SIMD\"\n-  \"smov\\\\t%0, %1.<Vetype>[%2]\"\n+  \"smov\\\\t%<GPI:w>0, %1.<VDQQH:Vetype>[%2]\"\n   [(set_attr \"simd_type\" \"simd_movgp\")\n-   (set_attr \"simd_mode\" \"<MODE>\")]\n+   (set_attr \"simd_mode\" \"<VDQQH:MODE>\")]\n )\n \n-(define_insn \"aarch64_get_lane_unsigned<mode>\"\n-  [(set (match_operand:<VEL> 0 \"register_operand\" \"=r\")\n-\t(zero_extend:<VEL>\n+(define_insn \"*aarch64_get_lane_zero_extendsi<mode>\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(zero_extend:SI\n \t  (vec_select:<VEL>\n-\t    (match_operand:VDQ 1 \"register_operand\" \"w\")\n+\t    (match_operand:VDQQH 1 \"register_operand\" \"w\")\n \t    (parallel [(match_operand:SI 2 \"immediate_operand\" \"i\")]))))]\n   \"TARGET_SIMD\"\n-  \"umov\\\\t%<vw>0, %1.<Vetype>[%2]\"\n+  \"umov\\\\t%w0, %1.<Vetype>[%2]\"\n   [(set_attr \"simd_type\" \"simd_movgp\")\n    (set_attr \"simd_mode\" \"<MODE>\")]\n )\n \n+;; Lane extraction of a value, neither sign nor zero extension\n+;; is guaranteed so upper bits should be considered undefined.\n (define_insn \"aarch64_get_lane<mode>\"\n-  [(set (match_operand:<VEL> 0 \"register_operand\" \"=w\")\n+  [(set (match_operand:<VEL> 0 \"register_operand\" \"=r, w\")\n \t(vec_select:<VEL>\n-\t    (match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t    (parallel [(match_operand:SI 2 \"immediate_operand\" \"i\")])))]\n+\t  (match_operand:VALL 1 \"register_operand\" \"w, w\")\n+\t  (parallel [(match_operand:SI 2 \"immediate_operand\" \"i, i\")])))]\n   \"TARGET_SIMD\"\n-  \"mov\\\\t%0.<Vetype>[0], %1.<Vetype>[%2]\"\n-  [(set_attr \"simd_type\" \"simd_ins\")\n+  \"@\n+   umov\\\\t%<vwcore>0, %1.<Vetype>[%2]\n+   dup\\\\t%<Vetype>0, %1.<Vetype>[%2]\"\n+  [(set_attr \"simd_type\" \"simd_movgp, simd_dup\")\n    (set_attr \"simd_mode\" \"<MODE>\")]\n )\n \n (define_expand \"aarch64_get_lanedi\"\n-  [(match_operand:DI 0 \"register_operand\" \"=r\")\n-   (match_operand:DI 1 \"register_operand\" \"w\")\n-   (match_operand:SI 2 \"immediate_operand\" \"i\")]\n+  [(match_operand:DI 0 \"register_operand\")\n+   (match_operand:DI 1 \"register_operand\")\n+   (match_operand:SI 2 \"immediate_operand\")]\n   \"TARGET_SIMD\"\n {\n   aarch64_simd_lane_bounds (operands[2], 0, 1);"}, {"sha": "73a5400831dd96c5d705c5fc4213b2681bba270a", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 162, "deletions": 87, "changes": 249, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=66adb8eb440d94f72f9973f63b1aac722eb1201d", "patch": "@@ -446,7 +446,66 @@ typedef struct poly16x8x4_t\n   poly16x8_t val[4];\n } poly16x8x4_t;\n \n-\n+/* vget_lane internal macros.  */\n+\n+#define __aarch64_vget_lane_any(__size, __cast_ret, __cast_a, __a, __b) \\\n+  (__cast_ret\t\t\t\t\t\t\t\t\\\n+     __builtin_aarch64_get_lane##__size (__cast_a __a, __b))\n+\n+#define __aarch64_vget_lane_f32(__a, __b) \\\n+  __aarch64_vget_lane_any (v2sf, , , __a, __b)\n+#define __aarch64_vget_lane_f64(__a, __b) (__a)\n+\n+#define __aarch64_vget_lane_p8(__a, __b) \\\n+  __aarch64_vget_lane_any (v8qi, (poly8_t), (int8x8_t), __a, __b)\n+#define __aarch64_vget_lane_p16(__a, __b) \\\n+  __aarch64_vget_lane_any (v4hi, (poly16_t), (int16x4_t), __a, __b)\n+\n+#define __aarch64_vget_lane_s8(__a, __b) \\\n+  __aarch64_vget_lane_any (v8qi, , ,__a, __b)\n+#define __aarch64_vget_lane_s16(__a, __b) \\\n+  __aarch64_vget_lane_any (v4hi, , ,__a, __b)\n+#define __aarch64_vget_lane_s32(__a, __b) \\\n+  __aarch64_vget_lane_any (v2si, , ,__a, __b)\n+#define __aarch64_vget_lane_s64(__a, __b) (__a)\n+\n+#define __aarch64_vget_lane_u8(__a, __b) \\\n+  __aarch64_vget_lane_any (v8qi, (uint8_t), (int8x8_t), __a, __b)\n+#define __aarch64_vget_lane_u16(__a, __b) \\\n+  __aarch64_vget_lane_any (v4hi, (uint16_t), (int16x4_t), __a, __b)\n+#define __aarch64_vget_lane_u32(__a, __b) \\\n+  __aarch64_vget_lane_any (v2si, (uint32_t), (int32x2_t), __a, __b)\n+#define __aarch64_vget_lane_u64(__a, __b) (__a)\n+\n+#define __aarch64_vgetq_lane_f32(__a, __b) \\\n+  __aarch64_vget_lane_any (v4sf, , , __a, __b)\n+#define __aarch64_vgetq_lane_f64(__a, __b) \\\n+  __aarch64_vget_lane_any (v2df, , , __a, __b)\n+\n+#define __aarch64_vgetq_lane_p8(__a, __b) \\\n+  __aarch64_vget_lane_any (v16qi, (poly8_t), (int8x16_t), __a, __b)\n+#define __aarch64_vgetq_lane_p16(__a, __b) \\\n+  __aarch64_vget_lane_any (v8hi, (poly16_t), (int16x8_t), __a, __b)\n+\n+#define __aarch64_vgetq_lane_s8(__a, __b) \\\n+  __aarch64_vget_lane_any (v16qi, , ,__a, __b)\n+#define __aarch64_vgetq_lane_s16(__a, __b) \\\n+  __aarch64_vget_lane_any (v8hi, , ,__a, __b)\n+#define __aarch64_vgetq_lane_s32(__a, __b) \\\n+  __aarch64_vget_lane_any (v4si, , ,__a, __b)\n+#define __aarch64_vgetq_lane_s64(__a, __b) \\\n+  __aarch64_vget_lane_any (v2di, , ,__a, __b)\n+\n+#define __aarch64_vgetq_lane_u8(__a, __b) \\\n+  __aarch64_vget_lane_any (v16qi, (uint8_t), (int8x16_t), __a, __b)\n+#define __aarch64_vgetq_lane_u16(__a, __b) \\\n+  __aarch64_vget_lane_any (v8hi, (uint16_t), (int16x8_t), __a, __b)\n+#define __aarch64_vgetq_lane_u32(__a, __b) \\\n+  __aarch64_vget_lane_any (v4si, (uint32_t), (int32x4_t), __a, __b)\n+#define __aarch64_vgetq_lane_u64(__a, __b) \\\n+  __aarch64_vget_lane_any (v2di, (uint64_t), (int64x2_t), __a, __b)\n+\n+/* vadd  */\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vadd_s8 (int8x8_t __a, int8x8_t __b)\n {\n@@ -2307,155 +2366,156 @@ vcreate_p16 (uint64_t __a)\n   return (poly16x4_t) __a;\n }\n \n+/* vget_lane  */\n+\n+__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n+vget_lane_f32 (float32x2_t __a, const int __b)\n+{\n+  return __aarch64_vget_lane_f32 (__a, __b);\n+}\n+\n+__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n+vget_lane_f64 (float64x1_t __a, const int __b)\n+{\n+  return __aarch64_vget_lane_f64 (__a, __b);\n+}\n+\n+__extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n+vget_lane_p8 (poly8x8_t __a, const int __b)\n+{\n+  return __aarch64_vget_lane_p8 (__a, __b);\n+}\n+\n+__extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n+vget_lane_p16 (poly16x4_t __a, const int __b)\n+{\n+  return __aarch64_vget_lane_p16 (__a, __b);\n+}\n+\n __extension__ static __inline int8_t __attribute__ ((__always_inline__))\n vget_lane_s8 (int8x8_t __a, const int __b)\n {\n-  return (int8_t) __builtin_aarch64_get_lane_signedv8qi (__a, __b);\n+  return __aarch64_vget_lane_s8 (__a, __b);\n }\n \n __extension__ static __inline int16_t __attribute__ ((__always_inline__))\n vget_lane_s16 (int16x4_t __a, const int __b)\n {\n-  return (int16_t) __builtin_aarch64_get_lane_signedv4hi (__a, __b);\n+  return __aarch64_vget_lane_s16 (__a, __b);\n }\n \n __extension__ static __inline int32_t __attribute__ ((__always_inline__))\n vget_lane_s32 (int32x2_t __a, const int __b)\n {\n-  return (int32_t) __builtin_aarch64_get_lane_signedv2si (__a, __b);\n+  return __aarch64_vget_lane_s32 (__a, __b);\n }\n \n-__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n-vget_lane_f32 (float32x2_t __a, const int __b)\n+__extension__ static __inline int64_t __attribute__ ((__always_inline__))\n+vget_lane_s64 (int64x1_t __a, const int __b)\n {\n-  return (float32_t) __builtin_aarch64_get_lanev2sf (__a, __b);\n+  return __aarch64_vget_lane_s64 (__a, __b);\n }\n \n __extension__ static __inline uint8_t __attribute__ ((__always_inline__))\n vget_lane_u8 (uint8x8_t __a, const int __b)\n {\n-  return (uint8_t) __builtin_aarch64_get_lane_unsignedv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t\t    __b);\n+  return __aarch64_vget_lane_u8 (__a, __b);\n }\n \n __extension__ static __inline uint16_t __attribute__ ((__always_inline__))\n vget_lane_u16 (uint16x4_t __a, const int __b)\n {\n-  return (uint16_t) __builtin_aarch64_get_lane_unsignedv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t\t     __b);\n+  return __aarch64_vget_lane_u16 (__a, __b);\n }\n \n __extension__ static __inline uint32_t __attribute__ ((__always_inline__))\n vget_lane_u32 (uint32x2_t __a, const int __b)\n {\n-  return (uint32_t) __builtin_aarch64_get_lane_unsignedv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t\t     __b);\n+  return __aarch64_vget_lane_u32 (__a, __b);\n }\n \n-__extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n-vget_lane_p8 (poly8x8_t __a, const int __b)\n+__extension__ static __inline uint64_t __attribute__ ((__always_inline__))\n+vget_lane_u64 (uint64x1_t __a, const int __b)\n {\n-  return (poly8_t) __builtin_aarch64_get_lane_unsignedv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t\t    __b);\n+  return __aarch64_vget_lane_u64 (__a, __b);\n }\n \n-__extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n-vget_lane_p16 (poly16x4_t __a, const int __b)\n+/* vgetq_lane  */\n+\n+__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n+vgetq_lane_f32 (float32x4_t __a, const int __b)\n {\n-  return (poly16_t) __builtin_aarch64_get_lane_unsignedv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t\t     __b);\n+  return __aarch64_vgetq_lane_f32 (__a, __b);\n }\n \n-__extension__ static __inline int64_t __attribute__ ((__always_inline__))\n-vget_lane_s64 (int64x1_t __a, const int __b)\n+__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n+vgetq_lane_f64 (float64x2_t __a, const int __b)\n {\n-  return (int64_t) __builtin_aarch64_get_lanedi (__a, __b);\n+  return __aarch64_vgetq_lane_f64 (__a, __b);\n }\n \n-__extension__ static __inline uint64_t __attribute__ ((__always_inline__))\n-vget_lane_u64 (uint64x1_t __a, const int __b)\n+__extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n+vgetq_lane_p8 (poly8x16_t __a, const int __b)\n+{\n+  return __aarch64_vgetq_lane_p8 (__a, __b);\n+}\n+\n+__extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n+vgetq_lane_p16 (poly16x8_t __a, const int __b)\n {\n-  return (uint64_t) __builtin_aarch64_get_lanedi ((int64x1_t) __a, __b);\n+  return __aarch64_vgetq_lane_p16 (__a, __b);\n }\n \n __extension__ static __inline int8_t __attribute__ ((__always_inline__))\n vgetq_lane_s8 (int8x16_t __a, const int __b)\n {\n-  return (int8_t) __builtin_aarch64_get_lane_signedv16qi (__a, __b);\n+  return __aarch64_vgetq_lane_s8 (__a, __b);\n }\n \n __extension__ static __inline int16_t __attribute__ ((__always_inline__))\n vgetq_lane_s16 (int16x8_t __a, const int __b)\n {\n-  return (int16_t) __builtin_aarch64_get_lane_signedv8hi (__a, __b);\n+  return __aarch64_vgetq_lane_s16 (__a, __b);\n }\n \n __extension__ static __inline int32_t __attribute__ ((__always_inline__))\n vgetq_lane_s32 (int32x4_t __a, const int __b)\n {\n-  return (int32_t) __builtin_aarch64_get_lane_signedv4si (__a, __b);\n-}\n-\n-__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n-vgetq_lane_f32 (float32x4_t __a, const int __b)\n-{\n-  return (float32_t) __builtin_aarch64_get_lanev4sf (__a, __b);\n+  return __aarch64_vgetq_lane_s32 (__a, __b);\n }\n \n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vgetq_lane_f64 (float64x2_t __a, const int __b)\n+__extension__ static __inline int64_t __attribute__ ((__always_inline__))\n+vgetq_lane_s64 (int64x2_t __a, const int __b)\n {\n-  return (float64_t) __builtin_aarch64_get_lanev2df (__a, __b);\n+  return __aarch64_vgetq_lane_s64 (__a, __b);\n }\n \n __extension__ static __inline uint8_t __attribute__ ((__always_inline__))\n vgetq_lane_u8 (uint8x16_t __a, const int __b)\n {\n-  return (uint8_t) __builtin_aarch64_get_lane_unsignedv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t\t     __b);\n+  return __aarch64_vgetq_lane_u8 (__a, __b);\n }\n \n __extension__ static __inline uint16_t __attribute__ ((__always_inline__))\n vgetq_lane_u16 (uint16x8_t __a, const int __b)\n {\n-  return (uint16_t) __builtin_aarch64_get_lane_unsignedv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t\t     __b);\n+  return __aarch64_vgetq_lane_u16 (__a, __b);\n }\n \n __extension__ static __inline uint32_t __attribute__ ((__always_inline__))\n vgetq_lane_u32 (uint32x4_t __a, const int __b)\n {\n-  return (uint32_t) __builtin_aarch64_get_lane_unsignedv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t\t     __b);\n-}\n-\n-__extension__ static __inline poly8_t __attribute__ ((__always_inline__))\n-vgetq_lane_p8 (poly8x16_t __a, const int __b)\n-{\n-  return (poly8_t) __builtin_aarch64_get_lane_unsignedv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t\t     __b);\n-}\n-\n-__extension__ static __inline poly16_t __attribute__ ((__always_inline__))\n-vgetq_lane_p16 (poly16x8_t __a, const int __b)\n-{\n-  return (poly16_t) __builtin_aarch64_get_lane_unsignedv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t\t     __b);\n-}\n-\n-__extension__ static __inline int64_t __attribute__ ((__always_inline__))\n-vgetq_lane_s64 (int64x2_t __a, const int __b)\n-{\n-  return __builtin_aarch64_get_lane_unsignedv2di (__a, __b);\n+  return __aarch64_vgetq_lane_u32 (__a, __b);\n }\n \n __extension__ static __inline uint64_t __attribute__ ((__always_inline__))\n vgetq_lane_u64 (uint64x2_t __a, const int __b)\n {\n-  return (uint64_t) __builtin_aarch64_get_lane_unsignedv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t\t     __b);\n+  return __aarch64_vgetq_lane_u64 (__a, __b);\n }\n \n+/* vreinterpret  */\n+\n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n vreinterpret_p8_s8 (int8x8_t __a)\n {\n@@ -6724,18 +6784,6 @@ vget_high_u64 (uint64x2_t a)\n   return result;\n }\n \n-#define vget_lane_f64(a, b)                                             \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float64x1_t a_ = (a);                                            \\\n-       float64_t result;                                                \\\n-       __asm__ (\"umov %x0, %1.d[%2]\"                                    \\\n-                : \"=r\"(result)                                          \\\n-                : \"w\"(a_), \"i\"(b)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vget_low_f32 (float32x4_t a)\n {\n@@ -19732,49 +19780,49 @@ vcvtpq_u64_f64 (float64x2_t __a)\n __extension__ static __inline int8x1_t __attribute__ ((__always_inline__))\n vdupb_lane_s8 (int8x16_t a, int const b)\n {\n-  return __builtin_aarch64_dup_lane_scalarv16qi (a, b);\n+  return __aarch64_vget_laneq_s8 (a, b);\n }\n \n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vdupb_lane_u8 (uint8x16_t a, int const b)\n {\n-  return (uint8x1_t) __builtin_aarch64_dup_lane_scalarv16qi ((int8x16_t) a, b);\n+  return __aarch64_vget_laneq_u8 (a, b);\n }\n \n __extension__ static __inline int16x1_t __attribute__ ((__always_inline__))\n vduph_lane_s16 (int16x8_t a, int const b)\n {\n-  return __builtin_aarch64_dup_lane_scalarv8hi (a, b);\n+  return __aarch64_vget_laneq_s16 (a, b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vduph_lane_u16 (uint16x8_t a, int const b)\n {\n-  return (uint16x1_t) __builtin_aarch64_dup_lane_scalarv8hi ((int16x8_t) a, b);\n+  return __aarch64_vget_laneq_u16 (a, b);\n }\n \n __extension__ static __inline int32x1_t __attribute__ ((__always_inline__))\n vdups_lane_s32 (int32x4_t a, int const b)\n {\n-  return __builtin_aarch64_dup_lane_scalarv4si (a, b);\n+  return __aarch64_vget_laneq_s32 (a, b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vdups_lane_u32 (uint32x4_t a, int const b)\n {\n-  return (uint32x1_t) __builtin_aarch64_dup_lane_scalarv4si ((int32x4_t) a, b);\n+  return __aarch64_vget_laneq_u32 (a, b);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vdupd_lane_s64 (int64x2_t a, int const b)\n {\n-  return __builtin_aarch64_dup_lane_scalarv2di (a, b);\n+  return __aarch64_vget_laneq_s64 (a, b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vdupd_lane_u64 (uint64x2_t a, int const b)\n {\n-  return (uint64x1_t) __builtin_aarch64_dup_lane_scalarv2di ((int64x2_t) a, b);\n+  return __aarch64_vget_laneq_s64 (a, b);\n }\n \n /* vld1 */\n@@ -25581,4 +25629,31 @@ __INTERLEAVE_LIST (zip)\n \n /* End of optimal implementations in approved order.  */\n \n+#undef __aarch64_vget_lane_any\n+#undef __aarch64_vget_lane_f32\n+#undef __aarch64_vget_lane_f64\n+#undef __aarch64_vget_lane_p8\n+#undef __aarch64_vget_lane_p16\n+#undef __aarch64_vget_lane_s8\n+#undef __aarch64_vget_lane_s16\n+#undef __aarch64_vget_lane_s32\n+#undef __aarch64_vget_lane_s64\n+#undef __aarch64_vget_lane_u8\n+#undef __aarch64_vget_lane_u16\n+#undef __aarch64_vget_lane_u32\n+#undef __aarch64_vget_lane_u64\n+\n+#undef __aarch64_vgetq_lane_f32\n+#undef __aarch64_vgetq_lane_f64\n+#undef __aarch64_vgetq_lane_p8\n+#undef __aarch64_vgetq_lane_p16\n+#undef __aarch64_vgetq_lane_s8\n+#undef __aarch64_vgetq_lane_s16\n+#undef __aarch64_vgetq_lane_s32\n+#undef __aarch64_vgetq_lane_s64\n+#undef __aarch64_vgetq_lane_u8\n+#undef __aarch64_vgetq_lane_u16\n+#undef __aarch64_vgetq_lane_u32\n+#undef __aarch64_vgetq_lane_u64\n+\n #endif"}, {"sha": "37b6cbc8dc8c0f6575302821883ddd8739b0e57a", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=66adb8eb440d94f72f9973f63b1aac722eb1201d", "patch": "@@ -134,9 +134,15 @@\n ;; Vector modes except double int.\n (define_mode_iterator VDQIF [V8QI V16QI V4HI V8HI V2SI V4SI V2SF V4SF V2DF])\n \n+;; Vector modes for Q and H types.\n+(define_mode_iterator VDQQH [V8QI V16QI V4HI V8HI])\n+\n ;; Vector modes for H and S types.\n (define_mode_iterator VDQHS [V4HI V8HI V2SI V4SI])\n \n+;; Vector modes for Q, H and S types.\n+(define_mode_iterator VDQQHS [V8QI V16QI V4HI V8HI V2SI V4SI])\n+\n ;; Vector and scalar integer modes for H and S\n (define_mode_iterator VSDQ_HSI [V4HI V8HI V2SI V4SI HI SI])\n \n@@ -453,6 +459,15 @@\n                         (V2SF \"s\") (V4SF \"s\")\n                         (V2DF \"d\")])\n \n+;; Corresponding core element mode for each vector mode.  This is a\n+;; variation on <vw> mapping FP modes to GP regs.\n+(define_mode_attr vwcore  [(V8QI \"w\") (V16QI \"w\")\n+\t\t\t   (V4HI \"w\") (V8HI \"w\")\n+\t\t\t   (V2SI \"w\") (V4SI \"w\")\n+\t\t\t   (DI   \"x\") (V2DI \"x\")\n+\t\t\t   (V2SF \"w\") (V4SF \"w\")\n+\t\t\t   (V2DF \"x\")])\n+\n ;; Double vector types for ALLX.\n (define_mode_attr Vallxd [(QI \"8b\") (HI \"4h\") (SI \"2s\")])\n "}, {"sha": "1e682b96fd85ea12f3bb7109beee6f853813d576", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=66adb8eb440d94f72f9973f63b1aac722eb1201d", "patch": "@@ -1,3 +1,8 @@\n+2013-08-09  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* gcc.target/aarch64/scalar_intrinsics.c: Update expected\n+\toutput of vdup intrinsics.\n+\n 2013-08-09  Zhenqiang Chen  <zhenqiang.chen@linaro.org>\n \n \t* gcc.target/arm/lp1189445.c: New testcase."}, {"sha": "d84bfeb55e903509be35248d031e7c59677dc9d6", "filename": "gcc/testsuite/gcc.target/aarch64/scalar_intrinsics.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fscalar_intrinsics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/66adb8eb440d94f72f9973f63b1aac722eb1201d/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fscalar_intrinsics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fscalar_intrinsics.c?ref=66adb8eb440d94f72f9973f63b1aac722eb1201d", "patch": "@@ -193,7 +193,7 @@ test_vcltzd_s64 (int64x1_t a)\n   return res;\n }\n \n-/* { dg-final { scan-assembler-times \"aarch64_dup_lane_scalarv16qi\"  2 } } */\n+/* { dg-final { scan-assembler-times \"aarch64_get_lanev16qi\" 2 } } */\n \n int8x1_t\n test_vdupb_lane_s8 (int8x16_t a)\n@@ -207,7 +207,7 @@ test_vdupb_lane_u8 (uint8x16_t a)\n   return vdupb_lane_u8 (a, 2);\n }\n \n-/* { dg-final { scan-assembler-times \"aarch64_dup_lane_scalarv8hi\"  2 } } */\n+/* { dg-final { scan-assembler-times \"aarch64_get_lanev8hi\" 2 } } */\n \n int16x1_t\n test_vduph_lane_s16 (int16x8_t a)\n@@ -221,7 +221,7 @@ test_vduph_lane_u16 (uint16x8_t a)\n   return vduph_lane_u16 (a, 2);\n }\n \n-/* { dg-final { scan-assembler-times \"aarch64_dup_lane_scalarv4si\"  2 } } */\n+/* { dg-final { scan-assembler-times \"aarch64_get_lanev4si\" 2 } } */\n \n int32x1_t\n test_vdups_lane_s32 (int32x4_t a)\n@@ -235,7 +235,7 @@ test_vdups_lane_u32 (uint32x4_t a)\n   return vdups_lane_u32 (a, 2);\n }\n \n-/* { dg-final { scan-assembler-times \"aarch64_dup_lane_scalarv2di\"  2 } } */\n+/* { dg-final { scan-assembler-times \"aarch64_get_lanev2di\" 2 } } */\n \n int64x1_t\n test_vdupd_lane_s64 (int64x2_t a)"}]}