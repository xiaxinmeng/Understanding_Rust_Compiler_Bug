{"sha": "e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTlkOGZjYWJkMDMyYjg3M2JmM2ZlMTRhZThhZmQ4OTcwODI3YzBjYg==", "commit": {"author": {"name": "Jakub Jelinek", "email": "jakub@redhat.com", "date": "2021-09-18T07:50:14Z"}, "committer": {"name": "Jakub Jelinek", "email": "jakub@redhat.com", "date": "2021-09-18T07:58:13Z"}, "message": "openmp: Handle unconstrained and reproducible modifiers on order(concurrent)\n\nThis patch adds handling for unconstrained and reproducible modifiers on\norder(concurrent) clause.  For all static schedules (including auto and\nno schedule or dist_schedule clauses) I believe what we implement is\nreproducible, so the patch doesn't do much beyond recognizing those.\nNote, there is an OpenMP/spec issue that needs resolution on what\nshould happen with the dynamic schedules (whether it should be an error\nto mix such clauses, or silently make it non-reproducible, and in which\nexact cases), so it might need some follow-up.\n\nBesides that, this patch allows order(concurrent) clause on the distribute\nconstruct which is something also added in OpenMP 5.1, and finally\ncheck the newly added restriction that at most one order clause\ncan appear on a construct.\n\nThe allowing of order clause on distribute has a side-effect that\norder(concurrent) copyin(thrpriv) is no longer allowed on combined/composite\nconstructs with distribute parallel for{, simd} in it, previously the\norder applied only to for/simd and so a threadprivate var could be seen\nin the construct, but now it also applies to distribute and so on the parallel\nwe shouldn't refer to a threadprivate var.\n\n2021-09-18  Jakub Jelinek  <jakub@redhat.com>\n\ngcc/\n\t* tree.h (OMP_CLAUSE_ORDER_UNCONSTRAINED): Define.\n\t* tree-pretty-print.c (dump_omp_clause): Print unconstrained:\n\tfor OMP_CLAUSE_ORDER_UNCONSTRAINED.\ngcc/c-family/\n\t* c-omp.c (c_omp_split_clauses): Split order clause also to\n\tdistribute construct.  Copy over OMP_CLAUSE_ORDER_UNCONSTRAINED.\ngcc/c/\n\t* c-parser.c (c_parser_omp_clause_order): Parse unconstrained\n\tand reproducible modifiers.\n\t(OMP_DISTRIBUTE_CLAUSE_MASK): Add order clause.\ngcc/cp/\n\t* parser.c (cp_parser_omp_clause_order): Parse unconstrained\n\tand reproducible modifiers.\n\t(OMP_DISTRIBUTE_CLAUSE_MASK): Add order clause.\ngcc/testsuite/\n\t* c-c++-common/gomp/order-1.c (f2): Add tests for distribute\n\twith order clause.\n\t(f3): Remove.\n\t* c-c++-common/gomp/order-2.c: Don't expect error for distribute\n\twith order clause.\n\t* c-c++-common/gomp/order-5.c: New test.\n\t* c-c++-common/gomp/order-6.c: New test.\n\t* c-c++-common/gomp/clause-dups-1.c (f1): Add tests for\n\tduplicated order clause.\n\t(f9): New function.\n\t* c-c++-common/gomp/clauses-1.c (baz, bar): Don't mix copyin and\n\torder(concurrent) clauses on the same composite construct combined\n\twith distribute, instead split it into two tests, one without\n\tcopyin and one without order(concurrent).  Add order(concurrent)\n\tclauses to {,{,target} teams} distribute.\n\t* g++.dg/gomp/attrs-1.C (baz, bar): Likewise.\n\t* g++.dg/gomp/attrs-2.C (baz, bar): Likewise.", "tree": {"sha": "f43a04685417a0e64905654a3ea2a45eb169a65e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f43a04685417a0e64905654a3ea2a45eb169a65e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/comments", "author": {"login": "jakubjelinek", "id": 9370665, "node_id": "MDQ6VXNlcjkzNzA2NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/9370665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubjelinek", "html_url": "https://github.com/jakubjelinek", "followers_url": "https://api.github.com/users/jakubjelinek/followers", "following_url": "https://api.github.com/users/jakubjelinek/following{/other_user}", "gists_url": "https://api.github.com/users/jakubjelinek/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubjelinek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubjelinek/subscriptions", "organizations_url": "https://api.github.com/users/jakubjelinek/orgs", "repos_url": "https://api.github.com/users/jakubjelinek/repos", "events_url": "https://api.github.com/users/jakubjelinek/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubjelinek/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jakubjelinek", "id": 9370665, "node_id": "MDQ6VXNlcjkzNzA2NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/9370665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubjelinek", "html_url": "https://github.com/jakubjelinek", "followers_url": "https://api.github.com/users/jakubjelinek/followers", "following_url": "https://api.github.com/users/jakubjelinek/following{/other_user}", "gists_url": "https://api.github.com/users/jakubjelinek/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubjelinek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubjelinek/subscriptions", "organizations_url": "https://api.github.com/users/jakubjelinek/orgs", "repos_url": "https://api.github.com/users/jakubjelinek/repos", "events_url": "https://api.github.com/users/jakubjelinek/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubjelinek/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e666a0a22a5c11b5bb894a75b73b6b7f3e364e4d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e666a0a22a5c11b5bb894a75b73b6b7f3e364e4d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e666a0a22a5c11b5bb894a75b73b6b7f3e364e4d"}], "stats": {"total": 780, "additions": 742, "deletions": 38}, "files": [{"sha": "b606cf4b5381ac2fd45a11d90468c13cb6919449", "filename": "gcc/c-family/c-omp.c", "status": "modified", "additions": 18, "deletions": 1, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Fc-family%2Fc-omp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Fc-family%2Fc-omp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-omp.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -2114,14 +2114,31 @@ c_omp_split_clauses (location_t loc, enum tree_code code,\n \t    }\n \t  s = C_OMP_CLAUSE_SPLIT_PARALLEL;\n \t  break;\n-\t/* order clauses are allowed on for, simd and loop.  */\n+\t/* order clauses are allowed on distribute, for, simd and loop.  */\n \tcase OMP_CLAUSE_ORDER:\n+\t  if ((mask & (OMP_CLAUSE_MASK_1\n+\t\t       << PRAGMA_OMP_CLAUSE_DIST_SCHEDULE)) != 0)\n+\t    {\n+\t      if (code == OMP_DISTRIBUTE)\n+\t\t{\n+\t\t  s = C_OMP_CLAUSE_SPLIT_DISTRIBUTE;\n+\t\t  break;\n+\t\t}\n+\t      c = build_omp_clause (OMP_CLAUSE_LOCATION (clauses),\n+\t\t\t\t    OMP_CLAUSE_ORDER);\n+\t      OMP_CLAUSE_ORDER_UNCONSTRAINED (c)\n+\t\t= OMP_CLAUSE_ORDER_UNCONSTRAINED (clauses);\n+\t      OMP_CLAUSE_CHAIN (c) = cclauses[C_OMP_CLAUSE_SPLIT_DISTRIBUTE];\n+\t      cclauses[C_OMP_CLAUSE_SPLIT_DISTRIBUTE] = c;\n+\t    }\n \t  if ((mask & (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_SCHEDULE)) != 0)\n \t    {\n \t      if (code == OMP_SIMD)\n \t\t{\n \t\t  c = build_omp_clause (OMP_CLAUSE_LOCATION (clauses),\n \t\t\t\t\tOMP_CLAUSE_ORDER);\n+\t\t  OMP_CLAUSE_ORDER_UNCONSTRAINED (c)\n+\t\t    = OMP_CLAUSE_ORDER_UNCONSTRAINED (clauses);\n \t\t  OMP_CLAUSE_CHAIN (c) = cclauses[C_OMP_CLAUSE_SPLIT_FOR];\n \t\t  cclauses[C_OMP_CLAUSE_SPLIT_FOR] = c;\n \t\t  s = C_OMP_CLAUSE_SPLIT_SIMD;"}, {"sha": "fb1399e300d4df4fbbed6493477fbd1b066f79ce", "filename": "gcc/c/c-parser.c", "status": "modified", "additions": 28, "deletions": 3, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Fc%2Fc-parser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Fc%2Fc-parser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2Fc-parser.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -14610,18 +14610,41 @@ c_parser_oacc_clause_wait (c_parser *parser, tree list)\n \n \n /* OpenMP 5.0:\n-   order ( concurrent ) */\n+   order ( concurrent )\n+\n+   OpenMP 5.1:\n+   order ( order-modifier : concurrent )\n+\n+   order-modifier:\n+     reproducible\n+     unconstrained  */\n \n static tree\n c_parser_omp_clause_order (c_parser *parser, tree list)\n {\n   location_t loc = c_parser_peek_token (parser)->location;\n   tree c;\n   const char *p;\n+  bool unconstrained = false;\n \n   matching_parens parens;\n   if (!parens.require_open (parser))\n     return list;\n+  if (c_parser_next_token_is (parser, CPP_NAME)\n+      && c_parser_peek_2nd_token (parser)->type == CPP_COLON)\n+    {\n+      p = IDENTIFIER_POINTER (c_parser_peek_token (parser)->value);\n+      if (strcmp (p, \"unconstrained\") == 0)\n+\tunconstrained = true;\n+      else if (strcmp (p, \"reproducible\") != 0)\n+\t{\n+\t  c_parser_error (parser, \"expected %<reproducible%> or \"\n+\t\t\t\t  \"%<unconstrained%>\");\n+\t  goto out_err;\n+\t}\n+      c_parser_consume_token (parser);\n+      c_parser_consume_token (parser);\n+    }\n   if (!c_parser_next_token_is (parser, CPP_NAME))\n     {\n       c_parser_error (parser, \"expected %<concurrent%>\");\n@@ -14635,8 +14658,9 @@ c_parser_omp_clause_order (c_parser *parser, tree list)\n     }\n   c_parser_consume_token (parser);\n   parens.skip_until_found_close (parser);\n-  /* check_no_duplicate_clause (list, OMP_CLAUSE_ORDER, \"order\"); */\n+  check_no_duplicate_clause (list, OMP_CLAUSE_ORDER, \"order\");\n   c = build_omp_clause (loc, OMP_CLAUSE_ORDER);\n+  OMP_CLAUSE_ORDER_UNCONSTRAINED (c) = unconstrained;\n   OMP_CLAUSE_CHAIN (c) = list;\n   return c;\n \n@@ -20250,7 +20274,8 @@ c_parser_omp_cancellation_point (c_parser *parser, enum pragma_context context)\n \t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_LASTPRIVATE)\t\\\n \t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_DIST_SCHEDULE)\\\n \t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_ALLOCATE)\t\\\n-\t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_COLLAPSE))\n+\t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_COLLAPSE)\t\\\n+\t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_ORDER))\n \n static tree\n c_parser_omp_distribute (location_t loc, c_parser *parser,"}, {"sha": "62908daa5b70b5103ebc77ffc4af0aa20e95226c", "filename": "gcc/cp/parser.c", "status": "modified", "additions": 29, "deletions": 3, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Fcp%2Fparser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Fcp%2Fparser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fparser.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -37703,18 +37703,42 @@ cp_parser_omp_clause_defaultmap (cp_parser *parser, tree list,\n }\n \n /* OpenMP 5.0:\n-   order ( concurrent ) */\n+   order ( concurrent )\n+\n+   OpenMP 5.1:\n+   order ( order-modifier : concurrent )\n+\n+   order-modifier:\n+     reproducible\n+     unconstrained  */\n \n static tree\n cp_parser_omp_clause_order (cp_parser *parser, tree list, location_t location)\n {\n   tree c, id;\n   const char *p;\n+  bool unconstrained = false;\n \n   matching_parens parens;\n   if (!parens.require_open (parser))\n     return list;\n \n+  if (cp_lexer_next_token_is (parser->lexer, CPP_NAME)\n+      && cp_lexer_nth_token_is (parser->lexer, 2, CPP_COLON))\n+    {\n+      id = cp_lexer_peek_token (parser->lexer)->u.value;\n+      p = IDENTIFIER_POINTER (id);\n+      if (strcmp (p, \"unconstrained\") == 0)\n+\tunconstrained = true;\n+      else if (strcmp (p, \"reproducible\") != 0)\n+\t{\n+\t  cp_parser_error (parser, \"expected %<reproducible%> or \"\n+\t\t\t\t   \"%<unconstrained%>\");\n+\t  goto out_err;\n+\t}\n+      cp_lexer_consume_token (parser->lexer);\n+      cp_lexer_consume_token (parser->lexer);\n+    }\n   if (!cp_lexer_next_token_is (parser->lexer, CPP_NAME))\n     {\n       cp_parser_error (parser, \"expected %<concurrent%>\");\n@@ -37734,8 +37758,9 @@ cp_parser_omp_clause_order (cp_parser *parser, tree list, location_t location)\n   if (!parens.require_close (parser))\n     goto out_err;\n \n-  /* check_no_duplicate_clause (list, OMP_CLAUSE_ORDER, \"order\", location); */\n+  check_no_duplicate_clause (list, OMP_CLAUSE_ORDER, \"order\", location);\n   c = build_omp_clause (location, OMP_CLAUSE_ORDER);\n+  OMP_CLAUSE_ORDER_UNCONSTRAINED (c) = unconstrained;\n   OMP_CLAUSE_CHAIN (c) = list;\n   return c;\n \n@@ -43346,7 +43371,8 @@ cp_parser_omp_cancellation_point (cp_parser *parser, cp_token *pragma_tok,\n \t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_LASTPRIVATE)\t\\\n \t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_DIST_SCHEDULE)\\\n \t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_ALLOCATE)\t\\\n-\t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_COLLAPSE))\n+\t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_COLLAPSE)\t\\\n+\t| (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_ORDER))\n \n static tree\n cp_parser_omp_distribute (cp_parser *parser, cp_token *pragma_tok,"}, {"sha": "a17f68dfb6b293bf16d1fc1aff5d9f4a0f7f4b1f", "filename": "gcc/testsuite/c-c++-common/gomp/clause-dups-1.c", "status": "modified", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fclause-dups-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fclause-dups-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fclause-dups-1.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -27,6 +27,12 @@ f1 (int *p)\n   for (i = 0; i < 8; ++i)\n     f0 ();\n   #pragma omp for nowait nowait\t\t\t\t\t/* { dg-error \"too many 'nowait' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n+  #pragma omp for schedule(static) order(concurrent) order(concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n+  #pragma omp for schedule(static) order(reproducible:concurrent) order(unconstrained:concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n   for (i = 0; i < 8; ++i)\n     f0 ();\n   #pragma omp simd collapse(1) collapse(1)\t\t\t/* { dg-error \"too many 'collapse' clauses\" } */\n@@ -207,6 +213,18 @@ f1 (int *p)\n   f0 ();\n   #pragma omp scope nowait nowait\t\t\t\t/* { dg-error \"too many 'nowait' clauses\" } */\n   ;\n+  #pragma omp loop bind(thread) order(concurrent) order(concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n+  #pragma omp loop bind(thread) order(reproducible:concurrent) order(unconstrained:concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n+  #pragma omp simd order(concurrent) order(concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n+  #pragma omp simd order(reproducible:concurrent) order(unconstrained:concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n }\n \n #pragma omp declare simd simdlen (4) simdlen (4)\t\t/* { dg-error \"too many 'simdlen' clauses\" } */\n@@ -223,3 +241,17 @@ void f6 (int a, int b);\n void f7 (int a, int b);\n #pragma omp declare simd linear (a) uniform (a)\t\t\t/* { dg-error \"'a' appears more than once in data clauses\" } */\n void f8 (int a, int b);\n+\n+#pragma omp declare target\n+void\n+f9 (void)\n+{\n+  int i;\n+  #pragma omp distribute dist_schedule(static) order(concurrent) order(concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n+  #pragma omp loop bind(thread) order(reproducible:concurrent) order(unconstrained:concurrent)\t/* { dg-error \"too many 'order' clauses\" } */\n+  for (i = 0; i < 8; ++i)\n+    f0 ();\n+}\n+#pragma omp end declare target"}, {"sha": "742132f202eb873f962e0f605428dcec77dc0b8e", "filename": "gcc/testsuite/c-c++-common/gomp/clauses-1.c", "status": "modified", "additions": 35, "deletions": 6, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fclauses-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fclauses-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fclauses-1.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -66,14 +66,27 @@ baz (int d, int m, int i1, int i2, int p, int *idp, int s,\n   #pragma omp distribute parallel for \\\n     private (p) firstprivate (f) collapse(1) dist_schedule(static, 16) \\\n     if (parallel: i2) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread) \\\n-    lastprivate (l) schedule(static, 4) copyin(t) order(concurrent) allocate (p)\n+    lastprivate (l) schedule(static, 4) copyin(t) allocate (p)\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n+  #pragma omp distribute parallel for \\\n+    private (p) firstprivate (f) collapse(1) dist_schedule(static, 16) \\\n+    if (parallel: i2) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread) \\\n+    lastprivate (l) schedule(static, 4) order(concurrent) allocate (p)\n   for (int i = 0; i < 64; i++)\n     ll++;\n   #pragma omp distribute parallel for simd \\\n     private (p) firstprivate (f) collapse(1) dist_schedule(static, 16) \\\n     if (parallel: i2) if(simd: i1) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread) \\\n     lastprivate (l) schedule(static, 4) nontemporal(ntm) \\\n-    safelen(8) simdlen(4) aligned(q: 32) copyin(t) order(concurrent) allocate (f)\n+    safelen(8) simdlen(4) aligned(q: 32) copyin(t) allocate (f)\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n+  #pragma omp distribute parallel for simd \\\n+    private (p) firstprivate (f) collapse(1) dist_schedule(static, 16) \\\n+    if (parallel: i2) if(simd: i1) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread) \\\n+    lastprivate (l) schedule(static, 4) nontemporal(ntm) \\\n+    safelen(8) simdlen(4) aligned(q: 32) order(concurrent) allocate (f)\n   for (int i = 0; i < 64; i++)\n     ll++;\n   #pragma omp distribute simd \\\n@@ -156,7 +169,7 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n     ;\n   #pragma omp target teams distribute \\\n     device(d) map (tofrom: m) if (target: i1) private (p) firstprivate (f) defaultmap(tofrom: scalar) is_device_ptr (idp) \\\n-    shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) \\\n+    shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) order(concurrent) \\\n     collapse(1) dist_schedule(static, 16) nowait depend(inout: dd[0]) allocate (omp_default_mem_alloc:f) in_reduction(+:r2)\n   for (int i = 0; i < 64; i++)\n     ;\n@@ -218,7 +231,7 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n   #pragma omp target nowait depend(inout: dd[0]) in_reduction(+:r2)\n   #pragma omp teams distribute \\\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) \\\n-    collapse(1) dist_schedule(static, 16) allocate (omp_default_mem_alloc: f)\n+    collapse(1) dist_schedule(static, 16) allocate (omp_default_mem_alloc: f) order(concurrent)\n   for (int i = 0; i < 64; i++)\n     ;\n   #pragma omp target\n@@ -249,20 +262,36 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n     ll++;\n   #pragma omp teams distribute parallel for \\\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) \\\n-    collapse(1) dist_schedule(static, 16) order(concurrent) \\\n+    collapse(1) dist_schedule(static, 16) \\\n     if (parallel: i2) num_threads (nth) proc_bind(spread) \\\n     lastprivate (l) schedule(static, 4) copyin(t) allocate (f)\n   for (int i = 0; i < 64; i++)\n     ll++;\n+  #pragma omp teams distribute parallel for \\\n+    private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) \\\n+    collapse(1) dist_schedule(static, 16) order(concurrent) \\\n+    if (parallel: i2) num_threads (nth) proc_bind(spread) \\\n+    lastprivate (l) schedule(static, 4) allocate (f)\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n   #pragma omp teams distribute parallel for simd \\\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) \\\n     collapse(1) dist_schedule(static, 16) \\\n     if (parallel: i2) num_threads (nth) proc_bind(spread) \\\n-    lastprivate (l) schedule(static, 4) order(concurrent) \\\n+    lastprivate (l) schedule(static, 4) \\\n     safelen(8) simdlen(4) aligned(q: 32) if (simd: i3) nontemporal(ntm) copyin(t) \\\n     allocate (f)\n   for (int i = 0; i < 64; i++)\n     ll++;\n+  #pragma omp teams distribute parallel for simd \\\n+    private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) \\\n+    collapse(1) dist_schedule(static, 16) \\\n+    if (parallel: i2) num_threads (nth) proc_bind(spread) \\\n+    lastprivate (l) schedule(static, 4) order(concurrent) \\\n+    safelen(8) simdlen(4) aligned(q: 32) if (simd: i3) nontemporal(ntm) \\\n+    allocate (f)\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n   #pragma omp teams distribute simd \\\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) \\\n     collapse(1) dist_schedule(static, 16) order(concurrent) \\"}, {"sha": "547d06190a46ecd04e0e3e81c4e8d284f14f0425", "filename": "gcc/testsuite/c-c++-common/gomp/order-1.c", "status": "modified", "additions": 6, "deletions": 9, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-1.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -27,6 +27,9 @@ f2 (int *a)\n   for (i = 0; i < 128; i++)\n     a[i]++;\n   #pragma omp teams distribute parallel for simd order(concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams distribute order(concurrent)\n   for (i = 0; i < 128; i++)\n     a[i]++;\n   #pragma omp teams\n@@ -37,17 +40,11 @@ f2 (int *a)\n     #pragma omp distribute parallel for simd order(concurrent)\n     for (i = 0; i < 128; i++)\n       a[i]++;\n+    #pragma omp distribute order(concurrent)\n+    for (i = 0; i < 128; i++)\n+      a[i]++;\n   }\n   #pragma omp taskloop simd order (concurrent)\n   for (i = 0; i < 128; i++)\n     a[i]++;\n }\n-\n-void\n-f3 (int *a)\n-{\n-  int i;\n-  #pragma omp for order(concurrent) order(concurrent) order(concurrent)\n-  for (i = 0; i < 128; i++)\n-    a[i]++;\n-}"}, {"sha": "5e044dc65c6052b608800da8eb9bffcb0c8cb305", "filename": "gcc/testsuite/c-c++-common/gomp/order-2.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-2.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -24,7 +24,7 @@ f2 (int *a)\n {\n   int i;\n   #pragma omp teams\n-  #pragma omp distribute order(concurrent)\t/* { dg-error \"'order' is not valid for '#pragma omp distribute'\" } */\n+  #pragma omp distribute order(concurrent)\n   for (i = 0; i < 128; i++)\n     a[i]++;\n   #pragma omp taskloop order (concurrent)\t/* { dg-error \"'order' is not valid for '#pragma omp taskloop'\" } */"}, {"sha": "17cc8b5ce0f592b854492e8c264c1fac048467c7", "filename": "gcc/testsuite/c-c++-common/gomp/order-5.c", "status": "added", "additions": 101, "deletions": 0, "changes": 101, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-5.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -0,0 +1,101 @@\n+void\n+f1 (int *a)\n+{\n+  int i;\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp simd order ( reproducible : concurrent )\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp for simd order(reproducible :concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+}\n+\n+void\n+f2 (int *a)\n+{\n+  int i;\n+  #pragma omp parallel for order(reproducible: concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp parallel for simd order (reproducible:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams distribute parallel for order(reproducible:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams distribute parallel for simd order(reproducible:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams distribute order(reproducible:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams\n+  {\n+    #pragma omp distribute parallel for order(reproducible:concurrent)\n+    for (i = 0; i < 128; i++)\n+      a[i]++;\n+    #pragma omp distribute parallel for simd order(reproducible:concurrent)\n+    for (i = 0; i < 128; i++)\n+      a[i]++;\n+    #pragma omp distribute order(reproducible:concurrent)\n+    for (i = 0; i < 128; i++)\n+      a[i]++;\n+  }\n+  #pragma omp taskloop simd order (reproducible:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+}\n+\n+void\n+f3 (int *a)\n+{\n+  int i;\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp simd order ( unconstrained : concurrent )\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp for simd order(unconstrained :concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+}\n+\n+void\n+f4 (int *a)\n+{\n+  int i;\n+  #pragma omp parallel for order(unconstrained: concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp parallel for simd order (unconstrained:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams distribute parallel for order(unconstrained:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams distribute parallel for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams distribute order(unconstrained:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+  #pragma omp teams\n+  {\n+    #pragma omp distribute parallel for order(unconstrained:concurrent)\n+    for (i = 0; i < 128; i++)\n+      a[i]++;\n+    #pragma omp distribute parallel for simd order(unconstrained:concurrent)\n+    for (i = 0; i < 128; i++)\n+      a[i]++;\n+    #pragma omp distribute order(unconstrained:concurrent)\n+    for (i = 0; i < 128; i++)\n+      a[i]++;\n+  }\n+  #pragma omp taskloop simd order (unconstrained:concurrent)\n+  for (i = 0; i < 128; i++)\n+    a[i]++;\n+}"}, {"sha": "2127830e247f56d74f17f17b039ddcc3f0c468c2", "filename": "gcc/testsuite/c-c++-common/gomp/order-6.c", "status": "added", "additions": 412, "deletions": 0, "changes": 412, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-6.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-6.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Forder-6.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -0,0 +1,412 @@\n+void foo (void);\n+int v;\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+int omp_get_thread_num (void);\n+int omp_get_num_threads (void);\n+int omp_target_is_present (const void *, int);\n+int omp_get_cancellation (void);\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+void\n+f1 (int *a)\n+{\n+  int i;\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp parallel\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp simd\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp critical\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp ordered simd\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      v++;\n+    }\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic read\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      a[i] = v;\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic write\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      v = a[i];\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_thread_num ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_thread_num\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_num_threads ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_num_threads\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_target_is_present (a + i, 0);\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_target_is_present\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_cancellation ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_cancellation\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+}\n+\n+void\n+f2 (int *a)\n+{\n+  int i;\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp parallel\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp simd\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp critical\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp ordered simd\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      v++;\n+    }\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic read\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      a[i] = v;\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic write\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      v = a[i];\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_thread_num ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_thread_num\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_num_threads ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_num_threads\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_target_is_present (a + i, 0);\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_target_is_present\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for simd order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_cancellation ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_cancellation\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+}\n+\n+void\n+f3 (int *a)\n+{\n+  int i;\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp parallel\n+      foo ();\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp simd\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp critical\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp ordered simd\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      v++;\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic read\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      a[i] = v;\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic write\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      v = a[i];\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp task\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      a[i]++;\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp taskloop\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_thread_num ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_thread_num\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_num_threads ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_num_threads\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_target_is_present (a + i, 0);\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_target_is_present\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for order(reproducible:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_cancellation ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_cancellation\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+}\n+\n+void\n+f4 (int *a)\n+{\n+  int i;\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp parallel\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp simd\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp critical\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp ordered simd\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      v++;\n+    }\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic read\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      a[i] = v;\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic write\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      v = a[i];\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_thread_num ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_thread_num\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_num_threads ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_num_threads\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_target_is_present (a + i, 0);\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_target_is_present\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_cancellation ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_cancellation\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+}\n+\n+void\n+f5 (int *a)\n+{\n+  int i;\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp parallel\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp simd\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp critical\t\t/* { dg-error \"OpenMP constructs other than 'ordered simd', 'simd', 'loop' or 'atomic' may not be nested inside 'simd' region\" } */\n+      foo ();\n+    }\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp ordered simd\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      v++;\n+    }\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic read\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      a[i] = v;\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic write\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      v = a[i];\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_thread_num ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_thread_num\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_num_threads ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_num_threads\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_target_is_present (a + i, 0);\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_target_is_present\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for simd order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_cancellation ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_cancellation\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+}\n+\n+void\n+f6 (int *a)\n+{\n+  int i;\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp parallel\n+      foo ();\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp simd\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp critical\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp ordered simd\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      foo ();\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      v++;\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic read\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      a[i] = v;\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp atomic write\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c++ } } */\n+      v = a[i];\t\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" \"\" { target c } } */\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      #pragma omp task\t\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      a[i]++;\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    {\n+      int j;\n+      #pragma omp taskloop\t\t/* { dg-error \"OpenMP constructs other than 'parallel', 'loop' or 'simd' may not be nested inside a region with the 'order\\\\(concurrent\\\\)' clause\" } */\n+      for (j = 0; j < 64; j++)\n+\ta[64 * i + j] = i + j;\n+    }\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_thread_num ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_thread_num\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_num_threads ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_num_threads\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_target_is_present (a + i, 0);\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_target_is_present\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+  #pragma omp for order(unconstrained:concurrent)\n+  for (i = 0; i < 64; i++)\n+    a[i] += omp_get_cancellation ();\t/* { dg-error \"OpenMP runtime API call '\\[^\\n\\r]*omp_get_cancellation\\[^\\n\\r]*' in a region with 'order\\\\(concurrent\\\\)' clause\" } */\n+}"}, {"sha": "2a5f2cf63234415b513c12d4839074311ba9db37", "filename": "gcc/testsuite/g++.dg/gomp/attrs-1.C", "status": "modified", "additions": 36, "deletions": 7, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fgomp%2Fattrs-1.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fgomp%2Fattrs-1.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fgomp%2Fattrs-1.C?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -63,7 +63,7 @@ foo (int d, int m, int i1, int i2, int p, int *idp, int s,\n     ll++;\n   [[omp::directive (distribute\n     private (p) firstprivate (f) collapse(1) dist_schedule(static, 16)\n-    allocate (omp_default_mem_alloc:f))]]\n+    allocate (omp_default_mem_alloc:f) order(concurrent))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n }\n@@ -85,14 +85,27 @@ baz (int d, int m, int i1, int i2, int p, int *idp, int s,\n   [[omp::directive (distribute parallel for\n     private (p) firstprivate (f) collapse(1) dist_schedule(static, 16)\n     if (parallel: i2) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread)\n-    lastprivate (l) schedule(static, 4) copyin(t) order(concurrent) allocate (p))]]\n+    lastprivate (l) schedule(static, 4) copyin(t) allocate (p))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n+  [[omp::directive (distribute parallel for\n+    private (p) firstprivate (f) collapse(1) dist_schedule(static, 16)\n+    if (parallel: i2) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread)\n+    lastprivate (l) schedule(static, 4) order(concurrent) allocate (p))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n   [[omp::directive (distribute parallel for simd\n     private (p) firstprivate (f) collapse(1) dist_schedule(static, 16)\n     if (parallel: i2) if(simd: i1) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread)\n     lastprivate (l) schedule(static, 4) nontemporal(ntm)\n-    safelen(8) simdlen(4) aligned(q: 32) copyin(t) order(concurrent) allocate (f))]]\n+    safelen(8) simdlen(4) aligned(q: 32) copyin(t) allocate (f))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n+  [[omp::directive (distribute parallel for simd\n+    private (p) firstprivate (f) collapse(1) dist_schedule(static, 16)\n+    if (parallel: i2) if(simd: i1) default(shared) shared(s) reduction(+:r) num_threads (nth) proc_bind(spread)\n+    lastprivate (l) schedule(static, 4) nontemporal(ntm)\n+    safelen(8) simdlen(4) aligned(q: 32) order(concurrent) allocate (f))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n   [[omp::directive (distribute simd\n@@ -207,7 +220,7 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n     ;\n   [[omp::sequence (omp::directive (target teams distribute\n     device(d) map (tofrom: m) if (target: i1) private (p) firstprivate (f) defaultmap(tofrom: scalar) is_device_ptr (idp)\n-    shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl)\n+    shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl) order(concurrent)\n     collapse(1) dist_schedule(static, 16) nowait depend(inout: dd[0]) allocate (omp_default_mem_alloc:f) in_reduction(+:r2)))]]\n   for (int i = 0; i < 64; i++)\n     ;\n@@ -292,7 +305,7 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n   [[omp::sequence (directive (target nowait depend(inout: dd[0]) in_reduction(+:r2)),\n     directive (teams distribute\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl)\n-    collapse(1) dist_schedule(static, 16) allocate (omp_default_mem_alloc: f)))]]\n+    collapse(1) dist_schedule(static, 16) allocate (omp_default_mem_alloc: f) order(concurrent)))]]\n   for (int i = 0; i < 64; i++)\n     ;\n   [[omp::directive (teams\n@@ -327,20 +340,36 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n     ll++;\n   [[omp::directive (teams distribute parallel for\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl)\n-    collapse(1) dist_schedule(static, 16) order(concurrent)\n+    collapse(1) dist_schedule(static, 16)\n     if (parallel: i2) num_threads (nth) proc_bind(spread)\n     lastprivate (l) schedule(static, 4) copyin(t) allocate (f))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n+  [[omp::directive (teams distribute parallel for\n+    private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl)\n+    collapse(1) dist_schedule(static, 16) order(concurrent)\n+    if (parallel: i2) num_threads (nth) proc_bind(spread)\n+    lastprivate (l) schedule(static, 4) allocate (f))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n   [[omp::directive (teams distribute parallel for simd\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl)\n     collapse(1) dist_schedule(static, 16)\n     if (parallel: i2) num_threads (nth) proc_bind(spread)\n-    lastprivate (l) schedule(static, 4) order(concurrent)\n+    lastprivate (l) schedule(static, 4)\n     safelen(8) simdlen(4) aligned(q: 32) if (simd: i3) nontemporal(ntm) copyin(t)\n     allocate (f))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n+  [[omp::directive (teams distribute parallel for simd\n+    private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl)\n+    collapse(1) dist_schedule(static, 16)\n+    if (parallel: i2) num_threads (nth) proc_bind(spread)\n+    lastprivate (l) schedule(static, 4) order(concurrent)\n+    safelen(8) simdlen(4) aligned(q: 32) if (simd: i3) nontemporal(ntm)\n+    allocate (f))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n   [[omp::directive (teams distribute simd\n     private(p) firstprivate (f) shared(s) default(shared) reduction(+:r) num_teams(nte) thread_limit(tl)\n     collapse(1) dist_schedule(static, 16) order(concurrent)"}, {"sha": "c00be7f1db71e46bac71cfb2b642e9190dbdd3d8", "filename": "gcc/testsuite/g++.dg/gomp/attrs-2.C", "status": "modified", "additions": 36, "deletions": 7, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fgomp%2Fattrs-2.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fgomp%2Fattrs-2.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fgomp%2Fattrs-2.C?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -63,7 +63,7 @@ foo (int d, int m, int i1, int i2, int p, int *idp, int s,\n     ll++;\n   [[omp::directive (distribute,\n     private (p),firstprivate (f),collapse(1),dist_schedule(static, 16),\n-    allocate (omp_default_mem_alloc:f))]]\n+    allocate (omp_default_mem_alloc:f),order(concurrent))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n }\n@@ -85,14 +85,27 @@ baz (int d, int m, int i1, int i2, int p, int *idp, int s,\n   [[omp::directive (distribute parallel for,\n     private (p),firstprivate (f),collapse(1),dist_schedule(static, 16),\n     if (parallel: i2),default(shared),shared(s),reduction(+:r),num_threads (nth),proc_bind(spread),\n-    lastprivate (l),schedule(static, 4),copyin(t),order(concurrent),allocate (p))]]\n+    lastprivate (l),schedule(static, 4),copyin(t),allocate (p))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n+  [[omp::directive (distribute parallel for,\n+    private (p),firstprivate (f),collapse(1),dist_schedule(static, 16),\n+    if (parallel: i2),default(shared),shared(s),reduction(+:r),num_threads (nth),proc_bind(spread),\n+    lastprivate (l),schedule(static, 4),order(concurrent),allocate (p))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n   [[omp::directive (distribute parallel for simd,\n     private (p),firstprivate (f),collapse(1),dist_schedule(static, 16),\n     if (parallel: i2),if(simd: i1),default(shared),shared(s),reduction(+:r),num_threads (nth),proc_bind(spread),\n     lastprivate (l),schedule(static, 4),nontemporal(ntm),\n-    safelen(8),simdlen(4),aligned(q: 32),copyin(t),order(concurrent),allocate (f))]]\n+    safelen(8),simdlen(4),aligned(q: 32),copyin(t),allocate (f))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n+  [[omp::directive (distribute parallel for simd,\n+    private (p),firstprivate (f),collapse(1),dist_schedule(static, 16),\n+    if (parallel: i2),if(simd: i1),default(shared),shared(s),reduction(+:r),num_threads (nth),proc_bind(spread),\n+    lastprivate (l),schedule(static, 4),nontemporal(ntm),\n+    safelen(8),simdlen(4),aligned(q: 32),order(concurrent),allocate (f))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n   [[omp::directive (distribute simd,\n@@ -207,7 +220,7 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n     ;\n   [[omp::sequence (omp::directive (target teams distribute,\n     device(d),map (tofrom: m),if (target: i1),private (p),firstprivate (f),defaultmap(tofrom: scalar),is_device_ptr (idp),\n-    shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),\n+    shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),order(concurrent),\n     collapse(1),dist_schedule(static, 16),nowait depend(inout: dd[0]),allocate (omp_default_mem_alloc:f),in_reduction(+:r2)))]]\n   for (int i = 0; i < 64; i++)\n     ;\n@@ -292,7 +305,7 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n   [[omp::sequence (directive (target, nowait,depend(inout: dd[0]),in_reduction(+:r2)),\n     directive (teams distribute,\n     private(p),firstprivate (f),shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),\n-    collapse(1),dist_schedule(static, 16),allocate (omp_default_mem_alloc: f)))]]\n+    collapse(1),dist_schedule(static, 16),allocate (omp_default_mem_alloc: f),order(concurrent)))]]\n   for (int i = 0; i < 64; i++)\n     ;\n   [[omp::directive (teams,\n@@ -327,20 +340,36 @@ bar (int d, int m, int i1, int i2, int i3, int p, int *idp, int s,\n     ll++;\n   [[omp::directive (teams distribute parallel for,\n     private(p),firstprivate (f),shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),\n-    collapse(1),dist_schedule(static, 16),order(concurrent),\n+    collapse(1),dist_schedule(static, 16),\n     if (parallel: i2),num_threads (nth),proc_bind(spread),\n     lastprivate (l),schedule(static, 4),copyin(t),allocate (f))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n+  [[omp::directive (teams distribute parallel for,\n+    private(p),firstprivate (f),shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),\n+    collapse(1),dist_schedule(static, 16),order(concurrent),\n+    if (parallel: i2),num_threads (nth),proc_bind(spread),\n+    lastprivate (l),schedule(static, 4),allocate (f))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n   [[omp::directive (teams distribute parallel for simd,\n     private(p),firstprivate (f),shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),\n     collapse(1),dist_schedule(static, 16),\n     if (parallel: i2),num_threads (nth),proc_bind(spread),\n-    lastprivate (l),schedule(static, 4),order(concurrent),\n+    lastprivate (l),schedule(static, 4),\n     safelen(8),simdlen(4),aligned(q: 32),if (simd: i3),nontemporal(ntm),copyin(t),\n     allocate (f))]]\n   for (int i = 0; i < 64; i++)\n     ll++;\n+  [[omp::directive (teams distribute parallel for simd,\n+    private(p),firstprivate (f),shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),\n+    collapse(1),dist_schedule(static, 16),\n+    if (parallel: i2),num_threads (nth),proc_bind(spread),\n+    lastprivate (l),schedule(static, 4),order(concurrent),\n+    safelen(8),simdlen(4),aligned(q: 32),if (simd: i3),nontemporal(ntm),\n+    allocate (f))]]\n+  for (int i = 0; i < 64; i++)\n+    ll++;\n   [[omp::directive (teams distribute simd,\n     private(p),firstprivate (f),shared(s),default(shared),reduction(+:r),num_teams(nte),thread_limit(tl),\n     collapse(1),dist_schedule(static, 16),order(concurrent),"}, {"sha": "7de12f33fef8833890f84b4efa4216bd15af7895", "filename": "gcc/tree-pretty-print.c", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftree-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftree-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pretty-print.c?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -1149,7 +1149,10 @@ dump_omp_clause (pretty_printer *pp, tree clause, int spc, dump_flags_t flags)\n       break;\n \n     case OMP_CLAUSE_ORDER:\n-      pp_string (pp, \"order(concurrent)\");\n+      pp_string (pp, \"order(\");\n+      if (OMP_CLAUSE_ORDER_UNCONSTRAINED (clause))\n+\tpp_string (pp, \"unconstrained:\");\n+      pp_string (pp, \"concurrent)\");\n       break;\n \n     case OMP_CLAUSE_BIND:"}, {"sha": "091ad3d3777ab80932e40d1c90c8f86f47fbbcec", "filename": "gcc/tree.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9d8fcabd032b873bf3fe14ae8afd8970827c0cb/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=e9d8fcabd032b873bf3fe14ae8afd8970827c0cb", "patch": "@@ -1715,6 +1715,10 @@ class auto_suppress_location_wrappers\n #define OMP_CLAUSE_ORDERED_EXPR(NODE) \\\n   OMP_CLAUSE_OPERAND (OMP_CLAUSE_SUBCODE_CHECK (NODE, OMP_CLAUSE_ORDERED), 0)\n \n+/* True for unconstrained modifier on order(concurrent) clause.  */\n+#define OMP_CLAUSE_ORDER_UNCONSTRAINED(NODE) \\\n+  (OMP_CLAUSE_SUBCODE_CHECK (NODE, OMP_CLAUSE_ORDER)->base.public_flag)\n+\n #define OMP_CLAUSE_REDUCTION_CODE(NODE)\t\\\n   (OMP_CLAUSE_RANGE_CHECK (NODE, OMP_CLAUSE_REDUCTION, \\\n      OMP_CLAUSE_IN_REDUCTION)->omp_clause.subcode.reduction_code)"}]}