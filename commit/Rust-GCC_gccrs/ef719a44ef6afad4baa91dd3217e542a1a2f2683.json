{"sha": "ef719a44ef6afad4baa91dd3217e542a1a2f2683", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZWY3MTlhNDRlZjZhZmFkNGJhYTkxZGQzMjE3ZTU0MmExYTJmMjY4Mw==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2005-01-09T00:51:31Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2005-01-09T00:51:31Z"}, "message": "emmintrin.h (_mm_cvtsi128_si32): Move earlier.\n\n\t* config/i386/emmintrin.h (_mm_cvtsi128_si32): Move earlier.\n\t(_mm_cvtsi128_si64x): Likewise.\n\t(_mm_srl_epi64, _mm_srl_epi32, _mm_srl_epi16, _mm_sra_epi32,\n\t_mm_sra_epi16, _mm_sll_epi64, _mm_sll_epi32, _mm_sll_epi16): Use\n\tthe _mm_{srl,sll}i_foo counterpart, and _mm_cvtsi128_si32.\n\t* config/i386/i386-modes.def: Add V16HI, V32QI, V4DF, V8SF.\n\t* config/i386/i386-protos.h: Update.\n\t* config/i386/i386.c (print_operand): Add 'H'.\n\t(ix86_fixup_binary_operands): Split out from ...\n\t(ix86_expand_binary_operator): ... here.\n\t(ix86_fixup_binary_operands_no_copy): New.\n\t(ix86_expand_fp_absneg_operator): Handle vector mode results.\n\t(bdesc_2arg): Update names for sse{,2,3}_ prefixes.\n\t(ix86_init_mmx_sse_builtins): Remove *maskncmp* special cases.\n\t(safe_vector_operand): Use CONST0_RTX.\n\t(ix86_expand_binop_builtin): Use ix86_fixup_binary_operands.\n\t(ix86_expand_builtin): Merge CODE_FOR_sse2_maskmovdqu_rex64 and\n\tCODE_FOR_sse2_maskmovdqu.  Special case SSE version of MASKMOVDQU\n\texpansion.  Update names for sse{,2,3}_ prefixes.  Remove *maskncmp*\n\tspecial cases.\n\t* config/i386/i386.h (IX86_BUILTIN_CMPNGTSS): New.\n\t(IX86_BUILTIN_CMPNGESS): New.\n\t* config/i386/i386.md (UNSPEC_FIX_NOTRUNC): New.\n\t(attr type): Add sselog1.\n\t(attr unit, attr memory): Handle it.\n\t(movti, movti_internal, movti_rex64): Move near other integer moves.\n\t(movtf, movtf_internal): Move near other fp moves.\n\t(SSEMODE, SSEMODEI, vec_setv2df, vec_extractv2df, vec_initv2df,\n\tvec_setv4sf, vec_extractv4sf, vec_initv4sf, movv4sf, movv4sf_internal,\n\tmovv2df, movv2df_internal, mov<SSEMODEI>, mov<SSEMODEI>_internal,\n\tmovmisalign<SSEMODE>, sse_movups_1, sse_movmskps, sse_movntv4sf,\n\tsse_movhlps, sse_movlhps, sse_storehps, sse_loadhps, sse_storelps,\n\tsse_loadlps, sse_loadss, sse_loadss_1, sse_movss, sse_storess,\n\tsse_shufps, addv4sf3, vmaddv4sf3, subv4sf3, vmsubv4sf3, negv4sf2,\n\tmulv4sf3, vmmulv4sf3, divv4sf3, vmdivv4sf3, rcpv4sf2, vmrcpv4sf2,\n\trsqrtv4sf2, vmrsqrtv4sf2, sqrtv4sf2, vmsqrtv4sf2, sse_andv4sf3,\n\tsse_nandv4sf3, sse_iorv4sf3, sse_xorv4sf3, sse2_andv2df3,\n\tsse2_nandv2df3, sse2_iorv2df3, sse2_xorv2df3, sse2_andv2di3,\n\tsse2_nandv2di3, sse2_iorv2di3, sse2_xorv2di3, maskcmpv4sf3,\n\tvmmaskcmpv4sf3, sse_comi, sse_ucomi, sse_unpckhps, sse_unpcklps,\n\tsmaxv4sf3, vmsmaxv4sf3, sminv4sf3, vmsminv4sf3, cvtpi2ps, cvtps2pi,\n\tcvttps2pi, cvtsi2ss, cvtsi2ssq, cvtss2si, cvtss2siq, cvttss2si,\n\tcvttss2siq, addv2df3, vmaddv2df3, subv2df3, vmsubv2df3, mulv2df3,\n\tvmmulv2df3, divv2df3, vmdivv2df3, smaxv2df3, vmsmaxv2df3, sminv2df3,\n\tvmsminv2df3, sqrtv2df2, vmsqrtv2df2, maskcmpv2df3, vmmaskcmpv2df3,\n\tsse2_comi, sse2_ucomi, sse2_movmskpd, sse2_pmovmskb, sse2_maskmovdqu,\n\tsse2_maskmovdqu_rex64, sse2_movntv2df, sse2_movntv2di, sse2_movntsi,\n\tcvtdq2ps, cvtps2dq, cvttps2dq, cvtdq2pd, cvtpd2dq, cvttpd2dq,\n\tcvtpd2pi, cvttpd2pi, cvtpi2pd, cvtsd2si, cvtsd2siq, cvttsd2si,\n\tcvttsd2siq, cvtsi2sd, cvtsi2sdq, cvtsd2ss, cvtss2sd, cvtpd2ps,\n\tcvtps2pd, addv16qi3, addv8hi3, addv4si3, addv2di3, ssaddv16qi3,\n\tssaddv8hi3, usaddv16qi3, usaddv8hi3, subv16qi3, subv8hi3, subv4si3,\n\tsubv2di3, sssubv16qi3, sssubv8hi3, ussubv16qi3, ussubv8hi3, mulv8hi3,\n\tsmulv8hi3_highpart, umulv8hi3_highpart, sse2_umulsidi3,\n\tsse2_umulv2siv2di3, sse2_pmaddwd, sse2_uavgv16qi3, sse2_uavgv8hi3,\n\tsse2_psadbw, sse2_pinsrw, sse2_pextrw, sse2_pshufd, sse2_pshuflw,\n\tsse2_pshufhw, eqv16qi3, eqv8hi3, eqv4si3, gtv16qi3, gtv8hi3,\n\tgtv4si3, umaxv16qi3, smaxv8hi3, uminv16qi3, sminv8hi3, ashrv8hi3,\n\tashrv4si3, lshrv8hi3, lshrv4si3, lshrv2di3, ashlv8hi3, ashlv4si3,\n\tashlv2di3, sse2_ashlti3, sse2_lshrti3, sse2_unpckhpd, sse2_unpcklpd,\n\tsse2_packsswb, sse2_packssdw, sse2_packuswb, sse2_punpckhbw,\n\tsse2_punpckhwd, sse2_punpckhdq, sse2_punpcklbw, sse2_punpcklwd,\n\tsse2_punpckldq, sse2_punpcklqdq, sse2_punpckhqdq, sse2_movupd,\n\tsse2_movdqu, sse2_movdq2q, sse2_movdq2q_rex64, sse2_movq2dq,\n\tsse2_movq2dq_rex64, sse2_loadd, sse2_stored, sse2_storehpd,\n\tsse2_loadhpd, sse2_storelpd, sse2_loadlpd, sse2_movsd, sse2_loadsd,\n\tsse2_loadsd_1, sse2_storesd, sse2_shufpd, sse2_clflush, sse2_mfence,\n\tmfence_insn, sse2_lfence, lfence_insn, mwait, monitor, addsubv4sf3,\n\taddsubv2df3, haddv4sf3, haddv2df3, hsubv4sf3, hsubv2df3, movshdup,\n\tmovsldup, lddqu, loadddup, movddup): Move to sse.md.  Any with\n\tnon-optabs meanings renamed with an \"sse{,2,3}_\" prefix at the\n\tsame time.\n\t(SSEPUSH, push<SSEPUSH>): Remove.\n\t(MMXPUSH, push<MMXPUSH>): Remove.\n\t(sse_movaps, sse_movaps_1, sse_movups): Remove.\n\t(sse2_movapd, sse2_movdqa, sse2_movq): Remove.\n\t(sse2_andti3, sse2_nandti3, sse2_iorti3, sse2_xorti3): Remove.\n\t(sse_clrv4sf, sse_clrv2df, sse2_clrti): Remove.\n\t(maskncmpv4sf3, vmmaskncmpv4sf3): Remove.\n\t(maskncmpv2df3, vmmaskncmpv2df3): Remove.\n\t(ashrv8hi3_ti, ashrv4si3_ti, lshrv8hi3_ti, lshrv4si3_ti): Remove.\n\t(lshrv2di3_ti, ashlv8hi3_ti, ashlv4si3_ti, ashlv2di3_ti): Remove.\n\t* config/i386/athlon.md (athlon_sselog_load): Handle sselog1.\n\t(athlon_sselog_load_k8, athlon_sselog, athlon_sselog_k8): Likewise.\n\t* config/i386/ppro.md (ppro_sse_div_V4SF_load): Fix memory attr.\n\t(ppro_sse_log_V4SF_load): Similarly.  Handle sselog1.\n\t(ppro_sse_log_V4SF): Handle sselog1.\n\t* config/i386/predicates.md (const_0_to_1_operand): New.\n\t(const_0_to_255_mul_8_operand): New.\n\t(const_1_to_31_operand): Rename from const_int_1_31_operand.\n\t(const_2_to_3_operand, const_4_to_7_operand): New.\n\t* config/i386/sse.md: New file.\n\t(SSEMODE12, SSEMODE24, SSEMODE124, SSEMODE248, ssevecsize): New.\n\t(sse_movups): Rename from sse_movups_1.\n\t(sse_loadlss): Rename from sse_loadss_1.\n\t(andv4sf3, iorv4sf3, xorv4sf3, andv2df3): Remove the sse prefix\n\tfrom the name.\n\t(negv4sf2): Use ix86_expand_fp_absneg_operator.\n\t(absv4sf2, negv2df, absv2df): New.\n\t(addv4sf3): Add expander to call ix86_fixup_binary_operands_no_copy.\n\t(subv4sf3, mulv4sf3, divv4sf3, smaxv4sf3, sminv4sf3, andv4sf3,\n\tiorv4sf3, xorv4sf3, addv2df3, subv2df3, mulv2df3, divv2df3,\n\tsmaxv2df3, sminv2df3, andv2df3, iorv2df3, xorv2df3, mulv8hi3,\n\tumaxv16qi3, smaxv8hi3, uminv16qi3, sminv8hi3): Likewise.\n\t(sse3_addsubv4sf3): Model correctly.\n\tsse3_haddv4sf3, sse3_hsubv4sf3, sse3_addsubv2df3, sse3_haddv2df3,\n\tsse3_hsubv2df3, sse2_ashlti3, sse2_lshrti3): Likewise.\n\t(sse_movhlps): Model with vec_select+vec_concat.\n\t(sse_movlhps, sse_unpckhps, sse_unpcklps, sse3_movshdup,\n\tsse3_movsldup, sse_shufps, sse_shufps_1, sse2_unpckhpd, sse3_movddup,\n\tsse2_unpcklpd, sse2_shufpd, sse2_shufpd_1, sse2_punpckhbw,\n\tsse2_punpcklbw, sse2_punpckhwd, sse2_punpcklwd, sse2_punpckhdq,\n\tsse2_punpckldq, sse2_punpckhqdq, sse2_punpcklqdq, sse2_pshufd,\n\tsse2_pshufd_1, sse2_pshuflw, sse2_pshuflw_1, sse2_pshufhw,\n\tsse2_pshufhw_1): Likewise.\n\t(neg<SSEMODEI>2, one_cmpl<SSEMODEI>2): New.\n\t(add<SSEMODEI>3, sse2_ssadd<SSEMODE12>3, sse2_usadd<SSEMODE12>3,\n\tsub<SSEMODEI>3, sse2_sssub<SSEMODE12>3, sse2_ussub<SSEMODE12>3,\n\tashr<SSEMODE24>3, lshr<SSEMODE248>3, sse2_eq<SSEMODE124>3,\n\tsse2_gt<SSEMODDE124>3, and<SSEMODEI>3, sse_nand<SSEMODEI>3,\n\tior<SSEMODEI>3, xor<SSEMODEI>3): Macroize from existing patterns.\n\t(addv4sf3, sse_vmaddv4sf3, mulv4sf3, sse_vmmulv4sf3, smaxv4sf3,\n\tsse_vmsmaxv4sf3, sminv4sf3, sse_vmsminv4sf3, addv2df3, sse2_vmaddv2df3,\n\tmulv2df3, sse2_vmmulv2df3, smaxv2df3, sse2_vmsmaxv2df3, sminv2df3,\n\tsse2_vmsminv2df3, umaxv16qi3, smaxv8hi3, uminv16qi3\n\tsminv8hi3): Mark commutative\n\toperands.  Use ix86_binary_operator_ok.\n\t(sse_unpckhps, sse_unpcklps, sse2_packsswb, sse2_packssdw,\n\tsse2_packuswb, sse2_punpckhbw, sse2_punpcklbw, sse2_punpckhwd,\n\tsse2_punpcklwd, sse2_punpckhdq, sse2_punpckldq, sse2_punpckhqdq,\n\tsse2_punpcklqdq): Allow operand2 in memory.\n\t(sse_movhlps, sse_movlhps, sse2_unpckhpd, sse2_unpcklpd\n\tsse2_movsd): Add memory alternatives.\n\t(sse_storelps): Turn expander into an insn; split after reload.\n\t(sse_storess, sse2_loadhpd, sse2_loadlpd): Add non-xmm inputs.\n\t(sse2_storehpd, sse2_storelpd): Add non-xmm outputs.\n\nFrom-SVN: r93101", "tree": {"sha": "ef51b7b547c8dc8f2858a16968104ce392cb7ee1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ef51b7b547c8dc8f2858a16968104ce392cb7ee1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ef719a44ef6afad4baa91dd3217e542a1a2f2683", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ef719a44ef6afad4baa91dd3217e542a1a2f2683", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ef719a44ef6afad4baa91dd3217e542a1a2f2683", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ef719a44ef6afad4baa91dd3217e542a1a2f2683/comments", "author": null, "committer": null, "parents": [{"sha": "a7e53bbf01c7b3301f12f7efcd79ce4e6e36ee2e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a7e53bbf01c7b3301f12f7efcd79ce4e6e36ee2e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a7e53bbf01c7b3301f12f7efcd79ce4e6e36ee2e"}], "stats": {"total": 9597, "additions": 4911, "deletions": 4686}, "files": [{"sha": "5238e1e32764c96703732c686cfd486a2362067d", "filename": "gcc/ChangeLog", "status": "modified", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -1,3 +1,142 @@\n+2005-01-08  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/i386/emmintrin.h (_mm_cvtsi128_si32): Move earlier.\n+\t(_mm_cvtsi128_si64x): Likewise.\n+\t(_mm_srl_epi64, _mm_srl_epi32, _mm_srl_epi16, _mm_sra_epi32,\n+\t_mm_sra_epi16, _mm_sll_epi64, _mm_sll_epi32, _mm_sll_epi16): Use\n+\tthe _mm_{srl,sll}i_foo counterpart, and _mm_cvtsi128_si32.\n+\t* config/i386/i386-modes.def: Add V16HI, V32QI, V4DF, V8SF.\n+\t* config/i386/i386-protos.h: Update.\n+\t* config/i386/i386.c (print_operand): Add 'H'.\n+\t(ix86_fixup_binary_operands): Split out from ...\n+\t(ix86_expand_binary_operator): ... here.\n+\t(ix86_fixup_binary_operands_no_copy): New.\n+\t(ix86_expand_fp_absneg_operator): Handle vector mode results.\n+\t(bdesc_2arg): Update names for sse{,2,3}_ prefixes.\n+\t(ix86_init_mmx_sse_builtins): Remove *maskncmp* special cases.\n+\t(safe_vector_operand): Use CONST0_RTX.\n+\t(ix86_expand_binop_builtin): Use ix86_fixup_binary_operands.\n+\t(ix86_expand_builtin): Merge CODE_FOR_sse2_maskmovdqu_rex64 and\n+\tCODE_FOR_sse2_maskmovdqu.  Special case SSE version of MASKMOVDQU\n+\texpansion.  Update names for sse{,2,3}_ prefixes.  Remove *maskncmp*\n+\tspecial cases.\n+\t* config/i386/i386.h (IX86_BUILTIN_CMPNGTSS): New.\n+\t(IX86_BUILTIN_CMPNGESS): New.\n+\t* config/i386/i386.md (UNSPEC_FIX_NOTRUNC): New.\n+\t(attr type): Add sselog1.\n+\t(attr unit, attr memory): Handle it.\n+\t(movti, movti_internal, movti_rex64): Move near other integer moves.\n+\t(movtf, movtf_internal): Move near other fp moves.\n+\t(SSEMODE, SSEMODEI, vec_setv2df, vec_extractv2df, vec_initv2df,\n+\tvec_setv4sf, vec_extractv4sf, vec_initv4sf, movv4sf, movv4sf_internal,\n+\tmovv2df, movv2df_internal, mov<SSEMODEI>, mov<SSEMODEI>_internal, \n+\tmovmisalign<SSEMODE>, sse_movups_1, sse_movmskps, sse_movntv4sf,\n+\tsse_movhlps, sse_movlhps, sse_storehps, sse_loadhps, sse_storelps,\n+\tsse_loadlps, sse_loadss, sse_loadss_1, sse_movss, sse_storess,\n+\tsse_shufps, addv4sf3, vmaddv4sf3, subv4sf3, vmsubv4sf3, negv4sf2,\n+\tmulv4sf3, vmmulv4sf3, divv4sf3, vmdivv4sf3, rcpv4sf2, vmrcpv4sf2,\n+\trsqrtv4sf2, vmrsqrtv4sf2, sqrtv4sf2, vmsqrtv4sf2, sse_andv4sf3,\n+\tsse_nandv4sf3, sse_iorv4sf3, sse_xorv4sf3, sse2_andv2df3, \n+\tsse2_nandv2df3, sse2_iorv2df3, sse2_xorv2df3, sse2_andv2di3, \n+\tsse2_nandv2di3, sse2_iorv2di3, sse2_xorv2di3, maskcmpv4sf3, \n+\tvmmaskcmpv4sf3, sse_comi, sse_ucomi, sse_unpckhps, sse_unpcklps,\n+\tsmaxv4sf3, vmsmaxv4sf3, sminv4sf3, vmsminv4sf3, cvtpi2ps, cvtps2pi,\n+\tcvttps2pi, cvtsi2ss, cvtsi2ssq, cvtss2si, cvtss2siq, cvttss2si,\n+\tcvttss2siq, addv2df3, vmaddv2df3, subv2df3, vmsubv2df3, mulv2df3,\n+\tvmmulv2df3, divv2df3, vmdivv2df3, smaxv2df3, vmsmaxv2df3, sminv2df3,\n+\tvmsminv2df3, sqrtv2df2, vmsqrtv2df2, maskcmpv2df3, vmmaskcmpv2df3,\n+\tsse2_comi, sse2_ucomi, sse2_movmskpd, sse2_pmovmskb, sse2_maskmovdqu,\n+\tsse2_maskmovdqu_rex64, sse2_movntv2df, sse2_movntv2di, sse2_movntsi,\n+\tcvtdq2ps, cvtps2dq, cvttps2dq, cvtdq2pd, cvtpd2dq, cvttpd2dq,\n+\tcvtpd2pi, cvttpd2pi, cvtpi2pd, cvtsd2si, cvtsd2siq, cvttsd2si,\n+\tcvttsd2siq, cvtsi2sd, cvtsi2sdq, cvtsd2ss, cvtss2sd, cvtpd2ps,\n+\tcvtps2pd, addv16qi3, addv8hi3, addv4si3, addv2di3, ssaddv16qi3,\n+\tssaddv8hi3, usaddv16qi3, usaddv8hi3, subv16qi3, subv8hi3, subv4si3,\n+\tsubv2di3, sssubv16qi3, sssubv8hi3, ussubv16qi3, ussubv8hi3, mulv8hi3,\n+\tsmulv8hi3_highpart, umulv8hi3_highpart, sse2_umulsidi3,\n+\tsse2_umulv2siv2di3, sse2_pmaddwd, sse2_uavgv16qi3, sse2_uavgv8hi3,\n+\tsse2_psadbw, sse2_pinsrw, sse2_pextrw, sse2_pshufd, sse2_pshuflw,\n+\tsse2_pshufhw, eqv16qi3, eqv8hi3, eqv4si3, gtv16qi3, gtv8hi3, \n+\tgtv4si3, umaxv16qi3, smaxv8hi3, uminv16qi3, sminv8hi3, ashrv8hi3,\n+\tashrv4si3, lshrv8hi3, lshrv4si3, lshrv2di3, ashlv8hi3, ashlv4si3,\n+\tashlv2di3, sse2_ashlti3, sse2_lshrti3, sse2_unpckhpd, sse2_unpcklpd,\n+\tsse2_packsswb, sse2_packssdw, sse2_packuswb, sse2_punpckhbw, \n+\tsse2_punpckhwd, sse2_punpckhdq, sse2_punpcklbw, sse2_punpcklwd,\n+\tsse2_punpckldq, sse2_punpcklqdq, sse2_punpckhqdq, sse2_movupd,\n+\tsse2_movdqu, sse2_movdq2q, sse2_movdq2q_rex64, sse2_movq2dq, \n+\tsse2_movq2dq_rex64, sse2_loadd, sse2_stored, sse2_storehpd,\n+\tsse2_loadhpd, sse2_storelpd, sse2_loadlpd, sse2_movsd, sse2_loadsd,\n+\tsse2_loadsd_1, sse2_storesd, sse2_shufpd, sse2_clflush, sse2_mfence,\n+\tmfence_insn, sse2_lfence, lfence_insn, mwait, monitor, addsubv4sf3,\n+\taddsubv2df3, haddv4sf3, haddv2df3, hsubv4sf3, hsubv2df3, movshdup,\n+\tmovsldup, lddqu, loadddup, movddup): Move to sse.md.  Any with\n+\tnon-optabs meanings renamed with an \"sse{,2,3}_\" prefix at the\n+\tsame time.\n+\t(SSEPUSH, push<SSEPUSH>): Remove.\n+\t(MMXPUSH, push<MMXPUSH>): Remove.\n+\t(sse_movaps, sse_movaps_1, sse_movups): Remove.\n+\t(sse2_movapd, sse2_movdqa, sse2_movq): Remove.\n+\t(sse2_andti3, sse2_nandti3, sse2_iorti3, sse2_xorti3): Remove.\n+\t(sse_clrv4sf, sse_clrv2df, sse2_clrti): Remove.\n+\t(maskncmpv4sf3, vmmaskncmpv4sf3): Remove.\n+\t(maskncmpv2df3, vmmaskncmpv2df3): Remove.\n+\t(ashrv8hi3_ti, ashrv4si3_ti, lshrv8hi3_ti, lshrv4si3_ti): Remove.\n+\t(lshrv2di3_ti, ashlv8hi3_ti, ashlv4si3_ti, ashlv2di3_ti): Remove.\n+\t* config/i386/athlon.md (athlon_sselog_load): Handle sselog1.\n+\t(athlon_sselog_load_k8, athlon_sselog, athlon_sselog_k8): Likewise.\n+\t* config/i386/ppro.md (ppro_sse_div_V4SF_load): Fix memory attr.\n+\t(ppro_sse_log_V4SF_load): Similarly.  Handle sselog1.\n+\t(ppro_sse_log_V4SF): Handle sselog1.\n+\t* config/i386/predicates.md (const_0_to_1_operand): New.\n+\t(const_0_to_255_mul_8_operand): New.\n+\t(const_1_to_31_operand): Rename from const_int_1_31_operand.\n+\t(const_2_to_3_operand, const_4_to_7_operand): New.\n+\t* config/i386/sse.md: New file.\n+\t(SSEMODE12, SSEMODE24, SSEMODE124, SSEMODE248, ssevecsize): New.\n+\t(sse_movups): Rename from sse_movups_1.\n+\t(sse_loadlss): Rename from sse_loadss_1.\n+\t(andv4sf3, iorv4sf3, xorv4sf3, andv2df3): Remove the sse prefix\n+\tfrom the name.\n+\t(negv4sf2): Use ix86_expand_fp_absneg_operator.\n+\t(absv4sf2, negv2df, absv2df): New.\n+\t(addv4sf3): Add expander to call ix86_fixup_binary_operands_no_copy.\n+\t(subv4sf3, mulv4sf3, divv4sf3, smaxv4sf3, sminv4sf3, andv4sf3,\n+\tiorv4sf3, xorv4sf3, addv2df3, subv2df3, mulv2df3, divv2df3,\n+\tsmaxv2df3, sminv2df3, andv2df3, iorv2df3, xorv2df3, mulv8hi3,\n+\tumaxv16qi3, smaxv8hi3, uminv16qi3, sminv8hi3): Likewise.\n+\t(sse3_addsubv4sf3): Model correctly.\n+\tsse3_haddv4sf3, sse3_hsubv4sf3, sse3_addsubv2df3, sse3_haddv2df3,\n+\tsse3_hsubv2df3, sse2_ashlti3, sse2_lshrti3): Likewise.\n+\t(sse_movhlps): Model with vec_select+vec_concat.\n+\t(sse_movlhps, sse_unpckhps, sse_unpcklps, sse3_movshdup, \n+\tsse3_movsldup, sse_shufps, sse_shufps_1, sse2_unpckhpd, sse3_movddup,\n+\tsse2_unpcklpd, sse2_shufpd, sse2_shufpd_1, sse2_punpckhbw,\n+\tsse2_punpcklbw, sse2_punpckhwd, sse2_punpcklwd, sse2_punpckhdq,\n+\tsse2_punpckldq, sse2_punpckhqdq, sse2_punpcklqdq, sse2_pshufd,\n+\tsse2_pshufd_1, sse2_pshuflw, sse2_pshuflw_1, sse2_pshufhw, \n+\tsse2_pshufhw_1): Likewise.\n+\t(neg<SSEMODEI>2, one_cmpl<SSEMODEI>2): New.\n+\t(add<SSEMODEI>3, sse2_ssadd<SSEMODE12>3, sse2_usadd<SSEMODE12>3,\n+\tsub<SSEMODEI>3, sse2_sssub<SSEMODE12>3, sse2_ussub<SSEMODE12>3,\n+\tashr<SSEMODE24>3, lshr<SSEMODE248>3, sse2_eq<SSEMODE124>3,\n+\tsse2_gt<SSEMODDE124>3, and<SSEMODEI>3, sse_nand<SSEMODEI>3,\n+\tior<SSEMODEI>3, xor<SSEMODEI>3): Macroize from existing patterns.\t\n+\t(addv4sf3, sse_vmaddv4sf3, mulv4sf3, sse_vmmulv4sf3, smaxv4sf3,\n+\tsse_vmsmaxv4sf3, sminv4sf3, sse_vmsminv4sf3, addv2df3, sse2_vmaddv2df3,\n+\tmulv2df3, sse2_vmmulv2df3, smaxv2df3, sse2_vmsmaxv2df3, sminv2df3,\n+\tsse2_vmsminv2df3, umaxv16qi3, smaxv8hi3, uminv16qi3\n+\tsminv8hi3): Mark commutative\n+\toperands.  Use ix86_binary_operator_ok.\n+\t(sse_unpckhps, sse_unpcklps, sse2_packsswb, sse2_packssdw,\n+\tsse2_packuswb, sse2_punpckhbw, sse2_punpcklbw, sse2_punpckhwd,\n+\tsse2_punpcklwd, sse2_punpckhdq, sse2_punpckldq, sse2_punpckhqdq,\n+\tsse2_punpcklqdq): Allow operand2 in memory.\n+\t(sse_movhlps, sse_movlhps, sse2_unpckhpd, sse2_unpcklpd\n+\tsse2_movsd): Add memory alternatives.\n+\t(sse_storelps): Turn expander into an insn; split after reload.\n+\t(sse_storess, sse2_loadhpd, sse2_loadlpd): Add non-xmm inputs.\n+\t(sse2_storehpd, sse2_storelpd): Add non-xmm outputs.\n+\n 2005-01-08  Eric Botcazou  <ebotcazou@libertysurf.fr>\n \n \t* configure.ac (DWARF-2 debug_line): Use objdump."}, {"sha": "1029a818196fc9d1fdd10a284d1e2397fcd566b8", "filename": "gcc/config/i386/athlon.md", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fathlon.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fathlon.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fathlon.md?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -565,21 +565,21 @@\n \n (define_insn_reservation \"athlon_sselog_load\" 3\n \t\t\t (and (eq_attr \"cpu\" \"athlon\")\n-\t\t\t      (and (eq_attr \"type\" \"sselog\")\n+\t\t\t      (and (eq_attr \"type\" \"sselog,sselog1\")\n \t\t\t\t   (eq_attr \"memory\" \"load\")))\n \t\t\t \"athlon-vector,athlon-fpload2,(athlon-fmul*2)\")\n (define_insn_reservation \"athlon_sselog_load_k8\" 5\n \t\t\t (and (eq_attr \"cpu\" \"k8\")\n-\t\t\t      (and (eq_attr \"type\" \"sselog\")\n+\t\t\t      (and (eq_attr \"type\" \"sselog,sselog1\")\n \t\t\t\t   (eq_attr \"memory\" \"load\")))\n \t\t\t \"athlon-double,athlon-fpload2k8,(athlon-fmul*2)\")\n (define_insn_reservation \"athlon_sselog\" 3\n \t\t\t (and (eq_attr \"cpu\" \"athlon\")\n-\t\t\t      (eq_attr \"type\" \"sselog\"))\n+\t\t\t      (eq_attr \"type\" \"sselog,sselog1\"))\n \t\t\t \"athlon-vector,athlon-fpsched,athlon-fmul*2\")\n (define_insn_reservation \"athlon_sselog_k8\" 3\n \t\t\t (and (eq_attr \"cpu\" \"k8\")\n-\t\t\t      (eq_attr \"type\" \"sselog\"))\n+\t\t\t      (eq_attr \"type\" \"sselog,sselog1\"))\n \t\t\t \"athlon-double,athlon-fpsched,athlon-fmul\")\n ;; ??? pcmp executes in addmul, probably not worthwhile to bother about that.\n (define_insn_reservation \"athlon_ssecmp_load\" 2"}, {"sha": "2d2b710d734e654830c7b086fe0494345a995a02", "filename": "gcc/config/i386/emmintrin.h", "status": "modified", "additions": 63, "deletions": 60, "changes": 123, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Femmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Femmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Femmintrin.h?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -177,6 +177,22 @@ _mm_storer_pd (double *__P, __m128d __A)\n   __builtin_ia32_storeapd (__P, __tmp);\n }\n \n+static __inline int\n+_mm_cvtsi128_si32 (__m128i __A)\n+{\n+  int __tmp;\n+  __builtin_ia32_stored (&__tmp, (__v4si)__A);\n+  return __tmp;\n+}\n+\n+#ifdef __x86_64__\n+static __inline long long\n+_mm_cvtsi128_si64x (__m128i __A)\n+{\n+  return __builtin_ia32_movdq2q ((__v2di)__A);\n+}\n+#endif\n+\n /* Sets the low DPFP value of A from the low value of B.  */\n static __inline __m128d\n _mm_move_sd (__m128d __A, __m128d __B)\n@@ -1157,115 +1173,118 @@ _mm_mul_epu32 (__m128i __A, __m128i __B)\n }\n \n static __inline __m128i\n-_mm_sll_epi16 (__m128i __A, __m128i __B)\n+_mm_slli_epi16 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_psllw128 ((__v8hi)__A, (__v2di)__B);\n+  return (__m128i)__builtin_ia32_psllwi128 ((__v8hi)__A, __B);\n }\n \n static __inline __m128i\n-_mm_sll_epi32 (__m128i __A, __m128i __B)\n+_mm_slli_epi32 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_pslld128 ((__v4si)__A, (__v2di)__B);\n+  return (__m128i)__builtin_ia32_pslldi128 ((__v4si)__A, __B);\n }\n \n static __inline __m128i\n-_mm_sll_epi64 (__m128i __A, __m128i __B)\n+_mm_slli_epi64 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_psllq128 ((__v2di)__A, (__v2di)__B);\n+  return (__m128i)__builtin_ia32_psllqi128 ((__v2di)__A, __B);\n }\n \n static __inline __m128i\n-_mm_sra_epi16 (__m128i __A, __m128i __B)\n+_mm_srai_epi16 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_psraw128 ((__v8hi)__A, (__v2di)__B);\n+  return (__m128i)__builtin_ia32_psrawi128 ((__v8hi)__A, __B);\n }\n \n static __inline __m128i\n-_mm_sra_epi32 (__m128i __A, __m128i __B)\n+_mm_srai_epi32 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_psrad128 ((__v4si)__A, (__v2di)__B);\n+  return (__m128i)__builtin_ia32_psradi128 ((__v4si)__A, __B);\n }\n \n-static __inline __m128i\n-_mm_srl_epi16 (__m128i __A, __m128i __B)\n+#if 0\n+static __m128i __attribute__((__always_inline__))\n+_mm_srli_si128 (__m128i __A, const int __B)\n {\n-  return (__m128i)__builtin_ia32_psrlw128 ((__v8hi)__A, (__v2di)__B);\n+  return ((__m128i)__builtin_ia32_psrldqi128 (__A, __B))\n }\n \n-static __inline __m128i\n-_mm_srl_epi32 (__m128i __A, __m128i __B)\n+static __m128i __attribute__((__always_inline__))\n+_mm_srli_si128 (__m128i __A, const int __B)\n {\n-  return (__m128i)__builtin_ia32_psrld128 ((__v4si)__A, (__v2di)__B);\n+  return ((__m128i)__builtin_ia32_pslldqi128 (__A, __B))\n }\n+#else\n+#define _mm_srli_si128(__A, __B) \\\n+  ((__m128i)__builtin_ia32_psrldqi128 (__A, (__B) * 8))\n+#define _mm_slli_si128(__A, __B) \\\n+  ((__m128i)__builtin_ia32_pslldqi128 (__A, (__B) * 8))\n+#endif\n \n static __inline __m128i\n-_mm_srl_epi64 (__m128i __A, __m128i __B)\n+_mm_srli_epi16 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_psrlq128 ((__v2di)__A, (__v2di)__B);\n+  return (__m128i)__builtin_ia32_psrlwi128 ((__v8hi)__A, __B);\n }\n \n static __inline __m128i\n-_mm_slli_epi16 (__m128i __A, int __B)\n+_mm_srli_epi32 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_psllwi128 ((__v8hi)__A, __B);\n+  return (__m128i)__builtin_ia32_psrldi128 ((__v4si)__A, __B);\n }\n \n static __inline __m128i\n-_mm_slli_epi32 (__m128i __A, int __B)\n+_mm_srli_epi64 (__m128i __A, int __B)\n {\n-  return (__m128i)__builtin_ia32_pslldi128 ((__v4si)__A, __B);\n+  return (__m128i)__builtin_ia32_psrlqi128 ((__v2di)__A, __B);\n }\n \n static __inline __m128i\n-_mm_slli_epi64 (__m128i __A, int __B)\n+_mm_sll_epi16 (__m128i __A, __m128i __B)\n {\n-  return (__m128i)__builtin_ia32_psllqi128 ((__v2di)__A, __B);\n+  return _mm_slli_epi16 (__A, _mm_cvtsi128_si32 (__B));\n }\n \n static __inline __m128i\n-_mm_srai_epi16 (__m128i __A, int __B)\n+_mm_sll_epi32 (__m128i __A, __m128i __B)\n {\n-  return (__m128i)__builtin_ia32_psrawi128 ((__v8hi)__A, __B);\n+  return _mm_slli_epi32 (__A, _mm_cvtsi128_si32 (__B));\n }\n \n static __inline __m128i\n-_mm_srai_epi32 (__m128i __A, int __B)\n+_mm_sll_epi64 (__m128i __A, __m128i __B)\n {\n-  return (__m128i)__builtin_ia32_psradi128 ((__v4si)__A, __B);\n+  return _mm_slli_epi64 (__A, _mm_cvtsi128_si32 (__B));\n }\n \n-#if 0\n-static __m128i __attribute__((__always_inline__))\n-_mm_srli_si128 (__m128i __A, const int __B)\n+static __inline __m128i\n+_mm_sra_epi16 (__m128i __A, __m128i __B)\n {\n-  return ((__m128i)__builtin_ia32_psrldqi128 (__A, __B))\n+  return _mm_srai_epi16 (__A, _mm_cvtsi128_si32 (__B));\n }\n \n-static __m128i __attribute__((__always_inline__))\n-_mm_srli_si128 (__m128i __A, const int __B)\n+static __inline __m128i\n+_mm_sra_epi32 (__m128i __A, __m128i __B)\n {\n-  return ((__m128i)__builtin_ia32_pslldqi128 (__A, __B))\n+  return _mm_srai_epi32 (__A, _mm_cvtsi128_si32 (__B));\n }\n-#endif\n-#define _mm_srli_si128(__A, __B) ((__m128i)__builtin_ia32_psrldqi128 (__A, __B))\n-#define _mm_slli_si128(__A, __B) ((__m128i)__builtin_ia32_pslldqi128 (__A, __B))\n \n static __inline __m128i\n-_mm_srli_epi16 (__m128i __A, int __B)\n+_mm_srl_epi16 (__m128i __A, __m128i __B)\n {\n-  return (__m128i)__builtin_ia32_psrlwi128 ((__v8hi)__A, __B);\n+  return _mm_srli_epi16 (__A, _mm_cvtsi128_si32 (__B));\n }\n \n static __inline __m128i\n-_mm_srli_epi32 (__m128i __A, int __B)\n+_mm_srl_epi32 (__m128i __A, __m128i __B)\n {\n-  return (__m128i)__builtin_ia32_psrldi128 ((__v4si)__A, __B);\n+  return _mm_srli_epi32 (__A, _mm_cvtsi128_si32 (__B));\n }\n \n static __inline __m128i\n-_mm_srli_epi64 (__m128i __A, int __B)\n+_mm_srl_epi64 (__m128i __A, __m128i __B)\n {\n-  return (__m128i)__builtin_ia32_psrlqi128 ((__v2di)__A, __B);\n+  return _mm_srli_epi64 (__A, _mm_cvtsi128_si32 (__B));\n }\n \n static __inline __m128i\n@@ -1470,22 +1489,6 @@ _mm_cvtsi64x_si128 (long long __A)\n }\n #endif\n \n-static __inline int\n-_mm_cvtsi128_si32 (__m128i __A)\n-{\n-  int __tmp;\n-  __builtin_ia32_stored (&__tmp, (__v4si)__A);\n-  return __tmp;\n-}\n-\n-#ifdef __x86_64__\n-static __inline long long\n-_mm_cvtsi128_si64x (__m128i __A)\n-{\n-  return __builtin_ia32_movdq2q ((__v2di)__A);\n-}\n-#endif\n-\n #endif /* __SSE2__  */\n \n #endif /* _EMMINTRIN_H_INCLUDED */"}, {"sha": "6a6e68d8b1fb7baff4cef479cf8a00f286a69fe3", "filename": "gcc/config/i386/i386-modes.def", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386-modes.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386-modes.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-modes.def?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -70,6 +70,10 @@ VECTOR_MODES (FLOAT, 8);      /*            V4HF V2SF */\n VECTOR_MODES (FLOAT, 16);     /*       V8HF V4SF V2DF */\n VECTOR_MODE (INT, DI, 4);     /*                 V4DI */\n VECTOR_MODE (INT, SI, 8);     /*                 V8SI */\n+VECTOR_MODE (INT, HI, 16);    /*                V16HI */\n+VECTOR_MODE (INT, QI, 32);    /*                V32QI */\n+VECTOR_MODE (FLOAT, DF, 4);   /*                 V4DF */\n+VECTOR_MODE (FLOAT, SF, 8);   /*                 V8SF */\n \n /* The symbol Pmode stands for one of the above machine modes (usually SImode).\n    The tm.h file specifies which one.  It is not a distinct mode.  */"}, {"sha": "5920c9f1fdd2380c2271b4cc686cb313ed994f4f", "filename": "gcc/config/i386/i386-protos.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-protos.h?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -126,6 +126,10 @@ extern void ix86_expand_clear (rtx);\n extern void ix86_expand_move (enum machine_mode, rtx[]);\n extern void ix86_expand_vector_move (enum machine_mode, rtx[]);\n extern void ix86_expand_vector_move_misalign (enum machine_mode, rtx[]);\n+extern rtx ix86_fixup_binary_operands (enum rtx_code,\n+\t\t\t\t       enum machine_mode, rtx[]);\n+extern void ix86_fixup_binary_operands_no_copy (enum rtx_code,\n+\t\t\t\t\t\tenum machine_mode, rtx[]);\n extern void ix86_expand_binary_operator (enum rtx_code,\n \t\t\t\t\t enum machine_mode, rtx[]);\n extern int ix86_binary_operator_ok (enum rtx_code, enum machine_mode, rtx[]);"}, {"sha": "7edd97c3c991624c31ed186060cdbec4f2fd9c0a", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 274, "deletions": 224, "changes": 498, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -6312,6 +6312,7 @@ get_some_local_dynamic_name_1 (rtx *px, void *data ATTRIBUTE_UNUSED)\n    P -- if PIC, print an @PLT suffix.\n    X -- don't print any sort of PIC '@' suffix for a symbol.\n    & -- print some in-use local-dynamic symbol name.\n+   H -- print a memory address offset by 8; used for sse high-parts\n  */\n \n void\n@@ -6539,6 +6540,13 @@ print_operand (FILE *file, rtx x, int code)\n #endif\n \t  put_condition_code (GET_CODE (x), GET_MODE (XEXP (x, 0)), 1, 1, file);\n \t  return;\n+\n+\tcase 'H':\n+\t  /* It doesn't actually matter what mode we use here, as we're\n+\t     only going to use this for printing.  */\n+\t  x = adjust_address_nv (x, DImode, 8);\n+\t  break;\n+\n \tcase '+':\n \t  {\n \t    rtx x;\n@@ -7714,16 +7722,16 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n }\n \n \n-/* Attempt to expand a binary operator.  Make the expansion closer to the\n-   actual machine, then just general_operand, which will allow 3 separate\n-   memory references (one output, two input) in a single insn.  */\n+/* Fix up OPERANDS to satisfy ix86_binary_operator_ok.  Return the\n+   destination to use for the operation.  If different from the true\n+   destination in operands[0], a copy operation will be required.  */\n \n-void\n-ix86_expand_binary_operator (enum rtx_code code, enum machine_mode mode,\n-\t\t\t     rtx operands[])\n+rtx\n+ix86_fixup_binary_operands (enum rtx_code code, enum machine_mode mode,\n+\t\t\t    rtx operands[])\n {\n   int matching_memory;\n-  rtx src1, src2, dst, op, clob;\n+  rtx src1, src2, dst;\n \n   dst = operands[0];\n   src1 = operands[1];\n@@ -7780,7 +7788,37 @@ ix86_expand_binary_operator (enum rtx_code code, enum machine_mode mode,\n \tsrc2 = force_reg (mode, src2);\n     }\n \n-  /* Emit the instruction.  */\n+  src1 = operands[1] = src1;\n+  src2 = operands[2] = src2;\n+  return dst;\n+}\n+\n+/* Similarly, but assume that the destination has already been\n+   set up properly.  */\n+\n+void\n+ix86_fixup_binary_operands_no_copy (enum rtx_code code,\n+\t\t\t\t    enum machine_mode mode, rtx operands[])\n+{\n+  rtx dst = ix86_fixup_binary_operands (code, mode, operands);\n+  gcc_assert (dst == operands[0]);\n+}\n+\n+/* Attempt to expand a binary operator.  Make the expansion closer to the\n+   actual machine, then just general_operand, which will allow 3 separate\n+   memory references (one output, two input) in a single insn.  */\n+\n+void\n+ix86_expand_binary_operator (enum rtx_code code, enum machine_mode mode,\n+\t\t\t     rtx operands[])\n+{\n+  rtx src1, src2, dst, op, clob;\n+\n+  dst = ix86_fixup_binary_operands (code, mode, operands);\n+  src1 = operands[1];\n+  src2 = operands[2];\n+\n+ /* Emit the instruction.  */\n \n   op = gen_rtx_SET (VOIDmode, dst, gen_rtx_fmt_ee (code, mode, src1, src2));\n   if (reload_in_progress)\n@@ -7916,13 +7954,28 @@ ix86_expand_fp_absneg_operator (enum rtx_code code, enum machine_mode mode,\n   rtx mask, set, use, clob, dst, src;\n   bool matching_memory;\n   bool use_sse = false;\n+  bool vector_mode = VECTOR_MODE_P (mode);\n+  enum machine_mode elt_mode = mode;\n+  enum machine_mode vec_mode = VOIDmode;\n \n+  if (vector_mode)\n+    {\n+      elt_mode = GET_MODE_INNER (mode);\n+      vec_mode = mode;\n+      use_sse = true;\n+    }\n   if (TARGET_SSE_MATH)\n     {\n       if (mode == SFmode)\n-\tuse_sse = true;\n+\t{\n+\t  use_sse = true;\n+\t  vec_mode = V4SFmode;\n+\t}\n       else if (mode == DFmode && TARGET_SSE2)\n-\tuse_sse = true;\n+\t{\n+\t  use_sse = true;\n+\t  vec_mode = V2DFmode;\n+\t}\n     }\n \n   /* NEG and ABS performed with SSE use bitwise mask operations.\n@@ -7931,9 +7984,10 @@ ix86_expand_fp_absneg_operator (enum rtx_code code, enum machine_mode mode,\n     {\n       HOST_WIDE_INT hi, lo;\n       int shift = 63;\n+      rtvec v;\n \n       /* Find the sign bit, sign extended to 2*HWI.  */\n-      if (mode == SFmode)\n+      if (elt_mode == SFmode)\n         lo = 0x80000000, hi = lo < 0;\n       else if (HOST_BITS_PER_WIDE_INT >= 64)\n         lo = (HOST_WIDE_INT)1 << shift, hi = -1;\n@@ -7948,15 +8002,32 @@ ix86_expand_fp_absneg_operator (enum rtx_code code, enum machine_mode mode,\n       /* Force this value into the low part of a fp vector constant.  */\n       mask = immed_double_const (lo, hi, mode == SFmode ? SImode : DImode);\n       mask = gen_lowpart (mode, mask);\n-      if (mode == SFmode)\n-        mask = gen_rtx_CONST_VECTOR (V4SFmode,\n-\t\t\t\t     gen_rtvec (4, mask, CONST0_RTX (SFmode),\n-\t\t\t\t\t\tCONST0_RTX (SFmode),\n-\t\t\t\t\t\tCONST0_RTX (SFmode)));\n-      else\n-        mask = gen_rtx_CONST_VECTOR (V2DFmode,\n-\t\t\t\t     gen_rtvec (2, mask, CONST0_RTX (DFmode)));\n-      mask = force_reg (GET_MODE (mask), mask);\n+\n+      switch (mode)\n+\t{\n+\tcase SFmode:\n+\t  v = gen_rtvec (4, mask, CONST0_RTX (SFmode),\n+\t\t\t CONST0_RTX (SFmode), CONST0_RTX (SFmode));\n+\t  break;\n+\n+\tcase DFmode:\n+\t  v = gen_rtvec (2, mask, CONST0_RTX (DFmode));\n+\t  break;\n+\n+\tcase V4SFmode:\n+\t  v = gen_rtvec (4, mask, mask, mask, mask);\n+\t  break;\n+\n+\tcase V4DFmode:\n+\t  v = gen_rtvec (2, mask, mask);\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+\n+      mask = gen_rtx_CONST_VECTOR (vec_mode, v);\n+      mask = force_reg (vec_mode, mask);\n     }\n   else\n     {\n@@ -7982,11 +8053,20 @@ ix86_expand_fp_absneg_operator (enum rtx_code code, enum machine_mode mode,\n   if (MEM_P (src) && !matching_memory)\n     src = force_reg (mode, src);\n \n-  set = gen_rtx_fmt_e (code, mode, src);\n-  set = gen_rtx_SET (VOIDmode, dst, set);\n-  use = gen_rtx_USE (VOIDmode, mask);\n-  clob = gen_rtx_CLOBBER (VOIDmode, gen_rtx_REG (CCmode, FLAGS_REG));\n-  emit_insn (gen_rtx_PARALLEL (VOIDmode, gen_rtvec (3, set, use, clob)));\n+  if (vector_mode)\n+    {\n+      set = gen_rtx_fmt_ee (code == NEG ? XOR : AND, mode, src, mask);\n+      set = gen_rtx_SET (VOIDmode, dst, set);\n+      emit_insn (set);\n+    }\n+  else\n+    {\n+      set = gen_rtx_fmt_e (code, mode, src);\n+      set = gen_rtx_SET (VOIDmode, dst, set);\n+      use = gen_rtx_USE (VOIDmode, mask);\n+      clob = gen_rtx_CLOBBER (VOIDmode, gen_rtx_REG (CCmode, FLAGS_REG));\n+      emit_insn (gen_rtx_PARALLEL (VOIDmode, gen_rtvec (3, set, use, clob)));\n+    }\n \n   if (dst != operands[0])\n     emit_move_insn (operands[0], dst);\n@@ -12128,45 +12208,49 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE, CODE_FOR_subv4sf3, \"__builtin_ia32_subps\", IX86_BUILTIN_SUBPS, 0, 0 },\n   { MASK_SSE, CODE_FOR_mulv4sf3, \"__builtin_ia32_mulps\", IX86_BUILTIN_MULPS, 0, 0 },\n   { MASK_SSE, CODE_FOR_divv4sf3, \"__builtin_ia32_divps\", IX86_BUILTIN_DIVPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_vmaddv4sf3,  \"__builtin_ia32_addss\", IX86_BUILTIN_ADDSS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_vmsubv4sf3,  \"__builtin_ia32_subss\", IX86_BUILTIN_SUBSS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_vmmulv4sf3,  \"__builtin_ia32_mulss\", IX86_BUILTIN_MULSS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_vmdivv4sf3,  \"__builtin_ia32_divss\", IX86_BUILTIN_DIVSS, 0, 0 },\n-\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpeqps\", IX86_BUILTIN_CMPEQPS, EQ, 0 },\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpltps\", IX86_BUILTIN_CMPLTPS, LT, 0 },\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpleps\", IX86_BUILTIN_CMPLEPS, LE, 0 },\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpgtps\", IX86_BUILTIN_CMPGTPS, LT,\n+  { MASK_SSE, CODE_FOR_sse_vmaddv4sf3,  \"__builtin_ia32_addss\", IX86_BUILTIN_ADDSS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmsubv4sf3,  \"__builtin_ia32_subss\", IX86_BUILTIN_SUBSS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmulv4sf3,  \"__builtin_ia32_mulss\", IX86_BUILTIN_MULSS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmdivv4sf3,  \"__builtin_ia32_divss\", IX86_BUILTIN_DIVSS, 0, 0 },\n+\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpeqps\", IX86_BUILTIN_CMPEQPS, EQ, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpltps\", IX86_BUILTIN_CMPLTPS, LT, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpleps\", IX86_BUILTIN_CMPLEPS, LE, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpgtps\", IX86_BUILTIN_CMPGTPS, LT,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpgeps\", IX86_BUILTIN_CMPGEPS, LE,\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpgeps\", IX86_BUILTIN_CMPGEPS, LE,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpunordps\", IX86_BUILTIN_CMPUNORDPS, UNORDERED, 0 },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpneqps\", IX86_BUILTIN_CMPNEQPS, EQ, 0 },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpnltps\", IX86_BUILTIN_CMPNLTPS, LT, 0 },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpnleps\", IX86_BUILTIN_CMPNLEPS, LE, 0 },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpngtps\", IX86_BUILTIN_CMPNGTPS, LT,\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpunordps\", IX86_BUILTIN_CMPUNORDPS, UNORDERED, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpneqps\", IX86_BUILTIN_CMPNEQPS, NE, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpnltps\", IX86_BUILTIN_CMPNLTPS, UNGE, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpnleps\", IX86_BUILTIN_CMPNLEPS, UNGT, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpngtps\", IX86_BUILTIN_CMPNGTPS, UNGE,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpngeps\", IX86_BUILTIN_CMPNGEPS, LE,\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpngeps\", IX86_BUILTIN_CMPNGEPS, UNGT,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpordps\", IX86_BUILTIN_CMPORDPS, UNORDERED, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskcmpv4sf3, \"__builtin_ia32_cmpeqss\", IX86_BUILTIN_CMPEQSS, EQ, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskcmpv4sf3, \"__builtin_ia32_cmpltss\", IX86_BUILTIN_CMPLTSS, LT, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskcmpv4sf3, \"__builtin_ia32_cmpless\", IX86_BUILTIN_CMPLESS, LE, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskcmpv4sf3, \"__builtin_ia32_cmpunordss\", IX86_BUILTIN_CMPUNORDSS, UNORDERED, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskncmpv4sf3, \"__builtin_ia32_cmpneqss\", IX86_BUILTIN_CMPNEQSS, EQ, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskncmpv4sf3, \"__builtin_ia32_cmpnltss\", IX86_BUILTIN_CMPNLTSS, LT, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskncmpv4sf3, \"__builtin_ia32_cmpnless\", IX86_BUILTIN_CMPNLESS, LE, 0 },\n-  { MASK_SSE, CODE_FOR_vmmaskncmpv4sf3, \"__builtin_ia32_cmpordss\", IX86_BUILTIN_CMPORDSS, UNORDERED, 0 },\n+  { MASK_SSE, CODE_FOR_sse_maskcmpv4sf3, \"__builtin_ia32_cmpordps\", IX86_BUILTIN_CMPORDPS, ORDERED, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpeqss\", IX86_BUILTIN_CMPEQSS, EQ, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpltss\", IX86_BUILTIN_CMPLTSS, LT, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpless\", IX86_BUILTIN_CMPLESS, LE, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpunordss\", IX86_BUILTIN_CMPUNORDSS, UNORDERED, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpneqss\", IX86_BUILTIN_CMPNEQSS, NE, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpnltss\", IX86_BUILTIN_CMPNLTSS, UNGE, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpnless\", IX86_BUILTIN_CMPNLESS, UNGT, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpngtss\", IX86_BUILTIN_CMPNGTSS, UNGE,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpngess\", IX86_BUILTIN_CMPNGESS, UNGT,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n+  { MASK_SSE, CODE_FOR_sse_vmmaskcmpv4sf3, \"__builtin_ia32_cmpordss\", IX86_BUILTIN_CMPORDSS, UNORDERED, 0 },\n \n   { MASK_SSE, CODE_FOR_sminv4sf3, \"__builtin_ia32_minps\", IX86_BUILTIN_MINPS, 0, 0 },\n   { MASK_SSE, CODE_FOR_smaxv4sf3, \"__builtin_ia32_maxps\", IX86_BUILTIN_MAXPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_vmsminv4sf3, \"__builtin_ia32_minss\", IX86_BUILTIN_MINSS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_vmsmaxv4sf3, \"__builtin_ia32_maxss\", IX86_BUILTIN_MAXSS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmsminv4sf3, \"__builtin_ia32_minss\", IX86_BUILTIN_MINSS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_vmsmaxv4sf3, \"__builtin_ia32_maxss\", IX86_BUILTIN_MAXSS, 0, 0 },\n \n-  { MASK_SSE, CODE_FOR_sse_andv4sf3, \"__builtin_ia32_andps\", IX86_BUILTIN_ANDPS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_andv4sf3, \"__builtin_ia32_andps\", IX86_BUILTIN_ANDPS, 0, 0 },\n   { MASK_SSE, CODE_FOR_sse_nandv4sf3,  \"__builtin_ia32_andnps\", IX86_BUILTIN_ANDNPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_sse_iorv4sf3, \"__builtin_ia32_orps\", IX86_BUILTIN_ORPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_sse_xorv4sf3,  \"__builtin_ia32_xorps\", IX86_BUILTIN_XORPS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_iorv4sf3, \"__builtin_ia32_orps\", IX86_BUILTIN_ORPS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_xorv4sf3,  \"__builtin_ia32_xorps\", IX86_BUILTIN_XORPS, 0, 0 },\n \n   { MASK_SSE, CODE_FOR_sse_movss,  \"__builtin_ia32_movss\", IX86_BUILTIN_MOVSS, 0, 0 },\n   { MASK_SSE, CODE_FOR_sse_movhlps,  \"__builtin_ia32_movhlps\", IX86_BUILTIN_MOVHLPS, 0, 0 },\n@@ -12229,9 +12313,9 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_MMX, CODE_FOR_mmx_packssdw, 0, IX86_BUILTIN_PACKSSDW, 0, 0 },\n   { MASK_MMX, CODE_FOR_mmx_packuswb, 0, IX86_BUILTIN_PACKUSWB, 0, 0 },\n \n-  { MASK_SSE, CODE_FOR_cvtpi2ps, 0, IX86_BUILTIN_CVTPI2PS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_cvtsi2ss, 0, IX86_BUILTIN_CVTSI2SS, 0, 0 },\n-  { MASK_SSE | MASK_64BIT, CODE_FOR_cvtsi2ssq, 0, IX86_BUILTIN_CVTSI642SS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_cvtpi2ps, 0, IX86_BUILTIN_CVTPI2PS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_cvtsi2ss, 0, IX86_BUILTIN_CVTSI2SS, 0, 0 },\n+  { MASK_SSE | MASK_64BIT, CODE_FOR_sse_cvtsi2ssq, 0, IX86_BUILTIN_CVTSI642SS, 0, 0 },\n \n   { MASK_MMX, CODE_FOR_ashlv4hi3, 0, IX86_BUILTIN_PSLLW, 0, 0 },\n   { MASK_MMX, CODE_FOR_ashlv4hi3, 0, IX86_BUILTIN_PSLLWI, 0, 0 },\n@@ -12260,45 +12344,45 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE2, CODE_FOR_subv2df3, \"__builtin_ia32_subpd\", IX86_BUILTIN_SUBPD, 0, 0 },\n   { MASK_SSE2, CODE_FOR_mulv2df3, \"__builtin_ia32_mulpd\", IX86_BUILTIN_MULPD, 0, 0 },\n   { MASK_SSE2, CODE_FOR_divv2df3, \"__builtin_ia32_divpd\", IX86_BUILTIN_DIVPD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_vmaddv2df3,  \"__builtin_ia32_addsd\", IX86_BUILTIN_ADDSD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_vmsubv2df3,  \"__builtin_ia32_subsd\", IX86_BUILTIN_SUBSD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmulv2df3,  \"__builtin_ia32_mulsd\", IX86_BUILTIN_MULSD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_vmdivv2df3,  \"__builtin_ia32_divsd\", IX86_BUILTIN_DIVSD, 0, 0 },\n-\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpeqpd\", IX86_BUILTIN_CMPEQPD, EQ, 0 },\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpltpd\", IX86_BUILTIN_CMPLTPD, LT, 0 },\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmplepd\", IX86_BUILTIN_CMPLEPD, LE, 0 },\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpgtpd\", IX86_BUILTIN_CMPGTPD, LT,\n+  { MASK_SSE2, CODE_FOR_sse2_vmaddv2df3,  \"__builtin_ia32_addsd\", IX86_BUILTIN_ADDSD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmsubv2df3,  \"__builtin_ia32_subsd\", IX86_BUILTIN_SUBSD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmulv2df3,  \"__builtin_ia32_mulsd\", IX86_BUILTIN_MULSD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmdivv2df3,  \"__builtin_ia32_divsd\", IX86_BUILTIN_DIVSD, 0, 0 },\n+\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpeqpd\", IX86_BUILTIN_CMPEQPD, EQ, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpltpd\", IX86_BUILTIN_CMPLTPD, LT, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmplepd\", IX86_BUILTIN_CMPLEPD, LE, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpgtpd\", IX86_BUILTIN_CMPGTPD, LT,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpgepd\", IX86_BUILTIN_CMPGEPD, LE,\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpgepd\", IX86_BUILTIN_CMPGEPD, LE,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpunordpd\", IX86_BUILTIN_CMPUNORDPD, UNORDERED, 0 },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpneqpd\", IX86_BUILTIN_CMPNEQPD, EQ, 0 },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpnltpd\", IX86_BUILTIN_CMPNLTPD, LT, 0 },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpnlepd\", IX86_BUILTIN_CMPNLEPD, LE, 0 },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpngtpd\", IX86_BUILTIN_CMPNGTPD, LT,\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpunordpd\", IX86_BUILTIN_CMPUNORDPD, UNORDERED, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpneqpd\", IX86_BUILTIN_CMPNEQPD, NE, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpnltpd\", IX86_BUILTIN_CMPNLTPD, UNGE, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpnlepd\", IX86_BUILTIN_CMPNLEPD, UNGT, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpngtpd\", IX86_BUILTIN_CMPNGTPD, UNGE,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpngepd\", IX86_BUILTIN_CMPNGEPD, LE,\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpngepd\", IX86_BUILTIN_CMPNGEPD, UNGT,\n     BUILTIN_DESC_SWAP_OPERANDS },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpordpd\", IX86_BUILTIN_CMPORDPD, UNORDERED, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskcmpv2df3, \"__builtin_ia32_cmpeqsd\", IX86_BUILTIN_CMPEQSD, EQ, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskcmpv2df3, \"__builtin_ia32_cmpltsd\", IX86_BUILTIN_CMPLTSD, LT, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskcmpv2df3, \"__builtin_ia32_cmplesd\", IX86_BUILTIN_CMPLESD, LE, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskcmpv2df3, \"__builtin_ia32_cmpunordsd\", IX86_BUILTIN_CMPUNORDSD, UNORDERED, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskncmpv2df3, \"__builtin_ia32_cmpneqsd\", IX86_BUILTIN_CMPNEQSD, EQ, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskncmpv2df3, \"__builtin_ia32_cmpnltsd\", IX86_BUILTIN_CMPNLTSD, LT, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskncmpv2df3, \"__builtin_ia32_cmpnlesd\", IX86_BUILTIN_CMPNLESD, LE, 0 },\n-  { MASK_SSE2, CODE_FOR_vmmaskncmpv2df3, \"__builtin_ia32_cmpordsd\", IX86_BUILTIN_CMPORDSD, UNORDERED, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_maskcmpv2df3, \"__builtin_ia32_cmpordpd\", IX86_BUILTIN_CMPORDPD, ORDERED, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmpeqsd\", IX86_BUILTIN_CMPEQSD, EQ, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmpltsd\", IX86_BUILTIN_CMPLTSD, LT, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmplesd\", IX86_BUILTIN_CMPLESD, LE, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmpunordsd\", IX86_BUILTIN_CMPUNORDSD, UNORDERED, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmpneqsd\", IX86_BUILTIN_CMPNEQSD, NE, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmpnltsd\", IX86_BUILTIN_CMPNLTSD, UNGE, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmpnlesd\", IX86_BUILTIN_CMPNLESD, UNGT, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmmaskcmpv2df3, \"__builtin_ia32_cmpordsd\", IX86_BUILTIN_CMPORDSD, ORDERED, 0 },\n \n   { MASK_SSE2, CODE_FOR_sminv2df3, \"__builtin_ia32_minpd\", IX86_BUILTIN_MINPD, 0, 0 },\n   { MASK_SSE2, CODE_FOR_smaxv2df3, \"__builtin_ia32_maxpd\", IX86_BUILTIN_MAXPD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_vmsminv2df3, \"__builtin_ia32_minsd\", IX86_BUILTIN_MINSD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_vmsmaxv2df3, \"__builtin_ia32_maxsd\", IX86_BUILTIN_MAXSD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmsminv2df3, \"__builtin_ia32_minsd\", IX86_BUILTIN_MINSD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_vmsmaxv2df3, \"__builtin_ia32_maxsd\", IX86_BUILTIN_MAXSD, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_sse2_andv2df3, \"__builtin_ia32_andpd\", IX86_BUILTIN_ANDPD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_andv2df3, \"__builtin_ia32_andpd\", IX86_BUILTIN_ANDPD, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_nandv2df3,  \"__builtin_ia32_andnpd\", IX86_BUILTIN_ANDNPD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_iorv2df3, \"__builtin_ia32_orpd\", IX86_BUILTIN_ORPD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_xorv2df3,  \"__builtin_ia32_xorpd\", IX86_BUILTIN_XORPD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_iorv2df3, \"__builtin_ia32_orpd\", IX86_BUILTIN_ORPD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_xorv2df3,  \"__builtin_ia32_xorpd\", IX86_BUILTIN_XORPD, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_sse2_movsd,  \"__builtin_ia32_movsd\", IX86_BUILTIN_MOVSD, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_unpckhpd, \"__builtin_ia32_unpckhpd\", IX86_BUILTIN_UNPCKHPD, 0, 0 },\n@@ -12314,32 +12398,32 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE2, CODE_FOR_subv4si3, \"__builtin_ia32_psubd128\", IX86_BUILTIN_PSUBD128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_subv2di3, \"__builtin_ia32_psubq128\", IX86_BUILTIN_PSUBQ128, 0, 0 },\n \n-  { MASK_MMX, CODE_FOR_ssaddv16qi3, \"__builtin_ia32_paddsb128\", IX86_BUILTIN_PADDSB128, 0, 0 },\n-  { MASK_MMX, CODE_FOR_ssaddv8hi3, \"__builtin_ia32_paddsw128\", IX86_BUILTIN_PADDSW128, 0, 0 },\n-  { MASK_MMX, CODE_FOR_sssubv16qi3, \"__builtin_ia32_psubsb128\", IX86_BUILTIN_PSUBSB128, 0, 0 },\n-  { MASK_MMX, CODE_FOR_sssubv8hi3, \"__builtin_ia32_psubsw128\", IX86_BUILTIN_PSUBSW128, 0, 0 },\n-  { MASK_MMX, CODE_FOR_usaddv16qi3, \"__builtin_ia32_paddusb128\", IX86_BUILTIN_PADDUSB128, 0, 0 },\n-  { MASK_MMX, CODE_FOR_usaddv8hi3, \"__builtin_ia32_paddusw128\", IX86_BUILTIN_PADDUSW128, 0, 0 },\n-  { MASK_MMX, CODE_FOR_ussubv16qi3, \"__builtin_ia32_psubusb128\", IX86_BUILTIN_PSUBUSB128, 0, 0 },\n-  { MASK_MMX, CODE_FOR_ussubv8hi3, \"__builtin_ia32_psubusw128\", IX86_BUILTIN_PSUBUSW128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_ssaddv16qi3, \"__builtin_ia32_paddsb128\", IX86_BUILTIN_PADDSB128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_ssaddv8hi3, \"__builtin_ia32_paddsw128\", IX86_BUILTIN_PADDSW128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_sssubv16qi3, \"__builtin_ia32_psubsb128\", IX86_BUILTIN_PSUBSB128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_sssubv8hi3, \"__builtin_ia32_psubsw128\", IX86_BUILTIN_PSUBSW128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_usaddv16qi3, \"__builtin_ia32_paddusb128\", IX86_BUILTIN_PADDUSB128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_usaddv8hi3, \"__builtin_ia32_paddusw128\", IX86_BUILTIN_PADDUSW128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_ussubv16qi3, \"__builtin_ia32_psubusb128\", IX86_BUILTIN_PSUBUSB128, 0, 0 },\n+  { MASK_MMX, CODE_FOR_sse2_ussubv8hi3, \"__builtin_ia32_psubusw128\", IX86_BUILTIN_PSUBUSW128, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_mulv8hi3, \"__builtin_ia32_pmullw128\", IX86_BUILTIN_PMULLW128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_smulv8hi3_highpart, \"__builtin_ia32_pmulhw128\", IX86_BUILTIN_PMULHW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_smulv8hi3_highpart, \"__builtin_ia32_pmulhw128\", IX86_BUILTIN_PMULHW128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_sse2_andv2di3, \"__builtin_ia32_pand128\", IX86_BUILTIN_PAND128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_andv2di3, \"__builtin_ia32_pand128\", IX86_BUILTIN_PAND128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_nandv2di3, \"__builtin_ia32_pandn128\", IX86_BUILTIN_PANDN128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_iorv2di3, \"__builtin_ia32_por128\", IX86_BUILTIN_POR128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_xorv2di3, \"__builtin_ia32_pxor128\", IX86_BUILTIN_PXOR128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_iorv2di3, \"__builtin_ia32_por128\", IX86_BUILTIN_POR128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_xorv2di3, \"__builtin_ia32_pxor128\", IX86_BUILTIN_PXOR128, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_sse2_uavgv16qi3, \"__builtin_ia32_pavgb128\", IX86_BUILTIN_PAVGB128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_uavgv8hi3, \"__builtin_ia32_pavgw128\", IX86_BUILTIN_PAVGW128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_eqv16qi3, \"__builtin_ia32_pcmpeqb128\", IX86_BUILTIN_PCMPEQB128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_eqv8hi3, \"__builtin_ia32_pcmpeqw128\", IX86_BUILTIN_PCMPEQW128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_eqv4si3, \"__builtin_ia32_pcmpeqd128\", IX86_BUILTIN_PCMPEQD128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_gtv16qi3, \"__builtin_ia32_pcmpgtb128\", IX86_BUILTIN_PCMPGTB128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_gtv8hi3, \"__builtin_ia32_pcmpgtw128\", IX86_BUILTIN_PCMPGTW128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_gtv4si3, \"__builtin_ia32_pcmpgtd128\", IX86_BUILTIN_PCMPGTD128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_eqv16qi3, \"__builtin_ia32_pcmpeqb128\", IX86_BUILTIN_PCMPEQB128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_eqv8hi3, \"__builtin_ia32_pcmpeqw128\", IX86_BUILTIN_PCMPEQW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_eqv4si3, \"__builtin_ia32_pcmpeqd128\", IX86_BUILTIN_PCMPEQD128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_gtv16qi3, \"__builtin_ia32_pcmpgtb128\", IX86_BUILTIN_PCMPGTB128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_gtv8hi3, \"__builtin_ia32_pcmpgtw128\", IX86_BUILTIN_PCMPGTW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_gtv4si3, \"__builtin_ia32_pcmpgtd128\", IX86_BUILTIN_PCMPGTD128, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_umaxv16qi3, \"__builtin_ia32_pmaxub128\", IX86_BUILTIN_PMAXUB128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_smaxv8hi3, \"__builtin_ia32_pmaxsw128\", IX86_BUILTIN_PMAXSW128, 0, 0 },\n@@ -12359,45 +12443,37 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE2, CODE_FOR_sse2_packssdw, \"__builtin_ia32_packssdw128\", IX86_BUILTIN_PACKSSDW128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_packuswb, \"__builtin_ia32_packuswb128\", IX86_BUILTIN_PACKUSWB128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_umulv8hi3_highpart, \"__builtin_ia32_pmulhuw128\", IX86_BUILTIN_PMULHUW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_umulv8hi3_highpart, \"__builtin_ia32_pmulhuw128\", IX86_BUILTIN_PMULHUW128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_psadbw, 0, IX86_BUILTIN_PSADBW128, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_sse2_umulsidi3, 0, IX86_BUILTIN_PMULUDQ, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_umulv2siv2di3, 0, IX86_BUILTIN_PMULUDQ128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_ashlv8hi3_ti, 0, IX86_BUILTIN_PSLLW128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_ashlv8hi3, 0, IX86_BUILTIN_PSLLWI128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_ashlv4si3_ti, 0, IX86_BUILTIN_PSLLD128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_ashlv4si3, 0, IX86_BUILTIN_PSLLDI128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_ashlv2di3_ti, 0, IX86_BUILTIN_PSLLQ128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_ashlv2di3, 0, IX86_BUILTIN_PSLLQI128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_lshrv8hi3_ti, 0, IX86_BUILTIN_PSRLW128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_lshrv8hi3, 0, IX86_BUILTIN_PSRLWI128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_lshrv4si3_ti, 0, IX86_BUILTIN_PSRLD128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_lshrv4si3, 0, IX86_BUILTIN_PSRLDI128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_lshrv2di3_ti, 0, IX86_BUILTIN_PSRLQ128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_lshrv2di3, 0, IX86_BUILTIN_PSRLQI128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_ashrv8hi3_ti, 0, IX86_BUILTIN_PSRAW128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_ashrv8hi3, 0, IX86_BUILTIN_PSRAWI128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_ashrv4si3_ti, 0, IX86_BUILTIN_PSRAD128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_ashrv4si3, 0, IX86_BUILTIN_PSRADI128, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_sse2_pmaddwd, 0, IX86_BUILTIN_PMADDWD128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_cvtsi2sd, 0, IX86_BUILTIN_CVTSI2SD, 0, 0 },\n-  { MASK_SSE2 | MASK_64BIT, CODE_FOR_cvtsi2sdq, 0, IX86_BUILTIN_CVTSI642SD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvtsd2ss, 0, IX86_BUILTIN_CVTSD2SS, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvtss2sd, 0, IX86_BUILTIN_CVTSS2SD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtsi2sd, 0, IX86_BUILTIN_CVTSI2SD, 0, 0 },\n+  { MASK_SSE2 | MASK_64BIT, CODE_FOR_sse2_cvtsi2sdq, 0, IX86_BUILTIN_CVTSI642SD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtsd2ss, 0, IX86_BUILTIN_CVTSD2SS, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtss2sd, 0, IX86_BUILTIN_CVTSS2SD, 0, 0 },\n \n   /* SSE3 MMX */\n-  { MASK_SSE3, CODE_FOR_addsubv4sf3, \"__builtin_ia32_addsubps\", IX86_BUILTIN_ADDSUBPS, 0, 0 },\n-  { MASK_SSE3, CODE_FOR_addsubv2df3, \"__builtin_ia32_addsubpd\", IX86_BUILTIN_ADDSUBPD, 0, 0 },\n-  { MASK_SSE3, CODE_FOR_haddv4sf3, \"__builtin_ia32_haddps\", IX86_BUILTIN_HADDPS, 0, 0 },\n-  { MASK_SSE3, CODE_FOR_haddv2df3, \"__builtin_ia32_haddpd\", IX86_BUILTIN_HADDPD, 0, 0 },\n-  { MASK_SSE3, CODE_FOR_hsubv4sf3, \"__builtin_ia32_hsubps\", IX86_BUILTIN_HSUBPS, 0, 0 },\n-  { MASK_SSE3, CODE_FOR_hsubv2df3, \"__builtin_ia32_hsubpd\", IX86_BUILTIN_HSUBPD, 0, 0 }\n+  { MASK_SSE3, CODE_FOR_sse3_addsubv4sf3, \"__builtin_ia32_addsubps\", IX86_BUILTIN_ADDSUBPS, 0, 0 },\n+  { MASK_SSE3, CODE_FOR_sse3_addsubv2df3, \"__builtin_ia32_addsubpd\", IX86_BUILTIN_ADDSUBPD, 0, 0 },\n+  { MASK_SSE3, CODE_FOR_sse3_haddv4sf3, \"__builtin_ia32_haddps\", IX86_BUILTIN_HADDPS, 0, 0 },\n+  { MASK_SSE3, CODE_FOR_sse3_haddv2df3, \"__builtin_ia32_haddpd\", IX86_BUILTIN_HADDPD, 0, 0 },\n+  { MASK_SSE3, CODE_FOR_sse3_hsubv4sf3, \"__builtin_ia32_hsubps\", IX86_BUILTIN_HSUBPS, 0, 0 },\n+  { MASK_SSE3, CODE_FOR_sse3_hsubv2df3, \"__builtin_ia32_hsubpd\", IX86_BUILTIN_HSUBPD, 0, 0 }\n };\n \n static const struct builtin_description bdesc_1arg[] =\n@@ -12406,49 +12482,45 @@ static const struct builtin_description bdesc_1arg[] =\n   { MASK_SSE, CODE_FOR_sse_movmskps, 0, IX86_BUILTIN_MOVMSKPS, 0, 0 },\n \n   { MASK_SSE, CODE_FOR_sqrtv4sf2, 0, IX86_BUILTIN_SQRTPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_rsqrtv4sf2, 0, IX86_BUILTIN_RSQRTPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_rcpv4sf2, 0, IX86_BUILTIN_RCPPS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_rsqrtv4sf2, 0, IX86_BUILTIN_RSQRTPS, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_rcpv4sf2, 0, IX86_BUILTIN_RCPPS, 0, 0 },\n \n-  { MASK_SSE, CODE_FOR_cvtps2pi, 0, IX86_BUILTIN_CVTPS2PI, 0, 0 },\n-  { MASK_SSE, CODE_FOR_cvtss2si, 0, IX86_BUILTIN_CVTSS2SI, 0, 0 },\n-  { MASK_SSE | MASK_64BIT, CODE_FOR_cvtss2siq, 0, IX86_BUILTIN_CVTSS2SI64, 0, 0 },\n-  { MASK_SSE, CODE_FOR_cvttps2pi, 0, IX86_BUILTIN_CVTTPS2PI, 0, 0 },\n-  { MASK_SSE, CODE_FOR_cvttss2si, 0, IX86_BUILTIN_CVTTSS2SI, 0, 0 },\n-  { MASK_SSE | MASK_64BIT, CODE_FOR_cvttss2siq, 0, IX86_BUILTIN_CVTTSS2SI64, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_cvtps2pi, 0, IX86_BUILTIN_CVTPS2PI, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_cvtss2si, 0, IX86_BUILTIN_CVTSS2SI, 0, 0 },\n+  { MASK_SSE | MASK_64BIT, CODE_FOR_sse_cvtss2siq, 0, IX86_BUILTIN_CVTSS2SI64, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_cvttps2pi, 0, IX86_BUILTIN_CVTTPS2PI, 0, 0 },\n+  { MASK_SSE, CODE_FOR_sse_cvttss2si, 0, IX86_BUILTIN_CVTTSS2SI, 0, 0 },\n+  { MASK_SSE | MASK_64BIT, CODE_FOR_sse_cvttss2siq, 0, IX86_BUILTIN_CVTTSS2SI64, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_sse2_pmovmskb, 0, IX86_BUILTIN_PMOVMSKB128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_movmskpd, 0, IX86_BUILTIN_MOVMSKPD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_movq2dq, 0, IX86_BUILTIN_MOVQ2DQ, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_movdq2q, 0, IX86_BUILTIN_MOVDQ2Q, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_sqrtv2df2, 0, IX86_BUILTIN_SQRTPD, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_cvtdq2pd, 0, IX86_BUILTIN_CVTDQ2PD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvtdq2ps, 0, IX86_BUILTIN_CVTDQ2PS, 0, 0 },\n-\n-  { MASK_SSE2, CODE_FOR_cvtpd2dq, 0, IX86_BUILTIN_CVTPD2DQ, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvtpd2pi, 0, IX86_BUILTIN_CVTPD2PI, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvtpd2ps, 0, IX86_BUILTIN_CVTPD2PS, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvttpd2dq, 0, IX86_BUILTIN_CVTTPD2DQ, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvttpd2pi, 0, IX86_BUILTIN_CVTTPD2PI, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtdq2pd, 0, IX86_BUILTIN_CVTDQ2PD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtdq2ps, 0, IX86_BUILTIN_CVTDQ2PS, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_cvtpi2pd, 0, IX86_BUILTIN_CVTPI2PD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtpd2dq, 0, IX86_BUILTIN_CVTPD2DQ, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtpd2pi, 0, IX86_BUILTIN_CVTPD2PI, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtpd2ps, 0, IX86_BUILTIN_CVTPD2PS, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvttpd2dq, 0, IX86_BUILTIN_CVTTPD2DQ, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvttpd2pi, 0, IX86_BUILTIN_CVTTPD2PI, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_cvtsd2si, 0, IX86_BUILTIN_CVTSD2SI, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvttsd2si, 0, IX86_BUILTIN_CVTTSD2SI, 0, 0 },\n-  { MASK_SSE2 | MASK_64BIT, CODE_FOR_cvtsd2siq, 0, IX86_BUILTIN_CVTSD2SI64, 0, 0 },\n-  { MASK_SSE2 | MASK_64BIT, CODE_FOR_cvttsd2siq, 0, IX86_BUILTIN_CVTTSD2SI64, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtpi2pd, 0, IX86_BUILTIN_CVTPI2PD, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_cvtps2dq, 0, IX86_BUILTIN_CVTPS2DQ, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvtps2pd, 0, IX86_BUILTIN_CVTPS2PD, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_cvttps2dq, 0, IX86_BUILTIN_CVTTPS2DQ, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtsd2si, 0, IX86_BUILTIN_CVTSD2SI, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvttsd2si, 0, IX86_BUILTIN_CVTTSD2SI, 0, 0 },\n+  { MASK_SSE2 | MASK_64BIT, CODE_FOR_sse2_cvtsd2siq, 0, IX86_BUILTIN_CVTSD2SI64, 0, 0 },\n+  { MASK_SSE2 | MASK_64BIT, CODE_FOR_sse2_cvttsd2siq, 0, IX86_BUILTIN_CVTTSD2SI64, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_sse2_movq, 0, IX86_BUILTIN_MOVQ, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtps2dq, 0, IX86_BUILTIN_CVTPS2DQ, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvtps2pd, 0, IX86_BUILTIN_CVTPS2PD, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_cvttps2dq, 0, IX86_BUILTIN_CVTTPS2DQ, 0, 0 },\n \n   /* SSE3 */\n-  { MASK_SSE3, CODE_FOR_movshdup, 0, IX86_BUILTIN_MOVSHDUP, 0, 0 },\n-  { MASK_SSE3, CODE_FOR_movsldup, 0, IX86_BUILTIN_MOVSLDUP, 0, 0 },\n-  { MASK_SSE3, CODE_FOR_movddup,  0, IX86_BUILTIN_MOVDDUP, 0, 0 }\n+  { MASK_SSE3, CODE_FOR_sse3_movshdup, 0, IX86_BUILTIN_MOVSHDUP, 0, 0 },\n+  { MASK_SSE3, CODE_FOR_sse3_movsldup, 0, IX86_BUILTIN_MOVSLDUP, 0, 0 },\n+  { MASK_SSE3, CODE_FOR_sse3_movddup,  0, IX86_BUILTIN_MOVDDUP, 0, 0 }\n };\n \n void\n@@ -12857,16 +12929,12 @@ ix86_init_mmx_sse_builtins (void)\n \t}\n \n       /* Override for comparisons.  */\n-      if (d->icode == CODE_FOR_maskcmpv4sf3\n-\t  || d->icode == CODE_FOR_maskncmpv4sf3\n-\t  || d->icode == CODE_FOR_vmmaskcmpv4sf3\n-\t  || d->icode == CODE_FOR_vmmaskncmpv4sf3)\n+      if (d->icode == CODE_FOR_sse_maskcmpv4sf3\n+\t  || d->icode == CODE_FOR_sse_vmmaskcmpv4sf3)\n \ttype = v4si_ftype_v4sf_v4sf;\n \n-      if (d->icode == CODE_FOR_maskcmpv2df3\n-\t  || d->icode == CODE_FOR_maskncmpv2df3\n-\t  || d->icode == CODE_FOR_vmmaskcmpv2df3\n-\t  || d->icode == CODE_FOR_vmmaskncmpv2df3)\n+      if (d->icode == CODE_FOR_sse2_maskcmpv2df3\n+\t  || d->icode == CODE_FOR_sse2_vmmaskcmpv2df3)\n \ttype = v2di_ftype_v2df_v2df;\n \n       def_builtin (d->mask, d->name, type, d->code);\n@@ -13118,17 +13186,8 @@ ix86_init_mmx_sse_builtins (void)\n static rtx\n safe_vector_operand (rtx x, enum machine_mode mode)\n {\n-  if (x != const0_rtx)\n-    return x;\n-  x = gen_reg_rtx (mode);\n-\n-  if (VALID_MMX_REG_MODE (mode) || VALID_MMX_REG_MODE_3DNOW (mode))\n-    emit_insn (gen_mmx_clrdi (mode == DImode ? x\n-\t\t\t      : gen_rtx_SUBREG (DImode, x, 0)));\n-  else\n-    emit_insn (gen_sse_clrv4sf (mode == V4SFmode ? x\n-\t\t\t\t: gen_rtx_SUBREG (V4SFmode, x, 0),\n-\t\t\t\tCONST0_RTX (V4SFmode)));\n+  if (x == const0_rtx)\n+    x = CONST0_RTX (mode);\n   return x;\n }\n \n@@ -13137,7 +13196,7 @@ safe_vector_operand (rtx x, enum machine_mode mode)\n static rtx\n ix86_expand_binop_builtin (enum insn_code icode, tree arglist, rtx target)\n {\n-  rtx pat;\n+  rtx pat, xops[3];\n   tree arg0 = TREE_VALUE (arglist);\n   tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n   rtx op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n@@ -13169,20 +13228,17 @@ ix86_expand_binop_builtin (enum insn_code icode, tree arglist, rtx target)\n       || (GET_MODE (op1) != mode1 && GET_MODE (op1) != VOIDmode))\n     abort ();\n \n-  if ((optimize && !register_operand (op0, mode0))\n-      || !(*insn_data[icode].operand[1].predicate) (op0, mode0))\n+  if (!(*insn_data[icode].operand[1].predicate) (op0, mode0))\n     op0 = copy_to_mode_reg (mode0, op0);\n-  if ((optimize && !register_operand (op1, mode1))\n-      || !(*insn_data[icode].operand[2].predicate) (op1, mode1))\n+  if (!(*insn_data[icode].operand[2].predicate) (op1, mode1))\n     op1 = copy_to_mode_reg (mode1, op1);\n \n-  /* In the commutative cases, both op0 and op1 are nonimmediate_operand,\n-     yet one of the two must not be a memory.  This is normally enforced\n-     by expanders, but we didn't bother to create one here.  */\n-  if (GET_CODE (op0) == MEM && GET_CODE (op1) == MEM)\n-    op0 = copy_to_mode_reg (mode0, op0);\n+  xops[0] = target;\n+  xops[1] = op0;\n+  xops[2] = op1;\n+  target = ix86_fixup_binary_operands (UNKNOWN, tmode, xops);\n \n-  pat = GEN_FCN (icode) (target, op0, op1);\n+  pat = GEN_FCN (icode) (target, xops[1], xops[2]);\n   if (! pat)\n     return 0;\n   emit_insn (pat);\n@@ -13495,8 +13551,7 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       icode = (fcode == IX86_BUILTIN_MASKMOVQ\n \t       ? (TARGET_64BIT ? CODE_FOR_mmx_maskmovq_rex\n \t\t  : CODE_FOR_mmx_maskmovq)\n-\t       : (TARGET_64BIT ? CODE_FOR_sse2_maskmovdqu_rex64\n-\t\t  : CODE_FOR_sse2_maskmovdqu));\n+\t       : CODE_FOR_sse2_maskmovdqu);\n       /* Note the arg order is different from the operand order.  */\n       arg1 = TREE_VALUE (arglist);\n       arg2 = TREE_VALUE (TREE_CHAIN (arglist));\n@@ -13508,6 +13563,12 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       mode1 = insn_data[icode].operand[1].mode;\n       mode2 = insn_data[icode].operand[2].mode;\n \n+      if (fcode == IX86_BUILTIN_MASKMOVDQU)\n+\t{\n+\t  op0 = force_reg (Pmode, op0);\n+\t  op0 = gen_rtx_MEM (V16QImode, op0);\n+\t}\n+\n       if (! (*insn_data[icode].operand[0].predicate) (op0, mode0))\n \top0 = copy_to_mode_reg (mode0, op0);\n       if (! (*insn_data[icode].operand[1].predicate) (op1, mode1))\n@@ -13521,20 +13582,20 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       return 0;\n \n     case IX86_BUILTIN_SQRTSS:\n-      return ix86_expand_unop1_builtin (CODE_FOR_vmsqrtv4sf2, arglist, target);\n+      return ix86_expand_unop1_builtin (CODE_FOR_sse_vmsqrtv4sf2, arglist, target);\n     case IX86_BUILTIN_RSQRTSS:\n-      return ix86_expand_unop1_builtin (CODE_FOR_vmrsqrtv4sf2, arglist, target);\n+      return ix86_expand_unop1_builtin (CODE_FOR_sse_vmrsqrtv4sf2, arglist, target);\n     case IX86_BUILTIN_RCPSS:\n-      return ix86_expand_unop1_builtin (CODE_FOR_vmrcpv4sf2, arglist, target);\n+      return ix86_expand_unop1_builtin (CODE_FOR_sse_vmrcpv4sf2, arglist, target);\n \n     case IX86_BUILTIN_LOADAPS:\n-      return ix86_expand_unop_builtin (CODE_FOR_sse_movaps, arglist, target, 1);\n+      return ix86_expand_unop_builtin (CODE_FOR_movv4sf, arglist, target, 1);\n \n     case IX86_BUILTIN_LOADUPS:\n       return ix86_expand_unop_builtin (CODE_FOR_sse_movups, arglist, target, 1);\n \n     case IX86_BUILTIN_STOREAPS:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_movaps, arglist);\n+      return ix86_expand_store_builtin (CODE_FOR_movv4sf, arglist);\n \n     case IX86_BUILTIN_STOREUPS:\n       return ix86_expand_store_builtin (CODE_FOR_sse_movups, arglist);\n@@ -13794,38 +13855,33 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       return ix86_expand_unop_builtin (CODE_FOR_pswapdv2sf2, arglist, target, 0);\n \n     case IX86_BUILTIN_SSE_ZERO:\n-      target = gen_reg_rtx (V4SFmode);\n-      emit_insn (gen_sse_clrv4sf (target, CONST0_RTX (V4SFmode)));\n-      return target;\n+      return CONST0_RTX (V4SFmode);\n \n     case IX86_BUILTIN_MMX_ZERO:\n       target = gen_reg_rtx (DImode);\n       emit_insn (gen_mmx_clrdi (target));\n       return target;\n \n     case IX86_BUILTIN_CLRTI:\n-      target = gen_reg_rtx (V2DImode);\n-      emit_insn (gen_sse2_clrti (simplify_gen_subreg (TImode, target, V2DImode, 0)));\n-      return target;\n-\n+      return const0_rtx;\n \n     case IX86_BUILTIN_SQRTSD:\n-      return ix86_expand_unop1_builtin (CODE_FOR_vmsqrtv2df2, arglist, target);\n+      return ix86_expand_unop1_builtin (CODE_FOR_sse2_vmsqrtv2df2, arglist, target);\n     case IX86_BUILTIN_LOADAPD:\n-      return ix86_expand_unop_builtin (CODE_FOR_sse2_movapd, arglist, target, 1);\n+      return ix86_expand_unop_builtin (CODE_FOR_movv2df, arglist, target, 1);\n     case IX86_BUILTIN_LOADUPD:\n       return ix86_expand_unop_builtin (CODE_FOR_sse2_movupd, arglist, target, 1);\n \n     case IX86_BUILTIN_STOREAPD:\n-      return ix86_expand_store_builtin (CODE_FOR_sse2_movapd, arglist);\n+      return ix86_expand_store_builtin (CODE_FOR_movv2df, arglist);\n     case IX86_BUILTIN_STOREUPD:\n       return ix86_expand_store_builtin (CODE_FOR_sse2_movupd, arglist);\n \n     case IX86_BUILTIN_LOADSD:\n       return ix86_expand_unop_builtin (CODE_FOR_sse2_loadsd, arglist, target, 1);\n \n     case IX86_BUILTIN_STORESD:\n-      return ix86_expand_store_builtin (CODE_FOR_sse2_storesd, arglist);\n+      return ix86_expand_store_builtin (CODE_FOR_sse2_storelpd, arglist);\n \n     case IX86_BUILTIN_SETPD1:\n       target = assign_386_stack_local (DFmode, 0);\n@@ -13846,11 +13902,11 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       emit_move_insn (adjust_address (target, DFmode, 8),\n \t\t      expand_expr (arg1, NULL_RTX, VOIDmode, 0));\n       op0 = gen_reg_rtx (V2DFmode);\n-      emit_insn (gen_sse2_movapd (op0, target));\n+      emit_move_insn (op0, target);\n       return op0;\n \n     case IX86_BUILTIN_LOADRPD:\n-      target = ix86_expand_unop_builtin (CODE_FOR_sse2_movapd, arglist,\n+      target = ix86_expand_unop_builtin (CODE_FOR_movv2df, arglist,\n \t\t\t\t\t gen_reg_rtx (V2DFmode), 1);\n       emit_insn (gen_sse2_shufpd (target, target, target, const1_rtx));\n       return target;\n@@ -13862,14 +13918,12 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       return target;\n \n     case IX86_BUILTIN_STOREPD1:\n-      return ix86_expand_store_builtin (CODE_FOR_sse2_movapd, arglist);\n+      return ix86_expand_store_builtin (CODE_FOR_movv2df, arglist);\n     case IX86_BUILTIN_STORERPD:\n-      return ix86_expand_store_builtin (CODE_FOR_sse2_movapd, arglist);\n+      return ix86_expand_store_builtin (CODE_FOR_movv2df, arglist);\n \n     case IX86_BUILTIN_CLRPD:\n-      target = gen_reg_rtx (V2DFmode);\n-      emit_insn (gen_sse_clrv2df (target));\n-      return target;\n+      return CONST0_RTX (V2DFmode);\n \n     case IX86_BUILTIN_MFENCE:\n \temit_insn (gen_sse2_mfence ());\n@@ -13896,14 +13950,14 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       return ix86_expand_store_builtin (CODE_FOR_sse2_movntsi, arglist);\n \n     case IX86_BUILTIN_LOADDQA:\n-      return ix86_expand_unop_builtin (CODE_FOR_sse2_movdqa, arglist, target, 1);\n+      return ix86_expand_unop_builtin (CODE_FOR_movv2di, arglist, target, 1);\n     case IX86_BUILTIN_LOADDQU:\n       return ix86_expand_unop_builtin (CODE_FOR_sse2_movdqu, arglist, target, 1);\n     case IX86_BUILTIN_LOADD:\n       return ix86_expand_unop_builtin (CODE_FOR_sse2_loadd, arglist, target, 1);\n \n     case IX86_BUILTIN_STOREDQA:\n-      return ix86_expand_store_builtin (CODE_FOR_sse2_movdqa, arglist);\n+      return ix86_expand_store_builtin (CODE_FOR_movv2di, arglist);\n     case IX86_BUILTIN_STOREDQU:\n       return ix86_expand_store_builtin (CODE_FOR_sse2_movdqu, arglist);\n     case IX86_BUILTIN_STORED:\n@@ -13922,7 +13976,7 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n \top1 = copy_to_mode_reg (SImode, op1);\n       if (!REG_P (op2))\n \top2 = copy_to_mode_reg (SImode, op2);\n-      emit_insn (gen_monitor (op0, op1, op2));\n+      emit_insn (gen_sse3_monitor (op0, op1, op2));\n       return 0;\n \n     case IX86_BUILTIN_MWAIT:\n@@ -13934,14 +13988,14 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n \top0 = copy_to_mode_reg (SImode, op0);\n       if (!REG_P (op1))\n \top1 = copy_to_mode_reg (SImode, op1);\n-      emit_insn (gen_mwait (op0, op1));\n+      emit_insn (gen_sse3_mwait (op0, op1));\n       return 0;\n \n     case IX86_BUILTIN_LOADDDUP:\n-      return ix86_expand_unop_builtin (CODE_FOR_loadddup, arglist, target, 1);\n+      return ix86_expand_unop_builtin (CODE_FOR_sse3_loadddup, arglist, target, 1);\n \n     case IX86_BUILTIN_LDDQU:\n-      return ix86_expand_unop_builtin (CODE_FOR_lddqu, arglist, target,\n+      return ix86_expand_unop_builtin (CODE_FOR_sse3_lddqu, arglist, target,\n \t\t\t\t       1);\n \n     default:\n@@ -13952,14 +14006,10 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n     if (d->code == fcode)\n       {\n \t/* Compares are treated specially.  */\n-\tif (d->icode == CODE_FOR_maskcmpv4sf3\n-\t    || d->icode == CODE_FOR_vmmaskcmpv4sf3\n-\t    || d->icode == CODE_FOR_maskncmpv4sf3\n-\t    || d->icode == CODE_FOR_vmmaskncmpv4sf3\n-\t    || d->icode == CODE_FOR_maskcmpv2df3\n-\t    || d->icode == CODE_FOR_vmmaskcmpv2df3\n-\t    || d->icode == CODE_FOR_maskncmpv2df3\n-\t    || d->icode == CODE_FOR_vmmaskncmpv2df3)\n+\tif (d->icode == CODE_FOR_sse_maskcmpv4sf3\n+\t    || d->icode == CODE_FOR_sse_vmmaskcmpv4sf3\n+\t    || d->icode == CODE_FOR_sse2_maskcmpv2df3\n+\t    || d->icode == CODE_FOR_sse2_vmmaskcmpv2df3)\n \t  return ix86_expand_sse_compare (d, arglist, target);\n \n \treturn ix86_expand_binop_builtin (d->icode, arglist, target);"}, {"sha": "0a0db2e102f907b8e141462bf2e2dfc9e5ac0af6", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -2062,6 +2062,8 @@ enum ix86_builtins\n   IX86_BUILTIN_CMPNEQSS,\n   IX86_BUILTIN_CMPNLTSS,\n   IX86_BUILTIN_CMPNLESS,\n+  IX86_BUILTIN_CMPNGTSS,\n+  IX86_BUILTIN_CMPNGESS,\n   IX86_BUILTIN_CMPORDSS,\n   IX86_BUILTIN_CMPUNORDSS,\n   IX86_BUILTIN_CMPNESS,"}, {"sha": "08aa382fb9d4f93f0de0e89e100ff44eb53440d7", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 1272, "deletions": 4384, "changes": 5656, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683"}, {"sha": "29dd4aafcb45e4da01dbaad060a86d41446d0b08", "filename": "gcc/config/i386/ppro.md", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fppro.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fppro.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fppro.md?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -687,7 +687,7 @@\n \n (define_insn_reservation \"ppro_sse_div_V4SF_load\" 48\n \t\t\t (and (eq_attr \"cpu\" \"pentiumpro\")\n-\t\t\t      (and (eq_attr \"memory\" \"none\")\n+\t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"V4SF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssediv\"))))\n \t\t\t \"decoder0,(p2+p0)*2,p0*32\")\n@@ -696,14 +696,14 @@\n \t\t\t (and (eq_attr \"cpu\" \"pentiumpro\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"V4SF\")\n-\t\t\t\t\t(eq_attr \"type\" \"sselog\"))))\n+\t\t\t\t\t(eq_attr \"type\" \"sselog,sselog1\"))))\n \t\t\t \"decodern,p1\")\n \n (define_insn_reservation \"ppro_sse_log_V4SF_load\" 2\n \t\t\t (and (eq_attr \"cpu\" \"pentiumpro\")\n-\t\t\t      (and (eq_attr \"memory\" \"none\")\n+\t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"V4SF\")\n-\t\t\t\t\t(eq_attr \"type\" \"sselog\"))))\n+\t\t\t\t\t(eq_attr \"type\" \"sselog,sselog1\"))))\n \t\t\t \"decoder0,(p2+p1)\")\n \n (define_insn_reservation \"ppro_sse_mov_V4SF\" 1"}, {"sha": "fde85dd6d693f602cb695fd3f47a3c295af3f9fe", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 29, "deletions": 6, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -319,12 +319,6 @@\n \t (and (match_operand 0 \"const_double_operand\")\n \t      (match_test \"GET_MODE_SIZE (mode) <= 8\")))))\n \n-;; Return nonzero if OP is CONST_INT >= 1 and <= 31 (a valid operand\n-;; for shift & compare patterns, as shifting by 0 does not change flags).\n-(define_predicate \"const_int_1_31_operand\"\n-  (and (match_code \"const_int\")\n-       (match_test \"INTVAL (op) >= 1 && INTVAL (op) <= 31\")))\n-\n ;; Returns nonzero if OP is either a symbol reference or a sum of a symbol\n ;; reference and a constant.\n (define_predicate \"symbolic_operand\"\n@@ -521,6 +515,11 @@\n   return i == 2 || i == 4 || i == 8;\n })\n \n+;; Match 0 or 1.\n+(define_predicate \"const_0_to_1_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"op == const0_rtx || op == const1_rtx\")))\n+\n ;; Match 0 to 3.\n (define_predicate \"const_0_to_3_operand\"\n   (and (match_code \"const_int\")\n@@ -546,6 +545,30 @@\n   (and (match_code \"const_int\")\n        (match_test \"INTVAL (op) >= 0 && INTVAL (op) <= 255\")))\n \n+;; Match (0 to 255) * 8\n+(define_predicate \"const_0_to_255_mul_8_operand\"\n+  (match_code \"const_int\")\n+{\n+  unsigned HOST_WIDE_INT val = INTVAL (op);\n+  return val <= 255*8 && val % 8 == 0;\n+})\n+\n+;; Return nonzero if OP is CONST_INT >= 1 and <= 31 (a valid operand\n+;; for shift & compare patterns, as shifting by 0 does not change flags).\n+(define_predicate \"const_1_to_31_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"INTVAL (op) >= 1 && INTVAL (op) <= 31\")))\n+\n+;; Match 2 or 3.\n+(define_predicate \"const_2_to_3_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"INTVAL (op) == 2 || INTVAL (op) == 3\")))\n+\n+;; Match 4 to 7.\n+(define_predicate \"const_4_to_7_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"INTVAL (op) >= 4 && INTVAL (op) <= 7\")))\n+\n ;; Match exactly one bit in 4-bit mask.\n (define_predicate \"const_pow2_1_to_8_operand\"\n   (match_code \"const_int\")"}, {"sha": "ee90d0664d62a3b14c10a2e97228c589df5f2e58", "filename": "gcc/config/i386/sse.md", "status": "added", "additions": 3111, "deletions": 0, "changes": 3111, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683"}, {"sha": "bd05d6327d21a8049fdba343c3eec2b677aeb1ea", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -1,3 +1,8 @@\n+2005-01-08  Richard Henderson  <rth@redhat.com>\n+\n+\t* lib/target-supports.exp (check_effective_target_vect_no_bitwise):\n+\tFalse for x86 and x86-64.\n+\n 2005-01-08  Diego Novillo  <dnovillo@redhat.com>\n \n \tPR tree-optimization/18241"}, {"sha": "1f966de88819b8f15648df232cf5ecdca571c0ed", "filename": "gcc/testsuite/lib/target-supports.exp", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ef719a44ef6afad4baa91dd3217e542a1a2f2683/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp?ref=ef719a44ef6afad4baa91dd3217e542a1a2f2683", "patch": "@@ -563,10 +563,6 @@ proc check_effective_target_vect_no_bitwise { } {\n \tverbose \"check_effective_target_vect_no_bitwise: using cached result\" 2\n     } else {\n \tset et_vect_no_bitwise_saved 0\n-\tif { [istarget i?86-*-*]\n-\t     || [istarget x86_64-*-*] } {\n-\t    set et_vect_no_bitwise_saved 1\n-\t}\n     }\n     verbose \"check_effective_target_vect_no_bitwise: returning $et_vect_no_bitwise_saved\" 2\n     return $et_vect_no_bitwise_saved"}]}