{"sha": "d397e8c6729cde9044c1ee42d28f2d1e98204cfc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDM5N2U4YzY3MjljZGU5MDQ0YzFlZTQyZDI4ZjJkMWU5ODIwNGNmYw==", "commit": {"author": {"name": "Mostafa Hagog", "email": "hagog@gcc.gnu.org", "date": "2004-05-25T12:58:32Z"}, "committer": {"name": "Mostafa Hagog", "email": "hagog@gcc.gnu.org", "date": "2004-05-25T12:58:32Z"}, "message": "New files for implementing sms in gcc.\n\nFrom-SVN: r82236", "tree": {"sha": "7a818210ec5b5ad8bfadde298e02d012e88d4c8f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7a818210ec5b5ad8bfadde298e02d012e88d4c8f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d397e8c6729cde9044c1ee42d28f2d1e98204cfc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d397e8c6729cde9044c1ee42d28f2d1e98204cfc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d397e8c6729cde9044c1ee42d28f2d1e98204cfc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d397e8c6729cde9044c1ee42d28f2d1e98204cfc/comments", "author": null, "committer": null, "parents": [{"sha": "e56261981bc8ad88515fda18d846bf61bf6c2353", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e56261981bc8ad88515fda18d846bf61bf6c2353", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e56261981bc8ad88515fda18d846bf61bf6c2353"}], "stats": {"total": 3352, "additions": 3352, "deletions": 0}, "files": [{"sha": "408a4d8acf0dc56cb062394c7db0056bdbbaae81", "filename": "gcc/ddg.c", "status": "added", "additions": 1046, "deletions": 0, "changes": 1046, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d397e8c6729cde9044c1ee42d28f2d1e98204cfc/gcc%2Fddg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d397e8c6729cde9044c1ee42d28f2d1e98204cfc/gcc%2Fddg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fddg.c?ref=d397e8c6729cde9044c1ee42d28f2d1e98204cfc", "patch": "@@ -0,0 +1,1046 @@\n+/* DDG - Data Dependence Graph implementation.\n+   Copyright (C) 2004\n+   Free Software Foundation, Inc.\n+   Contributed by Ayal Zaks and Mustafa Hagog <zaks,mustafa@il.ibm.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"toplev.h\"\n+#include \"rtl.h\"\n+#include \"tm_p.h\"\n+#include \"hard-reg-set.h\"\n+#include \"basic-block.h\"\n+#include \"regs.h\"\n+#include \"function.h\"\n+#include \"flags.h\"\n+#include \"insn-config.h\"\n+#include \"insn-attr.h\"\n+#include \"except.h\"\n+#include \"recog.h\"\n+#include \"sched-int.h\"\n+#include \"target.h\"\n+#include \"cfglayout.h\"\n+#include \"cfgloop.h\"\n+#include \"sbitmap.h\"\n+#include \"expr.h\"\n+#include \"bitmap.h\"\n+#include \"df.h\"\n+#include \"ddg.h\"\n+\n+/* A flag indicating that a ddg edge belongs to an SCC or not.  */\n+enum edge_flag {NOT_IN_SCC = 0, IN_SCC};\n+\n+/* Forward declarations.  */\n+static void add_backarc_to_ddg (ddg_ptr, ddg_edge_ptr);\n+static void add_backarc_to_scc (ddg_scc_ptr, ddg_edge_ptr);\n+static void add_scc_to_ddg (ddg_all_sccs_ptr, ddg_scc_ptr);\n+static void create_ddg_dependence (ddg_ptr, ddg_node_ptr, ddg_node_ptr, rtx);\n+static void create_ddg_dep_no_link (ddg_ptr, ddg_node_ptr, ddg_node_ptr,\n+ \t\t\t\t    dep_type, dep_data_type, int);\n+static ddg_edge_ptr create_ddg_edge (ddg_node_ptr, ddg_node_ptr, dep_type,\n+\t\t\t\t     dep_data_type, int, int);\n+static void add_edge_to_ddg (ddg_ptr g, ddg_edge_ptr);\n+\f\n+/* Auxiliary variable for mem_read_insn_p/mem_write_insn_p.  */\n+static bool mem_ref_p;\n+\n+/* Auxiliary function for mem_read_insn_p.  */\n+static int\n+mark_mem_use (rtx *x, void *data ATTRIBUTE_UNUSED)\n+{\n+  if (GET_CODE (*x) == MEM)\n+    mem_ref_p = true;\n+  return 0;\n+}\n+\n+/* Auxiliary function for mem_read_insn_p.  */\n+static void\n+mark_mem_use_1 (rtx *x, void *data)\n+{\n+  for_each_rtx (x, mark_mem_use, data);\n+}\n+\n+/* Returns non-zero if INSN reads from memory.  */\n+static bool\n+mem_read_insn_p (rtx insn)\n+{\n+  mem_ref_p = false;\n+  note_uses (&PATTERN (insn), mark_mem_use_1, NULL);\n+  return mem_ref_p;\n+}\n+\n+static void\n+mark_mem_store (rtx loc, rtx setter ATTRIBUTE_UNUSED, void *data ATTRIBUTE_UNUSED)\n+{\n+  if (GET_CODE (loc) == MEM)\n+    mem_ref_p = true;\n+}\n+\n+/* Returns non-zero if INSN writes to memory.  */\n+static bool\n+mem_write_insn_p (rtx insn)\n+{\n+  mem_ref_p = false;\n+  note_stores (PATTERN (insn), mark_mem_store, NULL);\n+  return mem_ref_p;\n+}\n+\n+/* Returns non-zero if X has access to memory.  */\n+static bool\n+rtx_mem_access_p (rtx x)\n+{\n+  int i, j;\n+  const char *fmt;\n+  enum rtx_code code;\n+\n+  if (x == 0)\n+    return false;\n+\n+  if (GET_CODE (x) == MEM)\n+    return true;\n+\n+  code = GET_CODE (x);\n+  fmt = GET_RTX_FORMAT (code);\n+  for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)\n+    {\n+      if (fmt[i] == 'e')\n+\t{\n+\t  if (rtx_mem_access_p (XEXP (x, i)))\n+            return true;\n+        }\n+      else if (fmt[i] == 'E')\n+\tfor (j = 0; j < XVECLEN (x, i); j++)\n+\t  {\n+\t    if (rtx_mem_access_p (XVECEXP (x, i, j)))\n+              return true;\n+          }\n+    }\n+  return false;\n+}\n+\n+/* Returns non-zero if INSN reads to or writes from memory.  */\n+static bool\n+mem_access_insn_p (rtx insn)\n+{\n+  return rtx_mem_access_p (PATTERN (insn));\n+}\n+\n+/* Computes the dependence parameters (latency, distance etc.), creates\n+   a ddg_edge and adds it to the given DDG.  */\n+static void\n+create_ddg_dependence (ddg_ptr g, ddg_node_ptr src_node,\n+\t\t       ddg_node_ptr dest_node, rtx link)\n+{\n+  ddg_edge_ptr e;\n+  int latency, distance = 0;\n+  int interloop = (src_node->cuid >= dest_node->cuid);\n+  dep_type t = TRUE_DEP;\n+  dep_data_type dt = (mem_access_insn_p (src_node->insn)\n+\t\t      && mem_access_insn_p (dest_node->insn) ? MEM_DEP\n+\t\t\t\t\t\t\t     : REG_DEP);\n+\n+  /* For now we don't have an exact calculation of the distance,\n+     so assume 1 conservatively.  */\n+  if (interloop)\n+     distance = 1;\n+\n+  if (!link)\n+    abort ();\n+\n+  /* Note: REG_DEP_ANTI applies to MEM ANTI_DEP as well!!  */\n+  if (REG_NOTE_KIND (link) == REG_DEP_ANTI)\n+    t = ANTI_DEP;\n+  else if (REG_NOTE_KIND (link) == REG_DEP_OUTPUT)\n+    t = OUTPUT_DEP;\n+  latency = insn_cost (src_node->insn, link, dest_node->insn);\n+\n+  e = create_ddg_edge (src_node, dest_node, t, dt, latency, distance);\n+\n+  if (interloop)\n+    {\n+      /* Some interloop dependencies are relaxed:\n+\t 1. Every insn is output dependent on itself; ignore such deps.\n+\t 2. Every true/flow dependence is an anti dependence in the\n+\t opposite direction with distance 1; such register deps\n+\t will be removed by renaming if broken --- ignore them.  */\n+      if (!(t == OUTPUT_DEP && src_node == dest_node)\n+\t  && !(t == ANTI_DEP && dt == REG_DEP))\n+\tadd_backarc_to_ddg (g, e);\n+      else\n+\tfree (e);\n+    }\n+  else\n+    add_edge_to_ddg (g, e);\n+}\n+\n+/* The same as the above function, but it doesn't require a link parameter.  */\n+static void\n+create_ddg_dep_no_link (ddg_ptr g, ddg_node_ptr from, ddg_node_ptr to,\n+\t\t\tdep_type d_t, dep_data_type d_dt, int distance)\n+{\n+  ddg_edge_ptr e;\n+  int l;\n+  rtx link = alloc_INSN_LIST (to->insn, NULL_RTX);\n+\n+  if (d_t == ANTI_DEP)\n+    PUT_REG_NOTE_KIND (link, REG_DEP_ANTI);\n+  else if (d_t == OUTPUT_DEP)\n+    PUT_REG_NOTE_KIND (link, REG_DEP_OUTPUT);\n+\n+  l = insn_cost (from->insn, link, to->insn);\n+  free_INSN_LIST_node (link);\n+\n+  e = create_ddg_edge (from, to, d_t, d_dt, l, distance);\n+  if (distance > 0)\n+    add_backarc_to_ddg (g, e);\n+  else\n+    add_edge_to_ddg (g, e);\n+}\n+\n+\f\n+/* Given a downwards exposed register def RD, add inter-loop true dependences\n+   for all its uses in the next iteration, and an output dependence to the\n+   first def of the next iteration.  */\n+static void\n+add_deps_for_def (ddg_ptr g, struct df *df, struct ref *rd)\n+{\n+  int regno = DF_REF_REGNO (rd);\n+  struct bb_info *bb_info = DF_BB_INFO (df, g->bb);\n+  struct df_link *r_use;\n+  int use_before_def = false;\n+  rtx def_insn = DF_REF_INSN (rd);\n+  ddg_node_ptr src_node = get_node_of_insn (g, def_insn);\n+\n+  /* Create and inter-loop true dependence between RD and each of its uses\n+     that is upwards exposed in RD's block.  */\n+  for (r_use = DF_REF_CHAIN (rd); r_use != NULL; r_use = r_use->next)\n+    {\n+      if (bitmap_bit_p (bb_info->ru_gen, r_use->ref->id))\n+\t{\n+\t  rtx use_insn = DF_REF_INSN (r_use->ref);\n+\t  ddg_node_ptr dest_node = get_node_of_insn (g, use_insn);\n+\n+\t  if (!src_node || !dest_node)\n+\t    abort ();\n+\n+\t  /* Any such upwards exposed use appears before the rd def.  */\n+\t  use_before_def = true;\n+\t  create_ddg_dep_no_link (g, src_node, dest_node, TRUE_DEP,\n+\t\t\t\t  REG_DEP, 1);\n+\t}\n+    }\n+\n+  /* Create an inter-loop output dependence between RD (which is the\n+     last def in its block, being downwards exposed) and the first def\n+     in its block.  Avoid creating a self output dependence.  Avoid creating\n+     an output dependence if there is a dependence path between the two defs\n+     starting with a true dependence followed by an anti dependence (i.e. if\n+     there is a use between the two defs.  */\n+  if (! use_before_def)\n+    {\n+      struct ref *def = df_bb_regno_first_def_find (df, g->bb, regno);\n+      int i;\n+      ddg_node_ptr dest_node;\n+\n+      if (!def || rd->id == def->id)\n+\treturn;\n+\n+      /* Check if there are uses after RD.  */\n+      for (i = src_node->cuid + 1; i < g->num_nodes; i++)\n+\t if (df_reg_used (df, g->nodes[i].insn, rd->reg))\n+\t   return;\n+\n+      dest_node = get_node_of_insn (g, def->insn);\n+      create_ddg_dep_no_link (g, src_node, dest_node, OUTPUT_DEP, REG_DEP, 1);\n+    }\n+}\n+\n+/* Given a register USE, add an inter-loop anti dependence to the first\n+   (nearest BLOCK_BEGIN) def of the next iteration, unless USE is followed\n+   by a def in the block.  */\n+static void\n+add_deps_for_use (ddg_ptr g, struct df *df, struct ref *use)\n+{\n+  int i;\n+  int regno = DF_REF_REGNO (use);\n+  struct ref *first_def = df_bb_regno_first_def_find (df, g->bb, regno);\n+  ddg_node_ptr use_node;\n+  ddg_node_ptr def_node;\n+  struct bb_info *bb_info;\n+\n+  bb_info = DF_BB_INFO (df, g->bb);\n+\n+  if (!first_def)\n+    return;\n+\n+  use_node = get_node_of_insn (g, use->insn);\n+  def_node = get_node_of_insn (g, first_def->insn);\n+\n+  if (!use_node || !def_node)\n+    abort ();\n+\n+  /* Make sure there are no defs after USE.  */\n+  for (i = use_node->cuid + 1; i < g->num_nodes; i++)\n+     if (df_find_def (df, g->nodes[i].insn, use->reg))\n+       return;\n+  /* We must not add ANTI dep when there is an intra-loop TRUE dep in\n+     the opozite direction. If the first_def reaches the USE then there is\n+     such a dep. */\n+  if (! bitmap_bit_p (bb_info->rd_gen, first_def->id))\n+    create_ddg_dep_no_link (g, use_node, def_node, ANTI_DEP, REG_DEP, 1);\n+}\n+\n+/* Build inter-loop dependencies, by looking at DF analysis backwards.  */\n+static void\n+build_inter_loop_deps (ddg_ptr g, struct df *df)\n+{\n+  int rd_num, u_num;\n+  struct bb_info *bb_info;\n+\n+  bb_info = DF_BB_INFO (df, g->bb);\n+\n+  /* Find inter-loop output and true deps by connecting downward exposed defs\n+     to the first def of the BB and to upwards exposed uses.  */\n+  EXECUTE_IF_SET_IN_BITMAP (bb_info->rd_gen, 0, rd_num,\n+    {\n+      struct ref *rd = df->defs[rd_num];\n+\n+      add_deps_for_def (g, df, rd);\n+    });\n+\n+  /* Find inter-loop anti deps.  We are interested in uses of the block that\n+     appear below all defs; this implies that these uses are killed.  */\n+  EXECUTE_IF_SET_IN_BITMAP (bb_info->ru_kill, 0, u_num,\n+    {\n+      struct ref *use = df->uses[u_num];\n+\n+      /* We are interested in uses of this BB.  */\n+      if (BLOCK_FOR_INSN (use->insn) == g->bb)\n+      \tadd_deps_for_use (g, df,use);\n+    });\n+}\n+\n+/* Given two nodes, analyze their RTL insns and add inter-loop mem deps\n+   to ddg G.  */\n+static void\n+add_inter_loop_mem_dep (ddg_ptr g, ddg_node_ptr from, ddg_node_ptr to)\n+{\n+  if (mem_write_insn_p (from->insn))\n+    {\n+      if (mem_read_insn_p (to->insn))\n+  \tcreate_ddg_dep_no_link (g, from, to, TRUE_DEP, MEM_DEP, 1);\n+      else if (from->cuid != to->cuid)\n+  \tcreate_ddg_dep_no_link (g, from, to, OUTPUT_DEP, MEM_DEP, 1);\n+    }\n+  else\n+    {\n+      if (mem_read_insn_p (to->insn))\n+\treturn;\n+      else if (from->cuid != to->cuid)\n+\t{\n+  \t  create_ddg_dep_no_link (g, from, to, ANTI_DEP, MEM_DEP, 1);\n+  \t  create_ddg_dep_no_link (g, to, from, TRUE_DEP, MEM_DEP, 1);\n+\t}\n+    }\n+\n+}\n+\n+/* Perform intra-block Data Dependency analysis and connect the nodes in\n+   the DDG.  We assume the loop has a single basic block. */\n+static void\n+build_intra_loop_deps (ddg_ptr g)\n+{\n+  int i;\n+  /* Hold the dependency analysis state during dependency calculations.  */\n+  struct deps tmp_deps;\n+  rtx head, tail, link;\n+\n+  /* Build the dependence information, using the sched_analyze function.  */\n+  init_deps_global ();\n+  init_deps (&tmp_deps);\n+\n+  /* Do the intra-block data dependence analysis for the given block.  */\n+  get_block_head_tail (g->bb->index, &head, &tail);\n+  sched_analyze (&tmp_deps, head, tail);\n+\n+  /* Build intra-loop data dependecies using the schedular dependecy\n+     analysis.  */\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      ddg_node_ptr dest_node = &g->nodes[i];\n+\n+      if (! INSN_P (dest_node->insn))\n+\tcontinue;\n+\n+      for (link = LOG_LINKS (dest_node->insn); link; link = XEXP (link, 1))\n+\t{\n+\t  ddg_node_ptr src_node = get_node_of_insn (g, XEXP (link, 0));\n+\n+\t  if (!src_node)\n+\t    continue;\n+\n+      \t  add_forward_dependence (XEXP (link, 0), dest_node->insn,\n+\t\t\t\t  REG_NOTE_KIND (link));\n+\t  create_ddg_dependence (g, src_node, dest_node,\n+\t\t\t\t INSN_DEPEND (src_node->insn));\n+\t}\n+\n+      /* If this insn modifies memory, add an edge to all insns that access\n+\t memory.  */\n+      if (mem_access_insn_p (dest_node->insn))\n+\t{\n+\t  int j;\n+\n+\t  for (j = 0; j <= i; j++)\n+\t    {\n+\t      ddg_node_ptr j_node = &g->nodes[j];\n+\t      if (mem_access_insn_p (j_node->insn))\n+ \t\t/* Don't bother calculating inter-loop dep if an intra-loop dep\n+\t\t   already exists.  */\n+\t      \t  if (! TEST_BIT (dest_node->successors, j))\n+\t\t    add_inter_loop_mem_dep (g, dest_node, j_node);\n+            }\n+        }\n+    }\n+\n+  /* Free the INSN_LISTs.  */\n+  finish_deps_global ();\n+  free_deps (&tmp_deps);\n+}\n+\n+\n+/* Given a basic block, create its DDG and return a pointer to a variable\n+   of ddg type that represents it.\n+   Initialize the ddg structure fields to the appropriate values.  */\n+ddg_ptr\n+create_ddg (basic_block bb, struct df *df, int closing_branch_deps)\n+{\n+  ddg_ptr g;\n+  rtx insn, first_note;\n+  int i;\n+  int num_nodes = 0;\n+\n+  g = (ddg_ptr) xcalloc (1, sizeof (struct ddg));\n+\n+  g->bb = bb;\n+  g->closing_branch_deps = closing_branch_deps;\n+\n+  /* Count the number of insns in the BB.  */\n+  for (insn = BB_HEAD (bb); insn != NEXT_INSN (BB_END (bb));\n+       insn = NEXT_INSN (insn))\n+    {\n+      if (! INSN_P (insn) || GET_CODE (PATTERN (insn)) == USE)\n+\tcontinue;\n+\n+      if (mem_read_insn_p (insn))\n+\tg->num_loads++;\n+      if (mem_write_insn_p (insn))\n+\tg->num_stores++;\n+      num_nodes++;\n+    }\n+\n+  /* There is nothing to do for this BB.  */\n+  if (num_nodes <= 1)\n+    {\n+      free (g);\n+      return NULL;\n+    }\n+\n+  /* Allocate the nodes array, and initialize the nodes.  */\n+  g->num_nodes = num_nodes;\n+  g->nodes = (ddg_node_ptr) xcalloc (num_nodes, sizeof (struct ddg_node));\n+  g->closing_branch = NULL;\n+  i = 0;\n+  first_note = NULL_RTX;\n+  for (insn = BB_HEAD (bb); insn != NEXT_INSN (BB_END (bb));\n+       insn = NEXT_INSN (insn))\n+    {\n+      if (! INSN_P (insn))\n+\t{\n+\t  if (! first_note && GET_CODE (insn) == NOTE\n+\t      && NOTE_LINE_NUMBER (insn) !=  NOTE_INSN_BASIC_BLOCK)\n+\t    first_note = insn;\n+\t  continue;\n+\t}\n+      if (GET_CODE (insn) == JUMP_INSN)\n+\t{\n+\t  if (g->closing_branch)\n+\t    abort (); /* Found two branches in DDG.  */\n+\t  else\n+\t    g->closing_branch = &g->nodes[i];\n+\t}\n+      else if (GET_CODE (PATTERN (insn)) == USE)\n+\t{\n+\t  if (! first_note)\n+\t    first_note = insn;\n+\t  continue;\n+\t}\n+\n+      g->nodes[i].cuid = i;\n+      g->nodes[i].successors = sbitmap_alloc (num_nodes);\n+      sbitmap_zero (g->nodes[i].successors);\n+      g->nodes[i].predecessors = sbitmap_alloc (num_nodes);\n+      sbitmap_zero (g->nodes[i].predecessors);\n+      g->nodes[i].first_note = (first_note ? first_note : insn);\n+      g->nodes[i++].insn = insn;\n+      first_note = NULL_RTX;\n+    }\n+\n+  if (!g->closing_branch)\n+    abort ();  /* Found no branch in DDG.  */\n+\n+  /* Build the data dependecy graph.  */\n+  build_intra_loop_deps (g);\n+  build_inter_loop_deps (g, df);\n+  return g;\n+}\n+\n+/* Free all the memory allocated for the DDG.  */\n+void\n+free_ddg (ddg_ptr g)\n+{\n+  int i;\n+\n+  if (!g)\n+    return;\n+\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      ddg_edge_ptr e = g->nodes[i].out;\n+\n+      while (e)\n+\t{\n+\t  ddg_edge_ptr next = e->next_out;\n+\n+\t  free (e);\n+\t  e = next;\n+\t}\n+      sbitmap_free (g->nodes[i].successors);\n+      sbitmap_free (g->nodes[i].predecessors);\n+    }\n+  if (g->num_backarcs > 0)\n+    free (g->backarcs);\n+  free (g->nodes);\n+  free (g);\n+}\n+\n+void\n+print_ddg_edge (FILE *dump_file, ddg_edge_ptr e)\n+{\n+  char dep_c;\n+\n+  switch (e->type) {\n+    case OUTPUT_DEP :\n+      dep_c = 'O';\n+      break;\n+    case ANTI_DEP :\n+      dep_c = 'A';\n+      break;\n+    default:\n+      dep_c = 'T';\n+  }\n+\n+  fprintf (dump_file, \" [%d -(%c,%d,%d)-> %d] \", INSN_UID (e->src->insn),\n+\t   dep_c, e->latency, e->distance, INSN_UID (e->dest->insn));\n+}\n+\n+/* Print the DDG nodes with there in/out edges to the dump file.  */\n+void\n+print_ddg (FILE *dump_file, ddg_ptr g)\n+{\n+  int i;\n+\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      ddg_edge_ptr e;\n+\n+      print_rtl_single (dump_file, g->nodes[i].insn);\n+      fprintf (dump_file, \"OUT ARCS: \");\n+      for (e = g->nodes[i].out; e; e = e->next_out)\n+\tprint_ddg_edge (dump_file, e);\n+\n+      fprintf (dump_file, \"\\nIN ARCS: \");\n+      for (e = g->nodes[i].in; e; e = e->next_in)\n+\tprint_ddg_edge (dump_file, e);\n+\n+      fprintf (dump_file, \"\\n\");\n+    }\n+}\n+\n+/* Print the given DDG in VCG format.  */\n+void\n+vcg_print_ddg (FILE *dump_file, ddg_ptr g)\n+{\n+  int src_cuid;\n+\n+  fprintf (dump_file, \"graph: {\\n\");\n+  for (src_cuid = 0; src_cuid < g->num_nodes; src_cuid++)\n+    {\n+      ddg_edge_ptr e;\n+      int src_uid = INSN_UID (g->nodes[src_cuid].insn);\n+\n+      fprintf (dump_file, \"node: {title: \\\"%d_%d\\\" info1: \\\"\", src_cuid, src_uid);\n+      print_rtl_single (dump_file, g->nodes[src_cuid].insn);\n+      fprintf (dump_file, \"\\\"}\\n\");\n+      for (e = g->nodes[src_cuid].out; e; e = e->next_out)\n+\t{\n+\t  int dst_uid = INSN_UID (e->dest->insn);\n+\t  int dst_cuid = e->dest->cuid;\n+\n+\t  /* Give the backarcs a different color.  */\n+\t  if (e->distance > 0)\n+\t    fprintf (dump_file, \"backedge: {color: red \");\n+\t  else\n+\t    fprintf (dump_file, \"edge: { \");\n+\n+\t  fprintf (dump_file, \"sourcename: \\\"%d_%d\\\" \", src_cuid, src_uid);\n+\t  fprintf (dump_file, \"targetname: \\\"%d_%d\\\" \", dst_cuid, dst_uid);\n+\t  fprintf (dump_file, \"label: \\\"%d_%d\\\"}\\n\", e->latency, e->distance);\n+\t}\n+    }\n+  fprintf (dump_file, \"}\\n\");\n+}\n+\n+/* Create an edge and initialize it with given values.  */\n+static ddg_edge_ptr\n+create_ddg_edge (ddg_node_ptr src, ddg_node_ptr dest,\n+\t\t dep_type t, dep_data_type dt, int l, int d)\n+{\n+  ddg_edge_ptr e = (ddg_edge_ptr) xmalloc (sizeof (struct ddg_edge));\n+\n+  e->src = src;\n+  e->dest = dest;\n+  e->type = t;\n+  e->data_type = dt;\n+  e->latency = l;\n+  e->distance = d;\n+  e->next_in = e->next_out = NULL;\n+  e->aux.info = 0;\n+  return e;\n+}\n+\n+/* Add the given edge to the in/out linked lists of the DDG nodes.  */\n+static void\n+add_edge_to_ddg (ddg_ptr g ATTRIBUTE_UNUSED, ddg_edge_ptr e)\n+{\n+  ddg_node_ptr src = e->src;\n+  ddg_node_ptr dest = e->dest;\n+\n+  if (!src->successors || !dest->predecessors)\n+    abort (); /* Should have allocated the sbitmaps.  */\n+\n+  SET_BIT (src->successors, dest->cuid);\n+  SET_BIT (dest->predecessors, src->cuid);\n+  e->next_in = dest->in;\n+  dest->in = e;\n+  e->next_out = src->out;\n+  src->out = e;\n+}\n+\n+\n+\f\n+/* Algorithm for computing the recurrence_length of an scc.  We assume at\n+   for now that cycles in the data dependence graph contain a single backarc.\n+   This simplifies the algorithm, and can be generalized later.  */\n+static void\n+set_recurrence_length (ddg_scc_ptr scc, ddg_ptr g)\n+{\n+  int j;\n+  int result = -1;\n+\n+  for (j = 0; j < scc->num_backarcs; j++)\n+    {\n+      ddg_edge_ptr backarc = scc->backarcs[j];\n+      int length;\n+      int distance = backarc->distance;\n+      ddg_node_ptr src = backarc->dest;\n+      ddg_node_ptr dest = backarc->src;\n+\n+      length = longest_simple_path (g, src->cuid, dest->cuid, scc->nodes);\n+      if (length < 0 )\n+\t{\n+\t  /* fprintf (stderr, \"Backarc not on simple cycle in SCC.\\n\"); */\n+\t  continue;\n+\t}\n+      length += backarc->latency;\n+      result = MAX (result, (length / distance));\n+    }\n+  scc->recurrence_length = result;\n+}\n+\n+/* Create a new SCC given the set of its nodes.  Compute its recurrence_length\n+   and mark edges that belong to this scc as IN_SCC.  */\n+static ddg_scc_ptr\n+create_scc (ddg_ptr g, sbitmap nodes)\n+{\n+  ddg_scc_ptr scc;\n+  int u;\n+\n+  scc = (ddg_scc_ptr) xmalloc (sizeof (struct ddg_scc));\n+  scc->backarcs = NULL;\n+  scc->num_backarcs = 0;\n+  scc->nodes = sbitmap_alloc (g->num_nodes);\n+  sbitmap_copy (scc->nodes, nodes);\n+\n+  /* Mark the backarcs that belong to this SCC.  */\n+  EXECUTE_IF_SET_IN_SBITMAP (nodes, 0, u,\n+    {\n+      ddg_edge_ptr e;\n+      ddg_node_ptr n = &g->nodes[u];\n+\n+      for (e = n->out; e; e = e->next_out)\n+\tif (TEST_BIT (nodes, e->dest->cuid))\n+\t  {\n+\t    e->aux.count = IN_SCC;\n+\t    if (e->distance > 0)\n+\t      add_backarc_to_scc (scc, e);\n+\t  }\n+    });\n+\n+  set_recurrence_length (scc, g);\n+  return scc;\n+}\n+\n+/* Cleans the memory allocation of a given SCC.  */\n+static void\n+free_scc (ddg_scc_ptr scc)\n+{\n+  if (!scc)\n+    return;\n+\n+  sbitmap_free (scc->nodes);\n+  if (scc->num_backarcs > 0)\n+    free (scc->backarcs);\n+  free (scc);\n+}\n+\n+\n+/* Add a given edge known to be a backarc to the given DDG.  */\n+static void\n+add_backarc_to_ddg (ddg_ptr g, ddg_edge_ptr e)\n+{\n+  int size = (g->num_backarcs + 1) * sizeof (ddg_edge_ptr);\n+\n+  add_edge_to_ddg (g, e);\n+  g->backarcs = (ddg_edge_ptr *) xrealloc (g->backarcs, size);\n+  g->backarcs[g->num_backarcs++] = e;\n+}\n+\n+/* Add backarc to an SCC.  */\n+static void\n+add_backarc_to_scc (ddg_scc_ptr scc, ddg_edge_ptr e)\n+{\n+  int size = (scc->num_backarcs + 1) * sizeof (ddg_edge_ptr);\n+\n+  scc->backarcs = (ddg_edge_ptr *) xrealloc (scc->backarcs, size);\n+  scc->backarcs[scc->num_backarcs++] = e;\n+}\n+\n+/* Add the given SCC to the DDG.  */\n+static void\n+add_scc_to_ddg (ddg_all_sccs_ptr g, ddg_scc_ptr scc)\n+{\n+  int size = (g->num_sccs + 1) * sizeof (ddg_scc_ptr);\n+\n+  g->sccs = (ddg_scc_ptr *) xrealloc (g->sccs, size);\n+  g->sccs[g->num_sccs++] = scc;\n+}\n+\n+/* Given the instruction INSN return the node that represents it.  */\n+ddg_node_ptr\n+get_node_of_insn (ddg_ptr g, rtx insn)\n+{\n+  int i;\n+\n+  for (i = 0; i < g->num_nodes; i++)\n+    if (insn == g->nodes[i].insn)\n+      return &g->nodes[i];\n+  return NULL;\n+}\n+\n+/* Given a set OPS of nodes in the DDG, find the set of their successors\n+   which are not in OPS, and set their bits in SUCC.  Bits corresponding to\n+   OPS are cleared from SUCC.  Leaves the other bits in SUCC unchanged.  */\n+void\n+find_successors (sbitmap succ, ddg_ptr g, sbitmap ops)\n+{\n+  int i;\n+\n+  EXECUTE_IF_SET_IN_SBITMAP (ops, 0, i,\n+    {\n+      const sbitmap node_succ = NODE_SUCCESSORS (&g->nodes[i]);\n+      sbitmap_a_or_b (succ, succ, node_succ);\n+    });\n+\n+  /* We want those that are not in ops.  */\n+  sbitmap_difference (succ, succ, ops);\n+}\n+\n+/* Given a set OPS of nodes in the DDG, find the set of their predecessors\n+   which are not in OPS, and set their bits in PREDS.  Bits corresponding to\n+   OPS are cleared from PREDS.  Leaves the other bits in PREDS unchanged.  */\n+void\n+find_predecessors (sbitmap preds, ddg_ptr g, sbitmap ops)\n+{\n+  int i;\n+\n+  EXECUTE_IF_SET_IN_SBITMAP (ops, 0, i,\n+    {\n+      const sbitmap node_preds = NODE_PREDECESSORS (&g->nodes[i]);\n+      sbitmap_a_or_b (preds, preds, node_preds);\n+    });\n+\n+  /* We want those that are not in ops.  */\n+  sbitmap_difference (preds, preds, ops);\n+}\n+\n+\n+/* Compare function to be passed to qsort to order the backarcs in descending\n+   recMII order.  */\n+static int\n+compare_sccs (const void *s1, const void *s2)\n+{\n+  int rec_l1 = (*(ddg_scc_ptr *)s1)->recurrence_length;\n+  int rec_l2 = (*(ddg_scc_ptr *)s2)->recurrence_length; \n+  return ((rec_l2 > rec_l1) - (rec_l2 < rec_l1));\n+\t  \n+}\n+\n+/* Order the backarcs in descending recMII order using compare_sccs.  */\n+static void\n+order_sccs (ddg_all_sccs_ptr g)\n+{\n+  qsort (g->sccs, g->num_sccs, sizeof (ddg_scc_ptr),\n+\t (int (*) (const void *, const void *)) compare_sccs);\n+}\n+\n+/* Perform the Strongly Connected Components decomposing algorithm on the\n+   DDG and return DDG_ALL_SCCS structure that contains them.  */\n+ddg_all_sccs_ptr\n+create_ddg_all_sccs (ddg_ptr g)\n+{\n+  int i;\n+  int num_nodes = g->num_nodes;\n+  sbitmap from = sbitmap_alloc (num_nodes);\n+  sbitmap to = sbitmap_alloc (num_nodes);\n+  sbitmap scc_nodes = sbitmap_alloc (num_nodes);\n+  ddg_all_sccs_ptr sccs = (ddg_all_sccs_ptr)\n+\t\t\t  xmalloc (sizeof (struct ddg_all_sccs));\n+\n+  sccs->ddg = g;\n+  sccs->sccs = NULL;\n+  sccs->num_sccs = 0;\n+\n+  for (i = 0; i < g->num_backarcs; i++)\n+    {\n+      ddg_scc_ptr  scc;\n+      ddg_edge_ptr backarc = g->backarcs[i];\n+      ddg_node_ptr src = backarc->src;\n+      ddg_node_ptr dest = backarc->dest;\n+\n+      /* If the backarc already belongs to an SCC, continue.  */\n+      if (backarc->aux.count == IN_SCC)\n+\tcontinue;\n+\n+      sbitmap_zero (from);\n+      sbitmap_zero (to);\n+      SET_BIT (from, dest->cuid);\n+      SET_BIT (to, src->cuid);\n+\n+      if (find_nodes_on_paths (scc_nodes, g, from, to))\n+\t{\n+\t  scc = create_scc (g, scc_nodes);\n+\t  add_scc_to_ddg (sccs, scc);\n+\t}\n+    }\n+  order_sccs (sccs);\n+  sbitmap_free (from);\n+  sbitmap_free (to);\n+  sbitmap_free (scc_nodes);\n+  return sccs;\n+}\n+\n+/* Frees the memory allocated for all SCCs of the DDG, but keeps the DDG.  */\n+void\n+free_ddg_all_sccs (ddg_all_sccs_ptr all_sccs)\n+{\n+  int i;\n+\n+  if (!all_sccs)\n+    return;\n+\n+  for (i = 0; i < all_sccs->num_sccs; i++)\n+    free_scc (all_sccs->sccs[i]);\n+\n+  free (all_sccs);\n+}\n+\n+\f\n+/* Given FROM - a bitmap of source nodes - and TO - a bitmap of destination\n+   nodes - find all nodes that lie on paths from FROM to TO (not excluding\n+   nodes from FROM and TO).  Return non zero if nodes exist.  */\n+int\n+find_nodes_on_paths (sbitmap result, ddg_ptr g, sbitmap from, sbitmap to)\n+{\n+  int answer;\n+  int change, u;\n+  int num_nodes = g->num_nodes;\n+  sbitmap workset = sbitmap_alloc (num_nodes);\n+  sbitmap reachable_from = sbitmap_alloc (num_nodes);\n+  sbitmap reach_to = sbitmap_alloc (num_nodes);\n+  sbitmap tmp = sbitmap_alloc (num_nodes);\n+\n+  sbitmap_copy (reachable_from, from);\n+  sbitmap_copy (tmp, from);\n+\n+  change = 1;\n+  while (change)\n+    {\n+      change = 0;\n+      sbitmap_copy (workset, tmp);\n+      sbitmap_zero (tmp);\n+      EXECUTE_IF_SET_IN_SBITMAP (workset, 0, u,\n+\t{\n+\t  ddg_edge_ptr e;\n+\t  ddg_node_ptr u_node = &g->nodes[u];\n+\n+\t  for (e = u_node->out; e != (ddg_edge_ptr) 0; e = e->next_out)\n+\t    {\n+\t      ddg_node_ptr v_node = e->dest;\n+\t      int v = v_node->cuid;\n+\n+\t      if (!TEST_BIT (reachable_from, v))\n+\t\t{\n+\t\t  SET_BIT (reachable_from, v);\n+\t\t  SET_BIT (tmp, v);\n+\t\t  change = 1;\n+\t\t}\n+\t    }\n+\t});\n+    }\n+\n+  sbitmap_copy (reach_to, to);\n+  sbitmap_copy (tmp, to);\n+\n+  change = 1;\n+  while (change)\n+    {\n+      change = 0;\n+      sbitmap_copy (workset, tmp);\n+      sbitmap_zero (tmp);\n+      EXECUTE_IF_SET_IN_SBITMAP (workset, 0, u,\n+\t{\n+\t  ddg_edge_ptr e;\n+\t  ddg_node_ptr u_node = &g->nodes[u];\n+\n+\t  for (e = u_node->in; e != (ddg_edge_ptr) 0; e = e->next_in)\n+\t    {\n+\t      ddg_node_ptr v_node = e->src;\n+\t      int v = v_node->cuid;\n+\n+\t      if (!TEST_BIT (reach_to, v))\n+\t\t{\n+\t\t  SET_BIT (reach_to, v);\n+\t\t  SET_BIT (tmp, v);\n+\t\t  change = 1;\n+\t\t}\n+\t    }\n+\t});\n+    }\n+\n+  answer = sbitmap_a_and_b_cg (result, reachable_from, reach_to);\n+  sbitmap_free (workset);\n+  sbitmap_free (reachable_from);\n+  sbitmap_free (reach_to);\n+  sbitmap_free (tmp);\n+  return answer;\n+}\n+\n+\n+/* Updates the counts of U_NODE's successors (that belong to NODES) to be\n+   at-least as large as the count of U_NODE plus the latency between them.\n+   Sets a bit in TMP for each successor whose count was changed (increased).\n+   Returns non-zero if any count was changed.  */\n+static int\n+update_dist_to_successors (ddg_node_ptr u_node, sbitmap nodes, sbitmap tmp)\n+{\n+  ddg_edge_ptr e;\n+  int result = 0;\n+\n+  for (e = u_node->out; e; e = e->next_out)\n+    {\n+      ddg_node_ptr v_node = e->dest;\n+      int v = v_node->cuid;\n+\n+      if (TEST_BIT (nodes, v)\n+\t  && (e->distance == 0)\n+\t  && (v_node->aux.count < u_node->aux.count + e->latency))\n+\t{\n+\t  v_node->aux.count = u_node->aux.count + e->latency;\n+\t  SET_BIT (tmp, v);\n+\t  result = 1;\n+\t}\n+    }\n+  return result;\n+}\n+\n+\n+/* Find the length of a longest path from SRC to DEST in G,\n+   going only through NODES, and disregarding backarcs.  */\n+int\n+longest_simple_path (struct ddg * g, int src, int dest, sbitmap nodes)\n+{\n+  int i, u;\n+  int change = 1;\n+  int result;\n+  int num_nodes = g->num_nodes;\n+  sbitmap workset = sbitmap_alloc (num_nodes);\n+  sbitmap tmp = sbitmap_alloc (num_nodes);\n+\n+\n+  /* Data will hold the distance of the longest path found so far from\n+     src to each node.  Initialize to -1 = less than minimum.  */\n+  for (i = 0; i < g->num_nodes; i++)\n+    g->nodes[i].aux.count = -1;\n+  g->nodes[src].aux.count = 0;\n+\n+  sbitmap_zero (tmp);\n+  SET_BIT (tmp, src);\n+\n+  while (change)\n+    {\n+      change = 0;\n+      sbitmap_copy (workset, tmp);\n+      sbitmap_zero (tmp);\n+      EXECUTE_IF_SET_IN_SBITMAP (workset, 0, u,\n+\t{\n+\t  ddg_node_ptr u_node = &g->nodes[u];\n+\n+\t  change |= update_dist_to_successors (u_node, nodes, tmp);\n+\t});\n+    }\n+  result = g->nodes[dest].aux.count;\n+  sbitmap_free (workset);\n+  sbitmap_free (tmp);\n+  return result;\n+}"}, {"sha": "ea85ac4c0ff479dfb58d84b4bf5779b098c9e240", "filename": "gcc/ddg.h", "status": "added", "additions": 181, "deletions": 0, "changes": 181, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d397e8c6729cde9044c1ee42d28f2d1e98204cfc/gcc%2Fddg.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d397e8c6729cde9044c1ee42d28f2d1e98204cfc/gcc%2Fddg.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fddg.h?ref=d397e8c6729cde9044c1ee42d28f2d1e98204cfc", "patch": "@@ -0,0 +1,181 @@\n+/* DDG - Data Dependence Graph - interface.\n+   Copyright (C) 2004\n+   Free Software Foundation, Inc.\n+   Contributed by Ayal Zaks and Mustafa Hagog <zaks,mustafa@il.ibm.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#ifndef GCC_DDG_H\n+#define GCC_DDG_H\n+\n+\n+typedef struct ddg_node *ddg_node_ptr;\n+typedef struct ddg_edge *ddg_edge_ptr;\n+typedef struct ddg *ddg_ptr;\n+typedef struct ddg_scc *ddg_scc_ptr;\n+typedef struct ddg_all_sccs *ddg_all_sccs_ptr;\n+\n+typedef enum {TRUE_DEP, OUTPUT_DEP, ANTI_DEP} dep_type;\n+typedef enum {REG_OR_MEM_DEP, REG_DEP, MEM_DEP, REG_AND_MEM_DEP}\n+\t     dep_data_type;\n+\n+/* The following two macros enables direct access to the successors and\n+   predecessors bitmaps held in each ddg_node.  Do not make changes to\n+   these bitmaps, unless you want to change the DDG.  */\n+#define NODE_SUCCESSORS(x)  ((x)->successors)\n+#define NODE_PREDECESSORS(x)  ((x)->predecessors)\n+\n+/* A structure that represents a node in the DDG.  */\n+struct ddg_node\n+{\n+  /* Each node has a unique CUID index.  These indices increase monotonically\n+     (according to the order of the corresponding INSN in the BB), starting\n+     from 0 with no gaps.  */\n+  int cuid;\n+\n+  /* The insn represented by the node.  */\n+  rtx insn;\n+\n+  /* A note preceeding INSN (or INSN itself), such that all insns linked\n+     from FIRST_NOTE until INSN (inclusive of both) are moved together\n+     when reordering the insns.  This takes care of notes that should\n+     continue to preceed INSN.  */\n+  rtx first_note;\n+\n+  /* Incoming and outgoing dependency edges.  */\n+  ddg_edge_ptr in;\n+  ddg_edge_ptr out;\n+\n+  /* Each bit corresponds to a ddg_node according to its cuid, and is\n+     set iff the node is a successor/predecessor of \"this\" node.  */\n+  sbitmap successors;\n+  sbitmap predecessors;\n+\n+  /* For general use by algorithms manipulating the ddg.  */\n+  union {\n+    int count;\n+    void *info;\n+  } aux;\n+};\n+\n+/* A structure that represents an edge in the DDG.  */\n+struct ddg_edge\n+{\n+  /* The source and destination nodes of the dependency edge.  */\n+  ddg_node_ptr src;\n+  ddg_node_ptr dest;\n+\n+  /* TRUE, OUTPUT or ANTI dependency.  */\n+  dep_type type;\n+\n+  /* REG or MEM dependency.  */\n+  dep_data_type data_type;\n+\n+  /* Latency of the depedency.  */\n+  int latency;\n+\n+  /* The distance: number of loop iterations the dependency crosses.  */\n+  int distance;\n+\n+  /* The following two fields are used to form a linked list of the in/out\n+     going edges to/from each node.  */\n+  ddg_edge_ptr next_in;\n+  ddg_edge_ptr next_out;\n+\n+  /* For general use by algorithms manipulating the ddg.  */\n+  union {\n+    int count;\n+    void *info;\n+  } aux;\n+};\n+\n+/* This structure holds the Data Dependence Graph for a basic block.  */\n+struct ddg\n+{\n+  /* The basic block for which this DDG is built.  */\n+  basic_block bb;\n+\n+  /* Number of instructions in the basic block.  */\n+  int num_nodes;\n+\n+  /* Number of load/store instructions in the BB - statistics.  */\n+  int num_loads;\n+  int num_stores;\n+\n+  /* This array holds the nodes in the graph; it is indexed by the node\n+     cuid, which follows the order of the instructions in the BB.  */\n+  ddg_node_ptr nodes;\n+\n+  /* The branch closing the loop.  */\n+  ddg_node_ptr closing_branch;\n+\n+  /* Build dependence edges for closing_branch, when set.  In certain cases,\n+     the closing branch can be dealt with separately from the insns of the\n+     loop, and then no such deps are needed.  */\n+  int closing_branch_deps;\n+\n+  /* Array and number of backarcs (edges with distance > 0) in the DDG.  */\n+  ddg_edge_ptr *backarcs;\n+  int num_backarcs;\n+};\n+\n+\f\n+/* Holds information on an SCC (Strongly Connected Component) of the DDG.  */\n+struct ddg_scc\n+{\n+  /* A bitmap that represents the nodes of the DDG that are in the SCC.  */\n+  sbitmap nodes;\n+\n+  /* Array and number of backarcs (edges with distance > 0) in the SCC.  */\n+  ddg_edge_ptr *backarcs;\n+  int num_backarcs;\n+\n+  /* The maximum of (total_latency/total_distance) over all cycles in SCC.  */\n+  int recurrence_length;\n+};\n+\n+/* This structure holds the SCCs of the DDG.  */\n+struct ddg_all_sccs\n+{\n+  /* Array that holds the SCCs in the DDG, and their number.  */\n+  ddg_scc_ptr *sccs;\n+  int num_sccs;\n+\n+  ddg_ptr ddg;\n+};\n+\n+\f\n+ddg_ptr create_ddg (basic_block, struct df *, int closing_branch_deps);\n+void free_ddg (ddg_ptr);\n+\n+void print_ddg (FILE *, ddg_ptr);\n+void vcg_print_ddg (FILE *, ddg_ptr);\n+void print_ddg_edge (FILE *, ddg_edge_ptr);\n+\n+ddg_node_ptr get_node_of_insn (ddg_ptr, rtx);\n+\n+void find_successors (sbitmap result, ddg_ptr, sbitmap);\n+void find_predecessors (sbitmap result, ddg_ptr, sbitmap);\n+\n+ddg_all_sccs_ptr create_ddg_all_sccs (ddg_ptr);\n+void free_ddg_all_sccs (ddg_all_sccs_ptr);\n+\n+int find_nodes_on_paths (sbitmap result, ddg_ptr, sbitmap from, sbitmap to);\n+int longest_simple_path (ddg_ptr, int from, int to, sbitmap via);\n+\n+#endif /* GCC_DDG_H */"}, {"sha": "77dd6e8551b80c64cccda234ea4335fb1fd768ac", "filename": "gcc/modulo-sched.c", "status": "added", "additions": 2125, "deletions": 0, "changes": 2125, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d397e8c6729cde9044c1ee42d28f2d1e98204cfc/gcc%2Fmodulo-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d397e8c6729cde9044c1ee42d28f2d1e98204cfc/gcc%2Fmodulo-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmodulo-sched.c?ref=d397e8c6729cde9044c1ee42d28f2d1e98204cfc", "patch": "@@ -0,0 +1,2125 @@\n+/* Swing Modulo Scheduling implementation.\n+   Copyright (C) 2004\n+   Free Software Foundation, Inc.\n+   Contributed by Ayal Zaks and Mustafa Hagog <zaks,mustafa@il.ibm.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"toplev.h\"\n+#include \"rtl.h\"\n+#include \"tm_p.h\"\n+#include \"hard-reg-set.h\"\n+#include \"basic-block.h\"\n+#include \"regs.h\"\n+#include \"function.h\"\n+#include \"flags.h\"\n+#include \"insn-config.h\"\n+#include \"insn-attr.h\"\n+#include \"except.h\"\n+#include \"toplev.h\"\n+#include \"recog.h\"\n+#include \"sched-int.h\"\n+#include \"target.h\"\n+#include \"cfglayout.h\"\n+#include \"cfgloop.h\"\n+#include \"cfghooks.h\"\n+#include \"expr.h\"\n+#include \"params.h\"\n+#include \"gcov-io.h\"\n+#include \"df.h\"\n+#include \"ddg.h\"\n+\n+\n+/* This file contains the implementation of the Swing Modulo Scheduler,\n+   described in the following references:\n+   [1] J. Llosa, A. Gonzalez, E. Ayguade, M. Valero., and J. Eckhardt.\n+       Lifetime--sensitive modulo scheduling in a production environment.\n+       IEEE Trans. on Comps., 50(3), March 2001\n+   [2] J. Llosa, A. Gonzalez, E. Ayguade, and M. Valero.\n+       Swing Modulo Scheduling: A Lifetime Sensitive Approach.\n+       PACT '96 , pages 80-87, October 1996 (Boston - Massachussets - USA).\n+\n+   The basic structure is:\n+   1. Build a data-dependence graph (DDG) for each loop.\n+   2. Use the DDG to order the insns of a loop (not in topological order\n+      necessarily, but rather) trying to place each insn after all its\n+      predecessors _or_ after all its successors.\n+   3. Compute MII: a lower bound on the number of cycles to schedule the loop.\n+   4. Use the ordering to perform list-scheduling of the loop:\n+      1. Set II = MII.  We will try to schedule the loop within II cycles.\n+      2. Try to schedule the insns one by one according to the ordering.\n+\t For each insn compute an interval of cycles by considering already-\n+\t scheduled preds and succs (and associated latencies); try to place\n+\t the insn in the cycles of this window checking for potential\n+\t resource conflicts (using the DFA interface).\n+\t Note: this is different from the cycle-scheduling of schedule_insns;\n+\t here the insns are not scheduled monotonically top-down (nor bottom-\n+\t up).\n+      3. If failed in scheduling all insns - bump II++ and try again, unless\n+\t II reaches an upper bound MaxII, inwhich case report failure.\n+   5. If we succeeded in scheduling the loop within II cycles, we now\n+      generate prolog and epilog, decrease the counter of the loop, and\n+      perform modulo variable expansion for live ranges that span more than\n+      II cycles (i.e. use register copies to prevent a def from overwriting\n+      itself before reaching the use).\n+*/\n+\n+\f\n+/* This page defines partial-schedule structures and functions for\n+   modulo scheduling.  */\n+\n+typedef struct partial_schedule *partial_schedule_ptr;\n+typedef struct ps_insn *ps_insn_ptr;\n+\n+/* The minimum (absolute) cycle that a node of ps was scheduled in.  */\n+#define PS_MIN_CYCLE(ps) (((partial_schedule_ptr)(ps))->min_cycle)\n+\n+/* The maximum (absolute) cycle that a node of ps was scheduled in.  */\n+#define PS_MAX_CYCLE(ps) (((partial_schedule_ptr)(ps))->max_cycle)\n+\n+/* Perform signed modulo, always returning a non-negative value.  */\n+#define SMODULO(x,y) ((x) % (y) < 0 ? ((x) % (y) + (y)) : (x) % (y))\n+\n+/* The number of different iterations the nodes in ps span, assuming\n+   the stage boundaries are placed efficiently.  */\n+#define PS_STAGE_COUNT(ps) ((PS_MAX_CYCLE (ps) - PS_MIN_CYCLE (ps) \\\n+\t\t\t     + 1 + (ps)->ii - 1) / (ps)->ii)\n+\n+#define CFG_HOOKS cfg_layout_rtl_cfg_hooks\n+\n+/* A single instruction in the partial schedule.  */\n+struct ps_insn\n+{\n+  /* The corresponding DDG_NODE.  */\n+  ddg_node_ptr node;\n+\n+  /* The (absolute) cycle in which the PS instruction is scheduled.\n+     Same as SCHED_TIME (node).  */\n+  int cycle;\n+\n+  /* The next/prev PS_INSN in the same row.  */\n+  ps_insn_ptr next_in_row,\n+\t      prev_in_row;\n+\n+  /* The number of nodes in the same row that come after this node.  */\n+  int row_rest_count;\n+};\n+\n+/* Holds the partial schedule as an array of II rows.  Each entry of the\n+   array points to a linked list of PS_INSNs, which represents the\n+   instructions that are scheduled for that row.  */\n+struct partial_schedule\n+{\n+  int ii;\t/* Number of rows in the partial schedule.  */\n+  int history;  /* Threshold for conflict checking using DFA.  */\n+\n+  /* rows[i] points to linked list of insns scheduled in row i (0<=i<ii).  */\n+  ps_insn_ptr *rows;\n+\n+  /* The earliest absolute cycle of an insn in the partial schedule.  */\n+  int min_cycle;\n+\n+  /* The latest absolute cycle of an insn in the partial schedule.  */\n+  int max_cycle;\n+\n+  ddg_ptr g;\t/* The DDG of the insns in the partial schedule.  */\n+};\n+\n+\n+partial_schedule_ptr create_partial_schedule (int ii, ddg_ptr, int history);\n+void free_partial_schedule (partial_schedule_ptr);\n+void reset_partial_schedule (partial_schedule_ptr, int new_ii);\n+void print_partial_schedule (partial_schedule_ptr, FILE *);\n+ps_insn_ptr ps_add_node_check_conflicts (partial_schedule_ptr,\n+\t\t\t\t\t ddg_node_ptr node, int cycle);\n+void rotate_partial_schedule (partial_schedule_ptr, int);\n+void set_row_column_for_ps (partial_schedule_ptr);\n+\n+\f\n+/* This page defines constants and structures for the modulo scheduiing\n+   driver.  */\n+\n+/* As in haifa-sched.c:  */\n+/* issue_rate is the number of insns that can be scheduled in the same\n+   machine cycle.  It can be defined in the config/mach/mach.h file,\n+   otherwise we set it to 1.  */\n+\n+static int issue_rate;\n+\n+/* For printing statistics.  */\n+static FILE *stats_file;\n+\n+static int sms_order_nodes (ddg_ptr, int, int * result);\n+static void set_node_sched_params (ddg_ptr);\n+static partial_schedule_ptr sms_schedule_by_order (ddg_ptr, int, int,\n+\t\t\t\t\t\t   int *, FILE*);\n+static void permute_partial_schedule (partial_schedule_ptr ps, rtx last);\n+static void generate_prolog_epilog (partial_schedule_ptr, rtx, rtx, int);\n+static void duplicate_insns_of_cycles (partial_schedule_ptr ps,\n+\t\t\t\t       int from_stage, int to_stage,\n+\t\t\t\t       int is_prolog);\n+\n+\n+#define SCHED_ASAP(x) (((node_sched_params_ptr)(x)->aux.info)->asap)\n+#define SCHED_TIME(x) (((node_sched_params_ptr)(x)->aux.info)->time)\n+#define SCHED_FIRST_REG_MOVE(x) \\\n+\t(((node_sched_params_ptr)(x)->aux.info)->first_reg_move)\n+#define SCHED_NREG_MOVES(x) \\\n+\t(((node_sched_params_ptr)(x)->aux.info)->nreg_moves)\n+#define SCHED_ROW(x) (((node_sched_params_ptr)(x)->aux.info)->row)\n+#define SCHED_STAGE(x) (((node_sched_params_ptr)(x)->aux.info)->stage)\n+#define SCHED_COLUMN(x) (((node_sched_params_ptr)(x)->aux.info)->column)\n+\n+/* The scheduling parameters held for each node.  */\n+typedef struct node_sched_params\n+{\n+  int asap;\t/* A lower-bound on the absolute scheduling cycle.  */\n+  int time;\t/* The absolute scheduling cycle (time >= asap).  */\n+\n+  /* The following field (first_reg_move) is a pointer to the first\n+     register-move instruction added to handle the modulo-variable-expansion\n+     of the register defined by this node.  This register-move copies the\n+     original register defined by the node.  */\n+  rtx first_reg_move;\n+\n+  /* The number of register-move instructions added, immediately preceeding\n+     first_reg_move.  */\n+  int nreg_moves;\n+\n+  int row;    /* Holds time % ii.  */\n+  int stage;  /* Holds time / ii.  */\n+\n+  /* The column of a node inside the ps.  If nodes u, v are on the same row,\n+     u will preceed v if column (u) < column (v).  */\n+  int column;\n+} *node_sched_params_ptr;\n+\n+\f\n+/* The following three functions are copied from the current scheduler\n+   code in order to use sched_analyze() for computing the dependecies.\n+   They are used when initializing the sched_info structure.  */\n+static const char *\n+sms_print_insn (rtx insn, int aligned ATTRIBUTE_UNUSED)\n+{\n+  static char tmp[80];\n+\n+  sprintf (tmp, \"i%4d\", INSN_UID (insn));\n+  return tmp;\n+}\n+\n+static int\n+contributes_to_priority (rtx next, rtx insn)\n+{\n+  return BLOCK_NUM (next) == BLOCK_NUM (insn);\n+}\n+\n+static void\n+compute_jump_reg_dependencies (rtx insn ATTRIBUTE_UNUSED,\n+\t\t\t       regset cond_exec ATTRIBUTE_UNUSED,\n+\t\t\t       regset used ATTRIBUTE_UNUSED,\n+\t\t\t       regset set ATTRIBUTE_UNUSED)\n+{\n+}\n+\n+static struct sched_info sms_sched_info =\n+{\n+  NULL,\n+  NULL,\n+  NULL,\n+  NULL,\n+  NULL,\n+  sms_print_insn,\n+  contributes_to_priority,\n+  compute_jump_reg_dependencies,\n+  NULL, NULL,\n+  NULL, NULL,\n+  0, 0, 0\n+};\n+\n+\n+/* Return the register decremented and tested or zero if it is not a decrement\n+   and branch jump insn (similar to doloop_condition_get).  */\n+static rtx\n+doloop_register_get (rtx insn, rtx *comp)\n+{\n+  rtx pattern, cmp, inc, reg, condition;\n+\n+  if (GET_CODE (insn) != JUMP_INSN)\n+    return NULL_RTX;\n+  pattern = PATTERN (insn);\n+\n+  /* The canonical doloop pattern we expect is:\n+\n+     (parallel [(set (pc) (if_then_else (condition)\n+\t\t\t\t\t(label_ref (label))\n+\t\t\t\t\t(pc)))\n+\t\t(set (reg) (plus (reg) (const_int -1)))\n+\t\t(additional clobbers and uses)])\n+\n+    where condition is further restricted to be\n+      (ne (reg) (const_int 1)).  */\n+\n+  if (GET_CODE (pattern) != PARALLEL)\n+    return NULL_RTX;\n+\n+  cmp = XVECEXP (pattern, 0, 0);\n+  inc = XVECEXP (pattern, 0, 1);\n+  /* Return the compare rtx.  */\n+  *comp = cmp;\n+\n+  /* Check for (set (reg) (something)).  */\n+  if (GET_CODE (inc) != SET || ! REG_P (SET_DEST (inc)))\n+    return NULL_RTX;\n+\n+  /* Extract loop counter register.  */\n+  reg = SET_DEST (inc);\n+\n+  /* Check if something = (plus (reg) (const_int -1)).  */\n+  if (GET_CODE (SET_SRC (inc)) != PLUS\n+      || XEXP (SET_SRC (inc), 0) != reg\n+      || XEXP (SET_SRC (inc), 1) != constm1_rtx)\n+    return NULL_RTX;\n+\n+  /* Check for (set (pc) (if_then_else (condition)\n+\t\t\t\t       (label_ref (label))\n+\t\t\t\t       (pc))).  */\n+  if (GET_CODE (cmp) != SET\n+      || SET_DEST (cmp) != pc_rtx\n+      || GET_CODE (SET_SRC (cmp)) != IF_THEN_ELSE\n+      || GET_CODE (XEXP (SET_SRC (cmp), 1)) != LABEL_REF\n+      || XEXP (SET_SRC (cmp), 2) != pc_rtx)\n+    return NULL_RTX;\n+\n+  /* Extract loop termination condition.  */\n+  condition = XEXP (SET_SRC (cmp), 0);\n+\n+  /* Check if condition = (ne (reg) (const_int 1)), which is more\n+     restrictive than the check in doloop_condition_get:\n+     if ((GET_CODE (condition) != GE && GET_CODE (condition) != NE)\n+\t || GET_CODE (XEXP (condition, 1)) != CONST_INT).  */\n+  if (GET_CODE (condition) != NE\n+      || XEXP (condition, 1) != const1_rtx)\n+    return NULL_RTX;\n+\n+  if (XEXP (condition, 0) == reg)\n+    return reg;\n+\n+  return NULL_RTX;\n+}\n+\n+/* Check if COUNT_REG is set to a constant in the PRE_HEADER block, so\n+   that the number of iterations is a compile-time constant.  If so,\n+   return the rtx that sets COUNT_REG to a constant, and set COUNT to\n+   this constant.  Otherwise return 0.  */\n+static rtx\n+const_iteration_count (rtx count_reg, basic_block pre_header,\n+\t\t       HOST_WIDEST_INT * count)\n+{\n+  rtx insn;\n+  rtx head, tail;\n+  get_block_head_tail (pre_header->index, &head, &tail);\n+\n+  for (insn = tail; insn != PREV_INSN (head); insn = PREV_INSN (insn))\n+    if (INSN_P (insn) && single_set (insn) &&\n+\trtx_equal_p (count_reg, SET_DEST (single_set (insn))))\n+      {\n+\trtx pat = single_set (insn);\n+\n+\tif (GET_CODE (SET_SRC (pat)) == CONST_INT)\n+\t  {\n+\t    *count = INTVAL (SET_SRC (pat));\n+\t    return insn;\n+\t  }\n+\n+\treturn NULL_RTX;\n+      }\n+\n+  return NULL_RTX;\n+}\n+\n+/* A very simple resource-based lower bound on the initiation interval.\n+   ??? Improve the accuracy of this bound by considering the\n+   utilization of various units.  */\n+static int\n+res_MII (ddg_ptr g)\n+{\n+  return (g->num_nodes / issue_rate);\n+}\n+\n+\n+/* Points to the array that contains the sched data for each node.  */\n+static node_sched_params_ptr node_sched_params;\n+\n+/* Allocate sched_params for each node and initialize it.  Assumes that\n+   the aux field of each node contain the asap bound (computed earlier),\n+   and copies it into the sched_params field.  */\n+static void\n+set_node_sched_params (ddg_ptr g)\n+{\n+  int i;\n+\n+  /* Allocate for each node in the DDG a place to hold the \"sched_data\".  */\n+  /* Initialize ASAP/ALAP/HIGHT to zero.  */\n+  node_sched_params = (node_sched_params_ptr)\n+\t\t       xcalloc (g->num_nodes,\n+\t\t\t\tsizeof (struct node_sched_params));\n+\n+  /* Set the pointer of the general data of the node to point to the\n+     appropriate sched_params strcture.  */\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      /* Watch out for aliasing problems?  */\n+      node_sched_params[i].asap = g->nodes[i].aux.count;\n+      g->nodes[i].aux.info = &node_sched_params[i];\n+    }\n+}\n+\n+static void\n+print_node_sched_params (FILE * dump_file, int num_nodes)\n+{\n+  int i;\n+\n+  for (i = 0; i < num_nodes; i++)\n+    {\n+      node_sched_params_ptr nsp = &node_sched_params[i];\n+      rtx reg_move = nsp->first_reg_move;\n+      int j;\n+\n+      fprintf (dump_file, \"Node %d:\\n\", i);\n+      fprintf (dump_file, \" asap = %d:\\n\", nsp->asap);\n+      fprintf (dump_file, \" time = %d:\\n\", nsp->time);\n+      fprintf (dump_file, \" nreg_moves = %d:\\n\", nsp->nreg_moves);\n+      for (j = 0; j < nsp->nreg_moves; j++)\n+\t{\n+\t  fprintf (dump_file, \" reg_move = \");\n+\t  print_rtl_single (dump_file, reg_move);\n+\t  reg_move = PREV_INSN (reg_move);\n+\t}\n+    }\n+}\n+\n+/* Calculate an upper bound for II.  SMS should not schedule the loop if it\n+   requires more cycles than this bound.  Currently set to the sum of the\n+   longest latency edge for each node.  Reset based on experiments.  */\n+static int\n+calculate_maxii (ddg_ptr g)\n+{\n+  int i;\n+  int maxii = 0;\n+\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      ddg_node_ptr u = &g->nodes[i];\n+      ddg_edge_ptr e;\n+      int max_edge_latency = 0;\n+\n+      for (e = u->out; e; e = e->next_out)\n+\tmax_edge_latency = MAX (max_edge_latency, e->latency);\n+\n+      maxii += max_edge_latency;\n+    }\n+  return maxii;\n+}\n+\n+\n+/* Given the partial schdule, generate register moves when the length\n+   of the register live range is more than ii; the number of moves is\n+   determined according to the following equation:\n+\t\tSCHED_TIME (use) - SCHED_TIME (def)   { 1 broken loop-carried\n+   nreg_moves = ----------------------------------- - {   dependecnce.\n+\t\t\t      ii\t\t      { 0 if not.\n+   This handles the modulo-variable-expansions (mve's) needed for the ps.  */\n+static void\n+generate_reg_moves (partial_schedule_ptr ps)\n+{\n+  ddg_ptr g = ps->g;\n+  int ii = ps->ii;\n+  int i;\n+\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      ddg_node_ptr u = &g->nodes[i];\n+      ddg_edge_ptr e;\n+      int nreg_moves = 0, i_reg_move;\n+      sbitmap *uses_of_defs;\n+      rtx last_reg_move;\n+      rtx prev_reg, old_reg;\n+\n+      /* Compute the number of reg_moves needed for u, by looking at life\n+\t ranges started at u (excluding self-loops).  */\n+      for (e = u->out; e; e = e->next_out)\n+\tif (e->type == TRUE_DEP && e->dest != e->src)\n+\t  {\n+\t    int nreg_moves4e = (SCHED_TIME (e->dest) - SCHED_TIME (e->src)) / ii;\n+\n+\t    /* If dest preceeds src in the schedule of the kernel, then dest\n+\t       will read before src writes and we can save one reg_copy.  */\n+\t    if (SCHED_ROW (e->dest) == SCHED_ROW (e->src)\n+\t\t&& SCHED_COLUMN (e->dest) < SCHED_COLUMN (e->src))\n+\t      nreg_moves4e--;\n+\n+\t    nreg_moves = MAX (nreg_moves, nreg_moves4e);\n+\t  }\n+\n+      if (nreg_moves == 0)\n+\tcontinue;\n+\n+      /* Every use of the register defined by node may require a different\n+\t copy of this register, depending on the time the use is scheduled.\n+\t Set a bitmap vector, telling which nodes use each copy of this\n+\t register.  */\n+      uses_of_defs = sbitmap_vector_alloc (nreg_moves, g->num_nodes);\n+      sbitmap_vector_zero (uses_of_defs, nreg_moves);\n+      for (e = u->out; e; e = e->next_out)\n+\tif (e->type == TRUE_DEP && e->dest != e->src)\n+\t  {\n+\t    int dest_copy = (SCHED_TIME (e->dest) - SCHED_TIME (e->src)) / ii;\n+\n+\t    if (SCHED_ROW (e->dest) == SCHED_ROW (e->src)\n+\t\t&& SCHED_COLUMN (e->dest) < SCHED_COLUMN (e->src))\n+\t      dest_copy--;\n+\n+\t    if (dest_copy)\n+\t      SET_BIT (uses_of_defs[dest_copy - 1], e->dest->cuid);\n+\t  }\n+\n+      /* Now generate the reg_moves, attaching relevant uses to them.  */\n+      SCHED_NREG_MOVES (u) = nreg_moves;\n+      old_reg = prev_reg = copy_rtx (SET_DEST (single_set (u->insn)));\n+      last_reg_move = u->insn;\n+\n+      for (i_reg_move = 0; i_reg_move < nreg_moves; i_reg_move++)\n+\t{\n+\t  int i_use;\n+\t  rtx new_reg = gen_reg_rtx (GET_MODE (prev_reg));\n+\t  rtx reg_move = gen_move_insn (new_reg, prev_reg);\n+\n+\t  add_insn_before (reg_move, last_reg_move);\n+\t  last_reg_move = reg_move;\n+\n+\t  if (!SCHED_FIRST_REG_MOVE (u))\n+\t    SCHED_FIRST_REG_MOVE (u) = reg_move;\n+\n+\t  EXECUTE_IF_SET_IN_SBITMAP (uses_of_defs[i_reg_move], 0, i_use,\n+\t    replace_rtx (g->nodes[i_use].insn, old_reg, new_reg));\n+\n+\t  prev_reg = new_reg;\n+\t}\n+    }\n+}\n+\n+/* Bump the SCHED_TIMEs of all nodes to start from zero.  Set the values\n+   of SCHED_ROW and SCHED_STAGE.  */\n+static void\n+normalize_sched_times (partial_schedule_ptr ps)\n+{\n+  int i;\n+  ddg_ptr g = ps->g;\n+  int amount = PS_MIN_CYCLE (ps);\n+  int ii = ps->ii;\n+\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      ddg_node_ptr u = &g->nodes[i];\n+      int normalized_time = SCHED_TIME (u) - amount;\n+\n+      if (normalized_time < 0)\n+\tabort ();\n+\n+      SCHED_TIME (u) = normalized_time;\n+      SCHED_ROW (u) = normalized_time % ii;\n+      SCHED_STAGE (u) = normalized_time / ii;\n+    }\n+}\n+\n+/* Set SCHED_COLUMN of each node according to its position in PS.  */\n+static void\n+set_columns_for_ps (partial_schedule_ptr ps)\n+{\n+  int row;\n+\n+  for (row = 0; row < ps->ii; row++)\n+    {\n+      ps_insn_ptr cur_insn = ps->rows[row];\n+      int column = 0;\n+\n+      for (; cur_insn; cur_insn = cur_insn->next_in_row)\n+\tSCHED_COLUMN (cur_insn->node) = column++;\n+    }\n+}\n+\n+/* Permute the insns according to their order in PS, from row 0 to\n+   row ii-1, and position them right before LAST.  This schedules\n+   the insns of the loop kernel.  */\n+static void\n+permute_partial_schedule (partial_schedule_ptr ps, rtx last)\n+{\n+  int ii = ps->ii;\n+  int row;\n+  ps_insn_ptr ps_ij;\n+\n+  for (row = 0; row < ii ; row++)\n+    for (ps_ij = ps->rows[row]; ps_ij; ps_ij = ps_ij->next_in_row)\n+      if (PREV_INSN (last) != ps_ij->node->insn)\n+      \treorder_insns_nobb (ps_ij->node->first_note, ps_ij->node->insn,\n+\t\t\t    PREV_INSN (last));\n+}\n+\n+/* Used to generate the prologue & epilogue.  Duplicate the subset of\n+   nodes whose stages are between FROM_STAGE and TO_STAGE (inclusive\n+   of both), together with a prefix/suffix of their reg_moves.  */\n+static void\n+duplicate_insns_of_cycles (partial_schedule_ptr ps, int from_stage,\n+\t\t\t   int to_stage, int for_prolog)\n+{\n+  int row;\n+  ps_insn_ptr ps_ij;\n+\n+  for (row = 0; row < ps->ii; row++)\n+    for (ps_ij = ps->rows[row]; ps_ij; ps_ij = ps_ij->next_in_row)\n+      {\n+\tddg_node_ptr u_node = ps_ij->node;\n+\tint j, i_reg_moves;\n+\trtx reg_move = NULL_RTX;\n+\n+\tif (for_prolog)\n+\t  {\n+\t    /* SCHED_STAGE (u_node) >= from_stage == 0.  Generate increasing\n+\t       number of reg_moves starting with the second occurance of\n+\t       u_node, which is generated if its SCHED_STAGE <= to_stage.  */\n+\t    i_reg_moves = to_stage - SCHED_STAGE (u_node);\n+\t    i_reg_moves = MAX (i_reg_moves, 0);\n+\t    i_reg_moves = MIN (i_reg_moves, SCHED_NREG_MOVES (u_node));\n+\n+\t    /* The reg_moves start from the *first* reg_move backwards.  */\n+\t    if (i_reg_moves)\n+\t      {\n+\t\treg_move = SCHED_FIRST_REG_MOVE (u_node);\n+\t\tfor (j = 1; j < i_reg_moves; j++)\n+\t\t  reg_move = PREV_INSN (reg_move);\n+\t      }\n+\t  }\n+\telse /* It's for the epilog.  */\n+\t  {\n+\t    /* SCHED_STAGE (u_node) <= to_stage.  Generate all reg_moves,\n+\t       starting to decrease one stage after u_node no longer occurs;\n+\t       that is, generate all reg_moves until\n+\t       SCHED_STAGE (u_node) == from_stage - 1.  */\n+\t    i_reg_moves = SCHED_NREG_MOVES (u_node)\n+\t    \t       - (from_stage - SCHED_STAGE (u_node) - 1);\n+\t    i_reg_moves = MAX (i_reg_moves, 0);\n+\t    i_reg_moves = MIN (i_reg_moves, SCHED_NREG_MOVES (u_node));\n+\n+\t    /* The reg_moves start from the *last* reg_move forwards.  */\n+\t    if (i_reg_moves)\n+\t      {\n+\t\treg_move = SCHED_FIRST_REG_MOVE (u_node);\n+\t\tfor (j = 1; j < SCHED_NREG_MOVES (u_node); j++)\n+\t\t  reg_move = PREV_INSN (reg_move);\n+\t      }\n+\t  }\n+\n+\tfor (j = 0; j < i_reg_moves; j++, reg_move = NEXT_INSN (reg_move))\n+\t  emit_insn (copy_rtx (PATTERN (reg_move)));\n+\n+\tif (SCHED_STAGE (u_node) >= from_stage\n+\t    && SCHED_STAGE (u_node) <= to_stage)\n+\t  duplicate_insn_chain (u_node->first_note, u_node->insn);\n+      }\n+}\n+\n+\n+/* Generate the instructions (including reg_moves) for prolog & epilog.  */\n+static void\n+generate_prolog_epilog (partial_schedule_ptr ps, rtx orig_loop_beg,\n+\t\t\trtx orig_loop_end, int unknown_count)\n+{\n+  int i;\n+  int last_stage = PS_STAGE_COUNT (ps) - 1;\n+  edge e;\n+  rtx c_reg = NULL_RTX;\n+  rtx cmp = NULL_RTX;\n+  rtx precond_jump = NULL_RTX;\n+  rtx precond_exit_label = NULL_RTX;\n+  rtx precond_exit_label_insn = NULL_RTX;\n+  rtx last_epilog_insn = NULL_RTX;\n+  rtx loop_exit_label = NULL_RTX;\n+  rtx loop_exit_label_insn = NULL_RTX;\n+  rtx orig_loop_bct = NULL_RTX;\n+\n+  /* Loop header edge.  */\n+  e = ps->g->bb->pred;\n+  if (e->src == ps->g->bb)\n+    e = e->pred_next;\n+\n+  /* Generate the prolog, inserting its insns on the loop-entry edge.  */\n+  start_sequence ();\n+\n+  /* This is the place where we want to insert the precondition.  */\n+  if (unknown_count)\n+    precond_jump = emit_note (NOTE_INSN_DELETED);\n+\n+  for (i = 0; i < last_stage; i++)\n+    duplicate_insns_of_cycles (ps, 0, i, 1);\n+\n+  /* No need to call insert_insn_on_edge; we prepared the sequence.  */\n+  e->insns.r = get_insns ();\n+  end_sequence ();\n+\n+  /* Generate the epilog, inserting its insns on the loop-exit edge.  */\n+  start_sequence ();\n+\n+  for (i = 0; i < last_stage; i++)\n+    duplicate_insns_of_cycles (ps, i + 1, last_stage, 0);\n+\n+  last_epilog_insn = emit_note (NOTE_INSN_DELETED);\n+\n+  /* Emit the label where to put the original loop code.  */\n+  if (unknown_count)\n+    {\n+      rtx label, cond;\n+\n+      precond_exit_label = gen_label_rtx ();\n+      precond_exit_label_insn = emit_label (precond_exit_label);\n+\n+      /* Put the original loop code.  */\n+      reorder_insns_nobb (orig_loop_beg, orig_loop_end, precond_exit_label_insn);\n+\n+      /* Change the label of the BCT to be the PRECOND_EXIT_LABEL.  */\n+      orig_loop_bct = get_last_insn ();\n+      c_reg = doloop_register_get (orig_loop_bct, &cmp);\n+      label = XEXP (SET_SRC (cmp), 1);\n+      cond = XEXP (SET_SRC (cmp), 0);\n+\n+      if (! c_reg || GET_CODE (cond) != NE)\n+        abort ();\n+\n+      XEXP (label, 0) = precond_exit_label;\n+      JUMP_LABEL (orig_loop_bct) = precond_exit_label_insn;\n+      LABEL_NUSES (precond_exit_label_insn)++;\n+\n+      /* Generate the loop exit label.  */\n+      loop_exit_label = gen_label_rtx ();\n+      loop_exit_label_insn = emit_label (loop_exit_label);\n+    }\n+\n+  e = ps->g->bb->succ;\n+  if (e->dest == ps->g->bb)\n+    e = e->succ_next;\n+\n+  e->insns.r = get_insns ();\n+  end_sequence ();\n+\n+  commit_edge_insertions ();\n+\n+  if (unknown_count)\n+    {\n+      rtx precond_insns, epilog_jump, insert_after_insn;\n+      basic_block loop_exit_bb = BLOCK_FOR_INSN (loop_exit_label_insn);\n+      basic_block epilog_bb = BLOCK_FOR_INSN (last_epilog_insn);\n+      basic_block precond_bb = BLOCK_FOR_INSN (precond_jump);\n+      basic_block orig_loop_bb = BLOCK_FOR_INSN (precond_exit_label_insn);\n+      edge epilog_exit_edge = epilog_bb->succ;\n+\n+      /* Do loop preconditioning to take care of cases were the loop count is\n+\t less than the stage count.  Update the CFG properly.  */\n+      insert_after_insn = precond_jump;\n+      start_sequence ();\n+      c_reg = doloop_register_get (ps->g->closing_branch->insn, &cmp);\n+      emit_cmp_and_jump_insns (c_reg, GEN_INT (PS_STAGE_COUNT (ps)), LT, NULL,\n+      \t\t\t       GET_MODE (c_reg), 1, precond_exit_label);\n+      precond_insns = get_insns ();\n+      precond_jump = get_last_insn ();\n+      end_sequence ();\n+      reorder_insns (precond_insns, precond_jump, insert_after_insn);\n+\n+      /* Generate a subtract instruction at the beginning of the prolog to\n+\t adjust the loop count by STAGE_COUNT.  */\n+      emit_insn_after (gen_sub2_insn (c_reg, GEN_INT (PS_STAGE_COUNT (ps) - 1)),\n+                       precond_jump);\n+      update_bb_for_insn (precond_bb);\n+      delete_insn (insert_after_insn);\n+\n+      /* Update label info for the precondition jump.  */\n+      JUMP_LABEL (precond_jump) = precond_exit_label_insn;\n+      LABEL_NUSES (precond_exit_label_insn)++;\n+\n+      /* Update the CFG.  */\n+      split_block (precond_bb, precond_jump);\n+      make_edge (precond_bb, orig_loop_bb, 0);\n+\n+      /* Add a jump at end of the epilog to the LOOP_EXIT_LABEL to jump over the\n+\t original loop copy and update the CFG.  */\n+      epilog_jump = emit_jump_insn_after (gen_jump (loop_exit_label),\n+      \t\t\t\t\t  last_epilog_insn);\n+      delete_insn (last_epilog_insn);\n+      JUMP_LABEL (epilog_jump) = loop_exit_label_insn;\n+      LABEL_NUSES (loop_exit_label_insn)++;\n+\n+      redirect_edge_succ (epilog_exit_edge, loop_exit_bb);\n+      epilog_exit_edge->flags &= ~EDGE_FALLTHRU;\n+      emit_barrier_after (BB_END (epilog_bb));\n+    }\n+}\n+\n+/* Return the line note insn preceding INSN, for debugging.  Taken from\n+   emit-rtl.c.  */\n+static rtx\n+find_line_note (rtx insn)\n+{\n+  for (; insn; insn = PREV_INSN (insn))\n+    if (GET_CODE (insn) == NOTE\n+\t&& NOTE_LINE_NUMBER (insn) >= 0)\n+      break;\n+\n+  return insn;\n+}\n+\n+/* Main entry point, perform SMS scheduling on the loops of the function\n+   that consist of single basic blocks.  */\n+void\n+sms_schedule (FILE *dump_file)\n+{\n+  static int passes = 0;\n+  rtx insn;\n+  ddg_ptr *g_arr, g;\n+  basic_block bb, pre_header = NULL;\n+  int * node_order;\n+  int maxii;\n+  int i;\n+  partial_schedule_ptr ps;\n+  int max_bb_index = last_basic_block;\n+  struct df *df;\n+\n+  /* SMS uses the DFA interface.  */\n+  if (! targetm.sched.use_dfa_pipeline_interface\n+      || ! (*targetm.sched.use_dfa_pipeline_interface) ())\n+    return;\n+\n+  stats_file = dump_file;\n+\n+\n+  /* Initialize issue_rate.  */\n+  if (targetm.sched.issue_rate)\n+    {\n+      int temp = reload_completed;\n+\n+      reload_completed = 1;\n+      issue_rate = (*targetm.sched.issue_rate) ();\n+      reload_completed = temp;\n+    }\n+  else\n+    issue_rate = 1;\n+\n+  /* Initilize the scheduler.  */\n+  current_sched_info = &sms_sched_info;\n+  sched_init (NULL);\n+\n+  /* Init Data Flow analysis, to be used in interloop dep calculation.  */\n+  df = df_init ();\n+  df_analyze (df, 0, DF_ALL);\n+\n+  /* Allocate memory to hold the DDG array.  */\n+  g_arr = xcalloc (max_bb_index, sizeof (ddg_ptr));\n+\n+  /* Build DDGs for all the relevant loops and hold them in G_ARR\n+     indexed by the loop BB index.  */\n+  FOR_EACH_BB (bb)\n+    {\n+      rtx head, tail;\n+      rtx count_reg, comp;\n+      edge e, pre_header_edge;\n+\n+      if (bb->index < 0)\n+\tcontinue;\n+\n+      /* Check if bb has two successors, one being itself.  */\n+      e = bb->succ;\n+      if (!e || !e->succ_next || e->succ_next->succ_next)\n+\tcontinue;\n+\n+      if (e->dest != bb && e->succ_next->dest != bb)\n+\tcontinue;\n+\n+      if ((e->flags & EDGE_COMPLEX)\n+\t  || (e->succ_next->flags & EDGE_COMPLEX))\n+\tcontinue;\n+\n+      /* Check if bb has two predecessors, one being itself.  */\n+      /* In view of above tests, suffices to check e->pred_next->pred_next?  */\n+      e = bb->pred;\n+      if (!e || !e->pred_next || e->pred_next->pred_next)\n+\tcontinue;\n+\n+      if (e->src != bb && e->pred_next->src != bb)\n+\tcontinue;\n+\n+      if ((e->flags & EDGE_COMPLEX)\n+\t  || (e->pred_next->flags & EDGE_COMPLEX))\n+\tcontinue;\n+\n+      /* For debugging.  */\n+      if (passes++ > MAX_SMS_LOOP_NUMBER && MAX_SMS_LOOP_NUMBER != -1)\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \"SMS reached MAX_PASSES... \\n\");\n+\t  break;\n+\t}\n+\n+      get_block_head_tail (bb->index, &head, &tail);\n+      pre_header_edge = bb->pred;\n+      if (bb->pred->src != bb)\n+\tpre_header_edge = bb->pred->pred_next;\n+\n+      /* Perfrom SMS only on loops that their average count is above threshold.  */\n+      if (bb->count < pre_header_edge->count * SMS_LOOP_AVERAGE_COUNT_THRESHOLD)\n+        {\n+\t  if (stats_file)\n+\t    {\n+\t      rtx line_note = find_line_note (tail);\n+\n+\t      if (line_note)\n+\t    \tfprintf (stats_file, \"SMS bb %s %d (file, line)\\n\",\n+\t\t     \t NOTE_SOURCE_FILE (line_note), NOTE_LINE_NUMBER (line_note));\n+\t      fprintf (stats_file, \"SMS single-bb-loop\\n\");\n+\t      if (profile_info && flag_branch_probabilities)\n+\t    \t{\n+\t      \t  fprintf (stats_file, \"SMS loop-count \");\n+\t      \t  fprintf (stats_file, HOST_WIDEST_INT_PRINT_DEC,\n+\t             \t   (HOST_WIDEST_INT) bb->count);\n+\t      \t  fprintf (stats_file, \"\\n\");\n+\t      \t  fprintf (stats_file, \"SMS preheader-count \");\n+\t      \t  fprintf (stats_file, HOST_WIDEST_INT_PRINT_DEC,\n+\t           \t   (HOST_WIDEST_INT) pre_header_edge->count);\n+\t      \t  fprintf (stats_file, \"\\n\");\n+\t      \t  fprintf (stats_file, \"SMS profile-sum-max \");\n+\t      \t  fprintf (stats_file, HOST_WIDEST_INT_PRINT_DEC,\n+\t          \t   (HOST_WIDEST_INT) profile_info->sum_max);\n+\t      \t  fprintf (stats_file, \"\\n\");\n+\t    \t}\n+\t    }\n+          continue;\n+        }\n+\n+      /* Make sure this is a doloop.  */\n+      if ( !(count_reg = doloop_register_get (tail, &comp)))\n+\tcontinue;\n+\n+      e = bb->pred;\n+      if (e->src == bb)\n+\tpre_header = e->pred_next->src;\n+      else\n+\tpre_header = e->src;\n+\n+      /* Don't handle BBs with calls or barriers, or !single_set insns.  */\n+      for (insn = head; insn != NEXT_INSN (tail); insn = NEXT_INSN (insn))\n+\tif (GET_CODE (insn) == CALL_INSN\n+\t    || GET_CODE (insn) == BARRIER\n+\t    || (INSN_P (insn) && GET_CODE (insn) != JUMP_INSN\n+\t\t&& !single_set (insn) && GET_CODE (PATTERN (insn)) != USE))\n+\t  break;\n+\n+      if (insn != NEXT_INSN (tail))\n+\t{\n+\t  if (stats_file)\n+\t    {\n+\t      if (GET_CODE (insn) == CALL_INSN)\n+\t\tfprintf (stats_file, \"SMS loop-with-call\\n\");\n+\t      else if (GET_CODE (insn) == BARRIER)\n+\t\tfprintf (stats_file, \"SMS loop-with-barrier\\n\");\n+\t      else\n+\t\tfprintf (stats_file, \"SMS loop-with-not-single-set\\n\");\n+\t      print_rtl_single (stats_file, insn);\n+\t    }\n+\n+\t  continue;\n+\t}\n+\n+      if (! (g = create_ddg (bb, df, 0)))\n+        {\n+          if (stats_file)\n+\t    fprintf (stats_file, \"SMS doloop\\n\");\n+\t  continue;\n+        }\n+\n+      g_arr[bb->index] = g;\n+    }\n+\n+  /* Release Data Flow analysis data structures.  */\n+  df_finish (df);\n+\n+  /* Go over the built DDGs and perfrom SMS for each one of them.  */\n+  for (i = 0; i < max_bb_index; i++)\n+    {\n+      rtx head, tail;\n+      rtx count_reg, count_init, comp;\n+      edge pre_header_edge;\n+      int mii, rec_mii;\n+      int stage_count = 0;\n+      HOST_WIDEST_INT loop_count = 0;\n+\n+      if (! (g = g_arr[i]))\n+        continue;\n+\n+      if (dump_file)\n+\tprint_ddg (dump_file, g);\n+\n+      get_block_head_tail (g->bb->index, &head, &tail);\n+\n+      pre_header_edge = g->bb->pred;\n+      if (g->bb->pred->src != g->bb)\n+\tpre_header_edge = g->bb->pred->pred_next;\n+\n+      if (stats_file)\n+\t{\n+\t  rtx line_note = find_line_note (tail);\n+\n+\t  if (line_note)\n+\t    fprintf (stats_file, \"SMS bb %s %d (file, line)\\n\",\n+\t\t     NOTE_SOURCE_FILE (line_note), NOTE_LINE_NUMBER (line_note));\n+\t  fprintf (stats_file, \"SMS single-bb-loop\\n\");\n+\t  if (profile_info && flag_branch_probabilities)\n+\t    {\n+\t      fprintf (stats_file, \"SMS loop-count \");\n+\t      fprintf (stats_file, HOST_WIDEST_INT_PRINT_DEC,\n+\t               (HOST_WIDEST_INT) bb->count);\n+\t      fprintf (stats_file, \"\\n\");\n+\t      fprintf (stats_file, \"SMS preheader-count \");\n+\t      fprintf (stats_file, HOST_WIDEST_INT_PRINT_DEC,\n+\t               (HOST_WIDEST_INT) pre_header_edge->count);\n+\t      fprintf (stats_file, \"\\n\");\n+\t      fprintf (stats_file, \"SMS profile-sum-max \");\n+\t      fprintf (stats_file, HOST_WIDEST_INT_PRINT_DEC,\n+\t               (HOST_WIDEST_INT) profile_info->sum_max);\n+\t      fprintf (stats_file, \"\\n\");\n+\t    }\n+\t  fprintf (stats_file, \"SMS doloop\\n\");\n+\t  fprintf (stats_file, \"SMS built-ddg %d\\n\", g->num_nodes);\n+          fprintf (stats_file, \"SMS num-loads %d\\n\", g->num_loads);\n+          fprintf (stats_file, \"SMS num-stores %d\\n\", g->num_stores);\n+\t}\n+\n+      /* Make sure this is a doloop.  */\n+      if ( !(count_reg = doloop_register_get (tail, &comp)))\n+\tabort ();\n+\n+      /* This should be NULL_RTX if the count is unknown at compile time.  */\n+      count_init = const_iteration_count (count_reg, pre_header, &loop_count);\n+\n+      if (stats_file && count_init)\n+        {\n+          fprintf (stats_file, \"SMS const-doloop \");\n+          fprintf (stats_file, HOST_WIDEST_INT_PRINT_DEC, loop_count);\n+          fprintf (stats_file, \"\\n\");\n+        }\n+\n+      node_order = (int *) xmalloc (sizeof (int) * g->num_nodes);\n+\n+      mii = 1; /* Need to pass some estimate of mii.  */\n+      rec_mii = sms_order_nodes (g, mii, node_order);\n+      mii = MAX (res_MII (g), rec_mii);\n+      maxii = (calculate_maxii (g) * SMS_MAX_II_FACTOR) / 100;\n+\n+      if (stats_file)\n+\tfprintf (stats_file, \"SMS iis %d %d %d (rec_mii, mii, maxii)\\n\",\n+\t\t rec_mii, mii, maxii);\n+\n+      /* After sms_order_nodes and before sms_schedule_by_order, to copy over\n+\t ASAP.  */\n+      set_node_sched_params (g);\n+\n+      ps = sms_schedule_by_order (g, mii, maxii, node_order, dump_file);\n+\n+      if (ps)\n+\tstage_count = PS_STAGE_COUNT (ps);\n+\n+      if (stage_count == 0 || (count_init && (stage_count > loop_count)))\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \"SMS failed... \\n\");\n+\t  if (stats_file)\n+\t    fprintf (stats_file, \"SMS sched-failed %d\\n\", stage_count);\n+\t}\n+      else\n+\t{\n+          rtx orig_loop_beg = NULL_RTX;\n+\t  rtx orig_loop_end = NULL_RTX;\n+\n+\t  if (stats_file)\n+\t    {\n+\t      fprintf (stats_file,\n+\t\t       \"SMS succeeded %d %d (with ii, sc)\\n\", ps->ii,\n+\t\t       stage_count);\n+\t      print_partial_schedule (ps, dump_file);\n+\t      fprintf (dump_file,\n+\t\t       \"SMS Branch (%d) will later be scheduled at cycle %d.\\n\",\n+\t\t       g->closing_branch->cuid, PS_MIN_CYCLE (ps) - 1);\n+\t    }\n+\n+          /* Save the original loop if we want to do loop preconditioning in\n+\t     case the BCT count is not known.  */\n+          if (! count_init)\n+            {\n+\t      int i;\n+\n+              start_sequence ();\n+\t      /* Copy the original loop code before modifying it - so we can use\n+\t\t it later.  */\n+\t      for (i = 0; i < ps->g->num_nodes; i++)\n+\t\tduplicate_insn_chain (ps->g->nodes[i].first_note,\n+\t\t\t\t      ps->g->nodes[i].insn);\n+\n+\t      orig_loop_beg = get_insns ();\n+              orig_loop_end = get_last_insn ();\n+\t      end_sequence ();\n+            }\n+\t  /* Set the stage boundaries.  If the DDG is built with closing_branch_deps,\n+\t     the closing_branch was scheduled and should appear in the last (ii-1)\n+\t     row.  Otherwise, we are free to schedule the branch, and we let nodes\n+\t     that were scheduled at the first PS_MIN_CYCLE cycle appear in the first\n+\t     row; this should reduce stage_count to minimum.  */\n+\t  normalize_sched_times (ps);\n+\t  rotate_partial_schedule (ps, PS_MIN_CYCLE (ps));\n+\t  set_columns_for_ps (ps);\n+\n+\t  permute_partial_schedule (ps, g->closing_branch->first_note);\n+\t  generate_reg_moves (ps);\n+\t  if (dump_file)\n+\t    print_node_sched_params (dump_file, g->num_nodes);\n+\n+\t  /* Set new iteration count of loop kernel.  */\n+          if (count_init)\n+\t    SET_SRC (single_set (count_init)) = GEN_INT (loop_count\n+                                                         - stage_count + 1);\n+\n+\t  /* Generate prolog and epilog.  */\n+\t  generate_prolog_epilog (ps, orig_loop_beg, orig_loop_end,\n+\t\t\t\t  count_init ? 0 : 1);\n+\t}\n+      free_partial_schedule (ps);\n+      free (node_sched_params);\n+      free (node_order);\n+      free_ddg (g);\n+    }\n+\n+  /* Release scheduler data, needed until now because of DFA.  */\n+  sched_finish ();\n+}\n+\n+/* The SMS scheduling algorithm itself\n+   -----------------------------------\n+   Input: 'O' an ordered list of insns of a loop.\n+   Output: A scheduling of the loop - kernel, prolog, and epilogue.\n+\n+   'Q' is the empty Set\n+   'PS' is the partial schedule; it holds the currently scheduled nodes with\n+\ttheir cycle/slot.\n+   'PSP' previously scheduled predecessors.\n+   'PSS' previously scheduled successors.\n+   't(u)' the cycle where u is scheduled.\n+   'l(u)' is the latency of u.\n+   'd(v,u)' is the dependence distance from v to u.\n+   'ASAP(u)' the earliest time at which u could be scheduled as computed in\n+\t     the node ordering phase.\n+   'check_hardware_resources_conflicts(u, PS, c)'\n+\t\t\t     run a trace around cycle/slot through DFA model\n+\t\t\t     to check resource conflicts involving instruction u\n+\t\t\t     at cycle c given the partial schedule PS.\n+   'add_to_partial_schedule_at_time(u, PS, c)'\n+\t\t\t     Add the node/instruction u to the partial schedule\n+\t\t\t     PS at time c.\n+   'calculate_register_pressure(PS)'\n+\t\t\t     Given a schedule of instructions, calculate the register\n+\t\t\t     pressure it implies.  One implementation could be the\n+\t\t\t     maximum number of overlapping live ranges.\n+   'maxRP' The maximum allowed register pressure, it is usually derived from the number\n+\t   registers available in the hardware.\n+\n+   1. II = MII.\n+   2. PS = empty list\n+   3. for each node u in O in pre-computed order\n+   4.   if (PSP(u) != Q && PSS(u) == Q) then\n+   5.     Early_start(u) = max ( t(v) + l(v) - d(v,u)*II ) over all every v in PSP(u).\n+   6.     start = Early_start; end = Early_start + II - 1; step = 1\n+   11.  else if (PSP(u) == Q && PSS(u) != Q) then\n+   12.      Late_start(u) = min ( t(v) - l(v) + d(v,u)*II ) over all every v in PSS(u).\n+   13.     start = Late_start; end = Late_start - II + 1; step = -1\n+   14.  else if (PSP(u) != Q && PSS(u) != Q) then\n+   15.     Early_start(u) = max ( t(v) + l(v) - d(v,u)*II ) over all every v in PSP(u).\n+   16.     Late_start(u) = min ( t(v) - l(v) + d(v,u)*II ) over all every v in PSS(u).\n+   17.     start = Early_start;\n+   18.     end = min(Early_start + II - 1 , Late_start);\n+   19.     step = 1\n+   20.     else \"if (PSP(u) == Q && PSS(u) == Q)\"\n+   21.\t  start = ASAP(u); end = start + II - 1; step = 1\n+   22.  endif\n+\n+   23.  success = false\n+   24.  for (c = start ; c != end ; c += step)\n+   25.     if check_hardware_resources_conflicts(u, PS, c) then\n+   26.       add_to_partial_schedule_at_time(u, PS, c)\n+   27.       success = true\n+   28.       break\n+   29.     endif\n+   30.  endfor\n+   31.  if (success == false) then\n+   32.    II = II + 1\n+   33.    if (II > maxII) then\n+   34.       finish - failed to schedule\n+   35.\t endif\n+   36.    goto 2.\n+   37.  endif\n+   38. endfor\n+   39. if (calculate_register_pressure(PS) > maxRP) then\n+   40.    goto 32.\n+   41. endif\n+   42. compute epilogue & prologue\n+   43. finish - succeeded to schedule\n+*/\n+\n+/* A limit on the number of cycles that resource conflicts can span.  ??? Should\n+   be provided by DFA, and be dependent on the type of insn scheduled.  Currently\n+   set to 0 to save compile time.  */\n+#define DFA_HISTORY SMS_DFA_HISTORY\n+\n+static partial_schedule_ptr\n+sms_schedule_by_order (ddg_ptr g, int mii, int maxii, int *nodes_order, FILE *dump_file)\n+{\n+  int ii = mii;\n+  int i, c, success;\n+  int try_again_with_larger_ii = true;\n+  int num_nodes = g->num_nodes;\n+  ddg_edge_ptr e;\n+  int start, end, step; /* Place together into one struct?  */\n+  sbitmap sched_nodes = sbitmap_alloc (num_nodes);\n+  sbitmap psp = sbitmap_alloc (num_nodes);\n+  sbitmap pss = sbitmap_alloc (num_nodes);\n+  partial_schedule_ptr ps = create_partial_schedule (ii, g, DFA_HISTORY);\n+\n+  while (try_again_with_larger_ii && ii < maxii)\n+    {\n+      if (dump_file)\n+\tfprintf(dump_file, \"Starting with ii=%d\\n\", ii);\n+      try_again_with_larger_ii = false;\n+      sbitmap_zero (sched_nodes);\n+\n+      for (i = 0; i < num_nodes; i++)\n+\t{\n+\t  int u = nodes_order[i];\n+\t  ddg_node_ptr u_node = &g->nodes[u];\n+\t  sbitmap u_node_preds = NODE_PREDECESSORS (u_node);\n+\t  sbitmap u_node_succs = NODE_SUCCESSORS (u_node);\n+\t  int psp_not_empty;\n+\t  int pss_not_empty;\n+\t  rtx insn = u_node->insn;\n+\n+\t  if (!INSN_P (insn))\n+\t    continue;\n+\n+\t  if (GET_CODE (insn) == JUMP_INSN) /* Closing branch handled later.  */\n+\t    continue;\n+\n+\t  /* 1. compute sched window for u (start, end, step).  */\n+\t  sbitmap_zero (psp);\n+\t  sbitmap_zero (pss);\n+\t  psp_not_empty = sbitmap_a_and_b_cg (psp, u_node_preds, sched_nodes);\n+\t  pss_not_empty = sbitmap_a_and_b_cg (pss, u_node_succs, sched_nodes);\n+\n+\t  if (psp_not_empty && !pss_not_empty)\n+\t    {\n+\t      int early_start = 0;\n+\n+\t      end = INT_MAX;\n+\t      for (e = u_node->in; e != 0; e = e->next_in)\n+\t\t{\n+\t\t  ddg_node_ptr v_node = e->src;\n+\t\t  if (TEST_BIT (sched_nodes, v_node->cuid))\n+\t\t    {\n+\t\t      early_start = MAX (early_start,\n+\t\t\t\t\t SCHED_TIME (v_node)\n+\t\t\t\t\t + e->latency - (e->distance * ii));\n+\t\t      if (e->data_type == MEM_DEP)\n+\t\t\tend = MIN (end, SCHED_TIME (v_node) + ii - 1);\n+\t\t    }\n+\t\t}\n+\t      start = early_start;\n+\t      end = MIN (end, early_start + ii);\n+\t      step = 1;\n+\t    }\n+\n+\t  else if (!psp_not_empty && pss_not_empty)\n+\t    {\n+\t      int late_start = INT_MAX;\n+\n+\t      end = INT_MIN;\n+\t      for (e = u_node->out; e != 0; e = e->next_out)\n+\t\t{\n+\t\t  ddg_node_ptr v_node = e->dest;\n+\t\t  if (TEST_BIT (sched_nodes, v_node->cuid))\n+\t\t    {\n+\t\t      late_start = MIN (late_start,\n+\t\t\t\t\tSCHED_TIME (v_node) - e->latency\n+\t\t\t\t\t+ (e->distance * ii));\n+\t\t      if (e->data_type == MEM_DEP)\n+\t\t\tend = MAX (end, SCHED_TIME (v_node) - ii + 1);\n+\t\t    }\n+\t\t}\n+\t      start = late_start;\n+\t      end = MAX (end, late_start - ii);\n+\t      step = -1;\n+\t    }\n+\n+\t  else if (psp_not_empty && pss_not_empty)\n+\t    {\n+\t      int early_start = 0;\n+\t      int late_start = INT_MAX;\n+\n+\t      start = INT_MIN;\n+\t      end = INT_MAX;\n+\t      for (e = u_node->in; e != 0; e = e->next_in)\n+\t\t{\n+\t\t  ddg_node_ptr v_node = e->src;\n+\n+\t\t  if (TEST_BIT (sched_nodes, v_node->cuid))\n+\t\t    {\n+\t\t      early_start = MAX (early_start,\n+\t\t\t\t\t SCHED_TIME (v_node) + e->latency\n+\t\t\t\t\t - (e->distance * ii));\n+\t\t      if (e->data_type == MEM_DEP)\n+\t\t\tend = MIN (end, SCHED_TIME (v_node) + ii - 1);\n+\t\t    }\n+\t\t}\n+\t      for (e = u_node->out; e != 0; e = e->next_out)\n+\t\t{\n+\t\t  ddg_node_ptr v_node = e->dest;\n+\n+\t\t  if (TEST_BIT (sched_nodes, v_node->cuid))\n+\t\t    {\n+\t\t      late_start = MIN (late_start,\n+\t\t\t\t\tSCHED_TIME (v_node) - e->latency\n+\t\t\t\t\t+ (e->distance * ii));\n+\t\t      if (e->data_type == MEM_DEP)\n+\t\t\tstart = MAX (start, SCHED_TIME (v_node) - ii + 1);\n+\t\t    }\n+\t\t}\n+\t      start = MAX (start, early_start);\n+\t      end = MIN (end, MIN (early_start + ii, late_start + 1));\n+\t      step = 1;\n+\t    }\n+\t  else /* psp is empty && pss is empty.  */\n+\t    {\n+\t      start = SCHED_ASAP (u_node);\n+\t      end = start + ii;\n+\t      step = 1;\n+\t    }\n+\n+\t  /* 2. Try scheduling u in window.  */\n+\t  if (dump_file)\n+\t    fprintf(dump_file, \"Trying to schedule node %d in (%d .. %d) step %d\\n\",\n+\t\t    u, start, end, step);\n+\n+\t  success = 0;\n+\t  if ((step > 0 && start < end) ||  (step < 0 && start > end))\n+\t    for (c = start; c != end; c += step)\n+\t      {\n+\t\tps_insn_ptr psi = ps_add_node_check_conflicts (ps, u_node, c);\n+\n+  \t\tif (psi)\n+\t\t  {\n+\t\t    SCHED_TIME (u_node) = c;\n+\t\t    SET_BIT (sched_nodes, u);\n+\t\t    success = 1;\n+\t\t    if (dump_file)\n+\t\t      fprintf(dump_file, \"Schedule in %d\\n\", c);\n+\t\t    break;\n+\t\t  }\n+\t      }\n+\t  if (!success)\n+\t    {\n+\t      /* ??? Try backtracking instead of immediately ii++?  */\n+\t      ii++;\n+\t      try_again_with_larger_ii = true;\n+\t      reset_partial_schedule (ps, ii);\n+\t      break;\n+\t    }\n+\t  /* ??? If (success), check register pressure estimates.  */\n+\t} /* Continue with next node.  */\n+    } /* While try_again_with_larger_ii.  */\n+\n+  sbitmap_free (sched_nodes);\n+  sbitmap_free (psp);\n+  sbitmap_free (pss);\n+\n+  if (ii >= maxii)\n+    {\n+      free_partial_schedule (ps);\n+      ps = NULL;\n+    }\n+  return ps;\n+}\n+\n+\f\n+/* This page implements the algorithm for ordering the nodes of a DDG\n+   for modulo scheduling, activated through the\n+   \"int sms_order_nodes (ddg_ptr, int mii, int * result)\" API.  */\n+\n+#define ORDER_PARAMS(x) ((struct node_order_params *) (x)->aux.info)\n+#define ASAP(x) (ORDER_PARAMS ((x))->asap)\n+#define ALAP(x) (ORDER_PARAMS ((x))->alap)\n+#define HEIGHT(x) (ORDER_PARAMS ((x))->height)\n+#define MOB(x) (ALAP ((x)) - ASAP ((x)))\n+#define DEPTH(x) (ASAP ((x)))\n+\n+typedef struct node_order_params * nopa;\n+\n+static void order_nodes_of_sccs (ddg_all_sccs_ptr, int * result);\n+static int order_nodes_in_scc (ddg_ptr, sbitmap, sbitmap, int*, int);\n+static nopa  calculate_order_params (ddg_ptr, int mii);\n+static int find_max_asap (ddg_ptr, sbitmap);\n+static int find_max_hv_min_mob (ddg_ptr, sbitmap);\n+static int find_max_dv_min_mob (ddg_ptr, sbitmap);\n+\n+enum sms_direction {BOTTOMUP, TOPDOWN};\n+\n+struct node_order_params\n+{\n+  int asap;\n+  int alap;\n+  int height;\n+};\n+\n+/* Check if NODE_ORDER contains a permutation of 0 .. NUM_NODES-1.  */\n+static void\n+check_nodes_order (int *node_order, int num_nodes)\n+{\n+  int i;\n+  sbitmap tmp = sbitmap_alloc (num_nodes);\n+\n+  sbitmap_zero (tmp);\n+\n+  for (i = 0; i < num_nodes; i++)\n+    {\n+      int u = node_order[i];\n+\n+      if (u >= num_nodes || u < 0 || TEST_BIT (tmp, u))\n+\tabort ();\n+\n+      SET_BIT (tmp, u);\n+    }\n+\n+  sbitmap_free (tmp);\n+}\n+\n+/* Order the nodes of G for scheduling and pass the result in\n+   NODE_ORDER.  Also set aux.count of each node to ASAP.\n+   Return the recMII for the given DDG.  */\n+static int\n+sms_order_nodes (ddg_ptr g, int mii, int * node_order)\n+{\n+  int i;\n+  int rec_mii = 0;\n+  ddg_all_sccs_ptr sccs = create_ddg_all_sccs (g);\n+\n+  nopa nops = calculate_order_params (g, mii);\n+\n+  order_nodes_of_sccs (sccs, node_order);\n+\n+  if (sccs->num_sccs > 0)\n+    /* First SCC has the largest recurrence_length.  */\n+    rec_mii = sccs->sccs[0]->recurrence_length;\n+\n+  /* Save ASAP before destroying node_order_params.  */\n+  for (i = 0; i < g->num_nodes; i++)\n+    {\n+      ddg_node_ptr v = &g->nodes[i];\n+      v->aux.count = ASAP (v);\n+    }\n+\n+  free (nops);\n+  free_ddg_all_sccs (sccs);\n+  check_nodes_order (node_order, g->num_nodes);\n+\n+  return rec_mii;\n+}\n+\n+static void\n+order_nodes_of_sccs (ddg_all_sccs_ptr all_sccs, int * node_order)\n+{\n+  int i, pos = 0;\n+  ddg_ptr g = all_sccs->ddg;\n+  int num_nodes = g->num_nodes;\n+  sbitmap prev_sccs = sbitmap_alloc (num_nodes);\n+  sbitmap on_path = sbitmap_alloc (num_nodes);\n+  sbitmap tmp = sbitmap_alloc (num_nodes);\n+  sbitmap ones = sbitmap_alloc (num_nodes);\n+\n+  sbitmap_zero (prev_sccs);\n+  sbitmap_ones (ones);\n+\n+  /* Perfrom the node ordering starting from the SCC with the highest recMII.\n+     For each SCC order the nodes according to their ASAP/ALAP/HEIGHT etc.  */\n+  for (i = 0; i < all_sccs->num_sccs; i++)\n+    {\n+      ddg_scc_ptr scc = all_sccs->sccs[i];\n+\n+      /* Add nodes on paths from previous SCCs to the current SCC.  */\n+      find_nodes_on_paths (on_path, g, prev_sccs, scc->nodes);\n+      sbitmap_a_or_b (tmp, scc->nodes, on_path);\n+\n+      /* Add nodes on paths from the current SCC to previous SCCs.  */\n+      find_nodes_on_paths (on_path, g, scc->nodes, prev_sccs);\n+      sbitmap_a_or_b (tmp, tmp, on_path);\n+\n+      /* Remove nodes of previous SCCs from current extended SCC.  */\n+      sbitmap_difference (tmp, tmp, prev_sccs);\n+\n+      pos = order_nodes_in_scc (g, prev_sccs, tmp, node_order, pos);\n+      /* Above call to order_nodes_in_scc updated prev_sccs |= tmp.  */\n+    }\n+\n+  /* Handle the remaining nodes that do not belong to any scc.  Each call\n+     to order_nodes_in_scc handles a single connected component.  */\n+  while (pos < g->num_nodes)\n+    {\n+      sbitmap_difference (tmp, ones, prev_sccs);\n+      pos = order_nodes_in_scc (g, prev_sccs, tmp, node_order, pos);\n+    }\n+  sbitmap_free (prev_sccs);\n+  sbitmap_free (on_path);\n+  sbitmap_free (tmp);\n+  sbitmap_free (ones);\n+}\n+\n+/* MII is needed if we consider backarcs (that do not close recursive cycles).  */\n+static struct node_order_params *\n+calculate_order_params (ddg_ptr g, int mii ATTRIBUTE_UNUSED)\n+{\n+  int u;\n+  int max_asap;\n+  int num_nodes = g->num_nodes;\n+  ddg_edge_ptr e;\n+  /* Allocate a place to hold ordering params for each node in the DDG.  */\n+  nopa node_order_params_arr;\n+\n+  /* Initialize of ASAP/ALAP/HEIGHT to zero.  */\n+  node_order_params_arr = (nopa) xcalloc (num_nodes,\n+\t\t\t\t\t  sizeof (struct node_order_params));\n+\n+  /* Set the aux pointer of each node to point to its order_params strcture.  */\n+  for (u = 0; u < num_nodes; u++)\n+    g->nodes[u].aux.info = &node_order_params_arr[u];\n+\n+  /* Disregarding a backarc from each recursive cycle to obtain a DAG,\n+     calculate ASAP, ALAP, mobility, distance, and height for each node\n+     in the dependence (direct acyclic) graph.  */\n+\n+  /* We assume that the nodes in the array are in topological order.  */\n+\n+  max_asap = 0;\n+  for (u = 0; u < num_nodes; u++)\n+    {\n+      ddg_node_ptr u_node = &g->nodes[u];\n+\n+      ASAP (u_node) = 0;\n+      for (e = u_node->in; e; e = e->next_in)\n+\tif (e->distance == 0)\n+\t  ASAP (u_node) = MAX (ASAP (u_node),\n+\t\t\t       ASAP (e->src) + e->latency);\n+      max_asap = MAX (max_asap, ASAP (u_node));\n+    }\n+\n+  for (u = num_nodes - 1; u > -1; u--)\n+    {\n+      ddg_node_ptr u_node = &g->nodes[u];\n+\n+      ALAP (u_node) = max_asap;\n+      HEIGHT (u_node) = 0;\n+      for (e = u_node->out; e; e = e->next_out)\n+\tif (e->distance == 0)\n+\t  {\n+\t    ALAP (u_node) = MIN (ALAP (u_node),\n+\t\t\t\t ALAP (e->dest) - e->latency);\n+\t    HEIGHT (u_node) = MAX (HEIGHT (u_node),\n+\t\t\t\t   HEIGHT (e->dest) + e->latency);\n+\t  }\n+    }\n+\n+  return node_order_params_arr;\n+}\n+\n+static int\n+find_max_asap (ddg_ptr g, sbitmap nodes)\n+{\n+  int u;\n+  int max_asap = -1;\n+  int result = -1;\n+\n+  EXECUTE_IF_SET_IN_SBITMAP (nodes, 0, u,\n+    {\n+      ddg_node_ptr u_node = &g->nodes[u];\n+\n+      if (max_asap < ASAP (u_node))\n+\t{\n+\t  max_asap = ASAP (u_node);\n+\t  result = u;\n+\t}\n+    });\n+  return result;\n+}\n+\n+static int\n+find_max_hv_min_mob (ddg_ptr g, sbitmap nodes)\n+{\n+  int u;\n+  int max_hv = -1;\n+  int min_mob = INT_MAX;\n+  int result = -1;\n+\n+  EXECUTE_IF_SET_IN_SBITMAP (nodes, 0, u,\n+    {\n+      ddg_node_ptr u_node = &g->nodes[u];\n+\n+      if (max_hv < HEIGHT (u_node))\n+\t{\n+\t  max_hv = HEIGHT (u_node);\n+\t  min_mob = MOB (u_node);\n+\t  result = u;\n+\t}\n+      else if ((max_hv == HEIGHT (u_node))\n+\t       && (min_mob > MOB (u_node)))\n+\t{\n+\t  min_mob = MOB (u_node);\n+\t  result = u;\n+\t}\n+    });\n+  return result;\n+}\n+\n+static int\n+find_max_dv_min_mob (ddg_ptr g, sbitmap nodes)\n+{\n+  int u;\n+  int max_dv = -1;\n+  int min_mob = INT_MAX;\n+  int result = -1;\n+\n+  EXECUTE_IF_SET_IN_SBITMAP (nodes, 0, u,\n+    {\n+      ddg_node_ptr u_node = &g->nodes[u];\n+\n+      if (max_dv < DEPTH (u_node))\n+\t{\n+\t  max_dv = DEPTH (u_node);\n+\t  min_mob = MOB (u_node);\n+\t  result = u;\n+\t}\n+      else if ((max_dv == DEPTH (u_node))\n+\t       && (min_mob > MOB (u_node)))\n+\t{\n+\t  min_mob = MOB (u_node);\n+\t  result = u;\n+\t}\n+    });\n+  return result;\n+}\n+\n+/* Places the nodes of SCC into the NODE_ORDER array starting\n+   at position POS, according to the SMS ordering algorithm.\n+   NODES_ORDERED (in&out parameter) holds the bitset of all nodes in\n+   the NODE_ORDER array, starting from position zero.  */\n+static int\n+order_nodes_in_scc (ddg_ptr g, sbitmap nodes_ordered, sbitmap scc,\n+\t\t    int * node_order, int pos)\n+{\n+  enum sms_direction dir;\n+  int num_nodes = g->num_nodes;\n+  sbitmap workset = sbitmap_alloc (num_nodes);\n+  sbitmap tmp = sbitmap_alloc (num_nodes);\n+  sbitmap zero_bitmap = sbitmap_alloc (num_nodes);\n+  sbitmap predecessors = sbitmap_alloc (num_nodes);\n+  sbitmap successors = sbitmap_alloc (num_nodes);\n+\n+  sbitmap_zero (predecessors);\n+  find_predecessors (predecessors, g, nodes_ordered);\n+\n+  sbitmap_zero (successors);\n+  find_successors (successors, g, nodes_ordered);\n+\n+  sbitmap_zero (tmp);\n+  if (sbitmap_a_and_b_cg (tmp, predecessors, scc))\n+    {\n+      sbitmap_copy (workset, tmp);\n+      dir = BOTTOMUP;\n+    }\n+  else if (sbitmap_a_and_b_cg (tmp, successors, scc))\n+    {\n+      sbitmap_copy (workset, tmp);\n+      dir = TOPDOWN;\n+    }\n+  else\n+    {\n+      int u;\n+\n+      sbitmap_zero (workset);\n+      if ((u = find_max_asap (g, scc)) >= 0)\n+\tSET_BIT (workset, u);\n+      dir = BOTTOMUP;\n+    }\n+\n+  sbitmap_zero (zero_bitmap);\n+  while (!sbitmap_equal (workset, zero_bitmap))\n+    {\n+      int v;\n+      ddg_node_ptr v_node;\n+      sbitmap v_node_preds;\n+      sbitmap v_node_succs;\n+\n+      if (dir == TOPDOWN)\n+\t{\n+\t  while (!sbitmap_equal (workset, zero_bitmap))\n+\t    {\n+\t      v = find_max_hv_min_mob (g, workset);\n+\t      v_node = &g->nodes[v];\n+\t      node_order[pos++] = v;\n+\t      v_node_succs = NODE_SUCCESSORS (v_node);\n+\t      sbitmap_a_and_b (tmp, v_node_succs, scc);\n+\n+\t      /* Don't consider the already ordered successors again.  */\n+\t      sbitmap_difference (tmp, tmp, nodes_ordered);\n+\t      sbitmap_a_or_b (workset, workset, tmp);\n+\t      RESET_BIT (workset, v);\n+\t      SET_BIT (nodes_ordered, v);\n+\t    }\n+\t  dir = BOTTOMUP;\n+\t  sbitmap_zero (predecessors);\n+\t  find_predecessors (predecessors, g, nodes_ordered);\n+\t  sbitmap_a_and_b (workset, predecessors, scc);\n+\t}\n+      else\n+\t{\n+\t  while (!sbitmap_equal (workset, zero_bitmap))\n+\t    {\n+\t      v = find_max_dv_min_mob (g, workset);\n+\t      v_node = &g->nodes[v];\n+\t      node_order[pos++] = v;\n+\t      v_node_preds = NODE_PREDECESSORS (v_node);\n+\t      sbitmap_a_and_b (tmp, v_node_preds, scc);\n+\n+\t      /* Don't consider the already ordered predecessors again.  */\n+\t      sbitmap_difference (tmp, tmp, nodes_ordered);\n+\t      sbitmap_a_or_b (workset, workset, tmp);\n+\t      RESET_BIT (workset, v);\n+\t      SET_BIT (nodes_ordered, v);\n+\t    }\n+\t  dir = TOPDOWN;\n+\t  sbitmap_zero (successors);\n+\t  find_successors (successors, g, nodes_ordered);\n+\t  sbitmap_a_and_b (workset, successors, scc);\n+\t}\n+    }\n+  sbitmap_free (tmp);\n+  sbitmap_free (workset);\n+  sbitmap_free (zero_bitmap);\n+  sbitmap_free (predecessors);\n+  sbitmap_free (successors);\n+  return pos;\n+}\n+\n+\f\n+/* This page contains functions for manipulating partial-schedules during\n+   modulo scheduling.  */\n+\n+/* Create a partial schedule and allocate a memory to hold II rows.  */\n+partial_schedule_ptr\n+create_partial_schedule (int ii, ddg_ptr g, int history)\n+{\n+  partial_schedule_ptr ps = (partial_schedule_ptr)\n+\t\t\t     xmalloc (sizeof (struct partial_schedule));\n+  ps->rows = (ps_insn_ptr *) xcalloc (ii, sizeof (ps_insn_ptr));\n+  ps->ii = ii;\n+  ps->history = history;\n+  ps->min_cycle = INT_MAX;\n+  ps->max_cycle = INT_MIN;\n+  ps->g = g;\n+\n+  return ps;\n+}\n+\n+/* Free the PS_INSNs in rows array of the given partial schedule.\n+   ??? Consider caching the PS_INSN's.  */\n+static void\n+free_ps_insns (partial_schedule_ptr ps)\n+{\n+  int i;\n+\n+  for (i = 0; i < ps->ii; i++)\n+    {\n+      while (ps->rows[i])\n+\t{\n+\t  ps_insn_ptr ps_insn = ps->rows[i]->next_in_row;\n+\n+\t  free (ps->rows[i]);\n+\t  ps->rows[i] = ps_insn;\n+\t}\n+      ps->rows[i] = NULL;\n+    }\n+}\n+\n+/* Free all the memory allocated to the partial schedule.  */\n+void\n+free_partial_schedule (partial_schedule_ptr ps)\n+{\n+  if (!ps)\n+    return;\n+  free_ps_insns (ps);\n+  free (ps->rows);\n+  free (ps);\n+}\n+\n+/* Clear the rows array with its PS_INSNs, and create a new one with\n+   NEW_II rows.  */\n+void\n+reset_partial_schedule (partial_schedule_ptr ps, int new_ii)\n+{\n+  if (!ps)\n+    return;\n+  free_ps_insns (ps);\n+  if (new_ii == ps->ii)\n+    return;\n+  ps->rows = (ps_insn_ptr *) xrealloc (ps->rows, new_ii\n+\t\t\t\t\t\t * sizeof (ps_insn_ptr));\n+  memset (ps->rows, 0, new_ii * sizeof (ps_insn_ptr));\n+  ps->ii = new_ii;\n+  ps->min_cycle = INT_MAX;\n+  ps->max_cycle = INT_MIN;\n+}\n+\n+/* Prints the partial schedule as an ii rows array, for each rows\n+   print the ids of the insns in it.  */\n+void\n+print_partial_schedule (partial_schedule_ptr ps, FILE *dump)\n+{\n+  int i;\n+\n+  for (i = 0; i < ps->ii; i++)\n+    {\n+      ps_insn_ptr ps_i = ps->rows[i];\n+\n+      fprintf (dump, \"\\n[CYCLE %d ]: \", i);\n+      while (ps_i)\n+\t{\n+\t  fprintf (dump, \"%d, \",\n+\t\t   INSN_UID (ps_i->node->insn));\n+\t  ps_i = ps_i->next_in_row;\n+\t}\n+    }\n+}\n+\n+/* Creates an object of PS_INSN and initializes it to the given parameters.  */\n+static ps_insn_ptr\n+create_ps_insn (ddg_node_ptr node, int rest_count, int cycle)\n+{\n+  ps_insn_ptr ps_i = xmalloc (sizeof (struct ps_insn));\n+\n+  ps_i->node = node;\n+  ps_i->next_in_row = NULL;\n+  ps_i->prev_in_row = NULL;\n+  ps_i->row_rest_count = rest_count;\n+  ps_i->cycle = cycle;\n+\n+  return ps_i;\n+}\n+\n+\n+/* Removes the given PS_INSN from the partial schedule.  Returns false if the\n+   node is not found in the partial schedule, else returns true.  */\n+static int\n+remove_node_from_ps (partial_schedule_ptr ps, ps_insn_ptr ps_i)\n+{\n+  int row;\n+\n+  if (!ps || !ps_i)\n+    return false;\n+\n+  row = SMODULO (ps_i->cycle, ps->ii);\n+  if (! ps_i->prev_in_row)\n+    {\n+      if (ps_i != ps->rows[row])\n+\treturn false;\n+\n+      ps->rows[row] = ps_i->next_in_row;\n+      if (ps->rows[row])\n+\tps->rows[row]->prev_in_row = NULL;\n+    }\n+  else\n+    {\n+      ps_i->prev_in_row->next_in_row = ps_i->next_in_row;\n+      if (ps_i->next_in_row)\n+\tps_i->next_in_row->prev_in_row = ps_i->prev_in_row;\n+    }\n+  free (ps_i);\n+  return true;\n+}\n+\n+/* Advances the PS_INSN one column in its current row; returns false\n+   in failure and true in success.  */\n+static int\n+ps_insn_advance_column (partial_schedule_ptr ps, ps_insn_ptr ps_i)\n+{\n+  ps_insn_ptr prev, next;\n+  int row;\n+\n+  if (!ps || !ps_i)\n+    return false;\n+\n+  row = SMODULO (ps_i->cycle, ps->ii);\n+\n+  if (! ps_i->next_in_row)\n+    return false;\n+\n+  /* Check if next_in_row is dependent on ps_i, both having same sched\n+     times (typically ANTI_DEP).  If so, ps_i cannot skip over it.  */\n+  if (ps_i->cycle == ps_i->next_in_row->cycle)\n+    {\n+      ddg_edge_ptr e;\n+      ddg_node_ptr next_node = ps_i->next_in_row->node;\n+\n+      for (e = ps_i->node->out; e; e = e->next_out)\n+\tif (e->dest == next_node)\n+\t  return false;\n+    }\n+\n+  /* Advace PS_I over its next_in_row in the doubly linked list.  */\n+  prev = ps_i->prev_in_row;\n+  next = ps_i->next_in_row;\n+\n+  if (ps_i == ps->rows[row])\n+    ps->rows[row] = next;\n+\n+  ps_i->next_in_row = next->next_in_row;\n+\n+  if (next->next_in_row)\n+    next->next_in_row->prev_in_row = ps_i;\n+\n+  next->next_in_row = ps_i;\n+  ps_i->prev_in_row = next;\n+\n+  next->prev_in_row = prev;\n+  if (prev)\n+    prev->next_in_row = next;\n+\n+  return true;\n+}\n+\n+/* Inserts a DDG_NODE to the given partial schedule at the given cycle.\n+   Returns 0 if this is not possible and a PS_INSN otherwise.  */\n+static ps_insn_ptr\n+add_node_to_ps (partial_schedule_ptr ps, ddg_node_ptr node, int cycle)\n+{\n+  ps_insn_ptr ps_i, next_ps_i, advance_after;\n+  int rest_count = 1;\n+  int row = SMODULO (cycle, ps->ii);\n+  ddg_edge_ptr e;\n+\n+  if (ps->rows[row]\n+      && ps->rows[row]->row_rest_count >= issue_rate)\n+    return NULL;\n+\n+  if (ps->rows[row])\n+    rest_count += ps->rows[row]->row_rest_count;\n+\n+  ps_i = create_ps_insn (node, rest_count, cycle);\n+  ps_i->next_in_row = ps->rows[row];\n+  ps_i->prev_in_row = NULL;\n+  if (ps_i->next_in_row)\n+    ps_i->next_in_row->prev_in_row = ps_i;\n+  ps->rows[row] = ps_i;\n+\n+  /* Check if n is dependent on an insn already in row, having same cycle\n+     (typically ANTI_DEP).  If so, n must skip over it.  */\n+  advance_after = NULL;\n+  for (next_ps_i = ps_i->next_in_row;\n+       next_ps_i;\n+       next_ps_i = next_ps_i->next_in_row)\n+    if (next_ps_i->cycle == cycle)\n+      for (e = node->in; e; e = e->next_in)\n+\tif (e->src == next_ps_i->node)\n+\t  advance_after = next_ps_i;\n+\n+  if (advance_after)\n+    while (ps_i->prev_in_row != advance_after)\n+      if (!ps_insn_advance_column (ps, ps_i))\n+\t{\n+\t  remove_node_from_ps (ps, ps_i);\n+\t  return NULL;\n+\t}\n+\n+  return ps_i;\n+}\n+\n+/* Advance time one cycle.  Assumes DFA is being used.  */\n+static void\n+advance_one_cycle (void)\n+{\n+  if (targetm.sched.use_dfa_pipeline_interface\n+      && (*targetm.sched.use_dfa_pipeline_interface) ())\n+    {\n+      if (targetm.sched.dfa_pre_cycle_insn)\n+\tstate_transition (curr_state,\n+\t\t\t  (*targetm.sched.dfa_pre_cycle_insn) ());\n+\n+      state_transition (curr_state, NULL);\n+\n+      if (targetm.sched.dfa_post_cycle_insn)\n+\tstate_transition (curr_state,\n+\t\t\t  (*targetm.sched.dfa_post_cycle_insn) ());\n+    }\n+}\n+\n+/* Checks if PS has resource conflicts according to DFA, starting from\n+   FROM cycle to TO cycle; returns true if there are conflicts and false\n+   if there are no conflicts.  Assumes DFA is being used.  */\n+static int\n+ps_has_conflicts (partial_schedule_ptr ps, int from, int to)\n+{\n+  int cycle;\n+\n+  if (! targetm.sched.use_dfa_pipeline_interface\n+      || ! (*targetm.sched.use_dfa_pipeline_interface) ())\n+    return true;\n+\n+  state_reset (curr_state);\n+\n+  for (cycle = from; cycle <= to; cycle++)\n+    {\n+      ps_insn_ptr crr_insn;\n+      /* Holds the remaining issue slots in the current row.  */\n+      int can_issue_more = issue_rate;\n+\n+      /* Walk through the DFA for the current row.  */\n+      for (crr_insn = ps->rows[SMODULO (cycle, ps->ii)];\n+\t   crr_insn;\n+\t   crr_insn = crr_insn->next_in_row)\n+\t{\n+\t  rtx insn = crr_insn->node->insn;\n+\n+\t  if (!INSN_P (insn))\n+\t    continue;\n+\n+\t  /* Check if there is room for the current insn.  */\n+\t  if (!can_issue_more || state_dead_lock_p (curr_state))\n+\t    return true;\n+\n+\t  /* Update the DFA state and return with failure if the DFA found\n+\t     recource conflicts.  */\n+\t  if (state_transition (curr_state, insn) >= 0)\n+\t    return true;\n+\n+\t  if (targetm.sched.variable_issue)\n+\t    can_issue_more =\n+\t      (*targetm.sched.variable_issue) (sched_dump, sched_verbose,\n+\t\t\t\t\t       insn, can_issue_more);\n+\t  /* A naked CLOBBER or USE generates no instruction, so don't\n+\t     let them consume issue slots.  */\n+\t  else if (GET_CODE (PATTERN (insn)) != USE\n+\t\t   && GET_CODE (PATTERN (insn)) != CLOBBER)\n+\t    can_issue_more--;\n+\t}\n+\n+      /* Advance the DFA to the next cycle.  */\n+      advance_one_cycle ();\n+    }\n+  return false;\n+}\n+\n+/* Checks if the given node causes resource conflicts when added to PS at\n+   cycle C.  If not the node is added to PS and returned; otherwise zero\n+   is returned.  */\n+ps_insn_ptr\n+ps_add_node_check_conflicts (partial_schedule_ptr ps, ddg_node_ptr n, int c)\n+{\n+  int has_conflicts = 0;\n+  ps_insn_ptr ps_i;\n+\n+  /* First add the node to the PS, if this succeeds check for conflicts,\n+     trying different issue slots in the same row.  */\n+  if (! (ps_i = add_node_to_ps (ps, n, c)))\n+    return NULL; /* Failed to insert the node at the given cycle.  */\n+\n+  has_conflicts = ps_has_conflicts (ps, c, c)\n+\t\t  || (ps->history > 0\n+\t\t      && ps_has_conflicts (ps,\n+\t\t\t\t\t   c - ps->history,\n+\t\t\t\t\t   c + ps->history));\n+\n+  /* Try different issue slots to find one that the given node can be\n+     scheduled in without conflicts.  */\n+  while (has_conflicts)\n+    {\n+      if (! ps_insn_advance_column (ps, ps_i))\n+\tbreak;\n+      has_conflicts = ps_has_conflicts (ps, c, c)\n+\t\t      || (ps->history > 0\n+\t\t\t  && ps_has_conflicts (ps,\n+\t\t\t\t\t       c - ps->history,\n+\t\t\t\t\t       c + ps->history));\n+    }\n+\n+  if (has_conflicts)\n+    {\n+      remove_node_from_ps (ps, ps_i);\n+      return NULL;\n+    }\n+\n+  ps->min_cycle = MIN (ps->min_cycle, c);\n+  ps->max_cycle = MAX (ps->max_cycle, c);\n+  return ps_i;\n+}\n+\n+/* Rotate the rows of PS such that insns scheduled at time\n+   START_CYCLE will appear in row 0.  Updates max/min_cycles.  */\n+void\n+rotate_partial_schedule (partial_schedule_ptr ps, int start_cycle)\n+{\n+  int i, row, backward_rotates;\n+  int last_row = ps->ii - 1;\n+\n+  if (start_cycle == 0)\n+    return;\n+\n+  backward_rotates = SMODULO (start_cycle, ps->ii);\n+\n+  /* Revisit later and optimize this into a single loop.  */\n+  for (i = 0; i < backward_rotates; i++)\n+    {\n+      ps_insn_ptr first_row = ps->rows[0];\n+\n+      for (row = 0; row < last_row; row++)\n+\tps->rows[row] = ps->rows[row+1];\n+\n+      ps->rows[last_row] = first_row;\n+    }\n+\n+  ps->max_cycle -= start_cycle;\n+  ps->min_cycle -= start_cycle;\n+}"}]}