{"sha": "0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGNlZGIzNmNiZDdlMGM0MDdhMzNlY2JjZmZmZDA4NDU4MDU5YmYwMA==", "commit": {"author": {"name": "Jeffrey A Law", "email": "law@cygnus.com", "date": "1999-11-01T00:18:23Z"}, "committer": {"name": "Jeff Law", "email": "law@gcc.gnu.org", "date": "1999-11-01T00:18:23Z"}, "message": "simplify-rtx.c: New file.\n\n        * simplify-rtx.c: New file.\n        * Makefile.in (OBJS): Add simplify-rtx.o\n        (simplify-rtx.o): Add dependencies.\n        * rtl.h (simplify_gen_binary, simplify_rtx): Add prototypes.\n        * cse.c: Use simplify_gen_binary intead of cse_gen_binary.\n        (cse_gen_binary, simplify_unary_operation): Delete.\n        (simplify_binary_operation, simplify_plus_minus): Likewise.\n        (check_fold_consts, simplify_relation_operation): Likewise.\n        (simplify_ternary_operation): Likewise.\n        (delete_trivially_dead_insns): Simplify the contents of the\n        REG_EQUAL note before trying to substitute it into the source\n        of the reg-reg copy at the end of a libcall sequence.\n\nFrom-SVN: r30295", "tree": {"sha": "30a0da0025261198277a799d7e091866f77def9e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/30a0da0025261198277a799d7e091866f77def9e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/comments", "author": null, "committer": null, "parents": [{"sha": "8fbe10354e67f3e1e6de42a770c3247c6f3b9330", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8fbe10354e67f3e1e6de42a770c3247c6f3b9330", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8fbe10354e67f3e1e6de42a770c3247c6f3b9330"}], "stats": {"total": 4128, "additions": 2172, "deletions": 1956}, "files": [{"sha": "1df4e23fd9dd22c0f796d9b997ea7305524698c8", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "patch": "@@ -7,6 +7,19 @@ Sun Oct 31 13:32:15 CET 1999  Marc Lehmann <pcg@goof.com>\n \n Sun Oct 31 01:53:30 1999  Jeffrey A Law  (law@cygnus.com)\n \n+\t* simplify-rtx.c: New file.\n+\t* Makefile.in (OBJS): Add simplify-rtx.o\n+\t(simplify-rtx.o): Add dependencies.\n+\t* rtl.h (simplify_gen_binary, simplify_rtx): Add prototypes.\n+\t* cse.c: Use simplify_gen_binary intead of cse_gen_binary.\n+\t(cse_gen_binary, simplify_unary_operation): Delete.\n+\t(simplify_binary_operation, simplify_plus_minus): Likewise.\n+\t(check_fold_consts, simplify_relation_operation): Likewise.\n+\t(simplify_ternary_operation): Likewise.\n+\t(delete_trivially_dead_insns): Simplify the contents of the\n+\tREG_EQUAL note before trying to substitute it into the source\n+\tof the reg-reg copy at the end of a libcall sequence.\n+\n \t* combine.c (combine_simplify_rtx): Renamed from simplify_rtx.  All\n \treferences/callers changed.\n "}, {"sha": "3773f9b53a044ea56a7dd8e4e033b6eb3028bf55", "filename": "gcc/Makefile.in", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "patch": "@@ -667,7 +667,7 @@ OBJS = toplev.o version.o tree.o print-tree.o stor-layout.o fold-const.o \\\n  insn-opinit.o insn-recog.o insn-extract.o insn-output.o insn-emit.o lcm.o \\\n  profile.o insn-attrtab.o $(out_object_file) $(EXTRA_OBJS) convert.o \\\n  mbchar.o dyn-string.o splay-tree.o graph.o sbitmap.o resource.o hash.o \\\n- lists.o ggc-common.o $(GGC)\n+ lists.o ggc-common.o $(GGC) simplify-rtx.o\n \n # GEN files are listed separately, so they can be built before doing parallel\n #  makes for cc1 or cc1plus.  Otherwise sequent parallel make attempts to load\n@@ -1532,6 +1532,9 @@ jump.o : jump.c $(CONFIG_H) system.h $(RTL_H) flags.h hard-reg-set.h $(REGS_H) \\\n stupid.o : stupid.c $(CONFIG_H) system.h $(RTL_H) $(REGS_H) hard-reg-set.h \\\n    $(BASIC_BLOCK_H) insn-config.h reload.h flags.h function.h toplev.h\n \n+simplify-rtx.o : simplify-rtx.c $(CONFIG_H) system.h $(RTL_H) $(REGS_H) \\\n+   hard-reg-set.h flags.h real.h insn-config.h $(RECOG_H) $(EXPR_H) toplev.h \\\n+   output.h function.h \n cse.o : cse.c $(CONFIG_H) system.h $(RTL_H) $(REGS_H) hard-reg-set.h flags.h \\\n    real.h insn-config.h $(RECOG_H) $(EXPR_H) toplev.h output.h function.h \\\n    $(srcdir)/../include/hashtab.h ggc.h"}, {"sha": "1478556aa3822c5751688a046ca4e4c22813b343", "filename": "gcc/cse.c", "status": "modified", "additions": 199, "deletions": 1955, "changes": 2154, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "patch": "@@ -600,7 +600,12 @@ struct cse_basic_block_data {\n \n /* Nonzero if X has the form (PLUS frame-pointer integer).  We check for\n    virtual regs here because the simplify_*_operation routines are called\n-   by integrate.c, which is called before virtual register instantiation.  */\n+   by integrate.c, which is called before virtual register instantiation. \n+\n+   ?!? FIXED_BASE_PLUS_P and NONZERO_BASE_PLUS_P need to move into\n+   a header file so that their definitions can be shared with the\n+   simplification routines in simplify-rtx.c.  Until then, do not\n+   change these macros without also changing the copy in simplify-rtx.c.  */\n \n #define FIXED_BASE_PLUS_P(X)\t\t\t\t\t\\\n   ((X) == frame_pointer_rtx || (X) == hard_frame_pointer_rtx\t\\\n@@ -679,8 +684,6 @@ static void find_best_addr\tPROTO((rtx, rtx *));\n static enum rtx_code find_comparison_args PROTO((enum rtx_code, rtx *, rtx *,\n \t\t\t\t\t\t enum machine_mode *,\n \t\t\t\t\t\t enum machine_mode *));\n-static rtx cse_gen_binary\tPROTO((enum rtx_code, enum machine_mode,\n-\t\t\t\t       rtx, rtx));\n static rtx simplify_plus_minus\tPROTO((enum rtx_code, enum machine_mode,\n \t\t\t\t       rtx, rtx));\n static rtx fold_rtx\t\tPROTO((rtx, rtx));\n@@ -3020,1991 +3023,207 @@ find_best_addr (insn, loc)\n \t  /* This is at worst case an O(n^2) algorithm, so limit our search\n \t     to the first 32 elements on the list.  This avoids trouble\n \t     compiling code with very long basic blocks that can easily\n-\t     call cse_gen_binary so many times that we run out of memory.  */\n-\n-\t  found_better = 0;\n-\t  for (p = elt->first_same_value, count = 0;\n-\t       p && count < 32;\n-\t       p = p->next_same_value, count++)\n-\t    if (! p->flag\n-\t\t&& (GET_CODE (p->exp) == REG\n-\t\t    || exp_equiv_p (p->exp, p->exp, 1, 0)))\n-\t      {\n-\t\trtx new = cse_gen_binary (GET_CODE (*loc), Pmode, p->exp, c);\n-\n-\t\tif ((CSE_ADDRESS_COST (new) < best_addr_cost\n-\t\t    || (CSE_ADDRESS_COST (new) == best_addr_cost\n-\t\t\t&& (COST (new) + 1) >> 1 > best_rtx_cost)))\n-\t\t  {\n-\t\t    found_better = 1;\n-\t\t    best_addr_cost = CSE_ADDRESS_COST (new);\n-\t\t    best_rtx_cost = (COST (new) + 1) >> 1;\n-\t\t    best_elt = p;\n-\t\t    best_rtx = new;\n-\t\t  }\n-\t      }\n-\n-\t  if (found_better)\n-\t    {\n-\t      if (validate_change (insn, loc,\n-\t\t\t\t   canon_reg (copy_rtx (best_rtx),\n-\t\t\t\t\t      NULL_RTX), 0))\n-\t\treturn;\n-\t      else\n-\t\tbest_elt->flag = 1;\n-\t    }\n-\t}\n-    }\n-#endif\n-}\n-\f\n-/* Given an operation (CODE, *PARG1, *PARG2), where code is a comparison\n-   operation (EQ, NE, GT, etc.), follow it back through the hash table and\n-   what values are being compared.\n-\n-   *PARG1 and *PARG2 are updated to contain the rtx representing the values\n-   actually being compared.  For example, if *PARG1 was (cc0) and *PARG2\n-   was (const_int 0), *PARG1 and *PARG2 will be set to the objects that were\n-   compared to produce cc0.\n-\n-   The return value is the comparison operator and is either the code of\n-   A or the code corresponding to the inverse of the comparison.  */\n-\n-static enum rtx_code\n-find_comparison_args (code, parg1, parg2, pmode1, pmode2)\n-     enum rtx_code code;\n-     rtx *parg1, *parg2;\n-     enum machine_mode *pmode1, *pmode2;\n-{\n-  rtx arg1, arg2;\n-\n-  arg1 = *parg1, arg2 = *parg2;\n-\n-  /* If ARG2 is const0_rtx, see what ARG1 is equivalent to.  */\n-\n-  while (arg2 == CONST0_RTX (GET_MODE (arg1)))\n-    {\n-      /* Set non-zero when we find something of interest.  */\n-      rtx x = 0;\n-      int reverse_code = 0;\n-      struct table_elt *p = 0;\n-\n-      /* If arg1 is a COMPARE, extract the comparison arguments from it.\n-\t On machines with CC0, this is the only case that can occur, since\n-\t fold_rtx will return the COMPARE or item being compared with zero\n-\t when given CC0.  */\n-\n-      if (GET_CODE (arg1) == COMPARE && arg2 == const0_rtx)\n-\tx = arg1;\n-\n-      /* If ARG1 is a comparison operator and CODE is testing for\n-\t STORE_FLAG_VALUE, get the inner arguments.  */\n-\n-      else if (GET_RTX_CLASS (GET_CODE (arg1)) == '<')\n-\t{\n-\t  if (code == NE\n-\t      || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_INT\n-\t\t  && code == LT && STORE_FLAG_VALUE == -1)\n-#ifdef FLOAT_STORE_FLAG_VALUE\n-\t      || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_FLOAT\n-\t\t  && FLOAT_STORE_FLAG_VALUE < 0)\n-#endif\n-\t      )\n-\t    x = arg1;\n-\t  else if (code == EQ\n-\t\t   || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_INT\n-\t\t       && code == GE && STORE_FLAG_VALUE == -1)\n-#ifdef FLOAT_STORE_FLAG_VALUE\n-\t\t   || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_FLOAT\n-\t\t       && FLOAT_STORE_FLAG_VALUE < 0)\n-#endif\n-\t\t   )\n-\t    x = arg1, reverse_code = 1;\n-\t}\n-\n-      /* ??? We could also check for\n-\n-\t (ne (and (eq (...) (const_int 1))) (const_int 0))\n-\n-\t and related forms, but let's wait until we see them occurring.  */\n-\n-      if (x == 0)\n-\t/* Look up ARG1 in the hash table and see if it has an equivalence\n-\t   that lets us see what is being compared.  */\n-\tp = lookup (arg1, safe_hash (arg1, GET_MODE (arg1)) % NBUCKETS,\n-\t\t    GET_MODE (arg1));\n-      if (p) p = p->first_same_value;\n-\n-      for (; p; p = p->next_same_value)\n-\t{\n-\t  enum machine_mode inner_mode = GET_MODE (p->exp);\n-\n-\t  /* If the entry isn't valid, skip it.  */\n-\t  if (! exp_equiv_p (p->exp, p->exp, 1, 0))\n-\t    continue;\n-\n-\t  if (GET_CODE (p->exp) == COMPARE\n-\t      /* Another possibility is that this machine has a compare insn\n-\t\t that includes the comparison code.  In that case, ARG1 would\n-\t\t be equivalent to a comparison operation that would set ARG1 to\n-\t\t either STORE_FLAG_VALUE or zero.  If this is an NE operation,\n-\t\t ORIG_CODE is the actual comparison being done; if it is an EQ,\n-\t\t we must reverse ORIG_CODE.  On machine with a negative value\n-\t\t for STORE_FLAG_VALUE, also look at LT and GE operations.  */\n-\t      || ((code == NE\n-\t\t   || (code == LT\n-\t\t       && GET_MODE_CLASS (inner_mode) == MODE_INT\n-\t\t       && (GET_MODE_BITSIZE (inner_mode)\n-\t\t\t   <= HOST_BITS_PER_WIDE_INT)\n-\t\t       && (STORE_FLAG_VALUE\n-\t\t\t   & ((HOST_WIDE_INT) 1\n-\t\t\t      << (GET_MODE_BITSIZE (inner_mode) - 1))))\n-#ifdef FLOAT_STORE_FLAG_VALUE\n-\t\t   || (code == LT\n-\t\t       && GET_MODE_CLASS (inner_mode) == MODE_FLOAT\n-\t\t       && FLOAT_STORE_FLAG_VALUE < 0)\n-#endif\n-\t\t   )\n-\t\t  && GET_RTX_CLASS (GET_CODE (p->exp)) == '<'))\n-\t    {\n-\t      x = p->exp;\n-\t      break;\n-\t    }\n-\t  else if ((code == EQ\n-\t\t    || (code == GE\n-\t\t\t&& GET_MODE_CLASS (inner_mode) == MODE_INT\n-\t\t\t&& (GET_MODE_BITSIZE (inner_mode)\n-\t\t\t    <= HOST_BITS_PER_WIDE_INT)\n-\t\t\t&& (STORE_FLAG_VALUE\n-\t\t\t    & ((HOST_WIDE_INT) 1\n-\t\t\t       << (GET_MODE_BITSIZE (inner_mode) - 1))))\n-#ifdef FLOAT_STORE_FLAG_VALUE\n-\t\t    || (code == GE\n-\t\t\t&& GET_MODE_CLASS (inner_mode) == MODE_FLOAT\n-\t\t\t&& FLOAT_STORE_FLAG_VALUE < 0)\n-#endif\n-\t\t    )\n-\t\t   && GET_RTX_CLASS (GET_CODE (p->exp)) == '<')\n-\t    {\n-\t      reverse_code = 1;\n-\t      x = p->exp;\n-\t      break;\n-\t    }\n-\n-\t  /* If this is fp + constant, the equivalent is a better operand since\n-\t     it may let us predict the value of the comparison.  */\n-\t  else if (NONZERO_BASE_PLUS_P (p->exp))\n-\t    {\n-\t      arg1 = p->exp;\n-\t      continue;\n-\t    }\n-\t}\n-\n-      /* If we didn't find a useful equivalence for ARG1, we are done.\n-\t Otherwise, set up for the next iteration.  */\n-      if (x == 0)\n-\tbreak;\n-\n-      arg1 = XEXP (x, 0),  arg2 = XEXP (x, 1);\n-      if (GET_RTX_CLASS (GET_CODE (x)) == '<')\n-\tcode = GET_CODE (x);\n-\n-      if (reverse_code)\n-\tcode = reverse_condition (code);\n-    }\n-\n-  /* Return our results.  Return the modes from before fold_rtx\n-     because fold_rtx might produce const_int, and then it's too late.  */\n-  *pmode1 = GET_MODE (arg1), *pmode2 = GET_MODE (arg2);\n-  *parg1 = fold_rtx (arg1, 0), *parg2 = fold_rtx (arg2, 0);\n-\n-  return code;\n-}\n-\f\n-/* Try to simplify a unary operation CODE whose output mode is to be\n-   MODE with input operand OP whose mode was originally OP_MODE.\n-   Return zero if no simplification can be made.  */\n-\n-rtx\n-simplify_unary_operation (code, mode, op, op_mode)\n-     enum rtx_code code;\n-     enum machine_mode mode;\n-     rtx op;\n-     enum machine_mode op_mode;\n-{\n-  register int width = GET_MODE_BITSIZE (mode);\n-\n-  /* The order of these tests is critical so that, for example, we don't\n-     check the wrong mode (input vs. output) for a conversion operation,\n-     such as FIX.  At some point, this should be simplified.  */\n-\n-#if !defined(REAL_IS_NOT_DOUBLE) || defined(REAL_ARITHMETIC)\n-\n-  if (code == FLOAT && GET_MODE (op) == VOIDmode\n-      && (GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT))\n-    {\n-      HOST_WIDE_INT hv, lv;\n-      REAL_VALUE_TYPE d;\n-\n-      if (GET_CODE (op) == CONST_INT)\n-\tlv = INTVAL (op), hv = INTVAL (op) < 0 ? -1 : 0;\n-      else\n-\tlv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);\n-\n-#ifdef REAL_ARITHMETIC\n-      REAL_VALUE_FROM_INT (d, lv, hv, mode);\n-#else\n-      if (hv < 0)\n-\t{\n-\t  d = (double) (~ hv);\n-\t  d *= ((double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2))\n-\t\t* (double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2)));\n-\t  d += (double) (unsigned HOST_WIDE_INT) (~ lv);\n-\t  d = (- d - 1.0);\n-\t}\n-      else\n-\t{\n-\t  d = (double) hv;\n-\t  d *= ((double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2))\n-\t\t* (double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2)));\n-\t  d += (double) (unsigned HOST_WIDE_INT) lv;\n-\t}\n-#endif  /* REAL_ARITHMETIC */\n-      d = real_value_truncate (mode, d);\n-      return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n-    }\n-  else if (code == UNSIGNED_FLOAT && GET_MODE (op) == VOIDmode\n-\t   && (GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT))\n-    {\n-      HOST_WIDE_INT hv, lv;\n-      REAL_VALUE_TYPE d;\n-\n-      if (GET_CODE (op) == CONST_INT)\n-\tlv = INTVAL (op), hv = INTVAL (op) < 0 ? -1 : 0;\n-      else\n-\tlv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);\n-\n-      if (op_mode == VOIDmode)\n-\t{\n-\t  /* We don't know how to interpret negative-looking numbers in\n-\t     this case, so don't try to fold those.  */\n-\t  if (hv < 0)\n-\t    return 0;\n-\t}\n-      else if (GET_MODE_BITSIZE (op_mode) >= HOST_BITS_PER_WIDE_INT * 2)\n-\t;\n-      else\n-\thv = 0, lv &= GET_MODE_MASK (op_mode);\n-\n-#ifdef REAL_ARITHMETIC\n-      REAL_VALUE_FROM_UNSIGNED_INT (d, lv, hv, mode);\n-#else\n-\n-      d = (double) (unsigned HOST_WIDE_INT) hv;\n-      d *= ((double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2))\n-\t    * (double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2)));\n-      d += (double) (unsigned HOST_WIDE_INT) lv;\n-#endif  /* REAL_ARITHMETIC */\n-      d = real_value_truncate (mode, d);\n-      return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n-    }\n-#endif\n-\n-  if (GET_CODE (op) == CONST_INT\n-      && width <= HOST_BITS_PER_WIDE_INT && width > 0)\n-    {\n-      register HOST_WIDE_INT arg0 = INTVAL (op);\n-      register HOST_WIDE_INT val;\n-\n-      switch (code)\n-\t{\n-\tcase NOT:\n-\t  val = ~ arg0;\n-\t  break;\n-\n-\tcase NEG:\n-\t  val = - arg0;\n-\t  break;\n-\n-\tcase ABS:\n-\t  val = (arg0 >= 0 ? arg0 : - arg0);\n-\t  break;\n-\n-\tcase FFS:\n-\t  /* Don't use ffs here.  Instead, get low order bit and then its\n-\t     number.  If arg0 is zero, this will return 0, as desired.  */\n-\t  arg0 &= GET_MODE_MASK (mode);\n-\t  val = exact_log2 (arg0 & (- arg0)) + 1;\n-\t  break;\n-\n-\tcase TRUNCATE:\n-\t  val = arg0;\n-\t  break;\n-\n-\tcase ZERO_EXTEND:\n-\t  if (op_mode == VOIDmode)\n-\t    op_mode = mode;\n-\t  if (GET_MODE_BITSIZE (op_mode) == HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      /* If we were really extending the mode,\n-\t\t we would have to distinguish between zero-extension\n-\t\t and sign-extension.  */\n-\t      if (width != GET_MODE_BITSIZE (op_mode))\n-\t\tabort ();\n-\t      val = arg0;\n-\t    }\n-\t  else if (GET_MODE_BITSIZE (op_mode) < HOST_BITS_PER_WIDE_INT)\n-\t    val = arg0 & ~((HOST_WIDE_INT) (-1) << GET_MODE_BITSIZE (op_mode));\n-\t  else\n-\t    return 0;\n-\t  break;\n-\n-\tcase SIGN_EXTEND:\n-\t  if (op_mode == VOIDmode)\n-\t    op_mode = mode;\n-\t  if (GET_MODE_BITSIZE (op_mode) == HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      /* If we were really extending the mode,\n-\t\t we would have to distinguish between zero-extension\n-\t\t and sign-extension.  */\n-\t      if (width != GET_MODE_BITSIZE (op_mode))\n-\t\tabort ();\n-\t      val = arg0;\n-\t    }\n-\t  else if (GET_MODE_BITSIZE (op_mode) < HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      val\n-\t\t= arg0 & ~((HOST_WIDE_INT) (-1) << GET_MODE_BITSIZE (op_mode));\n-\t      if (val\n-\t\t  & ((HOST_WIDE_INT) 1 << (GET_MODE_BITSIZE (op_mode) - 1)))\n-\t\tval -= (HOST_WIDE_INT) 1 << GET_MODE_BITSIZE (op_mode);\n-\t    }\n-\t  else\n-\t    return 0;\n-\t  break;\n-\n-\tcase SQRT:\n-\t  return 0;\n-\n-\tdefault:\n-\t  abort ();\n-\t}\n-\n-      val = trunc_int_for_mode (val, mode);\n-\n-      return GEN_INT (val);\n-    }\n-\n-  /* We can do some operations on integer CONST_DOUBLEs.  Also allow\n-     for a DImode operation on a CONST_INT.  */\n-  else if (GET_MODE (op) == VOIDmode && width <= HOST_BITS_PER_INT * 2\n-\t   && (GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT))\n-    {\n-      HOST_WIDE_INT l1, h1, lv, hv;\n-\n-      if (GET_CODE (op) == CONST_DOUBLE)\n-\tl1 = CONST_DOUBLE_LOW (op), h1 = CONST_DOUBLE_HIGH (op);\n-      else\n-\tl1 = INTVAL (op), h1 = l1 < 0 ? -1 : 0;\n-\n-      switch (code)\n-\t{\n-\tcase NOT:\n-\t  lv = ~ l1;\n-\t  hv = ~ h1;\n-\t  break;\n-\n-\tcase NEG:\n-\t  neg_double (l1, h1, &lv, &hv);\n-\t  break;\n-\n-\tcase ABS:\n-\t  if (h1 < 0)\n-\t    neg_double (l1, h1, &lv, &hv);\n-\t  else\n-\t    lv = l1, hv = h1;\n-\t  break;\n-\n-\tcase FFS:\n-\t  hv = 0;\n-\t  if (l1 == 0)\n-\t    lv = HOST_BITS_PER_WIDE_INT + exact_log2 (h1 & (-h1)) + 1;\n-\t  else\n-\t    lv = exact_log2 (l1 & (-l1)) + 1;\n-\t  break;\n-\n-\tcase TRUNCATE:\n-\t  /* This is just a change-of-mode, so do nothing.  */\n-\t  lv = l1, hv = h1;\n-\t  break;\n-\n-\tcase ZERO_EXTEND:\n-\t  if (op_mode == VOIDmode\n-\t      || GET_MODE_BITSIZE (op_mode) > HOST_BITS_PER_WIDE_INT)\n-\t    return 0;\n-\n-\t  hv = 0;\n-\t  lv = l1 & GET_MODE_MASK (op_mode);\n-\t  break;\n-\n-\tcase SIGN_EXTEND:\n-\t  if (op_mode == VOIDmode\n-\t      || GET_MODE_BITSIZE (op_mode) > HOST_BITS_PER_WIDE_INT)\n-\t    return 0;\n-\t  else\n-\t    {\n-\t      lv = l1 & GET_MODE_MASK (op_mode);\n-\t      if (GET_MODE_BITSIZE (op_mode) < HOST_BITS_PER_WIDE_INT\n-\t\t  && (lv & ((HOST_WIDE_INT) 1\n-\t\t\t    << (GET_MODE_BITSIZE (op_mode) - 1))) != 0)\n-\t\tlv -= (HOST_WIDE_INT) 1 << GET_MODE_BITSIZE (op_mode);\n-\n-\t      hv = (lv < 0) ? ~ (HOST_WIDE_INT) 0 : 0;\n-\t    }\n-\t  break;\n-\n-\tcase SQRT:\n-\t  return 0;\n-\n-\tdefault:\n-\t  return 0;\n-\t}\n-\n-      return immed_double_const (lv, hv, mode);\n-    }\n-\n-#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n-  else if (GET_CODE (op) == CONST_DOUBLE\n-\t   && GET_MODE_CLASS (mode) == MODE_FLOAT)\n-    {\n-      REAL_VALUE_TYPE d;\n-      jmp_buf handler;\n-      rtx x;\n-\n-      if (setjmp (handler))\n-\t/* There used to be a warning here, but that is inadvisable.\n-\t   People may want to cause traps, and the natural way\n-\t   to do it should not get a warning.  */\n-\treturn 0;\n-\n-      set_float_handler (handler);\n-\n-      REAL_VALUE_FROM_CONST_DOUBLE (d, op);\n-\n-      switch (code)\n-\t{\n-\tcase NEG:\n-\t  d = REAL_VALUE_NEGATE (d);\n-\t  break;\n-\n-\tcase ABS:\n-\t  if (REAL_VALUE_NEGATIVE (d))\n-\t    d = REAL_VALUE_NEGATE (d);\n-\t  break;\n-\n-\tcase FLOAT_TRUNCATE:\n-\t  d = real_value_truncate (mode, d);\n-\t  break;\n-\n-\tcase FLOAT_EXTEND:\n-\t  /* All this does is change the mode.  */\n-\t  break;\n-\n-\tcase FIX:\n-\t  d = REAL_VALUE_RNDZINT (d);\n-\t  break;\n-\n-\tcase UNSIGNED_FIX:\n-\t  d = REAL_VALUE_UNSIGNED_RNDZINT (d);\n-\t  break;\n-\n-\tcase SQRT:\n-\t  return 0;\n-\n-\tdefault:\n-\t  abort ();\n-\t}\n-\n-      x = CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n-      set_float_handler (NULL_PTR);\n-      return x;\n-    }\n-\n-  else if (GET_CODE (op) == CONST_DOUBLE\n-\t   && GET_MODE_CLASS (GET_MODE (op)) == MODE_FLOAT\n-\t   && GET_MODE_CLASS (mode) == MODE_INT\n-\t   && width <= HOST_BITS_PER_WIDE_INT && width > 0)\n-    {\n-      REAL_VALUE_TYPE d;\n-      jmp_buf handler;\n-      HOST_WIDE_INT val;\n-\n-      if (setjmp (handler))\n-\treturn 0;\n-\n-      set_float_handler (handler);\n-\n-      REAL_VALUE_FROM_CONST_DOUBLE (d, op);\n-\n-      switch (code)\n-\t{\n-\tcase FIX:\n-\t  val = REAL_VALUE_FIX (d);\n-\t  break;\n-\n-\tcase UNSIGNED_FIX:\n-\t  val = REAL_VALUE_UNSIGNED_FIX (d);\n-\t  break;\n-\n-\tdefault:\n-\t  abort ();\n-\t}\n-\n-      set_float_handler (NULL_PTR);\n-\n-      val = trunc_int_for_mode (val, mode);\n-\n-      return GEN_INT (val);\n-    }\n-#endif\n-  /* This was formerly used only for non-IEEE float.\n-     eggert@twinsun.com says it is safe for IEEE also.  */\n-  else\n-    {\n-      /* There are some simplifications we can do even if the operands\n-\t aren't constant.  */\n-      switch (code)\n-\t{\n-\tcase NEG:\n-\tcase NOT:\n-\t  /* (not (not X)) == X, similarly for NEG.  */\n-\t  if (GET_CODE (op) == code)\n-\t    return XEXP (op, 0);\n-\t  break;\n-\n-\tcase SIGN_EXTEND:\n-\t  /* (sign_extend (truncate (minus (label_ref L1) (label_ref L2))))\n-\t     becomes just the MINUS if its mode is MODE.  This allows\n-\t     folding switch statements on machines using casesi (such as\n-\t     the Vax).  */\n-\t  if (GET_CODE (op) == TRUNCATE\n-\t      && GET_MODE (XEXP (op, 0)) == mode\n-\t      && GET_CODE (XEXP (op, 0)) == MINUS\n-\t      && GET_CODE (XEXP (XEXP (op, 0), 0)) == LABEL_REF\n-\t      && GET_CODE (XEXP (XEXP (op, 0), 1)) == LABEL_REF)\n-\t    return XEXP (op, 0);\n-\n-#ifdef POINTERS_EXTEND_UNSIGNED\n-\t  if (! POINTERS_EXTEND_UNSIGNED\n-\t      && mode == Pmode && GET_MODE (op) == ptr_mode\n-\t      && CONSTANT_P (op))\n-\t    return convert_memory_address (Pmode, op);\n-#endif\n-\t  break;\n-\n-#ifdef POINTERS_EXTEND_UNSIGNED\n-\tcase ZERO_EXTEND:\n-\t  if (POINTERS_EXTEND_UNSIGNED\n-\t      && mode == Pmode && GET_MODE (op) == ptr_mode\n-\t      && CONSTANT_P (op))\n-\t    return convert_memory_address (Pmode, op);\n-\t  break;\n-#endif\n-\t  \n-\tdefault:\n-\t  break;\n-\t}\n-\n-      return 0;\n-    }\n-}\n-\f\n-/* Simplify a binary operation CODE with result mode MODE, operating on OP0\n-   and OP1.  Return 0 if no simplification is possible.\n-\n-   Don't use this for relational operations such as EQ or LT.\n-   Use simplify_relational_operation instead.  */\n-\n-rtx\n-simplify_binary_operation (code, mode, op0, op1)\n-     enum rtx_code code;\n-     enum machine_mode mode;\n-     rtx op0, op1;\n-{\n-  register HOST_WIDE_INT arg0, arg1, arg0s, arg1s;\n-  HOST_WIDE_INT val;\n-  int width = GET_MODE_BITSIZE (mode);\n-  rtx tem;\n-\n-  /* Relational operations don't work here.  We must know the mode\n-     of the operands in order to do the comparison correctly.\n-     Assuming a full word can give incorrect results.\n-     Consider comparing 128 with -128 in QImode.  */\n-\n-  if (GET_RTX_CLASS (code) == '<')\n-    abort ();\n-\n-#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n-  if (GET_MODE_CLASS (mode) == MODE_FLOAT\n-      && GET_CODE (op0) == CONST_DOUBLE && GET_CODE (op1) == CONST_DOUBLE\n-      && mode == GET_MODE (op0) && mode == GET_MODE (op1))\n-    {\n-      REAL_VALUE_TYPE f0, f1, value;\n-      jmp_buf handler;\n-\n-      if (setjmp (handler))\n-\treturn 0;\n-\n-      set_float_handler (handler);\n-\n-      REAL_VALUE_FROM_CONST_DOUBLE (f0, op0);\n-      REAL_VALUE_FROM_CONST_DOUBLE (f1, op1);\n-      f0 = real_value_truncate (mode, f0);\n-      f1 = real_value_truncate (mode, f1);\n-\n-#ifdef REAL_ARITHMETIC\n-#ifndef REAL_INFINITY\n-      if (code == DIV && REAL_VALUES_EQUAL (f1, dconst0))\n-\treturn 0;\n-#endif\n-      REAL_ARITHMETIC (value, rtx_to_tree_code (code), f0, f1);\n-#else\n-      switch (code)\n-\t{\n-\tcase PLUS:\n-\t  value = f0 + f1;\n-\t  break;\n-\tcase MINUS:\n-\t  value = f0 - f1;\n-\t  break;\n-\tcase MULT:\n-\t  value = f0 * f1;\n-\t  break;\n-\tcase DIV:\n-#ifndef REAL_INFINITY\n-\t  if (f1 == 0)\n-\t    return 0;\n-#endif\n-\t  value = f0 / f1;\n-\t  break;\n-\tcase SMIN:\n-\t  value = MIN (f0, f1);\n-\t  break;\n-\tcase SMAX:\n-\t  value = MAX (f0, f1);\n-\t  break;\n-\tdefault:\n-\t  abort ();\n-\t}\n-#endif\n-\n-      value = real_value_truncate (mode, value);\n-      set_float_handler (NULL_PTR);\n-      return CONST_DOUBLE_FROM_REAL_VALUE (value, mode);\n-    }\n-#endif  /* not REAL_IS_NOT_DOUBLE, or REAL_ARITHMETIC */\n-\n-  /* We can fold some multi-word operations.  */\n-  if (GET_MODE_CLASS (mode) == MODE_INT\n-      && width == HOST_BITS_PER_WIDE_INT * 2\n-      && (GET_CODE (op0) == CONST_DOUBLE || GET_CODE (op0) == CONST_INT)\n-      && (GET_CODE (op1) == CONST_DOUBLE || GET_CODE (op1) == CONST_INT))\n-    {\n-      HOST_WIDE_INT l1, l2, h1, h2, lv, hv;\n-\n-      if (GET_CODE (op0) == CONST_DOUBLE)\n-\tl1 = CONST_DOUBLE_LOW (op0), h1 = CONST_DOUBLE_HIGH (op0);\n-      else\n-\tl1 = INTVAL (op0), h1 = l1 < 0 ? -1 : 0;\n-\n-      if (GET_CODE (op1) == CONST_DOUBLE)\n-\tl2 = CONST_DOUBLE_LOW (op1), h2 = CONST_DOUBLE_HIGH (op1);\n-      else\n-\tl2 = INTVAL (op1), h2 = l2 < 0 ? -1 : 0;\n-\n-      switch (code)\n-\t{\n-\tcase MINUS:\n-\t  /* A - B == A + (-B).  */\n-\t  neg_double (l2, h2, &lv, &hv);\n-\t  l2 = lv, h2 = hv;\n-\n-\t  /* .. fall through ...  */\n-\n-\tcase PLUS:\n-\t  add_double (l1, h1, l2, h2, &lv, &hv);\n-\t  break;\n-\n-\tcase MULT:\n-\t  mul_double (l1, h1, l2, h2, &lv, &hv);\n-\t  break;\n-\n-\tcase DIV:  case MOD:   case UDIV:  case UMOD:\n-\t  /* We'd need to include tree.h to do this and it doesn't seem worth\n-\t     it.  */\n-\t  return 0;\n-\n-\tcase AND:\n-\t  lv = l1 & l2, hv = h1 & h2;\n-\t  break;\n-\n-\tcase IOR:\n-\t  lv = l1 | l2, hv = h1 | h2;\n-\t  break;\n-\n-\tcase XOR:\n-\t  lv = l1 ^ l2, hv = h1 ^ h2;\n-\t  break;\n-\n-\tcase SMIN:\n-\t  if (h1 < h2\n-\t      || (h1 == h2\n-\t\t  && ((unsigned HOST_WIDE_INT) l1\n-\t\t      < (unsigned HOST_WIDE_INT) l2)))\n-\t    lv = l1, hv = h1;\n-\t  else\n-\t    lv = l2, hv = h2;\n-\t  break;\n-\n-\tcase SMAX:\n-\t  if (h1 > h2\n-\t      || (h1 == h2\n-\t\t  && ((unsigned HOST_WIDE_INT) l1\n-\t\t      > (unsigned HOST_WIDE_INT) l2)))\n-\t    lv = l1, hv = h1;\n-\t  else\n-\t    lv = l2, hv = h2;\n-\t  break;\n-\n-\tcase UMIN:\n-\t  if ((unsigned HOST_WIDE_INT) h1 < (unsigned HOST_WIDE_INT) h2\n-\t      || (h1 == h2\n-\t\t  && ((unsigned HOST_WIDE_INT) l1\n-\t\t      < (unsigned HOST_WIDE_INT) l2)))\n-\t    lv = l1, hv = h1;\n-\t  else\n-\t    lv = l2, hv = h2;\n-\t  break;\n-\n-\tcase UMAX:\n-\t  if ((unsigned HOST_WIDE_INT) h1 > (unsigned HOST_WIDE_INT) h2\n-\t      || (h1 == h2\n-\t\t  && ((unsigned HOST_WIDE_INT) l1\n-\t\t      > (unsigned HOST_WIDE_INT) l2)))\n-\t    lv = l1, hv = h1;\n-\t  else\n-\t    lv = l2, hv = h2;\n-\t  break;\n-\n-\tcase LSHIFTRT:   case ASHIFTRT:\n-\tcase ASHIFT:\n-\tcase ROTATE:     case ROTATERT:\n-#ifdef SHIFT_COUNT_TRUNCATED\n-\t  if (SHIFT_COUNT_TRUNCATED)\n-\t    l2 &= (GET_MODE_BITSIZE (mode) - 1), h2 = 0;\n-#endif\n-\n-\t  if (h2 != 0 || l2 < 0 || l2 >= GET_MODE_BITSIZE (mode))\n-\t    return 0;\n-\n-\t  if (code == LSHIFTRT || code == ASHIFTRT)\n-\t    rshift_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv,\n-\t\t\t   code == ASHIFTRT);\n-\t  else if (code == ASHIFT)\n-\t    lshift_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv, 1);\n-\t  else if (code == ROTATE)\n-\t    lrotate_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv);\n-\t  else /* code == ROTATERT */\n-\t    rrotate_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv);\n-\t  break;\n-\n-\tdefault:\n-\t  return 0;\n-\t}\n-\n-      return immed_double_const (lv, hv, mode);\n-    }\n-\n-  if (GET_CODE (op0) != CONST_INT || GET_CODE (op1) != CONST_INT\n-      || width > HOST_BITS_PER_WIDE_INT || width == 0)\n-    {\n-      /* Even if we can't compute a constant result,\n-\t there are some cases worth simplifying.  */\n-\n-      switch (code)\n-\t{\n-\tcase PLUS:\n-\t  /* In IEEE floating point, x+0 is not the same as x.  Similarly\n-\t     for the other optimizations below.  */\n-\t  if (TARGET_FLOAT_FORMAT == IEEE_FLOAT_FORMAT\n-\t      && FLOAT_MODE_P (mode) && ! flag_fast_math)\n-\t    break;\n-\n-\t  if (op1 == CONST0_RTX (mode))\n-\t    return op0;\n-\n-\t  /* ((-a) + b) -> (b - a) and similarly for (a + (-b)) */\n-\t  if (GET_CODE (op0) == NEG)\n-\t    return cse_gen_binary (MINUS, mode, op1, XEXP (op0, 0));\n-\t  else if (GET_CODE (op1) == NEG)\n-\t    return cse_gen_binary (MINUS, mode, op0, XEXP (op1, 0));\n-\n-\t  /* Handle both-operands-constant cases.  We can only add\n-\t     CONST_INTs to constants since the sum of relocatable symbols\n-\t     can't be handled by most assemblers.  Don't add CONST_INT\n-\t     to CONST_INT since overflow won't be computed properly if wider\n-\t     than HOST_BITS_PER_WIDE_INT.  */\n-\n-\t  if (CONSTANT_P (op0) && GET_MODE (op0) != VOIDmode\n-\t      && GET_CODE (op1) == CONST_INT)\n-\t    return plus_constant (op0, INTVAL (op1));\n-\t  else if (CONSTANT_P (op1) && GET_MODE (op1) != VOIDmode\n-\t\t   && GET_CODE (op0) == CONST_INT)\n-\t    return plus_constant (op1, INTVAL (op0));\n-\n-\t  /* See if this is something like X * C - X or vice versa or\n-\t     if the multiplication is written as a shift.  If so, we can\n-\t     distribute and make a new multiply, shift, or maybe just\n-\t     have X (if C is 2 in the example above).  But don't make\n-\t     real multiply if we didn't have one before.  */\n-\n-\t  if (! FLOAT_MODE_P (mode))\n-\t    {\n-\t      HOST_WIDE_INT coeff0 = 1, coeff1 = 1;\n-\t      rtx lhs = op0, rhs = op1;\n-\t      int had_mult = 0;\n-\n-\t      if (GET_CODE (lhs) == NEG)\n-\t\tcoeff0 = -1, lhs = XEXP (lhs, 0);\n-\t      else if (GET_CODE (lhs) == MULT\n-\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT)\n-\t\t{\n-\t\t  coeff0 = INTVAL (XEXP (lhs, 1)), lhs = XEXP (lhs, 0);\n-\t\t  had_mult = 1;\n-\t\t}\n-\t      else if (GET_CODE (lhs) == ASHIFT\n-\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT\n-\t\t       && INTVAL (XEXP (lhs, 1)) >= 0\n-\t\t       && INTVAL (XEXP (lhs, 1)) < HOST_BITS_PER_WIDE_INT)\n-\t\t{\n-\t\t  coeff0 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (lhs, 1));\n-\t\t  lhs = XEXP (lhs, 0);\n-\t\t}\n-\n-\t      if (GET_CODE (rhs) == NEG)\n-\t\tcoeff1 = -1, rhs = XEXP (rhs, 0);\n-\t      else if (GET_CODE (rhs) == MULT\n-\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT)\n-\t\t{\n-\t\t  coeff1 = INTVAL (XEXP (rhs, 1)), rhs = XEXP (rhs, 0);\n-\t\t  had_mult = 1;\n-\t\t}\n-\t      else if (GET_CODE (rhs) == ASHIFT\n-\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT\n-\t\t       && INTVAL (XEXP (rhs, 1)) >= 0\n-\t\t       && INTVAL (XEXP (rhs, 1)) < HOST_BITS_PER_WIDE_INT)\n-\t\t{\n-\t\t  coeff1 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (rhs, 1));\n-\t\t  rhs = XEXP (rhs, 0);\n-\t\t}\n-\n-\t      if (rtx_equal_p (lhs, rhs))\n-\t\t{\n-\t\t  tem = cse_gen_binary (MULT, mode, lhs,\n-\t\t\t\t\tGEN_INT (coeff0 + coeff1));\n-\t\t  return (GET_CODE (tem) == MULT && ! had_mult) ? 0 : tem;\n-\t\t}\n-\t    }\n-\n-\t  /* If one of the operands is a PLUS or a MINUS, see if we can\n-\t     simplify this by the associative law. \n-\t     Don't use the associative law for floating point.\n-\t     The inaccuracy makes it nonassociative,\n-\t     and subtle programs can break if operations are associated.  */\n-\n-\t  if (INTEGRAL_MODE_P (mode)\n-\t      && (GET_CODE (op0) == PLUS || GET_CODE (op0) == MINUS\n-\t\t  || GET_CODE (op1) == PLUS || GET_CODE (op1) == MINUS)\n-\t      && (tem = simplify_plus_minus (code, mode, op0, op1)) != 0)\n-\t    return tem;\n-\t  break;\n-\n-\tcase COMPARE:\n-#ifdef HAVE_cc0\n-\t  /* Convert (compare FOO (const_int 0)) to FOO unless we aren't\n-\t     using cc0, in which case we want to leave it as a COMPARE\n-\t     so we can distinguish it from a register-register-copy.\n-\n-\t     In IEEE floating point, x-0 is not the same as x.  */\n-\n-\t  if ((TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n-\t       || ! FLOAT_MODE_P (mode) || flag_fast_math)\n-\t      && op1 == CONST0_RTX (mode))\n-\t    return op0;\n-#else\n-\t  /* Do nothing here.  */\n-#endif\n-\t  break;\n-\t      \n-\tcase MINUS:\n-\t  /* None of these optimizations can be done for IEEE\n-\t     floating point.  */\n-\t  if (TARGET_FLOAT_FORMAT == IEEE_FLOAT_FORMAT\n-\t      && FLOAT_MODE_P (mode) && ! flag_fast_math)\n-\t    break;\n-\n-\t  /* We can't assume x-x is 0 even with non-IEEE floating point,\n-\t     but since it is zero except in very strange circumstances, we\n-\t     will treat it as zero with -ffast-math.  */\n-\t  if (rtx_equal_p (op0, op1)\n-\t      && ! side_effects_p (op0)\n-\t      && (! FLOAT_MODE_P (mode) || flag_fast_math))\n-\t    return CONST0_RTX (mode);\n-\n-\t  /* Change subtraction from zero into negation.  */\n-\t  if (op0 == CONST0_RTX (mode))\n-\t    return gen_rtx_NEG (mode, op1);\n-\n-\t  /* (-1 - a) is ~a.  */\n-\t  if (op0 == constm1_rtx)\n-\t    return gen_rtx_NOT (mode, op1);\n-\n-\t  /* Subtracting 0 has no effect.  */\n-\t  if (op1 == CONST0_RTX (mode))\n-\t    return op0;\n-\n-\t  /* See if this is something like X * C - X or vice versa or\n-\t     if the multiplication is written as a shift.  If so, we can\n-\t     distribute and make a new multiply, shift, or maybe just\n-\t     have X (if C is 2 in the example above).  But don't make\n-\t     real multiply if we didn't have one before.  */\n-\n-\t  if (! FLOAT_MODE_P (mode))\n-\t    {\n-\t      HOST_WIDE_INT coeff0 = 1, coeff1 = 1;\n-\t      rtx lhs = op0, rhs = op1;\n-\t      int had_mult = 0;\n-\n-\t      if (GET_CODE (lhs) == NEG)\n-\t\tcoeff0 = -1, lhs = XEXP (lhs, 0);\n-\t      else if (GET_CODE (lhs) == MULT\n-\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT)\n-\t\t{\n-\t\t  coeff0 = INTVAL (XEXP (lhs, 1)), lhs = XEXP (lhs, 0);\n-\t\t  had_mult = 1;\n-\t\t}\n-\t      else if (GET_CODE (lhs) == ASHIFT\n-\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT\n-\t\t       && INTVAL (XEXP (lhs, 1)) >= 0\n-\t\t       && INTVAL (XEXP (lhs, 1)) < HOST_BITS_PER_WIDE_INT)\n-\t\t{\n-\t\t  coeff0 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (lhs, 1));\n-\t\t  lhs = XEXP (lhs, 0);\n-\t\t}\n-\n-\t      if (GET_CODE (rhs) == NEG)\n-\t\tcoeff1 = - 1, rhs = XEXP (rhs, 0);\n-\t      else if (GET_CODE (rhs) == MULT\n-\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT)\n-\t\t{\n-\t\t  coeff1 = INTVAL (XEXP (rhs, 1)), rhs = XEXP (rhs, 0);\n-\t\t  had_mult = 1;\n-\t\t}\n-\t      else if (GET_CODE (rhs) == ASHIFT\n-\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT\n-\t\t       && INTVAL (XEXP (rhs, 1)) >= 0\n-\t\t       && INTVAL (XEXP (rhs, 1)) < HOST_BITS_PER_WIDE_INT)\n-\t\t{\n-\t\t  coeff1 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (rhs, 1));\n-\t\t  rhs = XEXP (rhs, 0);\n-\t\t}\n-\n-\t      if (rtx_equal_p (lhs, rhs))\n-\t\t{\n-\t\t  tem = cse_gen_binary (MULT, mode, lhs,\n-\t\t\t\t\tGEN_INT (coeff0 - coeff1));\n-\t\t  return (GET_CODE (tem) == MULT && ! had_mult) ? 0 : tem;\n-\t\t}\n-\t    }\n-\n-\t  /* (a - (-b)) -> (a + b).  */\n-\t  if (GET_CODE (op1) == NEG)\n-\t    return cse_gen_binary (PLUS, mode, op0, XEXP (op1, 0));\n-\n-\t  /* If one of the operands is a PLUS or a MINUS, see if we can\n-\t     simplify this by the associative law. \n-\t     Don't use the associative law for floating point.\n-\t     The inaccuracy makes it nonassociative,\n-\t     and subtle programs can break if operations are associated.  */\n-\n-\t  if (INTEGRAL_MODE_P (mode)\n-\t      && (GET_CODE (op0) == PLUS || GET_CODE (op0) == MINUS\n-\t\t  || GET_CODE (op1) == PLUS || GET_CODE (op1) == MINUS)\n-\t      && (tem = simplify_plus_minus (code, mode, op0, op1)) != 0)\n-\t    return tem;\n-\n-\t  /* Don't let a relocatable value get a negative coeff.  */\n-\t  if (GET_CODE (op1) == CONST_INT && GET_MODE (op0) != VOIDmode)\n-\t    return plus_constant (op0, - INTVAL (op1));\n-\n-\t  /* (x - (x & y)) -> (x & ~y) */\n-\t  if (GET_CODE (op1) == AND)\n-\t    {\n-\t     if (rtx_equal_p (op0, XEXP (op1, 0)))\n-\t       return cse_gen_binary (AND, mode, op0,\n-\t\t\t\t      gen_rtx_NOT (mode, XEXP (op1, 1)));\n-\t     if (rtx_equal_p (op0, XEXP (op1, 1)))\n-\t       return cse_gen_binary (AND, mode, op0,\n-\t\t\t\t      gen_rtx_NOT (mode, XEXP (op1, 0)));\n-\t   }\n-\t  break;\n-\n-\tcase MULT:\n-\t  if (op1 == constm1_rtx)\n-\t    {\n-\t      tem = simplify_unary_operation (NEG, mode, op0, mode);\n-\n-\t      return tem ? tem : gen_rtx_NEG (mode, op0);\n-\t    }\n-\n-\t  /* In IEEE floating point, x*0 is not always 0.  */\n-\t  if ((TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n-\t       || ! FLOAT_MODE_P (mode) || flag_fast_math)\n-\t      && op1 == CONST0_RTX (mode)\n-\t      && ! side_effects_p (op0))\n-\t    return op1;\n-\n-\t  /* In IEEE floating point, x*1 is not equivalent to x for nans.\n-\t     However, ANSI says we can drop signals,\n-\t     so we can do this anyway.  */\n-\t  if (op1 == CONST1_RTX (mode))\n-\t    return op0;\n-\n-\t  /* Convert multiply by constant power of two into shift unless\n-\t     we are still generating RTL.  This test is a kludge.  */\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && (val = exact_log2 (INTVAL (op1))) >= 0\n-\t      /* If the mode is larger than the host word size, and the\n-\t\t uppermost bit is set, then this isn't a power of two due\n-\t\t to implicit sign extension.  */\n-\t      && (width <= HOST_BITS_PER_WIDE_INT\n-\t\t  || val != HOST_BITS_PER_WIDE_INT - 1)\n-\t      && ! rtx_equal_function_value_matters)\n-\t    return gen_rtx_ASHIFT (mode, op0, GEN_INT (val));\n-\n-\t  if (GET_CODE (op1) == CONST_DOUBLE\n-\t      && GET_MODE_CLASS (GET_MODE (op1)) == MODE_FLOAT)\n-\t    {\n-\t      REAL_VALUE_TYPE d;\n-\t      jmp_buf handler;\n-\t      int op1is2, op1ism1;\n-\n-\t      if (setjmp (handler))\n-\t\treturn 0;\n-\n-\t      set_float_handler (handler);\n-\t      REAL_VALUE_FROM_CONST_DOUBLE (d, op1);\n-\t      op1is2 = REAL_VALUES_EQUAL (d, dconst2);\n-\t      op1ism1 = REAL_VALUES_EQUAL (d, dconstm1);\n-\t      set_float_handler (NULL_PTR);\n-\n-\t      /* x*2 is x+x and x*(-1) is -x */\n-\t      if (op1is2 && GET_MODE (op0) == mode)\n-\t\treturn gen_rtx_PLUS (mode, op0, copy_rtx (op0));\n-\n-\t      else if (op1ism1 && GET_MODE (op0) == mode)\n-\t\treturn gen_rtx_NEG (mode, op0);\n-\t    }\n-\t  break;\n-\n-\tcase IOR:\n-\t  if (op1 == const0_rtx)\n-\t    return op0;\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && (INTVAL (op1) & GET_MODE_MASK (mode)) == GET_MODE_MASK (mode))\n-\t    return op1;\n-\t  if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n-\t    return op0;\n-\t  /* A | (~A) -> -1 */\n-\t  if (((GET_CODE (op0) == NOT && rtx_equal_p (XEXP (op0, 0), op1))\n-\t       || (GET_CODE (op1) == NOT && rtx_equal_p (XEXP (op1, 0), op0)))\n-\t      && ! side_effects_p (op0)\n-\t      && GET_MODE_CLASS (mode) != MODE_CC)\n-\t    return constm1_rtx;\n-\t  break;\n-\n-\tcase XOR:\n-\t  if (op1 == const0_rtx)\n-\t    return op0;\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && (INTVAL (op1) & GET_MODE_MASK (mode)) == GET_MODE_MASK (mode))\n-\t    return gen_rtx_NOT (mode, op0);\n-\t  if (op0 == op1 && ! side_effects_p (op0)\n-\t      && GET_MODE_CLASS (mode) != MODE_CC)\n-\t    return const0_rtx;\n-\t  break;\n-\n-\tcase AND:\n-\t  if (op1 == const0_rtx && ! side_effects_p (op0))\n-\t    return const0_rtx;\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && (INTVAL (op1) & GET_MODE_MASK (mode)) == GET_MODE_MASK (mode))\n-\t    return op0;\n-\t  if (op0 == op1 && ! side_effects_p (op0)\n-\t      && GET_MODE_CLASS (mode) != MODE_CC)\n-\t    return op0;\n-\t  /* A & (~A) -> 0 */\n-\t  if (((GET_CODE (op0) == NOT && rtx_equal_p (XEXP (op0, 0), op1))\n-\t       || (GET_CODE (op1) == NOT && rtx_equal_p (XEXP (op1, 0), op0)))\n-\t      && ! side_effects_p (op0)\n-\t      && GET_MODE_CLASS (mode) != MODE_CC)\n-\t    return const0_rtx;\n-\t  break;\n-\n-\tcase UDIV:\n-\t  /* Convert divide by power of two into shift (divide by 1 handled\n-\t     below).  */\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && (arg1 = exact_log2 (INTVAL (op1))) > 0)\n-\t    return gen_rtx_LSHIFTRT (mode, op0, GEN_INT (arg1));\n-\n-\t  /* ... fall through ...  */\n-\n-\tcase DIV:\n-\t  if (op1 == CONST1_RTX (mode))\n-\t    return op0;\n-\n-\t  /* In IEEE floating point, 0/x is not always 0.  */\n-\t  if ((TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n-\t       || ! FLOAT_MODE_P (mode) || flag_fast_math)\n-\t      && op0 == CONST0_RTX (mode)\n-\t      && ! side_effects_p (op1))\n-\t    return op0;\n-\n-#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n-\t  /* Change division by a constant into multiplication.  Only do\n-\t     this with -ffast-math until an expert says it is safe in\n-\t     general.  */\n-\t  else if (GET_CODE (op1) == CONST_DOUBLE\n-\t\t   && GET_MODE_CLASS (GET_MODE (op1)) == MODE_FLOAT\n-\t\t   && op1 != CONST0_RTX (mode)\n-\t\t   && flag_fast_math)\n-\t    {\n-\t      REAL_VALUE_TYPE d;\n-\t      REAL_VALUE_FROM_CONST_DOUBLE (d, op1);\n-\n-\t      if (! REAL_VALUES_EQUAL (d, dconst0))\n-\t\t{\n-#if defined (REAL_ARITHMETIC)\n-\t\t  REAL_ARITHMETIC (d, rtx_to_tree_code (DIV), dconst1, d);\n-\t\t  return gen_rtx_MULT (mode, op0, \n-\t\t\t\t       CONST_DOUBLE_FROM_REAL_VALUE (d, mode));\n-#else\n-\t\t  return\n-\t\t    gen_rtx_MULT (mode, op0, \n-\t\t\t\t  CONST_DOUBLE_FROM_REAL_VALUE (1./d, mode));\n-#endif\n-\t\t}\n-\t    }\n-#endif\n-\t  break;\n-\n-\tcase UMOD:\n-\t  /* Handle modulus by power of two (mod with 1 handled below).  */\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && exact_log2 (INTVAL (op1)) > 0)\n-\t    return gen_rtx_AND (mode, op0, GEN_INT (INTVAL (op1) - 1));\n-\n-\t  /* ... fall through ...  */\n-\n-\tcase MOD:\n-\t  if ((op0 == const0_rtx || op1 == const1_rtx)\n-\t      && ! side_effects_p (op0) && ! side_effects_p (op1))\n-\t    return const0_rtx;\n-\t  break;\n-\n-\tcase ROTATERT:\n-\tcase ROTATE:\n-\t  /* Rotating ~0 always results in ~0.  */\n-\t  if (GET_CODE (op0) == CONST_INT && width <= HOST_BITS_PER_WIDE_INT\n-\t      && (unsigned HOST_WIDE_INT) INTVAL (op0) == GET_MODE_MASK (mode)\n-\t      && ! side_effects_p (op1))\n-\t    return op0;\n-\n-\t  /* ... fall through ...  */\n-\n-\tcase ASHIFT:\n-\tcase ASHIFTRT:\n-\tcase LSHIFTRT:\n-\t  if (op1 == const0_rtx)\n-\t    return op0;\n-\t  if (op0 == const0_rtx && ! side_effects_p (op1))\n-\t    return op0;\n-\t  break;\n-\n-\tcase SMIN:\n-\t  if (width <= HOST_BITS_PER_WIDE_INT && GET_CODE (op1) == CONST_INT \n-\t      && INTVAL (op1) == (HOST_WIDE_INT) 1 << (width -1)\n-\t      && ! side_effects_p (op0))\n-\t    return op1;\n-\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n-\t    return op0;\n-\t  break;\n-\t   \n-\tcase SMAX:\n-\t  if (width <= HOST_BITS_PER_WIDE_INT && GET_CODE (op1) == CONST_INT\n-\t      && ((unsigned HOST_WIDE_INT) INTVAL (op1)\n-\t\t  == (unsigned HOST_WIDE_INT) GET_MODE_MASK (mode) >> 1)\n-\t      && ! side_effects_p (op0))\n-\t    return op1;\n-\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n-\t    return op0;\n-\t  break;\n-\n-\tcase UMIN:\n-\t  if (op1 == const0_rtx && ! side_effects_p (op0))\n-\t    return op1;\n-\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n-\t    return op0;\n-\t  break;\n-\t    \n-\tcase UMAX:\n-\t  if (op1 == constm1_rtx && ! side_effects_p (op0))\n-\t    return op1;\n-\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n-\t    return op0;\n-\t  break;\n-\n-\tdefault:\n-\t  abort ();\n-\t}\n-      \n-      return 0;\n-    }\n-\n-  /* Get the integer argument values in two forms:\n-     zero-extended in ARG0, ARG1 and sign-extended in ARG0S, ARG1S.  */\n-\n-  arg0 = INTVAL (op0);\n-  arg1 = INTVAL (op1);\n-\n-  if (width < HOST_BITS_PER_WIDE_INT)\n-    {\n-      arg0 &= ((HOST_WIDE_INT) 1 << width) - 1;\n-      arg1 &= ((HOST_WIDE_INT) 1 << width) - 1;\n-\n-      arg0s = arg0;\n-      if (arg0s & ((HOST_WIDE_INT) 1 << (width - 1)))\n-\targ0s |= ((HOST_WIDE_INT) (-1) << width);\n-\n-      arg1s = arg1;\n-      if (arg1s & ((HOST_WIDE_INT) 1 << (width - 1)))\n-\targ1s |= ((HOST_WIDE_INT) (-1) << width);\n-    }\n-  else\n-    {\n-      arg0s = arg0;\n-      arg1s = arg1;\n-    }\n-\n-  /* Compute the value of the arithmetic.  */\n-\n-  switch (code)\n-    {\n-    case PLUS:\n-      val = arg0s + arg1s;\n-      break;\n-\n-    case MINUS:\n-      val = arg0s - arg1s;\n-      break;\n-\n-    case MULT:\n-      val = arg0s * arg1s;\n-      break;\n-\n-    case DIV:\n-      if (arg1s == 0)\n-\treturn 0;\n-      val = arg0s / arg1s;\n-      break;\n-\n-    case MOD:\n-      if (arg1s == 0)\n-\treturn 0;\n-      val = arg0s % arg1s;\n-      break;\n-\n-    case UDIV:\n-      if (arg1 == 0)\n-\treturn 0;\n-      val = (unsigned HOST_WIDE_INT) arg0 / arg1;\n-      break;\n-\n-    case UMOD:\n-      if (arg1 == 0)\n-\treturn 0;\n-      val = (unsigned HOST_WIDE_INT) arg0 % arg1;\n-      break;\n-\n-    case AND:\n-      val = arg0 & arg1;\n-      break;\n-\n-    case IOR:\n-      val = arg0 | arg1;\n-      break;\n-\n-    case XOR:\n-      val = arg0 ^ arg1;\n-      break;\n-\n-    case LSHIFTRT:\n-      /* If shift count is undefined, don't fold it; let the machine do\n-\t what it wants.  But truncate it if the machine will do that.  */\n-      if (arg1 < 0)\n-\treturn 0;\n-\n-#ifdef SHIFT_COUNT_TRUNCATED\n-      if (SHIFT_COUNT_TRUNCATED)\n-\targ1 %= width;\n-#endif\n-\n-      val = ((unsigned HOST_WIDE_INT) arg0) >> arg1;\n-      break;\n-\n-    case ASHIFT:\n-      if (arg1 < 0)\n-\treturn 0;\n-\n-#ifdef SHIFT_COUNT_TRUNCATED\n-      if (SHIFT_COUNT_TRUNCATED)\n-\targ1 %= width;\n-#endif\n-\n-      val = ((unsigned HOST_WIDE_INT) arg0) << arg1;\n-      break;\n-\n-    case ASHIFTRT:\n-      if (arg1 < 0)\n-\treturn 0;\n-\n-#ifdef SHIFT_COUNT_TRUNCATED\n-      if (SHIFT_COUNT_TRUNCATED)\n-\targ1 %= width;\n-#endif\n-\n-      val = arg0s >> arg1;\n-\n-      /* Bootstrap compiler may not have sign extended the right shift.\n-\t Manually extend the sign to insure bootstrap cc matches gcc.  */\n-      if (arg0s < 0 && arg1 > 0)\n-\tval |= ((HOST_WIDE_INT) -1) << (HOST_BITS_PER_WIDE_INT - arg1);\n-\n-      break;\n-\n-    case ROTATERT:\n-      if (arg1 < 0)\n-\treturn 0;\n-\n-      arg1 %= width;\n-      val = ((((unsigned HOST_WIDE_INT) arg0) << (width - arg1))\n-\t     | (((unsigned HOST_WIDE_INT) arg0) >> arg1));\n-      break;\n-\n-    case ROTATE:\n-      if (arg1 < 0)\n-\treturn 0;\n-\n-      arg1 %= width;\n-      val = ((((unsigned HOST_WIDE_INT) arg0) << arg1)\n-\t     | (((unsigned HOST_WIDE_INT) arg0) >> (width - arg1)));\n-      break;\n-\n-    case COMPARE:\n-      /* Do nothing here.  */\n-      return 0;\n-\n-    case SMIN:\n-      val = arg0s <= arg1s ? arg0s : arg1s;\n-      break;\n-\n-    case UMIN:\n-      val = ((unsigned HOST_WIDE_INT) arg0\n-\t     <= (unsigned HOST_WIDE_INT) arg1 ? arg0 : arg1);\n-      break;\n-\n-    case SMAX:\n-      val = arg0s > arg1s ? arg0s : arg1s;\n-      break;\n-\n-    case UMAX:\n-      val = ((unsigned HOST_WIDE_INT) arg0\n-\t     > (unsigned HOST_WIDE_INT) arg1 ? arg0 : arg1);\n-      break;\n-\n-    default:\n-      abort ();\n-    }\n-\n-  val = trunc_int_for_mode (val, mode);\n-\n-  return GEN_INT (val);\n-}\n-\f\n-/* Simplify a PLUS or MINUS, at least one of whose operands may be another\n-   PLUS or MINUS.\n-\n-   Rather than test for specific case, we do this by a brute-force method\n-   and do all possible simplifications until no more changes occur.  Then\n-   we rebuild the operation.  */\n-\n-static rtx\n-simplify_plus_minus (code, mode, op0, op1)\n-     enum rtx_code code;\n-     enum machine_mode mode;\n-     rtx op0, op1;\n-{\n-  rtx ops[8];\n-  int negs[8];\n-  rtx result, tem;\n-  int n_ops = 2, input_ops = 2, input_consts = 0, n_consts = 0;\n-  int first = 1, negate = 0, changed;\n-  int i, j;\n-\n-  bzero ((char *) ops, sizeof ops);\n-  \n-  /* Set up the two operands and then expand them until nothing has been\n-     changed.  If we run out of room in our array, give up; this should\n-     almost never happen.  */\n-\n-  ops[0] = op0, ops[1] = op1, negs[0] = 0, negs[1] = (code == MINUS);\n-\n-  changed = 1;\n-  while (changed)\n-    {\n-      changed = 0;\n-\n-      for (i = 0; i < n_ops; i++)\n-\tswitch (GET_CODE (ops[i]))\n-\t  {\n-\t  case PLUS:\n-\t  case MINUS:\n-\t    if (n_ops == 7)\n-\t      return 0;\n-\n-\t    ops[n_ops] = XEXP (ops[i], 1);\n-\t    negs[n_ops++] = GET_CODE (ops[i]) == MINUS ? !negs[i] : negs[i];\n-\t    ops[i] = XEXP (ops[i], 0);\n-\t    input_ops++;\n-\t    changed = 1;\n-\t    break;\n-\n-\t  case NEG:\n-\t    ops[i] = XEXP (ops[i], 0);\n-\t    negs[i] = ! negs[i];\n-\t    changed = 1;\n-\t    break;\n-\n-\t  case CONST:\n-\t    ops[i] = XEXP (ops[i], 0);\n-\t    input_consts++;\n-\t    changed = 1;\n-\t    break;\n-\n-\t  case NOT:\n-\t    /* ~a -> (-a - 1) */\n-\t    if (n_ops != 7)\n-\t      {\n-\t\tops[n_ops] = constm1_rtx;\n-\t\tnegs[n_ops++] = negs[i];\n-\t\tops[i] = XEXP (ops[i], 0);\n-\t\tnegs[i] = ! negs[i];\n-\t\tchanged = 1;\n-\t      }\n-\t    break;\n-\n-\t  case CONST_INT:\n-\t    if (negs[i])\n-\t      ops[i] = GEN_INT (- INTVAL (ops[i])), negs[i] = 0, changed = 1;\n-\t    break;\n-\n-\t  default:\n-\t    break;\n-\t  }\n-    }\n-\n-  /* If we only have two operands, we can't do anything.  */\n-  if (n_ops <= 2)\n-    return 0;\n-\n-  /* Now simplify each pair of operands until nothing changes.  The first\n-     time through just simplify constants against each other.  */\n-\n-  changed = 1;\n-  while (changed)\n-    {\n-      changed = first;\n-\n-      for (i = 0; i < n_ops - 1; i++)\n-\tfor (j = i + 1; j < n_ops; j++)\n-\t  if (ops[i] != 0 && ops[j] != 0\n-\t      && (! first || (CONSTANT_P (ops[i]) && CONSTANT_P (ops[j]))))\n-\t    {\n-\t      rtx lhs = ops[i], rhs = ops[j];\n-\t      enum rtx_code ncode = PLUS;\n-\n-\t      if (negs[i] && ! negs[j])\n-\t\tlhs = ops[j], rhs = ops[i], ncode = MINUS;\n-\t      else if (! negs[i] && negs[j])\n-\t\tncode = MINUS;\n-\n-\t      tem = simplify_binary_operation (ncode, mode, lhs, rhs);\n-\t      if (tem)\n-\t\t{\n-\t\t  ops[i] = tem, ops[j] = 0;\n-\t\t  negs[i] = negs[i] && negs[j];\n-\t\t  if (GET_CODE (tem) == NEG)\n-\t\t    ops[i] = XEXP (tem, 0), negs[i] = ! negs[i];\n-\n-\t\t  if (GET_CODE (ops[i]) == CONST_INT && negs[i])\n-\t\t    ops[i] = GEN_INT (- INTVAL (ops[i])), negs[i] = 0;\n-\t\t  changed = 1;\n-\t\t}\n-\t    }\n-\n-      first = 0;\n-    }\n-\n-  /* Pack all the operands to the lower-numbered entries and give up if\n-     we didn't reduce the number of operands we had.  Make sure we\n-     count a CONST as two operands.  If we have the same number of\n-     operands, but have made more CONSTs than we had, this is also\n-     an improvement, so accept it.  */\n-\n-  for (i = 0, j = 0; j < n_ops; j++)\n-    if (ops[j] != 0)\n-      {\n-\tops[i] = ops[j], negs[i++] = negs[j];\n-\tif (GET_CODE (ops[j]) == CONST)\n-\t  n_consts++;\n-      }\n-\n-  if (i + n_consts > input_ops\n-      || (i + n_consts == input_ops && n_consts <= input_consts))\n-    return 0;\n-\n-  n_ops = i;\n-\n-  /* If we have a CONST_INT, put it last.  */\n-  for (i = 0; i < n_ops - 1; i++)\n-    if (GET_CODE (ops[i]) == CONST_INT)\n-      {\n-\ttem = ops[n_ops - 1], ops[n_ops - 1] = ops[i] , ops[i] = tem;\n-\tj = negs[n_ops - 1], negs[n_ops - 1] = negs[i], negs[i] = j;\n-      }\n-\n-  /* Put a non-negated operand first.  If there aren't any, make all\n-     operands positive and negate the whole thing later.  */\n-  for (i = 0; i < n_ops && negs[i]; i++)\n-    ;\n-\n-  if (i == n_ops)\n-    {\n-      for (i = 0; i < n_ops; i++)\n-\tnegs[i] = 0;\n-      negate = 1;\n-    }\n-  else if (i != 0)\n-    {\n-      tem = ops[0], ops[0] = ops[i], ops[i] = tem;\n-      j = negs[0], negs[0] = negs[i], negs[i] = j;\n-    }\n-\n-  /* Now make the result by performing the requested operations.  */\n-  result = ops[0];\n-  for (i = 1; i < n_ops; i++)\n-    result = cse_gen_binary (negs[i] ? MINUS : PLUS, mode, result, ops[i]);\n+\t     call simplify_gen_binary so many times that we run out of\n+\t     memory.  */\n \n-  return negate ? gen_rtx_NEG (mode, result) : result;\n-}\n-\f\n-/* Make a binary operation by properly ordering the operands and \n-   seeing if the expression folds.  */\n+\t  found_better = 0;\n+\t  for (p = elt->first_same_value, count = 0;\n+\t       p && count < 32;\n+\t       p = p->next_same_value, count++)\n+\t    if (! p->flag\n+\t\t&& (GET_CODE (p->exp) == REG\n+\t\t    || exp_equiv_p (p->exp, p->exp, 1, 0)))\n+\t      {\n+\t\trtx new = simplify_gen_binary (GET_CODE (*loc), Pmode,\n+\t\t\t\t\t       p->exp, c);\n \n-static rtx\n-cse_gen_binary (code, mode, op0, op1)\n-     enum rtx_code code;\n-     enum machine_mode mode;\n-     rtx op0, op1;\n-{\n-  rtx tem;\n+\t\tif ((CSE_ADDRESS_COST (new) < best_addr_cost\n+\t\t    || (CSE_ADDRESS_COST (new) == best_addr_cost\n+\t\t\t&& (COST (new) + 1) >> 1 > best_rtx_cost)))\n+\t\t  {\n+\t\t    found_better = 1;\n+\t\t    best_addr_cost = CSE_ADDRESS_COST (new);\n+\t\t    best_rtx_cost = (COST (new) + 1) >> 1;\n+\t\t    best_elt = p;\n+\t\t    best_rtx = new;\n+\t\t  }\n+\t      }\n \n-  /* Put complex operands first and constants second if commutative.  */\n-  if (GET_RTX_CLASS (code) == 'c'\n-      && ((CONSTANT_P (op0) && GET_CODE (op1) != CONST_INT)\n-\t  || (GET_RTX_CLASS (GET_CODE (op0)) == 'o'\n-\t      && GET_RTX_CLASS (GET_CODE (op1)) != 'o')\n-\t  || (GET_CODE (op0) == SUBREG\n-\t      && GET_RTX_CLASS (GET_CODE (SUBREG_REG (op0))) == 'o'\n-\t      && GET_RTX_CLASS (GET_CODE (op1)) != 'o')))\n-    tem = op0, op0 = op1, op1 = tem;\n-\n-  /* If this simplifies, do it.  */\n-  tem = simplify_binary_operation (code, mode, op0, op1);\n-\n-  if (tem)\n-    return tem;\n-\n-  /* Handle addition and subtraction of CONST_INT specially.  Otherwise,\n-     just form the operation.  */\n-\n-  if (code == PLUS && GET_CODE (op1) == CONST_INT\n-      && GET_MODE (op0) != VOIDmode)\n-    return plus_constant (op0, INTVAL (op1));\n-  else if (code == MINUS && GET_CODE (op1) == CONST_INT\n-\t   && GET_MODE (op0) != VOIDmode)\n-    return plus_constant (op0, - INTVAL (op1));\n-  else\n-    return gen_rtx_fmt_ee (code, mode, op0, op1);\n+\t  if (found_better)\n+\t    {\n+\t      if (validate_change (insn, loc,\n+\t\t\t\t   canon_reg (copy_rtx (best_rtx),\n+\t\t\t\t\t      NULL_RTX), 0))\n+\t\treturn;\n+\t      else\n+\t\tbest_elt->flag = 1;\n+\t    }\n+\t}\n+    }\n+#endif\n }\n \f\n-struct cfc_args\n-{\n-  /* Input */\n-  rtx op0, op1;\n-  /* Output */\n-  int equal, op0lt, op1lt;\n-};\n-\n-static void\n-check_fold_consts (data)\n-  PTR data;\n-{\n-  struct cfc_args * args = (struct cfc_args *) data;\n-  REAL_VALUE_TYPE d0, d1;\n-\n-  REAL_VALUE_FROM_CONST_DOUBLE (d0, args->op0);\n-  REAL_VALUE_FROM_CONST_DOUBLE (d1, args->op1);\n-  args->equal = REAL_VALUES_EQUAL (d0, d1);\n-  args->op0lt = REAL_VALUES_LESS (d0, d1);\n-  args->op1lt = REAL_VALUES_LESS (d1, d0);\n-}\n+/* Given an operation (CODE, *PARG1, *PARG2), where code is a comparison\n+   operation (EQ, NE, GT, etc.), follow it back through the hash table and\n+   what values are being compared.\n \n-/* Like simplify_binary_operation except used for relational operators.\n-   MODE is the mode of the operands, not that of the result.  If MODE\n-   is VOIDmode, both operands must also be VOIDmode and we compare the\n-   operands in \"infinite precision\".\n+   *PARG1 and *PARG2 are updated to contain the rtx representing the values\n+   actually being compared.  For example, if *PARG1 was (cc0) and *PARG2\n+   was (const_int 0), *PARG1 and *PARG2 will be set to the objects that were\n+   compared to produce cc0.\n \n-   If no simplification is possible, this function returns zero.  Otherwise,\n-   it returns either const_true_rtx or const0_rtx.  */\n+   The return value is the comparison operator and is either the code of\n+   A or the code corresponding to the inverse of the comparison.  */\n \n-rtx\n-simplify_relational_operation (code, mode, op0, op1)\n+static enum rtx_code\n+find_comparison_args (code, parg1, parg2, pmode1, pmode2)\n      enum rtx_code code;\n-     enum machine_mode mode;\n-     rtx op0, op1;\n+     rtx *parg1, *parg2;\n+     enum machine_mode *pmode1, *pmode2;\n {\n-  int equal, op0lt, op0ltu, op1lt, op1ltu;\n-  rtx tem;\n-\n-  /* If op0 is a compare, extract the comparison arguments from it.  */\n-  if (GET_CODE (op0) == COMPARE && op1 == const0_rtx)\n-    op1 = XEXP (op0, 1), op0 = XEXP (op0, 0);\n-\n-  /* We can't simplify MODE_CC values since we don't know what the\n-     actual comparison is.  */\n-  if (GET_MODE_CLASS (GET_MODE (op0)) == MODE_CC\n-#ifdef HAVE_cc0\n-      || op0 == cc0_rtx\n-#endif\n-      )\n-    return 0;\n-\n-  /* For integer comparisons of A and B maybe we can simplify A - B and can\n-     then simplify a comparison of that with zero.  If A and B are both either\n-     a register or a CONST_INT, this can't help; testing for these cases will\n-     prevent infinite recursion here and speed things up.\n-\n-     If CODE is an unsigned comparison, then we can never do this optimization,\n-     because it gives an incorrect result if the subtraction wraps around zero.\n-     ANSI C defines unsigned operations such that they never overflow, and\n-     thus such cases can not be ignored.  */\n-\n-  if (INTEGRAL_MODE_P (mode) && op1 != const0_rtx\n-      && ! ((GET_CODE (op0) == REG || GET_CODE (op0) == CONST_INT)\n-\t    && (GET_CODE (op1) == REG || GET_CODE (op1) == CONST_INT))\n-      && 0 != (tem = simplify_binary_operation (MINUS, mode, op0, op1))\n-      && code != GTU && code != GEU && code != LTU && code != LEU)\n-    return simplify_relational_operation (signed_condition (code),\n-\t\t\t\t\t  mode, tem, const0_rtx);\n-\n-  /* For non-IEEE floating-point, if the two operands are equal, we know the\n-     result.  */\n-  if (rtx_equal_p (op0, op1)\n-      && (TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n-\t  || ! FLOAT_MODE_P (GET_MODE (op0)) || flag_fast_math))\n-    equal = 1, op0lt = 0, op0ltu = 0, op1lt = 0, op1ltu = 0;\n-\n-  /* If the operands are floating-point constants, see if we can fold\n-     the result.  */\n-#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n-  else if (GET_CODE (op0) == CONST_DOUBLE && GET_CODE (op1) == CONST_DOUBLE\n-\t   && GET_MODE_CLASS (GET_MODE (op0)) == MODE_FLOAT)\n-    {\n-      struct cfc_args args;\n+  rtx arg1, arg2;\n \n-      /* Setup input for check_fold_consts() */\n-      args.op0 = op0;\n-      args.op1 = op1;\n-      \n-      if (do_float_handler(check_fold_consts, (PTR) &args) == 0)\n-\t/* We got an exception from check_fold_consts() */\n-\treturn 0;\n+  arg1 = *parg1, arg2 = *parg2;\n \n-      /* Receive output from check_fold_consts() */\n-      equal = args.equal;\n-      op0lt = op0ltu = args.op0lt;\n-      op1lt = op1ltu = args.op1lt;\n-    }\n-#endif  /* not REAL_IS_NOT_DOUBLE, or REAL_ARITHMETIC */\n+  /* If ARG2 is const0_rtx, see what ARG1 is equivalent to.  */\n \n-  /* Otherwise, see if the operands are both integers.  */\n-  else if ((GET_MODE_CLASS (mode) == MODE_INT || mode == VOIDmode)\n-\t   && (GET_CODE (op0) == CONST_DOUBLE || GET_CODE (op0) == CONST_INT)\n-\t   && (GET_CODE (op1) == CONST_DOUBLE || GET_CODE (op1) == CONST_INT))\n+  while (arg2 == CONST0_RTX (GET_MODE (arg1)))\n     {\n-      int width = GET_MODE_BITSIZE (mode);\n-      HOST_WIDE_INT l0s, h0s, l1s, h1s;\n-      unsigned HOST_WIDE_INT l0u, h0u, l1u, h1u;\n-\n-      /* Get the two words comprising each integer constant.  */\n-      if (GET_CODE (op0) == CONST_DOUBLE)\n-\t{\n-\t  l0u = l0s = CONST_DOUBLE_LOW (op0);\n-\t  h0u = h0s = CONST_DOUBLE_HIGH (op0);\n-\t}\n-      else\n-\t{\n-\t  l0u = l0s = INTVAL (op0);\n-\t  h0u = h0s = l0s < 0 ? -1 : 0;\n-\t}\n-\t  \n-      if (GET_CODE (op1) == CONST_DOUBLE)\n-\t{\n-\t  l1u = l1s = CONST_DOUBLE_LOW (op1);\n-\t  h1u = h1s = CONST_DOUBLE_HIGH (op1);\n-\t}\n-      else\n-\t{\n-\t  l1u = l1s = INTVAL (op1);\n-\t  h1u = h1s = l1s < 0 ? -1 : 0;\n-\t}\n-\n-      /* If WIDTH is nonzero and smaller than HOST_BITS_PER_WIDE_INT,\n-\t we have to sign or zero-extend the values.  */\n-      if (width != 0 && width <= HOST_BITS_PER_WIDE_INT)\n-\th0u = h1u = 0, h0s = l0s < 0 ? -1 : 0, h1s = l1s < 0 ? -1 : 0;\n-\n-      if (width != 0 && width < HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  l0u &= ((HOST_WIDE_INT) 1 << width) - 1;\n-\t  l1u &= ((HOST_WIDE_INT) 1 << width) - 1;\n+      /* Set non-zero when we find something of interest.  */\n+      rtx x = 0;\n+      int reverse_code = 0;\n+      struct table_elt *p = 0;\n \n-\t  if (l0s & ((HOST_WIDE_INT) 1 << (width - 1)))\n-\t    l0s |= ((HOST_WIDE_INT) (-1) << width);\n+      /* If arg1 is a COMPARE, extract the comparison arguments from it.\n+\t On machines with CC0, this is the only case that can occur, since\n+\t fold_rtx will return the COMPARE or item being compared with zero\n+\t when given CC0.  */\n \n-\t  if (l1s & ((HOST_WIDE_INT) 1 << (width - 1)))\n-\t    l1s |= ((HOST_WIDE_INT) (-1) << width);\n-\t}\n+      if (GET_CODE (arg1) == COMPARE && arg2 == const0_rtx)\n+\tx = arg1;\n \n-      equal = (h0u == h1u && l0u == l1u);\n-      op0lt = (h0s < h1s || (h0s == h1s && l0s < l1s));\n-      op1lt = (h1s < h0s || (h1s == h0s && l1s < l0s));\n-      op0ltu = (h0u < h1u || (h0u == h1u && l0u < l1u));\n-      op1ltu = (h1u < h0u || (h1u == h0u && l1u < l0u));\n-    }\n+      /* If ARG1 is a comparison operator and CODE is testing for\n+\t STORE_FLAG_VALUE, get the inner arguments.  */\n \n-  /* Otherwise, there are some code-specific tests we can make.  */\n-  else\n-    {\n-      switch (code)\n+      else if (GET_RTX_CLASS (GET_CODE (arg1)) == '<')\n \t{\n-\tcase EQ:\n-\t  /* References to the frame plus a constant or labels cannot\n-\t     be zero, but a SYMBOL_REF can due to #pragma weak.  */\n-\t  if (((NONZERO_BASE_PLUS_P (op0) && op1 == const0_rtx)\n-\t       || GET_CODE (op0) == LABEL_REF)\n-#if FRAME_POINTER_REGNUM != ARG_POINTER_REGNUM\n-\t      /* On some machines, the ap reg can be 0 sometimes.  */\n-\t      && op0 != arg_pointer_rtx\n-#endif\n-\t\t)\n-\t    return const0_rtx;\n-\t  break;\n-\n-\tcase NE:\n-\t  if (((NONZERO_BASE_PLUS_P (op0) && op1 == const0_rtx)\n-\t       || GET_CODE (op0) == LABEL_REF)\n-#if FRAME_POINTER_REGNUM != ARG_POINTER_REGNUM\n-\t      && op0 != arg_pointer_rtx\n+\t  if (code == NE\n+\t      || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_INT\n+\t\t  && code == LT && STORE_FLAG_VALUE == -1)\n+#ifdef FLOAT_STORE_FLAG_VALUE\n+\t      || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_FLOAT\n+\t\t  && FLOAT_STORE_FLAG_VALUE < 0)\n #endif\n \t      )\n-\t    return const_true_rtx;\n-\t  break;\n-\n-\tcase GEU:\n-\t  /* Unsigned values are never negative.  */\n-\t  if (op1 == const0_rtx)\n-\t    return const_true_rtx;\n-\t  break;\n-\n-\tcase LTU:\n-\t  if (op1 == const0_rtx)\n-\t    return const0_rtx;\n-\t  break;\n-\n-\tcase LEU:\n-\t  /* Unsigned values are never greater than the largest\n-\t     unsigned value.  */\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && (unsigned HOST_WIDE_INT) INTVAL (op1) == GET_MODE_MASK (mode)\n-\t    && INTEGRAL_MODE_P (mode))\n-\t  return const_true_rtx;\n-\t  break;\n-\n-\tcase GTU:\n-\t  if (GET_CODE (op1) == CONST_INT\n-\t      && (unsigned HOST_WIDE_INT) INTVAL (op1) == GET_MODE_MASK (mode)\n-\t      && INTEGRAL_MODE_P (mode))\n-\t    return const0_rtx;\n-\t  break;\n-\t  \n-\tdefault:\n-\t  break;\n+\t    x = arg1;\n+\t  else if (code == EQ\n+\t\t   || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_INT\n+\t\t       && code == GE && STORE_FLAG_VALUE == -1)\n+#ifdef FLOAT_STORE_FLAG_VALUE\n+\t\t   || (GET_MODE_CLASS (GET_MODE (arg1)) == MODE_FLOAT\n+\t\t       && FLOAT_STORE_FLAG_VALUE < 0)\n+#endif\n+\t\t   )\n+\t    x = arg1, reverse_code = 1;\n \t}\n \n-      return 0;\n-    }\n+      /* ??? We could also check for\n \n-  /* If we reach here, EQUAL, OP0LT, OP0LTU, OP1LT, and OP1LTU are set\n-     as appropriate.  */\n-  switch (code)\n-    {\n-    case EQ:\n-      return equal ? const_true_rtx : const0_rtx;\n-    case NE:\n-      return ! equal ? const_true_rtx : const0_rtx;\n-    case LT:\n-      return op0lt ? const_true_rtx : const0_rtx;\n-    case GT:\n-      return op1lt ? const_true_rtx : const0_rtx;\n-    case LTU:\n-      return op0ltu ? const_true_rtx : const0_rtx;\n-    case GTU:\n-      return op1ltu ? const_true_rtx : const0_rtx;\n-    case LE:\n-      return equal || op0lt ? const_true_rtx : const0_rtx;\n-    case GE:\n-      return equal || op1lt ? const_true_rtx : const0_rtx;\n-    case LEU:\n-      return equal || op0ltu ? const_true_rtx : const0_rtx;\n-    case GEU:\n-      return equal || op1ltu ? const_true_rtx : const0_rtx;\n-    default:\n-      abort ();\n-    }\n-}\n-\f\n-/* Simplify CODE, an operation with result mode MODE and three operands,\n-   OP0, OP1, and OP2.  OP0_MODE was the mode of OP0 before it became\n-   a constant.  Return 0 if no simplifications is possible.  */\n+\t (ne (and (eq (...) (const_int 1))) (const_int 0))\n \n-rtx\n-simplify_ternary_operation (code, mode, op0_mode, op0, op1, op2)\n-     enum rtx_code code;\n-     enum machine_mode mode, op0_mode;\n-     rtx op0, op1, op2;\n-{\n-  int width = GET_MODE_BITSIZE (mode);\n+\t and related forms, but let's wait until we see them occurring.  */\n \n-  /* VOIDmode means \"infinite\" precision.  */\n-  if (width == 0)\n-    width = HOST_BITS_PER_WIDE_INT;\n+      if (x == 0)\n+\t/* Look up ARG1 in the hash table and see if it has an equivalence\n+\t   that lets us see what is being compared.  */\n+\tp = lookup (arg1, safe_hash (arg1, GET_MODE (arg1)) % NBUCKETS,\n+\t\t    GET_MODE (arg1));\n+      if (p) p = p->first_same_value;\n \n-  switch (code)\n-    {\n-    case SIGN_EXTRACT:\n-    case ZERO_EXTRACT:\n-      if (GET_CODE (op0) == CONST_INT\n-\t  && GET_CODE (op1) == CONST_INT\n-\t  && GET_CODE (op2) == CONST_INT\n-\t  && INTVAL (op1) + INTVAL (op2) <= GET_MODE_BITSIZE (op0_mode)\n-\t  && width <= HOST_BITS_PER_WIDE_INT)\n+      for (; p; p = p->next_same_value)\n \t{\n-\t  /* Extracting a bit-field from a constant */\n-\t  HOST_WIDE_INT val = INTVAL (op0);\n+\t  enum machine_mode inner_mode = GET_MODE (p->exp);\n \n-\t  if (BITS_BIG_ENDIAN)\n-\t    val >>= (GET_MODE_BITSIZE (op0_mode)\n-\t\t     - INTVAL (op2) - INTVAL (op1));\n-\t  else\n-\t    val >>= INTVAL (op2);\n+\t  /* If the entry isn't valid, skip it.  */\n+\t  if (! exp_equiv_p (p->exp, p->exp, 1, 0))\n+\t    continue;\n \n-\t  if (HOST_BITS_PER_WIDE_INT != INTVAL (op1))\n+\t  if (GET_CODE (p->exp) == COMPARE\n+\t      /* Another possibility is that this machine has a compare insn\n+\t\t that includes the comparison code.  In that case, ARG1 would\n+\t\t be equivalent to a comparison operation that would set ARG1 to\n+\t\t either STORE_FLAG_VALUE or zero.  If this is an NE operation,\n+\t\t ORIG_CODE is the actual comparison being done; if it is an EQ,\n+\t\t we must reverse ORIG_CODE.  On machine with a negative value\n+\t\t for STORE_FLAG_VALUE, also look at LT and GE operations.  */\n+\t      || ((code == NE\n+\t\t   || (code == LT\n+\t\t       && GET_MODE_CLASS (inner_mode) == MODE_INT\n+\t\t       && (GET_MODE_BITSIZE (inner_mode)\n+\t\t\t   <= HOST_BITS_PER_WIDE_INT)\n+\t\t       && (STORE_FLAG_VALUE\n+\t\t\t   & ((HOST_WIDE_INT) 1\n+\t\t\t      << (GET_MODE_BITSIZE (inner_mode) - 1))))\n+#ifdef FLOAT_STORE_FLAG_VALUE\n+\t\t   || (code == LT\n+\t\t       && GET_MODE_CLASS (inner_mode) == MODE_FLOAT\n+\t\t       && FLOAT_STORE_FLAG_VALUE < 0)\n+#endif\n+\t\t   )\n+\t\t  && GET_RTX_CLASS (GET_CODE (p->exp)) == '<'))\n \t    {\n-\t      /* First zero-extend.  */\n-\t      val &= ((HOST_WIDE_INT) 1 << INTVAL (op1)) - 1;\n-\t      /* If desired, propagate sign bit.  */\n-\t      if (code == SIGN_EXTRACT\n-\t\t  && (val & ((HOST_WIDE_INT) 1 << (INTVAL (op1) - 1))))\n-\t\tval |= ~ (((HOST_WIDE_INT) 1 << INTVAL (op1)) - 1);\n+\t      x = p->exp;\n+\t      break;\n+\t    }\n+\t  else if ((code == EQ\n+\t\t    || (code == GE\n+\t\t\t&& GET_MODE_CLASS (inner_mode) == MODE_INT\n+\t\t\t&& (GET_MODE_BITSIZE (inner_mode)\n+\t\t\t    <= HOST_BITS_PER_WIDE_INT)\n+\t\t\t&& (STORE_FLAG_VALUE\n+\t\t\t    & ((HOST_WIDE_INT) 1\n+\t\t\t       << (GET_MODE_BITSIZE (inner_mode) - 1))))\n+#ifdef FLOAT_STORE_FLAG_VALUE\n+\t\t    || (code == GE\n+\t\t\t&& GET_MODE_CLASS (inner_mode) == MODE_FLOAT\n+\t\t\t&& FLOAT_STORE_FLAG_VALUE < 0)\n+#endif\n+\t\t    )\n+\t\t   && GET_RTX_CLASS (GET_CODE (p->exp)) == '<')\n+\t    {\n+\t      reverse_code = 1;\n+\t      x = p->exp;\n+\t      break;\n \t    }\n \n-\t  /* Clear the bits that don't belong in our mode,\n-\t     unless they and our sign bit are all one.\n-\t     So we get either a reasonable negative value or a reasonable\n-\t     unsigned value for this mode.  */\n-\t  if (width < HOST_BITS_PER_WIDE_INT\n-\t      && ((val & ((HOST_WIDE_INT) (-1) << (width - 1)))\n-\t\t  != ((HOST_WIDE_INT) (-1) << (width - 1))))\n-\t    val &= ((HOST_WIDE_INT) 1 << width) - 1;\n-\n-\t  return GEN_INT (val);\n+\t  /* If this is fp + constant, the equivalent is a better operand since\n+\t     it may let us predict the value of the comparison.  */\n+\t  else if (NONZERO_BASE_PLUS_P (p->exp))\n+\t    {\n+\t      arg1 = p->exp;\n+\t      continue;\n+\t    }\n \t}\n-      break;\n \n-    case IF_THEN_ELSE:\n-      if (GET_CODE (op0) == CONST_INT)\n-\treturn op0 != const0_rtx ? op1 : op2;\n-\n-      /* Convert a == b ? b : a to \"a\".  */\n-      if (GET_CODE (op0) == NE && ! side_effects_p (op0)\n-\t  && rtx_equal_p (XEXP (op0, 0), op1)\n-\t  && rtx_equal_p (XEXP (op0, 1), op2))\n-\treturn op1;\n-      else if (GET_CODE (op0) == EQ && ! side_effects_p (op0)\n-\t  && rtx_equal_p (XEXP (op0, 1), op1)\n-\t  && rtx_equal_p (XEXP (op0, 0), op2))\n-\treturn op2;\n-      else if (GET_RTX_CLASS (GET_CODE (op0)) == '<' && ! side_effects_p (op0))\n-\t{\n-\t  rtx temp;\n-\t  temp = simplify_relational_operation (GET_CODE (op0), op0_mode,\n-\t\t\t\t\t\tXEXP (op0, 0), XEXP (op0, 1));\n-\t  /* See if any simplifications were possible.  */\n-\t  if (temp == const0_rtx)\n-\t    return op2;\n-\t  else if (temp == const1_rtx)\n-\t    return op1;\n-\t}\n-      break;\n+      /* If we didn't find a useful equivalence for ARG1, we are done.\n+\t Otherwise, set up for the next iteration.  */\n+      if (x == 0)\n+\tbreak;\n \n-    default:\n-      abort ();\n+      arg1 = XEXP (x, 0),  arg2 = XEXP (x, 1);\n+      if (GET_RTX_CLASS (GET_CODE (x)) == '<')\n+\tcode = GET_CODE (x);\n+\n+      if (reverse_code)\n+\tcode = reverse_condition (code);\n     }\n \n-  return 0;\n+  /* Return our results.  Return the modes from before fold_rtx\n+     because fold_rtx might produce const_int, and then it's too late.  */\n+  *pmode1 = GET_MODE (arg1), *pmode2 = GET_MODE (arg2);\n+  *parg1 = fold_rtx (arg1, 0), *parg2 = fold_rtx (arg2, 0);\n+\n+  return code;\n }\n \f\n /* If X is a nontrivial arithmetic operation on an argument\n@@ -5850,8 +4069,8 @@ fold_rtx (x, insn)\n \t      if (p)\n \t\tfor (p = p->first_same_value; p; p = p->next_same_value)\n \t\t  if (GET_CODE (p->exp) == REG)\n-\t\t    return cse_gen_binary (MINUS, mode, folded_arg0,\n-\t\t\t\t\t   canon_reg (p->exp, NULL_RTX));\n+\t\t    return simplify_gen_binary (MINUS, mode, folded_arg0,\n+\t\t\t\t\t\tcanon_reg (p->exp, NULL_RTX));\n \t    }\n \t  goto from_plus;\n \n@@ -5958,7 +4177,7 @@ fold_rtx (x, insn)\n \t      if (! reg_mentioned_p (folded_arg0, y))\n \t\ty = fold_rtx (y, insn);\n \n-\t      return cse_gen_binary (code, mode, y, new_const);\n+\t      return simplify_gen_binary (code, mode, y, new_const);\n \t    }\n \t  break;\n \n@@ -7298,11 +5517,32 @@ cse_insn (insn, libcall_insn)\n \t\t&& GET_CODE (XEXP (XEXP (src_const, 0), 0)) == LABEL_REF\n \t\t&& GET_CODE (XEXP (XEXP (src_const, 0), 1)) == LABEL_REF))\n \t{\n+\t  rtx simplified_src_const;\n \t  tem = find_reg_note (insn, REG_EQUAL, NULL_RTX);\n \t  \n \t  /* Make sure that the rtx is not shared with any other insn.  */\n \t  src_const = copy_rtx (src_const);\n \n+\t  /* Try to simplify SRC_CONST.\n+\n+\t     The primary purpose behind simplifying the note is to allow\n+\t     for easier removal of library call sequences later.  Consider\n+\t     a udiv libcall where we can determine the second argument is\n+\t     a constant.  SRC_CONST would look like:\n+\n+\t     \t(udiv (reg) (const_int 2**n))\n+\n+\t     That RTL expression will simplify into:\n+\n+\t\t(lshiftrt (reg) (const_int n))\n+\n+\t     A target using library calls for division is more likely to\n+\t     have a lshiftrt insn.  Thus, it is more likely that the libcall\n+\t     can be deleted in delete_trivially_dead_insns if we simplify\n+\t     the note.  */\n+\t  simplified_src_const = simplify_rtx (src_const);\n+\t  src_const = simplified_src_const ? simplified_src_const : src_const;\n+\t  \n \t  /* Record the actual constant value in a REG_EQUAL note, making\n \t     a new one if one does not already exist.  */\n \t  if (tem)\n@@ -9181,8 +7421,12 @@ delete_trivially_dead_insns (insns, nreg)\n \t  if (note)\n \t    {\n \t      rtx set = single_set (insn);\n-\t      if (set\n-\t\t  && validate_change (insn, &SET_SRC (set), XEXP (note, 0), 0))\n+\t      rtx new = simplify_rtx (XEXP (note, 0));\n+\n+\t      if (!new)\n+\t\tnew = XEXP (note, 0);\n+\n+\t      if (set && validate_change (insn, &SET_SRC (set), new, 0))\n \t\t{\n \t\t  remove_note (insn,\n \t\t\t       find_reg_note (insn, REG_RETVAL, NULL_RTX));"}, {"sha": "b96ab3839b2aa6936ca28c0799f165d9615f4fc4", "filename": "gcc/rtl.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "patch": "@@ -1069,6 +1069,9 @@ extern rtx simplify_unary_operation\tPROTO((enum rtx_code, enum machine_mode, rtx\n extern rtx simplify_binary_operation\tPROTO((enum rtx_code, enum machine_mode, rtx, rtx));\n extern rtx simplify_ternary_operation\tPROTO((enum rtx_code, enum machine_mode, enum machine_mode, rtx, rtx, rtx));\n extern rtx simplify_relational_operation PROTO((enum rtx_code, enum machine_mode, rtx, rtx));\n+extern rtx simplify_gen_binary\t\tPROTO((enum rtx_code, enum machine_mode,\n+\t\t\t\t\t       rtx, rtx));\n+extern rtx simplify_rtx\t\t\tPROTO((rtx));\n extern rtx gen_move_insn\t\tPROTO((rtx, rtx));\n extern rtx gen_jump\t\t\tPROTO((rtx));\n extern rtx gen_beq\t\t\tPROTO((rtx));"}, {"sha": "60c80c09d21aaaa95f10f77a43e9e5e4261b6aa0", "filename": "gcc/simplify-rtx.c", "status": "added", "additions": 1953, "deletions": 0, "changes": 1953, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0cedb36cbd7e0c407a33ecbcfffd08458059bf00/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=0cedb36cbd7e0c407a33ecbcfffd08458059bf00", "patch": "@@ -0,0 +1,1953 @@\n+/* Common subexpression elimination for GNU compiler.\n+   Copyright (C) 1987, 88, 89, 92-7, 1998, 1999 Free Software Foundation, Inc.\n+\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GNU CC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+\n+#include \"config.h\"\n+/* stdio.h must precede rtl.h for FFS.  */\n+#include \"system.h\"\n+#include <setjmp.h>\n+\n+#include \"rtl.h\"\n+#include \"tm_p.h\"\n+#include \"regs.h\"\n+#include \"hard-reg-set.h\"\n+#include \"flags.h\"\n+#include \"real.h\"\n+#include \"insn-config.h\"\n+#include \"recog.h\"\n+#include \"function.h\"\n+#include \"expr.h\"\n+#include \"toplev.h\"\n+#include \"output.h\"\n+\n+/* Simplification and canonicalization of RTL.  */\n+\n+/* Nonzero if X has the form (PLUS frame-pointer integer).  We check for\n+   virtual regs here because the simplify_*_operation routines are called\n+   by integrate.c, which is called before virtual register instantiation.\n+\n+   ?!? FIXED_BASE_PLUS_P and NONZERO_BASE_PLUS_P need to move into \n+   a header file so that their definitions can be shared with the\n+   simplification routines in simplify-rtx.c.  Until then, do not\n+   change these macros without also changing the copy in simplify-rtx.c.  */\n+\n+#define FIXED_BASE_PLUS_P(X)\t\t\t\t\t\\\n+  ((X) == frame_pointer_rtx || (X) == hard_frame_pointer_rtx\t\\\n+   || ((X) == arg_pointer_rtx && fixed_regs[ARG_POINTER_REGNUM])\\\n+   || (X) == virtual_stack_vars_rtx\t\t\t\t\\\n+   || (X) == virtual_incoming_args_rtx\t\t\t\t\\\n+   || (GET_CODE (X) == PLUS && GET_CODE (XEXP (X, 1)) == CONST_INT \\\n+       && (XEXP (X, 0) == frame_pointer_rtx\t\t\t\\\n+\t   || XEXP (X, 0) == hard_frame_pointer_rtx\t\t\\\n+\t   || ((X) == arg_pointer_rtx\t\t\t\t\\\n+\t       && fixed_regs[ARG_POINTER_REGNUM])\t\t\\\n+\t   || XEXP (X, 0) == virtual_stack_vars_rtx\t\t\\\n+\t   || XEXP (X, 0) == virtual_incoming_args_rtx))\t\\\n+   || GET_CODE (X) == ADDRESSOF)\n+\n+/* Similar, but also allows reference to the stack pointer.\n+\n+   This used to include FIXED_BASE_PLUS_P, however, we can't assume that\n+   arg_pointer_rtx by itself is nonzero, because on at least one machine,\n+   the i960, the arg pointer is zero when it is unused.  */\n+\n+#define NONZERO_BASE_PLUS_P(X)\t\t\t\t\t\\\n+  ((X) == frame_pointer_rtx || (X) == hard_frame_pointer_rtx\t\\\n+   || (X) == virtual_stack_vars_rtx\t\t\t\t\\\n+   || (X) == virtual_incoming_args_rtx\t\t\t\t\\\n+   || (GET_CODE (X) == PLUS && GET_CODE (XEXP (X, 1)) == CONST_INT \\\n+       && (XEXP (X, 0) == frame_pointer_rtx\t\t\t\\\n+\t   || XEXP (X, 0) == hard_frame_pointer_rtx\t\t\\\n+\t   || ((X) == arg_pointer_rtx\t\t\t\t\\\n+\t       && fixed_regs[ARG_POINTER_REGNUM])\t\t\\\n+\t   || XEXP (X, 0) == virtual_stack_vars_rtx\t\t\\\n+\t   || XEXP (X, 0) == virtual_incoming_args_rtx))\t\\\n+   || (X) == stack_pointer_rtx\t\t\t\t\t\\\n+   || (X) == virtual_stack_dynamic_rtx\t\t\t\t\\\n+   || (X) == virtual_outgoing_args_rtx\t\t\t\t\\\n+   || (GET_CODE (X) == PLUS && GET_CODE (XEXP (X, 1)) == CONST_INT \\\n+       && (XEXP (X, 0) == stack_pointer_rtx\t\t\t\\\n+\t   || XEXP (X, 0) == virtual_stack_dynamic_rtx\t\t\\\n+\t   || XEXP (X, 0) == virtual_outgoing_args_rtx))\t\\\n+   || GET_CODE (X) == ADDRESSOF)\n+\n+\n+static rtx simplify_plus_minus\tPROTO((enum rtx_code, enum machine_mode,\n+\t\t\t\t       rtx, rtx));\n+static void check_fold_consts\tPROTO((PTR));\n+\n+/* Make a binary operation by properly ordering the operands and \n+   seeing if the expression folds.  */\n+\n+rtx\n+simplify_gen_binary (code, mode, op0, op1)\n+     enum rtx_code code;\n+     enum machine_mode mode;\n+     rtx op0, op1;\n+{\n+  rtx tem;\n+\n+  /* Put complex operands first and constants second if commutative.  */\n+  if (GET_RTX_CLASS (code) == 'c'\n+      && ((CONSTANT_P (op0) && GET_CODE (op1) != CONST_INT)\n+\t  || (GET_RTX_CLASS (GET_CODE (op0)) == 'o'\n+\t      && GET_RTX_CLASS (GET_CODE (op1)) != 'o')\n+\t  || (GET_CODE (op0) == SUBREG\n+\t      && GET_RTX_CLASS (GET_CODE (SUBREG_REG (op0))) == 'o'\n+\t      && GET_RTX_CLASS (GET_CODE (op1)) != 'o')))\n+    tem = op0, op0 = op1, op1 = tem;\n+\n+  /* If this simplifies, do it.  */\n+  tem = simplify_binary_operation (code, mode, op0, op1);\n+\n+  if (tem)\n+    return tem;\n+\n+  /* Handle addition and subtraction of CONST_INT specially.  Otherwise,\n+     just form the operation.  */\n+\n+  if (code == PLUS && GET_CODE (op1) == CONST_INT\n+      && GET_MODE (op0) != VOIDmode)\n+    return plus_constant (op0, INTVAL (op1));\n+  else if (code == MINUS && GET_CODE (op1) == CONST_INT\n+\t   && GET_MODE (op0) != VOIDmode)\n+    return plus_constant (op0, - INTVAL (op1));\n+  else\n+    return gen_rtx_fmt_ee (code, mode, op0, op1);\n+}\n+\f\n+/* Try to simplify a unary operation CODE whose output mode is to be\n+   MODE with input operand OP whose mode was originally OP_MODE.\n+   Return zero if no simplification can be made.  */\n+\n+rtx\n+simplify_unary_operation (code, mode, op, op_mode)\n+     enum rtx_code code;\n+     enum machine_mode mode;\n+     rtx op;\n+     enum machine_mode op_mode;\n+{\n+  register int width = GET_MODE_BITSIZE (mode);\n+\n+  /* The order of these tests is critical so that, for example, we don't\n+     check the wrong mode (input vs. output) for a conversion operation,\n+     such as FIX.  At some point, this should be simplified.  */\n+\n+#if !defined(REAL_IS_NOT_DOUBLE) || defined(REAL_ARITHMETIC)\n+\n+  if (code == FLOAT && GET_MODE (op) == VOIDmode\n+      && (GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT))\n+    {\n+      HOST_WIDE_INT hv, lv;\n+      REAL_VALUE_TYPE d;\n+\n+      if (GET_CODE (op) == CONST_INT)\n+\tlv = INTVAL (op), hv = INTVAL (op) < 0 ? -1 : 0;\n+      else\n+\tlv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);\n+\n+#ifdef REAL_ARITHMETIC\n+      REAL_VALUE_FROM_INT (d, lv, hv, mode);\n+#else\n+      if (hv < 0)\n+\t{\n+\t  d = (double) (~ hv);\n+\t  d *= ((double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2))\n+\t\t* (double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2)));\n+\t  d += (double) (unsigned HOST_WIDE_INT) (~ lv);\n+\t  d = (- d - 1.0);\n+\t}\n+      else\n+\t{\n+\t  d = (double) hv;\n+\t  d *= ((double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2))\n+\t\t* (double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2)));\n+\t  d += (double) (unsigned HOST_WIDE_INT) lv;\n+\t}\n+#endif  /* REAL_ARITHMETIC */\n+      d = real_value_truncate (mode, d);\n+      return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n+    }\n+  else if (code == UNSIGNED_FLOAT && GET_MODE (op) == VOIDmode\n+\t   && (GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT))\n+    {\n+      HOST_WIDE_INT hv, lv;\n+      REAL_VALUE_TYPE d;\n+\n+      if (GET_CODE (op) == CONST_INT)\n+\tlv = INTVAL (op), hv = INTVAL (op) < 0 ? -1 : 0;\n+      else\n+\tlv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);\n+\n+      if (op_mode == VOIDmode)\n+\t{\n+\t  /* We don't know how to interpret negative-looking numbers in\n+\t     this case, so don't try to fold those.  */\n+\t  if (hv < 0)\n+\t    return 0;\n+\t}\n+      else if (GET_MODE_BITSIZE (op_mode) >= HOST_BITS_PER_WIDE_INT * 2)\n+\t;\n+      else\n+\thv = 0, lv &= GET_MODE_MASK (op_mode);\n+\n+#ifdef REAL_ARITHMETIC\n+      REAL_VALUE_FROM_UNSIGNED_INT (d, lv, hv, mode);\n+#else\n+\n+      d = (double) (unsigned HOST_WIDE_INT) hv;\n+      d *= ((double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2))\n+\t    * (double) ((HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT / 2)));\n+      d += (double) (unsigned HOST_WIDE_INT) lv;\n+#endif  /* REAL_ARITHMETIC */\n+      d = real_value_truncate (mode, d);\n+      return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n+    }\n+#endif\n+\n+  if (GET_CODE (op) == CONST_INT\n+      && width <= HOST_BITS_PER_WIDE_INT && width > 0)\n+    {\n+      register HOST_WIDE_INT arg0 = INTVAL (op);\n+      register HOST_WIDE_INT val;\n+\n+      switch (code)\n+\t{\n+\tcase NOT:\n+\t  val = ~ arg0;\n+\t  break;\n+\n+\tcase NEG:\n+\t  val = - arg0;\n+\t  break;\n+\n+\tcase ABS:\n+\t  val = (arg0 >= 0 ? arg0 : - arg0);\n+\t  break;\n+\n+\tcase FFS:\n+\t  /* Don't use ffs here.  Instead, get low order bit and then its\n+\t     number.  If arg0 is zero, this will return 0, as desired.  */\n+\t  arg0 &= GET_MODE_MASK (mode);\n+\t  val = exact_log2 (arg0 & (- arg0)) + 1;\n+\t  break;\n+\n+\tcase TRUNCATE:\n+\t  val = arg0;\n+\t  break;\n+\n+\tcase ZERO_EXTEND:\n+\t  if (op_mode == VOIDmode)\n+\t    op_mode = mode;\n+\t  if (GET_MODE_BITSIZE (op_mode) == HOST_BITS_PER_WIDE_INT)\n+\t    {\n+\t      /* If we were really extending the mode,\n+\t\t we would have to distinguish between zero-extension\n+\t\t and sign-extension.  */\n+\t      if (width != GET_MODE_BITSIZE (op_mode))\n+\t\tabort ();\n+\t      val = arg0;\n+\t    }\n+\t  else if (GET_MODE_BITSIZE (op_mode) < HOST_BITS_PER_WIDE_INT)\n+\t    val = arg0 & ~((HOST_WIDE_INT) (-1) << GET_MODE_BITSIZE (op_mode));\n+\t  else\n+\t    return 0;\n+\t  break;\n+\n+\tcase SIGN_EXTEND:\n+\t  if (op_mode == VOIDmode)\n+\t    op_mode = mode;\n+\t  if (GET_MODE_BITSIZE (op_mode) == HOST_BITS_PER_WIDE_INT)\n+\t    {\n+\t      /* If we were really extending the mode,\n+\t\t we would have to distinguish between zero-extension\n+\t\t and sign-extension.  */\n+\t      if (width != GET_MODE_BITSIZE (op_mode))\n+\t\tabort ();\n+\t      val = arg0;\n+\t    }\n+\t  else if (GET_MODE_BITSIZE (op_mode) < HOST_BITS_PER_WIDE_INT)\n+\t    {\n+\t      val\n+\t\t= arg0 & ~((HOST_WIDE_INT) (-1) << GET_MODE_BITSIZE (op_mode));\n+\t      if (val\n+\t\t  & ((HOST_WIDE_INT) 1 << (GET_MODE_BITSIZE (op_mode) - 1)))\n+\t\tval -= (HOST_WIDE_INT) 1 << GET_MODE_BITSIZE (op_mode);\n+\t    }\n+\t  else\n+\t    return 0;\n+\t  break;\n+\n+\tcase SQRT:\n+\t  return 0;\n+\n+\tdefault:\n+\t  abort ();\n+\t}\n+\n+      val = trunc_int_for_mode (val, mode);\n+\n+      return GEN_INT (val);\n+    }\n+\n+  /* We can do some operations on integer CONST_DOUBLEs.  Also allow\n+     for a DImode operation on a CONST_INT.  */\n+  else if (GET_MODE (op) == VOIDmode && width <= HOST_BITS_PER_INT * 2\n+\t   && (GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT))\n+    {\n+      HOST_WIDE_INT l1, h1, lv, hv;\n+\n+      if (GET_CODE (op) == CONST_DOUBLE)\n+\tl1 = CONST_DOUBLE_LOW (op), h1 = CONST_DOUBLE_HIGH (op);\n+      else\n+\tl1 = INTVAL (op), h1 = l1 < 0 ? -1 : 0;\n+\n+      switch (code)\n+\t{\n+\tcase NOT:\n+\t  lv = ~ l1;\n+\t  hv = ~ h1;\n+\t  break;\n+\n+\tcase NEG:\n+\t  neg_double (l1, h1, &lv, &hv);\n+\t  break;\n+\n+\tcase ABS:\n+\t  if (h1 < 0)\n+\t    neg_double (l1, h1, &lv, &hv);\n+\t  else\n+\t    lv = l1, hv = h1;\n+\t  break;\n+\n+\tcase FFS:\n+\t  hv = 0;\n+\t  if (l1 == 0)\n+\t    lv = HOST_BITS_PER_WIDE_INT + exact_log2 (h1 & (-h1)) + 1;\n+\t  else\n+\t    lv = exact_log2 (l1 & (-l1)) + 1;\n+\t  break;\n+\n+\tcase TRUNCATE:\n+\t  /* This is just a change-of-mode, so do nothing.  */\n+\t  lv = l1, hv = h1;\n+\t  break;\n+\n+\tcase ZERO_EXTEND:\n+\t  if (op_mode == VOIDmode\n+\t      || GET_MODE_BITSIZE (op_mode) > HOST_BITS_PER_WIDE_INT)\n+\t    return 0;\n+\n+\t  hv = 0;\n+\t  lv = l1 & GET_MODE_MASK (op_mode);\n+\t  break;\n+\n+\tcase SIGN_EXTEND:\n+\t  if (op_mode == VOIDmode\n+\t      || GET_MODE_BITSIZE (op_mode) > HOST_BITS_PER_WIDE_INT)\n+\t    return 0;\n+\t  else\n+\t    {\n+\t      lv = l1 & GET_MODE_MASK (op_mode);\n+\t      if (GET_MODE_BITSIZE (op_mode) < HOST_BITS_PER_WIDE_INT\n+\t\t  && (lv & ((HOST_WIDE_INT) 1\n+\t\t\t    << (GET_MODE_BITSIZE (op_mode) - 1))) != 0)\n+\t\tlv -= (HOST_WIDE_INT) 1 << GET_MODE_BITSIZE (op_mode);\n+\n+\t      hv = (lv < 0) ? ~ (HOST_WIDE_INT) 0 : 0;\n+\t    }\n+\t  break;\n+\n+\tcase SQRT:\n+\t  return 0;\n+\n+\tdefault:\n+\t  return 0;\n+\t}\n+\n+      return immed_double_const (lv, hv, mode);\n+    }\n+\n+#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n+  else if (GET_CODE (op) == CONST_DOUBLE\n+\t   && GET_MODE_CLASS (mode) == MODE_FLOAT)\n+    {\n+      REAL_VALUE_TYPE d;\n+      jmp_buf handler;\n+      rtx x;\n+\n+      if (setjmp (handler))\n+\t/* There used to be a warning here, but that is inadvisable.\n+\t   People may want to cause traps, and the natural way\n+\t   to do it should not get a warning.  */\n+\treturn 0;\n+\n+      set_float_handler (handler);\n+\n+      REAL_VALUE_FROM_CONST_DOUBLE (d, op);\n+\n+      switch (code)\n+\t{\n+\tcase NEG:\n+\t  d = REAL_VALUE_NEGATE (d);\n+\t  break;\n+\n+\tcase ABS:\n+\t  if (REAL_VALUE_NEGATIVE (d))\n+\t    d = REAL_VALUE_NEGATE (d);\n+\t  break;\n+\n+\tcase FLOAT_TRUNCATE:\n+\t  d = real_value_truncate (mode, d);\n+\t  break;\n+\n+\tcase FLOAT_EXTEND:\n+\t  /* All this does is change the mode.  */\n+\t  break;\n+\n+\tcase FIX:\n+\t  d = REAL_VALUE_RNDZINT (d);\n+\t  break;\n+\n+\tcase UNSIGNED_FIX:\n+\t  d = REAL_VALUE_UNSIGNED_RNDZINT (d);\n+\t  break;\n+\n+\tcase SQRT:\n+\t  return 0;\n+\n+\tdefault:\n+\t  abort ();\n+\t}\n+\n+      x = CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n+      set_float_handler (NULL_PTR);\n+      return x;\n+    }\n+\n+  else if (GET_CODE (op) == CONST_DOUBLE\n+\t   && GET_MODE_CLASS (GET_MODE (op)) == MODE_FLOAT\n+\t   && GET_MODE_CLASS (mode) == MODE_INT\n+\t   && width <= HOST_BITS_PER_WIDE_INT && width > 0)\n+    {\n+      REAL_VALUE_TYPE d;\n+      jmp_buf handler;\n+      HOST_WIDE_INT val;\n+\n+      if (setjmp (handler))\n+\treturn 0;\n+\n+      set_float_handler (handler);\n+\n+      REAL_VALUE_FROM_CONST_DOUBLE (d, op);\n+\n+      switch (code)\n+\t{\n+\tcase FIX:\n+\t  val = REAL_VALUE_FIX (d);\n+\t  break;\n+\n+\tcase UNSIGNED_FIX:\n+\t  val = REAL_VALUE_UNSIGNED_FIX (d);\n+\t  break;\n+\n+\tdefault:\n+\t  abort ();\n+\t}\n+\n+      set_float_handler (NULL_PTR);\n+\n+      val = trunc_int_for_mode (val, mode);\n+\n+      return GEN_INT (val);\n+    }\n+#endif\n+  /* This was formerly used only for non-IEEE float.\n+     eggert@twinsun.com says it is safe for IEEE also.  */\n+  else\n+    {\n+      /* There are some simplifications we can do even if the operands\n+\t aren't constant.  */\n+      switch (code)\n+\t{\n+\tcase NEG:\n+\tcase NOT:\n+\t  /* (not (not X)) == X, similarly for NEG.  */\n+\t  if (GET_CODE (op) == code)\n+\t    return XEXP (op, 0);\n+\t  break;\n+\n+\tcase SIGN_EXTEND:\n+\t  /* (sign_extend (truncate (minus (label_ref L1) (label_ref L2))))\n+\t     becomes just the MINUS if its mode is MODE.  This allows\n+\t     folding switch statements on machines using casesi (such as\n+\t     the Vax).  */\n+\t  if (GET_CODE (op) == TRUNCATE\n+\t      && GET_MODE (XEXP (op, 0)) == mode\n+\t      && GET_CODE (XEXP (op, 0)) == MINUS\n+\t      && GET_CODE (XEXP (XEXP (op, 0), 0)) == LABEL_REF\n+\t      && GET_CODE (XEXP (XEXP (op, 0), 1)) == LABEL_REF)\n+\t    return XEXP (op, 0);\n+\n+#ifdef POINTERS_EXTEND_UNSIGNED\n+\t  if (! POINTERS_EXTEND_UNSIGNED\n+\t      && mode == Pmode && GET_MODE (op) == ptr_mode\n+\t      && CONSTANT_P (op))\n+\t    return convert_memory_address (Pmode, op);\n+#endif\n+\t  break;\n+\n+#ifdef POINTERS_EXTEND_UNSIGNED\n+\tcase ZERO_EXTEND:\n+\t  if (POINTERS_EXTEND_UNSIGNED\n+\t      && mode == Pmode && GET_MODE (op) == ptr_mode\n+\t      && CONSTANT_P (op))\n+\t    return convert_memory_address (Pmode, op);\n+\t  break;\n+#endif\n+\t  \n+\tdefault:\n+\t  break;\n+\t}\n+\n+      return 0;\n+    }\n+}\n+\f\n+/* Simplify a binary operation CODE with result mode MODE, operating on OP0\n+   and OP1.  Return 0 if no simplification is possible.\n+\n+   Don't use this for relational operations such as EQ or LT.\n+   Use simplify_relational_operation instead.  */\n+\n+rtx\n+simplify_binary_operation (code, mode, op0, op1)\n+     enum rtx_code code;\n+     enum machine_mode mode;\n+     rtx op0, op1;\n+{\n+  register HOST_WIDE_INT arg0, arg1, arg0s, arg1s;\n+  HOST_WIDE_INT val;\n+  int width = GET_MODE_BITSIZE (mode);\n+  rtx tem;\n+\n+  /* Relational operations don't work here.  We must know the mode\n+     of the operands in order to do the comparison correctly.\n+     Assuming a full word can give incorrect results.\n+     Consider comparing 128 with -128 in QImode.  */\n+\n+  if (GET_RTX_CLASS (code) == '<')\n+    abort ();\n+\n+#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n+  if (GET_MODE_CLASS (mode) == MODE_FLOAT\n+      && GET_CODE (op0) == CONST_DOUBLE && GET_CODE (op1) == CONST_DOUBLE\n+      && mode == GET_MODE (op0) && mode == GET_MODE (op1))\n+    {\n+      REAL_VALUE_TYPE f0, f1, value;\n+      jmp_buf handler;\n+\n+      if (setjmp (handler))\n+\treturn 0;\n+\n+      set_float_handler (handler);\n+\n+      REAL_VALUE_FROM_CONST_DOUBLE (f0, op0);\n+      REAL_VALUE_FROM_CONST_DOUBLE (f1, op1);\n+      f0 = real_value_truncate (mode, f0);\n+      f1 = real_value_truncate (mode, f1);\n+\n+#ifdef REAL_ARITHMETIC\n+#ifndef REAL_INFINITY\n+      if (code == DIV && REAL_VALUES_EQUAL (f1, dconst0))\n+\treturn 0;\n+#endif\n+      REAL_ARITHMETIC (value, rtx_to_tree_code (code), f0, f1);\n+#else\n+      switch (code)\n+\t{\n+\tcase PLUS:\n+\t  value = f0 + f1;\n+\t  break;\n+\tcase MINUS:\n+\t  value = f0 - f1;\n+\t  break;\n+\tcase MULT:\n+\t  value = f0 * f1;\n+\t  break;\n+\tcase DIV:\n+#ifndef REAL_INFINITY\n+\t  if (f1 == 0)\n+\t    return 0;\n+#endif\n+\t  value = f0 / f1;\n+\t  break;\n+\tcase SMIN:\n+\t  value = MIN (f0, f1);\n+\t  break;\n+\tcase SMAX:\n+\t  value = MAX (f0, f1);\n+\t  break;\n+\tdefault:\n+\t  abort ();\n+\t}\n+#endif\n+\n+      value = real_value_truncate (mode, value);\n+      set_float_handler (NULL_PTR);\n+      return CONST_DOUBLE_FROM_REAL_VALUE (value, mode);\n+    }\n+#endif  /* not REAL_IS_NOT_DOUBLE, or REAL_ARITHMETIC */\n+\n+  /* We can fold some multi-word operations.  */\n+  if (GET_MODE_CLASS (mode) == MODE_INT\n+      && width == HOST_BITS_PER_WIDE_INT * 2\n+      && (GET_CODE (op0) == CONST_DOUBLE || GET_CODE (op0) == CONST_INT)\n+      && (GET_CODE (op1) == CONST_DOUBLE || GET_CODE (op1) == CONST_INT))\n+    {\n+      HOST_WIDE_INT l1, l2, h1, h2, lv, hv;\n+\n+      if (GET_CODE (op0) == CONST_DOUBLE)\n+\tl1 = CONST_DOUBLE_LOW (op0), h1 = CONST_DOUBLE_HIGH (op0);\n+      else\n+\tl1 = INTVAL (op0), h1 = l1 < 0 ? -1 : 0;\n+\n+      if (GET_CODE (op1) == CONST_DOUBLE)\n+\tl2 = CONST_DOUBLE_LOW (op1), h2 = CONST_DOUBLE_HIGH (op1);\n+      else\n+\tl2 = INTVAL (op1), h2 = l2 < 0 ? -1 : 0;\n+\n+      switch (code)\n+\t{\n+\tcase MINUS:\n+\t  /* A - B == A + (-B).  */\n+\t  neg_double (l2, h2, &lv, &hv);\n+\t  l2 = lv, h2 = hv;\n+\n+\t  /* .. fall through ...  */\n+\n+\tcase PLUS:\n+\t  add_double (l1, h1, l2, h2, &lv, &hv);\n+\t  break;\n+\n+\tcase MULT:\n+\t  mul_double (l1, h1, l2, h2, &lv, &hv);\n+\t  break;\n+\n+\tcase DIV:  case MOD:   case UDIV:  case UMOD:\n+\t  /* We'd need to include tree.h to do this and it doesn't seem worth\n+\t     it.  */\n+\t  return 0;\n+\n+\tcase AND:\n+\t  lv = l1 & l2, hv = h1 & h2;\n+\t  break;\n+\n+\tcase IOR:\n+\t  lv = l1 | l2, hv = h1 | h2;\n+\t  break;\n+\n+\tcase XOR:\n+\t  lv = l1 ^ l2, hv = h1 ^ h2;\n+\t  break;\n+\n+\tcase SMIN:\n+\t  if (h1 < h2\n+\t      || (h1 == h2\n+\t\t  && ((unsigned HOST_WIDE_INT) l1\n+\t\t      < (unsigned HOST_WIDE_INT) l2)))\n+\t    lv = l1, hv = h1;\n+\t  else\n+\t    lv = l2, hv = h2;\n+\t  break;\n+\n+\tcase SMAX:\n+\t  if (h1 > h2\n+\t      || (h1 == h2\n+\t\t  && ((unsigned HOST_WIDE_INT) l1\n+\t\t      > (unsigned HOST_WIDE_INT) l2)))\n+\t    lv = l1, hv = h1;\n+\t  else\n+\t    lv = l2, hv = h2;\n+\t  break;\n+\n+\tcase UMIN:\n+\t  if ((unsigned HOST_WIDE_INT) h1 < (unsigned HOST_WIDE_INT) h2\n+\t      || (h1 == h2\n+\t\t  && ((unsigned HOST_WIDE_INT) l1\n+\t\t      < (unsigned HOST_WIDE_INT) l2)))\n+\t    lv = l1, hv = h1;\n+\t  else\n+\t    lv = l2, hv = h2;\n+\t  break;\n+\n+\tcase UMAX:\n+\t  if ((unsigned HOST_WIDE_INT) h1 > (unsigned HOST_WIDE_INT) h2\n+\t      || (h1 == h2\n+\t\t  && ((unsigned HOST_WIDE_INT) l1\n+\t\t      > (unsigned HOST_WIDE_INT) l2)))\n+\t    lv = l1, hv = h1;\n+\t  else\n+\t    lv = l2, hv = h2;\n+\t  break;\n+\n+\tcase LSHIFTRT:   case ASHIFTRT:\n+\tcase ASHIFT:\n+\tcase ROTATE:     case ROTATERT:\n+#ifdef SHIFT_COUNT_TRUNCATED\n+\t  if (SHIFT_COUNT_TRUNCATED)\n+\t    l2 &= (GET_MODE_BITSIZE (mode) - 1), h2 = 0;\n+#endif\n+\n+\t  if (h2 != 0 || l2 < 0 || l2 >= GET_MODE_BITSIZE (mode))\n+\t    return 0;\n+\n+\t  if (code == LSHIFTRT || code == ASHIFTRT)\n+\t    rshift_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv,\n+\t\t\t   code == ASHIFTRT);\n+\t  else if (code == ASHIFT)\n+\t    lshift_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv, 1);\n+\t  else if (code == ROTATE)\n+\t    lrotate_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv);\n+\t  else /* code == ROTATERT */\n+\t    rrotate_double (l1, h1, l2, GET_MODE_BITSIZE (mode), &lv, &hv);\n+\t  break;\n+\n+\tdefault:\n+\t  return 0;\n+\t}\n+\n+      return immed_double_const (lv, hv, mode);\n+    }\n+\n+  if (GET_CODE (op0) != CONST_INT || GET_CODE (op1) != CONST_INT\n+      || width > HOST_BITS_PER_WIDE_INT || width == 0)\n+    {\n+      /* Even if we can't compute a constant result,\n+\t there are some cases worth simplifying.  */\n+\n+      switch (code)\n+\t{\n+\tcase PLUS:\n+\t  /* In IEEE floating point, x+0 is not the same as x.  Similarly\n+\t     for the other optimizations below.  */\n+\t  if (TARGET_FLOAT_FORMAT == IEEE_FLOAT_FORMAT\n+\t      && FLOAT_MODE_P (mode) && ! flag_fast_math)\n+\t    break;\n+\n+\t  if (op1 == CONST0_RTX (mode))\n+\t    return op0;\n+\n+\t  /* ((-a) + b) -> (b - a) and similarly for (a + (-b)) */\n+\t  if (GET_CODE (op0) == NEG)\n+\t    return simplify_gen_binary (MINUS, mode, op1, XEXP (op0, 0));\n+\t  else if (GET_CODE (op1) == NEG)\n+\t    return simplify_gen_binary (MINUS, mode, op0, XEXP (op1, 0));\n+\n+\t  /* Handle both-operands-constant cases.  We can only add\n+\t     CONST_INTs to constants since the sum of relocatable symbols\n+\t     can't be handled by most assemblers.  Don't add CONST_INT\n+\t     to CONST_INT since overflow won't be computed properly if wider\n+\t     than HOST_BITS_PER_WIDE_INT.  */\n+\n+\t  if (CONSTANT_P (op0) && GET_MODE (op0) != VOIDmode\n+\t      && GET_CODE (op1) == CONST_INT)\n+\t    return plus_constant (op0, INTVAL (op1));\n+\t  else if (CONSTANT_P (op1) && GET_MODE (op1) != VOIDmode\n+\t\t   && GET_CODE (op0) == CONST_INT)\n+\t    return plus_constant (op1, INTVAL (op0));\n+\n+\t  /* See if this is something like X * C - X or vice versa or\n+\t     if the multiplication is written as a shift.  If so, we can\n+\t     distribute and make a new multiply, shift, or maybe just\n+\t     have X (if C is 2 in the example above).  But don't make\n+\t     real multiply if we didn't have one before.  */\n+\n+\t  if (! FLOAT_MODE_P (mode))\n+\t    {\n+\t      HOST_WIDE_INT coeff0 = 1, coeff1 = 1;\n+\t      rtx lhs = op0, rhs = op1;\n+\t      int had_mult = 0;\n+\n+\t      if (GET_CODE (lhs) == NEG)\n+\t\tcoeff0 = -1, lhs = XEXP (lhs, 0);\n+\t      else if (GET_CODE (lhs) == MULT\n+\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT)\n+\t\t{\n+\t\t  coeff0 = INTVAL (XEXP (lhs, 1)), lhs = XEXP (lhs, 0);\n+\t\t  had_mult = 1;\n+\t\t}\n+\t      else if (GET_CODE (lhs) == ASHIFT\n+\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT\n+\t\t       && INTVAL (XEXP (lhs, 1)) >= 0\n+\t\t       && INTVAL (XEXP (lhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t{\n+\t\t  coeff0 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (lhs, 1));\n+\t\t  lhs = XEXP (lhs, 0);\n+\t\t}\n+\n+\t      if (GET_CODE (rhs) == NEG)\n+\t\tcoeff1 = -1, rhs = XEXP (rhs, 0);\n+\t      else if (GET_CODE (rhs) == MULT\n+\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT)\n+\t\t{\n+\t\t  coeff1 = INTVAL (XEXP (rhs, 1)), rhs = XEXP (rhs, 0);\n+\t\t  had_mult = 1;\n+\t\t}\n+\t      else if (GET_CODE (rhs) == ASHIFT\n+\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT\n+\t\t       && INTVAL (XEXP (rhs, 1)) >= 0\n+\t\t       && INTVAL (XEXP (rhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t{\n+\t\t  coeff1 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (rhs, 1));\n+\t\t  rhs = XEXP (rhs, 0);\n+\t\t}\n+\n+\t      if (rtx_equal_p (lhs, rhs))\n+\t\t{\n+\t\t  tem = simplify_gen_binary (MULT, mode, lhs,\n+\t\t\t\t\tGEN_INT (coeff0 + coeff1));\n+\t\t  return (GET_CODE (tem) == MULT && ! had_mult) ? 0 : tem;\n+\t\t}\n+\t    }\n+\n+\t  /* If one of the operands is a PLUS or a MINUS, see if we can\n+\t     simplify this by the associative law. \n+\t     Don't use the associative law for floating point.\n+\t     The inaccuracy makes it nonassociative,\n+\t     and subtle programs can break if operations are associated.  */\n+\n+\t  if (INTEGRAL_MODE_P (mode)\n+\t      && (GET_CODE (op0) == PLUS || GET_CODE (op0) == MINUS\n+\t\t  || GET_CODE (op1) == PLUS || GET_CODE (op1) == MINUS)\n+\t      && (tem = simplify_plus_minus (code, mode, op0, op1)) != 0)\n+\t    return tem;\n+\t  break;\n+\n+\tcase COMPARE:\n+#ifdef HAVE_cc0\n+\t  /* Convert (compare FOO (const_int 0)) to FOO unless we aren't\n+\t     using cc0, in which case we want to leave it as a COMPARE\n+\t     so we can distinguish it from a register-register-copy.\n+\n+\t     In IEEE floating point, x-0 is not the same as x.  */\n+\n+\t  if ((TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n+\t       || ! FLOAT_MODE_P (mode) || flag_fast_math)\n+\t      && op1 == CONST0_RTX (mode))\n+\t    return op0;\n+#else\n+\t  /* Do nothing here.  */\n+#endif\n+\t  break;\n+\t      \n+\tcase MINUS:\n+\t  /* None of these optimizations can be done for IEEE\n+\t     floating point.  */\n+\t  if (TARGET_FLOAT_FORMAT == IEEE_FLOAT_FORMAT\n+\t      && FLOAT_MODE_P (mode) && ! flag_fast_math)\n+\t    break;\n+\n+\t  /* We can't assume x-x is 0 even with non-IEEE floating point,\n+\t     but since it is zero except in very strange circumstances, we\n+\t     will treat it as zero with -ffast-math.  */\n+\t  if (rtx_equal_p (op0, op1)\n+\t      && ! side_effects_p (op0)\n+\t      && (! FLOAT_MODE_P (mode) || flag_fast_math))\n+\t    return CONST0_RTX (mode);\n+\n+\t  /* Change subtraction from zero into negation.  */\n+\t  if (op0 == CONST0_RTX (mode))\n+\t    return gen_rtx_NEG (mode, op1);\n+\n+\t  /* (-1 - a) is ~a.  */\n+\t  if (op0 == constm1_rtx)\n+\t    return gen_rtx_NOT (mode, op1);\n+\n+\t  /* Subtracting 0 has no effect.  */\n+\t  if (op1 == CONST0_RTX (mode))\n+\t    return op0;\n+\n+\t  /* See if this is something like X * C - X or vice versa or\n+\t     if the multiplication is written as a shift.  If so, we can\n+\t     distribute and make a new multiply, shift, or maybe just\n+\t     have X (if C is 2 in the example above).  But don't make\n+\t     real multiply if we didn't have one before.  */\n+\n+\t  if (! FLOAT_MODE_P (mode))\n+\t    {\n+\t      HOST_WIDE_INT coeff0 = 1, coeff1 = 1;\n+\t      rtx lhs = op0, rhs = op1;\n+\t      int had_mult = 0;\n+\n+\t      if (GET_CODE (lhs) == NEG)\n+\t\tcoeff0 = -1, lhs = XEXP (lhs, 0);\n+\t      else if (GET_CODE (lhs) == MULT\n+\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT)\n+\t\t{\n+\t\t  coeff0 = INTVAL (XEXP (lhs, 1)), lhs = XEXP (lhs, 0);\n+\t\t  had_mult = 1;\n+\t\t}\n+\t      else if (GET_CODE (lhs) == ASHIFT\n+\t\t       && GET_CODE (XEXP (lhs, 1)) == CONST_INT\n+\t\t       && INTVAL (XEXP (lhs, 1)) >= 0\n+\t\t       && INTVAL (XEXP (lhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t{\n+\t\t  coeff0 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (lhs, 1));\n+\t\t  lhs = XEXP (lhs, 0);\n+\t\t}\n+\n+\t      if (GET_CODE (rhs) == NEG)\n+\t\tcoeff1 = - 1, rhs = XEXP (rhs, 0);\n+\t      else if (GET_CODE (rhs) == MULT\n+\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT)\n+\t\t{\n+\t\t  coeff1 = INTVAL (XEXP (rhs, 1)), rhs = XEXP (rhs, 0);\n+\t\t  had_mult = 1;\n+\t\t}\n+\t      else if (GET_CODE (rhs) == ASHIFT\n+\t\t       && GET_CODE (XEXP (rhs, 1)) == CONST_INT\n+\t\t       && INTVAL (XEXP (rhs, 1)) >= 0\n+\t\t       && INTVAL (XEXP (rhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t{\n+\t\t  coeff1 = ((HOST_WIDE_INT) 1) << INTVAL (XEXP (rhs, 1));\n+\t\t  rhs = XEXP (rhs, 0);\n+\t\t}\n+\n+\t      if (rtx_equal_p (lhs, rhs))\n+\t\t{\n+\t\t  tem = simplify_gen_binary (MULT, mode, lhs,\n+\t\t\t\t\t     GEN_INT (coeff0 - coeff1));\n+\t\t  return (GET_CODE (tem) == MULT && ! had_mult) ? 0 : tem;\n+\t\t}\n+\t    }\n+\n+\t  /* (a - (-b)) -> (a + b).  */\n+\t  if (GET_CODE (op1) == NEG)\n+\t    return simplify_gen_binary (PLUS, mode, op0, XEXP (op1, 0));\n+\n+\t  /* If one of the operands is a PLUS or a MINUS, see if we can\n+\t     simplify this by the associative law. \n+\t     Don't use the associative law for floating point.\n+\t     The inaccuracy makes it nonassociative,\n+\t     and subtle programs can break if operations are associated.  */\n+\n+\t  if (INTEGRAL_MODE_P (mode)\n+\t      && (GET_CODE (op0) == PLUS || GET_CODE (op0) == MINUS\n+\t\t  || GET_CODE (op1) == PLUS || GET_CODE (op1) == MINUS)\n+\t      && (tem = simplify_plus_minus (code, mode, op0, op1)) != 0)\n+\t    return tem;\n+\n+\t  /* Don't let a relocatable value get a negative coeff.  */\n+\t  if (GET_CODE (op1) == CONST_INT && GET_MODE (op0) != VOIDmode)\n+\t    return plus_constant (op0, - INTVAL (op1));\n+\n+\t  /* (x - (x & y)) -> (x & ~y) */\n+\t  if (GET_CODE (op1) == AND)\n+\t    {\n+\t     if (rtx_equal_p (op0, XEXP (op1, 0)))\n+\t       return simplify_gen_binary (AND, mode, op0,\n+\t\t\t\t\t   gen_rtx_NOT (mode, XEXP (op1, 1)));\n+\t     if (rtx_equal_p (op0, XEXP (op1, 1)))\n+\t       return simplify_gen_binary (AND, mode, op0,\n+\t\t\t\t\t   gen_rtx_NOT (mode, XEXP (op1, 0)));\n+\t   }\n+\t  break;\n+\n+\tcase MULT:\n+\t  if (op1 == constm1_rtx)\n+\t    {\n+\t      tem = simplify_unary_operation (NEG, mode, op0, mode);\n+\n+\t      return tem ? tem : gen_rtx_NEG (mode, op0);\n+\t    }\n+\n+\t  /* In IEEE floating point, x*0 is not always 0.  */\n+\t  if ((TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n+\t       || ! FLOAT_MODE_P (mode) || flag_fast_math)\n+\t      && op1 == CONST0_RTX (mode)\n+\t      && ! side_effects_p (op0))\n+\t    return op1;\n+\n+\t  /* In IEEE floating point, x*1 is not equivalent to x for nans.\n+\t     However, ANSI says we can drop signals,\n+\t     so we can do this anyway.  */\n+\t  if (op1 == CONST1_RTX (mode))\n+\t    return op0;\n+\n+\t  /* Convert multiply by constant power of two into shift unless\n+\t     we are still generating RTL.  This test is a kludge.  */\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && (val = exact_log2 (INTVAL (op1))) >= 0\n+\t      /* If the mode is larger than the host word size, and the\n+\t\t uppermost bit is set, then this isn't a power of two due\n+\t\t to implicit sign extension.  */\n+\t      && (width <= HOST_BITS_PER_WIDE_INT\n+\t\t  || val != HOST_BITS_PER_WIDE_INT - 1)\n+\t      && ! rtx_equal_function_value_matters)\n+\t    return gen_rtx_ASHIFT (mode, op0, GEN_INT (val));\n+\n+\t  if (GET_CODE (op1) == CONST_DOUBLE\n+\t      && GET_MODE_CLASS (GET_MODE (op1)) == MODE_FLOAT)\n+\t    {\n+\t      REAL_VALUE_TYPE d;\n+\t      jmp_buf handler;\n+\t      int op1is2, op1ism1;\n+\n+\t      if (setjmp (handler))\n+\t\treturn 0;\n+\n+\t      set_float_handler (handler);\n+\t      REAL_VALUE_FROM_CONST_DOUBLE (d, op1);\n+\t      op1is2 = REAL_VALUES_EQUAL (d, dconst2);\n+\t      op1ism1 = REAL_VALUES_EQUAL (d, dconstm1);\n+\t      set_float_handler (NULL_PTR);\n+\n+\t      /* x*2 is x+x and x*(-1) is -x */\n+\t      if (op1is2 && GET_MODE (op0) == mode)\n+\t\treturn gen_rtx_PLUS (mode, op0, copy_rtx (op0));\n+\n+\t      else if (op1ism1 && GET_MODE (op0) == mode)\n+\t\treturn gen_rtx_NEG (mode, op0);\n+\t    }\n+\t  break;\n+\n+\tcase IOR:\n+\t  if (op1 == const0_rtx)\n+\t    return op0;\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && (INTVAL (op1) & GET_MODE_MASK (mode)) == GET_MODE_MASK (mode))\n+\t    return op1;\n+\t  if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n+\t    return op0;\n+\t  /* A | (~A) -> -1 */\n+\t  if (((GET_CODE (op0) == NOT && rtx_equal_p (XEXP (op0, 0), op1))\n+\t       || (GET_CODE (op1) == NOT && rtx_equal_p (XEXP (op1, 0), op0)))\n+\t      && ! side_effects_p (op0)\n+\t      && GET_MODE_CLASS (mode) != MODE_CC)\n+\t    return constm1_rtx;\n+\t  break;\n+\n+\tcase XOR:\n+\t  if (op1 == const0_rtx)\n+\t    return op0;\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && (INTVAL (op1) & GET_MODE_MASK (mode)) == GET_MODE_MASK (mode))\n+\t    return gen_rtx_NOT (mode, op0);\n+\t  if (op0 == op1 && ! side_effects_p (op0)\n+\t      && GET_MODE_CLASS (mode) != MODE_CC)\n+\t    return const0_rtx;\n+\t  break;\n+\n+\tcase AND:\n+\t  if (op1 == const0_rtx && ! side_effects_p (op0))\n+\t    return const0_rtx;\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && (INTVAL (op1) & GET_MODE_MASK (mode)) == GET_MODE_MASK (mode))\n+\t    return op0;\n+\t  if (op0 == op1 && ! side_effects_p (op0)\n+\t      && GET_MODE_CLASS (mode) != MODE_CC)\n+\t    return op0;\n+\t  /* A & (~A) -> 0 */\n+\t  if (((GET_CODE (op0) == NOT && rtx_equal_p (XEXP (op0, 0), op1))\n+\t       || (GET_CODE (op1) == NOT && rtx_equal_p (XEXP (op1, 0), op0)))\n+\t      && ! side_effects_p (op0)\n+\t      && GET_MODE_CLASS (mode) != MODE_CC)\n+\t    return const0_rtx;\n+\t  break;\n+\n+\tcase UDIV:\n+\t  /* Convert divide by power of two into shift (divide by 1 handled\n+\t     below).  */\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && (arg1 = exact_log2 (INTVAL (op1))) > 0)\n+\t    return gen_rtx_LSHIFTRT (mode, op0, GEN_INT (arg1));\n+\n+\t  /* ... fall through ...  */\n+\n+\tcase DIV:\n+\t  if (op1 == CONST1_RTX (mode))\n+\t    return op0;\n+\n+\t  /* In IEEE floating point, 0/x is not always 0.  */\n+\t  if ((TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n+\t       || ! FLOAT_MODE_P (mode) || flag_fast_math)\n+\t      && op0 == CONST0_RTX (mode)\n+\t      && ! side_effects_p (op1))\n+\t    return op0;\n+\n+#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n+\t  /* Change division by a constant into multiplication.  Only do\n+\t     this with -ffast-math until an expert says it is safe in\n+\t     general.  */\n+\t  else if (GET_CODE (op1) == CONST_DOUBLE\n+\t\t   && GET_MODE_CLASS (GET_MODE (op1)) == MODE_FLOAT\n+\t\t   && op1 != CONST0_RTX (mode)\n+\t\t   && flag_fast_math)\n+\t    {\n+\t      REAL_VALUE_TYPE d;\n+\t      REAL_VALUE_FROM_CONST_DOUBLE (d, op1);\n+\n+\t      if (! REAL_VALUES_EQUAL (d, dconst0))\n+\t\t{\n+#if defined (REAL_ARITHMETIC)\n+\t\t  REAL_ARITHMETIC (d, rtx_to_tree_code (DIV), dconst1, d);\n+\t\t  return gen_rtx_MULT (mode, op0, \n+\t\t\t\t       CONST_DOUBLE_FROM_REAL_VALUE (d, mode));\n+#else\n+\t\t  return\n+\t\t    gen_rtx_MULT (mode, op0, \n+\t\t\t\t  CONST_DOUBLE_FROM_REAL_VALUE (1./d, mode));\n+#endif\n+\t\t}\n+\t    }\n+#endif\n+\t  break;\n+\n+\tcase UMOD:\n+\t  /* Handle modulus by power of two (mod with 1 handled below).  */\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && exact_log2 (INTVAL (op1)) > 0)\n+\t    return gen_rtx_AND (mode, op0, GEN_INT (INTVAL (op1) - 1));\n+\n+\t  /* ... fall through ...  */\n+\n+\tcase MOD:\n+\t  if ((op0 == const0_rtx || op1 == const1_rtx)\n+\t      && ! side_effects_p (op0) && ! side_effects_p (op1))\n+\t    return const0_rtx;\n+\t  break;\n+\n+\tcase ROTATERT:\n+\tcase ROTATE:\n+\t  /* Rotating ~0 always results in ~0.  */\n+\t  if (GET_CODE (op0) == CONST_INT && width <= HOST_BITS_PER_WIDE_INT\n+\t      && (unsigned HOST_WIDE_INT) INTVAL (op0) == GET_MODE_MASK (mode)\n+\t      && ! side_effects_p (op1))\n+\t    return op0;\n+\n+\t  /* ... fall through ...  */\n+\n+\tcase ASHIFT:\n+\tcase ASHIFTRT:\n+\tcase LSHIFTRT:\n+\t  if (op1 == const0_rtx)\n+\t    return op0;\n+\t  if (op0 == const0_rtx && ! side_effects_p (op1))\n+\t    return op0;\n+\t  break;\n+\n+\tcase SMIN:\n+\t  if (width <= HOST_BITS_PER_WIDE_INT && GET_CODE (op1) == CONST_INT \n+\t      && INTVAL (op1) == (HOST_WIDE_INT) 1 << (width -1)\n+\t      && ! side_effects_p (op0))\n+\t    return op1;\n+\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n+\t    return op0;\n+\t  break;\n+\t   \n+\tcase SMAX:\n+\t  if (width <= HOST_BITS_PER_WIDE_INT && GET_CODE (op1) == CONST_INT\n+\t      && ((unsigned HOST_WIDE_INT) INTVAL (op1)\n+\t\t  == (unsigned HOST_WIDE_INT) GET_MODE_MASK (mode) >> 1)\n+\t      && ! side_effects_p (op0))\n+\t    return op1;\n+\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n+\t    return op0;\n+\t  break;\n+\n+\tcase UMIN:\n+\t  if (op1 == const0_rtx && ! side_effects_p (op0))\n+\t    return op1;\n+\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n+\t    return op0;\n+\t  break;\n+\t    \n+\tcase UMAX:\n+\t  if (op1 == constm1_rtx && ! side_effects_p (op0))\n+\t    return op1;\n+\t  else if (rtx_equal_p (op0, op1) && ! side_effects_p (op0))\n+\t    return op0;\n+\t  break;\n+\n+\tdefault:\n+\t  abort ();\n+\t}\n+      \n+      return 0;\n+    }\n+\n+  /* Get the integer argument values in two forms:\n+     zero-extended in ARG0, ARG1 and sign-extended in ARG0S, ARG1S.  */\n+\n+  arg0 = INTVAL (op0);\n+  arg1 = INTVAL (op1);\n+\n+  if (width < HOST_BITS_PER_WIDE_INT)\n+    {\n+      arg0 &= ((HOST_WIDE_INT) 1 << width) - 1;\n+      arg1 &= ((HOST_WIDE_INT) 1 << width) - 1;\n+\n+      arg0s = arg0;\n+      if (arg0s & ((HOST_WIDE_INT) 1 << (width - 1)))\n+\targ0s |= ((HOST_WIDE_INT) (-1) << width);\n+\n+      arg1s = arg1;\n+      if (arg1s & ((HOST_WIDE_INT) 1 << (width - 1)))\n+\targ1s |= ((HOST_WIDE_INT) (-1) << width);\n+    }\n+  else\n+    {\n+      arg0s = arg0;\n+      arg1s = arg1;\n+    }\n+\n+  /* Compute the value of the arithmetic.  */\n+\n+  switch (code)\n+    {\n+    case PLUS:\n+      val = arg0s + arg1s;\n+      break;\n+\n+    case MINUS:\n+      val = arg0s - arg1s;\n+      break;\n+\n+    case MULT:\n+      val = arg0s * arg1s;\n+      break;\n+\n+    case DIV:\n+      if (arg1s == 0)\n+\treturn 0;\n+      val = arg0s / arg1s;\n+      break;\n+\n+    case MOD:\n+      if (arg1s == 0)\n+\treturn 0;\n+      val = arg0s % arg1s;\n+      break;\n+\n+    case UDIV:\n+      if (arg1 == 0)\n+\treturn 0;\n+      val = (unsigned HOST_WIDE_INT) arg0 / arg1;\n+      break;\n+\n+    case UMOD:\n+      if (arg1 == 0)\n+\treturn 0;\n+      val = (unsigned HOST_WIDE_INT) arg0 % arg1;\n+      break;\n+\n+    case AND:\n+      val = arg0 & arg1;\n+      break;\n+\n+    case IOR:\n+      val = arg0 | arg1;\n+      break;\n+\n+    case XOR:\n+      val = arg0 ^ arg1;\n+      break;\n+\n+    case LSHIFTRT:\n+      /* If shift count is undefined, don't fold it; let the machine do\n+\t what it wants.  But truncate it if the machine will do that.  */\n+      if (arg1 < 0)\n+\treturn 0;\n+\n+#ifdef SHIFT_COUNT_TRUNCATED\n+      if (SHIFT_COUNT_TRUNCATED)\n+\targ1 %= width;\n+#endif\n+\n+      val = ((unsigned HOST_WIDE_INT) arg0) >> arg1;\n+      break;\n+\n+    case ASHIFT:\n+      if (arg1 < 0)\n+\treturn 0;\n+\n+#ifdef SHIFT_COUNT_TRUNCATED\n+      if (SHIFT_COUNT_TRUNCATED)\n+\targ1 %= width;\n+#endif\n+\n+      val = ((unsigned HOST_WIDE_INT) arg0) << arg1;\n+      break;\n+\n+    case ASHIFTRT:\n+      if (arg1 < 0)\n+\treturn 0;\n+\n+#ifdef SHIFT_COUNT_TRUNCATED\n+      if (SHIFT_COUNT_TRUNCATED)\n+\targ1 %= width;\n+#endif\n+\n+      val = arg0s >> arg1;\n+\n+      /* Bootstrap compiler may not have sign extended the right shift.\n+\t Manually extend the sign to insure bootstrap cc matches gcc.  */\n+      if (arg0s < 0 && arg1 > 0)\n+\tval |= ((HOST_WIDE_INT) -1) << (HOST_BITS_PER_WIDE_INT - arg1);\n+\n+      break;\n+\n+    case ROTATERT:\n+      if (arg1 < 0)\n+\treturn 0;\n+\n+      arg1 %= width;\n+      val = ((((unsigned HOST_WIDE_INT) arg0) << (width - arg1))\n+\t     | (((unsigned HOST_WIDE_INT) arg0) >> arg1));\n+      break;\n+\n+    case ROTATE:\n+      if (arg1 < 0)\n+\treturn 0;\n+\n+      arg1 %= width;\n+      val = ((((unsigned HOST_WIDE_INT) arg0) << arg1)\n+\t     | (((unsigned HOST_WIDE_INT) arg0) >> (width - arg1)));\n+      break;\n+\n+    case COMPARE:\n+      /* Do nothing here.  */\n+      return 0;\n+\n+    case SMIN:\n+      val = arg0s <= arg1s ? arg0s : arg1s;\n+      break;\n+\n+    case UMIN:\n+      val = ((unsigned HOST_WIDE_INT) arg0\n+\t     <= (unsigned HOST_WIDE_INT) arg1 ? arg0 : arg1);\n+      break;\n+\n+    case SMAX:\n+      val = arg0s > arg1s ? arg0s : arg1s;\n+      break;\n+\n+    case UMAX:\n+      val = ((unsigned HOST_WIDE_INT) arg0\n+\t     > (unsigned HOST_WIDE_INT) arg1 ? arg0 : arg1);\n+      break;\n+\n+    default:\n+      abort ();\n+    }\n+\n+  val = trunc_int_for_mode (val, mode);\n+\n+  return GEN_INT (val);\n+}\n+\f\n+/* Simplify a PLUS or MINUS, at least one of whose operands may be another\n+   PLUS or MINUS.\n+\n+   Rather than test for specific case, we do this by a brute-force method\n+   and do all possible simplifications until no more changes occur.  Then\n+   we rebuild the operation.  */\n+\n+static rtx\n+simplify_plus_minus (code, mode, op0, op1)\n+     enum rtx_code code;\n+     enum machine_mode mode;\n+     rtx op0, op1;\n+{\n+  rtx ops[8];\n+  int negs[8];\n+  rtx result, tem;\n+  int n_ops = 2, input_ops = 2, input_consts = 0, n_consts = 0;\n+  int first = 1, negate = 0, changed;\n+  int i, j;\n+\n+  bzero ((char *) ops, sizeof ops);\n+  \n+  /* Set up the two operands and then expand them until nothing has been\n+     changed.  If we run out of room in our array, give up; this should\n+     almost never happen.  */\n+\n+  ops[0] = op0, ops[1] = op1, negs[0] = 0, negs[1] = (code == MINUS);\n+\n+  changed = 1;\n+  while (changed)\n+    {\n+      changed = 0;\n+\n+      for (i = 0; i < n_ops; i++)\n+\tswitch (GET_CODE (ops[i]))\n+\t  {\n+\t  case PLUS:\n+\t  case MINUS:\n+\t    if (n_ops == 7)\n+\t      return 0;\n+\n+\t    ops[n_ops] = XEXP (ops[i], 1);\n+\t    negs[n_ops++] = GET_CODE (ops[i]) == MINUS ? !negs[i] : negs[i];\n+\t    ops[i] = XEXP (ops[i], 0);\n+\t    input_ops++;\n+\t    changed = 1;\n+\t    break;\n+\n+\t  case NEG:\n+\t    ops[i] = XEXP (ops[i], 0);\n+\t    negs[i] = ! negs[i];\n+\t    changed = 1;\n+\t    break;\n+\n+\t  case CONST:\n+\t    ops[i] = XEXP (ops[i], 0);\n+\t    input_consts++;\n+\t    changed = 1;\n+\t    break;\n+\n+\t  case NOT:\n+\t    /* ~a -> (-a - 1) */\n+\t    if (n_ops != 7)\n+\t      {\n+\t\tops[n_ops] = constm1_rtx;\n+\t\tnegs[n_ops++] = negs[i];\n+\t\tops[i] = XEXP (ops[i], 0);\n+\t\tnegs[i] = ! negs[i];\n+\t\tchanged = 1;\n+\t      }\n+\t    break;\n+\n+\t  case CONST_INT:\n+\t    if (negs[i])\n+\t      ops[i] = GEN_INT (- INTVAL (ops[i])), negs[i] = 0, changed = 1;\n+\t    break;\n+\n+\t  default:\n+\t    break;\n+\t  }\n+    }\n+\n+  /* If we only have two operands, we can't do anything.  */\n+  if (n_ops <= 2)\n+    return 0;\n+\n+  /* Now simplify each pair of operands until nothing changes.  The first\n+     time through just simplify constants against each other.  */\n+\n+  changed = 1;\n+  while (changed)\n+    {\n+      changed = first;\n+\n+      for (i = 0; i < n_ops - 1; i++)\n+\tfor (j = i + 1; j < n_ops; j++)\n+\t  if (ops[i] != 0 && ops[j] != 0\n+\t      && (! first || (CONSTANT_P (ops[i]) && CONSTANT_P (ops[j]))))\n+\t    {\n+\t      rtx lhs = ops[i], rhs = ops[j];\n+\t      enum rtx_code ncode = PLUS;\n+\n+\t      if (negs[i] && ! negs[j])\n+\t\tlhs = ops[j], rhs = ops[i], ncode = MINUS;\n+\t      else if (! negs[i] && negs[j])\n+\t\tncode = MINUS;\n+\n+\t      tem = simplify_binary_operation (ncode, mode, lhs, rhs);\n+\t      if (tem)\n+\t\t{\n+\t\t  ops[i] = tem, ops[j] = 0;\n+\t\t  negs[i] = negs[i] && negs[j];\n+\t\t  if (GET_CODE (tem) == NEG)\n+\t\t    ops[i] = XEXP (tem, 0), negs[i] = ! negs[i];\n+\n+\t\t  if (GET_CODE (ops[i]) == CONST_INT && negs[i])\n+\t\t    ops[i] = GEN_INT (- INTVAL (ops[i])), negs[i] = 0;\n+\t\t  changed = 1;\n+\t\t}\n+\t    }\n+\n+      first = 0;\n+    }\n+\n+  /* Pack all the operands to the lower-numbered entries and give up if\n+     we didn't reduce the number of operands we had.  Make sure we\n+     count a CONST as two operands.  If we have the same number of\n+     operands, but have made more CONSTs than we had, this is also\n+     an improvement, so accept it.  */\n+\n+  for (i = 0, j = 0; j < n_ops; j++)\n+    if (ops[j] != 0)\n+      {\n+\tops[i] = ops[j], negs[i++] = negs[j];\n+\tif (GET_CODE (ops[j]) == CONST)\n+\t  n_consts++;\n+      }\n+\n+  if (i + n_consts > input_ops\n+      || (i + n_consts == input_ops && n_consts <= input_consts))\n+    return 0;\n+\n+  n_ops = i;\n+\n+  /* If we have a CONST_INT, put it last.  */\n+  for (i = 0; i < n_ops - 1; i++)\n+    if (GET_CODE (ops[i]) == CONST_INT)\n+      {\n+\ttem = ops[n_ops - 1], ops[n_ops - 1] = ops[i] , ops[i] = tem;\n+\tj = negs[n_ops - 1], negs[n_ops - 1] = negs[i], negs[i] = j;\n+      }\n+\n+  /* Put a non-negated operand first.  If there aren't any, make all\n+     operands positive and negate the whole thing later.  */\n+  for (i = 0; i < n_ops && negs[i]; i++)\n+    ;\n+\n+  if (i == n_ops)\n+    {\n+      for (i = 0; i < n_ops; i++)\n+\tnegs[i] = 0;\n+      negate = 1;\n+    }\n+  else if (i != 0)\n+    {\n+      tem = ops[0], ops[0] = ops[i], ops[i] = tem;\n+      j = negs[0], negs[0] = negs[i], negs[i] = j;\n+    }\n+\n+  /* Now make the result by performing the requested operations.  */\n+  result = ops[0];\n+  for (i = 1; i < n_ops; i++)\n+    result = simplify_gen_binary (negs[i] ? MINUS : PLUS, mode, result, ops[i]);\n+\n+  return negate ? gen_rtx_NEG (mode, result) : result;\n+}\n+\n+struct cfc_args\n+{\n+  /* Input */\n+  rtx op0, op1;\n+  /* Output */\n+  int equal, op0lt, op1lt;\n+};\n+\n+static void\n+check_fold_consts (data)\n+  PTR data;\n+{\n+  struct cfc_args * args = (struct cfc_args *) data;\n+  REAL_VALUE_TYPE d0, d1;\n+\n+  REAL_VALUE_FROM_CONST_DOUBLE (d0, args->op0);\n+  REAL_VALUE_FROM_CONST_DOUBLE (d1, args->op1);\n+  args->equal = REAL_VALUES_EQUAL (d0, d1);\n+  args->op0lt = REAL_VALUES_LESS (d0, d1);\n+  args->op1lt = REAL_VALUES_LESS (d1, d0);\n+}\n+\n+/* Like simplify_binary_operation except used for relational operators.\n+   MODE is the mode of the operands, not that of the result.  If MODE\n+   is VOIDmode, both operands must also be VOIDmode and we compare the\n+   operands in \"infinite precision\".\n+\n+   If no simplification is possible, this function returns zero.  Otherwise,\n+   it returns either const_true_rtx or const0_rtx.  */\n+\n+rtx\n+simplify_relational_operation (code, mode, op0, op1)\n+     enum rtx_code code;\n+     enum machine_mode mode;\n+     rtx op0, op1;\n+{\n+  int equal, op0lt, op0ltu, op1lt, op1ltu;\n+  rtx tem;\n+\n+  /* If op0 is a compare, extract the comparison arguments from it.  */\n+  if (GET_CODE (op0) == COMPARE && op1 == const0_rtx)\n+    op1 = XEXP (op0, 1), op0 = XEXP (op0, 0);\n+\n+  /* We can't simplify MODE_CC values since we don't know what the\n+     actual comparison is.  */\n+  if (GET_MODE_CLASS (GET_MODE (op0)) == MODE_CC\n+#ifdef HAVE_cc0\n+      || op0 == cc0_rtx\n+#endif\n+      )\n+    return 0;\n+\n+  /* For integer comparisons of A and B maybe we can simplify A - B and can\n+     then simplify a comparison of that with zero.  If A and B are both either\n+     a register or a CONST_INT, this can't help; testing for these cases will\n+     prevent infinite recursion here and speed things up.\n+\n+     If CODE is an unsigned comparison, then we can never do this optimization,\n+     because it gives an incorrect result if the subtraction wraps around zero.\n+     ANSI C defines unsigned operations such that they never overflow, and\n+     thus such cases can not be ignored.  */\n+\n+  if (INTEGRAL_MODE_P (mode) && op1 != const0_rtx\n+      && ! ((GET_CODE (op0) == REG || GET_CODE (op0) == CONST_INT)\n+\t    && (GET_CODE (op1) == REG || GET_CODE (op1) == CONST_INT))\n+      && 0 != (tem = simplify_binary_operation (MINUS, mode, op0, op1))\n+      && code != GTU && code != GEU && code != LTU && code != LEU)\n+    return simplify_relational_operation (signed_condition (code),\n+\t\t\t\t\t  mode, tem, const0_rtx);\n+\n+  /* For non-IEEE floating-point, if the two operands are equal, we know the\n+     result.  */\n+  if (rtx_equal_p (op0, op1)\n+      && (TARGET_FLOAT_FORMAT != IEEE_FLOAT_FORMAT\n+\t  || ! FLOAT_MODE_P (GET_MODE (op0)) || flag_fast_math))\n+    equal = 1, op0lt = 0, op0ltu = 0, op1lt = 0, op1ltu = 0;\n+\n+  /* If the operands are floating-point constants, see if we can fold\n+     the result.  */\n+#if ! defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)\n+  else if (GET_CODE (op0) == CONST_DOUBLE && GET_CODE (op1) == CONST_DOUBLE\n+\t   && GET_MODE_CLASS (GET_MODE (op0)) == MODE_FLOAT)\n+    {\n+      struct cfc_args args;\n+\n+      /* Setup input for check_fold_consts() */\n+      args.op0 = op0;\n+      args.op1 = op1;\n+      \n+      if (do_float_handler(check_fold_consts, (PTR) &args) == 0)\n+\t/* We got an exception from check_fold_consts() */\n+\treturn 0;\n+\n+      /* Receive output from check_fold_consts() */\n+      equal = args.equal;\n+      op0lt = op0ltu = args.op0lt;\n+      op1lt = op1ltu = args.op1lt;\n+    }\n+#endif  /* not REAL_IS_NOT_DOUBLE, or REAL_ARITHMETIC */\n+\n+  /* Otherwise, see if the operands are both integers.  */\n+  else if ((GET_MODE_CLASS (mode) == MODE_INT || mode == VOIDmode)\n+\t   && (GET_CODE (op0) == CONST_DOUBLE || GET_CODE (op0) == CONST_INT)\n+\t   && (GET_CODE (op1) == CONST_DOUBLE || GET_CODE (op1) == CONST_INT))\n+    {\n+      int width = GET_MODE_BITSIZE (mode);\n+      HOST_WIDE_INT l0s, h0s, l1s, h1s;\n+      unsigned HOST_WIDE_INT l0u, h0u, l1u, h1u;\n+\n+      /* Get the two words comprising each integer constant.  */\n+      if (GET_CODE (op0) == CONST_DOUBLE)\n+\t{\n+\t  l0u = l0s = CONST_DOUBLE_LOW (op0);\n+\t  h0u = h0s = CONST_DOUBLE_HIGH (op0);\n+\t}\n+      else\n+\t{\n+\t  l0u = l0s = INTVAL (op0);\n+\t  h0u = h0s = l0s < 0 ? -1 : 0;\n+\t}\n+\t  \n+      if (GET_CODE (op1) == CONST_DOUBLE)\n+\t{\n+\t  l1u = l1s = CONST_DOUBLE_LOW (op1);\n+\t  h1u = h1s = CONST_DOUBLE_HIGH (op1);\n+\t}\n+      else\n+\t{\n+\t  l1u = l1s = INTVAL (op1);\n+\t  h1u = h1s = l1s < 0 ? -1 : 0;\n+\t}\n+\n+      /* If WIDTH is nonzero and smaller than HOST_BITS_PER_WIDE_INT,\n+\t we have to sign or zero-extend the values.  */\n+      if (width != 0 && width <= HOST_BITS_PER_WIDE_INT)\n+\th0u = h1u = 0, h0s = l0s < 0 ? -1 : 0, h1s = l1s < 0 ? -1 : 0;\n+\n+      if (width != 0 && width < HOST_BITS_PER_WIDE_INT)\n+\t{\n+\t  l0u &= ((HOST_WIDE_INT) 1 << width) - 1;\n+\t  l1u &= ((HOST_WIDE_INT) 1 << width) - 1;\n+\n+\t  if (l0s & ((HOST_WIDE_INT) 1 << (width - 1)))\n+\t    l0s |= ((HOST_WIDE_INT) (-1) << width);\n+\n+\t  if (l1s & ((HOST_WIDE_INT) 1 << (width - 1)))\n+\t    l1s |= ((HOST_WIDE_INT) (-1) << width);\n+\t}\n+\n+      equal = (h0u == h1u && l0u == l1u);\n+      op0lt = (h0s < h1s || (h0s == h1s && l0s < l1s));\n+      op1lt = (h1s < h0s || (h1s == h0s && l1s < l0s));\n+      op0ltu = (h0u < h1u || (h0u == h1u && l0u < l1u));\n+      op1ltu = (h1u < h0u || (h1u == h0u && l1u < l0u));\n+    }\n+\n+  /* Otherwise, there are some code-specific tests we can make.  */\n+  else\n+    {\n+      switch (code)\n+\t{\n+\tcase EQ:\n+\t  /* References to the frame plus a constant or labels cannot\n+\t     be zero, but a SYMBOL_REF can due to #pragma weak.  */\n+\t  if (((NONZERO_BASE_PLUS_P (op0) && op1 == const0_rtx)\n+\t       || GET_CODE (op0) == LABEL_REF)\n+#if FRAME_POINTER_REGNUM != ARG_POINTER_REGNUM\n+\t      /* On some machines, the ap reg can be 0 sometimes.  */\n+\t      && op0 != arg_pointer_rtx\n+#endif\n+\t\t)\n+\t    return const0_rtx;\n+\t  break;\n+\n+\tcase NE:\n+\t  if (((NONZERO_BASE_PLUS_P (op0) && op1 == const0_rtx)\n+\t       || GET_CODE (op0) == LABEL_REF)\n+#if FRAME_POINTER_REGNUM != ARG_POINTER_REGNUM\n+\t      && op0 != arg_pointer_rtx\n+#endif\n+\t      )\n+\t    return const_true_rtx;\n+\t  break;\n+\n+\tcase GEU:\n+\t  /* Unsigned values are never negative.  */\n+\t  if (op1 == const0_rtx)\n+\t    return const_true_rtx;\n+\t  break;\n+\n+\tcase LTU:\n+\t  if (op1 == const0_rtx)\n+\t    return const0_rtx;\n+\t  break;\n+\n+\tcase LEU:\n+\t  /* Unsigned values are never greater than the largest\n+\t     unsigned value.  */\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && (unsigned HOST_WIDE_INT) INTVAL (op1) == GET_MODE_MASK (mode)\n+\t    && INTEGRAL_MODE_P (mode))\n+\t  return const_true_rtx;\n+\t  break;\n+\n+\tcase GTU:\n+\t  if (GET_CODE (op1) == CONST_INT\n+\t      && (unsigned HOST_WIDE_INT) INTVAL (op1) == GET_MODE_MASK (mode)\n+\t      && INTEGRAL_MODE_P (mode))\n+\t    return const0_rtx;\n+\t  break;\n+\t  \n+\tdefault:\n+\t  break;\n+\t}\n+\n+      return 0;\n+    }\n+\n+  /* If we reach here, EQUAL, OP0LT, OP0LTU, OP1LT, and OP1LTU are set\n+     as appropriate.  */\n+  switch (code)\n+    {\n+    case EQ:\n+      return equal ? const_true_rtx : const0_rtx;\n+    case NE:\n+      return ! equal ? const_true_rtx : const0_rtx;\n+    case LT:\n+      return op0lt ? const_true_rtx : const0_rtx;\n+    case GT:\n+      return op1lt ? const_true_rtx : const0_rtx;\n+    case LTU:\n+      return op0ltu ? const_true_rtx : const0_rtx;\n+    case GTU:\n+      return op1ltu ? const_true_rtx : const0_rtx;\n+    case LE:\n+      return equal || op0lt ? const_true_rtx : const0_rtx;\n+    case GE:\n+      return equal || op1lt ? const_true_rtx : const0_rtx;\n+    case LEU:\n+      return equal || op0ltu ? const_true_rtx : const0_rtx;\n+    case GEU:\n+      return equal || op1ltu ? const_true_rtx : const0_rtx;\n+    default:\n+      abort ();\n+    }\n+}\n+\f\n+/* Simplify CODE, an operation with result mode MODE and three operands,\n+   OP0, OP1, and OP2.  OP0_MODE was the mode of OP0 before it became\n+   a constant.  Return 0 if no simplifications is possible.  */\n+\n+rtx\n+simplify_ternary_operation (code, mode, op0_mode, op0, op1, op2)\n+     enum rtx_code code;\n+     enum machine_mode mode, op0_mode;\n+     rtx op0, op1, op2;\n+{\n+  int width = GET_MODE_BITSIZE (mode);\n+\n+  /* VOIDmode means \"infinite\" precision.  */\n+  if (width == 0)\n+    width = HOST_BITS_PER_WIDE_INT;\n+\n+  switch (code)\n+    {\n+    case SIGN_EXTRACT:\n+    case ZERO_EXTRACT:\n+      if (GET_CODE (op0) == CONST_INT\n+\t  && GET_CODE (op1) == CONST_INT\n+\t  && GET_CODE (op2) == CONST_INT\n+\t  && INTVAL (op1) + INTVAL (op2) <= GET_MODE_BITSIZE (op0_mode)\n+\t  && width <= HOST_BITS_PER_WIDE_INT)\n+\t{\n+\t  /* Extracting a bit-field from a constant */\n+\t  HOST_WIDE_INT val = INTVAL (op0);\n+\n+\t  if (BITS_BIG_ENDIAN)\n+\t    val >>= (GET_MODE_BITSIZE (op0_mode)\n+\t\t     - INTVAL (op2) - INTVAL (op1));\n+\t  else\n+\t    val >>= INTVAL (op2);\n+\n+\t  if (HOST_BITS_PER_WIDE_INT != INTVAL (op1))\n+\t    {\n+\t      /* First zero-extend.  */\n+\t      val &= ((HOST_WIDE_INT) 1 << INTVAL (op1)) - 1;\n+\t      /* If desired, propagate sign bit.  */\n+\t      if (code == SIGN_EXTRACT\n+\t\t  && (val & ((HOST_WIDE_INT) 1 << (INTVAL (op1) - 1))))\n+\t\tval |= ~ (((HOST_WIDE_INT) 1 << INTVAL (op1)) - 1);\n+\t    }\n+\n+\t  /* Clear the bits that don't belong in our mode,\n+\t     unless they and our sign bit are all one.\n+\t     So we get either a reasonable negative value or a reasonable\n+\t     unsigned value for this mode.  */\n+\t  if (width < HOST_BITS_PER_WIDE_INT\n+\t      && ((val & ((HOST_WIDE_INT) (-1) << (width - 1)))\n+\t\t  != ((HOST_WIDE_INT) (-1) << (width - 1))))\n+\t    val &= ((HOST_WIDE_INT) 1 << width) - 1;\n+\n+\t  return GEN_INT (val);\n+\t}\n+      break;\n+\n+    case IF_THEN_ELSE:\n+      if (GET_CODE (op0) == CONST_INT)\n+\treturn op0 != const0_rtx ? op1 : op2;\n+\n+      /* Convert a == b ? b : a to \"a\".  */\n+      if (GET_CODE (op0) == NE && ! side_effects_p (op0)\n+\t  && rtx_equal_p (XEXP (op0, 0), op1)\n+\t  && rtx_equal_p (XEXP (op0, 1), op2))\n+\treturn op1;\n+      else if (GET_CODE (op0) == EQ && ! side_effects_p (op0)\n+\t  && rtx_equal_p (XEXP (op0, 1), op1)\n+\t  && rtx_equal_p (XEXP (op0, 0), op2))\n+\treturn op2;\n+      else if (GET_RTX_CLASS (GET_CODE (op0)) == '<' && ! side_effects_p (op0))\n+\t{\n+\t  rtx temp;\n+\t  temp = simplify_relational_operation (GET_CODE (op0), op0_mode,\n+\t\t\t\t\t\tXEXP (op0, 0), XEXP (op0, 1));\n+\t  /* See if any simplifications were possible.  */\n+\t  if (temp == const0_rtx)\n+\t    return op2;\n+\t  else if (temp == const1_rtx)\n+\t    return op1;\n+\t}\n+      break;\n+\n+    default:\n+      abort ();\n+    }\n+\n+  return 0;\n+}\n+\n+/* Simplify X, an rtx expression.\n+\n+   Return the simplified expression or NULL if no simplifications\n+   were possible.\n+\n+   This is the preferred entry point into the simplification routines;\n+   however, we still allow passes to call the more specific routines.\n+\n+   Right now GCC has three (yes, three) major bodies of RTL simplficiation\n+   code that need to be unified.\n+\n+\t1. fold_rtx in cse.c.  This code uses various CSE specific\n+\t   information to aid in RTL simplification.\n+\n+\t2. simplify_rtx in combine.c.  Similar to fold_rtx, except that\n+\t   it uses combine specific information to aid in RTL\n+\t   simplification.\n+\n+\t3. The routines in this file.\n+\n+\n+   Long term we want to only have one body of simplification code; to\n+   get to that state I recommend the following steps:\n+\n+\t1. Pour over fold_rtx & simplify_rtx and move any simplifications\n+\t   which are not pass dependent state into these routines.\n+\n+\t2. As code is moved by #1, change fold_rtx & simplify_rtx to\n+\t   use this routine whenever possible.\n+\n+\t3. Allow for pass dependent state to be provided to these\n+\t   routines and add simplifications based on the pass dependent\n+\t   state.  Remove code from cse.c & combine.c that becomes\n+\t   redundant/dead.\n+\n+    It will take time, but ultimately the compiler will be easier to\n+    maintain and improve.  It's totally silly that when we add a\n+    simplification that it needs to be added to 4 places (3 for RTL\n+    simplification and 1 for tree simplification.  */\n+\t   \n+rtx\n+simplify_rtx (x)\n+     rtx x;\n+{\n+  enum rtx_code code;\n+  enum machine_mode mode;\n+  rtx new;\n+\n+  mode = GET_MODE (x);\n+  code = GET_CODE (x);\n+\n+  switch (GET_RTX_CLASS (code))\n+    {\n+    case '1':\n+      return simplify_unary_operation (code, mode,\n+\t\t\t\t       XEXP (x, 0), GET_MODE (XEXP (x, 0)));\n+    case '2':\n+    case 'c':\n+      return simplify_binary_operation (code, mode, XEXP (x, 0), XEXP (x, 1));\n+\n+    case '3':\n+    case 'b':\n+      return simplify_ternary_operation (code, mode, GET_MODE (XEXP (x, 0)),\n+\t\t\t\t\t XEXP (x, 0), XEXP (x, 1), XEXP (x, 2));\n+\n+    case '<':\n+      return simplify_relational_operation (code, GET_MODE (XEXP (x, 0)),\n+\t\t\t\t\t    XEXP (x, 0), XEXP (x, 1));\n+    default:\n+      return NULL;\n+    }\n+}"}]}