{"sha": "93002327db5e5f466de60dc3f8c876cf9a56e183", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTMwMDIzMjdkYjVlNWY0NjZkZTYwZGMzZjhjODc2Y2Y5YTU2ZTE4Mw==", "commit": {"author": {"name": "Bryce McKinlay", "email": "bryce@gcc.gnu.org", "date": "2000-04-19T10:10:01Z"}, "committer": {"name": "Bryce McKinlay", "email": "bryce@gcc.gnu.org", "date": "2000-04-19T10:10:01Z"}, "message": "Imported version version 5.0alpha6.\n\n\t* acinclude.m4: Bump version to 5.0a6.\n\t* configure.in: Don't use alpha_mach_dep.s.\n\t* include/private/config.h, irix_threads.c gc_watcom.asm: Delete\n\tobsolete files.\n\nFrom-SVN: r33251", "tree": {"sha": "fec69f60b37ca7ee4a47582f914dabbc7b3ee0c4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/fec69f60b37ca7ee4a47582f914dabbc7b3ee0c4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/93002327db5e5f466de60dc3f8c876cf9a56e183", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/93002327db5e5f466de60dc3f8c876cf9a56e183", "html_url": "https://github.com/Rust-GCC/gccrs/commit/93002327db5e5f466de60dc3f8c876cf9a56e183", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/93002327db5e5f466de60dc3f8c876cf9a56e183/comments", "author": null, "committer": null, "parents": [{"sha": "5e787f078df8900b34981443e9f968fd5c3b039c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5e787f078df8900b34981443e9f968fd5c3b039c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5e787f078df8900b34981443e9f968fd5c3b039c"}], "stats": {"total": 3641, "additions": 1480, "deletions": 2161}, "files": [{"sha": "6831e8dfb444f0320816b3065a4cc1be4d8ebafe", "filename": "boehm-gc/ChangeLog", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2FChangeLog?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -1,3 +1,11 @@\n+2000-04-19  Bryce McKinlay  <bryce@albatross.co.nz>\n+\n+\tImported version version 5.0alpha6.\n+\t* acinclude.m4: Bump version to 5.0a6.\n+\t* configure.in: Don't use alpha_mach_dep.s.\n+\t* include/private/config.h, irix_threads.c gc_watcom.asm: Delete \n+\tobsolete files.\n+\n 2000-03-26  Anthony Green  <green@redhat.com>\n \n \t* misc.c (GC_enable): Always define GC_enable and GC_disable.\n@@ -105,7 +113,7 @@ Fri Jan 28 17:13:20 2000  Anthony Green  <green@cygnus.com>\n \n Tue Aug 10 00:08:29 1999  Rainer Orth  <ro@TechFak.Uni-Bielefeld.DE>\n \n-\t* gc_priv.h: Merged IRIX thread changes from\n+\t* gc_priv.h:  IRIX thread changes from\n \tinclude/private/gc_priv.h.\n \n Mon Aug  9 18:33:38 1999  Rainer Orth  <ro@TechFak.Uni-Bielefeld.DE>"}, {"sha": "f800ee46322be6fa0a8049dbede9185abc468db3", "filename": "boehm-gc/README", "status": "modified", "additions": 59, "deletions": 2, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2FREADME?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -15,7 +15,7 @@ Permission to modify the code and to distribute modified code is granted,\n provided the above notices are retained, and a notice that the code was\n modified is included with the above copyright notice.\n \n-This is version 5.0alpha4 of a conservative garbage collector for C and C++.\n+This is version 5.0alpha6 of a conservative garbage collector for C and C++.\n \n You might find a more recent version of this at\n \n@@ -1506,10 +1506,11 @@ Since 5.0 alpha3\n    Henderson and Roman Hodek.\n  - Removed the tests for SGI_SOURCE in new_gc_alloc.h.  This was causing that\n    interface to fail on nonSGI platforms.\n- - Changed the Linux stack finding code to use /proc, after chnging it\n+ - Changed the Linux stack finding code to use /proc, after changing it\n    to use HEURISTIC1.  (Thanks to David Mossberger for pointing out the\n    /proc hook.)\n  - Added HP/UX incremental GC support and HP/UX 11 thread support.\n+   Thread support is currently still flakey.\n  - Added basic Linux/IA64 support.\n  - Integrated Anthony Green's PicoJava support.\n  - Integrated Scott Ananian's StrongARM/NetBSD support.\n@@ -1527,6 +1528,58 @@ Since 5.0 alpha3\n  - GC_debug_free(0, ...) failed.  Thanks to Fergus Henderson for the\n    bug report and fix.\n \n+Since 5.0 alpha4\n+ - GC_malloc_explicitly_typed and friends sometimes failed to\n+   initialize first word.\n+ - Added allocation routines and support in the marker for mark descriptors\n+   in a type structure referenced by the first word of an object.  This was\n+   introduced to support gcj, but hopefully in a way that makes it\n+   generically useful.\n+ - Added GC_requested_heapsize, and inhibited collections in nonincremental\n+   mode if the actual used heap size is less than what was explicitly\n+   requested.\n+ - The Solaris pthreads version of GC_pthread_create didn't handle a NULL\n+   attribute pointer.  Solaris thread support used the wrong default thread\n+   stack size.  (Thanks to Melissa O'Neill for the patch.)\n+ - Changed PUSH_CONTENTS macro to no longer modify first parameter.\n+   This usually doesn't matter, but it was certainly an accident waiting\n+   to happen ...\n+ - Added GC_register_finalizer_no_order and friends to gc.h.  They're\n+   needed by Java implementations.\n+ - Integrated a fix for a win32 deadlock resulting from clock() calling\n+   malloc.  (Thanks to Chris Dodd.)\n+ - Integrated Hiroshi Kawashima's port to Linux/MIPS.  This was designed\n+   for a handheld platform, and may or may not be sufficient for other\n+   machines.\n+ - Fixed a va_arg problem with the %c specifier in cordprnt.c.  It appears\n+   that this was always broken, but recent versions of gcc are the first to\n+   report the (statically detectable) bug.\n+ - Added an attempt at a more general solution to dlopen races/deadlocks.\n+   GC_dlopen now temporarily disables collection.  Still not ideal, but ...\n+ - Added -DUSE_I686_PREFETCH, -DUSE_3DNOW_PREFETCH, and support for IA64\n+   prefetch instructions.  May improve performance measurably, but I'm not\n+   sure the code will run correctly on processors that don't support the\n+   instruction.  Won't build except with very recent gcc.\n+ - Added caching for header lookups in the marker.  This seems to result\n+   in a barely measurable performance gain.  Added support for interleaved\n+   lookups of two pointers, but unconfigured that since the performance\n+   gain is currently near zero, and it adds to code size.\n+ - Changed Linux DATA_START definition to check both data_start and\n+   __data_start, since nothing else seems to be portable.\n+ - Added -DUSE_LD_WRAP to optionally take advantage of the GNU ld function\n+   wrapping mechanism.  Probably currently useful only on Linux.\n+ - Moved some variables for the scratch allocator into GC_arrays, on\n+   Martin Hirzel's suggestion.\n+ - Fixed a win32 threads bug that caused the collector to not look for\n+   interior pointers from one of the thread stacks without\n+   ALL_INTERIOR_POINTERS.  (Thanks to Jeff Sturm.)\n+ - Added Mingw32 support.  (Thanks again to Jeff Sturm for the patch.)\n+ - Changed the alpha port to use the generic register scanning code instead\n+   of alpha_mach_dep.s.  Alpha_mach_dep.s doesn't look for pointers in fp\n+   registers, but gcc sometimes spills pointers there.  (Thanks to Manuel Serrano\n+   for helping me debug this by email.)  Changed the IA64 code to do something\n+   similar for similar reasons.\n+\n To do:\n  - Very large root set sizes (> 16 MB or so) could cause the collector\n    to abort with an unexpected mark stack overflow.  (Thanks again to\n@@ -1543,3 +1596,7 @@ To do:\n  - Incremental collector should handle large objects better.  Currently,\n    it looks like the whole object is treated as dirty if any part of it\n    is.\n+ - Cord/cordprnt.c doesn't build on a few platforms (notably PowerPC), since\n+   we make some unwarranted assumptions about how varargs are handled.  This\n+   currently makes the cord-aware versions of printf unusable on some platforms.\n+   Fixing this is unfortunately not trivial."}, {"sha": "f4dd65676aae5472806217081aae77aa1dd52ec7", "filename": "boehm-gc/README.debugging", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME.debugging", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME.debugging", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2FREADME.debugging?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -40,7 +40,8 @@ void * big_realloc(void *p, size_t new_size)\n 1) Consider using GC_malloc_atomic for objects containing nonpointers.  This is especially important for large arrays containg compressed data, pseudo-random numbers, and the like.  (This isn't all that likely to solve your problem, but it's a useful and easy optimization anyway, and this is a good time to try it.)   If you allocate large objects containg only one or two pointers at the beginning, either try the typed allocation primitives is gc.h, or separate out the pointerfree component.\n 2) If you are using the collector in its default mode, with interior pointer recognition enabled, consider using GC_malloc_ignore_off_page to allocate large objects.  (See gc.h and above for details.  Large means > 100K in most environments.)\n 3) GC_print_block_list() will print a list of all currently allocated heap blocks and what size objects they contain.  GC_print_hblkfreelist() will print a list of free heap blocks, and whether they are blacklisted.  GC_dump calls both of these, and also prints information about heap sections, and root segments.\n-4) Write a tool that traces back references to the appropriate root.  Send me the code.  (I have code that does this for old PCR.)\n+4) Build the collector with -DKEEP_BACK_PTRS, and use the backptr.h\n+interface to determine why objects are being retained.\n \n \n ****If the collector appears to be losing objects:\n@@ -54,5 +55,14 @@ void * big_realloc(void *p, size_t new_size)\n 6) \"print *GC_find_header(p)\" in dbx or gdb will print the garbage collector block header information associated with the object p (e.g. object size, etc.)\n 7) GC_is_marked(p) determines whether p is the base address of a marked object.  Note that objects allocated since the last collection should not be marked, and that unmarked objects are reclaimed incrementally.  It's usually most interesting to set a breakpoint in GC_finish_collection and then to determine how much of the damaged data structure is marked at that point.\n 8) Look at the tracing facility in mark.c.  (Ignore this suggestion unless you are very familiar with collector internals.)\n+9) [From Melissa O'Neill:]\n+If you're using multiple threads, double check that all thread\n+creation goes through the GC_ wrapper functions rather than\n+calling the thread-creation functions themselves (e.g.,\n+GC_pthread_create rather than pthread_create).  The gc.h header\n+file includes suitable preprocessor definitions to accomplish\n+this mapping transparently -- the question is: are you including\n+it in all the modules that create threads?\n+\n \n "}, {"sha": "e35e712ef95fbffc25f918a59261576d8287435c", "filename": "boehm-gc/README.linux", "status": "modified", "additions": 24, "deletions": 6, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME.linux", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME.linux", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2FREADME.linux?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -31,20 +31,38 @@ To use threads, you need to abide by the following requirements:\n 2) You must compile the collector with -DLINUX_THREADS and -D_REENTRANT\n    specified in the Makefile.\n \n-3) Every file that makes thread calls should define LINUX_THREADS and \n+3a) Every file that makes thread calls should define LINUX_THREADS and \n    _REENTRANT and then include gc.h.  Gc.h redefines some of the\n    pthread primitives as macros which also provide the collector with\n    information it requires.\n \n-4) Currently dlopen() is probably not safe.  The collector must traverse\n-   the list of libraries maintained by the runtime loader.  That can\n-   probably be an inconsistent state when a thread calling the loader is\n-   is stopped for GC.  (It's possible that this is fixable in the\n-   same way it is handled for SOLARIS_THREADS, with GC_dlopen.)\n+3b) A new alternative to (3a) is to build the collector with\n+   -DUSE_LD_WRAP, and to link the final program with\n+\n+   (for ld) --wrap read --wrap dlopen --wrap pthread_create \\\n+\t    --wrap pthread_join --wrap pthread_sigmask\n+\n+   (for gcc) -Wl,--wrap -Wl,read -Wl,--wrap -Wl,dlopen -Wl,--wrap \\\n+\t     -Wl,pthread_create -Wl,--wrap -Wl,pthread_join -Wl,--wrap \\\n+\t     -Wl,pthread_sigmask\n+\n+   In any case, _REENTRANT should be defined during compilation.\n+\n+4) Dlopen() disables collection during its execution.  (It can't run\n+   concurrently with the collector, since the collector looks at its\n+   data structures.  It can't acquire the allocator lock, since arbitrary\n+   user startup code may run as part of dlopen().)  Under unusual\n+   conditions, this may cause unexpected heap growth.\n \n 5) The combination of LINUX_THREADS, REDIRECT_MALLOC, and incremental\n    collection fails in seemingly random places.  This hasn't been tracked\n    down yet, but is perhaps not completely astonishing.  The thread package\n    uses malloc, and thus can presumably get SIGSEGVs while inside the\n    package.  There is no real guarantee that signals are handled properly\n    at that point.\n+\n+6) Thread local storage may not be viewed as part of the root set by the\n+   collector.  This probably depends on the linuxthreads version.  For the\n+   time being, any collectable memory referenced by thread local storage should\n+   also be referenced from elsewhere, or be allocated as uncollectable.\n+   (This is really a bug that should be fixed somehow.)"}, {"sha": "cb15e30a19c5db1177d1793f2a316b63d3d281d2", "filename": "boehm-gc/README.solaris2", "status": "modified", "additions": 4, "deletions": 7, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME.solaris2", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2FREADME.solaris2", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2FREADME.solaris2?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -37,13 +37,10 @@ a thread stack.  If you know that you will only be running Solaris2.5\n or later, it should be possible to fix this by compiling the collector\n with -DSOLARIS23_MPROTECT_BUG_FIXED.\n \n-Jeremy Fitzhardinge points out that there is a problem with the dlopen\n-replacement, in that startup code in the library is run while the allocation\n-lock is held.  This appears to be difficult to fix, since the collector does\n-look at data structures maintained by dlopen, and hence some locking is needed\n-around the dlopen call.  Defining USE_PROC_FOR_LIBRARIES will get address\n-space layout information from /proc avoiding the dlopen lock.  But this has\n-other disadvanatages, e.g. mmapped files may be scanned.\n+Since 5.0 alpha5, dlopen disables collection temporarily,\n+unless USE_PROC_FOR_LIBRARIES is defined.  In some unlikely cases, this\n+can result in unpleasant heap growth.  But it seems better than the\n+race/deadlock issues we had before.\n \n If solaris_threads are used on an X86 processor with malloc redirected to\n GC_malloc, it is necessary to call GC_thr_init explicitly before forking the"}, {"sha": "e413c6ab9df6ceddeb5b96f1a1c477d7e7a039d0", "filename": "boehm-gc/acinclude.m4", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Facinclude.m4", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Facinclude.m4", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Facinclude.m4?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -31,7 +31,7 @@ AC_SUBST(boehm_gc_basedir)\n \n AC_CANONICAL_HOST\n \n-AM_INIT_AUTOMAKE(boehm-gc, 5.0a4, no-define)\n+AM_INIT_AUTOMAKE(boehm-gc, 5.0a6, no-define)\n \n # FIXME: We temporarily define our own version of AC_PROG_CC.  This is\n # copied from autoconf 2.12, but does not call AC_PROG_CC_WORKS.  We"}, {"sha": "6510bcd31337d3dd8bf971aa46fe4261287929e1", "filename": "boehm-gc/aclocal.m4", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Faclocal.m4", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Faclocal.m4", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Faclocal.m4?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -43,7 +43,7 @@ AC_SUBST(boehm_gc_basedir)\n \n AC_CANONICAL_HOST\n \n-AM_INIT_AUTOMAKE(boehm-gc, 5.0a4, no-define)\n+AM_INIT_AUTOMAKE(boehm-gc, 5.0a6, no-define)\n \n # FIXME: We temporarily define our own version of AC_PROG_CC.  This is\n # copied from autoconf 2.12, but does not call AC_PROG_CC_WORKS.  We"}, {"sha": "1505f8e2c713887911cac71b93c6cff9f86ba633", "filename": "boehm-gc/allchblk.c", "status": "modified", "additions": 36, "deletions": 20, "changes": 56, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fallchblk.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fallchblk.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fallchblk.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -19,6 +19,7 @@\n #include <stdio.h>\n #include \"gc_priv.h\"\n \n+GC_bool GC_use_entire_heap = 0;\n \n /*\n  * Free heap blocks are kept on one of several free lists,\n@@ -229,11 +230,15 @@ int n;\n \tGC_ASSERT(HDR(GC_hblkfreelist[index]) == hhdr);\n \tGC_hblkfreelist[index] = hhdr -> hb_next;\n     } else {\n-\tPHDR(hhdr) -> hb_next = hhdr -> hb_next;\n+\thdr *phdr;\n+\tGET_HDR(hhdr -> hb_prev, phdr);\n+\tphdr -> hb_next = hhdr -> hb_next;\n     }\n     if (0 != hhdr -> hb_next) {\n+\thdr * nhdr;\n \tGC_ASSERT(!IS_FORWARDING_ADDR_OR_NIL(NHDR(hhdr)));\n-\tNHDR(hhdr) -> hb_prev = hhdr -> hb_prev;\n+\tGET_HDR(hhdr -> hb_next, nhdr);\n+\tnhdr -> hb_prev = hhdr -> hb_prev;\n     }\n }\n \n@@ -244,13 +249,20 @@ struct hblk * GC_free_block_ending_at(h)\n struct hblk *h;\n {\n     struct hblk * p = h - 1;\n-    hdr * phdr = HDR(p);\n+    hdr * phdr;\n \n+    GET_HDR(p, phdr);\n     while (0 != phdr && IS_FORWARDING_ADDR_OR_NIL(phdr)) {\n \tp = FORWARDED_ADDR(p,phdr);\n \tphdr = HDR(p);\n     }\n-    if (0 != phdr && HBLK_IS_FREE(phdr)) return p;\n+    if (0 != phdr) {\n+        if(HBLK_IS_FREE(phdr)) {\n+\t    return p;\n+\t} else {\n+\t    return 0;\n+\t}\n+    }\n     p = GC_prev_block(h - 1);\n     if (0 != p) {\n       phdr = HDR(p);\n@@ -271,6 +283,7 @@ hdr * hhdr;\n {\n     int index = GC_hblk_fl_from_blocks(divHBLKSZ(hhdr -> hb_sz));\n     struct hblk *second = GC_hblkfreelist[index];\n+    hdr * second_hdr;\n #   ifdef GC_ASSERTIONS\n       struct hblk *next = (struct hblk *)((word)h + hhdr -> hb_sz);\n       hdr * nexthdr = HDR(next);\n@@ -283,7 +296,10 @@ hdr * hhdr;\n     GC_hblkfreelist[index] = h;\n     hhdr -> hb_next = second;\n     hhdr -> hb_prev = 0;\n-    if (0 != second) HDR(second) -> hb_prev = h;\n+    if (0 != second) {\n+      GET_HDR(second, second_hdr);\n+      second_hdr -> hb_prev = h;\n+    }\n     GC_invalidate_map(hhdr);\n }\n \n@@ -330,10 +346,10 @@ void GC_merge_unmapped(void)\n     for (i = 0; i <= N_HBLK_FLS; ++i) {\n       h = GC_hblkfreelist[i];\n       while (h != 0) {\n-\thhdr = HDR(h);\n+\tGET_HDR(h, hhdr);\n \tsize = hhdr->hb_sz;\n \tnext = (struct hblk *)((word)h + size);\n-\tnexthdr = HDR(next);\n+\tGET_HDR(next, nexthdr);\n \t/* Coalesce with successor, if possible */\n \t  if (0 != nexthdr && HBLK_IS_FREE(nexthdr)) {\n \t    nextsize = nexthdr -> hb_sz;\n@@ -398,8 +414,8 @@ int index;\n     GC_remove_from_fl(hhdr, index);\n     if (total_size == bytes) return h;\n     rest = (struct hblk *)((word)h + bytes);\n-    if (!GC_install_header(rest)) return(0);\n-    rest_hdr = HDR(rest);\n+    rest_hdr = GC_install_header(rest);\n+    if (0 == rest_hdr) return(0);\n     rest_hdr -> hb_sz = total_size - bytes;\n     rest_hdr -> hb_flags = 0;\n #   ifdef GC_ASSERTIONS\n@@ -506,16 +522,17 @@ int n;\n \n     /* search for a big enough block in free list */\n \thbp = GC_hblkfreelist[n];\n-\thhdr = HDR(hbp);\n-\tfor(; 0 != hbp; hbp = hhdr -> hb_next, hhdr = HDR(hbp)) {\n+\tfor(; 0 != hbp; hbp = hhdr -> hb_next) {\n+\t    GET_HDR(hbp, hhdr);\n \t    size_avail = hhdr->hb_sz;\n \t    if (size_avail < size_needed) continue;\n-#\t    ifdef PRESERVE_LAST\n+\t    if (!GC_use_entire_heap) {\n \t\tif (size_avail != size_needed\n+\t\t    && USED_HEAP_SIZE >= GC_requested_heapsize\n \t\t    && !GC_incremental && GC_should_collect()) {\n \t\t    continue;\n \t\t} \n-#\t    endif\n+\t    }\n \t    /* If the next heap block is obviously better, go on.\t*/\n \t    /* This prevents us from disassembling a single large block */\n \t    /* to get tiny blocks.\t\t\t\t\t*/\n@@ -524,7 +541,7 @@ int n;\n \t      \n \t      thishbp = hhdr -> hb_next;\n \t      if (thishbp != 0) {\n-\t        thishdr = HDR(thishbp);\n+\t\tGET_HDR(thishbp, thishdr);\n \t        next_size = (signed_word)(thishdr -> hb_sz);\n \t        if (next_size < size_avail\n \t          && next_size >= size_needed\n@@ -551,7 +568,8 @@ int n;\n \t      size_avail -= (ptr_t)lasthbp - (ptr_t)hbp;\n \t      thishbp = lasthbp;\n \t      if (size_avail >= size_needed) {\n-\t        if (thishbp != hbp && GC_install_header(thishbp)) {\n+\t        if (thishbp != hbp &&\n+\t\t    0 != (thishdr = GC_install_header(thishbp))) {\n \t\t  /* Make sure it's mapped before we mangle it. */\n #\t\t    ifdef USE_MUNMAP\n \t\t      if (!IS_MAPPED(hhdr)) {\n@@ -560,7 +578,6 @@ int n;\n \t\t      }\n #\t\t    endif\n \t          /* Split the block at thishbp */\n-\t              thishdr = HDR(thishbp);\n \t\t      GC_split_block(hbp, hhdr, thishbp, thishdr, n);\n \t\t  /* Advance to thishbp */\n \t\t      hbp = thishbp;\n@@ -598,8 +615,7 @@ int n;\n \t\t      GC_large_free_bytes -= total_size;\n \t\t      GC_remove_from_fl(hhdr, n);\n \t              for (h = hbp; h < limit; h++) {\n-\t                if (h == hbp || GC_install_header(h)) {\n-\t                  hhdr = HDR(h);\n+\t                if (h == hbp || 0 != (hhdr = GC_install_header(h))) {\n \t                  (void) setup_header(\n \t                \t  hhdr,\n \t              \t\t  BYTES_TO_WORDS(HBLKSIZE - HDR_BYTES),\n@@ -686,7 +702,7 @@ hdr *hhdr, *prevhdr, *nexthdr;\n signed_word size;\n \n \n-    hhdr = HDR(hbp);\n+    GET_HDR(hbp, hhdr);\n     size = hhdr->hb_sz;\n     size = HBLKSIZE * OBJ_SZ_TO_BLOCKS(size);\n     GC_remove_counts(hbp, (word)size);\n@@ -701,7 +717,7 @@ signed_word size;\n     GC_ASSERT(IS_MAPPED(hhdr));\n     GC_invalidate_map(hhdr);\n     next = (struct hblk *)((word)hbp + size);\n-    nexthdr = HDR(next);\n+    GET_HDR(next, nexthdr);\n     prev = GC_free_block_ending_at(hbp);\n     /* Coalesce with successor, if possible */\n       if(0 != nexthdr && HBLK_IS_FREE(nexthdr) && IS_MAPPED(nexthdr)) {"}, {"sha": "7b923885b96cf35201e105f9d6effc83cc0a6177", "filename": "boehm-gc/alloc.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Falloc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Falloc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Falloc.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -70,8 +70,6 @@ int GC_full_freq = 19;\t   /* Every 20th collection is a full\t*/\n GC_bool GC_need_full_gc = FALSE;\n \t\t\t   /* Need full GC do to heap growth.\t*/\n \n-#define USED_HEAP_SIZE (GC_heapsize - GC_large_free_bytes)\n-\n word GC_used_heap_size_after_full = 0;\n \n char * GC_copyright[] =\n@@ -655,7 +653,8 @@ word bytes;\n     if (GC_n_heap_sects >= MAX_HEAP_SECTS) {\n     \tABORT(\"Too many heap sections: Increase MAXHINCR or MAX_HEAP_SECTS\");\n     }\n-    if (!GC_install_header(p)) {\n+    phdr = GC_install_header(p);\n+    if (0 == phdr) {\n     \t/* This is extremely unlikely. Can't add it.  This will\t\t*/\n     \t/* almost certainly result in a\t0 return from the allocator,\t*/\n     \t/* which is entirely appropriate.\t\t\t\t*/\n@@ -665,7 +664,6 @@ word bytes;\n     GC_heap_sects[GC_n_heap_sects].hs_bytes = bytes;\n     GC_n_heap_sects++;\n     words = BYTES_TO_WORDS(bytes - HDR_BYTES);\n-    phdr = HDR(p);\n     phdr -> hb_sz = words;\n     phdr -> hb_map = (char *)1;   /* A value != GC_invalid_map\t*/\n     phdr -> hb_flags = 0;\n@@ -814,6 +812,7 @@ word n;\n     LOCK();\n     if (!GC_is_initialized) GC_init_inner();\n     result = (int)GC_expand_hp_inner(divHBLKSZ((word)bytes));\n+    if (result) GC_requested_heapsize += bytes;\n     UNLOCK();\n     ENABLE_SIGNALS();\n     return(result);\n@@ -827,7 +826,8 @@ GC_bool GC_collect_or_expand(needed_blocks, ignore_off_page)\n word needed_blocks;\n GC_bool ignore_off_page;\n {\n-    if (!GC_incremental && !GC_dont_gc && GC_should_collect()) {\n+    if (!GC_incremental && !GC_dont_gc &&\n+\t(GC_dont_expand && GC_words_allocd > 0 || GC_should_collect())) {\n       GC_notify_full_gc();\n       GC_gcollect_inner();\n     } else {"}, {"sha": "124de69660145525f34823fb25ceefacc941c937", "filename": "boehm-gc/alpha_mach_dep.s", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Falpha_mach_dep.s", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Falpha_mach_dep.s", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Falpha_mach_dep.s?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -1,4 +1,8 @@\n \n+# This is BROKEN on a 21264 running gcc, and probably in other cases.\n+# The compiler may spill pointers to fp registers, and this code doesn't\n+# scan those.\n+\n # define call_push(x)    \t\t\t\t\t\t\\\n \tlda   $16, 0(x);    \t/* copy x to first argument register */\t\\\n \tjsr   $26, GC_push_one; /* call GC_push_one, ret addr in $26 */\t\\"}, {"sha": "b63d4e8aa860012bf2a6a0c83b2d9e2b4b7d77d1", "filename": "boehm-gc/configure", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fconfigure", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fconfigure", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fconfigure?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -2168,9 +2168,11 @@ esac\n \n machdep=\n case \"$host\" in\n- alpha*-*-*)\n-    machdep=\"alpha_mach_dep.lo\"\n-    ;;\n+# alpha_mach_dep.s assumes that pointers are not saved in fp registers.\n+# Gcc on a 21264 can spill pointers to fp registers.  Oops.\n+# alpha*-*-*)\n+#    machdep=\"alpha_mach_dep.lo\"\n+#    ;;\n  mipstx39-*-elf*)\n     machdep=\"mips_ultrix_mach_dep.lo\"\n     cat >> confdefs.h <<\\EOF"}, {"sha": "5d5e25d03334d703b63bc6c94a47ce3402dce8bd", "filename": "boehm-gc/configure.in", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fconfigure.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fconfigure.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fconfigure.in?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -134,9 +134,11 @@ AC_SUBST(CXXINCLUDES)\n \n machdep=\n case \"$host\" in\n- alpha*-*-*)\n-    machdep=\"alpha_mach_dep.lo\"\n-    ;;\n+# alpha_mach_dep.s assumes that pointers are not saved in fp registers.\n+# Gcc on a 21264 can spill pointers to fp registers.  Oops.\n+# alpha*-*-*)\n+#    machdep=\"alpha_mach_dep.lo\"\n+#    ;;\n  mipstx39-*-elf*)\n     machdep=\"mips_ultrix_mach_dep.lo\"\n     AC_DEFINE(STACKBASE, __stackbase)"}, {"sha": "776dc3f6ee88bb6d4ac4e6f955515611fd3dd851", "filename": "boehm-gc/dbg_mlc.c", "status": "modified", "additions": 35, "deletions": 80, "changes": 115, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fdbg_mlc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fdbg_mlc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdbg_mlc.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -2,6 +2,7 @@\n  * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n  * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n  * Copyright (c) 1997 by Silicon Graphics.  All rights reserved.\n+ * Copyright (c) 1999 by Hewlett-Packard Company.  All rights reserved.\n  *\n  * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n  * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n@@ -12,64 +13,14 @@\n  * provided the above notices are retained, and a notice that the code was\n  * modified is included with the above copyright notice.\n  */\n-# define I_HIDE_POINTERS\n-# include \"gc_priv.h\"\n-# ifdef KEEP_BACK_PTRS\n-#   include \"backptr.h\"\n-# endif\n+\n+#include \"dbg_mlc.h\"\n \n void GC_default_print_heap_obj_proc();\n GC_API void GC_register_finalizer_no_order\n     \tGC_PROTO((GC_PTR obj, GC_finalization_proc fn, GC_PTR cd,\n \t\t  GC_finalization_proc *ofn, GC_PTR *ocd));\n \n-/* Do we want to and know how to save the call stack at the time of\t*/\n-/* an allocation?  How much space do we want to use in each object?\t*/\n-\n-# define START_FLAG ((word)0xfedcedcb)\n-# define END_FLAG ((word)0xbcdecdef)\n-\t/* Stored both one past the end of user object, and one before\t*/\n-\t/* the end of the object as seen by the allocator.\t\t*/\n-\n-\n-/* Object header */\n-typedef struct {\n-#   ifdef KEEP_BACK_PTRS\n-\tptr_t oh_back_ptr;\n-#\tdefine MARKED_FOR_FINALIZATION (ptr_t)(-1)\n-\t    /* Object was marked because it is finalizable. */\n-#\tifdef ALIGN_DOUBLE\n-\t  word oh_dummy;\n-#\tendif\n-#   endif\n-    char * oh_string;\t\t/* object descriptor string\t*/\n-    word oh_int;\t\t/* object descriptor integers\t*/\n-#   ifdef NEED_CALLINFO\n-      struct callinfo oh_ci[NFRAMES];\n-#   endif\n-    word oh_sz;\t\t\t/* Original malloc arg.\t\t*/\n-    word oh_sf;\t\t\t/* start flag */\n-} oh;\n-/* The size of the above structure is assumed not to dealign things,\t*/\n-/* and to be a multiple of the word length.\t\t\t\t*/\n-\n-#define DEBUG_BYTES (sizeof (oh) + sizeof (word))\n-#undef ROUNDED_UP_WORDS\n-#define ROUNDED_UP_WORDS(n) BYTES_TO_WORDS((n) + WORDS_TO_BYTES(1) - 1)\n-\n-\n-#ifdef SAVE_CALL_CHAIN\n-#   define ADD_CALL_CHAIN(base, ra) GC_save_callers(((oh *)(base)) -> oh_ci)\n-#   define PRINT_CALL_CHAIN(base) GC_print_callers(((oh *)(base)) -> oh_ci)\n-#else\n-# ifdef GC_ADD_CALLER\n-#   define ADD_CALL_CHAIN(base, ra) ((oh *)(base)) -> oh_ci[0].ci_pc = (ra)\n-#   define PRINT_CALL_CHAIN(base) GC_print_callers(((oh *)(base)) -> oh_ci)\n-# else\n-#   define ADD_CALL_CHAIN(base, ra)\n-#   define PRINT_CALL_CHAIN(base)\n-# endif\n-#endif\n \n /* Check whether object with base pointer p has debugging info\t*/ \n /* p is assumed to point to a legitimate object in our part\t*/\n@@ -116,7 +67,7 @@ ptr_t p;\n \n   /* Store information about the object referencing dest in *base_p\t*/\n   /* and *offset_p.\t\t\t\t\t\t\t*/\n-  /*   source is root ==> *base_p = 0, *offset_p = address\t\t*/\n+  /*   source is root ==> *base_p = address, *offset_p = 0\t\t*/\n   /*   source is heap object ==> *base_p != 0, *offset_p = offset \t*/\n   /*   Returns 1 on success, 0 if source couldn't be determined.\t*/\n   /* Dest can be any address within a heap object.\t\t\t*/\n@@ -128,6 +79,7 @@ ptr_t p;\n     if (!GC_has_debug_info((ptr_t) hdr)) return GC_NO_SPACE;\n     bp = hdr -> oh_back_ptr;\n     if (MARKED_FOR_FINALIZATION == bp) return GC_FINALIZER_REFD;\n+    if (MARKED_FROM_REGISTER == bp) return GC_REFD_FROM_REG;\n     if (0 == bp) return GC_UNREFERENCED;\n     bp = REVEAL_POINTER(bp);\n     bp_base = GC_base(bp);\n@@ -177,18 +129,15 @@ ptr_t p;\n     }\n   }\n \n-  /* Force a garbage collection and generate a backtrace from a\t*/\n-  /* random heap address.\t\t\t\t\t*/\n-  void GC_generate_random_backtrace(void)\n+  /* Print back trace for p */\n+  void GC_print_backtrace(void *p)\n   {\n-    void * current;\n+    void *current = p;\n     int i;\n-    void * base;\n-    size_t offset;\n     GC_ref_kind source;\n-    GC_gcollect();\n-    current = GC_generate_random_valid_address();\n-    GC_printf1(\"Chose address 0x%lx in object\\n\", (unsigned long)current);\n+    size_t offset;\n+    void *base;\n+\n     GC_print_heap_obj(GC_base(current));\n     GC_err_printf0(\"\\n\");\n     for (i = 0; ; ++i) {\n@@ -207,6 +156,9 @@ ptr_t p;\n \tcase GC_REFD_FROM_ROOT:\n \t  GC_err_printf1(\"root at 0x%lx\\n\", (unsigned long)base);\n \t  goto out;\n+\tcase GC_REFD_FROM_REG:\n+\t  GC_err_printf0(\"root in register\\n\");\n+\t  goto out;\n \tcase GC_FINALIZER_REFD:\n \t  GC_err_printf0(\"list of finalizable objects\\n\");\n \t  goto out;\n@@ -221,6 +173,17 @@ ptr_t p;\n     }\n     out:;\n   }\n+\n+  /* Force a garbage collection and generate a backtrace from a\t*/\n+  /* random heap address.\t\t\t\t\t*/\n+  void GC_generate_random_backtrace(void)\n+  {\n+    void * current;\n+    GC_gcollect();\n+    current = GC_generate_random_valid_address();\n+    GC_printf1(\"Chose address 0x%lx in object\\n\", (unsigned long)current);\n+    GC_print_backtrace(current);\n+  }\n     \n #endif /* KEEP_BACK_PTRS */\n \n@@ -342,16 +305,8 @@ void GC_start_debugging()\n     GC_register_displacement((word)sizeof(oh) + offset);\n }\n \n-# ifdef GC_ADD_CALLER\n-#   define EXTRA_ARGS word ra, CONST char * s, int i\n-#   define OPT_RA ra,\n-# else\n-#   define EXTRA_ARGS CONST char * s, int i\n-#   define OPT_RA\n-# endif\n-\n # ifdef __STDC__\n-    GC_PTR GC_debug_malloc(size_t lb, EXTRA_ARGS)\n+    GC_PTR GC_debug_malloc(size_t lb, GC_EXTRA_PARAMS)\n # else\n     GC_PTR GC_debug_malloc(lb, s, i)\n     size_t lb;\n@@ -379,7 +334,7 @@ void GC_start_debugging()\n }\n \n # ifdef __STDC__\n-    GC_PTR GC_debug_generic_malloc(size_t lb, int k, EXTRA_ARGS)\n+    GC_PTR GC_debug_generic_malloc(size_t lb, int k, GC_EXTRA_PARAMS)\n # else\n     GC_PTR GC_debug_malloc(lb, k, s, i)\n     size_t lb;\n@@ -409,7 +364,7 @@ void GC_start_debugging()\n \n #ifdef STUBBORN_ALLOC\n # ifdef __STDC__\n-    GC_PTR GC_debug_malloc_stubborn(size_t lb, EXTRA_ARGS)\n+    GC_PTR GC_debug_malloc_stubborn(size_t lb, GC_EXTRA_PARAMS)\n # else\n     GC_PTR GC_debug_malloc_stubborn(lb, s, i)\n     size_t lb;\n@@ -476,7 +431,7 @@ GC_PTR p;\n #endif /* STUBBORN_ALLOC */\n \n # ifdef __STDC__\n-    GC_PTR GC_debug_malloc_atomic(size_t lb, EXTRA_ARGS)\n+    GC_PTR GC_debug_malloc_atomic(size_t lb, GC_EXTRA_PARAMS)\n # else\n     GC_PTR GC_debug_malloc_atomic(lb, s, i)\n     size_t lb;\n@@ -501,7 +456,7 @@ GC_PTR p;\n }\n \n # ifdef __STDC__\n-    GC_PTR GC_debug_malloc_uncollectable(size_t lb, EXTRA_ARGS)\n+    GC_PTR GC_debug_malloc_uncollectable(size_t lb, GC_EXTRA_PARAMS)\n # else\n     GC_PTR GC_debug_malloc_uncollectable(lb, s, i)\n     size_t lb;\n@@ -527,7 +482,7 @@ GC_PTR p;\n \n #ifdef ATOMIC_UNCOLLECTABLE\n # ifdef __STDC__\n-    GC_PTR GC_debug_malloc_atomic_uncollectable(size_t lb, EXTRA_ARGS)\n+    GC_PTR GC_debug_malloc_atomic_uncollectable(size_t lb, GC_EXTRA_PARAMS)\n # else\n     GC_PTR GC_debug_malloc_atomic_uncollectable(lb, s, i)\n     size_t lb;\n@@ -607,7 +562,7 @@ GC_PTR p;\n }\n \n # ifdef __STDC__\n-    GC_PTR GC_debug_realloc(GC_PTR p, size_t lb, EXTRA_ARGS)\n+    GC_PTR GC_debug_realloc(GC_PTR p, size_t lb, GC_EXTRA_PARAMS)\n # else\n     GC_PTR GC_debug_realloc(p, lb, s, i)\n     GC_PTR p;\n@@ -810,7 +765,7 @@ struct closure {\n     \t\t\t\t     GC_PTR cd, GC_finalization_proc *ofn,\n \t\t\t\t     GC_PTR *ocd)\n # else\n-    void GC_debug_register_finalizer_no_order\n+    void GC_debug_register_finalizer_ignore_self\n     \t\t\t\t    (obj, fn, cd, ofn, ocd)\n     GC_PTR obj;\n     GC_finalization_proc fn;\n@@ -822,9 +777,9 @@ struct closure {\n     ptr_t base = GC_base(obj);\n     if (0 == base || (ptr_t)obj - base != sizeof(oh)) {\n         GC_err_printf1(\n-\t    \"GC_register_finalizer_no_order called with non-base-pointer 0x%lx\\n\",\n+\t    \"GC_register_finalizer_ignore_self called with non-base-pointer 0x%lx\\n\",\n \t    obj);\n     }\n-    GC_register_finalizer_no_order(base, GC_debug_invoke_finalizer,\n+    GC_register_finalizer_ignore_self(base, GC_debug_invoke_finalizer,\n     \t\t\t  \t      GC_make_closure(fn,cd), ofn, ocd);\n }"}, {"sha": "8d00346c790e7b3d60cbff43f81f8ffdb61700d8", "filename": "boehm-gc/dyn_load.c", "status": "modified", "additions": 59, "deletions": 36, "changes": 95, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fdyn_load.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fdyn_load.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdyn_load.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -32,7 +32,9 @@\n #include \"gc_priv.h\"\n \n /* BTL: avoid circular redefinition of dlopen if SOLARIS_THREADS defined */\n-# if (defined(SOLARIS_THREADS) || defined(LINUX_THREADS)) && defined(dlopen)\n+# if (defined(LINUX_THREADS) || defined(SOLARIS_THREADS) \\\n+      || defined(HPUX_THREADS) || defined(IRIX_THREADS)) && defined(dlopen) \\\n+     && !defined(USE_LD_WRAP)\n     /* To support threads in Solaris, gc.h interposes on dlopen by       */\n     /* defining \"dlopen\" to be \"GC_dlopen\", which is implemented below.  */\n     /* However, both GC_FirstDLOpenedLinkMap() and GC_dlopen() use the   */\n@@ -159,37 +161,77 @@ static ptr_t GC_first_common()\n \n #endif  /* SUNOS4 ... */\n \n-# if defined(SUNOS4) || defined(SUNOS5DL)\n-/* Add dynamic library data sections to the root set.\t\t*/\n-# if !defined(PCR) && !defined(SOLARIS_THREADS) && defined(THREADS)\n-#   ifndef SRC_M3\n-\t--> fix mutual exclusion with dlopen\n-#   endif  /* We assume M3 programs don't call dlopen for now */\n-# endif\n+# if defined(LINUX_THREADS) || defined(SOLARIS_THREADS) \\\n+     || defined(HPUX_THREADS) || defined(IRIX_THREADS)\n+  /* Make sure we're not in the middle of a collection, and make\t*/\n+  /* sure we don't start any.\tReturns previous value of GC_dont_gc.\t*/\n+  /* This is invoked prior to a dlopen call to avoid synchronization\t*/\n+  /* issues.  We can't just acquire the allocation lock, since startup \t*/\n+  /* code in dlopen may try to allocate.\t\t\t\t*/\n+  /* This solution risks heap growth in the presence of many dlopen\t*/\n+  /* calls in either a multithreaded environment, or if the library\t*/\n+  /* initialization code allocates substantial amounts of GC'ed memory.\t*/\n+  /* But I don't know of a better solution.\t\t\t\t*/\n+  /* This can still deadlock if the client explicitly starts a GC \t*/\n+  /* during the dlopen.  He shouldn't do that.\t\t\t\t*/\n+  static GC_bool disable_gc_for_dlopen()\n+  {\n+    GC_bool result;\n+    LOCK();\n+    result = GC_dont_gc;\n+    while (GC_incremental && GC_collection_in_progress()) {\n+\tGC_collect_a_little_inner(1000);\n+    }\n+    GC_dont_gc = TRUE;\n+    UNLOCK();\n+    return(result);\n+  }\n \n-# ifdef SOLARIS_THREADS\n   /* Redefine dlopen to guarantee mutual exclusion with\t*/\n   /* GC_register_dynamic_libraries.\t\t\t*/\n-  /* assumes that dlopen doesn't need to call GC_malloc\t*/\n-  /* and friends.\t\t\t\t\t*/\n-# include <thread.h>\n-# include <synch.h>\n+  /* Should probably happen for other operating\tsystems, too. */\n \n-void * GC_dlopen(const char *path, int mode)\n+#include <dlfcn.h>\n+\n+#ifdef USE_LD_WRAP\n+  void * __wrap_dlopen(const char *path, int mode)\n+#else\n+  void * GC_dlopen(path, mode)\n+  GC_CONST char * path;\n+  int mode;\n+#endif\n {\n     void * result;\n+    GC_bool dont_gc_save;\n     \n #   ifndef USE_PROC_FOR_LIBRARIES\n-      mutex_lock(&GC_allocate_ml);\n+      dont_gc_save = disable_gc_for_dlopen();\n+#   endif\n+#   ifdef USE_LD_WRAP\n+      result = __real_dlopen(path, mode);\n+#   else\n+      result = dlopen(path, mode);\n #   endif\n-    result = dlopen(path, mode);\n #   ifndef USE_PROC_FOR_LIBRARIES\n-      mutex_unlock(&GC_allocate_ml);\n+      GC_dont_gc = dont_gc_save;\n #   endif\n     return(result);\n }\n # endif  /* SOLARIS_THREADS */\n \n+/* BTL: added to fix circular dlopen definition if SOLARIS_THREADS defined */\n+# if defined(GC_must_restore_redefined_dlopen)\n+#   define dlopen GC_dlopen\n+# endif\n+\n+# if defined(SUNOS4) || defined(SUNOS5DL)\n+/* Add dynamic library data sections to the root set.\t\t*/\n+# if !defined(PCR) && !defined(SOLARIS_THREADS) && defined(THREADS)\n+#   ifndef SRC_M3\n+\t--> fix mutual exclusion with dlopen\n+#   endif  /* We assume M3 programs don't call dlopen for now */\n+# endif\n+\n # ifndef USE_PROC_FOR_LIBRARIES\n void GC_register_dynamic_libraries()\n {\n@@ -255,25 +297,6 @@ void GC_register_dynamic_libraries()\n # endif /* !USE_PROC ... */\n # endif /* SUNOS */\n \n-#ifdef LINUX_THREADS\n-#include <dlfcn.h>\n-\n-void * GC_dlopen(const char *path, int mode)\n-{\n-    void * result;\n-    \n-    LOCK();\n-    result = dlopen(path, mode);\n-    UNLOCK();\n-    return(result);\n-}\n-#endif  /* LINUX_THREADS */\n-\n-/* BTL: added to fix circular dlopen definition if SOLARIS_THREADS defined */\n-#if defined(GC_must_restore_redefined_dlopen)\n-# define dlopen GC_dlopen\n-#endif\n-\n #if defined(LINUX) && defined(__ELF__) || defined(SCO_ELF)\n \n /* Dynamic loading code for Linux running ELF. Somewhat tested on"}, {"sha": "1ab56cee82ec8874df2e208facb9f0beedd183ad", "filename": "boehm-gc/finalize.c", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ffinalize.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ffinalize.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Ffinalize.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -694,6 +694,14 @@ GC_API void GC_finalize_all()\n }\n #endif\n \n+/* Returns true if it is worth calling GC_invoke_finalizers. (Useful if\t*/\n+/* finalizers can only be called from some kind of `safe state' and\t*/\n+/* getting into that safe state is expensive.)\t\t\t\t*/\n+int GC_should_invoke_finalizers GC_PROTO((void))\n+{\n+    return GC_finalize_now != 0;\n+}\n+\n /* Invoke finalizers for all objects that are ready to be finalized.\t*/\n /* Should be called without allocation lock.\t\t\t\t*/\n int GC_invoke_finalizers()"}, {"sha": "e35f54f7d3f5e3d1d85c65e31c5aa7bca29672f5", "filename": "boehm-gc/gc.h", "status": "modified", "additions": 32, "deletions": 10, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgc.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -1,7 +1,8 @@\n /* \n  * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n  * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n- * Copyright 1996 by Silicon Graphics.  All rights reserved.\n+ * Copyright 1996-1999 by Silicon Graphics.  All rights reserved.\n+ * Copyright 1999 by Hewlett-Packard Company.  All rights reserved.\n  *\n  * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n  * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n@@ -35,6 +36,14 @@\n #include \"libgc_globals.h\"\n #endif\n \n+#if defined(__MINGW32__) && defined(WIN32_THREADS)\n+# ifdef GC_BUILD\n+#   define GC_API __declspec(dllexport)\n+# else\n+#   define GC_API __declspec(dllimport)\n+# endif\n+#endif\n+\n #if defined(_MSC_VER) && defined(_DLL)\n # ifdef GC_BUILD\n #   define GC_API __declspec(dllexport)\n@@ -130,6 +139,17 @@ GC_API int GC_dont_expand;\n \t\t\t/* Dont expand heap unless explicitly requested */\n \t\t\t/* or forced to.\t\t\t\t*/\n \n+GC_API int GC_use_entire_heap;\n+\t\t/* Causes the nonincremental collector to use the\t*/\n+\t\t/* entire heap before collecting.  This was the only \t*/\n+\t\t/* option for GC versions < 5.0.  This sometimes\t*/\n+\t\t/* results in more large block fragmentation, since\t*/\n+\t\t/* very larg blocks will tend to get broken up\t\t*/\n+\t\t/* during each GC cycle.  It is likely to result in a\t*/\n+\t\t/* larger working set, but lower collection\t\t*/\n+\t\t/* frequencies, and hence fewer instructions executed\t*/\n+\t\t/* in the collector.\t\t\t\t\t*/\n+\n GC_API int GC_full_freq;    /* Number of partial collections between\t*/\n \t\t\t    /* full collections.  Matters only if\t*/\n \t\t\t    /* GC_incremental is set.\t\t\t*/\n@@ -352,11 +372,11 @@ GC_API GC_PTR GC_malloc_atomic_ignore_off_page GC_PROTO((size_t lb));\n \n #ifdef GC_ADD_CALLER\n #  define GC_EXTRAS GC_RETURN_ADDR, __FILE__, __LINE__\n-#  define GC_EXTRA_PARAMS GC_word ra, GC_CONST char * descr_string,\n-\t\t          int descr_int\n+#  define GC_EXTRA_PARAMS GC_word ra, GC_CONST char * s,\n+\t\t          int i\n #else\n #  define GC_EXTRAS __FILE__, __LINE__\n-#  define GC_EXTRA_PARAMS GC_CONST char * descr_string, int descr_int\n+#  define GC_EXTRA_PARAMS GC_CONST char * s, int i\n #endif\n \n /* Debugging (annotated) allocation.  GC_gcollect will check \t\t*/\n@@ -494,6 +514,7 @@ GC_API void GC_debug_register_finalizer_no_order\n \tGC_PROTO((GC_PTR obj, GC_finalization_proc fn, GC_PTR cd,\n \t\t  GC_finalization_proc *ofn, GC_PTR *ocd));\n \n+\n /* The following routine may be used to break cycles between\t*/\n /* finalizable objects, thus causing cyclic finalizable\t\t*/\n /* objects to be finalized in the correct order.  Standard\t*/\n@@ -550,6 +571,9 @@ GC_API int GC_unregister_disappearing_link GC_PROTO((GC_PTR * /* link */));\n GC_API GC_PTR GC_make_closure GC_PROTO((GC_finalization_proc fn, GC_PTR data));\n GC_API void GC_debug_invoke_finalizer GC_PROTO((GC_PTR obj, GC_PTR data));\n \n+/* Returns !=0  if GC_invoke_finalizers has something to do. \t\t*/\n+GC_API int GC_should_invoke_finalizers GC_PROTO((void));\n+\n GC_API int GC_invoke_finalizers GC_PROTO((void));\n \t/* Run finalizers for all objects that are ready to\t*/\n \t/* be finalized.  Return the number of finalizers\t*/\n@@ -712,12 +736,9 @@ GC_API void (*GC_is_visible_print_proc)\n \n # endif /* SOLARIS_THREADS */\n \n-#if defined(LINUX_THREADS)\n-  void * GC_dlopen(const char *path, int mode);\n-# define dlopen GC_dlopen\n-#endif\n \n-#if defined(IRIX_THREADS) || defined(LINUX_THREADS) || defined(HPUX_THREADS)\n+#if !defined(USE_LD_WRAP) && \\\n+    (defined(IRIX_THREADS) || defined(LINUX_THREADS) || defined(HPUX_THREADS))\n /* We treat these similarly. */\n # include <pthread.h>\n # include <signal.h>\n@@ -731,8 +752,9 @@ GC_API void (*GC_is_visible_print_proc)\n # define pthread_create GC_pthread_create\n # define pthread_sigmask GC_pthread_sigmask\n # define pthread_join GC_pthread_join\n+# define dlopen GC_dlopen\n \n-#endif /* IRIX_THREADS || LINUX_THREADS */\n+#endif /* xxxxx_THREADS */\n \n # if defined(PCR) || defined(SOLARIS_THREADS) || defined(WIN32_THREADS) || \\\n \tdefined(IRIX_THREADS) || defined(LINUX_THREADS) || \\"}, {"sha": "36013e135b9abe0599db5bbcd6802ace67730a0b", "filename": "boehm-gc/gc_cpp.h", "status": "modified", "additions": 15, "deletions": 6, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_cpp.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_cpp.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgc_cpp.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -16,12 +16,11 @@ the code was modified is included with the above copyright notice.\n C++ Interface to the Boehm Collector\n \n     John R. Ellis and Jesse Hull \n-    Last modified on Mon Jul 24 15:43:42 PDT 1995 by ellis\n \n This interface provides access to the Boehm collector.  It provides\n basic facilities similar to those described in \"Safe, Efficient\n Garbage Collection for C++\", by John R. Elis and David L. Detlefs\n-(ftp.parc.xerox.com:/pub/ellis/gc).\n+(ftp://ftp.parc.xerox.com/pub/ellis/gc).\n \n All heap-allocated objects are either \"collectable\" or\n \"uncollectable\".  Programs must explicitly delete uncollectable\n@@ -38,7 +37,7 @@ Objects derived from class \"gc\" are collectable.  For example:\n     A* a = new A;       // a is collectable. \n \n Collectable instances of non-class types can be allocated using the GC\n-placement:\n+(or UseGC) placement:\n \n     typedef int A[ 10 ];\n     A* a = new (GC) A;\n@@ -124,6 +123,12 @@ invoked using the ANSI-conforming syntax t->~T().  If you're using\n cfront 3.0, you'll have to comment out the class gc_cleanup, which\n uses explicit invocation.\n \n+5. GC name conflicts:\n+\n+Many other systems seem to use the identifier \"GC\" as an abbreviation\n+for \"Graphics Context\".  Since version 5.0, GC placement has been replaced\n+by UseGC.  GC is an alias for UseGC, unless GC_NAME_CONFLICT is defined.\n+\n ****************************************************************************/\n \n #include \"gc.h\"\n@@ -138,7 +143,11 @@ uses explicit invocation.\n #   define OPERATOR_NEW_ARRAY\n #endif\n \n-enum GCPlacement {GC, NoGC, PointerFreeGC};\n+enum GCPlacement {UseGC,\n+#ifndef GC_NAME_CONFLICT\n+\t\t  GC=UseGC,\n+#endif\n+                  NoGC, PointerFreeGC};\n \n class gc {public:\n     inline void* operator new( size_t size );\n@@ -211,7 +220,7 @@ inline void* gc::operator new( size_t size ) {\n     return GC_MALLOC( size );}\n     \n inline void* gc::operator new( size_t size, GCPlacement gcp ) {\n-    if (gcp == GC) \n+    if (gcp == UseGC) \n         return GC_MALLOC( size );\n     else if (gcp == PointerFreeGC)\n \treturn GC_MALLOC_ATOMIC( size );\n@@ -261,7 +270,7 @@ inline void* operator new(\n {\n     void* obj;\n \n-    if (gcp == GC) {\n+    if (gcp == UseGC) {\n         obj = GC_MALLOC( size );\n         if (cleanup != 0) \n             GC_REGISTER_FINALIZER_IGNORE_SELF( "}, {"sha": "6966a9a1a879fda70f0a946d1a9dd42fc1e00db5", "filename": "boehm-gc/gc_hdrs.h", "status": "modified", "additions": 168, "deletions": 0, "changes": 168, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_hdrs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_hdrs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgc_hdrs.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -24,6 +24,17 @@ typedef struct hblkhdr hdr;\n  * The 2 level tree data structure that is used to find block headers.\n  * If there are more than 32 bits in a pointer, the top level is a hash\n  * table.\n+ *\n+ * This defines HDR, GET_HDR, and SET_HDR, the main macros used to\n+ * retrieve and set object headers.  We also define some variants to\n+ * retrieve 2 unrelated headers in interleaved fashion.  This\n+ * slightly improves scheduling.\n+ *\n+ * Since 5.0 alpha 5, we can also take advantage of a header lookup\n+ * cache.  This is a locally declared direct mapped cache, used inside\n+ * the marker.  The HC_GET_HDR and HC_GET_HDR2 macros use and maintain this\n+ * cache.  Assuming we get reasonable hit rates, this shaves a few\n+ * memory references from each pointer validation.\n  */\n \n # if CPP_WORDSZ > 32\n@@ -45,6 +56,127 @@ typedef struct hblkhdr hdr;\n # define TOP_SZ (1 << LOG_TOP_SZ)\n # define BOTTOM_SZ (1 << LOG_BOTTOM_SZ)\n \n+#ifndef SMALL_CONFIG\n+# define USE_HDR_CACHE\n+#endif\n+\n+/* #define COUNT_HDR_CACHE_HITS  */\n+\n+extern hdr * GC_invalid_header; /* header for an imaginary block \t*/\n+\t\t\t\t/* containing no objects.\t\t*/\n+\n+\n+/* Check whether p and corresponding hhdr point to long or invalid\t*/\n+/* object.  If so, advance them\tto\t\t\t\t\t*/\n+/* beginning of\tblock, or set hhdr to GC_invalid_header.\t\t*/\n+#define ADVANCE(p, hhdr, source) \\\n+            if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) { \\\n+              p = GC_FIND_START(p, hhdr, (word)source); \\\n+              if (p == 0) { \\\n+\t\thhdr = GC_invalid_header; \\\n+\t      } else { \\\n+                hhdr = GC_find_header(p); \\\n+\t      } \\\n+    \t    }\n+\n+#ifdef USE_HDR_CACHE\n+\n+# ifdef COUNT_HDR_CACHE_HITS\n+    extern word GC_hdr_cache_hits;\n+    extern word GC_hdr_cache_misses;\n+#   define HC_HIT() ++GC_hdr_cache_hits\n+#   define HC_MISS() ++GC_hdr_cache_misses\n+# else\n+#   define HC_HIT()\n+#   define HC_MISS()\n+# endif\n+\n+  typedef struct hce {\n+    word block_addr;  \t/* right shifted by LOG_HBLKSIZE */\n+    hdr * hce_hdr;\n+  } hdr_cache_entry;\n+\n+# define HDR_CACHE_SIZE 8  /* power of 2 */\n+\n+# define DECLARE_HDR_CACHE \\\n+\thdr_cache_entry hdr_cache[HDR_CACHE_SIZE]\n+\n+# define INIT_HDR_CACHE BZERO(hdr_cache, sizeof(hdr_cache));\n+\n+# define HCE(h) hdr_cache + (((word)(h) >> LOG_HBLKSIZE) & (HDR_CACHE_SIZE-1))\n+\n+# define HCE_VALID_FOR(hce,h) ((hce) -> block_addr == \\\n+\t\t\t\t((word)(h) >> LOG_HBLKSIZE))\n+\n+# define HCE_HDR(h) ((hce) -> hce_hdr)\n+\n+\n+/* Analogous to GET_HDR, except that in the case of large objects, it\t*/\n+/* Returns the header for the object beginning, and updates p.\t\t*/\n+/* Returns &GC_bad_header instead of 0.  All of this saves a branch\t*/\n+/* in the fast path.\t\t\t\t\t\t\t*/\n+# define HC_GET_HDR(p, hhdr, source) \\\n+\t{ \\\n+\t  hdr_cache_entry * hce = HCE(p); \\\n+\t  if (HCE_VALID_FOR(hce, p)) { \\\n+\t    HC_HIT(); \\\n+\t    hhdr = hce -> hce_hdr; \\\n+\t  } else { \\\n+\t    HC_MISS(); \\\n+\t    GET_HDR(p, hhdr); \\\n+\t    ADVANCE(p, hhdr, source); \\\n+\t    hce -> block_addr = (word)(p) >> LOG_HBLKSIZE; \\\n+\t    hce -> hce_hdr = hhdr; \\\n+\t  } \\\n+\t}\n+\n+# define HC_GET_HDR2(p1, hhdr1, source1, p2, hhdr2, source2) \\\n+\t{ \\\n+\t  hdr_cache_entry * hce1 = HCE(p1); \\\n+\t  hdr_cache_entry * hce2 = HCE(p2); \\\n+\t  if (HCE_VALID_FOR(hce1, p1)) { \\\n+\t    HC_HIT(); \\\n+\t    hhdr1 = hce1 -> hce_hdr; \\\n+\t  } else { \\\n+\t    HC_MISS(); \\\n+\t    GET_HDR(p1, hhdr1); \\\n+\t    ADVANCE(p1, hhdr1, source1); \\\n+\t    hce1 -> block_addr = (word)(p1) >> LOG_HBLKSIZE; \\\n+\t    hce1 -> hce_hdr = hhdr1; \\\n+\t  } \\\n+\t  if (HCE_VALID_FOR(hce2, p2)) { \\\n+\t    HC_HIT(); \\\n+\t    hhdr2 = hce2 -> hce_hdr; \\\n+\t  } else { \\\n+\t    HC_MISS(); \\\n+\t    GET_HDR(p2, hhdr2); \\\n+\t    ADVANCE(p2, hhdr2, source2); \\\n+\t    hce2 -> block_addr = (word)(p2) >> LOG_HBLKSIZE; \\\n+\t    hce2 -> hce_hdr = hhdr2; \\\n+\t  } \\\n+\t}\n+\n+#else /* !USE_HDR_CACHE */\n+\n+# define DECLARE_HDR_CACHE\n+\n+# define INIT_HDR_CACHE\n+\n+# define HC_GET_HDR(p, hhdr, source) \\\n+\t{ \\\n+\t  GET_HDR(p, hhdr); \\\n+\t  ADVANCE(p, hhdr, source); \\\n+\t}\n+\n+# define HC_GET_HDR2(p1, hhdr1, source1, p2, hhdr2, source2) \\\n+\t{ \\\n+\t  GET_HDR2(p1, hhdr1, p2, hhdr2); \\\n+\t  ADVANCE(p1, hhdr1, source1); \\\n+\t  ADVANCE(p2, hhdr2, source2); \\\n+\t}\n+\n+#endif\n+\n typedef struct bi {\n     hdr * index[BOTTOM_SZ];\n \t/*\n@@ -97,6 +229,8 @@ typedef struct bi {\n #   define GET_HDR(p, hhdr) (hhdr) = HDR(p)\n #   define SET_HDR(p, hhdr) HDR_INNER(p) = (hhdr)\n #   define GET_HDR_ADDR(p, ha) (ha) = &(HDR_INNER(p))\n+#   define GET_HDR2(p1, hhdr1, p2, hhdr2) \\\n+\t{ GET_HDR(p1, hhdr1); GET_HDR(p2, hhdr2); }\n # else /* hash */\n /*  Hash function for tree top level */\n #   define TL_HASH(hi) ((hi) & (TOP_SZ - 1))\n@@ -123,6 +257,40 @@ typedef struct bi {\n #   define SET_HDR(p, hhdr) { register hdr ** _ha; GET_HDR_ADDR(p, _ha); \\\n \t\t\t      *_ha = (hhdr); }\n #   define HDR(p) GC_find_header((ptr_t)(p))\n+    /* And some interleaved versions for two pointers at once.  \t*/\n+    /* This hopefully helps scheduling on processors like IA64.\t\t*/\n+#   define GET_BI2(p1, bottom_indx1, p2, bottom_indx2) \\\n+\t{ \\\n+\t    register word hi1 = \\\n+\t        (word)(p1) >> (LOG_BOTTOM_SZ + LOG_HBLKSIZE); \\\n+\t    register word hi2 = \\\n+\t        (word)(p2) >> (LOG_BOTTOM_SZ + LOG_HBLKSIZE); \\\n+\t    register bottom_index * _bi1 = GC_top_index[TL_HASH(hi1)]; \\\n+\t    register bottom_index * _bi2 = GC_top_index[TL_HASH(hi2)]; \\\n+\t    \\\n+\t    while (_bi1 -> key != hi1 && _bi1 != GC_all_nils) \\\n+\t    \t_bi1 = _bi1 -> hash_link; \\\n+\t    while (_bi2 -> key != hi2 && _bi2 != GC_all_nils) \\\n+\t    \t_bi2 = _bi2 -> hash_link; \\\n+\t    (bottom_indx1) = _bi1; \\\n+\t    (bottom_indx2) = _bi2; \\\n+\t}\n+#   define GET_HDR_ADDR2(p1, ha1, p2, ha2) \\\n+\t{ \\\n+\t    register bottom_index * bi1; \\\n+\t    register bottom_index * bi2; \\\n+\t    \\\n+\t    GET_BI2(p1, bi1, p2, bi2);\t\\\n+\t    (ha1) = &(HDR_FROM_BI(bi1, p1)); \\\n+\t    (ha2) = &(HDR_FROM_BI(bi2, p2)); \\\n+\t}\n+#   define GET_HDR2(p1, hhdr1, p2, hhdr2) \\\n+\t{ register hdr ** _ha1;  \\\n+\t  register hdr ** _ha2;  \\\n+\t  GET_HDR_ADDR2(p1, _ha1, p2, _ha2); \\\n+\t  (hhdr1) = *_ha1;  \\\n+\t  (hhdr2) = *_ha2;  \\\n+\t}\n # endif\n \t\t\t    \n /* Is the result a forwarding address to someplace closer to the\t*/"}, {"sha": "3a4908fb908f9780cecd3ab990231644d5703ca2", "filename": "boehm-gc/gc_mark.h", "status": "modified", "additions": 76, "deletions": 14, "changes": 90, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_mark.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_mark.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgc_mark.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -20,6 +20,10 @@\n #ifndef GC_MARK_H\n # define GC_MARK_H\n \n+# ifdef KEEP_BACK_PTRS\n+#   include \"dbg_mlc.h\"\n+# endif\n+\n /* A client supplied mark procedure.  Returns new mark stack pointer.\t*/\n /* Primary effect should be to push new entries on the mark stack.\t*/\n /* Mark stack pointer values are passed and returned explicitly.\t*/\n@@ -41,8 +45,10 @@\n /* The real declarations of the following are in gc_priv.h, so that\t*/\n /* we can avoid scanning the following table.\t\t\t\t*/\n /*\n-typedef struct ms_entry * (*mark_proc)(   word * addr, mark_stack_ptr,\n-\t\t\t\t\t  mark_stack_limit, env   );\n+typedef struct ms_entry * (*mark_proc)(   word * addr,\n+\t\t\t\t\t  struct ms_entry *mark_stack_ptr,\n+\t\t\t\t\t  struct ms_entry *mark_stack_limit,\n+\t\t\t\t\t  word env   );\n \t\t\t\t\t  \n # define LOG_MAX_MARK_PROCS 6\n # define MAX_MARK_PROCS (1 << LOG_MAX_MARK_PROCS)\n@@ -51,6 +57,12 @@ extern mark_proc GC_mark_procs[MAX_MARK_PROCS];\n \n extern word GC_n_mark_procs;\n \n+/* In a few cases it's necessary to assign statically known indices to\t*/\n+/* certain mark procs.  Thus we reserve a few for well known clients.\t*/\n+/* (This is necessary if mark descriptors are compiler generated.)\t*/\n+#define GC_RESERVED_MARK_PROCS 8\n+#   define GCJ_RESERVED_MARK_PROC_INDEX 0\n+\n /* Object descriptors on mark stack or in objects.  Low order two\t*/\n /* bits are tags distinguishing among the following 4 possibilities\t*/\n /* for the high order 30 bits.\t\t\t\t\t\t*/\n@@ -84,6 +96,13 @@ extern word GC_n_mark_procs;\n #define DS_PER_OBJECT 3\t/* The real descriptor is at the\t\t*/\n \t\t\t/* byte displacement from the beginning of the\t*/\n \t\t\t/* object given by descr & ~DS_TAGS\t\t*/\n+\t\t\t/* If the descriptor is negative, the real\t*/\n+\t\t\t/* descriptor is at (*<object_start>) -\t\t*/\n+\t\t\t/* (descr & ~DS_TAGS) - INDIR_PER_OBJ_BIAS\t*/\n+\t\t\t/* The latter alternative can be used if each\t*/\n+\t\t\t/* object contains a type descriptor in the\t*/\n+\t\t\t/* first word.\t\t\t\t\t*/\n+#define INDIR_PER_OBJ_BIAS 0x10\n \t\t\t\n typedef struct ms_entry {\n     word * mse_start;   /* First word of object */\n@@ -98,7 +117,7 @@ extern mse * GC_mark_stack_top;\n \n extern mse * GC_mark_stack;\n \n-word GC_find_start();\n+ptr_t GC_find_start();\n \n mse * GC_signal_mark_stack_overflow();\n \n@@ -144,16 +163,60 @@ mse * GC_signal_mark_stack_overflow();\n # define PUSH_CONTENTS(current, mark_stack_top, mark_stack_limit, \\\n \t\t       source, exit_label) \\\n { \\\n-    register int displ;  /* Displacement in block; first bytes, then words */ \\\n-    register hdr * hhdr; \\\n-    register map_entry_type map_entry; \\\n-    \\\n-    GET_HDR(current,hhdr); \\\n-    if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) { \\\n-         current = GC_FIND_START(current, hhdr, (word)source); \\\n-         if (current == 0) goto exit_label; \\\n-         hhdr = HDR(current); \\\n+    hdr * my_hhdr; \\\n+    ptr_t my_current = current; \\\n+ \\\n+    GET_HDR(my_current, my_hhdr); \\\n+    if (IS_FORWARDING_ADDR_OR_NIL(my_hhdr)) { \\\n+         my_current = GC_FIND_START(my_current, my_hhdr, (word)source); \\\n+         if (my_current == 0) goto exit_label; \\\n+         my_hhdr = GC_find_header(my_current); \\\n     } \\\n+    PUSH_CONTENTS_HDR(my_current, mark_stack_top, mark_stack_limit, \\\n+\t\t  source, exit_label, my_hhdr);\t\\\n+exit_label: ; \\\n+}\n+\n+/* As above, but use header cache for header lookup.\t*/\n+# define HC_PUSH_CONTENTS(current, mark_stack_top, mark_stack_limit, \\\n+\t\t       source, exit_label) \\\n+{ \\\n+    hdr * my_hhdr; \\\n+    ptr_t my_current = current; \\\n+ \\\n+    HC_GET_HDR(my_current, my_hhdr, source); \\\n+    PUSH_CONTENTS_HDR(my_current, mark_stack_top, mark_stack_limit, \\\n+\t\t  source, exit_label, my_hhdr);\t\\\n+exit_label: ; \\\n+}\n+\n+/* As above, but deal with two pointers in interleaved fashion.\t*/\n+# define HC_PUSH_CONTENTS2(current1, current2, mark_stack_top, \\\n+\t\t\t   mark_stack_limit, \\\n+\t\t           source1, source2, exit_label1, exit_label2) \\\n+{ \\\n+    hdr * hhdr1; \\\n+    ptr_t my_current1 = current1; \\\n+    hdr * hhdr2; \\\n+    ptr_t my_current2 = current2; \\\n+ \\\n+    HC_GET_HDR2(my_current1, hhdr1, source1, my_current2, hhdr2, source2); \\\n+    PUSH_CONTENTS_HDR(my_current1, mark_stack_top, mark_stack_limit, \\\n+\t\t  source1, exit_label1, hhdr1);\t\\\n+exit_label1: ; \\\n+    if (0 != hhdr2) { \\\n+      PUSH_CONTENTS_HDR(my_current2, mark_stack_top, mark_stack_limit, \\\n+\t\t  source2, exit_label2, hhdr2);\t\\\n+    } \\\n+exit_label2: ; \\\n+}\n+\n+# define PUSH_CONTENTS_HDR(current, mark_stack_top, mark_stack_limit, \\\n+\t\t           source, exit_label, hhdr) \\\n+{ \\\n+    int displ;  /* Displacement in block; first bytes, then words */ \\\n+    map_entry_type map_entry; \\\n+    \\\n     displ = HBLKDISPL(current); \\\n     map_entry = MAP_ENTRY((hhdr -> hb_map), displ); \\\n     if (map_entry == OBJ_INVALID) { \\\n@@ -177,10 +240,9 @@ mse * GC_signal_mark_stack_overflow();\n     } \\\n     PUSH_OBJ(((word *)(HBLKPTR(current)) + displ), hhdr, \\\n     \t     mark_stack_top, mark_stack_limit) \\\n-  exit_label: ; \\\n }\n \n-#ifdef PRINT_BLACK_LIST\n+#if defined(PRINT_BLACK_LIST) || defined(KEEP_BACK_PTRS)\n #   define PUSH_ONE_CHECKED(p, ip, source) \\\n \tGC_push_one_checked(p, ip, (ptr_t)(source))\n #else"}, {"sha": "a4312b13dca294e19f1544718d8591509a429be0", "filename": "boehm-gc/gc_priv.h", "status": "modified", "additions": 122, "deletions": 58, "changes": 180, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_priv.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_priv.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgc_priv.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -82,6 +82,7 @@ typedef char * ptr_t;\t/* A generic pointer to which we can add\t*/\n #   define GC_FAR\n #endif\n \n+\n /*********************************/\n /*                               */\n /* Definitions for conservative  */\n@@ -173,15 +174,6 @@ typedef char * ptr_t;\t/* A generic pointer to which we can add\t*/\n \t\t    /* May save significant amounts of space for obj_map  */\n \t\t    /* entries.\t\t\t\t\t\t  */\n \n-#ifndef OLD_BLOCK_ALLOC\n-   /* Macros controlling large block allocation strategy.\t*/\n-#  define EXACT_FIRST  \t/* Make a complete pass through the large object */\n-\t\t\t/* free list before splitting a block\t\t */\n-#  define PRESERVE_LAST /* Do not divide last allocated heap segment\t */\n-\t\t\t/* unless we would otherwise need to expand the\t */\n-\t\t\t/* heap.\t\t\t\t\t */\n-#endif\n-\n /* ALIGN_DOUBLE requires MERGE_SIZES at present. */\n # if defined(ALIGN_DOUBLE) && !defined(MERGE_SIZES)\n #   define MERGE_SIZES\n@@ -281,6 +273,13 @@ void GC_print_callers (/* struct callinfo info[NFRAMES] */);\n #   define MS_TIME_DIFF(a,b) ((double) (a.tv_sec - b.tv_sec) * 1000.0 \\\n                                + (double) (a.tv_usec - b.tv_usec) / 1000.0)\n #else /* !BSD_TIME */\n+# ifdef MSWIN32\n+#   include <windows.h>\n+#   include <winbase.h>\n+#   define CLOCK_TYPE DWORD\n+#   define GET_TIME(x) x = GetTickCount()\n+#   define MS_TIME_DIFF(a,b) ((long)((a)-(b)))\n+# else /* !MSWIN32, !BSD_TIME */\n #   include <time.h>\n #   if !defined(__STDC__) && defined(SPARC) && defined(SUNOS4)\n       clock_t clock();\t/* Not in time.h, where it belongs\t*/\n@@ -306,6 +305,7 @@ void GC_print_callers (/* struct callinfo info[NFRAMES] */);\n #   define GET_TIME(x) x = clock()\n #   define MS_TIME_DIFF(a,b) ((unsigned long) \\\n \t\t(1000.0*(double)((a)-(b))/(double)CLOCKS_PER_SEC))\n+# endif /* !MSWIN32 */\n #endif /* !BSD_TIME */\n \n /* We use bzero and bcopy internally.  They may not be available.\t*/\n@@ -437,8 +437,11 @@ void GC_print_callers (/* struct callinfo info[NFRAMES] */);\n #    define LOCK() mutex_lock(&GC_allocate_ml);\n #    define UNLOCK() mutex_unlock(&GC_allocate_ml);\n #  endif\n-#  ifdef LINUX_THREADS\n+#  if defined(LINUX_THREADS) \n+#   if defined(I386)|| defined(POWERPC) || defined(ALPHA) || defined(IA64) \\\n+    || defined(M68K)\n #    include <pthread.h>\n+#    define USE_SPIN_LOCK\n #    if defined(I386)\n        inline static int GC_test_and_set(volatile unsigned int *addr) {\n \t  int oldval;\n@@ -448,9 +451,38 @@ void GC_print_callers (/* struct callinfo info[NFRAMES] */);\n \t\t: \"0\"(1), \"m\"(*(addr)));\n \t  return oldval;\n        }\n-#    else\n-#     if defined(POWERPC)\n+#    endif\n+#    if defined(IA64)\n        inline static int GC_test_and_set(volatile unsigned int *addr) {\n+\t  int oldval;\n+\t  __asm__ __volatile__(\"xchg4 %0=%1,%2\"\n+\t\t: \"=r\"(oldval), \"=m\"(*addr)\n+\t\t: \"r\"(1), \"1\"(*addr));\n+\t  return oldval;\n+       }\n+       inline static void GC_clear(volatile unsigned int *addr) {\n+\t __asm__ __volatile__(\"st4.rel %0=r0\" : \"=m\" (*addr));\n+       }\n+#      define GC_CLEAR_DEFINED\n+#    endif\n+#    ifdef M68K\n+       /* Contributed by Tony Mantler.  I'm not sure how well it was\t*/\n+       /* tested.\t\t\t\t\t\t\t*/\n+       inline static int GC_test_and_set(volatile unsigned int *addr) {\n+          char oldval; /* this must be no longer than 8 bits */\n+\n+          /* The return value is semi-phony. */\n+          /* 'tas' sets bit 7 while the return */\n+          /* value pretends bit 0 was set */\n+          __asm__ __volatile__(\n+                 \"tas %1@; sne %0; negb %0\"\n+                 : \"=d\" (oldval)\n+                 : \"a\" (addr));\n+          return oldval;\n+       }\n+#    endif\n+#    if defined(POWERPC)\n+      inline static int GC_test_and_set(volatile unsigned int *addr) {\n         int oldval;\n         int temp = 1; // locked value\n \n@@ -465,46 +497,61 @@ void GC_print_callers (/* struct callinfo info[NFRAMES] */);\n               : \"r\"(temp), \"1\"(addr)\n               : \"memory\");\n         return (int)oldval;\n-       }\n-#     else\n-#      ifdef ALPHA\n-         inline static int GC_test_and_set(volatile unsigned int *\n-addr)\n-         {\n-           unsigned long oldvalue;\n-           unsigned long temp;\n-\n-           __asm__ __volatile__(\n-                                \"1:     ldl_l %0,%1\\n\"\n-                                \"       and %0,%3,%2\\n\"\n-                                \"       bne %2,2f\\n\"\n-                                \"       xor %0,%3,%0\\n\"\n-                                \"       stl_c %0,%1\\n\"\n-                                \"       beq %0,3f\\n\"\n-                                \"       mb\\n\"\n-                                \"2:\\n\"\n-                                \".section .text2,\\\"ax\\\"\\n\"\n-                                \"3:     br 1b\\n\"\n-                                \".previous\"\n-                                :\"=&r\" (temp), \"=m\" (*addr), \"=&r\"\n-(oldvalue)\n-                                :\"Ir\" (1), \"m\" (*addr));\n-\n-           return oldvalue;\n-         }\n-#      else\n-         -- > Need implementation of GC_test_and_set()\n-#      endif\n-#     endif\n+      }\n+      inline static void GC_clear(volatile unsigned int *addr) {\n+\t __asm__ __volatile__(\"eieio\");\n+         *(addr) = 0;\n+      }\n+#     define GC_CLEAR_DEFINED\n #    endif\n-     inline static void GC_clear(volatile unsigned int *addr) {\n+#    ifdef ALPHA\n+      inline static int GC_test_and_set(volatile unsigned int * addr)\n+      {\n+        unsigned long oldvalue;\n+        unsigned long temp;\n+\n+        __asm__ __volatile__(\n+                             \"1:     ldl_l %0,%1\\n\"\n+                             \"       and %0,%3,%2\\n\"\n+                             \"       bne %2,2f\\n\"\n+                             \"       xor %0,%3,%0\\n\"\n+                             \"       stl_c %0,%1\\n\"\n+                             \"       beq %0,3f\\n\"\n+                             \"       mb\\n\"\n+                             \"2:\\n\"\n+                             \".section .text2,\\\"ax\\\"\\n\"\n+                             \"3:     br 1b\\n\"\n+                             \".previous\"\n+                             :\"=&r\" (temp), \"=m\" (*addr), \"=&r\" (oldvalue)\n+                             :\"Ir\" (1), \"m\" (*addr));\n+\n+        return oldvalue;\n+      }\n+      /* Should probably also define GC_clear, since it needs\t*/\n+      /* a memory barrier ??\t\t\t\t\t*/\n+#    endif /* ALPHA */\n+#    ifdef ARM32\n+      inline static int GC_test_and_set(volatile unsigned int *addr) {\n+        int oldval;\n+        /* SWP on ARM is very similar to XCHG on x86.  Doesn't lock the\n+         * bus because there are no SMP ARM machines.  If/when there are,\n+         * this code will likely need to be updated. */\n+        /* See linuxthreads/sysdeps/arm/pt-machine.h in glibc-2.1 */\n+        __asm__ __volatile__(\"swp %0, %1, [%2]\"\n+      \t\t\t     : \"=r\"(oldval)\n+      \t\t\t     : \"r\"(1), \"r\"(addr));\n+        return oldval;\n+      }\n+#    endif\n+#    ifndef GC_CLEAR_DEFINED\n+       inline static void GC_clear(volatile unsigned int *addr) {\n+\t  /* Try to discourage gcc from moving anything past this. */\n+\t  __asm__ __volatile__(\" \");\n           *(addr) = 0;\n-     }\n+       }\n+#    endif\n \n      extern volatile unsigned int GC_allocate_lock;\n-\t/* This is not a mutex because mutexes that obey the (optional)     */\n-\t/* POSIX scheduling rules are subject to convoys in high contention */\n-\t/* applications.  This is basically a spin lock.\t\t    */\n      extern pthread_t GC_lock_holder;\n      extern void GC_lock(void);\n \t/* Allocation lock holder.  Only set if acquired by client through */\n@@ -517,12 +564,19 @@ addr)\n \t\t{ if (GC_test_and_set(&GC_allocate_lock)) GC_lock(); }\n #    define UNLOCK() \\\n \t\tGC_clear(&GC_allocate_lock)\n-     extern GC_bool GC_collecting;\n+     extern VOLATILE GC_bool GC_collecting;\n #    define ENTER_GC() \\\n \t\t{ \\\n \t\t    GC_collecting = 1; \\\n \t\t}\n #    define EXIT_GC() GC_collecting = 0;\n+#   else /* LINUX_THREADS on hardware for which we don't know how\t*/\n+\t /* to do test and set.\t\t\t\t\t\t*/\n+#    include <pthread.h>\n+     extern pthread_mutex_t GC_allocate_ml;\n+#    define LOCK() pthread_mutex_lock(&GC_allocate_ml)\n+#    define UNLOCK() pthread_mutex_unlock(&GC_allocate_ml)\n+#   endif\n #  endif /* LINUX_THREADS */\n #  if defined(HPUX_THREADS)\n #    include <pthread.h>\n@@ -581,7 +635,7 @@ addr)\n \t\t\t*(volatile unsigned long *)(&GC_allocate_lock) = 0; }\n #      endif\n #    endif\n-     extern GC_bool GC_collecting;\n+     extern VOLATILE GC_bool GC_collecting;\n #    define ENTER_GC() \\\n \t\t{ \\\n \t\t    GC_collecting = 1; \\\n@@ -957,8 +1011,10 @@ struct hblk {\n /* The type of mark procedures.  This really belongs in gc_mark.h.\t*/\n /* But we put it here, so that we can avoid scanning the mark proc\t*/\n /* table.\t\t\t\t\t\t\t\t*/\n-typedef struct ms_entry * (*mark_proc)(/* word * addr, mark_stack_ptr,\n-\t\t\t\t\t  mark_stack_limit, env */);\n+typedef struct ms_entry * (*mark_proc)(/* word * addr,\n+\t\t\t\t\t  struct ms_entry *mark_stack_ptr,\n+\t\t\t\t\t  struct ms_entry *mark_stack_limit,\n+\t\t\t\t\t  word env */);\n # define LOG_MAX_MARK_PROCS 6\n # define MAX_MARK_PROCS (1 << LOG_MAX_MARK_PROCS)\n \n@@ -1035,6 +1091,7 @@ struct roots {\n struct _GC_arrays {\n   word _heapsize;\n   word _max_heapsize;\n+  word _requested_heapsize;\t/* Heap size due to explicit expansion */\n   ptr_t _last_heap_addr;\n   ptr_t _prev_heap_addr;\n   word _large_free_bytes;\n@@ -1059,6 +1116,10 @@ struct _GC_arrays {\n   word _mem_freed;\n   \t/* Number of explicitly deallocated words of memory\t*/\n   \t/* since last collection.\t\t\t\t*/\n+  ptr_t _scratch_end_ptr;\n+  ptr_t _scratch_last_end_ptr;\n+\t/* Used by headers.c, and can easily appear to point to\t*/\n+\t/* heap.\t\t\t\t\t\t*/\n   mark_proc _mark_procs[MAX_MARK_PROCS];\n   \t/* Table of user-defined mark procedures.  There is\t*/\n \t/* a small number of these, which can be referenced\t*/\n@@ -1223,9 +1284,12 @@ GC_API GC_FAR struct _GC_arrays GC_arrays;\n # define GC_words_finalized GC_arrays._words_finalized\n # define GC_non_gc_bytes_at_gc GC_arrays._non_gc_bytes_at_gc\n # define GC_mem_freed GC_arrays._mem_freed\n+# define GC_scratch_end_ptr GC_arrays._scratch_end_ptr\n+# define GC_scratch_last_end_ptr GC_arrays._scratch_last_end_ptr\n # define GC_mark_procs GC_arrays._mark_procs\n # define GC_heapsize GC_arrays._heapsize\n # define GC_max_heapsize GC_arrays._max_heapsize\n+# define GC_requested_heapsize GC_arrays._requested_heapsize\n # define GC_words_allocd_before_gc GC_arrays._words_allocd_before_gc\n # define GC_heap_sects GC_arrays._heap_sects\n # define GC_last_stack GC_arrays._last_stack\n@@ -1260,6 +1324,8 @@ GC_API GC_FAR struct _GC_arrays GC_arrays;\n # define beginGC_arrays ((ptr_t)(&GC_arrays))\n # define endGC_arrays (((ptr_t)(&GC_arrays)) + (sizeof GC_arrays))\n \n+#define USED_HEAP_SIZE (GC_heapsize - GC_large_free_bytes)\n+\n /* Object kinds: */\n # define MAXOBJKINDS 16\n \n@@ -1392,10 +1458,7 @@ extern ptr_t GC_greatest_plausible_heap_addr;\n ptr_t GC_approx_sp();\n \n GC_bool GC_should_collect();\n-#ifdef PRESERVE_LAST\n-    GC_bool GC_in_last_heap_sect(/* ptr_t */);\n-\t/* In last added heap section?  If so, avoid breaking up.\t*/\n-#endif\n+\n void GC_apply_to_all_blocks(/*fn, client_data*/);\n \t\t\t/* Invoke fn(hbp, client_data) for each \t*/\n \t\t\t/* allocated heap block.\t\t\t*/\n@@ -1672,9 +1735,10 @@ ptr_t GC_allocobj(/* sz_inn_words, kind */);\n \t\t\t\t/* head.\t\t\t\t*/\n \n void GC_init_headers();\n-GC_bool GC_install_header(/*h*/);\n+struct hblkhdr * GC_install_header(/*h*/);\n \t\t\t\t/* Install a header for block h.\t*/\n-\t\t\t\t/* Return FALSE on failure.\t\t*/\n+\t\t\t\t/* Return 0 on failure, or the header\t*/\n+\t\t\t\t/* otherwise.\t\t\t\t*/\n GC_bool GC_install_counts(/*h, sz*/);\n \t\t\t\t/* Set up forwarding counts for block\t*/\n \t\t\t\t/* h of size sz.\t\t\t*/"}, {"sha": "2e0598f204c71fa11ede4f2322d8de31dbd5b841", "filename": "boehm-gc/gc_typed.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_typed.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgc_typed.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgc_typed.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -61,6 +61,7 @@ GC_API GC_PTR GC_malloc_explicitly_typed\n \t\t\tGC_PROTO((size_t size_in_bytes, GC_descr d));\n \t\t/* Allocate an object whose layout is described by d.\t*/\n \t\t/* The resulting object MAY NOT BE PASSED TO REALLOC.\t*/\n+\t\t/* The returned object is cleared.\t\t\t*/\n \n GC_API GC_PTR GC_malloc_explicitly_typed_ignore_off_page\n                         GC_PROTO((size_t size_in_bytes, GC_descr d));\n@@ -75,6 +76,7 @@ GC_API GC_PTR GC_calloc_explicitly_typed\n   \t/* alignment required for pointers.  E.g. on a 32-bit\t*/\n   \t/* machine with 16-bit aligned pointers, size_in_bytes\t*/\n   \t/* must be a multiple of 2.\t\t\t\t*/\n+\t/* Returned object is cleared.\t\t\t\t*/\n \n #ifdef GC_DEBUG\n #   define GC_MALLOC_EXPLICTLY_TYPED(bytes, d) GC_MALLOC(bytes)"}, {"sha": "5131ab9650501d16fe8d62c8f5425bbeb2af670d", "filename": "boehm-gc/gc_watcom.asm", "status": "removed", "additions": 0, "deletions": 51, "changes": 51, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e787f078df8900b34981443e9f968fd5c3b039c/boehm-gc%2Fgc_watcom.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e787f078df8900b34981443e9f968fd5c3b039c/boehm-gc%2Fgc_watcom.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgc_watcom.asm?ref=5e787f078df8900b34981443e9f968fd5c3b039c", "patch": "@@ -1,51 +0,0 @@\n-\n-        name    gc_watcom\n-\n-.386p\n-\n-        extrn   _edata              : byte  ; end of DATA (start of BSS)\n-        extrn   _end                : byte  ; end of BSS (start of STACK)\n-        extrn   __nullarea          : word\n-\n-        extrn   \"C\",_STACKLOW          : dword\n-        extrn   \"C\",_STACKTOP          : dword\n-\n-\n-DGROUP  group   _DATA\n-\n-_DATA   segment dword public 'DATA'\n-_DATA   ends\n-\n-_TEXT   segment para public use32 'CODE'\n-        assume  cs:_TEXT, ds:DGROUP, ss:DGROUP\n-\n-        public  Get_DATASTART\n-        align   4\n-Get_DATASTART   proc near\n-\n-        mov     eax,offset DGROUP:__nullarea\n-        ret\n-\n-Get_DATASTART   endp\n-\n-        public  Get_DATAEND\n-        align   4\n-Get_DATAEND     proc near\n-\n-        mov     eax,offset DGROUP:_end\n-        ret\n-\n-Get_DATAEND     endp\n-\n-        public  Get_STACKBOTTOM\n-        align   4\n-Get_STACKBOTTOM proc near\n-\n-        mov     eax,_STACKTOP\n-        ret\n-\n-Get_STACKBOTTOM endp\n-\n-_TEXT   ends\n-\n-        end"}, {"sha": "47398a6debacc9b3d13dc04914d2dfc65a391faa", "filename": "boehm-gc/gcconfig.h", "status": "modified", "additions": 189, "deletions": 50, "changes": 239, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgcconfig.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fgcconfig.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fgcconfig.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -69,15 +69,18 @@\n # endif\n # if defined(mips) || defined(__mips)\n #    define MIPS\n-#    if defined(ultrix) || defined(__ultrix) || defined(__NetBSD__)\n-#\tdefine ULTRIX\n-#    else\n-#\tif defined(_SYSTYPE_SVR4) || defined(SYSTYPE_SVR4) || defined(__SYSTYPE_SVR4__)\n-#\t  define IRIX5   /* or IRIX 6.X */\n-#\telse\n-#\t  define RISCOS  /* or IRIX 4.X */\n-#\tendif\n-#    endif\n+#    if !defined(LINUX)\n+#      if defined(ultrix) || defined(__ultrix) || defined(__NetBSD__)\n+#\t define ULTRIX\n+#      else\n+#\t if defined(_SYSTYPE_SVR4) || defined(SYSTYPE_SVR4) \\\n+\t    || defined(__SYSTYPE_SVR4__)\n+#\t   define IRIX5   /* or IRIX 6.X */\n+#\t else\n+#\t   define RISCOS  /* or IRIX 4.X */\n+#\t endif\n+#      endif\n+#    endif /* !LINUX */\n #    define mach_type_known\n # endif\n # if defined(sequent) && defined(i386)\n@@ -159,10 +162,14 @@\n #    define M68K\n #    define mach_type_known\n # endif\n-# if defined(LINUX) && defined(sparc)\n+# if defined(LINUX) && (defined(sparc) || defined(__sparc__))\n #    define SPARC\n #    define mach_type_known\n # endif\n+# if defined(LINUX) && defined(arm)\n+#    define ARM32\n+#    define mach_type_known\n+# endif\n # if defined(__alpha) || defined(__alpha__)\n #   define ALPHA\n #   if !defined(LINUX)\n@@ -255,6 +262,11 @@\n #   define CYGWIN32\n #   define mach_type_known\n # endif\n+# if defined(__MINGW32__)\n+#   define I386\n+#   define MSWIN32\n+#   define mach_type_known\n+# endif\n # if defined(__BORLANDC__)\n #   define I386\n #   define MSWIN32\n@@ -323,6 +335,9 @@\n \t\t    /* \t\t        (CX_UX and DGUX)\t\t*/\n \t\t    /* \t\t   S370\t      ==> 370-like machine\t*/\n \t\t    /* \t\t\trunning Amdahl UTS4\t\t*/\n+\t\t    /* \t\t   ARM32      ==> Intel StrongARM\t*/\n+\t\t    /* \t\t   IA64\t      ==> Intel IA64\t\t*/\n+\t\t    /*\t\t\t\t  (e.g. Itanium)\t*/\n \n \n /*\n@@ -408,6 +423,15 @@\n  *\n  * An architecture may define DYNAMIC_LOADING if dynamic_load.c\n  * defined GC_register_dynamic_libraries() for the architecture.\n+ *\n+ * An architecture may define PREFETCH(x) to preload the cache with *x.\n+ * This defaults to a no-op.\n+ *\n+ * PREFETCH_FOR_WRITE(x) is used if *x is about to be written.\n+ *\n+ * An architecture may also define CLEAR_DOUBLE(x) to be a fast way to\n+ * clear the two words at GC_malloc-aligned address x.  By default,\n+ * word stores of 0 are used instead.\n  */\n \n \n@@ -532,11 +556,9 @@\n #     undef STACK_GRAN\n #     define STACK_GRAN 0x10000000\n \t/* Stack usually starts at 0x80000000 */\n-      extern int data_start;\n-#     define DATASTART (&data_start)\n+#     define LINUX_DATA_START\n       extern int _end;\n #     define DATAEND (&_end)\n-#     define DYNAMIC_LOADING\n #   endif\n #   ifdef MACOSX\n #     define ALIGNMENT 4\n@@ -633,8 +655,8 @@\n #   ifdef LINUX\n #     define OS_TYPE \"LINUX\"\n #     ifdef __ELF__\n-#         define DATASTART GC_data_start\n-#         define DYNAMIC_LOADING\n+#       define LINUX_DATA_START\n+#       define DYNAMIC_LOADING\n #     else\n           Linux Sparc non elf ?\n #     endif\n@@ -702,13 +724,16 @@\n #   endif\n #   ifdef LINUX\n #\tdefine OS_TYPE \"LINUX\"\n-#       define HEURISTIC1\n-#       undef STACK_GRAN\n-#       define STACK_GRAN 0x10000000\n-\t/* STACKBOTTOM is usually 0xc0000000, but this changes with\t*/\n-\t/* different kernel configurations.  In particular, systems\t*/\n-\t/* with 2GB physical memory will usually move the user\t\t*/\n-\t/* address space limit, and hence initial SP to 0x80000000.\t*/\n+#       define LINUX_STACKBOTTOM\n+#\tif 0\n+#\t  define HEURISTIC1\n+#         undef STACK_GRAN\n+#         define STACK_GRAN 0x10000000\n+\t  /* STACKBOTTOM is usually 0xc0000000, but this changes with\t*/\n+\t  /* different kernel configurations.  In particular, systems\t*/\n+\t  /* with 2GB physical memory will usually move the user\t*/\n+\t  /* address space limit, and hence initial SP to 0x80000000.\t*/\n+#       endif\n #       if !defined(LINUX_THREADS) || !defined(REDIRECT_MALLOC)\n \t/* libgcj: Linux threads don't interact well with the read() wrapper.\n \t   Not defining MPROTECT_VDB fixes this.  */\n@@ -726,8 +751,7 @@\n #\t     endif\n #\t     include <features.h>\n #\t     if defined(__GLIBC__) && __GLIBC__ >= 2\n-\t\t extern int __data_start;\n-#\t\t define DATASTART ((ptr_t)(&__data_start))\n+#\t\t define LINUX_DATA_START\n #\t     else\n      \t         extern char **__environ;\n #                define DATASTART ((ptr_t)(&__environ))\n@@ -746,6 +770,26 @@\n \t     extern int etext;\n #            define DATASTART ((ptr_t)((((word) (&etext)) + 0xfff) & ~0xfff))\n #       endif\n+#\tifdef USE_I686_PREFETCH\n+#\t  define PREFETCH(x) \\\n+\t    __asm__ __volatile__ (\"\tprefetchnta\t%0\": : \"m\"(*(char *)(x)))\n+\t    /* Empirically prefetcht0 is much more effective at reducing\t*/\n+\t    /* cache miss stalls for the targetted load instructions.  But it\t*/\n+\t    /* seems to interfere enough with other cache traffic that the net\t*/\n+\t    /* result is worse than prefetchnta.\t\t\t\t*/\n+#         if 0 \n+\t    /* Using prefetches for write seems to have a slight negative\t*/\n+\t    /* impact on performance, at least for a PIII/500.\t\t\t*/\n+#\t    define PREFETCH_FOR_WRITE(x) \\\n+\t      __asm__ __volatile__ (\"\tprefetcht0\t%0\": : \"m\"(*(char *)(x)))\n+#\t  endif\n+#\tendif\n+#\tifdef USE_3DNOW_PREFETCH\n+#\t  define PREFETCH(x) \\\n+\t    __asm__ __volatile__ (\"\tprefetch\t%0\": : \"m\"(*(char *)(x)))\n+#\t  define PREFETCH_FOR_WRITE(x) \n+\t    __asm__ __volatile__ (\"\tprefetchw\t%0\": : \"m\"(*(char *)(x)))\n+#\tendif\n #   endif\n #   ifdef CYGWIN32\n #       define OS_TYPE \"CYGWIN32\"\n@@ -862,36 +906,48 @@\n         extern int _etext;\n #     define DATASTART ((ptr_t)(&_etext))\n #   else\n-#     ifndef IRIX5\n+/* #   define STACKBOTTOM ((ptr_t)0x7fff8000)  sometimes also works.  */\n+#   ifdef LINUX\n+      /* This was developed for a linuxce style platform.  Probably\t*/\n+      /* needs to be tweaked for workstation class machines.\t\t*/\n+#     define OS_TYPE \"LINUX\"\n+      extern int __data_start;\n+#     define DATASTART ((ptr_t)(&__data_start))\n+#     define ALIGNMENT 4\n+#     define USE_GENERIC_PUSH_REGS 1\n+#     define STACKBOTTOM 0x80000000\n+\t/* In many cases, this should probably use LINUX_STACKBOTTOM \t*/\n+\t/* instead. But some kernel versions seem to give the wrong\t*/\n+\t/* value from /proc.\t\t\t\t\t\t*/\n+#   endif /* Linux */\n+#   ifdef ULTRIX\n+#\tdefine HEURISTIC2\n #       define DATASTART (ptr_t)0x10000000\n \t\t\t      /* Could probably be slightly higher since */\n \t\t\t      /* startup code allocates lots of stuff.   */\n-#     else\n+#\tdefine OS_TYPE \"ULTRIX\"\n+#       define ALIGNMENT 4\n+#   endif\n+#   ifdef RISCOS\n+#\tdefine HEURISTIC2\n+#       define DATASTART (ptr_t)0x10000000\n+#\tdefine OS_TYPE \"RISCOS\"\n+#   \tdefine ALIGNMENT 4  /* Required by hardware */\n+#   endif\n+#   ifdef IRIX5\n+#\tdefine HEURISTIC2\n         extern int _fdata;\n #       define DATASTART ((ptr_t)(&_fdata))\n #       ifdef USE_MMAP\n-#           define HEAP_START (ptr_t)0x30000000\n+#         define HEAP_START (ptr_t)0x30000000\n #       else\n-#\t    define HEAP_START DATASTART\n+#\t  define HEAP_START DATASTART\n #       endif\n \t\t\t      /* Lowest plausible heap address.\t\t*/\n \t\t\t      /* In the MMAP case, we map there.\t*/\n \t\t\t      /* In either case it is used to identify\t*/\n \t\t\t      /* heap sections so they're not \t\t*/\n \t\t\t      /* considered as roots.\t\t\t*/\n-#     endif /* IRIX5 */\n-#   endif /* DATASTART_IS_ETEXT */\n-#   define HEURISTIC2\n-/* #   define STACKBOTTOM ((ptr_t)0x7fff8000)  sometimes also works.  */\n-#   ifdef ULTRIX\n-#\tdefine OS_TYPE \"ULTRIX\"\n-#       define ALIGNMENT 4\n-#   endif\n-#   ifdef RISCOS\n-#\tdefine OS_TYPE \"RISCOS\"\n-#   \tdefine ALIGNMENT 4  /* Required by hardware */\n-#   endif\n-#   ifdef IRIX5\n #\tdefine OS_TYPE \"IRIX5\"\n #       define MPROTECT_VDB\n #       ifdef _MIPS_SZPTR\n@@ -906,6 +962,7 @@\n #\tendif\n #\tdefine DYNAMIC_LOADING\n #   endif\n+#   endif /* DATASTART_IS_ETEXT */\n #   endif /* ECOS */\n # ifdef ECOS\n     extern char __ram_data_start;\n@@ -963,12 +1020,16 @@\n #   endif\n #   include <unistd.h>\n #   define GETPAGESIZE() sysconf(_SC_PAGE_SIZE)\n-\t/* They misspelled the Posix macro?\t*/\n # endif\n \n # ifdef ALPHA\n #   define MACH_TYPE \"ALPHA\"\n #   define ALIGNMENT 8\n+#   define USE_GENERIC_PUSH_REGS\n+\t/* Gcc and probably the DEC/Compaq compiler spill pointers to preserved\t*/\n+\t/* fp registers in some cases when the target is a 21264.  The assembly\t*/\n+\t/* code doesn't handle that yet, and version dependencies make that a\t*/\n+\t/* bit tricky.  Do the easy thing for now.\t\t\t\t*/\n #   ifdef OSF1\n #\tdefine OS_TYPE \"OSF1\"\n #   \tdefine DATASTART ((ptr_t) 0x140000000)\n@@ -989,12 +1050,9 @@\n #       define CPP_WORDSZ 64\n #       define STACKBOTTOM ((ptr_t) 0x120000000)\n #       ifdef __ELF__\n-            /* glibc for Linux/Alpha no longer provides a symbol marking\n-               the start of the data segment.  So libgcj defines\n-               data_start on its own (in libgcjdata.a).  */\n-            extern int data_start;\n-#           define DATASTART &data_start\n-#           define DYNAMIC_LOADING\n+#\t  define LINUX_DATA_START\n+#         define DYNAMIC_LOADING\n+\t  /* This doesn't work if the collector is in a dynamic library. */\n #       else\n #           define DATASTART ((ptr_t) 0x140000000)\n #       endif\n@@ -1011,6 +1069,9 @@\n #   define ALIGN_DOUBLE\n \t/* Requires 16 byte alignment for malloc */\n #   define ALIGNMENT 8\n+#   define USE_GENERIC_PUSH_REGS\n+\t/* We need to get preserved registers in addition to register windows.\t*/\n+\t/* That's easiest to do with setjmp.\t\t\t\t\t*/\n #   ifdef HPUX\n \t--> needs work\n #   endif\n@@ -1024,10 +1085,25 @@\n \t/* backing store.  There is probably a better way to\t*/\n \t/* get that, too ...\t\t\t\t\t*/\n #\tdefine BACKING_STORE_BASE ((ptr_t) 0x9fffffff80000000l)\n-#       define DATASTART GC_data_start\n+#\tif 1\n+#\t    define SEARCH_FOR_DATA_START\n+#\t    define DATASTART GC_data_start\n+#\telse\n+\t    extern int data_start;\n+#\t    define DATASTART ((ptr_t)(&data_start))\n+#\tendif\n #       define DYNAMIC_LOADING\n+#\tdefine MPROTECT_VDB\n+\t\t/* Requires Linux 2.3.47 or later.\t*/\n \textern int _end;\n #\tdefine DATAEND (&_end)\n+\t/* PREFETCH appears to have a large performance impact.\t*/\n+#\tdefine PREFETCH(x) \\\n+\t  __asm__ (\"\tlfetch\t[%0]\": : \"r\"((void *)(x)))\n+#\tdefine PREFETCH_FOR_WRITE(x) \\\n+\t  __asm__ (\"\tlfetch.excl\t[%0]\": : \"r\"((void *)(x)))\n+#\tdefine CLEAR_DOUBLE(x) \\\n+\t  __asm__ (\"\tstf.spill\t[%0]=f0\": : \"r\"((void *)(x)))\n #   endif\n # endif\n \n@@ -1079,6 +1155,49 @@\n #       define DATASTART ((ptr_t)(&etext))\n #       define USE_GENERIC_PUSH_REGS\n #   endif\n+#   ifdef LINUX\n+#       define OS_TYPE \"LINUX\"\n+#       define HEURISTIC1\n+#       undef STACK_GRAN\n+#       define STACK_GRAN 0x10000000\n+#       define USE_GENERIC_PUSH_REGS\n+#       ifdef __ELF__\n+#            define DYNAMIC_LOADING\n+#\t     include <features.h>\n+#\t     if defined(__GLIBC__) && __GLIBC__ >= 2\n+#\t\t define LINUX_DATA_START\n+#\t     else\n+     \t         extern char **__environ;\n+#                define DATASTART ((ptr_t)(&__environ))\n+\t\t\t      /* hideous kludge: __environ is the first */\n+\t\t\t      /* word in crt0.o, and delimits the start */\n+\t\t\t      /* of the data segment, no matter which   */\n+\t\t\t      /* ld options were passed through.        */\n+\t\t\t      /* We could use _etext instead, but that  */\n+\t\t\t      /* would include .rodata, which may       */\n+\t\t\t      /* contain large read-only data tables    */\n+\t\t\t      /* that we'd rather not scan.\t\t*/\n+#\t     endif\n+\t     extern int _end;\n+#\t     define DATAEND (&_end)\n+#\telse\n+\t     extern int etext;\n+#            define DATASTART ((ptr_t)((((word) (&etext)) + 0xfff) & ~0xfff))\n+#       endif\n+#   endif\n+#endif\n+\n+#ifdef LINUX_DATA_START\n+    /* Some Linux distributions arrange to define __data_start.  Some\t*/\n+    /* define data_start as a weak symbol.  The latter is technically\t*/\n+    /* broken, since the user program may define data_start, in which\t*/\n+    /* case we lose.  Nonetheless, we try both, prefering __data_start.\t*/\n+    /* We assume gcc.\t*/\n+#   pragma weak __data_start\n+    extern int __data_start;\n+#   pragma weak data_start\n+    extern int data_start;\n+#   define DATASTART ((ptr_t)(&__data_start != 0? &__data_start : &data_start))\n #endif\n \n # ifndef STACK_GROWS_UP\n@@ -1161,6 +1280,26 @@\n #   define DEFAULT_VDB\n # endif\n \n+# ifndef PREFETCH\n+#   define PREFETCH(x)\n+#   define NO_PREFETCH\n+# endif\n+\n+# ifndef PREFETCH_FOR_WRITE\n+#   define PREFETCH_FOR_WRITE(x)\n+#   define NO_PREFETCH_FOR_WRITE\n+# endif\n+\n+# ifndef CACHE_LINE_SIZE\n+#   define CACHE_LINE_SIZE 32\t/* Wild guess\t*/\n+# endif\n+\n+# ifndef CLEAR_DOUBLE\n+#   define CLEAR_DOUBLE(x) \\\n+\t((word*)x)[0] = 0; \\\n+\t((word*)x)[1] = 0;\n+# endif /* CLEAR_DOUBLE */\n+\n # if defined(_SOLARIS_PTHREADS) && !defined(SOLARIS_THREADS)\n #   define SOLARIS_THREADS\n # endif\n@@ -1197,4 +1336,4 @@\n \t\t\t\t/* include assembly code to do it well.\t*/\n # endif\n \n-# endif\n+# endif /* GCCONFIG_H */"}, {"sha": "6e47bba8e3f08e500128d05b609959f0c3a1d52e", "filename": "boehm-gc/headers.c", "status": "modified", "additions": 16, "deletions": 9, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fheaders.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fheaders.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fheaders.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -50,10 +50,8 @@ ptr_t h;\n  \n static ptr_t scratch_free_ptr = 0;\n  \n-ptr_t GC_scratch_end_ptr = 0;\n-\n-ptr_t GC_scratch_last_end_ptr = 0;\n-\t\t/* End point of last obtained scratch area */\n+/* GC_scratch_last_end_ptr is end point of last obtained scratch area.  */\n+/* GC_scratch_end_ptr is end point of current scratch area.\t\t*/\n  \n ptr_t GC_scratch_alloc(bytes)\n register word bytes;\n@@ -128,6 +126,13 @@ hdr * hhdr;\n     hhdr -> hb_next = (struct hblk *) hdr_free_list;\n     hdr_free_list = hhdr;\n }\n+\n+hdr * GC_invalid_header;\n+\n+#ifdef USE_HDR_CACHE\n+  word GC_hdr_cache_hits = 0;\n+  word GC_hdr_cache_misses = 0;\n+#endif\n  \n void GC_init_headers()\n {\n@@ -138,6 +143,8 @@ void GC_init_headers()\n     for (i = 0; i < TOP_SZ; i++) {\n         GC_top_index[i] = GC_all_nils;\n     }\n+    GC_invalid_header = alloc_hdr();\n+    GC_invalidate_map(GC_invalid_header);\n }\n \n /* Make sure that there is a bottom level index block for address addr  */\n@@ -191,10 +198,10 @@ word addr;\n     return(TRUE);\n }\n \n-/* Install a header for block h.  */\n-/* The header is uninitialized.\t  */\n-/* Returns FALSE on failure.\t  */\n-GC_bool GC_install_header(h)\n+/* Install a header for block h.\t*/\n+/* The header is uninitialized.\t  \t*/\n+/* Returns the header or 0 on failure.\t*/\n+struct hblkhdr * GC_install_header(h)\n register struct hblk * h;\n {\n     hdr * result;\n@@ -205,7 +212,7 @@ register struct hblk * h;\n #   ifdef USE_MUNMAP\n \tresult -> hb_last_reclaimed = GC_gc_no;\n #   endif\n-    return(result != 0);\n+    return(result);\n }\n \n /* Set up forwarding counts for block h of size sz */"}, {"sha": "fc8004cebe5668a8422ee4588c31102d08ae9434", "filename": "boehm-gc/include/private/config.h", "status": "removed", "additions": 0, "deletions": 965, "changes": 965, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e787f078df8900b34981443e9f968fd5c3b039c/boehm-gc%2Finclude%2Fprivate%2Fconfig.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e787f078df8900b34981443e9f968fd5c3b039c/boehm-gc%2Finclude%2Fprivate%2Fconfig.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fprivate%2Fconfig.h?ref=5e787f078df8900b34981443e9f968fd5c3b039c", "patch": "@@ -1,965 +0,0 @@\n-/* \n- * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n- * Copyright (c) 1991-1994 by Xerox Corporation.  All rights reserved.\n- * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n- *\n- * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n- * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n- *\n- * Permission is hereby granted to use or copy this program\n- * for any purpose,  provided the above notices are retained on all copies.\n- * Permission to modify the code and to distribute modified code is granted,\n- * provided the above notices are retained, and a notice that the code was\n- * modified is included with the above copyright notice.\n- */\n- \n-#ifndef CONFIG_H\n-\n-# define CONFIG_H\n-\n-/* Machine dependent parameters.  Some tuning parameters can be found\t*/\n-/* near the top of gc_private.h.\t\t\t\t\t*/\n-\n-/* Machine specific parts contributed by various people.  See README file. */\n-\n-/* Determine the machine type: */\n-# if defined(sun) && defined(mc68000)\n-#    define M68K\n-#    define SUNOS4\n-#    define mach_type_known\n-# endif\n-# if defined(hp9000s300)\n-#    define M68K\n-#    define HP\n-#    define mach_type_known\n-# endif\n-# if defined(__NetBSD__) && defined(m68k)\n-#    define M68K\n-#    define NETBSD\n-#    define mach_type_known\n-# endif\n-# if defined(vax)\n-#    define VAX\n-#    ifdef ultrix\n-#\tdefine ULTRIX\n-#    else\n-#\tdefine BSD\n-#    endif\n-#    define mach_type_known\n-# endif\n-# if defined(mips) || defined(__mips)\n-#    define MIPS\n-#    if defined(ultrix) || defined(__ultrix) || defined(__NetBSD__)\n-#\tdefine ULTRIX\n-#    else\n-#\tif defined(_SYSTYPE_SVR4) || defined(SYSTYPE_SVR4) || defined(__SYSTYPE_SVR4__)\n-#\t  define IRIX5   /* or IRIX 6.X */\n-#\telse\n-#\t  define RISCOS  /* or IRIX 4.X */\n-#\tendif\n-#    endif\n-#    define mach_type_known\n-# endif\n-# if defined(sequent) && defined(i386)\n-#    define I386\n-#    define SEQUENT\n-#    define mach_type_known\n-# endif\n-# if defined(sun) && defined(i386)\n-#    define I386\n-#    define SUNOS5\n-#    define mach_type_known\n-# endif\n-# if (defined(__OS2__) || defined(__EMX__)) && defined(__32BIT__)\n-#    define I386\n-#    define OS2\n-#    define mach_type_known\n-# endif\n-# if defined(ibm032)\n-#   define RT\n-#   define mach_type_known\n-# endif\n-# if defined(sun) && (defined(sparc) || defined(__sparc))\n-#   define SPARC\n-    /* Test for SunOS 5.x */\n-#     include <errno.h>\n-#     ifdef ECHRNG\n-#       define SUNOS5\n-#     else\n-#\tdefine SUNOS4\n-#     endif\n-#   define mach_type_known\n-# endif\n-# if defined(sparc) && defined(unix) && !defined(sun)\n-#   define SPARC\n-#   define DRSNX\n-#   define mach_type_known\n-# endif\n-# if defined(_IBMR2)\n-#   define RS6000\n-#   define mach_type_known\n-# endif\n-# if defined(_M_XENIX) && defined(_M_SYSV) && defined(_M_I386)\n-\t/* The above test may need refinement\t*/\n-#   define I386\n-#   if defined(_SCO_ELF)\n-#     define SCO_ELF\n-#   else\n-#     define SCO\n-#   endif\n-#   define mach_type_known\n-# endif\n-# if defined(_AUX_SOURCE)\n-#   define M68K\n-#   define SYSV\n-#   define mach_type_known\n-# endif\n-# if defined(_PA_RISC1_0) || defined(_PA_RISC1_1)\n-#   define HP_PA\n-#   define mach_type_known\n-# endif\n-# if defined(linux) && defined(i386)\n-#    define I386\n-#    define LINUX\n-#    define mach_type_known\n-# endif\n-# if defined(linux) && defined(powerpc)\n-#    define POWERPC\n-#    define LINUX\n-#    define mach_type_known\n-# endif\n-# if defined(__alpha) || defined(__alpha__)\n-#   define ALPHA\n-#   if defined(linux) || defined(__linux__)\n-#     define LINUX\n-#   else\n-#     define OSF1\t/* a.k.a Digital Unix */\n-#   endif\n-#   define mach_type_known\n-# endif\n-# if defined(_AMIGA)\n-#   define M68K\n-#   define AMIGA\n-#   define mach_type_known\n-# endif\n-# if defined(THINK_C) || defined(__MWERKS__) && !defined(__powerc)\n-#   define M68K\n-#   define MACOS\n-#   define mach_type_known\n-# endif\n-# if defined(__MWERKS__) && defined(__powerc)\n-#   define POWERPC\n-#   define MACOS\n-#   define mach_type_known\n-# endif\n-# if defined(NeXT) && defined(mc68000)\n-#   define M68K\n-#   define NEXT\n-#   define mach_type_known\n-# endif\n-# if defined(NeXT) && defined(i386)\n-#   define I386\n-#   define NEXT\n-#   define mach_type_known\n-# endif\n-# if defined(__FreeBSD__) && defined(i386)\n-#   define I386\n-#   define FREEBSD\n-#   define mach_type_known\n-# endif\n-# if defined(__NetBSD__) && defined(i386)\n-#   define I386\n-#   define NETBSD\n-#   define mach_type_known\n-# endif\n-# if defined(bsdi) && defined(i386)\n-#    define I386\n-#    define BSDI\n-#    define mach_type_known\n-# endif\n-# if !defined(mach_type_known) && defined(__386BSD__)\n-#   define I386\n-#   define THREE86BSD\n-#   define mach_type_known\n-# endif\n-# if defined(_CX_UX) && defined(_M88K)\n-#   define M88K\n-#   define CX_UX\n-#   define mach_type_known\n-# endif\n-# if defined(DGUX)\n-#   define M88K\n-    /* DGUX defined */\n-#   define mach_type_known\n-# endif\n-# if (defined(_MSDOS) || defined(_MSC_VER)) && (_M_IX86 >= 300)\n-#   define I386\n-#   define MSWIN32\t/* or Win32s */\n-#   define mach_type_known\n-# endif\n-# if defined(__DJGPP__)\n-#   define I386\n-#   ifndef DJGPP\n-#     define DJGPP  /* MSDOS running the DJGPP port of GCC */\n-#   endif\n-#   define mach_type_known\n-# endif\n-# if defined(__CYGWIN32__)\n-#   define I386\n-#   define CYGWIN32\n-#   define mach_type_known\n-# endif\n-# if defined(__BORLANDC__)\n-#   define I386\n-#   define MSWIN32\n-#   define mach_type_known\n-# endif\n-# if defined(_UTS) && !defined(mach_type_known)\n-#   define S370\n-#   define UTS4\n-#   define mach_type_known\n-# endif\n-/* Ivan Demakov */\n-# if defined(__WATCOMC__) && defined(__386__)\n-#   define I386\n-#   if !defined(OS2) && !defined(MSWIN32) && !defined(DOS4GW)\n-#     if defined(__OS2__)\n-#       define OS2\n-#     else\n-#       if defined(__WINDOWS_386__) || defined(__NT__)\n-#         define MSWIN32\n-#       else\n-#         define DOS4GW\n-#       endif\n-#     endif\n-#   endif\n-#   define mach_type_known\n-# endif\n-\n-/* Feel free to add more clauses here */\n-\n-/* Or manually define the machine type here.  A machine type is \t*/\n-/* characterized by the architecture.  Some\t\t\t\t*/\n-/* machine types are further subdivided by OS.\t\t\t\t*/\n-/* the macros ULTRIX, RISCOS, and BSD to distinguish.\t\t\t*/\n-/* Note that SGI IRIX is treated identically to RISCOS.\t\t\t*/\n-/* SYSV on an M68K actually means A/UX.\t\t\t\t\t*/\n-/* The distinction in these cases is usually the stack starting address */\n-# ifndef mach_type_known\n-\t--> unknown machine type\n-# endif\n-\t\t    /* Mapping is: M68K       ==> Motorola 680X0\t*/\n-\t\t    /*\t\t   (SUNOS4,HP,NEXT, and SYSV (A/UX),\t*/\n-\t\t    /*\t\t   MACOS and AMIGA variants)\t\t*/\n-\t\t    /*             I386       ==> Intel 386\t \t*/\n-\t\t    /*\t\t    (SEQUENT, OS2, SCO, LINUX, NETBSD,\t*/\n-\t\t    /*\t\t     FREEBSD, THREE86BSD, MSWIN32,\t*/\n-\t\t    /* \t\t     BSDI, SUNOS5, NEXT\tvariants)\t*/\n-                    /*             NS32K      ==> Encore Multimax \t*/\n-                    /*             MIPS       ==> R2000 or R3000\t*/\n-                    /*\t\t\t(RISCOS, ULTRIX variants)\t*/\n-                    /*\t\t   VAX\t      ==> DEC VAX\t\t*/\n-                    /*\t\t\t(BSD, ULTRIX variants)\t\t*/\n-                    /*\t\t   RS6000     ==> IBM RS/6000 AIX3.X\t*/\n-                    /*\t\t   RT\t      ==> IBM PC/RT\t\t*/\n-                    /*\t\t   HP_PA      ==> HP9000/700 & /800\t*/\n-                    /*\t\t\t\t  HP/UX\t\t\t*/\n-\t\t    /*\t\t   SPARC      ==> SPARC under SunOS\t*/\n-\t\t    /*\t\t\t(SUNOS4, SUNOS5,\t\t*/\n-\t\t    /*\t\t\t DRSNX variants)\t\t*/\n-\t\t    /* \t\t   ALPHA      ==> DEC Alpha \t\t*/\n-\t\t    /*\t\t\t(OSF1 and LINUX variants)\t*/\n-\t\t    /* \t\t   M88K       ==> Motorola 88XX0        */\n-\t\t    /* \t\t        (CX_UX and DGUX)\t\t*/\n-\t\t    /* \t\t   S370\t      ==> 370-like machine\t*/\n-\t\t    /* \t\t\trunning Amdahl UTS4\t\t*/\n-\n-\n-/*\n- * For each architecture and OS, the following need to be defined:\n- *\n- * CPP_WORD_SZ is a simple integer constant representing the word size.\n- * in bits.  We assume byte addressibility, where a byte has 8 bits.\n- * We also assume CPP_WORD_SZ is either 32 or 64.\n- * (We care about the length of pointers, not hardware\n- * bus widths.  Thus a 64 bit processor with a C compiler that uses\n- * 32 bit pointers should use CPP_WORD_SZ of 32, not 64. Default is 32.)\n- *\n- * MACH_TYPE is a string representation of the machine type.\n- * OS_TYPE is analogous for the OS.\n- *\n- * ALIGNMENT is the largest N, such that\n- * all pointer are guaranteed to be aligned on N byte boundaries.\n- * defining it to be 1 will always work, but perform poorly.\n- *\n- * DATASTART is the beginning of the data segment.\n- * On UNIX systems, the collector will scan the area between DATASTART\n- * and DATAEND for root pointers.\n- *\n- * DATAEND, if not &end.\n- *\n- * ALIGN_DOUBLE of GC_malloc should return blocks aligned to twice\n- * the pointer size.\n- *\n- * STACKBOTTOM is the cool end of the stack, which is usually the\n- * highest address in the stack.\n- * Under PCR or OS/2, we have other ways of finding thread stacks.\n- * For each machine, the following should:\n- * 1) define STACK_GROWS_UP if the stack grows toward higher addresses, and\n- * 2) define exactly one of\n- *\tSTACKBOTTOM (should be defined to be an expression)\n- *\tHEURISTIC1\n- *\tHEURISTIC2\n- * If either of the last two macros are defined, then STACKBOTTOM is computed\n- * during collector startup using one of the following two heuristics:\n- * HEURISTIC1:  Take an address inside GC_init's frame, and round it up to\n- *\t\tthe next multiple of STACK_GRAN.\n- * HEURISTIC2:  Take an address inside GC_init's frame, increment it repeatedly\n- *\t\tin small steps (decrement if STACK_GROWS_UP), and read the value\n- *\t\tat each location.  Remember the value when the first\n- *\t\tSegmentation violation or Bus error is signalled.  Round that\n- *\t\tto the nearest plausible page boundary, and use that instead\n- *\t\tof STACKBOTTOM.\n- *\n- * If no expression for STACKBOTTOM can be found, and neither of the above\n- * heuristics are usable, the collector can still be used with all of the above\n- * undefined, provided one of the following is done:\n- * 1) GC_mark_roots can be changed to somehow mark from the correct stack(s)\n- *    without reference to STACKBOTTOM.  This is appropriate for use in\n- *    conjunction with thread packages, since there will be multiple stacks.\n- *    (Allocating thread stacks in the heap, and treating them as ordinary\n- *    heap data objects is also possible as a last resort.  However, this is\n- *    likely to introduce significant amounts of excess storage retention\n- *    unless the dead parts of the thread stacks are periodically cleared.)\n- * 2) Client code may set GC_stackbottom before calling any GC_ routines.\n- *    If the author of the client code controls the main program, this is\n- *    easily accomplished by introducing a new main program, setting\n- *    GC_stackbottom to the address of a local variable, and then calling\n- *    the original main program.  The new main program would read something\n- *    like:\n- *\n- *\t\t# include \"gc_private.h\"\n- *\n- *\t\tmain(argc, argv, envp)\n- *\t\tint argc;\n- *\t\tchar **argv, **envp;\n- *\t\t{\n- *\t\t    int dummy;\n- *\n- *\t\t    GC_stackbottom = (ptr_t)(&dummy);\n- *\t\t    return(real_main(argc, argv, envp));\n- *\t\t}\n- *\n- *\n- * Each architecture may also define the style of virtual dirty bit\n- * implementation to be used:\n- *   MPROTECT_VDB: Write protect the heap and catch faults.\n- *   PROC_VDB: Use the SVR4 /proc primitives to read dirty bits.\n- *\n- * An architecture may define DYNAMIC_LOADING if dynamic_load.c\n- * defined GC_register_dynamic_libraries() for the architecture.\n- */\n-\n-\n-# define STACK_GRAN 0x1000000\n-# ifdef M68K\n-#   define MACH_TYPE \"M68K\"\n-#   define ALIGNMENT 2\n-#   ifdef NETBSD\n-#\tdefine OS_TYPE \"NETBSD\"\n-#\tdefine HEURISTIC2\n-\textern char etext;\n-#\tdefine DATASTART ((ptr_t)(&etext))\n-#   endif\n-#   ifdef SUNOS4\n-#\tdefine OS_TYPE \"SUNOS4\"\n-\textern char etext;\n-#\tdefine DATASTART ((ptr_t)((((word) (&etext)) + 0x1ffff) & ~0x1ffff))\n-#\tdefine HEURISTIC1\t/* differs\t*/\n-#\tdefine DYNAMIC_LOADING\n-#   endif\n-#   ifdef HP\n-#\tdefine OS_TYPE \"HP\"\n-\textern char etext;\n-#       define DATASTART ((ptr_t)((((word) (&etext)) + 0xfff) & ~0xfff))\n-#       define STACKBOTTOM ((ptr_t) 0xffeffffc)\n-\t\t\t      /* empirically determined.  seems to work. */\n-#  \tinclude <unistd.h>\n-#\tdefine GETPAGESIZE() sysconf(_SC_PAGE_SIZE)\n-#   endif\n-#   ifdef SYSV\n-#\tdefine OS_TYPE \"SYSV\"\n-\textern etext;\n-#   \tdefine DATASTART ((ptr_t)((((word) (&etext)) + 0x3fffff) \\\n-\t\t\t\t   & ~0x3fffff) \\\n-\t\t\t\t  +((word)&etext & 0x1fff))\n-\t/* This only works for shared-text binaries with magic number 0413.\n-\t   The other sorts of SysV binaries put the data at the end of the text,\n-\t   in which case the default of &etext would work.  Unfortunately,\n-\t   handling both would require having the magic-number available.\n-\t   \t   \t\t-- Parag\n-\t   */\n-#\tdefine STACKBOTTOM ((ptr_t)0xFFFFFFFE)\n-\t\t\t/* The stack starts at the top of memory, but   */\n-\t\t\t/* 0x0 cannot be used as setjump_test complains */\n-\t\t\t/* that the stack direction is incorrect.  Two  */\n-\t\t\t/* bytes down from 0x0 should be safe enough.   */\n-\t\t\t/* \t\t--Parag\t\t\t\t*/\n-#   \tinclude <sys/mmu.h>\n-#\tdefine GETPAGESIZE() PAGESIZE\t/* Is this still right? */\n-#   endif\n-#   ifdef AMIGA\n-#\tdefine OS_TYPE \"AMIGA\"\n- \t    \t/* STACKBOTTOM and DATASTART handled specially\t*/\n- \t    \t/* in os_dep.c\t\t\t\t\t*/\n-# \tdefine DATAEND\t/* not needed */\n-#\tdefine GETPAGESIZE() 4096\n-#   endif\n-#   ifdef MACOS\n-#     ifndef __LOWMEM__\n-#     include <LowMem.h>\n-#     endif\n-#     define OS_TYPE \"MACOS\"\n-\t\t\t/* see os_dep.c for details of global data segments. */\n-#     define STACKBOTTOM ((ptr_t) LMGetCurStackBase())\n-#     define DATAEND\t/* not needed */\n-#     define GETPAGESIZE() 4096\n-#   endif\n-#   ifdef NEXT\n-#\tdefine OS_TYPE \"NEXT\"\n-#\tdefine DATASTART ((ptr_t) get_etext())\n-#\tdefine STACKBOTTOM ((ptr_t) 0x4000000)\n-#\tdefine DATAEND\t/* not needed */\n-#   endif\n-# endif\n-\n-# ifdef POWERPC\n-#   define MACH_TYPE \"POWERPC\"\n-#   define ALIGNMENT 2\n-#   ifdef MACOS\n-#     ifndef __LOWMEM__\n-#     include <LowMem.h>\n-#     endif\n-#     define OS_TYPE \"MACOS\"\n-\t\t\t/* see os_dep.c for details of global data segments. */\n-#     define STACKBOTTOM ((ptr_t) LMGetCurStackBase())\n-#     define DATAEND  /* not needed */\n-#   endif\n-#   ifdef LINUX\n-#     define OS_TYPE \"LINUX\"\n-#     define STACKBOTTOM ((ptr_t)0x80000000)\n-#     define DATASTART GC_data_start\n-      extern int _end;\n-#     define DATAEND (&_end)\n-#   endif\n-# endif\n-\n-# ifdef VAX\n-#   define MACH_TYPE \"VAX\"\n-#   define ALIGNMENT 4\t/* Pointers are longword aligned by 4.2 C compiler */\n-    extern char etext;\n-#   define DATASTART ((ptr_t)(&etext))\n-#   ifdef BSD\n-#\tdefine OS_TYPE \"BSD\"\n-#\tdefine HEURISTIC1\n-\t\t\t/* HEURISTIC2 may be OK, but it's hard to test. */\n-#   endif\n-#   ifdef ULTRIX\n-#\tdefine OS_TYPE \"ULTRIX\"\n-#\tdefine STACKBOTTOM ((ptr_t) 0x7fffc800)\n-#   endif\n-# endif\n-\n-# ifdef RT\n-#   define MACH_TYPE \"RT\"\n-#   define ALIGNMENT 4\n-#   define DATASTART ((ptr_t) 0x10000000)\n-#   define STACKBOTTOM ((ptr_t) 0x1fffd800)\n-# endif\n-\n-# ifdef SPARC\n-#   define MACH_TYPE \"SPARC\"\n-#   define ALIGNMENT 4\t/* Required by hardware\t*/\n-#   define ALIGN_DOUBLE\n-    extern int etext;\n-#   ifdef SUNOS5\n-#\tdefine OS_TYPE \"SUNOS5\"\n-\textern int _etext;\n-\textern int _end;\n-\textern char * GC_SysVGetDataStart();\n-#       define DATASTART (ptr_t)GC_SysVGetDataStart(0x10000, &_etext)\n-#\tdefine DATAEND (&_end)\n-#\tifndef USE_MMAP\n-#\t    define USE_MMAP\n-#\tendif\n-#       ifdef USE_MMAP\n-#         define HEAP_START (ptr_t)0x40000000\n-#       else\n-#\t  define HEAP_START DATAEND\n-#       endif\n-#\tdefine PROC_VDB\n-#\tdefine HEURISTIC1\n-#\tinclude <unistd.h>\n-#       define GETPAGESIZE()  sysconf(_SC_PAGESIZE)\n-\t\t/* getpagesize() appeared to be missing from at least one */\n-\t\t/* Solaris 5.4 installation.  Weird.\t\t\t  */\n-#   endif\n-#   ifdef SUNOS4\n-#\tdefine OS_TYPE \"SUNOS4\"\n-\t/* [If you have a weak stomach, don't read this.]\t\t*/\n-\t/* We would like to use:\t\t\t\t\t*/\n-/* #       define DATASTART ((ptr_t)((((word) (&etext)) + 0x1fff) & ~0x1fff)) */\n-\t/* This fails occasionally, due to an ancient, but very \t*/\n-\t/* persistent ld bug.  &etext is set 32 bytes too high.\t\t*/\n-\t/* We instead read the text segment size from the a.out\t\t*/\n-\t/* header, which happens to be mapped into our address space\t*/\n-\t/* at the start of the text segment.  The detective work here\t*/\n-\t/* was done by Robert Ehrlich, Manuel Serrano, and Bernard\t*/\n-\t/* Serpette of INRIA.\t\t\t\t\t\t*/\n-\t/* This assumes ZMAGIC, i.e. demand-loadable executables.\t*/\n-#\tdefine TEXTSTART 0x2000\n-#       define DATASTART ((ptr_t)(*(int *)(TEXTSTART+0x4)+TEXTSTART))\n-#\tdefine MPROTECT_VDB\n-#\tdefine HEURISTIC1\n-#   endif\n-#   ifdef DRSNX\n-#       define CPP_WORDSZ 32\n-#\tdefine OS_TYPE \"DRSNX\"\n-\textern char * GC_SysVGetDataStart();\n-\textern int etext;\n-#       define DATASTART (ptr_t)GC_SysVGetDataStart(0x10000, &etext)\n-#\tdefine MPROTECT_VDB\n-#       define STACKBOTTOM ((ptr_t) 0xdfff0000)\n-#   endif\n-#   define DYNAMIC_LOADING\n-# endif\n-\n-# ifdef I386\n-#   define MACH_TYPE \"I386\"\n-#   define ALIGNMENT 4\t/* Appears to hold for all \"32 bit\" compilers\t*/\n-\t\t\t/* except Borland.  The -a4 option fixes \t*/\n-\t\t\t/* Borland.\t\t\t\t\t*/\n-                        /* Ivan Demakov: For Watcom the option is -zp4. */\n-#   ifndef SMALL_CONFIG\n-#     define ALIGN_DOUBLE /* Not strictly necessary, but may give speed   */\n-\t\t\t  /* improvement on Pentiums.\t\t\t  */\n-#   endif\n-#   ifdef SEQUENT\n-#\tdefine OS_TYPE \"SEQUENT\"\n-\textern int etext;\n-#       define DATASTART ((ptr_t)((((word) (&etext)) + 0xfff) & ~0xfff))\n-#       define STACKBOTTOM ((ptr_t) 0x3ffff000) \n-#   endif\n-#   ifdef SUNOS5\n-#\tdefine OS_TYPE \"SUNOS5\"\n-  \textern int etext, _start;\n-  \textern char * GC_SysVGetDataStart();\n-#       define DATASTART GC_SysVGetDataStart(0x1000, &etext)\n-#\tdefine STACKBOTTOM ((ptr_t)(&_start))\n-/** At least in Solaris 2.5, PROC_VDB gives wrong values for dirty bits. */\n-/*#\tdefine PROC_VDB*/\n-#\tdefine DYNAMIC_LOADING\n-#\tifndef USE_MMAP\n-#\t    define USE_MMAP\n-#\tendif\n-#       ifdef USE_MMAP\n-#         define HEAP_START (ptr_t)0x40000000\n-#       else\n-#\t  define HEAP_START DATAEND\n-#       endif\n-#   endif\n-#   ifdef SCO\n-#\tdefine OS_TYPE \"SCO\"\n-\textern int etext;\n-#   \tdefine DATASTART ((ptr_t)((((word) (&etext)) + 0x3fffff) \\\n-\t\t\t\t  & ~0x3fffff) \\\n-\t\t\t\t +((word)&etext & 0xfff))\n-#\tdefine STACKBOTTOM ((ptr_t) 0x7ffffffc)\n-#   endif\n-#   ifdef SCO_ELF\n-#       define OS_TYPE \"SCO_ELF\"\n-        extern int etext;\n-#       define DATASTART ((ptr_t)(&etext))\n-#       define STACKBOTTOM ((ptr_t) 0x08048000)\n-#       define DYNAMIC_LOADING\n-#\tdefine ELF_CLASS ELFCLASS32\n-#   endif\n-#   ifdef LINUX\n-#\tdefine OS_TYPE \"LINUX\"\n-#\tdefine STACKBOTTOM ((ptr_t)0xc0000000)\n-\t/* Appears to be 0xe0000000 for at least one 2.1.91 kernel.\t*/\n-\t/* Probably needs to be more flexible, but I don't yet \t\t*/\n-\t/* fully understand how flexible.\t\t\t\t*/\n-#\tdefine MPROTECT_VDB\n-#       ifdef __ELF__\n-#            define DYNAMIC_LOADING\n-#\t     ifdef UNDEFINED\t/* includes ro data */\n-\t       extern int _etext;\n-#              define DATASTART ((ptr_t)((((word) (&_etext)) + 0xfff) & ~0xfff))\n-#\t     endif\n-#\t     include <linux/version.h>\n-#\t     include <features.h>\n-#\t     if LINUX_VERSION_CODE >= 0x20000 && defined(__GLIBC__) && __GLIBC__ >= 2\n-\t\t extern int __data_start;\n-#\t\t define DATASTART ((ptr_t)(&__data_start))\n-#\t     else\n-     \t         extern char **__environ;\n-#                define DATASTART ((ptr_t)(&__environ))\n-\t\t\t      /* hideous kludge: __environ is the first */\n-\t\t\t      /* word in crt0.o, and delimits the start */\n-\t\t\t      /* of the data segment, no matter which   */\n-\t\t\t      /* ld options were passed through.        */\n-\t\t\t      /* We could use _etext instead, but that  */\n-\t\t\t      /* would include .rodata, which may       */\n-\t\t\t      /* contain large read-only data tables    */\n-\t\t\t      /* that we'd rather not scan.\t\t*/\n-#\t     endif\n-\t     extern int _end;\n-#\t     define DATAEND (&_end)\n-#\telse\n-\t     extern int etext;\n-#            define DATASTART ((ptr_t)((((word) (&etext)) + 0xfff) & ~0xfff))\n-#       endif\n-#   endif\n-#   ifdef CYGWIN32\n-          extern int _data_start__;\n-          extern int _data_end__;\n-          extern int _bss_start__;\n-          extern int _bss_end__;\n-  \t/* For binutils 2.9.1, we have\t\t\t*/\n-  \t/*\tDATASTART   = _data_start__\t\t*/\n-  \t/*\tDATAEND\t    = _bss_end__\t\t*/\n-  \t/* whereas for some earlier versions it was\t*/\n-  \t/*\tDATASTART   = _bss_start__\t\t*/\n-  \t/*\tDATAEND\t    = _data_end__\t\t*/\n-  \t/* To get it right for both, we take the\t*/\n-  \t/* minumum/maximum of the two.\t\t\t*/\n-#   \tdefine MAX(x,y) ((x) > (y) ? (x) : (y))\n-#   \tdefine MIN(x,y) ((x) < (y) ? (x) : (y))\n-#       define DATASTART ((ptr_t) MIN(_data_start__, _bss_start__))\n-#       define DATAEND\t ((ptr_t) MAX(_data_end__, _bss_end__))\n-#\tundef STACK_GRAN\n-#       define STACK_GRAN 0x10000\n-#       define HEURISTIC1\n-#   endif\n-#   ifdef OS2\n-#\tdefine OS_TYPE \"OS2\"\n- \t    \t/* STACKBOTTOM and DATASTART are handled specially in \t*/\n-\t\t/* os_dep.c. OS2 actually has the right\t\t\t*/\n-\t\t/* system call!\t\t\t\t\t\t*/\n-#\tdefine DATAEND\t/* not needed */\n-#   endif\n-#   ifdef MSWIN32\n-#\tdefine OS_TYPE \"MSWIN32\"\n-\t\t/* STACKBOTTOM and DATASTART are handled specially in \t*/\n-\t\t/* os_dep.c.\t\t\t\t\t\t*/\n-#       ifndef __WATCOMC__\n-#\t  define MPROTECT_VDB\n-#\tendif\n-#       define DATAEND  /* not needed */\n-#   endif\n-#   ifdef DJGPP\n-#       define OS_TYPE \"DJGPP\"\n-#       include \"stubinfo.h\"\n-        extern int etext;\n-        extern int _stklen;\n-#       define DATASTART ((ptr_t)((((word) (&etext)) + 0x1ff) & ~0x1ff))\n-#       define STACKBOTTOM ((ptr_t)((word) _stubinfo + _stubinfo->size \\\n-                                                     + _stklen))\n-\t\t/* This may not be right.  */\n-#   endif\n-#   ifdef FREEBSD\n-#\tdefine OS_TYPE \"FREEBSD\"\n-#\tdefine MPROTECT_VDB\n-#   endif\n-#   ifdef NETBSD\n-#\tdefine OS_TYPE \"NETBSD\"\n-#   endif\n-#   ifdef THREE86BSD\n-#\tdefine OS_TYPE \"THREE86BSD\"\n-#   endif\n-#   ifdef BSDI\n-#\tdefine OS_TYPE \"BSDI\"\n-#   endif\n-#   if defined(FREEBSD) || defined(NETBSD) \\\n-        || defined(THREE86BSD) || defined(BSDI)\n-#\tdefine HEURISTIC2\n-\textern char etext;\n-#\tdefine DATASTART ((ptr_t)(&etext))\n-#   endif\n-#   ifdef NEXT\n-#\tdefine OS_TYPE \"NEXT\"\n-#\tdefine DATASTART ((ptr_t) get_etext())\n-#\tdefine STACKBOTTOM ((ptr_t)0xc0000000)\n-#\tdefine DATAEND\t/* not needed */\n-#   endif\n-#   ifdef DOS4GW\n-#     define OS_TYPE \"DOS4GW\"\n-      /* Get_DATASTART, Get_DATAEND, Get_STACKBOTTOM\n-       *      Defined in gc-watcom.asm\n-       */\n-      extern char* Get_DATASTART (void);\n-      extern char* Get_DATAEND (void);\n-      extern char* Get_STACKBOTTOM (void);\n-#     pragma aux Get_DATASTART \"*\" value [eax];\n-#     pragma aux Get_DATAEND \"*\" value [eax];\n-#     pragma aux Get_STACKBOTTOM \"*\" value [eax];\n-#     define DATASTART ((ptr_t) Get_DATASTART())\n-#     define STACKBOTTOM ((ptr_t) Get_STACKBOTTOM())\n-#     define DATAEND ((ptr_t) Get_DATAEND())\n-#   endif\n-# endif\n-\n-# ifdef NS32K\n-#   define MACH_TYPE \"NS32K\"\n-#   define ALIGNMENT 4\n-    extern char **environ;\n-#   define DATASTART ((ptr_t)(&environ))\n-\t\t\t      /* hideous kludge: environ is the first   */\n-\t\t\t      /* word in crt0.o, and delimits the start */\n-\t\t\t      /* of the data segment, no matter which   */\n-\t\t\t      /* ld options were passed through.        */\n-#   define STACKBOTTOM ((ptr_t) 0xfffff000) /* for Encore */\n-# endif\n-\n-# ifdef MIPS\n-#   define MACH_TYPE \"MIPS\"\n-#   ifndef IRIX5\n-#     define DATASTART (ptr_t)0x10000000\n-\t\t\t      /* Could probably be slightly higher since */\n-\t\t\t      /* startup code allocates lots of stuff.   */\n-#   else\n-      extern int _fdata;\n-#     define DATASTART ((ptr_t)(&_fdata))\n-#     ifdef USE_MMAP\n-#         define HEAP_START (ptr_t)0x30000000\n-#     else\n-#\t  define HEAP_START DATASTART\n-#     endif\n-\t\t\t      /* Lowest plausible heap address.\t\t*/\n-\t\t\t      /* In the MMAP case, we map there.\t*/\n-\t\t\t      /* In either case it is used to identify\t*/\n-\t\t\t      /* heap sections so they're not \t\t*/\n-\t\t\t      /* considered as roots.\t\t\t*/\n-#   endif /* IRIX5 */\n-#   define HEURISTIC2\n-/* #   define STACKBOTTOM ((ptr_t)0x7fff8000)  sometimes also works.  */\n-#   ifdef ULTRIX\n-#\tdefine OS_TYPE \"ULTRIX\"\n-#       define ALIGNMENT 4\n-#   endif\n-#   ifdef RISCOS\n-#\tdefine OS_TYPE \"RISCOS\"\n-#   \tdefine ALIGNMENT 4  /* Required by hardware */\n-#   endif\n-#   ifdef IRIX5\n-#\tdefine OS_TYPE \"IRIX5\"\n-#       define MPROTECT_VDB\n-#       ifdef _MIPS_SZPTR\n-#\t  define CPP_WORDSZ _MIPS_SZPTR\n-#\t  define ALIGNMENT (_MIPS_SZPTR/8)\n-#\t  if CPP_WORDSZ != 64\n-#\t    define ALIGN_DOUBLE\n-#\t  endif\n-#\telse\n-#         define ALIGNMENT 4\n-#\t  define ALIGN_DOUBLE\n-#\tendif\n-#\tdefine DYNAMIC_LOADING\n-#   endif\n-# endif\n-\n-# ifdef RS6000\n-#   define MACH_TYPE \"RS6000\"\n-#   define ALIGNMENT 4\n-#   define DATASTART ((ptr_t)0x20000000)\n-    extern int errno;\n-#   define STACKBOTTOM ((ptr_t)((ulong)&errno))\n-#   define DYNAMIC_LOADING\n-\t/* For really old versions of AIX, this may have to be removed. */\n-# endif\n-\n-# ifdef HP_PA\n-#   define MACH_TYPE \"HP_PA\"\n-#   define ALIGNMENT 4\n-#   define ALIGN_DOUBLE\n-    extern int __data_start;\n-#   define DATASTART ((ptr_t)(&__data_start))\n-#   if 0\n-\t/* The following appears to work for 7xx systems running HP/UX\t*/\n-\t/* 9.xx Furthermore, it might result in much faster\t\t*/\n-\t/* collections than HEURISTIC2, which may involve scanning\t*/\n-\t/* segments that directly precede the stack.  It is not the\t*/\n-\t/* default, since it may not work on older machine/OS\t\t*/\n-\t/* combinations. (Thanks to Raymond X.T. Nijssen for uncovering\t*/\n-\t/* this.)\t\t\t\t\t\t\t*/\n-#       define STACKBOTTOM ((ptr_t) 0x7b033000)  /* from /etc/conf/h/param.h */\n-#   else\n-#       define HEURISTIC2\n-#   endif\n-#   define STACK_GROWS_UP\n-#   define DYNAMIC_LOADING\n-#   include <unistd.h>\n-#   define GETPAGESIZE() sysconf(_SC_PAGE_SIZE)\n-\t/* They misspelled the Posix macro?\t*/\n-# endif\n-\n-# ifdef ALPHA\n-#   define MACH_TYPE \"ALPHA\"\n-#   define ALIGNMENT 8\n-#   ifdef OSF1\n-#\tdefine OS_TYPE \"OSF1\"\n-#   \tdefine DATASTART ((ptr_t) 0x140000000)\n-#   \tdefine HEURISTIC2\n-\t/* Normally HEURISTIC2 is too conervative, since\t\t*/\n-\t/* the text segment immediately follows the stack.\t\t*/\n-\t/* Hence we give an upper pound.\t\t\t\t*/\n-    \textern __start;\n-#   \tdefine HEURISTIC2_LIMIT ((ptr_t)((word)(&__start) & ~(getpagesize()-1)))\n-#   \tdefine CPP_WORDSZ 64\n-#   \tdefine MPROTECT_VDB\n-#   \tdefine DYNAMIC_LOADING\n-#   endif\n-#   ifdef LINUX\n-#       define OS_TYPE \"LINUX\"\n-#       define CPP_WORDSZ 64\n-#       define STACKBOTTOM ((ptr_t) 0x120000000)\n-#       ifdef __ELF__\n-            extern int __data_start;\n-#           define DATASTART &__data_start\n-#           define DYNAMIC_LOADING\n-#       else\n-#           define DATASTART ((ptr_t) 0x140000000)\n-#       endif\n-\textern int _end;\n-#\tdefine DATAEND (&_end)\n-\t/* As of 1.3.90, I couldn't find a way to retrieve the correct\t*/\n-\t/* fault address from a signal handler.\t\t\t\t*/\n-\t/* Hence MPROTECT_VDB is broken.\t\t\t\t*/\n-#   endif\n-# endif\n-\n-# ifdef M88K\n-#   define MACH_TYPE \"M88K\"\n-#   define ALIGNMENT 4\n-#   define ALIGN_DOUBLE\n-    extern int etext;\n-#   ifdef CX_UX\n-#\tdefine OS_TYPE \"CX_UX\"\n-#       define DATASTART ((((word)&etext + 0x3fffff) & ~0x3fffff) + 0x10000)\n-#   endif\n-#   ifdef  DGUX\n-#\tdefine OS_TYPE \"DGUX\"\n-\textern char * GC_SysVGetDataStart();\n-#       define DATASTART (ptr_t)GC_SysVGetDataStart(0x10000, &etext)\n-#   endif\n-#   define STACKBOTTOM ((char*)0xf0000000) /* determined empirically */\n-# endif\n-\n-# ifdef S370\n-#   define MACH_TYPE \"S370\"\n-#   define OS_TYPE \"UTS4\"\n-#   define ALIGNMENT 4\t/* Required by hardware\t*/\n-    extern int etext;\n-\textern int _etext;\n-\textern int _end;\n-\textern char * GC_SysVGetDataStart();\n-#       define DATASTART (ptr_t)GC_SysVGetDataStart(0x10000, &_etext)\n-#\tdefine DATAEND (&_end)\n-#\tdefine HEURISTIC2\n-# endif\n-\n-# ifndef STACK_GROWS_UP\n-#   define STACK_GROWS_DOWN\n-# endif\n-\n-# ifndef CPP_WORDSZ\n-#   define CPP_WORDSZ 32\n-# endif\n-\n-# ifndef OS_TYPE\n-#   define OS_TYPE \"\"\n-# endif\n-\n-# ifndef DATAEND\n-    extern int end;\n-#   define DATAEND (&end)\n-# endif\n-\n-# if defined(SVR4) && !defined(GETPAGESIZE)\n-#    include <unistd.h>\n-#    define GETPAGESIZE()  sysconf(_SC_PAGESIZE)\n-# endif\n-\n-# ifndef GETPAGESIZE\n-#   if defined(SUNOS5) || defined(IRIX5)\n-#\tinclude <unistd.h>\n-#   endif\n-#   define GETPAGESIZE() getpagesize()\n-# endif\n-\n-# if defined(SUNOS5) || defined(DRSNX) || defined(UTS4)\n-    /* OS has SVR4 generic features.  Probably others also qualify.\t*/\n-#   define SVR4\n-# endif\n-\n-# if defined(SUNOS5) || defined(DRSNX)\n-    /* OS has SUNOS5 style semi-undocumented interface to dynamic \t*/\n-    /* loader.\t\t\t\t\t\t\t\t*/\n-#   define SUNOS5DL\n-    /* OS has SUNOS5 style signal handlers.\t\t\t\t*/\n-#   define SUNOS5SIGS\n-# endif\n-\n-# if CPP_WORDSZ != 32 && CPP_WORDSZ != 64\n-   -> bad word size\n-# endif\n-\n-# ifdef PCR\n-#   undef DYNAMIC_LOADING\n-#   undef STACKBOTTOM\n-#   undef HEURISTIC1\n-#   undef HEURISTIC2\n-#   undef PROC_VDB\n-#   undef MPROTECT_VDB\n-#   define PCR_VDB\n-# endif\n-\n-# ifdef SRC_M3\n-/* Postponed for now. */\n-#   undef PROC_VDB\n-#   undef MPROTECT_VDB\n-# endif\n-\n-# ifdef SMALL_CONFIG\n-/* Presumably not worth the space it takes. */\n-#   undef PROC_VDB\n-#   undef MPROTECT_VDB\n-# endif\n-\n-# if !defined(PCR_VDB) && !defined(PROC_VDB) && !defined(MPROTECT_VDB)\n-#   define DEFAULT_VDB\n-# endif\n-\n-# if defined(IRIX_THREADS) && !defined(IRIX5)\n---> inconsistent configuration\n-# endif\n-# if defined(LINUX_THREADS) && !defined(LINUX)\n---> inconsistent configuration\n-# endif\n-# if defined(SOLARIS_THREADS) && !defined(SUNOS5)\n---> inconsistent configuration\n-# endif\n-# if defined(PCR) || defined(SRC_M3) || \\\n-\tdefined(SOLARIS_THREADS) || defined(WIN32_THREADS) || \\\n-\tdefined(IRIX_THREADS) || defined(LINUX_THREADS)\n-#   define THREADS\n-# endif\n-\n-# if defined(SPARC)\n-#   define SAVE_CALL_CHAIN\n-#   define ASM_CLEAR_CODE\t/* Stack clearing is crucial, and we \t*/\n-\t\t\t\t/* include assembly code to do it well.\t*/\n-# endif\n-\n-# endif"}, {"sha": "5efca2110343942b2adf44a736b25cb0af4067ae", "filename": "boehm-gc/irix_threads.c", "status": "removed", "additions": 0, "deletions": 674, "changes": 674, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e787f078df8900b34981443e9f968fd5c3b039c/boehm-gc%2Firix_threads.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e787f078df8900b34981443e9f968fd5c3b039c/boehm-gc%2Firix_threads.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Firix_threads.c?ref=5e787f078df8900b34981443e9f968fd5c3b039c", "patch": "@@ -1,674 +0,0 @@\n-/* \n- * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n- * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n- *\n- * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n- * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n- *\n- * Permission is hereby granted to use or copy this program\n- * for any purpose,  provided the above notices are retained on all copies.\n- * Permission to modify the code and to distribute modified code is granted,\n- * provided the above notices are retained, and a notice that the code was\n- * modified is included with the above copyright notice.\n- */\n-/*\n- * Support code for Irix (>=6.2) Pthreads.  This relies on properties\n- * not guaranteed by the Pthread standard.  It may or may not be portable\n- * to other implementations.\n- *\n- * Note that there is a lot of code duplication between linux_threads.c\n- * and irix_threads.c; any changes made here may need to be reflected\n- * there too.\n- */\n-\n-# if defined(IRIX_THREADS)\n-\n-# include \"gc_priv.h\"\n-# include <pthread.h>\n-# include <semaphore.h>\n-# include <time.h>\n-# include <errno.h>\n-# include <unistd.h>\n-# include <sys/mman.h>\n-# include <sys/time.h>\n-\n-#undef pthread_create\n-#undef pthread_sigmask\n-#undef pthread_join\n-\n-void GC_thr_init();\n-\n-#if 0\n-void GC_print_sig_mask()\n-{\n-    sigset_t blocked;\n-    int i;\n-\n-    if (pthread_sigmask(SIG_BLOCK, NULL, &blocked) != 0)\n-    \tABORT(\"pthread_sigmask\");\n-    GC_printf0(\"Blocked: \");\n-    for (i = 1; i <= MAXSIG; i++) {\n-        if (sigismember(&blocked, i)) { GC_printf1(\"%ld \",(long) i); }\n-    }\n-    GC_printf0(\"\\n\");\n-}\n-#endif\n-\n-/* We use the allocation lock to protect thread-related data structures. */\n-\n-/* The set of all known threads.  We intercept thread creation and \t*/\n-/* joins.  We never actually create detached threads.  We allocate all \t*/\n-/* new thread stacks ourselves.  These allow us to maintain this\t*/\n-/* data structure.\t\t\t\t\t\t\t*/\n-/* Protected by GC_thr_lock.\t\t\t\t\t\t*/\n-/* Some of this should be declared volatile, but that's incosnsistent\t*/\n-/* with some library routine declarations.  \t\t \t\t*/\n-typedef struct GC_Thread_Rep {\n-    struct GC_Thread_Rep * next;  /* More recently allocated threads\t*/\n-\t\t\t\t  /* with a given pthread id come \t*/\n-\t\t\t\t  /* first.  (All but the first are\t*/\n-\t\t\t\t  /* guaranteed to be dead, but we may  */\n-\t\t\t\t  /* not yet have registered the join.) */\n-    pthread_t id;\n-    word stop;\n-#\tdefine NOT_STOPPED 0\n-#\tdefine PLEASE_STOP 1\n-#\tdefine STOPPED 2\n-    word flags;\n-#\tdefine FINISHED 1   \t/* Thread has exited.\t*/\n-#\tdefine DETACHED 2\t/* Thread is intended to be detached.\t*/\n-#\tdefine CLIENT_OWNS_STACK\t4\n-\t\t\t\t/* Stack was supplied by client.\t*/\n-    ptr_t stack;\n-    ptr_t stack_ptr;  \t\t/* Valid only when stopped. */\n-\t\t\t\t/* But must be within stack region at\t*/\n-\t\t\t\t/* all times.\t\t\t\t*/\n-    size_t stack_size;\t\t/* 0 for original thread.\t*/\n-    void * status;\t\t/* Used only to avoid premature \t*/\n-\t\t\t\t/* reclamation of any data it might \t*/\n-\t\t\t\t/* reference.\t\t\t\t*/\n-} * GC_thread;\n-\n-GC_thread GC_lookup_thread(pthread_t id);\n-\n-/*\n- * The only way to suspend threads given the pthread interface is to send\n- * signals.  Unfortunately, this means we have to reserve\n- * a signal, and intercept client calls to change the signal mask.\n- */\n-# define SIG_SUSPEND (SIGRTMIN + 6)\n-\n-pthread_mutex_t GC_suspend_lock = PTHREAD_MUTEX_INITIALIZER;\n-\t\t\t\t/* Number of threads stopped so far\t*/\n-pthread_cond_t GC_suspend_ack_cv = PTHREAD_COND_INITIALIZER;\n-pthread_cond_t GC_continue_cv = PTHREAD_COND_INITIALIZER;\n-\n-void GC_suspend_handler(int sig)\n-{\n-    int dummy;\n-    GC_thread me;\n-    sigset_t all_sigs;\n-    sigset_t old_sigs;\n-    int i;\n-\n-    if (sig != SIG_SUSPEND) ABORT(\"Bad signal in suspend_handler\");\n-    me = GC_lookup_thread(pthread_self());\n-    /* The lookup here is safe, since I'm doing this on behalf  */\n-    /* of a thread which holds the allocation lock in order\t*/\n-    /* to stop the world.  Thus concurrent modification of the\t*/\n-    /* data structure is impossible.\t\t\t\t*/\n-    if (PLEASE_STOP != me -> stop) {\n-\t/* Misdirected signal.\t*/\n-\tpthread_mutex_unlock(&GC_suspend_lock);\n-\treturn;\n-    }\n-    pthread_mutex_lock(&GC_suspend_lock);\n-    me -> stack_ptr = (ptr_t)(&dummy);\n-    me -> stop = STOPPED;\n-    pthread_cond_signal(&GC_suspend_ack_cv);\n-    pthread_cond_wait(&GC_continue_cv, &GC_suspend_lock);\n-    pthread_mutex_unlock(&GC_suspend_lock);\n-    /* GC_printf1(\"Continuing 0x%x\\n\", pthread_self()); */\n-}\n-\n-\n-GC_bool GC_thr_initialized = FALSE;\n-\n-size_t GC_min_stack_sz;\n-\n-size_t GC_page_sz;\n-\n-# define N_FREE_LISTS 25\n-ptr_t GC_stack_free_lists[N_FREE_LISTS] = { 0 };\n-\t\t/* GC_stack_free_lists[i] is free list for stacks of \t*/\n-\t\t/* size GC_min_stack_sz*2**i.\t\t\t\t*/\n-\t\t/* Free lists are linked through first word.\t\t*/\n-\n-/* Return a stack of size at least *stack_size.  *stack_size is\t*/\n-/* replaced by the actual stack size.\t\t\t\t*/\n-/* Caller holds allocation lock.\t\t\t\t*/\n-ptr_t GC_stack_alloc(size_t * stack_size)\n-{\n-    register size_t requested_sz = *stack_size;\n-    register size_t search_sz = GC_min_stack_sz;\n-    register int index = 0;\t/* = log2(search_sz/GC_min_stack_sz) */\n-    register ptr_t result;\n-    \n-    while (search_sz < requested_sz) {\n-        search_sz *= 2;\n-        index++;\n-    }\n-    if ((result = GC_stack_free_lists[index]) == 0\n-        && (result = GC_stack_free_lists[index+1]) != 0) {\n-        /* Try next size up. */\n-        search_sz *= 2; index++;\n-    }\n-    if (result != 0) {\n-        GC_stack_free_lists[index] = *(ptr_t *)result;\n-    } else {\n-        result = (ptr_t) GC_scratch_alloc(search_sz + 2*GC_page_sz);\n-        result = (ptr_t)(((word)result + GC_page_sz) & ~(GC_page_sz - 1));\n-        /* Protect hottest page to detect overflow. */\n-        /* mprotect(result, GC_page_sz, PROT_NONE); */\n-        result += GC_page_sz;\n-    }\n-    *stack_size = search_sz;\n-    return(result);\n-}\n-\n-/* Caller holds allocation lock.\t\t\t\t\t*/\n-void GC_stack_free(ptr_t stack, size_t size)\n-{\n-    register int index = 0;\n-    register size_t search_sz = GC_min_stack_sz;\n-    \n-    while (search_sz < size) {\n-        search_sz *= 2;\n-        index++;\n-    }\n-    if (search_sz != size) ABORT(\"Bad stack size\");\n-    *(ptr_t *)stack = GC_stack_free_lists[index];\n-    GC_stack_free_lists[index] = stack;\n-}\n-\n-\n-\n-# define THREAD_TABLE_SZ 128\t/* Must be power of 2\t*/\n-volatile GC_thread GC_threads[THREAD_TABLE_SZ];\n-\n-/* Add a thread to GC_threads.  We assume it wasn't already there.\t*/\n-/* Caller holds allocation lock.\t\t\t\t\t*/\n-GC_thread GC_new_thread(pthread_t id)\n-{\n-    int hv = ((word)id) % THREAD_TABLE_SZ;\n-    GC_thread result;\n-    static struct GC_Thread_Rep first_thread;\n-    static GC_bool first_thread_used = FALSE;\n-    \n-    if (!first_thread_used) {\n-    \tresult = &first_thread;\n-    \tfirst_thread_used = TRUE;\n-    \t/* Dont acquire allocation lock, since we may already hold it. */\n-    } else {\n-        result = (struct GC_Thread_Rep *)\n-        \t GC_generic_malloc_inner(sizeof(struct GC_Thread_Rep), NORMAL);\n-    }\n-    if (result == 0) return(0);\n-    result -> id = id;\n-    result -> next = GC_threads[hv];\n-    GC_threads[hv] = result;\n-    /* result -> flags = 0;     */\n-    /* result -> stop = 0;\t*/\n-    return(result);\n-}\n-\n-/* Delete a thread from GC_threads.  We assume it is there.\t*/\n-/* (The code intentionally traps if it wasn't.)\t\t\t*/\n-/* Caller holds allocation lock.\t\t\t\t*/\n-void GC_delete_thread(pthread_t id)\n-{\n-    int hv = ((word)id) % THREAD_TABLE_SZ;\n-    register GC_thread p = GC_threads[hv];\n-    register GC_thread prev = 0;\n-    \n-    while (!pthread_equal(p -> id, id)) {\n-        prev = p;\n-        p = p -> next;\n-    }\n-    if (prev == 0) {\n-        GC_threads[hv] = p -> next;\n-    } else {\n-        prev -> next = p -> next;\n-    }\n-}\n-\n-/* If a thread has been joined, but we have not yet\t\t*/\n-/* been notified, then there may be more than one thread \t*/\n-/* in the table with the same pthread id.\t\t\t*/\n-/* This is OK, but we need a way to delete a specific one.\t*/\n-void GC_delete_gc_thread(pthread_t id, GC_thread gc_id)\n-{\n-    int hv = ((word)id) % THREAD_TABLE_SZ;\n-    register GC_thread p = GC_threads[hv];\n-    register GC_thread prev = 0;\n-\n-    while (p != gc_id) {\n-        prev = p;\n-        p = p -> next;\n-    }\n-    if (prev == 0) {\n-        GC_threads[hv] = p -> next;\n-    } else {\n-        prev -> next = p -> next;\n-    }\n-}\n-\n-/* Return a GC_thread corresponding to a given thread_t.\t*/\n-/* Returns 0 if it's not there.\t\t\t\t\t*/\n-/* Caller holds  allocation lock or otherwise inhibits \t\t*/\n-/* updates.\t\t\t\t\t\t\t*/\n-/* If there is more than one thread with the given id we \t*/\n-/* return the most recent one.\t\t\t\t\t*/\n-GC_thread GC_lookup_thread(pthread_t id)\n-{\n-    int hv = ((word)id) % THREAD_TABLE_SZ;\n-    register GC_thread p = GC_threads[hv];\n-    \n-    while (p != 0 && !pthread_equal(p -> id, id)) p = p -> next;\n-    return(p);\n-}\n-\n-\n-/* Caller holds allocation lock.\t*/\n-void GC_stop_world()\n-{\n-    pthread_t my_thread = pthread_self();\n-    register int i;\n-    register GC_thread p;\n-    register int result;\n-    struct timespec timeout;\n-    \n-    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n-      for (p = GC_threads[i]; p != 0; p = p -> next) {\n-        if (p -> id != my_thread) {\n-            if (p -> flags & FINISHED) {\n-\t\tp -> stop = STOPPED;\n-\t\tcontinue;\n-\t    }\n-\t    p -> stop = PLEASE_STOP;\n-            result = pthread_kill(p -> id, SIG_SUSPEND);\n-\t    /* GC_printf1(\"Sent signal to 0x%x\\n\", p -> id); */\n-\t    switch(result) {\n-                case ESRCH:\n-                    /* Not really there anymore.  Possible? */\n-                    p -> stop = STOPPED;\n-                    break;\n-                case 0:\n-                    break;\n-                default:\n-                    ABORT(\"pthread_kill failed\");\n-            }\n-        }\n-      }\n-    }\n-    pthread_mutex_lock(&GC_suspend_lock);\n-    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n-      for (p = GC_threads[i]; p != 0; p = p -> next) {\n-        while (p -> id != my_thread && p -> stop != STOPPED) {\n-\t    clock_gettime(CLOCK_REALTIME, &timeout);\n-            timeout.tv_nsec += 50000000; /* 50 msecs */\n-            if (timeout.tv_nsec >= 1000000000) {\n-                timeout.tv_nsec -= 1000000000;\n-                ++timeout.tv_sec;\n-            }\n-            result = pthread_cond_timedwait(&GC_suspend_ack_cv,\n-\t\t\t\t\t    &GC_suspend_lock,\n-                                            &timeout);\n-            if (result == ETIMEDOUT) {\n-                /* Signal was lost or misdirected.  Try again.      */\n-                /* Duplicate signals should be benign.              */\n-                result = pthread_kill(p -> id, SIG_SUSPEND);\n-\t    }\n-\t}\n-      }\n-    }\n-    pthread_mutex_unlock(&GC_suspend_lock);\n-    /* GC_printf1(\"World stopped 0x%x\\n\", pthread_self()); */\n-}\n-\n-/* Caller holds allocation lock.\t*/\n-void GC_start_world()\n-{\n-    GC_thread p;\n-    unsigned i;\n-\n-    /* GC_printf0(\"World starting\\n\"); */\n-    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n-      for (p = GC_threads[i]; p != 0; p = p -> next) {\n-\tp -> stop = NOT_STOPPED;\n-      }\n-    }\n-    pthread_mutex_lock(&GC_suspend_lock);\n-    /* All other threads are at pthread_cond_wait in signal handler.\t*/\n-    /* Otherwise we couldn't have acquired the lock.\t\t\t*/\n-    pthread_mutex_unlock(&GC_suspend_lock);\n-    pthread_cond_broadcast(&GC_continue_cv);\n-}\n-\n-# ifdef MMAP_STACKS\n---> not really supported yet.\n-int GC_is_thread_stack(ptr_t addr)\n-{\n-    register int i;\n-    register GC_thread p;\n-\n-    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n-      for (p = GC_threads[i]; p != 0; p = p -> next) {\n-        if (p -> stack_size != 0) {\n-            if (p -> stack <= addr &&\n-                addr < p -> stack + p -> stack_size)\n-                   return 1;\n-       }\n-      }\n-    }\n-    return 0;\n-}\n-# endif\n-\n-/* We hold allocation lock.  We assume the world is stopped.\t*/\n-void GC_push_all_stacks()\n-{\n-    register int i;\n-    register GC_thread p;\n-    register ptr_t sp = GC_approx_sp();\n-    register ptr_t lo, hi;\n-    pthread_t me = pthread_self();\n-    \n-    if (!GC_thr_initialized) GC_thr_init();\n-    /* GC_printf1(\"Pushing stacks from thread 0x%x\\n\", me); */\n-    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n-      for (p = GC_threads[i]; p != 0; p = p -> next) {\n-        if (p -> flags & FINISHED) continue;\n-        if (pthread_equal(p -> id, me)) {\n-\t    lo = GC_approx_sp();\n-\t} else {\n-\t    lo = p -> stack_ptr;\n-\t}\n-        if (p -> stack_size != 0) {\n-            hi = p -> stack + p -> stack_size;\n-        } else {\n-            /* The original stack. */\n-            hi = GC_stackbottom;\n-        }\n-        GC_push_all_stack(lo, hi);\n-      }\n-    }\n-}\n-\n-\n-/* We hold the allocation lock.\t*/\n-void GC_thr_init()\n-{\n-    GC_thread t;\n-    struct sigaction act;\n-\n-    if (GC_thr_initialized) return;\n-    GC_thr_initialized = TRUE;\n-    GC_min_stack_sz = HBLKSIZE;\n-    GC_page_sz = sysconf(_SC_PAGESIZE);\n-    (void) sigaction(SIG_SUSPEND, 0, &act);\n-    if (act.sa_handler != SIG_DFL)\n-    \tABORT(\"Previously installed SIG_SUSPEND handler\");\n-    /* Install handler.\t*/\n-\tact.sa_handler = GC_suspend_handler;\n-\tact.sa_flags = SA_RESTART;\n-\t(void) sigemptyset(&act.sa_mask);\n-        if (0 != sigaction(SIG_SUSPEND, &act, 0))\n-\t    ABORT(\"Failed to install SIG_SUSPEND handler\");\n-    /* Add the initial thread, so we can stop it.\t*/\n-      t = GC_new_thread(pthread_self());\n-      t -> stack_size = 0;\n-      t -> stack_ptr = (ptr_t)(&t);\n-      t -> flags = DETACHED;\n-}\n-\n-int GC_pthread_sigmask(int how, const sigset_t *set, sigset_t *oset)\n-{\n-    sigset_t fudged_set;\n-    \n-    if (set != NULL && (how == SIG_BLOCK || how == SIG_SETMASK)) {\n-        fudged_set = *set;\n-        sigdelset(&fudged_set, SIG_SUSPEND);\n-        set = &fudged_set;\n-    }\n-    return(pthread_sigmask(how, set, oset));\n-}\n-\n-struct start_info {\n-    void *(*start_routine)(void *);\n-    void *arg;\n-    word flags;\n-    ptr_t stack;\n-    size_t stack_size;\n-    sem_t registered;   \t/* 1 ==> in our thread table, but \t*/\n-\t\t\t\t/* parent hasn't yet noticed.\t\t*/\n-};\n-\n-void GC_thread_exit_proc(void *arg)\n-{\n-    GC_thread me;\n-\n-    LOCK();\n-    me = GC_lookup_thread(pthread_self());\n-    if (me -> flags & DETACHED) {\n-    \tGC_delete_thread(pthread_self());\n-    } else {\n-\tme -> flags |= FINISHED;\n-    }\n-    UNLOCK();\n-}\n-\n-int GC_pthread_join(pthread_t thread, void **retval)\n-{\n-    int result;\n-    GC_thread thread_gc_id;\n-    \n-    LOCK();\n-    thread_gc_id = GC_lookup_thread(thread);\n-    /* This is guaranteed to be the intended one, since the thread id\t*/\n-    /* cant have been recycled by pthreads.\t\t\t\t*/\n-    UNLOCK();\n-    result = pthread_join(thread, retval);\n-    /* Some versions of the Irix pthreads library can erroneously \t*/\n-    /* return EINTR when the call succeeds.\t\t\t\t*/\n-\tif (EINTR == result) result = 0;\n-    LOCK();\n-    /* Here the pthread thread id may have been recycled. */\n-    GC_delete_gc_thread(thread, thread_gc_id);\n-    UNLOCK();\n-    return result;\n-}\n-\n-void * GC_start_routine(void * arg)\n-{\n-    struct start_info * si = arg;\n-    void * result;\n-    GC_thread me;\n-    pthread_t my_pthread;\n-    void *(*start)(void *);\n-    void *start_arg;\n-\n-    my_pthread = pthread_self();\n-    /* If a GC occurs before the thread is registered, that GC will\t*/\n-    /* ignore this thread.  That's fine, since it will block trying to  */\n-    /* acquire the allocation lock, and won't yet hold interesting \t*/\n-    /* pointers.\t\t\t\t\t\t\t*/\n-    LOCK();\n-    /* We register the thread here instead of in the parent, so that\t*/\n-    /* we don't need to hold the allocation lock during pthread_create. */\n-    /* Holding the allocation lock there would make REDIRECT_MALLOC\t*/\n-    /* impossible.  It probably still doesn't work, but we're a little  */\n-    /* closer ...\t\t\t\t\t\t\t*/\n-    /* This unfortunately means that we have to be careful the parent\t*/\n-    /* doesn't try to do a pthread_join before we're registered.\t*/\n-    me = GC_new_thread(my_pthread);\n-    me -> flags = si -> flags;\n-    me -> stack = si -> stack;\n-    me -> stack_size = si -> stack_size;\n-    me -> stack_ptr = (ptr_t)si -> stack + si -> stack_size - sizeof(word);\n-    UNLOCK();\n-    start = si -> start_routine;\n-    start_arg = si -> arg;\n-    sem_post(&(si -> registered));\n-    pthread_cleanup_push(GC_thread_exit_proc, 0);\n-    result = (*start)(start_arg);\n-    me -> status = result;\n-    me -> flags |= FINISHED;\n-    pthread_cleanup_pop(1);\n-\t/* This involves acquiring the lock, ensuring that we can't exit */\n-\t/* while a collection that thinks we're alive is trying to stop  */\n-\t/* us.\t\t\t\t\t\t\t\t */\n-    return(result);\n-}\n-\n-int\n-GC_pthread_create(pthread_t *new_thread,\n-\t\t  const pthread_attr_t *attr,\n-                  void *(*start_routine)(void *), void *arg)\n-{\n-    int result;\n-    GC_thread t;\n-    void * stack;\n-    size_t stacksize;\n-    pthread_attr_t new_attr;\n-    int detachstate;\n-    word my_flags = 0;\n-    struct start_info * si = GC_malloc(sizeof(struct start_info)); \n-\t/* This is otherwise saved only in an area mmapped by the thread */\n-\t/* library, which isn't visible to the collector.\t\t */\n-\n-    if (0 == si) return(ENOMEM);\n-    sem_init(&(si -> registered), 0, 0);\n-    si -> start_routine = start_routine;\n-    si -> arg = arg;\n-    LOCK();\n-    if (!GC_thr_initialized) GC_thr_init();\n-    if (NULL == attr) {\n-        stack = 0;\n-\t(void) pthread_attr_init(&new_attr);\n-    } else {\n-        new_attr = *attr;\n-\tpthread_attr_getstackaddr(&new_attr, &stack);\n-    }\n-    pthread_attr_getstacksize(&new_attr, &stacksize);\n-    pthread_attr_getdetachstate(&new_attr, &detachstate);\n-    if (stacksize < GC_min_stack_sz) ABORT(\"Stack too small\");\n-    if (0 == stack) {\n-     \tstack = (void *)GC_stack_alloc(&stacksize);\n-     \tif (0 == stack) {\n-     \t    UNLOCK();\n-     \t    return(ENOMEM);\n-     \t}\n-\tpthread_attr_setstackaddr(&new_attr, stack);\n-    } else {\n-    \tmy_flags |= CLIENT_OWNS_STACK;\n-    }\n-    if (PTHREAD_CREATE_DETACHED == detachstate) my_flags |= DETACHED;\n-    si -> flags = my_flags;\n-    si -> stack = stack;\n-    si -> stack_size = stacksize;\n-    result = pthread_create(new_thread, &new_attr, GC_start_routine, si);\n-    if (0 == new_thread && !(my_flags & CLIENT_OWNS_STACK)) {\n-      \tGC_stack_free(stack, stacksize);\n-    }        \n-    UNLOCK();  \n-    /* Wait until child has been added to the thread table.\t\t*/\n-    /* This also ensures that we hold onto si until the child is done\t*/\n-    /* with it.  Thus it doesn't matter whether it is otherwise\t\t*/\n-    /* visible to the collector.\t\t\t\t\t*/\n-        if (0 != sem_wait(&(si -> registered))) ABORT(\"sem_wait failed\");\n-        sem_destroy(&(si -> registered));\n-    /* pthread_attr_destroy(&new_attr); */\n-    return(result);\n-}\n-\n-GC_bool GC_collecting = 0; /* A hint that we're in the collector and       */\n-                        /* holding the allocation lock for an           */\n-                        /* extended period.                             */\n-\n-/* Reasonably fast spin locks.  Basically the same implementation */\n-/* as STL alloc.h.  This isn't really the right way to do this.   */\n-/* but until the POSIX scheduling mess gets straightened out ...  */\n-\n-unsigned long GC_allocate_lock = 0;\n-\n-#define SLEEP_THRESHOLD 3\n-\n-void GC_lock()\n-{\n-#   define low_spin_max 30  /* spin cycles if we suspect uniprocessor */\n-#   define high_spin_max 1000 /* spin cycles for multiprocessor */\n-    static unsigned spin_max = low_spin_max;\n-    unsigned my_spin_max;\n-    static unsigned last_spins = 0;\n-    unsigned my_last_spins;\n-    volatile unsigned junk;\n-#   define PAUSE junk *= junk; junk *= junk; junk *= junk; junk *= junk\n-    int i;\n-\n-    if (!GC_test_and_set(&GC_allocate_lock, 1)) {\n-        return;\n-    }\n-    junk = 0;\n-    my_spin_max = spin_max;\n-    my_last_spins = last_spins;\n-    for (i = 0; i < my_spin_max; i++) {\n-        if (GC_collecting) goto yield;\n-        if (i < my_last_spins/2 || GC_allocate_lock) {\n-            PAUSE; \n-            continue;\n-        }\n-        if (!GC_test_and_set(&GC_allocate_lock, 1)) {\n-\t    /*\n-             * got it!\n-             * Spinning worked.  Thus we're probably not being scheduled\n-             * against the other process with which we were contending.\n-             * Thus it makes sense to spin longer the next time.\n-\t     */\n-            last_spins = i;\n-            spin_max = high_spin_max;\n-            return;\n-        }\n-    }\n-    /* We are probably being scheduled against the other process.  Sleep. */\n-    spin_max = low_spin_max;\n-yield:\n-    for (i = 0;; ++i) {\n-        if (!GC_test_and_set(&GC_allocate_lock, 1)) {\n-            return;\n-        }\n-        if (i < SLEEP_THRESHOLD) {\n-            sched_yield();\n-\t} else {\n-\t    struct timespec ts;\n-\t\n-\t    if (i > 26) i = 26;\n-\t\t\t/* Don't wait for more than about 60msecs, even\t*/\n-\t\t\t/* under extreme contention.\t\t\t*/\n-\t    ts.tv_sec = 0;\n-\t    ts.tv_nsec = 1 << i;\n-\t    nanosleep(&ts, 0);\n-\t}\n-    }\n-}\n-\n-\n-\n-# else\n-\n-#ifndef LINT\n-  int GC_no_Irix_threads;\n-#endif\n-\n-# endif /* IRIX_THREADS */\n-"}, {"sha": "d6cab0af4ce7bc2aa27c7adbd942c56233223b22", "filename": "boehm-gc/linux_threads.c", "status": "modified", "additions": 130, "deletions": 49, "changes": 179, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Flinux_threads.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Flinux_threads.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Flinux_threads.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -36,16 +36,26 @@\n # if defined(LINUX_THREADS)\n \n # include <pthread.h>\n+# include <sched.h>\n # include <time.h>\n # include <errno.h>\n # include <unistd.h>\n # include <sys/mman.h>\n # include <sys/time.h>\n # include <semaphore.h>\n+# include <signal.h>\n+\n+#ifdef USE_LD_WRAP\n+#   define WRAP_FUNC(f) __wrap_##f\n+#   define REAL_FUNC(f) __real_##f\n+#else\n+#   define WRAP_FUNC(f) GC_##f\n+#   define REAL_FUNC(f) f\n+#   undef pthread_create\n+#   undef pthread_sigmask\n+#   undef pthread_join\n+#endif\n \n-#undef pthread_create\n-#undef pthread_sigmask\n-#undef pthread_join\n \n void GC_thr_init();\n \n@@ -86,8 +96,12 @@ typedef struct GC_Thread_Rep {\n #\tdefine DETACHED 2\t/* Thread is intended to be detached.\t*/\n #\tdefine MAIN_THREAD 4\t/* True for the original thread only.\t*/\n \n-    ptr_t stack_end;\n-    ptr_t stack_ptr;  \t\t/* Valid only when stopped. */\n+    ptr_t stack_end;\t\t/* Cold end of the stack.\t\t*/\n+    ptr_t stack_ptr;  \t\t/* Valid only when stopped.      \t*/\n+#   ifdef IA64\n+\tptr_t backing_store_end;\n+\tptr_t backing_store_ptr;\n+#   endif\n     int\tsignal;\n     void * status;\t\t/* The value returned from the thread.  */\n     \t\t\t\t/* Used only to avoid premature \t*/\n@@ -138,6 +152,10 @@ static inline ptr_t GC_linux_thread_top_of_stack(void)\n   return tos;\n }\n \n+#ifdef IA64\n+  extern word GC_save_regs_in_stack();\n+#endif\n+\n void GC_suspend_handler(int sig)\n {\n     int dummy;\n@@ -160,7 +178,9 @@ void GC_suspend_handler(int sig)\n     /* to stop the world.  Thus concurrent modification of the\t*/\n     /* data structure is impossible.\t\t\t\t*/\n     me -> stack_ptr = (ptr_t)(&dummy);\n-    me -> stack_end = GC_linux_thread_top_of_stack();\n+#   ifdef IA64\n+\tme -> backing_store_ptr = (ptr_t)GC_save_regs_in_stack();\n+#   endif\n \n     /* Tell the thread that wants to stop the world that this   */\n     /* thread has been stopped.  Note that sem_post() is  \t*/\n@@ -173,11 +193,11 @@ void GC_suspend_handler(int sig)\n     /* is no race.\t\t\t\t\t\t*/\n     if (sigfillset(&mask) != 0) ABORT(\"sigfillset() failed\");\n     if (sigdelset(&mask, SIG_RESTART) != 0) ABORT(\"sigdelset() failed\");\n-#ifdef NO_SIGNALS\n-    if (sigdelset(&mask, SIGINT) != 0) ABORT(\"sigdelset() failed\");\n-    if (sigdelset(&mask, SIGQUIT) != 0) ABORT(\"sigdelset() failed\");\n-    if (sigdelset(&mask, SIGTERM) != 0) ABORT(\"sigdelset() failed\");\n-#endif\n+#   ifdef NO_SIGNALS\n+      if (sigdelset(&mask, SIGINT) != 0) ABORT(\"sigdelset() failed\");\n+      if (sigdelset(&mask, SIGQUIT) != 0) ABORT(\"sigdelset() failed\");\n+      if (sigdelset(&mask, SIGTERM) != 0) ABORT(\"sigdelset() failed\");\n+#   endif\n     do {\n \t    me->signal = 0;\n \t    sigsuspend(&mask);             /* Wait for signal */\n@@ -380,13 +400,21 @@ void GC_start_world()\n     #endif\n }\n \n-/* We hold allocation lock.  We assume the world is stopped.\t*/\n+# ifdef IA64\n+#   define IF_IA64(x) x\n+# else\n+#   define IF_IA64(x)\n+# endif\n+/* We hold allocation lock.  Should do exactly the right thing if the\t*/\n+/* world is stopped.  Should not fail if it isn't.\t\t\t*/\n void GC_push_all_stacks()\n {\n-    register int i;\n-    register GC_thread p;\n-    register ptr_t sp = GC_approx_sp();\n-    register ptr_t lo, hi;\n+    int i;\n+    GC_thread p;\n+    ptr_t sp = GC_approx_sp();\n+    ptr_t lo, hi;\n+    /* On IA64, we also need to scan the register backing store. */\n+    IF_IA64(ptr_t bs_lo; ptr_t bs_hi;)\n     pthread_t me = pthread_self();\n     \n     if (!GC_thr_initialized) GC_thr_init();\n@@ -398,25 +426,33 @@ void GC_push_all_stacks()\n         if (p -> flags & FINISHED) continue;\n         if (pthread_equal(p -> id, me)) {\n \t    lo = GC_approx_sp();\n+\t    IF_IA64(bs_hi = (ptr_t)GC_save_regs_in_stack();)\n \t} else {\n \t    lo = p -> stack_ptr;\n+\t    IF_IA64(bs_hi = p -> backing_store_ptr;)\n \t}\n         if ((p -> flags & MAIN_THREAD) == 0) {\n-\t    if (pthread_equal(p -> id, me)) {\n-\t\thi = GC_linux_thread_top_of_stack();\n-\t    } else {\n-\t\thi = p -> stack_end;\n-\t    }\n+\t    hi = p -> stack_end;\n+\t    IF_IA64(bs_lo = p -> backing_store_end);\n         } else {\n             /* The original stack. */\n             hi = GC_stackbottom;\n+\t    IF_IA64(bs_lo = BACKING_STORE_BASE;)\n         }\n         #if DEBUG_THREADS\n             GC_printf3(\"Stack for thread 0x%lx = [%lx,%lx)\\n\",\n     \t        (unsigned long) p -> id,\n \t\t(unsigned long) lo, (unsigned long) hi);\n         #endif\n+\tif (0 == lo) ABORT(\"GC_push_all_stacks: sp not set!\\n\");\n         GC_push_all_stack(lo, hi);\n+#\tifdef IA64\n+          if (pthread_equal(p -> id, me)) {\n+\t    GC_push_all_eager(bs_lo, bs_hi);\n+\t  } else {\n+\t    GC_push_all_stack(bs_lo, bs_hi);\n+\t  }\n+#\tendif\n       }\n     }\n }\n@@ -425,6 +461,7 @@ void GC_push_all_stacks()\n /* We hold the allocation lock.\t*/\n void GC_thr_init()\n {\n+    int dummy;\n     GC_thread t;\n     struct sigaction act;\n \n@@ -439,19 +476,13 @@ void GC_thr_init()\n     \tABORT(\"sigfillset() failed\");\n     }\n \n-#ifdef NO_SIGNALS\n-    if (sigdelset(&act.sa_mask, SIGINT) != 0) {\n-       ABORT(\"sigdelset() failed\");\n-    }\n-\n-    if (sigdelset(&act.sa_mask, SIGQUIT) != 0) {\n-       ABORT(\"sigdelset() failed\");\n-    }\n-\n-    if (sigdelset(&act.sa_mask, SIGTERM) != 0) {\n-       ABORT(\"sigdelset() failed\");\n-    }\n-#endif\n+#   ifdef NO_SIGNALS\n+      if (sigdelset(&act.sa_mask, SIGINT) != 0\n+\t  || sigdelset(&act.sa_mask, SIGQUIT != 0)\n+\t  || sigdelset(&act.sa_mask, SIGTERM != 0)) {\n+        ABORT(\"sigdelset() failed\");\n+      }\n+#   endif\n \n     /* SIG_RESTART is unmasked by the handler when necessary. \t*/\n     act.sa_handler = GC_suspend_handler;\n@@ -466,11 +497,11 @@ void GC_thr_init()\n \n     /* Add the initial thread, so we can stop it.\t*/\n       t = GC_new_thread(pthread_self());\n-      t -> stack_ptr = 0;\n+      t -> stack_ptr = (ptr_t)(&dummy);\n       t -> flags = DETACHED | MAIN_THREAD;\n }\n \n-int GC_pthread_sigmask(int how, const sigset_t *set, sigset_t *oset)\n+int WRAP_FUNC(pthread_sigmask)(int how, const sigset_t *set, sigset_t *oset)\n {\n     sigset_t fudged_set;\n     \n@@ -479,7 +510,7 @@ int GC_pthread_sigmask(int how, const sigset_t *set, sigset_t *oset)\n         sigdelset(&fudged_set, SIG_SUSPEND);\n         set = &fudged_set;\n     }\n-    return(pthread_sigmask(how, set, oset));\n+    return(REAL_FUNC(pthread_sigmask)(how, set, oset));\n }\n \n struct start_info {\n@@ -503,10 +534,25 @@ void GC_thread_exit_proc(void *arg)\n     } else {\n \tme -> flags |= FINISHED;\n     }\n+    if (GC_incremental && GC_collection_in_progress()) {\n+\tint old_gc_no = GC_gc_no;\n+\n+\t/* Make sure that no part of our stack is still on the mark stack, */\n+\t/* since it's about to be unmapped.\t\t\t\t   */\n+\twhile (GC_incremental && GC_collection_in_progress()\n+\t       && old_gc_no == GC_gc_no) {\n+\t    ENTER_GC();\n+            GC_collect_a_little_inner(1);\n+\t    EXIT_GC();\n+\t    UNLOCK();\n+\t    sched_yield();\n+\t    LOCK();\n+\t}\n+    }\n     UNLOCK();\n }\n \n-int GC_pthread_join(pthread_t thread, void **retval)\n+int WRAP_FUNC(pthread_join)(pthread_t thread, void **retval)\n {\n     int result;\n     GC_thread thread_gc_id;\n@@ -516,7 +562,7 @@ int GC_pthread_join(pthread_t thread, void **retval)\n     /* This is guaranteed to be the intended one, since the thread id\t*/\n     /* cant have been recycled by pthreads.\t\t\t\t*/\n     UNLOCK();\n-    result = pthread_join(thread, retval);\n+    result = REAL_FUNC(pthread_join)(thread, retval);\n     LOCK();\n     /* Here the pthread thread id may have been recycled. */\n     GC_delete_gc_thread(thread, thread_gc_id);\n@@ -526,6 +572,7 @@ int GC_pthread_join(pthread_t thread, void **retval)\n \n void * GC_start_routine(void * arg)\n {\n+    int dummy;\n     struct start_info * si = arg;\n     void * result;\n     GC_thread me;\n@@ -534,22 +581,45 @@ void * GC_start_routine(void * arg)\n     void *start_arg;\n \n     my_pthread = pthread_self();\n+#   ifdef DEBUG_THREADS\n+        GC_printf1(\"Starting thread 0x%lx\\n\", my_pthread);\n+        GC_printf1(\"pid = %ld\\n\", (long) getpid());\n+        GC_printf1(\"sp = 0x%lx\\n\", (long) &arg);\n+#   endif\n     LOCK();\n     me = GC_new_thread(my_pthread);\n     me -> flags = si -> flags;\n     me -> stack_ptr = 0;\n-    me -> stack_end = 0;\n+    /* me -> stack_end = GC_linux_stack_base(); -- currently (11/99)\t*/\n+    /* doesn't work because the stack base in /proc/self/stat is the \t*/\n+    /* one for the main thread.  There is a strong argument that that's\t*/\n+    /* a kernel bug, but a pervasive one.\t\t\t\t*/\n+#   ifdef STACK_GROWS_DOWN\n+      me -> stack_end = (ptr_t)(((word)(&dummy) + (GC_page_size - 1))\n+\t\t                & ~(GC_page_size - 1));\n+      me -> stack_ptr = me -> stack_end - 0x10;\n+\t/* Needs to be plausible, since an asynchronous stack mark\t*/\n+\t/* should not crash.\t\t\t\t\t\t*/\n+#   else\n+      me -> stack_end = (ptr_t)(((word)(&dummy) & ~(GC_page_size - 1));\n+      me -> stack_ptr = me -> stack_end + 0x10;\n+#   endif\n+    /* This is dubious, since we may be more than a page into the stack, */\n+    /* and hence skip some of it, though it's not clear that matters.\t */\n+#   ifdef IA64\n+      me -> backing_store_end = (ptr_t)\n+\t\t\t(GC_save_regs_in_stack() & ~(GC_page_size - 1));\n+      /* This is also < 100% convincing.  We should also read this \t*/\n+      /* from /proc, but the hook to do so isn't there yet.\t\t*/\n+#   endif /* IA64 */\n     UNLOCK();\n     start = si -> start_routine;\n-    start_arg = si -> arg;\n-    sem_post(&(si -> registered));\n-    pthread_cleanup_push(GC_thread_exit_proc, si);\n #   ifdef DEBUG_THREADS\n-        GC_printf1(\"Starting thread 0x%lx\\n\", pthread_self());\n-        GC_printf1(\"pid = %ld\\n\", (long) getpid());\n-        GC_printf1(\"sp = 0x%lx\\n\", (long) &arg);\n \tGC_printf1(\"start_routine = 0x%lx\\n\", start);\n #   endif\n+    start_arg = si -> arg;\n+    sem_post(&(si -> registered));\n+    pthread_cleanup_push(GC_thread_exit_proc, si);\n     result = (*start)(start_arg);\n #if DEBUG_THREADS\n         GC_printf1(\"Finishing thread 0x%x\\n\", pthread_self());\n@@ -564,7 +634,7 @@ void * GC_start_routine(void * arg)\n }\n \n int\n-GC_pthread_create(pthread_t *new_thread,\n+WRAP_FUNC(pthread_create)(pthread_t *new_thread,\n \t\t  const pthread_attr_t *attr,\n                   void *(*start_routine)(void *), void *arg)\n {\n@@ -596,7 +666,14 @@ GC_pthread_create(pthread_t *new_thread,\n     if (PTHREAD_CREATE_DETACHED == detachstate) my_flags |= DETACHED;\n     si -> flags = my_flags;\n     UNLOCK();\n-    result = pthread_create(new_thread, &new_attr, GC_start_routine, si);\n+#   ifdef DEBUG_THREADS\n+        GC_printf1(\"About to start new thread from thread 0x%X\\n\",\n+\t\t   pthread_self());\n+#   endif\n+    result = REAL_FUNC(pthread_create)(new_thread, &new_attr, GC_start_routine, si);\n+#   ifdef DEBUG_THREADS\n+        GC_printf1(\"Started thread 0x%X\\n\", *new_thread);\n+#   endif\n     /* Wait until child has been added to the thread table.\t\t*/\n     /* This also ensures that we hold onto si until the child is done\t*/\n     /* with it.  Thus it doesn't matter whether it is otherwise\t\t*/\n@@ -608,7 +685,9 @@ GC_pthread_create(pthread_t *new_thread,\n     return(result);\n }\n \n-GC_bool GC_collecting = 0;\n+#if defined(USE_SPIN_LOCK)\n+\n+VOLATILE GC_bool GC_collecting = 0;\n \t\t\t/* A hint that we're in the collector and       */\n                         /* holding the allocation lock for an           */\n                         /* extended period.                             */\n@@ -681,5 +760,7 @@ void GC_lock()\n     }\n }\n \n+#endif /* known architecture */\n+\n # endif /* LINUX_THREADS */\n "}, {"sha": "12c3f07603fe7ef66b18b67863a45d2d459ea5c9", "filename": "boehm-gc/mach_dep.c", "status": "modified", "additions": 52, "deletions": 16, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmach_dep.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmach_dep.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmach_dep.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -80,6 +80,24 @@ void GC_push_regs()\n #       ifdef RT\n \t  register long TMP_SP; /* must be bound to r11 */\n #       endif\n+\n+#       if defined(MIPS) && defined(LINUX)\n+\t  /* I'm not sure whether this has actually been tested. */\n+#         define call_push(x)     asm(\"move $4,\" x \";\"); asm(\"jal GC_push_one\")\n+\t  call_push(\"$2\");\n+\t  call_push(\"$3\");\n+\t  call_push(\"$16\");\n+\t  call_push(\"$17\");\n+\t  call_push(\"$18\");\n+\t  call_push(\"$19\");\n+\t  call_push(\"$20\");\n+\t  call_push(\"$21\");\n+\t  call_push(\"$22\");\n+\t  call_push(\"$23\");\n+\t  call_push(\"$30\");\n+#         undef call_push\n+#       endif\t/* MIPS && LINUX */\n+\n #       ifdef VAX\n \t  /* VAX - generic code below does not work under 4.2 */\n \t  /* r1 through r5 are caller save, and therefore     */\n@@ -199,10 +217,11 @@ void GC_push_regs()\n #\tendif\t/* __MWERKS__ */\n #   endif\t/* MACOS */\n \n-#       if defined(I386) &&!defined(OS2) &&!defined(SVR4) &&!defined(MSWIN32) \\\n+#       if defined(I386) &&!defined(OS2) &&!defined(SVR4) \\\n+\t&& (defined(__MINGW32__) || !defined(MSWIN32)) \\\n \t&& !defined(SCO) && !defined(SCO_ELF) \\\n  \t&& !(defined(LINUX)       && defined(__ELF__)) \\\n-\t&& !(defined(__FreeBSD__) && defined(__ELF__)) \\\n+\t&& !(defined(FREEBSD) && defined(__ELF__)) \\\n \t&& !defined(DOS4GW)\n \t/* I386 code, generic code does not appear to work */\n \t/* It does appear to work under OS2, and asms dont */\n@@ -217,20 +236,25 @@ void GC_push_regs()\n #       endif\n \n #\tif ( defined(I386) && defined(LINUX) && defined(__ELF__) ) \\\n-\t|| ( defined(I386) && defined(__FreeBSD__) && defined(__ELF__) )\n+\t|| ( defined(I386) && defined(FREEBSD) && defined(__ELF__) )\n \n \t/* This is modified for Linux with ELF (Note: _ELF_ only) */\n \t/* This section handles FreeBSD with ELF. */\n-\t  asm(\"pushl %eax\");  asm(\"call GC_push_one\"); asm(\"addl $4,%esp\");\n-\t  asm(\"pushl %ecx\");  asm(\"call GC_push_one\"); asm(\"addl $4,%esp\");\n-\t  asm(\"pushl %edx\");  asm(\"call GC_push_one\"); asm(\"addl $4,%esp\");\n-\t  asm(\"pushl %ebp\");  asm(\"call GC_push_one\"); asm(\"addl $4,%esp\");\n-\t  asm(\"pushl %esi\");  asm(\"call GC_push_one\"); asm(\"addl $4,%esp\");\n-\t  asm(\"pushl %edi\");  asm(\"call GC_push_one\"); asm(\"addl $4,%esp\");\n-\t  asm(\"pushl %ebx\");  asm(\"call GC_push_one\"); asm(\"addl $4,%esp\");\n+\t/* Eax is caller-save and dead here.  Other caller-save \t*/\n+\t/* registers could also be skipped.  We assume there are no\t*/\n+\t/* pointers in MMX registers, etc.\t\t\t\t*/\n+\t/* We combine instructions in a single asm to prevent gcc from \t*/\n+\t/* inserting code in the middle.\t\t\t\t*/\n+\t  asm(\"pushl %ecx; call GC_push_one; addl $4,%esp\");\n+\t  asm(\"pushl %edx; call GC_push_one; addl $4,%esp\");\n+\t  asm(\"pushl %ebp; call GC_push_one; addl $4,%esp\");\n+\t  asm(\"pushl %esi; call GC_push_one; addl $4,%esp\");\n+\t  asm(\"pushl %edi; call GC_push_one; addl $4,%esp\");\n+\t  asm(\"pushl %ebx; call GC_push_one; addl $4,%esp\");\n #\tendif\n \n-#       if defined(I386) && defined(MSWIN32) && !defined(USE_GENERIC)\n+#       if defined(I386) && defined(MSWIN32) && !defined(__MINGW32__) \\\n+\t   && !defined(USE_GENERIC)\n \t/* I386 code, Microsoft variant\t\t*/\n \t  __asm  push eax\n \t  __asm  call GC_push_one\n@@ -274,11 +298,10 @@ void GC_push_regs()\n \t  asm (\"movd r7, tos\"); asm (\"bsr ?_GC_push_one\"); asm (\"adjspb $-4\");\n #       endif\n \n-#       if defined(SPARC) || defined(IA64)\n+#       if defined(SPARC)\n \t  {\n \t      word GC_save_regs_in_stack();\n \t      \n-\t      /* generic code will not work */\n \t      GC_save_regs_ret_val = GC_save_regs_in_stack();\n \t  }\n #       endif\n@@ -351,8 +374,8 @@ void GC_push_regs()\n       /* other machines... */\n #       if !(defined M68K) && !(defined VAX) && !(defined RT) \n #\tif !(defined SPARC) && !(defined I386) && !(defined NS32K)\n-#\tif !defined(POWERPC) && !defined(UTS4) && !defined(IA64)\n-#       if !defined(PJ)\n+#\tif !defined(POWERPC) && !defined(UTS4) \n+#       if !defined(PJ) && !(defined(MIPS) && defined(LINUX))\n \t    --> bad news <--\n #\tendif\n #       endif\n@@ -379,11 +402,24 @@ ptr_t cold_gc_frame;\n \t\tfor (; (char *)i < lim; i++) {\n \t\t    *i = 0;\n \t\t}\n-#\t    if defined(POWERPC) || defined(MSWIN32) || defined(UTS4)\n+#\t    if defined(POWERPC) || defined(MSWIN32) || defined(UTS4) || defined(LINUX)\n \t\t(void) setjmp(regs);\n #\t    else\n \t        (void) _setjmp(regs);\n #\t    endif\n+#           if defined(SPARC) || defined(IA64)\n+\t      /* On a register window machine, we need to save register\t*/\n+\t      /* contents on the stack for this to work.  The setjmp\t*/\n+\t      /* is probably not needed on SPARC, since pointers are\t*/\n+\t      /* only stored in windowed or scratch registers.  It is\t*/\n+\t      /* needed on IA64, since some non-windowed registers are\t*/\n+\t      /* preserved.\t\t\t\t\t\t*/\n+\t      {\n+\t        word GC_save_regs_in_stack();\n+\t      \n+\t        GC_save_regs_ret_val = GC_save_regs_in_stack();\n+\t      }\n+#           endif\n \t    GC_push_current_stack(cold_gc_frame);\n \t}\n }"}, {"sha": "a5a93ad81192e823f7e376608ed7f5b5051f5e5b", "filename": "boehm-gc/malloc.c", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmalloc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmalloc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmalloc.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -81,6 +81,10 @@ register ptr_t *opp;\n         /* but that's benign.\t\t\t\t*/\n         /* Volatile declarations may need to be added\t*/\n         /* to prevent the compiler from breaking things.*/\n+\t/* If we only execute the second of the \t*/\n+\t/* following assignments, we lose the free\t*/\n+\t/* list, but that should still be OK, at least\t*/\n+\t/* for garbage collected memory.\t\t*/\n         *opp = obj_link(op);\n         obj_link(op) = 0;\n     } else {"}, {"sha": "c842665237ee0d70f7d5300a07847185deed7abb", "filename": "boehm-gc/mallocx.c", "status": "modified", "additions": 23, "deletions": 11, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmallocx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmallocx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmallocx.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -134,22 +134,14 @@ void GC_incr_mem_freed(size_t n)\n \n /* Analogous to the above, but assumes a small object size, and \t*/\n /* bypasses MERGE_SIZES mechanism.  Used by gc_inline.h.\t\t*/\n-#ifdef __STDC__\n-     ptr_t GC_generic_malloc_words_small(size_t lw, int k)\n-#else \n-     ptr_t GC_generic_malloc_words_small(lw, k)\n-     register word lw;\n-     register int k;\n-#endif\n+ptr_t GC_generic_malloc_words_small_inner(lw, k)\n+register word lw;\n+register int k;\n {\n register ptr_t op;\n register ptr_t *opp;\n register struct obj_kind * kind = GC_obj_kinds + k;\n-DCL_LOCK_STATE;\n \n-    GC_INVOKE_FINALIZERS();\n-    DISABLE_SIGNALS();\n-    LOCK();\n     opp = &(kind -> ok_freelist[lw]);\n     if( (op = *opp) == 0 ) {\n         if (!GC_is_initialized) {\n@@ -167,6 +159,26 @@ DCL_LOCK_STATE;\n     *opp = obj_link(op);\n     obj_link(op) = 0;\n     GC_words_allocd += lw;\n+    return((ptr_t)op);\n+}\n+\n+/* Analogous to the above, but assumes a small object size, and \t*/\n+/* bypasses MERGE_SIZES mechanism.  Used by gc_inline.h.\t\t*/\n+#ifdef __STDC__\n+     ptr_t GC_generic_malloc_words_small(size_t lw, int k)\n+#else \n+     ptr_t GC_generic_malloc_words_small(lw, k)\n+     register word lw;\n+     register int k;\n+#endif\n+{\n+register ptr_t op;\n+DCL_LOCK_STATE;\n+\n+    GC_INVOKE_FINALIZERS();\n+    DISABLE_SIGNALS();\n+    LOCK();\n+    op = GC_generic_malloc_words_small_inner(lw, k);\n     UNLOCK();\n     ENABLE_SIGNALS();\n     return((ptr_t)op);"}, {"sha": "d164702bf1ead65e4abe16f891b1e92ab7b10c3f", "filename": "boehm-gc/mark.c", "status": "modified", "additions": 105, "deletions": 21, "changes": 126, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmark.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmark.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmark.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -38,7 +38,7 @@ word x;\n \n /* mark_proc GC_mark_procs[MAX_MARK_PROCS] = {0} -- declared in gc_priv.h */\n \n-word GC_n_mark_procs = 0;\n+word GC_n_mark_procs = GC_RESERVED_MARK_PROCS;\n \n /* Initialize GC_obj_kinds properly and standard free lists properly.  \t*/\n /* This must be done statically since they may be accessed before \t*/\n@@ -365,20 +365,20 @@ GC_bool GC_mark_stack_empty()\n /* with IGNORE_OFF_PAGE set.\t\t\t\t\t\t*/\n /*ARGSUSED*/\n # ifdef PRINT_BLACK_LIST\n-  word GC_find_start(current, hhdr, source)\n+  ptr_t GC_find_start(current, hhdr, source)\n   word source;\n # else\n-  word GC_find_start(current, hhdr)\n+  ptr_t GC_find_start(current, hhdr)\n # define source 0\n # endif\n-register word current;\n+register ptr_t current;\n register hdr * hhdr;\n {\n #   ifdef ALL_INTERIOR_POINTERS\n \tif (hhdr != 0) {\n-\t    register word orig = current;\n+\t    register ptr_t orig = current;\n \t    \n-\t    current = (word)HBLKPTR(current) + HDR_BYTES;\n+\t    current = (ptr_t)HBLKPTR(current) + HDR_BYTES;\n \t    do {\n \t      current = current - HBLKSIZE*(word)hhdr;\n \t      hhdr = HDR(current);\n@@ -429,6 +429,12 @@ mse * msp;\n  * is never 0.  A mark stack entry never has size 0.\n  * We try to traverse on the order of a hblk of memory before we return.\n  * Caller is responsible for calling this until the mark stack is empty.\n+ * Note that this is the most performance critical routine in the\n+ * collector.  Hence it contains all sorts of ugly hacks to speed\n+ * things up.  In particular, we avoid procedure calls on the common\n+ * path, we take advantage of peculiarities of the mark descriptor\n+ * encoding, we optionally maintain a cache for the block address to\n+ * header mapping, we prefetch when an object is \"grayed\", etc. \n  */\n void GC_mark_from_mark_stack()\n {\n@@ -443,18 +449,26 @@ void GC_mark_from_mark_stack()\n   register word descr;\n   register ptr_t greatest_ha = GC_greatest_plausible_heap_addr;\n   register ptr_t least_ha = GC_least_plausible_heap_addr;\n+  DECLARE_HDR_CACHE;\n+\n # define SPLIT_RANGE_WORDS 128  /* Must be power of 2.\t\t*/\n \n   GC_objects_are_marked = TRUE;\n+  INIT_HDR_CACHE;\n # ifdef OS2 /* Use untweaked version to circumvent compiler problem */\n   while (GC_mark_stack_top_reg >= GC_mark_stack_reg && credit >= 0) {\n # else\n   while ((((ptr_t)GC_mark_stack_top_reg - (ptr_t)GC_mark_stack_reg) | credit)\n   \t>= 0) {\n # endif\n     current_p = GC_mark_stack_top_reg -> mse_start;\n-  retry:\n     descr = GC_mark_stack_top_reg -> mse_descr;\n+  retry:\n+    /* current_p and descr describe the current object.\t\t*/\n+    /* *GC_mark_stack_top_reg is vacant.\t\t\t*/\n+    /* The following is 0 only for small objects described by a simple\t*/\n+    /* length descriptor.  For many applications this is the common\t*/\n+    /* case, so we try to detect it quickly.\t\t\t\t*/\n     if (descr & ((~(WORDS_TO_BYTES(SPLIT_RANGE_WORDS) - 1)) | DS_TAGS)) {\n       word tag = descr & DS_TAGS;\n       \n@@ -465,8 +479,8 @@ void GC_mark_from_mark_stack()\n           /* stack.\t\t\t\t\t\t\t*/\n           GC_mark_stack_top_reg -> mse_start =\n          \tlimit = current_p + SPLIT_RANGE_WORDS-1;\n-          GC_mark_stack_top_reg -> mse_descr -=\n-          \t\tWORDS_TO_BYTES(SPLIT_RANGE_WORDS-1);\n+          GC_mark_stack_top_reg -> mse_descr =\n+          \t\tdescr - WORDS_TO_BYTES(SPLIT_RANGE_WORDS-1);\n           /* Make sure that pointers overlapping the two ranges are\t*/\n           /* considered. \t\t\t\t\t\t*/\n           limit = (word *)((char *)limit + sizeof(word) - ALIGNMENT);\n@@ -479,8 +493,8 @@ void GC_mark_from_mark_stack()\n             if ((signed_word)descr < 0) {\n               current = *current_p;\n \t      if ((ptr_t)current >= least_ha && (ptr_t)current < greatest_ha) {\n-                PUSH_CONTENTS(current, GC_mark_stack_top_reg, mark_stack_limit,\n-\t\t\t      current_p, exit1);\n+                PUSH_CONTENTS((ptr_t)current, GC_mark_stack_top_reg,\n+\t\t\t      mark_stack_limit, current_p, exit1);\n \t      }\n             }\n \t    descr <<= 1;\n@@ -499,24 +513,94 @@ void GC_mark_from_mark_stack()\n               \t    mark_stack_limit, ENV(descr));\n           continue;\n         case DS_PER_OBJECT:\n-          GC_mark_stack_top_reg -> mse_descr =\n-\t\t\t*(word *)((ptr_t)current_p + descr - tag);\n+\t  if ((signed_word)descr >= 0) {\n+\t    /* Descriptor is in the object.\t*/\n+            descr = *(word *)((ptr_t)current_p + descr - DS_PER_OBJECT);\n+\t  } else {\n+\t    /* Descriptor is in type descriptor pointed to by first\t*/\n+\t    /* word in object.\t\t\t\t\t\t*/\n+\t    ptr_t type_descr = *(ptr_t *)current_p;\n+\t    /* type_descr is either a valid pointer to the descriptor\t*/\n+\t    /* structure, or this object was on a free list.  If it \t*/\n+\t    /* it was anything but the last object on the free list,\t*/\n+\t    /* we will misinterpret the next object on the free list as */\n+\t    /* the type descriptor, and get a 0 GC descriptor, which\t*/\n+\t    /* is ideal.  Unfortunately, we need to check for the last\t*/\n+\t    /* object case explicitly.\t\t\t\t\t*/\n+\t    if (0 == type_descr) {\n+\t\t/* Rarely executed.\t*/\n+\t\tGC_mark_stack_top_reg--;\n+\t\tcontinue;\n+\t    }\n+            descr = *(word *)(type_descr\n+\t\t\t      - (descr - (DS_PER_OBJECT - INDIR_PER_OBJ_BIAS)));\n+\t  }\n           goto retry;\n       }\n-    } else {\n+    } else /* Small object with length descriptor */ {\n       GC_mark_stack_top_reg--;\n       limit = (word *)(((ptr_t)current_p) + (word)descr);\n     }\n     /* The simple case in which we're scanning a range.\t*/\n     credit -= (ptr_t)limit - (ptr_t)current_p;\n     limit -= 1;\n-    while (current_p <= limit) {\n-      current = *current_p;\n-      if ((ptr_t)current >= least_ha && (ptr_t)current <  greatest_ha) {\n-        PUSH_CONTENTS(current, GC_mark_stack_top_reg,\n-\t\t      mark_stack_limit, current_p, exit2);\n+    {\n+#     define PREF_DIST 4\n+\n+#     ifndef SMALL_CONFIG\n+        word deferred;\n+\n+\t/* Try to prefetch the next pointer to be examined asap.\t*/\n+\t/* Empirically, this also seems to help slightly without\t*/\n+\t/* prefetches, at least on linux/X86.  Presumably this loop \t*/\n+\t/* ends up with less register pressure, and gcc thus ends up \t*/\n+\t/* generating slightly better code.  Overall gcc code quality\t*/\n+\t/* for this loop is still not great.\t\t\t\t*/\n+\tfor(;;) {\n+\t  PREFETCH((ptr_t)limit - PREF_DIST*CACHE_LINE_SIZE);\n+\t  deferred = *limit;\n+\t  limit = (word *)((char *)limit - ALIGNMENT);\n+\t  if ((ptr_t)deferred >= least_ha && (ptr_t)deferred <  greatest_ha) {\n+\t    PREFETCH(deferred);\n+\t    break;\n+\t  }\n+\t  if (current_p > limit) goto next_object;\n+\t  /* Unroll once, so we don't do too many of the prefetches \t*/\n+\t  /* based on limit.\t\t\t\t\t\t*/\n+\t  deferred = *limit;\n+\t  limit = (word *)((char *)limit - ALIGNMENT);\n+\t  if ((ptr_t)deferred >= least_ha && (ptr_t)deferred <  greatest_ha) {\n+\t    PREFETCH(deferred);\n+\t    break;\n+\t  }\n+\t  if (current_p > limit) goto next_object;\n+\t}\n+#     endif\n+\n+      while (current_p <= limit) {\n+\t/* Empirically, unrolling this loop doesn't help a lot.\t*/\n+\t/* Since HC_PUSH_CONTENTS expands to a lot of code,\t*/\n+\t/* we don't.\t\t\t\t\t\t*/\n+        current = *current_p;\n+        PREFETCH((ptr_t)current_p + PREF_DIST*CACHE_LINE_SIZE);\n+        if ((ptr_t)current >= least_ha && (ptr_t)current <  greatest_ha) {\n+  \t  /* Prefetch the contents of the object we just pushed.  It's\t*/\n+  \t  /* likely we will need them soon.\t\t\t\t*/\n+  \t  PREFETCH(current);\n+          HC_PUSH_CONTENTS((ptr_t)current, GC_mark_stack_top_reg,\n+  \t\t           mark_stack_limit, current_p, exit2);\n+        }\n+        current_p = (word *)((char *)current_p + ALIGNMENT);\n       }\n-      current_p = (word *)((char *)current_p + ALIGNMENT);\n+\n+#     ifndef SMALL_CONFIG\n+\t/* We still need to mark the entry we previously prefetched.\t*/\n+\t/* We alrady know that it passes the preliminary pointer\t*/\n+\t/* validity test.\t\t\t\t\t\t*/\n+        HC_PUSH_CONTENTS((ptr_t)deferred, GC_mark_stack_top_reg,\n+  \t\t         mark_stack_limit, current_p, exit4);\n+\tnext_object:;\n+#     endif\n     }\n   }\n   GC_mark_stack_top = GC_mark_stack_top_reg;\n@@ -689,7 +773,7 @@ word p;\n \treturn;\n       }\n #   endif\n-    GC_PUSH_ONE_STACK(p, 0);\n+    GC_PUSH_ONE_STACK(p, MARKED_FROM_REGISTER);\n }\n \n # ifdef __STDC__"}, {"sha": "5bafd07ed897b40a5ed72fe75a967e73dbfc7358", "filename": "boehm-gc/mark_rts.c", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmark_rts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmark_rts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmark_rts.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -412,9 +412,8 @@ ptr_t cold_gc_frame;\n \tif (0 == cold_gc_frame) return;\n #       ifdef STACK_GROWS_DOWN\n     \t  GC_push_all_eager(GC_approx_sp(), cold_gc_frame);\n-#\t  ifdef IA64\n-\t    --> fix this\n-#\t  endif\n+\t  /* For IA64, the register stack backing store is handled \t*/\n+\t  /* in the thread-specific code.\t\t\t\t*/\n #       else\n \t  GC_push_all_eager( cold_gc_frame, GC_approx_sp() );\n #       endif\n@@ -505,6 +504,9 @@ ptr_t cold_gc_frame;\n \t/* In the USE_GENERIC_PUSH_REGS case, this is done inside\t*/\n \t/* GC_push_regs, so that we catch callee-save registers saved\t*/\n \t/* inside the GC_push_regs frame.\t\t\t\t*/\n+\t/* In the case of linux threads on Ia64, the hot section of\t*/\n+\t/* the main stack is marked here, but the register stack\t*/\n+\t/* backing store is handled in the threads-specific code.\t*/\n #   endif\n     if (GC_push_other_roots != 0) (*GC_push_other_roots)();\n     \t/* In the threads case, this also pushes thread stacks.\t*/"}, {"sha": "dd42961c4b385cb4ec7e245576df79ce47c63e2a", "filename": "boehm-gc/misc.c", "status": "modified", "additions": 17, "deletions": 4, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmisc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fmisc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmisc.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -42,11 +42,12 @@\n #          ifdef WIN32_THREADS\n \t      GC_API CRITICAL_SECTION GC_allocate_ml;\n #          else\n-#             if defined(IRIX_THREADS) || defined(LINUX_THREADS) \\\n-\t\t || defined(IRIX_JDK_THREADS)\n+#             if defined(IRIX_THREADS) || defined(IRIX_JDK_THREADS) \\\n+\t\t || (defined(LINUX_THREADS) && defined(USE_SPIN_LOCK))\n \t        pthread_t GC_lock_holder = NO_THREAD;\n #\t      else\n-#\t        if defined(HPUX_THREADS)\n+#\t        if defined(HPUX_THREADS) \\\n+\t\t   || defined(LINUX_THREADS) && !defined(USE_SPIN_LOCK)\n \t\t  pthread_mutex_t GC_allocate_ml = PTHREAD_MUTEX_INITIALIZER;\n #\t\telse \n \t          --> declare allocator lock here\n@@ -123,6 +124,15 @@ extern signed_word GC_mem_found;\n \tfor (i = 8*sizeof(word) + 1; i <= 16 * sizeof(word); i++) {\n \t      GC_size_map[i] = (ROUNDED_UP_WORDS(i) + 1) & (~1);\n \t}\n+#\tifdef GC_GCJ_SUPPORT\n+\t   /* Make all sizes up to 32 words predictable, so that a \t*/\n+\t   /* compiler can statically perform the same computation,\t*/\n+\t   /* or at least a computation that results in similar size\t*/\n+\t   /* classes.\t\t\t\t\t\t\t*/\n+\t   for (i = 16*sizeof(word) + 1; i <= 32 * sizeof(word); i++) {\n+\t      GC_size_map[i] = (ROUNDED_UP_WORDS(i) + 3) & (~3);\n+\t   }\n+#\tendif\n \t/* We leave the rest of the array to be filled in on demand. */\n     }\n     \n@@ -443,7 +453,8 @@ void GC_init_inner()\n #   ifdef MSWIN32\n  \tGC_init_win32();\n #   endif\n-#   if defined(LINUX) && (defined(SPARC) || defined(IA64))\n+#   if defined(SEARCH_FOR_DATA_START)\n+\t/* This doesn't really work if the collector is in a shared library. */\n \tGC_init_linux_data_start();\n #   endif\n #   ifdef SOLARIS_THREADS\n@@ -819,6 +830,8 @@ struct callinfo info[NFRAMES];\n \n #endif /* SAVE_CALL_CHAIN */\n \n+/* Needed by SRC_M3, gcj, and should perhaps be the official interface\t*/\n+/* to GC_dont_gc.\t\t\t\t\t\t\t*/\n void GC_enable()\n {\n     GC_dont_gc--;"}, {"sha": "1e1273f854ef54f673ee805e8667c900d5f8d449", "filename": "boehm-gc/new_hblk.c", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fnew_hblk.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fnew_hblk.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fnew_hblk.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -103,10 +103,10 @@ ptr_t ofl;\n     p[3] = 0;\n     p += 4;\n     for (; p < lim; p += 4) {\n+\tPREFETCH_FOR_WRITE(p+64);\n         p[0] = (word)(p-4);\n         p[1] = 0;\n-        p[2] = 0;\n-        p[3] = 0;\n+\tCLEAR_DOUBLE(p+2);\n     };\n     return((ptr_t)(p-4));\n }\n@@ -141,6 +141,7 @@ ptr_t ofl;\n     p[4] = (word)p;\n     p += 8;\n     for (; p < lim; p += 8) {\n+\tPREFETCH_FOR_WRITE(p+64);\n         p[0] = (word)(p-4);\n         p[4] = (word)p;\n     };\n@@ -179,6 +180,10 @@ int kind;\n   /* Mark all objects if appropriate. */\n       if (IS_UNCOLLECTABLE(kind)) GC_set_hdr_marks(HDR(h));\n \n+  PREFETCH_FOR_WRITE((char *)h);\n+  PREFETCH_FOR_WRITE((char *)h + 128);\n+  PREFETCH_FOR_WRITE((char *)h + 256);\n+  PREFETCH_FOR_WRITE((char *)h + 378);\n   /* Handle small objects sizes more efficiently.  For larger objects \t*/\n   /* the difference is less significant.\t\t\t\t*/\n #  ifndef SMALL_CONFIG"}, {"sha": "a972dec805c0ef38de109fc8e604908aba993070", "filename": "boehm-gc/os_dep.c", "status": "modified", "additions": 39, "deletions": 11, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fos_dep.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fos_dep.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fos_dep.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -66,7 +66,7 @@\n #   define NEED_FIND_LIMIT\n # endif\n \n-# if (defined(SUNOS4) & defined(DYNAMIC_LOADING)) && !defined(PCR)\n+# if (defined(SUNOS4) && defined(DYNAMIC_LOADING)) && !defined(PCR)\n #   define NEED_FIND_LIMIT\n # endif\n \n@@ -75,7 +75,8 @@\n # endif\n \n # if defined(LINUX) && \\\n-     (defined(SPARC) || defined(IA64))\n+     (defined(POWERPC) || defined(SPARC) || defined(ALPHA) || defined(IA64) \\\n+      || defined(MIPS))\n #   define NEED_FIND_LIMIT\n # endif\n \n@@ -142,7 +143,8 @@\n # define OPT_PROT_EXEC 0\n #endif\n \n-#if defined(LINUX) && (defined(SPARC) || defined(IA64))\n+#if defined(SEARCH_FOR_DATA_START)\n+  /* The following doesn't work if the GC is in a dynamic library.\t*/\n   /* The I386 case can be handled without a search.  The Alpha case\t*/\n   /* used to be handled differently as well, but the rules changed\t*/\n   /* for recent Linux versions.  This seems to be the easiest way to\t*/\n@@ -641,19 +643,17 @@ ptr_t GC_get_stack_base()\n #ifdef LINUX_STACKBOTTOM\n \n # define STAT_SKIP 27   /* Number of fields preceding startstack\t*/\n-\t\t\t/* field in /proc/<pid>/stat\t\t\t*/\n+\t\t\t/* field in /proc/self/stat\t\t\t*/\n \n   ptr_t GC_linux_stack_base(void)\n   {\n-    char buf[50];\n     FILE *f;\n     char c;\n     word result = 0;\n     int i;\n \n-    sprintf(buf, \"/proc/%d/stat\", getpid());\n-    f = fopen(buf, \"r\");\n-    if (NULL == f) ABORT(\"Couldn't open /proc/<pid>/stat\");\n+    f = fopen(\"/proc/self/stat\", \"r\");\n+    if (NULL == f) ABORT(\"Couldn't open /proc/self/stat\");\n     c = getc(f);\n     /* Skip the required number of fields.  This number is hopefully\t*/\n     /* constant across all Linux implementations.\t\t\t*/\n@@ -1874,6 +1874,9 @@ SIG_PF GC_old_segv_handler;\t/* Also old MSWIN32 ACCESS_VIOLATION filter */\n #\t  else\n #\t    ifdef IA64\n \t      char * addr = si -> si_addr;\n+\t      /* I believe this is claimed to work on all platforms for\t*/\n+\t      /* Linux 2.3.47 and later.  Hopefully we don't have to\t*/\n+\t      /* worry about earlier kernels on IA64.\t\t\t*/\n #\t    else\n #             if defined(POWERPC)\n                 char * addr = (char *) (sc.regs->dar);\n@@ -2178,12 +2181,13 @@ word len;\n     \t      ((ptr_t)end_block - (ptr_t)start_block) + HBLKSIZE);\n }\n \n-#ifndef MSWIN32\n+#if !defined(MSWIN32) && !defined(LINUX_THREADS)\n /* Replacement for UNIX system call.\t */\n /* Other calls that write to the heap\t */\n /* should be handled similarly.\t\t */\n # if defined(__STDC__) && !defined(SUNOS4)\n #   include <unistd.h>\n+#   include <sys/uio.h>\n     ssize_t read(int fd, void *buf, size_t nbyte)\n # else\n #   ifndef LINT\n@@ -2200,10 +2204,12 @@ word len;\n     \n     GC_begin_syscall();\n     GC_unprotect_range(buf, (word)nbyte);\n-#   ifdef IRIX5\n+#   if defined(IRIX5) || defined(LINUX_THREADS)\n \t/* Indirect system call may not always be easily available.\t*/\n \t/* We could call _read, but that would interfere with the\t*/\n \t/* libpthread interception of read.\t\t\t\t*/\n+\t/* On Linux, we have to be careful with the linuxthreads\t*/\n+\t/* read interception.\t\t\t\t\t\t*/\n \t{\n \t    struct iovec iov;\n \n@@ -2217,7 +2223,29 @@ word len;\n     GC_end_syscall();\n     return(result);\n }\n-#endif /* !MSWIN32 */\n+#endif /* !MSWIN32 && !LINUX */\n+\n+#ifdef USE_LD_WRAP\n+    /* We use the GNU ld call wrapping facility.\t\t\t*/\n+    /* This requires that the linker be invoked with \"--wrap read\".\t*/\n+    /* This can be done by passing -Wl,\"--wrap read\" to gcc.\t\t*/\n+    /* I'm not sure that this actually wraps whatever version of read\t*/\n+    /* is called by stdio.  That code also mentions __read.\t\t*/\n+#   include <unistd.h>\n+    ssize_t __wrap_read(int fd, void *buf, size_t nbyte)\n+    {\n+ \tint result;\n+\n+\tGC_begin_syscall();\n+    \tGC_unprotect_range(buf, (word)nbyte);\n+\tresult = __real_read(fd, buf, nbyte);\n+\tGC_end_syscall();\n+\treturn(result);\n+    }\n+\n+    /* We should probably also do this for __read, or whatever stdio\t*/\n+    /* actually calls.\t\t\t\t\t\t\t*/\n+#endif\n \n /*ARGSUSED*/\n GC_bool GC_page_was_ever_dirty(h)"}, {"sha": "1847e590aad0e4ebeb9faa5efacb136e5fbf186f", "filename": "boehm-gc/reclaim.c", "status": "modified", "additions": 19, "deletions": 5, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Freclaim.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Freclaim.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Freclaim.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -241,9 +241,18 @@ register word sz;\n \t\t/* Clear object, advance p to next object in the process */\n \t\t    q = p + sz;\n                     p++; /* Skip link field */\n-                    while (p < q) {\n+#\t\t    if defined(SMALL_CONFIG) && defined(ALIGN_DOUBLE)\n+\t\t      /* We assert that sz must be even\t*/\n+\t\t      *p++ = 0;\n+\t\t      while (p < q) {\n+\t\t\tCLEAR_DOUBLE(p);\n+\t\t\tp += 2;\n+\t\t      }\n+#\t\t    else\n+                      while (p < q) {\n \t\t\t*p++ = 0;\n-\t\t    }\n+\t\t      }\n+#\t\t    endif\n \t    }\n \t    word_no += sz;\n \t}\n@@ -321,8 +330,7 @@ register ptr_t list;\n \t    p[start_displ] = (word)list; \\\n \t    list = (ptr_t)(p+start_displ); \\\n \t    p[start_displ+1] = 0; \\\n-\t    p[start_displ+2] = 0; \\\n-\t    p[start_displ+3] = 0; \\\n+\t    CLEAR_DOUBLE(p + start_displ + 2); \\\n \t    INCR_WORDS(4); \\\n \t}\n     \n@@ -814,6 +822,12 @@ int report_if_found;\t\t/* Abort if a GC_reclaimable object is found */\n   /* Go through all heap blocks (in hblklist) and reclaim unmarked objects */\n   /* or enqueue the block for later processing.\t\t\t\t   */\n     GC_apply_to_all_blocks(GC_reclaim_block, (word)report_if_found);\n+\n+# ifdef EAGER_SWEEP\n+    /* This is a very stupid thing to do.  We make it possible anyway,\t*/\n+    /* so that you can convince yourself that it really is very stupid.\t*/\n+    GC_reclaim_all((GC_stop_func)0, FALSE);\n+# endif\n     \n }\n \n@@ -847,7 +861,7 @@ int kind;\n  * Abort and return FALSE when/if (*stop_func)() returns TRUE.\n  * If this returns TRUE, then it's safe to restart the world\n  * with incorrectly cleared mark bits.\n- * If ignore_old is TRUE, then reclain only blocks that have been \n+ * If ignore_old is TRUE, then reclaim only blocks that have been \n  * recently reclaimed, and discard the rest.\n  * Stop_func may be 0.\n  */"}, {"sha": "97ab13bbd46a95cb14a6b56e3ed8424290e3a988", "filename": "boehm-gc/solaris_pthreads.c", "status": "modified", "additions": 26, "deletions": 18, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fsolaris_pthreads.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fsolaris_pthreads.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fsolaris_pthreads.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -76,14 +76,16 @@ GC_pthread_create(pthread_t *new_thread,\n     pthread_attr_t  attr;\n     word my_flags = 0;\n     int  flag;\n-    void * stack;\n-    size_t stack_size;\n+    void * stack = 0;\n+    size_t stack_size = 0;\n     int    n;\n     struct sched_param schedparam;\n    \n-    (void)pthread_attr_getstacksize(attr_in, &stack_size);\n-    (void)pthread_attr_getstackaddr(attr_in, &stack);\n     (void)pthread_attr_init(&attr);\n+    if (attr_in != 0) {\n+\t(void)pthread_attr_getstacksize(attr_in, &stack_size);\n+\t(void)pthread_attr_getstackaddr(attr_in, &stack);\n+    }\n \n     LOCK();\n     if (!GC_thr_initialized) {\n@@ -93,7 +95,11 @@ GC_pthread_create(pthread_t *new_thread,\n \t    \n     if (stack == 0) {\n      \tif (stack_size == 0)\n-\t\tstack_size = GC_min_stack_sz;\n+\t\tstack_size = 1048576;\n+\t\t\t  /* ^-- 1 MB (this was GC_min_stack_sz, but that\n+\t\t\t   * violates the pthread_create documentation which\n+\t\t\t   * says the default value if none is supplied is\n+\t\t\t   * 1MB) */\n \telse\n \t\tstack_size += thr_min_stack();\n \n@@ -109,20 +115,22 @@ GC_pthread_create(pthread_t *new_thread,\n     }\n     (void)pthread_attr_setstacksize(&attr, stack_size);\n     (void)pthread_attr_setstackaddr(&attr, stack);\n-    (void)pthread_attr_getscope(attr_in, &n);\n-    (void)pthread_attr_setscope(&attr, n);\n-    (void)pthread_attr_getschedparam(attr_in, &schedparam);\n-    (void)pthread_attr_setschedparam(&attr, &schedparam);\n-    (void)pthread_attr_getschedpolicy(attr_in, &n);\n-    (void)pthread_attr_setschedpolicy(&attr, n);\n-    (void)pthread_attr_getinheritsched(attr_in, &n);\n-    (void)pthread_attr_setinheritsched(&attr, n);\n-\n-    (void)pthread_attr_getdetachstate(attr_in, &flag);\n-    if (flag == PTHREAD_CREATE_DETACHED) {\n-\t    my_flags |= DETACHED;\n+    if (attr_in != 0) {\n+\t(void)pthread_attr_getscope(attr_in, &n);\n+\t(void)pthread_attr_setscope(&attr, n);\n+\t(void)pthread_attr_getschedparam(attr_in, &schedparam);\n+\t(void)pthread_attr_setschedparam(&attr, &schedparam);\n+\t(void)pthread_attr_getschedpolicy(attr_in, &n);\n+\t(void)pthread_attr_setschedpolicy(&attr, n);\n+\t(void)pthread_attr_getinheritsched(attr_in, &n);\n+\t(void)pthread_attr_setinheritsched(&attr, n);\n+\n+\t(void)pthread_attr_getdetachstate(attr_in, &flag);\n+\tif (flag == PTHREAD_CREATE_DETACHED) {\n+\t\tmy_flags |= DETACHED;\n+\t}\n+\t(void)pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);\n     }\n-    (void)pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);\n     /*\n      * thr_create can call malloc(), which if redirected will\n      * attempt to acquire the allocation lock."}, {"sha": "c3b0b15b97c7b0517e2e98d9e018e63fdddb7193", "filename": "boehm-gc/solaris_threads.c", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fsolaris_threads.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fsolaris_threads.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fsolaris_threads.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -661,7 +661,8 @@ void GC_my_stack_limits()\n }\n \n \n-/* We hold allocation lock.  We assume the world is stopped.\t*/\n+/* We hold allocation lock.  Should do exactly the right thing if the\t*/\n+/* world is stopped.  Should not fail if it isn't.\t\t\t*/\n void GC_push_all_stacks()\n {\n     register int i;\n@@ -900,7 +901,7 @@ GC_thr_create(void *stack_base, size_t stack_size,\n     }\n     GC_multithreaded++;\n     if (stack == 0) {\n-     \tif (stack_size == 0) stack_size = GC_min_stack_sz;\n+     \tif (stack_size == 0) stack_size = 1024*1024;\n      \tstack = (void *)GC_stack_alloc(&stack_size);\n      \tif (stack == 0) {\n \t    GC_multithreaded--;"}, {"sha": "96a54150a86df8a458ca173ba552dee02c8564f4", "filename": "boehm-gc/test.c", "status": "modified", "additions": 132, "deletions": 7, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ftest.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ftest.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Ftest.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -15,6 +15,8 @@\n /* An incomplete test for the garbage collector.  \t\t*/\n /* Some more obscure entry points are not tested at all.\t*/\n \n+# undef GC_BUILD\n+\n # if defined(mips) && defined(SYSTYPE_BSD43)\n     /* MIPS RISCOS 4 */\n # else\n@@ -147,7 +149,6 @@ sexpr y;\n     register sexpr r;\n     \n     r = (sexpr) GC_MALLOC_UNCOLLECTABLE(sizeof(struct SEXPR));\n-assert(GC_is_marked(r));\n     if (r == 0) {\n         (void)GC_printf0(\"Out of memory\\n\");\n         exit(1);\n@@ -157,6 +158,76 @@ assert(GC_is_marked(r));\n     return(r);\n }\n \n+#ifdef GC_GCJ_SUPPORT\n+\n+#include \"gc_mark.h\"\n+#include \"dbg_mlc.h\"\n+#include \"include/gc_gcj.h\"\n+\n+/* The following struct emulates the vtable in gcj.\t*/\n+/* This assumes the default value of MARK_DESCR_OFFSET. */\n+struct fake_vtable {\n+  void * dummy;\t\t/* class pointer in real gcj.\t*/\n+  size_t descr;\n+};\n+\n+struct fake_vtable gcj_class_struct1 = { 0, sizeof(struct SEXPR)\n+\t\t\t\t\t    + sizeof(struct fake_vtable *) };\n+\t\t\t/* length based descriptor.\t*/\n+struct fake_vtable gcj_class_struct2 =\n+\t\t\t\t{ 0, (3l << (CPP_WORDSZ - 3)) | DS_BITMAP};\n+\t\t\t/* Bitmap based descriptor.\t*/\n+\n+struct ms_entry * fake_gcj_mark_proc(word * addr,\n+\t\t\t\t     struct ms_entry *mark_stack_ptr,\n+\t\t\t\t     struct ms_entry *mark_stack_limit,\n+\t\t\t\t     word env   )\n+{\n+    sexpr x;\n+    if (1 == env) {\n+\t/* Object allocated with debug allocator.\t*/\n+\taddr = (word *)USR_PTR_FROM_BASE(addr);\n+    }\n+    x = (sexpr)(addr + 1); /* Skip the vtable pointer. */\n+    /* We could just call PUSH_CONTENTS directly here.  But any real\t*/\n+    /* real client would try to filter out the obvious misses.\t\t*/\n+    if (0 != x -> sexpr_cdr) {\n+\tPUSH_CONTENTS((ptr_t)(x -> sexpr_cdr), mark_stack_ptr,\n+\t\t\t      mark_stack_limit, &(x -> sexpr_cdr), exit1);\n+    }\n+    if ((ptr_t)(x -> sexpr_car) > GC_least_plausible_heap_addr) {\n+\tPUSH_CONTENTS((ptr_t)(x -> sexpr_car), mark_stack_ptr,\n+\t\t\t      mark_stack_limit, &(x -> sexpr_car), exit2);\n+    }\n+    return(mark_stack_ptr);\n+}\n+\n+sexpr gcj_cons(x, y)\n+sexpr x;\n+sexpr y;\n+{\n+    GC_word * r;\n+    sexpr result;\n+    static int count = 0;\n+    \n+    if (++count & 1) {\n+        r = (GC_word *) GC_GCJ_FAST_MALLOC(3, &gcj_class_struct1);\n+    } else {\n+        r = (GC_word *) GC_GCJ_MALLOC(sizeof(struct SEXPR)\n+\t\t\t\t      + sizeof(struct fake_vtable*),\n+\t\t\t\t      &gcj_class_struct2);\n+    }\n+    if (r == 0) {\n+        (void)GC_printf0(\"Out of memory\\n\");\n+        exit(1);\n+    }\n+    result = (sexpr)(r + 1);\n+    result -> sexpr_car = x;\n+    result -> sexpr_cdr = y;\n+    return(result);\n+}\n+#endif\n+\n /* Return reverse(x) concatenated with y */\n sexpr reverse1(x, y)\n sexpr x, y;\n@@ -184,6 +255,35 @@ int low, up;\n     }\n }\n \n+#ifdef GC_GCJ_SUPPORT\n+/* Return reverse(x) concatenated with y */\n+sexpr gcj_reverse1(x, y)\n+sexpr x, y;\n+{\n+    if (is_nil(x)) {\n+        return(y);\n+    } else {\n+        return( gcj_reverse1(cdr(x), gcj_cons(car(x), y)) );\n+    }\n+}\n+\n+sexpr gcj_reverse(x)\n+sexpr x;\n+{\n+    return( gcj_reverse1(x, nil) );\n+}\n+\n+sexpr gcj_ints(low, up)\n+int low, up;\n+{\n+    if (low > up) {\n+\treturn(nil);\n+    } else {\n+        return(gcj_cons(gcj_cons(INT_TO_SEXPR(low), nil), gcj_ints(low+1, up)));\n+    }\n+}\n+#endif /* GC_GCJ_SUPPORT */\n+\n /* To check uncollectable allocation we build lists with disguised cdr\t*/\n /* pointers, and make sure they don't go away.\t\t\t\t*/\n sexpr uncollectable_ints(low, up)\n@@ -367,7 +467,12 @@ void reverse_test()\n     g[799] = ints(1,18);\n     h = (sexpr *)GC_MALLOC(1025 * sizeof(sexpr));\n     h = (sexpr *)GC_REALLOC((GC_PTR)h, 2000 * sizeof(sexpr));\n-    h[1999] = ints(1,19);\n+#   ifdef GC_GCJ_SUPPORT\n+      h[1999] = gcj_ints(1,200);\n+      h[1999] = gcj_reverse(h[1999]);\n+#   else\n+      h[1999] = ints(1,200);\n+#   endif\n     /* Try to force some collections and reuse of small list elements */\n       for (i = 0; i < 10; i++) {\n         (void)ints(1, BIG);\n@@ -412,7 +517,10 @@ void reverse_test()\n     check_uncollectable_ints(d, 1, 100);\n     check_ints(f[5], 1,17);\n     check_ints(g[799], 1,18);\n-    check_ints(h[1999], 1,19);\n+#   ifdef GC_GCJ_SUPPORT\n+      h[1999] = gcj_reverse(h[1999]);\n+#   endif\n+    check_ints(h[1999], 1,200);\n #   ifndef THREADS\n \ta = 0;\n #   endif  \n@@ -759,6 +867,10 @@ void typed_test()\n     old = 0;\n     for (i = 0; i < 4000; i++) {\n         new = (GC_word *) GC_malloc_explicitly_typed(4 * sizeof(GC_word), d1);\n+        if (0 != new[0] || 0 != new[1]) {\n+\t    GC_printf0(\"Bad initialization by GC_malloc_explicitly_typed\\n\");\n+\t    FAIL;\n+\t}\n         new[0] = 17;\n         new[1] = (GC_word)old;\n         old = new;\n@@ -782,6 +894,10 @@ void typed_test()\n           new = (GC_word *) GC_calloc_explicitly_typed(1001,\n           \t\t\t\t\t       3 * sizeof(GC_word),\n         \t\t\t\t\t       d2);\n+          if (0 != new[0] || 0 != new[1]) {\n+\t    GC_printf0(\"Bad initialization by GC_malloc_explicitly_typed\\n\");\n+\t    FAIL;\n+\t  }\n         }\n         new[0] = 17;\n         new[1] = (GC_word)old;\n@@ -906,6 +1022,10 @@ void run_one_test()\n     /* Test floating point alignment */\n \t*(double *)GC_MALLOC(sizeof(double)) = 1.0;\n \t*(double *)GC_MALLOC(sizeof(double)) = 1.0;\n+#   ifdef GC_GCJ_SUPPORT\n+      GC_REGISTER_DISPLACEMENT(sizeof(struct fake_vtable *));\n+      GC_init_gcj_malloc(0, (void *)fake_gcj_mark_proc);\n+#   endif\n     /* Repeated list reversal test. */\n \treverse_test();\n #   ifdef PRINTSTATS\n@@ -1032,7 +1152,7 @@ void SetMinimumStack(long minSize)\n #if !defined(PCR) && !defined(SOLARIS_THREADS) && !defined(WIN32_THREADS) \\\n   && !defined(IRIX_THREADS) && !defined(LINUX_THREADS) \\\n   && !defined(HPUX_THREADS) || defined(LINT)\n-#ifdef MSWIN32\n+#if defined(MSWIN32) && !defined(__MINGW32__)\n   int APIENTRY WinMain(HINSTANCE instance, HINSTANCE prev, LPSTR cmd, int n)\n #else\n   int main()\n@@ -1114,19 +1234,24 @@ int APIENTRY WinMain(HINSTANCE instance, HINSTANCE prev, LPSTR cmd, int n)\n # endif\n   InitializeCriticalSection(&incr_cs);\n   (void) GC_set_warn_proc(warn_proc);\n-  for (i = 0; i < NTEST; i++) {\n+# if NTEST > 0\n+   for (i = 0; i < NTEST; i++) {\n     h[i] = (HANDLE)_beginthreadex(NULL, 0, thr_run_one_test, 0, 0, &thread_id);\n     if (h[i] == (HANDLE)-1) {\n       (void)GC_printf1(\"Thread creation failed %lu\\n\", (unsigned long)GetLastError());\n       FAIL;\n     }\n-  }\n+   }\n+# endif /* NTEST > 0 */\n   run_one_test();\n-  for (i = 0; i < NTEST; i++)\n+# if NTEST > 0\n+   for (i = 0; i < NTEST; i++) {\n     if (WaitForSingleObject(h[i], INFINITE) != WAIT_OBJECT_0) {\n       (void)GC_printf1(\"Thread wait failed %lu\\n\", (unsigned long)GetLastError());\n       FAIL;\n     }\n+   }\n+# endif /* NTEST > 0 */\n   check_heap_stats();\n   (void)fflush(stdout);\n   return(0);"}, {"sha": "0d45077658f495a15dfa240162316e5a78a63eb1", "filename": "boehm-gc/test_cpp.cc", "status": "modified", "additions": 9, "deletions": 3, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ftest_cpp.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ftest_cpp.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Ftest_cpp.cc?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -37,6 +37,12 @@ extern \"C\" {\n #ifdef MSWIN32\n #   include <windows.h>\n #endif\n+#ifdef GC_NAME_CONFLICT\n+#   define USE_GC UseGC\n+    struct foo * GC;\n+#else\n+#   define USE_GC GC\n+#endif\n \n \n #define my_assert( e ) \\\n@@ -214,17 +220,17 @@ int APIENTRY WinMain(\n         for (i = 0; i < 1000; i++) {\n             C* c = new C( 2 );\n             C c1( 2 );           /* stack allocation should work too */\n-            D* d = ::new (GC, D::CleanUp, (void*) i) D( i );\n+            D* d = ::new (USE_GC, D::CleanUp, (void*) i) D( i );\n             F* f = new F;\n             if (0 == i % 10) delete c;}\n \n             /* Allocate a very large number of collectable As and Bs and\n             drop the references to them immediately, forcing many\n             collections. */\n         for (i = 0; i < 1000000; i++) {\n-            A* a = new (GC) A( i );\n+            A* a = new (USE_GC) A( i );\n             B* b = new B( i );\n-            b = new (GC) B( i );\n+            b = new (USE_GC) B( i );\n             if (0 == i % 10) {\n                 B::Deleting( 1 );\n                 delete b;"}, {"sha": "b2e6a10b0b96d3090821d13ea31efd720cbcca3a", "filename": "boehm-gc/threadlibs.c", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fthreadlibs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fthreadlibs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fthreadlibs.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -3,7 +3,16 @@\n \n int main()\n {\n-#   if defined(IRIX_THREADS) || defined(LINUX_THREADS)\n+#   if defined(LINUX_THREADS)\n+#     ifdef USE_LD_WRAP\n+\tprintf(\"-Wl,\\\"--wrap read\\\" -Wl,\\\"--wrap dlopen\\\" \"\n+\t       \"-Wl,\\\"--wrap pthread_create\\\" -Wl,\\\"--wrap pthread_join\\\" \"\n+\t       \"-Wl,\\\"--wrap pthread_sigmask\\\" -lpthread\\n\");\n+#     else\n+\tprintf(\"-lpthread\\n\");\n+#     endif\n+#   endif\n+#   if defined(IRIX_THREADS)\n \tprintf(\"-lpthread\\n\");\n #   endif\n #   if defined(HPUX_THREADS)"}, {"sha": "ce769d60fecea1c7a973f91fdb81d37e362fafeb", "filename": "boehm-gc/typd_mlc.c", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ftypd_mlc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Ftypd_mlc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Ftypd_mlc.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -430,7 +430,7 @@ word env;\n     \tif (bm & 1) {\n     \t    current = *current_p;\n     \t    if ((ptr_t)current >= least_ha && (ptr_t)current <= greatest_ha) {\n-    \t        PUSH_CONTENTS(current, mark_stack_ptr,\n+    \t        PUSH_CONTENTS((ptr_t)current, mark_stack_ptr,\n \t\t\t      mark_stack_limit, current_p, exit1);\n     \t    }\n     \t}\n@@ -665,6 +665,7 @@ DCL_LOCK_STATE;\n #\t    endif\n         } else {\n             *opp = obj_link(op);\n+\t    obj_link(op) = 0;\n             GC_words_allocd += lw;\n             FASTUNLOCK();\n         }\n@@ -708,6 +709,7 @@ DCL_LOCK_STATE;\n #\t    endif\n         } else {\n             *opp = obj_link(op);\n+\t    obj_link(op) = 0;\n             GC_words_allocd += lw;\n             FASTUNLOCK();\n         }\n@@ -717,7 +719,7 @@ DCL_LOCK_STATE;\n        lw = BYTES_TO_WORDS(GC_size(op));\n    }\n    if (op != NULL)\n-   ((word *)op)[lw - 1] = d;\n+       ((word *)op)[lw - 1] = d;\n    return((GC_PTR) op);\n }\n \n@@ -772,6 +774,7 @@ DCL_LOCK_STATE;\n #\t    endif\n         } else {\n             *opp = obj_link(op);\n+\t    obj_link(op) = 0;\n             GC_words_allocd += lw;\n             FASTUNLOCK();\n         }"}, {"sha": "c7095488bd53e7c3ee35665014e9a92b41d686fe", "filename": "boehm-gc/version.h", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fversion.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fversion.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fversion.h?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -1,9 +1,12 @@\n #define GC_VERSION_MAJOR 5\n #define GC_VERSION_MINOR 0\n-#define GC_ALPHA_VERSION 4\n+#define GC_ALPHA_VERSION 6\n \n #   define GC_NOT_ALPHA 0xff\n \n+/* This is really an unreleased version which doesn't have a real version */\n+/* number.\t\t\t\t\t\t\t\t  */\n+\n #ifndef GC_NO_VERSION_VAR\n \n unsigned GC_version = ((GC_VERSION_MAJOR << 16) | (GC_VERSION_MINOR << 8) | GC_ALPHA_VERSION);"}, {"sha": "469fd232003997f2e3ea888740d71f3bf9443a6a", "filename": "boehm-gc/win32_threads.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fwin32_threads.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/93002327db5e5f466de60dc3f8c876cf9a56e183/boehm-gc%2Fwin32_threads.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fwin32_threads.c?ref=93002327db5e5f466de60dc3f8c876cf9a56e183", "patch": "@@ -2,8 +2,10 @@\n \n #include \"gc_priv.h\"\n \n+#if 0\n #define STRICT\n #include <windows.h>\n+#endif\n \n #define MAX_THREADS 64\n \n@@ -61,7 +63,7 @@ ptr_t GC_current_stackbottom()\n   ABORT(\"no thread table entry for current thread\");\n }\n \n-ptr_t GC_get_lo_stack_addr(ptr_t s)\n+static ptr_t GC_get_lo_stack_addr(ptr_t s)\n {\n     ptr_t bottom;\n     MEMORY_BASIC_INFORMATION info;\n@@ -81,7 +83,7 @@ void GC_push_all_stacks()\n     if (thread_table[i].stack) {\n       ptr_t bottom = GC_get_lo_stack_addr(thread_table[i].stack);\n       if (thread_table[i].id == thread_id)\n-\tGC_push_all(&i, thread_table[i].stack);\n+\tGC_push_all_stack(&i, thread_table[i].stack);\n       else {\n \tthread_table[i].context.ContextFlags\n \t\t\t= (CONTEXT_INTEGER|CONTEXT_CONTROL);"}]}