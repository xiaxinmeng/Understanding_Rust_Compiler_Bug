{"sha": "bdcbe49686fce1d35955579428aa2ade21dd941c", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmRjYmU0OTY4NmZjZTFkMzU5NTU1Nzk0MjhhYTJhZGUyMWRkOTQxYw==", "commit": {"author": {"name": "Neil Booth", "email": "neil@daikokuya.demon.co.uk", "date": "2001-09-13T20:05:17Z"}, "committer": {"name": "Neil Booth", "email": "neil@gcc.gnu.org", "date": "2001-09-13T20:05:17Z"}, "message": "c-parse.in (_yylex): Use _cpp_backup_tokens.\n\n\t* c-parse.in (_yylex): Use _cpp_backup_tokens.\n\t* cpphash.h (struct tokenrun): Add prev.\n\t(struct lexer_state): Remove bol.\n\t(struct cpp_reader): Remove old lookahead stuff, add lookaheads.\n\t(_cpp_free_lookaheads, _cpp_release_lookahead, _cpp_push_token)\n\t: Remove.\n\t* cppinit.c (cpp_create_reader): Don't set bol.\n\t(cpp_destroy): Don't free lookaheads.\n\t* cpplex.c (lex_directive): Remove.\n\t(next_tokenrun): Update.\n\t(_cpp_lex_token): Clean up logic.\n\t(lex_token): Update to return a pointer to lexed token, since it\n\tcan move to the start of the buffer.  Simpify newline handling.\n\t* cpplib.c (SEEN_EOL): Update.\n\t(skip_rest_of_line): Remove lookahead stuff.\n\t(end_directive): Line numbers are already incremented.  Revert\n\tto start of lexed token buffer if we can.\n\t(_cpp_handle_directive, do_pragma, do_pragma_dependency,\n\tparse_answer): Use _cpp_backup_tokens.\n\t(run_directive, cpp_pop_buffer): Don't set bol, set saved_flags\n\tinstead.  Don't check for EOL.\n\t(do_include_common, do_line, do_pragma_system_header): Use\n\tskip_rest_of_line.\n\t* cpplib.h (BOL, _cpp_backup_tokens): New.\n\t* cppmacro.c (save_lookahead_token, take_lookahead_token,\n\talloc_lookahead, free_lookahead, _cpp_free_lookaheads,\n\tcpp_start_lookahead, cpp_stop_lookahead, _cpp_push_token): Remove.\n\t(builtin_macro): Don't use cpp_get_line.\n\t(cpp_get_line): Short term kludge.\n\t(parse_arg): Handle directives in arguments here.  Back up when\n\tappropriate.  Store EOF at end of argument list.\n\t(funlike_invocation_p): Use _cpp_backup_tokens.\n\t(push_arg_context): Account for EOF at end of list.\n\t(cpp_get_token): Remove lookahead stuff.  Update.\n\n\t* gcc.dg/cpp/directiv.c: Update.\n\t* gcc.dg/cpp/undef1.c: Update.\n\nFrom-SVN: r45582", "tree": {"sha": "f67a034f6447649165fb6297431354b49c7620fc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f67a034f6447649165fb6297431354b49c7620fc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/bdcbe49686fce1d35955579428aa2ade21dd941c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bdcbe49686fce1d35955579428aa2ade21dd941c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bdcbe49686fce1d35955579428aa2ade21dd941c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bdcbe49686fce1d35955579428aa2ade21dd941c/comments", "author": null, "committer": null, "parents": [{"sha": "83182544dbfc89d2d974431383d61039cac9b773", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/83182544dbfc89d2d974431383d61039cac9b773", "html_url": "https://github.com/Rust-GCC/gccrs/commit/83182544dbfc89d2d974431383d61039cac9b773"}], "stats": {"total": 558, "additions": 218, "deletions": 340}, "files": [{"sha": "1152607591c3726c4ae6a14ceed06faa420b35a5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -1,3 +1,40 @@\n+2001-09-13  Neil Booth  <neil@daikokuya.demon.co.uk>\n+\n+\t* c-parse.in (_yylex): Use _cpp_backup_tokens.\n+\t* cpphash.h (struct tokenrun): Add prev.\n+\t(struct lexer_state): Remove bol.\n+\t(struct cpp_reader): Remove old lookahead stuff, add lookaheads.\n+\t(_cpp_free_lookaheads, _cpp_release_lookahead, _cpp_push_token)\n+\t: Remove.\n+\t* cppinit.c (cpp_create_reader): Don't set bol.\n+\t(cpp_destroy): Don't free lookaheads.\n+\t* cpplex.c (lex_directive): Remove.\n+\t(next_tokenrun): Update.\n+\t(_cpp_lex_token): Clean up logic.\n+\t(lex_token): Update to return a pointer to lexed token, since it\n+\tcan move to the start of the buffer.  Simpify newline handling.\n+\t* cpplib.c (SEEN_EOL): Update.\n+\t(skip_rest_of_line): Remove lookahead stuff.\n+\t(end_directive): Line numbers are already incremented.  Revert\n+\tto start of lexed token buffer if we can.\n+\t(_cpp_handle_directive, do_pragma, do_pragma_dependency,\n+\tparse_answer): Use _cpp_backup_tokens.\n+\t(run_directive, cpp_pop_buffer): Don't set bol, set saved_flags\n+\tinstead.  Don't check for EOL.\n+\t(do_include_common, do_line, do_pragma_system_header): Use\n+\tskip_rest_of_line.\n+\t* cpplib.h (BOL, _cpp_backup_tokens): New.\n+\t* cppmacro.c (save_lookahead_token, take_lookahead_token,\n+\talloc_lookahead, free_lookahead, _cpp_free_lookaheads,\n+\tcpp_start_lookahead, cpp_stop_lookahead, _cpp_push_token): Remove.\n+\t(builtin_macro): Don't use cpp_get_line.\n+\t(cpp_get_line): Short term kludge.\n+\t(parse_arg): Handle directives in arguments here.  Back up when\n+\tappropriate.  Store EOF at end of argument list.\n+\t(funlike_invocation_p): Use _cpp_backup_tokens.\n+\t(push_arg_context): Account for EOF at end of list.\n+\t(cpp_get_token): Remove lookahead stuff.  Update.\n+\n 2001-09-13  Kaveh R. Ghazi  <ghazi@caip.rutgers.edu>\n \n \t* c-parse.in (yyerror): Const-ification and/or static-ization."}, {"sha": "0d76c3e59665eab937178d4e21240cd4ee488323", "filename": "gcc/c-parse.in", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fc-parse.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fc-parse.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-parse.in?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -3788,19 +3788,17 @@ ifobjc\n \ttree after_at;\n \tenum cpp_ttype after_at_type;\n \n-\tcpp_start_lookahead (parse_in);\n \tafter_at_type = c_lex (&after_at);\n \n \tif (after_at_type == CPP_NAME\n \t    && C_IS_RESERVED_WORD (after_at)\n \t    && OBJC_IS_AT_KEYWORD (C_RID_CODE (after_at)))\n \t  {\n-\t    cpp_stop_lookahead (parse_in, 1);  /* accept this token */\n \t    yylval.ttype = after_at;\n \t    last_token = after_at_type;\n \t    return rid_to_yy [(int) C_RID_CODE (after_at)];\n \t  }\n-\tcpp_stop_lookahead (parse_in, 0);  /* put back this token */\n+\t_cpp_backup_tokens (parse_in, 1);\n \treturn '@';\n       }\n end ifobjc"}, {"sha": "acf727f672feaaea2027aadc2dd2f5c2ecaf012d", "filename": "gcc/cpphash.h", "status": "modified", "additions": 2, "deletions": 14, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpphash.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpphash.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpphash.h?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -105,7 +105,7 @@ struct toklist\n typedef struct tokenrun tokenrun;\n struct tokenrun\n {\n-  tokenrun *next;\n+  tokenrun *next, *prev;\n   cpp_token *base, *limit;\n };\n \n@@ -131,9 +131,6 @@ struct lexer_state\n   /* True if we are skipping a failed conditional group.  */\n   unsigned char skipping;\n \n-  /* Nonzero if next token is the start of a line.  */\n-  unsigned char bol;\n-\n   /* Nonzero if in a directive that takes angle-bracketed headers.  */\n   unsigned char angled_headers;\n \n@@ -271,16 +268,11 @@ struct cpp_reader\n   /* Lexing.  */\n   cpp_token *cur_token;\n   tokenrun base_run, *cur_run;\n+  unsigned int lookaheads;\n \n   /* Non-zero prevents the lexer from re-using the token runs.  */\n   unsigned int keep_tokens;\n \n-  /* Token lookahead.  */\n-  struct cpp_lookahead *la_read;\t/* Read from this lookahead.  */\n-  struct cpp_lookahead *la_write;\t/* Write to this lookahead.  */\n-  struct cpp_lookahead *la_unused;\t/* Free store.  */\n-  struct cpp_lookahead *la_saved;\t/* Backup when entering directive.  */\n-\n   /* Error counter for exit code.  */\n   unsigned int errors;\n \n@@ -382,10 +374,6 @@ extern int _cpp_begin_message PARAMS ((cpp_reader *, enum error_type,\n extern void _cpp_free_definition\tPARAMS ((cpp_hashnode *));\n extern int _cpp_create_definition\tPARAMS ((cpp_reader *, cpp_hashnode *));\n extern void _cpp_pop_context\t\tPARAMS ((cpp_reader *));\n-extern void _cpp_free_lookaheads\tPARAMS ((cpp_reader *));\n-extern void _cpp_release_lookahead\tPARAMS ((cpp_reader *));\n-extern void _cpp_push_token\t\tPARAMS ((cpp_reader *, const cpp_token *,\n-\t\t\t\t\t\t const cpp_lexer_pos *));\n \n /* In cpphash.c */\n extern void _cpp_init_hashtable\t\tPARAMS ((cpp_reader *, hash_table *));"}, {"sha": "2cf746104505fc2a8145d9972f42780193dc979c", "filename": "gcc/cppinit.c", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcppinit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcppinit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppinit.c?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -515,7 +515,6 @@ cpp_create_reader (table, lang)\n   _cpp_init_tokenrun (&pfile->base_run, 250);\n   pfile->cur_run = &pfile->base_run;\n   pfile->cur_token = pfile->base_run.base;\n-  pfile->state.bol = 1;\n \n   /* Initialise the base context.  */\n   pfile->context = &pfile->base_context;\n@@ -581,7 +580,6 @@ cpp_destroy (pfile)\n \n   _cpp_destroy_hashtable (pfile);\n   _cpp_cleanup_includes (pfile);\n-  _cpp_free_lookaheads (pfile);\n \n   _cpp_free_pool (&pfile->ident_pool);\n   _cpp_free_pool (&pfile->macro_pool);"}, {"sha": "6d640e090afa805e84e21a9295f45c796b45886b", "filename": "gcc/cpplex.c", "status": "modified", "additions": 63, "deletions": 104, "changes": 167, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpplex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpplex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplex.c?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -102,8 +102,7 @@ static void lex_dot PARAMS ((cpp_reader *, cpp_token *));\n static int name_p PARAMS ((cpp_reader *, const cpp_string *));\n static int maybe_read_ucs PARAMS ((cpp_reader *, const unsigned char **,\n \t\t\t\t   const unsigned char *, unsigned int *));\n-static int lex_directive PARAMS ((cpp_reader *));\n-static void lex_token PARAMS ((cpp_reader *, cpp_token *, int));\n+static cpp_token *lex_token PARAMS ((cpp_reader *, cpp_token *));\n static tokenrun *next_tokenrun PARAMS ((tokenrun *));\n \n static cpp_chunk *new_chunk PARAMS ((unsigned int));\n@@ -925,114 +924,69 @@ next_tokenrun (run)\n   if (run->next == NULL)\n     {\n       run->next = xnew (tokenrun);\n+      run->next->prev = run;\n       _cpp_init_tokenrun (run->next, 250);\n     }\n \n   return run->next;\n }\n \n-static int\n-lex_directive (pfile)\n-     cpp_reader *pfile;\n-{\n-  /* 6.10.3 paragraph 11: If there are sequences of preprocessing\n-     tokens within the list of arguments that would otherwise act as\n-     preprocessing directives, the behavior is undefined.\n-\n-     This implementation will report a hard error, terminate the macro\n-     invocation, and proceed to process the directive.  */\n-  if (pfile->state.parsing_args)\n-    {\n-      pfile->lexer_pos.output_line = pfile->line;\n-      if (pfile->state.parsing_args == 2)\n-\t{\n-\t  cpp_error (pfile,\n-\t\t     \"directives may not be used inside a macro argument\");\n-\t  pfile->state.bol = 1;\n-\t  pfile->buffer->cur = pfile->buffer->line_base;\n-\t  pfile->buffer->read_ahead = EOF;\n-\t  pfile->cur_token->type = CPP_EOF;\n-\t}\n-\n-      return 0;\n-    }\n-\n-  /* This is a directive.  If the return value is false, it is an\n-     assembler #.  */\n-  {\n-    /* FIXME: short-term kludge only - it doesn't handle the case that\n-       the # is at the end of a run and we moved to the start of the\n-       next one.  Easily fixed once we kill lookaheads.  */\n-    cpp_token *token = pfile->cur_token++;\n-    if (_cpp_handle_directive (pfile, token->flags & PREV_WHITE))\n-      return 1;\n-    pfile->cur_token = token;\n-    return 0;\n-  }\n-}\n-\n /* Lex a token into RESULT (external interface).  */\n void\n-_cpp_lex_token (pfile, result)\n+_cpp_lex_token (pfile, dest)\n      cpp_reader *pfile;\n-     cpp_token *result;\n+     cpp_token *dest;\n {\n-  if (pfile->cur_token == pfile->cur_run->limit)\n-    {\n-      pfile->cur_run = next_tokenrun (pfile->cur_run);\n-      pfile->cur_token = pfile->cur_run->base;\n-    }\n+  cpp_token *result;\n \n- next_token:\n-  if (pfile->state.bol)\n+  for (;;)\n     {\n-    start_new_line:\n-      pfile->state.bol = 0;\n-\n-      /* Return lexer back to base.  */\n-      if (!pfile->keep_tokens)\n+      if (pfile->cur_token == pfile->cur_run->limit)\n \t{\n-\t  pfile->cur_run = &pfile->base_run;\n-\t  pfile->cur_token = pfile->base_run.base;\n+\t  pfile->cur_run = next_tokenrun (pfile->cur_run);\n+\t  pfile->cur_token = pfile->cur_run->base;\n \t}\n+      result = pfile->cur_token++;\n \n-      lex_token (pfile, pfile->cur_token, 1);\n-      pfile->lexer_pos.output_line = pfile->cur_token->line;\n-      if (pfile->cur_token->type == CPP_HASH && lex_directive (pfile))\n-\tgoto start_new_line;\n-    }\n-  else\n-    {\n-      lex_token (pfile, pfile->cur_token, 0);\n-      if (pfile->cur_token->type == CPP_EOF)\n+      if (pfile->lookaheads)\n+\tpfile->lookaheads--;\n+      else\n+\tresult = lex_token (pfile, result);\n+\n+      if (result->flags & BOL)\n \t{\n-\t  if (!pfile->state.in_directive)\n-\t    goto start_new_line;\n-\t  /* Decrementing pfile->line allows directives to recognise\n-\t     that the newline has been seen, and also means that\n-\t     diagnostics don't point to the next line.  */\n-\t  pfile->lexer_pos.output_line = pfile->line--;\n+\t  pfile->lexer_pos.output_line = result->line;\n+\t  /* Is this a directive.  If _cpp_handle_directive returns\n+\t     false, it is an assembler #.  */\n+\t  if (result->type == CPP_HASH\n+\t      && !pfile->state.parsing_args\n+\t      && _cpp_handle_directive (pfile, result->flags & PREV_WHITE))\n+\t    continue;\n \t}\n-    }\n \n-  if (!pfile->state.in_directive)\n-    {\n-      if (pfile->state.skipping && pfile->cur_token->type != CPP_EOF)\n-\tgoto next_token;\n+      /* We don't skip tokens in directives.  */\n+      if (pfile->state.in_directive)\n+\tbreak;\n \n-      /* Outside a directive, invalidate controlling macros.  */\n+      /* Outside a directive, invalidate controlling macros.  At file\n+\t EOF, lex_token takes care of popping the buffer, so we never\n+\t get here and MI optimisation works.  */\n       pfile->mi_valid = false;\n+\n+      if (!pfile->state.skipping || result->type == CPP_EOF)\n+\tbreak;\n     }\n \n-  *result = *pfile->cur_token++;\n+  *dest = *result;\n }\n \n-/* Lex a token into RESULT (internal interface).  */\n-static void\n-lex_token (pfile, result, skip_newlines)\n+/* Lex a token into RESULT.  When meeting a newline, returns CPP_EOF\n+   if parsing a directive, otherwise returns to the start of the token\n+   buffer if permissible.  Returns the location of the lexed token.  */\n+static cpp_token *\n+lex_token (pfile, result)\n      cpp_reader *pfile;\n      cpp_token *result;\n-     int skip_newlines;\n {\n   cppchar_t c;\n   cpp_buffer *buffer;\n@@ -1058,28 +1012,27 @@ lex_token (pfile, result, skip_newlines)\n   switch (c)\n     {\n     case EOF:\n+      buffer->saved_flags = BOL;\n       if (!pfile->state.parsing_args && !pfile->state.in_directive)\n \t{\n-\t  if (buffer->cur == buffer->line_base)\n-\t    {\n-\t      /* Don't pop the last buffer.  */\n-\t      if (buffer->prev)\n-\t\t{\n-\t\t  unsigned char stop = buffer->return_at_eof;\n-\n-\t\t  _cpp_pop_buffer (pfile);\n-\t\t  if (!stop)\n-\t\t    goto fresh_line;\n-\t\t}\n-\t    }\n-\t  else\n+\t  if (buffer->cur != buffer->line_base)\n \t    {\n \t      /* Non-empty files should end in a newline.  Don't warn\n \t\t for command line and _Pragma buffers.  */\n \t      if (!buffer->from_stage3)\n \t\tcpp_pedwarn (pfile, \"no newline at end of file\");\n \t      handle_newline (pfile, '\\n');\n \t    }\n+\n+\t  /* Don't pop the last buffer.  */\n+\t  if (buffer->prev)\n+\t    {\n+\t      unsigned char stop = buffer->return_at_eof;\n+\n+\t      _cpp_pop_buffer (pfile);\n+\t      if (!stop)\n+\t\tgoto fresh_line;\n+\t    }\n \t}\n       result->type = CPP_EOF;\n       break;\n@@ -1090,13 +1043,17 @@ lex_token (pfile, result, skip_newlines)\n       goto skipped_white;\n \n     case '\\n': case '\\r':\n-      if (pfile->state.in_directive && pfile->state.parsing_args)\n-\tbuffer->read_ahead = c;\n-      else\n+      handle_newline (pfile, c);\n+      buffer->saved_flags = BOL;\n+      if (! pfile->state.in_directive)\n \t{\n-\t  handle_newline (pfile, c);\n-\t  if (skip_newlines)\n-\t    goto fresh_line;\n+\t  if (!pfile->keep_tokens)\n+\t    {\n+\t      pfile->cur_run = &pfile->base_run;\n+\t      result = pfile->base_run.base;\n+\t      pfile->cur_token = result + 1;\n+\t    }\n+\t  goto fresh_line;\n \t}\n       result->type = CPP_EOF;\n       break;\n@@ -1228,7 +1185,7 @@ lex_token (pfile, result, skip_newlines)\n       /* Save the comment as a token in its own right.  */\n       save_comment (pfile, result, comment_start);\n       /* Don't do MI optimisation.  */\n-      return;\n+      break;\n \n     case '<':\n       if (pfile->state.angled_headers)\n@@ -1397,6 +1354,8 @@ lex_token (pfile, result, skip_newlines)\n       result->val.c = c;\n       break;\n     }\n+\n+  return result;\n }\n \n /* An upper bound on the number of bytes needed to spell a token,"}, {"sha": "5fe4b1ef8ee1ed09647e9aa1df308fd7d9137c33", "filename": "gcc/cpplib.c", "status": "modified", "additions": 29, "deletions": 34, "changes": 63, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpplib.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpplib.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.c?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -176,7 +176,7 @@ DIRECTIVE_TABLE\n #undef D\n #undef DIRECTIVE_TABLE\n \n-#define SEEN_EOL() (pfile->lexer_pos.output_line > pfile->line)\n+#define SEEN_EOL() (pfile->cur_token[-1].type == CPP_EOF)\n \n /* Skip any remaining tokens in a directive.  */\n static void\n@@ -185,10 +185,6 @@ skip_rest_of_line (pfile)\n {\n   cpp_token token;\n \n-  /* Discard all input lookaheads.  */\n-  while (pfile->la_read)\n-    _cpp_release_lookahead (pfile);\n-\n   /* Discard all stacked contexts.  */\n   while (pfile->context != &pfile->base_context)\n     _cpp_pop_context (pfile);\n@@ -227,10 +223,6 @@ start_directive (pfile)\n   pfile->directive_pos = pfile->lexer_pos;\n   pfile->directive_pos.line = pfile->line;\n   pfile->directive_line = pfile->line;\n-\n-  /* Don't save directive tokens for external clients.  */\n-  pfile->la_saved = pfile->la_write;\n-  pfile->la_write = 0;\n }\n \n /* Called when leaving a directive, _Pragma or command-line directive.  */\n@@ -243,12 +235,14 @@ end_directive (pfile, skip_line)\n   if (skip_line)\n     {\n       skip_rest_of_line (pfile);\n-      /*  \"Accept\" the newline now.  */\n-      pfile->line++;\n+      if (!pfile->keep_tokens)\n+\t{\n+\t  pfile->cur_run = &pfile->base_run;\n+\t  pfile->cur_token = pfile->base_run.base;\n+\t}\n     }\n \n   /* Restore state.  */\n-  pfile->la_write = pfile->la_saved;\n   pfile->state.save_comments = ! CPP_OPTION (pfile, discard_comments);\n   pfile->state.in_directive = 0;\n   pfile->state.angled_headers = 0;\n@@ -289,7 +283,7 @@ _cpp_handle_directive (pfile, indented)\n \t{\n \t  dir = &dtable[T_LINE];\n \t  pfile->state.line_extension = 1;\n-\t  _cpp_push_token (pfile, &dname, &pfile->directive_pos);\n+\t  _cpp_backup_tokens (pfile, 1);\n \t  if (CPP_PEDANTIC (pfile) && ! CPP_OPTION (pfile, preprocessed))\n \t    cpp_pedwarn (pfile, \"# followed by integer\");\n \t}\n@@ -324,7 +318,7 @@ _cpp_handle_directive (pfile, indented)\n \t      /* We don't want to process this directive.  Put back the\n \t\t tokens so caller will see them (and issue an error,\n \t\t probably).  */\n-\t      _cpp_push_token (pfile, &dname, &pfile->directive_pos);\n+\t      _cpp_backup_tokens (pfile, 1);\n \t      skip = 0;\n \t    }\n \t}\n@@ -376,8 +370,8 @@ _cpp_handle_directive (pfile, indented)\n \t directives in skipped conditional groups (6.10 p4).  */\n       if (CPP_OPTION (pfile, lang) == CLK_ASM)\n \t{\n-\t  /* Output the # and lookahead token for the assembler.  */\n-\t  _cpp_push_token (pfile, &dname, &pfile->directive_pos);\n+\t  /* Output the # and this token for the assembler.  */\n+\t  _cpp_backup_tokens (pfile, 1);\n \t  skip = 0;\n \t}\n       else\n@@ -402,12 +396,11 @@ run_directive (pfile, dir_no, buf, count)\n   cpp_push_buffer (pfile, (const U_CHAR *) buf, count,\n \t\t   /* from_stage3 */ true, 1);\n   start_directive (pfile);\n-  pfile->state.bol = 0;\n+  pfile->buffer->saved_flags = 0; /* We don't want to recognise directives.  */\n   pfile->state.prevent_expansion++;\n   pfile->directive = &dtable[dir_no];\n   (void) (*pfile->directive->handler) (pfile);\n   pfile->state.prevent_expansion--;\n-  check_eol (pfile);\n   end_directive (pfile, 1);\n   _cpp_pop_buffer (pfile);\n }\n@@ -618,7 +611,7 @@ do_include_common (pfile, type)\n \t{\n \t  check_eol (pfile);\n \t  /* Get out of macro context, if we are.  */\n-\t  end_directive (pfile, 1);\n+\t  skip_rest_of_line (pfile);\n \t  if (pfile->cb.include)\n \t    (*pfile->cb.include) (pfile, pfile->directive_line,\n \t\t\t\t  pfile->directive->name, &header);\n@@ -772,7 +765,7 @@ do_line (pfile)\n       return;\n     }\n \n-  end_directive (pfile, 1);\n+  skip_rest_of_line (pfile);\n   _cpp_do_file_change (pfile, reason, new_file, new_lineno, new_sysp);\n }\n \n@@ -961,12 +954,13 @@ do_pragma (pfile)\n   pragma_cb handler = NULL;\n   const struct pragma_entry *p;\n   cpp_token tok;\n+  unsigned int count = 0;\n \n   p = pfile->pragmas;\n   pfile->state.prevent_expansion++;\n-  cpp_start_lookahead (pfile);\n \n  new_space:\n+  count++;\n   cpp_get_token (pfile, &tok);\n   if (tok.type == CPP_NAME)\n     {\n@@ -993,13 +987,14 @@ do_pragma (pfile)\n \t}\n     }\n \n-  cpp_stop_lookahead (pfile, handler != NULL);\n   pfile->state.prevent_expansion--;\n-\n   if (handler)\n     (*handler) (pfile);\n   else if (pfile->cb.def_pragma)\n-    (*pfile->cb.def_pragma) (pfile, pfile->directive_line);\n+    {\n+      _cpp_backup_tokens (pfile, count);\n+      (*pfile->cb.def_pragma) (pfile, pfile->directive_line);\n+    }\n }\n \n static void\n@@ -1066,7 +1061,7 @@ do_pragma_system_header (pfile)\n   else\n     {\n       check_eol (pfile);\n-      end_directive (pfile, 1);\n+      skip_rest_of_line (pfile);\n       cpp_make_system_header (pfile, 1, 0);\n     }\n }\n@@ -1092,11 +1087,12 @@ do_pragma_dependency (pfile)\n     {\n       cpp_warning (pfile, \"current file is older than %s\",\n \t\t   cpp_token_as_text (pfile, &header));\n-      cpp_start_lookahead (pfile);\n       cpp_get_token (pfile, &msg);\n-      cpp_stop_lookahead (pfile, msg.type == CPP_EOF);\n       if (msg.type != CPP_EOF)\n-\tdo_diagnostic (pfile, WARNING, 0);\n+\t{\n+\t  _cpp_backup_tokens (pfile, 1);\n+\t  do_diagnostic (pfile, WARNING, 0);\n+\t}\n     }\n }\n \n@@ -1387,19 +1383,18 @@ parse_answer (pfile, answerp, type)\n \n   /* In a conditional, it is legal to not have an open paren.  We\n      should save the following token in this case.  */\n-  if (type == T_IF)\n-    cpp_start_lookahead (pfile);\n   cpp_get_token (pfile, &paren);\n-  if (type == T_IF)\n-    cpp_stop_lookahead (pfile, paren.type == CPP_OPEN_PAREN);\n \n   /* If not a paren, see if we're OK.  */\n   if (paren.type != CPP_OPEN_PAREN)\n     {\n       /* In a conditional no answer is a test for any answer.  It\n          could be followed by any token.  */\n       if (type == T_IF)\n-\treturn 0;\n+\t{\n+\t  _cpp_backup_tokens (pfile, 1);\n+\t  return 0;\n+\t}\n \n       /* #unassert with no answer is valid - it removes all answers.  */\n       if (type == T_UNASSERT && paren.type == CPP_EOF)\n@@ -1755,6 +1750,7 @@ cpp_push_buffer (pfile, buffer, len, from_stage3, return_at_eof)\n   new->from_stage3 = from_stage3;\n   new->prev = pfile->buffer;\n   new->return_at_eof = return_at_eof;\n+  new->saved_flags = BOL;\n \n   pfile->buffer = new;\n \n@@ -1783,7 +1779,6 @@ _cpp_pop_buffer (pfile)\n      case of a missing #endif.  */\n   pfile->lexer_pos.output_line = pfile->line;\n   pfile->state.skipping = 0;\n-  pfile->state.bol = 1;\n \n   /* Update the reader's buffer before _cpp_do_file_change.  */\n   pfile->buffer = buffer->prev;"}, {"sha": "ef6a1a56b013816b0abcec1bab5ffebbead3252d", "filename": "gcc/cpplib.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpplib.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcpplib.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.h?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -167,6 +167,7 @@ struct cpp_string\n #define NAMED_OP\t(1 << 4) /* C++ named operators.  */\n #define NO_EXPAND\t(1 << 5) /* Do not macro-expand this token.  */\n #define AVOID_LPASTE\t(1 << 6) /* Check left for accidental pastes.  */\n+#define BOL\t\t(1 << 7) /* Token at beginning of line.  */\n \n /* A preprocessing token.  This has been carefully packed and should\n    occupy 12 bytes on 32-bit hosts and 16 bytes on 64-bit hosts.  */\n@@ -524,6 +525,7 @@ extern void cpp_get_token PARAMS ((cpp_reader *, cpp_token *));\n extern const cpp_lexer_pos *cpp_get_line PARAMS ((cpp_reader *));\n extern const unsigned char *cpp_macro_definition PARAMS ((cpp_reader *,\n \t\t\t\t\t\t  const cpp_hashnode *));\n+extern void _cpp_backup_tokens PARAMS ((cpp_reader *, unsigned int));\n \n /* Evaluate a CPP_CHAR or CPP_WCHAR token.  */\n extern HOST_WIDE_INT"}, {"sha": "357d1baa940d904c3e8c410165ea581ad5ca17ad", "filename": "gcc/cppmacro.c", "status": "modified", "additions": 77, "deletions": 181, "changes": 258, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcppmacro.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Fcppmacro.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppmacro.c?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -77,13 +77,6 @@ static int funlike_invocation_p PARAMS ((cpp_reader *, const cpp_hashnode *,\n static void replace_args PARAMS ((cpp_reader *, cpp_macro *, macro_arg *,\n \t\t\t\t  struct toklist *));\n \n-/* Lookaheads.  */\n-\n-static void save_lookahead_token PARAMS ((cpp_reader *, const cpp_token *));\n-static void take_lookahead_token PARAMS ((cpp_reader *, cpp_token *));\n-static cpp_lookahead *alloc_lookahead PARAMS ((cpp_reader *));\n-static void free_lookahead PARAMS ((cpp_lookahead *));\n-\n /* #define directive parsing and handling.  */\n \n static cpp_token *lex_expansion_token PARAMS ((cpp_reader *, cpp_macro *));\n@@ -175,7 +168,7 @@ builtin_macro (pfile, token)\n \t line of the macro's invocation, not its definition.\n \t Otherwise things like assert() will not work properly.  */\n       make_number_token (pfile, token,\n-\t\t\t SOURCE_LINE (pfile->map, cpp_get_line (pfile)->line));\n+\t\t\t SOURCE_LINE (pfile->map, pfile->cur_token[-1].line));\n       break;\n \n     case BT_STDC:\n@@ -224,6 +217,12 @@ const cpp_lexer_pos *\n cpp_get_line (pfile)\n      cpp_reader *pfile;\n {\n+  if (pfile->context->prev == NULL)\n+    {\n+      pfile->lexer_pos.line = pfile->cur_token[-1].line;\n+      pfile->lexer_pos.col = pfile->cur_token[-1].col;\n+    }\n+\n   return &pfile->lexer_pos;\n }\n \n@@ -486,10 +485,12 @@ parse_arg (pfile, arg, variadic)\n       /* Newlines in arguments are white space (6.10.3.10).  */\n       line = pfile->line;\n       cpp_get_token (pfile, token);\n+\n       if (line != pfile->line)\n \ttoken->flags |= PREV_WHITE;\n \n       result = token->type;\n+\n       if (result == CPP_OPEN_PAREN)\n \tparen++;\n       else if (result == CPP_CLOSE_PAREN && paren-- == 0)\n@@ -498,11 +499,37 @@ parse_arg (pfile, arg, variadic)\n       else if (result == CPP_COMMA && paren == 0 && !variadic)\n \tbreak;\n       else if (result == CPP_EOF)\n-\tbreak;\t\t/* Error reported by caller.  */\n+\t{\n+\t  /* We still need the EOF (added below) to end pre-expansion\n+\t     and directives.  */\n+\t  if (pfile->context->prev || pfile->state.in_directive)\n+\t    _cpp_backup_tokens (pfile, 1);\n+\t  /* Error reported by caller.  */\n+\t  break;\n+\t}\n+      else if (result == CPP_HASH && token->flags & BOL)\n+\t{\n+\t  /* 6.10.3 paragraph 11: If there are sequences of\n+\t     preprocessing tokens within the list of arguments that\n+\t     would otherwise act as preprocessing directives, the\n+\t     behavior is undefined.\n+\n+\t     This implementation will report a hard error, terminate\n+\t     the macro invocation, and proceed to process the\n+\t     directive.  */\n+\t  cpp_error (pfile,\n+\t\t     \"directives may not be used inside a macro argument\");\n+\t  _cpp_backup_tokens (pfile, 1);\n+\t  result = CPP_EOF;\n+\t  break;\n+\t}\n     }\n \n-  /* Commit the memory used to store the arguments.  */\n-  POOL_COMMIT (&pfile->argument_pool, arg->count * sizeof (cpp_token));\n+  /* Commit the memory used to store the arguments.  We make the last\n+     argument a CPP_EOF, so that it terminates macro pre-expansion,\n+     but it is not included in arg->count.  */\n+  arg->first[arg->count].type = CPP_EOF;  \n+  POOL_COMMIT (&pfile->argument_pool, (arg->count + 1) * sizeof (cpp_token));\n \n   return result;\n }\n@@ -600,17 +627,19 @@ funlike_invocation_p (pfile, node, list)\n   pfile->state.prevent_expansion++;\n \n   pfile->keep_tokens++;\n-  cpp_start_lookahead (pfile);\n   cpp_get_token (pfile, &maybe_paren);\n-  cpp_stop_lookahead (pfile, maybe_paren.type == CPP_OPEN_PAREN);\n   pfile->state.parsing_args = 2;\n \n   if (maybe_paren.type == CPP_OPEN_PAREN)\n     args = parse_args (pfile, node);\n-  else if (CPP_WTRADITIONAL (pfile) && ! node->value.macro->syshdr)\n-    cpp_warning (pfile,\n-\t \"function-like macro \\\"%s\\\" must be used with arguments in traditional C\",\n-\t\t NODE_NAME (node));\n+  else\n+    {\n+      _cpp_backup_tokens (pfile, 1);\n+      if (CPP_WTRADITIONAL (pfile) && ! node->value.macro->syshdr)\n+\tcpp_warning (pfile,\n+ \"function-like macro \\\"%s\\\" must be used with arguments in traditional C\",\n+\t\t     NODE_NAME (node));\n+    }\n \n   pfile->state.prevent_expansion--;\n   pfile->state.parsing_args = 0;\n@@ -623,13 +652,7 @@ funlike_invocation_p (pfile, node, list)\n   if (args)\n     {\n       if (node->value.macro->paramc > 0)\n-\t{\n-\t  /* Don't save tokens during pre-expansion.  */\n-\t  struct cpp_lookahead *la_saved = pfile->la_write;\n-\t  pfile->la_write = 0;\n-\t  replace_args (pfile, node->value.macro, args, list);\n-\t  pfile->la_write = la_saved;\n-\t}\n+\treplace_args (pfile, node->value.macro, args, list);\n       free (args);\n     }\n \n@@ -838,7 +861,7 @@ push_arg_context (pfile, arg)\n   cpp_context *context = next_context (pfile);\n   context->macro = 0;\n   context->list.first = arg->first;\n-  context->list.limit = arg->first + arg->count;\n+  context->list.limit = arg->first + arg->count + 1;\n \n   return context;\n }\n@@ -908,10 +931,8 @@ cpp_get_token (pfile, token)\n     {\n       cpp_context *context = pfile->context;\n \n-      if (pfile->la_read)\n-\ttake_lookahead_token (pfile, token);\n       /* Context->prev == 0 <=> base context.  */\n-      else if (!context->prev)\n+      if (!context->prev)\n \t_cpp_lex_token (pfile, token);\n       else if (context->list.first != context->list.limit)\n \t{\n@@ -928,17 +949,13 @@ cpp_get_token (pfile, token)\n \t}\n       else\n \t{\n-\t  if (context->macro)\n-\t    {\n-\t      /* Avoid accidental paste at the end of a macro.  */\n-\t      pfile->buffer->saved_flags |= AVOID_LPASTE;\n-\t      _cpp_pop_context (pfile);\n-\t      continue;\n-\t    }\n-\t  /* End of argument pre-expansion.  */\n-\t  token->type = CPP_EOF;\n-\t  token->flags = 0;\n-\t  return;\n+\t  if (!context->macro)\n+\t    cpp_ice (pfile, \"context->macro == 0\");\n+\n+\t  /* Avoid accidental paste at the end of a macro.  */\n+\t  pfile->buffer->saved_flags |= AVOID_LPASTE;\n+\t  _cpp_pop_context (pfile);\n+\t  continue;\n \t}\n \n       if (token->type != CPP_NAME)\n@@ -983,9 +1000,6 @@ cpp_get_token (pfile, token)\n          since this token came from either the lexer or a macro.  */\n       _cpp_do__Pragma (pfile);\n     }\n-\n-  if (pfile->la_write)\n-    save_lookahead_token (pfile, token);\n }\n \n /* Returns true if we're expanding an object-like macro that was\n@@ -1013,154 +1027,36 @@ cpp_scan_nooutput (pfile)\n   while (token.type != CPP_EOF);\n }\n \n-/* Lookahead handling.  */\n-\n-static void\n-save_lookahead_token (pfile, token)\n-     cpp_reader *pfile;\n-     const cpp_token *token;\n-{\n-  cpp_lookahead *la = pfile->la_write;\n-  cpp_token_with_pos *twp;\n-\n-  if (la->count == la->cap)\n-    {\n-      la->cap += la->cap + 8;\n-      la->tokens = (cpp_token_with_pos *)\n-\txrealloc (la->tokens, la->cap * sizeof (cpp_token_with_pos));\n-    }\n-\n-  twp = &la->tokens[la->count++];\n-  twp->token = *token;\n-  twp->pos = *cpp_get_line (pfile);\n-}\n-\n-static void\n-take_lookahead_token (pfile, token)\n-     cpp_reader *pfile;\n-     cpp_token *token;\n-{\n-  cpp_lookahead *la = pfile->la_read;\n-  cpp_token_with_pos *twp = &la->tokens[la->cur];\n-\n-  *token = twp->token;\n-  pfile->lexer_pos = twp->pos;\n-\n-  if (++la->cur == la->count)\n-    _cpp_release_lookahead (pfile);\n-}\n-\n-/* Moves the lookahead at the front of the read list to the free store.  */\n+/* Step back one (or more) tokens.  Can only step mack more than 1 if\n+   they are from the lexer, and not from macro expansion.  */\n void\n-_cpp_release_lookahead (pfile)\n+_cpp_backup_tokens (pfile, count)\n      cpp_reader *pfile;\n+     unsigned int count;\n {\n-  cpp_lookahead *la = pfile->la_read;\n-\n-  pfile->la_read = la->next;\n-  la->next = pfile->la_unused;\n-  pfile->la_unused = la;\n-  unlock_pools (pfile);\n-}\n-\n-/* Take a new lookahead from the free store, or allocate one if none.  */\n-static cpp_lookahead *\n-alloc_lookahead (pfile)\n-     cpp_reader *pfile;\n-{\n-  cpp_lookahead *la = pfile->la_unused;\n-\n-  if (la)\n-    pfile->la_unused = la->next;\n-  else\n+  if (pfile->context->prev == NULL)\n     {\n-      la = xnew (cpp_lookahead);\n-      la->tokens = 0;\n-      la->cap = 0;\n+      pfile->lookaheads += count;\n+      while (count--)\n+\t{\n+\t  pfile->cur_token--;\n+\t  if (pfile->cur_token == pfile->cur_run->base)\n+\t    {\n+\t      if (pfile->cur_run == NULL)\n+\t\tabort ();\n+\t      pfile->cur_run = pfile->cur_run->prev;\n+\t      pfile->cur_token = pfile->cur_run->limit;\n+\t    }\n+\t}\n     }\n-\n-  la->cur = la->count = 0;\n-  return la;\n-}\n-\n-/* Free memory associated with a lookahead list.  */\n-static void\n-free_lookahead (la)\n-     cpp_lookahead *la;\n-{\n-  if (la->tokens)\n-    free ((PTR) la->tokens);\n-  free ((PTR) la);\n-}\n-\n-/* Free all the lookaheads of a cpp_reader.  */\n-void\n-_cpp_free_lookaheads (pfile)\n-     cpp_reader *pfile;\n-{\n-  cpp_lookahead *la, *lan;\n-\n-  if (pfile->la_read)\n-    free_lookahead (pfile->la_read);\n-  if (pfile->la_write)\n-    free_lookahead (pfile->la_write);\n-\n-  for (la = pfile->la_unused; la; la = lan)\n+  else\n     {\n-      lan = la->next;\n-      free_lookahead (la);\n+      if (count != 1)\n+\tabort ();\n+      pfile->context->list.first--;\n     }\n }\n \n-/* Allocate a lookahead and move it to the front of the write list.  */\n-void\n-cpp_start_lookahead (pfile)\n-     cpp_reader *pfile;\n-{\n-  cpp_lookahead *la = alloc_lookahead (pfile);\n-\n-  la->next = pfile->la_write;\n-  pfile->la_write = la;\n-\n-  la->pos = *cpp_get_line (pfile);\n-\n-  /* Don't allow memory pools to be re-used whilst we're reading ahead.  */\n-  lock_pools (pfile);\n-}\n-\n-/* Stop reading ahead - either step back, or drop the read ahead.  */\n-void\n-cpp_stop_lookahead (pfile, drop)\n-     cpp_reader *pfile;\n-     int drop;\n-{\n-  cpp_lookahead *la = pfile->la_write;\n-\n-  pfile->la_write = la->next;\n-  la->next = pfile->la_read;\n-  pfile->la_read = la;\n-\n-  if (drop || la->count == 0)\n-    _cpp_release_lookahead (pfile);\n-  else\n-    pfile->lexer_pos = la->pos;\n-}\n-\n-/* Push a single token back to the front of the queue.  Only to be\n-   used by cpplib, and only then when necessary.  POS is the position\n-   to report for the preceding token.  */\n-void\n-_cpp_push_token (pfile, token, pos)\n-     cpp_reader *pfile;\n-     const cpp_token *token;\n-     const cpp_lexer_pos *pos;\n-{\n-  cpp_start_lookahead (pfile);\n-  save_lookahead_token (pfile, token);\n-  cpp_stop_lookahead (pfile, 0);\n-  pfile->lexer_pos = *pos;\n-}\n-\n /* #define directive parsing and handling.  */\n \n /* Returns non-zero if a macro redefinition warning is required.  */"}, {"sha": "ee7987c67b0dbefce502459aa901e34b40803492", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -1,3 +1,8 @@\n+2001-09-13  Neil Booth  <neil@daikokuya.demon.co.uk>\n+\n+\t* gcc.dg/cpp/directiv.c: Update.\n+\t* gcc.dg/cpp/undef1.c: Update.\n+\n 2001-09-12  Jakub Jelinek  <jakub@redhat.com>\n \n \t* gcc.dg/20010912-1.c: New test."}, {"sha": "cbf4ac6501c65a0fb6a39d75d4cc6ac6504dbba6", "filename": "gcc/testsuite/gcc.dg/cpp/directiv.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fdirectiv.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fdirectiv.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fdirectiv.c?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -28,7 +28,7 @@ EMPTY #define bar\n /* Check that directives always start a line, even if in middle of\n    macro expansion.  */\n #define func(x) x\n-func (2\t\t/* { dg-error \"unterminated\" \"\" { target *-*-* } 32 } */\n+func (2\t\t/* { dg-error \"unterminated\" \"\" } */\n #define foobar\t/* { dg-error \"directives may not\" } */\n \n /* Check newlines end directives, even in function-like macro"}, {"sha": "446fc93117dd4a8be4001946e9f79f6603e6fe89", "filename": "gcc/testsuite/gcc.dg/cpp/undef1.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fundef1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bdcbe49686fce1d35955579428aa2ade21dd941c/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fundef1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fundef1.c?ref=bdcbe49686fce1d35955579428aa2ade21dd941c", "patch": "@@ -9,6 +9,6 @@\n \n #define foo(bar) bar\n \n-foo( blah\t/* { dg-error \"unterminated\" \"\" { target *-*-* } 13 } */\n+foo( blah\t/* { dg-error \"unterminated\" \"\" } */\n #undef foo\t/* { dg-error \"may not be used inside\" \"foo(#undef foo)\" } */\n      blah )"}]}