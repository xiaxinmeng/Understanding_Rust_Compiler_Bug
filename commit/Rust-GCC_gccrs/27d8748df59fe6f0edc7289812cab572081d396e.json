{"sha": "27d8748df59fe6f0edc7289812cab572081d396e", "node_id": "C_kwDOANBUbNoAKDI3ZDg3NDhkZjU5ZmU2ZjBlZGM3Mjg5ODEyY2FiNTcyMDgxZDM5NmU", "commit": {"author": {"name": "Andre Vieira", "email": "andre.simoesdiasvieira@arm.com", "date": "2022-03-22T10:48:41Z"}, "committer": {"name": "Andre Vieira", "email": "andre.simoesdiasvieira@arm.com", "date": "2022-03-22T12:00:52Z"}, "message": "aarch64: Add Demeter tuning structs\n\nThis patch adds tuning structs for -mcpu/-mtune=demeter.\n\ngcc/ChangeLog:\n\n2022-03-22  Tamar Christina  <tamar.christina@arm.com>\n\t    Andre Vieira  <andre.simoesdiasvieira@arm.com>\n\n\t* config/aarch64/aarch64.cc (demeter_addrcost_table,\n\tdemeter_regmove_cost, demeter_advsimd_vector_cost,\n\tdemeter_sve_vector_cost, demeter_scalar_issue_info,\n\tdemeter_advsimd_issue_info, demeter_sve_issue_info,\n\tdemeter_vec_issue_info, demeter_vector_cost,\n\tdemeter_tunings): New tuning structs.\n\t(aarch64_ve_op_count::rename_cycles_per_iter): Enable for demeter\n\ttuning.\n\t* config/aarch64/aarch64-cores.def: Add entry for demeter.\n\t* config/aarch64/aarch64-tune.md (tune): Add demeter to list.", "tree": {"sha": "eb7b86626f52920f22416c643bdc2a3f9afec107", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/eb7b86626f52920f22416c643bdc2a3f9afec107"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/27d8748df59fe6f0edc7289812cab572081d396e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/27d8748df59fe6f0edc7289812cab572081d396e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/27d8748df59fe6f0edc7289812cab572081d396e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/27d8748df59fe6f0edc7289812cab572081d396e/comments", "author": {"login": "avieira-arm", "id": 68072104, "node_id": "MDQ6VXNlcjY4MDcyMTA0", "avatar_url": "https://avatars.githubusercontent.com/u/68072104?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avieira-arm", "html_url": "https://github.com/avieira-arm", "followers_url": "https://api.github.com/users/avieira-arm/followers", "following_url": "https://api.github.com/users/avieira-arm/following{/other_user}", "gists_url": "https://api.github.com/users/avieira-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/avieira-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avieira-arm/subscriptions", "organizations_url": "https://api.github.com/users/avieira-arm/orgs", "repos_url": "https://api.github.com/users/avieira-arm/repos", "events_url": "https://api.github.com/users/avieira-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/avieira-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "avieira-arm", "id": 68072104, "node_id": "MDQ6VXNlcjY4MDcyMTA0", "avatar_url": "https://avatars.githubusercontent.com/u/68072104?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avieira-arm", "html_url": "https://github.com/avieira-arm", "followers_url": "https://api.github.com/users/avieira-arm/followers", "following_url": "https://api.github.com/users/avieira-arm/following{/other_user}", "gists_url": "https://api.github.com/users/avieira-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/avieira-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avieira-arm/subscriptions", "organizations_url": "https://api.github.com/users/avieira-arm/orgs", "repos_url": "https://api.github.com/users/avieira-arm/repos", "events_url": "https://api.github.com/users/avieira-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/avieira-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b074fa69707a891f07f06f0b1a95999447f66149", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b074fa69707a891f07f06f0b1a95999447f66149", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b074fa69707a891f07f06f0b1a95999447f66149"}], "stats": {"total": 224, "additions": 222, "deletions": 2}, "files": [{"sha": "9e6ca84bd4b277ccf2c1809c419703a23075f315", "filename": "gcc/config/aarch64/aarch64-cores.def", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/27d8748df59fe6f0edc7289812cab572081d396e/gcc%2Fconfig%2Faarch64%2Faarch64-cores.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/27d8748df59fe6f0edc7289812cab572081d396e/gcc%2Fconfig%2Faarch64%2Faarch64-cores.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-cores.def?ref=27d8748df59fe6f0edc7289812cab572081d396e", "patch": "@@ -172,4 +172,6 @@ AARCH64_CORE(\"cortex-a710\",  cortexa710, cortexa57, 9A,  AARCH64_FL_FOR_ARCH9 |\n \n AARCH64_CORE(\"cortex-x2\",  cortexx2, cortexa57, 9A,  AARCH64_FL_FOR_ARCH9 | AARCH64_FL_SVE2_BITPERM | AARCH64_FL_MEMTAG | AARCH64_FL_I8MM | AARCH64_FL_BF16, neoversen2, 0x41, 0xd48, -1)\n \n+AARCH64_CORE(\"demeter\", demeter, cortexa57, 9A, AARCH64_FL_FOR_ARCH9 | AARCH64_FL_I8MM | AARCH64_FL_BF16 | AARCH64_FL_SVE2_BITPERM | AARCH64_FL_RNG | AARCH64_FL_MEMTAG | AARCH64_FL_PROFILE, demeter, 0x41, 0xd4f, -1)\n+\n #undef AARCH64_CORE"}, {"sha": "dda5dbdda75c1383004f5dac3f249909f7f23589", "filename": "gcc/config/aarch64/aarch64-tune.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/27d8748df59fe6f0edc7289812cab572081d396e/gcc%2Fconfig%2Faarch64%2Faarch64-tune.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/27d8748df59fe6f0edc7289812cab572081d396e/gcc%2Fconfig%2Faarch64%2Faarch64-tune.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-tune.md?ref=27d8748df59fe6f0edc7289812cab572081d396e", "patch": "@@ -1,5 +1,5 @@\n ;; -*- buffer-read-only: t -*-\n ;; Generated automatically by gentune.sh from aarch64-cores.def\n (define_attr \"tune\"\n-\t\"cortexa34,cortexa35,cortexa53,cortexa57,cortexa72,cortexa73,thunderx,thunderxt88p1,thunderxt88,octeontx,octeontxt81,octeontxt83,thunderxt81,thunderxt83,ampere1,emag,xgene1,falkor,qdf24xx,exynosm1,phecda,thunderx2t99p1,vulcan,thunderx2t99,cortexa55,cortexa75,cortexa76,cortexa76ae,cortexa77,cortexa78,cortexa78ae,cortexa78c,cortexa65,cortexa65ae,cortexx1,ares,neoversen1,neoversee1,octeontx2,octeontx2t98,octeontx2t96,octeontx2t93,octeontx2f95,octeontx2f95n,octeontx2f95mm,a64fx,tsv110,thunderx3t110,zeus,neoversev1,neoverse512tvb,saphira,neoversen2,cortexa57cortexa53,cortexa72cortexa53,cortexa73cortexa35,cortexa73cortexa53,cortexa75cortexa55,cortexa76cortexa55,cortexr82,cortexa510,cortexa710,cortexx2\"\n+\t\"cortexa34,cortexa35,cortexa53,cortexa57,cortexa72,cortexa73,thunderx,thunderxt88p1,thunderxt88,octeontx,octeontxt81,octeontxt83,thunderxt81,thunderxt83,ampere1,emag,xgene1,falkor,qdf24xx,exynosm1,phecda,thunderx2t99p1,vulcan,thunderx2t99,cortexa55,cortexa75,cortexa76,cortexa76ae,cortexa77,cortexa78,cortexa78ae,cortexa78c,cortexa65,cortexa65ae,cortexx1,ares,neoversen1,neoversee1,octeontx2,octeontx2t98,octeontx2t96,octeontx2t93,octeontx2f95,octeontx2f95n,octeontx2f95mm,a64fx,tsv110,thunderx3t110,zeus,neoversev1,neoverse512tvb,saphira,neoversen2,cortexa57cortexa53,cortexa72cortexa53,cortexa73cortexa35,cortexa73cortexa53,cortexa75cortexa55,cortexa76cortexa55,cortexr82,cortexa510,cortexa710,cortexx2,demeter\"\n \t(const (symbol_ref \"((enum attr_tune) aarch64_tune)\")))"}, {"sha": "9fbc4f322c5ef1be0392e0c23d0ab8992d96c34c", "filename": "gcc/config/aarch64/aarch64.cc", "status": "modified", "additions": 219, "deletions": 1, "changes": 220, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/27d8748df59fe6f0edc7289812cab572081d396e/gcc%2Fconfig%2Faarch64%2Faarch64.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/27d8748df59fe6f0edc7289812cab572081d396e/gcc%2Fconfig%2Faarch64%2Faarch64.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.cc?ref=27d8748df59fe6f0edc7289812cab572081d396e", "patch": "@@ -537,6 +537,24 @@ static const struct cpu_addrcost_table neoversen2_addrcost_table =\n   0 /* imm_offset  */\n };\n \n+static const struct cpu_addrcost_table demeter_addrcost_table =\n+{\n+    {\n+      1, /* hi  */\n+      0, /* si  */\n+      0, /* di  */\n+      1, /* ti  */\n+    },\n+  0, /* pre_modify  */\n+  0, /* post_modify  */\n+  2, /* post_modify_ld3_st3  */\n+  2, /* post_modify_ld4_st4  */\n+  0, /* register_offset  */\n+  0, /* register_sextend  */\n+  0, /* register_zextend  */\n+  0 /* imm_offset  */\n+};\n+\n static const struct cpu_regmove_cost generic_regmove_cost =\n {\n   1, /* GP2GP  */\n@@ -652,6 +670,16 @@ static const struct cpu_regmove_cost neoversen2_regmove_cost =\n   2 /* FP2FP  */\n };\n \n+static const struct cpu_regmove_cost demeter_regmove_cost =\n+{\n+  1, /* GP2GP  */\n+  /* Spilling to int<->fp instead of memory is recommended so set\n+     realistic costs compared to memmov_cost.  */\n+  3, /* GP2FP  */\n+  2, /* FP2GP  */\n+  2 /* FP2FP  */\n+};\n+\n /* Generic costs for Advanced SIMD vector operations.   */\n static const advsimd_vec_cost generic_advsimd_vector_cost =\n {\n@@ -2391,6 +2419,195 @@ static const struct tune_params neoversen2_tunings =\n   &generic_prefetch_tune\n };\n \n+static const advsimd_vec_cost demeter_advsimd_vector_cost =\n+{\n+  2, /* int_stmt_cost  */\n+  2, /* fp_stmt_cost  */\n+  2, /* ld2_st2_permute_cost */\n+  2, /* ld3_st3_permute_cost  */\n+  3, /* ld4_st4_permute_cost  */\n+  3, /* permute_cost  */\n+  4, /* reduc_i8_cost  */\n+  4, /* reduc_i16_cost  */\n+  2, /* reduc_i32_cost  */\n+  2, /* reduc_i64_cost  */\n+  6, /* reduc_f16_cost  */\n+  3, /* reduc_f32_cost  */\n+  2, /* reduc_f64_cost  */\n+  2, /* store_elt_extra_cost  */\n+  /* This value is just inherited from the Cortex-A57 table.  */\n+  8, /* vec_to_scalar_cost  */\n+  /* This depends very much on what the scalar value is and\n+     where it comes from.  E.g. some constants take two dependent\n+     instructions or a load, while others might be moved from a GPR.\n+     4 seems to be a reasonable compromise in practice.  */\n+  4, /* scalar_to_vec_cost  */\n+  4, /* align_load_cost  */\n+  4, /* unalign_load_cost  */\n+  /* Although stores have a latency of 2 and compete for the\n+     vector pipes, in practice it's better not to model that.  */\n+  1, /* unalign_store_cost  */\n+  1  /* store_cost  */\n+};\n+\n+static const sve_vec_cost demeter_sve_vector_cost =\n+{\n+  {\n+    2, /* int_stmt_cost  */\n+    2, /* fp_stmt_cost  */\n+    3, /* ld2_st2_permute_cost  */\n+    3, /* ld3_st3_permute_cost  */\n+    4, /* ld4_st4_permute_cost  */\n+    3, /* permute_cost  */\n+    /* Theoretically, a reduction involving 15 scalar ADDs could\n+       complete in ~3 cycles and would have a cost of 15.  [SU]ADDV\n+       completes in 11 cycles, so give it a cost of 15 + 8.  */\n+    21, /* reduc_i8_cost  */\n+    /* Likewise for 7 scalar ADDs (~2 cycles) vs. 9: 7 + 7.  */\n+    14, /* reduc_i16_cost  */\n+    /* Likewise for 3 scalar ADDs (~2 cycles) vs. 8: 3 + 4.  */\n+    7, /* reduc_i32_cost  */\n+    /* Likewise for 1 scalar ADD (~1 cycles) vs. 2: 1 + 1.  */\n+    2, /* reduc_i64_cost  */\n+    /* Theoretically, a reduction involving 7 scalar FADDs could\n+       complete in ~6 cycles and would have a cost of 14.  FADDV\n+       completes in 8 cycles, so give it a cost of 14 + 2.  */\n+    16, /* reduc_f16_cost  */\n+    /* Likewise for 3 scalar FADDs (~4 cycles) vs. 6: 6 + 2.  */\n+    8, /* reduc_f32_cost  */\n+    /* Likewise for 1 scalar FADD (~2 cycles) vs. 4: 2 + 2.  */\n+    4, /* reduc_f64_cost  */\n+    2, /* store_elt_extra_cost  */\n+    /* This value is just inherited from the Cortex-A57 table.  */\n+    8, /* vec_to_scalar_cost  */\n+    /* See the comment above the Advanced SIMD versions.  */\n+    4, /* scalar_to_vec_cost  */\n+    4, /* align_load_cost  */\n+    4, /* unalign_load_cost  */\n+    /* Although stores have a latency of 2 and compete for the\n+       vector pipes, in practice it's better not to model that.  */\n+    1, /* unalign_store_cost  */\n+    1  /* store_cost  */\n+  },\n+  3, /* clast_cost  */\n+  10, /* fadda_f16_cost  */\n+  6, /* fadda_f32_cost  */\n+  4, /* fadda_f64_cost  */\n+  /* A strided Advanced SIMD x64 load would take two parallel FP loads\n+     (8 cycles) plus an insertion (2 cycles).  Assume a 64-bit SVE gather\n+     is 1 cycle more.  The Advanced SIMD version is costed as 2 scalar loads\n+     (cost 8) and a vec_construct (cost 2).  Add a full vector operation\n+     (cost 2) to that, to avoid the difference being lost in rounding.\n+\n+     There is no easy comparison between a strided Advanced SIMD x32 load\n+     and an SVE 32-bit gather, but cost an SVE 32-bit gather as 1 vector\n+     operation more than a 64-bit gather.  */\n+  14, /* gather_load_x32_cost  */\n+  12, /* gather_load_x64_cost  */\n+  3 /* scatter_store_elt_cost  */\n+};\n+\n+static const aarch64_scalar_vec_issue_info demeter_scalar_issue_info =\n+{\n+  3, /* loads_stores_per_cycle  */\n+  2, /* stores_per_cycle  */\n+  6, /* general_ops_per_cycle  */\n+  0, /* fp_simd_load_general_ops  */\n+  1 /* fp_simd_store_general_ops  */\n+};\n+\n+static const aarch64_advsimd_vec_issue_info demeter_advsimd_issue_info =\n+{\n+  {\n+    3, /* loads_stores_per_cycle  */\n+    2, /* stores_per_cycle  */\n+    4, /* general_ops_per_cycle  */\n+    0, /* fp_simd_load_general_ops  */\n+    1 /* fp_simd_store_general_ops  */\n+  },\n+  2, /* ld2_st2_general_ops  */\n+  2, /* ld3_st3_general_ops  */\n+  3 /* ld4_st4_general_ops  */\n+};\n+\n+static const aarch64_sve_vec_issue_info demeter_sve_issue_info =\n+{\n+  {\n+    {\n+      3, /* loads_per_cycle  */\n+      2, /* stores_per_cycle  */\n+      4, /* general_ops_per_cycle  */\n+      0, /* fp_simd_load_general_ops  */\n+      1 /* fp_simd_store_general_ops  */\n+    },\n+    2, /* ld2_st2_general_ops  */\n+    3, /* ld3_st3_general_ops  */\n+    3 /* ld4_st4_general_ops  */\n+  },\n+  2, /* pred_ops_per_cycle  */\n+  2, /* while_pred_ops  */\n+  2, /* int_cmp_pred_ops  */\n+  1, /* fp_cmp_pred_ops  */\n+  1, /* gather_scatter_pair_general_ops  */\n+  1 /* gather_scatter_pair_pred_ops  */\n+};\n+\n+static const aarch64_vec_issue_info demeter_vec_issue_info =\n+{\n+  &demeter_scalar_issue_info,\n+  &demeter_advsimd_issue_info,\n+  &demeter_sve_issue_info\n+};\n+\n+/* Demeter costs for vector insn classes.  */\n+static const struct cpu_vector_cost demeter_vector_cost =\n+{\n+  1, /* scalar_int_stmt_cost  */\n+  2, /* scalar_fp_stmt_cost  */\n+  4, /* scalar_load_cost  */\n+  1, /* scalar_store_cost  */\n+  1, /* cond_taken_branch_cost  */\n+  1, /* cond_not_taken_branch_cost  */\n+  &demeter_advsimd_vector_cost, /* advsimd  */\n+  &demeter_sve_vector_cost, /* sve  */\n+  &demeter_vec_issue_info /* issue_info  */\n+};\n+\n+static const struct tune_params demeter_tunings =\n+{\n+  &cortexa76_extra_costs,\n+  &demeter_addrcost_table,\n+  &demeter_regmove_cost,\n+  &demeter_vector_cost,\n+  &generic_branch_cost,\n+  &generic_approx_modes,\n+  SVE_128, /* sve_width  */\n+  { 4, /* load_int.  */\n+    2, /* store_int.  */\n+    6, /* load_fp.  */\n+    1, /* store_fp.  */\n+    6, /* load_pred.  */\n+    2 /* store_pred.  */\n+  }, /* memmov_cost.  */\n+  5, /* issue_rate  */\n+  (AARCH64_FUSE_AES_AESMC | AARCH64_FUSE_CMP_BRANCH), /* fusible_ops  */\n+  \"32:16\",\t/* function_align.  */\n+  \"4\",\t\t/* jump_align.  */\n+  \"32:16\",\t/* loop_align.  */\n+  3,\t/* int_reassoc_width.  */\n+  6,\t/* fp_reassoc_width.  */\n+  3,\t/* vec_reassoc_width.  */\n+  2,\t/* min_div_recip_mul_sf.  */\n+  2,\t/* min_div_recip_mul_df.  */\n+  0,\t/* max_case_values.  */\n+  tune_params::AUTOPREFETCHER_WEAK,\t/* autoprefetcher_model.  */\n+  (AARCH64_EXTRA_TUNE_CHEAP_SHIFT_EXTEND\n+   | AARCH64_EXTRA_TUNE_CSE_SVE_VL_CONSTANTS\n+   | AARCH64_EXTRA_TUNE_USE_NEW_VECTOR_COSTS\n+   | AARCH64_EXTRA_TUNE_MATCHED_VECTOR_THROUGHPUT),\t/* tune_flags.  */\n+  &generic_prefetch_tune\n+};\n+\n static const struct tune_params a64fx_tunings =\n {\n   &a64fx_extra_costs,\n@@ -15304,7 +15521,8 @@ fractional_cost\n aarch64_vec_op_count::rename_cycles_per_iter () const\n {\n   if (sve_issue_info () == &neoverse512tvb_sve_issue_info\n-      || sve_issue_info () == &neoversen2_sve_issue_info)\n+      || sve_issue_info () == &neoversen2_sve_issue_info\n+      || sve_issue_info () == &demeter_sve_issue_info)\n     /* + 1 for an addition.  We've already counted a general op for each\n        store, so we don't need to account for stores separately.  The branch\n        reads no registers and so does not need to be counted either."}]}