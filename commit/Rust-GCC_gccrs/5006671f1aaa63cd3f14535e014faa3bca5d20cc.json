{"sha": "5006671f1aaa63cd3f14535e014faa3bca5d20cc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTAwNjY3MWYxYWFhNjNjZDNmMTQ1MzVlMDE0ZmFhM2JjYTVkMjBjYw==", "commit": {"author": {"name": "Richard Guenther", "email": "rguenther@suse.de", "date": "2009-04-03T10:24:28Z"}, "committer": {"name": "Richard Biener", "email": "rguenth@gcc.gnu.org", "date": "2009-04-03T10:24:28Z"}, "message": "re PR middle-end/13146 (inheritance for nonoverlapping_component_refs_p)\n\n2009-04-03  Richard Guenther  <rguenther@suse.de>\n\n\tPR middle-end/13146\n\tPR tree-optimization/23940\n\tPR tree-optimization/33237\n\tPR middle-end/33974\n\tPR middle-end/34093\n\tPR tree-optimization/36201\n\tPR tree-optimization/36230\n\tPR tree-optimization/38049\n\tPR tree-optimization/38207\n\tPR tree-optimization/38230\n\tPR tree-optimization/38301\n\tPR tree-optimization/38585\n\tPR middle-end/38895\n\tPR tree-optimization/38985\n\tPR tree-optimization/39299\n\t* tree-ssa-structalias.h: Remove.\n\t* tree-ssa-operands.h (NULL_USE_OPERAND_P): Make of type use_operand_p.\n\t(NULL_DEF_OPERAND_P): Make of type def_operand_p.\n\t(struct vuse_element_d): Remove.\n\t(struct vuse_vec_d): Likewise.\n\t(VUSE_VECT_NUM_ELEM, VUSE_VECT_ELEMENT_NC, VUSE_ELEMENT_PTR_NC,\n\tVUSE_ELEMENT_VAR_NC, VUSE_VECT_ELEMENT, VUSE_ELEMENT_PTR,\n\tSET_VUSE_VECT_ELEMENT, SET_VUSE_ELEMENT_VAR, SET_VUSE_ELEMENT_PTR,\n\tVUSE_ELEMENT_VAR): Likewise.\n\t(struct voptype_d): Likewise.\n\t(NUM_VOP_FREE_BUCKETS): Likewise.\n\t(struct ssa_operands): Remove vop_free_buckets and mpt_table fields.\n\t(struct stmt_operands_d): Remove.\n\t(VUSE_OP_PTR, VUSE_OP, SET_VUSE_OP, VUSE_NUM, VUSE_VECT,\n\tVDEF_RESULT_PTR, VDEF_RESULT, VDEF_OP_PTR, VDEF_OP, SET_VDEF_OP,\n\tVDEF_NUM, VDEF_VECT): Likewise.\n\t(copy_virtual_operands): Remove.\n\t(operand_build_cmp): Likewise.\n\t(create_ssa_artificial_load_stmt): Likewise.\n\t(enum ssa_op_iter_type): Remove ssa_op_iter_vdef.\n\t(struct ssa_operand_iterator_d): Remove vuses, vdefs, mayusesm\n\tvuse_index and mayuse_index members.  Pack and move done and iter_type\n\tmembers to the front.\n\t(SSA_OP_VMAYUSE): Remove.\n\t(SSA_OP_VIRTUAL_USES): Adjust.\n\t(FOR_EACH_SSA_VDEF_OPERAND): Remove.\n\t(unlink_stmt_vdef): Declare.\n\t(add_to_addressable_set): Remove.\n\t* tree-vrp.c (stmt_interesting_for_vrp): Adjust.\n\t(vrp_visit_stmt): Likewise.\n\t* doc/tree-ssa.texi (Alias analysis): Update.\n\t* doc/invoke.texi (max-aliased-vops): Remove docs.\n\t(avg-aliased-vops): Likewise.\n\t* tree-into-ssa.c (syms_to_rename): Remove.\n\t(need_to_update_vops_p): Likewise.\n\t(need_to_initialize_update_ssa_p): Rename to ...\n\t(update_ssa_initialized_fn): ... this.  Track function we are\n\tinitialized for.\n\t(symbol_marked_for_renaming): Simplify.\n\t(add_new_name_mapping): Do not set need_to_update_vops_p.\n\t(dump_currdefs): Use SYMS_TO_RENAME.\n\t(rewrite_update_stmt): Always walk all uses/defs.\n\t(dump_update_ssa): Adjust.\n\t(init_update_ssa): Take function argument.  Track what we are\n\tinitialized for.\n\t(delete_update_ssa): Reset SYMS_TO_RENAME and update_ssa_initialized_fn.\n\t(create_new_def_for): Initialize for cfun, assert we are initialized\n\tfor cfun.\n\t(mark_sym_for_renaming): Simplify.\n\t(mark_set_for_renaming): Do not initialize update-ssa.\n\t(need_ssa_update_p): Simplify.  Take function argument.\n\t(name_mappings_registered_p): Assert we ask for the correct function.\n\t(name_registered_for_update_p): Likewise.\n\t(ssa_names_to_replace): Likewise.\n\t(release_ssa_name_after_update_ssa): Likewise.\n\t(update_ssa): Likewise.  Use SYMS_TO_RENAME.\n\t(dump_decl_set): Do not print a newline.\n\t(debug_decl_set): Do it here.\n\t(dump_update_ssa): And here.\n\t* tree-ssa-loop-im.c (move_computations): Adjust.\n\t(movement_possibility): Likewise.\n\t(determine_max_movement): Likewise.\n\t(gather_mem_refs_stmt): Likewise.\n\t* tree-dump.c (dequeue_and_dump): Do not handle SYMBOL_MEMORY_TAG\n\tor NAME_MEMORY_TAG.\n\t* tree-complex.c (update_all_vops): Remove.\n\t(expand_complex_move): Adjust.\n\t* tree-ssa-loop-niter.c (chain_of_csts_start): Use NULL_TREE.\n\tSimplify test for memory referencing statement.  Exclude\n\tnon-invariant ADDR_EXPRs.\n\t* tree-pretty-print.c (dump_generic_node): Do not handle memory tags.\n\t* tree-loop-distribution.c (generate_memset_zero): Adjust.\n\t(rdg_flag_uses): Likewise.\n\t* tree-tailcall.c (suitable_for_tail_opt_p): Remove memory-tag\n\trelated code.\n\t(tree_optimize_tail_calls_1): Also split the\n\tedge from the entry block if we have degenerate PHI nodes in\n\tthe first basic block.\n\t* tree.c (init_ttree): Remove memory-tag related code.\n\t(tree_code_size): Likewise.\n\t(tree_node_structure): Likewise.\n\t(build7_stat): Re-write to be build6_stat.\n\t* tree.h (MTAG_P, TREE_MEMORY_TAG_CHECK, TMR_TAG): Remove.\n\t(SSA_VAR_P): Adjust.\n\t(struct tree_memory_tag): Remove.\n\t(struct tree_memory_partition_tag): Likewise.\n\t(union tree_node): Adjust.\n\t(build7): Re-write to be build6.\n\t* tree-pass.h (pass_reset_cc_flags): Remove.\n\t(TODO_update_address_taken): New flag.\n\t(pass_simple_dse): Remove.\n\t* ipa-cp.c (ipcp_update_callgraph): Update SSA form.\n\t* params.h (MAX_ALIASED_VOPS): Remove.\n\t(AVG_ALIASED_VOPS): Likewise.\n\t* omp-low.c (expand_omp_taskreg): Update SSA form.\n\t* tree-ssa-dse.c (dse_optimize_stmt): Properly query if the rhs\n\taliases the lhs in a copy stmt.\n\t* tree-ssa-dse.c (struct address_walk_data): Remove.\n\t(memory_ssa_name_same): Likewise.\n\t(memory_address_same): Likewise.\n\t(get_kill_of_stmt_lhs): Likewise.\n\t(dse_possible_dead_store_p): Simplify, use the oracle.  Handle\n\tunused stores.  Look through PHI nodes into post-dominated regions.\n\t(dse_optimize_stmt): Simplify.  Properly remove stores.\n\t(tree_ssa_dse): Compute dominators.\n\t(execute_simple_dse): Remove.\n\t(pass_simple_dse): Likewise.\n\t* ipa-reference.c (scan_stmt_for_static_refs): Open-code\n\tgimple_loaded_syms and gimple_stored_syms computation.\n\t* toplev.c (dump_memory_report): Dump alias and pta stats.\n\t* tree-ssa-sccvn.c (vn_reference_compute_hash): Simplify.\n\t(vn_reference_eq): Likewise.\n\t(vuses_to_vec, copy_vuses_from_stmt, vdefs_to_vec,\n\tcopy_vdefs_from_stmt, shared_lookup_vops, shared_vuses_from_stmt,\n\tvalueize_vuses): Remove.\n\t(get_def_ref_stmt_vuses): Simplify.  Rename to ...\n\t(get_def_ref_stmt_vuse): ... this.\n\t(vn_reference_lookup_2): New function.\n\t(vn_reference_lookup_pieces): Use walk_non_aliased_vuses for\n\twalking equivalent vuses.  Simplify.\n\t(vn_reference_lookup): Likewise.\n\t(vn_reference_insert): Likewise.\n\t(vn_reference_insert_pieces): Likewise.\n\t(visit_reference_op_call): Simplify.\n\t(visit_reference_op_load): Likewise.\n\t(visit_reference_op_store): Likewise.\n\t(init_scc_vn): Remove shared_lookup_vuses initialization.\n\t(free_scc_vn): Remove shared_lookup_vuses freeing.\n\t(sort_vuses, sort_vuses_heap): Remove.\n\t(get_ref_from_reference_ops): Export.\n\t* tree-ssa-sccvn.h (struct vn_reference_s): Replace vuses\n\tvector with single vuse pointer.\n\t(vn_reference_lookup_pieces, vn_reference_lookup,\n\tvn_reference_insert, vn_reference_insert_pieces): Adjust prototypes.\n\t(shared_vuses_from_stmt): Remove.\n\t(get_ref_from_reference_ops): Declare.\n\t* tree-ssa-loop-manip.c (slpeel_can_duplicate_loop_p): Adjust.\n\t* tree-ssa-copyrename.c (copy_rename_partition_coalesce): Remove\n\tmemory-tag related code.\n\t* tree-ssa-ccp.c (get_symbol_constant_value): Remove memory-tag code.\n\t(likely_value): Add comment, skip static-chain of call statements.\n\t(surely_varying_stmt_p): Adjust.\n\t(gimplify_and_update_call_from_tree): Likewise.\n\t(execute_fold_all_builtins): Do not rebuild alias info.\n\t(gimplify_and_update_call_from_tree): Properly update VOPs.\n\t* tree-ssa-loop-ivopts.c (get_ref_tag): Remove.\n\t(copy_ref_info): Remove memory-tag related code.\n\t* tree-call-cdce.c (tree_call_cdce): Rename the VOP.\n\t* ipa-pure-const.c (check_decl): Remove memory-tag related code.\n\t(check_stmt): Open-code gimple_loaded_syms and gimple_stored_syms\n\tcomputation.\n\t* tree-ssa-dom.c (gimple_p): Remove typedef.\n\t(eliminate_redundant_computations): Adjust.\n\t(record_equivalences_from_stmt): Likewise.\n\t(avail_expr_hash): Likewise.\n\t(avail_expr_eq): Likewise.\n\t* tree-ssa-propagate.c (update_call_from_tree): Properly\n\tupdate VOPs.\n\t(stmt_makes_single_load): Likewise.\n\t(stmt_makes_single_store): Likewise.\n\t* tree-ssa-alias.c: Rewrite completely.\n\t(debug_memory_partitions, dump_mem_ref_stats, debug_mem_ref_stats,\n\tdebug_mem_sym_stats, dump_mem_sym_stats_for_var,\n\tdebug_all_mem_sym_stats, debug_mp_info, update_mem_sym_stats_from_stmt,\n\tdelete_mem_ref_stats, create_tag_raw, dump_points_to_info,\n\tdump_may_aliases_for, debug_may_aliases_for, new_type_alias):\n\tRemove public functions.\n\t(pass_reset_cc_flags): Remove.\n\t(pass_build_alias): Move ...\n\t* tree-ssa-structalias.c (pass_build_alias): ... here.\n\t* tree-ssa-alias.c (may_be_aliased): Move ...\n\t* tree-flow-inline.h (may_be_aliased): ... here.\n\ttree-ssa-alias.c (struct count_ptr_d, count_ptr_derefs,\n\tcount_uses_and_derefs): Move ...\n\t* gimple.c: ... here.\n\t* gimple.h (count_uses_and_derefs): Declare.\n\t* tree-ssa-alias.c (dump_alias_stats, ptr_deref_may_alias_global_p,\n\tptr_deref_may_alias_decl_p, ptr_derefs_may_alias_p,\n\tsame_type_for_tbaa, nonaliasing_component_refs_p, decl_refs_may_alias_p,\n\tindirect_ref_may_alias_decl_p, indirect_refs_may_alias_p,\n\tref_maybe_used_by_call_p, ref_maybe_used_by_stmt_p,\n\tcall_may_clobber_ref_p, stmt_may_clobber_ref_p, maybe_skip_until,\n\tget_continuation_for_phi, walk_non_aliased_vuses, walk_aliased_vdefs):\n\tNew functions.\n\t* tree-dfa.c (refs_may_alias_p): Move ...\n\t* tree-ssa-alias.c (refs_may_alias_p): ... here.  Extend.\n\t* tree-ssa-alias.h: New file.\n\t* tree-ssa-sink.c (is_hidden_global_store): Adjust.\n\t(statement_sink_location): Likewise.\n\t* opts.c (decode_options): Do not adjust max-aliased-vops or\n\tavg-aliased-vops values.\n\t* timevar.def (TV_TREE_MAY_ALIAS): Remove.\n\t(TV_CALL_CLOBBER): Likewise.\n\t(TV_FLOW_SENSITIVE): Likewise.\n\t(TV_FLOW_INSENSITIVE): Likewise.\n\t(TV_MEMORY_PARTITIONING): Likewise.\n\t(TV_ALIAS_STMT_WALK): New timevar.\n\t* tree-ssa-loop-ivcanon.c (empty_loop_p): Adjust.\n\t* tree-ssa-address.c (create_mem_ref_raw): Use build6.\n\t(get_address_description): Remove memory-tag related code.\n\t* tree-ssa-ifcombine.c (bb_no_side_effects_p): Adjust.\n\t* treestruct.def (TS_MEMORY_TAG, TS_MEMORY_PARTITION_TAG): Remove.\n\t* tree-eh.c (cleanup_empty_eh): Do not leave stale SSA_NAMEs\n\tand immediate uses in statements.  Document.\n\t* gimple-pretty-print.c (dump_gimple_mem_ops): Adjust.\n\t(dump_symbols): Remove.\n\t(dump_gimple_mem_ops): Do not dump loaded or stored syms.\n\t* alias.c (get_deref_alias_set): New function split out from ...\n\t(get_alias_set): ... here.\n\t* alias.h (get_deref_alias_set): Declare.\n\t* tree-vect-data-refs.c (vect_create_data_ref_ptr): Remove unused\n\ttype parameter.  Remove restrict pointer handling.  Create a\n\tref-all pointer in case type-based alias sets do not conflict.\n\t(vect_analyze_data_refs): Remove SMT related code.\n\t* tree-vect-stmts.c (vectorizable_store): Re-instantiate TBAA assert.\n\t(vectorizable_load): Likewise.\n\t* tree-data-ref.h (struct dr_alias): Remove symbol_tag field.\n\t(DR_SYMBOL_TAG, DR_VOPS): Remove.\n\t* tree-data-ref.c (dr_may_alias_p): Use the alias-oracle.\n\tIgnore vops and SMTs.\n\t(dr_analyze_alias): Likewise..\n\t(free_data_ref): Likewise.\n\t(create_data_ref): Likewise.\n\t(analyze_all_data_dependences): Likewise.\n\t(get_references_in_stmt): Adjust.\n\t* tree-flow-inline.h (gimple_aliases_computed_p,\n\tgimple_addressable_vars, gimple_call_clobbered_vars,\n\tgimple_call_used_vars, gimple_global_var, may_aliases, memory_partition,\n\tfactoring_name_p, mark_call_clobbered, clear_call_clobbered,\n\tcompare_ssa_operands_equal, symbol_mem_tag, set_symbol_mem_tag,\n\tgimple_mem_ref_stats): Remove.\n\t(gimple_vop): New function.\n\t(op_iter_next_use): Remove vuses and mayuses cases.\n\t(op_iter_next_def): Remove vdefs case.\n\t(op_iter_next_tree): Remove vuses, mayuses and vdefs cases.\n\t(clear_and_done_ssa_iter): Do not set removed fields.\n\t(op_iter_init): Likewise.  Skip vuse and/or vdef if requested.\n\tAssert we are not iterating over vuses or vdefs if not also\n\titerating over uses or defs.\n\t(op_iter_init_use): Likewise.\n\t(op_iter_init_def): Likewise.\n\t(op_iter_next_vdef): Remove.\n\t(op_iter_next_mustdef): Likewise.\n\t(op_iter_init_vdef): Likewise.\n\t(compare_ssa_operands_equal): Likewise.\n\t(link_use_stmts_after): Handle vuse operand.\n\t(is_call_used): Use is_call_clobbered.\n\t(is_call_clobbered): Global variables are always call clobbered,\n\tquery the call-clobbers bitmap.\n\t(mark_call_clobbered): Ignore global variables.\n\t(clear_call_clobbered): Likewise.\n\t* tree-ssa-coalesce.c (create_outofssa_var_map): Adjust\n\tvirtual operands sanity check.\n\t* tree.def (NAME_MEMORY_TAG, SYMBOL_MEMORY_TAG, MEMORY_PARTITION_TAG):\n\tRemove.\n\t(TARGET_MEM_REF): Remove TMR_TAG operand.\n\t* tree-dfa.c (add_referenced_var): Initialize call-clobber state.\n\tRemove call-clobber related code.\n\t(remove_referenced_var): Likewise.  Do not clear mpt or symbol_mem_tag.\n\t(dump_variable): Do not dump SMTs, memory stats, may-aliases or\n\tpartitions or escape reason.\n\t(get_single_def_stmt, get_single_def_stmt_from_phi,\n\tget_single_def_stmt_with_phi): Remove.\n\t(dump_referenced_vars): Tidy.\n\t(get_ref_base_and_extent): Allow bare decls.\n\t(collect_dfa_stats): Adjust.\n\t* graphite.c (rename_variables_in_stmt): Adjust.\n\t(graphite_copy_stmts_from_block): Likewise.\n\t(translate_clast): Likewise.\n\t* tree-ssa-pre.c (struct bb_bitmap_sets): Add expr_dies bitmap.\n\t(EXPR_DIES): New.\n\t(translate_vuse_through_block): Use the oracle.\n\t(phi_translate_1): Adjust.\n\t(value_dies_in_block_x): Use the oracle.  Cache the outcome\n\tin EXPR_DIES.\n\t(valid_in_sets): Check if the VUSE for\n\ta REFERENCE is available.\n\t(eliminate): Do not remove stmts during elimination,\n\tinstead queue and remove them afterwards.\n\t(do_pre): Do not rebuild alias info.\n\t(pass_pre): Run TODO_rebuild_alias before PRE.\n\t* tree-ssa-live.c (remove_unused_locals): Remove memory-tag code.\n\t* tree-sra.c (sra_walk_function): Use gimple_references_memory_p.\n\t(mark_all_v_defs_stmt): Remove.\n\t(mark_all_v_defs_seq): Adjust.\n\t(sra_replace): Likewise.\n\t(scalarize_use): Likewise.\n\t(scalarize_copy): Likewise.\n\t(scalarize_init): Likewise.\n\t(scalarize_ldst): Likewise.\n\t(todoflags): Remove.\n\t(tree_sra): Do not rebuild alias info.\n\t(tree_sra_early): Adjust.\n\t(pass_sra): Run TODO_update_address_taken before SRA.\n\t* tree-predcom.c (set_alias_info): Remove.\n\t(prepare_initializers_chain): Do not call it.\n\t(mark_virtual_ops_for_renaming): Adjust.\n\t(mark_virtual_ops_for_renaming_list): Remove.\n\t(initialize_root_vars): Adjust.\n\t(initialize_root_vars_lm): Likewise.\n\t(prepare_initializers_chain): Likewise.\n\t* tree-ssa-copy.c (may_propagate_copy): Remove memory-tag related code.\n\t(may_propagate_copy_into_stmt): Likewise.\n\t(merge_alias_info): Do nothing for now.\n\t(propagate_tree_value_into_stmt): Adjust.\n\t(stmt_may_generate_copy): Likewise.\n\t* tree-ssa-forwprop.c (tidy_after_forward_propagate_addr): Do\n\tnot mark symbols for renaming.\n\t(forward_propagate_addr_expr): Match up push/pop_stmt_changes\n\twith the same statement, make sure to update the new pointed-to one.\n\t* tree-ssa-dce.c (eliminate_unnecessary_stmts): Do not copy\n\tcall statements, do not mark symbols for renaming.\n\t(mark_operand_necessary): Dump something.\n\t(ref_may_be_aliased): New function.\n\t(mark_aliased_reaching_defs_necessary_1): New helper function.\n\t(mark_aliased_reaching_defs_necessary): Likewise.\n\t(mark_all_reaching_defs_necessary_1): Likewise.\n\t(mark_all_reaching_defs_necessary): Likewise.\n\t(propagate_necessity): Do not process virtual PHIs.  For\n\tnon-aliased loads mark all reaching definitions as necessary.\n\tFor aliased loads and stores mark the immediate dominating\n\taliased clobbers as necessary.\n\t(visited): New global static.\n\t(perform_tree_ssa_dce): Free visited bitmap after propagating\n\tnecessity.\n\t(remove_dead_phis): Perform simple dead virtual PHI removal.\n\t(remove_dead_stmt): Properly unlink virtual operands when\n\tremoving stores.\n\t(eliminate_unnecessary_stmts): Schedule PHI removal after\n\tstmt removal.\n\t* tree-ssa-ter.c (is_replaceable_p): Adjust.\n\t(process_replaceable): Likewise.\n\t(find_replaceable_in_bb): Likewise.\n\t* tree-ssa.c (verify_ssa_name): Verify all VOPs are\n\tbased on the single gimple vop.\n\t(verify_flow_insensitive_alias_info): Remove.\n\t(verify_flow_sensitive_alias_info): Likewise.\n\t(verify_call_clobbering): Likewise.\n\t(verify_memory_partitions): Likewise.\n\t(verify_alias_info): Likewise.\n\t(verify_ssa): Adjust..\n\t(execute_update_addresses_taken): Export.  Update SSA\n\tmanually.  Optimize only when optimizing.  Use a local bitmap.\n\t(pass_update_address_taken): Remove TODO_update_ssa, add\n\tTODO_dump_func.\n\t(pass_update_address_taken): Just use TODO_update_address_taken.\n\t(init_tree_ssa): Do not initialize addressable_vars.\n\t(verify_ssa): Verify new VUSE / VDEF properties.\n\tVerify that all stmts definitions have the stmt as SSA_NAME_DEF_STMT.\n\tDo not call verify_alias_info.\n\t(delete_tree_ssa): Clear the VUSE, VDEF operands.\n\tDo not free the loaded and stored syms bitmaps.  Reset the escaped\n\tand callused solutions.  Do not free addressable_vars.\n\tRemove memory-tag related code.\n\t(warn_uninitialized_var): Aliases are always available.\n\t* tree-ssa-loop-prefetch.c (gather_memory_references): Adjust.\n\t* lambda-code.c (can_put_in_inner_loop): Adjust.\n\t(can_put_after_inner_loop): Likewise.\n\t(perfect_nestify): Likewise.\n\t* tree-vect-stmts.c (vect_stmt_relevant_p): Adjust.\n\t(vect_gen_widened_results_half): Remove CALL_EXPR handling.\n\t(vectorizable_conversion): Do not mark symbols for renaming.\n\t* tree-inline.c (remap_gimple_stmt): Clear VUSE/VDEF.\n\t(expand_call_inline): Unlink the calls virtual operands before\n\treplacing it.\n\t(tree_function_versioning): Do not call update_ssa if we are not\n\tupdating clones.  Simplify.\n\t* tree-ssa-phiprop.c (phivn_valid_p): Adjust.\n\t(propagate_with_phi): Likewise..\n\t* tree-outof-ssa.c (create_temp): Remove memory tag and call\n\tclobber code.  Assert we are not aliased or global.\n\t* tree-flow.h: Include tree-ssa-alias.h\n\t(enum escape_type): Remove.\n\t(struct mem_sym_stats_d): Likewise.\n\t(struct mem_ref_stats_d): Likewise.\n\t(struct gimple_df): Add vop member.  Remove global_var,\n\tcall_clobbered_vars, call_used_vars, addressable_vars,\n\taliases_compted_p and mem_ref_stats members.  Add syms_to_rename,\n\tescaped and callused members.\n\t(struct ptr_info_def): Remove all members, add points-to solution\n\tmember pt.\n\t(struct var_ann_d): Remove in_vuse_list, in_vdef_list,\n\tcall_clobbered, escape_mask, mpt and symbol_mem_tag members.\n\t* Makefile.in (TREE_FLOW_H): Add tree-ssa-alias.h.\n\t(tree-ssa-structalias.o): Remove tree-ssa-structalias.h.\n\t(tree-ssa-alias.o): Likewise.\n\t(toplev.o): Add tree-ssa-alias.h\n\t(GTFILES): Remove tree-ssa-structalias.h, add tree-ssa-alias.h.\n\t* gimple.c (gimple_set_bb): Fix off-by-one error.\n\t(is_gimple_reg): Do not handle memory tags.\n\t(gimple_copy): Also copy virtual operands.\n\tDelay updating the statement.  Do not reset loaded and stored syms.\n\t(gimple_set_stored_syms): Remove.\n\t(gimple_set_loaded_syms): Likewise.\n\t(gimple_call_copy_skip_args): Copy the virtual operands\n\tand mark the new statement modified.\n\t* tree-ssa-structalias.c (may_alias_p): Remove.\n\t(set_uids_in_ptset): Take the alias set to prune with as\n\tparameter.  Fold in the alias test of may_alias_p.\n\t(compute_points_to_sets): Compute whether a ptr is dereferenced\n\tin a local sbitmap.\n\t(process_constraint): Deal with &ANYTHING on the lhs, reject all\n\tother ADDRESSOF constraints on the lhs.\n\t(get_constraint_for_component_ref): Assert that we don't get\n\tADDRESSOF constraints from the base of the reference.\n\tProperly generate UNKNOWN_OFFSET for DEREF if needed.\n\t(struct variable_info): Remove collapsed_to member.\n\t(get_varinfo_fc): Remove.\n\t(new_var_info): Do not set collapsed_to.\n\t(dump_constraint): Do not follow cycles.\n\t(dump_constraint_graph): Likewise.\n\t(build_pred_graph): Likewise.\n\t(build_succ_graph): Likewise.\n\t(rewrite_constraints): Likewise.\n\t(do_simple_structure_copy): Remove.\n\t(do_rhs_deref_structure_copy): Remove.\n\t(do_lhs_deref_structure_copy): Remove.\n\t(collapse_rest_of_var): Remove.\n\t(do_structure_copy): Re-implement.\n\t(pta_stats): New global variable.\n\t(dump_pta_stats): New function.\n\t(struct constraint_expr): Make offset signed.\n\t(UNKNOWN_OFFSET): Define special value.\n\t(dump_constraint): Dump UNKNOWN_OFFSET as UNKNOWN.\n\t(solution_set_expand): New helper function split out from ...\n\t(do_sd_constraint): ... here.\n\t(solution_set_add): Handle UNKNOWN_OFFSET.  Handle negative offsets.\n\t(do_ds_constraint): Likewise.\n\t(do_sd_constraint): Likewise.  Do not special-case ESCAPED = *ESCAPED\n\tand CALLUSED = *CALLUSED.\n\t(set_union_with_increment): Make inc argument signed.\n\t(type_safe): Remove.\n\t(get_constraint_for_ptr_offset): Handle unknown and negative\n\tconstant offsets.\n\t(first_vi_for_offset): Handle offsets before start.  Bail\n\tout early for offsets beyond the variable extent.\n\t(first_or_preceding_vi_for_offset): New function.\n\t(init_base_vars): Add ESCAPED = ESCAPED + UNKNOWN_OFFSET constraint.\n\tTogether with ESCAPED = *ESCAPED this properly computes reachability.\n\t(find_what_var_points_to): New function.\n\t(find_what_p_points_to): Implement in terms of find_what_var_points_to.\n\t(pt_solution_reset, pt_solution_empty_p, pt_solution_includes_global,\n\tpt_solution_includes_1, pt_solution_includes, pt_solutions_intersect_1,\n\tpt_solutions_intersect): New functions.\n\t(compute_call_used_vars): Remove.\n\t(compute_may_aliases): New main entry into PTA computation.\n\t* gimple.h (gimple_p): New typedef.\n\t(struct gimple_statement_base): Remove references_memory_p.\n\t(struct gimple_statement_with_memory_ops_base): Remove\n\tvdef_ops, vuse_ops, stores and loads members.  Add vdef and vuse\n\tmembers.\n\t(gimple_vuse_ops, gimple_set_vuse_ops, gimple_vdef_ops,\n\tgimple_set_vdef_ops, gimple_loaded_syms, gimple_stored_syms,\n\tgimple_set_references_memory): Remove.\n\t(gimple_vuse_op, gimple_vdef_op, gimple_vuse, gimple_vdef,\n\tgimple_vuse_ptr, gimple_vdef_ptri, gimple_set_vuse, gimple_set_vdef):\n\tNew functions.\n\t* tree-cfg.c (move_block_to_fn): Fix off-by-one error.\n\t(verify_expr): Allow RESULT_DECL.\n\t(gimple_duplicate_bb): Do not copy virtual operands.\n\t(gimple_duplicate_sese_region): Adjust.\n\t(gimple_duplicate_sese_tail): Likewise.\n\t(mark_virtual_ops_in_region): Remove.\n\t(move_sese_region_to_fn): Do not call it.\n\t* passes.c (init_optimization_passes): Remove pass_reset_cc_flags\n\tand pass_simple_dse.\n\t(execute_function_todo): Handle TODO_update_address_taken,\n\tcall execute_update_addresses_taken for TODO_rebuild_alias.\n\t(execute_todo): Adjust.\n\t(execute_one_pass): Init dump files early.\n\t* ipa-struct-reorg.c (finalize_var_creation): Do not mark vars\n\tcall-clobbered.\n\t(create_general_new_stmt): Clear vops.\n\t* tree-ssa-reassoc.c (get_rank): Adjust.\n\t* tree-vect-slp.c (vect_create_mask_and_perm): Do not mark\n\tsymbols for renaming.\n\t* params.def (PARAM_MAX_ALIASED_VOPS): Remove.\n\t(PARAM_AVG_ALIASED_VOPS): Likewise.\n\t* tree-ssanames.c (init_ssanames): Allocate SYMS_TO_RENAME.\n\t(duplicate_ssa_name_ptr_info): No need to copy the shared bitmaps.\n\t* tree-ssa-operands.c: Simplify for new virtual operand\n\trepresentation.\n\t(operand_build_cmp, copy_virtual_operands,\n\tcreate_ssa_artificial_load_stmt, add_to_addressable_set,\n\tgimple_add_to_addresses_taken): Remove public functions.\n\t(unlink_stmt_vdef): New function.\n\n\t* gcc.dg/pr19633-1.c: Adjust.\n\t* gcc.dg/torture/pta-callused-1.c: Likewise.\n\t* gcc.dg/torture/pr39074-2.c: Likewise.\n\t* gcc.dg/torture/pr39074.c: Likewise.\n\t* gcc.dg/torture/pta-ptrarith-3.c: New testcase.\n\t* gcc.dg/torture/pr30375.c: Adjust.\n\t* gcc.dg/torture/pr33563.c: Likewise.\n\t* gcc.dg/torture/pr33870.c: Likewise.\n\t* gcc.dg/torture/pr33560.c: Likewise.\n\t* gcc.dg/torture/pta-structcopy-1.c: New testcase.\n\t* gcc.dg/torture/ssa-pta-fn-1.c: Likewise.\n\t* gcc.dg/tree-ssa/alias-15.c: Remove.\n\t* gcc.dg/tree-ssa/ssa-dce-4.c: New testcase.\n\t* gcc.dg/tree-ssa/pr26421.c: Adjust.\n\t* gcc.dg/tree-ssa/ssa-fre-10.c: XFAIL.\n\t* gcc.dg/tree-ssa/ssa-dce-5.c: New testcase.\n\t* gcc.dg/tree-ssa/pr23382.c: Adjust.\n\t* gcc.dg/tree-ssa/ssa-fre-20.c: New testcase.\n\t* gcc.dg/tree-ssa/alias-16.c: Adjust.\n\t* gcc.dg/tree-ssa/ssa-fre-13.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-fre-14.c: Likewise.\n\t* gcc.dg/tree-ssa/alias-18.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-fre-15.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-lim-3.c: Likewise.\n\t* gcc.dg/tree-ssa/alias-19.c: Likewise.\n\t* gcc.dg/tree-ssa/pta-ptrarith-1.c: New testcase.\n\t* gcc.dg/tree-ssa/pr13146.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-pre-23.c: Likewise.\n\t* gcc.dg/tree-ssa/pta-ptrarith-2.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-fre-18.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-pre-24.c: New XFAILed testcase.\n\t* gcc.dg/tree-ssa/ssa-fre-19.c: New testcase.\n\t* gcc.dg/tree-ssa/alias-20.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-dse-12.c: Likewise.\n\t* gcc.dg/tree-ssa/pr38895.c: Likewise.\n\t* gcc.dg/uninit-B.c: XFAIL.\n\t* gcc.dg/vect/no-vfa-vect-43.c: Adjust.\n\t* gcc.dg/uninit-pr19430.c: XFAIL.\n\t* g++.dg/tree-ssa/pr13146.C: New testcase.\n\t* g++.dg/opt/pr36187.C: Adjust.\n\t* g++.dg/torture/20090329-1.C: New testcase.\n\nFrom-SVN: r145494", "tree": {"sha": "c6c1826ba3cd971c15d66cb4b498f99ad646ed70", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c6c1826ba3cd971c15d66cb4b498f99ad646ed70"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5006671f1aaa63cd3f14535e014faa3bca5d20cc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5006671f1aaa63cd3f14535e014faa3bca5d20cc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5006671f1aaa63cd3f14535e014faa3bca5d20cc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5006671f1aaa63cd3f14535e014faa3bca5d20cc/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "95fe602ebea97abb5c5a303e7441fa055b65bb32", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/95fe602ebea97abb5c5a303e7441fa055b65bb32", "html_url": "https://github.com/Rust-GCC/gccrs/commit/95fe602ebea97abb5c5a303e7441fa055b65bb32"}], "stats": {"total": 14462, "additions": 4933, "deletions": 9529}, "files": [{"sha": "38851471644353ea9c006f731f9bfabaa74d4f43", "filename": "gcc/ChangeLog", "status": "modified", "additions": 504, "deletions": 0, "changes": 504, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,3 +1,507 @@\n+2009-04-03  Richard Guenther  <rguenther@suse.de>\n+\n+\tPR middle-end/13146\n+\tPR tree-optimization/23940\n+\tPR tree-optimization/33237\n+\tPR middle-end/33974\n+\tPR middle-end/34093\n+\tPR tree-optimization/36201\n+\tPR tree-optimization/36230\n+\tPR tree-optimization/38049\n+\tPR tree-optimization/38207\n+\tPR tree-optimization/38230\n+\tPR tree-optimization/38301\n+\tPR tree-optimization/38585\n+\tPR middle-end/38895\n+\tPR tree-optimization/38985\n+\tPR tree-optimization/39299\n+\t* tree-ssa-structalias.h: Remove.\n+\t* tree-ssa-operands.h (NULL_USE_OPERAND_P): Make of type use_operand_p.\n+\t(NULL_DEF_OPERAND_P): Make of type def_operand_p.\n+\t(struct vuse_element_d): Remove.\n+\t(struct vuse_vec_d): Likewise.\n+\t(VUSE_VECT_NUM_ELEM, VUSE_VECT_ELEMENT_NC, VUSE_ELEMENT_PTR_NC,\n+\tVUSE_ELEMENT_VAR_NC, VUSE_VECT_ELEMENT, VUSE_ELEMENT_PTR,\n+\tSET_VUSE_VECT_ELEMENT, SET_VUSE_ELEMENT_VAR, SET_VUSE_ELEMENT_PTR,\n+\tVUSE_ELEMENT_VAR): Likewise.\n+\t(struct voptype_d): Likewise.\n+\t(NUM_VOP_FREE_BUCKETS): Likewise.\n+\t(struct ssa_operands): Remove vop_free_buckets and mpt_table fields.\n+\t(struct stmt_operands_d): Remove.\n+\t(VUSE_OP_PTR, VUSE_OP, SET_VUSE_OP, VUSE_NUM, VUSE_VECT,\n+\tVDEF_RESULT_PTR, VDEF_RESULT, VDEF_OP_PTR, VDEF_OP, SET_VDEF_OP,\n+\tVDEF_NUM, VDEF_VECT): Likewise.\n+\t(copy_virtual_operands): Remove.\n+\t(operand_build_cmp): Likewise.\n+\t(create_ssa_artificial_load_stmt): Likewise.\n+\t(enum ssa_op_iter_type): Remove ssa_op_iter_vdef.\n+\t(struct ssa_operand_iterator_d): Remove vuses, vdefs, mayusesm\n+\tvuse_index and mayuse_index members.  Pack and move done and iter_type\n+\tmembers to the front.\n+\t(SSA_OP_VMAYUSE): Remove.\n+\t(SSA_OP_VIRTUAL_USES): Adjust.\n+\t(FOR_EACH_SSA_VDEF_OPERAND): Remove.\n+\t(unlink_stmt_vdef): Declare.\n+\t(add_to_addressable_set): Remove.\n+\t* tree-vrp.c (stmt_interesting_for_vrp): Adjust.\n+\t(vrp_visit_stmt): Likewise.\n+\t* doc/tree-ssa.texi (Alias analysis): Update.\n+\t* doc/invoke.texi (max-aliased-vops): Remove docs.\n+\t(avg-aliased-vops): Likewise.\n+\t* tree-into-ssa.c (syms_to_rename): Remove.\n+\t(need_to_update_vops_p): Likewise.\n+\t(need_to_initialize_update_ssa_p): Rename to ...\n+\t(update_ssa_initialized_fn): ... this.  Track function we are\n+\tinitialized for.\n+\t(symbol_marked_for_renaming): Simplify.\n+\t(add_new_name_mapping): Do not set need_to_update_vops_p.\n+\t(dump_currdefs): Use SYMS_TO_RENAME.\n+\t(rewrite_update_stmt): Always walk all uses/defs.\n+\t(dump_update_ssa): Adjust.\n+\t(init_update_ssa): Take function argument.  Track what we are\n+\tinitialized for.\n+\t(delete_update_ssa): Reset SYMS_TO_RENAME and update_ssa_initialized_fn.\n+\t(create_new_def_for): Initialize for cfun, assert we are initialized\n+\tfor cfun.\n+\t(mark_sym_for_renaming): Simplify.\n+\t(mark_set_for_renaming): Do not initialize update-ssa.\n+\t(need_ssa_update_p): Simplify.  Take function argument.\n+\t(name_mappings_registered_p): Assert we ask for the correct function.\n+\t(name_registered_for_update_p): Likewise.\n+\t(ssa_names_to_replace): Likewise.\n+\t(release_ssa_name_after_update_ssa): Likewise.\n+\t(update_ssa): Likewise.  Use SYMS_TO_RENAME.\n+\t(dump_decl_set): Do not print a newline.\n+\t(debug_decl_set): Do it here.\n+\t(dump_update_ssa): And here.\n+\t* tree-ssa-loop-im.c (move_computations): Adjust.\n+\t(movement_possibility): Likewise.\n+\t(determine_max_movement): Likewise.\n+\t(gather_mem_refs_stmt): Likewise.\n+\t* tree-dump.c (dequeue_and_dump): Do not handle SYMBOL_MEMORY_TAG\n+\tor NAME_MEMORY_TAG.\n+\t* tree-complex.c (update_all_vops): Remove.\n+\t(expand_complex_move): Adjust.\n+\t* tree-ssa-loop-niter.c (chain_of_csts_start): Use NULL_TREE.\n+\tSimplify test for memory referencing statement.  Exclude\n+\tnon-invariant ADDR_EXPRs.\n+\t* tree-pretty-print.c (dump_generic_node): Do not handle memory tags.\n+\t* tree-loop-distribution.c (generate_memset_zero): Adjust.\n+\t(rdg_flag_uses): Likewise.\n+\t* tree-tailcall.c (suitable_for_tail_opt_p): Remove memory-tag\n+\trelated code.\n+\t(tree_optimize_tail_calls_1): Also split the\n+\tedge from the entry block if we have degenerate PHI nodes in\n+\tthe first basic block.\n+\t* tree.c (init_ttree): Remove memory-tag related code.\n+\t(tree_code_size): Likewise.\n+\t(tree_node_structure): Likewise.\n+\t(build7_stat): Re-write to be build6_stat.\n+\t* tree.h (MTAG_P, TREE_MEMORY_TAG_CHECK, TMR_TAG): Remove.\n+\t(SSA_VAR_P): Adjust.\n+\t(struct tree_memory_tag): Remove.\n+\t(struct tree_memory_partition_tag): Likewise.\n+\t(union tree_node): Adjust.\n+\t(build7): Re-write to be build6.\n+\t* tree-pass.h (pass_reset_cc_flags): Remove.\n+\t(TODO_update_address_taken): New flag.\n+\t(pass_simple_dse): Remove.\n+\t* ipa-cp.c (ipcp_update_callgraph): Update SSA form.\n+\t* params.h (MAX_ALIASED_VOPS): Remove.\n+\t(AVG_ALIASED_VOPS): Likewise.\n+\t* omp-low.c (expand_omp_taskreg): Update SSA form.\n+\t* tree-ssa-dse.c (dse_optimize_stmt): Properly query if the rhs\n+\taliases the lhs in a copy stmt.\n+\t* tree-ssa-dse.c (struct address_walk_data): Remove.\n+\t(memory_ssa_name_same): Likewise.\n+\t(memory_address_same): Likewise.\n+\t(get_kill_of_stmt_lhs): Likewise.\n+\t(dse_possible_dead_store_p): Simplify, use the oracle.  Handle\n+\tunused stores.  Look through PHI nodes into post-dominated regions.\n+\t(dse_optimize_stmt): Simplify.  Properly remove stores.\n+\t(tree_ssa_dse): Compute dominators.\n+\t(execute_simple_dse): Remove.\n+\t(pass_simple_dse): Likewise.\n+\t* ipa-reference.c (scan_stmt_for_static_refs): Open-code\n+\tgimple_loaded_syms and gimple_stored_syms computation.\n+\t* toplev.c (dump_memory_report): Dump alias and pta stats.\n+\t* tree-ssa-sccvn.c (vn_reference_compute_hash): Simplify.\n+\t(vn_reference_eq): Likewise.\n+\t(vuses_to_vec, copy_vuses_from_stmt, vdefs_to_vec,\n+\tcopy_vdefs_from_stmt, shared_lookup_vops, shared_vuses_from_stmt,\n+\tvalueize_vuses): Remove.\n+\t(get_def_ref_stmt_vuses): Simplify.  Rename to ...\n+\t(get_def_ref_stmt_vuse): ... this.\n+\t(vn_reference_lookup_2): New function.\n+\t(vn_reference_lookup_pieces): Use walk_non_aliased_vuses for\n+\twalking equivalent vuses.  Simplify.\n+\t(vn_reference_lookup): Likewise.\n+\t(vn_reference_insert): Likewise.\n+\t(vn_reference_insert_pieces): Likewise.\n+\t(visit_reference_op_call): Simplify.\n+\t(visit_reference_op_load): Likewise.\n+\t(visit_reference_op_store): Likewise.\n+\t(init_scc_vn): Remove shared_lookup_vuses initialization.\n+\t(free_scc_vn): Remove shared_lookup_vuses freeing.\n+\t(sort_vuses, sort_vuses_heap): Remove.\n+\t(get_ref_from_reference_ops): Export.\n+\t* tree-ssa-sccvn.h (struct vn_reference_s): Replace vuses\n+\tvector with single vuse pointer.\n+\t(vn_reference_lookup_pieces, vn_reference_lookup,\n+\tvn_reference_insert, vn_reference_insert_pieces): Adjust prototypes.\n+\t(shared_vuses_from_stmt): Remove.\n+\t(get_ref_from_reference_ops): Declare.\n+\t* tree-ssa-loop-manip.c (slpeel_can_duplicate_loop_p): Adjust.\n+\t* tree-ssa-copyrename.c (copy_rename_partition_coalesce): Remove\n+\tmemory-tag related code.\n+\t* tree-ssa-ccp.c (get_symbol_constant_value): Remove memory-tag code.\n+\t(likely_value): Add comment, skip static-chain of call statements.\n+\t(surely_varying_stmt_p): Adjust.\n+\t(gimplify_and_update_call_from_tree): Likewise.\n+\t(execute_fold_all_builtins): Do not rebuild alias info.\n+\t(gimplify_and_update_call_from_tree): Properly update VOPs.\n+\t* tree-ssa-loop-ivopts.c (get_ref_tag): Remove.\n+\t(copy_ref_info): Remove memory-tag related code.\n+\t* tree-call-cdce.c (tree_call_cdce): Rename the VOP.\n+\t* ipa-pure-const.c (check_decl): Remove memory-tag related code.\n+\t(check_stmt): Open-code gimple_loaded_syms and gimple_stored_syms\n+\tcomputation.\n+\t* tree-ssa-dom.c (gimple_p): Remove typedef.\n+\t(eliminate_redundant_computations): Adjust.\n+\t(record_equivalences_from_stmt): Likewise.\n+\t(avail_expr_hash): Likewise.\n+\t(avail_expr_eq): Likewise.\n+\t* tree-ssa-propagate.c (update_call_from_tree): Properly\n+\tupdate VOPs.\n+\t(stmt_makes_single_load): Likewise.\n+\t(stmt_makes_single_store): Likewise.\n+\t* tree-ssa-alias.c: Rewrite completely.\n+\t(debug_memory_partitions, dump_mem_ref_stats, debug_mem_ref_stats,\n+\tdebug_mem_sym_stats, dump_mem_sym_stats_for_var,\n+\tdebug_all_mem_sym_stats, debug_mp_info, update_mem_sym_stats_from_stmt,\n+\tdelete_mem_ref_stats, create_tag_raw, dump_points_to_info,\n+\tdump_may_aliases_for, debug_may_aliases_for, new_type_alias):\n+\tRemove public functions.\n+\t(pass_reset_cc_flags): Remove.\n+\t(pass_build_alias): Move ...\n+\t* tree-ssa-structalias.c (pass_build_alias): ... here.\n+\t* tree-ssa-alias.c (may_be_aliased): Move ...\n+\t* tree-flow-inline.h (may_be_aliased): ... here.\n+\ttree-ssa-alias.c (struct count_ptr_d, count_ptr_derefs,\n+\tcount_uses_and_derefs): Move ...\n+\t* gimple.c: ... here.\n+\t* gimple.h (count_uses_and_derefs): Declare.\n+\t* tree-ssa-alias.c (dump_alias_stats, ptr_deref_may_alias_global_p,\n+\tptr_deref_may_alias_decl_p, ptr_derefs_may_alias_p,\n+\tsame_type_for_tbaa, nonaliasing_component_refs_p, decl_refs_may_alias_p,\n+\tindirect_ref_may_alias_decl_p, indirect_refs_may_alias_p,\n+\tref_maybe_used_by_call_p, ref_maybe_used_by_stmt_p,\n+\tcall_may_clobber_ref_p, stmt_may_clobber_ref_p, maybe_skip_until,\n+\tget_continuation_for_phi, walk_non_aliased_vuses, walk_aliased_vdefs):\n+\tNew functions.\n+\t* tree-dfa.c (refs_may_alias_p): Move ...\n+\t* tree-ssa-alias.c (refs_may_alias_p): ... here.  Extend.\n+\t* tree-ssa-alias.h: New file.\n+\t* tree-ssa-sink.c (is_hidden_global_store): Adjust.\n+\t(statement_sink_location): Likewise.\n+\t* opts.c (decode_options): Do not adjust max-aliased-vops or\n+\tavg-aliased-vops values.\n+\t* timevar.def (TV_TREE_MAY_ALIAS): Remove.\n+\t(TV_CALL_CLOBBER): Likewise.\n+\t(TV_FLOW_SENSITIVE): Likewise.\n+\t(TV_FLOW_INSENSITIVE): Likewise.\n+\t(TV_MEMORY_PARTITIONING): Likewise.\n+\t(TV_ALIAS_STMT_WALK): New timevar.\n+\t* tree-ssa-loop-ivcanon.c (empty_loop_p): Adjust.\n+\t* tree-ssa-address.c (create_mem_ref_raw): Use build6.\n+\t(get_address_description): Remove memory-tag related code.\n+\t* tree-ssa-ifcombine.c (bb_no_side_effects_p): Adjust.\n+\t* treestruct.def (TS_MEMORY_TAG, TS_MEMORY_PARTITION_TAG): Remove.\n+\t* tree-eh.c (cleanup_empty_eh): Do not leave stale SSA_NAMEs\n+\tand immediate uses in statements.  Document.\n+\t* gimple-pretty-print.c (dump_gimple_mem_ops): Adjust.\n+\t(dump_symbols): Remove.\n+\t(dump_gimple_mem_ops): Do not dump loaded or stored syms.\n+\t* alias.c (get_deref_alias_set): New function split out from ...\n+\t(get_alias_set): ... here.\n+\t* alias.h (get_deref_alias_set): Declare.\n+\t* tree-vect-data-refs.c (vect_create_data_ref_ptr): Remove unused\n+\ttype parameter.  Remove restrict pointer handling.  Create a\n+\tref-all pointer in case type-based alias sets do not conflict.\n+\t(vect_analyze_data_refs): Remove SMT related code.\n+\t* tree-vect-stmts.c (vectorizable_store): Re-instantiate TBAA assert.\n+\t(vectorizable_load): Likewise.\n+\t* tree-data-ref.h (struct dr_alias): Remove symbol_tag field.\n+\t(DR_SYMBOL_TAG, DR_VOPS): Remove.\n+\t* tree-data-ref.c (dr_may_alias_p): Use the alias-oracle.\n+\tIgnore vops and SMTs.\n+\t(dr_analyze_alias): Likewise..\n+\t(free_data_ref): Likewise.\n+\t(create_data_ref): Likewise.\n+\t(analyze_all_data_dependences): Likewise.\n+\t(get_references_in_stmt): Adjust.\n+\t* tree-flow-inline.h (gimple_aliases_computed_p,\n+\tgimple_addressable_vars, gimple_call_clobbered_vars,\n+\tgimple_call_used_vars, gimple_global_var, may_aliases, memory_partition,\n+\tfactoring_name_p, mark_call_clobbered, clear_call_clobbered,\n+\tcompare_ssa_operands_equal, symbol_mem_tag, set_symbol_mem_tag,\n+\tgimple_mem_ref_stats): Remove.\n+\t(gimple_vop): New function.\n+\t(op_iter_next_use): Remove vuses and mayuses cases.\n+\t(op_iter_next_def): Remove vdefs case.\n+\t(op_iter_next_tree): Remove vuses, mayuses and vdefs cases.\n+\t(clear_and_done_ssa_iter): Do not set removed fields.\n+\t(op_iter_init): Likewise.  Skip vuse and/or vdef if requested.\n+\tAssert we are not iterating over vuses or vdefs if not also\n+\titerating over uses or defs.\n+\t(op_iter_init_use): Likewise.\n+\t(op_iter_init_def): Likewise.\n+\t(op_iter_next_vdef): Remove.\n+\t(op_iter_next_mustdef): Likewise.\n+\t(op_iter_init_vdef): Likewise.\n+\t(compare_ssa_operands_equal): Likewise.\n+\t(link_use_stmts_after): Handle vuse operand.\n+\t(is_call_used): Use is_call_clobbered.\n+\t(is_call_clobbered): Global variables are always call clobbered,\n+\tquery the call-clobbers bitmap.\n+\t(mark_call_clobbered): Ignore global variables.\n+\t(clear_call_clobbered): Likewise.\n+\t* tree-ssa-coalesce.c (create_outofssa_var_map): Adjust\n+\tvirtual operands sanity check.\n+\t* tree.def (NAME_MEMORY_TAG, SYMBOL_MEMORY_TAG, MEMORY_PARTITION_TAG):\n+\tRemove.\n+\t(TARGET_MEM_REF): Remove TMR_TAG operand.\n+\t* tree-dfa.c (add_referenced_var): Initialize call-clobber state.\n+\tRemove call-clobber related code.\n+\t(remove_referenced_var): Likewise.  Do not clear mpt or symbol_mem_tag.\n+\t(dump_variable): Do not dump SMTs, memory stats, may-aliases or\n+\tpartitions or escape reason.\n+\t(get_single_def_stmt, get_single_def_stmt_from_phi,\n+\tget_single_def_stmt_with_phi): Remove.\n+\t(dump_referenced_vars): Tidy.\n+\t(get_ref_base_and_extent): Allow bare decls.\n+\t(collect_dfa_stats): Adjust.\n+\t* graphite.c (rename_variables_in_stmt): Adjust.\n+\t(graphite_copy_stmts_from_block): Likewise.\n+\t(translate_clast): Likewise.\n+\t* tree-ssa-pre.c (struct bb_bitmap_sets): Add expr_dies bitmap.\n+\t(EXPR_DIES): New.\n+\t(translate_vuse_through_block): Use the oracle.\n+\t(phi_translate_1): Adjust.\n+\t(value_dies_in_block_x): Use the oracle.  Cache the outcome\n+\tin EXPR_DIES.\n+\t(valid_in_sets): Check if the VUSE for\n+\ta REFERENCE is available.\n+\t(eliminate): Do not remove stmts during elimination,\n+\tinstead queue and remove them afterwards.\n+\t(do_pre): Do not rebuild alias info.\n+\t(pass_pre): Run TODO_rebuild_alias before PRE.\n+\t* tree-ssa-live.c (remove_unused_locals): Remove memory-tag code.\n+\t* tree-sra.c (sra_walk_function): Use gimple_references_memory_p.\n+\t(mark_all_v_defs_stmt): Remove.\n+\t(mark_all_v_defs_seq): Adjust.\n+\t(sra_replace): Likewise.\n+\t(scalarize_use): Likewise.\n+\t(scalarize_copy): Likewise.\n+\t(scalarize_init): Likewise.\n+\t(scalarize_ldst): Likewise.\n+\t(todoflags): Remove.\n+\t(tree_sra): Do not rebuild alias info.\n+\t(tree_sra_early): Adjust.\n+\t(pass_sra): Run TODO_update_address_taken before SRA.\n+\t* tree-predcom.c (set_alias_info): Remove.\n+\t(prepare_initializers_chain): Do not call it.\n+\t(mark_virtual_ops_for_renaming): Adjust.\n+\t(mark_virtual_ops_for_renaming_list): Remove.\n+\t(initialize_root_vars): Adjust.\n+\t(initialize_root_vars_lm): Likewise.\n+\t(prepare_initializers_chain): Likewise.\n+\t* tree-ssa-copy.c (may_propagate_copy): Remove memory-tag related code.\n+\t(may_propagate_copy_into_stmt): Likewise.\n+\t(merge_alias_info): Do nothing for now.\n+\t(propagate_tree_value_into_stmt): Adjust.\n+\t(stmt_may_generate_copy): Likewise.\n+\t* tree-ssa-forwprop.c (tidy_after_forward_propagate_addr): Do\n+\tnot mark symbols for renaming.\n+\t(forward_propagate_addr_expr): Match up push/pop_stmt_changes\n+\twith the same statement, make sure to update the new pointed-to one.\n+\t* tree-ssa-dce.c (eliminate_unnecessary_stmts): Do not copy\n+\tcall statements, do not mark symbols for renaming.\n+\t(mark_operand_necessary): Dump something.\n+\t(ref_may_be_aliased): New function.\n+\t(mark_aliased_reaching_defs_necessary_1): New helper function.\n+\t(mark_aliased_reaching_defs_necessary): Likewise.\n+\t(mark_all_reaching_defs_necessary_1): Likewise.\n+\t(mark_all_reaching_defs_necessary): Likewise.\n+\t(propagate_necessity): Do not process virtual PHIs.  For\n+\tnon-aliased loads mark all reaching definitions as necessary.\n+\tFor aliased loads and stores mark the immediate dominating\n+\taliased clobbers as necessary.\n+\t(visited): New global static.\n+\t(perform_tree_ssa_dce): Free visited bitmap after propagating\n+\tnecessity.\n+\t(remove_dead_phis): Perform simple dead virtual PHI removal.\n+\t(remove_dead_stmt): Properly unlink virtual operands when\n+\tremoving stores.\n+\t(eliminate_unnecessary_stmts): Schedule PHI removal after\n+\tstmt removal.\n+\t* tree-ssa-ter.c (is_replaceable_p): Adjust.\n+\t(process_replaceable): Likewise.\n+\t(find_replaceable_in_bb): Likewise.\n+\t* tree-ssa.c (verify_ssa_name): Verify all VOPs are\n+\tbased on the single gimple vop.\n+\t(verify_flow_insensitive_alias_info): Remove.\n+\t(verify_flow_sensitive_alias_info): Likewise.\n+\t(verify_call_clobbering): Likewise.\n+\t(verify_memory_partitions): Likewise.\n+\t(verify_alias_info): Likewise.\n+\t(verify_ssa): Adjust..\n+\t(execute_update_addresses_taken): Export.  Update SSA\n+\tmanually.  Optimize only when optimizing.  Use a local bitmap.\n+\t(pass_update_address_taken): Remove TODO_update_ssa, add\n+\tTODO_dump_func.\n+\t(pass_update_address_taken): Just use TODO_update_address_taken.\n+\t(init_tree_ssa): Do not initialize addressable_vars.\n+\t(verify_ssa): Verify new VUSE / VDEF properties.\n+\tVerify that all stmts definitions have the stmt as SSA_NAME_DEF_STMT.\n+\tDo not call verify_alias_info.\n+\t(delete_tree_ssa): Clear the VUSE, VDEF operands.\n+\tDo not free the loaded and stored syms bitmaps.  Reset the escaped\n+\tand callused solutions.  Do not free addressable_vars.\n+\tRemove memory-tag related code.\n+\t(warn_uninitialized_var): Aliases are always available.\n+\t* tree-ssa-loop-prefetch.c (gather_memory_references): Adjust.\n+\t* lambda-code.c (can_put_in_inner_loop): Adjust.\n+\t(can_put_after_inner_loop): Likewise.\n+\t(perfect_nestify): Likewise.\n+\t* tree-vect-stmts.c (vect_stmt_relevant_p): Adjust.\n+\t(vect_gen_widened_results_half): Remove CALL_EXPR handling.\n+\t(vectorizable_conversion): Do not mark symbols for renaming.\n+\t* tree-inline.c (remap_gimple_stmt): Clear VUSE/VDEF.\n+\t(expand_call_inline): Unlink the calls virtual operands before\n+\treplacing it.\n+\t(tree_function_versioning): Do not call update_ssa if we are not\n+\tupdating clones.  Simplify.\n+\t* tree-ssa-phiprop.c (phivn_valid_p): Adjust.\n+\t(propagate_with_phi): Likewise..\n+\t* tree-outof-ssa.c (create_temp): Remove memory tag and call\n+\tclobber code.  Assert we are not aliased or global.\n+\t* tree-flow.h: Include tree-ssa-alias.h\n+\t(enum escape_type): Remove.\n+\t(struct mem_sym_stats_d): Likewise.\n+\t(struct mem_ref_stats_d): Likewise.\n+\t(struct gimple_df): Add vop member.  Remove global_var,\n+\tcall_clobbered_vars, call_used_vars, addressable_vars,\n+\taliases_compted_p and mem_ref_stats members.  Add syms_to_rename,\n+\tescaped and callused members.\n+\t(struct ptr_info_def): Remove all members, add points-to solution\n+\tmember pt.\n+\t(struct var_ann_d): Remove in_vuse_list, in_vdef_list,\n+\tcall_clobbered, escape_mask, mpt and symbol_mem_tag members.\n+\t* Makefile.in (TREE_FLOW_H): Add tree-ssa-alias.h.\n+\t(tree-ssa-structalias.o): Remove tree-ssa-structalias.h.\n+\t(tree-ssa-alias.o): Likewise.\n+\t(toplev.o): Add tree-ssa-alias.h\n+\t(GTFILES): Remove tree-ssa-structalias.h, add tree-ssa-alias.h.\n+\t* gimple.c (gimple_set_bb): Fix off-by-one error.\n+\t(is_gimple_reg): Do not handle memory tags.\n+\t(gimple_copy): Also copy virtual operands.\n+\tDelay updating the statement.  Do not reset loaded and stored syms.\n+\t(gimple_set_stored_syms): Remove.\n+\t(gimple_set_loaded_syms): Likewise.\n+\t(gimple_call_copy_skip_args): Copy the virtual operands\n+\tand mark the new statement modified.\n+\t* tree-ssa-structalias.c (may_alias_p): Remove.\n+\t(set_uids_in_ptset): Take the alias set to prune with as\n+\tparameter.  Fold in the alias test of may_alias_p.\n+\t(compute_points_to_sets): Compute whether a ptr is dereferenced\n+\tin a local sbitmap.\n+\t(process_constraint): Deal with &ANYTHING on the lhs, reject all\n+\tother ADDRESSOF constraints on the lhs.\n+\t(get_constraint_for_component_ref): Assert that we don't get\n+\tADDRESSOF constraints from the base of the reference.\n+\tProperly generate UNKNOWN_OFFSET for DEREF if needed.\n+\t(struct variable_info): Remove collapsed_to member.\n+\t(get_varinfo_fc): Remove.\n+\t(new_var_info): Do not set collapsed_to.\n+\t(dump_constraint): Do not follow cycles.\n+\t(dump_constraint_graph): Likewise.\n+\t(build_pred_graph): Likewise.\n+\t(build_succ_graph): Likewise.\n+\t(rewrite_constraints): Likewise.\n+\t(do_simple_structure_copy): Remove.\n+\t(do_rhs_deref_structure_copy): Remove.\n+\t(do_lhs_deref_structure_copy): Remove.\n+\t(collapse_rest_of_var): Remove.\n+\t(do_structure_copy): Re-implement.\n+\t(pta_stats): New global variable.\n+\t(dump_pta_stats): New function.\n+\t(struct constraint_expr): Make offset signed.\n+\t(UNKNOWN_OFFSET): Define special value.\n+\t(dump_constraint): Dump UNKNOWN_OFFSET as UNKNOWN.\n+\t(solution_set_expand): New helper function split out from ...\n+\t(do_sd_constraint): ... here.\n+\t(solution_set_add): Handle UNKNOWN_OFFSET.  Handle negative offsets.\n+\t(do_ds_constraint): Likewise.\n+\t(do_sd_constraint): Likewise.  Do not special-case ESCAPED = *ESCAPED\n+\tand CALLUSED = *CALLUSED.\n+\t(set_union_with_increment): Make inc argument signed.\n+\t(type_safe): Remove.\n+\t(get_constraint_for_ptr_offset): Handle unknown and negative\n+\tconstant offsets.\n+\t(first_vi_for_offset): Handle offsets before start.  Bail\n+\tout early for offsets beyond the variable extent.\n+\t(first_or_preceding_vi_for_offset): New function.\n+\t(init_base_vars): Add ESCAPED = ESCAPED + UNKNOWN_OFFSET constraint.\n+\tTogether with ESCAPED = *ESCAPED this properly computes reachability.\n+\t(find_what_var_points_to): New function.\n+\t(find_what_p_points_to): Implement in terms of find_what_var_points_to.\n+\t(pt_solution_reset, pt_solution_empty_p, pt_solution_includes_global,\n+\tpt_solution_includes_1, pt_solution_includes, pt_solutions_intersect_1,\n+\tpt_solutions_intersect): New functions.\n+\t(compute_call_used_vars): Remove.\n+\t(compute_may_aliases): New main entry into PTA computation.\n+\t* gimple.h (gimple_p): New typedef.\n+\t(struct gimple_statement_base): Remove references_memory_p.\n+\t(struct gimple_statement_with_memory_ops_base): Remove\n+\tvdef_ops, vuse_ops, stores and loads members.  Add vdef and vuse\n+\tmembers.\n+\t(gimple_vuse_ops, gimple_set_vuse_ops, gimple_vdef_ops,\n+\tgimple_set_vdef_ops, gimple_loaded_syms, gimple_stored_syms,\n+\tgimple_set_references_memory): Remove.\n+\t(gimple_vuse_op, gimple_vdef_op, gimple_vuse, gimple_vdef,\n+\tgimple_vuse_ptr, gimple_vdef_ptri, gimple_set_vuse, gimple_set_vdef):\n+\tNew functions.\n+\t* tree-cfg.c (move_block_to_fn): Fix off-by-one error.\n+\t(verify_expr): Allow RESULT_DECL.\n+\t(gimple_duplicate_bb): Do not copy virtual operands.\n+\t(gimple_duplicate_sese_region): Adjust.\n+\t(gimple_duplicate_sese_tail): Likewise.\n+\t(mark_virtual_ops_in_region): Remove.\n+\t(move_sese_region_to_fn): Do not call it.\n+\t* passes.c (init_optimization_passes): Remove pass_reset_cc_flags\n+\tand pass_simple_dse.\n+\t(execute_function_todo): Handle TODO_update_address_taken,\n+\tcall execute_update_addresses_taken for TODO_rebuild_alias.\n+\t(execute_todo): Adjust.\n+\t(execute_one_pass): Init dump files early.\n+\t* ipa-struct-reorg.c (finalize_var_creation): Do not mark vars\n+\tcall-clobbered.\n+\t(create_general_new_stmt): Clear vops.\n+\t* tree-ssa-reassoc.c (get_rank): Adjust.\n+\t* tree-vect-slp.c (vect_create_mask_and_perm): Do not mark\n+\tsymbols for renaming.\n+\t* params.def (PARAM_MAX_ALIASED_VOPS): Remove.\n+\t(PARAM_AVG_ALIASED_VOPS): Likewise.\n+\t* tree-ssanames.c (init_ssanames): Allocate SYMS_TO_RENAME.\n+\t(duplicate_ssa_name_ptr_info): No need to copy the shared bitmaps.\n+\t* tree-ssa-operands.c: Simplify for new virtual operand\n+\trepresentation.\n+\t(operand_build_cmp, copy_virtual_operands,\n+\tcreate_ssa_artificial_load_stmt, add_to_addressable_set,\n+\tgimple_add_to_addresses_taken): Remove public functions.\n+\t(unlink_stmt_vdef): New function.\n+\n 2009-04-03  Alan Modra  <amodra@bigpond.net.au>\n \n \t* config.gcc (powerpc-*-linux*): Merge variants."}, {"sha": "31c589887df38cf0e1c4c9817a4a403995db817b", "filename": "gcc/Makefile.in", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -856,7 +856,8 @@ CPP_INTERNAL_H = $(srcdir)/../libcpp/internal.h $(CPP_ID_DATA_H)\n TREE_DUMP_H = tree-dump.h $(SPLAY_TREE_H) tree-pass.h\n TREE_FLOW_H = tree-flow.h tree-flow-inline.h tree-ssa-operands.h \\\n \t\t$(BITMAP_H) $(BASIC_BLOCK_H) hard-reg-set.h $(GIMPLE_H) \\\n-\t\t$(HASHTAB_H) $(CGRAPH_H) $(IPA_REFERENCE_H)\n+\t\t$(HASHTAB_H) $(CGRAPH_H) $(IPA_REFERENCE_H) \\\n+\t\ttree-ssa-alias.h\n TREE_SSA_LIVE_H = tree-ssa-live.h $(PARTITION_H) vecprim.h\n PRETTY_PRINT_H = pretty-print.h $(INPUT_H) $(OBSTACK_H)\n DIAGNOSTIC_H = diagnostic.h diagnostic.def $(PRETTY_PRINT_H) options.h\n@@ -2069,7 +2070,7 @@ stor-layout.o : stor-layout.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n    $(TREE_H) $(PARAMS_H) $(FLAGS_H) $(FUNCTION_H) $(EXPR_H) output.h $(RTL_H) \\\n    $(GGC_H) $(TM_P_H) $(TARGET_H) langhooks.h $(REGS_H) gt-stor-layout.h \\\n    $(TOPLEV_H)\n-tree-ssa-structalias.o: tree-ssa-structalias.c tree-ssa-structalias.h \\\n+tree-ssa-structalias.o: tree-ssa-structalias.c \\\n    $(SYSTEM_H) $(CONFIG_H) coretypes.h $(TM_H) $(GGC_H) $(OBSTACK_H) $(BITMAP_H) \\\n    $(FLAGS_H) $(RTL_H) $(TM_P_H) hard-reg-set.h $(BASIC_BLOCK_H) output.h \\\n    $(DIAGNOSTIC_H) $(TREE_H) $(C_COMMON_H) $(TREE_FLOW_H) $(TREE_INLINE_H) varray.h \\\n@@ -2291,7 +2292,7 @@ tree-ssa-alias.o : tree-ssa-alias.c $(TREE_FLOW_H) $(CONFIG_H) $(SYSTEM_H) \\\n    $(RTL_H) $(TREE_H) $(TM_P_H) $(EXPR_H) $(GGC_H) $(TREE_INLINE_H) $(FLAGS_H) \\\n    $(FUNCTION_H) $(TIMEVAR_H) convert.h $(TM_H) coretypes.h langhooks.h \\\n    $(TREE_DUMP_H) tree-pass.h $(PARAMS_H) $(BASIC_BLOCK_H) $(DIAGNOSTIC_H) \\\n-   hard-reg-set.h $(GIMPLE_H) vec.h tree-ssa-structalias.h \\\n+   hard-reg-set.h $(GIMPLE_H) vec.h \\\n    $(IPA_TYPE_ESCAPE_H) vecprim.h pointer-set.h alloc-pool.h\n tree-ssa-reassoc.o : tree-ssa-reassoc.c $(TREE_FLOW_H) $(CONFIG_H) \\\n    $(SYSTEM_H) $(TREE_H) $(GGC_H) $(DIAGNOSTIC_H) $(TIMEVAR_H) \\\n@@ -2442,7 +2443,8 @@ toplev.o : toplev.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) \\\n    value-prof.h $(PARAMS_H) $(TM_P_H) reload.h ira.h dwarf2asm.h $(TARGET_H) \\\n    langhooks.h insn-flags.h $(CFGLAYOUT_H) $(CFGLOOP_H) hosthooks.h \\\n    $(CGRAPH_H) $(COVERAGE_H) alloc-pool.h $(GGC_H) $(INTEGRATE_H) \\\n-   opts.h params.def tree-mudflap.h $(REAL_H) tree-pass.h $(GIMPLE_H)\n+   opts.h params.def tree-mudflap.h $(REAL_H) tree-pass.h $(GIMPLE_H) \\\n+   tree-ssa-alias.h\n \t$(CC) $(ALL_CFLAGS) $(ALL_CPPFLAGS) \\\n \t  -DTARGET_NAME=\\\"$(target_noncanonical)\\\" \\\n \t  -c $(srcdir)/toplev.c $(OUTPUT_OPTION)\n@@ -3304,8 +3306,9 @@ GTFILES = $(CPP_ID_DATA_H) $(srcdir)/input.h $(srcdir)/coretypes.h \\\n   $(srcdir)/targhooks.c $(out_file) $(srcdir)/passes.c $(srcdir)/cgraphunit.c \\\n   $(srcdir)/tree-ssa-propagate.c \\\n   $(srcdir)/tree-phinodes.c \\\n-  $(srcdir)/ipa-reference.c $(srcdir)/tree-ssa-structalias.h \\\n+  $(srcdir)/ipa-reference.c \\\n   $(srcdir)/tree-ssa-structalias.c $(srcdir)/tree-inline.c \\\n+  $(srcdir)/tree-ssa-alias.h \\\n   @all_gtfiles@\n \n # Compute the list of GT header files from the corresponding C sources,"}, {"sha": "2bc87024f551fed825ca4c923b2670b38d651d71", "filename": "gcc/alias.c", "status": "modified", "additions": 95, "deletions": 58, "changes": 153, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Falias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Falias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Falias.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -518,6 +518,98 @@ component_uses_parent_alias_set (const_tree t)\n     }\n }\n \n+/* Return the alias set for the memory pointed to by T, which may be\n+   either a type or an expression.  Return -1 if there is nothing\n+   special about dereferencing T.  */\n+\n+static alias_set_type\n+get_deref_alias_set_1 (tree t)\n+{\n+  /* If we're not doing any alias analysis, just assume everything\n+     aliases everything else.  */\n+  if (!flag_strict_aliasing)\n+    return 0;\n+\n+  if (! TYPE_P (t))\n+    {\n+      tree decl = find_base_decl (t);\n+\n+      if (decl && DECL_POINTER_ALIAS_SET_KNOWN_P (decl))\n+\t{\n+\t  /* If we haven't computed the actual alias set, do it now.  */\n+\t  if (DECL_POINTER_ALIAS_SET (decl) == -2)\n+\t    {\n+\t      tree pointed_to_type = TREE_TYPE (TREE_TYPE (decl));\n+\n+\t      /* No two restricted pointers can point at the same thing.\n+\t\t However, a restricted pointer can point at the same thing\n+\t\t as an unrestricted pointer, if that unrestricted pointer\n+\t\t is based on the restricted pointer.  So, we make the\n+\t\t alias set for the restricted pointer a subset of the\n+\t\t alias set for the type pointed to by the type of the\n+\t\t decl.  */\n+\t      alias_set_type pointed_to_alias_set\n+\t\t  = get_alias_set (pointed_to_type);\n+\n+\t      if (pointed_to_alias_set == 0)\n+\t\t/* It's not legal to make a subset of alias set zero.  */\n+\t\tDECL_POINTER_ALIAS_SET (decl) = 0;\n+\t      else if (AGGREGATE_TYPE_P (pointed_to_type))\n+\t\t/* For an aggregate, we must treat the restricted\n+\t\t   pointer the same as an ordinary pointer.  If we\n+\t\t   were to make the type pointed to by the\n+\t\t   restricted pointer a subset of the pointed-to\n+\t\t   type, then we would believe that other subsets\n+\t\t   of the pointed-to type (such as fields of that\n+\t\t   type) do not conflict with the type pointed to\n+\t\t   by the restricted pointer.  */\n+\t\tDECL_POINTER_ALIAS_SET (decl)\n+\t\t    = pointed_to_alias_set;\n+\t      else\n+\t\t{\n+\t\t  DECL_POINTER_ALIAS_SET (decl) = new_alias_set ();\n+\t\t  record_alias_subset (pointed_to_alias_set,\n+\t\t\t\t       DECL_POINTER_ALIAS_SET (decl));\n+\t\t}\n+\t    }\n+\n+\t  /* We use the alias set indicated in the declaration.  */\n+\t  return DECL_POINTER_ALIAS_SET (decl);\n+\t}\n+\n+      /* Now all we care about is the type.  */\n+      t = TREE_TYPE (t);\n+    }\n+\n+  /* If we have an INDIRECT_REF via a void pointer, we don't\n+     know anything about what that might alias.  Likewise if the\n+     pointer is marked that way.  */\n+  if (TREE_CODE (TREE_TYPE (t)) == VOID_TYPE\n+      || TYPE_REF_CAN_ALIAS_ALL (t))\n+    return 0;\n+\n+  return -1;\n+}\n+\n+/* Return the alias set for the memory pointed to by T, which may be\n+   either a type or an expression.  */\n+\n+alias_set_type\n+get_deref_alias_set (tree t)\n+{\n+  alias_set_type set = get_deref_alias_set_1 (t);\n+\n+  /* Fall back to the alias-set of the pointed-to type.  */\n+  if (set == -1)\n+    {\n+      if (! TYPE_P (t))\n+\tt = TREE_TYPE (t);\n+      set = get_alias_set (TREE_TYPE (t));\n+    }\n+\n+  return set;\n+}\n+\n /* Return the alias set for T, which may be either a type or an\n    expression.  Call language-specific routine for help, if needed.  */\n \n@@ -558,66 +650,11 @@ get_alias_set (tree t)\n \t  STRIP_NOPS (inner);\n \t}\n \n-      /* Check for accesses through restrict-qualified pointers.  */\n       if (INDIRECT_REF_P (inner))\n \t{\n-\t  tree decl;\n-\n-\t  if (TREE_CODE (TREE_OPERAND (inner, 0)) == SSA_NAME)\n-\t    decl = SSA_NAME_VAR (TREE_OPERAND (inner, 0));\n- \t  else\n-\t    decl = find_base_decl (TREE_OPERAND (inner, 0));\n-\n-\t  if (decl && DECL_POINTER_ALIAS_SET_KNOWN_P (decl))\n-\t    {\n-\t      /* If we haven't computed the actual alias set, do it now.  */\n-\t      if (DECL_POINTER_ALIAS_SET (decl) == -2)\n-\t\t{\n-\t\t  tree pointed_to_type = TREE_TYPE (TREE_TYPE (decl));\n-\n-\t\t  /* No two restricted pointers can point at the same thing.\n-\t\t     However, a restricted pointer can point at the same thing\n-\t\t     as an unrestricted pointer, if that unrestricted pointer\n-\t\t     is based on the restricted pointer.  So, we make the\n-\t\t     alias set for the restricted pointer a subset of the\n-\t\t     alias set for the type pointed to by the type of the\n-\t\t     decl.  */\n-\t\t  alias_set_type pointed_to_alias_set\n-\t\t    = get_alias_set (pointed_to_type);\n-\n-\t\t  if (pointed_to_alias_set == 0)\n-\t\t    /* It's not legal to make a subset of alias set zero.  */\n-\t\t    DECL_POINTER_ALIAS_SET (decl) = 0;\n-\t\t  else if (AGGREGATE_TYPE_P (pointed_to_type))\n-\t\t    /* For an aggregate, we must treat the restricted\n-\t\t       pointer the same as an ordinary pointer.  If we\n-\t\t       were to make the type pointed to by the\n-\t\t       restricted pointer a subset of the pointed-to\n-\t\t       type, then we would believe that other subsets\n-\t\t       of the pointed-to type (such as fields of that\n-\t\t       type) do not conflict with the type pointed to\n-\t\t       by the restricted pointer.  */\n-\t\t    DECL_POINTER_ALIAS_SET (decl)\n-\t\t      = pointed_to_alias_set;\n-\t\t  else\n-\t\t    {\n-\t\t      DECL_POINTER_ALIAS_SET (decl) = new_alias_set ();\n-\t\t      record_alias_subset (pointed_to_alias_set,\n-\t\t\t\t\t   DECL_POINTER_ALIAS_SET (decl));\n-\t\t    }\n-\t\t}\n-\n-\t      /* We use the alias set indicated in the declaration.  */\n-\t      return DECL_POINTER_ALIAS_SET (decl);\n-\t    }\n-\n-\t  /* If we have an INDIRECT_REF via a void pointer, we don't\n-\t     know anything about what that might alias.  Likewise if the\n-\t     pointer is marked that way.  */\n-\t  else if (TREE_CODE (TREE_TYPE (inner)) == VOID_TYPE\n-\t\t   || (TYPE_REF_CAN_ALIAS_ALL\n-\t\t       (TREE_TYPE (TREE_OPERAND (inner, 0)))))\n-\t    return 0;\n+\t  set = get_deref_alias_set_1 (TREE_OPERAND (inner, 0));\n+\t  if (set != -1)\n+\t    return set;\n \t}\n \n       /* Otherwise, pick up the outermost object that we could have a pointer"}, {"sha": "5907215824d666fba3947e22994af1e67e162e2f", "filename": "gcc/alias.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Falias.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Falias.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Falias.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -32,6 +32,7 @@ typedef int alias_set_type;\n \n extern alias_set_type new_alias_set (void);\n extern alias_set_type get_alias_set (tree);\n+extern alias_set_type get_deref_alias_set (tree);\n extern alias_set_type get_varargs_alias_set (void);\n extern alias_set_type get_frame_alias_set (void);\n extern bool component_uses_parent_alias_set (const_tree);"}, {"sha": "5eb977673bee20fe1d6ef29257814efe39e2fbee", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 0, "deletions": 26, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -7584,32 +7584,6 @@ Maximum number of basic blocks on path that cse considers.  The default is 10.\n @item max-cse-insns\n The maximum instructions CSE process before flushing. The default is 1000.\n \n-@item max-aliased-vops\n-\n-Maximum number of virtual operands per function allowed to represent\n-aliases before triggering the alias partitioning heuristic.  Alias\n-partitioning reduces compile times and memory consumption needed for\n-aliasing at the expense of precision loss in alias information.  The\n-default value for this parameter is 100 for -O1, 500 for -O2 and 1000\n-for -O3.\n-\n-Notice that if a function contains more memory statements than the\n-value of this parameter, it is not really possible to achieve this\n-reduction.  In this case, the compiler will use the number of memory\n-statements as the value for @option{max-aliased-vops}.\n-\n-@item avg-aliased-vops\n-\n-Average number of virtual operands per statement allowed to represent\n-aliases before triggering the alias partitioning heuristic.  This\n-works in conjunction with @option{max-aliased-vops}.  If a function\n-contains more than @option{max-aliased-vops} virtual operators, then\n-memory symbols will be grouped into memory partitions until either the\n-total number of virtual operators is below @option{max-aliased-vops}\n-or the average number of virtual operators per memory statement is\n-below @option{avg-aliased-vops}.  The default value for this parameter\n-is 1 for -O1 and -O2, and 3 for -O3.\n-\n @item ggc-min-expand\n \n GCC uses a garbage collector to manage its own memory allocation.  This"}, {"sha": "659431b0274ee61bcb8aeea6cc53c34d9b175b88", "filename": "gcc/doc/tree-ssa.texi", "status": "modified", "additions": 67, "deletions": 197, "changes": 264, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fdoc%2Ftree-ssa.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fdoc%2Ftree-ssa.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftree-ssa.texi?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -795,230 +795,100 @@ is popped.\n @cindex flow-sensitive alias analysis\n @cindex flow-insensitive alias analysis\n \n-Alias analysis proceeds in 4 main phases:\n+Alias analysis in GIMPLE SSA form consists of two pieces.  First\n+the virtual SSA web ties conflicting memory accesses and provides\n+a SSA use-def chain and SSA immediate-use chains for walking\n+possibly dependent memory accesses.  Second an alias-oracle can\n+be queried to disambiguate explicit and implicit memory references.\n \n @enumerate\n-@item   Structural alias analysis.\n+@item Memory SSA form.\n \n-This phase walks the types for structure variables, and determines which\n-of the fields can overlap using offset and size of each field.  For each\n-field, a ``subvariable'' called a ``Structure field tag'' (SFT)@ is\n-created, which represents that field as a separate variable.  All\n-accesses that could possibly overlap with a given field will have\n-virtual operands for the SFT of that field.\n+All statements that may use memory have exactly one accompanied use of\n+a virtual SSA name that represents the state of memory at the\n+given point in the IL.\n+\n+All statements that may define memory have exactly one accompanied\n+definition of a virtual SSA name using the previous state of memory\n+and defining the new state of memory after the given point in the IL.\n \n @smallexample\n-struct foo\n-@{\n-  int a;\n-  int b;\n-@}\n-struct foo temp;\n-int bar (void)\n+int i;\n+int foo (void)\n @{\n-  int tmp1, tmp2, tmp3;\n-  SFT.0_2 = VDEF <SFT.0_1>\n-  temp.a = 5;\n-  SFT.1_4 = VDEF <SFT.1_3>\n-  temp.b = 6;\n-  \n-  VUSE <SFT.1_4>\n-  tmp1_5 = temp.b;\n-  VUSE <SFT.0_2>\n-  tmp2_6 = temp.a;\n-\n-  tmp3_7 = tmp1_5 + tmp2_6;\n-  return tmp3_7;\n+  # .MEM_3 = VDEF <.MEM_2(D)>\n+  i = 1;\n+  # VUSE <.MEM_3>\n+  return i;\n @}\n @end smallexample\n \n-If you copy the symbol tag for a variable for some reason, you probably\n-also want to copy the subvariables for that variable.\n+The virtual SSA names in this case are @code{.MEM_2(D)} and\n+@code{.MEM_3}.  The store to the global variable @code{i}\n+defines @code{.MEM_3} invalidating @code{.MEM_2(D)}.  The\n+load from @code{i} uses that new state @code{.MEM_3}.\n+\n+The virtual SSA web serves as constraints to SSA optimizers\n+preventing illegitimate code-motion and optimization.  It\n+also provides a way to walk related memory statements.\n \n @item Points-to and escape analysis.\n \n-This phase walks the use-def chains in the SSA web looking for\n-three things:\n+Points-to analysis builds a set of constraints from the GIMPLE\n+SSA IL representing all pointer operations and facts we do\n+or do not know about pointers.  Solving this set of constraints\n+yields a conservatively correct solution for each pointer\n+variable in the program (though we are only interested in\n+SSA name pointers) as to what it may possibly point to.\n+\n+This points-to solution for a given SSA name pointer is stored\n+in the @code{pt_solution} sub-structure of the\n+@code{SSA_NAME_PTR_INFO} record.  The following accessor\n+functions are available:\n \n @itemize @bullet\n-@item Assignments of the form @code{P_i = &VAR}\n-@item Assignments of the form P_i = malloc()\n-@item Pointers and ADDR_EXPR that escape the current function.\n+@item @code{pt_solution_includes}\n+@item @code{pt_solutions_intersect}\n @end itemize\n \n-The concept of `escaping' is the same one used in the Java world.\n-When a pointer or an ADDR_EXPR escapes, it means that it has been\n-exposed outside of the current function.  So, assignment to\n-global variables, function arguments and returning a pointer are\n-all escape sites.\n-\n-This is where we are currently limited.  Since not everything is\n-renamed into SSA, we lose track of escape properties when a\n-pointer is stashed inside a field in a structure, for instance.\n-In those cases, we are assuming that the pointer does escape.\n-\n-We use escape analysis to determine whether a variable is\n-call-clobbered.  Simply put, if an ADDR_EXPR escapes, then the\n-variable is call-clobbered.  If a pointer P_i escapes, then all\n-the variables pointed-to by P_i (and its memory tag) also escape.\n-\n-@item Compute flow-sensitive aliases\n+Points-to analysis also computes the solution for two special\n+set of pointers, @code{ESCAPED} and @code{CALLUSED}.  Those\n+represent all memory that has escaped the scope of analysis\n+or that is used by pure or nested const calls.\n \n-We have two classes of memory tags.  Memory tags associated with\n-the pointed-to data type of the pointers in the program.  These\n-tags are called ``symbol memory tag'' (SMT)@.  The other class are\n-those associated with SSA_NAMEs, called ``name memory tag'' (NMT)@.\n-The basic idea is that when adding operands for an INDIRECT_REF\n-*P_i, we will first check whether P_i has a name tag, if it does\n-we use it, because that will have more precise aliasing\n-information.  Otherwise, we use the standard symbol tag.\n+@item Type-based alias analysis\n \n-In this phase, we go through all the pointers we found in\n-points-to analysis and create alias sets for the name memory tags\n-associated with each pointer P_i.  If P_i escapes, we mark\n-call-clobbered the variables it points to and its tag.\n-\n-\n-@item Compute flow-insensitive aliases\n-\n-This pass will compare the alias set of every symbol memory tag and\n-every addressable variable found in the program.  Given a symbol\n-memory tag SMT and an addressable variable V@.  If the alias sets\n-of SMT and V conflict (as computed by may_alias_p), then V is\n-marked as an alias tag and added to the alias set of SMT@.\n+Type-based alias analysis is frontend dependent though generic\n+support is provided by the middle-end in @code{alias.c}.  TBAA\n+code is used by both tree optimizers and RTL optimizers.\n \n Every language that wishes to perform language-specific alias analysis\n should define a function that computes, given a @code{tree}\n node, an alias set for the node.  Nodes in different alias sets are not\n allowed to alias.  For an example, see the C front-end function\n @code{c_get_alias_set}.\n-@end enumerate\n-\n-For instance, consider the following function:\n-\n-@smallexample\n-foo (int i)\n-@{\n-  int *p, *q, a, b;\n-\n-  if (i > 10)\n-    p = &a;\n-  else\n-    q = &b;\n-\n-  *p = 3;\n-  *q = 5;\n-  a = b + 2;\n-  return *p;\n-@}\n-@end smallexample\n-\n-After aliasing analysis has finished, the symbol memory tag for\n-pointer @code{p} will have two aliases, namely variables @code{a} and\n-@code{b}.\n-Every time pointer @code{p} is dereferenced, we want to mark the\n-operation as a potential reference to @code{a} and @code{b}.\n-\n-@smallexample\n-foo (int i)\n-@{\n-  int *p, a, b;\n-\n-  if (i_2 > 10)\n-    p_4 = &a;\n-  else\n-    p_6 = &b;\n-  # p_1 = PHI <p_4(1), p_6(2)>;\n \n-  # a_7 = VDEF <a_3>;\n-  # b_8 = VDEF <b_5>;\n-  *p_1 = 3;\n+@item Tree alias-oracle\n \n-  # a_9 = VDEF <a_7>\n-  # VUSE <b_8>\n-  a_9 = b_8 + 2;\n+The tree alias-oracle provides means to disambiguate two memory\n+references and memory references against statements.  The following\n+queries are available:\n \n-  # VUSE <a_9>;\n-  # VUSE <b_8>;\n-  return *p_1;\n-@}\n-@end smallexample\n-\n-In certain cases, the list of may aliases for a pointer may grow\n-too large.  This may cause an explosion in the number of virtual\n-operands inserted in the code.  Resulting in increased memory\n-consumption and compilation time.\n-\n-When the number of virtual operands needed to represent aliased\n-loads and stores grows too large (configurable with @option{--param\n-max-aliased-vops}), alias sets are grouped to avoid severe\n-compile-time slow downs and memory consumption.  The alias\n-grouping heuristic proceeds as follows:\n-\n-@enumerate\n-@item Sort the list of pointers in decreasing number of contributed\n-virtual operands.\n-\n-@item Take the first pointer from the list and reverse the role\n-of the memory tag and its aliases.  Usually, whenever an\n-aliased variable Vi is found to alias with a memory tag\n-T, we add Vi to the may-aliases set for T@.  Meaning that\n-after alias analysis, we will have:\n-\n-@smallexample\n-may-aliases(T) = @{ V1, V2, V3, @dots{}, Vn @}\n-@end smallexample\n-\n-This means that every statement that references T, will get\n-@code{n} virtual operands for each of the Vi tags.  But, when\n-alias grouping is enabled, we make T an alias tag and add it\n-to the alias set of all the Vi variables:\n-\n-@smallexample\n-may-aliases(V1) = @{ T @}\n-may-aliases(V2) = @{ T @}\n-@dots{}\n-may-aliases(Vn) = @{ T @}\n-@end smallexample\n-\n-This has two effects: (a) statements referencing T will only get\n-a single virtual operand, and, (b) all the variables Vi will now\n-appear to alias each other.  So, we lose alias precision to\n-improve compile time.  But, in theory, a program with such a high\n-level of aliasing should not be very optimizable in the first\n-place.\n-\n-@item Since variables may be in the alias set of more than one\n-memory tag, the grouping done in step (2) needs to be extended\n-to all the memory tags that have a non-empty intersection with\n-the may-aliases set of tag T@.  For instance, if we originally\n-had these may-aliases sets:\n-\n-@smallexample\n-may-aliases(T) = @{ V1, V2, V3 @}\n-may-aliases(R) = @{ V2, V4 @}\n-@end smallexample\n-\n-In step (2) we would have reverted the aliases for T as:\n-\n-@smallexample\n-may-aliases(V1) = @{ T @}\n-may-aliases(V2) = @{ T @}\n-may-aliases(V3) = @{ T @}\n-@end smallexample\n+@itemize @bullet\n+@item @code{refs_may_alias_p}\n+@item @code{ref_maybe_used_by_stmt_p}\n+@item @code{stmt_may_clobber_ref_p}\n+@end itemize\n \n-But note that now V2 is no longer aliased with R@.  We could\n-add R to may-aliases(V2), but we are in the process of\n-grouping aliases to reduce virtual operands so what we do is\n-add V4 to the grouping to obtain:\n+In addition to those two kind of statement walkers are available\n+walking statements related to a reference ref.\n+@code{walk_non_aliased_vuses} walks over dominating memory defining\n+statements and calls back if the statement does not clobber ref\n+providing the non-aliased VUSE.  The walk stops at\n+the first clobbering statement or if asked to.\n+@code{walk_aliased_vdefs} walks over dominating memory defining\n+statements and calls back on each statement clobbering ref\n+providing its aliasing VDEF.  The walk stops if asked to.\n \n-@smallexample\n-may-aliases(V1) = @{ T @}\n-may-aliases(V2) = @{ T @}\n-may-aliases(V3) = @{ T @}\n-may-aliases(V4) = @{ T @}\n-@end smallexample\n-\n-@item If the total number of virtual operands due to aliasing is\n-still above the threshold set by max-alias-vops, go back to (2).\n @end enumerate\n+"}, {"sha": "163acf9c065e6e811fa340ddd3fcc1a0da9b04e4", "filename": "gcc/gimple-pretty-print.c", "status": "modified", "additions": 10, "deletions": 91, "changes": 101, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgimple-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgimple-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-pretty-print.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1132,33 +1132,6 @@ dump_gimple_asm (pretty_printer *buffer, gimple gs, int spc, int flags)\n }\n \n \n-/* Dump the set of decls SYMS.  BUFFER, SPC and FLAGS are as in\n-   dump_generic_node.  */\n-\n-static void\n-dump_symbols (pretty_printer *buffer, bitmap syms, int flags)\n-{\n-  unsigned i;\n-  bitmap_iterator bi;\n-\n-  if (syms == NULL)\n-    pp_string (buffer, \"NIL\");\n-  else\n-    {\n-      pp_string (buffer, \" { \");\n-\n-      EXECUTE_IF_SET_IN_BITMAP (syms, 0, i, bi)\n-\t{\n-\t  tree sym = referenced_var_lookup (i);\n-\t  dump_generic_node (buffer, sym, 0, flags, false);\n-\t  pp_character (buffer, ' ');\n-\t}\n-\n-      pp_character (buffer, '}');\n-    }\n-}\n-\n-\n /* Dump a PHI node PHI.  BUFFER, SPC and FLAGS are as in\n    dump_gimple_stmt.  */\n \n@@ -1379,81 +1352,27 @@ dump_gimple_cdt (pretty_printer *buffer, gimple gs, int spc, int flags)\n static void\n dump_gimple_mem_ops (pretty_printer *buffer, gimple gs, int spc, int flags)\n {\n-  struct voptype_d *vdefs;\n-  struct voptype_d *vuses;\n-  int i, n;\n+  tree vdef = gimple_vdef (gs);\n+  tree vuse = gimple_vuse (gs);\n \n   if (!ssa_operands_active () || !gimple_references_memory_p (gs))\n     return;\n \n-  /* Even if the statement doesn't have virtual operators yet, it may\n-     contain symbol information (this happens before aliases have been\n-     computed).  */\n-  if ((flags & TDF_MEMSYMS)\n-      && gimple_vuse_ops (gs) == NULL\n-      && gimple_vdef_ops (gs) == NULL)\n-    {\n-      if (gimple_loaded_syms (gs))\n-\t{\n-\t  pp_string (buffer, \"# LOADS: \");\n-\t  dump_symbols (buffer, gimple_loaded_syms (gs), flags);\n-\t  newline_and_indent (buffer, spc);\n-\t}\n-\n-      if (gimple_stored_syms (gs))\n-\t{\n-\t  pp_string (buffer, \"# STORES: \");\n-\t  dump_symbols (buffer, gimple_stored_syms (gs), flags);\n-\t  newline_and_indent (buffer, spc);\n-\t}\n-\n-      return;\n-    }\n-\n-  vuses = gimple_vuse_ops (gs);\n-  while (vuses)\n+  if (vdef != NULL_TREE)\n     {\n-      pp_string (buffer, \"# VUSE <\");\n-\n-      n = VUSE_NUM (vuses);\n-      for (i = 0; i < n; i++)\n-\t{\n-\t  dump_generic_node (buffer, VUSE_OP (vuses, i), spc + 2, flags, false);\n-\t  if (i < n - 1)\n-\t    pp_string (buffer, \", \");\n-\t}\n-\n+      pp_string (buffer, \"# \");\n+      dump_generic_node (buffer, vdef, spc + 2, flags, false);\n+      pp_string (buffer, \" = VDEF <\");\n+      dump_generic_node (buffer, vuse, spc + 2, flags, false);\n       pp_character (buffer, '>');\n-\n-      if (flags & TDF_MEMSYMS)\n-\tdump_symbols (buffer, gimple_loaded_syms (gs), flags);\n-\n       newline_and_indent (buffer, spc);\n-      vuses = vuses->next;\n     }\n-\n-  vdefs = gimple_vdef_ops (gs);\n-  while (vdefs)\n+  else if (vuse != NULL_TREE)\n     {\n-      pp_string (buffer, \"# \");\n-      dump_generic_node (buffer, VDEF_RESULT (vdefs), spc + 2, flags, false);\n-      pp_string (buffer, \" = VDEF <\");\n-\n-      n = VDEF_NUM (vdefs);\n-      for (i = 0; i < n; i++)\n-\t{\n-\t  dump_generic_node (buffer, VDEF_OP (vdefs, i), spc + 2, flags, 0);\n-\t  if (i < n - 1)\n-\t    pp_string (buffer, \", \");\n-\t}\n-\n+      pp_string (buffer, \"# VUSE <\");\n+      dump_generic_node (buffer, vuse, spc + 2, flags, false);\n       pp_character (buffer, '>');\n-\n-      if ((flags & TDF_MEMSYMS) && vdefs->next == NULL)\n-\tdump_symbols (buffer, gimple_stored_syms (gs), flags);\n-\n       newline_and_indent (buffer, spc);\n-      vdefs = vdefs->next;\n     }\n }\n "}, {"sha": "4d05c983e9d76a7e9ac21840bd0c6347ab213922", "filename": "gcc/gimple.c", "status": "modified", "additions": 102, "deletions": 49, "changes": 151, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgimple.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgimple.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1902,7 +1902,7 @@ gimple_set_bb (gimple stmt, basic_block bb)\n \t  LABEL_DECL_UID (t) = uid = cfun->cfg->last_label_uid++;\n \t  if (old_len <= (unsigned) uid)\n \t    {\n-\t      unsigned new_len = 3 * uid / 2;\n+\t      unsigned new_len = 3 * uid / 2 + 1;\n \n \t      VEC_safe_grow_cleared (basic_block, gc, label_to_block_map,\n \t\t\t\t     new_len);\n@@ -2209,13 +2209,12 @@ gimple_copy (gimple stmt)\n \n       if (gimple_has_mem_ops (stmt))\n \t{\n-\t  gimple_set_vdef_ops (copy, NULL);\n-\t  gimple_set_vuse_ops (copy, NULL);\n-\t  copy->gsmem.membase.stores = NULL;\n-\t  copy->gsmem.membase.loads = NULL;\n+\t  gimple_set_vdef (copy, gimple_vdef (stmt));\n+\t  gimple_set_vuse (copy, gimple_vuse (stmt));\n \t}\n \n-      update_stmt (copy);\n+      /* SSA operands need to be updated.  */\n+      gimple_set_modified (copy, true);\n     }\n \n   return copy;\n@@ -2456,46 +2455,6 @@ dump_gimple_statistics (void)\n }\n \n \n-/* Deep copy SYMS into the set of symbols stored by STMT.  If SYMS is\n-   NULL or empty, the storage used is freed up.  */\n-\n-void\n-gimple_set_stored_syms (gimple stmt, bitmap syms, bitmap_obstack *obs)\n-{\n-  gcc_assert (gimple_has_mem_ops (stmt));\n-\n-  if (syms == NULL || bitmap_empty_p (syms))\n-    BITMAP_FREE (stmt->gsmem.membase.stores);\n-  else\n-    {\n-      if (stmt->gsmem.membase.stores == NULL)\n-\tstmt->gsmem.membase.stores = BITMAP_ALLOC (obs);\n-\n-      bitmap_copy (stmt->gsmem.membase.stores, syms);\n-    }\n-}\n-\n-\n-/* Deep copy SYMS into the set of symbols loaded by STMT.  If SYMS is\n-   NULL or empty, the storage used is freed up.  */\n-\n-void\n-gimple_set_loaded_syms (gimple stmt, bitmap syms, bitmap_obstack *obs)\n-{\n-  gcc_assert (gimple_has_mem_ops (stmt));\n-\n-  if (syms == NULL || bitmap_empty_p (syms))\n-    BITMAP_FREE (stmt->gsmem.membase.loads);\n-  else\n-    {\n-      if (stmt->gsmem.membase.loads == NULL)\n-\tstmt->gsmem.membase.loads = BITMAP_ALLOC (obs);\n-\n-      bitmap_copy (stmt->gsmem.membase.loads, syms);\n-    }\n-}\n-\n-\n /* Return the number of operands needed on the RHS of a GIMPLE\n    assignment for an expression with tree code CODE.  */\n \n@@ -2866,9 +2825,6 @@ is_gimple_reg (tree t)\n   if (TREE_CODE (t) == SSA_NAME)\n     t = SSA_NAME_VAR (t);\n \n-  if (MTAG_P (t))\n-    return false;\n-\n   if (!is_gimple_variable (t))\n     return false;\n \n@@ -3127,6 +3083,9 @@ gimple_call_copy_skip_args (gimple stmt, bitmap args_to_skip)\n   if (gimple_call_lhs (stmt))\n     gimple_call_set_lhs (new_stmt, gimple_call_lhs (stmt));\n \n+  gimple_set_vuse (new_stmt, gimple_vuse (stmt));\n+  gimple_set_vdef (new_stmt, gimple_vdef (stmt));\n+\n   gimple_set_block (new_stmt, gimple_block (stmt));\n   if (gimple_has_location (stmt))\n     gimple_set_location (new_stmt, gimple_location (stmt));\n@@ -3138,7 +3097,101 @@ gimple_call_copy_skip_args (gimple stmt, bitmap args_to_skip)\n   gimple_call_set_return_slot_opt (new_stmt, gimple_call_return_slot_opt_p (stmt));\n   gimple_call_set_from_thunk (new_stmt, gimple_call_from_thunk_p (stmt));\n   gimple_call_set_va_arg_pack (new_stmt, gimple_call_va_arg_pack_p (stmt));\n+\n+  gimple_set_modified (new_stmt, true);\n+\n   return new_stmt;\n }\n \n+\n+/* Data structure used to count the number of dereferences to PTR\n+   inside an expression.  */\n+struct count_ptr_d\n+{\n+  tree ptr;\n+  unsigned num_stores;\n+  unsigned num_loads;\n+};\n+\n+/* Helper for count_uses_and_derefs.  Called by walk_tree to look for\n+   (ALIGN/MISALIGNED_)INDIRECT_REF nodes for the pointer passed in DATA.  */\n+\n+static tree\n+count_ptr_derefs (tree *tp, int *walk_subtrees, void *data)\n+{\n+  struct walk_stmt_info *wi_p = (struct walk_stmt_info *) data;\n+  struct count_ptr_d *count_p = (struct count_ptr_d *) wi_p->info;\n+\n+  /* Do not walk inside ADDR_EXPR nodes.  In the expression &ptr->fld,\n+     pointer 'ptr' is *not* dereferenced, it is simply used to compute\n+     the address of 'fld' as 'ptr + offsetof(fld)'.  */\n+  if (TREE_CODE (*tp) == ADDR_EXPR)\n+    {\n+      *walk_subtrees = 0;\n+      return NULL_TREE;\n+    }\n+\n+  if (INDIRECT_REF_P (*tp) && TREE_OPERAND (*tp, 0) == count_p->ptr)\n+    {\n+      if (wi_p->is_lhs)\n+\tcount_p->num_stores++;\n+      else\n+\tcount_p->num_loads++;\n+    }\n+\n+  return NULL_TREE;\n+}\n+\n+/* Count the number of direct and indirect uses for pointer PTR in\n+   statement STMT.  The number of direct uses is stored in\n+   *NUM_USES_P.  Indirect references are counted separately depending\n+   on whether they are store or load operations.  The counts are\n+   stored in *NUM_STORES_P and *NUM_LOADS_P.  */\n+\n+void\n+count_uses_and_derefs (tree ptr, gimple stmt, unsigned *num_uses_p,\n+\t\t       unsigned *num_loads_p, unsigned *num_stores_p)\n+{\n+  ssa_op_iter i;\n+  tree use;\n+\n+  *num_uses_p = 0;\n+  *num_loads_p = 0;\n+  *num_stores_p = 0;\n+\n+  /* Find out the total number of uses of PTR in STMT.  */\n+  FOR_EACH_SSA_TREE_OPERAND (use, stmt, i, SSA_OP_USE)\n+    if (use == ptr)\n+      (*num_uses_p)++;\n+\n+  /* Now count the number of indirect references to PTR.  This is\n+     truly awful, but we don't have much choice.  There are no parent\n+     pointers inside INDIRECT_REFs, so an expression like\n+     '*x_1 = foo (x_1, *x_1)' needs to be traversed piece by piece to\n+     find all the indirect and direct uses of x_1 inside.  The only\n+     shortcut we can take is the fact that GIMPLE only allows\n+     INDIRECT_REFs inside the expressions below.  */\n+  if (is_gimple_assign (stmt)\n+      || gimple_code (stmt) == GIMPLE_RETURN\n+      || gimple_code (stmt) == GIMPLE_ASM\n+      || is_gimple_call (stmt))\n+    {\n+      struct walk_stmt_info wi;\n+      struct count_ptr_d count;\n+\n+      count.ptr = ptr;\n+      count.num_stores = 0;\n+      count.num_loads = 0;\n+\n+      memset (&wi, 0, sizeof (wi));\n+      wi.info = &count;\n+      walk_gimple_op (stmt, count_ptr_derefs, &wi);\n+\n+      *num_stores_p = count.num_stores;\n+      *num_loads_p = count.num_loads;\n+    }\n+\n+  gcc_assert (*num_uses_p >= *num_loads_p + *num_stores_p);\n+}\n+\n #include \"gt-gimple.h\""}, {"sha": "dde7f942e16451bf8a6770a84c824891020df2a7", "filename": "gcc/gimple.h", "status": "modified", "additions": 78, "deletions": 64, "changes": 142, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgimple.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgimple.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -34,6 +34,10 @@ DEF_VEC_P(gimple);\n DEF_VEC_ALLOC_P(gimple,heap);\n DEF_VEC_ALLOC_P(gimple,gc);\n \n+typedef gimple *gimple_p;\n+DEF_VEC_P(gimple_p);\n+DEF_VEC_ALLOC_P(gimple_p,heap);\n+\n DEF_VEC_P(gimple_seq);\n DEF_VEC_ALLOC_P(gimple_seq,gc);\n DEF_VEC_ALLOC_P(gimple_seq,heap);\n@@ -288,8 +292,8 @@ struct gimple_statement_base GTY(())\n   /* Nonzero if this statement contains volatile operands.  */\n   unsigned has_volatile_ops \t: 1;\n \n-  /* Nonzero if this statement contains memory refernces.  */\n-  unsigned references_memory_p \t: 1;\n+  /* Padding to get subcode to 16 bit alignment.  */\n+  unsigned pad\t\t\t: 1;\n \n   /* The SUBCODE field can be used for tuple-specific flags for tuples\n      that do not require subcodes.  Note that SUBCODE should be at\n@@ -363,26 +367,22 @@ struct gimple_statement_with_memory_ops_base GTY(())\n   /* [ WORD 1-7 ]  */\n   struct gimple_statement_with_ops_base opbase;\n \n-  /* [ WORD 8-9 ]  \n-     Vectors for virtual operands.  */\n-  struct voptype_d GTY((skip (\"\"))) *vdef_ops;\n-  struct voptype_d GTY((skip (\"\"))) *vuse_ops;\n-\n-  /* [ WORD 9-10 ]\n-     Symbols stored/loaded by this statement.  */\n-  bitmap GTY((skip (\"\"))) stores;\n-  bitmap GTY((skip (\"\"))) loads;\n+  /* [ WORD 8-9 ]\n+     Virtual operands for this statement.  The GC will pick them\n+     up via the ssa_names array.  */\n+  tree GTY((skip (\"\"))) vdef;\n+  tree GTY((skip (\"\"))) vuse;\n };\n \n \n /* Statements that take both memory and register operands.  */\n \n struct gimple_statement_with_memory_ops GTY(())\n {\n-  /* [ WORD 1-10 ]  */\n+  /* [ WORD 1-9 ]  */\n   struct gimple_statement_with_memory_ops_base membase;\n \n-  /* [ WORD 11 ]\n+  /* [ WORD 10 ]\n      Operand vector.  NOTE!  This must always be the last field\n      of this structure.  In particular, this means that this\n      structure cannot be embedded inside another one.  */\n@@ -545,20 +545,20 @@ struct gimple_statement_wce GTY(())\n \n struct gimple_statement_asm GTY(())\n {\n-  /* [ WORD 1-10 ]  */\n+  /* [ WORD 1-9 ]  */\n   struct gimple_statement_with_memory_ops_base membase;\n \n-  /* [ WORD 11 ]\n+  /* [ WORD 10 ]\n      __asm__ statement.  */\n   const char *string;\n \n-  /* [ WORD 12 ]\n+  /* [ WORD 11 ]\n        Number of inputs, outputs and clobbers.  */\n   unsigned char ni;\n   unsigned char no;\n   unsigned short nc;\n \n-  /* [ WORD 13 ]\n+  /* [ WORD 12 ]\n      Operand vector.  NOTE!  This must always be the last field\n      of this structure.  In particular, this means that this\n      structure cannot be embedded inside another one.  */\n@@ -907,6 +907,8 @@ extern bool is_gimple_call_addr (tree);\n extern tree get_call_expr_in (tree t);\n \n extern void recalculate_side_effects (tree);\n+extern void count_uses_and_derefs (tree, gimple, unsigned *, unsigned *,\n+\t\t\t\t   unsigned *);\n \n /* In gimplify.c  */\n extern tree create_tmp_var_raw (tree, const char *);\n@@ -1010,9 +1012,6 @@ extern tree gimple_assign_rhs_to_tree (gimple);\n /* In builtins.c  */\n extern bool validate_gimple_arglist (const_gimple, ...);\n \n-/* In tree-ssa-operands.c  */\n-extern void gimple_add_to_addresses_taken (gimple, tree);\n-\n /* In tree-ssa.c  */\n extern bool tree_ssa_useless_type_conversion (tree);\n extern bool useless_type_conversion_p (tree, tree);\n@@ -1314,69 +1313,93 @@ gimple_set_use_ops (gimple g, struct use_optype_d *use)\n }\n \n \n-/* Return the set of VUSE operands for statement G.  */\n+/* Return the set of VUSE operand for statement G.  */\n \n-static inline struct voptype_d *\n-gimple_vuse_ops (const_gimple g)\n+static inline use_operand_p\n+gimple_vuse_op (const_gimple g)\n {\n+  struct use_optype_d *ops;\n   if (!gimple_has_mem_ops (g))\n-    return NULL;\n-  return g->gsmem.membase.vuse_ops;\n+    return NULL_USE_OPERAND_P;\n+  ops = g->gsops.opbase.use_ops;\n+  if (ops\n+      && USE_OP_PTR (ops)->use == &g->gsmem.membase.vuse)\n+    return USE_OP_PTR (ops);\n+  return NULL_USE_OPERAND_P;\n }\n \n+/* Return the set of VDEF operand for statement G.  */\n \n-/* Set OPS to be the set of VUSE operands for statement G.  */\n-\n-static inline void\n-gimple_set_vuse_ops (gimple g, struct voptype_d *ops)\n+static inline def_operand_p\n+gimple_vdef_op (const_gimple g)\n {\n-  gcc_assert (gimple_has_mem_ops (g));\n-  g->gsmem.membase.vuse_ops = ops;\n+  struct def_optype_d *ops;\n+  if (!gimple_has_mem_ops (g))\n+    return NULL_DEF_OPERAND_P;\n+  ops = g->gsops.opbase.def_ops;\n+  if (ops\n+      && DEF_OP_PTR (ops) == &g->gsmem.membase.vdef)\n+    return DEF_OP_PTR (ops);\n+  return NULL_DEF_OPERAND_P;\n }\n \n \n-/* Return the set of VDEF operands for statement G.  */\n+/* Return the single VUSE operand of the statement G.  */\n \n-static inline struct voptype_d *\n-gimple_vdef_ops (const_gimple g)\n+static inline tree\n+gimple_vuse (const_gimple g)\n {\n   if (!gimple_has_mem_ops (g))\n-    return NULL;\n-  return g->gsmem.membase.vdef_ops;\n+    return NULL_TREE;\n+  return g->gsmem.membase.vuse;\n }\n \n+/* Return the single VDEF operand of the statement G.  */\n \n-/* Set OPS to be the set of VDEF operands for statement G.  */\n-\n-static inline void\n-gimple_set_vdef_ops (gimple g, struct voptype_d *ops)\n+static inline tree\n+gimple_vdef (const_gimple g)\n {\n-  gcc_assert (gimple_has_mem_ops (g));\n-  g->gsmem.membase.vdef_ops = ops;\n+  if (!gimple_has_mem_ops (g))\n+    return NULL_TREE;\n+  return g->gsmem.membase.vdef;\n }\n \n+/* Return the single VUSE operand of the statement G.  */\n \n-/* Return the set of symbols loaded by statement G.  Each element of the\n-   set is the DECL_UID of the corresponding symbol.  */\n-\n-static inline bitmap\n-gimple_loaded_syms (const_gimple g)\n+static inline tree *\n+gimple_vuse_ptr (gimple g)\n {\n   if (!gimple_has_mem_ops (g))\n     return NULL;\n-  return g->gsmem.membase.loads;\n+  return &g->gsmem.membase.vuse;\n }\n \n+/* Return the single VDEF operand of the statement G.  */\n \n-/* Return the set of symbols stored by statement G.  Each element of\n-   the set is the DECL_UID of the corresponding symbol.  */\n-\n-static inline bitmap\n-gimple_stored_syms (const_gimple g)\n+static inline tree *\n+gimple_vdef_ptr (gimple g)\n {\n   if (!gimple_has_mem_ops (g))\n     return NULL;\n-  return g->gsmem.membase.stores;\n+  return &g->gsmem.membase.vdef;\n+}\n+\n+/* Set the single VUSE operand of the statement G.  */\n+\n+static inline void\n+gimple_set_vuse (gimple g, tree vuse)\n+{\n+  gcc_assert (gimple_has_mem_ops (g));\n+  g->gsmem.membase.vuse = vuse;\n+}\n+\n+/* Set the single VDEF operand of the statement G.  */\n+\n+static inline void\n+gimple_set_vdef (gimple g, tree vdef)\n+{\n+  gcc_assert (gimple_has_mem_ops (g));\n+  g->gsmem.membase.vdef = vdef;\n }\n \n \n@@ -1486,19 +1509,10 @@ gimple_set_has_volatile_ops (gimple stmt, bool volatilep)\n static inline bool\n gimple_references_memory_p (gimple stmt)\n {\n-  return gimple_has_mem_ops (stmt) && stmt->gsbase.references_memory_p;\n+  return gimple_has_mem_ops (stmt) && gimple_vuse (stmt);\n }\n \n \n-/* Set the REFERENCES_MEMORY_P flag for STMT to MEM_P.  */\n-\n-static inline void\n-gimple_set_references_memory (gimple stmt, bool mem_p)\n-{\n-  if (gimple_has_mem_ops (stmt))\n-    stmt->gsbase.references_memory_p = (unsigned) mem_p;\n-}\n-\n /* Return the subcode for OMP statement S.  */\n \n static inline unsigned"}, {"sha": "e106f480cbce9bea60c25918d5e702f68e5db949", "filename": "gcc/graphite.c", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgraphite.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fgraphite.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgraphite.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -4119,7 +4119,7 @@ rename_variables_in_stmt (gimple stmt, htab_t map)\n   ssa_op_iter iter;\n   use_operand_p use_p;\n \n-  FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_USE)\n+  FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_ALL_USES)\n     {\n       tree use = USE_FROM_PTR (use_p);\n       tree new_name = get_new_name_from_old_name (map, use);\n@@ -4238,8 +4238,6 @@ expand_scalar_variables_expr (tree type, tree op0, enum tree_code code,\n \t    tree new_name = force_gimple_operand_gsi (gsi, expr, true, NULL,\n \t\t\t\t\t\t      true, GSI_SAME_STMT);\n \n-\t    set_symbol_mem_tag (SSA_NAME_VAR (new_name),\n-\t\t\t\tsymbol_mem_tag (SSA_NAME_VAR (old_name)));\n \t    return fold_build1 (code, type, new_name);\n \t  }\n \n@@ -4479,7 +4477,7 @@ graphite_copy_stmts_from_block (basic_block bb, basic_block new_bb, htab_t map)\n \t operands.  */\n       copy = gimple_copy (stmt);\n       gsi_insert_after (&gsi_tgt, copy, GSI_NEW_STMT);\n-      mark_symbols_for_renaming (copy);\n+      mark_sym_for_renaming (gimple_vop (cfun));\n \n       region = lookup_stmt_eh_region (stmt);\n       if (region >= 0)\n@@ -4488,7 +4486,7 @@ graphite_copy_stmts_from_block (basic_block bb, basic_block new_bb, htab_t map)\n \n       /* Create new names for all the definitions created by COPY and\n \t add replacement mappings for each new name.  */\n-      FOR_EACH_SSA_DEF_OPERAND (def_p, copy, op_iter, SSA_OP_DEF)\n+      FOR_EACH_SSA_DEF_OPERAND (def_p, copy, op_iter, SSA_OP_ALL_DEFS)\n \t{\n \t  tree old_name = DEF_FROM_PTR (def_p);\n \t  tree new_name = create_new_def_for (old_name, copy, def_p);\n@@ -4708,8 +4706,8 @@ translate_clast (scop_p scop, struct loop *context_loop,\n \t\t\t\t\t       next_e, map);\n       htab_delete (map);\n       loop_iv_stack_remove_constants (ivstack);\n-      update_ssa (TODO_update_ssa);\n       recompute_all_dominators ();\n+      update_ssa (TODO_update_ssa);\n       graphite_verify ();\n       return translate_clast (scop, context_loop, stmt->next, next_e, ivstack);\n     }"}, {"sha": "137dd66a3b3dc9537ba32bc89b8b6dbf22fb42f6", "filename": "gcc/ipa-cp.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-cp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-cp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-cp.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -969,6 +969,8 @@ ipcp_update_callgraph (void)\n \t\t\n \t\tnew_stmt = gimple_call_copy_skip_args (cs->call_stmt,\n \t\t\t\t\t\t       args_to_skip);\n+\t\tif (gimple_vdef (new_stmt))\n+\t\t  SSA_NAME_DEF_STMT (gimple_vdef (new_stmt)) = new_stmt;\n \t\tgsi = gsi_for_stmt (cs->call_stmt);\n \t\tgsi_replace (&gsi, new_stmt, true);\n \t\tcgraph_set_call_stmt (cs, new_stmt);"}, {"sha": "a8c4b1b310b9d8439fdf67f688620532e27984f5", "filename": "gcc/ipa-pure-const.c", "status": "modified", "additions": 42, "deletions": 11, "changes": 53, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-pure-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-pure-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-pure-const.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -140,8 +140,6 @@ static inline void\n check_decl (funct_state local, \n \t    tree t, bool checking_write)\n {\n-  if (MTAG_P (t))\n-    return;\n   /* Do not want to do anything with volatile except mark any\n      function that uses one to be not const or pure.  */\n   if (TREE_THIS_VOLATILE (t)) \n@@ -377,26 +375,59 @@ check_call (funct_state local, gimple call, bool ipa)\n   /* Direct functions calls are handled by IPA propagation.  */\n }\n \n-/* Look into pointer pointed to by GSIP and figure out what interesting side effects\n-   it have.  */\n+/* Look into pointer pointed to by GSIP and figure out what interesting side\n+   effects it has.  */\n static void\n check_stmt (gimple_stmt_iterator *gsip, funct_state local, bool ipa)\n {\n   gimple stmt = gsi_stmt (*gsip);\n   unsigned int i = 0;\n-  bitmap_iterator bi;\n \n   if (dump_file)\n     {\n       fprintf (dump_file, \"  scanning: \");\n       print_gimple_stmt (dump_file, stmt, 0, 0);\n     }\n-  if (gimple_loaded_syms (stmt))\n-    EXECUTE_IF_SET_IN_BITMAP (gimple_loaded_syms (stmt), 0, i, bi)\n-      check_decl (local, referenced_var_lookup (i), false);\n-  if (gimple_stored_syms (stmt))\n-    EXECUTE_IF_SET_IN_BITMAP (gimple_stored_syms (stmt), 0, i, bi)\n-      check_decl (local, referenced_var_lookup (i), true);\n+\n+  /* Look for direct loads and stores.  */\n+  if (gimple_has_lhs (stmt))\n+    {\n+      tree lhs = get_base_address (gimple_get_lhs (stmt));\n+      if (lhs && DECL_P (lhs))\n+\tcheck_decl (local, lhs, true);\n+    }\n+  if (gimple_assign_single_p (stmt))\n+    {\n+      tree rhs = get_base_address (gimple_assign_rhs1 (stmt));\n+      if (rhs && DECL_P (rhs))\n+\tcheck_decl (local, rhs, false);\n+    }\n+  else if (is_gimple_call (stmt))\n+    {\n+      for (i = 0; i < gimple_call_num_args (stmt); ++i)\n+\t{\n+\t  tree rhs = get_base_address (gimple_call_arg (stmt, i));\n+\t  if (rhs && DECL_P (rhs))\n+\t    check_decl (local, rhs, false);\n+\t}\n+    }\n+  else if (gimple_code (stmt) == GIMPLE_ASM)\n+    {\n+      for (i = 0; i < gimple_asm_ninputs (stmt); ++i)\n+\t{\n+\t  tree op = TREE_VALUE (gimple_asm_input_op (stmt, i));\n+\t  op = get_base_address (op);\n+\t  if (op && DECL_P (op))\n+\t    check_decl (local, op, false);\n+\t}\n+      for (i = 0; i < gimple_asm_noutputs (stmt); ++i)\n+\t{\n+\t  tree op = TREE_VALUE (gimple_asm_output_op (stmt, i));\n+\t  op = get_base_address (op);\n+\t  if (op && DECL_P (op))\n+\t    check_decl (local, op, true);\n+\t}\n+    }\n \n   if (gimple_code (stmt) != GIMPLE_CALL\n       && stmt_could_throw_p (stmt))"}, {"sha": "4bc49cf0a058500d7037551f9ac6b94e00ccc7ad", "filename": "gcc/ipa-reference.c", "status": "modified", "additions": 41, "deletions": 23, "changes": 64, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-reference.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-reference.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-reference.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -433,33 +433,51 @@ scan_stmt_for_static_refs (gimple_stmt_iterator *gsip,\n   if (fn)\n     local = get_reference_vars_info (fn)->local;\n \n-  if (gimple_loaded_syms (stmt))\n-    EXECUTE_IF_SET_IN_BITMAP (gimple_loaded_syms (stmt), 0, i, bi)\n-      mark_load (local, referenced_var_lookup (i));\n-  if (gimple_stored_syms (stmt))\n-    EXECUTE_IF_SET_IN_BITMAP (gimple_stored_syms (stmt), 0, i, bi)\n-      mark_store (local, referenced_var_lookup (i));\n-  if (gimple_addresses_taken (stmt))\n-    EXECUTE_IF_SET_IN_BITMAP (gimple_addresses_taken (stmt), 0, i, bi)\n-      mark_address_taken (referenced_var_lookup (i));\n-\n-  switch (gimple_code (stmt))\n+  /* Look for direct loads and stores.  */\n+  if (gimple_has_lhs (stmt))\n+    {\n+      tree lhs = get_base_address (gimple_get_lhs (stmt));\n+      if (lhs && DECL_P (lhs))\n+        mark_store (local, lhs);\n+    }\n+  if (gimple_assign_single_p (stmt))\n     {\n-    case GIMPLE_CALL:\n+      tree rhs = get_base_address (gimple_assign_rhs1 (stmt));\n+      if (rhs && DECL_P (rhs))\n+\tmark_load (local, rhs);\n+    }\n+  else if (is_gimple_call (stmt))\n+    {\n+      for (i = 0; i < gimple_call_num_args (stmt); ++i)\n+\t{\n+\t  tree rhs = get_base_address (gimple_call_arg (stmt, i));\n+\t  if (rhs && DECL_P (rhs))\n+\t    mark_load (local, rhs);\n+\t}\n       check_call (local, stmt);\n-      break;\n-      \n-    case GIMPLE_ASM:\n+    }\n+  else if (gimple_code (stmt) == GIMPLE_ASM)\n+    {\n+      for (i = 0; i < gimple_asm_ninputs (stmt); ++i)\n+\t{\n+\t  tree op = TREE_VALUE (gimple_asm_input_op (stmt, i));\n+\t  op = get_base_address (op);\n+\t  if (op && DECL_P (op))\n+\t    mark_load (local, op);\n+\t}\n+      for (i = 0; i < gimple_asm_noutputs (stmt); ++i)\n+\t{\n+\t  tree op = TREE_VALUE (gimple_asm_output_op (stmt, i));\n+\t  op = get_base_address (op);\n+\t  if (op && DECL_P (op))\n+\t    mark_store (local, op);\n+\t}\n       check_asm_memory_clobber (local, stmt);\n-      break;\n-\n-    /* We used to check nonlocal labels here and set them as potentially modifying\n-       everything.  This is not needed, since we can get to nonlocal label only\n-       from callee and thus we will get info propagated.  */\n-\n-    default:\n-      break;\n     }\n+\n+  if (gimple_addresses_taken (stmt))\n+    EXECUTE_IF_SET_IN_BITMAP (gimple_addresses_taken (stmt), 0, i, bi)\n+      mark_address_taken (referenced_var_lookup (i));\n   \n   return NULL;\n }"}, {"sha": "9ca53645aa0633ef544dcc7f8bbde85e8d2546a4", "filename": "gcc/ipa-struct-reorg.c", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-struct-reorg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fipa-struct-reorg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-struct-reorg.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -495,8 +495,6 @@ static void\n finalize_var_creation (tree new_decl)\n {\n   add_referenced_var (new_decl);  \n-  if (is_global_var (new_decl))\n-    mark_call_clobbered (new_decl, ESCAPE_UNKNOWN);\n   mark_sym_for_renaming (new_decl); \n }\n \n@@ -1249,6 +1247,13 @@ create_general_new_stmt (struct access_site *acc, tree new_type)\n   gimple new_stmt = gimple_copy (old_stmt);\n   unsigned i;\n \n+  /* We are really building a new stmt, clear the virtual operands.  */\n+  if (gimple_has_mem_ops (new_stmt))\n+    {\n+      gimple_set_vuse (new_stmt, NULL_TREE);\n+      gimple_set_vdef (new_stmt, NULL_TREE);\n+    }\n+\n   for (i = 0; VEC_iterate (tree, acc->vars, i, var); i++)\n     {\n       tree *pos;"}, {"sha": "852be11153cc2a0e0d0944357ff94db4b5814124", "filename": "gcc/lambda-code.c", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Flambda-code.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Flambda-code.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flambda-code.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -2142,7 +2142,7 @@ can_put_in_inner_loop (struct loop *inner, gimple stmt)\n   use_operand_p use_p;\n   \n   gcc_assert (is_gimple_assign (stmt));\n-  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS)\n+  if (gimple_vuse (stmt)\n       || !stmt_invariant_in_loop_p (inner, stmt))\n     return false;\n   \n@@ -2167,7 +2167,7 @@ can_put_after_inner_loop (struct loop *loop, gimple stmt)\n   imm_use_iterator imm_iter;\n   use_operand_p use_p;\n \n-  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS))\n+  if (gimple_vuse (stmt))\n     return false;\n   \n   FOR_EACH_IMM_USE_FAST (use_p, imm_iter, gimple_assign_lhs (stmt))\n@@ -2536,8 +2536,6 @@ perfect_nestify (struct loop *loop,\n \t\t incremented when we do.  */\n \t      for (bsi = gsi_start_bb (bbs[i]); !gsi_end_p (bsi);)\n \t\t{ \n-\t\t  ssa_op_iter i;\n-\t\t  tree n;\n \t\t  gimple stmt = gsi_stmt (bsi);\n \t\t  \n \t\t  if (stmt == exit_condition\n@@ -2553,12 +2551,12 @@ perfect_nestify (struct loop *loop,\n \t\t     VEC_index (tree, lbounds, 0), replacements, &firstbsi);\n \n \t\t  gsi_move_before (&bsi, &tobsi);\n-\t\t  \n+\n \t\t  /* If the statement has any virtual operands, they may\n \t\t     need to be rewired because the original loop may\n \t\t     still reference them.  */\n-\t\t  FOR_EACH_SSA_TREE_OPERAND (n, stmt, i, SSA_OP_ALL_VIRTUALS)\n-\t\t    mark_sym_for_renaming (SSA_NAME_VAR (n));\n+\t\t  if (gimple_vuse (stmt))\n+\t\t    mark_sym_for_renaming (gimple_vop (cfun));\n \t\t}\n \t    }\n \t  "}, {"sha": "ec02b5f50a49a34fd2bea88cc0613fb4dd36ae0f", "filename": "gcc/omp-low.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fomp-low.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fomp-low.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-low.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -3495,6 +3495,8 @@ expand_omp_taskreg (struct omp_region *region)\n \t  if (changed)\n \t    cleanup_tree_cfg ();\n \t}\n+      if (gimple_in_ssa_p (cfun))\n+\tupdate_ssa (TODO_update_ssa);\n       current_function_decl = save_current;\n       pop_cfun ();\n     }"}, {"sha": "2c7531e2dbaf63dc365cdfe15de8cb540a2c2d1c", "filename": "gcc/opts.c", "status": "modified", "additions": 0, "deletions": 16, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fopts.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -777,8 +777,6 @@ void\n decode_options (unsigned int argc, const char **argv)\n {\n   static bool first_time_p = true;\n-  static int initial_max_aliased_vops;\n-  static int initial_avg_aliased_vops;\n   static int initial_min_crossjump_insns;\n   static int initial_max_fields_for_field_sensitive;\n   static int initial_loop_invariant_max_bbs_in_loop;\n@@ -798,8 +796,6 @@ decode_options (unsigned int argc, const char **argv)\n       lang_hooks.initialize_diagnostics (global_dc);\n \n       /* Save initial values of parameters we reset.  */\n-      initial_max_aliased_vops = MAX_ALIASED_VOPS;\n-      initial_avg_aliased_vops = AVG_ALIASED_VOPS;\n       initial_min_crossjump_insns\n \t= compiler_params[PARAM_MIN_CROSSJUMP_INSNS].value;\n       initial_max_fields_for_field_sensitive\n@@ -907,11 +903,6 @@ decode_options (unsigned int argc, const char **argv)\n   flag_tree_switch_conversion = 1;\n   flag_ipa_cp = opt2;\n \n-  /* Allow more virtual operators to increase alias precision.  */\n-\n-  set_param_value (\"max-aliased-vops\",\n-\t\t   (opt2) ? 500 : initial_max_aliased_vops);\n-\n   /* Track fields in field-sensitive alias analysis.  */\n   set_param_value (\"max-fields-for-field-sensitive\",\n \t\t   (opt2) ? 100 : initial_max_fields_for_field_sensitive);\n@@ -931,13 +922,6 @@ decode_options (unsigned int argc, const char **argv)\n   if (flag_ipa_cp_clone)\n     flag_ipa_cp = 1;\n \n-  /* Allow even more virtual operators.  Max-aliased-vops was set above for\n-     -O2, so don't reset it unless we are at -O3.  */\n-  if (opt3)\n-    set_param_value (\"max-aliased-vops\", 1000);\n-\n-  set_param_value (\"avg-aliased-vops\", (opt3) ? 3 : initial_avg_aliased_vops);\n-\n   /* Just -O1/-O0 optimizations.  */\n   opt1_max = (optimize <= 1);\n   align_loops = opt1_max;"}, {"sha": "652bbb2dd5386b355c1864da9bfeeef4f20e9f4f", "filename": "gcc/params.def", "status": "modified", "additions": 0, "deletions": 10, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fparams.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fparams.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.def?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -537,16 +537,6 @@ DEFPARAM(PARAM_MAX_RELOAD_SEARCH_INSNS,\n \t \"The maximum number of instructions to search backward when looking for equivalent reload\",\n \t 100, 0, 0)\n \n-DEFPARAM(PARAM_MAX_ALIASED_VOPS,\n-         \"max-aliased-vops\",\n-\t \"The maximum number of virtual operators that a function is allowed to have before triggering memory partitioning heuristics\",\n-\t 100, 0, 0)\n-\n-DEFPARAM(PARAM_AVG_ALIASED_VOPS,\n-    \t \"avg-aliased-vops\",\n-\t \"The average number of virtual operators that memory statements are allowed to have before triggering memory partitioning heuristics\",\n-\t 1, 0, 0)\n-\n DEFPARAM(PARAM_MAX_SCHED_REGION_BLOCKS,\n \t \"max-sched-region-blocks\",\n \t \"The maximum number of blocks in a region to be considered for interblock scheduling\","}, {"sha": "a607fb05a42222cb77ebee1e1c3372ec89c19cd7", "filename": "gcc/params.h", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fparams.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fparams.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -140,10 +140,6 @@ typedef enum compiler_param\n   PARAM_VALUE (PARAM_SMS_DFA_HISTORY)\n #define SMS_LOOP_AVERAGE_COUNT_THRESHOLD \\\n   PARAM_VALUE (PARAM_SMS_LOOP_AVERAGE_COUNT_THRESHOLD)\n-#define MAX_ALIASED_VOPS \\\n-  PARAM_VALUE (PARAM_MAX_ALIASED_VOPS)\n-#define AVG_ALIASED_VOPS \\\n-  PARAM_VALUE (PARAM_AVG_ALIASED_VOPS)\n #define INTEGER_SHARE_LIMIT \\\n   PARAM_VALUE (PARAM_INTEGER_SHARE_LIMIT)\n #define MAX_LAST_VALUE_RTL \\"}, {"sha": "f19b8dda166f6d4b523483514ac35ea9bc6af0ad", "filename": "gcc/passes.c", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fpasses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Fpasses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -543,7 +543,6 @@ init_optimization_passes (void)\n       NEXT_PASS (pass_expand_omp);\n \n       NEXT_PASS (pass_referenced_vars);\n-      NEXT_PASS (pass_reset_cc_flags);\n       NEXT_PASS (pass_build_ssa);\n       NEXT_PASS (pass_early_warn_uninitialized);\n       NEXT_PASS (pass_all_early_optimizations);\n@@ -560,7 +559,6 @@ init_optimization_passes (void)\n \t  NEXT_PASS (pass_copy_prop);\n \t  NEXT_PASS (pass_merge_phi);\n \t  NEXT_PASS (pass_cd_dce);\n-\t  NEXT_PASS (pass_simple_dse);\n \t  NEXT_PASS (pass_tail_recursion);\n \t  NEXT_PASS (pass_convert_switch);\n           NEXT_PASS (pass_cleanup_eh);\n@@ -937,7 +935,7 @@ execute_function_todo (void *data)\n \t SSA form to become out-of-date (see PR 22037).  So, even\n \t if the parent pass had not scheduled an SSA update, we may\n \t still need to do one.  */\n-      if (!(flags & TODO_update_ssa_any) && need_ssa_update_p ())\n+      if (!(flags & TODO_update_ssa_any) && need_ssa_update_p (cfun))\n \tflags |= TODO_update_ssa;\n     }\n \n@@ -948,8 +946,13 @@ execute_function_todo (void *data)\n       cfun->last_verified &= ~TODO_verify_ssa;\n     }\n   \n+  if (flags & TODO_update_address_taken)\n+    execute_update_addresses_taken (true);\n+\n   if (flags & TODO_rebuild_alias)\n     {\n+      if (!(flags & TODO_update_address_taken))\n+\texecute_update_addresses_taken (true);\n       compute_may_aliases ();\n       cfun->curr_properties |= PROP_alias;\n     }\n@@ -1021,7 +1024,8 @@ static void\n execute_todo (unsigned int flags)\n {\n #if defined ENABLE_CHECKING\n-  if (need_ssa_update_p ())\n+  if (cfun\n+      && need_ssa_update_p (cfun))\n     gcc_assert (flags & TODO_update_ssa_any);\n #endif\n \n@@ -1265,6 +1269,8 @@ execute_one_pass (struct opt_pass *pass)\n      This is a hack until the new folder is ready.  */\n   in_gimple_form = (cfun && (cfun->curr_properties & PROP_trees)) != 0;\n \n+  initializing_dump = pass_init_dump_file (pass);\n+\n   /* Run pre-pass verification.  */\n   execute_todo (pass->todo_flags_start);\n \n@@ -1273,8 +1279,6 @@ execute_one_pass (struct opt_pass *pass)\n \t\t   (void *)(size_t)pass->properties_required);\n #endif\n \n-  initializing_dump = pass_init_dump_file (pass);\n-\n   /* If a timevar is present, start it.  */\n   if (pass->tv_id)\n     timevar_push (pass->tv_id);"}, {"sha": "77f7ed8a7683ff29d9deac111d231135a08818ed", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,3 +1,62 @@\n+2009-04-03  Richard Guenther  <rguenther@suse.de>\n+\n+\tPR middle-end/13146\n+\tPR tree-optimization/23940\n+\tPR tree-optimization/33237\n+\tPR middle-end/33974\n+\tPR middle-end/34093\n+\tPR tree-optimization/36201\n+\tPR tree-optimization/36230\n+\tPR tree-optimization/38049\n+\tPR tree-optimization/38207\n+\tPR tree-optimization/38230\n+\tPR tree-optimization/38301\n+\tPR tree-optimization/38585\n+\tPR middle-end/38895\n+\tPR tree-optimization/38985\n+\tPR tree-optimization/39299\n+\t* gcc.dg/pr19633-1.c: Adjust.\n+\t* gcc.dg/torture/pta-callused-1.c: Likewise.\n+\t* gcc.dg/torture/pr39074-2.c: Likewise.\n+\t* gcc.dg/torture/pr39074.c: Likewise.\n+\t* gcc.dg/torture/pta-ptrarith-3.c: New testcase.\n+\t* gcc.dg/torture/pr30375.c: Adjust.\n+\t* gcc.dg/torture/pr33563.c: Likewise.\n+\t* gcc.dg/torture/pr33870.c: Likewise.\n+\t* gcc.dg/torture/pr33560.c: Likewise.\n+\t* gcc.dg/torture/pta-structcopy-1.c: New testcase.\n+\t* gcc.dg/torture/ssa-pta-fn-1.c: Likewise.\n+\t* gcc.dg/tree-ssa/alias-15.c: Remove.\n+\t* gcc.dg/tree-ssa/ssa-dce-4.c: New testcase.\n+\t* gcc.dg/tree-ssa/pr26421.c: Adjust.\n+\t* gcc.dg/tree-ssa/ssa-fre-10.c: XFAIL.\n+\t* gcc.dg/tree-ssa/ssa-dce-5.c: New testcase.\n+\t* gcc.dg/tree-ssa/pr23382.c: Adjust.\n+\t* gcc.dg/tree-ssa/ssa-fre-20.c: New testcase.\n+\t* gcc.dg/tree-ssa/alias-16.c: Adjust.\n+\t* gcc.dg/tree-ssa/ssa-fre-13.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-fre-14.c: Likewise.\n+\t* gcc.dg/tree-ssa/alias-18.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-fre-15.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-lim-3.c: Likewise.\n+\t* gcc.dg/tree-ssa/alias-19.c: Likewise.\n+\t* gcc.dg/tree-ssa/pta-ptrarith-1.c: New testcase.\n+\t* gcc.dg/tree-ssa/pr13146.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-pre-23.c: Likewise.\n+\t* gcc.dg/tree-ssa/pta-ptrarith-2.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-fre-18.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-pre-24.c: New XFAILed testcase.\n+\t* gcc.dg/tree-ssa/ssa-fre-19.c: New testcase.\n+\t* gcc.dg/tree-ssa/alias-20.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-dse-12.c: Likewise.\n+\t* gcc.dg/tree-ssa/pr38895.c: Likewise.\n+\t* gcc.dg/uninit-B.c: XFAIL.\n+\t* gcc.dg/vect/no-vfa-vect-43.c: Adjust.\n+\t* gcc.dg/uninit-pr19430.c: XFAIL.\n+\t* g++.dg/tree-ssa/pr13146.C: New testcase.\n+\t* g++.dg/opt/pr36187.C: Adjust.\n+\t* g++.dg/torture/20090329-1.C: New testcase.\n+\n 2009-04-02  Chao-ying Fu  <fu@mips.com>\n \n \t* gcc.target/mips/interrupt_handler.c: New test."}, {"sha": "91166940d0915143b265c38881bc7941a383f565", "filename": "gcc/testsuite/g++.dg/opt/pr36187.C", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fopt%2Fpr36187.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fopt%2Fpr36187.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fopt%2Fpr36187.C?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do run } */\n-/* { dg-options \"-O2 --param max-aliased-vops=20\" } */\n+/* { dg-options \"-O2\" } */\n \n extern \"C\" void abort (void);\n enum SbxDataType { SbxINTEGER, SbxDECIMAL, SbxBYREF = 0x4000 };"}, {"sha": "0274a1944e5060abad6cdc1068f934c738ec0561", "filename": "gcc/testsuite/g++.dg/torture/20090329-1.C", "status": "added", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftorture%2F20090329-1.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftorture%2F20090329-1.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftorture%2F20090329-1.C?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,59 @@\n+/* { dg-do compile } */\n+\n+struct input_iterator_tag { };\n+template<typename _Category, typename _Tp, typename _Distance = long, typename _Pointer = _Tp*, typename _Reference = _Tp&>\n+struct iterator {\n+    typedef _Category iterator_category;\n+};\n+template<typename _Iterator> struct iterator_traits {\n+    typedef typename _Iterator::iterator_category iterator_category;\n+};\n+template<typename, typename> struct __lc_rai {\n+    template<typename _II1, typename _II2>\n+\tstatic _II1 __newlast1(_II1, _II1 __last1, _II2, _II2) {\n+\t    return __last1;\n+\t}\n+    template<typename _II> \n+\tstatic bool __cnd2(_II __first, _II __last) {\n+\t    return __first != __last;\n+\t}\n+};\n+template<typename _II1, typename _II2, typename _Compare>\n+bool lexicographical_compare(_II1 __first1, _II1 __last1, _II2 __first2,\n+\t\t\t     _II2 __last2, _Compare __comp) {\n+    typedef typename iterator_traits<_II1>::iterator_category _Category1;\n+    typedef typename iterator_traits<_II2>::iterator_category _Category2;\n+    typedef __lc_rai<_Category1, _Category2> __rai_type;\n+    __last1 = __rai_type::__newlast1(__first1, __last1, __first2, __last2);\n+    for (;\n+\t __first1 != __last1 && __rai_type::__cnd2(__first2, __last2);\n+\t ++__first1, ++__first2) {\n+\tif (__comp(*__first1, *__first2)) return true;\n+    }\n+}\n+void __assert_fail () throw () __attribute__ ((__noreturn__));\n+template<typename T> struct BoundsContainer { };\n+template<class T> class input_iterator_wrapper : public iterator<input_iterator_tag, T, long, T*, T&> {\n+public:\n+    typedef BoundsContainer<T> ContainerType;\n+    T* ptr;\n+    ContainerType* SharedInfo;\n+    input_iterator_wrapper(const input_iterator_wrapper& in) : ptr(in.ptr), SharedInfo(in.SharedInfo) { }\n+    bool operator==(const input_iterator_wrapper& in) const {\n+\t(static_cast<void> ((SharedInfo != __null\n+\t\t\t     && SharedInfo == in.SharedInfo)\n+\t\t\t    ? 0 : (__assert_fail (), 0)));\n+    }\n+    bool operator!=(const input_iterator_wrapper& in) const {\n+\treturn !(*this == in);\n+    }\n+    T& operator*() const { }\n+    input_iterator_wrapper& operator++() { }\n+};\n+struct X { };\n+bool predicate(const X&, const X&) {\n+    return true;\n+}\n+bool test2(input_iterator_wrapper<X>& x) {\n+    return lexicographical_compare(x, x, x, x, predicate);\n+}"}, {"sha": "62447c1a2727799a8b6363a9419b567dd6c6ac91", "filename": "gcc/testsuite/g++.dg/tree-ssa/pr13146.C", "status": "added", "additions": 74, "deletions": 0, "changes": 74, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftree-ssa%2Fpr13146.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftree-ssa%2Fpr13146.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftree-ssa%2Fpr13146.C?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,74 @@\n+/* { dg-do link } */\n+/* { dg-options \"-O -fstrict-aliasing\" } */\n+\n+class first\n+{\n+public:\n+  double d;\n+  int f1;\n+};\n+\n+class middle : public first\n+{\n+};\n+\n+class second : public middle\n+{\n+public:\n+  int f2;\n+  short a;\n+};\n+\n+class third\n+{\n+public:\n+  char a;\n+  char b;\n+};\n+\n+class multi: public third, public second\n+{\n+public:\n+  short s;\n+  char f3;\n+};\n+\n+extern void link_error ();\n+\n+void\n+foo (first *s1, second *s2)\n+{\n+  s1->f1 = 0;\n+  s2->f2 = 0;\n+  s1->f1++;\n+  s2->f2++;\n+  s1->f1++;\n+  s2->f2++;\n+  if (s1->f1 != 2)\n+    link_error ();\n+}\n+\n+void\n+bar (first *s1, multi *s3)\n+{\n+  s1->f1 = 0;\n+  s3->f3 = 0;\n+  s1->f1++;\n+  s3->f3++;\n+  s1->f1++;\n+  s3->f3++;\n+  if (s1->f1 != 2)\n+    link_error ();\n+}\n+\n+\n+int\n+main()\n+{\n+  first a;\n+  second b;\n+  multi c;\n+  foo (&a, &b);\n+  bar (&a, &c);\n+  return 0;\n+}"}, {"sha": "c05e46aef643a40125d9b3eadb49b0478bbebc4e", "filename": "gcc/testsuite/gcc.dg/pr19633-1.c", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Fpr19633-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Fpr19633-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fpr19633-1.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,9 +1,5 @@\n /* { dg-do run } */\n-\n-/* The max-aliased-vops setting is a temporary workaround to avoid the\n-   random failures as described in PR 30194.  This test case does not\n-   need alias sets bigger than 13 elements.  */\n-/* { dg-options \"-O2 --param max-aliased-vops=15\" } */\n+/* { dg-options \"-O2\" } */\n \n extern void abort (void);\n "}, {"sha": "435c38f13b866629045f851fdddca8cdcc6ac36c", "filename": "gcc/testsuite/gcc.dg/torture/pr30375.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr30375.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr30375.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr30375.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,4 @@\n /* { dg-do run } */\n-/* { dg-options \"--param max-aliased-vops=0\" } */\n \n typedef struct _s {\n     int a;"}, {"sha": "7eea1e3f6019a4f0f24157a53ebf5f6b5f3a6b92", "filename": "gcc/testsuite/gcc.dg/torture/pr33560.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33560.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33560.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33560.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,4 @@\n /* { dg-do run } */\n-/* { dg-options \"--param max-aliased-vops=0\" } */\n \n struct T\n {"}, {"sha": "33e78521c50c863bc7d1bf4ff8c0abea91a3bd5b", "filename": "gcc/testsuite/gcc.dg/torture/pr33563.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33563.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33563.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33563.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,4 @@\n /* { dg-do run } */\n-/* { dg-options \"--param max-aliased-vops=0\" } */\n \n struct T\n {"}, {"sha": "9c0e30d94be586db0dc1f3d2b0de67e7be5cd8d1", "filename": "gcc/testsuite/gcc.dg/torture/pr33870.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33870.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33870.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr33870.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,4 @@\n /* { dg-do run } */\n-/* { dg-options \"--param max-aliased-vops=1\" } */\n \n struct X {\n   int i;"}, {"sha": "a90c5643dca55d9332a01110e3a2e8e250ed86b1", "filename": "gcc/testsuite/gcc.dg/torture/pr39074-2.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr39074-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr39074-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr39074-2.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -30,5 +30,5 @@ int main()\n   return 0;\n }\n \n-/* { dg-final { scan-tree-dump \"y.._., name memory tag: NMT..., is dereferenced, points-to vars: { i }\" \"alias\" } } */\n+/* { dg-final { scan-tree-dump \"y.._., points-to vars: { i }\" \"alias\" } } */\n /* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "7be7e227b252a46e60054afeaf22ee3af7619ec7", "filename": "gcc/testsuite/gcc.dg/torture/pr39074.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr39074.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr39074.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr39074.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -27,5 +27,5 @@ int main()\n   return 0;\n }\n \n-/* { dg-final { scan-tree-dump \"y.._., name memory tag: NMT..., is dereferenced, points-to vars: { i }\" \"alias\" } } */\n+/* { dg-final { scan-tree-dump \"y.._., points-to vars: { i }\" \"alias\" } } */\n /* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "dfbde86c65b28fa9c688eb0fcca36392dd1ebbc1", "filename": "gcc/testsuite/gcc.dg/torture/pta-callused-1.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-callused-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-callused-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-callused-1.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -21,5 +21,5 @@ int main()\n   return 0;\n }\n \n-/* { dg-final { scan-tree-dump \"p.._., name memory tag: NMT..., is dereferenced, points-to vars: { i j }\" \"alias\" } } */\n+/* { dg-final { scan-tree-dump \"p.._., points-to vars: { i j }\" \"alias\" } } */\n /* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "6c08319d8c53fb11b6c13cca092823ee8ec5296b", "filename": "gcc/testsuite/gcc.dg/torture/pta-ptrarith-3.c", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-ptrarith-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-ptrarith-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-ptrarith-3.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,37 @@\n+/* { dg-do run } */\n+/* { dg-options \"-fdump-tree-alias\" } */\n+/* { dg-skip-if \"\" { *-*-* } { \"-O0\" } { \"\" } } */\n+\n+extern void abort (void);\n+struct X {\n+  int *p;\n+  int *q;\n+  int *r;\n+};\n+int __attribute__((noinline))\n+foo(int i, int j, int k, int off)\n+{\n+  struct X x;\n+  int **p, *q;\n+  x.p = &i;\n+  x.q = &j;\n+  x.r = &k;\n+  p = &x.q;\n+  p += off;\n+  /* *p points to { i, j, k } */\n+  q = *p;\n+  return *q;\n+}\n+int main()\n+{\n+  if (foo(1, 2, 3, -1) != 1)\n+    abort ();\n+  if (foo(1, 2, 3, 0) != 2)\n+    abort ();\n+  if (foo(1, 2, 3, 1) != 3)\n+    abort ();\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump \"q_., points-to vars: { i j k }\" \"alias\" } } */\n+/* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "bdb2acb0464ff563f1e1d8ff543e923cbe412fb2", "filename": "gcc/testsuite/gcc.dg/torture/pta-structcopy-1.c", "status": "added", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-structcopy-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-structcopy-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpta-structcopy-1.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,34 @@\n+/* { dg-do run } */\n+/* { dg-options \"-fno-tree-sra -fdump-tree-alias\" } */\n+/* { dg-skip-if \"\" { *-*-* } { \"-O0\" } { \"\" } } */\n+\n+struct X\n+{\n+  long l1;\n+  struct Y\n+    {\n+      long l2;\n+      int *p;\n+    } y;\n+};\n+int i;\n+static int\n+foo (struct X *x)\n+{\n+  struct Y y = x->y;\n+  *y.p = 0;\n+  i = 1;\n+  return *y.p;\n+}\n+extern void abort (void);\n+int main()\n+{\n+  struct X x;\n+  x.y.p = &i;\n+  if (foo(&x) != 1)\n+    abort ();\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump \"points-to vars: { i }\" \"alias\" } } */\n+/* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "21d36dc60f25b1ca8b183844a3528c538eea31da", "filename": "gcc/testsuite/gcc.dg/torture/ssa-pta-fn-1.c", "status": "added", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fssa-pta-fn-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fssa-pta-fn-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fssa-pta-fn-1.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,61 @@\n+/* { dg-do run } */\n+/* { dg-options \"-fdump-tree-alias\" } */\n+/* { dg-skip-if \"\" { *-*-* } { \"-O0\" } { \"\" } } */\n+\n+extern void abort (void);\n+int *glob;\n+\n+int * __attribute__((noinline,const))\n+foo_const(int *p) { return p; }\n+\n+int * __attribute__((noinline,pure))\n+foo_pure(int *p) { return glob; }\n+\n+int * __attribute__((noinline))\n+foo_normal(int *p) { glob = p; return p; }\n+\n+void test_const(void)\n+{\n+  int i;\n+  int *p = &i;\n+  int *q_const = foo_const(p);\n+  *p = 1;\n+  *q_const = 2;\n+  if (*p != 2)\n+    abort ();\n+}\n+\n+void test(void)\n+{\n+  int i;\n+  int *p = &i;\n+  int *q_normal = foo_normal(p);\n+  *p = 1;\n+  *q_normal = 2;\n+  if (*p != 2)\n+    abort ();\n+}\n+\n+void test_pure(void)\n+{\n+  int i;\n+  int *p = &i;\n+  int *q_pure = foo_pure(p);\n+  *p = 1;\n+  *q_pure = 2;\n+  if (*p != 2)\n+    abort ();\n+}\n+\n+int main()\n+{\n+  test_const();\n+  test();\n+  test_pure();\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump \"q_const_., points-to non-local, points-to vars: { i }\" \"alias\" } } */\n+/* { dg-final { scan-tree-dump \"q_pure_., points-to non-local, points-to escaped, points-to vars: { i }\" \"alias\" } } */\n+/* { dg-final { scan-tree-dump \"q_normal_., points-to non-local, points-to escaped, points-to vars: { }\" \"alias\" } } */\n+/* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "617af0fd154fabd1d173b1f6c928a68f6e05157a", "filename": "gcc/testsuite/gcc.dg/tree-ssa/alias-15.c", "status": "removed", "additions": 0, "deletions": 19, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/95fe602ebea97abb5c5a303e7441fa055b65bb32/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-15.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/95fe602ebea97abb5c5a303e7441fa055b65bb32/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-15.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-15.c?ref=95fe602ebea97abb5c5a303e7441fa055b65bb32", "patch": "@@ -1,19 +0,0 @@\n-/* { dg-do compile } */\n-/* { dg-options \"-O -fno-early-inlining -fdump-tree-alias-vops-details\" } */\n-\n-struct foo {\n-  int a;\n-  struct X {\n-    int b[4];\n-  } b;\n-} m;\n-static inline struct X *wrap(struct X *p) { return p; }\n-int test2(void)\n-{\n-  struct X *p = wrap(&m.b);\n-  /* Both memory references need to alias the same tags.  */\n-  return p->b[3] - m.b.b[3];\n-}\n-\n-/* { dg-final { scan-tree-dump-times \"VUSE <m_.\\\\\\(D\\\\\\)>\" 2 \"alias\" } } */\n-/* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "c71486c26c20ab8a483dfa04b2cc86db669a71d5", "filename": "gcc/testsuite/gcc.dg/tree-ssa/alias-16.c", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-16.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-16.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-16.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,9 +1,5 @@\n /* { dg-do run } */\n-/* { dg-options \"-O --param max-aliased-vops=1\" } */\n \n-/* Compile with -O --param max-aliased-vops=1.  This partitions all\n-   the initial SFTs for 'm' which was causing the operand scanner to\n-   miss adding the right SFTs to p->b[2].  */\n extern void abort (void);\n \n struct X {"}, {"sha": "c78bcebfbf7782dfec34280dc36b174351af28fd", "filename": "gcc/testsuite/gcc.dg/tree-ssa/alias-18.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-18.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-18.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-18.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O2 -fdump-tree-fre-details -fdump-tree-optimized --param max-aliased-vops=0\" } */\n+/* { dg-options \"-O2 -fdump-tree-fre-details -fdump-tree-optimized\" } */\n \n struct A {\n   int i;"}, {"sha": "7b3689049ac54baa6f5064eb028c6c0a7d6a749a", "filename": "gcc/testsuite/gcc.dg/tree-ssa/alias-19.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-19.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-19.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-19.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -26,6 +26,5 @@ int main()\n }\n \n /* { dg-final { scan-tree-dump \"q_. = { a b }\" \"alias\" } } */\n-/* { dg-final { scan-tree-dump \"q_., name memory tag: NMT..., is dereferenced, points-to vars: { a b }\" \"alias\" } } */\n-/* { dg-final { scan-tree-dump \"# VUSE <a_.\\\\\\(D\\\\\\), b_.>\" \"alias\" } } */\n+/* { dg-final { scan-tree-dump \"q_., points-to vars: { a b }\" \"alias\" } } */\n /* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "7991c52fd0a512baa35d3e782ec787c3ee6996ae", "filename": "gcc/testsuite/gcc.dg/tree-ssa/alias-20.c", "status": "added", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-20.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-20.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-20.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,24 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fstrict-aliasing -fdump-tree-optimized\" } */\n+\n+struct S { float f; int i; };\n+struct R { int x; int i; };\n+\n+/* Strict-aliasing rules say that int and float do not alias.  */\n+int bar(struct S *s, int *i)\n+{\n+  *i = 0;\n+  s->f = 1.0;\n+  return *i;\n+}\n+\n+/* Strict-aliasing rules say that S and R do not alias.  */\n+int foo(struct S *s, struct R *r)\n+{\n+  r->i = 0;\n+  s->i = 1;\n+  return r->i;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"return 0;\" 2 \"optimized\" } } */\n+/* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "b556457678ccdda2efdd1c30a068c5bbd86711e0", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr13146.c", "status": "added", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr13146.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr13146.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr13146.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,22 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fstrict-aliasing -fdump-tree-optimized\" } */\n+\n+struct A\n+{\n+  int i;\n+};\n+struct B\n+{\n+  struct A a;\n+  int j;\n+};\n+\n+int foo (struct A *p, struct B *q)\n+{\n+  p->i = 0;\n+  q->j = 1;\n+  return p->i;\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 0;\" \"optimized\" } } */\n+/* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "fd74af8d6a18f9373c42a67eceee990de9a01626", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr23382.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr23382.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr23382.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr23382.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */ \n-/* { dg-options \"-O2 -fdump-tree-alias-vops\" } */\n+/* { dg-options \"-O2 -fdump-tree-pre-details\" } */\n struct a\n {\n   int length;\n@@ -13,5 +13,5 @@ int f(void)\n    struct a *a = malloc(sizeof(struct a));\n    return a->length;\n }\n-/* { dg-final { scan-tree-dump-times \"VDEF <HEAP\" 1 \"alias\"} } */\n-/* { dg-final { cleanup-tree-dump \"alias\" } } */\n+/* { dg-final { scan-tree-dump-times \"Variable: HEAP\" 1 \"pre\"} } */\n+/* { dg-final { cleanup-tree-dump \"pre\" } } */"}, {"sha": "70f123158afbe9f7f8be300b360bb3793fa3aa3d", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr26421.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr26421.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr26421.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr26421.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O2 -fdump-tree-alias-vops\" } */\n+/* { dg-options \"-O2 -fdump-tree-optimized\" } */\n \n typedef struct {\n   int i;\n@@ -18,5 +18,5 @@ int foo(void)\n \n /* Verify the call clobbers all of a.  */\n \n-/* { dg-final { scan-tree-dump-times \"VDEF <a_\" 2 \"alias\" } } */\n-/* { dg-final { cleanup-tree-dump \"alias\" } } */\n+/* { dg-final { scan-tree-dump-not \"return 1;\" \"optimized\" } } */\n+/* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "0a96e53348aeac11886e0920a80a64fec44d3f4a", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr38895.c", "status": "added", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr38895.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr38895.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr38895.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,24 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fstrict-aliasing -fdump-tree-optimized\" } */\n+\n+struct A {\n+  int i;\n+  int j;\n+};\n+struct B {\n+  struct A a1;\n+  struct A a2;\n+};\n+struct C {\n+  struct A a1;\n+  struct B b;\n+};\n+int foo(struct C *c, struct B *b)\n+{\n+  c->a1.i = 1;\n+  b->a1.i = 0;\n+  return c->a1.i;\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 1;\" \"optimized\" } } */\n+/* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "b61674dff3ac8967d3910e6071d768435e36cad6", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pta-ptrarith-1.c", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpta-ptrarith-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpta-ptrarith-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpta-ptrarith-1.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,26 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -fno-tree-ccp -fdump-tree-alias\" } */\n+\n+extern void abort (void);\n+struct X {\n+  int *p;\n+  int *q;\n+  int *r;\n+};\n+int __attribute__((noinline))\n+foo(int i, int j, int k, int off)\n+{\n+  struct X x;\n+  int **p, *q;\n+  x.p = &i;\n+  x.q = &j;\n+  x.r = &k;\n+  p = &x.q;\n+  p += 1;\n+  /* *p points to { k } */\n+  q = *p;\n+  return *q;\n+}\n+\n+/* { dg-final { scan-tree-dump \"q_., points-to vars: { k }\" \"alias\" } } */\n+/* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "adb01b2316527f5b460ae0706ce0bf4a9a59c5a8", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pta-ptrarith-2.c", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpta-ptrarith-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpta-ptrarith-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpta-ptrarith-2.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,26 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -fno-tree-ccp -fdump-tree-alias\" } */\n+\n+extern void abort (void);\n+struct X {\n+  int *p;\n+  int *q;\n+  int *r;\n+};\n+int __attribute__((noinline))\n+foo(int i, int j, int k, int off)\n+{\n+  struct X x;\n+  int **p, *q;\n+  x.p = &i;\n+  x.q = &j;\n+  x.r = &k;\n+  p = &x.q;\n+  p -= 1;\n+  /* *p points to { i } */\n+  q = *p;\n+  return *q;\n+}\n+\n+/* { dg-final { scan-tree-dump \"q_., points-to vars: { i }\" \"alias\" } } */\n+/* { dg-final { cleanup-tree-dump \"alias\" } } */"}, {"sha": "89118a62621c6f7c02540d12563167ddf8c95e0d", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-dce-4.c", "status": "added", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-4.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,18 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-cddce1\" } */\n+\n+int foo(int b)\n+{\n+  int a[128];\n+  a[b] = 1;\n+  if (b)\n+    {\n+      b = 2;\n+      a[2] = 0;\n+    }\n+  a[2] = 3;\n+  return a[2] + b;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"a\\\\\\[\\[^\\n\\]\\\\\\]\" 2 \"cddce1\" } } */\n+/* { dg-final { cleanup-tree-dump \"cddce1\" } } */"}, {"sha": "11c9e666b3c646edf3e5971011c0505f07e8855b", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-dce-5.c", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-5.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,15 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fno-tree-sra -fdump-tree-cddce1\" } */\n+\n+struct X { int i; };\n+struct X foo(int b)\n+{\n+  struct X x;\n+  if (b)\n+    x.i = 0;\n+  x.i = 1;\n+  return x;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"x.i =\" 1 \"cddce1\" } } */\n+/* { dg-final { cleanup-tree-dump \"cddce1\" } } */"}, {"sha": "dd8f69c8aea98f46603fbfa5a817dc633db123ac", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-dse-12.c", "status": "added", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dse-12.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dse-12.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dse-12.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,12 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-dse1\" } */\n+\n+void foo (int *p, int b)\n+{\n+  if (b)\n+    *p = 1;\n+  *p = 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"\\\\\\*p\" 1 \"dse1\" } } */\n+/* { dg-final { cleanup-tree-dump \"dse1\" } } */"}, {"sha": "34217a0298a672a6f95e6c99e5c2b9ab57c67a2c", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-10.c", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-10.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-10.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-10.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -18,5 +18,9 @@ void __frame_state_for (volatile char *state_in, int x)\n     }\n }\n \n-/* { dg-final { scan-tree-dump \"Insertions: 2\" \"pre\" } } */\n+/* This is a weird testcase.  It should need PPRE to hoist the loop\n+   invariants and the volatileness of state_in prevents DSE of the\n+   first store.  Thus, this is XFAILed.  */\n+\n+/* { dg-final { scan-tree-dump \"Insertions: 2\" \"pre\" { xfail *-*-* } } } */\n /* { dg-final { cleanup-tree-dump \"pre\" } } */"}, {"sha": "ae9eb5a2002de2e4426d9527f5f4d197c4b5bcf4", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-13.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-13.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-13.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-13.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,9 +1,7 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O -fstrict-aliasing -fno-tree-sra --param max-aliased-vops=0 --param max-fields-for-field-sensitive=0 -fdump-tree-fre-details\" } */\n+/* { dg-options \"-O -fstrict-aliasing -fno-tree-sra -fdump-tree-fre-details\" } */\n \n-/* Should be optimized, propagating &a into (*p)[i] with parameters\n-     --param max-aliased-vops=0 --param max-fields-for-field-sensitive=0\n-   which means max 1 VOP per stmt and no SFTs.  */\n+/* Should be optimized, propagating &a into (*p)[i].  */\n \n /* For this testcase we need TBAA to work.  */\n "}, {"sha": "24b58ee941a31233ed861f03ed83afaf256e60f8", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-14.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-14.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-14.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-14.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,9 +1,7 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O -fno-tree-sra --param max-aliased-vops=0 --param max-fields-for-field-sensitive=0 -fdump-tree-fre-details\" } */\n+/* { dg-options \"-O -fno-tree-sra -fdump-tree-fre-details\" } */\n \n-/* Should be optimized, propagating &a into (*p)[i] with parameters\n-     --param max-aliased-vops=0 --param max-fields-for-field-sensitive=0\n-   which means max 1 VOP per stmt and no SFTs.  */\n+/* Should be optimized, propagating &a into (*p)[i].  */\n \n struct Foo\n {"}, {"sha": "a557f27f319b00ba272fd85887929f963220e05f", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-15.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-15.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-15.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-15.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,9 +1,7 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O -fno-tree-sra --param max-aliased-vops=0 --param max-fields-for-field-sensitive=0 -fdump-tree-fre-details\" } */\n+/* { dg-options \"-O -fno-tree-sra -fdump-tree-fre-details\" } */\n \n-/* Should be optimized, propagating &a into (*p)[i] with parameters\n-     --param max-aliased-vops=0 --param max-fields-for-field-sensitive=0\n-   which means max 1 VOP per stmt and no SFTs.  */\n+/* Should be optimized, propagating &a into (*p)[i].  */\n \n struct Foo\n {"}, {"sha": "392b1f6cf7df91c2f682bee105dbd946e925ebe7", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-18.c", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-18.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-18.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-18.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,28 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-fre\" } */\n+\n+struct a\n+{\n+  union\n+  {\n+    int a;\n+    int b;\n+  };\n+  union\n+  {\n+    int c;\n+    int d;\n+  };\n+};\n+\n+int f(struct a *c)\n+{\n+  int d = c->a;\n+  c->c = 1;\n+  return c->a + d;\n+}\n+\n+/* We should have CSEd the load from c->a.  */\n+\n+/* { dg-final { scan-tree-dump-times \"c_.*\\\\\\.a\" 1 \"fre\" } } */\n+/* { dg-final { cleanup-tree-dump \"fre\" } } */"}, {"sha": "688fe86403e89f4fac2945fb257b725342133a15", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-19.c", "status": "added", "additions": 31, "deletions": 0, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-19.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-19.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-19.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,31 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-fre\" } */\n+\n+struct a\n+{\n+  union\n+  {\n+    int a;\n+    int b;\n+  };\n+  union\n+  {\n+    int c;\n+    int d;\n+  };\n+  int e;\n+};\n+\n+int f(struct a *c)\n+{\n+  int d;\n+  c->e = 2;\n+  d = c->a;\n+  c->c = 1;\n+  return c->a + d;\n+}\n+\n+/* We should have CSEd the load from c->a.  */\n+\n+/* { dg-final { scan-tree-dump-times \"c_.*\\\\\\.a\" 1 \"fre\" } } */\n+/* { dg-final { cleanup-tree-dump \"fre\" } } */"}, {"sha": "f73ad36c5b751757528ea7f8980b31d25518862c", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-20.c", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-20.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-20.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-20.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,20 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-optimized\" } */\n+\n+int i, j;\n+int foo(int b)\n+{\n+  j = 0;\n+  if (b)\n+    goto L2;\n+L1:\n+  i = i + 1;\n+L2:\n+  i = i + 1;\n+  if (i == 1)\n+    goto L1;\n+  return j;\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 0;\" \"optimized\" } } */\n+/* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "91956017898a51524814e581352ccc50d5f093f3", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-lim-3.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-lim-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-lim-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-lim-3.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O2 -fdump-tree-lim-details\" } */\n+/* { dg-options \"-O -fdump-tree-lim-details\" } */\n \n struct { int x; int y; } global;\n void foo(int n)"}, {"sha": "88c8bb71eb9c8f43197f7456757eb786fc8a87ee", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-pre-23.c", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-23.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-23.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-23.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,13 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -fdump-tree-pre-stats\" } */\n+\n+struct { int x; int y; } global;\n+void foo(int n)\n+{\n+  int i;\n+  for ( i=0; i<n; i++)\n+    global.y += global.x*global.x;\n+}\n+\n+/* { dg-final { scan-tree-dump \"Eliminated: 2\" \"pre\" } } */\n+/* { dg-final { cleanup-tree-dump \"pre\" } } */"}, {"sha": "6729e2a297ebf42401e3332b71891531cbeef5e1", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-pre-24.c", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-24.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-24.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-24.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,20 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -fdump-tree-pre\" } */\n+\n+void foo(int *p, double *x, int n)\n+{\n+  int i;\n+  for (i = 0; i < n; ++i)\n+    *(x + *p * i) = 0.0;\n+}\n+\n+/* We should remove the unnecessary insertion of a phi-node and\n+   _not_ end up using the phi result for replacement *p.\n+   The issue here is that when PHI-translating the virtual operands\n+   we assign different value-numbers to the load.  Re-running VN\n+   after insertion or trying to be clever and doing this on the\n+   fly during PHI translation would solve this.  The next copyprop\n+   fixes this anyway.  */\n+\n+/* { dg-final { scan-tree-dump-not \"= prephitmp\" \"pre\" { xfail *-*-* } } } */\n+/* { dg-final { cleanup-tree-dump \"pre\" } } */"}, {"sha": "f03dd701853ed20d066399727869040af6146c3a", "filename": "gcc/testsuite/gcc.dg/uninit-B.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Funinit-B.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Funinit-B.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Funinit-B.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -9,7 +9,7 @@ void\n baz (void)\n {\n   int i;\n-  if (i) /* { dg-warning \"is used uninitialized\" \"uninit i warning\" } */\n+  if (i) /* { dg-warning \"is used uninitialized\" \"uninit i warning\" { xfail *-*-* } } */\n     bar (i);\n   foo (&i);\n }"}, {"sha": "53810c553e1c6aebf6def1e416867ffa25e04e60", "filename": "gcc/testsuite/gcc.dg/uninit-pr19430.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Funinit-pr19430.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Funinit-pr19430.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Funinit-pr19430.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -29,7 +29,7 @@ void frob(int *pi);\n int main(void)\n {\n   int i; \n-  printf(\"i = %d\\n\", i); /* { dg-warning \"'i' is used uninitialized in this function\" } */\n+  printf(\"i = %d\\n\", i); /* { dg-warning \"'i' is used uninitialized in this function\" \"\" { xfail *-*-* } } */\n   frob(&i);\n \n   return 0;\n@@ -38,6 +38,6 @@ int main(void)\n void foo3(int*);\n void bar3(void) { \n   int x; \n-  if(x) /* { dg-warning \"'x' is used uninitialized in this function\" \"uninitialized\" } */\n+  if(x) /* { dg-warning \"'x' is used uninitialized in this function\" \"uninitialized\" { xfail *-*-* } } */\n     foo3(&x); \n }"}, {"sha": "d9bb114d416f9b1a3807a062bf482d871f072bc5", "filename": "gcc/testsuite/gcc.dg/vect/no-vfa-vect-43.c", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fno-vfa-vect-43.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fno-vfa-vect-43.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fno-vfa-vect-43.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -28,7 +28,8 @@ main1 (float *pa)\n   float pb[N] __attribute__ ((__aligned__(16))) = {0,3,6,9,12,15,18,21,24,27,30,33,36,39,42,45,48,51,54,57};\n   float pc[N] __attribute__ ((__aligned__(16))) = {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19};\n \n- /* Not vectorizable: pa may alias pb and/or pc, since their addresses escape.  */\n+  /* Vectorizable: pa may not alias pb and/or pc, even though their\n+     addresses escape.  &pa would need to escape to point to escaped memory.  */\n   for (i = 0; i < N; i++)\n     {\n       pa[i] = pb[i] * pc[i];\n@@ -74,6 +75,6 @@ int main (void)\n   return 0;\n }\n \n-/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\" } } */\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 2 \"vect\" } } */\n /*  { dg-final { scan-tree-dump-times \"Alignment of access forced using versioning\" 1 \"vect\" { target vect_no_align } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "30149cd921510a6ea087bf6d524c1b08f6638da8", "filename": "gcc/timevar.def", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftimevar.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftimevar.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftimevar.def?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -69,6 +69,7 @@ DEFTIMEVAR (TV_DF_NOTE\t\t     , \"df reg dead/unused notes\")\n DEFTIMEVAR (TV_REG_STATS\t     , \"register information\")\n \n DEFTIMEVAR (TV_ALIAS_ANALYSIS\t     , \"alias analysis\")\n+DEFTIMEVAR (TV_ALIAS_STMT_WALK\t     , \"alias stmt walking\")\n DEFTIMEVAR (TV_REG_SCAN\t\t     , \"register scan\")\n DEFTIMEVAR (TV_REBUILD_JUMP\t     , \"rebuild jump labels\")\n /* Timing in various stages of the compiler.  */\n@@ -87,11 +88,6 @@ DEFTIMEVAR (TV_TREE_COPY_PROP        , \"tree copy propagation\")\n DEFTIMEVAR (TV_TREE_STORE_COPY_PROP  , \"tree store copy prop\")\n DEFTIMEVAR (TV_FIND_REFERENCED_VARS  , \"tree find ref. vars\")\n DEFTIMEVAR (TV_TREE_PTA\t\t     , \"tree PTA\")\n-DEFTIMEVAR (TV_TREE_MAY_ALIAS        , \"tree alias analysis\")\n-DEFTIMEVAR (TV_CALL_CLOBBER          , \"tree call clobbering\")\n-DEFTIMEVAR (TV_FLOW_SENSITIVE        , \"tree flow sensitive alias\")\n-DEFTIMEVAR (TV_FLOW_INSENSITIVE      , \"tree flow insensitive alias\")\n-DEFTIMEVAR (TV_MEMORY_PARTITIONING   , \"tree memory partitioning\")\n DEFTIMEVAR (TV_TREE_INSERT_PHI_NODES , \"tree PHI insertion\")\n DEFTIMEVAR (TV_TREE_SSA_REWRITE_BLOCKS, \"tree SSA rewrite\")\n DEFTIMEVAR (TV_TREE_SSA_OTHER\t     , \"tree SSA other\")"}, {"sha": "fe4768df12173ae699d55f529f848ef6b64cfe5a", "filename": "gcc/toplev.c", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftoplev.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftoplev.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftoplev.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -84,6 +84,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-mudflap.h\"\n #include \"tree-pass.h\"\n #include \"gimple.h\"\n+#include \"tree-ssa-alias.h\"\n \n #if defined (DWARF2_UNWIND_INFO) || defined (DWARF2_DEBUGGING_INFO)\n #include \"dwarf2out.h\"\n@@ -2170,6 +2171,8 @@ dump_memory_report (bool final)\n   dump_bitmap_statistics ();\n   dump_vec_loc_statistics ();\n   dump_ggc_loc_statistics (final);\n+  dump_alias_stats (stderr);\n+  dump_pta_stats (stderr);\n }\n \n /* Clean up: close opened files, etc.  */"}, {"sha": "698ec2f483e641094b6cd5678d372f89e14f4fdc", "filename": "gcc/tree-call-cdce.c", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-call-cdce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-call-cdce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-call-cdce.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -906,6 +906,9 @@ tree_call_cdce (void)\n     {\n       free_dominance_info (CDI_DOMINATORS);\n       free_dominance_info (CDI_POST_DOMINATORS);\n+      /* As we introduced new control-flow we need to insert PHI-nodes\n+         for the call-clobbers of the remaining call.  */\n+      mark_sym_for_renaming (gimple_vop (cfun));\n       return (TODO_update_ssa | TODO_cleanup_cfg | TODO_ggc_collect \n               | TODO_remove_unused_locals);\n     }"}, {"sha": "07a46df08ded3fc8b8f92284f0765fada7673b3a", "filename": "gcc/tree-cfg.c", "status": "modified", "additions": 6, "deletions": 23, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-cfg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-cfg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-cfg.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -2879,7 +2879,9 @@ verify_expr (tree *tp, int *walk_subtrees, void *data ATTRIBUTE_UNUSED)\n \t     x = TREE_OPERAND (x, 0))\n \t  ;\n \n-\tif (TREE_CODE (x) != VAR_DECL && TREE_CODE (x) != PARM_DECL)\n+\tif (!(TREE_CODE (x) == VAR_DECL\n+\t      || TREE_CODE (x) == PARM_DECL\n+\t      || TREE_CODE (x) == RESULT_DECL))\n \t  return NULL;\n \tif (!TREE_ADDRESSABLE (x))\n \t  {\n@@ -4969,7 +4971,6 @@ gimple_duplicate_bb (basic_block bb)\n \t operands.  */\n       copy = gimple_copy (stmt);\n       gsi_insert_after (&gsi_tgt, copy, GSI_NEW_STMT);\n-      copy_virtual_operands (copy, stmt);\n       region = lookup_stmt_eh_region (stmt);\n       if (region >= 0)\n \tadd_stmt_to_eh_region (copy, region);\n@@ -5141,7 +5142,7 @@ gimple_duplicate_sese_region (edge entry, edge exit,\n       free_region_copy = true;\n     }\n \n-  gcc_assert (!need_ssa_update_p ());\n+  gcc_assert (!need_ssa_update_p (cfun));\n \n   /* Record blocks outside the region that are dominated by something\n      inside.  */\n@@ -5300,7 +5301,7 @@ gimple_duplicate_sese_tail (edge entry ATTRIBUTE_UNUSED, edge exit ATTRIBUTE_UNU\n       free_region_copy = true;\n     }\n \n-  gcc_assert (!need_ssa_update_p ());\n+  gcc_assert (!need_ssa_update_p (cfun));\n \n   /* Record blocks outside the region that are dominated by something\n      inside.  */\n@@ -5627,19 +5628,6 @@ mark_virtual_ops_in_bb (basic_block bb)\n     mark_virtual_ops_for_renaming (gsi_stmt (gsi));\n }\n \n-/* Marks virtual operands of all statements in basic blocks BBS for\n-   renaming.  */\n-\n-static void\n-mark_virtual_ops_in_region (VEC (basic_block,heap) *bbs)\n-{\n-  basic_block bb;\n-  unsigned i;\n-\n-  for (i = 0; VEC_iterate (basic_block, bbs, i, bb); i++)\n-    mark_virtual_ops_in_bb (bb);\n-}\n-\n /* Move basic block BB from function CFUN to function DEST_FN.  The\n    block is moved out of the original linked list and placed after\n    block AFTER in the new list.  Also, the block is removed from the\n@@ -5746,7 +5734,7 @@ move_block_to_fn (struct function *dest_cfun, basic_block bb,\n \t  old_len = VEC_length (basic_block, cfg->x_label_to_block_map);\n \t  if (old_len <= (unsigned) uid)\n \t    {\n-\t      new_len = 3 * uid / 2;\n+\t      new_len = 3 * uid / 2 + 1;\n \t      VEC_safe_grow_cleared (basic_block, gc,\n \t\t\t\t     cfg->x_label_to_block_map, new_len);\n \t    }\n@@ -6008,11 +5996,6 @@ move_sese_region_to_fn (struct function *dest_cfun, basic_block entry_bb,\n \n   pop_cfun ();\n \n-  /* The ssa form for virtual operands in the source function will have to\n-     be repaired.  We do not care for the real operands -- the sese region\n-     must be closed with respect to those.  */\n-  mark_virtual_ops_in_region (bbs);\n-\n   /* Move blocks from BBS into DEST_CFUN.  */\n   gcc_assert (VEC_length (basic_block, bbs) >= 2);\n   after = dest_cfun->cfg->x_entry_block_ptr;"}, {"sha": "ac7748ed5132cf5d22d8cb29834d5371dfc719a5", "filename": "gcc/tree-complex.c", "status": "modified", "additions": 0, "deletions": 19, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-complex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-complex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-complex.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -745,23 +745,6 @@ update_phi_components (basic_block bb)\n     }\n }\n \n-/* Mark each virtual op in STMT for ssa update.  */\n-\n-static void\n-update_all_vops (gimple stmt)\n-{\n-  ssa_op_iter iter;\n-  tree sym;\n-\n-  FOR_EACH_SSA_TREE_OPERAND (sym, stmt, iter, SSA_OP_ALL_VIRTUALS)\n-    {\n-      if (TREE_CODE (sym) == SSA_NAME)\n-\tsym = SSA_NAME_VAR (sym);\n-      mark_sym_for_renaming (sym);\n-    }\n-}\n-\n-\n /* Expand a complex move to scalars.  */\n \n static void\n@@ -817,7 +800,6 @@ expand_complex_move (gimple_stmt_iterator *gsi, tree type)\n \t}\n       else\n \t{\n-\t  update_all_vops (stmt);\n \t  if (gimple_assign_rhs_code (stmt) != COMPLEX_EXPR)\n \t    {\n \t      r = extract_component (gsi, rhs, 0, true);\n@@ -860,7 +842,6 @@ expand_complex_move (gimple_stmt_iterator *gsi, tree type)\n \t  gimple_return_set_retval (stmt, lhs);\n \t}\n \n-      update_all_vops (stmt);\n       update_stmt (stmt);\n     }\n }"}, {"sha": "305d5e45b309e52c12554225bd1244735d90d0b8", "filename": "gcc/tree-data-ref.c", "status": "modified", "additions": 13, "deletions": 46, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-data-ref.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-data-ref.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-data-ref.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -792,34 +792,15 @@ dr_analyze_indices (struct data_reference *dr, struct loop *nest)\n static void\n dr_analyze_alias (struct data_reference *dr)\n {\n-  gimple stmt = DR_STMT (dr);\n   tree ref = DR_REF (dr);\n-  tree base = get_base_address (ref), addr, smt = NULL_TREE;\n-  ssa_op_iter it;\n-  tree op;\n-  bitmap vops;\n+  tree base = get_base_address (ref), addr;\n \n-  if (DECL_P (base))\n-    smt = base;\n-  else if (INDIRECT_REF_P (base))\n+  if (INDIRECT_REF_P (base))\n     {\n       addr = TREE_OPERAND (base, 0);\n       if (TREE_CODE (addr) == SSA_NAME)\n-\t{\n-\t  smt = symbol_mem_tag (SSA_NAME_VAR (addr));\n-\t  DR_PTR_INFO (dr) = SSA_NAME_PTR_INFO (addr);\n-\t}\n+\tDR_PTR_INFO (dr) = SSA_NAME_PTR_INFO (addr);\n     }\n-\n-  DR_SYMBOL_TAG (dr) = smt;\n-\n-  vops = BITMAP_ALLOC (NULL);\n-  FOR_EACH_SSA_TREE_OPERAND (op, stmt, it, SSA_OP_VIRTUAL_USES)\n-    {\n-      bitmap_set_bit (vops, DECL_UID (SSA_NAME_VAR (op)));\n-    }\n-\n-  DR_VOPS (dr) = vops;\n }\n \n /* Returns true if the address of DR is invariant.  */\n@@ -842,7 +823,6 @@ dr_address_invariant_p (struct data_reference *dr)\n void\n free_data_ref (data_reference_p dr)\n {\n-  BITMAP_FREE (DR_VOPS (dr));\n   VEC_free (tree, heap, DR_ACCESS_FNS (dr));\n   free (dr);\n }\n@@ -887,8 +867,6 @@ create_data_ref (struct loop *nest, tree memref, gimple stmt, bool is_read)\n       print_generic_expr (dump_file, DR_ALIGNED_TO (dr), TDF_SLIM);\n       fprintf (dump_file, \"\\n\\tbase_object: \");\n       print_generic_expr (dump_file, DR_BASE_OBJECT (dr), TDF_SLIM);\n-      fprintf (dump_file, \"\\n\\tsymbol tag: \");\n-      print_generic_expr (dump_file, DR_SYMBOL_TAG (dr), TDF_SLIM);\n       fprintf (dump_file, \"\\n\");\n     }\n \n@@ -1238,23 +1216,21 @@ dr_may_alias_p (const struct data_reference *a, const struct data_reference *b)\n   const_tree type_a, type_b;\n   const_tree decl_a = NULL_TREE, decl_b = NULL_TREE;\n \n-  /* If the sets of virtual operands are disjoint, the memory references do not\n-     alias.  */\n-  if (!bitmap_intersect_p (DR_VOPS (a), DR_VOPS (b)))\n-    return false;\n-\n   /* If the accessed objects are disjoint, the memory references do not\n      alias.  */\n   if (disjoint_objects_p (DR_BASE_OBJECT (a), DR_BASE_OBJECT (b)))\n     return false;\n \n+  /* Query the alias oracle.  */\n+  if (!refs_may_alias_p (DR_REF (a), DR_REF (b)))\n+    return false;\n+\n   if (!addr_a || !addr_b)\n     return true;\n \n-  /* If the references are based on different static objects, they cannot alias\n-     (PTA should be able to disambiguate such accesses, but often it fails to,\n-     since currently we cannot distinguish between pointer and offset in pointer\n-     arithmetics).  */\n+  /* If the references are based on different static objects, they cannot\n+     alias (PTA should be able to disambiguate such accesses, but often\n+     it fails to).  */\n   if (TREE_CODE (addr_a) == ADDR_EXPR\n       && TREE_CODE (addr_b) == ADDR_EXPR)\n     return TREE_OPERAND (addr_a, 0) == TREE_OPERAND (addr_b, 0);\n@@ -4050,7 +4026,7 @@ get_references_in_stmt (gimple stmt, VEC (data_ref_loc, heap) **references)\n \t  && gimple_asm_volatile_p (stmt)))\n     clobbers_memory = true;\n \n-  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS))\n+  if (!gimple_vuse (stmt))\n     return clobbers_memory;\n \n   if (stmt_code == GIMPLE_ASSIGN)\n@@ -4358,7 +4334,6 @@ analyze_all_data_dependences (struct loop *loop)\n \t{\n \t  unsigned nb_top_relations = 0;\n \t  unsigned nb_bot_relations = 0;\n-\t  unsigned nb_basename_differ = 0;\n \t  unsigned nb_chrec_relations = 0;\n \t  struct data_dependence_relation *ddr;\n \n@@ -4368,15 +4343,7 @@ analyze_all_data_dependences (struct loop *loop)\n \t\tnb_top_relations++;\n \t  \n \t      else if (DDR_ARE_DEPENDENT (ddr) == chrec_known)\n-\t\t{\n-\t\t  struct data_reference *a = DDR_A (ddr);\n-\t\t  struct data_reference *b = DDR_B (ddr);\n-\n-\t\t  if (!bitmap_intersect_p (DR_VOPS (a), DR_VOPS (b)))\n-\t\t    nb_basename_differ++;\n-\t\t  else\n-\t\t    nb_bot_relations++;\n-\t\t}\n+\t\tnb_bot_relations++;\n \t  \n \t      else \n \t\tnb_chrec_relations++;\n@@ -4939,7 +4906,7 @@ stores_from_loop (struct loop *loop, VEC (gimple, heap) **stmts)\n       gimple_stmt_iterator bsi;\n \n       for (bsi = gsi_start_bb (bb); !gsi_end_p (bsi); gsi_next (&bsi))\n-\tif (!ZERO_SSA_OPERANDS (gsi_stmt (bsi), SSA_OP_VDEF))\n+\tif (gimple_vdef (gsi_stmt (bsi)))\n \t  VEC_safe_push (gimple, heap, *stmts, gsi_stmt (bsi));\n     }\n "}, {"sha": "690301a6f94a9d8a6a1eca9cf8c17bbb0917acef", "filename": "gcc/tree-data-ref.h", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-data-ref.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-data-ref.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-data-ref.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -88,7 +88,6 @@ struct dr_alias\n {\n   /* The alias information that should be used for new pointers to this\n      location.  SYMBOL_TAG is either a DECL or a SYMBOL_MEMORY_TAG.  */\n-  tree symbol_tag;\n   struct ptr_info_def *ptr_info;\n \n   /* The set of virtual operands corresponding to this memory reference,\n@@ -204,9 +203,7 @@ struct data_reference\n #define DR_OFFSET(DR)              (DR)->innermost.offset\n #define DR_INIT(DR)                (DR)->innermost.init\n #define DR_STEP(DR)                (DR)->innermost.step\n-#define DR_SYMBOL_TAG(DR)          (DR)->alias.symbol_tag\n #define DR_PTR_INFO(DR)            (DR)->alias.ptr_info\n-#define DR_VOPS(DR)\t\t   (DR)->alias.vops\n #define DR_ALIGNED_TO(DR)          (DR)->innermost.aligned_to\n #define DR_ACCESS_MATRIX(DR)       (DR)->access_matrix\n "}, {"sha": "d50b7ddb362eb3fc694de299933d3d7bca540d50", "filename": "gcc/tree-dfa.c", "status": "modified", "additions": 12, "deletions": 322, "changes": 334, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-dfa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-dfa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dfa.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -254,8 +254,9 @@ dump_referenced_vars (FILE *file)\n     {\n       fprintf (file, \"Variable: \");\n       dump_variable (file, var);\n-      fprintf (file, \"\\n\");\n     }\n+\n+  fprintf (file, \"\\n\");\n }\n \n \n@@ -297,12 +298,6 @@ dump_variable (FILE *file, tree var)\n   fprintf (file, \", \");\n   print_generic_expr (file, TREE_TYPE (var), dump_flags);\n \n-  if (ann && ann->symbol_mem_tag)\n-    {\n-      fprintf (file, \", symbol memory tag: \");\n-      print_generic_expr (file, ann->symbol_mem_tag, dump_flags);\n-    }\n-\n   if (TREE_ADDRESSABLE (var))\n     fprintf (file, \", is addressable\");\n   \n@@ -312,36 +307,10 @@ dump_variable (FILE *file, tree var)\n   if (TREE_THIS_VOLATILE (var))\n     fprintf (file, \", is volatile\");\n \n-  dump_mem_sym_stats_for_var (file, var);\n-\n   if (is_call_clobbered (var))\n-    {\n-      const char *s = \"\";\n-      var_ann_t va = var_ann (var);\n-      unsigned int escape_mask = va->escape_mask;\n-\n-      fprintf (file, \", call clobbered\");\n-      fprintf (file, \" (\");\n-      if (escape_mask & ESCAPE_STORED_IN_GLOBAL)\n-\t{ fprintf (file, \"%sstored in global\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_TO_ASM)\n-\t{ fprintf (file, \"%sgoes through ASM\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_TO_CALL)\n-\t{ fprintf (file, \"%spassed to call\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_BAD_CAST)\n-\t{ fprintf (file, \"%sbad cast\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_TO_RETURN)\n-\t{ fprintf (file, \"%sreturned from func\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_TO_PURE_CONST)\n-\t{ fprintf (file, \"%spassed to pure/const\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_IS_GLOBAL)\n-\t{ fprintf (file, \"%sis global var\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_IS_PARM)\n-\t{ fprintf (file, \"%sis incoming pointer\", s); s = \", \"; }\n-      if (escape_mask & ESCAPE_UNKNOWN)\n-\t{ fprintf (file, \"%sunknown escape\", s); s = \", \"; }\n-      fprintf (file, \")\");\n-    }\n+    fprintf (file, \", call clobbered\");\n+  else if (is_call_used (var))\n+    fprintf (file, \", call used\");\n \n   if (ann->noalias_state == NO_ALIAS)\n     fprintf (file, \", NO_ALIAS (does not alias other NO_ALIAS symbols)\");\n@@ -357,27 +326,6 @@ dump_variable (FILE *file, tree var)\n       print_generic_expr (file, gimple_default_def (cfun, var), dump_flags);\n     }\n \n-  if (MTAG_P (var) && may_aliases (var))\n-    {\n-      fprintf (file, \", may aliases: \");\n-      dump_may_aliases_for (file, var);\n-    }\n-\n-  if (!is_gimple_reg (var))\n-    {\n-      if (memory_partition (var))\n-\t{\n-\t  fprintf (file, \", belongs to partition: \");\n-\t  print_generic_expr (file, memory_partition (var), dump_flags);\n-\t}\n-\n-      if (TREE_CODE (var) == MEMORY_PARTITION_TAG)\n-\t{\n-\t  fprintf (file, \", partition symbols: \");\n-\t  dump_decl_set (file, MPT_SYMBOLS (var));\n-\t}\n-    }\n-\n   fprintf (file, \"\\n\");\n }\n \n@@ -516,8 +464,8 @@ collect_dfa_stats (struct dfa_stats_d *dfa_stats_p ATTRIBUTE_UNUSED)\n \t  gimple stmt = gsi_stmt (si);\n \t  dfa_stats_p->num_defs += NUM_SSA_OPERANDS (stmt, SSA_OP_DEF);\n \t  dfa_stats_p->num_uses += NUM_SSA_OPERANDS (stmt, SSA_OP_USE);\n-\t  dfa_stats_p->num_vdefs += NUM_SSA_OPERANDS (stmt, SSA_OP_VDEF);\n-\t  dfa_stats_p->num_vuses += NUM_SSA_OPERANDS (stmt, SSA_OP_VUSE);\n+\t  dfa_stats_p->num_vdefs += gimple_vdef (stmt) ? 1 : 0;\n+\t  dfa_stats_p->num_vuses += gimple_vuse (stmt) ? 1 : 0;\n \t}\n     }\n }\n@@ -650,13 +598,6 @@ add_referenced_var (tree var)\n   /* Insert VAR into the referenced_vars has table if it isn't present.  */\n   if (referenced_var_check_and_insert (var))\n     {\n-      /* This is the first time we found this variable, annotate it with\n-\t attributes that are intrinsic to the variable.  */\n-      \n-      /* Tag's don't have DECL_INITIAL.  */\n-      if (MTAG_P (var))\n-\treturn true;\n-\n       /* Scan DECL_INITIAL for pointer variables as they may contain\n \t address arithmetic referencing the address of other\n \t variables.  \n@@ -684,22 +625,12 @@ remove_referenced_var (tree var)\n   void **loc;\n   unsigned int uid = DECL_UID (var);\n \n-  clear_call_clobbered (var);\n-  bitmap_clear_bit (gimple_call_used_vars (cfun), uid);\n-  if ((v_ann = var_ann (var)))\n+  /* Preserve var_anns of globals.  */\n+  if (!is_global_var (var)\n+      && (v_ann = var_ann (var)))\n     {\n-      /* Preserve var_anns of globals, but clear their alias info.  */\n-      if (MTAG_P (var)\n-\t  || (!TREE_STATIC (var) && !DECL_EXTERNAL (var)))\n-\t{\n-\t  ggc_free (v_ann);\n-\t  var->base.ann = NULL;\n-\t}\n-      else\n-\t{\n-\t  v_ann->mpt = NULL_TREE;\n-\t  v_ann->symbol_mem_tag = NULL_TREE;\n-\t}\n+      ggc_free (v_ann);\n+      var->base.ann = NULL;\n     }\n   gcc_assert (DECL_P (var));\n   in.uid = uid;\n@@ -803,8 +734,6 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n   bool seen_variable_array_ref = false;\n   bool seen_union = false;\n \n-  gcc_assert (!SSA_VAR_P (exp));\n-\n   /* First get the final access size from just the outermost expression.  */\n   if (TREE_CODE (exp) == COMPONENT_REF)\n     size_tree = DECL_SIZE (TREE_OPERAND (exp, 1));\n@@ -984,242 +913,3 @@ stmt_references_abnormal_ssa_name (gimple stmt)\n   return false;\n }\n \n-/* Return true, if the two memory references REF1 and REF2 may alias.  */\n-\n-bool\n-refs_may_alias_p (tree ref1, tree ref2)\n-{\n-  tree base1, base2;\n-  HOST_WIDE_INT offset1 = 0, offset2 = 0;\n-  HOST_WIDE_INT size1 = -1, size2 = -1;\n-  HOST_WIDE_INT max_size1 = -1, max_size2 = -1;\n-  bool strict_aliasing_applies;\n-\n-  gcc_assert ((SSA_VAR_P (ref1)\n-\t       || handled_component_p (ref1)\n-\t       || INDIRECT_REF_P (ref1)\n-\t       || TREE_CODE (ref1) == TARGET_MEM_REF)\n-\t      && (SSA_VAR_P (ref2)\n-\t\t  || handled_component_p (ref2)\n-\t\t  || INDIRECT_REF_P (ref2)\n-\t\t  || TREE_CODE (ref2) == TARGET_MEM_REF));\n-\n-  /* Defer to TBAA if possible.  */\n-  if (flag_strict_aliasing\n-      && !alias_sets_conflict_p (get_alias_set (ref1), get_alias_set (ref2)))\n-    return false;\n-\n-  /* Decompose the references into their base objects and the access.  */\n-  base1 = ref1;\n-  if (handled_component_p (ref1))\n-    base1 = get_ref_base_and_extent (ref1, &offset1, &size1, &max_size1);\n-  base2 = ref2;\n-  if (handled_component_p (ref2))\n-    base2 = get_ref_base_and_extent (ref2, &offset2, &size2, &max_size2);\n-\n-  /* If both references are based on different variables, they cannot alias.\n-     If both references are based on the same variable, they cannot alias if\n-     the accesses do not overlap.  */\n-  if (SSA_VAR_P (base1)\n-      && SSA_VAR_P (base2))\n-    {\n-      if (!operand_equal_p (base1, base2, 0))\n-\treturn false;\n-      return ranges_overlap_p (offset1, max_size1, offset2, max_size2);\n-    }\n-\n-  /* If one base is a ref-all pointer weird things are allowed.  */\n-  strict_aliasing_applies = (flag_strict_aliasing\n-\t\t\t     && (!INDIRECT_REF_P (base1)\n-\t\t\t\t || get_alias_set (base1) != 0)\n-\t\t\t     && (!INDIRECT_REF_P (base2)\n-\t\t\t\t || get_alias_set (base2) != 0));\n-\n-  /* If strict aliasing applies the only way to access a scalar variable\n-     is through a pointer dereference or through a union (gcc extension).  */\n-  if (strict_aliasing_applies\n-      && ((SSA_VAR_P (ref2)\n-\t   && !AGGREGATE_TYPE_P (TREE_TYPE (ref2))\n-\t   && !INDIRECT_REF_P (ref1)\n-\t   && TREE_CODE (TREE_TYPE (base1)) != UNION_TYPE)\n-\t  || (SSA_VAR_P (ref1)\n-\t      && !AGGREGATE_TYPE_P (TREE_TYPE (ref1))\n-\t      && !INDIRECT_REF_P (ref2)\n-\t      && TREE_CODE (TREE_TYPE (base2)) != UNION_TYPE)))\n-    return false;\n-\n-  /* If both references are through the same type, or if strict aliasing\n-     doesn't apply they are through two same pointers, they do not alias\n-     if the accesses do not overlap.  */\n-  if ((strict_aliasing_applies\n-       && (TYPE_MAIN_VARIANT (TREE_TYPE (base1))\n-\t   == TYPE_MAIN_VARIANT (TREE_TYPE (base2))))\n-      || (TREE_CODE (base1) == INDIRECT_REF\n-\t  && TREE_CODE (base2) == INDIRECT_REF\n-\t  && operand_equal_p (TREE_OPERAND (base1, 0),\n-\t\t\t      TREE_OPERAND (base2, 0), 0)))\n-    return ranges_overlap_p (offset1, max_size1, offset2, max_size2);\n-\n-  /* If both are component references through pointers try to find a\n-     common base and apply offset based disambiguation.  This handles\n-     for example\n-       struct A { int i; int j; } *q;\n-       struct B { struct A a; int k; } *p;\n-     disambiguating q->i and p->a.j.  */\n-  if (strict_aliasing_applies\n-      && (TREE_CODE (base1) == INDIRECT_REF\n-\t  || TREE_CODE (base2) == INDIRECT_REF)\n-      && handled_component_p (ref1)\n-      && handled_component_p (ref2))\n-    {\n-      tree *refp;\n-      /* Now search for the type of base1 in the access path of ref2.  This\n-\t would be a common base for doing offset based disambiguation on.  */\n-      refp = &ref2;\n-      while (handled_component_p (*refp)\n-\t     /* Note that the following is only conservative if there are\n-\t\tnever copies of types appearing as sub-structures.  */\n-\t     && (TYPE_MAIN_VARIANT (TREE_TYPE (*refp))\n-\t\t != TYPE_MAIN_VARIANT (TREE_TYPE (base1))))\n-\trefp = &TREE_OPERAND (*refp, 0);\n-      if (TYPE_MAIN_VARIANT (TREE_TYPE (*refp))\n-\t  == TYPE_MAIN_VARIANT (TREE_TYPE (base1)))\n-\t{\n-\t  HOST_WIDE_INT offadj, sztmp, msztmp;\n-\t  get_ref_base_and_extent (*refp, &offadj, &sztmp, &msztmp);\n-\t  offset2 -= offadj;\n-\t  return ranges_overlap_p (offset1, max_size1, offset2, max_size2);\n-\t}\n-      /* The other way around.  */\n-      refp = &ref1;\n-      while (handled_component_p (*refp)\n-\t     && (TYPE_MAIN_VARIANT (TREE_TYPE (*refp))\n-\t\t != TYPE_MAIN_VARIANT (TREE_TYPE (base2))))\n-\trefp = &TREE_OPERAND (*refp, 0);\n-      if (TYPE_MAIN_VARIANT (TREE_TYPE (*refp))\n-\t  == TYPE_MAIN_VARIANT (TREE_TYPE (base2)))\n-\t{\n-\t  HOST_WIDE_INT offadj, sztmp, msztmp;\n-\t  get_ref_base_and_extent (*refp, &offadj, &sztmp, &msztmp);\n-\t  offset1 -= offadj;\n-\t  return ranges_overlap_p (offset1, max_size1, offset2, max_size2);\n-\t}\n-      /* If we can be sure to catch all equivalent types in the search\n-\t for the common base then we could return false here.  In that\n-\t case we would be able to disambiguate q->i and p->k.  */\n-    }\n-\n-  return true;\n-}\n-\n-/* Given a stmt STMT that references memory, return the single stmt\n-   that is reached by following the VUSE -> VDEF link.  Returns\n-   NULL_TREE, if there is no single stmt that defines all VUSEs of\n-   STMT.\n-   Note that for a stmt with a single virtual operand this may return\n-   a PHI node as well.  Note that if all VUSEs are default definitions\n-   this function will return an empty statement.  */\n-\n-gimple\n-get_single_def_stmt (gimple stmt)\n-{\n-  gimple def_stmt = NULL;\n-  tree use;\n-  ssa_op_iter iter;\n-\n-  FOR_EACH_SSA_TREE_OPERAND (use, stmt, iter, SSA_OP_VIRTUAL_USES)\n-    {\n-      gimple tmp = SSA_NAME_DEF_STMT (use);\n-\n-      /* ???  This is too simplistic for multiple virtual operands\n-\t reaching different PHI nodes of the same basic blocks or for\n-\t reaching all default definitions.  */\n-      if (def_stmt\n-\t  && def_stmt != tmp\n-\t  && !(gimple_nop_p (def_stmt)\n-\t       && gimple_nop_p (tmp)))\n-\treturn NULL;\n-\n-      def_stmt = tmp;\n-    }\n-\n-  return def_stmt;\n-}\n-\n-/* Given a PHI node of virtual operands, tries to eliminate cyclic\n-   reached definitions if they do not alias REF and returns the\n-   defining statement of the single virtual operand that flows in\n-   from a non-backedge.  Returns NULL_TREE if such statement within\n-   the above conditions cannot be found.  */\n-\n-gimple\n-get_single_def_stmt_from_phi (tree ref, gimple phi)\n-{\n-  tree def_arg = NULL_TREE;\n-  unsigned i;\n-\n-  /* Find the single PHI argument that is not flowing in from a\n-     back edge and verify that the loop-carried definitions do\n-     not alias the reference we look for.  */\n-  for (i = 0; i < gimple_phi_num_args (phi); ++i)\n-    {\n-      tree arg = PHI_ARG_DEF (phi, i);\n-      gimple def_stmt;\n-\n-      if (!(gimple_phi_arg_edge (phi, i)->flags & EDGE_DFS_BACK))\n-\t{\n-\t  /* Multiple non-back edges?  Do not try to handle this.  */\n-\t  if (def_arg)\n-\t    return NULL;\n-\t  def_arg = arg;\n-\t  continue;\n-\t}\n-\n-      /* Follow the definitions back to the original PHI node.  Bail\n-\t out once a definition is found that may alias REF.  */\n-      def_stmt = SSA_NAME_DEF_STMT (arg);\n-      do\n-\t{\n-\t  if (!is_gimple_assign (def_stmt)\n-\t      || refs_may_alias_p (ref, gimple_assign_lhs (def_stmt)))\n-\t    return NULL;\n-\t  /* ???  This will only work, reaching the PHI node again if\n-\t     there is a single virtual operand on def_stmt.  */\n-\t  def_stmt = get_single_def_stmt (def_stmt);\n-\t  if (!def_stmt)\n-\t    return NULL;\n-\t}\n-      while (def_stmt != phi);\n-    }\n-\n-  return SSA_NAME_DEF_STMT (def_arg);\n-}\n-\n-/* Return the single reference statement defining all virtual uses\n-   on STMT or NULL_TREE, if there are multiple defining statements.\n-   Take into account only definitions that alias REF if following\n-   back-edges when looking through a loop PHI node.  */\n-\n-gimple\n-get_single_def_stmt_with_phi (tree ref, gimple stmt)\n-{\n-  switch (NUM_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_USES))\n-    {\n-    case 0:\n-      gcc_unreachable ();\n-\n-    case 1:\n-      {\n-\tgimple def_stmt = SSA_NAME_DEF_STMT (SINGLE_SSA_TREE_OPERAND\n-\t\t\t\t\t     (stmt, SSA_OP_VIRTUAL_USES));\n-\t/* We can handle lookups over PHI nodes only for a single\n-\t   virtual operand.  */\n-\tif (gimple_code (def_stmt) == GIMPLE_PHI)\n-\t  return get_single_def_stmt_from_phi (ref, def_stmt);\n-\treturn def_stmt;\n-      }\n-\n-    default:\n-      return get_single_def_stmt (stmt);\n-    }\n-}"}, {"sha": "c4a643e3d4aa144a779e89920a3dd29fbe3b3ab2", "filename": "gcc/tree-dump.c", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-dump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-dump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dump.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -510,10 +510,6 @@ dequeue_and_dump (dump_info_p di)\n     case CONST_DECL:\n       dump_child (\"cnst\", DECL_INITIAL (t));\n       break;\n-      \n-    case SYMBOL_MEMORY_TAG:\n-    case NAME_MEMORY_TAG:\n-      break;\n \n     case VAR_DECL:\n     case PARM_DECL:"}, {"sha": "c39017be0c93e682788e87c3ec7bfd93e749eecf", "filename": "gcc/tree-eh.c", "status": "modified", "additions": 24, "deletions": 1, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-eh.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-eh.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-eh.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -2824,8 +2824,29 @@ cleanup_empty_eh (basic_block bb)\n          similar updating as jump threading does.  */\n \n       for (si = gsi_start_phis (bb); !gsi_end_p (si); gsi_next (&si))\n-\tmark_sym_for_renaming (SSA_NAME_VAR (PHI_RESULT (gsi_stmt (si))));\n+\t{\n+\t  tree res = PHI_RESULT (gsi_stmt (si));\n+\t  gimple stmt;\n+\t  imm_use_iterator iter;\n+\t  use_operand_p use_p;\n+\n+\t  /* As we are going to delete this block we will release all\n+\t     defs which makes the immediate uses on use stmts invalid.\n+\t     Avoid that by replacing all uses with the bare variable\n+\t     and updating the stmts.  */\n+\t  FOR_EACH_IMM_USE_STMT (stmt, iter, res)\n+\t    {\n+\t      FOR_EACH_IMM_USE_ON_STMT (use_p, iter)\n+\t\tSET_USE (use_p, SSA_NAME_VAR (res));\n+\t      update_stmt (stmt);\n+\t    }\n+\t  mark_sym_for_renaming (SSA_NAME_VAR (res));\n+\t}\n \n+      /* We want to thread over the current receiver to the next reachable\n+         one.  Do so by deleting all outgoing EH edges from all\n+\t predecessors of the receiver block we are going to delete and\n+\t rebuild EH edges for them.  */\n       while ((e = ei_safe_edge (ei_start (bb->preds))))\n \t{\n \t  basic_block src = e->src;\n@@ -2843,6 +2864,8 @@ cleanup_empty_eh (basic_block bb)\n \t  if (!stmt_can_throw_internal (last_stmt (src)))\n \t    continue;\n \t  make_eh_edges (last_stmt (src));\n+\t  /* Make sure to also rename symbols that feed into receivers\n+\t     that are now newly reachable from current src.  */\n \t  FOR_EACH_EDGE (e, ei, src->succs)\n \t    if (e->flags & EDGE_EH)\n \t      {"}, {"sha": "7de8db8d321532992fef55184986e4c154b8b1e9", "filename": "gcc/tree-flow-inline.h", "status": "modified", "additions": 63, "deletions": 332, "changes": 395, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-flow-inline.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-flow-inline.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow-inline.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -35,46 +35,6 @@ gimple_in_ssa_p (const struct function *fun)\n   return fun && fun->gimple_df && fun->gimple_df->in_ssa_p;\n }\n \n-/* 'true' after aliases have been computed (see compute_may_aliases).  */\n-static inline bool\n-gimple_aliases_computed_p (const struct function *fun)\n-{\n-  gcc_assert (fun && fun->gimple_df);\n-  return fun->gimple_df->aliases_computed_p;\n-}\n-\n-/* Addressable variables in the function.  If bit I is set, then\n-   REFERENCED_VARS (I) has had its address taken.  Note that\n-   CALL_CLOBBERED_VARS and ADDRESSABLE_VARS are not related.  An\n-   addressable variable is not necessarily call-clobbered (e.g., a\n-   local addressable whose address does not escape) and not all\n-   call-clobbered variables are addressable (e.g., a local static\n-   variable).  */\n-static inline bitmap\n-gimple_addressable_vars (const struct function *fun)\n-{\n-  gcc_assert (fun && fun->gimple_df);\n-  return fun->gimple_df->addressable_vars;\n-}\n-\n-/* Call clobbered variables in the function.  If bit I is set, then\n-   REFERENCED_VARS (I) is call-clobbered.  */\n-static inline bitmap\n-gimple_call_clobbered_vars (const struct function *fun)\n-{\n-  gcc_assert (fun && fun->gimple_df);\n-  return fun->gimple_df->call_clobbered_vars;\n-}\n-\n-/* Call-used variables in the function.  If bit I is set, then\n-   REFERENCED_VARS (I) is call-used at pure function call-sites.  */\n-static inline bitmap\n-gimple_call_used_vars (const struct function *fun)\n-{\n-  gcc_assert (fun && fun->gimple_df);\n-  return fun->gimple_df->call_used_vars;\n-}\n-\n /* Array of all variables referenced in the function.  */\n static inline htab_t\n gimple_referenced_vars (const struct function *fun)\n@@ -84,21 +44,21 @@ gimple_referenced_vars (const struct function *fun)\n   return fun->gimple_df->referenced_vars;\n }\n \n-/* Artificial variable used to model the effects of function calls.  */\n+/* Artificial variable used to model the effects of nonlocal\n+   variables.  */\n static inline tree\n-gimple_global_var (const struct function *fun)\n+gimple_nonlocal_all (const struct function *fun)\n {\n   gcc_assert (fun && fun->gimple_df);\n-  return fun->gimple_df->global_var;\n+  return fun->gimple_df->nonlocal_all;\n }\n \n-/* Artificial variable used to model the effects of nonlocal\n-   variables.  */\n+/* Artificial variable used for the virtual operand FUD chain.  */\n static inline tree\n-gimple_nonlocal_all (const struct function *fun)\n+gimple_vop (const struct function *fun)\n {\n   gcc_assert (fun && fun->gimple_df);\n-  return fun->gimple_df->nonlocal_all;\n+  return fun->gimple_df->vop;\n }\n \n /* Initialize the hashtable iterator HTI to point to hashtable TABLE */\n@@ -263,14 +223,6 @@ ann_type (tree_ann_t ann)\n   return ann->common.type;\n }\n \n-/* Return the may_aliases bitmap for variable VAR, or NULL if it has\n-   no may aliases.  */\n-static inline bitmap\n-may_aliases (const_tree var)\n-{\n-  return MTAG_ALIASES (var);\n-}\n-\n /* Return the line number for EXPR, or return -1 if we have no line\n    number information for it.  */\n static inline int\n@@ -592,17 +544,27 @@ set_is_used (tree var)\n }\n \n \n-/* Return true if T (assumed to be a DECL) is a global variable.  */\n+/* Return true if T (assumed to be a DECL) is a global variable.\n+   A variable is considered global if its storage is not automatic.  */\n \n static inline bool\n is_global_var (const_tree t)\n {\n-  if (MTAG_P (t))\n-    return MTAG_GLOBAL (t);\n-  else\n-    return (TREE_STATIC (t) || DECL_EXTERNAL (t));\n+  return (TREE_STATIC (t) || DECL_EXTERNAL (t));\n+}\n+\n+\n+/* Return true if VAR may be aliased.  A variable is considered as\n+   maybe aliased if it has its address taken by the local TU\n+   or possibly by another TU.  */\n+\n+static inline bool\n+may_be_aliased (const_tree var)\n+{\n+  return (TREE_PUBLIC (var) || DECL_EXTERNAL (var) || TREE_ADDRESSABLE (var));\n }\n \n+\n /* PHI nodes should contain only ssa_names and invariants.  A test\n    for ssa_name is definitely simpler; don't let invalid contents\n    slip in in the meantime.  */\n@@ -632,77 +594,22 @@ loop_containing_stmt (gimple stmt)\n }\n \n \n-/* Return the memory partition tag associated with symbol SYM.  */\n-\n-static inline tree\n-memory_partition (tree sym)\n-{\n-  tree tag;\n-\n-  /* MPTs belong to their own partition.  */\n-  if (TREE_CODE (sym) == MEMORY_PARTITION_TAG)\n-    return sym;\n-\n-  gcc_assert (!is_gimple_reg (sym));\n-  /* Autoparallelization moves statements from the original function (which has\n-     aliases computed) to the new one (which does not).  When rebuilding\n-     operands for the statement in the new function, we do not want to\n-     record the memory partition tags of the original function.  */\n-  if (!gimple_aliases_computed_p (cfun))\n-    return NULL_TREE;\n-  tag = get_var_ann (sym)->mpt;\n-\n-#if defined ENABLE_CHECKING\n-  if (tag)\n-    gcc_assert (TREE_CODE (tag) == MEMORY_PARTITION_TAG);\n-#endif\n-\n-  return tag;\n-}\n-\n-/* Return true if NAME is a memory factoring SSA name (i.e., an SSA\n-   name for a memory partition.  */\n-\n+/* Return true if VAR is clobbered by function calls.  */\n static inline bool\n-factoring_name_p (const_tree name)\n+is_call_clobbered (const_tree var)\n {\n-  return TREE_CODE (SSA_NAME_VAR (name)) == MEMORY_PARTITION_TAG;\n+  return (is_global_var (var)\n+\t  || (may_be_aliased (var)\n+\t      && pt_solution_includes (&cfun->gimple_df->escaped, var)));\n }\n \n /* Return true if VAR is used by function calls.  */\n static inline bool\n is_call_used (const_tree var)\n {\n-  return (var_ann (var)->call_clobbered\n-\t  || bitmap_bit_p (gimple_call_used_vars (cfun), DECL_UID (var)));\n-}\n-\n-/* Return true if VAR is clobbered by function calls.  */\n-static inline bool\n-is_call_clobbered (const_tree var)\n-{\n-  return var_ann (var)->call_clobbered;\n-}\n-\n-/* Mark variable VAR as being clobbered by function calls.  */\n-static inline void\n-mark_call_clobbered (tree var, unsigned int escape_type)\n-{\n-  var_ann (var)->escape_mask |= escape_type;\n-  var_ann (var)->call_clobbered = true;\n-  bitmap_set_bit (gimple_call_clobbered_vars (cfun), DECL_UID (var));\n-}\n-\n-/* Clear the call-clobbered attribute from variable VAR.  */\n-static inline void\n-clear_call_clobbered (tree var)\n-{\n-  var_ann_t ann = var_ann (var);\n-  ann->escape_mask = 0;\n-  if (MTAG_P (var))\n-    MTAG_GLOBAL (var) = 0;\n-  var_ann (var)->call_clobbered = false;\n-  bitmap_clear_bit (gimple_call_clobbered_vars (cfun), DECL_UID (var));\n+  return (is_call_clobbered (var)\n+\t  || (may_be_aliased (var)\n+\t      && pt_solution_includes (&cfun->gimple_df->callused, var)));\n }\n \n /* Return the common annotation for T.  Return NULL if the annotation\n@@ -751,26 +658,6 @@ op_iter_next_use (ssa_op_iter *ptr)\n       ptr->uses = ptr->uses->next;\n       return use_p;\n     }\n-  if (ptr->vuses)\n-    {\n-      use_p = VUSE_OP_PTR (ptr->vuses, ptr->vuse_index);\n-      if (++(ptr->vuse_index) >= VUSE_NUM (ptr->vuses))\n-        {\n-\t  ptr->vuse_index = 0;\n-\t  ptr->vuses = ptr->vuses->next;\n-\t}\n-      return use_p;\n-    }\n-  if (ptr->mayuses)\n-    {\n-      use_p = VDEF_OP_PTR (ptr->mayuses, ptr->mayuse_index);\n-      if (++(ptr->mayuse_index) >= VDEF_NUM (ptr->mayuses))\n-        {\n-\t  ptr->mayuse_index = 0;\n-\t  ptr->mayuses = ptr->mayuses->next;\n-\t}\n-      return use_p;\n-    }\n   if (ptr->phi_i < ptr->num_phi)\n     {\n       return PHI_ARG_DEF_PTR (ptr->phi_stmt, (ptr->phi_i)++);\n@@ -793,12 +680,6 @@ op_iter_next_def (ssa_op_iter *ptr)\n       ptr->defs = ptr->defs->next;\n       return def_p;\n     }\n-  if (ptr->vdefs)\n-    {\n-      def_p = VDEF_RESULT_PTR (ptr->vdefs);\n-      ptr->vdefs = ptr->vdefs->next;\n-      return def_p;\n-    }\n   ptr->done = true;\n   return NULL_DEF_OPERAND_P;\n }\n@@ -817,38 +698,12 @@ op_iter_next_tree (ssa_op_iter *ptr)\n       ptr->uses = ptr->uses->next;\n       return val;\n     }\n-  if (ptr->vuses)\n-    {\n-      val = VUSE_OP (ptr->vuses, ptr->vuse_index);\n-      if (++(ptr->vuse_index) >= VUSE_NUM (ptr->vuses))\n-        {\n-\t  ptr->vuse_index = 0;\n-\t  ptr->vuses = ptr->vuses->next;\n-\t}\n-      return val;\n-    }\n-  if (ptr->mayuses)\n-    {\n-      val = VDEF_OP (ptr->mayuses, ptr->mayuse_index);\n-      if (++(ptr->mayuse_index) >= VDEF_NUM (ptr->mayuses))\n-        {\n-\t  ptr->mayuse_index = 0;\n-\t  ptr->mayuses = ptr->mayuses->next;\n-\t}\n-      return val;\n-    }\n   if (ptr->defs)\n     {\n       val = DEF_OP (ptr->defs);\n       ptr->defs = ptr->defs->next;\n       return val;\n     }\n-  if (ptr->vdefs)\n-    {\n-      val = VDEF_RESULT (ptr->vdefs);\n-      ptr->vdefs = ptr->vdefs->next;\n-      return val;\n-    }\n \n   ptr->done = true;\n   return NULL_TREE;\n@@ -865,42 +720,45 @@ clear_and_done_ssa_iter (ssa_op_iter *ptr)\n {\n   ptr->defs = NULL;\n   ptr->uses = NULL;\n-  ptr->vuses = NULL;\n-  ptr->vdefs = NULL;\n-  ptr->mayuses = NULL;\n   ptr->iter_type = ssa_op_iter_none;\n   ptr->phi_i = 0;\n   ptr->num_phi = 0;\n   ptr->phi_stmt = NULL;\n   ptr->done = true;\n-  ptr->vuse_index = 0;\n-  ptr->mayuse_index = 0;\n }\n \n /* Initialize the iterator PTR to the virtual defs in STMT.  */\n static inline void\n op_iter_init (ssa_op_iter *ptr, gimple stmt, int flags)\n {\n-  ptr->defs = (flags & SSA_OP_DEF) ? gimple_def_ops (stmt) : NULL;\n-  ptr->uses = (flags & SSA_OP_USE) ? gimple_use_ops (stmt) : NULL;\n-  ptr->vuses = (flags & SSA_OP_VUSE) ? gimple_vuse_ops (stmt) : NULL;\n-  ptr->vdefs = (flags & SSA_OP_VDEF) ? gimple_vdef_ops (stmt) : NULL;\n-  ptr->mayuses = (flags & SSA_OP_VMAYUSE) ? gimple_vdef_ops (stmt) : NULL;\n+  /* We do not support iterating over virtual defs or uses without\n+     iterating over defs or uses at the same time.  */\n+  gcc_assert ((!(flags & SSA_OP_VDEF) || (flags & SSA_OP_DEF))\n+\t      && (!(flags & SSA_OP_VUSE) || (flags & SSA_OP_USE)));\n+  ptr->defs = (flags & (SSA_OP_DEF|SSA_OP_VDEF)) ? gimple_def_ops (stmt) : NULL;\n+  if (!(flags & SSA_OP_VDEF)\n+      && ptr->defs\n+      && gimple_vdef (stmt) != NULL_TREE)\n+    ptr->defs = ptr->defs->next;\n+  ptr->uses = (flags & (SSA_OP_USE|SSA_OP_VUSE)) ? gimple_use_ops (stmt) : NULL;\n+  if (!(flags & SSA_OP_VUSE)\n+      && ptr->uses\n+      && gimple_vuse (stmt) != NULL_TREE)\n+    ptr->uses = ptr->uses->next;\n   ptr->done = false;\n \n   ptr->phi_i = 0;\n   ptr->num_phi = 0;\n   ptr->phi_stmt = NULL;\n-  ptr->vuse_index = 0;\n-  ptr->mayuse_index = 0;\n }\n \n /* Initialize iterator PTR to the use operands in STMT based on FLAGS. Return\n    the first use.  */\n static inline use_operand_p\n op_iter_init_use (ssa_op_iter *ptr, gimple stmt, int flags)\n {\n-  gcc_assert ((flags & SSA_OP_ALL_DEFS) == 0);\n+  gcc_assert ((flags & SSA_OP_ALL_DEFS) == 0\n+\t      && (flags & SSA_OP_USE));\n   op_iter_init (ptr, stmt, flags);\n   ptr->iter_type = ssa_op_iter_use;\n   return op_iter_next_use (ptr);\n@@ -911,7 +769,8 @@ op_iter_init_use (ssa_op_iter *ptr, gimple stmt, int flags)\n static inline def_operand_p\n op_iter_init_def (ssa_op_iter *ptr, gimple stmt, int flags)\n {\n-  gcc_assert ((flags & SSA_OP_ALL_USES) == 0);\n+  gcc_assert ((flags & SSA_OP_ALL_USES) == 0\n+\t      && (flags & SSA_OP_DEF));\n   op_iter_init (ptr, stmt, flags);\n   ptr->iter_type = ssa_op_iter_def;\n   return op_iter_next_def (ptr);\n@@ -927,58 +786,6 @@ op_iter_init_tree (ssa_op_iter *ptr, gimple stmt, int flags)\n   return op_iter_next_tree (ptr);\n }\n \n-/* Get the next iterator mustdef value for PTR, returning the mustdef values in\n-   KILL and DEF.  */\n-static inline void\n-op_iter_next_vdef (vuse_vec_p *use, def_operand_p *def, \n-\t\t\t ssa_op_iter *ptr)\n-{\n-#ifdef ENABLE_CHECKING\n-  gcc_assert (ptr->iter_type == ssa_op_iter_vdef);\n-#endif\n-  if (ptr->mayuses)\n-    {\n-      *def = VDEF_RESULT_PTR (ptr->mayuses);\n-      *use = VDEF_VECT (ptr->mayuses);\n-      ptr->mayuses = ptr->mayuses->next;\n-      return;\n-    }\n-\n-  *def = NULL_DEF_OPERAND_P;\n-  *use = NULL;\n-  ptr->done = true;\n-  return;\n-}\n-\n-\n-static inline void\n-op_iter_next_mustdef (use_operand_p *use, def_operand_p *def, \n-\t\t\t ssa_op_iter *ptr)\n-{\n-  vuse_vec_p vp;\n-  op_iter_next_vdef (&vp, def, ptr);\n-  if (vp != NULL)\n-    {\n-      gcc_assert (VUSE_VECT_NUM_ELEM (*vp) == 1);\n-      *use = VUSE_ELEMENT_PTR (*vp, 0);\n-    }\n-  else\n-    *use = NULL_USE_OPERAND_P;\n-}\n-\n-/* Initialize iterator PTR to the operands in STMT.  Return the first operands\n-   in USE and DEF.  */\n-static inline void\n-op_iter_init_vdef (ssa_op_iter *ptr, gimple stmt, vuse_vec_p *use, \n-\t\t     def_operand_p *def)\n-{\n-  gcc_assert (gimple_code (stmt) != GIMPLE_PHI);\n-\n-  op_iter_init (ptr, stmt, SSA_OP_VMAYUSE);\n-  ptr->iter_type = ssa_op_iter_vdef;\n-  op_iter_next_vdef (use, def, ptr);\n-}\n-\n \n /* If there is a single operand in STMT matching FLAGS, return it.  Otherwise\n    return NULL.  */\n@@ -1074,52 +881,6 @@ delink_stmt_imm_use (gimple stmt)\n }\n \n \n-/* This routine will compare all the operands matching FLAGS in STMT1 to those\n-   in STMT2.  TRUE is returned if they are the same.  STMTs can be NULL.  */\n-static inline bool\n-compare_ssa_operands_equal (gimple stmt1, gimple stmt2, int flags)\n-{\n-  ssa_op_iter iter1, iter2;\n-  tree op1 = NULL_TREE;\n-  tree op2 = NULL_TREE;\n-  bool look1, look2;\n-\n-  if (stmt1 == stmt2)\n-    return true;\n-\n-  look1 = stmt1 != NULL;\n-  look2 = stmt2 != NULL;\n-\n-  if (look1)\n-    {\n-      op1 = op_iter_init_tree (&iter1, stmt1, flags);\n-      if (!look2)\n-        return op_iter_done (&iter1);\n-    }\n-  else\n-    clear_and_done_ssa_iter (&iter1);\n-\n-  if (look2)\n-    {\n-      op2 = op_iter_init_tree (&iter2, stmt2, flags);\n-      if (!look1)\n-        return op_iter_done (&iter2);\n-    }\n-  else\n-    clear_and_done_ssa_iter (&iter2);\n-\n-  while (!op_iter_done (&iter1) && !op_iter_done (&iter2))\n-    {\n-      if (op1 != op2)\n-\treturn false;\n-      op1 = op_iter_next_tree (&iter1);\n-      op2 = op_iter_next_tree (&iter2);\n-    }\n-\n-  return (op_iter_done (&iter1) && op_iter_done (&iter2));\n-}\n-\n-\n /* If there is a single DEF in the PHI node which matches FLAG, return it.\n    Otherwise return NULL_DEF_OPERAND_P.  */\n static inline tree\n@@ -1177,11 +938,12 @@ op_iter_init_phidef (ssa_op_iter *ptr, gimple phi, int flags)\n \n   comp = (is_gimple_reg (phi_def) ? SSA_OP_DEF : SSA_OP_VIRTUAL_DEFS);\n     \n-  /* If the PHI node doesn't the operand type we care about, we're done.  */\n+  /* If the PHI node doesn't have the operand type we care about,\n+     we're done.  */\n   if ((flags & comp) == 0)\n     {\n       ptr->done = true;\n-      return NULL_USE_OPERAND_P;\n+      return NULL_DEF_OPERAND_P;\n     }\n \n   ptr->iter_type = ssa_op_iter_def;\n@@ -1261,9 +1023,17 @@ link_use_stmts_after (use_operand_p head, imm_use_iterator *imm)\n     }\n   else\n     {\n-      FOR_EACH_SSA_USE_OPERAND (use_p, head_stmt, op_iter, flag)\n-\tif (USE_FROM_PTR (use_p) == use)\n-\t  last_p = move_use_after_head (use_p, head, last_p);\n+      if (flag == SSA_OP_USE)\n+\t{\n+\t  FOR_EACH_SSA_USE_OPERAND (use_p, head_stmt, op_iter, flag)\n+\t    if (USE_FROM_PTR (use_p) == use)\n+\t      last_p = move_use_after_head (use_p, head, last_p);\n+\t}\n+      else if ((use_p = gimple_vuse_op (head_stmt)) != NULL_USE_OPERAND_P)\n+\t{\n+\t  if (USE_FROM_PTR (use_p) == use)\n+\t    last_p = move_use_after_head (use_p, head, last_p);\n+\t}\n     }\n   /* Link iter node in after last_p.  */\n   if (imm->iter_node.prev != NULL)\n@@ -1287,7 +1057,7 @@ first_imm_use_stmt (imm_use_iterator *imm, tree var)\n   imm->iter_node.prev = NULL_USE_OPERAND_P;\n   imm->iter_node.next = NULL_USE_OPERAND_P;\n   imm->iter_node.loc.stmt = NULL;\n-  imm->iter_node.use = NULL_USE_OPERAND_P;\n+  imm->iter_node.use = NULL;\n \n   if (end_imm_use_stmt_p (imm))\n     return NULL;\n@@ -1355,9 +1125,6 @@ unmodifiable_var_p (const_tree var)\n   if (TREE_CODE (var) == SSA_NAME)\n     var = SSA_NAME_VAR (var);\n \n-  if (MTAG_P (var))\n-    return false;\n-\n   return TREE_READONLY (var) && (TREE_STATIC (var) || DECL_EXTERNAL (var));\n }\n \n@@ -1414,49 +1181,13 @@ ranges_overlap_p (unsigned HOST_WIDE_INT pos1,\n   return false;\n }\n \n-/* Return the memory tag associated with symbol SYM.  */\n-\n-static inline tree\n-symbol_mem_tag (tree sym)\n-{\n-  tree tag = get_var_ann (sym)->symbol_mem_tag;\n-\n-#if defined ENABLE_CHECKING\n-  if (tag)\n-    gcc_assert (TREE_CODE (tag) == SYMBOL_MEMORY_TAG);\n-#endif\n-\n-  return tag;\n-}\n-\n-\n-/* Set the memory tag associated with symbol SYM.  */\n-\n-static inline void\n-set_symbol_mem_tag (tree sym, tree tag)\n-{\n-#if defined ENABLE_CHECKING\n-  if (tag)\n-    gcc_assert (TREE_CODE (tag) == SYMBOL_MEMORY_TAG);\n-#endif\n-\n-  get_var_ann (sym)->symbol_mem_tag = tag;\n-}\n-\n /* Accessor to tree-ssa-operands.c caches.  */\n static inline struct ssa_operands *\n gimple_ssa_operands (const struct function *fun)\n {\n   return &fun->gimple_df->ssa_operands;\n }\n \n-/* Map describing reference statistics for function FN.  */\n-static inline struct mem_ref_stats_d *\n-gimple_mem_ref_stats (const struct function *fn)\n-{\n-  return &fn->gimple_df->mem_ref_stats;\n-}\n-\n /* Given an edge_var_map V, return the PHI arg definition.  */\n \n static inline tree"}, {"sha": "f2d7c5f7f930c7d47a78347fdf79009c2a84eef2", "filename": "gcc/tree-flow.h", "status": "modified", "additions": 25, "deletions": 226, "changes": 251, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-flow.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-flow.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -30,6 +30,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-ssa-operands.h\"\n #include \"cgraph.h\"\n #include \"ipa-reference.h\"\n+#include \"tree-ssa-alias.h\"\n \n /* Forward declare structures for the garbage collector GTY markers.  */\n #ifndef GCC_BASIC_BLOCK_H\n@@ -40,98 +41,6 @@ typedef struct basic_block_def *basic_block;\n #endif\n struct static_var_ann_d;\n \n-/* The reasons a variable may escape a function.  */\n-enum escape_type \n-{\n-  NO_ESCAPE = 0,\t\t\t/* Doesn't escape.  */\n-  ESCAPE_STORED_IN_GLOBAL = 1 << 0,\n-  ESCAPE_TO_ASM = 1 << 1,\t\t/* Passed by address to an assembly\n-\t\t\t\t\t   statement.  */\n-  ESCAPE_TO_CALL = 1 << 2,\t\t/* Escapes to a function call.  */\n-  ESCAPE_BAD_CAST = 1 << 3,\t\t/* Cast from pointer to integer */\n-  ESCAPE_TO_RETURN = 1 << 4,\t\t/* Returned from function.  */\n-  ESCAPE_TO_PURE_CONST = 1 << 5,\t/* Escapes to a pure or constant\n-\t\t\t\t\t   function call.  */\n-  ESCAPE_IS_GLOBAL = 1 << 6,\t\t/* Is a global variable.  */\n-  ESCAPE_IS_PARM = 1 << 7,\t\t/* Is an incoming function argument.  */\n-  ESCAPE_UNKNOWN = 1 << 8\t\t/* We believe it escapes for\n-\t\t\t\t\t   some reason not enumerated\n-\t\t\t\t\t   above.  */\n-};\n-\n-/* Memory reference statistics for individual memory symbols,\n-   collected during alias analysis.  */\n-struct mem_sym_stats_d GTY(())\n-{\n-  /* Memory symbol.  */\n-  tree var;\n-\n-  /* Nonzero if this entry has been assigned a partition.  */\n-  unsigned int partitioned_p : 1;\n-\n-  /* Nonzero if VAR is a memory partition tag that already contains\n-     call-clobbered variables in its partition set.  */\n-  unsigned int has_call_clobbered_vars : 1;\n-\n-  /* Number of direct reference sites.  A direct reference to VAR is any\n-     reference of the form 'VAR = ' or ' = VAR'.  For GIMPLE reg\n-     pointers, this is the number of sites where the pointer is\n-     dereferenced.  */\n-  long num_direct_writes;\n-  long num_direct_reads;\n-\n-  /* Number of indirect reference sites.  An indirect reference to VAR\n-     is any reference via a pointer that contains VAR in its points-to\n-     set or, in the case of call-clobbered symbols, a function call.  */\n-  long num_indirect_writes;\n-  long num_indirect_reads;\n-\n-  /* Execution frequency.  This is the sum of the execution\n-     frequencies of all the statements that reference this object\n-     weighted by the number of references in each statement.  This is\n-     the main key used to sort the list of symbols to partition.\n-     Symbols with high execution frequencies are put at the bottom of\n-     the work list (ie, they are partitioned last).\n-     Execution frequencies are taken directly from each basic block,\n-     so compiling with PGO enabled will increase the precision of this\n-     estimate.  */\n-  long frequency_reads;\n-  long frequency_writes;\n-\n-  /* Set of memory tags that contain VAR in their alias set.  */\n-  bitmap parent_tags;\n-};\n-\n-typedef struct mem_sym_stats_d *mem_sym_stats_t;\n-DEF_VEC_P(mem_sym_stats_t);\n-DEF_VEC_ALLOC_P(mem_sym_stats_t, heap);\n-\n-/* Memory reference statistics collected during alias analysis.  */\n-struct mem_ref_stats_d GTY(())\n-{\n-  /* Number of statements that make memory references.  */\n-  long num_mem_stmts;\n-\n-  /* Number of statements that make function calls.  */\n-  long num_call_sites;\n-\n-  /* Number of statements that make calls to pure/const functions.  */\n-  long num_pure_const_call_sites;\n-\n-  /* Number of ASM statements.  */\n-  long num_asm_sites;\n-\n-  /* Estimated number of virtual operands needed as computed by\n-   compute_memory_partitions.  */\n-  long num_vuses;\n-  long num_vdefs;\n-\n-  /* This maps every symbol used to make \"memory\" references\n-     (pointers, arrays, structures, etc) to an instance of struct\n-     mem_sym_stats_d describing reference statistics for the symbol.  */\n-  struct pointer_map_t * GTY((skip)) mem_sym_stats;\n-};\n-\n \n /* Gimple dataflow datastructure. All publicly available fields shall have\n    gimple_ accessor defined in tree-flow-inline.h, all publicly modifiable\n@@ -151,29 +60,18 @@ struct gimple_df GTY(())\n   /* Array of all SSA_NAMEs used in the function.  */\n   VEC(tree,gc) *ssa_names;\n \n-  /* Artificial variable used to model the effects of function calls.  */\n-  tree global_var;\n+  /* Artificial variable used for the virtual operand FUD chain.  */\n+  tree vop;\n \n   /* Artificial variable used to model the effects of nonlocal\n      variables.  */\n   tree nonlocal_all;\n \n-  /* Call clobbered variables in the function.  If bit I is set, then\n-     REFERENCED_VARS (I) is call-clobbered.  */\n-  bitmap call_clobbered_vars;\n-\n-  /* Call-used variables in the function.  If bit I is set, then\n-     REFERENCED_VARS (I) is call-used at pure function call-sites.  */\n-  bitmap call_used_vars;\n+  /* The PTA solution for the ESCAPED artificial variable.  */\n+  struct pt_solution escaped;\n \n-  /* Addressable variables in the function.  If bit I is set, then\n-     REFERENCED_VARS (I) has had its address taken.  Note that\n-     CALL_CLOBBERED_VARS and ADDRESSABLE_VARS are not related.  An\n-     addressable variable is not necessarily call-clobbered (e.g., a\n-     local addressable whose address does not escape) and not all\n-     call-clobbered variables are addressable (e.g., a local static\n-     variable).  */\n-  bitmap addressable_vars;\n+  /* The PTA solution for the CALLUSED artificial variable.  */\n+  struct pt_solution callused;\n \n   /* Free list of SSA_NAMEs.  */\n   tree free_ssanames;\n@@ -184,18 +82,14 @@ struct gimple_df GTY(())\n      for this variable with an empty defining statement.  */\n   htab_t GTY((param_is (union tree_node))) default_defs;\n \n-  /* 'true' after aliases have been computed (see compute_may_aliases).  */\n-  unsigned int aliases_computed_p : 1;\n+  /* Symbols whose SSA form needs to be updated or created for the first\n+     time.  */\n+  bitmap syms_to_rename;\n \n   /* True if the code is in ssa form.  */\n   unsigned int in_ssa_p : 1;\n \n   struct ssa_operands ssa_operands;\n-\n-  /* Memory reference statistics collected during alias analysis.\n-     This information is used to drive the memory partitioning\n-     heuristics in compute_memory_partitions.  */\n-  struct mem_ref_stats_d mem_ref_stats;\n };\n \n /* Accessors for internal use only.  Generic code should use abstraction\n@@ -204,6 +98,7 @@ struct gimple_df GTY(())\n #define SSANAMES(fun) (fun)->gimple_df->ssa_names\n #define MODIFIED_NORETURN_CALLS(fun) (fun)->gimple_df->modified_noreturn_calls\n #define DEFAULT_DEFS(fun) (fun)->gimple_df->default_defs\n+#define SYMS_TO_RENAME(fun) (fun)->gimple_df->syms_to_rename\n \n typedef struct\n {\n@@ -231,37 +126,8 @@ typedef struct\n /* Aliasing information for SSA_NAMEs representing pointer variables.  */\n struct ptr_info_def GTY(())\n {\n-  /* Mask of reasons this pointer's value escapes the function.  */\n-  ENUM_BITFIELD (escape_type) escape_mask : 9;\n-\n-  /* Nonzero if points-to analysis couldn't determine where this pointer\n-     is pointing to.  */\n-  unsigned int pt_anything : 1;\n-\n-  /* Nonzero if the value of this pointer escapes the current function.  */\n-  unsigned int value_escapes_p : 1;\n-\n-  /* Nonzero if a memory tag is needed for this pointer.  This is\n-     true if this pointer is eventually dereferenced.  */\n-  unsigned int memory_tag_needed : 1;\n-\n-  /* Nonzero if this pointer is really dereferenced.  */\n-  unsigned int is_dereferenced : 1;\n-\n-  /* Nonzero if this pointer points to a global variable.  */\n-  unsigned int pt_global_mem : 1;\n-\n-  /* Nonzero if this pointer points to NULL.  */\n-  unsigned int pt_null : 1;\n-\n-  /* Set of variables that this pointer may point to.  */\n-  bitmap pt_vars;\n-\n-  /* If this pointer has been dereferenced, and points-to information is\n-     more precise than type-based aliasing, indirect references to this\n-     pointer will be represented by this memory tag, instead of the type\n-     tag computed by TBAA.  */\n-  tree name_mem_tag;\n+  /* The points-to solution, TBAA-pruned if the pointer is dereferenced.  */\n+  struct pt_solution pt;\n };\n \n \n@@ -359,42 +225,15 @@ struct var_ann_d GTY(())\n      states.  */\n   ENUM_BITFIELD (need_phi_state) need_phi_state : 2;\n \n-  /* Used during operand processing to determine if this variable is already \n-     in the VUSE list.  */\n-  unsigned in_vuse_list : 1;\n-\n-  /* Used during operand processing to determine if this variable is already \n-     in the VDEF list.  */\n-  unsigned in_vdef_list : 1;\n-\n   /* True for HEAP artificial variables.  These variables represent\n      the memory area allocated by a call to malloc.  */\n   unsigned is_heapvar : 1;\n \n-  /* True if the variable is call clobbered.  */\n-  unsigned call_clobbered : 1;\n-\n   /* This field describes several \"no alias\" attributes that some\n      symbols are known to have.  See the enum's definition for more\n      information on each attribute.  */\n   ENUM_BITFIELD (noalias_state) noalias_state : 2;\n \n-  /* Mask of values saying the reasons why this variable has escaped\n-     the function.  */\n-  ENUM_BITFIELD (escape_type) escape_mask : 9;\n-\n-  /* Memory partition tag assigned to this symbol.  */\n-  tree mpt;\n-\n-  /* If this variable is a pointer P that has been dereferenced, this\n-     field is an artificial variable that represents the memory\n-     location *P.  Every other pointer Q that is type-compatible with\n-     P will also have the same memory tag.  If the variable is not a\n-     pointer or if it is never dereferenced, this must be NULL.\n-     FIXME, do we really need this here?  How much slower would it be\n-     to convert to hash table?  */\n-  tree symbol_mem_tag;\n-\n   /* Used when going out of SSA form to indicate which partition this\n      variable represents storage for.  */\n   unsigned partition;\n@@ -535,7 +374,6 @@ static inline function_ann_t function_ann (const_tree);\n static inline function_ann_t get_function_ann (tree);\n static inline enum tree_ann_type ann_type (tree_ann_t);\n static inline void update_stmt (gimple);\n-static inline bitmap may_aliases (const_tree);\n static inline int get_lineno (const_gimple);\n \n /*---------------------------------------------------------------------------\n@@ -776,10 +614,8 @@ extern tree make_rename_temp (tree, const char *);\n extern void set_default_def (tree, tree);\n extern tree gimple_default_def (struct function *, tree);\n extern bool stmt_references_abnormal_ssa_name (gimple);\n-extern bool refs_may_alias_p (tree, tree);\n-extern gimple get_single_def_stmt (gimple);\n-extern gimple get_single_def_stmt_from_phi (tree, gimple);\n-extern gimple get_single_def_stmt_with_phi (tree, gimple);\n+extern tree get_ref_base_and_extent (tree, HOST_WIDE_INT *,\n+\t\t\t\t     HOST_WIDE_INT *, HOST_WIDE_INT *);\n \n /* In tree-phinodes.c  */\n extern void reserve_phi_args_for_new_edge (basic_block);\n@@ -804,43 +640,6 @@ extern bool block_may_fallthru (const_tree);\n extern bool gimple_seq_may_fallthru (gimple_seq);\n extern bool gimple_stmt_may_fallthru (gimple);\n \n-/* In tree-ssa-alias.c  */\n-extern unsigned int compute_may_aliases (void);\n-extern void dump_may_aliases_for (FILE *, tree);\n-extern void debug_may_aliases_for (tree);\n-extern void dump_alias_info (FILE *);\n-extern void debug_alias_info (void);\n-extern void dump_points_to_info (FILE *);\n-extern void debug_points_to_info (void);\n-extern void dump_points_to_info_for (FILE *, tree);\n-extern void debug_points_to_info_for (tree);\n-extern bool may_be_aliased (tree);\n-extern bool may_alias_p (tree, alias_set_type, tree, alias_set_type, bool);\n-extern struct ptr_info_def *get_ptr_info (tree);\n-extern bool may_point_to_global_var (tree);\n-extern void new_type_alias (tree, tree, tree);\n-extern void count_uses_and_derefs (tree, gimple, unsigned *, unsigned *,\n-\t\t\t\t   unsigned *);\n-static inline bool ref_contains_array_ref (const_tree);\n-static inline bool array_ref_contains_indirect_ref (const_tree);\n-extern tree get_ref_base_and_extent (tree, HOST_WIDE_INT *,\n-\t\t\t\t     HOST_WIDE_INT *, HOST_WIDE_INT *);\n-extern tree create_tag_raw (enum tree_code, tree, const char *);\n-extern void delete_mem_ref_stats (struct function *);\n-extern void dump_mem_ref_stats (FILE *);\n-extern void debug_mem_ref_stats (void);\n-extern void debug_memory_partitions (void);\n-extern void debug_mem_sym_stats (tree var);\n-extern void dump_mem_sym_stats_for_var (FILE *, tree);\n-extern void debug_all_mem_sym_stats (void);\n-\n-/* Call-back function for walk_use_def_chains().  At each reaching\n-   definition, a function with this prototype is called.  */\n-typedef bool (*walk_use_def_chains_fn) (tree, gimple, void *);\n-\n-/* In tree-ssa-alias-warnings.c  */\n-extern void strict_aliasing_warning_backend (void);\n-\n \n /* In tree-ssa.c  */\n \n@@ -869,16 +668,22 @@ extern edge ssa_redirect_edge (edge, basic_block);\n extern void flush_pending_stmts (edge);\n extern void verify_ssa (bool);\n extern void delete_tree_ssa (void);\n-extern void walk_use_def_chains (tree, walk_use_def_chains_fn, void *, bool);\n extern bool ssa_undefined_value_p (tree);\n+extern void execute_update_addresses_taken (bool);\n+\n+/* Call-back function for walk_use_def_chains().  At each reaching\n+   definition, a function with this prototype is called.  */\n+typedef bool (*walk_use_def_chains_fn) (tree, gimple, void *);\n+\n+extern void walk_use_def_chains (tree, walk_use_def_chains_fn, void *, bool);\n \n \n /* In tree-into-ssa.c  */\n void update_ssa (unsigned);\n void delete_update_ssa (void);\n void register_new_name_mapping (tree, tree);\n tree create_new_def_for (tree, gimple, def_operand_p);\n-bool need_ssa_update_p (void);\n+bool need_ssa_update_p (struct function *);\n bool name_mappings_registered_p (void);\n bool name_registered_for_update_p (tree);\n bitmap ssa_names_to_replace (void);\n@@ -1065,9 +870,10 @@ char *get_lsm_tmp_name (tree, unsigned);\n \n /* In tree-flow-inline.h  */\n static inline bool is_call_clobbered (const_tree);\n-static inline void mark_call_clobbered (tree, unsigned int);\n static inline void set_is_used (tree);\n static inline bool unmodifiable_var_p (const_tree);\n+static inline bool ref_contains_array_ref (const_tree);\n+static inline bool array_ref_contains_indirect_ref (const_tree);\n \n /* In tree-eh.c  */\n extern void make_eh_edges (gimple);\n@@ -1149,11 +955,6 @@ tree force_gimple_operand_gsi (gimple_stmt_iterator *, tree, bool, tree,\n tree gimple_fold_indirect_ref (tree);\n void mark_addressable (tree);\n \n-/* In tree-ssa-structalias.c */\n-bool find_what_p_points_to (tree);\n-bool clobber_what_escaped (void);\n-void compute_call_used_vars (void);\n-\n /* In tree-ssa-live.c */\n extern void remove_unused_locals (void);\n extern void dump_scope_blocks (FILE *, int);\n@@ -1174,8 +975,6 @@ rtx addr_for_mem_ref (struct mem_address *, bool);\n void get_address_description (tree, struct mem_address *);\n tree maybe_fold_tmr (tree);\n \n-void init_alias_heapvars (void);\n-void delete_alias_heapvars (void);\n unsigned int execute_fixup_cfg (void);\n \n #include \"tree-flow-inline.h\""}, {"sha": "e1e1f1154d1b003ec4b7949e9ac4f8da02bd3260", "filename": "gcc/tree-inline.c", "status": "modified", "additions": 15, "deletions": 20, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-inline.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1297,6 +1297,14 @@ remap_gimple_stmt (gimple stmt, copy_body_data *id)\n   else\n     walk_gimple_op (copy, remap_gimple_op_r, &wi); \n \n+  /* Clear the copied virtual operands.  We are not remapping them here\n+     but are going to recreate them from scratch.  */\n+  if (gimple_has_mem_ops (copy))\n+    {\n+      gimple_set_vdef (copy, NULL_TREE);\n+      gimple_set_vuse (copy, NULL_TREE);\n+    }\n+\n   /* We have to handle EH region remapping of GIMPLE_RESX specially because\n      the region number is not an operand.  */\n   if (gimple_code (stmt) == GIMPLE_RESX && id->eh_region_offset)\n@@ -3410,6 +3418,9 @@ expand_call_inline (basic_block bb, gimple stmt, copy_body_data *id)\n   pointer_map_destroy (id->decl_map);\n   id->decl_map = st;\n \n+  /* Unlink the calls virtual operands before replacing it.  */\n+  unlink_stmt_vdef (stmt);\n+\n   /* If the inlined function returns a result that we care about,\n      substitute the GIMPLE_CALL with an assignment of the return\n      variable to the LHS of the call.  That is, if STMT was\n@@ -3420,10 +3431,7 @@ expand_call_inline (basic_block bb, gimple stmt, copy_body_data *id)\n       stmt = gimple_build_assign (gimple_call_lhs (stmt), use_retvar);\n       gsi_replace (&stmt_gsi, stmt, false);\n       if (gimple_in_ssa_p (cfun))\n-\t{\n-          update_stmt (stmt);\n-          mark_symbols_for_renaming (stmt);\n-\t}\n+\tmark_symbols_for_renaming (stmt);\n       maybe_clean_or_replace_eh_stmt (old_stmt, stmt);\n     }\n   else\n@@ -3443,7 +3451,6 @@ expand_call_inline (basic_block bb, gimple stmt, copy_body_data *id)\n \t\t undefined via a move.  */\n \t      stmt = gimple_build_assign (gimple_call_lhs (stmt), def);\n \t      gsi_replace (&stmt_gsi, stmt, true);\n-\t      update_stmt (stmt);\n \t    }\n \t  else\n \t    {\n@@ -4451,28 +4458,16 @@ tree_function_versioning (tree old_decl, tree new_decl, varray_type tree_map,\n \n   /* Clean up.  */\n   pointer_map_destroy (id.decl_map);\n+  free_dominance_info (CDI_DOMINATORS);\n+  free_dominance_info (CDI_POST_DOMINATORS);\n   if (!update_clones)\n     {\n       fold_marked_statements (0, id.statements_to_fold);\n       pointer_set_destroy (id.statements_to_fold);\n       fold_cond_expr_cond ();\n-    }\n-  if (gimple_in_ssa_p (cfun))\n-    {\n-      free_dominance_info (CDI_DOMINATORS);\n-      free_dominance_info (CDI_POST_DOMINATORS);\n-      if (!update_clones)\n-        delete_unreachable_blocks ();\n+      delete_unreachable_blocks ();\n       update_ssa (TODO_update_ssa);\n-      if (!update_clones)\n-\t{\n-\t  fold_cond_expr_cond ();\n-\t  if (need_ssa_update_p ())\n-\t    update_ssa (TODO_update_ssa);\n-\t}\n     }\n-  free_dominance_info (CDI_DOMINATORS);\n-  free_dominance_info (CDI_POST_DOMINATORS);\n   VEC_free (gimple, heap, init_stmts);\n   pop_cfun ();\n   current_function_decl = old_current_function_decl;"}, {"sha": "67f8fd87220a7149c33bccbd1b29aa6597ff8d4d", "filename": "gcc/tree-into-ssa.c", "status": "modified", "additions": 66, "deletions": 86, "changes": 152, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-into-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-into-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-into-ssa.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -113,10 +113,6 @@ static sbitmap old_ssa_names;\n static sbitmap new_ssa_names;\n \n \n-/* Symbols whose SSA form needs to be updated or created for the first\n-   time.  */\n-static bitmap syms_to_rename;\n-\n /* Subset of SYMS_TO_RENAME.  Contains all the GIMPLE register symbols\n    that have been marked for renaming.  */\n static bitmap regs_to_rename;\n@@ -155,12 +151,9 @@ struct repl_map_d\n    then REPL_TBL[N_i] = { O_1, O_2, ..., O_j }.  */\n static htab_t repl_tbl;\n \n-/* true if register_new_name_mapping needs to initialize the data\n-   structures needed by update_ssa.  */\n-static bool need_to_initialize_update_ssa_p = true;\n-\n-/* true if update_ssa needs to update virtual operands.  */\n-static bool need_to_update_vops_p = false;\n+/* The function the SSA updating data structures have been initialized for.\n+   NULL if they need to be initialized by register_new_name_mapping.  */\n+static struct function *update_ssa_initialized_fn = NULL;\n \n /* Statistics kept by update_ssa to use in the virtual mapping\n    heuristic.  If the number of virtual mappings is beyond certain\n@@ -585,7 +578,7 @@ set_livein_block (tree var, basic_block bb)\n static inline bool\n symbol_marked_for_renaming (tree sym)\n {\n-  return bitmap_bit_p (syms_to_rename, DECL_UID (sym));\n+  return bitmap_bit_p (SYMS_TO_RENAME (cfun), DECL_UID (sym));\n }\n \n \n@@ -595,6 +588,8 @@ static inline bool\n is_old_name (tree name)\n {\n   unsigned ver = SSA_NAME_VERSION (name);\n+  if (!new_ssa_names)\n+    return false;\n   return ver < new_ssa_names->n_bits && TEST_BIT (old_ssa_names, ver);\n }\n \n@@ -605,6 +600,8 @@ static inline bool\n is_new_name (tree name)\n {\n   unsigned ver = SSA_NAME_VERSION (name);\n+  if (!new_ssa_names)\n+    return false;\n   return ver < new_ssa_names->n_bits && TEST_BIT (new_ssa_names, ver);\n }\n \n@@ -695,8 +692,6 @@ add_new_name_mapping (tree new_tree, tree old)\n     {\n       tree sym;\n \n-      need_to_update_vops_p = true;\n-\n       update_ssa_stats.num_virtual_mappings++;\n       update_ssa_stats.num_virtual_symbols++;\n \n@@ -1455,10 +1450,10 @@ dump_decl_set (FILE *file, bitmap set)\n \t  fprintf (file, \" \");\n \t}\n \n-      fprintf (file, \"}\\n\");\n+      fprintf (file, \"}\");\n     }\n   else\n-    fprintf (file, \"NIL\\n\");\n+    fprintf (file, \"NIL\");\n }\n \n \n@@ -1468,6 +1463,7 @@ void\n debug_decl_set (bitmap set)\n {\n   dump_decl_set (stderr, set);\n+  fprintf (stderr, \"\\n\");\n }\n \n \n@@ -1551,7 +1547,8 @@ dump_currdefs (FILE *file)\n \n   fprintf (file, \"\\n\\nCurrent reaching definitions\\n\\n\");\n   FOR_EACH_REFERENCED_VAR (var, i)\n-    if (syms_to_rename == NULL || bitmap_bit_p (syms_to_rename, DECL_UID (var)))\n+    if (SYMS_TO_RENAME (cfun) == NULL\n+\t|| bitmap_bit_p (SYMS_TO_RENAME (cfun), DECL_UID (var)))\n       {\n \tfprintf (file, \"CURRDEF (\");\n \tprint_generic_expr (file, var, 0);\n@@ -1943,27 +1940,15 @@ rewrite_update_stmt (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n   /* Rewrite USES included in OLD_SSA_NAMES and USES whose underlying\n      symbol is marked for renaming.  */\n   if (rewrite_uses_p (stmt))\n-    {\n-      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_USE)\n-\tmaybe_replace_use (use_p);\n-\n-      if (need_to_update_vops_p)\n-\tFOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_VIRTUAL_USES)\n-\t  maybe_replace_use (use_p);\n-    }\n+    FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_ALL_USES)\n+      maybe_replace_use (use_p);\n \n   /* Register definitions of names in NEW_SSA_NAMES and OLD_SSA_NAMES.\n      Also register definitions for names whose underlying symbol is\n      marked for renaming.  */\n   if (register_defs_p (stmt))\n-    {\n-      FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, iter, SSA_OP_DEF)\n-\tmaybe_register_def (def_p, stmt);\n-\n-      if (need_to_update_vops_p)\n-\tFOR_EACH_SSA_DEF_OPERAND (def_p, stmt, iter, SSA_OP_VIRTUAL_DEFS)\n-\t  maybe_register_def (def_p, stmt);\n-    }\n+    FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, iter, SSA_OP_ALL_DEFS)\n+      maybe_register_def (def_p, stmt);\n }\n \n \n@@ -2293,6 +2278,7 @@ struct gimple_opt_pass pass_build_ssa =\n   0,\t\t\t\t\t/* properties_destroyed */\n   0,\t\t\t\t\t/* todo_flags_start */\n   TODO_dump_func\n+    | TODO_update_ssa_only_virtuals\n     | TODO_verify_ssa\n     | TODO_remove_unused_locals\t\t/* todo_flags_finish */\n  }\n@@ -2577,7 +2563,7 @@ dump_update_ssa (FILE *file)\n   unsigned i = 0;\n   bitmap_iterator bi;\n \n-  if (!need_ssa_update_p ())\n+  if (!need_ssa_update_p (cfun))\n     return;\n \n   if (new_ssa_names && sbitmap_first_set_bit (new_ssa_names) >= 0)\n@@ -2604,10 +2590,11 @@ dump_update_ssa (FILE *file)\n \t       update_ssa_stats.num_virtual_symbols);\n     }\n \n-  if (syms_to_rename && !bitmap_empty_p (syms_to_rename))\n+  if (!bitmap_empty_p (SYMS_TO_RENAME (cfun)))\n     {\n       fprintf (file, \"\\n\\nSymbols to be put in SSA form\\n\\n\");\n-      dump_decl_set (file, syms_to_rename);\n+      dump_decl_set (file, SYMS_TO_RENAME (cfun));\n+      fprintf (file, \"\\n\");\n     }\n \n   if (names_to_release && !bitmap_empty_p (names_to_release))\n@@ -2636,7 +2623,7 @@ debug_update_ssa (void)\n /* Initialize data structures used for incremental SSA updates.  */\n \n static void\n-init_update_ssa (void)\n+init_update_ssa (struct function *fn)\n {\n   /* Reserve more space than the current number of names.  The calls to\n      add_new_name_mapping are typically done after creating new SSA\n@@ -2648,14 +2635,12 @@ init_update_ssa (void)\n   sbitmap_zero (new_ssa_names);\n \n   repl_tbl = htab_create (20, repl_map_hash, repl_map_eq, repl_map_free);\n-  need_to_initialize_update_ssa_p = false;\n-  need_to_update_vops_p = false;\n-  syms_to_rename = BITMAP_ALLOC (NULL);\n   regs_to_rename = BITMAP_ALLOC (NULL);\n   mem_syms_to_rename = BITMAP_ALLOC (NULL);\n   names_to_release = NULL;\n   memset (&update_ssa_stats, 0, sizeof (update_ssa_stats));\n   update_ssa_stats.virtual_symbols = BITMAP_ALLOC (NULL);\n+  update_ssa_initialized_fn = fn;\n }\n \n \n@@ -2676,9 +2661,7 @@ delete_update_ssa (void)\n   htab_delete (repl_tbl);\n   repl_tbl = NULL;\n \n-  need_to_initialize_update_ssa_p = true;\n-  need_to_update_vops_p = false;\n-  BITMAP_FREE (syms_to_rename);\n+  bitmap_clear (SYMS_TO_RENAME (update_ssa_initialized_fn));\n   BITMAP_FREE (regs_to_rename);\n   BITMAP_FREE (mem_syms_to_rename);\n   BITMAP_FREE (update_ssa_stats.virtual_symbols);\n@@ -2705,6 +2688,7 @@ delete_update_ssa (void)\n \n   BITMAP_FREE (blocks_with_phis_to_rewrite);\n   BITMAP_FREE (blocks_to_update);\n+  update_ssa_initialized_fn = NULL;\n }\n \n \n@@ -2751,12 +2735,14 @@ create_new_def_for (tree old_name, gimple stmt, def_operand_p def)\n    update_ssa.  */\n \n void\n-register_new_name_mapping (tree new_Tree ATTRIBUTE_UNUSED, tree old ATTRIBUTE_UNUSED)\n+register_new_name_mapping (tree new_tree, tree old)\n {\n-  if (need_to_initialize_update_ssa_p)\n-    init_update_ssa ();\n+  if (!update_ssa_initialized_fn)\n+    init_update_ssa (cfun);\n+\n+  gcc_assert (update_ssa_initialized_fn == cfun);\n \n-  add_new_name_mapping (new_Tree, old);\n+  add_new_name_mapping (new_tree, old);\n }\n \n \n@@ -2765,17 +2751,7 @@ register_new_name_mapping (tree new_Tree ATTRIBUTE_UNUSED, tree old ATTRIBUTE_UN\n void\n mark_sym_for_renaming (tree sym)\n {\n-  if (need_to_initialize_update_ssa_p)\n-    init_update_ssa ();\n-\n-  bitmap_set_bit (syms_to_rename, DECL_UID (sym));\n-\n-  if (!is_gimple_reg (sym))\n-    {\n-      need_to_update_vops_p = true;\n-      if (memory_partition (sym))\n-\tbitmap_set_bit (syms_to_rename, DECL_UID (memory_partition (sym)));\n-    }\n+  bitmap_set_bit (SYMS_TO_RENAME (cfun), DECL_UID (sym));\n }\n \n \n@@ -2790,27 +2766,33 @@ mark_set_for_renaming (bitmap set)\n   if (set == NULL || bitmap_empty_p (set))\n     return;\n \n-  if (need_to_initialize_update_ssa_p)\n-    init_update_ssa ();\n-\n   EXECUTE_IF_SET_IN_BITMAP (set, 0, i, bi)\n     mark_sym_for_renaming (referenced_var (i));\n }\n \n \n-/* Return true if there is any work to be done by update_ssa.  */\n+/* Return true if there is any work to be done by update_ssa\n+   for function FN.  */\n \n bool\n-need_ssa_update_p (void)\n+need_ssa_update_p (struct function *fn)\n {\n-  return syms_to_rename || old_ssa_names || new_ssa_names;\n+  gcc_assert (fn != NULL);\n+  return (update_ssa_initialized_fn == fn\n+\t  || (fn->gimple_df\n+\t      && !bitmap_empty_p (SYMS_TO_RENAME (fn))));\n }\n \n /* Return true if SSA name mappings have been registered for SSA updating.  */\n \n bool\n name_mappings_registered_p (void)\n {\n+  if (!update_ssa_initialized_fn)\n+    return false;\n+\n+  gcc_assert (update_ssa_initialized_fn == cfun);\n+\n   return repl_tbl && htab_elements (repl_tbl) > 0;\n }\n \n@@ -2819,12 +2801,12 @@ name_mappings_registered_p (void)\n bool\n name_registered_for_update_p (tree n ATTRIBUTE_UNUSED)\n {\n-  if (!need_ssa_update_p ())\n+  if (!update_ssa_initialized_fn)\n     return false;\n \n-  return is_new_name (n)\n-         || is_old_name (n)\n-\t || symbol_marked_for_renaming (SSA_NAME_VAR (n));\n+  gcc_assert (update_ssa_initialized_fn == cfun);\n+\n+  return is_new_name (n) || is_old_name (n);\n }\n \n \n@@ -2837,6 +2819,9 @@ ssa_names_to_replace (void)\n   bitmap ret;\n   sbitmap_iterator sbi;\n   \n+  gcc_assert (update_ssa_initialized_fn == NULL\n+\t      || update_ssa_initialized_fn == cfun);\n+\n   ret = BITMAP_ALLOC (NULL);\n   EXECUTE_IF_SET_IN_SBITMAP (old_ssa_names, 0, i, sbi)\n     bitmap_set_bit (ret, i);\n@@ -2850,7 +2835,7 @@ ssa_names_to_replace (void)\n void\n release_ssa_name_after_update_ssa (tree name)\n {\n-  gcc_assert (!need_to_initialize_update_ssa_p);\n+  gcc_assert (cfun && update_ssa_initialized_fn == cfun);\n \n   if (names_to_release == NULL)\n     names_to_release = BITMAP_ALLOC (NULL);\n@@ -3110,11 +3095,15 @@ update_ssa (unsigned update_flags)\n   bool insert_phi_p;\n   sbitmap_iterator sbi;\n \n-  if (!need_ssa_update_p ())\n+  if (!need_ssa_update_p (cfun))\n     return;\n \n   timevar_push (TV_TREE_SSA_INCREMENTAL);\n \n+  if (!update_ssa_initialized_fn)\n+    init_update_ssa (cfun);\n+  gcc_assert (update_ssa_initialized_fn == cfun);\n+\n   blocks_with_phis_to_rewrite = BITMAP_ALLOC (NULL);\n   if (!phis_to_rewrite)\n     phis_to_rewrite = VEC_alloc (gimple_vec, heap, last_basic_block);\n@@ -3166,30 +3155,21 @@ update_ssa (unsigned update_flags)\n   /* If there are symbols to rename, identify those symbols that are\n      GIMPLE registers into the set REGS_TO_RENAME and those that are\n      memory symbols into the set MEM_SYMS_TO_RENAME.  */\n-  if (!bitmap_empty_p (syms_to_rename))\n+  if (!bitmap_empty_p (SYMS_TO_RENAME (cfun)))\n     {\n       unsigned i;\n       bitmap_iterator bi;\n \n-      EXECUTE_IF_SET_IN_BITMAP (syms_to_rename, 0, i, bi)\n+      EXECUTE_IF_SET_IN_BITMAP (SYMS_TO_RENAME (cfun), 0, i, bi)\n \t{\n \t  tree sym = referenced_var (i);\n \t  if (is_gimple_reg (sym))\n \t    bitmap_set_bit (regs_to_rename, i);\n-\t  else\n-\t    {\n-\t      /* Memory partitioning information may have been\n-\t\t computed after the symbol was marked for renaming,\n-\t\t if SYM is inside a partition also mark the partition\n-\t\t for renaming.  */\n-\t      tree mpt = memory_partition (sym);\n-\t      if (mpt)\n-\t\tbitmap_set_bit (syms_to_rename, DECL_UID (mpt));\n-\t    }\n \t}\n \n       /* Memory symbols are those not in REGS_TO_RENAME.  */\n-      bitmap_and_compl (mem_syms_to_rename, syms_to_rename, regs_to_rename);\n+      bitmap_and_compl (mem_syms_to_rename,\n+\t\t\tSYMS_TO_RENAME (cfun), regs_to_rename);\n     }\n \n   /* If there are names defined in the replacement table, prepare\n@@ -3203,12 +3183,12 @@ update_ssa (unsigned update_flags)\n \t removal, and there are no symbols to rename, then there's\n \t nothing else to do.  */\n       if (sbitmap_first_set_bit (new_ssa_names) < 0\n-\t  && bitmap_empty_p (syms_to_rename))\n+\t  && bitmap_empty_p (SYMS_TO_RENAME (cfun)))\n \tgoto done;\n     }\n \n   /* Next, determine the block at which to start the renaming process.  */\n-  if (!bitmap_empty_p (syms_to_rename))\n+  if (!bitmap_empty_p (SYMS_TO_RENAME (cfun)))\n     {\n       /* If we have to rename some symbols from scratch, we need to\n \t start the process at the root of the CFG.  FIXME, it should\n@@ -3262,7 +3242,7 @@ update_ssa (unsigned update_flags)\n \t  sbitmap_free (tmp);\n \t}\n \n-      EXECUTE_IF_SET_IN_BITMAP (syms_to_rename, 0, i, bi)\n+      EXECUTE_IF_SET_IN_BITMAP (SYMS_TO_RENAME (cfun), 0, i, bi)\n \tinsert_updated_phi_nodes_for (referenced_var (i), dfs, blocks_to_update,\n \t                              update_flags);\n \n@@ -3283,7 +3263,7 @@ update_ssa (unsigned update_flags)\n   EXECUTE_IF_SET_IN_SBITMAP (old_ssa_names, 0, i, sbi)\n     set_current_def (ssa_name (i), NULL_TREE);\n \n-  EXECUTE_IF_SET_IN_BITMAP (syms_to_rename, 0, i, bi)\n+  EXECUTE_IF_SET_IN_BITMAP (SYMS_TO_RENAME (cfun), 0, i, bi)\n     set_current_def (referenced_var (i), NULL_TREE);\n \n   /* Now start the renaming process at START_BB.  */"}, {"sha": "61762971c7cdd716907cdee812654110ba74b93a", "filename": "gcc/tree-loop-distribution.c", "status": "modified", "additions": 3, "deletions": 35, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-loop-distribution.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-loop-distribution.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-loop-distribution.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -77,9 +77,6 @@ static bitmap remaining_stmts;\n    predecessor a node that writes to memory.  */\n static bitmap upstream_mem_writes;\n \n-/* TODOs we need to run after the pass.  */\n-static unsigned int todo;\n-\n /* Update the PHI nodes of NEW_LOOP.  NEW_LOOP is a duplicate of\n    ORIG_LOOP.  */\n \n@@ -241,14 +238,13 @@ static bool\n generate_memset_zero (gimple stmt, tree op0, tree nb_iter,\n \t\t      gimple_stmt_iterator bsi)\n {\n-  tree t, addr_base;\n+  tree addr_base;\n   tree nb_bytes = NULL;\n   bool res = false;\n   gimple_seq stmts = NULL, stmt_list = NULL;\n   gimple fn_call;\n   tree mem, fndecl, fntype, fn;\n   gimple_stmt_iterator i;\n-  ssa_op_iter iter;\n   struct data_reference *dr = XCNEW (struct data_reference);\n \n   DR_STMT (dr) = stmt;\n@@ -303,29 +299,6 @@ generate_memset_zero (gimple stmt, tree op0, tree nb_iter,\n     {\n       gimple s = gsi_stmt (i);\n       update_stmt_if_modified (s);\n-\n-      FOR_EACH_SSA_TREE_OPERAND (t, s, iter, SSA_OP_VIRTUAL_DEFS)\n-\t{\n-\t  if (TREE_CODE (t) == SSA_NAME)\n-\t    t = SSA_NAME_VAR (t);\n-\t  mark_sym_for_renaming (t);\n-\t}\n-    }\n-\n-  /* Mark also the uses of the VDEFS of STMT to be renamed.  */\n-  FOR_EACH_SSA_TREE_OPERAND (t, stmt, iter, SSA_OP_VIRTUAL_DEFS)\n-    {\n-      if (TREE_CODE (t) == SSA_NAME)\n-\t{\n-\t  gimple s;\n-\t  imm_use_iterator imm_iter;\n-\n-\t  FOR_EACH_IMM_USE_STMT (s, imm_iter, t)\n-\t    update_stmt (s);\n-\n-\t  t = SSA_NAME_VAR (t);\n-\t}\n-      mark_sym_for_renaming (t);\n     }\n \n   gsi_insert_seq_after (&bsi, stmt_list, GSI_CONTINUE_LINKING);\n@@ -334,8 +307,6 @@ generate_memset_zero (gimple stmt, tree op0, tree nb_iter,\n   if (dump_file && (dump_flags & TDF_DETAILS))\n     fprintf (dump_file, \"generated memset zero\\n\");\n \n-  todo |= TODO_rebuild_alias;\n-\n  end:\n   free_data_ref (dr);\n   return res;\n@@ -606,7 +577,6 @@ static void\n rdg_flag_uses (struct graph *rdg, int u, bitmap partition, bitmap loops,\n \t       bitmap processed, bool *part_has_writes)\n {\n-  ssa_op_iter iter;\n   use_operand_p use_p;\n   struct vertex *x = &(rdg->vertices[u]);\n   gimple stmt = RDGV_STMT (x);\n@@ -626,7 +596,7 @@ rdg_flag_uses (struct graph *rdg, int u, bitmap partition, bitmap loops,\n \n   if (gimple_code (stmt) != GIMPLE_PHI)\n     {\n-      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_VIRTUAL_USES)\n+      if ((use_p = gimple_vuse_op (stmt)) != NULL_USE_OPERAND_P)\n \t{\n \t  tree use = USE_FROM_PTR (use_p);\n \n@@ -1211,8 +1181,6 @@ tree_loop_distribution (void)\n   loop_iterator li;\n   int nb_generated_loops = 0;\n \n-  todo = 0;\n-\n   FOR_EACH_LOOP (li, loop, 0)\n     {\n       VEC (gimple, heap) *work_list = VEC_alloc (gimple, heap, 3);\n@@ -1244,7 +1212,7 @@ tree_loop_distribution (void)\n       VEC_free (gimple, heap, work_list);\n     }\n \n-  return todo;\n+  return 0;\n }\n \n static bool"}, {"sha": "19e49d5dad0d952a3425339b9ae7fe652f0bde50", "filename": "gcc/tree-outof-ssa.c", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-outof-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-outof-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-outof-ssa.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -122,14 +122,10 @@ create_temp (tree t)\n   DECL_GIMPLE_REG_P (tmp) = DECL_GIMPLE_REG_P (t);\n   add_referenced_var (tmp);\n \n-  /* add_referenced_var will create the annotation and set up some\n-     of the flags in the annotation.  However, some flags we need to\n-     inherit from our original variable.  */\n-  set_symbol_mem_tag (tmp, symbol_mem_tag (t));\n-  if (is_call_clobbered (t))\n-    mark_call_clobbered (tmp, var_ann (t)->escape_mask);\n-  if (bitmap_bit_p (gimple_call_used_vars (cfun), DECL_UID (t)))\n-    bitmap_set_bit (gimple_call_used_vars (cfun), DECL_UID (tmp));\n+  /* We should never have copied variables in non-automatic storage\n+     or variables that have their address taken.  So it is pointless\n+     to try to copy call-clobber state here.  */\n+  gcc_assert (!may_be_aliased (t) && !is_global_var (t));\n \n   return tmp;\n }"}, {"sha": "cc9a80c0681917376c5d5a44ad5b4234c0f1abc9", "filename": "gcc/tree-pass.h", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-pass.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-pass.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pass.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -286,7 +286,10 @@ struct dump_file_info\n #define TODO_mark_first_instance\t(1 << 19)\n \n /* Rebuild aliasing info.  */\n-#define TODO_rebuild_alias                (1 << 20)\n+#define TODO_rebuild_alias              (1 << 20)\n+\n+/* Rebuild the addressable-vars bitmap and do register promotion.  */\n+#define TODO_update_address_taken\t(1 << 21)\n \n #define TODO_update_ssa_any\t\t\\\n     (TODO_update_ssa\t\t\t\\\n@@ -374,7 +377,6 @@ extern struct gimple_opt_pass pass_forwprop;\n extern struct gimple_opt_pass pass_phiprop;\n extern struct gimple_opt_pass pass_tree_ifcombine;\n extern struct gimple_opt_pass pass_dse;\n-extern struct gimple_opt_pass pass_simple_dse;\n extern struct gimple_opt_pass pass_nrv;\n extern struct gimple_opt_pass pass_mark_used_blocks;\n extern struct gimple_opt_pass pass_rename_ssa_copies;\n@@ -391,7 +393,6 @@ extern struct gimple_opt_pass pass_reassoc;\n extern struct gimple_opt_pass pass_rebuild_cgraph_edges;\n extern struct gimple_opt_pass pass_remove_cgraph_callee_edges;\n extern struct gimple_opt_pass pass_build_cgraph_edges;\n-extern struct gimple_opt_pass pass_reset_cc_flags;\n extern struct gimple_opt_pass pass_local_pure_const;\n \n /* IPA Passes */"}, {"sha": "a5d4dcd5da6445278775dab7f54624aa952b4a17", "filename": "gcc/tree-predcom.c", "status": "modified", "additions": 5, "deletions": 57, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-predcom.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-predcom.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-predcom.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1423,7 +1423,6 @@ get_init_expr (chain_p chain, unsigned index)\n void\n mark_virtual_ops_for_renaming (gimple stmt)\n {\n-  ssa_op_iter iter;\n   tree var;\n \n   if (gimple_code (stmt) == GIMPLE_PHI)\n@@ -1439,24 +1438,8 @@ mark_virtual_ops_for_renaming (gimple stmt)\n     }\n \n   update_stmt (stmt);\n-\n-  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, SSA_OP_ALL_VIRTUALS)\n-    {\n-      if (TREE_CODE (var) == SSA_NAME)\n-\tvar = SSA_NAME_VAR (var);\n-      mark_sym_for_renaming (var);\n-    }\n-}\n-\n-/* Calls mark_virtual_ops_for_renaming for all members of LIST.  */\n-\n-static void\n-mark_virtual_ops_for_renaming_list (gimple_seq list)\n-{\n-  gimple_stmt_iterator gsi;\n-\n-  for (gsi = gsi_start (list); !gsi_end_p (gsi); gsi_next (&gsi))\n-    mark_virtual_ops_for_renaming (gsi_stmt (gsi));\n+  if (gimple_vuse (stmt))\n+    mark_sym_for_renaming (gimple_vop (cfun));\n }\n \n /* Returns a new temporary variable used for the I-th variable carrying\n@@ -1525,10 +1508,7 @@ initialize_root_vars (struct loop *loop, chain_p chain, bitmap tmp_vars)\n \n       init = force_gimple_operand (init, &stmts, true, NULL_TREE);\n       if (stmts)\n-\t{\n-\t  mark_virtual_ops_for_renaming_list (stmts);\n-\t  gsi_insert_seq_on_edge_immediate (entry, stmts);\n-\t}\n+\tgsi_insert_seq_on_edge_immediate (entry, stmts);\n \n       phi = create_phi_node (var, loop->header);\n       SSA_NAME_DEF_STMT (var) = phi;\n@@ -1589,10 +1569,7 @@ initialize_root_vars_lm (struct loop *loop, dref root, bool written,\n       \n   init = force_gimple_operand (init, &stmts, written, NULL_TREE);\n   if (stmts)\n-    {\n-      mark_virtual_ops_for_renaming_list (stmts);\n-      gsi_insert_seq_on_edge_immediate (entry, stmts);\n-    }\n+    gsi_insert_seq_on_edge_immediate (entry, stmts);\n \n   if (written)\n     {\n@@ -2421,31 +2398,6 @@ try_combine_chains (VEC (chain_p, heap) **chains)\n     }\n }\n \n-/* Sets alias information based on data reference DR for REF,\n-   if necessary.  */\n-\n-static void\n-set_alias_info (tree ref, struct data_reference *dr)\n-{\n-  tree var;\n-  tree tag = DR_SYMBOL_TAG (dr);\n-\n-  gcc_assert (tag != NULL_TREE);\n-\n-  ref = get_base_address (ref);\n-  if (!ref || !INDIRECT_REF_P (ref))\n-    return;\n-\n-  var = SSA_NAME_VAR (TREE_OPERAND (ref, 0));\n-  if (var_ann (var)->symbol_mem_tag)\n-    return;\n-\n-  if (!MTAG_P (tag))\n-    new_type_alias (var, tag, ref);\n-  else\n-    var_ann (var)->symbol_mem_tag = tag;\n-}\n-\n /* Prepare initializers for CHAIN in LOOP.  Returns false if this is\n    impossible because one of these initializers may trap, true otherwise.  */\n \n@@ -2491,11 +2443,7 @@ prepare_initializers_chain (struct loop *loop, chain_p chain)\n \n       init = force_gimple_operand (init, &stmts, false, NULL_TREE);\n       if (stmts)\n-\t{\n-\t  mark_virtual_ops_for_renaming_list (stmts);\n-\t  gsi_insert_seq_on_edge_immediate (entry, stmts);\n-\t}\n-      set_alias_info (init, dr);\n+\tgsi_insert_seq_on_edge_immediate (entry, stmts);\n \n       VEC_replace (tree, chain->inits, i, init);\n     }"}, {"sha": "a497ca794f5e4a1278b0f0277e503a3d6bb915b4", "filename": "gcc/tree-pretty-print.c", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pretty-print.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -881,13 +881,10 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n \t}\n       break;\n \n-    case SYMBOL_MEMORY_TAG:\n-    case NAME_MEMORY_TAG:\n     case VAR_DECL:\n     case PARM_DECL:\n     case FIELD_DECL:\n     case NAMESPACE_DECL:\n-    case MEMORY_PARTITION_TAG:\n       dump_decl_name (buffer, node, flags);\n       break;\n "}, {"sha": "f0e4bd02ff5aab3597fc646c657ebe15bbacfa5b", "filename": "gcc/tree-sra.c", "status": "modified", "additions": 12, "deletions": 40, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-sra.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-sra.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-sra.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -78,9 +78,6 @@ along with GCC; see the file COPYING3.  If not see\n /* True if this is the \"early\" pass, before inlining.  */\n static bool early_sra;\n \n-/* The set of todo flags to return from tree_sra.  */\n-static unsigned int todoflags;\n-\n /* The set of aggregate variables that are candidates for scalarization.  */\n static bitmap sra_candidates;\n \n@@ -210,7 +207,6 @@ extern void debug_sra_elt_name (struct sra_elt *);\n static tree generate_element_ref (struct sra_elt *);\n static gimple_seq sra_build_assignment (tree dst, tree src);\n static void mark_all_v_defs_seq (gimple_seq);\n-static void mark_all_v_defs_stmt (gimple);\n \n \f\n /* Return true if DECL is an SRA candidate.  */\n@@ -1057,11 +1053,10 @@ sra_walk_function (const struct sra_walk_fns *fns)\n \tni = si;\n \tgsi_next (&ni);\n \n-\t/* If the statement has no virtual operands, then it doesn't\n+\t/* If the statement does not reference memory, then it doesn't\n \t   make any structure references that we care about.  */\n-\tif (gimple_aliases_computed_p (cfun)\n-\t    && ZERO_SSA_OPERANDS (stmt, (SSA_OP_VIRTUAL_DEFS | SSA_OP_VUSE)))\n-\t      continue;\n+\tif (!gimple_references_memory_p (stmt))\n+\t  continue;\n \n \tswitch (gimple_code (stmt))\n \t  {\n@@ -2008,27 +2003,6 @@ decide_instantiations (void)\n \f\n /* Phase Four: Update the function to match the replacements created.  */\n \n-/* Mark all the variables in VDEF/VUSE operators for STMT for\n-   renaming. This becomes necessary when we modify all of a\n-   non-scalar.  */\n-\n-static void\n-mark_all_v_defs_stmt (gimple stmt)\n-{\n-  tree sym;\n-  ssa_op_iter iter;\n-\n-  update_stmt_if_modified (stmt);\n-\n-  FOR_EACH_SSA_TREE_OPERAND (sym, stmt, iter, SSA_OP_ALL_VIRTUALS)\n-    {\n-      if (TREE_CODE (sym) == SSA_NAME)\n-\tsym = SSA_NAME_VAR (sym);\n-      mark_sym_for_renaming (sym);\n-    }\n-}\n-\n-\n /* Mark all the variables in virtual operands in all the statements in\n    LIST for renaming.  */\n \n@@ -2038,7 +2012,7 @@ mark_all_v_defs_seq (gimple_seq seq)\n   gimple_stmt_iterator gsi;\n \n   for (gsi = gsi_start (seq); !gsi_end_p (gsi); gsi_next (&gsi))\n-    mark_all_v_defs_stmt (gsi_stmt (gsi));\n+    update_stmt_if_modified (gsi_stmt (gsi));\n }\n \n /* Mark every replacement under ELT with TREE_NO_WARNING.  */\n@@ -2863,6 +2837,7 @@ static void\n sra_replace (gimple_stmt_iterator *gsi, gimple_seq seq)\n {\n   sra_insert_before (gsi, seq);\n+  unlink_stmt_vdef (gsi_stmt (*gsi));\n   gsi_remove (gsi, false);\n   if (gsi_end_p (*gsi))\n     *gsi = gsi_last (gsi_seq (*gsi));\n@@ -3138,7 +3113,7 @@ scalarize_use (struct sra_elt *elt, tree *expr_p, gimple_stmt_iterator *gsi,\n \t  replacement = tmp;\n \t}\n       if (is_output)\n-\t  mark_all_v_defs_stmt (stmt);\n+\t  update_stmt_if_modified (stmt);\n       *expr_p = REPLDUP (replacement);\n       update_stmt (stmt);\n     }\n@@ -3358,7 +3333,7 @@ scalarize_copy (struct sra_elt *lhs_elt, struct sra_elt *rhs_elt,\n \t original block copy statement.  */\n \n       stmt = gsi_stmt (*gsi);\n-      mark_all_v_defs_stmt (stmt);\n+      update_stmt_if_modified (stmt);\n \n       seq = NULL;\n       generate_element_copy (lhs_elt, rhs_elt, &seq);\n@@ -3425,7 +3400,7 @@ scalarize_init (struct sra_elt *lhs_elt, tree rhs, gimple_stmt_iterator *gsi)\n       /* The LHS is fully instantiated.  The list of initializations\n \t replaces the original structure assignment.  */\n       gcc_assert (seq);\n-      mark_all_v_defs_stmt (gsi_stmt (*gsi));\n+      update_stmt_if_modified (gsi_stmt (*gsi));\n       mark_all_v_defs_seq (seq);\n       sra_replace (gsi, seq);\n     }\n@@ -3476,7 +3451,7 @@ scalarize_ldst (struct sra_elt *elt, tree other,\n       gimple_seq seq = NULL;\n       gimple stmt = gsi_stmt (*gsi);\n \n-      mark_all_v_defs_stmt (stmt);\n+      update_stmt_if_modified (stmt);\n       generate_copy_inout (elt, is_output, other, &seq);\n       gcc_assert (seq);\n       mark_all_v_defs_seq (seq);\n@@ -3637,7 +3612,6 @@ static unsigned int\n tree_sra (void)\n {\n   /* Initialize local variables.  */\n-  todoflags = 0;\n   gcc_obstack_init (&sra_obstack);\n   sra_candidates = BITMAP_ALLOC (NULL);\n   needs_copy_in = BITMAP_ALLOC (NULL);\n@@ -3650,8 +3624,6 @@ tree_sra (void)\n       scan_function ();\n       decide_instantiations ();\n       scalarize_function ();\n-      if (!bitmap_empty_p (sra_candidates))\n-\ttodoflags |= TODO_rebuild_alias;\n     }\n \n   /* Free allocated memory.  */\n@@ -3662,7 +3634,7 @@ tree_sra (void)\n   BITMAP_FREE (sra_type_decomp_cache);\n   BITMAP_FREE (sra_type_inst_cache);\n   obstack_free (&sra_obstack, NULL);\n-  return todoflags;\n+  return 0;\n }\n \n static unsigned int\n@@ -3674,7 +3646,7 @@ tree_sra_early (void)\n   ret = tree_sra ();\n   early_sra = false;\n \n-  return ret & ~TODO_rebuild_alias;\n+  return ret;\n }\n \n static bool\n@@ -3719,7 +3691,7 @@ struct gimple_opt_pass pass_sra =\n   PROP_cfg | PROP_ssa,\t\t\t/* properties_required */\n   0,\t\t\t\t\t/* properties_provided */\n   0,\t\t\t\t        /* properties_destroyed */\n-  0,\t\t\t\t\t/* todo_flags_start */\n+  TODO_update_address_taken,\t\t/* todo_flags_start */\n   TODO_dump_func\n   | TODO_update_ssa\n   | TODO_ggc_collect"}, {"sha": "f9cd5300ff2b9493db299d43d3754814ac8cb057", "filename": "gcc/tree-ssa-address.c", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-address.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-address.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-address.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -333,9 +333,9 @@ create_mem_ref_raw (tree type, struct mem_address *addr)\n   if (addr->offset && integer_zerop (addr->offset))\n     addr->offset = NULL_TREE;\n \n-  return build7 (TARGET_MEM_REF, type,\n+  return build6 (TARGET_MEM_REF, type,\n \t\t addr->symbol, addr->base, addr->index,\n-\t\t addr->step, addr->offset, NULL, NULL);\n+\t\t addr->step, addr->offset, NULL);\n }\n \n /* Returns true if OBJ is an object whose address is a link time constant.  */\n@@ -709,9 +709,6 @@ get_address_description (tree op, struct mem_address *addr)\n void\n copy_mem_ref_info (tree to, tree from)\n {\n-  /* Copy the annotation, to preserve the aliasing information.  */\n-  TMR_TAG (to) = TMR_TAG (from);\n-\n   /* And the info about the original reference.  */\n   TMR_ORIGINAL (to) = TMR_ORIGINAL (from);\n }"}, {"sha": "a85858e17af9d0928734d50013a5f2baf17be0bf", "filename": "gcc/tree-ssa-alias.c", "status": "modified", "additions": 827, "deletions": 3493, "changes": 4320, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-alias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-alias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-alias.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc"}, {"sha": "dfaa213d7947937e9512d078d51f532381bd4cdf", "filename": "gcc/tree-ssa-alias.h", "status": "added", "additions": 106, "deletions": 0, "changes": 106, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-alias.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-alias.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-alias.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -0,0 +1,106 @@\n+/* Tree based alias analysis and alias oracle.\n+   Copyright (C) 2008 Free Software Foundation, Inc.\n+   Contributed by Richard Guenther  <rguenther@suse.de>\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify\n+   under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3 of the License, or\n+   (at your option) any later version.\n+\n+   GCC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#ifndef TREE_SSA_ALIAS_H\n+#define TREE_SSA_ALIAS_H\n+\n+#include \"coretypes.h\"\n+\n+\n+/* The reasons a variable may escape a function.  */\n+enum escape_type \n+{\n+  NO_ESCAPE = 0,\t\t\t/* Doesn't escape.  */\n+  ESCAPE_STORED_IN_GLOBAL = 1 << 0,\n+  ESCAPE_TO_ASM = 1 << 1,\t\t/* Passed by address to an assembly\n+\t\t\t\t\t   statement.  */\n+  ESCAPE_TO_CALL = 1 << 2,\t\t/* Escapes to a function call.  */\n+  ESCAPE_BAD_CAST = 1 << 3,\t\t/* Cast from pointer to integer */\n+  ESCAPE_TO_RETURN = 1 << 4,\t\t/* Returned from function.  */\n+  ESCAPE_TO_PURE_CONST = 1 << 5,\t/* Escapes to a pure or constant\n+\t\t\t\t\t   function call.  */\n+  ESCAPE_IS_GLOBAL = 1 << 6,\t\t/* Is a global variable.  */\n+  ESCAPE_IS_PARM = 1 << 7,\t\t/* Is an incoming function argument.  */\n+  ESCAPE_UNKNOWN = 1 << 8\t\t/* We believe it escapes for\n+\t\t\t\t\t   some reason not enumerated\n+\t\t\t\t\t   above.  */\n+};\n+\n+\n+/* The points-to solution.\n+\n+   The points-to solution is a union of pt_vars and the abstract\n+   sets specified by the flags.  */\n+struct pt_solution GTY(())\n+{\n+  /* Nonzero if points-to analysis couldn't determine where this pointer\n+     is pointing to.  */\n+  unsigned int anything : 1;\n+\n+  /* Nonzero if the points-to set includes any global memory.  Note that\n+     even if this is zero pt_vars can still include global variables.  */\n+  unsigned int nonlocal : 1;\n+\n+  /* Nonzero if the points-to set includes any escaped local variable.  */\n+  unsigned int escaped : 1;\n+\n+  /* Nonzero if the points-to set includes 'nothing', the points-to set\n+     includes memory at address NULL.  */\n+  unsigned int null : 1;\n+\n+\n+  /* Nonzero if the pt_vars bitmap includes a global variable.  */\n+  unsigned int vars_contains_global : 1;\n+\n+  /* Set of variables that this pointer may point to.  */\n+  bitmap vars;\n+};\n+\n+\n+/* In tree-ssa-alias.c  */\n+extern enum escape_type is_escape_site (gimple);\n+extern bool ptr_deref_may_alias_global_p (tree);\n+extern bool refs_may_alias_p (tree, tree);\n+extern bool ref_maybe_used_by_stmt_p (gimple, tree);\n+extern bool stmt_may_clobber_ref_p (gimple, tree);\n+extern void *walk_non_aliased_vuses (tree, tree,\n+\t\t\t\t     void *(*)(tree, tree, void *), void *);\n+extern unsigned int walk_aliased_vdefs (tree, tree,\n+\t\t\t\t\tbool (*)(tree, tree, void *), void *,\n+\t\t\t\t\tbitmap *);\n+extern struct ptr_info_def *get_ptr_info (tree);\n+extern void dump_alias_info (FILE *);\n+extern void debug_alias_info (void);\n+extern void dump_points_to_info_for (FILE *, tree);\n+extern void debug_points_to_info_for (tree);\n+extern void dump_alias_stats (FILE *);\n+\n+\n+/* In tree-ssa-structalias.c  */\n+extern unsigned int compute_may_aliases (void);\n+extern void delete_alias_heapvars (void);\n+extern bool pt_solution_includes_global (struct pt_solution *);\n+extern bool pt_solution_includes (struct pt_solution *, const_tree);\n+extern bool pt_solutions_intersect (struct pt_solution *, struct pt_solution *);\n+extern void pt_solution_reset (struct pt_solution *);\n+extern void dump_pta_stats (FILE *);\n+\n+\n+#endif /* TREE_SSA_ALIAS_H  */"}, {"sha": "6d8e88e6d33a42fa2283868c427c5306216c9cae", "filename": "gcc/tree-ssa-ccp.c", "status": "modified", "additions": 14, "deletions": 11, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-ccp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-ccp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ccp.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -274,8 +274,7 @@ tree\n get_symbol_constant_value (tree sym)\n {\n   if (TREE_STATIC (sym)\n-      && TREE_READONLY (sym)\n-      && !MTAG_P (sym))\n+      && TREE_READONLY (sym))\n     {\n       tree val = DECL_INITIAL (sym);\n       if (val)\n@@ -528,8 +527,10 @@ likely_value (gimple stmt)\n \thas_constant_operand = true;\n     }\n \n-  /* There may be constants in regular rhs operands.  */\n-  for (i = is_gimple_call (stmt) + gimple_has_lhs (stmt);\n+  /* There may be constants in regular rhs operands.  For calls we\n+     have to ignore lhs, fndecl and static chain, otherwise only\n+     the lhs.  */\n+  for (i = (is_gimple_call (stmt) ? 2 : 0) + gimple_has_lhs (stmt);\n        i < gimple_num_ops (stmt); ++i)\n     {\n       tree op = gimple_op (stmt, i);\n@@ -601,7 +602,7 @@ surely_varying_stmt_p (gimple stmt)\n     }\n \n   /* Any other store operation is not interesting.  */\n-  else if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_DEFS))\n+  else if (gimple_vdef (stmt))\n     return true;\n \n   /* Anything other than assignments and conditional jumps are not\n@@ -3172,11 +3173,16 @@ gimplify_and_update_call_from_tree (gimple_stmt_iterator *si_p, tree expr)\n   }\n \n   if (lhs == NULL_TREE)\n-    new_stmt = gimple_build_nop ();\n+    {\n+      new_stmt = gimple_build_nop ();\n+      unlink_stmt_vdef (stmt);\n+      release_defs (stmt);\n+    }\n   else\n     {\n       new_stmt = gimple_build_assign (lhs, tmp);\n-      copy_virtual_operands (new_stmt, stmt);\n+      gimple_set_vuse (new_stmt, gimple_vuse (stmt));\n+      gimple_set_vdef (new_stmt, gimple_vdef (stmt));\n       move_ssa_defining_stmt_for_defs (new_stmt, stmt);\n     }\n \n@@ -3264,10 +3270,7 @@ execute_fold_all_builtins (void)\n \t  push_stmt_changes (gsi_stmt_ptr (&i));\n \n           if (!update_call_from_tree (&i, result))\n-            {\n-              gimplify_and_update_call_from_tree (&i, result);\n-              todoflags |= TODO_rebuild_alias;\n-            }\n+\t    gimplify_and_update_call_from_tree (&i, result);\n \n \t  stmt = gsi_stmt (i);\n \t  pop_stmt_changes (gsi_stmt_ptr (&i));"}, {"sha": "97f9f4099895e7c1b4d69f2a0516820c3a434fcb", "filename": "gcc/tree-ssa-coalesce.c", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-coalesce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-coalesce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-coalesce.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1114,12 +1114,9 @@ create_outofssa_var_map (coalesce_list_p cl, bitmap used_in_copy)\n \t    bitmap_set_bit (used_in_real_ops, DECL_UID (SSA_NAME_VAR (var)));\n \n \t  /* Validate that virtual ops don't get used in funny ways.  */\n-\t  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, SSA_OP_ALL_VIRTUALS)\n-\t    {\n-\t      bitmap_set_bit (used_in_virtual_ops, \n-\t\t\t      DECL_UID (SSA_NAME_VAR (var)));\n-\t    }\n-\n+\t  if (gimple_vuse (stmt))\n+\t    bitmap_set_bit (used_in_virtual_ops, \n+\t\t\t    DECL_UID (SSA_NAME_VAR (gimple_vuse (stmt))));\n #endif /* ENABLE_CHECKING */\n \t}\n     }"}, {"sha": "a02aee0ca4939ae5cff73465f3a5231917d9d24c", "filename": "gcc/tree-ssa-copy.c", "status": "modified", "additions": 23, "deletions": 130, "changes": 153, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-copy.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-copy.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-copy.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -72,24 +72,6 @@ may_propagate_copy (tree dest, tree orig)\n   if (TREE_CODE (dest) == SSA_NAME\n       && SSA_NAME_OCCURS_IN_ABNORMAL_PHI (dest))\n     return false;\n-\n-  /* For memory partitions, copies are OK as long as the memory symbol\n-     belongs to the partition.  */\n-  if (TREE_CODE (dest) == SSA_NAME\n-      && TREE_CODE (SSA_NAME_VAR (dest)) == MEMORY_PARTITION_TAG)\n-    return (TREE_CODE (orig) == SSA_NAME\n-            && !is_gimple_reg (orig)\n-\t    && (SSA_NAME_VAR (dest) == SSA_NAME_VAR (orig)\n-\t        || bitmap_bit_p (MPT_SYMBOLS (SSA_NAME_VAR (dest)),\n-\t                         DECL_UID (SSA_NAME_VAR (orig)))));\n-\n-  if (TREE_CODE (orig) == SSA_NAME\n-      && TREE_CODE (SSA_NAME_VAR (orig)) == MEMORY_PARTITION_TAG)\n-    return (TREE_CODE (dest) == SSA_NAME\n-            && !is_gimple_reg (dest)\n-\t    && (SSA_NAME_VAR (dest) == SSA_NAME_VAR (orig)\n-                || bitmap_bit_p (MPT_SYMBOLS (SSA_NAME_VAR (orig)),\n-\t                         DECL_UID (SSA_NAME_VAR (dest)))));\n   \n   /* Do not copy between types for which we *do* need a conversion.  */\n   if (!useless_type_conversion_p (type_d, type_o))\n@@ -136,48 +118,21 @@ may_propagate_copy (tree dest, tree orig)\n       && POINTER_TYPE_P (type_d)\n       && POINTER_TYPE_P (type_o))\n     {\n-      tree mt_dest = symbol_mem_tag (SSA_NAME_VAR (dest));\n-      tree mt_orig = symbol_mem_tag (SSA_NAME_VAR (orig));\n-      if (mt_dest && mt_orig && mt_dest != mt_orig)\n-\treturn false;\n-      else if (get_alias_set (TREE_TYPE (type_d)) != \n-\t       get_alias_set (TREE_TYPE (type_o)))\n+      if (get_alias_set (TREE_TYPE (type_d))\n+\t  != get_alias_set (TREE_TYPE (type_o)))\n \treturn false;\n-      else if (!MTAG_P (SSA_NAME_VAR (dest))\n-\t       && !MTAG_P (SSA_NAME_VAR (orig))\n-\t       && (DECL_NO_TBAA_P (SSA_NAME_VAR (dest))\n-\t\t   != DECL_NO_TBAA_P (SSA_NAME_VAR (orig))))\n+      else if (DECL_NO_TBAA_P (SSA_NAME_VAR (dest))\n+\t       != DECL_NO_TBAA_P (SSA_NAME_VAR (orig)))\n \treturn false;\n-\n-      /* Also verify flow-sensitive information is compatible.  */\n-      if (SSA_NAME_PTR_INFO (orig) && SSA_NAME_PTR_INFO (dest))\n-\t{\n-\t  struct ptr_info_def *orig_ptr_info = SSA_NAME_PTR_INFO (orig);\n-\t  struct ptr_info_def *dest_ptr_info = SSA_NAME_PTR_INFO (dest);\n-\n-\t  if (orig_ptr_info->name_mem_tag\n-\t      && dest_ptr_info->name_mem_tag\n-\t      && orig_ptr_info->pt_vars\n-\t      && dest_ptr_info->pt_vars\n-\t      && !bitmap_intersect_p (dest_ptr_info->pt_vars,\n-\t\t\t\t      orig_ptr_info->pt_vars))\n-\t    return false;\n-\t}\n     }\n \n-  /* If the destination is a SSA_NAME for a virtual operand, then we have\n-     some special cases to handle.  */\n+  /* Propagating virtual operands is always ok.  */\n   if (TREE_CODE (dest) == SSA_NAME && !is_gimple_reg (dest))\n     {\n-      /* If both operands are SSA_NAMEs referring to virtual operands, then\n-\t we can always propagate.  */\n-      if (TREE_CODE (orig) == SSA_NAME\n-\t  && !is_gimple_reg (orig))\n-\treturn true;\n-\n-      /* We have a \"copy\" from something like a constant into a virtual\n-\t operand.  Reject these.  */\n-      return false;\n+      /* But only between virtual operands.  */\n+      gcc_assert (TREE_CODE (orig) == SSA_NAME && !is_gimple_reg (orig));\n+\n+      return true;\n     }\n \n   /* Anything else is OK.  */\n@@ -211,8 +166,7 @@ may_propagate_copy_into_stmt (gimple dest, tree orig)\n      is much simpler.  */\n \n   if (TREE_CODE (orig) == SSA_NAME\n-      && (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (orig)\n-          ||  TREE_CODE (SSA_NAME_VAR (orig)) == MEMORY_PARTITION_TAG))\n+      && SSA_NAME_OCCURS_IN_ABNORMAL_PHI (orig))\n     return false;\n \n   if (is_gimple_assign (dest))\n@@ -252,29 +206,13 @@ may_propagate_copy_into_asm (tree dest)\n void\n merge_alias_info (tree orig_name, tree new_name)\n {\n-  tree new_sym = SSA_NAME_VAR (new_name);\n-  tree orig_sym = SSA_NAME_VAR (orig_name);\n-  var_ann_t new_ann = var_ann (new_sym);\n-  var_ann_t orig_ann = var_ann (orig_sym);\n-\n-  /* No merging necessary when memory partitions are involved.  */\n-  if (factoring_name_p (new_name))\n-    {\n-      gcc_assert (!is_gimple_reg (orig_sym));\n-      return;\n-    }\n-  else if (factoring_name_p (orig_name))\n-    {\n-      gcc_assert (!is_gimple_reg (new_sym));\n-      return;\n-    }\n-\n   gcc_assert (POINTER_TYPE_P (TREE_TYPE (orig_name))\n \t      && POINTER_TYPE_P (TREE_TYPE (new_name)));\n \n #if defined ENABLE_CHECKING\n   gcc_assert (useless_type_conversion_p (TREE_TYPE (orig_name),\n-\t\t\t\t\tTREE_TYPE (new_name)));\n+\t\t\t\t\t TREE_TYPE (new_name)));\n+#endif\n \n   /* Check that flow-sensitive information is compatible.  Notice that\n      we may not merge flow-sensitive information here.  This function\n@@ -290,58 +228,12 @@ merge_alias_info (tree orig_name, tree new_name)\n      same in every block dominated by the predicate.\n \n      Since we cannot distinguish one case from another in this\n-     function, we can only make sure that if P_i and Q_j have\n-     flow-sensitive information, they should be compatible.\n-\n-     As callers of merge_alias_info are supposed to call may_propagate_copy\n-     first, the following check is redundant.  Thus, only do it if checking\n-     is enabled.  */\n-  if (SSA_NAME_PTR_INFO (orig_name) && SSA_NAME_PTR_INFO (new_name))\n-    {\n-      struct ptr_info_def *orig_ptr_info = SSA_NAME_PTR_INFO (orig_name);\n-      struct ptr_info_def *new_ptr_info = SSA_NAME_PTR_INFO (new_name);\n-\n-      /* Note that pointer NEW and ORIG may actually have different\n-\t pointed-to variables (e.g., PR 18291 represented in\n-\t testsuite/gcc.c-torture/compile/pr18291.c).  However, since\n-\t NEW is being copy-propagated into ORIG, it must always be\n-\t true that the pointed-to set for pointer NEW is the same, or\n-\t a subset, of the pointed-to set for pointer ORIG.  If this\n-\t isn't the case, we shouldn't have been able to do the\n-\t propagation of NEW into ORIG.  */\n-      if (orig_ptr_info->name_mem_tag\n-\t  && new_ptr_info->name_mem_tag\n-\t  && orig_ptr_info->pt_vars\n-\t  && new_ptr_info->pt_vars)\n-\tgcc_assert (bitmap_intersect_p (new_ptr_info->pt_vars,\n-\t\t\t\t\torig_ptr_info->pt_vars));\n-    }\n-#endif\n+     function, we cannot merge flow-sensitive information by\n+     intersecting.  Instead the only thing we can do is to _not_\n+     merge flow-sensitive information.\n \n-  /* Synchronize the symbol tags.  If both pointers had a tag and they\n-     are different, then something has gone wrong.  Symbol tags can\n-     always be merged because they are flow insensitive, all the SSA\n-     names of the same base DECL share the same symbol tag.  */\n-  if (new_ann->symbol_mem_tag == NULL_TREE)\n-    new_ann->symbol_mem_tag = orig_ann->symbol_mem_tag;\n-  else if (orig_ann->symbol_mem_tag == NULL_TREE)\n-    orig_ann->symbol_mem_tag = new_ann->symbol_mem_tag;\n-  else\n-    gcc_assert (new_ann->symbol_mem_tag == orig_ann->symbol_mem_tag);\n-\n-  /* Copy flow-sensitive alias information in case that NEW_NAME\n-     didn't get a NMT but was set to pt_anything for optimization\n-     purposes.  In case ORIG_NAME has a NMT we can safely use its\n-     flow-sensitive alias information as a conservative estimate.  */\n-  if (SSA_NAME_PTR_INFO (orig_name)\n-      && SSA_NAME_PTR_INFO (orig_name)->name_mem_tag\n-      && (!SSA_NAME_PTR_INFO (new_name)\n-\t  || !SSA_NAME_PTR_INFO (new_name)->name_mem_tag))\n-    {\n-      struct ptr_info_def *orig_ptr_info = SSA_NAME_PTR_INFO (orig_name);\n-      struct ptr_info_def *new_ptr_info = get_ptr_info (new_name);\n-      memcpy (new_ptr_info, orig_ptr_info, sizeof (struct ptr_info_def));\n-    }\n+     ???  At some point we should enhance this machinery to distinguish\n+     both cases in the caller.  */\n }\n \n \n@@ -464,8 +356,7 @@ propagate_tree_value_into_stmt (gimple_stmt_iterator *gsi, tree val)\n \n       tree expr = NULL_TREE;\n       propagate_tree_value (&expr, val);\n-      new_stmt  = gimple_build_assign (gimple_call_lhs (stmt), expr);\n-      copy_virtual_operands (new_stmt, stmt);\n+      new_stmt = gimple_build_assign (gimple_call_lhs (stmt), expr);\n       move_ssa_defining_stmt_for_defs (new_stmt, stmt);\n       gsi_replace (gsi, new_stmt, false);\n     }\n@@ -513,7 +404,7 @@ stmt_may_generate_copy (gimple stmt)\n     return false;\n \n   /* Statements with loads and/or stores will never generate a useful copy.  */\n-  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS))\n+  if (gimple_vuse (stmt))\n     return false;\n \n   /* Otherwise, the only statements that generate useful copies are\n@@ -864,8 +755,10 @@ copy_prop_visit_phi_node (gimple phi)\n \t Otherwise, this may move loop variant variables outside of\n \t their loops and prevent coalescing opportunities.  If the\n \t value was loop invariant, it will be hoisted by LICM and\n-\t exposed for copy propagation.  */\n-      if (loop_depth_of_name (arg) > loop_depth_of_name (lhs))\n+\t exposed for copy propagation.  Not a problem for virtual\n+\t operands though.  */\n+      if (is_gimple_reg (lhs)\n+\t  && loop_depth_of_name (arg) > loop_depth_of_name (lhs))\n \t{\n \t  phi_val.value = lhs;\n \t  break;"}, {"sha": "e89824f74f9b38d37735b6dafc848229043a9007", "filename": "gcc/tree-ssa-copyrename.c", "status": "modified", "additions": 1, "deletions": 23, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-copyrename.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-copyrename.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-copyrename.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -115,7 +115,6 @@ copy_rename_partition_coalesce (var_map map, tree var1, tree var2, FILE *debug)\n   int p1, p2, p3;\n   tree root1, root2;\n   tree rep1, rep2;\n-  var_ann_t ann1, ann2, ann3;\n   bool ign1, ign2, abnorm;\n \n   gcc_assert (TREE_CODE (var1) == SSA_NAME);\n@@ -144,9 +143,6 @@ copy_rename_partition_coalesce (var_map map, tree var1, tree var2, FILE *debug)\n   root1 = SSA_NAME_VAR (rep1);\n   root2 = SSA_NAME_VAR (rep2);\n \n-  ann1 = var_ann (root1);\n-  ann2 = var_ann (root2);\n-\n   if (p1 == p2)\n     {\n       if (debug)\n@@ -207,16 +203,6 @@ copy_rename_partition_coalesce (var_map map, tree var1, tree var2, FILE *debug)\n \t}\n     }\n \n-  /* Don't coalesce if there are two different memory tags.  */\n-  if (ann1->symbol_mem_tag\n-      && ann2->symbol_mem_tag\n-      && ann1->symbol_mem_tag != ann2->symbol_mem_tag)\n-    {\n-      if (debug)\n-\tfprintf (debug, \" : 2 memory tags. No coalesce.\\n\");\n-      return false;\n-    }\n-\n   /* If both values have default defs, we can't coalesce.  If only one has a \n      tag, make sure that variable is the new root partition.  */\n   if (gimple_default_def (cfun, root1))\n@@ -252,8 +238,7 @@ copy_rename_partition_coalesce (var_map map, tree var1, tree var2, FILE *debug)\n       && POINTER_TYPE_P (TREE_TYPE (root2))\n       && ((get_alias_set (TREE_TYPE (TREE_TYPE (root1)))\n \t   != get_alias_set (TREE_TYPE (TREE_TYPE (root2))))\n-\t  || ((DECL_P (root1) && !MTAG_P (root1))\n-\t      && (DECL_P (root2) && !MTAG_P (root2))\n+\t  || (DECL_P (root1) && DECL_P (root2)\n \t      && DECL_NO_TBAA_P (root1) != DECL_NO_TBAA_P (root2))))\n     {\n       if (debug)\n@@ -272,13 +257,6 @@ copy_rename_partition_coalesce (var_map map, tree var1, tree var2, FILE *debug)\n   else if (!ign1)\n     replace_ssa_name_symbol (partition_to_var (map, p3), root1);\n \n-  /* Update the various flag widgitry of the current base representative.  */\n-  ann3 = var_ann (SSA_NAME_VAR (partition_to_var (map, p3)));\n-  if (ann1->symbol_mem_tag)\n-    ann3->symbol_mem_tag = ann1->symbol_mem_tag;\n-  else\n-    ann3->symbol_mem_tag = ann2->symbol_mem_tag;\n-\n   if (debug)\n     {\n       fprintf (debug, \" --> P%d \", p3);"}, {"sha": "0c2057104251ddee8bcf7e985c70d932f60938f6", "filename": "gcc/tree-ssa-dce.c", "status": "modified", "additions": 307, "deletions": 24, "changes": 331, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-dce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-dce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dce.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -233,7 +233,12 @@ mark_operand_necessary (tree op)\n \n   ver = SSA_NAME_VERSION (op);\n   if (TEST_BIT (processed, ver))\n-    return;\n+    {\n+      stmt = SSA_NAME_DEF_STMT (op);\n+      gcc_assert (gimple_nop_p (stmt)\n+\t\t  || gimple_plf (stmt, STMT_NECESSARY));\n+      return;\n+    }\n   SET_BIT (processed, ver);\n \n   stmt = SSA_NAME_DEF_STMT (op);\n@@ -242,6 +247,14 @@ mark_operand_necessary (tree op)\n   if (gimple_plf (stmt, STMT_NECESSARY) || gimple_nop_p (stmt))\n     return;\n \n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    {\n+      fprintf (dump_file, \"marking necessary through \");\n+      print_generic_expr (dump_file, op, 0);\n+      fprintf (dump_file, \" stmt \");\n+      print_gimple_stmt (dump_file, stmt, 0, 0);\n+    }\n+\n   gimple_set_plf (stmt, STMT_NECESSARY, true);\n   VEC_safe_push (gimple, heap, worklist, stmt);\n }\n@@ -429,6 +442,133 @@ find_obviously_necessary_stmts (struct edge_list *el)\n }\n \n \n+/* Return true if REF is based on an aliased base, otherwise false.  */\n+\n+static bool\n+ref_may_be_aliased (tree ref)\n+{\n+  while (handled_component_p (ref))\n+    ref = TREE_OPERAND (ref, 0);\n+  return !(DECL_P (ref)\n+\t   && !may_be_aliased (ref));\n+}\n+\n+struct ref_data {\n+  tree base;\n+  HOST_WIDE_INT size;\n+  HOST_WIDE_INT offset;\n+  HOST_WIDE_INT max_size;\n+};\n+\n+static bitmap visited = NULL;\n+static unsigned int longest_chain = 0;\n+static unsigned int total_chain = 0;\n+static bool chain_ovfl = false;\n+\n+/* Worker for the walker that marks reaching definitions of REF,\n+   which is based on a non-aliased decl, necessary.  It returns\n+   true whenever the defining statement of the current VDEF is\n+   a kill for REF, as no dominating may-defs are necessary for REF\n+   anymore.  DATA points to cached get_ref_base_and_extent data for REF.  */\n+\n+static bool\n+mark_aliased_reaching_defs_necessary_1 (tree ref, tree vdef, void *data)\n+{\n+  gimple def_stmt = SSA_NAME_DEF_STMT (vdef);\n+  struct ref_data *refd = (struct ref_data *)data;\n+\n+  /* All stmts we visit are necessary.  */\n+  mark_operand_necessary (vdef);\n+\n+  /* If the stmt lhs kills ref, then we can stop walking.  */\n+  if (gimple_has_lhs (def_stmt)\n+      && TREE_CODE (gimple_get_lhs (def_stmt)) != SSA_NAME)\n+    {\n+      tree base, lhs = gimple_get_lhs (def_stmt);\n+      HOST_WIDE_INT size, offset, max_size;\n+      base = get_ref_base_and_extent (lhs, &offset, &size, &max_size);\n+      /* We can get MEM[symbol: sZ, index: D.8862_1] here,\n+\t so base == refd->base does not always hold.  */\n+      if (base == refd->base)\n+\t{\n+\t  /* For a must-alias check we need to be able to constrain\n+\t     the accesses properly.  */\n+\t  if (size != -1 && size == max_size\n+\t      && refd->max_size != -1)\n+\t    {\n+\t      if (offset <= refd->offset\n+\t\t  && offset + size >= refd->offset + refd->max_size)\n+\t\treturn true;\n+\t    }\n+\t  /* Or they need to be exactly the same.  */\n+\t  else if (operand_equal_p (ref, lhs, 0))\n+\t    return true;\n+\t}\n+    }\n+\n+  /* Otherwise keep walking.  */\n+  return false;\n+}\n+\n+static void\n+mark_aliased_reaching_defs_necessary (gimple stmt, tree ref)\n+{\n+  struct ref_data refd;\n+  unsigned int chain;\n+  gcc_assert (!chain_ovfl);\n+  refd.base = get_ref_base_and_extent (ref, &refd.offset, &refd.size,\n+\t\t\t\t       &refd.max_size);\n+  chain = walk_aliased_vdefs (ref, gimple_vuse (stmt),\n+\t\t\t      mark_aliased_reaching_defs_necessary_1,\n+\t\t\t      &refd, NULL);\n+  if (chain > longest_chain)\n+    longest_chain = chain;\n+  total_chain += chain;\n+}\n+\n+/* Worker for the walker that marks reaching definitions of REF, which\n+   is not based on a non-aliased decl.  For simplicity we need to end\n+   up marking all may-defs necessary that are not based on a non-aliased\n+   decl.  The only job of this walker is to skip may-defs based on\n+   a non-aliased decl.  */\n+\n+static bool\n+mark_all_reaching_defs_necessary_1 (tree ref ATTRIBUTE_UNUSED,\n+\t\t\t\ttree vdef, void *data ATTRIBUTE_UNUSED)\n+{\n+  gimple def_stmt = SSA_NAME_DEF_STMT (vdef);\n+\n+  /* We have to skip already visited (and thus necessary) statements\n+     to make the chaining work after we dropped back to simple mode.  */\n+  if (chain_ovfl\n+      && TEST_BIT (processed, SSA_NAME_VERSION (vdef)))\n+    {\n+      gcc_assert (gimple_nop_p (def_stmt)\n+\t\t  || gimple_plf (def_stmt, STMT_NECESSARY));\n+      return false;\n+    }\n+\n+  /* We want to skip stores to non-aliased variables.  */\n+  if (!chain_ovfl\n+      && gimple_assign_single_p (def_stmt))\n+    {\n+      tree lhs = gimple_assign_lhs (def_stmt);\n+      if (!ref_may_be_aliased (lhs))\n+\treturn false;\n+    }\n+\n+  /* But can stop after the first necessary statement.  */\n+  mark_operand_necessary (vdef);\n+  return true;\n+}\n+\n+static void\n+mark_all_reaching_defs_necessary (gimple stmt)\n+{\n+  walk_aliased_vdefs (NULL, gimple_vuse (stmt),\n+\t\t      mark_all_reaching_defs_necessary_1, NULL, &visited);\n+}\n+\n /* Propagate necessity using the operands of necessary statements.\n    Process the uses on each statement in the worklist, and add all\n    feeding statements which contribute to the calculation of this\n@@ -471,7 +611,10 @@ propagate_necessity (struct edge_list *el)\n \t    }\n \t}\n \n-      if (gimple_code (stmt) == GIMPLE_PHI)\n+      if (gimple_code (stmt) == GIMPLE_PHI\n+\t  /* We do not process virtual PHI nodes nor do we track their\n+\t     necessity.  */\n+\t  && is_gimple_reg (gimple_phi_result (stmt)))\n \t{\n \t  /* PHI nodes are somewhat special in that each PHI alternative has\n \t     data and control dependencies.  All the statements feeding the\n@@ -506,16 +649,121 @@ propagate_necessity (struct edge_list *el)\n \t{\n \t  /* Propagate through the operands.  Examine all the USE, VUSE and\n \t     VDEF operands in this statement.  Mark all the statements \n-\t     which feed this statement's uses as necessary.  The\n-\t     operands of VDEF expressions are also needed as they\n-\t     represent potential definitions that may reach this\n-\t     statement (VDEF operands allow us to follow def-def\n-\t     links).  */\n+\t     which feed this statement's uses as necessary.  */\n \t  ssa_op_iter iter;\n \t  tree use;\n \n-\t  FOR_EACH_SSA_TREE_OPERAND (use, stmt, iter, SSA_OP_ALL_USES)\n+\t  FOR_EACH_SSA_TREE_OPERAND (use, stmt, iter, SSA_OP_USE)\n \t    mark_operand_necessary (use);\n+\n+\t  use = gimple_vuse (stmt);\n+\t  if (!use)\n+\t    continue;\n+\n+\t  /* If we dropped to simple mode make all immediately\n+\t     reachable definitions necessary.  */\n+\t  if (chain_ovfl)\n+\t    {\n+\t      mark_all_reaching_defs_necessary (stmt);\n+\t      continue;\n+\t    }\n+\n+\t  /* For statements that may load from memory (have a VUSE) we\n+\t     have to mark all reaching (may-)definitions as necessary.\n+\t     We partition this task into two cases:\n+\t      1) explicit loads based on decls that are not aliased\n+\t      2) implicit loads (like calls) and explicit loads not\n+\t         based on decls that are not aliased (like indirect\n+\t\t references or loads from globals)\n+\t     For 1) we mark all reaching may-defs as necessary, stopping\n+\t     at dominating kills.  For 2) we want to mark all dominating\n+\t     references necessary, but non-aliased ones which we handle\n+\t     in 1).  Instead of doing so for each load we rely on the\n+\t     worklist to eventually reach all dominating references and\n+\t     instead just mark the immediately dominating references\n+\t     as necessary (but skipping non-aliased ones).  */\n+\n+\t  if (is_gimple_call (stmt))\n+\t    {\n+\t      unsigned i;\n+\n+\t      /* Calls implicitly load from memory, their arguments\n+\t         in addition may explicitly perform memory loads.\n+\t\t This also ensures propagation for case 2 for stores.  */\n+\t      mark_all_reaching_defs_necessary (stmt);\n+\t      for (i = 0; i < gimple_call_num_args (stmt); ++i)\n+\t\t{\n+\t\t  tree arg = gimple_call_arg (stmt, i);\n+\t\t  if (TREE_CODE (arg) == SSA_NAME\n+\t\t      || is_gimple_min_invariant (arg))\n+\t\t    continue;\n+\t\t  if (!ref_may_be_aliased (arg))\n+\t\t    mark_aliased_reaching_defs_necessary (stmt, arg);\n+\t\t}\n+\t    }\n+\t  else if (gimple_assign_single_p (stmt))\n+\t    {\n+\t      tree lhs, rhs;\n+\t      bool rhs_aliased = false;\n+\t      /* If this is a load mark things necessary.  */\n+\t      rhs = gimple_assign_rhs1 (stmt);\n+\t      if (TREE_CODE (rhs) != SSA_NAME\n+\t\t  && !is_gimple_min_invariant (rhs))\n+\t\t{\n+\t\t  if (!ref_may_be_aliased (rhs))\n+\t\t    mark_aliased_reaching_defs_necessary (stmt, rhs);\n+\t\t  else\n+\t\t    rhs_aliased = true;\n+\t\t}\n+\t      /* If this is an aliased store, mark things necessary.\n+\t\t This is where we make sure to propagate for case 2.  */\n+\t      lhs = gimple_assign_lhs (stmt);\n+\t      if (rhs_aliased\n+\t\t  || (TREE_CODE (lhs) != SSA_NAME\n+\t\t      && ref_may_be_aliased (lhs)))\n+\t\tmark_all_reaching_defs_necessary (stmt);\n+\t    }\n+\t  else if (gimple_code (stmt) == GIMPLE_RETURN)\n+\t    {\n+\t      tree rhs = gimple_return_retval (stmt);\n+\t      /* A return statement may perform a load.  */\n+\t      if (TREE_CODE (rhs) != SSA_NAME\n+\t\t  && !is_gimple_min_invariant (rhs))\n+\t\t{\n+\t\t  if (!ref_may_be_aliased (rhs))\n+\t\t    mark_aliased_reaching_defs_necessary (stmt, rhs);\n+\t\t  else\n+\t\t    mark_all_reaching_defs_necessary (stmt);\n+\t\t}\n+\t    }\n+\t  else if (gimple_code (stmt) == GIMPLE_ASM)\n+\t    {\n+\t      unsigned i;\n+\t      mark_all_reaching_defs_necessary (stmt);\n+\t      /* Inputs may perform loads.  */\n+\t      for (i = 0; i < gimple_asm_ninputs (stmt); ++i)\n+\t\t{\n+\t\t  tree op = TREE_VALUE (gimple_asm_input_op (stmt, i));\n+\t\t  if (TREE_CODE (op) != SSA_NAME\n+\t\t      && !is_gimple_min_invariant (op)\n+\t\t      && !ref_may_be_aliased (op))\n+\t\t    mark_aliased_reaching_defs_necessary (stmt, op);\n+\t\t}\n+\t    }\n+\t  else\n+\t    gcc_unreachable ();\n+\n+\t  /* If we over-used our alias oracle budget drop to simple\n+\t     mode.  The cost metric allows quadratic behavior up to\n+\t     a constant maximal chain and after that falls back to\n+\t     super-linear complexity.  */\n+\t  if (longest_chain > 256\n+\t      && total_chain > 256 * longest_chain)\n+\t    {\n+\t      chain_ovfl = true;\n+\t      if (visited)\n+\t\tbitmap_clear (visited);\n+\t    }\n \t}\n     }\n }\n@@ -537,6 +785,40 @@ remove_dead_phis (basic_block bb)\n       stats.total_phis++;\n       phi = gsi_stmt (gsi);\n \n+      /* We do not track necessity of virtual PHI nodes.  Instead do\n+         very simple dead PHI removal here.  */\n+      if (!is_gimple_reg (gimple_phi_result (phi)))\n+\t{\n+\t  unsigned i;\n+\t  tree vuse;\n+\n+\t  /* Virtual PHI nodes with one or identical arguments\n+\t     can be removed.  */\n+\t  vuse = gimple_phi_arg_def (phi, 0);\n+\t  for (i = 1; i < gimple_phi_num_args (phi); ++i)\n+\t    {\n+\t      if (gimple_phi_arg_def (phi, i) != vuse)\n+\t\t{\n+\t\t  vuse = NULL_TREE;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\t  if (vuse != NULL_TREE)\n+\t    {\n+\t      tree vdef = gimple_phi_result (phi);\n+\t      use_operand_p use_p;\n+\t      imm_use_iterator iter;\n+\t      gimple use_stmt;\n+\t      FOR_EACH_IMM_USE_STMT (use_stmt, iter, vdef)\n+\t\tFOR_EACH_IMM_USE_ON_STMT (use_p, iter)\n+\t\t  SET_USE (use_p, vuse);\n+\t      if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (vdef))\n+\t\tSSA_NAME_OCCURS_IN_ABNORMAL_PHI (vuse) = 1;\n+\t    }\n+\t  else\n+\t    gimple_set_plf (phi, STMT_NECESSARY, true);\n+\t}\n+\n       if (!gimple_plf (phi, STMT_NECESSARY))\n \t{\n \t  something_changed = true;\n@@ -549,11 +831,10 @@ remove_dead_phis (basic_block bb)\n \n \t  remove_phi_node (&gsi, true);\n \t  stats.removed_phis++;\n+\t  continue;\n \t}\n-      else\n-\t{\n-          gsi_next (&gsi);\n-\t}\n+\n+      gsi_next (&gsi);\n     }\n   return something_changed;\n }\n@@ -643,7 +924,8 @@ remove_dead_stmt (gimple_stmt_iterator *i, basic_block bb)\n           remove_edge (EDGE_SUCC (bb, 1));\n \t}\n     }\n-  \n+\n+  unlink_stmt_vdef (stmt);\n   gsi_remove (i, true);  \n   release_defs (stmt); \n }\n@@ -665,11 +947,6 @@ eliminate_unnecessary_stmts (void)\n     fprintf (dump_file, \"\\nEliminating unnecessary statements:\\n\");\n \n   clear_special_calls ();\n-  FOR_EACH_BB (bb)\n-    {\n-      /* Remove dead PHI nodes.  */\n-      something_changed |= remove_dead_phis (bb);\n-    }\n \n   FOR_EACH_BB (bb)\n     {\n@@ -692,7 +969,6 @@ eliminate_unnecessary_stmts (void)\n \t      if (call)\n \t\t{\n \t\t  tree name;\n-\t\t  gimple g;\n \n \t\t  /* When LHS of var = call (); is dead, simplify it into\n \t\t     call (); saving one operand.  */\n@@ -709,11 +985,8 @@ eliminate_unnecessary_stmts (void)\n \t\t\t}\n \t\t      \n \t\t      push_stmt_changes (gsi_stmt_ptr (&gsi));\n-\t\t      g = gimple_copy (stmt);\n-\t\t      gimple_call_set_lhs (g, NULL_TREE);\n-\t\t      gsi_replace (&gsi, g, false);\n-\t\t      maybe_clean_or_replace_eh_stmt (stmt, g);\n-\t\t      mark_symbols_for_renaming (g);\n+\t\t      gimple_call_set_lhs (stmt, NULL_TREE);\n+\t\t      maybe_clean_or_replace_eh_stmt (stmt, stmt);\n \t\t      pop_stmt_changes (gsi_stmt_ptr (&gsi));\n \t\t      release_ssa_name (name);\n \t\t    }\n@@ -728,6 +1001,12 @@ eliminate_unnecessary_stmts (void)\n \t}\n     }\n \n+  FOR_EACH_BB (bb)\n+    {\n+      /* Remove dead PHI nodes.  */\n+      something_changed |= remove_dead_phis (bb);\n+    }\n+\n   return something_changed;\n }\n \n@@ -839,7 +1118,11 @@ perform_tree_ssa_dce (bool aggressive)\n \n   find_obviously_necessary_stmts (el);\n \n+  longest_chain = 0;\n+  total_chain = 0;\n+  chain_ovfl = false;\n   propagate_necessity (el);\n+  BITMAP_FREE (visited);\n \n   something_changed |= eliminate_unnecessary_stmts ();\n   something_changed |= cfg_altered;"}, {"sha": "e2909e8033fe5af985f3cedc3b30eb2cb691974a", "filename": "gcc/tree-ssa-dom.c", "status": "modified", "additions": 6, "deletions": 11, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-dom.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-dom.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dom.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -134,10 +134,6 @@ static VEC(expr_hash_elt_t,heap) *avail_exprs_stack;\n    expressions are removed from AVAIL_EXPRS.  Else we may change the\n    hash code for an expression and be unable to find/remove it from\n    AVAIL_EXPRS.  */\n-typedef gimple *gimple_p;\n-DEF_VEC_P(gimple_p);\n-DEF_VEC_ALLOC_P(gimple_p,heap);\n-\n static VEC(gimple_p,heap) *stmts_to_rescan;\n \n /* Structure for entries in the expression hash table.  */\n@@ -1841,7 +1837,7 @@ eliminate_redundant_computations (gimple_stmt_iterator* gsi)\n   if (! def\n       || TREE_CODE (def) != SSA_NAME\n       || SSA_NAME_OCCURS_IN_ABNORMAL_PHI (def)\n-      || !ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF)\n+      || gimple_vdef (stmt)\n       /* Do not record equivalences for increments of ivs.  This would create\n \t overlapping live ranges for a very questionable gain.  */\n       || simple_iv_increment_p (stmt))\n@@ -2021,7 +2017,7 @@ record_equivalences_from_stmt (gimple stmt, int may_optimize_p)\n       else\n         new_stmt = gimple_build_assign (rhs, lhs);\n \n-      create_ssa_artificial_load_stmt (new_stmt, stmt, true);\n+      gimple_set_vuse (new_stmt, gimple_vdef (stmt));\n \n       /* Finally enter the statement into the available expression\n \t table.  */\n@@ -2405,7 +2401,6 @@ avail_expr_hash (const void *p)\n   gimple stmt = ((const struct expr_hash_elt *)p)->stmt;\n   const struct hashable_expr *expr = &((const struct expr_hash_elt *)p)->expr;\n   tree vuse;\n-  ssa_op_iter iter;\n   hashval_t val = 0;\n \n   val = iterative_hash_hashable_expr (expr, val);\n@@ -2416,11 +2411,11 @@ avail_expr_hash (const void *p)\n   if (!stmt)\n     return val;\n \n-  /* Add the SSA version numbers of every vuse operand.  This is important\n+  /* Add the SSA version numbers of the vuse operand.  This is important\n      because compound variables like arrays are not renamed in the\n      operands.  Rather, the rename is done on the virtual variable\n      representing all the elements of the array.  */\n-  FOR_EACH_SSA_TREE_OPERAND (vuse, stmt, iter, SSA_OP_VUSE)\n+  if ((vuse = gimple_vuse (stmt)))\n     val = iterative_hash_expr (vuse, val);\n \n   return val;\n@@ -2462,8 +2457,8 @@ avail_expr_eq (const void *p1, const void *p2)\n       && types_compatible_p (expr1->type, expr2->type))\n     {\n       /* Note that STMT1 and/or STMT2 may be NULL.  */\n-      bool ret = compare_ssa_operands_equal (stmt1, stmt2, SSA_OP_VUSE);\n-      return ret;\n+      return ((stmt1 ? gimple_vuse (stmt1) : NULL_TREE)\n+\t      == (stmt2 ? gimple_vuse (stmt2) : NULL_TREE));\n     }\n \n   return false;"}, {"sha": "315b5507b711e9a18e58dd38b7aa23f14bcd9452", "filename": "gcc/tree-ssa-dse.c", "status": "modified", "additions": 99, "deletions": 407, "changes": 506, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-dse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-dse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dse.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -84,13 +84,6 @@ struct dse_block_local_data\n   bitmap stores;\n };\n \n-/* Basic blocks of the potentially dead store and the following\n-   store, for memory_address_same.  */\n-struct address_walk_data\n-{\n-  basic_block store1_bb, store2_bb;\n-};\n-\n static bool gate_dse (void);\n static unsigned int tree_ssa_dse (void);\n static void dse_initialize_block_local_data (struct dom_walk_data *,\n@@ -151,218 +144,112 @@ dse_initialize_block_local_data (struct dom_walk_data *walk_data,\n     }\n }\n \n-/* Helper function for memory_address_same via walk_tree.  Returns\n-   non-NULL if it finds an SSA_NAME which is part of the address,\n-   such that the definition of the SSA_NAME post-dominates the store\n-   we want to delete but not the store that we believe makes it\n-   redundant.  This indicates that the address may change between\n-   the two stores.  */\n-\n-static tree\n-memory_ssa_name_same (tree *expr_p, int *walk_subtrees ATTRIBUTE_UNUSED,\n-\t\t      void *data)\n-{\n-  struct address_walk_data *walk_data = (struct address_walk_data *) data;\n-  tree expr = *expr_p;\n-  gimple def_stmt;\n-  basic_block def_bb;\n-\n-  if (TREE_CODE (expr) != SSA_NAME)\n-    return NULL_TREE;\n-\n-  /* If we've found a default definition, then there's no problem.  Both\n-     stores will post-dominate it.  And def_bb will be NULL.  */\n-  if (SSA_NAME_IS_DEFAULT_DEF (expr))\n-    return NULL_TREE;\n-\n-  def_stmt = SSA_NAME_DEF_STMT (expr);\n-  def_bb = gimple_bb (def_stmt);\n-\n-  /* DEF_STMT must dominate both stores.  So if it is in the same\n-     basic block as one, it does not post-dominate that store.  */\n-  if (walk_data->store1_bb != def_bb\n-      && dominated_by_p (CDI_POST_DOMINATORS, walk_data->store1_bb, def_bb))\n-    {\n-      if (walk_data->store2_bb == def_bb\n-\t  || !dominated_by_p (CDI_POST_DOMINATORS, walk_data->store2_bb,\n-\t\t\t      def_bb))\n-\t/* Return non-NULL to stop the walk.  */\n-\treturn *expr_p;\n-    }\n-\n-  return NULL_TREE;\n-}\n-\n-/* Return TRUE if the destination memory address in STORE1 and STORE2\n-   might be modified after STORE1, before control reaches STORE2.  */\n-\n-static bool\n-memory_address_same (gimple store1, gimple store2)\n-{\n-  struct address_walk_data walk_data;\n-\n-  walk_data.store1_bb = gimple_bb (store1);\n-  walk_data.store2_bb = gimple_bb (store2);\n-\n-  return (walk_tree (gimple_assign_lhs_ptr (store1), memory_ssa_name_same,\n-\t\t     &walk_data, NULL)\n-\t  == NULL);\n-}\n-\n-/* Return true if there is a stmt that kills the lhs of STMT and is in the\n-   virtual def-use chain of STMT without a use in between the kill and STMT.\n-   Returns false if no such stmt is found.\n-   *FIRST_USE_P is set to the first use of the single virtual def of\n-   STMT.  *USE_P is set to the vop killed by *USE_STMT.  */\n-\n-static bool\n-get_kill_of_stmt_lhs (gimple stmt,\n-\t\t      use_operand_p * first_use_p,\n- \t\t      use_operand_p * use_p, gimple * use_stmt)\n-{\n-  tree lhs;\n-\n-  gcc_assert (is_gimple_assign (stmt));\n-\n-  lhs = gimple_assign_lhs (stmt);\n-\n-  /* We now walk the chain of single uses of the single VDEFs.\n-     We succeeded finding a kill if the lhs of the use stmt is\n-     equal to the original lhs.  We can keep walking to the next\n-     use if there are no possible uses of the original lhs in\n-     the stmt.  */\n-  do\n-    {\n-      tree use_lhs;\n-      def_operand_p def_p;\n-\n-      /* The stmt must have a single VDEF.  */\n-      def_p = SINGLE_SSA_DEF_OPERAND (stmt, SSA_OP_VDEF);\n-      if (def_p == NULL_DEF_OPERAND_P)\n-\treturn false;\n-\n-      /* Get the single immediate use of the def.  */\n-      if (!single_imm_use (DEF_FROM_PTR (def_p), first_use_p, &stmt))\n-\treturn false;\n-      first_use_p = use_p;\n-\n-      /* If there are possible hidden uses, give up.  */\n-      if (!gimple_assign_single_p (stmt)\n-\t  || (TREE_CODE (gimple_assign_rhs1 (stmt)) != SSA_NAME\n-\t      && !is_gimple_min_invariant (gimple_assign_rhs1 (stmt))))\n-\treturn false;\n-\n-      /* If the use stmts lhs matches the original lhs we have\n-\t found the kill, otherwise continue walking.  */\n-      use_lhs = gimple_assign_lhs (stmt);\n-      if (operand_equal_p (use_lhs, lhs, 0))\n-\t{\n-\t  *use_stmt = stmt;\n-\t  return true;\n-\t}\n-    }\n-  while (1);\n-}\n-\n /* A helper of dse_optimize_stmt.\n-   Given a GIMPLE_ASSIGN in STMT, check that each VDEF has one\n-   use, and that one use is another VDEF clobbering the first one.\n-\n+   Given a GIMPLE_ASSIGN in STMT, find a candidate statement *USE_STMT that\n+   may prove STMT to be dead.\n    Return TRUE if the above conditions are met, otherwise FALSE.  */\n \n static bool\n-dse_possible_dead_store_p (gimple stmt,\n-\t\t\t   use_operand_p *first_use_p,\n-\t\t\t   use_operand_p *use_p,\n-\t\t\t   gimple *use_stmt,\n-\t\t\t   struct dse_global_data *dse_gd,\n-\t\t\t   struct dse_block_local_data *bd)\n+dse_possible_dead_store_p (gimple stmt, gimple *use_stmt)\n {\n-  ssa_op_iter op_iter;\n-  bool fail = false;\n-  def_operand_p var1;\n-  vuse_vec_p vv;\n-  tree defvar = NULL_TREE;\n-  tree prev_defvar = NULL_TREE;\n   gimple temp;\n+  unsigned cnt = 0;\n \n-  /* We want to verify that each virtual definition in STMT has\n-     precisely one use and that all the virtual definitions are\n-     used by the same single statement.  When complete, we\n-     want USE_STMT to refer to the one statement which uses\n-     all of the virtual definitions from STMT.  */\n   *use_stmt = NULL;\n-  FOR_EACH_SSA_VDEF_OPERAND (var1, vv, stmt, op_iter)\n-    {\n-      defvar = DEF_FROM_PTR (var1);\n-\n-      /* If this virtual def does not have precisely one use, then\n-\t we will not be able to eliminate STMT.  */\n-      if (!has_single_use (defvar))\n-\t{\n-\t  fail = true;\n-\t  break;\n-\t}\n \n-      /* Get the one and only immediate use of DEFVAR.  */\n-      single_imm_use (defvar, use_p, &temp);\n-      gcc_assert (*use_p != NULL_USE_OPERAND_P);\n-      *first_use_p = *use_p;\n+  /* Find the first dominated statement that clobbers (part of) the\n+     memory stmt stores to with no intermediate statement that may use\n+     part of the memory stmt stores.  That is, find a store that may\n+     prove stmt to be a dead store.  */\n+  temp = stmt;\n+  do\n+    {\n+      gimple prev, use_stmt;\n+      imm_use_iterator ui;\n+      bool fail = false;\n+      tree defvar;\n+\n+      /* Limit stmt walking to be linear in the number of possibly\n+         dead stores.  */\n+      if (++cnt > 256)\n+\treturn false;\n \n-      /* ???  If we hit a GIMPLE_PHI we could skip to the PHI_RESULT uses.\n-\t Don't bother to do that for now.  */\n       if (gimple_code (temp) == GIMPLE_PHI)\n+\tdefvar = PHI_RESULT (temp);\n+      else\n+\tdefvar = gimple_vdef (temp);\n+      prev = temp;\n+      temp = NULL;\n+      FOR_EACH_IMM_USE_STMT (use_stmt, ui, defvar)\n \t{\n-\t  fail = true;\n-\t  break;\n-\t}\n-\n-      /* In the case of memory partitions, we may get:\n+\t  cnt++;\n \n-\t   # MPT.764_162 = VDEF <MPT.764_161(D)>\n-\t   x = {};\n-\t   # MPT.764_167 = VDEF <MPT.764_162>\n-\t   y = {};\n-\n-\t   So we must make sure we're talking about the same LHS.\n-      */\n-      if (is_gimple_assign (temp))\n-\t{\n-\t  tree base1 = get_base_address (gimple_assign_lhs (stmt));\n-\t  tree base2 = get_base_address (gimple_assign_lhs (temp));\n-\n-\t  while (base1 && INDIRECT_REF_P (base1))\n-\t    base1 = TREE_OPERAND (base1, 0);\n-\t  while (base2 && INDIRECT_REF_P (base2))\n-\t    base2 = TREE_OPERAND (base2, 0);\n-\n-\t  if (base1 != base2)\n+\t  /* In simple cases we can look through PHI nodes, but we\n+\t     have to be careful with loops and with memory references\n+\t     containing operands that are also operands of PHI nodes.\n+\t     See gcc.c-torture/execute/20051110-*.c.  */\n+\t  if (gimple_code (use_stmt) == GIMPLE_PHI)\n+\t    {\n+\t      if (temp\n+\t\t  /* We can look through PHIs to post-dominated regions\n+\t\t     without worrying if the use not also dominates prev\n+\t\t     (in which case it would be a loop PHI with the use\n+\t\t     in a latch block).  */\n+\t\t  || gimple_bb (prev) == gimple_bb (use_stmt)\n+\t\t  || !dominated_by_p (CDI_POST_DOMINATORS,\n+\t\t\t\t      gimple_bb (prev), gimple_bb (use_stmt))\n+\t\t  || dominated_by_p (CDI_DOMINATORS,\n+\t\t\t\t     gimple_bb (prev), gimple_bb (use_stmt)))\n+\t\t{\n+\t\t  fail = true;\n+\t\t  BREAK_FROM_IMM_USE_STMT (ui);\n+\t\t}\n+\t      temp = use_stmt;\n+\t    }\n+\t  /* If the statement is a use the store is not dead.  */\n+\t  else if (ref_maybe_used_by_stmt_p (use_stmt,\n+\t\t\t\t\t     gimple_assign_lhs (stmt)))\n \t    {\n \t      fail = true;\n-\t      break;\n+\t      BREAK_FROM_IMM_USE_STMT (ui);\n+\t    }\n+\t  /* If this is a store, remember it or bail out if we have\n+\t     multiple ones (the will be in different CFG parts then).  */\n+\t  else if (gimple_vdef (use_stmt))\n+\t    {\n+\t      if (temp)\n+\t\t{\n+\t\t  fail = true;\n+\t\t  BREAK_FROM_IMM_USE_STMT (ui);\n+\t\t}\n+\t      temp = use_stmt;\n \t    }\n \t}\n \n-      /* If the immediate use of DEF_VAR is not the same as the\n-\t previously find immediate uses, then we will not be able\n-\t to eliminate STMT.  */\n-      if (*use_stmt == NULL)\n-\t{\n-\t  *use_stmt = temp;\n-\t  prev_defvar = defvar;\n-\t}\n-      else if (temp != *use_stmt)\n+      if (fail)\n+\treturn false;\n+\n+      /* If we didn't find any definition this means the store is dead\n+         if it isn't a store to global reachable memory.  In this case\n+\t just pretend the stmt makes itself dead.  Otherwise fail.  */\n+      if (!temp)\n \t{\n-\t  fail = true;\n+\t  if (is_hidden_global_store (stmt))\n+\t    return false;\n+\n+\t  temp = stmt;\n \t  break;\n \t}\n     }\n+  /* We deliberately stop on clobbering statements and not only on\n+     killing ones to make walking cheaper.  Otherwise we can just\n+     continue walking until both stores have equal reference trees.  */\n+  while (!stmt_may_clobber_ref_p (temp, gimple_assign_lhs (stmt)));\n \n-  if (fail)\n-    {\n-      record_voperand_set (dse_gd->stores, &bd->stores, gimple_uid (stmt));\n-      return false;\n-    }\n+  if (!is_gimple_assign (temp))\n+    return false;\n+\n+  *use_stmt = temp;\n \n   return true;\n }\n@@ -393,7 +280,7 @@ dse_optimize_stmt (struct dom_walk_data *walk_data,\n \n   /* If this statement has no virtual defs, then there is nothing\n      to do.  */\n-  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF))\n+  if (!gimple_vdef (stmt))\n     return;\n \n   /* We know we have virtual definitions.  If this is a GIMPLE_ASSIGN\n@@ -406,51 +293,21 @@ dse_optimize_stmt (struct dom_walk_data *walk_data,\n \n   if (is_gimple_assign (stmt))\n     {\n-      use_operand_p first_use_p = NULL_USE_OPERAND_P;\n-      use_operand_p use_p = NULL;\n       gimple use_stmt;\n \n-      if (!dse_possible_dead_store_p (stmt, &first_use_p, &use_p, &use_stmt, \n-\t\t\t\t      dse_gd, bd))\n-\treturn;\n+      record_voperand_set (dse_gd->stores, &bd->stores, gimple_uid (stmt));\n \n-      /* If we have precisely one immediate use at this point, then we may\n-\t have found redundant store.  Make sure that the stores are to\n-\t the same memory location.  This includes checking that any\n-\t SSA-form variables in the address will have the same values.  */\n-      if (use_p != NULL_USE_OPERAND_P\n-          && bitmap_bit_p (dse_gd->stores, get_stmt_uid (use_stmt))\n-          && !operand_equal_p (gimple_assign_lhs (stmt),\n-                               gimple_assign_lhs (use_stmt), 0)\n-          && memory_address_same (stmt, use_stmt))\n-        {\n-          /* If we have precisely one immediate use at this point, but\n-             the stores are not to the same memory location then walk the\n-             virtual def-use chain to get the stmt which stores to that same\n-             memory location.  */\n-          if (!get_kill_of_stmt_lhs (stmt, &first_use_p, &use_p, &use_stmt))\n-            {\n-              record_voperand_set (dse_gd->stores, &bd->stores, \n-\t\t\t\t   gimple_uid (stmt));\n-              return;\n-            }\n-        }\n+      if (!dse_possible_dead_store_p (stmt, &use_stmt))\n+\treturn;\n \n       /* If we have precisely one immediate use at this point and the\n \t stores are to the same memory location or there is a chain of\n \t virtual uses from stmt and the stmt which stores to that same\n \t memory location, then we may have found redundant store.  */\n-      if (use_p != NULL_USE_OPERAND_P\n-\t  && bitmap_bit_p (dse_gd->stores, get_stmt_uid (use_stmt))\n+      if (bitmap_bit_p (dse_gd->stores, get_stmt_uid (use_stmt))\n \t  && operand_equal_p (gimple_assign_lhs (stmt),\n-\t\t\t      gimple_assign_lhs (use_stmt), 0)\n-\t  && memory_address_same (stmt, use_stmt))\n+\t\t\t      gimple_assign_lhs (use_stmt), 0))\n \t{\n-\t  ssa_op_iter op_iter;\n-\t  def_operand_p var1;\n-\t  vuse_vec_p vv;\n-\t  tree stmt_lhs;\n-\n \t  /* If use_stmt is or might be a nop assignment, e.g. for\n \t     struct { ... } S a, b, *p; ...\n \t     b = a; b = b;\n@@ -462,14 +319,14 @@ dse_optimize_stmt (struct dom_walk_data *walk_data,\n \t     *p = *u; *p = *v; where p might be v, then USE_STMT\n \t     acts as a use as well as definition, so store in STMT\n \t     is not dead.  */\n-\t  if (gimple_loaded_syms (use_stmt)\n-\t      && bitmap_intersect_p (gimple_loaded_syms (use_stmt),\n-\t\t\t\t     gimple_stored_syms (use_stmt)))\n-\t    {\n-              record_voperand_set (dse_gd->stores, &bd->stores, \n-\t\t\t\t   gimple_uid (stmt));\n-\t      return;\n-\t    }\n+\t  if (stmt != use_stmt\n+\t      && !is_gimple_reg (gimple_assign_rhs1 (use_stmt))\n+\t      && !is_gimple_min_invariant (gimple_assign_rhs1 (use_stmt))\n+\t      /* ???  Should {} be invariant?  */\n+\t      && gimple_assign_rhs_code (use_stmt) != CONSTRUCTOR\n+\t      && refs_may_alias_p (gimple_assign_lhs (use_stmt),\n+\t\t\t\t   gimple_assign_rhs1 (use_stmt)))\n+\t    return;\n \n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n             {\n@@ -479,21 +336,7 @@ dse_optimize_stmt (struct dom_walk_data *walk_data,\n             }\n \n \t  /* Then we need to fix the operand of the consuming stmt.  */\n-\t  stmt_lhs = USE_FROM_PTR (first_use_p);\n-\t  FOR_EACH_SSA_VDEF_OPERAND (var1, vv, stmt, op_iter)\n-\t    {\n-\t      tree usevar;\n-\t      gimple temp;\n-\n-\t      single_imm_use (DEF_FROM_PTR (var1), &use_p, &temp);\n-\t      gcc_assert (VUSE_VECT_NUM_ELEM (*vv) == 1);\n-\t      usevar = VUSE_ELEMENT_VAR (*vv, 0);\n-\t      SET_USE (use_p, usevar);\n-\n-\t      /* Make sure we propagate the ABNORMAL bit setting.  */\n-\t      if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (stmt_lhs))\n-\t\tSSA_NAME_OCCURS_IN_ABNORMAL_PHI (usevar) = 1;\n-\t    }\n+\t  unlink_stmt_vdef (stmt);\n \n \t  /* Remove the dead store.  */\n \t  gsi_remove (&gsi, true);\n@@ -502,8 +345,6 @@ dse_optimize_stmt (struct dom_walk_data *walk_data,\n \t     SSA_NAME manager.  */\n \t  release_defs (stmt);\n \t}\n-\n-      record_voperand_set (dse_gd->stores, &bd->stores, gimple_uid (stmt));\n     }\n }\n \n@@ -564,6 +405,7 @@ tree_ssa_dse (void)\n      this pass could be seen as an extension of DCE which needs post\n      dominators.  */\n   calculate_dominance_info (CDI_POST_DOMINATORS);\n+  calculate_dominance_info (CDI_DOMINATORS);\n \n   /* Dead store elimination is fundamentally a walk of the post-dominator\n      tree and a backwards walk of statements within each block.  */\n@@ -630,153 +472,3 @@ struct gimple_opt_pass pass_dse =\n  }\n };\n \n-/* A very simple dead store pass eliminating write only local variables.\n-   The pass does not require alias information and thus can be run before\n-   inlining to quickly eliminate artifacts of some common C++ constructs.  */\n-\n-static unsigned int\n-execute_simple_dse (void)\n-{\n-  gimple_stmt_iterator gsi;\n-  basic_block bb;\n-  bitmap variables_loaded = BITMAP_ALLOC (NULL);\n-  unsigned int todo = 0;\n-\n-  /* Collect into VARIABLES LOADED all variables that are read in function\n-     body.  */\n-  FOR_EACH_BB (bb)\n-    for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n-\n-      if (gimple_loaded_syms (gsi_stmt (gsi)))\n-\tbitmap_ior_into (variables_loaded,\n-\t\t\t gimple_loaded_syms (gsi_stmt (gsi)));\n-\n-  /* Look for statements writing into the write only variables.\n-     And try to remove them.  */\n-\n-  FOR_EACH_BB (bb)\n-    for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi);)\n-      {\n-\tgimple stmt = gsi_stmt (gsi);\n-        tree op;\n-\tbool removed = false;\n-        ssa_op_iter iter;\n-\ttree size;\n-\n-\tif (is_gimple_assign (stmt)\n-\t    && AGGREGATE_TYPE_P (TREE_TYPE (gimple_assign_lhs (stmt)))\n-\t    && (size = lang_hooks.expr_size (gimple_assign_lhs (stmt)))\n-\t    && integer_zerop (size))\n-\t  {\n-\t    if (dump_file && (dump_flags & TDF_DETAILS))\n-\t      {\n-\t\tfprintf (dump_file, \"  Deleted zero-sized store '\");\n-\t\tprint_gimple_stmt (dump_file, stmt, 0, dump_flags);\n-\t\tfprintf (dump_file, \"'\\n\");\n-\t      }\n-\t    removed = true;\n-\t    gsi_remove (&gsi, true);\n-\t    todo |= TODO_cleanup_cfg;\n-\t  }\n-\telse if (gimple_stored_syms (stmt)\n-\t\t && !bitmap_empty_p (gimple_stored_syms (stmt))\n-\t\t && (is_gimple_assign (stmt)\n-\t\t     || (is_gimple_call (stmt)\n-\t\t\t && gimple_call_lhs (stmt)))\n-\t\t && !bitmap_intersect_p (gimple_stored_syms (stmt),\n-\t\t\t\t\t variables_loaded))\n-\t  {\n-\t    unsigned int i;\n-\t    bitmap_iterator bi;\n-\t    bool dead = true;\n-\n-\t    /* See if STMT only stores to write-only variables and\n-\t       verify that there are no volatile operands.  tree-ssa-operands\n-\t       sets has_volatile_ops flag for all statements involving\n-\t       reads and writes when aliases are not built to prevent passes\n-\t       from removing them as dead.  The flag thus has no use for us\n-\t       and we need to look into all operands.  */\n-\t      \n-\t    EXECUTE_IF_SET_IN_BITMAP (gimple_stored_syms (stmt), 0, i, bi)\n-\t      {\n-\t\ttree var = referenced_var_lookup (i);\n-\t\tif (TREE_ADDRESSABLE (var)\n-\t\t    || is_global_var (var)\n-\t\t    || TREE_THIS_VOLATILE (var))\n-\t\t  dead = false;\n-\t      }\n-\n-\t    if (dead && gimple_loaded_syms (stmt))\n-\t      EXECUTE_IF_SET_IN_BITMAP (gimple_loaded_syms (stmt), 0, i, bi)\n-\t\tif (TREE_THIS_VOLATILE (referenced_var_lookup (i)))\n-\t\t  dead = false;\n-\n-\t    if (dead)\n-\t      FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_ALL_OPERANDS)\n-\t\tif (TREE_THIS_VOLATILE (op))\n-\t\t  dead = false;\n-\n-\t    /* Look for possible occurrence var = indirect_ref (...) where\n-\t       indirect_ref itself is volatile.  */\n-\n-\t    if (dead && is_gimple_assign (stmt)\n-\t        && TREE_THIS_VOLATILE (gimple_assign_rhs1 (stmt)))\n-\t      dead = false;\n-\n-\t    if (dead)\n-\t      {\n-\t\t/* When LHS of var = call (); is dead, simplify it into\n-\t\t   call (); saving one operand.  */\n-                if (is_gimple_call (stmt)\n-                    && gimple_has_side_effects (stmt))\n-\t\t  {\n-\t\t    if (dump_file && (dump_flags & TDF_DETAILS))\n-\t\t      {\n-\t\t\tfprintf (dump_file, \"Deleted LHS of call: \");\n-\t\t\tprint_gimple_stmt (dump_file, stmt, 0, TDF_SLIM);\n-\t\t\tfprintf (dump_file, \"\\n\");\n-\t\t      }\n-\t\t    push_stmt_changes (gsi_stmt_ptr (&gsi));\n-                    gimple_call_set_lhs (stmt, NULL);\n-\t\t    pop_stmt_changes (gsi_stmt_ptr (&gsi));\n-\t\t  }\n-\t\telse\n-\t\t  {\n-\t\t    if (dump_file && (dump_flags & TDF_DETAILS))\n-\t\t      {\n-\t\t\tfprintf (dump_file, \"  Deleted dead store '\");\n-\t\t\tprint_gimple_stmt (dump_file, stmt, 0, dump_flags);\n-\t\t\tfprintf (dump_file, \"'\\n\");\n-\t\t      }\n-\t\t    removed = true;\n-\t\t    gsi_remove (&gsi, true);\n-\t\t    todo |= TODO_cleanup_cfg;\n-\t\t  }\n-\t\ttodo |= TODO_remove_unused_locals | TODO_ggc_collect;\n-\t      }\n-\t  }\n-\tif (!removed)\n-\t  gsi_next (&gsi);\n-      }\n-  BITMAP_FREE (variables_loaded);\n-  return todo;\n-}\n-\n-struct gimple_opt_pass pass_simple_dse =\n-{\n- {\n-  GIMPLE_PASS,\n-  \"sdse\",\t\t\t\t/* name */\n-  NULL,\t\t\t\t\t/* gate */\n-  execute_simple_dse,\t\t\t/* execute */\n-  NULL,\t\t\t\t\t/* sub */\n-  NULL,\t\t\t\t\t/* next */\n-  0,\t\t\t\t\t/* static_pass_number */\n-  0,\t\t\t\t\t/* tv_id */\n-  PROP_ssa,\t\t\t\t/* properties_required */\n-  0,\t\t\t\t\t/* properties_provided */\n-  0,\t\t\t\t\t/* properties_destroyed */\n-  0,\t\t\t\t\t/* todo_flags_start */\n-  TODO_dump_func          \t        /* todo_flags_finish */\n- }\n-};"}, {"sha": "c3e7d432528627fca812e1e53638ef264fdb6020", "filename": "gcc/tree-ssa-forwprop.c", "status": "modified", "additions": 11, "deletions": 7, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-forwprop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-forwprop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-forwprop.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -594,8 +594,6 @@ tidy_after_forward_propagate_addr (gimple stmt)\n \n   if (TREE_CODE (gimple_assign_rhs1 (stmt)) == ADDR_EXPR)\n      recompute_tree_invariant_for_addr_expr (gimple_assign_rhs1 (stmt));\n-\n-  mark_symbols_for_renaming (stmt);\n }\n \n /* DEF_RHS contains the address of the 0th element in an array.\n@@ -930,18 +928,24 @@ forward_propagate_addr_expr (tree name, tree rhs)\n \t  continue;\n \t}\n \n-      push_stmt_changes (&use_stmt);\n-\n       {\n \tgimple_stmt_iterator gsi = gsi_for_stmt (use_stmt);\n+\tpush_stmt_changes (&use_stmt);\n \tresult = forward_propagate_addr_expr_1 (name, rhs, &gsi,\n \t\t\t\t\t\tsingle_use_p);\n-\tuse_stmt = gsi_stmt (gsi);\n+\t/* If the use has moved to a different statement adjust\n+\t   the update machinery.  */\n+\tif (use_stmt != gsi_stmt (gsi))\n+\t  {\n+\t    pop_stmt_changes (&use_stmt);\n+\t    use_stmt = gsi_stmt (gsi);\n+\t    update_stmt (use_stmt);\n+\t  }\n+\telse\n+\t  pop_stmt_changes (&use_stmt);\n       }\n       all &= result;\n \n-      pop_stmt_changes (&use_stmt);\n-\n       /* Remove intermediate now unused copy and conversion chains.  */\n       use_rhs = gimple_assign_rhs1 (use_stmt);\n       if (result"}, {"sha": "e6dc78a8c69b34ca6fca43c2afba32ab3a47416e", "filename": "gcc/tree-ssa-ifcombine.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-ifcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-ifcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ifcombine.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -108,7 +108,7 @@ bb_no_side_effects_p (basic_block bb)\n       gimple stmt = gsi_stmt (gsi);\n \n       if (gimple_has_volatile_ops (stmt)\n-\t  || !ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS))\n+\t  || gimple_vuse (stmt))\n \treturn false;\n     }\n "}, {"sha": "fa247458e9298b7e46b5362b0afb3537cfb597db", "filename": "gcc/tree-ssa-live.c", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-live.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-live.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-live.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -797,11 +797,9 @@ remove_unused_locals (void)\n      pass is performed.  */\n   FOR_EACH_REFERENCED_VAR (t, rvi)\n     if (!is_global_var (t)\n-\t&& !MTAG_P (t)\n \t&& TREE_CODE (t) != PARM_DECL\n \t&& TREE_CODE (t) != RESULT_DECL\n \t&& !(ann = var_ann (t))->used\n-\t&& !ann->symbol_mem_tag\n \t&& !TREE_ADDRESSABLE (t)\n \t&& (optimize || DECL_ARTIFICIAL (t)))\n       remove_referenced_var (t);"}, {"sha": "c9d235835876d1248d448b021bfa9bb6868fb48c", "filename": "gcc/tree-ssa-loop-im.c", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-im.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-im.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-im.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -362,7 +362,7 @@ movement_possibility (gimple stmt)\n   if (gimple_get_lhs (stmt) == NULL_TREE)\n     return MOVE_IMPOSSIBLE;\n \n-  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_DEFS))\n+  if (gimple_vdef (stmt))\n     return MOVE_IMPOSSIBLE;\n \n   if (stmt_ends_bb_p (stmt)\n@@ -681,7 +681,7 @@ determine_max_movement (gimple stmt, bool must_preserve_exec)\n     if (!add_dependency (val, lim_data, loop, true))\n       return false;\n \n-  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_USES))\n+  if (gimple_vuse (stmt))\n     {\n       mem_ref_p ref = mem_ref_in_stmt (stmt);\n \n@@ -694,7 +694,7 @@ determine_max_movement (gimple stmt, bool must_preserve_exec)\n \t}\n       else\n \t{\n-\t  FOR_EACH_SSA_TREE_OPERAND (val, stmt, iter, SSA_OP_VIRTUAL_USES)\n+\t  if ((val = gimple_vuse (stmt)) != NULL_TREE)\n \t    {\n \t      if (!add_dependency (val, lim_data, loop, false))\n \t\treturn false;\n@@ -1080,7 +1080,7 @@ move_computations (void)\n   fini_walk_dominator_tree (&walk_data);\n \n   gsi_commit_edge_inserts ();\n-  if (need_ssa_update_p ())\n+  if (need_ssa_update_p (cfun))\n     rewrite_into_loop_closed_ssa (NULL, TODO_update_ssa);\n }\n \n@@ -1309,13 +1309,12 @@ gather_mem_refs_stmt (struct loop *loop, gimple stmt)\n   hashval_t hash;\n   PTR *slot;\n   mem_ref_p ref;\n-  ssa_op_iter oi;\n   tree vname;\n   bool is_stored;\n   bitmap clvops;\n   unsigned id;\n \n-  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS))\n+  if (!gimple_vuse (stmt))\n     return;\n \n   mem = simple_mem_ref_in_stmt (stmt, &is_stored);\n@@ -1347,14 +1346,14 @@ gather_mem_refs_stmt (struct loop *loop, gimple stmt)\n   if (is_stored)\n     mark_ref_stored (ref, loop);\n \n-  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi, SSA_OP_VIRTUAL_USES)\n+  if ((vname = gimple_vuse (stmt)) != NULL_TREE)\n     bitmap_set_bit (ref->vops, DECL_UID (SSA_NAME_VAR (vname)));\n   record_mem_ref_loc (ref, loop, stmt, mem);\n   return;\n \n fail:\n   clvops = VEC_index (bitmap, memory_accesses.clobbered_vops, loop->num);\n-  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi, SSA_OP_VIRTUAL_USES)\n+  if ((vname = gimple_vuse (stmt)) != NULL_TREE)\n     bitmap_set_bit (clvops, DECL_UID (SSA_NAME_VAR (vname)));\n }\n "}, {"sha": "5c2f6aff56835c41b7e985aa806c7c85d8e575f2", "filename": "gcc/tree-ssa-loop-ivcanon.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-ivcanon.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-ivcanon.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-ivcanon.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -442,7 +442,7 @@ empty_loop_p (struct loop *loop)\n \t{\n \t  gimple stmt = gsi_stmt (gsi);\n \n-\t  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_DEFS)\n+\t  if (gimple_vdef (stmt)\n \t      || gimple_has_volatile_ops (stmt))\n \t    {\n \t      free (body);"}, {"sha": "37865e20701057fc021ddcb706d307c7380d096f", "filename": "gcc/tree-ssa-loop-ivopts.c", "status": "modified", "additions": 1, "deletions": 61, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-ivopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-ivopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-ivopts.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -5222,63 +5222,6 @@ unshare_and_remove_ssa_names (tree ref)\n   return ref;\n }\n \n-/* Extract the alias analysis info for the memory reference REF.  There are\n-   several ways how this information may be stored and what precisely is\n-   its semantics depending on the type of the reference, but there always is\n-   somewhere hidden one _DECL node that is used to determine the set of\n-   virtual operands for the reference.  The code below deciphers this jungle\n-   and extracts this single useful piece of information.  */\n-\n-static tree\n-get_ref_tag (tree ref, tree orig)\n-{\n-  tree var = get_base_address (ref);\n-  tree aref = NULL_TREE, tag, sv;\n-  HOST_WIDE_INT offset, size, maxsize;\n-\n-  for (sv = orig; handled_component_p (sv); sv = TREE_OPERAND (sv, 0))\n-    {\n-      aref = get_ref_base_and_extent (sv, &offset, &size, &maxsize);\n-      if (ref)\n-\tbreak;\n-    }\n-\n-  if (!var)\n-    return NULL_TREE;\n-\n-  if (TREE_CODE (var) == INDIRECT_REF)\n-    {\n-      /* If the base is a dereference of a pointer, first check its name memory\n-\t tag.  If it does not have one, use its symbol memory tag.  */\n-      var = TREE_OPERAND (var, 0);\n-      if (TREE_CODE (var) != SSA_NAME)\n-\treturn NULL_TREE;\n-\n-      if (SSA_NAME_PTR_INFO (var))\n-\t{\n-\t  tag = SSA_NAME_PTR_INFO (var)->name_mem_tag;\n-\t  if (tag)\n-\t    return tag;\n-\t}\n- \n-      var = SSA_NAME_VAR (var);\n-      tag = symbol_mem_tag (var);\n-      gcc_assert (tag != NULL_TREE);\n-      return tag;\n-    }\n-  else\n-    { \n-      if (!DECL_P (var))\n-\treturn NULL_TREE;\n-\n-      tag = symbol_mem_tag (var);\n-      if (tag)\n-\treturn tag;\n-\n-      return var;\n-    }\n-}\n-\n /* Copies the reference information from OLD_REF to NEW_REF.  */\n \n static void\n@@ -5287,10 +5230,7 @@ copy_ref_info (tree new_ref, tree old_ref)\n   if (TREE_CODE (old_ref) == TARGET_MEM_REF)\n     copy_mem_ref_info (new_ref, old_ref);\n   else\n-    {\n-      TMR_ORIGINAL (new_ref) = unshare_and_remove_ssa_names (old_ref);\n-      TMR_TAG (new_ref) = get_ref_tag (old_ref, TMR_ORIGINAL (new_ref));\n-    }\n+    TMR_ORIGINAL (new_ref) = unshare_and_remove_ssa_names (old_ref);\n }\n \n /* Rewrites USE (address that is an iv) using candidate CAND.  */"}, {"sha": "6547382bbb4212b13a311aea11536c0846329090", "filename": "gcc/tree-ssa-loop-niter.c", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-niter.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-niter.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-niter.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1993,17 +1993,13 @@ chain_of_csts_start (struct loop *loop, tree x)\n \n   code = gimple_assign_rhs_code (stmt);\n   if (gimple_references_memory_p (stmt)\n-      /* Before alias information is computed, operand scanning marks\n-\t statements that write memory volatile.  However, the statements\n-\t that only read memory are not marked, thus gimple_references_memory_p\n-\t returns false for them.  */\n       || TREE_CODE_CLASS (code) == tcc_reference\n-      || TREE_CODE_CLASS (code) == tcc_declaration\n-      || SINGLE_SSA_DEF_OPERAND (stmt, SSA_OP_DEF) == NULL_DEF_OPERAND_P)\n+      || (code == ADDR_EXPR\n+\t  && !is_gimple_min_invariant (gimple_assign_rhs1 (stmt))))\n     return NULL;\n \n   use = SINGLE_SSA_TREE_OPERAND (stmt, SSA_OP_USE);\n-  if (use == NULL_USE_OPERAND_P)\n+  if (use == NULL_TREE)\n     return NULL;\n \n   return chain_of_csts_start (loop, use);"}, {"sha": "bcff26ae7ae0cd4fe5a9a0f78b7d7c9da930412b", "filename": "gcc/tree-ssa-loop-prefetch.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-prefetch.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-loop-prefetch.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-prefetch.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -502,7 +502,7 @@ gather_memory_references (struct loop *loop, bool *no_other_refs)\n \n \t  if (gimple_code (stmt) != GIMPLE_ASSIGN)\n \t    {\n-\t      if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS)\n+\t      if (gimple_vuse (stmt)\n \t\t  || (is_gimple_call (stmt)\n \t\t      && !(gimple_call_flags (stmt) & ECF_CONST)))\n \t\t*no_other_refs = false;"}, {"sha": "56d8e84a73b1cda0b9be58f3842bedb6aaf6f52f", "filename": "gcc/tree-ssa-operands.c", "status": "modified", "additions": 249, "deletions": 1544, "changes": 1793, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-operands.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-operands.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-operands.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -75,11 +75,6 @@ along with GCC; see the file COPYING3.  If not see\n    operand vector for VUSE, then the new vector will also be modified\n    such that it contains 'a_5' rather than 'a'.  */\n \n-/* Helper functions from gimple.c.  These are GIMPLE manipulation\n-   routines that only the operand scanner should need.  */\n-void gimple_set_stored_syms (gimple, bitmap, bitmap_obstack *);\n-void gimple_set_loaded_syms (gimple, bitmap, bitmap_obstack *);\n-\n /* Structure storing statistics on how many call clobbers we have, and\n    how many where avoided.  */\n \n@@ -137,69 +132,26 @@ static VEC(tree,heap) *build_defs;\n /* Array for building all the use operands.  */\n static VEC(tree,heap) *build_uses;\n \n-/* Set for building all the VDEF operands.  */\n-static VEC(tree,heap) *build_vdefs;\n+/* The built VDEF operand.  */\n+static tree build_vdef;\n \n-/* Set for building all the VUSE operands.  */\n-static VEC(tree,heap) *build_vuses;\n+/* The built VUSE operand.  */\n+static tree build_vuse;\n \n /* Bitmap obstack for our datastructures that needs to survive across\t\n    compilations of multiple functions.  */\n static bitmap_obstack operands_bitmap_obstack;\n \n-/* Set for building all the loaded symbols.  */\n-static bitmap build_loads;\n-\n-/* Set for building all the stored symbols.  */\n-static bitmap build_stores;\n-\n static void get_expr_operands (gimple, tree *, int);\n \n /* Number of functions with initialized ssa_operands.  */\n static int n_initialized = 0;\n \n-/* Statement change buffer.  Data structure used to record state\n-   information for statements.  This is used to determine what needs\n-   to be done in order to update the SSA web after a statement is\n-   modified by a pass.  If STMT is a statement that has just been\n-   created, or needs to be folded via fold_stmt, or anything that\n-   changes its physical structure then the pass should:\n-\n-   1- Call push_stmt_changes (&stmt) to record the current state of\n-      STMT before any modifications are made.\n-\n-   2- Make all appropriate modifications to the statement.\n-\n-   3- Call pop_stmt_changes (&stmt) to find new symbols that\n-      need to be put in SSA form, SSA name mappings for names that\n-      have disappeared, recompute invariantness for address\n-      expressions, cleanup EH information, etc.\n-\n-   If it is possible to determine that the statement was not modified,\n-   instead of calling pop_stmt_changes it is quicker to call\n-   discard_stmt_changes to avoid the expensive and unnecessary operand\n-   re-scan and change comparison.  */\n-\n-struct scb_d\n-{\n-  /* Pointer to the statement being modified.  */\n-  gimple *stmt_p;\n-\n-  /* If the statement references memory these are the sets of symbols\n-     loaded and stored by the statement.  */\n-  bitmap loads;\n-  bitmap stores;\n-};\n-\n-typedef struct scb_d *scb_t;\n-DEF_VEC_P(scb_t);\n-DEF_VEC_ALLOC_P(scb_t,heap);\n-\n-/* Stack of statement change buffers (SCB).  Every call to\n-   push_stmt_changes pushes a new buffer onto the stack.  Calls to\n-   pop_stmt_changes pop a buffer off of the stack and compute the set\n+/* Stack of statements to change.  Every call to\n+   push_stmt_changes pushes the stmt onto the stack.  Calls to\n+   pop_stmt_changes pop a stmt off of the stack and compute the set\n    of changes for the popped statement.  */\n-static VEC(scb_t,heap) *scb_stack;\n+static VEC(gimple_p,heap) *scb_stack;\n \n /* Return the DECL_UID of the base variable of T.  */\n \n@@ -213,54 +165,6 @@ get_name_decl (const_tree t)\n }\n \n \n-/* Comparison function for qsort used in operand_build_sort_virtual.  */\n-\n-int\n-operand_build_cmp (const void *p, const void *q)\n-{\n-  const_tree const e1 = *((const_tree const *)p);\n-  const_tree const e2 = *((const_tree const *)q);\n-  const unsigned int u1 = get_name_decl (e1);\n-  const unsigned int u2 = get_name_decl (e2);\n-\n-  /* We want to sort in ascending order.  They can never be equal.  */\n-#ifdef ENABLE_CHECKING\n-  gcc_assert (u1 != u2);\n-#endif\n-  return (u1 > u2 ? 1 : -1);\n-}\n-\n-\n-/* Sort the virtual operands in LIST from lowest DECL_UID to highest.  */\n-\n-static inline void\n-operand_build_sort_virtual (VEC(tree,heap) *list)\n-{\n-  int num = VEC_length (tree, list);\n-\n-  if (num < 2)\n-    return;\n-\n-  if (num == 2)\n-    {\n-      if (get_name_decl (VEC_index (tree, list, 0)) \n-\t  > get_name_decl (VEC_index (tree, list, 1)))\n-\t{  \n-\t  /* Swap elements if in the wrong order.  */\n-\t  tree tmp = VEC_index (tree, list, 0);\n-\t  VEC_replace (tree, list, 0, VEC_index (tree, list, 1));\n-\t  VEC_replace (tree, list, 1, tmp);\n-\t}\n-      return;\n-    }\n-\n-  /* There are 3 or more elements, call qsort.  */\n-  qsort (VEC_address (tree, list), \n-\t VEC_length (tree, list), \n-\t sizeof (tree),\n-\t operand_build_cmp);\n-}\n-\n /*  Return true if the SSA operands cache is active.  */\n \n bool\n@@ -276,94 +180,44 @@ ssa_operands_active (void)\n   return cfun->gimple_df && gimple_ssa_operands (cfun)->ops_active;\n }\n \n+ \n+/* Create the VOP variable, an artificial global variable to act as a\n+   representative of all of the virtual operands FUD chain.  */\n \n-/* VOPs are of variable sized, so the free list maps \"free buckets\" to the \n-   following table:  \n-    bucket   # operands\n-    ------   ----------\n-\t0\t1\n-\t1\t2\n-\t  ...\n-\t15\t16\n-\t16\t17-24\n-\t17\t25-32\n-\t18\t31-40\n-\t  ...\n-\t29\t121-128\n-   Any VOPs larger than this are simply added to the largest bucket when they\n-   are freed.  */\n-\n-\n-/* Return the number of operands used in bucket BUCKET.  */\n-\n-static inline int\n-vop_free_bucket_size (int bucket)\n-{\n-#ifdef ENABLE_CHECKING\n-  gcc_assert (bucket >= 0 && bucket < NUM_VOP_FREE_BUCKETS);\n-#endif\n-  if (bucket < 16)\n-    return bucket + 1;\n-  return (bucket - 13) * 8;\n-}\n-\n-\n-/* For a vop of NUM operands, return the bucket NUM belongs to.  If NUM is \n-   beyond the end of the bucket table, return -1.  */\n-\n-static inline int \n-vop_free_bucket_index (int num)\n-{\n-  gcc_assert (num > 0 && NUM_VOP_FREE_BUCKETS > 16);\n-\n-  /* Sizes 1 through 16 use buckets 0-15.  */\n-  if (num <= 16)\n-    return num - 1;\n-  /* Buckets 16 - NUM_VOP_FREE_BUCKETS represent 8 unit chunks.  */\n-  num = 14 + (num - 1) / 8;\n-  if (num >= NUM_VOP_FREE_BUCKETS)\n-    return -1;\n-  else\n-    return num;\n-}\n-\n-\n-/* Initialize the VOP free buckets.  */\n-\n-static inline void\n-init_vop_buckets (void)\n-{\n-  int x;\n-\n-  for (x = 0; x < NUM_VOP_FREE_BUCKETS; x++)\n-    gimple_ssa_operands (cfun)->vop_free_buckets[x] = NULL;\n-}\n-\n-\n-/* Add PTR to the appropriate VOP bucket.  */\n-\n-static inline void\n-add_vop_to_freelist (voptype_p ptr)\n+static void\n+create_vop_var (void)\n {\n-  int bucket = vop_free_bucket_index (VUSE_VECT_NUM_ELEM (ptr->usev));\n-\n-  /* Too large, use the largest bucket so its not a complete throw away.  */\n-  if (bucket == -1)\n-    bucket = NUM_VOP_FREE_BUCKETS - 1;\n-\n-  ptr->next = gimple_ssa_operands (cfun)->vop_free_buckets[bucket];\n-  gimple_ssa_operands (cfun)->vop_free_buckets[bucket] = ptr;\n+  tree global_var;\n+\n+  gcc_assert (cfun->gimple_df->vop == NULL_TREE);\n+\n+  global_var = build_decl (VAR_DECL, get_identifier (\".MEM\"),\n+\t\t\t   void_type_node);\n+  DECL_ARTIFICIAL (global_var) = 1;\n+  TREE_READONLY (global_var) = 0;\n+  DECL_EXTERNAL (global_var) = 1;\n+  TREE_STATIC (global_var) = 1;\n+  TREE_USED (global_var) = 1;\n+  DECL_CONTEXT (global_var) = NULL_TREE;\n+  TREE_THIS_VOLATILE (global_var) = 0;\n+  TREE_ADDRESSABLE (global_var) = 0;\n+\n+  create_var_ann (global_var);\n+  add_referenced_var (global_var);\n+  cfun->gimple_df->vop = global_var;\n }\n- \n \n-/* These are the sizes of the operand memory  buffer which gets allocated each \n-   time more operands space is required.  The final value is the amount that is\n-   allocated every time after that.  */\n+/* These are the sizes of the operand memory buffer in bytes which gets\n+   allocated each time more operands space is required.  The final value is\n+   the amount that is allocated every time after that.\n+   In 1k we can fit 25 use operands (or 63 def operands) on a host with\n+   8 byte pointers, that would be 10 statements each with 1 def and 2\n+   uses.  */\n   \n #define OP_SIZE_INIT\t0\n-#define OP_SIZE_1\t30\n-#define OP_SIZE_2\t110\n-#define OP_SIZE_3\t511\n+#define OP_SIZE_1\t(1024 - sizeof (void *))\n+#define OP_SIZE_2\t(1024 * 4 - sizeof (void *))\n+#define OP_SIZE_3\t(1024 * 16 - sizeof (void *))\n \n /* Initialize the operand cache routines.  */\n \n@@ -374,22 +228,19 @@ init_ssa_operands (void)\n     {\n       build_defs = VEC_alloc (tree, heap, 5);\n       build_uses = VEC_alloc (tree, heap, 10);\n-      build_vuses = VEC_alloc (tree, heap, 25);\n-      build_vdefs = VEC_alloc (tree, heap, 25);\n+      build_vuse = NULL_TREE;\n+      build_vdef = NULL_TREE;\n       bitmap_obstack_initialize (&operands_bitmap_obstack);\n-      build_loads = BITMAP_ALLOC (&operands_bitmap_obstack);\n-      build_stores = BITMAP_ALLOC (&operands_bitmap_obstack);\n-      scb_stack = VEC_alloc (scb_t, heap, 20);\n+      scb_stack = VEC_alloc (gimple_p, heap, 20);\n     }\n \n   gcc_assert (gimple_ssa_operands (cfun)->operand_memory == NULL);\n-  gcc_assert (gimple_ssa_operands (cfun)->mpt_table == NULL);\n   gimple_ssa_operands (cfun)->operand_memory_index\n      = gimple_ssa_operands (cfun)->ssa_operand_mem_size;\n   gimple_ssa_operands (cfun)->ops_active = true;\n   memset (&clobber_stats, 0, sizeof (clobber_stats));\n-  init_vop_buckets ();\n   gimple_ssa_operands (cfun)->ssa_operand_mem_size = OP_SIZE_INIT;\n+  create_vop_var ();\n }\n \n \n@@ -399,21 +250,17 @@ void\n fini_ssa_operands (void)\n {\n   struct ssa_operand_memory_d *ptr;\n-  unsigned ix;\n-  tree mpt;\n \n   if (!--n_initialized)\n     {\n       VEC_free (tree, heap, build_defs);\n       VEC_free (tree, heap, build_uses);\n-      VEC_free (tree, heap, build_vdefs);\n-      VEC_free (tree, heap, build_vuses);\n-      BITMAP_FREE (build_loads);\n-      BITMAP_FREE (build_stores);\n+      build_vdef = NULL_TREE;\n+      build_vuse = NULL_TREE;\n \n       /* The change buffer stack had better be empty.  */\n-      gcc_assert (VEC_length (scb_t, scb_stack) == 0);\n-      VEC_free (scb_t, heap, scb_stack);\n+      gcc_assert (VEC_length (gimple_p, scb_stack) == 0);\n+      VEC_free (gimple_p, heap, scb_stack);\n       scb_stack = NULL;\n     }\n \n@@ -427,21 +274,13 @@ fini_ssa_operands (void)\n       ggc_free (ptr);\n     }\n \n-  for (ix = 0;\n-       VEC_iterate (tree, gimple_ssa_operands (cfun)->mpt_table, ix, mpt);\n-       ix++)\n-    {\n-      if (mpt)\n-\tBITMAP_FREE (MPT_SYMBOLS (mpt));\n-    }\n-\n-  VEC_free (tree, heap, gimple_ssa_operands (cfun)->mpt_table);\n-\n   gimple_ssa_operands (cfun)->ops_active = false;\n \n   if (!n_initialized)\n     bitmap_obstack_release (&operands_bitmap_obstack);\n \n+  cfun->gimple_df->vop = NULL_TREE;\n+\n   if (dump_file && (dump_flags & TDF_STATS))\n     {\n       fprintf (dump_file, \"Original clobbered vars:           %d\\n\",\n@@ -460,47 +299,45 @@ fini_ssa_operands (void)\n }\n \n \n-/* Return memory for operands of SIZE chunks.  */\n+/* Return memory for an operand of size SIZE.  */\n                                                                               \n static inline void *\n ssa_operand_alloc (unsigned size)\n {\n   char *ptr;\n \n+  gcc_assert (size == sizeof (struct use_optype_d)\n+\t      || size == sizeof (struct def_optype_d));\n+\n   if (gimple_ssa_operands (cfun)->operand_memory_index + size\n       >= gimple_ssa_operands (cfun)->ssa_operand_mem_size)\n     {\n       struct ssa_operand_memory_d *ptr;\n \n-      if (gimple_ssa_operands (cfun)->ssa_operand_mem_size == OP_SIZE_INIT)\n-\tgimple_ssa_operands (cfun)->ssa_operand_mem_size\n-\t   = OP_SIZE_1 * sizeof (struct voptype_d);\n-      else\n-\tif (gimple_ssa_operands (cfun)->ssa_operand_mem_size\n-\t    == OP_SIZE_1 * sizeof (struct voptype_d))\n-\t  gimple_ssa_operands (cfun)->ssa_operand_mem_size\n-\t     = OP_SIZE_2 * sizeof (struct voptype_d);\n-\telse\n-\t  gimple_ssa_operands (cfun)->ssa_operand_mem_size\n-\t     = OP_SIZE_3 * sizeof (struct voptype_d);\n-\n-      /* Go right to the maximum size if the request is too large.  */\n-      if (size > gimple_ssa_operands (cfun)->ssa_operand_mem_size)\n-        gimple_ssa_operands (cfun)->ssa_operand_mem_size\n-\t  = OP_SIZE_3 * sizeof (struct voptype_d);\n-\n-      /* We can reliably trigger the case that we need arbitrary many\n-\t operands (see PR34093), so allocate a buffer just for this request.  */\n-      if (size > gimple_ssa_operands (cfun)->ssa_operand_mem_size)\n-\tgimple_ssa_operands (cfun)->ssa_operand_mem_size = size;\n+      switch (gimple_ssa_operands (cfun)->ssa_operand_mem_size)\n+\t{\n+\tcase OP_SIZE_INIT:\n+\t  gimple_ssa_operands (cfun)->ssa_operand_mem_size = OP_SIZE_1;\n+\t  break;\n+\tcase OP_SIZE_1:\n+\t  gimple_ssa_operands (cfun)->ssa_operand_mem_size = OP_SIZE_2;\n+\t  break;\n+\tcase OP_SIZE_2:\n+\tcase OP_SIZE_3:\n+\t  gimple_ssa_operands (cfun)->ssa_operand_mem_size = OP_SIZE_3;\n+\t  break;\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n \n       ptr = (struct ssa_operand_memory_d *) \n-\t      ggc_alloc (sizeof (struct ssa_operand_memory_d) \n-\t\t\t + gimple_ssa_operands (cfun)->ssa_operand_mem_size - 1);\n+\t      ggc_alloc (sizeof (void *)\n+\t\t\t + gimple_ssa_operands (cfun)->ssa_operand_mem_size);\n       ptr->next = gimple_ssa_operands (cfun)->operand_memory;\n       gimple_ssa_operands (cfun)->operand_memory = ptr;\n       gimple_ssa_operands (cfun)->operand_memory_index = 0;\n     }\n+\n   ptr = &(gimple_ssa_operands (cfun)->operand_memory\n \t  ->mem[gimple_ssa_operands (cfun)->operand_memory_index]);\n   gimple_ssa_operands (cfun)->operand_memory_index += size;\n@@ -546,55 +383,6 @@ alloc_use (void)\n }\n \n \n-/* Allocate a vop with NUM elements.  */\n-\n-static inline struct voptype_d *\n-alloc_vop (int num)\n-{\n-  struct voptype_d *ret = NULL;\n-  int alloc_size = 0;\n-\n-  int bucket = vop_free_bucket_index (num);\n-  if (bucket != -1)\n-    {\n-      /* If there is a free operand, use it.  */\n-      if (gimple_ssa_operands (cfun)->vop_free_buckets[bucket] != NULL)\n-\t{\n-\t  ret = gimple_ssa_operands (cfun)->vop_free_buckets[bucket];\n-\t  gimple_ssa_operands (cfun)->vop_free_buckets[bucket] = \n-\t\t  gimple_ssa_operands (cfun)->vop_free_buckets[bucket]->next;\n-\t}\n-      else\n-        alloc_size = vop_free_bucket_size(bucket);\n-    }\n-  else\n-    alloc_size = num;\n-\n-  if (alloc_size > 0)\n-    ret = (struct voptype_d *)ssa_operand_alloc (\n-\tsizeof (struct voptype_d) + (alloc_size - 1) * sizeof (vuse_element_t));\n-\n-  VUSE_VECT_NUM_ELEM (ret->usev) = num;\n-  return ret;\n-}\n-\n-\n-/* This routine makes sure that PTR is in an immediate use list, and makes\n-   sure the stmt pointer is set to the current stmt.  */\n-\n-static inline void\n-set_virtual_use_link (use_operand_p ptr, gimple stmt)\n-{\n-  /*  fold_stmt may have changed the stmt pointers.  */\n-  if (ptr->loc.stmt != stmt)\n-    ptr->loc.stmt = stmt;\n-\n-  /* If this use isn't in a list, add it to the correct list.  */\n-  if (!ptr->prev)\n-    link_imm_use (ptr, *(ptr->use));\n-}\n-\n-\n /* Adds OP to the list of defs after LAST.  */\n \n static inline def_optype_p \n@@ -626,56 +414,6 @@ add_use_op (gimple stmt, tree *op, use_optype_p last)\n }\n \n \n-/* Return a virtual op pointer with NUM elements which are all\n-   initialized to OP and are linked into the immediate uses for STMT.\n-   The new vop is appended after PREV.  */\n-\n-static inline voptype_p\n-add_vop (gimple stmt, tree op, int num, voptype_p prev)\n-{\n-  voptype_p new_vop;\n-  int x;\n-\n-  new_vop = alloc_vop (num);\n-  for (x = 0; x < num; x++)\n-    {\n-      VUSE_OP_PTR (new_vop, x)->prev = NULL;\n-      SET_VUSE_OP (new_vop, x, op);\n-      VUSE_OP_PTR (new_vop, x)->use = &new_vop->usev.uses[x].use_var;\n-      link_imm_use_stmt (VUSE_OP_PTR (new_vop, x),\n-\t\t\t new_vop->usev.uses[x].use_var, stmt);\n-    }\n-\n-  if (prev)\n-    prev->next = new_vop;\n-  new_vop->next = NULL;\n-  return new_vop;\n-}\n-\n-\n-/* Adds OP to the list of vuses of statement STMT after LAST, and moves\n-   LAST to the new element.  */\n-\n-static inline voptype_p\n-add_vuse_op (gimple stmt, tree op, int num, voptype_p last)\n-{\n-  voptype_p new_vop = add_vop (stmt, op, num, last);\n-  VDEF_RESULT (new_vop) = NULL_TREE;\n-  return new_vop;\n-}\n-\n-\n-/* Adds OP to the list of vdefs of statement STMT after LAST, and moves\n-   LAST to the new element.  */\n-\n-static inline voptype_p\n-add_vdef_op (gimple stmt, tree op, int num, voptype_p last)\n-{\n-  voptype_p new_vop = add_vop (stmt, op, num, last);\n-  VDEF_RESULT (new_vop) = op;\n-  return new_vop;\n-}\n-  \n \n /* Takes elements from build_defs and turns them into def operands of STMT.\n    TODO -- Make build_defs VEC of tree *.  */\n@@ -691,13 +429,43 @@ finalize_ssa_defs (gimple stmt)\n   /* There should only be a single real definition per assignment.  */\n   gcc_assert ((stmt && gimple_code (stmt) != GIMPLE_ASSIGN) || num <= 1);\n \n+  /* Pre-pend the vdef we may have built.  */\n+  if (build_vdef != NULL_TREE)\n+    {\n+      tree oldvdef = gimple_vdef (stmt);\n+      if (oldvdef\n+\t  && TREE_CODE (oldvdef) == SSA_NAME)\n+\toldvdef = SSA_NAME_VAR (oldvdef);\n+      if (oldvdef != build_vdef)\n+\tgimple_set_vdef (stmt, build_vdef);\n+      VEC_safe_insert (tree, heap, build_defs, 0, (tree)gimple_vdef_ptr (stmt));\n+      ++num;\n+    }\n+\n   new_list.next = NULL;\n   last = &new_list;\n \n   old_ops = gimple_def_ops (stmt);\n \n   new_i = 0;\n \n+  /* Clear and unlink a no longer necessary VDEF.  */\n+  if (build_vdef == NULL_TREE\n+      && gimple_vdef (stmt) != NULL_TREE)\n+    {\n+      if (TREE_CODE (gimple_vdef (stmt)) == SSA_NAME)\n+\t{\n+\t  unlink_stmt_vdef (stmt);\n+\t  release_ssa_name (gimple_vdef (stmt));\n+\t}\n+      gimple_set_vdef (stmt, NULL_TREE);\n+    }\n+\n+  /* If we have a non-SSA_NAME VDEF, mark it for renaming.  */\n+  if (gimple_vdef (stmt)\n+      && TREE_CODE (gimple_vdef (stmt)) != SSA_NAME)\n+    mark_sym_for_renaming (gimple_vdef (stmt));\n+\n   /* Check for the common case of 1 def that hasn't changed.  */\n   if (old_ops && old_ops->next == NULL && num == 1\n       && (tree *) VEC_index (tree, build_defs, 0) == DEF_OP_PTR (old_ops))\n@@ -716,17 +484,6 @@ finalize_ssa_defs (gimple stmt)\n \n   /* Now set the stmt's operands.  */\n   gimple_set_def_ops (stmt, new_list.next);\n-\n-#ifdef ENABLE_CHECKING\n-  {\n-    def_optype_p ptr;\n-    unsigned x = 0;\n-    for (ptr = gimple_def_ops (stmt); ptr; ptr = ptr->next)\n-      x++;\n-\n-    gcc_assert (x == num);\n-  }\n-#endif\n }\n \n \n@@ -740,11 +497,29 @@ finalize_ssa_uses (gimple stmt)\n   struct use_optype_d new_list;\n   use_optype_p old_ops, ptr, last;\n \n+  /* Pre-pend the VUSE we may have built.  */\n+  if (build_vuse != NULL_TREE)\n+    {\n+      tree oldvuse = gimple_vuse (stmt);\n+      if (oldvuse\n+\t  && TREE_CODE (oldvuse) == SSA_NAME)\n+\toldvuse = SSA_NAME_VAR (oldvuse);\n+      if (oldvuse != (build_vuse != NULL_TREE\n+\t\t      ? build_vuse : build_vdef))\n+\tgimple_set_vuse (stmt, NULL_TREE);\n+      VEC_safe_insert (tree, heap, build_uses, 0, (tree)gimple_vuse_ptr (stmt));\n+    }\n+\n   new_list.next = NULL;\n   last = &new_list;\n \n   old_ops = gimple_use_ops (stmt);\n \n+  /* Clear a no longer necessary VUSE.  */\n+  if (build_vuse == NULL_TREE\n+      && gimple_vuse (stmt) != NULL_TREE)\n+    gimple_set_vuse (stmt, NULL_TREE);\n+\n   /* If there is anything in the old list, free it.  */\n   if (old_ops)\n     {\n@@ -754,6 +529,15 @@ finalize_ssa_uses (gimple stmt)\n       gimple_ssa_operands (cfun)->free_uses = old_ops;\n     }\n \n+  /* If we added a VUSE, make sure to set the operand if it is not already\n+     present and mark it for renaming.  */\n+  if (build_vuse != NULL_TREE\n+      && gimple_vuse (stmt) == NULL_TREE)\n+    {\n+      gimple_set_vuse (stmt, gimple_vop (cfun));\n+      mark_sym_for_renaming (gimple_vop (cfun));\n+    }\n+\n   /* Now create nodes for all the new nodes.  */\n   for (new_i = 0; new_i < VEC_length (tree, build_uses); new_i++)\n     last = add_use_op (stmt, \n@@ -762,259 +546,6 @@ finalize_ssa_uses (gimple stmt)\n \n   /* Now set the stmt's operands.  */\n   gimple_set_use_ops (stmt, new_list.next);\n-\n-#ifdef ENABLE_CHECKING\n-  {\n-    unsigned x = 0;\n-    for (ptr = gimple_use_ops (stmt); ptr; ptr = ptr->next)\n-      x++;\n-\n-    gcc_assert (x == VEC_length (tree, build_uses));\n-  }\n-#endif\n-}\n-\n-\n-/* Takes elements from BUILD_VDEFS and turns them into vdef operands of\n-   STMT.  */\n-\n-static inline void\n-finalize_ssa_vdefs (gimple stmt)\n-{\n-  unsigned new_i;\n-  struct voptype_d new_list;\n-  voptype_p old_ops, ptr, last;\n-\n-  /* Set the symbols referenced by STMT.  */\n-  gimple_set_stored_syms (stmt, build_stores, &operands_bitmap_obstack);\n-\n-  /* If aliases have not been computed, do not instantiate a virtual\n-     operator on STMT.  Initially, we only compute the SSA form on\n-     GIMPLE registers.  The virtual SSA form is only computed after\n-     alias analysis, so virtual operators will remain unrenamed and\n-     the verifier will complain.  However, alias analysis needs to\n-     access symbol load/store information, so we need to compute\n-     those.  */\n-  if (!gimple_aliases_computed_p (cfun))\n-    return;\n-\n-  new_list.next = NULL;\n-  last = &new_list;\n-\n-  old_ops = gimple_vdef_ops (stmt);\n-  new_i = 0;\n-  while (old_ops && new_i < VEC_length (tree, build_vdefs))\n-    {\n-      tree op = VEC_index (tree, build_vdefs, new_i);\n-      unsigned new_uid = get_name_decl (op);\n-      unsigned old_uid = get_name_decl (VDEF_RESULT (old_ops));\n-\n-      /* FIXME, for now each VDEF operator should have at most one\n-\t operand in their RHS.  */\n-      gcc_assert (VDEF_NUM (old_ops) == 1);\n-\n-      if (old_uid == new_uid)\n-        {\n-\t  /* If the symbols are the same, reuse the existing operand.  */\n-\t  last->next = old_ops;\n-\t  last = old_ops;\n-\t  old_ops = old_ops->next;\n-\t  last->next = NULL;\n-\t  set_virtual_use_link (VDEF_OP_PTR (last, 0), stmt);\n-\t  new_i++;\n-\t}\n-      else if (old_uid < new_uid)\n-\t{\n-\t  /* If old is less than new, old goes to the free list.  */\n-\t  voptype_p next;\n-\t  delink_imm_use (VDEF_OP_PTR (old_ops, 0));\n-\t  next = old_ops->next;\n-\t  add_vop_to_freelist (old_ops);\n-\t  old_ops = next;\n-\t}\n-      else\n-\t{\n-\t  /* This is a new operand.  */\n-\t  last = add_vdef_op (stmt, op, 1, last);\n-\t  new_i++;\n-\t}\n-    }\n-\n-  /* If there is anything remaining in BUILD_VDEFS, simply emit it.  */\n-  for ( ; new_i < VEC_length (tree, build_vdefs); new_i++)\n-    last = add_vdef_op (stmt, VEC_index (tree, build_vdefs, new_i), 1, last);\n-\n-  /* If there is anything in the old list, free it.  */\n-  if (old_ops)\n-    {\n-      for (ptr = old_ops; ptr; ptr = last)\n-        {\n-\t  last = ptr->next;\n-\t  delink_imm_use (VDEF_OP_PTR (ptr, 0));\n-\t  add_vop_to_freelist (ptr);\n-\t}\n-    }\n-\n-  /* Now set STMT's operands.  */\n-  gimple_set_vdef_ops (stmt, new_list.next);\n-\n-#ifdef ENABLE_CHECKING\n-  {\n-    unsigned x = 0;\n-    for (ptr = gimple_vdef_ops (stmt); ptr; ptr = ptr->next)\n-      x++;\n-\n-    gcc_assert (x == VEC_length (tree, build_vdefs));\n-  }\n-#endif\n-}\n-\n-\n-/* Takes elements from BUILD_VUSES and turns them into VUSE operands of\n-   STMT.  */\n-\n-static inline void\n-finalize_ssa_vuse_ops (gimple stmt)\n-{\n-  unsigned new_i, old_i;\n-  voptype_p old_ops, last;\n-  VEC(tree,heap) *new_ops;\n-\n-  /* Set the symbols referenced by STMT.  */\n-  gimple_set_loaded_syms (stmt, build_loads, &operands_bitmap_obstack);\n-\n-  /* If aliases have not been computed, do not instantiate a virtual\n-     operator on STMT.  Initially, we only compute the SSA form on\n-     GIMPLE registers.  The virtual SSA form is only computed after\n-     alias analysis, so virtual operators will remain unrenamed and\n-     the verifier will complain.  However, alias analysis needs to\n-     access symbol load/store information, so we need to compute\n-     those.  */\n-  if (!gimple_aliases_computed_p (cfun))\n-    return;\n-\n-  /* STMT should have at most one VUSE operator.  */\n-  old_ops = gimple_vuse_ops (stmt);\n-  gcc_assert (old_ops == NULL || old_ops->next == NULL);\n-\n-  new_ops = NULL;\n-  new_i = old_i = 0;\n-  while (old_ops\n-         && old_i < VUSE_NUM (old_ops)\n-\t && new_i < VEC_length (tree, build_vuses))\n-    {\n-      tree new_op = VEC_index (tree, build_vuses, new_i);\n-      tree old_op = VUSE_OP (old_ops, old_i);\n-      unsigned new_uid = get_name_decl (new_op);\n-      unsigned old_uid = get_name_decl (old_op);\n-\n-      if (old_uid == new_uid)\n-        {\n-\t  /* If the symbols are the same, reuse the existing operand.  */\n-\t  VEC_safe_push (tree, heap, new_ops, old_op);\n-\t  new_i++;\n-\t  old_i++;\n-\t}\n-      else if (old_uid < new_uid)\n-\t{\n-\t  /* If OLD_UID is less than NEW_UID, the old operand has\n-\t     disappeared, skip to the next old operand.  */\n-\t  old_i++;\n-\t}\n-      else\n-\t{\n-\t  /* This is a new operand.  */\n-\t  VEC_safe_push (tree, heap, new_ops, new_op);\n-\t  new_i++;\n-\t}\n-    }\n-\n-  /* If there is anything remaining in the build_vuses list, simply emit it.  */\n-  for ( ; new_i < VEC_length (tree, build_vuses); new_i++)\n-    VEC_safe_push (tree, heap, new_ops, VEC_index (tree, build_vuses, new_i));\n-\n-  /* If there is anything in the old list, free it.  */\n-  if (old_ops)\n-    {\n-      for (old_i = 0; old_i < VUSE_NUM (old_ops); old_i++)\n-\tdelink_imm_use (VUSE_OP_PTR (old_ops, old_i));\n-      add_vop_to_freelist (old_ops);\n-      gimple_set_vuse_ops (stmt, NULL);\n-    }\n-\n-  /* If there are any operands, instantiate a VUSE operator for STMT.  */\n-  if (new_ops)\n-    {\n-      tree op;\n-      unsigned i;\n-\n-      last = add_vuse_op (stmt, NULL, VEC_length (tree, new_ops), NULL);\n-\n-      for (i = 0; VEC_iterate (tree, new_ops, i, op); i++)\n-\tSET_USE (VUSE_OP_PTR (last, (int) i), op);\n-\n-      gimple_set_vuse_ops (stmt, last);\n-      VEC_free (tree, heap, new_ops);\n-    }\n-\n-#ifdef ENABLE_CHECKING\n-  {\n-    unsigned x;\n-    \n-    if (gimple_vuse_ops (stmt))\n-      {\n-\tgcc_assert (gimple_vuse_ops (stmt)->next == NULL);\n-\tx = VUSE_NUM (gimple_vuse_ops (stmt));\n-      }\n-    else\n-      x = 0;\n-\n-    gcc_assert (x == VEC_length (tree, build_vuses));\n-  }\n-#endif\n-}\n-\n-/* Return a new VUSE operand vector for STMT.  */\n-                                                                              \n-static void\n-finalize_ssa_vuses (gimple stmt)\n-{\n-  unsigned num, num_vdefs;\n-  unsigned vuse_index;\n-\n-  /* Remove superfluous VUSE operands.  If the statement already has a\n-     VDEF operator for a variable 'a', then a VUSE for 'a' is not\n-     needed because VDEFs imply a VUSE of the variable.  For instance,\n-     suppose that variable 'a' is pointed-to by p and q:\n-\n-\t      # VUSE <a_2>\n-\t      # a_3 = VDEF <a_2>\n-\t      *p = *q;\n-\n-     The VUSE <a_2> is superfluous because it is implied by the\n-     VDEF operator.  */\n-  num = VEC_length (tree, build_vuses);\n-  num_vdefs = VEC_length (tree, build_vdefs);\n-\n-  if (num > 0 && num_vdefs > 0)\n-    for (vuse_index = 0; vuse_index < VEC_length (tree, build_vuses); )\n-      {\n-\ttree vuse;\n-\tvuse = VEC_index (tree, build_vuses, vuse_index);\n-\tif (TREE_CODE (vuse) != SSA_NAME)\n-\t  {\n-\t    var_ann_t ann = var_ann (vuse);\n-\t    ann->in_vuse_list = 0;\n-\t    if (ann->in_vdef_list)\n-\t      {\n-\t\tVEC_ordered_remove (tree, build_vuses, vuse_index);\n-\t\tcontinue;\n-\t      }\n-\t  }\n-\tvuse_index++;\n-      }\n-\n-  finalize_ssa_vuse_ops (stmt);\n }\n \n \n@@ -1024,23 +555,10 @@ finalize_ssa_vuses (gimple stmt)\n static inline void\n cleanup_build_arrays (void)\n {\n-  unsigned i;\n-  tree t;\n-\n-  for (i = 0; VEC_iterate (tree, build_vdefs, i, t); i++)\n-    if (TREE_CODE (t) != SSA_NAME)\n-      var_ann (t)->in_vdef_list = false;\n-\n-  for (i = 0; VEC_iterate (tree, build_vuses, i, t); i++)\n-    if (TREE_CODE (t) != SSA_NAME)\n-      var_ann (t)->in_vuse_list = false;\n-\n-  VEC_truncate (tree, build_vdefs, 0);\n-  VEC_truncate (tree, build_vuses, 0);\n+  build_vdef = NULL_TREE;\n+  build_vuse = NULL_TREE;\n   VEC_truncate (tree, build_defs, 0);\n   VEC_truncate (tree, build_uses, 0);\n-  bitmap_clear (build_loads);\n-  bitmap_clear (build_stores);\n }\n \n \n@@ -1051,11 +569,6 @@ finalize_ssa_stmt_operands (gimple stmt)\n {\n   finalize_ssa_defs (stmt);\n   finalize_ssa_uses (stmt);\n-  if (gimple_has_mem_ops (stmt))\n-    {\n-      finalize_ssa_vdefs (stmt);\n-      finalize_ssa_vuses (stmt);\n-    }\n   cleanup_build_arrays ();\n }\n \n@@ -1067,10 +580,8 @@ start_ssa_stmt_operands (void)\n {\n   gcc_assert (VEC_length (tree, build_defs) == 0);\n   gcc_assert (VEC_length (tree, build_uses) == 0);\n-  gcc_assert (VEC_length (tree, build_vuses) == 0);\n-  gcc_assert (VEC_length (tree, build_vdefs) == 0);\n-  gcc_assert (bitmap_empty_p (build_loads));\n-  gcc_assert (bitmap_empty_p (build_stores));\n+  gcc_assert (build_vuse == NULL_TREE);\n+  gcc_assert (build_vdef == NULL_TREE);\n }\n \n \n@@ -1097,31 +608,13 @@ append_use (tree *use_p)\n static inline void\n append_vdef (tree var)\n {\n-  tree sym;\n-\n-  if (TREE_CODE (var) != SSA_NAME)\n-    {\n-      tree mpt;\n-      var_ann_t ann;\n+  gcc_assert ((build_vdef == NULL_TREE\n+\t       || build_vdef == var)\n+\t      && (build_vuse == NULL_TREE\n+\t\t  || build_vuse == var));\n \n-      /* If VAR belongs to a memory partition, use it instead of VAR.  */\n-      mpt = memory_partition (var);\n-      if (mpt)\n-\tvar = mpt;\n-\n-      /* Don't allow duplicate entries.  */\n-      ann = get_var_ann (var);\n-      if (ann->in_vdef_list)\n-        return;\n-\n-      ann->in_vdef_list = true;\n-      sym = var;\n-    }\n-  else\n-    sym = SSA_NAME_VAR (var);\n-\n-  VEC_safe_push (tree, heap, build_vdefs, var);\n-  bitmap_set_bit (build_stores, DECL_UID (sym));\n+  build_vdef = var;\n+  build_vuse = var;\n }\n \n \n@@ -1130,303 +623,27 @@ append_vdef (tree var)\n static inline void\n append_vuse (tree var)\n {\n-  tree sym;\n-\n-  if (TREE_CODE (var) != SSA_NAME)\n-    {\n-      tree mpt;\n-      var_ann_t ann;\n-\n-      /* If VAR belongs to a memory partition, use it instead of VAR.  */\n-      mpt = memory_partition (var);\n-      if (mpt)\n-\tvar = mpt;\n-\n-      /* Don't allow duplicate entries.  */\n-      ann = get_var_ann (var);\n-      if (ann->in_vuse_list)\n-\treturn;\n-      else if (ann->in_vdef_list)\n-       {\n-         /* We don't want a vuse if we already have a vdef, but we must\n-            still put this in build_loads.  */\n-         bitmap_set_bit (build_loads, DECL_UID (var));\n-         return;\n-       }\n-\n-      ann->in_vuse_list = true;\n-      sym = var;\n-    }\n-  else\n-    sym = SSA_NAME_VAR (var);\n-\n-  VEC_safe_push (tree, heap, build_vuses, var);\n-  bitmap_set_bit (build_loads, DECL_UID (sym));\n-}\n-\n-\n-/* REF is a tree that contains the entire pointer dereference\n-   expression, if available, or NULL otherwise.  ALIAS is the variable\n-   we are asking if REF can access.  OFFSET and SIZE come from the\n-   memory access expression that generated this virtual operand.\n-\n-   XXX: We should handle the NO_ALIAS attributes here.  */\n-\n-static bool\n-access_can_touch_variable (tree ref, tree alias, HOST_WIDE_INT offset,\n-\t\t\t   HOST_WIDE_INT size)\n-{\n-  bool offsetgtz = offset > 0;\n-  unsigned HOST_WIDE_INT uoffset = (unsigned HOST_WIDE_INT) offset;\n-  tree base = ref ? get_base_address (ref) : NULL;\n-\n-  /* If ALIAS is .GLOBAL_VAR then the memory reference REF must be\n-     using a call-clobbered memory tag.  By definition, call-clobbered\n-     memory tags can always touch .GLOBAL_VAR.  */\n-  if (alias == gimple_global_var (cfun))\n-    return true;\n-\n-  /* If ref is a TARGET_MEM_REF, just return true, as we can't really\n-     disambiguate them right now.  */\n-  if (ref && TREE_CODE (ref) == TARGET_MEM_REF)\n-    return true;\n-  \n-  /* Without strict aliasing, it is impossible for a component access\n-     through a pointer to touch a random variable, unless that\n-     variable *is* a structure or a pointer.\n-\n-     That is, given p->c, and some random global variable b,\n-     there is no legal way that p->c could be an access to b.\n-     \n-     Without strict aliasing on, we consider it legal to do something\n-     like:\n-\n-     struct foos { int l; };\n-     int foo;\n-     static struct foos *getfoo(void);\n-     int main (void)\n-     {\n-       struct foos *f = getfoo();\n-       f->l = 1;\n-       foo = 2;\n-       if (f->l == 1)\n-         abort();\n-       exit(0);\n-     }\n-     static struct foos *getfoo(void)     \n-     { return (struct foos *)&foo; }\n-     \n-     (taken from 20000623-1.c)\n-\n-     The docs also say/imply that access through union pointers\n-     is legal (but *not* if you take the address of the union member,\n-     i.e. the inverse), such that you can do\n-\n-     typedef union {\n-       int d;\n-     } U;\n-\n-     int rv;\n-     void breakme()\n-     {\n-       U *rv0;\n-       U *pretmp = (U*)&rv;\n-       rv0 = pretmp;\n-       rv0->d = 42;    \n-     }\n-     To implement this, we just punt on accesses through union\n-     pointers entirely.\n-\n-     Another case we have to allow is accessing a variable\n-     through an array access at offset zero.  This happens from\n-     code generated by the fortran frontend like\n-\n-     char[1:1] & my_char_ref;\n-     char my_char;\n-     my_char_ref_1 = (char[1:1] &) &my_char;\n-     D.874_2 = (*my_char_ref_1)[1]{lb: 1 sz: 1};\n-  */\n-  if (ref \n-      && flag_strict_aliasing\n-      && TREE_CODE (ref) != INDIRECT_REF\n-      && !MTAG_P (alias)\n-      && base\n-      && (TREE_CODE (base) != INDIRECT_REF\n-\t  || TREE_CODE (TREE_TYPE (base)) != UNION_TYPE)\n-      && (TREE_CODE (base) != INDIRECT_REF\n-\t  || TREE_CODE (ref) != ARRAY_REF\n-\t  || offset != 0\n-\t  || (DECL_SIZE (alias)\n-\t      && TREE_CODE (DECL_SIZE (alias)) == INTEGER_CST\n-\t      && size != -1\n-\t      && (unsigned HOST_WIDE_INT)size\n-\t      != TREE_INT_CST_LOW (DECL_SIZE (alias))))\n-      && !AGGREGATE_TYPE_P (TREE_TYPE (alias))\n-      && TREE_CODE (TREE_TYPE (alias)) != COMPLEX_TYPE\n-      && !var_ann (alias)->is_heapvar\n-      /* When the struct has may_alias attached to it, we need not to\n-\t return true.  */\n-      && get_alias_set (base))\n-    {\n-#ifdef ACCESS_DEBUGGING\n-      fprintf (stderr, \"Access to \");\n-      print_generic_expr (stderr, ref, 0);\n-      fprintf (stderr, \" may not touch \");\n-      print_generic_expr (stderr, alias, 0);\n-      fprintf (stderr, \" in function %s\\n\", get_name (current_function_decl));\n-#endif\n-      return false;\n-    }\n-\n-  /* If the offset of the access is greater than the size of one of\n-     the possible aliases, it can't be touching that alias, because it\n-     would be past the end of the structure.  */\n-  else if (ref\n-\t   && flag_strict_aliasing\n-\t   && TREE_CODE (ref) != INDIRECT_REF\n-\t   && !MTAG_P (alias)\n-\t   && !var_ann (alias)->is_heapvar\n-\t   && !POINTER_TYPE_P (TREE_TYPE (alias))\n-\t   && offsetgtz\n-\t   && DECL_SIZE (alias)\n-\t   && TREE_CODE (DECL_SIZE (alias)) == INTEGER_CST\n-\t   && uoffset >= TREE_INT_CST_LOW (DECL_SIZE (alias)))\n-    {\n-#ifdef ACCESS_DEBUGGING\n-      fprintf (stderr, \"Access to \");\n-      print_generic_expr (stderr, ref, 0);\n-      fprintf (stderr, \" may not touch \");\n-      print_generic_expr (stderr, alias, 0);\n-      fprintf (stderr, \" in function %s\\n\", get_name (current_function_decl));\n-#endif\n-      return false;\n-    }\t   \n+  gcc_assert (build_vuse == NULL_TREE\n+\t      || build_vuse == var);\n \n-  return true;\n+  build_vuse = var;\n }\n \n-/* Add VAR to the virtual operands for STMT.  FLAGS is as in\n-   get_expr_operands.  FULL_REF is a tree that contains the entire\n-   pointer dereference expression, if available, or NULL otherwise.\n-   OFFSET and SIZE come from the memory access expression that\n-   generated this virtual operand.  IS_CALL_SITE is true if the\n-   affected statement is a call site.  */\n-\n-static void\n-add_virtual_operand (tree var, gimple stmt, int flags,\n-\t\t     tree full_ref, HOST_WIDE_INT offset,\n-\t\t     HOST_WIDE_INT size, bool is_call_site)\n-{\n-  bitmap aliases = NULL;\n-  tree sym;\n-  var_ann_t v_ann;\n-  \n-  sym = (TREE_CODE (var) == SSA_NAME ? SSA_NAME_VAR (var) : var);\n-  v_ann = var_ann (sym);\n-  \n-  /* Mark the statement as having memory operands.  */\n-  gimple_set_references_memory (stmt, true);\n-\n-  /* If the variable cannot be modified and this is a VDEF change\n-     it into a VUSE.  This happens when read-only variables are marked\n-     call-clobbered and/or aliased to writable variables.  So we only\n-     check that this only happens on non-specific stores.\n-\n-     Note that if this is a specific store, i.e. associated with a\n-     MODIFY_EXPR, then we can't suppress the VDEF, lest we run\n-     into validation problems.\n-\n-     This can happen when programs cast away const, leaving us with a\n-     store to read-only memory.  If the statement is actually executed\n-     at runtime, then the program is ill formed.  If the statement is\n-     not executed then all is well.  At the very least, we cannot ICE.  */\n-  if ((flags & opf_implicit) && unmodifiable_var_p (var))\n-    flags &= ~opf_def;\n-  \n-  /* The variable is not a GIMPLE register.  Add it (or its aliases) to\n-     virtual operands, unless the caller has specifically requested\n-     not to add virtual operands (used when adding operands inside an\n-     ADDR_EXPR expression).  */\n-  if (flags & opf_no_vops)\n-    return;\n-  \n-  if (MTAG_P (var))\n-    aliases = MTAG_ALIASES (var);\n-\n-  if (aliases == NULL)\n-    {\n-      if (!gimple_aliases_computed_p (cfun) && (flags & opf_def))\n-\tgimple_set_has_volatile_ops (stmt, true);\n-\n-      /* The variable is not aliased or it is an alias tag.  */\n-      if (flags & opf_def)\n-\tappend_vdef (var);\n-      else\n-\tappend_vuse (var);\n-    }\n-  else\n-    {\n-      bitmap_iterator bi;\n-      unsigned int i;\n-      bool none_added = true;\n-      \n-      /* The variable is aliased.  Add its aliases to the virtual\n-\t operands.  */\n-      gcc_assert (!bitmap_empty_p (aliases));\n-\n-      EXECUTE_IF_SET_IN_BITMAP (aliases, 0, i, bi)\n-\t{\n-\t  tree al = referenced_var (i);\n-\n-\t  /* Call-clobbered tags may have non-call-clobbered\n-\t     symbols in their alias sets.  Ignore them if we are\n-\t     adding VOPs for a call site.  */\n-\t  if (is_call_site && !is_call_clobbered (al))\n-\t    continue;\n-\n-\t  /* If we do not know the full reference tree or if the access is\n-\t     unspecified [0, -1], we cannot prune it.  Otherwise try doing\n-\t     so using access_can_touch_variable.  */\n-\t  if (full_ref\n-\t      && !access_can_touch_variable (full_ref, al, offset, size))\n-\t    continue;\n-\n-\t  if (flags & opf_def)\n-\t    append_vdef (al);\n-\t  else\n-\t    append_vuse (al);\n-\t  none_added = false;\n-\t}\n+/* Add virtual operands for STMT.  FLAGS is as in get_expr_operands.  */\n \n-      if (flags & opf_def)\n-\t{\n-\t  /* If the variable is also an alias tag, add a virtual\n-\t     operand for it, otherwise we will miss representing\n-\t     references to the members of the variable's alias set.\t     \n-\t     This fixes the bug in gcc.c-torture/execute/20020503-1.c.\n-\t     \n-\t     It is also necessary to add bare defs on clobbers for\n-\t     SMT's, so that bare SMT uses caused by pruning all the\n-\t     aliases will link up properly with calls.   In order to\n-\t     keep the number of these bare defs we add down to the\n-\t     minimum necessary, we keep track of which SMT's were used\n-\t     alone in statement vdefs or VUSEs.  */\n-\t  if (none_added\n-\t      || (TREE_CODE (var) == SYMBOL_MEMORY_TAG\n-\t\t  && is_call_site))\n-\t    append_vdef (var);\n-\t}\n-      else\n-\t{\n-\t  /* Even if no aliases have been added, we still need to\n-\t     establish def-use and use-def chains, lest\n-\t     transformations think that this is not a memory\n-\t     reference.  For an example of this scenario, see\n-\t     testsuite/g++.dg/opt/cleanup1.C.  */\n-\t  if (none_added)\n-\t    append_vuse (var);\n-\t}\n-    }\n+static void\n+add_virtual_operand (gimple stmt ATTRIBUTE_UNUSED, int flags)\n+{\n+  /* Add virtual operands to the stmt, unless the caller has specifically\n+     requested not to do that (used when adding operands inside an\n+     ADDR_EXPR expression).  */\n+  if (flags & opf_no_vops)\n+    return;\n+\n+  if (flags & opf_def)\n+    append_vdef (gimple_vop (cfun));\n+  else\n+    append_vuse (gimple_vop (cfun));\n }\n \n \n@@ -1460,106 +677,43 @@ add_stmt_operand (tree *var_p, gimple stmt, int flags)\n \tappend_use (var_p);\n     }\n   else\n-    add_virtual_operand (var, stmt, flags, NULL_TREE, 0, -1, false);\n+    add_virtual_operand (stmt, flags);\n }\n \n-/* Subroutine of get_indirect_ref_operands.  ADDR is the address\n-   that is dereferenced, the meaning of the rest of the arguments\n-   is the same as in get_indirect_ref_operands.  */\n+/* Add the base address of REF to SET.  */\n \n static void\n-get_addr_dereference_operands (gimple stmt, tree *addr, int flags,\n-\t\t\t       tree full_ref, HOST_WIDE_INT offset,\n-\t\t\t       HOST_WIDE_INT size, bool recurse_on_base)\n+add_to_addressable_set (tree ref, bitmap *set)\n {\n-  tree ptr = *addr;\n-\n-  /* Mark the statement as having memory operands.  */\n-  gimple_set_references_memory (stmt, true);\n+  tree var;\n \n-  if (SSA_VAR_P (ptr))\n+  /* Note that it is *NOT OKAY* to use the target of a COMPONENT_REF\n+     as the only thing we take the address of.  If VAR is a structure,\n+     taking the address of a field means that the whole structure may\n+     be referenced using pointer arithmetic.  See PR 21407 and the\n+     ensuing mailing list discussion.  */\n+  var = get_base_address (ref);\n+  if (var && SSA_VAR_P (var))\n     {\n-      struct ptr_info_def *pi = NULL;\n+      if (*set == NULL)\n+\t*set = BITMAP_ALLOC (&operands_bitmap_obstack);\n \n-      /* If PTR has flow-sensitive points-to information, use it.  */\n-      if (TREE_CODE (ptr) == SSA_NAME\n-\t  && (pi = SSA_NAME_PTR_INFO (ptr)) != NULL\n-\t  && pi->name_mem_tag)\n-\t{\n-\t  /* PTR has its own memory tag.  Use it.  */\n-\t  add_virtual_operand (pi->name_mem_tag, stmt, flags,\n-\t\t\t       full_ref, offset, size, false);\n-\t}\n-      else\n-\t{\n-\t  /* If PTR is not an SSA_NAME or it doesn't have a name\n-\t     tag, use its symbol memory tag.  */\n-\t  var_ann_t v_ann;\n-\n-\t  /* If we are emitting debugging dumps, display a warning if\n-\t     PTR is an SSA_NAME with no flow-sensitive alias\n-\t     information.  That means that we may need to compute\n-\t     aliasing again or that a propagation pass forgot to\n-\t     update the alias information on the pointers.  */\n-\t  if (dump_file\n-\t      && TREE_CODE (ptr) == SSA_NAME\n-\t      && (pi == NULL\n-\t\t  || (pi->name_mem_tag == NULL_TREE\n-\t\t      && !pi->pt_anything))\n-\t      && gimple_aliases_computed_p (cfun))\n-\t    {\n-\t      fprintf (dump_file,\n-\t\t  \"NOTE: no flow-sensitive alias info for \");\n-\t      print_generic_expr (dump_file, ptr, dump_flags);\n-\t      fprintf (dump_file, \" in \");\n-\t      print_gimple_stmt (dump_file, stmt, 0, 0);\n-\t    }\n-\n-\t  if (TREE_CODE (ptr) == SSA_NAME)\n-\t    ptr = SSA_NAME_VAR (ptr);\n-\t  v_ann = var_ann (ptr);\n-\n-\t  /* If we don't know what this pointer points to then we have\n-\t     to make sure to not prune virtual operands based on offset\n-\t     and size.  */\n-\t  if (v_ann->symbol_mem_tag)\n-\t    {\n-\t      add_virtual_operand (v_ann->symbol_mem_tag, stmt, flags,\n-\t\t\t\t   full_ref, 0, -1, false);\n-\t      /* Make sure we add the SMT itself.  */\n-\t      if (!(flags & opf_no_vops))\n-\t\t{\n-\t\t  if (flags & opf_def)\n-\t\t    append_vdef (v_ann->symbol_mem_tag);\n-\t\t  else\n-\t\t    append_vuse (v_ann->symbol_mem_tag);\n-\t\t}\n-\t    }\n-\n-\t  /* Aliasing information is missing; mark statement as\n-\t     volatile so we won't optimize it out too actively.  */\n-          else if (!gimple_aliases_computed_p (cfun)\n-                   && (flags & opf_def))\n-\t    gimple_set_has_volatile_ops (stmt, true);\n-\t}\n-    }\n-  else if (TREE_CODE (ptr) == INTEGER_CST)\n-    {\n-      /* If a constant is used as a pointer, we can't generate a real\n-\t operand for it but we mark the statement volatile to prevent\n-\t optimizations from messing things up.  */\n-      gimple_set_has_volatile_ops (stmt, true);\n-      return;\n-    }\n-  else\n-    {\n-      /* Ok, this isn't even is_gimple_min_invariant.  Something's broke.  */\n-      gcc_unreachable ();\n+      bitmap_set_bit (*set, DECL_UID (var));\n+      TREE_ADDRESSABLE (var) = 1;\n     }\n+}\n \n-  /* If requested, add a USE operand for the base pointer.  */\n-  if (recurse_on_base)\n-    get_expr_operands (stmt, addr, opf_use);\n+/* Add the base address of REF to the set of addresses taken by STMT.\n+   REF may be a single variable whose address has been taken or any\n+   other valid GIMPLE memory reference (structure reference, array,\n+   etc).  If the base address of REF is a decl that has sub-variables,\n+   also add all of its sub-variables.  */\n+\n+static void\n+gimple_add_to_addresses_taken (gimple stmt, tree ref)\n+{\n+  gcc_assert (gimple_has_ops (stmt));\n+  add_to_addressable_set (ref, gimple_addresses_taken_ptr (stmt));\n }\n \n \n@@ -1571,28 +725,25 @@ get_addr_dereference_operands (gimple stmt, tree *addr, int flags,\n    \n    FLAGS is as in get_expr_operands.\n \n-   FULL_REF contains the full pointer dereference expression, if we\n-      have it, or NULL otherwise.\n-\n-   OFFSET and SIZE are the location of the access inside the\n-      dereferenced pointer, if known.\n-\n    RECURSE_ON_BASE should be set to true if we want to continue\n       calling get_expr_operands on the base pointer, and false if\n       something else will do it for us.  */\n \n static void\n-get_indirect_ref_operands (gimple stmt, tree expr, int flags, tree full_ref,\n-\t\t\t   HOST_WIDE_INT offset, HOST_WIDE_INT size,\n+get_indirect_ref_operands (gimple stmt, tree expr, int flags,\n \t\t\t   bool recurse_on_base)\n {\n   tree *pptr = &TREE_OPERAND (expr, 0);\n \n   if (TREE_THIS_VOLATILE (expr))\n     gimple_set_has_volatile_ops (stmt, true);\n \n-  get_addr_dereference_operands (stmt, pptr, flags, full_ref, offset, size,\n-\t\t\t\t recurse_on_base);\n+  /* Add the VOP.  */\n+  add_virtual_operand (stmt, flags);\n+\n+  /* If requested, add a USE operand for the base pointer.  */\n+  if (recurse_on_base)\n+    get_expr_operands (stmt, pptr, opf_use);\n }\n \n \n@@ -1601,192 +752,37 @@ get_indirect_ref_operands (gimple stmt, tree expr, int flags, tree full_ref,\n static void\n get_tmr_operands (gimple stmt, tree expr, int flags)\n {\n-  tree tag;\n-\n-  /* Mark the statement as having memory operands.  */\n-  gimple_set_references_memory (stmt, true);\n-\n   /* First record the real operands.  */\n   get_expr_operands (stmt, &TMR_BASE (expr), opf_use);\n   get_expr_operands (stmt, &TMR_INDEX (expr), opf_use);\n \n   if (TMR_SYMBOL (expr))\n     gimple_add_to_addresses_taken (stmt, TMR_SYMBOL (expr));\n \n-  tag = TMR_TAG (expr);\n-  if (!tag)\n-    {\n-      /* Something weird, so ensure that we will be careful.  */\n-      gimple_set_has_volatile_ops (stmt, true);\n-      return;\n-    }\n-  if (!MTAG_P (tag))\n-    {\n-      get_expr_operands (stmt, &tag, flags);\n-      return;\n-    }\n-\n-  add_virtual_operand (tag, stmt, flags, expr, 0, -1, false);\n-}\n-\n-\n-/* Add clobbering definitions for .GLOBAL_VAR or for each of the call\n-   clobbered variables in the function.  */\n-\n-static void\n-add_call_clobber_ops (gimple stmt, tree callee ATTRIBUTE_UNUSED)\n-{\n-  unsigned u;\n-  bitmap_iterator bi;\n-  bitmap not_read_b, not_written_b;\n-\n-  gcc_assert (!(gimple_call_flags (stmt) & (ECF_PURE | ECF_CONST)));\n-\n-  /* If we created .GLOBAL_VAR earlier, just use it.  */\n-  if (gimple_global_var (cfun))\n-    {\n-      tree var = gimple_global_var (cfun);\n-      add_virtual_operand (var, stmt, opf_def, NULL, 0, -1, true);\n-      return;\n-    }\n-\n-  /* Get info for local and module level statics.  There is a bit\n-     set for each static if the call being processed does not read\n-     or write that variable.  */\n-  not_read_b = callee ? ipa_reference_get_not_read_global (cgraph_node (callee)) : NULL; \n-  not_written_b = callee ? ipa_reference_get_not_written_global (cgraph_node (callee)) : NULL;\n-\n-  /* Add a VDEF operand for every call clobbered variable.  */\n-  EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, u, bi)\n-    {\n-      tree var = referenced_var_lookup (u);\n-      tree real_var = var;\n-      bool not_read;\n-      bool not_written;\n-\n-      not_read = not_read_b\n-\t         ? bitmap_bit_p (not_read_b, DECL_UID (real_var))\n-\t         : false;\n-\n-      not_written = not_written_b\n-\t            ? bitmap_bit_p (not_written_b, DECL_UID (real_var))\n-\t\t    : false;\n-      gcc_assert (!unmodifiable_var_p (var));\n-      \n-      clobber_stats.clobbered_vars++;\n-\n-      /* See if this variable is really clobbered by this function.  */\n-\n-      if (not_written)\n-\t{\n-\t  clobber_stats.static_write_clobbers_avoided++;\n-\t  if (!not_read)\n-\t    add_virtual_operand (var, stmt, opf_use, NULL, 0, -1, true);\n-\t  else\n-\t    clobber_stats.static_read_clobbers_avoided++;\n-\t}\n-      else\n-\tadd_virtual_operand (var, stmt, opf_def, NULL, 0, -1, true);\n-    }\n-}\n-\n-\n-/* Add VUSE operands for .GLOBAL_VAR or all call clobbered variables in the\n-   function.  */\n-\n-static void\n-add_call_read_ops (gimple stmt, tree callee ATTRIBUTE_UNUSED)\n-{\n-  unsigned u;\n-  bitmap_iterator bi;\n-  bitmap not_read_b;\n-\n-  /* Const functions do not reference memory.  */\n-  if (gimple_call_flags (stmt) & ECF_CONST)\n-    return;\n-\n-  not_read_b = callee ? ipa_reference_get_not_read_global (cgraph_node (callee)) : NULL;\n-\n-  /* For pure functions we compute non-escaped uses separately.  */\n-  if (gimple_call_flags (stmt) & ECF_PURE)\n-    EXECUTE_IF_SET_IN_BITMAP (gimple_call_used_vars (cfun), 0, u, bi)\n-      {\n-\ttree var = referenced_var_lookup (u);\n-\ttree real_var = var;\n-\tbool not_read;\n-\n-\tif (unmodifiable_var_p (var))\n-\t  continue;\n-\n-\tnot_read = not_read_b\n-\t    ? bitmap_bit_p (not_read_b, DECL_UID (real_var))\n-\t    : false;\n-\n-\tclobber_stats.readonly_clobbers++;\n-\n-\t/* See if this variable is really used by this function.  */\n-\tif (!not_read)\n-\t  add_virtual_operand (var, stmt, opf_use, NULL, 0, -1, true);\n-\telse\n-\t  clobber_stats.static_readonly_clobbers_avoided++;\n-      }\n-\n-  /* Add a VUSE for .GLOBAL_VAR if it has been created.  See\n-     add_referenced_var for the heuristic used to decide whether to\n-     create .GLOBAL_VAR.  */\n-  if (gimple_global_var (cfun))\n-    {\n-      tree var = gimple_global_var (cfun);\n-      add_virtual_operand (var, stmt, opf_use, NULL, 0, -1, true);\n-      return;\n-    }\n-\n-  /* Add a VUSE for each call-clobbered variable.  */\n-  EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, u, bi)\n-    {\n-      tree var = referenced_var (u);\n-      tree real_var = var;\n-      bool not_read;\n-      \n-      clobber_stats.readonly_clobbers++;\n-\n-      not_read = not_read_b ? bitmap_bit_p (not_read_b, DECL_UID (real_var))\n-\t                    : false;\n-      \n-      if (not_read)\n-\t{\n-\t  clobber_stats.static_readonly_clobbers_avoided++;\n-\t  continue;\n-\t}\n-            \n-      add_virtual_operand (var, stmt, opf_use, NULL, 0, -1, true);\n-    }\n+  add_virtual_operand (stmt, flags);\n }\n \n \n /* If STMT is a call that may clobber globals and other symbols that\n    escape, add them to the VDEF/VUSE lists for it.  */\n \n static void\n-maybe_add_call_clobbered_vops (gimple stmt)\n+maybe_add_call_vops (gimple stmt)\n {\n   int call_flags = gimple_call_flags (stmt);\n \n-  /* Mark the statement as having memory operands.  */\n-  gimple_set_references_memory (stmt, true);\n-\n   /* If aliases have been computed already, add VDEF or VUSE\n      operands for all the symbols that have been found to be\n      call-clobbered.  */\n-  if (gimple_aliases_computed_p (cfun) && !(call_flags & ECF_NOVOPS))\n+  if (!(call_flags & ECF_NOVOPS))\n     {\n       /* A 'pure' or a 'const' function never call-clobbers anything. \n \t A 'noreturn' function might, but since we don't return anyway \n \t there is no point in recording that.  */ \n       if (!(call_flags & (ECF_PURE | ECF_CONST | ECF_NORETURN)))\n-\tadd_call_clobber_ops (stmt, gimple_call_fndecl (stmt));\n+\tadd_virtual_operand (stmt, opf_def);\n       else if (!(call_flags & ECF_CONST))\n-\tadd_call_read_ops (stmt, gimple_call_fndecl (stmt));\n+\tadd_virtual_operand (stmt, opf_use);\n     }\n }\n \n@@ -1854,23 +850,7 @@ get_asm_expr_operands (gimple stmt)\n       tree link = gimple_asm_clobber_op (stmt, i);\n       if (strcmp (TREE_STRING_POINTER (TREE_VALUE (link)), \"memory\") == 0)\n \t{\n-\t  unsigned i;\n-\t  bitmap_iterator bi;\n-\n-\t  /* Mark the statement as having memory operands.  */\n-\t  gimple_set_references_memory (stmt, true);\n-\n-\t  EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, i, bi)\n-\t    {\n-\t      tree var = referenced_var (i);\n-\t      add_stmt_operand (&var, stmt, opf_def | opf_implicit);\n-\t    }\n-\n-\t  EXECUTE_IF_SET_IN_BITMAP (gimple_addressable_vars (cfun), 0, i, bi)\n-\t    {\n-\t      tree var = referenced_var (i);\n-\t      add_stmt_operand (&var, stmt, opf_def | opf_implicit);\n-\t    }\n+\t  add_virtual_operand (stmt, opf_def);\n \t  break;\n \t}\n     }\n@@ -1918,8 +898,6 @@ get_expr_operands (gimple stmt, tree *expr_p, int flags)\n       return;\n \n     case SSA_NAME:\n-    case SYMBOL_MEMORY_TAG:\n-    case NAME_MEMORY_TAG:\n      add_stmt_operand (expr_p, stmt, flags);\n      return;\n \n@@ -1935,7 +913,7 @@ get_expr_operands (gimple stmt, tree *expr_p, int flags)\n \n     case ALIGN_INDIRECT_REF:\n     case INDIRECT_REF:\n-      get_indirect_ref_operands (stmt, expr, flags, expr, 0, -1, true);\n+      get_indirect_ref_operands (stmt, expr, flags, true);\n       return;\n \n     case TARGET_MEM_REF:\n@@ -1957,8 +935,7 @@ get_expr_operands (gimple stmt, tree *expr_p, int flags)\n \tref = get_ref_base_and_extent (expr, &offset, &size, &maxsize);\n \tif (TREE_CODE (ref) == INDIRECT_REF)\n \t  {\n-\t    get_indirect_ref_operands (stmt, ref, flags, expr, offset,\n-\t\t                       maxsize, false);\n+\t    get_indirect_ref_operands (stmt, ref, flags, false);\n \t    flags |= opf_no_vops;\n \t  }\n \n@@ -2098,7 +1075,7 @@ parse_ssa_operands (gimple stmt)\n \n       /* Add call-clobbered operands, if needed.  */\n       if (code == GIMPLE_CALL)\n-\tmaybe_add_call_clobbered_vops (stmt);\n+\tmaybe_add_call_vops (stmt);\n     }\n }\n \n@@ -2111,22 +1088,14 @@ build_ssa_operands (gimple stmt)\n   /* Initially assume that the statement has no volatile operands and\n      makes no memory references.  */\n   gimple_set_has_volatile_ops (stmt, false);\n-  gimple_set_references_memory (stmt, false);\n \n   /* Just clear the bitmap so we don't end up reallocating it over and over.  */\n   if (gimple_addresses_taken (stmt))\n     bitmap_clear (gimple_addresses_taken (stmt));\n \n   start_ssa_stmt_operands ();\n   parse_ssa_operands (stmt);\n-  operand_build_sort_virtual (build_vuses);\n-  operand_build_sort_virtual (build_vdefs);\n   finalize_ssa_stmt_operands (stmt);\n-\n-  /* For added safety, assume that statements with volatile operands\n-     also reference memory.  */\n-  if (gimple_has_volatile_ops (stmt))\n-    gimple_set_references_memory (stmt, true);\n }\n \n \n@@ -2138,9 +1107,6 @@ free_stmt_operands (gimple stmt)\n {\n   def_optype_p defs = gimple_def_ops (stmt), last_def;\n   use_optype_p uses = gimple_use_ops (stmt), last_use;\n-  voptype_p vuses = gimple_vuse_ops (stmt);\n-  voptype_p vdefs = gimple_vdef_ops (stmt), vdef, next_vdef;\n-  unsigned i;\n \n   if (defs)\n     {\n@@ -2161,32 +1127,13 @@ free_stmt_operands (gimple stmt)\n       gimple_set_use_ops (stmt, NULL);\n     }\n \n-  if (vuses)\n-    {\n-      for (i = 0; i < VUSE_NUM (vuses); i++)\n-\tdelink_imm_use (VUSE_OP_PTR (vuses, i));\n-      add_vop_to_freelist (vuses);\n-      gimple_set_vuse_ops (stmt, NULL);\n-    }\n-\n-  if (vdefs)\n-    {\n-      for (vdef = vdefs; vdef; vdef = next_vdef)\n-\t{\n-\t  next_vdef = vdef->next;\n-\t  delink_imm_use (VDEF_OP_PTR (vdef, 0));\n-\t  add_vop_to_freelist (vdef);\n-\t}\n-      gimple_set_vdef_ops (stmt, NULL);\n-    }\n-\n   if (gimple_has_ops (stmt))\n     gimple_set_addresses_taken (stmt, NULL);\n \n   if (gimple_has_mem_ops (stmt))\n     {\n-      gimple_set_stored_syms (stmt, NULL, &operands_bitmap_obstack);\n-      gimple_set_loaded_syms (stmt, NULL, &operands_bitmap_obstack);\n+      gimple_set_vuse (stmt, NULL_TREE);\n+      gimple_set_vdef (stmt, NULL_TREE);\n     }\n }\n \n@@ -2211,113 +1158,6 @@ update_stmt_operands (gimple stmt)\n }\n \n \n-/* Copies virtual operands from SRC to DST.  */\n-\n-void\n-copy_virtual_operands (gimple dest, gimple src)\n-{\n-  unsigned int i, n;\n-  voptype_p src_vuses, dest_vuses;\n-  voptype_p src_vdefs, dest_vdefs;\n-  struct voptype_d vuse;\n-  struct voptype_d vdef;\n-\n-  if (!gimple_has_mem_ops (src))\n-    return;\n-\n-  gimple_set_vdef_ops (dest, NULL);\n-  gimple_set_vuse_ops (dest, NULL);\n-\n-  gimple_set_stored_syms (dest, gimple_stored_syms (src),\n-\t\t\t  &operands_bitmap_obstack);\n-  gimple_set_loaded_syms (dest, gimple_loaded_syms (src),\n-\t\t\t  &operands_bitmap_obstack);\n-\n-  /* Copy all the VUSE operators and corresponding operands.  */\n-  dest_vuses = &vuse;\n-  for (src_vuses = gimple_vuse_ops (src);\n-       src_vuses;\n-       src_vuses = src_vuses->next)\n-    {\n-      n = VUSE_NUM (src_vuses);\n-      dest_vuses = add_vuse_op (dest, NULL_TREE, n, dest_vuses);\n-      for (i = 0; i < n; i++)\n-\tSET_USE (VUSE_OP_PTR (dest_vuses, i), VUSE_OP (src_vuses, i));\n-\n-      if (gimple_vuse_ops (dest) == NULL)\n-\tgimple_set_vuse_ops (dest, vuse.next);\n-    }\n-\n-  /* Copy all the VDEF operators and corresponding operands.  */\n-  dest_vdefs = &vdef;\n-  for (src_vdefs = gimple_vdef_ops (src);\n-       src_vdefs;\n-       src_vdefs = src_vdefs->next)\n-    {\n-      n = VUSE_NUM (src_vdefs);\n-      dest_vdefs = add_vdef_op (dest, NULL_TREE, n, dest_vdefs);\n-      VDEF_RESULT (dest_vdefs) = VDEF_RESULT (src_vdefs);\n-      for (i = 0; i < n; i++)\n-\tSET_USE (VUSE_OP_PTR (dest_vdefs, i), VUSE_OP (src_vdefs, i));\n-\n-      if (gimple_vdef_ops (dest) == NULL)\n-\tgimple_set_vdef_ops (dest, vdef.next);\n-    }\n-}\n-\n-\n-/* Specifically for use in DOM's expression analysis.  Given a store, we\n-   create an artificial stmt which looks like a load from the store, this can\n-   be used to eliminate redundant loads.  OLD_OPS are the operands from the \n-   store stmt, and NEW_STMT is the new load which represents a load of the\n-   values stored.  If DELINK_IMM_USES_P is specified, the immediate\n-   uses of this stmt will be de-linked.  */\n-\n-void\n-create_ssa_artificial_load_stmt (gimple new_stmt, gimple old_stmt,\n-\t\t\t\t bool delink_imm_uses_p)\n-{\n-  tree op;\n-  ssa_op_iter iter;\n-  use_operand_p use_p;\n-  unsigned i;\n-\n-  gimple_set_modified (new_stmt, false);\n-\n-  /* Process NEW_STMT looking for operands.  */\n-  start_ssa_stmt_operands ();\n-  parse_ssa_operands (new_stmt);\n-\n-  for (i = 0; VEC_iterate (tree, build_vuses, i, op); i++)\n-    if (TREE_CODE (op) != SSA_NAME)\n-      var_ann (op)->in_vuse_list = false;\n-   \n-  for (i = 0; VEC_iterate (tree, build_vdefs, i, op); i++)\n-    if (TREE_CODE (op) != SSA_NAME)\n-      var_ann (op)->in_vdef_list = false;\n-\n-  /* Remove any virtual operands that were found.  */\n-  VEC_truncate (tree, build_vdefs, 0);\n-  VEC_truncate (tree, build_vuses, 0);\n-\n-  /* Clear the loads and stores bitmaps.  */\n-  bitmap_clear (build_loads);\n-  bitmap_clear (build_stores);\n-\n-  /* For each VDEF on the original statement, we want to create a\n-     VUSE of the VDEF result operand on the new statement.  */\n-  FOR_EACH_SSA_TREE_OPERAND (op, old_stmt, iter, SSA_OP_VDEF)\n-    append_vuse (op);\n-\n-  finalize_ssa_stmt_operands (new_stmt);\n-\n-  /* All uses in this fake stmt must not be in the immediate use lists.  */\n-  if (delink_imm_uses_p)\n-    FOR_EACH_SSA_USE_OPERAND (use_p, new_stmt, iter, SSA_OP_ALL_USES)\n-      delink_imm_use (use_p);\n-}\n-\n-\n /* Swap operands EXP0 and EXP1 in statement STMT.  No attempt is done\n    to test the validity of the swap operation.  */\n \n@@ -2366,43 +1206,6 @@ swap_tree_operands (gimple stmt, tree *exp0, tree *exp1)\n   *exp1 = op0;\n }\n \n-/* Add the base address of REF to SET.  */\n-\n-void\n-add_to_addressable_set (tree ref, bitmap *set)\n-{\n-  tree var;\n-\n-  /* Note that it is *NOT OKAY* to use the target of a COMPONENT_REF\n-     as the only thing we take the address of.  If VAR is a structure,\n-     taking the address of a field means that the whole structure may\n-     be referenced using pointer arithmetic.  See PR 21407 and the\n-     ensuing mailing list discussion.  */\n-  var = get_base_address (ref);\n-  if (var && SSA_VAR_P (var))\n-    {\n-      if (*set == NULL)\n-\t*set = BITMAP_ALLOC (&operands_bitmap_obstack);\n-\n-      bitmap_set_bit (*set, DECL_UID (var));\n-      TREE_ADDRESSABLE (var) = 1;\n-    }\n-}\n-\n-\n-/* Add the base address of REF to the set of addresses taken by STMT.\n-   REF may be a single variable whose address has been taken or any\n-   other valid GIMPLE memory reference (structure reference, array,\n-   etc).  If the base address of REF is a decl that has sub-variables,\n-   also add all of its sub-variables.  */\n-\n-void\n-gimple_add_to_addresses_taken (gimple stmt, tree ref)\n-{\n-  gcc_assert (gimple_has_ops (stmt));\n-  add_to_addressable_set (ref, gimple_addresses_taken_ptr (stmt));\n-}\n-\n \n /* Scan the immediate_use list for VAR making sure its linked properly.\n    Return TRUE if there is a problem and emit an error message to F.  */\n@@ -2547,192 +1350,94 @@ debug_immediate_uses_for (tree var)\n }\n \n \n-/* Create a new change buffer for the statement pointed by STMT_P and\n-   push the buffer into SCB_STACK.  Each change buffer\n-   records state information needed to determine what changed in the\n-   statement.  Mainly, this keeps track of symbols that may need to be\n-   put into SSA form, SSA name replacements and other information\n-   needed to keep the SSA form up to date.  */\n+/* Push *STMT_P on the SCB_STACK.  This function is deprecated, do not\n+   introduce new uses of it.  */\n \n void\n push_stmt_changes (gimple *stmt_p)\n {\n-  gimple stmt;\n-  scb_t buf;\n-\n-  stmt = *stmt_p;\n+  gimple stmt = *stmt_p;\n \n   /* It makes no sense to keep track of PHI nodes.  */\n   if (gimple_code (stmt) == GIMPLE_PHI)\n     return;\n \n-  buf = XNEW (struct scb_d);\n-  memset (buf, 0, sizeof *buf);\n-\n-  buf->stmt_p = stmt_p;\n-\n-  if (gimple_references_memory_p (stmt))\n-    {\n-      tree op;\n-      ssa_op_iter i;\n-\n-      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VUSE)\n-\t{\n-\t  tree sym = TREE_CODE (op) == SSA_NAME ? SSA_NAME_VAR (op) : op;\n-\t  if (buf->loads == NULL)\n-\t    buf->loads = BITMAP_ALLOC (NULL);\n-\t  bitmap_set_bit (buf->loads, DECL_UID (sym));\n-\t}\n-\n-      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VDEF)\n-\t{\n-\t  tree sym = TREE_CODE (op) == SSA_NAME ? SSA_NAME_VAR (op) : op;\n-\t  if (buf->stores == NULL)\n-\t    buf->stores = BITMAP_ALLOC (NULL);\n-\t  bitmap_set_bit (buf->stores, DECL_UID (sym));\n-\t}\n-    }\n-\n-  VEC_safe_push (scb_t, heap, scb_stack, buf);\n-}\n-\n-\n-/* Given two sets S1 and S2, mark the symbols that differ in S1 and S2\n-   for renaming.  The set to mark for renaming is (S1 & ~S2) | (S2 & ~S1).  */\n-\n-static void\n-mark_difference_for_renaming (bitmap s1, bitmap s2)\n-{\n-  if (s1 == NULL && s2 == NULL)\n-    return;\n-\n-  if (s1 && s2 == NULL)\n-    mark_set_for_renaming (s1);\n-  else if (s1 == NULL && s2)\n-    mark_set_for_renaming (s2);\n-  else if (!bitmap_equal_p (s1, s2))\n-    {\n-      bitmap t1 = BITMAP_ALLOC (NULL);\n-      bitmap_xor (t1, s1, s2);\n-      mark_set_for_renaming (t1);\n-      BITMAP_FREE (t1);\n-    }\n+  VEC_safe_push (gimple_p, heap, scb_stack, stmt_p);\n }\n \n-\n-/* Pop the top SCB from SCB_STACK and act on the differences between\n+/* Pop the top stmt from SCB_STACK and act on the differences between\n    what was recorded by push_stmt_changes and the current state of\n-   the statement.  */\n+   the statement.  This function is deprecated, do not introduce\n+   new uses of it.  */\n \n void\n pop_stmt_changes (gimple *stmt_p)\n {\n-  tree op;\n-  gimple stmt;\n+  gimple *stmt2_p, stmt = *stmt_p;\n   ssa_op_iter iter;\n-  bitmap loads, stores;\n-  scb_t buf;\n-\n-  stmt = *stmt_p;\n+  tree op;\n \n   /* It makes no sense to keep track of PHI nodes.  */\n   if (gimple_code (stmt) == GIMPLE_PHI)\n     return;\n \n-  buf = VEC_pop (scb_t, scb_stack);\n-  gcc_assert (stmt_p == buf->stmt_p);\n+  stmt2_p = VEC_pop (gimple_p, scb_stack);\n+  gcc_assert (stmt_p == stmt2_p);\n \n   /* Force an operand re-scan on the statement and mark any newly\n-     exposed variables.  */\n+     exposed variables.  This also will mark the virtual operand\n+     for renaming if necessary.  */\n   update_stmt (stmt);\n \n-  /* Determine whether any memory symbols need to be renamed.  If the\n-     sets of loads and stores are different after the statement is\n-     modified, then the affected symbols need to be renamed.\n-     \n-     Note that it may be possible for the statement to not reference\n-     memory anymore, but we still need to act on the differences in\n-     the sets of symbols.  */\n-  loads = stores = NULL;\n-  if (gimple_references_memory_p (stmt))\n-    {\n-      tree op;\n-      ssa_op_iter i;\n-\n-      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VUSE)\n-\t{\n-\t  tree sym = TREE_CODE (op) == SSA_NAME ? SSA_NAME_VAR (op) : op;\n-\t  if (loads == NULL)\n-\t    loads = BITMAP_ALLOC (NULL);\n-\t  bitmap_set_bit (loads, DECL_UID (sym));\n-\t}\n-\n-      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VDEF)\n-\t{\n-\t  tree sym = TREE_CODE (op) == SSA_NAME ? SSA_NAME_VAR (op) : op;\n-\t  if (stores == NULL)\n-\t    stores = BITMAP_ALLOC (NULL);\n-\t  bitmap_set_bit (stores, DECL_UID (sym));\n-\t}\n-    }\n-\n-  /* If LOADS is different from BUF->LOADS, the affected\n-     symbols need to be marked for renaming.  */\n-  mark_difference_for_renaming (loads, buf->loads);\n-\n-  /* Similarly for STORES and BUF->STORES.  */\n-  mark_difference_for_renaming (stores, buf->stores);\n-\n-  /* Mark all the naked GIMPLE register operands for renaming.  */\n+  /* Mark all the naked GIMPLE register operands for renaming.\n+     ???  Especially this is considered bad behavior of the caller,\n+     it should have updated SSA form manually.  Even more so as\n+     we do not have a way to verify that no SSA names for op are\n+     already in use.  */\n   FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_DEF|SSA_OP_USE)\n     if (DECL_P (op))\n       mark_sym_for_renaming (op);\n-\n-  /* FIXME, need to add more finalizers here.  Cleanup EH info,\n-     recompute invariants for address expressions, add\n-     SSA replacement mappings, etc.  For instance, given\n-     testsuite/gcc.c-torture/compile/pr16808.c, we fold a statement of\n-     the form:\n-\n-\t  # SMT.4_20 = VDEF <SMT.4_16>\n-\t  D.1576_11 = 1.0e+0;\n-\n-     So, the VDEF will disappear, but instead of marking SMT.4 for\n-     renaming it would be far more efficient to establish a\n-     replacement mapping that would replace every reference of\n-     SMT.4_20 with SMT.4_16.  */\n-\n-  /* Free memory used by the buffer.  */\n-  BITMAP_FREE (buf->loads);\n-  BITMAP_FREE (buf->stores);\n-  BITMAP_FREE (loads);\n-  BITMAP_FREE (stores);\n-  buf->stmt_p = NULL;\n-  free (buf);\n }\n \n-\n-/* Discard the topmost change buffer from SCB_STACK.  This is useful\n+/* Discard the topmost stmt from SCB_STACK.  This is useful\n    when the caller realized that it did not actually modified the\n-   statement.  It avoids the expensive operand re-scan.  */\n+   statement.  It avoids the expensive operand re-scan.\n+   This function is deprecated, do not introduce new uses of it.  */\n \n void\n discard_stmt_changes (gimple *stmt_p)\n {\n-  scb_t buf;\n-  gimple stmt;\n+  gimple *stmt2_p, stmt = *stmt_p;\n   \n   /* It makes no sense to keep track of PHI nodes.  */\n-  stmt = *stmt_p;\n   if (gimple_code (stmt) == GIMPLE_PHI)\n     return;\n \n-  buf = VEC_pop (scb_t, scb_stack);\n-  gcc_assert (stmt_p == buf->stmt_p);\n+  stmt2_p = VEC_pop (gimple_p, scb_stack);\n+  gcc_assert (stmt_p == stmt2_p);\n+}\n+\n+/* Unlink STMTs virtual definition from the IL by propagating its use.  */\n+\n+void\n+unlink_stmt_vdef (gimple stmt)\n+{\n+  use_operand_p use_p;\n+  imm_use_iterator iter;\n+  gimple use_stmt;\n+  tree vdef = gimple_vdef (stmt);\n+\n+  if (!vdef\n+      || TREE_CODE (vdef) != SSA_NAME)\n+    return;\n+\n+  FOR_EACH_IMM_USE_STMT (use_stmt, iter, gimple_vdef (stmt))\n+    {\n+      FOR_EACH_IMM_USE_ON_STMT (use_p, iter)\n+\tSET_USE (use_p, gimple_vuse (stmt));\n+    }\n \n-  /* Free memory used by the buffer.  */\n-  BITMAP_FREE (buf->loads);\n-  BITMAP_FREE (buf->stores);\n-  buf->stmt_p = NULL;\n-  free (buf);\n+  if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (gimple_vdef (stmt)))\n+    SSA_NAME_OCCURS_IN_ABNORMAL_PHI (gimple_vuse (stmt)) = 1;\n }\n+"}, {"sha": "a8d364d4701298368111fb6997849720b5c11c71", "filename": "gcc/tree-ssa-operands.h", "status": "modified", "additions": 9, "deletions": 121, "changes": 130, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-operands.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-operands.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-operands.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -30,8 +30,8 @@ typedef tree *def_operand_p;\n typedef ssa_use_operand_t *use_operand_p;\n \n /* NULL operand types.  */\n-#define NULL_USE_OPERAND_P \t\tNULL\n-#define NULL_DEF_OPERAND_P \t\tNULL\n+#define NULL_USE_OPERAND_P \t\t((use_operand_p)NULL)\n+#define NULL_DEF_OPERAND_P \t\t((def_operand_p)NULL)\n \n /* This represents the DEF operands of a stmt.  */\n struct def_optype_d\n@@ -49,63 +49,6 @@ struct use_optype_d\n };\n typedef struct use_optype_d *use_optype_p;\n \n-typedef struct vuse_element_d\n-{\n-  tree use_var;\n-  struct ssa_use_operand_d use_ptr;\n-} vuse_element_t;\n-\n-typedef struct vuse_vec_d\n-{\n-  unsigned int num_vuse;\n-  vuse_element_t uses[1];\n-} vuse_vec_t;\n-typedef struct vuse_vec_d *vuse_vec_p;\n-\n-#define VUSE_VECT_NUM_ELEM(V)\t\t(V).num_vuse\n-#define VUSE_VECT_ELEMENT_NC(V,X)\t(V).uses[(X)]\n-#define VUSE_ELEMENT_PTR_NC(V,X)\t(&(VUSE_VECT_ELEMENT_NC ((V),(X)).use_ptr))\n-#define VUSE_ELEMENT_VAR_NC(V,X)\t(VUSE_VECT_ELEMENT_NC ((V),(X)).use_var)\n-\n-#ifdef ENABLE_CHECKING\n-#define VUSE_VECT_ELEMENT(V,X)\t\t\t\t\t\t\\\n-    (gcc_assert (((unsigned int) (X)) < VUSE_VECT_NUM_ELEM (V)),\t\\\n-     VUSE_VECT_ELEMENT_NC (V,X))\n-\n-#define VUSE_ELEMENT_PTR(V,X)\t\t\t\t\t\t\\\n-    (gcc_assert (((unsigned int) (X)) < VUSE_VECT_NUM_ELEM (V)),\t\\\n-     VUSE_ELEMENT_PTR_NC (V, X))\n-\n-#define SET_VUSE_VECT_ELEMENT(V,X,N)\t\t\t\t\t\\\n-    (gcc_assert (((unsigned int) (X)) < VUSE_VECT_NUM_ELEM (V)),\t\\\n-     VUSE_VECT_ELEMENT_NC (V,X) = (N))\n-\n-#define SET_VUSE_ELEMENT_VAR(V,X,N)\t\t\t\t\t\\\n-    (gcc_assert (((unsigned int) (X)) < VUSE_VECT_NUM_ELEM (V)),\t\\\n-     VUSE_VECT_ELEMENT_NC ((V),(X)).use_var = (N))\n-\n-#define SET_VUSE_ELEMENT_PTR(V,X,N)\t\t\t\t\t\\\n-    (gcc_assert (((unsigned int) (X)) < VUSE_VECT_NUM_ELEM (V)),\t\\\n-     VUSE_ELEMENT_PTR_NC (V, X) = (N))\n-#else\n-#define VUSE_VECT_ELEMENT(V,X) VUSE_VECT_ELEMENT_NC(V,X)\n-#define VUSE_ELEMENT_PTR(V,X) VUSE_ELEMENT_PTR_NC(V,X)\n-#define SET_VUSE_VECT_ELEMENT(V,X,N) VUSE_VECT_ELEMENT_NC(V,X) = (N)\n-#define SET_VUSE_ELEMENT_PTR(V,X,N) VUSE_ELEMENT_PTR_NC(V,X) = (N)\n-#define SET_VUSE_ELEMENT_VAR(V,X,N) VUSE_VECT_ELEMENT_NC ((V),(X)).use_var = (N)\n-#endif\n-\n-#define VUSE_ELEMENT_VAR(V,X)\t(VUSE_VECT_ELEMENT ((V),(X)).use_var)\n-\n-/* This represents the virtual ops of a stmt.  */\n-struct voptype_d\n-{\n-  struct voptype_d *next;\n-  tree def_var;\n-  vuse_vec_t usev;\n-};\n-typedef struct voptype_d *voptype_p;\n-\n /* This structure represents a variable sized buffer which is allocated by the\n    operand memory manager.  Operands are suballocated out of this block.  The\n    MEM array varies in size.  */\n@@ -116,9 +59,6 @@ struct ssa_operand_memory_d GTY((chain_next(\"%h.next\")))\n   char mem[1];\n };\n \n-/* Number of different size free buckets for virtual operands.  */\n-#define NUM_VOP_FREE_BUCKETS\t\t29\n-\n /* Per-function operand caches.  */\n struct ssa_operands GTY(()) {\n    struct ssa_operand_memory_d *operand_memory;\n@@ -130,28 +70,8 @@ struct ssa_operands GTY(()) {\n \n    struct def_optype_d * GTY ((skip (\"\"))) free_defs;\n    struct use_optype_d * GTY ((skip (\"\"))) free_uses;\n-   struct voptype_d * GTY ((skip (\"\"))) vop_free_buckets[NUM_VOP_FREE_BUCKETS];\n-   VEC(tree,heap) * GTY ((skip (\"\"))) mpt_table;\n-};\n-\n-/* This represents the operand cache for a stmt.  */\n-struct stmt_operands_d\n-{\n-  /* Statement operands.  */\n-  struct def_optype_d * def_ops;\n-  struct use_optype_d * use_ops;\n-                                                                              \n-  /* Virtual operands (VDEF, VUSE).  */\n-  struct voptype_d * vdef_ops;\n-  struct voptype_d * vuse_ops;\n-\n-  /* Sets of memory symbols loaded and stored.  */\n-  bitmap stores;\n-  bitmap loads;\n };\n                                                                               \n-typedef struct stmt_operands_d *stmt_operands_p;\n-                                                                              \n #define USE_FROM_PTR(PTR)\tget_use_from_ptr (PTR)\n #define DEF_FROM_PTR(PTR)\tget_def_from_ptr (PTR)\n #define SET_USE(USE, V)\t\tset_ssa_use_from_ptr (USE, V)\n@@ -165,20 +85,6 @@ typedef struct stmt_operands_d *stmt_operands_p;\n #define DEF_OP_PTR(OP)\t\t((OP)->def_ptr)\n #define DEF_OP(OP)\t\t(DEF_FROM_PTR (DEF_OP_PTR (OP)))\n \n-#define VUSE_OP_PTR(OP,X)\tVUSE_ELEMENT_PTR ((OP)->usev, (X)) \n-#define VUSE_OP(OP,X)\t\tVUSE_ELEMENT_VAR ((OP)->usev, (X))\n-#define SET_VUSE_OP(OP,X,N)\tSET_VUSE_ELEMENT_VAR ((OP)->usev, (X), (N))\n-#define VUSE_NUM(OP)\t\tVUSE_VECT_NUM_ELEM ((OP)->usev)\n-#define VUSE_VECT(OP)\t\t&((OP)->usev)\n-\n-#define VDEF_RESULT_PTR(OP)\t(&((OP)->def_var))\n-#define VDEF_RESULT(OP)\t\t((OP)->def_var)\n-#define VDEF_OP_PTR(OP,X)\tVUSE_OP_PTR (OP, X)\n-#define VDEF_OP(OP,X)\t\tVUSE_OP (OP, X)\n-#define SET_VDEF_OP(OP,X,N)\tSET_VUSE_OP (OP, X, N)\n-#define VDEF_NUM(OP)\t\tVUSE_VECT_NUM_ELEM ((OP)->usev)\n-#define VDEF_VECT(OP)\t\t&((OP)->usev)\n-\n #define PHI_RESULT_PTR(PHI)\tgimple_phi_result_ptr (PHI)\n #define PHI_RESULT(PHI)\t\tDEF_FROM_PTR (PHI_RESULT_PTR (PHI))\n #define SET_PHI_RESULT(PHI, V)\tSET_DEF (PHI_RESULT_PTR (PHI), (V))\n@@ -200,10 +106,6 @@ extern void update_stmt_operands (gimple);\n extern void free_stmt_operands (gimple);\n extern bool verify_imm_links (FILE *f, tree var);\n \n-extern void copy_virtual_operands (gimple, gimple);\n-extern int operand_build_cmp (const void *, const void *);\n-extern void create_ssa_artificial_load_stmt (gimple, gimple, bool);\n-\n extern void dump_immediate_uses (FILE *file);\n extern void dump_immediate_uses_for (FILE *file, tree var);\n extern void debug_immediate_uses (void);\n@@ -216,14 +118,14 @@ extern bool ssa_operands_active (void);\n extern void push_stmt_changes (gimple *);\n extern void pop_stmt_changes (gimple *);\n extern void discard_stmt_changes (gimple *);\n-void add_to_addressable_set (tree, bitmap *);\n+\n+extern void unlink_stmt_vdef (gimple);\n \n enum ssa_op_iter_type {\n   ssa_op_iter_none = 0,\n   ssa_op_iter_tree,\n   ssa_op_iter_use,\n-  ssa_op_iter_def,\n-  ssa_op_iter_vdef\n+  ssa_op_iter_def\n };\n \n /* This structure is used in the operand iterator loops.  It contains the \n@@ -233,30 +135,24 @@ enum ssa_op_iter_type {\n \n typedef struct ssa_operand_iterator_d\n {\n+  bool done;\n+  enum ssa_op_iter_type iter_type;\n   def_optype_p defs;\n   use_optype_p uses;\n-  voptype_p vuses;\n-  voptype_p vdefs;\n-  voptype_p mayuses;\n-  enum ssa_op_iter_type iter_type;\n   int phi_i;\n   int num_phi;\n   gimple phi_stmt;\n-  bool done;\n-  unsigned int vuse_index;\n-  unsigned int mayuse_index;\n } ssa_op_iter;\n \n /* These flags are used to determine which operands are returned during \n    execution of the loop.  */\n #define SSA_OP_USE\t\t0x01\t/* Real USE operands.  */\n #define SSA_OP_DEF\t\t0x02\t/* Real DEF operands.  */\n #define SSA_OP_VUSE\t\t0x04\t/* VUSE operands.  */\n-#define SSA_OP_VMAYUSE\t\t0x08\t/* USE portion of VDEFS.  */\n-#define SSA_OP_VDEF\t\t0x10\t/* DEF portion of VDEFS.  */\n+#define SSA_OP_VDEF\t\t0x08\t/* VDEF operands.  */\n \n /* These are commonly grouped operand flags.  */\n-#define SSA_OP_VIRTUAL_USES\t(SSA_OP_VUSE | SSA_OP_VMAYUSE)\n+#define SSA_OP_VIRTUAL_USES\t(SSA_OP_VUSE)\n #define SSA_OP_VIRTUAL_DEFS\t(SSA_OP_VDEF)\n #define SSA_OP_ALL_VIRTUALS     (SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_DEFS)\n #define SSA_OP_ALL_USES\t\t(SSA_OP_VIRTUAL_USES | SSA_OP_USE)\n@@ -287,14 +183,6 @@ typedef struct ssa_operand_iterator_d\n        !op_iter_done (&(ITER));\t\t\t\t\t\\\n        DEFVAR = op_iter_next_def (&(ITER)))\n \n-/* This macro executes a loop over the VDEF operands of STMT.  The def\n-   and use vector for each VDEF is returned in DEFVAR and USEVECT. \n-   ITER is an ssa_op_iter structure used to control the loop.  */\n-#define FOR_EACH_SSA_VDEF_OPERAND(DEFVAR, USEVECT, STMT, ITER)\t\\\n-  for (op_iter_init_vdef (&(ITER), STMT, &(USEVECT), &(DEFVAR));\t\\\n-       !op_iter_done (&(ITER));\t\t\t\t\t\\\n-       op_iter_next_vdef (&(USEVECT), &(DEFVAR), &(ITER)))\n-\n /* This macro will execute a loop over all the arguments of a PHI which\n    match FLAGS.   A use_operand_p is always returned via USEVAR.  FLAGS\n    can be either SSA_OP_USE or SSA_OP_VIRTUAL_USES or SSA_OP_ALL_USES.  */"}, {"sha": "d95b3584b91ba80914968a15e9bb6f6a88d55988", "filename": "gcc/tree-ssa-phiprop.c", "status": "modified", "additions": 4, "deletions": 7, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-phiprop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-phiprop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-phiprop.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -105,12 +105,11 @@ static bool\n phivn_valid_p (struct phiprop_d *phivn, tree name, basic_block bb)\n {\n   gimple vop_stmt = phivn[SSA_NAME_VERSION (name)].vop_stmt;\n-  ssa_op_iter ui;\n   tree vuse;\n \n   /* The def stmts of all virtual uses need to be post-dominated\n      by bb.  */\n-  FOR_EACH_SSA_TREE_OPERAND (vuse, vop_stmt, ui, SSA_OP_VUSE)\n+  if ((vuse = gimple_vuse (vop_stmt)))\n     {\n       gimple use_stmt;\n       imm_use_iterator ui2;\n@@ -120,7 +119,7 @@ phivn_valid_p (struct phiprop_d *phivn, tree name, basic_block bb)\n \t{\n \t  /* If BB does not dominate a VDEF, the value is invalid.  */\n \t  if (((is_gimple_assign (use_stmt)\n-\t        && !ZERO_SSA_OPERANDS (use_stmt, SSA_OP_VDEF))\n+\t        && gimple_vdef (use_stmt))\n \t       || gimple_code (use_stmt) == GIMPLE_PHI)\n \t      && !dominated_by_p (CDI_DOMINATORS, gimple_bb (use_stmt), bb))\n \t    {\n@@ -229,8 +228,7 @@ propagate_with_phi (basic_block bb, gimple phi, struct phiprop_d *phivn,\n   ssa_op_iter i;\n   bool phi_inserted;\n \n-  if (MTAG_P (SSA_NAME_VAR (ptr))\n-      || !POINTER_TYPE_P (TREE_TYPE (ptr))\n+  if (!POINTER_TYPE_P (TREE_TYPE (ptr))\n       || !is_gimple_reg_type (TREE_TYPE (TREE_TYPE (ptr))))\n     return false;\n \n@@ -271,7 +269,6 @@ propagate_with_phi (basic_block bb, gimple phi, struct phiprop_d *phivn,\n   phi_inserted = false;\n   FOR_EACH_IMM_USE_STMT (use_stmt, ui, ptr)\n     {\n-      ssa_op_iter ui2;\n       tree vuse;\n \n       /* Check whether this is a load of *ptr.  */\n@@ -285,7 +282,7 @@ propagate_with_phi (basic_block bb, gimple phi, struct phiprop_d *phivn,\n \n       /* Check if we can move the loads.  The def stmts of all virtual uses\n \t need to be post-dominated by bb.  */\n-      FOR_EACH_SSA_TREE_OPERAND (vuse, use_stmt, ui2, SSA_OP_VUSE)\n+      if ((vuse = gimple_vuse (use_stmt)) != NULL_TREE)\n \t{\n \t  gimple def_stmt = SSA_NAME_DEF_STMT (vuse);\n \t  if (!SSA_NAME_IS_DEFAULT_DEF (vuse)"}, {"sha": "c1cbe0ca6502be3d22de33f02cb2095f94bf6697", "filename": "gcc/tree-ssa-pre.c", "status": "modified", "additions": 174, "deletions": 103, "changes": 277, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-pre.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-pre.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-pre.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -377,6 +377,9 @@ typedef struct bb_bitmap_sets\n      the current iteration.  */\n   bitmap_set_t new_sets;\n \n+  /* A cache for value_dies_in_block_x.  */\n+  bitmap expr_dies;\n+\n   /* True if we have visited this block during ANTIC calculation.  */\n   unsigned int visited:1;\n \n@@ -392,7 +395,8 @@ typedef struct bb_bitmap_sets\n #define ANTIC_IN(BB)\t((bb_value_sets_t) ((BB)->aux))->antic_in\n #define PA_IN(BB)\t((bb_value_sets_t) ((BB)->aux))->pa_in\n #define NEW_SETS(BB)\t((bb_value_sets_t) ((BB)->aux))->new_sets\n-#define BB_VISITED(BB) ((bb_value_sets_t) ((BB)->aux))->visited\n+#define EXPR_DIES(BB)\t((bb_value_sets_t) ((BB)->aux))->expr_dies\n+#define BB_VISITED(BB)\t((bb_value_sets_t) ((BB)->aux))->visited\n #define BB_DEFERRED(BB) ((bb_value_sets_t) ((BB)->aux))->deferred\n \n \n@@ -906,26 +910,42 @@ print_pre_expr (FILE *outfile, const pre_expr expr)\n \t     VEC_iterate (vn_reference_op_s, ref->operands, i, vro);\n \t     i++)\n \t  {\n+\t    bool closebrace = false;\n \t    if (vro->opcode != SSA_NAME\n \t\t&& TREE_CODE_CLASS (vro->opcode) != tcc_declaration)\n-\t      fprintf (outfile, \"%s \", tree_code_name [vro->opcode]);\n+\t      {\n+\t\tfprintf (outfile, \"%s\", tree_code_name [vro->opcode]);\n+\t\tif (vro->op0)\n+\t\t  {\n+\t\t    fprintf (outfile, \"<\");\n+\t\t    closebrace = true;\n+\t\t  }\n+\t      }\n \t    if (vro->op0)\n \t      {\n-\t\tif (vro->op1)\n-\t\t  fprintf (outfile, \"<\");\n \t\tprint_generic_expr (outfile, vro->op0, 0);\n \t\tif (vro->op1)\n \t\t  {\n \t\t    fprintf (outfile, \",\");\n \t\t    print_generic_expr (outfile, vro->op1, 0);\n \t\t  }\n-\t\tif (vro->op1)\n-\t\t  fprintf (outfile, \">\");\n+\t\tif (vro->op2)\n+\t\t  {\n+\t\t    fprintf (outfile, \",\");\n+\t\t    print_generic_expr (outfile, vro->op2, 0);\n+\t\t  }\n \t      }\n+\t    if (closebrace)\n+\t\tfprintf (outfile, \">\");\n \t    if (i != VEC_length (vn_reference_op_s, ref->operands) - 1)\n \t      fprintf (outfile, \",\");\n \t  }\n \tfprintf (outfile, \"}\");\n+\tif (ref->vuse)\n+\t  {\n+\t    fprintf (outfile, \"@\");\n+\t    print_generic_expr (outfile, ref->vuse, 0);\n+\t  }\n       }\n       break;\n     }\n@@ -1227,48 +1247,47 @@ fully_constant_expression (pre_expr e)\n   return e;\n }\n \n-/* Translate the vuses in the VUSES vector backwards through phi nodes\n-   in PHIBLOCK, so that they have the value they would have in\n-   BLOCK. */\n+/* Translate the VUSE backwards through phi nodes in PHIBLOCK, so that\n+   it has the value it would have in BLOCK.  */\n \n-static VEC(tree, gc) *\n-translate_vuses_through_block (VEC (tree, gc) *vuses,\n-\t\t\t       basic_block phiblock,\n-\t\t\t       basic_block block)\n+static tree\n+translate_vuse_through_block (VEC (vn_reference_op_s, heap) *operands,\n+\t\t\t      tree vuse,\n+\t\t\t      basic_block phiblock,\n+\t\t\t      basic_block block)\n {\n-  tree oldvuse;\n-  VEC(tree, gc) *result = NULL;\n-  int i;\n+  gimple phi = SSA_NAME_DEF_STMT (vuse);\n+  tree ref;\n \n-  for (i = 0; VEC_iterate (tree, vuses, i, oldvuse); i++)\n+  if (gimple_bb (phi) != phiblock)\n+    return vuse;\n+\n+  if (gimple_code (phi) == GIMPLE_PHI)\n     {\n-      gimple phi = SSA_NAME_DEF_STMT (oldvuse);\n-      if (gimple_code (phi) == GIMPLE_PHI\n-\t  && gimple_bb (phi) == phiblock)\n-\t{\n-\t  edge e = find_edge (block, gimple_bb (phi));\n-\t  if (e)\n-\t    {\n-\t      tree def = PHI_ARG_DEF (phi, e->dest_idx);\n-\t      if (def != oldvuse)\n-\t\t{\n-\t\t  if (!result)\n-\t\t    result = VEC_copy (tree, gc, vuses);\n-\t\t  VEC_replace (tree, result, i, def);\n-\t\t}\n-\t    }\n-\t}\n+      edge e = find_edge (block, phiblock);\n+      return PHI_ARG_DEF (phi, e->dest_idx);\n     }\n \n-  /* We avoid creating a new copy of the vuses unless something\n-     actually changed, so result can be NULL.  */\n-  if (result)\n+  if (!(ref = get_ref_from_reference_ops (operands)))\n+    return NULL_TREE;\n+\n+  /* Use the alias-oracle to find either the PHI node in this block,\n+     the first VUSE used in this block that is equivalent to vuse or\n+     the first VUSE which definition in this block kills the value.  */\n+  while (!stmt_may_clobber_ref_p (phi, ref))\n     {\n-      sort_vuses (result);\n-      return result;\n+      vuse = gimple_vuse (phi);\n+      phi = SSA_NAME_DEF_STMT (vuse);\n+      if (gimple_bb (phi) != phiblock)\n+\treturn vuse;\n+      if (gimple_code (phi) == GIMPLE_PHI)\n+\t{\n+\t  edge e = find_edge (block, phiblock);\n+\t  return PHI_ARG_DEF (phi, e->dest_idx);\n+\t}\n     }\n-  return vuses;\n \n+  return NULL_TREE;\n }\n \n /* Like find_leader, but checks for the value existing in SET1 *or*\n@@ -1540,8 +1559,8 @@ phi_translate_1 (pre_expr expr, bitmap_set_t set1, bitmap_set_t set2,\n       {\n \tvn_reference_t ref = PRE_EXPR_REFERENCE (expr);\n \tVEC (vn_reference_op_s, heap) *operands = ref->operands;\n-\tVEC (tree, gc) *vuses = ref->vuses;\n-\tVEC (tree, gc) *newvuses = vuses;\n+\ttree vuse = ref->vuse;\n+\ttree newvuse = vuse;\n \tVEC (vn_reference_op_s, heap) *newoperands = NULL;\n \tbool changed = false;\n \tunsigned int i;\n@@ -1632,15 +1651,24 @@ phi_translate_1 (pre_expr expr, bitmap_set_t set1, bitmap_set_t set2,\n \t    return NULL;\n \t  }\n \n-\tnewvuses = translate_vuses_through_block (vuses, phiblock, pred);\n-\tchanged |= newvuses != vuses;\n+\tif (vuse)\n+\t  {\n+\t    newvuse = translate_vuse_through_block (newoperands,\n+\t\t\t\t\t\t    vuse, phiblock, pred);\n+\t    if (newvuse == NULL_TREE)\n+\t      {\n+\t\tVEC_free (vn_reference_op_s, heap, newoperands);\n+\t\treturn NULL;\n+\t      }\n+\t  }\n+\tchanged |= newvuse != vuse;\n \n \tif (changed)\n \t  {\n \t    unsigned int new_val_id;\n \t    pre_expr constant;\n \n-\t    tree result = vn_reference_lookup_pieces (newvuses,\n+\t    tree result = vn_reference_lookup_pieces (newvuse,\n \t\t\t\t\t\t      newoperands,\n \t\t\t\t\t\t      &newref, true);\n \t    if (newref)\n@@ -1671,7 +1699,7 @@ phi_translate_1 (pre_expr expr, bitmap_set_t set1, bitmap_set_t set2,\n \t\tnew_val_id = get_next_value_id ();\n \t\tVEC_safe_grow_cleared (bitmap_set_t, heap, value_expressions,\n \t\t\t\t       get_max_value_id() + 1);\n-\t\tnewref = vn_reference_insert_pieces (newvuses,\n+\t\tnewref = vn_reference_insert_pieces (newvuse,\n \t\t\t\t\t\t     newoperands,\n \t\t\t\t\t\t     result, new_val_id);\n \t\tnewoperands = NULL;\n@@ -1846,24 +1874,73 @@ bitmap_find_leader (bitmap_set_t set, unsigned int val, gimple stmt)\n static bool\n value_dies_in_block_x (pre_expr expr, basic_block block)\n {\n-  int i;\n-  tree vuse;\n-  VEC (tree, gc) *vuses = PRE_EXPR_REFERENCE (expr)->vuses;\n+  tree vuse = PRE_EXPR_REFERENCE (expr)->vuse;\n+  vn_reference_t refx = PRE_EXPR_REFERENCE (expr);\n+  gimple def;\n+  tree ref = NULL_TREE;\n+  gimple_stmt_iterator gsi;\n+  unsigned id = get_expression_id (expr);\n+  bool res = false;\n \n-  /* Conservatively, a value dies if it's vuses are defined in this\n-     block, unless they come from phi nodes (which are merge operations,\n-     rather than stores.  */\n-  for (i = 0; VEC_iterate (tree, vuses, i, vuse); i++)\n+  if (!vuse)\n+    return false;\n+\n+  /* Lookup a previously calculated result.  */\n+  if (EXPR_DIES (block)\n+      && bitmap_bit_p (EXPR_DIES (block), id * 2))\n+    return bitmap_bit_p (EXPR_DIES (block), id * 2 + 1);\n+\n+  /* A memory expression {e, VUSE} dies in the block if there is a\n+     statement that may clobber e.  If, starting statement walk from the\n+     top of the basic block, a statement uses VUSE there can be no kill\n+     inbetween that use and the original statement that loaded {e, VUSE},\n+     so we can stop walking.  */\n+  for (gsi = gsi_start_bb (block); !gsi_end_p (gsi); gsi_next (&gsi))\n     {\n-      gimple def = SSA_NAME_DEF_STMT (vuse);\n+      tree def_vuse, def_vdef;\n+      def = gsi_stmt (gsi);\n+      def_vuse = gimple_vuse (def);\n+      def_vdef = gimple_vdef (def);\n \n-      if (gimple_bb (def) != block)\n+      /* Not a memory statement.  */\n+      if (!def_vuse)\n \tcontinue;\n-      if (gimple_code (def) == GIMPLE_PHI)\n-\tcontinue;\n-      return true;\n+\n+      /* Not a may-def.  */\n+      if (!def_vdef)\n+\t{\n+\t  /* A load with the same VUSE, we're done.  */\n+\t  if (def_vuse == vuse)\n+\t    break;\n+\n+\t  continue;\n+\t}\n+\n+      /* Init ref only if we really need it.  */\n+      if (ref == NULL_TREE)\n+\t{\n+\t  if (!(ref = get_ref_from_reference_ops (refx->operands)))\n+\t    {\n+\t      res = true;\n+\t      break;\n+\t    }\n+\t}\n+      /* If the statement may clobber expr, it dies.  */\n+      if (stmt_may_clobber_ref_p (def, ref))\n+\t{\n+\t  res = true;\n+\t  break;\n+\t}\n     }\n-  return false;\n+\n+  /* Remember the result.  */\n+  if (!EXPR_DIES (block))\n+    EXPR_DIES (block) = BITMAP_ALLOC (&grand_bitmap_obstack);\n+  bitmap_set_bit (EXPR_DIES (block), id * 2);\n+  if (res)\n+    bitmap_set_bit (EXPR_DIES (block), id * 2 + 1);\n+\n+  return res;\n }\n \n \n@@ -1925,7 +2002,7 @@ vro_valid_in_sets (bitmap_set_t set1, bitmap_set_t set2,\n    ONLY SET2 CAN BE NULL.\n    This means that we have a leader for each part of the expression\n    (if it consists of values), or the expression is an SSA_NAME.\n-   For loads/calls, we also see if the vuses are killed in this block.\n+   For loads/calls, we also see if the vuse is killed in this block.\n */\n \n static bool\n@@ -1970,6 +2047,15 @@ valid_in_sets (bitmap_set_t set1, bitmap_set_t set2, pre_expr expr,\n \t    if (!vro_valid_in_sets (set1, set2, vro))\n \t      return false;\n \t  }\n+\tif (ref->vuse)\n+\t  {\n+\t    gimple def_stmt = SSA_NAME_DEF_STMT (ref->vuse);\n+\t    if (!gimple_nop_p (def_stmt)\n+\t\t&& gimple_bb (def_stmt) != block\n+\t\t&& !dominated_by_p (CDI_DOMINATORS,\n+\t\t\t\t    block, gimple_bb (def_stmt)))\n+\t      return false;\n+\t  }\n \treturn !value_dies_in_block_x (expr, block);\n       }\n     default:\n@@ -3664,7 +3750,7 @@ compute_avail (void)\n \t\t  continue;\n \n \t\tcopy_reference_ops_from_call (stmt, &ops);\n-\t\tvn_reference_lookup_pieces (shared_vuses_from_stmt (stmt),\n+\t\tvn_reference_lookup_pieces (gimple_vuse (stmt),\n \t\t\t\t\t    ops, &ref, false);\n \t\tVEC_free (vn_reference_op_s, heap, ops);\n \t\tif (!ref)\n@@ -3740,7 +3826,7 @@ compute_avail (void)\n \t\t      vn_reference_op_t vro;\n \n \t\t      vn_reference_lookup (gimple_assign_rhs1 (stmt),\n-\t\t\t\t\t   shared_vuses_from_stmt (stmt),\n+\t\t\t\t\t   gimple_vuse (stmt),\n \t\t\t\t\t   false, &ref);\n \t\t      if (!ref)\n \t\t\tcontinue;\n@@ -3834,16 +3920,18 @@ do_SCCVN_insertion (gimple stmt, tree ssa_vn)\n static unsigned int\n eliminate (void)\n {\n+  VEC (gimple, heap) *to_remove = NULL;\n   basic_block b;\n   unsigned int todo = 0;\n+  gimple_stmt_iterator gsi;\n+  gimple stmt;\n+  unsigned i;\n \n   FOR_EACH_BB (b)\n     {\n-      gimple_stmt_iterator i;\n-\n-      for (i = gsi_start_bb (b); !gsi_end_p (i);)\n+      for (gsi = gsi_start_bb (b); !gsi_end_p (gsi); gsi_next (&gsi))\n \t{\n-\t  gimple stmt = gsi_stmt (i);\n+\t  stmt = gsi_stmt (gsi);\n \n \t  /* Lookup the RHS of the expression, see if we have an\n \t     available computation for it.  If so, replace the RHS with\n@@ -3896,10 +3984,9 @@ eliminate (void)\n \t\t      print_gimple_stmt (dump_file, stmt, 0, 0);\n \t\t    }\n \t\t  pre_stats.eliminations++;\n-\t\t  propagate_tree_value_into_stmt (&i, sprime);\n-\t\t  stmt = gsi_stmt (i);\n+\t\t  propagate_tree_value_into_stmt (&gsi, sprime);\n+\t\t  stmt = gsi_stmt (gsi);\n \t\t  update_stmt (stmt);\n-\t\t  gsi_next (&i);\n \t\t  continue;\n \t\t}\n \n@@ -3945,8 +4032,8 @@ eliminate (void)\n \t\t    sprime = fold_convert (gimple_expr_type (stmt), sprime);\n \n \t\t  pre_stats.eliminations++;\n-\t\t  propagate_tree_value_into_stmt (&i, sprime);\n-\t\t  stmt = gsi_stmt (i);\n+\t\t  propagate_tree_value_into_stmt (&gsi, sprime);\n+\t\t  stmt = gsi_stmt (gsi);\n \t\t  update_stmt (stmt);\n \n \t\t  /* If we removed EH side effects from the statement, clean\n@@ -3971,45 +4058,20 @@ eliminate (void)\n \t      tree rhs = gimple_assign_rhs1 (stmt);\n \t      tree val;\n \t      val = vn_reference_lookup (gimple_assign_lhs (stmt),\n-\t\t\t\t\t shared_vuses_from_stmt (stmt),\n-\t\t\t\t\t true, NULL);\n+\t\t\t\t\t gimple_vuse (stmt), true, NULL);\n \t      if (TREE_CODE (rhs) == SSA_NAME)\n \t\trhs = VN_INFO (rhs)->valnum;\n \t      if (val\n \t\t  && operand_equal_p (val, rhs, 0))\n \t\t{\n-\t\t  def_operand_p def;\n-\t\t  use_operand_p use;\n-\t\t  vuse_vec_p usevec;\n-\t\t  ssa_op_iter oi;\n-\t\t  imm_use_iterator ui;\n-\t\t  gimple use_stmt;\n-\n \t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n \t\t    {\n-\t\t      fprintf (dump_file, \"Deleted dead store \");\n+\t\t      fprintf (dump_file, \"Deleted redundant store \");\n \t\t      print_gimple_stmt (dump_file, stmt, 0, 0);\n \t\t    }\n \n-\t\t  /* Propagate all may-uses to the uses of their defs.  */\n-\t\t  FOR_EACH_SSA_VDEF_OPERAND (def, usevec, stmt, oi)\n-\t\t    {\n-\t\t      tree vuse = VUSE_ELEMENT_VAR (*usevec, 0);\n-\t\t      tree vdef = DEF_FROM_PTR (def);\n-\n-\t\t      /* If the vdef is used in an abnormal PHI node we\n-\t\t         have to propagate that flag to the vuse as well.  */\n-\t\t      if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (vdef))\n-\t\t\tSSA_NAME_OCCURS_IN_ABNORMAL_PHI (vuse) = 1;\n-\n-\t\t      FOR_EACH_IMM_USE_STMT (use_stmt, ui, vdef)\n-\t\t\tFOR_EACH_IMM_USE_ON_STMT (use, ui)\n-\t\t\t  SET_USE (use, vuse);\n-\t\t    }\n-\n-\t\t  gsi_remove (&i, true);\n-\t\t  release_defs (stmt);\n-\t\t  continue;\n+\t\t  /* Queue stmt for removal.  */\n+\t\t  VEC_safe_push (gimple, heap, to_remove, stmt);\n \t\t}\n \t    }\n \t  /* Visit COND_EXPRs and fold the comparison with the\n@@ -4036,11 +4098,20 @@ eliminate (void)\n \t\t  todo = TODO_cleanup_cfg;\n \t\t}\n \t    }\n-\n-\t  gsi_next (&i);\n \t}\n     }\n \n+  /* We cannot remove stmts during BB walk, especially not release SSA\n+     names there as this confuses the VN machinery.  */\n+  for (i = 0; VEC_iterate (gimple, to_remove, i, stmt); ++i)\n+    {\n+      gsi = gsi_for_stmt (stmt);\n+      unlink_stmt_vdef (stmt);\n+      gsi_remove (&gsi, true);\n+      release_defs (stmt);\n+    }\n+  VEC_free (gimple, heap, to_remove);\n+\n   return todo;\n }\n \n@@ -4341,7 +4412,7 @@ execute_pre (bool do_fre ATTRIBUTE_UNUSED)\n static unsigned int\n do_pre (void)\n {\n-  return TODO_rebuild_alias | execute_pre (false);\n+  return execute_pre (false);\n }\n \n static bool\n@@ -4366,7 +4437,7 @@ struct gimple_opt_pass pass_pre =\n     | PROP_ssa | PROP_alias,\t\t/* properties_required */\n   0,\t\t\t\t\t/* properties_provided */\n   0,\t\t\t\t\t/* properties_destroyed */\n-  0,\t\t\t\t\t/* todo_flags_start */\n+  TODO_rebuild_alias,\t\t\t/* todo_flags_start */\n   TODO_update_ssa_only_virtuals | TODO_dump_func | TODO_ggc_collect\n   | TODO_verify_ssa /* todo_flags_finish */\n  }"}, {"sha": "ad6858891e601b27d6f27f6539dc7ee36f9dbbf2", "filename": "gcc/tree-ssa-propagate.c", "status": "modified", "additions": 10, "deletions": 5, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-propagate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-propagate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-propagate.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -730,8 +730,9 @@ update_call_from_tree (gimple_stmt_iterator *si_p, tree expr)\n \n       new_stmt = gimple_build_call_vec (fn, args);\n       gimple_call_set_lhs (new_stmt, lhs);\n-      copy_virtual_operands (new_stmt, stmt);\n       move_ssa_defining_stmt_for_defs (new_stmt, stmt);\n+      gimple_set_vuse (new_stmt, gimple_vuse (stmt));\n+      gimple_set_vdef (new_stmt, gimple_vdef (stmt));\n       gimple_set_location (new_stmt, gimple_location (stmt));\n       gsi_replace (si_p, new_stmt, false);\n       VEC_free (tree, heap, args);\n@@ -750,14 +751,17 @@ update_call_from_tree (gimple_stmt_iterator *si_p, tree expr)\n              Introduce a new GIMPLE_ASSIGN statement.  */\n           STRIP_USELESS_TYPE_CONVERSION (expr);\n           new_stmt = gimple_build_assign (lhs, expr);\n-          copy_virtual_operands (new_stmt, stmt);\n           move_ssa_defining_stmt_for_defs (new_stmt, stmt);\n+\t  gimple_set_vuse (new_stmt, gimple_vuse (stmt));\n+\t  gimple_set_vdef (new_stmt, gimple_vdef (stmt));\n         }\n       else if (!TREE_SIDE_EFFECTS (expr))\n         {\n           /* No value is expected, and EXPR has no effect.\n              Replace it with an empty statement.  */\n           new_stmt = gimple_build_nop ();\n+\t  unlink_stmt_vdef (stmt);\n+\t  release_defs (stmt);\n         }\n       else\n         {\n@@ -771,7 +775,8 @@ update_call_from_tree (gimple_stmt_iterator *si_p, tree expr)\n           add_referenced_var (lhs);\n           lhs = make_ssa_name (lhs, new_stmt);\n           gimple_assign_set_lhs (new_stmt, lhs);\n-          copy_virtual_operands (new_stmt, stmt);\n+\t  gimple_set_vuse (new_stmt, gimple_vuse (stmt));\n+\t  gimple_set_vdef (new_stmt, gimple_vdef (stmt));\n           move_ssa_defining_stmt_for_defs (new_stmt, stmt);\n         }\n       gimple_set_location (new_stmt, gimple_location (stmt));\n@@ -842,7 +847,7 @@ stmt_makes_single_load (gimple stmt)\n       != GIMPLE_SINGLE_RHS)\n     return false;\n \n-  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF|SSA_OP_VUSE))\n+  if (!gimple_vuse (stmt))\n     return false;\n \n   rhs = gimple_assign_rhs1 (stmt);\n@@ -867,7 +872,7 @@ stmt_makes_single_store (gimple stmt)\n       && gimple_code (stmt) != GIMPLE_CALL)\n     return false;\n \n-  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF))\n+  if (!gimple_vdef (stmt))\n     return false;\n \n   lhs = gimple_get_lhs (stmt);"}, {"sha": "a3e84680972ff26e621cdb4f98314b4cab413afd", "filename": "gcc/tree-ssa-reassoc.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-reassoc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-reassoc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-reassoc.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -242,7 +242,7 @@ get_rank (tree e)\n \treturn 0;\n \n       if (!is_gimple_assign (stmt)\n-\t  || !ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_DEFS))\n+\t  || gimple_vdef (stmt))\n \treturn bb_rank[gimple_bb (stmt)->index];\n \n       /* If we already have a rank for this expression, use that.  */"}, {"sha": "8abc3061a2050d3f6071973ab3656043f5d89283", "filename": "gcc/tree-ssa-sccvn.c", "status": "modified", "additions": 103, "deletions": 287, "changes": 390, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-sccvn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-sccvn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sccvn.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -426,13 +426,11 @@ vn_reference_hash (const void *p1)\n hashval_t\n vn_reference_compute_hash (const vn_reference_t vr1)\n {\n-  hashval_t result = 0;\n-  tree v;\n+  hashval_t result;\n   int i;\n   vn_reference_op_t vro;\n \n-  for (i = 0; VEC_iterate (tree, vr1->vuses, i, v); i++)\n-    result += iterative_hash_expr (v, 0);\n+  result = iterative_hash_expr (vr1->vuse, 0);\n   for (i = 0; VEC_iterate (vn_reference_op_s, vr1->operands, i, vro); i++)\n     result += vn_reference_op_compute_hash (vro);\n \n@@ -445,7 +443,6 @@ vn_reference_compute_hash (const vn_reference_t vr1)\n int\n vn_reference_eq (const void *p1, const void *p2)\n {\n-  tree v;\n   int i;\n   vn_reference_op_t vro;\n \n@@ -454,115 +451,31 @@ vn_reference_eq (const void *p1, const void *p2)\n   if (vr1->hashcode != vr2->hashcode)\n     return false;\n \n-  if (vr1->vuses == vr2->vuses\n-      && vr1->operands == vr2->operands)\n-    return true;\n+  /* Early out if this is not a hash collision.  */\n+  if (vr1->hashcode != vr2->hashcode)\n+    return false;\n \n-  /* Impossible for them to be equivalent if they have different\n-     number of vuses.  */\n-  if (VEC_length (tree, vr1->vuses) != VEC_length (tree, vr2->vuses))\n+  /* The VOP needs to be the same.  */\n+  if (vr1->vuse != vr2->vuse)\n     return false;\n \n+  /* If the operands are the same we are done.  */\n+  if (vr1->operands == vr2->operands)\n+    return true;\n+\n   /* We require that address operands be canonicalized in a way that\n      two memory references will have the same operands if they are\n      equivalent.  */\n   if (VEC_length (vn_reference_op_s, vr1->operands)\n       != VEC_length (vn_reference_op_s, vr2->operands))\n     return false;\n \n-  /* The memory state is more often different than the address of the\n-     store/load, so check it first.  */\n-  for (i = 0; VEC_iterate (tree, vr1->vuses, i, v); i++)\n-    {\n-      if (VEC_index (tree, vr2->vuses, i) != v)\n-\treturn false;\n-    }\n-\n   for (i = 0; VEC_iterate (vn_reference_op_s, vr1->operands, i, vro); i++)\n-    {\n-      if (!vn_reference_op_eq (VEC_index (vn_reference_op_s, vr2->operands, i),\n-\t\t\t       vro))\n-\treturn false;\n-    }\n-  return true;\n-}\n-\n-/* Place the vuses from STMT into *result.  */\n-\n-static inline void\n-vuses_to_vec (gimple stmt, VEC (tree, gc) **result)\n-{\n-  ssa_op_iter iter;\n-  tree vuse;\n-\n-  if (!stmt)\n-    return;\n-\n-  VEC_reserve_exact (tree, gc, *result,\n-\t\t     num_ssa_operands (stmt, SSA_OP_VIRTUAL_USES));\n-\n-  FOR_EACH_SSA_TREE_OPERAND (vuse, stmt, iter, SSA_OP_VIRTUAL_USES)\n-    VEC_quick_push (tree, *result, vuse);\n-}\n-\n-\n-/* Copy the VUSE names in STMT into a vector, and return\n-   the vector.  */\n-\n-static VEC (tree, gc) *\n-copy_vuses_from_stmt (gimple stmt)\n-{\n-  VEC (tree, gc) *vuses = NULL;\n-\n-  vuses_to_vec (stmt, &vuses);\n-\n-  return vuses;\n-}\n-\n-/* Place the vdefs from STMT into *result.  */\n-\n-static inline void\n-vdefs_to_vec (gimple stmt, VEC (tree, gc) **result)\n-{\n-  ssa_op_iter iter;\n-  tree vdef;\n-\n-  if (!stmt)\n-    return;\n-\n-  *result = VEC_alloc (tree, gc, num_ssa_operands (stmt, SSA_OP_VIRTUAL_DEFS));\n-\n-  FOR_EACH_SSA_TREE_OPERAND (vdef, stmt, iter, SSA_OP_VIRTUAL_DEFS)\n-    VEC_quick_push (tree, *result, vdef);\n-}\n-\n-/* Copy the names of vdef results in STMT into a vector, and return\n-   the vector.  */\n-\n-static VEC (tree, gc) *\n-copy_vdefs_from_stmt (gimple stmt)\n-{\n-  VEC (tree, gc) *vdefs = NULL;\n-\n-  vdefs_to_vec (stmt, &vdefs);\n-\n-  return vdefs;\n-}\n-\n-/* Place for shared_v{uses/defs}_from_stmt to shove vuses/vdefs.  */\n-static VEC (tree, gc) *shared_lookup_vops;\n-\n-/* Copy the virtual uses from STMT into SHARED_LOOKUP_VOPS.\n-   This function will overwrite the current SHARED_LOOKUP_VOPS\n-   variable.  */\n-\n-VEC (tree, gc) *\n-shared_vuses_from_stmt (gimple stmt)\n-{\n-  VEC_truncate (tree, shared_lookup_vops, 0);\n-  vuses_to_vec (stmt, &shared_lookup_vops);\n+    if (!vn_reference_op_eq (VEC_index (vn_reference_op_s, vr2->operands, i),\n+\t\t\t     vro))\n+      return false;\n \n-  return shared_lookup_vops;\n+  return true;\n }\n \n /* Copy the operations present in load/store REF into RESULT, a vector of\n@@ -696,7 +609,7 @@ copy_reference_ops_from_ref (tree ref, VEC(vn_reference_op_s, heap) **result)\n    Returns NULL_TREE if the ops were not handled.\n    This routine needs to be kept in sync with copy_reference_ops_from_ref.  */\n \n-static tree\n+tree\n get_ref_from_reference_ops (VEC(vn_reference_op_s, heap) *ops)\n {\n   vn_reference_op_t op;\n@@ -891,78 +804,6 @@ valueize_refs (VEC (vn_reference_op_s, heap) *orig)\n   return orig;\n }\n \n-/* Transform any SSA_NAME's in ORIG, a vector of vuse trees, into\n-   their value numbers. This is done in-place, and the vector passed\n-   in is returned.  */\n-\n-static VEC (tree, gc) *\n-valueize_vuses (VEC (tree, gc) *orig)\n-{\n-  bool made_replacement = false;\n-  tree vuse;\n-  int i;\n-\n-  for (i = 0; VEC_iterate (tree, orig, i, vuse); i++)\n-    {\n-      if (vuse != SSA_VAL (vuse))\n-\t{\n-\t  made_replacement = true;\n-\t  VEC_replace (tree, orig, i, SSA_VAL (vuse));\n-\t}\n-    }\n-\n-  if (made_replacement && VEC_length (tree, orig) > 1)\n-    sort_vuses (orig);\n-\n-  return orig;\n-}\n-\n-/* Return the single reference statement defining all virtual uses\n-   in VUSES or NULL_TREE, if there are multiple defining statements.\n-   Take into account only definitions that alias REF if following\n-   back-edges.  */\n-\n-static gimple\n-get_def_ref_stmt_vuses (tree ref, VEC (tree, gc) *vuses)\n-{\n-  gimple def_stmt;\n-  tree vuse;\n-  unsigned int i;\n-\n-  gcc_assert (VEC_length (tree, vuses) >= 1);\n-\n-  def_stmt = SSA_NAME_DEF_STMT (VEC_index (tree, vuses, 0));\n-  if (gimple_code (def_stmt) == GIMPLE_PHI)\n-    {\n-      /* We can only handle lookups over PHI nodes for a single\n-\t virtual operand.  */\n-      if (VEC_length (tree, vuses) == 1)\n-\t{\n-\t  def_stmt = get_single_def_stmt_from_phi (ref, def_stmt);\n-\t  goto cont;\n-\t}\n-      else\n-\treturn NULL;\n-    }\n-\n-  /* Verify each VUSE reaches the same defining stmt.  */\n-  for (i = 1; VEC_iterate (tree, vuses, i, vuse); ++i)\n-    {\n-      gimple tmp = SSA_NAME_DEF_STMT (vuse);\n-      if (tmp != def_stmt)\n-\treturn NULL;\n-    }\n-\n-  /* Now see if the definition aliases ref, and loop until it does.  */\n-cont:\n-  while (def_stmt\n-\t && is_gimple_assign (def_stmt)\n-\t && !refs_may_alias_p (ref, gimple_get_lhs (def_stmt)))\n-    def_stmt = get_single_def_stmt_with_phi (ref, def_stmt);\n-\n-  return def_stmt;\n-}\n-\n /* Lookup a SCCVN reference operation VR in the current hash table.\n    Returns the resulting value number if it exists in the hash table,\n    NULL_TREE otherwise.  VNRESULT will be filled in with the actual\n@@ -990,50 +831,71 @@ vn_reference_lookup_1 (vn_reference_t vr, vn_reference_t *vnresult)\n   return NULL_TREE;\n }\n \n+/* Callback for walk_non_aliased_vuses.  Adjusts the vn_reference_t VR_\n+   with the current VUSE and performs the expression lookup.  */\n+\n+static void *\n+vn_reference_lookup_2 (tree op ATTRIBUTE_UNUSED, tree vuse, void *vr_)\n+{\n+  vn_reference_t vr = (vn_reference_t)vr_;\n+  void **slot;\n+  hashval_t hash;\n+\n+  /* Fixup vuse and hash.  */\n+  vr->hashcode = vr->hashcode - iterative_hash_expr (vr->vuse, 0);\n+  vr->vuse = SSA_VAL (vuse);\n+  vr->hashcode = vr->hashcode + iterative_hash_expr (vr->vuse, 0);\n+\n+  hash = vr->hashcode;\n+  slot = htab_find_slot_with_hash (current_info->references, vr,\n+\t\t\t\t   hash, NO_INSERT);\n+  if (!slot && current_info == optimistic_info)\n+    slot = htab_find_slot_with_hash (valid_info->references, vr,\n+\t\t\t\t     hash, NO_INSERT);\n+  if (slot)\n+    return *slot;\n+  \n+  return NULL;\n+}\n \n /* Lookup a reference operation by it's parts, in the current hash table.\n    Returns the resulting value number if it exists in the hash table,\n    NULL_TREE otherwise.  VNRESULT will be filled in with the actual\n    vn_reference_t stored in the hashtable if something is found.  */\n \n tree\n-vn_reference_lookup_pieces (VEC (tree, gc) *vuses,\n+vn_reference_lookup_pieces (tree vuse,\n \t\t\t    VEC (vn_reference_op_s, heap) *operands,\n \t\t\t    vn_reference_t *vnresult, bool maywalk)\n {\n   struct vn_reference_s vr1;\n-  tree result;\n-  if (vnresult)\n-    *vnresult = NULL;\n+  vn_reference_t tmp;\n+\n+  if (!vnresult)\n+    vnresult = &tmp;\n+  *vnresult = NULL;\n   \n-  vr1.vuses = valueize_vuses (vuses);\n+  vr1.vuse = vuse ? SSA_VAL (vuse) : NULL_TREE;\n   vr1.operands = valueize_refs (operands);\n   vr1.hashcode = vn_reference_compute_hash (&vr1);\n-  result = vn_reference_lookup_1 (&vr1, vnresult);\n+  vn_reference_lookup_1 (&vr1, vnresult);\n \n-  /* If there is a single defining statement for all virtual uses, we can\n-     use that, following virtual use-def chains.  */\n-  if (!result\n+  if (!*vnresult\n       && maywalk\n-      && vr1.vuses\n-      && VEC_length (tree, vr1.vuses) >= 1)\n+      && vr1.vuse)\n     {\n       tree ref = get_ref_from_reference_ops (operands);\n-      gimple def_stmt;\n-      if (ref\n-\t  && (def_stmt = get_def_ref_stmt_vuses (ref, vr1.vuses))\n-\t  && is_gimple_assign (def_stmt))\n-\t{\n-\t  /* We are now at an aliasing definition for the vuses we want to\n-\t     look up.  Re-do the lookup with the vdefs for this stmt.  */\n-\t  vdefs_to_vec (def_stmt, &vuses);\n-\t  vr1.vuses = valueize_vuses (vuses);\n-\t  vr1.hashcode = vn_reference_compute_hash (&vr1);\n-\t  result = vn_reference_lookup_1 (&vr1, vnresult);\n-\t}\n+      if (!ref)\n+\treturn NULL_TREE;\n+      *vnresult =\n+\t(vn_reference_t)walk_non_aliased_vuses (ref, vr1.vuse,\n+\t\t\t\t\t\tvn_reference_lookup_2, &vr1);\n     }\n \n-  return result;\n+  if (*vnresult)\n+     return (*vnresult)->result;\n+\n+  return NULL_TREE;\n }\n \n /* Lookup OP in the current hash table, and return the resulting value\n@@ -1043,46 +905,44 @@ vn_reference_lookup_pieces (VEC (tree, gc) *vuses,\n    stored in the hashtable if one exists.  */\n \n tree\n-vn_reference_lookup (tree op, VEC (tree, gc) *vuses, bool maywalk,\n+vn_reference_lookup (tree op, tree vuse, bool maywalk,\n \t\t     vn_reference_t *vnresult)\n {\n   struct vn_reference_s vr1;\n-  tree result;\n-  gimple def_stmt;\n+\n   if (vnresult)\n     *vnresult = NULL;\n \n-  vr1.vuses = valueize_vuses (vuses);\n+  vr1.vuse = vuse ? SSA_VAL (vuse) : NULL_TREE;\n   vr1.operands = valueize_refs (shared_reference_ops_from_ref (op));\n   vr1.hashcode = vn_reference_compute_hash (&vr1);\n-  result = vn_reference_lookup_1 (&vr1, vnresult);\n \n-  /* If there is a single defining statement for all virtual uses, we can\n-     use that, following virtual use-def chains.  */\n-  if (!result\n-      && maywalk\n-      && vr1.vuses\n-      && VEC_length (tree, vr1.vuses) >= 1\n-      && (def_stmt = get_def_ref_stmt_vuses (op, vr1.vuses))\n-      && is_gimple_assign (def_stmt))\n+  if (maywalk\n+      && vr1.vuse)\n     {\n-      /* We are now at an aliasing definition for the vuses we want to\n-\t look up.  Re-do the lookup with the vdefs for this stmt.  */\n-      vdefs_to_vec (def_stmt, &vuses);\n-      vr1.vuses = valueize_vuses (vuses);\n-      vr1.hashcode = vn_reference_compute_hash (&vr1);\n-      result = vn_reference_lookup_1 (&vr1, vnresult);\n+      vn_reference_t wvnresult;\n+      wvnresult =\n+\t(vn_reference_t)walk_non_aliased_vuses (op, vr1.vuse,\n+\t\t\t\t\t\tvn_reference_lookup_2, &vr1);\n+      if (wvnresult)\n+\t{\n+\t  if (vnresult)\n+\t    *vnresult = wvnresult;\n+\t  return wvnresult->result;\n+\t}\n+\n+      return NULL_TREE;\n     }\n \n-  return result;\n+  return vn_reference_lookup_1 (&vr1, vnresult);\n }\n \n \n /* Insert OP into the current hash table with a value number of\n    RESULT, and return the resulting reference structure we created.  */\n \n vn_reference_t\n-vn_reference_insert (tree op, tree result, VEC (tree, gc) *vuses)\n+vn_reference_insert (tree op, tree result, tree vuse)\n {\n   void **slot;\n   vn_reference_t vr1;\n@@ -1092,7 +952,7 @@ vn_reference_insert (tree op, tree result, VEC (tree, gc) *vuses)\n     vr1->value_id = VN_INFO (result)->value_id;\n   else\n     vr1->value_id = get_or_alloc_constant_value_id (result);\n-  vr1->vuses = valueize_vuses (vuses);\n+  vr1->vuse = vuse ? SSA_VAL (vuse) : NULL_TREE;\n   vr1->operands = valueize_refs (create_reference_ops_from_ref (op));\n   vr1->hashcode = vn_reference_compute_hash (vr1);\n   vr1->result = TREE_CODE (result) == SSA_NAME ? SSA_VAL (result) : result;\n@@ -1121,7 +981,7 @@ vn_reference_insert (tree op, tree result, VEC (tree, gc) *vuses)\n    structure we created.  */\n \n vn_reference_t\n-vn_reference_insert_pieces (VEC (tree, gc) *vuses,\n+vn_reference_insert_pieces (tree vuse,\n \t\t\t    VEC (vn_reference_op_s, heap) *operands,\n \t\t\t    tree result, unsigned int value_id)\n \n@@ -1130,8 +990,8 @@ vn_reference_insert_pieces (VEC (tree, gc) *vuses,\n   vn_reference_t vr1;\n \n   vr1 = (vn_reference_t) pool_alloc (current_info->references_pool);\n-  vr1->value_id =  value_id;\n-  vr1->vuses = valueize_vuses (vuses);\n+  vr1->value_id = value_id;\n+  vr1->vuse = vuse ? SSA_VAL (vuse) : NULL_TREE;\n   vr1->operands = valueize_refs (operands);\n   vr1->hashcode = vn_reference_compute_hash (vr1);\n   if (result && TREE_CODE (result) == SSA_NAME)\n@@ -1142,8 +1002,8 @@ vn_reference_insert_pieces (VEC (tree, gc) *vuses,\n \t\t\t\t   INSERT);\n   \n   /* At this point we should have all the things inserted that we have\n-  seen before, and we should never try inserting something that\n-  already exists.  */\n+     seen before, and we should never try inserting something that\n+     already exists.  */\n   gcc_assert (!*slot);\n   if (*slot)\n     free_reference (*slot);\n@@ -1614,7 +1474,7 @@ set_ssa_val_to (tree from, tree to)\n \n   if (currval != to  && !operand_equal_p (currval, to, OEP_PURE_SAME))\n     {\n-      SSA_VAL (from) = to;\n+      VN_INFO (from)->valnum = to;\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \tfprintf (dump_file, \" (changed)\\n\");\n       return true;\n@@ -1722,8 +1582,9 @@ visit_reference_op_call (tree lhs, gimple stmt)\n   bool changed = false;\n   struct vn_reference_s vr1;\n   tree result;\n+  tree vuse = gimple_vuse (stmt);\n \n-  vr1.vuses = valueize_vuses (shared_vuses_from_stmt (stmt));\n+  vr1.vuse = vuse ? SSA_VAL (vuse) : NULL_TREE;\n   vr1.operands = valueize_refs (shared_reference_ops_from_call (stmt));\n   vr1.hashcode = vn_reference_compute_hash (&vr1);\n   result = vn_reference_lookup_1 (&vr1, NULL);\n@@ -1740,7 +1601,7 @@ visit_reference_op_call (tree lhs, gimple stmt)\n       vn_reference_t vr2;\n       changed = set_ssa_val_to (lhs, lhs);\n       vr2 = (vn_reference_t) pool_alloc (current_info->references_pool);\n-      vr2->vuses = valueize_vuses (copy_vuses_from_stmt (stmt));\n+      vr2->vuse = vr1.vuse;\n       vr2->operands = valueize_refs (create_reference_ops_from_call (stmt));\n       vr2->hashcode = vr1.hashcode;\n       vr2->result = lhs;\n@@ -1761,8 +1622,7 @@ static bool\n visit_reference_op_load (tree lhs, tree op, gimple stmt)\n {\n   bool changed = false;\n-  tree result = vn_reference_lookup (op, shared_vuses_from_stmt (stmt), true,\n-\t\t\t\t     NULL);\n+  tree result = vn_reference_lookup (op, gimple_vuse (stmt), true, NULL);\n \n   /* We handle type-punning through unions by value-numbering based\n      on offset and size of the access.  Be prepared to handle a\n@@ -1840,7 +1700,7 @@ visit_reference_op_load (tree lhs, tree op, gimple stmt)\n   else\n     {\n       changed = set_ssa_val_to (lhs, lhs);\n-      vn_reference_insert (op, lhs, copy_vuses_from_stmt (stmt));\n+      vn_reference_insert (op, lhs, gimple_vuse (stmt));\n     }\n \n   return changed;\n@@ -1873,8 +1733,7 @@ visit_reference_op_store (tree lhs, tree op, gimple stmt)\n      Otherwise, the vdefs for the store are used when inserting into\n      the table, since the store generates a new memory state.  */\n \n-  result = vn_reference_lookup (lhs, shared_vuses_from_stmt (stmt), false,\n-\t\t\t\tNULL);\n+  result = vn_reference_lookup (lhs, gimple_vuse (stmt), false, NULL);\n \n   if (result)\n     {\n@@ -1887,8 +1746,6 @@ visit_reference_op_store (tree lhs, tree op, gimple stmt)\n \n   if (!result || !resultsame)\n     {\n-      VEC(tree, gc) *vdefs = copy_vdefs_from_stmt (stmt);\n-      int i;\n       tree vdef;\n \n       if (dump_file && (dump_flags & TDF_DETAILS))\n@@ -1902,7 +1759,7 @@ visit_reference_op_store (tree lhs, tree op, gimple stmt)\n \t}\n       /* Have to set value numbers before insert, since insert is\n \t going to valueize the references in-place.  */\n-      for (i = 0; VEC_iterate (tree, vdefs, i, vdef); i++)\n+      if ((vdef = gimple_vdef (stmt)))\n \t{\n \t  VN_INFO (vdef)->use_processed = true;\n \t  changed |= set_ssa_val_to (vdef, vdef);\n@@ -1911,36 +1768,23 @@ visit_reference_op_store (tree lhs, tree op, gimple stmt)\n       /* Do not insert structure copies into the tables.  */\n       if (is_gimple_min_invariant (op)\n \t  || is_gimple_reg (op))\n-        vn_reference_insert (lhs, op, vdefs);\n+        vn_reference_insert (lhs, op, vdef);\n     }\n   else\n     {\n-      /* We had a match, so value number the vdefs to have the value\n-\t number of the vuses they came from.  */\n-      ssa_op_iter op_iter;\n-      def_operand_p var;\n-      vuse_vec_p vv;\n+      /* We had a match, so value number the vdef to have the value\n+\t number of the vuse it came from.  */\n+      tree def, use;\n \n       if (dump_file && (dump_flags & TDF_DETAILS))\n \tfprintf (dump_file, \"Store matched earlier value,\"\n \t\t \"value numbering store vdefs to matching vuses.\\n\");\n \n-      FOR_EACH_SSA_VDEF_OPERAND (var, vv, stmt, op_iter)\n-\t{\n-\t  tree def = DEF_FROM_PTR (var);\n-\t  tree use;\n-\n-\t  /* Uh, if the vuse is a multiuse, we can't really do much\n-\t     here, sadly, since we don't know which value number of\n-\t     which vuse to use.  */\n-\t  if (VUSE_VECT_NUM_ELEM (*vv) != 1)\n-\t    use = def;\n-\t  else\n-\t    use = VUSE_ELEMENT_VAR (*vv, 0);\n+      def = gimple_vdef (stmt);\n+      use = gimple_vuse (stmt);\n \n-\t  VN_INFO (def)->use_processed = true;\n-\t  changed |= set_ssa_val_to (def, SSA_VAL (use));\n-\t}\n+      VN_INFO (def)->use_processed = true;\n+      changed |= set_ssa_val_to (def, SSA_VAL (use));\n     }\n \n   return changed;\n@@ -2802,7 +2646,6 @@ init_scc_vn (void)\n   gcc_obstack_init (&vn_ssa_aux_obstack);\n \n   shared_lookup_phiargs = NULL;\n-  shared_lookup_vops = NULL;\n   shared_lookup_references = NULL;\n   rpo_numbers = XCNEWVEC (int, last_basic_block + NUM_FIXED_BLOCKS);\n   rpo_numbers_temp = XCNEWVEC (int, last_basic_block + NUM_FIXED_BLOCKS);\n@@ -2848,7 +2691,6 @@ free_scc_vn (void)\n   htab_delete (constant_to_value_id);\n   BITMAP_FREE (constant_value_ids);\n   VEC_free (tree, heap, shared_lookup_phiargs);\n-  VEC_free (tree, gc, shared_lookup_vops);\n   VEC_free (vn_reference_op_s, heap, shared_lookup_references);\n   XDELETEVEC (rpo_numbers);\n \n@@ -2941,7 +2783,7 @@ run_scc_vn (bool may_insert_arg)\n       if (gimple_default_def (cfun, param) != NULL)\n \t{\n \t  tree def = gimple_default_def (cfun, param);\n-\t  SSA_VAL (def) = def;\n+\t  VN_INFO (def)->valnum = def;\n \t}\n     }\n \n@@ -3074,32 +2916,6 @@ expressions_equal_p (tree e1, tree e2)\n   return false;\n }\n \n-/* Sort the VUSE array so that we can do equality comparisons\n-   quicker on two vuse vecs.  */\n-\n-void\n-sort_vuses (VEC (tree,gc) *vuses)\n-{\n-  if (VEC_length (tree, vuses) > 1)\n-    qsort (VEC_address (tree, vuses),\n-\t   VEC_length (tree, vuses),\n-\t   sizeof (tree),\n-\t   operand_build_cmp);\n-}\n-\n-/* Sort the VUSE array so that we can do equality comparisons\n-   quicker on two vuse vecs.  */\n-\n-void\n-sort_vuses_heap (VEC (tree,heap) *vuses)\n-{\n-  if (VEC_length (tree, vuses) > 1)\n-    qsort (VEC_address (tree, vuses),\n-\t   VEC_length (tree, vuses),\n-\t   sizeof (tree),\n-\t   operand_build_cmp);\n-}\n-\n \n /* Return true if the nary operation NARY may trap.  This is a copy\n    of stmt_could_throw_1_p adjusted to the SCCVN IL.  */"}, {"sha": "644bc127f7829a69fe498d502950fc48ef76b8a0", "filename": "gcc/tree-ssa-sccvn.h", "status": "modified", "additions": 9, "deletions": 10, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-sccvn.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-sccvn.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sccvn.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -79,20 +79,19 @@ typedef const vn_reference_op_s *const_vn_reference_op_t;\n DEF_VEC_O(vn_reference_op_s);\n DEF_VEC_ALLOC_O(vn_reference_op_s, heap);\n \n-/* A reference operation in the hashtable is representation as a\n-   collection of vuses, representing the memory state at the time of\n+/* A reference operation in the hashtable is representation as\n+   the vuse, representing the memory state at the time of\n    the operation, and a collection of operands that make up the\n    addressing calculation.  If two vn_reference_t's have the same set\n    of operands, they access the same memory location. We also store\n-   the resulting value number, and the hashcode.  The vuses are\n-   always stored in order sorted by ssa name version.  */\n+   the resulting value number, and the hashcode.  */\n \n typedef struct vn_reference_s\n {\n   /* Unique identifier that all expressions with the same value have. */\n   unsigned int value_id;\n   hashval_t hashcode;\n-  VEC (tree, gc) *vuses;\n+  tree vuse;\n   VEC (vn_reference_op_s, heap) *operands;\n   tree result;\n } *vn_reference_t;\n@@ -176,12 +175,13 @@ vn_nary_op_t vn_nary_op_insert_pieces (unsigned int, enum tree_code,\n \t\t\t\t       tree, tree, unsigned int);\n void copy_reference_ops_from_ref (tree, VEC(vn_reference_op_s, heap) **);\n void copy_reference_ops_from_call (gimple, VEC(vn_reference_op_s, heap) **);\n-tree vn_reference_lookup_pieces (VEC (tree, gc) *,\n+tree get_ref_from_reference_ops (VEC(vn_reference_op_s, heap) *ops);\n+tree vn_reference_lookup_pieces (tree,\n \t\t\t\t VEC (vn_reference_op_s, heap) *,\n \t\t\t\t vn_reference_t *, bool);\n-tree vn_reference_lookup (tree, VEC (tree, gc) *, bool, vn_reference_t *);\n-vn_reference_t vn_reference_insert (tree, tree, VEC (tree, gc) *);\n-vn_reference_t vn_reference_insert_pieces (VEC (tree, gc) *,\n+tree vn_reference_lookup (tree, tree, bool, vn_reference_t *);\n+vn_reference_t vn_reference_insert (tree, tree, tree);\n+vn_reference_t vn_reference_insert_pieces (tree,\n \t\t\t\t\t   VEC (vn_reference_op_s, heap) *,\n \t\t\t\t\t   tree, unsigned int);\n \n@@ -195,5 +195,4 @@ unsigned int get_next_value_id (void);\n unsigned int get_constant_value_id (tree);\n unsigned int get_or_alloc_constant_value_id (tree);\n bool value_id_constant_p (unsigned int);\n-VEC (tree, gc) *shared_vuses_from_stmt (gimple);\n #endif /* TREE_SSA_SCCVN_H  */"}, {"sha": "d0c550d8abb18442e56cdb6dcb11f3b3b166177b", "filename": "gcc/tree-ssa-sink.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-sink.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-sink.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sink.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -140,7 +140,7 @@ is_hidden_global_store (gimple stmt)\n   /* Check virtual definitions.  If we get here, the only virtual\n      definitions we should see are those generated by assignment or call\n      statements.  */\n-  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_DEFS))\n+  if (gimple_vdef (stmt))\n     {\n       tree lhs;\n \n@@ -191,7 +191,7 @@ is_hidden_global_store (gimple stmt)\n \n \t}\n       else if (INDIRECT_REF_P (lhs))\n-\treturn may_point_to_global_var (TREE_OPERAND (lhs, 0));\n+\treturn ptr_deref_may_alias_global_p (TREE_OPERAND (lhs, 0));\n       else\n \tgcc_unreachable ();\n     }\n@@ -317,7 +317,7 @@ statement_sink_location (gimple stmt, basic_block frombb,\n       || code == FILTER_EXPR\n       || is_hidden_global_store (stmt)\n       || gimple_has_volatile_ops (stmt)\n-      || !ZERO_SSA_OPERANDS (stmt, SSA_OP_VUSE)\n+      || gimple_vuse (stmt)\n       || (cfun->has_local_explicit_reg_vars\n \t  && TYPE_MODE (TREE_TYPE (gimple_assign_lhs (stmt))) == BLKmode))\n     return false;"}, {"sha": "7ac27c06ad6ae4a1383abc3955a9f26f484c621a", "filename": "gcc/tree-ssa-structalias.c", "status": "modified", "additions": 897, "deletions": 804, "changes": 1701, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-structalias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-structalias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-structalias.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -48,7 +48,6 @@\n #include \"alloc-pool.h\"\n #include \"splay-tree.h\"\n #include \"params.h\"\n-#include \"tree-ssa-structalias.h\"\n #include \"cgraph.h\"\n #include \"alias.h\"\n #include \"pointer-set.h\"\n@@ -185,6 +184,9 @@ static unsigned int create_variable_info_for (tree, const char *);\n typedef struct constraint_graph *constraint_graph_t;\n static void unify_nodes (constraint_graph_t, unsigned int, unsigned int, bool);\n \n+struct constraint;\n+typedef struct constraint *constraint_t;\n+\n DEF_VEC_P(constraint_t);\n DEF_VEC_ALLOC_P(constraint_t,heap);\n \n@@ -233,11 +235,6 @@ struct variable_info\n   /* True if this field may contain pointers.  */\n   unsigned int may_have_pointers : 1;\n \n-  /* Variable id this was collapsed to due to type unsafety.  Zero if\n-     this variable was not collapsed.  This should be unused completely\n-     after build_succ_graph, or something is broken.  */\n-  unsigned int collapsed_to;\n-\n   /* A link to the variable for the next field in this structure.  */\n   struct variable_info *next;\n \n@@ -265,6 +262,8 @@ struct variable_info\n typedef struct variable_info *varinfo_t;\n \n static varinfo_t first_vi_for_offset (varinfo_t, unsigned HOST_WIDE_INT);\n+static varinfo_t first_or_preceding_vi_for_offset (varinfo_t,\n+\t\t\t\t\t\t   unsigned HOST_WIDE_INT);\n static varinfo_t lookup_vi_for_tree (tree);\n \n /* Pool of variable info structures.  */\n@@ -286,18 +285,6 @@ get_varinfo (unsigned int n)\n   return VEC_index (varinfo_t, varmap, n);\n }\n \n-/* Return the varmap element N, following the collapsed_to link.  */\n-\n-static inline varinfo_t\n-get_varinfo_fc (unsigned int n)\n-{\n-  varinfo_t v = VEC_index (varinfo_t, varmap, n);\n-\n-  if (v->collapsed_to != 0)\n-    return get_varinfo (v->collapsed_to);\n-  return v;\n-}\n-\n /* Static IDs for the special variables.  */\n enum { nothing_id = 0, anything_id = 1, readonly_id = 2,\n        escaped_id = 3, nonlocal_id = 4, callused_id = 5,\n@@ -395,7 +382,6 @@ new_var_info (tree t, unsigned int id, const char *name)\n   ret->solution = BITMAP_ALLOC (&pta_obstack);\n   ret->oldsolution = BITMAP_ALLOC (&oldpta_obstack);\n   ret->next = NULL;\n-  ret->collapsed_to = 0;\n   return ret;\n }\n \n@@ -416,9 +402,12 @@ struct constraint_expr\n \n      IOW, in a deref constraint, we would deref, get the result set,\n      then add OFFSET to each member.   */\n-  unsigned HOST_WIDE_INT offset;\n+  HOST_WIDE_INT offset;\n };\n \n+/* Use 0x8000... as special unknown offset.  */\n+#define UNKNOWN_OFFSET ((HOST_WIDE_INT)-1 << (HOST_BITS_PER_WIDE_INT-1))\n+\n typedef struct constraint_expr ce_s;\n DEF_VEC_O(ce_s);\n DEF_VEC_ALLOC_O(ce_s, heap);\n@@ -575,27 +564,38 @@ new_constraint (const struct constraint_expr lhs,\n \n /* Print out constraint C to FILE.  */\n \n-void\n+static void\n dump_constraint (FILE *file, constraint_t c)\n {\n   if (c->lhs.type == ADDRESSOF)\n     fprintf (file, \"&\");\n   else if (c->lhs.type == DEREF)\n     fprintf (file, \"*\");\n-  fprintf (file, \"%s\", get_varinfo_fc (c->lhs.var)->name);\n-  if (c->lhs.offset != 0)\n+  fprintf (file, \"%s\", get_varinfo (c->lhs.var)->name);\n+  if (c->lhs.offset == UNKNOWN_OFFSET)\n+    fprintf (file, \" + UNKNOWN\");\n+  else if (c->lhs.offset != 0)\n     fprintf (file, \" + \" HOST_WIDE_INT_PRINT_DEC, c->lhs.offset);\n   fprintf (file, \" = \");\n   if (c->rhs.type == ADDRESSOF)\n     fprintf (file, \"&\");\n   else if (c->rhs.type == DEREF)\n     fprintf (file, \"*\");\n-  fprintf (file, \"%s\", get_varinfo_fc (c->rhs.var)->name);\n-  if (c->rhs.offset != 0)\n+  fprintf (file, \"%s\", get_varinfo (c->rhs.var)->name);\n+  if (c->rhs.offset == UNKNOWN_OFFSET)\n+    fprintf (file, \" + UNKNOWN\");\n+  else if (c->rhs.offset != 0)\n     fprintf (file, \" + \" HOST_WIDE_INT_PRINT_DEC, c->rhs.offset);\n   fprintf (file, \"\\n\");\n }\n \n+\n+void debug_constraint (constraint_t);\n+void debug_constraints (void);\n+void debug_constraint_graph (void);\n+void debug_solution_for_var (unsigned int);\n+void debug_sa_points_to_info (void);\n+\n /* Print out constraint C to stderr.  */\n \n void\n@@ -606,7 +606,7 @@ debug_constraint (constraint_t c)\n \n /* Print out all constraints to FILE */\n \n-void\n+static void\n dump_constraints (FILE *file)\n {\n   int i;\n@@ -630,13 +630,13 @@ debug_constraints (void)\n    complex with an offset, e.g: a = b + 8, then the label is \"+\".\n    Otherwise the edge has no label.  */\n \n-void\n+static void\n dump_constraint_edge (FILE *file, constraint_t c)\n {\n   if (c->rhs.type != ADDRESSOF)\n     {\n-      const char *src = get_varinfo_fc (c->rhs.var)->name;\n-      const char *dst = get_varinfo_fc (c->lhs.var)->name;\n+      const char *src = get_varinfo (c->rhs.var)->name;\n+      const char *dst = get_varinfo (c->lhs.var)->name;\n       fprintf (file, \"  \\\"%s\\\" -> \\\"%s\\\" \", src, dst);\n       /* Due to preprocessing of constraints, instructions like *a = *b are\n          illegal; thus, we do not have to handle such cases.  */\n@@ -658,7 +658,7 @@ dump_constraint_edge (FILE *file, constraint_t c)\n \n /* Print the constraint graph in dot format.  */\n \n-void\n+static void\n dump_constraint_graph (FILE *file)\n {\n   unsigned int i=0, size;\n@@ -690,7 +690,7 @@ dump_constraint_graph (FILE *file)\n   size = size < graph->size ? size : graph->size;\n   for (i = 0; i < size; i++)\n     {\n-      const char *name = get_varinfo_fc (graph->rep[i])->name;\n+      const char *name = get_varinfo (graph->rep[i])->name;\n       fprintf (file, \"  \\\"%s\\\" ;\\n\", name);\n     }\n \n@@ -833,16 +833,62 @@ constraint_set_union (VEC(constraint_t,heap) **to,\n     }\n }\n \n+/* Expands the solution in SET to all sub-fields of variables included.\n+   Union the expanded result into RESULT.  */\n+\n+static void\n+solution_set_expand (bitmap result, bitmap set)\n+{\n+  bitmap_iterator bi;\n+  bitmap vars = NULL;\n+  unsigned j;\n+\n+  /* In a first pass record all variables we need to add all\n+     sub-fields off.  This avoids quadratic behavior.  */\n+  EXECUTE_IF_SET_IN_BITMAP (set, 0, j, bi)\n+    {\n+      varinfo_t v = get_varinfo (j);\n+      if (v->is_artificial_var\n+\t  || v->is_full_var)\n+\tcontinue;\n+      v = lookup_vi_for_tree (v->decl);\n+      if (vars == NULL)\n+\tvars = BITMAP_ALLOC (NULL);\n+      bitmap_set_bit (vars, v->id);\n+    }\n+\n+  /* In the second pass now do the addition to the solution and\n+     to speed up solving add it to the delta as well.  */\n+  if (vars != NULL)\n+    {\n+      EXECUTE_IF_SET_IN_BITMAP (vars, 0, j, bi)\n+\t{\n+\t  varinfo_t v = get_varinfo (j);\n+\t  for (; v != NULL; v = v->next)\n+\t    bitmap_set_bit (result, v->id);\n+\t}\n+      BITMAP_FREE (vars);\n+    }\n+}\n+\n /* Take a solution set SET, add OFFSET to each member of the set, and\n    overwrite SET with the result when done.  */\n \n static void\n-solution_set_add (bitmap set, unsigned HOST_WIDE_INT offset)\n+solution_set_add (bitmap set, HOST_WIDE_INT offset)\n {\n   bitmap result = BITMAP_ALLOC (&iteration_obstack);\n   unsigned int i;\n   bitmap_iterator bi;\n \n+  /* If the offset is unknown we have to expand the solution to\n+     all subfields.  */\n+  if (offset == UNKNOWN_OFFSET)\n+    {\n+      solution_set_expand (set, set);\n+      return;\n+    }\n+\n   EXECUTE_IF_SET_IN_BITMAP (set, 0, i, bi)\n     {\n       varinfo_t vi = get_varinfo (i);\n@@ -856,21 +902,23 @@ solution_set_add (bitmap set, unsigned HOST_WIDE_INT offset)\n       else\n \t{\n \t  unsigned HOST_WIDE_INT fieldoffset = vi->offset + offset;\n-\t  varinfo_t v = first_vi_for_offset (vi, fieldoffset);\n-\t  /* If the result is outside of the variable use the last field.  */\n-\t  if (!v)\n-\t    {\n-\t      v = vi;\n-\t      while (v->next != NULL)\n-\t\tv = v->next;\n-\t    }\n-\t  bitmap_set_bit (result, v->id);\n+\n+\t  /* If the offset makes the pointer point to before the\n+\t     variable use offset zero for the field lookup.  */\n+\t  if (offset < 0\n+\t      && fieldoffset > vi->offset)\n+\t    fieldoffset = 0;\n+\n+\t  if (offset != 0)\n+\t    vi = first_or_preceding_vi_for_offset (vi, fieldoffset);\n+\n+\t  bitmap_set_bit (result, vi->id);\n \t  /* If the result is not exactly at fieldoffset include the next\n \t     field as well.  See get_constraint_for_ptr_offset for more\n \t     rationale.  */\n-\t  if (v->offset != fieldoffset\n-\t      && v->next != NULL)\n-\t    bitmap_set_bit (result, v->next->id);\n+\t  if (vi->offset != fieldoffset\n+\t      && vi->next != NULL)\n+\t    bitmap_set_bit (result, vi->next->id);\n \t}\n     }\n \n@@ -882,7 +930,7 @@ solution_set_add (bitmap set, unsigned HOST_WIDE_INT offset)\n    process.  */\n \n static bool\n-set_union_with_increment  (bitmap to, bitmap from, unsigned HOST_WIDE_INT inc)\n+set_union_with_increment  (bitmap to, bitmap from, HOST_WIDE_INT inc)\n {\n   if (inc == 0)\n     return bitmap_ior_into (to, from);\n@@ -1119,8 +1167,8 @@ build_pred_graph (void)\n     {\n       struct constraint_expr lhs = c->lhs;\n       struct constraint_expr rhs = c->rhs;\n-      unsigned int lhsvar = get_varinfo_fc (lhs.var)->id;\n-      unsigned int rhsvar = get_varinfo_fc (rhs.var)->id;\n+      unsigned int lhsvar = lhs.var;\n+      unsigned int rhsvar = rhs.var;\n \n       if (lhs.type == DEREF)\n \t{\n@@ -1154,17 +1202,17 @@ build_pred_graph (void)\n \n \t  /* All related variables are no longer direct nodes.  */\n \t  RESET_BIT (graph->direct_nodes, rhsvar);\n-\t  v = get_varinfo (rhsvar);\n-\t  if (!v->is_full_var)\n-\t    {\n-\t      v = lookup_vi_for_tree (v->decl);\n-\t      do\n-\t\t{\n-\t\t  RESET_BIT (graph->direct_nodes, v->id);\n-\t\t  v = v->next;\n-\t\t}\n-\t      while (v != NULL);\n-\t    }\n+          v = get_varinfo (rhsvar);\n+          if (!v->is_full_var)\n+            {\n+              v = lookup_vi_for_tree (v->decl);\n+              do\n+                {\n+                  RESET_BIT (graph->direct_nodes, v->id);\n+                  v = v->next;\n+                }\n+              while (v != NULL);\n+            }\n \t  bitmap_set_bit (graph->address_taken, rhsvar);\n \t}\n       else if (lhsvar > anything_id\n@@ -1206,8 +1254,8 @@ build_succ_graph (void)\n \n       lhs = c->lhs;\n       rhs = c->rhs;\n-      lhsvar = find (get_varinfo_fc (lhs.var)->id);\n-      rhsvar = find (get_varinfo_fc (rhs.var)->id);\n+      lhsvar = find (lhs.var);\n+      rhsvar = find (rhs.var);\n \n       if (lhs.type == DEREF)\n \t{\n@@ -1222,8 +1270,7 @@ build_succ_graph (void)\n       else if (rhs.type == ADDRESSOF)\n \t{\n \t  /* x = &y */\n-\t  gcc_assert (find (get_varinfo_fc (rhs.var)->id)\n-\t\t      == get_varinfo_fc (rhs.var)->id);\n+\t  gcc_assert (find (rhs.var) == rhs.var);\n \t  bitmap_set_bit (get_varinfo (lhsvar)->solution, rhsvar);\n \t}\n       else if (lhsvar > anything_id\n@@ -1485,29 +1532,8 @@ topo_visit (constraint_graph_t graph, struct topo_info *ti,\n   VEC_safe_push (unsigned, heap, ti->topo_order, n);\n }\n \n-/* Return true if variable N + OFFSET is a legal field of N.  */\n-\n-static bool\n-type_safe (unsigned int n, unsigned HOST_WIDE_INT *offset)\n-{\n-  varinfo_t ninfo = get_varinfo (n);\n-\n-  /* For things we've globbed to single variables, any offset into the\n-     variable acts like the entire variable, so that it becomes offset\n-     0.  */\n-  if (ninfo->is_special_var\n-      || ninfo->is_artificial_var\n-      || ninfo->is_unknown_size_var\n-      || ninfo->is_full_var)\n-    {\n-      *offset = 0;\n-      return true;\n-    }\n-  return (get_varinfo (n)->offset + *offset) < get_varinfo (n)->fullsize;\n-}\n-\n-/* Process a constraint C that represents x = *y, using DELTA as the\n-   starting solution.  */\n+/* Process a constraint C that represents x = *(y + off), using DELTA as the\n+   starting solution for y.  */\n \n static void\n do_sd_constraint (constraint_graph_t graph, constraint_t c,\n@@ -1518,73 +1544,47 @@ do_sd_constraint (constraint_graph_t graph, constraint_t c,\n   bitmap sol = get_varinfo (lhs)->solution;\n   unsigned int j;\n   bitmap_iterator bi;\n+  HOST_WIDE_INT roffset = c->rhs.offset;\n \n-  /* For x = *ESCAPED and x = *CALLUSED we want to compute the\n-     reachability set of the rhs var.  As a pointer to a sub-field\n-     of a variable can also reach all other fields of the variable\n-     we simply have to expand the solution to contain all sub-fields\n-     if one sub-field is contained.  */\n-  if (c->rhs.var == find (escaped_id)\n-      || c->rhs.var == find (callused_id))\n-    {\n-      bitmap vars = NULL;\n-      /* In a first pass record all variables we need to add all\n-         sub-fields off.  This avoids quadratic behavior.  */\n-      EXECUTE_IF_SET_IN_BITMAP (delta, 0, j, bi)\n-\t{\n-\t  varinfo_t v = get_varinfo (j);\n-\t  if (v->is_full_var)\n-\t    continue;\n-\n-\t  v = lookup_vi_for_tree (v->decl);\n-\t  if (v->next != NULL)\n-\t    {\n-\t      if (vars == NULL)\n-\t\tvars = BITMAP_ALLOC (NULL);\n-\t      bitmap_set_bit (vars, v->id);\n-\t    }\n-\t}\n-      /* In the second pass now do the addition to the solution and\n-         to speed up solving add it to the delta as well.  */\n-      if (vars != NULL)\n-\t{\n-\t  EXECUTE_IF_SET_IN_BITMAP (vars, 0, j, bi)\n-\t    {\n-\t      varinfo_t v = get_varinfo (j);\n-\t      for (; v != NULL; v = v->next)\n-\t\t{\n-\t\t  if (bitmap_set_bit (sol, v->id))\n-\t\t    {\n-\t\t      flag = true;\n-\t\t      bitmap_set_bit (delta, v->id);\n-\t\t    }\n-\t\t}\n-\t    }\n-\t  BITMAP_FREE (vars);\n-\t}\n-    }\n+  /* Our IL does not allow this.  */\n+  gcc_assert (c->lhs.offset == 0);\n \n+  /* If the solution of Y contains anything it is good enough to transfer\n+     this to the LHS.  */\n   if (bitmap_bit_p (delta, anything_id))\n     {\n       flag |= bitmap_set_bit (sol, anything_id);\n       goto done;\n     }\n \n+  /* If we do not know at with offset the rhs is dereferenced compute\n+     the reachability set of DELTA, conservatively assuming it is\n+     dereferenced at all valid offsets.  */\n+  if (roffset == UNKNOWN_OFFSET)\n+    {\n+      solution_set_expand (delta, delta);\n+      /* No further offset processing is necessary.  */\n+      roffset = 0;\n+    }\n+\n   /* For each variable j in delta (Sol(y)), add\n      an edge in the graph from j to x, and union Sol(j) into Sol(x).  */\n   EXECUTE_IF_SET_IN_BITMAP (delta, 0, j, bi)\n     {\n-      unsigned HOST_WIDE_INT roffset = c->rhs.offset;\n-      if (type_safe (j, &roffset))\n-\t{\n-\t  varinfo_t v;\n-\t  unsigned HOST_WIDE_INT fieldoffset = get_varinfo (j)->offset + roffset;\n-\t  unsigned int t;\n+      varinfo_t v = get_varinfo (j);\n+      HOST_WIDE_INT fieldoffset = v->offset + roffset;\n+      unsigned int t;\n+\n+      if (v->is_full_var)\n+\tfieldoffset = v->offset;\n+      else if (roffset != 0)\n+\tv = first_vi_for_offset (v, fieldoffset);\n+      /* If the access is outside of the variable we can ignore it.  */\n+      if (!v)\n+\tcontinue;\n \n-\t  v = first_vi_for_offset (get_varinfo (j), fieldoffset);\n-\t  /* If the access is outside of the variable we can ignore it.  */\n-\t  if (!v)\n-\t    continue;\n+      do\n+\t{\n \t  t = find (v->id);\n \n \t  /* Adding edges from the special vars is pointless.\n@@ -1593,11 +1593,21 @@ do_sd_constraint (constraint_graph_t graph, constraint_t c,\n \t    flag |= bitmap_ior_into (sol, get_varinfo (t)->solution);\n \t  /* Merging the solution from ESCAPED needlessly increases\n \t     the set.  Use ESCAPED as representative instead.  */\n-\t  else if (get_varinfo (t)->id == find (escaped_id))\n+\t  else if (v->id == escaped_id)\n \t    flag |= bitmap_set_bit (sol, escaped_id);\n \t  else if (add_graph_edge (graph, lhs, t))\n \t    flag |= bitmap_ior_into (sol, get_varinfo (t)->solution);\n+\n+\t  /* If the variable is not exactly at the requested offset\n+\t     we have to include the next one.  */\n+\t  if (v->offset == (unsigned HOST_WIDE_INT)fieldoffset\n+\t      || v->next == NULL)\n+\t    break;\n+\n+\t  v = v->next;\n+\t  fieldoffset = v->offset;\n \t}\n+      while (1);\n     }\n \n done:\n@@ -1613,7 +1623,8 @@ do_sd_constraint (constraint_graph_t graph, constraint_t c,\n     }\n }\n \n-/* Process a constraint C that represents *x = y.  */\n+/* Process a constraint C that represents *(x + off) = y using DELTA\n+   as the starting solution for x.  */\n \n static void\n do_ds_constraint (constraint_t c, bitmap delta)\n@@ -1622,6 +1633,7 @@ do_ds_constraint (constraint_t c, bitmap delta)\n   bitmap sol = get_varinfo (rhs)->solution;\n   unsigned int j;\n   bitmap_iterator bi;\n+  HOST_WIDE_INT loff = c->lhs.offset;\n \n   /* Our IL does not allow this.  */\n   gcc_assert (c->rhs.offset == 0);\n@@ -1651,22 +1663,36 @@ do_ds_constraint (constraint_t c, bitmap delta)\n       return;\n     }\n \n+  /* If we do not know at with offset the rhs is dereferenced compute\n+     the reachability set of DELTA, conservatively assuming it is\n+     dereferenced at all valid offsets.  */\n+  if (loff == UNKNOWN_OFFSET)\n+    {\n+      solution_set_expand (delta, delta);\n+      loff = 0;\n+    }\n+\n   /* For each member j of delta (Sol(x)), add an edge from y to j and\n      union Sol(y) into Sol(j) */\n   EXECUTE_IF_SET_IN_BITMAP (delta, 0, j, bi)\n     {\n-      unsigned HOST_WIDE_INT loff = c->lhs.offset;\n-      if (type_safe (j, &loff) && !(get_varinfo (j)->is_special_var))\n-\t{\n-\t  varinfo_t v;\n-\t  unsigned int t;\n-\t  unsigned HOST_WIDE_INT fieldoffset = get_varinfo (j)->offset + loff;\n+      varinfo_t v = get_varinfo (j);\n+      unsigned int t;\n+      HOST_WIDE_INT fieldoffset = v->offset + loff;\n \n-\t  v = first_vi_for_offset (get_varinfo (j), fieldoffset);\n-\t  /* If the access is outside of the variable we can ignore it.  */\n-\t  if (!v)\n-\t    continue;\n+      if (v->is_special_var)\n+\tcontinue;\n+\n+      if (v->is_full_var)\n+\tfieldoffset = v->offset;\n+      else if (loff != 0)\n+\tv = first_vi_for_offset (v, fieldoffset);\n+      /* If the access is outside of the variable we can ignore it.  */\n+      if (!v)\n+\tcontinue;\n \n+      do\n+\t{\n \t  if (v->may_have_pointers)\n \t    {\n \t      t = find (v->id);\n@@ -1684,7 +1710,17 @@ do_ds_constraint (constraint_t c, bitmap delta)\n \t\t    }\n \t\t}\n \t    }\n+\n+\t  /* If the variable is not exactly at the requested offset\n+\t     we have to include the next one.  */\n+\t  if (v->offset == (unsigned HOST_WIDE_INT)fieldoffset\n+\t      || v->next == NULL)\n+\t    break;\n+\n+\t  v = v->next;\n+\t  fieldoffset = v->offset;\n \t}\n+      while (1);\n     }\n }\n \n@@ -2321,8 +2357,8 @@ rewrite_constraints (constraint_graph_t graph,\n     {\n       struct constraint_expr lhs = c->lhs;\n       struct constraint_expr rhs = c->rhs;\n-      unsigned int lhsvar = find (get_varinfo_fc (lhs.var)->id);\n-      unsigned int rhsvar = find (get_varinfo_fc (rhs.var)->id);\n+      unsigned int lhsvar = find (lhs.var);\n+      unsigned int rhsvar = find (rhs.var);\n       unsigned int lhsnode, rhsnode;\n       unsigned int lhslabel, rhslabel;\n \n@@ -2512,11 +2548,10 @@ solve_graph (constraint_graph_t graph)\n \n \t      solution_empty = bitmap_empty_p (solution);\n \n-\t      if (!solution_empty\n-\t\t  /* Do not propagate the ESCAPED solutions.  */\n-\t\t  && i != find (escaped_id))\n+\t      if (!solution_empty)\n \t\t{\n \t\t  bitmap_iterator bi;\n+\t\t  unsigned eff_escaped_id = find (escaped_id);\n \n \t\t  /* Propagate solution to all successors.  */\n \t\t  EXECUTE_IF_IN_NONNULL_BITMAP (graph->succs[i],\n@@ -2533,7 +2568,12 @@ solve_graph (constraint_graph_t graph)\n \t\t      if (to == i)\n \t\t\tcontinue;\n \n-\t\t      flag = set_union_with_increment (tmp, pts, 0);\n+\t\t      /* If we propagate from ESCAPED use ESCAPED as\n+\t\t         placeholder.  */\n+\t\t      if (i == eff_escaped_id)\n+\t\t\tflag = bitmap_set_bit (tmp, escaped_id);\n+\t\t      else\n+\t\t\tflag = set_union_with_increment (tmp, pts, 0);\n \n \t\t      if (flag)\n \t\t\t{\n@@ -2710,20 +2750,18 @@ process_constraint (constraint_t t)\n   gcc_assert (rhs.var < VEC_length (varinfo_t, varmap));\n   gcc_assert (lhs.var < VEC_length (varinfo_t, varmap));\n \n-  /* ANYTHING == ANYTHING is pointless.  */\n-  if (lhs.var == anything_id && rhs.var == anything_id)\n-    return;\n+  /* If we didn't get any useful constraint from the lhs we get\n+     &ANYTHING as fallback from get_constraint_for.  Deal with\n+     it here by turning it into *ANYTHING.  */\n+  if (lhs.type == ADDRESSOF\n+      && lhs.var == anything_id)\n+    lhs.type = DEREF;\n+\n+  /* ADDRESSOF on the lhs is invalid.  */\n+  gcc_assert (lhs.type != ADDRESSOF);\n \n-  /* If we have &ANYTHING = something, convert to SOMETHING = &ANYTHING) */\n-  else if (lhs.var == anything_id && lhs.type == ADDRESSOF)\n-    {\n-      rhs = t->lhs;\n-      t->lhs = t->rhs;\n-      t->rhs = rhs;\n-      process_constraint (t);\n-    }\n   /* This can happen in our IR with things like n->a = *p */\n-  else if (rhs.type == DEREF && lhs.type == DEREF && rhs.var != anything_id)\n+  if (rhs.type == DEREF && lhs.type == DEREF && rhs.var != anything_id)\n     {\n       /* Split into tmp = *rhs, *lhs = tmp */\n       tree rhsdecl = get_varinfo (rhs.var)->decl;\n@@ -2801,7 +2839,7 @@ get_constraint_for_ptr_offset (tree ptr, tree offset,\n {\n   struct constraint_expr *c;\n   unsigned int j, n;\n-  unsigned HOST_WIDE_INT rhsunitoffset, rhsoffset;\n+  HOST_WIDE_INT rhsunitoffset, rhsoffset;\n \n   /* If we do not do field-sensitive PTA adding offsets to pointers\n      does not change the points-to solution.  */\n@@ -2814,30 +2852,16 @@ get_constraint_for_ptr_offset (tree ptr, tree offset,\n   /* If the offset is not a non-negative integer constant that fits\n      in a HOST_WIDE_INT, we have to fall back to a conservative\n      solution which includes all sub-fields of all pointed-to\n-     variables of ptr.\n-     ???  As we do not have the ability to express this, fall back\n-     to anything.  */\n-  if (!host_integerp (offset, 1))\n-    {\n-      struct constraint_expr temp;\n-      temp.var = anything_id;\n-      temp.type = SCALAR;\n-      temp.offset = 0;\n-      VEC_safe_push (ce_s, heap, *results, &temp);\n-      return;\n-    }\n-\n-  /* Make sure the bit-offset also fits.  */\n-  rhsunitoffset = TREE_INT_CST_LOW (offset);\n-  rhsoffset = rhsunitoffset * BITS_PER_UNIT;\n-  if (rhsunitoffset != rhsoffset / BITS_PER_UNIT)\n+     variables of ptr.  */\n+  if (!host_integerp (offset, 0))\n+    rhsoffset = UNKNOWN_OFFSET;\n+  else\n     {\n-      struct constraint_expr temp;\n-      temp.var = anything_id;\n-      temp.type = SCALAR;\n-      temp.offset = 0;\n-      VEC_safe_push (ce_s, heap, *results, &temp);\n-      return;\n+      /* Make sure the bit-offset also fits.  */\n+      rhsunitoffset = TREE_INT_CST_LOW (offset);\n+      rhsoffset = rhsunitoffset * BITS_PER_UNIT;\n+      if (rhsunitoffset != rhsoffset / BITS_PER_UNIT)\n+\trhsoffset = UNKNOWN_OFFSET;\n     }\n \n   get_constraint_for (ptr, results);\n@@ -2854,36 +2878,49 @@ get_constraint_for_ptr_offset (tree ptr, tree offset,\n       curr = get_varinfo (c->var);\n \n       if (c->type == ADDRESSOF\n-\t  && !curr->is_full_var)\n+\t  /* If this varinfo represents a full variable just use it.  */\n+\t  && curr->is_full_var)\n+\tc->offset = 0;\n+      else if (c->type == ADDRESSOF\n+\t       /* If we do not know the offset add all subfields.  */\n+\t       && rhsoffset == UNKNOWN_OFFSET)\n+\t{\n+\t  varinfo_t temp = lookup_vi_for_tree (curr->decl);\n+\t  do\n+\t    {\n+\t      struct constraint_expr c2;\n+\t      c2.var = temp->id;\n+\t      c2.type = ADDRESSOF;\n+\t      c2.offset = 0;\n+\t      VEC_safe_push (ce_s, heap, *results, &c2);\n+\t      temp = temp->next;\n+\t    }\n+\t  while (temp);\n+\t}\n+      else if (c->type == ADDRESSOF)\n \t{\n-\t  varinfo_t temp, curr = get_varinfo (c->var);\n+\t  varinfo_t temp;\n+\t  unsigned HOST_WIDE_INT offset = curr->offset + rhsoffset;\n \n \t  /* Search the sub-field which overlaps with the\n-\t     pointed-to offset.  As we deal with positive offsets\n-\t     only, we can start the search from the current variable.  */\n-\t  temp = first_vi_for_offset (curr, curr->offset + rhsoffset);\n-\n-\t  /* If the result is outside of the variable we have to provide\n-\t     a conservative result, as the variable is still reachable\n-\t     from the resulting pointer (even though it technically\n-\t     cannot point to anything).  The last sub-field is such\n-\t     a conservative result.\n+\t     pointed-to offset.  If the result is outside of the variable\n+\t     we have to provide a conservative result, as the variable is\n+\t     still reachable from the resulting pointer (even though it\n+\t     technically cannot point to anything).  The last and first\n+\t     sub-fields are such conservative results.\n \t     ???  If we always had a sub-field for &object + 1 then\n \t     we could represent this in a more precise way.  */\n-\t  if (temp == NULL)\n-\t    {\n-\t      temp = curr;\n-\t      while (temp->next != NULL)\n-\t\ttemp = temp->next;\n-\t      continue;\n-\t    }\n+\t  if (rhsoffset < 0\n+\t      && curr->offset < offset)\n+\t    offset = 0;\n+\t  temp = first_or_preceding_vi_for_offset (curr, offset);\n \n \t  /* If the found variable is not exactly at the pointed to\n \t     result, we have to include the next variable in the\n \t     solution as well.  Otherwise two increments by offset / 2\n \t     do not result in the same or a conservative superset\n \t     solution.  */\n-\t  if (temp->offset != curr->offset + rhsoffset\n+\t  if (temp->offset != offset\n \t      && temp->next != NULL)\n \t    {\n \t      struct constraint_expr c2;\n@@ -2895,10 +2932,6 @@ get_constraint_for_ptr_offset (tree ptr, tree offset,\n \t  c->var = temp->id;\n \t  c->offset = 0;\n \t}\n-      else if (c->type == ADDRESSOF\n-\t       /* If this varinfo represents a full variable just use it.  */\n-\t       && curr->is_full_var)\n-\tc->offset = 0;\n       else\n \tc->offset = rhsoffset;\n     }\n@@ -2944,10 +2977,6 @@ get_constraint_for_component_ref (tree t, VEC(ce_s, heap) **results,\n   gcc_assert (VEC_length (ce_s, *results) == 1);\n   result = VEC_last (ce_s, *results);\n \n-  /* This can also happen due to weird offsetof type macros.  */\n-  if (TREE_CODE (t) != ADDR_EXPR && result->type == ADDRESSOF)\n-    result->type = SCALAR;\n-\n   if (result->type == SCALAR\n       && get_varinfo (result->var)->is_full_var)\n     /* For single-field vars do not bother about the offset.  */\n@@ -3011,15 +3040,20 @@ get_constraint_for_component_ref (tree t, VEC(ce_s, heap) **results,\n \tif (dump_file && (dump_flags & TDF_DETAILS))\n \t  fprintf (dump_file, \"Access to past the end of variable, ignoring\\n\");\n     }\n-  else if (bitmaxsize == -1)\n+  else if (result->type == DEREF)\n     {\n-      /* We can't handle DEREF constraints with unknown size, we'll\n-\t get the wrong answer.  Punt and return anything.  */\n-      result->var = anything_id;\n-      result->offset = 0;\n+      /* If we do not know exactly where the access goes say so.  Note\n+\t that only for non-structure accesses we know that we access\n+\t at most one subfiled of any variable.  */\n+      if (bitpos == -1\n+\t  || bitsize != bitmaxsize\n+\t  || AGGREGATE_TYPE_P (TREE_TYPE (orig_t)))\n+\tresult->offset = UNKNOWN_OFFSET;\n+      else\n+\tresult->offset = bitpos;\n     }\n   else\n-    result->offset = bitpos;\n+    gcc_unreachable ();\n }\n \n \n@@ -3074,8 +3108,11 @@ get_constraint_for_1 (tree t, VEC (ce_s, heap) **results, bool address_p)\n      It is not worth adding a new option or renaming the existing one,\n      since this case is relatively obscure.  */\n   if (flag_delete_null_pointer_checks\n-      && TREE_CODE (t) == INTEGER_CST\n-      && integer_zerop (t))\n+      && ((TREE_CODE (t) == INTEGER_CST\n+\t   && integer_zerop (t))\n+\t  /* The only valid CONSTRUCTORs in gimple with pointer typed\n+\t     elements are zero-initializer.  */\n+\t  || TREE_CODE (t) == CONSTRUCTOR))\n     {\n       temp.var = nothing_id;\n       temp.type = ADDRESSOF;\n@@ -3137,6 +3174,10 @@ get_constraint_for_1 (tree t, VEC (ce_s, heap) **results, bool address_p)\n \t  case COMPONENT_REF:\n \t    get_constraint_for_component_ref (t, results, address_p);\n \t    return;\n+\t  case VIEW_CONVERT_EXPR:\n+\t    get_constraint_for_1 (TREE_OPERAND (t, 0), results, address_p);\n+\t    return;\n+\t  /* We are missing handling for TARGET_MEM_REF here.  */\n \t  default:;\n \t  }\n \tbreak;\n@@ -3179,277 +3220,73 @@ get_constraint_for (tree t, VEC (ce_s, heap) **results)\n   get_constraint_for_1 (t, results, false);\n }\n \n-/* Handle the structure copy case where we have a simple structure copy\n-   between LHS and RHS that is of SIZE (in bits)\n-\n-   For each field of the lhs variable (lhsfield)\n-     For each field of the rhs variable at lhsfield.offset (rhsfield)\n-       add the constraint lhsfield = rhsfield\n-\n-   If we fail due to some kind of type unsafety or other thing we\n-   can't handle, return false.  We expect the caller to collapse the\n-   variable in that case.  */\n-\n-static bool\n-do_simple_structure_copy (const struct constraint_expr lhs,\n-\t\t\t  const struct constraint_expr rhs,\n-\t\t\t  const unsigned HOST_WIDE_INT size)\n-{\n-  varinfo_t p = get_varinfo (lhs.var);\n-  unsigned HOST_WIDE_INT pstart, last;\n-  pstart = p->offset;\n-  last = p->offset + size;\n-  for (; p && p->offset < last; p = p->next)\n-    {\n-      varinfo_t q;\n-      struct constraint_expr templhs = lhs;\n-      struct constraint_expr temprhs = rhs;\n-      unsigned HOST_WIDE_INT fieldoffset;\n-\n-      templhs.var = p->id;\n-      q = get_varinfo (temprhs.var);\n-      fieldoffset = p->offset - pstart;\n-      q = first_vi_for_offset (q, q->offset + fieldoffset);\n-      if (!q)\n-\treturn false;\n-      temprhs.var = q->id;\n-      process_constraint (new_constraint (templhs, temprhs));\n-    }\n-  return true;\n-}\n-\n-\n-/* Handle the structure copy case where we have a  structure copy between a\n-   aggregate on the LHS and a dereference of a pointer on the RHS\n-   that is of SIZE (in bits)\n-\n-   For each field of the lhs variable (lhsfield)\n-       rhs.offset = lhsfield->offset\n-       add the constraint lhsfield = rhs\n-*/\n-\n-static void\n-do_rhs_deref_structure_copy (const struct constraint_expr lhs,\n-\t\t\t     const struct constraint_expr rhs,\n-\t\t\t     const unsigned HOST_WIDE_INT size)\n-{\n-  varinfo_t p = get_varinfo (lhs.var);\n-  unsigned HOST_WIDE_INT pstart,last;\n-  pstart = p->offset;\n-  last = p->offset + size;\n-\n-  for (; p && p->offset < last; p = p->next)\n-    {\n-      varinfo_t q;\n-      struct constraint_expr templhs = lhs;\n-      struct constraint_expr temprhs = rhs;\n-      unsigned HOST_WIDE_INT fieldoffset;\n-\n-\n-      if (templhs.type == SCALAR)\n-\ttemplhs.var = p->id;\n-      else\n-\ttemplhs.offset = p->offset;\n-\n-      q = get_varinfo (temprhs.var);\n-      fieldoffset = p->offset - pstart;\n-      temprhs.offset += fieldoffset;\n-      process_constraint (new_constraint (templhs, temprhs));\n-    }\n-}\n-\n-/* Handle the structure copy case where we have a structure copy\n-   between an aggregate on the RHS and a dereference of a pointer on\n-   the LHS that is of SIZE (in bits)\n-\n-   For each field of the rhs variable (rhsfield)\n-       lhs.offset = rhsfield->offset\n-       add the constraint lhs = rhsfield\n-*/\n-\n-static void\n-do_lhs_deref_structure_copy (const struct constraint_expr lhs,\n-\t\t\t     const struct constraint_expr rhs,\n-\t\t\t     const unsigned HOST_WIDE_INT size)\n-{\n-  varinfo_t p = get_varinfo (rhs.var);\n-  unsigned HOST_WIDE_INT pstart,last;\n-  pstart = p->offset;\n-  last = p->offset + size;\n-\n-  for (; p && p->offset < last; p = p->next)\n-    {\n-      varinfo_t q;\n-      struct constraint_expr templhs = lhs;\n-      struct constraint_expr temprhs = rhs;\n-      unsigned HOST_WIDE_INT fieldoffset;\n-\n-\n-      if (temprhs.type == SCALAR)\n-\ttemprhs.var = p->id;\n-      else\n-\ttemprhs.offset = p->offset;\n-\n-      q = get_varinfo (templhs.var);\n-      fieldoffset = p->offset - pstart;\n-      templhs.offset += fieldoffset;\n-      process_constraint (new_constraint (templhs, temprhs));\n-    }\n-}\n-\n-/* Sometimes, frontends like to give us bad type information.  This\n-   function will collapse all the fields from VAR to the end of VAR,\n-   into VAR, so that we treat those fields as a single variable.\n-   We return the variable they were collapsed into.  */\n-\n-static unsigned int\n-collapse_rest_of_var (unsigned int var)\n-{\n-  varinfo_t currvar = get_varinfo (var);\n-  varinfo_t field;\n-\n-  for (field = currvar->next; field; field = field->next)\n-    {\n-      if (dump_file)\n-\tfprintf (dump_file, \"Type safety: Collapsing var %s into %s\\n\",\n-\t\t field->name, currvar->name);\n-\n-      gcc_assert (field->collapsed_to == 0);\n-      field->collapsed_to = currvar->id;\n-    }\n-\n-  currvar->next = NULL;\n-  currvar->size = currvar->fullsize - currvar->offset;\n-\n-  return currvar->id;\n-}\n-\n /* Handle aggregate copies by expanding into copies of the respective\n    fields of the structures.  */\n \n static void\n do_structure_copy (tree lhsop, tree rhsop)\n {\n-  struct constraint_expr lhs, rhs, tmp;\n+  struct constraint_expr *lhsp, *rhsp;\n   VEC (ce_s, heap) *lhsc = NULL, *rhsc = NULL;\n-  varinfo_t p;\n-  unsigned HOST_WIDE_INT lhssize;\n-  unsigned HOST_WIDE_INT rhssize;\n-\n-  /* Pretend we are taking the address of the constraint exprs.\n-     We deal with walking the sub-fields ourselves.  */\n-  get_constraint_for_1 (lhsop, &lhsc, true);\n-  get_constraint_for_1 (rhsop, &rhsc, true);\n-  gcc_assert (VEC_length (ce_s, lhsc) == 1);\n-  gcc_assert (VEC_length (ce_s, rhsc) == 1);\n-  lhs = *(VEC_last (ce_s, lhsc));\n-  rhs = *(VEC_last (ce_s, rhsc));\n-\n-  VEC_free (ce_s, heap, lhsc);\n-  VEC_free (ce_s, heap, rhsc);\n-\n-  /* If we have special var = x, swap it around.  */\n-  if (lhs.var <= integer_id && !(get_varinfo (rhs.var)->is_special_var))\n-    {\n-      tmp = lhs;\n-      lhs = rhs;\n-      rhs = tmp;\n-    }\n-\n-  /*  This is fairly conservative for the RHS == ADDRESSOF case, in that it's\n-      possible it's something we could handle.  However, most cases falling\n-      into this are dealing with transparent unions, which are slightly\n-      weird. */\n-  if (rhs.type == ADDRESSOF && !(get_varinfo (rhs.var)->is_special_var))\n+  unsigned j;\n+\n+  get_constraint_for (lhsop, &lhsc);\n+  get_constraint_for (rhsop, &rhsc);\n+  lhsp = VEC_index (ce_s, lhsc, 0);\n+  rhsp = VEC_index (ce_s, rhsc, 0);\n+  if (lhsp->type == DEREF\n+      || (lhsp->type == ADDRESSOF && lhsp->var == anything_id)\n+      || rhsp->type == DEREF)\n     {\n-      rhs.type = ADDRESSOF;\n-      rhs.var = anything_id;\n+      struct constraint_expr tmp;\n+      tree tmpvar = create_tmp_var_raw (ptr_type_node,\n+\t\t\t\t\t\"structcopydereftmp\");\n+      tmp.var = get_vi_for_tree (tmpvar)->id;\n+      tmp.type = SCALAR;\n+      tmp.offset = 0;\n+      for (j = 0; VEC_iterate (ce_s, rhsc, j, rhsp); ++j)\n+\tprocess_constraint (new_constraint (tmp, *rhsp));\n+      for (j = 0; VEC_iterate (ce_s, lhsc, j, lhsp); ++j)\n+\tprocess_constraint (new_constraint (*lhsp, tmp));\n     }\n-\n-  /* If the RHS is a special var, or an addressof, set all the LHS fields to\n-     that special var.  */\n-  if (rhs.var <= integer_id)\n+  else if (lhsp->type == SCALAR\n+\t   && (rhsp->type == SCALAR\n+\t       || rhsp->type == ADDRESSOF))\n     {\n-      for (p = get_varinfo (lhs.var); p; p = p->next)\n+      tree lhsbase, rhsbase;\n+      HOST_WIDE_INT lhssize, lhsmaxsize, lhsoffset;\n+      HOST_WIDE_INT rhssize, rhsmaxsize, rhsoffset;\n+      unsigned k = 0;\n+      lhsbase = get_ref_base_and_extent (lhsop, &lhsoffset,\n+\t\t\t\t\t &lhssize, &lhsmaxsize);\n+      rhsbase = get_ref_base_and_extent (rhsop, &rhsoffset,\n+\t\t\t\t\t &rhssize, &rhsmaxsize);\n+      for (j = 0; VEC_iterate (ce_s, lhsc, j, lhsp);)\n \t{\n-\t  struct constraint_expr templhs = lhs;\n-\t  struct constraint_expr temprhs = rhs;\n-\n-\t  if (templhs.type == SCALAR )\n-\t    templhs.var = p->id;\n+\t  varinfo_t lhsv, rhsv;\n+\t  rhsp = VEC_index (ce_s, rhsc, k);\n+\t  lhsv = get_varinfo (lhsp->var);\n+\t  rhsv = get_varinfo (rhsp->var);\n+\t  if (lhsv->may_have_pointers\n+\t      && ranges_overlap_p (lhsv->offset + rhsoffset, lhsv->size,\n+\t\t\t\t   rhsv->offset + lhsoffset, rhsv->size))\n+\t    process_constraint (new_constraint (*lhsp, *rhsp));\n+\t  if (lhsv->offset + rhsoffset + lhsv->size\n+\t      > rhsv->offset + lhsoffset + rhsv->size)\n+\t    {\n+\t      ++k;\n+\t      if (k >= VEC_length (ce_s, rhsc))\n+\t\tbreak;\n+\t    }\n \t  else\n-\t    templhs.offset += p->offset;\n-\t  process_constraint (new_constraint (templhs, temprhs));\n+\t    ++j;\n \t}\n     }\n   else\n-    {\n-      tree rhstype = TREE_TYPE (rhsop);\n-      tree lhstype = TREE_TYPE (lhsop);\n-      tree rhstypesize;\n-      tree lhstypesize;\n-\n-      lhstypesize = DECL_P (lhsop) ? DECL_SIZE (lhsop) : TYPE_SIZE (lhstype);\n-      rhstypesize = DECL_P (rhsop) ? DECL_SIZE (rhsop) : TYPE_SIZE (rhstype);\n-\n-      /* If we have a variably sized types on the rhs or lhs, and a deref\n-\t constraint, add the constraint, lhsconstraint = &ANYTHING.\n-\t This is conservatively correct because either the lhs is an unknown\n-\t sized var (if the constraint is SCALAR), or the lhs is a DEREF\n-\t constraint, and every variable it can point to must be unknown sized\n-\t anyway, so we don't need to worry about fields at all.  */\n-      if ((rhs.type == DEREF && TREE_CODE (rhstypesize) != INTEGER_CST)\n-\t  || (lhs.type == DEREF && TREE_CODE (lhstypesize) != INTEGER_CST))\n-\t{\n-\t  rhs.var = anything_id;\n-\t  rhs.type = ADDRESSOF;\n-\t  rhs.offset = 0;\n-\t  process_constraint (new_constraint (lhs, rhs));\n-\t  return;\n-\t}\n-\n-      /* The size only really matters insofar as we don't set more or less of\n-\t the variable.  If we hit an unknown size var, the size should be the\n-\t whole darn thing.  */\n-      if (get_varinfo (rhs.var)->is_unknown_size_var)\n-\trhssize = ~0;\n-      else\n-\trhssize = TREE_INT_CST_LOW (rhstypesize);\n-\n-      if (get_varinfo (lhs.var)->is_unknown_size_var)\n-\tlhssize = ~0;\n-      else\n-\tlhssize = TREE_INT_CST_LOW (lhstypesize);\n-\n-\n-      if (rhs.type == SCALAR && lhs.type == SCALAR)\n-\t{\n-\t  if (!do_simple_structure_copy (lhs, rhs, MIN (lhssize, rhssize)))\n-\t    {\n-\t      lhs.var = collapse_rest_of_var (get_varinfo_fc (lhs.var)->id);\n-\t      rhs.var = collapse_rest_of_var (get_varinfo_fc (rhs.var)->id);\n-\t      lhs.offset = 0;\n-\t      rhs.offset = 0;\n-\t      lhs.type = SCALAR;\n-\t      rhs.type = SCALAR;\n-\t      process_constraint (new_constraint (lhs, rhs));\n-\t    }\n-\t}\n-      else if (lhs.type != DEREF && rhs.type == DEREF)\n-\tdo_rhs_deref_structure_copy (lhs, rhs, MIN (lhssize, rhssize));\n-      else if (lhs.type == DEREF && rhs.type != DEREF)\n-\tdo_lhs_deref_structure_copy (lhs, rhs, MIN (lhssize, rhssize));\n-      else\n-\t{\n-\t  tree pointedtotype = lhstype;\n-\t  tree tmpvar;\n+    gcc_unreachable ();\n \n-\t  gcc_assert (rhs.type == DEREF && lhs.type == DEREF);\n-\t  tmpvar = create_tmp_var_raw (pointedtotype, \"structcopydereftmp\");\n-\t  do_structure_copy (tmpvar, rhsop);\n-\t  do_structure_copy (lhsop, tmpvar);\n-\t}\n-    }\n+  VEC_free (ce_s, heap, lhsc);\n+  VEC_free (ce_s, heap, rhsc);\n }\n \n /* Create a constraint ID = OP.  */\n@@ -3503,10 +3340,10 @@ handle_rhs_call (gimple stmt, VEC(ce_s, heap) **results)\n   if (gimple_call_chain (stmt))\n     make_escape_constraint (gimple_call_chain (stmt));\n \n-  /* Regular functions return escaped addresses.  */\n-  rhsc.var = escaped_id;\n+  /* Regular functions return nonlocal memory.  */\n+  rhsc.var = nonlocal_id;\n   rhsc.offset = 0;\n-  rhsc.type = ADDRESSOF;\n+  rhsc.type = SCALAR;\n   VEC_safe_push (ce_s, heap, *results, &rhsc);\n }\n \n@@ -3663,17 +3500,17 @@ handle_pure_call (gimple stmt, VEC(ce_s, heap) **results)\n       need_callused = true;\n     }\n \n-  /* Pure functions may return callused and escaped memory.  */\n+  /* Pure functions may return callused and nonlocal memory.  */\n   if (need_callused)\n     {\n       rhsc.var = callused_id;\n       rhsc.offset = 0;\n       rhsc.type = SCALAR;\n       VEC_safe_push (ce_s, heap, *results, &rhsc);\n     }\n-  rhsc.var = escaped_id;\n+  rhsc.var = nonlocal_id;\n   rhsc.offset = 0;\n-  rhsc.type = ADDRESSOF;\n+  rhsc.type = SCALAR;\n   VEC_safe_push (ce_s, heap, *results, &rhsc);\n }\n \n@@ -3922,58 +3759,128 @@ find_func_aliases (gimple origt)\n     }\n   else if (stmt_escape_type == ESCAPE_TO_ASM)\n     {\n-      unsigned i;\n-      for (i = 0; i < gimple_asm_noutputs (t); ++i)\n+      unsigned i, noutputs;\n+      const char **oconstraints;\n+      const char *constraint;\n+      bool allows_mem, allows_reg, is_inout;\n+\n+      noutputs = gimple_asm_noutputs (t);\n+      oconstraints = XALLOCAVEC (const char *, noutputs);\n+\n+      for (i = 0; i < noutputs; ++i)\n \t{\n-\t  tree op = TREE_VALUE (gimple_asm_output_op (t, i));\n+\t  tree link = gimple_asm_output_op (t, i);\n+\t  tree op = TREE_VALUE (link);\n+\n+\t  constraint = TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+\t  oconstraints[i] = constraint;\n+\t  parse_output_constraint (&constraint, i, 0, 0, &allows_mem,\n+\t\t\t\t   &allows_reg, &is_inout);\n+\n+\t  /* A memory constraint makes the address of the operand escape.  */\n+\t  if (!allows_reg && allows_mem)\n+\t    make_escape_constraint (build_fold_addr_expr (op));\n+\n+\t  /* The asm may read global memory, so outputs may point to\n+\t     any global memory.  */\n \t  if (op && could_have_pointers (op))\n-\t    /* Strictly we'd only need the constraints from ESCAPED and\n-\t       NONLOCAL.  */\n-\t    make_escape_constraint (op);\n+\t    {\n+\t      VEC(ce_s, heap) *lhsc = NULL;\n+\t      struct constraint_expr rhsc, *lhsp;\n+\t      unsigned j;\n+\t      get_constraint_for (op, &lhsc);\n+\t      rhsc.var = nonlocal_id;\n+\t      rhsc.offset = 0;\n+\t      rhsc.type = SCALAR;\n+\t      for (j = 0; VEC_iterate (ce_s, lhsc, j, lhsp); j++)\n+\t\tprocess_constraint (new_constraint (*lhsp, rhsc));\n+\t      VEC_free (ce_s, heap, lhsc);\n+\t    }\n \t}\n       for (i = 0; i < gimple_asm_ninputs (t); ++i)\n \t{\n-\t  tree op = TREE_VALUE (gimple_asm_input_op (t, i));\n-\t  if (op && could_have_pointers (op))\n-\t    /* Strictly we'd only need the constraint to ESCAPED.  */\n+\t  tree link = gimple_asm_input_op (t, i);\n+\t  tree op = TREE_VALUE (link);\n+\n+\t  constraint = TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+\n+\t  parse_input_constraint (&constraint, 0, 0, noutputs, 0, oconstraints,\n+\t\t\t\t  &allows_mem, &allows_reg);\n+\n+\t  /* A memory constraint makes the address of the operand escape.  */\n+\t  if (!allows_reg && allows_mem)\n+\t    make_escape_constraint (build_fold_addr_expr (op));\n+\t  /* Strictly we'd only need the constraint to ESCAPED if\n+\t     the asm clobbers memory, otherwise using CALLUSED\n+\t     would be enough.  */\n+\t  else if (op && could_have_pointers (op))\n \t    make_escape_constraint (op);\n \t}\n     }\n \n-  /* After promoting variables and computing aliasing we will\n-     need to re-scan most statements.  FIXME: Try to minimize the\n-     number of statements re-scanned.  It's not really necessary to\n-     re-scan *all* statements.  */\n-  if (!in_ipa_mode)\n-    gimple_set_modified (origt, true);\n   VEC_free (ce_s, heap, rhsc);\n   VEC_free (ce_s, heap, lhsc);\n }\n \n \n /* Find the first varinfo in the same variable as START that overlaps with\n-   OFFSET.\n-   Effectively, walk the chain of fields for the variable START to find the\n-   first field that overlaps with OFFSET.\n-   Return NULL if we can't find one.  */\n+   OFFSET.  Return NULL if we can't find one.  */\n \n static varinfo_t\n first_vi_for_offset (varinfo_t start, unsigned HOST_WIDE_INT offset)\n {\n-  varinfo_t curr = start;\n-  while (curr)\n+  /* If the offset is outside of the variable, bail out.  */\n+  if (offset >= start->fullsize)\n+    return NULL;\n+\n+  /* If we cannot reach offset from start, lookup the first field\n+     and start from there.  */\n+  if (start->offset > offset)\n+    start = lookup_vi_for_tree (start->decl);\n+\n+  while (start)\n     {\n       /* We may not find a variable in the field list with the actual\n \t offset when when we have glommed a structure to a variable.\n \t In that case, however, offset should still be within the size\n \t of the variable. */\n-      if (offset >= curr->offset && offset < (curr->offset +  curr->size))\n-\treturn curr;\n-      curr = curr->next;\n+      if (offset >= start->offset\n+\t  && offset < (start->offset + start->size))\n+\treturn start;\n+\n+      start= start->next;\n     }\n+\n   return NULL;\n }\n \n+/* Find the first varinfo in the same variable as START that overlaps with\n+   OFFSET.  If there is no such varinfo the varinfo directly preceding\n+   OFFSET is returned.  */\n+\n+static varinfo_t\n+first_or_preceding_vi_for_offset (varinfo_t start,\n+\t\t\t\t  unsigned HOST_WIDE_INT offset)\n+{\n+  /* If we cannot reach offset from start, lookup the first field\n+     and start from there.  */\n+  if (start->offset > offset)\n+    start = lookup_vi_for_tree (start->decl);\n+\n+  /* We may not find a variable in the field list with the actual\n+     offset when when we have glommed a structure to a variable.\n+     In that case, however, offset should still be within the size\n+     of the variable.\n+     If we got beyond the offset we look for return the field\n+     directly preceding offset which may be the last field.  */\n+  while (start->next\n+\t && offset >= start->offset\n+\t && !(offset < (start->offset + start->size)))\n+    start = start->next;\n+\n+  return start;\n+}\n+\n \n /* Insert the varinfo FIELD into the field list for BASE, at the front\n    of the list.  */\n@@ -4083,7 +3990,7 @@ var_can_have_subvars (const_tree v)\n     return false;\n \n   /* Non decls or memory tags can never have subvars.  */\n-  if (!DECL_P (v) || MTAG_P (v))\n+  if (!DECL_P (v))\n     return false;\n \n   /* Aggregates without overlapping fields can have subvars.  */\n@@ -4197,18 +4104,35 @@ make_constraint_from (varinfo_t vi, int from)\n   process_constraint (new_constraint (lhs, rhs));\n }\n \n-/* Count the number of arguments DECL has, and set IS_VARARGS to true\n-   if it is a varargs function.  */\n+/* Create a constraint ID = FROM.  */\n \n-static unsigned int\n-count_num_arguments (tree decl, bool *is_varargs)\n+static void\n+make_copy_constraint (varinfo_t vi, int from)\n {\n-  unsigned int i = 0;\n-  tree t;\n+  struct constraint_expr lhs, rhs;\n \n-  for (t = TYPE_ARG_TYPES (TREE_TYPE (decl));\n-       t;\n-       t = TREE_CHAIN (t))\n+  lhs.var = vi->id;\n+  lhs.offset = 0;\n+  lhs.type = SCALAR;\n+\n+  rhs.var = from;\n+  rhs.offset = 0;\n+  rhs.type = SCALAR;\n+  process_constraint (new_constraint (lhs, rhs));\n+}\n+\n+/* Count the number of arguments DECL has, and set IS_VARARGS to true\n+   if it is a varargs function.  */\n+\n+static unsigned int\n+count_num_arguments (tree decl, bool *is_varargs)\n+{\n+  unsigned int i = 0;\n+  tree t;\n+\n+  for (t = TYPE_ARG_TYPES (TREE_TYPE (decl));\n+       t;\n+       t = TREE_CHAIN (t))\n     {\n       if (TREE_VALUE (t) == void_type_node)\n \tbreak;\n@@ -4398,7 +4322,7 @@ create_variable_info_for (tree decl, const char *name)\n \t  && var_ann (decl)->noalias_state == NO_ALIAS_ANYTHING)\n \tmake_constraint_from (vi, vi->id);\n       else\n-\tmake_constraint_from (vi, escaped_id);\n+\tmake_copy_constraint (vi, nonlocal_id);\n     }\n \n   stats.total_vars++;\n@@ -4480,7 +4404,7 @@ create_variable_info_for (tree decl, const char *name)\n \t  VEC_safe_push (varinfo_t, heap, varmap, newvi);\n \t  if (is_global && (!flag_whole_program || !in_ipa_mode)\n \t      && newvi->may_have_pointers)\n-\t    make_constraint_from (newvi, escaped_id);\n+\t    make_copy_constraint (newvi, nonlocal_id);\n \n \t  stats.total_vars++;\n \t}\n@@ -4495,7 +4419,7 @@ create_variable_info_for (tree decl, const char *name)\n \n /* Print out the points-to solution for VAR to FILE.  */\n \n-void\n+static void\n dump_solution_for_var (FILE *file, unsigned int var)\n {\n   varinfo_t vi = get_varinfo (var);\n@@ -4615,7 +4539,7 @@ intra_create_variable_infos (void)\n       varinfo_t p, result_vi = get_vi_for_tree (DECL_RESULT (cfun->decl));\n \n       for (p = result_vi; p; p = p->next)\n-        make_constraint_from (p, nonlocal_id);\n+\tmake_constraint_from (p, nonlocal_id);\n     }\n \n   /* Add a constraint for the incoming static chain parameter.  */\n@@ -4698,25 +4622,20 @@ shared_bitmap_add (bitmap pt_vars)\n }\n \n \n-/* Set bits in INTO corresponding to the variable uids in solution set\n-   FROM, which came from variable PTR.\n-   For variables that are actually dereferenced, we also use type\n-   based alias analysis to prune the points-to sets.\n-   IS_DEREFED is true if PTR was directly dereferenced, which we use to\n-   help determine whether we are we are allowed to prune using TBAA.\n-   If NO_TBAA_PRUNING is true, we do not perform any TBAA pruning of\n-   the from set.  Returns the number of pruned variables.  */\n+/* Set bits in INTO corresponding to the variable uids in solution set FROM.\n+   If MEM_ALIAS_SET is not zero, we also use type based alias analysis to\n+   prune the points-to sets with this alias-set.\n+   Returns the number of pruned variables and updates the vars_contains_global\n+   member of *PT .  */\n \n static unsigned\n-set_uids_in_ptset (tree ptr, bitmap into, bitmap from, bool is_derefed,\n-\t\t   bool no_tbaa_pruning)\n+set_uids_in_ptset (bitmap into, bitmap from,\n+\t\t   alias_set_type mem_alias_set, struct pt_solution *pt)\n {\n   unsigned int i;\n   bitmap_iterator bi;\n   unsigned pruned = 0;\n \n-  gcc_assert (POINTER_TYPE_P (TREE_TYPE (ptr)));\n-\n   EXECUTE_IF_SET_IN_BITMAP (from, 0, i, bi)\n     {\n       varinfo_t vi = get_varinfo (i);\n@@ -4730,26 +4649,27 @@ set_uids_in_ptset (tree ptr, bitmap into, bitmap from, bool is_derefed,\n \t  || TREE_CODE (vi->decl) == PARM_DECL\n \t  || TREE_CODE (vi->decl) == RESULT_DECL)\n \t{\n-\t  /* Just add VI->DECL to the alias set.\n-\t     Don't type prune artificial vars or points-to sets\n+\t  /* Don't type prune artificial vars or points-to sets\n \t     for pointers that have not been dereferenced or with\n \t     type-based pruning disabled.  */\n-\t  if (vi->is_artificial_var\n-\t      || !is_derefed\n-\t      || no_tbaa_pruning\n-\t      || vi->no_tbaa_pruning)\n-\t    bitmap_set_bit (into, DECL_UID (vi->decl));\n-\t  else\n+\t  if (!vi->is_artificial_var\n+\t      && !vi->no_tbaa_pruning\n+\t      && mem_alias_set != 0)\n \t    {\n-\t      alias_set_type var_alias_set, mem_alias_set;\n-\t      var_alias_set = get_alias_set (vi->decl);\n-\t      mem_alias_set = get_alias_set (TREE_TYPE (TREE_TYPE (ptr)));\n-\t      if (may_alias_p (SSA_NAME_VAR (ptr), mem_alias_set,\n-\t\t\t       vi->decl, var_alias_set, true))\n-\t        bitmap_set_bit (into, DECL_UID (vi->decl));\n-\t      else\n-\t\t++pruned;\n+\t      alias_set_type var_alias_set = get_alias_set (vi->decl);\n+\t      if (mem_alias_set != var_alias_set\n+\t\t  && !alias_set_subset_of (mem_alias_set, var_alias_set))\n+\t\t{\n+\t\t  ++pruned;\n+\t\t  continue;\n+\t\t}\n \t    }\n+\n+\t  /* Add the decl to the points-to set.  Note that the points-to\n+\t     set contains global variables.  */\n+\t  bitmap_set_bit (into, DECL_UID (vi->decl));\n+\t  if (is_global_var (vi->decl))\n+\t    pt->vars_contains_global = true;\n \t}\n     }\n \n@@ -4844,26 +4764,101 @@ emit_alias_warning (tree ptr)\n     }\n }\n \n-/* Given a pointer variable P, fill in its points-to set, or return\n-   false if we can't.\n-   Rather than return false for variables that point-to anything, we\n-   instead find the corresponding SMT, and merge in its aliases.  In\n-   addition to these aliases, we also set the bits for the SMT's\n-   themselves and their subsets, as SMT's are still in use by\n-   non-SSA_NAME's, and pruning may eliminate every one of their\n-   aliases.  In such a case, if we did not include the right set of\n-   SMT's in the points-to set of the variable, we'd end up with\n-   statements that do not conflict but should.  */\n+/* Compute the points-to solution *PT for the variable VI.\n+   Prunes the points-to set based on TBAA rules if DO_TBAA_PRUNING\n+   is true.  Returns the number of TBAA pruned variables from the\n+   points-to set.  */\n \n-bool\n-find_what_p_points_to (tree p)\n+static unsigned int\n+find_what_var_points_to (varinfo_t vi, struct pt_solution *pt,\n+\t\t\t bool do_tbaa_pruning)\n {\n+  unsigned int i, pruned;\n+  bitmap_iterator bi;\n+  bitmap finished_solution;\n+  bitmap result;\n+  tree ptr = vi->decl;\n+  alias_set_type mem_alias_set;\n+\n+  memset (pt, 0, sizeof (struct pt_solution));\n+\n+  /* This variable may have been collapsed, let's get the real\n+     variable.  */\n+  vi = get_varinfo (find (vi->id));\n+\n+  /* Translate artificial variables into SSA_NAME_PTR_INFO\n+     attributes.  */\n+  EXECUTE_IF_SET_IN_BITMAP (vi->solution, 0, i, bi)\n+    {\n+      varinfo_t vi = get_varinfo (i);\n+\n+      if (vi->is_artificial_var)\n+\t{\n+\t  if (vi->id == nothing_id)\n+\t    pt->null = 1;\n+\t  else if (vi->id == escaped_id)\n+\t    pt->escaped = 1;\n+\t  else if (vi->id == callused_id)\n+\t    gcc_unreachable ();\n+\t  else if (vi->id == nonlocal_id)\n+\t    pt->nonlocal = 1;\n+\t  else if (vi->is_heap_var)\n+\t    /* We represent heapvars in the points-to set properly.  */\n+\t    ;\n+\t  else if (vi->id == anything_id\n+\t\t   || vi->id == readonly_id\n+\t\t   || vi->id == integer_id)\n+\t    pt->anything = 1;\n+\t}\n+    }\n+\n+  /* Instead of doing extra work, simply do not create\n+     elaborate points-to information for pt_anything pointers.  */\n+  if (pt->anything)\n+    return 0;\n+\n+  /* Share the final set of variables when possible.  */\n+  finished_solution = BITMAP_GGC_ALLOC ();\n+  stats.points_to_sets_created++;\n+\n+  if (TREE_CODE (ptr) == SSA_NAME)\n+    ptr = SSA_NAME_VAR (ptr);\n+\n+  /* If the pointer decl is marked that no TBAA is to be applied,\n+     do not do tbaa pruning.  */\n+  if (!do_tbaa_pruning\n+      || DECL_NO_TBAA_P (ptr))\n+    mem_alias_set = 0;\n+  else\n+    mem_alias_set = get_deref_alias_set (ptr);\n+  pruned = set_uids_in_ptset (finished_solution, vi->solution,\n+\t\t\t      mem_alias_set, pt);\n+  result = shared_bitmap_lookup (finished_solution);\n+  if (!result)\n+    {\n+      shared_bitmap_add (finished_solution);\n+      pt->vars = finished_solution;\n+    }\n+  else\n+    {\n+      pt->vars = result;\n+      bitmap_clear (finished_solution);\n+    }\n+\n+  return pruned;\n+}\n+\n+/* Given a pointer variable P, fill in its points-to set.  Apply\n+   type-based pruning if IS_DEREFERENCED is true.  */\n+\n+static void\n+find_what_p_points_to (tree p, bool is_dereferenced)\n+{\n+  struct ptr_info_def *pi;\n+  unsigned int pruned;\n   tree lookup_p = p;\n   varinfo_t vi;\n \n-  if (!have_alias_info)\n-    return false;\n-\n   /* For parameters, get at the points-to set for the actual parm\n      decl.  */\n   if (TREE_CODE (p) == SSA_NAME\n@@ -4872,225 +4867,198 @@ find_what_p_points_to (tree p)\n     lookup_p = SSA_NAME_VAR (p);\n \n   vi = lookup_vi_for_tree (lookup_p);\n-  if (vi)\n-    {\n-      if (vi->is_artificial_var)\n-\treturn false;\n+  if (!vi)\n+    return;\n+\n+  pi = get_ptr_info (p);\n+  pruned = find_what_var_points_to (vi, &pi->pt, is_dereferenced);\n \n-      /* See if this is a field or a structure.  */\n-      if (vi->size != vi->fullsize)\n+  if (!(pi->pt.anything || pi->pt.nonlocal || pi->pt.escaped)\n+      && bitmap_empty_p (pi->pt.vars)\n+      && pruned > 0\n+      && is_dereferenced\n+      && warn_strict_aliasing > 0\n+      && !SSA_NAME_IS_DEFAULT_DEF (p))\n+    {\n+      if (dump_file && dump_flags & TDF_DETAILS)\n \t{\n-\t  /* Nothing currently asks about structure fields directly,\n-\t     but when they do, we need code here to hand back the\n-\t     points-to set.  */\n-\t  return false;\n+\t  fprintf (dump_file, \"alias warning for \");\n+\t  print_generic_expr (dump_file, p, 0);\n+\t  fprintf (dump_file, \"\\n\");\n \t}\n-      else\n-\t{\n-\t  struct ptr_info_def *pi = get_ptr_info (p);\n-\t  unsigned int i, pruned;\n-\t  bitmap_iterator bi;\n-\t  bool was_pt_anything = false;\n-\t  bitmap finished_solution;\n-\t  bitmap result;\n+      emit_alias_warning (p);\n+    }\n+}\n \n-\t  if (!pi->memory_tag_needed)\n-\t    return false;\n \n-\t  /* This variable may have been collapsed, let's get the real\n-\t     variable.  */\n-\t  vi = get_varinfo (find (vi->id));\n+/* Query statistics for points-to solutions.  */\n \n-\t  /* Translate artificial variables into SSA_NAME_PTR_INFO\n-\t     attributes.  */\n-\t  EXECUTE_IF_SET_IN_BITMAP (vi->solution, 0, i, bi)\n-\t    {\n-\t      varinfo_t vi = get_varinfo (i);\n+static struct {\n+  unsigned HOST_WIDE_INT pt_solution_includes_may_alias;\n+  unsigned HOST_WIDE_INT pt_solution_includes_no_alias;\n+  unsigned HOST_WIDE_INT pt_solutions_intersect_may_alias;\n+  unsigned HOST_WIDE_INT pt_solutions_intersect_no_alias;\n+} pta_stats;\n \n-\t      if (vi->is_artificial_var)\n-\t\t{\n-\t\t  /* FIXME.  READONLY should be handled better so that\n-\t\t     flow insensitive aliasing can disregard writable\n-\t\t     aliases.  */\n-\t\t  if (vi->id == nothing_id)\n-\t\t    pi->pt_null = 1;\n-\t\t  else if (vi->id == anything_id\n-\t\t\t   || vi->id == nonlocal_id\n-\t\t\t   || vi->id == escaped_id)\n-\t\t    was_pt_anything = 1;\n-\t\t  else if (vi->id == callused_id)\n-\t\t    gcc_unreachable ();\n-\t\t  else if (vi->id == readonly_id)\n-\t\t    was_pt_anything = 1;\n-\t\t  else if (vi->id == integer_id)\n-\t\t    was_pt_anything = 1;\n-\t\t  else if (vi->is_heap_var)\n-\t\t    pi->pt_global_mem = 1;\n-\t\t}\n-\t    }\n+void\n+dump_pta_stats (FILE *s)\n+{\n+  fprintf (s, \"\\nPTA query stats:\\n\");\n+  fprintf (s, \"  pt_solution_includes: \"\n+\t   HOST_WIDE_INT_PRINT_DEC\" disambiguations, \"\n+\t   HOST_WIDE_INT_PRINT_DEC\" queries\\n\",\n+\t   pta_stats.pt_solution_includes_no_alias,\n+\t   pta_stats.pt_solution_includes_no_alias\n+\t   + pta_stats.pt_solution_includes_may_alias);\n+  fprintf (s, \"  pt_solutions_intersect: \"\n+\t   HOST_WIDE_INT_PRINT_DEC\" disambiguations, \"\n+\t   HOST_WIDE_INT_PRINT_DEC\" queries\\n\",\n+\t   pta_stats.pt_solutions_intersect_no_alias,\n+\t   pta_stats.pt_solutions_intersect_no_alias\n+\t   + pta_stats.pt_solutions_intersect_may_alias);\n+}\n \n-\t  /* Instead of doing extra work, simply do not create\n-\t     points-to information for pt_anything pointers.  This\n-\t     will cause the operand scanner to fall back to the\n-\t     type-based SMT and its aliases.  Which is the best\n-\t     we could do here for the points-to set as well.  */\n-\t  if (was_pt_anything)\n-\t    return false;\n \n-\t  /* Share the final set of variables when possible.  */\n-\t  finished_solution = BITMAP_GGC_ALLOC ();\n-\t  stats.points_to_sets_created++;\n+/* Reset the points-to solution *PT to a conservative default\n+   (point to anything).  */\n \n-\t  pruned = set_uids_in_ptset (p, finished_solution, vi->solution,\n-\t\t\t\t      pi->is_dereferenced,\n-\t\t\t\t      vi->no_tbaa_pruning);\n-\t  result = shared_bitmap_lookup (finished_solution);\n+void\n+pt_solution_reset (struct pt_solution *pt)\n+{\n+  memset (pt, 0, sizeof (struct pt_solution));\n+  pt->anything = true;\n+}\n \n-\t  if (!result)\n-\t    {\n-\t      shared_bitmap_add (finished_solution);\n-\t      pi->pt_vars = finished_solution;\n-\t    }\n-\t  else\n-\t    {\n-\t      pi->pt_vars = result;\n-\t      bitmap_clear (finished_solution);\n-\t    }\n+/* Return true if the points-to solution *PT is empty.  */\n \n-\t  if (bitmap_empty_p (pi->pt_vars))\n-\t    {\n-\t      pi->pt_vars = NULL;\n-\t      if (pruned > 0\n-\t\t  && !pi->pt_null\n-\t\t  && pi->is_dereferenced\n-\t\t  && warn_strict_aliasing > 0\n-\t\t  && !SSA_NAME_IS_DEFAULT_DEF (p))\n-\t\t{\n-\t\t  if (dump_file && dump_flags & TDF_DETAILS)\n-\t\t    {\n-\t\t      fprintf (dump_file, \"alias warning for \");\n-\t\t      print_generic_expr (dump_file, p, 0);\n-\t\t      fprintf (dump_file, \"\\n\");\n-\t\t    }\n-\t\t  emit_alias_warning (p);\n-\t\t}\n-\t    }\n+static bool\n+pt_solution_empty_p (struct pt_solution *pt)\n+{\n+  if (pt->anything\n+      || pt->nonlocal)\n+    return false;\n \n-\t  return true;\n-\t}\n-    }\n+  if (pt->vars\n+      && !bitmap_empty_p (pt->vars))\n+    return false;\n \n-  return false;\n+  /* If the solution includes ESCAPED, check if that is empty.  */\n+  if (pt->escaped\n+      && !pt_solution_empty_p (&cfun->gimple_df->escaped))\n+    return false;\n+\n+  return true;\n }\n \n-/* Mark the ESCAPED solution as call clobbered.  Returns false if\n-   pt_anything escaped which needs all locals that have their address\n-   taken marked call clobbered as well.  */\n+/* Return true if the points-to solution *PT includes global memory.  */\n \n bool\n-clobber_what_escaped (void)\n+pt_solution_includes_global (struct pt_solution *pt)\n {\n-  varinfo_t vi;\n-  unsigned int i;\n-  bitmap_iterator bi;\n+  if (pt->anything\n+      || pt->nonlocal\n+      || pt->vars_contains_global)\n+    return true;\n \n-  if (!have_alias_info)\n-    return false;\n+  if (pt->escaped)\n+    return pt_solution_includes_global (&cfun->gimple_df->escaped);\n \n-  /* This variable may have been collapsed, let's get the real\n-     variable for escaped_id.  */\n-  vi = get_varinfo (find (escaped_id));\n+  return false;\n+}\n \n-  /* If call-used memory escapes we need to include it in the\n-     set of escaped variables.  This can happen if a pure\n-     function returns a pointer and this pointer escapes.  */\n-  if (bitmap_bit_p (vi->solution, callused_id))\n-    {\n-      varinfo_t cu_vi = get_varinfo (find (callused_id));\n-      bitmap_ior_into (vi->solution, cu_vi->solution);\n-    }\n+/* Return true if the points-to solution *PT includes the variable\n+   declaration DECL.  */\n \n-  /* Mark variables in the solution call-clobbered.  */\n-  EXECUTE_IF_SET_IN_BITMAP (vi->solution, 0, i, bi)\n-    {\n-      varinfo_t vi = get_varinfo (i);\n+static bool\n+pt_solution_includes_1 (struct pt_solution *pt, const_tree decl)\n+{\n+  if (pt->anything)\n+    return true;\n \n-      if (vi->is_artificial_var)\n-\t{\n-\t  /* nothing_id and readonly_id do not cause any\n-\t     call clobber ops.  For anything_id and integer_id\n-\t     we need to clobber all addressable vars.  */\n-\t  if (vi->id == anything_id\n-\t      || vi->id == integer_id)\n-\t    return false;\n-\t}\n+  if (pt->nonlocal\n+      && is_global_var (decl))\n+    return true;\n \n-      /* Only artificial heap-vars are further interesting.  */\n-      if (vi->is_artificial_var && !vi->is_heap_var)\n-\tcontinue;\n+  if (pt->vars\n+      && bitmap_bit_p (pt->vars, DECL_UID (decl)))\n+    return true;\n \n-      if ((TREE_CODE (vi->decl) == VAR_DECL\n-\t   || TREE_CODE (vi->decl) == PARM_DECL\n-\t   || TREE_CODE (vi->decl) == RESULT_DECL)\n-\t  && !unmodifiable_var_p (vi->decl))\n-\tmark_call_clobbered (vi->decl, ESCAPE_TO_CALL);\n-    }\n+  /* If the solution includes ESCAPED, check it.  */\n+  if (pt->escaped\n+      && pt_solution_includes_1 (&cfun->gimple_df->escaped, decl))\n+    return true;\n \n-  return true;\n+  return false;\n }\n \n-/* Compute the call-used variables.  */\n-\n-void\n-compute_call_used_vars (void)\n+bool\n+pt_solution_includes (struct pt_solution *pt, const_tree decl)\n {\n-  varinfo_t vi;\n-  unsigned int i;\n-  bitmap_iterator bi;\n-  bool has_anything_id = false;\n-\n-  if (!have_alias_info)\n-    return;\n+  bool res = pt_solution_includes_1 (pt, decl);\n+  if (res)\n+    ++pta_stats.pt_solution_includes_may_alias;\n+  else\n+    ++pta_stats.pt_solution_includes_no_alias;\n+  return res;\n+}\n \n-  /* This variable may have been collapsed, let's get the real\n-     variable for escaped_id.  */\n-  vi = get_varinfo (find (callused_id));\n+/* Return true if both points-to solutions PT1 and PT2 have a non-empty\n+   intersection.  */\n \n-  /* Mark variables in the solution call-clobbered.  */\n-  EXECUTE_IF_SET_IN_BITMAP (vi->solution, 0, i, bi)\n-    {\n-      varinfo_t vi = get_varinfo (i);\n+static bool\n+pt_solutions_intersect_1 (struct pt_solution *pt1, struct pt_solution *pt2)\n+{\n+  if (pt1->anything || pt2->anything)\n+    return true;\n \n-      if (vi->is_artificial_var)\n-\t{\n-\t  /* For anything_id and integer_id we need to make\n-\t     all local addressable vars call-used.  */\n-\t  if (vi->id == anything_id\n-\t      || vi->id == integer_id)\n-\t    has_anything_id = true;\n-\t}\n+  /* If either points to unknown global memory and the other points to\n+     any global memory they alias.  */\n+  if ((pt1->nonlocal\n+       && (pt2->nonlocal\n+\t   || pt2->vars_contains_global))\n+      || (pt2->nonlocal\n+\t  && pt1->vars_contains_global))\n+    return true;\n \n-      /* Only artificial heap-vars are further interesting.  */\n-      if (vi->is_artificial_var && !vi->is_heap_var)\n-\tcontinue;\n+  /* Check the escaped solution if required.  */\n+  if ((pt1->escaped || pt2->escaped)\n+      && !pt_solution_empty_p (&cfun->gimple_df->escaped))\n+    {\n+      /* If both point to escaped memory and that solution\n+\t is not empty they alias.  */\n+      if (pt1->escaped && pt2->escaped)\n+\treturn true;\n \n-      if ((TREE_CODE (vi->decl) == VAR_DECL\n-\t   || TREE_CODE (vi->decl) == PARM_DECL\n-\t   || TREE_CODE (vi->decl) == RESULT_DECL)\n-\t  && !unmodifiable_var_p (vi->decl))\n-\tbitmap_set_bit (gimple_call_used_vars (cfun), DECL_UID (vi->decl));\n+      /* If either points to escaped memory see if the escaped solution\n+\t intersects with the other.  */\n+      if ((pt1->escaped\n+\t   && pt_solutions_intersect_1 (&cfun->gimple_df->escaped, pt2))\n+\t  || (pt2->escaped\n+\t      && pt_solutions_intersect_1 (&cfun->gimple_df->escaped, pt1)))\n+\treturn true;\n     }\n \n-  /* If anything is call-used, add all addressable locals to the set.  */\n-  if (has_anything_id)\n-    bitmap_ior_into (gimple_call_used_vars (cfun),\n-\t\t     gimple_addressable_vars (cfun));\n+  /* Now both pointers alias if their points-to solution intersects.  */\n+  return (pt1->vars\n+\t  && pt2->vars\n+\t  && bitmap_intersect_p (pt1->vars, pt2->vars));\n+}\n+\n+bool\n+pt_solutions_intersect (struct pt_solution *pt1, struct pt_solution *pt2)\n+{\n+  bool res = pt_solutions_intersect_1 (pt1, pt2);\n+  if (res)\n+    ++pta_stats.pt_solutions_intersect_may_alias;\n+  else\n+    ++pta_stats.pt_solutions_intersect_no_alias;\n+  return res;\n }\n \n \n /* Dump points-to information to OUTFILE.  */\n \n-void\n+static void\n dump_sa_points_to_info (FILE *outfile)\n {\n   unsigned int i;\n@@ -5149,7 +5117,7 @@ init_base_vars (void)\n \n   /* Create the ANYTHING variable, used to represent that a variable\n      points to some unknown piece of memory.  */\n-  anything_tree = create_tmp_var_raw (void_type_node, \"ANYTHING\");\n+  anything_tree = create_tmp_var_raw (ptr_type_node, \"ANYTHING\");\n   var_anything = new_var_info (anything_tree, anything_id, \"ANYTHING\");\n   insert_vi_for_tree (anything_tree, var_anything);\n   var_anything->is_artificial_var = 1;\n@@ -5177,7 +5145,7 @@ init_base_vars (void)\n \n   /* Create the READONLY variable, used to represent that a variable\n      points to readonly memory.  */\n-  readonly_tree = create_tmp_var_raw (void_type_node, \"READONLY\");\n+  readonly_tree = create_tmp_var_raw (ptr_type_node, \"READONLY\");\n   var_readonly = new_var_info (readonly_tree, readonly_id, \"READONLY\");\n   var_readonly->is_artificial_var = 1;\n   var_readonly->offset = 0;\n@@ -5202,7 +5170,7 @@ init_base_vars (void)\n \n   /* Create the ESCAPED variable, used to represent the set of escaped\n      memory.  */\n-  escaped_tree = create_tmp_var_raw (void_type_node, \"ESCAPED\");\n+  escaped_tree = create_tmp_var_raw (ptr_type_node, \"ESCAPED\");\n   var_escaped = new_var_info (escaped_tree, escaped_id, \"ESCAPED\");\n   insert_vi_for_tree (escaped_tree, var_escaped);\n   var_escaped->is_artificial_var = 1;\n@@ -5213,18 +5181,9 @@ init_base_vars (void)\n   VEC_safe_push (varinfo_t, heap, varmap, var_escaped);\n   gcc_assert (VEC_index (varinfo_t, varmap, 3) == var_escaped);\n \n-  /* ESCAPED = *ESCAPED, because escaped is may-deref'd at calls, etc.  */\n-  lhs.type = SCALAR;\n-  lhs.var = escaped_id;\n-  lhs.offset = 0;\n-  rhs.type = DEREF;\n-  rhs.var = escaped_id;\n-  rhs.offset = 0;\n-  process_constraint (new_constraint (lhs, rhs));\n-\n   /* Create the NONLOCAL variable, used to represent the set of nonlocal\n      memory.  */\n-  nonlocal_tree = create_tmp_var_raw (void_type_node, \"NONLOCAL\");\n+  nonlocal_tree = create_tmp_var_raw (ptr_type_node, \"NONLOCAL\");\n   var_nonlocal = new_var_info (nonlocal_tree, nonlocal_id, \"NONLOCAL\");\n   insert_vi_for_tree (nonlocal_tree, var_nonlocal);\n   var_nonlocal->is_artificial_var = 1;\n@@ -5234,19 +5193,53 @@ init_base_vars (void)\n   var_nonlocal->is_special_var = 1;\n   VEC_safe_push (varinfo_t, heap, varmap, var_nonlocal);\n \n-  /* Nonlocal memory points to escaped (which includes nonlocal),\n-     in order to make deref easier.  */\n+  /* ESCAPED = *ESCAPED, because escaped is may-deref'd at calls, etc.  */\n+  lhs.type = SCALAR;\n+  lhs.var = escaped_id;\n+  lhs.offset = 0;\n+  rhs.type = DEREF;\n+  rhs.var = escaped_id;\n+  rhs.offset = 0;\n+  process_constraint (new_constraint (lhs, rhs));\n+\n+  /* ESCAPED = ESCAPED + UNKNOWN_OFFSET, because if a sub-field escapes the\n+     whole variable escapes.  */\n+  lhs.type = SCALAR;\n+  lhs.var = escaped_id;\n+  lhs.offset = 0;\n+  rhs.type = SCALAR;\n+  rhs.var = escaped_id;\n+  rhs.offset = UNKNOWN_OFFSET;\n+  process_constraint (new_constraint (lhs, rhs));\n+\n+  /* *ESCAPED = NONLOCAL.  This is true because we have to assume\n+     everything pointed to by escaped points to what global memory can\n+     point to.  */\n+  lhs.type = DEREF;\n+  lhs.var = escaped_id;\n+  lhs.offset = 0;\n+  rhs.type = SCALAR;\n+  rhs.var = nonlocal_id;\n+  rhs.offset = 0;\n+  process_constraint (new_constraint (lhs, rhs));\n+\n+  /* NONLOCAL = &NONLOCAL, NONLOCAL = &ESCAPED.  This is true because\n+     global memory may point to global memory and escaped memory.  */\n   lhs.type = SCALAR;\n   lhs.var = nonlocal_id;\n   lhs.offset = 0;\n   rhs.type = ADDRESSOF;\n+  rhs.var = nonlocal_id;\n+  rhs.offset = 0;\n+  process_constraint (new_constraint (lhs, rhs));\n+  rhs.type = ADDRESSOF;\n   rhs.var = escaped_id;\n   rhs.offset = 0;\n   process_constraint (new_constraint (lhs, rhs));\n \n   /* Create the CALLUSED variable, used to represent the set of call-used\n      memory.  */\n-  callused_tree = create_tmp_var_raw (void_type_node, \"CALLUSED\");\n+  callused_tree = create_tmp_var_raw (ptr_type_node, \"CALLUSED\");\n   var_callused = new_var_info (callused_tree, callused_id, \"CALLUSED\");\n   insert_vi_for_tree (callused_tree, var_callused);\n   var_callused->is_artificial_var = 1;\n@@ -5265,6 +5258,16 @@ init_base_vars (void)\n   rhs.offset = 0;\n   process_constraint (new_constraint (lhs, rhs));\n \n+  /* CALLUSED = CALLUSED + UNKNOWN, because if a sub-field is call-used the\n+     whole variable is call-used.  */\n+  lhs.type = SCALAR;\n+  lhs.var = callused_id;\n+  lhs.offset = 0;\n+  rhs.type = SCALAR;\n+  rhs.var = callused_id;\n+  rhs.offset = UNKNOWN_OFFSET;\n+  process_constraint (new_constraint (lhs, rhs));\n+\n   /* Create the STOREDANYTHING variable, used to represent the set of\n      variables stored to *ANYTHING.  */\n   storedanything_tree = create_tmp_var_raw (ptr_type_node, \"STOREDANYTHING\");\n@@ -5279,8 +5282,8 @@ init_base_vars (void)\n   VEC_safe_push (varinfo_t, heap, varmap, var_storedanything);\n \n   /* Create the INTEGER variable, used to represent that a variable points\n-     to an INTEGER.  */\n-  integer_tree = create_tmp_var_raw (void_type_node, \"INTEGER\");\n+     to what an INTEGER \"points to\".  */\n+  integer_tree = create_tmp_var_raw (ptr_type_node, \"INTEGER\");\n   var_integer = new_var_info (integer_tree, integer_id, \"INTEGER\");\n   insert_vi_for_tree (integer_tree, var_integer);\n   var_integer->is_artificial_var = 1;\n@@ -5300,26 +5303,6 @@ init_base_vars (void)\n   rhs.var = anything_id;\n   rhs.offset = 0;\n   process_constraint (new_constraint (lhs, rhs));\n-\n-  /* *ESCAPED = &ESCAPED.  This is true because we have to assume\n-     everything pointed to by escaped can also point to escaped. */\n-  lhs.type = DEREF;\n-  lhs.var = escaped_id;\n-  lhs.offset = 0;\n-  rhs.type = ADDRESSOF;\n-  rhs.var = escaped_id;\n-  rhs.offset = 0;\n-  process_constraint (new_constraint (lhs, rhs));\n-\n-  /* *ESCAPED = &NONLOCAL.  This is true because we have to assume\n-     everything pointed to by escaped can also point to nonlocal. */\n-  lhs.type = DEREF;\n-  lhs.var = escaped_id;\n-  lhs.offset = 0;\n-  rhs.type = ADDRESSOF;\n-  rhs.var = nonlocal_id;\n-  rhs.offset = 0;\n-  process_constraint (new_constraint (lhs, rhs));\n }\n \n /* Initialize things necessary to perform PTA */\n@@ -5516,14 +5499,36 @@ compute_tbaa_pruning (void)\n     }\n }\n \n+/* Initialize the heapvar for statement mapping.  */\n+\n+static void\n+init_alias_heapvars (void)\n+{\n+  if (!heapvar_for_stmt)\n+    heapvar_for_stmt = htab_create_ggc (11, tree_map_hash, tree_map_eq,\n+\t\t\t\t\tNULL);\n+}\n+\n+/* Delete the heapvar for statement mapping.  */\n+\n+void\n+delete_alias_heapvars (void)\n+{\n+  if (heapvar_for_stmt)\n+    htab_delete (heapvar_for_stmt);\n+  heapvar_for_stmt = NULL;\n+}\n+\n /* Create points-to sets for the current function.  See the comments\n    at the start of the file for an algorithmic overview.  */\n \n-void\n+static void\n compute_points_to_sets (void)\n {\n   struct scc_info *si;\n   basic_block bb;\n+  unsigned i;\n+  sbitmap dereferenced_ptrs;\n \n   timevar_push (TV_TREE_PTA);\n \n@@ -5532,6 +5537,11 @@ compute_points_to_sets (void)\n \n   intra_create_variable_infos ();\n \n+  /* A bitmap of SSA_NAME pointers that are dereferenced.  This is\n+     used to track which points-to sets may be TBAA pruned.  */\n+  dereferenced_ptrs = sbitmap_alloc (num_ssa_names);\n+  sbitmap_zero (dereferenced_ptrs);\n+\n   /* Now walk all statements and derive aliases.  */\n   FOR_EACH_BB (bb)\n     {\n@@ -5546,7 +5556,30 @@ compute_points_to_sets (void)\n \t}\n \n       for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n-\tfind_func_aliases (gsi_stmt (gsi));\n+\t{\n+\t  gimple stmt = gsi_stmt (gsi);\n+\t  use_operand_p use_p;\n+\t  ssa_op_iter iter;\n+\n+\t  /* Mark dereferenced pointers.  This is used by TBAA pruning\n+\t     of the points-to sets and the alias warning machinery.  */\n+\t  FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_USE)\n+\t    {\n+\t      unsigned num_uses, num_loads, num_stores;\n+\t      tree op = USE_FROM_PTR (use_p);\n+\n+\t      if (!POINTER_TYPE_P (TREE_TYPE (op)))\n+\t\tcontinue;\n+\n+\t      /* Determine whether OP is a dereferenced pointer.  */\n+\t      count_uses_and_derefs (op, stmt,\n+\t\t\t\t     &num_uses, &num_loads, &num_stores);\n+\t      if (num_loads + num_stores > 0)\n+\t\tSET_BIT (dereferenced_ptrs, SSA_NAME_VERSION (op));\n+\t    }\n+\n+\t  find_func_aliases (stmt);\n+\t}\n     }\n \n \n@@ -5608,15 +5641,35 @@ compute_points_to_sets (void)\n   if (dump_file)\n     dump_sa_points_to_info (dump_file);\n \n-  have_alias_info = true;\n+  /* Compute the points-to sets for ESCAPED and CALLUSED used for\n+     call-clobber analysis.  */\n+  find_what_var_points_to (var_escaped, &cfun->gimple_df->escaped, false);\n+  find_what_var_points_to (var_callused, &cfun->gimple_df->callused, false);\n+\n+  /* Make sure the ESCAPED solution (which is used as placeholder in\n+     other solutions) does not reference itself.  This simplifies\n+     points-to solution queries.  */\n+  cfun->gimple_df->escaped.escaped = 0;\n+\n+  /* Compute the points-to sets for pointer SSA_NAMEs.  */\n+  for (i = 0; i < num_ssa_names; ++i)\n+    {\n+      tree ptr = ssa_name (i);\n+      if (ptr\n+\t  && POINTER_TYPE_P (TREE_TYPE (ptr)))\n+\tfind_what_p_points_to (ptr, TEST_BIT (dereferenced_ptrs, i));\n+    }\n+  sbitmap_free (dereferenced_ptrs);\n \n   timevar_pop (TV_TREE_PTA);\n+\n+  have_alias_info = true;\n }\n \n \n /* Delete created points-to sets.  */\n \n-void\n+static void\n delete_points_to_sets (void)\n {\n   unsigned int i;\n@@ -5647,6 +5700,61 @@ delete_points_to_sets (void)\n   have_alias_info = false;\n }\n \n+\n+/* Compute points-to information for every SSA_NAME pointer in the\n+   current function and compute the transitive closure of escaped\n+   variables to re-initialize the call-clobber states of local variables.  */\n+\n+unsigned int\n+compute_may_aliases (void)\n+{\n+  /* For each pointer P_i, determine the sets of variables that P_i may\n+     point-to.  Compute the reachability set of escaped and call-used\n+     variables.  */\n+  compute_points_to_sets ();\n+\n+  /* Debugging dumps.  */\n+  if (dump_file)\n+    {\n+      dump_alias_info (dump_file);\n+\n+      if (dump_flags & TDF_DETAILS)\n+\tdump_referenced_vars (dump_file);\n+    }\n+\n+  /* Deallocate memory used by aliasing data structures and the internal\n+     points-to solution.  */\n+  delete_points_to_sets ();\n+\n+  gcc_assert (!need_ssa_update_p (cfun));\n+\n+  return 0;\n+}\n+\n+\n+/* A dummy pass to cause points-to information to be computed via\n+   TODO_rebuild_alias.  */\n+\n+struct gimple_opt_pass pass_build_alias =\n+{\n+ {\n+  GIMPLE_PASS,\n+  \"alias\",\t\t    /* name */\n+  NULL,\t\t\t    /* gate */\n+  NULL,                     /* execute */\n+  NULL,                     /* sub */\n+  NULL,                     /* next */\n+  0,                        /* static_pass_number */\n+  0,                        /* tv_id */\n+  PROP_cfg | PROP_ssa,      /* properties_required */\n+  PROP_alias,               /* properties_provided */\n+  0,                        /* properties_destroyed */\n+  0,                        /* todo_flags_start */\n+  TODO_rebuild_alias | TODO_dump_func  /* todo_flags_finish */\n+ }\n+};\n+\n+\n /* Return true if we should execute IPA PTA.  */\n static bool\n gate_ipa_pta (void)\n@@ -5778,20 +5886,5 @@ struct simple_ipa_opt_pass pass_ipa_pta =\n  }\n };\n \n-/* Initialize the heapvar for statement mapping.  */\n-void\n-init_alias_heapvars (void)\n-{\n-  if (!heapvar_for_stmt)\n-    heapvar_for_stmt = htab_create_ggc (11, tree_map_hash, tree_map_eq,\n-\t\t\t\t\tNULL);\n-}\n-\n-void\n-delete_alias_heapvars (void)\n-{\n-  htab_delete (heapvar_for_stmt);\n-  heapvar_for_stmt = NULL;\n-}\n \n #include \"gt-tree-ssa-structalias.h\""}, {"sha": "6f2b93d42923cede68f040db85196b03fcda0596", "filename": "gcc/tree-ssa-structalias.h", "status": "removed", "additions": 0, "deletions": 46, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/95fe602ebea97abb5c5a303e7441fa055b65bb32/gcc%2Ftree-ssa-structalias.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/95fe602ebea97abb5c5a303e7441fa055b65bb32/gcc%2Ftree-ssa-structalias.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-structalias.h?ref=95fe602ebea97abb5c5a303e7441fa055b65bb32", "patch": "@@ -1,46 +0,0 @@\n-/* Tree based points-to analysis\n-   Copyright (C) 2002, 2003, 2007, 2008 Free Software Foundation, Inc.\n-   Contributed by Daniel Berlin <dberlin@dberlin.org>\n-\n-   This file is part of GCC.\n-\n-   GCC is free software; you can redistribute it and/or modify\n-   under the terms of the GNU General Public License as published by\n-   the Free Software Foundation; either version 3 of the License, or\n-   (at your option) any later version.\n-\n-   GCC is distributed in the hope that it will be useful,\n-   but WITHOUT ANY WARRANTY; without even the implied warranty of\n-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-   GNU General Public License for more details.\n-\n-   You should have received a copy of the GNU General Public License\n-   along with GCC; see the file COPYING3.  If not see\n-   <http://www.gnu.org/licenses/>.  */\n-\n-#ifndef TREE_SSA_STRUCTALIAS_H\n-#define TREE_SSA_STRUCTALIAS_H\n-\n-struct constraint;\n-typedef struct constraint *constraint_t;\n-\n-/* In tree-ssa-alias.c.  */\n-enum escape_type is_escape_site (gimple);\n-void update_mem_sym_stats_from_stmt (tree, gimple, long, long);\n-\n-/* In tree-ssa-structalias.c.  */\n-extern void compute_points_to_sets (void);\n-extern void delete_points_to_sets (void);\n-extern void dump_constraint (FILE *, constraint_t);\n-extern void dump_constraint_edge (FILE *, constraint_t);\n-extern void dump_constraints (FILE *);\n-extern void dump_constraint_graph (FILE *);\n-extern void debug_constraint (constraint_t);\n-extern void debug_constraints (void);\n-extern void debug_constraint_graph (void);\n-extern void dump_solution_for_var (FILE *, unsigned int);\n-extern void debug_solution_for_var (unsigned int);\n-extern void dump_sa_points_to_info (FILE *);\n-extern void debug_sa_points_to_info (void);\n-\n-#endif /* TREE_SSA_STRUCTALIAS_H  */"}, {"sha": "b415971a243d54d54281b99ff119e2ac54e3d8d0", "filename": "gcc/tree-ssa-ter.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-ter.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa-ter.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ter.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -412,7 +412,7 @@ is_replaceable_p (gimple stmt)\n     return false;\n \n   /* There must be no VDEFs.  */\n-  if (!(ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF)))\n+  if (gimple_vdef (stmt))\n     return false;\n \n   /* Without alias info we can't move around loads.  */\n@@ -504,7 +504,7 @@ process_replaceable (temp_expr_table_p tab, gimple stmt)\n   tab->expr_decl_uids[version] = def_vars;\n \n   /* If there are VUSES, add a dependence on virtual defs.  */\n-  if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VUSE))\n+  if (gimple_vuse (stmt))\n     {\n       make_dependent_on_partition (tab, version, VIRTUAL_PARTITION (tab));\n       add_to_partition_kill_list (tab, VIRTUAL_PARTITION (tab), version);\n@@ -639,7 +639,7 @@ find_replaceable_in_bb (temp_expr_table_p tab, basic_block bb)\n \n       /* A V_{MAY,MUST}_DEF kills any expression using a virtual operand,\n \t including the current stmt.  */\n-      if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_DEFS))\n+      if (gimple_vdef (stmt))\n         kill_virtual_exprs (tab);\n     }\n }"}, {"sha": "3c4fc0c0d38cbf4524258d9a7d7951e3b2f7eed6", "filename": "gcc/tree-ssa.c", "status": "modified", "additions": 126, "deletions": 329, "changes": 455, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -271,6 +271,12 @@ verify_ssa_name (tree ssa_name, bool is_virtual)\n       return true;\n     }\n \n+  if (is_virtual && SSA_NAME_VAR (ssa_name) != gimple_vop (cfun))\n+    {\n+      error (\"virtual SSA name for non-VOP decl\");\n+      return true;\n+    }\n+\n   if (!is_virtual && !is_gimple_reg (ssa_name))\n     {\n       error (\"found a real definition for a non-register\");\n@@ -520,232 +526,6 @@ verify_phi_args (gimple phi, basic_block bb, basic_block *definition_block)\n }\n \n \n-static void\n-verify_flow_insensitive_alias_info (void)\n-{\n-  tree var;\n-  referenced_var_iterator rvi;\n-\n-  FOR_EACH_REFERENCED_VAR (var, rvi)\n-    {\n-      unsigned int j;\n-      bitmap aliases;\n-      tree alias;\n-      bitmap_iterator bi;\n-\n-      if (!MTAG_P (var) || !MTAG_ALIASES (var))\n-\tcontinue;\n-      \n-      aliases = MTAG_ALIASES (var);\n-\n-      EXECUTE_IF_SET_IN_BITMAP (aliases, 0, j, bi)\n-\t{\n-\t  alias = referenced_var (j);\n-\n-\t  if (TREE_CODE (alias) != MEMORY_PARTITION_TAG\n-\t      && !may_be_aliased (alias))\n-\t    {\n-\t      error (\"non-addressable variable inside an alias set\");\n-\t      debug_variable (alias);\n-\t      goto err;\n-\t    }\n-\t}\n-    }\n-\n-  return;\n-\n-err:\n-  debug_variable (var);\n-  internal_error (\"verify_flow_insensitive_alias_info failed\");\n-}\n-\n-\n-static void\n-verify_flow_sensitive_alias_info (void)\n-{\n-  size_t i;\n-  tree ptr;\n-\n-  for (i = 1; i < num_ssa_names; i++)\n-    {\n-      tree var;\n-      var_ann_t ann;\n-      struct ptr_info_def *pi;\n- \n-\n-      ptr = ssa_name (i);\n-      if (!ptr)\n-\tcontinue;\n-\n-      /* We only care for pointers that are actually referenced in the\n-\t program.  */\n-      if (!POINTER_TYPE_P (TREE_TYPE (ptr)) || !TREE_VISITED (ptr))\n-\tcontinue;\n-\n-      /* RESULT_DECL is special.  If it's a GIMPLE register, then it\n-\t is only written-to only once in the return statement.\n-\t Otherwise, aggregate RESULT_DECLs may be written-to more than\n-\t once in virtual operands.  */\n-      var = SSA_NAME_VAR (ptr);\n-      if (TREE_CODE (var) == RESULT_DECL\n-\t  && is_gimple_reg (ptr))\n-\tcontinue;\n-\n-      pi = SSA_NAME_PTR_INFO (ptr);\n-      if (pi == NULL)\n-\tcontinue;\n-\n-      ann = var_ann (var);\n-      if (pi->memory_tag_needed && !pi->name_mem_tag && !ann->symbol_mem_tag)\n-\t{\n-\t  error (\"dereferenced pointers should have a name or a symbol tag\");\n-\t  goto err;\n-\t}\n-\n-      if (pi->name_mem_tag\n-\t  && (pi->pt_vars == NULL || bitmap_empty_p (pi->pt_vars)))\n-\t{\n-\t  error (\"pointers with a memory tag, should have points-to sets\");\n-\t  goto err;\n-\t}\n-\n-      if (pi->value_escapes_p\n-\t  && pi->escape_mask & ~ESCAPE_TO_RETURN\n-\t  && pi->name_mem_tag)\n-\t{\n-\t  tree t = memory_partition (pi->name_mem_tag);\n-\t  if (t == NULL_TREE)\n-\t    t = pi->name_mem_tag;\n-\t  \n-\t  if (!is_call_clobbered (t))\n-\t    {\n-\t      error (\"pointer escapes but its name tag is not call-clobbered\");\n-\t      goto err;\n-\t    }\n-\t}\n-    }\n-\n-  return;\n-\n-err:\n-  debug_variable (ptr);\n-  internal_error (\"verify_flow_sensitive_alias_info failed\");\n-}\n-\n-\n-/* Verify the consistency of call clobbering information.  */\n-\n-static void\n-verify_call_clobbering (void)\n-{\n-  unsigned int i;\n-  bitmap_iterator bi;\n-  tree var;\n-  referenced_var_iterator rvi;\n-\n-  /* At all times, the result of the call_clobbered flag should\n-     match the result of the call_clobbered_vars bitmap.  Verify both\n-     that everything in call_clobbered_vars is marked\n-     call_clobbered, and that everything marked\n-     call_clobbered is in call_clobbered_vars.  */\n-  EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, i, bi)\n-    {\n-      var = referenced_var (i);\n-\n-      if (memory_partition (var))\n-\tvar = memory_partition (var);\n-\n-      if (!MTAG_P (var) && !var_ann (var)->call_clobbered)\n-\t{\n-\t  error (\"variable in call_clobbered_vars but not marked \"\n-\t         \"call_clobbered\");\n-\t  debug_variable (var);\n-\t  goto err;\n-\t}\n-    }\n-\n-  FOR_EACH_REFERENCED_VAR (var, rvi)\n-    {\n-      if (is_gimple_reg (var))\n-\tcontinue;\n-\n-      if (memory_partition (var))\n-\tvar = memory_partition (var);\n-\n-      if (!MTAG_P (var)\n-\t  && var_ann (var)->call_clobbered\n-\t  && !bitmap_bit_p (gimple_call_clobbered_vars (cfun), DECL_UID (var)))\n-\t{\n-\t  error (\"variable marked call_clobbered but not in \"\n-\t         \"call_clobbered_vars bitmap.\");\n-\t  debug_variable (var);\n-\t  goto err;\n-\t}\n-    }\n-\n-  return;\n-\n- err:\n-    internal_error (\"verify_call_clobbering failed\");\n-}\n-\n-\n-/* Verify invariants in memory partitions.  */\n-\n-static void\n-verify_memory_partitions (void)\n-{\n-  unsigned i;\n-  tree mpt;\n-  VEC(tree,heap) *mpt_table = gimple_ssa_operands (cfun)->mpt_table;\n-  struct pointer_set_t *partitioned_syms = pointer_set_create ();\n-\n-  for (i = 0; VEC_iterate (tree, mpt_table, i, mpt); i++)\n-    {\n-      unsigned j;\n-      bitmap_iterator bj;\n-\n-      if (MPT_SYMBOLS (mpt) == NULL)\n-\t{\n-\t  error (\"Memory partitions should have at least one symbol\");\n-\t  debug_variable (mpt);\n-\t  goto err;\n-\t}\n-\n-      EXECUTE_IF_SET_IN_BITMAP (MPT_SYMBOLS (mpt), 0, j, bj)\n-\t{\n-\t  tree var = referenced_var (j);\n-\t  if (pointer_set_insert (partitioned_syms, var))\n-\t    {\n-\t      error (\"Partitioned symbols should belong to exactly one \"\n-\t\t     \"partition\");\n-\t      debug_variable (var);\n-\t      goto err;\n-\t    }\n-\t}\n-    }\n-\n-  pointer_set_destroy (partitioned_syms);\n-\n-  return;\n-\n-err:\n-  internal_error (\"verify_memory_partitions failed\");\n-}\n-\n-\n-/* Verify the consistency of aliasing information.  */\n-\n-static void\n-verify_alias_info (void)\n-{\n-  verify_flow_sensitive_alias_info ();\n-  verify_call_clobbering ();\n-  verify_flow_insensitive_alias_info ();\n-  verify_memory_partitions ();\n-}\n-\n-\n /* Verify common invariants in the SSA web.\n    TODO: verify the variable annotations.  */\n \n@@ -760,7 +540,7 @@ verify_ssa (bool check_modified_stmt)\n   enum dom_state orig_dom_state = dom_info_state (CDI_DOMINATORS);\n   bitmap names_defined_in_bb = BITMAP_ALLOC (NULL);\n \n-  gcc_assert (!need_ssa_update_p ());\n+  gcc_assert (!need_ssa_update_p (cfun));\n \n   verify_stmts ();\n \n@@ -824,6 +604,7 @@ verify_ssa (bool check_modified_stmt)\n \t{\n \t  gimple stmt = gsi_stmt (gsi);\n \t  use_operand_p use_p;\n+\t  bool has_err;\n \n \t  if (check_modified_stmt && gimple_modified_p (stmt))\n \t    {\n@@ -842,25 +623,51 @@ verify_ssa (bool check_modified_stmt)\n \t      base_address = get_base_address (lhs);\n \n \t      if (base_address\n-\t\t  && gimple_aliases_computed_p (cfun)\n \t\t  && SSA_VAR_P (base_address)\n-\t\t  && !gimple_has_volatile_ops (stmt)\n-\t\t  && ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF))\n+\t\t  && !gimple_vdef (stmt))\n \t\t{\n \t\t  error (\"statement makes a memory store, but has no VDEFS\");\n \t\t  print_gimple_stmt (stderr, stmt, 0, TDF_VOPS);\n \t\t  goto err;\n \t\t}\n \t    }\n \n-\t  FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_ALL_VIRTUALS)\n+\t  /* Verify the single virtual operand and its constraints.  */\n+\t  has_err = false;\n+\t  if (gimple_vdef (stmt))\n \t    {\n-\t      if (verify_ssa_name (op, true))\n+\t      if (gimple_vdef_op (stmt) == NULL_DEF_OPERAND_P)\n \t\t{\n-\t\t  error (\"in statement\");\n-\t\t  print_gimple_stmt (stderr, stmt, 0, TDF_VOPS|TDF_MEMSYMS);\n-\t\t  goto err;\n+\t\t  error (\"statement has VDEF operand not in defs list\");\n+\t\t  has_err = true;\n+\t\t}\n+\t      if (!gimple_vuse (stmt))\n+\t\t{\n+\t\t  error (\"statement has VDEF but no VUSE operand\");\n+\t\t  has_err = true;\n \t\t}\n+\t      else if (SSA_NAME_VAR (gimple_vdef (stmt))\n+\t\t       != SSA_NAME_VAR (gimple_vuse (stmt)))\n+\t\t{\n+\t\t  error (\"VDEF and VUSE do not use the same symbol\");\n+\t\t  has_err = true;\n+\t\t}\n+\t      has_err |= verify_ssa_name (gimple_vdef (stmt), true);\n+\t    }\n+\t  if (gimple_vuse (stmt))\n+\t    {\n+\t      if  (gimple_vuse_op (stmt) == NULL_USE_OPERAND_P)\n+\t\t{\n+\t\t  error (\"statement has VUSE operand not in uses list\");\n+\t\t  has_err = true;\n+\t\t}\n+\t      has_err |= verify_ssa_name (gimple_vuse (stmt), true);\n+\t    }\n+\t  if (has_err)\n+\t    {\n+\t      error (\"in statement\");\n+\t      print_gimple_stmt (stderr, stmt, 0, TDF_VOPS|TDF_MEMSYMS);\n+\t      goto err;\n \t    }\n \n \t  FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_USE|SSA_OP_DEF)\n@@ -882,16 +689,24 @@ verify_ssa (bool check_modified_stmt)\n \t    }\n \n \t  FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_ALL_DEFS)\n-\t    bitmap_set_bit (names_defined_in_bb, SSA_NAME_VERSION (op));\n+\t    {\n+\t      if (SSA_NAME_DEF_STMT (op) != stmt)\n+\t\t{\n+\t\t  error (\"SSA_NAME_DEF_STMT is wrong\");\n+\t\t  fprintf (stderr, \"Expected definition statement:\\n\");\n+\t\t  print_gimple_stmt (stderr, stmt, 4, TDF_VOPS);\n+\t\t  fprintf (stderr, \"\\nActual definition statement:\\n\");\n+\t\t  print_gimple_stmt (stderr, SSA_NAME_DEF_STMT (op),\n+\t\t\t\t     4, TDF_VOPS);\n+\t\t  goto err;\n+\t\t}\n+\t      bitmap_set_bit (names_defined_in_bb, SSA_NAME_VERSION (op));\n+\t    }\n \t}\n \n       bitmap_clear (names_defined_in_bb);\n     }\n \n-  /* Finally, verify alias information.  */\n-  if (gimple_aliases_computed_p (cfun))\n-    verify_alias_info ();\n-\n   free (definition_block);\n \n   /* Restore the dominance information to its prior known state, so\n@@ -974,9 +789,8 @@ init_tree_ssa (struct function *fn)\n \t\t\t\t     \t\t    uid_decl_map_eq, NULL);\n   fn->gimple_df->default_defs = htab_create_ggc (20, uid_ssaname_map_hash, \n \t\t\t\t                 uid_ssaname_map_eq, NULL);\n-  fn->gimple_df->call_clobbered_vars = BITMAP_GGC_ALLOC ();\n-  fn->gimple_df->call_used_vars = BITMAP_GGC_ALLOC ();\n-  fn->gimple_df->addressable_vars = BITMAP_GGC_ALLOC ();\n+  pt_solution_reset (&fn->gimple_df->escaped);\n+  pt_solution_reset (&fn->gimple_df->callused);\n   init_ssanames (fn, 0);\n   init_phinodes ();\n }\n@@ -1024,10 +838,8 @@ delete_tree_ssa (void)\n \n \t  if (gimple_has_mem_ops (stmt))\n \t    {\n-\t      gimple_set_vdef_ops (stmt, NULL);\n-\t      gimple_set_vuse_ops (stmt, NULL);\n-\t      BITMAP_FREE (stmt->gsmem.membase.stores);\n-\t      BITMAP_FREE (stmt->gsmem.membase.loads);\n+\t      gimple_set_vdef (stmt, NULL_TREE);\n+\t      gimple_set_vuse (stmt, NULL_TREE);\n \t    }\n \n \t  gimple_set_modified (stmt, true);\n@@ -1038,13 +850,8 @@ delete_tree_ssa (void)\n   /* Remove annotations from every referenced local variable.  */\n   FOR_EACH_REFERENCED_VAR (var, rvi)\n     {\n-      if (!MTAG_P (var)\n-\t  && (TREE_STATIC (var) || DECL_EXTERNAL (var)))\n-\t{\n-\t  var_ann (var)->mpt = NULL_TREE;\n-\t  var_ann (var)->symbol_mem_tag = NULL_TREE;\n-\t  continue;\n-\t}\n+      if (is_global_var (var))\n+\tcontinue;\n       if (var->base.ann)\n         ggc_free (var->base.ann);\n       var->base.ann = NULL;\n@@ -1059,22 +866,13 @@ delete_tree_ssa (void)\n   if (ssa_operands_active ())\n     fini_ssa_operands ();\n \n-  cfun->gimple_df->global_var = NULL_TREE;\n-  \n+  delete_alias_heapvars ();\n+\n   htab_delete (cfun->gimple_df->default_defs);\n   cfun->gimple_df->default_defs = NULL;\n-  cfun->gimple_df->call_clobbered_vars = NULL;\n-  cfun->gimple_df->call_used_vars = NULL;\n-  cfun->gimple_df->addressable_vars = NULL;\n+  pt_solution_reset (&cfun->gimple_df->escaped);\n+  pt_solution_reset (&cfun->gimple_df->callused);\n   cfun->gimple_df->modified_noreturn_calls = NULL;\n-  if (gimple_aliases_computed_p (cfun))\n-    {\n-      delete_alias_heapvars ();\n-      gcc_assert (!need_ssa_update_p ());\n-    }\n-  cfun->gimple_df->aliases_computed_p = false;\n-  delete_mem_ref_stats (cfun);\n-\n   cfun->gimple_df = NULL;\n \n   /* We no longer need the edge variable maps.  */\n@@ -1507,15 +1305,14 @@ warn_uninitialized_var (tree *tp, int *walk_subtrees, void *data_)\n \t/* If there is not gimple stmt, \n \t   or alias information has not been computed,\n \t   then we cannot check VUSE ops.  */\n-\tif (data->stmt == NULL\n-            || !gimple_aliases_computed_p (cfun))\n+\tif (data->stmt == NULL)\n \t  return NULL_TREE;\n \n \t/* If the load happens as part of a call do not warn about it.  */\n \tif (is_gimple_call (data->stmt))\n \t  return NULL_TREE;\n \n-\tvuse = SINGLE_SSA_USE_OPERAND (data->stmt, SSA_OP_VUSE);\n+\tvuse = gimple_vuse_op (data->stmt);\n \tif (vuse == NULL_USE_OPERAND_P)\n \t  return NULL_TREE;\n \n@@ -1689,16 +1486,15 @@ struct gimple_opt_pass pass_late_warn_uninitialized =\n \n /* Compute TREE_ADDRESSABLE and DECL_GIMPLE_REG_P for local variables.  */\n \n-static unsigned int\n-execute_update_addresses_taken (void)\n+void\n+execute_update_addresses_taken (bool do_optimize)\n {\n   tree var;\n   referenced_var_iterator rvi;\n   gimple_stmt_iterator gsi;\n   basic_block bb;\n   bitmap addresses_taken = BITMAP_ALLOC (NULL);\n   bitmap not_reg_needs = BITMAP_ALLOC (NULL);\n-  bitmap vars_updated = BITMAP_ALLOC (NULL);\n   bool update_vops = false;\n \n   /* Collect into ADDRESSES_TAKEN all variables whose address is taken within\n@@ -1747,69 +1543,69 @@ execute_update_addresses_taken (void)\n \n   /* When possible, clear ADDRESSABLE bit or set the REGISTER bit\n      and mark variable for conversion into SSA.  */\n-  FOR_EACH_REFERENCED_VAR (var, rvi)\n-    {\n-      /* Global Variables, result decls cannot be changed.  */\n-      if (is_global_var (var)\n-          || TREE_CODE (var) == RESULT_DECL\n-\t  || bitmap_bit_p (addresses_taken, DECL_UID (var)))\n-\tcontinue;\n-\t\n-      if (TREE_ADDRESSABLE (var)\n-\t  /* Do not change TREE_ADDRESSABLE if we need to preserve var as\n-\t     a non-register.  Otherwise we are confused and forget to\n-\t     add virtual operands for it.  */\n-\t  && (!is_gimple_reg_type (TREE_TYPE (var))\n-\t      || !bitmap_bit_p (not_reg_needs, DECL_UID (var))))\n-\t{\n-\t  TREE_ADDRESSABLE (var) = 0;\n-\t  if (is_gimple_reg (var))\n+  if (optimize && do_optimize)\n+    FOR_EACH_REFERENCED_VAR (var, rvi)\n+      {\n+\t/* Global Variables, result decls cannot be changed.  */\n+\tif (is_global_var (var)\n+\t    || TREE_CODE (var) == RESULT_DECL\n+\t    || bitmap_bit_p (addresses_taken, DECL_UID (var)))\n+\t  continue;\n+\n+\tif (TREE_ADDRESSABLE (var)\n+\t    /* Do not change TREE_ADDRESSABLE if we need to preserve var as\n+\t       a non-register.  Otherwise we are confused and forget to\n+\t       add virtual operands for it.  */\n+\t    && (!is_gimple_reg_type (TREE_TYPE (var))\n+\t\t|| !bitmap_bit_p (not_reg_needs, DECL_UID (var))))\n+\t  {\n+\t    TREE_ADDRESSABLE (var) = 0;\n+\t    if (is_gimple_reg (var))\n+\t      mark_sym_for_renaming (var);\n+\t    update_vops = true;\n+\t    if (dump_file)\n+\t      {\n+\t\tfprintf (dump_file, \"No longer having address taken \");\n+\t\tprint_generic_expr (dump_file, var, 0);\n+\t\tfprintf (dump_file, \"\\n\");\n+\t      }\n+\t  }\n+\tif (!DECL_GIMPLE_REG_P (var)\n+\t    && !bitmap_bit_p (not_reg_needs, DECL_UID (var))\n+\t    && (TREE_CODE (TREE_TYPE (var)) == COMPLEX_TYPE\n+\t\t|| TREE_CODE (TREE_TYPE (var)) == VECTOR_TYPE))\n+\t  {\n+\t    DECL_GIMPLE_REG_P (var) = 1;\n \t    mark_sym_for_renaming (var);\n-\t  update_vops = true;\n-\t  bitmap_set_bit (vars_updated, DECL_UID (var));\n-\t  if (dump_file)\n-\t    {\n-\t      fprintf (dump_file, \"No longer having address taken \");\n-\t      print_generic_expr (dump_file, var, 0);\n-\t      fprintf (dump_file, \"\\n\");\n-\t    }\n-\t}\n-      if (!DECL_GIMPLE_REG_P (var)\n-\t  && !bitmap_bit_p (not_reg_needs, DECL_UID (var))\n-\t  && (TREE_CODE (TREE_TYPE (var)) == COMPLEX_TYPE\n-\t      || TREE_CODE (TREE_TYPE (var)) == VECTOR_TYPE))\n-\t{\n-\t  DECL_GIMPLE_REG_P (var) = 1;\n-\t  mark_sym_for_renaming (var);\n-\t  update_vops = true;\n-\t  bitmap_set_bit (vars_updated, DECL_UID (var));\n-\t  if (dump_file)\n-\t    {\n-\t      fprintf (dump_file, \"Decl is now a gimple register \");\n-\t      print_generic_expr (dump_file, var, 0);\n-\t      fprintf (dump_file, \"\\n\");\n-\t    }\n-\t}\n+\t    update_vops = true;\n+\t    if (dump_file)\n+\t      {\n+\t\tfprintf (dump_file, \"Decl is now a gimple register \");\n+\t\tprint_generic_expr (dump_file, var, 0);\n+\t\tfprintf (dump_file, \"\\n\");\n+\t      }\n+\t  }\n       }\n \n   /* Operand caches needs to be recomputed for operands referencing the updated\n      variables.  */\n   if (update_vops)\n-    FOR_EACH_BB (bb)\n-      for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n-\t{\n-\t  gimple stmt = gsi_stmt (gsi);\n+    {\n+      FOR_EACH_BB (bb)\n+\t  for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n+\t    {\n+\t      gimple stmt = gsi_stmt (gsi);\n+\n+\t      if (gimple_references_memory_p (stmt))\n+\t\tupdate_stmt (stmt);\n+\t    }\n+\n+      /* Update SSA form here, we are called as non-pass as well.  */\n+      update_ssa (TODO_update_ssa);\n+    }\n \n-\t  if ((gimple_loaded_syms (stmt)\n-\t       && bitmap_intersect_p (gimple_loaded_syms (stmt), vars_updated))\n-\t      || (gimple_stored_syms (stmt)\n-\t\t  && bitmap_intersect_p (gimple_stored_syms (stmt), vars_updated)))\n-\t    update_stmt (stmt);\n-\t}\n   BITMAP_FREE (not_reg_needs);\n   BITMAP_FREE (addresses_taken);\n-  BITMAP_FREE (vars_updated);\n-  return 0;\n }\n \n struct gimple_opt_pass pass_update_address_taken =\n@@ -1818,7 +1614,7 @@ struct gimple_opt_pass pass_update_address_taken =\n   GIMPLE_PASS,\n   \"addressables\",\t\t\t/* name */\n   NULL,\t\t\t\t\t/* gate */\n-  execute_update_addresses_taken,\t/* execute */\n+  NULL,\t\t\t\t\t/* execute */\n   NULL,\t\t\t\t\t/* sub */\n   NULL,\t\t\t\t\t/* next */\n   0,\t\t\t\t\t/* static_pass_number */\n@@ -1827,6 +1623,7 @@ struct gimple_opt_pass pass_update_address_taken =\n   0,\t\t\t\t\t/* properties_provided */\n   0,\t\t\t\t\t/* properties_destroyed */\n   0,\t\t\t\t\t/* todo_flags_start */\n-  TODO_update_ssa                       /* todo_flags_finish */\n+  TODO_update_address_taken\n+  | TODO_dump_func\t\t\t/* todo_flags_finish */\n  }\n };"}, {"sha": "19032d52448714ee5ce24e2f6f418599b755829c", "filename": "gcc/tree-ssanames.c", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssanames.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-ssanames.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssanames.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -87,6 +87,8 @@ init_ssanames (struct function *fn, int size)\n      least 50 elements reserved in it.  */\n   VEC_quick_push (tree, SSANAMES (fn), NULL_TREE);\n   FREE_SSANAMES (fn) = NULL;\n+\n+  SYMS_TO_RENAME (fn) = BITMAP_GGC_ALLOC ();\n }\n \n /* Finalize management of SSA_NAMEs.  */\n@@ -268,12 +270,6 @@ duplicate_ssa_name_ptr_info (tree name, struct ptr_info_def *ptr_info)\n   new_ptr_info = GGC_NEW (struct ptr_info_def);\n   *new_ptr_info = *ptr_info;\n \n-  if (ptr_info->pt_vars)\n-    {\n-      new_ptr_info->pt_vars = BITMAP_GGC_ALLOC ();\n-      bitmap_copy (new_ptr_info->pt_vars, ptr_info->pt_vars);\n-    }\n-\n   SSA_NAME_PTR_INFO (name) = new_ptr_info;\n }\n "}, {"sha": "59a7694f095d3d77fd61f623c40823a12a0eabd8", "filename": "gcc/tree-tailcall.c", "status": "modified", "additions": 9, "deletions": 13, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-tailcall.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-tailcall.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-tailcall.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -136,15 +136,11 @@ suitable_for_tail_opt_p (void)\n   if (cfun->stdarg)\n     return false;\n \n-  /* No local variable nor structure field should be call-used.  We\n-     ignore any kind of memory tag, as these are not real variables.  */\n-\n+  /* No local variable nor structure field should be call-used.  */\n   FOR_EACH_REFERENCED_VAR (var, rvi)\n     {\n       if (!is_global_var (var)\n-\t  && !MTAG_P (var)\n-\t  && (gimple_aliases_computed_p (cfun)? is_call_used (var)\n-\t      : TREE_ADDRESSABLE (var)))\n+\t  && is_call_used (var))\n \treturn false;\n     }\n \n@@ -410,11 +406,9 @@ find_tail_calls (basic_block bb, struct tailcall **ret)\n \t  break;\n \t}\n \n-      /* If the statement has virtual or volatile operands, fail.  */\n-      if (!ZERO_SSA_OPERANDS (stmt, (SSA_OP_VUSE | SSA_OP_VIRTUAL_DEFS))\n-\t  || gimple_has_volatile_ops (stmt)\n-\t  || (!gimple_aliases_computed_p (cfun)\n-\t      && gimple_references_memory_p (stmt)))\n+      /* If the statement references memory or volatile operands, fail.  */\n+      if (gimple_references_memory_p (stmt)\n+\t  || gimple_has_volatile_ops (stmt))\n \treturn;\n     }\n \n@@ -914,8 +908,10 @@ tree_optimize_tail_calls_1 (bool opt_tailcalls)\n \n       if (!phis_constructed)\n \t{\n-\t  /* Ensure that there is only one predecessor of the block.  */\n-\t  if (!single_pred_p (first))\n+\t  /* Ensure that there is only one predecessor of the block\n+\t     or if there are existing degenerate PHI nodes.  */\n+\t  if (!single_pred_p (first)\n+\t      || !gimple_seq_empty_p (phi_nodes (first)))\n \t    first = split_edge (single_succ_edge (ENTRY_BLOCK_PTR));\n \n \t  /* Copy the args if needed.  */"}, {"sha": "637075cbb656e6702d7354d89832a77b941402c5", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 23, "deletions": 42, "changes": 65, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1815,16 +1815,6 @@ vect_analyze_data_refs (loop_vec_info loop_vinfo)\n           return false;\n         }\n \n-      if (!DR_SYMBOL_TAG (dr))\n-        {\n-          if (vect_print_dump_info (REPORT_UNVECTORIZED_LOOPS))\n-            {\n-              fprintf (vect_dump, \"not vectorized: no memory tag for \");\n-              print_generic_expr (vect_dump, DR_REF (dr), TDF_SLIM);\n-            }\n-          return false;\n-        }\n-\n       base = unshare_expr (DR_BASE_ADDRESS (dr));\n       offset = unshare_expr (DR_OFFSET (dr));\n       init = unshare_expr (DR_INIT (dr));\n@@ -2186,7 +2176,7 @@ vect_create_addr_base_for_vector_ref (gimple stmt,\n tree\n vect_create_data_ref_ptr (gimple stmt, struct loop *at_loop,\n \t\t\t  tree offset, tree *initial_address, gimple *ptr_incr,\n-\t\t\t  bool only_init, bool *inv_p, tree type)\n+\t\t\t  bool only_init, bool *inv_p)\n {\n   tree base_name;\n   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n@@ -2197,7 +2187,6 @@ vect_create_data_ref_ptr (gimple stmt, struct loop *at_loop,\n   tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n   tree vect_ptr_type;\n   tree vect_ptr;\n-  tree tag;\n   tree new_temp;\n   gimple vec_stmt;\n   gimple_seq new_stmt_list = NULL;\n@@ -2245,42 +2234,34 @@ vect_create_data_ref_ptr (gimple stmt, struct loop *at_loop,\n     }\n \n   /** (1) Create the new vector-pointer variable:  **/\n-  if (type)\n-    vect_ptr_type = build_pointer_type (type);\n-  else\n-    vect_ptr_type = build_pointer_type (vectype);\n-\n-  if (TREE_CODE (DR_BASE_ADDRESS (dr)) == SSA_NAME\n-      && TYPE_RESTRICT (TREE_TYPE (DR_BASE_ADDRESS (dr))))\n-    vect_ptr_type = build_qualified_type (vect_ptr_type, TYPE_QUAL_RESTRICT);\n+  vect_ptr_type = build_pointer_type (vectype);\n   vect_ptr = vect_get_new_vect_var (vect_ptr_type, vect_pointer_var,\n                                     get_name (base_name));\n-  if (TREE_CODE (DR_BASE_ADDRESS (dr)) == SSA_NAME\n-      && TYPE_RESTRICT (TREE_TYPE (DR_BASE_ADDRESS (dr))))\n+  /* If any of the data-references in the stmt group does not conflict\n+     with the created vector data-reference use a ref-all pointer instead.  */\n+  if (STMT_VINFO_DR_GROUP_SIZE (stmt_info) > 1)\n     {\n-      get_alias_set (base_name);\n-      DECL_POINTER_ALIAS_SET (vect_ptr)\n-\t= DECL_POINTER_ALIAS_SET (SSA_NAME_VAR (DR_BASE_ADDRESS (dr)));\n+      gimple orig_stmt = STMT_VINFO_DR_GROUP_FIRST_DR (stmt_info);\n+      do\n+\t{\n+\t  tree lhs = gimple_assign_lhs (orig_stmt);\n+\t  if (!alias_sets_conflict_p (get_deref_alias_set (vect_ptr),\n+\t\t\t\t      get_alias_set (lhs)))\n+\t    {\n+\t      vect_ptr_type = build_pointer_type_for_mode (vectype,\n+\t\t\t\t\t\t\t   ptr_mode, true);\n+\t      vect_ptr = vect_get_new_vect_var (vect_ptr_type, vect_pointer_var,\n+\t\t\t\t\t\tget_name (base_name));\n+\t      break;\n+\t    }\n+\n+\t  orig_stmt = STMT_VINFO_DR_GROUP_NEXT_DR (vinfo_for_stmt (orig_stmt));\n+\t}\n+      while (orig_stmt);\n     }\n \n   add_referenced_var (vect_ptr);\n \n-  /** (2) Add aliasing information to the new vector-pointer:\n-          (The points-to info (DR_PTR_INFO) may be defined later.)  **/\n-  \n-  tag = DR_SYMBOL_TAG (dr);\n-  gcc_assert (tag);\n-\n-  /* If tag is a variable (and NOT_A_TAG) than a new symbol memory\n-     tag must be created with tag added to its may alias list.  */\n-  if (!MTAG_P (tag))\n-    new_type_alias (vect_ptr, tag, DR_REF (dr));\n-  else\n-    {\n-      set_symbol_mem_tag (vect_ptr, tag);\n-      mark_sym_for_renaming (tag);\n-    }\n-\n   /** Note: If the dataref is in an inner-loop nested in LOOP, and we are\n       vectorizing LOOP (i.e. outer-loop vectorization), we need to create two\n       def-use update cycles for the pointer: One relative to the outer-loop\n@@ -2858,7 +2839,7 @@ vect_setup_realignment (gimple stmt, gimple_stmt_iterator *gsi,\n       pe = loop_preheader_edge (loop_for_initial_load);\n       vec_dest = vect_create_destination_var (scalar_dest, vectype);\n       ptr = vect_create_data_ref_ptr (stmt, loop_for_initial_load, NULL_TREE,\n-\t\t                  &init_addr, &inc, true, &inv_p, NULL_TREE);\n+\t\t\t\t      &init_addr, &inc, true, &inv_p);\n       data_ref = build1 (ALIGN_INDIRECT_REF, vectype, ptr);\n       new_stmt = gimple_build_assign (vec_dest, data_ref);\n       new_temp = make_ssa_name (vec_dest, new_stmt);"}, {"sha": "16a340c7738a0c57ef80a59fabf2fafc53294551", "filename": "gcc/tree-vect-loop-manip.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-loop-manip.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-loop-manip.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop-manip.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -841,7 +841,7 @@ slpeel_can_duplicate_loop_p (const struct loop *loop, const_edge e)\n   gimple orig_cond = get_loop_exit_condition (loop);\n   gimple_stmt_iterator loop_exit_gsi = gsi_last_bb (exit_e->src);\n \n-  if (need_ssa_update_p ())\n+  if (need_ssa_update_p (cfun))\n     return false;\n \n   if (loop->inner"}, {"sha": "058438dc5e988ce50bff95652b20e19f6268d3f0", "filename": "gcc/tree-vect-slp.c", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-slp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-slp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-slp.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -1307,8 +1307,6 @@ vect_create_mask_and_perm (gimple stmt, gimple next_scalar_stmt,\n   stmt_vec_info next_stmt_info;\n   int i, group_size, stride, dr_chain_size;\n   tree first_vec, second_vec, data_ref;\n-  tree sym;\n-  ssa_op_iter iter;\n   VEC (tree, heap) *params = NULL;\n \n   /* Create a vector mask.  */\n@@ -1346,12 +1344,6 @@ vect_create_mask_and_perm (gimple stmt, gimple next_scalar_stmt,\n       data_ref = make_ssa_name (perm_dest, perm_stmt);\n       gimple_call_set_lhs (perm_stmt, data_ref);\n       vect_finish_stmt_generation (stmt, perm_stmt, gsi);\n-      FOR_EACH_SSA_TREE_OPERAND (sym, perm_stmt, iter, SSA_OP_ALL_VIRTUALS)\n-        {\n-          if (TREE_CODE (sym) == SSA_NAME)\n-            sym = SSA_NAME_VAR (sym);\n-          mark_sym_for_renaming (sym);\n-        }\n \n       /* Store the vector statement in NODE.  */ \n       VEC_replace (gimple, SLP_TREE_VEC_STMTS (node), "}, {"sha": "26748c9bf061ca9089cb5bc27fe92f256916e022", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 14, "deletions": 28, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -126,7 +126,7 @@ vect_stmt_relevant_p (gimple stmt, loop_vec_info loop_vinfo,\n \n   /* changing memory.  */\n   if (gimple_code (stmt) != GIMPLE_PHI)\n-    if (!ZERO_SSA_OPERANDS (stmt, SSA_OP_VIRTUAL_DEFS))\n+    if (gimple_vdef (stmt))\n       {\n \tif (vect_print_dump_info (REPORT_DETAILS))\n \t  fprintf (vect_dump, \"vec_stmt_relevant_p: stmt has vdefs.\");\n@@ -1270,7 +1270,7 @@ vectorizable_call (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt)\n       return false;\n     }\n \n-  gcc_assert (ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS));\n+  gcc_assert (!gimple_vuse (stmt));\n \n   if (modifier == NARROW)\n     ncopies = LOOP_VINFO_VECT_FACTOR (loop_vinfo) / nunits_out;\n@@ -1436,8 +1436,6 @@ vect_gen_widened_results_half (enum tree_code code,\n { \n   gimple new_stmt;\n   tree new_temp; \n-  tree sym; \n-  ssa_op_iter iter;\n  \n   /* Generate half of the widened result:  */ \n   if (code == CALL_EXPR) \n@@ -1463,16 +1461,6 @@ vect_gen_widened_results_half (enum tree_code code,\n     } \n   vect_finish_stmt_generation (stmt, new_stmt, gsi);\n \n-  if (code == CALL_EXPR)\n-    {\n-      FOR_EACH_SSA_TREE_OPERAND (sym, new_stmt, iter, SSA_OP_ALL_VIRTUALS)\n-        {\n-          if (TREE_CODE (sym) == SSA_NAME)\n-            sym = SSA_NAME_VAR (sym);\n-          mark_sym_for_renaming (sym);\n-        }\n-    }\n-\n   return new_stmt;\n }\n \n@@ -1637,9 +1625,6 @@ vectorizable_conversion (gimple stmt, gimple_stmt_iterator *gsi,\n     case NONE:\n       for (j = 0; j < ncopies; j++)\n \t{\n-\t  tree sym;\n-\t  ssa_op_iter iter;\n-\n \t  if (j == 0)\n \t    vect_get_vec_defs (op0, NULL, stmt, &vec_oprnds0, NULL, slp_node); \n \t  else\n@@ -1654,13 +1639,6 @@ vectorizable_conversion (gimple stmt, gimple_stmt_iterator *gsi,\n \t      new_temp = make_ssa_name (vec_dest, new_stmt);\n \t      gimple_call_set_lhs (new_stmt, new_temp);\n \t      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\t      FOR_EACH_SSA_TREE_OPERAND (sym, new_stmt, iter, \n-\t\t\t\t\t SSA_OP_ALL_VIRTUALS)\n-\t\t{\n-\t\t  if (TREE_CODE (sym) == SSA_NAME)\n-\t\t    sym = SSA_NAME_VAR (sym);\n-\t\t  mark_sym_for_renaming (sym);\n-\t\t}\n \t      if (slp_node)\n \t\tVEC_quick_push (gimple, SLP_TREE_VEC_STMTS (slp_node), new_stmt);\n \t    }\n@@ -3071,7 +3049,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t\t\t\t\t\t TREE_TYPE (vec_oprnd)));\n \t  dataref_ptr = vect_create_data_ref_ptr (first_stmt, NULL, NULL_TREE, \n \t\t\t\t\t\t  &dummy, &ptr_incr, false, \n-\t\t\t\t\t\t  &inv_p, NULL);\n+\t\t\t\t\t\t  &inv_p);\n \t  gcc_assert (!inv_p);\n \t}\n       else \n@@ -3120,6 +3098,10 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t    vec_oprnd = VEC_index (tree, result_chain, i);\n \n \t  data_ref = build_fold_indirect_ref (dataref_ptr);\n+\t  /* If accesses through a pointer to vectype do not alias the original\n+\t     memory reference we have a problem.  This should never happen.  */\n+\t  gcc_assert (alias_sets_conflict_p (get_alias_set (data_ref),\n+\t\t      get_alias_set (gimple_assign_lhs (stmt))));\n \n \t  /* Arguments are ready. Create the new vector stmt.  */\n \t  new_stmt = gimple_build_assign (data_ref, vec_oprnd);\n@@ -3456,7 +3438,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n         dataref_ptr = vect_create_data_ref_ptr (first_stmt,\n \t\t\t\t\t        at_loop, offset, \n \t\t\t\t\t\t&dummy, &ptr_incr, false, \n-\t\t\t\t\t\t&inv_p, NULL_TREE);\n+\t\t\t\t\t\t&inv_p);\n       else\n         dataref_ptr = \n \t\tbump_vector_ptr (dataref_ptr, ptr_incr, gsi, stmt, NULL_TREE);\n@@ -3500,9 +3482,9 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t\tnew_stmt = gimple_build_assign (vec_dest, data_ref);\n \t\tnew_temp = make_ssa_name (vec_dest, new_stmt);\n \t\tgimple_assign_set_lhs (new_stmt, new_temp);\n+\t\tgimple_set_vdef (new_stmt, gimple_vdef (stmt));\n+\t\tgimple_set_vuse (new_stmt, gimple_vuse (stmt));\n \t\tvect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\t\tcopy_virtual_operands (new_stmt, stmt);\n-\t\tmark_symbols_for_renaming (new_stmt);\n \t\tmsq = new_temp;\n \n \t\tbump = size_binop (MULT_EXPR, vs_minus_1,\n@@ -3517,6 +3499,10 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t    default:\n \t      gcc_unreachable ();\n \t    }\n+\t  /* If accesses through a pointer to vectype do not alias the original\n+\t     memory reference we have a problem.  This should never happen. */\n+\t  gcc_assert (alias_sets_conflict_p (get_alias_set (data_ref),\n+\t\t      get_alias_set (gimple_assign_rhs1 (stmt))));\n \t  vec_dest = vect_create_destination_var (scalar_dest, vectype);\n \t  new_stmt = gimple_build_assign (vec_dest, data_ref);\n \t  new_temp = make_ssa_name (vec_dest, new_stmt);"}, {"sha": "0cf78621bdc46cb122827a55bd9feb9bfb78376b", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -757,7 +757,7 @@ extern bool vect_analyze_data_ref_accesses (loop_vec_info);\n extern bool vect_prune_runtime_alias_test_list (loop_vec_info);\n extern bool vect_analyze_data_refs (loop_vec_info);\n extern tree vect_create_data_ref_ptr (gimple, struct loop *, tree, tree *,\n-                                      gimple *, bool, bool *, tree);\n+                                      gimple *, bool, bool *);\n extern tree bump_vector_ptr (tree, gimple, gimple_stmt_iterator *, gimple, tree);\n extern tree vect_create_destination_var (tree, tree);\n extern bool vect_strided_store_supported (tree);"}, {"sha": "cceea2549a35317028f253530491c9e767887567", "filename": "gcc/tree-vrp.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vrp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree-vrp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vrp.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -5278,7 +5278,7 @@ stmt_interesting_for_vrp (gimple stmt)\n \t  && ((is_gimple_call (stmt)\n \t       && gimple_call_fndecl (stmt) != NULL_TREE\n \t       && DECL_IS_BUILTIN (gimple_call_fndecl (stmt)))\n-\t      || ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS)))\n+\t      || !gimple_vuse (stmt)))\n \treturn true;\n     }\n   else if (gimple_code (stmt) == GIMPLE_COND\n@@ -6097,7 +6097,7 @@ vrp_visit_stmt (gimple stmt, edge *taken_edge_p, tree *output_p)\n       if ((is_gimple_call (stmt)\n \t   && gimple_call_fndecl (stmt) != NULL_TREE\n \t   && DECL_IS_BUILTIN (gimple_call_fndecl (stmt)))\n-\t  || ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS))\n+\t  || !gimple_vuse (stmt))\n \treturn vrp_visit_assignment_or_call (stmt, output_p);\n     }\n   else if (gimple_code (stmt) == GIMPLE_COND)"}, {"sha": "a66479d5e5a16a2a476d0803fde7ef8bfd9a9b16", "filename": "gcc/tree.c", "status": "modified", "additions": 2, "deletions": 22, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -320,15 +320,6 @@ init_ttree (void)\n   tree_contains_struct[TRANSLATION_UNIT_DECL][TS_DECL_MINIMAL] = 1;\n   tree_contains_struct[LABEL_DECL][TS_DECL_MINIMAL] = 1;\n   tree_contains_struct[FIELD_DECL][TS_DECL_MINIMAL] = 1;\n-  tree_contains_struct[NAME_MEMORY_TAG][TS_DECL_MINIMAL] = 1;\n-  tree_contains_struct[SYMBOL_MEMORY_TAG][TS_DECL_MINIMAL] = 1;\n-  tree_contains_struct[MEMORY_PARTITION_TAG][TS_DECL_MINIMAL] = 1;\n-\n-  tree_contains_struct[NAME_MEMORY_TAG][TS_MEMORY_TAG] = 1;\n-  tree_contains_struct[SYMBOL_MEMORY_TAG][TS_MEMORY_TAG] = 1;\n-  tree_contains_struct[MEMORY_PARTITION_TAG][TS_MEMORY_TAG] = 1;\n-\n-  tree_contains_struct[MEMORY_PARTITION_TAG][TS_MEMORY_PARTITION_TAG] = 1;\n \n   tree_contains_struct[VAR_DECL][TS_DECL_WITH_VIS] = 1;\n   tree_contains_struct[FUNCTION_DECL][TS_DECL_WITH_VIS] = 1;\n@@ -465,11 +456,6 @@ tree_code_size (enum tree_code code)\n \t    return sizeof (struct tree_type_decl);\n \t  case FUNCTION_DECL:\n \t    return sizeof (struct tree_function_decl);\n-\t  case NAME_MEMORY_TAG:\n-\t  case SYMBOL_MEMORY_TAG:\n-\t    return sizeof (struct tree_memory_tag);\n-\t  case MEMORY_PARTITION_TAG:\n-\t    return sizeof (struct tree_memory_partition_tag);\n \t  default:\n \t    return sizeof (struct tree_decl_non_common);\n \t  }\n@@ -2409,10 +2395,6 @@ tree_node_structure (const_tree t)\n \t    return TS_TYPE_DECL;\n \t  case FUNCTION_DECL:\n \t    return TS_FUNCTION_DECL;\n-\t  case SYMBOL_MEMORY_TAG:\n-\t  case NAME_MEMORY_TAG:\n-\t  case MEMORY_PARTITION_TAG:\n-\t    return TS_MEMORY_TAG;\n \t  default:\n \t    return TS_DECL_NON_COMMON;\n \t  }\n@@ -3433,9 +3415,8 @@ build5_stat (enum tree_code code, tree tt, tree arg0, tree arg1,\n }\n \n tree\n-build7_stat (enum tree_code code, tree tt, tree arg0, tree arg1,\n-\t     tree arg2, tree arg3, tree arg4, tree arg5,\n-\t     tree arg6 MEM_STAT_DECL)\n+build6_stat (enum tree_code code, tree tt, tree arg0, tree arg1,\n+\t     tree arg2, tree arg3, tree arg4, tree arg5 MEM_STAT_DECL)\n {\n   bool constant, read_only, side_effects;\n   tree t;\n@@ -3453,7 +3434,6 @@ build7_stat (enum tree_code code, tree tt, tree arg0, tree arg1,\n   PROCESS_ARG(3);\n   PROCESS_ARG(4);\n   PROCESS_ARG(5);\n-  PROCESS_ARG(6);\n \n   TREE_SIDE_EFFECTS (t) = side_effects;\n   TREE_THIS_VOLATILE (t) = 0;"}, {"sha": "a4c524e1807f823fd14f60b4d086dbcc7a37df7d", "filename": "gcc/tree.def", "status": "modified", "additions": 2, "deletions": 9, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.def?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -361,12 +361,6 @@ DEFTREECODE (PARM_DECL, \"parm_decl\", tcc_declaration, 0)\n DEFTREECODE (TYPE_DECL, \"type_decl\", tcc_declaration, 0)\n DEFTREECODE (RESULT_DECL, \"result_decl\", tcc_declaration, 0)\n \n-/* Memory tags used in tree-ssa to represent memory locations in\n-   virtual SSA.  */\n-DEFTREECODE (NAME_MEMORY_TAG, \"name_memory_tag\", tcc_declaration, 0)\n-DEFTREECODE (SYMBOL_MEMORY_TAG, \"symbol_memory_tag\", tcc_declaration, 0)\n-DEFTREECODE (MEMORY_PARTITION_TAG, \"memory_partition_tag\", tcc_declaration, 0)\n-\n /* A namespace declaration.  Namespaces appear in DECL_CONTEXT of other\n    _DECLs, providing a hierarchy of names.  */\n DEFTREECODE (NAMESPACE_DECL, \"namespace_decl\", tcc_declaration, 0)\n@@ -992,10 +986,9 @@ DEFTREECODE (REALIGN_LOAD_EXPR, \"realign_load\", tcc_expression, 3)\n    sizetype or a pointer type (if SYMBOL is NULL).\n    \n    The sixth argument is the reference to the original memory access, which\n-   is preserved for the purposes of the RTL alias analysis.  The seventh\n-   argument is a tag representing results of the tree level alias analysis.  */\n+   is preserved for the purposes of the RTL alias analysis.  */\n \n-DEFTREECODE (TARGET_MEM_REF, \"target_mem_ref\", tcc_reference, 7)\n+DEFTREECODE (TARGET_MEM_REF, \"target_mem_ref\", tcc_reference, 6)\n \n /* The ordering of the codes between OMP_PARALLEL and OMP_CRITICAL is\n    exposed to TREE_RANGE_CHECK.  */"}, {"sha": "b191d43d0460f9c8d9a47d2082682ba811961dcc", "filename": "gcc/tree.h", "status": "modified", "additions": 5, "deletions": 62, "changes": 67, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -105,14 +105,6 @@ extern const enum tree_code_class tree_code_type[];\n #define DECL_P(CODE)\\\n         (TREE_CODE_CLASS (TREE_CODE (CODE)) == tcc_declaration)\n \n-/* Nonzero if CODE represents a memory tag.  */\n-\n-#define MTAG_P(CODE) \\\n-  (TREE_CODE (CODE) == NAME_MEMORY_TAG\t\t\\\n-   || TREE_CODE (CODE) == SYMBOL_MEMORY_TAG\t\\\n-   || TREE_CODE (CODE) == MEMORY_PARTITION_TAG)\n-\n-\n /* Nonzero if DECL represents a VAR_DECL or FUNCTION_DECL.  */\n \n #define VAR_OR_FUNCTION_DECL_P(DECL)\\\n@@ -933,7 +925,6 @@ extern void omp_clause_range_check_failed (const_tree, const char *, int,\n \n #define TYPE_CHECK(T)\t\tTREE_CLASS_CHECK (T, tcc_type)\n #define DECL_MINIMAL_CHECK(T)   CONTAINS_STRUCT_CHECK (T, TS_DECL_MINIMAL)\n-#define TREE_MEMORY_TAG_CHECK(T)       CONTAINS_STRUCT_CHECK (T, TS_MEMORY_TAG)\n #define DECL_COMMON_CHECK(T)    CONTAINS_STRUCT_CHECK (T, TS_DECL_COMMON)\n #define DECL_WRTL_CHECK(T)      CONTAINS_STRUCT_CHECK (T, TS_DECL_WRTL)\n #define DECL_WITH_VIS_CHECK(T)  CONTAINS_STRUCT_CHECK (T, TS_DECL_WITH_VIS)\n@@ -1613,7 +1604,6 @@ extern void protected_set_expr_location (tree, location_t);\n #define TMR_STEP(NODE) (TREE_OPERAND (TARGET_MEM_REF_CHECK (NODE), 3))\n #define TMR_OFFSET(NODE) (TREE_OPERAND (TARGET_MEM_REF_CHECK (NODE), 4))\n #define TMR_ORIGINAL(NODE) (TREE_OPERAND (TARGET_MEM_REF_CHECK (NODE), 5))\n-#define TMR_TAG(NODE) (TREE_OPERAND (TARGET_MEM_REF_CHECK (NODE), 6))\n \n /* The operands of a BIND_EXPR.  */\n #define BIND_EXPR_VARS(NODE) (TREE_OPERAND (BIND_EXPR_CHECK (NODE), 0))\n@@ -2438,12 +2428,10 @@ struct tree_binfo GTY (())\n \t(TREE_CODE (DECL) == VAR_DECL\t\t\t\t\t\\\n \t || TREE_CODE (DECL) == PARM_DECL\t\t\t\t\\\n \t || TREE_CODE (DECL) == RESULT_DECL\t\t\t\t\\\n-\t || MTAG_P (DECL)\t\t\t\t\t\t\\\n \t || (TREE_CODE (DECL) == SSA_NAME\t\t\t\t\\\n \t     && (TREE_CODE (SSA_NAME_VAR (DECL)) == VAR_DECL\t\t\\\n \t\t || TREE_CODE (SSA_NAME_VAR (DECL)) == PARM_DECL\t\\\n-\t\t || TREE_CODE (SSA_NAME_VAR (DECL)) == RESULT_DECL\t\\\n-\t\t || MTAG_P (SSA_NAME_VAR (DECL)))))\n+\t\t || TREE_CODE (SSA_NAME_VAR (DECL)) == RESULT_DECL)))\n \n \n \n@@ -2498,49 +2486,6 @@ struct tree_decl_minimal GTY(())\n   tree context;\n };\n \n-/* When computing aliasing information, we represent the memory pointed-to\n-   by pointers with artificial variables called \"memory tags\" (MT).  There\n-   are two kinds of tags, namely symbol and name:\n-\n-   Symbol tags (SMT) are used in flow-insensitive alias analysis, they\n-   represent all the pointed-to locations and variables pointed-to by\n-   the same pointer symbol.  Usually, this set is computed using\n-   type-based analysis (i.e., alias set classes), but this may not\n-   always be the case.\n-\n-   Name tags (NMT) are used in flow-sensitive points-to alias\n-   analysis, they represent the variables and memory locations\n-   pointed-to by a specific SSA_NAME pointer.\n-\n-   In general, given a pointer P with a symbol tag SMT, the alias set\n-   of SMT should be the union of all the alias sets of the NMTs of\n-   every SSA_NAME for P.  */\n-struct tree_memory_tag GTY(())\n-{\n-  struct tree_decl_minimal common;\n-\n-  bitmap GTY ((skip)) aliases;\n-\n-  /* True if this tag has global scope.  */\n-  unsigned int is_global : 1;\n-};\n-\n-#define MTAG_GLOBAL(NODE) (TREE_MEMORY_TAG_CHECK (NODE)->mtag.is_global)\n-#define MTAG_ALIASES(NODE) (TREE_MEMORY_TAG_CHECK (NODE)->mtag.aliases)\n-\n-/* Memory Partition Tags (MPTs) group memory symbols under one\n-   common name for the purposes of placing memory PHI nodes.  */\n-\n-struct tree_memory_partition_tag GTY(())\n-{\n-  struct tree_memory_tag common;\n-  \n-  /* Set of symbols grouped under this MPT.  */\n-  bitmap symbols;\n-};\n-\n-#define MPT_SYMBOLS(NODE)\t(MEMORY_PARTITION_TAG_CHECK (NODE)->mpt.symbols)\n-\n \n /* For any sort of a ..._DECL node, this points to the original (abstract)\n    decl node which this decl is an instance of, or else it is NULL indicating\n@@ -3448,9 +3393,7 @@ union tree_node GTY ((ptr_alias (union lang_tree_node),\n   struct tree_binfo GTY ((tag (\"TS_BINFO\"))) binfo;\n   struct tree_statement_list GTY ((tag (\"TS_STATEMENT_LIST\"))) stmt_list;\n   struct tree_constructor GTY ((tag (\"TS_CONSTRUCTOR\"))) constructor;\n-  struct tree_memory_tag GTY ((tag (\"TS_MEMORY_TAG\"))) mtag;\n   struct tree_omp_clause GTY ((tag (\"TS_OMP_CLAUSE\"))) omp_clause;\n-  struct tree_memory_partition_tag GTY ((tag (\"TS_MEMORY_PARTITION_TAG\"))) mpt;\n   struct tree_optimization_option GTY ((tag (\"TS_OPTIMIZATION\"))) optimization;\n   struct tree_target_option GTY ((tag (\"TS_TARGET_OPTION\"))) target_option;\n };\n@@ -3942,10 +3885,10 @@ extern tree build4_stat (enum tree_code, tree, tree, tree, tree,\n extern tree build5_stat (enum tree_code, tree, tree, tree, tree, tree,\n \t\t\t tree MEM_STAT_DECL);\n #define build5(c,t1,t2,t3,t4,t5,t6) build5_stat (c,t1,t2,t3,t4,t5,t6 MEM_STAT_INFO)\n-extern tree build7_stat (enum tree_code, tree, tree, tree, tree, tree,\n-\t\t\t tree, tree, tree MEM_STAT_DECL);\n-#define build7(c,t1,t2,t3,t4,t5,t6,t7,t8) \\\n-  build7_stat (c,t1,t2,t3,t4,t5,t6,t7,t8 MEM_STAT_INFO)\n+extern tree build6_stat (enum tree_code, tree, tree, tree, tree, tree,\n+\t\t\t tree, tree MEM_STAT_DECL);\n+#define build6(c,t1,t2,t3,t4,t5,t6,t7) \\\n+  build6_stat (c,t1,t2,t3,t4,t5,t6,t7 MEM_STAT_INFO)\n \n extern tree build_int_cst (tree, HOST_WIDE_INT);\n extern tree build_int_cst_type (tree, HOST_WIDE_INT);"}, {"sha": "e920a97b01040072a9d9a30b14ad997543370fa0", "filename": "gcc/treestruct.def", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftreestruct.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5006671f1aaa63cd3f14535e014faa3bca5d20cc/gcc%2Ftreestruct.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftreestruct.def?ref=5006671f1aaa63cd3f14535e014faa3bca5d20cc", "patch": "@@ -60,9 +60,7 @@ DEFTREESTRUCT(TS_BINFO, \"binfo\")\n DEFTREESTRUCT(TS_STATEMENT_LIST, \"statement list\")\n DEFTREESTRUCT(TS_GIMPLE_STATEMENT, \"gimple statement\")\n DEFTREESTRUCT(TS_CONSTRUCTOR, \"constructor\")\n-DEFTREESTRUCT(TS_MEMORY_TAG, \"memory tag\")\n DEFTREESTRUCT(TS_OMP_CLAUSE, \"omp clause\")\n-DEFTREESTRUCT(TS_MEMORY_PARTITION_TAG, \"memory partition tag\")\n DEFTREESTRUCT(TS_OPTIMIZATION, \"optimization options\")\n DEFTREESTRUCT(TS_TARGET_OPTION, \"target options\")\n "}]}