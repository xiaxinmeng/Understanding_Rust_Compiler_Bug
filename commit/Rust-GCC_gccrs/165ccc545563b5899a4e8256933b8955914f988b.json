{"sha": "165ccc545563b5899a4e8256933b8955914f988b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTY1Y2NjNTQ1NTYzYjU4OTlhNGU4MjU2OTMzYjg5NTU5MTRmOTg4Yg==", "commit": {"author": {"name": "Trevor Saunders", "email": "tbsaunde+gcc@tbsaunde.org", "date": "2015-10-07T02:11:17Z"}, "committer": {"name": "Trevor Saunders", "email": "tbsaunde@gcc.gnu.org", "date": "2015-10-07T02:11:17Z"}, "message": "reorg.c: use vec<rtx_insn *> instead of rtx_insn_list for the delay insn list\n\ngcc/ChangeLog:\n\n2015-10-06  Trevor Saunders  <tbsaunde+gcc@tbsaunde.org>\n\n\t* reorg.c (emit_delay_sequence): Store list of delay slot insns\n\tin a vector instead of rtx_insn_list.\n\t(add_to_delay_list): Likewise.\n\t(delete_from_delay_slot): Likewise.\n\t(optimize_skip): Likewise.\n\t(redirect_with_delay_list_safe_p): Likewise.\n\t(check_annul_list_true_false): Likewise.\n\t(steal_delay_list_from_target): Likewise.\n\t(steal_delay_list_from_fallthrough): Likewise.\n\t(redundant_insn): Likewise.\n\t(fill_simple_delay_slots): Likewise.\n\t(fill_slots_from_thread): Likewise.\n\t(fill_eager_delay_slots): Likewise.\n\t(relax_delay_slots): Likewise.\n\nFrom-SVN: r228558", "tree": {"sha": "e9c9a2bb7b696946b05ffbd7bedbd352120814ee", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e9c9a2bb7b696946b05ffbd7bedbd352120814ee"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/165ccc545563b5899a4e8256933b8955914f988b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/165ccc545563b5899a4e8256933b8955914f988b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/165ccc545563b5899a4e8256933b8955914f988b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/165ccc545563b5899a4e8256933b8955914f988b/comments", "author": null, "committer": null, "parents": [{"sha": "8237beb118c5b5a724a459584975a11c3234c1c7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8237beb118c5b5a724a459584975a11c3234c1c7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8237beb118c5b5a724a459584975a11c3234c1c7"}], "stats": {"total": 373, "additions": 172, "deletions": 201}, "files": [{"sha": "732b3d18c13731ad40ae0fb66545752aefff0c03", "filename": "gcc/ChangeLog", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/165ccc545563b5899a4e8256933b8955914f988b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/165ccc545563b5899a4e8256933b8955914f988b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=165ccc545563b5899a4e8256933b8955914f988b", "patch": "@@ -1,3 +1,20 @@\n+2015-10-06  Trevor Saunders  <tbsaunde+gcc@tbsaunde.org>\n+\n+\t* reorg.c (emit_delay_sequence): Store list of delay slot insns\n+\tin a vector instead of rtx_insn_list.\n+\t(add_to_delay_list): Likewise.\n+\t(delete_from_delay_slot): Likewise.\n+\t(optimize_skip): Likewise.\n+\t(redirect_with_delay_list_safe_p): Likewise.\n+\t(check_annul_list_true_false): Likewise.\n+\t(steal_delay_list_from_target): Likewise.\n+\t(steal_delay_list_from_fallthrough): Likewise.\n+\t(redundant_insn): Likewise.\n+\t(fill_simple_delay_slots): Likewise.\n+\t(fill_slots_from_thread): Likewise.\n+\t(fill_eager_delay_slots): Likewise.\n+\t(relax_delay_slots): Likewise.\n+\n 2015-10-06  Sandra Loosemore  <sandra@codesourcery.com>\n \n \t* config/nios2/nios2.c (nios2_symbol_ref_in_small_data_p):"}, {"sha": "c51e03cf366effb8f5be3cb2a12ec9df25e55a53", "filename": "gcc/reorg.c", "status": "modified", "additions": 155, "deletions": 201, "changes": 356, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/165ccc545563b5899a4e8256933b8955914f988b/gcc%2Freorg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/165ccc545563b5899a4e8256933b8955914f988b/gcc%2Freorg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freorg.c?ref=165ccc545563b5899a4e8256933b8955914f988b", "patch": "@@ -213,48 +213,48 @@ static int resource_conflicts_p (struct resources *, struct resources *);\n static int insn_references_resource_p (rtx, struct resources *, bool);\n static int insn_sets_resource_p (rtx, struct resources *, bool);\n static rtx_code_label *find_end_label (rtx);\n-static rtx_insn *emit_delay_sequence (rtx_insn *, rtx_insn_list *, int);\n-static rtx_insn_list *add_to_delay_list (rtx_insn *, rtx_insn_list *);\n+static rtx_insn *emit_delay_sequence (rtx_insn *, const vec<rtx_insn *> &,\n+\t\t\t\t      int);\n+static void add_to_delay_list (rtx_insn *, vec<rtx_insn *> *);\n static rtx_insn *delete_from_delay_slot (rtx_insn *);\n static void delete_scheduled_jump (rtx_insn *);\n static void note_delay_statistics (int, int);\n #if defined(ANNUL_IFFALSE_SLOTS) || defined(ANNUL_IFTRUE_SLOTS)\n-static rtx_insn_list *optimize_skip (rtx_jump_insn *);\n+static void optimize_skip (rtx_jump_insn *, vec<rtx_insn *> *);\n #endif\n static int get_jump_flags (const rtx_insn *, rtx);\n static int mostly_true_jump (rtx);\n static rtx get_branch_condition (const rtx_insn *, rtx);\n static int condition_dominates_p (rtx, const rtx_insn *);\n static int redirect_with_delay_slots_safe_p (rtx_insn *, rtx, rtx);\n-static int redirect_with_delay_list_safe_p (rtx_insn *, rtx, rtx_insn_list *);\n-static int check_annul_list_true_false (int, rtx);\n-static rtx_insn_list *steal_delay_list_from_target (rtx_insn *, rtx,\n-\t\t\t\t\t\t    rtx_sequence *,\n-\t\t\t\t\t\t    rtx_insn_list *,\n-\t\t\t\t\t\t    struct resources *,\n-\t\t\t\t\t\t    struct resources *,\n-\t\t\t\t\t\t    struct resources *,\n-\t\t\t\t\t\t    int, int *, int *,\n-\t\t\t\t\t\t    rtx *);\n-static rtx_insn_list *steal_delay_list_from_fallthrough (rtx_insn *, rtx,\n-\t\t\t\t\t\t\t rtx_sequence *,\n-\t\t\t\t\t\t\t rtx_insn_list *,\n-\t\t\t\t\t\t\t struct resources *,\n-\t\t\t\t\t\t\t struct resources *,\n-\t\t\t\t\t\t\t struct resources *,\n-\t\t\t\t\t\t\t int, int *, int *);\n+static int redirect_with_delay_list_safe_p (rtx_insn *, rtx,\n+\t\t\t\t\t    const vec<rtx_insn *> &);\n+static int check_annul_list_true_false (int, const vec<rtx_insn *> &);\n+static void steal_delay_list_from_target (rtx_insn *, rtx, rtx_sequence *,\n+\t\t\t\t\t  vec<rtx_insn *> *,\n+\t\t\t\t\t  struct resources *,\n+\t\t\t\t\t  struct resources *,\n+\t\t\t\t\t  struct resources *,\n+\t\t\t\t\t  int, int *, int *,\n+\t\t\t\t\t  rtx *);\n+static void steal_delay_list_from_fallthrough (rtx_insn *, rtx, rtx_sequence *,\n+\t\t\t\t\t       vec<rtx_insn *> *,\n+\t\t\t\t\t       struct resources *,\n+\t\t\t\t\t       struct resources *,\n+\t\t\t\t\t       struct resources *,\n+\t\t\t\t\t       int, int *, int *);\n static void try_merge_delay_insns (rtx_insn *, rtx_insn *);\n-static rtx redundant_insn (rtx, rtx_insn *, rtx);\n+static rtx redundant_insn (rtx, rtx_insn *, const vec<rtx_insn *> &);\n static int own_thread_p (rtx, rtx, int);\n static void update_block (rtx_insn *, rtx);\n static int reorg_redirect_jump (rtx_jump_insn *, rtx);\n static void update_reg_dead_notes (rtx_insn *, rtx_insn *);\n static void fix_reg_dead_note (rtx, rtx);\n static void update_reg_unused_notes (rtx, rtx);\n static void fill_simple_delay_slots (int);\n-static rtx_insn_list *fill_slots_from_thread (rtx_jump_insn *, rtx, rtx, rtx,\n-\t\t\t\t\t      int, int, int, int,\n-\t\t\t\t\t      int *, rtx_insn_list *);\n+static void fill_slots_from_thread (rtx_jump_insn *, rtx, rtx, rtx,\n+\t\t\t\t    int, int, int, int,\n+\t\t\t\t    int *, vec<rtx_insn *> *);\n static void fill_eager_delay_slots (void);\n static void relax_delay_slots (rtx_insn *);\n static void make_return_insns (rtx_insn *);\n@@ -504,7 +504,7 @@ find_end_label (rtx kind)\n    Returns the insn containing the SEQUENCE that replaces INSN.  */\n \n static rtx_insn *\n-emit_delay_sequence (rtx_insn *insn, rtx_insn_list *list, int length)\n+emit_delay_sequence (rtx_insn *insn, const vec<rtx_insn *> &list, int length)\n {\n   /* Allocate the rtvec to hold the insns and the SEQUENCE.  */\n   rtvec seqv = rtvec_alloc (length + 1);\n@@ -523,12 +523,14 @@ emit_delay_sequence (rtx_insn *insn, rtx_insn_list *list, int length)\n   SET_NEXT_INSN (insn) = SET_PREV_INSN (insn) = NULL;\n \n   /* Build our SEQUENCE and rebuild the insn chain.  */\n-  int i = 1;\n   start_sequence ();\n   XVECEXP (seq, 0, 0) = emit_insn (insn);\n-  for (rtx_insn_list *li = list; li; li = li->next (), i++)\n+\n+  unsigned int delay_insns = list.length ();\n+  gcc_assert (delay_insns == (unsigned int) length);\n+  for (unsigned int i = 0; i < delay_insns; i++)\n     {\n-      rtx_insn *tem = li->insn ();\n+      rtx_insn *tem = list[i];\n       rtx note, next;\n \n       /* Show that this copy of the insn isn't deleted.  */\n@@ -537,7 +539,7 @@ emit_delay_sequence (rtx_insn *insn, rtx_insn_list *list, int length)\n       /* Unlink insn from its original place, and re-emit it into\n \t the sequence.  */\n       SET_NEXT_INSN (tem) = SET_PREV_INSN (tem) = NULL;\n-      XVECEXP (seq, 0, i) = emit_insn (tem);\n+      XVECEXP (seq, 0, i + 1) = emit_insn (tem);\n \n       /* SPARC assembler, for instance, emit warning when debug info is output\n          into the delay slot.  */\n@@ -569,7 +571,6 @@ emit_delay_sequence (rtx_insn *insn, rtx_insn_list *list, int length)\n \t}\n     }\n   end_sequence ();\n-  gcc_assert (i == length + 1);\n \n   /* Splice our SEQUENCE into the insn stream where INSN used to be.  */\n   add_insn_after (seq_insn, after, NULL);\n@@ -580,24 +581,13 @@ emit_delay_sequence (rtx_insn *insn, rtx_insn_list *list, int length)\n /* Add INSN to DELAY_LIST and return the head of the new list.  The list must\n    be in the order in which the insns are to be executed.  */\n \n-static rtx_insn_list *\n-add_to_delay_list (rtx_insn *insn, rtx_insn_list *delay_list)\n+static void\n+add_to_delay_list (rtx_insn *insn, vec<rtx_insn *> *delay_list)\n {\n-  /* If we have an empty list, just make a new list element.  If\n-     INSN has its block number recorded, clear it since we may\n+  /* If INSN has its block number recorded, clear it since we may\n      be moving the insn to a new block.  */\n-\n-  if (delay_list == 0)\n-    {\n       clear_hashed_info_for_insn (insn);\n-      return gen_rtx_INSN_LIST (VOIDmode, insn, NULL_RTX);\n-    }\n-\n-  /* Otherwise this must be an INSN_LIST.  Add INSN to the end of the\n-     list.  */\n-  XEXP (delay_list, 1) = add_to_delay_list (insn, delay_list->next ());\n-\n-  return delay_list;\n+      delay_list->safe_push (insn);\n }\n \f\n /* Delete INSN from the delay slot of the insn that it is in, which may\n@@ -608,7 +598,6 @@ delete_from_delay_slot (rtx_insn *insn)\n {\n   rtx_insn *trial, *seq_insn, *prev;\n   rtx_sequence *seq;\n-  rtx_insn_list *delay_list = 0;\n   int i;\n   int had_barrier = 0;\n \n@@ -629,10 +618,11 @@ delete_from_delay_slot (rtx_insn *insn)\n \n   /* Create a delay list consisting of all the insns other than the one\n      we are deleting (unless we were the only one).  */\n+  auto_vec<rtx_insn *, 5> delay_list;\n   if (seq->len () > 2)\n     for (i = 1; i < seq->len (); i++)\n       if (seq->insn (i) != insn)\n-\tdelay_list = add_to_delay_list (seq->insn (i), delay_list);\n+\tadd_to_delay_list (seq->insn (i), &delay_list);\n \n   /* Delete the old SEQUENCE, re-emit the insn that used to have the delay\n      list, and rebuild the delay list if non-empty.  */\n@@ -647,7 +637,7 @@ delete_from_delay_slot (rtx_insn *insn)\n \n   /* If there are any delay insns, remit them.  Otherwise clear the\n      annul flag.  */\n-  if (delay_list)\n+  if (!delay_list.is_empty ())\n     trial = emit_delay_sequence (trial, delay_list, XVECLEN (seq, 0) - 2);\n   else if (JUMP_P (trial))\n     INSN_ANNULLED_BRANCH_P (trial) = 0;\n@@ -761,12 +751,11 @@ note_delay_statistics (int slots_filled, int index)\n    This should be expanded to skip over N insns, where N is the number\n    of delay slots required.  */\n \n-static rtx_insn_list *\n-optimize_skip (rtx_jump_insn *insn)\n+static void\n+optimize_skip (rtx_jump_insn *insn, vec<rtx_insn *> *delay_list)\n {\n   rtx_insn *trial = next_nonnote_insn (insn);\n   rtx_insn *next_trial = next_active_insn (trial);\n-  rtx_insn_list *delay_list = 0;\n   int flags;\n \n   flags = get_jump_flags (insn, JUMP_LABEL (insn));\n@@ -778,7 +767,7 @@ optimize_skip (rtx_jump_insn *insn)\n       || (! eligible_for_annul_false (insn, 0, trial, flags)\n \t  && ! eligible_for_annul_true (insn, 0, trial, flags))\n       || can_throw_internal (trial))\n-    return 0;\n+    return;\n \n   /* There are two cases where we are just executing one insn (we assume\n      here that a branch requires only one insn; this should be generalized\n@@ -796,10 +785,10 @@ optimize_skip (rtx_jump_insn *insn)\n \t  if (invert_jump (insn, JUMP_LABEL (insn), 1))\n \t    INSN_FROM_TARGET_P (trial) = 1;\n \t  else if (! eligible_for_annul_true (insn, 0, trial, flags))\n-\t    return 0;\n+\t    return;\n \t}\n \n-      delay_list = add_to_delay_list (trial, NULL);\n+      add_to_delay_list (trial, delay_list);\n       next_trial = next_active_insn (trial);\n       update_block (trial, trial);\n       delete_related_insns (trial);\n@@ -828,8 +817,6 @@ optimize_skip (rtx_jump_insn *insn)\n \n       INSN_ANNULLED_BRANCH_P (insn) = 1;\n     }\n-\n-  return delay_list;\n }\n #endif\n \f\n@@ -1007,54 +994,47 @@ redirect_with_delay_slots_safe_p (rtx_insn *jump, rtx newlabel, rtx seq)\n \n static int\n redirect_with_delay_list_safe_p (rtx_insn *jump, rtx newlabel,\n-\t\t\t\t rtx_insn_list *delay_list)\n+\t\t\t\t const vec<rtx_insn *> &delay_list)\n {\n-  int flags, i;\n-  rtx_insn_list *li;\n-\n   /* Make sure all the insns in DELAY_LIST would still be\n      valid after threading the jump.  If they are still\n      valid, then return nonzero.  */\n \n-  flags = get_jump_flags (jump, newlabel);\n-  for (li = delay_list, i = 0; li; li = li->next (), i++)\n+  int flags = get_jump_flags (jump, newlabel);\n+  unsigned int delay_insns = delay_list.length ();\n+  unsigned int i = 0;\n+  for (; i < delay_insns; i++)\n     if (! (\n #ifdef ANNUL_IFFALSE_SLOTS\n \t   (INSN_ANNULLED_BRANCH_P (jump)\n-\t    && INSN_FROM_TARGET_P (li->insn ()))\n-\t   ? eligible_for_annul_false (jump, i, li->insn (), flags) :\n+\t    && INSN_FROM_TARGET_P (delay_list[i]))\n+\t   ? eligible_for_annul_false (jump, i, delay_list[i], flags) :\n #endif\n #ifdef ANNUL_IFTRUE_SLOTS\n \t   (INSN_ANNULLED_BRANCH_P (jump)\n-\t    && ! INSN_FROM_TARGET_P (XEXP (li, 0)))\n-\t   ? eligible_for_annul_true (jump, i, li->insn (), flags) :\n+\t    && ! INSN_FROM_TARGET_P (delay_list[i]))\n+\t   ? eligible_for_annul_true (jump, i, delay_list[i], flags) :\n #endif\n-\t   eligible_for_delay (jump, i, li->insn (), flags)))\n+\t   eligible_for_delay (jump, i, delay_list[i], flags)))\n       break;\n \n-  return (li == NULL);\n+  return i == delay_insns;\n }\n \n /* DELAY_LIST is a list of insns that have already been placed into delay\n    slots.  See if all of them have the same annulling status as ANNUL_TRUE_P.\n    If not, return 0; otherwise return 1.  */\n \n static int\n-check_annul_list_true_false (int annul_true_p, rtx delay_list)\n+check_annul_list_true_false (int annul_true_p,\n+\t\t\t     const vec<rtx_insn *> &delay_list)\n {\n-  rtx temp;\n-\n-  if (delay_list)\n-    {\n-      for (temp = delay_list; temp; temp = XEXP (temp, 1))\n-\t{\n-\t  rtx trial = XEXP (temp, 0);\n-\n-\t  if ((annul_true_p && INSN_FROM_TARGET_P (trial))\n-\t      || (!annul_true_p && !INSN_FROM_TARGET_P (trial)))\n-\t    return 0;\n-\t}\n-    }\n+  rtx_insn *trial;\n+  unsigned int i;\n+  FOR_EACH_VEC_ELT (delay_list, i, trial)\n+    if ((annul_true_p && INSN_FROM_TARGET_P (trial))\n+\t|| (!annul_true_p && !INSN_FROM_TARGET_P (trial)))\n+      return 0;\n \n   return 1;\n }\n@@ -1079,17 +1059,17 @@ check_annul_list_true_false (int annul_true_p, rtx delay_list)\n    PNEW_THREAD points to a location that is to receive the place at which\n    execution should continue.  */\n \n-static rtx_insn_list *\n+static void\n steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n-\t\t\t      rtx_insn_list *delay_list, struct resources *sets,\n+\t\t\t      vec<rtx_insn *> *delay_list, resources *sets,\n \t\t\t      struct resources *needed,\n \t\t\t      struct resources *other_needed,\n \t\t\t      int slots_to_fill, int *pslots_filled,\n \t\t\t      int *pannul_p, rtx *pnew_thread)\n {\n   int slots_remaining = slots_to_fill - *pslots_filled;\n   int total_slots_filled = *pslots_filled;\n-  rtx_insn_list *new_delay_list = 0;\n+  auto_vec<rtx_insn *, 5> new_delay_list;\n   int must_annul = *pannul_p;\n   int used_annul = 0;\n   int i;\n@@ -1113,25 +1093,25 @@ steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n      will effect the direction of the jump in the sequence.  */\n \n   CLEAR_RESOURCE (&cc_set);\n-  for (rtx_insn_list *temp = delay_list; temp; temp = temp->next ())\n-    {\n-      rtx_insn *trial = temp->insn ();\n \n+  rtx_insn *trial;\n+  FOR_EACH_VEC_ELT (*delay_list, i, trial)\n+    {\n       mark_set_resources (trial, &cc_set, 0, MARK_SRC_DEST_CALL);\n       if (insn_references_resource_p (seq->insn (0), &cc_set, false))\n-\treturn delay_list;\n+\treturn;\n     }\n \n   if (XVECLEN (seq, 0) - 1 > slots_remaining\n       || ! condition_dominates_p (condition, seq->insn (0))\n       || ! single_set (seq->insn (0)))\n-    return delay_list;\n+    return;\n \n   /* On some targets, branches with delay slots can have a limited\n      displacement.  Give the back end a chance to tell us we can't do\n      this.  */\n   if (! targetm.can_follow_jump (insn, seq->insn (0)))\n-    return delay_list;\n+    return;\n \n   redundant = XALLOCAVEC (bool, XVECLEN (seq, 0));\n   for (i = 1; i < seq->len (); i++)\n@@ -1149,7 +1129,7 @@ steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n \t     in SEQ, we cannot use it.  */\n \t  || (INSN_ANNULLED_BRANCH_P (seq->insn (0))\n \t      && ! INSN_FROM_TARGET_P (trial)))\n-\treturn delay_list;\n+\treturn;\n \n       /* If this insn was already done (usually in a previous delay slot),\n \t pretend we put it in our delay slot.  */\n@@ -1166,9 +1146,9 @@ steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n \t       || (! insn_sets_resource_p (trial, other_needed, false)\n \t\t   && ! may_trap_or_fault_p (PATTERN (trial)))))\n \t  ? eligible_for_delay (insn, total_slots_filled, trial, flags)\n-\t  : (must_annul || (delay_list == NULL && new_delay_list == NULL))\n+\t  : (must_annul || (delay_list->is_empty () && new_delay_list.is_empty ()))\n \t     && (must_annul = 1,\n-\t         check_annul_list_true_false (0, delay_list)\n+\t\t check_annul_list_true_false (0, *delay_list)\n \t         && check_annul_list_true_false (0, new_delay_list)\n \t         && eligible_for_annul_false (insn, total_slots_filled,\n \t\t\t\t\t      trial, flags)))\n@@ -1177,14 +1157,14 @@ steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n \t    used_annul = 1;\n \t  rtx_insn *temp = copy_delay_slot_insn (trial);\n \t  INSN_FROM_TARGET_P (temp) = 1;\n-\t  new_delay_list = add_to_delay_list (temp, new_delay_list);\n+\t  add_to_delay_list (temp, &new_delay_list);\n \t  total_slots_filled++;\n \n \t  if (--slots_remaining == 0)\n \t    break;\n \t}\n       else\n-\treturn delay_list;\n+\treturn;\n     }\n \n   /* Record the effect of the instructions that were redundant and which\n@@ -1202,24 +1182,20 @@ steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n   if (used_annul)\n     *pannul_p = 1;\n \n-  if (delay_list == 0)\n-    return new_delay_list;\n-\n-  for (rtx_insn_list *temp = new_delay_list; temp; temp = temp->next ())\n-    delay_list = add_to_delay_list (temp->insn (), delay_list);\n-\n-  return delay_list;\n+  rtx_insn *temp;\n+  FOR_EACH_VEC_ELT (new_delay_list, i, temp)\n+    add_to_delay_list (temp, delay_list);\n }\n \f\n /* Similar to steal_delay_list_from_target except that SEQ is on the\n    fallthrough path of INSN.  Here we only do something if the delay insn\n    of SEQ is an unconditional branch.  In that case we steal its delay slot\n    for INSN since unconditional branches are much easier to fill.  */\n \n-static rtx_insn_list *\n+static void\n steal_delay_list_from_fallthrough (rtx_insn *insn, rtx condition,\n \t\t\t\t   rtx_sequence *seq,\n-\t\t\t\t   rtx_insn_list *delay_list,\n+\t\t\t\t   vec<rtx_insn *> *delay_list,\n \t\t\t\t   struct resources *sets,\n \t\t\t\t   struct resources *needed,\n \t\t\t\t   struct resources *other_needed,\n@@ -1237,7 +1213,7 @@ steal_delay_list_from_fallthrough (rtx_insn *insn, rtx condition,\n      unconditional branch.  */\n \n   if (! simplejump_or_return_p (seq->insn (0)))\n-    return delay_list;\n+    return;\n \n   for (i = 1; i < seq->len (); i++)\n     {\n@@ -1253,7 +1229,7 @@ steal_delay_list_from_fallthrough (rtx_insn *insn, rtx condition,\n \tbreak;\n \n       /* If this insn was already done, we don't need it.  */\n-      if (redundant_insn (trial, insn, delay_list))\n+      if (redundant_insn (trial, insn, *delay_list))\n \t{\n \t  update_block (trial, insn);\n \t  delete_from_delay_slot (trial);\n@@ -1265,14 +1241,14 @@ steal_delay_list_from_fallthrough (rtx_insn *insn, rtx condition,\n \t       || (! insn_sets_resource_p (trial, other_needed, false)\n \t\t   && ! may_trap_or_fault_p (PATTERN (trial)))))\n \t  ? eligible_for_delay (insn, *pslots_filled, trial, flags)\n-\t  : (must_annul || delay_list == NULL) && (must_annul = 1,\n-\t     check_annul_list_true_false (1, delay_list)\n+\t  : (must_annul || delay_list->is_empty ()) && (must_annul = 1,\n+\t     check_annul_list_true_false (1, *delay_list)\n \t     && eligible_for_annul_true (insn, *pslots_filled, trial, flags)))\n \t{\n \t  if (must_annul)\n \t    used_annul = 1;\n \t  delete_from_delay_slot (trial);\n-\t  delay_list = add_to_delay_list (trial, delay_list);\n+\t  add_to_delay_list (trial, delay_list);\n \n \t  if (++(*pslots_filled) == slots_to_fill)\n \t    break;\n@@ -1283,7 +1259,6 @@ steal_delay_list_from_fallthrough (rtx_insn *insn, rtx condition,\n \n   if (used_annul)\n     *pannul_p = 1;\n-  return delay_list;\n }\n \f\n /* Try merging insns starting at THREAD which match exactly the insns in\n@@ -1500,7 +1475,7 @@ try_merge_delay_insns (rtx_insn *insn, rtx_insn *thread)\n    gain in rare cases.  */\n \n static rtx\n-redundant_insn (rtx insn, rtx_insn *target, rtx delay_list)\n+redundant_insn (rtx insn, rtx_insn *target, const vec<rtx_insn *> &delay_list)\n {\n   rtx target_main = target;\n   rtx ipat = PATTERN (insn);\n@@ -1602,12 +1577,11 @@ redundant_insn (rtx insn, rtx_insn *target, rtx delay_list)\n   /* This insn isn't redundant if it conflicts with an insn that either is\n      or will be in a delay slot of TARGET.  */\n \n-  while (delay_list)\n-    {\n-      if (insn_sets_resource_p (XEXP (delay_list, 0), &needed, true))\n-\treturn 0;\n-      delay_list = XEXP (delay_list, 1);\n-    }\n+  unsigned int j;\n+  rtx_insn *temp;\n+  FOR_EACH_VEC_ELT (delay_list, j, temp)\n+    if (insn_sets_resource_p (temp, &needed, true))\n+      return 0;\n \n   if (NONJUMP_INSN_P (target) && GET_CODE (PATTERN (target)) == SEQUENCE)\n     for (i = 1; i < XVECLEN (PATTERN (target), 0); i++)\n@@ -1928,7 +1902,7 @@ fill_simple_delay_slots (int non_jumps_p)\n   int num_unfilled_slots = unfilled_slots_next - unfilled_slots_base;\n   struct resources needed, set;\n   int slots_to_fill, slots_filled;\n-  rtx_insn_list *delay_list;\n+  auto_vec<rtx_insn *, 5> delay_list;\n \n   for (i = 0; i < num_unfilled_slots; i++)\n     {\n@@ -1984,7 +1958,7 @@ fill_simple_delay_slots (int non_jumps_p)\n \t CALL_INSNs.  */\n \n       slots_filled = 0;\n-      delay_list = 0;\n+      delay_list.truncate (0);\n \n       if (JUMP_P (insn))\n \tflags = get_jump_flags (insn, JUMP_LABEL (insn));\n@@ -2000,7 +1974,7 @@ fill_simple_delay_slots (int non_jumps_p)\n \t{\n \t  rtx_insn **tmp;\n \t  slots_filled++;\n-\t  delay_list = add_to_delay_list (trial, delay_list);\n+\t  add_to_delay_list (trial, &delay_list);\n \n \t  /* TRIAL may have had its delay slot filled, then unfilled.  When\n \t     the delay slot is unfilled, TRIAL is placed back on the unfilled\n@@ -2093,8 +2067,7 @@ fill_simple_delay_slots (int non_jumps_p)\n \t\t\t tail, of the list.  */\n \n \t\t      update_reg_dead_notes (trial, insn);\n-\t\t      delay_list = gen_rtx_INSN_LIST (VOIDmode,\n-\t\t\t\t\t\t      trial, delay_list);\n+\t\t      delay_list.safe_insert (0, trial);\n \t\t      update_block (trial, trial);\n \t\t      delete_related_insns (trial);\n \t\t      if (slots_to_fill == ++slots_filled)\n@@ -2125,13 +2098,13 @@ fill_simple_delay_slots (int non_jumps_p)\n       /* Try to optimize case of jumping around a single insn.  */\n #if defined(ANNUL_IFFALSE_SLOTS) || defined(ANNUL_IFTRUE_SLOTS)\n       if (slots_filled != slots_to_fill\n-\t  && delay_list == 0\n+\t  && delay_list.is_empty ()\n \t  && JUMP_P (insn)\n \t  && (condjump_p (insn) || condjump_in_parallel_p (insn))\n \t  && !ANY_RETURN_P (JUMP_LABEL (insn)))\n \t{\n-\t  delay_list = optimize_skip (as_a <rtx_jump_insn *> (insn));\n-\t  if (delay_list)\n+\t  optimize_skip (as_a <rtx_jump_insn *> (insn), &delay_list);\n+\t  if (!delay_list.is_empty ())\n \t    slots_filled += 1;\n \t}\n #endif\n@@ -2219,7 +2192,7 @@ fill_simple_delay_slots (int non_jumps_p)\n \t\t  && ! can_throw_internal (trial))\n \t\t{\n \t\t  next_trial = next_nonnote_insn (trial);\n-\t\t  delay_list = add_to_delay_list (trial, delay_list);\n+\t\t  add_to_delay_list (trial, &delay_list);\n \t\t  if (HAVE_cc0 && reg_mentioned_p (cc0_rtx, pat))\n \t\t    link_cc0_insns (trial);\n \n@@ -2275,9 +2248,8 @@ fill_simple_delay_slots (int non_jumps_p)\n \n \t      if (new_label)\n \t        {\n-\t\t  delay_list\n-\t\t    = add_to_delay_list (copy_delay_slot_insn (next_trial),\n-\t\t\t\t\t delay_list);\n+\t\t  add_to_delay_list (copy_delay_slot_insn (next_trial),\n+\t\t\t\t     &delay_list);\n \t\t  slots_filled++;\n \t\t  reorg_redirect_jump (as_a <rtx_jump_insn *> (trial),\n \t\t\t\t       new_label);\n@@ -2291,16 +2263,13 @@ fill_simple_delay_slots (int non_jumps_p)\n       if ((jump_insn = dyn_cast <rtx_jump_insn *> (insn))\n \t  && simplejump_p (jump_insn)\n \t  && slots_filled != slots_to_fill)\n-\tdelay_list\n-\t  = fill_slots_from_thread (jump_insn, const_true_rtx,\n-\t\t\t\t    next_active_insn (JUMP_LABEL (insn)),\n-\t\t\t\t    NULL, 1, 1,\n-\t\t\t\t    own_thread_p (JUMP_LABEL (insn),\n-\t\t\t\t\t\t  JUMP_LABEL (insn), 0),\n-\t\t\t\t    slots_to_fill, &slots_filled,\n-\t\t\t\t    delay_list);\n-\n-      if (delay_list)\n+\tfill_slots_from_thread (jump_insn, const_true_rtx,\n+\t\t\t\tnext_active_insn (JUMP_LABEL (insn)), NULL, 1,\n+\t\t\t\t1, own_thread_p (JUMP_LABEL (insn),\n+\t\t\t\t\t\t JUMP_LABEL (insn), 0),\n+\t\t\t\tslots_to_fill, &slots_filled, &delay_list);\n+\n+      if (!delay_list.is_empty ())\n \tunfilled_slots_base[i]\n \t  = emit_delay_sequence (insn, delay_list, slots_filled);\n \n@@ -2395,11 +2364,11 @@ follow_jumps (rtx label, rtx_insn *jump, bool *crossing)\n    case, we can only take insns from the head of the thread for our delay\n    slot.  We then adjust the jump to point after the insns we have taken.  */\n \n-static rtx_insn_list *\n+static void\n fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t\t\trtx thread_or_return, rtx opposite_thread, int likely,\n \t\t\tint thread_if_true, int own_thread, int slots_to_fill,\n-\t\t\tint *pslots_filled, rtx_insn_list *delay_list)\n+\t\t\tint *pslots_filled, vec<rtx_insn *> *delay_list)\n {\n   rtx new_thread;\n   struct resources opposite_needed, set, needed;\n@@ -2417,7 +2386,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n   /* If our thread is the end of subroutine, we can't get any delay\n      insns from that.  */\n   if (thread_or_return == NULL_RTX || ANY_RETURN_P (thread_or_return))\n-    return delay_list;\n+    return;\n \n   rtx_insn *thread = as_a <rtx_insn *> (thread_or_return);\n \n@@ -2479,7 +2448,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t  /* If TRIAL is redundant with some insn before INSN, we don't\n \t     actually need to add it to the delay list; we can merely pretend\n \t     we did.  */\n-\t  if ((prior_insn = redundant_insn (trial, insn, delay_list)))\n+\t  if ((prior_insn = redundant_insn (trial, insn, *delay_list)))\n \t    {\n \t      fix_reg_dead_note (prior_insn, insn);\n \t      if (own_thread)\n@@ -2540,10 +2509,10 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t      if (thread == old_trial)\n \t\tthread = trial;\n \t      pat = PATTERN (trial);\n-\t      if ((must_annul || delay_list == NULL) && (thread_if_true\n-\t\t   ? check_annul_list_true_false (0, delay_list)\n+\t      if ((must_annul || delay_list->is_empty ()) && (thread_if_true\n+\t\t   ? check_annul_list_true_false (0, *delay_list)\n \t\t     && eligible_for_annul_false (insn, *pslots_filled, trial, flags)\n-\t\t   : check_annul_list_true_false (1, delay_list)\n+\t\t   : check_annul_list_true_false (1, *delay_list)\n \t\t     && eligible_for_annul_true (insn, *pslots_filled, trial, flags)))\n \t\t{\n \t\t  rtx_insn *temp;\n@@ -2616,7 +2585,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t\t  if (thread_if_true)\n \t\t    INSN_FROM_TARGET_P (temp) = 1;\n \n-\t\t  delay_list = add_to_delay_list (temp, delay_list);\n+\t\t  add_to_delay_list (temp, delay_list);\n \n \t\t  if (slots_to_fill == ++(*pslots_filled))\n \t\t    {\n@@ -2631,7 +2600,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t\t\t\t\t\t\t      &set, true)\n \t\t\t     && (prior_insn\n \t\t\t\t = redundant_insn (new_thread, insn,\n-\t\t\t\t\t\t   delay_list)))\n+\t\t\t\t\t\t   *delay_list)))\n \t\t\t{\n \t\t\t  /* We know we do not own the thread, so no need\n \t\t\t     to call update_block and delete_insn.  */\n@@ -2702,24 +2671,21 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t so we can only do this if we have taken everything up to here.  */\n       if (thread_if_true && trial == new_thread)\n \t{\n-\t  delay_list\n-\t    = steal_delay_list_from_target (insn, condition, sequence,\n-\t\t\t\t\t    delay_list, &set, &needed,\n-\t\t\t\t\t    &opposite_needed, slots_to_fill,\n-\t\t\t\t\t    pslots_filled, &must_annul,\n-\t\t\t\t\t    &new_thread);\n+\t  steal_delay_list_from_target (insn, condition, sequence,\n+\t\t\t\t\tdelay_list, &set, &needed,\n+\t\t\t\t\t&opposite_needed, slots_to_fill,\n+\t\t\t\t\tpslots_filled, &must_annul,\n+\t\t\t\t\t&new_thread);\n \t  /* If we owned the thread and are told that it branched\n \t     elsewhere, make sure we own the thread at the new location.  */\n \t  if (own_thread && trial != new_thread)\n \t    own_thread = own_thread_p (new_thread, new_thread, 0);\n \t}\n       else if (! thread_if_true)\n-\tdelay_list\n-\t  = steal_delay_list_from_fallthrough (insn, condition,\n-\t\t\t\t\t       sequence,\n-\t\t\t\t\t       delay_list, &set, &needed,\n-\t\t\t\t\t       &opposite_needed, slots_to_fill,\n-\t\t\t\t\t       pslots_filled, &must_annul);\n+\tsteal_delay_list_from_fallthrough (insn, condition, sequence,\n+\t\t\t\t\t   delay_list, &set, &needed,\n+\t\t\t\t\t   &opposite_needed, slots_to_fill,\n+\t\t\t\t\t   pslots_filled, &must_annul);\n     }\n \n   /* If we haven't found anything for this delay slot and it is very\n@@ -2728,7 +2694,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n      depend on the destination register.  If so, try to place the opposite\n      arithmetic insn after the jump insn and put the arithmetic insn in the\n      delay slot.  If we can't do this, return.  */\n-  if (delay_list == 0 && likely\n+  if (delay_list->is_empty () && likely\n       && new_thread && !ANY_RETURN_P (new_thread)\n       && NONJUMP_INSN_P (new_thread)\n       && !RTX_FRAME_RELATED_P (new_thread)\n@@ -2748,7 +2714,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t  || GET_CODE (pat) != SET\n \t  || ! eligible_for_delay (insn, 0, trial, flags)\n \t  || can_throw_internal (trial))\n-\treturn 0;\n+\treturn;\n \n       dest = SET_DEST (pat), src = SET_SRC (pat);\n       if ((GET_CODE (src) == PLUS || GET_CODE (src) == MINUS)\n@@ -2779,7 +2745,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t\t  !constrain_operands (1, get_preferred_alternatives (ninsn))))\n \t    {\n \t      delete_related_insns (ninsn);\n-\t      return 0;\n+\t      return;\n \t    }\n \n \t  if (own_thread)\n@@ -2800,12 +2766,12 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t  if (thread_if_true)\n \t    INSN_FROM_TARGET_P (ninsn) = 1;\n \n-\t  delay_list = add_to_delay_list (ninsn, NULL);\n+\t  add_to_delay_list (ninsn, delay_list);\n \t  (*pslots_filled)++;\n \t}\n     }\n \n-  if (delay_list && must_annul)\n+  if (!delay_list->is_empty () && must_annul)\n     INSN_ANNULLED_BRANCH_P (insn) = 1;\n \n   /* If we are to branch into the middle of this thread, find an appropriate\n@@ -2821,7 +2787,7 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n       if (new_thread && simplejump_or_return_p (new_thread)\n \t  && redirect_with_delay_list_safe_p (insn,\n \t\t\t\t\t      JUMP_LABEL (new_thread),\n-\t\t\t\t\t      delay_list))\n+\t\t\t\t\t      *delay_list))\n \tnew_thread = follow_jumps (JUMP_LABEL (new_thread), insn,\n \t\t\t\t   &crossing);\n \n@@ -2840,8 +2806,6 @@ fill_slots_from_thread (rtx_jump_insn *insn, rtx condition,\n \t    CROSSING_JUMP_P (insn) = 1;\n \t}\n     }\n-\n-  return delay_list;\n }\n \f\n /* Make another attempt to find insns to place in delay slots.\n@@ -2866,7 +2830,7 @@ fill_eager_delay_slots (void)\n       rtx condition;\n       rtx target_label, insn_at_target;\n       rtx_insn *fallthrough_insn;\n-      rtx_insn_list *delay_list = 0;\n+      auto_vec<rtx_insn *, 5> delay_list;\n       rtx_jump_insn *jump_insn;\n       int own_target;\n       int own_fallthrough;\n@@ -2927,13 +2891,12 @@ fill_eager_delay_slots (void)\n \n       if (prediction > 0)\n \t{\n-\t  delay_list\n-\t    = fill_slots_from_thread (jump_insn, condition, insn_at_target,\n-\t\t\t\t      fallthrough_insn, prediction == 2, 1,\n-\t\t\t\t      own_target,\n-\t\t\t\t      slots_to_fill, &slots_filled, delay_list);\n+\t  fill_slots_from_thread (jump_insn, condition, insn_at_target,\n+\t\t\t\t  fallthrough_insn, prediction == 2, 1,\n+\t\t\t\t  own_target,\n+\t\t\t\t  slots_to_fill, &slots_filled, &delay_list);\n \n-\t  if (delay_list == 0 && own_fallthrough)\n+\t  if (delay_list.is_empty () && own_fallthrough)\n \t    {\n \t      /* Even though we didn't find anything for delay slots,\n \t\t we might have found a redundant insn which we deleted\n@@ -2942,35 +2905,26 @@ fill_eager_delay_slots (void)\n \t      target_label = JUMP_LABEL (jump_insn);\n \t      insn_at_target = first_active_target_insn (target_label);\n \n-\t      delay_list\n-\t\t= fill_slots_from_thread (jump_insn, condition,\n-\t\t\t\t\t  fallthrough_insn,\n-\t\t\t\t\t  insn_at_target, 0, 0,\n-\t\t\t\t\t  own_fallthrough,\n-\t\t\t\t\t  slots_to_fill, &slots_filled,\n-\t\t\t\t\t  delay_list);\n+\t      fill_slots_from_thread (jump_insn, condition, fallthrough_insn,\n+\t\t\t\t      insn_at_target, 0, 0, own_fallthrough,\n+\t\t\t\t      slots_to_fill, &slots_filled,\n+\t\t\t\t      &delay_list);\n \t    }\n \t}\n       else\n \t{\n \t  if (own_fallthrough)\n-\t    delay_list\n-\t      = fill_slots_from_thread (jump_insn, condition, fallthrough_insn,\n-\t\t\t\t\tinsn_at_target, 0, 0,\n-\t\t\t\t\town_fallthrough,\n-\t\t\t\t\tslots_to_fill, &slots_filled,\n-\t\t\t\t\tdelay_list);\n-\n-\t  if (delay_list == 0)\n-\t    delay_list\n-\t      = fill_slots_from_thread (jump_insn, condition, insn_at_target,\n-\t\t\t\t\tnext_active_insn (insn), 0, 1,\n-\t\t\t\t\town_target,\n-\t\t\t\t\tslots_to_fill, &slots_filled,\n-\t\t\t\t\tdelay_list);\n+\t    fill_slots_from_thread (jump_insn, condition, fallthrough_insn,\n+\t\t\t\t    insn_at_target, 0, 0, own_fallthrough,\n+\t\t\t\t    slots_to_fill, &slots_filled, &delay_list);\n+\n+\t  if (delay_list.is_empty ())\n+\t    fill_slots_from_thread (jump_insn, condition, insn_at_target,\n+\t\t\t\t    next_active_insn (insn), 0, 1, own_target,\n+\t\t\t\t    slots_to_fill, &slots_filled, &delay_list);\n \t}\n \n-      if (delay_list)\n+      if (!delay_list.is_empty ())\n \tunfilled_slots_base[i]\n \t  = emit_delay_sequence (jump_insn, delay_list, slots_filled);\n \n@@ -3304,7 +3258,7 @@ relax_delay_slots (rtx_insn *first)\n       /* See if the first insn in the delay slot is redundant with some\n \t previous insn.  Remove it from the delay slot if so; then set up\n \t to reprocess this insn.  */\n-      if (redundant_insn (pat->insn (1), delay_insn, 0))\n+      if (redundant_insn (pat->insn (1), delay_insn, vNULL))\n \t{\n \t  update_block (pat->insn (1), insn);\n \t  delete_from_delay_slot (pat->insn (1));\n@@ -3390,7 +3344,7 @@ relax_delay_slots (rtx_insn *first)\n \t liveness info.  */\n       trial = next_real_insn (target_label);\n       if (trial && GET_CODE (PATTERN (trial)) != SEQUENCE\n-\t  && redundant_insn (trial, insn, 0)\n+\t  && redundant_insn (trial, insn, vNULL)\n \t  && ! can_throw_internal (trial))\n \t{\n \t  /* Figure out where to emit the special USE insn so we don't\n@@ -3423,7 +3377,7 @@ relax_delay_slots (rtx_insn *first)\n \t  && trial_seq->len () == 2\n \t  && JUMP_P (trial_seq->insn (0))\n \t  && simplejump_or_return_p (trial_seq->insn (0))\n-\t  && redundant_insn (trial_seq->insn (1), insn, 0))\n+\t  && redundant_insn (trial_seq->insn (1), insn, vNULL))\n \t{\n \t  target_label = JUMP_LABEL (trial_seq->insn (0));\n \t  if (ANY_RETURN_P (target_label))"}]}