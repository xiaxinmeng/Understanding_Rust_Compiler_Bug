{"sha": "53109ba8a720c135a79b6536c79350e6f1a45895", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTMxMDliYThhNzIwYzEzNWE3OWI2NTM2Yzc5MzUwZTZmMWE0NTg5NQ==", "commit": {"author": {"name": "Kyrylo Tkachov", "email": "kyrylo.tkachov@arm.com", "date": "2016-07-14T14:32:39Z"}, "committer": {"name": "Kyrylo Tkachov", "email": "ktkachov@gcc.gnu.org", "date": "2016-07-14T14:32:39Z"}, "message": "[vectorizer][2/2] Hook up mult synthesis logic into vectorisation of mult-by-constant\n\n\tPR target/65951\n\tPR tree-optimization/70923\n\t* tree-vect-patterns.c: Include mult-synthesis.h.\n\t(target_supports_mult_synth_alg): New function.\n\t(synth_lshift_by_additions): Likewise.\n\t(apply_binop_and_append_stmt): Likewise.\n\t(vect_synth_mult_by_constant): Likewise.\n\t(target_has_vecop_for_code): Likewise.\n\t(vect_recog_mult_pattern): Use above functions to synthesize vector\n\tmultiplication by integer constants.\n\n\t* gcc.dg/vect/vect-mult-const-pattern-1.c: New test.\n\t* gcc.dg/vect/vect-mult-const-pattern-2.c: Likewise.\n\t* gcc.dg/vect/pr65951.c: Likewise.\n\t* gcc.dg/vect/vect-iv-9.c: Remove ! vect_int_mult-specific scan.\n\nFrom-SVN: r238340", "tree": {"sha": "b79ce2c9e3e5d2c590ca6cd9941695f230913329", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b79ce2c9e3e5d2c590ca6cd9941695f230913329"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/53109ba8a720c135a79b6536c79350e6f1a45895", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/53109ba8a720c135a79b6536c79350e6f1a45895", "html_url": "https://github.com/Rust-GCC/gccrs/commit/53109ba8a720c135a79b6536c79350e6f1a45895", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/53109ba8a720c135a79b6536c79350e6f1a45895/comments", "author": {"login": "ktkachov-arm", "id": 74917949, "node_id": "MDQ6VXNlcjc0OTE3OTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/74917949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktkachov-arm", "html_url": "https://github.com/ktkachov-arm", "followers_url": "https://api.github.com/users/ktkachov-arm/followers", "following_url": "https://api.github.com/users/ktkachov-arm/following{/other_user}", "gists_url": "https://api.github.com/users/ktkachov-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktkachov-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktkachov-arm/subscriptions", "organizations_url": "https://api.github.com/users/ktkachov-arm/orgs", "repos_url": "https://api.github.com/users/ktkachov-arm/repos", "events_url": "https://api.github.com/users/ktkachov-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/ktkachov-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "0c15a902d1eb8d9b2be4eeced2a500c4a8a25152", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0c15a902d1eb8d9b2be4eeced2a500c4a8a25152", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0c15a902d1eb8d9b2be4eeced2a500c4a8a25152"}], "stats": {"total": 544, "additions": 476, "deletions": 68}, "files": [{"sha": "4b099bed410e87459dcb2c70e1ab3466744ad6a9", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=53109ba8a720c135a79b6536c79350e6f1a45895", "patch": "@@ -1,3 +1,16 @@\n+2016-07-14  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n+\n+\tPR target/65951\n+\tPR tree-optimization/70923\n+\t* tree-vect-patterns.c: Include mult-synthesis.h.\n+\t(target_supports_mult_synth_alg): New function.\n+\t(synth_lshift_by_additions): Likewise.\n+\t(apply_binop_and_append_stmt): Likewise.\n+\t(vect_synth_mult_by_constant): Likewise.\n+\t(target_has_vecop_for_code): Likewise.\n+\t(vect_recog_mult_pattern): Use above functions to synthesize vector\n+\tmultiplication by integer constants.\n+\n 2016-07-14  Alan Modra  <amodra@gmail.com>\n \n \t* gcc/config/rs6000/altivec.md (altivec_mov<mode>): Disparage"}, {"sha": "9eeec45ee2c0d12bb964173c6d8ed2f9c2031a83", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=53109ba8a720c135a79b6536c79350e6f1a45895", "patch": "@@ -1,3 +1,12 @@\n+2016-07-14  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n+\n+\tPR target/65951\n+\tPR tree-optimization/70923\n+\t* gcc.dg/vect/vect-mult-const-pattern-1.c: New test.\n+\t* gcc.dg/vect/vect-mult-const-pattern-2.c: Likewise.\n+\t* gcc.dg/vect/pr65951.c: Likewise.\n+\t* gcc.dg/vect/vect-iv-9.c: Remove ! vect_int_mult-specific scan.\n+\n 2016-07-14  David Edelsohn  <dje.gcc@gmail.com>\n \n \t* c-c++-common/pr60226.c: Expect maximum object file alignment"}, {"sha": "cfd32373181fc4fc1e37677ccec6505321a81b2f", "filename": "gcc/testsuite/gcc.dg/vect/pr65951.c", "status": "added", "additions": 63, "deletions": 0, "changes": 63, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fpr65951.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fpr65951.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fpr65951.c?ref=53109ba8a720c135a79b6536c79350e6f1a45895", "patch": "@@ -0,0 +1,63 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include \"tree-vect.h\"\n+\n+#define N 512\n+\n+/* These multiplications should be vectorizable with additions when\n+   no vector shift is available.  */\n+\n+__attribute__ ((noinline)) void\n+foo (int *arr)\n+{\n+  for (int i = 0; i < N; i++)\n+    arr[i] *= 2;\n+}\n+\n+__attribute__ ((noinline)) void\n+foo2 (int *arr)\n+{\n+  for (int i = 0; i < N; i++)\n+    arr[i] *= 4;\n+}\n+\n+int\n+main (void)\n+{\n+  check_vect ();\n+  int data[N];\n+  int i;\n+\n+  for (i = 0; i < N; i++)\n+    {\n+      data[i] = i;\n+      __asm__ volatile (\"\");\n+    }\n+\n+  foo (data);\n+  for (i = 0; i < N; i++)\n+    {\n+      if (data[i] / 2 != i)\n+      __builtin_abort ();\n+      __asm__ volatile (\"\");\n+    }\n+\n+  for (i = 0; i < N; i++)\n+    {\n+      data[i] = i;\n+      __asm__ volatile (\"\");\n+    }\n+\n+  foo2 (data);\n+  for (i = 0; i < N; i++)\n+    {\n+      if (data[i] / 4 != i)\n+      __builtin_abort ();\n+      __asm__ volatile (\"\");\n+    }\n+\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 2 \"vect\" } } */"}, {"sha": "e548b81b922fccc738f217a37a67042ee8e1856f", "filename": "gcc/testsuite/gcc.dg/vect/vect-iv-9.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-iv-9.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-iv-9.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-iv-9.c?ref=53109ba8a720c135a79b6536c79350e6f1a45895", "patch": "@@ -33,5 +33,4 @@ int main (void)\n   return 0;\n } \n \n-/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 2 \"vect\" { target vect_int_mult } } } */\n-/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\" { target {! vect_int_mult } } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 2 \"vect\" } } */"}, {"sha": "e5dba82d7fa955a6a37a0eabf980127e464ac77b", "filename": "gcc/testsuite/gcc.dg/vect/vect-mult-const-pattern-1.c", "status": "added", "additions": 41, "deletions": 0, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-mult-const-pattern-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-mult-const-pattern-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-mult-const-pattern-1.c?ref=53109ba8a720c135a79b6536c79350e6f1a45895", "patch": "@@ -0,0 +1,41 @@\n+/* { dg-require-effective-target vect_int } */\n+/* { dg-require-effective-target vect_shift } */\n+\n+#include <stdarg.h>\n+#include \"tree-vect.h\"\n+\n+#define N 256\n+\n+__attribute__ ((noinline)) void\n+foo (long long *arr)\n+{\n+  for (int i = 0; i < N; i++)\n+    arr[i] *= 123;\n+}\n+\n+int\n+main (void)\n+{\n+  check_vect ();\n+  long long data[N];\n+  int i;\n+\n+  for (i = 0; i < N; i++)\n+    {\n+      data[i] = i;\n+      __asm__ volatile (\"\");\n+    }\n+\n+  foo (data);\n+  for (i = 0; i < N; i++)\n+    {\n+      if (data[i] / 123 != i)\n+      __builtin_abort ();\n+      __asm__ volatile (\"\");\n+    }\n+\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vect_recog_mult_pattern: detected\" 2 \"vect\"  { target aarch64*-*-* } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\"  { target aarch64*-*-* } } } */"}, {"sha": "c5beabaa97425cc1e644d37a69eba65036eeaf4a", "filename": "gcc/testsuite/gcc.dg/vect/vect-mult-const-pattern-2.c", "status": "added", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-mult-const-pattern-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-mult-const-pattern-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-mult-const-pattern-2.c?ref=53109ba8a720c135a79b6536c79350e6f1a45895", "patch": "@@ -0,0 +1,40 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include \"tree-vect.h\"\n+\n+#define N 256\n+\n+__attribute__ ((noinline)) void\n+foo (long long *arr)\n+{\n+  for (int i = 0; i < N; i++)\n+    arr[i] *= -19594LL;\n+}\n+\n+int\n+main (void)\n+{\n+  check_vect ();\n+  long long data[N];\n+  int i;\n+\n+  for (i = 0; i < N; i++)\n+    {\n+      data[i] = i;\n+      __asm__ volatile (\"\");\n+    }\n+\n+  foo (data);\n+  for (i = 0; i < N; i++)\n+    {\n+      if (data[i] / -19594LL != i)\n+      __builtin_abort ();\n+      __asm__ volatile (\"\");\n+    }\n+\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vect_recog_mult_pattern: detected\" 2 \"vect\"  { target aarch64*-*-* } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\"  { target aarch64*-*-* } } } */"}, {"sha": "3be1b89d5842955a4ef56f4a0e5e6f47046c5150", "filename": "gcc/tree-vect-patterns.c", "status": "modified", "additions": 309, "deletions": 66, "changes": 375, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftree-vect-patterns.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/53109ba8a720c135a79b6536c79350e6f1a45895/gcc%2Ftree-vect-patterns.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-patterns.c?ref=53109ba8a720c135a79b6536c79350e6f1a45895", "patch": "@@ -2131,53 +2131,331 @@ vect_recog_vector_vector_shift_pattern (vec<gimple *> *stmts,\n   return pattern_stmt;\n }\n \n-/* Detect multiplication by constant which are postive or negatives of power 2,\n-   and convert them to shift patterns.\n+/* Return true iff the target has a vector optab implementing the operation\n+   CODE on type VECTYPE.  */\n \n-   Mult with constants that are postive power of two.\n-   type a_t;\n-   type b_t\n-   S1: b_t = a_t * n\n+static bool\n+target_has_vecop_for_code (tree_code code, tree vectype)\n+{\n+  optab voptab = optab_for_tree_code (code, vectype, optab_vector);\n+  return voptab\n+\t && optab_handler (voptab, TYPE_MODE (vectype)) != CODE_FOR_nothing;\n+}\n \n-   or\n+/* Verify that the target has optabs of VECTYPE to perform all the steps\n+   needed by the multiplication-by-immediate synthesis algorithm described by\n+   ALG and VAR.  If SYNTH_SHIFT_P is true ensure that vector addition is\n+   present.  Return true iff the target supports all the steps.  */\n+\n+static bool\n+target_supports_mult_synth_alg (struct algorithm *alg, mult_variant var,\n+\t\t\t\t tree vectype, bool synth_shift_p)\n+{\n+  if (alg->op[0] != alg_zero && alg->op[0] != alg_m)\n+    return false;\n+\n+  bool supports_vminus = target_has_vecop_for_code (MINUS_EXPR, vectype);\n+  bool supports_vplus = target_has_vecop_for_code (PLUS_EXPR, vectype);\n+\n+  if (var == negate_variant\n+      && !target_has_vecop_for_code (NEGATE_EXPR, vectype))\n+    return false;\n+\n+  /* If we must synthesize shifts with additions make sure that vector\n+     addition is available.  */\n+  if ((var == add_variant || synth_shift_p) && !supports_vplus)\n+    return false;\n+\n+  for (int i = 1; i < alg->ops; i++)\n+    {\n+      switch (alg->op[i])\n+\t{\n+\tcase alg_shift:\n+\t  break;\n+\tcase alg_add_t_m2:\n+\tcase alg_add_t2_m:\n+\tcase alg_add_factor:\n+\t  if (!supports_vplus)\n+\t    return false;\n+\t  break;\n+\tcase alg_sub_t_m2:\n+\tcase alg_sub_t2_m:\n+\tcase alg_sub_factor:\n+\t  if (!supports_vminus)\n+\t    return false;\n+\t  break;\n+\tcase alg_unknown:\n+\tcase alg_m:\n+\tcase alg_zero:\n+\tcase alg_impossible:\n+\t  return false;\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+    }\n+\n+  return true;\n+}\n+\n+/* Synthesize a left shift of OP by AMNT bits using a series of additions and\n+   putting the final result in DEST.  Append all statements but the last into\n+   VINFO.  Return the last statement.  */\n+\n+static gimple *\n+synth_lshift_by_additions (tree dest, tree op, HOST_WIDE_INT amnt,\n+\t\t\t   stmt_vec_info vinfo)\n+{\n+  HOST_WIDE_INT i;\n+  tree itype = TREE_TYPE (op);\n+  tree prev_res = op;\n+  gcc_assert (amnt >= 0);\n+  for (i = 0; i < amnt; i++)\n+    {\n+      tree tmp_var = (i < amnt - 1) ? vect_recog_temp_ssa_var (itype, NULL)\n+\t\t      : dest;\n+      gimple *stmt\n+        = gimple_build_assign (tmp_var, PLUS_EXPR, prev_res, prev_res);\n+      prev_res = tmp_var;\n+      if (i < amnt - 1)\n+\tappend_pattern_def_seq (vinfo, stmt);\n+      else\n+\treturn stmt;\n+    }\n+  gcc_unreachable ();\n+  return NULL;\n+}\n+\n+/* Helper for vect_synth_mult_by_constant.  Apply a binary operation\n+   CODE to operands OP1 and OP2, creating a new temporary SSA var in\n+   the process if necessary.  Append the resulting assignment statements\n+   to the sequence in STMT_VINFO.  Return the SSA variable that holds the\n+   result of the binary operation.  If SYNTH_SHIFT_P is true synthesize\n+   left shifts using additions.  */\n+\n+static tree\n+apply_binop_and_append_stmt (tree_code code, tree op1, tree op2,\n+\t\t\t     stmt_vec_info stmt_vinfo, bool synth_shift_p)\n+{\n+  if (integer_zerop (op2)\n+      && (code == LSHIFT_EXPR\n+\t  || code == PLUS_EXPR))\n+    {\n+      gcc_assert (TREE_CODE (op1) == SSA_NAME);\n+      return op1;\n+    }\n+\n+  gimple *stmt;\n+  tree itype = TREE_TYPE (op1);\n+  tree tmp_var = vect_recog_temp_ssa_var (itype, NULL);\n+\n+  if (code == LSHIFT_EXPR\n+      && synth_shift_p)\n+    {\n+      stmt = synth_lshift_by_additions (tmp_var, op1, TREE_INT_CST_LOW (op2),\n+\t\t\t\t\t stmt_vinfo);\n+      append_pattern_def_seq (stmt_vinfo, stmt);\n+      return tmp_var;\n+    }\n+\n+  stmt = gimple_build_assign (tmp_var, code, op1, op2);\n+  append_pattern_def_seq (stmt_vinfo, stmt);\n+  return tmp_var;\n+}\n+\n+/* Synthesize a multiplication of OP by an INTEGER_CST VAL using shifts\n+   and simple arithmetic operations to be vectorized.  Record the statements\n+   produced in STMT_VINFO and return the last statement in the sequence or\n+   NULL if it's not possible to synthesize such a multiplication.\n+   This function mirrors the behavior of expand_mult_const in expmed.c but\n+   works on tree-ssa form.  */\n+\n+static gimple *\n+vect_synth_mult_by_constant (tree op, tree val,\n+\t\t\t     stmt_vec_info stmt_vinfo)\n+{\n+  tree itype = TREE_TYPE (op);\n+  machine_mode mode = TYPE_MODE (itype);\n+  struct algorithm alg;\n+  mult_variant variant;\n+  if (!tree_fits_shwi_p (val))\n+    return NULL;\n+\n+  /* Multiplication synthesis by shifts, adds and subs can introduce\n+     signed overflow where the original operation didn't.  Perform the\n+     operations on an unsigned type and cast back to avoid this.\n+     In the future we may want to relax this for synthesis algorithms\n+     that we can prove do not cause unexpected overflow.  */\n+  bool cast_to_unsigned_p = !TYPE_OVERFLOW_WRAPS (itype);\n+\n+  tree multtype = cast_to_unsigned_p ? unsigned_type_for (itype) : itype;\n+\n+  /* Targets that don't support vector shifts but support vector additions\n+     can synthesize shifts that way.  */\n+  bool synth_shift_p = !vect_supportable_shift (LSHIFT_EXPR, multtype);\n+\n+  HOST_WIDE_INT hwval = tree_to_shwi (val);\n+  /* Use MAX_COST here as we don't want to limit the sequence on rtx costs.\n+     The vectorizer's benefit analysis will decide whether it's beneficial\n+     to do this.  */\n+  bool possible = choose_mult_variant (mode, hwval, &alg,\n+\t\t\t\t\t&variant, MAX_COST);\n+  if (!possible)\n+    return NULL;\n \n-   Mult with constants that are negative power of two.\n-   S2: b_t = a_t * -n\n+  tree vectype = get_vectype_for_scalar_type (multtype);\n+\n+  if (!vectype\n+      || !target_supports_mult_synth_alg (&alg, variant,\n+\t\t\t\t\t   vectype, synth_shift_p))\n+    return NULL;\n+\n+  tree accumulator;\n+\n+  /* Clear out the sequence of statements so we can populate it below.  */\n+  STMT_VINFO_PATTERN_DEF_SEQ (stmt_vinfo) = NULL;\n+  gimple *stmt = NULL;\n+\n+  if (cast_to_unsigned_p)\n+    {\n+      tree tmp_op = vect_recog_temp_ssa_var (multtype, NULL);\n+      stmt = gimple_build_assign (tmp_op, CONVERT_EXPR, op);\n+      append_pattern_def_seq (stmt_vinfo, stmt);\n+      op = tmp_op;\n+    }\n+\n+  if (alg.op[0] == alg_zero)\n+    accumulator = build_int_cst (multtype, 0);\n+  else\n+    accumulator = op;\n+\n+  bool needs_fixup = (variant == negate_variant)\n+\t\t      || (variant == add_variant);\n+\n+  for (int i = 1; i < alg.ops; i++)\n+    {\n+      tree shft_log = build_int_cst (multtype, alg.log[i]);\n+      tree accum_tmp = vect_recog_temp_ssa_var (multtype, NULL);\n+      tree tmp_var = NULL_TREE;\n+\n+      switch (alg.op[i])\n+\t{\n+\tcase alg_shift:\n+\t  if (synth_shift_p)\n+\t    stmt\n+\t      = synth_lshift_by_additions (accum_tmp, accumulator, alg.log[i],\n+\t\t\t\t\t    stmt_vinfo);\n+\t  else\n+\t    stmt = gimple_build_assign (accum_tmp, LSHIFT_EXPR, accumulator,\n+\t\t\t\t\t shft_log);\n+\t  break;\n+\tcase alg_add_t_m2:\n+\t  tmp_var\n+\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, op, shft_log,\n+\t\t\t\t\t    stmt_vinfo, synth_shift_p);\n+\t  stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, accumulator,\n+\t\t\t\t       tmp_var);\n+\t  break;\n+\tcase alg_sub_t_m2:\n+\t  tmp_var = apply_binop_and_append_stmt (LSHIFT_EXPR, op,\n+\t\t\t\t\t\t  shft_log, stmt_vinfo,\n+\t\t\t\t\t\t  synth_shift_p);\n+\t  /* In some algorithms the first step involves zeroing the\n+\t     accumulator.  If subtracting from such an accumulator\n+\t     just emit the negation directly.  */\n+\t  if (integer_zerop (accumulator))\n+\t    stmt = gimple_build_assign (accum_tmp, NEGATE_EXPR, tmp_var);\n+\t  else\n+\t    stmt = gimple_build_assign (accum_tmp, MINUS_EXPR, accumulator,\n+\t\t\t\t\ttmp_var);\n+\t  break;\n+\tcase alg_add_t2_m:\n+\t  tmp_var\n+\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n+\t\t\t\t\t   stmt_vinfo, synth_shift_p);\n+\t  stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, tmp_var, op);\n+\t  break;\n+\tcase alg_sub_t2_m:\n+\t  tmp_var\n+\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n+\t\t\t\t\t   stmt_vinfo, synth_shift_p);\n+\t  stmt = gimple_build_assign (accum_tmp, MINUS_EXPR, tmp_var, op);\n+\t  break;\n+\tcase alg_add_factor:\n+\t  tmp_var\n+\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n+\t\t\t\t\t    stmt_vinfo, synth_shift_p);\n+\t  stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, accumulator,\n+\t\t\t\t       tmp_var);\n+\t  break;\n+\tcase alg_sub_factor:\n+\t  tmp_var\n+\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n+\t\t\t\t\t   stmt_vinfo, synth_shift_p);\n+\t  stmt = gimple_build_assign (accum_tmp, MINUS_EXPR, tmp_var,\n+\t\t\t\t      accumulator);\n+\t  break;\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+      /* We don't want to append the last stmt in the sequence to stmt_vinfo\n+\t but rather return it directly.  */\n+\n+      if ((i < alg.ops - 1) || needs_fixup || cast_to_unsigned_p)\n+\tappend_pattern_def_seq (stmt_vinfo, stmt);\n+      accumulator = accum_tmp;\n+    }\n+  if (variant == negate_variant)\n+    {\n+      tree accum_tmp = vect_recog_temp_ssa_var (multtype, NULL);\n+      stmt = gimple_build_assign (accum_tmp, NEGATE_EXPR, accumulator);\n+      accumulator = accum_tmp;\n+      if (cast_to_unsigned_p)\n+\tappend_pattern_def_seq (stmt_vinfo, stmt);\n+    }\n+  else if (variant == add_variant)\n+    {\n+      tree accum_tmp = vect_recog_temp_ssa_var (multtype, NULL);\n+      stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, accumulator, op);\n+      accumulator = accum_tmp;\n+      if (cast_to_unsigned_p)\n+\tappend_pattern_def_seq (stmt_vinfo, stmt);\n+    }\n+  /* Move back to a signed if needed.  */\n+  if (cast_to_unsigned_p)\n+    {\n+      tree accum_tmp = vect_recog_temp_ssa_var (itype, NULL);\n+      stmt = gimple_build_assign (accum_tmp, CONVERT_EXPR, accumulator);\n+    }\n+\n+  return stmt;\n+}\n+\n+/* Detect multiplication by constant and convert it into a sequence of\n+   shifts and additions, subtractions, negations.  We reuse the\n+   choose_mult_variant algorithms from expmed.c\n \n    Input/Output:\n \n    STMTS: Contains a stmt from which the pattern search begins,\n-   i.e. the mult stmt.  Convert the mult operation to LSHIFT if\n-   constant operand is a power of 2.\n-   type a_t, b_t\n-   S1': b_t = a_t << log2 (n)\n-\n-   Convert the mult operation to LSHIFT and followed by a NEGATE\n-   if constant operand is a negative power of 2.\n-   type a_t, b_t, res_T;\n-   S2': b_t = a_t << log2 (n)\n-   S3': res_T  = - (b_t)\n+   i.e. the mult stmt.\n \n  Output:\n \n   * TYPE_IN: The type of the input arguments to the pattern.\n \n   * TYPE_OUT: The type of the output of this pattern.\n \n-  * Return value: A new stmt that will be used to replace the multiplication\n-    S1 or S2 stmt.  */\n+  * Return value: A new stmt that will be used to replace\n+    the multiplication.  */\n \n static gimple *\n vect_recog_mult_pattern (vec<gimple *> *stmts,\n \t\t\t tree *type_in, tree *type_out)\n {\n   gimple *last_stmt = stmts->pop ();\n   tree oprnd0, oprnd1, vectype, itype;\n-  gimple *pattern_stmt, *def_stmt;\n-  optab optab;\n+  gimple *pattern_stmt;\n   stmt_vec_info stmt_vinfo = vinfo_for_stmt (last_stmt);\n-  int power2_val, power2_neg_val;\n-  tree shift;\n \n   if (!is_gimple_assign (last_stmt))\n     return NULL;\n@@ -2201,52 +2479,17 @@ vect_recog_mult_pattern (vec<gimple *> *stmts,\n \n   /* If the target can handle vectorized multiplication natively,\n      don't attempt to optimize this.  */\n-  optab = optab_for_tree_code (MULT_EXPR, vectype, optab_default);\n-  if (optab != unknown_optab)\n+  optab mul_optab = optab_for_tree_code (MULT_EXPR, vectype, optab_default);\n+  if (mul_optab != unknown_optab)\n     {\n       machine_mode vec_mode = TYPE_MODE (vectype);\n-      int icode = (int) optab_handler (optab, vec_mode);\n+      int icode = (int) optab_handler (mul_optab, vec_mode);\n       if (icode != CODE_FOR_nothing)\n-\treturn NULL;\n+       return NULL;\n     }\n \n-  /* If target cannot handle vector left shift then we cannot\n-     optimize and bail out.  */\n-  optab = optab_for_tree_code (LSHIFT_EXPR, vectype, optab_vector);\n-  if (!optab\n-      || optab_handler (optab, TYPE_MODE (vectype)) == CODE_FOR_nothing)\n-    return NULL;\n-\n-  power2_val = wi::exact_log2 (oprnd1);\n-  power2_neg_val = wi::exact_log2 (wi::neg (oprnd1));\n-\n-  /* Handle constant operands that are postive or negative powers of 2.  */\n-  if (power2_val != -1)\n-    {\n-      shift = build_int_cst (itype, power2_val);\n-      pattern_stmt\n-\t= gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n-\t\t\t       LSHIFT_EXPR, oprnd0, shift);\n-    }\n-  else if (power2_neg_val != -1)\n-    {\n-      /* If the target cannot handle vector NEGATE then we cannot\n-\t do the optimization.  */\n-      optab = optab_for_tree_code (NEGATE_EXPR, vectype, optab_vector);\n-      if (!optab\n-\t  || optab_handler (optab, TYPE_MODE (vectype)) == CODE_FOR_nothing)\n-\treturn NULL;\n-\n-      shift = build_int_cst (itype, power2_neg_val);\n-      def_stmt\n-\t= gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n-\t\t\t       LSHIFT_EXPR, oprnd0, shift);\n-      new_pattern_def_seq (stmt_vinfo, def_stmt);\n-      pattern_stmt\n-\t = gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n-\t\t\t\tNEGATE_EXPR, gimple_assign_lhs (def_stmt));\n-    }\n-  else\n+  pattern_stmt = vect_synth_mult_by_constant (oprnd0, oprnd1, stmt_vinfo);\n+  if (!pattern_stmt)\n     return NULL;\n \n   /* Pattern detected.  */"}]}