{"sha": "61b03ade93b0f47dd888cd5228f017979c494263", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NjFiMDNhZGU5M2IwZjQ3ZGQ4ODhjZDUyMjhmMDE3OTc5YzQ5NDI2Mw==", "commit": {"author": {"name": "H.J. Lu", "email": "hjl.tools@gmail.com", "date": "2021-09-15T06:15:10Z"}, "committer": {"name": "liuhongt", "email": "hongtao.liu@intel.com", "date": "2021-09-17T08:17:00Z"}, "message": "x86: Update -mtune=tremont\n\nInitial -mtune=tremont update\n\n1. Use Haswell scheduling model.\n2. Assume that stack engine allows to execute push&pop instructions in\nparall.\n3. Prepare for scheduling pass as -mtune=generic.\n4. Use the same issue rate as -mtune=generic.\n5. Enable partial_reg_dependency.\n6. Disable accumulate_outgoing_args\n7. Enable use_leave\n8. Enable push_memory\n9. Disable four_jump_limit\n10. Disable opt_agu\n11. Disable avoid_lea_for_addr\n12. Disable avoid_mem_opnd_for_cmove\n13. Enable misaligned_move_string_pro_epilogues\n14. Enable use_cltd\n16. Enable avoid_false_dep_for_bmi\n17. Enable avoid_mfence\n18. Disable expand_abs\n19. Enable sse_typeless_stores\n20. Enable sse_load0_by_pxor\n21. Disable split_mem_opnd_for_fp_converts\n22. Disable slow_pshufb\n23. Enable partial_reg_dependency\n\nThis is the first patch to tune for Tremont.  With all patches applied,\nperformance impacts on SPEC CPU 2017 are:\n\n500.perlbench_r         1.81%\n502.gcc_r               0.57%\n505.mcf_r               1.16%\n520.omnetpp_r           0.00%\n523.xalancbmk_r         0.00%\n525.x264_r              4.55%\n531.deepsjeng_r         0.00%\n541.leela_r             0.39%\n548.exchange2_r         1.13%\n557.xz_r                0.00%\ngeomean for intrate     0.95%\n503.bwaves_r            0.00%\n507.cactuBSSN_r         6.94%\n508.namd_r              12.37%\n510.parest_r            1.01%\n511.povray_r            3.70%\n519.lbm_r               36.61%\n521.wrf_r               8.79%\n526.blender_r           2.91%\n527.cam4_r              6.23%\n538.imagick_r           0.28%\n544.nab_r               21.99%\n549.fotonik3d_r         3.63%\n554.roms_r              -1.20%\ngeomean for fprate      7.50%\n\ngcc/ChangeLog\n\n\t* common/config/i386/i386-common.c: Use Haswell scheduling model\n\tfor Tremont.\n\t* config/i386/i386.c (ix86_sched_init_global): Prepare for Tremont\n\tscheduling pass.\n\t* config/i386/x86-tune-sched.c (ix86_issue_rate): Change Tremont\n\tissue rate to 4.\n\t(ix86_adjust_cost): Handle Tremont.\n\t* config/i386/x86-tune.def (X86_TUNE_SSE_PARTIAL_REG_DEPENDENCY):\n\tEnable for Tremont.\n\t(X86_TUNE_USE_LEAVE): Likewise.\n\t(X86_TUNE_PUSH_MEMORY): Likewise.\n\t(X86_TUNE_MISALIGNED_MOVE_STRING_PRO_EPILOGUES): Likewise.\n\t(X86_TUNE_USE_CLTD): Likewise.\n\t(X86_TUNE_AVOID_FALSE_DEP_FOR_BMI): Likewise.\n\t(X86_TUNE_AVOID_MFENCE): Likewise.\n\t(X86_TUNE_SSE_TYPELESS_STORES): Likewise.\n\t(X86_TUNE_SSE_LOAD0_BY_PXOR): Likewise.\n\t(X86_TUNE_ACCUMULATE_OUTGOING_ARGS): Disable for Tremont.\n\t(X86_TUNE_FOUR_JUMP_LIMIT): Likewise.\n\t(X86_TUNE_OPT_AGU): Likewise.\n\t(X86_TUNE_AVOID_LEA_FOR_ADDR): Likewise.\n\t(X86_TUNE_AVOID_MEM_OPND_FOR_CMOVE): Likewise.\n\t(X86_TUNE_EXPAND_ABS): Likewise.\n\t(X86_TUNE_SPLIT_MEM_OPND_FOR_FP_CONVERTS): Likewise.\n\t(X86_TUNE_SLOW_PSHUFB): Likewise.", "tree": {"sha": "c601f18d62399c6b004581f56e6ea014fce29f1f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c601f18d62399c6b004581f56e6ea014fce29f1f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/61b03ade93b0f47dd888cd5228f017979c494263", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/61b03ade93b0f47dd888cd5228f017979c494263", "html_url": "https://github.com/Rust-GCC/gccrs/commit/61b03ade93b0f47dd888cd5228f017979c494263", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/61b03ade93b0f47dd888cd5228f017979c494263/comments", "author": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "committer": {"login": "algebra84", "id": 22926165, "node_id": "MDQ6VXNlcjIyOTI2MTY1", "avatar_url": "https://avatars.githubusercontent.com/u/22926165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/algebra84", "html_url": "https://github.com/algebra84", "followers_url": "https://api.github.com/users/algebra84/followers", "following_url": "https://api.github.com/users/algebra84/following{/other_user}", "gists_url": "https://api.github.com/users/algebra84/gists{/gist_id}", "starred_url": "https://api.github.com/users/algebra84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/algebra84/subscriptions", "organizations_url": "https://api.github.com/users/algebra84/orgs", "repos_url": "https://api.github.com/users/algebra84/repos", "events_url": "https://api.github.com/users/algebra84/events{/privacy}", "received_events_url": "https://api.github.com/users/algebra84/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "687e30d9d74f5c69a54617147ce3433b07ee59ce", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/687e30d9d74f5c69a54617147ce3433b07ee59ce", "html_url": "https://github.com/Rust-GCC/gccrs/commit/687e30d9d74f5c69a54617147ce3433b07ee59ce"}], "stats": {"total": 42, "additions": 23, "deletions": 19}, "files": [{"sha": "2c9e1ccbc6e6fd9366b3de9e48eccad2ff385d2a", "filename": "gcc/common/config/i386/i386-common.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fcommon%2Fconfig%2Fi386%2Fi386-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fcommon%2Fconfig%2Fi386%2Fi386-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcommon%2Fconfig%2Fi386%2Fi386-common.c?ref=61b03ade93b0f47dd888cd5228f017979c494263", "patch": "@@ -1935,7 +1935,7 @@ const pta processor_alias_table[] =\n     M_CPU_TYPE (INTEL_GOLDMONT), P_PROC_SSE4_2},\n   {\"goldmont-plus\", PROCESSOR_GOLDMONT_PLUS, CPU_GLM, PTA_GOLDMONT_PLUS,\n     M_CPU_TYPE (INTEL_GOLDMONT_PLUS), P_PROC_SSE4_2},\n-  {\"tremont\", PROCESSOR_TREMONT, CPU_GLM, PTA_TREMONT,\n+  {\"tremont\", PROCESSOR_TREMONT, CPU_HASWELL, PTA_TREMONT,\n     M_CPU_TYPE (INTEL_TREMONT), P_PROC_SSE4_2},\n   {\"knl\", PROCESSOR_KNL, CPU_SLM, PTA_KNL,\n     M_CPU_TYPE (INTEL_KNL), P_PROC_AVX512F},"}, {"sha": "afc2674d49da370ae0f5ef277df7e9954f303b8e", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=61b03ade93b0f47dd888cd5228f017979c494263", "patch": "@@ -16976,6 +16976,7 @@ ix86_sched_init_global (FILE *, int, int)\n     case PROCESSOR_NEHALEM:\n     case PROCESSOR_SANDYBRIDGE:\n     case PROCESSOR_HASWELL:\n+    case PROCESSOR_TREMONT:\n     case PROCESSOR_GENERIC:\n       /* Do not perform multipass scheduling for pre-reload schedule\n          to save compile time.  */"}, {"sha": "56ada99a4507fa020b4323a976cc8685c65df5d6", "filename": "gcc/config/i386/x86-tune-sched.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fconfig%2Fi386%2Fx86-tune-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fconfig%2Fi386%2Fx86-tune-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fx86-tune-sched.c?ref=61b03ade93b0f47dd888cd5228f017979c494263", "patch": "@@ -71,6 +71,7 @@ ix86_issue_rate (void)\n     case PROCESSOR_NEHALEM:\n     case PROCESSOR_SANDYBRIDGE:\n     case PROCESSOR_HASWELL:\n+    case PROCESSOR_TREMONT:\n     case PROCESSOR_GENERIC:\n       return 4;\n \n@@ -429,6 +430,7 @@ ix86_adjust_cost (rtx_insn *insn, int dep_type, rtx_insn *dep_insn, int cost,\n     case PROCESSOR_NEHALEM:\n     case PROCESSOR_SANDYBRIDGE:\n     case PROCESSOR_HASWELL:\n+    case PROCESSOR_TREMONT:\n     case PROCESSOR_GENERIC:\n       /* Stack engine allows to execute push&pop instructions in parall.  */\n       if ((insn_type == TYPE_PUSH || insn_type == TYPE_POP)"}, {"sha": "385e275bbd9f6bdba5d9d0647ba14be65bc72cf8", "filename": "gcc/config/i386/x86-tune.def", "status": "modified", "additions": 19, "deletions": 18, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/61b03ade93b0f47dd888cd5228f017979c494263/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fx86-tune.def?ref=61b03ade93b0f47dd888cd5228f017979c494263", "patch": "@@ -62,7 +62,7 @@ DEF_TUNE (X86_TUNE_PARTIAL_REG_DEPENDENCY, \"partial_reg_dependency\",\n    that can be partly masked by careful scheduling of moves.  */\n DEF_TUNE (X86_TUNE_SSE_PARTIAL_REG_DEPENDENCY, \"sse_partial_reg_dependency\",\n           m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_AMDFAM10\n-\t  | m_BDVER | m_ZNVER | m_GENERIC)\n+\t  | m_BDVER | m_ZNVER | m_TREMONT | m_GENERIC)\n \n /* X86_TUNE_SSE_SPLIT_REGS: Set for machines where the type and dependencies\n    are resolved on SSE register parts instead of whole registers, so we may\n@@ -136,7 +136,7 @@ DEF_TUNE (X86_TUNE_FUSE_ALU_AND_BRANCH, \"fuse_alu_and_branch\",\n \n DEF_TUNE (X86_TUNE_ACCUMULATE_OUTGOING_ARGS, \"accumulate_outgoing_args\",\n \t  m_PPRO | m_P4_NOCONA | m_BONNELL | m_SILVERMONT | m_KNL | m_KNM | m_INTEL\n-\t  | m_GOLDMONT | m_GOLDMONT_PLUS | m_TREMONT | m_ATHLON_K8)\n+\t  | m_GOLDMONT | m_GOLDMONT_PLUS | m_ATHLON_K8)\n \n /* X86_TUNE_PROLOGUE_USING_MOVE: Do not use push/pop in prologues that are\n    considered on critical path.  */\n@@ -150,14 +150,15 @@ DEF_TUNE (X86_TUNE_EPILOGUE_USING_MOVE, \"epilogue_using_move\",\n \n /* X86_TUNE_USE_LEAVE: Use \"leave\" instruction in epilogues where it fits.  */\n DEF_TUNE (X86_TUNE_USE_LEAVE, \"use_leave\",\n-\t  m_386 | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE | m_GENERIC)\n+\t  m_386 | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE | m_TREMONT\n+\t  | m_GENERIC)\n \n /* X86_TUNE_PUSH_MEMORY: Enable generation of \"push mem\" instructions.\n    Some chips, like 486 and Pentium works faster with separate load\n    and push instructions.  */\n DEF_TUNE (X86_TUNE_PUSH_MEMORY, \"push_memory\",\n           m_386 | m_P4_NOCONA | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE\n-          | m_GENERIC)\n+          | m_TREMONT | m_GENERIC)\n \n /* X86_TUNE_SINGLE_PUSH: Enable if single push insn is preferred\n    over esp subtraction.  */\n@@ -198,8 +199,7 @@ DEF_TUNE (X86_TUNE_PAD_RETURNS, \"pad_returns\",\n    than 4 branch instructions in the 16 byte window.  */\n DEF_TUNE (X86_TUNE_FOUR_JUMP_LIMIT, \"four_jump_limit\",\n           m_PPRO | m_P4_NOCONA | m_BONNELL | m_SILVERMONT | m_KNL | m_KNM\n-\t  | m_GOLDMONT | m_GOLDMONT_PLUS | m_TREMONT | m_INTEL | m_ATHLON_K8\n-\t  | m_AMDFAM10)\n+\t  | m_GOLDMONT | m_GOLDMONT_PLUS | m_INTEL | m_ATHLON_K8 | m_AMDFAM10)\n \n /*****************************************************************************/\n /* Integer instruction selection tuning                                      */\n@@ -240,11 +240,11 @@ DEF_TUNE (X86_TUNE_INTEGER_DFMODE_MOVES, \"integer_dfmode_moves\",\n /* X86_TUNE_OPT_AGU: Optimize for Address Generation Unit. This flag\n    will impact LEA instruction selection. */\n DEF_TUNE (X86_TUNE_OPT_AGU, \"opt_agu\", m_BONNELL | m_SILVERMONT | m_KNL\n-\t | m_KNM | m_GOLDMONT | m_GOLDMONT_PLUS | m_TREMONT | m_INTEL)\n+\t | m_KNM | m_GOLDMONT | m_GOLDMONT_PLUS | m_INTEL)\n \n /* X86_TUNE_AVOID_LEA_FOR_ADDR: Avoid lea for address computation.  */\n DEF_TUNE (X86_TUNE_AVOID_LEA_FOR_ADDR, \"avoid_lea_for_addr\",\n-\t  m_BONNELL | m_SILVERMONT | m_GOLDMONT | m_GOLDMONT_PLUS | m_TREMONT\n+\t  m_BONNELL | m_SILVERMONT | m_GOLDMONT | m_GOLDMONT_PLUS\n \t  | m_KNL | m_KNM)\n \n /* X86_TUNE_SLOW_IMUL_IMM32_MEM: Imul of 32-bit constant and memory is\n@@ -263,7 +263,7 @@ DEF_TUNE (X86_TUNE_SLOW_IMUL_IMM8, \"slow_imul_imm8\",\n    a conditional move.  */\n DEF_TUNE (X86_TUNE_AVOID_MEM_OPND_FOR_CMOVE, \"avoid_mem_opnd_for_cmove\",\n \t  m_BONNELL | m_SILVERMONT | m_GOLDMONT | m_GOLDMONT_PLUS | m_KNL\n-\t  | m_KNM | m_TREMONT | m_INTEL)\n+\t  | m_KNM | m_INTEL)\n \n /* X86_TUNE_SINGLE_STRINGOP: Enable use of single string operations, such\n    as MOVS and STOS (without a REP prefix) to move/set sequences of bytes.  */\n@@ -282,7 +282,8 @@ DEF_TUNE (X86_TUNE_PREFER_KNOWN_REP_MOVSB_STOSB,\n    FIXME: This may actualy be a win on more targets than listed here.  */\n DEF_TUNE (X86_TUNE_MISALIGNED_MOVE_STRING_PRO_EPILOGUES,\n \t  \"misaligned_move_string_pro_epilogues\",\n-\t  m_386 | m_486 | m_CORE_ALL | m_AMD_MULTIPLE | m_GENERIC)\n+\t  m_386 | m_486 | m_CORE_ALL | m_AMD_MULTIPLE | m_TREMONT\n+\t  | m_GENERIC)\n \n /* X86_TUNE_USE_SAHF: Controls use of SAHF.  */\n DEF_TUNE (X86_TUNE_USE_SAHF, \"use_sahf\",\n@@ -294,7 +295,7 @@ DEF_TUNE (X86_TUNE_USE_SAHF, \"use_sahf\",\n /* X86_TUNE_USE_CLTD: Controls use of CLTD and CTQO instructions.  */\n DEF_TUNE (X86_TUNE_USE_CLTD, \"use_cltd\",\n \t  ~(m_PENT | m_LAKEMONT | m_BONNELL | m_SILVERMONT | m_KNL | m_KNM | m_INTEL\n-\t    | m_K6 | m_GOLDMONT | m_GOLDMONT_PLUS | m_TREMONT))\n+\t    | m_K6 | m_GOLDMONT | m_GOLDMONT_PLUS))\n \n /* X86_TUNE_USE_BT: Enable use of BT (bit test) instructions.  */\n DEF_TUNE (X86_TUNE_USE_BT, \"use_bt\",\n@@ -305,7 +306,7 @@ DEF_TUNE (X86_TUNE_USE_BT, \"use_bt\",\n /* X86_TUNE_AVOID_FALSE_DEP_FOR_BMI: Avoid false dependency\n    for bit-manipulation instructions.  */\n DEF_TUNE (X86_TUNE_AVOID_FALSE_DEP_FOR_BMI, \"avoid_false_dep_for_bmi\",\n-\t  m_SANDYBRIDGE | m_CORE_AVX2 | m_GENERIC)\n+\t  m_SANDYBRIDGE | m_CORE_AVX2 | m_TREMONT | m_GENERIC)\n \n /* X86_TUNE_ADJUST_UNROLL: This enables adjusting the unroll factor based\n    on hardware capabilities. Bdver3 hardware has a loop buffer which makes\n@@ -321,14 +322,14 @@ DEF_TUNE (X86_TUNE_ONE_IF_CONV_INSN, \"one_if_conv_insn\",\n \n /* X86_TUNE_AVOID_MFENCE: Use lock prefixed instructions instead of mfence.  */\n DEF_TUNE (X86_TUNE_AVOID_MFENCE, \"avoid_mfence\",\n-\t m_CORE_ALL | m_BDVER | m_ZNVER | m_GENERIC)\n+\t m_CORE_ALL | m_BDVER | m_ZNVER | m_TREMONT | m_GENERIC)\n \n /* X86_TUNE_EXPAND_ABS: This enables a new abs pattern by\n    generating instructions for abs (x) = (((signed) x >> (W-1) ^ x) -\n    (signed) x >> (W-1)) instead of cmove or SSE max/abs instructions.  */\n DEF_TUNE (X86_TUNE_EXPAND_ABS, \"expand_abs\",\n \t  m_CORE_ALL | m_SILVERMONT | m_KNL | m_KNM | m_GOLDMONT\n-\t  | m_GOLDMONT_PLUS | m_TREMONT )\n+\t  | m_GOLDMONT_PLUS)\n \n /*****************************************************************************/\n /* 387 instruction selection tuning                                          */\n@@ -386,13 +387,13 @@ DEF_TUNE (X86_TUNE_SSE_PACKED_SINGLE_INSN_OPTIMAL, \"sse_packed_single_insn_optim\n \n /* X86_TUNE_SSE_TYPELESS_STORES: Always movaps/movups for 128bit stores.   */\n DEF_TUNE (X86_TUNE_SSE_TYPELESS_STORES, \"sse_typeless_stores\",\n-\t  m_AMD_MULTIPLE | m_CORE_ALL | m_GENERIC)\n+\t  m_AMD_MULTIPLE | m_CORE_ALL | m_TREMONT | m_GENERIC)\n \n /* X86_TUNE_SSE_LOAD0_BY_PXOR: Always use pxor to load0 as opposed to\n    xorps/xorpd and other variants.  */\n DEF_TUNE (X86_TUNE_SSE_LOAD0_BY_PXOR, \"sse_load0_by_pxor\",\n \t  m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_BDVER | m_BTVER | m_ZNVER\n-\t  | m_GENERIC)\n+\t  | m_TREMONT | m_GENERIC)\n \n /* X86_TUNE_INTER_UNIT_MOVES_TO_VEC: Enable moves in from integer\n    to SSE registers.  If disabled, the moves will be done by storing\n@@ -419,7 +420,7 @@ DEF_TUNE (X86_TUNE_INTER_UNIT_CONVERSIONS, \"inter_unit_conversions\",\n    fp converts to destination register.  */\n DEF_TUNE (X86_TUNE_SPLIT_MEM_OPND_FOR_FP_CONVERTS, \"split_mem_opnd_for_fp_converts\",\n \t  m_SILVERMONT | m_KNL | m_KNM | m_GOLDMONT | m_GOLDMONT_PLUS\n-\t  | m_TREMONT | m_INTEL)\n+\t  | m_INTEL)\n \n /* X86_TUNE_USE_VECTOR_FP_CONVERTS: Prefer vector packed SSE conversion\n    from FP to FP.  This form of instructions avoids partial write to the\n@@ -434,7 +435,7 @@ DEF_TUNE (X86_TUNE_USE_VECTOR_CONVERTS, \"use_vector_converts\", m_AMDFAM10)\n /* X86_TUNE_SLOW_SHUFB: Indicates tunings with slow pshufb instruction.  */\n DEF_TUNE (X86_TUNE_SLOW_PSHUFB, \"slow_pshufb\",\n \t  m_BONNELL | m_SILVERMONT | m_KNL | m_KNM | m_GOLDMONT\n-\t  | m_GOLDMONT_PLUS | m_TREMONT | m_INTEL)\n+\t  | m_GOLDMONT_PLUS | m_INTEL)\n \n /* X86_TUNE_AVOID_4BYTE_PREFIXES: Avoid instructions requiring 4+ bytes of prefixes.  */\n DEF_TUNE (X86_TUNE_AVOID_4BYTE_PREFIXES, \"avoid_4byte_prefixes\","}]}