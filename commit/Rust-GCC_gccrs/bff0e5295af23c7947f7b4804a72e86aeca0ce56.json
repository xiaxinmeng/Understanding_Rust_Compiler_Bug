{"sha": "bff0e5295af23c7947f7b4804a72e86aeca0ce56", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmZmMGU1Mjk1YWYyM2M3OTQ3ZjdiNDgwNGE3MmU4NmFlY2EwY2U1Ng==", "commit": {"author": {"name": "Lawrence Crowl", "email": "crowl@google.com", "date": "2012-11-07T00:36:04Z"}, "committer": {"name": "Lawrence Crowl", "email": "crowl@gcc.gnu.org", "date": "2012-11-07T00:36:04Z"}, "message": "Add a contrib script for comparing the performance of two sets of\ncompiler runs.\n\nUsage documentation is in the script.\n\nThe script produces output of the form:\n\n$ compare_two_ftime_report_sets \"Log0/*perf\" \"Log3/*perf\" \n\nArithmetic sample for timevar log files\n\"Log0/*perf\"\nand selecting lines containing \"TOTAL\" with desired confidence 95 is \ntrial count is 4, mean is 443.022 (95% confidence in 440.234 to 445.811),\nstd.deviation is 1.75264, std.error is 0.876322\n\nArithmetic sample for timevar log files\n\"Log3/*perf\"\nand selecting lines containing \"TOTAL\" with desired confidence 95 is \ntrial count is 4, mean is 441.302 (95% confidence in 436.671 to 445.934),\nstd.deviation is 2.91098, std.error is 1.45549\n\nThe first sample appears to be 0.39% larger,\nwith 60% confidence of being larger.\nTo reach 95% confidence, you need roughly 14 trials,\nassuming the standard deviation is stable, which is iffy.\n\nTested on x86_64 builds.\n\n\nIndex: contrib/ChangeLog\n\n2012-11-05  Lawrence Crowl  <crowl@google.com>\n\n\t* compare_two_ftime_report_sets: New.\n\nFrom-SVN: r193277", "tree": {"sha": "8ab0c916dd01a2cfac2710a91391bbc30eaeb98e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8ab0c916dd01a2cfac2710a91391bbc30eaeb98e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/bff0e5295af23c7947f7b4804a72e86aeca0ce56", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bff0e5295af23c7947f7b4804a72e86aeca0ce56", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bff0e5295af23c7947f7b4804a72e86aeca0ce56", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bff0e5295af23c7947f7b4804a72e86aeca0ce56/comments", "author": null, "committer": null, "parents": [{"sha": "8f7a6877dbcd89fd253fd7a6e9ffdb2c7949063e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8f7a6877dbcd89fd253fd7a6e9ffdb2c7949063e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8f7a6877dbcd89fd253fd7a6e9ffdb2c7949063e"}], "stats": {"total": 609, "additions": 609, "deletions": 0}, "files": [{"sha": "ef5d6f6f9832c0b8c4dc0b931e96d0758ace5536", "filename": "contrib/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bff0e5295af23c7947f7b4804a72e86aeca0ce56/contrib%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bff0e5295af23c7947f7b4804a72e86aeca0ce56/contrib%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/contrib%2FChangeLog?ref=bff0e5295af23c7947f7b4804a72e86aeca0ce56", "patch": "@@ -1,3 +1,7 @@\n+2012-11-05  Lawrence Crowl  <crowl@google.com>\n+\n+\t* compare_two_ftime_report_sets: New.\n+\n 2012-11-02  Diego Novillo  <dnovillo@google.com>\n \n \t* testsuite-management/validate_failures.py: Add option"}, {"sha": "384dfde1d25c3831ec653bb41b063e80d511f59d", "filename": "contrib/compare_two_ftime_report_sets", "status": "added", "additions": 605, "deletions": 0, "changes": 605, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bff0e5295af23c7947f7b4804a72e86aeca0ce56/contrib%2Fcompare_two_ftime_report_sets", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bff0e5295af23c7947f7b4804a72e86aeca0ce56/contrib%2Fcompare_two_ftime_report_sets", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/contrib%2Fcompare_two_ftime_report_sets?ref=bff0e5295af23c7947f7b4804a72e86aeca0ce56", "patch": "@@ -0,0 +1,605 @@\n+#!/usr/bin/python\n+\n+# Script to statistically compare two sets of log files with -ftime-report\n+# output embedded within them.\n+\n+# Contributed by Lawrence Crowl <crowl@google.com>\n+#\n+# Copyright (C) 2012 Free Software Foundation, Inc.\n+#\n+# This file is part of GCC.\n+#\n+# GCC is free software; you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation; either version 3, or (at your option)\n+# any later version.\n+#\n+# GCC is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+#\n+# You should have received a copy of the GNU General Public License\n+# along with GCC; see the file COPYING.  If not, write to\n+# the Free Software Foundation, 51 Franklin Street, Fifth Floor,\n+# Boston, MA 02110-1301, USA.\n+\n+\n+\"\"\" Compare two sets of compile-time performance numbers.\n+\n+The intent of this script is to compare compile-time performance of two\n+different versions of the compiler.  Each version of the compiler must be\n+run at least three times with the -ftime-report option.  Each log file\n+represents a data point, or trial.  The set of trials for each compiler\n+version constitutes a sample.  The ouput of the script is a description\n+of the statistically significant difference between the two version of\n+the compiler.\n+\n+The parameters to the script are:\n+\n+  Two file patterns that each match a set of log files.  You will probably\n+  need to quote the patterns before passing them to the script.\n+\n+    Each pattern corresponds to a version of the compiler.\n+\n+  A regular expression that finds interesting lines in the log files.\n+  If you want to match the beginning of the line, you will need to add\n+  the ^ operator.  The filtering uses Python regular expression syntax.\n+\n+    The default is \"TOTAL\".\n+\n+    All of the interesting lines in a single log file are summed to produce\n+    a single trial (data point).\n+\n+  A desired statistical confidence within the range 60% to 99.9%.  Due to\n+  the implementation, this confidence will be rounded down to one of 60%,\n+  70%, 80%, 90%, 95%, 98%, 99%, 99.5%, 99.8%, and 99.9%.\n+\n+    The default is 95.\n+\n+    If the computed confidence is lower than desired, the script will\n+    estimate the number of trials needed to meet the desired confidence.\n+    This estimate is not very good, as the variance tends to change as\n+    you increase the number of trials.\n+\n+The most common use of the script is total compile-time comparison between\n+logfiles stored in different directories.\n+\n+compare_two_ftime_report_sets \"Log1/*perf\" \"Log2/*perf\"\n+\n+One can also look at parsing time, but expecting a lower confidence.\n+\n+compare_two_ftime_report_sets \"Log1/*perf\" \"Log2/*perf\" \"^phase parsing\" 75\n+\n+\"\"\"\n+\n+\n+import os\n+import sys\n+import fnmatch\n+import glob\n+import re\n+import math\n+\n+\n+####################################################################### Utility\n+\n+\n+def divide(dividend, divisor):\n+  \"\"\" Return the quotient, avoiding division by zero.\n+  \"\"\"\n+  if divisor == 0:\n+    return sys.float_info.max\n+  else:\n+    return dividend / divisor\n+\n+\n+################################################################# File and Line\n+\n+\n+# Should you repurpose this script, this code might help.\n+#\n+#def find_files(topdir, filepat):\n+#  \"\"\" Find a set of file names, under a given directory,\n+#  matching a Unix shell file pattern.\n+#  Returns an iterator over the file names.\n+#  \"\"\"\n+#  for path, dirlist, filelist in os.walk(topdir):\n+#    for name in fnmatch.filter(filelist, filepat):\n+#      yield os.path.join(path, name)\n+\n+\n+def match_files(fileglob):\n+  \"\"\" Find a set of file names matching a Unix shell glob pattern.\n+  Returns an iterator over the file names.\n+  \"\"\"\n+  return glob.iglob(os.path.expanduser(fileglob))\n+\n+\n+def lines_in_file(filename):\n+  \"\"\" Return an iterator over lines in the named file.  \"\"\"\n+  filedesc = open(filename, \"r\")\n+  for line in filedesc:\n+    yield line\n+  filedesc.close()\n+\n+\n+def lines_containing_pattern(pattern, lines):\n+  \"\"\" Find lines by a Python regular-expression.\n+  Returns an iterator over lines containing the expression.\n+  \"\"\"\n+  parser = re.compile(pattern)\n+  for line in lines:\n+    if parser.search(line):\n+      yield line\n+\n+\n+############################################################# Number Formatting\n+\n+\n+def strip_redundant_digits(numrep):\n+  if numrep.find(\".\") == -1:\n+    return numrep\n+  return numrep.rstrip(\"0\").rstrip(\".\")\n+\n+\n+def text_number(number):\n+  return strip_redundant_digits(\"%g\" % number)\n+\n+\n+def round_significant(digits, number):\n+  if number == 0:\n+    return 0\n+  magnitude = abs(number)\n+  significance = math.floor(math.log10(magnitude))\n+  least_position = int(significance - digits + 1)\n+  return round(number, -least_position)\n+\n+\n+def text_significant(digits, number):\n+  return text_number(round_significant(digits, number))\n+\n+\n+def text_percent(number):\n+  return text_significant(3, number*100) + \"%\"\n+\n+\n+################################################################ T-Distribution\n+\n+\n+# This section of code provides functions for using Student's t-distribution.\n+\n+\n+# The functions are implemented using table lookup\n+# to facilitate implementation of inverse functions.\n+\n+\n+# The table is comprised of row 0 listing the alpha values,\n+# column 0 listing the degree-of-freedom values,\n+# and the other entries listing the corresponding t-distribution values.\n+\n+t_dist_table = [\n+[  0, 0.200, 0.150, 0.100, 0.050, 0.025, 0.010, 0.005, .0025, 0.001, .0005],\n+[  1, 1.376, 1.963, 3.078, 6.314, 12.71, 31.82, 63.66, 127.3, 318.3, 636.6],\n+[  2, 1.061, 1.386, 1.886, 2.920, 4.303, 6.965, 9.925, 14.09, 22.33, 31.60],\n+[  3, 0.978, 1.250, 1.638, 2.353, 3.182, 4.541, 5.841, 7.453, 10.21, 12.92],\n+[  4, 0.941, 1.190, 1.533, 2.132, 2.776, 3.747, 4.604, 5.598, 7.173, 8.610],\n+[  5, 0.920, 1.156, 1.476, 2.015, 2.571, 3.365, 4.032, 4.773, 5.894, 6.869],\n+[  6, 0.906, 1.134, 1.440, 1.943, 2.447, 3.143, 3.707, 4.317, 5.208, 5.959],\n+[  7, 0.896, 1.119, 1.415, 1.895, 2.365, 2.998, 3.499, 4.029, 4.785, 5.408],\n+[  8, 0.889, 1.108, 1.397, 1.860, 2.306, 2.896, 3.355, 3.833, 4.501, 5.041],\n+[  9, 0.883, 1.100, 1.383, 1.833, 2.262, 2.821, 3.250, 3.690, 4.297, 4.781],\n+[ 10, 0.879, 1.093, 1.372, 1.812, 2.228, 2.764, 3.169, 3.581, 4.144, 4.587],\n+[ 11, 0.876, 1.088, 1.363, 1.796, 2.201, 2.718, 3.106, 3.497, 4.025, 4.437],\n+[ 12, 0.873, 1.083, 1.356, 1.782, 2.179, 2.681, 3.055, 3.428, 3.930, 4.318],\n+[ 13, 0.870, 1.079, 1.350, 1.771, 2.160, 2.650, 3.012, 3.372, 3.852, 4.221],\n+[ 14, 0.868, 1.076, 1.345, 1.761, 2.145, 2.624, 2.977, 3.326, 3.787, 4.140],\n+[ 15, 0.866, 1.074, 1.341, 1.753, 2.131, 2.602, 2.947, 3.286, 3.733, 4.073],\n+[ 16, 0.865, 1.071, 1.337, 1.746, 2.120, 2.583, 2.921, 3.252, 3.686, 4.015],\n+[ 17, 0.863, 1.069, 1.333, 1.740, 2.110, 2.567, 2.898, 3.222, 3.646, 3.965],\n+[ 18, 0.862, 1.067, 1.330, 1.734, 2.101, 2.552, 2.878, 3.197, 3.610, 3.922],\n+[ 19, 0.861, 1.066, 1.328, 1.729, 2.093, 2.539, 2.861, 3.174, 3.579, 3.883],\n+[ 20, 0.860, 1.064, 1.325, 1.725, 2.086, 2.528, 2.845, 3.153, 3.552, 3.850],\n+[ 21, 0.859, 1.063, 1.323, 1.721, 2.080, 2.518, 2.831, 3.135, 3.527, 3.819],\n+[ 22, 0.858, 1.061, 1.321, 1.717, 2.074, 2.508, 2.819, 3.119, 3.505, 3.792],\n+[ 23, 0.858, 1.060, 1.319, 1.714, 2.069, 2.500, 2.807, 3.104, 3.485, 3.768],\n+[ 24, 0.857, 1.059, 1.318, 1.711, 2.064, 2.492, 2.797, 3.091, 3.467, 3.745],\n+[ 25, 0.856, 1.058, 1.316, 1.708, 2.060, 2.485, 2.787, 3.078, 3.450, 3.725],\n+[ 26, 0.856, 1.058, 1.315, 1.706, 2.056, 2.479, 2.779, 3.067, 3.435, 3.707],\n+[ 27, 0.855, 1.057, 1.314, 1.703, 2.052, 2.473, 2.771, 3.057, 3.421, 3.689],\n+[ 28, 0.855, 1.056, 1.313, 1.701, 2.048, 2.467, 2.763, 3.047, 3.408, 3.674],\n+[ 29, 0.854, 1.055, 1.311, 1.699, 2.045, 2.462, 2.756, 3.038, 3.396, 3.660],\n+[ 30, 0.854, 1.055, 1.310, 1.697, 2.042, 2.457, 2.750, 3.030, 3.385, 3.646],\n+[ 31, 0.853, 1.054, 1.309, 1.696, 2.040, 2.453, 2.744, 3.022, 3.375, 3.633],\n+[ 32, 0.853, 1.054, 1.309, 1.694, 2.037, 2.449, 2.738, 3.015, 3.365, 3.622],\n+[ 33, 0.853, 1.053, 1.308, 1.692, 2.035, 2.445, 2.733, 3.008, 3.356, 3.611],\n+[ 34, 0.852, 1.052, 1.307, 1.691, 2.032, 2.441, 2.728, 3.002, 3.348, 3.601],\n+[ 35, 0.852, 1.052, 1.306, 1.690, 2.030, 2.438, 2.724, 2.996, 3.340, 3.591],\n+[ 36, 0.852, 1.052, 1.306, 1.688, 2.028, 2.434, 2.719, 2.990, 3.333, 3.582],\n+[ 37, 0.851, 1.051, 1.305, 1.687, 2.026, 2.431, 2.715, 2.985, 3.326, 3.574],\n+[ 38, 0.851, 1.051, 1.304, 1.686, 2.024, 2.429, 2.712, 2.980, 3.319, 3.566],\n+[ 39, 0.851, 1.050, 1.304, 1.685, 2.023, 2.426, 2.708, 2.976, 3.313, 3.558],\n+[ 40, 0.851, 1.050, 1.303, 1.684, 2.021, 2.423, 2.704, 2.971, 3.307, 3.551],\n+[ 50, 0.849, 1.047, 1.299, 1.676, 2.009, 2.403, 2.678, 2.937, 3.261, 3.496],\n+[ 60, 0.848, 1.045, 1.296, 1.671, 2.000, 2.390, 2.660, 2.915, 3.232, 3.460],\n+[ 80, 0.846, 1.043, 1.292, 1.664, 1.990, 2.374, 2.639, 2.887, 3.195, 3.416],\n+[100, 0.845, 1.042, 1.290, 1.660, 1.984, 2.364, 2.626, 2.871, 3.174, 3.390],\n+[150, 0.844, 1.040, 1.287, 1.655, 1.976, 2.351, 2.609, 2.849, 3.145, 3.357] ]\n+\n+\n+# The functions use the following parameter name conventions:\n+# alpha - the alpha parameter\n+# degree - the degree-of-freedom parameter\n+# value - the t-distribution value for some alpha and degree\n+# deviations - a confidence interval radius,\n+#   expressed as a multiple of the standard deviation of the sample\n+# ax - the alpha parameter index\n+# dx - the degree-of-freedom parameter index\n+\n+# The interface to this section of code is the last three functions,\n+# find_t_dist_value, find_t_dist_alpha, and find_t_dist_degree.\n+\n+\n+def t_dist_alpha_at_index(ax):\n+  if ax == 0:\n+    return .25 # effectively no confidence\n+  else:\n+    return t_dist_table[0][ax]\n+\n+\n+def t_dist_degree_at_index(dx):\n+  return t_dist_table[dx][0]\n+\n+\n+def t_dist_value_at_index(ax, dx):\n+  return t_dist_table[dx][ax]\n+\n+\n+def t_dist_index_of_degree(degree):\n+  limit = len(t_dist_table) - 1\n+  dx = 0\n+  while dx < limit and t_dist_degree_at_index(dx+1) <= degree:\n+    dx += 1\n+  return dx\n+\n+\n+def t_dist_index_of_alpha(alpha):\n+  limit = len(t_dist_table[0]) - 1\n+  ax = 0\n+  while ax < limit and t_dist_alpha_at_index(ax+1) >= alpha:\n+    ax += 1\n+  return ax\n+\n+\n+def t_dist_index_of_value(dx, value):\n+  limit = len(t_dist_table[dx]) - 1\n+  ax = 0\n+  while ax < limit and t_dist_value_at_index(ax+1, dx) < value:\n+    ax += 1\n+  return ax\n+\n+\n+def t_dist_value_within_deviations(dx, ax, deviations):\n+  degree = t_dist_degree_at_index(dx)\n+  count = degree + 1\n+  root = math.sqrt(count)\n+  value = t_dist_value_at_index(ax, dx)\n+  nominal = value / root\n+  comparison = nominal <= deviations\n+  return comparison\n+\n+\n+def t_dist_index_of_degree_for_deviations(ax, deviations):\n+  limit = len(t_dist_table) - 1\n+  dx = 1\n+  while dx < limit and not t_dist_value_within_deviations(dx, ax, deviations):\n+    dx += 1\n+  return dx\n+\n+\n+def find_t_dist_value(alpha, degree):\n+  \"\"\" Return the t-distribution value.\n+  The parameters are alpha and degree of freedom.\n+  \"\"\"\n+  dx = t_dist_index_of_degree(degree)\n+  ax = t_dist_index_of_alpha(alpha)\n+  return t_dist_value_at_index(ax, dx)\n+\n+\n+def find_t_dist_alpha(value, degree):\n+  \"\"\" Return the alpha.\n+  The parameters are the t-distribution value for a given degree of freedom.\n+  \"\"\"\n+  dx = t_dist_index_of_degree(degree)\n+  ax = t_dist_index_of_value(dx, value)\n+  return t_dist_alpha_at_index(ax)\n+\n+\n+def find_t_dist_degree(alpha, deviations):\n+  \"\"\" Return the degree-of-freedom.\n+  The parameters are the desired alpha and the number of standard deviations\n+  away from the mean that the degree should handle.\n+  \"\"\"\n+  ax = t_dist_index_of_alpha(alpha)\n+  dx = t_dist_index_of_degree_for_deviations(ax, deviations)\n+  return t_dist_degree_at_index(dx)\n+\n+\n+############################################################## Core Statistical\n+\n+\n+# This section provides the core statistical classes and functions.\n+\n+\n+class Accumulator:\n+\n+  \"\"\" An accumulator for statistical information using arithmetic mean.  \"\"\"\n+\n+  def __init__(self):\n+    self.count = 0\n+    self.mean = 0\n+    self.sumsqdiff = 0\n+\n+  def insert(self, value):\n+    self.count += 1\n+    diff = value - self.mean\n+    self.mean += diff / self.count\n+    self.sumsqdiff += (self.count - 1) * diff * diff / self.count\n+\n+\n+def fill_accumulator_from_values(values):\n+  accumulator = Accumulator()\n+  for value in values:\n+    accumulator.insert(value)\n+  return accumulator\n+\n+\n+def alpha_from_confidence(confidence):\n+  scrubbed = min(99.99, max(confidence, 60))\n+  return (100.0 - scrubbed) / 200.0\n+\n+\n+def confidence_from_alpha(alpha):\n+  return 100 - 200 * alpha\n+\n+\n+class Sample:\n+\n+  \"\"\" A description of a sample using an arithmetic mean.  \"\"\"\n+\n+  def __init__(self, accumulator, alpha):\n+    if accumulator.count < 3:\n+      sys.exit(\"Samples must contain three trials.\")\n+    self.count = accumulator.count\n+    self.mean = accumulator.mean\n+    variance = accumulator.sumsqdiff / (self.count - 1)\n+    self.deviation = math.sqrt(variance)\n+    self.error = self.deviation / math.sqrt(self.count)\n+    self.alpha = alpha\n+    self.radius = find_t_dist_value(alpha, self.count - 1) * self.error\n+\n+  def alpha_for_radius(self, radius):\n+    return find_t_dist_alpha(divide(radius, self.error), self.count)\n+\n+  def degree_for_radius(self, radius):\n+    return find_t_dist_degree(self.alpha, divide(radius, self.deviation))\n+\n+  def __str__(self):\n+    text = \"trial count is \" + text_number(self.count)\n+    text += \", mean is \" + text_number(self.mean)\n+    text += \" (\" + text_number(confidence_from_alpha(self.alpha)) +\"%\"\n+    text += \" confidence in \" + text_number(self.mean - self.radius)\n+    text += \" to \" + text_number(self.mean + self.radius) + \")\"\n+    text += \",\\nstd.deviation is \" + text_number(self.deviation)\n+    text += \", std.error is \" + text_number(self.error)\n+    return text\n+\n+\n+def sample_from_values(values, alpha):\n+  accumulator = fill_accumulator_from_values(values)\n+  return Sample(accumulator, alpha)\n+\n+\n+class Comparison:\n+\n+  \"\"\" A comparison of two samples using arithmetic means.  \"\"\"\n+\n+  def __init__(self, first, second, alpha):\n+    if first.mean > second.mean:\n+      self.upper = first\n+      self.lower = second\n+      self.larger = \"first\"\n+    else:\n+      self.upper = second\n+      self.lower = first\n+      self.larger = \"second\"\n+    self.a_wanted = alpha\n+    radius = self.upper.mean - self.lower.mean\n+    rising = self.lower.alpha_for_radius(radius)\n+    falling = self.upper.alpha_for_radius(radius)\n+    self.a_actual = max(rising, falling)\n+    rising = self.lower.degree_for_radius(radius)\n+    falling = self.upper.degree_for_radius(radius)\n+    self.count = max(rising, falling) + 1\n+\n+  def __str__(self):\n+    message = \"The \" + self.larger + \" sample appears to be \"\n+    change = divide(self.upper.mean, self.lower.mean) - 1\n+    message += text_percent(change) + \" larger,\\n\"\n+    confidence = confidence_from_alpha(self.a_actual)\n+    if confidence >= 60:\n+      message += \"with \" + text_number(confidence) + \"% confidence\"\n+      message += \" of being larger.\"\n+    else:\n+      message += \"but with no confidence of actually being larger.\"\n+    if self.a_actual > self.a_wanted:\n+      confidence = confidence_from_alpha(self.a_wanted)\n+      message += \"\\nTo reach \" + text_number(confidence) + \"% confidence,\"\n+      if self.count < 100:\n+        message += \" you need roughly \" + text_number(self.count) + \" trials,\\n\"\n+        message += \"assuming the standard deviation is stable, which is iffy.\"\n+      else:\n+        message += \"\\nyou need to reduce the larger deviation\"\n+        message += \" or increase the number of trials.\"\n+    return message\n+\n+\n+############################################################ Single Value Files\n+\n+\n+# This section provides functions to compare two raw data files,\n+# each containing a whole sample consisting of single number per line.\n+\n+\n+# Should you repurpose this script, this code might help.\n+#\n+#def values_from_data_file(filename):\n+#  for line in lines_in_file(filename):\n+#    yield float(line)\n+\n+\n+# Should you repurpose this script, this code might help.\n+#\n+#def sample_from_data_file(filename, alpha):\n+#  confidence = confidence_from_alpha(alpha)\n+#  text = \"\\nArithmetic sample for data file\\n\\\"\" + filename + \"\\\"\"\n+#  text += \" with desired confidence \" + text_number(confidence) + \" is \"\n+#  print text\n+#  values = values_from_data_file(filename)\n+#  sample = sample_from_values(values, alpha)\n+#  print sample\n+#  return sample\n+\n+\n+# Should you repurpose this script, this code might help.\n+#\n+#def compare_two_data_files(filename1, filename2, confidence):\n+#  alpha = alpha_from_confidence(confidence)\n+#  sample1 = sample_from_data_file(filename1, alpha)\n+#  sample2 = sample_from_data_file(filename2, alpha)\n+#  print \n+#  print Comparison(sample1, sample2, alpha)\n+\n+\n+# Should you repurpose this script, this code might help.\n+#\n+#def command_two_data_files():\n+#  argc = len(sys.argv)\n+#  if argc < 2 or 4 < argc:\n+#    message = \"usage: \" + sys.argv[0]\n+#    message += \" file-name file-name [confidence]\"\n+#    print message\n+#  else:\n+#    filename1 = sys.argv[1]\n+#    filename2 = sys.argv[2]\n+#    if len(sys.argv) >= 4:\n+#      confidence = int(sys.argv[3])\n+#    else:\n+#      confidence = 95\n+#  compare_two_data_files(filename1, filename2, confidence)\n+\n+\n+############################################### -ftime-report TimeVar Log Files\n+\n+\n+# This section provides functions to compare two sets of -ftime-report log\n+# files.  Each set is a sample, where each data point is derived from the\n+# sum of values in a single log file.\n+\n+\n+label = r\"^ *([^:]*[^: ]) *:\"\n+number = r\" *([0-9.]*) *\"\n+percent = r\"\\( *[0-9]*\\%\\)\"\n+numpct = number + percent\n+total_format = label + number + number + number + number + \" kB\\n\"\n+total_parser = re.compile(total_format)\n+tmvar_format = label + numpct + \" usr\" + numpct + \" sys\"\n+tmvar_format += numpct + \" wall\" + number + \" kB \" + percent + \" ggc\\n\"\n+tmvar_parser = re.compile(tmvar_format)\n+replace = r\"\\2\\t\\3\\t\\4\\t\\5\\t\\1\"\n+\n+\n+def split_time_report(lines, pattern):\n+  if pattern == \"TOTAL\":\n+    parser = total_parser\n+  else:\n+    parser = tmvar_parser\n+  for line in lines:\n+    modified = parser.sub(replace, line)\n+    if modified != line:\n+      yield re.split(\"\\t\", modified)\n+\n+\n+def extract_cpu_time(tvtuples):\n+  for tuple in tvtuples:\n+    yield float(tuple[0]) + float(tuple[1])\n+\n+\n+def sum_values(values):\n+  sum = 0\n+  for value in values:\n+    sum += value\n+  return sum\n+\n+\n+def extract_time_for_timevar_log(filename, pattern):\n+  lines = lines_in_file(filename)\n+  tmvars = lines_containing_pattern(pattern, lines)\n+  tuples = split_time_report(tmvars, pattern)\n+  times = extract_cpu_time(tuples)\n+  return sum_values(times)\n+\n+\n+def extract_times_for_timevar_logs(filelist, pattern):\n+  for filename in filelist:\n+    yield extract_time_for_timevar_log(filename, pattern)\n+\n+\n+def sample_from_timevar_logs(fileglob, pattern, alpha):\n+  confidence = confidence_from_alpha(alpha)\n+  text = \"\\nArithmetic sample for timevar log files\\n\\\"\" + fileglob + \"\\\"\"\n+  text += \"\\nand selecting lines containing \\\"\" + pattern + \"\\\"\"\n+  text += \" with desired confidence \" + text_number(confidence) + \" is \"\n+  print text\n+  filelist = match_files(fileglob)\n+  values = extract_times_for_timevar_logs(filelist, pattern)\n+  sample = sample_from_values(values, alpha)\n+  print sample\n+  return sample\n+\n+\n+def compare_two_timevar_logs(fileglob1, fileglob2, pattern, confidence):\n+  alpha = alpha_from_confidence(confidence)\n+  sample1 = sample_from_timevar_logs(fileglob1, pattern, alpha)\n+  sample2 = sample_from_timevar_logs(fileglob2, pattern, alpha)\n+  print\n+  print Comparison(sample1, sample2, alpha)\n+\n+\n+def command_two_timevar_logs():\n+  argc = len(sys.argv)\n+  if argc < 3 or 5 < argc:\n+    message = \"usage: \" + sys.argv[0]\n+    message += \" file-pattern file-pattern [line-pattern [confidence]]\"\n+    print message\n+  else:\n+    filepat1 = sys.argv[1]\n+    filepat2 = sys.argv[2]\n+    if len(sys.argv) >= 5:\n+      confidence = int(sys.argv[4])\n+    else:\n+      confidence = 95\n+    if len(sys.argv) >= 4:\n+      linepat = sys.argv[3]\n+    else:\n+      linepat = \"TOTAL\"\n+    compare_two_timevar_logs(filepat1, filepat2, linepat, confidence)\n+\n+\n+########################################################################## Main\n+\n+\n+# This section is the main code, implementing the command.\n+\n+\n+command_two_timevar_logs()"}]}