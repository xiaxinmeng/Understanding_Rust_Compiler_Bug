{"sha": "6f52a889fdd6a6127889944fb7ae8a96e768d6c3", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NmY1MmE4ODlmZGQ2YTYxMjc4ODk5NDRmYjdhZThhOTZlNzY4ZDZjMw==", "commit": {"author": {"name": "Paolo Carlini", "email": "paolo@gcc.gnu.org", "date": "2004-03-27T10:15:49Z"}, "committer": {"name": "Paolo Carlini", "email": "paolo@gcc.gnu.org", "date": "2004-03-27T10:15:49Z"}, "message": "[multiple changes]\n\n2004-03-27  Paolo Carlini  <pcarlini@suse.de>\n\n\t* include/ext/mt_allocator.h: Uglify consistently names of\n\tvariables, members and classes; tidy.\n\n2004-03-27  Dhruv Matani  <dhruvbird@gmx.net>\n\n\t* include/ext/mt_allocator.h (__mt_alloc<>::deallocate):\n\tDeallocation loop rewrote.\n\nFrom-SVN: r80012", "tree": {"sha": "7aed0cef5feba762e693510916dfd198c0a6e267", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7aed0cef5feba762e693510916dfd198c0a6e267"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/6f52a889fdd6a6127889944fb7ae8a96e768d6c3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6f52a889fdd6a6127889944fb7ae8a96e768d6c3", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6f52a889fdd6a6127889944fb7ae8a96e768d6c3", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6f52a889fdd6a6127889944fb7ae8a96e768d6c3/comments", "author": null, "committer": null, "parents": [{"sha": "ca4944e1fe6248ece2811207072e60005699e22a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca4944e1fe6248ece2811207072e60005699e22a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ca4944e1fe6248ece2811207072e60005699e22a"}], "stats": {"total": 340, "additions": 173, "deletions": 167}, "files": [{"sha": "ce9d7b0f01cad94dc30fea5611b761163f6ee9c2", "filename": "libstdc++-v3/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6f52a889fdd6a6127889944fb7ae8a96e768d6c3/libstdc%2B%2B-v3%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6f52a889fdd6a6127889944fb7ae8a96e768d6c3/libstdc%2B%2B-v3%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2FChangeLog?ref=6f52a889fdd6a6127889944fb7ae8a96e768d6c3", "patch": "@@ -1,3 +1,13 @@\n+2004-03-27  Paolo Carlini  <pcarlini@suse.de>\n+\n+\t* include/ext/mt_allocator.h: Uglify consistently names of\n+\tvariables, members and classes; tidy.\n+\n+2004-03-27  Dhruv Matani  <dhruvbird@gmx.net>\n+\n+\t* include/ext/mt_allocator.h (__mt_alloc<>::deallocate):\n+\tDeallocation loop rewrote.\n+\n 2004-03-26  Paolo Carlini  <pcarlini@suse.de>\n \n \t* include/ext/mt_allocator.h (__mt_alloc<>::allocate,"}, {"sha": "91bee239194687d7d778871f133297fece8a210e", "filename": "libstdc++-v3/include/ext/mt_allocator.h", "status": "modified", "additions": 163, "deletions": 167, "changes": 330, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6f52a889fdd6a6127889944fb7ae8a96e768d6c3/libstdc%2B%2B-v3%2Finclude%2Fext%2Fmt_allocator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6f52a889fdd6a6127889944fb7ae8a96e768d6c3/libstdc%2B%2B-v3%2Finclude%2Fext%2Fmt_allocator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fext%2Fmt_allocator.h?ref=6f52a889fdd6a6127889944fb7ae8a96e768d6c3", "patch": "@@ -57,13 +57,13 @@ namespace __gnu_cxx\n     class __mt_alloc\n     {\n     public:\n-      typedef size_t     size_type;\n-      typedef ptrdiff_t  difference_type;\n-      typedef _Tp*       pointer;\n-      typedef const _Tp* const_pointer;\n-      typedef _Tp&       reference;\n-      typedef const _Tp& const_reference;\n-      typedef _Tp        value_type;\n+      typedef size_t                    size_type;\n+      typedef ptrdiff_t                 difference_type;\n+      typedef _Tp*                      pointer;\n+      typedef const _Tp*                const_pointer;\n+      typedef _Tp&                      reference;\n+      typedef const _Tp&                const_reference;\n+      typedef _Tp                       value_type;\n \n       template<typename _Tp1>\n         struct rebind\n@@ -88,10 +88,12 @@ namespace __gnu_cxx\n       ~__mt_alloc() throw() { }\n \n       pointer\n-      address(reference __x) const { return &__x; }\n+      address(reference __x) const\n+      { return &__x; }\n \n       const_pointer\n-      address(const_reference __x) const { return &__x; }\n+      address(const_reference __x) const\n+      { return &__x; }\n \n       size_type\n       max_size() const throw() \n@@ -107,14 +109,14 @@ namespace __gnu_cxx\n       destroy(pointer __p) { __p->~_Tp(); }\n \n       pointer\n-      allocate(size_t __n, const void* = 0);\n+      allocate(size_type __n, const void* = 0);\n \n       void\n       deallocate(pointer __p, size_type __n);\n \n       // Variables used to configure the behavior of the allocator,\n       // assigned and explained in detail below.\n-      struct tune\n+      struct _Tune\n       {\n \t// Allocation requests (after round-up to power of 2) below\n \t// this value will be handled by the allocator. A raw new/\n@@ -146,7 +148,7 @@ namespace __gnu_cxx\n \t// Set to true forces all allocations to use new().\n \tbool \t_M_force_new; \n      \n-\texplicit tune() \n+\texplicit _Tune()\n \t: _M_max_bytes(128), _M_min_bin(8),\n \t  _M_chunk_size(4096 - 4 * sizeof(void*)), \n #ifdef __GTHREADS\n@@ -158,8 +160,8 @@ namespace __gnu_cxx\n \t  _M_force_new(getenv(\"GLIBCXX_FORCE_NEW\") ? true : false) \n \t{ }      \n \n-\texplicit tune(size_t __maxb, size_t __minbin, size_t __chunk,\n-\t\t      size_t __maxthreads, size_t __headroom, bool __force) \n+\texplicit _Tune(size_t __maxb, size_t __minbin, size_t __chunk,\n+\t\t       size_t __maxthreads, size_t __headroom, bool __force) \n \t: _M_max_bytes(__maxb), _M_min_bin(__minbin), _M_chunk_size(__chunk), \n \t  _M_max_threads(__maxthreads), _M_freelist_headroom(__headroom), \n \t  _M_force_new(__force)\n@@ -174,26 +176,27 @@ namespace __gnu_cxx\n #endif\n       static bool \t\t\t_S_init;\n \n-      static void \n+      static void\n       _S_initialize();\n \n       // Configuration options.\n-      static tune \t       \t\t_S_options;\n+      static _Tune \t       \t\t_S_options;\n \n-      static const tune\n-      _S_get_options() { return _S_options; }\n+      static const _Tune\n+      _S_get_options()\n+      { return _S_options; }\n \n       static void\n-      _S_set_options(tune __t)\n+      _S_set_options(_Tune __t)\n       { \n \tif (!_S_init)\n \t  _S_options = __t;\n       }\n \n       // Using short int as type for the binmap implies we are never\n       // caching blocks larger than 65535 with this allocator\n-      typedef unsigned short int binmap_type;\n-      static binmap_type* \t\t_S_binmap;\n+      typedef unsigned short int        _Binmap_type;\n+      static _Binmap_type* \t\t_S_binmap;\n \n       // Each requesting thread is assigned an id ranging from 1 to\n       // _S_max_threads. Thread id 0 is used as a global memory pool.\n@@ -205,63 +208,63 @@ namespace __gnu_cxx\n       // (i.e. the thread dies) is called, we return the thread id to\n       // the front of this list.\n #ifdef __GTHREADS\n-      struct thread_record\n+      struct _Thread_record\n       {\n         // Points to next free thread id record. NULL if last record in list.\n-        thread_record* volatile next;\n+        _Thread_record* volatile        _M_next;\n \n \t// Thread id ranging from 1 to _S_max_threads.\n-        size_t id;\n+        size_t                          _M_id;\n       };\n \n-      static thread_record* volatile \t_S_thread_freelist_first;\n+      static _Thread_record* volatile \t_S_thread_freelist_first;\n       static __gthread_mutex_t \t\t_S_thread_freelist_mutex;\n       static __gthread_key_t \t\t_S_thread_key;\n \n       static void \n-      _S_destroy_thread_key(void* freelist_pos);\n+      _S_destroy_thread_key(void* __freelist_pos);\n #endif\n \n       static size_t \n       _S_get_thread_id();\n \n-      union block_record\n+      union _Block_record\n       {\n \t// Points to the next block_record for its thread_id.\n-        block_record* volatile next;\n+        _Block_record* volatile         _M_next;\n \n \t// The thread id of the thread which has requested this block.\n #ifdef __GTHREADS\n-        size_t thread_id;\n+        size_t                          _M_thread_id;\n #endif\n       };\n \n-      struct bin_record\n+      struct _Bin_record\n       {\n \t// An \"array\" of pointers to the first free block for each\n \t// thread id. Memory to this \"array\" is allocated in _S_initialize()\n \t// for _S_max_threads + global pool 0.\n-        block_record** volatile first;\n+        _Block_record** volatile        _M_first;\n \n \t// An \"array\" of counters used to keep track of the amount of\n \t// blocks that are on the freelist/used for each thread id.\n \t// Memory to these \"arrays\" is allocated in _S_initialize() for\n \t// _S_max_threads + global pool 0.\n-        size_t* volatile free;\n-        size_t* volatile used;\n+        size_t* volatile                _M_free;\n+        size_t* volatile                _M_used;\n \n \t// Each bin has its own mutex which is used to ensure data\n \t// integrity while changing \"ownership\" on a block.  The mutex\n \t// is initialized in _S_initialize().\n #ifdef __GTHREADS\n-        __gthread_mutex_t* mutex;\n+        __gthread_mutex_t*              _M_mutex;\n #endif\n       };\n \n       // An \"array\" of bin_records each of which represents a specific\n       // power of 2 size. Memory to this \"array\" is allocated in\n       // _S_initialize().\n-      static bin_record* volatile     \t_S_bin;\n+      static _Bin_record* volatile     \t_S_bin;\n \n       // Actual value calculated in _S_initialize().\n       static size_t \t       \t     \t_S_bin_size; \n@@ -270,7 +273,7 @@ namespace __gnu_cxx\n   template<typename _Tp>\n     typename __mt_alloc<_Tp>::pointer\n     __mt_alloc<_Tp>::\n-    allocate(size_t __n, const void*)\n+    allocate(size_type __n, const void*)\n     {\n       // Although the test in __gthread_once() would suffice, we wrap\n       // test of the once condition in our own unlocked check. This\n@@ -295,20 +298,24 @@ namespace __gnu_cxx\n \t  void* __ret = ::operator new(__bytes);\n \t  return static_cast<_Tp*>(__ret);\n \t}\n-      \n+\n       // Round up to power of 2 and figure out which bin to use.\n       const size_t __which = _S_binmap[__bytes];      \n       const size_t __thread_id = _S_get_thread_id();\n       \n       // Find out if we have blocks on our freelist.  If so, go ahead\n       // and use them directly without having to lock anything.\n-      const bin_record& __bin = _S_bin[__which];\n-      block_record* block = NULL;\n-      if (__bin.first[__thread_id] == NULL)\n+      const _Bin_record& __bin = _S_bin[__which];\n+      _Block_record* __block = NULL;\n+      if (__bin._M_first[__thread_id] == NULL)\n \t{\n+\t  const size_t __bin_size = ((_S_options._M_min_bin << __which)\n+\t\t\t\t     + sizeof(_Block_record));\n+\t  size_t __block_count = _S_options._M_chunk_size / __bin_size;\t  \n+\n \t  // Are we using threads?\n \t  // - Yes, check if there are free blocks on the global\n-\t  //   list. If so, grab up to block_count blocks in one\n+\t  //   list. If so, grab up to __block_count blocks in one\n \t  //   lock and change ownership. If the global list is \n \t  //   empty, we allocate a new chunk and add those blocks \n \t  //   directly to our own freelist (with us as owner).\n@@ -319,107 +326,95 @@ namespace __gnu_cxx\n #ifdef __GTHREADS\n \t  if (__gthread_active_p())\n \t    {\n-\t      const size_t bin_size = ((_S_options._M_min_bin << __which)\n-\t\t\t\t       + sizeof(block_record));\n-\t      size_t block_count = _S_options._M_chunk_size / bin_size;\n-\t      \n-\t      __gthread_mutex_lock(__bin.mutex);\t      \n-\t      if (__bin.first[0] == NULL)\n+\t      __gthread_mutex_lock(__bin._M_mutex);\n+\t      if (__bin._M_first[0] == NULL)\n \t\t{\n \t\t  // No need to hold the lock when we are adding a\n \t\t  // whole chunk to our own list.\n-\t\t  __gthread_mutex_unlock(__bin.mutex);\n-\t\t  \n-\t\t  void* v = ::operator new(_S_options._M_chunk_size);\n-\t\t  __bin.first[__thread_id] = static_cast<block_record*>(v);\n+\t\t  __gthread_mutex_unlock(__bin._M_mutex);\n \t\t  \n-\t\t  __bin.free[__thread_id] = block_count;\t\t  \n-\t\t  block_count--;\n-\t\t  block = __bin.first[__thread_id];\n-\t\t  \n-\t\t  while (block_count > 0)\n+\t\t  void* __v = ::operator new(_S_options._M_chunk_size);\n+\t\t  __bin._M_first[__thread_id] = static_cast<_Block_record*>(__v);\n+\t\t  __bin._M_free[__thread_id] = __block_count;\t\t  \n+\n+\t\t  --__block_count;\n+\t\t  __block = __bin._M_first[__thread_id];\n+\t\t  while (__block_count > 0)\n \t\t    {\n-\t\t      char* c = reinterpret_cast<char*>(block) + bin_size;\n-\t\t      block->next = reinterpret_cast<block_record*>(c);\n-\t\t      block = block->next;\n-\t\t      block_count--;\n+\t\t      char* __c = reinterpret_cast<char*>(__block) + __bin_size;\n+\t\t      __block->_M_next = reinterpret_cast<_Block_record*>(__c);\n+\t\t      __block = __block->_M_next;\n+\t\t      --__block_count;\n \t\t    }\n-\t\t  block->next = NULL;\n+\t\t  __block->_M_next = NULL;\n \t\t}\n \t      else\n \t\t{\n-\t\t  size_t global_count = 0;\t\t  \n-\t\t  block_record* tmp;\t\t  \n-\t\t  while (__bin.first[0] != NULL && global_count < block_count)\n+\t\t  while (__bin._M_first[0] != NULL && __block_count > 0)\n \t\t    {\n-\t\t      tmp = __bin.first[0]->next;\n-\t\t      block = __bin.first[0];\n+\t\t      _Block_record* __tmp = __bin._M_first[0]->_M_next;\n+\t\t      __block = __bin._M_first[0];\n \n-\t\t      block->next = __bin.first[__thread_id];\n-\t\t      __bin.first[__thread_id] = block;\t\t      \n+\t\t      __block->_M_next = __bin._M_first[__thread_id];\n+\t\t      __bin._M_first[__thread_id] = __block;\t\t      \n \t\t      \n-\t\t      __bin.free[__thread_id]++;\n-\t\t      __bin.first[0] = tmp;\n-\t\t      global_count++;\n+\t\t      ++__bin._M_free[__thread_id];\n+\t\t      __bin._M_first[0] = __tmp;\n+\t\t      --__block_count;\n \t\t    }\n-\t\t  __gthread_mutex_unlock(__bin.mutex);\n+\t\t  __gthread_mutex_unlock(__bin._M_mutex);\n \t\t}\n \t      \n \t      // Return the first newly added block in our list and\n \t      // update the counters\n-\t      block = __bin.first[__thread_id];\n-\t      __bin.first[__thread_id] = __bin.first[__thread_id]->next; \n-\t      block->thread_id = __thread_id;\n-\t      __bin.free[__thread_id]--;\n-\t      __bin.used[__thread_id]++;\n+\t      __block = __bin._M_first[__thread_id];\n+\t      __bin._M_first[__thread_id] = __bin._M_first[__thread_id]->_M_next;\n+\t      __block->_M_thread_id = __thread_id;\n+\t      --__bin._M_free[__thread_id];\n+\t      ++__bin._M_used[__thread_id];\n \t    }\n \t  else\n #endif\n \t    {\n \t      void* __v = ::operator new(_S_options._M_chunk_size);\n-\t      __bin.first[0] = static_cast<block_record*>(__v);\n-\t      \n-\t      const size_t bin_size = ((_S_options._M_min_bin << __which)\n-\t\t\t\t       + sizeof(block_record));\n-\t      size_t block_count = _S_options._M_chunk_size / bin_size;\n+\t      __bin._M_first[0] = static_cast<_Block_record*>(__v);\n \t      \n-\t      block_count--;\n-\t      block = __bin.first[0];\n-\t      while (block_count > 0)\n+\t      --__block_count;\n+\t      __block = __bin._M_first[0];\n+\t      while (__block_count > 0)\n \t\t{\n-\t\t  char* __c = reinterpret_cast<char*>(block) + bin_size;\n-\t\t  block->next = reinterpret_cast<block_record*>(__c);\n-\t\t  block = block->next;\n-\t\t  block_count--;\n+\t\t  char* __c = reinterpret_cast<char*>(__block) + __bin_size;\n+\t\t  __block->_M_next = reinterpret_cast<_Block_record*>(__c);\n+\t\t  __block = __block->_M_next;\n+\t\t  --__block_count;\n \t\t}\n-\t      block->next = NULL;\n+\t      __block->_M_next = NULL;\n \t      \n \t      // Remove from list.\n-\t      block = __bin.first[0];\n-\t      __bin.first[0] = __bin.first[0]->next;\n+\t      __block = __bin._M_first[0];\n+\t      __bin._M_first[0] = __bin._M_first[0]->_M_next;\n \t    }\n \t}\n       else\n \t{\n \t  // \"Default\" operation - we have blocks on our own freelist\n \t  // grab the first record and update the counters.\n-\t  block = __bin.first[__thread_id];\n-\t  __bin.first[__thread_id] = __bin.first[__thread_id]->next;\n+\t  __block = __bin._M_first[__thread_id];\n+\t  __bin._M_first[__thread_id] = __bin._M_first[__thread_id]->_M_next;\n \n #ifdef __GTHREADS\n-\t  block->thread_id = __thread_id;\n \t  if (__gthread_active_p())\n \t    {\n-\t      __bin.free[__thread_id]--;\n-\t      __bin.used[__thread_id]++;\n+\t      __block->_M_thread_id = __thread_id;\n+\t      --__bin._M_free[__thread_id];\n+\t      ++__bin._M_used[__thread_id];\n \t    }\n #endif\n \t}\n-      char* __c = reinterpret_cast<char*>(block) + sizeof(block_record);\n+      char* __c = reinterpret_cast<char*>(__block) + sizeof(_Block_record);\n       return static_cast<_Tp*>(static_cast<void*>(__c));\n     }\n   \n-\n   template<typename _Tp>\n     void\n     __mt_alloc<_Tp>::\n@@ -436,58 +431,60 @@ namespace __gnu_cxx\n       \n       // Round up to power of 2 and figure out which bin to use.\n       const size_t __which = _S_binmap[__bytes];\n-      const bin_record& __bin = _S_bin[__which];\n+      const _Bin_record& __bin = _S_bin[__which];\n \n-      char* __c = reinterpret_cast<char*>(__p) - sizeof(block_record);\n-      block_record* block = reinterpret_cast<block_record*>(__c);\n+      char* __c = reinterpret_cast<char*>(__p) - sizeof(_Block_record);\n+      _Block_record* __block = reinterpret_cast<_Block_record*>(__c);\n       \n #ifdef __GTHREADS\n-      const size_t thread_id = _S_get_thread_id();\n       if (__gthread_active_p())\n \t{\n \t  // Calculate the number of records to remove from our freelist.\n-\t  int remove = __bin.free[thread_id] -\n-\t    (__bin.used[thread_id] / _S_options._M_freelist_headroom);\n+\t  const size_t __thread_id = _S_get_thread_id();\n+\t  int __remove = (__bin._M_free[__thread_id]\n+\t\t\t  - (__bin._M_used[__thread_id]\n+\t\t\t     / _S_options._M_freelist_headroom));\n \n \t  // The calculation above will almost always tell us to\n \t  // remove one or two records at a time, but this creates too\n \t  // much contention when locking and therefore we wait until\n \t  // the number of records is \"high enough\".\n \t  int __cond1 = static_cast<int>(100 * (_S_bin_size - __which));\n-\t  int __cond2 = static_cast<int>(__bin.free[thread_id]\n+\t  int __cond2 = static_cast<int>(__bin._M_free[__thread_id]\n \t\t\t\t\t / _S_options._M_freelist_headroom);\n-\t  if (remove > __cond1 && remove > __cond2)\n+\t  if (__remove > __cond1 && __remove > __cond2)\n \t    {\n-\t      __gthread_mutex_lock(__bin.mutex);\n-\t      block_record* tmp;\n-\t      while (remove > 0)\n+\t      __gthread_mutex_lock(__bin._M_mutex);\n+\t      _Block_record* __tmp = __bin._M_first[__thread_id];\n+\t      _Block_record* __first = __tmp;\n+\t      const int __removed = __remove;\n+\t      while (__remove > 1)\n \t\t{\n-\t\t  tmp = __bin.first[thread_id]->next;\n-\t\t  __bin.first[thread_id]->next = __bin.first[0];\n-\t\t  __bin.first[0] = __bin.first[thread_id];\n-\t\t  \n-\t\t  __bin.first[thread_id] = tmp;\n-\t\t  __bin.free[thread_id]--;\n-\t\t  remove--;\n+\t\t  __tmp = __tmp->_M_next;\n+\t\t  --__remove;\n \t\t}\n-\t      __gthread_mutex_unlock(__bin.mutex);\n+\t      __bin._M_first[__thread_id] = __tmp->_M_next;\n+\t      __tmp->_M_next = __bin._M_first[0];\n+\t      __bin._M_first[0] = __first;\n+\t      __bin._M_free[__thread_id] -= __removed;\n+\t      __gthread_mutex_unlock(__bin._M_mutex);\n \t    }\n \t  \n \t  // Return this block to our list and update counters and\n \t  // owner id as needed.\n-\t  __bin.used[block->thread_id]--;\n+\t  --__bin._M_used[__block->_M_thread_id];\n \n-\t  block->next = __bin.first[thread_id];\n-\t  __bin.first[thread_id] = block;\n+\t  __block->_M_next = __bin._M_first[__thread_id];\n+\t  __bin._M_first[__thread_id] = __block;\n \t  \n-\t  __bin.free[thread_id]++;\n+\t  ++__bin._M_free[__thread_id];\n \t}\n       else\n #endif\n \t{\n \t  // Single threaded application - return to global pool.\n-\t  block->next = __bin.first[0];\n-\t  __bin.first[0] = block;\n+\t  __block->_M_next = __bin._M_first[0];\n+\t  __bin._M_first[0] = __block;\n \t}\n     }\n   \n@@ -505,22 +502,22 @@ namespace __gnu_cxx\n       while (_S_options._M_max_bytes > __bin_size)\n \t{\n \t  __bin_size <<= 1;\n-\t  _S_bin_size++;\n+\t  ++_S_bin_size;\n \t}\n \n       // Setup the bin map for quick lookup of the relevant bin.\n-      const size_t __j = (_S_options._M_max_bytes + 1) * sizeof(binmap_type);\n-      _S_binmap = static_cast<binmap_type*>(::operator new(__j));\n+      const size_t __j = (_S_options._M_max_bytes + 1) * sizeof(_Binmap_type);\n+      _S_binmap = static_cast<_Binmap_type*>(::operator new(__j));\n \n-      binmap_type* __bp = _S_binmap;\n-      binmap_type __bin_max = _S_options._M_min_bin;\n-      binmap_type __bint = 0;\n-      for (binmap_type __ct = 0; __ct <= _S_options._M_max_bytes; __ct++)\n+      _Binmap_type* __bp = _S_binmap;\n+      _Binmap_type __bin_max = _S_options._M_min_bin;\n+      _Binmap_type __bint = 0;\n+      for (_Binmap_type __ct = 0; __ct <= _S_options._M_max_bytes; ++__ct)\n         {\n           if (__ct > __bin_max)\n             {\n               __bin_max <<= 1;\n-              __bint++;\n+              ++__bint;\n             }\n           *__bp++ = __bint;\n         }\n@@ -532,24 +529,23 @@ namespace __gnu_cxx\n #ifdef __GTHREADS\n       if (__gthread_active_p())\n         {\n-\t  const size_t __k = sizeof(thread_record) * _S_options._M_max_threads;\n+\t  const size_t __k = sizeof(_Thread_record) * _S_options._M_max_threads;\n \t  __v = ::operator new(__k);\n-          _S_thread_freelist_first = static_cast<thread_record*>(__v);\n+          _S_thread_freelist_first = static_cast<_Thread_record*>(__v);\n \n \t  // NOTE! The first assignable thread id is 1 since the\n \t  // global pool uses id 0\n           size_t __i;\n-          for (__i = 1; __i < _S_options._M_max_threads; __i++)\n+          for (__i = 1; __i < _S_options._M_max_threads; ++__i)\n             {\n-\t      thread_record& __tr = _S_thread_freelist_first[__i - 1];\n-              __tr.next = &_S_thread_freelist_first[__i];\n-              __tr.id = __i;\n+\t      _Thread_record& __tr = _S_thread_freelist_first[__i - 1];\n+              __tr._M_next = &_S_thread_freelist_first[__i];\n+              __tr._M_id = __i;\n             }\n \n           // Set last record.\n-          _S_thread_freelist_first[__i - 1].next = NULL;\n-          _S_thread_freelist_first[__i - 1].id = __i;\n-\n+          _S_thread_freelist_first[__i - 1]._M_next = NULL;\n+          _S_thread_freelist_first[__i - 1]._M_id = __i;\n \n \t  // Make sure this is initialized.\n #ifndef __GTHREAD_MUTEX_INIT\n@@ -562,8 +558,8 @@ namespace __gnu_cxx\n #endif\n \n       // Initialize _S_bin and its members.\n-      __v = ::operator new(sizeof(bin_record) * _S_bin_size);\n-      _S_bin = static_cast<bin_record*>(__v);\n+      __v = ::operator new(sizeof(_Bin_record) * _S_bin_size);\n+      _S_bin = static_cast<_Bin_record*>(__v);\n \t\n       // Maximum number of threads. \n       size_t __max_threads = 1;\n@@ -572,44 +568,44 @@ namespace __gnu_cxx\n         __max_threads = _S_options._M_max_threads + 1;\n #endif\n \n-      for (size_t __n = 0; __n < _S_bin_size; __n++)\n+      for (size_t __n = 0; __n < _S_bin_size; ++__n)\n         {\n-\t  bin_record& __bin = _S_bin[__n];\n-\t  __v = ::operator new(sizeof(block_record*) * __max_threads);\n-          __bin.first = static_cast<block_record**>(__v);\n+\t  _Bin_record& __bin = _S_bin[__n];\n+\t  __v = ::operator new(sizeof(_Block_record*) * __max_threads);\n+          __bin._M_first = static_cast<_Block_record**>(__v);\n \n #ifdef __GTHREADS\n           if (__gthread_active_p())\n             {\n \t      __v = ::operator new(sizeof(size_t) * __max_threads);\n-              __bin.free = static_cast<size_t*>(__v);\n+              __bin._M_free = static_cast<size_t*>(__v);\n \n \t      __v = ::operator new(sizeof(size_t) * __max_threads);\n-              __bin.used = static_cast<size_t*>(__v);\n+              __bin._M_used = static_cast<size_t*>(__v);\n \n \t      __v = ::operator new(sizeof(__gthread_mutex_t));\n-              __bin.mutex = static_cast<__gthread_mutex_t*>(__v);\n+              __bin._M_mutex = static_cast<__gthread_mutex_t*>(__v);\n \n #ifdef __GTHREAD_MUTEX_INIT\n               {\n                 // Do not copy a POSIX/gthr mutex once in use.\n                 __gthread_mutex_t __tmp = __GTHREAD_MUTEX_INIT;\n-                *__bin.mutex = __tmp;\n+                *__bin._M_mutex = __tmp;\n               }\n #else\n-              { __GTHREAD_MUTEX_INIT_FUNCTION(__bin.mutex); }\n+              { __GTHREAD_MUTEX_INIT_FUNCTION(__bin._M_mutex); }\n #endif\n             }\n #endif\n \n-          for (size_t __threadn = 0; __threadn < __max_threads; __threadn++)\n+          for (size_t __threadn = 0; __threadn < __max_threads; ++__threadn)\n             {\n-              __bin.first[__threadn] = NULL;\n+              __bin._M_first[__threadn] = NULL;\n #ifdef __GTHREADS\n               if (__gthread_active_p())\n                 {\n-                  __bin.free[__threadn] = 0;\n-                  __bin.used[__threadn] = 0;\n+                  __bin._M_free[__threadn] = 0;\n+                  __bin._M_used[__threadn] = 0;\n                 }\n #endif\n             }\n@@ -624,27 +620,27 @@ namespace __gnu_cxx\n     {\n #ifdef __GTHREADS\n       // If we have thread support and it's active we check the thread\n-      // key value and return it's id or if it's not set we take the\n+      // key value and return its id or if it's not set we take the\n       // first record from _S_thread_freelist and sets the key and\n       // returns it's id.\n       if (__gthread_active_p())\n         {\n-          thread_record* __freelist_pos =\n-\t    static_cast<thread_record*>(__gthread_getspecific(_S_thread_key)); \n+          _Thread_record* __freelist_pos =\n+\t    static_cast<_Thread_record*>(__gthread_getspecific(_S_thread_key)); \n \t  if (__freelist_pos == NULL)\n             {\n \t      // Since _S_options._M_max_threads must be larger than\n \t      // the theoretical max number of threads of the OS the\n \t      // list can never be empty.\n               __gthread_mutex_lock(&_S_thread_freelist_mutex);\n               __freelist_pos = _S_thread_freelist_first;\n-              _S_thread_freelist_first = _S_thread_freelist_first->next;\n+              _S_thread_freelist_first = _S_thread_freelist_first->_M_next;\n               __gthread_mutex_unlock(&_S_thread_freelist_mutex);\n \n               __gthread_setspecific(_S_thread_key, \n \t\t\t\t    static_cast<void*>(__freelist_pos));\n             }\n-          return __freelist_pos->id;\n+          return __freelist_pos->_M_id;\n         }\n #endif\n       // Otherwise (no thread support or inactive) all requests are\n@@ -660,8 +656,8 @@ namespace __gnu_cxx\n     {\n       // Return this thread id record to front of thread_freelist.\n       __gthread_mutex_lock(&_S_thread_freelist_mutex);\n-      thread_record* __tr = static_cast<thread_record*>(__freelist_pos);\n-      __tr->next = _S_thread_freelist_first;\n+      _Thread_record* __tr = static_cast<_Thread_record*>(__freelist_pos);\n+      __tr->_M_next = _S_thread_freelist_first;\n       _S_thread_freelist_first = __tr;\n       __gthread_mutex_unlock(&_S_thread_freelist_mutex);\n     }\n@@ -681,13 +677,13 @@ namespace __gnu_cxx\n     bool __mt_alloc<_Tp>::_S_init = false;\n \n   template<typename _Tp> \n-    typename __mt_alloc<_Tp>::tune __mt_alloc<_Tp>::_S_options;\n+    typename __mt_alloc<_Tp>::_Tune __mt_alloc<_Tp>::_S_options;\n \n   template<typename _Tp> \n-    typename __mt_alloc<_Tp>::binmap_type* __mt_alloc<_Tp>::_S_binmap;\n+    typename __mt_alloc<_Tp>::_Binmap_type* __mt_alloc<_Tp>::_S_binmap;\n \n   template<typename _Tp> \n-    typename __mt_alloc<_Tp>::bin_record* volatile __mt_alloc<_Tp>::_S_bin;\n+    typename __mt_alloc<_Tp>::_Bin_record* volatile __mt_alloc<_Tp>::_S_bin;\n \n   template<typename _Tp> \n     size_t __mt_alloc<_Tp>::_S_bin_size = 1;\n@@ -698,7 +694,7 @@ namespace __gnu_cxx\n     __gthread_once_t __mt_alloc<_Tp>::_S_once = __GTHREAD_ONCE_INIT;\n \n   template<typename _Tp> \n-    typename __mt_alloc<_Tp>::thread_record*\n+    typename __mt_alloc<_Tp>::_Thread_record*\n     volatile __mt_alloc<_Tp>::_S_thread_freelist_first = NULL;\n \n   template<typename _Tp> "}]}