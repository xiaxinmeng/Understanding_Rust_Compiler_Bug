{"sha": "0a9d038ec10aa0d109ca965cc435934bfea92d14", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGE5ZDAzOGVjMTBhYTBkMTA5Y2E5NjVjYzQzNTkzNGJmZWE5MmQxNA==", "commit": {"author": {"name": "prathamesh.kulkarni", "email": "prathamesh.kulkarni@linaro.org", "date": "2021-06-30T09:42:06Z"}, "committer": {"name": "prathamesh.kulkarni", "email": "prathamesh.kulkarni@linaro.org", "date": "2021-06-30T09:45:23Z"}, "message": "arm/66791: Gate comparison in vca intrinsics on __FAST_MATH__.\n\ngcc/ChangeLog:\n\n\tPR target/66791\n\t* config/arm/arm_neon.h: Move vabs intrinsics before vcage_f32.\n\t(vcage_f32): Gate comparison on __FAST_MATH__.\n\t(vcageq_f32): Likewise.\n\t(vcale_f32): Likewise.\n\t(vcaleq_f32): Likewise.\n\t(vcagt_f32): Likewise.\n\t(vcagtq_f32): Likewise.\n\t(vcalt_f32): Likewise.\n\t(vcaltq_f32): Likewise.\n\t(vcage_f16): Likewise.\n\t(vcageq_f16): Likewise.\n\t(vcale_f16): Likewise.\n\t(vcaleq_f16): Likewise.\n\t(vcagt_f16): Likewise.\n\t(vcagtq_f16): Likewise.\n\t(vcalt_f16): Likewise.\n\t(vcaltq_f16): Likewise.", "tree": {"sha": "b2189006fec91e93a310cb5169b3548e50fea4dd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b2189006fec91e93a310cb5169b3548e50fea4dd"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0a9d038ec10aa0d109ca965cc435934bfea92d14", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0a9d038ec10aa0d109ca965cc435934bfea92d14", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0a9d038ec10aa0d109ca965cc435934bfea92d14", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0a9d038ec10aa0d109ca965cc435934bfea92d14/comments", "author": null, "committer": null, "parents": [{"sha": "39da8a7ba9a3a643e6318a5534d5d7c85a3bedfa", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/39da8a7ba9a3a643e6318a5534d5d7c85a3bedfa", "html_url": "https://github.com/Rust-GCC/gccrs/commit/39da8a7ba9a3a643e6318a5534d5d7c85a3bedfa"}], "stats": {"total": 259, "additions": 161, "deletions": 98}, "files": [{"sha": "f42a15f79123d8e2cbaf8207fc733a66ca3bad23", "filename": "gcc/config/arm/arm_neon.h", "status": "modified", "additions": 161, "deletions": 98, "changes": 259, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0a9d038ec10aa0d109ca965cc435934bfea92d14/gcc%2Fconfig%2Farm%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0a9d038ec10aa0d109ca965cc435934bfea92d14/gcc%2Fconfig%2Farm%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm_neon.h?ref=0a9d038ec10aa0d109ca965cc435934bfea92d14", "patch": "@@ -2867,60 +2867,189 @@ vcltq_u32 (uint32x4_t __a, uint32x4_t __b)\n   return (__a < __b);\n }\n \n+__extension__ extern __inline int8x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabs_s8 (int8x8_t __a)\n+{\n+  return (int8x8_t)__builtin_neon_vabsv8qi (__a);\n+}\n+\n+__extension__ extern __inline int16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabs_s16 (int16x4_t __a)\n+{\n+  return (int16x4_t)__builtin_neon_vabsv4hi (__a);\n+}\n+\n+__extension__ extern __inline int32x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabs_s32 (int32x2_t __a)\n+{\n+  return (int32x2_t)__builtin_neon_vabsv2si (__a);\n+}\n+\n+__extension__ extern __inline float32x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabs_f32 (float32x2_t __a)\n+{\n+  return (float32x2_t)__builtin_neon_vabsv2sf (__a);\n+}\n+\n+__extension__ extern __inline int8x16_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabsq_s8 (int8x16_t __a)\n+{\n+  return (int8x16_t)__builtin_neon_vabsv16qi (__a);\n+}\n+\n+__extension__ extern __inline int16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabsq_s16 (int16x8_t __a)\n+{\n+  return (int16x8_t)__builtin_neon_vabsv8hi (__a);\n+}\n+\n+__extension__ extern __inline int32x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabsq_s32 (int32x4_t __a)\n+{\n+  return (int32x4_t)__builtin_neon_vabsv4si (__a);\n+}\n+\n+__extension__ extern __inline float32x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vabsq_f32 (float32x4_t __a)\n+{\n+  return (float32x4_t)__builtin_neon_vabsv4sf (__a);\n+}\n+\n+__extension__ extern __inline int8x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vqabs_s8 (int8x8_t __a)\n+{\n+  return (int8x8_t)__builtin_neon_vqabsv8qi (__a);\n+}\n+\n+__extension__ extern __inline int16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vqabs_s16 (int16x4_t __a)\n+{\n+  return (int16x4_t)__builtin_neon_vqabsv4hi (__a);\n+}\n+\n+__extension__ extern __inline int32x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vqabs_s32 (int32x2_t __a)\n+{\n+  return (int32x2_t)__builtin_neon_vqabsv2si (__a);\n+}\n+\n+__extension__ extern __inline int8x16_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vqabsq_s8 (int8x16_t __a)\n+{\n+  return (int8x16_t)__builtin_neon_vqabsv16qi (__a);\n+}\n+\n+__extension__ extern __inline int16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vqabsq_s16 (int16x8_t __a)\n+{\n+  return (int16x8_t)__builtin_neon_vqabsv8hi (__a);\n+}\n+\n+__extension__ extern __inline int32x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vqabsq_s32 (int32x4_t __a)\n+{\n+  return (int32x4_t)__builtin_neon_vqabsv4si (__a);\n+}\n __extension__ extern __inline uint32x2_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcage_f32 (float32x2_t __a, float32x2_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x2_t) (vabs_f32 (__a) >= vabs_f32 (__b));\n+#else\n   return (uint32x2_t)__builtin_neon_vcagev2sf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint32x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcageq_f32 (float32x4_t __a, float32x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x4_t) (vabsq_f32 (__a) >= vabsq_f32 (__b));\n+#else\n   return (uint32x4_t)__builtin_neon_vcagev4sf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint32x2_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcale_f32 (float32x2_t __a, float32x2_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x2_t) (vabs_f32 (__a) <= vabs_f32 (__b));\n+#else\n   return (uint32x2_t)__builtin_neon_vcagev2sf (__b, __a);\n+#endif\n }\n \n __extension__ extern __inline uint32x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcaleq_f32 (float32x4_t __a, float32x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x4_t) (vabsq_f32 (__a) <= vabsq_f32 (__b));\n+#else\n   return (uint32x4_t)__builtin_neon_vcagev4sf (__b, __a);\n+#endif\n }\n \n __extension__ extern __inline uint32x2_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcagt_f32 (float32x2_t __a, float32x2_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x2_t) (vabs_f32 (__a) > vabs_f32 (__b));\n+#else\n   return (uint32x2_t)__builtin_neon_vcagtv2sf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint32x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcagtq_f32 (float32x4_t __a, float32x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x4_t) (vabsq_f32 (__a) > vabsq_f32 (__b));\n+#else\n   return (uint32x4_t)__builtin_neon_vcagtv4sf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint32x2_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcalt_f32 (float32x2_t __a, float32x2_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x2_t) (vabs_f32 (__a) < vabs_f32 (__b));\n+#else\n   return (uint32x2_t)__builtin_neon_vcagtv2sf (__b, __a);\n+#endif\n }\n \n __extension__ extern __inline uint32x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcaltq_f32 (float32x4_t __a, float32x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint32x4_t) (vabsq_f32 (__a) < vabsq_f32 (__b));\n+#else\n   return (uint32x4_t)__builtin_neon_vcagtv4sf (__b, __a);\n+#endif\n }\n \n __extension__ extern __inline uint8x8_t\n@@ -5620,104 +5749,6 @@ vsliq_n_p16 (poly16x8_t __a, poly16x8_t __b, const int __c)\n   return (poly16x8_t)__builtin_neon_vsli_nv8hi ((int16x8_t) __a, (int16x8_t) __b, __c);\n }\n \n-__extension__ extern __inline int8x8_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabs_s8 (int8x8_t __a)\n-{\n-  return (int8x8_t)__builtin_neon_vabsv8qi (__a);\n-}\n-\n-__extension__ extern __inline int16x4_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabs_s16 (int16x4_t __a)\n-{\n-  return (int16x4_t)__builtin_neon_vabsv4hi (__a);\n-}\n-\n-__extension__ extern __inline int32x2_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabs_s32 (int32x2_t __a)\n-{\n-  return (int32x2_t)__builtin_neon_vabsv2si (__a);\n-}\n-\n-__extension__ extern __inline float32x2_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabs_f32 (float32x2_t __a)\n-{\n-  return (float32x2_t)__builtin_neon_vabsv2sf (__a);\n-}\n-\n-__extension__ extern __inline int8x16_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabsq_s8 (int8x16_t __a)\n-{\n-  return (int8x16_t)__builtin_neon_vabsv16qi (__a);\n-}\n-\n-__extension__ extern __inline int16x8_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabsq_s16 (int16x8_t __a)\n-{\n-  return (int16x8_t)__builtin_neon_vabsv8hi (__a);\n-}\n-\n-__extension__ extern __inline int32x4_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabsq_s32 (int32x4_t __a)\n-{\n-  return (int32x4_t)__builtin_neon_vabsv4si (__a);\n-}\n-\n-__extension__ extern __inline float32x4_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vabsq_f32 (float32x4_t __a)\n-{\n-  return (float32x4_t)__builtin_neon_vabsv4sf (__a);\n-}\n-\n-__extension__ extern __inline int8x8_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vqabs_s8 (int8x8_t __a)\n-{\n-  return (int8x8_t)__builtin_neon_vqabsv8qi (__a);\n-}\n-\n-__extension__ extern __inline int16x4_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vqabs_s16 (int16x4_t __a)\n-{\n-  return (int16x4_t)__builtin_neon_vqabsv4hi (__a);\n-}\n-\n-__extension__ extern __inline int32x2_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vqabs_s32 (int32x2_t __a)\n-{\n-  return (int32x2_t)__builtin_neon_vqabsv2si (__a);\n-}\n-\n-__extension__ extern __inline int8x16_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vqabsq_s8 (int8x16_t __a)\n-{\n-  return (int8x16_t)__builtin_neon_vqabsv16qi (__a);\n-}\n-\n-__extension__ extern __inline int16x8_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vqabsq_s16 (int16x8_t __a)\n-{\n-  return (int16x8_t)__builtin_neon_vqabsv8hi (__a);\n-}\n-\n-__extension__ extern __inline int32x4_t\n-__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n-vqabsq_s32 (int32x4_t __a)\n-{\n-  return (int32x4_t)__builtin_neon_vqabsv4si (__a);\n-}\n-\n __extension__ extern __inline int8x8_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vneg_s8 (int8x8_t __a)\n@@ -17147,56 +17178,88 @@ __extension__ extern __inline uint16x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcage_f16 (float16x4_t __a, float16x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x4_t) (vabs_f16 (__a) >= vabs_f16 (__b));\n+#else\n   return (uint16x4_t)__builtin_neon_vcagev4hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x8_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcageq_f16 (float16x8_t __a, float16x8_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x8_t) (vabsq_f16 (__a) >= vabsq_f16 (__b));\n+#else\n   return (uint16x8_t)__builtin_neon_vcagev8hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcagt_f16 (float16x4_t __a, float16x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x4_t) (vabs_f16 (__a) > vabs_f16 (__b));\n+#else\n   return (uint16x4_t)__builtin_neon_vcagtv4hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x8_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcagtq_f16 (float16x8_t __a, float16x8_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x8_t) (vabsq_f16 (__a) > vabsq_f16 (__b));\n+#else\n   return (uint16x8_t)__builtin_neon_vcagtv8hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcale_f16 (float16x4_t __a, float16x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x4_t) (vabs_f16 (__a) <= vabs_f16 (__b));\n+#else\n   return (uint16x4_t)__builtin_neon_vcalev4hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x8_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcaleq_f16 (float16x8_t __a, float16x8_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x8_t) (vabsq_f16 (__a) <= vabsq_f16 (__b));\n+#else\n   return (uint16x8_t)__builtin_neon_vcalev8hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcalt_f16 (float16x4_t __a, float16x4_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x4_t) (vabs_f16 (__a) < vabs_f16 (__b));\n+#else\n   return (uint16x4_t)__builtin_neon_vcaltv4hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x8_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n vcaltq_f16 (float16x8_t __a, float16x8_t __b)\n {\n+#ifdef __FAST_MATH__\n+  return (uint16x8_t) (vabsq_f16 (__a) < vabsq_f16 (__b));\n+#else\n   return (uint16x8_t)__builtin_neon_vcaltv8hf (__a, __b);\n+#endif\n }\n \n __extension__ extern __inline uint16x4_t"}]}