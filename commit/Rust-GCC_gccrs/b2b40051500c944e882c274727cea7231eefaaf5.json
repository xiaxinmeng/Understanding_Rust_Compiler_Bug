{"sha": "b2b40051500c944e882c274727cea7231eefaaf5", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjJiNDAwNTE1MDBjOTQ0ZTg4MmMyNzQ3MjdjZWE3MjMxZWVmYWFmNQ==", "commit": {"author": {"name": "Martin Jambor", "email": "jamborm@gcc.gnu.org", "date": "2016-01-19T10:35:10Z"}, "committer": {"name": "Martin Jambor", "email": "jamborm@gcc.gnu.org", "date": "2016-01-19T10:35:10Z"}, "message": "Merge of HSA\n\n2016-01-19  Martin Jambor  <mjambor@suse.cz>\n\t    Martin Liska  <mliska@suse.cz>\n\t    Michael Matz <matz@suse.de>\n\nlibgomp/\n\t* plugin/Makefrag.am: Add HSA plugin requirements.\n\t* plugin/configfrag.ac (HSA_RUNTIME_INCLUDE): New variable.\n\t(HSA_RUNTIME_LIB): Likewise.\n\t(HSA_RUNTIME_CPPFLAGS): Likewise.\n\t(HSA_RUNTIME_INCLUDE): New substitution.\n\t(HSA_RUNTIME_LIB): Likewise.\n\t(HSA_RUNTIME_LDFLAGS): Likewise.\n\t(hsa-runtime): New configure option.\n\t(hsa-runtime-include): Likewise.\n\t(hsa-runtime-lib): Likewise.\n\t(PLUGIN_HSA): New substitution variable.\n\tFill HSA_RUNTIME_INCLUDE and HSA_RUNTIME_LIB according to the new\n\tconfigure options.\n\t(PLUGIN_HSA_CPPFLAGS): Likewise.\n\t(PLUGIN_HSA_LDFLAGS): Likewise.\n\t(PLUGIN_HSA_LIBS): Likewise.\n\tCheck that we have access to HSA run-time.\n\t* libgomp-plugin.h (offload_target_type): New element\n\tOFFLOAD_TARGET_TYPE_HSA.\n\t* libgomp.h (gomp_target_task): New fields firstprivate_copies and\n\targs.\n\t(bool gomp_create_target_task): Updated.\n\t(gomp_device_descr): Extra parameter of run_func and async_run_func,\n\tnew field can_run_func.\n\t* libgomp_g.h (GOMP_target_ext): Update prototype.\n\t* oacc-host.c (host_run): Added a new parameter args.\n\t* target.c (calculate_firstprivate_requirements): New function.\n\t(copy_firstprivate_data): Likewise.\n\t(gomp_target_fallback_firstprivate): Use them.\n\t(gomp_target_unshare_firstprivate): New function.\n\t(gomp_get_target_fn_addr): Allow returning NULL for shared memory\n\tdevices.\n\t(GOMP_target): Do host fallback for all shared memory devices.  Do not\n\tpass any args to plugins.\n\t(GOMP_target_ext): Introduce device-specific argument parameter args.\n\tAllow host fallback if device shares memory.  Do not remap data if\n\tdevice has shared memory.\n\t(gomp_target_task_fn): Likewise.  Also treat shared memory devices\n\tlike host fallback for mappings.\n\t(GOMP_target_data): Treat shared memory devices like host fallback.\n\t(GOMP_target_data_ext): Likewise.\n\t(GOMP_target_update): Likewise.\n\t(GOMP_target_update_ext): Likewise.  Also pass NULL as args to\n\tgomp_create_target_task.\n\t(GOMP_target_enter_exit_data): Likewise.\n\t(omp_target_alloc): Treat shared memory devices like host fallback.\n\t(omp_target_free): Likewise.\n\t(omp_target_is_present): Likewise.\n\t(omp_target_memcpy): Likewise.\n\t(omp_target_memcpy_rect): Likewise.\n\t(omp_target_associate_ptr): Likewise.\n\t(gomp_load_plugin_for_device): Also load can_run.\n\t* task.c (GOMP_PLUGIN_target_task_completion): Free\n\tfirstprivate_copies.\n\t(gomp_create_target_task): Accept new argument args and store it to\n\tttask.\n\t* plugin/plugin-hsa.c: New file.\n\ngcc/\n\t* Makefile.in (OBJS): Add new source files.\n\t(GTFILES): Add hsa.c.\n\t* common.opt (disable_hsa): New variable.\n\t(-Whsa): New warning.\n\t* config.in (ENABLE_HSA): New.\n\t* configure.ac: Treat hsa differently from other accelerators.\n\t(OFFLOAD_TARGETS): Define ENABLE_OFFLOADING according to\n\t$enable_offloading.\n\t(ENABLE_HSA): Define ENABLE_HSA according to $enable_hsa.\n\t* doc/install.texi (Configuration): Document --with-hsa-runtime,\n\t--with-hsa-runtime-include, --with-hsa-runtime-lib and\n\t--with-hsa-kmt-lib.\n\t* doc/invoke.texi (-Whsa): Document.\n\t(hsa-gen-debug-stores): Likewise.\n\t* lto-wrapper.c (compile_images_for_offload_targets): Do not attempt\n\tto invoke offload compiler for hsa acclerator.\n\t* opts.c (common_handle_option): Determine whether HSA offloading\n\tshould be performed.\n\t* params.def (PARAM_HSA_GEN_DEBUG_STORES): New parameter.\n\t* builtin-types.def (BT_FN_VOID_UINT_PTR_INT_PTR): New.\n\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_INT_INT): Removed.\n\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_PTR): New.\n\t* gimple-low.c (lower_stmt): Also handle GIMPLE_OMP_GRID_BODY.\n\t* gimple-pretty-print.c (dump_gimple_omp_for): Also handle\n\tGF_OMP_FOR_KIND_GRID_LOOP.\n\t(dump_gimple_omp_block): Also handle GIMPLE_OMP_GRID_BODY.\n\t(pp_gimple_stmt_1): Likewise.\n\t* gimple-walk.c (walk_gimple_stmt): Likewise.\n\t* gimple.c (gimple_build_omp_grid_body): New function.\n\t(gimple_copy): Also handle GIMPLE_OMP_GRID_BODY.\n\t* gimple.def (GIMPLE_OMP_GRID_BODY): New.\n\t* gimple.h (enum gf_mask): Added GF_OMP_PARALLEL_GRID_PHONY,\n\tGF_OMP_FOR_KIND_GRID_LOOP, GF_OMP_FOR_GRID_PHONY and\n\tGF_OMP_TEAMS_GRID_PHONY.\n\t(gimple_statement_omp_single_layout): Updated comments.\n\t(gimple_build_omp_grid_body): New function.\n\t(gimple_has_substatements): Also handle GIMPLE_OMP_GRID_BODY.\n\t(gimple_omp_for_grid_phony): New function.\n\t(gimple_omp_for_set_grid_phony): Likewise.\n\t(gimple_omp_parallel_grid_phony): Likewise.\n\t(gimple_omp_parallel_set_grid_phony): Likewise.\n\t(gimple_omp_teams_grid_phony): Likewise.\n\t(gimple_omp_teams_set_grid_phony): Likewise.\n\t(gimple_return_set_retbnd): Also handle GIMPLE_OMP_GRID_BODY.\n\t* omp-builtins.def (BUILT_IN_GOMP_OFFLOAD_REGISTER): New.\n\t(BUILT_IN_GOMP_OFFLOAD_UNREGISTER): Likewise.\n\t(BUILT_IN_GOMP_TARGET): Updated type.\n\t* omp-low.c: Include symbol-summary.h, hsa.h and params.h.\n\t(adjust_for_condition): New function.\n\t(get_omp_for_step_from_incr): Likewise.\n\t(extract_omp_for_data): Moved parts to adjust_for_condition and\n\tget_omp_for_step_from_incr.\n\t(build_outer_var_ref): Handle GIMPLE_OMP_GRID_BODY.\n\t(fixup_child_record_type): Bail out if receiver_decl is NULL.\n\t(scan_sharing_clauses): Handle OMP_CLAUSE__GRIDDIM_.\n\t(scan_omp_parallel): Do not create child functions for phony\n\tconstructs.\n\t(check_omp_nesting_restrictions): Handle GIMPLE_OMP_GRID_BODY.\n\t(scan_omp_1_op): Checking assert we are not remapping to\n\tERROR_MARK.  Also also handle GIMPLE_OMP_GRID_BODY.\n\t(parallel_needs_hsa_kernel_p): New function.\n\t(expand_parallel_call): Register apprpriate parallel child\n\tfunctions as HSA kernels.\n\t(grid_launch_attributes_trees): New type.\n\t(grid_attr_trees): New variable.\n\t(grid_create_kernel_launch_attr_types): New function.\n\t(grid_insert_store_range_dim): Likewise.\n\t(grid_get_kernel_launch_attributes): Likewise.\n\t(get_target_argument_identifier_1): Likewise.\n\t(get_target_argument_identifier): Likewise.\n\t(get_target_argument_value): Likewise.\n\t(push_target_argument_according_to_value): Likewise.\n\t(get_target_arguments): Likewise.\n\t(expand_omp_target): Call get_target_arguments instead of looking\n\tup for teams and thread limit.\n\t(grid_expand_omp_for_loop): New function.\n\t(grid_arg_decl_map): New type.\n\t(grid_remap_kernel_arg_accesses): New function.\n\t(grid_expand_target_kernel_body): New function.\n\t(expand_omp): Call it.\n\t(lower_omp_for): Do not emit phony constructs.\n\t(lower_omp_taskreg): Do not emit phony constructs but create for them\n\ta temporary variable receiver_decl.\n\t(lower_omp_taskreg): Do not emit phony constructs.\n\t(lower_omp_teams): Likewise.\n\t(lower_omp_grid_body): New function.\n\t(lower_omp_1): Call it.\n\t(grid_reg_assignment_to_local_var_p): New function.\n\t(grid_seq_only_contains_local_assignments): Likewise.\n\t(grid_find_single_omp_among_assignments_1): Likewise.\n\t(grid_find_single_omp_among_assignments): Likewise.\n\t(grid_find_ungridifiable_statement): Likewise.\n\t(grid_target_follows_gridifiable_pattern): Likewise.\n\t(grid_remap_prebody_decls): Likewise.\n\t(grid_copy_leading_local_assignments): Likewise.\n\t(grid_process_kernel_body_copy): Likewise.\n\t(grid_attempt_target_gridification): Likewise.\n\t(grid_gridify_all_targets_stmt): Likewise.\n\t(grid_gridify_all_targets): Likewise.\n\t(execute_lower_omp): Call grid_gridify_all_targets.\n\t(make_gimple_omp_edges): Handle GIMPLE_OMP_GRID_BODY.\n\t* tree-core.h (omp_clause_code): Added OMP_CLAUSE__GRIDDIM_.\n\t(tree_omp_clause): Added union field dimension.\n\t* tree-pretty-print.c (dump_omp_clause): Handle OMP_CLAUSE__GRIDDIM_.\n\t* tree.c (omp_clause_num_ops): Added number of arguments of\n\tOMP_CLAUSE__GRIDDIM_.\n\t(omp_clause_code_name): Added name of OMP_CLAUSE__GRIDDIM_.\n\t(walk_tree_1): Handle OMP_CLAUSE__GRIDDIM_.\n\t* tree.h (OMP_CLAUSE_GRIDDIM_DIMENSION): New.\n\t(OMP_CLAUSE_SET_GRIDDIM_DIMENSION): Likewise.\n\t(OMP_CLAUSE_GRIDDIM_SIZE): Likewise.\n\t(OMP_CLAUSE_GRIDDIM_GROUP): Likewise.\n\t* passes.def: Schedule pass_ipa_hsa and pass_gen_hsail.\n\t* tree-pass.h (make_pass_gen_hsail): Declare.\n\t(make_pass_ipa_hsa): Likewise.\n\t* ipa-hsa.c: New file.\n\t* lto-section-in.c (lto_section_name): Add hsa section name.\n\t* lto-streamer.h (lto_section_type): Add hsa section.\n\t* timevar.def (TV_IPA_HSA): New.\n        * hsa-brig-format.h: New file.\n\t* hsa-brig.c: New file.\n\t* hsa-dump.c: Likewise.\n\t* hsa-gen.c: Likewise.\n\t* hsa.c: Likewise.\n\t* hsa.h: Likewise.\n\t* toplev.c (compile_file): Call hsa_output_brig.\n\t* hsa-regalloc.c: New file.\n\ngcc/fortran/\n\t* types.def (BT_FN_VOID_UINT_PTR_INT_PTR): New.\n\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_INT_INT): Removed.\n\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_PTR): New.\n\ngcc/lto/\n\t* lto-partition.c: Include \"hsa.h\"\n\t(add_symbol_to_partition_1): Put hsa implementations into the\n\tsame partition as host implementations.\n\nliboffloadmic/\n\t* plugin/libgomp-plugin-intelmic.cpp (GOMP_OFFLOAD_async_run): New\n\tunused parameter.\n\t(GOMP_OFFLOAD_run): Likewise.\n\ninclude/\n\t* gomp-constants.h (GOMP_DEVICE_HSA): New macro.\n\t(GOMP_VERSION_HSA): Likewise.\n\t(GOMP_TARGET_ARG_DEVICE_MASK): Likewise.\n\t(GOMP_TARGET_ARG_DEVICE_ALL): Likewise.\n\t(GOMP_TARGET_ARG_SUBSEQUENT_PARAM): Likewise.\n\t(GOMP_TARGET_ARG_ID_MASK): Likewise.\n\t(GOMP_TARGET_ARG_NUM_TEAMS): Likewise.\n\t(GOMP_TARGET_ARG_THREAD_LIMIT): Likewise.\n\t(GOMP_TARGET_ARG_VALUE_SHIFT): Likewise.\n\t(GOMP_TARGET_ARG_HSA_KERNEL_ATTRIBUTES): Likewise.\n\nFrom-SVN: r232549", "tree": {"sha": "e669eb9cc41ef75177ede8bd306f466709040c9b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e669eb9cc41ef75177ede8bd306f466709040c9b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b2b40051500c944e882c274727cea7231eefaaf5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b2b40051500c944e882c274727cea7231eefaaf5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b2b40051500c944e882c274727cea7231eefaaf5", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b2b40051500c944e882c274727cea7231eefaaf5/comments", "author": null, "committer": null, "parents": [{"sha": "2bedb645f2aef48d7cbb70bf5ddb8bf0a4342019", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2bedb645f2aef48d7cbb70bf5ddb8bf0a4342019", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2bedb645f2aef48d7cbb70bf5ddb8bf0a4342019"}], "stats": {"total": 18783, "additions": 18517, "deletions": 266}, "files": [{"sha": "907a528894bdf4bed4d57b60667c8ca3c8a03bb8", "filename": "gcc/ChangeLog", "status": "modified", "additions": 132, "deletions": 0, "changes": 132, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1,3 +1,135 @@\n+2016-01-19  Martin Jambor  <mjambor@suse.cz>\n+\t    Martin Liska  <mliska@suse.cz>\n+\t    Michael Matz <matz@suse.de>\n+\n+\t* Makefile.in (OBJS): Add new source files.\n+\t(GTFILES): Add hsa.c.\n+\t* common.opt (disable_hsa): New variable.\n+\t(-Whsa): New warning.\n+\t* config.in (ENABLE_HSA): New.\n+\t* configure.ac: Treat hsa differently from other accelerators.\n+\t(OFFLOAD_TARGETS): Define ENABLE_OFFLOADING according to\n+\t$enable_offloading.\n+\t(ENABLE_HSA): Define ENABLE_HSA according to $enable_hsa.\n+\t* doc/install.texi (Configuration): Document --with-hsa-runtime,\n+\t--with-hsa-runtime-include, --with-hsa-runtime-lib and\n+\t--with-hsa-kmt-lib.\n+\t* doc/invoke.texi (-Whsa): Document.\n+\t(hsa-gen-debug-stores): Likewise.\n+\t* lto-wrapper.c (compile_images_for_offload_targets): Do not attempt\n+\tto invoke offload compiler for hsa acclerator.\n+\t* opts.c (common_handle_option): Determine whether HSA offloading\n+\tshould be performed.\n+\t* params.def (PARAM_HSA_GEN_DEBUG_STORES): New parameter.\n+\t* builtin-types.def (BT_FN_VOID_UINT_PTR_INT_PTR): New.\n+\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_INT_INT): Removed.\n+\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_PTR): New.\n+\t* gimple-low.c (lower_stmt): Also handle GIMPLE_OMP_GRID_BODY.\n+\t* gimple-pretty-print.c (dump_gimple_omp_for): Also handle\n+\tGF_OMP_FOR_KIND_GRID_LOOP.\n+\t(dump_gimple_omp_block): Also handle GIMPLE_OMP_GRID_BODY.\n+\t(pp_gimple_stmt_1): Likewise.\n+\t* gimple-walk.c (walk_gimple_stmt): Likewise.\n+\t* gimple.c (gimple_build_omp_grid_body): New function.\n+\t(gimple_copy): Also handle GIMPLE_OMP_GRID_BODY.\n+\t* gimple.def (GIMPLE_OMP_GRID_BODY): New.\n+\t* gimple.h (enum gf_mask): Added GF_OMP_PARALLEL_GRID_PHONY,\n+\tGF_OMP_FOR_KIND_GRID_LOOP, GF_OMP_FOR_GRID_PHONY and\n+\tGF_OMP_TEAMS_GRID_PHONY.\n+\t(gimple_statement_omp_single_layout): Updated comments.\n+\t(gimple_build_omp_grid_body): New function.\n+\t(gimple_has_substatements): Also handle GIMPLE_OMP_GRID_BODY.\n+\t(gimple_omp_for_grid_phony): New function.\n+\t(gimple_omp_for_set_grid_phony): Likewise.\n+\t(gimple_omp_parallel_grid_phony): Likewise.\n+\t(gimple_omp_parallel_set_grid_phony): Likewise.\n+\t(gimple_omp_teams_grid_phony): Likewise.\n+\t(gimple_omp_teams_set_grid_phony): Likewise.\n+\t(gimple_return_set_retbnd): Also handle GIMPLE_OMP_GRID_BODY.\n+\t* omp-builtins.def (BUILT_IN_GOMP_OFFLOAD_REGISTER): New.\n+\t(BUILT_IN_GOMP_OFFLOAD_UNREGISTER): Likewise.\n+\t(BUILT_IN_GOMP_TARGET): Updated type.\n+\t* omp-low.c: Include symbol-summary.h, hsa.h and params.h.\n+\t(adjust_for_condition): New function.\n+\t(get_omp_for_step_from_incr): Likewise.\n+\t(extract_omp_for_data): Moved parts to adjust_for_condition and\n+\tget_omp_for_step_from_incr.\n+\t(build_outer_var_ref): Handle GIMPLE_OMP_GRID_BODY.\n+\t(fixup_child_record_type): Bail out if receiver_decl is NULL.\n+\t(scan_sharing_clauses): Handle OMP_CLAUSE__GRIDDIM_.\n+\t(scan_omp_parallel): Do not create child functions for phony\n+\tconstructs.\n+\t(check_omp_nesting_restrictions): Handle GIMPLE_OMP_GRID_BODY.\n+\t(scan_omp_1_op): Checking assert we are not remapping to\n+\tERROR_MARK.  Also also handle GIMPLE_OMP_GRID_BODY.\n+\t(parallel_needs_hsa_kernel_p): New function.\n+\t(expand_parallel_call): Register apprpriate parallel child\n+\tfunctions as HSA kernels.\n+\t(grid_launch_attributes_trees): New type.\n+\t(grid_attr_trees): New variable.\n+\t(grid_create_kernel_launch_attr_types): New function.\n+\t(grid_insert_store_range_dim): Likewise.\n+\t(grid_get_kernel_launch_attributes): Likewise.\n+\t(get_target_argument_identifier_1): Likewise.\n+\t(get_target_argument_identifier): Likewise.\n+\t(get_target_argument_value): Likewise.\n+\t(push_target_argument_according_to_value): Likewise.\n+\t(get_target_arguments): Likewise.\n+\t(expand_omp_target): Call get_target_arguments instead of looking\n+\tup for teams and thread limit.\n+\t(grid_expand_omp_for_loop): New function.\n+\t(grid_arg_decl_map): New type.\n+\t(grid_remap_kernel_arg_accesses): New function.\n+\t(grid_expand_target_kernel_body): New function.\n+\t(expand_omp): Call it.\n+\t(lower_omp_for): Do not emit phony constructs.\n+\t(lower_omp_taskreg): Do not emit phony constructs but create for them\n+\ta temporary variable receiver_decl.\n+\t(lower_omp_taskreg): Do not emit phony constructs.\n+\t(lower_omp_teams): Likewise.\n+\t(lower_omp_grid_body): New function.\n+\t(lower_omp_1): Call it.\n+\t(grid_reg_assignment_to_local_var_p): New function.\n+\t(grid_seq_only_contains_local_assignments): Likewise.\n+\t(grid_find_single_omp_among_assignments_1): Likewise.\n+\t(grid_find_single_omp_among_assignments): Likewise.\n+\t(grid_find_ungridifiable_statement): Likewise.\n+\t(grid_target_follows_gridifiable_pattern): Likewise.\n+\t(grid_remap_prebody_decls): Likewise.\n+\t(grid_copy_leading_local_assignments): Likewise.\n+\t(grid_process_kernel_body_copy): Likewise.\n+\t(grid_attempt_target_gridification): Likewise.\n+\t(grid_gridify_all_targets_stmt): Likewise.\n+\t(grid_gridify_all_targets): Likewise.\n+\t(execute_lower_omp): Call grid_gridify_all_targets.\n+\t(make_gimple_omp_edges): Handle GIMPLE_OMP_GRID_BODY.\n+\t* tree-core.h (omp_clause_code): Added OMP_CLAUSE__GRIDDIM_.\n+\t(tree_omp_clause): Added union field dimension.\n+\t* tree-pretty-print.c (dump_omp_clause): Handle OMP_CLAUSE__GRIDDIM_.\n+\t* tree.c (omp_clause_num_ops): Added number of arguments of\n+\tOMP_CLAUSE__GRIDDIM_.\n+\t(omp_clause_code_name): Added name of OMP_CLAUSE__GRIDDIM_.\n+\t(walk_tree_1): Handle OMP_CLAUSE__GRIDDIM_.\n+\t* tree.h (OMP_CLAUSE_GRIDDIM_DIMENSION): New.\n+\t(OMP_CLAUSE_SET_GRIDDIM_DIMENSION): Likewise.\n+\t(OMP_CLAUSE_GRIDDIM_SIZE): Likewise.\n+\t(OMP_CLAUSE_GRIDDIM_GROUP): Likewise.\n+\t* passes.def: Schedule pass_ipa_hsa and pass_gen_hsail.\n+\t* tree-pass.h (make_pass_gen_hsail): Declare.\n+\t(make_pass_ipa_hsa): Likewise.\n+\t* ipa-hsa.c: New file.\n+\t* lto-section-in.c (lto_section_name): Add hsa section name.\n+\t* lto-streamer.h (lto_section_type): Add hsa section.\n+\t* timevar.def (TV_IPA_HSA): New.\n+        * hsa-brig-format.h: New file.\n+\t* hsa-brig.c: New file.\n+\t* hsa-dump.c: Likewise.\n+\t* hsa-gen.c: Likewise.\n+\t* hsa.c: Likewise.\n+\t* hsa.h: Likewise.\n+\t* toplev.c (compile_file): Call hsa_output_brig.\n+\t* hsa-regalloc.c: New file.\n+\n 2016-01-18  Jeff Law  <law@redhat.com>\n \n \tPR tree-optimization/69320"}, {"sha": "ab9cbbfaf02215a348ca3a115d9d7612bc86492c", "filename": "gcc/Makefile.in", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1297,6 +1297,11 @@ OBJS = \\\n \tgraphite-sese-to-poly.o \\\n \tgtype-desc.o \\\n \thaifa-sched.o \\\n+\thsa.o \\\n+\thsa-gen.o \\\n+\thsa-regalloc.o \\\n+\thsa-brig.o \\\n+\thsa-dump.o \\\n \thw-doloop.o \\\n \thwint.o \\\n \tifcvt.o \\\n@@ -1321,6 +1326,7 @@ OBJS = \\\n \tipa-icf.o \\\n \tipa-icf-gimple.o \\\n \tipa-reference.o \\\n+\tipa-hsa.o \\\n \tipa-ref.o \\\n \tipa-utils.o \\\n \tipa.o \\\n@@ -2404,6 +2410,7 @@ GTFILES = $(CPP_ID_DATA_H) $(srcdir)/input.h $(srcdir)/coretypes.h \\\n   $(srcdir)/sancov.c \\\n   $(srcdir)/ipa-devirt.c \\\n   $(srcdir)/internal-fn.h \\\n+  $(srcdir)/hsa.c \\\n   @all_gtfiles@\n \n # Compute the list of GT header files from the corresponding C sources,"}, {"sha": "7fab9f831584b9ea7b71cbee6a6d824969f5e957", "filename": "gcc/builtin-types.def", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fbuiltin-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fbuiltin-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltin-types.def?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -478,6 +478,8 @@ DEF_FUNCTION_TYPE_4 (BT_FN_BOOL_UINT_LONGPTR_LONGPTR_LONGPTR,\n DEF_FUNCTION_TYPE_4 (BT_FN_BOOL_UINT_ULLPTR_ULLPTR_ULLPTR,\n \t\t     BT_BOOL, BT_UINT, BT_PTR_ULONGLONG, BT_PTR_ULONGLONG,\n \t\t     BT_PTR_ULONGLONG)\n+DEF_FUNCTION_TYPE_4 (BT_FN_VOID_UINT_PTR_INT_PTR, BT_VOID, BT_INT, BT_PTR,\n+\t\t     BT_INT, BT_PTR)\n \n DEF_FUNCTION_TYPE_5 (BT_FN_INT_STRING_INT_SIZE_CONST_STRING_VALIST_ARG,\n \t\t     BT_INT, BT_STRING, BT_INT, BT_SIZE, BT_CONST_STRING,\n@@ -555,10 +557,9 @@ DEF_FUNCTION_TYPE_9 (BT_FN_VOID_OMPFN_PTR_OMPCPYFN_LONG_LONG_BOOL_UINT_PTR_INT,\n \t\t     BT_VOID, BT_PTR_FN_VOID_PTR, BT_PTR,\n \t\t     BT_PTR_FN_VOID_PTR_PTR, BT_LONG, BT_LONG,\n \t\t     BT_BOOL, BT_UINT, BT_PTR, BT_INT)\n-\n-DEF_FUNCTION_TYPE_10 (BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_INT_INT,\n-\t\t      BT_VOID, BT_INT, BT_PTR_FN_VOID_PTR, BT_SIZE, BT_PTR,\n-\t\t      BT_PTR, BT_PTR, BT_UINT, BT_PTR, BT_INT, BT_INT)\n+DEF_FUNCTION_TYPE_9 (BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_PTR,\n+\t\t     BT_VOID, BT_INT, BT_PTR_FN_VOID_PTR, BT_SIZE, BT_PTR,\n+\t\t     BT_PTR, BT_PTR, BT_UINT, BT_PTR, BT_PTR)\n \n DEF_FUNCTION_TYPE_11 (BT_FN_VOID_OMPFN_PTR_OMPCPYFN_LONG_LONG_UINT_LONG_INT_LONG_LONG_LONG,\n \t\t      BT_VOID, BT_PTR_FN_VOID_PTR, BT_PTR,"}, {"sha": "23e6ed71ea7ffbf24472ed9e55858d20c4ddc8a5", "filename": "gcc/common.opt", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fcommon.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fcommon.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcommon.opt?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -239,6 +239,10 @@ Inserts call to __sanitizer_cov_trace_pc into every basic block.\n Variable\n bool dump_base_name_prefixed = false\n \n+; Flag whether HSA generation has been explicitely disabled\n+Variable\n+bool flag_disable_hsa = false\n+\n ###\n Driver\n \n@@ -593,6 +597,10 @@ Wfree-nonheap-object\n Common Var(warn_free_nonheap_object) Init(1) Warning\n Warn when attempting to free a non-heap object.\n \n+Whsa\n+Common Var(warn_hsa) Init(1) Warning\n+Warn when a function cannot be expanded to HSAIL.\n+\n Winline\n Common Var(warn_inline) Warning\n Warn when an inlined function cannot be inlined."}, {"sha": "c3340bb09014e7d396193ac0d9c0c978da685443", "filename": "gcc/config.in", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fconfig.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fconfig.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.in?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -144,6 +144,12 @@\n #endif\n \n \n+/* Define this to enable support for generating HSAIL. */\n+#ifndef USED_FOR_TARGET\n+#undef ENABLE_HSA\n+#endif\n+\n+\n /* Define if gcc should always pass --build-id to linker. */\n #ifndef USED_FOR_TARGET\n #undef ENABLE_LD_BUILDID"}, {"sha": "7db75526dd22c70ca0c5a0384415b5c5cb6adce0", "filename": "gcc/configure", "status": "modified", "additions": 16, "deletions": 3, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fconfigure", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fconfigure", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfigure?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -7700,6 +7700,13 @@ fi\n \n for tgt in `echo $enable_offload_targets | sed 's/,/ /g'`; do\n   tgt=`echo $tgt | sed 's/=.*//'`\n+\n+  if echo \"$tgt\" | grep \"^hsa\" > /dev/null ; then\n+    enable_hsa=1\n+  else\n+    enable_offloading=1\n+  fi\n+\n   if test x\"$offload_targets\" = x; then\n     offload_targets=$tgt\n   else\n@@ -7711,7 +7718,7 @@ cat >>confdefs.h <<_ACEOF\n #define OFFLOAD_TARGETS \"$offload_targets\"\n _ACEOF\n \n-if test x\"$offload_targets\" != x; then\n+if test x\"$enable_offloading\" != x; then\n \n $as_echo \"#define ENABLE_OFFLOADING 1\" >>confdefs.h\n \n@@ -7721,6 +7728,12 @@ $as_echo \"#define ENABLE_OFFLOADING 0\" >>confdefs.h\n \n fi\n \n+if test x\"$enable_hsa\" = x1 ; then\n+\n+$as_echo \"#define ENABLE_HSA 1\" >>confdefs.h\n+\n+fi\n+\n \n # Check whether --with-multilib-list was given.\n if test \"${with_multilib_list+set}\" = set; then :\n@@ -18406,7 +18419,7 @@ else\n   lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n   lt_status=$lt_dlunknown\n   cat > conftest.$ac_ext <<_LT_EOF\n-#line 18409 \"configure\"\n+#line 18422 \"configure\"\n #include \"confdefs.h\"\n \n #if HAVE_DLFCN_H\n@@ -18512,7 +18525,7 @@ else\n   lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n   lt_status=$lt_dlunknown\n   cat > conftest.$ac_ext <<_LT_EOF\n-#line 18515 \"configure\"\n+#line 18528 \"configure\"\n #include \"confdefs.h\"\n \n #if HAVE_DLFCN_H"}, {"sha": "8d3a86943afae0e5ce7249f2f0049385014d0994", "filename": "gcc/configure.ac", "status": "modified", "additions": 13, "deletions": 1, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fconfigure.ac", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fconfigure.ac", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfigure.ac?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -940,6 +940,13 @@ AC_SUBST(accel_dir_suffix)\n \n for tgt in `echo $enable_offload_targets | sed 's/,/ /g'`; do\n   tgt=`echo $tgt | sed 's/=.*//'`\n+\n+  if echo \"$tgt\" | grep \"^hsa\" > /dev/null ; then\n+    enable_hsa=1\n+  else\n+    enable_offloading=1\n+  fi\n+\n   if test x\"$offload_targets\" = x; then\n     offload_targets=$tgt\n   else\n@@ -948,14 +955,19 @@ for tgt in `echo $enable_offload_targets | sed 's/,/ /g'`; do\n done\n AC_DEFINE_UNQUOTED(OFFLOAD_TARGETS, \"$offload_targets\",\n   [Define to offload targets, separated by commas.])\n-if test x\"$offload_targets\" != x; then\n+if test x\"$enable_offloading\" != x; then\n   AC_DEFINE(ENABLE_OFFLOADING, 1,\n     [Define this to enable support for offloading.])\n else\n   AC_DEFINE(ENABLE_OFFLOADING, 0,\n     [Define this to enable support for offloading.])\n fi\n \n+if test x\"$enable_hsa\" = x1 ; then\n+  AC_DEFINE(ENABLE_HSA, 1,\n+    [Define this to enable support for generating HSAIL.])\n+fi\n+\n AC_ARG_WITH(multilib-list,\n [AS_HELP_STRING([--with-multilib-list], [select multilibs (AArch64, SH and x86-64 only)])],\n :,"}, {"sha": "062f42cedef082c19d50c257980a10753921b1d9", "filename": "gcc/doc/install.texi", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fdoc%2Finstall.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fdoc%2Finstall.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finstall.texi?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1992,6 +1992,28 @@ specifying paths @var{path1}, @dots{}, @var{pathN}.\n % @var{srcdir}/configure \\\n     --enable-offload-target=i686-unknown-linux-gnu=/path/to/i686/compiler,x86_64-pc-linux-gnu\n @end smallexample\n+\n+If @samp{hsa} is specified as one of the targets, the compiler will be\n+built with support for HSA GPU accelerators.  Because the same\n+compiler will emit the accelerator code, no path should be specified.\n+\n+@item --with-hsa-runtime=@var{pathname}\n+@itemx --with-hsa-runtime-include=@var{pathname}\n+@itemx --with-hsa-runtime-lib=@var{pathname}\n+\n+If you configure GCC with HSA offloading but do not have the HSA\n+run-time library installed in a standard location then you can\n+explicitly specify the directory where they are installed.  The\n+@option{--with-hsa-runtime=@/@var{hsainstalldir}} option is a\n+shorthand for\n+@option{--with-hsa-runtime-lib=@/@var{hsainstalldir}/lib} and\n+@option{--with-hsa-runtime-include=@/@var{hsainstalldir}/include}.\n+\n+@item --with-hsa-kmt-lib=@var{pathname}\n+\n+If you configure GCC with HSA offloading but do not have the HSA\n+KMT library installed in a standard location then you can\n+explicitly specify the directory where it resides.\n @end table\n \n @subheading Cross-Compiler-Specific Options"}, {"sha": "077324bb968171fbdef25b96db3c861b3f8ebe05", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -305,7 +305,7 @@ Objective-C and Objective-C++ Dialects}.\n -Wunused-but-set-parameter -Wunused-but-set-variable @gol\n -Wuseless-cast -Wvariadic-macros -Wvector-operation-performance @gol\n -Wvla -Wvolatile-register-var  -Wwrite-strings @gol\n--Wzero-as-null-pointer-constant}\n+-Wzero-as-null-pointer-constant -Whsa}\n \n @item C and Objective-C-only Warning Options\n @gccoptlist{-Wbad-function-cast  -Wmissing-declarations @gol\n@@ -5693,6 +5693,10 @@ Suppress warnings when a positional initializer is used to initialize\n a structure that has been marked with the @code{designated_init}\n attribute.\n \n+@item -Whsa\n+Issue a warning when HSAIL cannot be emitted for the compiled function or\n+OpenMP construct.\n+\n @end table\n \n @node Debugging Options\n@@ -9508,6 +9512,12 @@ dynamic, guided, auto, runtime).  The default is static.\n Maximum depth of recursion when querying properties of SSA names in things\n like fold routines.  One level of recursion corresponds to following a\n use-def chain.\n+\n+@item hsa-gen-debug-stores\n+Enable emission of special debug stores within HSA kernels which are\n+then read and reported by libgomp plugin.  Generation of these stores\n+is disabled by default, use @option{--param hsa-gen-debug-stores=1} to\n+enable it.\n @end table\n @end table\n "}, {"sha": "ee83c2e9f8e5c5ea8942df0bde4850946d652f75", "filename": "gcc/fortran/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ffortran%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ffortran%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2FChangeLog?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1,3 +1,9 @@\n+2016-01-19  Martin Jambor  <mjambor@suse.cz>\n+\n+\t* types.def (BT_FN_VOID_UINT_PTR_INT_PTR): New.\n+\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_INT_INT): Removed.\n+\t(BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_PTR): New.\n+\n 2016-01-15  Paul Thomas  <pault@gcc.gnu.org>\n \n \tPR fortran/64324"}, {"sha": "8780b761da94cb87a287d330458e87d50b397c0b", "filename": "gcc/fortran/types.def", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ffortran%2Ftypes.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ffortran%2Ftypes.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftypes.def?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -159,6 +159,8 @@ DEF_FUNCTION_TYPE_4 (BT_FN_BOOL_UINT_LONGPTR_LONGPTR_LONGPTR,\n DEF_FUNCTION_TYPE_4 (BT_FN_BOOL_UINT_ULLPTR_ULLPTR_ULLPTR,\n \t\t     BT_BOOL, BT_UINT, BT_PTR_ULONGLONG, BT_PTR_ULONGLONG,\n \t\t     BT_PTR_ULONGLONG)\n+DEF_FUNCTION_TYPE_4 (BT_FN_VOID_UINT_PTR_INT_PTR, BT_VOID, BT_INT, BT_PTR,\n+\t\t     BT_INT, BT_PTR)\n \n DEF_FUNCTION_TYPE_5 (BT_FN_VOID_OMPFN_PTR_UINT_UINT_UINT,\n \t\t     BT_VOID, BT_PTR_FN_VOID_PTR, BT_PTR, BT_UINT, BT_UINT,\n@@ -220,10 +222,9 @@ DEF_FUNCTION_TYPE_9 (BT_FN_VOID_OMPFN_PTR_OMPCPYFN_LONG_LONG_BOOL_UINT_PTR_INT,\n \t\t     BT_VOID, BT_PTR_FN_VOID_PTR, BT_PTR,\n \t\t     BT_PTR_FN_VOID_PTR_PTR, BT_LONG, BT_LONG,\n \t\t     BT_BOOL, BT_UINT, BT_PTR, BT_INT)\n-\n-DEF_FUNCTION_TYPE_10 (BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_INT_INT,\n+DEF_FUNCTION_TYPE_9 (BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_PTR,\n \t\t      BT_VOID, BT_INT, BT_PTR_FN_VOID_PTR, BT_SIZE, BT_PTR,\n-\t\t      BT_PTR, BT_PTR, BT_UINT, BT_PTR, BT_INT, BT_INT)\n+\t\t      BT_PTR, BT_PTR, BT_UINT, BT_PTR, BT_PTR)\n \n DEF_FUNCTION_TYPE_11 (BT_FN_VOID_OMPFN_PTR_OMPCPYFN_LONG_LONG_UINT_LONG_INT_LONG_LONG_LONG,\n \t\t      BT_VOID, BT_PTR_FN_VOID_PTR, BT_PTR,"}, {"sha": "eb90d481a7df720064c96e45964755d52434d3c6", "filename": "gcc/gimple-low.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple-low.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple-low.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-low.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -358,6 +358,7 @@ lower_stmt (gimple_stmt_iterator *gsi, struct lower_data *data)\n     case GIMPLE_OMP_TASK:\n     case GIMPLE_OMP_TARGET:\n     case GIMPLE_OMP_TEAMS:\n+    case GIMPLE_OMP_GRID_BODY:\n       data->cannot_fallthru = false;\n       lower_omp_directive (gsi, data);\n       data->cannot_fallthru = false;"}, {"sha": "e27214fd1a812f0f5a7feba93a2b64d39a8996a3", "filename": "gcc/gimple-pretty-print.c", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-pretty-print.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1187,6 +1187,9 @@ dump_gimple_omp_for (pretty_printer *buffer, gomp_for *gs, int spc, int flags)\n \tcase GF_OMP_FOR_KIND_CILKSIMD:\n \t  pp_string (buffer, \"#pragma simd\");\n \t  break;\n+\tcase GF_OMP_FOR_KIND_GRID_LOOP:\n+\t  pp_string (buffer, \"#pragma omp for grid_loop\");\n+\t  break;\n \tdefault:\n \t  gcc_unreachable ();\n \t}\n@@ -1494,6 +1497,9 @@ dump_gimple_omp_block (pretty_printer *buffer, gimple *gs, int spc, int flags)\n \tcase GIMPLE_OMP_SECTION:\n \t  pp_string (buffer, \"#pragma omp section\");\n \t  break;\n+\tcase GIMPLE_OMP_GRID_BODY:\n+\t  pp_string (buffer, \"#pragma omp gridified body\");\n+\t  break;\n \tdefault:\n \t  gcc_unreachable ();\n \t}\n@@ -2301,6 +2307,7 @@ pp_gimple_stmt_1 (pretty_printer *buffer, gimple *gs, int spc, int flags)\n     case GIMPLE_OMP_MASTER:\n     case GIMPLE_OMP_TASKGROUP:\n     case GIMPLE_OMP_SECTION:\n+    case GIMPLE_OMP_GRID_BODY:\n       dump_gimple_omp_block (buffer, gs, spc, flags);\n       break;\n "}, {"sha": "15cd84209042927fe9a577d1210e8726c720a7af", "filename": "gcc/gimple-walk.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple-walk.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple-walk.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-walk.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -655,6 +655,7 @@ walk_gimple_stmt (gimple_stmt_iterator *gsi, walk_stmt_fn callback_stmt,\n     case GIMPLE_OMP_SINGLE:\n     case GIMPLE_OMP_TARGET:\n     case GIMPLE_OMP_TEAMS:\n+    case GIMPLE_OMP_GRID_BODY:\n       ret = walk_gimple_seq_mod (gimple_omp_body_ptr (stmt), callback_stmt,\n \t\t\t     callback_op, wi);\n       if (ret)"}, {"sha": "850e54669cd6fd74280da714c9c4c402723ea414", "filename": "gcc/gimple.c", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -954,6 +954,19 @@ gimple_build_omp_master (gimple_seq body)\n   return p;\n }\n \n+/* Build a GIMPLE_OMP_GRID_BODY statement.\n+\n+   BODY is the sequence of statements to be executed by the kernel.  */\n+\n+gimple *\n+gimple_build_omp_grid_body (gimple_seq body)\n+{\n+  gimple *p = gimple_alloc (GIMPLE_OMP_GRID_BODY, 0);\n+  if (body)\n+    gimple_omp_set_body (p, body);\n+\n+  return p;\n+}\n \n /* Build a GIMPLE_OMP_TASKGROUP statement.\n \n@@ -1807,6 +1820,7 @@ gimple_copy (gimple *stmt)\n \tcase GIMPLE_OMP_SECTION:\n \tcase GIMPLE_OMP_MASTER:\n \tcase GIMPLE_OMP_TASKGROUP:\n+\tcase GIMPLE_OMP_GRID_BODY:\n \tcopy_omp_body:\n \t  new_seq = gimple_seq_copy (gimple_omp_body (stmt));\n \t  gimple_omp_set_body (copy, new_seq);"}, {"sha": "2ff22b881abd07273098fb359a8588e228a2da83", "filename": "gcc/gimple.def", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple.def?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -376,6 +376,10 @@ DEFGSCODE(GIMPLE_OMP_TEAMS, \"gimple_omp_teams\", GSS_OMP_SINGLE_LAYOUT)\n    CLAUSES is an OMP_CLAUSE chain holding the associated clauses.  */\n DEFGSCODE(GIMPLE_OMP_ORDERED, \"gimple_omp_ordered\", GSS_OMP_SINGLE_LAYOUT)\n \n+/* GIMPLE_OMP_GRID_BODY <BODY> represents a parallel loop lowered for execution\n+   on a GPU.  It is an artificial statement created by omp lowering.  */\n+DEFGSCODE(GIMPLE_OMP_GRID_BODY, \"gimple_omp_gpukernel\", GSS_OMP)\n+\n /* GIMPLE_PREDICT <PREDICT, OUTCOME> specifies a hint for branch prediction.\n \n    PREDICT is one of the predictors from predict.def."}, {"sha": "6d15dab5120e0b24294dff506d6ea3396a0fa04f", "filename": "gcc/gimple.h", "status": "modified", "additions": 63, "deletions": 2, "changes": 65, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fgimple.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -146,19 +146,22 @@ enum gf_mask {\n     GF_CALL_CTRL_ALTERING       = 1 << 7,\n     GF_CALL_WITH_BOUNDS \t= 1 << 8,\n     GF_OMP_PARALLEL_COMBINED\t= 1 << 0,\n+    GF_OMP_PARALLEL_GRID_PHONY = 1 << 1,\n     GF_OMP_TASK_TASKLOOP\t= 1 << 0,\n     GF_OMP_FOR_KIND_MASK\t= (1 << 4) - 1,\n     GF_OMP_FOR_KIND_FOR\t\t= 0,\n     GF_OMP_FOR_KIND_DISTRIBUTE\t= 1,\n     GF_OMP_FOR_KIND_TASKLOOP\t= 2,\n     GF_OMP_FOR_KIND_CILKFOR     = 3,\n     GF_OMP_FOR_KIND_OACC_LOOP\t= 4,\n+    GF_OMP_FOR_KIND_GRID_LOOP = 5,\n     /* Flag for SIMD variants of OMP_FOR kinds.  */\n     GF_OMP_FOR_SIMD\t\t= 1 << 3,\n     GF_OMP_FOR_KIND_SIMD\t= GF_OMP_FOR_SIMD | 0,\n     GF_OMP_FOR_KIND_CILKSIMD\t= GF_OMP_FOR_SIMD | 1,\n     GF_OMP_FOR_COMBINED\t\t= 1 << 4,\n     GF_OMP_FOR_COMBINED_INTO\t= 1 << 5,\n+    GF_OMP_FOR_GRID_PHONY\t= 1 << 6,\n     GF_OMP_TARGET_KIND_MASK\t= (1 << 4) - 1,\n     GF_OMP_TARGET_KIND_REGION\t= 0,\n     GF_OMP_TARGET_KIND_DATA\t= 1,\n@@ -172,6 +175,7 @@ enum gf_mask {\n     GF_OMP_TARGET_KIND_OACC_ENTER_EXIT_DATA = 9,\n     GF_OMP_TARGET_KIND_OACC_DECLARE = 10,\n     GF_OMP_TARGET_KIND_OACC_HOST_DATA = 11,\n+    GF_OMP_TEAMS_GRID_PHONY\t= 1 << 0,\n \n     /* True on an GIMPLE_OMP_RETURN statement if the return does not require\n        a thread synchronization via some sort of barrier.  The exact barrier\n@@ -733,7 +737,7 @@ struct GTY((tag(\"GSS_OMP_SINGLE_LAYOUT\")))\n {\n   /* [ WORD 1-7 ] : base class */\n \n-  /* [ WORD 7 ]  */\n+  /* [ WORD 8 ]  */\n   tree clauses;\n };\n \n@@ -1454,6 +1458,7 @@ gomp_task *gimple_build_omp_task (gimple_seq, tree, tree, tree, tree,\n \t\t\t\t       tree, tree);\n gimple *gimple_build_omp_section (gimple_seq);\n gimple *gimple_build_omp_master (gimple_seq);\n+gimple *gimple_build_omp_grid_body (gimple_seq);\n gimple *gimple_build_omp_taskgroup (gimple_seq);\n gomp_continue *gimple_build_omp_continue (tree, tree);\n gomp_ordered *gimple_build_omp_ordered (gimple_seq, tree);\n@@ -1714,6 +1719,7 @@ gimple_has_substatements (gimple *g)\n     case GIMPLE_OMP_CRITICAL:\n     case GIMPLE_WITH_CLEANUP_EXPR:\n     case GIMPLE_TRANSACTION:\n+    case GIMPLE_OMP_GRID_BODY:\n       return true;\n \n     default:\n@@ -5079,6 +5085,24 @@ gimple_omp_for_set_pre_body (gimple *gs, gimple_seq pre_body)\n   omp_for_stmt->pre_body = pre_body;\n }\n \n+/* Return the kernel_phony of OMP_FOR statement.  */\n+\n+static inline bool\n+gimple_omp_for_grid_phony (const gomp_for *omp_for)\n+{\n+  return (gimple_omp_subcode (omp_for) & GF_OMP_FOR_GRID_PHONY) != 0;\n+}\n+\n+/* Set kernel_phony flag of OMP_FOR to VALUE.  */\n+\n+static inline void\n+gimple_omp_for_set_grid_phony (gomp_for *omp_for, bool value)\n+{\n+  if (value)\n+    omp_for->subcode |= GF_OMP_FOR_GRID_PHONY;\n+  else\n+    omp_for->subcode &= ~GF_OMP_FOR_GRID_PHONY;\n+}\n \n /* Return the clauses associated with OMP_PARALLEL GS.  */\n \n@@ -5165,6 +5189,24 @@ gimple_omp_parallel_set_data_arg (gomp_parallel *omp_parallel_stmt,\n   omp_parallel_stmt->data_arg = data_arg;\n }\n \n+/* Return the kernel_phony flag of OMP_PARALLEL_STMT.  */\n+\n+static inline bool\n+gimple_omp_parallel_grid_phony (const gomp_parallel *stmt)\n+{\n+  return (gimple_omp_subcode (stmt) & GF_OMP_PARALLEL_GRID_PHONY) != 0;\n+}\n+\n+/* Set kernel_phony flag of OMP_PARALLEL_STMT to VALUE.  */\n+\n+static inline void\n+gimple_omp_parallel_set_grid_phony (gomp_parallel *stmt, bool value)\n+{\n+  if (value)\n+    stmt->subcode |= GF_OMP_PARALLEL_GRID_PHONY;\n+  else\n+    stmt->subcode &= ~GF_OMP_PARALLEL_GRID_PHONY;\n+}\n \n /* Return the clauses associated with OMP_TASK GS.  */\n \n@@ -5638,6 +5680,24 @@ gimple_omp_teams_set_clauses (gomp_teams *omp_teams_stmt, tree clauses)\n   omp_teams_stmt->clauses = clauses;\n }\n \n+/* Return the kernel_phony flag of an OMP_TEAMS_STMT.  */\n+\n+static inline bool\n+gimple_omp_teams_grid_phony (const gomp_teams *omp_teams_stmt)\n+{\n+  return (gimple_omp_subcode (omp_teams_stmt) & GF_OMP_TEAMS_GRID_PHONY) != 0;\n+}\n+\n+/* Set kernel_phony flag of an OMP_TEAMS_STMT to VALUE.  */\n+\n+static inline void\n+gimple_omp_teams_set_grid_phony (gomp_teams *omp_teams_stmt, bool value)\n+{\n+  if (value)\n+    omp_teams_stmt->subcode |= GF_OMP_TEAMS_GRID_PHONY;\n+  else\n+    omp_teams_stmt->subcode &= ~GF_OMP_TEAMS_GRID_PHONY;\n+}\n \n /* Return the clauses associated with OMP_SECTIONS GS.  */\n \n@@ -6002,7 +6062,8 @@ gimple_return_set_retbnd (gimple *gs, tree retval)\n     case GIMPLE_OMP_RETURN:\t\t\t\\\n     case GIMPLE_OMP_ATOMIC_LOAD:\t\t\\\n     case GIMPLE_OMP_ATOMIC_STORE:\t\t\\\n-    case GIMPLE_OMP_CONTINUE\n+    case GIMPLE_OMP_CONTINUE:\t\t\t\\\n+    case GIMPLE_OMP_GRID_BODY\n \n static inline bool\n is_gimple_omp (const gimple *stmt)"}, {"sha": "e1c6cd2a899b6c5e939be098f1c78433ac07c78c", "filename": "gcc/hsa-brig-format.h", "status": "added", "additions": 1234, "deletions": 0, "changes": 1234, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-brig-format.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-brig-format.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa-brig-format.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,1234 @@\n+/* HSA BRIG (binary representation of HSAIL) 1.0.1 representation description.\n+   Copyright (C) 2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.\n+\n+The contents of the file was created by extracting data structures, enum,\n+typedef and other definitions from HSA Programmer's Reference Manual Version\n+1.0.1 (http://www.hsafoundation.com/standards/).\n+\n+HTML version is provided on the following link:\n+http://www.hsafoundation.com/html/Content/PRM/Topics/PRM_title_page.htm */\n+\n+#ifndef HSA_BRIG_FORMAT_H\n+#define HSA_BRIG_FORMAT_H\n+\n+struct BrigModuleHeader;\n+typedef uint16_t BrigKind16_t;\n+typedef uint32_t BrigVersion32_t;\n+\n+typedef BrigModuleHeader *BrigModule_t;\n+typedef uint32_t BrigDataOffset32_t;\n+typedef uint32_t BrigCodeOffset32_t;\n+typedef uint32_t BrigOperandOffset32_t;\n+typedef BrigDataOffset32_t BrigDataOffsetString32_t;\n+typedef BrigDataOffset32_t BrigDataOffsetCodeList32_t;\n+typedef BrigDataOffset32_t BrigDataOffsetOperandList32_t;\n+typedef uint8_t BrigAlignment8_t;\n+\n+enum BrigAlignment\n+{\n+  BRIG_ALIGNMENT_NONE = 0,\n+  BRIG_ALIGNMENT_1 = 1,\n+  BRIG_ALIGNMENT_2 = 2,\n+  BRIG_ALIGNMENT_4 = 3,\n+  BRIG_ALIGNMENT_8 = 4,\n+  BRIG_ALIGNMENT_16 = 5,\n+  BRIG_ALIGNMENT_32 = 6,\n+  BRIG_ALIGNMENT_64 = 7,\n+  BRIG_ALIGNMENT_128 = 8,\n+  BRIG_ALIGNMENT_256 = 9\n+};\n+\n+typedef uint8_t BrigAllocation8_t;\n+\n+enum BrigAllocation\n+{\n+  BRIG_ALLOCATION_NONE = 0,\n+  BRIG_ALLOCATION_PROGRAM = 1,\n+  BRIG_ALLOCATION_AGENT = 2,\n+  BRIG_ALLOCATION_AUTOMATIC = 3\n+};\n+\n+typedef uint8_t BrigAluModifier8_t;\n+\n+enum BrigAluModifierMask\n+{\n+  BRIG_ALU_FTZ = 1\n+};\n+\n+typedef uint8_t BrigAtomicOperation8_t;\n+\n+enum BrigAtomicOperation\n+{\n+  BRIG_ATOMIC_ADD = 0,\n+  BRIG_ATOMIC_AND = 1,\n+  BRIG_ATOMIC_CAS = 2,\n+  BRIG_ATOMIC_EXCH = 3,\n+  BRIG_ATOMIC_LD = 4,\n+  BRIG_ATOMIC_MAX = 5,\n+  BRIG_ATOMIC_MIN = 6,\n+  BRIG_ATOMIC_OR = 7,\n+  BRIG_ATOMIC_ST = 8,\n+  BRIG_ATOMIC_SUB = 9,\n+  BRIG_ATOMIC_WRAPDEC = 10,\n+  BRIG_ATOMIC_WRAPINC = 11,\n+  BRIG_ATOMIC_XOR = 12,\n+  BRIG_ATOMIC_WAIT_EQ = 13,\n+  BRIG_ATOMIC_WAIT_NE = 14,\n+  BRIG_ATOMIC_WAIT_LT = 15,\n+  BRIG_ATOMIC_WAIT_GTE = 16,\n+  BRIG_ATOMIC_WAITTIMEOUT_EQ = 17,\n+  BRIG_ATOMIC_WAITTIMEOUT_NE = 18,\n+  BRIG_ATOMIC_WAITTIMEOUT_LT = 19,\n+  BRIG_ATOMIC_WAITTIMEOUT_GTE = 20\n+};\n+\n+struct BrigBase\n+{\n+  uint16_t byteCount;\n+  BrigKind16_t kind;\n+};\n+\n+typedef uint8_t BrigCompareOperation8_t;\n+\n+enum BrigCompareOperation\n+{\n+  BRIG_COMPARE_EQ = 0,\n+  BRIG_COMPARE_NE = 1,\n+  BRIG_COMPARE_LT = 2,\n+  BRIG_COMPARE_LE = 3,\n+  BRIG_COMPARE_GT = 4,\n+  BRIG_COMPARE_GE = 5,\n+  BRIG_COMPARE_EQU = 6,\n+  BRIG_COMPARE_NEU = 7,\n+  BRIG_COMPARE_LTU = 8,\n+  BRIG_COMPARE_LEU = 9,\n+  BRIG_COMPARE_GTU = 10,\n+  BRIG_COMPARE_GEU = 11,\n+  BRIG_COMPARE_NUM = 12,\n+  BRIG_COMPARE_NAN = 13,\n+  BRIG_COMPARE_SEQ = 14,\n+  BRIG_COMPARE_SNE = 15,\n+  BRIG_COMPARE_SLT = 16,\n+  BRIG_COMPARE_SLE = 17,\n+  BRIG_COMPARE_SGT = 18,\n+  BRIG_COMPARE_SGE = 19,\n+  BRIG_COMPARE_SGEU = 20,\n+  BRIG_COMPARE_SEQU = 21,\n+  BRIG_COMPARE_SNEU = 22,\n+  BRIG_COMPARE_SLTU = 23,\n+  BRIG_COMPARE_SLEU = 24,\n+  BRIG_COMPARE_SNUM = 25,\n+  BRIG_COMPARE_SNAN = 26,\n+  BRIG_COMPARE_SGTU = 27\n+};\n+\n+typedef uint16_t BrigControlDirective16_t;\n+\n+enum BrigControlDirective\n+{\n+  BRIG_CONTROL_NONE = 0,\n+  BRIG_CONTROL_ENABLEBREAKEXCEPTIONS = 1,\n+  BRIG_CONTROL_ENABLEDETECTEXCEPTIONS = 2,\n+  BRIG_CONTROL_MAXDYNAMICGROUPSIZE = 3,\n+  BRIG_CONTROL_MAXFLATGRIDSIZE = 4,\n+  BRIG_CONTROL_MAXFLATWORKGROUPSIZE = 5,\n+  BRIG_CONTROL_REQUIREDDIM = 6,\n+  BRIG_CONTROL_REQUIREDGRIDSIZE = 7,\n+  BRIG_CONTROL_REQUIREDWORKGROUPSIZE = 8,\n+  BRIG_CONTROL_REQUIRENOPARTIALWORKGROUPS = 9\n+};\n+\n+typedef uint32_t BrigExceptions32_t;\n+\n+enum BrigExceptionsMask\n+{\n+  BRIG_EXCEPTIONS_INVALID_OPERATION = 1 << 0,\n+  BRIG_EXCEPTIONS_DIVIDE_BY_ZERO = 1 << 1,\n+  BRIG_EXCEPTIONS_OVERFLOW = 1 << 2,\n+  BRIG_EXCEPTIONS_UNDERFLOW = 1 << 3,\n+  BRIG_EXCEPTIONS_INEXACT = 1 << 4,\n+  BRIG_EXCEPTIONS_FIRST_USER_DEFINED = 1 << 16\n+};\n+\n+typedef uint8_t BrigExecutableModifier8_t;\n+\n+enum BrigExecutableModifierMask\n+{\n+  BRIG_EXECUTABLE_DEFINITION = 1\n+};\n+\n+typedef uint8_t BrigImageChannelOrder8_t;\n+\n+enum BrigImageChannelOrder\n+{\n+  BRIG_CHANNEL_ORDER_A = 0,\n+  BRIG_CHANNEL_ORDER_R = 1,\n+  BRIG_CHANNEL_ORDER_RX = 2,\n+  BRIG_CHANNEL_ORDER_RG = 3,\n+  BRIG_CHANNEL_ORDER_RGX = 4,\n+  BRIG_CHANNEL_ORDER_RA = 5,\n+  BRIG_CHANNEL_ORDER_RGB = 6,\n+  BRIG_CHANNEL_ORDER_RGBX = 7,\n+  BRIG_CHANNEL_ORDER_RGBA = 8,\n+  BRIG_CHANNEL_ORDER_BGRA = 9,\n+  BRIG_CHANNEL_ORDER_ARGB = 10,\n+  BRIG_CHANNEL_ORDER_ABGR = 11,\n+  BRIG_CHANNEL_ORDER_SRGB = 12,\n+  BRIG_CHANNEL_ORDER_SRGBX = 13,\n+  BRIG_CHANNEL_ORDER_SRGBA = 14,\n+  BRIG_CHANNEL_ORDER_SBGRA = 15,\n+  BRIG_CHANNEL_ORDER_INTENSITY = 16,\n+  BRIG_CHANNEL_ORDER_LUMINANCE = 17,\n+  BRIG_CHANNEL_ORDER_DEPTH = 18,\n+  BRIG_CHANNEL_ORDER_DEPTH_STENCIL = 19,\n+  BRIG_CHANNEL_ORDER_FIRST_USER_DEFINED = 128\n+};\n+\n+typedef uint8_t BrigImageChannelType8_t;\n+\n+enum BrigImageChannelType\n+{\n+  BRIG_CHANNEL_TYPE_SNORM_INT8 = 0,\n+  BRIG_CHANNEL_TYPE_SNORM_INT16 = 1,\n+  BRIG_CHANNEL_TYPE_UNORM_INT8 = 2,\n+  BRIG_CHANNEL_TYPE_UNORM_INT16 = 3,\n+  BRIG_CHANNEL_TYPE_UNORM_INT24 = 4,\n+  BRIG_CHANNEL_TYPE_UNORM_SHORT_555 = 5,\n+  BRIG_CHANNEL_TYPE_UNORM_SHORT_565 = 6,\n+  BRIG_CHANNEL_TYPE_UNORM_INT_101010 = 7,\n+  BRIG_CHANNEL_TYPE_SIGNED_INT8 = 8,\n+  BRIG_CHANNEL_TYPE_SIGNED_INT16 = 9,\n+  BRIG_CHANNEL_TYPE_SIGNED_INT32 = 10,\n+  BRIG_CHANNEL_TYPE_UNSIGNED_INT8 = 11,\n+  BRIG_CHANNEL_TYPE_UNSIGNED_INT16 = 12,\n+  BRIG_CHANNEL_TYPE_UNSIGNED_INT32 = 13,\n+  BRIG_CHANNEL_TYPE_HALF_FLOAT = 14,\n+  BRIG_CHANNEL_TYPE_FLOAT = 15,\n+  BRIG_CHANNEL_TYPE_FIRST_USER_DEFINED = 128\n+};\n+\n+typedef uint8_t BrigImageGeometry8_t;\n+\n+enum BrigImageGeometry\n+{\n+  BRIG_GEOMETRY_1D = 0,\n+  BRIG_GEOMETRY_2D = 1,\n+  BRIG_GEOMETRY_3D = 2,\n+  BRIG_GEOMETRY_1DA = 3,\n+  BRIG_GEOMETRY_2DA = 4,\n+  BRIG_GEOMETRY_1DB = 5,\n+  BRIG_GEOMETRY_2DDEPTH = 6,\n+  BRIG_GEOMETRY_2DADEPTH = 7,\n+  BRIG_GEOMETRY_FIRST_USER_DEFINED = 128\n+};\n+\n+typedef uint8_t BrigImageQuery8_t;\n+\n+enum BrigImageQuery\n+{\n+  BRIG_IMAGE_QUERY_WIDTH = 0,\n+  BRIG_IMAGE_QUERY_HEIGHT = 1,\n+  BRIG_IMAGE_QUERY_DEPTH = 2,\n+  BRIG_IMAGE_QUERY_ARRAY = 3,\n+  BRIG_IMAGE_QUERY_CHANNELORDER = 4,\n+  BRIG_IMAGE_QUERY_CHANNELTYPE = 5\n+};\n+\n+enum BrigKind\n+{\n+  BRIG_KIND_NONE = 0x0000,\n+  BRIG_KIND_DIRECTIVE_BEGIN = 0x1000,\n+  BRIG_KIND_DIRECTIVE_ARG_BLOCK_END = 0x1000,\n+  BRIG_KIND_DIRECTIVE_ARG_BLOCK_START = 0x1001,\n+  BRIG_KIND_DIRECTIVE_COMMENT = 0x1002,\n+  BRIG_KIND_DIRECTIVE_CONTROL = 0x1003,\n+  BRIG_KIND_DIRECTIVE_EXTENSION = 0x1004,\n+  BRIG_KIND_DIRECTIVE_FBARRIER = 0x1005,\n+  BRIG_KIND_DIRECTIVE_FUNCTION = 0x1006,\n+  BRIG_KIND_DIRECTIVE_INDIRECT_FUNCTION = 0x1007,\n+  BRIG_KIND_DIRECTIVE_KERNEL = 0x1008,\n+  BRIG_KIND_DIRECTIVE_LABEL = 0x1009,\n+  BRIG_KIND_DIRECTIVE_LOC = 0x100a,\n+  BRIG_KIND_DIRECTIVE_MODULE = 0x100b,\n+  BRIG_KIND_DIRECTIVE_PRAGMA = 0x100c,\n+  BRIG_KIND_DIRECTIVE_SIGNATURE = 0x100d,\n+  BRIG_KIND_DIRECTIVE_VARIABLE = 0x100e,\n+  BRIG_KIND_DIRECTIVE_END = 0x100f,\n+  BRIG_KIND_INST_BEGIN = 0x2000,\n+  BRIG_KIND_INST_ADDR = 0x2000,\n+  BRIG_KIND_INST_ATOMIC = 0x2001,\n+  BRIG_KIND_INST_BASIC = 0x2002,\n+  BRIG_KIND_INST_BR = 0x2003,\n+  BRIG_KIND_INST_CMP = 0x2004,\n+  BRIG_KIND_INST_CVT = 0x2005,\n+  BRIG_KIND_INST_IMAGE = 0x2006,\n+  BRIG_KIND_INST_LANE = 0x2007,\n+  BRIG_KIND_INST_MEM = 0x2008,\n+  BRIG_KIND_INST_MEM_FENCE = 0x2009,\n+  BRIG_KIND_INST_MOD = 0x200a,\n+  BRIG_KIND_INST_QUERY_IMAGE = 0x200b,\n+  BRIG_KIND_INST_QUERY_SAMPLER = 0x200c,\n+  BRIG_KIND_INST_QUEUE = 0x200d,\n+  BRIG_KIND_INST_SEG = 0x200e,\n+  BRIG_KIND_INST_SEG_CVT = 0x200f,\n+  BRIG_KIND_INST_SIGNAL = 0x2010,\n+  BRIG_KIND_INST_SOURCE_TYPE = 0x2011,\n+  BRIG_KIND_INST_END = 0x2012,\n+  BRIG_KIND_OPERAND_BEGIN = 0x3000,\n+  BRIG_KIND_OPERAND_ADDRESS = 0x3000,\n+  BRIG_KIND_OPERAND_ALIGN = 0x3001,\n+  BRIG_KIND_OPERAND_CODE_LIST = 0x3002,\n+  BRIG_KIND_OPERAND_CODE_REF = 0x3003,\n+  BRIG_KIND_OPERAND_CONSTANT_BYTES = 0x3004,\n+  BRIG_KIND_OPERAND_RESERVED = 0x3005,\n+  BRIG_KIND_OPERAND_CONSTANT_IMAGE = 0x3006,\n+  BRIG_KIND_OPERAND_CONSTANT_OPERAND_LIST = 0x3007,\n+  BRIG_KIND_OPERAND_CONSTANT_SAMPLER = 0x3008,\n+  BRIG_KIND_OPERAND_OPERAND_LIST = 0x3009,\n+  BRIG_KIND_OPERAND_REGISTER = 0x300a,\n+  BRIG_KIND_OPERAND_STRING = 0x300b,\n+  BRIG_KIND_OPERAND_WAVESIZE = 0x300c,\n+  BRIG_KIND_OPERAND_END = 0x300d\n+};\n+\n+typedef uint8_t BrigLinkage8_t;\n+\n+enum BrigLinkage\n+{\n+  BRIG_LINKAGE_NONE = 0,\n+  BRIG_LINKAGE_PROGRAM = 1,\n+  BRIG_LINKAGE_MODULE = 2,\n+  BRIG_LINKAGE_FUNCTION = 3,\n+  BRIG_LINKAGE_ARG = 4\n+};\n+\n+typedef uint8_t BrigMachineModel8_t;\n+\n+enum BrigMachineModel\n+{\n+  BRIG_MACHINE_SMALL = 0,\n+  BRIG_MACHINE_LARGE = 1\n+};\n+\n+typedef uint8_t BrigMemoryModifier8_t;\n+\n+enum BrigMemoryModifierMask\n+{\n+  BRIG_MEMORY_CONST = 1\n+};\n+\n+typedef uint8_t BrigMemoryOrder8_t;\n+\n+enum BrigMemoryOrder\n+{\n+  BRIG_MEMORY_ORDER_NONE = 0,\n+  BRIG_MEMORY_ORDER_RELAXED = 1,\n+  BRIG_MEMORY_ORDER_SC_ACQUIRE = 2,\n+  BRIG_MEMORY_ORDER_SC_RELEASE = 3,\n+  BRIG_MEMORY_ORDER_SC_ACQUIRE_RELEASE = 4\n+};\n+\n+typedef uint8_t BrigMemoryScope8_t;\n+\n+enum BrigMemoryScope\n+{\n+  BRIG_MEMORY_SCOPE_NONE = 0,\n+  BRIG_MEMORY_SCOPE_WORKITEM = 1,\n+  BRIG_MEMORY_SCOPE_WAVEFRONT = 2,\n+  BRIG_MEMORY_SCOPE_WORKGROUP = 3,\n+  BRIG_MEMORY_SCOPE_AGENT = 4,\n+  BRIG_MEMORY_SCOPE_SYSTEM = 5\n+};\n+\n+struct BrigModuleHeader\n+{\n+  char identification[8];\n+  BrigVersion32_t brigMajor;\n+  BrigVersion32_t brigMinor;\n+  uint64_t byteCount;\n+  uint8_t hash[64];\n+  uint32_t reserved;\n+  uint32_t sectionCount;\n+  uint64_t sectionIndex;\n+};\n+\n+typedef uint16_t BrigOpcode16_t;\n+\n+enum BrigOpcode\n+{\n+  BRIG_OPCODE_NOP = 0,\n+  BRIG_OPCODE_ABS = 1,\n+  BRIG_OPCODE_ADD = 2,\n+  BRIG_OPCODE_BORROW = 3,\n+  BRIG_OPCODE_CARRY = 4,\n+  BRIG_OPCODE_CEIL = 5,\n+  BRIG_OPCODE_COPYSIGN = 6,\n+  BRIG_OPCODE_DIV = 7,\n+  BRIG_OPCODE_FLOOR = 8,\n+  BRIG_OPCODE_FMA = 9,\n+  BRIG_OPCODE_FRACT = 10,\n+  BRIG_OPCODE_MAD = 11,\n+  BRIG_OPCODE_MAX = 12,\n+  BRIG_OPCODE_MIN = 13,\n+  BRIG_OPCODE_MUL = 14,\n+  BRIG_OPCODE_MULHI = 15,\n+  BRIG_OPCODE_NEG = 16,\n+  BRIG_OPCODE_REM = 17,\n+  BRIG_OPCODE_RINT = 18,\n+  BRIG_OPCODE_SQRT = 19,\n+  BRIG_OPCODE_SUB = 20,\n+  BRIG_OPCODE_TRUNC = 21,\n+  BRIG_OPCODE_MAD24 = 22,\n+  BRIG_OPCODE_MAD24HI = 23,\n+  BRIG_OPCODE_MUL24 = 24,\n+  BRIG_OPCODE_MUL24HI = 25,\n+  BRIG_OPCODE_SHL = 26,\n+  BRIG_OPCODE_SHR = 27,\n+  BRIG_OPCODE_AND = 28,\n+  BRIG_OPCODE_NOT = 29,\n+  BRIG_OPCODE_OR = 30,\n+  BRIG_OPCODE_POPCOUNT = 31,\n+  BRIG_OPCODE_XOR = 32,\n+  BRIG_OPCODE_BITEXTRACT = 33,\n+  BRIG_OPCODE_BITINSERT = 34,\n+  BRIG_OPCODE_BITMASK = 35,\n+  BRIG_OPCODE_BITREV = 36,\n+  BRIG_OPCODE_BITSELECT = 37,\n+  BRIG_OPCODE_FIRSTBIT = 38,\n+  BRIG_OPCODE_LASTBIT = 39,\n+  BRIG_OPCODE_COMBINE = 40,\n+  BRIG_OPCODE_EXPAND = 41,\n+  BRIG_OPCODE_LDA = 42,\n+  BRIG_OPCODE_MOV = 43,\n+  BRIG_OPCODE_SHUFFLE = 44,\n+  BRIG_OPCODE_UNPACKHI = 45,\n+  BRIG_OPCODE_UNPACKLO = 46,\n+  BRIG_OPCODE_PACK = 47,\n+  BRIG_OPCODE_UNPACK = 48,\n+  BRIG_OPCODE_CMOV = 49,\n+  BRIG_OPCODE_CLASS = 50,\n+  BRIG_OPCODE_NCOS = 51,\n+  BRIG_OPCODE_NEXP2 = 52,\n+  BRIG_OPCODE_NFMA = 53,\n+  BRIG_OPCODE_NLOG2 = 54,\n+  BRIG_OPCODE_NRCP = 55,\n+  BRIG_OPCODE_NRSQRT = 56,\n+  BRIG_OPCODE_NSIN = 57,\n+  BRIG_OPCODE_NSQRT = 58,\n+  BRIG_OPCODE_BITALIGN = 59,\n+  BRIG_OPCODE_BYTEALIGN = 60,\n+  BRIG_OPCODE_PACKCVT = 61,\n+  BRIG_OPCODE_UNPACKCVT = 62,\n+  BRIG_OPCODE_LERP = 63,\n+  BRIG_OPCODE_SAD = 64,\n+  BRIG_OPCODE_SADHI = 65,\n+  BRIG_OPCODE_SEGMENTP = 66,\n+  BRIG_OPCODE_FTOS = 67,\n+  BRIG_OPCODE_STOF = 68,\n+  BRIG_OPCODE_CMP = 69,\n+  BRIG_OPCODE_CVT = 70,\n+  BRIG_OPCODE_LD = 71,\n+  BRIG_OPCODE_ST = 72,\n+  BRIG_OPCODE_ATOMIC = 73,\n+  BRIG_OPCODE_ATOMICNORET = 74,\n+  BRIG_OPCODE_SIGNAL = 75,\n+  BRIG_OPCODE_SIGNALNORET = 76,\n+  BRIG_OPCODE_MEMFENCE = 77,\n+  BRIG_OPCODE_RDIMAGE = 78,\n+  BRIG_OPCODE_LDIMAGE = 79,\n+  BRIG_OPCODE_STIMAGE = 80,\n+  BRIG_OPCODE_IMAGEFENCE = 81,\n+  BRIG_OPCODE_QUERYIMAGE = 82,\n+  BRIG_OPCODE_QUERYSAMPLER = 83,\n+  BRIG_OPCODE_CBR = 84,\n+  BRIG_OPCODE_BR = 85,\n+  BRIG_OPCODE_SBR = 86,\n+  BRIG_OPCODE_BARRIER = 87,\n+  BRIG_OPCODE_WAVEBARRIER = 88,\n+  BRIG_OPCODE_ARRIVEFBAR = 89,\n+  BRIG_OPCODE_INITFBAR = 90,\n+  BRIG_OPCODE_JOINFBAR = 91,\n+  BRIG_OPCODE_LEAVEFBAR = 92,\n+  BRIG_OPCODE_RELEASEFBAR = 93,\n+  BRIG_OPCODE_WAITFBAR = 94,\n+  BRIG_OPCODE_LDF = 95,\n+  BRIG_OPCODE_ACTIVELANECOUNT = 96,\n+  BRIG_OPCODE_ACTIVELANEID = 97,\n+  BRIG_OPCODE_ACTIVELANEMASK = 98,\n+  BRIG_OPCODE_ACTIVELANEPERMUTE = 99,\n+  BRIG_OPCODE_CALL = 100,\n+  BRIG_OPCODE_SCALL = 101,\n+  BRIG_OPCODE_ICALL = 102,\n+  BRIG_OPCODE_RET = 103,\n+  BRIG_OPCODE_ALLOCA = 104,\n+  BRIG_OPCODE_CURRENTWORKGROUPSIZE = 105,\n+  BRIG_OPCODE_CURRENTWORKITEMFLATID = 106,\n+  BRIG_OPCODE_DIM = 107,\n+  BRIG_OPCODE_GRIDGROUPS = 108,\n+  BRIG_OPCODE_GRIDSIZE = 109,\n+  BRIG_OPCODE_PACKETCOMPLETIONSIG = 110,\n+  BRIG_OPCODE_PACKETID = 111,\n+  BRIG_OPCODE_WORKGROUPID = 112,\n+  BRIG_OPCODE_WORKGROUPSIZE = 113,\n+  BRIG_OPCODE_WORKITEMABSID = 114,\n+  BRIG_OPCODE_WORKITEMFLATABSID = 115,\n+  BRIG_OPCODE_WORKITEMFLATID = 116,\n+  BRIG_OPCODE_WORKITEMID = 117,\n+  BRIG_OPCODE_CLEARDETECTEXCEPT = 118,\n+  BRIG_OPCODE_GETDETECTEXCEPT = 119,\n+  BRIG_OPCODE_SETDETECTEXCEPT = 120,\n+  BRIG_OPCODE_ADDQUEUEWRITEINDEX = 121,\n+  BRIG_OPCODE_CASQUEUEWRITEINDEX = 122,\n+  BRIG_OPCODE_LDQUEUEREADINDEX = 123,\n+  BRIG_OPCODE_LDQUEUEWRITEINDEX = 124,\n+  BRIG_OPCODE_STQUEUEREADINDEX = 125,\n+  BRIG_OPCODE_STQUEUEWRITEINDEX = 126,\n+  BRIG_OPCODE_CLOCK = 127,\n+  BRIG_OPCODE_CUID = 128,\n+  BRIG_OPCODE_DEBUGTRAP = 129,\n+  BRIG_OPCODE_GROUPBASEPTR = 130,\n+  BRIG_OPCODE_KERNARGBASEPTR = 131,\n+  BRIG_OPCODE_LANEID = 132,\n+  BRIG_OPCODE_MAXCUID = 133,\n+  BRIG_OPCODE_MAXWAVEID = 134,\n+  BRIG_OPCODE_NULLPTR = 135,\n+  BRIG_OPCODE_WAVEID = 136,\n+  BRIG_OPCODE_FIRST_USER_DEFINED = 32768\n+};\n+\n+typedef uint8_t BrigPack8_t;\n+\n+enum BrigPack\n+{\n+  BRIG_PACK_NONE = 0,\n+  BRIG_PACK_PP = 1,\n+  BRIG_PACK_PS = 2,\n+  BRIG_PACK_SP = 3,\n+  BRIG_PACK_SS = 4,\n+  BRIG_PACK_S = 5,\n+  BRIG_PACK_P = 6,\n+  BRIG_PACK_PPSAT = 7,\n+  BRIG_PACK_PSSAT = 8,\n+  BRIG_PACK_SPSAT = 9,\n+  BRIG_PACK_SSSAT = 10,\n+  BRIG_PACK_SSAT = 11,\n+  BRIG_PACK_PSAT = 12\n+};\n+\n+typedef uint8_t BrigProfile8_t;\n+\n+enum BrigProfile\n+{\n+  BRIG_PROFILE_BASE = 0,\n+  BRIG_PROFILE_FULL = 1\n+};\n+\n+typedef uint16_t BrigRegisterKind16_t;\n+\n+enum BrigRegisterKind\n+{\n+  BRIG_REGISTER_KIND_CONTROL = 0,\n+  BRIG_REGISTER_KIND_SINGLE = 1,\n+  BRIG_REGISTER_KIND_DOUBLE = 2,\n+  BRIG_REGISTER_KIND_QUAD = 3\n+};\n+\n+typedef uint8_t BrigRound8_t;\n+\n+enum BrigRound\n+{\n+  BRIG_ROUND_NONE = 0,\n+  BRIG_ROUND_FLOAT_DEFAULT = 1,\n+  BRIG_ROUND_FLOAT_NEAR_EVEN = 2,\n+  BRIG_ROUND_FLOAT_ZERO = 3,\n+  BRIG_ROUND_FLOAT_PLUS_INFINITY = 4,\n+  BRIG_ROUND_FLOAT_MINUS_INFINITY = 5,\n+  BRIG_ROUND_INTEGER_NEAR_EVEN = 6,\n+  BRIG_ROUND_INTEGER_ZERO = 7,\n+  BRIG_ROUND_INTEGER_PLUS_INFINITY = 8,\n+  BRIG_ROUND_INTEGER_MINUS_INFINITY = 9,\n+  BRIG_ROUND_INTEGER_NEAR_EVEN_SAT = 10,\n+  BRIG_ROUND_INTEGER_ZERO_SAT = 11,\n+  BRIG_ROUND_INTEGER_PLUS_INFINITY_SAT = 12,\n+  BRIG_ROUND_INTEGER_MINUS_INFINITY_SAT = 13,\n+  BRIG_ROUND_INTEGER_SIGNALING_NEAR_EVEN = 14,\n+  BRIG_ROUND_INTEGER_SIGNALING_ZERO = 15,\n+  BRIG_ROUND_INTEGER_SIGNALING_PLUS_INFINITY = 16,\n+  BRIG_ROUND_INTEGER_SIGNALING_MINUS_INFINITY = 17,\n+  BRIG_ROUND_INTEGER_SIGNALING_NEAR_EVEN_SAT = 18,\n+  BRIG_ROUND_INTEGER_SIGNALING_ZERO_SAT = 19,\n+  BRIG_ROUND_INTEGER_SIGNALING_PLUS_INFINITY_SAT = 20,\n+  BRIG_ROUND_INTEGER_SIGNALING_MINUS_INFINITY_SAT = 21\n+};\n+\n+typedef uint8_t BrigSamplerAddressing8_t;\n+\n+enum BrigSamplerAddressing\n+{\n+  BRIG_ADDRESSING_UNDEFINED = 0,\n+  BRIG_ADDRESSING_CLAMP_TO_EDGE = 1,\n+  BRIG_ADDRESSING_CLAMP_TO_BORDER = 2,\n+  BRIG_ADDRESSING_REPEAT = 3,\n+  BRIG_ADDRESSING_MIRRORED_REPEAT = 4,\n+  BRIG_ADDRESSING_FIRST_USER_DEFINED = 128\n+};\n+\n+typedef uint8_t BrigSamplerCoordNormalization8_t;\n+\n+enum BrigSamplerCoordNormalization\n+{\n+  BRIG_COORD_UNNORMALIZED = 0,\n+  BRIG_COORD_NORMALIZED = 1\n+};\n+\n+typedef uint8_t BrigSamplerFilter8_t;\n+\n+enum BrigSamplerFilter\n+{\n+  BRIG_FILTER_NEAREST = 0,\n+  BRIG_FILTER_LINEAR = 1,\n+  BRIG_FILTER_FIRST_USER_DEFINED = 128\n+};\n+\n+typedef uint8_t BrigSamplerQuery8_t;\n+\n+enum BrigSamplerQuery\n+{\n+  BRIG_SAMPLER_QUERY_ADDRESSING = 0,\n+  BRIG_SAMPLER_QUERY_COORD = 1,\n+  BRIG_SAMPLER_QUERY_FILTER = 2\n+};\n+\n+typedef uint32_t BrigSectionIndex32_t;\n+\n+enum BrigSectionIndex\n+{\n+  BRIG_SECTION_INDEX_DATA = 0,\n+  BRIG_SECTION_INDEX_CODE = 1,\n+  BRIG_SECTION_INDEX_OPERAND = 2,\n+  BRIG_SECTION_INDEX_BEGIN_IMPLEMENTATION_DEFINED = 3\n+};\n+\n+struct BrigSectionHeader\n+{\n+  uint64_t byteCount;\n+  uint32_t headerByteCount;\n+  uint32_t nameLength;\n+  uint8_t name[1];\n+};\n+\n+typedef uint8_t BrigSegCvtModifier8_t;\n+\n+enum BrigSegCvtModifierMask\n+{\n+  BRIG_SEG_CVT_NONULL = 1\n+};\n+\n+typedef uint8_t BrigSegment8_t;\n+\n+enum BrigSegment\n+{\n+  BRIG_SEGMENT_NONE = 0,\n+  BRIG_SEGMENT_FLAT = 1,\n+  BRIG_SEGMENT_GLOBAL = 2,\n+  BRIG_SEGMENT_READONLY = 3,\n+  BRIG_SEGMENT_KERNARG = 4,\n+  BRIG_SEGMENT_GROUP = 5,\n+  BRIG_SEGMENT_PRIVATE = 6,\n+  BRIG_SEGMENT_SPILL = 7,\n+  BRIG_SEGMENT_ARG = 8,\n+  BRIG_SEGMENT_FIRST_USER_DEFINED = 128\n+};\n+\n+enum\n+{\n+  BRIG_TYPE_BASE_SIZE = 5,\n+  BRIG_TYPE_PACK_SIZE = 2,\n+  BRIG_TYPE_ARRAY_SIZE = 1,\n+\n+  BRIG_TYPE_BASE_SHIFT = 0,\n+  BRIG_TYPE_PACK_SHIFT = BRIG_TYPE_BASE_SHIFT + BRIG_TYPE_BASE_SIZE,\n+  BRIG_TYPE_ARRAY_SHIFT = BRIG_TYPE_PACK_SHIFT + BRIG_TYPE_PACK_SIZE,\n+\n+  BRIG_TYPE_BASE_MASK = ((1 << BRIG_TYPE_BASE_SIZE) - 1)\n+\t\t\t<< BRIG_TYPE_BASE_SHIFT,\n+  BRIG_TYPE_PACK_MASK = ((1 << BRIG_TYPE_PACK_SIZE) - 1)\n+\t\t\t<< BRIG_TYPE_PACK_SHIFT,\n+  BRIG_TYPE_ARRAY_MASK = ((1 << BRIG_TYPE_ARRAY_SIZE) - 1)\n+\t\t\t << BRIG_TYPE_ARRAY_SHIFT,\n+\n+  BRIG_TYPE_PACK_NONE = 0 << BRIG_TYPE_PACK_SHIFT,\n+  BRIG_TYPE_PACK_32 = 1 << BRIG_TYPE_PACK_SHIFT,\n+  BRIG_TYPE_PACK_64 = 2 << BRIG_TYPE_PACK_SHIFT,\n+  BRIG_TYPE_PACK_128 = 3 << BRIG_TYPE_PACK_SHIFT,\n+\n+  BRIG_TYPE_ARRAY = 1 << BRIG_TYPE_ARRAY_SHIFT\n+};\n+\n+typedef uint16_t BrigType16_t;\n+\n+enum BrigType\n+{\n+  BRIG_TYPE_NONE = 0,\n+\n+  BRIG_TYPE_U8 = 1,\n+  BRIG_TYPE_U16 = 2,\n+  BRIG_TYPE_U32 = 3,\n+  BRIG_TYPE_U64 = 4,\n+\n+  BRIG_TYPE_S8 = 5,\n+  BRIG_TYPE_S16 = 6,\n+  BRIG_TYPE_S32 = 7,\n+  BRIG_TYPE_S64 = 8,\n+\n+  BRIG_TYPE_F16 = 9,\n+  BRIG_TYPE_F32 = 10,\n+  BRIG_TYPE_F64 = 11,\n+\n+  BRIG_TYPE_B1 = 12,\n+  BRIG_TYPE_B8 = 13,\n+  BRIG_TYPE_B16 = 14,\n+  BRIG_TYPE_B32 = 15,\n+  BRIG_TYPE_B64 = 16,\n+  BRIG_TYPE_B128 = 17,\n+\n+  BRIG_TYPE_SAMP = 18,\n+  BRIG_TYPE_ROIMG = 19,\n+  BRIG_TYPE_WOIMG = 20,\n+  BRIG_TYPE_RWIMG = 21,\n+\n+  BRIG_TYPE_SIG32 = 22,\n+  BRIG_TYPE_SIG64 = 23,\n+\n+  BRIG_TYPE_U8X4 = BRIG_TYPE_U8 | BRIG_TYPE_PACK_32,\n+  BRIG_TYPE_U8X8 = BRIG_TYPE_U8 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_U8X16 = BRIG_TYPE_U8 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_U16X2 = BRIG_TYPE_U16 | BRIG_TYPE_PACK_32,\n+  BRIG_TYPE_U16X4 = BRIG_TYPE_U16 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_U16X8 = BRIG_TYPE_U16 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_U32X2 = BRIG_TYPE_U32 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_U32X4 = BRIG_TYPE_U32 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_U64X2 = BRIG_TYPE_U64 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_S8X4 = BRIG_TYPE_S8 | BRIG_TYPE_PACK_32,\n+  BRIG_TYPE_S8X8 = BRIG_TYPE_S8 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_S8X16 = BRIG_TYPE_S8 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_S16X2 = BRIG_TYPE_S16 | BRIG_TYPE_PACK_32,\n+  BRIG_TYPE_S16X4 = BRIG_TYPE_S16 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_S16X8 = BRIG_TYPE_S16 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_S32X2 = BRIG_TYPE_S32 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_S32X4 = BRIG_TYPE_S32 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_S64X2 = BRIG_TYPE_S64 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_F16X2 = BRIG_TYPE_F16 | BRIG_TYPE_PACK_32,\n+  BRIG_TYPE_F16X4 = BRIG_TYPE_F16 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_F16X8 = BRIG_TYPE_F16 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_F32X2 = BRIG_TYPE_F32 | BRIG_TYPE_PACK_64,\n+  BRIG_TYPE_F32X4 = BRIG_TYPE_F32 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_F64X2 = BRIG_TYPE_F64 | BRIG_TYPE_PACK_128,\n+\n+  BRIG_TYPE_U8_ARRAY = BRIG_TYPE_U8 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U16_ARRAY = BRIG_TYPE_U16 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U32_ARRAY = BRIG_TYPE_U32 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U64_ARRAY = BRIG_TYPE_U64 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_S8_ARRAY = BRIG_TYPE_S8 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S16_ARRAY = BRIG_TYPE_S16 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S32_ARRAY = BRIG_TYPE_S32 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S64_ARRAY = BRIG_TYPE_S64 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_F16_ARRAY = BRIG_TYPE_F16 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_F32_ARRAY = BRIG_TYPE_F32 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_F64_ARRAY = BRIG_TYPE_F64 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_B8_ARRAY = BRIG_TYPE_B8 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_B16_ARRAY = BRIG_TYPE_B16 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_B32_ARRAY = BRIG_TYPE_B32 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_B64_ARRAY = BRIG_TYPE_B64 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_B128_ARRAY = BRIG_TYPE_B128 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_SAMP_ARRAY = BRIG_TYPE_SAMP | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_ROIMG_ARRAY = BRIG_TYPE_ROIMG | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_WOIMG_ARRAY = BRIG_TYPE_WOIMG | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_RWIMG_ARRAY = BRIG_TYPE_RWIMG | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_SIG32_ARRAY = BRIG_TYPE_SIG32 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_SIG64_ARRAY = BRIG_TYPE_SIG64 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_U8X4_ARRAY = BRIG_TYPE_U8X4 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U8X8_ARRAY = BRIG_TYPE_U8X8 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U8X16_ARRAY = BRIG_TYPE_U8X16 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_U16X2_ARRAY = BRIG_TYPE_U16X2 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U16X4_ARRAY = BRIG_TYPE_U16X4 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U16X8_ARRAY = BRIG_TYPE_U16X8 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_U32X2_ARRAY = BRIG_TYPE_U32X2 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_U32X4_ARRAY = BRIG_TYPE_U32X4 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_U64X2_ARRAY = BRIG_TYPE_U64X2 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_S8X4_ARRAY = BRIG_TYPE_S8X4 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S8X8_ARRAY = BRIG_TYPE_S8X8 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S8X16_ARRAY = BRIG_TYPE_S8X16 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_S16X2_ARRAY = BRIG_TYPE_S16X2 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S16X4_ARRAY = BRIG_TYPE_S16X4 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S16X8_ARRAY = BRIG_TYPE_S16X8 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_S32X2_ARRAY = BRIG_TYPE_S32X2 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_S32X4_ARRAY = BRIG_TYPE_S32X4 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_S64X2_ARRAY = BRIG_TYPE_S64X2 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_F16X2_ARRAY = BRIG_TYPE_F16X2 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_F16X4_ARRAY = BRIG_TYPE_F16X4 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_F16X8_ARRAY = BRIG_TYPE_F16X8 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_F32X2_ARRAY = BRIG_TYPE_F32X2 | BRIG_TYPE_ARRAY,\n+  BRIG_TYPE_F32X4_ARRAY = BRIG_TYPE_F32X4 | BRIG_TYPE_ARRAY,\n+\n+  BRIG_TYPE_F64X2_ARRAY = BRIG_TYPE_F64X2 | BRIG_TYPE_ARRAY\n+};\n+\n+struct BrigUInt64\n+{\n+  uint32_t lo;\n+  uint32_t hi;\n+};\n+\n+typedef uint8_t BrigVariableModifier8_t;\n+\n+enum BrigVariableModifierMask\n+{\n+  BRIG_VARIABLE_DEFINITION = 1,\n+  BRIG_VARIABLE_CONST = 2\n+};\n+\n+enum BrigVersion\n+{\n+  BRIG_VERSION_HSAIL_MAJOR = 1,\n+  BRIG_VERSION_HSAIL_MINOR = 0,\n+  BRIG_VERSION_BRIG_MAJOR = 1,\n+  BRIG_VERSION_BRIG_MINOR = 0\n+};\n+\n+typedef uint8_t BrigWidth8_t;\n+\n+enum BrigWidth\n+{\n+  BRIG_WIDTH_NONE = 0,\n+  BRIG_WIDTH_1 = 1,\n+  BRIG_WIDTH_2 = 2,\n+  BRIG_WIDTH_4 = 3,\n+  BRIG_WIDTH_8 = 4,\n+  BRIG_WIDTH_16 = 5,\n+  BRIG_WIDTH_32 = 6,\n+  BRIG_WIDTH_64 = 7,\n+  BRIG_WIDTH_128 = 8,\n+  BRIG_WIDTH_256 = 9,\n+  BRIG_WIDTH_512 = 10,\n+  BRIG_WIDTH_1024 = 11,\n+  BRIG_WIDTH_2048 = 12,\n+  BRIG_WIDTH_4096 = 13,\n+  BRIG_WIDTH_8192 = 14,\n+  BRIG_WIDTH_16384 = 15,\n+  BRIG_WIDTH_32768 = 16,\n+  BRIG_WIDTH_65536 = 17,\n+  BRIG_WIDTH_131072 = 18,\n+  BRIG_WIDTH_262144 = 19,\n+  BRIG_WIDTH_524288 = 20,\n+  BRIG_WIDTH_1048576 = 21,\n+  BRIG_WIDTH_2097152 = 22,\n+  BRIG_WIDTH_4194304 = 23,\n+  BRIG_WIDTH_8388608 = 24,\n+  BRIG_WIDTH_16777216 = 25,\n+  BRIG_WIDTH_33554432 = 26,\n+  BRIG_WIDTH_67108864 = 27,\n+  BRIG_WIDTH_134217728 = 28,\n+  BRIG_WIDTH_268435456 = 29,\n+  BRIG_WIDTH_536870912 = 30,\n+  BRIG_WIDTH_1073741824 = 31,\n+  BRIG_WIDTH_2147483648 = 32,\n+  BRIG_WIDTH_WAVESIZE = 33,\n+  BRIG_WIDTH_ALL = 34\n+};\n+\n+struct BrigData\n+{\n+  uint32_t byteCount;\n+  uint8_t bytes[1];\n+};\n+\n+struct BrigDirectiveArgBlock\n+{\n+  BrigBase base;\n+};\n+\n+struct BrigDirectiveComment\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t name;\n+};\n+\n+struct BrigDirectiveControl\n+{\n+  BrigBase base;\n+  BrigControlDirective16_t control;\n+  uint16_t reserved;\n+  BrigDataOffsetOperandList32_t operands;\n+};\n+\n+struct BrigDirectiveExecutable\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t name;\n+  uint16_t outArgCount;\n+  uint16_t inArgCount;\n+  BrigCodeOffset32_t firstInArg;\n+  BrigCodeOffset32_t firstCodeBlockEntry;\n+  BrigCodeOffset32_t nextModuleEntry;\n+  BrigExecutableModifier8_t modifier;\n+  BrigLinkage8_t linkage;\n+  uint16_t reserved;\n+};\n+\n+struct BrigDirectiveExtension\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t name;\n+};\n+\n+struct BrigDirectiveFbarrier\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t name;\n+  BrigVariableModifier8_t modifier;\n+  BrigLinkage8_t linkage;\n+  uint16_t reserved;\n+};\n+\n+struct BrigDirectiveLabel\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t name;\n+};\n+\n+struct BrigDirectiveLoc\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t filename;\n+  uint32_t line;\n+  uint32_t column;\n+};\n+\n+struct BrigDirectiveModule\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t name;\n+  BrigVersion32_t hsailMajor;\n+  BrigVersion32_t hsailMinor;\n+  BrigProfile8_t profile;\n+  BrigMachineModel8_t machineModel;\n+  BrigRound8_t defaultFloatRound;\n+  uint8_t reserved;\n+};\n+\n+struct BrigDirectiveNone\n+{\n+  BrigBase base;\n+};\n+\n+struct BrigDirectivePragma\n+{\n+  BrigBase base;\n+  BrigDataOffsetOperandList32_t operands;\n+};\n+\n+struct BrigDirectiveVariable\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t name;\n+  BrigOperandOffset32_t init;\n+  BrigType16_t type;\n+  BrigSegment8_t segment;\n+  BrigAlignment8_t align;\n+  BrigUInt64 dim;\n+  BrigVariableModifier8_t modifier;\n+  BrigLinkage8_t linkage;\n+  BrigAllocation8_t allocation;\n+  uint8_t reserved;\n+};\n+\n+struct BrigInstBase\n+{\n+  BrigBase base;\n+  BrigOpcode16_t opcode;\n+  BrigType16_t type;\n+  BrigDataOffsetOperandList32_t operands;\n+};\n+\n+struct BrigInstAddr\n+{\n+  BrigInstBase base;\n+  BrigSegment8_t segment;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigInstAtomic\n+{\n+  BrigInstBase base;\n+  BrigSegment8_t segment;\n+  BrigMemoryOrder8_t memoryOrder;\n+  BrigMemoryScope8_t memoryScope;\n+  BrigAtomicOperation8_t atomicOperation;\n+  uint8_t equivClass;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigInstBasic\n+{\n+  BrigInstBase base;\n+};\n+\n+struct BrigInstBr\n+{\n+  BrigInstBase base;\n+  BrigWidth8_t width;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigInstCmp\n+{\n+  BrigInstBase base;\n+  BrigType16_t sourceType;\n+  BrigAluModifier8_t modifier;\n+  BrigCompareOperation8_t compare;\n+  BrigPack8_t pack;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigInstCvt\n+{\n+  BrigInstBase base;\n+  BrigType16_t sourceType;\n+  BrigAluModifier8_t modifier;\n+  BrigRound8_t round;\n+};\n+\n+struct BrigInstImage\n+{\n+  BrigInstBase base;\n+  BrigType16_t imageType;\n+  BrigType16_t coordType;\n+  BrigImageGeometry8_t geometry;\n+  uint8_t equivClass;\n+  uint16_t reserved;\n+};\n+\n+struct BrigInstLane\n+{\n+  BrigInstBase base;\n+  BrigType16_t sourceType;\n+  BrigWidth8_t width;\n+  uint8_t reserved;\n+};\n+\n+struct BrigInstMem\n+{\n+  BrigInstBase base;\n+  BrigSegment8_t segment;\n+  BrigAlignment8_t align;\n+  uint8_t equivClass;\n+  BrigWidth8_t width;\n+  BrigMemoryModifier8_t modifier;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigInstMemFence\n+{\n+  BrigInstBase base;\n+  BrigMemoryOrder8_t memoryOrder;\n+  BrigMemoryScope8_t globalSegmentMemoryScope;\n+  BrigMemoryScope8_t groupSegmentMemoryScope;\n+  BrigMemoryScope8_t imageSegmentMemoryScope;\n+};\n+\n+struct BrigInstMod\n+{\n+  BrigInstBase base;\n+  BrigAluModifier8_t modifier;\n+  BrigRound8_t round;\n+  BrigPack8_t pack;\n+  uint8_t reserved;\n+};\n+\n+struct BrigInstQueryImage\n+{\n+  BrigInstBase base;\n+  BrigType16_t imageType;\n+  BrigImageGeometry8_t geometry;\n+  BrigImageQuery8_t query;\n+};\n+\n+struct BrigInstQuerySampler\n+{\n+  BrigInstBase base;\n+  BrigSamplerQuery8_t query;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigInstQueue\n+{\n+  BrigInstBase base;\n+  BrigSegment8_t segment;\n+  BrigMemoryOrder8_t memoryOrder;\n+  uint16_t reserved;\n+};\n+\n+struct BrigInstSeg\n+{\n+  BrigInstBase base;\n+  BrigSegment8_t segment;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigInstSegCvt\n+{\n+  BrigInstBase base;\n+  BrigType16_t sourceType;\n+  BrigSegment8_t segment;\n+  BrigSegCvtModifier8_t modifier;\n+};\n+\n+struct BrigInstSignal\n+{\n+  BrigInstBase base;\n+  BrigType16_t signalType;\n+  BrigMemoryOrder8_t memoryOrder;\n+  BrigAtomicOperation8_t signalOperation;\n+};\n+\n+struct BrigInstSourceType\n+{\n+  BrigInstBase base;\n+  BrigType16_t sourceType;\n+  uint16_t reserved;\n+};\n+\n+struct BrigOperandAddress\n+{\n+  BrigBase base;\n+  BrigCodeOffset32_t symbol;\n+  BrigOperandOffset32_t reg;\n+  BrigUInt64 offset;\n+};\n+\n+struct BrigOperandAlign\n+{\n+  BrigBase base;\n+  BrigAlignment8_t align;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigOperandCodeList\n+{\n+  BrigBase base;\n+  BrigDataOffsetCodeList32_t elements;\n+};\n+\n+struct BrigOperandCodeRef\n+{\n+  BrigBase base;\n+  BrigCodeOffset32_t ref;\n+};\n+\n+struct BrigOperandConstantBytes\n+{\n+  BrigBase base;\n+  BrigType16_t type;\n+  uint16_t reserved;\n+  BrigDataOffsetString32_t bytes;\n+};\n+\n+struct BrigOperandConstantImage\n+{\n+  BrigBase base;\n+  BrigType16_t type;\n+  BrigImageGeometry8_t geometry;\n+  BrigImageChannelOrder8_t channelOrder;\n+  BrigImageChannelType8_t channelType;\n+  uint8_t reserved[3];\n+  BrigUInt64 width;\n+  BrigUInt64 height;\n+  BrigUInt64 depth;\n+  BrigUInt64 array;\n+};\n+\n+struct BrigOperandConstantOperandList\n+{\n+  BrigBase base;\n+  BrigType16_t type;\n+  uint16_t reserved;\n+  BrigDataOffsetOperandList32_t elements;\n+};\n+\n+struct BrigOperandConstantSampler\n+{\n+  BrigBase base;\n+  BrigType16_t type;\n+  BrigSamplerCoordNormalization8_t coord;\n+  BrigSamplerFilter8_t filter;\n+  BrigSamplerAddressing8_t addressing;\n+  uint8_t reserved[3];\n+};\n+\n+struct BrigOperandOperandList\n+{\n+  BrigBase base;\n+  BrigDataOffsetOperandList32_t elements;\n+};\n+\n+struct BrigOperandRegister\n+{\n+  BrigBase base;\n+  BrigRegisterKind16_t regKind;\n+  uint16_t regNum;\n+};\n+\n+struct BrigOperandString\n+{\n+  BrigBase base;\n+  BrigDataOffsetString32_t string;\n+};\n+\n+struct BrigOperandWavesize\n+{\n+  BrigBase base;\n+};\n+\n+#endif /* HSA_BRIG_FORMAT_H */"}, {"sha": "cfbac581a30b3d1f6632f99bd49455250ce26029", "filename": "gcc/hsa-brig.c", "status": "added", "additions": 2560, "deletions": 0, "changes": 2560, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-brig.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-brig.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa-brig.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,2560 @@\n+/* Producing binary form of HSA BRIG from our internal representation.\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+   Contributed by Martin Jambor <mjambor@suse.cz> and\n+   Martin Liska <mliska@suse.cz>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"target.h\"\n+#include \"tm_p.h\"\n+#include \"is-a.h\"\n+#include \"vec.h\"\n+#include \"hash-table.h\"\n+#include \"hash-map.h\"\n+#include \"tree.h\"\n+#include \"tree-iterator.h\"\n+#include \"stor-layout.h\"\n+#include \"output.h\"\n+#include \"cfg.h\"\n+#include \"function.h\"\n+#include \"fold-const.h\"\n+#include \"stringpool.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"diagnostic-core.h\"\n+#include \"cgraph.h\"\n+#include \"dumpfile.h\"\n+#include \"print-tree.h\"\n+#include \"symbol-summary.h\"\n+#include \"hsa.h\"\n+#include \"gomp-constants.h\"\n+\n+/* Convert VAL to little endian form, if necessary.  */\n+\n+static uint16_t\n+lendian16 (uint16_t val)\n+{\n+#if GCC_VERSION >= 4006\n+#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__\n+  return val;\n+#elif __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__\n+  return __builtin_bswap16 (val);\n+#else   /* __ORDER_PDP_ENDIAN__ */\n+  return val;\n+#endif\n+#else\n+// provide a safe slower default, with shifts and masking\n+#ifndef WORDS_BIGENDIAN\n+  return val;\n+#else\n+  return (val >> 8) | (val << 8);\n+#endif\n+#endif\n+}\n+\n+/* Convert VAL to little endian form, if necessary.  */\n+\n+static uint32_t\n+lendian32 (uint32_t val)\n+{\n+#if GCC_VERSION >= 4006\n+#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__\n+  return val;\n+#elif __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__\n+  return __builtin_bswap32 (val);\n+#else  /* __ORDER_PDP_ENDIAN__ */\n+  return (val >> 16) | (val << 16);\n+#endif\n+#else\n+// provide a safe slower default, with shifts and masking\n+#ifndef WORDS_BIGENDIAN\n+  return val;\n+#else\n+  val = ((val & 0xff00ff00) >> 8) | ((val & 0xff00ff) << 8);\n+  return (val >> 16) | (val << 16);\n+#endif\n+#endif\n+}\n+\n+/* Convert VAL to little endian form, if necessary.  */\n+\n+static uint64_t\n+lendian64 (uint64_t val)\n+{\n+#if GCC_VERSION >= 4006\n+#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__\n+  return val;\n+#elif __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__\n+  return __builtin_bswap64 (val);\n+#else  /* __ORDER_PDP_ENDIAN__ */\n+  return (((val & 0xffffll) << 48)\n+\t  | ((val & 0xffff0000ll) << 16)\n+\t  | ((val & 0xffff00000000ll) >> 16)\n+\t  | ((val & 0xffff000000000000ll) >> 48));\n+#endif\n+#else\n+// provide a safe slower default, with shifts and masking\n+#ifndef WORDS_BIGENDIAN\n+  return val;\n+#else\n+  val = (((val & 0xff00ff00ff00ff00ll) >> 8)\n+\t | ((val & 0x00ff00ff00ff00ffll) << 8));\n+  val = ((( val & 0xffff0000ffff0000ll) >> 16)\n+\t | (( val & 0x0000ffff0000ffffll) << 16));\n+  return (val >> 32) | (val << 32);\n+#endif\n+#endif\n+}\n+\n+#define BRIG_ELF_SECTION_NAME \".brig\"\n+#define BRIG_LABEL_STRING \"hsa_brig\"\n+#define BRIG_SECTION_DATA_NAME    \"hsa_data\"\n+#define BRIG_SECTION_CODE_NAME    \"hsa_code\"\n+#define BRIG_SECTION_OPERAND_NAME \"hsa_operand\"\n+\n+#define BRIG_CHUNK_MAX_SIZE (64 * 1024)\n+\n+/* Required HSA section alignment.  */\n+\n+#define HSA_SECTION_ALIGNMENT 16\n+\n+/* Chunks of BRIG binary data.  */\n+\n+struct hsa_brig_data_chunk\n+{\n+  /* Size of the data already stored into a chunk.  */\n+  unsigned size;\n+\n+  /* Pointer to the data.  */\n+  char *data;\n+};\n+\n+/* Structure representing a BRIG section, holding and writing its data.  */\n+\n+class hsa_brig_section\n+{\n+public:\n+  /* Section name that will be output to the BRIG.  */\n+  const char *section_name;\n+  /* Size in bytes of all data stored in the section.  */\n+  unsigned total_size;\n+  /* The size of the header of the section including padding.  */\n+  unsigned header_byte_count;\n+  /* The size of the header of the section without any padding.  */\n+  unsigned header_byte_delta;\n+\n+  /* Buffers of binary data, each containing BRIG_CHUNK_MAX_SIZE bytes.  */\n+  vec <struct hsa_brig_data_chunk> chunks;\n+\n+  /* More convenient access to the last chunk from the vector above.  */\n+  struct hsa_brig_data_chunk *cur_chunk;\n+\n+  void allocate_new_chunk ();\n+  void init (const char *name);\n+  void release ();\n+  void output ();\n+  unsigned add (const void *data, unsigned len);\n+  void round_size_up (int factor);\n+  void *get_ptr_by_offset (unsigned int offset);\n+};\n+\n+static struct hsa_brig_section brig_data, brig_code, brig_operand;\n+static uint32_t brig_insn_count;\n+static bool brig_initialized = false;\n+\n+/* Mapping between emitted HSA functions and their offset in code segment.  */\n+static hash_map<tree, BrigCodeOffset32_t> *function_offsets;\n+\n+/* Hash map of emitted function declarations.  */\n+static hash_map <tree, BrigDirectiveExecutable *> *emitted_declarations;\n+\n+/* Hash table of emitted internal function declaration offsets.  */\n+hash_table <hsa_internal_fn_hasher> *hsa_emitted_internal_decls;\n+\n+/* List of sbr instructions.  */\n+static vec <hsa_insn_sbr *> *switch_instructions;\n+\n+struct function_linkage_pair\n+{\n+  function_linkage_pair (tree decl, unsigned int off)\n+    : function_decl (decl), offset (off) {}\n+\n+  /* Declaration of called function.  */\n+  tree function_decl;\n+\n+  /* Offset in operand section.  */\n+  unsigned int offset;\n+};\n+\n+/* Vector of function calls where we need to resolve function offsets.  */\n+static auto_vec <function_linkage_pair> function_call_linkage;\n+\n+/* Add a new chunk, allocate data for it and initialize it.  */\n+\n+void\n+hsa_brig_section::allocate_new_chunk ()\n+{\n+  struct hsa_brig_data_chunk new_chunk;\n+\n+  new_chunk.data = XCNEWVEC (char, BRIG_CHUNK_MAX_SIZE);\n+  new_chunk.size = 0;\n+  cur_chunk = chunks.safe_push (new_chunk);\n+}\n+\n+/* Initialize the brig section.  */\n+\n+void\n+hsa_brig_section::init (const char *name)\n+{\n+  section_name = name;\n+  /* While the following computation is basically wrong, because the intent\n+     certainly wasn't to have the first character of name and padding, which\n+     are a part of sizeof (BrigSectionHeader), included in the first addend,\n+     this is what the disassembler expects.  */\n+  total_size = sizeof (BrigSectionHeader) + strlen (section_name);\n+  chunks.create (1);\n+  allocate_new_chunk ();\n+  header_byte_delta = total_size;\n+  round_size_up (4);\n+  header_byte_count = total_size;\n+}\n+\n+/* Free all data in the section.  */\n+\n+void\n+hsa_brig_section::release ()\n+{\n+  for (unsigned i = 0; i < chunks.length (); i++)\n+    free (chunks[i].data);\n+  chunks.release ();\n+  cur_chunk = NULL;\n+}\n+\n+/* Write the section to the output file to a section with the name given at\n+   initialization.  Switches the output section and does not restore it.  */\n+\n+void\n+hsa_brig_section::output ()\n+{\n+  struct BrigSectionHeader section_header;\n+  char padding[8];\n+\n+  section_header.byteCount = lendian64 (total_size);\n+  section_header.headerByteCount = lendian32 (header_byte_count);\n+  section_header.nameLength = lendian32 (strlen (section_name));\n+  assemble_string ((const char *) &section_header, 16);\n+  assemble_string (section_name, (section_header.nameLength));\n+  memset (&padding, 0, sizeof (padding));\n+  /* This is also a consequence of the wrong header size computation described\n+     in a comment in hsa_brig_section::init.  */\n+  assemble_string (padding, 8);\n+  for (unsigned i = 0; i < chunks.length (); i++)\n+    assemble_string (chunks[i].data, chunks[i].size);\n+}\n+\n+/* Add to the stream LEN bytes of opaque binary DATA.  Return the offset at\n+   which it was stored.  */\n+\n+unsigned\n+hsa_brig_section::add (const void *data, unsigned len)\n+{\n+  unsigned offset = total_size;\n+\n+  gcc_assert (len <= BRIG_CHUNK_MAX_SIZE);\n+  if (cur_chunk->size > (BRIG_CHUNK_MAX_SIZE - len))\n+    allocate_new_chunk ();\n+\n+  memcpy (cur_chunk->data + cur_chunk->size, data, len);\n+  cur_chunk->size += len;\n+  total_size += len;\n+\n+  return offset;\n+}\n+\n+/* Add padding to section so that its size is divisible by FACTOR.  */\n+\n+void\n+hsa_brig_section::round_size_up (int factor)\n+{\n+  unsigned padding, res = total_size % factor;\n+\n+  if (res == 0)\n+    return;\n+\n+  padding = factor - res;\n+  total_size += padding;\n+  if (cur_chunk->size > (BRIG_CHUNK_MAX_SIZE - padding))\n+    {\n+      padding -= BRIG_CHUNK_MAX_SIZE - cur_chunk->size;\n+      cur_chunk->size = BRIG_CHUNK_MAX_SIZE;\n+      allocate_new_chunk ();\n+    }\n+\n+  cur_chunk->size += padding;\n+}\n+\n+/* Return pointer to data by global OFFSET in the section.  */\n+\n+void *\n+hsa_brig_section::get_ptr_by_offset (unsigned int offset)\n+{\n+  gcc_assert (offset < total_size);\n+  offset -= header_byte_delta;\n+\n+  unsigned i;\n+  for (i = 0; offset >= chunks[i].size; i++)\n+    offset -= chunks[i].size;\n+\n+  return chunks[i].data + offset;\n+}\n+\n+/* BRIG string data hashing.  */\n+\n+struct brig_string_slot\n+{\n+  const char *s;\n+  char prefix;\n+  int len;\n+  uint32_t offset;\n+};\n+\n+/* Hash table helpers.  */\n+\n+struct brig_string_slot_hasher : pointer_hash <brig_string_slot>\n+{\n+  static inline hashval_t hash (const value_type);\n+  static inline bool equal (const value_type, const compare_type);\n+  static inline void remove (value_type);\n+};\n+\n+/* Returns a hash code for DS.  Adapted from libiberty's htab_hash_string\n+   to support strings that may not end in '\\0'.  */\n+\n+inline hashval_t\n+brig_string_slot_hasher::hash (const value_type ds)\n+{\n+  hashval_t r = ds->len;\n+  int i;\n+\n+  for (i = 0; i < ds->len; i++)\n+     r = r * 67 + (unsigned) ds->s[i] - 113;\n+  r = r * 67 + (unsigned) ds->prefix - 113;\n+  return r;\n+}\n+\n+/* Returns nonzero if DS1 and DS2 are equal.  */\n+\n+inline bool\n+brig_string_slot_hasher::equal (const value_type ds1, const compare_type ds2)\n+{\n+  if (ds1->len == ds2->len)\n+    return ds1->prefix == ds2->prefix\n+      && memcmp (ds1->s, ds2->s, ds1->len) == 0;\n+\n+  return 0;\n+}\n+\n+/* Deallocate memory for DS upon its removal.  */\n+\n+inline void\n+brig_string_slot_hasher::remove (value_type ds)\n+{\n+  free (const_cast<char *> (ds->s));\n+  free (ds);\n+}\n+\n+/* Hash for strings we output in order not to duplicate them needlessly.  */\n+\n+static hash_table<brig_string_slot_hasher> *brig_string_htab;\n+\n+/* Emit a null terminated string STR to the data section and return its\n+   offset in it.  If PREFIX is non-zero, output it just before STR too.\n+   Sanitize the string if SANITIZE option is set to true.  */\n+\n+static unsigned\n+brig_emit_string (const char *str, char prefix = 0, bool sanitize = true)\n+{\n+  unsigned slen = strlen (str);\n+  unsigned offset, len = slen + (prefix ? 1 : 0);\n+  uint32_t hdr_len = lendian32 (len);\n+  brig_string_slot s_slot;\n+  brig_string_slot **slot;\n+  char *str2;\n+\n+  str2 = xstrdup (str);\n+\n+  if (sanitize)\n+    hsa_sanitize_name (str2);\n+  s_slot.s = str2;\n+  s_slot.len = slen;\n+  s_slot.prefix = prefix;\n+  s_slot.offset = 0;\n+\n+  slot = brig_string_htab->find_slot (&s_slot, INSERT);\n+  if (*slot == NULL)\n+    {\n+      brig_string_slot *new_slot = XCNEW (brig_string_slot);\n+\n+      /* In theory we should fill in BrigData but that would mean copying\n+\t the string to a buffer for no reason, so we just emulate it.  */\n+      offset = brig_data.add (&hdr_len, sizeof (hdr_len));\n+      if (prefix)\n+\tbrig_data.add (&prefix, 1);\n+\n+      brig_data.add (str2, slen);\n+      brig_data.round_size_up (4);\n+\n+      /* TODO: could use the string we just copied into\n+\t brig_string->cur_chunk */\n+      new_slot->s = str2;\n+      new_slot->len = slen;\n+      new_slot->prefix = prefix;\n+      new_slot->offset = offset;\n+      *slot = new_slot;\n+    }\n+  else\n+    {\n+      offset = (*slot)->offset;\n+      free (str2);\n+    }\n+\n+  return offset;\n+}\n+\n+/* Linked list of queued operands.  */\n+\n+static struct operand_queue\n+{\n+  /* First from the chain of queued operands.  */\n+  hsa_op_base *first_op, *last_op;\n+\n+  /* The offset at which the next operand will be enqueued.  */\n+  unsigned projected_size;\n+\n+} op_queue;\n+\n+/* Unless already initialized, initialize infrastructure to produce BRIG.  */\n+\n+static void\n+brig_init (void)\n+{\n+  brig_insn_count = 0;\n+\n+  if (brig_initialized)\n+    return;\n+\n+  brig_string_htab = new hash_table<brig_string_slot_hasher> (37);\n+  brig_data.init (BRIG_SECTION_DATA_NAME);\n+  brig_code.init (BRIG_SECTION_CODE_NAME);\n+  brig_operand.init (BRIG_SECTION_OPERAND_NAME);\n+  brig_initialized = true;\n+\n+  struct BrigDirectiveModule moddir;\n+  memset (&moddir, 0, sizeof (moddir));\n+  moddir.base.byteCount = lendian16 (sizeof (moddir));\n+\n+  char *modname;\n+  if (main_input_filename && *main_input_filename != '\\0')\n+    {\n+      const char *part = strrchr (main_input_filename, '/');\n+      if (!part)\n+\tpart = main_input_filename;\n+      else\n+\tpart++;\n+      modname = concat (\"&__hsa_module_\", part, NULL);\n+      char *extension = strchr (modname, '.');\n+      if (extension)\n+\t*extension = '\\0';\n+\n+      /* As in LTO mode, we have to emit a different module names.  */\n+      if (flag_ltrans)\n+\t{\n+\t  part = strrchr (asm_file_name, '/');\n+\t  if (!part)\n+\t    part = asm_file_name;\n+\t  else\n+\t    part++;\n+\t  char *modname2;\n+\t  asprintf (&modname2, \"%s_%s\", modname, part);\n+\t  free (modname);\n+\t  modname = modname2;\n+\t}\n+\n+      hsa_sanitize_name (modname);\n+      moddir.name = brig_emit_string (modname);\n+      free (modname);\n+    }\n+  else\n+    moddir.name = brig_emit_string (\"__hsa_module_unnamed\", '&');\n+  moddir.base.kind = lendian16 (BRIG_KIND_DIRECTIVE_MODULE);\n+  moddir.hsailMajor = lendian32 (BRIG_VERSION_HSAIL_MAJOR);\n+  moddir.hsailMinor = lendian32 (BRIG_VERSION_HSAIL_MINOR);\n+  moddir.profile = hsa_full_profile_p () ? BRIG_PROFILE_FULL: BRIG_PROFILE_BASE;\n+  if (hsa_machine_large_p ())\n+    moddir.machineModel = BRIG_MACHINE_LARGE;\n+  else\n+    moddir.machineModel = BRIG_MACHINE_SMALL;\n+  moddir.defaultFloatRound = BRIG_ROUND_FLOAT_DEFAULT;\n+  brig_code.add (&moddir, sizeof (moddir));\n+}\n+\n+/* Free all BRIG data.  */\n+\n+static void\n+brig_release_data (void)\n+{\n+  delete brig_string_htab;\n+  brig_data.release ();\n+  brig_code.release ();\n+  brig_operand.release ();\n+\n+  brig_initialized = 0;\n+}\n+\n+/* Enqueue operation OP.  Return the offset at which it will be stored.  */\n+\n+static unsigned int\n+enqueue_op (hsa_op_base *op)\n+{\n+  unsigned ret;\n+\n+  if (op->m_brig_op_offset)\n+    return op->m_brig_op_offset;\n+\n+  ret = op_queue.projected_size;\n+  op->m_brig_op_offset = op_queue.projected_size;\n+\n+  if (!op_queue.first_op)\n+    op_queue.first_op = op;\n+  else\n+    op_queue.last_op->m_next = op;\n+  op_queue.last_op = op;\n+\n+  if (is_a <hsa_op_immed *> (op))\n+    op_queue.projected_size += sizeof (struct BrigOperandConstantBytes);\n+  else if (is_a <hsa_op_reg *> (op))\n+    op_queue.projected_size += sizeof (struct BrigOperandRegister);\n+  else if (is_a <hsa_op_address *> (op))\n+    op_queue.projected_size += sizeof (struct BrigOperandAddress);\n+  else if (is_a <hsa_op_code_ref *> (op))\n+    op_queue.projected_size += sizeof (struct BrigOperandCodeRef);\n+  else if (is_a <hsa_op_code_list *> (op))\n+    op_queue.projected_size += sizeof (struct BrigOperandCodeList);\n+  else if (is_a <hsa_op_operand_list *> (op))\n+    op_queue.projected_size += sizeof (struct BrigOperandOperandList);\n+  else\n+    gcc_unreachable ();\n+  return ret;\n+}\n+\n+\n+/* Emit directive describing a symbol if it has not been emitted already.\n+   Return the offset of the directive.  */\n+\n+static unsigned\n+emit_directive_variable (struct hsa_symbol *symbol)\n+{\n+  struct BrigDirectiveVariable dirvar;\n+  unsigned name_offset;\n+  static unsigned res_name_offset;\n+\n+  if (symbol->m_directive_offset)\n+    return symbol->m_directive_offset;\n+\n+  memset (&dirvar, 0, sizeof (dirvar));\n+  dirvar.base.byteCount = lendian16 (sizeof (dirvar));\n+  dirvar.base.kind = lendian16 (BRIG_KIND_DIRECTIVE_VARIABLE);\n+  dirvar.allocation = symbol->m_allocation;\n+\n+  char prefix = symbol->m_global_scope_p ? '&' : '%';\n+\n+  if (symbol->m_decl && TREE_CODE (symbol->m_decl) == RESULT_DECL)\n+    {\n+      if (res_name_offset == 0)\n+\tres_name_offset = brig_emit_string (symbol->m_name, '%');\n+      name_offset = res_name_offset;\n+    }\n+  else if (symbol->m_name)\n+    name_offset = brig_emit_string (symbol->m_name, prefix);\n+  else\n+    {\n+      char buf[64];\n+      snprintf (buf, 64, \"__%s_%i\", hsa_seg_name (symbol->m_segment),\n+\t\tsymbol->m_name_number);\n+      name_offset = brig_emit_string (buf, prefix);\n+    }\n+\n+  dirvar.name = lendian32 (name_offset);\n+  dirvar.init = 0;\n+  dirvar.type = lendian16 (symbol->m_type);\n+  dirvar.segment = symbol->m_segment;\n+  /* TODO: Once we are able to access global variables, we must copy their\n+     alignment.  */\n+  dirvar.align = MAX (hsa_natural_alignment (dirvar.type),\n+\t\t      (BrigAlignment8_t) BRIG_ALIGNMENT_4);\n+  dirvar.linkage = symbol->m_linkage;\n+  dirvar.dim.lo = symbol->m_dim;\n+  dirvar.dim.hi = symbol->m_dim >> 32;\n+\n+  /* Global variables are just declared and linked via HSA runtime.  */\n+  if (symbol->m_linkage != BRIG_ALLOCATION_PROGRAM)\n+    dirvar.modifier |= BRIG_VARIABLE_DEFINITION;\n+  dirvar.reserved = 0;\n+\n+  if (symbol->m_cst_value)\n+    {\n+      dirvar.modifier |= BRIG_VARIABLE_CONST;\n+      dirvar.init = lendian32 (enqueue_op (symbol->m_cst_value));\n+    }\n+\n+  symbol->m_directive_offset = brig_code.add (&dirvar, sizeof (dirvar));\n+  return symbol->m_directive_offset;\n+}\n+\n+/* Emit directives describing either a function declaration or\n+   definition F.  */\n+\n+static BrigDirectiveExecutable *\n+emit_function_directives (hsa_function_representation *f, bool is_declaration)\n+{\n+  struct BrigDirectiveExecutable fndir;\n+  unsigned name_offset, inarg_off, scoped_off, next_toplev_off;\n+  int count = 0;\n+  BrigDirectiveExecutable *ptr_to_fndir;\n+  hsa_symbol *sym;\n+\n+  if (!f->m_declaration_p)\n+    for (int i = 0; f->m_global_symbols.iterate (i, &sym); i++)\n+      {\n+\temit_directive_variable (sym);\n+\tbrig_insn_count++;\n+      }\n+\n+  name_offset = brig_emit_string (f->m_name, '&');\n+  inarg_off = brig_code.total_size + sizeof (fndir)\n+    + (f->m_output_arg ? sizeof (struct BrigDirectiveVariable) : 0);\n+  scoped_off = inarg_off\n+    + f->m_input_args.length () * sizeof (struct BrigDirectiveVariable);\n+\n+  if (!f->m_declaration_p)\n+    {\n+      count += f->m_spill_symbols.length ();\n+      count += f->m_private_variables.length ();\n+    }\n+\n+  next_toplev_off = scoped_off + count * sizeof (struct BrigDirectiveVariable);\n+\n+  memset (&fndir, 0, sizeof (fndir));\n+  fndir.base.byteCount = lendian16 (sizeof (fndir));\n+  fndir.base.kind = lendian16 (f->m_kern_p ? BRIG_KIND_DIRECTIVE_KERNEL\n+\t\t\t       : BRIG_KIND_DIRECTIVE_FUNCTION);\n+  fndir.name = lendian32 (name_offset);\n+  fndir.inArgCount = lendian16 (f->m_input_args.length ());\n+  fndir.outArgCount = lendian16 (f->m_output_arg ? 1 : 0);\n+  fndir.firstInArg = lendian32 (inarg_off);\n+  fndir.firstCodeBlockEntry = lendian32 (scoped_off);\n+  fndir.nextModuleEntry = lendian32 (next_toplev_off);\n+  fndir.linkage = f->get_linkage ();\n+  if (!f->m_declaration_p)\n+    fndir.modifier |= BRIG_EXECUTABLE_DEFINITION;\n+  memset (&fndir.reserved, 0, sizeof (fndir.reserved));\n+\n+  /* Once we put a definition of function_offsets, we should not overwrite\n+     it with a declaration of the function.  */\n+  if (f->m_internal_fn == NULL)\n+    {\n+      if (!function_offsets->get (f->m_decl) || !is_declaration)\n+\tfunction_offsets->put (f->m_decl, brig_code.total_size);\n+    }\n+  else\n+    {\n+      /* Internal function.  */\n+      hsa_internal_fn **slot\n+\t= hsa_emitted_internal_decls->find_slot (f->m_internal_fn, INSERT);\n+      hsa_internal_fn *int_fn = new hsa_internal_fn (f->m_internal_fn);\n+      int_fn->m_offset = brig_code.total_size;\n+      *slot = int_fn;\n+    }\n+\n+  brig_code.add (&fndir, sizeof (fndir));\n+  /* terrible hack: we need to set instCount after we emit all\n+     insns, but we need to emit directive in order, and we emit directives\n+     during insn emitting.  So we need to emit the FUNCTION directive\n+     early, then the insns, and then we need to set instCount, so remember\n+     a pointer to it, in some horrible way.  cur_chunk.data+size points\n+     directly to after fndir here.  */\n+  ptr_to_fndir\n+      = (BrigDirectiveExecutable *)(brig_code.cur_chunk->data\n+\t\t\t\t    + brig_code.cur_chunk->size\n+\t\t\t\t    - sizeof (fndir));\n+\n+  if (f->m_output_arg)\n+    emit_directive_variable (f->m_output_arg);\n+  for (unsigned i = 0; i < f->m_input_args.length (); i++)\n+    emit_directive_variable (f->m_input_args[i]);\n+\n+  if (!f->m_declaration_p)\n+    {\n+      for (int i = 0; f->m_spill_symbols.iterate (i, &sym); i++)\n+\t{\n+\t  emit_directive_variable (sym);\n+\t  brig_insn_count++;\n+\t}\n+      for (unsigned i = 0; i < f->m_private_variables.length (); i++)\n+\t{\n+\t  emit_directive_variable (f->m_private_variables[i]);\n+\t  brig_insn_count++;\n+\t}\n+    }\n+\n+  return ptr_to_fndir;\n+}\n+\n+/* Emit a label directive for the given HBB.  We assume it is about to start on\n+   the current offset in the code section.  */\n+\n+static void\n+emit_bb_label_directive (hsa_bb *hbb)\n+{\n+  struct BrigDirectiveLabel lbldir;\n+\n+  lbldir.base.byteCount = lendian16 (sizeof (lbldir));\n+  lbldir.base.kind = lendian16 (BRIG_KIND_DIRECTIVE_LABEL);\n+  char buf[32];\n+  snprintf (buf, 32, \"BB_%u_%i\", DECL_UID (current_function_decl),\n+\t    hbb->m_index);\n+  lbldir.name = lendian32 (brig_emit_string (buf, '@'));\n+\n+  hbb->m_label_ref.m_directive_offset = brig_code.add (&lbldir,\n+\t\t\t\t\t\t       sizeof (lbldir));\n+  brig_insn_count++;\n+}\n+\n+/* Map a normal HSAIL type to the type of the equivalent BRIG operand\n+   holding such, for constants and registers.  */\n+\n+static BrigType16_t\n+regtype_for_type (BrigType16_t t)\n+{\n+  switch (t)\n+    {\n+    case BRIG_TYPE_B1:\n+      return BRIG_TYPE_B1;\n+\n+    case BRIG_TYPE_U8:\n+    case BRIG_TYPE_U16:\n+    case BRIG_TYPE_U32:\n+    case BRIG_TYPE_S8:\n+    case BRIG_TYPE_S16:\n+    case BRIG_TYPE_S32:\n+    case BRIG_TYPE_B8:\n+    case BRIG_TYPE_B16:\n+    case BRIG_TYPE_B32:\n+    case BRIG_TYPE_F16:\n+    case BRIG_TYPE_F32:\n+    case BRIG_TYPE_U8X4:\n+    case BRIG_TYPE_U16X2:\n+    case BRIG_TYPE_S8X4:\n+    case BRIG_TYPE_S16X2:\n+    case BRIG_TYPE_F16X2:\n+      return BRIG_TYPE_B32;\n+\n+    case BRIG_TYPE_U64:\n+    case BRIG_TYPE_S64:\n+    case BRIG_TYPE_F64:\n+    case BRIG_TYPE_B64:\n+    case BRIG_TYPE_U8X8:\n+    case BRIG_TYPE_U16X4:\n+    case BRIG_TYPE_U32X2:\n+    case BRIG_TYPE_S8X8:\n+    case BRIG_TYPE_S16X4:\n+    case BRIG_TYPE_S32X2:\n+    case BRIG_TYPE_F16X4:\n+    case BRIG_TYPE_F32X2:\n+      return BRIG_TYPE_B64;\n+\n+    case BRIG_TYPE_B128:\n+    case BRIG_TYPE_U8X16:\n+    case BRIG_TYPE_U16X8:\n+    case BRIG_TYPE_U32X4:\n+    case BRIG_TYPE_U64X2:\n+    case BRIG_TYPE_S8X16:\n+    case BRIG_TYPE_S16X8:\n+    case BRIG_TYPE_S32X4:\n+    case BRIG_TYPE_S64X2:\n+    case BRIG_TYPE_F16X8:\n+    case BRIG_TYPE_F32X4:\n+    case BRIG_TYPE_F64X2:\n+      return BRIG_TYPE_B128;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Return the length of the BRIG type TYPE that is going to be streamed out as\n+   an immediate constant (so it must not be B1).  */\n+\n+unsigned\n+hsa_get_imm_brig_type_len (BrigType16_t type)\n+{\n+  BrigType16_t base_type = type & BRIG_TYPE_BASE_MASK;\n+  BrigType16_t pack_type = type & BRIG_TYPE_PACK_MASK;\n+\n+  switch (pack_type)\n+    {\n+    case BRIG_TYPE_PACK_NONE:\n+      break;\n+    case BRIG_TYPE_PACK_32:\n+      return 4;\n+    case BRIG_TYPE_PACK_64:\n+      return 8;\n+    case BRIG_TYPE_PACK_128:\n+      return 16;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  switch (base_type)\n+    {\n+    case BRIG_TYPE_U8:\n+    case BRIG_TYPE_S8:\n+    case BRIG_TYPE_B8:\n+      return 1;\n+    case BRIG_TYPE_U16:\n+    case BRIG_TYPE_S16:\n+    case BRIG_TYPE_F16:\n+    case BRIG_TYPE_B16:\n+      return 2;\n+    case BRIG_TYPE_U32:\n+    case BRIG_TYPE_S32:\n+    case BRIG_TYPE_F32:\n+    case BRIG_TYPE_B32:\n+      return 4;\n+    case BRIG_TYPE_U64:\n+    case BRIG_TYPE_S64:\n+    case BRIG_TYPE_F64:\n+    case BRIG_TYPE_B64:\n+      return 8;\n+    case BRIG_TYPE_B128:\n+      return 16;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Emit one scalar VALUE to the buffer DATA intended for BRIG emission.\n+   If NEED_LEN is not equal to zero, shrink or extend the value\n+   to NEED_LEN bytes.  Return how many bytes were written.  */\n+\n+static int\n+emit_immediate_scalar_to_buffer (tree value, char *data, unsigned need_len)\n+{\n+  union hsa_bytes bytes;\n+\n+  memset (&bytes, 0, sizeof (bytes));\n+  tree type = TREE_TYPE (value);\n+  gcc_checking_assert (TREE_CODE (type) != VECTOR_TYPE);\n+\n+  unsigned data_len = tree_to_uhwi (TYPE_SIZE (type)) / BITS_PER_UNIT;\n+  if (INTEGRAL_TYPE_P (type)\n+      || (POINTER_TYPE_P (type) && TREE_CODE (value) == INTEGER_CST))\n+    switch (data_len)\n+      {\n+      case 1:\n+\tbytes.b8 = (uint8_t) TREE_INT_CST_LOW (value);\n+\tbreak;\n+      case 2:\n+\tbytes.b16 = (uint16_t) TREE_INT_CST_LOW (value);\n+\tbreak;\n+      case 4:\n+\tbytes.b32 = (uint32_t) TREE_INT_CST_LOW (value);\n+\tbreak;\n+      case 8:\n+\tbytes.b64 = (uint64_t) TREE_INT_CST_LOW (value);\n+\tbreak;\n+      default:\n+\tgcc_unreachable ();\n+      }\n+  else if (SCALAR_FLOAT_TYPE_P (type))\n+    {\n+      if (data_len == 2)\n+\t{\n+\t  sorry (\"Support for HSA does not implement immediate 16 bit FPU \"\n+\t\t \"operands\");\n+\t  return 2;\n+\t}\n+      unsigned int_len = GET_MODE_SIZE (TYPE_MODE (type));\n+      /* There are always 32 bits in each long, no matter the size of\n+\t the hosts long.  */\n+      long tmp[6];\n+\n+      real_to_target (tmp, TREE_REAL_CST_PTR (value), TYPE_MODE (type));\n+\n+      if (int_len == 4)\n+\tbytes.b32 = (uint32_t) tmp[0];\n+      else\n+\t{\n+\t  bytes.b64 = (uint64_t)(uint32_t) tmp[1];\n+\t  bytes.b64 <<= 32;\n+\t  bytes.b64 |= (uint32_t) tmp[0];\n+\t}\n+    }\n+  else\n+    gcc_unreachable ();\n+\n+  int len;\n+  if (need_len == 0)\n+    len = data_len;\n+  else\n+    len = need_len;\n+\n+  memcpy (data, &bytes, len);\n+  return len;\n+}\n+\n+void\n+hsa_op_immed::emit_to_buffer (tree value)\n+{\n+  unsigned total_len = m_brig_repr_size;\n+\n+  /* As we can have a constructor with fewer elements, fill the memory\n+     with zeros.  */\n+  m_brig_repr = XCNEWVEC (char, total_len);\n+  char *p = m_brig_repr;\n+\n+  if (TREE_CODE (value) == VECTOR_CST)\n+    {\n+      int i, num = VECTOR_CST_NELTS (value);\n+      for (i = 0; i < num; i++)\n+\t{\n+\t  unsigned actual;\n+\t  actual\n+\t    = emit_immediate_scalar_to_buffer (VECTOR_CST_ELT (value, i), p, 0);\n+\t  total_len -= actual;\n+\t  p += actual;\n+\t}\n+      /* Vectors should have the exact size.  */\n+      gcc_assert (total_len == 0);\n+    }\n+  else if (TREE_CODE (value) == STRING_CST)\n+    memcpy (m_brig_repr, TREE_STRING_POINTER (value),\n+\t    TREE_STRING_LENGTH (value));\n+  else if (TREE_CODE (value) == COMPLEX_CST)\n+    {\n+      gcc_assert (total_len % 2 == 0);\n+      unsigned actual;\n+      actual\n+\t= emit_immediate_scalar_to_buffer (TREE_REALPART (value), p,\n+\t\t\t\t\t   total_len / 2);\n+\n+      gcc_assert (actual == total_len / 2);\n+      p += actual;\n+\n+      actual\n+\t= emit_immediate_scalar_to_buffer (TREE_IMAGPART (value), p,\n+\t\t\t\t\t   total_len / 2);\n+      gcc_assert (actual == total_len / 2);\n+    }\n+  else if (TREE_CODE (value) == CONSTRUCTOR)\n+    {\n+      unsigned len = vec_safe_length (CONSTRUCTOR_ELTS (value));\n+      for (unsigned i = 0; i < len; i++)\n+\t{\n+\t  tree v = CONSTRUCTOR_ELT (value, i)->value;\n+\t  unsigned actual = emit_immediate_scalar_to_buffer (v, p, 0);\n+\t  total_len -= actual;\n+\t  p += actual;\n+\t}\n+    }\n+  else\n+    emit_immediate_scalar_to_buffer (value, p, total_len);\n+}\n+\n+/* Emit an immediate BRIG operand IMM.  The BRIG type of the immediate might\n+   have been massaged to comply with various HSA/BRIG type requirements, so the\n+   only important aspect of that is the length (because HSAIL might expect\n+   smaller constants or become bit-data).  The data should be represented\n+   according to what is in the tree representation.  */\n+\n+static void\n+emit_immediate_operand (hsa_op_immed *imm)\n+{\n+  struct BrigOperandConstantBytes out;\n+\n+  memset (&out, 0, sizeof (out));\n+  out.base.byteCount = lendian16 (sizeof (out));\n+  out.base.kind = lendian16 (BRIG_KIND_OPERAND_CONSTANT_BYTES);\n+  uint32_t byteCount = lendian32 (imm->m_brig_repr_size);\n+  out.type = lendian16 (imm->m_type);\n+  out.bytes = lendian32 (brig_data.add (&byteCount, sizeof (byteCount)));\n+  brig_operand.add (&out, sizeof (out));\n+  brig_data.add (imm->m_brig_repr, imm->m_brig_repr_size);\n+  brig_data.round_size_up (4);\n+}\n+\n+/* Emit a register BRIG operand REG.  */\n+\n+static void\n+emit_register_operand (hsa_op_reg *reg)\n+{\n+  struct BrigOperandRegister out;\n+\n+  out.base.byteCount = lendian16 (sizeof (out));\n+  out.base.kind = lendian16 (BRIG_KIND_OPERAND_REGISTER);\n+  out.regNum = lendian32 (reg->m_hard_num);\n+\n+  switch (regtype_for_type (reg->m_type))\n+    {\n+    case BRIG_TYPE_B32:\n+      out.regKind = BRIG_REGISTER_KIND_SINGLE;\n+      break;\n+    case BRIG_TYPE_B64:\n+      out.regKind = BRIG_REGISTER_KIND_DOUBLE;\n+      break;\n+    case BRIG_TYPE_B128:\n+      out.regKind = BRIG_REGISTER_KIND_QUAD;\n+      break;\n+    case BRIG_TYPE_B1:\n+      out.regKind = BRIG_REGISTER_KIND_CONTROL;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  brig_operand.add (&out, sizeof (out));\n+}\n+\n+/* Emit an address BRIG operand ADDR.  */\n+\n+static void\n+emit_address_operand (hsa_op_address *addr)\n+{\n+  struct BrigOperandAddress out;\n+\n+  out.base.byteCount = lendian16 (sizeof (out));\n+  out.base.kind = lendian16 (BRIG_KIND_OPERAND_ADDRESS);\n+  out.symbol = addr->m_symbol\n+    ? lendian32 (emit_directive_variable (addr->m_symbol)) : 0;\n+  out.reg = addr->m_reg ? lendian32 (enqueue_op (addr->m_reg)) : 0;\n+\n+  if (sizeof (addr->m_imm_offset) == 8)\n+    {\n+      out.offset.lo = lendian32 (addr->m_imm_offset);\n+      out.offset.hi = lendian32 (addr->m_imm_offset >> 32);\n+    }\n+  else\n+    {\n+      gcc_assert (sizeof (addr->m_imm_offset) == 4);\n+      out.offset.lo = lendian32 (addr->m_imm_offset);\n+      out.offset.hi = 0;\n+    }\n+\n+  brig_operand.add (&out, sizeof (out));\n+}\n+\n+/* Emit a code reference operand REF.  */\n+\n+static void\n+emit_code_ref_operand (hsa_op_code_ref *ref)\n+{\n+  struct BrigOperandCodeRef out;\n+\n+  out.base.byteCount = lendian16 (sizeof (out));\n+  out.base.kind = lendian16 (BRIG_KIND_OPERAND_CODE_REF);\n+  out.ref = lendian32 (ref->m_directive_offset);\n+  brig_operand.add (&out, sizeof (out));\n+}\n+\n+/* Emit a code list operand CODE_LIST.  */\n+\n+static void\n+emit_code_list_operand (hsa_op_code_list *code_list)\n+{\n+  struct BrigOperandCodeList out;\n+  unsigned args = code_list->m_offsets.length ();\n+\n+  for (unsigned i = 0; i < args; i++)\n+    gcc_assert (code_list->m_offsets[i]);\n+\n+  out.base.byteCount = lendian16 (sizeof (out));\n+  out.base.kind = lendian16 (BRIG_KIND_OPERAND_CODE_LIST);\n+\n+  uint32_t byteCount = lendian32 (4 * args);\n+\n+  out.elements = lendian32 (brig_data.add (&byteCount, sizeof (byteCount)));\n+  brig_data.add (code_list->m_offsets.address (), args * sizeof (uint32_t));\n+  brig_data.round_size_up (4);\n+  brig_operand.add (&out, sizeof (out));\n+}\n+\n+/* Emit an operand list operand OPERAND_LIST.  */\n+\n+static void\n+emit_operand_list_operand (hsa_op_operand_list *operand_list)\n+{\n+  struct BrigOperandOperandList out;\n+  unsigned args = operand_list->m_offsets.length ();\n+\n+  for (unsigned i = 0; i < args; i++)\n+    gcc_assert (operand_list->m_offsets[i]);\n+\n+  out.base.byteCount = lendian16 (sizeof (out));\n+  out.base.kind = lendian16 (BRIG_KIND_OPERAND_OPERAND_LIST);\n+\n+  uint32_t byteCount = lendian32 (4 * args);\n+\n+  out.elements = lendian32 (brig_data.add (&byteCount, sizeof (byteCount)));\n+  brig_data.add (operand_list->m_offsets.address (), args * sizeof (uint32_t));\n+  brig_data.round_size_up (4);\n+  brig_operand.add (&out, sizeof (out));\n+}\n+\n+/* Emit all operands queued for writing.  */\n+\n+static void\n+emit_queued_operands (void)\n+{\n+  for (hsa_op_base *op = op_queue.first_op; op; op = op->m_next)\n+    {\n+      gcc_assert (op->m_brig_op_offset == brig_operand.total_size);\n+      if (hsa_op_immed *imm = dyn_cast <hsa_op_immed *> (op))\n+\temit_immediate_operand (imm);\n+      else if (hsa_op_reg *reg = dyn_cast <hsa_op_reg *> (op))\n+\temit_register_operand (reg);\n+      else if (hsa_op_address *addr = dyn_cast <hsa_op_address *> (op))\n+\temit_address_operand (addr);\n+      else if (hsa_op_code_ref *ref = dyn_cast <hsa_op_code_ref *> (op))\n+\temit_code_ref_operand (ref);\n+      else if (hsa_op_code_list *code_list = dyn_cast <hsa_op_code_list *> (op))\n+\temit_code_list_operand (code_list);\n+      else if (hsa_op_operand_list *l = dyn_cast <hsa_op_operand_list *> (op))\n+\temit_operand_list_operand (l);\n+      else\n+\tgcc_unreachable ();\n+    }\n+}\n+\n+/* Emit directives describing the function that is used for\n+   a function declaration.  */\n+\n+static BrigDirectiveExecutable *\n+emit_function_declaration (tree decl)\n+{\n+  hsa_function_representation *f = hsa_generate_function_declaration (decl);\n+\n+  BrigDirectiveExecutable *e = emit_function_directives (f, true);\n+  emit_queued_operands ();\n+\n+  delete f;\n+\n+  return e;\n+}\n+\n+/* Emit directives describing the function that is used for\n+   an internal function declaration.  */\n+\n+static BrigDirectiveExecutable *\n+emit_internal_fn_decl (hsa_internal_fn *fn)\n+{\n+  hsa_function_representation *f = hsa_generate_internal_fn_decl (fn);\n+\n+  BrigDirectiveExecutable *e = emit_function_directives (f, true);\n+  emit_queued_operands ();\n+\n+  delete f;\n+\n+  return e;\n+}\n+\n+/* Enqueue all operands of INSN and return offset to BRIG data section\n+   to list of operand offsets.  */\n+\n+static unsigned\n+emit_insn_operands (hsa_insn_basic *insn)\n+{\n+  auto_vec<BrigOperandOffset32_t, HSA_BRIG_INT_STORAGE_OPERANDS>\n+    operand_offsets;\n+\n+  unsigned l = insn->operand_count ();\n+  operand_offsets.safe_grow (l);\n+\n+  for (unsigned i = 0; i < l; i++)\n+    operand_offsets[i] = lendian32 (enqueue_op (insn->get_op (i)));\n+\n+  /* We have N operands so use 4 * N for the byte_count.  */\n+  uint32_t byte_count = lendian32 (4 * l);\n+\n+  unsigned offset = brig_data.add (&byte_count, sizeof (byte_count));\n+  brig_data.add (operand_offsets.address (),\n+\t\t l * sizeof (BrigOperandOffset32_t));\n+\n+  brig_data.round_size_up (4);\n+\n+  return offset;\n+}\n+\n+/* Enqueue operand OP0, OP1, OP2 (if different from NULL) and return offset\n+   to BRIG data section to list of operand offsets.  */\n+\n+static unsigned\n+emit_operands (hsa_op_base *op0, hsa_op_base *op1 = NULL,\n+\t       hsa_op_base *op2 = NULL)\n+{\n+  auto_vec<BrigOperandOffset32_t, HSA_BRIG_INT_STORAGE_OPERANDS>\n+    operand_offsets;\n+\n+  gcc_checking_assert (op0 != NULL);\n+  operand_offsets.safe_push (enqueue_op (op0));\n+\n+  if (op1 != NULL)\n+    {\n+      operand_offsets.safe_push (enqueue_op (op1));\n+      if (op2 != NULL)\n+\toperand_offsets.safe_push (enqueue_op (op2));\n+    }\n+\n+  unsigned l = operand_offsets.length ();\n+\n+  /* We have N operands so use 4 * N for the byte_count.  */\n+  uint32_t byte_count = lendian32 (4 * l);\n+\n+  unsigned offset = brig_data.add (&byte_count, sizeof (byte_count));\n+  brig_data.add (operand_offsets.address (),\n+\t\t l * sizeof (BrigOperandOffset32_t));\n+\n+  brig_data.round_size_up (4);\n+\n+  return offset;\n+}\n+\n+/* Emit an HSA memory instruction and all necessary directives, schedule\n+   necessary operands for writing.  */\n+\n+static void\n+emit_memory_insn (hsa_insn_mem *mem)\n+{\n+  struct BrigInstMem repr;\n+  gcc_checking_assert (mem->operand_count () == 2);\n+\n+  hsa_op_address *addr = as_a <hsa_op_address *> (mem->get_op (1));\n+\n+  /* This is necessary because of the erroneous typedef of\n+     BrigMemoryModifier8_t which introduces padding which may then contain\n+     random stuff (which we do not want so that we can test things don't\n+     change).  */\n+  memset (&repr, 0, sizeof (repr));\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_MEM);\n+  repr.base.opcode = lendian16 (mem->m_opcode);\n+  repr.base.type = lendian16 (mem->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (mem));\n+\n+  if (addr->m_symbol)\n+    repr.segment = addr->m_symbol->m_segment;\n+  else\n+    repr.segment = BRIG_SEGMENT_FLAT;\n+  repr.modifier = 0;\n+  repr.equivClass = mem->m_equiv_class;\n+  repr.align = mem->m_align;\n+  if (mem->m_opcode == BRIG_OPCODE_LD)\n+    repr.width = BRIG_WIDTH_1;\n+  else\n+    repr.width = BRIG_WIDTH_NONE;\n+  memset (&repr.reserved, 0, sizeof (repr.reserved));\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA signal memory instruction and all necessary directives, schedule\n+   necessary operands for writing.  */\n+\n+static void\n+emit_signal_insn (hsa_insn_signal *mem)\n+{\n+  struct BrigInstSignal repr;\n+\n+  /* This is necessary because of the erroneous typedef of\n+     BrigMemoryModifier8_t which introduces padding which may then contain\n+     random stuff (which we do not want so that we can test things don't\n+     change).  */\n+  memset (&repr, 0, sizeof (repr));\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_SIGNAL);\n+  repr.base.opcode = lendian16 (mem->m_opcode);\n+  repr.base.type = lendian16 (mem->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (mem));\n+\n+  repr.memoryOrder = mem->m_memoryorder;\n+  repr.signalOperation = mem->m_atomicop;\n+  repr.signalType = BRIG_TYPE_SIG64;\n+\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA atomic memory instruction and all necessary directives, schedule\n+   necessary operands for writing.  */\n+\n+static void\n+emit_atomic_insn (hsa_insn_atomic *mem)\n+{\n+  struct BrigInstAtomic repr;\n+\n+  /* Either operand[0] or operand[1] must be an address operand.  */\n+  hsa_op_address *addr = NULL;\n+  if (is_a <hsa_op_address *> (mem->get_op (0)))\n+    addr = as_a <hsa_op_address *> (mem->get_op (0));\n+  else\n+    addr = as_a <hsa_op_address *> (mem->get_op (1));\n+\n+  /* This is necessary because of the erroneous typedef of\n+     BrigMemoryModifier8_t which introduces padding which may then contain\n+     random stuff (which we do not want so that we can test things don't\n+     change).  */\n+  memset (&repr, 0, sizeof (repr));\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_ATOMIC);\n+  repr.base.opcode = lendian16 (mem->m_opcode);\n+  repr.base.type = lendian16 (mem->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (mem));\n+\n+  if (addr->m_symbol)\n+    repr.segment = addr->m_symbol->m_segment;\n+  else\n+    repr.segment = BRIG_SEGMENT_FLAT;\n+  repr.memoryOrder = mem->m_memoryorder;\n+  repr.memoryScope = mem->m_memoryscope;\n+  repr.atomicOperation = mem->m_atomicop;\n+\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA LDA instruction and all necessary directives, schedule\n+   necessary operands for writing.  */\n+\n+static void\n+emit_addr_insn (hsa_insn_basic *insn)\n+{\n+  struct BrigInstAddr repr;\n+\n+  hsa_op_address *addr = as_a <hsa_op_address *> (insn->get_op (1));\n+\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_ADDR);\n+  repr.base.opcode = lendian16 (insn->m_opcode);\n+  repr.base.type = lendian16 (insn->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (insn));\n+\n+  if (addr->m_symbol)\n+    repr.segment = addr->m_symbol->m_segment;\n+  else\n+    repr.segment = BRIG_SEGMENT_FLAT;\n+  memset (&repr.reserved, 0, sizeof (repr.reserved));\n+\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA segment conversion instruction and all necessary directives,\n+   schedule necessary operands for writing.  */\n+\n+static void\n+emit_segment_insn (hsa_insn_seg *seg)\n+{\n+  struct BrigInstSegCvt repr;\n+\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_SEG_CVT);\n+  repr.base.opcode = lendian16 (seg->m_opcode);\n+  repr.base.type = lendian16 (seg->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (seg));\n+  repr.sourceType = lendian16 (as_a <hsa_op_reg *> (seg->get_op (1))->m_type);\n+  repr.segment = seg->m_segment;\n+  repr.modifier = 0;\n+\n+  brig_code.add (&repr, sizeof (repr));\n+\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA alloca instruction and all necessary directives,\n+   schedule necessary operands for writing.  */\n+\n+static void\n+emit_alloca_insn (hsa_insn_alloca *alloca)\n+{\n+  struct BrigInstMem repr;\n+  gcc_checking_assert (alloca->operand_count () == 2);\n+\n+  /* This is necessary because of the erroneous typedef of\n+     BrigMemoryModifier8_t which introduces padding which may then contain\n+     random stuff (which we do not want so that we can test things don't\n+     change).  */\n+  memset (&repr, 0, sizeof (repr));\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_MEM);\n+  repr.base.opcode = lendian16 (alloca->m_opcode);\n+  repr.base.type = lendian16 (alloca->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (alloca));\n+  repr.segment = BRIG_SEGMENT_PRIVATE;\n+  repr.modifier = 0;\n+  repr.equivClass = 0;\n+  repr.align = alloca->m_align;\n+  repr.width = BRIG_WIDTH_NONE;\n+  memset (&repr.reserved, 0, sizeof (repr.reserved));\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA comparison instruction and all necessary directives,\n+   schedule necessary operands for writing.  */\n+\n+static void\n+emit_cmp_insn (hsa_insn_cmp *cmp)\n+{\n+  struct BrigInstCmp repr;\n+\n+  memset (&repr, 0, sizeof (repr));\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_CMP);\n+  repr.base.opcode = lendian16 (cmp->m_opcode);\n+  repr.base.type = lendian16 (cmp->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (cmp));\n+\n+  if (is_a <hsa_op_reg *> (cmp->get_op (1)))\n+    repr.sourceType\n+      = lendian16 (as_a <hsa_op_reg *> (cmp->get_op (1))->m_type);\n+  else\n+    repr.sourceType\n+      = lendian16 (as_a <hsa_op_immed *> (cmp->get_op (1))->m_type);\n+  repr.modifier = 0;\n+  repr.compare = cmp->m_compare;\n+  repr.pack = 0;\n+\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA branching instruction and all necessary directives, schedule\n+   necessary operands for writing.  */\n+\n+static void\n+emit_branch_insn (hsa_insn_br *br)\n+{\n+  struct BrigInstBr repr;\n+\n+  basic_block target = NULL;\n+  edge_iterator ei;\n+  edge e;\n+\n+  /* At the moment we only handle direct conditional jumps.  */\n+  gcc_assert (br->m_opcode == BRIG_OPCODE_CBR);\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_BR);\n+  repr.base.opcode = lendian16 (br->m_opcode);\n+  repr.width = BRIG_WIDTH_1;\n+  /* For Conditional jumps the type is always B1.  */\n+  repr.base.type = lendian16 (BRIG_TYPE_B1);\n+\n+  FOR_EACH_EDGE (e, ei, br->m_bb->succs)\n+    if (e->flags & EDGE_TRUE_VALUE)\n+      {\n+\ttarget = e->dest;\n+\tbreak;\n+      }\n+  gcc_assert (target);\n+\n+  repr.base.operands\n+    = lendian32 (emit_operands (br->get_op (0),\n+\t\t\t\t&hsa_bb_for_bb (target)->m_label_ref));\n+  memset (&repr.reserved, 0, sizeof (repr.reserved));\n+\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA unconditional jump branching instruction that points to\n+   a label REFERENCE.  */\n+\n+static void\n+emit_unconditional_jump (hsa_op_code_ref *reference)\n+{\n+  struct BrigInstBr repr;\n+\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_BR);\n+  repr.base.opcode = lendian16 (BRIG_OPCODE_BR);\n+  repr.base.type = lendian16 (BRIG_TYPE_NONE);\n+  /* Direct branches to labels must be width(all).  */\n+  repr.width = BRIG_WIDTH_ALL;\n+\n+  repr.base.operands = lendian32 (emit_operands (reference));\n+  memset (&repr.reserved, 0, sizeof (repr.reserved));\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA switch jump instruction that uses a jump table to\n+   jump to a destination label.  */\n+\n+static void\n+emit_switch_insn (hsa_insn_sbr *sbr)\n+{\n+  struct BrigInstBr repr;\n+\n+  gcc_assert (sbr->m_opcode == BRIG_OPCODE_SBR);\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_BR);\n+  repr.base.opcode = lendian16 (sbr->m_opcode);\n+  repr.width = BRIG_WIDTH_1;\n+  /* For Conditional jumps the type is always B1.  */\n+  hsa_op_reg *index = as_a <hsa_op_reg *> (sbr->get_op (0));\n+  repr.base.type = lendian16 (index->m_type);\n+  repr.base.operands\n+    = lendian32 (emit_operands (sbr->get_op (0), sbr->m_label_code_list));\n+  memset (&repr.reserved, 0, sizeof (repr.reserved));\n+\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+\n+  /* Emit jump to default label.  */\n+  hsa_bb *hbb = hsa_bb_for_bb (sbr->m_default_bb);\n+  emit_unconditional_jump (&hbb->m_label_ref);\n+}\n+\n+/* Emit a HSA convert instruction and all necessary directives, schedule\n+   necessary operands for writing.  */\n+\n+static void\n+emit_cvt_insn (hsa_insn_cvt *insn)\n+{\n+  struct BrigInstCvt repr;\n+  BrigType16_t srctype;\n+\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_CVT);\n+  repr.base.opcode = lendian16 (insn->m_opcode);\n+  repr.base.type = lendian16 (insn->m_type);\n+  repr.base.operands = lendian32 (emit_insn_operands (insn));\n+\n+  if (is_a <hsa_op_reg *> (insn->get_op (1)))\n+    srctype = as_a <hsa_op_reg *> (insn->get_op (1))->m_type;\n+  else\n+    srctype = as_a <hsa_op_immed *> (insn->get_op (1))->m_type;\n+  repr.sourceType = lendian16 (srctype);\n+  repr.modifier = 0;\n+  /* float to smaller float requires a rounding setting (we default\n+     to 'near'.  */\n+  if (hsa_type_float_p (insn->m_type)\n+      && (!hsa_type_float_p (srctype)\n+\t  || ((insn->m_type & BRIG_TYPE_BASE_MASK)\n+\t      < (srctype & BRIG_TYPE_BASE_MASK))))\n+    repr.round = BRIG_ROUND_FLOAT_NEAR_EVEN;\n+  else if (hsa_type_integer_p (insn->m_type) &&\n+\t   hsa_type_float_p (srctype))\n+    repr.round = BRIG_ROUND_INTEGER_ZERO;\n+  else\n+    repr.round = BRIG_ROUND_NONE;\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit call instruction INSN, where this instruction must be closed\n+   within a call block instruction.  */\n+\n+static void\n+emit_call_insn (hsa_insn_call *call)\n+{\n+  struct BrigInstBr repr;\n+\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_BR);\n+  repr.base.opcode = lendian16 (BRIG_OPCODE_CALL);\n+  repr.base.type = lendian16 (BRIG_TYPE_NONE);\n+\n+  repr.base.operands\n+    = lendian32 (emit_operands (call->m_result_code_list, &call->m_func,\n+\t\t\t\tcall->m_args_code_list));\n+\n+  /* Internal functions have not set m_called_function.  */\n+  if (call->m_called_function)\n+    {\n+      function_linkage_pair pair (call->m_called_function,\n+\t\t\t\t  call->m_func.m_brig_op_offset);\n+      function_call_linkage.safe_push (pair);\n+    }\n+  else\n+    {\n+      hsa_internal_fn *slot\n+\t= hsa_emitted_internal_decls->find (call->m_called_internal_fn);\n+      gcc_assert (slot);\n+      gcc_assert (slot->m_offset > 0);\n+      call->m_func.m_directive_offset = slot->m_offset;\n+    }\n+\n+  repr.width = BRIG_WIDTH_ALL;\n+  memset (&repr.reserved, 0, sizeof (repr.reserved));\n+\n+  brig_code.add (&repr, sizeof (repr));\n+  brig_insn_count++;\n+}\n+\n+/* Emit argument block directive.  */\n+\n+static void\n+emit_arg_block_insn (hsa_insn_arg_block *insn)\n+{\n+  switch (insn->m_kind)\n+    {\n+    case BRIG_KIND_DIRECTIVE_ARG_BLOCK_START:\n+      {\n+\tstruct BrigDirectiveArgBlock repr;\n+\trepr.base.byteCount = lendian16 (sizeof (repr));\n+\trepr.base.kind = lendian16 (insn->m_kind);\n+\tbrig_code.add (&repr, sizeof (repr));\n+\n+\tfor (unsigned i = 0; i < insn->m_call_insn->m_input_args.length (); i++)\n+\t  {\n+\t    insn->m_call_insn->m_args_code_list->m_offsets[i]\n+\t      = lendian32 (emit_directive_variable\n+\t\t\t   (insn->m_call_insn->m_input_args[i]));\n+\t    brig_insn_count++;\n+\t  }\n+\n+\tif (insn->m_call_insn->m_output_arg)\n+\t  {\n+\t    insn->m_call_insn->m_result_code_list->m_offsets[0]\n+\t      = lendian32 (emit_directive_variable\n+\t\t\t   (insn->m_call_insn->m_output_arg));\n+\t    brig_insn_count++;\n+\t  }\n+\n+\tbreak;\n+      }\n+    case BRIG_KIND_DIRECTIVE_ARG_BLOCK_END:\n+      {\n+\tstruct BrigDirectiveArgBlock repr;\n+\trepr.base.byteCount = lendian16 (sizeof (repr));\n+\trepr.base.kind = lendian16 (insn->m_kind);\n+\tbrig_code.add (&repr, sizeof (repr));\n+\tbreak;\n+      }\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  brig_insn_count++;\n+}\n+\n+/* Emit comment directive.  */\n+\n+static void\n+emit_comment_insn (hsa_insn_comment *insn)\n+{\n+  struct BrigDirectiveComment repr;\n+  memset (&repr, 0, sizeof (repr));\n+\n+  repr.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.kind = lendian16 (insn->m_opcode);\n+  repr.name = brig_emit_string (insn->m_comment, '\\0', false);\n+  brig_code.add (&repr, sizeof (repr));\n+}\n+\n+/* Emit queue instruction INSN.  */\n+\n+static void\n+emit_queue_insn (hsa_insn_queue *insn)\n+{\n+  BrigInstQueue repr;\n+  memset (&repr, 0, sizeof (repr));\n+\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_QUEUE);\n+  repr.base.opcode = lendian16 (insn->m_opcode);\n+  repr.base.type = lendian16 (insn->m_type);\n+  repr.segment = BRIG_SEGMENT_GLOBAL;\n+  repr.memoryOrder = BRIG_MEMORY_ORDER_SC_RELEASE;\n+  repr.base.operands = lendian32 (emit_insn_operands (insn));\n+  brig_data.round_size_up (4);\n+  brig_code.add (&repr, sizeof (repr));\n+\n+  brig_insn_count++;\n+}\n+\n+/* Emit source type instruction INSN.  */\n+\n+static void\n+emit_srctype_insn (hsa_insn_srctype *insn)\n+{\n+  /* We assume that BrigInstMod has a BrigInstBasic prefix.  */\n+  struct BrigInstSourceType repr;\n+  unsigned operand_count = insn->operand_count ();\n+  gcc_checking_assert (operand_count >= 2);\n+\n+  memset (&repr, 0, sizeof (repr));\n+  repr.sourceType = lendian16 (insn->m_source_type);\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_SOURCE_TYPE);\n+  repr.base.opcode = lendian16 (insn->m_opcode);\n+  repr.base.type = lendian16 (insn->m_type);\n+\n+  repr.base.operands = lendian32 (emit_insn_operands (insn));\n+  brig_code.add (&repr, sizeof (struct BrigInstSourceType));\n+  brig_insn_count++;\n+}\n+\n+/* Emit packed instruction INSN.  */\n+\n+static void\n+emit_packed_insn (hsa_insn_packed *insn)\n+{\n+  /* We assume that BrigInstMod has a BrigInstBasic prefix.  */\n+  struct BrigInstSourceType repr;\n+  unsigned operand_count = insn->operand_count ();\n+  gcc_checking_assert (operand_count >= 2);\n+\n+  memset (&repr, 0, sizeof (repr));\n+  repr.sourceType = lendian16 (insn->m_source_type);\n+  repr.base.base.byteCount = lendian16 (sizeof (repr));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_SOURCE_TYPE);\n+  repr.base.opcode = lendian16 (insn->m_opcode);\n+  repr.base.type = lendian16 (insn->m_type);\n+\n+  if (insn->m_opcode == BRIG_OPCODE_COMBINE)\n+    {\n+      /* Create operand list for packed type.  */\n+      for (unsigned i = 1; i < operand_count; i++)\n+\t{\n+\t  gcc_checking_assert (insn->get_op (i));\n+\t  insn->m_operand_list->m_offsets[i - 1]\n+\t    = lendian32 (enqueue_op (insn->get_op (i)));\n+\t}\n+\n+      repr.base.operands = lendian32 (emit_operands (insn->get_op (0),\n+\t\t\t\t\t\t     insn->m_operand_list));\n+    }\n+  else if (insn->m_opcode == BRIG_OPCODE_EXPAND)\n+    {\n+      /* Create operand list for packed type.  */\n+      for (unsigned i = 0; i < operand_count - 1; i++)\n+\t{\n+\t  gcc_checking_assert (insn->get_op (i));\n+\t  insn->m_operand_list->m_offsets[i]\n+\t    = lendian32 (enqueue_op (insn->get_op (i)));\n+\t}\n+\n+      unsigned ops = emit_operands (insn->m_operand_list,\n+\t\t\t\t    insn->get_op (insn->operand_count () - 1));\n+      repr.base.operands = lendian32 (ops);\n+    }\n+\n+\n+  brig_code.add (&repr, sizeof (struct BrigInstSourceType));\n+  brig_insn_count++;\n+}\n+\n+/* Emit a basic HSA instruction and all necessary directives, schedule\n+   necessary operands for writing.  */\n+\n+static void\n+emit_basic_insn (hsa_insn_basic *insn)\n+{\n+  /* We assume that BrigInstMod has a BrigInstBasic prefix.  */\n+  struct BrigInstMod repr;\n+  BrigType16_t type;\n+\n+  memset (&repr, 0, sizeof (repr));\n+  repr.base.base.byteCount = lendian16 (sizeof (BrigInstBasic));\n+  repr.base.base.kind = lendian16 (BRIG_KIND_INST_BASIC);\n+  repr.base.opcode = lendian16 (insn->m_opcode);\n+  switch (insn->m_opcode)\n+    {\n+      /* And the bit-logical operations need bit types and whine about\n+\t arithmetic types :-/  */\n+      case BRIG_OPCODE_AND:\n+      case BRIG_OPCODE_OR:\n+      case BRIG_OPCODE_XOR:\n+      case BRIG_OPCODE_NOT:\n+\ttype = regtype_for_type (insn->m_type);\n+\tbreak;\n+      default:\n+\ttype = insn->m_type;\n+\tbreak;\n+    }\n+  repr.base.type = lendian16 (type);\n+  repr.base.operands = lendian32 (emit_insn_operands (insn));\n+\n+  if ((type & BRIG_TYPE_PACK_MASK) != BRIG_TYPE_PACK_NONE)\n+    {\n+      if (hsa_type_float_p (type)\n+\t  && !hsa_opcode_floating_bit_insn_p (insn->m_opcode))\n+\trepr.round = BRIG_ROUND_FLOAT_NEAR_EVEN;\n+      else\n+\trepr.round = 0;\n+      /* We assume that destination and sources agree in packing layout.  */\n+      if (insn->num_used_ops () >= 2)\n+\trepr.pack = BRIG_PACK_PP;\n+      else\n+\trepr.pack = BRIG_PACK_P;\n+      repr.reserved = 0;\n+      repr.base.base.byteCount = lendian16 (sizeof (BrigInstMod));\n+      repr.base.base.kind = lendian16 (BRIG_KIND_INST_MOD);\n+      brig_code.add (&repr, sizeof (struct BrigInstMod));\n+    }\n+  else\n+    brig_code.add (&repr, sizeof (struct BrigInstBasic));\n+  brig_insn_count++;\n+}\n+\n+/* Emit an HSA instruction and all necessary directives, schedule necessary\n+   operands for writing.  */\n+\n+static void\n+emit_insn (hsa_insn_basic *insn)\n+{\n+  gcc_assert (!is_a <hsa_insn_phi *> (insn));\n+\n+  insn->m_brig_offset = brig_code.total_size;\n+\n+  if (hsa_insn_signal *signal = dyn_cast <hsa_insn_signal *> (insn))\n+    emit_signal_insn (signal);\n+  else if (hsa_insn_atomic *atom = dyn_cast <hsa_insn_atomic *> (insn))\n+    emit_atomic_insn (atom);\n+  else if (hsa_insn_mem *mem = dyn_cast <hsa_insn_mem *> (insn))\n+    emit_memory_insn (mem);\n+  else if (insn->m_opcode == BRIG_OPCODE_LDA)\n+    emit_addr_insn (insn);\n+  else if (hsa_insn_seg *seg = dyn_cast <hsa_insn_seg *> (insn))\n+    emit_segment_insn (seg);\n+  else if (hsa_insn_cmp *cmp = dyn_cast <hsa_insn_cmp *> (insn))\n+    emit_cmp_insn (cmp);\n+  else if (hsa_insn_br *br = dyn_cast <hsa_insn_br *> (insn))\n+    emit_branch_insn (br);\n+  else if (hsa_insn_sbr *sbr = dyn_cast <hsa_insn_sbr *> (insn))\n+    {\n+      if (switch_instructions == NULL)\n+\tswitch_instructions = new vec <hsa_insn_sbr *> ();\n+\n+      switch_instructions->safe_push (sbr);\n+      emit_switch_insn (sbr);\n+    }\n+  else if (hsa_insn_arg_block *block = dyn_cast <hsa_insn_arg_block *> (insn))\n+    emit_arg_block_insn (block);\n+  else if (hsa_insn_call *call = dyn_cast <hsa_insn_call *> (insn))\n+    emit_call_insn (call);\n+  else if (hsa_insn_comment *comment = dyn_cast <hsa_insn_comment *> (insn))\n+    emit_comment_insn (comment);\n+  else if (hsa_insn_queue *queue = dyn_cast <hsa_insn_queue *> (insn))\n+    emit_queue_insn (queue);\n+  else if (hsa_insn_srctype *srctype = dyn_cast <hsa_insn_srctype *> (insn))\n+    emit_srctype_insn (srctype);\n+  else if (hsa_insn_packed *packed = dyn_cast <hsa_insn_packed *> (insn))\n+    emit_packed_insn (packed);\n+  else if (hsa_insn_cvt *cvt = dyn_cast <hsa_insn_cvt *> (insn))\n+    emit_cvt_insn (cvt);\n+  else if (hsa_insn_alloca *alloca = dyn_cast <hsa_insn_alloca *> (insn))\n+    emit_alloca_insn (alloca);\n+  else\n+    emit_basic_insn (insn);\n+}\n+\n+/* We have just finished emitting BB and are about to emit NEXT_BB if non-NULL,\n+   or we are about to finish emitting code, if it is NULL.  If the fall through\n+   edge from BB does not lead to NEXT_BB, emit an unconditional jump.  */\n+\n+static void\n+perhaps_emit_branch (basic_block bb, basic_block next_bb)\n+{\n+  basic_block t_bb = NULL, ff = NULL;\n+\n+  edge_iterator ei;\n+  edge e;\n+\n+  /* If the last instruction of BB is a switch, ignore emission of all\n+     edges.  */\n+  if (hsa_bb_for_bb (bb)->m_last_insn\n+      && is_a <hsa_insn_sbr *> (hsa_bb_for_bb (bb)->m_last_insn))\n+    return;\n+\n+  FOR_EACH_EDGE (e, ei, bb->succs)\n+    if (e->flags & EDGE_TRUE_VALUE)\n+      {\n+\tgcc_assert (!t_bb);\n+\tt_bb = e->dest;\n+      }\n+    else\n+      {\n+\tgcc_assert (!ff);\n+\tff = e->dest;\n+      }\n+\n+  if (!ff || ff == next_bb || ff == EXIT_BLOCK_PTR_FOR_FN (cfun))\n+    return;\n+\n+  emit_unconditional_jump (&hsa_bb_for_bb (ff)->m_label_ref);\n+}\n+\n+/* Emit the a function with name NAME to the various brig sections.  */\n+\n+void\n+hsa_brig_emit_function (void)\n+{\n+  basic_block bb, prev_bb;\n+  hsa_insn_basic *insn;\n+  BrigDirectiveExecutable *ptr_to_fndir;\n+\n+  brig_init ();\n+\n+  brig_insn_count = 0;\n+  memset (&op_queue, 0, sizeof (op_queue));\n+  op_queue.projected_size = brig_operand.total_size;\n+\n+  if (!function_offsets)\n+    function_offsets = new hash_map<tree, BrigCodeOffset32_t> ();\n+\n+  if (!emitted_declarations)\n+    emitted_declarations = new hash_map <tree, BrigDirectiveExecutable *> ();\n+\n+  for (unsigned i = 0; i < hsa_cfun->m_called_functions.length (); i++)\n+    {\n+      tree called = hsa_cfun->m_called_functions[i];\n+\n+      /* If the function has no definition, emit a declaration.  */\n+      if (!emitted_declarations->get (called))\n+\t{\n+\t  BrigDirectiveExecutable *e = emit_function_declaration (called);\n+\t  emitted_declarations->put (called, e);\n+\t}\n+    }\n+\n+  for (unsigned i = 0; i < hsa_cfun->m_called_internal_fns.length (); i++)\n+    {\n+      hsa_internal_fn *called = hsa_cfun->m_called_internal_fns[i];\n+      emit_internal_fn_decl (called);\n+    }\n+\n+  ptr_to_fndir = emit_function_directives (hsa_cfun, false);\n+  for (insn = hsa_bb_for_bb (ENTRY_BLOCK_PTR_FOR_FN (cfun))->m_first_insn;\n+       insn;\n+       insn = insn->m_next)\n+    emit_insn (insn);\n+  prev_bb = ENTRY_BLOCK_PTR_FOR_FN (cfun);\n+  FOR_EACH_BB_FN (bb, cfun)\n+    {\n+      perhaps_emit_branch (prev_bb, bb);\n+      emit_bb_label_directive (hsa_bb_for_bb (bb));\n+      for (insn = hsa_bb_for_bb (bb)->m_first_insn; insn; insn = insn->m_next)\n+\temit_insn (insn);\n+      prev_bb = bb;\n+    }\n+  perhaps_emit_branch (prev_bb, NULL);\n+  ptr_to_fndir->nextModuleEntry = brig_code.total_size;\n+\n+  /* Fill up label references for all sbr instructions.  */\n+  if (switch_instructions)\n+    {\n+      for (unsigned i = 0; i < switch_instructions->length (); i++)\n+\t{\n+\t  hsa_insn_sbr *sbr = (*switch_instructions)[i];\n+\t  for (unsigned j = 0; j < sbr->m_jump_table.length (); j++)\n+\t    {\n+\t      hsa_bb *hbb = hsa_bb_for_bb (sbr->m_jump_table[j]);\n+\t      sbr->m_label_code_list->m_offsets[j]\n+\t\t= hbb->m_label_ref.m_directive_offset;\n+\t    }\n+\t}\n+\n+      switch_instructions->release ();\n+      delete switch_instructions;\n+      switch_instructions = NULL;\n+    }\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"------- After BRIG emission: -------\\n\");\n+      dump_hsa_cfun (dump_file);\n+    }\n+\n+  emit_queued_operands ();\n+}\n+\n+/* Emit all OMP symbols related to OMP.  */\n+\n+void\n+hsa_brig_emit_omp_symbols (void)\n+{\n+  brig_init ();\n+  emit_directive_variable (hsa_num_threads);\n+}\n+\n+static GTY(()) tree hsa_cdtor_statements[2];\n+\n+/* Create and return __hsa_global_variables symbol that contains\n+   all informations consumed by libgomp to link global variables\n+   with their string names used by an HSA kernel.  */\n+\n+static tree\n+hsa_output_global_variables ()\n+{\n+  unsigned l = hsa_global_variable_symbols->elements ();\n+\n+  tree variable_info_type = make_node (RECORD_TYPE);\n+  tree id_f1 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"name\"), ptr_type_node);\n+  DECL_CHAIN (id_f1) = NULL_TREE;\n+  tree id_f2 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"omp_data_size\"),\n+\t\t\t   ptr_type_node);\n+  DECL_CHAIN (id_f2) = id_f1;\n+  finish_builtin_struct (variable_info_type, \"__hsa_variable_info\", id_f2,\n+\t\t\t NULL_TREE);\n+\n+  tree int_num_of_global_vars;\n+  int_num_of_global_vars = build_int_cst (uint32_type_node, l);\n+  tree global_vars_num_index_type = build_index_type (int_num_of_global_vars);\n+  tree global_vars_array_type = build_array_type (variable_info_type,\n+\t\t\t\t\t\t  global_vars_num_index_type);\n+  TYPE_ARTIFICIAL (global_vars_array_type) = 1;\n+\n+  vec<constructor_elt, va_gc> *global_vars_vec = NULL;\n+\n+  for (hash_table <hsa_noop_symbol_hasher>::iterator it\n+       = hsa_global_variable_symbols->begin ();\n+       it != hsa_global_variable_symbols->end (); ++it)\n+    {\n+      unsigned len = strlen ((*it)->m_name);\n+      char *copy = XNEWVEC (char, len + 2);\n+      copy[0] = '&';\n+      memcpy (copy + 1, (*it)->m_name, len);\n+      copy[len + 1] = '\\0';\n+      len++;\n+      hsa_sanitize_name (copy);\n+\n+      tree var_name = build_string (len, copy);\n+      TREE_TYPE (var_name)\n+\t= build_array_type (char_type_node, build_index_type (size_int (len)));\n+      free (copy);\n+\n+      vec<constructor_elt, va_gc> *variable_info_vec = NULL;\n+      CONSTRUCTOR_APPEND_ELT (variable_info_vec, NULL_TREE,\n+\t\t\t      build1 (ADDR_EXPR,\n+\t\t\t\t      build_pointer_type (TREE_TYPE (var_name)),\n+\t\t\t\t      var_name));\n+      CONSTRUCTOR_APPEND_ELT (variable_info_vec, NULL_TREE,\n+\t\t\t      build_fold_addr_expr ((*it)->m_decl));\n+\n+      tree variable_info_ctor = build_constructor (variable_info_type,\n+\t\t\t\t\t\t   variable_info_vec);\n+\n+      CONSTRUCTOR_APPEND_ELT (global_vars_vec, NULL_TREE,\n+\t\t\t      variable_info_ctor);\n+    }\n+\n+  tree global_vars_ctor = build_constructor (global_vars_array_type,\n+\t\t\t\t\t     global_vars_vec);\n+\n+  char tmp_name[64];\n+  ASM_GENERATE_INTERNAL_LABEL (tmp_name, \"__hsa_global_variables\", 1);\n+  tree global_vars_table = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t\t   get_identifier (tmp_name),\n+\t\t\t\t\t   global_vars_array_type);\n+  TREE_STATIC (global_vars_table) = 1;\n+  TREE_READONLY (global_vars_table) = 1;\n+  TREE_PUBLIC (global_vars_table) = 0;\n+  DECL_ARTIFICIAL (global_vars_table) = 1;\n+  DECL_IGNORED_P (global_vars_table) = 1;\n+  DECL_EXTERNAL (global_vars_table) = 0;\n+  TREE_CONSTANT (global_vars_table) = 1;\n+  DECL_INITIAL (global_vars_table) = global_vars_ctor;\n+  varpool_node::finalize_decl (global_vars_table);\n+\n+  return global_vars_table;\n+}\n+\n+/* Create __hsa_host_functions and __hsa_kernels that contain\n+   all informations consumed by libgomp to register all kernels\n+   in the BRIG binary.  */\n+\n+static void\n+hsa_output_kernels (tree *host_func_table, tree *kernels)\n+{\n+  unsigned map_count = hsa_get_number_decl_kernel_mappings ();\n+\n+  tree int_num_of_kernels;\n+  int_num_of_kernels = build_int_cst (uint32_type_node, map_count);\n+  tree kernel_num_index_type = build_index_type (int_num_of_kernels);\n+  tree host_functions_array_type = build_array_type (ptr_type_node,\n+\t\t\t\t\t\t     kernel_num_index_type);\n+  TYPE_ARTIFICIAL (host_functions_array_type) = 1;\n+\n+  vec<constructor_elt, va_gc> *host_functions_vec = NULL;\n+  for (unsigned i = 0; i < map_count; ++i)\n+    {\n+      tree decl = hsa_get_decl_kernel_mapping_decl (i);\n+      tree host_fn = build_fold_addr_expr (hsa_get_host_function (decl));\n+      CONSTRUCTOR_APPEND_ELT (host_functions_vec, NULL_TREE, host_fn);\n+    }\n+  tree host_functions_ctor = build_constructor (host_functions_array_type,\n+\t\t\t\t\t\thost_functions_vec);\n+  char tmp_name[64];\n+  ASM_GENERATE_INTERNAL_LABEL (tmp_name, \"__hsa_host_functions\", 1);\n+  tree hsa_host_func_table = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t\t get_identifier (tmp_name),\n+\t\t\t\t\t host_functions_array_type);\n+  TREE_STATIC (hsa_host_func_table) = 1;\n+  TREE_READONLY (hsa_host_func_table) = 1;\n+  TREE_PUBLIC (hsa_host_func_table) = 0;\n+  DECL_ARTIFICIAL (hsa_host_func_table) = 1;\n+  DECL_IGNORED_P (hsa_host_func_table) = 1;\n+  DECL_EXTERNAL (hsa_host_func_table) = 0;\n+  TREE_CONSTANT (hsa_host_func_table) = 1;\n+  DECL_INITIAL (hsa_host_func_table) = host_functions_ctor;\n+  varpool_node::finalize_decl (hsa_host_func_table);\n+  *host_func_table = hsa_host_func_table;\n+\n+  /* Following code emits list of kernel_info structures.  */\n+\n+  tree kernel_info_type = make_node (RECORD_TYPE);\n+  tree id_f1 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"name\"), ptr_type_node);\n+  DECL_CHAIN (id_f1) = NULL_TREE;\n+  tree id_f2 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"omp_data_size\"),\n+\t\t\t   unsigned_type_node);\n+  DECL_CHAIN (id_f2) = id_f1;\n+  tree id_f3 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"gridified_kernel_p\"),\n+\t\t\t   boolean_type_node);\n+  DECL_CHAIN (id_f3) = id_f2;\n+  tree id_f4 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"kernel_dependencies_count\"),\n+\t\t\t   unsigned_type_node);\n+  DECL_CHAIN (id_f4) = id_f3;\n+  tree id_f5 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"kernel_dependencies\"),\n+\t\t\t   build_pointer_type (build_pointer_type\n+\t\t\t\t\t       (char_type_node)));\n+  DECL_CHAIN (id_f5) = id_f4;\n+  finish_builtin_struct (kernel_info_type, \"__hsa_kernel_info\", id_f5,\n+\t\t\t NULL_TREE);\n+\n+  int_num_of_kernels = build_int_cstu (uint32_type_node, map_count);\n+  tree kernel_info_vector_type\n+    = build_array_type (kernel_info_type,\n+\t\t\tbuild_index_type (int_num_of_kernels));\n+  TYPE_ARTIFICIAL (kernel_info_vector_type) = 1;\n+\n+  vec<constructor_elt, va_gc> *kernel_info_vector_vec = NULL;\n+  tree kernel_dependencies_vector_type = NULL;\n+\n+  for (unsigned i = 0; i < map_count; ++i)\n+    {\n+      tree kernel = hsa_get_decl_kernel_mapping_decl (i);\n+      char *name = hsa_get_decl_kernel_mapping_name (i);\n+      unsigned len = strlen (name);\n+      char *copy = XNEWVEC (char, len + 2);\n+      copy[0] = '&';\n+      memcpy (copy + 1, name, len);\n+      copy[len + 1] = '\\0';\n+      len++;\n+\n+      tree kern_name = build_string (len, copy);\n+      TREE_TYPE (kern_name)\n+\t= build_array_type (char_type_node, build_index_type (size_int (len)));\n+      free (copy);\n+\n+      unsigned omp_size = hsa_get_decl_kernel_mapping_omp_size (i);\n+      tree omp_data_size = build_int_cstu (unsigned_type_node, omp_size);\n+      bool gridified_kernel_p = hsa_get_decl_kernel_mapping_gridified (i);\n+      tree gridified_kernel_p_tree = build_int_cstu (boolean_type_node,\n+\t\t\t\t\t\t     gridified_kernel_p);\n+      unsigned count = 0;\n+\n+      kernel_dependencies_vector_type\n+\t= build_array_type (build_pointer_type (char_type_node),\n+\t\t\t    build_index_type (size_int (0)));\n+\n+      vec<constructor_elt, va_gc> *kernel_dependencies_vec = NULL;\n+      if (hsa_decl_kernel_dependencies)\n+\t{\n+\t  vec<const char *> **slot;\n+\t  slot = hsa_decl_kernel_dependencies->get (kernel);\n+\t  if (slot)\n+\t    {\n+\t      vec <const char *> *dependencies = *slot;\n+\t      count = dependencies->length ();\n+\n+\t      kernel_dependencies_vector_type\n+\t\t= build_array_type (build_pointer_type (char_type_node),\n+\t\t\t\t    build_index_type (size_int (count)));\n+\t      TYPE_ARTIFICIAL (kernel_dependencies_vector_type) = 1;\n+\n+\t      for (unsigned j = 0; j < count; j++)\n+\t\t{\n+\t\t  const char *d = (*dependencies)[j];\n+\t\t  len = strlen (d);\n+\t\t  tree dependency_name = build_string (len, d);\n+\t\t  TREE_TYPE (dependency_name)\n+\t\t    = build_array_type (char_type_node,\n+\t\t\t\t\tbuild_index_type (size_int (len)));\n+\n+\t\t  CONSTRUCTOR_APPEND_ELT\n+\t\t    (kernel_dependencies_vec, NULL_TREE,\n+\t\t     build1 (ADDR_EXPR,\n+\t\t\t     build_pointer_type (TREE_TYPE (dependency_name)),\n+\t\t\t     dependency_name));\n+\t\t}\n+\t    }\n+\t}\n+\n+      tree dependencies_count = build_int_cstu (unsigned_type_node, count);\n+\n+      vec<constructor_elt, va_gc> *kernel_info_vec = NULL;\n+      CONSTRUCTOR_APPEND_ELT (kernel_info_vec, NULL_TREE,\n+\t\t\t      build1 (ADDR_EXPR,\n+\t\t\t\t      build_pointer_type (TREE_TYPE\n+\t\t\t\t\t\t\t  (kern_name)),\n+\t\t\t\t      kern_name));\n+      CONSTRUCTOR_APPEND_ELT (kernel_info_vec, NULL_TREE, omp_data_size);\n+      CONSTRUCTOR_APPEND_ELT (kernel_info_vec, NULL_TREE,\n+\t\t\t      gridified_kernel_p_tree);\n+      CONSTRUCTOR_APPEND_ELT (kernel_info_vec, NULL_TREE, dependencies_count);\n+\n+      if (count > 0)\n+\t{\n+\t  ASM_GENERATE_INTERNAL_LABEL (tmp_name, \"__hsa_dependencies_list\", i);\n+\t  tree dependencies_list = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t\t       get_identifier (tmp_name),\n+\t\t\t\t\t       kernel_dependencies_vector_type);\n+\n+\t  TREE_STATIC (dependencies_list) = 1;\n+\t  TREE_READONLY (dependencies_list) = 1;\n+\t  TREE_PUBLIC (dependencies_list) = 0;\n+\t  DECL_ARTIFICIAL (dependencies_list) = 1;\n+\t  DECL_IGNORED_P (dependencies_list) = 1;\n+\t  DECL_EXTERNAL (dependencies_list) = 0;\n+\t  TREE_CONSTANT (dependencies_list) = 1;\n+\t  DECL_INITIAL (dependencies_list)\n+\t    = build_constructor (kernel_dependencies_vector_type,\n+\t\t\t\t kernel_dependencies_vec);\n+\t  varpool_node::finalize_decl (dependencies_list);\n+\n+\t  CONSTRUCTOR_APPEND_ELT (kernel_info_vec, NULL_TREE,\n+\t\t\t\t  build1 (ADDR_EXPR,\n+\t\t\t\t\t  build_pointer_type\n+\t\t\t\t\t    (TREE_TYPE (dependencies_list)),\n+\t\t\t\t\t  dependencies_list));\n+\t}\n+      else\n+\tCONSTRUCTOR_APPEND_ELT (kernel_info_vec, NULL_TREE, null_pointer_node);\n+\n+      tree kernel_info_ctor = build_constructor (kernel_info_type,\n+\t\t\t\t\t\t kernel_info_vec);\n+\n+      CONSTRUCTOR_APPEND_ELT (kernel_info_vector_vec, NULL_TREE,\n+\t\t\t      kernel_info_ctor);\n+    }\n+\n+  ASM_GENERATE_INTERNAL_LABEL (tmp_name, \"__hsa_kernels\", 1);\n+  tree hsa_kernels = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t get_identifier (tmp_name),\n+\t\t\t\t kernel_info_vector_type);\n+\n+  TREE_STATIC (hsa_kernels) = 1;\n+  TREE_READONLY (hsa_kernels) = 1;\n+  TREE_PUBLIC (hsa_kernels) = 0;\n+  DECL_ARTIFICIAL (hsa_kernels) = 1;\n+  DECL_IGNORED_P (hsa_kernels) = 1;\n+  DECL_EXTERNAL (hsa_kernels) = 0;\n+  TREE_CONSTANT (hsa_kernels) = 1;\n+  DECL_INITIAL (hsa_kernels) = build_constructor (kernel_info_vector_type,\n+\t\t\t\t\t\t  kernel_info_vector_vec);\n+  varpool_node::finalize_decl (hsa_kernels);\n+  *kernels = hsa_kernels;\n+}\n+\n+/* Create a static constructor that will register out brig stuff with\n+   libgomp.  */\n+\n+static void\n+hsa_output_libgomp_mapping (tree brig_decl)\n+{\n+  unsigned kernel_count = hsa_get_number_decl_kernel_mappings ();\n+  unsigned global_variable_count = hsa_global_variable_symbols->elements ();\n+\n+  tree kernels;\n+  tree host_func_table;\n+\n+  hsa_output_kernels (&host_func_table, &kernels);\n+  tree global_vars = hsa_output_global_variables ();\n+\n+  tree hsa_image_desc_type = make_node (RECORD_TYPE);\n+  tree id_f1 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"brig_module\"), ptr_type_node);\n+  DECL_CHAIN (id_f1) = NULL_TREE;\n+  tree id_f2 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"kernel_count\"),\n+\t\t\t   unsigned_type_node);\n+\n+  DECL_CHAIN (id_f2) = id_f1;\n+  tree id_f3 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"hsa_kernel_infos\"),\n+\t\t\t   ptr_type_node);\n+  DECL_CHAIN (id_f3) = id_f2;\n+  tree id_f4 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"global_variable_count\"),\n+\t\t\t   unsigned_type_node);\n+  DECL_CHAIN (id_f4) = id_f3;\n+  tree id_f5 = build_decl (BUILTINS_LOCATION, FIELD_DECL,\n+\t\t\t   get_identifier (\"hsa_global_variable_infos\"),\n+\t\t\t   ptr_type_node);\n+  DECL_CHAIN (id_f5) = id_f4;\n+  finish_builtin_struct (hsa_image_desc_type, \"__hsa_image_desc\", id_f5,\n+\t\t\t NULL_TREE);\n+  TYPE_ARTIFICIAL (hsa_image_desc_type) = 1;\n+\n+  vec<constructor_elt, va_gc> *img_desc_vec = NULL;\n+  CONSTRUCTOR_APPEND_ELT (img_desc_vec, NULL_TREE,\n+\t\t\t  build_fold_addr_expr (brig_decl));\n+  CONSTRUCTOR_APPEND_ELT (img_desc_vec, NULL_TREE,\n+\t\t\t  build_int_cstu (unsigned_type_node, kernel_count));\n+  CONSTRUCTOR_APPEND_ELT (img_desc_vec, NULL_TREE,\n+\t\t\t  build1 (ADDR_EXPR,\n+\t\t\t\t  build_pointer_type (TREE_TYPE (kernels)),\n+\t\t\t\t  kernels));\n+  CONSTRUCTOR_APPEND_ELT (img_desc_vec, NULL_TREE,\n+\t\t\t  build_int_cstu (unsigned_type_node,\n+\t\t\t\t\t  global_variable_count));\n+  CONSTRUCTOR_APPEND_ELT (img_desc_vec, NULL_TREE,\n+\t\t\t  build1 (ADDR_EXPR,\n+\t\t\t\t  build_pointer_type (TREE_TYPE (global_vars)),\n+\t\t\t\t  global_vars));\n+\n+  tree img_desc_ctor = build_constructor (hsa_image_desc_type, img_desc_vec);\n+\n+  char tmp_name[64];\n+  ASM_GENERATE_INTERNAL_LABEL (tmp_name, \"__hsa_img_descriptor\", 1);\n+  tree hsa_img_descriptor = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t\tget_identifier (tmp_name),\n+\t\t\t\t\thsa_image_desc_type);\n+  TREE_STATIC (hsa_img_descriptor) = 1;\n+  TREE_READONLY (hsa_img_descriptor) = 1;\n+  TREE_PUBLIC (hsa_img_descriptor) = 0;\n+  DECL_ARTIFICIAL (hsa_img_descriptor) = 1;\n+  DECL_IGNORED_P (hsa_img_descriptor) = 1;\n+  DECL_EXTERNAL (hsa_img_descriptor) = 0;\n+  TREE_CONSTANT (hsa_img_descriptor) = 1;\n+  DECL_INITIAL (hsa_img_descriptor) = img_desc_ctor;\n+  varpool_node::finalize_decl (hsa_img_descriptor);\n+\n+  /* Construct the \"host_table\" libgomp expects.  */\n+  tree index_type = build_index_type (build_int_cst (integer_type_node, 4));\n+  tree libgomp_host_table_type = build_array_type (ptr_type_node, index_type);\n+  TYPE_ARTIFICIAL (libgomp_host_table_type) = 1;\n+  vec<constructor_elt, va_gc> *libgomp_host_table_vec = NULL;\n+  tree host_func_table_addr = build_fold_addr_expr (host_func_table);\n+  CONSTRUCTOR_APPEND_ELT (libgomp_host_table_vec, NULL_TREE,\n+\t\t\t  host_func_table_addr);\n+  offset_int func_table_size\n+    = wi::to_offset (TYPE_SIZE_UNIT (ptr_type_node)) * kernel_count;\n+  CONSTRUCTOR_APPEND_ELT (libgomp_host_table_vec, NULL_TREE,\n+\t\t\t  fold_build2 (POINTER_PLUS_EXPR,\n+\t\t\t\t       TREE_TYPE (host_func_table_addr),\n+\t\t\t\t       host_func_table_addr,\n+\t\t\t\t       build_int_cst (size_type_node,\n+\t\t\t\t\t\t      func_table_size.to_uhwi\n+\t\t\t\t\t\t      ())));\n+  CONSTRUCTOR_APPEND_ELT (libgomp_host_table_vec, NULL_TREE, null_pointer_node);\n+  CONSTRUCTOR_APPEND_ELT (libgomp_host_table_vec, NULL_TREE, null_pointer_node);\n+  tree libgomp_host_table_ctor = build_constructor (libgomp_host_table_type,\n+\t\t\t\t\t\t    libgomp_host_table_vec);\n+  ASM_GENERATE_INTERNAL_LABEL (tmp_name, \"__hsa_libgomp_host_table\", 1);\n+  tree hsa_libgomp_host_table = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t\t    get_identifier (tmp_name),\n+\t\t\t\t\t    libgomp_host_table_type);\n+\n+  TREE_STATIC (hsa_libgomp_host_table) = 1;\n+  TREE_READONLY (hsa_libgomp_host_table) = 1;\n+  TREE_PUBLIC (hsa_libgomp_host_table) = 0;\n+  DECL_ARTIFICIAL (hsa_libgomp_host_table) = 1;\n+  DECL_IGNORED_P (hsa_libgomp_host_table) = 1;\n+  DECL_EXTERNAL (hsa_libgomp_host_table) = 0;\n+  TREE_CONSTANT (hsa_libgomp_host_table) = 1;\n+  DECL_INITIAL (hsa_libgomp_host_table) = libgomp_host_table_ctor;\n+  varpool_node::finalize_decl (hsa_libgomp_host_table);\n+\n+  /* Generate an initializer with a call to the registration routine.  */\n+\n+  tree offload_register\n+    = builtin_decl_explicit (BUILT_IN_GOMP_OFFLOAD_REGISTER);\n+  gcc_checking_assert (offload_register);\n+\n+  append_to_statement_list\n+    (build_call_expr (offload_register, 4,\n+\t\t      build_int_cstu (unsigned_type_node,\n+\t\t\t\t      GOMP_VERSION_PACK (GOMP_VERSION,\n+\t\t\t\t\t\t\t GOMP_VERSION_HSA)),\n+\t\t      build_fold_addr_expr (hsa_libgomp_host_table),\n+\t\t      build_int_cst (integer_type_node, GOMP_DEVICE_HSA),\n+\t\t      build_fold_addr_expr (hsa_img_descriptor)),\n+     &hsa_cdtor_statements[0]);\n+\n+  cgraph_build_static_cdtor ('I', hsa_cdtor_statements[0],\n+\t\t\t     DEFAULT_INIT_PRIORITY);\n+\n+  tree offload_unregister\n+    = builtin_decl_explicit (BUILT_IN_GOMP_OFFLOAD_UNREGISTER);\n+  gcc_checking_assert (offload_unregister);\n+\n+  append_to_statement_list\n+    (build_call_expr (offload_unregister, 4,\n+\t\t      build_int_cstu (unsigned_type_node,\n+\t\t\t\t      GOMP_VERSION_PACK (GOMP_VERSION,\n+\t\t\t\t\t\t\t GOMP_VERSION_HSA)),\n+\t\t      build_fold_addr_expr (hsa_libgomp_host_table),\n+\t\t      build_int_cst (integer_type_node, GOMP_DEVICE_HSA),\n+\t\t      build_fold_addr_expr (hsa_img_descriptor)),\n+     &hsa_cdtor_statements[1]);\n+  cgraph_build_static_cdtor ('D', hsa_cdtor_statements[1],\n+\t\t\t     DEFAULT_INIT_PRIORITY);\n+}\n+\n+/* Emit the brig module we have compiled to a section in the final assembly and\n+   also create a compile unit static constructor that will register the brig\n+   module with libgomp.  */\n+\n+void\n+hsa_output_brig (void)\n+{\n+  section *saved_section;\n+\n+  if (!brig_initialized)\n+    return;\n+\n+  for (unsigned i = 0; i < function_call_linkage.length (); i++)\n+    {\n+      function_linkage_pair p = function_call_linkage[i];\n+\n+      BrigCodeOffset32_t *func_offset = function_offsets->get (p.function_decl);\n+      gcc_assert (*func_offset);\n+      BrigOperandCodeRef *code_ref\n+\t= (BrigOperandCodeRef *) (brig_operand.get_ptr_by_offset (p.offset));\n+      gcc_assert (code_ref->base.kind == BRIG_KIND_OPERAND_CODE_REF);\n+      code_ref->ref = lendian32 (*func_offset);\n+    }\n+\n+  /* Iterate all function declarations and if we meet a function that should\n+     have module linkage and we are unable to emit HSAIL for the function,\n+     then change the linkage to program linkage.  Doing so, we will emit\n+     a valid BRIG image.  */\n+  if (hsa_failed_functions != NULL && emitted_declarations != NULL)\n+    for (hash_map <tree, BrigDirectiveExecutable *>::iterator it\n+\t = emitted_declarations->begin ();\n+\t it != emitted_declarations->end ();\n+\t ++it)\n+      {\n+\tif (hsa_failed_functions->contains ((*it).first))\n+\t  (*it).second->linkage = BRIG_LINKAGE_PROGRAM;\n+      }\n+\n+  saved_section = in_section;\n+\n+  switch_to_section (get_section (BRIG_ELF_SECTION_NAME, SECTION_NOTYPE, NULL));\n+  char tmp_name[64];\n+  ASM_GENERATE_INTERNAL_LABEL (tmp_name, BRIG_LABEL_STRING, 1);\n+  ASM_OUTPUT_LABEL (asm_out_file, tmp_name);\n+  tree brig_id = get_identifier (tmp_name);\n+  tree brig_decl = build_decl (UNKNOWN_LOCATION, VAR_DECL, brig_id,\n+\t\t\t       char_type_node);\n+  SET_DECL_ASSEMBLER_NAME (brig_decl, brig_id);\n+  TREE_ADDRESSABLE (brig_decl) = 1;\n+  TREE_READONLY (brig_decl) = 1;\n+  DECL_ARTIFICIAL (brig_decl) = 1;\n+  DECL_IGNORED_P (brig_decl) = 1;\n+  TREE_STATIC (brig_decl) = 1;\n+  TREE_PUBLIC (brig_decl) = 0;\n+  TREE_USED (brig_decl) = 1;\n+  DECL_INITIAL (brig_decl) = brig_decl;\n+  TREE_ASM_WRITTEN (brig_decl) = 1;\n+\n+  BrigModuleHeader module_header;\n+  memcpy (&module_header.identification, \"HSA BRIG\",\n+\t  sizeof (module_header.identification));\n+  module_header.brigMajor = lendian32 (BRIG_VERSION_BRIG_MAJOR);\n+  module_header.brigMinor = lendian32 (BRIG_VERSION_BRIG_MINOR);\n+  uint64_t section_index[3];\n+\n+  int data_padding, code_padding, operand_padding;\n+  data_padding = HSA_SECTION_ALIGNMENT\n+    - brig_data.total_size % HSA_SECTION_ALIGNMENT;\n+  code_padding = HSA_SECTION_ALIGNMENT\n+    - brig_code.total_size % HSA_SECTION_ALIGNMENT;\n+  operand_padding = HSA_SECTION_ALIGNMENT\n+    - brig_operand.total_size % HSA_SECTION_ALIGNMENT;\n+\n+  uint64_t module_size = sizeof (module_header)\n+    + sizeof (section_index)\n+    + brig_data.total_size\n+    + data_padding\n+    + brig_code.total_size\n+    + code_padding\n+    + brig_operand.total_size\n+    + operand_padding;\n+  gcc_assert ((module_size % 16) == 0);\n+  module_header.byteCount = lendian64 (module_size);\n+  memset (&module_header.hash, 0, sizeof (module_header.hash));\n+  module_header.reserved = 0;\n+  module_header.sectionCount = lendian32 (3);\n+  module_header.sectionIndex = lendian64 (sizeof (module_header));\n+  assemble_string ((const char *) &module_header, sizeof (module_header));\n+  uint64_t off = sizeof (module_header) + sizeof (section_index);\n+  section_index[0] = lendian64 (off);\n+  off += brig_data.total_size + data_padding;\n+  section_index[1] = lendian64 (off);\n+  off += brig_code.total_size + code_padding;\n+  section_index[2] = lendian64 (off);\n+  assemble_string ((const char *) &section_index, sizeof (section_index));\n+\n+  char padding[HSA_SECTION_ALIGNMENT];\n+  memset (padding, 0, sizeof (padding));\n+\n+  brig_data.output ();\n+  assemble_string (padding, data_padding);\n+  brig_code.output ();\n+  assemble_string (padding, code_padding);\n+  brig_operand.output ();\n+  assemble_string (padding, operand_padding);\n+\n+  if (saved_section)\n+    switch_to_section (saved_section);\n+\n+  hsa_output_libgomp_mapping (brig_decl);\n+\n+  hsa_free_decl_kernel_mapping ();\n+  brig_release_data ();\n+  hsa_deinit_compilation_unit_data ();\n+\n+  delete emitted_declarations;\n+  emitted_declarations = NULL;\n+  delete function_offsets;\n+  function_offsets = NULL;\n+}"}, {"sha": "c5f1f69cd39bf547115042f2b93db309cebbbc30", "filename": "gcc/hsa-dump.c", "status": "added", "additions": 1189, "deletions": 0, "changes": 1189, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-dump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-dump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa-dump.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,1189 @@\n+/* Infrastructure to dump our HSAIL IL\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+   Contributed by Martin Jambor <mjambor@suse.cz> and\n+   Martin Liska <mliska@suse.cz>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"is-a.h\"\n+#include \"vec.h\"\n+#include \"tree.h\"\n+#include \"cfg.h\"\n+#include \"function.h\"\n+#include \"dumpfile.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"cgraph.h\"\n+#include \"print-tree.h\"\n+#include \"symbol-summary.h\"\n+#include \"hsa.h\"\n+\n+/* Return textual name of TYPE.  */\n+\n+static const char *\n+hsa_type_name (BrigType16_t type)\n+{\n+  switch (type)\n+    {\n+    case BRIG_TYPE_NONE:\n+      return \"none\";\n+    case BRIG_TYPE_U8:\n+      return \"u8\";\n+    case BRIG_TYPE_U16:\n+      return \"u16\";\n+    case BRIG_TYPE_U32:\n+      return \"u32\";\n+    case BRIG_TYPE_U64:\n+      return \"u64\";\n+    case BRIG_TYPE_S8:\n+      return \"s8\";\n+    case BRIG_TYPE_S16:\n+      return \"s16\";\n+    case BRIG_TYPE_S32:\n+      return \"s32\";\n+    case BRIG_TYPE_S64:\n+      return \"s64\";\n+    case BRIG_TYPE_F16:\n+      return \"f16\";\n+    case BRIG_TYPE_F32:\n+      return \"f32\";\n+    case BRIG_TYPE_F64:\n+      return \"f64\";\n+    case BRIG_TYPE_B1:\n+      return \"b1\";\n+    case BRIG_TYPE_B8:\n+      return \"b8\";\n+    case BRIG_TYPE_B16:\n+      return \"b16\";\n+    case BRIG_TYPE_B32:\n+      return \"b32\";\n+    case BRIG_TYPE_B64:\n+      return \"b64\";\n+    case BRIG_TYPE_B128:\n+      return \"b128\";\n+    case BRIG_TYPE_SAMP:\n+      return \"samp\";\n+    case BRIG_TYPE_ROIMG:\n+      return \"roimg\";\n+    case BRIG_TYPE_WOIMG:\n+      return \"woimg\";\n+    case BRIG_TYPE_RWIMG:\n+      return \"rwimg\";\n+    case BRIG_TYPE_SIG32:\n+      return \"sig32\";\n+    case BRIG_TYPE_SIG64:\n+      return \"sig64\";\n+    case BRIG_TYPE_U8X4:\n+      return \"u8x4\";\n+    case BRIG_TYPE_U8X8:\n+      return \"u8x8\";\n+    case BRIG_TYPE_U8X16:\n+      return \"u8x16\";\n+    case BRIG_TYPE_U16X2:\n+      return \"u16x2\";\n+    case BRIG_TYPE_U16X4:\n+      return \"u16x4\";\n+    case BRIG_TYPE_U16X8:\n+      return \"u16x8\";\n+    case BRIG_TYPE_U32X2:\n+      return \"u32x2\";\n+    case BRIG_TYPE_U32X4:\n+      return \"u32x4\";\n+    case BRIG_TYPE_U64X2:\n+      return \"u64x2\";\n+    case BRIG_TYPE_S8X4:\n+      return \"s8x4\";\n+    case BRIG_TYPE_S8X8:\n+      return \"s8x8\";\n+    case BRIG_TYPE_S8X16:\n+      return \"s8x16\";\n+    case BRIG_TYPE_S16X2:\n+      return \"s16x2\";\n+    case BRIG_TYPE_S16X4:\n+      return \"s16x4\";\n+    case BRIG_TYPE_S16X8:\n+      return \"s16x8\";\n+    case BRIG_TYPE_S32X2:\n+      return \"s32x2\";\n+    case BRIG_TYPE_S32X4:\n+      return \"s32x4\";\n+    case BRIG_TYPE_S64X2:\n+      return \"s64x2\";\n+    case BRIG_TYPE_F16X2:\n+      return \"f16x2\";\n+    case BRIG_TYPE_F16X4:\n+      return \"f16x4\";\n+    case BRIG_TYPE_F16X8:\n+      return \"f16x8\";\n+    case BRIG_TYPE_F32X2:\n+      return \"f32x2\";\n+    case BRIG_TYPE_F32X4:\n+      return \"f32x4\";\n+    case BRIG_TYPE_F64X2:\n+      return \"f64x2\";\n+    default:\n+      return \"UNKNOWN_TYPE\";\n+    }\n+}\n+\n+/* Return textual name of OPCODE.  */\n+\n+static const char *\n+hsa_opcode_name (BrigOpcode16_t opcode)\n+{\n+  switch (opcode)\n+    {\n+    case BRIG_OPCODE_NOP:\n+      return \"nop\";\n+    case BRIG_OPCODE_ABS:\n+      return \"abs\";\n+    case BRIG_OPCODE_ADD:\n+      return \"add\";\n+    case BRIG_OPCODE_BORROW:\n+      return \"borrow\";\n+    case BRIG_OPCODE_CARRY:\n+      return \"carry\";\n+    case BRIG_OPCODE_CEIL:\n+      return \"ceil\";\n+    case BRIG_OPCODE_COPYSIGN:\n+      return \"copysign\";\n+    case BRIG_OPCODE_DIV:\n+      return \"div\";\n+    case BRIG_OPCODE_FLOOR:\n+      return \"floor\";\n+    case BRIG_OPCODE_FMA:\n+      return \"fma\";\n+    case BRIG_OPCODE_FRACT:\n+      return \"fract\";\n+    case BRIG_OPCODE_MAD:\n+      return \"mad\";\n+    case BRIG_OPCODE_MAX:\n+      return \"max\";\n+    case BRIG_OPCODE_MIN:\n+      return \"min\";\n+    case BRIG_OPCODE_MUL:\n+      return \"mul\";\n+    case BRIG_OPCODE_MULHI:\n+      return \"mulhi\";\n+    case BRIG_OPCODE_NEG:\n+      return \"neg\";\n+    case BRIG_OPCODE_REM:\n+      return \"rem\";\n+    case BRIG_OPCODE_RINT:\n+      return \"rint\";\n+    case BRIG_OPCODE_SQRT:\n+      return \"sqrt\";\n+    case BRIG_OPCODE_SUB:\n+      return \"sub\";\n+    case BRIG_OPCODE_TRUNC:\n+      return \"trunc\";\n+    case BRIG_OPCODE_MAD24:\n+      return \"mad24\";\n+    case BRIG_OPCODE_MAD24HI:\n+      return \"mad24hi\";\n+    case BRIG_OPCODE_MUL24:\n+      return \"mul24\";\n+    case BRIG_OPCODE_MUL24HI:\n+      return \"mul24hi\";\n+    case BRIG_OPCODE_SHL:\n+      return \"shl\";\n+    case BRIG_OPCODE_SHR:\n+      return \"shr\";\n+    case BRIG_OPCODE_AND:\n+      return \"and\";\n+    case BRIG_OPCODE_NOT:\n+      return \"not\";\n+    case BRIG_OPCODE_OR:\n+      return \"or\";\n+    case BRIG_OPCODE_POPCOUNT:\n+      return \"popcount\";\n+    case BRIG_OPCODE_XOR:\n+      return \"xor\";\n+    case BRIG_OPCODE_BITEXTRACT:\n+      return \"bitextract\";\n+    case BRIG_OPCODE_BITINSERT:\n+      return \"bitinsert\";\n+    case BRIG_OPCODE_BITMASK:\n+      return \"bitmask\";\n+    case BRIG_OPCODE_BITREV:\n+      return \"bitrev\";\n+    case BRIG_OPCODE_BITSELECT:\n+      return \"bitselect\";\n+    case BRIG_OPCODE_FIRSTBIT:\n+      return \"firstbit\";\n+    case BRIG_OPCODE_LASTBIT:\n+      return \"lastbit\";\n+    case BRIG_OPCODE_COMBINE:\n+      return \"combine\";\n+    case BRIG_OPCODE_EXPAND:\n+      return \"expand\";\n+    case BRIG_OPCODE_LDA:\n+      return \"lda\";\n+    case BRIG_OPCODE_MOV:\n+      return \"mov\";\n+    case BRIG_OPCODE_SHUFFLE:\n+      return \"shuffle\";\n+    case BRIG_OPCODE_UNPACKHI:\n+      return \"unpackhi\";\n+    case BRIG_OPCODE_UNPACKLO:\n+      return \"unpacklo\";\n+    case BRIG_OPCODE_PACK:\n+      return \"pack\";\n+    case BRIG_OPCODE_UNPACK:\n+      return \"unpack\";\n+    case BRIG_OPCODE_CMOV:\n+      return \"cmov\";\n+    case BRIG_OPCODE_CLASS:\n+      return \"class\";\n+    case BRIG_OPCODE_NCOS:\n+      return \"ncos\";\n+    case BRIG_OPCODE_NEXP2:\n+      return \"nexp2\";\n+    case BRIG_OPCODE_NFMA:\n+      return \"nfma\";\n+    case BRIG_OPCODE_NLOG2:\n+      return \"nlog2\";\n+    case BRIG_OPCODE_NRCP:\n+      return \"nrcp\";\n+    case BRIG_OPCODE_NRSQRT:\n+      return \"nrsqrt\";\n+    case BRIG_OPCODE_NSIN:\n+      return \"nsin\";\n+    case BRIG_OPCODE_NSQRT:\n+      return \"nsqrt\";\n+    case BRIG_OPCODE_BITALIGN:\n+      return \"bitalign\";\n+    case BRIG_OPCODE_BYTEALIGN:\n+      return \"bytealign\";\n+    case BRIG_OPCODE_PACKCVT:\n+      return \"packcvt\";\n+    case BRIG_OPCODE_UNPACKCVT:\n+      return \"unpackcvt\";\n+    case BRIG_OPCODE_LERP:\n+      return \"lerp\";\n+    case BRIG_OPCODE_SAD:\n+      return \"sad\";\n+    case BRIG_OPCODE_SADHI:\n+      return \"sadhi\";\n+    case BRIG_OPCODE_SEGMENTP:\n+      return \"segmentp\";\n+    case BRIG_OPCODE_FTOS:\n+      return \"ftos\";\n+    case BRIG_OPCODE_STOF:\n+      return \"stof\";\n+    case BRIG_OPCODE_CMP:\n+      return \"cmp\";\n+    case BRIG_OPCODE_CVT:\n+      return \"cvt\";\n+    case BRIG_OPCODE_LD:\n+      return \"ld\";\n+    case BRIG_OPCODE_ST:\n+      return \"st\";\n+    case BRIG_OPCODE_ATOMIC:\n+      return \"atomic\";\n+    case BRIG_OPCODE_ATOMICNORET:\n+      return \"atomicnoret\";\n+    case BRIG_OPCODE_SIGNAL:\n+      return \"signal\";\n+    case BRIG_OPCODE_SIGNALNORET:\n+      return \"signalnoret\";\n+    case BRIG_OPCODE_MEMFENCE:\n+      return \"memfence\";\n+    case BRIG_OPCODE_RDIMAGE:\n+      return \"rdimage\";\n+    case BRIG_OPCODE_LDIMAGE:\n+      return \"ldimage\";\n+    case BRIG_OPCODE_STIMAGE:\n+      return \"stimage\";\n+    case BRIG_OPCODE_QUERYIMAGE:\n+      return \"queryimage\";\n+    case BRIG_OPCODE_QUERYSAMPLER:\n+      return \"querysampler\";\n+    case BRIG_OPCODE_CBR:\n+      return \"cbr\";\n+    case BRIG_OPCODE_BR:\n+      return \"br\";\n+    case BRIG_OPCODE_SBR:\n+      return \"sbr\";\n+    case BRIG_OPCODE_BARRIER:\n+      return \"barrier\";\n+    case BRIG_OPCODE_WAVEBARRIER:\n+      return \"wavebarrier\";\n+    case BRIG_OPCODE_ARRIVEFBAR:\n+      return \"arrivefbar\";\n+    case BRIG_OPCODE_INITFBAR:\n+      return \"initfbar\";\n+    case BRIG_OPCODE_JOINFBAR:\n+      return \"joinfbar\";\n+    case BRIG_OPCODE_LEAVEFBAR:\n+      return \"leavefbar\";\n+    case BRIG_OPCODE_RELEASEFBAR:\n+      return \"releasefbar\";\n+    case BRIG_OPCODE_WAITFBAR:\n+      return \"waitfbar\";\n+    case BRIG_OPCODE_LDF:\n+      return \"ldf\";\n+    case BRIG_OPCODE_ACTIVELANECOUNT:\n+      return \"activelanecount\";\n+    case BRIG_OPCODE_ACTIVELANEID:\n+      return \"activelaneid\";\n+    case BRIG_OPCODE_ACTIVELANEMASK:\n+      return \"activelanemask\";\n+    case BRIG_OPCODE_CALL:\n+      return \"call\";\n+    case BRIG_OPCODE_SCALL:\n+      return \"scall\";\n+    case BRIG_OPCODE_ICALL:\n+      return \"icall\";\n+    case BRIG_OPCODE_RET:\n+      return \"ret\";\n+    case BRIG_OPCODE_ALLOCA:\n+      return \"alloca\";\n+    case BRIG_OPCODE_CURRENTWORKGROUPSIZE:\n+      return \"currentworkgroupsize\";\n+    case BRIG_OPCODE_DIM:\n+      return \"dim\";\n+    case BRIG_OPCODE_GRIDGROUPS:\n+      return \"gridgroups\";\n+    case BRIG_OPCODE_GRIDSIZE:\n+      return \"gridsize\";\n+    case BRIG_OPCODE_PACKETCOMPLETIONSIG:\n+      return \"packetcompletionsig\";\n+    case BRIG_OPCODE_PACKETID:\n+      return \"packetid\";\n+    case BRIG_OPCODE_WORKGROUPID:\n+      return \"workgroupid\";\n+    case BRIG_OPCODE_WORKGROUPSIZE:\n+      return \"workgroupsize\";\n+    case BRIG_OPCODE_WORKITEMABSID:\n+      return \"workitemabsid\";\n+    case BRIG_OPCODE_WORKITEMFLATABSID:\n+      return \"workitemflatabsid\";\n+    case BRIG_OPCODE_WORKITEMFLATID:\n+      return \"workitemflatid\";\n+    case BRIG_OPCODE_WORKITEMID:\n+      return \"workitemid\";\n+    case BRIG_OPCODE_CLEARDETECTEXCEPT:\n+      return \"cleardetectexcept\";\n+    case BRIG_OPCODE_GETDETECTEXCEPT:\n+      return \"getdetectexcept\";\n+    case BRIG_OPCODE_SETDETECTEXCEPT:\n+      return \"setdetectexcept\";\n+    case BRIG_OPCODE_ADDQUEUEWRITEINDEX:\n+      return \"addqueuewriteindex\";\n+    case BRIG_OPCODE_CASQUEUEWRITEINDEX:\n+      return \"casqueuewriteindex\";\n+    case BRIG_OPCODE_LDQUEUEREADINDEX:\n+      return \"ldqueuereadindex\";\n+    case BRIG_OPCODE_LDQUEUEWRITEINDEX:\n+      return \"ldqueuewriteindex\";\n+    case BRIG_OPCODE_STQUEUEREADINDEX:\n+      return \"stqueuereadindex\";\n+    case BRIG_OPCODE_STQUEUEWRITEINDEX:\n+      return \"stqueuewriteindex\";\n+    case BRIG_OPCODE_CLOCK:\n+      return \"clock\";\n+    case BRIG_OPCODE_CUID:\n+      return \"cuid\";\n+    case BRIG_OPCODE_DEBUGTRAP:\n+      return \"debugtrap\";\n+    case BRIG_OPCODE_GROUPBASEPTR:\n+      return \"groupbaseptr\";\n+    case BRIG_OPCODE_KERNARGBASEPTR:\n+      return \"kernargbaseptr\";\n+    case BRIG_OPCODE_LANEID:\n+      return \"laneid\";\n+    case BRIG_OPCODE_MAXCUID:\n+      return \"maxcuid\";\n+    case BRIG_OPCODE_MAXWAVEID:\n+      return \"maxwaveid\";\n+    case BRIG_OPCODE_NULLPTR:\n+      return \"nullptr\";\n+    case BRIG_OPCODE_WAVEID:\n+      return \"waveid\";\n+    default:\n+      return \"UNKNOWN_OPCODE\";\n+    }\n+}\n+\n+/* Return textual name of SEG.  */\n+\n+const char *\n+hsa_seg_name (BrigSegment8_t seg)\n+{\n+  switch (seg)\n+    {\n+    case BRIG_SEGMENT_NONE:\n+      return \"none\";\n+    case BRIG_SEGMENT_FLAT:\n+      return \"flat\";\n+    case BRIG_SEGMENT_GLOBAL:\n+      return \"global\";\n+    case BRIG_SEGMENT_READONLY:\n+      return \"readonly\";\n+    case BRIG_SEGMENT_KERNARG:\n+      return \"kernarg\";\n+    case BRIG_SEGMENT_GROUP:\n+      return \"group\";\n+    case BRIG_SEGMENT_PRIVATE:\n+      return \"private\";\n+    case BRIG_SEGMENT_SPILL:\n+      return \"spill\";\n+    case BRIG_SEGMENT_ARG:\n+      return \"arg\";\n+    default:\n+      return \"UNKNOWN_SEGMENT\";\n+    }\n+}\n+\n+/* Return textual name of CMPOP.  */\n+\n+static const char *\n+hsa_cmpop_name (BrigCompareOperation8_t cmpop)\n+{\n+  switch (cmpop)\n+    {\n+    case BRIG_COMPARE_EQ:\n+      return \"eq\";\n+    case BRIG_COMPARE_NE:\n+      return \"ne\";\n+    case BRIG_COMPARE_LT:\n+      return \"lt\";\n+    case BRIG_COMPARE_LE:\n+      return \"le\";\n+    case BRIG_COMPARE_GT:\n+      return \"gt\";\n+    case BRIG_COMPARE_GE:\n+      return \"ge\";\n+    case BRIG_COMPARE_EQU:\n+      return \"equ\";\n+    case BRIG_COMPARE_NEU:\n+      return \"neu\";\n+    case BRIG_COMPARE_LTU:\n+      return \"ltu\";\n+    case BRIG_COMPARE_LEU:\n+      return \"leu\";\n+    case BRIG_COMPARE_GTU:\n+      return \"gtu\";\n+    case BRIG_COMPARE_GEU:\n+      return \"geu\";\n+    case BRIG_COMPARE_NUM:\n+      return \"num\";\n+    case BRIG_COMPARE_NAN:\n+      return \"nan\";\n+    case BRIG_COMPARE_SEQ:\n+      return \"seq\";\n+    case BRIG_COMPARE_SNE:\n+      return \"sne\";\n+    case BRIG_COMPARE_SLT:\n+      return \"slt\";\n+    case BRIG_COMPARE_SLE:\n+      return \"sle\";\n+    case BRIG_COMPARE_SGT:\n+      return \"sgt\";\n+    case BRIG_COMPARE_SGE:\n+      return \"sge\";\n+    case BRIG_COMPARE_SGEU:\n+      return \"sgeu\";\n+    case BRIG_COMPARE_SEQU:\n+      return \"sequ\";\n+    case BRIG_COMPARE_SNEU:\n+      return \"sneu\";\n+    case BRIG_COMPARE_SLTU:\n+      return \"sltu\";\n+    case BRIG_COMPARE_SLEU:\n+      return \"sleu\";\n+    case BRIG_COMPARE_SNUM:\n+      return \"snum\";\n+    case BRIG_COMPARE_SNAN:\n+      return \"snan\";\n+    case BRIG_COMPARE_SGTU:\n+      return \"sgtu\";\n+    default:\n+      return \"UNKNOWN_COMPARISON\";\n+    }\n+}\n+\n+/* Return textual name for memory order.  */\n+\n+static const char *\n+hsa_memsem_name (enum BrigMemoryOrder mo)\n+{\n+  switch (mo)\n+    {\n+    case BRIG_MEMORY_ORDER_NONE:\n+      return \"\";\n+    case BRIG_MEMORY_ORDER_RELAXED:\n+      return \"rlx\";\n+    case BRIG_MEMORY_ORDER_SC_ACQUIRE:\n+      return \"scacq\";\n+    case BRIG_MEMORY_ORDER_SC_RELEASE:\n+      return \"screl\";\n+    case BRIG_MEMORY_ORDER_SC_ACQUIRE_RELEASE:\n+      return \"scar\";\n+    default:\n+      return \"UNKNOWN_MEMORY_ORDER\";\n+    }\n+}\n+\n+/* Return textual name for memory scope.  */\n+\n+static const char *\n+hsa_memscope_name (enum BrigMemoryScope scope)\n+{\n+  switch (scope)\n+    {\n+    case BRIG_MEMORY_SCOPE_NONE:\n+      return \"\";\n+    case BRIG_MEMORY_SCOPE_WORKITEM:\n+      return \"wi\";\n+    case BRIG_MEMORY_SCOPE_WAVEFRONT:\n+      return \"wave\";\n+    case BRIG_MEMORY_SCOPE_WORKGROUP:\n+      return \"wg\";\n+    case BRIG_MEMORY_SCOPE_AGENT:\n+      return \"agent\";\n+    case BRIG_MEMORY_SCOPE_SYSTEM:\n+      return \"sys\";\n+    default:\n+      return \"UNKNOWN_SCOPE\";\n+    }\n+}\n+\n+/* Return textual name for atomic operation.  */\n+\n+static const char *\n+hsa_m_atomicop_name (enum BrigAtomicOperation op)\n+{\n+  switch (op)\n+    {\n+    case BRIG_ATOMIC_ADD:\n+      return \"add\";\n+    case BRIG_ATOMIC_AND:\n+      return \"and\";\n+    case BRIG_ATOMIC_CAS:\n+      return \"cas\";\n+    case BRIG_ATOMIC_EXCH:\n+      return \"exch\";\n+    case BRIG_ATOMIC_LD:\n+      return \"ld\";\n+    case BRIG_ATOMIC_MAX:\n+      return \"max\";\n+    case BRIG_ATOMIC_MIN:\n+      return \"min\";\n+    case BRIG_ATOMIC_OR:\n+      return \"or\";\n+    case BRIG_ATOMIC_ST:\n+      return \"st\";\n+    case BRIG_ATOMIC_SUB:\n+      return \"sub\";\n+    case BRIG_ATOMIC_WRAPDEC:\n+      return \"wrapdec\";\n+    case BRIG_ATOMIC_WRAPINC:\n+      return \"wrapinc\";\n+    case BRIG_ATOMIC_XOR:\n+      return \"xor\";\n+    case BRIG_ATOMIC_WAIT_EQ:\n+      return \"wait_eq\";\n+    case BRIG_ATOMIC_WAIT_NE:\n+      return \"wait_ne\";\n+    case BRIG_ATOMIC_WAIT_LT:\n+      return \"wait_lt\";\n+    case BRIG_ATOMIC_WAIT_GTE:\n+      return \"wait_gte\";\n+    case BRIG_ATOMIC_WAITTIMEOUT_EQ:\n+      return \"waittimeout_eq\";\n+    case BRIG_ATOMIC_WAITTIMEOUT_NE:\n+      return \"waittimeout_ne\";\n+    case BRIG_ATOMIC_WAITTIMEOUT_LT:\n+      return \"waittimeout_lt\";\n+    case BRIG_ATOMIC_WAITTIMEOUT_GTE:\n+      return \"waittimeout_gte\";\n+    default:\n+      return \"UNKNOWN_ATOMIC_OP\";\n+    }\n+}\n+\n+/* Return byte alignment for given BrigAlignment8_t value.  */\n+\n+static unsigned\n+hsa_byte_alignment (BrigAlignment8_t alignment)\n+{\n+  gcc_assert (alignment != BRIG_ALIGNMENT_NONE);\n+\n+  return 1 << (alignment - 1);\n+}\n+\n+/* Dump textual representation of HSA IL register REG to file F.  */\n+\n+static void\n+dump_hsa_reg (FILE *f, hsa_op_reg *reg, bool dump_type = false)\n+{\n+  if (reg->m_reg_class)\n+    fprintf (f, \"$%c%i\", reg->m_reg_class, reg->m_hard_num);\n+  else\n+    fprintf (f, \"$_%i\", reg->m_order);\n+  if (dump_type)\n+    fprintf (f, \" (%s)\", hsa_type_name (reg->m_type));\n+}\n+\n+/* Dump textual representation of HSA IL immediate operand IMM to file F.  */\n+\n+static void\n+dump_hsa_immed (FILE *f, hsa_op_immed *imm)\n+{\n+  bool unsigned_int_type\n+    = (BRIG_TYPE_U8 | BRIG_TYPE_U16 | BRIG_TYPE_U32 | BRIG_TYPE_U64)\n+    & imm->m_type;\n+\n+  if (imm->m_tree_value)\n+    print_generic_expr (f, imm->m_tree_value, 0);\n+  else\n+    {\n+      gcc_checking_assert (imm->m_brig_repr_size <= 8);\n+\n+      if (unsigned_int_type)\n+\tfprintf (f, HOST_WIDE_INT_PRINT_DEC, imm->m_int_value);\n+      else\n+\tfprintf (f, HOST_WIDE_INT_PRINT_UNSIGNED,\n+\t\t (unsigned HOST_WIDE_INT) imm->m_int_value);\n+    }\n+\n+  fprintf (f, \" (%s)\", hsa_type_name (imm->m_type));\n+}\n+\n+/* Dump textual representation of HSA IL address operand ADDR to file F.  */\n+\n+static void\n+dump_hsa_address (FILE *f, hsa_op_address *addr)\n+{\n+  bool sth = false;\n+\n+  if (addr->m_symbol)\n+    {\n+      sth = true;\n+      if (addr->m_symbol->m_name)\n+\tfprintf (f, \"[%%%s]\", addr->m_symbol->m_name);\n+      else\n+\tfprintf (f, \"[%%__%s_%i]\", hsa_seg_name (addr->m_symbol->m_segment),\n+\t\t addr->m_symbol->m_name_number);\n+    }\n+\n+  if (addr->m_reg)\n+    {\n+      fprintf (f, \"[\");\n+      dump_hsa_reg (f, addr->m_reg);\n+      if (addr->m_imm_offset != 0)\n+\tfprintf (f, \" + \" HOST_WIDE_INT_PRINT_DEC \"]\", addr->m_imm_offset);\n+      else\n+\tfprintf (f, \"]\");\n+    }\n+  else if (!sth || addr->m_imm_offset != 0)\n+    fprintf (f, \"[\" HOST_WIDE_INT_PRINT_DEC \"]\", addr->m_imm_offset);\n+}\n+\n+/* Dump textual representation of HSA IL symbol SYMBOL to file F.  */\n+\n+static void\n+dump_hsa_symbol (FILE *f, hsa_symbol *symbol)\n+{\n+  const char *name;\n+  if (symbol->m_name)\n+    name = symbol->m_name;\n+  else\n+    {\n+      char buf[64];\n+      sprintf (buf, \"__%s_%i\", hsa_seg_name (symbol->m_segment),\n+\t       symbol->m_name_number);\n+\n+      name = buf;\n+    }\n+\n+  fprintf (f, \"%s_%s %s\", hsa_seg_name (symbol->m_segment),\n+\t   hsa_type_name (symbol->m_type & ~BRIG_TYPE_ARRAY_MASK), name);\n+\n+  if (symbol->m_type & BRIG_TYPE_ARRAY_MASK)\n+    fprintf (f, \"[%lu]\", (unsigned long) symbol->m_dim);\n+}\n+\n+/* Dump textual representation of HSA IL operand OP to file F.  */\n+\n+static void\n+dump_hsa_operand (FILE *f, hsa_op_base *op, bool dump_reg_type = false)\n+{\n+  if (is_a <hsa_op_immed *> (op))\n+    dump_hsa_immed (f, as_a <hsa_op_immed *> (op));\n+  else if (is_a <hsa_op_reg *> (op))\n+    dump_hsa_reg (f, as_a <hsa_op_reg *> (op), dump_reg_type);\n+  else if (is_a <hsa_op_address *> (op))\n+    dump_hsa_address (f, as_a <hsa_op_address *> (op));\n+  else\n+    fprintf (f, \"UNKNOWN_OP_KIND\");\n+}\n+\n+/* Dump textual representation of HSA IL operands in VEC to file F.  */\n+\n+static void\n+dump_hsa_operands (FILE *f, hsa_insn_basic *insn, int start = 0,\n+\t\t   int end = -1, bool dump_reg_type = false)\n+{\n+  if (end == -1)\n+    end = insn->operand_count ();\n+\n+  for (int i = start; i < end; i++)\n+    {\n+      dump_hsa_operand (f, insn->get_op (i), dump_reg_type);\n+      if (i != end - 1)\n+\tfprintf (f, \", \");\n+    }\n+}\n+\n+/* Indent F stream with INDENT spaces.  */\n+\n+static void indent_stream (FILE *f, int indent)\n+{\n+  for (int i = 0; i < indent; i++)\n+    fputc (' ', f);\n+}\n+\n+/* Dump textual representation of HSA IL instruction INSN to file F.  Prepend\n+   the instruction with *INDENT spaces and adjust the indentation for call\n+   instructions as appropriate.  */\n+\n+static void\n+dump_hsa_insn_1 (FILE *f, hsa_insn_basic *insn, int *indent)\n+{\n+  gcc_checking_assert (insn);\n+\n+  if (insn->m_number)\n+    fprintf (f, \"%5d: \", insn->m_number);\n+\n+  indent_stream (f, *indent);\n+\n+  if (is_a <hsa_insn_phi *> (insn))\n+    {\n+      hsa_insn_phi *phi = as_a <hsa_insn_phi *> (insn);\n+      bool first = true;\n+      dump_hsa_reg (f, phi->m_dest, true);\n+      fprintf (f, \" = PHI <\");\n+      unsigned count = phi->operand_count ();\n+      for (unsigned i = 0; i < count; i++)\n+\t{\n+\t  if (!phi->get_op (i))\n+\t    break;\n+\t  if (!first)\n+\t    fprintf (f, \", \");\n+\t  else\n+\t    first = false;\n+\t  dump_hsa_operand (f, phi->get_op (i), true);\n+\t}\n+      fprintf (f, \">\");\n+    }\n+  else if (is_a <hsa_insn_signal *> (insn))\n+    {\n+      hsa_insn_signal *mem = as_a <hsa_insn_signal *> (insn);\n+\n+      fprintf (f, \"%s\", hsa_opcode_name (mem->m_opcode));\n+      fprintf (f, \"_%s\", hsa_m_atomicop_name (mem->m_atomicop));\n+      if (mem->m_memoryorder != BRIG_MEMORY_ORDER_NONE)\n+\tfprintf (f, \"_%s\", hsa_memsem_name (mem->m_memoryorder));\n+      fprintf (f, \"_%s \", hsa_type_name (mem->m_type));\n+\n+      dump_hsa_operands (f, mem);\n+    }\n+\n+  else if (is_a <hsa_insn_atomic *> (insn))\n+    {\n+      hsa_insn_atomic *mem = as_a <hsa_insn_atomic *> (insn);\n+\n+      /* Either operand[0] or operand[1] must be an address operand.  */\n+      hsa_op_address *addr = NULL;\n+      if (is_a <hsa_op_address *> (mem->get_op (0)))\n+\taddr = as_a <hsa_op_address *> (mem->get_op (0));\n+      else\n+\taddr = as_a <hsa_op_address *> (mem->get_op (1));\n+\n+      fprintf (f, \"%s\", hsa_opcode_name (mem->m_opcode));\n+      fprintf (f, \"_%s\", hsa_m_atomicop_name (mem->m_atomicop));\n+      if (addr->m_symbol)\n+\tfprintf (f, \"_%s\", hsa_seg_name (addr->m_symbol->m_segment));\n+      if (mem->m_memoryorder != BRIG_MEMORY_ORDER_NONE)\n+\tfprintf (f, \"_%s\", hsa_memsem_name (mem->m_memoryorder));\n+      if (mem->m_memoryscope != BRIG_MEMORY_SCOPE_NONE)\n+\tfprintf (f, \"_%s\", hsa_memscope_name (mem->m_memoryscope));\n+      fprintf (f, \"_%s \", hsa_type_name (mem->m_type));\n+\n+      dump_hsa_operands (f, mem);\n+    }\n+  else if (is_a <hsa_insn_mem *> (insn))\n+    {\n+      hsa_insn_mem *mem = as_a <hsa_insn_mem *> (insn);\n+      hsa_op_address *addr = as_a <hsa_op_address *> (mem->get_op (1));\n+\n+      fprintf (f, \"%s\", hsa_opcode_name (mem->m_opcode));\n+      if (addr->m_symbol)\n+\tfprintf (f, \"_%s\", hsa_seg_name (addr->m_symbol->m_segment));\n+      if (mem->m_align != BRIG_ALIGNMENT_NONE)\n+\tfprintf (f, \"_align(%u)\", hsa_byte_alignment (mem->m_align));\n+      if (mem->m_equiv_class != 0)\n+\tfprintf (f, \"_equiv(%i)\", mem->m_equiv_class);\n+      fprintf (f, \"_%s \", hsa_type_name (mem->m_type));\n+\n+      dump_hsa_operand (f, mem->get_op (0));\n+      fprintf (f, \", \");\n+      dump_hsa_address (f, addr);\n+    }\n+  else if (insn->m_opcode == BRIG_OPCODE_LDA)\n+    {\n+      hsa_op_address *addr = as_a <hsa_op_address *> (insn->get_op (1));\n+\n+      fprintf (f, \"%s\", hsa_opcode_name (insn->m_opcode));\n+      if (addr->m_symbol)\n+\tfprintf (f, \"_%s\", hsa_seg_name (addr->m_symbol->m_segment));\n+      fprintf (f, \"_%s \", hsa_type_name (insn->m_type));\n+\n+      dump_hsa_operand (f, insn->get_op (0));\n+      fprintf (f, \", \");\n+      dump_hsa_address (f, addr);\n+    }\n+  else if (is_a <hsa_insn_seg *> (insn))\n+    {\n+      hsa_insn_seg *seg = as_a <hsa_insn_seg *> (insn);\n+      fprintf (f, \"%s_%s_%s_%s \", hsa_opcode_name (seg->m_opcode),\n+\t       hsa_seg_name (seg->m_segment),\n+\t       hsa_type_name (seg->m_type), hsa_type_name (seg->m_src_type));\n+      dump_hsa_reg (f, as_a <hsa_op_reg *> (seg->get_op (0)));\n+      fprintf (f, \", \");\n+      dump_hsa_operand (f, seg->get_op (1));\n+    }\n+  else if (is_a <hsa_insn_cmp *> (insn))\n+    {\n+      hsa_insn_cmp *cmp = as_a <hsa_insn_cmp *> (insn);\n+      BrigType16_t src_type;\n+\n+      if (is_a <hsa_op_reg *> (cmp->get_op (1)))\n+\tsrc_type = as_a <hsa_op_reg *> (cmp->get_op (1))->m_type;\n+      else\n+\tsrc_type = as_a <hsa_op_immed *> (cmp->get_op (1))->m_type;\n+\n+      fprintf (f, \"%s_%s_%s_%s \", hsa_opcode_name (cmp->m_opcode),\n+\t       hsa_cmpop_name (cmp->m_compare),\n+\t       hsa_type_name (cmp->m_type), hsa_type_name (src_type));\n+      dump_hsa_reg (f, as_a <hsa_op_reg *> (cmp->get_op (0)));\n+      fprintf (f, \", \");\n+      dump_hsa_operand (f, cmp->get_op (1));\n+      fprintf (f, \", \");\n+      dump_hsa_operand (f, cmp->get_op (2));\n+    }\n+  else if (is_a <hsa_insn_br *> (insn))\n+    {\n+      hsa_insn_br *br = as_a <hsa_insn_br *> (insn);\n+      basic_block target = NULL;\n+      edge_iterator ei;\n+      edge e;\n+\n+      fprintf (f, \"%s \", hsa_opcode_name (br->m_opcode));\n+      if (br->m_opcode == BRIG_OPCODE_CBR)\n+\t{\n+\t  dump_hsa_reg (f, as_a <hsa_op_reg *> (br->get_op (0)));\n+\t  fprintf (f, \", \");\n+\t}\n+\n+      FOR_EACH_EDGE (e, ei, br->m_bb->succs)\n+\tif (e->flags & EDGE_TRUE_VALUE)\n+\t  {\n+\t    target = e->dest;\n+\t    break;\n+\t  }\n+      fprintf (f, \"BB %i\", hsa_bb_for_bb (target)->m_index);\n+    }\n+  else if (is_a <hsa_insn_sbr *> (insn))\n+    {\n+      hsa_insn_sbr *sbr = as_a <hsa_insn_sbr *> (insn);\n+\n+      fprintf (f, \"%s \", hsa_opcode_name (sbr->m_opcode));\n+      dump_hsa_reg (f, as_a <hsa_op_reg *> (sbr->get_op (0)));\n+      fprintf (f, \", [\");\n+\n+      for (unsigned i = 0; i < sbr->m_jump_table.length (); i++)\n+\t{\n+\t  fprintf (f, \"BB %i\", hsa_bb_for_bb (sbr->m_jump_table[i])->m_index);\n+\t  if (i != sbr->m_jump_table.length () - 1)\n+\t    fprintf (f, \", \");\n+\t}\n+\n+      fprintf (f, \"]\");\n+    }\n+  else if (is_a <hsa_insn_arg_block *> (insn))\n+    {\n+      hsa_insn_arg_block *arg_block = as_a <hsa_insn_arg_block *> (insn);\n+      bool start_p = arg_block->m_kind == BRIG_KIND_DIRECTIVE_ARG_BLOCK_START;\n+      char c = start_p ? '{' : '}';\n+\n+      if (start_p)\n+\t{\n+\t  *indent += 2;\n+\t  indent_stream (f, 2);\n+\t}\n+\n+      if (!start_p)\n+\t*indent -= 2;\n+\n+      fprintf (f, \"%c\", c);\n+    }\n+  else if (is_a <hsa_insn_call *> (insn))\n+    {\n+      hsa_insn_call *call = as_a <hsa_insn_call *> (insn);\n+      if (call->m_called_function)\n+\t{\n+\t  const char *name = hsa_get_declaration_name (call->m_called_function);\n+\t  fprintf (f, \"call &%s\", name);\n+\t}\n+      else\n+\t{\n+\t  char *name = call->m_called_internal_fn->name ();\n+\t  fprintf (f, \"call &%s\", name);\n+\t  free (name);\n+\t}\n+\n+      if (call->m_output_arg)\n+\tfprintf (f, \"(%%res) \");\n+\n+      fprintf (f, \"(\");\n+      for (unsigned i = 0; i < call->m_input_args.length (); i++)\n+\t{\n+\t  fprintf (f, \"%%__arg_%u\", i);\n+\n+\t  if (i != call->m_input_args.length () - 1)\n+\t    fprintf (f, \", \");\n+\t}\n+      fprintf (f, \")\");\n+    }\n+  else if (is_a <hsa_insn_comment *> (insn))\n+    {\n+      hsa_insn_comment *c = as_a <hsa_insn_comment *> (insn);\n+      fprintf (f, \"%s\", c->m_comment);\n+    }\n+  else if (is_a <hsa_insn_srctype *> (insn))\n+    {\n+      hsa_insn_srctype *srctype = as_a <hsa_insn_srctype *> (insn);\n+\n+      fprintf (f, \"%s_%s_%s \", hsa_opcode_name (srctype->m_opcode),\n+\t       hsa_type_name (srctype->m_type),\n+\t       hsa_type_name (srctype->m_source_type));\n+\n+      dump_hsa_operands (f, insn);\n+    }\n+  else if (is_a <hsa_insn_packed *> (insn))\n+    {\n+      hsa_insn_packed *packed = as_a <hsa_insn_packed *> (insn);\n+\n+      fprintf (f, \"%s_v%u_%s_%s \", hsa_opcode_name (packed->m_opcode),\n+\t       packed->operand_count () - 1,\n+\t       hsa_type_name (packed->m_type),\n+\t       hsa_type_name (packed->m_source_type));\n+\n+      if (packed->m_opcode == BRIG_OPCODE_COMBINE)\n+\t{\n+\t  dump_hsa_operand (f, insn->get_op (0));\n+\t  fprintf (f, \", (\");\n+\t  dump_hsa_operands (f, insn, 1);\n+\t  fprintf (f, \")\");\n+\t}\n+      else if (packed->m_opcode == BRIG_OPCODE_EXPAND)\n+\t{\n+\t  fprintf (f, \"(\");\n+\t  dump_hsa_operands (f, insn, 0, insn->operand_count () - 1);\n+\t  fprintf (f, \"), \");\n+\t  dump_hsa_operand (f, insn->get_op (insn->operand_count () - 1));\n+\n+\t}\n+      else\n+\tgcc_unreachable ();\n+    }\n+  else if (is_a <hsa_insn_alloca *> (insn))\n+    {\n+      hsa_insn_alloca *alloca = as_a <hsa_insn_alloca *> (insn);\n+\n+      fprintf (f, \"%s_align(%u)_%s \", hsa_opcode_name (insn->m_opcode),\n+\t       hsa_byte_alignment (alloca->m_align),\n+\t       hsa_type_name (insn->m_type));\n+\n+      dump_hsa_operands (f, insn);\n+    }\n+  else\n+    {\n+      fprintf (f, \"%s_%s \", hsa_opcode_name (insn->m_opcode),\n+\t       hsa_type_name (insn->m_type));\n+\n+      dump_hsa_operands (f, insn);\n+    }\n+\n+  if (insn->m_brig_offset)\n+    {\n+      fprintf (f, \"             /* BRIG offset: %u\", insn->m_brig_offset);\n+\n+      for (unsigned i = 0; i < insn->operand_count (); i++)\n+\tfprintf (f, \", op%u: %u\", i, insn->get_op (i)->m_brig_op_offset);\n+\n+      fprintf (f, \" */\");\n+    }\n+\n+  fprintf (f, \"\\n\");\n+}\n+\n+/* Dump textual representation of HSA IL instruction INSN to file F.  */\n+\n+void\n+dump_hsa_insn (FILE *f, hsa_insn_basic *insn)\n+{\n+  int indent = 0;\n+  dump_hsa_insn_1 (f, insn, &indent);\n+}\n+\n+/* Dump textual representation of HSA IL in HBB to file F.  */\n+\n+void\n+dump_hsa_bb (FILE *f, hsa_bb *hbb)\n+{\n+  hsa_insn_basic *insn;\n+  edge_iterator ei;\n+  edge e;\n+  basic_block true_bb = NULL, other = NULL;\n+\n+  fprintf (f, \"BB %i:\\n\", hbb->m_index);\n+\n+  int indent = 2;\n+  for (insn = hbb->m_first_phi; insn; insn = insn->m_next)\n+    dump_hsa_insn_1 (f, insn, &indent);\n+\n+  for (insn = hbb->m_first_insn; insn; insn = insn->m_next)\n+    dump_hsa_insn_1 (f, insn, &indent);\n+\n+  if (hbb->m_last_insn && is_a <hsa_insn_sbr *> (hbb->m_last_insn))\n+    goto exit;\n+\n+  FOR_EACH_EDGE (e, ei, hbb->m_bb->succs)\n+    if (e->flags & EDGE_TRUE_VALUE)\n+      {\n+\tgcc_assert (!true_bb);\n+\ttrue_bb = e->dest;\n+      }\n+    else\n+      {\n+\tgcc_assert (!other);\n+\tother = e->dest;\n+      }\n+\n+  if (true_bb)\n+    {\n+      if (!hbb->m_last_insn\n+\t  || hbb->m_last_insn->m_opcode != BRIG_OPCODE_CBR)\n+\tfprintf (f, \"WARNING: No branch insn for a true edge. \\n\");\n+    }\n+  else if (hbb->m_last_insn\n+\t   && hbb->m_last_insn->m_opcode == BRIG_OPCODE_CBR)\n+    fprintf (f, \"WARNING: No true edge for a cbr statement\\n\");\n+\n+  if (other && other->aux)\n+    fprintf (f, \"  Fall-through to BB %i\\n\",\n+\t     hsa_bb_for_bb (other)->m_index);\n+  else if (hbb->m_last_insn\n+\t   && hbb->m_last_insn->m_opcode != BRIG_OPCODE_RET)\n+    fprintf (f, \"  WARNING: Fall through to a BB with no aux!\\n\");\n+\n+exit:\n+  fprintf (f, \"\\n\");\n+}\n+\n+/* Dump textual representation of HSA IL of the current function to file F.  */\n+\n+void\n+dump_hsa_cfun (FILE *f)\n+{\n+  basic_block bb;\n+\n+  if (hsa_cfun->m_global_symbols.length () > 0)\n+    fprintf (f, \"\\nHSAIL in global scope\\n\");\n+\n+  for (unsigned i = 0; i < hsa_cfun->m_global_symbols.length (); i++)\n+    {\n+      fprintf (f, \"  \");\n+      dump_hsa_symbol (f, hsa_cfun->m_global_symbols[i]);\n+      fprintf (f, \"\\n\");\n+    }\n+\n+  fprintf (f, \"\\nHSAIL IL for %s\\n\", hsa_cfun->m_name);\n+\n+  for (unsigned i = 0; i < hsa_cfun->m_private_variables.length (); i++)\n+    {\n+      fprintf (f, \"  \");\n+      dump_hsa_symbol (f, hsa_cfun->m_private_variables[i]);\n+      fprintf (f, \"\\n\");\n+    }\n+\n+  FOR_ALL_BB_FN (bb, cfun)\n+  {\n+    hsa_bb *hbb = (struct hsa_bb *) bb->aux;\n+    dump_hsa_bb (f, hbb);\n+  }\n+}\n+\n+/* Dump textual representation of HSA IL instruction INSN to stderr.  */\n+\n+DEBUG_FUNCTION void\n+debug_hsa_insn (hsa_insn_basic *insn)\n+{\n+  dump_hsa_insn (stderr, insn);\n+}\n+\n+/* Dump textual representation of HSA IL in HBB to stderr.  */\n+\n+DEBUG_FUNCTION void\n+debug_hsa_bb (hsa_bb *hbb)\n+{\n+  dump_hsa_bb (stderr, hbb);\n+}\n+\n+/* Dump textual representation of HSA IL of the current function to stderr.  */\n+\n+DEBUG_FUNCTION void\n+debug_hsa_cfun (void)\n+{\n+  dump_hsa_cfun (stderr);\n+}\n+\n+/* Dump textual representation of an HSA operand to stderr.  */\n+\n+DEBUG_FUNCTION void\n+debug_hsa_operand (hsa_op_base *opc)\n+{\n+  dump_hsa_operand (stderr, opc, true);\n+  fprintf (stderr, \"\\n\");\n+}\n+\n+/* Dump textual representation of as HSA symbol.  */\n+\n+DEBUG_FUNCTION void\n+debug_hsa_symbol (hsa_symbol *symbol)\n+{\n+  dump_hsa_symbol (stderr, symbol);\n+  fprintf (stderr, \"\\n\");\n+}"}, {"sha": "a6f4170dfa63ff0ef252e2306a2c0a635e26db08", "filename": "gcc/hsa-gen.c", "status": "added", "additions": 6151, "deletions": 0, "changes": 6151, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-gen.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-gen.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa-gen.c?ref=b2b40051500c944e882c274727cea7231eefaaf5"}, {"sha": "f8e83ecfffe1935f7f486158ad1b256fcb7c7732", "filename": "gcc/hsa-regalloc.c", "status": "added", "additions": 719, "deletions": 0, "changes": 719, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-regalloc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa-regalloc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa-regalloc.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,719 @@\n+/* HSAIL IL Register allocation and out-of-SSA.\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+   Contributed by Michael Matz <matz@suse.de>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"is-a.h\"\n+#include \"vec.h\"\n+#include \"tree.h\"\n+#include \"dominance.h\"\n+#include \"cfg.h\"\n+#include \"cfganal.h\"\n+#include \"function.h\"\n+#include \"bitmap.h\"\n+#include \"dumpfile.h\"\n+#include \"cgraph.h\"\n+#include \"print-tree.h\"\n+#include \"cfghooks.h\"\n+#include \"symbol-summary.h\"\n+#include \"hsa.h\"\n+\n+\n+/* Process a PHI node PHI of basic block BB as a part of naive out-f-ssa.  */\n+\n+static void\n+naive_process_phi (hsa_insn_phi *phi)\n+{\n+  unsigned count = phi->operand_count ();\n+  for (unsigned i = 0; i < count; i++)\n+    {\n+      gcc_checking_assert (phi->get_op (i));\n+      hsa_op_base *op = phi->get_op (i);\n+      hsa_bb *hbb;\n+      edge e;\n+\n+      if (!op)\n+\tbreak;\n+\n+      e = EDGE_PRED (phi->m_bb, i);\n+      if (single_succ_p (e->src))\n+\thbb = hsa_bb_for_bb (e->src);\n+      else\n+\t{\n+\t  basic_block old_dest = e->dest;\n+\t  hbb = hsa_init_new_bb (split_edge (e));\n+\n+\t  /* If switch insn used this edge, fix jump table.  */\n+\t  hsa_bb *source = hsa_bb_for_bb (e->src);\n+\t  hsa_insn_sbr *sbr;\n+\t  if (source->m_last_insn\n+\t      && (sbr = dyn_cast <hsa_insn_sbr *> (source->m_last_insn)))\n+\t    sbr->replace_all_labels (old_dest, hbb->m_bb);\n+\t}\n+\n+      hsa_build_append_simple_mov (phi->m_dest, op, hbb);\n+    }\n+}\n+\n+/* Naive out-of SSA.  */\n+\n+static void\n+naive_outof_ssa (void)\n+{\n+  basic_block bb;\n+\n+  hsa_cfun->m_in_ssa = false;\n+\n+  FOR_ALL_BB_FN (bb, cfun)\n+  {\n+    hsa_bb *hbb = hsa_bb_for_bb (bb);\n+    hsa_insn_phi *phi;\n+\n+    for (phi = hbb->m_first_phi;\n+\t phi;\n+\t phi = phi->m_next ? as_a <hsa_insn_phi *> (phi->m_next) : NULL)\n+      naive_process_phi (phi);\n+\n+    /* Zap PHI nodes, they will be deallocated when everything else will.  */\n+    hbb->m_first_phi = NULL;\n+    hbb->m_last_phi = NULL;\n+  }\n+}\n+\n+/* Return register class number for the given HSA TYPE.  0 means the 'c' one\n+   bit register class, 1 means 's' 32 bit class, 2 stands for 'd' 64 bit class\n+   and 3 for 'q' 128 bit class.  */\n+\n+static int\n+m_reg_class_for_type (BrigType16_t type)\n+{\n+  switch (type)\n+    {\n+    case BRIG_TYPE_B1:\n+      return 0;\n+\n+    case BRIG_TYPE_U8:\n+    case BRIG_TYPE_U16:\n+    case BRIG_TYPE_U32:\n+    case BRIG_TYPE_S8:\n+    case BRIG_TYPE_S16:\n+    case BRIG_TYPE_S32:\n+    case BRIG_TYPE_F16:\n+    case BRIG_TYPE_F32:\n+    case BRIG_TYPE_B8:\n+    case BRIG_TYPE_B16:\n+    case BRIG_TYPE_B32:\n+    case BRIG_TYPE_U8X4:\n+    case BRIG_TYPE_S8X4:\n+    case BRIG_TYPE_U16X2:\n+    case BRIG_TYPE_S16X2:\n+    case BRIG_TYPE_F16X2:\n+      return 1;\n+\n+    case BRIG_TYPE_U64:\n+    case BRIG_TYPE_S64:\n+    case BRIG_TYPE_F64:\n+    case BRIG_TYPE_B64:\n+    case BRIG_TYPE_U8X8:\n+    case BRIG_TYPE_S8X8:\n+    case BRIG_TYPE_U16X4:\n+    case BRIG_TYPE_S16X4:\n+    case BRIG_TYPE_F16X4:\n+    case BRIG_TYPE_U32X2:\n+    case BRIG_TYPE_S32X2:\n+    case BRIG_TYPE_F32X2:\n+      return 2;\n+\n+    case BRIG_TYPE_B128:\n+    case BRIG_TYPE_U8X16:\n+    case BRIG_TYPE_S8X16:\n+    case BRIG_TYPE_U16X8:\n+    case BRIG_TYPE_S16X8:\n+    case BRIG_TYPE_F16X8:\n+    case BRIG_TYPE_U32X4:\n+    case BRIG_TYPE_U64X2:\n+    case BRIG_TYPE_S32X4:\n+    case BRIG_TYPE_S64X2:\n+    case BRIG_TYPE_F32X4:\n+    case BRIG_TYPE_F64X2:\n+      return 3;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* If the Ith operands of INSN is or contains a register (in an address),\n+   return the address of that register operand.  If not return NULL.  */\n+\n+static hsa_op_reg **\n+insn_reg_addr (hsa_insn_basic *insn, int i)\n+{\n+  hsa_op_base *op = insn->get_op (i);\n+  if (!op)\n+    return NULL;\n+  hsa_op_reg *reg = dyn_cast <hsa_op_reg *> (op);\n+  if (reg)\n+    return (hsa_op_reg **) insn->get_op_addr (i);\n+  hsa_op_address *addr = dyn_cast <hsa_op_address *> (op);\n+  if (addr && addr->m_reg)\n+    return &addr->m_reg;\n+  return NULL;\n+}\n+\n+struct m_reg_class_desc\n+{\n+  unsigned next_avail, max_num;\n+  unsigned used_num, max_used;\n+  uint64_t used[2];\n+  char cl_char;\n+};\n+\n+/* Rewrite the instructions in BB to observe spilled live ranges.\n+   CLASSES is the global register class state.  */\n+\n+static void\n+rewrite_code_bb (basic_block bb, struct m_reg_class_desc *classes)\n+{\n+  hsa_bb *hbb = hsa_bb_for_bb (bb);\n+  hsa_insn_basic *insn, *next_insn;\n+\n+  for (insn = hbb->m_first_insn; insn; insn = next_insn)\n+    {\n+      next_insn = insn->m_next;\n+      unsigned count = insn->operand_count ();\n+      for (unsigned i = 0; i < count; i++)\n+\t{\n+\t  gcc_checking_assert (insn->get_op (i));\n+\t  hsa_op_reg **regaddr = insn_reg_addr (insn, i);\n+\n+\t  if (regaddr)\n+\t    {\n+\t      hsa_op_reg *reg = *regaddr;\n+\t      if (reg->m_reg_class)\n+\t\tcontinue;\n+\t      gcc_assert (reg->m_spill_sym);\n+\n+\t      int cl = m_reg_class_for_type (reg->m_type);\n+\t      hsa_op_reg *tmp, *tmp2;\n+\t      if (insn->op_output_p (i))\n+\t\ttmp = hsa_spill_out (insn, reg, &tmp2);\n+\t      else\n+\t\ttmp = hsa_spill_in (insn, reg, &tmp2);\n+\n+\t      *regaddr = tmp;\n+\n+\t      tmp->m_reg_class = classes[cl].cl_char;\n+\t      tmp->m_hard_num = (char) (classes[cl].max_num + i);\n+\t      if (tmp2)\n+\t\t{\n+\t\t  gcc_assert (cl == 0);\n+\t\t  tmp2->m_reg_class = classes[1].cl_char;\n+\t\t  tmp2->m_hard_num = (char) (classes[1].max_num + i);\n+\t\t}\n+\t    }\n+\t}\n+    }\n+}\n+\n+/* Dump current function to dump file F, with info specific\n+   to register allocation.  */\n+\n+void\n+dump_hsa_cfun_regalloc (FILE *f)\n+{\n+  basic_block bb;\n+\n+  fprintf (f, \"\\nHSAIL IL for %s\\n\", hsa_cfun->m_name);\n+\n+  FOR_ALL_BB_FN (bb, cfun)\n+  {\n+    hsa_bb *hbb = (struct hsa_bb *) bb->aux;\n+    bitmap_print (dump_file, hbb->m_livein, \"m_livein  \", \"\\n\");\n+    dump_hsa_bb (f, hbb);\n+    bitmap_print (dump_file, hbb->m_liveout, \"m_liveout \", \"\\n\");\n+  }\n+}\n+\n+/* Given the global register allocation state CLASSES and a\n+   register REG, try to give it a hardware register.  If successful,\n+   store that hardreg in REG and return it, otherwise return -1.\n+   Also changes CLASSES to accommodate for the allocated register.  */\n+\n+static int\n+try_alloc_reg (struct m_reg_class_desc *classes, hsa_op_reg *reg)\n+{\n+  int cl = m_reg_class_for_type (reg->m_type);\n+  int ret = -1;\n+  if (classes[1].used_num + classes[2].used_num * 2 + classes[3].used_num * 4\n+      >= 128 - 5)\n+    return -1;\n+  if (classes[cl].used_num < classes[cl].max_num)\n+    {\n+      unsigned int i;\n+      classes[cl].used_num++;\n+      if (classes[cl].used_num > classes[cl].max_used)\n+\tclasses[cl].max_used = classes[cl].used_num;\n+      for (i = 0; i < classes[cl].used_num; i++)\n+\tif (! (classes[cl].used[i / 64] & (((uint64_t)1) << (i & 63))))\n+\t  break;\n+      ret = i;\n+      classes[cl].used[i / 64] |= (((uint64_t)1) << (i & 63));\n+      reg->m_reg_class = classes[cl].cl_char;\n+      reg->m_hard_num = i;\n+    }\n+  return ret;\n+}\n+\n+/* Free up hardregs used by REG, into allocation state CLASSES.  */\n+\n+static void\n+free_reg (struct m_reg_class_desc *classes, hsa_op_reg *reg)\n+{\n+  int cl = m_reg_class_for_type (reg->m_type);\n+  int ret = reg->m_hard_num;\n+  gcc_assert (reg->m_reg_class == classes[cl].cl_char);\n+  classes[cl].used_num--;\n+  classes[cl].used[ret / 64] &= ~(((uint64_t)1) << (ret & 63));\n+}\n+\n+/* Note that the live range for REG ends at least at END.  */\n+\n+static void\n+note_lr_end (hsa_op_reg *reg, int end)\n+{\n+  if (reg->m_lr_end < end)\n+    reg->m_lr_end = end;\n+}\n+\n+/* Note that the live range for REG starts at least at BEGIN.  */\n+\n+static void\n+note_lr_begin (hsa_op_reg *reg, int begin)\n+{\n+  if (reg->m_lr_begin > begin)\n+    reg->m_lr_begin = begin;\n+}\n+\n+/* Given two registers A and B, return -1, 0 or 1 if A's live range\n+   starts before, at or after B's live range.  */\n+\n+static int\n+cmp_begin (const void *a, const void *b)\n+{\n+  const hsa_op_reg * const *rega = (const hsa_op_reg * const *)a;\n+  const hsa_op_reg * const *regb = (const hsa_op_reg * const *)b;\n+  int ret;\n+  if (rega == regb)\n+    return 0;\n+  ret = (*rega)->m_lr_begin - (*regb)->m_lr_begin;\n+  if (ret)\n+    return ret;\n+  return ((*rega)->m_order - (*regb)->m_order);\n+}\n+\n+/* Given two registers REGA and REGB, return true if REGA's\n+   live range ends after REGB's.  This results in a sorting order\n+   with earlier end points at the end.  */\n+\n+static bool\n+cmp_end (hsa_op_reg * const &rega, hsa_op_reg * const &regb)\n+{\n+  int ret;\n+  if (rega == regb)\n+    return false;\n+  ret = (regb)->m_lr_end - (rega)->m_lr_end;\n+  if (ret)\n+    return ret < 0;\n+  return (((regb)->m_order - (rega)->m_order)) < 0;\n+}\n+\n+/* Expire all old intervals in ACTIVE (a per-regclass vector),\n+   that is, those that end before the interval REG starts.  Give\n+   back resources freed so into the state CLASSES.  */\n+\n+static void\n+expire_old_intervals (hsa_op_reg *reg, vec<hsa_op_reg*> *active,\n+\t\t      struct m_reg_class_desc *classes)\n+{\n+  for (int i = 0; i < 4; i++)\n+    while (!active[i].is_empty ())\n+      {\n+\thsa_op_reg *a = active[i].pop ();\n+\tif (a->m_lr_end > reg->m_lr_begin)\n+\t  {\n+\t    active[i].quick_push (a);\n+\t    break;\n+\t  }\n+\tfree_reg (classes, a);\n+      }\n+}\n+\n+/* The interval REG didn't get a hardreg.  Spill it or one of those\n+   from ACTIVE (if the latter, then REG will become allocated to the\n+   hardreg that formerly was used by it).  */\n+\n+static void\n+spill_at_interval (hsa_op_reg *reg, vec<hsa_op_reg*> *active)\n+{\n+  int cl = m_reg_class_for_type (reg->m_type);\n+  gcc_assert (!active[cl].is_empty ());\n+  hsa_op_reg *cand = active[cl][0];\n+  if (cand->m_lr_end > reg->m_lr_end)\n+    {\n+      reg->m_reg_class = cand->m_reg_class;\n+      reg->m_hard_num = cand->m_hard_num;\n+      active[cl].ordered_remove (0);\n+      unsigned place = active[cl].lower_bound (reg, cmp_end);\n+      active[cl].quick_insert (place, reg);\n+    }\n+  else\n+    cand = reg;\n+\n+  gcc_assert (!cand->m_spill_sym);\n+  BrigType16_t type = cand->m_type;\n+  if (type == BRIG_TYPE_B1)\n+    type = BRIG_TYPE_U8;\n+  cand->m_reg_class = 0;\n+  cand->m_spill_sym = hsa_get_spill_symbol (type);\n+  cand->m_spill_sym->m_name_number = cand->m_order;\n+}\n+\n+/* Given the global register state CLASSES allocate all HSA virtual\n+   registers either to hardregs or to a spill symbol.  */\n+\n+static void\n+linear_scan_regalloc (struct m_reg_class_desc *classes)\n+{\n+  /* Compute liveness.  */\n+  bool changed;\n+  int i, n;\n+  int insn_order;\n+  int *bbs = XNEWVEC (int, n_basic_blocks_for_fn (cfun));\n+  bitmap work = BITMAP_ALLOC (NULL);\n+  vec<hsa_op_reg*> ind2reg = vNULL;\n+  vec<hsa_op_reg*> active[4] = {vNULL, vNULL, vNULL, vNULL};\n+  hsa_insn_basic *m_last_insn;\n+\n+  /* We will need the reverse post order for linearization,\n+     and the post order for liveness analysis, which is the same\n+     backward.  */\n+  n = pre_and_rev_post_order_compute (NULL, bbs, true);\n+  ind2reg.safe_grow_cleared (hsa_cfun->m_reg_count);\n+\n+  /* Give all instructions a linearized number, at the same time\n+     build a mapping from register index to register.  */\n+  insn_order = 1;\n+  for (i = 0; i < n; i++)\n+    {\n+      basic_block bb = BASIC_BLOCK_FOR_FN (cfun, bbs[i]);\n+      hsa_bb *hbb = hsa_bb_for_bb (bb);\n+      hsa_insn_basic *insn;\n+      for (insn = hbb->m_first_insn; insn; insn = insn->m_next)\n+\t{\n+\t  unsigned opi;\n+\t  insn->m_number = insn_order++;\n+\t  for (opi = 0; opi < insn->operand_count (); opi++)\n+\t    {\n+\t      gcc_checking_assert (insn->get_op (opi));\n+\t      hsa_op_reg **regaddr = insn_reg_addr (insn, opi);\n+\t      if (regaddr)\n+\t\tind2reg[(*regaddr)->m_order] = *regaddr;\n+\t    }\n+\t}\n+    }\n+\n+  /* Initialize all live ranges to [after-end, 0).  */\n+  for (i = 0; i < hsa_cfun->m_reg_count; i++)\n+    if (ind2reg[i])\n+      ind2reg[i]->m_lr_begin = insn_order, ind2reg[i]->m_lr_end = 0;\n+\n+  /* Classic liveness analysis, as long as something changes:\n+       m_liveout is union (m_livein of successors)\n+       m_livein is m_liveout minus defs plus uses.  */\n+  do\n+    {\n+      changed = false;\n+      for (i = n - 1; i >= 0; i--)\n+\t{\n+\t  edge e;\n+\t  edge_iterator ei;\n+\t  basic_block bb = BASIC_BLOCK_FOR_FN (cfun, bbs[i]);\n+\t  hsa_bb *hbb = hsa_bb_for_bb (bb);\n+\n+\t  /* Union of successors m_livein (or empty if none).  */\n+\t  bool first = true;\n+\t  FOR_EACH_EDGE (e, ei, bb->succs)\n+\t    if (e->dest != EXIT_BLOCK_PTR_FOR_FN (cfun))\n+\t      {\n+\t\thsa_bb *succ = hsa_bb_for_bb (e->dest);\n+\t\tif (first)\n+\t\t  {\n+\t\t    bitmap_copy (work, succ->m_livein);\n+\t\t    first = false;\n+\t\t  }\n+\t\telse\n+\t\t  bitmap_ior_into (work, succ->m_livein);\n+\t      }\n+\t  if (first)\n+\t    bitmap_clear (work);\n+\n+\t  bitmap_copy (hbb->m_liveout, work);\n+\n+\t  /* Remove defs, include uses in a backward insn walk.  */\n+\t  hsa_insn_basic *insn;\n+\t  for (insn = hbb->m_last_insn; insn; insn = insn->m_prev)\n+\t    {\n+\t      unsigned opi;\n+\t      unsigned ndefs = insn->input_count ();\n+\t      for (opi = 0; opi < ndefs && insn->get_op (opi); opi++)\n+\t\t{\n+\t\t  gcc_checking_assert (insn->get_op (opi));\n+\t\t  hsa_op_reg **regaddr = insn_reg_addr (insn, opi);\n+\t\t  if (regaddr)\n+\t\t    bitmap_clear_bit (work, (*regaddr)->m_order);\n+\t\t}\n+\t      for (; opi < insn->operand_count (); opi++)\n+\t\t{\n+\t\t  gcc_checking_assert (insn->get_op (opi));\n+\t\t  hsa_op_reg **regaddr = insn_reg_addr (insn, opi);\n+\t\t  if (regaddr)\n+\t\t    bitmap_set_bit (work, (*regaddr)->m_order);\n+\t\t}\n+\t    }\n+\n+\t  /* Note if that changed something.  */\n+\t  if (bitmap_ior_into (hbb->m_livein, work))\n+\t    changed = true;\n+\t}\n+    }\n+  while (changed);\n+\n+  /* Make one pass through all instructions in linear order,\n+     noting and merging possible live range start and end points.  */\n+  m_last_insn = NULL;\n+  for (i = n - 1; i >= 0; i--)\n+    {\n+      basic_block bb = BASIC_BLOCK_FOR_FN (cfun, bbs[i]);\n+      hsa_bb *hbb = hsa_bb_for_bb (bb);\n+      hsa_insn_basic *insn;\n+      int after_end_number;\n+      unsigned bit;\n+      bitmap_iterator bi;\n+\n+      if (m_last_insn)\n+\tafter_end_number = m_last_insn->m_number;\n+      else\n+\tafter_end_number = insn_order;\n+      /* Everything live-out in this BB has at least an end point\n+\t after us.  */\n+      EXECUTE_IF_SET_IN_BITMAP (hbb->m_liveout, 0, bit, bi)\n+\tnote_lr_end (ind2reg[bit], after_end_number);\n+\n+      for (insn = hbb->m_last_insn; insn; insn = insn->m_prev)\n+\t{\n+\t  unsigned opi;\n+\t  unsigned ndefs = insn->input_count ();\n+\t  for (opi = 0; opi < insn->operand_count (); opi++)\n+\t    {\n+\t      gcc_checking_assert (insn->get_op (opi));\n+\t      hsa_op_reg **regaddr = insn_reg_addr (insn, opi);\n+\t      if (regaddr)\n+\t\t{\n+\t\t  hsa_op_reg *reg = *regaddr;\n+\t\t  if (opi < ndefs)\n+\t\t    note_lr_begin (reg, insn->m_number);\n+\t\t  else\n+\t\t    note_lr_end (reg, insn->m_number);\n+\t\t}\n+\t    }\n+\t}\n+\n+      /* Everything live-in in this BB has a start point before\n+\t our first insn.  */\n+      int before_start_number;\n+      if (hbb->m_first_insn)\n+\tbefore_start_number = hbb->m_first_insn->m_number;\n+      else\n+\tbefore_start_number = after_end_number;\n+      before_start_number--;\n+      EXECUTE_IF_SET_IN_BITMAP (hbb->m_livein, 0, bit, bi)\n+\tnote_lr_begin (ind2reg[bit], before_start_number);\n+\n+      if (hbb->m_first_insn)\n+\tm_last_insn = hbb->m_first_insn;\n+    }\n+\n+  for (i = 0; i < hsa_cfun->m_reg_count; i++)\n+    if (ind2reg[i])\n+      {\n+\t/* All regs that have still their start at after all code actually\n+\t   are defined at the start of the routine (prologue).  */\n+\tif (ind2reg[i]->m_lr_begin == insn_order)\n+\t  ind2reg[i]->m_lr_begin = 0;\n+\t/* All regs that have no use but a def will have lr_end == 0,\n+\t   they are actually live from def until after the insn they are\n+\t   defined in.  */\n+\tif (ind2reg[i]->m_lr_end == 0)\n+\t  ind2reg[i]->m_lr_end = ind2reg[i]->m_lr_begin + 1;\n+      }\n+\n+  /* Sort all intervals by increasing start point.  */\n+  gcc_assert (ind2reg.length () == (size_t) hsa_cfun->m_reg_count);\n+\n+#ifdef ENABLE_CHECKING\n+  for (unsigned i = 0; i < ind2reg.length (); i++)\n+    gcc_assert (ind2reg[i]);\n+#endif\n+\n+  ind2reg.qsort (cmp_begin);\n+  for (i = 0; i < 4; i++)\n+    active[i].reserve_exact (hsa_cfun->m_reg_count);\n+\n+  /* Now comes the linear scan allocation.  */\n+  for (i = 0; i < hsa_cfun->m_reg_count; i++)\n+    {\n+      hsa_op_reg *reg = ind2reg[i];\n+      if (!reg)\n+\tcontinue;\n+      expire_old_intervals (reg, active, classes);\n+      int cl = m_reg_class_for_type (reg->m_type);\n+      if (try_alloc_reg (classes, reg) >= 0)\n+\t{\n+\t  unsigned place = active[cl].lower_bound (reg, cmp_end);\n+\t  active[cl].quick_insert (place, reg);\n+\t}\n+      else\n+\tspill_at_interval (reg, active);\n+\n+      /* Some interesting dumping as we go.  */\n+      if (dump_file)\n+\t{\n+\t  fprintf (dump_file, \"  reg%d: [%5d, %5d)->\",\n+\t\t   reg->m_order, reg->m_lr_begin, reg->m_lr_end);\n+\t  if (reg->m_reg_class)\n+\t    fprintf (dump_file, \"$%c%i\", reg->m_reg_class, reg->m_hard_num);\n+\t  else\n+\t    fprintf (dump_file, \"[%%__%s_%i]\",\n+\t\t     hsa_seg_name (reg->m_spill_sym->m_segment),\n+\t\t     reg->m_spill_sym->m_name_number);\n+\t  for (int cl = 0; cl < 4; cl++)\n+\t    {\n+\t      bool first = true;\n+\t      hsa_op_reg *r;\n+\t      fprintf (dump_file, \" {\");\n+\t      for (int j = 0; active[cl].iterate (j, &r); j++)\n+\t\tif (first)\n+\t\t  {\n+\t\t    fprintf (dump_file, \"%d\", r->m_order);\n+\t\t    first = false;\n+\t\t  }\n+\t\telse\n+\t\t  fprintf (dump_file, \", %d\", r->m_order);\n+\t      fprintf (dump_file, \"}\");\n+\t    }\n+\t  fprintf (dump_file, \"\\n\");\n+\t}\n+    }\n+\n+  BITMAP_FREE (work);\n+  free (bbs);\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"------- After liveness: -------\\n\");\n+      dump_hsa_cfun_regalloc (dump_file);\n+      fprintf (dump_file, \"  ----- Intervals:\\n\");\n+      for (i = 0; i < hsa_cfun->m_reg_count; i++)\n+\t{\n+\t  hsa_op_reg *reg = ind2reg[i];\n+\t  if (!reg)\n+\t    continue;\n+\t  fprintf (dump_file, \"  reg%d: [%5d, %5d)->\", reg->m_order,\n+\t\t   reg->m_lr_begin, reg->m_lr_end);\n+\t  if (reg->m_reg_class)\n+\t    fprintf (dump_file, \"$%c%i\\n\", reg->m_reg_class, reg->m_hard_num);\n+\t  else\n+\t    fprintf (dump_file, \"[%%__%s_%i]\\n\",\n+\t\t     hsa_seg_name (reg->m_spill_sym->m_segment),\n+\t\t     reg->m_spill_sym->m_name_number);\n+\t}\n+    }\n+\n+  for (i = 0; i < 4; i++)\n+    active[i].release ();\n+  ind2reg.release ();\n+}\n+\n+/* Entry point for register allocation.  */\n+\n+static void\n+regalloc (void)\n+{\n+  basic_block bb;\n+  m_reg_class_desc classes[4];\n+\n+  /* If there are no registers used in the function, exit right away.  */\n+  if (hsa_cfun->m_reg_count == 0)\n+    return;\n+\n+  memset (classes, 0, sizeof (classes));\n+  classes[0].next_avail = 0;\n+  classes[0].max_num = 7;\n+  classes[0].cl_char = 'c';\n+  classes[1].cl_char = 's';\n+  classes[2].cl_char = 'd';\n+  classes[3].cl_char = 'q';\n+\n+  for (int i = 1; i < 4; i++)\n+    {\n+      classes[i].next_avail = 0;\n+      classes[i].max_num = 20;\n+    }\n+\n+  linear_scan_regalloc (classes);\n+\n+  FOR_ALL_BB_FN (bb, cfun)\n+    rewrite_code_bb (bb, classes);\n+}\n+\n+/* Out of SSA and register allocation on HSAIL IL.  */\n+\n+void\n+hsa_regalloc (void)\n+{\n+  naive_outof_ssa ();\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"------- After out-of-SSA: -------\\n\");\n+      dump_hsa_cfun (dump_file);\n+    }\n+\n+  regalloc ();\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"------- After register allocation: -------\\n\");\n+      dump_hsa_cfun (dump_file);\n+    }\n+}"}, {"sha": "ec23f8126f0160e866a86a5e533ddec678726f01", "filename": "gcc/hsa.c", "status": "added", "additions": 947, "deletions": 0, "changes": 947, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,947 @@\n+/* Implementation of commonly needed HSAIL related functions and methods.\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+   Contributed by Martin Jambor <mjambor@suse.cz> and\n+   Martin Liska <mliska@suse.cz>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"is-a.h\"\n+#include \"hash-set.h\"\n+#include \"hash-map.h\"\n+#include \"vec.h\"\n+#include \"tree.h\"\n+#include \"dumpfile.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"diagnostic-core.h\"\n+#include \"alloc-pool.h\"\n+#include \"cgraph.h\"\n+#include \"print-tree.h\"\n+#include \"stringpool.h\"\n+#include \"symbol-summary.h\"\n+#include \"hsa.h\"\n+#include \"internal-fn.h\"\n+#include \"ctype.h\"\n+\n+/* Structure containing intermediate HSA representation of the generated\n+   function.  */\n+class hsa_function_representation *hsa_cfun;\n+\n+/* Element of the mapping vector between a host decl and an HSA kernel.  */\n+\n+struct GTY(()) hsa_decl_kernel_map_element\n+{\n+  /* The decl of the host function.  */\n+  tree decl;\n+  /* Name of the HSA kernel in BRIG.  */\n+  char * GTY((skip)) name;\n+  /* Size of OMP data, if the kernel contains a kernel dispatch.  */\n+  unsigned omp_data_size;\n+  /* True if the function is gridified kernel.  */\n+  bool gridified_kernel_p;\n+};\n+\n+/* Mapping between decls and corresponding HSA kernels in this compilation\n+   unit.  */\n+\n+static GTY (()) vec<hsa_decl_kernel_map_element, va_gc>\n+  *hsa_decl_kernel_mapping;\n+\n+/* Mapping between decls and corresponding HSA kernels\n+   called by the function.  */\n+hash_map <tree, vec <const char *> *> *hsa_decl_kernel_dependencies;\n+\n+/* Hash function to lookup a symbol for a decl.  */\n+hash_table <hsa_noop_symbol_hasher> *hsa_global_variable_symbols;\n+\n+/* HSA summaries.  */\n+hsa_summary_t *hsa_summaries = NULL;\n+\n+/* HSA number of threads.  */\n+hsa_symbol *hsa_num_threads = NULL;\n+\n+/* HSA function that cannot be expanded to HSAIL.  */\n+hash_set <tree> *hsa_failed_functions = NULL;\n+\n+/* True if compilation unit-wide data are already allocated and initialized.  */\n+static bool compilation_unit_data_initialized;\n+\n+/* Return true if FNDECL represents an HSA-callable function.  */\n+\n+bool\n+hsa_callable_function_p (tree fndecl)\n+{\n+  return (lookup_attribute (\"omp declare target\", DECL_ATTRIBUTES (fndecl))\n+\t  && !lookup_attribute (\"oacc function\", DECL_ATTRIBUTES (fndecl)));\n+}\n+\n+/* Allocate HSA structures that are are used when dealing with different\n+   functions.  */\n+\n+void\n+hsa_init_compilation_unit_data (void)\n+{\n+  if (compilation_unit_data_initialized)\n+    return;\n+\n+  compilation_unit_data_initialized = true;\n+\n+  hsa_global_variable_symbols = new hash_table <hsa_noop_symbol_hasher> (8);\n+  hsa_failed_functions = new hash_set <tree> ();\n+  hsa_emitted_internal_decls = new hash_table <hsa_internal_fn_hasher> (2);\n+}\n+\n+/* Free data structures that are used when dealing with different\n+   functions.  */\n+\n+void\n+hsa_deinit_compilation_unit_data (void)\n+{\n+  gcc_assert (compilation_unit_data_initialized);\n+\n+  delete hsa_failed_functions;\n+  delete hsa_emitted_internal_decls;\n+\n+  for (hash_table <hsa_noop_symbol_hasher>::iterator it\n+       = hsa_global_variable_symbols->begin ();\n+       it != hsa_global_variable_symbols->end ();\n+       ++it)\n+    {\n+      hsa_symbol *sym = *it;\n+      delete sym;\n+    }\n+\n+  delete hsa_global_variable_symbols;\n+\n+  if (hsa_num_threads)\n+    {\n+      delete hsa_num_threads;\n+      hsa_num_threads = NULL;\n+    }\n+\n+  compilation_unit_data_initialized = false;\n+}\n+\n+/* Return true if we are generating large HSA machine model.  */\n+\n+bool\n+hsa_machine_large_p (void)\n+{\n+  /* FIXME: I suppose this is technically wrong but should work for me now.  */\n+  return (GET_MODE_BITSIZE (Pmode) == 64);\n+}\n+\n+/* Return the HSA profile we are using.  */\n+\n+bool\n+hsa_full_profile_p (void)\n+{\n+  return true;\n+}\n+\n+/* Return true if a register in operand number OPNUM of instruction\n+   is an output.  False if it is an input.  */\n+\n+bool\n+hsa_insn_basic::op_output_p (unsigned opnum)\n+{\n+  switch (m_opcode)\n+    {\n+    case HSA_OPCODE_PHI:\n+    case BRIG_OPCODE_CBR:\n+    case BRIG_OPCODE_SBR:\n+    case BRIG_OPCODE_ST:\n+    case BRIG_OPCODE_SIGNALNORET:\n+      /* FIXME: There are probably missing cases here, double check.  */\n+      return false;\n+    case BRIG_OPCODE_EXPAND:\n+      /* Example: expand_v4_b32_b128 (dest0, dest1, dest2, dest3), src0.  */\n+      return opnum < operand_count () - 1;\n+    default:\n+     return opnum == 0;\n+    }\n+}\n+\n+/* Return true if OPCODE is an floating-point bit instruction opcode.  */\n+\n+bool\n+hsa_opcode_floating_bit_insn_p (BrigOpcode16_t opcode)\n+{\n+  switch (opcode)\n+    {\n+    case BRIG_OPCODE_NEG:\n+    case BRIG_OPCODE_ABS:\n+    case BRIG_OPCODE_CLASS:\n+    case BRIG_OPCODE_COPYSIGN:\n+      return true;\n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Return the number of destination operands for this INSN.  */\n+\n+unsigned\n+hsa_insn_basic::input_count ()\n+{\n+  switch (m_opcode)\n+    {\n+      default:\n+\treturn 1;\n+\n+      case BRIG_OPCODE_NOP:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_EXPAND:\n+\treturn 2;\n+\n+      case BRIG_OPCODE_LD:\n+\t/* ld_v[234] not yet handled.  */\n+\treturn 1;\n+\n+      case BRIG_OPCODE_ST:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_ATOMICNORET:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_SIGNAL:\n+\treturn 1;\n+\n+      case BRIG_OPCODE_SIGNALNORET:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_MEMFENCE:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_RDIMAGE:\n+      case BRIG_OPCODE_LDIMAGE:\n+      case BRIG_OPCODE_STIMAGE:\n+      case BRIG_OPCODE_QUERYIMAGE:\n+      case BRIG_OPCODE_QUERYSAMPLER:\n+\tsorry (\"HSA image ops not handled\");\n+\treturn 0;\n+\n+      case BRIG_OPCODE_CBR:\n+      case BRIG_OPCODE_BR:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_SBR:\n+\treturn 0; /* ??? */\n+\n+      case BRIG_OPCODE_WAVEBARRIER:\n+\treturn 0; /* ??? */\n+\n+      case BRIG_OPCODE_BARRIER:\n+      case BRIG_OPCODE_ARRIVEFBAR:\n+      case BRIG_OPCODE_INITFBAR:\n+      case BRIG_OPCODE_JOINFBAR:\n+      case BRIG_OPCODE_LEAVEFBAR:\n+      case BRIG_OPCODE_RELEASEFBAR:\n+      case BRIG_OPCODE_WAITFBAR:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_LDF:\n+\treturn 1;\n+\n+      case BRIG_OPCODE_ACTIVELANECOUNT:\n+      case BRIG_OPCODE_ACTIVELANEID:\n+      case BRIG_OPCODE_ACTIVELANEMASK:\n+      case BRIG_OPCODE_ACTIVELANEPERMUTE:\n+\treturn 1; /* ??? */\n+\n+      case BRIG_OPCODE_CALL:\n+      case BRIG_OPCODE_SCALL:\n+      case BRIG_OPCODE_ICALL:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_RET:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_ALLOCA:\n+\treturn 1;\n+\n+      case BRIG_OPCODE_CLEARDETECTEXCEPT:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_SETDETECTEXCEPT:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_PACKETCOMPLETIONSIG:\n+      case BRIG_OPCODE_PACKETID:\n+      case BRIG_OPCODE_CASQUEUEWRITEINDEX:\n+      case BRIG_OPCODE_LDQUEUEREADINDEX:\n+      case BRIG_OPCODE_LDQUEUEWRITEINDEX:\n+      case BRIG_OPCODE_STQUEUEREADINDEX:\n+      case BRIG_OPCODE_STQUEUEWRITEINDEX:\n+\treturn 1; /* ??? */\n+\n+      case BRIG_OPCODE_ADDQUEUEWRITEINDEX:\n+\treturn 1;\n+\n+      case BRIG_OPCODE_DEBUGTRAP:\n+\treturn 0;\n+\n+      case BRIG_OPCODE_GROUPBASEPTR:\n+      case BRIG_OPCODE_KERNARGBASEPTR:\n+\treturn 1; /* ??? */\n+\n+      case HSA_OPCODE_ARG_BLOCK:\n+\treturn 0;\n+\n+      case BRIG_KIND_DIRECTIVE_COMMENT:\n+\treturn 0;\n+    }\n+}\n+\n+/* Return the number of source operands for this INSN.  */\n+\n+unsigned\n+hsa_insn_basic::num_used_ops ()\n+{\n+  gcc_checking_assert (input_count () <= operand_count ());\n+\n+  return operand_count () - input_count ();\n+}\n+\n+/* Set alignment to VALUE.  */\n+\n+void\n+hsa_insn_mem::set_align (BrigAlignment8_t value)\n+{\n+  /* TODO: Perhaps remove this dump later on:  */\n+  if (dump_file && (dump_flags & TDF_DETAILS) && value < m_align)\n+    {\n+      fprintf (dump_file, \"Decreasing alignment to %u in instruction \", value);\n+      dump_hsa_insn (dump_file, this);\n+    }\n+  m_align = value;\n+}\n+\n+/* Return size of HSA type T in bits.  */\n+\n+unsigned\n+hsa_type_bit_size (BrigType16_t t)\n+{\n+  switch (t)\n+    {\n+    case BRIG_TYPE_B1:\n+      return 1;\n+\n+    case BRIG_TYPE_U8:\n+    case BRIG_TYPE_S8:\n+    case BRIG_TYPE_B8:\n+      return 8;\n+\n+    case BRIG_TYPE_U16:\n+    case BRIG_TYPE_S16:\n+    case BRIG_TYPE_B16:\n+    case BRIG_TYPE_F16:\n+      return 16;\n+\n+    case BRIG_TYPE_U32:\n+    case BRIG_TYPE_S32:\n+    case BRIG_TYPE_B32:\n+    case BRIG_TYPE_F32:\n+    case BRIG_TYPE_U8X4:\n+    case BRIG_TYPE_U16X2:\n+    case BRIG_TYPE_S8X4:\n+    case BRIG_TYPE_S16X2:\n+    case BRIG_TYPE_F16X2:\n+      return 32;\n+\n+    case BRIG_TYPE_U64:\n+    case BRIG_TYPE_S64:\n+    case BRIG_TYPE_F64:\n+    case BRIG_TYPE_B64:\n+    case BRIG_TYPE_U8X8:\n+    case BRIG_TYPE_U16X4:\n+    case BRIG_TYPE_U32X2:\n+    case BRIG_TYPE_S8X8:\n+    case BRIG_TYPE_S16X4:\n+    case BRIG_TYPE_S32X2:\n+    case BRIG_TYPE_F16X4:\n+    case BRIG_TYPE_F32X2:\n+\n+      return 64;\n+\n+    case BRIG_TYPE_B128:\n+    case BRIG_TYPE_U8X16:\n+    case BRIG_TYPE_U16X8:\n+    case BRIG_TYPE_U32X4:\n+    case BRIG_TYPE_U64X2:\n+    case BRIG_TYPE_S8X16:\n+    case BRIG_TYPE_S16X8:\n+    case BRIG_TYPE_S32X4:\n+    case BRIG_TYPE_S64X2:\n+    case BRIG_TYPE_F16X8:\n+    case BRIG_TYPE_F32X4:\n+    case BRIG_TYPE_F64X2:\n+      return 128;\n+\n+    default:\n+      gcc_assert (hsa_seen_error ());\n+      return t;\n+    }\n+}\n+\n+/* Return BRIG bit-type with BITSIZE length.  */\n+\n+BrigType16_t\n+hsa_bittype_for_bitsize (unsigned bitsize)\n+{\n+  switch (bitsize)\n+    {\n+    case 1:\n+      return BRIG_TYPE_B1;\n+    case 8:\n+      return BRIG_TYPE_B8;\n+    case 16:\n+      return BRIG_TYPE_B16;\n+    case 32:\n+      return BRIG_TYPE_B32;\n+    case 64:\n+      return BRIG_TYPE_B64;\n+    case 128:\n+      return BRIG_TYPE_B128;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Return BRIG unsigned int type with BITSIZE length.  */\n+\n+BrigType16_t\n+hsa_uint_for_bitsize (unsigned bitsize)\n+{\n+  switch (bitsize)\n+    {\n+    case 8:\n+      return BRIG_TYPE_U8;\n+    case 16:\n+      return BRIG_TYPE_U16;\n+    case 32:\n+      return BRIG_TYPE_U32;\n+    case 64:\n+      return BRIG_TYPE_U64;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Return BRIG float type with BITSIZE length.  */\n+\n+BrigType16_t\n+hsa_float_for_bitsize (unsigned bitsize)\n+{\n+  switch (bitsize)\n+    {\n+    case 16:\n+      return BRIG_TYPE_F16;\n+    case 32:\n+      return BRIG_TYPE_F32;\n+    case 64:\n+      return BRIG_TYPE_F64;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Return HSA bit-type with the same size as the type T.  */\n+\n+BrigType16_t\n+hsa_bittype_for_type (BrigType16_t t)\n+{\n+  return hsa_bittype_for_bitsize (hsa_type_bit_size (t));\n+}\n+\n+/* Return true if and only if TYPE is a floating point number type.  */\n+\n+bool\n+hsa_type_float_p (BrigType16_t type)\n+{\n+  switch (type & BRIG_TYPE_BASE_MASK)\n+    {\n+    case BRIG_TYPE_F16:\n+    case BRIG_TYPE_F32:\n+    case BRIG_TYPE_F64:\n+      return true;\n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Return true if and only if TYPE is an integer number type.  */\n+\n+bool\n+hsa_type_integer_p (BrigType16_t type)\n+{\n+  switch (type & BRIG_TYPE_BASE_MASK)\n+    {\n+    case BRIG_TYPE_U8:\n+    case BRIG_TYPE_U16:\n+    case BRIG_TYPE_U32:\n+    case BRIG_TYPE_U64:\n+    case BRIG_TYPE_S8:\n+    case BRIG_TYPE_S16:\n+    case BRIG_TYPE_S32:\n+    case BRIG_TYPE_S64:\n+      return true;\n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Return true if and only if TYPE is an bit-type.  */\n+\n+bool\n+hsa_btype_p (BrigType16_t type)\n+{\n+  switch (type & BRIG_TYPE_BASE_MASK)\n+    {\n+    case BRIG_TYPE_B8:\n+    case BRIG_TYPE_B16:\n+    case BRIG_TYPE_B32:\n+    case BRIG_TYPE_B64:\n+    case BRIG_TYPE_B128:\n+      return true;\n+    default:\n+      return false;\n+    }\n+}\n+\n+\n+/* Return HSA alignment encoding alignment to N bits.  */\n+\n+BrigAlignment8_t\n+hsa_alignment_encoding (unsigned n)\n+{\n+  gcc_assert (n >= 8 && !(n & (n - 1)));\n+  if (n >= 256)\n+    return BRIG_ALIGNMENT_32;\n+\n+  switch (n)\n+    {\n+    case 8:\n+      return BRIG_ALIGNMENT_1;\n+    case 16:\n+      return BRIG_ALIGNMENT_2;\n+    case 32:\n+      return BRIG_ALIGNMENT_4;\n+    case 64:\n+      return BRIG_ALIGNMENT_8;\n+    case 128:\n+      return BRIG_ALIGNMENT_16;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Return natural alignment of HSA TYPE.  */\n+\n+BrigAlignment8_t\n+hsa_natural_alignment (BrigType16_t type)\n+{\n+  return hsa_alignment_encoding (hsa_type_bit_size (type & ~BRIG_TYPE_ARRAY));\n+}\n+\n+/* Call the correct destructor of a HSA instruction.  */\n+\n+void\n+hsa_destroy_insn (hsa_insn_basic *insn)\n+{\n+  if (hsa_insn_phi *phi = dyn_cast <hsa_insn_phi *> (insn))\n+    phi->~hsa_insn_phi ();\n+  else if (hsa_insn_br *br = dyn_cast <hsa_insn_br *> (insn))\n+    br->~hsa_insn_br ();\n+  else if (hsa_insn_cmp *cmp = dyn_cast <hsa_insn_cmp *> (insn))\n+    cmp->~hsa_insn_cmp ();\n+  else if (hsa_insn_mem *mem = dyn_cast <hsa_insn_mem *> (insn))\n+    mem->~hsa_insn_mem ();\n+  else if (hsa_insn_atomic *atomic = dyn_cast <hsa_insn_atomic *> (insn))\n+    atomic->~hsa_insn_atomic ();\n+  else if (hsa_insn_seg *seg = dyn_cast <hsa_insn_seg *> (insn))\n+    seg->~hsa_insn_seg ();\n+  else if (hsa_insn_call *call = dyn_cast <hsa_insn_call *> (insn))\n+    call->~hsa_insn_call ();\n+  else if (hsa_insn_arg_block *block = dyn_cast <hsa_insn_arg_block *> (insn))\n+    block->~hsa_insn_arg_block ();\n+  else if (hsa_insn_sbr *sbr = dyn_cast <hsa_insn_sbr *> (insn))\n+    sbr->~hsa_insn_sbr ();\n+  else if (hsa_insn_comment *comment = dyn_cast <hsa_insn_comment *> (insn))\n+    comment->~hsa_insn_comment ();\n+  else\n+    insn->~hsa_insn_basic ();\n+}\n+\n+/* Call the correct destructor of a HSA operand.  */\n+\n+void\n+hsa_destroy_operand (hsa_op_base *op)\n+{\n+  if (hsa_op_code_list *list = dyn_cast <hsa_op_code_list *> (op))\n+    list->~hsa_op_code_list ();\n+  else if (hsa_op_operand_list *list = dyn_cast <hsa_op_operand_list *> (op))\n+    list->~hsa_op_operand_list ();\n+  else if (hsa_op_reg *reg = dyn_cast <hsa_op_reg *> (op))\n+    reg->~hsa_op_reg ();\n+  else if (hsa_op_immed *immed = dyn_cast <hsa_op_immed *> (op))\n+    immed->~hsa_op_immed ();\n+  else\n+    op->~hsa_op_base ();\n+}\n+\n+/* Create a mapping between the original function DECL and kernel name NAME.  */\n+\n+void\n+hsa_add_kern_decl_mapping (tree decl, char *name, unsigned omp_data_size,\n+\t\t\t   bool gridified_kernel_p)\n+{\n+  hsa_decl_kernel_map_element dkm;\n+  dkm.decl = decl;\n+  dkm.name = name;\n+  dkm.omp_data_size = omp_data_size;\n+  dkm.gridified_kernel_p = gridified_kernel_p;\n+  vec_safe_push (hsa_decl_kernel_mapping, dkm);\n+}\n+\n+/* Return the number of kernel decl name mappings.  */\n+\n+unsigned\n+hsa_get_number_decl_kernel_mappings (void)\n+{\n+  return vec_safe_length (hsa_decl_kernel_mapping);\n+}\n+\n+/* Return the decl in the Ith kernel decl name mapping.  */\n+\n+tree\n+hsa_get_decl_kernel_mapping_decl (unsigned i)\n+{\n+  return (*hsa_decl_kernel_mapping)[i].decl;\n+}\n+\n+/* Return the name in the Ith kernel decl name mapping.  */\n+\n+char *\n+hsa_get_decl_kernel_mapping_name (unsigned i)\n+{\n+  return (*hsa_decl_kernel_mapping)[i].name;\n+}\n+\n+/* Return maximum OMP size for kernel decl name mapping.  */\n+\n+unsigned\n+hsa_get_decl_kernel_mapping_omp_size (unsigned i)\n+{\n+  return (*hsa_decl_kernel_mapping)[i].omp_data_size;\n+}\n+\n+/* Return if the function is gridified kernel in decl name mapping.  */\n+\n+bool\n+hsa_get_decl_kernel_mapping_gridified (unsigned i)\n+{\n+  return (*hsa_decl_kernel_mapping)[i].gridified_kernel_p;\n+}\n+\n+/* Free the mapping between original decls and kernel names.  */\n+\n+void\n+hsa_free_decl_kernel_mapping (void)\n+{\n+  if (hsa_decl_kernel_mapping == NULL)\n+    return;\n+\n+  for (unsigned i = 0; i < hsa_decl_kernel_mapping->length (); ++i)\n+    free ((*hsa_decl_kernel_mapping)[i].name);\n+  ggc_free (hsa_decl_kernel_mapping);\n+}\n+\n+/* Add new kernel dependency.  */\n+\n+void\n+hsa_add_kernel_dependency (tree caller, const char *called_function)\n+{\n+  if (hsa_decl_kernel_dependencies == NULL)\n+    hsa_decl_kernel_dependencies = new hash_map<tree, vec<const char *> *> ();\n+\n+  vec <const char *> *s = NULL;\n+  vec <const char *> **slot = hsa_decl_kernel_dependencies->get (caller);\n+  if (slot == NULL)\n+    {\n+      s = new vec <const char *> ();\n+      hsa_decl_kernel_dependencies->put (caller, s);\n+    }\n+  else\n+    s = *slot;\n+\n+  s->safe_push (called_function);\n+}\n+\n+/* Modify the name P in-place so that it is a valid HSA identifier.  */\n+\n+void\n+hsa_sanitize_name (char *p)\n+{\n+  for (; *p; p++)\n+    if (*p == '.' || *p == '-')\n+      *p = '_';\n+}\n+\n+/* Clone the name P, set trailing ampersand and sanitize the name.  */\n+\n+char *\n+hsa_brig_function_name (const char *p)\n+{\n+  unsigned len = strlen (p);\n+  char *buf = XNEWVEC (char, len + 2);\n+\n+  buf[0] = '&';\n+  buf[len + 1] = '\\0';\n+  memcpy (buf + 1, p, len);\n+\n+  hsa_sanitize_name (buf);\n+  return buf;\n+}\n+\n+/* Return declaration name if exists.  */\n+\n+const char *\n+hsa_get_declaration_name (tree decl)\n+{\n+  if (!DECL_NAME (decl))\n+    {\n+      char buf[64];\n+      snprintf (buf, 64, \"__hsa_anonymous_%i\", DECL_UID (decl));\n+      const char *ggc_str = ggc_strdup (buf);\n+      return ggc_str;\n+    }\n+\n+  tree name_tree;\n+  if (TREE_CODE (decl) == FUNCTION_DECL\n+      || (TREE_CODE (decl) == VAR_DECL && is_global_var (decl)))\n+    name_tree = DECL_ASSEMBLER_NAME (decl);\n+  else\n+    name_tree = DECL_NAME (decl);\n+\n+  const char *name = IDENTIFIER_POINTER (name_tree);\n+  /* User-defined assembly names have prepended asterisk symbol.  */\n+  if (name[0] == '*')\n+    name++;\n+\n+  return name;\n+}\n+\n+void\n+hsa_summary_t::link_functions (cgraph_node *gpu, cgraph_node *host,\n+\t\t\t       hsa_function_kind kind, bool gridified_kernel_p)\n+{\n+  hsa_function_summary *gpu_summary = get (gpu);\n+  hsa_function_summary *host_summary = get (host);\n+\n+  gpu_summary->m_kind = kind;\n+  host_summary->m_kind = kind;\n+\n+  gpu_summary->m_gpu_implementation_p = true;\n+  host_summary->m_gpu_implementation_p = false;\n+\n+  gpu_summary->m_gridified_kernel_p = gridified_kernel_p;\n+  host_summary->m_gridified_kernel_p = gridified_kernel_p;\n+\n+  gpu_summary->m_binded_function = host;\n+  host_summary->m_binded_function = gpu;\n+\n+  tree gdecl = gpu->decl;\n+  DECL_ATTRIBUTES (gdecl)\n+    = tree_cons (get_identifier (\"flatten\"), NULL_TREE,\n+\t\t DECL_ATTRIBUTES (gdecl));\n+\n+  tree fn_opts = DECL_FUNCTION_SPECIFIC_OPTIMIZATION (gdecl);\n+  if (fn_opts == NULL_TREE)\n+    fn_opts = optimization_default_node;\n+  fn_opts = copy_node (fn_opts);\n+  TREE_OPTIMIZATION (fn_opts)->x_flag_tree_loop_vectorize = false;\n+  TREE_OPTIMIZATION (fn_opts)->x_flag_tree_slp_vectorize = false;\n+  DECL_FUNCTION_SPECIFIC_OPTIMIZATION (gdecl) = fn_opts;\n+}\n+\n+/* Add a HOST function to HSA summaries.  */\n+\n+void\n+hsa_register_kernel (cgraph_node *host)\n+{\n+  if (hsa_summaries == NULL)\n+    hsa_summaries = new hsa_summary_t (symtab);\n+  hsa_function_summary *s = hsa_summaries->get (host);\n+  s->m_kind = HSA_KERNEL;\n+}\n+\n+/* Add a pair of functions to HSA summaries.  GPU is an HSA implementation of\n+   a HOST function.  */\n+\n+void\n+hsa_register_kernel (cgraph_node *gpu, cgraph_node *host)\n+{\n+  if (hsa_summaries == NULL)\n+    hsa_summaries = new hsa_summary_t (symtab);\n+  hsa_summaries->link_functions (gpu, host, HSA_KERNEL, true);\n+}\n+\n+/* Return true if expansion of the current HSA function has already failed.  */\n+\n+bool\n+hsa_seen_error (void)\n+{\n+  return hsa_cfun->m_seen_error;\n+}\n+\n+/* Mark current HSA function as failed.  */\n+\n+void\n+hsa_fail_cfun (void)\n+{\n+  hsa_failed_functions->add (hsa_cfun->m_decl);\n+  hsa_cfun->m_seen_error = true;\n+}\n+\n+char *\n+hsa_internal_fn::name ()\n+{\n+  char *name = xstrdup (internal_fn_name (m_fn));\n+  for (char *ptr = name; *ptr; ptr++)\n+    *ptr = TOLOWER (*ptr);\n+\n+  const char *suffix = NULL;\n+  if (m_type_bit_size == 32)\n+    suffix = \"f\";\n+\n+  if (suffix)\n+    {\n+      char *name2 = concat (name, suffix, NULL);\n+      free (name);\n+      name = name2;\n+    }\n+\n+  hsa_sanitize_name (name);\n+  return name;\n+}\n+\n+unsigned\n+hsa_internal_fn::get_arity ()\n+{\n+  switch (m_fn)\n+    {\n+    case IFN_ACOS:\n+    case IFN_ASIN:\n+    case IFN_ATAN:\n+    case IFN_COS:\n+    case IFN_EXP:\n+    case IFN_EXP10:\n+    case IFN_EXP2:\n+    case IFN_EXPM1:\n+    case IFN_LOG:\n+    case IFN_LOG10:\n+    case IFN_LOG1P:\n+    case IFN_LOG2:\n+    case IFN_LOGB:\n+    case IFN_SIGNIFICAND:\n+    case IFN_SIN:\n+    case IFN_SQRT:\n+    case IFN_TAN:\n+    case IFN_CEIL:\n+    case IFN_FLOOR:\n+    case IFN_NEARBYINT:\n+    case IFN_RINT:\n+    case IFN_ROUND:\n+    case IFN_TRUNC:\n+      return 1;\n+    case IFN_ATAN2:\n+    case IFN_COPYSIGN:\n+    case IFN_FMOD:\n+    case IFN_POW:\n+    case IFN_REMAINDER:\n+    case IFN_SCALB:\n+    case IFN_LDEXP:\n+      return 2;\n+      break;\n+    case IFN_CLRSB:\n+    case IFN_CLZ:\n+    case IFN_CTZ:\n+    case IFN_FFS:\n+    case IFN_PARITY:\n+    case IFN_POPCOUNT:\n+    default:\n+      /* As we produce sorry message for unknown internal functions,\n+\t reaching this label is definitely a bug.  */\n+      gcc_unreachable ();\n+    }\n+}\n+\n+BrigType16_t\n+hsa_internal_fn::get_argument_type (int n)\n+{\n+  switch (m_fn)\n+    {\n+    case IFN_ACOS:\n+    case IFN_ASIN:\n+    case IFN_ATAN:\n+    case IFN_COS:\n+    case IFN_EXP:\n+    case IFN_EXP10:\n+    case IFN_EXP2:\n+    case IFN_EXPM1:\n+    case IFN_LOG:\n+    case IFN_LOG10:\n+    case IFN_LOG1P:\n+    case IFN_LOG2:\n+    case IFN_LOGB:\n+    case IFN_SIGNIFICAND:\n+    case IFN_SIN:\n+    case IFN_SQRT:\n+    case IFN_TAN:\n+    case IFN_CEIL:\n+    case IFN_FLOOR:\n+    case IFN_NEARBYINT:\n+    case IFN_RINT:\n+    case IFN_ROUND:\n+    case IFN_TRUNC:\n+    case IFN_ATAN2:\n+    case IFN_COPYSIGN:\n+    case IFN_FMOD:\n+    case IFN_POW:\n+    case IFN_REMAINDER:\n+    case IFN_SCALB:\n+      return hsa_float_for_bitsize (m_type_bit_size);\n+    case IFN_LDEXP:\n+      {\n+\tif (n == -1 || n == 0)\n+\t  return hsa_float_for_bitsize (m_type_bit_size);\n+\telse\n+\t  return BRIG_TYPE_S32;\n+      }\n+    default:\n+      /* As we produce sorry message for unknown internal functions,\n+\t reaching this label is definitely a bug.  */\n+      gcc_unreachable ();\n+    }\n+}\n+\n+#include \"gt-hsa.h\""}, {"sha": "f0436f3cf69190ecdf5680b869cdbcc5d626f3ee", "filename": "gcc/hsa.h", "status": "added", "additions": 1402, "deletions": 0, "changes": 1402, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fhsa.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,1402 @@\n+/* HSAIL and BRIG related macros and definitions.\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef HSA_H\n+#define HSA_H\n+\n+#include \"hsa-brig-format.h\"\n+#include \"is-a.h\"\n+#include \"predict.h\"\n+#include \"tree.h\"\n+#include \"vec.h\"\n+#include \"hash-table.h\"\n+#include \"basic-block.h\"\n+\n+\n+/* Return true if the compiler should produce HSAIL.  */\n+\n+static inline bool\n+hsa_gen_requested_p (void)\n+{\n+#ifndef ENABLE_HSA\n+  return false;\n+#endif\n+  return !flag_disable_hsa;\n+}\n+\n+/* Standard warning message if we failed to generate HSAIL for a function.  */\n+\n+#define HSA_SORRY_MSG \"could not emit HSAIL for the function\"\n+\n+class hsa_op_immed;\n+class hsa_op_cst_list;\n+class hsa_insn_basic;\n+class hsa_op_address;\n+class hsa_op_reg;\n+class hsa_bb;\n+typedef hsa_insn_basic *hsa_insn_basic_p;\n+\n+/* Class representing an input argument, output argument (result) or a\n+   variable, that will eventually end up being a symbol directive.  */\n+\n+struct hsa_symbol\n+{\n+  /* Constructor.  */\n+  hsa_symbol (BrigType16_t type, BrigSegment8_t segment,\n+\t      BrigLinkage8_t linkage, bool global_scope_p = false,\n+\t      BrigAllocation allocation = BRIG_ALLOCATION_AUTOMATIC);\n+\n+  /* Return total size of the symbol.  */\n+  unsigned HOST_WIDE_INT total_byte_size ();\n+\n+  /* Fill in those values into the symbol according to DECL, which are\n+     determined independently from whether it is parameter, result,\n+     or a variable, local or global.  */\n+  void fillup_for_decl (tree decl);\n+\n+  /* Pointer to the original tree, which is PARM_DECL for input parameters and\n+     RESULT_DECL for the output parameters.  */\n+  tree m_decl;\n+\n+  /* Name of the symbol, that will be written into output and dumps.  Can be\n+     NULL, see name_number below.  */\n+  const char *m_name;\n+\n+  /* If name is NULL, artificial name will be formed from the segment name and\n+     this number.  */\n+  int m_name_number;\n+\n+  /* Once written, this is the offset of the associated symbol directive.  Zero\n+     means the symbol has not been written yet.  */\n+  unsigned m_directive_offset;\n+\n+  /* HSA type of the parameter.  */\n+  BrigType16_t m_type;\n+\n+  /* The HSA segment this will eventually end up in.  */\n+  BrigSegment8_t m_segment;\n+\n+  /* The HSA kind of linkage.  */\n+  BrigLinkage8_t m_linkage;\n+\n+  /* Array dimension, if non-zero.  */\n+  unsigned HOST_WIDE_INT m_dim;\n+\n+  /* Constant value, used for string constants.  */\n+  hsa_op_immed *m_cst_value;\n+\n+  /* Is in global scope.  */\n+  bool m_global_scope_p;\n+\n+  /* True if an error has been seen for the symbol.  */\n+  bool m_seen_error;\n+\n+  /* Symbol allocation.  */\n+  BrigAllocation m_allocation;\n+\n+private:\n+  /* Default constructor.  */\n+  hsa_symbol ();\n+};\n+\n+/* Abstract class for HSA instruction operands.  */\n+\n+class hsa_op_base\n+{\n+public:\n+  /* Next operand scheduled to be written when writing BRIG operand\n+     section.  */\n+  hsa_op_base *m_next;\n+\n+  /* Offset to which the associated operand structure will be written.  Zero if\n+     yet not scheduled for writing.  */\n+  unsigned m_brig_op_offset;\n+\n+  /* The type of a particular operand.  */\n+  BrigKind16_t m_kind;\n+\n+protected:\n+  hsa_op_base (BrigKind16_t k);\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_op_base () {}\n+};\n+\n+/* Common abstract ancestor for operands which have a type.  */\n+\n+class hsa_op_with_type : public hsa_op_base\n+{\n+public:\n+  /* The type.  */\n+  BrigType16_t m_type;\n+\n+  /* Convert an operand to a destination type DTYPE and attach insns\n+     to HBB if needed.  */\n+  hsa_op_with_type *get_in_type (BrigType16_t dtype, hsa_bb *hbb);\n+\n+protected:\n+  hsa_op_with_type (BrigKind16_t k, BrigType16_t t);\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_op_with_type () : hsa_op_base (BRIG_KIND_NONE) {}\n+};\n+\n+/* An immediate HSA operand.  */\n+\n+class hsa_op_immed : public hsa_op_with_type\n+{\n+public:\n+  hsa_op_immed (tree tree_val, bool min32int = true);\n+  hsa_op_immed (HOST_WIDE_INT int_value, BrigType16_t type);\n+  void *operator new (size_t);\n+  ~hsa_op_immed ();\n+  void set_type (BrigKind16_t t);\n+\n+  /* Value as represented by middle end.  */\n+  tree m_tree_value;\n+\n+  /* Integer value representation.  */\n+  HOST_WIDE_INT m_int_value;\n+\n+  /* Brig data representation.  */\n+  char *m_brig_repr;\n+\n+  /* Brig data representation size in bytes.  */\n+  unsigned m_brig_repr_size;\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_op_immed ();\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+  void emit_to_buffer (tree value);\n+};\n+\n+/* Report whether or not P is a an immediate operand.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_op_immed *>::test (hsa_op_base *p)\n+{\n+  return p->m_kind == BRIG_KIND_OPERAND_CONSTANT_BYTES;\n+}\n+\n+/* HSA register operand.  */\n+\n+class hsa_op_reg : public hsa_op_with_type\n+{\n+  friend class hsa_insn_basic;\n+  friend class hsa_insn_phi;\n+public:\n+  hsa_op_reg (BrigType16_t t);\n+  void *operator new (size_t);\n+\n+  /* Verify register operand.  */\n+  void verify_ssa ();\n+\n+  /* If NON-NULL, gimple SSA that we come from.  NULL if none.  */\n+  tree m_gimple_ssa;\n+\n+  /* Defining instruction while still in the SSA.  */\n+  hsa_insn_basic *m_def_insn;\n+\n+  /* If the register allocator decides to spill the register, this is the\n+     appropriate spill symbol.  */\n+  hsa_symbol *m_spill_sym;\n+\n+  /* Number of this register structure in the order in which they were\n+     allocated.  */\n+  int m_order;\n+  int m_lr_begin, m_lr_end;\n+\n+  /* Zero if the register is not yet allocated.  After, allocation, this must\n+     be 'c', 's', 'd' or 'q'.  */\n+  char m_reg_class;\n+  /* If allocated, the number of the HW register (within its HSA register\n+     class).  */\n+  char m_hard_num;\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_op_reg () : hsa_op_with_type (BRIG_KIND_NONE, BRIG_TYPE_NONE) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+  /* Set definition where the register is defined.  */\n+  void set_definition (hsa_insn_basic *insn);\n+  /* Uses of the value while still in SSA.  */\n+  auto_vec <hsa_insn_basic_p> m_uses;\n+};\n+\n+typedef class hsa_op_reg *hsa_op_reg_p;\n+\n+/* Report whether or not P is a register operand.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_op_reg *>::test (hsa_op_base *p)\n+{\n+  return p->m_kind == BRIG_KIND_OPERAND_REGISTER;\n+}\n+\n+/* Report whether or not P is a register operand.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_op_reg *>::test (hsa_op_with_type *p)\n+{\n+  return p->m_kind == BRIG_KIND_OPERAND_REGISTER;\n+}\n+\n+/* An address HSA operand.  */\n+\n+class hsa_op_address : public hsa_op_base\n+{\n+public:\n+  /* set up a new address operand consisting of base symbol SYM, register R and\n+     immediate OFFSET.  If the machine model is not large and offset is 64 bit,\n+     the upper, 32 bits have to be zero.  */\n+  hsa_op_address (hsa_symbol *sym, hsa_op_reg *reg,\n+\t\t  HOST_WIDE_INT offset = 0);\n+\n+  void *operator new (size_t);\n+\n+  /* Set up a new address operand consisting of base symbol SYM and\n+     immediate OFFSET.  If the machine model is not large and offset is 64 bit,\n+     the upper, 32 bits have to be zero.  */\n+  hsa_op_address (hsa_symbol *sym, HOST_WIDE_INT offset = 0);\n+\n+  /* Set up a new address operand consisting of register R and\n+     immediate OFFSET.  If the machine model is not large and offset is 64 bit,\n+     the upper, 32 bits have to be zero.  */\n+  hsa_op_address (hsa_op_reg *reg, HOST_WIDE_INT offset = 0);\n+\n+  /* Symbol base of the address.  Can be NULL if there is none.  */\n+  hsa_symbol *m_symbol;\n+\n+  /* Register offset.  Can be NULL if there is none.  */\n+  hsa_op_reg *m_reg;\n+\n+  /* Immediate byte offset.  */\n+  HOST_WIDE_INT m_imm_offset;\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_op_address () : hsa_op_base (BRIG_KIND_NONE) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is an address operand.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_op_address *>::test (hsa_op_base *p)\n+{\n+  return p->m_kind == BRIG_KIND_OPERAND_ADDRESS;\n+}\n+\n+/* A reference to code HSA operand.  It can be either reference\n+   to a start of a BB or a start of a function.  */\n+\n+class hsa_op_code_ref : public hsa_op_base\n+{\n+public:\n+  hsa_op_code_ref ();\n+\n+  /* Offset in the code section that this refers to.  */\n+  unsigned m_directive_offset;\n+};\n+\n+/* Report whether or not P is a code reference operand.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_op_code_ref *>::test (hsa_op_base *p)\n+{\n+  return p->m_kind == BRIG_KIND_OPERAND_CODE_REF;\n+}\n+\n+/* Code list HSA operand.  */\n+\n+class hsa_op_code_list: public hsa_op_base\n+{\n+public:\n+  hsa_op_code_list (unsigned elements);\n+  void *operator new (size_t);\n+\n+  /* Offset to variable-sized array in hsa_data section, where\n+     are offsets to entries in the hsa_code section.  */\n+  auto_vec<unsigned> m_offsets;\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_op_code_list () : hsa_op_base (BRIG_KIND_NONE) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a code list operand.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_op_code_list *>::test (hsa_op_base *p)\n+{\n+  return p->m_kind == BRIG_KIND_OPERAND_CODE_LIST;\n+}\n+\n+/* Operand list HSA operand.  */\n+\n+class hsa_op_operand_list: public hsa_op_base\n+{\n+public:\n+  hsa_op_operand_list (unsigned elements);\n+  ~hsa_op_operand_list ();\n+  void *operator new (size_t);\n+\n+  /* Offset to variable-sized array in hsa_data section, where\n+     are offsets to entries in the hsa_code section.  */\n+  auto_vec<unsigned> m_offsets;\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_op_operand_list () : hsa_op_base (BRIG_KIND_NONE) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a code list operand.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_op_operand_list *>::test (hsa_op_base *p)\n+{\n+  return p->m_kind == BRIG_KIND_OPERAND_OPERAND_LIST;\n+}\n+\n+/* Opcodes of instructions that are not part of HSA but that we use to\n+   represent it nevertheless.  */\n+\n+#define HSA_OPCODE_PHI (-1)\n+#define HSA_OPCODE_ARG_BLOCK (-2)\n+\n+/* The number of operand pointers we can directly in an instruction.  */\n+#define HSA_BRIG_INT_STORAGE_OPERANDS 5\n+\n+/* Class representing an HSA instruction.  Unlike typical ancestors for\n+   specialized classes, this one is also directly used for all instructions\n+   that are then represented as BrigInstBasic.  */\n+\n+class hsa_insn_basic\n+{\n+public:\n+  hsa_insn_basic (unsigned nops, int opc);\n+  hsa_insn_basic (unsigned nops, int opc, BrigType16_t t,\n+\t\t  hsa_op_base *arg0 = NULL,\n+\t\t  hsa_op_base *arg1 = NULL,\n+\t\t  hsa_op_base *arg2 = NULL,\n+\t\t  hsa_op_base *arg3 = NULL);\n+\n+  void *operator new (size_t);\n+  void set_op (int index, hsa_op_base *op);\n+  hsa_op_base *get_op (int index);\n+  hsa_op_base **get_op_addr (int index);\n+  unsigned int operand_count ();\n+  void verify ();\n+  unsigned input_count ();\n+  unsigned num_used_ops ();\n+  void set_output_in_type (hsa_op_reg *dest, unsigned op_index, hsa_bb *hbb);\n+  bool op_output_p (unsigned opnum);\n+\n+  /* The previous and next instruction in the basic block.  */\n+  hsa_insn_basic *m_prev, *m_next;\n+\n+  /* Basic block this instruction belongs to.  */\n+  basic_block m_bb;\n+\n+  /* Operand code distinguishing different types of instructions.  Eventually\n+     these should only be BRIG_INST_* values from the BrigOpcode16_t range but\n+     initially we use negative values for PHI nodes and such.  */\n+  int m_opcode;\n+\n+  /* Linearized number assigned to the instruction by HSA RA.  */\n+  int m_number;\n+\n+  /* Type of the destination of the operations.  */\n+  BrigType16_t m_type;\n+\n+  /* BRIG offset of the instruction in code section.  */\n+  unsigned int m_brig_offset;\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_basic () {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+  /* The individual operands.  All instructions but PHI nodes have five or\n+     fewer instructions and so will fit the internal storage.  */\n+  /* TODO: Vast majority of instructions have three or fewer operands, so we\n+     may actually try reducing it.  */\n+  auto_vec<hsa_op_base *, HSA_BRIG_INT_STORAGE_OPERANDS> m_operands;\n+};\n+\n+/* Class representing a PHI node of the SSA form of HSA virtual\n+   registers.  */\n+\n+class hsa_insn_phi : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_phi (unsigned nops, hsa_op_reg *dst);\n+\n+  void *operator new (size_t);\n+\n+  /* Destination.  */\n+  hsa_op_reg *m_dest;\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_phi () : hsa_insn_basic (1, HSA_OPCODE_PHI) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a PHI node.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_phi *>::test (hsa_insn_basic *p)\n+{\n+  return p->m_opcode == HSA_OPCODE_PHI;\n+}\n+\n+/* HSA instruction for branches.  Currently we explicitely represent only\n+   conditional branches.  */\n+\n+class hsa_insn_br : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_br (hsa_op_reg *ctrl);\n+\n+  void *operator new (size_t);\n+\n+  /* Width as described in HSA documentation.  */\n+  BrigWidth8_t m_width;\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_br () : hsa_insn_basic (1, BRIG_OPCODE_CBR) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether P is a branching instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_br *>::test (hsa_insn_basic *p)\n+{\n+  return p->m_opcode == BRIG_OPCODE_BR\n+    || p->m_opcode == BRIG_OPCODE_CBR;\n+}\n+\n+/* HSA instruction for switch branches.  */\n+\n+class hsa_insn_sbr : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_sbr (hsa_op_reg *index, unsigned jump_count);\n+\n+  /* Default destructor.  */\n+  ~hsa_insn_sbr ();\n+\n+  void *operator new (size_t);\n+\n+  void replace_all_labels (basic_block old_bb, basic_block new_bb);\n+\n+  /* Width as described in HSA documentation.  */\n+  BrigWidth8_t m_width;\n+\n+  /* Jump table.  */\n+  vec <basic_block> m_jump_table;\n+\n+  /* Default label basic block.  */\n+  basic_block m_default_bb;\n+\n+  /* Code list for label references.  */\n+  hsa_op_code_list *m_label_code_list;\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_sbr () : hsa_insn_basic (1, BRIG_OPCODE_SBR) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether P is a switch branching instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_sbr *>::test (hsa_insn_basic *p)\n+{\n+  return p->m_opcode == BRIG_OPCODE_SBR;\n+}\n+\n+/* HSA instruction for comparisons.  */\n+\n+class hsa_insn_cmp : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_cmp (BrigCompareOperation8_t cmp, BrigType16_t t,\n+\t\thsa_op_base *arg0 = NULL, hsa_op_base *arg1 = NULL,\n+\t\thsa_op_base *arg2 = NULL);\n+\n+  void *operator new (size_t);\n+\n+  /* Source type should be derived from operand types.  */\n+\n+  /* The comparison operation.  */\n+  BrigCompareOperation8_t m_compare;\n+\n+  /* TODO: Modifiers and packing control are missing but so are everywhere\n+     else.  */\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_cmp () : hsa_insn_basic (1, BRIG_OPCODE_CMP) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a comparison instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_cmp *>::test (hsa_insn_basic *p)\n+{\n+  return p->m_opcode == BRIG_OPCODE_CMP;\n+}\n+\n+/* HSA instruction for memory operations.  */\n+\n+class hsa_insn_mem : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_mem (int opc, BrigType16_t t, hsa_op_base *arg0, hsa_op_base *arg1);\n+\n+  void *operator new (size_t);\n+\n+  /* Set alignment to VALUE.  */\n+\n+  void set_align (BrigAlignment8_t value);\n+\n+  /* The segment is of the memory access is either the segment of the symbol in\n+     the address operand or flat address is there is no symbol there.  */\n+\n+  /* Required alignment of the memory operation.  */\n+  BrigAlignment8_t m_align;\n+\n+  /* HSA equiv class, basically an alias set number.  */\n+  uint8_t m_equiv_class;\n+\n+  /* TODO:  Add width modifier, perhaps also other things.  */\n+protected:\n+  hsa_insn_mem (unsigned nops, int opc, BrigType16_t t,\n+\t\thsa_op_base *arg0 = NULL, hsa_op_base *arg1 = NULL,\n+\t\thsa_op_base *arg2 = NULL, hsa_op_base *arg3 = NULL);\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_mem () : hsa_insn_basic (1, BRIG_OPCODE_LD) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a memory instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_mem *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_LD\n+\t  || p->m_opcode == BRIG_OPCODE_ST);\n+}\n+\n+/* HSA instruction for atomic operations.  */\n+\n+class hsa_insn_atomic : public hsa_insn_mem\n+{\n+public:\n+  hsa_insn_atomic (int nops, int opc, enum BrigAtomicOperation aop,\n+\t\t   BrigType16_t t, BrigMemoryOrder memorder,\n+\t\t   hsa_op_base *arg0 = NULL, hsa_op_base *arg1 = NULL,\n+\t\t   hsa_op_base *arg2 = NULL, hsa_op_base *arg3 = NULL);\n+  void *operator new (size_t);\n+\n+  /* The operation itself.  */\n+  enum BrigAtomicOperation m_atomicop;\n+\n+  /* Things like acquire/release/aligned.  */\n+  enum BrigMemoryOrder m_memoryorder;\n+\n+  /* Scope of the atomic operation.  */\n+  enum BrigMemoryScope m_memoryscope;\n+\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_atomic () : hsa_insn_mem (1, BRIG_KIND_NONE, BRIG_TYPE_NONE) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is an atomic instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_atomic *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_ATOMIC\n+\t  || p->m_opcode == BRIG_OPCODE_ATOMICNORET);\n+}\n+\n+/* HSA instruction for signal operations.  */\n+\n+class hsa_insn_signal : public hsa_insn_atomic\n+{\n+public:\n+  hsa_insn_signal (int nops, int opc, enum BrigAtomicOperation sop,\n+\t\t   BrigType16_t t, hsa_op_base *arg0 = NULL,\n+\t\t   hsa_op_base *arg1 = NULL,\n+\t\t   hsa_op_base *arg2 = NULL, hsa_op_base *arg3 = NULL);\n+\n+  void *operator new (size_t);\n+\n+private:\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a signal instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_signal *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_SIGNAL\n+\t  || p->m_opcode == BRIG_OPCODE_SIGNALNORET);\n+}\n+\n+/* HSA instruction to convert between flat addressing and segments.  */\n+\n+class hsa_insn_seg : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_seg (int opc, BrigType16_t destt, BrigType16_t srct,\n+\t\tBrigSegment8_t seg, hsa_op_base *arg0, hsa_op_base *arg1);\n+\n+  void *operator new (size_t);\n+\n+  /* Source type.  Depends on the source addressing/segment.  */\n+  BrigType16_t m_src_type;\n+  /* The segment we are converting from or to.  */\n+  BrigSegment8_t m_segment;\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_seg () : hsa_insn_basic (1, BRIG_OPCODE_STOF) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a segment conversion instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_seg *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_STOF\n+\t  || p->m_opcode == BRIG_OPCODE_FTOS);\n+}\n+\n+/* Class for internal functions for purpose of HSA emission.  */\n+\n+class hsa_internal_fn\n+{\n+public:\n+  hsa_internal_fn (enum internal_fn fn, unsigned type_bit_size):\n+    m_fn (fn), m_type_bit_size (type_bit_size), m_offset (0) {}\n+\n+  hsa_internal_fn (const hsa_internal_fn *f):\n+    m_fn (f->m_fn), m_type_bit_size (f->m_type_bit_size),\n+    m_offset (f->m_offset) {}\n+\n+  /* Return arity of the internal function.  */\n+  unsigned get_arity ();\n+\n+  /* Return BRIG type of N-th argument, if -1 is passed, return value type\n+     is received.  */\n+  BrigType16_t get_argument_type (int n);\n+\n+  /* Return function name.  The memory must be released by a caller.  */\n+  char *name ();\n+\n+  /* Internal function.  */\n+  enum internal_fn m_fn;\n+\n+  /* Bit width of return type.  */\n+  unsigned m_type_bit_size;\n+\n+  /* BRIG offset of declaration of the function.  */\n+  BrigCodeOffset32_t m_offset;\n+};\n+\n+/* HSA instruction for function call.  */\n+\n+class hsa_insn_call : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_call (tree callee);\n+  hsa_insn_call (hsa_internal_fn *fn);\n+\n+  /* Default destructor.  */\n+  ~hsa_insn_call ();\n+\n+  void *operator new (size_t);\n+\n+  /* Called function.  */\n+  tree m_called_function;\n+\n+  /* Called internal function.  */\n+  hsa_internal_fn *m_called_internal_fn;\n+\n+  /* Input formal arguments.  */\n+  auto_vec <hsa_symbol *> m_input_args;\n+\n+  /* Input arguments store instructions.  */\n+  auto_vec <hsa_insn_mem *> m_input_arg_insns;\n+\n+  /* Output argument, can be NULL for void functions.  */\n+  hsa_symbol *m_output_arg;\n+\n+  /* Called function code reference.  */\n+  hsa_op_code_ref m_func;\n+\n+  /* Code list for arguments of the function.  */\n+  hsa_op_code_list *m_args_code_list;\n+\n+  /* Code list for result of the function.  */\n+  hsa_op_code_list *m_result_code_list;\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_insn_call () : hsa_insn_basic (0, BRIG_OPCODE_CALL) {}\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a call instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_call *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_CALL);\n+}\n+\n+/* HSA call instruction block encapsulates definition of arguments,\n+   result type, corresponding loads and a possible store.\n+   Moreover, it contains a single call instruction.\n+   Emission of the instruction will produce multiple\n+   HSAIL instructions.  */\n+\n+class hsa_insn_arg_block : public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_arg_block (BrigKind brig_kind, hsa_insn_call * call);\n+\n+  void *operator new (size_t);\n+\n+  /* Kind of argument block.  */\n+  BrigKind m_kind;\n+\n+  /* Call instruction.  */\n+  hsa_insn_call *m_call_insn;\n+private:\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Report whether or not P is a call block instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_arg_block *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == HSA_OPCODE_ARG_BLOCK);\n+}\n+\n+/* HSA comment instruction.  */\n+\n+class hsa_insn_comment: public hsa_insn_basic\n+{\n+public:\n+  /* Constructor of class representing the comment in HSAIL.  */\n+  hsa_insn_comment (const char *s);\n+\n+  /* Default destructor.  */\n+  ~hsa_insn_comment ();\n+\n+  void *operator new (size_t);\n+\n+  char *m_comment;\n+};\n+\n+/* Report whether or not P is a call block instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_comment *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_KIND_DIRECTIVE_COMMENT);\n+}\n+\n+/* HSA queue instruction.  */\n+\n+class hsa_insn_queue: public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_queue (int nops, BrigOpcode opcode);\n+\n+  /* Destructor.  */\n+  ~hsa_insn_queue ();\n+};\n+\n+/* Report whether or not P is a queue instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_queue *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_ADDQUEUEWRITEINDEX);\n+}\n+\n+/* HSA source type instruction.  */\n+\n+class hsa_insn_srctype: public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_srctype (int nops, BrigOpcode opcode, BrigType16_t destt,\n+\t\t   BrigType16_t srct, hsa_op_base *arg0, hsa_op_base *arg1,\n+\t\t   hsa_op_base *arg2);\n+\n+  /* Pool allocator.  */\n+  void *operator new (size_t);\n+\n+  /* Source type.  */\n+  BrigType16_t m_source_type;\n+\n+  /* Destructor.  */\n+  ~hsa_insn_srctype ();\n+};\n+\n+/* Report whether or not P is a source type instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_srctype *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_POPCOUNT\n+\t  || p->m_opcode == BRIG_OPCODE_FIRSTBIT\n+\t  || p->m_opcode == BRIG_OPCODE_LASTBIT);\n+}\n+\n+/* HSA packed instruction.  */\n+\n+class hsa_insn_packed : public hsa_insn_srctype\n+{\n+public:\n+  hsa_insn_packed (int nops, BrigOpcode opcode, BrigType16_t destt,\n+\t\t   BrigType16_t srct, hsa_op_base *arg0, hsa_op_base *arg1,\n+\t\t   hsa_op_base *arg2);\n+\n+  /* Pool allocator.  */\n+  void *operator new (size_t);\n+\n+  /* Operand list for an operand of the instruction.  */\n+  hsa_op_operand_list *m_operand_list;\n+\n+  /* Destructor.  */\n+  ~hsa_insn_packed ();\n+};\n+\n+/* Report whether or not P is a combine instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_packed *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_COMBINE\n+\t  || p->m_opcode == BRIG_OPCODE_EXPAND);\n+}\n+\n+/* HSA convert instruction.  */\n+\n+class hsa_insn_cvt: public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_cvt (hsa_op_with_type *dest, hsa_op_with_type *src);\n+\n+  /* Pool allocator.  */\n+  void *operator new (size_t);\n+};\n+\n+/* Report whether or not P is a convert instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_cvt *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_CVT);\n+}\n+\n+/* HSA alloca instruction.  */\n+\n+class hsa_insn_alloca: public hsa_insn_basic\n+{\n+public:\n+  hsa_insn_alloca (hsa_op_with_type *dest, hsa_op_with_type *size,\n+\t\t   unsigned alignment = 0);\n+\n+  /* Required alignment of the allocation.  */\n+  BrigAlignment8_t m_align;\n+\n+  /* Pool allocator.  */\n+  void *operator new (size_t);\n+};\n+\n+/* Report whether or not P is an alloca instruction.  */\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <hsa_insn_alloca *>::test (hsa_insn_basic *p)\n+{\n+  return (p->m_opcode == BRIG_OPCODE_ALLOCA);\n+}\n+\n+/* Basic block of HSA instructions.  */\n+\n+class hsa_bb\n+{\n+public:\n+  hsa_bb (basic_block cfg_bb);\n+  hsa_bb (basic_block cfg_bb, int idx);\n+  ~hsa_bb ();\n+\n+  /* Append an instruction INSN into the basic block.  */\n+  void append_insn (hsa_insn_basic *insn);\n+\n+  /* The real CFG BB that this HBB belongs to.  */\n+  basic_block m_bb;\n+\n+  /* The operand that refers to the label to this BB.  */\n+  hsa_op_code_ref m_label_ref;\n+\n+  /* The first and last instruction.  */\n+  hsa_insn_basic *m_first_insn, *m_last_insn;\n+  /* The first and last phi node.  */\n+  hsa_insn_phi *m_first_phi, *m_last_phi;\n+\n+  /* Just a number to construct names from.  */\n+  int m_index;\n+\n+  bitmap m_liveout, m_livein;\n+private:\n+  /* Make the default constructor inaccessible.  */\n+  hsa_bb ();\n+  /* All objects are deallocated by destroying their pool, so make delete\n+     inaccessible too.  */\n+  void operator delete (void *) {}\n+};\n+\n+/* Return the corresponding HSA basic block structure for the given control\n+   flow basic_block BB.  */\n+\n+static inline hsa_bb *\n+hsa_bb_for_bb (basic_block bb)\n+{\n+  return (struct hsa_bb *) bb->aux;\n+}\n+\n+/* Class for hashing local hsa_symbols.  */\n+\n+struct hsa_noop_symbol_hasher : nofree_ptr_hash <hsa_symbol>\n+{\n+  static inline hashval_t hash (const value_type);\n+  static inline bool equal (const value_type, const compare_type);\n+};\n+\n+/* Hash hsa_symbol.  */\n+\n+inline hashval_t\n+hsa_noop_symbol_hasher::hash (const value_type item)\n+{\n+  return DECL_UID (item->m_decl);\n+}\n+\n+/* Return true if the DECL_UIDs of decls both symbols refer to are equal.  */\n+\n+inline bool\n+hsa_noop_symbol_hasher::equal (const value_type a, const compare_type b)\n+{\n+  return (DECL_UID (a->m_decl) == DECL_UID (b->m_decl));\n+}\n+\n+/* Structure that encapsulates intermediate representation of a HSA\n+   function.  */\n+\n+class hsa_function_representation\n+{\n+public:\n+  hsa_function_representation (tree fdecl, bool kernel_p,\n+\t\t\t       unsigned ssa_names_count);\n+  hsa_function_representation (hsa_internal_fn *fn);\n+  ~hsa_function_representation ();\n+\n+  /* Builds a shadow register that is utilized to a kernel dispatch.  */\n+  hsa_op_reg *get_shadow_reg ();\n+\n+  /* Return true if we are in a function that has kernel dispatch\n+     shadow register.  */\n+  bool has_shadow_reg_p ();\n+\n+  /* The entry/exit blocks don't contain incoming code,\n+     but the HSA generator might use them to put code into,\n+     so we need hsa_bb instances of them.  */\n+  void init_extra_bbs ();\n+\n+  /* Return linkage of the representation.  */\n+  BrigLinkage8_t get_linkage ();\n+\n+  /* Create a private symbol of requested TYPE.  */\n+  hsa_symbol *create_hsa_temporary (BrigType16_t type);\n+\n+  /* Lookup or create a HSA pseudo register for a given gimple SSA name.  */\n+  hsa_op_reg *reg_for_gimple_ssa (tree ssa);\n+\n+  /* Name of the function.  */\n+  char *m_name;\n+\n+  /* Number of allocated register structures.  */\n+  int m_reg_count;\n+\n+  /* Input arguments.  */\n+  vec <hsa_symbol *> m_input_args;\n+\n+  /* Output argument or NULL if there is none.  */\n+  hsa_symbol *m_output_arg;\n+\n+  /* Hash table of local variable symbols.  */\n+  hash_table <hsa_noop_symbol_hasher> *m_local_symbols;\n+\n+  /* Hash map for string constants.  */\n+  hash_map <tree, hsa_symbol *> m_string_constants_map;\n+\n+  /* Vector of pointers to spill symbols.  */\n+  vec <struct hsa_symbol *> m_spill_symbols;\n+\n+  /* Vector of pointers to global variables and transformed string constants\n+     that are used by the function.  */\n+  vec <struct hsa_symbol *> m_global_symbols;\n+\n+  /* Private function artificial variables.  */\n+  vec <struct hsa_symbol *> m_private_variables;\n+\n+  /* Vector of called function declarations.  */\n+  vec <tree> m_called_functions;\n+\n+  /* Vector of used internal functions.  */\n+  vec <hsa_internal_fn *> m_called_internal_fns;\n+\n+  /* Number of HBB BBs.  */\n+  int m_hbb_count;\n+\n+  /* Whether or not we could check and enforce SSA properties.  */\n+  bool m_in_ssa;\n+\n+  /* True if the function is kernel function.  */\n+  bool m_kern_p;\n+\n+  /* True if the function representation is a declaration.  */\n+  bool m_declaration_p;\n+\n+  /* Function declaration tree.  */\n+  tree m_decl;\n+\n+  /* Internal function info is used for declarations of internal functions.  */\n+  hsa_internal_fn *m_internal_fn;\n+\n+  /* Runtime shadow register.  */\n+  hsa_op_reg *m_shadow_reg;\n+\n+  /* Number of kernel dispatched which take place in the function.  */\n+  unsigned m_kernel_dispatch_count;\n+\n+  /* If the function representation contains a kernel dispatch,\n+     OMP data size is necessary memory that is used for copying before\n+     a kernel dispatch.  */\n+  unsigned m_maximum_omp_data_size;\n+\n+  /* Return true if there's an HSA-specific warning already seen.  */\n+  bool m_seen_error;\n+\n+  /* Counter for temporary symbols created in the function representation.  */\n+  unsigned m_temp_symbol_count;\n+\n+  /* SSA names mapping.  */\n+  vec <hsa_op_reg_p> m_ssa_map;\n+};\n+\n+enum hsa_function_kind\n+{\n+  HSA_NONE,\n+  HSA_KERNEL,\n+  HSA_FUNCTION\n+};\n+\n+struct hsa_function_summary\n+{\n+  /* Default constructor.  */\n+  hsa_function_summary ();\n+\n+  /* Kind of GPU/host function.  */\n+  hsa_function_kind m_kind;\n+\n+  /* Pointer to a cgraph node which is a HSA implementation of the function.\n+     In case of the function is a HSA function, the binded function points\n+     to the host function.  */\n+  cgraph_node *m_binded_function;\n+\n+  /* Identifies if the function is an HSA function or a host function.  */\n+  bool m_gpu_implementation_p;\n+\n+  /* True if the function is a gridified kernel.  */\n+  bool m_gridified_kernel_p;\n+};\n+\n+inline\n+hsa_function_summary::hsa_function_summary (): m_kind (HSA_NONE),\n+  m_binded_function (NULL), m_gpu_implementation_p (false)\n+{\n+}\n+\n+/* Function summary for HSA functions.  */\n+class hsa_summary_t: public function_summary <hsa_function_summary *>\n+{\n+public:\n+  hsa_summary_t (symbol_table *table):\n+    function_summary<hsa_function_summary *> (table) { }\n+\n+  /* Couple GPU and HOST as gpu-specific and host-specific implementation of\n+     the same function.  KIND determines whether GPU is a host-invokable kernel\n+     or gpu-callable function and GRIDIFIED_KERNEL_P is set if the function was\n+     gridified in OMP.  */\n+\n+  void link_functions (cgraph_node *gpu, cgraph_node *host,\n+\t\t       hsa_function_kind kind, bool gridified_kernel_p);\n+};\n+\n+/* OMP simple builtin describes behavior that should be done for\n+   the routine.  */\n+class omp_simple_builtin\n+{\n+public:\n+  omp_simple_builtin (const char *name, const char *warning_message,\n+\t       bool sorry, hsa_op_immed *return_value = NULL):\n+    m_name (name), m_warning_message (warning_message), m_sorry (sorry),\n+    m_return_value (return_value)\n+  {}\n+\n+  /* Generate HSAIL instructions for the builtin or produce warning message.  */\n+  void generate (gimple *stmt, hsa_bb *hbb);\n+\n+  /* Name of function.  */\n+  const char *m_name;\n+\n+  /* Warning message.  */\n+  const char *m_warning_message;\n+\n+  /* Flag if we should sorry after the warning message is printed.  */\n+  bool m_sorry;\n+\n+  /* Return value of the function.  */\n+  hsa_op_immed *m_return_value;\n+\n+  /* Emission function.  */\n+  void (*m_emit_func) (gimple *stmt, hsa_bb *);\n+};\n+\n+/* Class for hashing hsa_internal_fn.  */\n+\n+struct hsa_internal_fn_hasher: free_ptr_hash <hsa_internal_fn>\n+{\n+  static inline hashval_t hash (const value_type);\n+  static inline bool equal (const value_type, const compare_type);\n+};\n+\n+/* Hash hsa_symbol.  */\n+\n+inline hashval_t\n+hsa_internal_fn_hasher::hash (const value_type item)\n+{\n+  return item->m_fn;\n+}\n+\n+/* Return true if the DECL_UIDs of decls both symbols refer to  are equal.  */\n+\n+inline bool\n+hsa_internal_fn_hasher::equal (const value_type a, const compare_type b)\n+{\n+  return a->m_fn == b->m_fn && a->m_type_bit_size == b->m_type_bit_size;\n+}\n+\n+/* in hsa.c */\n+extern struct hsa_function_representation *hsa_cfun;\n+extern hash_map <tree, vec <const char *> *> *hsa_decl_kernel_dependencies;\n+extern hsa_summary_t *hsa_summaries;\n+extern hsa_symbol *hsa_num_threads;\n+extern unsigned hsa_kernel_calls_counter;\n+extern hash_set <tree> *hsa_failed_functions;\n+extern hash_table <hsa_noop_symbol_hasher> *hsa_global_variable_symbols;\n+\n+bool hsa_callable_function_p (tree fndecl);\n+void hsa_init_compilation_unit_data (void);\n+void hsa_deinit_compilation_unit_data (void);\n+bool hsa_machine_large_p (void);\n+bool hsa_full_profile_p (void);\n+bool hsa_opcode_floating_bit_insn_p (BrigOpcode16_t);\n+unsigned hsa_type_bit_size (BrigType16_t t);\n+BrigType16_t hsa_bittype_for_bitsize (unsigned bitsize);\n+BrigType16_t hsa_uint_for_bitsize (unsigned bitsize);\n+BrigType16_t hsa_float_for_bitsize (unsigned bitsize);\n+BrigType16_t hsa_bittype_for_type (BrigType16_t t);\n+bool hsa_type_float_p (BrigType16_t type);\n+bool hsa_type_integer_p (BrigType16_t type);\n+bool hsa_btype_p (BrigType16_t type);\n+BrigAlignment8_t hsa_alignment_encoding (unsigned n);\n+BrigAlignment8_t hsa_natural_alignment (BrigType16_t type);\n+void hsa_destroy_operand (hsa_op_base *op);\n+void hsa_destroy_insn (hsa_insn_basic *insn);\n+void hsa_add_kern_decl_mapping (tree decl, char *name, unsigned, bool);\n+unsigned hsa_get_number_decl_kernel_mappings (void);\n+tree hsa_get_decl_kernel_mapping_decl (unsigned i);\n+char *hsa_get_decl_kernel_mapping_name (unsigned i);\n+unsigned hsa_get_decl_kernel_mapping_omp_size (unsigned i);\n+bool hsa_get_decl_kernel_mapping_gridified (unsigned i);\n+void hsa_free_decl_kernel_mapping (void);\n+void hsa_add_kernel_dependency (tree caller, const char *called_function);\n+void hsa_sanitize_name (char *p);\n+char *hsa_brig_function_name (const char *p);\n+const char *hsa_get_declaration_name (tree decl);\n+void hsa_register_kernel (cgraph_node *host);\n+void hsa_register_kernel (cgraph_node *gpu, cgraph_node *host);\n+bool hsa_seen_error (void);\n+void hsa_fail_cfun (void);\n+\n+/* In hsa-gen.c.  */\n+void hsa_build_append_simple_mov (hsa_op_reg *, hsa_op_base *, hsa_bb *);\n+hsa_symbol *hsa_get_spill_symbol (BrigType16_t);\n+hsa_symbol *hsa_get_string_cst_symbol (BrigType16_t);\n+hsa_op_reg *hsa_spill_in (hsa_insn_basic *, hsa_op_reg *, hsa_op_reg **);\n+hsa_op_reg *hsa_spill_out (hsa_insn_basic *, hsa_op_reg *, hsa_op_reg **);\n+hsa_bb *hsa_init_new_bb (basic_block);\n+hsa_function_representation *hsa_generate_function_declaration (tree decl);\n+hsa_function_representation *hsa_generate_internal_fn_decl (hsa_internal_fn *);\n+tree hsa_get_host_function (tree decl);\n+\n+/* In hsa-regalloc.c.  */\n+void hsa_regalloc (void);\n+\n+/* In hsa-brig.c.  */\n+extern hash_table <hsa_internal_fn_hasher> *hsa_emitted_internal_decls;\n+void hsa_brig_emit_function (void);\n+void hsa_output_brig (void);\n+unsigned hsa_get_imm_brig_type_len (BrigType16_t type);\n+void hsa_brig_emit_omp_symbols (void);\n+\n+/*  In hsa-dump.c.  */\n+const char *hsa_seg_name (BrigSegment8_t);\n+void dump_hsa_insn (FILE *f, hsa_insn_basic *insn);\n+void dump_hsa_bb (FILE *, hsa_bb *);\n+void dump_hsa_cfun (FILE *);\n+DEBUG_FUNCTION void debug_hsa_operand (hsa_op_base *opc);\n+DEBUG_FUNCTION void debug_hsa_insn (hsa_insn_basic *insn);\n+\n+union hsa_bytes\n+{\n+  uint8_t b8;\n+  uint16_t b16;\n+  uint32_t b32;\n+  uint64_t b64;\n+};\n+\n+/* Return true if a function DECL is an HSA implementation.  */\n+\n+static inline bool\n+hsa_gpu_implementation_p (tree decl)\n+{\n+  if (hsa_summaries == NULL)\n+    return false;\n+\n+  hsa_function_summary *s = hsa_summaries->get (cgraph_node::get_create (decl));\n+\n+  return s->m_gpu_implementation_p;\n+}\n+\n+#endif /* HSA_H */"}, {"sha": "769657f330a5b7f2042aad1ec919fea164fa88bd", "filename": "gcc/ipa-hsa.c", "status": "added", "additions": 331, "deletions": 0, "changes": 331, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fipa-hsa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fipa-hsa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-hsa.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,331 @@\n+/* Callgraph based analysis of static variables.\n+   Copyright (C) 2015-2016 Free Software Foundation, Inc.\n+   Contributed by Martin Liska <mliska@suse.cz>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+/* Interprocedural HSA pass is responsible for creation of HSA clones.\n+   For all these HSA clones, we emit HSAIL instructions and pass processing\n+   is terminated.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"is-a.h\"\n+#include \"hash-set.h\"\n+#include \"vec.h\"\n+#include \"tree.h\"\n+#include \"tree-pass.h\"\n+#include \"function.h\"\n+#include \"basic-block.h\"\n+#include \"gimple.h\"\n+#include \"dumpfile.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"tree-streamer.h\"\n+#include \"stringpool.h\"\n+#include \"cgraph.h\"\n+#include \"print-tree.h\"\n+#include \"symbol-summary.h\"\n+#include \"hsa.h\"\n+\n+namespace {\n+\n+/* If NODE is not versionable, warn about not emiting HSAIL and return false.\n+   Otherwise return true.  */\n+\n+static bool\n+check_warn_node_versionable (cgraph_node *node)\n+{\n+  if (!node->local.versionable)\n+    {\n+      warning_at (EXPR_LOCATION (node->decl), OPT_Whsa,\n+\t\t  \"could not emit HSAIL for function %s: function cannot be \"\n+\t\t  \"cloned\", node->name ());\n+      return false;\n+    }\n+  return true;\n+}\n+\n+/* The function creates HSA clones for all functions that were either\n+   marked as HSA kernels or are callable HSA functions.  Apart from that,\n+   we redirect all edges that come from an HSA clone and end in another\n+   HSA clone to connect these two functions.  */\n+\n+static unsigned int\n+process_hsa_functions (void)\n+{\n+  struct cgraph_node *node;\n+\n+  if (hsa_summaries == NULL)\n+    hsa_summaries = new hsa_summary_t (symtab);\n+\n+  FOR_EACH_DEFINED_FUNCTION (node)\n+    {\n+      hsa_function_summary *s = hsa_summaries->get (node);\n+\n+      /* A linked function is skipped.  */\n+      if (s->m_binded_function != NULL)\n+\tcontinue;\n+\n+      if (s->m_kind != HSA_NONE)\n+\t{\n+\t  if (!check_warn_node_versionable (node))\n+\t    continue;\n+\t  cgraph_node *clone\n+\t    = node->create_virtual_clone (vec <cgraph_edge *> (),\n+\t\t\t\t\t  NULL, NULL, \"hsa\");\n+\t  TREE_PUBLIC (clone->decl) = TREE_PUBLIC (node->decl);\n+\n+\t  clone->force_output = true;\n+\t  hsa_summaries->link_functions (clone, node, s->m_kind, false);\n+\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \"Created a new HSA clone: %s, type: %s\\n\",\n+\t\t     clone->name (),\n+\t\t     s->m_kind == HSA_KERNEL ? \"kernel\" : \"function\");\n+\t}\n+      else if (hsa_callable_function_p (node->decl))\n+\t{\n+\t  if (!check_warn_node_versionable (node))\n+\t    continue;\n+\t  cgraph_node *clone\n+\t    = node->create_virtual_clone (vec <cgraph_edge *> (),\n+\t\t\t\t\t  NULL, NULL, \"hsa\");\n+\t  TREE_PUBLIC (clone->decl) = TREE_PUBLIC (node->decl);\n+\n+\t  if (!cgraph_local_p (node))\n+\t    clone->force_output = true;\n+\t  hsa_summaries->link_functions (clone, node, HSA_FUNCTION, false);\n+\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \"Created a new HSA function clone: %s\\n\",\n+\t\t     clone->name ());\n+\t}\n+    }\n+\n+  /* Redirect all edges that are between HSA clones.  */\n+  FOR_EACH_DEFINED_FUNCTION (node)\n+    {\n+      cgraph_edge *e = node->callees;\n+\n+      while (e)\n+\t{\n+\t  hsa_function_summary *src = hsa_summaries->get (node);\n+\t  if (src->m_kind != HSA_NONE && src->m_gpu_implementation_p)\n+\t    {\n+\t      hsa_function_summary *dst = hsa_summaries->get (e->callee);\n+\t      if (dst->m_kind != HSA_NONE && !dst->m_gpu_implementation_p)\n+\t\t{\n+\t\t  e->redirect_callee (dst->m_binded_function);\n+\t\t  if (dump_file)\n+\t\t    fprintf (dump_file,\n+\t\t\t     \"Redirecting edge to HSA function: %s->%s\\n\",\n+\t\t\t     xstrdup_for_dump (e->caller->name ()),\n+\t\t\t     xstrdup_for_dump (e->callee->name ()));\n+\t\t}\n+\t    }\n+\n+\t  e = e->next_callee;\n+\t}\n+    }\n+\n+  return 0;\n+}\n+\n+/* Iterate all HSA functions and stream out HSA function summary.  */\n+\n+static void\n+ipa_hsa_write_summary (void)\n+{\n+  struct bitpack_d bp;\n+  struct cgraph_node *node;\n+  struct output_block *ob;\n+  unsigned int count = 0;\n+  lto_symtab_encoder_iterator lsei;\n+  lto_symtab_encoder_t encoder;\n+\n+  if (!hsa_summaries)\n+    return;\n+\n+  ob = create_output_block (LTO_section_ipa_hsa);\n+  encoder = ob->decl_state->symtab_node_encoder;\n+  ob->symbol = NULL;\n+  for (lsei = lsei_start_function_in_partition (encoder); !lsei_end_p (lsei);\n+       lsei_next_function_in_partition (&lsei))\n+    {\n+      node = lsei_cgraph_node (lsei);\n+      hsa_function_summary *s = hsa_summaries->get (node);\n+\n+      if (s->m_kind != HSA_NONE)\n+\tcount++;\n+    }\n+\n+  streamer_write_uhwi (ob, count);\n+\n+  /* Process all of the functions.  */\n+  for (lsei = lsei_start_function_in_partition (encoder); !lsei_end_p (lsei);\n+       lsei_next_function_in_partition (&lsei))\n+    {\n+      node = lsei_cgraph_node (lsei);\n+      hsa_function_summary *s = hsa_summaries->get (node);\n+\n+      if (s->m_kind != HSA_NONE)\n+\t{\n+\t  encoder = ob->decl_state->symtab_node_encoder;\n+\t  int node_ref = lto_symtab_encoder_encode (encoder, node);\n+\t  streamer_write_uhwi (ob, node_ref);\n+\n+\t  bp = bitpack_create (ob->main_stream);\n+\t  bp_pack_value (&bp, s->m_kind, 2);\n+\t  bp_pack_value (&bp, s->m_gpu_implementation_p, 1);\n+\t  bp_pack_value (&bp, s->m_binded_function != NULL, 1);\n+\t  streamer_write_bitpack (&bp);\n+\t  if (s->m_binded_function)\n+\t    stream_write_tree (ob, s->m_binded_function->decl, true);\n+\t}\n+    }\n+\n+  streamer_write_char_stream (ob->main_stream, 0);\n+  produce_asm (ob, NULL);\n+  destroy_output_block (ob);\n+}\n+\n+/* Read section in file FILE_DATA of length LEN with data DATA.  */\n+\n+static void\n+ipa_hsa_read_section (struct lto_file_decl_data *file_data, const char *data,\n+\t\t       size_t len)\n+{\n+  const struct lto_function_header *header\n+    = (const struct lto_function_header *) data;\n+  const int cfg_offset = sizeof (struct lto_function_header);\n+  const int main_offset = cfg_offset + header->cfg_size;\n+  const int string_offset = main_offset + header->main_size;\n+  struct data_in *data_in;\n+  unsigned int i;\n+  unsigned int count;\n+\n+  lto_input_block ib_main ((const char *) data + main_offset,\n+\t\t\t   header->main_size, file_data->mode_table);\n+\n+  data_in\n+    = lto_data_in_create (file_data, (const char *) data + string_offset,\n+\t\t\t  header->string_size, vNULL);\n+  count = streamer_read_uhwi (&ib_main);\n+\n+  for (i = 0; i < count; i++)\n+    {\n+      unsigned int index;\n+      struct cgraph_node *node;\n+      lto_symtab_encoder_t encoder;\n+\n+      index = streamer_read_uhwi (&ib_main);\n+      encoder = file_data->symtab_node_encoder;\n+      node = dyn_cast<cgraph_node *> (lto_symtab_encoder_deref (encoder,\n+\t\t\t\t\t\t\t\tindex));\n+      gcc_assert (node->definition);\n+      hsa_function_summary *s = hsa_summaries->get (node);\n+\n+      struct bitpack_d bp = streamer_read_bitpack (&ib_main);\n+      s->m_kind = (hsa_function_kind) bp_unpack_value (&bp, 2);\n+      s->m_gpu_implementation_p = bp_unpack_value (&bp, 1);\n+      bool has_tree = bp_unpack_value (&bp, 1);\n+\n+      if (has_tree)\n+\t{\n+\t  tree decl = stream_read_tree (&ib_main, data_in);\n+\t  s->m_binded_function = cgraph_node::get_create (decl);\n+\t}\n+    }\n+  lto_free_section_data (file_data, LTO_section_ipa_hsa, NULL, data,\n+\t\t\t len);\n+  lto_data_in_delete (data_in);\n+}\n+\n+/* Load streamed HSA functions summary and assign the summary to a function.  */\n+\n+static void\n+ipa_hsa_read_summary (void)\n+{\n+  struct lto_file_decl_data **file_data_vec = lto_get_file_decl_data ();\n+  struct lto_file_decl_data *file_data;\n+  unsigned int j = 0;\n+\n+  if (hsa_summaries == NULL)\n+    hsa_summaries = new hsa_summary_t (symtab);\n+\n+  while ((file_data = file_data_vec[j++]))\n+    {\n+      size_t len;\n+      const char *data = lto_get_section_data (file_data, LTO_section_ipa_hsa,\n+\t\t\t\t\t       NULL, &len);\n+\n+      if (data)\n+\tipa_hsa_read_section (file_data, data, len);\n+    }\n+}\n+\n+const pass_data pass_data_ipa_hsa =\n+{\n+  IPA_PASS, /* type */\n+  \"hsa\", /* name */\n+  OPTGROUP_NONE, /* optinfo_flags */\n+  TV_IPA_HSA, /* tv_id */\n+  0, /* properties_required */\n+  0, /* properties_provided */\n+  0, /* properties_destroyed */\n+  0, /* todo_flags_start */\n+  TODO_dump_symtab, /* todo_flags_finish */\n+};\n+\n+class pass_ipa_hsa : public ipa_opt_pass_d\n+{\n+public:\n+  pass_ipa_hsa (gcc::context *ctxt)\n+    : ipa_opt_pass_d (pass_data_ipa_hsa, ctxt,\n+\t\t      NULL, /* generate_summary */\n+\t\t      ipa_hsa_write_summary, /* write_summary */\n+\t\t      ipa_hsa_read_summary, /* read_summary */\n+\t\t      ipa_hsa_write_summary, /* write_optimization_summary */\n+\t\t      ipa_hsa_read_summary, /* read_optimization_summary */\n+\t\t      NULL, /* stmt_fixup */\n+\t\t      0, /* function_transform_todo_flags_start */\n+\t\t      NULL, /* function_transform */\n+\t\t      NULL) /* variable_transform */\n+    {}\n+\n+  /* opt_pass methods: */\n+  virtual bool gate (function *);\n+\n+  virtual unsigned int execute (function *) { return process_hsa_functions (); }\n+\n+}; // class pass_ipa_reference\n+\n+bool\n+pass_ipa_hsa::gate (function *)\n+{\n+  return hsa_gen_requested_p ();\n+}\n+\n+} // anon namespace\n+\n+ipa_opt_pass_d *\n+make_pass_ipa_hsa (gcc::context *ctxt)\n+{\n+  return new pass_ipa_hsa (ctxt);\n+}"}, {"sha": "93b82be81ffa75c8a911469f0034c05fc8d34059", "filename": "gcc/lto-section-in.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto-section-in.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto-section-in.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto-section-in.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -51,7 +51,8 @@ const char *lto_section_name[LTO_N_SECTION_TYPES] =\n   \"ipcp_trans\",\n   \"icf\",\n   \"offload_table\",\n-  \"mode_table\"\n+  \"mode_table\",\n+  \"hsa\"\n };\n \n "}, {"sha": "0cb200e2d3fed5763db59e75cc8a7c56f30f39bb", "filename": "gcc/lto-streamer.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto-streamer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto-streamer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto-streamer.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -244,6 +244,7 @@ enum lto_section_type\n   LTO_section_ipa_icf,\n   LTO_section_offload_table,\n   LTO_section_mode_table,\n+  LTO_section_ipa_hsa,\n   LTO_N_SECTION_TYPES\t\t/* Must be last.  */\n };\n "}, {"sha": "16d1f4573fd596fd6f4313cfc50da62f8d67e701", "filename": "gcc/lto-wrapper.c", "status": "modified", "additions": 9, "deletions": 2, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto-wrapper.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto-wrapper.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto-wrapper.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -736,6 +736,7 @@ compile_images_for_offload_targets (unsigned in_argc, char *in_argv[],\n     return;\n   unsigned num_targets = parse_env_var (target_names, &names, NULL);\n \n+  int next_name_entry = 0;\n   const char *compiler_path = getenv (\"COMPILER_PATH\");\n   if (!compiler_path)\n     goto out;\n@@ -745,13 +746,19 @@ compile_images_for_offload_targets (unsigned in_argc, char *in_argv[],\n   offload_names = XCNEWVEC (char *, num_targets + 1);\n   for (unsigned i = 0; i < num_targets; i++)\n     {\n-      offload_names[i]\n+      /* HSA does not use LTO-like streaming and a different compiler, skip\n+\t it. */\n+      if (strcmp (names[i], \"hsa\") == 0)\n+\tcontinue;\n+\n+      offload_names[next_name_entry]\n \t= compile_offload_image (names[i], compiler_path, in_argc, in_argv,\n \t\t\t\t compiler_opts, compiler_opt_count,\n \t\t\t\t linker_opts, linker_opt_count);\n-      if (!offload_names[i])\n+      if (!offload_names[next_name_entry])\n \tfatal_error (input_location,\n \t\t     \"problem with building target image for %s\\n\", names[i]);\n+      next_name_entry++;\n     }\n \n  out:"}, {"sha": "430dcfedb267277fe537ae3af54af95a70e2348a", "filename": "gcc/lto/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto%2FChangeLog?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1,3 +1,10 @@\n+2016-01-19  Martin Liska  <mliska@suse.cz>\n+            Martin Jambor  <mjambor@suse.cz>\n+\n+\t* lto-partition.c: Include \"hsa.h\"\n+\t(add_symbol_to_partition_1): Put hsa implementations into the\n+\tsame partition as host implementations.\n+\n 2016-01-12  Jan Hubicka  <hubicka@ucw.cz>\n \n \tPR lto/69003"}, {"sha": "eb28fed625c7cc3b6c1f0de9add709f99fe6da79", "filename": "gcc/lto/lto-partition.c", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto%2Flto-partition.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Flto%2Flto-partition.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto%2Flto-partition.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -34,6 +34,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"ipa-prop.h\"\n #include \"ipa-inline.h\"\n #include \"lto-partition.h\"\n+#include \"hsa.h\"\n \n vec<ltrans_partition> ltrans_partitions;\n \n@@ -170,6 +171,24 @@ add_symbol_to_partition_1 (ltrans_partition part, symtab_node *node)\n \t Therefore put it into the same partition.  */\n       if (cnode->instrumented_version)\n \tadd_symbol_to_partition_1 (part, cnode->instrumented_version);\n+\n+      /* Add an HSA associated with the symbol.  */\n+      if (hsa_summaries != NULL)\n+\t{\n+\t  hsa_function_summary *s = hsa_summaries->get (cnode);\n+\t  if (s->m_kind == HSA_KERNEL)\n+\t    {\n+\t      /* Add binded function.  */\n+\t      bool added = add_symbol_to_partition_1 (part,\n+\t\t\t\t\t\t      s->m_binded_function);\n+\t      gcc_assert (added);\n+\t      if (symtab->dump_file)\n+\t\tfprintf (symtab->dump_file,\n+\t\t\t \"adding an HSA function (host/gpu) to the \"\n+\t\t\t \"partition: %s\\n\",\n+\t\t\t s->m_binded_function->name ());\n+\t    }\n+\t}\n     }\n \n   add_references_to_partition (part, node);"}, {"sha": "60199b03b13e74b44f7386e166e8efb7f877bda9", "filename": "gcc/omp-builtins.def", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fomp-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fomp-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-builtins.def?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -340,8 +340,13 @@ DEF_GOMP_BUILTIN (BUILT_IN_GOMP_SINGLE_COPY_START, \"GOMP_single_copy_start\",\n \t\t  BT_FN_PTR, ATTR_NOTHROW_LEAF_LIST)\n DEF_GOMP_BUILTIN (BUILT_IN_GOMP_SINGLE_COPY_END, \"GOMP_single_copy_end\",\n \t\t  BT_FN_VOID_PTR, ATTR_NOTHROW_LEAF_LIST)\n+DEF_GOMP_BUILTIN (BUILT_IN_GOMP_OFFLOAD_REGISTER, \"GOMP_offload_register_ver\",\n+\t\t  BT_FN_VOID_UINT_PTR_INT_PTR, ATTR_NOTHROW_LIST)\n+DEF_GOMP_BUILTIN (BUILT_IN_GOMP_OFFLOAD_UNREGISTER,\n+\t\t  \"GOMP_offload_unregister_ver\",\n+\t\t  BT_FN_VOID_UINT_PTR_INT_PTR, ATTR_NOTHROW_LIST)\n DEF_GOMP_BUILTIN (BUILT_IN_GOMP_TARGET, \"GOMP_target_ext\",\n-\t\t  BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_INT_INT,\n+\t\t  BT_FN_VOID_INT_OMPFN_SIZE_PTR_PTR_PTR_UINT_PTR_PTR,\n \t\t  ATTR_NOTHROW_LIST)\n DEF_GOMP_BUILTIN (BUILT_IN_GOMP_TARGET_DATA, \"GOMP_target_data_ext\",\n \t\t  BT_FN_VOID_INT_SIZE_PTR_PTR_PTR, ATTR_NOTHROW_LIST)"}, {"sha": "673dee34e21e40a7e1a4cd68594d6d86e12aa5ca", "filename": "gcc/omp-low.c", "status": "modified", "additions": 1430, "deletions": 164, "changes": 1594, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fomp-low.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fomp-low.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-low.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -80,6 +80,9 @@ along with GCC; see the file COPYING3.  If not see\n #include \"lto-section-names.h\"\n #include \"gomp-constants.h\"\n #include \"gimple-pretty-print.h\"\n+#include \"symbol-summary.h\"\n+#include \"hsa.h\"\n+#include \"params.h\"\n \n /* Lowering of OMP parallel and workshare constructs proceeds in two\n    phases.  The first phase scans the function looking for OMP statements\n@@ -450,6 +453,63 @@ is_combined_parallel (struct omp_region *region)\n   return region->is_combined_parallel;\n }\n \n+/* Adjust *COND_CODE and *N2 so that the former is either LT_EXPR or\n+   GT_EXPR.  */\n+\n+static void\n+adjust_for_condition (location_t loc, enum tree_code *cond_code, tree *n2)\n+{\n+  switch (*cond_code)\n+    {\n+    case LT_EXPR:\n+    case GT_EXPR:\n+    case NE_EXPR:\n+      break;\n+    case LE_EXPR:\n+      if (POINTER_TYPE_P (TREE_TYPE (*n2)))\n+\t*n2 = fold_build_pointer_plus_hwi_loc (loc, *n2, 1);\n+      else\n+\t*n2 = fold_build2_loc (loc, PLUS_EXPR, TREE_TYPE (*n2), *n2,\n+\t\t\t       build_int_cst (TREE_TYPE (*n2), 1));\n+      *cond_code = LT_EXPR;\n+      break;\n+    case GE_EXPR:\n+      if (POINTER_TYPE_P (TREE_TYPE (*n2)))\n+\t*n2 = fold_build_pointer_plus_hwi_loc (loc, *n2, -1);\n+      else\n+\t*n2 = fold_build2_loc (loc, MINUS_EXPR, TREE_TYPE (*n2), *n2,\n+\t\t\t       build_int_cst (TREE_TYPE (*n2), 1));\n+      *cond_code = GT_EXPR;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Return the looping step from INCR, extracted from the step of a gimple omp\n+   for statement.  */\n+\n+static tree\n+get_omp_for_step_from_incr (location_t loc, tree incr)\n+{\n+  tree step;\n+  switch (TREE_CODE (incr))\n+    {\n+    case PLUS_EXPR:\n+      step = TREE_OPERAND (incr, 1);\n+      break;\n+    case POINTER_PLUS_EXPR:\n+      step = fold_convert (ssizetype, TREE_OPERAND (incr, 1));\n+      break;\n+    case MINUS_EXPR:\n+      step = TREE_OPERAND (incr, 1);\n+      step = fold_build1_loc (loc, NEGATE_EXPR, TREE_TYPE (step), step);\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+  return step;\n+}\n \n /* Extract the header elements of parallel loop FOR_STMT and store\n    them into *FD.  */\n@@ -579,58 +639,14 @@ extract_omp_for_data (gomp_for *for_stmt, struct omp_for_data *fd,\n \n       loop->cond_code = gimple_omp_for_cond (for_stmt, i);\n       loop->n2 = gimple_omp_for_final (for_stmt, i);\n-      switch (loop->cond_code)\n-\t{\n-\tcase LT_EXPR:\n-\tcase GT_EXPR:\n-\t  break;\n-\tcase NE_EXPR:\n-\t  gcc_assert (gimple_omp_for_kind (for_stmt)\n-\t\t      == GF_OMP_FOR_KIND_CILKSIMD\n-\t\t      || (gimple_omp_for_kind (for_stmt)\n-\t\t\t  == GF_OMP_FOR_KIND_CILKFOR));\n-\t  break;\n-\tcase LE_EXPR:\n-\t  if (POINTER_TYPE_P (TREE_TYPE (loop->n2)))\n-\t    loop->n2 = fold_build_pointer_plus_hwi_loc (loc, loop->n2, 1);\n-\t  else\n-\t    loop->n2 = fold_build2_loc (loc,\n-\t\t\t\t    PLUS_EXPR, TREE_TYPE (loop->n2), loop->n2,\n-\t\t\t\t    build_int_cst (TREE_TYPE (loop->n2), 1));\n-\t  loop->cond_code = LT_EXPR;\n-\t  break;\n-\tcase GE_EXPR:\n-\t  if (POINTER_TYPE_P (TREE_TYPE (loop->n2)))\n-\t    loop->n2 = fold_build_pointer_plus_hwi_loc (loc, loop->n2, -1);\n-\t  else\n-\t    loop->n2 = fold_build2_loc (loc,\n-\t\t\t\t    MINUS_EXPR, TREE_TYPE (loop->n2), loop->n2,\n-\t\t\t\t    build_int_cst (TREE_TYPE (loop->n2), 1));\n-\t  loop->cond_code = GT_EXPR;\n-\t  break;\n-\tdefault:\n-\t  gcc_unreachable ();\n-\t}\n+      gcc_assert (loop->cond_code != NE_EXPR\n+\t\t  || gimple_omp_for_kind (for_stmt) == GF_OMP_FOR_KIND_CILKSIMD\n+\t\t  || gimple_omp_for_kind (for_stmt) == GF_OMP_FOR_KIND_CILKFOR);\n+      adjust_for_condition (loc, &loop->cond_code, &loop->n2);\n \n       t = gimple_omp_for_incr (for_stmt, i);\n       gcc_assert (TREE_OPERAND (t, 0) == var);\n-      switch (TREE_CODE (t))\n-\t{\n-\tcase PLUS_EXPR:\n-\t  loop->step = TREE_OPERAND (t, 1);\n-\t  break;\n-\tcase POINTER_PLUS_EXPR:\n-\t  loop->step = fold_convert (ssizetype, TREE_OPERAND (t, 1));\n-\t  break;\n-\tcase MINUS_EXPR:\n-\t  loop->step = TREE_OPERAND (t, 1);\n-\t  loop->step = fold_build1_loc (loc,\n-\t\t\t\t    NEGATE_EXPR, TREE_TYPE (loop->step),\n-\t\t\t\t    loop->step);\n-\t  break;\n-\tdefault:\n-\t  gcc_unreachable ();\n-\t}\n+      loop->step = get_omp_for_step_from_incr (loc, t);\n \n       if (simd\n \t  || (fd->sched_kind == OMP_CLAUSE_SCHEDULE_STATIC\n@@ -1321,7 +1337,16 @@ build_outer_var_ref (tree var, omp_context *ctx, bool lastprivate = false)\n \t}\n     }\n   else if (ctx->outer)\n-    x = lookup_decl (var, ctx->outer);\n+    {\n+      omp_context *outer = ctx->outer;\n+      if (gimple_code (outer->stmt) == GIMPLE_OMP_GRID_BODY)\n+\t{\n+\t  outer = outer->outer;\n+\t  gcc_assert (outer\n+\t\t      && gimple_code (outer->stmt) != GIMPLE_OMP_GRID_BODY);\n+\t}\n+\tx = lookup_decl (var, outer);\n+    }\n   else if (is_reference (var))\n     /* This can happen with orphaned constructs.  If var is reference, it is\n        possible it is shared and as such valid.  */\n@@ -1774,6 +1799,8 @@ fixup_child_record_type (omp_context *ctx)\n {\n   tree f, type = ctx->record_type;\n \n+  if (!ctx->receiver_decl)\n+    return;\n   /* ??? It isn't sufficient to just call remap_type here, because\n      variably_modified_type_p doesn't work the way we expect for\n      record types.  Testing each field for whether it needs remapping\n@@ -2132,6 +2159,14 @@ scan_sharing_clauses (tree clauses, omp_context *ctx,\n \t    }\n \t  break;\n \n+\tcase OMP_CLAUSE__GRIDDIM_:\n+\t  if (ctx->outer)\n+\t    {\n+\t      scan_omp_op (&OMP_CLAUSE__GRIDDIM__SIZE (c), ctx->outer);\n+\t      scan_omp_op (&OMP_CLAUSE__GRIDDIM__GROUP (c), ctx->outer);\n+\t    }\n+\t  break;\n+\n \tcase OMP_CLAUSE_NOWAIT:\n \tcase OMP_CLAUSE_ORDERED:\n \tcase OMP_CLAUSE_COLLAPSE:\n@@ -2327,6 +2362,7 @@ scan_sharing_clauses (tree clauses, omp_context *ctx,\n \tcase OMP_CLAUSE_INDEPENDENT:\n \tcase OMP_CLAUSE_AUTO:\n \tcase OMP_CLAUSE_SEQ:\n+\tcase OMP_CLAUSE__GRIDDIM_:\n \t  break;\n \n \tcase OMP_CLAUSE_DEVICE_RESIDENT:\n@@ -2648,8 +2684,11 @@ scan_omp_parallel (gimple_stmt_iterator *gsi, omp_context *outer_ctx)\n   DECL_NAMELESS (name) = 1;\n   TYPE_NAME (ctx->record_type) = name;\n   TYPE_ARTIFICIAL (ctx->record_type) = 1;\n-  create_omp_child_function (ctx, false);\n-  gimple_omp_parallel_set_child_fn (stmt, ctx->cb.dst_fn);\n+  if (!gimple_omp_parallel_grid_phony (stmt))\n+    {\n+      create_omp_child_function (ctx, false);\n+      gimple_omp_parallel_set_child_fn (stmt, ctx->cb.dst_fn);\n+    }\n \n   scan_sharing_clauses (gimple_omp_parallel_clauses (stmt), ctx);\n   scan_omp (gimple_omp_body_ptr (stmt), ctx);\n@@ -3189,6 +3228,11 @@ check_omp_nesting_restrictions (gimple *stmt, omp_context *ctx)\n {\n   tree c;\n \n+  if (ctx && gimple_code (ctx->stmt) == GIMPLE_OMP_GRID_BODY)\n+    /* GRID_BODY is an artificial construct, nesting rules will be checked in\n+       the original copy of its contents.  */\n+    return true;\n+\n   /* No nesting of non-OpenACC STMT (that is, an OpenMP one, or a GOMP builtin)\n      inside an OpenACC CTX.  */\n   if (!(is_gimple_omp (stmt)\n@@ -3777,7 +3821,11 @@ scan_omp_1_op (tree *tp, int *walk_subtrees, void *data)\n     case LABEL_DECL:\n     case RESULT_DECL:\n       if (ctx)\n-\t*tp = remap_decl (t, &ctx->cb);\n+\t{\n+\t  tree repl = remap_decl (t, &ctx->cb);\n+\t  gcc_checking_assert (TREE_CODE (repl) != ERROR_MARK);\n+\t  *tp = repl;\n+\t}\n       break;\n \n     default:\n@@ -3911,6 +3959,7 @@ scan_omp_1_stmt (gimple_stmt_iterator *gsi, bool *handled_ops_p,\n     case GIMPLE_OMP_TASKGROUP:\n     case GIMPLE_OMP_ORDERED:\n     case GIMPLE_OMP_CRITICAL:\n+    case GIMPLE_OMP_GRID_BODY:\n       ctx = new_omp_context (stmt, ctx);\n       scan_omp (gimple_omp_body_ptr (stmt), ctx);\n       break;\n@@ -6343,6 +6392,37 @@ gimple_build_cond_empty (tree cond)\n   return gimple_build_cond (pred_code, lhs, rhs, NULL_TREE, NULL_TREE);\n }\n \n+/* Return true if a parallel REGION is within a declare target function or\n+   within a target region and is not a part of a gridified target.  */\n+\n+static bool\n+parallel_needs_hsa_kernel_p (struct omp_region *region)\n+{\n+  bool indirect = false;\n+  for (region = region->outer; region; region = region->outer)\n+    {\n+      if (region->type == GIMPLE_OMP_PARALLEL)\n+\tindirect = true;\n+      else if (region->type == GIMPLE_OMP_TARGET)\n+\t{\n+\t  gomp_target *tgt_stmt\n+\t    = as_a <gomp_target *> (last_stmt (region->entry));\n+\n+\t  if (find_omp_clause (gimple_omp_target_clauses (tgt_stmt),\n+\t\t\t       OMP_CLAUSE__GRIDDIM_))\n+\t    return indirect;\n+\t  else\n+\t    return true;\n+\t}\n+    }\n+\n+  if (lookup_attribute (\"omp declare target\",\n+\t\t\tDECL_ATTRIBUTES (current_function_decl)))\n+    return true;\n+\n+  return false;\n+}\n+\n static void expand_omp_build_assign (gimple_stmt_iterator *, tree, tree,\n \t\t\t\t     bool = false);\n \n@@ -6512,7 +6592,8 @@ expand_parallel_call (struct omp_region *region, basic_block bb,\n     t1 = null_pointer_node;\n   else\n     t1 = build_fold_addr_expr (t);\n-  t2 = build_fold_addr_expr (gimple_omp_parallel_child_fn (entry_stmt));\n+  tree child_fndecl = gimple_omp_parallel_child_fn (entry_stmt);\n+  t2 = build_fold_addr_expr (child_fndecl);\n \n   vec_alloc (args, 4 + vec_safe_length (ws_args));\n   args->quick_push (t2);\n@@ -6527,6 +6608,13 @@ expand_parallel_call (struct omp_region *region, basic_block bb,\n \n   force_gimple_operand_gsi (&gsi, t, true, NULL_TREE,\n \t\t\t    false, GSI_CONTINUE_LINKING);\n+\n+  if (hsa_gen_requested_p ()\n+      && parallel_needs_hsa_kernel_p (region))\n+    {\n+      cgraph_node *child_cnode = cgraph_node::get (child_fndecl);\n+      hsa_register_kernel (child_cnode);\n+    }\n }\n \n /* Insert a function call whose name is FUNC_NAME with the information from\n@@ -12570,6 +12658,236 @@ mark_loops_in_oacc_kernels_region (basic_block region_entry,\n     loop->in_oacc_kernels_region = true;\n }\n \n+/* Types used to pass grid and wortkgroup sizes to kernel invocation.  */\n+\n+struct GTY(()) grid_launch_attributes_trees\n+{\n+  tree kernel_dim_array_type;\n+  tree kernel_lattrs_dimnum_decl;\n+  tree kernel_lattrs_grid_decl;\n+  tree kernel_lattrs_group_decl;\n+  tree kernel_launch_attributes_type;\n+};\n+\n+static GTY(()) struct grid_launch_attributes_trees *grid_attr_trees;\n+\n+/* Create types used to pass kernel launch attributes to target.  */\n+\n+static void\n+grid_create_kernel_launch_attr_types (void)\n+{\n+  if (grid_attr_trees)\n+    return;\n+  grid_attr_trees = ggc_alloc <grid_launch_attributes_trees> ();\n+\n+  tree dim_arr_index_type\n+    = build_index_type (build_int_cst (integer_type_node, 2));\n+  grid_attr_trees->kernel_dim_array_type\n+    = build_array_type (uint32_type_node, dim_arr_index_type);\n+\n+  grid_attr_trees->kernel_launch_attributes_type = make_node (RECORD_TYPE);\n+  grid_attr_trees->kernel_lattrs_dimnum_decl\n+    = build_decl (BUILTINS_LOCATION, FIELD_DECL, get_identifier (\"ndim\"),\n+\t\t  uint32_type_node);\n+  DECL_CHAIN (grid_attr_trees->kernel_lattrs_dimnum_decl) = NULL_TREE;\n+\n+  grid_attr_trees->kernel_lattrs_grid_decl\n+    = build_decl (BUILTINS_LOCATION, FIELD_DECL, get_identifier (\"grid_size\"),\n+\t\t  grid_attr_trees->kernel_dim_array_type);\n+  DECL_CHAIN (grid_attr_trees->kernel_lattrs_grid_decl)\n+    = grid_attr_trees->kernel_lattrs_dimnum_decl;\n+  grid_attr_trees->kernel_lattrs_group_decl\n+    = build_decl (BUILTINS_LOCATION, FIELD_DECL, get_identifier (\"group_size\"),\n+\t\t  grid_attr_trees->kernel_dim_array_type);\n+  DECL_CHAIN (grid_attr_trees->kernel_lattrs_group_decl)\n+    = grid_attr_trees->kernel_lattrs_grid_decl;\n+  finish_builtin_struct (grid_attr_trees->kernel_launch_attributes_type,\n+\t\t\t \"__gomp_kernel_launch_attributes\",\n+\t\t\t grid_attr_trees->kernel_lattrs_group_decl, NULL_TREE);\n+}\n+\n+/* Insert before the current statement in GSI a store of VALUE to INDEX of\n+   array (of type kernel_dim_array_type) FLD_DECL of RANGE_VAR.  VALUE must be\n+   of type uint32_type_node.  */\n+\n+static void\n+grid_insert_store_range_dim (gimple_stmt_iterator *gsi, tree range_var,\n+\t\t\t     tree fld_decl, int index, tree value)\n+{\n+  tree ref = build4 (ARRAY_REF, uint32_type_node,\n+\t\t     build3 (COMPONENT_REF,\n+\t\t\t     grid_attr_trees->kernel_dim_array_type,\n+\t\t\t     range_var, fld_decl, NULL_TREE),\n+\t\t     build_int_cst (integer_type_node, index),\n+\t\t     NULL_TREE, NULL_TREE);\n+  gsi_insert_before (gsi, gimple_build_assign (ref, value), GSI_SAME_STMT);\n+}\n+\n+/* Return a tree representation of a pointer to a structure with grid and\n+   work-group size information.  Statements filling that information will be\n+   inserted before GSI, TGT_STMT is the target statement which has the\n+   necessary information in it.  */\n+\n+static tree\n+grid_get_kernel_launch_attributes (gimple_stmt_iterator *gsi,\n+\t\t\t\t   gomp_target *tgt_stmt)\n+{\n+  grid_create_kernel_launch_attr_types ();\n+  tree u32_one = build_one_cst (uint32_type_node);\n+  tree lattrs = create_tmp_var (grid_attr_trees->kernel_launch_attributes_type,\n+\t\t\t\t\"__kernel_launch_attrs\");\n+\n+  unsigned max_dim = 0;\n+  for (tree clause = gimple_omp_target_clauses (tgt_stmt);\n+       clause;\n+       clause = OMP_CLAUSE_CHAIN (clause))\n+    {\n+      if (OMP_CLAUSE_CODE (clause) != OMP_CLAUSE__GRIDDIM_)\n+\tcontinue;\n+\n+      unsigned dim = OMP_CLAUSE__GRIDDIM__DIMENSION (clause);\n+      max_dim = MAX (dim, max_dim);\n+\n+      grid_insert_store_range_dim (gsi, lattrs,\n+\t\t\t\t   grid_attr_trees->kernel_lattrs_grid_decl,\n+\t\t\t\t   dim, OMP_CLAUSE__GRIDDIM__SIZE (clause));\n+      grid_insert_store_range_dim (gsi, lattrs,\n+\t\t\t\t   grid_attr_trees->kernel_lattrs_group_decl,\n+\t\t\t\t   dim, OMP_CLAUSE__GRIDDIM__GROUP (clause));\n+    }\n+\n+  tree dimref = build3 (COMPONENT_REF, uint32_type_node, lattrs,\n+\t\t\tgrid_attr_trees->kernel_lattrs_dimnum_decl, NULL_TREE);\n+  /* At this moment we cannot gridify a loop with a collapse clause.  */\n+  /* TODO: Adjust when we support bigger collapse.  */\n+  gcc_assert (max_dim == 0);\n+  gsi_insert_before (gsi, gimple_build_assign (dimref, u32_one), GSI_SAME_STMT);\n+  TREE_ADDRESSABLE (lattrs) = 1;\n+  return build_fold_addr_expr (lattrs);\n+}\n+\n+/* Build target argument identifier from the DEVICE identifier, value\n+   identifier ID and whether the element also has a SUBSEQUENT_PARAM.  */\n+\n+static tree\n+get_target_argument_identifier_1 (int device, bool subseqent_param, int id)\n+{\n+  tree t = build_int_cst (integer_type_node, device);\n+  if (subseqent_param)\n+    t = fold_build2 (BIT_IOR_EXPR, integer_type_node, t,\n+\t\t     build_int_cst (integer_type_node,\n+\t\t\t\t    GOMP_TARGET_ARG_SUBSEQUENT_PARAM));\n+  t = fold_build2 (BIT_IOR_EXPR, integer_type_node, t,\n+\t\t   build_int_cst (integer_type_node, id));\n+  return t;\n+}\n+\n+/* Like above but return it in type that can be directly stored as an element\n+   of the argument array.  */\n+\n+static tree\n+get_target_argument_identifier (int device, bool subseqent_param, int id)\n+{\n+  tree t = get_target_argument_identifier_1 (device, subseqent_param, id);\n+  return fold_convert (ptr_type_node, t);\n+}\n+\n+/* Return a target argument consisting of DEVICE identifier, value identifier\n+   ID, and the actual VALUE.  */\n+\n+static tree\n+get_target_argument_value (gimple_stmt_iterator *gsi, int device, int id,\n+\t\t\t   tree value)\n+{\n+  tree t = fold_build2 (LSHIFT_EXPR, integer_type_node,\n+\t\t\tfold_convert (integer_type_node, value),\n+\t\t\tbuild_int_cst (unsigned_type_node,\n+\t\t\t\t       GOMP_TARGET_ARG_VALUE_SHIFT));\n+  t = fold_build2 (BIT_IOR_EXPR, integer_type_node, t,\n+\t\t   get_target_argument_identifier_1 (device, false, id));\n+  t = fold_convert (ptr_type_node, t);\n+  return force_gimple_operand_gsi (gsi, t, true, NULL, true, GSI_SAME_STMT);\n+}\n+\n+/* If VALUE is an integer constant greater than -2^15 and smaller than 2^15,\n+   push one argument to ARGS with both the DEVICE, ID and VALUE embedded in it,\n+   otherwise push an identifier (with DEVICE and ID) and the VALUE in two\n+   arguments.  */\n+\n+static void\n+push_target_argument_according_to_value (gimple_stmt_iterator *gsi, int device,\n+\t\t\t\t\t int id, tree value, vec <tree> *args)\n+{\n+  if (tree_fits_shwi_p (value)\n+      && tree_to_shwi (value) > -(1 << 15)\n+      && tree_to_shwi (value) < (1 << 15))\n+    args->quick_push (get_target_argument_value (gsi, device, id, value));\n+  else\n+    {\n+      args->quick_push (get_target_argument_identifier (device, true, id));\n+      value = fold_convert (ptr_type_node, value);\n+      value = force_gimple_operand_gsi (gsi, value, true, NULL, true,\n+\t\t\t\t\tGSI_SAME_STMT);\n+      args->quick_push (value);\n+    }\n+}\n+\n+/* Create an array of arguments that is then passed to GOMP_target.   */\n+\n+static tree\n+get_target_arguments (gimple_stmt_iterator *gsi, gomp_target *tgt_stmt)\n+{\n+  auto_vec <tree, 6> args;\n+  tree clauses = gimple_omp_target_clauses (tgt_stmt);\n+  tree t, c = find_omp_clause (clauses, OMP_CLAUSE_NUM_TEAMS);\n+  if (c)\n+    t = OMP_CLAUSE_NUM_TEAMS_EXPR (c);\n+  else\n+    t = integer_minus_one_node;\n+  push_target_argument_according_to_value (gsi, GOMP_TARGET_ARG_DEVICE_ALL,\n+\t\t\t\t\t   GOMP_TARGET_ARG_NUM_TEAMS, t, &args);\n+\n+  c = find_omp_clause (clauses, OMP_CLAUSE_THREAD_LIMIT);\n+  if (c)\n+    t = OMP_CLAUSE_THREAD_LIMIT_EXPR (c);\n+  else\n+    t = integer_minus_one_node;\n+  push_target_argument_according_to_value (gsi, GOMP_TARGET_ARG_DEVICE_ALL,\n+\t\t\t\t\t   GOMP_TARGET_ARG_THREAD_LIMIT, t,\n+\t\t\t\t\t   &args);\n+\n+  /* Add HSA-specific grid sizes, if available.  */\n+  if (find_omp_clause (gimple_omp_target_clauses (tgt_stmt),\n+\t\t       OMP_CLAUSE__GRIDDIM_))\n+    {\n+      t = get_target_argument_identifier (GOMP_DEVICE_HSA, true,\n+\t\t\t\t\t  GOMP_TARGET_ARG_HSA_KERNEL_ATTRIBUTES);\n+      args.quick_push (t);\n+      args.quick_push (grid_get_kernel_launch_attributes (gsi, tgt_stmt));\n+    }\n+\n+  /* Produce more, perhaps device specific, arguments here.  */\n+\n+  tree argarray = create_tmp_var (build_array_type_nelts (ptr_type_node,\n+\t\t\t\t\t\t\t  args.length () + 1),\n+\t\t\t\t  \".omp_target_args\");\n+  for (unsigned i = 0; i < args.length (); i++)\n+    {\n+      tree ref = build4 (ARRAY_REF, ptr_type_node, argarray,\n+\t\t\t build_int_cst (integer_type_node, i),\n+\t\t\t NULL_TREE, NULL_TREE);\n+      gsi_insert_before (gsi, gimple_build_assign (ref, args[i]),\n+\t\t\t GSI_SAME_STMT);\n+    }\n+  tree ref = build4 (ARRAY_REF, ptr_type_node, argarray,\n+\t\t     build_int_cst (integer_type_node, args.length ()),\n+\t\t     NULL_TREE, NULL_TREE);\n+  gsi_insert_before (gsi, gimple_build_assign (ref, null_pointer_node),\n+\t\t     GSI_SAME_STMT);\n+  TREE_ADDRESSABLE (argarray) = 1;\n+  return build_fold_addr_expr (argarray);\n+}\n+\n /* Expand the GIMPLE_OMP_TARGET starting at REGION.  */\n \n static void\n@@ -12982,30 +13300,7 @@ expand_omp_target (struct omp_region *region)\n \tdepend = build_int_cst (ptr_type_node, 0);\n       args.quick_push (depend);\n       if (start_ix == BUILT_IN_GOMP_TARGET)\n-\t{\n-\t  c = find_omp_clause (clauses, OMP_CLAUSE_NUM_TEAMS);\n-\t  if (c)\n-\t    {\n-\t      t = fold_convert (integer_type_node,\n-\t\t\t\tOMP_CLAUSE_NUM_TEAMS_EXPR (c));\n-\t      t = force_gimple_operand_gsi (&gsi, t, true, NULL,\n-\t\t\t\t\t    true, GSI_SAME_STMT);\n-\t    }\n-\t  else\n-\t    t = integer_minus_one_node;\n-\t  args.quick_push (t);\n-\t  c = find_omp_clause (clauses, OMP_CLAUSE_THREAD_LIMIT);\n-\t  if (c)\n-\t    {\n-\t      t = fold_convert (integer_type_node,\n-\t\t\t\tOMP_CLAUSE_THREAD_LIMIT_EXPR (c));\n-\t      t = force_gimple_operand_gsi (&gsi, t, true, NULL,\n-\t\t\t\t\t    true, GSI_SAME_STMT);\n-\t    }\n-\t  else\n-\t    t = integer_minus_one_node;\n-\t  args.quick_push (t);\n-\t}\n+\targs.quick_push (get_target_arguments (&gsi, entry_stmt));\n       break;\n     case BUILT_IN_GOACC_PARALLEL:\n       {\n@@ -13109,90 +13404,343 @@ expand_omp_target (struct omp_region *region)\n     }\n }\n \n-\n-/* Expand the parallel region tree rooted at REGION.  Expansion\n-   proceeds in depth-first order.  Innermost regions are expanded\n-   first.  This way, parallel regions that require a new function to\n-   be created (e.g., GIMPLE_OMP_PARALLEL) can be expanded without having any\n-   internal dependencies in their body.  */\n+/* Expand KFOR loop as a GPGPU kernel, i.e. as a body only with iteration\n+   variable derived from the thread number.  */\n \n static void\n-expand_omp (struct omp_region *region)\n+grid_expand_omp_for_loop (struct omp_region *kfor)\n {\n-  omp_any_child_fn_dumped = false;\n-  while (region)\n-    {\n-      location_t saved_location;\n-      gimple *inner_stmt = NULL;\n+  tree t, threadid;\n+  tree type, itype;\n+  gimple_stmt_iterator gsi;\n+  tree n1, step;\n+  struct omp_for_data fd;\n \n-      /* First, determine whether this is a combined parallel+workshare\n-       \t region.  */\n-      if (region->type == GIMPLE_OMP_PARALLEL)\n-\tdetermine_parallel_type (region);\n+  gomp_for *for_stmt = as_a <gomp_for *> (last_stmt (kfor->entry));\n+  gcc_checking_assert (gimple_omp_for_kind (for_stmt)\n+\t\t       == GF_OMP_FOR_KIND_GRID_LOOP);\n+  basic_block body_bb = FALLTHRU_EDGE (kfor->entry)->dest;\n \n-      if (region->type == GIMPLE_OMP_FOR\n-\t  && gimple_omp_for_combined_p (last_stmt (region->entry)))\n-\tinner_stmt = last_stmt (region->inner->entry);\n+  gcc_assert (gimple_omp_for_collapse (for_stmt) == 1);\n+  gcc_assert (kfor->cont);\n+  extract_omp_for_data (for_stmt, &fd, NULL);\n \n-      if (region->inner)\n-\texpand_omp (region->inner);\n+  itype = type = TREE_TYPE (fd.loop.v);\n+  if (POINTER_TYPE_P (type))\n+    itype = signed_type_for (type);\n \n-      saved_location = input_location;\n-      if (gimple_has_location (last_stmt (region->entry)))\n-\tinput_location = gimple_location (last_stmt (region->entry));\n+  gsi = gsi_start_bb (body_bb);\n \n-      switch (region->type)\n-\t{\n-\tcase GIMPLE_OMP_PARALLEL:\n-\tcase GIMPLE_OMP_TASK:\n-\t  expand_omp_taskreg (region);\n-\t  break;\n+  n1 = fd.loop.n1;\n+  step = fd.loop.step;\n+  n1 = force_gimple_operand_gsi (&gsi, fold_convert (type, n1),\n+\t\t\t\t true, NULL_TREE, true, GSI_SAME_STMT);\n+  step = force_gimple_operand_gsi (&gsi, fold_convert (itype, step),\n+\t\t\t\t   true, NULL_TREE, true, GSI_SAME_STMT);\n+  threadid = build_call_expr (builtin_decl_explicit\n+\t\t\t      (BUILT_IN_OMP_GET_THREAD_NUM), 0);\n+  threadid = fold_convert (itype, threadid);\n+  threadid = force_gimple_operand_gsi (&gsi, threadid, true, NULL_TREE,\n+\t\t\t\t       true, GSI_SAME_STMT);\n \n-\tcase GIMPLE_OMP_FOR:\n-\t  expand_omp_for (region, inner_stmt);\n-\t  break;\n+  tree startvar = fd.loop.v;\n+  t = fold_build2 (MULT_EXPR, itype, threadid, step);\n+  if (POINTER_TYPE_P (type))\n+    t = fold_build_pointer_plus (n1, t);\n+  else\n+    t = fold_build2 (PLUS_EXPR, type, t, n1);\n+  t = fold_convert (type, t);\n+  t = force_gimple_operand_gsi (&gsi, t,\n+\t\t\t\tDECL_P (startvar)\n+\t\t\t\t&& TREE_ADDRESSABLE (startvar),\n+\t\t\t\tNULL_TREE, true, GSI_SAME_STMT);\n+  gassign *assign_stmt = gimple_build_assign (startvar, t);\n+  gsi_insert_before (&gsi, assign_stmt, GSI_SAME_STMT);\n \n-\tcase GIMPLE_OMP_SECTIONS:\n-\t  expand_omp_sections (region);\n-\t  break;\n+  /* Remove the omp for statement */\n+  gsi = gsi_last_bb (kfor->entry);\n+  gsi_remove (&gsi, true);\n \n-\tcase GIMPLE_OMP_SECTION:\n-\t  /* Individual omp sections are handled together with their\n-\t     parent GIMPLE_OMP_SECTIONS region.  */\n-\t  break;\n+  /* Remove the GIMPLE_OMP_CONTINUE statement.  */\n+  gsi = gsi_last_bb (kfor->cont);\n+  gcc_assert (!gsi_end_p (gsi)\n+\t      && gimple_code (gsi_stmt (gsi)) == GIMPLE_OMP_CONTINUE);\n+  gsi_remove (&gsi, true);\n \n-\tcase GIMPLE_OMP_SINGLE:\n-\t  expand_omp_single (region);\n-\t  break;\n+  /* Replace the GIMPLE_OMP_RETURN with a real return.  */\n+  gsi = gsi_last_bb (kfor->exit);\n+  gcc_assert (!gsi_end_p (gsi)\n+\t      && gimple_code (gsi_stmt (gsi)) == GIMPLE_OMP_RETURN);\n+  gsi_remove (&gsi, true);\n \n-\tcase GIMPLE_OMP_ORDERED:\n-\t  {\n-\t    gomp_ordered *ord_stmt\n-\t      = as_a <gomp_ordered *> (last_stmt (region->entry));\n-\t    if (find_omp_clause (gimple_omp_ordered_clauses (ord_stmt),\n-\t\t\t\t OMP_CLAUSE_DEPEND))\n-\t      {\n-\t\t/* We'll expand these when expanding corresponding\n-\t\t   worksharing region with ordered(n) clause.  */\n-\t\tgcc_assert (region->outer\n-\t\t\t    && region->outer->type == GIMPLE_OMP_FOR);\n-\t\tregion->ord_stmt = ord_stmt;\n-\t\tbreak;\n-\t      }\n-\t  }\n-\t  /* FALLTHRU */\n-\tcase GIMPLE_OMP_MASTER:\n-\tcase GIMPLE_OMP_TASKGROUP:\n-\tcase GIMPLE_OMP_CRITICAL:\n-\tcase GIMPLE_OMP_TEAMS:\n-\t  expand_omp_synch (region);\n-\t  break;\n+  /* Fixup the much simpler CFG.  */\n+  remove_edge (find_edge (kfor->cont, body_bb));\n \n-\tcase GIMPLE_OMP_ATOMIC_LOAD:\n-\t  expand_omp_atomic (region);\n-\t  break;\n+  if (kfor->cont != body_bb)\n+    set_immediate_dominator (CDI_DOMINATORS, kfor->cont, body_bb);\n+  set_immediate_dominator (CDI_DOMINATORS, kfor->exit, kfor->cont);\n+}\n \n-\tcase GIMPLE_OMP_TARGET:\n+/* Structure passed to grid_remap_kernel_arg_accesses so that it can remap\n+   argument_decls.  */\n+\n+struct grid_arg_decl_map\n+{\n+  tree old_arg;\n+  tree new_arg;\n+};\n+\n+/* Invoked through walk_gimple_op, will remap all PARM_DECLs to the ones\n+   pertaining to kernel function.  */\n+\n+static tree\n+grid_remap_kernel_arg_accesses (tree *tp, int *walk_subtrees, void *data)\n+{\n+  struct walk_stmt_info *wi = (struct walk_stmt_info *) data;\n+  struct grid_arg_decl_map *adm = (struct grid_arg_decl_map *) wi->info;\n+  tree t = *tp;\n+\n+  if (t == adm->old_arg)\n+    *tp = adm->new_arg;\n+  *walk_subtrees = !TYPE_P (t) && !DECL_P (t);\n+  return NULL_TREE;\n+}\n+\n+static void expand_omp (struct omp_region *region);\n+\n+/* If TARGET region contains a kernel body for loop, remove its region from the\n+   TARGET and expand it in GPGPU kernel fashion. */\n+\n+static void\n+grid_expand_target_grid_body (struct omp_region *target)\n+{\n+  if (!hsa_gen_requested_p ())\n+    return;\n+\n+  gomp_target *tgt_stmt = as_a <gomp_target *> (last_stmt (target->entry));\n+  struct omp_region **pp;\n+\n+  for (pp = &target->inner; *pp; pp = &(*pp)->next)\n+    if ((*pp)->type == GIMPLE_OMP_GRID_BODY)\n+      break;\n+\n+  struct omp_region *gpukernel = *pp;\n+\n+  tree orig_child_fndecl = gimple_omp_target_child_fn (tgt_stmt);\n+  if (!gpukernel)\n+    {\n+      /* HSA cannot handle OACC stuff.  */\n+      if (gimple_omp_target_kind (tgt_stmt) != GF_OMP_TARGET_KIND_REGION)\n+\treturn;\n+      gcc_checking_assert (orig_child_fndecl);\n+      gcc_assert (!find_omp_clause (gimple_omp_target_clauses (tgt_stmt),\n+\t\t\t\t    OMP_CLAUSE__GRIDDIM_));\n+      cgraph_node *n = cgraph_node::get (orig_child_fndecl);\n+\n+      hsa_register_kernel (n);\n+      return;\n+    }\n+\n+  gcc_assert (find_omp_clause (gimple_omp_target_clauses (tgt_stmt),\n+\t\t\t       OMP_CLAUSE__GRIDDIM_));\n+  tree inside_block = gimple_block (first_stmt (single_succ (gpukernel->entry)));\n+  *pp = gpukernel->next;\n+  for (pp = &gpukernel->inner; *pp; pp = &(*pp)->next)\n+    if ((*pp)->type == GIMPLE_OMP_FOR)\n+      break;\n+\n+  struct omp_region *kfor = *pp;\n+  gcc_assert (kfor);\n+  gcc_assert (gimple_omp_for_kind (last_stmt ((kfor)->entry))\n+\t      == GF_OMP_FOR_KIND_GRID_LOOP);\n+  *pp = kfor->next;\n+  if (kfor->inner)\n+    expand_omp (kfor->inner);\n+  if (gpukernel->inner)\n+    expand_omp (gpukernel->inner);\n+\n+  tree kern_fndecl = copy_node (orig_child_fndecl);\n+  DECL_NAME (kern_fndecl) = clone_function_name (kern_fndecl, \"kernel\");\n+  SET_DECL_ASSEMBLER_NAME (kern_fndecl, DECL_NAME (kern_fndecl));\n+  tree tgtblock = gimple_block (tgt_stmt);\n+  tree fniniblock = make_node (BLOCK);\n+  BLOCK_ABSTRACT_ORIGIN (fniniblock) = tgtblock;\n+  BLOCK_SOURCE_LOCATION (fniniblock) = BLOCK_SOURCE_LOCATION (tgtblock);\n+  BLOCK_SOURCE_END_LOCATION (fniniblock) = BLOCK_SOURCE_END_LOCATION (tgtblock);\n+  DECL_INITIAL (kern_fndecl) = fniniblock;\n+  push_struct_function (kern_fndecl);\n+  cfun->function_end_locus = gimple_location (tgt_stmt);\n+  pop_cfun ();\n+\n+  tree old_parm_decl = DECL_ARGUMENTS (kern_fndecl);\n+  gcc_assert (!DECL_CHAIN (old_parm_decl));\n+  tree new_parm_decl = copy_node (DECL_ARGUMENTS (kern_fndecl));\n+  DECL_CONTEXT (new_parm_decl) = kern_fndecl;\n+  DECL_ARGUMENTS (kern_fndecl) = new_parm_decl;\n+  struct function *kern_cfun = DECL_STRUCT_FUNCTION (kern_fndecl);\n+  kern_cfun->curr_properties = cfun->curr_properties;\n+\n+  remove_edge (BRANCH_EDGE (kfor->entry));\n+  grid_expand_omp_for_loop (kfor);\n+\n+  /* Remove the omp for statement */\n+  gimple_stmt_iterator gsi = gsi_last_bb (gpukernel->entry);\n+  gsi_remove (&gsi, true);\n+  /* Replace the GIMPLE_OMP_RETURN at the end of the kernel region with a real\n+     return.  */\n+  gsi = gsi_last_bb (gpukernel->exit);\n+  gcc_assert (!gsi_end_p (gsi)\n+\t      && gimple_code (gsi_stmt (gsi)) == GIMPLE_OMP_RETURN);\n+  gimple *ret_stmt = gimple_build_return (NULL);\n+  gsi_insert_after (&gsi, ret_stmt, GSI_SAME_STMT);\n+  gsi_remove (&gsi, true);\n+\n+  /* Statements in the first BB in the target construct have been produced by\n+     target lowering and must be copied inside the GPUKERNEL, with the two\n+     exceptions of the first OMP statement and the OMP_DATA assignment\n+     statement.  */\n+  gsi = gsi_start_bb (single_succ (gpukernel->entry));\n+  tree data_arg = gimple_omp_target_data_arg (tgt_stmt);\n+  tree sender = data_arg ? TREE_VEC_ELT (data_arg, 0) : NULL;\n+  for (gimple_stmt_iterator tsi = gsi_start_bb (single_succ (target->entry));\n+       !gsi_end_p (tsi); gsi_next (&tsi))\n+    {\n+      gimple *stmt = gsi_stmt (tsi);\n+      if (is_gimple_omp (stmt))\n+\tbreak;\n+      if (sender\n+\t  && is_gimple_assign (stmt)\n+\t  && TREE_CODE (gimple_assign_rhs1 (stmt)) == ADDR_EXPR\n+\t  && TREE_OPERAND (gimple_assign_rhs1 (stmt), 0) == sender)\n+\tcontinue;\n+      gimple *copy = gimple_copy (stmt);\n+      gsi_insert_before (&gsi, copy, GSI_SAME_STMT);\n+      gimple_set_block (copy, fniniblock);\n+    }\n+\n+  move_sese_region_to_fn (kern_cfun, single_succ (gpukernel->entry),\n+\t\t\t  gpukernel->exit, inside_block);\n+\n+  cgraph_node *kcn = cgraph_node::get_create (kern_fndecl);\n+  kcn->mark_force_output ();\n+  cgraph_node *orig_child = cgraph_node::get (orig_child_fndecl);\n+\n+  hsa_register_kernel (kcn, orig_child);\n+\n+  cgraph_node::add_new_function (kern_fndecl, true);\n+  push_cfun (kern_cfun);\n+  cgraph_edge::rebuild_edges ();\n+\n+  /* Re-map any mention of the PARM_DECL of the original function to the\n+     PARM_DECL of the new one.\n+\n+     TODO: It would be great if lowering produced references into the GPU\n+     kernel decl straight away and we did not have to do this.  */\n+  struct grid_arg_decl_map adm;\n+  adm.old_arg = old_parm_decl;\n+  adm.new_arg = new_parm_decl;\n+  basic_block bb;\n+  FOR_EACH_BB_FN (bb, kern_cfun)\n+    {\n+      for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n+\t{\n+\t  gimple *stmt = gsi_stmt (gsi);\n+\t  struct walk_stmt_info wi;\n+\t  memset (&wi, 0, sizeof (wi));\n+\t  wi.info = &adm;\n+\t  walk_gimple_op (stmt, grid_remap_kernel_arg_accesses, &wi);\n+\t}\n+    }\n+  pop_cfun ();\n+\n+  return;\n+}\n+\n+/* Expand the parallel region tree rooted at REGION.  Expansion\n+   proceeds in depth-first order.  Innermost regions are expanded\n+   first.  This way, parallel regions that require a new function to\n+   be created (e.g., GIMPLE_OMP_PARALLEL) can be expanded without having any\n+   internal dependencies in their body.  */\n+\n+static void\n+expand_omp (struct omp_region *region)\n+{\n+  omp_any_child_fn_dumped = false;\n+  while (region)\n+    {\n+      location_t saved_location;\n+      gimple *inner_stmt = NULL;\n+\n+      /* First, determine whether this is a combined parallel+workshare\n+       \t region.  */\n+      if (region->type == GIMPLE_OMP_PARALLEL)\n+\tdetermine_parallel_type (region);\n+      else if (region->type == GIMPLE_OMP_TARGET)\n+\tgrid_expand_target_grid_body (region);\n+\n+      if (region->type == GIMPLE_OMP_FOR\n+\t  && gimple_omp_for_combined_p (last_stmt (region->entry)))\n+\tinner_stmt = last_stmt (region->inner->entry);\n+\n+      if (region->inner)\n+\texpand_omp (region->inner);\n+\n+      saved_location = input_location;\n+      if (gimple_has_location (last_stmt (region->entry)))\n+\tinput_location = gimple_location (last_stmt (region->entry));\n+\n+      switch (region->type)\n+\t{\n+\tcase GIMPLE_OMP_PARALLEL:\n+\tcase GIMPLE_OMP_TASK:\n+\t  expand_omp_taskreg (region);\n+\t  break;\n+\n+\tcase GIMPLE_OMP_FOR:\n+\t  expand_omp_for (region, inner_stmt);\n+\t  break;\n+\n+\tcase GIMPLE_OMP_SECTIONS:\n+\t  expand_omp_sections (region);\n+\t  break;\n+\n+\tcase GIMPLE_OMP_SECTION:\n+\t  /* Individual omp sections are handled together with their\n+\t     parent GIMPLE_OMP_SECTIONS region.  */\n+\t  break;\n+\n+\tcase GIMPLE_OMP_SINGLE:\n+\t  expand_omp_single (region);\n+\t  break;\n+\n+\tcase GIMPLE_OMP_ORDERED:\n+\t  {\n+\t    gomp_ordered *ord_stmt\n+\t      = as_a <gomp_ordered *> (last_stmt (region->entry));\n+\t    if (find_omp_clause (gimple_omp_ordered_clauses (ord_stmt),\n+\t\t\t\t OMP_CLAUSE_DEPEND))\n+\t      {\n+\t\t/* We'll expand these when expanding corresponding\n+\t\t   worksharing region with ordered(n) clause.  */\n+\t\tgcc_assert (region->outer\n+\t\t\t    && region->outer->type == GIMPLE_OMP_FOR);\n+\t\tregion->ord_stmt = ord_stmt;\n+\t\tbreak;\n+\t      }\n+\t  }\n+\t  /* FALLTHRU */\n+\tcase GIMPLE_OMP_MASTER:\n+\tcase GIMPLE_OMP_TASKGROUP:\n+\tcase GIMPLE_OMP_CRITICAL:\n+\tcase GIMPLE_OMP_TEAMS:\n+\t  expand_omp_synch (region);\n+\t  break;\n+\n+\tcase GIMPLE_OMP_ATOMIC_LOAD:\n+\t  expand_omp_atomic (region);\n+\t  break;\n+\n+\tcase GIMPLE_OMP_TARGET:\n \t  expand_omp_target (region);\n \t  break;\n \n@@ -14507,11 +15055,13 @@ lower_omp_for (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n \t\t\t\t\t\tctx);\n \t}\n \n-  gimple_seq_add_stmt (&body, stmt);\n+  if (!gimple_omp_for_grid_phony (stmt))\n+    gimple_seq_add_stmt (&body, stmt);\n   gimple_seq_add_seq (&body, gimple_omp_body (stmt));\n \n-  gimple_seq_add_stmt (&body, gimple_build_omp_continue (fd.loop.v,\n-\t\t\t\t\t\t\t fd.loop.v));\n+  if (!gimple_omp_for_grid_phony (stmt))\n+    gimple_seq_add_stmt (&body, gimple_build_omp_continue (fd.loop.v,\n+\t\t\t\t\t\t\t   fd.loop.v));\n \n   /* After the loop, add exit clauses.  */\n   lower_reduction_clauses (gimple_omp_for_clauses (stmt), &body, ctx);\n@@ -14523,9 +15073,12 @@ lower_omp_for (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n \n   body = maybe_catch_exception (body);\n \n-  /* Region exit marker goes at the end of the loop body.  */\n-  gimple_seq_add_stmt (&body, gimple_build_omp_return (fd.have_nowait));\n-  maybe_add_implicit_barrier_cancel (ctx, &body);\n+  if (!gimple_omp_for_grid_phony (stmt))\n+    {\n+      /* Region exit marker goes at the end of the loop body.  */\n+      gimple_seq_add_stmt (&body, gimple_build_omp_return (fd.have_nowait));\n+      maybe_add_implicit_barrier_cancel (ctx, &body);\n+    }\n \n   /* Add OpenACC joining and reduction markers just after the loop.  */\n   if (oacc_tail)\n@@ -14968,6 +15521,14 @@ lower_omp_taskreg (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n   par_olist = NULL;\n   par_ilist = NULL;\n   par_rlist = NULL;\n+  bool phony_construct = gimple_code (stmt) == GIMPLE_OMP_PARALLEL\n+    && gimple_omp_parallel_grid_phony (as_a <gomp_parallel *> (stmt));\n+  if (phony_construct && ctx->record_type)\n+    {\n+      gcc_checking_assert (!ctx->receiver_decl);\n+      ctx->receiver_decl = create_tmp_var\n+\t(build_reference_type (ctx->record_type), \".omp_rec\");\n+    }\n   lower_rec_input_clauses (clauses, &par_ilist, &par_olist, ctx, NULL);\n   lower_omp (&par_body, ctx);\n   if (gimple_code (stmt) == GIMPLE_OMP_PARALLEL)\n@@ -15026,13 +15587,19 @@ lower_omp_taskreg (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n     gimple_seq_add_stmt (&new_body,\n \t\t\t gimple_build_omp_continue (integer_zero_node,\n \t\t\t\t\t\t    integer_zero_node));\n-  gimple_seq_add_stmt (&new_body, gimple_build_omp_return (false));\n-  gimple_omp_set_body (stmt, new_body);\n+  if (!phony_construct)\n+    {\n+      gimple_seq_add_stmt (&new_body, gimple_build_omp_return (false));\n+      gimple_omp_set_body (stmt, new_body);\n+    }\n \n   bind = gimple_build_bind (NULL, NULL, gimple_bind_block (par_bind));\n   gsi_replace (gsi_p, dep_bind ? dep_bind : bind, true);\n   gimple_bind_add_seq (bind, ilist);\n-  gimple_bind_add_stmt (bind, stmt);\n+  if (!phony_construct)\n+    gimple_bind_add_stmt (bind, stmt);\n+  else\n+    gimple_bind_add_seq (bind, new_body);\n   gimple_bind_add_seq (bind, olist);\n \n   pop_gimplify_context (NULL);\n@@ -16165,19 +16732,22 @@ lower_omp_teams (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n \t\t\t   &bind_body, &dlist, ctx, NULL);\n   lower_omp (gimple_omp_body_ptr (teams_stmt), ctx);\n   lower_reduction_clauses (gimple_omp_teams_clauses (teams_stmt), &olist, ctx);\n-  gimple_seq_add_stmt (&bind_body, teams_stmt);\n-\n-  location_t loc = gimple_location (teams_stmt);\n-  tree decl = builtin_decl_explicit (BUILT_IN_GOMP_TEAMS);\n-  gimple *call = gimple_build_call (decl, 2, num_teams, thread_limit);\n-  gimple_set_location (call, loc);\n-  gimple_seq_add_stmt (&bind_body, call);\n+  if (!gimple_omp_teams_grid_phony (teams_stmt))\n+    {\n+      gimple_seq_add_stmt (&bind_body, teams_stmt);\n+      location_t loc = gimple_location (teams_stmt);\n+      tree decl = builtin_decl_explicit (BUILT_IN_GOMP_TEAMS);\n+      gimple *call = gimple_build_call (decl, 2, num_teams, thread_limit);\n+      gimple_set_location (call, loc);\n+      gimple_seq_add_stmt (&bind_body, call);\n+    }\n \n   gimple_seq_add_seq (&bind_body, gimple_omp_body (teams_stmt));\n   gimple_omp_set_body (teams_stmt, NULL);\n   gimple_seq_add_seq (&bind_body, olist);\n   gimple_seq_add_seq (&bind_body, dlist);\n-  gimple_seq_add_stmt (&bind_body, gimple_build_omp_return (true));\n+  if (!gimple_omp_teams_grid_phony (teams_stmt))\n+    gimple_seq_add_stmt (&bind_body, gimple_build_omp_return (true));\n   gimple_bind_set_body (bind, bind_body);\n \n   pop_gimplify_context (bind);\n@@ -16188,6 +16758,17 @@ lower_omp_teams (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n     TREE_USED (block) = 1;\n }\n \n+/* Expand code within an artificial GIMPLE_OMP_GRID_BODY OMP construct.  */\n+\n+static void\n+lower_omp_grid_body (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n+{\n+  gimple *stmt = gsi_stmt (*gsi_p);\n+  lower_omp (gimple_omp_body_ptr (stmt), ctx);\n+  gimple_seq_add_stmt (gimple_omp_body_ptr (stmt),\n+\t\t       gimple_build_omp_return (false));\n+}\n+\n \n /* Callback for lower_omp_1.  Return non-NULL if *tp needs to be\n    regimplified.  If DATA is non-NULL, lower_omp_1 is outside\n@@ -16399,6 +16980,11 @@ lower_omp_1 (gimple_stmt_iterator *gsi_p, omp_context *ctx)\n       gcc_assert (ctx);\n       lower_omp_teams (gsi_p, ctx);\n       break;\n+    case GIMPLE_OMP_GRID_BODY:\n+      ctx = maybe_lookup_ctx (stmt);\n+      gcc_assert (ctx);\n+      lower_omp_grid_body (gsi_p, ctx);\n+      break;\n     case GIMPLE_CALL:\n       tree fndecl;\n       call_stmt = as_a <gcall *> (stmt);\n@@ -16488,7 +17074,682 @@ lower_omp (gimple_seq *body, omp_context *ctx)\n       fold_stmt (&gsi);\n   input_location = saved_location;\n }\n+\n+/* Returen true if STMT is an assignment of a register-type into a local\n+   VAR_DECL.  */\n+\n+static bool\n+grid_reg_assignment_to_local_var_p (gimple *stmt)\n+{\n+  gassign *assign = dyn_cast <gassign *> (stmt);\n+  if (!assign)\n+    return false;\n+  tree lhs = gimple_assign_lhs (assign);\n+  if (TREE_CODE (lhs) != VAR_DECL\n+      || !is_gimple_reg_type (TREE_TYPE (lhs))\n+      || is_global_var (lhs))\n+    return false;\n+  return true;\n+}\n+\n+/* Return true if all statements in SEQ are assignments to local register-type\n+   variables.  */\n+\n+static bool\n+grid_seq_only_contains_local_assignments (gimple_seq seq)\n+{\n+  if (!seq)\n+    return true;\n+\n+  gimple_stmt_iterator gsi;\n+  for (gsi = gsi_start (seq); !gsi_end_p (gsi); gsi_next (&gsi))\n+    if (!grid_reg_assignment_to_local_var_p (gsi_stmt (gsi)))\n+      return false;\n+  return true;\n+}\n+\n+/* Scan statements in SEQ and call itself recursively on any bind.  If during\n+   whole search only assignments to register-type local variables and one\n+   single OMP statement is encountered, return true, otherwise return false.\n+   RET is where we store any OMP statement encountered.  TARGET_LOC and NAME\n+   are used for dumping a note about a failure.  */\n+\n+static bool\n+grid_find_single_omp_among_assignments_1 (gimple_seq seq, location_t target_loc,\n+\t\t\t\t     const char *name, gimple **ret)\n+{\n+  gimple_stmt_iterator gsi;\n+  for (gsi = gsi_start (seq); !gsi_end_p (gsi); gsi_next (&gsi))\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+\n+      if (grid_reg_assignment_to_local_var_p (stmt))\n+\tcontinue;\n+      if (gbind *bind = dyn_cast <gbind *> (stmt))\n+\t{\n+\t  if (!grid_find_single_omp_among_assignments_1 (gimple_bind_body (bind),\n+\t\t\t\t\t\t\t target_loc, name, ret))\n+\t      return false;\n+\t}\n+      else if (is_gimple_omp (stmt))\n+\t{\n+\t  if (*ret)\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\tdump_printf_loc (MSG_NOTE, target_loc,\n+\t\t\t\t \"Will not turn target construct into a simple \"\n+\t\t\t\t \"GPGPU kernel because %s construct contains \"\n+\t\t\t\t \"multiple OpenMP constructs\\n\", name);\n+\t      return false;\n+\t    }\n+\t  *ret = stmt;\n+\t}\n+      else\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, target_loc,\n+\t\t\t     \"Will not turn target construct into a simple \"\n+\t\t\t     \"GPGPU kernel because %s construct contains \"\n+\t\t\t     \"a complex statement\\n\", name);\n+\t  return false;\n+\t}\n+    }\n+  return true;\n+}\n+\n+/* Scan statements in SEQ and make sure that it and any binds in it contain\n+   only assignments to local register-type variables and one OMP construct.  If\n+   so, return that construct, otherwise return NULL.  If dumping is enabled and\n+   function fails, use TARGET_LOC and NAME to dump a note with the reason for\n+   failure.  */\n+\n+static gimple *\n+grid_find_single_omp_among_assignments (gimple_seq seq, location_t target_loc,\n+\t\t\t\t\tconst char *name)\n+{\n+  if (!seq)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, target_loc,\n+\t\t\t \"Will not turn target construct into a simple \"\n+\t\t\t \"GPGPU kernel because %s construct has empty \"\n+\t\t\t \"body\\n\",\n+\t\t\t name);\n+      return NULL;\n+    }\n+\n+  gimple *ret = NULL;\n+  if (grid_find_single_omp_among_assignments_1 (seq, target_loc, name, &ret))\n+    {\n+      if (!ret && dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, target_loc,\n+\t\t\t \"Will not turn target construct into a simple \"\n+\t\t\t \"GPGPU kernel because %s construct does not contain\"\n+\t\t\t \"any other OpenMP construct\\n\", name);\n+      return ret;\n+    }\n+  else\n+    return NULL;\n+}\n+\n+/* Walker function looking for statements there is no point gridifying (and for\n+   noreturn function calls which we cannot do).  Return non-NULL if such a\n+   function is found.  */\n+\n+static tree\n+grid_find_ungridifiable_statement (gimple_stmt_iterator *gsi,\n+\t\t\t\t   bool *handled_ops_p,\n+\t\t\t\t   struct walk_stmt_info *)\n+{\n+  *handled_ops_p = false;\n+  gimple *stmt = gsi_stmt (*gsi);\n+  switch (gimple_code (stmt))\n+    {\n+    case GIMPLE_CALL:\n+      if (gimple_call_noreturn_p (as_a <gcall *> (stmt)))\n+\t{\n+\t  *handled_ops_p = true;\n+\t  return error_mark_node;\n+\t}\n+      break;\n+\n+    /* We may reduce the following list if we find a way to implement the\n+       clauses, but now there is no point trying further.  */\n+    case GIMPLE_OMP_CRITICAL:\n+    case GIMPLE_OMP_TASKGROUP:\n+    case GIMPLE_OMP_TASK:\n+    case GIMPLE_OMP_SECTION:\n+    case GIMPLE_OMP_SECTIONS:\n+    case GIMPLE_OMP_SECTIONS_SWITCH:\n+    case GIMPLE_OMP_TARGET:\n+    case GIMPLE_OMP_ORDERED:\n+      *handled_ops_p = true;\n+      return error_mark_node;\n+\n+    default:\n+      break;\n+    }\n+  return NULL;\n+}\n+\n+\n+/* If TARGET follows a pattern that can be turned into a gridified GPGPU\n+   kernel, return true, otherwise return false.  In the case of success, also\n+   fill in GROUP_SIZE_P with the requested group size or NULL if there is\n+   none.  */\n+\n+static bool\n+grid_target_follows_gridifiable_pattern (gomp_target *target, tree *group_size_p)\n+{\n+  if (gimple_omp_target_kind (target) != GF_OMP_TARGET_KIND_REGION)\n+    return false;\n+\n+  location_t tloc = gimple_location (target);\n+  gimple *stmt\n+    = grid_find_single_omp_among_assignments (gimple_omp_body (target),\n+\t\t\t\t\t      tloc, \"target\");\n+  if (!stmt)\n+    return false;\n+  gomp_teams *teams = dyn_cast <gomp_teams *> (stmt);\n+  tree group_size = NULL;\n+  if (!teams)\n+    {\n+      dump_printf_loc (MSG_NOTE, tloc,\n+\t\t       \"Will not turn target construct into a simple \"\n+\t\t       \"GPGPU kernel because it does not have a sole teams \"\n+\t\t       \"construct in it.\\n\");\n+      return false;\n+    }\n+\n+  tree clauses = gimple_omp_teams_clauses (teams);\n+  while (clauses)\n+    {\n+      switch (OMP_CLAUSE_CODE (clauses))\n+\t{\n+\tcase OMP_CLAUSE_NUM_TEAMS:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because we cannot \"\n+\t\t\t     \"handle num_teams clause of teams \"\n+\t\t\t     \"construct\\n \");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_REDUCTION:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because a reduction \"\n+\t\t\t     \"clause is present\\n \");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_LASTPRIVATE:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because a lastprivate \"\n+\t\t\t     \"clause is present\\n \");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_THREAD_LIMIT:\n+\t  group_size = OMP_CLAUSE_OPERAND (clauses, 0);\n+\t  break;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      clauses = OMP_CLAUSE_CHAIN (clauses);\n+    }\n+\n+  stmt = grid_find_single_omp_among_assignments (gimple_omp_body (teams), tloc,\n+\t\t\t\t\t\t \"teams\");\n+  if (!stmt)\n+    return false;\n+  gomp_for *dist = dyn_cast <gomp_for *> (stmt);\n+  if (!dist)\n+    {\n+      dump_printf_loc (MSG_NOTE, tloc,\n+\t\t       \"Will not turn target construct into a simple \"\n+\t\t       \"GPGPU kernel because the teams construct  does not have \"\n+\t\t       \"a sole distribute construct in it.\\n\");\n+      return false;\n+    }\n+\n+  gcc_assert (gimple_omp_for_kind (dist) == GF_OMP_FOR_KIND_DISTRIBUTE);\n+  if (!gimple_omp_for_combined_p (dist))\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t \"Will not turn target construct into a gridified GPGPU \"\n+\t\t\t \"kernel because we cannot handle a standalone \"\n+\t\t\t \"distribute construct\\n \");\n+      return false;\n+    }\n+  if (dist->collapse > 1)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t \"Will not turn target construct into a gridified GPGPU \"\n+\t\t\t \"kernel because the distribute construct contains \"\n+\t\t\t \"collapse clause\\n\");\n+      return false;\n+    }\n+  struct omp_for_data fd;\n+  extract_omp_for_data (dist, &fd, NULL);\n+  if (fd.chunk_size)\n+    {\n+      if (group_size && !operand_equal_p (group_size, fd.chunk_size, 0))\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because the teams \"\n+\t\t\t     \"thread limit is different from distribute \"\n+\t\t\t     \"schedule chunk\\n\");\n+\t  return false;\n+\t}\n+      group_size = fd.chunk_size;\n+    }\n+  stmt = grid_find_single_omp_among_assignments (gimple_omp_body (dist), tloc,\n+\t\t\t\t\t\t \"distribute\");\n+  gomp_parallel *par;\n+  if (!stmt || !(par = dyn_cast <gomp_parallel *> (stmt)))\n+    return false;\n+\n+  clauses = gimple_omp_parallel_clauses (par);\n+  while (clauses)\n+    {\n+      switch (OMP_CLAUSE_CODE (clauses))\n+\t{\n+\tcase OMP_CLAUSE_NUM_THREADS:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a gridified\"\n+\t\t\t     \"GPGPU kernel because there is a num_threads \"\n+\t\t\t     \"clause of the parallel construct\\n\");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_REDUCTION:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because a reduction \"\n+\t\t\t     \"clause is present\\n \");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_LASTPRIVATE:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because a lastprivate \"\n+\t\t\t     \"clause is present\\n \");\n+\t  return false;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      clauses = OMP_CLAUSE_CHAIN (clauses);\n+    }\n+\n+  stmt = grid_find_single_omp_among_assignments (gimple_omp_body (par), tloc,\n+\t\t\t\t\t\t \"parallel\");\n+  gomp_for *gfor;\n+  if (!stmt || !(gfor = dyn_cast <gomp_for *> (stmt)))\n+    return false;\n+\n+  if (gimple_omp_for_kind (gfor) != GF_OMP_FOR_KIND_FOR)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t \"Will not turn target construct into a gridified GPGPU \"\n+\t\t\t \"kernel because the inner loop is not a simple for \"\n+\t\t\t \"loop\\n\");\n+      return false;\n+    }\n+  if (gfor->collapse > 1)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t \"Will not turn target construct into a gridified GPGPU \"\n+\t\t\t \"kernel because the inner loop contains collapse \"\n+\t\t\t \"clause\\n\");\n+      return false;\n+    }\n+\n+  if (!grid_seq_only_contains_local_assignments (gimple_omp_for_pre_body (gfor)))\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t \"Will not turn target construct into a gridified GPGPU \"\n+\t\t\t \"kernel because the inner loop pre_body contains\"\n+\t\t\t \"a complex instruction\\n\");\n+      return false;\n+    }\n+\n+  clauses = gimple_omp_for_clauses (gfor);\n+  while (clauses)\n+    {\n+      switch (OMP_CLAUSE_CODE (clauses))\n+\t{\n+\tcase OMP_CLAUSE_SCHEDULE:\n+\t  if (OMP_CLAUSE_SCHEDULE_KIND (clauses) != OMP_CLAUSE_SCHEDULE_AUTO)\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\tdump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t\t \"Will not turn target construct into a \"\n+\t\t\t\t \"gridified GPGPU kernel because the inner \"\n+\t\t\t\t \"loop has a non-automatic scheduling clause\\n\");\n+\t      return false;\n+\t    }\n+\t  break;\n+\n+\tcase OMP_CLAUSE_REDUCTION:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because a reduction \"\n+\t\t\t     \"clause is present\\n \");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_LASTPRIVATE:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a \"\n+\t\t\t     \"gridified GPGPU kernel because a lastprivate \"\n+\t\t\t     \"clause is present\\n \");\n+\t  return false;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      clauses = OMP_CLAUSE_CHAIN (clauses);\n+    }\n+\n+  struct walk_stmt_info wi;\n+  memset (&wi, 0, sizeof (wi));\n+  if (gimple *bad = walk_gimple_seq (gimple_omp_body (gfor),\n+\t\t\t\t     grid_find_ungridifiable_statement,\n+\t\t\t\t     NULL, &wi))\n+    {\n+      if (dump_enabled_p ())\n+\t{\n+\t  if (is_gimple_call (bad))\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a gridified \"\n+\t\t\t     \" GPGPU kernel because the inner loop contains \"\n+\t\t\t     \"call to a noreturn function\\n\");\n+\t  else\n+\t    dump_printf_loc (MSG_NOTE, tloc,\n+\t\t\t     \"Will not turn target construct into a gridified \"\n+\t\t\t     \"GPGPU kernel because the inner loop contains \"\n+\t\t\t     \"statement %s which cannot be transformed\\n\",\n+\t\t\t     gimple_code_name[(int) gimple_code (bad)]);\n+\t}\n+      return false;\n+    }\n+\n+  *group_size_p = group_size;\n+  return true;\n+}\n+\n+/* Operand walker, used to remap pre-body declarations according to a hash map\n+   provided in DATA.  */\n+\n+static tree\n+grid_remap_prebody_decls (tree *tp, int *walk_subtrees, void *data)\n+{\n+  tree t = *tp;\n+\n+  if (DECL_P (t) || TYPE_P (t))\n+    *walk_subtrees = 0;\n+  else\n+    *walk_subtrees = 1;\n+\n+  if (TREE_CODE (t) == VAR_DECL)\n+    {\n+      struct walk_stmt_info *wi = (struct walk_stmt_info *) data;\n+      hash_map<tree, tree> *declmap = (hash_map<tree, tree> *) wi->info;\n+      tree *repl = declmap->get (t);\n+      if (repl)\n+\t*tp = *repl;\n+    }\n+  return NULL_TREE;\n+}\n+\n+/* Copy leading register-type assignments to local variables in SRC to just\n+   before DST, Creating temporaries, adjusting mapping of operands in WI and\n+   remapping operands as necessary.  Add any new temporaries to TGT_BIND.\n+   Return the first statement that does not conform to\n+   grid_reg_assignment_to_local_var_p or NULL.  */\n+\n+static gimple *\n+grid_copy_leading_local_assignments (gimple_seq src, gimple_stmt_iterator *dst,\n+\t\t\t\tgbind *tgt_bind, struct walk_stmt_info *wi)\n+{\n+  hash_map<tree, tree> *declmap = (hash_map<tree, tree> *) wi->info;\n+  gimple_stmt_iterator gsi;\n+  for (gsi = gsi_start (src); !gsi_end_p (gsi); gsi_next (&gsi))\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+      if (gbind *bind = dyn_cast <gbind *> (stmt))\n+\t{\n+\t  gimple *r = grid_copy_leading_local_assignments\n+\t    (gimple_bind_body (bind), dst, tgt_bind, wi);\n+\t  if (r)\n+\t    return r;\n+\t  else\n+\t    continue;\n+\t}\n+      if (!grid_reg_assignment_to_local_var_p (stmt))\n+\treturn stmt;\n+      tree lhs = gimple_assign_lhs (as_a <gassign *> (stmt));\n+      tree repl = copy_var_decl (lhs, create_tmp_var_name (NULL),\n+\t\t\t\t TREE_TYPE (lhs));\n+      DECL_CONTEXT (repl) = current_function_decl;\n+      gimple_bind_append_vars (tgt_bind, repl);\n+\n+      declmap->put (lhs, repl);\n+      gassign *copy = as_a <gassign *> (gimple_copy (stmt));\n+      walk_gimple_op (copy, grid_remap_prebody_decls, wi);\n+      gsi_insert_before (dst, copy, GSI_SAME_STMT);\n+    }\n+  return NULL;\n+}\n+\n+/* Given freshly copied top level kernel SEQ, identify the individual OMP\n+   components, mark them as part of kernel and return the inner loop, and copy\n+   assignment leading to them just before DST, remapping them using WI and\n+   adding new temporaries to TGT_BIND.  */\n+\n+static gomp_for *\n+grid_process_kernel_body_copy (gimple_seq seq, gimple_stmt_iterator *dst,\n+\t\t\t       gbind *tgt_bind, struct walk_stmt_info *wi)\n+{\n+  gimple *stmt = grid_copy_leading_local_assignments (seq, dst, tgt_bind, wi);\n+  gomp_teams *teams = dyn_cast <gomp_teams *> (stmt);\n+  gcc_assert (teams);\n+  gimple_omp_teams_set_grid_phony (teams, true);\n+  stmt = grid_copy_leading_local_assignments (gimple_omp_body (teams), dst,\n+\t\t\t\t\t tgt_bind, wi);\n+  gcc_checking_assert (stmt);\n+  gomp_for *dist = dyn_cast <gomp_for *> (stmt);\n+  gcc_assert (dist);\n+  gimple_seq prebody = gimple_omp_for_pre_body (dist);\n+  if (prebody)\n+    grid_copy_leading_local_assignments (prebody, dst, tgt_bind, wi);\n+  gimple_omp_for_set_grid_phony (dist, true);\n+  stmt = grid_copy_leading_local_assignments (gimple_omp_body (dist), dst,\n+\t\t\t\t\t tgt_bind, wi);\n+  gcc_checking_assert (stmt);\n+\n+  gomp_parallel *parallel = as_a <gomp_parallel *> (stmt);\n+  gimple_omp_parallel_set_grid_phony (parallel, true);\n+  stmt = grid_copy_leading_local_assignments (gimple_omp_body (parallel), dst,\n+\t\t\t\t\t tgt_bind, wi);\n+  gomp_for *inner_loop = as_a <gomp_for *> (stmt);\n+  gimple_omp_for_set_kind (inner_loop, GF_OMP_FOR_KIND_GRID_LOOP);\n+  prebody = gimple_omp_for_pre_body (inner_loop);\n+  if (prebody)\n+    grid_copy_leading_local_assignments (prebody, dst, tgt_bind, wi);\n+\n+  return inner_loop;\n+}\n+\n+/* If TARGET points to a GOMP_TARGET which follows a gridifiable pattern,\n+   create a GPU kernel for it.  GSI must point to the same statement, TGT_BIND\n+   is the bind into which temporaries inserted before TARGET should be\n+   added.  */\n+\n+static void\n+grid_attempt_target_gridification (gomp_target *target,\n+\t\t\t\t   gimple_stmt_iterator *gsi,\n+\t\t\t\t   gbind *tgt_bind)\n+{\n+  tree group_size;\n+  if (!target || !grid_target_follows_gridifiable_pattern (target, &group_size))\n+    return;\n+\n+  location_t loc = gimple_location (target);\n+  if (dump_enabled_p ())\n+    dump_printf_loc (MSG_OPTIMIZED_LOCATIONS, loc,\n+\t\t     \"Target construct will be turned into a gridified GPGPU \"\n+\t\t     \"kernel\\n\");\n+\n+  /* Copy target body to a GPUKERNEL construct:  */\n+  gimple_seq kernel_seq = copy_gimple_seq_and_replace_locals\n+    (gimple_omp_body (target));\n+\n+  hash_map<tree, tree> *declmap = new hash_map<tree, tree>;\n+  struct walk_stmt_info wi;\n+  memset (&wi, 0, sizeof (struct walk_stmt_info));\n+  wi.info = declmap;\n+\n+  /* Copy assignments in between OMP statements before target, mark OMP\n+     statements within copy appropriatly.  */\n+  gomp_for *inner_loop = grid_process_kernel_body_copy (kernel_seq, gsi,\n+\t\t\t\t\t\t\ttgt_bind, &wi);\n+\n+  gbind *old_bind = as_a <gbind *> (gimple_seq_first (gimple_omp_body (target)));\n+  gbind *new_bind = as_a <gbind *> (gimple_seq_first (kernel_seq));\n+  tree new_block = gimple_bind_block (new_bind);\n+  tree enc_block = BLOCK_SUPERCONTEXT (gimple_bind_block (old_bind));\n+  BLOCK_CHAIN (new_block) = BLOCK_SUBBLOCKS (enc_block);\n+  BLOCK_SUBBLOCKS (enc_block) = new_block;\n+  BLOCK_SUPERCONTEXT (new_block) = enc_block;\n+  gimple *gpukernel = gimple_build_omp_grid_body (kernel_seq);\n+  gimple_seq_add_stmt\n+    (gimple_bind_body_ptr (as_a <gbind *> (gimple_omp_body (target))),\n+     gpukernel);\n+\n+  walk_tree (&group_size, grid_remap_prebody_decls, &wi, NULL);\n+  push_gimplify_context ();\n+  size_t collapse = gimple_omp_for_collapse (inner_loop);\n+  for (size_t i = 0; i < collapse; i++)\n+    {\n+      tree itype, type = TREE_TYPE (gimple_omp_for_index (inner_loop, i));\n+      if (POINTER_TYPE_P (type))\n+\titype = signed_type_for (type);\n+      else\n+\titype = type;\n+\n+      enum tree_code cond_code = gimple_omp_for_cond (inner_loop, i);\n+      tree n1 = unshare_expr (gimple_omp_for_initial (inner_loop, i));\n+      walk_tree (&n1, grid_remap_prebody_decls, &wi, NULL);\n+      tree n2 = unshare_expr (gimple_omp_for_final (inner_loop, i));\n+      walk_tree (&n2, grid_remap_prebody_decls, &wi, NULL);\n+      adjust_for_condition (loc, &cond_code, &n2);\n+      tree step;\n+      step = get_omp_for_step_from_incr (loc,\n+\t\t\t\t\t gimple_omp_for_incr (inner_loop, i));\n+      gimple_seq tmpseq = NULL;\n+      n1 = fold_convert (itype, n1);\n+      n2 = fold_convert (itype, n2);\n+      tree t = build_int_cst (itype, (cond_code == LT_EXPR ? -1 : 1));\n+      t = fold_build2 (PLUS_EXPR, itype, step, t);\n+      t = fold_build2 (PLUS_EXPR, itype, t, n2);\n+      t = fold_build2 (MINUS_EXPR, itype, t, n1);\n+      if (TYPE_UNSIGNED (itype) && cond_code == GT_EXPR)\n+\tt = fold_build2 (TRUNC_DIV_EXPR, itype,\n+\t\t\t fold_build1 (NEGATE_EXPR, itype, t),\n+\t\t\t fold_build1 (NEGATE_EXPR, itype, step));\n+      else\n+\tt = fold_build2 (TRUNC_DIV_EXPR, itype, t, step);\n+      tree gs = fold_convert (uint32_type_node, t);\n+      gimplify_expr (&gs, &tmpseq, NULL, is_gimple_val, fb_rvalue);\n+      if (!gimple_seq_empty_p (tmpseq))\n+\tgsi_insert_seq_before (gsi, tmpseq, GSI_SAME_STMT);\n+\n+      tree ws;\n+      if (i == 0 && group_size)\n+\t{\n+\t  ws = fold_convert (uint32_type_node, group_size);\n+\t  tmpseq = NULL;\n+\t  gimplify_expr (&ws, &tmpseq, NULL, is_gimple_val, fb_rvalue);\n+\t  if (!gimple_seq_empty_p (tmpseq))\n+\t    gsi_insert_seq_before (gsi, tmpseq, GSI_SAME_STMT);\n+\t}\n+      else\n+\tws = build_zero_cst (uint32_type_node);\n+\n+      tree c = build_omp_clause (UNKNOWN_LOCATION, OMP_CLAUSE__GRIDDIM_);\n+      OMP_CLAUSE__GRIDDIM__DIMENSION (c) = i;\n+      OMP_CLAUSE__GRIDDIM__SIZE (c) = gs;\n+      OMP_CLAUSE__GRIDDIM__GROUP (c) = ws;\n+      OMP_CLAUSE_CHAIN (c) = gimple_omp_target_clauses (target);\n+      gimple_omp_target_set_clauses (target, c);\n+    }\n+  pop_gimplify_context (tgt_bind);\n+  delete declmap;\n+  return;\n+}\n+\n+/* Walker function doing all the work for create_target_kernels. */\n+\n+static tree\n+grid_gridify_all_targets_stmt (gimple_stmt_iterator *gsi,\n+\t\t\t\t   bool *handled_ops_p,\n+\t\t\t\t   struct walk_stmt_info *incoming)\n+{\n+  *handled_ops_p = false;\n+\n+  gimple *stmt = gsi_stmt (*gsi);\n+  gomp_target *target = dyn_cast <gomp_target *> (stmt);\n+  if (target)\n+    {\n+      gbind *tgt_bind = (gbind *) incoming->info;\n+      gcc_checking_assert (tgt_bind);\n+      grid_attempt_target_gridification (target, gsi, tgt_bind);\n+      return NULL_TREE;\n+    }\n+  gbind *bind = dyn_cast <gbind *> (stmt);\n+  if (bind)\n+    {\n+      *handled_ops_p = true;\n+      struct walk_stmt_info wi;\n+      memset (&wi, 0, sizeof (wi));\n+      wi.info = bind;\n+      walk_gimple_seq_mod (gimple_bind_body_ptr (bind),\n+\t\t\t   grid_gridify_all_targets_stmt, NULL, &wi);\n+    }\n+  return NULL_TREE;\n+}\n+\n+/* Attempt to gridify all target constructs in BODY_P.  All such targets will\n+   have their bodies duplicated, with the new copy being put into a\n+   gimple_omp_grid_body statement.  All kernel-related construct within the\n+   grid_body will be marked with phony flags or kernel kinds.  Moreover, some\n+   re-structuring is often needed, such as copying pre-bodies before the target\n+   construct so that kernel grid sizes can be computed.  */\n+\n+static void\n+grid_gridify_all_targets (gimple_seq *body_p)\n+{\n+  struct walk_stmt_info wi;\n+  memset (&wi, 0, sizeof (wi));\n+  walk_gimple_seq_mod (body_p, grid_gridify_all_targets_stmt, NULL, &wi);\n+}\n \f\n+\n /* Main entry point.  */\n \n static unsigned int\n@@ -16508,6 +17769,10 @@ execute_lower_omp (void)\n \t\t\t\t delete_omp_context);\n \n   body = gimple_body (current_function_decl);\n+\n+  if (hsa_gen_requested_p ())\n+    grid_gridify_all_targets (&body);\n+\n   scan_omp (&body, NULL);\n   gcc_assert (taskreg_nesting_level == 0);\n   FOR_EACH_VEC_ELT (taskreg_contexts, i, ctx)\n@@ -16845,6 +18110,7 @@ make_gimple_omp_edges (basic_block bb, struct omp_region **region,\n     case GIMPLE_OMP_TASKGROUP:\n     case GIMPLE_OMP_CRITICAL:\n     case GIMPLE_OMP_SECTION:\n+    case GIMPLE_OMP_GRID_BODY:\n       cur_region = new_omp_region (bb, code, cur_region);\n       fallthru = true;\n       break;"}, {"sha": "8e8410cd370025e969be179cdddbb418791056c0", "filename": "gcc/opts.c", "status": "modified", "additions": 29, "deletions": 2, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fopts.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1916,8 +1916,35 @@ common_handle_option (struct gcc_options *opts,\n       break;\n \n     case OPT_foffload_:\n-      /* Deferred.  */\n-      break;\n+      {\n+\tconst char *p = arg;\n+\topts->x_flag_disable_hsa = true;\n+\twhile (*p != 0)\n+\t  {\n+\t    const char *comma = strchr (p, ',');\n+\n+\t    if ((strncmp (p, \"disable\", 7) == 0)\n+\t\t&& (p[7] == ',' || p[7] == '\\0'))\n+\t      {\n+\t\topts->x_flag_disable_hsa = true;\n+\t\tbreak;\n+\t      }\n+\n+\t    if ((strncmp (p, \"hsa\", 3) == 0)\n+\t\t&& (p[3] == ',' || p[3] == '\\0'))\n+\t      {\n+#ifdef ENABLE_HSA\n+\t\topts->x_flag_disable_hsa = false;\n+#else\n+\t\tsorry (\"HSA has not been enabled during configuration\");\n+#endif\n+\t      }\n+\t    if (!comma)\n+\t      break;\n+\t    p = comma + 1;\n+\t  }\n+\tbreak;\n+      }\n \n #ifndef ACCEL_COMPILER\n     case OPT_foffload_abi_:"}, {"sha": "88971c7c0617296eeaff208700f3d597cd73fcd8", "filename": "gcc/params.def", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fparams.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fparams.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.def?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1183,6 +1183,11 @@ DEFPARAM (PARAM_MAX_RTL_IF_CONVERSION_INSNS,\n \t  \"Maximum number of insns in a basic block to consider for RTL \"\n \t  \"if-conversion.\",\n \t  10, 0, 99)\n+\n+DEFPARAM (PARAM_HSA_GEN_DEBUG_STORES,\n+\t  \"hsa-gen-debug-stores\",\n+\t  \"Level of hsa debug stores verbosity\",\n+\t  0, 0, 1)\n /*\n \n Local variables:"}, {"sha": "a6dae769121d8121e55a0718fb1c418510c9276e", "filename": "gcc/passes.def", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fpasses.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Fpasses.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.def?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -151,6 +151,7 @@ along with GCC; see the file COPYING3.  If not see\n   NEXT_PASS (pass_ipa_cp);\n   NEXT_PASS (pass_ipa_cdtor_merge);\n   NEXT_PASS (pass_target_clone);\n+  NEXT_PASS (pass_ipa_hsa);\n   NEXT_PASS (pass_ipa_inline);\n   NEXT_PASS (pass_ipa_pure_const);\n   NEXT_PASS (pass_ipa_reference);\n@@ -386,6 +387,7 @@ along with GCC; see the file COPYING3.  If not see\n   NEXT_PASS (pass_nrv);\n   NEXT_PASS (pass_cleanup_cfg_post_optimizing);\n   NEXT_PASS (pass_warn_function_noreturn);\n+  NEXT_PASS (pass_gen_hsail);\n \n   NEXT_PASS (pass_expand);\n "}, {"sha": "d9a5066727b5e8aba380839258441131a243b997", "filename": "gcc/timevar.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftimevar.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftimevar.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftimevar.def?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -97,6 +97,7 @@ DEFTIMEVAR (TV_WHOPR_WPA_IO          , \"whopr wpa I/O\")\n DEFTIMEVAR (TV_WHOPR_PARTITIONING    , \"whopr partitioning\")\n DEFTIMEVAR (TV_WHOPR_LTRANS          , \"whopr ltrans\")\n DEFTIMEVAR (TV_IPA_REFERENCE         , \"ipa reference\")\n+DEFTIMEVAR (TV_IPA_HSA\t\t     , \"ipa HSA\")\n DEFTIMEVAR (TV_IPA_PROFILE           , \"ipa profile\")\n DEFTIMEVAR (TV_IPA_AUTOFDO           , \"auto profile\")\n DEFTIMEVAR (TV_IPA_PURE_CONST        , \"ipa pure const\")"}, {"sha": "b754e5b24085cf9adadd9e91092878e62f21f355", "filename": "gcc/toplev.c", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftoplev.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftoplev.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftoplev.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -75,6 +75,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"gcse.h\"\n #include \"tree-chkp.h\"\n #include \"omp-low.h\"\n+#include \"hsa.h\"\n \n #if defined(DBX_DEBUGGING_INFO) || defined(XCOFF_DEBUGGING_INFO)\n #include \"dbxout.h\"\n@@ -518,6 +519,8 @@ compile_file (void)\n \n       omp_finish_file ();\n \n+      hsa_output_brig ();\n+\n       output_shared_constant_pool ();\n       output_object_blocks ();\n       finish_tm_clone_pairs ();"}, {"sha": "41c1a9bd329ca8e145632072423933eb25fa4e12", "filename": "gcc/tree-core.h", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree-core.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree-core.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-core.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -458,7 +458,11 @@ enum omp_clause_code {\n   OMP_CLAUSE_VECTOR_LENGTH,\n \n   /* OpenACC clause: tile ( size-expr-list ).  */\n-  OMP_CLAUSE_TILE\n+  OMP_CLAUSE_TILE,\n+\n+  /* OpenMP internal-only clause to specify grid dimensions of a gridified\n+     kernel.  */\n+  OMP_CLAUSE__GRIDDIM_\n };\n \n #undef DEFTREESTRUCT\n@@ -1375,6 +1379,9 @@ struct GTY(()) tree_omp_clause {\n     enum tree_code                 reduction_code;\n     enum omp_clause_linear_kind    linear_kind;\n     enum tree_code                 if_modifier;\n+    /* The dimension a OMP_CLAUSE__GRIDDIM_ clause of a gridified target\n+       construct describes.  */\n+    unsigned int\t\t   dimension;\n   } GTY ((skip)) subcode;\n \n   /* The gimplification of OMP_CLAUSE_REDUCTION_{INIT,MERGE} for omp-low's"}, {"sha": "b942a01f445840fdd7b35b57d313abe94a4e7cb8", "filename": "gcc/tree-pass.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree-pass.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree-pass.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pass.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -471,6 +471,7 @@ extern gimple_opt_pass *make_pass_sanopt (gcc::context *ctxt);\n extern gimple_opt_pass *make_pass_oacc_kernels (gcc::context *ctxt);\n extern simple_ipa_opt_pass *make_pass_ipa_oacc (gcc::context *ctxt);\n extern simple_ipa_opt_pass *make_pass_ipa_oacc_kernels (gcc::context *ctxt);\n+extern gimple_opt_pass *make_pass_gen_hsail (gcc::context *ctxt);\n \n /* IPA Passes */\n extern simple_ipa_opt_pass *make_pass_ipa_lower_emutls (gcc::context *ctxt);\n@@ -495,6 +496,7 @@ extern ipa_opt_pass_d *make_pass_ipa_cp (gcc::context *ctxt);\n extern ipa_opt_pass_d *make_pass_ipa_icf (gcc::context *ctxt);\n extern ipa_opt_pass_d *make_pass_ipa_devirt (gcc::context *ctxt);\n extern ipa_opt_pass_d *make_pass_ipa_reference (gcc::context *ctxt);\n+extern ipa_opt_pass_d *make_pass_ipa_hsa (gcc::context *ctxt);\n extern ipa_opt_pass_d *make_pass_ipa_pure_const (gcc::context *ctxt);\n extern simple_ipa_opt_pass *make_pass_ipa_pta (gcc::context *ctxt);\n extern simple_ipa_opt_pass *make_pass_ipa_tm (gcc::context *ctxt);"}, {"sha": "9c13d848829de06d233d46292f625aba02543de9", "filename": "gcc/tree-pretty-print.c", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pretty-print.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -942,6 +942,18 @@ dump_omp_clause (pretty_printer *pp, tree clause, int spc, int flags)\n       pp_right_paren (pp);\n       break;\n \n+    case OMP_CLAUSE__GRIDDIM_:\n+      pp_string (pp, \"_griddim_(\");\n+      pp_unsigned_wide_integer (pp, OMP_CLAUSE__GRIDDIM__DIMENSION (clause));\n+      pp_colon (pp);\n+      dump_generic_node (pp, OMP_CLAUSE__GRIDDIM__SIZE (clause), spc, flags,\n+\t\t\t false);\n+      pp_comma (pp);\n+      dump_generic_node (pp, OMP_CLAUSE__GRIDDIM__GROUP (clause), spc, flags,\n+\t\t\t false);\n+      pp_right_paren (pp);\n+      break;\n+\n     default:\n       /* Should never happen.  */\n       dump_generic_node (pp, clause, spc, flags, false);"}, {"sha": "4e54a7e9b57034cd5ce3b93a6e25c074e6e2bb75", "filename": "gcc/tree.c", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -328,6 +328,7 @@ unsigned const char omp_clause_num_ops[] =\n   1, /* OMP_CLAUSE_NUM_WORKERS  */\n   1, /* OMP_CLAUSE_VECTOR_LENGTH  */\n   1, /* OMP_CLAUSE_TILE  */\n+  2, /* OMP_CLAUSE__GRIDDIM_  */\n };\n \n const char * const omp_clause_code_name[] =\n@@ -398,7 +399,8 @@ const char * const omp_clause_code_name[] =\n   \"num_gangs\",\n   \"num_workers\",\n   \"vector_length\",\n-  \"tile\"\n+  \"tile\",\n+  \"_griddim_\"\n };\n \n \n@@ -11744,6 +11746,7 @@ walk_tree_1 (tree *tp, walk_tree_fn func, void *data,\n       switch (OMP_CLAUSE_CODE (*tp))\n \t{\n \tcase OMP_CLAUSE_GANG:\n+\tcase OMP_CLAUSE__GRIDDIM_:\n \t  WALK_SUBTREE (OMP_CLAUSE_OPERAND (*tp, 1));\n \t  /* FALLTHRU */\n "}, {"sha": "9b987bbbbc674ed3026a6e9009d709939ac02bfc", "filename": "gcc/tree.h", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1636,6 +1636,14 @@ extern void protected_set_expr_location (tree, location_t);\n #define OMP_CLAUSE_TILE_LIST(NODE) \\\n   OMP_CLAUSE_OPERAND (OMP_CLAUSE_SUBCODE_CHECK (NODE, OMP_CLAUSE_TILE), 0)\n \n+#define OMP_CLAUSE__GRIDDIM__DIMENSION(NODE) \\\n+  (OMP_CLAUSE_SUBCODE_CHECK (NODE, OMP_CLAUSE__GRIDDIM_)\\\n+   ->omp_clause.subcode.dimension)\n+#define OMP_CLAUSE__GRIDDIM__SIZE(NODE) \\\n+  OMP_CLAUSE_OPERAND (OMP_CLAUSE_SUBCODE_CHECK (NODE, OMP_CLAUSE__GRIDDIM_), 0)\n+#define OMP_CLAUSE__GRIDDIM__GROUP(NODE) \\\n+  OMP_CLAUSE_OPERAND (OMP_CLAUSE_SUBCODE_CHECK (NODE, OMP_CLAUSE__GRIDDIM_), 1)\n+\n /* SSA_NAME accessors.  */\n \n /* Returns the IDENTIFIER_NODE giving the SSA name a name or NULL_TREE"}, {"sha": "51736f7ea2f7b38f9b1cb3c77a61686ae6845bb3", "filename": "include/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/include%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/include%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/include%2FChangeLog?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1,3 +1,16 @@\n+2016-01-19  Martin Jambor  <mjambor@suse.cz>\n+\n+\t* gomp-constants.h (GOMP_DEVICE_HSA): New macro.\n+\t(GOMP_VERSION_HSA): Likewise.\n+\t(GOMP_TARGET_ARG_DEVICE_MASK): Likewise.\n+\t(GOMP_TARGET_ARG_DEVICE_ALL): Likewise.\n+\t(GOMP_TARGET_ARG_SUBSEQUENT_PARAM): Likewise.\n+\t(GOMP_TARGET_ARG_ID_MASK): Likewise.\n+\t(GOMP_TARGET_ARG_NUM_TEAMS): Likewise.\n+\t(GOMP_TARGET_ARG_THREAD_LIMIT): Likewise.\n+\t(GOMP_TARGET_ARG_VALUE_SHIFT): Likewise.\n+\t(GOMP_TARGET_ARG_HSA_KERNEL_ATTRIBUTES): Likewise.\n+\n 2016-01-07  Mike Frysinger  <vapier@gentoo.org>\n \n \t* longlong.h: Change !__SHMEDIA__ to"}, {"sha": "a8e7723b324646525964511c5eab55cee3b3f138", "filename": "include/gomp-constants.h", "status": "modified", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/include%2Fgomp-constants.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/include%2Fgomp-constants.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/include%2Fgomp-constants.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -176,6 +176,7 @@ enum gomp_map_kind\n #define GOMP_DEVICE_NOT_HOST\t\t4\n #define GOMP_DEVICE_NVIDIA_PTX\t\t5\n #define GOMP_DEVICE_INTEL_MIC\t\t6\n+#define GOMP_DEVICE_HSA\t\t\t7\n \n #define GOMP_DEVICE_ICV\t\t\t-1\n #define GOMP_DEVICE_HOST_FALLBACK\t-2\n@@ -201,6 +202,7 @@ enum gomp_map_kind\n #define GOMP_VERSION\t0\n #define GOMP_VERSION_NVIDIA_PTX 1\n #define GOMP_VERSION_INTEL_MIC 0\n+#define GOMP_VERSION_HSA 0\n \n #define GOMP_VERSION_PACK(LIB, DEV) (((LIB) << 16) | (DEV))\n #define GOMP_VERSION_LIB(PACK) (((PACK) >> 16) & 0xffff)\n@@ -228,4 +230,30 @@ enum gomp_map_kind\n #define GOMP_LAUNCH_OP(X) (((X) >> GOMP_LAUNCH_OP_SHIFT) & 0xffff)\n #define GOMP_LAUNCH_OP_MAX 0xffff\n \n+/* Bitmask to apply in order to find out the intended device of a target\n+   argument.  */\n+#define GOMP_TARGET_ARG_DEVICE_MASK\t\t((1 << 7) - 1)\n+/* The target argument is significant for all devices.  */\n+#define GOMP_TARGET_ARG_DEVICE_ALL\t\t0\n+\n+/* Flag set when the subsequent element in the device-specific argument\n+   values.  */\n+#define GOMP_TARGET_ARG_SUBSEQUENT_PARAM\t(1 << 7)\n+\n+/* Bitmask to apply to a target argument to find out the value identifier.  */\n+#define GOMP_TARGET_ARG_ID_MASK\t\t\t(((1 << 8) - 1) << 8)\n+/* Target argument index of NUM_TEAMS.  */\n+#define GOMP_TARGET_ARG_NUM_TEAMS\t\t(1 << 8)\n+/* Target argument index of THREAD_LIMIT.  */\n+#define GOMP_TARGET_ARG_THREAD_LIMIT\t\t(2 << 8)\n+\n+/* If the value is directly embeded in target argument, it should be a 16-bit\n+   at most and shifted by this many bits.  */\n+#define GOMP_TARGET_ARG_VALUE_SHIFT\t\t16\n+\n+/* HSA specific data structures.  */\n+\n+/* Identifiers of device-specific target arguments.  */\n+#define GOMP_TARGET_ARG_HSA_KERNEL_ATTRIBUTES\t(1 << 8)\n+\n #endif"}, {"sha": "82619e6ad8e944324c27235309f3e49ad98c0593", "filename": "libgomp/ChangeLog", "status": "modified", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2FChangeLog?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1,3 +1,64 @@\n+2016-01-19  Martin Jambor  <mjambor@suse.cz>\n+\t    Martin Liska  <mliska@suse.cz>\n+\n+\t* plugin/Makefrag.am: Add HSA plugin requirements.\n+\t* plugin/configfrag.ac (HSA_RUNTIME_INCLUDE): New variable.\n+\t(HSA_RUNTIME_LIB): Likewise.\n+\t(HSA_RUNTIME_CPPFLAGS): Likewise.\n+\t(HSA_RUNTIME_INCLUDE): New substitution.\n+\t(HSA_RUNTIME_LIB): Likewise.\n+\t(HSA_RUNTIME_LDFLAGS): Likewise.\n+\t(hsa-runtime): New configure option.\n+\t(hsa-runtime-include): Likewise.\n+\t(hsa-runtime-lib): Likewise.\n+\t(PLUGIN_HSA): New substitution variable.\n+\tFill HSA_RUNTIME_INCLUDE and HSA_RUNTIME_LIB according to the new\n+\tconfigure options.\n+\t(PLUGIN_HSA_CPPFLAGS): Likewise.\n+\t(PLUGIN_HSA_LDFLAGS): Likewise.\n+\t(PLUGIN_HSA_LIBS): Likewise.\n+\tCheck that we have access to HSA run-time.\n+\t* libgomp-plugin.h (offload_target_type): New element\n+\tOFFLOAD_TARGET_TYPE_HSA.\n+\t* libgomp.h (gomp_target_task): New fields firstprivate_copies and\n+\targs.\n+\t(bool gomp_create_target_task): Updated.\n+\t(gomp_device_descr): Extra parameter of run_func and async_run_func,\n+\tnew field can_run_func.\n+\t* libgomp_g.h (GOMP_target_ext): Update prototype.\n+\t* oacc-host.c (host_run): Added a new parameter args.\n+\t* target.c (calculate_firstprivate_requirements): New function.\n+\t(copy_firstprivate_data): Likewise.\n+\t(gomp_target_fallback_firstprivate): Use them.\n+\t(gomp_target_unshare_firstprivate): New function.\n+\t(gomp_get_target_fn_addr): Allow returning NULL for shared memory\n+\tdevices.\n+\t(GOMP_target): Do host fallback for all shared memory devices.  Do not\n+\tpass any args to plugins.\n+\t(GOMP_target_ext): Introduce device-specific argument parameter args.\n+\tAllow host fallback if device shares memory.  Do not remap data if\n+\tdevice has shared memory.\n+\t(gomp_target_task_fn): Likewise.  Also treat shared memory devices\n+\tlike host fallback for mappings.\n+\t(GOMP_target_data): Treat shared memory devices like host fallback.\n+\t(GOMP_target_data_ext): Likewise.\n+\t(GOMP_target_update): Likewise.\n+\t(GOMP_target_update_ext): Likewise.  Also pass NULL as args to\n+\tgomp_create_target_task.\n+\t(GOMP_target_enter_exit_data): Likewise.\n+\t(omp_target_alloc): Treat shared memory devices like host fallback.\n+\t(omp_target_free): Likewise.\n+\t(omp_target_is_present): Likewise.\n+\t(omp_target_memcpy): Likewise.\n+\t(omp_target_memcpy_rect): Likewise.\n+\t(omp_target_associate_ptr): Likewise.\n+\t(gomp_load_plugin_for_device): Also load can_run.\n+\t* task.c (GOMP_PLUGIN_target_task_completion): Free\n+\tfirstprivate_copies.\n+\t(gomp_create_target_task): Accept new argument args and store it to\n+\tttask.\n+\t* plugin/plugin-hsa.c: New file.\n+\n 2016-01-18  Tom de Vries  <tom@codesourcery.com>\n \n \t* testsuite/libgomp.oacc-c-c++-common/kernels-loop-2.c: New test."}, {"sha": "bbfac4e183f6e75023a9930d3b3931d03e305bd1", "filename": "libgomp/Makefile.in", "status": "modified", "additions": 44, "deletions": 5, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2FMakefile.in?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -17,7 +17,7 @@\n \n # Plugins for offload execution, Makefile.am fragment.\n #\n-# Copyright (C) 2014-2015 Free Software Foundation, Inc.\n+# Copyright (C) 2014-2016 Free Software Foundation, Inc.\n #\n # Contributed by Mentor Embedded.\n #\n@@ -89,7 +89,8 @@ DIST_COMMON = $(top_srcdir)/plugin/Makefrag.am ChangeLog \\\n \t$(srcdir)/omp_lib.f90.in $(srcdir)/libgomp_f.h.in \\\n \t$(srcdir)/libgomp.spec.in $(srcdir)/../depcomp\n @PLUGIN_NVPTX_TRUE@am__append_1 = libgomp-plugin-nvptx.la\n-@USE_FORTRAN_TRUE@am__append_2 = openacc.f90\n+@PLUGIN_HSA_TRUE@am__append_2 = libgomp-plugin-hsa.la\n+@USE_FORTRAN_TRUE@am__append_3 = openacc.f90\n subdir = .\n ACLOCAL_M4 = $(top_srcdir)/aclocal.m4\n am__aclocal_m4_deps = $(top_srcdir)/../config/acx.m4 \\\n@@ -147,6 +148,17 @@ am__installdirs = \"$(DESTDIR)$(toolexeclibdir)\" \"$(DESTDIR)$(infodir)\" \\\n \t\"$(DESTDIR)$(toolexeclibdir)\"\n LTLIBRARIES = $(toolexeclib_LTLIBRARIES)\n am__DEPENDENCIES_1 =\n+@PLUGIN_HSA_TRUE@libgomp_plugin_hsa_la_DEPENDENCIES = libgomp.la \\\n+@PLUGIN_HSA_TRUE@\t$(am__DEPENDENCIES_1)\n+@PLUGIN_HSA_TRUE@am_libgomp_plugin_hsa_la_OBJECTS =  \\\n+@PLUGIN_HSA_TRUE@\tlibgomp_plugin_hsa_la-plugin-hsa.lo\n+libgomp_plugin_hsa_la_OBJECTS = $(am_libgomp_plugin_hsa_la_OBJECTS)\n+libgomp_plugin_hsa_la_LINK = $(LIBTOOL) --tag=CC \\\n+\t$(libgomp_plugin_hsa_la_LIBTOOLFLAGS) $(LIBTOOLFLAGS) \\\n+\t--mode=link $(CCLD) $(AM_CFLAGS) $(CFLAGS) \\\n+\t$(libgomp_plugin_hsa_la_LDFLAGS) $(LDFLAGS) -o $@\n+@PLUGIN_HSA_TRUE@am_libgomp_plugin_hsa_la_rpath = -rpath \\\n+@PLUGIN_HSA_TRUE@\t$(toolexeclibdir)\n @PLUGIN_NVPTX_TRUE@libgomp_plugin_nvptx_la_DEPENDENCIES = libgomp.la \\\n @PLUGIN_NVPTX_TRUE@\t$(am__DEPENDENCIES_1)\n @PLUGIN_NVPTX_TRUE@am_libgomp_plugin_nvptx_la_OBJECTS =  \\\n@@ -187,7 +199,8 @@ FCLD = $(FC)\n FCLINK = $(LIBTOOL) --tag=FC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) \\\n \t--mode=link $(FCLD) $(AM_FCFLAGS) $(FCFLAGS) $(AM_LDFLAGS) \\\n \t$(LDFLAGS) -o $@\n-SOURCES = $(libgomp_plugin_nvptx_la_SOURCES) $(libgomp_la_SOURCES)\n+SOURCES = $(libgomp_plugin_hsa_la_SOURCES) \\\n+\t$(libgomp_plugin_nvptx_la_SOURCES) $(libgomp_la_SOURCES)\n MULTISRCTOP = \n MULTIBUILDTOP = \n MULTIDIRS = \n@@ -255,6 +268,8 @@ FC = @FC@\n FCFLAGS = @FCFLAGS@\n FGREP = @FGREP@\n GREP = @GREP@\n+HSA_RUNTIME_INCLUDE = @HSA_RUNTIME_INCLUDE@\n+HSA_RUNTIME_LIB = @HSA_RUNTIME_LIB@\n INSTALL = @INSTALL@\n INSTALL_DATA = @INSTALL_DATA@\n INSTALL_PROGRAM = @INSTALL_PROGRAM@\n@@ -299,6 +314,10 @@ PACKAGE_URL = @PACKAGE_URL@\n PACKAGE_VERSION = @PACKAGE_VERSION@\n PATH_SEPARATOR = @PATH_SEPARATOR@\n PERL = @PERL@\n+PLUGIN_HSA = @PLUGIN_HSA@\n+PLUGIN_HSA_CPPFLAGS = @PLUGIN_HSA_CPPFLAGS@\n+PLUGIN_HSA_LDFLAGS = @PLUGIN_HSA_LDFLAGS@\n+PLUGIN_HSA_LIBS = @PLUGIN_HSA_LIBS@\n PLUGIN_NVPTX = @PLUGIN_NVPTX@\n PLUGIN_NVPTX_CPPFLAGS = @PLUGIN_NVPTX_CPPFLAGS@\n PLUGIN_NVPTX_LDFLAGS = @PLUGIN_NVPTX_LDFLAGS@\n@@ -391,7 +410,7 @@ libsubincludedir = $(libdir)/gcc/$(target_alias)/$(gcc_version)/include\n AM_CPPFLAGS = $(addprefix -I, $(search_path))\n AM_CFLAGS = $(XCFLAGS)\n AM_LDFLAGS = $(XLDFLAGS) $(SECTION_LDFLAGS) $(OPT_LDFLAGS)\n-toolexeclib_LTLIBRARIES = libgomp.la $(am__append_1)\n+toolexeclib_LTLIBRARIES = libgomp.la $(am__append_1) $(am__append_2)\n nodist_toolexeclib_HEADERS = libgomp.spec\n \n # -Wc is only a libtool option.\n@@ -415,7 +434,7 @@ libgomp_la_SOURCES = alloc.c barrier.c critical.c env.c error.c iter.c \\\n \tbar.c ptrlock.c time.c fortran.c affinity.c target.c \\\n \tsplay-tree.c libgomp-plugin.c oacc-parallel.c oacc-host.c \\\n \toacc-init.c oacc-mem.c oacc-async.c oacc-plugin.c oacc-cuda.c \\\n-\tpriority_queue.c $(am__append_2)\n+\tpriority_queue.c $(am__append_3)\n \n # Nvidia PTX OpenACC plugin.\n @PLUGIN_NVPTX_TRUE@libgomp_plugin_nvptx_version_info = -version-info $(libtool_VERSION)\n@@ -426,6 +445,16 @@ libgomp_la_SOURCES = alloc.c barrier.c critical.c env.c error.c iter.c \\\n @PLUGIN_NVPTX_TRUE@\t$(lt_host_flags) $(PLUGIN_NVPTX_LDFLAGS)\n @PLUGIN_NVPTX_TRUE@libgomp_plugin_nvptx_la_LIBADD = libgomp.la $(PLUGIN_NVPTX_LIBS)\n @PLUGIN_NVPTX_TRUE@libgomp_plugin_nvptx_la_LIBTOOLFLAGS = --tag=disable-static\n+\n+# Heterogenous Systems Architecture plugin\n+@PLUGIN_HSA_TRUE@libgomp_plugin_hsa_version_info = -version-info $(libtool_VERSION)\n+@PLUGIN_HSA_TRUE@libgomp_plugin_hsa_la_SOURCES = plugin/plugin-hsa.c\n+@PLUGIN_HSA_TRUE@libgomp_plugin_hsa_la_CPPFLAGS = $(AM_CPPFLAGS) $(PLUGIN_HSA_CPPFLAGS)\n+@PLUGIN_HSA_TRUE@libgomp_plugin_hsa_la_LDFLAGS =  \\\n+@PLUGIN_HSA_TRUE@\t$(libgomp_plugin_hsa_version_info) \\\n+@PLUGIN_HSA_TRUE@\t$(lt_host_flags) $(PLUGIN_HSA_LDFLAGS)\n+@PLUGIN_HSA_TRUE@libgomp_plugin_hsa_la_LIBADD = libgomp.la $(PLUGIN_HSA_LIBS)\n+@PLUGIN_HSA_TRUE@libgomp_plugin_hsa_la_LIBTOOLFLAGS = --tag=disable-static\n nodist_noinst_HEADERS = libgomp_f.h\n nodist_libsubinclude_HEADERS = omp.h openacc.h\n @USE_FORTRAN_TRUE@nodist_finclude_HEADERS = omp_lib.h omp_lib.f90 omp_lib.mod omp_lib_kinds.mod \\\n@@ -553,6 +582,8 @@ clean-toolexeclibLTLIBRARIES:\n \t  echo \"rm -f \\\"$${dir}/so_locations\\\"\"; \\\n \t  rm -f \"$${dir}/so_locations\"; \\\n \tdone\n+libgomp-plugin-hsa.la: $(libgomp_plugin_hsa_la_OBJECTS) $(libgomp_plugin_hsa_la_DEPENDENCIES) $(EXTRA_libgomp_plugin_hsa_la_DEPENDENCIES) \n+\t$(libgomp_plugin_hsa_la_LINK) $(am_libgomp_plugin_hsa_la_rpath) $(libgomp_plugin_hsa_la_OBJECTS) $(libgomp_plugin_hsa_la_LIBADD) $(LIBS)\n libgomp-plugin-nvptx.la: $(libgomp_plugin_nvptx_la_OBJECTS) $(libgomp_plugin_nvptx_la_DEPENDENCIES) $(EXTRA_libgomp_plugin_nvptx_la_DEPENDENCIES) \n \t$(libgomp_plugin_nvptx_la_LINK) $(am_libgomp_plugin_nvptx_la_rpath) $(libgomp_plugin_nvptx_la_OBJECTS) $(libgomp_plugin_nvptx_la_LIBADD) $(LIBS)\n libgomp.la: $(libgomp_la_OBJECTS) $(libgomp_la_DEPENDENCIES) $(EXTRA_libgomp_la_DEPENDENCIES) \n@@ -575,6 +606,7 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/iter.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/iter_ull.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libgomp-plugin.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libgomp_plugin_hsa_la-plugin-hsa.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libgomp_plugin_nvptx_la-plugin-nvptx.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/lock.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/loop.Plo@am__quote@\n@@ -623,6 +655,13 @@ distclean-compile:\n @AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n @am__fastdepCC_FALSE@\t$(LTCOMPILE) -c -o $@ $<\n \n+libgomp_plugin_hsa_la-plugin-hsa.lo: plugin/plugin-hsa.c\n+@am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(libgomp_plugin_hsa_la_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(libgomp_plugin_hsa_la_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT libgomp_plugin_hsa_la-plugin-hsa.lo -MD -MP -MF $(DEPDIR)/libgomp_plugin_hsa_la-plugin-hsa.Tpo -c -o libgomp_plugin_hsa_la-plugin-hsa.lo `test -f 'plugin/plugin-hsa.c' || echo '$(srcdir)/'`plugin/plugin-hsa.c\n+@am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/libgomp_plugin_hsa_la-plugin-hsa.Tpo $(DEPDIR)/libgomp_plugin_hsa_la-plugin-hsa.Plo\n+@AMDEP_TRUE@@am__fastdepCC_FALSE@\tsource='plugin/plugin-hsa.c' object='libgomp_plugin_hsa_la-plugin-hsa.lo' libtool=yes @AMDEPBACKSLASH@\n+@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n+@am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(libgomp_plugin_hsa_la_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(libgomp_plugin_hsa_la_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o libgomp_plugin_hsa_la-plugin-hsa.lo `test -f 'plugin/plugin-hsa.c' || echo '$(srcdir)/'`plugin/plugin-hsa.c\n+\n libgomp_plugin_nvptx_la-plugin-nvptx.lo: plugin/plugin-nvptx.c\n @am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(libgomp_plugin_nvptx_la_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(libgomp_plugin_nvptx_la_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT libgomp_plugin_nvptx_la-plugin-nvptx.lo -MD -MP -MF $(DEPDIR)/libgomp_plugin_nvptx_la-plugin-nvptx.Tpo -c -o libgomp_plugin_nvptx_la-plugin-nvptx.lo `test -f 'plugin/plugin-nvptx.c' || echo '$(srcdir)/'`plugin/plugin-nvptx.c\n @am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/libgomp_plugin_nvptx_la-plugin-nvptx.Tpo $(DEPDIR)/libgomp_plugin_nvptx_la-plugin-nvptx.Plo"}, {"sha": "226ac5358a70b7266299ff376708e8208c53858c", "filename": "libgomp/config.h.in", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fconfig.h.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fconfig.h.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fconfig.h.in?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -60,6 +60,9 @@\n /* Define to 1 if you have the `strtoull' function. */\n #undef HAVE_STRTOULL\n \n+/* Define to 1 if the system has the type `struct _Mutex_Control'. */\n+#undef HAVE_STRUCT__MUTEX_CONTROL\n+\n /* Define to 1 if the target runtime linker supports binding the same symbol\n    to different versions. */\n #undef HAVE_SYMVER_SYMBOL_RENAMING_RUNTIME_SUPPORT\n@@ -119,6 +122,9 @@\n /* Define to the version of this package. */\n #undef PACKAGE_VERSION\n \n+/* Define to 1 if the HSA plugin is built, 0 if not. */\n+#undef PLUGIN_HSA\n+\n /* Define to 1 if the NVIDIA plugin is built, 0 if not. */\n #undef PLUGIN_NVPTX\n "}, {"sha": "1410bc71223c834376bf728939dd41460cfcd2d2", "filename": "libgomp/configure", "status": "modified", "additions": 163, "deletions": 3, "changes": 166, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fconfigure", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fconfigure", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fconfigure?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -627,10 +627,18 @@ LIBGOMP_BUILD_VERSIONED_SHLIB_FALSE\n LIBGOMP_BUILD_VERSIONED_SHLIB_TRUE\n OPT_LDFLAGS\n SECTION_LDFLAGS\n+PLUGIN_HSA_FALSE\n+PLUGIN_HSA_TRUE\n PLUGIN_NVPTX_FALSE\n PLUGIN_NVPTX_TRUE\n offload_additional_lib_paths\n offload_additional_options\n+PLUGIN_HSA_LIBS\n+PLUGIN_HSA_LDFLAGS\n+PLUGIN_HSA_CPPFLAGS\n+PLUGIN_HSA\n+HSA_RUNTIME_LIB\n+HSA_RUNTIME_INCLUDE\n PLUGIN_NVPTX_LIBS\n PLUGIN_NVPTX_LDFLAGS\n PLUGIN_NVPTX_CPPFLAGS\n@@ -782,6 +790,10 @@ enable_maintainer_mode\n with_cuda_driver\n with_cuda_driver_include\n with_cuda_driver_lib\n+with_hsa_runtime\n+with_hsa_runtime_include\n+with_hsa_runtime_lib\n+with_hsa_kmt_lib\n enable_linux_futex\n enable_tls\n enable_symvers\n@@ -1453,6 +1465,17 @@ Optional Packages:\n   --with-cuda-driver-lib=PATH\n                           specify directory for the installed CUDA driver\n                           library\n+  --with-hsa-runtime=PATH specify prefix directory for installed HSA run-time\n+                          package. Equivalent to\n+                          --with-hsa-runtime-include=PATH/include plus\n+                          --with-hsa-runtime-lib=PATH/lib\n+  --with-hsa-runtime-include=PATH\n+                          specify directory for installed HSA run-time include\n+                          files\n+  --with-hsa-runtime-lib=PATH\n+                          specify directory for the installed HSA run-time\n+                          library\n+  --with-hsa-kmt-lib=PATH specify directory for installed HSA KMT library.\n \n Some influential environment variables:\n   CC          C compiler command\n@@ -11121,7 +11144,7 @@ else\n   lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n   lt_status=$lt_dlunknown\n   cat > conftest.$ac_ext <<_LT_EOF\n-#line 11124 \"configure\"\n+#line 11147 \"configure\"\n #include \"confdefs.h\"\n \n #if HAVE_DLFCN_H\n@@ -11227,7 +11250,7 @@ else\n   lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n   lt_status=$lt_dlunknown\n   cat > conftest.$ac_ext <<_LT_EOF\n-#line 11230 \"configure\"\n+#line 11253 \"configure\"\n #include \"confdefs.h\"\n \n #if HAVE_DLFCN_H\n@@ -15090,7 +15113,7 @@ esac\n \n # Plugins for offload execution, configure.ac fragment.  -*- mode: autoconf -*-\n #\n-# Copyright (C) 2014-2015 Free Software Foundation, Inc.\n+# Copyright (C) 2014-2016 Free Software Foundation, Inc.\n #\n # Contributed by Mentor Embedded.\n #\n@@ -15225,6 +15248,72 @@ PLUGIN_NVPTX_LIBS=\n \n \n \n+# Look for HSA run-time, its includes and libraries\n+\n+HSA_RUNTIME_INCLUDE=\n+HSA_RUNTIME_LIB=\n+\n+\n+HSA_RUNTIME_CPPFLAGS=\n+HSA_RUNTIME_LDFLAGS=\n+\n+\n+# Check whether --with-hsa-runtime was given.\n+if test \"${with_hsa_runtime+set}\" = set; then :\n+  withval=$with_hsa_runtime;\n+fi\n+\n+\n+# Check whether --with-hsa-runtime-include was given.\n+if test \"${with_hsa_runtime_include+set}\" = set; then :\n+  withval=$with_hsa_runtime_include;\n+fi\n+\n+\n+# Check whether --with-hsa-runtime-lib was given.\n+if test \"${with_hsa_runtime_lib+set}\" = set; then :\n+  withval=$with_hsa_runtime_lib;\n+fi\n+\n+if test \"x$with_hsa_runtime\" != x; then\n+  HSA_RUNTIME_INCLUDE=$with_hsa_runtime/include\n+  HSA_RUNTIME_LIB=$with_hsa_runtime/lib\n+fi\n+if test \"x$with_hsa_runtime_include\" != x; then\n+  HSA_RUNTIME_INCLUDE=$with_hsa_runtime_include\n+fi\n+if test \"x$with_hsa_runtime_lib\" != x; then\n+  HSA_RUNTIME_LIB=$with_hsa_runtime_lib\n+fi\n+if test \"x$HSA_RUNTIME_INCLUDE\" != x; then\n+  HSA_RUNTIME_CPPFLAGS=-I$HSA_RUNTIME_INCLUDE\n+fi\n+if test \"x$HSA_RUNTIME_LIB\" != x; then\n+  HSA_RUNTIME_LDFLAGS=-L$HSA_RUNTIME_LIB\n+fi\n+\n+\n+# Check whether --with-hsa-kmt-lib was given.\n+if test \"${with_hsa_kmt_lib+set}\" = set; then :\n+  withval=$with_hsa_kmt_lib;\n+fi\n+\n+if test \"x$with_hsa_kmt_lib\" != x; then\n+  HSA_RUNTIME_LDFLAGS=\"$HSA_RUNTIME_LDFLAGS -L$with_hsa_kmt_lib\"\n+  HSA_RUNTIME_LIB=\n+fi\n+\n+PLUGIN_HSA=0\n+PLUGIN_HSA_CPPFLAGS=\n+PLUGIN_HSA_LDFLAGS=\n+PLUGIN_HSA_LIBS=\n+\n+\n+\n+\n+\n+\n+\n # Get offload targets and path to install tree of offloading compiler.\n offload_additional_options=\n offload_additional_lib_paths=\n@@ -15277,6 +15366,60 @@ rm -f core conftest.err conftest.$ac_objext \\\n \t    ;;\n \tesac\n \t;;\n+      hsa*)\n+\tcase \"${target}\" in\n+\t  x86_64-*-*)\n+\t    case \" ${CC} ${CFLAGS} \" in\n+\t      *\" -m32 \"*)\n+\t        PLUGIN_HSA=0\n+\t\t;;\n+\t      *)\n+\t        tgt_name=hsa\n+\t        PLUGIN_HSA=$tgt\n+\t        PLUGIN_HSA_CPPFLAGS=$HSA_RUNTIME_CPPFLAGS\n+\t        PLUGIN_HSA_LDFLAGS=$HSA_RUNTIME_LDFLAGS\n+\t        PLUGIN_HSA_LIBS=\"-lhsa-runtime64 -lhsakmt\"\n+\n+\t        PLUGIN_HSA_save_CPPFLAGS=$CPPFLAGS\n+\t        CPPFLAGS=\"$PLUGIN_HSA_CPPFLAGS $CPPFLAGS\"\n+\t        PLUGIN_HSA_save_LDFLAGS=$LDFLAGS\n+\t        LDFLAGS=\"$PLUGIN_HSA_LDFLAGS $LDFLAGS\"\n+\t        PLUGIN_HSA_save_LIBS=$LIBS\n+\t        LIBS=\"$PLUGIN_HSA_LIBS $LIBS\"\n+\n+\t        cat confdefs.h - <<_ACEOF >conftest.$ac_ext\n+/* end confdefs.h.  */\n+#include \"hsa.h\"\n+int\n+main ()\n+{\n+hsa_status_t status = hsa_init ()\n+  ;\n+  return 0;\n+}\n+_ACEOF\n+if ac_fn_c_try_link \"$LINENO\"; then :\n+  PLUGIN_HSA=1\n+fi\n+rm -f core conftest.err conftest.$ac_objext \\\n+    conftest$ac_exeext conftest.$ac_ext\n+\t        CPPFLAGS=$PLUGIN_HSA_save_CPPFLAGS\n+\t        LDFLAGS=$PLUGIN_HSA_save_LDFLAGS\n+\t        LIBS=$PLUGIN_HSA_save_LIBS\n+\t        case $PLUGIN_HSA in\n+\t          hsa*)\n+\t            HSA_PLUGIN=0\n+\t            as_fn_error \"HSA run-time package required for HSA support\" \"$LINENO\" 5\n+\t            ;;\n+\t        esac\n+\t\t;;\n+\t      esac\n+    \t    ;;\n+\t  *-*-*)\n+\t    PLUGIN_HSA=0\n+            ;;\n+        esac\n+        ;;\n       *)\n \tas_fn_error \"unknown offload target specified\" \"$LINENO\" 5\n \t;;\n@@ -15313,6 +15456,19 @@ cat >>confdefs.h <<_ACEOF\n #define PLUGIN_NVPTX $PLUGIN_NVPTX\n _ACEOF\n \n+ if test $PLUGIN_HSA = 1; then\n+  PLUGIN_HSA_TRUE=\n+  PLUGIN_HSA_FALSE='#'\n+else\n+  PLUGIN_HSA_TRUE='#'\n+  PLUGIN_HSA_FALSE=\n+fi\n+\n+\n+cat >>confdefs.h <<_ACEOF\n+#define PLUGIN_HSA $PLUGIN_HSA\n+_ACEOF\n+\n \n \n # Check for functions needed.\n@@ -16712,6 +16868,10 @@ if test -z \"${PLUGIN_NVPTX_TRUE}\" && test -z \"${PLUGIN_NVPTX_FALSE}\"; then\n   as_fn_error \"conditional \\\"PLUGIN_NVPTX\\\" was never defined.\n Usually this means the macro was only invoked conditionally.\" \"$LINENO\" 5\n fi\n+if test -z \"${PLUGIN_HSA_TRUE}\" && test -z \"${PLUGIN_HSA_FALSE}\"; then\n+  as_fn_error \"conditional \\\"PLUGIN_HSA\\\" was never defined.\n+Usually this means the macro was only invoked conditionally.\" \"$LINENO\" 5\n+fi\n if test -z \"${LIBGOMP_BUILD_VERSIONED_SHLIB_TRUE}\" && test -z \"${LIBGOMP_BUILD_VERSIONED_SHLIB_FALSE}\"; then\n   as_fn_error \"conditional \\\"LIBGOMP_BUILD_VERSIONED_SHLIB\\\" was never defined.\n Usually this means the macro was only invoked conditionally.\" \"$LINENO\" 5"}, {"sha": "53f9248363175324e24b98fbf1471e29667d3057", "filename": "libgomp/libgomp-plugin.h", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Flibgomp-plugin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Flibgomp-plugin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Flibgomp-plugin.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -48,7 +48,8 @@ enum offload_target_type\n   OFFLOAD_TARGET_TYPE_HOST = 2,\n   /* OFFLOAD_TARGET_TYPE_HOST_NONSHM = 3 removed.  */\n   OFFLOAD_TARGET_TYPE_NVIDIA_PTX = 5,\n-  OFFLOAD_TARGET_TYPE_INTEL_MIC = 6\n+  OFFLOAD_TARGET_TYPE_INTEL_MIC = 6,\n+  OFFLOAD_TARGET_TYPE_HSA = 7\n };\n \n /* Auxiliary struct, used for transferring pairs of addresses from plugin"}, {"sha": "7108a6d0118fdffbcaad0b5189bbeaa0848989b5", "filename": "libgomp/libgomp.h", "status": "modified", "additions": 9, "deletions": 3, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Flibgomp.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Flibgomp.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Flibgomp.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -496,6 +496,10 @@ struct gomp_target_task\n   struct target_mem_desc *tgt;\n   struct gomp_task *task;\n   struct gomp_team *team;\n+  /* Copies of firstprivate mapped data for shared memory accelerators.  */\n+  void *firstprivate_copies;\n+  /* Device-specific target arguments.  */\n+  void **args;\n   void *hostaddrs[];\n };\n \n@@ -750,7 +754,8 @@ extern void gomp_task_maybe_wait_for_dependencies (void **);\n extern bool gomp_create_target_task (struct gomp_device_descr *,\n \t\t\t\t     void (*) (void *), size_t, void **,\n \t\t\t\t     size_t *, unsigned short *, unsigned int,\n-\t\t\t\t     void **, enum gomp_target_task_state);\n+\t\t\t\t     void **, void **,\n+\t\t\t\t     enum gomp_target_task_state);\n \n static void inline\n gomp_finish_task (struct gomp_task *task)\n@@ -937,8 +942,9 @@ struct gomp_device_descr\n   void *(*dev2host_func) (int, void *, const void *, size_t);\n   void *(*host2dev_func) (int, void *, const void *, size_t);\n   void *(*dev2dev_func) (int, void *, const void *, size_t);\n-  void (*run_func) (int, void *, void *);\n-  void (*async_run_func) (int, void *, void *, void *);\n+  bool (*can_run_func) (void *);\n+  void (*run_func) (int, void *, void *, void **);\n+  void (*async_run_func) (int, void *, void *, void **, void *);\n \n   /* Splay tree containing information about mapped memory regions.  */\n   struct splay_tree_s mem_map;"}, {"sha": "24eebb68e6727b5cc68226c6ef25f005fb0ed933", "filename": "libgomp/libgomp_g.h", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Flibgomp_g.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Flibgomp_g.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Flibgomp_g.h?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -278,8 +278,7 @@ extern void GOMP_single_copy_end (void *);\n extern void GOMP_target (int, void (*) (void *), const void *,\n \t\t\t size_t, void **, size_t *, unsigned char *);\n extern void GOMP_target_ext (int, void (*) (void *), size_t, void **, size_t *,\n-\t\t\t     unsigned short *, unsigned int, void **,\n-\t\t\t     int, int);\n+\t\t\t     unsigned short *, unsigned int, void **, void **);\n extern void GOMP_target_data (int, const void *,\n \t\t\t      size_t, void **, size_t *, unsigned char *);\n extern void GOMP_target_data_ext (int, size_t, void **, size_t *,"}, {"sha": "1e760f6d83a6892c1cd818c6364032b46996a589", "filename": "libgomp/oacc-host.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Foacc-host.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Foacc-host.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Foacc-host.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -123,7 +123,8 @@ host_host2dev (int n __attribute__ ((unused)),\n }\n \n static void\n-host_run (int n __attribute__ ((unused)), void *fn_ptr, void *vars)\n+host_run (int n __attribute__ ((unused)), void *fn_ptr, void *vars,\n+\t  void **args __attribute__((unused)))\n {\n   void (*fn)(void *) = (void (*)(void *)) fn_ptr;\n "}, {"sha": "035a6636aaa7fb703f0db87f7a29c2998f6161b6", "filename": "libgomp/plugin/Makefrag.am", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fplugin%2FMakefrag.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fplugin%2FMakefrag.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fplugin%2FMakefrag.am?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -38,3 +38,16 @@ libgomp_plugin_nvptx_la_LDFLAGS += $(PLUGIN_NVPTX_LDFLAGS)\n libgomp_plugin_nvptx_la_LIBADD = libgomp.la $(PLUGIN_NVPTX_LIBS)\n libgomp_plugin_nvptx_la_LIBTOOLFLAGS = --tag=disable-static\n endif\n+\n+if PLUGIN_HSA\n+# Heterogenous Systems Architecture plugin\n+libgomp_plugin_hsa_version_info = -version-info $(libtool_VERSION)\n+toolexeclib_LTLIBRARIES += libgomp-plugin-hsa.la\n+libgomp_plugin_hsa_la_SOURCES = plugin/plugin-hsa.c\n+libgomp_plugin_hsa_la_CPPFLAGS = $(AM_CPPFLAGS) $(PLUGIN_HSA_CPPFLAGS)\n+libgomp_plugin_hsa_la_LDFLAGS = $(libgomp_plugin_hsa_version_info) \\\n+\t$(lt_host_flags)\n+libgomp_plugin_hsa_la_LDFLAGS += $(PLUGIN_HSA_LDFLAGS)\n+libgomp_plugin_hsa_la_LIBADD = libgomp.la $(PLUGIN_HSA_LIBS)\n+libgomp_plugin_hsa_la_LIBTOOLFLAGS = --tag=disable-static\n+endif"}, {"sha": "2a9d9f907e3eb9b24c46387dffa827f2e1caffc3", "filename": "libgomp/plugin/configfrag.ac", "status": "modified", "additions": 102, "deletions": 0, "changes": 102, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fplugin%2Fconfigfrag.ac", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fplugin%2Fconfigfrag.ac", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fplugin%2Fconfigfrag.ac?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -81,6 +81,62 @@ AC_SUBST(PLUGIN_NVPTX_CPPFLAGS)\n AC_SUBST(PLUGIN_NVPTX_LDFLAGS)\n AC_SUBST(PLUGIN_NVPTX_LIBS)\n \n+# Look for HSA run-time, its includes and libraries\n+\n+HSA_RUNTIME_INCLUDE=\n+HSA_RUNTIME_LIB=\n+AC_SUBST(HSA_RUNTIME_INCLUDE)\n+AC_SUBST(HSA_RUNTIME_LIB)\n+HSA_RUNTIME_CPPFLAGS=\n+HSA_RUNTIME_LDFLAGS=\n+\n+AC_ARG_WITH(hsa-runtime,\n+\t[AS_HELP_STRING([--with-hsa-runtime=PATH],\n+\t\t[specify prefix directory for installed HSA run-time package.\n+\t\t Equivalent to --with-hsa-runtime-include=PATH/include\n+\t\t plus --with-hsa-runtime-lib=PATH/lib])])\n+AC_ARG_WITH(hsa-runtime-include,\n+\t[AS_HELP_STRING([--with-hsa-runtime-include=PATH],\n+\t\t[specify directory for installed HSA run-time include files])])\n+AC_ARG_WITH(hsa-runtime-lib,\n+\t[AS_HELP_STRING([--with-hsa-runtime-lib=PATH],\n+\t\t[specify directory for the installed HSA run-time library])])\n+if test \"x$with_hsa_runtime\" != x; then\n+  HSA_RUNTIME_INCLUDE=$with_hsa_runtime/include\n+  HSA_RUNTIME_LIB=$with_hsa_runtime/lib\n+fi\n+if test \"x$with_hsa_runtime_include\" != x; then\n+  HSA_RUNTIME_INCLUDE=$with_hsa_runtime_include\n+fi\n+if test \"x$with_hsa_runtime_lib\" != x; then\n+  HSA_RUNTIME_LIB=$with_hsa_runtime_lib\n+fi\n+if test \"x$HSA_RUNTIME_INCLUDE\" != x; then\n+  HSA_RUNTIME_CPPFLAGS=-I$HSA_RUNTIME_INCLUDE\n+fi\n+if test \"x$HSA_RUNTIME_LIB\" != x; then\n+  HSA_RUNTIME_LDFLAGS=-L$HSA_RUNTIME_LIB\n+fi\n+\n+AC_ARG_WITH(hsa-kmt-lib,\n+\t[AS_HELP_STRING([--with-hsa-kmt-lib=PATH],\n+\t\t[specify directory for installed HSA KMT library.])])\n+if test \"x$with_hsa_kmt_lib\" != x; then\n+  HSA_RUNTIME_LDFLAGS=\"$HSA_RUNTIME_LDFLAGS -L$with_hsa_kmt_lib\"\n+  HSA_RUNTIME_LIB=\n+fi\n+\n+PLUGIN_HSA=0\n+PLUGIN_HSA_CPPFLAGS=\n+PLUGIN_HSA_LDFLAGS=\n+PLUGIN_HSA_LIBS=\n+AC_SUBST(PLUGIN_HSA)\n+AC_SUBST(PLUGIN_HSA_CPPFLAGS)\n+AC_SUBST(PLUGIN_HSA_LDFLAGS)\n+AC_SUBST(PLUGIN_HSA_LIBS)\n+\n+\n+\n # Get offload targets and path to install tree of offloading compiler.\n offload_additional_options=\n offload_additional_lib_paths=\n@@ -122,6 +178,49 @@ if test x\"$enable_offload_targets\" != x; then\n \t    ;;\n \tesac\n \t;;\n+      hsa*)\n+\tcase \"${target}\" in\n+\t  x86_64-*-*)\n+\t    case \" ${CC} ${CFLAGS} \" in\n+\t      *\" -m32 \"*)\n+\t        PLUGIN_HSA=0\n+\t\t;;\n+\t      *)\n+\t        tgt_name=hsa\n+\t        PLUGIN_HSA=$tgt\n+\t        PLUGIN_HSA_CPPFLAGS=$HSA_RUNTIME_CPPFLAGS\n+\t        PLUGIN_HSA_LDFLAGS=$HSA_RUNTIME_LDFLAGS\n+\t        PLUGIN_HSA_LIBS=\"-lhsa-runtime64 -lhsakmt\"\n+\n+\t        PLUGIN_HSA_save_CPPFLAGS=$CPPFLAGS\n+\t        CPPFLAGS=\"$PLUGIN_HSA_CPPFLAGS $CPPFLAGS\"\n+\t        PLUGIN_HSA_save_LDFLAGS=$LDFLAGS\n+\t        LDFLAGS=\"$PLUGIN_HSA_LDFLAGS $LDFLAGS\"\n+\t        PLUGIN_HSA_save_LIBS=$LIBS\n+\t        LIBS=\"$PLUGIN_HSA_LIBS $LIBS\"\n+\n+\t        AC_LINK_IFELSE(\n+\t          [AC_LANG_PROGRAM(\n+\t            [#include \"hsa.h\"],\n+\t              [hsa_status_t status = hsa_init ()])],\n+\t          [PLUGIN_HSA=1])\n+\t        CPPFLAGS=$PLUGIN_HSA_save_CPPFLAGS\n+\t        LDFLAGS=$PLUGIN_HSA_save_LDFLAGS\n+\t        LIBS=$PLUGIN_HSA_save_LIBS\n+\t        case $PLUGIN_HSA in\n+\t          hsa*)\n+\t            HSA_PLUGIN=0\n+\t            AC_MSG_ERROR([HSA run-time package required for HSA support])\n+\t            ;;\n+\t        esac\n+\t\t;;\n+\t      esac\n+    \t    ;;\n+\t  *-*-*)\n+\t    PLUGIN_HSA=0\n+            ;;\n+        esac\n+        ;;\n       *)\n \tAC_MSG_ERROR([unknown offload target specified])\n \t;;\n@@ -145,3 +244,6 @@ AC_DEFINE_UNQUOTED(OFFLOAD_TARGETS, \"$offload_targets\",\n AM_CONDITIONAL([PLUGIN_NVPTX], [test $PLUGIN_NVPTX = 1])\n AC_DEFINE_UNQUOTED([PLUGIN_NVPTX], [$PLUGIN_NVPTX],\n   [Define to 1 if the NVIDIA plugin is built, 0 if not.])\n+AM_CONDITIONAL([PLUGIN_HSA], [test $PLUGIN_HSA = 1])\n+AC_DEFINE_UNQUOTED([PLUGIN_HSA], [$PLUGIN_HSA],\n+  [Define to 1 if the HSA plugin is built, 0 if not.])"}, {"sha": "d88849338dca773ad7672c1b68a486ca2273f114", "filename": "libgomp/plugin/plugin-hsa.c", "status": "added", "additions": 1493, "deletions": 0, "changes": 1493, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fplugin%2Fplugin-hsa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Fplugin%2Fplugin-hsa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fplugin%2Fplugin-hsa.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -0,0 +1,1493 @@\n+/* Plugin for HSAIL execution.\n+\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+\n+   Contributed by Martin Jambor <mjambor@suse.cz> and\n+   Martin Liska <mliska@suse.cz>.\n+\n+   This file is part of the GNU Offloading and Multi Processing Library\n+   (libgomp).\n+\n+   Libgomp is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   Libgomp is distributed in the hope that it will be useful, but WITHOUT ANY\n+   WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+   FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n+   more details.\n+\n+   Under Section 7 of GPL version 3, you are granted additional\n+   permissions described in the GCC Runtime Library Exception, version\n+   3.1, as published by the Free Software Foundation.\n+\n+   You should have received a copy of the GNU General Public License and\n+   a copy of the GCC Runtime Library Exception along with this program;\n+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <pthread.h>\n+#include <hsa.h>\n+#include <hsa_ext_finalize.h>\n+#include <dlfcn.h>\n+#include \"libgomp-plugin.h\"\n+#include \"gomp-constants.h\"\n+\n+/* Keep the following GOMP prefixed structures in sync with respective parts of\n+   the compiler.  */\n+\n+/* Structure describing the run-time and grid properties of an HSA kernel\n+   lauch.  */\n+\n+struct GOMP_kernel_launch_attributes\n+{\n+  /* Number of dimensions the workload has.  Maximum number is 3.  */\n+  uint32_t ndim;\n+  /* Size of the grid in the three respective dimensions.  */\n+  uint32_t gdims[3];\n+  /* Size of work-groups in the respective dimensions.  */\n+  uint32_t wdims[3];\n+};\n+\n+/* Collection of information needed for a dispatch of a kernel from a\n+   kernel.  */\n+\n+struct GOMP_hsa_kernel_dispatch\n+{\n+  /* Pointer to a command queue associated with a kernel dispatch agent.  */\n+  void *queue;\n+  /* Pointer to reserved memory for OMP data struct copying.  */\n+  void *omp_data_memory;\n+  /* Pointer to a memory space used for kernel arguments passing.  */\n+  void *kernarg_address;\n+  /* Kernel object.  */\n+  uint64_t object;\n+  /* Synchronization signal used for dispatch synchronization.  */\n+  uint64_t signal;\n+  /* Private segment size.  */\n+  uint32_t private_segment_size;\n+  /* Group segment size.  */\n+  uint32_t group_segment_size;\n+  /* Number of children kernel dispatches.  */\n+  uint64_t kernel_dispatch_count;\n+  /* Debug purpose argument.  */\n+  uint64_t debug;\n+  /* Levels-var ICV.  */\n+  uint64_t omp_level;\n+  /* Kernel dispatch structures created for children kernel dispatches.  */\n+  struct GOMP_hsa_kernel_dispatch **children_dispatches;\n+  /* Number of threads.  */\n+  uint32_t omp_num_threads;\n+};\n+\n+/* Part of the libgomp plugin interface.  Return the name of the accelerator,\n+   which is \"hsa\".  */\n+\n+const char *\n+GOMP_OFFLOAD_get_name (void)\n+{\n+  return \"hsa\";\n+}\n+\n+/* Part of the libgomp plugin interface.  Return the specific capabilities the\n+   HSA accelerator have.  */\n+\n+unsigned int\n+GOMP_OFFLOAD_get_caps (void)\n+{\n+  return GOMP_OFFLOAD_CAP_SHARED_MEM | GOMP_OFFLOAD_CAP_OPENMP_400;\n+}\n+\n+/* Part of the libgomp plugin interface.  Identify as HSA accelerator.  */\n+\n+int\n+GOMP_OFFLOAD_get_type (void)\n+{\n+  return OFFLOAD_TARGET_TYPE_HSA;\n+}\n+\n+/* Return the libgomp version number we're compatible with.  There is\n+   no requirement for cross-version compatibility.  */\n+\n+unsigned\n+GOMP_OFFLOAD_version (void)\n+{\n+  return GOMP_VERSION;\n+}\n+\n+/* Flag to decide whether print to stderr information about what is going on.\n+   Set in init_debug depending on environment variables.  */\n+\n+static bool debug;\n+\n+/* Flag to decide if the runtime should suppress a possible fallback to host\n+   execution.  */\n+\n+static bool suppress_host_fallback;\n+\n+/* Initialize debug and suppress_host_fallback according to the environment.  */\n+\n+static void\n+init_enviroment_variables (void)\n+{\n+  if (getenv (\"HSA_DEBUG\"))\n+    debug = true;\n+  else\n+    debug = false;\n+\n+  if (getenv (\"HSA_SUPPRESS_HOST_FALLBACK\"))\n+    suppress_host_fallback = true;\n+  else\n+    suppress_host_fallback = false;\n+}\n+\n+/* Print a logging message with PREFIX to stderr if HSA_DEBUG value\n+   is set to true.  */\n+\n+#define HSA_LOG(prefix, ...) \\\n+  do \\\n+  { \\\n+    if (debug) \\\n+      { \\\n+\tfprintf (stderr, prefix); \\\n+\tfprintf (stderr, __VA_ARGS__); \\\n+      } \\\n+  } \\\n+  while (false);\n+\n+/* Print a debugging message to stderr.  */\n+\n+#define HSA_DEBUG(...) HSA_LOG (\"HSA debug: \", __VA_ARGS__)\n+\n+/* Print a warning message to stderr.  */\n+\n+#define HSA_WARNING(...) HSA_LOG (\"HSA warning: \", __VA_ARGS__)\n+\n+/* Print HSA warning STR with an HSA STATUS code.  */\n+\n+static void\n+hsa_warn (const char *str, hsa_status_t status)\n+{\n+  if (!debug)\n+    return;\n+\n+  const char *hsa_error;\n+  hsa_status_string (status, &hsa_error);\n+\n+  fprintf (stderr, \"HSA warning: %s\\nRuntime message: %s\", str, hsa_error);\n+}\n+\n+/* Report a fatal error STR together with the HSA error corresponding to STATUS\n+   and terminate execution of the current process.  */\n+\n+static void\n+hsa_fatal (const char *str, hsa_status_t status)\n+{\n+  const char *hsa_error;\n+  hsa_status_string (status, &hsa_error);\n+  GOMP_PLUGIN_fatal (\"HSA fatal error: %s\\nRuntime message: %s\", str,\n+\t\t     hsa_error);\n+}\n+\n+struct hsa_kernel_description\n+{\n+  const char *name;\n+  unsigned omp_data_size;\n+  bool gridified_kernel_p;\n+  unsigned kernel_dependencies_count;\n+  const char **kernel_dependencies;\n+};\n+\n+struct global_var_info\n+{\n+  const char *name;\n+  void *address;\n+};\n+\n+/* Data passed by the static initializer of a compilation unit containing BRIG\n+   to GOMP_offload_register.  */\n+\n+struct brig_image_desc\n+{\n+  hsa_ext_module_t brig_module;\n+  const unsigned kernel_count;\n+  struct hsa_kernel_description *kernel_infos;\n+  const unsigned global_variable_count;\n+  struct global_var_info *global_variables;\n+};\n+\n+struct agent_info;\n+\n+/* Information required to identify, finalize and run any given kernel.  */\n+\n+struct kernel_info\n+{\n+  /* Name of the kernel, required to locate it within the brig module.  */\n+  const char *name;\n+  /* Size of memory space for OMP data.  */\n+  unsigned omp_data_size;\n+  /* The specific agent the kernel has been or will be finalized for and run\n+     on.  */\n+  struct agent_info *agent;\n+  /* The specific module where the kernel takes place.  */\n+  struct module_info *module;\n+  /* Mutex enforcing that at most once thread ever initializes a kernel for\n+     use.  A thread should have locked agent->modules_rwlock for reading before\n+     acquiring it.  */\n+  pthread_mutex_t init_mutex;\n+  /* Flag indicating whether the kernel has been initialized and all fields\n+     below it contain valid data.  */\n+  bool initialized;\n+  /* Flag indicating that the kernel has a problem that blocks an execution.  */\n+  bool initialization_failed;\n+  /* The object to be put into the dispatch queue.  */\n+  uint64_t object;\n+  /* Required size of kernel arguments.  */\n+  uint32_t kernarg_segment_size;\n+  /* Required size of group segment.  */\n+  uint32_t group_segment_size;\n+  /* Required size of private segment.  */\n+  uint32_t private_segment_size;\n+  /* List of all kernel dependencies.  */\n+  const char **dependencies;\n+  /* Number of dependencies.  */\n+  unsigned dependencies_count;\n+  /* Maximum OMP data size necessary for kernel from kernel dispatches.  */\n+  unsigned max_omp_data_size;\n+  /* True if the kernel is gridified.  */\n+  bool gridified_kernel_p;\n+};\n+\n+/* Information about a particular brig module, its image and kernels.  */\n+\n+struct module_info\n+{\n+  /* The next and previous module in the linked list of modules of an agent.  */\n+  struct module_info *next, *prev;\n+  /* The description with which the program has registered the image.  */\n+  struct brig_image_desc *image_desc;\n+\n+  /* Number of kernels in this module.  */\n+  int kernel_count;\n+  /* An array of kernel_info structures describing each kernel in this\n+     module.  */\n+  struct kernel_info kernels[];\n+};\n+\n+/* Information about shared brig library.  */\n+\n+struct brig_library_info\n+{\n+  char *file_name;\n+  hsa_ext_module_t image;\n+};\n+\n+/* Description of an HSA GPU agent and the program associated with it.  */\n+\n+struct agent_info\n+{\n+  /* The HSA ID of the agent.  Assigned when hsa_context is initialized.  */\n+  hsa_agent_t id;\n+  /* Whether the agent has been initialized.  The fields below are usable only\n+     if it has been.  */\n+  bool initialized;\n+  /* The HSA ISA of this agent.  */\n+  hsa_isa_t isa;\n+  /* Command queue of the agent.  */\n+  hsa_queue_t *command_q;\n+  /* Kernel from kernel dispatch command queue.  */\n+  hsa_queue_t *kernel_dispatch_command_q;\n+  /* The HSA memory region from which to allocate kernel arguments.  */\n+  hsa_region_t kernarg_region;\n+\n+  /* Read-write lock that protects kernels which are running or about to be run\n+     from interference with loading and unloading of images.  Needs to be\n+     locked for reading while a kernel is being run, and for writing if the\n+     list of modules is manipulated (and thus the HSA program invalidated).  */\n+  pthread_rwlock_t modules_rwlock;\n+  /* The first module in a linked list of modules associated with this\n+     kernel.  */\n+  struct module_info *first_module;\n+\n+  /* Mutex enforcing that only one thread will finalize the HSA program.  A\n+     thread should have locked agent->modules_rwlock for reading before\n+     acquiring it.  */\n+  pthread_mutex_t prog_mutex;\n+  /* Flag whether the HSA program that consists of all the modules has been\n+     finalized.  */\n+  bool prog_finalized;\n+  /* Flag whether the program was finalized but with a failure.  */\n+  bool prog_finalized_error;\n+  /* HSA executable - the finalized program that is used to locate kernels.  */\n+  hsa_executable_t executable;\n+  /* List of BRIG libraries.  */\n+  struct brig_library_info **brig_libraries;\n+  /* Number of loaded shared BRIG libraries.  */\n+  unsigned brig_libraries_count;\n+};\n+\n+/* Information about the whole HSA environment and all of its agents.  */\n+\n+struct hsa_context_info\n+{\n+  /* Whether the structure has been initialized.  */\n+  bool initialized;\n+  /* Number of usable GPU HSA agents in the system.  */\n+  int agent_count;\n+  /* Array of agent_info structures describing the individual HSA agents.  */\n+  struct agent_info *agents;\n+};\n+\n+/* Information about the whole HSA environment and all of its agents.  */\n+\n+static struct hsa_context_info hsa_context;\n+\n+/* Find kernel for an AGENT by name provided in KERNEL_NAME.  */\n+\n+static struct kernel_info *\n+get_kernel_for_agent (struct agent_info *agent, const char *kernel_name)\n+{\n+  struct module_info *module = agent->first_module;\n+\n+  while (module)\n+    {\n+      for (unsigned i = 0; i < module->kernel_count; i++)\n+\tif (strcmp (module->kernels[i].name, kernel_name) == 0)\n+\t  return &module->kernels[i];\n+\n+      module = module->next;\n+    }\n+\n+  return NULL;\n+}\n+\n+/* Return true if the agent is a GPU and acceptable of concurrent submissions\n+   from different threads.  */\n+\n+static bool\n+suitable_hsa_agent_p (hsa_agent_t agent)\n+{\n+  hsa_device_type_t device_type;\n+  hsa_status_t status\n+    = hsa_agent_get_info (agent, HSA_AGENT_INFO_DEVICE, &device_type);\n+  if (status != HSA_STATUS_SUCCESS || device_type != HSA_DEVICE_TYPE_GPU)\n+    return false;\n+\n+  uint32_t features = 0;\n+  status = hsa_agent_get_info (agent, HSA_AGENT_INFO_FEATURE, &features);\n+  if (status != HSA_STATUS_SUCCESS\n+      || !(features & HSA_AGENT_FEATURE_KERNEL_DISPATCH))\n+    return false;\n+  hsa_queue_type_t queue_type;\n+  status = hsa_agent_get_info (agent, HSA_AGENT_INFO_QUEUE_TYPE, &queue_type);\n+  if (status != HSA_STATUS_SUCCESS\n+      || (queue_type != HSA_QUEUE_TYPE_MULTI))\n+    return false;\n+\n+  return true;\n+}\n+\n+/* Callback of hsa_iterate_agents, if AGENT is a GPU device, increment\n+   agent_count in hsa_context.  */\n+\n+static hsa_status_t\n+count_gpu_agents (hsa_agent_t agent, void *data __attribute__ ((unused)))\n+{\n+  if (suitable_hsa_agent_p (agent))\n+    hsa_context.agent_count++;\n+  return HSA_STATUS_SUCCESS;\n+}\n+\n+/* Callback of hsa_iterate_agents, if AGENT is a GPU device, assign the agent\n+   id to the describing structure in the hsa context.  The index of the\n+   structure is pointed to by DATA, increment it afterwards.  */\n+\n+static hsa_status_t\n+assign_agent_ids (hsa_agent_t agent, void *data)\n+{\n+  if (suitable_hsa_agent_p (agent))\n+    {\n+      int *agent_index = (int *) data;\n+      hsa_context.agents[*agent_index].id = agent;\n+      ++*agent_index;\n+    }\n+  return HSA_STATUS_SUCCESS;\n+}\n+\n+/* Initialize hsa_context if it has not already been done.  */\n+\n+static void\n+init_hsa_context (void)\n+{\n+  hsa_status_t status;\n+  int agent_index = 0;\n+\n+  if (hsa_context.initialized)\n+    return;\n+  init_enviroment_variables ();\n+  status = hsa_init ();\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Run-time could not be initialized\", status);\n+  HSA_DEBUG (\"HSA run-time initialized\\n\");\n+  status = hsa_iterate_agents (count_gpu_agents, NULL);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"HSA GPU devices could not be enumerated\", status);\n+  HSA_DEBUG (\"There are %i HSA GPU devices.\\n\", hsa_context.agent_count);\n+\n+  hsa_context.agents\n+    = GOMP_PLUGIN_malloc_cleared (hsa_context.agent_count\n+\t\t\t\t  * sizeof (struct agent_info));\n+  status = hsa_iterate_agents (assign_agent_ids, &agent_index);\n+  if (agent_index != hsa_context.agent_count)\n+    GOMP_PLUGIN_fatal (\"Failed to assign IDs to all HSA agents\");\n+  hsa_context.initialized = true;\n+}\n+\n+/* Callback of dispatch queues to report errors.  */\n+\n+static void\n+queue_callback (hsa_status_t status,\n+\t\thsa_queue_t *queue __attribute__ ((unused)),\n+\t\tvoid *data __attribute__ ((unused)))\n+{\n+  hsa_fatal (\"Asynchronous queue error\", status);\n+}\n+\n+/* Callback of hsa_agent_iterate_regions.  Determine if a memory REGION can be\n+   used for kernarg allocations and if so write it to the memory pointed to by\n+   DATA and break the query.  */\n+\n+static hsa_status_t\n+get_kernarg_memory_region (hsa_region_t region, void *data)\n+{\n+  hsa_status_t status;\n+  hsa_region_segment_t segment;\n+\n+  status = hsa_region_get_info (region, HSA_REGION_INFO_SEGMENT, &segment);\n+  if (status != HSA_STATUS_SUCCESS)\n+    return status;\n+  if (segment != HSA_REGION_SEGMENT_GLOBAL)\n+    return HSA_STATUS_SUCCESS;\n+\n+  uint32_t flags;\n+  status = hsa_region_get_info (region, HSA_REGION_INFO_GLOBAL_FLAGS, &flags);\n+  if (status != HSA_STATUS_SUCCESS)\n+    return status;\n+  if (flags & HSA_REGION_GLOBAL_FLAG_KERNARG)\n+    {\n+      hsa_region_t *ret = (hsa_region_t *) data;\n+      *ret = region;\n+      return HSA_STATUS_INFO_BREAK;\n+    }\n+  return HSA_STATUS_SUCCESS;\n+}\n+\n+/* Part of the libgomp plugin interface.  Return the number of HSA devices on\n+   the system.  */\n+\n+int\n+GOMP_OFFLOAD_get_num_devices (void)\n+{\n+  init_hsa_context ();\n+  return hsa_context.agent_count;\n+}\n+\n+/* Part of the libgomp plugin interface.  Initialize agent number N so that it\n+   can be used for computation.  */\n+\n+void\n+GOMP_OFFLOAD_init_device (int n)\n+{\n+  init_hsa_context ();\n+  if (n >= hsa_context.agent_count)\n+    GOMP_PLUGIN_fatal (\"Request to initialize non-existing HSA device %i\", n);\n+  struct agent_info *agent = &hsa_context.agents[n];\n+\n+  if (agent->initialized)\n+    return;\n+\n+  if (pthread_rwlock_init (&agent->modules_rwlock, NULL))\n+    GOMP_PLUGIN_fatal (\"Failed to initialize an HSA agent rwlock\");\n+  if (pthread_mutex_init (&agent->prog_mutex, NULL))\n+    GOMP_PLUGIN_fatal (\"Failed to initialize an HSA agent program mutex\");\n+\n+  uint32_t queue_size;\n+  hsa_status_t status;\n+  status = hsa_agent_get_info (agent->id, HSA_AGENT_INFO_QUEUE_MAX_SIZE,\n+\t\t\t       &queue_size);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Error requesting maximum queue size of the HSA agent\", status);\n+  status = hsa_agent_get_info (agent->id, HSA_AGENT_INFO_ISA, &agent->isa);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Error querying the ISA of the agent\", status);\n+  status = hsa_queue_create (agent->id, queue_size, HSA_QUEUE_TYPE_MULTI,\n+\t\t\t     queue_callback, NULL, UINT32_MAX, UINT32_MAX,\n+\t\t\t     &agent->command_q);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Error creating command queue\", status);\n+\n+  status = hsa_queue_create (agent->id, queue_size, HSA_QUEUE_TYPE_MULTI,\n+\t\t\t     queue_callback, NULL, UINT32_MAX, UINT32_MAX,\n+\t\t\t     &agent->kernel_dispatch_command_q);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Error creating kernel dispatch command queue\", status);\n+\n+  agent->kernarg_region.handle = (uint64_t) -1;\n+  status = hsa_agent_iterate_regions (agent->id, get_kernarg_memory_region,\n+\t\t\t\t      &agent->kernarg_region);\n+  if (agent->kernarg_region.handle == (uint64_t) -1)\n+    GOMP_PLUGIN_fatal (\"Could not find suitable memory region for kernel \"\n+\t\t       \"arguments\");\n+  HSA_DEBUG (\"HSA agent initialized, queue has id %llu\\n\",\n+\t     (long long unsigned) agent->command_q->id);\n+  HSA_DEBUG (\"HSA agent initialized, kernel dispatch queue has id %llu\\n\",\n+\t     (long long unsigned) agent->kernel_dispatch_command_q->id);\n+  agent->initialized = true;\n+}\n+\n+/* Verify that hsa_context has already been initialized and return the\n+   agent_info structure describing device number N.  */\n+\n+static struct agent_info *\n+get_agent_info (int n)\n+{\n+  if (!hsa_context.initialized)\n+    GOMP_PLUGIN_fatal (\"Attempt to use uninitialized HSA context.\");\n+  if (n >= hsa_context.agent_count)\n+    GOMP_PLUGIN_fatal (\"Request to operate on anon-existing HSA device %i\", n);\n+  if (!hsa_context.agents[n].initialized)\n+    GOMP_PLUGIN_fatal (\"Attempt to use an uninitialized HSA agent.\");\n+  return &hsa_context.agents[n];\n+}\n+\n+/* Insert MODULE to the linked list of modules of AGENT.  */\n+\n+static void\n+add_module_to_agent (struct agent_info *agent, struct module_info *module)\n+{\n+  if (agent->first_module)\n+    agent->first_module->prev = module;\n+  module->next = agent->first_module;\n+  module->prev = NULL;\n+  agent->first_module = module;\n+}\n+\n+/* Remove MODULE from the linked list of modules of AGENT.  */\n+\n+static void\n+remove_module_from_agent (struct agent_info *agent, struct module_info *module)\n+{\n+  if (agent->first_module == module)\n+    agent->first_module = module->next;\n+  if (module->prev)\n+    module->prev->next = module->next;\n+  if (module->next)\n+    module->next->prev = module->prev;\n+}\n+\n+/* Free the HSA program in agent and everything associated with it and set\n+   agent->prog_finalized and the initialized flags of all kernels to false.  */\n+\n+static void\n+destroy_hsa_program (struct agent_info *agent)\n+{\n+  if (!agent->prog_finalized || agent->prog_finalized_error)\n+    return;\n+\n+  hsa_status_t status;\n+\n+  HSA_DEBUG (\"Destroying the current HSA program.\\n\");\n+\n+  status = hsa_executable_destroy (agent->executable);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not destroy HSA executable\", status);\n+\n+  struct module_info *module;\n+  for (module = agent->first_module; module; module = module->next)\n+    {\n+      int i;\n+      for (i = 0; i < module->kernel_count; i++)\n+\tmodule->kernels[i].initialized = false;\n+    }\n+  agent->prog_finalized = false;\n+}\n+\n+/* Part of the libgomp plugin interface.  Load BRIG module described by struct\n+   brig_image_desc in TARGET_DATA and return references to kernel descriptors\n+   in TARGET_TABLE.  */\n+\n+int\n+GOMP_OFFLOAD_load_image (int ord, unsigned version, void *target_data,\n+\t\t\t struct addr_pair **target_table)\n+{\n+  if (GOMP_VERSION_DEV (version) > GOMP_VERSION_HSA)\n+    GOMP_PLUGIN_fatal (\"Offload data incompatible with HSA plugin\"\n+\t\t       \" (expected %u, received %u)\",\n+\t\t       GOMP_VERSION_HSA, GOMP_VERSION_DEV (version));\n+\n+  struct brig_image_desc *image_desc = (struct brig_image_desc *) target_data;\n+  struct agent_info *agent;\n+  struct addr_pair *pair;\n+  struct module_info *module;\n+  struct kernel_info *kernel;\n+  int kernel_count = image_desc->kernel_count;\n+\n+  agent = get_agent_info (ord);\n+  if (pthread_rwlock_wrlock (&agent->modules_rwlock))\n+    GOMP_PLUGIN_fatal (\"Unable to write-lock an HSA agent rwlock\");\n+  if (agent->prog_finalized)\n+    destroy_hsa_program (agent);\n+\n+  HSA_DEBUG (\"Encountered %d kernels in an image\\n\", kernel_count);\n+  pair = GOMP_PLUGIN_malloc (kernel_count * sizeof (struct addr_pair));\n+  *target_table = pair;\n+  module = (struct module_info *)\n+    GOMP_PLUGIN_malloc_cleared (sizeof (struct module_info)\n+\t\t\t\t+ kernel_count * sizeof (struct kernel_info));\n+  module->image_desc = image_desc;\n+  module->kernel_count = kernel_count;\n+\n+  kernel = &module->kernels[0];\n+\n+  /* Allocate memory for kernel dependencies.  */\n+  for (unsigned i = 0; i < kernel_count; i++)\n+    {\n+      pair->start = (uintptr_t) kernel;\n+      pair->end = (uintptr_t) (kernel + 1);\n+\n+      struct hsa_kernel_description *d = &image_desc->kernel_infos[i];\n+      kernel->agent = agent;\n+      kernel->module = module;\n+      kernel->name = d->name;\n+      kernel->omp_data_size = d->omp_data_size;\n+      kernel->gridified_kernel_p = d->gridified_kernel_p;\n+      kernel->dependencies_count = d->kernel_dependencies_count;\n+      kernel->dependencies = d->kernel_dependencies;\n+      if (pthread_mutex_init (&kernel->init_mutex, NULL))\n+\tGOMP_PLUGIN_fatal (\"Failed to initialize an HSA kernel mutex\");\n+\n+      kernel++;\n+      pair++;\n+    }\n+\n+  add_module_to_agent (agent, module);\n+  if (pthread_rwlock_unlock (&agent->modules_rwlock))\n+    GOMP_PLUGIN_fatal (\"Unable to unlock an HSA agent rwlock\");\n+  return kernel_count;\n+}\n+\n+/* Add a shared BRIG library from a FILE_NAME to an AGENT.  */\n+\n+static struct brig_library_info *\n+add_shared_library (const char *file_name, struct agent_info *agent)\n+{\n+  struct brig_library_info *library = NULL;\n+\n+  void *f = dlopen (file_name, RTLD_NOW);\n+  void *start = dlsym (f, \"__brig_start\");\n+  void *end = dlsym (f, \"__brig_end\");\n+\n+  if (start == NULL || end == NULL)\n+    return NULL;\n+\n+  unsigned size = end - start;\n+  char *buf = (char *) GOMP_PLUGIN_malloc (size);\n+  memcpy (buf, start, size);\n+\n+  library = GOMP_PLUGIN_malloc (sizeof (struct agent_info));\n+  library->file_name = (char *) GOMP_PLUGIN_malloc\n+    ((strlen (file_name) + 1));\n+  strcpy (library->file_name, file_name);\n+  library->image = (hsa_ext_module_t) buf;\n+\n+  return library;\n+}\n+\n+/* Release memory used for BRIG shared libraries that correspond\n+   to an AGENT.  */\n+\n+static void\n+release_agent_shared_libraries (struct agent_info *agent)\n+{\n+  for (unsigned i = 0; i < agent->brig_libraries_count; i++)\n+    if (agent->brig_libraries[i])\n+      {\n+\tfree (agent->brig_libraries[i]->file_name);\n+\tfree (agent->brig_libraries[i]->image);\n+\tfree (agent->brig_libraries[i]);\n+      }\n+\n+  free (agent->brig_libraries);\n+}\n+\n+/* Create and finalize the program consisting of all loaded modules.  */\n+\n+static void\n+create_and_finalize_hsa_program (struct agent_info *agent)\n+{\n+  hsa_status_t status;\n+  hsa_ext_program_t prog_handle;\n+  int mi = 0;\n+\n+  if (pthread_mutex_lock (&agent->prog_mutex))\n+    GOMP_PLUGIN_fatal (\"Could not lock an HSA agent program mutex\");\n+  if (agent->prog_finalized)\n+    goto final;\n+\n+  status = hsa_ext_program_create (HSA_MACHINE_MODEL_LARGE, HSA_PROFILE_FULL,\n+\t\t\t\t   HSA_DEFAULT_FLOAT_ROUNDING_MODE_DEFAULT,\n+\t\t\t\t   NULL, &prog_handle);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not create an HSA program\", status);\n+\n+  HSA_DEBUG (\"Created a finalized program\\n\");\n+\n+  struct module_info *module = agent->first_module;\n+  while (module)\n+    {\n+      status = hsa_ext_program_add_module (prog_handle,\n+\t\t\t\t\t   module->image_desc->brig_module);\n+      if (status != HSA_STATUS_SUCCESS)\n+\thsa_fatal (\"Could not add a module to the HSA program\", status);\n+      module = module->next;\n+      mi++;\n+    }\n+\n+  /* Load all shared libraries.  */\n+  const char *libraries[] = { \"libhsamath.so\", \"libhsastd.so\" };\n+  const unsigned libraries_count = sizeof (libraries) / sizeof (const char *);\n+\n+  agent->brig_libraries_count = libraries_count;\n+  agent->brig_libraries = GOMP_PLUGIN_malloc_cleared\n+    (sizeof (struct brig_library_info) * libraries_count);\n+\n+  for (unsigned i = 0; i < libraries_count; i++)\n+    {\n+      struct brig_library_info *library = add_shared_library (libraries[i],\n+\t\t\t\t\t\t\t      agent);\n+      if (library == NULL)\n+\t{\n+\t  HSA_WARNING (\"Could not open a shared BRIG library: %s\\n\",\n+\t\t       libraries[i]);\n+\t  continue;\n+\t}\n+\n+      status = hsa_ext_program_add_module (prog_handle, library->image);\n+      if (status != HSA_STATUS_SUCCESS)\n+\thsa_warn (\"Could not add a shared BRIG library the HSA program\",\n+\t\t  status);\n+      else\n+\tHSA_DEBUG (\"a shared BRIG library has been added to a program: %s\\n\",\n+\t\t   libraries[i]);\n+    }\n+\n+  hsa_ext_control_directives_t control_directives;\n+  memset (&control_directives, 0, sizeof (control_directives));\n+  hsa_code_object_t code_object;\n+  status = hsa_ext_program_finalize (prog_handle, agent->isa,\n+\t\t\t\t     HSA_EXT_FINALIZER_CALL_CONVENTION_AUTO,\n+\t\t\t\t     control_directives, \"\",\n+\t\t\t\t     HSA_CODE_OBJECT_TYPE_PROGRAM,\n+\t\t\t\t     &code_object);\n+  if (status != HSA_STATUS_SUCCESS)\n+    {\n+      hsa_warn (\"Finalization of the HSA program failed\", status);\n+      goto failure;\n+    }\n+\n+  HSA_DEBUG (\"Finalization done\\n\");\n+  hsa_ext_program_destroy (prog_handle);\n+\n+  status\n+    = hsa_executable_create (HSA_PROFILE_FULL, HSA_EXECUTABLE_STATE_UNFROZEN,\n+\t\t\t     \"\", &agent->executable);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not create HSA executable\", status);\n+\n+  module = agent->first_module;\n+  while (module)\n+    {\n+      /* Initialize all global variables declared in the module.  */\n+      for (unsigned i = 0; i < module->image_desc->global_variable_count; i++)\n+\t{\n+\t  struct global_var_info *var;\n+\t  var = &module->image_desc->global_variables[i];\n+\t  status\n+\t    = hsa_executable_global_variable_define (agent->executable,\n+\t\t\t\t\t\t     var->name, var->address);\n+\n+\t  HSA_DEBUG (\"Defining global variable: %s, address: %p\\n\", var->name,\n+\t\t     var->address);\n+\n+\t  if (status != HSA_STATUS_SUCCESS)\n+\t    hsa_fatal (\"Could not define a global variable in the HSA program\",\n+\t\t       status);\n+\t}\n+\n+      module = module->next;\n+    }\n+\n+  status = hsa_executable_load_code_object (agent->executable, agent->id,\n+\t\t\t\t\t    code_object, \"\");\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not add a code object to the HSA executable\", status);\n+  status = hsa_executable_freeze (agent->executable, \"\");\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not freeze the HSA executable\", status);\n+\n+  HSA_DEBUG (\"Froze HSA executable with the finalized code object\\n\");\n+\n+  /* If all goes good, jump to final.  */\n+  goto final;\n+\n+failure:\n+  agent->prog_finalized_error = true;\n+\n+final:\n+  agent->prog_finalized = true;\n+\n+  if (pthread_mutex_unlock (&agent->prog_mutex))\n+    GOMP_PLUGIN_fatal (\"Could not unlock an HSA agent program mutex\");\n+}\n+\n+/* Create kernel dispatch data structure for given KERNEL.  */\n+\n+static struct GOMP_hsa_kernel_dispatch *\n+create_single_kernel_dispatch (struct kernel_info *kernel,\n+\t\t\t       unsigned omp_data_size)\n+{\n+  struct agent_info *agent = kernel->agent;\n+  struct GOMP_hsa_kernel_dispatch *shadow\n+    = GOMP_PLUGIN_malloc_cleared (sizeof (struct GOMP_hsa_kernel_dispatch));\n+\n+  shadow->queue = agent->command_q;\n+  shadow->omp_data_memory\n+    = omp_data_size > 0 ? GOMP_PLUGIN_malloc (omp_data_size) : NULL;\n+  unsigned dispatch_count = kernel->dependencies_count;\n+  shadow->kernel_dispatch_count = dispatch_count;\n+\n+  shadow->children_dispatches\n+    = GOMP_PLUGIN_malloc (dispatch_count * sizeof (shadow));\n+\n+  shadow->object = kernel->object;\n+\n+  hsa_signal_t sync_signal;\n+  hsa_status_t status = hsa_signal_create (1, 0, NULL, &sync_signal);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Error creating the HSA sync signal\", status);\n+\n+  shadow->signal = sync_signal.handle;\n+  shadow->private_segment_size = kernel->private_segment_size;\n+  shadow->group_segment_size = kernel->group_segment_size;\n+\n+  status\n+    = hsa_memory_allocate (agent->kernarg_region, kernel->kernarg_segment_size,\n+\t\t\t   &shadow->kernarg_address);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not allocate memory for HSA kernel arguments\", status);\n+\n+  return shadow;\n+}\n+\n+/* Release data structure created for a kernel dispatch in SHADOW argument.  */\n+\n+static void\n+release_kernel_dispatch (struct GOMP_hsa_kernel_dispatch *shadow)\n+{\n+  HSA_DEBUG (\"Released kernel dispatch: %p has value: %lu (%p)\\n\", shadow,\n+\t     shadow->debug, (void *) shadow->debug);\n+\n+  hsa_memory_free (shadow->kernarg_address);\n+\n+  hsa_signal_t s;\n+  s.handle = shadow->signal;\n+  hsa_signal_destroy (s);\n+\n+  free (shadow->omp_data_memory);\n+\n+  for (unsigned i = 0; i < shadow->kernel_dispatch_count; i++)\n+    release_kernel_dispatch (shadow->children_dispatches[i]);\n+\n+  free (shadow->children_dispatches);\n+  free (shadow);\n+}\n+\n+/* Initialize a KERNEL without its dependencies.  MAX_OMP_DATA_SIZE is used\n+   to calculate maximum necessary memory for OMP data allocation.  */\n+\n+static void\n+init_single_kernel (struct kernel_info *kernel, unsigned *max_omp_data_size)\n+{\n+  hsa_status_t status;\n+  struct agent_info *agent = kernel->agent;\n+  hsa_executable_symbol_t kernel_symbol;\n+  status = hsa_executable_get_symbol (agent->executable, NULL, kernel->name,\n+\t\t\t\t      agent->id, 0, &kernel_symbol);\n+  if (status != HSA_STATUS_SUCCESS)\n+    {\n+      hsa_warn (\"Could not find symbol for kernel in the code object\", status);\n+      goto failure;\n+    }\n+  HSA_DEBUG (\"Located kernel %s\\n\", kernel->name);\n+  status\n+    = hsa_executable_symbol_get_info (kernel_symbol,\n+\t\t\t\t      HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_OBJECT,\n+\t\t\t\t      &kernel->object);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not extract a kernel object from its symbol\", status);\n+  status = hsa_executable_symbol_get_info\n+    (kernel_symbol, HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_KERNARG_SEGMENT_SIZE,\n+     &kernel->kernarg_segment_size);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not get info about kernel argument size\", status);\n+  status = hsa_executable_symbol_get_info\n+    (kernel_symbol, HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_GROUP_SEGMENT_SIZE,\n+     &kernel->group_segment_size);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not get info about kernel group segment size\", status);\n+  status = hsa_executable_symbol_get_info\n+    (kernel_symbol, HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_PRIVATE_SEGMENT_SIZE,\n+     &kernel->private_segment_size);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Could not get info about kernel private segment size\",\n+\t       status);\n+\n+  HSA_DEBUG (\"Kernel structure for %s fully initialized with \"\n+\t     \"following segment sizes: \\n\", kernel->name);\n+  HSA_DEBUG (\"  group_segment_size: %u\\n\",\n+\t     (unsigned) kernel->group_segment_size);\n+  HSA_DEBUG (\"  private_segment_size: %u\\n\",\n+\t     (unsigned) kernel->private_segment_size);\n+  HSA_DEBUG (\"  kernarg_segment_size: %u\\n\",\n+\t     (unsigned) kernel->kernarg_segment_size);\n+  HSA_DEBUG (\"  omp_data_size: %u\\n\", kernel->omp_data_size);\n+  HSA_DEBUG (\"  gridified_kernel_p: %u\\n\", kernel->gridified_kernel_p);\n+\n+  if (kernel->omp_data_size > *max_omp_data_size)\n+    *max_omp_data_size = kernel->omp_data_size;\n+\n+  for (unsigned i = 0; i < kernel->dependencies_count; i++)\n+    {\n+      struct kernel_info *dependency\n+\t= get_kernel_for_agent (agent, kernel->dependencies[i]);\n+\n+      if (dependency == NULL)\n+\t{\n+\t  HSA_DEBUG (\"Could not find a dependency for a kernel: %s, \"\n+\t\t     \"dependency name: %s\\n\", kernel->name,\n+\t\t     kernel->dependencies[i]);\n+\t  goto failure;\n+\t}\n+\n+      if (dependency->dependencies_count > 0)\n+\t{\n+\t  HSA_DEBUG (\"HSA does not allow kernel dispatching code with \"\n+\t\t     \"a depth bigger than one\\n\")\n+\t  goto failure;\n+\t}\n+\n+      init_single_kernel (dependency, max_omp_data_size);\n+    }\n+\n+  return;\n+\n+failure:\n+  kernel->initialization_failed = true;\n+}\n+\n+/* Indent stream F by INDENT spaces.  */\n+\n+static void\n+indent_stream (FILE *f, unsigned indent)\n+{\n+  fprintf (f, \"%*s\", indent, \"\");\n+}\n+\n+/* Dump kernel DISPATCH data structure and indent it by INDENT spaces.  */\n+\n+static void\n+print_kernel_dispatch (struct GOMP_hsa_kernel_dispatch *dispatch, unsigned indent)\n+{\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"this: %p\\n\", dispatch);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"queue: %p\\n\", dispatch->queue);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"omp_data_memory: %p\\n\", dispatch->omp_data_memory);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"kernarg_address: %p\\n\", dispatch->kernarg_address);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"object: %lu\\n\", dispatch->object);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"signal: %lu\\n\", dispatch->signal);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"private_segment_size: %u\\n\",\n+\t   dispatch->private_segment_size);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"group_segment_size: %u\\n\",\n+\t   dispatch->group_segment_size);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"children dispatches: %lu\\n\",\n+\t   dispatch->kernel_dispatch_count);\n+  indent_stream (stderr, indent);\n+  fprintf (stderr, \"omp_num_threads: %u\\n\",\n+\t   dispatch->omp_num_threads);\n+  fprintf (stderr, \"\\n\");\n+\n+  for (unsigned i = 0; i < dispatch->kernel_dispatch_count; i++)\n+    print_kernel_dispatch (dispatch->children_dispatches[i], indent + 2);\n+}\n+\n+/* Create kernel dispatch data structure for a KERNEL and all its\n+   dependencies.  */\n+\n+static struct GOMP_hsa_kernel_dispatch *\n+create_kernel_dispatch (struct kernel_info *kernel, unsigned omp_data_size)\n+{\n+  struct GOMP_hsa_kernel_dispatch *shadow\n+    = create_single_kernel_dispatch (kernel, omp_data_size);\n+  shadow->omp_num_threads = 64;\n+  shadow->debug = 0;\n+  shadow->omp_level = kernel->gridified_kernel_p ? 1 : 0;\n+\n+  /* Create kernel dispatch data structures.  We do not allow to have\n+     a kernel dispatch with depth bigger than one.  */\n+  for (unsigned i = 0; i < kernel->dependencies_count; i++)\n+    {\n+      struct kernel_info *dependency\n+\t= get_kernel_for_agent (kernel->agent, kernel->dependencies[i]);\n+      shadow->children_dispatches[i]\n+\t= create_single_kernel_dispatch (dependency, omp_data_size);\n+      shadow->children_dispatches[i]->queue\n+\t= kernel->agent->kernel_dispatch_command_q;\n+      shadow->children_dispatches[i]->omp_level = 1;\n+    }\n+\n+  return shadow;\n+}\n+\n+/* Do all the work that is necessary before running KERNEL for the first time.\n+   The function assumes the program has been created, finalized and frozen by\n+   create_and_finalize_hsa_program.  */\n+\n+static void\n+init_kernel (struct kernel_info *kernel)\n+{\n+  if (pthread_mutex_lock (&kernel->init_mutex))\n+    GOMP_PLUGIN_fatal (\"Could not lock an HSA kernel initialization mutex\");\n+  if (kernel->initialized)\n+    {\n+      if (pthread_mutex_unlock (&kernel->init_mutex))\n+\tGOMP_PLUGIN_fatal (\"Could not unlock an HSA kernel initialization \"\n+\t\t\t   \"mutex\");\n+\n+      return;\n+    }\n+\n+  /* Precomputed maximum size of OMP data necessary for a kernel from kernel\n+     dispatch operation.  */\n+  init_single_kernel (kernel, &kernel->max_omp_data_size);\n+\n+  if (!kernel->initialization_failed)\n+    HSA_DEBUG (\"\\n\");\n+\n+  kernel->initialized = true;\n+  if (pthread_mutex_unlock (&kernel->init_mutex))\n+    GOMP_PLUGIN_fatal (\"Could not unlock an HSA kernel initialization \"\n+\t\t       \"mutex\");\n+}\n+\n+/* Parse the target attributes INPUT provided by the compiler and return true\n+   if we should run anything all.  If INPUT is NULL, fill DEF with default\n+   values, then store INPUT or DEF into *RESULT.  */\n+\n+static bool\n+parse_target_attributes (void **input,\n+\t\t\t struct GOMP_kernel_launch_attributes *def,\n+\t\t\t struct GOMP_kernel_launch_attributes **result)\n+{\n+  if (!input)\n+    GOMP_PLUGIN_fatal (\"No target arguments provided\");\n+\n+  bool attrs_found = false;\n+  while (*input)\n+    {\n+      uintptr_t id = (uintptr_t) *input;\n+      if ((id & GOMP_TARGET_ARG_DEVICE_MASK) == GOMP_DEVICE_HSA\n+\t  && ((id & GOMP_TARGET_ARG_ID_MASK)\n+\t      == GOMP_TARGET_ARG_HSA_KERNEL_ATTRIBUTES))\n+\t{\n+\t  input++;\n+\t  attrs_found = true;\n+\t  break;\n+\t}\n+\n+      if (id & GOMP_TARGET_ARG_SUBSEQUENT_PARAM)\n+\tinput++;\n+      input++;\n+    }\n+\n+  if (!attrs_found)\n+    {\n+      def->ndim = 1;\n+      def->gdims[0] = 1;\n+      def->gdims[1] = 1;\n+      def->gdims[2] = 1;\n+      def->wdims[0] = 1;\n+      def->wdims[1] = 1;\n+      def->wdims[2] = 1;\n+      *result = def;\n+      HSA_DEBUG (\"GOMP_OFFLOAD_run called with no launch attributes\\n\");\n+      return true;\n+    }\n+\n+  struct GOMP_kernel_launch_attributes *kla;\n+  kla = (struct GOMP_kernel_launch_attributes *) *input;\n+  *result = kla;\n+  if (kla->ndim != 1)\n+    GOMP_PLUGIN_fatal (\"HSA does not yet support number of dimensions \"\n+\t\t       \"different from one.\");\n+  if (kla->gdims[0] == 0)\n+    return false;\n+\n+  HSA_DEBUG (\"GOMP_OFFLOAD_run called with grid size %u and group size %u\\n\",\n+\t     kla->gdims[0], kla->wdims[0]);\n+\n+  return true;\n+}\n+\n+/* Return true if the HSA runtime can run function FN_PTR.  */\n+\n+bool\n+GOMP_OFFLOAD_can_run (void *fn_ptr)\n+{\n+  struct kernel_info *kernel = (struct kernel_info *) fn_ptr;\n+  struct agent_info *agent = kernel->agent;\n+  create_and_finalize_hsa_program (agent);\n+\n+  if (agent->prog_finalized_error)\n+    goto failure;\n+\n+  init_kernel (kernel);\n+  if (kernel->initialization_failed)\n+    goto failure;\n+\n+  return true;\n+\n+failure:\n+  if (suppress_host_fallback)\n+    GOMP_PLUGIN_fatal (\"HSA host fallback has been suppressed\");\n+  HSA_DEBUG (\"HSA target cannot be launched, doing a host fallback\\n\");\n+  return false;\n+}\n+\n+/* Part of the libgomp plugin interface.  Run a kernel on device N and pass it\n+   an array of pointers in VARS as a parameter.  The kernel is identified by\n+   FN_PTR which must point to a kernel_info structure.  */\n+\n+void\n+GOMP_OFFLOAD_run (int n, void *fn_ptr, void *vars, void **args)\n+{\n+  struct kernel_info *kernel = (struct kernel_info *) fn_ptr;\n+  struct agent_info *agent = kernel->agent;\n+  struct GOMP_kernel_launch_attributes def;\n+  struct GOMP_kernel_launch_attributes *kla;\n+  if (!parse_target_attributes (args, &def, &kla))\n+    {\n+      HSA_DEBUG (\"Will not run HSA kernel because the grid size is zero\\n\");\n+      return;\n+    }\n+  if (pthread_rwlock_rdlock (&agent->modules_rwlock))\n+    GOMP_PLUGIN_fatal (\"Unable to read-lock an HSA agent rwlock\");\n+\n+  if (!agent->initialized)\n+    GOMP_PLUGIN_fatal (\"Agent must be initialized\");\n+\n+  if (!kernel->initialized)\n+    GOMP_PLUGIN_fatal (\"Called kernel must be initialized\");\n+\n+  struct GOMP_hsa_kernel_dispatch *shadow\n+    = create_kernel_dispatch (kernel, kernel->max_omp_data_size);\n+\n+  if (debug)\n+    {\n+      fprintf (stderr, \"\\nKernel has following dependencies:\\n\");\n+      print_kernel_dispatch (shadow, 2);\n+    }\n+\n+  uint64_t index = hsa_queue_add_write_index_release (agent->command_q, 1);\n+  HSA_DEBUG (\"Got AQL index %llu\\n\", (long long int) index);\n+\n+  /* Wait until the queue is not full before writing the packet.   */\n+  while (index - hsa_queue_load_read_index_acquire (agent->command_q)\n+\t >= agent->command_q->size)\n+    ;\n+\n+  hsa_kernel_dispatch_packet_t *packet;\n+  packet = ((hsa_kernel_dispatch_packet_t *) agent->command_q->base_address)\n+\t   + index % agent->command_q->size;\n+\n+  memset (((uint8_t *) packet) + 4, 0, sizeof (*packet) - 4);\n+  packet->setup |= (uint16_t) 1 << HSA_KERNEL_DISPATCH_PACKET_SETUP_DIMENSIONS;\n+  packet->grid_size_x = kla->gdims[0];\n+  uint32_t wgs = kla->wdims[0];\n+  if (wgs == 0)\n+    /* TODO: Provide a default via environment.  */\n+    wgs = 64;\n+  else if (wgs > kla->gdims[0])\n+    wgs = kla->gdims[0];\n+  packet->workgroup_size_x = wgs;\n+  packet->grid_size_y = 1;\n+  packet->workgroup_size_y = 1;\n+  packet->grid_size_z = 1;\n+  packet->workgroup_size_z = 1;\n+  packet->private_segment_size = kernel->private_segment_size;\n+  packet->group_segment_size = kernel->group_segment_size;\n+  packet->kernel_object = kernel->object;\n+  packet->kernarg_address = shadow->kernarg_address;\n+  hsa_signal_t s;\n+  s.handle = shadow->signal;\n+  packet->completion_signal = s;\n+  hsa_signal_store_relaxed (s, 1);\n+  memcpy (shadow->kernarg_address, &vars, sizeof (vars));\n+\n+  memcpy (shadow->kernarg_address + sizeof (vars), &shadow,\n+\t  sizeof (struct hsa_kernel_runtime *));\n+\n+  HSA_DEBUG (\"Copying kernel runtime pointer to kernarg_address\\n\");\n+\n+  uint16_t header;\n+  header = HSA_PACKET_TYPE_KERNEL_DISPATCH << HSA_PACKET_HEADER_TYPE;\n+  header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE;\n+  header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE;\n+\n+  HSA_DEBUG (\"Going to dispatch kernel %s\\n\", kernel->name);\n+\n+  __atomic_store_n ((uint16_t *) (&packet->header), header, __ATOMIC_RELEASE);\n+  hsa_signal_store_release (agent->command_q->doorbell_signal, index);\n+\n+  /* TODO: GPU agents in Carrizo APUs cannot properly update L2 cache for\n+     signal wait and signal load operations on their own and we need to\n+     periodically call the hsa_signal_load_acquire on completion signals of\n+     children kernels in the CPU to make that happen.  As soon the\n+     limitation will be resolved, this workaround can be removed.  */\n+\n+  HSA_DEBUG (\"Kernel dispatched, waiting for completion\\n\");\n+\n+  /* Root signal waits with 1ms timeout.  */\n+  while (hsa_signal_wait_acquire (s, HSA_SIGNAL_CONDITION_LT, 1, 1000 * 1000,\n+\t\t\t\t  HSA_WAIT_STATE_BLOCKED) != 0)\n+    for (unsigned i = 0; i < shadow->kernel_dispatch_count; i++)\n+      {\n+\thsa_signal_t child_s;\n+\tchild_s.handle = shadow->children_dispatches[i]->signal;\n+\n+\tHSA_DEBUG (\"Waiting for children completion signal: %lu\\n\",\n+\t\t   shadow->children_dispatches[i]->signal);\n+\thsa_signal_load_acquire (child_s);\n+      }\n+\n+  release_kernel_dispatch (shadow);\n+\n+  if (pthread_rwlock_unlock (&agent->modules_rwlock))\n+    GOMP_PLUGIN_fatal (\"Unable to unlock an HSA agent rwlock\");\n+}\n+\n+/* Information to be passed to a thread running a kernel asycnronously.  */\n+\n+struct async_run_info\n+{\n+  int device;\n+  void *tgt_fn;\n+  void *tgt_vars;\n+  void **args;\n+  void *async_data;\n+};\n+\n+/* Thread routine to run a kernel asynchronously.  */\n+\n+static void *\n+run_kernel_asynchronously (void *thread_arg)\n+{\n+  struct async_run_info *info = (struct async_run_info *) thread_arg;\n+  int device = info->device;\n+  void *tgt_fn = info->tgt_fn;\n+  void *tgt_vars = info->tgt_vars;\n+  void **args = info->args;\n+  void *async_data = info->async_data;\n+\n+  free (info);\n+  GOMP_OFFLOAD_run (device, tgt_fn, tgt_vars, args);\n+  GOMP_PLUGIN_target_task_completion (async_data);\n+  return NULL;\n+}\n+\n+/* Part of the libgomp plugin interface.  Run a kernel like GOMP_OFFLOAD_run\n+   does, but asynchronously and call GOMP_PLUGIN_target_task_completion when it\n+   has finished.  */\n+\n+void\n+GOMP_OFFLOAD_async_run (int device, void *tgt_fn, void *tgt_vars,\n+\t\t\tvoid **args, void *async_data)\n+{\n+  pthread_t pt;\n+  struct async_run_info *info;\n+  HSA_DEBUG (\"GOMP_OFFLOAD_async_run invoked\\n\")\n+  info = GOMP_PLUGIN_malloc (sizeof (struct async_run_info));\n+\n+  info->device = device;\n+  info->tgt_fn = tgt_fn;\n+  info->tgt_vars = tgt_vars;\n+  info->args = args;\n+  info->async_data = async_data;\n+\n+  int err = pthread_create (&pt, NULL, &run_kernel_asynchronously, info);\n+  if (err != 0)\n+    GOMP_PLUGIN_fatal (\"HSA asynchronous thread creation failed: %s\",\n+\t\t       strerror (err));\n+  err = pthread_detach (pt);\n+  if (err != 0)\n+    GOMP_PLUGIN_fatal (\"Failed to detach a thread to run HSA kernel \"\n+\t\t       \"asynchronously: %s\", strerror (err));\n+}\n+\n+/* Deinitialize all information associated with MODULE and kernels within\n+   it.  */\n+\n+void\n+destroy_module (struct module_info *module)\n+{\n+  int i;\n+  for (i = 0; i < module->kernel_count; i++)\n+    if (pthread_mutex_destroy (&module->kernels[i].init_mutex))\n+      GOMP_PLUGIN_fatal (\"Failed to destroy an HSA kernel initialization \"\n+\t\t\t \"mutex\");\n+}\n+\n+/* Part of the libgomp plugin interface.  Unload BRIG module described by\n+   struct brig_image_desc in TARGET_DATA from agent number N.  */\n+\n+void\n+GOMP_OFFLOAD_unload_image (int n, unsigned version, void *target_data)\n+{\n+  if (GOMP_VERSION_DEV (version) > GOMP_VERSION_HSA)\n+    GOMP_PLUGIN_fatal (\"Offload data incompatible with HSA plugin\"\n+\t\t       \" (expected %u, received %u)\",\n+\t\t       GOMP_VERSION_HSA, GOMP_VERSION_DEV (version));\n+\n+  struct agent_info *agent;\n+  agent = get_agent_info (n);\n+  if (pthread_rwlock_wrlock (&agent->modules_rwlock))\n+    GOMP_PLUGIN_fatal (\"Unable to write-lock an HSA agent rwlock\");\n+\n+  struct module_info *module = agent->first_module;\n+  while (module)\n+    {\n+      if (module->image_desc == target_data)\n+\tbreak;\n+      module = module->next;\n+    }\n+  if (!module)\n+    GOMP_PLUGIN_fatal (\"Attempt to unload an image that has never been \"\n+\t\t       \"loaded before\");\n+\n+  remove_module_from_agent (agent, module);\n+  destroy_module (module);\n+  free (module);\n+  destroy_hsa_program (agent);\n+  if (pthread_rwlock_unlock (&agent->modules_rwlock))\n+    GOMP_PLUGIN_fatal (\"Unable to unlock an HSA agent rwlock\");\n+}\n+\n+/* Part of the libgomp plugin interface.  Deinitialize all information and\n+   status associated with agent number N.  We do not attempt any\n+   synchronization, assuming the user and libgomp will not attempt\n+   deinitialization of a device that is in any way being used at the same\n+   time.  */\n+\n+void\n+GOMP_OFFLOAD_fini_device (int n)\n+{\n+  struct agent_info *agent = get_agent_info (n);\n+  if (!agent->initialized)\n+    return;\n+\n+  struct module_info *next_module = agent->first_module;\n+  while (next_module)\n+    {\n+      struct module_info *module = next_module;\n+      next_module = module->next;\n+      destroy_module (module);\n+      free (module);\n+    }\n+  agent->first_module = NULL;\n+  destroy_hsa_program (agent);\n+\n+  release_agent_shared_libraries (agent);\n+\n+  hsa_status_t status = hsa_queue_destroy (agent->command_q);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Error destroying command queue\", status);\n+  status = hsa_queue_destroy (agent->kernel_dispatch_command_q);\n+  if (status != HSA_STATUS_SUCCESS)\n+    hsa_fatal (\"Error destroying kernel dispatch command queue\", status);\n+  if (pthread_mutex_destroy (&agent->prog_mutex))\n+    GOMP_PLUGIN_fatal (\"Failed to destroy an HSA agent program mutex\");\n+  if (pthread_rwlock_destroy (&agent->modules_rwlock))\n+    GOMP_PLUGIN_fatal (\"Failed to destroy an HSA agent rwlock\");\n+  agent->initialized = false;\n+}\n+\n+/* Part of the libgomp plugin interface.  Not implemented as it is not required\n+   for HSA.  */\n+\n+void *\n+GOMP_OFFLOAD_alloc (int ord, size_t size)\n+{\n+  GOMP_PLUGIN_fatal (\"HSA GOMP_OFFLOAD_alloc is not implemented because \"\n+\t\t     \"it should never be called\");\n+}\n+\n+/* Part of the libgomp plugin interface.  Not implemented as it is not required\n+   for HSA.  */\n+\n+void\n+GOMP_OFFLOAD_free (int ord, void *ptr)\n+{\n+  GOMP_PLUGIN_fatal (\"HSA GOMP_OFFLOAD_free is not implemented because \"\n+\t\t     \"it should never be called\");\n+}\n+\n+/* Part of the libgomp plugin interface.  Not implemented as it is not required\n+   for HSA.  */\n+\n+void *\n+GOMP_OFFLOAD_dev2host (int ord, void *dst, const void *src, size_t n)\n+{\n+  GOMP_PLUGIN_fatal (\"HSA GOMP_OFFLOAD_dev2host is not implemented because \"\n+\t\t     \"it should never be called\");\n+}\n+\n+/* Part of the libgomp plugin interface.  Not implemented as it is not required\n+   for HSA.  */\n+\n+void *\n+GOMP_OFFLOAD_host2dev (int ord, void *dst, const void *src, size_t n)\n+{\n+  GOMP_PLUGIN_fatal (\"HSA GOMP_OFFLOAD_host2dev is not implemented because \"\n+\t\t     \"it should never be called\");\n+}\n+\n+/* Part of the libgomp plugin interface.  Not implemented as it is not required\n+   for HSA.  */\n+\n+void *\n+GOMP_OFFLOAD_dev2dev (int ord, void *dst, const void *src, size_t n)\n+{\n+  GOMP_PLUGIN_fatal (\"HSA GOMP_OFFLOAD_dev2dev is not implemented because \"\n+\t\t     \"it should never be called\");\n+}"}, {"sha": "f1f58492ee5490c01731f10be39dc08a2665d3de", "filename": "libgomp/target.c", "status": "modified", "additions": 163, "deletions": 62, "changes": 225, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Ftarget.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Ftarget.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Ftarget.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1329,44 +1329,90 @@ gomp_target_fallback (void (*fn) (void *), void **hostaddrs)\n   *thr = old_thr;\n }\n \n-/* Host fallback with firstprivate map-type handling.  */\n+/* Calculate alignment and size requirements of a private copy of data shared\n+   as GOMP_MAP_FIRSTPRIVATE and store them to TGT_ALIGN and TGT_SIZE.  */\n \n-static void\n-gomp_target_fallback_firstprivate (void (*fn) (void *), size_t mapnum,\n-\t\t\t\t   void **hostaddrs, size_t *sizes,\n-\t\t\t\t   unsigned short *kinds)\n+static inline void\n+calculate_firstprivate_requirements (size_t mapnum, size_t *sizes,\n+\t\t\t\t     unsigned short *kinds, size_t *tgt_align,\n+\t\t\t\t     size_t *tgt_size)\n {\n-  size_t i, tgt_align = 0, tgt_size = 0;\n-  char *tgt = NULL;\n+  size_t i;\n+  for (i = 0; i < mapnum; i++)\n+    if ((kinds[i] & 0xff) == GOMP_MAP_FIRSTPRIVATE)\n+      {\n+\tsize_t align = (size_t) 1 << (kinds[i] >> 8);\n+\tif (*tgt_align < align)\n+\t  *tgt_align = align;\n+\t*tgt_size = (*tgt_size + align - 1) & ~(align - 1);\n+\t*tgt_size += sizes[i];\n+      }\n+}\n+\n+/* Copy data shared as GOMP_MAP_FIRSTPRIVATE to DST.  */\n+\n+static inline void\n+copy_firstprivate_data (char *tgt, size_t mapnum, void **hostaddrs,\n+\t\t\tsize_t *sizes, unsigned short *kinds, size_t tgt_align,\n+\t\t\tsize_t tgt_size)\n+{\n+  uintptr_t al = (uintptr_t) tgt & (tgt_align - 1);\n+  if (al)\n+    tgt += tgt_align - al;\n+  tgt_size = 0;\n+  size_t i;\n   for (i = 0; i < mapnum; i++)\n     if ((kinds[i] & 0xff) == GOMP_MAP_FIRSTPRIVATE)\n       {\n \tsize_t align = (size_t) 1 << (kinds[i] >> 8);\n-\tif (tgt_align < align)\n-\t  tgt_align = align;\n \ttgt_size = (tgt_size + align - 1) & ~(align - 1);\n-\ttgt_size += sizes[i];\n+\tmemcpy (tgt + tgt_size, hostaddrs[i], sizes[i]);\n+\thostaddrs[i] = tgt + tgt_size;\n+\ttgt_size = tgt_size + sizes[i];\n       }\n+}\n+\n+/* Host fallback with firstprivate map-type handling.  */\n+\n+static void\n+gomp_target_fallback_firstprivate (void (*fn) (void *), size_t mapnum,\n+\t\t\t\t   void **hostaddrs, size_t *sizes,\n+\t\t\t\t   unsigned short *kinds)\n+{\n+  size_t tgt_align = 0, tgt_size = 0;\n+  calculate_firstprivate_requirements (mapnum, sizes, kinds, &tgt_align,\n+\t\t\t\t       &tgt_size);\n   if (tgt_align)\n     {\n-      tgt = gomp_alloca (tgt_size + tgt_align - 1);\n-      uintptr_t al = (uintptr_t) tgt & (tgt_align - 1);\n-      if (al)\n-\ttgt += tgt_align - al;\n-      tgt_size = 0;\n-      for (i = 0; i < mapnum; i++)\n-\tif ((kinds[i] & 0xff) == GOMP_MAP_FIRSTPRIVATE)\n-\t  {\n-\t    size_t align = (size_t) 1 << (kinds[i] >> 8);\n-\t    tgt_size = (tgt_size + align - 1) & ~(align - 1);\n-\t    memcpy (tgt + tgt_size, hostaddrs[i], sizes[i]);\n-\t    hostaddrs[i] = tgt + tgt_size;\n-\t    tgt_size = tgt_size + sizes[i];\n-\t  }\n+      char *tgt = gomp_alloca (tgt_size + tgt_align - 1);\n+      copy_firstprivate_data (tgt, mapnum, hostaddrs, sizes, kinds, tgt_align,\n+\t\t\t      tgt_size);\n     }\n   gomp_target_fallback (fn, hostaddrs);\n }\n \n+/* Handle firstprivate map-type for shared memory devices and the host\n+   fallback.  Return the pointer of firstprivate copies which has to be freed\n+   after use.  */\n+\n+static void *\n+gomp_target_unshare_firstprivate (size_t mapnum, void **hostaddrs,\n+\t\t\t\t  size_t *sizes, unsigned short *kinds)\n+{\n+  size_t tgt_align = 0, tgt_size = 0;\n+  char *tgt = NULL;\n+\n+  calculate_firstprivate_requirements (mapnum, sizes, kinds, &tgt_align,\n+\t\t\t\t       &tgt_size);\n+  if (tgt_align)\n+    {\n+      tgt = gomp_malloc (tgt_size + tgt_align - 1);\n+      copy_firstprivate_data (tgt, mapnum, hostaddrs, sizes, kinds, tgt_align,\n+\t\t\t      tgt_size);\n+    }\n+  return tgt;\n+}\n+\n /* Helper function of GOMP_target{,_ext} routines.  */\n \n static void *\n@@ -1390,7 +1436,12 @@ gomp_get_target_fn_addr (struct gomp_device_descr *devicep,\n       splay_tree_key tgt_fn = splay_tree_lookup (&devicep->mem_map, &k);\n       gomp_mutex_unlock (&devicep->lock);\n       if (tgt_fn == NULL)\n-\tgomp_fatal (\"Target function wasn't mapped\");\n+\t{\n+\t  if (devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n+\t    return NULL;\n+\t  else\n+\t    gomp_fatal (\"Target function wasn't mapped\");\n+\t}\n \n       return (void *) tgt_fn->tgt_offset;\n     }\n@@ -1416,20 +1467,32 @@ GOMP_target (int device, void (*fn) (void *), const void *unused,\n   void *fn_addr;\n   if (devicep == NULL\n       || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      /* All shared memory devices should use the GOMP_target_ext function.  */\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM\n       || !(fn_addr = gomp_get_target_fn_addr (devicep, fn)))\n     return gomp_target_fallback (fn, hostaddrs);\n \n   struct target_mem_desc *tgt_vars\n     = gomp_map_vars (devicep, mapnum, hostaddrs, NULL, sizes, kinds, false,\n \t\t     GOMP_MAP_VARS_TARGET);\n-  devicep->run_func (devicep->target_id, fn_addr, (void *) tgt_vars->tgt_start);\n+  devicep->run_func (devicep->target_id, fn_addr, (void *) tgt_vars->tgt_start,\n+\t\t     NULL);\n   gomp_unmap_vars (tgt_vars, true);\n }\n \n /* Like GOMP_target, but KINDS is 16-bit, UNUSED is no longer present,\n    and several arguments have been added:\n    FLAGS is a bitmask, see GOMP_TARGET_FLAG_* in gomp-constants.h.\n    DEPEND is array of dependencies, see GOMP_task for details.\n+\n+   ARGS is a pointer to an array consisting of a variable number of both\n+   device-independent and device-specific arguments, which can take one two\n+   elements where the first specifies for which device it is intended, the type\n+   and optionally also the value.  If the value is not present in the first\n+   one, the whole second element the actual value.  The last element of the\n+   array is a single NULL.  Among the device independent can be for example\n+   NUM_TEAMS and THREAD_LIMIT.\n+\n    NUM_TEAMS is positive if GOMP_teams will be called in the body with\n    that value, or 1 if teams construct is not present, or 0, if\n    teams construct does not have num_teams clause and so the choice is\n@@ -1443,14 +1506,10 @@ GOMP_target (int device, void (*fn) (void *), const void *unused,\n void\n GOMP_target_ext (int device, void (*fn) (void *), size_t mapnum,\n \t\t void **hostaddrs, size_t *sizes, unsigned short *kinds,\n-\t\t unsigned int flags, void **depend, int num_teams,\n-\t\t int thread_limit)\n+\t\t unsigned int flags, void **depend, void **args)\n {\n   struct gomp_device_descr *devicep = resolve_device (device);\n \n-  (void) num_teams;\n-  (void) thread_limit;\n-\n   if (flags & GOMP_TARGET_FLAG_NOWAIT)\n     {\n       struct gomp_thread *thr = gomp_thread ();\n@@ -1487,7 +1546,7 @@ GOMP_target_ext (int device, void (*fn) (void *), size_t mapnum,\n \t  && !thr->task->final_task)\n \t{\n \t  gomp_create_target_task (devicep, fn, mapnum, hostaddrs,\n-\t\t\t\t   sizes, kinds, flags, depend,\n+\t\t\t\t   sizes, kinds, flags, depend, args,\n \t\t\t\t   GOMP_TARGET_TASK_BEFORE_MAP);\n \t  return;\n \t}\n@@ -1507,17 +1566,30 @@ GOMP_target_ext (int device, void (*fn) (void *), size_t mapnum,\n   void *fn_addr;\n   if (devicep == NULL\n       || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n-      || !(fn_addr = gomp_get_target_fn_addr (devicep, fn)))\n+      || !(fn_addr = gomp_get_target_fn_addr (devicep, fn))\n+      || (devicep->can_run_func && !devicep->can_run_func (fn_addr)))\n     {\n       gomp_target_fallback_firstprivate (fn, mapnum, hostaddrs, sizes, kinds);\n       return;\n     }\n \n-  struct target_mem_desc *tgt_vars\n-    = gomp_map_vars (devicep, mapnum, hostaddrs, NULL, sizes, kinds, true,\n-\t\t     GOMP_MAP_VARS_TARGET);\n-  devicep->run_func (devicep->target_id, fn_addr, (void *) tgt_vars->tgt_start);\n-  gomp_unmap_vars (tgt_vars, true);\n+  struct target_mem_desc *tgt_vars;\n+  void *fpc = NULL;\n+  if (devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n+    {\n+      fpc = gomp_target_unshare_firstprivate (mapnum, hostaddrs, sizes, kinds);\n+      tgt_vars = NULL;\n+    }\n+  else\n+    tgt_vars = gomp_map_vars (devicep, mapnum, hostaddrs, NULL, sizes, kinds,\n+\t\t\t      true, GOMP_MAP_VARS_TARGET);\n+  devicep->run_func (devicep->target_id, fn_addr,\n+\t\t     tgt_vars ? (void *) tgt_vars->tgt_start : hostaddrs,\n+\t\t     args);\n+  if (tgt_vars)\n+    gomp_unmap_vars (tgt_vars, true);\n+  else\n+    free (fpc);\n }\n \n /* Host fallback for GOMP_target_data{,_ext} routines.  */\n@@ -1547,7 +1619,8 @@ GOMP_target_data (int device, const void *unused, size_t mapnum,\n   struct gomp_device_descr *devicep = resolve_device (device);\n \n   if (devicep == NULL\n-      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || (devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM))\n     return gomp_target_data_fallback ();\n \n   struct target_mem_desc *tgt\n@@ -1565,7 +1638,8 @@ GOMP_target_data_ext (int device, size_t mapnum, void **hostaddrs,\n   struct gomp_device_descr *devicep = resolve_device (device);\n \n   if (devicep == NULL\n-      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return gomp_target_data_fallback ();\n \n   struct target_mem_desc *tgt\n@@ -1595,7 +1669,8 @@ GOMP_target_update (int device, const void *unused, size_t mapnum,\n   struct gomp_device_descr *devicep = resolve_device (device);\n \n   if (devicep == NULL\n-      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return;\n \n   gomp_update (devicep, mapnum, hostaddrs, sizes, kinds, false);\n@@ -1626,7 +1701,7 @@ GOMP_target_update_ext (int device, size_t mapnum, void **hostaddrs,\n \t      if (gomp_create_target_task (devicep, (void (*) (void *)) NULL,\n \t\t\t\t\t   mapnum, hostaddrs, sizes, kinds,\n \t\t\t\t\t   flags | GOMP_TARGET_FLAG_UPDATE,\n-\t\t\t\t\t   depend, GOMP_TARGET_TASK_DATA))\n+\t\t\t\t\t   depend, NULL, GOMP_TARGET_TASK_DATA))\n \t\treturn;\n \t    }\n \t  else\n@@ -1646,7 +1721,8 @@ GOMP_target_update_ext (int device, size_t mapnum, void **hostaddrs,\n     }\n \n   if (devicep == NULL\n-      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return;\n \n   struct gomp_thread *thr = gomp_thread ();\n@@ -1756,7 +1832,7 @@ GOMP_target_enter_exit_data (int device, size_t mapnum, void **hostaddrs,\n \t    {\n \t      if (gomp_create_target_task (devicep, (void (*) (void *)) NULL,\n \t\t\t\t\t   mapnum, hostaddrs, sizes, kinds,\n-\t\t\t\t\t   flags, depend,\n+\t\t\t\t\t   flags, depend, NULL,\n \t\t\t\t\t   GOMP_TARGET_TASK_DATA))\n \t\treturn;\n \t    }\n@@ -1777,7 +1853,8 @@ GOMP_target_enter_exit_data (int device, size_t mapnum, void **hostaddrs,\n     }\n \n   if (devicep == NULL\n-      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return;\n \n   struct gomp_thread *thr = gomp_thread ();\n@@ -1815,7 +1892,8 @@ gomp_target_task_fn (void *data)\n       void *fn_addr;\n       if (devicep == NULL\n \t  || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n-\t  || !(fn_addr = gomp_get_target_fn_addr (devicep, ttask->fn)))\n+\t  || !(fn_addr = gomp_get_target_fn_addr (devicep, ttask->fn))\n+\t  || (devicep->can_run_func && !devicep->can_run_func (fn_addr)))\n \t{\n \t  ttask->state = GOMP_TARGET_TASK_FALLBACK;\n \t  gomp_target_fallback_firstprivate (ttask->fn, ttask->mapnum,\n@@ -1826,22 +1904,36 @@ gomp_target_task_fn (void *data)\n \n       if (ttask->state == GOMP_TARGET_TASK_FINISHED)\n \t{\n-\t  gomp_unmap_vars (ttask->tgt, true);\n+\t  if (ttask->tgt)\n+\t    gomp_unmap_vars (ttask->tgt, true);\n \t  return false;\n \t}\n \n-      ttask->tgt\n-\t= gomp_map_vars (devicep, ttask->mapnum, ttask->hostaddrs, NULL,\n-\t\t\t ttask->sizes, ttask->kinds, true,\n-\t\t\t GOMP_MAP_VARS_TARGET);\n+      void *actual_arguments;\n+      if (devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n+\t{\n+\t  ttask->tgt = NULL;\n+\t  ttask->firstprivate_copies\n+\t    = gomp_target_unshare_firstprivate (ttask->mapnum, ttask->hostaddrs,\n+\t\t\t\t\t\tttask->sizes, ttask->kinds);\n+\t  actual_arguments = ttask->hostaddrs;\n+\t}\n+      else\n+\t{\n+\t  ttask->tgt = gomp_map_vars (devicep, ttask->mapnum, ttask->hostaddrs,\n+\t\t\t\t      NULL, ttask->sizes, ttask->kinds, true,\n+\t\t\t\t      GOMP_MAP_VARS_TARGET);\n+\t  actual_arguments = (void *) ttask->tgt->tgt_start;\n+\t}\n       ttask->state = GOMP_TARGET_TASK_READY_TO_RUN;\n \n-      devicep->async_run_func (devicep->target_id, fn_addr,\n-\t\t\t       (void *) ttask->tgt->tgt_start, (void *) ttask);\n+      devicep->async_run_func (devicep->target_id, fn_addr, actual_arguments,\n+\t\t\t       ttask->args, (void *) ttask);\n       return true;\n     }\n   else if (devicep == NULL\n-\t   || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+\t   || !(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+\t   || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return false;\n \n   size_t i;\n@@ -1891,7 +1983,8 @@ omp_target_alloc (size_t size, int device_num)\n   if (devicep == NULL)\n     return NULL;\n \n-  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return malloc (size);\n \n   gomp_mutex_lock (&devicep->lock);\n@@ -1919,7 +2012,8 @@ omp_target_free (void *device_ptr, int device_num)\n   if (devicep == NULL)\n     return;\n \n-  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     {\n       free (device_ptr);\n       return;\n@@ -1946,7 +2040,8 @@ omp_target_is_present (void *ptr, int device_num)\n   if (devicep == NULL)\n     return 0;\n \n-  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return 1;\n \n   gomp_mutex_lock (&devicep->lock);\n@@ -1976,7 +2071,8 @@ omp_target_memcpy (void *dst, void *src, size_t length, size_t dst_offset,\n       if (dst_devicep == NULL)\n \treturn EINVAL;\n \n-      if (!(dst_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      if (!(dst_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+\t  || dst_devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n \tdst_devicep = NULL;\n     }\n   if (src_device_num != GOMP_DEVICE_HOST_FALLBACK)\n@@ -1988,7 +2084,8 @@ omp_target_memcpy (void *dst, void *src, size_t length, size_t dst_offset,\n       if (src_devicep == NULL)\n \treturn EINVAL;\n \n-      if (!(src_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      if (!(src_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+\t  || src_devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n \tsrc_devicep = NULL;\n     }\n   if (src_devicep == NULL && dst_devicep == NULL)\n@@ -2118,7 +2215,8 @@ omp_target_memcpy_rect (void *dst, void *src, size_t element_size,\n       if (dst_devicep == NULL)\n \treturn EINVAL;\n \n-      if (!(dst_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      if (!(dst_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+\t  || dst_devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n \tdst_devicep = NULL;\n     }\n   if (src_device_num != GOMP_DEVICE_HOST_FALLBACK)\n@@ -2130,7 +2228,8 @@ omp_target_memcpy_rect (void *dst, void *src, size_t element_size,\n       if (src_devicep == NULL)\n \treturn EINVAL;\n \n-      if (!(src_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+      if (!(src_devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+\t  || src_devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n \tsrc_devicep = NULL;\n     }\n \n@@ -2166,7 +2265,8 @@ omp_target_associate_ptr (void *host_ptr, void *device_ptr, size_t size,\n   if (devicep == NULL)\n     return EINVAL;\n \n-  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400))\n+  if (!(devicep->capabilities & GOMP_OFFLOAD_CAP_OPENMP_400)\n+      || devicep->capabilities & GOMP_OFFLOAD_CAP_SHARED_MEM)\n     return EINVAL;\n \n   gomp_mutex_lock (&devicep->lock);\n@@ -2309,6 +2409,7 @@ gomp_load_plugin_for_device (struct gomp_device_descr *device,\n     {\n       DLSYM (run);\n       DLSYM (async_run);\n+      DLSYM_OPT (can_run, can_run);\n       DLSYM (dev2dev);\n     }\n   if (device->capabilities & GOMP_OFFLOAD_CAP_OPENACC_200)"}, {"sha": "0f45c444623969ac192f7c3aed4449cac72d1afa", "filename": "libgomp/task.c", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Ftask.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Ftask.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Ftask.c?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -582,6 +582,7 @@ GOMP_PLUGIN_target_task_completion (void *data)\n       return;\n     }\n   ttask->state = GOMP_TARGET_TASK_FINISHED;\n+  free (ttask->firstprivate_copies);\n   gomp_target_task_completion (team, task);\n   gomp_mutex_unlock (&team->task_lock);\n }\n@@ -594,7 +595,7 @@ bool\n gomp_create_target_task (struct gomp_device_descr *devicep,\n \t\t\t void (*fn) (void *), size_t mapnum, void **hostaddrs,\n \t\t\t size_t *sizes, unsigned short *kinds,\n-\t\t\t unsigned int flags, void **depend,\n+\t\t\t unsigned int flags, void **depend, void **args,\n \t\t\t enum gomp_target_task_state state)\n {\n   struct gomp_thread *thr = gomp_thread ();\n@@ -654,6 +655,7 @@ gomp_create_target_task (struct gomp_device_descr *devicep,\n   ttask->devicep = devicep;\n   ttask->fn = fn;\n   ttask->mapnum = mapnum;\n+  ttask->args = args;\n   memcpy (ttask->hostaddrs, hostaddrs, mapnum * sizeof (void *));\n   ttask->sizes = (size_t *) &ttask->hostaddrs[mapnum];\n   memcpy (ttask->sizes, sizes, mapnum * sizeof (size_t));"}, {"sha": "1fae9e8cdcbe3677ab2b0fcff4f915cd886a9591", "filename": "libgomp/testsuite/Makefile.in", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Ftestsuite%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/libgomp%2Ftestsuite%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Ftestsuite%2FMakefile.in?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -111,6 +111,8 @@ FC = @FC@\n FCFLAGS = @FCFLAGS@\n FGREP = @FGREP@\n GREP = @GREP@\n+HSA_RUNTIME_INCLUDE = @HSA_RUNTIME_INCLUDE@\n+HSA_RUNTIME_LIB = @HSA_RUNTIME_LIB@\n INSTALL = @INSTALL@\n INSTALL_DATA = @INSTALL_DATA@\n INSTALL_PROGRAM = @INSTALL_PROGRAM@\n@@ -155,6 +157,10 @@ PACKAGE_URL = @PACKAGE_URL@\n PACKAGE_VERSION = @PACKAGE_VERSION@\n PATH_SEPARATOR = @PATH_SEPARATOR@\n PERL = @PERL@\n+PLUGIN_HSA = @PLUGIN_HSA@\n+PLUGIN_HSA_CPPFLAGS = @PLUGIN_HSA_CPPFLAGS@\n+PLUGIN_HSA_LDFLAGS = @PLUGIN_HSA_LDFLAGS@\n+PLUGIN_HSA_LIBS = @PLUGIN_HSA_LIBS@\n PLUGIN_NVPTX = @PLUGIN_NVPTX@\n PLUGIN_NVPTX_CPPFLAGS = @PLUGIN_NVPTX_CPPFLAGS@\n PLUGIN_NVPTX_LDFLAGS = @PLUGIN_NVPTX_LDFLAGS@"}, {"sha": "a4dc72ec0a732f2a7ca3dfe0c40da8163e472df8", "filename": "liboffloadmic/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/liboffloadmic%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/liboffloadmic%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/liboffloadmic%2FChangeLog?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -1,3 +1,8 @@\n+2016-01-19  Martin Jambor  <mjambor@suse.cz>\n+\t* plugin/libgomp-plugin-intelmic.cpp (GOMP_OFFLOAD_async_run): New\n+\tunused parameter.\n+\t(GOMP_OFFLOAD_run): Likewise.\n+\n 2015-12-14  Ilya Verbin  <ilya.verbin@intel.com>\n \n \t* plugin/libgomp-plugin-intelmic.cpp (unregister_main_image): Remove."}, {"sha": "58ef5954ec52daf7128f4ab6d49480b6990e5d0d", "filename": "liboffloadmic/plugin/libgomp-plugin-intelmic.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b2b40051500c944e882c274727cea7231eefaaf5/liboffloadmic%2Fplugin%2Flibgomp-plugin-intelmic.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b2b40051500c944e882c274727cea7231eefaaf5/liboffloadmic%2Fplugin%2Flibgomp-plugin-intelmic.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/liboffloadmic%2Fplugin%2Flibgomp-plugin-intelmic.cpp?ref=b2b40051500c944e882c274727cea7231eefaaf5", "patch": "@@ -528,7 +528,7 @@ GOMP_OFFLOAD_dev2dev (int device, void *dst_ptr, const void *src_ptr,\n \n extern \"C\" void\n GOMP_OFFLOAD_async_run (int device, void *tgt_fn, void *tgt_vars,\n-\t\t\tvoid *async_data)\n+\t\t\tvoid **, void *async_data)\n {\n   TRACE (\"(device = %d, tgt_fn = %p, tgt_vars = %p, async_data = %p)\", device,\n \t tgt_fn, tgt_vars, async_data);\n@@ -544,7 +544,7 @@ GOMP_OFFLOAD_async_run (int device, void *tgt_fn, void *tgt_vars,\n }\n \n extern \"C\" void\n-GOMP_OFFLOAD_run (int device, void *tgt_fn, void *tgt_vars)\n+GOMP_OFFLOAD_run (int device, void *tgt_fn, void *tgt_vars, void **)\n {\n   TRACE (\"(device = %d, tgt_fn = %p, tgt_vars = %p)\", device, tgt_fn, tgt_vars);\n "}]}