{"sha": "e6fcb60dd918ee3419b78329721ed6bd22c4be25", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTZmY2I2MGRkOTE4ZWUzNDE5Yjc4MzI5NzIxZWQ2YmQyMmM0YmUyNQ==", "commit": {"author": {"name": "Kazu Hirata", "email": "kazu@hxi.com", "date": "2000-08-06T17:57:57Z"}, "committer": {"name": "Jeff Law", "email": "law@gcc.gnu.org", "date": "2000-08-06T17:57:57Z"}, "message": "* loop.c: Fix formatting.\n\nFrom-SVN: r35526", "tree": {"sha": "9e89fd722806a5f3e2ea33829404a12a672edd6e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9e89fd722806a5f3e2ea33829404a12a672edd6e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e6fcb60dd918ee3419b78329721ed6bd22c4be25", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e6fcb60dd918ee3419b78329721ed6bd22c4be25", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e6fcb60dd918ee3419b78329721ed6bd22c4be25", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e6fcb60dd918ee3419b78329721ed6bd22c4be25/comments", "author": null, "committer": null, "parents": [{"sha": "556273e010e8a1a09c02e8dbb4b47d4abf9ecb1c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/556273e010e8a1a09c02e8dbb4b47d4abf9ecb1c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/556273e010e8a1a09c02e8dbb4b47d4abf9ecb1c"}], "stats": {"total": 437, "additions": 221, "deletions": 216}, "files": [{"sha": "01ad603bfc8d96e59a6af2a9c7365743817e8f37", "filename": "gcc/ChangeLog", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e6fcb60dd918ee3419b78329721ed6bd22c4be25/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e6fcb60dd918ee3419b78329721ed6bd22c4be25/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e6fcb60dd918ee3419b78329721ed6bd22c4be25", "patch": "@@ -1,5 +1,7 @@\n 2000-08-06  Kazu Hirata  <kazu@hxi.com>\n \n+\t* loop.c: Fix formatting.\n+\n \t* dwarf2out.c: Fix formatting.\n \n \t* tm.texi (FUNCTION_ARG_PARTIAL_NREGS): Fix a typo."}, {"sha": "225e73a5c113ed8fc81928e134396fc4199a79a1", "filename": "gcc/loop.c", "status": "modified", "additions": 219, "deletions": 216, "changes": 435, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e6fcb60dd918ee3419b78329721ed6bd22c4be25/gcc%2Floop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e6fcb60dd918ee3419b78329721ed6bd22c4be25/gcc%2Floop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.c?ref=e6fcb60dd918ee3419b78329721ed6bd22c4be25", "patch": "@@ -19,10 +19,9 @@ along with GNU CC; see the file COPYING.  If not, write to\n the Free Software Foundation, 59 Temple Place - Suite 330,\n Boston, MA 02111-1307, USA.  */\n \n-\n /* This is the loop optimization pass of the compiler.\n    It finds invariant computations within loops and moves them\n-   to the beginning of the loop.  Then it identifies basic and \n+   to the beginning of the loop.  Then it identifies basic and\n    general induction variables.  Strength reduction is applied to the general\n    induction variables, and induction variable elimination is applied to\n    the basic induction variables.\n@@ -192,7 +191,7 @@ struct movable\n   rtx set_dest;\t\t\t/* The destination of this SET.  */\n   rtx dependencies;\t\t/* When INSN is libcall, this is an EXPR_LIST\n \t\t\t\t   of any registers used within the LIBCALL.  */\n-  int consec;\t\t\t/* Number of consecutive following insns \n+  int consec;\t\t\t/* Number of consecutive following insns\n \t\t\t\t   that must be moved with this one.  */\n   unsigned int regno;\t\t/* The register it sets */\n   short lifetime;\t\t/* lifetime of that register;\n@@ -208,7 +207,7 @@ struct movable\n \t\t   that the reg is live outside the range from where it is set\n \t\t   to the following label.  */\n   unsigned int done : 1;\t/* 1 inhibits further processing of this */\n-  \n+\n   unsigned int partial : 1;\t/* 1 means this reg is used for zero-extending.\n \t\t\t\t   In particular, moving it does not make it\n \t\t\t\t   invariant.  */\n@@ -242,7 +241,7 @@ static int labels_in_range_p PARAMS ((rtx, int));\n static void count_one_set PARAMS ((rtx, rtx, varray_type, rtx *));\n \n static void count_loop_regs_set PARAMS ((rtx, rtx, varray_type, varray_type,\n-\t\t\t\t\t int *, int)); \n+\t\t\t\t\t int *, int));\n static void note_addr_stored PARAMS ((rtx, rtx, void *));\n static void note_set_pseudo_multiple_uses PARAMS ((rtx, rtx, void *));\n static int loop_reg_used_before_p PARAMS ((const struct loop *, rtx, rtx));\n@@ -258,7 +257,7 @@ static void combine_movables PARAMS ((struct movable *, int));\n static int regs_match_p PARAMS ((rtx, rtx, struct movable *));\n static int rtx_equal_for_loop_p PARAMS ((rtx, rtx, struct movable *));\n static void add_label_notes PARAMS ((rtx, rtx));\n-static void move_movables PARAMS ((struct loop *loop, struct movable *, \n+static void move_movables PARAMS ((struct loop *loop, struct movable *,\n \t\t\t\t   int, int, int));\n static int count_nonfixed_reads PARAMS ((const struct loop *, rtx));\n static void strength_reduce PARAMS ((struct loop *, int, int));\n@@ -269,11 +268,11 @@ static void record_biv PARAMS ((struct induction *, rtx, rtx, rtx, rtx, rtx *,\n \t\t\t\tint, int));\n static void check_final_value PARAMS ((const struct loop *,\n \t\t\t\t       struct induction *));\n-static void record_giv PARAMS ((const struct loop *, struct induction *, \n-\t\t\t\trtx, rtx, rtx, rtx, rtx, int, enum g_types, \n+static void record_giv PARAMS ((const struct loop *, struct induction *,\n+\t\t\t\trtx, rtx, rtx, rtx, rtx, int, enum g_types,\n \t\t\t\tint, int, rtx *));\n static void update_giv_derive PARAMS ((const struct loop *, rtx));\n-static int basic_induction_var PARAMS ((const struct loop *, rtx, \n+static int basic_induction_var PARAMS ((const struct loop *, rtx,\n \t\t\t\t\tenum machine_mode, rtx, rtx,\n \t\t\t\t\trtx *, rtx *, rtx **));\n static rtx simplify_giv_expr PARAMS ((const struct loop *, rtx, int *));\n@@ -293,7 +292,7 @@ static void recombine_givs PARAMS ((const struct loop *, struct iv_class *,\n static int product_cheap_p PARAMS ((rtx, rtx));\n static int maybe_eliminate_biv PARAMS ((const struct loop *, struct iv_class *,\n \t\t\t\t\tint, int, int));\n-static int maybe_eliminate_biv_1 PARAMS ((const struct loop *, rtx, rtx, \n+static int maybe_eliminate_biv_1 PARAMS ((const struct loop *, rtx, rtx,\n \t\t\t\t\t  struct iv_class *, int, rtx));\n static int last_use_this_basic_block PARAMS ((rtx, rtx));\n static void record_initial PARAMS ((rtx, rtx, void *));\n@@ -352,7 +351,6 @@ static int copy_cost;\n /* Cost of using a register, to normalize the benefits of a giv.  */\n static int reg_address_cost;\n \n-\n void\n init_loop ()\n {\n@@ -455,7 +453,7 @@ loop_optimize (f, dumpfile, flags)\n   max_uid_for_loop = get_max_uid () + 1 + max_loop_num * 32;\n \n   uid_luid = (int *) xcalloc (max_uid_for_loop, sizeof (int));\n-  uid_loop = (struct loop **) xcalloc (max_uid_for_loop, \n+  uid_loop = (struct loop **) xcalloc (max_uid_for_loop,\n \t\t\t\t       sizeof (struct loop *));\n \n   /* Allocate storage for array of loops.  */\n@@ -634,7 +632,7 @@ scan_loop (loop, flags)\n      Note that if we mistakenly think that a loop is entered at the top\n      when, in fact, it is entered at the exit test, the only effect will be\n      slightly poorer optimization.  Making the opposite error can generate\n-     incorrect code.  Since very few loops now start with a jump to the \n+     incorrect code.  Since very few loops now start with a jump to the\n      exit test, the code here to detect that case is very conservative.  */\n \n   for (p = NEXT_INSN (loop_start);\n@@ -679,7 +677,7 @@ scan_loop (loop, flags)\n \n   /* If LOOP->SCAN_START was an insn created by loop, we don't know its luid\n      as required by loop_reg_used_before_p.  So skip such loops.  (This\n-     test may never be true, but it's best to play it safe.) \n+     test may never be true, but it's best to play it safe.)\n \n      Also, skip loops where we do not start scanning at a label.  This\n      test also rejects loops starting with a JUMP_INSN that failed the\n@@ -697,7 +695,7 @@ scan_loop (loop, flags)\n   /* Count number of times each reg is set during this loop.\n      Set VARRAY_CHAR (may_not_optimize, I) if it is not safe to move out\n      the setting of register I.  Set VARRAY_RTX (reg_single_usage, I).  */\n-  \n+\n   /* Allocate extra space for REGS that might be created by\n      load_mems.  We allocate a little extra slop as well, in the hopes\n      that even after the moving of movables creates some new registers\n@@ -726,7 +724,7 @@ scan_loop (loop, flags)\n       VARRAY_CHAR (may_not_optimize, i) = 1;\n #endif\n \n-  bcopy ((char *) &set_in_loop->data, \n+  bcopy ((char *) &set_in_loop->data,\n \t (char *) &n_times_set->data, nregs * sizeof (int));\n \n   if (loop_dump_stream)\n@@ -751,7 +749,7 @@ scan_loop (loop, flags)\n      When MAYBE_NEVER is 0, all insns will be executed at least once\n      so that is not a problem.  */\n \n-  for (p = next_insn_in_loop (loop, loop->scan_start); \n+  for (p = next_insn_in_loop (loop, loop->scan_start);\n        p != NULL_RTX;\n        p = next_insn_in_loop (loop, p))\n     {\n@@ -782,7 +780,7 @@ scan_loop (loop, flags)\n \t  temp = find_reg_note (p, REG_EQUIV, NULL_RTX);\n \t  if (temp)\n \t    src = XEXP (temp, 0), move_insn = 1;\n-\t  else \n+\t  else\n \t    {\n \t      temp = find_reg_note (p, REG_EQUAL, NULL_RTX);\n \t      if (temp && CONSTANT_P (XEXP (temp, 0)))\n@@ -809,7 +807,7 @@ scan_loop (loop, flags)\n \t\t   ! reg_in_basic_block_p (p, SET_DEST (set))\n \t\t   /* And the set is not guaranteed to be executed one\n \t\t      the loop starts, or the value before the set is\n-\t\t      needed before the set occurs... \n+\t\t      needed before the set occurs...\n \n \t\t      ??? Note we have quadratic behaviour here, mitigated\n \t\t      by the fact that the previous test will often fail for\n@@ -818,7 +816,7 @@ scan_loop (loop, flags)\n \t\t      of the register usage and use them here instead.  */\n \t\t   && (maybe_never\n \t\t       || loop_reg_used_before_p (loop, set, p)))\n-\t    /* It is unsafe to move the set.  \n+\t    /* It is unsafe to move the set.\n \n \t       This code used to consider it OK to move a set of a variable\n \t       which was not created by the user and not used in an exit test.\n@@ -827,10 +825,10 @@ scan_loop (loop, flags)\n \t  else if ((tem = loop_invariant_p (loop, src))\n \t\t   && (dependencies == 0\n \t\t       || (tem2 = loop_invariant_p (loop, dependencies)) != 0)\n-\t\t   && (VARRAY_INT (set_in_loop, \n+\t\t   && (VARRAY_INT (set_in_loop,\n \t\t\t\t   REGNO (SET_DEST (set))) == 1\n \t\t       || (tem1\n-\t\t\t   = consec_sets_invariant_p \n+\t\t\t   = consec_sets_invariant_p\n \t\t\t   (loop, SET_DEST (set),\n \t\t\t    VARRAY_INT (set_in_loop, REGNO (SET_DEST (set))),\n \t\t\t    p)))\n@@ -849,12 +847,12 @@ scan_loop (loop, flags)\n \t\t can be combined as long as they are both in the loop, but\n \t\t we move one of them outside the loop.  For large loops,\n \t\t this can lose.  The most common case of this is the address\n-\t\t of a function being called.  \n+\t\t of a function being called.\n \n \t\t Therefore, if this register is marked as being used exactly\n \t\t once if we are in a loop with calls (a \"large loop\"), see if\n \t\t we can replace the usage of this register with the source\n-\t\t of this SET.  If we can, delete this insn. \n+\t\t of this SET.  If we can, delete this insn.\n \n \t\t Don't do this if P has a REG_RETVAL note or if we have\n \t\t SMALL_REGISTER_CLASSES and SET_SRC is a hard register.  */\n@@ -876,20 +874,20 @@ scan_loop (loop, flags)\n \t\t     might span a call.  */\n \t\t  && ! modified_between_p (SET_SRC (set), p,\n \t\t\t\t\t   VARRAY_RTX\n-\t\t\t\t\t   (reg_single_usage, regno)) \n+\t\t\t\t\t   (reg_single_usage, regno))\n \t\t  && no_labels_between_p (p, VARRAY_RTX (reg_single_usage, regno))\n \t\t  && validate_replace_rtx (SET_DEST (set), SET_SRC (set),\n \t\t\t\t\t   VARRAY_RTX\n-\t\t\t\t\t   (reg_single_usage, regno))) \n+\t\t\t\t\t   (reg_single_usage, regno)))\n \t\t{\n \t\t  /* Replace any usage in a REG_EQUAL note.  Must copy the\n \t\t     new source, so that we don't get rtx sharing between the\n \t\t     SET_SOURCE and REG_NOTES of insn p.  */\n \t\t  REG_NOTES (VARRAY_RTX (reg_single_usage, regno))\n \t\t    = replace_rtx (REG_NOTES (VARRAY_RTX\n-\t\t\t\t\t      (reg_single_usage, regno)), \n+\t\t\t\t\t      (reg_single_usage, regno)),\n \t\t\t\t   SET_DEST (set), copy_rtx (SET_SRC (set)));\n-\t\t\t\t   \n+\n \t\t  PUT_CODE (p, NOTE);\n \t\t  NOTE_LINE_NUMBER (p) = NOTE_INSN_DELETED;\n \t\t  NOTE_SOURCE_FILE (p) = 0;\n@@ -904,7 +902,7 @@ scan_loop (loop, flags)\n \t      m->dependencies = dependencies;\n \t      m->set_dest = SET_DEST (set);\n \t      m->force = 0;\n-\t      m->consec = VARRAY_INT (set_in_loop, \n+\t      m->consec = VARRAY_INT (set_in_loop,\n \t\t\t\t      REGNO (SET_DEST (set))) - 1;\n \t      m->done = 0;\n \t      m->forces = 0;\n@@ -918,7 +916,7 @@ scan_loop (loop, flags)\n \t\t or consec_sets_invariant_p returned 2\n \t\t (only conditionally invariant).  */\n \t      m->cond = ((tem | tem1 | tem2) > 1);\n-\t      m->global = (uid_luid[REGNO_LAST_UID (regno)] \n+\t      m->global = (uid_luid[REGNO_LAST_UID (regno)]\n \t\t\t   > INSN_LUID (loop_end)\n \t\t\t   || uid_luid[REGNO_FIRST_UID (regno)] < INSN_LUID (loop_start));\n \t      m->match = 0;\n@@ -1099,7 +1097,7 @@ scan_loop (loop, flags)\n      all together as the priority of the first.  */\n \n   combine_movables (movables, nregs);\n-\t\n+\n   /* Now consider each movable insn to decide whether it is worth moving.\n      Store 0 in set_in_loop for each reg that is moved.\n \n@@ -1182,7 +1180,7 @@ record_excess_regs (in_this, not_in_this, output)\n \t  && ! reg_mentioned_p (in_this, not_in_this))\n \t*output = gen_rtx_EXPR_LIST (VOIDmode, in_this, *output);\n       return;\n-      \n+\n     default:\n       break;\n     }\n@@ -1236,7 +1234,7 @@ libcall_other_reg (insn, equiv)\n /* Return 1 if all uses of REG\n    are between INSN and the end of the basic block.  */\n \n-static int \n+static int\n reg_in_basic_block_p (insn, reg)\n      rtx insn, reg;\n {\n@@ -1272,7 +1270,7 @@ reg_in_basic_block_p (insn, reg)\n \tcase BARRIER:\n \t  /* It's the end of the basic block, so we lose.  */\n \t  return 0;\n-\t  \n+\n \tdefault:\n \t  break;\n \t}\n@@ -1324,13 +1322,14 @@ skip_consec_insns (insn, count)\n       rtx temp;\n \n       /* If first insn of libcall sequence, skip to end.  */\n-      /* Do this at start of loop, since INSN is guaranteed to \n+      /* Do this at start of loop, since INSN is guaranteed to\n \t be an insn here.  */\n       if (GET_CODE (insn) != NOTE\n \t  && (temp = find_reg_note (insn, REG_LIBCALL, NULL_RTX)))\n \tinsn = XEXP (temp, 0);\n \n-      do insn = NEXT_INSN (insn);\n+      do\n+\tinsn = NEXT_INSN (insn);\n       while (GET_CODE (insn) == NOTE);\n     }\n \n@@ -1367,7 +1366,7 @@ ignore_some_movables (movables)\n \t\tm1->done = 1;\n \t}\n     }\n-}\t  \n+}\n \n /* For each movable insn, see if the reg that it loads\n    leads when it dies right into another conditionally movable insn.\n@@ -1427,7 +1426,8 @@ combine_movables (movables, nregs)\n   /* Perhaps testing m->consec_sets would be more appropriate here?  */\n \n   for (m = movables; m; m = m->next)\n-    if (m->match == 0 && VARRAY_INT (n_times_set, m->regno) == 1 && !m->partial)\n+    if (m->match == 0 && VARRAY_INT (n_times_set, m->regno) == 1\n+\t&& !m->partial)\n       {\n \tregister struct movable *m1;\n \tint regno = m->regno;\n@@ -1497,13 +1497,13 @@ combine_movables (movables, nregs)\n \t      {\n \t\t/* First one: don't check for overlap, just record it.  */\n \t\tm0 = m;\n-\t\t  continue;\n+\t\tcontinue;\n \t      }\n \n \t    /* Make sure they extend to the same mode.\n \t       (Almost always true.)  */\n \t    if (GET_MODE (m->set_dest) != GET_MODE (m0->set_dest))\n-\t\tcontinue;\n+\t      continue;\n \n \t    /* We already have one: check for overlap with those\n \t       already combined together.  */\n@@ -1519,7 +1519,8 @@ combine_movables (movables, nregs)\n \t    m->done = 1;\n \t    m->match = m0;\n \n-\t  overlap: ;\n+\t  overlap:\n+\t    ;\n \t  }\n     }\n \n@@ -1914,7 +1915,7 @@ move_movables (loop, movables, threshold, insn_count, nregs)\n \t\t      rtx i1, temp;\n \n \t\t      /* If first insn of libcall sequence, skip to end.  */\n-\t\t      /* Do this at start of loop, since p is guaranteed to \n+\t\t      /* Do this at start of loop, since p is guaranteed to\n \t\t\t be an insn here.  */\n \t\t      if (GET_CODE (p) != NOTE\n \t\t\t  && (temp = find_reg_note (p, REG_LIBCALL, NULL_RTX)))\n@@ -1951,7 +1952,7 @@ move_movables (loop, movables, threshold, insn_count, nregs)\n \t\t\t\t       && GET_CODE (PATTERN (next)) == USE)\n \t\t\t\t    && GET_CODE (next) != NOTE)\n \t\t\t\t  break;\n-\t\t\t      \n+\n \t\t\t      /* If that is the call, this may be the insn\n \t\t\t\t that loads the function address.\n \n@@ -2015,7 +2016,7 @@ move_movables (loop, movables, threshold, insn_count, nregs)\n \t\t\t  rtx reg = m->set_dest;\n \t\t\t  rtx sequence;\n \t\t\t  rtx tem;\n-\t\t      \n+\n \t\t\t  start_sequence ();\n \t\t\t  tem = expand_binop\n \t\t\t    (GET_MODE (reg), and_optab, reg,\n@@ -2071,7 +2072,7 @@ move_movables (loop, movables, threshold, insn_count, nregs)\n \t\t\t     may cause problems with later optimization passes.\n \t\t\t     It is possible for cse to create such notes\n \t\t\t     like this as a result of record_jump_cond.  */\n-\t\t      \n+\n \t\t\t  if ((temp = find_reg_note (i1, REG_EQUAL, NULL_RTX))\n \t\t\t      && ! loop_invariant_p (loop, XEXP (temp, 0)))\n \t\t\t    remove_note (i1, temp);\n@@ -2162,7 +2163,7 @@ move_movables (loop, movables, threshold, insn_count, nregs)\n \t\t\treg_map[m1->regno]\n \t\t\t  = gen_lowpart_common (GET_MODE (m1->set_dest),\n \t\t\t\t\t\tm->set_dest);\n-\t\t    \n+\n \t\t      /* Get rid of the matching insn\n \t\t\t and prevent further processing of it.  */\n \t\t      m1->done = 1;\n@@ -2261,7 +2262,7 @@ replace_call_address (x, reg, addr)\n \tabort ();\n       XEXP (x, 0) = addr;\n       return;\n-      \n+\n     default:\n       break;\n     }\n@@ -2313,7 +2314,7 @@ count_nonfixed_reads (loop, x)\n     case MEM:\n       return ((loop_invariant_p (loop, XEXP (x, 0)) != 1)\n \t      + count_nonfixed_reads (loop, XEXP (x, 0)));\n-      \n+\n     default:\n       break;\n     }\n@@ -2333,7 +2334,6 @@ count_nonfixed_reads (loop, x)\n     }\n   return value;\n }\n-\n \f\n #if 0\n /* P is an instruction that sets a register to the result of a ZERO_EXTEND.\n@@ -2467,7 +2467,7 @@ prescan_loop (loop)\n \t      && (GET_CODE (PATTERN (insn)) == ADDR_DIFF_VEC\n \t\t  || GET_CODE (PATTERN (insn)) == ADDR_VEC))\n \t    loop_info->has_tablejump = 1;\n-\t  \n+\n \t  note_stores (PATTERN (insn), note_addr_stored, NULL);\n \t  if (! first_loop_store_insn && loop_store_mems)\n \t    first_loop_store_insn = insn;\n@@ -2487,27 +2487,29 @@ prescan_loop (loop)\n \t\t  label1 = SET_SRC (PATTERN (insn));\n \t\t}\n \n-\t      do {\n-\t\tif (label1 && label1 != pc_rtx)\n-\t\t  {\n-\t\t    if (GET_CODE (label1) != LABEL_REF)\n-\t\t      {\n-\t\t\t/* Something tricky.  */\n-\t\t\tloop_info->has_multiple_exit_targets = 1;\n-\t\t\tbreak;\n-\t\t      }\n-\t\t    else if (XEXP (label1, 0) != exit_target\n-\t\t\t     && LABEL_OUTSIDE_LOOP_P (label1))\n-\t\t      {\n-\t\t\t/* A jump outside the current loop.  */\n-\t\t\tloop_info->has_multiple_exit_targets = 1;\n-\t\t\tbreak;\n-\t\t      }\n-\t\t  }\n+\t      do\n+\t\t{\n+\t\t  if (label1 && label1 != pc_rtx)\n+\t\t    {\n+\t\t      if (GET_CODE (label1) != LABEL_REF)\n+\t\t\t{\n+\t\t\t  /* Something tricky.  */\n+\t\t\t  loop_info->has_multiple_exit_targets = 1;\n+\t\t\t  break;\n+\t\t\t}\n+\t\t      else if (XEXP (label1, 0) != exit_target\n+\t\t\t       && LABEL_OUTSIDE_LOOP_P (label1))\n+\t\t\t{\n+\t\t\t  /* A jump outside the current loop.  */\n+\t\t\t  loop_info->has_multiple_exit_targets = 1;\n+\t\t\t  break;\n+\t\t\t}\n+\t\t    }\n \n-\t\tlabel1 = label2;\n-\t\tlabel2 = NULL_RTX;\n-\t      } while (label1);\n+\t\t  label1 = label2;\n+\t\t  label2 = NULL_RTX;\n+\t\t}\n+\t      while (label1);\n \t    }\n \t}\n       else if (GET_CODE (insn) == RETURN)\n@@ -2516,7 +2518,7 @@ prescan_loop (loop)\n \n   /* Now, rescan the loop, setting up the LOOP_MEMS array.  */\n   if (/* We can't tell what MEMs are aliased by what.  */\n-      ! unknown_address_altered \n+      ! unknown_address_altered\n       /* An exception thrown by a called function might land us\n \t anywhere.  */\n       && ! loop_info->has_call\n@@ -2729,7 +2731,7 @@ find_and_verify_loops (f, loops)\n      anywhere.\n \n      Also look for blocks of code ending in an unconditional branch that\n-     exits the loop.  If such a block is surrounded by a conditional \n+     exits the loop.  If such a block is surrounded by a conditional\n      branch around the block, move the block elsewhere (see below) and\n      invert the jump to point to the code block.  This may eliminate a\n      label in our loop and will simplify processing by both us and a\n@@ -2821,7 +2823,7 @@ find_and_verify_loops (f, loops)\n \t\t&& next_real_insn (JUMP_LABEL (p)) == our_next\n \t\t/* If it's not safe to move the sequence, then we\n \t\t   mustn't try.  */\n-\t\t&& insns_safe_to_move_p (p, NEXT_INSN (insn), \n+\t\t&& insns_safe_to_move_p (p, NEXT_INSN (insn),\n \t\t\t\t\t &last_insn_to_move))\n \t      {\n \t\trtx target\n@@ -2891,12 +2893,12 @@ find_and_verify_loops (f, loops)\n \n \t\t\t/* Include the BARRIER after INSN and copy the\n \t\t\t   block after LOC.  */\n-\t\t\tnew_label = squeeze_notes (new_label, \n+\t\t\tnew_label = squeeze_notes (new_label,\n \t\t\t\t\t\t   last_insn_to_move);\n \t\t\treorder_insns (new_label, last_insn_to_move, loc);\n \n \t\t\t/* All those insns are now in TARGET_LOOP.  */\n-\t\t\tfor (q = new_label; \n+\t\t\tfor (q = new_label;\n \t\t\t     q != NEXT_INSN (last_insn_to_move);\n \t\t\t     q = NEXT_INSN (q))\n \t\t\t  uid_loop[INSN_UID (q)] = target_loop;\n@@ -3063,7 +3065,7 @@ mark_loop_jump (x, loop)\n \t    fprintf (loop_dump_stream,\n \t\t     \"\\nLoop at %d ignored due to multiple entry points.\\n\",\n \t\t     INSN_UID (dest_loop->start));\n-\t  \n+\n \t  dest_loop->invalid = 1;\n \t}\n       return;\n@@ -3269,7 +3271,7 @@ loop_invariant_p (loop, x)\n       /* If we had a subroutine call, any location in memory could\n \t have been clobbered.  We used to test here for volatile and\n \t readonly, but true_dependence knows how to do that better\n-\t than we do. */\n+\t than we do.  */\n       if (RTX_UNCHANGING_P (x)\n \t  ? unknown_constant_address_altered : unknown_address_altered)\n \treturn 0;\n@@ -3294,7 +3296,7 @@ loop_invariant_p (loop, x)\n       if (MEM_VOLATILE_P (x))\n \treturn 0;\n       break;\n-      \n+\n     default:\n       break;\n     }\n@@ -3327,7 +3329,6 @@ loop_invariant_p (loop, x)\n \n   return 1 + conditional;\n }\n-\n \f\n /* Return nonzero if all the insns in the loop that set REG\n    are INSN and the immediately following insns,\n@@ -3456,15 +3457,15 @@ find_single_use_in_loop (insn, x, usage)\n \n   if (code == REG)\n     VARRAY_RTX (usage, REGNO (x))\n-      = (VARRAY_RTX (usage, REGNO (x)) != 0 \n+      = (VARRAY_RTX (usage, REGNO (x)) != 0\n \t && VARRAY_RTX (usage, REGNO (x)) != insn)\n \t? const0_rtx : insn;\n \n   else if (code == SET)\n     {\n       /* Don't count SET_DEST if it is a REG; otherwise count things\n \t in SET_DEST because if a register is partially modified, it won't\n-\t show up as a potential movable so we don't care how USAGE is set \n+\t show up as a potential movable so we don't care how USAGE is set\n \t for it.  */\n       if (GET_CODE (SET_DEST (x)) != REG)\n \tfind_single_use_in_loop (insn, SET_DEST (x), usage);\n@@ -3510,7 +3511,7 @@ count_one_set (insn, x, may_not_move, last_set)\n \t     in current basic block, and it was set before,\n \t     it must be set in two basic blocks, so it cannot\n \t     be moved out of the loop.  */\n-\t  if (VARRAY_INT (set_in_loop, regno) > 0 \n+\t  if (VARRAY_INT (set_in_loop, regno) > 0\n \t      && last_set[regno] == 0)\n \t    VARRAY_CHAR (may_not_move, regno) = 1;\n \t  /* If this is not first setting in current basic block,\n@@ -3693,7 +3694,7 @@ static rtx addr_placeholder;\n /* Scan the loop body and call FNCALL for each insn.  In the addition to the\n    LOOP and INSN parameters pass MAYBE_MULTIPLE and NOT_EVERY_ITERATION to the\n    callback.\n- \n+\n    NOT_EVERY_ITERATION if current insn is not executed at least once for every\n    loop iteration except for the last one.\n \n@@ -3843,7 +3844,7 @@ for_each_insn_in_loop (loop, fncall)\n     }\n }\n \f\n-/* Perform strength reduction and induction variable elimination.  \n+/* Perform strength reduction and induction variable elimination.\n \n    Pseudo registers created during this function will be beyond the last\n    valid index in several tables including n_times_set and regno_last_uid.\n@@ -3889,9 +3890,9 @@ strength_reduce (loop, insn_count, flags)\n \n   /* Save insn immediately after the loop_end.  Insns inserted after loop_end\n      must be put before this insn, so that they will appear in the right\n-     order (i.e. loop order). \n+     order (i.e. loop order).\n \n-     If loop_end is the end of the current function, then emit a \n+     If loop_end is the end of the current function, then emit a\n      NOTE_INSN_DELETED after loop_end and set end_insert_before to the\n      dummy note insn.  */\n   if (NEXT_INSN (loop_end) != 0)\n@@ -3920,7 +3921,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t      ? \"not induction variable\"\n \t\t      : (! bl->incremented ? \"never incremented\"\n \t\t\t : \"count error\")));\n-\t  \n+\n \t  REG_IV_TYPE (bl->regno) = NOT_BASIC_INDUCT;\n \t  *backbl = bl->next;\n \t}\n@@ -4053,7 +4054,7 @@ strength_reduce (loop, insn_count, flags)\n \t\tif (bl2->regno == regno)\n \t\t  break;\n \t    }\n-\t\n+\n \t  /* Now, can we transform this biv into a giv?  */\n \t  if (bl2\n \t      && bl2->biv_count == 1\n@@ -4099,7 +4100,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t  rtx p;\n \t\t  rtx next;\n \n-\t\t  for (next = NEXT_INSN (dominator); ; next = NEXT_INSN (next))\n+\t\t  for (next = NEXT_INSN (dominator);; next = NEXT_INSN (next))\n \t\t    {\n \t\t      if (GET_CODE (next) == JUMP_INSN\n \t\t\t  || (INSN_P (next)\n@@ -4116,7 +4117,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t  /* Avoid problems with luids by actually moving the insn\n \t\t     and adjusting all luids in the range.  */\n \t\t  reorder_insns (giv_insn, giv_insn, dominator);\n-\t\t  for (p = dominator; INSN_UID (p) >= max_uid_for_loop; )\n+\t\t  for (p = dominator; INSN_UID (p) >= max_uid_for_loop;)\n \t\t    p = PREV_INSN (p);\n \t\t  compute_luids (giv_insn, after_giv, INSN_LUID (p));\n \t\t  /* If the only purpose of the init insn is to initialize\n@@ -4230,7 +4231,7 @@ strength_reduce (loop, insn_count, flags)\n \t      add_val = plus_constant (next->add_val, offset);\n \t      old_reg = v->dest_reg;\n \t      dest_reg = gen_reg_rtx (v->mode);\n-    \n+\n \t      /* Unlike reg_iv_type / reg_iv_info, the other three arrays\n \t\t have been allocated with some slop space, so we may not\n \t\t actually need to reallocate them.  If we do, the following\n@@ -4243,7 +4244,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t  VARRAY_GROW (may_not_optimize, nregs);\n \t\t  VARRAY_GROW (reg_single_usage, nregs);\n \t\t}\n-    \n+\n \t      /* Some bivs are incremented with a multi-insn sequence.\n \t\t The first insn contains the add.  */\n \t      next_loc_insn = next->insn;\n@@ -4313,15 +4314,15 @@ strength_reduce (loop, insn_count, flags)\n \t      v->always_executed = 1;\n \t      v->replaceable = 1;\n \t      v->no_const_addval = 0;\n-    \n+\n \t      old_regno = REGNO (old_reg);\n \t      new_regno = REGNO (dest_reg);\n \t      VARRAY_INT (set_in_loop, old_regno)--;\n \t      VARRAY_INT (set_in_loop, new_regno) = 1;\n \t      VARRAY_INT (n_times_set, old_regno)--;\n \t      VARRAY_INT (n_times_set, new_regno) = 1;\n \t      VARRAY_CHAR (may_not_optimize, new_regno) = 0;\n-    \n+\n \t      REG_IV_TYPE (new_regno) = GENERAL_INDUCT;\n \t      REG_IV_INFO (new_regno) = v;\n \n@@ -4340,7 +4341,7 @@ strength_reduce (loop, insn_count, flags)\n \t      bl->giv_count++;\n \t      v->benefit = rtx_cost (SET_SRC (set), SET);\n \t      bl->total_benefit += v->benefit;\n-    \n+\n \t      /* Now replace the biv with DEST_REG in all insns between\n \t\t the replaced increment and the next increment, and\n \t\t remember the last insn that needed a replacement.  */\n@@ -4349,7 +4350,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t   p = next_insn_in_loop (loop, p))\n \t\t{\n \t\t  rtx note;\n-    \n+\n \t\t  if (! INSN_P (p))\n \t\t    continue;\n \t\t  if (reg_mentioned_p (old_reg, PATTERN (p)))\n@@ -4365,7 +4366,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t\t  = replace_rtx (XEXP (note, 0), old_reg, dest_reg);\n \t\t    }\n \t\t}\n-    \n+\n \t      v->last_use = last_use_insn;\n \t      v->lifetime = INSN_LUID (last_use_insn) - INSN_LUID (v->insn);\n \t      /* If the lifetime is zero, it means that this register is really\n@@ -4459,7 +4460,7 @@ strength_reduce (loop, insn_count, flags)\n \t      && ! bl->nonneg\n #endif\n \t      ))\n-\tbl->eliminable = maybe_eliminate_biv (loop, bl, 0, threshold, \n+\tbl->eliminable = maybe_eliminate_biv (loop, bl, 0, threshold,\n \t\t\t\t\t      insn_count);\n       else\n \t{\n@@ -4788,7 +4789,7 @@ strength_reduce (loop, insn_count, flags)\n \n       /* Rescan all givs.  If a giv is the same as a giv not reduced, mark it\n \t as not reduced.\n-\t \n+\n \t For each giv register that can be reduced now: if replaceable,\n \t substitute reduced reg wherever the old giv occurs;\n \t else add new move insn \"giv_reg = reduced_reg\".  */\n@@ -4912,11 +4913,11 @@ strength_reduce (loop, insn_count, flags)\n \n \t We have to be careful that we didn't initially think we could eliminate\n \t this biv because of a giv that we now think may be dead and shouldn't\n-\t be used as a biv replacement.  \n+\t be used as a biv replacement.\n \n \t Also, there is the possibility that we may have a giv that looks\n \t like it can be used to eliminate a biv, but the resulting insn\n-\t isn't valid.  This can happen, for example, on the 88k, where a \n+\t isn't valid.  This can happen, for example, on the 88k, where a\n \t JUMP_INSN can compare a register only with zero.  Attempts to\n \t replace it with a compare with a constant will fail.\n \n@@ -4980,7 +4981,7 @@ strength_reduce (loop, insn_count, flags)\n \n   for (p = loop_start; p != loop_end; p = NEXT_INSN (p))\n     if (GET_CODE (p) == INSN || GET_CODE (p) == JUMP_INSN\n- \t|| GET_CODE (p) == CALL_INSN)\n+\t|| GET_CODE (p) == CALL_INSN)\n       {\n \treplace_regs (PATTERN (p), reg_map, reg_map_size, 0);\n \treplace_regs (REG_NOTES (p), reg_map, reg_map_size, 0);\n@@ -5013,7 +5014,7 @@ strength_reduce (loop, insn_count, flags)\n       if (unrolled_insn_copies < 0)\n \tunrolled_insn_copies = 0;\n     }\n-  \n+\n   /* Unroll loops from within strength reduction so that we can use the\n      induction variable information that strength_reduce has already\n      collected.  Always unroll loops that would be as small or smaller\n@@ -5071,7 +5072,7 @@ check_insn_for_bivs (loop, p, not_every_iteration, maybe_multiple)\n \t         Create and initialize an induction structure for it.  */\n \n \t      struct induction *v\n-\t      = (struct induction *) oballoc (sizeof (struct induction));\n+\t\t= (struct induction *) oballoc (sizeof (struct induction));\n \n \t      record_biv (v, p, dest_reg, inc_val, mult_val, location,\n \t\t\t  not_every_iteration, maybe_multiple);\n@@ -5084,7 +5085,7 @@ check_insn_for_bivs (loop, p, not_every_iteration, maybe_multiple)\n   return p;\n }\n \f\n-/* Record all givs calculated in the insn.  \n+/* Record all givs calculated in the insn.\n    A register is a giv if: it is only set once, it is a function of a\n    biv and a constant (or invariant), and it is not a biv.  */\n static rtx\n@@ -5164,7 +5165,7 @@ check_insn_for_givs (loop, p, not_every_iteration, maybe_multiple)\n   /* Update the status of whether giv can derive other givs.  This can\n      change when we pass a label or an insn that updates a biv.  */\n   if (GET_CODE (p) == INSN || GET_CODE (p) == JUMP_INSN\n-    || GET_CODE (p) == CODE_LABEL)\n+      || GET_CODE (p) == CODE_LABEL)\n     update_giv_derive (loop, p);\n   return p;\n }\n@@ -5253,7 +5254,7 @@ find_mem_givs (loop, x, insn, not_every_iteration, maybe_multiple)\n \tint benefit;\n \n \t/* This code used to disable creating GIVs with mult_val == 1 and\n-\t   add_val == 0.  However, this leads to lost optimizations when \n+\t   add_val == 0.  However, this leads to lost optimizations when\n \t   it comes time to combine a set of related DEST_ADDR GIVs, since\n \t   this one would not be seen.   */\n \n@@ -5525,17 +5526,17 @@ record_giv (loop, v, insn, src_reg, dest_reg, mult_val, add_val, benefit,\n \n       if (REGNO_FIRST_UID (REGNO (dest_reg)) == INSN_UID (insn)\n \t  /* Previous line always fails if INSN was moved by loop opt.  */\n-\t  && uid_luid[REGNO_LAST_UID (REGNO (dest_reg))] \n+\t  && uid_luid[REGNO_LAST_UID (REGNO (dest_reg))]\n \t  < INSN_LUID (loop->end)\n \t  && (! not_every_iteration\n \t      || last_use_this_basic_block (dest_reg, insn)))\n- \t{\n+\t{\n \t  /* Now check that there are no assignments to the biv within the\n \t     giv's lifetime.  This requires two separate checks.  */\n \n \t  /* Check each biv update, and fail if any are between the first\n \t     and last use of the giv.\n-\t     \n+\n \t     If this loop contains an inner loop that was unrolled, then\n \t     the insn modifying the biv may have been emitted by the loop\n \t     unrolling code, and hence does not have a valid luid.  Just\n@@ -5556,7 +5557,7 @@ record_giv (loop, v, insn, src_reg, dest_reg, mult_val, add_val, benefit,\n \t\t  v->replaceable = 0;\n \t\t  v->not_replaceable = 1;\n \t\t  break;\n- \t\t}\n+\t\t}\n \t    }\n \n \t  /* If there are any backwards branches that go from after the\n@@ -5653,7 +5654,6 @@ record_giv (loop, v, insn, src_reg, dest_reg, mult_val, add_val, benefit,\n \n }\n \n-\n /* All this does is determine whether a giv can be made replaceable because\n    its final value can be calculated.  This code can not be part of record_giv\n    above, because final_giv_value requires that the number of loop iterations\n@@ -5745,7 +5745,7 @@ check_final_value (loop, v)\n \t\tlast_giv_use = p;\n \t    }\n \t}\n-      \n+\n       /* Now that the lifetime of the giv is known, check for branches\n \t from within the lifetime to outside the lifetime if it is still\n \t replaceable.  */\n@@ -5803,7 +5803,7 @@ check_final_value (loop, v)\n \n static void\n update_giv_derive (loop, p)\n-     const  struct loop *loop;\n+     const struct loop *loop;\n      rtx p;\n {\n   struct iv_class *bl;\n@@ -5925,7 +5925,7 @@ update_giv_derive (loop, p)\n    Note that treating the entire pseudo as a BIV will result in making\n    simple increments to any GIVs based on it.  However, if the variable\n    overflows in its declared mode but not its promoted mode, the result will\n-   be incorrect.  This is acceptable if the variable is signed, since \n+   be incorrect.  This is acceptable if the variable is signed, since\n    overflows in such cases are undefined, but not if it is unsigned, since\n    those overflows are defined.  So we only check for SIGN_EXTEND and\n    not ZERO_EXTEND.\n@@ -5967,7 +5967,7 @@ basic_induction_var (loop, x, mode, dest_reg, p, inc_val, mult_val, location)\n \t  argp = &XEXP (x, 0);\n \t}\n       else\n- \treturn 0;\n+\treturn 0;\n \n       arg = *argp;\n       if (loop_invariant_p (loop, arg) != 1)\n@@ -5999,12 +5999,14 @@ basic_induction_var (loop, x, mode, dest_reg, p, inc_val, mult_val, location)\n       insn = p;\n       while (1)\n \t{\n-\t  do {\n-\t    insn = PREV_INSN (insn);\n-\t  } while (insn && GET_CODE (insn) == NOTE\n-\t           && NOTE_LINE_NUMBER (insn) != NOTE_INSN_LOOP_BEG);\n+\t  do\n+\t    {\n+\t      insn = PREV_INSN (insn);\n+\t    }\n+\t  while (insn && GET_CODE (insn) == NOTE\n+\t\t && NOTE_LINE_NUMBER (insn) != NOTE_INSN_LOOP_BEG);\n \n-          if (!insn)\n+\t  if (!insn)\n \t    break;\n \t  set = single_set (insn);\n \t  if (set == 0)\n@@ -6046,11 +6048,11 @@ basic_induction_var (loop, x, mode, dest_reg, p, inc_val, mult_val, location)\n  \t{\n \t  /* Possible bug here?  Perhaps we don't know the mode of X.  */\n \t  *inc_val = convert_modes (GET_MODE (dest_reg), mode, x, 0);\n- \t  *mult_val = const0_rtx;\n- \t  return 1;\n- \t}\n+\t  *mult_val = const0_rtx;\n+\t  return 1;\n+\t}\n       else\n- \treturn 0;\n+\treturn 0;\n \n     case SIGN_EXTEND:\n       return basic_induction_var (loop, XEXP (x, 0), GET_MODE (XEXP (x, 0)),\n@@ -6187,9 +6189,9 @@ general_induction_var (loop, x, src_reg, add_val, mult_val, is_addr,\n     *pbenefit += rtx_cost (orig_x, SET);\n \n   /* Always return true if this is a giv so it will be detected as such,\n-     even if the benefit is zero or negative.  This allows elimination  \n-     of bivs that might otherwise not be eliminated.  */                \n-  return 1;                                                             \n+     even if the benefit is zero or negative.  This allows elimination\n+     of bivs that might otherwise not be eliminated.  */\n+  return 1;\n }\n \f\n /* Given an expression, X, try to form it as a linear function of a biv.\n@@ -6208,7 +6210,7 @@ general_induction_var (loop, x, src_reg, add_val, mult_val, is_addr,\n    returns 0.\n \n    For a non-zero return, the result will have a code of CONST_INT, USE,\n-   REG (for a BIV), PLUS, or MULT.  No other codes will occur.  \n+   REG (for a BIV), PLUS, or MULT.  No other codes will occur.\n \n    *BENEFIT will be incremented by the benefit of any sub-giv encountered.  */\n \n@@ -6505,15 +6507,15 @@ simplify_giv_expr (loop, x, benefit)\n \t    {\n \t      struct movable *m;\n \n-\t      for (m = the_movables; m ; m = m->next)\n+\t      for (m = the_movables; m; m = m->next)\n \t\tif (rtx_equal_p (x, m->set_dest))\n \t\t  {\n \t\t    /* Ok, we found a match.  Substitute and simplify.  */\n \n-\t\t    /* If we match another movable, we must use that, as \n+\t\t    /* If we match another movable, we must use that, as\n \t\t       this one is going away.  */\n \t\t    if (m->match)\n-\t\t      return simplify_giv_expr (loop, m->match->set_dest, \n+\t\t      return simplify_giv_expr (loop, m->match->set_dest,\n \t\t\t\t\t\tbenefit);\n \n \t\t    /* If consec is non-zero, this is a member of a group of\n@@ -6532,8 +6534,8 @@ simplify_giv_expr (loop, x, benefit)\n \t\t      }\n \t\t    else\n \t\t      {\n-\t\t        tem = single_set (m->insn);\n-\t\t        if (tem)\n+\t\t\ttem = single_set (m->insn);\n+\t\t\tif (tem)\n \t\t\t  tem = SET_SRC (tem);\n \t\t      }\n \n@@ -6680,7 +6682,7 @@ consec_sets_giv (loop, first_benefit, p, src_reg, dest_reg,\n   rtx set;\n \n   /* Indicate that this is a giv so that we can update the value produced in\n-     each insn of the multi-insn sequence. \n+     each insn of the multi-insn sequence.\n \n      This induction structure will be used only by the call to\n      general_induction_var below, so we can allocate it on our stack.\n@@ -6752,7 +6754,7 @@ consec_sets_giv (loop, first_benefit, p, src_reg, dest_reg,\n \f\n /* Return an rtx, if any, that expresses giv G2 as a function of the register\n    represented by G1.  If no such expression can be found, or it is clear that\n-   it cannot possibly be a valid address, 0 is returned. \n+   it cannot possibly be a valid address, 0 is returned.\n \n    To perform the computation, we note that\n    \tG1 = x * v + a\t\tand\n@@ -6796,11 +6798,11 @@ express_from_1 (a, b, mult)\n \n       ra = XEXP (a, 0), oa = XEXP (a, 1);\n       if (GET_CODE (ra) == PLUS)\n-        tmp = ra, ra = oa, oa = tmp;\n+\ttmp = ra, ra = oa, oa = tmp;\n \n       rb = XEXP (b, 0), ob = XEXP (b, 1);\n       if (GET_CODE (rb) == PLUS)\n-        tmp = rb, rb = ob, ob = tmp;\n+\ttmp = rb, rb = ob, ob = tmp;\n \n       if (rtx_equal_p (ra, rb))\n \t/* We matched: remove one reg completely.  */\n@@ -6813,7 +6815,7 @@ express_from_1 (a, b, mult)\n \ta = ra, b = ob;\n       else\n \t{\n-          /* Indicates an extra register in B.  Strip one level from B and \n+          /* Indicates an extra register in B.  Strip one level from B and\n \t     recurse, hoping B was the higher order expression.  */\n \t  ob = express_from_1 (a, ob, mult);\n \t  if (ob == NULL_RTX)\n@@ -6876,8 +6878,8 @@ express_from (g1, g2)\n       && GET_CODE (g2->mult_val) == CONST_INT)\n     {\n       if (g1->mult_val == const0_rtx\n-          || INTVAL (g2->mult_val) % INTVAL (g1->mult_val) != 0)\n-        return NULL_RTX;\n+\t  || INTVAL (g2->mult_val) % INTVAL (g1->mult_val) != 0)\n+\treturn NULL_RTX;\n       mult = GEN_INT (INTVAL (g2->mult_val) / INTVAL (g1->mult_val));\n     }\n   else if (rtx_equal_p (g1->mult_val, g2->mult_val))\n@@ -6935,10 +6937,9 @@ express_from (g1, g2)\n \t  mult = gen_rtx_PLUS (g2->mode, mult, XEXP (add, 0));\n \t  add = tem;\n \t}\n-      \n+\n       return gen_rtx_PLUS (g2->mode, mult, add);\n     }\n-  \n }\n \f\n /* Return an rtx, if any, that expresses giv G2 as a function of the register\n@@ -7041,7 +7042,7 @@ combine_givs (bl)\n       giv_array[i++] = g1;\n \n   stats = (struct combine_givs_stats *) xcalloc (giv_count, sizeof (*stats));\n-  can_combine = (rtx *) xcalloc (giv_count, giv_count * sizeof(rtx));\n+  can_combine = (rtx *) xcalloc (giv_count, giv_count * sizeof (rtx));\n \n   for (i = 0; i < giv_count; i++)\n     {\n@@ -7054,7 +7055,7 @@ combine_givs (bl)\n       /* If a DEST_REG GIV is used only once, do not allow it to combine\n \t with anything, for in doing so we will gain nothing that cannot\n \t be had by simply letting the GIV with which we would have combined\n-\t to be reduced on its own.  The losage shows up in particular with \n+\t to be reduced on its own.  The losage shows up in particular with\n \t DEST_ADDR targets on hosts with reg+reg addressing, though it can\n \t be seen elsewhere as well.  */\n       if (g1->giv_type == DEST_REG\n@@ -7075,7 +7076,7 @@ combine_givs (bl)\n \t  if (g1 != g2\n \t      && (this_combine = combine_givs_p (g1, g2)) != NULL_RTX)\n \t    {\n-\t      can_combine[i*giv_count + j] = this_combine;\n+\t      can_combine[i * giv_count + j] = this_combine;\n \t      this_benefit += g2->benefit + extra_benefit;\n \t    }\n \t}\n@@ -7084,7 +7085,7 @@ combine_givs (bl)\n \n   /* Iterate, combining until we can't.  */\n restart:\n-  qsort (stats, giv_count, sizeof(*stats), cmp_combine_givs_stats);\n+  qsort (stats, giv_count, sizeof (*stats), cmp_combine_givs_stats);\n \n   if (loop_dump_stream)\n     {\n@@ -7093,7 +7094,7 @@ combine_givs (bl)\n \t{\n \t  g1 = giv_array[stats[k].giv_number];\n \t  if (!g1->combined_with && !g1->same)\n-\t    fprintf (loop_dump_stream, \" {%d, %d}\", \n+\t    fprintf (loop_dump_stream, \" {%d, %d}\",\n \t\t     INSN_UID (giv_array[stats[k].giv_number]->insn),\n \t\t     stats[k].total_benefit);\n \t}\n@@ -7114,13 +7115,13 @@ combine_givs (bl)\n       for (j = 0; j < giv_count; j++)\n \t{\n \t  g2 = giv_array[j];\n-\t  if (g1 != g2 && can_combine[i*giv_count + j]\n+\t  if (g1 != g2 && can_combine[i * giv_count + j]\n \t      /* If it has already been combined, skip.  */\n \t      && ! g2->same && ! g2->combined_with)\n \t    {\n \t      int l;\n \n-\t      g2->new_reg = can_combine[i*giv_count + j];\n+\t      g2->new_reg = can_combine[i * giv_count + j];\n \t      g2->same = g1;\n \t      g1->combined_with++;\n \t      g1->lifetime += g2->lifetime;\n@@ -7132,13 +7133,13 @@ combine_givs (bl)\n \t\t longer be necessary.  */\n \t      if (! g2->replaceable && REG_USERVAR_P (g2->dest_reg))\n \t\tg1_add_benefit -= copy_cost;\n-\t\t\n+\n \t      /* To help optimize the next set of combinations, remove\n \t\t this giv from the benefits of other potential mates.  */\n \t      for (l = 0; l < giv_count; ++l)\n \t\t{\n \t\t  int m = stats[l].giv_number;\n-\t\t  if (can_combine[m*giv_count + j])\n+\t\t  if (can_combine[m * giv_count + j])\n \t\t    stats[l].total_benefit -= g2->benefit + extra_benefit;\n \t\t}\n \n@@ -7156,14 +7157,14 @@ combine_givs (bl)\n \t  for (j = 0; j < giv_count; ++j)\n \t    {\n \t      int m = stats[j].giv_number;\n-\t      if (can_combine[m*giv_count + i])\n+\t      if (can_combine[m * giv_count + i])\n \t\tstats[j].total_benefit -= g1->benefit + extra_benefit;\n \t    }\n \n \t  g1->benefit += g1_add_benefit;\n \n \t  /* We've finished with this giv, and everything it touched.\n-\t     Restart the combination so that proper weights for the \n+\t     Restart the combination so that proper weights for the\n \t     rest of the givs are properly taken into account.  */\n \t  /* ??? Ideally we would compact the arrays at this point, so\n \t     as to not cover old ground.  But sanely compacting\n@@ -7284,7 +7285,7 @@ find_life_end (x, stats, insn, biv)\n \tretval += find_life_end (XEXP (x, i), stats, insn, biv);\n \n       else if (fmt[i] == 'E')\n-        for (j = XVECLEN (x, i) - 1; j >= 0; j--)\n+\tfor (j = XVECLEN (x, i) - 1; j >= 0; j--)\n \t  retval += find_life_end (XVECEXP (x, i, j), stats, insn, biv);\n     }\n   return retval;\n@@ -7333,7 +7334,7 @@ recombine_givs (loop, bl, unroll_p)\n       i++;\n     }\n \n-  qsort (stats, giv_count, sizeof(*stats), cmp_recombine_givs_stats);\n+  qsort (stats, giv_count, sizeof (*stats), cmp_recombine_givs_stats);\n \n   /* Set up the ix field for each giv in stats to name\n      the corresponding index into stats, and\n@@ -7397,7 +7398,7 @@ recombine_givs (loop, bl, unroll_p)\n \t  /* Loop unrolling of an inner loop can even create new DEST_REG\n \t     givs.  */\n \t  rtx p;\n-\t  for (p = v->insn; INSN_UID (p) >= max_uid_for_loop; )\n+\t  for (p = v->insn; INSN_UID (p) >= max_uid_for_loop;)\n \t    p = PREV_INSN (p);\n \t  stats[i].start_luid = stats[i].end_luid = INSN_LUID (p);\n \t  if (p != v->insn)\n@@ -7438,7 +7439,7 @@ recombine_givs (loop, bl, unroll_p)\n \t\t{\n \t\t  p = prev_nonnote_insn (p);\n \t\t  if (reg_set_p (v->dest_reg, p))\n-\t\t  count--;\n+\t\t    count--;\n \t\t}\n \n \t      stats[i].start_luid = INSN_LUID (p);\n@@ -7510,7 +7511,7 @@ recombine_givs (loop, bl, unroll_p)\n \t}\n     }\n \n-  qsort (stats, giv_count, sizeof(*stats), cmp_recombine_givs_stats);\n+  qsort (stats, giv_count, sizeof (*stats), cmp_recombine_givs_stats);\n \n   /* Try to derive DEST_REG givs from previous DEST_REG givs with the\n      same mult_val and non-overlapping lifetime.  This reduces register\n@@ -7641,8 +7642,8 @@ emit_iv_add_mult (b, m, a, reg, insert_before)\n \n   emit_insn_before (seq, insert_before);\n \n-  /* It is entirely possible that the expansion created lots of new \n-     registers.  Iterate over the sequence we just created and \n+  /* It is entirely possible that the expansion created lots of new\n+     registers.  Iterate over the sequence we just created and\n      record them all.  */\n \n   if (GET_CODE (seq) == SEQUENCE)\n@@ -7945,7 +7946,8 @@ check_dbra_loop (loop, insn_count)\n \t}\n \n       if (no_use_except_counting)\n-\t; /* no need to worry about MEMs.  */\n+\t/* No need to worry about MEMs.  */\n+\t;\n       else if (num_mem_sets <= 1)\n \t{\n \t  for (p = loop_start; p != loop_end; p = NEXT_INSN (p))\n@@ -7976,7 +7978,7 @@ check_dbra_loop (loop, insn_count)\n \t\t{\n \t\t  if (v->giv_type == DEST_REG\n \t\t      && reg_mentioned_p (v->dest_reg,\n-\t\t\t\t\t PATTERN (first_loop_store_insn)) \n+\t\t\t\t\t  PATTERN (first_loop_store_insn))\n \t\t      && loop_insn_first_p (first_loop_store_insn, v->insn))\n \t\t    reversible_mem_store = 0;\n \t\t}\n@@ -8011,7 +8013,7 @@ check_dbra_loop (loop, insn_count)\n \t  /* Now check other conditions:\n \n \t     The increment must be a constant, as must the initial value,\n-\t     and the comparison code must be LT. \n+\t     and the comparison code must be LT.\n \n \t     This test can probably be improved since +/- 1 in the constant\n \t     can be obtained by changing LT to LE and vice versa; this is\n@@ -8041,7 +8043,7 @@ check_dbra_loop (loop, insn_count)\n \t      if (comparison_const_width > HOST_BITS_PER_WIDE_INT)\n \t\tcomparison_const_width = HOST_BITS_PER_WIDE_INT;\n \t      comparison_sign_mask\n-\t\t= (unsigned HOST_WIDE_INT)1 << (comparison_const_width - 1);\n+\t\t= (unsigned HOST_WIDE_INT) 1 << (comparison_const_width - 1);\n \n \t      /* If the comparison value is not a loop invariant, then we\n \t\t can not reverse this loop.\n@@ -8055,8 +8057,8 @@ check_dbra_loop (loop, insn_count)\n \t      if (GET_CODE (comparison_value) == CONST_INT)\n \t\tcomparison_val = INTVAL (comparison_value);\n \t      initial_value = bl->initial_value;\n-\t\t\n-\t      /* Normalize the initial value if it is an integer and \n+\n+\t      /* Normalize the initial value if it is an integer and\n \t\t has no other use except as a counter.  This will allow\n \t\t a few more loops to be reversed.  */\n \t      if (no_use_except_counting\n@@ -8211,12 +8213,12 @@ check_dbra_loop (loop, insn_count)\n \t\t create a sequence to hold all the insns from expand_inc.  */\n \t      start_sequence ();\n \t      expand_inc (reg, new_add_val);\n-              tem = gen_sequence ();\n-              end_sequence ();\n+\t      tem = gen_sequence ();\n+\t      end_sequence ();\n \n \t      p = emit_insn_before (tem, bl->biv->insn);\n \t      delete_insn (bl->biv->insn);\n-\t\t      \n+\n \t      /* Update biv info to reflect its new status.  */\n \t      bl->biv->insn = p;\n \t      bl->initial_value = start_value;\n@@ -8251,7 +8253,7 @@ check_dbra_loop (loop, insn_count)\n \t      /* Add new compare/branch insn at end of loop.  */\n \t      start_sequence ();\n \t      emit_cmp_and_jump_insns (reg, const0_rtx, cmp_code, NULL_RTX,\n-\t\t\t\t       GET_MODE (reg), 0, 0, \n+\t\t\t\t       GET_MODE (reg), 0, 0,\n \t\t\t\t       XEXP (jump_label, 0));\n \t      tem = gen_sequence ();\n \t      end_sequence ();\n@@ -8418,7 +8420,7 @@ loop_insn_first_p (insn, reference)\n {\n   rtx p, q;\n \n-  for (p = insn, q = reference; ;)\n+  for (p = insn, q = reference;;)\n     {\n       /* Start with test for not first so that INSN == REFERENCE yields not\n          first.  */\n@@ -8573,7 +8575,8 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t     overflow problem.  */\n \n \t  for (v = bl->giv; v; v = v->next_iv)\n-\t    if (GET_CODE (v->mult_val) == CONST_INT && v->mult_val != const0_rtx\n+\t    if (GET_CODE (v->mult_val) == CONST_INT\n+\t\t&& v->mult_val != const0_rtx\n \t\t&& ! v->ignore && ! v->maybe_dead && v->always_computable\n \t\t&& v->mode == mode\n \t\t&& (GET_CODE (v->add_val) == SYMBOL_REF\n@@ -8610,7 +8613,7 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t\t\t\t  where);\n \n \t\t/* Substitute the new register for its invariant value in\n-\t\t   the compare expression. */\n+\t\t   the compare expression.  */\n \t\tXEXP (new, (INTVAL (v->mult_val) < 0) ? 0 : 1) = tem;\n \t\tif (validate_change (insn, &SET_SRC (PATTERN (insn)), new, 0))\n \t\t  return 1;\n@@ -8638,7 +8641,8 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t     negative mult_val, but it seems complex to do it in general.  */\n \n \t  for (v = bl->giv; v; v = v->next_iv)\n-\t    if (GET_CODE (v->mult_val) == CONST_INT && INTVAL (v->mult_val) > 0\n+\t    if (GET_CODE (v->mult_val) == CONST_INT\n+\t\t&& INTVAL (v->mult_val) > 0\n \t\t&& (GET_CODE (v->add_val) == SYMBOL_REF\n \t\t    || GET_CODE (v->add_val) == LABEL_REF\n \t\t    || GET_CODE (v->add_val) == CONST\n@@ -8654,7 +8658,7 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t\t  return 1;\n \n \t\t/* Replace biv with the giv's reduced reg.  */\n-\t\tvalidate_change (insn, &XEXP (x, 1-arg_operand), v->new_reg, 1);\n+\t\tvalidate_change (insn, &XEXP (x, 1 - arg_operand), v->new_reg, 1);\n \n \t\t/* If all constants are actually constant integers and\n \t\t   the derived constant can be directly placed in the COMPARE,\n@@ -8665,8 +8669,8 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t\t  {\n \t\t    validate_change (insn, &XEXP (x, arg_operand),\n \t\t\t\t     GEN_INT (INTVAL (arg)\n-\t\t\t\t\t     * INTVAL (v->mult_val)\n-\t\t\t\t\t     + INTVAL (v->add_val)), 1);\n+\t\t\t\t\t      * INTVAL (v->mult_val)\n+\t\t\t\t\t      + INTVAL (v->add_val)), 1);\n \t\t  }\n \t\telse\n \t\t  {\n@@ -8678,13 +8682,14 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t\tif (apply_change_group ())\n \t\t  return 1;\n \t      }\n-\t  \n+\n \t  /* Look for giv with positive constant mult_val and nonconst add_val.\n-\t     Insert insns to calculate new compare value.  \n+\t     Insert insns to calculate new compare value.\n \t     ??? Turn this off due to possible overflow.  */\n \n \t  for (v = bl->giv; v; v = v->next_iv)\n-\t    if (GET_CODE (v->mult_val) == CONST_INT && INTVAL (v->mult_val) > 0\n+\t    if (GET_CODE (v->mult_val) == CONST_INT\n+\t\t&& INTVAL (v->mult_val) > 0\n \t\t&& ! v->ignore && ! v->maybe_dead && v->always_computable\n \t\t&& v->mode == mode\n \t\t&& 0)\n@@ -8716,7 +8721,7 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t  if (loop_invariant_p (loop, arg) == 1)\n \t    {\n \t      /* Look for giv with constant positive mult_val and nonconst\n-\t\t add_val. Insert insns to compute new compare value. \n+\t\t add_val. Insert insns to compute new compare value.\n \t\t ??? Turn this off due to possible overflow.  */\n \n \t      for (v = bl->giv; v; v = v->next_iv)\n@@ -8788,7 +8793,7 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n \t\t      return 1;\n \n \t\t    /* Replace biv with its giv's reduced reg.  */\n-\t\t    XEXP (x, 1-arg_operand) = v->new_reg;\n+\t\t    XEXP (x, 1 - arg_operand) = v->new_reg;\n \t\t    /* Replace other operand with the other giv's\n \t\t       reduced reg.  */\n \t\t    XEXP (x, arg_operand) = tv->new_reg;\n@@ -8820,7 +8825,7 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n       switch (fmt[i])\n \t{\n \tcase 'e':\n-\t  if (! maybe_eliminate_biv_1 (loop, XEXP (x, i), insn, bl, \n+\t  if (! maybe_eliminate_biv_1 (loop, XEXP (x, i), insn, bl,\n \t\t\t\t       eliminate_p, where))\n \t    return 0;\n \t  break;\n@@ -8835,7 +8840,7 @@ maybe_eliminate_biv_1 (loop, x, insn, bl, eliminate_p, where)\n     }\n \n   return 1;\n-}  \n+}\n \f\n /* Return nonzero if the last use of REG\n    is in an insn following INSN in the same basic block.  */\n@@ -9076,7 +9081,7 @@ canonicalize_condition (insn, cond, reverse, earliest, want_reg)\n #endif\n \t\t     ))\n \t\t   && GET_RTX_CLASS (GET_CODE (SET_SRC (set))) == '<'\n-\t           && (((GET_MODE_CLASS (mode) == MODE_CC)\n+\t\t   && (((GET_MODE_CLASS (mode) == MODE_CC)\n \t\t\t== (GET_MODE_CLASS (inner_mode) == MODE_CC))\n \t\t       || mode == VOIDmode || inner_mode == VOIDmode))\n \n@@ -9141,7 +9146,7 @@ canonicalize_condition (insn, cond, reverse, earliest, want_reg)\n \t{\n \tcase LE:\n \t  if ((unsigned HOST_WIDE_INT) const_val != max_val >> 1)\n-\t    code = LT,\top1 = GEN_INT (const_val + 1);\n+\t    code = LT, op1 = GEN_INT (const_val + 1);\n \t  break;\n \n \t/* When cross-compiling, const_val might be sign-extended from\n@@ -9186,7 +9191,6 @@ canonicalize_condition (insn, cond, reverse, earliest, want_reg)\n   return gen_rtx_fmt_ee (code, VOIDmode, op0, op1);\n }\n \n-\n /* Given a jump insn JUMP, return the condition that will cause it to branch\n    to its JUMP_LABEL.  If the condition cannot be understood, or is an\n    inequality floating-point comparison which needs to be reversed, 0 will\n@@ -9242,7 +9246,6 @@ get_condition_for_loop (loop, x)\n \t\t\t XEXP (comparison, 1), XEXP (comparison, 0));\n }\n \n-\n /* Scan the function and determine whether it has indirect (computed) jumps.\n \n    This is taken mostly from flow.c; similar code exists elsewhere\n@@ -9300,7 +9303,7 @@ insert_loop_mem (mem, data)\n \n   /* See if we've already seen this MEM.  */\n   for (i = 0; i < loop_mems_idx; ++i)\n-    if (rtx_equal_p (m, loop_mems[i].mem)) \n+    if (rtx_equal_p (m, loop_mems[i].mem))\n       {\n \tif (GET_MODE (m) != GET_MODE (loop_mems[i].mem))\n \t  /* The modes of the two memory accesses are different.  If\n@@ -9312,16 +9315,16 @@ insert_loop_mem (mem, data)\n       }\n \n   /* Resize the array, if necessary.  */\n-  if (loop_mems_idx == loop_mems_allocated) \n+  if (loop_mems_idx == loop_mems_allocated)\n     {\n       if (loop_mems_allocated != 0)\n \tloop_mems_allocated *= 2;\n       else\n \tloop_mems_allocated = 32;\n \n-      loop_mems = (loop_mem_info*) \n+      loop_mems = (loop_mem_info*)\n \txrealloc (loop_mems,\n-\t\t  loop_mems_allocated * sizeof (loop_mem_info)); \n+\t\t  loop_mems_allocated * sizeof (loop_mem_info));\n     }\n \n   /* Actually insert the MEM.  */\n@@ -9349,7 +9352,7 @@ load_mems_and_recount_loop_regs_set (loop, insn_count)\n   int nregs = max_reg_num ();\n \n   load_mems (loop);\n-  \n+\n   /* Recalculate set_in_loop and friends since load_mems may have\n      created new registers.  */\n   if (max_reg_num () > nregs)\n@@ -9375,14 +9378,14 @@ load_mems_and_recount_loop_regs_set (loop, insn_count)\n \n       count_loop_regs_set (loop->top ? loop->top : loop->start, loop->end,\n \t\t\t   may_not_optimize, reg_single_usage,\n-\t\t\t   insn_count, nregs); \n+\t\t\t   insn_count, nregs);\n \n       for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n \t{\n \t  VARRAY_CHAR (may_not_optimize, i) = 1;\n \t  VARRAY_INT (set_in_loop, i) = 1;\n \t}\n-      \n+\n #ifdef AVOID_CCMODE_COPIES\n       /* Don't try to move insns which set CC registers if we should not\n \t create CCmode register copies.  */\n@@ -9431,8 +9434,8 @@ load_mems (loop)\n \n   /* Check to see if it's possible that some instructions in the\n      loop are never executed.  */\n-  for (p = next_insn_in_loop (loop, loop->scan_start); \n-       p != NULL_RTX && ! maybe_never; \n+  for (p = next_insn_in_loop (loop, loop->scan_start);\n+       p != NULL_RTX && ! maybe_never;\n        p = next_insn_in_loop (loop, p))\n     {\n       if (GET_CODE (p) == CODE_LABEL)\n@@ -9444,7 +9447,7 @@ load_mems (loop)\n \t\t  otherwise the code at the top of the loop might\n \t\t  never be executed.  Unconditional jumps are\n \t\t  followed a by barrier then loop end.  */\n-\t       && ! (GET_CODE (p) == JUMP_INSN \n+\t       && ! (GET_CODE (p) == JUMP_INSN\n \t\t     && JUMP_LABEL (p) == loop->top\n \t\t     && NEXT_INSN (NEXT_INSN (p)) == loop->end\n \t\t     && any_uncondjump_p (p)))\n@@ -9455,14 +9458,14 @@ load_mems (loop)\n \t  else\n \t    /* If there are any more instructions in the loop, they\n \t       might not be reached.  */\n-\t    next_maybe_never = 1; \n-\t} \n+\t    next_maybe_never = 1;\n+\t}\n       else if (next_maybe_never)\n \tmaybe_never = 1;\n     }\n \n   /* Actually move the MEMs.  */\n-  for (i = 0; i < loop_mems_idx; ++i) \n+  for (i = 0; i < loop_mems_idx; ++i)\n     {\n       regset_head load_copies;\n       regset_head store_copies;\n@@ -9471,7 +9474,7 @@ load_mems (loop)\n       rtx mem = loop_mems[i].mem;\n       rtx mem_list_entry;\n \n-      if (MEM_VOLATILE_P (mem) \n+      if (MEM_VOLATILE_P (mem)\n \t  || loop_invariant_p (loop, XEXP (mem, 0)) != 1)\n \t/* There's no telling whether or not MEM is modified.  */\n \tloop_mems[i].optimize = 0;\n@@ -9496,9 +9499,9 @@ load_mems (loop)\n       if (flag_float_store && written\n \t  && GET_MODE_CLASS (GET_MODE (mem)) == MODE_FLOAT)\n \tloop_mems[i].optimize = 0;\n-  \n+\n       /* If this MEM is written to, we must be sure that there\n-\t are no reads from another MEM that aliases this one.  */ \n+\t are no reads from another MEM that aliases this one.  */\n       if (loop_mems[i].optimize && written)\n \t{\n \t  int j;\n@@ -9525,7 +9528,7 @@ load_mems (loop)\n \t/* We can't access the MEM outside the loop; it might\n \t   cause a trap that wouldn't have happened otherwise.  */\n \tloop_mems[i].optimize = 0;\n-\t  \n+\n       if (!loop_mems[i].optimize)\n \t/* We thought we were going to lift this MEM out of the\n \t   loop, but later discovered that we could not.  */\n@@ -9664,7 +9667,7 @@ load_mems (loop)\n \n \t      /* Store the memory immediately after END, which is\n \t\t the NOTE_LOOP_END.  */\n-\t      set = gen_move_insn (copy_rtx (mem), reg); \n+\t      set = gen_move_insn (copy_rtx (mem), reg);\n \t      emit_insn_after (set, label);\n \t    }\n \n@@ -9699,7 +9702,7 @@ load_mems (loop)\n     {\n       /* Now, we need to replace all references to the previous exit\n \t label with the new one.  */\n-      rtx_pair rr; \n+      rtx_pair rr;\n       rr.r1 = end_label;\n       rr.r2 = label;\n \n@@ -9735,7 +9738,7 @@ note_reg_stored (x, setter, arg)\n      rtx x, setter ATTRIBUTE_UNUSED;\n      void *arg;\n {\n-  struct note_reg_stored_arg *t = (struct note_reg_stored_arg *)arg;\n+  struct note_reg_stored_arg *t = (struct note_reg_stored_arg *) arg;\n   if (t->reg == x)\n     t->set_seen = 1;\n }\n@@ -9789,7 +9792,7 @@ try_copy_prop (loop, replacement, regno)\n \n       /* Only substitute after seeing the initializing insn.  */\n       if (init_insn && insn != init_insn)\n-\t{\t\n+\t{\n \t  struct note_reg_stored_arg arg;\n \t  rtx array[3];\n \t  array[0] = reg_rtx;\n@@ -9926,7 +9929,7 @@ replace_loop_mem (mem, data)\n      rtx *mem;\n      void *data;\n {\n-  rtx_and_int *ri; \n+  rtx_and_int *ri;\n   rtx insn;\n   int i;\n   rtx m = *mem;\n@@ -9949,7 +9952,7 @@ replace_loop_mem (mem, data)\n       return 0;\n     }\n \n-  ri = (rtx_and_int*) data;\n+  ri = (rtx_and_int *) data;\n   i = ri->i;\n \n   if (!rtx_equal_p (loop_mems[i].mem, m))\n@@ -9975,7 +9978,7 @@ replace_loop_reg (px, data)\n      void *data;\n {\n   rtx x = *px;\n-  rtx *array = (rtx *)data;\n+  rtx *array = (rtx *) data;\n \n   if (x == NULL_RTX)\n     return 0;\n@@ -9996,8 +9999,8 @@ replace_label (x, data)\n      void *data;\n {\n   rtx l = *x;\n-  rtx old_label = ((rtx_pair*) data)->r1;\n-  rtx new_label = ((rtx_pair*) data)->r2;\n+  rtx old_label = ((rtx_pair *) data)->r1;\n+  rtx new_label = ((rtx_pair *) data)->r2;\n \n   if (l == NULL_RTX)\n     return 0;\n@@ -10007,7 +10010,7 @@ replace_label (x, data)\n \n   if (XEXP (l, 0) != old_label)\n     return 0;\n-  \n+\n   XEXP (l, 0) = new_label;\n   ++LABEL_NUSES (new_label);\n   --LABEL_NUSES (old_label);"}]}