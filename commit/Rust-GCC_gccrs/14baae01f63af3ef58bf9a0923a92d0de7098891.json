{"sha": "14baae01f63af3ef58bf9a0923a92d0de7098891", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTRiYWFlMDFmNjNhZjNlZjU4YmY5YTA5MjNhOTJkMGRlNzA5ODg5MQ==", "commit": {"author": {"name": "Neil Booth", "email": "neil@daikokuya.demon.co.uk", "date": "2001-09-17T18:26:12Z"}, "committer": {"name": "Neil Booth", "email": "neil@gcc.gnu.org", "date": "2001-09-17T18:26:12Z"}, "message": "cpphash.h (_cpp_lex_direct): New.\n\n\t* cpphash.h (_cpp_lex_direct): New.\n\t* cpplex.c (_cpp_lex_token): Update.\n\t(lex_token): Rename _cpp_lex_direct; lex into pfile->cur_token,\n\tand increment that pointer.\n\t* cppmacro.c (alloc_expansion_token): New.\n\t(lex_expansion_token): Lex macro expansion directly into\n\tmacro storage.\n\nFrom-SVN: r45656", "tree": {"sha": "1bee8006a617d6612c2e199afafa13805239e1a9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1bee8006a617d6612c2e199afafa13805239e1a9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/14baae01f63af3ef58bf9a0923a92d0de7098891", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/14baae01f63af3ef58bf9a0923a92d0de7098891", "html_url": "https://github.com/Rust-GCC/gccrs/commit/14baae01f63af3ef58bf9a0923a92d0de7098891", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/14baae01f63af3ef58bf9a0923a92d0de7098891/comments", "author": null, "committer": null, "parents": [{"sha": "7a91449ca19c444f48b8bc36f6a665dbec267706", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7a91449ca19c444f48b8bc36f6a665dbec267706", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7a91449ca19c444f48b8bc36f6a665dbec267706"}], "stats": {"total": 116, "additions": 82, "deletions": 34}, "files": [{"sha": "8b0fe94eca4d2b3e1576c082bc82c5a9ab1f3370", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=14baae01f63af3ef58bf9a0923a92d0de7098891", "patch": "@@ -1,3 +1,13 @@\n+2001-09-17  Neil Booth  <neil@daikokuya.demon.co.uk>\n+\n+\t* cpphash.h (_cpp_lex_direct): New.\n+\t* cpplex.c (_cpp_lex_token): Update.\n+\t(lex_token): Rename _cpp_lex_direct; lex into pfile->cur_token,\n+\tand increment that pointer.\n+\t* cppmacro.c (alloc_expansion_token): New.\n+\t(lex_expansion_token): Lex macro expansion directly into\n+\tmacro storage.\n+\n 2001-09-16  Brad Lucier  <lucier@math.purdue.edu>\n \n \t* Makefile.in: Make rtl-error.o depend on $(CONFIG_H)."}, {"sha": "64deaa2fa23ee457df87d5a2d1f15d32af5092d0", "filename": "gcc/cpphash.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2Fcpphash.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2Fcpphash.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpphash.h?ref=14baae01f63af3ef58bf9a0923a92d0de7098891", "patch": "@@ -399,6 +399,7 @@ extern int _cpp_parse_expr\t\tPARAMS ((cpp_reader *));\n \n /* In cpplex.c */\n extern const cpp_token *_cpp_lex_token\tPARAMS ((cpp_reader *));\n+extern cpp_token *_cpp_lex_direct\tPARAMS ((cpp_reader *));\n extern int _cpp_equiv_tokens\t\tPARAMS ((const cpp_token *,\n \t\t\t\t\t\t const cpp_token *));\n extern void _cpp_init_tokenrun\t\tPARAMS ((tokenrun *, unsigned int));"}, {"sha": "e734f4021b2b68cf38d1c88be88341705557b2ab", "filename": "gcc/cpplex.c", "status": "modified", "additions": 25, "deletions": 14, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2Fcpplex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2Fcpplex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplex.c?ref=14baae01f63af3ef58bf9a0923a92d0de7098891", "patch": "@@ -102,7 +102,6 @@ static void lex_dot PARAMS ((cpp_reader *, cpp_token *));\n static int name_p PARAMS ((cpp_reader *, const cpp_string *));\n static int maybe_read_ucs PARAMS ((cpp_reader *, const unsigned char **,\n \t\t\t\t   const unsigned char *, unsigned int *));\n-static cpp_token *lex_token PARAMS ((cpp_reader *, cpp_token *));\n static tokenrun *next_tokenrun PARAMS ((tokenrun *));\n \n static cpp_chunk *new_chunk PARAMS ((unsigned int));\n@@ -811,7 +810,7 @@ save_comment (pfile, token, from)\n   memcpy (buffer + 1, from, len - 1);\n }\n \n-/* Subroutine of lex_token to handle '%'.  A little tricky, since we\n+/* Subroutine of _cpp_lex_direct to handle '%'.  A little tricky, since we\n    want to avoid stepping back when lexing %:%X.  */\n static void\n lex_percent (pfile, result)\n@@ -860,7 +859,7 @@ lex_percent (pfile, result)\n     }\n }\n \n-/* Subroutine of lex_token to handle '.'.  This is tricky, since we\n+/* Subroutine of _cpp_lex_direct to handle '.'.  This is tricky, since we\n    want to avoid stepping back when lexing '...' or '.123'.  In the\n    latter case we should also set a flag for parse_number.  */\n static void\n@@ -932,7 +931,9 @@ next_tokenrun (run)\n   return run->next;\n }\n \n-/* Lex a token into RESULT (external interface).  */\n+/* Lex a token into RESULT (external interface).  Takes care of issues\n+   like directive handling, token lookahead, multiple include\n+   opimisation and skipping.  */\n const cpp_token *\n _cpp_lex_token (pfile)\n      cpp_reader *pfile;\n@@ -946,12 +947,14 @@ _cpp_lex_token (pfile)\n \t  pfile->cur_run = next_tokenrun (pfile->cur_run);\n \t  pfile->cur_token = pfile->cur_run->base;\n \t}\n-      result = pfile->cur_token++;\n \n       if (pfile->lookaheads)\n-\tpfile->lookaheads--;\n+\t{\n+\t  pfile->lookaheads--;\n+\t  result = pfile->cur_token++;\n+\t}\n       else\n-\tresult = lex_token (pfile, result);\n+\tresult = _cpp_lex_direct (pfile);\n \n       if (result->flags & BOL)\n \t{\n@@ -970,7 +973,7 @@ _cpp_lex_token (pfile)\n \tbreak;\n \n       /* Outside a directive, invalidate controlling macros.  At file\n-\t EOF, lex_token takes care of popping the buffer, so we never\n+\t EOF, _cpp_lex_direct takes care of popping the buffer, so we never\n \t get here and MI optimisation works.  */\n       pfile->mi_valid = false;\n \n@@ -981,17 +984,25 @@ _cpp_lex_token (pfile)\n   return result;\n }\n \n-/* Lex a token into RESULT.  When meeting a newline, returns CPP_EOF\n-   if parsing a directive, otherwise returns to the start of the token\n-   buffer if permissible.  Returns the location of the lexed token.  */\n-static cpp_token *\n-lex_token (pfile, result)\n+/* Lex a token into pfile->cur_token, which is also incremented, to\n+   get diagnostics pointing to the correct location.\n+\n+   Does not handle issues such as token lookahead, multiple-include\n+   optimisation, directives, skipping etc.  This function is only\n+   suitable for use by _cpp_lex_token, and in special cases like\n+   lex_expansion_token which doesn't care for any of these issues.\n+\n+   When meeting a newline, returns CPP_EOF if parsing a directive,\n+   otherwise returns to the start of the token buffer if permissible.\n+   Returns the location of the lexed token.  */\n+cpp_token *\n+_cpp_lex_direct (pfile)\n      cpp_reader *pfile;\n-     cpp_token *result;\n {\n   cppchar_t c;\n   cpp_buffer *buffer;\n   const unsigned char *comment_start;\n+  cpp_token *result = pfile->cur_token++;\n \n  fresh_line:\n   buffer = pfile->buffer;"}, {"sha": "e5260694c420b305dbe74d00fee3aa05943519f7", "filename": "gcc/cppmacro.c", "status": "modified", "additions": 46, "deletions": 20, "changes": 66, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2Fcppmacro.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/14baae01f63af3ef58bf9a0923a92d0de7098891/gcc%2Fcppmacro.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppmacro.c?ref=14baae01f63af3ef58bf9a0923a92d0de7098891", "patch": "@@ -79,6 +79,7 @@ static void replace_args PARAMS ((cpp_reader *, cpp_macro *, macro_arg *,\n \n /* #define directive parsing and handling.  */\n \n+static cpp_token *alloc_expansion_token PARAMS ((cpp_reader *, cpp_macro *));\n static cpp_token *lex_expansion_token PARAMS ((cpp_reader *, cpp_macro *));\n static int warn_of_redefinition PARAMS ((cpp_reader *, const cpp_hashnode *,\n \t\t\t\t\t const cpp_macro *));\n@@ -1089,6 +1090,8 @@ _cpp_free_definition (h)\n   h->flags &= ~NODE_BUILTIN;\n }\n \n+/* Save parameter NODE to the parameter list of macro MACRO.  Returns\n+   zero on success, non-zero if the paramter is a duplicate.  */\n static int\n save_parameter (pfile, macro, node)\n      cpp_reader *pfile;\n@@ -1119,6 +1122,7 @@ save_parameter (pfile, macro, node)\n   return 0;\n }\n \n+/* Check the syntax of the paramters in a MACRO definition.  */\n static int\n parse_params (pfile, macro)\n      cpp_reader *pfile;\n@@ -1195,10 +1199,9 @@ parse_params (pfile, macro)\n     }\n }\n \n-/* Lex a token from a macro's replacement list.  Translate it to a\n-   CPP_MACRO_ARG if appropriate.  */\n+/* Allocate room for a token from a macro's replacement list.  */\n static cpp_token *\n-lex_expansion_token (pfile, macro)\n+alloc_expansion_token (pfile, macro)\n      cpp_reader *pfile;\n      cpp_macro *macro;\n {\n@@ -1213,7 +1216,18 @@ lex_expansion_token (pfile, macro)\n     }\n \n   macro->count++;\n-  *token = *_cpp_lex_token (pfile);\n+  return token;\n+}\n+\n+static cpp_token *\n+lex_expansion_token (pfile, macro)\n+     cpp_reader *pfile;\n+     cpp_macro *macro;\n+{\n+  cpp_token *token;\n+\n+  pfile->cur_token = alloc_expansion_token (pfile, macro);\n+  token = _cpp_lex_direct (pfile);\n \n   /* Is this an argument?  */\n   if (token->type == CPP_NAME && token->val.node->arg_index)\n@@ -1235,37 +1249,43 @@ _cpp_create_definition (pfile, node)\n      cpp_hashnode *node;\n {\n   cpp_macro *macro;\n-  cpp_token *token;\n+  cpp_token *token, *saved_cur_token;\n+  const cpp_token *ctoken;\n   unsigned int i, ok = 1;\n \n   macro = (cpp_macro *) _cpp_pool_alloc (&pfile->macro_pool,\n \t\t\t\t\t sizeof (cpp_macro));\n   macro->line = pfile->directive_line;\n   macro->params = 0;\n   macro->paramc = 0;\n-  macro->fun_like = 0;\n   macro->variadic = 0;\n   macro->count = 0;\n-  macro->expansion = (cpp_token *) POOL_FRONT (&pfile->macro_pool);\n+  macro->fun_like = 0;\n \n   /* Get the first token of the expansion (or the '(' of a\n      function-like macro).  */\n-  token = lex_expansion_token (pfile, macro);\n-  if (token->type == CPP_OPEN_PAREN && !(token->flags & PREV_WHITE))\n+  ctoken = _cpp_lex_token (pfile);\n+\n+  if (ctoken->type == CPP_OPEN_PAREN && !(ctoken->flags & PREV_WHITE))\n     {\n       if (!(ok = parse_params (pfile, macro)))\n-\tgoto cleanup;\n-      macro->count = 0;\n+\tgoto cleanup2;\n       macro->fun_like = 1;\n-      /* Some of the pool may have been used for the parameter store.  */\n-      macro->expansion = (cpp_token *) POOL_FRONT (&pfile->macro_pool);\n-      token = lex_expansion_token (pfile, macro);\n     }\n-  else if (token->type != CPP_EOF && !(token->flags & PREV_WHITE))\n+  else if (ctoken->type != CPP_EOF && !(ctoken->flags & PREV_WHITE))\n     cpp_pedwarn (pfile, \"ISO C requires whitespace after the macro name\");\n \n-  /* Setting it here means we don't catch leading comments.  */\n   pfile->state.save_comments = ! CPP_OPTION (pfile, discard_comments);\n+  saved_cur_token = pfile->cur_token;\n+  macro->expansion = (cpp_token *) POOL_FRONT (&pfile->macro_pool);\n+\n+  if (macro->fun_like)\n+    token = lex_expansion_token (pfile, macro);\n+  else\n+    {\n+      token = alloc_expansion_token (pfile, macro);\n+      *token = *ctoken;\n+    }\n \n   for (;;)\n     {\n@@ -1286,7 +1306,7 @@ _cpp_create_definition (pfile, node)\n \t    {\n \t      ok = 0;\n \t      cpp_error (pfile, \"'#' is not followed by a macro parameter\");\n-\t      goto cleanup;\n+\t      goto cleanup1;\n \t    }\n \t}\n \n@@ -1306,7 +1326,7 @@ _cpp_create_definition (pfile, node)\n \t      ok = 0;\n \t      cpp_error (pfile,\n \t\t\t \"'##' cannot appear at either end of a macro expansion\");\n-\t      goto cleanup;\n+\t      goto cleanup1;\n \t    }\n \n \t  token[-1].flags |= PASTE_LEFT;\n@@ -1346,7 +1366,7 @@ _cpp_create_definition (pfile, node)\n \t\t\t\t \"\\\"%s\\\" redefined\", NODE_NAME (node));\n \n \t  if (node->type == NT_MACRO && !(node->flags & NODE_BUILTIN))\n-\t    cpp_pedwarn_with_line (pfile, node->value.macro->line, 1,\n+\t    cpp_pedwarn_with_line (pfile, node->value.macro->line, 0,\n \t\t\t    \"this is the location of the previous definition\");\n \t}\n       _cpp_free_definition (node);\n@@ -1358,7 +1378,13 @@ _cpp_create_definition (pfile, node)\n   if (! ustrncmp (NODE_NAME (node), DSC (\"__STDC_\")))\n     node->flags |= NODE_WARN;\n \n- cleanup:\n+ cleanup1:\n+\n+  /* Set type for SEEN_EOL() in cpplib.c, restore the lexer position.  */\n+  saved_cur_token[-1].type = pfile->cur_token[-1].type;\n+  pfile->cur_token = saved_cur_token;\n+\n+ cleanup2:\n \n   /* Stop the lexer accepting __VA_ARGS__.  */\n   pfile->state.va_args_ok = 0;"}]}