{"sha": "e0d98ffd14487b7105de3d151122144086faa1fa", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTBkOThmZmQxNDQ4N2I3MTA1ZGUzZDE1MTEyMjE0NDA4NmZhYTFmYQ==", "commit": {"author": {"name": "Kewen Lin", "email": "linkw@linux.ibm.com", "date": "2020-09-16T03:32:55Z"}, "committer": {"name": "Kewen Lin", "email": "linkw@linux.ibm.com", "date": "2020-09-16T03:59:35Z"}, "message": "rs6000: Remove useless insns fed into lvx/stvx [PR97019]\n\nThis patch is to extend the existing function find_alignment_op to\ncheck all defintions of base_reg are AND operations with mask -16B\nto force the alignment.  If all are satifised, it passes all AND\noperations and instructions to function recombine_lvx_pattern\nand recombine_stvx_pattern, they can remove all useless ANDs\nfurther.\n\nBootstrapped/regtested on powerpc64le-linux-gnu P8.\n\ngcc/ChangeLog:\n\n\tPR target/97019\n\t* config/rs6000/rs6000-p8swap.c (find_alignment_op): Adjust to\n\tsupport multiple defintions which are all AND operations with\n\tthe mask -16B.\n\t(recombine_lvx_pattern): Adjust to handle multiple AND operations\n\tfrom find_alignment_op.\n\t(recombine_stvx_pattern): Likewise.\n\ngcc/testsuite/ChangeLog:\n\n\tPR target/97019\n\t* gcc.target/powerpc/pr97019.c: New test.", "tree": {"sha": "06428317ab4a0f16f5940fb03dd8d0da63a8c6c0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/06428317ab4a0f16f5940fb03dd8d0da63a8c6c0"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e0d98ffd14487b7105de3d151122144086faa1fa", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e0d98ffd14487b7105de3d151122144086faa1fa", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e0d98ffd14487b7105de3d151122144086faa1fa", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e0d98ffd14487b7105de3d151122144086faa1fa/comments", "author": {"login": "jedilyn", "id": 38515402, "node_id": "MDQ6VXNlcjM4NTE1NDAy", "avatar_url": "https://avatars.githubusercontent.com/u/38515402?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jedilyn", "html_url": "https://github.com/jedilyn", "followers_url": "https://api.github.com/users/jedilyn/followers", "following_url": "https://api.github.com/users/jedilyn/following{/other_user}", "gists_url": "https://api.github.com/users/jedilyn/gists{/gist_id}", "starred_url": "https://api.github.com/users/jedilyn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jedilyn/subscriptions", "organizations_url": "https://api.github.com/users/jedilyn/orgs", "repos_url": "https://api.github.com/users/jedilyn/repos", "events_url": "https://api.github.com/users/jedilyn/events{/privacy}", "received_events_url": "https://api.github.com/users/jedilyn/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jedilyn", "id": 38515402, "node_id": "MDQ6VXNlcjM4NTE1NDAy", "avatar_url": "https://avatars.githubusercontent.com/u/38515402?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jedilyn", "html_url": "https://github.com/jedilyn", "followers_url": "https://api.github.com/users/jedilyn/followers", "following_url": "https://api.github.com/users/jedilyn/following{/other_user}", "gists_url": "https://api.github.com/users/jedilyn/gists{/gist_id}", "starred_url": "https://api.github.com/users/jedilyn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jedilyn/subscriptions", "organizations_url": "https://api.github.com/users/jedilyn/orgs", "repos_url": "https://api.github.com/users/jedilyn/repos", "events_url": "https://api.github.com/users/jedilyn/events{/privacy}", "received_events_url": "https://api.github.com/users/jedilyn/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "01d56aeaffa11959278dd6f6f2c1085cac25a345", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/01d56aeaffa11959278dd6f6f2c1085cac25a345", "html_url": "https://github.com/Rust-GCC/gccrs/commit/01d56aeaffa11959278dd6f6f2c1085cac25a345"}], "stats": {"total": 230, "additions": 176, "deletions": 54}, "files": [{"sha": "fff1b08afa60cf179fa39b790dd9ada013d29bc7", "filename": "gcc/config/rs6000/rs6000-p8swap.c", "status": "modified", "additions": 93, "deletions": 54, "changes": 147, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e0d98ffd14487b7105de3d151122144086faa1fa/gcc%2Fconfig%2Frs6000%2Frs6000-p8swap.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e0d98ffd14487b7105de3d151122144086faa1fa/gcc%2Fconfig%2Frs6000%2Frs6000-p8swap.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-p8swap.c?ref=e0d98ffd14487b7105de3d151122144086faa1fa", "patch": "@@ -2095,11 +2095,15 @@ alignment_mask (rtx_insn *insn)\n   return alignment_with_canonical_addr (SET_SRC (body));\n }\n \n-/* Given INSN that's a load or store based at BASE_REG, look for a\n-   feeding computation that aligns its address on a 16-byte boundary.\n-   Return the rtx and its containing AND_INSN.  */\n-static rtx\n-find_alignment_op (rtx_insn *insn, rtx base_reg, rtx_insn **and_insn)\n+/* Given INSN that's a load or store based at BASE_REG, check if\n+   all of its feeding computations align its address on a 16-byte\n+   boundary.  If so, return true and add all definition insns into\n+   AND_INSNS and their corresponding fully-expanded rtxes for the\n+   masking operations into AND_OPS.  */\n+\n+static bool\n+find_alignment_op (rtx_insn *insn, rtx base_reg, vec<rtx_insn *> *and_insns,\n+\t\t   vec<rtx> *and_ops)\n {\n   df_ref base_use;\n   struct df_insn_info *insn_info = DF_INSN_INFO_GET (insn);\n@@ -2111,19 +2115,28 @@ find_alignment_op (rtx_insn *insn, rtx base_reg, rtx_insn **and_insn)\n \tcontinue;\n \n       struct df_link *base_def_link = DF_REF_CHAIN (base_use);\n-      if (!base_def_link || base_def_link->next)\n-\tbreak;\n+      if (!base_def_link)\n+\treturn false;\n \n-      /* With stack-protector code enabled, and possibly in other\n-\t circumstances, there may not be an associated insn for \n-\t the def.  */\n-      if (DF_REF_IS_ARTIFICIAL (base_def_link->ref))\n-\tbreak;\n+      while (base_def_link)\n+\t{\n+\t  /* With stack-protector code enabled, and possibly in other\n+\t     circumstances, there may not be an associated insn for\n+\t     the def.  */\n+\t  if (DF_REF_IS_ARTIFICIAL (base_def_link->ref))\n+\t    return false;\n \n-      *and_insn = DF_REF_INSN (base_def_link->ref);\n-      and_operation = alignment_mask (*and_insn);\n-      if (and_operation != 0)\n-\tbreak;\n+\t  rtx_insn *and_insn = DF_REF_INSN (base_def_link->ref);\n+\t  and_operation = alignment_mask (and_insn);\n+\n+\t  /* Stop if we find any one which doesn't align.  */\n+\t  if (!and_operation)\n+\t    return false;\n+\n+\t  and_insns->safe_push (and_insn);\n+\t  and_ops->safe_push (and_operation);\n+\t  base_def_link = base_def_link->next;\n+\t}\n     }\n \n   return and_operation;\n@@ -2143,11 +2156,14 @@ recombine_lvx_pattern (rtx_insn *insn, del_info *to_delete)\n   rtx mem = XEXP (SET_SRC (body), 0);\n   rtx base_reg = XEXP (mem, 0);\n \n-  rtx_insn *and_insn;\n-  rtx and_operation = find_alignment_op (insn, base_reg, &and_insn);\n+  auto_vec<rtx_insn *> and_insns;\n+  auto_vec<rtx> and_ops;\n+  bool is_any_def_and\n+    = find_alignment_op (insn, base_reg, &and_insns, &and_ops);\n \n-  if (and_operation != 0)\n+  if (is_any_def_and)\n     {\n+      gcc_assert (and_insns.length () == and_ops.length ());\n       df_ref def;\n       struct df_insn_info *insn_info = DF_INSN_INFO_GET (insn);\n       FOR_EACH_INSN_INFO_DEF (def, insn_info)\n@@ -2168,25 +2184,35 @@ recombine_lvx_pattern (rtx_insn *insn, del_info *to_delete)\n \t  to_delete[INSN_UID (swap_insn)].replace = true;\n \t  to_delete[INSN_UID (swap_insn)].replace_insn = swap_insn;\n \n-\t  /* However, first we must be sure that we make the\n-\t     base register from the AND operation available\n-\t     in case the register has been overwritten.  Copy\n-\t     the base register to a new pseudo and use that\n-\t     as the base register of the AND operation in\n-\t     the new LVX instruction.  */\n-\t  rtx and_base = XEXP (and_operation, 0);\n-\t  rtx new_reg = gen_reg_rtx (GET_MODE (and_base));\n-\t  rtx copy = gen_rtx_SET (new_reg, and_base);\n-\t  rtx_insn *new_insn = emit_insn_after (copy, and_insn);\n-\t  set_block_for_insn (new_insn, BLOCK_FOR_INSN (and_insn));\n-\t  df_insn_rescan (new_insn);\n-\n-\t  XEXP (mem, 0) = gen_rtx_AND (GET_MODE (and_base), new_reg,\n-\t\t\t\t       XEXP (and_operation, 1));\n+\t  rtx new_reg = 0;\n+\t  rtx and_mask = 0;\n+\t  for (unsigned i = 0; i < and_insns.length (); i++)\n+\t    {\n+\t      /* However, first we must be sure that we make the\n+\t\t base register from the AND operation available\n+\t\t in case the register has been overwritten.  Copy\n+\t\t the base register to a new pseudo and use that\n+\t\t as the base register of the AND operation in\n+\t\t the new LVX instruction.  */\n+\t      rtx_insn *and_insn = and_insns[i];\n+\t      rtx and_op = and_ops[i];\n+\t      rtx and_base = XEXP (and_op, 0);\n+\t      if (!new_reg)\n+\t\t{\n+\t\t  new_reg = gen_reg_rtx (GET_MODE (and_base));\n+\t\t  and_mask = XEXP (and_op, 1);\n+\t\t}\n+\t      rtx copy = gen_rtx_SET (new_reg, and_base);\n+\t      rtx_insn *new_insn = emit_insn_after (copy, and_insn);\n+\t      set_block_for_insn (new_insn, BLOCK_FOR_INSN (and_insn));\n+\t      df_insn_rescan (new_insn);\n+\t    }\n+\n+\t  XEXP (mem, 0) = gen_rtx_AND (GET_MODE (new_reg), new_reg, and_mask);\n \t  SET_SRC (body) = mem;\n \t  INSN_CODE (insn) = -1; /* Force re-recognition.  */\n \t  df_insn_rescan (insn);\n-\t\t  \n+\n \t  if (dump_file)\n \t    fprintf (dump_file, \"lvx opportunity found at %d\\n\",\n \t\t     INSN_UID (insn));\n@@ -2205,11 +2231,14 @@ recombine_stvx_pattern (rtx_insn *insn, del_info *to_delete)\n   rtx mem = SET_DEST (body);\n   rtx base_reg = XEXP (mem, 0);\n \n-  rtx_insn *and_insn;\n-  rtx and_operation = find_alignment_op (insn, base_reg, &and_insn);\n+  auto_vec<rtx_insn *> and_insns;\n+  auto_vec<rtx> and_ops;\n+  bool is_any_def_and\n+    = find_alignment_op (insn, base_reg, &and_insns, &and_ops);\n \n-  if (and_operation != 0)\n+  if (is_any_def_and)\n     {\n+      gcc_assert (and_insns.length () == and_ops.length ());\n       rtx src_reg = XEXP (SET_SRC (body), 0);\n       df_ref src_use;\n       struct df_insn_info *insn_info = DF_INSN_INFO_GET (insn);\n@@ -2234,25 +2263,35 @@ recombine_stvx_pattern (rtx_insn *insn, del_info *to_delete)\n \t  to_delete[INSN_UID (swap_insn)].replace = true;\n \t  to_delete[INSN_UID (swap_insn)].replace_insn = swap_insn;\n \n-\t  /* However, first we must be sure that we make the\n-\t     base register from the AND operation available\n-\t     in case the register has been overwritten.  Copy\n-\t     the base register to a new pseudo and use that\n-\t     as the base register of the AND operation in\n-\t     the new STVX instruction.  */\n-\t  rtx and_base = XEXP (and_operation, 0);\n-\t  rtx new_reg = gen_reg_rtx (GET_MODE (and_base));\n-\t  rtx copy = gen_rtx_SET (new_reg, and_base);\n-\t  rtx_insn *new_insn = emit_insn_after (copy, and_insn);\n-\t  set_block_for_insn (new_insn, BLOCK_FOR_INSN (and_insn));\n-\t  df_insn_rescan (new_insn);\n-\n-\t  XEXP (mem, 0) = gen_rtx_AND (GET_MODE (and_base), new_reg,\n-\t\t\t\t       XEXP (and_operation, 1));\n+\t  rtx new_reg = 0;\n+\t  rtx and_mask = 0;\n+\t  for (unsigned i = 0; i < and_insns.length (); i++)\n+\t    {\n+\t      /* However, first we must be sure that we make the\n+\t\t base register from the AND operation available\n+\t\t in case the register has been overwritten.  Copy\n+\t\t the base register to a new pseudo and use that\n+\t\t as the base register of the AND operation in\n+\t\t the new STVX instruction.  */\n+\t      rtx_insn *and_insn = and_insns[i];\n+\t      rtx and_op = and_ops[i];\n+\t      rtx and_base = XEXP (and_op, 0);\n+\t      if (!new_reg)\n+\t\t{\n+\t\t  new_reg = gen_reg_rtx (GET_MODE (and_base));\n+\t\t  and_mask = XEXP (and_op, 1);\n+\t\t}\n+\t      rtx copy = gen_rtx_SET (new_reg, and_base);\n+\t      rtx_insn *new_insn = emit_insn_after (copy, and_insn);\n+\t      set_block_for_insn (new_insn, BLOCK_FOR_INSN (and_insn));\n+\t      df_insn_rescan (new_insn);\n+\t    }\n+\n+\t  XEXP (mem, 0) = gen_rtx_AND (GET_MODE (new_reg), new_reg, and_mask);\n \t  SET_SRC (body) = src_reg;\n \t  INSN_CODE (insn) = -1; /* Force re-recognition.  */\n \t  df_insn_rescan (insn);\n-\t\t  \n+\n \t  if (dump_file)\n \t    fprintf (dump_file, \"stvx opportunity found at %d\\n\",\n \t\t     INSN_UID (insn));"}, {"sha": "81b1bda320fe00e55a0af009fc0abe0648e952af", "filename": "gcc/testsuite/gcc.target/powerpc/pr97019.c", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e0d98ffd14487b7105de3d151122144086faa1fa/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpr97019.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e0d98ffd14487b7105de3d151122144086faa1fa/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpr97019.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpr97019.c?ref=e0d98ffd14487b7105de3d151122144086faa1fa", "patch": "@@ -0,0 +1,83 @@\n+/* This issue can only exist on little-endian P8 targets, since\n+   the built-in functions vec_ld/vec_st can use lxvd2x/stxvd2x\n+   (P8 big-endian) or lxv/stxv (P9 and later) for some cases,\n+   those rldicr instructions fed to them are necessary.  */\n+/* { dg-do compile { target { powerpc_p8vector_ok && le } } } */\n+/* { dg-options \"-O2 -mdejagnu-cpu=power8\" } */\n+\n+/* Test there are no useless instructions \"rldicr x,y,0,59\"\n+   to align the addresses for lvx/stvx.  */\n+\n+extern int a, b, c;\n+extern vector unsigned long long ev5, ev6, ev7, ev8;\n+extern int dummy (vector unsigned long long);\n+\n+int test_vec_ld(unsigned char *pe) {\n+\n+  vector unsigned long long v1, v2, v3, v4, v9;\n+  vector unsigned long long v5 = ev5;\n+  vector unsigned long long v6 = ev6;\n+  vector unsigned long long v7 = ev7;\n+  vector unsigned long long v8 = ev8;\n+\n+  unsigned char *e = pe;\n+\n+  do {\n+    if (a) {\n+      v1 = __builtin_vec_ld(16, (unsigned long long *)e);\n+      v2 = __builtin_vec_ld(32, (unsigned long long *)e);\n+      v3 = __builtin_vec_ld(48, (unsigned long long *)e);\n+      e = e + 8;\n+      for (int i = 0; i < a; i++) {\n+        v4 = v5;\n+        v5 = __builtin_crypto_vpmsumd(v1, v6);\n+        v6 = __builtin_crypto_vpmsumd(v2, v7);\n+        v7 = __builtin_crypto_vpmsumd(v3, v8);\n+        e = e + 8;\n+      }\n+    }\n+    v5 = __builtin_vec_ld(16, (unsigned long long *)e);\n+    v6 = __builtin_vec_ld(32, (unsigned long long *)e);\n+    v7 = __builtin_vec_ld(48, (unsigned long long *)e);\n+    if (c)\n+      b = 1;\n+  } while (b);\n+\n+  return dummy(v4);\n+}\n+\n+int test_vec_st(unsigned char *pe) {\n+\n+  vector unsigned long long v1, v2, v3, v4;\n+  vector unsigned long long v5 = ev5;\n+  vector unsigned long long v6 = ev6;\n+  vector unsigned long long v7 = ev7;\n+  vector unsigned long long v8 = ev8;\n+\n+  unsigned char *e = pe;\n+\n+  do {\n+    if (a) {\n+      __builtin_vec_st(v1, 16, (unsigned long long *)e);\n+      __builtin_vec_st(v2, 32, (unsigned long long *)e);\n+      __builtin_vec_st(v3, 48, (unsigned long long *)e);\n+      e = e + 8;\n+      for (int i = 0; i < a; i++) {\n+        v4 = v5;\n+        v5 = __builtin_crypto_vpmsumd(v1, v6);\n+        v6 = __builtin_crypto_vpmsumd(v2, v7);\n+        v7 = __builtin_crypto_vpmsumd(v3, v8);\n+        e = e + 8;\n+      }\n+    }\n+    __builtin_vec_st(v5, 16, (unsigned long long *)e);\n+    __builtin_vec_st(v6, 32, (unsigned long long *)e);\n+    __builtin_vec_st(v7, 48, (unsigned long long *)e);\n+    if (c)\n+      b = 1;\n+  } while (b);\n+\n+  return dummy(v4);\n+}\n+\n+/* { dg-final { scan-assembler-not {(?n)rldicr.*,0,59} } } */"}]}