{"sha": "929b44113eec0c7f5d4a1ab9ff117736760deabe", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTI5YjQ0MTEzZWVjMGM3ZjVkNGExYWI5ZmYxMTc3MzY3NjBkZWFiZQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2018-01-20T13:43:22Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2018-01-20T13:43:22Z"}, "message": "Fix vect_def_type handling in x86 scatter support (PR 83940)\n\nAs Jakub says in the PR, the problem here was that the x86/built-in\nversion of the scatter support was using a bogus scatter_src_dt\nwhen calling vect_get_vec_def_for_stmt_copy (and had since it\nwas added).  The patch uses the vect_def_type from the original\ncall to vect_is_simple_use instead.\n\nHowever, Jakub also pointed out that other parts of the load and store\ncode passed the vector operand rather than the scalar operand to\nvect_is_simple_use.  That probably works most of the time since\na constant scalar operand should give a constant vector operand,\nand likewise for external and internal definitions.  But it\ndefinitely seems more robust to pass the scalar operand.\n\nThe patch avoids the issue for gather and scatter offsets by\nusing the cached gs_info.offset_dt.  This is safe because gathers\nand scatters are never grouped, so there's only one statement operand\nto consider.  The patch also caches the vect_def_type for mask operands,\nwhich is safe because grouped masked operations share the same mask.\n\nThat just leaves the store rhs.  We still need to recalculate the\nvect_def_type there since different store values in the group can\nhave different definition types.  But since we still have access\nto the original scalar operand, it seems better to use that instead.\n\n2018-01-20  Richard Sandiford  <richard.sandiford@linaro.org>\n\ngcc/\n\tPR tree-optimization/83940\n\t* tree-vect-stmts.c (vect_truncate_gather_scatter_offset): Set\n\toffset_dt to vect_constant_def rather than vect_unknown_def_type.\n\t(vect_check_load_store_mask): Add a mask_dt_out parameter and\n\tuse it to pass back the definition type.\n\t(vect_check_store_rhs): Likewise rhs_dt_out.\n\t(vect_build_gather_load_calls): Add a mask_dt argument and use\n\tit instead of a call to vect_is_simple_use.\n\t(vectorizable_store): Update calls to vect_check_load_store_mask\n\tand vect_check_store_rhs.  Use the dt returned by the latter instead\n\tof scatter_src_dt.  Use the cached mask_dt and gs_info.offset_dt\n\tinstead of calls to vect_is_simple_use.  Pass the scalar rather\n\tthan the vector operand to vect_is_simple_use when handling\n\tsecond and subsequent copies of an rhs value.\n\t(vectorizable_load): Update calls to vect_check_load_store_mask\n\tand vect_build_gather_load_calls.  Use the cached mask_dt and\n\tgs_info.offset_dt instead of calls to vect_is_simple_use.\n\ngcc/testsuite/\n\tPR tree-optimization/83940\n\t* gcc.dg/torture/pr83940.c: New test.\n\nFrom-SVN: r256918", "tree": {"sha": "99371e5dda020a3dcdaa7a48e27b182dc9195d50", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/99371e5dda020a3dcdaa7a48e27b182dc9195d50"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/929b44113eec0c7f5d4a1ab9ff117736760deabe", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/929b44113eec0c7f5d4a1ab9ff117736760deabe", "html_url": "https://github.com/Rust-GCC/gccrs/commit/929b44113eec0c7f5d4a1ab9ff117736760deabe", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/929b44113eec0c7f5d4a1ab9ff117736760deabe/comments", "author": null, "committer": null, "parents": [{"sha": "37b7e7873d3a3e79523f4474a330fe41e1a90b36", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/37b7e7873d3a3e79523f4474a330fe41e1a90b36", "html_url": "https://github.com/Rust-GCC/gccrs/commit/37b7e7873d3a3e79523f4474a330fe41e1a90b36"}], "stats": {"total": 133, "additions": 78, "deletions": 55}, "files": [{"sha": "f41e1adf0bd51b9077779087a51ae8fc28e2aa4a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=929b44113eec0c7f5d4a1ab9ff117736760deabe", "patch": "@@ -1,3 +1,23 @@\n+2018-01-20  Richard Sandiford  <richard.sandiford@linaro.org>\n+\n+\tPR tree-optimization/83940\n+\t* tree-vect-stmts.c (vect_truncate_gather_scatter_offset): Set\n+\toffset_dt to vect_constant_def rather than vect_unknown_def_type.\n+\t(vect_check_load_store_mask): Add a mask_dt_out parameter and\n+\tuse it to pass back the definition type.\n+\t(vect_check_store_rhs): Likewise rhs_dt_out.\n+\t(vect_build_gather_load_calls): Add a mask_dt argument and use\n+\tit instead of a call to vect_is_simple_use.\n+\t(vectorizable_store): Update calls to vect_check_load_store_mask\n+\tand vect_check_store_rhs.  Use the dt returned by the latter instead\n+\tof scatter_src_dt.  Use the cached mask_dt and gs_info.offset_dt\n+\tinstead of calls to vect_is_simple_use.  Pass the scalar rather\n+\tthan the vector operand to vect_is_simple_use when handling\n+\tsecond and subsequent copies of an rhs value.\n+\t(vectorizable_load): Update calls to vect_check_load_store_mask\n+\tand vect_build_gather_load_calls.  Use the cached mask_dt and\n+\tgs_info.offset_dt instead of calls to vect_is_simple_use.\n+\n 2018-01-20  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR middle-end/83945"}, {"sha": "7b48adb561b964a357fcc846cf34339363366768", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=929b44113eec0c7f5d4a1ab9ff117736760deabe", "patch": "@@ -1,3 +1,8 @@\n+2018-01-20  Richard Sandiford  <richard.sandiford@linaro.org>\n+\n+\tPR tree-optimization/83940\n+\t* gcc.dg/torture/pr83940.c: New test.\n+\n 2018-01-20  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR middle-end/83945"}, {"sha": "49a00fdcc5bce956f146c9c389a40e2c126d274e", "filename": "gcc/testsuite/gcc.dg/torture/pr83940.c", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr83940.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr83940.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr83940.c?ref=929b44113eec0c7f5d4a1ab9ff117736760deabe", "patch": "@@ -0,0 +1,9 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-mavx512f\" { target { i?86-*-* x86_64-*-* } } } */\n+\n+void\n+foo (double *a[], int b)\n+{\n+  for (; b; b++)\n+    a[b][b] = 1.0;\n+}"}, {"sha": "da76572ce45d9ddd5434e2dd4e886f4f15e0dc61", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 44, "deletions": 55, "changes": 99, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/929b44113eec0c7f5d4a1ab9ff117736760deabe/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=929b44113eec0c7f5d4a1ab9ff117736760deabe", "patch": "@@ -1932,7 +1932,7 @@ vect_truncate_gather_scatter_offset (gimple *stmt, loop_vec_info loop_vinfo,\n \t but we don't need to store that here.  */\n       gs_info->base = NULL_TREE;\n       gs_info->offset = fold_convert (offset_type, step);\n-      gs_info->offset_dt = vect_unknown_def_type;\n+      gs_info->offset_dt = vect_constant_def;\n       gs_info->offset_vectype = NULL_TREE;\n       gs_info->scale = scale;\n       gs_info->memory_type = memory_type;\n@@ -2374,11 +2374,14 @@ get_load_store_type (gimple *stmt, tree vectype, bool slp, bool masked_p,\n }\n \n /* Return true if boolean argument MASK is suitable for vectorizing\n-   conditional load or store STMT.  When returning true, store the\n-   type of the vectorized mask in *MASK_VECTYPE_OUT.  */\n+   conditional load or store STMT.  When returning true, store the type\n+   of the definition in *MASK_DT_OUT and the type of the vectorized mask\n+   in *MASK_VECTYPE_OUT.  */\n \n static bool\n-vect_check_load_store_mask (gimple *stmt, tree mask, tree *mask_vectype_out)\n+vect_check_load_store_mask (gimple *stmt, tree mask,\n+\t\t\t    vect_def_type *mask_dt_out,\n+\t\t\t    tree *mask_vectype_out)\n {\n   if (!VECT_SCALAR_BOOLEAN_TYPE_P (TREE_TYPE (mask)))\n     {\n@@ -2398,9 +2401,9 @@ vect_check_load_store_mask (gimple *stmt, tree mask, tree *mask_vectype_out)\n \n   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n   gimple *def_stmt;\n-  enum vect_def_type dt;\n+  enum vect_def_type mask_dt;\n   tree mask_vectype;\n-  if (!vect_is_simple_use (mask, stmt_info->vinfo, &def_stmt, &dt,\n+  if (!vect_is_simple_use (mask, stmt_info->vinfo, &def_stmt, &mask_dt,\n \t\t\t   &mask_vectype))\n     {\n       if (dump_enabled_p ())\n@@ -2437,18 +2440,19 @@ vect_check_load_store_mask (gimple *stmt, tree mask, tree *mask_vectype_out)\n       return false;\n     }\n \n+  *mask_dt_out = mask_dt;\n   *mask_vectype_out = mask_vectype;\n   return true;\n }\n \n /* Return true if stored value RHS is suitable for vectorizing store\n    statement STMT.  When returning true, store the type of the\n-   vectorized store value in *RHS_VECTYPE_OUT and the type of the\n-   store in *VLS_TYPE_OUT.  */\n+   definition in *RHS_DT_OUT, the type of the vectorized store value in\n+   *RHS_VECTYPE_OUT and the type of the store in *VLS_TYPE_OUT.  */\n \n static bool\n-vect_check_store_rhs (gimple *stmt, tree rhs, tree *rhs_vectype_out,\n-\t\t      vec_load_store_type *vls_type_out)\n+vect_check_store_rhs (gimple *stmt, tree rhs, vect_def_type *rhs_dt_out,\n+\t\t      tree *rhs_vectype_out, vec_load_store_type *vls_type_out)\n {\n   /* In the case this is a store from a constant make sure\n      native_encode_expr can handle it.  */\n@@ -2462,9 +2466,9 @@ vect_check_store_rhs (gimple *stmt, tree rhs, tree *rhs_vectype_out,\n \n   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n   gimple *def_stmt;\n-  enum vect_def_type dt;\n+  enum vect_def_type rhs_dt;\n   tree rhs_vectype;\n-  if (!vect_is_simple_use (rhs, stmt_info->vinfo, &def_stmt, &dt,\n+  if (!vect_is_simple_use (rhs, stmt_info->vinfo, &def_stmt, &rhs_dt,\n \t\t\t   &rhs_vectype))\n     {\n       if (dump_enabled_p ())\n@@ -2482,8 +2486,9 @@ vect_check_store_rhs (gimple *stmt, tree rhs, tree *rhs_vectype_out,\n       return false;\n     }\n \n+  *rhs_dt_out = rhs_dt;\n   *rhs_vectype_out = rhs_vectype;\n-  if (dt == vect_constant_def || dt == vect_external_def)\n+  if (rhs_dt == vect_constant_def || rhs_dt == vect_external_def)\n     *vls_type_out = VLS_STORE_INVARIANT;\n   else\n     *vls_type_out = VLS_STORE;\n@@ -2546,12 +2551,12 @@ vect_build_zero_merge_argument (gimple *stmt, tree vectype)\n /* Build a gather load call while vectorizing STMT.  Insert new instructions\n    before GSI and add them to VEC_STMT.  GS_INFO describes the gather load\n    operation.  If the load is conditional, MASK is the unvectorized\n-   condition, otherwise MASK is null.  */\n+   condition and MASK_DT is its definition type, otherwise MASK is null.  */\n \n static void\n vect_build_gather_load_calls (gimple *stmt, gimple_stmt_iterator *gsi,\n \t\t\t      gimple **vec_stmt, gather_scatter_info *gs_info,\n-\t\t\t      tree mask)\n+\t\t\t      tree mask, vect_def_type mask_dt)\n {\n   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n   loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n@@ -2682,12 +2687,7 @@ vect_build_gather_load_calls (gimple *stmt, gimple_stmt_iterator *gsi,\n \t      if (j == 0)\n \t\tvec_mask = vect_get_vec_def_for_operand (mask, stmt);\n \t      else\n-\t\t{\n-\t\t  gimple *def_stmt;\n-\t\t  enum vect_def_type dt;\n-\t\t  vect_is_simple_use (vec_mask, loop_vinfo, &def_stmt, &dt);\n-\t\t  vec_mask = vect_get_vec_def_for_stmt_copy (dt, vec_mask);\n-\t\t}\n+\t\tvec_mask = vect_get_vec_def_for_stmt_copy (mask_dt, vec_mask);\n \n \t      mask_op = vec_mask;\n \t      if (!useless_type_conversion_p (masktype, TREE_TYPE (vec_mask)))\n@@ -6057,7 +6057,8 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n   tree dummy;\n   enum dr_alignment_support alignment_support_scheme;\n   gimple *def_stmt;\n-  enum vect_def_type dt;\n+  enum vect_def_type rhs_dt = vect_unknown_def_type;\n+  enum vect_def_type mask_dt = vect_unknown_def_type;\n   stmt_vec_info prev_stmt_info = NULL;\n   tree dataref_ptr = NULL_TREE;\n   tree dataref_offset = NULL_TREE;\n@@ -6078,7 +6079,6 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n   vec_info *vinfo = stmt_info->vinfo;\n   tree aggr_type;\n   gather_scatter_info gs_info;\n-  enum vect_def_type scatter_src_dt = vect_unknown_def_type;\n   gimple *new_stmt;\n   poly_uint64 vf;\n   vec_load_store_type vls_type;\n@@ -6131,7 +6131,8 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n       if (mask_index >= 0)\n \t{\n \t  mask = gimple_call_arg (call, mask_index);\n-\t  if (!vect_check_load_store_mask (stmt, mask, &mask_vectype))\n+\t  if (!vect_check_load_store_mask (stmt, mask, &mask_dt,\n+\t\t\t\t\t   &mask_vectype))\n \t    return false;\n \t}\n     }\n@@ -6172,7 +6173,7 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n       return false;\n     }\n \n-  if (!vect_check_store_rhs (stmt, op, &rhs_vectype, &vls_type))\n+  if (!vect_check_store_rhs (stmt, op, &rhs_dt, &rhs_vectype, &vls_type))\n     return false;\n \n   elem_type = TREE_TYPE (vectype);\n@@ -6339,7 +6340,7 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t      if (modifier == WIDEN)\n \t\t{\n \t\t  src = vec_oprnd1\n-\t\t    = vect_get_vec_def_for_stmt_copy (scatter_src_dt, vec_oprnd1);\n+\t\t    = vect_get_vec_def_for_stmt_copy (rhs_dt, vec_oprnd1);\n \t\t  op = permute_vec_elements (vec_oprnd0, vec_oprnd0, perm_mask,\n \t\t\t\t\t     stmt, gsi);\n \t\t}\n@@ -6357,7 +6358,7 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t  else\n \t    {\n \t      src = vec_oprnd1\n-\t\t= vect_get_vec_def_for_stmt_copy (scatter_src_dt, vec_oprnd1);\n+\t\t= vect_get_vec_def_for_stmt_copy (rhs_dt, vec_oprnd1);\n \t      op = vec_oprnd0\n \t\t= vect_get_vec_def_for_stmt_copy (gs_info.offset_dt,\n \t\t\t\t\t\t  vec_oprnd0);\n@@ -6616,8 +6617,9 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t\t    vec_oprnd = vec_oprnds[j];\n \t\t  else\n \t\t    {\n-\t\t      vect_is_simple_use (vec_oprnd, vinfo, &def_stmt, &dt);\n-\t\t      vec_oprnd = vect_get_vec_def_for_stmt_copy (dt, vec_oprnd);\n+\t\t      vect_is_simple_use (op, vinfo, &def_stmt, &rhs_dt);\n+\t\t      vec_oprnd = vect_get_vec_def_for_stmt_copy (rhs_dt,\n+\t\t\t\t\t\t\t\t  vec_oprnd);\n \t\t    }\n \t\t}\n \t      /* Pun the vector to extract from if necessary.  */\n@@ -6858,26 +6860,19 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t  for (i = 0; i < group_size; i++)\n \t    {\n \t      op = oprnds[i];\n-\t      vect_is_simple_use (op, vinfo, &def_stmt, &dt);\n-\t      vec_oprnd = vect_get_vec_def_for_stmt_copy (dt, op);\n+\t      vect_is_simple_use (op, vinfo, &def_stmt, &rhs_dt);\n+\t      vec_oprnd = vect_get_vec_def_for_stmt_copy (rhs_dt, op);\n \t      dr_chain[i] = vec_oprnd;\n \t      oprnds[i] = vec_oprnd;\n \t    }\n \t  if (mask)\n-\t    {\n-\t      vect_is_simple_use (vec_mask, vinfo, &def_stmt, &dt);\n-\t      vec_mask = vect_get_vec_def_for_stmt_copy (dt, vec_mask);\n-\t    }\n+\t    vec_mask = vect_get_vec_def_for_stmt_copy (mask_dt, vec_mask);\n \t  if (dataref_offset)\n \t    dataref_offset\n \t      = int_const_binop (PLUS_EXPR, dataref_offset, bump);\n \t  else if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n-\t    {\n-\t      gimple *def_stmt;\n-\t      vect_def_type dt;\n-\t      vect_is_simple_use (vec_offset, loop_vinfo, &def_stmt, &dt);\n-\t      vec_offset = vect_get_vec_def_for_stmt_copy (dt, vec_offset);\n-\t    }\n+\t    vec_offset = vect_get_vec_def_for_stmt_copy (gs_info.offset_dt,\n+\t\t\t\t\t\t\t vec_offset);\n \t  else\n \t    dataref_ptr = bump_vector_ptr (dataref_ptr, ptr_incr, gsi, stmt,\n \t\t\t\t\t   bump);\n@@ -7238,6 +7233,7 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n   gather_scatter_info gs_info;\n   vec_info *vinfo = stmt_info->vinfo;\n   tree ref_type;\n+  enum vect_def_type mask_dt = vect_unknown_def_type;\n \n   if (!STMT_VINFO_RELEVANT_P (stmt_info) && !bb_vinfo)\n     return false;\n@@ -7290,7 +7286,8 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n       if (mask_index >= 0)\n \t{\n \t  mask = gimple_call_arg (call, mask_index);\n-\t  if (!vect_check_load_store_mask (stmt, mask, &mask_vectype))\n+\t  if (!vect_check_load_store_mask (stmt, mask, &mask_dt,\n+\t\t\t\t\t   &mask_vectype))\n \t    return false;\n \t}\n     }\n@@ -7472,7 +7469,8 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \n   if (memory_access_type == VMAT_GATHER_SCATTER && gs_info.decl)\n     {\n-      vect_build_gather_load_calls (stmt, gsi, vec_stmt, &gs_info, mask);\n+      vect_build_gather_load_calls (stmt, gsi, vec_stmt, &gs_info, mask,\n+\t\t\t\t    mask_dt);\n       return true;\n     }\n \n@@ -7999,22 +7997,13 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t    dataref_offset = int_const_binop (PLUS_EXPR, dataref_offset,\n \t\t\t\t\t      bump);\n \t  else if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n-\t    {\n-\t      gimple *def_stmt;\n-\t      vect_def_type dt;\n-\t      vect_is_simple_use (vec_offset, loop_vinfo, &def_stmt, &dt);\n-\t      vec_offset = vect_get_vec_def_for_stmt_copy (dt, vec_offset);\n-\t    }\n+\t    vec_offset = vect_get_vec_def_for_stmt_copy (gs_info.offset_dt,\n+\t\t\t\t\t\t\t vec_offset);\n \t  else\n \t    dataref_ptr = bump_vector_ptr (dataref_ptr, ptr_incr, gsi,\n \t\t\t\t\t   stmt, bump);\n \t  if (mask)\n-\t    {\n-\t      gimple *def_stmt;\n-\t      vect_def_type dt;\n-\t      vect_is_simple_use (vec_mask, vinfo, &def_stmt, &dt);\n-\t      vec_mask = vect_get_vec_def_for_stmt_copy (dt, vec_mask);\n-\t    }\n+\t    vec_mask = vect_get_vec_def_for_stmt_copy (mask_dt, vec_mask);\n \t}\n \n       if (grouped_load || slp_perm)"}]}