{"sha": "a82ffd436193d97b0b47441f540e61001f16a682", "node_id": "C_kwDOANBUbNoAKGE4MmZmZDQzNjE5M2Q5N2IwYjQ3NDQxZjU0MGU2MTAwMWYxNmE2ODI", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-11-12T17:33:02Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-11-12T17:33:02Z"}, "message": "aarch64: Move cycle estimation into aarch64_vec_op_count\n\nThis patch just moves the main cycle estimation routines\ninto aarch64_vec_op_count.\n\ngcc/\n\t* config/aarch64/aarch64.c\n\t(aarch64_vec_op_count::rename_cycles_per_iter): New function.\n\t(aarch64_vec_op_count::min_nonpred_cycles_per_iter): Likewise.\n\t(aarch64_vec_op_count::min_pred_cycles_per_iter): Likewise.\n\t(aarch64_vec_op_count::min_cycles_per_iter): Likewise.\n\t(aarch64_vec_op_count::dump): Move earlier in file.  Dump the\n\tabove properties too.\n\t(aarch64_estimate_min_cycles_per_iter): Delete.\n\t(adjust_body_cost): Use aarch64_vec_op_count::min_cycles_per_iter\n\tinstead of aarch64_estimate_min_cycles_per_iter.  Rely on the dump\n\troutine to print CPI estimates.\n\t(adjust_body_cost_sve): Likewise.  Use the other functions above\n\tinstead of doing the work inline.", "tree": {"sha": "fc39f70b5adab3a23610d73819195714abf1d875", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/fc39f70b5adab3a23610d73819195714abf1d875"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a82ffd436193d97b0b47441f540e61001f16a682", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a82ffd436193d97b0b47441f540e61001f16a682", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a82ffd436193d97b0b47441f540e61001f16a682", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a82ffd436193d97b0b47441f540e61001f16a682/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1a5288fe3dcaa1eb5398ed28b0765f8dad9a1b2a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1a5288fe3dcaa1eb5398ed28b0765f8dad9a1b2a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1a5288fe3dcaa1eb5398ed28b0765f8dad9a1b2a"}], "stats": {"total": 203, "additions": 105, "deletions": 98}, "files": [{"sha": "241cef8c5d9b218732c38bce318b13abc0f9e504", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 105, "deletions": 98, "changes": 203, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a82ffd436193d97b0b47441f540e61001f16a682/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a82ffd436193d97b0b47441f540e61001f16a682/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=a82ffd436193d97b0b47441f540e61001f16a682", "patch": "@@ -14718,6 +14718,11 @@ class aarch64_vec_op_count\n   const aarch64_simd_vec_issue_info *simd_issue_info () const;\n   const aarch64_sve_vec_issue_info *sve_issue_info () const;\n \n+  fractional_cost rename_cycles_per_iter () const;\n+  fractional_cost min_nonpred_cycles_per_iter () const;\n+  fractional_cost min_pred_cycles_per_iter () const;\n+  fractional_cost min_cycles_per_iter () const;\n+\n   void dump () const;\n \n   /* The number of individual \"general\" operations.  See the comments\n@@ -14791,6 +14796,95 @@ aarch64_vec_op_count::sve_issue_info () const\n   return nullptr;\n }\n \n+/* Estimate the minimum number of cycles per iteration needed to rename\n+   the instructions.\n+\n+   ??? For now this is done inline rather than via cost tables, since it\n+   isn't clear how it should be parameterized for the general case.  */\n+fractional_cost\n+aarch64_vec_op_count::rename_cycles_per_iter () const\n+{\n+  if (sve_issue_info () == &neoverse512tvb_sve_issue_info)\n+    /* + 1 for an addition.  We've already counted a general op for each\n+       store, so we don't need to account for stores separately.  The branch\n+       reads no registers and so does not need to be counted either.\n+\n+       ??? This value is very much on the pessimistic side, but seems to work\n+       pretty well in practice.  */\n+    return { general_ops + loads + pred_ops + 1, 5 };\n+\n+  return 0;\n+}\n+\n+/* Like min_cycles_per_iter, but excluding predicate operations.  */\n+fractional_cost\n+aarch64_vec_op_count::min_nonpred_cycles_per_iter () const\n+{\n+  auto *issue_info = base_issue_info ();\n+\n+  fractional_cost cycles = MAX (reduction_latency, 1);\n+  cycles = std::max (cycles, { stores, issue_info->stores_per_cycle });\n+  cycles = std::max (cycles, { loads + stores,\n+\t\t\t       issue_info->loads_stores_per_cycle });\n+  cycles = std::max (cycles, { general_ops,\n+\t\t\t       issue_info->general_ops_per_cycle });\n+  cycles = std::max (cycles, rename_cycles_per_iter ());\n+  return cycles;\n+}\n+\n+/* Like min_cycles_per_iter, but including only the predicate operations.  */\n+fractional_cost\n+aarch64_vec_op_count::min_pred_cycles_per_iter () const\n+{\n+  if (auto *issue_info = sve_issue_info ())\n+    return { pred_ops, issue_info->pred_ops_per_cycle };\n+  return 0;\n+}\n+\n+/* Estimate the minimum number of cycles needed to issue the operations.\n+   This is a very simplistic model!  */\n+fractional_cost\n+aarch64_vec_op_count::min_cycles_per_iter () const\n+{\n+  return std::max (min_nonpred_cycles_per_iter (),\n+\t\t   min_pred_cycles_per_iter ());\n+}\n+\n+/* Dump information about the structure.  */\n+void\n+aarch64_vec_op_count::dump () const\n+{\n+  dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t   \"  load operations = %d\\n\", loads);\n+  dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t   \"  store operations = %d\\n\", stores);\n+  dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t   \"  general operations = %d\\n\", general_ops);\n+  if (sve_issue_info ())\n+    dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t     \"  predicate operations = %d\\n\", pred_ops);\n+  dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t   \"  reduction latency = %d\\n\", reduction_latency);\n+  if (auto rcpi = rename_cycles_per_iter ())\n+    dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t     \"  estimated cycles per iteration to rename = %f\\n\",\n+\t\t     rcpi.as_double ());\n+  if (auto pred_cpi = min_pred_cycles_per_iter ())\n+    {\n+      dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t       \"  estimated min cycles per iteration\"\n+\t\t       \" without predication = %f\\n\",\n+\t\t       min_nonpred_cycles_per_iter ().as_double ());\n+      dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t       \"  estimated min cycles per iteration\"\n+\t\t       \" for predication = %f\\n\", pred_cpi.as_double ());\n+    }\n+  if (auto cpi = min_cycles_per_iter ())\n+    dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t     \"  estimated min cycles per iteration = %f\\n\",\n+\t\t     cpi.as_double ());\n+}\n+\n /* Information about vector code that we're in the process of costing.  */\n class aarch64_vector_costs : public vector_costs\n {\n@@ -15813,38 +15907,6 @@ aarch64_vector_costs::add_stmt_cost (int count, vect_cost_for_stmt kind,\n   return record_stmt_cost (stmt_info, where, (count * stmt_cost).ceil ());\n }\n \n-/* Dump information about the structure.  */\n-void\n-aarch64_vec_op_count::dump () const\n-{\n-  dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t   \"  load operations = %d\\n\", loads);\n-  dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t   \"  store operations = %d\\n\", stores);\n-  dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t   \"  general operations = %d\\n\", general_ops);\n-  if (sve_issue_info ())\n-    dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t     \"  predicate operations = %d\\n\", pred_ops);\n-  dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t   \"  reduction latency = %d\\n\", reduction_latency);\n-}\n-\n-/* Estimate the minimum number of cycles needed to issue the operations\n-   described by OPS.  This is a very simplistic model!  */\n-static fractional_cost\n-aarch64_estimate_min_cycles_per_iter (const aarch64_vec_op_count *ops)\n-{\n-  auto *issue_info = ops->base_issue_info ();\n-  fractional_cost cycles = MAX (ops->reduction_latency, 1);\n-  cycles = std::max (cycles, { ops->stores, issue_info->stores_per_cycle });\n-  cycles = std::max (cycles, { ops->loads + ops->stores,\n-\t\t\t       issue_info->loads_stores_per_cycle });\n-  cycles = std::max (cycles, { ops->general_ops,\n-\t\t\t       issue_info->general_ops_per_cycle });\n-  return cycles;\n-}\n-\n /* Subroutine of adjust_body_cost for handling SVE.  Use ISSUE_INFO to work out\n    how fast the SVE code can be issued and compare it to the equivalent value\n    for scalar code (SCALAR_CYCLES_PER_ITER).  If COULD_USE_ADVSIMD is true,\n@@ -15863,60 +15925,13 @@ adjust_body_cost_sve (const aarch64_vec_op_count *ops,\n \t\t      bool could_use_advsimd, unsigned int orig_body_cost,\n \t\t      unsigned int *body_cost, bool *should_disparage)\n {\n-  auto *issue_info = ops->sve_issue_info ();\n-\n-  /* Estimate the minimum number of cycles per iteration needed to issue\n-     non-predicate operations.  */\n-  fractional_cost sve_nonpred_issue_cycles_per_iter\n-    = aarch64_estimate_min_cycles_per_iter (ops);\n-\n-  /* Estimate the minimum number of cycles per iteration needed to rename\n-     SVE instructions.\n-\n-     ??? For now this is done inline rather than via cost tables, since it\n-     isn't clear how it should be parameterized for the general case.  */\n-  fractional_cost sve_rename_cycles_per_iter = 0;\n-  if (issue_info == &neoverse512tvb_sve_issue_info)\n-    /* + 1 for an addition.  We've already counted a general op for each\n-       store, so we don't need to account for stores separately.  The branch\n-       reads no registers and so does not need to be counted either.\n-\n-       ??? This value is very much on the pessimistic side, but seems to work\n-       pretty well in practice.  */\n-    sve_rename_cycles_per_iter\n-      = { ops->general_ops + ops->loads + ops->pred_ops + 1, 5 };\n+  if (dump_enabled_p ())\n+    ops->dump ();\n \n-  /* Combine the rename and non-predicate issue limits into a single value.  */\n   fractional_cost sve_nonpred_cycles_per_iter\n-    = std::max (sve_nonpred_issue_cycles_per_iter, sve_rename_cycles_per_iter);\n-\n-  /* Separately estimate the minimum number of cycles per iteration needed\n-     to issue the predicate operations.  */\n-  fractional_cost sve_pred_issue_cycles_per_iter\n-    = { ops->pred_ops, issue_info->pred_ops_per_cycle };\n-\n-  /* Calculate the overall limit on the number of cycles per iteration.  */\n-  fractional_cost sve_cycles_per_iter\n-    = std::max (sve_nonpred_cycles_per_iter, sve_pred_issue_cycles_per_iter);\n-\n-  if (dump_enabled_p ())\n-    {\n-      ops->dump ();\n-      dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t       \"  estimated cycles per iteration = %f\\n\",\n-\t\t       sve_cycles_per_iter.as_double ());\n-      if (ops->pred_ops)\n-\tdump_printf_loc (MSG_NOTE, vect_location,\n-\t\t\t \"    predicate issue = %f\\n\",\n-\t\t\t sve_pred_issue_cycles_per_iter.as_double ());\n-      if (ops->pred_ops || sve_rename_cycles_per_iter)\n-\tdump_printf_loc (MSG_NOTE, vect_location,\n-\t\t\t \"    non-predicate issue = %f\\n\",\n-\t\t\t sve_nonpred_issue_cycles_per_iter.as_double ());\n-      if (sve_rename_cycles_per_iter)\n-\tdump_printf_loc (MSG_NOTE, vect_location, \"    rename = %f\\n\",\n-\t\t\t sve_rename_cycles_per_iter.as_double ());\n-    }\n+    = ops->min_nonpred_cycles_per_iter ();\n+  fractional_cost sve_pred_cycles_per_iter = ops->min_pred_cycles_per_iter ();\n+  fractional_cost sve_cycles_per_iter = ops->min_cycles_per_iter ();\n \n   /* If the scalar version of the loop could issue at least as\n      quickly as the predicate parts of the SVE loop, make the SVE loop\n@@ -15928,7 +15943,7 @@ adjust_body_cost_sve (const aarch64_vec_op_count *ops,\n      costs would not model.  Adding this kind of cliffedge would be\n      too drastic for scalar_cycles_per_iter vs. sve_cycles_per_iter;\n      code in the caller handles that case in a more conservative way.  */\n-  fractional_cost sve_estimate = sve_pred_issue_cycles_per_iter + 1;\n+  fractional_cost sve_estimate = sve_pred_cycles_per_iter + 1;\n   if (scalar_cycles_per_iter < sve_estimate)\n     {\n       unsigned int min_cost\n@@ -15954,7 +15969,7 @@ adjust_body_cost_sve (const aarch64_vec_op_count *ops,\n \n      The reasoning is similar to the scalar vs. predicate comparison above:\n      if the issue rate of the SVE code is limited by predicate operations\n-     (i.e. if sve_pred_issue_cycles_per_iter > sve_nonpred_cycles_per_iter),\n+     (i.e. if sve_pred_cycles_per_iter > sve_nonpred_cycles_per_iter),\n      and if the Advanced SIMD code could issue within the limit imposed\n      by the predicate operations, the predicate operations are adding an\n      overhead that the original code didn't have and so we should prefer\n@@ -15963,7 +15978,7 @@ adjust_body_cost_sve (const aarch64_vec_op_count *ops,\n      the SVE code if sve_cycles_per_iter is strictly greater than\n      advsimd_cycles_per_iter.  Given rounding effects, this should mean\n      that Advanced SIMD is either better or at least no worse.  */\n-  if (sve_nonpred_cycles_per_iter >= sve_pred_issue_cycles_per_iter)\n+  if (sve_nonpred_cycles_per_iter >= sve_pred_cycles_per_iter)\n     sve_estimate = sve_cycles_per_iter;\n   if (could_use_advsimd && advsimd_cycles_per_iter < sve_estimate)\n     {\n@@ -16042,11 +16057,9 @@ adjust_body_cost (loop_vec_info loop_vinfo,\n     }\n \n   fractional_cost scalar_cycles_per_iter\n-    = aarch64_estimate_min_cycles_per_iter (&scalar_ops);\n-  scalar_cycles_per_iter *= estimated_vf;\n+    = scalar_ops.min_cycles_per_iter () * estimated_vf;\n \n-  fractional_cost vector_cycles_per_iter\n-    = aarch64_estimate_min_cycles_per_iter (&vector_ops);\n+  fractional_cost vector_cycles_per_iter = vector_ops.min_cycles_per_iter ();\n \n   if (dump_enabled_p ())\n     {\n@@ -16071,17 +16084,14 @@ adjust_body_cost (loop_vec_info loop_vinfo,\n \t   && !m_saw_sve_only_op);\n \n       fractional_cost advsimd_cycles_per_iter\n-\t= aarch64_estimate_min_cycles_per_iter (&m_advsimd_ops[0]);\n+\t= m_advsimd_ops[0].min_cycles_per_iter ();\n       if (dump_enabled_p ())\n \t{\n \t  if (could_use_advsimd)\n \t    {\n \t      dump_printf_loc (MSG_NOTE, vect_location,\n \t\t\t       \"Advanced SIMD issue estimate:\\n\");\n \t      m_advsimd_ops[0].dump ();\n-\t      dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t\t       \"  estimated cycles per iteration = %f\\n\",\n-\t\t\t       advsimd_cycles_per_iter.as_double ());\n \t    }\n \t  else\n \t    dump_printf_loc (MSG_NOTE, vect_location,\n@@ -16114,9 +16124,6 @@ adjust_body_cost (loop_vec_info loop_vinfo,\n \t  dump_printf_loc (MSG_NOTE, vect_location,\n \t\t\t   \"Vector issue estimate:\\n\");\n \t  vector_ops.dump ();\n-\t  dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t\t   \"  estimated cycles per iteration = %f\\n\",\n-\t\t\t   vector_cycles_per_iter.as_double ());\n \t}\n     }\n "}]}