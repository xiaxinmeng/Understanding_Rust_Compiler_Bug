{"sha": "ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2E5YjI2NGU0MTVjYTEzY2M0ZmYxYjNlZjkzOTI2YjA2MmVmNmFiMQ==", "commit": {"author": {"name": "Alexander Ivchenko", "email": "alexander.ivchenko@intel.com", "date": "2014-08-27T11:31:51Z"}, "committer": {"name": "Kirill Yukhin", "email": "kyukhin@gcc.gnu.org", "date": "2014-08-27T11:31:51Z"}, "message": "sse.md (define_mode_iterator VI48_AVX512VL): New.\n\ngcc/\n        * config/i386/sse.md\n\t(define_mode_iterator VI48_AVX512VL): New.\n\t(define_mode_iterator VI_UNALIGNED_LOADSTORE): Delete.\n\t(define_mode_iterator VI_ULOADSTORE_BW_AVX512VL): New.\n\t(define_mode_iterator VI_ULOADSTORE_F_AVX512VL): Ditto.\n\t(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n\twith VI1): Change mode iterator.\n\t(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n\twith VI_ULOADSTORE_BW_AVX512VL): New.\n\t(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n\twith VI_ULOADSTORE_F_AVX512VL): Ditto.\n\t(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n\twith VI1): Change mode iterator.\n\t(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n\twith VI_ULOADSTORE_BW_AVX512VL): New.\n\t(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n\twith VI_ULOADSTORE_F_AVX512VL): Ditto.\n\t(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\n\twith VI1): Change mode iterator.\n\t(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\n\twith VI_ULOADSTORE_BW_AVX512VL): New.\n\t(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\n\twith VI_ULOADSTORE_BW_AVX512VL): Ditto.\n\t(define_insn \"avx512f_storedqu<mode>_mask\"): Delete.\n\t(define_insn \"<avx512>_storedqu<mode>_mask\" with\n\tVI48_AVX512VL): New.\n\t(define_insn \"<avx512>_storedqu<mode>_mask\" with\n\tVI12_AVX512VL): Ditto.\n\n\nCo-Authored-By: Andrey Turetskiy <andrey.turetskiy@intel.com>\nCo-Authored-By: Anna Tikhonova <anna.tikhonova@intel.com>\nCo-Authored-By: Ilya Tocar <ilya.tocar@intel.com>\nCo-Authored-By: Ilya Verbin <ilya.verbin@intel.com>\nCo-Authored-By: Kirill Yukhin <kirill.yukhin@intel.com>\nCo-Authored-By: Maxim Kuznetsov <maxim.kuznetsov@intel.com>\nCo-Authored-By: Michael Zolotukhin <michael.v.zolotukhin@intel.com>\n\nFrom-SVN: r214570", "tree": {"sha": "cc1bde5d5b1a62f1b9bc4926106e9a85fc17efe3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/cc1bde5d5b1a62f1b9bc4926106e9a85fc17efe3"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1/comments", "author": null, "committer": null, "parents": [{"sha": "38f4b55004b0e6c7ffc5a8138db457ce5df12ff1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/38f4b55004b0e6c7ffc5a8138db457ce5df12ff1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/38f4b55004b0e6c7ffc5a8138db457ce5df12ff1"}], "stats": {"total": 228, "additions": 186, "deletions": 42}, "files": [{"sha": "5ccfd6e206ee385df66f889c33bef60ba639fab0", "filename": "gcc/ChangeLog", "status": "modified", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1", "patch": "@@ -1,3 +1,41 @@\n+2014-08-27  Alexander Ivchenko  <alexander.ivchenko@intel.com>\n+\t    Maxim Kuznetsov  <maxim.kuznetsov@intel.com>\n+\t    Anna Tikhonova  <anna.tikhonova@intel.com>\n+\t    Ilya Tocar  <ilya.tocar@intel.com>\n+\t    Andrey Turetskiy  <andrey.turetskiy@intel.com>\n+\t    Ilya Verbin  <ilya.verbin@intel.com>\n+\t    Kirill Yukhin  <kirill.yukhin@intel.com>\n+\t    Michael Zolotukhin  <michael.v.zolotukhin@intel.com>\n+\n+        * config/i386/sse.md\n+\t(define_mode_iterator VI48_AVX512VL): New.\n+\t(define_mode_iterator VI_UNALIGNED_LOADSTORE): Delete.\n+\t(define_mode_iterator VI_ULOADSTORE_BW_AVX512VL): New.\n+\t(define_mode_iterator VI_ULOADSTORE_F_AVX512VL): Ditto.\n+\t(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+\twith VI1): Change mode iterator.\n+\t(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+\twith VI_ULOADSTORE_BW_AVX512VL): New.\n+\t(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+\twith VI_ULOADSTORE_F_AVX512VL): Ditto.\n+\t(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+\twith VI1): Change mode iterator.\n+\t(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+\twith VI_ULOADSTORE_BW_AVX512VL): New.\n+\t(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+\twith VI_ULOADSTORE_F_AVX512VL): Ditto.\n+\t(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\n+\twith VI1): Change mode iterator.\n+\t(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\n+\twith VI_ULOADSTORE_BW_AVX512VL): New.\n+\t(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\n+\twith VI_ULOADSTORE_BW_AVX512VL): Ditto.\n+\t(define_insn \"avx512f_storedqu<mode>_mask\"): Delete.\n+\t(define_insn \"<avx512>_storedqu<mode>_mask\" with\n+\tVI48_AVX512VL): New.\n+\t(define_insn \"<avx512>_storedqu<mode>_mask\" with\n+\tVI12_AVX512VL): Ditto.\n+\n 2014-08-27  Alexander Ivchenko  <alexander.ivchenko@intel.com>\n \t    Maxim Kuznetsov  <maxim.kuznetsov@intel.com>\n \t    Anna Tikhonova  <anna.tikhonova@intel.com>"}, {"sha": "2fac897fb4d48049851f09012f818cfa61fd7f40", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 148, "deletions": 42, "changes": 190, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=ca9b264e415ca13cc4ff1b3ef93926b062ef6ab1", "patch": "@@ -235,6 +235,10 @@\n (define_mode_iterator VF_512\n   [V16SF V8DF])\n \n+(define_mode_iterator VI48_AVX512VL\n+  [V16SI (V8SI  \"TARGET_AVX512VL\") (V4SI  \"TARGET_AVX512VL\")\n+   V8DI  (V4DI  \"TARGET_AVX512VL\") (V2DI  \"TARGET_AVX512VL\")])\n+\n (define_mode_iterator VF2_AVX512VL\n   [V8DF (V4DF \"TARGET_AVX512VL\") (V2DF \"TARGET_AVX512VL\")])\n \n@@ -259,9 +263,13 @@\n (define_mode_iterator VI1\n   [(V32QI \"TARGET_AVX\") V16QI])\n \n-(define_mode_iterator VI_UNALIGNED_LOADSTORE\n-  [(V32QI \"TARGET_AVX\") V16QI\n-   (V16SI \"TARGET_AVX512F\") (V8DI \"TARGET_AVX512F\")])\n+(define_mode_iterator VI_ULOADSTORE_BW_AVX512VL\n+  [V64QI\n+   V32HI (V8HI \"TARGET_AVX512VL\") (V16HI \"TARGET_AVX512VL\")])\n+\n+(define_mode_iterator VI_ULOADSTORE_F_AVX512VL\n+  [V16SI (V8SI \"TARGET_AVX512VL\") (V4SI \"TARGET_AVX512VL\")\n+   V8DI (V4DI \"TARGET_AVX512VL\") (V2DI \"TARGET_AVX512VL\")])\n \n ;; All DImode vector integer modes\n (define_mode_iterator VI8\n@@ -1167,18 +1175,18 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+/* For AVX, normal *mov<mode>_internal pattern will handle unaligned loads\n+   just fine if misaligned_operand is true, and without the UNSPEC it can\n+   be combined with arithmetic instructions.  If misaligned_operand is\n+   false, still emit UNSPEC_LOADU insn to honor user's request for\n+   misaligned load.  */\n (define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n-  [(set (match_operand:VI_UNALIGNED_LOADSTORE 0 \"register_operand\")\n-\t(unspec:VI_UNALIGNED_LOADSTORE\n-\t  [(match_operand:VI_UNALIGNED_LOADSTORE 1 \"nonimmediate_operand\")]\n+  [(set (match_operand:VI1 0 \"register_operand\")\n+\t(unspec:VI1\n+\t  [(match_operand:VI1 1 \"nonimmediate_operand\")]\n \t  UNSPEC_LOADU))]\n-  \"TARGET_SSE2 && <mask_mode512bit_condition>\"\n+  \"TARGET_SSE2 && <mask_avx512vl_condition> && <mask_avx512bw_condition>\"\n {\n-  /* For AVX, normal *mov<mode>_internal pattern will handle unaligned loads\n-     just fine if misaligned_operand is true, and without the UNSPEC it can\n-     be combined with arithmetic instructions.  If misaligned_operand is\n-     false, still emit UNSPEC_LOADU insn to honor user's request for\n-     misaligned load.  */\n   if (TARGET_AVX\n       && misaligned_operand (operands[1], <MODE>mode))\n     {\n@@ -1192,25 +1200,61 @@\n     }\n })\n \n+(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+  [(set (match_operand:VI_ULOADSTORE_BW_AVX512VL 0 \"register_operand\")\n+\t(unspec:VI_ULOADSTORE_BW_AVX512VL\n+\t  [(match_operand:VI_ULOADSTORE_BW_AVX512VL 1 \"nonimmediate_operand\")]\n+\t  UNSPEC_LOADU))]\n+  \"TARGET_AVX512BW\"\n+{\n+  if (misaligned_operand (operands[1], <MODE>mode))\n+    {\n+      rtx src = operands[1];\n+      if (<mask_applied>)\n+\tsrc = gen_rtx_VEC_MERGE (<MODE>mode, operands[1],\n+\t\t\t\t operands[2 * <mask_applied>],\n+\t\t\t\t operands[3 * <mask_applied>]);\n+      emit_insn (gen_rtx_SET (VOIDmode, operands[0], src));\n+      DONE;\n+    }\n+})\n+\n+(define_expand \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+  [(set (match_operand:VI_ULOADSTORE_F_AVX512VL 0 \"register_operand\")\n+\t(unspec:VI_ULOADSTORE_F_AVX512VL\n+\t  [(match_operand:VI_ULOADSTORE_F_AVX512VL 1 \"nonimmediate_operand\")]\n+\t  UNSPEC_LOADU))]\n+  \"TARGET_AVX512F\"\n+{\n+  if (misaligned_operand (operands[1], <MODE>mode))\n+    {\n+      rtx src = operands[1];\n+      if (<mask_applied>)\n+\tsrc = gen_rtx_VEC_MERGE (<MODE>mode, operands[1],\n+\t\t\t\t operands[2 * <mask_applied>],\n+\t\t\t\t operands[3 * <mask_applied>]);\n+      emit_insn (gen_rtx_SET (VOIDmode, operands[0], src));\n+      DONE;\n+    }\n+})\n+\n (define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n-  [(set (match_operand:VI_UNALIGNED_LOADSTORE 0 \"register_operand\" \"=v\")\n-\t(unspec:VI_UNALIGNED_LOADSTORE\n-\t  [(match_operand:VI_UNALIGNED_LOADSTORE 1 \"nonimmediate_operand\" \"vm\")]\n+  [(set (match_operand:VI1 0 \"register_operand\" \"=v\")\n+\t(unspec:VI1\n+\t  [(match_operand:VI1 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_LOADU))]\n-  \"TARGET_SSE2 && <mask_mode512bit_condition>\"\n+  \"TARGET_SSE2 && <mask_avx512vl_condition> && <mask_avx512bw_condition>\"\n {\n   switch (get_attr_mode (insn))\n     {\n     case MODE_V8SF:\n     case MODE_V4SF:\n       return \"%vmovups\\t{%1, %0|%0, %1}\";\n-    case MODE_XI:\n-      if (<MODE>mode == V8DImode)\n-\treturn \"vmovdqu64\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n-      else\n-\treturn \"vmovdqu32\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n     default:\n-      return \"%vmovdqu\\t{%1, %0|%0, %1}\";\n+      if (!(TARGET_AVX512VL && TARGET_AVX512BW))\n+\treturn \"%vmovdqu\\t{%1, %0|%0, %1}\";\n+      else\n+\treturn \"vmovdqu<ssescalarsize>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n     }\n }\n   [(set_attr \"type\" \"ssemov\")\n@@ -1233,10 +1277,34 @@\n \t      ]\n \t      (const_string \"<sseinsnmode>\")))])\n \n+(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+  [(set (match_operand:VI_ULOADSTORE_BW_AVX512VL 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_ULOADSTORE_BW_AVX512VL\n+\t  [(match_operand:VI_ULOADSTORE_BW_AVX512VL 1 \"nonimmediate_operand\" \"vm\")]\n+\t  UNSPEC_LOADU))]\n+  \"TARGET_AVX512BW\"\n+  \"vmovdqu<ssescalarsize>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"movu\" \"1\")\n+   (set_attr \"ssememalign\" \"8\")\n+   (set_attr \"prefix\" \"maybe_evex\")])\n+\n+(define_insn \"*<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n+  [(set (match_operand:VI_ULOADSTORE_F_AVX512VL 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_ULOADSTORE_F_AVX512VL\n+\t  [(match_operand:VI_ULOADSTORE_F_AVX512VL 1 \"nonimmediate_operand\" \"vm\")]\n+\t  UNSPEC_LOADU))]\n+  \"TARGET_AVX512F\"\n+  \"vmovdqu<ssescalarsize>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"movu\" \"1\")\n+   (set_attr \"ssememalign\" \"8\")\n+   (set_attr \"prefix\" \"maybe_evex\")])\n+\n (define_insn \"<sse2_avx_avx512f>_storedqu<mode>\"\n-  [(set (match_operand:VI_UNALIGNED_LOADSTORE 0 \"memory_operand\" \"=m\")\n-\t(unspec:VI_UNALIGNED_LOADSTORE\n-\t  [(match_operand:VI_UNALIGNED_LOADSTORE 1 \"register_operand\" \"v\")]\n+  [(set (match_operand:VI1 0 \"memory_operand\" \"=m\")\n+\t(unspec:VI1\n+\t  [(match_operand:VI1 1 \"register_operand\" \"v\")]\n \t  UNSPEC_STOREU))]\n   \"TARGET_SSE2\"\n {\n@@ -1246,13 +1314,16 @@\n     case MODE_V8SF:\n     case MODE_V4SF:\n       return \"%vmovups\\t{%1, %0|%0, %1}\";\n-    case MODE_XI:\n-      if (<MODE>mode == V8DImode)\n-\treturn \"vmovdqu64\\t{%1, %0|%0, %1}\";\n-      else\n-\treturn \"vmovdqu32\\t{%1, %0|%0, %1}\";\n     default:\n-      return \"%vmovdqu\\t{%1, %0|%0, %1}\";\n+      switch (<MODE>mode)\n+      {\n+      case V32QImode:\n+      case V16QImode:\n+\tif (!(TARGET_AVX512VL && TARGET_AVX512BW))\n+\t  return \"%vmovdqu\\t{%1, %0|%0, %1}\";\n+      default:\n+\t  return \"vmovdqu<ssescalarsize>\\t{%1, %0|%0, %1}\";\n+      }\n     }\n }\n   [(set_attr \"type\" \"ssemov\")\n@@ -1276,21 +1347,56 @@\n \t      ]\n \t      (const_string \"<sseinsnmode>\")))])\n \n-(define_insn \"avx512f_storedqu<mode>_mask\"\n-  [(set (match_operand:VI48_512 0 \"memory_operand\" \"=m\")\n-\t(vec_merge:VI48_512\n-\t  (unspec:VI48_512\n-\t    [(match_operand:VI48_512 1 \"register_operand\" \"v\")]\n+(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\"\n+  [(set (match_operand:VI_ULOADSTORE_BW_AVX512VL 0 \"memory_operand\" \"=m\")\n+\t(unspec:VI_ULOADSTORE_BW_AVX512VL\n+\t  [(match_operand:VI_ULOADSTORE_BW_AVX512VL 1 \"register_operand\" \"v\")]\n+\t  UNSPEC_STOREU))]\n+  \"TARGET_AVX512BW\"\n+  \"vmovdqu<ssescalarsize>\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"movu\" \"1\")\n+   (set_attr \"ssememalign\" \"8\")\n+   (set_attr \"prefix\" \"maybe_evex\")])\n+\n+(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\"\n+  [(set (match_operand:VI_ULOADSTORE_F_AVX512VL 0 \"memory_operand\" \"=m\")\n+\t(unspec:VI_ULOADSTORE_F_AVX512VL\n+\t  [(match_operand:VI_ULOADSTORE_F_AVX512VL 1 \"register_operand\" \"v\")]\n+\t  UNSPEC_STOREU))]\n+  \"TARGET_AVX512F\"\n+  \"vmovdqu<ssescalarsize>\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"movu\" \"1\")\n+   (set_attr \"ssememalign\" \"8\")\n+   (set_attr \"prefix\" \"maybe_vex\")])\n+\n+(define_insn \"<avx512>_storedqu<mode>_mask\"\n+  [(set (match_operand:VI48_AVX512VL 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:VI48_AVX512VL\n+\t  (unspec:VI48_AVX512VL\n+\t    [(match_operand:VI48_AVX512VL 1 \"register_operand\" \"v\")]\n \t    UNSPEC_STOREU)\n \t  (match_dup 0)\n \t  (match_operand:<avx512fmaskmode> 2 \"register_operand\" \"Yk\")))]\n   \"TARGET_AVX512F\"\n-{\n-  if (<MODE>mode == V8DImode)\n-    return \"vmovdqu64\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n-  else\n-    return \"vmovdqu32\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n-}\n+  \"vmovdqu<ssescalarsize>\\t{%1, %0%{%2%}|%0%{%2%}, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"movu\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"<avx512>_storedqu<mode>_mask\"\n+  [(set (match_operand:VI12_AVX512VL 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:VI12_AVX512VL\n+\t  (unspec:VI12_AVX512VL\n+\t    [(match_operand:VI12_AVX512VL 1 \"register_operand\" \"v\")]\n+\t    UNSPEC_STOREU)\n+\t  (match_dup 0)\n+\t  (match_operand:<avx512fmaskmode> 2 \"register_operand\" \"Yk\")))]\n+  \"TARGET_AVX512BW\"\n+  \"vmovdqu<ssescalarsize>\\t{%1, %0%{%2%}|%0%{%2%}, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"movu\" \"1\")\n    (set_attr \"memory\" \"store\")"}]}