{"sha": "e3731c52cf1b60d90f27f81ff0d1e2ad164fed07", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTM3MzFjNTJjZjFiNjBkOTBmMjdmODFmZjBkMWUyYWQxNjRmZWQwNw==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-08-30T11:15:38Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-08-30T11:15:38Z"}, "message": "[42/77] Use scalar_int_mode in simplify_shift_const_1\n\nThis patch makes simplify_shift_const_1 use scalar_int_modes\nfor all code that is specific to scalars rather than vectors.\nThis includes situations in which the new shift mode is different\nfrom the original one, since the function never changes the mode\nof vector shifts.  That in turn makes it more natural to test for\nequal modes in simplify_shift_const_1 rather than try_widen_shift_mode\n(which only applies to scalars).\n\n2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* combine.c (try_widen_shift_mode): Move check for equal modes to...\n\t(simplify_shift_const_1): ...here.  Use scalar_int_mode for\n\tshift_unit_mode and for modes involved in scalar shifts.\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r251494", "tree": {"sha": "dd8686b6bb9c379481012af719e72aaeae06a911", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/dd8686b6bb9c379481012af719e72aaeae06a911"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07/comments", "author": null, "committer": null, "parents": [{"sha": "0b73246f1a11354037b6bb069ab1056f121e34fd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0b73246f1a11354037b6bb069ab1056f121e34fd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0b73246f1a11354037b6bb069ab1056f121e34fd"}], "stats": {"total": 230, "additions": 135, "deletions": 95}, "files": [{"sha": "fb28c999d90e98852b6f1ff1eee31e9456347054", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e3731c52cf1b60d90f27f81ff0d1e2ad164fed07", "patch": "@@ -1,3 +1,11 @@\n+2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* combine.c (try_widen_shift_mode): Move check for equal modes to...\n+\t(simplify_shift_const_1): ...here.  Use scalar_int_mode for\n+\tshift_unit_mode and for modes involved in scalar shifts.\n+\n 2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "2e0e67be222c09c2e52c33602ee2853ca531bd95", "filename": "gcc/combine.c", "status": "modified", "additions": 127, "deletions": 95, "changes": 222, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e3731c52cf1b60d90f27f81ff0d1e2ad164fed07/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=e3731c52cf1b60d90f27f81ff0d1e2ad164fed07", "patch": "@@ -10321,8 +10321,6 @@ try_widen_shift_mode (enum rtx_code code, rtx op, int count,\n \t\t      machine_mode orig_mode, machine_mode mode,\n \t\t      enum rtx_code outer_code, HOST_WIDE_INT outer_const)\n {\n-  if (orig_mode == mode)\n-    return mode;\n   gcc_assert (GET_MODE_PRECISION (mode) > GET_MODE_PRECISION (orig_mode));\n \n   /* In general we can't perform in wider mode for right shift and rotate.  */\n@@ -10383,7 +10381,7 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n   int count;\n   machine_mode mode = result_mode;\n   machine_mode shift_mode;\n-  scalar_int_mode tmode, inner_mode;\n+  scalar_int_mode tmode, inner_mode, int_mode, int_varop_mode, int_result_mode;\n   unsigned int mode_words\n     = (GET_MODE_SIZE (mode) + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD;\n   /* We form (outer_op (code varop count) (outer_const)).  */\n@@ -10423,9 +10421,19 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  count = bitsize - count;\n \t}\n \n-      shift_mode = try_widen_shift_mode (code, varop, count, result_mode,\n-\t\t\t\t\t mode, outer_op, outer_const);\n-      machine_mode shift_unit_mode = GET_MODE_INNER (shift_mode);\n+      shift_mode = result_mode;\n+      if (shift_mode != mode)\n+\t{\n+\t  /* We only change the modes of scalar shifts.  */\n+\t  int_mode = as_a <scalar_int_mode> (mode);\n+\t  int_result_mode = as_a <scalar_int_mode> (result_mode);\n+\t  shift_mode = try_widen_shift_mode (code, varop, count,\n+\t\t\t\t\t     int_result_mode, int_mode,\n+\t\t\t\t\t     outer_op, outer_const);\n+\t}\n+\n+      scalar_int_mode shift_unit_mode\n+\t= as_a <scalar_int_mode> (GET_MODE_INNER (shift_mode));\n \n       /* Handle cases where the count is greater than the size of the mode\n \t minus 1.  For ASHIFT, use the size minus one as the count (this can\n@@ -10520,6 +10528,7 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_mode = as_a <scalar_int_mode> (mode);\n \n \t  /* If we have (xshiftrt (mem ...) C) and C is MODE_WIDTH\n \t     minus the width of a smaller mode, we can do this with a\n@@ -10528,15 +10537,15 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t      && ! mode_dependent_address_p (XEXP (varop, 0),\n \t\t\t\t\t     MEM_ADDR_SPACE (varop))\n \t      && ! MEM_VOLATILE_P (varop)\n-\t      && (int_mode_for_size (GET_MODE_BITSIZE (mode) - count, 1)\n+\t      && (int_mode_for_size (GET_MODE_BITSIZE (int_mode) - count, 1)\n \t\t  .exists (&tmode)))\n \t    {\n \t      new_rtx = adjust_address_nv (varop, tmode,\n-\t\t\t\t       BYTES_BIG_ENDIAN ? 0\n-\t\t\t\t       : count / BITS_PER_UNIT);\n+\t\t\t\t\t   BYTES_BIG_ENDIAN ? 0\n+\t\t\t\t\t   : count / BITS_PER_UNIT);\n \n \t      varop = gen_rtx_fmt_e (code == ASHIFTRT ? SIGN_EXTEND\n-\t\t\t\t     : ZERO_EXTEND, mode, new_rtx);\n+\t\t\t\t     : ZERO_EXTEND, int_mode, new_rtx);\n \t      count = 0;\n \t      continue;\n \t    }\n@@ -10546,20 +10555,22 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_mode = as_a <scalar_int_mode> (mode);\n+\t  int_varop_mode = as_a <scalar_int_mode> (GET_MODE (varop));\n \n \t  /* If VAROP is a SUBREG, strip it as long as the inner operand has\n \t     the same number of words as what we've seen so far.  Then store\n \t     the widest mode in MODE.  */\n \t  if (subreg_lowpart_p (varop)\n \t      && is_int_mode (GET_MODE (SUBREG_REG (varop)), &inner_mode)\n-\t      && GET_MODE_SIZE (inner_mode) > GET_MODE_SIZE (GET_MODE (varop))\n+\t      && GET_MODE_SIZE (inner_mode) > GET_MODE_SIZE (int_varop_mode)\n \t      && (unsigned int) ((GET_MODE_SIZE (inner_mode)\n \t\t\t\t  + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD)\n \t\t == mode_words\n-\t      && GET_MODE_CLASS (GET_MODE (varop)) == MODE_INT)\n+\t      && GET_MODE_CLASS (int_varop_mode) == MODE_INT)\n \t    {\n \t      varop = SUBREG_REG (varop);\n-\t      if (GET_MODE_SIZE (inner_mode) > GET_MODE_SIZE (mode))\n+\t      if (GET_MODE_SIZE (inner_mode) > GET_MODE_SIZE (int_mode))\n \t\tmode = inner_mode;\n \t      continue;\n \t    }\n@@ -10618,14 +10629,17 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_mode = as_a <scalar_int_mode> (mode);\n+\t  int_varop_mode = as_a <scalar_int_mode> (GET_MODE (varop));\n+\t  int_result_mode = as_a <scalar_int_mode> (result_mode);\n \n \t  /* Here we have two nested shifts.  The result is usually the\n \t     AND of a new shift with a mask.  We compute the result below.  */\n \t  if (CONST_INT_P (XEXP (varop, 1))\n \t      && INTVAL (XEXP (varop, 1)) >= 0\n-\t      && INTVAL (XEXP (varop, 1)) < GET_MODE_PRECISION (GET_MODE (varop))\n-\t      && HWI_COMPUTABLE_MODE_P (result_mode)\n-\t      && HWI_COMPUTABLE_MODE_P (mode))\n+\t      && INTVAL (XEXP (varop, 1)) < GET_MODE_PRECISION (int_varop_mode)\n+\t      && HWI_COMPUTABLE_MODE_P (int_result_mode)\n+\t      && HWI_COMPUTABLE_MODE_P (int_mode))\n \t    {\n \t      enum rtx_code first_code = GET_CODE (varop);\n \t      unsigned int first_count = INTVAL (XEXP (varop, 1));\n@@ -10640,18 +10654,18 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t\t (ashiftrt:M1 (ashift:M1 (and:M1 (subreg:M1 FOO 0) C3) C2) C1).\n \t\t This simplifies certain SIGN_EXTEND operations.  */\n \t      if (code == ASHIFT && first_code == ASHIFTRT\n-\t\t  && count == (GET_MODE_PRECISION (result_mode)\n-\t\t\t       - GET_MODE_PRECISION (GET_MODE (varop))))\n+\t\t  && count == (GET_MODE_PRECISION (int_result_mode)\n+\t\t\t       - GET_MODE_PRECISION (int_varop_mode)))\n \t\t{\n \t\t  /* C3 has the low-order C1 bits zero.  */\n \n-\t\t  mask = GET_MODE_MASK (mode)\n+\t\t  mask = GET_MODE_MASK (int_mode)\n \t\t\t & ~((HOST_WIDE_INT_1U << first_count) - 1);\n \n-\t\t  varop = simplify_and_const_int (NULL_RTX, result_mode,\n+\t\t  varop = simplify_and_const_int (NULL_RTX, int_result_mode,\n \t\t\t\t\t\t  XEXP (varop, 0), mask);\n-\t\t  varop = simplify_shift_const (NULL_RTX, ASHIFT, result_mode,\n-\t\t\t\t\t\tvarop, count);\n+\t\t  varop = simplify_shift_const (NULL_RTX, ASHIFT,\n+\t\t\t\t\t\tint_result_mode, varop, count);\n \t\t  count = first_count;\n \t\t  code = ASHIFTRT;\n \t\t  continue;\n@@ -10662,11 +10676,11 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t\t this to either an ASHIFT or an ASHIFTRT depending on the\n \t\t two counts.\n \n-\t\t We cannot do this if VAROP's mode is not SHIFT_MODE.  */\n+\t\t We cannot do this if VAROP's mode is not SHIFT_UNIT_MODE.  */\n \n \t      if (code == ASHIFTRT && first_code == ASHIFT\n-\t\t  && GET_MODE (varop) == shift_mode\n-\t\t  && (num_sign_bit_copies (XEXP (varop, 0), shift_mode)\n+\t\t  && int_varop_mode == shift_unit_mode\n+\t\t  && (num_sign_bit_copies (XEXP (varop, 0), shift_unit_mode)\n \t\t      > first_count))\n \t\t{\n \t\t  varop = XEXP (varop, 0);\n@@ -10697,7 +10711,7 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \n \t      if (code == first_code)\n \t\t{\n-\t\t  if (GET_MODE (varop) != result_mode\n+\t\t  if (int_varop_mode != int_result_mode\n \t\t      && (code == ASHIFTRT || code == LSHIFTRT\n \t\t\t  || code == ROTATE))\n \t\t    break;\n@@ -10709,8 +10723,8 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \n \t      if (code == ASHIFTRT\n \t\t  || (code == ROTATE && first_code == ASHIFTRT)\n-\t\t  || GET_MODE_PRECISION (mode) > HOST_BITS_PER_WIDE_INT\n-\t\t  || (GET_MODE (varop) != result_mode\n+\t\t  || GET_MODE_PRECISION (int_mode) > HOST_BITS_PER_WIDE_INT\n+\t\t  || (int_varop_mode != int_result_mode\n \t\t      && (first_code == ASHIFTRT || first_code == LSHIFTRT\n \t\t\t  || first_code == ROTATE\n \t\t\t  || code == ROTATE)))\n@@ -10720,19 +10734,19 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t\t nonzero bits of the inner shift the same way the\n \t\t outer shift will.  */\n \n-\t      mask_rtx = gen_int_mode (nonzero_bits (varop, GET_MODE (varop)),\n-\t\t\t\t       result_mode);\n+\t      mask_rtx = gen_int_mode (nonzero_bits (varop, int_varop_mode),\n+\t\t\t\t       int_result_mode);\n \n \t      mask_rtx\n-\t\t= simplify_const_binary_operation (code, result_mode, mask_rtx,\n-\t\t\t\t\t\t   GEN_INT (count));\n+\t\t= simplify_const_binary_operation (code, int_result_mode,\n+\t\t\t\t\t\t   mask_rtx, GEN_INT (count));\n \n \t      /* Give up if we can't compute an outer operation to use.  */\n \t      if (mask_rtx == 0\n \t\t  || !CONST_INT_P (mask_rtx)\n \t\t  || ! merge_outer_ops (&outer_op, &outer_const, AND,\n \t\t\t\t\tINTVAL (mask_rtx),\n-\t\t\t\t\tresult_mode, &complement_p))\n+\t\t\t\t\tint_result_mode, &complement_p))\n \t\tbreak;\n \n \t      /* If the shifts are in the same direction, we add the\n@@ -10769,22 +10783,22 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t      /* For ((unsigned) (cstULL >> count)) >> cst2 we have to make\n \t\t sure the result will be masked.  See PR70222.  */\n \t      if (code == LSHIFTRT\n-\t\t  && mode != result_mode\n+\t\t  && int_mode != int_result_mode\n \t\t  && !merge_outer_ops (&outer_op, &outer_const, AND,\n-\t\t\t\t       GET_MODE_MASK (result_mode)\n-\t\t\t\t       >> orig_count, result_mode,\n+\t\t\t\t       GET_MODE_MASK (int_result_mode)\n+\t\t\t\t       >> orig_count, int_result_mode,\n \t\t\t\t       &complement_p))\n \t\tbreak;\n \t      /* For ((int) (cstLL >> count)) >> cst2 just give up.  Queuing\n \t\t up outer sign extension (often left and right shift) is\n \t\t hardly more efficient than the original.  See PR70429.  */\n-\t      if (code == ASHIFTRT && mode != result_mode)\n+\t      if (code == ASHIFTRT && int_mode != int_result_mode)\n \t\tbreak;\n \n-\t      rtx new_rtx = simplify_const_binary_operation (code, mode,\n+\t      rtx new_rtx = simplify_const_binary_operation (code, int_mode,\n \t\t\t\t\t\t\t     XEXP (varop, 0),\n \t\t\t\t\t\t\t     GEN_INT (count));\n-\t      varop = gen_rtx_fmt_ee (code, mode, new_rtx, XEXP (varop, 1));\n+\t      varop = gen_rtx_fmt_ee (code, int_mode, new_rtx, XEXP (varop, 1));\n \t      count = 0;\n \t      continue;\n \t    }\n@@ -10805,6 +10819,8 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_varop_mode = as_a <scalar_int_mode> (GET_MODE (varop));\n+\t  int_result_mode = as_a <scalar_int_mode> (result_mode);\n \n \t  /* If we have (xshiftrt (ior (plus X (const_int -1)) X) C)\n \t     with C the size of VAROP - 1 and the shift is logical if\n@@ -10817,15 +10833,15 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t      && XEXP (XEXP (varop, 0), 1) == constm1_rtx\n \t      && (STORE_FLAG_VALUE == 1 || STORE_FLAG_VALUE == -1)\n \t      && (code == LSHIFTRT || code == ASHIFTRT)\n-\t      && count == (GET_MODE_PRECISION (GET_MODE (varop)) - 1)\n+\t      && count == (GET_MODE_PRECISION (int_varop_mode) - 1)\n \t      && rtx_equal_p (XEXP (XEXP (varop, 0), 0), XEXP (varop, 1)))\n \t    {\n \t      count = 0;\n-\t      varop = gen_rtx_LE (GET_MODE (varop), XEXP (varop, 1),\n+\t      varop = gen_rtx_LE (int_varop_mode, XEXP (varop, 1),\n \t\t\t\t  const0_rtx);\n \n \t      if (STORE_FLAG_VALUE == 1 ? code == ASHIFTRT : code == LSHIFTRT)\n-\t\tvarop = gen_rtx_NEG (GET_MODE (varop), varop);\n+\t\tvarop = gen_rtx_NEG (int_varop_mode, varop);\n \n \t      continue;\n \t    }\n@@ -10838,19 +10854,20 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \n \t  if (CONST_INT_P (XEXP (varop, 1))\n \t      /* We can't do this if we have (ashiftrt (xor))  and the\n-\t\t constant has its sign bit set in shift_mode with shift_mode\n-\t\t wider than result_mode.  */\n+\t\t constant has its sign bit set in shift_unit_mode with\n+\t\t shift_unit_mode wider than result_mode.  */\n \t      && !(code == ASHIFTRT && GET_CODE (varop) == XOR\n-\t\t   && result_mode != shift_mode\n+\t\t   && int_result_mode != shift_unit_mode\n \t\t   && 0 > trunc_int_for_mode (INTVAL (XEXP (varop, 1)),\n-\t\t\t\t\t      shift_mode))\n+\t\t\t\t\t      shift_unit_mode))\n \t      && (new_rtx = simplify_const_binary_operation\n-\t\t  (code, result_mode,\n-\t\t   gen_int_mode (INTVAL (XEXP (varop, 1)), result_mode),\n+\t\t  (code, int_result_mode,\n+\t\t   gen_int_mode (INTVAL (XEXP (varop, 1)), int_result_mode),\n \t\t   GEN_INT (count))) != 0\n \t      && CONST_INT_P (new_rtx)\n \t      && merge_outer_ops (&outer_op, &outer_const, GET_CODE (varop),\n-\t\t\t\t  INTVAL (new_rtx), result_mode, &complement_p))\n+\t\t\t\t  INTVAL (new_rtx), int_result_mode,\n+\t\t\t\t  &complement_p))\n \t    {\n \t      varop = XEXP (varop, 0);\n \t      continue;\n@@ -10863,16 +10880,16 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t     changes the sign bit.  */\n \t  if (CONST_INT_P (XEXP (varop, 1))\n \t     && !(code == ASHIFTRT && GET_CODE (varop) == XOR\n-\t\t  && result_mode != shift_mode\n+\t\t  && int_result_mode != shift_unit_mode\n \t\t  && 0 > trunc_int_for_mode (INTVAL (XEXP (varop, 1)),\n-\t\t\t\t\t     shift_mode)))\n+\t\t\t\t\t     shift_unit_mode)))\n \t    {\n-\t      rtx lhs = simplify_shift_const (NULL_RTX, code, shift_mode,\n+\t      rtx lhs = simplify_shift_const (NULL_RTX, code, shift_unit_mode,\n \t\t\t\t\t      XEXP (varop, 0), count);\n-\t      rtx rhs = simplify_shift_const (NULL_RTX, code, shift_mode,\n+\t      rtx rhs = simplify_shift_const (NULL_RTX, code, shift_unit_mode,\n \t\t\t\t\t      XEXP (varop, 1), count);\n \n-\t      varop = simplify_gen_binary (GET_CODE (varop), shift_mode,\n+\t      varop = simplify_gen_binary (GET_CODE (varop), shift_unit_mode,\n \t\t\t\t\t   lhs, rhs);\n \t      varop = apply_distributive_law (varop);\n \n@@ -10885,20 +10902,21 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_result_mode = as_a <scalar_int_mode> (result_mode);\n \n \t  /* Convert (lshiftrt (eq FOO 0) C) to (xor FOO 1) if STORE_FLAG_VALUE\n \t     says that the sign bit can be tested, FOO has mode MODE, C is\n \t     GET_MODE_PRECISION (MODE) - 1, and FOO has only its low-order bit\n \t     that may be nonzero.  */\n \t  if (code == LSHIFTRT\n \t      && XEXP (varop, 1) == const0_rtx\n-\t      && GET_MODE (XEXP (varop, 0)) == result_mode\n-\t      && count == (GET_MODE_PRECISION (result_mode) - 1)\n-\t      && HWI_COMPUTABLE_MODE_P (result_mode)\n+\t      && GET_MODE (XEXP (varop, 0)) == int_result_mode\n+\t      && count == (GET_MODE_PRECISION (int_result_mode) - 1)\n+\t      && HWI_COMPUTABLE_MODE_P (int_result_mode)\n \t      && STORE_FLAG_VALUE == -1\n-\t      && nonzero_bits (XEXP (varop, 0), result_mode) == 1\n-\t      && merge_outer_ops (&outer_op, &outer_const, XOR, 1, result_mode,\n-\t\t\t\t  &complement_p))\n+\t      && nonzero_bits (XEXP (varop, 0), int_result_mode) == 1\n+\t      && merge_outer_ops (&outer_op, &outer_const, XOR, 1,\n+\t\t\t\t  int_result_mode, &complement_p))\n \t    {\n \t      varop = XEXP (varop, 0);\n \t      count = 0;\n@@ -10910,12 +10928,13 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_result_mode = as_a <scalar_int_mode> (result_mode);\n \n \t  /* (lshiftrt (neg A) C) where A is either 0 or 1 and C is one less\n \t     than the number of bits in the mode is equivalent to A.  */\n \t  if (code == LSHIFTRT\n-\t      && count == (GET_MODE_PRECISION (result_mode) - 1)\n-\t      && nonzero_bits (XEXP (varop, 0), result_mode) == 1)\n+\t      && count == (GET_MODE_PRECISION (int_result_mode) - 1)\n+\t      && nonzero_bits (XEXP (varop, 0), int_result_mode) == 1)\n \t    {\n \t      varop = XEXP (varop, 0);\n \t      count = 0;\n@@ -10925,8 +10944,8 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* NEG commutes with ASHIFT since it is multiplication.  Move the\n \t     NEG outside to allow shifts to combine.  */\n \t  if (code == ASHIFT\n-\t      && merge_outer_ops (&outer_op, &outer_const, NEG, 0, result_mode,\n-\t\t\t\t  &complement_p))\n+\t      && merge_outer_ops (&outer_op, &outer_const, NEG, 0,\n+\t\t\t\t  int_result_mode, &complement_p))\n \t    {\n \t      varop = XEXP (varop, 0);\n \t      continue;\n@@ -10937,16 +10956,17 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_result_mode = as_a <scalar_int_mode> (result_mode);\n \n \t  /* (lshiftrt (plus A -1) C) where A is either 0 or 1 and C\n \t     is one less than the number of bits in the mode is\n \t     equivalent to (xor A 1).  */\n \t  if (code == LSHIFTRT\n-\t      && count == (GET_MODE_PRECISION (result_mode) - 1)\n+\t      && count == (GET_MODE_PRECISION (int_result_mode) - 1)\n \t      && XEXP (varop, 1) == constm1_rtx\n-\t      && nonzero_bits (XEXP (varop, 0), result_mode) == 1\n-\t      && merge_outer_ops (&outer_op, &outer_const, XOR, 1, result_mode,\n-\t\t\t\t  &complement_p))\n+\t      && nonzero_bits (XEXP (varop, 0), int_result_mode) == 1\n+\t      && merge_outer_ops (&outer_op, &outer_const, XOR, 1,\n+\t\t\t\t  int_result_mode, &complement_p))\n \t    {\n \t      count = 0;\n \t      varop = XEXP (varop, 0);\n@@ -10961,21 +10981,20 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \n \t  if ((code == ASHIFTRT || code == LSHIFTRT)\n \t      && count < HOST_BITS_PER_WIDE_INT\n-\t      && nonzero_bits (XEXP (varop, 1), result_mode) >> count == 0\n-\t      && (nonzero_bits (XEXP (varop, 1), result_mode)\n-\t\t  & nonzero_bits (XEXP (varop, 0), result_mode)) == 0)\n+\t      && nonzero_bits (XEXP (varop, 1), int_result_mode) >> count == 0\n+\t      && (nonzero_bits (XEXP (varop, 1), int_result_mode)\n+\t\t  & nonzero_bits (XEXP (varop, 0), int_result_mode)) == 0)\n \t    {\n \t      varop = XEXP (varop, 0);\n \t      continue;\n \t    }\n \t  else if ((code == ASHIFTRT || code == LSHIFTRT)\n \t\t   && count < HOST_BITS_PER_WIDE_INT\n-\t\t   && HWI_COMPUTABLE_MODE_P (result_mode)\n-\t\t   && 0 == (nonzero_bits (XEXP (varop, 0), result_mode)\n+\t\t   && HWI_COMPUTABLE_MODE_P (int_result_mode)\n+\t\t   && 0 == (nonzero_bits (XEXP (varop, 0), int_result_mode)\n \t\t\t    >> count)\n-\t\t   && 0 == (nonzero_bits (XEXP (varop, 0), result_mode)\n-\t\t\t    & nonzero_bits (XEXP (varop, 1),\n-\t\t\t\t\t\t result_mode)))\n+\t\t   && 0 == (nonzero_bits (XEXP (varop, 0), int_result_mode)\n+\t\t\t    & nonzero_bits (XEXP (varop, 1), int_result_mode)))\n \t    {\n \t      varop = XEXP (varop, 1);\n \t      continue;\n@@ -10985,12 +11004,13 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  if (code == ASHIFT\n \t      && CONST_INT_P (XEXP (varop, 1))\n \t      && (new_rtx = simplify_const_binary_operation\n-\t\t  (ASHIFT, result_mode,\n-\t\t   gen_int_mode (INTVAL (XEXP (varop, 1)), result_mode),\n+\t\t  (ASHIFT, int_result_mode,\n+\t\t   gen_int_mode (INTVAL (XEXP (varop, 1)), int_result_mode),\n \t\t   GEN_INT (count))) != 0\n \t      && CONST_INT_P (new_rtx)\n \t      && merge_outer_ops (&outer_op, &outer_const, PLUS,\n-\t\t\t\t  INTVAL (new_rtx), result_mode, &complement_p))\n+\t\t\t\t  INTVAL (new_rtx), int_result_mode,\n+\t\t\t\t  &complement_p))\n \t    {\n \t      varop = XEXP (varop, 0);\n \t      continue;\n@@ -11003,14 +11023,15 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t     for reasoning in doing so.  */\n \t  if (code == LSHIFTRT\n \t      && CONST_INT_P (XEXP (varop, 1))\n-\t      && mode_signbit_p (result_mode, XEXP (varop, 1))\n+\t      && mode_signbit_p (int_result_mode, XEXP (varop, 1))\n \t      && (new_rtx = simplify_const_binary_operation\n-\t\t  (code, result_mode,\n-\t\t   gen_int_mode (INTVAL (XEXP (varop, 1)), result_mode),\n+\t\t  (code, int_result_mode,\n+\t\t   gen_int_mode (INTVAL (XEXP (varop, 1)), int_result_mode),\n \t\t   GEN_INT (count))) != 0\n \t      && CONST_INT_P (new_rtx)\n \t      && merge_outer_ops (&outer_op, &outer_const, XOR,\n-\t\t\t\t  INTVAL (new_rtx), result_mode, &complement_p))\n+\t\t\t\t  INTVAL (new_rtx), int_result_mode,\n+\t\t\t\t  &complement_p))\n \t    {\n \t      varop = XEXP (varop, 0);\n \t      continue;\n@@ -11022,6 +11043,7 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t  /* The following rules apply only to scalars.  */\n \t  if (shift_mode != shift_unit_mode)\n \t    break;\n+\t  int_varop_mode = as_a <scalar_int_mode> (GET_MODE (varop));\n \n \t  /* If we have (xshiftrt (minus (ashiftrt X C)) X) C)\n \t     with C the size of VAROP - 1 and the shift is logical if\n@@ -11032,18 +11054,18 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \n \t  if ((STORE_FLAG_VALUE == 1 || STORE_FLAG_VALUE == -1)\n \t      && GET_CODE (XEXP (varop, 0)) == ASHIFTRT\n-\t      && count == (GET_MODE_PRECISION (GET_MODE (varop)) - 1)\n+\t      && count == (GET_MODE_PRECISION (int_varop_mode) - 1)\n \t      && (code == LSHIFTRT || code == ASHIFTRT)\n \t      && CONST_INT_P (XEXP (XEXP (varop, 0), 1))\n \t      && INTVAL (XEXP (XEXP (varop, 0), 1)) == count\n \t      && rtx_equal_p (XEXP (XEXP (varop, 0), 0), XEXP (varop, 1)))\n \t    {\n \t      count = 0;\n-\t      varop = gen_rtx_GT (GET_MODE (varop), XEXP (varop, 1),\n+\t      varop = gen_rtx_GT (int_varop_mode, XEXP (varop, 1),\n \t\t\t\t  const0_rtx);\n \n \t      if (STORE_FLAG_VALUE == 1 ? code == ASHIFTRT : code == LSHIFTRT)\n-\t\tvarop = gen_rtx_NEG (GET_MODE (varop), varop);\n+\t\tvarop = gen_rtx_NEG (int_varop_mode, varop);\n \n \t      continue;\n \t    }\n@@ -11079,8 +11101,15 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n       break;\n     }\n \n-  shift_mode = try_widen_shift_mode (code, varop, count, result_mode, mode,\n-\t\t\t\t     outer_op, outer_const);\n+  shift_mode = result_mode;\n+  if (shift_mode != mode)\n+    {\n+      /* We only change the modes of scalar shifts.  */\n+      int_mode = as_a <scalar_int_mode> (mode);\n+      int_result_mode = as_a <scalar_int_mode> (result_mode);\n+      shift_mode = try_widen_shift_mode (code, varop, count, int_result_mode,\n+\t\t\t\t\t int_mode, outer_op, outer_const);\n+    }\n \n   /* We have now finished analyzing the shift.  The result should be\n      a shift of type CODE with SHIFT_MODE shifting VAROP COUNT places.  If\n@@ -11115,8 +11144,9 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n   /* If we were doing an LSHIFTRT in a wider mode than it was originally,\n      turn off all the bits that the shift would have turned off.  */\n   if (orig_code == LSHIFTRT && result_mode != shift_mode)\n-    x = simplify_and_const_int (NULL_RTX, shift_mode, x,\n-\t\t\t\tGET_MODE_MASK (result_mode) >> orig_count);\n+    /* We only change the modes of scalar shifts.  */\n+    x = simplify_and_const_int (NULL_RTX, as_a <scalar_int_mode> (shift_mode),\n+\t\t\t\tx, GET_MODE_MASK (result_mode) >> orig_count);\n \n   /* Do the remainder of the processing in RESULT_MODE.  */\n   x = gen_lowpart_or_truncate (result_mode, x);\n@@ -11128,12 +11158,14 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \n   if (outer_op != UNKNOWN)\n     {\n+      int_result_mode = as_a <scalar_int_mode> (result_mode);\n+\n       if (GET_RTX_CLASS (outer_op) != RTX_UNARY\n-\t  && GET_MODE_PRECISION (result_mode) < HOST_BITS_PER_WIDE_INT)\n-\touter_const = trunc_int_for_mode (outer_const, result_mode);\n+\t  && GET_MODE_PRECISION (int_result_mode) < HOST_BITS_PER_WIDE_INT)\n+\touter_const = trunc_int_for_mode (outer_const, int_result_mode);\n \n       if (outer_op == AND)\n-\tx = simplify_and_const_int (NULL_RTX, result_mode, x, outer_const);\n+\tx = simplify_and_const_int (NULL_RTX, int_result_mode, x, outer_const);\n       else if (outer_op == SET)\n \t{\n \t  /* This means that we have determined that the result is\n@@ -11142,9 +11174,9 @@ simplify_shift_const_1 (enum rtx_code code, machine_mode result_mode,\n \t    x = GEN_INT (outer_const);\n \t}\n       else if (GET_RTX_CLASS (outer_op) == RTX_UNARY)\n-\tx = simplify_gen_unary (outer_op, result_mode, x, result_mode);\n+\tx = simplify_gen_unary (outer_op, int_result_mode, x, int_result_mode);\n       else\n-\tx = simplify_gen_binary (outer_op, result_mode, x,\n+\tx = simplify_gen_binary (outer_op, int_result_mode, x,\n \t\t\t\t GEN_INT (outer_const));\n     }\n "}]}