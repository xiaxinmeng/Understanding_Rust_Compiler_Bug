{"sha": "d76b6ea41791f792e202cde0eb5227cd1de80201", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDc2YjZlYTQxNzkxZjc5MmUyMDJjZGUwZWI1MjI3Y2QxZGU4MDIwMQ==", "commit": {"author": {"name": "Andi Kleen", "email": "ak@linux.intel.com", "date": "2013-01-20T19:03:22Z"}, "committer": {"name": "Andi Kleen", "email": "ak@gcc.gnu.org", "date": "2013-01-20T19:03:22Z"}, "message": "libstdc++: Add mem_order_hle_acquire/release to atomic.h v2\n\nThe underlying compiler supports additional __ATOMIC_HLE_ACQUIRE/RELEASE\nmemmodel flags for TSX, but this was not exposed to the C++ wrapper.\nHandle it there.\n\nThese are additional flags, so some of assert checks need to mask\noff the flags before checking the memory model type.\n\nlibstdc++-v3/:\n2013-01-12  Andi Kleen  <ak@linux.intel.com>\n\t    Jonathan Wakely  <jwakely.gcc@gmail.com>\n\n        PR libstdc++/55223\n\t* include/bits/atomic_base.h (__memory_order_modifier): Add\n\t__memory_order_mask, __memory_order_modifier_mask,\n\t__memory_order_hle_acquire, __memory_order_hle_release.\n\t(operator|,operator&): Add.\n\t(__cmpexch_failure_order):  Rename to __cmpexch_failure_order2.\n\t(__cmpexch_failure_order): Add.\n\t(clear, store, load, compare_exchange_weak, compare_exchange_strong):\n\tHandle flags.\n\t* testsuite/29_atomics/atomic_flag/test_and_set/explicit-hle.cc:\n\tAdd.\n\nCo-Authored-By: Jonathan Wakely <jwakely.gcc@gmail.com>\n\nFrom-SVN: r195321", "tree": {"sha": "0b2492617f97e63077e8a77faae69484cc2f7b75", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0b2492617f97e63077e8a77faae69484cc2f7b75"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d76b6ea41791f792e202cde0eb5227cd1de80201", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d76b6ea41791f792e202cde0eb5227cd1de80201", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d76b6ea41791f792e202cde0eb5227cd1de80201", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d76b6ea41791f792e202cde0eb5227cd1de80201/comments", "author": null, "committer": null, "parents": [{"sha": "fe6035536ae0297dc80c38b679042265f4810286", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fe6035536ae0297dc80c38b679042265f4810286", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fe6035536ae0297dc80c38b679042265f4810286"}], "stats": {"total": 277, "additions": 232, "deletions": 45}, "files": [{"sha": "416b7e93d599a52489979b4e2f3b0b5eb65aa3e0", "filename": "libstdc++-v3/ChangeLog", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d76b6ea41791f792e202cde0eb5227cd1de80201/libstdc%2B%2B-v3%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d76b6ea41791f792e202cde0eb5227cd1de80201/libstdc%2B%2B-v3%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2FChangeLog?ref=d76b6ea41791f792e202cde0eb5227cd1de80201", "patch": "@@ -1,3 +1,18 @@\n+2013-01-12  Andi Kleen  <ak@linux.intel.com>\n+\t    Jonathan Wakely  <jwakely.gcc@gmail.com>\n+\n+\tPR libstdc++/55223\n+\t* include/bits/atomic_base.h (__memory_order_modifier): Add\n+\t__memory_order_mask, __memory_order_modifier_mask,\n+\t__memory_order_hle_acquire, __memory_order_hle_release.\n+\t(operator|,operator&): Add.\n+\t(__cmpexch_failure_order):  Rename to __cmpexch_failure_order2.\n+\t(__cmpexch_failure_order): Add.\n+\t(clear, store, load, compare_exchange_weak, compare_exchange_strong):\n+\tHandle flags.\n+\t* testsuite/29_atomics/atomic_flag/test_and_set/explicit-hle.cc:\n+\tAdd.\n+\n 2013-01-19  Jonathan Wakely  <jwakely.gcc@gmail.com>\n \n \tPR libstdc++/55861"}, {"sha": "d69bc76135e5f823440cb93244b96aa0a4c7445a", "filename": "libstdc++-v3/include/bits/atomic_base.h", "status": "modified", "additions": 97, "deletions": 45, "changes": 142, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d76b6ea41791f792e202cde0eb5227cd1de80201/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d76b6ea41791f792e202cde0eb5227cd1de80201/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h?ref=d76b6ea41791f792e202cde0eb5227cd1de80201", "patch": "@@ -59,14 +59,41 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       memory_order_seq_cst\n     } memory_order;\n \n+  enum __memory_order_modifier\n+    {\n+      __memory_order_mask          = 0x0ffff,\n+      __memory_order_modifier_mask = 0xffff0000,\n+      __memory_order_hle_acquire   = 0x10000,\n+      __memory_order_hle_release   = 0x20000\n+    };\n+\n+  constexpr memory_order\n+  operator|(memory_order __m, __memory_order_modifier __mod)\n+  {\n+    return memory_order(__m | int(__mod));\n+  }\n+\n+  constexpr memory_order\n+  operator&(memory_order __m, __memory_order_modifier __mod)\n+  {\n+    return memory_order(__m & int(__mod));\n+  }\n+\n   // Drop release ordering as per [atomics.types.operations.req]/21\n   constexpr memory_order\n-  __cmpexch_failure_order(memory_order __m) noexcept\n+  __cmpexch_failure_order2(memory_order __m) noexcept\n   {\n     return __m == memory_order_acq_rel ? memory_order_acquire\n       : __m == memory_order_release ? memory_order_relaxed : __m;\n   }\n \n+  constexpr memory_order\n+  __cmpexch_failure_order(memory_order __m) noexcept\n+  {\n+    return memory_order(__cmpexch_failure_order2(__m & __memory_order_mask)\n+      | (__m & __memory_order_modifier_mask));\n+  }\n+\n   inline void\n   atomic_thread_fence(memory_order __m) noexcept\n   { __atomic_thread_fence(__m); }\n@@ -268,19 +295,21 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     void\n     clear(memory_order __m = memory_order_seq_cst) noexcept\n     {\n-      __glibcxx_assert(__m != memory_order_consume);\n-      __glibcxx_assert(__m != memory_order_acquire);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n+      memory_order __b = __m & __memory_order_mask;\n+      __glibcxx_assert(__b != memory_order_consume);\n+      __glibcxx_assert(__b != memory_order_acquire);\n+      __glibcxx_assert(__b != memory_order_acq_rel);\n \n       __atomic_clear (&_M_i, __m);\n     }\n \n     void\n     clear(memory_order __m = memory_order_seq_cst) volatile noexcept\n     {\n-      __glibcxx_assert(__m != memory_order_consume);\n-      __glibcxx_assert(__m != memory_order_acquire);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n+      memory_order __b = __m & __memory_order_mask;\n+      __glibcxx_assert(__b != memory_order_consume);\n+      __glibcxx_assert(__b != memory_order_acquire);\n+      __glibcxx_assert(__b != memory_order_acq_rel);\n \n       __atomic_clear (&_M_i, __m);\n     }\n@@ -431,9 +460,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       void\n       store(__int_type __i, memory_order __m = memory_order_seq_cst) noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_acquire);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n-\t__glibcxx_assert(__m != memory_order_consume);\n+        memory_order __b = __m & __memory_order_mask;\n+\t__glibcxx_assert(__b != memory_order_acquire);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n+\t__glibcxx_assert(__b != memory_order_consume);\n \n \t__atomic_store_n(&_M_i, __i, __m);\n       }\n@@ -442,27 +472,30 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       store(__int_type __i,\n \t    memory_order __m = memory_order_seq_cst) volatile noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_acquire);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n-\t__glibcxx_assert(__m != memory_order_consume);\n+        memory_order __b = __m & __memory_order_mask;\n+\t__glibcxx_assert(__b != memory_order_acquire);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n+\t__glibcxx_assert(__b != memory_order_consume);\n \n \t__atomic_store_n(&_M_i, __i, __m);\n       }\n \n       __int_type\n       load(memory_order __m = memory_order_seq_cst) const noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_release);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n+       memory_order __b = __m & __memory_order_mask;\n+\t__glibcxx_assert(__b != memory_order_release);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n \n \treturn __atomic_load_n(&_M_i, __m);\n       }\n \n       __int_type\n       load(memory_order __m = memory_order_seq_cst) const volatile noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_release);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n+        memory_order __b = __m & __memory_order_mask;\n+\t__glibcxx_assert(__b != memory_order_release);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n \n \treturn __atomic_load_n(&_M_i, __m);\n       }\n@@ -486,9 +519,11 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       compare_exchange_weak(__int_type& __i1, __int_type __i2,\n \t\t\t    memory_order __m1, memory_order __m2) noexcept\n       {\n-\t__glibcxx_assert(__m2 != memory_order_release);\n-\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n-\t__glibcxx_assert(__m2 <= __m1);\n+       memory_order __b2 = __m2 & __memory_order_mask;\n+       memory_order __b1 = __m1 & __memory_order_mask;\n+\t__glibcxx_assert(__b2 != memory_order_release);\n+\t__glibcxx_assert(__b2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__b2 <= __b1);\n \n \treturn __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);\n       }\n@@ -498,9 +533,11 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t    memory_order __m1,\n \t\t\t    memory_order __m2) volatile noexcept\n       {\n-\t__glibcxx_assert(__m2 != memory_order_release);\n-\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n-\t__glibcxx_assert(__m2 <= __m1);\n+       memory_order __b2 = __m2 & __memory_order_mask;\n+       memory_order __b1 = __m1 & __memory_order_mask;\n+\t__glibcxx_assert(__b2 != memory_order_release);\n+\t__glibcxx_assert(__b2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__b2 <= __b1);\n \n \treturn __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);\n       }\n@@ -525,9 +562,11 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       compare_exchange_strong(__int_type& __i1, __int_type __i2,\n \t\t\t      memory_order __m1, memory_order __m2) noexcept\n       {\n-\t__glibcxx_assert(__m2 != memory_order_release);\n-\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n-\t__glibcxx_assert(__m2 <= __m1);\n+        memory_order __b2 = __m2 & __memory_order_mask;\n+        memory_order __b1 = __m1 & __memory_order_mask;\n+\t__glibcxx_assert(__b2 != memory_order_release);\n+\t__glibcxx_assert(__b2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__b2 <= __b1);\n \n \treturn __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);\n       }\n@@ -537,9 +576,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t      memory_order __m1,\n \t\t\t      memory_order __m2) volatile noexcept\n       {\n-\t__glibcxx_assert(__m2 != memory_order_release);\n-\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n-\t__glibcxx_assert(__m2 <= __m1);\n+        memory_order __b2 = __m2 & __memory_order_mask;\n+        memory_order __b1 = __m1 & __memory_order_mask;\n+\n+\t__glibcxx_assert(__b2 != memory_order_release);\n+\t__glibcxx_assert(__b2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__b2 <= __b1);\n \n \treturn __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);\n       }\n@@ -726,9 +768,11 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       store(__pointer_type __p,\n \t    memory_order __m = memory_order_seq_cst) noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_acquire);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n-\t__glibcxx_assert(__m != memory_order_consume);\n+        memory_order __b = __m & __memory_order_mask;\n+\n+\t__glibcxx_assert(__b != memory_order_acquire);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n+\t__glibcxx_assert(__b != memory_order_consume);\n \n \t__atomic_store_n(&_M_p, __p, __m);\n       }\n@@ -737,27 +781,30 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       store(__pointer_type __p,\n \t    memory_order __m = memory_order_seq_cst) volatile noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_acquire);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n-\t__glibcxx_assert(__m != memory_order_consume);\n+        memory_order __b = __m & __memory_order_mask;\n+\t__glibcxx_assert(__b != memory_order_acquire);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n+\t__glibcxx_assert(__b != memory_order_consume);\n \n \t__atomic_store_n(&_M_p, __p, __m);\n       }\n \n       __pointer_type\n       load(memory_order __m = memory_order_seq_cst) const noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_release);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n+        memory_order __b = __m & __memory_order_mask;\n+\t__glibcxx_assert(__b != memory_order_release);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n \n \treturn __atomic_load_n(&_M_p, __m);\n       }\n \n       __pointer_type\n       load(memory_order __m = memory_order_seq_cst) const volatile noexcept\n       {\n-\t__glibcxx_assert(__m != memory_order_release);\n-\t__glibcxx_assert(__m != memory_order_acq_rel);\n+        memory_order __b = __m & __memory_order_mask;\n+\t__glibcxx_assert(__b != memory_order_release);\n+\t__glibcxx_assert(__b != memory_order_acq_rel);\n \n \treturn __atomic_load_n(&_M_p, __m);\n       }\n@@ -782,9 +829,11 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t      memory_order __m1,\n \t\t\t      memory_order __m2) noexcept\n       {\n-\t__glibcxx_assert(__m2 != memory_order_release);\n-\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n-\t__glibcxx_assert(__m2 <= __m1);\n+        memory_order __b2 = __m2 & __memory_order_mask;\n+        memory_order __b1 = __m1 & __memory_order_mask;\n+\t__glibcxx_assert(__b2 != memory_order_release);\n+\t__glibcxx_assert(__b2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__b2 <= __b1);\n \n \treturn __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 0, __m1, __m2);\n       }\n@@ -794,9 +843,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t      memory_order __m1,\n \t\t\t      memory_order __m2) volatile noexcept\n       {\n-\t__glibcxx_assert(__m2 != memory_order_release);\n-\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n-\t__glibcxx_assert(__m2 <= __m1);\n+        memory_order __b2 = __m2 & __memory_order_mask;\n+        memory_order __b1 = __m1 & __memory_order_mask;\n+\n+\t__glibcxx_assert(__b2 != memory_order_release);\n+\t__glibcxx_assert(__b2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__b2 <= __b1);\n \n \treturn __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 0, __m1, __m2);\n       }"}, {"sha": "916a5e2d7772aea98035129f19b7e0a41c5a6f3f", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_flag/test_and_set/explicit-hle.cc", "status": "added", "additions": 120, "deletions": 0, "changes": 120, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d76b6ea41791f792e202cde0eb5227cd1de80201/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_flag%2Ftest_and_set%2Fexplicit-hle.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d76b6ea41791f792e202cde0eb5227cd1de80201/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_flag%2Ftest_and_set%2Fexplicit-hle.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_flag%2Ftest_and_set%2Fexplicit-hle.cc?ref=d76b6ea41791f792e202cde0eb5227cd1de80201", "patch": "@@ -0,0 +1,120 @@\n+// { dg-options \"-std=gnu++0x\" }\n+// { dg-do compile { target i?86-*-* x86_64-*-* } }\n+// { dg-final { scan-assembler-times \"\\(xacquire\\|\\.byte.*0xf2\\)\" 14 } }\n+// { dg-final { scan-assembler-times \"\\(xrelease\\|\\.byte.*0xf3\\)\" 14 } }\n+\n+// Copyright (C) 2008, 2009, 2013 Free Software Foundation, Inc.\n+//\n+// This file is part of the GNU ISO C++ Library.  This library is free\n+// software; you can redistribute it and/or modify it under the\n+// terms of the GNU General Public License as published by the\n+// Free Software Foundation; either version 3, or (at your option)\n+// any later version.\n+\n+// This library is distributed in the hope that it will be useful,\n+// but WITHOUT ANY WARRANTY; without even the implied warranty of\n+// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+// GNU General Public License for more details.\n+\n+// You should have received a copy of the GNU General Public License along\n+// with this library; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#include <atomic>\n+\n+#define ACQ memory_order_acquire | __memory_order_hle_acquire\n+#define REL memory_order_release | __memory_order_hle_release\n+\n+int main()\n+{\n+  unsigned zero, one;\n+  using namespace std;\n+  atomic_flag af = ATOMIC_FLAG_INIT;\n+\n+  if (!af.test_and_set(ACQ))\n+    af.clear(REL);\n+\n+  atomic_uint au = ATOMIC_VAR_INIT(0);\n+\n+  if (au.exchange(1, ACQ))\n+    au.store(0, REL);\n+\n+  if (au.exchange(1, ACQ))\n+    au.exchange(0, REL);\n+\n+  zero = 0;\n+  one = 1;\n+  if (au.compare_exchange_weak(zero, 1, ACQ, memory_order_consume))\n+    au.compare_exchange_weak(one, 0, REL, memory_order_consume);\n+\n+  zero = 0;\n+  one = 1;\n+  if (au.compare_exchange_strong(zero, 1, ACQ, memory_order_consume))\n+    au.compare_exchange_strong(one, 0, REL, memory_order_consume);\n+\n+  if (!au.fetch_add(1, ACQ))\n+    au.fetch_add(-1, REL);\n+\n+  if (!au.fetch_sub(1, ACQ))\n+    au.fetch_sub(-1, REL);\n+\n+#if 0 /* broken in underlying target */\n+  if (!au.fetch_and(1, ACQ))\n+    au.fetch_and(-1, REL);\n+\n+  if (!au.fetch_or(1, ACQ))\n+    au.fetch_or(-1, REL);\n+\n+  if (!au.fetch_xor(1, ACQ))\n+    au.fetch_xor(-1, REL);\n+\n+  if (!au.fetch_nand(1, ACQ))\n+    au.fetch_nand(-1, REL);\n+#endif\n+\n+  volatile atomic_flag vaf = ATOMIC_FLAG_INIT;\n+\n+  if (!vaf.test_and_set(ACQ))\n+    vaf.clear(REL);\n+\n+  volatile atomic_uint vau = ATOMIC_VAR_INIT(0);\n+\n+  if (!vau.exchange(1, ACQ))\n+    vau.store(0, REL);\n+\n+  if (!vau.exchange(1, ACQ))\n+    vau.exchange(0, REL);\n+\n+  zero = 0;\n+  one = 1;\n+  if (vau.compare_exchange_weak(zero, 1, ACQ, memory_order_consume))\n+    vau.compare_exchange_weak(one, 0, REL, memory_order_consume);\n+\n+  zero = 0;\n+  one = 1;\n+  if (vau.compare_exchange_strong(zero, 1, ACQ, memory_order_consume))\n+    vau.compare_exchange_strong(one, 0, REL, memory_order_consume);\n+\n+  if (!vau.fetch_add(1, ACQ))\n+    vau.fetch_add(-1, REL);\n+\n+  if (!vau.fetch_sub(1, ACQ))\n+    vau.fetch_sub(-1, REL);\n+\n+#if 0 /* broken in underlying target */\n+\n+  if (!vau.fetch_and(1, ACQ))\n+    vau.fetch_and(-1, REL);\n+\n+  if (!vau.fetch_or(1, ACQ))\n+    vau.fetch_or(-1, REL);\n+\n+  if (!vau.fetch_xor(1, ACQ))\n+    vau.fetch_xor(-1, REL);\n+\n+  if (!vau.fetch_nand(1, ACQ))\n+    vau.fetch_nand(-1, REL);\n+#endif\n+\n+  return 0;\n+}"}]}