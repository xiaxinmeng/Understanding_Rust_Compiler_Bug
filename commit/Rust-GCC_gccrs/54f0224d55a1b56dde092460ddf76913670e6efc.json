{"sha": "54f0224d55a1b56dde092460ddf76913670e6efc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTRmMDIyNGQ1NWExYjU2ZGRlMDkyNDYwZGRmNzY5MTM2NzBlNmVmYw==", "commit": {"author": {"name": "Patrick McGehearty", "email": "patrick.mcgehearty@oracle.com", "date": "2021-04-28T19:14:48Z"}, "committer": {"name": "Jose E. Marchesi", "email": "jose.marchesi@oracle.com", "date": "2021-04-28T19:54:44Z"}, "message": "Practical improvement to libgcc complex divide\n\nCorrectness and performance test programs used during development of\nthis project may be found in the attachment to:\nhttps://www.mail-archive.com/gcc-patches@gcc.gnu.org/msg254210.html\n\nSummary of Purpose\n\nThis patch to libgcc/libgcc2.c __divdc3 provides an\nopportunity to gain important improvements to the quality of answers\nfor the default complex divide routine (half, float, double, extended,\nlong double precisions) when dealing with very large or very small exponents.\n\nThe current code correctly implements Smith's method (1962) [2]\nfurther modified by c99's requirements for dealing with NaN (not a\nnumber) results. When working with input values where the exponents\nare greater than *_MAX_EXP/2 or less than -(*_MAX_EXP)/2, results are\nsubstantially different from the answers provided by quad precision\nmore than 1% of the time. This error rate may be unacceptable for many\napplications that cannot a priori restrict their computations to the\nsafe range. The proposed method reduces the frequency of\n\"substantially different\" answers by more than 99% for double\nprecision at a modest cost of performance.\n\nDifferences between current gcc methods and the new method will be\ndescribed. Then accuracy and performance differences will be discussed.\n\nBackground\n\nThis project started with an investigation related to\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=59714.  Study of Beebe[1]\nprovided an overview of past and recent practice for computing complex\ndivide. The current glibc implementation is based on Robert Smith's\nalgorithm [2] from 1962.  A google search found the paper by Baudin\nand Smith [3] (same Robert Smith) published in 2012. Elen Kalda's\nproposed patch [4] is based on that paper.\n\nI developed two sets of test data by randomly distributing values over\na restricted range and the full range of input values. The current\ncomplex divide handled the restricted range well enough, but failed on\nthe full range more than 1% of the time. Baudin and Smith's primary\ntest for \"ratio\" equals zero reduced the cases with 16 or more error\nbits by a factor of 5, but still left too many flawed answers. Adding\ndebug print out to cases with substantial errors allowed me to see the\nintermediate calculations for test values that failed. I noted that\nfor many of the failures, \"ratio\" was a subnormal. Changing the\n\"ratio\" test from check for zero to check for subnormal reduced the 16\nbit error rate by another factor of 12. This single modified test\nprovides the greatest benefit for the least cost, but the percentage\nof cases with greater than 16 bit errors (double precision data) is\nstill greater than 0.027% (2.7 in 10,000).\n\nContinued examination of remaining errors and their intermediate\ncomputations led to the various tests of input value tests and scaling\nto avoid under/overflow. The current patch does not handle some of the\nrare and most extreme combinations of input values, but the random\ntest data is only showing 1 case in 10 million that has an error of\ngreater than 12 bits. That case has 18 bits of error and is due to\nsubtraction cancellation. These results are significantly better\nthan the results reported by Baudin and Smith.\n\nSupport for half, float, double, extended, and long double precision\nis included as all are handled with suitable preprocessor symbols in a\nsingle source routine. Since half precision is computed with float\nprecision as per current libgcc practice, the enhanced algorithm\nprovides no benefit for half precision and would cost performance.\nFurther investigation showed changing the half precision algorithm\nto use the simple formula (real=a*c+b*d imag=b*c-a*d) caused no\nloss of precision and modest improvement in performance.\n\nThe existing constants for each precision:\nfloat: FLT_MAX, FLT_MIN;\ndouble: DBL_MAX, DBL_MIN;\nextended and/or long double: LDBL_MAX, LDBL_MIN\nare used for avoiding the more common overflow/underflow cases.  This\nuse is made generic by defining appropriate __LIBGCC2_* macros in\nc-cppbuiltin.c.\n\nTests are added for when both parts of the denominator have exponents\nsmall enough to allow shifting any subnormal values to normal values\nall input values could be scaled up without risking overflow. That\ngained a clear improvement in accuracy. Similarly, when either\nnumerator was subnormal and the other numerator and both denominator\nvalues were not too large, scaling could be used to reduce risk of\ncomputing with subnormals.  The test and scaling values used all fit\nwithin the allowed exponent range for each precision required by the C\nstandard.\n\nFloat precision has more difficulty with getting correct answers than\ndouble precision. When hardware for double precision floating point\noperations is available, float precision is now handled in double\nprecision intermediate calculations with the simple algorithm the same\nas the half-precision method of using float precision for intermediate\ncalculations. Using the higher precision yields exact results for all\ntested input values (64-bit double, 32-bit float) with the only\nperformance cost being the requirement to convert the four input\nvalues from float to double. If double precision hardware is not\navailable, then float complex divide will use the same improved\nalgorithm as the other precisions with similar change in performance.\n\nFurther Improvement\n\nThe most common remaining substantial errors are due to accuracy loss\nwhen subtracting nearly equal values. This patch makes no attempt to\nimprove that situation.\n\nNOTATION\n\nFor all of the following, the notation is:\nInput complex values:\n  a+bi  (a= real part, b= imaginary part)\n  c+di\nOutput complex value:\n  e+fi = (a+bi)/(c+di)\n\nFor the result tables:\ncurrent = current method (SMITH)\nb1div = method proposed by Elen Kalda\nb2div = alternate method considered by Elen Kalda\nnew = new method proposed by this patch\n\nDESCRIPTIONS of different complex divide methods:\n\nNAIVE COMPUTATION (-fcx-limited-range):\n  e = (a*c + b*d)/(c*c + d*d)\n  f = (b*c - a*d)/(c*c + d*d)\n\nNote that c*c and d*d will overflow or underflow if either\nc or d is outside the range 2^-538 to 2^512.\n\nThis method is available in gcc when the switch -fcx-limited-range is\nused. That switch is also enabled by -ffast-math. Only one who has a\nclear understanding of the maximum range of all intermediate values\ngenerated by an application should consider using this switch.\n\nSMITH's METHOD (current libgcc):\n  if(fabs(c)<fabs(d) {\n    r = c/d;\n    denom = (c*r) + d;\n    e = (a*r + b) / denom;\n    f = (b*r - a) / denom;\n  } else {\n    r = d/c;\n    denom = c + (d*r);\n    e = (a + b*r) / denom;\n    f = (b - a*r) / denom;\n  }\n\nSmith's method is the current default method available with __divdc3.\n\nElen Kalda's METHOD\n\nElen Kalda proposed a patch about a year ago, also based on Baudin and\nSmith, but not including tests for subnormals:\nhttps://gcc.gnu.org/legacy-ml/gcc-patches/2019-08/msg01629.html [4]\nIt is compared here for accuracy with this patch.\n\nThis method applies the most significant part of the algorithm\nproposed by Baudin&Smith (2012) in the paper \"A Robust Complex\nDivision in Scilab\" [3]. Elen's method also replaces two divides by\none divide and two multiplies due to the high cost of divide on\naarch64. In the comparison sections, this method will be labeled\nb1div. A variation discussed in that patch which does not replace the\ntwo divides will be labeled b2div.\n\n  inline void improved_internal (MTYPE a, MTYPE b, MTYPE c, MTYPE d)\n  {\n    r = d/c;\n    t = 1.0 / (c + (d * r));\n    if (r != 0) {\n        x = (a + (b * r)) * t;\n        y = (b - (a * r)) * t;\n    }  else {\n    /* Changing the order of operations avoids the underflow of r impacting\n     the result. */\n        x = (a + (d * (b / c))) * t;\n        y = (b - (d * (a / c))) * t;\n    }\n  }\n\n  if (FABS (d) < FABS (c)) {\n      improved_internal (a, b, c, d);\n  } else {\n      improved_internal (b, a, d, c);\n      y = -y;\n  }\n\nNEW METHOD (proposed by patch) to replace the current default method:\n\nThe proposed method starts with an algorithm proposed by Baudin&Smith\n(2012) in the paper \"A Robust Complex Division in Scilab\" [3]. The\npatch makes additional modifications to that method for further\nreductions in the error rate. The following code shows the #define\nvalues for double precision. See the patch for #define values used\nfor other precisions.\n\n  #define RBIG ((DBL_MAX)/2.0)\n  #define RMIN (DBL_MIN)\n  #define RMIN2 (0x1.0p-53)\n  #define RMINSCAL (0x1.0p+51)\n  #define RMAX2  ((RBIG)*(RMIN2))\n\n  if (FABS(c) < FABS(d)) {\n  /* prevent overflow when arguments are near max representable */\n  if ((FABS (d) > RBIG) || (FABS (a) > RBIG) || (FABS (b) > RBIG) ) {\n      a = a * 0.5;\n      b = b * 0.5;\n      c = c * 0.5;\n      d = d * 0.5;\n  }\n  /* minimize overflow/underflow issues when c and d are small */\n  else if (FABS (d) < RMIN2) {\n      a = a * RMINSCAL;\n      b = b * RMINSCAL;\n      c = c * RMINSCAL;\n      d = d * RMINSCAL;\n  }\n  else {\n    if(((FABS (a) < RMIN) && (FABS (b) < RMAX2) && (FABS (d) < RMAX2)) ||\n       ((FABS (b) < RMIN) && (FABS (a) < RMAX2) && (FABS (d) < RMAX2))) {\n        a = a * RMINSCAL;\n        b = b * RMINSCAL;\n        c = c * RMINSCAL;\n        d = d * RMINSCAL;\n    }\n  }\n  r = c/d; denom = (c*r) + d;\n  if( r > RMIN ) {\n      e = (a*r + b) / denom   ;\n      f = (b*r - a) / denom\n  } else {\n      e = (c * (a/d) + b) / denom;\n      f = (c * (b/d) - a) / denom;\n  }\n  }\n[ only presenting the fabs(c) < fabs(d) case here, full code in patch. ]\n\nBefore any computation of the answer, the code checks for any input\nvalues near maximum to allow down scaling to avoid overflow.  These\nscalings almost never harm the accuracy since they are by 2. Values that\nare over RBIG are relatively rare but it is easy to test for them and\nallow aviodance of overflows.\n\nTesting for RMIN2 reveals when both c and d are less than [FLT|DBL]_EPSILON.\nBy scaling all values by 1/EPSILON, the code converts subnormals to normals,\navoids loss of accuracy and underflows in intermediate computations\nthat otherwise might occur. If scaling a and b by 1/EPSILON causes either\nto overflow, then the computation will overflow whatever method is used.\n\nFinally, we test for either a or b being subnormal (RMIN) and if so,\nfor the other three values being small enough to allow scaling.  We\nonly need to test a single denominator value since we have already\ndetermined which of c and d is larger.\n\nNext, r (the ratio of c to d) is checked for being near zero. Baudin\nand Smith checked r for zero. This code improves that approach by\nchecking for values less than DBL_MIN (subnormal) covers roughly 12\ntimes as many cases and substantially improves overall accuracy. If r\nis too small, then when it is used in a multiplication, there is a\nhigh chance that the result will underflow to zero, losing significant\naccuracy. That underflow is avoided by reordering the computation.\nWhen r is subnormal, the code replaces a*r (= a*(c/d)) with ((a/d)*c)\nwhich is mathematically the same but avoids the unnecessary underflow.\n\nTEST Data\n\nTwo sets of data are presented to test these methods. Both sets\ncontain 10 million pairs of complex values.  The exponents and\nmantissas are generated using multiple calls to random() and then\ncombining the results. Only values which give results to complex\ndivide that are representable in the appropriate precision after\nbeing computed in quad precision are used.\n\nThe first data set is labeled \"moderate exponents\".\nThe exponent range is limited to -DBL_MAX_EXP/2 to DBL_MAX_EXP/2\nfor Double Precision (use FLT_MAX_EXP or LDBL_MAX_EXP for the\nappropriate precisions.\nThe second data set is labeled \"full exponents\".\nThe exponent range for these cases is the full exponent range\nincluding subnormals for a given precision.\n\nACCURACY Test results:\n\nNote: The following accuracy tests are based on IEEE-754 arithmetic.\n\nNote: All results reporteed are based on use of fused multiply-add. If\nfused multiply-add is not used, the error rate increases, giving more\n1 and 2 bit errors for both current and new complex divide.\nDifferences between using fused multiply and not using it that are\ngreater than 2 bits are less than 1 in a million.\n\nThe complex divide methods are evaluated by determining the percentage\nof values that exceed differences in low order bits.  If a \"2 bit\"\ntest results show 1%, that would mean that 1% of 10,000,000 values\n(100,000) have either a real or imaginary part that differs from the\nquad precision result by more than the last 2 bits.\n\nResults are reported for differences greater than or equal to 1 bit, 2\nbits, 8 bits, 16 bits, 24 bits, and 52 bits for double precision.  Even\nwhen the patch avoids overflows and underflows, some input values are\nexpected to have errors due to the potential for catastrophic roundoff\nfrom floating point subtraction. For example, when b*c and a*d are\nnearly equal, the result of subtraction may lose several places of\naccuracy. This patch does not attempt to detect or minimize this type\nof error, but neither does it increase them.\n\nI only show the results for Elen Kalda's method (with both 1 and\n2 divides) and the new method for only 1 divide in the double\nprecision table.\n\nIn the following charts, lower values are better.\n\ncurrent - current complex divide in libgcc\nb1div - Elen Kalda's method from Baudin & Smith with one divide\nb2div - Elen Kalda's method from Baudin & Smith with two divides\nnew   - This patch which uses 2 divides\n\n===================================================\nErrors   Moderate Dataset\ngtr eq     current    b1div      b2div        new\n======    ========   ========   ========   ========\n 1 bit    0.24707%   0.92986%   0.24707%   0.24707%\n 2 bits   0.01762%   0.01770%   0.01762%   0.01762%\n 8 bits   0.00026%   0.00026%   0.00026%   0.00026%\n16 bits   0.00000%   0.00000%   0.00000%   0.00000%\n24 bits         0%         0%         0%         0%\n52 bits         0%         0%         0%         0%\n===================================================\nTable 1: Errors with Moderate Dataset (Double Precision)\n\nNote in Table 1 that both the old and new methods give identical error\nrates for data with moderate exponents. Errors exceeding 16 bits are\nexceedingly rare. There are substantial increases in the 1 bit error\nrates for b1div (the 1 divide/2 multiplys method) as compared to b2div\n(the 2 divides method). These differences are minimal for 2 bits and\nlarger error measurements.\n\n===================================================\nErrors   Full Dataset\ngtr eq     current    b1div      b2div        new\n======    ========   ========   ========   ========\n 1 bit      2.05%   1.23842%    0.67130%   0.16664%\n 2 bits     1.88%   0.51615%    0.50354%   0.00900%\n 8 bits     1.77%   0.42856%    0.42168%   0.00011%\n16 bits     1.63%   0.33840%    0.32879%   0.00001%\n24 bits     1.51%   0.25583%    0.24405%   0.00000%\n52 bits     1.13%   0.01886%    0.00350%   0.00000%\n===================================================\nTable 2: Errors with Full Dataset (Double Precision)\n\nTable 2 shows significant differences in error rates. First, the\ndifference between b1div and b2div show a significantly higher error\nrate for the b1div method both for single bit errros and well\nbeyond. Even for 52 bits, we see the b1div method gets completely\nwrong answers more than 5 times as often as b2div. To retain\ncomparable accuracy with current complex divide results for small\nexponents and due to the increase in errors for large exponents, I\nchoose to use the more accurate method of two divides.\n\nThe current method has more 1.6% of cases where it is getting results\nwhere the low 24 bits of the mantissa differ from the correct\nanswer. More than 1.1% of cases where the answer is completely wrong.\nThe new method shows less than one case in 10,000 with greater than\ntwo bits of error and only one case in 10 million with greater than\n16 bits of errors. The new patch reduces 8 bit errors by\na factor of 16,000 and virtually eliminates completely wrong\nanswers.\n\nAs noted above, for architectures with double precision\nhardware, the new method uses that hardware for the\nintermediate calculations before returning the\nresult in float precision. Testing of the new patch\nhas shown zero errors found as seen in Tables 3 and 4.\n\nCorrectness for float\n=============================\nErrors   Moderate Dataset\ngtr eq     current     new\n======    ========   ========\n 1 bit   28.68070%         0%\n 2 bits   0.64386%         0%\n 8 bits   0.00401%         0%\n16 bits   0.00001%         0%\n24 bits         0%         0%\n=============================\nTable 3: Errors with Moderate Dataset (float)\n\n=============================\nErrors   Full Dataset\ngtr eq     current     new\n======    ========   ========\n 1 bit     19.98%         0%\n 2 bits     3.20%         0%\n 8 bits     1.97%         0%\n16 bits     1.08%         0%\n24 bits     0.55%         0%\n=============================\nTable 4: Errors with Full Dataset (float)\n\nAs before, the current method shows an troubling rate of extreme\nerrors.\n\nThere very minor changes in accuracy for half-precision since the code\nchanges from Smith's method to the simple method. 5 out of 1 million\ntest cases show correct answers instead of 1 or 2 bit errors.\nlibgcc computes half-precision functions in float precision\nallowing the existing methods to avoid overflow/underflow issues\nfor the allowed range of exponents for half-precision.\n\nExtended precision (using x87 80-bit format on x86) and Long double\n(using IEEE-754 128-bit on x86 and aarch64) both have 15-bit exponents\nas compared to 11-bit exponents in double precision. We note that the\nC standard also allows Long Double to be implemented in the equivalent\nrange of Double. The RMIN2 and RMINSCAL constants are selected to work\nwithin the Double range as well as with extended and 128-bit ranges.\nWe will limit our performance and accurancy discussions to the 80-bit\nand 128-bit formats as seen on x86 here.\n\nThe extended and long double precision investigations were more\nlimited. Aarch64 does not support extended precision but does support\nthe software implementation of 128-bit long double precision. For x86,\nlong double defaults to the 80-bit precision but using the\n-mlong-double-128 flag switches to using the software implementation\nof 128-bit precision. Both 80-bit and 128-bit precisions have the same\nexponent range, with the 128-bit precision has extended mantissas.\nSince this change is only aimed at avoiding underflow/overflow for\nextreme exponents, I studied the extended precision results on x86 for\n100,000 values. The limited exponent dataset showed no differences.\nFor the dataset with full exponent range, the current and new values\nshowed major differences (greater than 32 bits) in 567 cases out of\n100,000 (0.56%). In every one of these cases, the ratio of c/d or d/c\n(as appropriate) was zero or subnormal, indicating the advantage of\nthe new method and its continued correctness where needed.\n\nPERFORMANCE Test results\n\nIn order for a library change to be practical, it is necessary to show\nthe slowdown is tolerable. The slowdowns observed are much less than\nwould be seen by (for example) switching from hardware double precison\nto a software quad precision, which on the tested machines causes a\nslowdown of around 100x).\n\nThe actual slowdown depends on the machine architecture. It also\ndepends on the nature of the input data. If underflow/overflow is\nrare, then implementations that have strong branch prediction will\nonly slowdown by a few cycles. If underflow/overflow is common, then\nthe branch predictors will be less accurate and the cost will be\nhigher.\n\nResults from two machines are presented as examples of the overhead\nfor the new method. The one labeled x86 is a 5 year old Intel x86\nprocessor and the one labeled aarch64 is a 3 year old arm64 processor.\n\nIn the following chart, the times are averaged over a one million\nvalue data set. All values are scaled to set the time of the current\nmethod to be 1.0. Lower values are better. A value of less than 1.0\nwould be faster than the current method and a value greater than 1.0\nwould be slower than the current method.\n\n================================================\n               Moderate set          full set\n               x86  aarch64        x86  aarch64\n========     ===============     ===============\nfloat         0.59    0.79        0.45    0.81\ndouble        1.04    1.24        1.38    1.56\nlong double   1.13    1.24        1.29    1.25\n================================================\nTable 5: Performance Comparisons (ratio new/current)\n\nThe above tables omit the timing for the 1 divide and 2 multiply\ncomparison with the 2 divide approach.\n\nThe float results show clear performance improvement due to using the\nsimple method with double precision for intermediate calculations.\n\nThe double results with the newer method show less overhead for the\nmoderate dataset than for the full dataset. That's because the moderate\ndataset does not ever take the new branches which protect from\nunder/overflow. The better the branch predictor, the lower the cost\nfor these untaken branches. Both platforms are somewhat dated, with\nthe x86 having a better branch predictor which reduces the cost of the\nadditional branches in the new code. Of course, the relative slowdown\nmay be greater for some architectures, especially those with limited\nbranch prediction combined with a high cost of misprediction.\n\nThe long double results are fairly consistent in showing the moderate\nadditional cost of the extra branches and calculations for all cases.\n\nThe observed cost for all precisions is claimed to be tolerable on the\ngrounds that:\n\n(a) the cost is worthwhile considering the accuracy improvement shown.\n(b) most applications will only spend a small fraction of their time\n    calculating complex divide.\n(c) it is much less than the cost of extended precision\n(d) users are not forced to use it (as described below)\n\nThose users who find this degree of slowdown unsatisfactory may use\nthe gcc switch -fcx-fortran-rules which does not use the library\nroutine, instead inlining Smith's method without the C99 requirement\nfor dealing with NaN results. The proposed patch for libgcc complex\ndivide does not affect the code generated by -fcx-fortran-rules.\n\nSUMMARY\n\nWhen input data to complex divide has exponents whose absolute value\nis less than half of *_MAX_EXP, this patch makes no changes in\naccuracy and has only a modest effect on performance.  When input data\ncontains values outside those ranges, the patch eliminates more than\n99.9% of major errors with a tolerable cost in performance.\n\nIn comparison to Elen Kalda's method, this patch introduces more\nperformance overhead but reduces major errors by a factor of\ngreater than 4000.\n\nREFERENCES\n\n[1] Nelson H.F. Beebe, \"The Mathematical-Function Computation Handbook.\nSpringer International Publishing AG, 2017.\n\n[2] Robert L. Smith. Algorithm 116: Complex division.  Commun. ACM,\n 5(8):435, 1962.\n\n[3] Michael Baudin and Robert L. Smith. \"A robust complex division in\nScilab,\" October 2012, available at http://arxiv.org/abs/1210.4539.\n\n[4] Elen Kalda: Complex division improvements in libgcc\nhttps://gcc.gnu.org/legacy-ml/gcc-patches/2019-08/msg01629.html\n\n2020-12-08  Patrick McGehearty  <patrick.mcgehearty@oracle.com>\n\ngcc/c-family/\n\t* c-cppbuiltin.c (c_cpp_builtins): Add supporting macros for new\n\tcomplex divide\nlibgcc/\n\t* libgcc2.c (XMTYPE, XCTYPE, RBIG, RMIN, RMIN2, RMINSCAL, RMAX2):\n\tDefine.\n\t(__divsc3, __divdc3, __divxc3, __divtc3): Improve complex divide.\n\t* config/rs6000/_divkc3.c (RBIG, RMIN, RMIN2, RMINSCAL, RMAX2):\n\tDefine.\n\t(__divkc3): Improve complex divide.\ngcc/testsuite/\n\t* gcc.c-torture/execute/ieee/cdivchkd.c: New test.\n\t* gcc.c-torture/execute/ieee/cdivchkf.c: Likewise.\n\t* gcc.c-torture/execute/ieee/cdivchkld.c: Likewise.", "tree": {"sha": "82cf71c5b7d80b15323a691976811d5884c9a1c4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/82cf71c5b7d80b15323a691976811d5884c9a1c4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/54f0224d55a1b56dde092460ddf76913670e6efc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/54f0224d55a1b56dde092460ddf76913670e6efc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/54f0224d55a1b56dde092460ddf76913670e6efc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/54f0224d55a1b56dde092460ddf76913670e6efc/comments", "author": {"login": "patrickmcgehearty", "id": 68669378, "node_id": "MDQ6VXNlcjY4NjY5Mzc4", "avatar_url": "https://avatars.githubusercontent.com/u/68669378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/patrickmcgehearty", "html_url": "https://github.com/patrickmcgehearty", "followers_url": "https://api.github.com/users/patrickmcgehearty/followers", "following_url": "https://api.github.com/users/patrickmcgehearty/following{/other_user}", "gists_url": "https://api.github.com/users/patrickmcgehearty/gists{/gist_id}", "starred_url": "https://api.github.com/users/patrickmcgehearty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/patrickmcgehearty/subscriptions", "organizations_url": "https://api.github.com/users/patrickmcgehearty/orgs", "repos_url": "https://api.github.com/users/patrickmcgehearty/repos", "events_url": "https://api.github.com/users/patrickmcgehearty/events{/privacy}", "received_events_url": "https://api.github.com/users/patrickmcgehearty/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jemarch", "id": 7061875, "node_id": "MDQ6VXNlcjcwNjE4NzU=", "avatar_url": "https://avatars.githubusercontent.com/u/7061875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jemarch", "html_url": "https://github.com/jemarch", "followers_url": "https://api.github.com/users/jemarch/followers", "following_url": "https://api.github.com/users/jemarch/following{/other_user}", "gists_url": "https://api.github.com/users/jemarch/gists{/gist_id}", "starred_url": "https://api.github.com/users/jemarch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jemarch/subscriptions", "organizations_url": "https://api.github.com/users/jemarch/orgs", "repos_url": "https://api.github.com/users/jemarch/repos", "events_url": "https://api.github.com/users/jemarch/events{/privacy}", "received_events_url": "https://api.github.com/users/jemarch/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4c84c45d8ab5ef55aabef18da17244dc13170f9c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4c84c45d8ab5ef55aabef18da17244dc13170f9c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4c84c45d8ab5ef55aabef18da17244dc13170f9c"}], "stats": {"total": 734, "additions": 704, "deletions": 30}, "files": [{"sha": "42b7604c9ac243854a8d4c141a5047262f512921", "filename": "gcc/c-family/c-cppbuiltin.c", "status": "modified", "additions": 46, "deletions": 12, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Fc-family%2Fc-cppbuiltin.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Fc-family%2Fc-cppbuiltin.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-cppbuiltin.c?ref=54f0224d55a1b56dde092460ddf76913670e6efc", "patch": "@@ -1277,29 +1277,39 @@ c_cpp_builtins (cpp_reader *pfile)\n \t{\n \t  scalar_float_mode mode = mode_iter.require ();\n \t  const char *name = GET_MODE_NAME (mode);\n+\t  const size_t name_len = strlen (name);\n+\t  char float_h_prefix[16] = \"\";\n \t  char *macro_name\n-\t    = (char *) alloca (strlen (name)\n-\t\t\t       + sizeof (\"__LIBGCC__MANT_DIG__\"));\n+\t    = XALLOCAVEC (char, name_len + sizeof (\"__LIBGCC__MANT_DIG__\"));\n \t  sprintf (macro_name, \"__LIBGCC_%s_MANT_DIG__\", name);\n \t  builtin_define_with_int_value (macro_name,\n \t\t\t\t\t REAL_MODE_FORMAT (mode)->p);\n \t  if (!targetm.scalar_mode_supported_p (mode)\n \t      || !targetm.libgcc_floating_mode_supported_p (mode))\n \t    continue;\n-\t  macro_name = (char *) alloca (strlen (name)\n-\t\t\t\t\t+ sizeof (\"__LIBGCC_HAS__MODE__\"));\n+\t  macro_name = XALLOCAVEC (char, name_len\n+\t\t\t\t   + sizeof (\"__LIBGCC_HAS__MODE__\"));\n \t  sprintf (macro_name, \"__LIBGCC_HAS_%s_MODE__\", name);\n \t  cpp_define (pfile, macro_name);\n-\t  macro_name = (char *) alloca (strlen (name)\n-\t\t\t\t\t+ sizeof (\"__LIBGCC__FUNC_EXT__\"));\n+\t  macro_name = XALLOCAVEC (char, name_len\n+\t\t\t\t   + sizeof (\"__LIBGCC__FUNC_EXT__\"));\n \t  sprintf (macro_name, \"__LIBGCC_%s_FUNC_EXT__\", name);\n \t  char suffix[20] = \"\";\n \t  if (mode == TYPE_MODE (double_type_node))\n-\t    ; /* Empty suffix correct.  */\n+\t    {\n+\t      /* Empty suffix correct.  */\n+\t      memcpy (float_h_prefix, \"DBL\", 4);\n+\t    }\n \t  else if (mode == TYPE_MODE (float_type_node))\n-\t    suffix[0] = 'f';\n+\t    {\n+\t      suffix[0] = 'f';\n+\t      memcpy (float_h_prefix, \"FLT\", 4);\n+\t    }\n \t  else if (mode == TYPE_MODE (long_double_type_node))\n-\t    suffix[0] = 'l';\n+\t    {\n+\t      suffix[0] = 'l';\n+\t      memcpy (float_h_prefix, \"LDBL\", 5);\n+\t    }\n \t  else\n \t    {\n \t      bool found_suffix = false;\n@@ -1310,6 +1320,8 @@ c_cpp_builtins (cpp_reader *pfile)\n \t\t    sprintf (suffix, \"f%d%s\", floatn_nx_types[i].n,\n \t\t\t     floatn_nx_types[i].extended ? \"x\" : \"\");\n \t\t    found_suffix = true;\n+\t\t    sprintf (float_h_prefix, \"FLT%d%s\", floatn_nx_types[i].n,\n+\t\t\t     floatn_nx_types[i].extended ? \"X\" : \"\");\n \t\t    break;\n \t\t  }\n \t      gcc_assert (found_suffix);\n@@ -1347,11 +1359,33 @@ c_cpp_builtins (cpp_reader *pfile)\n \t    default:\n \t      gcc_unreachable ();\n \t    }\n-\t  macro_name = (char *) alloca (strlen (name)\n-\t\t\t\t\t+ sizeof (\"__LIBGCC__EXCESS_\"\n-\t\t\t\t\t\t  \"PRECISION__\"));\n+\t  macro_name = XALLOCAVEC (char, name_len\n+\t\t\t\t   + sizeof (\"__LIBGCC__EXCESS_PRECISION__\"));\n \t  sprintf (macro_name, \"__LIBGCC_%s_EXCESS_PRECISION__\", name);\n \t  builtin_define_with_int_value (macro_name, excess_precision);\n+\n+\t  char val_name[64];\n+\n+\t  macro_name = XALLOCAVEC (char, name_len\n+\t\t\t\t   + sizeof (\"__LIBGCC__EPSILON__\"));\n+\t  sprintf (macro_name, \"__LIBGCC_%s_EPSILON__\", name);\n+\t  sprintf (val_name, \"__%s_EPSILON__\", float_h_prefix);\n+\t  builtin_define_with_value (macro_name, val_name, 0);\n+\n+\t  macro_name = XALLOCAVEC (char, name_len + sizeof (\"__LIBGCC__MAX__\"));\n+\t  sprintf (macro_name, \"__LIBGCC_%s_MAX__\", name);\n+\t  sprintf (val_name, \"__%s_MAX__\", float_h_prefix);\n+\t  builtin_define_with_value (macro_name, val_name, 0);\n+\n+\t  macro_name = XALLOCAVEC (char, name_len + sizeof (\"__LIBGCC__MIN__\"));\n+\t  sprintf (macro_name, \"__LIBGCC_%s_MIN__\", name);\n+\t  sprintf (val_name, \"__%s_MIN__\", float_h_prefix);\n+\t  builtin_define_with_value (macro_name, val_name, 0);\n+\n+#ifdef HAVE_adddf3\n+\t  builtin_define_with_int_value (\"__LIBGCC_HAVE_HWDBL__\",\n+\t\t\t\t\t HAVE_adddf3);\n+#endif\n \t}\n \n       /* For libgcc crtstuff.c and libgcc2.c.  */"}, {"sha": "3ef5fadcf2a7d1ea121dc9d957f8222575b894f3", "filename": "gcc/testsuite/gcc.c-torture/execute/ieee/cdivchkd.c", "status": "added", "additions": 126, "deletions": 0, "changes": 126, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkd.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkd.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkd.c?ref=54f0224d55a1b56dde092460ddf76913670e6efc", "patch": "@@ -0,0 +1,126 @@\n+/*\n+  Program to test complex divide for correct results on selected values.\n+  Checking known failure points.\n+*/\n+\n+#include <float.h>\n+\n+extern void abort (void);\n+extern void exit (int);\n+\n+extern int ilogb (double);\n+int match (double _Complex, double _Complex);\n+\n+#define SMALL DBL_MIN\n+#define MAXBIT DBL_MANT_DIG\n+#define ERRLIM 6\n+\n+/*\n+  Compare c (computed value) with z (expected value).\n+  Return 0 if within allowed range.  Return 1 if not.\n+*/\n+int match (double _Complex c, double _Complex z)\n+{\n+  double rz, iz, rc, ic;\n+  double rerr, ierr, rmax;\n+  int biterr;\n+  rz = __real__ z;\n+  iz = __imag__ z;\n+  rc = __real__ c;\n+  ic = __imag__ c;\n+\n+  if (__builtin_fabs (rz) > SMALL)\n+    {\n+      rerr = __builtin_fabs (rz - rc) / __builtin_fabs (rz);\n+    }\n+  else if (__builtin_fabs (rz) == 0.0)\n+    {\n+      rerr = __builtin_fabs (rc);\n+    }\n+  else\n+    {\n+      rerr = __builtin_fabs (rz - rc) / SMALL;\n+    }\n+\n+  if (__builtin_fabs (iz) > SMALL)\n+    {\n+      ierr = __builtin_fabs (iz - ic) / __builtin_fabs (iz);\n+    }\n+  else if (__builtin_fabs (iz) == 0.0)\n+    {\n+      ierr = __builtin_fabs (ic);\n+    }\n+  else\n+    {\n+      ierr = __builtin_fabs (iz - ic) / SMALL;\n+    }\n+  rmax = __builtin_fmax(rerr, ierr);\n+  biterr = 0;\n+  if ( rmax != 0.0)      \n+    {\n+      biterr = ilogb (rmax) + MAXBIT + 1;\n+    }\n+\n+  if (biterr >= ERRLIM)\n+    return 0;\n+  else\n+    return 1;\n+}\n+\n+\n+int main (int argc, char** argv)\n+{\n+  double _Complex a,b,c,z;\n+  double xr[4], xi[4], yr[4], yi[4], zr[4], zi[4];\n+  double cr, ci;\n+  int i;\n+  int ok = 1;\n+  xr[0] = -0x1.16e7fad79e45ep+651;\n+  xi[0] = -0x1.f7f75b94c6c6ap-860;\n+  yr[0] = -0x1.2f40d8ff7e55ep+245;\n+  yi[0] = -0x0.0000000004ebcp-1022;\n+  zr[0] = 0x1.d6e4b0e282869p+405;\n+  zi[0] = -0x1.e9095e311e706p-900;\n+\n+  xr[1] = -0x1.21ff587f953d3p-310;\n+  xi[1] = -0x1.5a526dcc59960p+837;\n+  yr[1] = 0x1.b88b8b552eaadp+735;\n+  yi[1] = -0x1.873e2d6544d92p-327;\n+  zr[1] = 0x1.65734a88b2de0p-961;\n+  zi[1] =  -0x1.927e85b8b5770p+101;\n+\n+  xr[2] = 0x1.4612e41aa8080p-846;\n+  xi[2] = -0x0.0000000613e07p-1022;\n+  yr[2] = 0x1.df9cd0d58caafp-820;\n+  yi[2] = -0x1.e47051a9036dbp-584;\n+  zr[2] = 0x1.9b194f3fffa32p-469;\n+  zi[2] = 0x1.58a00ab740a6bp-263;\n+\n+  xr[3] = 0x1.cb27eece7c585p-355;\n+  xi[3] = 0x0.000000223b8a8p-1022;\n+  yr[3] = -0x1.74e7ed2b9189fp-22;\n+  yi[3] = 0x1.3d80439e9a119p-731;\n+  zr[3] = -0x1.3b35ed806ae5ap-333;\n+  zi[3] = -0x0.05e01bcbfd9f6p-1022;\n+\n+\n+  for (i = 0; i < 4; i++)\n+    {\n+      __real__ a = xr[i];\n+      __imag__ a = xi[i];\n+      __real__ b = yr[i];\n+      __imag__ b = yi[i];\n+      __real__ z = zr[i];\n+      __imag__ z = zi[i];\n+      c = a / b;\n+      cr = __real__ c;\n+      ci = __imag__ c;\n+\n+      if (!match (c,z)){\n+\tok = 0;\n+      }\n+    }\n+  if (!ok)\n+    abort ();\n+  exit (0);\n+}"}, {"sha": "adf1ed91dc7d7187d652e6a2e97eec1d5b7924df", "filename": "gcc/testsuite/gcc.c-torture/execute/ieee/cdivchkf.c", "status": "added", "additions": 125, "deletions": 0, "changes": 125, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkf.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkf.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkf.c?ref=54f0224d55a1b56dde092460ddf76913670e6efc", "patch": "@@ -0,0 +1,125 @@\n+/*\n+  Program to test complex divide for correct results on selected values.\n+  Checking known failure points.\n+*/\n+\n+#include <float.h>\n+\n+extern void abort (void);\n+extern void exit (int);\n+\n+extern int ilogbf (float);\n+int match (float _Complex, float _Complex);\n+\n+#define SMALL FLT_MIN\n+#define MAXBIT FLT_MANT_DIG\n+#define ERRLIM 6\n+\n+/*\n+  Compare c (computed value) with z (expected value).\n+  Return 0 if within allowed range.  Return 1 if not.\n+*/\n+int match (float _Complex c, float _Complex z)\n+{\n+  float rz, iz, rc, ic;\n+  float rerr, ierr, rmax;\n+  int biterr;\n+  rz = __real__ z;\n+  iz = __imag__ z;\n+  rc = __real__ c;\n+  ic = __imag__ c;\n+\n+  if (__builtin_fabsf (rz) > SMALL)\n+    {\n+      rerr = __builtin_fabsf (rz - rc) / __builtin_fabsf (rz);\n+    }\n+  else if (__builtin_fabsf (rz) == 0.0)\n+    {\n+      rerr = __builtin_fabsf (rc);\n+    }\n+  else\n+    {\n+      rerr = __builtin_fabsf (rz - rc) / SMALL;\n+    }\n+\n+  if (__builtin_fabsf (iz) > SMALL)\n+    {\n+      ierr = __builtin_fabsf (iz - ic) / __builtin_fabsf (iz);\n+    }\n+  else if (__builtin_fabsf (iz) == 0.0)\n+    {\n+      ierr = __builtin_fabsf (ic);\n+    }\n+  else\n+    {\n+      ierr = __builtin_fabsf (iz - ic) / SMALL;\n+    }\n+  rmax = __builtin_fmaxf(rerr, ierr);\n+  biterr = 0;\n+  if ( rmax != 0.0)      \n+    {\n+      biterr = ilogbf (rmax) + MAXBIT + 1;\n+    }\n+\n+  if (biterr >= ERRLIM)\n+    return 0;\n+  else\n+    return 1;\n+}\n+\n+\n+int main(int argc, char** argv)\n+{\n+  float _Complex a,b,c,z;\n+  float xr[4], xi[4], yr[4], yi[4], zr[4], zi[4];\n+  float cr, ci;\n+  int i;\n+  int ok = 1;\n+  xr[0] = 0x1.0b1600p-133;\n+  xi[0] = 0x1.5e1c28p+54;\n+  yr[0] = -0x1.cdec8cp-119;\n+  yi[0] = 0x1.1e72ccp+32;\n+  zr[0] = 0x1.38e502p+22;\n+  zi[0] = -0x1.f89220p-129;\n+\n+  xr[1] = -0x1.b1bee2p+121;\n+  xi[1] = -0x1.cb403ep-59;\n+  yr[1] = 0x1.480000p-144;\n+  yi[1] = -0x1.c66fc4p+5;\n+  zr[1] = -0x1.60b8cap-34;\n+  zi[1] = -0x1.e8b02ap+115;\n+\n+  xr[2] = -0x1.3f6e00p-97;\n+  xi[2] = -0x1.c00000p-146;\n+  yr[2] = 0x1.000000p-148;\n+  yi[2] = -0x1.0c4e70p-91;\n+  zr[2] = 0x1.aa50d0p-55;\n+  zi[2] = -0x1.30c746p-6;\n+\n+  xr[3] = 0x1.000000p-148;\n+  xi[3] = 0x1.f4bc04p-84;\n+  yr[3] = 0x1.00ad74p-20;\n+  yi[3] = 0x1.2ad02ep-85;\n+  zr[3] = 0x1.1102ccp-127;\n+  zi[3] = 0x1.f369a4p-64;\n+\n+  for (i = 0; i < 4; i++)\n+    {\n+      __real__ a = xr[i];\n+      __imag__ a = xi[i];\n+      __real__ b = yr[i];\n+      __imag__ b = yi[i];\n+      __real__ z = zr[i];\n+      __imag__ z = zi[i];\n+      c = a / b;\n+      cr = __real__ c;\n+      ci = __imag__ c;\n+\n+      if (!match (c,z)){\n+\tok = 0;\n+      }\n+    }\n+  if (!ok)\n+    abort ();\n+  exit (0);\n+}"}, {"sha": "ffe9c346ad3064a018b0203dab33b5cd0329ff21", "filename": "gcc/testsuite/gcc.c-torture/execute/ieee/cdivchkld.c", "status": "added", "additions": 168, "deletions": 0, "changes": 168, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkld.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/54f0224d55a1b56dde092460ddf76913670e6efc/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkld.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fieee%2Fcdivchkld.c?ref=54f0224d55a1b56dde092460ddf76913670e6efc", "patch": "@@ -0,0 +1,168 @@\n+/*\n+  Program to test complex divide for correct results on selected values.\n+  Checking known failure points.\n+*/\n+\n+#include <float.h>\n+\n+extern void abort (void);\n+extern void exit (int);\n+\n+extern int ilogbl (long double);\n+int match (long double _Complex,long double _Complex);\n+\n+#define SMALL LDBL_MIN\n+#define MAXBIT LDBL_MANT_DIG\n+#define ERRLIM 6\n+\n+/*\n+  Compare c (computed value) with z (expected value).\n+  Return 0 if within allowed range.  Return 1 if not.\n+*/\n+int match (long double _Complex c,long double _Complex z)\n+{\n+  long double rz, iz, rc, ic;\n+  long double rerr, ierr, rmax;\n+  int biterr;\n+  rz = __real__ z;\n+  iz = __imag__ z;\n+  rc = __real__ c;\n+  ic = __imag__ c;\n+\n+  if (__builtin_fabsl (rz) > SMALL)\n+    {\n+      rerr = __builtin_fabsl (rz - rc) / __builtin_fabsl(rz);\n+    }\n+  else if (__builtin_fabsl (rz) == 0.0)\n+    {\n+      rerr = __builtin_fabsl (rc);\n+    }\n+  else\n+    {\n+      rerr = __builtin_fabsl (rz - rc) / SMALL;\n+    }\n+\n+  if (__builtin_fabsl (iz) > SMALL)\n+    {\n+      ierr = __builtin_fabsl (iz - ic) / __builtin_fabsl(iz);\n+    }\n+  else if (__builtin_fabsl (iz) == 0.0)\n+    {\n+      ierr = __builtin_fabsl (ic);\n+    }\n+  else\n+    {\n+      ierr = __builtin_fabsl (iz - ic) / SMALL;\n+    }\n+  rmax = __builtin_fmaxl (rerr, ierr);\n+  biterr = 0;\n+  if ( rmax != 0.0)      \n+    {\n+      biterr = ilogbl (rmax) + MAXBIT + 1;\n+    }\n+\n+  if (biterr >= ERRLIM)\n+    return 0;\n+  else\n+    return 1;\n+}\n+\n+\n+int main (int argc, char** argv)\n+{\n+  long double _Complex a,b,c,z;\n+  long double xr[4], xi[4], yr[4], yi[4], zr[4], zi[4];\n+  long double cr, ci;\n+  int i;\n+  int ok = 1;\n+\n+#if (LDBL_MAX_EXP < 2048)\n+  /*\n+    Test values when mantissa is 11 or fewer bits.  Either LDBL is\n+    using DBL on this platform or we are using IBM extended double\n+    precision. Test values will be automatically truncated when\n+    the available precision is smaller than the explicit precision.\n+  */\n+  xr[0] = -0x1.16e7fad79e45ep+651;\n+  xi[0] = -0x1.f7f75b94c6c6ap-860;\n+  yr[0] = -0x1.2f40d8ff7e55ep+245;\n+  yi[0] = -0x0.0000000004ebcp-968;\n+  zr[0] = 0x1.d6e4b0e2828694570ba839070beep+405L;\n+  zi[0] = -0x1.e9095e311e70498db810196259b7p-846L;\n+\n+  xr[1] = -0x1.21ff587f953d3p-310;\n+  xi[1] = -0x1.5a526dcc59960p+837;\n+  yr[1] = 0x1.b88b8b552eaadp+735;\n+  yi[1] = -0x1.873e2d6544d92p-327;\n+  zr[1] = 0x1.65734a88b2ddff699c482ee8eef6p-961L;\n+  zi[1] = -0x1.927e85b8b576f94a797a1bcb733dp+101L;\n+\n+  xr[2] = 0x1.4612e41aa8080p-846;\n+  xi[2] = -0x0.0000000613e07p-968;\n+  yr[2] = 0x1.df9cd0d58caafp-820;\n+  yi[2] = -0x1.e47051a9036dbp-584;\n+  zr[2] = 0x1.9b194f3aaadea545174c5372d8p-415L;\n+  zi[2] = 0x1.58a00ab740a6ad3249002f2b79p-263L;\n+\n+  xr[3] = 0x1.cb27eece7c585p-355;\n+  xi[3] = 0x0.000000223b8a8p-968;\n+  yr[3] = -0x1.74e7ed2b9189fp-22;\n+  yi[3] = 0x1.3d80439e9a119p-731;\n+  zr[3] = -0x1.3b35ed806ae5a2a8cc1c9a96931dp-333L;\n+  zi[3] = -0x1.7802c17c774895bd541adeb200p-974L;\n+#else\n+  /*\n+    Test values intended for either IEEE128 or Intel80 formats.  In\n+    either case, 15 bits of exponent are available.  Test values will\n+    be automatically truncated when the available precision is smaller\n+    than the explicit precision.\n+  */\n+  xr[0] = -0x9.c793985b7d029d90p-8480L;\n+  xi[0] = 0x8.018745ffa61a8fe0p+16329L;\n+  yr[0] = -0xe.d5bee9c523a35ad0p-15599L;\n+  yi[0] = -0xa.8c93c5a4f94128f0p+869L;\n+  zr[0] = -0x1.849178451c035b95d16311d0efdap+15459L;\n+  zi[0] = -0x1.11375ed2c1f58b9d047ab64aed97p-1008L;\n+\n+  xr[1] = 0xb.68e44bc6d0b91a30p+16026L;\n+  xi[1] = 0xb.ab10f5453e972f30p-14239L;\n+  yr[1] = 0x8.8cbd470705428ff0p-16350L;\n+  yi[1] = -0xa.0c1cbeae4e4b69f0p+347L;\n+  zr[1] = 0x1.eec40848785e500d9f0945ab58d3p-1019L;\n+  zi[1] = 0x1.22b6b579927a3f238b772bb6dc95p+15679L;\n+\n+  xr[2] = -0x9.e8c093a43b546a90p+15983L;\n+  xi[2] = 0xc.95b18274208311e0p-2840L;\n+  yr[2] = -0x8.dedb729b5c1b2ec0p+8L;\n+  yi[2] = 0xa.a49fb81b24738370p-16385L;\n+  zr[2] = 0x1.1df99ee89bb118f3201369e06576p+15975L;\n+  zi[2] = 0x1.571e7ef904d6b6eee7acb0dcf098p-418L;\n+\n+  xr[3] = 0xc.4687f251c0f48bd0p-3940L;\n+  xi[3] = -0xe.a3f2138992d85fa0p+15598L;\n+  yr[3] = 0xe.4b0c25c3d5ebb830p-16344L;\n+  yi[3] = -0xa.6cbf1ba80f7b97a0p+78L;\n+  zr[3] = 0x1.6785ba23bfb744cee97b4142348bp+15520L;\n+  zi[3] = -0x1.ecee7b8c7bdd36237eb538324289p-902L;\n+#endif\n+\n+  for (i = 0; i < 4; i++)\n+    {\n+      __real__ a = xr[i];\n+      __imag__ a = xi[i];\n+      __real__ b = yr[i];\n+      __imag__ b = yi[i];\n+      __real__ z = zr[i];\n+      __imag__ z = zi[i];\n+      c = a / b;\n+      cr = __real__ c;\n+      ci = __imag__ c;\n+\n+      if (!match (c,z)){\n+\tok = 0;\n+      }\n+    }\n+  if (!ok)\n+    abort ();\n+  exit (0);\n+}"}, {"sha": "a1d29d2e4b45fa094609d21cc7a8a5fb3c678cf9", "filename": "libgcc/config/rs6000/_divkc3.c", "status": "modified", "additions": 101, "deletions": 8, "changes": 109, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/54f0224d55a1b56dde092460ddf76913670e6efc/libgcc%2Fconfig%2Frs6000%2F_divkc3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/54f0224d55a1b56dde092460ddf76913670e6efc/libgcc%2Fconfig%2Frs6000%2F_divkc3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Frs6000%2F_divkc3.c?ref=54f0224d55a1b56dde092460ddf76913670e6efc", "patch": "@@ -37,29 +37,122 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n #define __divkc3 __divkc3_sw\n #endif\n \n+#ifndef __LONG_DOUBLE_IEEE128__\n+#define RBIG   (__LIBGCC_KF_MAX__ / 2)\n+#define RMIN   (__LIBGCC_KF_MIN__)\n+#define RMIN2  (__LIBGCC_KF_EPSILON__)\n+#define RMINSCAL (1 / __LIBGCC_KF_EPSILON__)\n+#define RMAX2  (RBIG * RMIN2)\n+#else\n+#define RBIG   (__LIBGCC_TF_MAX__ / 2)\n+#define RMIN   (__LIBGCC_TF_MIN__)\n+#define RMIN2  (__LIBGCC_TF_EPSILON__)\n+#define RMINSCAL (1 / __LIBGCC_TF_EPSILON__)\n+#define RMAX2  (RBIG * RMIN2)\n+#endif\n+\n TCtype\n __divkc3 (TFtype a, TFtype b, TFtype c, TFtype d)\n {\n   TFtype denom, ratio, x, y;\n   TCtype res;\n \n-  /* ??? We can get better behavior from logarithmic scaling instead of\n-     the division.  But that would mean starting to link libgcc against\n-     libm.  We could implement something akin to ldexp/frexp as gcc builtins\n-     fairly easily...  */\n+  /* long double has significant potential underflow/overflow errors that\n+     can be greatly reduced with a limited number of tests and adjustments.\n+  */\n+\n+  /* Scale by max(c,d) to reduce chances of denominator overflowing.  */\n   if (FABS (c) < FABS (d))\n     {\n+      /* Prevent underflow when denominator is near max representable.  */\n+      if (FABS (d) >= RBIG)\n+\t{\n+\t  a = a / 2;\n+\t  b = b / 2;\n+\t  c = c / 2;\n+\t  d = d / 2;\n+\t}\n+      /* Avoid overflow/underflow issues when c and d are small.\n+\t Scaling up helps avoid some underflows.\n+\t No new overflow possible since c&d < RMIN2.  */\n+      if (FABS (d) < RMIN2)\n+\t{\n+\t  a = a * RMINSCAL;\n+\t  b = b * RMINSCAL;\n+\t  c = c * RMINSCAL;\n+\t  d = d * RMINSCAL;\n+\t}\n+      else\n+\t{\n+\t  if (((FABS (a) < RMIN) && (FABS (b) < RMAX2) && (FABS (d) < RMAX2))\n+\t      || ((FABS (b) < RMIN) && (FABS (a) < RMAX2)\n+\t\t  && (FABS (d) < RMAX2)))\n+\t    {\n+\t      a = a * RMINSCAL;\n+\t      b = b * RMINSCAL;\n+\t      c = c * RMINSCAL;\n+\t      d = d * RMINSCAL;\n+\t    }\n+\t}\n       ratio = c / d;\n       denom = (c * ratio) + d;\n-      x = ((a * ratio) + b) / denom;\n-      y = ((b * ratio) - a) / denom;\n+      /* Choose alternate order of computation if ratio is subnormal.  */\n+      if (FABS (ratio) > RMIN)\n+\t{\n+\t  x = ((a * ratio) + b) / denom;\n+\t  y = ((b * ratio) - a) / denom;\n+\t}\n+      else\n+\t{\n+\t  x = ((c * (a / d)) + b) / denom;\n+\t  y = ((c * (b / d)) - a) / denom;\n+\t}\n     }\n   else\n     {\n+      /* Prevent underflow when denominator is near max representable.  */\n+      if (FABS (c) >= RBIG)\n+\t{\n+\t  a = a / 2;\n+\t  b = b / 2;\n+\t  c = c / 2;\n+\t  d = d / 2;\n+\t}\n+      /* Avoid overflow/underflow issues when both c and d are small.\n+\t Scaling up helps avoid some underflows.\n+\t No new overflow possible since both c&d are less than RMIN2.  */\n+      if (FABS (c) < RMIN2)\n+\t{\n+\t  a = a * RMINSCAL;\n+\t  b = b * RMINSCAL;\n+\t  c = c * RMINSCAL;\n+\t  d = d * RMINSCAL;\n+\t}\n+      else\n+\t{\n+\t  if (((FABS (a) < RMIN) && (FABS (b) < RMAX2) && (FABS (c) < RMAX2))\n+\t      || ((FABS (b) < RMIN) && (FABS (a) < RMAX2)\n+\t\t  && (FABS (c) < RMAX2)))\n+\t    {\n+\t      a = a * RMINSCAL;\n+\t      b = b * RMINSCAL;\n+\t      c = c * RMINSCAL;\n+\t      d = d * RMINSCAL;\n+\t    }\n+\t}\n       ratio = d / c;\n       denom = (d * ratio) + c;\n-      x = ((b * ratio) + a) / denom;\n-      y = (b - (a * ratio)) / denom;\n+      /* Choose alternate order of computation if ratio is subnormal.  */\n+      if (FABS (ratio) > RMIN)\n+\t{\n+\t  x = ((b * ratio) + a) / denom;\n+\t  y = (b - (a * ratio)) / denom;\n+\t}\n+      else\n+\t{\n+\t  x = (a + (d * (b / c))) / denom;\n+\t  y = (b - (d * (a / c))) / denom;\n+\t}\n     }\n \n   /* Recover infinities and zeros that computed as NaN+iNaN; the only cases"}, {"sha": "38f935e31aacd465a92d179d99396d568787d0b0", "filename": "libgcc/libgcc2.c", "status": "modified", "additions": 138, "deletions": 10, "changes": 148, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/54f0224d55a1b56dde092460ddf76913670e6efc/libgcc%2Flibgcc2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/54f0224d55a1b56dde092460ddf76913670e6efc/libgcc%2Flibgcc2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Flibgcc2.c?ref=54f0224d55a1b56dde092460ddf76913670e6efc", "patch": "@@ -1860,33 +1860,55 @@ NAME (TYPE x, int m)\n #if defined(L_mulhc3) || defined(L_divhc3)\n # define MTYPE\tHFtype\n # define CTYPE\tHCtype\n+# define AMTYPE SFtype\n # define MODE\thc\n # define CEXT\t__LIBGCC_HF_FUNC_EXT__\n # define NOTRUNC (!__LIBGCC_HF_EXCESS_PRECISION__)\n #elif defined(L_mulsc3) || defined(L_divsc3)\n # define MTYPE\tSFtype\n # define CTYPE\tSCtype\n+# define AMTYPE DFtype\n # define MODE\tsc\n # define CEXT\t__LIBGCC_SF_FUNC_EXT__\n # define NOTRUNC (!__LIBGCC_SF_EXCESS_PRECISION__)\n+# define RBIG\t(__LIBGCC_SF_MAX__ / 2)\n+# define RMIN\t(__LIBGCC_SF_MIN__)\n+# define RMIN2\t(__LIBGCC_SF_EPSILON__)\n+# define RMINSCAL (1 / __LIBGCC_SF_EPSILON__)\n+# define RMAX2\t(RBIG * RMIN2)\n #elif defined(L_muldc3) || defined(L_divdc3)\n # define MTYPE\tDFtype\n # define CTYPE\tDCtype\n # define MODE\tdc\n # define CEXT\t__LIBGCC_DF_FUNC_EXT__\n # define NOTRUNC (!__LIBGCC_DF_EXCESS_PRECISION__)\n+# define RBIG\t(__LIBGCC_DF_MAX__ / 2)\n+# define RMIN\t(__LIBGCC_DF_MIN__)\n+# define RMIN2\t(__LIBGCC_DF_EPSILON__)\n+# define RMINSCAL (1 / __LIBGCC_DF_EPSILON__)\n+# define RMAX2  (RBIG * RMIN2)\n #elif defined(L_mulxc3) || defined(L_divxc3)\n # define MTYPE\tXFtype\n # define CTYPE\tXCtype\n # define MODE\txc\n # define CEXT\t__LIBGCC_XF_FUNC_EXT__\n # define NOTRUNC (!__LIBGCC_XF_EXCESS_PRECISION__)\n+# define RBIG\t(__LIBGCC_XF_MAX__ / 2)\n+# define RMIN\t(__LIBGCC_XF_MIN__)\n+# define RMIN2\t(__LIBGCC_XF_EPSILON__)\n+# define RMINSCAL (1 / __LIBGCC_XF_EPSILON__)\n+# define RMAX2\t(RBIG * RMIN2)\n #elif defined(L_multc3) || defined(L_divtc3)\n # define MTYPE\tTFtype\n # define CTYPE\tTCtype\n # define MODE\ttc\n # define CEXT\t__LIBGCC_TF_FUNC_EXT__\n # define NOTRUNC (!__LIBGCC_TF_EXCESS_PRECISION__)\n+# define RBIG\t(__LIBGCC_TF_MAX__ / 2)\n+# define RMIN\t(__LIBGCC_TF_MIN__)\n+# define RMIN2\t(__LIBGCC_TF_EPSILON__)\n+# define RMINSCAL (1 / __LIBGCC_TF_EPSILON__)\n+# define RMAX2\t(RBIG * RMIN2)\n #else\n # error\n #endif\n@@ -1994,30 +2016,136 @@ CONCAT3(__mul,MODE,3) (MTYPE a, MTYPE b, MTYPE c, MTYPE d)\n CTYPE\n CONCAT3(__div,MODE,3) (MTYPE a, MTYPE b, MTYPE c, MTYPE d)\n {\n+#if defined(L_divhc3)\t\t\t\t\t\t\\\n+  || (defined(L_divsc3) && defined(__LIBGCC_HAVE_HWDBL__) )\n+\n+  /* Half precision is handled with float precision.\n+     float is handled with double precision when double precision\n+     hardware is available.\n+     Due to the additional precision, the simple complex divide\n+     method (without Smith's method) is sufficient to get accurate\n+     answers and runs slightly faster than Smith's method.  */\n+\n+  AMTYPE aa, bb, cc, dd;\n+  AMTYPE denom;\n+  MTYPE x, y;\n+  CTYPE res;\n+  aa = a;\n+  bb = b;\n+  cc = c;\n+  dd = d;\n+\n+  denom = (cc * cc) + (dd * dd);\n+  x = ((aa * cc) + (bb * dd)) / denom;\n+  y = ((bb * cc) - (aa * dd)) / denom;\n+\n+#else\n   MTYPE denom, ratio, x, y;\n   CTYPE res;\n \n-  /* ??? We can get better behavior from logarithmic scaling instead of\n-     the division.  But that would mean starting to link libgcc against\n-     libm.  We could implement something akin to ldexp/frexp as gcc builtins\n-     fairly easily...  */\n+  /* double, extended, long double have significant potential\n+     underflow/overflow errors that can be greatly reduced with\n+     a limited number of tests and adjustments.  float is handled\n+     the same way when no HW double is available.\n+  */\n+\n+  /* Scale by max(c,d) to reduce chances of denominator overflowing.  */\n   if (FABS (c) < FABS (d))\n     {\n+      /* Prevent underflow when denominator is near max representable.  */\n+      if (FABS (d) >= RBIG)\n+\t{\n+\t  a = a / 2;\n+\t  b = b / 2;\n+\t  c = c / 2;\n+\t  d = d / 2;\n+\t}\n+      /* Avoid overflow/underflow issues when c and d are small.\n+\t Scaling up helps avoid some underflows.\n+\t No new overflow possible since c&d < RMIN2.  */\n+      if (FABS (d) < RMIN2)\n+\t{\n+\t  a = a * RMINSCAL;\n+\t  b = b * RMINSCAL;\n+\t  c = c * RMINSCAL;\n+\t  d = d * RMINSCAL;\n+\t}\n+      else\n+\t{\n+\t  if (((FABS (a) < RMIN) && (FABS (b) < RMAX2) && (FABS (d) < RMAX2))\n+\t      || ((FABS (b) < RMIN) && (FABS (a) < RMAX2)\n+\t\t  && (FABS (d) < RMAX2)))\n+\t    {\n+\t      a = a * RMINSCAL;\n+\t      b = b * RMINSCAL;\n+\t      c = c * RMINSCAL;\n+\t      d = d * RMINSCAL;\n+\t    }\n+\t}\n       ratio = c / d;\n       denom = (c * ratio) + d;\n-      x = ((a * ratio) + b) / denom;\n-      y = ((b * ratio) - a) / denom;\n+      /* Choose alternate order of computation if ratio is subnormal.  */\n+      if (FABS (ratio) > RMIN)\n+\t{\n+\t  x = ((a * ratio) + b) / denom;\n+\t  y = ((b * ratio) - a) / denom;\n+\t}\n+      else\n+\t{\n+\t  x = ((c * (a / d)) + b) / denom;\n+\t  y = ((c * (b / d)) - a) / denom;\n+\t}\n     }\n   else\n     {\n+      /* Prevent underflow when denominator is near max representable.  */\n+      if (FABS (c) >= RBIG)\n+\t{\n+\t  a = a / 2;\n+\t  b = b / 2;\n+\t  c = c / 2;\n+\t  d = d / 2;\n+\t}\n+      /* Avoid overflow/underflow issues when both c and d are small.\n+\t Scaling up helps avoid some underflows.\n+\t No new overflow possible since both c&d are less than RMIN2.  */\n+      if (FABS (c) < RMIN2)\n+\t{\n+\t  a = a * RMINSCAL;\n+\t  b = b * RMINSCAL;\n+\t  c = c * RMINSCAL;\n+\t  d = d * RMINSCAL;\n+\t}\n+      else\n+\t{\n+\t  if (((FABS (a) < RMIN) && (FABS (b) < RMAX2) && (FABS (c) < RMAX2))\n+\t      || ((FABS (b) < RMIN) && (FABS (a) < RMAX2)\n+\t\t  && (FABS (c) < RMAX2)))\n+\t    {\n+\t      a = a * RMINSCAL;\n+\t      b = b * RMINSCAL;\n+\t      c = c * RMINSCAL;\n+\t      d = d * RMINSCAL;\n+\t    }\n+\t}\n       ratio = d / c;\n       denom = (d * ratio) + c;\n-      x = ((b * ratio) + a) / denom;\n-      y = (b - (a * ratio)) / denom;\n+      /* Choose alternate order of computation if ratio is subnormal.  */\n+      if (FABS (ratio) > RMIN)\n+\t{\n+\t  x = ((b * ratio) + a) / denom;\n+\t  y = (b - (a * ratio)) / denom;\n+\t}\n+      else\n+\t{\n+\t  x = (a + (d * (b / c))) / denom;\n+\t  y = (b - (d * (a / c))) / denom;\n+\t}\n     }\n+#endif\n \n-  /* Recover infinities and zeros that computed as NaN+iNaN; the only cases\n-     are nonzero/zero, infinite/finite, and finite/infinite.  */\n+  /* Recover infinities and zeros that computed as NaN+iNaN; the only\n+     cases are nonzero/zero, infinite/finite, and finite/infinite.  */\n   if (isnan (x) && isnan (y))\n     {\n       if (c == 0.0 && d == 0.0 && (!isnan (a) || !isnan (b)))"}]}