{"sha": "36b85e432865a312aa8edc8978e38266e8a0f14c", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzZiODVlNDMyODY1YTMxMmFhOGVkYzg5NzhlMzgyNjZlOGEwZjE0Yw==", "commit": {"author": {"name": "Bernd Schmidt", "email": "bernds@redhat.com", "date": "2016-06-03T14:20:53Z"}, "committer": {"name": "Bernd Schmidt", "email": "bernds@gcc.gnu.org", "date": "2016-06-03T14:20:53Z"}, "message": "re PR tree-optimization/52171 (memcmp/strcmp/strncmp can be optimized when the result is tested for [in]equality with 0)\n\n        PR tree-optimization/52171\n        * builtins.c (expand_cmpstrn_or_cmpmem): Delete, moved elsewhere.\n        (expand_builtin_memcmp): New arg RESULT_EQ.  All callers changed.\n        Look for constant strings.  Move some code to emit_block_cmp_hints\n        and use it.\n        * builtins.def (BUILT_IN_MEMCMP_EQ): New.\n        * defaults.h (COMPARE_MAX_PIECES): New macro.\n        * expr.c (move_by_pieces_d, store_by_pieces_d): Remove old structs.\n        (move_by_pieces_1, store_by_pieces_1, store_by_pieces_2): Remvoe.\n        (clear_by_pieces_1): Don't declare.  Move definition before use.\n        (can_do_by_pieces): New static function.\n        (can_move_by_pieces): Use it.  Return bool.\n        (by_pieces_ninsns): Renamed from move_by_pieces_ninsns.  New arg\n        OP.  All callers changed.  Handle COMPARE_BY_PIECES.\n        (class pieces_addr); New.\n        (pieces_addr::pieces_addr, pieces_addr::decide_autoinc,\n        pieces_addr::adjust, pieces_addr::increment_address,\n        pieces_addr::maybe_predec, pieces_addr::maybe_postinc): New member\n        functions for it.\n        (class op_by_pieces_d): New.\n        (op_by_pieces_d::op_by_pieces_d, op_by_pieces_d::run): New member\n        functions for it.\n        (class move_by_pieces_d, class compare_by_pieces_d,\n        class store_by_pieces_d): New subclasses of op_by_pieces_d.\n        (move_by_pieces_d::prepare_mode, move_by_pieces_d::generate,\n        move_by_pieces_d::finish_endp, store_by_pieces_d::prepare_mode,\n        store_by_pieces_d::generate, store_by_pieces_d::finish_endp,\n        compare_by_pieces_d::generate, compare_by_pieces_d::prepare_mode,\n        compare_by_pieces_d::finish_mode): New member functions.\n        (compare_by_pieces, emit_block_cmp_via_cmpmem): New static\n        functions.\n        (expand_cmpstrn_or_cmpmem): Moved here from builtins.c.\n        (emit_block_cmp_hints): New function.\n        (move_by_pieces, store_by_pieces, clear_by_pieces): Rewrite to just\n        use the newly defined classes.\n        * expr.h (by_pieces_constfn): New typedef.\n        (can_store_by_pieces, store_by_pieces): Use it in arg declarations.\n        (emit_block_cmp_hints, expand_cmpstrn_or_cmpmem): Declare.\n        (move_by_pieces_ninsns): Don't declare.\n        (can_move_by_pieces): Change return value to bool.\n        * target.def (TARGET_USE_BY_PIECES_INFRASTRUCTURE_P): Update docs.\n        (compare_by_pieces_branch_ratio): New hook.\n        * target.h (enum by_pieces_operation): Add COMPARE_BY_PIECES.\n        (by_pieces_ninsns): Declare.\n        * targethooks.c (default_use_by_pieces_infrastructure_p): Handle\n        COMPARE_BY_PIECES.\n        (default_compare_by_pieces_branch_ratio): New function.\n        * targhooks.h (default_compare_by_pieces_branch_ratio): Declare.\n        * doc/tm.texi.in (STORE_MAX_PIECES, COMPARE_MAX_PIECES): Document.\n        * doc/tm.texi: Regenerate.\n        * tree-ssa-strlen.c: Include \"builtins.h\".\n        (handle_builtin_memcmp): New static function.\n        (strlen_optimize_stmt): Call it for BUILT_IN_MEMCMP.\n        * tree.c (build_common_builtin_nodes): Create __builtin_memcmp_eq.\n\ntestsuite/\n        PR tree-optimization/52171\n        * gcc.dg/pr52171.c: New test.\n        * gcc.target/i386/pr52171.c: New test.\n\nFrom-SVN: r237069", "tree": {"sha": "a37f7aeb86dcb59106ae4cd545a9e74dfaf5f8d7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a37f7aeb86dcb59106ae4cd545a9e74dfaf5f8d7"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/36b85e432865a312aa8edc8978e38266e8a0f14c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/36b85e432865a312aa8edc8978e38266e8a0f14c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/36b85e432865a312aa8edc8978e38266e8a0f14c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/36b85e432865a312aa8edc8978e38266e8a0f14c/comments", "author": null, "committer": null, "parents": [{"sha": "bfeee8acaabebf2eb6d4587731b2a639f530293e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bfeee8acaabebf2eb6d4587731b2a639f530293e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bfeee8acaabebf2eb6d4587731b2a639f530293e"}], "stats": {"total": 1782, "additions": 1163, "deletions": 619}, "files": [{"sha": "75b4c01ba68fbaaf6fa4aad9a9207f51a8e94533", "filename": "gcc/ChangeLog", "status": "modified", "additions": 57, "deletions": 0, "changes": 57, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -1,3 +1,60 @@\n+2016-06-03  Bernd Schmidt  <bschmidt@redhat.com>\n+\n+        PR tree-optimization/52171\n+        * builtins.c (expand_cmpstrn_or_cmpmem): Delete, moved elsewhere.\n+        (expand_builtin_memcmp): New arg RESULT_EQ.  All callers changed.\n+        Look for constant strings.  Move some code to emit_block_cmp_hints\n+        and use it.\n+        * builtins.def (BUILT_IN_MEMCMP_EQ): New.\n+        * defaults.h (COMPARE_MAX_PIECES): New macro.\n+        * expr.c (move_by_pieces_d, store_by_pieces_d): Remove old structs.\n+        (move_by_pieces_1, store_by_pieces_1, store_by_pieces_2): Remvoe.\n+        (clear_by_pieces_1): Don't declare.  Move definition before use.\n+        (can_do_by_pieces): New static function.\n+        (can_move_by_pieces): Use it.  Return bool.\n+        (by_pieces_ninsns): Renamed from move_by_pieces_ninsns.  New arg\n+        OP.  All callers changed.  Handle COMPARE_BY_PIECES.\n+        (class pieces_addr); New.\n+        (pieces_addr::pieces_addr, pieces_addr::decide_autoinc,\n+        pieces_addr::adjust, pieces_addr::increment_address,\n+        pieces_addr::maybe_predec, pieces_addr::maybe_postinc): New member\n+        functions for it.\n+        (class op_by_pieces_d): New.\n+        (op_by_pieces_d::op_by_pieces_d, op_by_pieces_d::run): New member\n+        functions for it.\n+        (class move_by_pieces_d, class compare_by_pieces_d,\n+        class store_by_pieces_d): New subclasses of op_by_pieces_d.\n+        (move_by_pieces_d::prepare_mode, move_by_pieces_d::generate,\n+        move_by_pieces_d::finish_endp, store_by_pieces_d::prepare_mode,\n+        store_by_pieces_d::generate, store_by_pieces_d::finish_endp,\n+        compare_by_pieces_d::generate, compare_by_pieces_d::prepare_mode,\n+        compare_by_pieces_d::finish_mode): New member functions.\n+        (compare_by_pieces, emit_block_cmp_via_cmpmem): New static\n+        functions.\n+        (expand_cmpstrn_or_cmpmem): Moved here from builtins.c.\n+        (emit_block_cmp_hints): New function.\n+        (move_by_pieces, store_by_pieces, clear_by_pieces): Rewrite to just\n+        use the newly defined classes.\n+        * expr.h (by_pieces_constfn): New typedef.\n+        (can_store_by_pieces, store_by_pieces): Use it in arg declarations.\n+        (emit_block_cmp_hints, expand_cmpstrn_or_cmpmem): Declare.\n+        (move_by_pieces_ninsns): Don't declare.\n+        (can_move_by_pieces): Change return value to bool.\n+        * target.def (TARGET_USE_BY_PIECES_INFRASTRUCTURE_P): Update docs.\n+        (compare_by_pieces_branch_ratio): New hook.\n+        * target.h (enum by_pieces_operation): Add COMPARE_BY_PIECES.\n+        (by_pieces_ninsns): Declare.\n+        * targethooks.c (default_use_by_pieces_infrastructure_p): Handle\n+        COMPARE_BY_PIECES.\n+        (default_compare_by_pieces_branch_ratio): New function.\n+        * targhooks.h (default_compare_by_pieces_branch_ratio): Declare.\n+        * doc/tm.texi.in (STORE_MAX_PIECES, COMPARE_MAX_PIECES): Document.\n+        * doc/tm.texi: Regenerate.\n+        * tree-ssa-strlen.c: Include \"builtins.h\".\n+        (handle_builtin_memcmp): New static function.\n+        (strlen_optimize_stmt): Call it for BUILT_IN_MEMCMP.\n+        * tree.c (build_common_builtin_nodes): Create __builtin_memcmp_eq.\n+\n 2016-06-03  Alan Hayward  <alan.hayward@arm.com>\n \n \t* tree-vect-stmts.c (vect_stmt_relevant_p): Do not vectorize non live"}, {"sha": "d51917616807003eb4363ca4b2807a002202c1f7", "filename": "gcc/builtins.c", "status": "modified", "additions": 38, "deletions": 45, "changes": 83, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -3671,53 +3671,24 @@ expand_cmpstr (insn_code icode, rtx target, rtx arg1_rtx, rtx arg2_rtx,\n   return NULL_RTX;\n }\n \n-/* Try to expand cmpstrn or cmpmem operation ICODE with the given operands.\n-   ARG3_TYPE is the type of ARG3_RTX.  Return the result rtx on success,\n-   otherwise return null.  */\n-\n-static rtx\n-expand_cmpstrn_or_cmpmem (insn_code icode, rtx target, rtx arg1_rtx,\n-\t\t\t  rtx arg2_rtx, tree arg3_type, rtx arg3_rtx,\n-\t\t\t  HOST_WIDE_INT align)\n-{\n-  machine_mode insn_mode = insn_data[icode].operand[0].mode;\n-\n-  if (target && (!REG_P (target) || HARD_REGISTER_P (target)))\n-    target = NULL_RTX;\n-\n-  struct expand_operand ops[5];\n-  create_output_operand (&ops[0], target, insn_mode);\n-  create_fixed_operand (&ops[1], arg1_rtx);\n-  create_fixed_operand (&ops[2], arg2_rtx);\n-  create_convert_operand_from (&ops[3], arg3_rtx, TYPE_MODE (arg3_type),\n-\t\t\t       TYPE_UNSIGNED (arg3_type));\n-  create_integer_operand (&ops[4], align);\n-  if (maybe_expand_insn (icode, 5, ops))\n-    return ops[0].value;\n-  return NULL_RTX;\n-}\n-\n /* Expand expression EXP, which is a call to the memcmp built-in function.\n    Return NULL_RTX if we failed and the caller should emit a normal call,\n-   otherwise try to get the result in TARGET, if convenient.  */\n+   otherwise try to get the result in TARGET, if convenient.\n+   RESULT_EQ is true if we can relax the returned value to be either zero\n+   or nonzero, without caring about the sign.  */\n \n static rtx\n-expand_builtin_memcmp (tree exp, rtx target)\n+expand_builtin_memcmp (tree exp, rtx target, bool result_eq)\n {\n   if (!validate_arglist (exp,\n  \t\t\t POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))\n     return NULL_RTX;\n \n-  /* Note: The cmpstrnsi pattern, if it exists, is not suitable for\n-     implementing memcmp because it will stop if it encounters two\n-     zero bytes.  */\n-  insn_code icode = direct_optab_handler (cmpmem_optab, SImode);\n-  if (icode == CODE_FOR_nothing)\n-    return NULL_RTX;\n-\n   tree arg1 = CALL_EXPR_ARG (exp, 0);\n   tree arg2 = CALL_EXPR_ARG (exp, 1);\n   tree len = CALL_EXPR_ARG (exp, 2);\n+  machine_mode mode = TYPE_MODE (TREE_TYPE (exp));\n+  location_t loc = EXPR_LOCATION (exp);\n \n   unsigned int arg1_align = get_pointer_alignment (arg1) / BITS_PER_UNIT;\n   unsigned int arg2_align = get_pointer_alignment (arg2) / BITS_PER_UNIT;\n@@ -3726,22 +3697,38 @@ expand_builtin_memcmp (tree exp, rtx target)\n   if (arg1_align == 0 || arg2_align == 0)\n     return NULL_RTX;\n \n-  machine_mode mode = TYPE_MODE (TREE_TYPE (exp));\n-  location_t loc = EXPR_LOCATION (exp);\n   rtx arg1_rtx = get_memory_rtx (arg1, len);\n   rtx arg2_rtx = get_memory_rtx (arg2, len);\n-  rtx arg3_rtx = expand_normal (fold_convert_loc (loc, sizetype, len));\n+  rtx len_rtx = expand_normal (fold_convert_loc (loc, sizetype, len));\n \n   /* Set MEM_SIZE as appropriate.  */\n-  if (CONST_INT_P (arg3_rtx))\n+  if (CONST_INT_P (len_rtx))\n     {\n-      set_mem_size (arg1_rtx, INTVAL (arg3_rtx));\n-      set_mem_size (arg2_rtx, INTVAL (arg3_rtx));\n+      set_mem_size (arg1_rtx, INTVAL (len_rtx));\n+      set_mem_size (arg2_rtx, INTVAL (len_rtx));\n     }\n \n-  rtx result = expand_cmpstrn_or_cmpmem (icode, target, arg1_rtx, arg2_rtx,\n-\t\t\t\t\t TREE_TYPE (len), arg3_rtx,\n-\t\t\t\t\t MIN (arg1_align, arg2_align));\n+  by_pieces_constfn constfn = NULL;\n+\n+  const char *src_str = c_getstr (arg1);\n+  if (src_str == NULL)\n+    src_str = c_getstr (arg2);\n+  else\n+    std::swap (arg1_rtx, arg2_rtx);\n+\n+  /* If SRC is a string constant and block move would be done\n+     by pieces, we can avoid loading the string from memory\n+     and only stored the computed constants.  */\n+  if (src_str\n+      && CONST_INT_P (len_rtx)\n+      && (unsigned HOST_WIDE_INT) INTVAL (len_rtx) <= strlen (src_str) + 1)\n+    constfn = builtin_memcpy_read_str;\n+\n+  rtx result = emit_block_cmp_hints (arg1_rtx, arg2_rtx, len_rtx,\n+\t\t\t\t     TREE_TYPE (len), target,\n+\t\t\t\t     result_eq, constfn,\n+\t\t\t\t     CONST_CAST (char *, src_str));\n+\n   if (result)\n     {\n       /* Return the value in the proper mode for this function.  */\n@@ -6073,9 +6060,15 @@ expand_builtin (tree exp, rtx target, rtx subtarget, machine_mode mode,\n \n     case BUILT_IN_BCMP:\n     case BUILT_IN_MEMCMP:\n-      target = expand_builtin_memcmp (exp, target);\n+    case BUILT_IN_MEMCMP_EQ:\n+      target = expand_builtin_memcmp (exp, target, fcode == BUILT_IN_MEMCMP_EQ);\n       if (target)\n \treturn target;\n+      if (fcode == BUILT_IN_MEMCMP_EQ)\n+\t{\n+\t  tree newdecl = builtin_decl_explicit (BUILT_IN_MEMCMP);\n+\t  TREE_OPERAND (exp, 1) = build_fold_addr_expr (newdecl);\n+\t}\n       break;\n \n     case BUILT_IN_SETJMP:"}, {"sha": "527503800ffa82f0b94f881eca089b028db5b83f", "filename": "gcc/builtins.def", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fbuiltins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fbuiltins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.def?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -864,6 +864,10 @@ DEF_BUILTIN_STUB (BUILT_IN_STACK_SAVE, \"__builtin_stack_save\")\n DEF_BUILTIN_STUB (BUILT_IN_STACK_RESTORE, \"__builtin_stack_restore\")\n DEF_BUILTIN_STUB (BUILT_IN_ALLOCA_WITH_ALIGN, \"__builtin_alloca_with_align\")\n \n+/* An internal version of memcmp, used when the result is only tested for\n+   equality with zero.  */\n+DEF_BUILTIN_STUB (BUILT_IN_MEMCMP_EQ, \"__builtin_memcmp_eq\")\n+\n /* Object size checking builtins.  */\n DEF_GCC_BUILTIN\t       (BUILT_IN_OBJECT_SIZE, \"object_size\", BT_FN_SIZE_CONST_PTR_INT, ATTR_PURE_NOTHROW_LEAF_LIST)\n DEF_EXT_LIB_BUILTIN_CHKP (BUILT_IN_MEMCPY_CHK, \"__memcpy_chk\", BT_FN_PTR_PTR_CONST_PTR_SIZE_SIZE, ATTR_RET1_NOTHROW_NONNULL_LEAF)"}, {"sha": "319a7dce6f5351af4cc08fc751c1325a8b4c2f2c", "filename": "gcc/defaults.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fdefaults.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fdefaults.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdefaults.h?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -1039,6 +1039,11 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n #define STORE_MAX_PIECES  MIN (MOVE_MAX_PIECES, 2 * sizeof (HOST_WIDE_INT))\n #endif\n \n+/* Likewise for block comparisons.  */\n+#ifndef COMPARE_MAX_PIECES\n+#define COMPARE_MAX_PIECES  MOVE_MAX_PIECES\n+#endif\n+\n #ifndef MAX_MOVE_MAX\n #define MAX_MOVE_MAX MOVE_MAX\n #endif"}, {"sha": "b318615b7b35ab93ad13e5e535a1d4e6d02cb7f7", "filename": "gcc/doc/tm.texi", "status": "modified", "additions": 25, "deletions": 2, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fdoc%2Ftm.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fdoc%2Ftm.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftm.texi?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -6315,8 +6315,9 @@ Both @var{size} and @var{alignment} are measured in terms of storage\n units.\n \n The parameter @var{op} is one of: @code{CLEAR_BY_PIECES},\n-@code{MOVE_BY_PIECES}, @code{SET_BY_PIECES}, @code{STORE_BY_PIECES}.\n-These describe the type of memory operation under consideration.\n+@code{MOVE_BY_PIECES}, @code{SET_BY_PIECES}, @code{STORE_BY_PIECES} or\n+@code{COMPARE_BY_PIECES}.  These describe the type of memory operation\n+under consideration.\n \n The parameter @var{speed_p} is true if the code is currently being\n optimized for speed rather than size.\n@@ -6333,11 +6334,33 @@ in code size, for example where the number of insns emitted to perform a\n move would be greater than that of a library call.\n @end deftypefn\n \n+@deftypefn {Target Hook} int TARGET_COMPARE_BY_PIECES_BRANCH_RATIO (machine_mode @var{mode})\n+When expanding a block comparison in MODE, gcc can try to reduce the\n+number of branches at the expense of more memory operations.  This hook\n+allows the target to override the default choice.  It should return the\n+factor by which branches should be reduced over the plain expansion with\n+one comparison per @var{mode}-sized piece.  A port can also prevent a\n+particular mode from being used for block comparisons by returning a\n+negative number from this hook.\n+@end deftypefn\n+\n @defmac MOVE_MAX_PIECES\n A C expression used by @code{move_by_pieces} to determine the largest unit\n a load or store used to copy memory is.  Defaults to @code{MOVE_MAX}.\n @end defmac\n \n+@defmac STORE_MAX_PIECES\n+A C expression used by @code{store_by_pieces} to determine the largest unit\n+a store used to memory is.  Defaults to @code{MOVE_MAX_PIECES}, or two times\n+the size of @code{HOST_WIDE_INT}, whichever is smaller.\n+@end defmac\n+\n+@defmac COMPARE_MAX_PIECES\n+A C expression used by @code{compare_by_pieces} to determine the largest unit\n+a load or store used to compare memory is.  Defaults to\n+@code{MOVE_MAX_PIECES}.\n+@end defmac\n+\n @defmac CLEAR_RATIO (@var{speed})\n The threshold of number of scalar move insns, @emph{below} which a sequence\n of insns should be generated to clear memory instead of a string clear insn"}, {"sha": "1e8423cb4e255acd8144e4b105186cee3d1d04fd", "filename": "gcc/doc/tm.texi.in", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fdoc%2Ftm.texi.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fdoc%2Ftm.texi.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftm.texi.in?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -4653,11 +4653,25 @@ If you don't define this, a reasonable default is used.\n \n @hook TARGET_USE_BY_PIECES_INFRASTRUCTURE_P\n \n+@hook TARGET_COMPARE_BY_PIECES_BRANCH_RATIO\n+\n @defmac MOVE_MAX_PIECES\n A C expression used by @code{move_by_pieces} to determine the largest unit\n a load or store used to copy memory is.  Defaults to @code{MOVE_MAX}.\n @end defmac\n \n+@defmac STORE_MAX_PIECES\n+A C expression used by @code{store_by_pieces} to determine the largest unit\n+a store used to memory is.  Defaults to @code{MOVE_MAX_PIECES}, or two times\n+the size of @code{HOST_WIDE_INT}, whichever is smaller.\n+@end defmac\n+\n+@defmac COMPARE_MAX_PIECES\n+A C expression used by @code{compare_by_pieces} to determine the largest unit\n+a load or store used to compare memory is.  Defaults to\n+@code{MOVE_MAX_PIECES}.\n+@end defmac\n+\n @defmac CLEAR_RATIO (@var{speed})\n The threshold of number of scalar move insns, @emph{below} which a sequence\n of insns should be generated to clear memory instead of a string clear insn"}, {"sha": "19af58fe03d02c75470bccabe2012991d6d4699a", "filename": "gcc/expr.c", "status": "modified", "additions": 816, "deletions": 542, "changes": 1358, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -70,51 +70,12 @@ along with GCC; see the file COPYING3.  If not see\n    the same indirect address eventually.  */\n int cse_not_expected;\n \n-/* This structure is used by move_by_pieces to describe the move to\n-   be performed.  */\n-struct move_by_pieces_d\n-{\n-  rtx to;\n-  rtx to_addr;\n-  int autinc_to;\n-  int explicit_inc_to;\n-  rtx from;\n-  rtx from_addr;\n-  int autinc_from;\n-  int explicit_inc_from;\n-  unsigned HOST_WIDE_INT len;\n-  HOST_WIDE_INT offset;\n-  int reverse;\n-};\n-\n-/* This structure is used by store_by_pieces to describe the clear to\n-   be performed.  */\n-\n-struct store_by_pieces_d\n-{\n-  rtx to;\n-  rtx to_addr;\n-  int autinc_to;\n-  int explicit_inc_to;\n-  unsigned HOST_WIDE_INT len;\n-  HOST_WIDE_INT offset;\n-  rtx (*constfun) (void *, HOST_WIDE_INT, machine_mode);\n-  void *constfundata;\n-  int reverse;\n-};\n-\n-static void move_by_pieces_1 (insn_gen_fn, machine_mode,\n-\t\t\t      struct move_by_pieces_d *);\n static bool block_move_libcall_safe_for_call_parm (void);\n static bool emit_block_move_via_movmem (rtx, rtx, rtx, unsigned, unsigned, HOST_WIDE_INT,\n \t\t\t\t\tunsigned HOST_WIDE_INT, unsigned HOST_WIDE_INT,\n \t\t\t\t\tunsigned HOST_WIDE_INT);\n static void emit_block_move_via_loop (rtx, rtx, rtx, unsigned);\n-static rtx clear_by_pieces_1 (void *, HOST_WIDE_INT, machine_mode);\n static void clear_by_pieces (rtx, unsigned HOST_WIDE_INT, unsigned int);\n-static void store_by_pieces_1 (struct store_by_pieces_d *, unsigned int);\n-static void store_by_pieces_2 (insn_gen_fn, machine_mode,\n-\t\t\t       struct store_by_pieces_d *);\n static rtx_insn *compress_float_constant (rtx, rtx);\n static rtx get_subtarget (rtx);\n static void store_constructor_field (rtx, unsigned HOST_WIDE_INT,\n@@ -767,276 +728,799 @@ widest_int_mode_for_size (unsigned int size)\n   return mode;\n }\n \n+/* Determine whether an operation OP on LEN bytes with alignment ALIGN can\n+   and should be performed piecewise.  */\n+\n+static bool\n+can_do_by_pieces (unsigned HOST_WIDE_INT len, unsigned int align,\n+\t\t  enum by_pieces_operation op)\n+{\n+  return targetm.use_by_pieces_infrastructure_p (len, align, op,\n+\t\t\t\t\t\t optimize_insn_for_speed_p ());\n+}\n+\n /* Determine whether the LEN bytes can be moved by using several move\n    instructions.  Return nonzero if a call to move_by_pieces should\n    succeed.  */\n \n-int\n-can_move_by_pieces (unsigned HOST_WIDE_INT len,\n-\t\t    unsigned int align)\n+bool\n+can_move_by_pieces (unsigned HOST_WIDE_INT len, unsigned int align)\n {\n-  return targetm.use_by_pieces_infrastructure_p (len, align, MOVE_BY_PIECES,\n-\t\t\t\t\t\t optimize_insn_for_speed_p ());\n+  return can_do_by_pieces (len, align, MOVE_BY_PIECES);\n }\n \n-/* Generate several move instructions to copy LEN bytes from block FROM to\n-   block TO.  (These are MEM rtx's with BLKmode).\n+/* Return number of insns required to perform operation OP by pieces\n+   for L bytes.  ALIGN (in bits) is maximum alignment we can assume.  */\n \n-   If PUSH_ROUNDING is defined and TO is NULL, emit_single_push_insn is\n-   used to push FROM to the stack.\n+unsigned HOST_WIDE_INT\n+by_pieces_ninsns (unsigned HOST_WIDE_INT l, unsigned int align,\n+\t\t  unsigned int max_size, by_pieces_operation op)\n+{\n+  unsigned HOST_WIDE_INT n_insns = 0;\n \n-   ALIGN is maximum stack alignment we can assume.\n+  align = alignment_for_piecewise_move (MOVE_MAX_PIECES, align);\n \n-   If ENDP is 0 return to, if ENDP is 1 return memory at the end ala\n-   mempcpy, and if ENDP is 2 return memory the end minus one byte ala\n-   stpcpy.  */\n+  while (max_size > 1 && l > 0)\n+    {\n+      machine_mode mode;\n+      enum insn_code icode;\n \n-rtx\n-move_by_pieces (rtx to, rtx from, unsigned HOST_WIDE_INT len,\n-\t\tunsigned int align, int endp)\n+      mode = widest_int_mode_for_size (max_size);\n+\n+      if (mode == VOIDmode)\n+\tbreak;\n+      unsigned int modesize = GET_MODE_SIZE (mode);\n+\n+      icode = optab_handler (mov_optab, mode);\n+      if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))\n+\t{\n+\t  unsigned HOST_WIDE_INT n_pieces = l / modesize;\n+\t  l %= modesize;\n+\t  switch (op)\n+\t    {\n+\t    default:\n+\t      n_insns += n_pieces;\n+\t      break;\n+\n+\t    case COMPARE_BY_PIECES:\n+\t      int batch = targetm.compare_by_pieces_branch_ratio (mode);\n+\t      int batch_ops = 4 * batch - 1;\n+\t      int full = n_pieces / batch;\n+\t      n_insns += full * batch_ops;\n+\t      if (n_pieces % batch != 0)\n+\t\tn_insns++;\n+\t      break;\n+\n+\t    }\n+\t}\n+      max_size = modesize;\n+    }\n+\n+  gcc_assert (!l);\n+  return n_insns;\n+}\n+\n+/* Used when performing piecewise block operations, holds information\n+   about one of the memory objects involved.  The member functions\n+   can be used to generate code for loading from the object and\n+   updating the address when iterating.  */\n+\n+class pieces_addr\n {\n-  struct move_by_pieces_d data;\n-  machine_mode to_addr_mode;\n-  machine_mode from_addr_mode = get_address_mode (from);\n-  rtx to_addr, from_addr = XEXP (from, 0);\n-  unsigned int max_size = MOVE_MAX_PIECES + 1;\n-  enum insn_code icode;\n+  /* The object being referenced, a MEM.  Can be NULL_RTX to indicate\n+     stack pushes.  */\n+  rtx m_obj;\n+  /* The address of the object.  Can differ from that seen in the\n+     MEM rtx if we copied the address to a register.  */\n+  rtx m_addr;\n+  /* Nonzero if the address on the object has an autoincrement already,\n+     signifies whether that was an increment or decrement.  */\n+  signed char m_addr_inc;\n+  /* Nonzero if we intend to use autoinc without the address already\n+     having autoinc form.  We will insert add insns around each memory\n+     reference, expecting later passes to form autoinc addressing modes.\n+     The only supported options are predecrement and postincrement.  */\n+  signed char m_explicit_inc;\n+  /* True if we have either of the two possible cases of using\n+     autoincrement.  */\n+  bool m_auto;\n+  /* True if this is an address to be used for load operations rather\n+     than stores.  */\n+  bool m_is_load;\n+\n+  /* Optionally, a function to obtain constants for any given offset into\n+     the objects, and data associated with it.  */\n+  by_pieces_constfn m_constfn;\n+  void *m_cfndata;\n+public:\n+  pieces_addr (rtx, bool, by_pieces_constfn, void *);\n+  rtx adjust (machine_mode, HOST_WIDE_INT);\n+  void increment_address (HOST_WIDE_INT);\n+  void maybe_predec (HOST_WIDE_INT);\n+  void maybe_postinc (HOST_WIDE_INT);\n+  void decide_autoinc (machine_mode, bool, HOST_WIDE_INT);\n+  int get_addr_inc ()\n+  {\n+    return m_addr_inc;\n+  }\n+};\n \n-  align = MIN (to ? MEM_ALIGN (to) : align, MEM_ALIGN (from));\n+/* Initialize a pieces_addr structure from an object OBJ.  IS_LOAD is\n+   true if the operation to be performed on this object is a load\n+   rather than a store.  For stores, OBJ can be NULL, in which case we\n+   assume the operation is a stack push.  For loads, the optional\n+   CONSTFN and its associated CFNDATA can be used in place of the\n+   memory load.  */\n \n-  data.offset = 0;\n-  data.from_addr = from_addr;\n-  if (to)\n-    {\n-      to_addr_mode = get_address_mode (to);\n-      to_addr = XEXP (to, 0);\n-      data.to = to;\n-      data.autinc_to\n-\t= (GET_CODE (to_addr) == PRE_INC || GET_CODE (to_addr) == PRE_DEC\n-\t   || GET_CODE (to_addr) == POST_INC || GET_CODE (to_addr) == POST_DEC);\n-      data.reverse\n-\t= (GET_CODE (to_addr) == PRE_DEC || GET_CODE (to_addr) == POST_DEC);\n+pieces_addr::pieces_addr (rtx obj, bool is_load, by_pieces_constfn constfn,\n+\t\t\t  void *cfndata)\n+  : m_obj (obj), m_is_load (is_load), m_constfn (constfn), m_cfndata (cfndata)\n+{\n+  m_addr_inc = 0;\n+  m_auto = false;\n+  if (obj)\n+    {\n+      rtx addr = XEXP (obj, 0);\n+      rtx_code code = GET_CODE (addr);\n+      m_addr = addr;\n+      bool dec = code == PRE_DEC || code == POST_DEC;\n+      bool inc = code == PRE_INC || code == POST_INC;\n+      m_auto = inc || dec;\n+      if (m_auto)\n+\tm_addr_inc = dec ? -1 : 1;\n+\n+      /* While we have always looked for these codes here, the code\n+\t implementing the memory operation has never handled them.\n+\t Support could be added later if necessary or beneficial.  */\n+      gcc_assert (code != PRE_INC && code != POST_DEC);\n     }\n   else\n     {\n-      to_addr_mode = VOIDmode;\n-      to_addr = NULL_RTX;\n-      data.to = NULL_RTX;\n-      data.autinc_to = 1;\n-      if (STACK_GROWS_DOWNWARD)\n-\tdata.reverse = 1;\n+      m_addr = NULL_RTX;\n+      if (!is_load)\n+\t{\n+\t  m_auto = true;\n+\t  if (STACK_GROWS_DOWNWARD)\n+\t    m_addr_inc = -1;\n+\t  else\n+\t    m_addr_inc = 1;\n+\t}\n       else\n-\tdata.reverse = 0;\n+\tgcc_assert (constfn != NULL);\n     }\n-  data.to_addr = to_addr;\n-  data.from = from;\n-  data.autinc_from\n-    = (GET_CODE (from_addr) == PRE_INC || GET_CODE (from_addr) == PRE_DEC\n-       || GET_CODE (from_addr) == POST_INC\n-       || GET_CODE (from_addr) == POST_DEC);\n+  m_explicit_inc = 0;\n+  if (constfn)\n+    gcc_assert (is_load);\n+}\n+\n+/* Decide whether to use autoinc for an address involved in a memory op.\n+   MODE is the mode of the accesses, REVERSE is true if we've decided to\n+   perform the operation starting from the end, and LEN is the length of\n+   the operation.  Don't override an earlier decision to set m_auto.  */\n+\n+void\n+pieces_addr::decide_autoinc (machine_mode ARG_UNUSED (mode), bool reverse,\n+\t\t\t     HOST_WIDE_INT len)\n+{\n+  if (m_auto || m_obj == NULL_RTX)\n+    return;\n+\n+  bool use_predec = (m_is_load\n+\t\t     ? USE_LOAD_PRE_DECREMENT (mode)\n+\t\t     : USE_STORE_PRE_DECREMENT (mode));\n+  bool use_postinc = (m_is_load\n+\t\t      ? USE_LOAD_POST_INCREMENT (mode)\n+\t\t      : USE_STORE_POST_INCREMENT (mode));\n+  machine_mode addr_mode = get_address_mode (m_obj);\n+\n+  if (use_predec && reverse)\n+    {\n+      m_addr = copy_to_mode_reg (addr_mode,\n+\t\t\t\t plus_constant (addr_mode,\n+\t\t\t\t\t\tm_addr, len));\n+      m_auto = true;\n+      m_explicit_inc = -1;\n+    }\n+  else if (use_postinc && !reverse)\n+    {\n+      m_addr = copy_to_mode_reg (addr_mode, m_addr);\n+      m_auto = true;\n+      m_explicit_inc = 1;\n+    }\n+  else if (CONSTANT_P (m_addr))\n+    m_addr = copy_to_mode_reg (addr_mode, m_addr);\n+}\n+\n+/* Adjust the address to refer to the data at OFFSET in MODE.  If we\n+   are using autoincrement for this address, we don't add the offset,\n+   but we still modify the MEM's properties.  */\n+\n+rtx\n+pieces_addr::adjust (machine_mode mode, HOST_WIDE_INT offset)\n+{\n+  if (m_constfn)\n+    return m_constfn (m_cfndata, offset, mode);\n+  if (m_obj == NULL_RTX)\n+    return NULL_RTX;\n+  if (m_auto)\n+    return adjust_automodify_address (m_obj, mode, m_addr, offset);\n+  else\n+    return adjust_address (m_obj, mode, offset);\n+}\n+\n+/* Emit an add instruction to increment the address by SIZE.  */\n+\n+void\n+pieces_addr::increment_address (HOST_WIDE_INT size)\n+{\n+  rtx amount = gen_int_mode (size, GET_MODE (m_addr));\n+  emit_insn (gen_add2_insn (m_addr, amount));\n+}\n \n-  data.explicit_inc_from = 0;\n-  data.explicit_inc_to = 0;\n-  if (data.reverse) data.offset = len;\n-  data.len = len;\n+/* If we are supposed to decrement the address after each access, emit code\n+   to do so now.  Increment by SIZE (which has should have the correct sign\n+   already).  */\n+\n+void\n+pieces_addr::maybe_predec (HOST_WIDE_INT size)\n+{\n+  if (m_explicit_inc >= 0)\n+    return;\n+  gcc_assert (HAVE_PRE_DECREMENT);\n+  increment_address (size);\n+}\n+\n+/* If we are supposed to decrement the address after each access, emit code\n+   to do so now.  Increment by SIZE.  */\n+\n+void\n+pieces_addr::maybe_postinc (HOST_WIDE_INT size)\n+{\n+  if (m_explicit_inc <= 0)\n+    return;\n+  gcc_assert (HAVE_POST_INCREMENT);\n+  increment_address (size);\n+}\n+\n+/* This structure is used by do_op_by_pieces to describe the operation\n+   to be performed.  */\n+\n+class op_by_pieces_d\n+{\n+ protected:\n+  pieces_addr m_to, m_from;\n+  unsigned HOST_WIDE_INT m_len;\n+  HOST_WIDE_INT m_offset;\n+  unsigned int m_align;\n+  unsigned int m_max_size;\n+  bool m_reverse;\n+\n+  /* Virtual functions, overriden by derived classes for the specific\n+     operation.  */\n+  virtual void generate (rtx, rtx, machine_mode) = 0;\n+  virtual bool prepare_mode (machine_mode, unsigned int) = 0;\n+  virtual void finish_mode (machine_mode)\n+  {\n+  }\n+\n+ public:\n+  op_by_pieces_d (rtx, bool, rtx, bool, by_pieces_constfn, void *,\n+\t\t  unsigned HOST_WIDE_INT, unsigned int);\n+  void run ();\n+};\n+\n+/* The constructor for an op_by_pieces_d structure.  We require two\n+   objects named TO and FROM, which are identified as loads or stores\n+   by TO_LOAD and FROM_LOAD.  If FROM is a load, the optional FROM_CFN\n+   and its associated FROM_CFN_DATA can be used to replace loads with\n+   constant values.  LEN describes the length of the operation.  */\n+\n+op_by_pieces_d::op_by_pieces_d (rtx to, bool to_load,\n+\t\t\t\trtx from, bool from_load,\n+\t\t\t\tby_pieces_constfn from_cfn,\n+\t\t\t\tvoid *from_cfn_data,\n+\t\t\t\tunsigned HOST_WIDE_INT len,\n+\t\t\t\tunsigned int align)\n+  : m_to (to, to_load, NULL, NULL),\n+    m_from (from, from_load, from_cfn, from_cfn_data),\n+    m_len (len), m_max_size (MOVE_MAX_PIECES + 1)\n+{\n+  int toi = m_to.get_addr_inc ();\n+  int fromi = m_from.get_addr_inc ();\n+  if (toi >= 0 && fromi >= 0)\n+    m_reverse = false;\n+  else if (toi <= 0 && fromi <= 0)\n+    m_reverse = true;\n+  else\n+    gcc_unreachable ();\n+\n+  m_offset = m_reverse ? len : 0;\n+  align = MIN (to ? MEM_ALIGN (to) : align,\n+\t       from ? MEM_ALIGN (from) : align);\n \n   /* If copying requires more than two move insns,\n      copy addresses to registers (to make displacements shorter)\n      and use post-increment if available.  */\n-  if (!(data.autinc_from && data.autinc_to)\n-      && move_by_pieces_ninsns (len, align, max_size) > 2)\n+  if (by_pieces_ninsns (len, align, m_max_size, MOVE_BY_PIECES) > 2)\n     {\n-      /* Find the mode of the largest move...\n-\t MODE might not be used depending on the definitions of the\n-\t USE_* macros below.  */\n-      machine_mode mode ATTRIBUTE_UNUSED\n-\t= widest_int_mode_for_size (max_size);\n+      /* Find the mode of the largest comparison.  */\n+      machine_mode mode = widest_int_mode_for_size (m_max_size);\n \n-      if (USE_LOAD_PRE_DECREMENT (mode) && data.reverse && ! data.autinc_from)\n-\t{\n-\t  data.from_addr = copy_to_mode_reg (from_addr_mode,\n-\t\t\t\t\t     plus_constant (from_addr_mode,\n-\t\t\t\t\t\t\t    from_addr, len));\n-\t  data.autinc_from = 1;\n-\t  data.explicit_inc_from = -1;\n-\t}\n-      if (USE_LOAD_POST_INCREMENT (mode) && ! data.autinc_from)\n-\t{\n-\t  data.from_addr = copy_to_mode_reg (from_addr_mode, from_addr);\n-\t  data.autinc_from = 1;\n-\t  data.explicit_inc_from = 1;\n-\t}\n-      if (!data.autinc_from && CONSTANT_P (from_addr))\n-\tdata.from_addr = copy_to_mode_reg (from_addr_mode, from_addr);\n-      if (USE_STORE_PRE_DECREMENT (mode) && data.reverse && ! data.autinc_to)\n-\t{\n-\t  data.to_addr = copy_to_mode_reg (to_addr_mode,\n-\t\t\t\t\t   plus_constant (to_addr_mode,\n-\t\t\t\t\t\t\t  to_addr, len));\n-\t  data.autinc_to = 1;\n-\t  data.explicit_inc_to = -1;\n-\t}\n-      if (USE_STORE_POST_INCREMENT (mode) && ! data.reverse && ! data.autinc_to)\n-\t{\n-\t  data.to_addr = copy_to_mode_reg (to_addr_mode, to_addr);\n-\t  data.autinc_to = 1;\n-\t  data.explicit_inc_to = 1;\n-\t}\n-      if (!data.autinc_to && CONSTANT_P (to_addr))\n-\tdata.to_addr = copy_to_mode_reg (to_addr_mode, to_addr);\n+      m_from.decide_autoinc (mode, m_reverse, len);\n+      m_to.decide_autoinc (mode, m_reverse, len);\n     }\n \n   align = alignment_for_piecewise_move (MOVE_MAX_PIECES, align);\n+  m_align = align;\n+}\n \n-  /* First move what we can in the largest integer mode, then go to\n-     successively smaller modes.  */\n+/* This function contains the main loop used for expanding a block\n+   operation.  First move what we can in the largest integer mode,\n+   then go to successively smaller modes.  For every access, call\n+   GENFUN with the two operands and the EXTRA_DATA.  */\n \n-  while (max_size > 1 && data.len > 0)\n+void\n+op_by_pieces_d::run ()\n+{\n+  while (m_max_size > 1 && m_len > 0)\n     {\n-      machine_mode mode = widest_int_mode_for_size (max_size);\n+      machine_mode mode = widest_int_mode_for_size (m_max_size);\n \n       if (mode == VOIDmode)\n \tbreak;\n \n-      icode = optab_handler (mov_optab, mode);\n-      if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))\n-\tmove_by_pieces_1 (GEN_FCN (icode), mode, &data);\n+      if (prepare_mode (mode, m_align))\n+\t{\n+\t  unsigned int size = GET_MODE_SIZE (mode);\n+\t  rtx to1 = NULL_RTX, from1;\n+\n+\t  while (m_len >= size)\n+\t    {\n+\t      if (m_reverse)\n+\t\tm_offset -= size;\n+\n+\t      to1 = m_to.adjust (mode, m_offset);\n+\t      from1 = m_from.adjust (mode, m_offset);\n+\n+\t      m_to.maybe_predec (-(HOST_WIDE_INT)size);\n+\t      m_from.maybe_predec (-(HOST_WIDE_INT)size);\n \n-      max_size = GET_MODE_SIZE (mode);\n+\t      generate (to1, from1, mode);\n+\n+\t      m_to.maybe_postinc (size);\n+\t      m_from.maybe_postinc (size);\n+\n+\t      if (!m_reverse)\n+\t\tm_offset += size;\n+\n+\t      m_len -= size;\n+\t    }\n+\n+\t  finish_mode (mode);\n+\t}\n+\n+      m_max_size = GET_MODE_SIZE (mode);\n     }\n \n   /* The code above should have handled everything.  */\n-  gcc_assert (!data.len);\n+  gcc_assert (!m_len);\n+}\n+\n+/* Derived class from op_by_pieces_d, providing support for block move\n+   operations.  */\n+\n+class move_by_pieces_d : public op_by_pieces_d\n+{\n+  insn_gen_fn m_gen_fun;\n+  void generate (rtx, rtx, machine_mode);\n+  bool prepare_mode (machine_mode, unsigned int);\n+\n+ public:\n+  move_by_pieces_d (rtx to, rtx from, unsigned HOST_WIDE_INT len,\n+\t\t    unsigned int align)\n+    : op_by_pieces_d (to, false, from, true, NULL, NULL, len, align)\n+  {\n+  }\n+  rtx finish_endp (int);\n+};\n+\n+/* Return true if MODE can be used for a set of copies, given an\n+   alignment ALIGN.  Prepare whatever data is necessary for later\n+   calls to generate.  */\n+\n+bool\n+move_by_pieces_d::prepare_mode (machine_mode mode, unsigned int align)\n+{\n+  insn_code icode = optab_handler (mov_optab, mode);\n+  m_gen_fun = GEN_FCN (icode);\n+  return icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode);\n+}\n+\n+/* A callback used when iterating for a compare_by_pieces_operation.\n+   OP0 and OP1 are the values that have been loaded and should be\n+   compared in MODE.  If OP0 is NULL, this means we should generate a\n+   push; otherwise EXTRA_DATA holds a pointer to a pointer to the insn\n+   gen function that should be used to generate the mode.  */\n+\n+void\n+move_by_pieces_d::generate (rtx op0, rtx op1, machine_mode mode)\n+{\n+#ifdef PUSH_ROUNDING\n+  if (op0 == NULL_RTX)\n+    {\n+      emit_single_push_insn (mode, op1, NULL);\n+      return;\n+    }\n+#endif\n+  emit_insn (m_gen_fun (op0, op1));\n+}\n+\n+/* Perform the final adjustment at the end of a string to obtain the\n+   correct return value for the block operation.  If ENDP is 1 return\n+   memory at the end ala mempcpy, and if ENDP is 2 return memory the\n+   end minus one byte ala stpcpy.  */\n+\n+rtx\n+move_by_pieces_d::finish_endp (int endp)\n+{\n+  gcc_assert (!m_reverse);\n+  if (endp == 2)\n+    {\n+      m_to.maybe_postinc (-1);\n+      --m_offset;\n+    }\n+  return m_to.adjust (QImode, m_offset);\n+}\n+\n+/* Generate several move instructions to copy LEN bytes from block FROM to\n+   block TO.  (These are MEM rtx's with BLKmode).\n+\n+   If PUSH_ROUNDING is defined and TO is NULL, emit_single_push_insn is\n+   used to push FROM to the stack.\n+\n+   ALIGN is maximum stack alignment we can assume.\n+\n+   If ENDP is 0 return to, if ENDP is 1 return memory at the end ala\n+   mempcpy, and if ENDP is 2 return memory the end minus one byte ala\n+   stpcpy.  */\n+\n+rtx\n+move_by_pieces (rtx to, rtx from, unsigned HOST_WIDE_INT len,\n+\t\tunsigned int align, int endp)\n+{\n+#ifndef PUSH_ROUNDING\n+  if (to == NULL)\n+    gcc_unreachable ();\n+#endif\n+\n+  move_by_pieces_d data (to, from, len, align);\n+\n+  data.run ();\n \n   if (endp)\n+    return data.finish_endp (endp);\n+  else\n+    return to;\n+}\n+\n+/* Derived class from op_by_pieces_d, providing support for block move\n+   operations.  */\n+\n+class store_by_pieces_d : public op_by_pieces_d\n+{\n+  insn_gen_fn m_gen_fun;\n+  void generate (rtx, rtx, machine_mode);\n+  bool prepare_mode (machine_mode, unsigned int);\n+\n+ public:\n+  store_by_pieces_d (rtx to, by_pieces_constfn cfn, void *cfn_data,\n+\t\t     unsigned HOST_WIDE_INT len, unsigned int align)\n+    : op_by_pieces_d (to, false, NULL_RTX, true, cfn, cfn_data, len, align)\n+  {\n+  }\n+  rtx finish_endp (int);\n+};\n+\n+/* Return true if MODE can be used for a set of stores, given an\n+   alignment ALIGN.  Prepare whatever data is necessary for later\n+   calls to generate.  */\n+\n+bool\n+store_by_pieces_d::prepare_mode (machine_mode mode, unsigned int align)\n+{\n+  insn_code icode = optab_handler (mov_optab, mode);\n+  m_gen_fun = GEN_FCN (icode);\n+  return icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode);\n+}\n+\n+/* A callback used when iterating for a store_by_pieces_operation.\n+   OP0 and OP1 are the values that have been loaded and should be\n+   compared in MODE.  If OP0 is NULL, this means we should generate a\n+   push; otherwise EXTRA_DATA holds a pointer to a pointer to the insn\n+   gen function that should be used to generate the mode.  */\n+\n+void\n+store_by_pieces_d::generate (rtx op0, rtx op1, machine_mode)\n+{\n+  emit_insn (m_gen_fun (op0, op1));\n+}\n+\n+/* Perform the final adjustment at the end of a string to obtain the\n+   correct return value for the block operation.  If ENDP is 1 return\n+   memory at the end ala mempcpy, and if ENDP is 2 return memory the\n+   end minus one byte ala stpcpy.  */\n+\n+rtx\n+store_by_pieces_d::finish_endp (int endp)\n+{\n+  gcc_assert (!m_reverse);\n+  if (endp == 2)\n     {\n-      rtx to1;\n+      m_to.maybe_postinc (-1);\n+      --m_offset;\n+    }\n+  return m_to.adjust (QImode, m_offset);\n+}\n+\n+/* Determine whether the LEN bytes generated by CONSTFUN can be\n+   stored to memory using several move instructions.  CONSTFUNDATA is\n+   a pointer which will be passed as argument in every CONSTFUN call.\n+   ALIGN is maximum alignment we can assume.  MEMSETP is true if this is\n+   a memset operation and false if it's a copy of a constant string.\n+   Return nonzero if a call to store_by_pieces should succeed.  */\n \n-      gcc_assert (!data.reverse);\n-      if (data.autinc_to)\n+int\n+can_store_by_pieces (unsigned HOST_WIDE_INT len,\n+\t\t     rtx (*constfun) (void *, HOST_WIDE_INT, machine_mode),\n+\t\t     void *constfundata, unsigned int align, bool memsetp)\n+{\n+  unsigned HOST_WIDE_INT l;\n+  unsigned int max_size;\n+  HOST_WIDE_INT offset = 0;\n+  machine_mode mode;\n+  enum insn_code icode;\n+  int reverse;\n+  /* cst is set but not used if LEGITIMATE_CONSTANT doesn't use it.  */\n+  rtx cst ATTRIBUTE_UNUSED;\n+\n+  if (len == 0)\n+    return 1;\n+\n+  if (!targetm.use_by_pieces_infrastructure_p (len, align,\n+\t\t\t\t\t       memsetp\n+\t\t\t\t\t\t ? SET_BY_PIECES\n+\t\t\t\t\t\t : STORE_BY_PIECES,\n+\t\t\t\t\t       optimize_insn_for_speed_p ()))\n+    return 0;\n+\n+  align = alignment_for_piecewise_move (STORE_MAX_PIECES, align);\n+\n+  /* We would first store what we can in the largest integer mode, then go to\n+     successively smaller modes.  */\n+\n+  for (reverse = 0;\n+       reverse <= (HAVE_PRE_DECREMENT || HAVE_POST_DECREMENT);\n+       reverse++)\n+    {\n+      l = len;\n+      max_size = STORE_MAX_PIECES + 1;\n+      while (max_size > 1 && l > 0)\n \t{\n-\t  if (endp == 2)\n+\t  mode = widest_int_mode_for_size (max_size);\n+\n+\t  if (mode == VOIDmode)\n+\t    break;\n+\n+\t  icode = optab_handler (mov_optab, mode);\n+\t  if (icode != CODE_FOR_nothing\n+\t      && align >= GET_MODE_ALIGNMENT (mode))\n \t    {\n-\t      if (HAVE_POST_INCREMENT && data.explicit_inc_to > 0)\n-\t\temit_insn (gen_add2_insn (data.to_addr, constm1_rtx));\n-\t      else\n-\t\tdata.to_addr = copy_to_mode_reg (to_addr_mode,\n-\t\t\t\t\t\t plus_constant (to_addr_mode,\n-\t\t\t\t\t\t\t\tdata.to_addr,\n-\t\t\t\t\t\t\t\t-1));\n+\t      unsigned int size = GET_MODE_SIZE (mode);\n+\n+\t      while (l >= size)\n+\t\t{\n+\t\t  if (reverse)\n+\t\t    offset -= size;\n+\n+\t\t  cst = (*constfun) (constfundata, offset, mode);\n+\t\t  if (!targetm.legitimate_constant_p (mode, cst))\n+\t\t    return 0;\n+\n+\t\t  if (!reverse)\n+\t\t    offset += size;\n+\n+\t\t  l -= size;\n+\t\t}\n \t    }\n-\t  to1 = adjust_automodify_address (data.to, QImode, data.to_addr,\n-\t\t\t\t\t   data.offset);\n-\t}\n-      else\n-\t{\n-\t  if (endp == 2)\n-\t    --data.offset;\n-\t  to1 = adjust_address (data.to, QImode, data.offset);\n+\n+\t  max_size = GET_MODE_SIZE (mode);\n \t}\n-      return to1;\n+\n+      /* The code above should have handled everything.  */\n+      gcc_assert (!l);\n     }\n+\n+  return 1;\n+}\n+\n+/* Generate several move instructions to store LEN bytes generated by\n+   CONSTFUN to block TO.  (A MEM rtx with BLKmode).  CONSTFUNDATA is a\n+   pointer which will be passed as argument in every CONSTFUN call.\n+   ALIGN is maximum alignment we can assume.  MEMSETP is true if this is\n+   a memset operation and false if it's a copy of a constant string.\n+   If ENDP is 0 return to, if ENDP is 1 return memory at the end ala\n+   mempcpy, and if ENDP is 2 return memory the end minus one byte ala\n+   stpcpy.  */\n+\n+rtx\n+store_by_pieces (rtx to, unsigned HOST_WIDE_INT len,\n+\t\t rtx (*constfun) (void *, HOST_WIDE_INT, machine_mode),\n+\t\t void *constfundata, unsigned int align, bool memsetp, int endp)\n+{\n+  if (len == 0)\n+    {\n+      gcc_assert (endp != 2);\n+      return to;\n+    }\n+\n+  gcc_assert (targetm.use_by_pieces_infrastructure_p\n+\t\t(len, align,\n+\t\t memsetp ? SET_BY_PIECES : STORE_BY_PIECES,\n+\t\t optimize_insn_for_speed_p ()));\n+\n+  store_by_pieces_d data (to, constfun, constfundata, len, align);\n+  data.run ();\n+\n+  if (endp)\n+    return data.finish_endp (endp);\n   else\n-    return data.to;\n+    return to;\n }\n \n-/* Return number of insns required to move L bytes by pieces.\n-   ALIGN (in bits) is maximum alignment we can assume.  */\n+/* Callback routine for clear_by_pieces.\n+   Return const0_rtx unconditionally.  */\n \n-unsigned HOST_WIDE_INT\n-move_by_pieces_ninsns (unsigned HOST_WIDE_INT l, unsigned int align,\n-\t\t       unsigned int max_size)\n+static rtx\n+clear_by_pieces_1 (void *, HOST_WIDE_INT, machine_mode)\n {\n-  unsigned HOST_WIDE_INT n_insns = 0;\n+  return const0_rtx;\n+}\n \n-  align = alignment_for_piecewise_move (MOVE_MAX_PIECES, align);\n+/* Generate several move instructions to clear LEN bytes of block TO.  (A MEM\n+   rtx with BLKmode).  ALIGN is maximum alignment we can assume.  */\n \n-  while (max_size > 1 && l > 0)\n-    {\n-      machine_mode mode;\n-      enum insn_code icode;\n+static void\n+clear_by_pieces (rtx to, unsigned HOST_WIDE_INT len, unsigned int align)\n+{\n+  if (len == 0)\n+    return;\n \n-      mode = widest_int_mode_for_size (max_size);\n+  store_by_pieces_d data (to, clear_by_pieces_1, NULL, len, align);\n+  data.run ();\n+}\n \n-      if (mode == VOIDmode)\n-\tbreak;\n+/* Context used by compare_by_pieces_genfn.  It stores the fail label\n+   to jump to in case of miscomparison, and for branch ratios greater than 1,\n+   it stores an accumulator and the current and maximum counts before\n+   emitting another branch.  */\n \n-      icode = optab_handler (mov_optab, mode);\n-      if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))\n-\tn_insns += l / GET_MODE_SIZE (mode), l %= GET_MODE_SIZE (mode);\n+class compare_by_pieces_d : public op_by_pieces_d\n+{\n+  rtx_code_label *m_fail_label;\n+  rtx m_accumulator;\n+  int m_count, m_batch;\n+\n+  void generate (rtx, rtx, machine_mode);\n+  bool prepare_mode (machine_mode, unsigned int);\n+  void finish_mode (machine_mode);\n+ public:\n+  compare_by_pieces_d (rtx op0, rtx op1, by_pieces_constfn op1_cfn,\n+\t\t       void *op1_cfn_data, HOST_WIDE_INT len, int align,\n+\t\t       rtx_code_label *fail_label)\n+    : op_by_pieces_d (op0, true, op1, true, op1_cfn, op1_cfn_data, len, align)\n+  {\n+    m_fail_label = fail_label;\n+  }\n+};\n+\n+/* A callback used when iterating for a compare_by_pieces_operation.\n+   OP0 and OP1 are the values that have been loaded and should be\n+   compared in MODE.  DATA holds a pointer to the compare_by_pieces_data\n+   context structure.  */\n+\n+void\n+compare_by_pieces_d::generate (rtx op0, rtx op1, machine_mode mode)\n+{\n+  if (m_batch > 1)\n+    {\n+      rtx temp = expand_binop (mode, sub_optab, op0, op1, NULL_RTX,\n+\t\t\t       true, OPTAB_LIB_WIDEN);\n+      if (m_count != 0)\n+\ttemp = expand_binop (mode, ior_optab, m_accumulator, temp, temp,\n+\t\t\t     true, OPTAB_LIB_WIDEN);\n+      m_accumulator = temp;\n+\n+      if (++m_count < m_batch)\n+\treturn;\n \n-      max_size = GET_MODE_SIZE (mode);\n+      m_count = 0;\n+      op0 = m_accumulator;\n+      op1 = const0_rtx;\n+      m_accumulator = NULL_RTX;\n     }\n+  do_compare_rtx_and_jump (op0, op1, NE, true, mode, NULL_RTX, NULL,\n+\t\t\t   m_fail_label, -1);\n+}\n \n-  gcc_assert (!l);\n-  return n_insns;\n+/* Return true if MODE can be used for a set of moves and comparisons,\n+   given an alignment ALIGN.  Prepare whatever data is necessary for\n+   later calls to generate.  */\n+\n+bool\n+compare_by_pieces_d::prepare_mode (machine_mode mode, unsigned int align)\n+{\n+  insn_code icode = optab_handler (mov_optab, mode);\n+  if (icode == CODE_FOR_nothing\n+      || align < GET_MODE_ALIGNMENT (mode)\n+      || !can_compare_p (EQ, mode, ccp_jump))\n+    return false;\n+  m_batch = targetm.compare_by_pieces_branch_ratio (mode);\n+  if (m_batch < 0)\n+    return false;\n+  m_accumulator = NULL_RTX;\n+  m_count = 0;\n+  return true;\n+}\n+\n+/* Called after expanding a series of comparisons in MODE.  If we have\n+   accumulated results for which we haven't emitted a branch yet, do\n+   so now.  */\n+\n+void\n+compare_by_pieces_d::finish_mode (machine_mode mode)\n+{\n+  if (m_accumulator != NULL_RTX)\n+    do_compare_rtx_and_jump (m_accumulator, const0_rtx, NE, true, mode,\n+\t\t\t     NULL_RTX, NULL, m_fail_label, -1);\n }\n \n-/* Subroutine of move_by_pieces.  Move as many bytes as appropriate\n-   with move instructions for mode MODE.  GENFUN is the gen_... function\n-   to make a move insn for that mode.  DATA has all the other info.  */\n+/* Generate several move instructions to compare LEN bytes from blocks\n+   ARG0 and ARG1.  (These are MEM rtx's with BLKmode).\n \n-static void\n-move_by_pieces_1 (insn_gen_fn genfun, machine_mode mode,\n-\t\t  struct move_by_pieces_d *data)\n-{\n-  unsigned int size = GET_MODE_SIZE (mode);\n-  rtx to1 = NULL_RTX, from1;\n+   If PUSH_ROUNDING is defined and TO is NULL, emit_single_push_insn is\n+   used to push FROM to the stack.\n \n-  while (data->len >= size)\n-    {\n-      if (data->reverse)\n-\tdata->offset -= size;\n+   ALIGN is maximum stack alignment we can assume.\n \n-      if (data->to)\n-\t{\n-\t  if (data->autinc_to)\n-\t    to1 = adjust_automodify_address (data->to, mode, data->to_addr,\n-\t\t\t\t\t     data->offset);\n-\t  else\n-\t    to1 = adjust_address (data->to, mode, data->offset);\n-\t}\n+   Optionally, the caller can pass a constfn and associated data in A1_CFN\n+   and A1_CFN_DATA. describing that the second operand being compared is a\n+   known constant and how to obtain its data.  */\n \n-      if (data->autinc_from)\n-\tfrom1 = adjust_automodify_address (data->from, mode, data->from_addr,\n-\t\t\t\t\t   data->offset);\n-      else\n-\tfrom1 = adjust_address (data->from, mode, data->offset);\n-\n-      if (HAVE_PRE_DECREMENT && data->explicit_inc_to < 0)\n-\temit_insn (gen_add2_insn (data->to_addr,\n-\t\t\t\t  gen_int_mode (-(HOST_WIDE_INT) size,\n-\t\t\t\t\t\tGET_MODE (data->to_addr))));\n-      if (HAVE_PRE_DECREMENT && data->explicit_inc_from < 0)\n-\temit_insn (gen_add2_insn (data->from_addr,\n-\t\t\t\t  gen_int_mode (-(HOST_WIDE_INT) size,\n-\t\t\t\t\t\tGET_MODE (data->from_addr))));\n-\n-      if (data->to)\n-\temit_insn ((*genfun) (to1, from1));\n-      else\n-\t{\n-#ifdef PUSH_ROUNDING\n-\t  emit_single_push_insn (mode, from1, NULL);\n-#else\n-\t  gcc_unreachable ();\n-#endif\n-\t}\n+static rtx\n+compare_by_pieces (rtx arg0, rtx arg1, unsigned HOST_WIDE_INT len,\n+\t\t   rtx target, unsigned int align,\n+\t\t   by_pieces_constfn a1_cfn, void *a1_cfn_data)\n+{\n+  rtx_code_label *fail_label = gen_label_rtx ();\n+  rtx_code_label *end_label = gen_label_rtx ();\n \n-      if (HAVE_POST_INCREMENT && data->explicit_inc_to > 0)\n-\temit_insn (gen_add2_insn (data->to_addr,\n-\t\t\t\t  gen_int_mode (size,\n-\t\t\t\t\t\tGET_MODE (data->to_addr))));\n-      if (HAVE_POST_INCREMENT && data->explicit_inc_from > 0)\n-\temit_insn (gen_add2_insn (data->from_addr,\n-\t\t\t\t  gen_int_mode (size,\n-\t\t\t\t\t\tGET_MODE (data->from_addr))));\n+  if (target == NULL_RTX\n+      || !REG_P (target) || REGNO (target) < FIRST_PSEUDO_REGISTER)\n+    target = gen_reg_rtx (TYPE_MODE (integer_type_node));\n \n-      if (! data->reverse)\n-\tdata->offset += size;\n+  compare_by_pieces_d data (arg0, arg1, a1_cfn, a1_cfn_data, len, align,\n+\t\t\t    fail_label);\n \n-      data->len -= size;\n-    }\n+  data.run ();\n+\n+  emit_move_insn (target, const0_rtx);\n+  emit_jump (end_label);\n+  emit_barrier ();\n+  emit_label (fail_label);\n+  emit_move_insn (target, const1_rtx);\n+  emit_label (end_label);\n+\n+  return target;\n }\n \f\n /* Emit code to move a block Y to a block X.  This may be done with\n@@ -1066,8 +1550,7 @@ emit_block_move_hints (rtx x, rtx y, rtx size, enum block_op_methods method,\n   unsigned int align;\n \n   gcc_assert (size);\n-  if (CONST_INT_P (size)\n-      && INTVAL (size) == 0)\n+  if (CONST_INT_P (size) && INTVAL (size) == 0)\n     return 0;\n \n   switch (method)\n@@ -1394,6 +1877,99 @@ emit_block_op_via_libcall (enum built_in_function fncode, rtx dst, rtx src,\n \n   return expand_call (call_expr, NULL_RTX, false);\n }\n+\n+/* Try to expand cmpstrn or cmpmem operation ICODE with the given operands.\n+   ARG3_TYPE is the type of ARG3_RTX.  Return the result rtx on success,\n+   otherwise return null.  */\n+\n+rtx\n+expand_cmpstrn_or_cmpmem (insn_code icode, rtx target, rtx arg1_rtx,\n+\t\t\t  rtx arg2_rtx, tree arg3_type, rtx arg3_rtx,\n+\t\t\t  HOST_WIDE_INT align)\n+{\n+  machine_mode insn_mode = insn_data[icode].operand[0].mode;\n+\n+  if (target && (!REG_P (target) || HARD_REGISTER_P (target)))\n+    target = NULL_RTX;\n+\n+  struct expand_operand ops[5];\n+  create_output_operand (&ops[0], target, insn_mode);\n+  create_fixed_operand (&ops[1], arg1_rtx);\n+  create_fixed_operand (&ops[2], arg2_rtx);\n+  create_convert_operand_from (&ops[3], arg3_rtx, TYPE_MODE (arg3_type),\n+\t\t\t       TYPE_UNSIGNED (arg3_type));\n+  create_integer_operand (&ops[4], align);\n+  if (maybe_expand_insn (icode, 5, ops))\n+    return ops[0].value;\n+  return NULL_RTX;\n+}\n+\n+/* Expand a block compare between X and Y with length LEN using the\n+   cmpmem optab, placing the result in TARGET.  LEN_TYPE is the type\n+   of the expression that was used to calculate the length.  ALIGN\n+   gives the known minimum common alignment.  */\n+\n+static rtx\n+emit_block_cmp_via_cmpmem (rtx x, rtx y, rtx len, tree len_type, rtx target,\n+\t\t\t   unsigned align)\n+{\n+  /* Note: The cmpstrnsi pattern, if it exists, is not suitable for\n+     implementing memcmp because it will stop if it encounters two\n+     zero bytes.  */\n+  insn_code icode = direct_optab_handler (cmpmem_optab, SImode);\n+\n+  if (icode == CODE_FOR_nothing)\n+    return NULL_RTX;\n+\n+  return expand_cmpstrn_or_cmpmem (icode, target, x, y, len_type, len, align);\n+}\n+\n+/* Emit code to compare a block Y to a block X.  This may be done with\n+   string-compare instructions, with multiple scalar instructions,\n+   or with a library call.\n+\n+   Both X and Y must be MEM rtx's.  LEN is an rtx that says how long\n+   they are.  LEN_TYPE is the type of the expression that was used to\n+   calculate it.\n+\n+   If EQUALITY_ONLY is true, it means we don't have to return the tri-state\n+   value of a normal memcmp call, instead we can just compare for equality.\n+   If FORCE_LIBCALL is true, we should emit a call to memcmp rather than\n+   returning NULL_RTX.\n+\n+   Optionally, the caller can pass a constfn and associated data in Y_CFN\n+   and Y_CFN_DATA. describing that the second operand being compared is a\n+   known constant and how to obtain its data.\n+   Return the result of the comparison, or NULL_RTX if we failed to\n+   perform the operation.  */\n+\n+rtx\n+emit_block_cmp_hints (rtx x, rtx y, rtx len, tree len_type, rtx target,\n+\t\t      bool equality_only, by_pieces_constfn y_cfn,\n+\t\t      void *y_cfndata)\n+{\n+  rtx result = 0;\n+\n+  if (CONST_INT_P (len) && INTVAL (len) == 0)\n+    return const0_rtx;\n+\n+  gcc_assert (MEM_P (x) && MEM_P (y));\n+  unsigned int align = MIN (MEM_ALIGN (x), MEM_ALIGN (y));\n+  gcc_assert (align >= BITS_PER_UNIT);\n+\n+  x = adjust_address (x, BLKmode, 0);\n+  y = adjust_address (y, BLKmode, 0);\n+\n+  if (equality_only\n+      && CONST_INT_P (len)\n+      && can_do_by_pieces (INTVAL (len), align, COMPARE_BY_PIECES))\n+    result = compare_by_pieces (x, y, INTVAL (len), target, align,\n+\t\t\t\ty_cfn, y_cfndata);\n+  else\n+    result = emit_block_cmp_via_cmpmem (x, y, len, len_type, target, align);\n+\n+  return result;\n+}\n \f\n /* Copy all or part of a value X into registers starting at REGNO.\n    The number of registers to be filled is NREGS.  */\n@@ -2330,308 +2906,6 @@ get_def_for_expr_class (tree name, enum tree_code_class tclass)\n   return def_stmt;\n }\n \f\n-\n-/* Determine whether the LEN bytes generated by CONSTFUN can be\n-   stored to memory using several move instructions.  CONSTFUNDATA is\n-   a pointer which will be passed as argument in every CONSTFUN call.\n-   ALIGN is maximum alignment we can assume.  MEMSETP is true if this is\n-   a memset operation and false if it's a copy of a constant string.\n-   Return nonzero if a call to store_by_pieces should succeed.  */\n-\n-int\n-can_store_by_pieces (unsigned HOST_WIDE_INT len,\n-\t\t     rtx (*constfun) (void *, HOST_WIDE_INT, machine_mode),\n-\t\t     void *constfundata, unsigned int align, bool memsetp)\n-{\n-  unsigned HOST_WIDE_INT l;\n-  unsigned int max_size;\n-  HOST_WIDE_INT offset = 0;\n-  machine_mode mode;\n-  enum insn_code icode;\n-  int reverse;\n-  /* cst is set but not used if LEGITIMATE_CONSTANT doesn't use it.  */\n-  rtx cst ATTRIBUTE_UNUSED;\n-\n-  if (len == 0)\n-    return 1;\n-\n-  if (!targetm.use_by_pieces_infrastructure_p (len, align,\n-\t\t\t\t\t       memsetp\n-\t\t\t\t\t\t ? SET_BY_PIECES\n-\t\t\t\t\t\t : STORE_BY_PIECES,\n-\t\t\t\t\t       optimize_insn_for_speed_p ()))\n-    return 0;\n-\n-  align = alignment_for_piecewise_move (STORE_MAX_PIECES, align);\n-\n-  /* We would first store what we can in the largest integer mode, then go to\n-     successively smaller modes.  */\n-\n-  for (reverse = 0;\n-       reverse <= (HAVE_PRE_DECREMENT || HAVE_POST_DECREMENT);\n-       reverse++)\n-    {\n-      l = len;\n-      max_size = STORE_MAX_PIECES + 1;\n-      while (max_size > 1 && l > 0)\n-\t{\n-\t  mode = widest_int_mode_for_size (max_size);\n-\n-\t  if (mode == VOIDmode)\n-\t    break;\n-\n-\t  icode = optab_handler (mov_optab, mode);\n-\t  if (icode != CODE_FOR_nothing\n-\t      && align >= GET_MODE_ALIGNMENT (mode))\n-\t    {\n-\t      unsigned int size = GET_MODE_SIZE (mode);\n-\n-\t      while (l >= size)\n-\t\t{\n-\t\t  if (reverse)\n-\t\t    offset -= size;\n-\n-\t\t  cst = (*constfun) (constfundata, offset, mode);\n-\t\t  if (!targetm.legitimate_constant_p (mode, cst))\n-\t\t    return 0;\n-\n-\t\t  if (!reverse)\n-\t\t    offset += size;\n-\n-\t\t  l -= size;\n-\t\t}\n-\t    }\n-\n-\t  max_size = GET_MODE_SIZE (mode);\n-\t}\n-\n-      /* The code above should have handled everything.  */\n-      gcc_assert (!l);\n-    }\n-\n-  return 1;\n-}\n-\n-/* Generate several move instructions to store LEN bytes generated by\n-   CONSTFUN to block TO.  (A MEM rtx with BLKmode).  CONSTFUNDATA is a\n-   pointer which will be passed as argument in every CONSTFUN call.\n-   ALIGN is maximum alignment we can assume.  MEMSETP is true if this is\n-   a memset operation and false if it's a copy of a constant string.\n-   If ENDP is 0 return to, if ENDP is 1 return memory at the end ala\n-   mempcpy, and if ENDP is 2 return memory the end minus one byte ala\n-   stpcpy.  */\n-\n-rtx\n-store_by_pieces (rtx to, unsigned HOST_WIDE_INT len,\n-\t\t rtx (*constfun) (void *, HOST_WIDE_INT, machine_mode),\n-\t\t void *constfundata, unsigned int align, bool memsetp, int endp)\n-{\n-  machine_mode to_addr_mode = get_address_mode (to);\n-  struct store_by_pieces_d data;\n-\n-  if (len == 0)\n-    {\n-      gcc_assert (endp != 2);\n-      return to;\n-    }\n-\n-  gcc_assert (targetm.use_by_pieces_infrastructure_p\n-\t\t(len, align,\n-\t\t memsetp\n-\t\t   ? SET_BY_PIECES\n-\t\t   : STORE_BY_PIECES,\n-\t\t optimize_insn_for_speed_p ()));\n-\n-  data.constfun = constfun;\n-  data.constfundata = constfundata;\n-  data.len = len;\n-  data.to = to;\n-  store_by_pieces_1 (&data, align);\n-  if (endp)\n-    {\n-      rtx to1;\n-\n-      gcc_assert (!data.reverse);\n-      if (data.autinc_to)\n-\t{\n-\t  if (endp == 2)\n-\t    {\n-\t      if (HAVE_POST_INCREMENT && data.explicit_inc_to > 0)\n-\t\temit_insn (gen_add2_insn (data.to_addr, constm1_rtx));\n-\t      else\n-\t\tdata.to_addr = copy_to_mode_reg (to_addr_mode,\n-\t\t\t\t\t\t plus_constant (to_addr_mode,\n-\t\t\t\t\t\t\t\tdata.to_addr,\n-\t\t\t\t\t\t\t\t-1));\n-\t    }\n-\t  to1 = adjust_automodify_address (data.to, QImode, data.to_addr,\n-\t\t\t\t\t   data.offset);\n-\t}\n-      else\n-\t{\n-\t  if (endp == 2)\n-\t    --data.offset;\n-\t  to1 = adjust_address (data.to, QImode, data.offset);\n-\t}\n-      return to1;\n-    }\n-  else\n-    return data.to;\n-}\n-\n-/* Generate several move instructions to clear LEN bytes of block TO.  (A MEM\n-   rtx with BLKmode).  ALIGN is maximum alignment we can assume.  */\n-\n-static void\n-clear_by_pieces (rtx to, unsigned HOST_WIDE_INT len, unsigned int align)\n-{\n-  struct store_by_pieces_d data;\n-\n-  if (len == 0)\n-    return;\n-\n-  data.constfun = clear_by_pieces_1;\n-  data.constfundata = NULL;\n-  data.len = len;\n-  data.to = to;\n-  store_by_pieces_1 (&data, align);\n-}\n-\n-/* Callback routine for clear_by_pieces.\n-   Return const0_rtx unconditionally.  */\n-\n-static rtx\n-clear_by_pieces_1 (void *data ATTRIBUTE_UNUSED,\n-\t\t   HOST_WIDE_INT offset ATTRIBUTE_UNUSED,\n-\t\t   machine_mode mode ATTRIBUTE_UNUSED)\n-{\n-  return const0_rtx;\n-}\n-\n-/* Subroutine of clear_by_pieces and store_by_pieces.\n-   Generate several move instructions to store LEN bytes of block TO.  (A MEM\n-   rtx with BLKmode).  ALIGN is maximum alignment we can assume.  */\n-\n-static void\n-store_by_pieces_1 (struct store_by_pieces_d *data ATTRIBUTE_UNUSED,\n-\t\t   unsigned int align ATTRIBUTE_UNUSED)\n-{\n-  machine_mode to_addr_mode = get_address_mode (data->to);\n-  rtx to_addr = XEXP (data->to, 0);\n-  unsigned int max_size = STORE_MAX_PIECES + 1;\n-  enum insn_code icode;\n-\n-  data->offset = 0;\n-  data->to_addr = to_addr;\n-  data->autinc_to\n-    = (GET_CODE (to_addr) == PRE_INC || GET_CODE (to_addr) == PRE_DEC\n-       || GET_CODE (to_addr) == POST_INC || GET_CODE (to_addr) == POST_DEC);\n-\n-  data->explicit_inc_to = 0;\n-  data->reverse\n-    = (GET_CODE (to_addr) == PRE_DEC || GET_CODE (to_addr) == POST_DEC);\n-  if (data->reverse)\n-    data->offset = data->len;\n-\n-  /* If storing requires more than two move insns,\n-     copy addresses to registers (to make displacements shorter)\n-     and use post-increment if available.  */\n-  if (!data->autinc_to\n-      && move_by_pieces_ninsns (data->len, align, max_size) > 2)\n-    {\n-      /* Determine the main mode we'll be using.\n-\t MODE might not be used depending on the definitions of the\n-\t USE_* macros below.  */\n-      machine_mode mode ATTRIBUTE_UNUSED\n-\t= widest_int_mode_for_size (max_size);\n-\n-      if (USE_STORE_PRE_DECREMENT (mode) && data->reverse && ! data->autinc_to)\n-\t{\n-\t  data->to_addr = copy_to_mode_reg (to_addr_mode,\n-\t\t\t\t\t    plus_constant (to_addr_mode,\n-\t\t\t\t\t\t\t   to_addr,\n-\t\t\t\t\t\t\t   data->len));\n-\t  data->autinc_to = 1;\n-\t  data->explicit_inc_to = -1;\n-\t}\n-\n-      if (USE_STORE_POST_INCREMENT (mode) && ! data->reverse\n-\t  && ! data->autinc_to)\n-\t{\n-\t  data->to_addr = copy_to_mode_reg (to_addr_mode, to_addr);\n-\t  data->autinc_to = 1;\n-\t  data->explicit_inc_to = 1;\n-\t}\n-\n-      if ( !data->autinc_to && CONSTANT_P (to_addr))\n-\tdata->to_addr = copy_to_mode_reg (to_addr_mode, to_addr);\n-    }\n-\n-  align = alignment_for_piecewise_move (STORE_MAX_PIECES, align);\n-\n-  /* First store what we can in the largest integer mode, then go to\n-     successively smaller modes.  */\n-\n-  while (max_size > 1 && data->len > 0)\n-    {\n-      machine_mode mode = widest_int_mode_for_size (max_size);\n-\n-      if (mode == VOIDmode)\n-\tbreak;\n-\n-      icode = optab_handler (mov_optab, mode);\n-      if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))\n-\tstore_by_pieces_2 (GEN_FCN (icode), mode, data);\n-\n-      max_size = GET_MODE_SIZE (mode);\n-    }\n-\n-  /* The code above should have handled everything.  */\n-  gcc_assert (!data->len);\n-}\n-\n-/* Subroutine of store_by_pieces_1.  Store as many bytes as appropriate\n-   with move instructions for mode MODE.  GENFUN is the gen_... function\n-   to make a move insn for that mode.  DATA has all the other info.  */\n-\n-static void\n-store_by_pieces_2 (insn_gen_fn genfun, machine_mode mode,\n-\t\t   struct store_by_pieces_d *data)\n-{\n-  unsigned int size = GET_MODE_SIZE (mode);\n-  rtx to1, cst;\n-\n-  while (data->len >= size)\n-    {\n-      if (data->reverse)\n-\tdata->offset -= size;\n-\n-      if (data->autinc_to)\n-\tto1 = adjust_automodify_address (data->to, mode, data->to_addr,\n-\t\t\t\t\t data->offset);\n-      else\n-\tto1 = adjust_address (data->to, mode, data->offset);\n-\n-      if (HAVE_PRE_DECREMENT && data->explicit_inc_to < 0)\n-\temit_insn (gen_add2_insn (data->to_addr,\n-\t\t\t\t  gen_int_mode (-(HOST_WIDE_INT) size,\n-\t\t\t\t\t\tGET_MODE (data->to_addr))));\n-\n-      cst = (*data->constfun) (data->constfundata, data->offset, mode);\n-      emit_insn ((*genfun) (to1, cst));\n-\n-      if (HAVE_POST_INCREMENT && data->explicit_inc_to > 0)\n-\temit_insn (gen_add2_insn (data->to_addr,\n-\t\t\t\t  gen_int_mode (size,\n-\t\t\t\t\t\tGET_MODE (data->to_addr))));\n-\n-      if (! data->reverse)\n-\tdata->offset += size;\n-\n-      data->len -= size;\n-    }\n-}\n-\f\n /* Write zeros through the storage of OBJECT.  If OBJECT has BLKmode, SIZE is\n    its length in bytes.  */\n "}, {"sha": "bd0da5ea36413974889582e939f506d3c93a5d38", "filename": "gcc/expr.h", "status": "modified", "additions": 12, "deletions": 9, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -103,12 +103,16 @@ enum block_op_methods\n   BLOCK_OP_TAILCALL\n };\n \n+typedef rtx (*by_pieces_constfn) (void *, HOST_WIDE_INT, machine_mode);\n+\n extern rtx emit_block_move (rtx, rtx, rtx, enum block_op_methods);\n extern rtx emit_block_move_hints (rtx, rtx, rtx, enum block_op_methods,\n \t\t\t          unsigned int, HOST_WIDE_INT,\n \t\t\t\t  unsigned HOST_WIDE_INT,\n \t\t\t\t  unsigned HOST_WIDE_INT,\n \t\t\t\t  unsigned HOST_WIDE_INT);\n+extern rtx emit_block_cmp_hints (rtx, rtx, rtx, tree, rtx, bool,\n+\t\t\t\t by_pieces_constfn, void *);\n extern bool emit_storent_insn (rtx to, rtx from);\n \n /* Copy all or part of a value X into registers starting at REGNO.\n@@ -173,6 +177,11 @@ extern void use_regs (rtx *, int, int);\n /* Mark a PARALLEL as holding a parameter for the next CALL_INSN.  */\n extern void use_group_regs (rtx *, rtx);\n \n+#ifdef GCC_INSN_CODES_H\n+extern rtx expand_cmpstrn_or_cmpmem (insn_code, rtx, rtx, rtx, tree, rtx,\n+\t\t\t\t     HOST_WIDE_INT);\n+#endif\n+\n /* Write zeros through the storage of OBJECT.\n    If OBJECT has BLKmode, SIZE is its length in bytes.  */\n extern rtx clear_storage (rtx, rtx, enum block_op_methods);\n@@ -191,10 +200,6 @@ extern bool set_storage_via_setmem (rtx, rtx, rtx, unsigned int,\n \t\t\t\t    unsigned HOST_WIDE_INT,\n \t\t\t\t    unsigned HOST_WIDE_INT);\n \n-extern unsigned HOST_WIDE_INT move_by_pieces_ninsns (unsigned HOST_WIDE_INT,\n-\t\t\t\t\t\t     unsigned int,\n-\t\t\t\t\t\t     unsigned int);\n-\n /* Return nonzero if it is desirable to store LEN bytes generated by\n    CONSTFUN with several move instructions by store_by_pieces\n    function.  CONSTFUNDATA is a pointer which will be passed as argument\n@@ -203,8 +208,7 @@ extern unsigned HOST_WIDE_INT move_by_pieces_ninsns (unsigned HOST_WIDE_INT,\n    MEMSETP is true if this is a real memset/bzero, not a copy\n    of a const string.  */\n extern int can_store_by_pieces (unsigned HOST_WIDE_INT,\n-\t\t\t\trtx (*) (void *, HOST_WIDE_INT,\n-\t\t\t\t\t machine_mode),\n+\t\t\t\tby_pieces_constfn,\n \t\t\t\tvoid *, unsigned int, bool);\n \n /* Generate several move instructions to store LEN bytes generated by\n@@ -213,8 +217,7 @@ extern int can_store_by_pieces (unsigned HOST_WIDE_INT,\n    ALIGN is maximum alignment we can assume.\n    MEMSETP is true if this is a real memset/bzero, not a copy.\n    Returns TO + LEN.  */\n-extern rtx store_by_pieces (rtx, unsigned HOST_WIDE_INT,\n-\t\t\t    rtx (*) (void *, HOST_WIDE_INT, machine_mode),\n+extern rtx store_by_pieces (rtx, unsigned HOST_WIDE_INT, by_pieces_constfn,\n \t\t\t    void *, unsigned int, bool, int);\n \n /* Emit insns to set X from Y.  */\n@@ -295,7 +298,7 @@ rtx get_personality_function (tree);\n /* Determine whether the LEN bytes can be moved by using several move\n    instructions.  Return nonzero if a call to move_by_pieces should\n    succeed.  */\n-extern int can_move_by_pieces (unsigned HOST_WIDE_INT, unsigned int);\n+extern bool can_move_by_pieces (unsigned HOST_WIDE_INT, unsigned int);\n \n extern unsigned HOST_WIDE_INT highest_pow2_factor (const_tree);\n "}, {"sha": "a4df363698ce776b51d11c187baed2069ba88a52", "filename": "gcc/target.def", "status": "modified", "additions": 15, "deletions": 2, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarget.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarget.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarget.def?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -3397,8 +3397,9 @@ Both @var{size} and @var{alignment} are measured in terms of storage\\n\\\n units.\\n\\\n \\n\\\n The parameter @var{op} is one of: @code{CLEAR_BY_PIECES},\\n\\\n-@code{MOVE_BY_PIECES}, @code{SET_BY_PIECES}, @code{STORE_BY_PIECES}.\\n\\\n-These describe the type of memory operation under consideration.\\n\\\n+@code{MOVE_BY_PIECES}, @code{SET_BY_PIECES}, @code{STORE_BY_PIECES} or\\n\\\n+@code{COMPARE_BY_PIECES}.  These describe the type of memory operation\\n\\\n+under consideration.\\n\\\n \\n\\\n The parameter @var{speed_p} is true if the code is currently being\\n\\\n optimized for speed rather than size.\\n\\\n@@ -3417,6 +3418,18 @@ move would be greater than that of a library call.\",\n         enum by_pieces_operation op, bool speed_p),\n  default_use_by_pieces_infrastructure_p)\n \n+DEFHOOK\n+(compare_by_pieces_branch_ratio,\n+ \"When expanding a block comparison in MODE, gcc can try to reduce the\\n\\\n+number of branches at the expense of more memory operations.  This hook\\n\\\n+allows the target to override the default choice.  It should return the\\n\\\n+factor by which branches should be reduced over the plain expansion with\\n\\\n+one comparison per @var{mode}-sized piece.  A port can also prevent a\\n\\\n+particular mode from being used for block comparisons by returning a\\n\\\n+negative number from this hook.\",\n+ int, (machine_mode mode),\n+ default_compare_by_pieces_branch_ratio)\n+\n DEFHOOK\n (optab_supported_p,\n  \"Return true if the optimizers should use optab @var{op} with\\n\\"}, {"sha": "f4fed68ba32acc512128c665d8d199476a78c742", "filename": "gcc/target.h", "status": "modified", "additions": 9, "deletions": 2, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarget.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarget.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarget.h?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -79,16 +79,23 @@ enum print_switch_type\n };\n \n /* Types of memory operation understood by the \"by_pieces\" infrastructure.\n-   Used by the TARGET_USE_BY_PIECES_INFRASTRUCTURE_P target hook.  */\n+   Used by the TARGET_USE_BY_PIECES_INFRASTRUCTURE_P target hook and\n+   internally by the functions in expr.c.  */\n \n enum by_pieces_operation\n {\n   CLEAR_BY_PIECES,\n   MOVE_BY_PIECES,\n   SET_BY_PIECES,\n-  STORE_BY_PIECES\n+  STORE_BY_PIECES,\n+  COMPARE_BY_PIECES\n };\n \n+extern unsigned HOST_WIDE_INT by_pieces_ninsns (unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\tunsigned int,\n+\t\t\t\t\t\tunsigned int,\n+\t\t\t\t\t\tby_pieces_operation);\n+\n typedef int (* print_switch_fn_type) (print_switch_type, const char *);\n \n /* An example implementation for ELF targets.  Defined in varasm.c  */"}, {"sha": "95980f547bd9acf2dbbbc47c91ed5b6d2385cacc", "filename": "gcc/targhooks.c", "status": "modified", "additions": 32, "deletions": 17, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarghooks.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarghooks.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarghooks.c?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -1482,25 +1482,40 @@ default_use_by_pieces_infrastructure_p (unsigned HOST_WIDE_INT size,\n \n   switch (op)\n     {\n-      case CLEAR_BY_PIECES:\n-\tmax_size = STORE_MAX_PIECES;\n-\tratio = CLEAR_RATIO (speed_p);\n-\tbreak;\n-      case MOVE_BY_PIECES:\n-\tmax_size = MOVE_MAX_PIECES;\n-\tratio = get_move_ratio (speed_p);\n-\tbreak;\n-      case SET_BY_PIECES:\n-\tmax_size = STORE_MAX_PIECES;\n-\tratio = SET_RATIO (speed_p);\n-\tbreak;\n-      case STORE_BY_PIECES:\n-\tmax_size = STORE_MAX_PIECES;\n-\tratio = get_move_ratio (speed_p);\n-\tbreak;\n+    case CLEAR_BY_PIECES:\n+      max_size = STORE_MAX_PIECES;\n+      ratio = CLEAR_RATIO (speed_p);\n+      break;\n+    case MOVE_BY_PIECES:\n+      max_size = MOVE_MAX_PIECES;\n+      ratio = get_move_ratio (speed_p);\n+      break;\n+    case SET_BY_PIECES:\n+      max_size = STORE_MAX_PIECES;\n+      ratio = SET_RATIO (speed_p);\n+      break;\n+    case STORE_BY_PIECES:\n+      max_size = STORE_MAX_PIECES;\n+      ratio = get_move_ratio (speed_p);\n+      break;\n+    case COMPARE_BY_PIECES:\n+      max_size = COMPARE_MAX_PIECES;\n+      /* Pick a likely default, just as in get_move_ratio.  */\n+      ratio = speed_p ? 15 : 3;\n+      break;\n     }\n \n-  return move_by_pieces_ninsns (size, alignment, max_size + 1) < ratio;\n+  return by_pieces_ninsns (size, alignment, max_size + 1, op) < ratio;\n+}\n+\n+/* This hook controls code generation for expanding a memcmp operation by\n+   pieces.  Return 1 for the normal pattern of compare/jump after each pair\n+   of loads, or a higher number to reduce the number of branches.  */\n+\n+int\n+default_compare_by_pieces_branch_ratio (machine_mode)\n+{\n+  return 1;\n }\n \n bool"}, {"sha": "d6581cfab893e0da619c6bc0f98ff722a7ab4404", "filename": "gcc/targhooks.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarghooks.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftarghooks.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarghooks.h?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -199,6 +199,7 @@ extern bool default_use_by_pieces_infrastructure_p (unsigned HOST_WIDE_INT,\n \t\t\t\t\t\t    unsigned int,\n \t\t\t\t\t\t    enum by_pieces_operation,\n \t\t\t\t\t\t    bool);\n+extern int default_compare_by_pieces_branch_ratio (machine_mode);\n \n extern bool default_profile_before_prologue (void);\n extern reg_class_t default_preferred_reload_class (rtx, reg_class_t);"}, {"sha": "784bf205fcaf99b8fc8f1e3a9b635f44a230a749", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -1,3 +1,9 @@\n+2016-06-03  Bernd Schmidt  <bschmidt@redhat.com>\n+\n+        PR tree-optimization/52171\n+        * gcc.dg/pr52171.c: New test.\n+        * gcc.target/i386/pr52171.c: New test.\n+\n 2016-06-03  Jan Hubicka  <jh@suse.cz>\n \n \t* g++.dg/tree-ssa/pred-1.C: New testcase"}, {"sha": "45aeff6b8eb12a3a19cd0bef4bb5663694ad5811", "filename": "gcc/testsuite/gcc.dg/pr52171.c", "status": "added", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftestsuite%2Fgcc.dg%2Fpr52171.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftestsuite%2Fgcc.dg%2Fpr52171.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fpr52171.c?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -0,0 +1,12 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2\" } */\n+/* { dg-final { scan-assembler-not \"memcmp\" } } */\n+#include <string.h>\n+struct A { int x; } a, b;\n+\n+extern char s[], t[];\n+\n+int foo ()\n+{\n+  return memcmp (&a, &b, sizeof (struct A)) == 0;\n+}"}, {"sha": "50cc520b60c62719624ff701b2801cf49589c180", "filename": "gcc/testsuite/gcc.target/i386/pr52171.c", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr52171.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr52171.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr52171.c?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -0,0 +1,23 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2\" } */\n+/* { dg-final { scan-assembler-not \"memcmp\" } } */\n+/* { dg-final { scan-assembler \"1752394086\" } } */\n+\n+/* This should turn into four compare/jump pairs with -m32, within the\n+   limit of what the tuning considers acceptable for -O2.  */\n+int cmp (char *p, char *q)\n+{\n+  char *pa = __builtin_assume_aligned (p, 4);\n+  char *qa = __builtin_assume_aligned (q, 4);\n+  if (__builtin_memcmp (pa, qa, 16) != 0)\n+    return 1;\n+  return 0;\n+}\n+/* Since we have fast unaligned access, we should make a single\n+   constant comparison.  The constant becomes 1752394086.  */\n+int cmp2 (char *p)\n+{\n+  if (__builtin_memcmp (p, \"fish\", 4) != 0)\n+    return 1;\n+  return 0;\n+}"}, {"sha": "5e2d7dbe7b1178b4067ac619e4f5f3f1ba60e28f", "filename": "gcc/tree-ssa-strlen.c", "status": "modified", "additions": 87, "deletions": 0, "changes": 87, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftree-ssa-strlen.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftree-ssa-strlen.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-strlen.c?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -44,6 +44,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"params.h\"\n #include \"ipa-chkp.h\"\n #include \"tree-hash-traits.h\"\n+#include \"builtins.h\"\n \n /* A vector indexed by SSA_NAME_VERSION.  0 means unknown, positive value\n    is an index into strinfo vector, negative value stands for\n@@ -1843,6 +1844,88 @@ handle_builtin_memset (gimple_stmt_iterator *gsi)\n   return false;\n }\n \n+/* Handle a call to memcmp.  We try to handle small comparisons by\n+   converting them to load and compare, and replacing the call to memcmp\n+   with a __builtin_memcmp_eq call where possible.  */\n+\n+static bool\n+handle_builtin_memcmp (gimple_stmt_iterator *gsi)\n+{\n+  gcall *stmt2 = as_a <gcall *> (gsi_stmt (*gsi));\n+  tree res = gimple_call_lhs (stmt2);\n+  tree arg1 = gimple_call_arg (stmt2, 0);\n+  tree arg2 = gimple_call_arg (stmt2, 1);\n+  tree len = gimple_call_arg (stmt2, 2);\n+  unsigned HOST_WIDE_INT leni;\n+  use_operand_p use_p;\n+  imm_use_iterator iter;\n+\n+  if (!res)\n+    return true;\n+\n+  FOR_EACH_IMM_USE_FAST (use_p, iter, res)\n+    {\n+      gimple *ustmt = USE_STMT (use_p);\n+\n+      if (gimple_code (ustmt) == GIMPLE_ASSIGN)\n+\t{\n+\t  gassign *asgn = as_a <gassign *> (ustmt);\n+\t  tree_code code = gimple_assign_rhs_code (asgn);\n+\t  if ((code != EQ_EXPR && code != NE_EXPR)\n+\t      || !integer_zerop (gimple_assign_rhs2 (asgn)))\n+\t    return true;\n+\t}\n+      else if (gimple_code (ustmt) == GIMPLE_COND)\n+\t{\n+\t  tree_code code = gimple_cond_code (ustmt);\n+\t  if ((code != EQ_EXPR && code != NE_EXPR)\n+\t      || !integer_zerop (gimple_cond_rhs (ustmt)))\n+\t    return true;\n+\t}\n+      else\n+\treturn true;\n+    }\n+\n+  if (tree_fits_uhwi_p (len)\n+      && (leni = tree_to_uhwi (len)) <= GET_MODE_SIZE (word_mode)\n+      && exact_log2 (leni) != -1)\n+    {\n+      leni *= CHAR_TYPE_SIZE;\n+      unsigned align1 = get_pointer_alignment (arg1);\n+      unsigned align2 = get_pointer_alignment (arg2);\n+      unsigned align = MIN (align1, align2);\n+      machine_mode mode = mode_for_size (leni, MODE_INT, 1);\n+      if (mode != BLKmode\n+\t  && (align >= leni || !SLOW_UNALIGNED_ACCESS (mode, align)))\n+\t{\n+\t  location_t loc = gimple_location (stmt2);\n+\t  tree type, off;\n+\t  type = build_nonstandard_integer_type (leni, 1);\n+\t  gcc_assert (GET_MODE_BITSIZE (TYPE_MODE (type)) == leni);\n+\t  tree ptrtype = build_pointer_type_for_mode (char_type_node,\n+\t\t\t\t\t\t      ptr_mode, true);\n+\t  off = build_int_cst (ptrtype, 0);\n+\t  arg1 = build2_loc (loc, MEM_REF, type, arg1, off);\n+\t  arg2 = build2_loc (loc, MEM_REF, type, arg2, off);\n+\t  tree tem1 = fold_const_aggregate_ref (arg1);\n+\t  if (tem1)\n+\t    arg1 = tem1;\n+\t  tree tem2 = fold_const_aggregate_ref (arg2);\n+\t  if (tem2)\n+\t    arg2 = tem2;\n+\t  res = fold_convert_loc (loc, TREE_TYPE (res),\n+\t\t\t\t  fold_build2_loc (loc, NE_EXPR,\n+\t\t\t\t\t\t   boolean_type_node,\n+\t\t\t\t\t\t   arg1, arg2));\n+\t  gimplify_and_update_call_from_tree (gsi, res);\n+\t  return false;\n+\t}\n+    }\n+\n+  gimple_call_set_fndecl (stmt2, builtin_decl_explicit (BUILT_IN_MEMCMP_EQ));\n+  return false;\n+}\n+\n /* Handle a POINTER_PLUS_EXPR statement.\n    For p = \"abcd\" + 2; compute associated length, or if\n    p = q + off is pointing to a '\\0' character of a string, call\n@@ -2100,6 +2183,10 @@ strlen_optimize_stmt (gimple_stmt_iterator *gsi)\n \t    if (!handle_builtin_memset (gsi))\n \t      return false;\n \t    break;\n+\t  case BUILT_IN_MEMCMP:\n+\t    if (!handle_builtin_memcmp (gsi))\n+\t      return false;\n+\t    break;\n \t  default:\n \t    break;\n \t  }"}, {"sha": "2e01eac6acacb44ec31b794830948f8cc293270b", "filename": "gcc/tree.c", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36b85e432865a312aa8edc8978e38266e8a0f14c/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=36b85e432865a312aa8edc8978e38266e8a0f14c", "patch": "@@ -10601,6 +10601,13 @@ build_common_builtin_nodes (void)\n \t\t\tBUILT_IN_STACK_RESTORE,\n \t\t\t\"__builtin_stack_restore\", ECF_NOTHROW | ECF_LEAF);\n \n+  ftype = build_function_type_list (integer_type_node, const_ptr_type_node,\n+\t\t\t\t    const_ptr_type_node, size_type_node,\n+\t\t\t\t    NULL_TREE);\n+  local_define_builtin (\"__builtin_memcmp_eq\", ftype, BUILT_IN_MEMCMP_EQ,\n+\t\t\t\"__builtin_memcmp_eq\",\n+\t\t\tECF_PURE | ECF_NOTHROW | ECF_LEAF);\n+\n   /* If there's a possibility that we might use the ARM EABI, build the\n     alternate __cxa_end_cleanup node used to resume from C++ and Java.  */\n   if (targetm.arm_eabi_unwinder)"}]}