{"sha": "dc808df68ad8864d5d9e9ff7df501d8277e6da8b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZGM4MDhkZjY4YWQ4ODY0ZDVkOWU5ZmY3ZGY1MDFkODI3N2U2ZGE4Yg==", "commit": {"author": {"name": "Alexandre Oliva", "email": "aoliva@redhat.com", "date": "2007-04-05T18:50:34Z"}, "committer": {"name": "Alexandre Oliva", "email": "aoliva@gcc.gnu.org", "date": "2007-04-05T18:50:34Z"}, "message": "re PR middle-end/22156 (bit-field copying regressed)\n\nPR middle-end/22156\n* tree-sra.c (struct sra_elt): Add in_bitfld_block.  Remove\nall_no_warning.\n(struct sra_walk_fns): Remove use_all parameter from use.\n(sra_hash_tree): Handle BIT_FIELD_REFs.\n(sra_elt_hash): Don't hash bitfld blocks.\n(sra_elt_eq): Skip them in parent compares as well.  Handle\nBIT_FIELD_REFs.\n(sra_walk_expr): Don't maintain or pass down use_all_p.\n(scan_use): Remove use_all parameter.\n(scalarize_use): Likewise.  Re-expand assignment to\nBIT_FIELD_REF of gimple_reg.  De-scalarize before input or\noutput, and re-scalarize after output.  Don't mark anything\nfor no warning.\n(scalarize_ldst): Adjust.\n(scalarize_walk_gimple_modify_statement): Likewise.\n(build_element_name_1): Handle BIT_FIELD_REFs.\n(instantiate_element): Don't warn for any element whose parent\nis used as a whole.\n(instantiate_missing_elements_1): Return the sra_elt.\n(canon_type_for_field): New.\n(try_instantiate_multiple_fields): New.\n(instantiate_missing_elemnts): Use them.\n(mark_no_warning): Removed.\n(generate_one_element_ref): Handle BIT_FIELD_REFs.\n(REPLDUP, sra_build_elt_assignment): New.\n(generate_copy_inout): Use them.\n(generate_element_copy): Likewise.  Handle bitfld differences.\n(generate_element_zero): Don't recurse for blocks.  Use\nsra_build_elt_assignment.\n(generate_one_element_int): Take elt instead of var.  Use\nsra_build_elt_assignment.\n(generate_element_init_1): Adjust.\n(scalarize_use, scalarize_copy): Use REPLDUP.\n(scalarize_ldst): Move assert before dereference.\n(dump_sra_elt_name): Handle BIT_FIELD_REFs.\n\nFrom-SVN: r123524", "tree": {"sha": "f71b3ed74f78953c54cfd297e8eaa10395a94836", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f71b3ed74f78953c54cfd297e8eaa10395a94836"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/dc808df68ad8864d5d9e9ff7df501d8277e6da8b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/dc808df68ad8864d5d9e9ff7df501d8277e6da8b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/dc808df68ad8864d5d9e9ff7df501d8277e6da8b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/dc808df68ad8864d5d9e9ff7df501d8277e6da8b/comments", "author": null, "committer": null, "parents": [{"sha": "21f7aaa4967a82493d5be7878469d2ab3dba2212", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/21f7aaa4967a82493d5be7878469d2ab3dba2212", "html_url": "https://github.com/Rust-GCC/gccrs/commit/21f7aaa4967a82493d5be7878469d2ab3dba2212"}], "stats": {"total": 622, "additions": 562, "deletions": 60}, "files": [{"sha": "330c180590a1e65fe6a9e7ee6118e9249ece5e19", "filename": "gcc/ChangeLog", "status": "modified", "additions": 39, "deletions": 0, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/dc808df68ad8864d5d9e9ff7df501d8277e6da8b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/dc808df68ad8864d5d9e9ff7df501d8277e6da8b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=dc808df68ad8864d5d9e9ff7df501d8277e6da8b", "patch": "@@ -1,3 +1,42 @@\n+2007-04-05  Alexandre Oliva  <aoliva@redhat.com>\n+\n+\tPR middle-end/22156\n+\t* tree-sra.c (struct sra_elt): Add in_bitfld_block.  Remove\n+\tall_no_warning.\n+\t(struct sra_walk_fns): Remove use_all parameter from use.\n+\t(sra_hash_tree): Handle BIT_FIELD_REFs.\n+\t(sra_elt_hash): Don't hash bitfld blocks.\n+\t(sra_elt_eq): Skip them in parent compares as well.  Handle\n+\tBIT_FIELD_REFs.\n+\t(sra_walk_expr): Don't maintain or pass down use_all_p.\n+\t(scan_use): Remove use_all parameter.\n+\t(scalarize_use): Likewise.  Re-expand assignment to\n+\tBIT_FIELD_REF of gimple_reg.  De-scalarize before input or\n+\toutput, and re-scalarize after output.  Don't mark anything\n+\tfor no warning.\n+\t(scalarize_ldst): Adjust.\n+\t(scalarize_walk_gimple_modify_statement): Likewise.\n+\t(build_element_name_1): Handle BIT_FIELD_REFs.\n+\t(instantiate_element): Don't warn for any element whose parent\n+\tis used as a whole.\n+\t(instantiate_missing_elements_1): Return the sra_elt.\n+\t(canon_type_for_field): New.\n+\t(try_instantiate_multiple_fields): New.\n+\t(instantiate_missing_elemnts): Use them.\n+\t(mark_no_warning): Removed.\n+\t(generate_one_element_ref): Handle BIT_FIELD_REFs.\n+\t(REPLDUP, sra_build_elt_assignment): New.\n+\t(generate_copy_inout): Use them.\n+\t(generate_element_copy): Likewise.  Handle bitfld differences.\n+\t(generate_element_zero): Don't recurse for blocks.  Use\n+\tsra_build_elt_assignment.\n+\t(generate_one_element_int): Take elt instead of var.  Use\n+\tsra_build_elt_assignment.\n+\t(generate_element_init_1): Adjust.\n+\t(scalarize_use, scalarize_copy): Use REPLDUP.\n+\t(scalarize_ldst): Move assert before dereference.\n+\t(dump_sra_elt_name): Handle BIT_FIELD_REFs.\n+\n 2007-04-05  Steven Bosscher  <steven@gcc.gnu.org>\n \n \t* regmove.c: Fix unused variable warnings due to previous commit."}, {"sha": "a73f22d69fce0d99aebbb24a2f45a6fa570ac9bf", "filename": "gcc/tree-sra.c", "status": "modified", "additions": 523, "deletions": 60, "changes": 583, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/dc808df68ad8864d5d9e9ff7df501d8277e6da8b/gcc%2Ftree-sra.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/dc808df68ad8864d5d9e9ff7df501d8277e6da8b/gcc%2Ftree-sra.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-sra.c?ref=dc808df68ad8864d5d9e9ff7df501d8277e6da8b", "patch": "@@ -147,6 +147,10 @@ struct sra_elt\n \n   /* True if there is BIT_FIELD_REF on the lhs with a vector. */\n   bool is_vector_lhs;\n+\n+  /* 1 if the element is a field that is part of a block, 2 if the field\n+     is the block itself, 0 if it's neither.  */\n+  char in_bitfld_block;\n };\n \n #define IS_ELEMENT_FOR_GROUP(ELEMENT) (TREE_CODE (ELEMENT) == RANGE_EXPR)\n@@ -461,6 +465,12 @@ sra_hash_tree (tree t)\n       h = iterative_hash_expr (DECL_FIELD_BIT_OFFSET (t), h);\n       break;\n \n+    case BIT_FIELD_REF:\n+      /* Don't take operand 0 into account, that's our parent.  */\n+      h = iterative_hash_expr (TREE_OPERAND (t, 1), 0);\n+      h = iterative_hash_expr (TREE_OPERAND (t, 2), h);\n+      break;\n+\n     default:\n       gcc_unreachable ();\n     }\n@@ -479,12 +489,14 @@ sra_elt_hash (const void *x)\n \n   h = sra_hash_tree (e->element);\n \n-  /* Take into account everything back up the chain.  Given that chain\n-     lengths are rarely very long, this should be acceptable.  If we\n-     truly identify this as a performance problem, it should work to\n-     hash the pointer value \"e->parent\".  */\n+  /* Take into account everything except bitfield blocks back up the\n+     chain.  Given that chain lengths are rarely very long, this\n+     should be acceptable.  If we truly identify this as a performance\n+     problem, it should work to hash the pointer value\n+     \"e->parent\".  */\n   for (p = e->parent; p ; p = p->parent)\n-    h = (h * 65521) ^ sra_hash_tree (p->element);\n+    if (!p->in_bitfld_block)\n+      h = (h * 65521) ^ sra_hash_tree (p->element);\n \n   return h;\n }\n@@ -497,8 +509,17 @@ sra_elt_eq (const void *x, const void *y)\n   const struct sra_elt *a = x;\n   const struct sra_elt *b = y;\n   tree ae, be;\n+  const struct sra_elt *ap = a->parent;\n+  const struct sra_elt *bp = b->parent;\n \n-  if (a->parent != b->parent)\n+  if (ap)\n+    while (ap->in_bitfld_block)\n+      ap = ap->parent;\n+  if (bp)\n+    while (bp->in_bitfld_block)\n+      bp = bp->parent;\n+\n+  if (ap != bp)\n     return false;\n \n   ae = a->element;\n@@ -533,6 +554,11 @@ sra_elt_eq (const void *x, const void *y)\n \treturn false;\n       return fields_compatible_p (ae, be);\n \n+    case BIT_FIELD_REF:\n+      return\n+\ttree_int_cst_equal (TREE_OPERAND (ae, 1), TREE_OPERAND (be, 1))\n+\t&& tree_int_cst_equal (TREE_OPERAND (ae, 2), TREE_OPERAND (be, 2));\n+\n     default:\n       gcc_unreachable ();\n     }\n@@ -671,10 +697,9 @@ struct sra_walk_fns\n   /* Invoked when ELT is required as a unit.  Note that ELT might refer to\n      a leaf node, in which case this is a simple scalar reference.  *EXPR_P\n      points to the location of the expression.  IS_OUTPUT is true if this\n-     is a left-hand-side reference.  USE_ALL is true if we saw something we\n-     couldn't quite identify and had to force the use of the entire object.  */\n+     is a left-hand-side reference.  */\n   void (*use) (struct sra_elt *elt, tree *expr_p,\n-\t       block_stmt_iterator *bsi, bool is_output, bool use_all);\n+\t       block_stmt_iterator *bsi, bool is_output);\n \n   /* Invoked when we have a copy between two scalarizable references.  */\n   void (*copy) (struct sra_elt *lhs_elt, struct sra_elt *rhs_elt,\n@@ -728,7 +753,6 @@ sra_walk_expr (tree *expr_p, block_stmt_iterator *bsi, bool is_output,\n   tree expr = *expr_p;\n   tree inner = expr;\n   bool disable_scalarization = false;\n-  bool use_all_p = false;\n \n   /* We're looking to collect a reference expression between EXPR and INNER,\n      such that INNER is a scalarizable decl and all other nodes through EXPR\n@@ -749,7 +773,7 @@ sra_walk_expr (tree *expr_p, block_stmt_iterator *bsi, bool is_output,\n \t    if (disable_scalarization)\n \t      elt->cannot_scalarize = true;\n \t    else\n-\t      fns->use (elt, expr_p, bsi, is_output, use_all_p);\n+\t      fns->use (elt, expr_p, bsi, is_output);\n \t  }\n \treturn;\n \n@@ -836,7 +860,6 @@ sra_walk_expr (tree *expr_p, block_stmt_iterator *bsi, bool is_output,\n       use_all:\n         expr_p = &TREE_OPERAND (inner, 0);\n \tinner = expr = *expr_p;\n-\tuse_all_p = true;\n \tbreak;\n \n       default:\n@@ -884,11 +907,14 @@ sra_walk_asm_expr (tree expr, block_stmt_iterator *bsi,\n   sra_walk_tree_list (ASM_OUTPUTS (expr), bsi, true, fns);\n }\n \n+static void sra_replace (block_stmt_iterator *bsi, tree list);\n+static tree sra_build_elt_assignment (struct sra_elt *elt, tree src);\n+\n /* Walk a GIMPLE_MODIFY_STMT and categorize the assignment appropriately.  */\n \n static void\n sra_walk_gimple_modify_stmt (tree expr, block_stmt_iterator *bsi,\n-\t\t      const struct sra_walk_fns *fns)\n+\t\t\t     const struct sra_walk_fns *fns)\n {\n   struct sra_elt *lhs_elt, *rhs_elt;\n   tree lhs, rhs;\n@@ -911,7 +937,7 @@ sra_walk_gimple_modify_stmt (tree expr, block_stmt_iterator *bsi,\n       if (!rhs_elt->is_scalar && !TREE_SIDE_EFFECTS (lhs))\n \tfns->ldst (rhs_elt, lhs, bsi, false);\n       else\n-\tfns->use (rhs_elt, &GIMPLE_STMT_OPERAND (expr, 1), bsi, false, false);\n+\tfns->use (rhs_elt, &GIMPLE_STMT_OPERAND (expr, 1), bsi, false);\n     }\n \n   /* If it isn't scalarizable, there may be scalarizable variables within, so\n@@ -958,7 +984,9 @@ sra_walk_gimple_modify_stmt (tree expr, block_stmt_iterator *bsi,\n       /* Otherwise we're being used in some context that requires the\n \t aggregate to be seen as a whole.  Invoke USE.  */\n       else\n-\tfns->use (lhs_elt, &GIMPLE_STMT_OPERAND (expr, 0), bsi, true, false);\n+\t{\n+\t  fns->use (lhs_elt, &GIMPLE_STMT_OPERAND (expr, 0), bsi, true);\n+\t}\n     }\n \n   /* Similarly to above, LHS_ELT being null only means that the LHS as a\n@@ -1069,7 +1097,7 @@ find_candidates_for_sra (void)\n static void\n scan_use (struct sra_elt *elt, tree *expr_p ATTRIBUTE_UNUSED,\n \t  block_stmt_iterator *bsi ATTRIBUTE_UNUSED,\n-\t  bool is_output ATTRIBUTE_UNUSED, bool use_all ATTRIBUTE_UNUSED)\n+\t  bool is_output ATTRIBUTE_UNUSED)\n {\n   elt->n_uses += 1;\n }\n@@ -1177,6 +1205,15 @@ build_element_name_1 (struct sra_elt *elt)\n       sprintf (buffer, HOST_WIDE_INT_PRINT_DEC, TREE_INT_CST_LOW (t));\n       obstack_grow (&sra_obstack, buffer, strlen (buffer));\n     }\n+  else if (TREE_CODE (t) == BIT_FIELD_REF)\n+    {\n+      sprintf (buffer, \"B\" HOST_WIDE_INT_PRINT_DEC,\n+\t       tree_low_cst (TREE_OPERAND (t, 2), 1));\n+      obstack_grow (&sra_obstack, buffer, strlen (buffer));\n+      sprintf (buffer, \"F\" HOST_WIDE_INT_PRINT_DEC,\n+\t       tree_low_cst (TREE_OPERAND (t, 1), 1));\n+      obstack_grow (&sra_obstack, buffer, strlen (buffer));\n+    }\n   else\n     {\n       tree name = DECL_NAME (t);\n@@ -1209,9 +1246,12 @@ instantiate_element (struct sra_elt *elt)\n {\n   struct sra_elt *base_elt;\n   tree var, base;\n+  bool nowarn = TREE_NO_WARNING (elt->element);\n \n   for (base_elt = elt; base_elt->parent; base_elt = base_elt->parent)\n-    continue;\n+    if (!nowarn)\n+      nowarn = base_elt->parent->n_uses\n+\t|| TREE_NO_WARNING (base_elt->parent->element);\n   base = base_elt->element;\n \n   elt->replacement = var = make_rename_temp (elt->type, \"SR\");\n@@ -1240,9 +1280,7 @@ instantiate_element (struct sra_elt *elt)\n       DECL_DEBUG_EXPR_IS_FROM (var) = 1;\n       \n       DECL_IGNORED_P (var) = 0;\n-      TREE_NO_WARNING (var) = TREE_NO_WARNING (base);\n-      if (elt->element && TREE_NO_WARNING (elt->element))\n-\tTREE_NO_WARNING (var) = 1;\n+      TREE_NO_WARNING (var) = nowarn;\n     }\n   else\n     {\n@@ -1337,7 +1375,7 @@ sum_instantiated_sizes (struct sra_elt *elt, unsigned HOST_WIDE_INT *sizep)\n \n static void instantiate_missing_elements (struct sra_elt *elt);\n \n-static void\n+static struct sra_elt *\n instantiate_missing_elements_1 (struct sra_elt *elt, tree child, tree type)\n {\n   struct sra_elt *sub = lookup_element (elt, child, type, INSERT);\n@@ -1348,6 +1386,262 @@ instantiate_missing_elements_1 (struct sra_elt *elt, tree child, tree type)\n     }\n   else\n     instantiate_missing_elements (sub);\n+  return sub;\n+}\n+\n+/* Obtain the canonical type for field F of ELEMENT.  */\n+\n+static tree\n+canon_type_for_field (tree f, tree element)\n+{\n+  tree field_type = TREE_TYPE (f);\n+\n+  /* canonicalize_component_ref() unwidens some bit-field types (not\n+     marked as DECL_BIT_FIELD in C++), so we must do the same, lest we\n+     may introduce type mismatches.  */\n+  if (INTEGRAL_TYPE_P (field_type)\n+      && DECL_MODE (f) != TYPE_MODE (field_type))\n+    field_type = TREE_TYPE (get_unwidened (build3 (COMPONENT_REF,\n+\t\t\t\t\t\t   field_type,\n+\t\t\t\t\t\t   element,\n+\t\t\t\t\t\t   f, NULL_TREE),\n+\t\t\t\t\t   NULL_TREE));\n+\n+  return field_type;\n+}\n+\n+/* Look for adjacent fields of ELT starting at F that we'd like to\n+   scalarize as a single variable.  Return the last field of the\n+   group.  */\n+\n+static tree\n+try_instantiate_multiple_fields (struct sra_elt *elt, tree f)\n+{\n+  unsigned HOST_WIDE_INT align, oalign, word, bit, size, alchk;\n+  enum machine_mode mode;\n+  tree first = f, prev;\n+  tree type, var;\n+  struct sra_elt *block;\n+\n+  if (!is_sra_scalar_type (TREE_TYPE (f))\n+      || !host_integerp (DECL_FIELD_OFFSET (f), 1)\n+      || !host_integerp (DECL_FIELD_BIT_OFFSET (f), 1)\n+      || !host_integerp (DECL_SIZE (f), 1)\n+      || lookup_element (elt, f, NULL, NO_INSERT))\n+    return f;\n+\n+  /* Taking the alignment of elt->element is not enough, since it\n+     might be just an array index or some such.  */\n+  for (block = elt; block; block = block->parent)\n+    if (DECL_P (block->element))\n+      {\n+\talign = DECL_ALIGN (block->element);\n+\tbreak;\n+      }\n+  gcc_assert (block);\n+\n+  oalign = DECL_OFFSET_ALIGN (f);\n+  word = tree_low_cst (DECL_FIELD_OFFSET (f), 1);\n+  bit = tree_low_cst (DECL_FIELD_BIT_OFFSET (f), 1);\n+  size = tree_low_cst (DECL_SIZE (f), 1);\n+\n+  if (align > oalign)\n+    align = oalign;\n+\n+  alchk = align - 1;\n+  alchk = ~alchk;\n+\n+  if ((bit & alchk) != ((bit + size - 1) & alchk))\n+    return f;\n+\n+  /* Find adjacent fields in the same alignment word.  */\n+\n+  for (prev = f, f = TREE_CHAIN (f);\n+       f && TREE_CODE (f) == FIELD_DECL\n+\t && is_sra_scalar_type (TREE_TYPE (f))\n+\t && host_integerp (DECL_FIELD_OFFSET (f), 1)\n+\t && host_integerp (DECL_FIELD_BIT_OFFSET (f), 1)\n+\t && host_integerp (DECL_SIZE (f), 1)\n+\t && (HOST_WIDE_INT)word == tree_low_cst (DECL_FIELD_OFFSET (f), 1)\n+\t && !lookup_element (elt, f, NULL, NO_INSERT);\n+       prev = f, f = TREE_CHAIN (f))\n+    {\n+      unsigned HOST_WIDE_INT nbit, nsize;\n+\n+      nbit = tree_low_cst (DECL_FIELD_BIT_OFFSET (f), 1);\n+      nsize = tree_low_cst (DECL_SIZE (f), 1);\n+\n+      if (bit + size == nbit)\n+\t{\n+\t  if ((bit & alchk) != ((nbit + nsize - 1) & alchk))\n+\t    break;\n+\t  size += nsize;\n+\t}\n+      else if (nbit + nsize == bit)\n+\t{\n+\t  if ((nbit & alchk) != ((bit + size - 1) & alchk))\n+\t    break;\n+\t  bit = nbit;\n+\t  size += nsize;\n+\t}\n+      else\n+\tbreak;\n+    }\n+\n+  f = prev;\n+\n+  if (f == first)\n+    return f;\n+\n+  gcc_assert ((bit & alchk) == ((bit + size - 1) & alchk));\n+\n+  /* Try to widen the bit range so as to cover padding bits as well.  */\n+\n+  if ((bit & ~alchk) || size != align)\n+    {\n+      unsigned HOST_WIDE_INT mbit = bit & alchk;\n+      unsigned HOST_WIDE_INT msize = align;\n+\n+      for (f = TYPE_FIELDS (elt->type);\n+\t   f; f = TREE_CHAIN (f))\n+\t{\n+\t  unsigned HOST_WIDE_INT fword, fbit, fsize;\n+\n+\t  /* Skip the fields from first to prev.  */\n+\t  if (f == first)\n+\t    {\n+\t      f = prev;\n+\t      continue;\n+\t    }\n+\n+\t  if (!(TREE_CODE (f) == FIELD_DECL\n+\t\t&& host_integerp (DECL_FIELD_OFFSET (f), 1)\n+\t\t&& host_integerp (DECL_FIELD_BIT_OFFSET (f), 1)))\n+\t    continue;\n+\n+\t  fword = tree_low_cst (DECL_FIELD_OFFSET (f), 1);\n+\t  /* If we're past the selected word, we're fine.  */\n+\t  if (word < fword)\n+\t    continue;\n+\n+\t  fbit = tree_low_cst (DECL_FIELD_BIT_OFFSET (f), 1);\n+\n+\t  if (host_integerp (DECL_SIZE (f), 1))\n+\t    fsize = tree_low_cst (DECL_SIZE (f), 1);\n+\t  else\n+\t    /* Assume a variable-sized field takes up all space till\n+\t       the end of the word.  ??? Endianness issues?  */\n+\t    fsize = align - fbit;\n+\n+\t  if (fword < word)\n+\t    {\n+\t      /* A large field might start at a previous word and\n+\t\t extend into the selected word.  Exclude those\n+\t\t bits.  ??? Endianness issues? */\n+\t      HOST_WIDE_INT diff = fbit + fsize\n+\t\t- (HOST_WIDE_INT)((word - fword) * BITS_PER_UNIT + mbit);\n+\n+\t      if (diff <= 0)\n+\t\tcontinue;\n+\n+\t      mbit += diff;\n+\t      msize -= diff;\n+\t    }\n+\t  else\n+\t    {\n+\t      gcc_assert (fword == word);\n+\n+\t      /* Non-overlapping, great.  */\n+\t      if (fbit + fsize <= mbit\n+\t\t  || mbit + msize <= fbit)\n+\t\tcontinue;\n+\n+\t      if (fbit <= mbit)\n+\t\t{\n+\t\t  unsigned HOST_WIDE_INT diff = fbit + fsize - mbit;\n+\t\t  mbit += diff;\n+\t\t  msize -= diff;\n+\t\t}\n+\t      else if (fbit > mbit)\n+\t\tmsize -= (mbit + msize - fbit);\n+\t      else\n+\t\tgcc_unreachable ();\n+\t    }\n+\t}\n+\n+      bit = mbit;\n+      size = msize;\n+    }\n+\n+  /* Now we know the bit range we're interested in.  Find the smallest\n+     machine mode we can use to access it.  */\n+\n+  for (mode = smallest_mode_for_size (size, MODE_INT);\n+       ;\n+       mode = GET_MODE_WIDER_MODE (mode))\n+    {\n+      gcc_assert (mode != VOIDmode);\n+\n+      alchk = GET_MODE_PRECISION (mode) - 1;\n+      alchk = ~alchk;\n+\n+      if ((bit & alchk) == ((bit + size - 1) & alchk))\n+\tbreak;\n+    }\n+\n+  gcc_assert (~alchk < align);\n+\n+  /* Create the field group as a single variable.  */\n+\n+  type = lang_hooks.types.type_for_mode (mode, 1);\n+  gcc_assert (type);\n+  var = build3 (BIT_FIELD_REF, type, NULL_TREE,\n+\t\tbitsize_int (size),\n+\t\tbitsize_int (word * BITS_PER_UNIT + bit));\n+  BIT_FIELD_REF_UNSIGNED (var) = 1;\n+\n+  block = instantiate_missing_elements_1 (elt, var, type);\n+  gcc_assert (block && block->is_scalar);\n+\n+  var = block->replacement;\n+\n+  if (((word * BITS_PER_UNIT + bit) & ~alchk)\n+      || (HOST_WIDE_INT)size != tree_low_cst (DECL_SIZE (var), 1))\n+    {\n+      block->replacement = build3 (BIT_FIELD_REF,\n+\t\t\t\t   TREE_TYPE (block->element), var,\n+\t\t\t\t   bitsize_int (size),\n+\t\t\t\t   bitsize_int ((word * BITS_PER_UNIT\n+\t\t\t\t\t\t + bit) & ~alchk));\n+      BIT_FIELD_REF_UNSIGNED (block->replacement) = 1;\n+      TREE_NO_WARNING (block->replacement) = 1;\n+    }\n+\n+  block->in_bitfld_block = 2;\n+\n+  /* Add the member fields to the group, such that they access\n+     portions of the group variable.  */\n+\n+  for (f = first; f != TREE_CHAIN (prev); f = TREE_CHAIN (f))\n+    {\n+      tree field_type = canon_type_for_field (f, elt->element);\n+      struct sra_elt *fld = lookup_element (block, f, field_type, INSERT);\n+\n+      gcc_assert (fld && fld->is_scalar && !fld->replacement);\n+\n+      fld->replacement = build3 (BIT_FIELD_REF, field_type, var,\n+\t\t\t\t DECL_SIZE (f),\n+\t\t\t\t bitsize_int\n+\t\t\t\t ((word * BITS_PER_UNIT\n+\t\t\t\t   + (TREE_INT_CST_LOW\n+\t\t\t\t      (DECL_FIELD_BIT_OFFSET (f))))\n+\t\t\t\t  & ~alchk));\n+      BIT_FIELD_REF_UNSIGNED (fld->replacement) = TYPE_UNSIGNED (field_type);\n+      TREE_NO_WARNING (block->replacement) = 1;\n+      fld->in_bitfld_block = 1;\n+    }\n+\n+  return prev;\n }\n \n static void\n@@ -1363,21 +1657,17 @@ instantiate_missing_elements (struct sra_elt *elt)\n \tfor (f = TYPE_FIELDS (type); f ; f = TREE_CHAIN (f))\n \t  if (TREE_CODE (f) == FIELD_DECL)\n \t    {\n-\t      tree field_type = TREE_TYPE (f);\n-\n-\t      /* canonicalize_component_ref() unwidens some bit-field\n-\t\t types (not marked as DECL_BIT_FIELD in C++), so we\n-\t\t must do the same, lest we may introduce type\n-\t\t mismatches.  */\n-\t      if (INTEGRAL_TYPE_P (field_type)\n-\t\t  && DECL_MODE (f) != TYPE_MODE (field_type))\n-\t\tfield_type = TREE_TYPE (get_unwidened (build3 (COMPONENT_REF,\n-\t\t\t\t\t\t\t       field_type,\n-\t\t\t\t\t\t\t       elt->element,\n-\t\t\t\t\t\t\t       f, NULL_TREE),\n-\t\t\t\t\t\t       NULL_TREE));\n-\n-\t      instantiate_missing_elements_1 (elt, f, field_type);\n+\t      tree last = try_instantiate_multiple_fields (elt, f);\n+\n+\t      if (last != f)\n+\t\t{\n+\t\t  f = last;\n+\t\t  continue;\n+\t\t}\n+\n+\t      instantiate_missing_elements_1 (elt, f,\n+\t\t\t\t\t      canon_type_for_field\n+\t\t\t\t\t      (f, elt->element));\n \t    }\n \tbreak;\n       }\n@@ -1689,6 +1979,16 @@ generate_one_element_ref (struct sra_elt *elt, tree base)\n       {\n \ttree field = elt->element;\n \n+\t/* We can't test elt->in_bitfld_blk here because, when this is\n+\t   called from instantiate_element, we haven't set this field\n+\t   yet.  */\n+\tif (TREE_CODE (field) == BIT_FIELD_REF)\n+\t  {\n+\t    tree ret = copy_node (field);\n+\t    TREE_OPERAND (ret, 0) = base;\n+\t    return ret;\n+\t  }\n+\n \t/* Watch out for compatible records with differing field lists.  */\n \tif (DECL_FIELD_CONTEXT (field) != TYPE_MAIN_VARIANT (TREE_TYPE (base)))\n \t  field = find_compatible_field (TREE_TYPE (base), field);\n@@ -1741,6 +2041,126 @@ sra_build_assignment (tree dst, tree src)\n   return build_gimple_modify_stmt (dst, src);\n }\n \n+/* BIT_FIELD_REFs must not be shared.  sra_build_elt_assignment()\n+   takes care of assignments, but we must create copies for uses.  */\n+#define REPLDUP(t) (TREE_CODE (t) != BIT_FIELD_REF ? (t) : copy_node (t))\n+\n+static tree\n+sra_build_elt_assignment (struct sra_elt *elt, tree src)\n+{\n+  tree dst = elt->replacement;\n+  tree var, type, tmp, tmp2, tmp3;\n+  tree list, stmt;\n+  tree cst, cst2, mask;\n+  tree minshift, maxshift;\n+\n+  if (TREE_CODE (dst) != BIT_FIELD_REF\n+      || !elt->in_bitfld_block)\n+    return sra_build_assignment (REPLDUP (dst), src);\n+\n+  var = TREE_OPERAND (dst, 0);\n+\n+  /* Try to widen the assignment to the entire variable.\n+     We need the source to be a BIT_FIELD_REF as well, such that, for\n+     BIT_FIELD_REF<d,sz,dp> = BIT_FIELD_REF<s,sz,sp>,\n+     if sp >= dp, we can turn it into\n+     d = BIT_FIELD_REF<s,sp+sz,sp-dp>.  */\n+  if (elt->in_bitfld_block == 2\n+      && TREE_CODE (src) == BIT_FIELD_REF\n+      && !tree_int_cst_lt (TREE_OPERAND (src, 2), TREE_OPERAND (dst, 2)))\n+    {\n+      src = fold_build3 (BIT_FIELD_REF, TREE_TYPE (var),\n+\t\t\t TREE_OPERAND (src, 0),\n+\t\t\t size_binop (PLUS_EXPR, TREE_OPERAND (src, 1),\n+\t\t\t\t     TREE_OPERAND (dst, 2)),\n+\t\t\t size_binop (MINUS_EXPR, TREE_OPERAND (src, 2),\n+\t\t\t\t     TREE_OPERAND (dst, 2)));\n+      BIT_FIELD_REF_UNSIGNED (src) = 1;\n+\n+      return sra_build_assignment (var, src);\n+    }\n+\n+  if (!is_gimple_reg (var))\n+    return sra_build_assignment (REPLDUP (dst), src);\n+\n+  list = alloc_stmt_list ();\n+\n+  cst = TREE_OPERAND (dst, 2);\n+  if (WORDS_BIG_ENDIAN)\n+    {\n+      cst = size_binop (MINUS_EXPR, DECL_SIZE (var), cst);\n+      maxshift = cst;\n+    }\n+  else\n+    minshift = cst;\n+\n+  cst2 = size_binop (PLUS_EXPR, TREE_OPERAND (dst, 1),\n+\t\t     TREE_OPERAND (dst, 2));\n+  if (WORDS_BIG_ENDIAN)\n+    {\n+      cst2 = size_binop (MINUS_EXPR, DECL_SIZE (var), cst2);\n+      minshift = cst2;\n+    }\n+  else\n+    maxshift = cst2;\n+\n+  type = TREE_TYPE (var);\n+\n+  mask = build_int_cst_wide (type, 1, 0);\n+  cst = int_const_binop (LSHIFT_EXPR, mask, maxshift, 1);\n+  cst2 = int_const_binop (LSHIFT_EXPR, mask, minshift, 1);\n+  mask = int_const_binop (MINUS_EXPR, cst, cst2, 1);\n+  mask = fold_build1 (BIT_NOT_EXPR, type, mask);\n+\n+  if (!WORDS_BIG_ENDIAN)\n+    cst2 = TREE_OPERAND (dst, 2);\n+\n+  tmp = make_rename_temp (type, \"SR\");\n+  stmt = build_gimple_modify_stmt (tmp,\n+\t\t\t\t   fold_build2 (BIT_AND_EXPR, type,\n+\t\t\t\t\t\tvar, mask));\n+  append_to_statement_list (stmt, &list);\n+\n+  if (is_gimple_reg (src))\n+    tmp2 = src;\n+  else\n+    {\n+      tmp2 = make_rename_temp (TREE_TYPE (src), \"SR\");\n+      stmt = sra_build_assignment (tmp2, src);\n+      append_to_statement_list (stmt, &list);\n+    }\n+\n+  if (!TYPE_UNSIGNED (TREE_TYPE (tmp2))\n+      || TYPE_MAIN_VARIANT (TREE_TYPE (tmp2)) != TYPE_MAIN_VARIANT (type))\n+    {\n+      tmp3 = make_rename_temp (type, \"SR\");\n+      tmp2 = fold_build3 (BIT_FIELD_REF, type, tmp2, TREE_OPERAND (dst, 1),\n+\t\t\t  bitsize_int (0));\n+      if (TREE_CODE (tmp2) == BIT_FIELD_REF)\n+\tBIT_FIELD_REF_UNSIGNED (tmp2) = 1;\n+      stmt = sra_build_assignment (tmp3, tmp2);\n+      append_to_statement_list (stmt, &list);\n+      tmp2 = tmp3;\n+    }\n+\n+  if (!integer_zerop (minshift))\n+    {\n+      tmp3 = make_rename_temp (type, \"SR\");\n+      stmt = build_gimple_modify_stmt (tmp3,\n+\t\t\t\t       fold_build2 (LSHIFT_EXPR, type,\n+\t\t\t\t\t\t    tmp2, minshift));\n+      append_to_statement_list (stmt, &list);\n+      tmp2 = tmp3;\n+    }\n+\n+  stmt = build_gimple_modify_stmt (var,\n+\t\t\t\t   fold_build2 (BIT_IOR_EXPR, type,\n+\t\t\t\t\t\ttmp, tmp2));\n+  append_to_statement_list (stmt, &list);\n+\n+  return list;\n+}\n+\n /* Generate a set of assignment statements in *LIST_P to copy all\n    instantiated elements under ELT to or from the equivalent structure\n    rooted at EXPR.  COPY_OUT controls the direction of the copy, with\n@@ -1771,9 +2191,9 @@ generate_copy_inout (struct sra_elt *elt, bool copy_out, tree expr,\n   else if (elt->replacement)\n     {\n       if (copy_out)\n-\tt = sra_build_assignment (elt->replacement, expr);\n+\tt = sra_build_elt_assignment (elt, expr);\n       else\n-\tt = sra_build_assignment (expr, elt->replacement);\n+\tt = sra_build_assignment (expr, REPLDUP (elt->replacement));\n       append_to_statement_list (t, list_p);\n     }\n   else\n@@ -1798,6 +2218,19 @@ generate_element_copy (struct sra_elt *dst, struct sra_elt *src, tree *list_p)\n   FOR_EACH_ACTUAL_CHILD (dc, dst)\n     {\n       sc = lookup_element (src, dc->element, NULL, NO_INSERT);\n+      if (!sc && dc->in_bitfld_block == 2)\n+\t{\n+\t  struct sra_elt *dcs;\n+\n+\t  FOR_EACH_ACTUAL_CHILD (dcs, dc)\n+\t    {\n+\t      sc = lookup_element (src, dcs->element, NULL, NO_INSERT);\n+\t      gcc_assert (sc);\n+\t      generate_element_copy (dcs, sc, list_p);\n+\t    }\n+\n+\t  continue;\n+\t}\n       gcc_assert (sc);\n       generate_element_copy (dc, sc, list_p);\n     }\n@@ -1808,7 +2241,7 @@ generate_element_copy (struct sra_elt *dst, struct sra_elt *src, tree *list_p)\n \n       gcc_assert (src->replacement);\n \n-      t = sra_build_assignment (dst->replacement, src->replacement);\n+      t = sra_build_elt_assignment (dst, REPLDUP (src->replacement));\n       append_to_statement_list (t, list_p);\n     }\n }\n@@ -1829,8 +2262,9 @@ generate_element_zero (struct sra_elt *elt, tree *list_p)\n       return;\n     }\n \n-  FOR_EACH_ACTUAL_CHILD (c, elt)\n-    generate_element_zero (c, list_p);\n+  if (!elt->in_bitfld_block)\n+    FOR_EACH_ACTUAL_CHILD (c, elt)\n+      generate_element_zero (c, list_p);\n \n   if (elt->replacement)\n     {\n@@ -1839,7 +2273,7 @@ generate_element_zero (struct sra_elt *elt, tree *list_p)\n       gcc_assert (elt->is_scalar);\n       t = fold_convert (elt->type, integer_zero_node);\n \n-      t = sra_build_assignment (elt->replacement, t);\n+      t = sra_build_elt_assignment (elt, t);\n       append_to_statement_list (t, list_p);\n     }\n }\n@@ -1848,10 +2282,10 @@ generate_element_zero (struct sra_elt *elt, tree *list_p)\n    Add the result to *LIST_P.  */\n \n static void\n-generate_one_element_init (tree var, tree init, tree *list_p)\n+generate_one_element_init (struct sra_elt *elt, tree init, tree *list_p)\n {\n   /* The replacement can be almost arbitrarily complex.  Gimplify.  */\n-  tree stmt = sra_build_assignment (var, init);\n+  tree stmt = sra_build_elt_assignment (elt, init);\n   gimplify_and_add (stmt, list_p);\n }\n \n@@ -1880,7 +2314,7 @@ generate_element_init_1 (struct sra_elt *elt, tree init, tree *list_p)\n     {\n       if (elt->replacement)\n \t{\n-\t  generate_one_element_init (elt->replacement, init, list_p);\n+\t  generate_one_element_init (elt, init, list_p);\n \t  elt->visited = true;\n \t}\n       return result;\n@@ -2039,7 +2473,7 @@ sra_replace (block_stmt_iterator *bsi, tree list)\n \n static void\n scalarize_use (struct sra_elt *elt, tree *expr_p, block_stmt_iterator *bsi,\n-\t       bool is_output, bool use_all)\n+\t       bool is_output)\n {\n   tree list = NULL, stmt = bsi_stmt (*bsi);\n \n@@ -2048,8 +2482,27 @@ scalarize_use (struct sra_elt *elt, tree *expr_p, block_stmt_iterator *bsi,\n       /* If we have a replacement, then updating the reference is as\n \t simple as modifying the existing statement in place.  */\n       if (is_output)\n-\tmark_all_v_defs (stmt);\n-      *expr_p = elt->replacement;\n+\t{\n+\t  if (TREE_CODE (elt->replacement) == BIT_FIELD_REF\n+\t      && is_gimple_reg (TREE_OPERAND (elt->replacement, 0))\n+\t      && TREE_CODE (stmt) == GIMPLE_MODIFY_STMT\n+\t      && &GIMPLE_STMT_OPERAND (stmt, 0) == expr_p)\n+\t    {\n+\t      tree newstmt = sra_build_elt_assignment\n+\t\t(elt, GIMPLE_STMT_OPERAND (stmt, 1));\n+\t      if (TREE_CODE (newstmt) != STATEMENT_LIST)\n+\t\t{\n+\t\t  tree list = alloc_stmt_list ();\n+\t\t  append_to_statement_list (newstmt, &list);\n+\t\t  newstmt = list;\n+\t\t}\n+\t      sra_replace (bsi, newstmt);\n+\t      return;\n+\t    }\n+\n+\t  mark_all_v_defs (stmt);\n+\t}\n+      *expr_p = REPLDUP (elt->replacement);\n       update_stmt (stmt);\n     }\n   else\n@@ -2067,17 +2520,23 @@ scalarize_use (struct sra_elt *elt, tree *expr_p, block_stmt_iterator *bsi,\n \t This optimization would be most effective if sra_walk_function\n \t processed the blocks in dominator order.  */\n \n-      generate_copy_inout (elt, is_output, generate_element_ref (elt), &list);\n-      if (list == NULL)\n-\treturn;\n-      mark_all_v_defs (list);\n-      if (is_output)\n-\tsra_insert_after (bsi, list);\n-      else\n+      generate_copy_inout (elt, false, generate_element_ref (elt), &list);\n+      if (list)\n \t{\n+\t  mark_all_v_defs (list);\n \t  sra_insert_before (bsi, list);\n-\t  if (use_all)\n-\t    mark_no_warning (elt);\n+\t  mark_no_warning (elt);\n+\t}\n+\n+      if (is_output)\n+\t{\n+\t  list = NULL;\n+\t  generate_copy_inout (elt, true, generate_element_ref (elt), &list);\n+\t  if (list)\n+\t    {\n+\t      mark_all_v_defs (list);\n+\t      sra_insert_after (bsi, list);\n+\t    }\n \t}\n     }\n }\n@@ -2101,7 +2560,7 @@ scalarize_copy (struct sra_elt *lhs_elt, struct sra_elt *rhs_elt,\n       gcc_assert (TREE_CODE (stmt) == GIMPLE_MODIFY_STMT);\n \n       GIMPLE_STMT_OPERAND (stmt, 0) = lhs_elt->replacement;\n-      GIMPLE_STMT_OPERAND (stmt, 1) = rhs_elt->replacement;\n+      GIMPLE_STMT_OPERAND (stmt, 1) = REPLDUP (rhs_elt->replacement);\n       update_stmt (stmt);\n     }\n   else if (lhs_elt->use_block_copy || rhs_elt->use_block_copy)\n@@ -2243,7 +2702,7 @@ scalarize_ldst (struct sra_elt *elt, tree other,\n     {\n       /* Since ELT is not fully instantiated, we have to leave the\n \t block copy in place.  Treat this as a USE.  */\n-      scalarize_use (elt, NULL, bsi, is_output, false);\n+      scalarize_use (elt, NULL, bsi, is_output);\n     }\n   else\n     {\n@@ -2255,8 +2714,8 @@ scalarize_ldst (struct sra_elt *elt, tree other,\n \n       mark_all_v_defs (stmt);\n       generate_copy_inout (elt, is_output, other, &list);\n-      mark_all_v_defs (list);\n       gcc_assert (list);\n+      mark_all_v_defs (list);\n \n       /* Preserve EH semantics.  */\n       if (stmt_ends_bb_p (stmt))\n@@ -2352,6 +2811,10 @@ dump_sra_elt_name (FILE *f, struct sra_elt *elt)\n \t    fputc ('.', f);\n \t  print_generic_expr (f, elt->element, dump_flags);\n \t}\n+      else if (TREE_CODE (elt->element) == BIT_FIELD_REF)\n+\tfprintf (f, \"$B\" HOST_WIDE_INT_PRINT_DEC \"F\" HOST_WIDE_INT_PRINT_DEC,\n+\t\t tree_low_cst (TREE_OPERAND (elt->element, 2), 1),\n+\t\t tree_low_cst (TREE_OPERAND (elt->element, 1), 1));\n       else if (TREE_CODE (elt->element) == RANGE_EXPR)\n \tfprintf (f, \"[\"HOST_WIDE_INT_PRINT_DEC\"..\"HOST_WIDE_INT_PRINT_DEC\"]\",\n \t\t TREE_INT_CST_LOW (TREE_OPERAND (elt->element, 0)),"}]}