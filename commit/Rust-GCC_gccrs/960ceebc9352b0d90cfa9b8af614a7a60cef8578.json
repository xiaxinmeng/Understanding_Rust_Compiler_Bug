{"sha": "960ceebc9352b0d90cfa9b8af614a7a60cef8578", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTYwY2VlYmM5MzUyYjBkOTBjZmE5YjhhZjYxNGE3YTYwY2VmODU3OA==", "commit": {"author": {"name": "Alan Lawrence", "email": "alan.lawrence@arm.com", "date": "2014-11-17T18:29:49Z"}, "committer": {"name": "Alan Lawrence", "email": "alalaw01@gcc.gnu.org", "date": "2014-11-17T18:29:49Z"}, "message": "[AArch64] Extend aarch64_simd_vec_set pattern, replace asm for vld1_lane\n\ngcc/:\n \n\t* config/aarch64/aarch64-simd.md (aarch64_simd_vec_set<mode>): Add\n\tvariant reading from memory and assembling to ld1.\n\n\t* config/aarch64/arm_neon.h (vld1_lane_f32, vld1_lane_f64, vld1_lane_p8,\n\tvld1_lane_p16, vld1_lane_s8, vld1_lane_s16, vld1_lane_s32,\n\tvld1_lane_s64, vld1_lane_u8, vld1_lane_u16, vld1_lane_u32,\n\tvld1_lane_u64, vld1q_lane_f32, vld1q_lane_f64, vld1q_lane_p8,\n\tvld1q_lane_p16, vld1q_lane_s8, vld1q_lane_s16, vld1q_lane_s32,\n\tvld1q_lane_s64, vld1q_lane_u8, vld1q_lane_u16, vld1q_lane_u32,\n\tvld1q_lane_u64): Replace asm with vset_lane and pointer dereference.\n\ngcc/testsuite/:\n \n\t* gcc.target/aarch64/vld1_lane.c: New test.\n\nFrom-SVN: r217665", "tree": {"sha": "4d3cf3fd8e60d50d3359b991be4fb2398137bcab", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4d3cf3fd8e60d50d3359b991be4fb2398137bcab"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/960ceebc9352b0d90cfa9b8af614a7a60cef8578", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/960ceebc9352b0d90cfa9b8af614a7a60cef8578", "html_url": "https://github.com/Rust-GCC/gccrs/commit/960ceebc9352b0d90cfa9b8af614a7a60cef8578", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/960ceebc9352b0d90cfa9b8af614a7a60cef8578/comments", "author": null, "committer": null, "parents": [{"sha": "e6b021859d9ca64b8a9f1bcfda8b8f6319be7d71", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e6b021859d9ca64b8a9f1bcfda8b8f6319be7d71", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e6b021859d9ca64b8a9f1bcfda8b8f6319be7d71"}], "stats": {"total": 576, "additions": 258, "deletions": 318}, "files": [{"sha": "e1d68dea336333c6590bd9449875daac8c29e55c", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=960ceebc9352b0d90cfa9b8af614a7a60cef8578", "patch": "@@ -1,3 +1,16 @@\n+2014-11-17  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\t* config/aarch64/aarch64-simd.md (aarch64_simd_vec_set<mode>): Add\n+\tvariant reading from memory and assembling to ld1.\n+\n+\t* config/aarch64/arm_neon.h (vld1_lane_f32, vld1_lane_f64, vld1_lane_p8,\n+\tvld1_lane_p16, vld1_lane_s8, vld1_lane_s16, vld1_lane_s32,\n+\tvld1_lane_s64, vld1_lane_u8, vld1_lane_u16, vld1_lane_u32,\n+\tvld1_lane_u64, vld1q_lane_f32, vld1q_lane_f64, vld1q_lane_p8,\n+\tvld1q_lane_p16, vld1q_lane_s8, vld1q_lane_s16, vld1q_lane_s32,\n+\tvld1q_lane_s64, vld1q_lane_u8, vld1q_lane_u16, vld1q_lane_u32,\n+\tvld1q_lane_u64): Replace asm with vset_lane and pointer dereference.\n+\n 2014-11-17  Jason Merrill  <jason@redhat.com>\n \n \t* tree-inline.c (copy_fn): New."}, {"sha": "43bfec95702d8becdd9ae43f5561d92f6f306e77", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=960ceebc9352b0d90cfa9b8af614a7a60cef8578", "patch": "@@ -455,12 +455,12 @@\n )\n \n (define_insn \"aarch64_simd_vec_set<mode>\"\n-  [(set (match_operand:VQ_S 0 \"register_operand\" \"=w,w\")\n+  [(set (match_operand:VQ_S 0 \"register_operand\" \"=w,w,w\")\n         (vec_merge:VQ_S\n \t    (vec_duplicate:VQ_S\n-\t\t(match_operand:<VEL> 1 \"register_operand\" \"r,w\"))\n-\t    (match_operand:VQ_S 3 \"register_operand\" \"0,0\")\n-\t    (match_operand:SI 2 \"immediate_operand\" \"i,i\")))]\n+\t\t(match_operand:<VEL> 1 \"aarch64_simd_general_operand\" \"r,w,Utv\"))\n+\t    (match_operand:VQ_S 3 \"register_operand\" \"0,0,0\")\n+\t    (match_operand:SI 2 \"immediate_operand\" \"i,i,i\")))]\n   \"TARGET_SIMD\"\n   {\n    int elt = ENDIAN_LANE_N (<MODE>mode, exact_log2 (INTVAL (operands[2])));\n@@ -471,11 +471,13 @@\n \treturn \"ins\\\\t%0.<Vetype>[%p2], %w1\";\n      case 1:\n \treturn \"ins\\\\t%0.<Vetype>[%p2], %1.<Vetype>[0]\";\n+     case 2:\n+        return \"ld1\\\\t{%0.<Vetype>}[%p2], %1\";\n      default:\n \tgcc_unreachable ();\n      }\n   }\n-  [(set_attr \"type\" \"neon_from_gp<q>, neon_ins<q>\")]\n+  [(set_attr \"type\" \"neon_from_gp<q>, neon_ins<q>, neon_load1_1reg<q>\")]\n )\n \n (define_insn \"aarch64_simd_lshr<mode>\""}, {"sha": "86d9a8160e434f97b6895a4ecda6ca127af31a95", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 149, "deletions": 313, "changes": 462, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=960ceebc9352b0d90cfa9b8af614a7a60cef8578", "patch": "@@ -604,7 +604,7 @@ typedef struct poly16x8x4_t\n #define __aarch64_vdupq_laneq_u64(__a, __b) \\\n    __aarch64_vdup_lane_any (u64, q, q, __a, __b)\n \n-/* vset_lane internal macro.  */\n+/* vset_lane and vld1_lane internal macro.  */\n \n #ifdef __AARCH64EB__\n /* For big-endian, GCC's vector indices are the opposite way around\n@@ -6251,162 +6251,6 @@ vld1_dup_u64 (const uint64_t * a)\n   return result;\n }\n \n-#define vld1_lane_f32(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float32x2_t b_ = (b);                                            \\\n-       const float32_t * a_ = (a);                                      \\\n-       float32x2_t result;                                              \\\n-       __asm__ (\"ld1 {%0.s}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_f64(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float64x1_t b_ = (b);                                            \\\n-       const float64_t * a_ = (a);                                      \\\n-       float64x1_t result;                                              \\\n-       __asm__ (\"ld1 {%0.d}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_p8(a, b, c)                                           \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       poly8x8_t b_ = (b);                                              \\\n-       const poly8_t * a_ = (a);                                        \\\n-       poly8x8_t result;                                                \\\n-       __asm__ (\"ld1 {%0.b}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_p16(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       poly16x4_t b_ = (b);                                             \\\n-       const poly16_t * a_ = (a);                                       \\\n-       poly16x4_t result;                                               \\\n-       __asm__ (\"ld1 {%0.h}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_s8(a, b, c)                                           \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int8x8_t b_ = (b);                                               \\\n-       const int8_t * a_ = (a);                                         \\\n-       int8x8_t result;                                                 \\\n-       __asm__ (\"ld1 {%0.b}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_s16(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x4_t b_ = (b);                                              \\\n-       const int16_t * a_ = (a);                                        \\\n-       int16x4_t result;                                                \\\n-       __asm__ (\"ld1 {%0.h}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_s32(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x2_t b_ = (b);                                              \\\n-       const int32_t * a_ = (a);                                        \\\n-       int32x2_t result;                                                \\\n-       __asm__ (\"ld1 {%0.s}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_s64(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int64x1_t b_ = (b);                                              \\\n-       const int64_t * a_ = (a);                                        \\\n-       int64x1_t result;                                                \\\n-       __asm__ (\"ld1 {%0.d}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_u8(a, b, c)                                           \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint8x8_t b_ = (b);                                              \\\n-       const uint8_t * a_ = (a);                                        \\\n-       uint8x8_t result;                                                \\\n-       __asm__ (\"ld1 {%0.b}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_u16(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x4_t b_ = (b);                                             \\\n-       const uint16_t * a_ = (a);                                       \\\n-       uint16x4_t result;                                               \\\n-       __asm__ (\"ld1 {%0.h}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_u32(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x2_t b_ = (b);                                             \\\n-       const uint32_t * a_ = (a);                                       \\\n-       uint32x2_t result;                                               \\\n-       __asm__ (\"ld1 {%0.s}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1_lane_u64(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint64x1_t b_ = (b);                                             \\\n-       const uint64_t * a_ = (a);                                       \\\n-       uint64x1_t result;                                               \\\n-       __asm__ (\"ld1 {%0.d}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\" (c), \"Utv\"(*a_), \"0\"(b_)                          \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vld1q_dup_f32 (const float32_t * a)\n {\n@@ -6539,162 +6383,6 @@ vld1q_dup_u64 (const uint64_t * a)\n   return result;\n }\n \n-#define vld1q_lane_f32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float32x4_t b_ = (b);                                            \\\n-       const float32_t * a_ = (a);                                      \\\n-       float32x4_t result;                                              \\\n-       __asm__ (\"ld1 {%0.s}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_f64(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float64x2_t b_ = (b);                                            \\\n-       const float64_t * a_ = (a);                                      \\\n-       float64x2_t result;                                              \\\n-       __asm__ (\"ld1 {%0.d}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_p8(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       poly8x16_t b_ = (b);                                             \\\n-       const poly8_t * a_ = (a);                                        \\\n-       poly8x16_t result;                                               \\\n-       __asm__ (\"ld1 {%0.b}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_p16(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       poly16x8_t b_ = (b);                                             \\\n-       const poly16_t * a_ = (a);                                       \\\n-       poly16x8_t result;                                               \\\n-       __asm__ (\"ld1 {%0.h}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_s8(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int8x16_t b_ = (b);                                              \\\n-       const int8_t * a_ = (a);                                         \\\n-       int8x16_t result;                                                \\\n-       __asm__ (\"ld1 {%0.b}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_s16(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x8_t b_ = (b);                                              \\\n-       const int16_t * a_ = (a);                                        \\\n-       int16x8_t result;                                                \\\n-       __asm__ (\"ld1 {%0.h}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_s32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x4_t b_ = (b);                                              \\\n-       const int32_t * a_ = (a);                                        \\\n-       int32x4_t result;                                                \\\n-       __asm__ (\"ld1 {%0.s}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_s64(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int64x2_t b_ = (b);                                              \\\n-       const int64_t * a_ = (a);                                        \\\n-       int64x2_t result;                                                \\\n-       __asm__ (\"ld1 {%0.d}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_u8(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint8x16_t b_ = (b);                                             \\\n-       const uint8_t * a_ = (a);                                        \\\n-       uint8x16_t result;                                               \\\n-       __asm__ (\"ld1 {%0.b}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_u16(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x8_t b_ = (b);                                             \\\n-       const uint16_t * a_ = (a);                                       \\\n-       uint16x8_t result;                                               \\\n-       __asm__ (\"ld1 {%0.h}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_u32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x4_t b_ = (b);                                             \\\n-       const uint32_t * a_ = (a);                                       \\\n-       uint32x4_t result;                                               \\\n-       __asm__ (\"ld1 {%0.s}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vld1q_lane_u64(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint64x2_t b_ = (b);                                             \\\n-       const uint64_t * a_ = (a);                                       \\\n-       uint64x2_t result;                                               \\\n-       __asm__ (\"ld1 {%0.d}[%1], %2\"                                    \\\n-                : \"=w\"(result)                                          \\\n-                : \"i\"(c), \"Utv\"(*a_), \"0\"(b_)                           \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmla_n_f32 (float32x2_t a, float32x2_t b, float32_t c)\n {\n@@ -16430,6 +16118,154 @@ vld1q_u64 (const uint64_t *a)\n     __builtin_aarch64_ld1v2di ((const __builtin_aarch64_simd_di *) a);\n }\n \n+/* vld1_lane  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vld1_lane_f32 (const float32_t *__src, float32x2_t __vec, const int __lane)\n+{\n+  return vset_lane_f32 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vld1_lane_f64 (const float64_t *__src, float64x1_t __vec, const int __lane)\n+{\n+  return vset_lane_f64 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vld1_lane_p8 (const poly8_t *__src, poly8x8_t __vec, const int __lane)\n+{\n+  return vset_lane_p8 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n+vld1_lane_p16 (const poly16_t *__src, poly16x4_t __vec, const int __lane)\n+{\n+  return vset_lane_p16 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vld1_lane_s8 (const int8_t *__src, int8x8_t __vec, const int __lane)\n+{\n+  return vset_lane_s8 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vld1_lane_s16 (const int16_t *__src, int16x4_t __vec, const int __lane)\n+{\n+  return vset_lane_s16 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vld1_lane_s32 (const int32_t *__src, int32x2_t __vec, const int __lane)\n+{\n+  return vset_lane_s32 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n+vld1_lane_s64 (const int64_t *__src, int64x1_t __vec, const int __lane)\n+{\n+  return vset_lane_s64 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vld1_lane_u8 (const uint8_t *__src, uint8x8_t __vec, const int __lane)\n+{\n+  return vset_lane_u8 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vld1_lane_u16 (const uint16_t *__src, uint16x4_t __vec, const int __lane)\n+{\n+  return vset_lane_u16 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vld1_lane_u32 (const uint32_t *__src, uint32x2_t __vec, const int __lane)\n+{\n+  return vset_lane_u32 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n+vld1_lane_u64 (const uint64_t *__src, uint64x1_t __vec, const int __lane)\n+{\n+  return vset_lane_u64 (*__src, __vec, __lane);\n+}\n+\n+/* vld1q_lane  */\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vld1q_lane_f32 (const float32_t *__src, float32x4_t __vec, const int __lane)\n+{\n+  return vsetq_lane_f32 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vld1q_lane_f64 (const float64_t *__src, float64x2_t __vec, const int __lane)\n+{\n+  return vsetq_lane_f64 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n+vld1q_lane_p8 (const poly8_t *__src, poly8x16_t __vec, const int __lane)\n+{\n+  return vsetq_lane_p8 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n+vld1q_lane_p16 (const poly16_t *__src, poly16x8_t __vec, const int __lane)\n+{\n+  return vsetq_lane_p16 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vld1q_lane_s8 (const int8_t *__src, int8x16_t __vec, const int __lane)\n+{\n+  return vsetq_lane_s8 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vld1q_lane_s16 (const int16_t *__src, int16x8_t __vec, const int __lane)\n+{\n+  return vsetq_lane_s16 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vld1q_lane_s32 (const int32_t *__src, int32x4_t __vec, const int __lane)\n+{\n+  return vsetq_lane_s32 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n+vld1q_lane_s64 (const int64_t *__src, int64x2_t __vec, const int __lane)\n+{\n+  return vsetq_lane_s64 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vld1q_lane_u8 (const uint8_t *__src, uint8x16_t __vec, const int __lane)\n+{\n+  return vsetq_lane_u8 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vld1q_lane_u16 (const uint16_t *__src, uint16x8_t __vec, const int __lane)\n+{\n+  return vsetq_lane_u16 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vld1q_lane_u32 (const uint32_t *__src, uint32x4_t __vec, const int __lane)\n+{\n+  return vsetq_lane_u32 (*__src, __vec, __lane);\n+}\n+\n+__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n+vld1q_lane_u64 (const uint64_t *__src, uint64x2_t __vec, const int __lane)\n+{\n+  return vsetq_lane_u64 (*__src, __vec, __lane);\n+}\n+\n /* vldn */\n \n __extension__ static __inline int64x1x2_t __attribute__ ((__always_inline__))"}, {"sha": "e8a7fbc75282aefab04d1b5b68cf0817bf63f997", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=960ceebc9352b0d90cfa9b8af614a7a60cef8578", "patch": "@@ -1,3 +1,7 @@\n+2014-11-17  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\t* gcc.target/aarch64/vld1_lane.c: New test.\n+\n 2014-11-17  Alan Lawrence  <alan.lawrence@arm.com>\n \n \t* gcc.target/aarch64/simd/vfma_f64.c: Add asm volatile memory."}, {"sha": "c2445f8df53034027051722155a40161b86574bb", "filename": "gcc/testsuite/gcc.target/aarch64/vld1_lane.c", "status": "added", "additions": 85, "deletions": 0, "changes": 85, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvld1_lane.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/960ceebc9352b0d90cfa9b8af614a7a60cef8578/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvld1_lane.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvld1_lane.c?ref=960ceebc9352b0d90cfa9b8af614a7a60cef8578", "patch": "@@ -0,0 +1,85 @@\n+/* { dg-do run } */\n+/* { dg-options \"-O3 -fno-inline\" } */\n+\n+#include <arm_neon.h>\n+\n+extern void abort (void);\n+\n+#define VARIANTS(VARIANT)\t\\\n+VARIANT (uint8, , 8, _u8, 5)\t\\\n+VARIANT (uint16, , 4, _u16, 3)\t\\\n+VARIANT (uint32, , 2, _u32, 1)\t\\\n+VARIANT (uint64, , 1, _u64, 0)\t\\\n+VARIANT (int8, , 8, _s8, 3)\t\\\n+VARIANT (int16, , 4, _s16, 2)\t\\\n+VARIANT (int32, , 2, _s32, 0)\t\\\n+VARIANT (int64, , 1, _s64, 0)\t\\\n+VARIANT (poly8, , 8, _p8, 7)\t\\\n+VARIANT (poly16, , 4, _p16, 2)\t\\\n+VARIANT (float32, , 2, _f32, 1)\t\\\n+VARIANT (float64, , 1, _f64, 0)\t\\\n+VARIANT (uint8, q, 16, _u8, 13)\t\\\n+VARIANT (uint16, q, 8, _u16, 5)\t\\\n+VARIANT (uint32, q, 4, _u32, 1)\t\\\n+VARIANT (uint64, q, 2, _u64, 0)\t\\\n+VARIANT (int8, q, 16, _s8, 15)\t\\\n+VARIANT (int16, q, 8, _s16, 3)\t\\\n+VARIANT (int32, q, 4, _s32, 1)\t\\\n+VARIANT (int64, q, 2, _s64, 1)\t\\\n+VARIANT (poly8, q, 16, _p8, 7)\t\\\n+VARIANT (poly16, q, 8, _p16, 4)\t\\\n+VARIANT (float32, q, 4, _f32, 2)\\\n+VARIANT (float64, q, 2, _f64, 1)\n+\n+#define TESTMETH(BASE, Q, ELTS, SUFFIX, LANE)\t\t\t\\\n+__attribute__((noinline)) BASE##x##ELTS##_t\t\t\t\\\n+wrap_vld1##Q##_lane##SUFFIX (const BASE##_t *load,\t\t\\\n+\t\t\t     BASE##x##ELTS##_t vec)\t\t\\\n+{ return vld1##Q##_lane##SUFFIX (load, vec, LANE); }\t\t\\\n+int\t\t\t\t\t\t\t\t\\\n+test_vld1##Q##_lane##SUFFIX (const BASE##_t *data,\t\t\\\n+\t\t\t     const BASE##_t *overwrite)\t\t\\\n+{\t\t\t\t\t\t\t\t\\\n+  BASE##_t out[ELTS];\t\t\t\t\t\t\\\n+  int j;\t\t\t\t\t\t\t\\\n+  BASE##x##ELTS##_t in = vld1##Q##SUFFIX (data);\t\t\\\n+  in = wrap_vld1##Q##_lane##SUFFIX (overwrite, in);\t\t\\\n+  vst1##Q##SUFFIX (out, in);\t\t\t\t\t\\\n+    for (j = 0; j < ELTS; j++)\t\t\t\t\t\\\n+      if (out[j] != (j == LANE ? *overwrite : data[j]))\t\t\\\n+        return 1;\t\t\t\t\t\t\\\n+  return 0;\t\t\t\t\t\t\t\\\n+}\n+\n+\n+VARIANTS (TESTMETH)\n+\n+#define CHECK(BASE, Q, ELTS, SUFFIX, LANE)\t\t\t\\\n+  if (test_vld1##Q##_lane##SUFFIX ((const BASE##_t *)orig_data,\t\\\n+\t\t\t\t   BASE##_data) != 0)\t\\\n+    abort ();\n+\n+int\n+main (int argc, char **argv)\n+{\n+  /* Original data for all vector formats.  */\n+  uint64_t orig_data[2] = {0x1234567890abcdefULL, 0x13579bdf02468aceULL};\n+\n+  /* Data with which vldN_lane will overwrite some of previous.  */\n+  uint8_t uint8_data[4] = { 7, 11, 13, 17 };\n+  uint16_t uint16_data[4] = { 257, 263, 269, 271 };\n+  uint32_t uint32_data[4] = { 65537, 65539, 65543, 65551 };\n+  uint64_t uint64_data[4] = { 0xdeadbeefcafebabeULL, 0x0123456789abcdefULL,\n+\t\t\t      0xfedcba9876543210LL, 0xdeadbabecafebeefLL };\n+  int8_t int8_data[4] = { -1, 3, -5, 7 };\n+  int16_t int16_data[4] = { 257, -259, 261, -263 };\n+  int32_t int32_data[4] = { 123456789, -987654321, -135792468, 975318642 };\n+  int64_t *int64_data = (int64_t *)uint64_data;\n+  poly8_t poly8_data[4] = { 0, 7, 13, 18, };\n+  poly16_t poly16_data[4] = { 11111, 2222, 333, 44 };\n+  float32_t float32_data[4] = { 3.14159, 2.718, 1.414, 100.0 };\n+  float64_t float64_data[4] = { 1.010010001, 12345.6789, -9876.54321, 1.618 };\n+\n+  VARIANTS (CHECK);\n+  return 0;\n+}"}]}