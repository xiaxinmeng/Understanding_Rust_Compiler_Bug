{"sha": "737087cbc8393b1a95a871b15a917872f1328c6b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzM3MDg3Y2JjODM5M2IxYTk1YTg3MWIxNWE5MTc4NzJmMTMyOGM2Yg==", "commit": {"author": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2011-11-28T05:45:49Z"}, "committer": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2011-11-28T05:45:49Z"}, "message": "runtime: Multiplex goroutines onto OS threads.\n\nFrom-SVN: r181772", "tree": {"sha": "af256a0152425084325ad100d75615322c726b8a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/af256a0152425084325ad100d75615322c726b8a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/737087cbc8393b1a95a871b15a917872f1328c6b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/737087cbc8393b1a95a871b15a917872f1328c6b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/737087cbc8393b1a95a871b15a917872f1328c6b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/737087cbc8393b1a95a871b15a917872f1328c6b/comments", "author": null, "committer": null, "parents": [{"sha": "a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a01207c473dcab88eb0ac769d2d9c68d7c9e0588"}], "stats": {"total": 3300, "additions": 2065, "deletions": 1235}, "files": [{"sha": "c30d9c36c2b0ab985c5bb470973595bf74378f1e", "filename": "libgo/Makefile.am", "status": "modified", "additions": 10, "deletions": 5, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2FMakefile.am?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -421,14 +421,11 @@ runtime_files = \\\n \truntime/go-eface-compare.c \\\n \truntime/go-eface-val-compare.c \\\n \truntime/go-getgoroot.c \\\n-\truntime/go-go.c \\\n-\truntime/go-gomaxprocs.c \\\n \truntime/go-int-array-to-string.c \\\n \truntime/go-int-to-string.c \\\n \truntime/go-interface-compare.c \\\n \truntime/go-interface-eface-compare.c \\\n \truntime/go-interface-val-compare.c \\\n-\truntime/go-lock-os-thread.c \\\n \truntime/go-make-slice.c \\\n \truntime/go-map-delete.c \\\n \truntime/go-map-index.c \\\n@@ -451,9 +448,7 @@ runtime_files = \\\n \truntime/go-reflect-map.c \\\n \truntime/go-rune.c \\\n \truntime/go-runtime-error.c \\\n-\truntime/go-sched.c \\\n \truntime/go-select.c \\\n-\truntime/go-semacquire.c \\\n \truntime/go-send-big.c \\\n \truntime/go-send-nb-big.c \\\n \truntime/go-send-nb-small.c \\\n@@ -499,6 +494,8 @@ runtime_files = \\\n \tmap.c \\\n \tmprof.c \\\n \treflect.c \\\n+\truntime1.c \\\n+\tsema.c \\\n \tsigqueue.c \\\n \tstring.c\n \n@@ -520,6 +517,14 @@ reflect.c: $(srcdir)/runtime/reflect.goc goc2c\n \t./goc2c --gcc --go-prefix libgo_reflect $< > $@.tmp\n \tmv -f $@.tmp $@\n \n+runtime1.c: $(srcdir)/runtime/runtime1.goc goc2c\n+\t./goc2c --gcc --go-prefix libgo_runtime $< > $@.tmp\n+\tmv -f $@.tmp $@\n+\n+sema.c: $(srcdir)/runtime/sema.goc goc2c\n+\t./goc2c --gcc --go-prefix libgo_runtime $< > $@.tmp\n+\tmv -f $@.tmp $@\n+\n sigqueue.c: $(srcdir)/runtime/sigqueue.goc goc2c\n \t./goc2c --gcc --go-prefix libgo_runtime $< > $@.tmp\n \tmv -f $@.tmp $@"}, {"sha": "8b6bb7282722de66757c8d81b2973d1579e7ca32", "filename": "libgo/Makefile.in", "status": "modified", "additions": 34, "deletions": 69, "changes": 103, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2FMakefile.in?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -189,25 +189,24 @@ am__libgo_la_SOURCES_DIST = runtime/go-append.c runtime/go-assert.c \\\n \truntime/go-copy.c runtime/go-defer.c \\\n \truntime/go-deferred-recover.c runtime/go-eface-compare.c \\\n \truntime/go-eface-val-compare.c runtime/go-getgoroot.c \\\n-\truntime/go-go.c runtime/go-gomaxprocs.c \\\n \truntime/go-int-array-to-string.c runtime/go-int-to-string.c \\\n \truntime/go-interface-compare.c \\\n \truntime/go-interface-eface-compare.c \\\n-\truntime/go-interface-val-compare.c runtime/go-lock-os-thread.c \\\n-\truntime/go-make-slice.c runtime/go-map-delete.c \\\n-\truntime/go-map-index.c runtime/go-map-len.c \\\n-\truntime/go-map-range.c runtime/go-nanotime.c \\\n-\truntime/go-new-channel.c runtime/go-new-map.c runtime/go-new.c \\\n-\truntime/go-panic.c runtime/go-print.c runtime/go-rec-big.c \\\n+\truntime/go-interface-val-compare.c runtime/go-make-slice.c \\\n+\truntime/go-map-delete.c runtime/go-map-index.c \\\n+\truntime/go-map-len.c runtime/go-map-range.c \\\n+\truntime/go-nanotime.c runtime/go-new-channel.c \\\n+\truntime/go-new-map.c runtime/go-new.c runtime/go-panic.c \\\n+\truntime/go-print.c runtime/go-rec-big.c \\\n \truntime/go-rec-nb-big.c runtime/go-rec-nb-small.c \\\n \truntime/go-rec-small.c runtime/go-recover.c \\\n \truntime/go-reflect.c runtime/go-reflect-call.c \\\n \truntime/go-reflect-chan.c runtime/go-reflect-map.c \\\n \truntime/go-rune.c runtime/go-runtime-error.c \\\n-\truntime/go-sched.c runtime/go-select.c runtime/go-semacquire.c \\\n-\truntime/go-send-big.c runtime/go-send-nb-big.c \\\n-\truntime/go-send-nb-small.c runtime/go-send-small.c \\\n-\truntime/go-setenv.c runtime/go-signal.c runtime/go-strcmp.c \\\n+\truntime/go-select.c runtime/go-send-big.c \\\n+\truntime/go-send-nb-big.c runtime/go-send-nb-small.c \\\n+\truntime/go-send-small.c runtime/go-setenv.c \\\n+\truntime/go-signal.c runtime/go-strcmp.c \\\n \truntime/go-string-to-byte-array.c \\\n \truntime/go-string-to-int-array.c runtime/go-strplus.c \\\n \truntime/go-strslice.c runtime/go-trampoline.c \\\n@@ -224,7 +223,7 @@ am__libgo_la_SOURCES_DIST = runtime/go-append.c runtime/go-assert.c \\\n \truntime/mheap.c runtime/msize.c runtime/proc.c \\\n \truntime/runtime.c runtime/thread.c runtime/yield.c \\\n \truntime/rtems-task-variable-add.c chan.c iface.c malloc.c \\\n-\tmap.c mprof.c reflect.c sigqueue.c string.c\n+\tmap.c mprof.c reflect.c runtime1.c sema.c sigqueue.c string.c\n @LIBGO_IS_LINUX_FALSE@am__objects_1 = lock_sema.lo thread-sema.lo\n @LIBGO_IS_LINUX_TRUE@am__objects_1 = lock_futex.lo thread-linux.lo\n @HAVE_SYS_MMAN_H_FALSE@am__objects_2 = mem_posix_memalign.lo\n@@ -236,19 +235,18 @@ am__objects_4 = go-append.lo go-assert.lo go-assert-interface.lo \\\n \tgo-chan-len.lo go-check-interface.lo go-close.lo \\\n \tgo-construct-map.lo go-convert-interface.lo go-copy.lo \\\n \tgo-defer.lo go-deferred-recover.lo go-eface-compare.lo \\\n-\tgo-eface-val-compare.lo go-getgoroot.lo go-go.lo \\\n-\tgo-gomaxprocs.lo go-int-array-to-string.lo go-int-to-string.lo \\\n+\tgo-eface-val-compare.lo go-getgoroot.lo \\\n+\tgo-int-array-to-string.lo go-int-to-string.lo \\\n \tgo-interface-compare.lo go-interface-eface-compare.lo \\\n-\tgo-interface-val-compare.lo go-lock-os-thread.lo \\\n-\tgo-make-slice.lo go-map-delete.lo go-map-index.lo \\\n-\tgo-map-len.lo go-map-range.lo go-nanotime.lo go-new-channel.lo \\\n-\tgo-new-map.lo go-new.lo go-panic.lo go-print.lo go-rec-big.lo \\\n-\tgo-rec-nb-big.lo go-rec-nb-small.lo go-rec-small.lo \\\n-\tgo-recover.lo go-reflect.lo go-reflect-call.lo \\\n+\tgo-interface-val-compare.lo go-make-slice.lo go-map-delete.lo \\\n+\tgo-map-index.lo go-map-len.lo go-map-range.lo go-nanotime.lo \\\n+\tgo-new-channel.lo go-new-map.lo go-new.lo go-panic.lo \\\n+\tgo-print.lo go-rec-big.lo go-rec-nb-big.lo go-rec-nb-small.lo \\\n+\tgo-rec-small.lo go-recover.lo go-reflect.lo go-reflect-call.lo \\\n \tgo-reflect-chan.lo go-reflect-map.lo go-rune.lo \\\n-\tgo-runtime-error.lo go-sched.lo go-select.lo go-semacquire.lo \\\n-\tgo-send-big.lo go-send-nb-big.lo go-send-nb-small.lo \\\n-\tgo-send-small.lo go-setenv.lo go-signal.lo go-strcmp.lo \\\n+\tgo-runtime-error.lo go-select.lo go-send-big.lo \\\n+\tgo-send-nb-big.lo go-send-nb-small.lo go-send-small.lo \\\n+\tgo-setenv.lo go-signal.lo go-strcmp.lo \\\n \tgo-string-to-byte-array.lo go-string-to-int-array.lo \\\n \tgo-strplus.lo go-strslice.lo go-trampoline.lo go-type-eface.lo \\\n \tgo-type-error.lo go-type-identity.lo go-type-interface.lo \\\n@@ -258,7 +256,7 @@ am__objects_4 = go-append.lo go-assert.lo go-assert-interface.lo \\\n \tmcache.lo mcentral.lo $(am__objects_2) mfinal.lo mfixalloc.lo \\\n \tmgc0.lo mheap.lo msize.lo proc.lo runtime.lo thread.lo \\\n \tyield.lo $(am__objects_3) chan.lo iface.lo malloc.lo map.lo \\\n-\tmprof.lo reflect.lo sigqueue.lo string.lo\n+\tmprof.lo reflect.lo runtime1.lo sema.lo sigqueue.lo string.lo\n am_libgo_la_OBJECTS = $(am__objects_4)\n libgo_la_OBJECTS = $(am_libgo_la_OBJECTS)\n libgo_la_LINK = $(LIBTOOL) --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) \\\n@@ -850,14 +848,11 @@ runtime_files = \\\n \truntime/go-eface-compare.c \\\n \truntime/go-eface-val-compare.c \\\n \truntime/go-getgoroot.c \\\n-\truntime/go-go.c \\\n-\truntime/go-gomaxprocs.c \\\n \truntime/go-int-array-to-string.c \\\n \truntime/go-int-to-string.c \\\n \truntime/go-interface-compare.c \\\n \truntime/go-interface-eface-compare.c \\\n \truntime/go-interface-val-compare.c \\\n-\truntime/go-lock-os-thread.c \\\n \truntime/go-make-slice.c \\\n \truntime/go-map-delete.c \\\n \truntime/go-map-index.c \\\n@@ -880,9 +875,7 @@ runtime_files = \\\n \truntime/go-reflect-map.c \\\n \truntime/go-rune.c \\\n \truntime/go-runtime-error.c \\\n-\truntime/go-sched.c \\\n \truntime/go-select.c \\\n-\truntime/go-semacquire.c \\\n \truntime/go-send-big.c \\\n \truntime/go-send-nb-big.c \\\n \truntime/go-send-nb-small.c \\\n@@ -928,6 +921,8 @@ runtime_files = \\\n \tmap.c \\\n \tmprof.c \\\n \treflect.c \\\n+\truntime1.c \\\n+\tsema.c \\\n \tsigqueue.c \\\n \tstring.c\n \n@@ -2476,14 +2471,11 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-eface-compare.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-eface-val-compare.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-getgoroot.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-go.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-gomaxprocs.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-int-array-to-string.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-int-to-string.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-interface-compare.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-interface-eface-compare.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-interface-val-compare.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-lock-os-thread.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-main.Po@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-make-slice.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-map-delete.Plo@am__quote@\n@@ -2507,9 +2499,7 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-reflect.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-rune.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-runtime-error.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-sched.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-select.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-semacquire.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-send-big.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-send-nb-big.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/go-send-nb-small.Plo@am__quote@\n@@ -2553,6 +2543,8 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/reflect.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/rtems-task-variable-add.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/runtime.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/runtime1.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sema.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sigqueue.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/string.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/thread-linux.Plo@am__quote@\n@@ -2735,20 +2727,6 @@ go-getgoroot.lo: runtime/go-getgoroot.c\n @AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n @am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-getgoroot.lo `test -f 'runtime/go-getgoroot.c' || echo '$(srcdir)/'`runtime/go-getgoroot.c\n \n-go-go.lo: runtime/go-go.c\n-@am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-go.lo -MD -MP -MF $(DEPDIR)/go-go.Tpo -c -o go-go.lo `test -f 'runtime/go-go.c' || echo '$(srcdir)/'`runtime/go-go.c\n-@am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-go.Tpo $(DEPDIR)/go-go.Plo\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tsource='runtime/go-go.c' object='go-go.lo' libtool=yes @AMDEPBACKSLASH@\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n-@am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-go.lo `test -f 'runtime/go-go.c' || echo '$(srcdir)/'`runtime/go-go.c\n-\n-go-gomaxprocs.lo: runtime/go-gomaxprocs.c\n-@am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-gomaxprocs.lo -MD -MP -MF $(DEPDIR)/go-gomaxprocs.Tpo -c -o go-gomaxprocs.lo `test -f 'runtime/go-gomaxprocs.c' || echo '$(srcdir)/'`runtime/go-gomaxprocs.c\n-@am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-gomaxprocs.Tpo $(DEPDIR)/go-gomaxprocs.Plo\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tsource='runtime/go-gomaxprocs.c' object='go-gomaxprocs.lo' libtool=yes @AMDEPBACKSLASH@\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n-@am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-gomaxprocs.lo `test -f 'runtime/go-gomaxprocs.c' || echo '$(srcdir)/'`runtime/go-gomaxprocs.c\n-\n go-int-array-to-string.lo: runtime/go-int-array-to-string.c\n @am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-int-array-to-string.lo -MD -MP -MF $(DEPDIR)/go-int-array-to-string.Tpo -c -o go-int-array-to-string.lo `test -f 'runtime/go-int-array-to-string.c' || echo '$(srcdir)/'`runtime/go-int-array-to-string.c\n @am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-int-array-to-string.Tpo $(DEPDIR)/go-int-array-to-string.Plo\n@@ -2784,13 +2762,6 @@ go-interface-val-compare.lo: runtime/go-interface-val-compare.c\n @AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n @am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-interface-val-compare.lo `test -f 'runtime/go-interface-val-compare.c' || echo '$(srcdir)/'`runtime/go-interface-val-compare.c\n \n-go-lock-os-thread.lo: runtime/go-lock-os-thread.c\n-@am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-lock-os-thread.lo -MD -MP -MF $(DEPDIR)/go-lock-os-thread.Tpo -c -o go-lock-os-thread.lo `test -f 'runtime/go-lock-os-thread.c' || echo '$(srcdir)/'`runtime/go-lock-os-thread.c\n-@am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-lock-os-thread.Tpo $(DEPDIR)/go-lock-os-thread.Plo\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tsource='runtime/go-lock-os-thread.c' object='go-lock-os-thread.lo' libtool=yes @AMDEPBACKSLASH@\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n-@am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-lock-os-thread.lo `test -f 'runtime/go-lock-os-thread.c' || echo '$(srcdir)/'`runtime/go-lock-os-thread.c\n-\n go-make-slice.lo: runtime/go-make-slice.c\n @am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-make-slice.lo -MD -MP -MF $(DEPDIR)/go-make-slice.Tpo -c -o go-make-slice.lo `test -f 'runtime/go-make-slice.c' || echo '$(srcdir)/'`runtime/go-make-slice.c\n @am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-make-slice.Tpo $(DEPDIR)/go-make-slice.Plo\n@@ -2945,27 +2916,13 @@ go-runtime-error.lo: runtime/go-runtime-error.c\n @AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n @am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-runtime-error.lo `test -f 'runtime/go-runtime-error.c' || echo '$(srcdir)/'`runtime/go-runtime-error.c\n \n-go-sched.lo: runtime/go-sched.c\n-@am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-sched.lo -MD -MP -MF $(DEPDIR)/go-sched.Tpo -c -o go-sched.lo `test -f 'runtime/go-sched.c' || echo '$(srcdir)/'`runtime/go-sched.c\n-@am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-sched.Tpo $(DEPDIR)/go-sched.Plo\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tsource='runtime/go-sched.c' object='go-sched.lo' libtool=yes @AMDEPBACKSLASH@\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n-@am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-sched.lo `test -f 'runtime/go-sched.c' || echo '$(srcdir)/'`runtime/go-sched.c\n-\n go-select.lo: runtime/go-select.c\n @am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-select.lo -MD -MP -MF $(DEPDIR)/go-select.Tpo -c -o go-select.lo `test -f 'runtime/go-select.c' || echo '$(srcdir)/'`runtime/go-select.c\n @am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-select.Tpo $(DEPDIR)/go-select.Plo\n @AMDEP_TRUE@@am__fastdepCC_FALSE@\tsource='runtime/go-select.c' object='go-select.lo' libtool=yes @AMDEPBACKSLASH@\n @AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n @am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-select.lo `test -f 'runtime/go-select.c' || echo '$(srcdir)/'`runtime/go-select.c\n \n-go-semacquire.lo: runtime/go-semacquire.c\n-@am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-semacquire.lo -MD -MP -MF $(DEPDIR)/go-semacquire.Tpo -c -o go-semacquire.lo `test -f 'runtime/go-semacquire.c' || echo '$(srcdir)/'`runtime/go-semacquire.c\n-@am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-semacquire.Tpo $(DEPDIR)/go-semacquire.Plo\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tsource='runtime/go-semacquire.c' object='go-semacquire.lo' libtool=yes @AMDEPBACKSLASH@\n-@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n-@am__fastdepCC_FALSE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -c -o go-semacquire.lo `test -f 'runtime/go-semacquire.c' || echo '$(srcdir)/'`runtime/go-semacquire.c\n-\n go-send-big.lo: runtime/go-send-big.c\n @am__fastdepCC_TRUE@\t$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS) -MT go-send-big.lo -MD -MP -MF $(DEPDIR)/go-send-big.Tpo -c -o go-send-big.lo `test -f 'runtime/go-send-big.c' || echo '$(srcdir)/'`runtime/go-send-big.c\n @am__fastdepCC_TRUE@\t$(am__mv) $(DEPDIR)/go-send-big.Tpo $(DEPDIR)/go-send-big.Plo\n@@ -4454,6 +4411,14 @@ reflect.c: $(srcdir)/runtime/reflect.goc goc2c\n \t./goc2c --gcc --go-prefix libgo_reflect $< > $@.tmp\n \tmv -f $@.tmp $@\n \n+runtime1.c: $(srcdir)/runtime/runtime1.goc goc2c\n+\t./goc2c --gcc --go-prefix libgo_runtime $< > $@.tmp\n+\tmv -f $@.tmp $@\n+\n+sema.c: $(srcdir)/runtime/sema.goc goc2c\n+\t./goc2c --gcc --go-prefix libgo_runtime $< > $@.tmp\n+\tmv -f $@.tmp $@\n+\n sigqueue.c: $(srcdir)/runtime/sigqueue.goc goc2c\n \t./goc2c --gcc --go-prefix libgo_runtime $< > $@.tmp\n \tmv -f $@.tmp $@"}, {"sha": "49828d94ce35ebbef1a77acb2366b38d7470d07f", "filename": "libgo/go/syscall/mksyscall.awk", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fgo%2Fsyscall%2Fmksyscall.awk", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fgo%2Fsyscall%2Fmksyscall.awk", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fgo%2Fsyscall%2Fmksyscall.awk?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -102,10 +102,6 @@ BEGIN {\n \t   gofnname, gofnparams, gofnresults == \"\" ? \"\" : \"(\", gofnresults,\n \t   gofnresults == \"\" ? \"\" : \")\", gofnresults == \"\" ? \"\" : \" \")\n \n-    if (blocking) {\n-\tprint \"\\tentersyscall()\"\n-    }\n-\n     loc = gofnname \"/\" cfnname \":\"\n \n     split(gofnparams, goargs, \", *\")\n@@ -151,7 +147,8 @@ BEGIN {\n \t\tstatus = 1\n \t\tnext\n \t    }\n-\t    args = args \"StringBytePtr(\" goname \")\"\n+\t    printf(\"\\t_p%d := StringBytePtr(%s)\\n\", goarg, goname)\n+\t    args = sprintf(\"%s_p%d\", args, goarg)\n \t} else if (gotype ~ /^\\[\\](.*)/) {\n \t    if (ctype !~ /^\\*/ || cargs[carg + 1] == \"\") {\n \t\tprint loc, \"bad C type for slice:\", gotype, ctype | \"cat 1>&2\"\n@@ -192,6 +189,10 @@ BEGIN {\n \tnext\n     }\n \n+    if (blocking) {\n+\tprint \"\\tentersyscall()\"\n+    }\n+\n     printf(\"\\t\")\n     if (gofnresults != \"\") {\n \tprintf(\"_r := \")"}, {"sha": "5e3fc99d914b7b224b5e53dd41ad52947ecf9e56", "filename": "libgo/runtime/cpuprof.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fcpuprof.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fcpuprof.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fcpuprof.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -361,9 +361,9 @@ getprofile(Profile *p)\n \t\treturn ret;\n \n \t// Wait for new log.\n-\t// runtime\u00b7entersyscall();\n+\truntime_entersyscall();\n \truntime_notesleep(&p->wait);\n-\t// runtime\u00b7exitsyscall();\n+\truntime_exitsyscall();\n \truntime_noteclear(&p->wait);\n \n \tn = p->handoff;"}, {"sha": "a6df3833c26e5ef5216deafaa4afa309196c97c8", "filename": "libgo/runtime/go-close.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-close.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-close.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-close.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -4,6 +4,7 @@\n    Use of this source code is governed by a BSD-style\n    license that can be found in the LICENSE file.  */\n \n+#include \"runtime.h\"\n #include \"go-assert.h\"\n #include \"go-panic.h\"\n #include \"channel.h\"\n@@ -23,10 +24,7 @@ __go_builtin_close (struct __go_channel *channel)\n   __go_assert (i == 0);\n \n   while (channel->selected_for_send)\n-    {\n-      i = pthread_cond_wait (&channel->cond, &channel->lock);\n-      __go_assert (i == 0);\n-    }\n+    runtime_cond_wait (&channel->cond, &channel->lock);\n \n   if (channel->is_closed)\n     {"}, {"sha": "c27de6ab463c7878c04a270394d45c9daef51c48", "filename": "libgo/runtime/go-defer.c", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-defer.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-defer.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-defer.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -16,8 +16,10 @@\n void\n __go_defer (_Bool *frame, void (*pfn) (void *), void *arg)\n {\n+  G *g;\n   struct __go_defer_stack *n;\n \n+  g = runtime_g ();\n   n = (struct __go_defer_stack *) __go_alloc (sizeof (struct __go_defer_stack));\n   n->__next = g->defer;\n   n->__frame = frame;\n@@ -33,6 +35,9 @@ __go_defer (_Bool *frame, void (*pfn) (void *), void *arg)\n void\n __go_undefer (_Bool *frame)\n {\n+  G *g;\n+\n+  g = runtime_g ();\n   while (g->defer != NULL && g->defer->__frame == frame)\n     {\n       struct __go_defer_stack *d;\n@@ -63,6 +68,9 @@ __go_undefer (_Bool *frame)\n _Bool\n __go_set_defer_retaddr (void *retaddr)\n {\n+  G *g;\n+\n+  g = runtime_g ();\n   if (g->defer != NULL)\n     g->defer->__retaddr = retaddr;\n   return 0;"}, {"sha": "78ef287cf00a05342ec65ac83b4f1ba19fe92971", "filename": "libgo/runtime/go-deferred-recover.c", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-deferred-recover.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-deferred-recover.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-deferred-recover.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -79,6 +79,9 @@\n struct __go_empty_interface\n __go_deferred_recover ()\n {\n+  G *g;\n+\n+  g = runtime_g ();\n   if (g->defer == NULL || g->defer->__panic != g->panic)\n     {\n       struct __go_empty_interface ret;\n@@ -87,5 +90,5 @@ __go_deferred_recover ()\n       ret.__object = NULL;\n       return ret;\n     }\n-  return __go_recover();\n+  return __go_recover ();\n }"}, {"sha": "82b265f964ef748320f274f1df196a0e65fc51c7", "filename": "libgo/runtime/go-go.c", "status": "removed", "additions": 0, "deletions": 668, "changes": 668, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-go.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-go.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-go.c?ref=a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "patch": "@@ -1,668 +0,0 @@\n-/* go-go.c -- the go function.\n-\n-   Copyright 2009 The Go Authors. All rights reserved.\n-   Use of this source code is governed by a BSD-style\n-   license that can be found in the LICENSE file.  */\n-\n-#include <errno.h>\n-#include <limits.h>\n-#include <signal.h>\n-#include <stdint.h>\n-#include <stdlib.h>\n-#include <pthread.h>\n-#include <semaphore.h>\n-\n-#include \"config.h\"\n-#include \"go-assert.h\"\n-#include \"go-panic.h\"\n-#include \"go-alloc.h\"\n-#include \"runtime.h\"\n-#include \"arch.h\"\n-#include \"malloc.h\"\n-\n-#ifdef USING_SPLIT_STACK\n-/* FIXME: This is not declared anywhere.  */\n-extern void *__splitstack_find (void *, void *, size_t *, void **, void **,\n-\t\t\t\tvoid **);\n-#endif\n-\n-/* We stop the threads by sending them the signal GO_SIG_STOP and we\n-   start them by sending them the signal GO_SIG_START.  */\n-\n-#define GO_SIG_START (SIGRTMIN + 1)\n-#define GO_SIG_STOP (SIGRTMIN + 2)\n-\n-#ifndef SA_RESTART\n-  #define SA_RESTART 0\n-#endif\n-\n-/* A doubly linked list of the threads we have started.  */\n-\n-struct __go_thread_id\n-{\n-  /* Links.  */\n-  struct __go_thread_id *prev;\n-  struct __go_thread_id *next;\n-  /* True if the thread ID has not yet been filled in.  */\n-  _Bool tentative;\n-  /* Thread ID.  */\n-  pthread_t id;\n-  /* Thread's M structure.  */\n-  struct M *m;\n-  /* If the thread ID has not been filled in, the function we are\n-     running.  */\n-  void (*pfn) (void *);\n-  /* If the thread ID has not been filled in, the argument to the\n-     function.  */\n-  void *arg;\n-};\n-\n-static struct __go_thread_id *__go_all_thread_ids;\n-\n-/* A lock to control access to ALL_THREAD_IDS.  */\n-\n-static pthread_mutex_t __go_thread_ids_lock = PTHREAD_MUTEX_INITIALIZER;\n-\n-/* A semaphore used to wait until all the threads have stopped.  */\n-\n-static sem_t __go_thread_ready_sem;\n-\n-/* A signal set used to wait until garbage collection is complete.  */\n-\n-static sigset_t __go_thread_wait_sigset;\n-\n-/* Remove the current thread from the list of threads.  */\n-\n-static void\n-remove_current_thread (void *dummy __attribute__ ((unused)))\n-{\n-  struct __go_thread_id *list_entry;\n-  MCache *mcache;\n-  int i;\n-  \n-  list_entry = m->list_entry;\n-  mcache = m->mcache;\n-\n-  i = pthread_mutex_lock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-\n-  if (list_entry->prev != NULL)\n-    list_entry->prev->next = list_entry->next;\n-  else\n-    __go_all_thread_ids = list_entry->next;\n-  if (list_entry->next != NULL)\n-    list_entry->next->prev = list_entry->prev;\n-\n-  /* This will lock runtime_mheap as needed.  */\n-  runtime_MCache_ReleaseAll (mcache);\n-\n-  /* This should never deadlock--there shouldn't be any code that\n-     holds the runtime_mheap lock when locking __go_thread_ids_lock.\n-     We don't want to do this after releasing __go_thread_ids_lock\n-     because it will mean that the garbage collector might run, and\n-     the garbage collector does not try to lock runtime_mheap in all\n-     cases since it knows it is running single-threaded.  */\n-  runtime_lock (&runtime_mheap);\n-  mstats.heap_alloc += mcache->local_alloc;\n-  mstats.heap_objects += mcache->local_objects;\n-  __builtin_memset (mcache, 0, sizeof (struct MCache));\n-  runtime_FixAlloc_Free (&runtime_mheap.cachealloc, mcache);\n-  runtime_unlock (&runtime_mheap);\n-\n-  /* As soon as we release this look, a GC could run.  Since this\n-     thread is no longer on the list, the GC will not find our M\n-     structure, so it could get freed at any time.  That means that\n-     any code from here to thread exit must not assume that m is\n-     valid.  */\n-  m = NULL;\n-  g = NULL;\n-\n-  i = pthread_mutex_unlock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-\n-  free (list_entry);\n-}\n-\n-/* Start the thread.  */\n-\n-static void *\n-start_go_thread (void *thread_arg)\n-{\n-  struct M *newm = (struct M *) thread_arg;\n-  void (*pfn) (void *);\n-  void *arg;\n-  struct __go_thread_id *list_entry;\n-  int i;\n-\n-#ifdef __rtems__\n-  __wrap_rtems_task_variable_add ((void **) &m);\n-  __wrap_rtems_task_variable_add ((void **) &g);\n-#endif\n-\n-  m = newm;\n-  g = m->curg;\n-\n-  pthread_cleanup_push (remove_current_thread, NULL);\n-\n-  list_entry = newm->list_entry;\n-\n-  pfn = list_entry->pfn;\n-  arg = list_entry->arg;\n-\n-#ifndef USING_SPLIT_STACK\n-  /* If we don't support split stack, record the current stack as the\n-     top of the stack.  There shouldn't be anything relevant to the\n-     garbage collector above this point.  */\n-  m->gc_sp = (void *) &arg;\n-#endif\n-\n-  /* Finish up the entry on the thread list.  */\n-\n-  i = pthread_mutex_lock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-\n-  list_entry->id = pthread_self ();\n-  list_entry->pfn = NULL;\n-  list_entry->arg = NULL;\n-  list_entry->tentative = 0;\n-\n-  i = pthread_mutex_unlock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-\n-  (*pfn) (arg);\n-\n-  pthread_cleanup_pop (1);\n-\n-  return NULL;\n-}\n-\n-/* The runtime.Goexit function.  */\n-\n-void Goexit (void) asm (\"libgo_runtime.runtime.Goexit\");\n-\n-void\n-Goexit (void)\n-{\n-  pthread_exit (NULL);\n-  abort ();\n-}\n-\n-/* Count of threads created.  */\n-\n-static volatile int mcount;\n-\n-/* Implement the go statement.  */\n-\n-void\n-__go_go (void (*pfn) (void*), void *arg)\n-{\n-  int i;\n-  pthread_attr_t attr;\n-  struct M *newm;\n-  struct __go_thread_id *list_entry;\n-  pthread_t tid;\n-\n-  i = pthread_attr_init (&attr);\n-  __go_assert (i == 0);\n-  i = pthread_attr_setdetachstate (&attr, PTHREAD_CREATE_DETACHED);\n-  __go_assert (i == 0);\n-\n-#ifdef LINKER_SUPPORTS_SPLIT_STACK\n-  /* The linker knows how to handle calls between code which uses\n-     -fsplit-stack and code which does not.  That means that we can\n-     run with a smaller stack and rely on the -fsplit-stack support to\n-     save us.  The GNU/Linux glibc library won't let us have a very\n-     small stack, but we make it as small as we can.  */\n-#ifndef PTHREAD_STACK_MIN\n-#define PTHREAD_STACK_MIN 8192\n-#endif\n-  i = pthread_attr_setstacksize (&attr, PTHREAD_STACK_MIN);\n-  __go_assert (i == 0);\n-#endif\n-\n-  newm = __go_alloc (sizeof (M));\n-\n-  list_entry = malloc (sizeof (struct __go_thread_id));\n-  list_entry->prev = NULL;\n-  list_entry->next = NULL;\n-  list_entry->tentative = 1;\n-  list_entry->m = newm;\n-  list_entry->pfn = pfn;\n-  list_entry->arg = arg;\n-\n-  newm->list_entry = list_entry;\n-\n-  newm->curg = __go_alloc (sizeof (G));\n-  newm->curg->m = newm;\n-\n-  newm->id = __sync_fetch_and_add (&mcount, 1);\n-  newm->fastrand = 0x49f6428aUL + newm->id;\n-\n-  newm->mcache = runtime_allocmcache ();\n-\n-  /* Add the thread to the list of all threads, marked as tentative\n-     since it is not yet ready to go.  */\n-  i = pthread_mutex_lock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-\n-  if (__go_all_thread_ids != NULL)\n-    __go_all_thread_ids->prev = list_entry;\n-  list_entry->next = __go_all_thread_ids;\n-  __go_all_thread_ids = list_entry;\n-\n-  i = pthread_mutex_unlock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-\n-  /* Start the thread.  */\n-  i = pthread_create (&tid, &attr, start_go_thread, newm);\n-  __go_assert (i == 0);\n-\n-  i = pthread_attr_destroy (&attr);\n-  __go_assert (i == 0);\n-}\n-\n-/* This is the signal handler for GO_SIG_START.  The garbage collector\n-   will send this signal to a thread when it wants the thread to\n-   start.  We don't have to actually do anything here, but we need a\n-   signal handler since ignoring the signal will mean that the\n-   sigsuspend will never see it.  */\n-\n-static void\n-gc_start_handler (int sig __attribute__ ((unused)))\n-{\n-}\n-\n-/* Tell the garbage collector that we are ready, and wait for the\n-   garbage collector to tell us that it is done.  This may be called\n-   by a signal handler, so it is restricted to using functions which\n-   are async cancel safe.  */\n-\n-static void\n-stop_for_gc (void)\n-{\n-  int i;\n-\n-  /* Tell the garbage collector about our stack.  */\n-#ifdef USING_SPLIT_STACK\n-  m->gc_sp = __splitstack_find (NULL, NULL, &m->gc_len,\n-\t\t\t\t&m->gc_next_segment, &m->gc_next_sp,\n-\t\t\t\t&m->gc_initial_sp);\n-#else\n-  {\n-    uintptr_t top = (uintptr_t) m->gc_sp;\n-    uintptr_t bottom = (uintptr_t) &top;\n-    if (top < bottom)\n-      {\n-\tm->gc_next_sp = m->gc_sp;\n-\tm->gc_len = bottom - top;\n-      }\n-    else\n-      {\n-\tm->gc_next_sp = (void *) bottom;\n-\tm->gc_len = top - bottom;\n-      }\n-  }\n-#endif\n-\n-  /* Tell the garbage collector that we are ready by posting to the\n-     semaphore.  */\n-  i = sem_post (&__go_thread_ready_sem);\n-  __go_assert (i == 0);\n-\n-  /* Wait for the garbage collector to tell us to continue.  */\n-  sigsuspend (&__go_thread_wait_sigset);\n-}\n-\n-/* This is the signal handler for GO_SIG_STOP.  The garbage collector\n-   will send this signal to a thread when it wants the thread to\n-   stop.  */\n-\n-static void\n-gc_stop_handler (int sig __attribute__ ((unused)))\n-{\n-  struct M *pm = m;\n-\n-  if (__sync_bool_compare_and_swap (&pm->holds_finlock, 1, 1))\n-    {\n-      /* We can't interrupt the thread while it holds the finalizer\n-\t lock.  Otherwise we can get into a deadlock when mark calls\n-\t runtime_walkfintab.  */\n-      __sync_bool_compare_and_swap (&pm->gcing_for_finlock, 0, 1);\n-      return;\n-    }\n-\n-  if (__sync_bool_compare_and_swap (&pm->mallocing, 1, 1))\n-    {\n-      /* m->mallocing was already non-zero.  We can't interrupt the\n-\t thread while it is running an malloc.  Instead, tell it to\n-\t call back to us when done.  */\n-      __sync_bool_compare_and_swap (&pm->gcing, 0, 1);\n-      return;\n-    }\n-\n-  if (__sync_bool_compare_and_swap (&pm->nomemprof, 1, 1))\n-    {\n-      /* Similarly, we can't interrupt the thread while it is building\n-\t profiling information.  Otherwise we can get into a deadlock\n-\t when sweepspan calls MProf_Free.  */\n-      __sync_bool_compare_and_swap (&pm->gcing_for_prof, 0, 1);\n-      return;\n-    }\n-\n-  stop_for_gc ();\n-}\n-\n-/* This is called by malloc when it gets a signal during the malloc\n-   call itself.  */\n-\n-int\n-__go_run_goroutine_gc (int r)\n-{\n-  /* Force callee-saved registers to be saved on the stack.  This is\n-     not needed if we are invoked from the signal handler, but it is\n-     needed if we are called directly, since otherwise we might miss\n-     something that a function somewhere up the call stack is holding\n-     in a register.  */\n-  __builtin_unwind_init ();\n-\n-  stop_for_gc ();\n-\n-  /* This avoids tail recursion, to make sure that the saved registers\n-     are on the stack.  */\n-  return r;\n-}\n-\n-/* Stop all the other threads for garbage collection.  */\n-\n-void\n-runtime_stoptheworld (void)\n-{\n-  int i;\n-  pthread_t me;\n-  int c;\n-  struct __go_thread_id *p;\n-\n-  i = pthread_mutex_lock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-\n-  me = pthread_self ();\n-  c = 0;\n-  p = __go_all_thread_ids;\n-  while (p != NULL)\n-    {\n-      if (p->tentative || pthread_equal (me, p->id))\n-\tp = p->next;\n-      else\n-\t{\n-\t  i = pthread_kill (p->id, GO_SIG_STOP);\n-\t  if (i == 0)\n-\t    {\n-\t      ++c;\n-\t      p = p->next;\n-\t    }\n-\t  else if (i == ESRCH)\n-\t    {\n-\t      struct __go_thread_id *next;\n-\n-\t      /* This thread died somehow.  Remove it from the\n-\t\t list.  */\n-\t      next = p->next;\n-\t      if (p->prev != NULL)\n-\t\tp->prev->next = next;\n-\t      else\n-\t\t__go_all_thread_ids = next;\n-\t      if (next != NULL)\n-\t\tnext->prev = p->prev;\n-\t      free (p);\n-\t      p = next;\n-\t    }\n-\t  else\n-\t    abort ();\n-\t}\n-    }\n-\n-  /* Wait for each thread to receive the signal and post to the\n-     semaphore.  If a thread receives the signal but contrives to die\n-     before it posts to the semaphore, then we will hang forever\n-     here.  */\n-\n-  while (c > 0)\n-    {\n-      i = sem_wait (&__go_thread_ready_sem);\n-      if (i < 0 && errno == EINTR)\n-\tcontinue;\n-      __go_assert (i == 0);\n-      --c;\n-    }\n-\n-  /* Leave with __go_thread_ids_lock held.  */\n-}\n-\n-/* Scan all the stacks for garbage collection.  This should be called\n-   with __go_thread_ids_lock held.  */\n-\n-void\n-__go_scanstacks (void (*scan) (byte *, int64))\n-{\n-  pthread_t me;\n-  struct __go_thread_id *p;\n-\n-  /* Make sure all the registers for this thread are on the stack.  */\n-  __builtin_unwind_init ();\n-\n-  me = pthread_self ();\n-  for (p = __go_all_thread_ids; p != NULL; p = p->next)\n-    {\n-      if (p->tentative)\n-\t{\n-\t  /* The goroutine function and argument can be allocated on\n-\t     the heap, so we have to scan them for a thread that has\n-\t     not yet started.  */\n-\t  scan ((void *) &p->pfn, sizeof (void *));\n-\t  scan ((void *) &p->arg, sizeof (void *));\n-\t  scan ((void *) &p->m, sizeof (void *));\n-\t  continue;\n-\t}\n-\n-#ifdef USING_SPLIT_STACK\n-\n-      void *sp;\n-      size_t len;\n-      void *next_segment;\n-      void *next_sp;\n-      void *initial_sp;\n-\n-      if (pthread_equal (me, p->id))\n-\t{\n-\t  next_segment = NULL;\n-\t  next_sp = NULL;\n-\t  initial_sp = NULL;\n-\t  sp = __splitstack_find (NULL, NULL, &len, &next_segment,\n-\t\t\t\t  &next_sp, &initial_sp);\n-\t}\n-      else\n-\t{\n-\t  sp = p->m->gc_sp;\n-\t  len = p->m->gc_len;\n-\t  next_segment = p->m->gc_next_segment;\n-\t  next_sp = p->m->gc_next_sp;\n-\t  initial_sp = p->m->gc_initial_sp;\n-\t}\n-\n-      while (sp != NULL)\n-\t{\n-\t  scan (sp, len);\n-\t  sp = __splitstack_find (next_segment, next_sp, &len,\n-\t\t\t\t  &next_segment, &next_sp, &initial_sp);\n-\t}\n-\n-#else /* !defined(USING_SPLIT_STACK) */\n-\n-      if (pthread_equal (me, p->id))\n-\t{\n-\t  uintptr_t top = (uintptr_t) m->gc_sp;\n-\t  uintptr_t bottom = (uintptr_t) &top;\n-\t  if (top < bottom)\n-\t    scan (m->gc_sp, bottom - top);\n-\t  else\n-\t    scan ((void *) bottom, top - bottom);\n-\t}\n-      else\n-\t{\n-\t  scan (p->m->gc_next_sp, p->m->gc_len);\n-\t}\n-\t\n-#endif /* !defined(USING_SPLIT_STACK) */\n-\n-      /* Also scan the M structure while we're at it.  */\n-\n-      scan ((void *) &p->m, sizeof (void *));\n-    }\n-}\n-\n-/* Release all the memory caches.  This is called with\n-   __go_thread_ids_lock held.  */\n-\n-void\n-__go_stealcache (void)\n-{\n-  struct __go_thread_id *p;\n-\n-  for (p = __go_all_thread_ids; p != NULL; p = p->next)\n-    runtime_MCache_ReleaseAll (p->m->mcache);\n-}\n-\n-/* Gather memory cache statistics.  This is called with\n-   __go_thread_ids_lock held.  */\n-\n-void\n-__go_cachestats (void)\n-{\n-  struct __go_thread_id *p;\n-\n-  for (p = __go_all_thread_ids; p != NULL; p = p->next)\n-    {\n-      MCache *c;\n-      int i;\n-\n-      runtime_purgecachedstats(p->m);\n-      c = p->m->mcache;\n-      for (i = 0; i < NumSizeClasses; ++i)\n-\t{\n-\t  mstats.by_size[i].nmalloc += c->local_by_size[i].nmalloc;\n-\t  c->local_by_size[i].nmalloc = 0;\n-\t  mstats.by_size[i].nfree += c->local_by_size[i].nfree;\n-\t  c->local_by_size[i].nfree = 0;\n-\t}\n-    }\n-}\n-\n-/* Start the other threads after garbage collection.  */\n-\n-void\n-runtime_starttheworld (bool extra __attribute__ ((unused)))\n-{\n-  int i;\n-  pthread_t me;\n-  struct __go_thread_id *p;\n-\n-  /* Here __go_thread_ids_lock should be held.  */\n-\n-  me = pthread_self ();\n-  p = __go_all_thread_ids;\n-  while (p != NULL)\n-    {\n-      if (p->tentative || pthread_equal (me, p->id))\n-\tp = p->next;\n-      else\n-\t{\n-\t  i = pthread_kill (p->id, GO_SIG_START);\n-\t  if (i == 0)\n-\t    p = p->next;\n-\t  else\n-\t    abort ();\n-\t}\n-    }\n-\n-  i = pthread_mutex_unlock (&__go_thread_ids_lock);\n-  __go_assert (i == 0);\n-}\n-\n-/* Initialize the interaction between goroutines and the garbage\n-   collector.  */\n-\n-void\n-__go_gc_goroutine_init (void *sp __attribute__ ((unused)))\n-{\n-  struct __go_thread_id *list_entry;\n-  int i;\n-  sigset_t sset;\n-  struct sigaction act;\n-\n-  /* Add the initial thread to the list of all threads.  */\n-\n-  list_entry = malloc (sizeof (struct __go_thread_id));\n-  list_entry->prev = NULL;\n-  list_entry->next = NULL;\n-  list_entry->tentative = 0;\n-  list_entry->id = pthread_self ();\n-  list_entry->m = m;\n-  list_entry->pfn = NULL;\n-  list_entry->arg = NULL;\n-  __go_all_thread_ids = list_entry;\n-\n-  /* Initialize the semaphore which signals when threads are ready for\n-     GC.  */\n-\n-  i = sem_init (&__go_thread_ready_sem, 0, 0);\n-  __go_assert (i == 0);\n-\n-  /* Fetch the current signal mask.  */\n-\n-  i = sigemptyset (&sset);\n-  __go_assert (i == 0);\n-  i = sigprocmask (SIG_BLOCK, NULL, &sset);\n-  __go_assert (i == 0);\n-\n-  /* Make sure that GO_SIG_START is not blocked and GO_SIG_STOP is\n-     blocked, and save that set for use with later calls to sigsuspend\n-     while waiting for GC to complete.  */\n-\n-  i = sigdelset (&sset, GO_SIG_START);\n-  __go_assert (i == 0);\n-  i = sigaddset (&sset, GO_SIG_STOP);\n-  __go_assert (i == 0);\n-  __go_thread_wait_sigset = sset;\n-\n-  /* Block SIG_SET_START and unblock SIG_SET_STOP, and use that for\n-     the process signal mask.  */\n-\n-  i = sigaddset (&sset, GO_SIG_START);\n-  __go_assert (i == 0);\n-  i = sigdelset (&sset, GO_SIG_STOP);\n-  __go_assert (i == 0);\n-  i = sigprocmask (SIG_SETMASK, &sset, NULL);\n-  __go_assert (i == 0);\n-\n-  /* Install the signal handlers.  */\n-  memset (&act, 0, sizeof act);\n-  i = sigemptyset (&act.sa_mask);\n-  __go_assert (i == 0);\n-\n-  act.sa_handler = gc_start_handler;\n-  act.sa_flags = SA_RESTART;\n-  i = sigaction (GO_SIG_START, &act, NULL);\n-  __go_assert (i == 0);\n-\n-  /* We could consider using an alternate signal stack for this.  The\n-     function does not use much stack space, so it may be OK.  */\n-  act.sa_handler = gc_stop_handler;\n-  i = sigaction (GO_SIG_STOP, &act, NULL);\n-  __go_assert (i == 0);\n-\n-#ifndef USING_SPLIT_STACK\n-  /* If we don't support split stack, record the current stack as the\n-     top of the stack.  */\n-  m->gc_sp = sp;\n-#endif\n-}"}, {"sha": "65146c501208ce5f7528e536ef46fcb636f2b245", "filename": "libgo/runtime/go-gomaxprocs.c", "status": "removed", "additions": 0, "deletions": 23, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-gomaxprocs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-gomaxprocs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-gomaxprocs.c?ref=a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "patch": "@@ -1,23 +0,0 @@\n-/* go-gomaxprocs.c -- runtime.GOMAXPROCS.\n-\n-   Copyright 2009 The Go Authors. All rights reserved.\n-   Use of this source code is governed by a BSD-style\n-   license that can be found in the LICENSE file.  */\n-\n-/* This is the runtime.GOMAXPROCS function.  This currently does\n-   nothing, since each goroutine runs in a separate thread anyhow.  */\n-\n-extern int GOMAXPROCS (int) asm (\"libgo_runtime.runtime.GOMAXPROCS\");\n-\n-static int set = 1;\n-\n-int\n-GOMAXPROCS (int n)\n-{\n-  int ret;\n-\n-  ret = set;\n-  if (n > 0)\n-    set = n;\n-  return ret;\n-}"}, {"sha": "204f11dce7cde7a8246a01919be0a75ce490625c", "filename": "libgo/runtime/go-lock-os-thread.c", "status": "removed", "additions": 0, "deletions": 24, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-lock-os-thread.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-lock-os-thread.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-lock-os-thread.c?ref=a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "patch": "@@ -1,24 +0,0 @@\n-/* go-lock-os-thread.c -- the LockOSThread and UnlockOSThread functions.\n-\n-   Copyright 2009 The Go Authors. All rights reserved.\n-   Use of this source code is governed by a BSD-style\n-   license that can be found in the LICENSE file.  */\n-\n-/* The runtime.LockOSThread and runtime.UnlockOSThread functions are\n-   meaningless in the current implementation, since for us a goroutine\n-   always stays on a single OS thread.  */\n-\n-extern void LockOSThread (void) __asm__ (\"libgo_runtime.runtime.LockOSThread\");\n-\n-void\n-LockOSThread (void)\n-{\n-}\n-\n-extern void UnlockOSThread (void)\n-  __asm__ (\"libgo_runtime.runtime.UnlockOSThread\");\n-\n-void\n-UnlockOSThread (void)\n-{\n-}"}, {"sha": "8047eaea93f75ae97df52a8cd676fe28f554554f", "filename": "libgo/runtime/go-main.c", "status": "modified", "additions": 19, "deletions": 16, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-main.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-main.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-main.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -8,14 +8,14 @@\n \n #include <stdlib.h>\n #include <time.h>\n+#include <unistd.h>\n \n #ifdef HAVE_FPU_CONTROL_H\n #include <fpu_control.h>\n #endif\n \n #include \"go-alloc.h\"\n #include \"array.h\"\n-#include \"go-signal.h\"\n #include \"go-string.h\"\n \n #include \"runtime.h\"\n@@ -36,36 +36,39 @@ extern char **environ;\n extern void __go_init_main (void);\n extern void real_main (void) asm (\"main.main\");\n \n+static void mainstart (void *);\n+\n /* The main function.  */\n \n int\n main (int argc, char **argv)\n {\n+  runtime_initsig (0);\n   runtime_args (argc, (byte **) argv);\n-\n-  m = &runtime_m0;\n-  g = &runtime_g0;\n-  m->curg = g;\n-  g->m = m;\n-  runtime_mallocinit ();\n-  __go_gc_goroutine_init (&argc);\n-\n-  runtime_osinit();\n-  runtime_goargs();\n-  runtime_goenvs();\n-\n-  __initsig ();\n+  runtime_osinit ();\n+  runtime_schedinit ();\n \n #if defined(HAVE_SRANDOM)\n   srandom ((unsigned int) time (NULL));\n #else\n   srand ((unsigned int) time (NULL));\n #endif\n+\n+  __go_go (mainstart, NULL);\n+  runtime_mstart (runtime_m ());\n+  abort ();\n+}\n+\n+static void\n+mainstart (void *arg __attribute__ ((unused)))\n+{\n   __go_init_main ();\n \n-  __go_enable_gc ();\n+  mstats.enablegc = 1;\n \n   real_main ();\n \n-  return 0;\n+  runtime_exit (0);\n+\n+  abort ();\n }"}, {"sha": "23df57930b73fec5eb91a5271f55a9dfe6d8959b", "filename": "libgo/runtime/go-panic.c", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-panic.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-panic.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-panic.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -39,8 +39,11 @@ __printpanics (struct __go_panic_stack *p)\n void\n __go_panic (struct __go_empty_interface arg)\n {\n+  G *g;\n   struct __go_panic_stack *n;\n \n+  g = runtime_g ();\n+\n   n = (struct __go_panic_stack *) __go_alloc (sizeof (struct __go_panic_stack));\n   n->__arg = arg;\n   n->__next = g->panic;"}, {"sha": "c21878ce131b247a395d64613dfcd3374328d719", "filename": "libgo/runtime/go-rec-nb-small.c", "status": "modified", "additions": 3, "deletions": 8, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-rec-nb-small.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-rec-nb-small.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-rec-nb-small.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -6,6 +6,7 @@\n \n #include <stdint.h>\n \n+#include \"runtime.h\"\n #include \"go-assert.h\"\n #include \"go-panic.h\"\n #include \"channel.h\"\n@@ -22,10 +23,7 @@ __go_receive_nonblocking_acquire (struct __go_channel *channel)\n   __go_assert (i == 0);\n \n   while (channel->selected_for_receive)\n-    {\n-      i = pthread_cond_wait (&channel->cond, &channel->lock);\n-      __go_assert (i == 0);\n-    }\n+    runtime_cond_wait (&channel->cond, &channel->lock);\n \n   if (channel->is_closed\n       && (channel->num_entries == 0\n@@ -59,10 +57,7 @@ __go_receive_nonblocking_acquire (struct __go_channel *channel)\n \t  __go_broadcast_to_select (channel);\n \n \t  while (channel->next_store == 0)\n-\t    {\n-\t      i = pthread_cond_wait (&channel->cond, &channel->lock);\n-\t      __go_assert (i == 0);\n-\t    }\n+\t    runtime_cond_wait (&channel->cond, &channel->lock);\n \n \t  has_data = 1;\n \t}"}, {"sha": "f26dbcdd99388644a3de66625e23a0024596025b", "filename": "libgo/runtime/go-rec-small.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-rec-small.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-rec-small.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-rec-small.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -6,6 +6,7 @@\n \n #include <stdint.h>\n \n+#include \"runtime.h\"\n #include \"go-assert.h\"\n #include \"go-panic.h\"\n #include \"channel.h\"\n@@ -198,8 +199,7 @@ __go_receive_acquire (struct __go_channel *channel, _Bool for_select)\n       /* Wait for something to change, then loop around and try\n \t again.  */\n \n-      i = pthread_cond_wait (&channel->cond, &channel->lock);\n-      __go_assert (i == 0);\n+      runtime_cond_wait (&channel->cond, &channel->lock);\n     }\n }\n "}, {"sha": "7101d518ade9bfb4eb4e29ccd946a03d29dba3c4", "filename": "libgo/runtime/go-recover.c", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-recover.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-recover.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-recover.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -18,10 +18,13 @@\n _Bool\n __go_can_recover (const void* retaddr)\n {\n+  G *g;\n   struct __go_defer_stack *d;\n   const char* ret;\n   const char* dret;\n \n+  g = runtime_g ();\n+\n   d = g->defer;\n   if (d == NULL)\n     return 0;\n@@ -50,8 +53,11 @@ __go_can_recover (const void* retaddr)\n struct __go_empty_interface\n __go_recover ()\n {\n+  G *g;\n   struct __go_panic_stack *p;\n \n+  g = runtime_g ();\n+\n   if (g->panic == NULL || g->panic->__was_recovered)\n     {\n       struct __go_empty_interface ret;"}, {"sha": "2e36d31a5dc94949b50b7fa00dc7cf5e6e677d3a", "filename": "libgo/runtime/go-sched.c", "status": "removed", "additions": 0, "deletions": 15, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-sched.c?ref=a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "patch": "@@ -1,15 +0,0 @@\n-/* go-sched.c -- the runtime.Gosched function.\n-\n-   Copyright 2009 The Go Authors. All rights reserved.\n-   Use of this source code is governed by a BSD-style\n-   license that can be found in the LICENSE file.  */\n-\n-#include <sched.h>\n-\n-void Gosched (void) asm (\"libgo_runtime.runtime.Gosched\");\n-\n-void\n-Gosched (void)\n-{\n-  sched_yield ();\n-}"}, {"sha": "677c699b52c39c168fd69dd32fbd28dcd5ae67c8", "filename": "libgo/runtime/go-select.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-select.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-select.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-select.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -11,6 +11,7 @@\n #include <stdlib.h>\n #include <unistd.h>\n \n+#include \"runtime.h\"\n #include \"config.h\"\n #include \"go-assert.h\"\n #include \"channel.h\"\n@@ -746,10 +747,7 @@ __go_select (uintptr_t count, _Bool has_default,\n \t\t\t\t\t  (is_queued\n \t\t\t\t\t   ? NULL\n \t\t\t\t\t   : &selected_for_read)))\n-\t    {\n-\t      x = pthread_cond_wait (&__go_select_cond, &__go_select_mutex);\n-\t      __go_assert (x == 0);\n-\t    }\n+\t    runtime_cond_wait (&__go_select_cond, &__go_select_mutex);\n \n \t  is_queued = 1;\n \t}"}, {"sha": "7c77c0b418bfa4e03512cdcfa2d1a5d00b5c89b0", "filename": "libgo/runtime/go-semacquire.c", "status": "removed", "additions": 0, "deletions": 119, "changes": 119, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-semacquire.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-semacquire.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-semacquire.c?ref=a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "patch": "@@ -1,119 +0,0 @@\n-/* go-semacquire.c -- implement runtime.Semacquire and runtime.Semrelease.\n-\n-   Copyright 2009 The Go Authors. All rights reserved.\n-   Use of this source code is governed by a BSD-style\n-   license that can be found in the LICENSE file.  */\n-\n-#include <stdint.h>\n-\n-#include <pthread.h>\n-\n-#include \"go-assert.h\"\n-#include \"runtime.h\"\n-\n-/* We use a single global lock and condition variable.  This is\n-   painful, since it will cause unnecessary contention, but is hard to\n-   avoid in a portable manner.  On GNU/Linux we can use futexes, but\n-   they are unfortunately not exposed by libc and are thus also hard\n-   to use portably.  */\n-\n-static pthread_mutex_t sem_lock = PTHREAD_MUTEX_INITIALIZER;\n-static pthread_cond_t sem_cond = PTHREAD_COND_INITIALIZER;\n-\n-/* If the value in *ADDR is positive, and we are able to atomically\n-   decrement it, return true.  Otherwise do nothing and return\n-   false.  */\n-\n-static _Bool\n-acquire (uint32 *addr)\n-{\n-  while (1)\n-    {\n-      uint32 val;\n-\n-      val = *addr;\n-      if (val == 0)\n-\treturn 0;\n-      if (__sync_bool_compare_and_swap (addr, val, val - 1))\n-\treturn 1;\n-    }\n-}\n-\n-/* Implement runtime.Semacquire.  ADDR points to a semaphore count.\n-   We have acquired the semaphore when we have decremented the count\n-   and it remains nonnegative.  */\n-\n-void\n-runtime_semacquire (uint32 *addr)\n-{\n-  while (1)\n-    {\n-      int i;\n-\n-      /* If the current count is positive, and we are able to atomically\n-\t decrement it, then we have acquired the semaphore.  */\n-      if (acquire (addr))\n-\treturn;\n-\n-      /* Lock the mutex.  */\n-      i = pthread_mutex_lock (&sem_lock);\n-      __go_assert (i == 0);\n-\n-      /* Check the count again with the mutex locked.  */\n-      if (acquire (addr))\n-\t{\n-\t  i = pthread_mutex_unlock (&sem_lock);\n-\t  __go_assert (i == 0);\n-\t  return;\n-\t}\n-\n-      /* The count is zero.  Even if a call to runtime.Semrelease\n-\t increments it to become positive, that call will try to\n-\t acquire the mutex and block, so we are sure to see the signal\n-\t of the condition variable.  */\n-      i = pthread_cond_wait (&sem_cond, &sem_lock);\n-      __go_assert (i == 0);\n-\n-      /* Unlock the mutex and try again.  */\n-      i = pthread_mutex_unlock (&sem_lock);\n-      __go_assert (i == 0);\n-    }\n-}\n-\n-/* Implement runtime.Semrelease.  ADDR points to a semaphore count.  We\n-   must atomically increment the count.  If the count becomes\n-   positive, we signal the condition variable to wake up another\n-   process.  */\n-\n-void\n-runtime_semrelease (uint32 *addr)\n-{\n-  int32_t val;\n-\n-  val = __sync_fetch_and_add (addr, 1);\n-\n-  /* VAL is the old value.  It should never be negative.  If it is\n-     negative, that implies that Semacquire somehow decremented a zero\n-     value, or that the count has overflowed.  */\n-  __go_assert (val >= 0);\n-\n-  /* If the old value was zero, then we have now released a count, and\n-     we signal the condition variable.  If the old value was positive,\n-     then nobody can be waiting.  We have to use\n-     pthread_cond_broadcast, not pthread_cond_signal, because\n-     otherwise there would be a race condition when the count is\n-     incremented twice before any locker manages to decrement it.  */\n-  if (val == 0)\n-    {\n-      int i;\n-\n-      i = pthread_mutex_lock (&sem_lock);\n-      __go_assert (i == 0);\n-\n-      i = pthread_cond_broadcast (&sem_cond);\n-      __go_assert (i == 0);\n-\n-      i = pthread_mutex_unlock (&sem_lock);\n-      __go_assert (i == 0);\n-    }\n-}"}, {"sha": "f3336099bf7e626700f7271f89ea7f3d3f6fb0d2", "filename": "libgo/runtime/go-send-nb-small.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-send-nb-small.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-send-nb-small.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-send-nb-small.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -6,6 +6,7 @@\n \n #include <stdint.h>\n \n+#include \"runtime.h\"\n #include \"go-assert.h\"\n #include \"go-panic.h\"\n #include \"channel.h\"\n@@ -24,10 +25,7 @@ __go_send_nonblocking_acquire (struct __go_channel *channel)\n   __go_assert (i == 0);\n \n   while (channel->selected_for_send)\n-    {\n-      i = pthread_cond_wait (&channel->cond, &channel->lock);\n-      __go_assert (i == 0);\n-    }\n+    runtime_cond_wait (&channel->cond, &channel->lock);\n \n   if (channel->is_closed)\n     {"}, {"sha": "89a7032756da9b0c41128655d9e8d1e0094c17f4", "filename": "libgo/runtime/go-send-small.c", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-send-small.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-send-small.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-send-small.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -6,6 +6,7 @@\n \n #include <stdint.h>\n \n+#include \"runtime.h\"\n #include \"go-assert.h\"\n #include \"go-panic.h\"\n #include \"channel.h\"\n@@ -62,8 +63,7 @@ __go_send_acquire (struct __go_channel *channel, _Bool for_select)\n       /* Wait for something to change, then loop around and try\n \t again.  */\n \n-      i = pthread_cond_wait (&channel->cond, &channel->lock);\n-      __go_assert (i == 0);\n+      runtime_cond_wait (&channel->cond, &channel->lock);\n     }\n }\n \n@@ -118,8 +118,7 @@ __go_send_release (struct __go_channel *channel)\n \t\t}\n \t    }\n \n-\t  i = pthread_cond_wait (&channel->cond, &channel->lock);\n-\t  __go_assert (i == 0);\n+\t  runtime_cond_wait (&channel->cond, &channel->lock);\n \t}\n \n       channel->waiting_to_send = 0;"}, {"sha": "468235ddf4e51e7df4c413447c7c86468e8c8c38", "filename": "libgo/runtime/go-signal.c", "status": "modified", "additions": 80, "deletions": 33, "changes": 113, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-signal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-signal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-signal.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -6,13 +6,12 @@\n \n #include <signal.h>\n #include <stdlib.h>\n+#include <unistd.h>\n #include <sys/time.h>\n \n+#include \"runtime.h\"\n #include \"go-assert.h\"\n #include \"go-panic.h\"\n-#include \"go-signal.h\"\n-\n-#include \"runtime.h\"\n \n #ifndef SA_RESTART\n   #define SA_RESTART 0\n@@ -24,6 +23,10 @@ struct sigtab\n {\n   /* Signal number.  */\n   int sig;\n+  /* Nonzero if the signal should be caught.  */\n+  _Bool catch;\n+  /* Nonzero if the signal should be queued.  */\n+  _Bool queue;\n   /* Nonzero if the signal should be ignored.  */\n   _Bool ignore;\n   /* Nonzero if we should restart system calls.  */\n@@ -34,62 +37,81 @@ struct sigtab\n \n static struct sigtab signals[] =\n {\n-  { SIGHUP, 0, 1 },\n-  { SIGINT, 0, 1 },\n-  { SIGALRM, 1, 1 },\n-  { SIGTERM, 0, 1 },\n+  { SIGHUP, 0, 1, 0, 1 },\n+  { SIGINT, 0, 1, 0, 1 },\n+  { SIGQUIT, 0, 1, 0, 1 },\n+  { SIGALRM, 0, 1, 1, 1 },\n+  { SIGTERM, 0, 1, 0, 1 },\n+#ifdef SIGILL\n+  { SIGILL, 1, 0, 0, 0 },\n+#endif\n+#ifdef SIGTRAP\n+  { SIGTRAP, 1, 0, 0, 0 },\n+#endif\n+#ifdef SIGABRT\n+  { SIGABRT, 1, 0, 0, 0 },\n+#endif\n #ifdef SIGBUS\n-  { SIGBUS, 0, 0 },\n+  { SIGBUS, 1, 0, 0, 0 },\n #endif\n #ifdef SIGFPE\n-  { SIGFPE, 0, 0 },\n+  { SIGFPE, 1, 0, 0, 0 },\n #endif\n #ifdef SIGUSR1\n-  { SIGUSR1, 1, 1 },\n+  { SIGUSR1, 0, 1, 1, 1 },\n #endif\n #ifdef SIGSEGV\n-  { SIGSEGV, 0, 0 },\n+  { SIGSEGV, 1, 0, 0, 0 },\n #endif\n #ifdef SIGUSR2\n-  { SIGUSR2, 1, 1 },\n+  { SIGUSR2, 0, 1, 1, 1 },\n #endif\n #ifdef SIGPIPE\n-  { SIGPIPE, 1, 0 },\n+  { SIGPIPE, 0, 0, 1, 0 },\n+#endif\n+#ifdef SIGSTKFLT\n+  { SIGSTKFLT, 1, 0, 0, 0 },\n #endif\n #ifdef SIGCHLD\n-  { SIGCHLD, 1, 1 },\n+  { SIGCHLD, 0, 1, 1, 1 },\n #endif\n #ifdef SIGTSTP\n-  { SIGTSTP, 1, 1 },\n+  { SIGTSTP, 0, 1, 1, 1 },\n #endif\n #ifdef SIGTTIN\n-  { SIGTTIN, 1, 1 },\n+  { SIGTTIN, 0, 1, 1, 1 },\n #endif\n #ifdef SIGTTOU\n-  { SIGTTOU, 1, 1 },\n+  { SIGTTOU, 0, 1, 1, 1 },\n #endif\n #ifdef SIGURG\n-  { SIGURG, 1, 1 },\n+  { SIGURG, 0, 1, 1, 1 },\n #endif\n #ifdef SIGXCPU\n-  { SIGXCPU, 1, 1 },\n+  { SIGXCPU, 0, 1, 1, 1 },\n #endif\n #ifdef SIGXFSZ\n-  { SIGXFSZ, 1, 1 },\n+  { SIGXFSZ, 0, 1, 1, 1 },\n #endif\n #ifdef SIGVTARLM\n-  { SIGVTALRM, 1, 1 },\n+  { SIGVTALRM, 0, 1, 1, 1 },\n+#endif\n+#ifdef SIGPROF\n+  { SIGPROF, 0, 1, 1, 1 },\n #endif\n #ifdef SIGWINCH\n-  { SIGWINCH, 1, 1 },\n+  { SIGWINCH, 0, 1, 1, 1 },\n #endif\n #ifdef SIGIO\n-  { SIGIO, 1, 1 },\n+  { SIGIO, 0, 1, 1, 1 },\n #endif\n #ifdef SIGPWR\n-  { SIGPWR, 1, 1 },\n+  { SIGPWR, 0, 1, 1, 1 },\n+#endif\n+#ifdef SIGSYS\n+  { SIGSYS, 1, 0, 0, 0 },\n #endif\n-  { -1, 0, 0 }\n+  { -1, 0, 0, 0, 0 }\n };\n \n /* The Go signal handler.  */\n@@ -103,7 +125,7 @@ sighandler (int sig)\n   if (sig == SIGPROF)\n     {\n       /* FIXME.  */\n-      runtime_sigprof (0, 0, nil);\n+      runtime_sigprof (0, 0, nil, nil);\n       return;\n     }\n \n@@ -112,6 +134,12 @@ sighandler (int sig)\n   msg = NULL;\n   switch (sig)\n     {\n+#ifdef SIGILL\n+    case SIGILL:\n+      msg = \"illegal instruction\";\n+      break;\n+#endif\n+\n #ifdef SIGBUS\n     case SIGBUS:\n       msg = \"invalid memory address or nil pointer dereference\";\n@@ -138,7 +166,7 @@ sighandler (int sig)\n     {\n       sigset_t clear;\n \n-      if (__sync_bool_compare_and_swap (&m->mallocing, 1, 1))\n+      if (runtime_m()->mallocing)\n \t{\n \t  fprintf (stderr, \"caught signal while mallocing: %s\\n\", msg);\n \t  __go_assert (0);\n@@ -153,16 +181,22 @@ sighandler (int sig)\n       __go_panic_msg (msg);\n     }\n \n-  if (__go_sigsend (sig))\n-    return;\n   for (i = 0; signals[i].sig != -1; ++i)\n     {\n       if (signals[i].sig == sig)\n \t{\n \t  struct sigaction sa;\n \n-\t  if (signals[i].ignore)\n-\t    return;\n+\t  if (signals[i].queue)\n+\t    {\n+\t      if (__go_sigsend (sig) || signals[i].ignore)\n+\t\treturn;\n+\t      runtime_exit (2);\t\t// SIGINT, SIGTERM, etc\n+\t    }\n+\n+\t  if (runtime_panicking)\n+\t    runtime_exit (2);\n+\t  runtime_panicking = 1;\n \n \t  memset (&sa, 0, sizeof sa);\n \n@@ -181,11 +215,18 @@ sighandler (int sig)\n   abort ();\n }\n \n+/* Ignore a signal.  */\n+\n+static void\n+sigignore (int sig __attribute__ ((unused)))\n+{\n+}\n+\n /* Initialize signal handling for Go.  This is called when the program\n    starts.  */\n \n void\n-__initsig ()\n+runtime_initsig (int32 queue)\n {\n   struct sigaction sa;\n   int i;\n@@ -201,6 +242,12 @@ __initsig ()\n \n   for (i = 0; signals[i].sig != -1; ++i)\n     {\n+      if (signals[i].queue != (queue ? 1 : 0))\n+\tcontinue;\n+      if (signals[i].catch || signals[i].queue)\n+\tsa.sa_handler = sighandler;\n+      else\n+\tsa.sa_handler = sigignore;\n       sa.sa_flags = signals[i].restart ? SA_RESTART : 0;\n       if (sigaction (signals[i].sig, &sa, NULL) != 0)\n \t__go_assert (0);\n@@ -243,7 +290,7 @@ runtime_resetcpuprofiler(int32 hz)\n       __go_assert (i == 0);\n     }\n \n-  m->profilehz = hz;\n+  runtime_m()->profilehz = hz;\n }\n \n /* Used by the os package to raise SIGPIPE.  */"}, {"sha": "a30173a34de10b609a480080d323b098fd30e2ea", "filename": "libgo/runtime/go-signal.h", "status": "removed", "additions": 0, "deletions": 7, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-signal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a01207c473dcab88eb0ac769d2d9c68d7c9e0588/libgo%2Fruntime%2Fgo-signal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-signal.h?ref=a01207c473dcab88eb0ac769d2d9c68d7c9e0588", "patch": "@@ -1,7 +0,0 @@\n-/* go-signal.h -- signal handling for Go.\n-\n-   Copyright 2009 The Go Authors. All rights reserved.\n-   Use of this source code is governed by a BSD-style\n-   license that can be found in the LICENSE file.  */\n-\n-extern void __initsig (void);"}, {"sha": "c669a3ce889f543cc157069e5568e5afac384126", "filename": "libgo/runtime/go-unwind.c", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-unwind.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fgo-unwind.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fgo-unwind.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -47,8 +47,11 @@ static const _Unwind_Exception_Class __go_exception_class =\n void\n __go_check_defer (_Bool *frame)\n {\n+  G *g;\n   struct _Unwind_Exception *hdr;\n \n+  g = runtime_g ();\n+\n   if (g == NULL)\n     {\n       /* Some other language has thrown an exception.  We know there\n@@ -164,7 +167,7 @@ __go_unwind_stack ()\n \t\t    sizeof hdr->exception_class);\n   hdr->exception_cleanup = NULL;\n \n-  g->exception = hdr;\n+  runtime_g ()->exception = hdr;\n \n #ifdef __USING_SJLJ_EXCEPTIONS__\n   _Unwind_SjLj_RaiseException (hdr);\n@@ -280,6 +283,7 @@ PERSONALITY_FUNCTION (int version,\n   _Unwind_Ptr landing_pad, ip;\n   int ip_before_insn = 0;\n   _Bool is_foreign;\n+  G *g;\n \n #ifdef __ARM_EABI_UNWINDER__\n   _Unwind_Action actions;\n@@ -416,6 +420,7 @@ PERSONALITY_FUNCTION (int version,\n \n   /* It's possible for g to be NULL here for an exception thrown by a\n      language other than Go.  */\n+  g = runtime_g ();\n   if (g == NULL)\n     {\n       if (!is_foreign)"}, {"sha": "4f3d507726d9e014eb4593e17b402c604e21967b", "filename": "libgo/runtime/lock_futex.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Flock_futex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Flock_futex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Flock_futex.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -35,7 +35,7 @@ runtime_lock(Lock *l)\n {\n \tuint32 i, v, wait, spin;\n \n-\tif(m->locks++ < 0)\n+\tif(runtime_m()->locks++ < 0)\n \t\truntime_throw(\"runtime_lock: lock count\");\n \n \t// Speculative grab for lock.\n@@ -89,7 +89,7 @@ runtime_unlock(Lock *l)\n {\n \tuint32 v;\n \n-\tif(--m->locks < 0)\n+\tif(--runtime_m()->locks < 0)\n \t\truntime_throw(\"runtime_unlock: lock count\");\n \n \tv = runtime_xchg(&l->key, MUTEX_UNLOCKED);"}, {"sha": "73446bf83478ae8664ef5ae453dc43275cc8bc14", "filename": "libgo/runtime/malloc.goc", "status": "modified", "additions": 21, "deletions": 33, "changes": 54, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmalloc.goc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmalloc.goc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fmalloc.goc?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -33,14 +33,25 @@ extern volatile int32 runtime_MemProfileRate\n void*\n runtime_mallocgc(uintptr size, uint32 flag, int32 dogc, int32 zeroed)\n {\n+\tM *m;\n+\tG *g;\n \tint32 sizeclass, rate;\n \tMCache *c;\n \tuintptr npages;\n \tMSpan *s;\n \tvoid *v;\n \n-\tif(!__sync_bool_compare_and_swap(&m->mallocing, 0, 1))\n+\tm = runtime_m();\n+\tg = runtime_g();\n+\tif(g->status == Gsyscall)\n+\t\tdogc = 0;\n+\tif(runtime_gcwaiting && g != m->g0 && m->locks == 0 && g->status != Gsyscall) {\n+\t\truntime_gosched();\n+\t\tm = runtime_m();\n+\t}\n+\tif(m->mallocing)\n \t\truntime_throw(\"malloc/free - deadlock\");\n+\tm->mallocing = 1;\n \tif(size == 0)\n \t\tsize = 1;\n \n@@ -63,7 +74,7 @@ runtime_mallocgc(uintptr size, uint32 flag, int32 dogc, int32 zeroed)\n \t\tnpages = size >> PageShift;\n \t\tif((size & PageMask) != 0)\n \t\t\tnpages++;\n-\t\ts = runtime_MHeap_Alloc(&runtime_mheap, npages, 0, 1);\n+\t\ts = runtime_MHeap_Alloc(&runtime_mheap, npages, 0, !(flag & FlagNoGC));\n \t\tif(s == nil)\n \t\t\truntime_throw(\"out of memory\");\n \t\tsize = npages<<PageShift;\n@@ -77,18 +88,7 @@ runtime_mallocgc(uintptr size, uint32 flag, int32 dogc, int32 zeroed)\n \tif(!(flag & FlagNoGC))\n \t\truntime_markallocated(v, size, (flag&FlagNoPointers) != 0);\n \n-\t__sync_bool_compare_and_swap(&m->mallocing, 1, 0);\n-\n-\tif(__sync_bool_compare_and_swap(&m->gcing, 1, 0)) {\n-\t\tif(!(flag & FlagNoProfiling))\n-\t\t\t__go_run_goroutine_gc(0);\n-\t\telse {\n-\t\t\t// We are being called from the profiler.  Tell it\n-\t\t\t// to invoke the garbage collector when it is\n-\t\t\t// done.  No need to use a sync function here.\n-\t\t\tm->gcing_for_prof = 1;\n-\t\t}\n-\t}\n+\tm->mallocing = 0;\n \n \tif(!(flag & FlagNoProfiling) && (rate = runtime_MemProfileRate) > 0) {\n \t\tif(size >= (uint32) rate)\n@@ -122,6 +122,7 @@ __go_alloc(uintptr size)\n void\n __go_free(void *v)\n {\n+\tM *m;\n \tint32 sizeclass;\n \tMSpan *s;\n \tMCache *c;\n@@ -134,8 +135,10 @@ __go_free(void *v)\n \t// If you change this also change mgc0.c:/^sweepspan,\n \t// which has a copy of the guts of free.\n \n-\tif(!__sync_bool_compare_and_swap(&m->mallocing, 0, 1))\n+\tm = runtime_m();\n+\tif(m->mallocing)\n \t\truntime_throw(\"malloc/free - deadlock\");\n+\tm->mallocing = 1;\n \n \tif(!runtime_mlookup(v, nil, nil, &s)) {\n \t\t// runtime_printf(\"free %p: not an allocated block\\n\", v);\n@@ -170,11 +173,7 @@ __go_free(void *v)\n \tc->local_alloc -= size;\n \tif(prof)\n \t\truntime_MProf_Free(v, size);\n-\n-\t__sync_bool_compare_and_swap(&m->mallocing, 1, 0);\n-\n-\tif(__sync_bool_compare_and_swap(&m->gcing, 1, 0))\n-\t\t__go_run_goroutine_gc(1);\n+\tm->mallocing = 0;\n }\n \n int32\n@@ -184,7 +183,7 @@ runtime_mlookup(void *v, byte **base, uintptr *size, MSpan **sp)\n \tbyte *p;\n \tMSpan *s;\n \n-\tm->mcache->local_nlookup++;\n+\truntime_m()->mcache->local_nlookup++;\n \ts = runtime_MHeap_LookupMaybe(&runtime_mheap, v);\n \tif(sp)\n \t\t*sp = s;\n@@ -229,15 +228,8 @@ runtime_allocmcache(void)\n \tint32 rate;\n \tMCache *c;\n \n-\tif(!__sync_bool_compare_and_swap(&m->mallocing, 0, 1))\n-\t\truntime_throw(\"allocmcache - deadlock\");\n-\n \truntime_lock(&runtime_mheap);\n \tc = runtime_FixAlloc_Alloc(&runtime_mheap.cachealloc);\n-\n-\t// Clear the free list used by FixAlloc; assume the rest is zeroed.\n-\tc->list[0].list = nil;\n-\n \tmstats.mcache_inuse = runtime_mheap.cachealloc.inuse;\n \tmstats.mcache_sys = runtime_mheap.cachealloc.sys;\n \truntime_unlock(&runtime_mheap);\n@@ -249,10 +241,6 @@ runtime_allocmcache(void)\n \tif(rate != 0)\n \t\tc->next_sample = runtime_fastrand1() % (2*rate);\n \n-\t__sync_bool_compare_and_swap(&m->mallocing, 1, 0);\n-\tif(__sync_bool_compare_and_swap(&m->gcing, 1, 0))\n-\t\t__go_run_goroutine_gc(2);\n-\n \treturn c;\n }\n \n@@ -374,7 +362,7 @@ runtime_mallocinit(void)\n \n \t// Initialize the rest of the allocator.\t\n \truntime_MHeap_Init(&runtime_mheap, runtime_SysAlloc);\n-\tm->mcache = runtime_allocmcache();\n+\truntime_m()->mcache = runtime_allocmcache();\n \n \t// See if it works.\n \truntime_free(runtime_malloc(1));"}, {"sha": "da0c0f85766ae83fa084bf8dbc93f25f68d25a0e", "filename": "libgo/runtime/malloc.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmalloc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmalloc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fmalloc.h?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -422,4 +422,4 @@ extern int32 runtime_malloc_profile;\n \n struct __go_func_type;\n bool\truntime_getfinalizer(void *p, bool del, void (**fn)(void*), const struct __go_func_type **ft);\n-void\truntime_walkfintab(void (*fn)(void*), void (*scan)(byte*, int64));\n+void\truntime_walkfintab(void (*fn)(void*), void (*scan)(byte *, int64));"}, {"sha": "a89003716794d477eb9a53d1cea19a3692eafeae", "filename": "libgo/runtime/mfinal.c", "status": "modified", "additions": 5, "deletions": 36, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmfinal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmfinal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fmfinal.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -141,28 +141,24 @@ runtime_addfinalizer(void *p, void (*f)(void*), const struct __go_func_type *ft)\n {\n \tFintab *tab;\n \tbyte *base;\n-\tbool ret = false;\n \t\n \tif(debug) {\n \t\tif(!runtime_mlookup(p, &base, nil, nil) || p != base)\n \t\t\truntime_throw(\"addfinalizer on invalid pointer\");\n \t}\n \t\n-\tif(!__sync_bool_compare_and_swap(&m->holds_finlock, 0, 1))\n-\t\truntime_throw(\"finalizer deadlock\");\n-\n \ttab = TAB(p);\n \truntime_lock(tab);\n \tif(f == nil) {\n \t\tif(lookfintab(tab, p, true, nil))\n \t\t\truntime_setblockspecial(p, false);\n-\t\tret = true;\n-\t\tgoto unlock;\n+\t\truntime_unlock(tab);\n+\t\treturn true;\n \t}\n \n \tif(lookfintab(tab, p, false, nil)) {\n-\t\tret = false;\n-\t\tgoto unlock;\n+\t\truntime_unlock(tab);\n+\t\treturn false;\n \t}\n \n \tif(tab->nkey >= tab->max/2+tab->max/4) {\n@@ -173,18 +169,8 @@ runtime_addfinalizer(void *p, void (*f)(void*), const struct __go_func_type *ft)\n \n \taddfintab(tab, p, f, ft);\n \truntime_setblockspecial(p, true);\n-\tret = true;\n-\n- unlock:\n \truntime_unlock(tab);\n-\n-\t__sync_bool_compare_and_swap(&m->holds_finlock, 1, 0);\n-\n-\tif(__sync_bool_compare_and_swap(&m->gcing_for_finlock, 1, 0)) {\n-\t\t__go_run_goroutine_gc(200);\n-\t}\n-\n-\treturn ret;\n+\treturn true;\n }\n \n // get finalizer; if del, delete finalizer.\n@@ -196,19 +182,10 @@ runtime_getfinalizer(void *p, bool del, void (**fn)(void*), const struct __go_fu\n \tbool res;\n \tFin f;\n \t\n-\tif(!__sync_bool_compare_and_swap(&m->holds_finlock, 0, 1))\n-\t\truntime_throw(\"finalizer deadlock\");\n-\n \ttab = TAB(p);\n \truntime_lock(tab);\n \tres = lookfintab(tab, p, del, &f);\n \truntime_unlock(tab);\n-\n-\t__sync_bool_compare_and_swap(&m->holds_finlock, 1, 0);\n-\tif(__sync_bool_compare_and_swap(&m->gcing_for_finlock, 1, 0)) {\n-\t\t__go_run_goroutine_gc(201);\n-\t}\n-\n \tif(res==false)\n \t\treturn false;\n \t*fn = f.fn;\n@@ -223,9 +200,6 @@ runtime_walkfintab(void (*fn)(void*), void (*scan)(byte *, int64))\n \tvoid **ekey;\n \tint32 i;\n \n-\tif(!__sync_bool_compare_and_swap(&m->holds_finlock, 0, 1))\n-\t\truntime_throw(\"finalizer deadlock\");\n-\n \tfor(i=0; i<TABSZ; i++) {\n \t\truntime_lock(&fintab[i]);\n \t\tkey = fintab[i].fkey;\n@@ -237,9 +211,4 @@ runtime_walkfintab(void (*fn)(void*), void (*scan)(byte *, int64))\n \t\tscan((byte*)&fintab[i].val, sizeof(void*));\n \t\truntime_unlock(&fintab[i]);\n \t}\n-\n-\t__sync_bool_compare_and_swap(&m->holds_finlock, 1, 0);\n-\tif(__sync_bool_compare_and_swap(&m->gcing_for_finlock, 1, 0)) {\n-\t\truntime_throw(\"walkfintab not called from gc\");\n-\t}\n }"}, {"sha": "0f1cb49e40f4addf83c17ba16c76cfbfb34c9662", "filename": "libgo/runtime/mgc0.c", "status": "modified", "additions": 193, "deletions": 51, "changes": 244, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmgc0.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmgc0.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fmgc0.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -8,6 +8,16 @@\n #include \"arch.h\"\n #include \"malloc.h\"\n \n+#ifdef USING_SPLIT_STACK\n+\n+extern void * __splitstack_find (void *, void *, size_t *, void **, void **,\n+\t\t\t\t void **);\n+\n+extern void * __splitstack_find_context (void *context[10], size_t *, void **,\n+\t\t\t\t\t void **, void **);\n+\n+#endif\n+\n enum {\n \tDebug = 0,\n \tPtrSize = sizeof(void*),\n@@ -85,9 +95,8 @@ struct FinBlock\n \tFinalizer fin[1];\n };\n \n-static bool finstarted;\n-static pthread_mutex_t finqlock = PTHREAD_MUTEX_INITIALIZER;\n-static pthread_cond_t finqcond = PTHREAD_COND_INITIALIZER;\n+\n+static G *fing;\n static FinBlock *finq; // list of finalizers that are to be executed\n static FinBlock *finc; // cache of free blocks\n static FinBlock *allfin; // list of all blocks\n@@ -590,6 +599,79 @@ handoff(Workbuf *b)\n \treturn b1;\n }\n \n+// Scanstack calls scanblock on each of gp's stack segments.\n+static void\n+scanstack(void (*scanblock)(byte*, int64), G *gp)\n+{\n+#ifdef USING_SPLIT_STACK\n+\tM *mp;\n+\tvoid* sp;\n+\tsize_t spsize;\n+\tvoid* next_segment;\n+\tvoid* next_sp;\n+\tvoid* initial_sp;\n+\n+\tif(gp == runtime_g()) {\n+\t\t// Scanning our own stack.\n+\t\tsp = __splitstack_find(nil, nil, &spsize, &next_segment,\n+\t\t\t\t       &next_sp, &initial_sp);\n+\t} else if((mp = gp->m) != nil && mp->helpgc) {\n+\t\t// gchelper's stack is in active use and has no interesting pointers.\n+\t\treturn;\n+\t} else {\n+\t\t// Scanning another goroutine's stack.\n+\t\t// The goroutine is usually asleep (the world is stopped).\n+\n+\t\t// The exception is that if the goroutine is about to enter or might\n+\t\t// have just exited a system call, it may be executing code such\n+\t\t// as schedlock and may have needed to start a new stack segment.\n+\t\t// Use the stack segment and stack pointer at the time of\n+\t\t// the system call instead, since that won't change underfoot.\n+\t\tif(gp->gcstack != nil) {\n+\t\t\tsp = gp->gcstack;\n+\t\t\tspsize = gp->gcstack_size;\n+\t\t\tnext_segment = gp->gcnext_segment;\n+\t\t\tnext_sp = gp->gcnext_sp;\n+\t\t\tinitial_sp = gp->gcinitial_sp;\n+\t\t} else {\n+\t\t\tsp = __splitstack_find_context(&gp->stack_context[0],\n+\t\t\t\t\t\t       &spsize, &next_segment,\n+\t\t\t\t\t\t       &next_sp, &initial_sp);\n+\t\t}\n+\t}\n+\tif(sp != nil) {\n+\t\tscanblock(sp, spsize);\n+\t\twhile((sp = __splitstack_find(next_segment, next_sp,\n+\t\t\t\t\t      &spsize, &next_segment,\n+\t\t\t\t\t      &next_sp, &initial_sp)) != nil)\n+\t\t\tscanblock(sp, spsize);\n+\t}\n+#else\n+\tM *mp;\n+\tbyte* bottom;\n+\tbyte* top;\n+\n+\tif(gp == runtime_g()) {\n+\t\t// Scanning our own stack.\n+\t\tbottom = (byte*)&gp;\n+\t} else if((mp = gp->m) != nil && mp->helpgc) {\n+\t\t// gchelper's stack is in active use and has no interesting pointers.\n+\t\treturn;\n+\t} else {\n+\t\t// Scanning another goroutine's stack.\n+\t\t// The goroutine is usually asleep (the world is stopped).\n+\t\tbottom = (byte*)gp->gcnext_sp;\n+\t\tif(bottom == nil)\n+\t\t\treturn;\n+\t}\n+\ttop = (byte*)gp->gcinitial_sp + gp->gcstack_size;\n+\tif(top > bottom)\n+\t\tscanblock(bottom, top - bottom);\n+\telse\n+\t\tscanblock(top, bottom - top);\n+#endif\n+}\n+\n // Markfin calls scanblock on the blocks that have finalizers:\n // the things pointed at cannot be freed until the finalizers have run.\n static void\n@@ -639,8 +721,10 @@ static void\n mark(void (*scan)(byte*, int64))\n {\n \tstruct root_list *pl;\n+\tG *gp;\n \tFinBlock *fb;\n \n+\t// mark data+bss.\n \tfor(pl = roots; pl != nil; pl = pl->next) {\n \t\tstruct root* pr = &pl->roots[0];\n \t\twhile(1) {\n@@ -654,11 +738,30 @@ mark(void (*scan)(byte*, int64))\n \n \tscan((byte*)&runtime_m0, sizeof runtime_m0);\n \tscan((byte*)&runtime_g0, sizeof runtime_g0);\n-\tscan((byte*)&finq, sizeof finq);\n+\tscan((byte*)&runtime_allg, sizeof runtime_allg);\n+\tscan((byte*)&runtime_allm, sizeof runtime_allm);\n \truntime_MProf_Mark(scan);\n \n \t// mark stacks\n-\t__go_scanstacks(scan);\n+\tfor(gp=runtime_allg; gp!=nil; gp=gp->alllink) {\n+\t\tswitch(gp->status){\n+\t\tdefault:\n+\t\t\truntime_printf(\"unexpected G.status %d\\n\", gp->status);\n+\t\t\truntime_throw(\"mark - bad status\");\n+\t\tcase Gdead:\n+\t\t\tbreak;\n+\t\tcase Grunning:\n+\t\t\tif(gp != runtime_g())\n+\t\t\t\truntime_throw(\"mark - world not stopped\");\n+\t\t\tscanstack(scan, gp);\n+\t\t\tbreak;\n+\t\tcase Grunnable:\n+\t\tcase Gsyscall:\n+\t\tcase Gwaiting:\n+\t\t\tscanstack(scan, gp);\n+\t\t\tbreak;\n+\t\t}\n+\t}\n \n \t// mark things pointed at by objects with finalizers\n \tif(scan == debug_scanblock)\n@@ -714,13 +817,15 @@ handlespecial(byte *p, uintptr size)\n static void\n sweep(void)\n {\n+\tM *m;\n \tMSpan *s;\n \tint32 cl, n, npages;\n \tuintptr size;\n \tbyte *p;\n \tMCache *c;\n \tbyte *arena_start;\n \n+\tm = runtime_m();\n \tarena_start = runtime_mheap.arena_start;\n \n \tfor(;;) {\n@@ -799,8 +904,6 @@ sweep(void)\n \t}\n }\n \n-static pthread_mutex_t gcsema = PTHREAD_MUTEX_INITIALIZER;\n-\n void\n runtime_gchelper(void)\n {\n@@ -818,6 +921,11 @@ runtime_gchelper(void)\n \t\truntime_notewakeup(&work.alldone);\n }\n \n+// Semaphore, not Lock, so that the goroutine\n+// reschedules when there is contention rather\n+// than spinning.\n+static uint32 gcsema = 1;\n+\n // Initialized from $GOGC.  GOGC=off means no gc.\n //\n // Next gc is after we've allocated an extra amount of\n@@ -829,9 +937,46 @@ runtime_gchelper(void)\n // extra memory used).\n static int32 gcpercent = -2;\n \n+static void\n+stealcache(void)\n+{\n+\tM *m;\n+\n+\tfor(m=runtime_allm; m; m=m->alllink)\n+\t\truntime_MCache_ReleaseAll(m->mcache);\n+}\n+\n+static void\n+cachestats(void)\n+{\n+\tM *m;\n+\tMCache *c;\n+\tuint32 i;\n+\tuint64 stacks_inuse;\n+\tuint64 stacks_sys;\n+\n+\tstacks_inuse = 0;\n+\tstacks_sys = 0;\n+\tfor(m=runtime_allm; m; m=m->alllink) {\n+\t\truntime_purgecachedstats(m);\n+\t\t// stacks_inuse += m->stackalloc->inuse;\n+\t\t// stacks_sys += m->stackalloc->sys;\n+\t\tc = m->mcache;\n+\t\tfor(i=0; i<nelem(c->local_by_size); i++) {\n+\t\t\tmstats.by_size[i].nmalloc += c->local_by_size[i].nmalloc;\n+\t\t\tc->local_by_size[i].nmalloc = 0;\n+\t\t\tmstats.by_size[i].nfree += c->local_by_size[i].nfree;\n+\t\t\tc->local_by_size[i].nfree = 0;\n+\t\t}\n+\t}\n+\tmstats.stacks_inuse = stacks_inuse;\n+\tmstats.stacks_sys = stacks_sys;\n+}\n+\n void\n-runtime_gc(int32 force __attribute__ ((unused)))\n+runtime_gc(int32 force)\n {\n+\tM *m;\n \tint64 t0, t1, t2, t3;\n \tuint64 heap0, heap1, obj0, obj1;\n \tconst byte *p;\n@@ -845,7 +990,8 @@ runtime_gc(int32 force __attribute__ ((unused)))\n \t// problems, don't bother trying to run gc\n \t// while holding a lock.  The next mallocgc\n \t// without a lock will do the gc instead.\n-\tif(!mstats.enablegc || m->locks > 0 /* || runtime_panicking */)\n+\tm = runtime_m();\n+\tif(!mstats.enablegc || m->locks > 0 || runtime_panicking)\n \t\treturn;\n \n \tif(gcpercent == -2) {\t// first time through\n@@ -864,11 +1010,9 @@ runtime_gc(int32 force __attribute__ ((unused)))\n \tif(gcpercent < 0)\n \t\treturn;\n \n-\tpthread_mutex_lock(&finqlock);\n-\tpthread_mutex_lock(&gcsema);\n+\truntime_semacquire(&gcsema);\n \tif(!force && mstats.heap_alloc < mstats.next_gc) {\n-\t\tpthread_mutex_unlock(&gcsema);\n-\t\tpthread_mutex_unlock(&finqlock);\n+\t\truntime_semrelease(&gcsema);\n \t\treturn;\n \t}\n \n@@ -881,7 +1025,7 @@ runtime_gc(int32 force __attribute__ ((unused)))\n \tm->gcing = 1;\n \truntime_stoptheworld();\n \n-\t__go_cachestats();\n+\tcachestats();\n \theap0 = mstats.heap_alloc;\n \tobj0 = mstats.nmalloc - mstats.nfree;\n \n@@ -890,12 +1034,10 @@ runtime_gc(int32 force __attribute__ ((unused)))\n \n \textra = false;\n \twork.nproc = 1;\n-#if 0\n \tif(runtime_gomaxprocs > 1 && runtime_ncpu > 1) {\n \t\truntime_noteclear(&work.alldone);\n \t\twork.nproc += runtime_helpgc(&extra);\n \t}\n-#endif\n \twork.nwait = 0;\n \twork.ndone = 0;\n \n@@ -912,14 +1054,25 @@ runtime_gc(int32 force __attribute__ ((unused)))\n \t\truntime_notesleep(&work.alldone);\n \tt2 = runtime_nanotime();\n \n-\t__go_stealcache();\n-\t__go_cachestats();\n+\tstealcache();\n+\tcachestats();\n \n \tmstats.next_gc = mstats.heap_alloc+mstats.heap_alloc*gcpercent/100;\n \tm->gcing = 0;\n \n \tm->locks++;\t// disable gc during the mallocs in newproc\n+\tif(finq != nil) {\n+\t\t// kick off or wake up goroutine to run queued finalizers\n+\t\tif(fing == nil)\n+\t\t\tfing = __go_go(runfinq, nil);\n+\t\telse if(fingwait) {\n+\t\t\tfingwait = 0;\n+\t\t\truntime_ready(fing);\n+\t\t}\n+\t}\n+\tm->locks--;\n \n+\tcachestats();\n \theap1 = mstats.heap_alloc;\n \tobj1 = mstats.nmalloc - mstats.nfree;\n \n@@ -938,7 +1091,7 @@ runtime_gc(int32 force __attribute__ ((unused)))\n \t\t\t(unsigned long long)nlookup, (unsigned long long)nsizelookup, (unsigned long long)naddrlookup, (unsigned long long) nhandoff);\n \t}\n \n-\tpthread_mutex_unlock(&gcsema);\n+\truntime_semrelease(&gcsema);\n \n \t// If we could have used another helper proc, start one now,\n \t// in the hope that it will be available next time.\n@@ -949,20 +1102,9 @@ runtime_gc(int32 force __attribute__ ((unused)))\n \t// the maximum number of procs.\n \truntime_starttheworld(extra);\n \n-\t// finqlock is still held.\n-\tif(finq != nil) {\n-\t\t// kick off or wake up goroutine to run queued finalizers\n-\t\tif(!finstarted) {\n-\t\t\t__go_go(runfinq, nil);\n-\t\t\tfinstarted = 1;\n-\t\t}\n-\t\telse if(fingwait) {\n-\t\t\tfingwait = 0;\n-\t\t\tpthread_cond_signal(&finqcond);\n-\t\t}\n-\t}\n-\tm->locks--;\n-\tpthread_mutex_unlock(&finqlock);\n+\t// give the queued finalizers, if any, a chance to run\t\n+\tif(finq != nil)\t\n+\t\truntime_gosched();\n \n \tif(gctrace > 1 && !force)\n \t\truntime_gc(1);\n@@ -974,39 +1116,47 @@ void runtime_UpdateMemStats(void)\n void\n runtime_UpdateMemStats(void)\n {\n+\tM *m;\n+\n \t// Have to acquire gcsema to stop the world,\n \t// because stoptheworld can only be used by\n \t// one goroutine at a time, and there might be\n \t// a pending garbage collection already calling it.\n-\tpthread_mutex_lock(&gcsema);\n+\truntime_semacquire(&gcsema);\n+\tm = runtime_m();\n \tm->gcing = 1;\n \truntime_stoptheworld();\n-\t__go_cachestats();\n+\tcachestats();\n \tm->gcing = 0;\n-\tpthread_mutex_unlock(&gcsema);\n+\truntime_semrelease(&gcsema);\n \truntime_starttheworld(false);\n }\n \n static void\n-runfinq(void* dummy)\n+runfinq(void* dummy __attribute__ ((unused)))\n {\n+\tG* gp;\n \tFinalizer *f;\n \tFinBlock *fb, *next;\n \tuint32 i;\n \n-\tUSED(dummy);\n-\n+\tgp = runtime_g();\n \tfor(;;) {\n-\t\tpthread_mutex_lock(&finqlock);\n+\t\t// There's no need for a lock in this section\n+\t\t// because it only conflicts with the garbage\n+\t\t// collector, and the garbage collector only\n+\t\t// runs when everyone else is stopped, and\n+\t\t// runfinq only stops at the gosched() or\n+\t\t// during the calls in the for loop.\n \t\tfb = finq;\n \t\tfinq = nil;\n \t\tif(fb == nil) {\n \t\t\tfingwait = 1;\n-\t\t\tpthread_cond_wait(&finqcond, &finqlock);\n-\t\t\tpthread_mutex_unlock(&finqlock);\n+\t\t\tgp->status = Gwaiting;\n+\t\t\tgp->waitreason = \"finalizer wait\";\n+\t\t\truntime_gosched();\n \t\t\tcontinue;\n \t\t}\n-\t\tpthread_mutex_unlock(&finqlock);\n \t\tfor(; fb; fb=next) {\n \t\t\tnext = fb->next;\n \t\t\tfor(i=0; i<(uint32)fb->cnt; i++) {\n@@ -1027,8 +1177,6 @@ runfinq(void* dummy)\n \t}\n }\n \n-#define runtime_singleproc 0\n-\n // mark the block at v of size n as allocated.\n // If noptr is true, mark it as having no pointers.\n void\n@@ -1231,9 +1379,3 @@ runtime_MHeap_MapBits(MHeap *h)\n \truntime_SysMap(h->arena_start - n, n - h->bitmap_mapped);\n \th->bitmap_mapped = n;\n }\n-\n-void\n-__go_enable_gc()\n-{\n-  mstats.enablegc = 1;\n-}"}, {"sha": "5a5a1e71a1233e24dbbf2e73c0c8f2f670b26fa4", "filename": "libgo/runtime/mheap.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmheap.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmheap.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fmheap.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -58,7 +58,7 @@ runtime_MHeap_Alloc(MHeap *h, uintptr npage, int32 sizeclass, int32 acct)\n \tMSpan *s;\n \n \truntime_lock(h);\n-\truntime_purgecachedstats(m);\n+\truntime_purgecachedstats(runtime_m());\n \ts = MHeap_AllocLocked(h, npage, sizeclass);\n \tif(s != nil) {\n \t\tmstats.heap_inuse += npage<<PageShift;\n@@ -257,7 +257,7 @@ void\n runtime_MHeap_Free(MHeap *h, MSpan *s, int32 acct)\n {\n \truntime_lock(h);\n-\truntime_purgecachedstats(m);\n+\truntime_purgecachedstats(runtime_m());\n \tmstats.heap_inuse -= s->npages<<PageShift;\n \tif(acct) {\n \t\tmstats.heap_alloc -= s->npages<<PageShift;"}, {"sha": "f44f45083f7244410a177056ba1dcfb966133aa5", "filename": "libgo/runtime/mprof.goc", "status": "modified", "additions": 13, "deletions": 17, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmprof.goc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fmprof.goc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fmprof.goc?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -190,12 +190,16 @@ found:\n void\n runtime_MProf_Malloc(void *p, uintptr size)\n {\n+\tM *m;\n \tint32 nstk;\n \tuintptr stk[32];\n \tBucket *b;\n \n-\tif(!__sync_bool_compare_and_swap(&m->nomemprof, 0, 1))\n+\tm = runtime_m();\n+\tif(m->nomemprof > 0)\n \t\treturn;\n+\n+\tm->nomemprof++;\n #if 0\n \tnstk = runtime_callers(1, stk, 32);\n #else\n@@ -207,32 +211,31 @@ runtime_MProf_Malloc(void *p, uintptr size)\n \tb->alloc_bytes += size;\n \tsetaddrbucket((uintptr)p, b);\n \truntime_unlock(&proflock);\n-\t__sync_bool_compare_and_swap(&m->nomemprof, 1, 0);\n-\n-\tif(__sync_bool_compare_and_swap(&m->gcing_for_prof, 1, 0))\n-\t\t__go_run_goroutine_gc(100);\n+\tm = runtime_m();\n+\tm->nomemprof--;\n }\n \n // Called when freeing a profiled block.\n void\n runtime_MProf_Free(void *p, uintptr size)\n {\n+\tM *m;\n \tBucket *b;\n \n-\tif(!__sync_bool_compare_and_swap(&m->nomemprof, 0, 1))\n+\tm = runtime_m();\n+\tif(m->nomemprof > 0)\n \t\treturn;\n \n+\tm->nomemprof++;\n \truntime_lock(&proflock);\n \tb = getaddrbucket((uintptr)p);\n \tif(b != nil) {\n \t\tb->frees++;\n \t\tb->free_bytes += size;\n \t}\n \truntime_unlock(&proflock);\n-\t__sync_bool_compare_and_swap(&m->nomemprof, 1, 0);\n-\n-\tif(__sync_bool_compare_and_swap(&m->gcing_for_prof, 1, 0))\n-\t\t__go_run_goroutine_gc(101);\n+\tm = runtime_m();\n+\tm->nomemprof--;\n }\n \n \n@@ -267,8 +270,6 @@ func MemProfile(p Slice, include_inuse_zero bool) (n int32, ok bool) {\n \tBucket *b;\n \tRecord *r;\n \n-\t__sync_bool_compare_and_swap(&m->nomemprof, 0, 1);\n-\n \truntime_lock(&proflock);\n \tn = 0;\n \tfor(b=buckets; b; b=b->allnext)\n@@ -283,11 +284,6 @@ func MemProfile(p Slice, include_inuse_zero bool) (n int32, ok bool) {\n \t\t\t\trecord(r++, b);\n \t}\n \truntime_unlock(&proflock);\n-\n-\t__sync_bool_compare_and_swap(&m->nomemprof, 1, 0);\n-\n-\tif(__sync_bool_compare_and_swap(&m->gcing_for_prof, 1, 0))\n-\t\t__go_run_goroutine_gc(102);\n }\n \n void"}, {"sha": "b243de2424ec9ea05c63ec3d7e4a97e8743ddbda", "filename": "libgo/runtime/proc.c", "status": "modified", "additions": 1318, "deletions": 34, "changes": 1352, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fproc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fproc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fproc.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -2,21 +2,1323 @@\n // Use of this source code is governed by a BSD-style\n // license that can be found in the LICENSE file.\n \n+#include <limits.h>\n+#include <stdlib.h>\n+#include <pthread.h>\n+#include <unistd.h>\n+\n+#include \"config.h\"\n #include \"runtime.h\"\n #include \"arch.h\"\n-#include \"malloc.h\"\t/* so that acid generated from proc.c includes malloc data structures */\n+#include \"defs.h\"\n+#include \"malloc.h\"\n+#include \"go-defer.h\"\n+\n+#ifdef USING_SPLIT_STACK\n+\n+/* FIXME: These are not declared anywhere.  */\n+\n+extern void __splitstack_getcontext(void *context[10]);\n+\n+extern void __splitstack_setcontext(void *context[10]);\n+\n+extern void *__splitstack_makecontext(size_t, void *context[10], size_t *);\n+\n+extern void * __splitstack_resetcontext(void *context[10], size_t *);\n+\n+extern void *__splitstack_find(void *, void *, size_t *, void **, void **,\n+\t\t\t       void **);\n+\n+#endif\n+\n+#if defined(USING_SPLIT_STACK) && defined(LINKER_SUPPORTS_SPLIT_STACK)\n+# ifdef PTHREAD_STACK_MIN\n+#  define StackMin PTHREAD_STACK_MIN\n+# else\n+#  define StackMin 8192\n+# endif\n+#else\n+# define StackMin 2 * 1024 * 1024\n+#endif\n+\n+static void schedule(G*);\n+static M *startm(void);\n \n typedef struct Sched Sched;\n \n-G\truntime_g0;\n M\truntime_m0;\n+G\truntime_g0;\t// idle goroutine for m0\n \n #ifdef __rtems__\n #define __thread\n #endif\n \n-__thread G *g;\n-__thread M *m;\n+static __thread G *g;\n+static __thread M *m;\n+\n+// We can not always refer to the TLS variables directly.  The\n+// compiler will call tls_get_addr to get the address of the variable,\n+// and it may hold it in a register across a call to schedule.  When\n+// we get back from the call we may be running in a different thread,\n+// in which case the register now points to the TLS variable for a\n+// different thread.  We use non-inlinable functions to avoid this\n+// when necessary.\n+\n+G* runtime_g(void) __attribute__ ((noinline, no_split_stack));\n+\n+G*\n+runtime_g(void)\n+{\n+\treturn g;\n+}\n+\n+M* runtime_m(void) __attribute__ ((noinline, no_split_stack));\n+\n+M*\n+runtime_m(void)\n+{\n+\treturn m;\n+}\n+\n+int32\truntime_gcwaiting;\n+\n+// Go scheduler\n+//\n+// The go scheduler's job is to match ready-to-run goroutines (`g's)\n+// with waiting-for-work schedulers (`m's).  If there are ready g's\n+// and no waiting m's, ready() will start a new m running in a new\n+// OS thread, so that all ready g's can run simultaneously, up to a limit.\n+// For now, m's never go away.\n+//\n+// By default, Go keeps only one kernel thread (m) running user code\n+// at a single time; other threads may be blocked in the operating system.\n+// Setting the environment variable $GOMAXPROCS or calling\n+// runtime.GOMAXPROCS() will change the number of user threads\n+// allowed to execute simultaneously.  $GOMAXPROCS is thus an\n+// approximation of the maximum number of cores to use.\n+//\n+// Even a program that can run without deadlock in a single process\n+// might use more m's if given the chance.  For example, the prime\n+// sieve will use as many m's as there are primes (up to runtime_sched.mmax),\n+// allowing different stages of the pipeline to execute in parallel.\n+// We could revisit this choice, only kicking off new m's for blocking\n+// system calls, but that would limit the amount of parallel computation\n+// that go would try to do.\n+//\n+// In general, one could imagine all sorts of refinements to the\n+// scheduler, but the goal now is just to get something working on\n+// Linux and OS X.\n+\n+struct Sched {\n+\tLock;\n+\n+\tG *gfree;\t// available g's (status == Gdead)\n+\tint32 goidgen;\n+\n+\tG *ghead;\t// g's waiting to run\n+\tG *gtail;\n+\tint32 gwait;\t// number of g's waiting to run\n+\tint32 gcount;\t// number of g's that are alive\n+\tint32 grunning;\t// number of g's running on cpu or in syscall\n+\n+\tM *mhead;\t// m's waiting for work\n+\tint32 mwait;\t// number of m's waiting for work\n+\tint32 mcount;\t// number of m's that have been created\n+\n+\tvolatile uint32 atomic;\t// atomic scheduling word (see below)\n+\n+\tint32 profilehz;\t// cpu profiling rate\n+\n+\tNote\tstopped;\t// one g can set waitstop and wait here for m's to stop\n+};\n+\n+// The atomic word in sched is an atomic uint32 that\n+// holds these fields.\n+//\n+//\t[15 bits] mcpu\t\tnumber of m's executing on cpu\n+//\t[15 bits] mcpumax\tmax number of m's allowed on cpu\n+//\t[1 bit] waitstop\tsome g is waiting on stopped\n+//\t[1 bit] gwaiting\tgwait != 0\n+//\n+// These fields are the information needed by entersyscall\n+// and exitsyscall to decide whether to coordinate with the\n+// scheduler.  Packing them into a single machine word lets\n+// them use a fast path with a single atomic read/write and\n+// no lock/unlock.  This greatly reduces contention in\n+// syscall- or cgo-heavy multithreaded programs.\n+//\n+// Except for entersyscall and exitsyscall, the manipulations\n+// to these fields only happen while holding the schedlock,\n+// so the routines holding schedlock only need to worry about\n+// what entersyscall and exitsyscall do, not the other routines\n+// (which also use the schedlock).\n+//\n+// In particular, entersyscall and exitsyscall only read mcpumax,\n+// waitstop, and gwaiting.  They never write them.  Thus, writes to those\n+// fields can be done (holding schedlock) without fear of write conflicts.\n+// There may still be logic conflicts: for example, the set of waitstop must\n+// be conditioned on mcpu >= mcpumax or else the wait may be a\n+// spurious sleep.  The Promela model in proc.p verifies these accesses.\n+enum {\n+\tmcpuWidth = 15,\n+\tmcpuMask = (1<<mcpuWidth) - 1,\n+\tmcpuShift = 0,\n+\tmcpumaxShift = mcpuShift + mcpuWidth,\n+\twaitstopShift = mcpumaxShift + mcpuWidth,\n+\tgwaitingShift = waitstopShift+1,\n+\n+\t// The max value of GOMAXPROCS is constrained\n+\t// by the max value we can store in the bit fields\n+\t// of the atomic word.  Reserve a few high values\n+\t// so that we can detect accidental decrement\n+\t// beyond zero.\n+\tmaxgomaxprocs = mcpuMask - 10,\n+};\n+\n+#define atomic_mcpu(v)\t\t(((v)>>mcpuShift)&mcpuMask)\n+#define atomic_mcpumax(v)\t(((v)>>mcpumaxShift)&mcpuMask)\n+#define atomic_waitstop(v)\t(((v)>>waitstopShift)&1)\n+#define atomic_gwaiting(v)\t(((v)>>gwaitingShift)&1)\n+\n+Sched runtime_sched;\n+int32 runtime_gomaxprocs;\n+bool runtime_singleproc;\n+\n+static bool canaddmcpu(void);\n+\n+// An m that is waiting for notewakeup(&m->havenextg).  This may\n+// only be accessed while the scheduler lock is held.  This is used to\n+// minimize the number of times we call notewakeup while the scheduler\n+// lock is held, since the m will normally move quickly to lock the\n+// scheduler itself, producing lock contention.\n+static M* mwakeup;\n+\n+// Scheduling helpers.  Sched must be locked.\n+static void gput(G*);\t// put/get on ghead/gtail\n+static G* gget(void);\n+static void mput(M*);\t// put/get on mhead\n+static M* mget(G*);\n+static void gfput(G*);\t// put/get on gfree\n+static G* gfget(void);\n+static void matchmg(void);\t// match m's to g's\n+static void readylocked(G*);\t// ready, but sched is locked\n+static void mnextg(M*, G*);\n+static void mcommoninit(M*);\n+\n+void\n+setmcpumax(uint32 n)\n+{\n+\tuint32 v, w;\n+\n+\tfor(;;) {\n+\t\tv = runtime_sched.atomic;\n+\t\tw = v;\n+\t\tw &= ~(mcpuMask<<mcpumaxShift);\n+\t\tw |= n<<mcpumaxShift;\n+\t\tif(runtime_cas(&runtime_sched.atomic, v, w))\n+\t\t\tbreak;\n+\t}\n+}\n+\n+// First function run by a new goroutine.  This replaces gogocall.\n+static void\n+kickoff(void)\n+{\n+\tvoid (*fn)(void*);\n+\n+\tfn = (void (*)(void*))(g->entry);\n+\tfn(g->param);\n+\truntime_goexit();\n+}\n+\n+// Switch context to a different goroutine.  This is like longjmp.\n+static void runtime_gogo(G*) __attribute__ ((noinline));\n+static void\n+runtime_gogo(G* newg)\n+{\n+#ifdef USING_SPLIT_STACK\n+\t__splitstack_setcontext(&newg->stack_context[0]);\n+#endif\n+\tg = newg;\n+\tnewg->fromgogo = true;\n+\tsetcontext(&newg->context);\n+}\n+\n+// Save context and call fn passing g as a parameter.  This is like\n+// setjmp.  Because getcontext always returns 0, unlike setjmp, we use\n+// g->fromgogo as a code.  It will be true if we got here via\n+// setcontext.  g == nil the first time this is called in a new m.\n+static void runtime_mcall(void (*)(G*)) __attribute__ ((noinline));\n+static void\n+runtime_mcall(void (*pfn)(G*))\n+{\n+#ifndef USING_SPLIT_STACK\n+\tint i;\n+#endif\n+\n+\t// Ensure that all registers are on the stack for the garbage\n+\t// collector.\n+\t__builtin_unwind_init();\n+\n+\tif(g == m->g0)\n+\t\truntime_throw(\"runtime: mcall called on m->g0 stack\");\n+\n+\tif(g != nil) {\n+\n+#ifdef USING_SPLIT_STACK\n+\t\t__splitstack_getcontext(&g->stack_context[0]);\n+#else\n+\t\tg->gcnext_sp = &i;\n+#endif\n+\t\tg->fromgogo = false;\n+\t\tgetcontext(&g->context);\n+\t}\n+\tif (g == nil || !g->fromgogo) {\n+#ifdef USING_SPLIT_STACK\n+\t\t__splitstack_setcontext(&m->g0->stack_context[0]);\n+#endif\n+\t\tm->g0->entry = (byte*)pfn;\n+\t\tm->g0->param = g;\n+\t\tg = m->g0;\n+\t\tsetcontext(&m->g0->context);\n+\t\truntime_throw(\"runtime: mcall function returned\");\n+\t}\n+}\n+\n+// The bootstrap sequence is:\n+//\n+//\tcall osinit\n+//\tcall schedinit\n+//\tmake & queue new G\n+//\tcall runtime_mstart\n+//\n+// The new G does:\n+//\n+//\tcall main_init_function\n+//\tcall initdone\n+//\tcall main_main\n+void\n+runtime_schedinit(void)\n+{\n+\tint32 n;\n+\tconst byte *p;\n+\n+\tm = &runtime_m0;\n+\tg = &runtime_g0;\n+\tm->g0 = g;\n+\tm->curg = g;\n+\tg->m = m;\n+\n+\tm->nomemprof++;\n+\truntime_mallocinit();\n+\tmcommoninit(m);\n+\n+\truntime_goargs();\n+\truntime_goenvs();\n+\n+\t// For debugging:\n+\t// Allocate internal symbol table representation now,\n+\t// so that we don't need to call malloc when we crash.\n+\t// runtime_findfunc(0);\n+\n+\truntime_gomaxprocs = 1;\n+\tp = runtime_getenv(\"GOMAXPROCS\");\n+\tif(p != nil && (n = runtime_atoi(p)) != 0) {\n+\t\tif(n > maxgomaxprocs)\n+\t\t\tn = maxgomaxprocs;\n+\t\truntime_gomaxprocs = n;\n+\t}\n+\tsetmcpumax(runtime_gomaxprocs);\n+\truntime_singleproc = runtime_gomaxprocs == 1;\n+\n+\tcanaddmcpu();\t// mcpu++ to account for bootstrap m\n+\tm->helpgc = 1;\t// flag to tell schedule() to mcpu--\n+\truntime_sched.grunning++;\n+\n+\t// Can not enable GC until all roots are registered.\n+\t// mstats.enablegc = 1;\n+\tm->nomemprof--;\n+}\n+\n+// Lock the scheduler.\n+static void\n+schedlock(void)\n+{\n+\truntime_lock(&runtime_sched);\n+}\n+\n+// Unlock the scheduler.\n+static void\n+schedunlock(void)\n+{\n+\tM *m;\n+\n+\tm = mwakeup;\n+\tmwakeup = nil;\n+\truntime_unlock(&runtime_sched);\n+\tif(m != nil)\n+\t\truntime_notewakeup(&m->havenextg);\n+}\n+\n+void\n+runtime_goexit(void)\n+{\n+\tg->status = Gmoribund;\n+\truntime_gosched();\n+}\n+\n+void\n+runtime_goroutineheader(G *g)\n+{\n+\tconst char *status;\n+\n+\tswitch(g->status) {\n+\tcase Gidle:\n+\t\tstatus = \"idle\";\n+\t\tbreak;\n+\tcase Grunnable:\n+\t\tstatus = \"runnable\";\n+\t\tbreak;\n+\tcase Grunning:\n+\t\tstatus = \"running\";\n+\t\tbreak;\n+\tcase Gsyscall:\n+\t\tstatus = \"syscall\";\n+\t\tbreak;\n+\tcase Gwaiting:\n+\t\tif(g->waitreason)\n+\t\t\tstatus = g->waitreason;\n+\t\telse\n+\t\t\tstatus = \"waiting\";\n+\t\tbreak;\n+\tcase Gmoribund:\n+\t\tstatus = \"moribund\";\n+\t\tbreak;\n+\tdefault:\n+\t\tstatus = \"???\";\n+\t\tbreak;\n+\t}\n+\truntime_printf(\"goroutine %d [%s]:\\n\", g->goid, status);\n+}\n+\n+void\n+runtime_tracebackothers(G *me)\n+{\n+\tG *g;\n+\n+\tfor(g = runtime_allg; g != nil; g = g->alllink) {\n+\t\tif(g == me || g->status == Gdead)\n+\t\t\tcontinue;\n+\t\truntime_printf(\"\\n\");\n+\t\truntime_goroutineheader(g);\n+\t\t// runtime_traceback(g->sched.pc, g->sched.sp, 0, g);\n+\t}\n+}\n+\n+// Mark this g as m's idle goroutine.\n+// This functionality might be used in environments where programs\n+// are limited to a single thread, to simulate a select-driven\n+// network server.  It is not exposed via the standard runtime API.\n+void\n+runtime_idlegoroutine(void)\n+{\n+\tif(g->idlem != nil)\n+\t\truntime_throw(\"g is already an idle goroutine\");\n+\tg->idlem = m;\n+}\n+\n+static void\n+mcommoninit(M *m)\n+{\n+\t// Add to runtime_allm so garbage collector doesn't free m\n+\t// when it is just in a register or thread-local storage.\n+\tm->alllink = runtime_allm;\n+\t// runtime_Cgocalls() iterates over allm w/o schedlock,\n+\t// so we need to publish it safely.\n+\truntime_atomicstorep((void**)&runtime_allm, m);\n+\n+\tm->id = runtime_sched.mcount++;\n+\tm->fastrand = 0x49f6428aUL + m->id;\n+\n+\tif(m->mcache == nil)\n+\t\tm->mcache = runtime_allocmcache();\n+}\n+\n+// Try to increment mcpu.  Report whether succeeded.\n+static bool\n+canaddmcpu(void)\n+{\n+\tuint32 v;\n+\n+\tfor(;;) {\n+\t\tv = runtime_sched.atomic;\n+\t\tif(atomic_mcpu(v) >= atomic_mcpumax(v))\n+\t\t\treturn 0;\n+\t\tif(runtime_cas(&runtime_sched.atomic, v, v+(1<<mcpuShift)))\n+\t\t\treturn 1;\n+\t}\n+}\n+\n+// Put on `g' queue.  Sched must be locked.\n+static void\n+gput(G *g)\n+{\n+\tM *m;\n+\n+\t// If g is wired, hand it off directly.\n+\tif((m = g->lockedm) != nil && canaddmcpu()) {\n+\t\tmnextg(m, g);\n+\t\treturn;\n+\t}\n+\n+\t// If g is the idle goroutine for an m, hand it off.\n+\tif(g->idlem != nil) {\n+\t\tif(g->idlem->idleg != nil) {\n+\t\t\truntime_printf(\"m%d idle out of sync: g%d g%d\\n\",\n+\t\t\t\tg->idlem->id,\n+\t\t\t\tg->idlem->idleg->goid, g->goid);\n+\t\t\truntime_throw(\"runtime: double idle\");\n+\t\t}\n+\t\tg->idlem->idleg = g;\n+\t\treturn;\n+\t}\n+\n+\tg->schedlink = nil;\n+\tif(runtime_sched.ghead == nil)\n+\t\truntime_sched.ghead = g;\n+\telse\n+\t\truntime_sched.gtail->schedlink = g;\n+\truntime_sched.gtail = g;\n+\n+\t// increment gwait.\n+\t// if it transitions to nonzero, set atomic gwaiting bit.\n+\tif(runtime_sched.gwait++ == 0)\n+\t\truntime_xadd(&runtime_sched.atomic, 1<<gwaitingShift);\n+}\n+\n+// Report whether gget would return something.\n+static bool\n+haveg(void)\n+{\n+\treturn runtime_sched.ghead != nil || m->idleg != nil;\n+}\n+\n+// Get from `g' queue.  Sched must be locked.\n+static G*\n+gget(void)\n+{\n+\tG *g;\n+\n+\tg = runtime_sched.ghead;\n+\tif(g){\n+\t\truntime_sched.ghead = g->schedlink;\n+\t\tif(runtime_sched.ghead == nil)\n+\t\t\truntime_sched.gtail = nil;\n+\t\t// decrement gwait.\n+\t\t// if it transitions to zero, clear atomic gwaiting bit.\n+\t\tif(--runtime_sched.gwait == 0)\n+\t\t\truntime_xadd(&runtime_sched.atomic, -1<<gwaitingShift);\n+\t} else if(m->idleg != nil) {\n+\t\tg = m->idleg;\n+\t\tm->idleg = nil;\n+\t}\n+\treturn g;\n+}\n+\n+// Put on `m' list.  Sched must be locked.\n+static void\n+mput(M *m)\n+{\n+\tm->schedlink = runtime_sched.mhead;\n+\truntime_sched.mhead = m;\n+\truntime_sched.mwait++;\n+}\n+\n+// Get an `m' to run `g'.  Sched must be locked.\n+static M*\n+mget(G *g)\n+{\n+\tM *m;\n+\n+\t// if g has its own m, use it.\n+\tif(g && (m = g->lockedm) != nil)\n+\t\treturn m;\n+\n+\t// otherwise use general m pool.\n+\tif((m = runtime_sched.mhead) != nil){\n+\t\truntime_sched.mhead = m->schedlink;\n+\t\truntime_sched.mwait--;\n+\t}\n+\treturn m;\n+}\n+\n+// Mark g ready to run.\n+void\n+runtime_ready(G *g)\n+{\n+\tschedlock();\n+\treadylocked(g);\n+\tschedunlock();\n+}\n+\n+// Mark g ready to run.  Sched is already locked.\n+// G might be running already and about to stop.\n+// The sched lock protects g->status from changing underfoot.\n+static void\n+readylocked(G *g)\n+{\n+\tif(g->m){\n+\t\t// Running on another machine.\n+\t\t// Ready it when it stops.\n+\t\tg->readyonstop = 1;\n+\t\treturn;\n+\t}\n+\n+\t// Mark runnable.\n+\tif(g->status == Grunnable || g->status == Grunning) {\n+\t\truntime_printf(\"goroutine %d has status %d\\n\", g->goid, g->status);\n+\t\truntime_throw(\"bad g->status in ready\");\n+\t}\n+\tg->status = Grunnable;\n+\n+\tgput(g);\n+\tmatchmg();\n+}\n+\n+// Same as readylocked but a different symbol so that\n+// debuggers can set a breakpoint here and catch all\n+// new goroutines.\n+static void\n+newprocreadylocked(G *g)\n+{\n+\treadylocked(g);\n+}\n+\n+// Pass g to m for running.\n+// Caller has already incremented mcpu.\n+static void\n+mnextg(M *m, G *g)\n+{\n+\truntime_sched.grunning++;\n+\tm->nextg = g;\n+\tif(m->waitnextg) {\n+\t\tm->waitnextg = 0;\n+\t\tif(mwakeup != nil)\n+\t\t\truntime_notewakeup(&mwakeup->havenextg);\n+\t\tmwakeup = m;\n+\t}\n+}\n+\n+// Get the next goroutine that m should run.\n+// Sched must be locked on entry, is unlocked on exit.\n+// Makes sure that at most $GOMAXPROCS g's are\n+// running on cpus (not in system calls) at any given time.\n+static G*\n+nextgandunlock(void)\n+{\n+\tG *gp;\n+\tuint32 v;\n+\n+top:\n+\tif(atomic_mcpu(runtime_sched.atomic) >= maxgomaxprocs)\n+\t\truntime_throw(\"negative mcpu\");\n+\n+\t// If there is a g waiting as m->nextg, the mcpu++\n+\t// happened before it was passed to mnextg.\n+\tif(m->nextg != nil) {\n+\t\tgp = m->nextg;\n+\t\tm->nextg = nil;\n+\t\tschedunlock();\n+\t\treturn gp;\n+\t}\n+\n+\tif(m->lockedg != nil) {\n+\t\t// We can only run one g, and it's not available.\n+\t\t// Make sure some other cpu is running to handle\n+\t\t// the ordinary run queue.\n+\t\tif(runtime_sched.gwait != 0) {\n+\t\t\tmatchmg();\n+\t\t\t// m->lockedg might have been on the queue.\n+\t\t\tif(m->nextg != nil) {\n+\t\t\t\tgp = m->nextg;\n+\t\t\t\tm->nextg = nil;\n+\t\t\t\tschedunlock();\n+\t\t\t\treturn gp;\n+\t\t\t}\n+\t\t}\n+\t} else {\n+\t\t// Look for work on global queue.\n+\t\twhile(haveg() && canaddmcpu()) {\n+\t\t\tgp = gget();\n+\t\t\tif(gp == nil)\n+\t\t\t\truntime_throw(\"gget inconsistency\");\n+\n+\t\t\tif(gp->lockedm) {\n+\t\t\t\tmnextg(gp->lockedm, gp);\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\t\t\truntime_sched.grunning++;\n+\t\t\tschedunlock();\n+\t\t\treturn gp;\n+\t\t}\n+\n+\t\t// The while loop ended either because the g queue is empty\n+\t\t// or because we have maxed out our m procs running go\n+\t\t// code (mcpu >= mcpumax).  We need to check that\n+\t\t// concurrent actions by entersyscall/exitsyscall cannot\n+\t\t// invalidate the decision to end the loop.\n+\t\t//\n+\t\t// We hold the sched lock, so no one else is manipulating the\n+\t\t// g queue or changing mcpumax.  Entersyscall can decrement\n+\t\t// mcpu, but if does so when there is something on the g queue,\n+\t\t// the gwait bit will be set, so entersyscall will take the slow path\n+\t\t// and use the sched lock.  So it cannot invalidate our decision.\n+\t\t//\n+\t\t// Wait on global m queue.\n+\t\tmput(m);\n+\t}\n+\n+\tv = runtime_atomicload(&runtime_sched.atomic);\n+\tif(runtime_sched.grunning == 0)\n+\t\truntime_throw(\"all goroutines are asleep - deadlock!\");\n+\tm->nextg = nil;\n+\tm->waitnextg = 1;\n+\truntime_noteclear(&m->havenextg);\n+\n+\t// Stoptheworld is waiting for all but its cpu to go to stop.\n+\t// Entersyscall might have decremented mcpu too, but if so\n+\t// it will see the waitstop and take the slow path.\n+\t// Exitsyscall never increments mcpu beyond mcpumax.\n+\tif(atomic_waitstop(v) && atomic_mcpu(v) <= atomic_mcpumax(v)) {\n+\t\t// set waitstop = 0 (known to be 1)\n+\t\truntime_xadd(&runtime_sched.atomic, -1<<waitstopShift);\n+\t\truntime_notewakeup(&runtime_sched.stopped);\n+\t}\n+\tschedunlock();\n+\n+\truntime_notesleep(&m->havenextg);\n+\tif(m->helpgc) {\n+\t\truntime_gchelper();\n+\t\tm->helpgc = 0;\n+\t\truntime_lock(&runtime_sched);\n+\t\tgoto top;\n+\t}\n+\tif((gp = m->nextg) == nil)\n+\t\truntime_throw(\"bad m->nextg in nextgoroutine\");\n+\tm->nextg = nil;\n+\treturn gp;\n+}\n+\n+int32\n+runtime_helpgc(bool *extra)\n+{\n+\tM *mp;\n+\tint32 n, max;\n+\n+\t// Figure out how many CPUs to use.\n+\t// Limited by gomaxprocs, number of actual CPUs, and MaxGcproc.\n+\tmax = runtime_gomaxprocs;\n+\tif(max > runtime_ncpu)\n+\t\tmax = runtime_ncpu > 0 ? runtime_ncpu : 1;\n+\tif(max > MaxGcproc)\n+\t\tmax = MaxGcproc;\n+\n+\t// We're going to use one CPU no matter what.\n+\t// Figure out the max number of additional CPUs.\n+\tmax--;\n+\n+\truntime_lock(&runtime_sched);\n+\tn = 0;\n+\twhile(n < max && (mp = mget(nil)) != nil) {\n+\t\tn++;\n+\t\tmp->helpgc = 1;\n+\t\tmp->waitnextg = 0;\n+\t\truntime_notewakeup(&mp->havenextg);\n+\t}\n+\truntime_unlock(&runtime_sched);\n+\tif(extra)\n+\t\t*extra = n != max;\n+\treturn n;\n+}\n+\n+void\n+runtime_stoptheworld(void)\n+{\n+\tuint32 v;\n+\n+\tschedlock();\n+\truntime_gcwaiting = 1;\n+\n+\tsetmcpumax(1);\n+\n+\t// while mcpu > 1\n+\tfor(;;) {\n+\t\tv = runtime_sched.atomic;\n+\t\tif(atomic_mcpu(v) <= 1)\n+\t\t\tbreak;\n+\n+\t\t// It would be unsafe for multiple threads to be using\n+\t\t// the stopped note at once, but there is only\n+\t\t// ever one thread doing garbage collection.\n+\t\truntime_noteclear(&runtime_sched.stopped);\n+\t\tif(atomic_waitstop(v))\n+\t\t\truntime_throw(\"invalid waitstop\");\n+\n+\t\t// atomic { waitstop = 1 }, predicated on mcpu <= 1 check above\n+\t\t// still being true.\n+\t\tif(!runtime_cas(&runtime_sched.atomic, v, v+(1<<waitstopShift)))\n+\t\t\tcontinue;\n+\n+\t\tschedunlock();\n+\t\truntime_notesleep(&runtime_sched.stopped);\n+\t\tschedlock();\n+\t}\n+\truntime_singleproc = runtime_gomaxprocs == 1;\n+\tschedunlock();\n+}\n+\n+void\n+runtime_starttheworld(bool extra)\n+{\n+\tM *m;\n+\n+\tschedlock();\n+\truntime_gcwaiting = 0;\n+\tsetmcpumax(runtime_gomaxprocs);\n+\tmatchmg();\n+\tif(extra && canaddmcpu()) {\n+\t\t// Start a new m that will (we hope) be idle\n+\t\t// and so available to help when the next\n+\t\t// garbage collection happens.\n+\t\t// canaddmcpu above did mcpu++\n+\t\t// (necessary, because m will be doing various\n+\t\t// initialization work so is definitely running),\n+\t\t// but m is not running a specific goroutine,\n+\t\t// so set the helpgc flag as a signal to m's\n+\t\t// first schedule(nil) to mcpu-- and grunning--.\n+\t\tm = startm();\n+\t\tm->helpgc = 1;\n+\t\truntime_sched.grunning++;\n+\t}\n+\tschedunlock();\n+}\n+\n+// Called to start an M.\n+void*\n+runtime_mstart(void* mp)\n+{\n+\tm = (M*)mp;\n+\tg = m->g0;\n+\n+\tg->entry = nil;\n+\tg->param = nil;\n+\n+\t// Record top of stack for use by mcall.\n+\t// Once we call schedule we're never coming back,\n+\t// so other calls can reuse this stack space.\n+#ifdef USING_SPLIT_STACK\n+\t__splitstack_getcontext(&g->stack_context[0]);\n+#else\n+\tg->gcinitial_sp = &mp;\n+\tg->gcstack_size = StackMin;\n+\tg->gcnext_sp = &mp;\n+#endif\n+\tgetcontext(&g->context);\n+\n+\tif(g->entry != nil) {\n+\t\t// Got here from mcall.\n+\t\tvoid (*pfn)(G*) = (void (*)(G*))g->entry;\n+\t\tG* gp = (G*)g->param;\n+\t\tpfn(gp);\n+\t\t*(int*)0x21 = 0x21;\n+\t}\n+\truntime_minit();\n+\tschedule(nil);\n+\treturn nil;\n+}\n+\n+typedef struct CgoThreadStart CgoThreadStart;\n+struct CgoThreadStart\n+{\n+\tM *m;\n+\tG *g;\n+\tvoid (*fn)(void);\n+};\n+\n+// Kick off new m's as needed (up to mcpumax).\n+// There are already `other' other cpus that will\n+// start looking for goroutines shortly.\n+// Sched is locked.\n+static void\n+matchmg(void)\n+{\n+\tG *gp;\n+\tM *mp;\n+\n+\tif(m->mallocing || m->gcing)\n+\t\treturn;\n+\n+\twhile(haveg() && canaddmcpu()) {\n+\t\tgp = gget();\n+\t\tif(gp == nil)\n+\t\t\truntime_throw(\"gget inconsistency\");\n+\n+\t\t// Find the m that will run gp.\n+\t\tif((mp = mget(gp)) == nil)\n+\t\t\tmp = startm();\n+\t\tmnextg(mp, gp);\n+\t}\n+}\n+\n+static M*\n+startm(void)\n+{\n+\tM *m;\n+\tpthread_attr_t attr;\n+\tpthread_t tid;\n+\n+\tm = runtime_malloc(sizeof(M));\n+\tmcommoninit(m);\n+\tm->g0 = runtime_malg(-1, nil, nil);\n+\n+\tif(pthread_attr_init(&attr) != 0)\n+\t\truntime_throw(\"pthread_attr_init\");\n+\tif(pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED) != 0)\n+\t\truntime_throw(\"pthread_attr_setdetachstate\");\n+\n+#ifndef PTHREAD_STACK_MIN\n+#define PTHREAD_STACK_MIN 8192\n+#endif\n+\tif(pthread_attr_setstacksize(&attr, PTHREAD_STACK_MIN) != 0)\n+\t\truntime_throw(\"pthread_attr_setstacksize\");\n+\n+\tif(pthread_create(&tid, &attr, runtime_mstart, m) != 0)\n+\t\truntime_throw(\"pthread_create\");\n+\n+\treturn m;\n+}\n+\n+// One round of scheduler: find a goroutine and run it.\n+// The argument is the goroutine that was running before\n+// schedule was called, or nil if this is the first call.\n+// Never returns.\n+static void\n+schedule(G *gp)\n+{\n+\tint32 hz;\n+\tuint32 v;\n+\n+\tschedlock();\n+\tif(gp != nil) {\n+\t\t// Just finished running gp.\n+\t\tgp->m = nil;\n+\t\truntime_sched.grunning--;\n+\n+\t\t// atomic { mcpu-- }\n+\t\tv = runtime_xadd(&runtime_sched.atomic, -1<<mcpuShift);\n+\t\tif(atomic_mcpu(v) > maxgomaxprocs)\n+\t\t\truntime_throw(\"negative mcpu in scheduler\");\n+\n+\t\tswitch(gp->status){\n+\t\tcase Grunnable:\n+\t\tcase Gdead:\n+\t\t\t// Shouldn't have been running!\n+\t\t\truntime_throw(\"bad gp->status in sched\");\n+\t\tcase Grunning:\n+\t\t\tgp->status = Grunnable;\n+\t\t\tgput(gp);\n+\t\t\tbreak;\n+\t\tcase Gmoribund:\n+\t\t\tgp->status = Gdead;\n+\t\t\tif(gp->lockedm) {\n+\t\t\t\tgp->lockedm = nil;\n+\t\t\t\tm->lockedg = nil;\n+\t\t\t}\n+\t\t\tgp->idlem = nil;\n+\t\t\tgfput(gp);\n+\t\t\tif(--runtime_sched.gcount == 0)\n+\t\t\t\truntime_exit(0);\n+\t\t\tbreak;\n+\t\t}\n+\t\tif(gp->readyonstop){\n+\t\t\tgp->readyonstop = 0;\n+\t\t\treadylocked(gp);\n+\t\t}\n+\t} else if(m->helpgc) {\n+\t\t// Bootstrap m or new m started by starttheworld.\n+\t\t// atomic { mcpu-- }\n+\t\tv = runtime_xadd(&runtime_sched.atomic, -1<<mcpuShift);\n+\t\tif(atomic_mcpu(v) > maxgomaxprocs)\n+\t\t\truntime_throw(\"negative mcpu in scheduler\");\n+\t\t// Compensate for increment in starttheworld().\n+\t\truntime_sched.grunning--;\n+\t\tm->helpgc = 0;\n+\t} else if(m->nextg != nil) {\n+\t\t// New m started by matchmg.\n+\t} else {\n+\t\truntime_throw(\"invalid m state in scheduler\");\n+\t}\n+\n+\t// Find (or wait for) g to run.  Unlocks runtime_sched.\n+\tgp = nextgandunlock();\n+\tgp->readyonstop = 0;\n+\tgp->status = Grunning;\n+\tm->curg = gp;\n+\tgp->m = m;\n+\n+\t// Check whether the profiler needs to be turned on or off.\n+\thz = runtime_sched.profilehz;\n+\tif(m->profilehz != hz)\n+\t\truntime_resetcpuprofiler(hz);\n+\n+\truntime_gogo(gp);\n+}\n+\n+// Enter scheduler.  If g->status is Grunning,\n+// re-queues g and runs everyone else who is waiting\n+// before running g again.  If g->status is Gmoribund,\n+// kills off g.\n+void\n+runtime_gosched(void)\n+{\n+\tif(m->locks != 0)\n+\t\truntime_throw(\"gosched holding locks\");\n+\tif(g == m->g0)\n+\t\truntime_throw(\"gosched of g0\");\n+\truntime_mcall(schedule);\n+}\n+\n+// The goroutine g is about to enter a system call.\n+// Record that it's not using the cpu anymore.\n+// This is called only from the go syscall library and cgocall,\n+// not from the low-level system calls used by the runtime.\n+//\n+// Entersyscall cannot split the stack: the runtime_gosave must\n+// make g->sched refer to the caller's stack segment, because\n+// entersyscall is going to return immediately after.\n+// It's okay to call matchmg and notewakeup even after\n+// decrementing mcpu, because we haven't released the\n+// sched lock yet, so the garbage collector cannot be running.\n+\n+void runtime_entersyscall(void) __attribute__ ((no_split_stack));\n+\n+void\n+runtime_entersyscall(void)\n+{\n+\tuint32 v;\n+\n+\t// Leave SP around for gc and traceback.\n+#ifdef USING_SPLIT_STACK\n+\tg->gcstack = __splitstack_find(NULL, NULL, &g->gcstack_size,\n+\t\t\t\t       &g->gcnext_segment, &g->gcnext_sp,\n+\t\t\t\t       &g->gcinitial_sp);\n+#else\n+\tg->gcnext_sp = (byte *) &v;\n+#endif\n+\n+\t// Save the registers in the g structure so that any pointers\n+\t// held in registers will be seen by the garbage collector.\n+\t// We could use getcontext here, but setjmp is more efficient\n+\t// because it doesn't need to save the signal mask.\n+\tsetjmp(g->gcregs);\n+\n+\tg->status = Gsyscall;\n+\n+\t// Fast path.\n+\t// The slow path inside the schedlock/schedunlock will get\n+\t// through without stopping if it does:\n+\t//\tmcpu--\n+\t//\tgwait not true\n+\t//\twaitstop && mcpu <= mcpumax not true\n+\t// If we can do the same with a single atomic add,\n+\t// then we can skip the locks.\n+\tv = runtime_xadd(&runtime_sched.atomic, -1<<mcpuShift);\n+\tif(!atomic_gwaiting(v) && (!atomic_waitstop(v) || atomic_mcpu(v) > atomic_mcpumax(v)))\n+\t\treturn;\n+\n+\tschedlock();\n+\tv = runtime_atomicload(&runtime_sched.atomic);\n+\tif(atomic_gwaiting(v)) {\n+\t\tmatchmg();\n+\t\tv = runtime_atomicload(&runtime_sched.atomic);\n+\t}\n+\tif(atomic_waitstop(v) && atomic_mcpu(v) <= atomic_mcpumax(v)) {\n+\t\truntime_xadd(&runtime_sched.atomic, -1<<waitstopShift);\n+\t\truntime_notewakeup(&runtime_sched.stopped);\n+\t}\n+\n+\tschedunlock();\n+}\n+\n+// The goroutine g exited its system call.\n+// Arrange for it to run on a cpu again.\n+// This is called only from the go syscall library, not\n+// from the low-level system calls used by the runtime.\n+void\n+runtime_exitsyscall(void)\n+{\n+\tG *gp;\n+\tuint32 v;\n+\n+\t// Fast path.\n+\t// If we can do the mcpu++ bookkeeping and\n+\t// find that we still have mcpu <= mcpumax, then we can\n+\t// start executing Go code immediately, without having to\n+\t// schedlock/schedunlock.\n+\tgp = g;\n+\tv = runtime_xadd(&runtime_sched.atomic, (1<<mcpuShift));\n+\tif(m->profilehz == runtime_sched.profilehz && atomic_mcpu(v) <= atomic_mcpumax(v)) {\n+\t\t// There's a cpu for us, so we can run.\n+\t\tgp->status = Grunning;\n+\t\t// Garbage collector isn't running (since we are),\n+\t\t// so okay to clear gcstack.\n+#ifdef USING_SPLIT_STACK\n+\t\tgp->gcstack = nil;\n+#endif\n+\t\tgp->gcnext_sp = nil;\n+\t\truntime_memclr(gp->gcregs, sizeof gp->gcregs);\n+\t\treturn;\n+\t}\n+\n+\t// Tell scheduler to put g back on the run queue:\n+\t// mostly equivalent to g->status = Grunning,\n+\t// but keeps the garbage collector from thinking\n+\t// that g is running right now, which it's not.\n+\tgp->readyonstop = 1;\n+\n+\t// All the cpus are taken.\n+\t// The scheduler will ready g and put this m to sleep.\n+\t// When the scheduler takes g away from m,\n+\t// it will undo the runtime_sched.mcpu++ above.\n+\truntime_gosched();\n+\n+\t// Gosched returned, so we're allowed to run now.\n+\t// Delete the gcstack information that we left for\n+\t// the garbage collector during the system call.\n+\t// Must wait until now because until gosched returns\n+\t// we don't know for sure that the garbage collector\n+\t// is not running.\n+#ifdef USING_SPLIT_STACK\n+\tgp->gcstack = nil;\n+#endif\n+\tgp->gcnext_sp = nil;\n+\truntime_memclr(gp->gcregs, sizeof gp->gcregs);\n+}\n+\n+G*\n+runtime_malg(int32 stacksize, byte** ret_stack, size_t* ret_stacksize)\n+{\n+\tG *newg;\n+\n+\tnewg = runtime_malloc(sizeof(G));\n+\tif(stacksize >= 0) {\n+#if USING_SPLIT_STACK\n+\t\t*ret_stack = __splitstack_makecontext(stacksize,\n+\t\t\t\t\t\t      &newg->stack_context[0],\n+\t\t\t\t\t\t      ret_stacksize);\n+#else\n+\t\t*ret_stack = runtime_mallocgc(stacksize, FlagNoProfiling|FlagNoGC, 0, 0);\n+\t\t*ret_stacksize = stacksize;\n+\t\tnewg->gcinitial_sp = *ret_stack;\n+\t\tnewg->gcstack_size = stacksize;\n+#endif\n+\t}\n+\treturn newg;\n+}\n+\n+G*\n+__go_go(void (*fn)(void*), void* arg)\n+{\n+\tbyte *sp;\n+\tsize_t spsize;\n+\tG * volatile newg;\t// volatile to avoid longjmp warning\n+\n+\tschedlock();\n+\n+\tif((newg = gfget()) != nil){\n+#ifdef USING_SPLIT_STACK\n+\t\tsp = __splitstack_resetcontext(&newg->stack_context[0],\n+\t\t\t\t\t       &spsize);\n+#else\n+\t\tsp = newg->gcinitial_sp;\n+\t\tspsize = newg->gcstack_size;\n+\t\tnewg->gcnext_sp = sp;\n+#endif\n+\t} else {\n+\t\tnewg = runtime_malg(StackMin, &sp, &spsize);\n+\t\tif(runtime_lastg == nil)\n+\t\t\truntime_allg = newg;\n+\t\telse\n+\t\t\truntime_lastg->alllink = newg;\n+\t\truntime_lastg = newg;\n+\t}\n+\tnewg->status = Gwaiting;\n+\tnewg->waitreason = \"new goroutine\";\n+\n+\tnewg->entry = (byte*)fn;\n+\tnewg->param = arg;\n+\tnewg->gopc = (uintptr)__builtin_return_address(0);\n+\n+\truntime_sched.gcount++;\n+\truntime_sched.goidgen++;\n+\tnewg->goid = runtime_sched.goidgen;\n+\n+\tif(sp == nil)\n+\t\truntime_throw(\"nil g->stack0\");\n+\n+\tgetcontext(&newg->context);\n+\tnewg->context.uc_stack.ss_sp = sp;\n+\tnewg->context.uc_stack.ss_size = spsize;\n+\tmakecontext(&newg->context, kickoff, 0);\n+\n+\tnewprocreadylocked(newg);\n+\tschedunlock();\n+\n+\treturn newg;\n+//printf(\" goid=%d\\n\", newg->goid);\n+}\n+\n+// Put on gfree list.  Sched must be locked.\n+static void\n+gfput(G *g)\n+{\n+\tg->schedlink = runtime_sched.gfree;\n+\truntime_sched.gfree = g;\n+}\n+\n+// Get from gfree list.  Sched must be locked.\n+static G*\n+gfget(void)\n+{\n+\tG *g;\n+\n+\tg = runtime_sched.gfree;\n+\tif(g)\n+\t\truntime_sched.gfree = g->schedlink;\n+\treturn g;\n+}\n+\n+// Run all deferred functions for the current goroutine.\n+static void\n+rundefer(void)\n+{\n+\tDefer *d;\n+\n+\twhile((d = g->defer) != nil) {\n+\t\tvoid (*pfn)(void*);\n+\n+\t\tpfn = d->__pfn;\n+\t\td->__pfn = nil;\n+\t\tif (pfn != nil)\n+\t\t\t(*pfn)(d->__arg);\n+\t\tg->defer = d->__next;\n+\t\truntime_free(d);\n+\t}\n+}\n+\n+void runtime_Goexit (void) asm (\"libgo_runtime.runtime.Goexit\");\n+\n+void\n+runtime_Goexit(void)\n+{\n+\trundefer();\n+\truntime_goexit();\n+}\n+\n+void runtime_Gosched (void) asm (\"libgo_runtime.runtime.Gosched\");\n+\n+void\n+runtime_Gosched(void)\n+{\n+\truntime_gosched();\n+}\n+\n+void runtime_LockOSThread (void)\n+  __asm__ (\"libgo_runtime.runtime.LockOSThread\");\n+\n+void\n+runtime_LockOSThread(void)\n+{\n+\tm->lockedg = g;\n+\tg->lockedm = m;\n+}\n+\n+// delete when scheduler is stronger\n+int32\n+runtime_gomaxprocsfunc(int32 n)\n+{\n+\tint32 ret;\n+\tuint32 v;\n+\n+\tschedlock();\n+\tret = runtime_gomaxprocs;\n+\tif(n <= 0)\n+\t\tn = ret;\n+\tif(n > maxgomaxprocs)\n+\t\tn = maxgomaxprocs;\n+\truntime_gomaxprocs = n;\n+\tif(runtime_gomaxprocs > 1)\n+\t\truntime_singleproc = false;\n+ \tif(runtime_gcwaiting != 0) {\n+ \t\tif(atomic_mcpumax(runtime_sched.atomic) != 1)\n+ \t\t\truntime_throw(\"invalid mcpumax during gc\");\n+\t\tschedunlock();\n+\t\treturn ret;\n+\t}\n+\n+\tsetmcpumax(n);\n+\n+\t// If there are now fewer allowed procs\n+\t// than procs running, stop.\n+\tv = runtime_atomicload(&runtime_sched.atomic);\n+\tif((int32)atomic_mcpu(v) > n) {\n+\t\tschedunlock();\n+\t\truntime_gosched();\n+\t\treturn ret;\n+\t}\n+\t// handle more procs\n+\tmatchmg();\n+\tschedunlock();\n+\treturn ret;\n+}\n+\n+void runtime_UnlockOSThread (void)\n+  __asm__ (\"libgo_runtime.runtime.UnlockOSThread\");\n+\n+void\n+runtime_UnlockOSThread(void)\n+{\n+\tm->lockedg = nil;\n+\tg->lockedm = nil;\n+}\n+\n+bool\n+runtime_lockedOSThread(void)\n+{\n+\treturn g->lockedm != nil && m->lockedg != nil;\n+}\n+\n+// for testing of wire, unwire\n+uint32\n+runtime_mid()\n+{\n+\treturn m->id;\n+}\n+\n+int32 runtime_Goroutines (void)\n+  __asm__ (\"libgo_runtime.runtime.Goroutines\");\n+\n+int32\n+runtime_Goroutines()\n+{\n+\treturn runtime_sched.gcount;\n+}\n+\n+int32\n+runtime_mcount(void)\n+{\n+\treturn runtime_sched.mcount;\n+}\n \n static struct {\n \tLock;\n@@ -28,22 +1330,22 @@ static struct {\n void\n runtime_sigprof(uint8 *pc __attribute__ ((unused)),\n \t\tuint8 *sp __attribute__ ((unused)),\n-\t\tuint8 *lr __attribute__ ((unused)))\n+\t\tuint8 *lr __attribute__ ((unused)),\n+\t\tG *gp __attribute__ ((unused)))\n {\n-\tint32 n;\n-\t\n+\t// int32 n;\n+\n \tif(prof.fn == nil || prof.hz == 0)\n \t\treturn;\n-\t\n+\n \truntime_lock(&prof);\n \tif(prof.fn == nil) {\n \t\truntime_unlock(&prof);\n \t\treturn;\n \t}\n-\tn = 0;\n-\t// n = runtime\u00b7gentraceback(pc, sp, lr, gp, 0, prof.pcbuf, nelem(prof.pcbuf));\n-\tif(n > 0)\n-\t\tprof.fn(prof.pcbuf, n);\n+\t// n = runtime_gentraceback(pc, sp, lr, gp, 0, prof.pcbuf, nelem(prof.pcbuf));\n+\t// if(n > 0)\n+\t// \tprof.fn(prof.pcbuf, n);\n \truntime_unlock(&prof);\n }\n \n@@ -67,28 +1369,10 @@ runtime_setcpuprofilerate(void (*fn)(uintptr*, int32), int32 hz)\n \tprof.fn = fn;\n \tprof.hz = hz;\n \truntime_unlock(&prof);\n-\t// runtime_lock(&runtime_sched);\n-\t// runtime_sched.profilehz = hz;\n-\t// runtime_unlock(&runtime_sched);\n-\t\n+\truntime_lock(&runtime_sched);\n+\truntime_sched.profilehz = hz;\n+\truntime_unlock(&runtime_sched);\n+\n \tif(hz != 0)\n \t\truntime_resetcpuprofiler(hz);\n }\n-\n-/* The entersyscall and exitsyscall functions aren't used for anything\n-   yet.  Eventually they will be used to switch to a new OS thread\n-   when making a potentially-blocking library call.  */\n-\n-void runtime_entersyscall() __asm__(\"libgo_syscall.syscall.entersyscall\");\n-\n-void\n-runtime_entersyscall()\n-{\n-}\n-\n-void runtime_exitsyscall() __asm__(\"libgo_syscall.syscall.exitsyscall\");\n-\n-void\n-runtime_exitsyscall()\n-{\n-}"}, {"sha": "de4c982620f42c64cb96b8c190f82eebc4e48473", "filename": "libgo/runtime/runtime.c", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fruntime.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fruntime.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fruntime.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -16,6 +16,9 @@ static Lock paniclk;\n void\n runtime_startpanic(void)\n {\n+\tM *m;\n+\n+\tm = runtime_m();\n \tif(m->dying) {\n \t\truntime_printf(\"panic during panic\\n\");\n \t\truntime_exit(3);\n@@ -156,8 +159,10 @@ runtime_atoi(const byte *p)\n uint32\n runtime_fastrand1(void)\n {\n+\tM *m;\n \tuint32 x;\n \n+\tm = runtime_m();\n \tx = m->fastrand;\n \tx += x;\n \tif(x & 0x80000000L)"}, {"sha": "818465cb897f2e40a6210de0ae9958c533fabb31", "filename": "libgo/runtime/runtime.h", "status": "modified", "additions": 71, "deletions": 39, "changes": 110, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fruntime.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fruntime.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fruntime.h?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -8,6 +8,7 @@\n \n #define _GNU_SOURCE\n #include \"go-assert.h\"\n+#include <setjmp.h>\n #include <signal.h>\n #include <stdio.h>\n #include <stdlib.h>\n@@ -17,6 +18,7 @@\n #include <fcntl.h>\n #include <pthread.h>\n #include <semaphore.h>\n+#include <ucontext.h>\n \n #ifdef HAVE_SYS_MMAN_H\n #include <sys/mman.h>\n@@ -59,24 +61,33 @@ typedef\tstruct\t__go_panic_stack\tPanic;\n typedef\tstruct\t__go_open_array\t\tSlice;\n typedef\tstruct\t__go_string\t\tString;\n \n-/* Per CPU declarations.  */\n-\n-#ifdef __rtems__\n-#define __thread\n-#endif\n-\n-extern __thread\t\tG*\tg;\n-extern __thread\t\tM* \tm;\n+/*\n+ * per-cpu declaration.\n+ */\n+extern M*\truntime_m(void);\n+extern G*\truntime_g(void);\n \n extern M\truntime_m0;\n extern G\truntime_g0;\n \n-#ifdef __rtems__\n-#undef __thread\n-#endif\n-\n-/* Constants.  */\n-\n+/*\n+ * defined constants\n+ */\n+enum\n+{\n+\t// G status\n+\t//\n+\t// If you add to this list, add to the list\n+\t// of \"okay during garbage collection\" status\n+\t// in mgc0.c too.\n+\tGidle,\n+\tGrunnable,\n+\tGrunning,\n+\tGsyscall,\n+\tGwaiting,\n+\tGmoribund,\n+\tGdead,\n+};\n enum\n {\n \ttrue\t= 1,\n@@ -102,12 +113,19 @@ struct\tG\n \tPanic*\tpanic;\n \tvoid*\texception;\t// current exception being thrown\n \tbool\tis_foreign;\t// whether current exception from other language\n+\tvoid\t*gcstack;\t// if status==Gsyscall, gcstack = stackbase to use during gc\n+\tuintptr\tgcstack_size;\n+\tvoid*\tgcnext_segment;\n+\tvoid*\tgcnext_sp;\n+\tvoid*\tgcinitial_sp;\n+\tjmp_buf\tgcregs;\n \tbyte*\tentry;\t\t// initial function\n \tG*\talllink;\t// on allg\n \tvoid*\tparam;\t\t// passed parameter on wakeup\n+\tbool\tfromgogo;\t// reached from gogo\n \tint16\tstatus;\n \tint32\tgoid;\n-\tint8*\twaitreason;\t// if status==Gwaiting\n+\tconst char*\twaitreason;\t// if status==Gwaiting\n \tG*\tschedlink;\n \tbool\treadyonstop;\n \tbool\tispanic;\n@@ -118,38 +136,38 @@ struct\tG\n \t// uintptr\tsigcode0;\n \t// uintptr\tsigcode1;\n \t// uintptr\tsigpc;\n-\t// uintptr\tgopc;\t// pc of go statement that created this goroutine\n+\tuintptr\tgopc;\t// pc of go statement that created this goroutine\n+\n+\tucontext_t\tcontext;\n+\tvoid*\t\tstack_context[10];\n };\n \n struct\tM\n {\n+\tG*\tg0;\t\t// goroutine with scheduling stack\n+\tG*\tgsignal;\t// signal-handling G\n \tG*\tcurg;\t\t// current running goroutine\n \tint32\tid;\n \tint32\tmallocing;\n \tint32\tgcing;\n \tint32\tlocks;\n \tint32\tnomemprof;\n-\tint32\tgcing_for_prof;\n-\tint32\tholds_finlock;\n-\tint32\tgcing_for_finlock;\n+\tint32\twaitnextg;\n \tint32\tdying;\n \tint32\tprofilehz;\n+\tint32\thelpgc;\n \tuint32\tfastrand;\n+\tNote\thavenextg;\n+\tG*\tnextg;\n+\tM*\talllink;\t// on allm\n+\tM*\tschedlink;\n \tMCache\t*mcache;\n+\tG*\tlockedg;\n+\tG*\tidleg;\n \tM*\tnextwaitm;\t// next M waiting for lock\n \tuintptr\twaitsema;\t// semaphore for parking on locks\n \tuint32\twaitsemacount;\n \tuint32\twaitsemalock;\n-\n-\t/* For the list of all threads.  */\n-\tstruct __go_thread_id *list_entry;\n-\n-\t/* For the garbage collector.  */\n-\tvoid\t*gc_sp;\n-\tsize_t\tgc_len;\n-\tvoid\t*gc_next_segment;\n-\tvoid\t*gc_next_sp;\n-\tvoid\t*gc_initial_sp;\n };\n \n /* Macros.  */\n@@ -171,7 +189,13 @@ enum {\n /*\n  * external data\n  */\n+G*\truntime_allg;\n+G*\truntime_lastg;\n+M*\truntime_allm;\n+extern\tint32\truntime_gomaxprocs;\n+extern\tbool\truntime_singleproc;\n extern\tuint32\truntime_panicking;\n+extern\tint32\truntime_gcwaiting;\t\t// gc is waiting to run\n int32\truntime_ncpu;\n \n /*\n@@ -188,21 +212,24 @@ void\truntime_goargs(void);\n void\truntime_goenvs(void);\n void\truntime_throw(const char*);\n void*\truntime_mal(uintptr);\n+void\truntime_schedinit(void);\n+void\truntime_initsig(int32);\n String\truntime_gostringnocopy(byte*);\n+void*\truntime_mstart(void*);\n+G*\truntime_malg(int32, byte**, size_t*);\n+void\truntime_minit(void);\n void\truntime_mallocinit(void);\n+void\truntime_gosched(void);\n+void\truntime_goexit(void);\n+void\truntime_entersyscall(void) __asm__(\"libgo_syscall.syscall.entersyscall\");\n+void\truntime_exitsyscall(void) __asm__(\"libgo_syscall.syscall.exitsyscall\");\n void\tsiginit(void);\n bool\t__go_sigsend(int32 sig);\n int64\truntime_nanotime(void);\n \n void\truntime_stoptheworld(void);\n void\truntime_starttheworld(bool);\n-void\t__go_go(void (*pfn)(void*), void*);\n-void\t__go_gc_goroutine_init(void*);\n-void\t__go_enable_gc(void);\n-int\t__go_run_goroutine_gc(int);\n-void\t__go_scanstacks(void (*scan)(byte *, int64));\n-void\t__go_stealcache(void);\n-void\t__go_cachestats(void);\n+G*\t__go_go(void (*pfn)(void*), void*);\n \n /*\n  * mutual exclusion locks.  in the uncontended case,\n@@ -274,14 +301,16 @@ bool\truntime_addfinalizer(void*, void(*fn)(void*), const struct __go_func_type *\n \n void\truntime_dopanic(int32) __attribute__ ((noreturn));\n void\truntime_startpanic(void);\n+void\truntime_ready(G*);\n const byte*\truntime_getenv(const char*);\n int32\truntime_atoi(const byte*);\n-void\truntime_sigprof(uint8 *pc, uint8 *sp, uint8 *lr);\n+void\truntime_sigprof(uint8 *pc, uint8 *sp, uint8 *lr, G *gp);\n void\truntime_resetcpuprofiler(int32);\n void\truntime_setcpuprofilerate(void(*)(uintptr*, int32), int32);\n uint32\truntime_fastrand1(void);\n-void\truntime_semacquire (uint32 *) asm (\"libgo_runtime.runtime.Semacquire\");\n-void\truntime_semrelease (uint32 *) asm (\"libgo_runtime.runtime.Semrelease\");\n+void\truntime_semacquire(uint32 volatile *);\n+void\truntime_semrelease(uint32 volatile *);\n+int32\truntime_gomaxprocsfunc(int32 n);\n void\truntime_procyield(uint32);\n void\truntime_osyield(void);\n void\truntime_usleep(uint32);\n@@ -294,3 +323,6 @@ void reflect_call(const struct __go_func_type *, const void *, _Bool, _Bool,\n #ifdef __rtems__\n void __wrap_rtems_task_variable_add(void **);\n #endif\n+\n+/* Temporary.  */\n+void\truntime_cond_wait(pthread_cond_t*, pthread_mutex_t*);"}, {"sha": "4cd98041717f3137352e74a42a6ec9d4ec5c000c", "filename": "libgo/runtime/runtime1.goc", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fruntime1.goc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fruntime1.goc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fruntime1.goc?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -0,0 +1,10 @@\n+// Copyright 2010 The Go Authors.  All rights reserved.\n+// Use of this source code is governed by a BSD-style\n+// license that can be found in the LICENSE file.\n+\n+package runtime\n+#include \"runtime.h\"\n+\n+func GOMAXPROCS(n int32) (ret int32) {\n+\tret = runtime_gomaxprocsfunc(n);\n+}"}, {"sha": "dd58cf38fb88f6e4893242ea6a8f479673348052", "filename": "libgo/runtime/sema.goc", "status": "added", "additions": 181, "deletions": 0, "changes": 181, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fsema.goc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fsema.goc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fsema.goc?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -0,0 +1,181 @@\n+// Copyright 2009 The Go Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style\n+// license that can be found in the LICENSE file.\n+\n+// Semaphore implementation exposed to Go.\n+// Intended use is provide a sleep and wakeup\n+// primitive that can be used in the contended case\n+// of other synchronization primitives.\n+// Thus it targets the same goal as Linux's futex,\n+// but it has much simpler semantics.\n+//\n+// That is, don't think of these as semaphores.\n+// Think of them as a way to implement sleep and wakeup\n+// such that every sleep is paired with a single wakeup,\n+// even if, due to races, the wakeup happens before the sleep.\n+//\n+// See Mullender and Cox, ``Semaphores in Plan 9,''\n+// http://swtch.com/semaphore.pdf\n+\n+package runtime\n+#include \"runtime.h\"\n+#include \"arch.h\"\n+\n+typedef struct Sema Sema;\n+struct Sema\n+{\n+\tuint32 volatile *addr;\n+\tG *g;\n+\tSema *prev;\n+\tSema *next;\n+};\n+\n+typedef struct SemaRoot SemaRoot;\n+struct SemaRoot\n+{\n+        Lock;\n+\tSema *head;\n+\tSema *tail;\n+\t// Number of waiters. Read w/o the lock.\n+\tuint32 volatile nwait;\n+};\n+\n+// Prime to not correlate with any user patterns.\n+#define SEMTABLESZ 251\n+\n+static union\n+{\n+\tSemaRoot;\n+\tuint8 pad[CacheLineSize];\n+} semtable[SEMTABLESZ];\n+\n+static SemaRoot*\n+semroot(uint32 volatile *addr)\n+{\n+\treturn &semtable[((uintptr)addr >> 3) % SEMTABLESZ];\n+}\n+\n+static void\n+semqueue(SemaRoot *root, uint32 volatile *addr, Sema *s)\n+{\n+\ts->g = runtime_g();\n+\ts->addr = addr;\n+\ts->next = nil;\n+\ts->prev = root->tail;\n+\tif(root->tail)\n+\t\troot->tail->next = s;\n+\telse\n+\t\troot->head = s;\n+\troot->tail = s;\n+}\n+\n+static void\n+semdequeue(SemaRoot *root, Sema *s)\n+{\n+\tif(s->next)\n+\t\ts->next->prev = s->prev;\n+\telse\n+\t\troot->tail = s->prev;\n+\tif(s->prev)\n+\t\ts->prev->next = s->next;\n+\telse\n+\t\troot->head = s->next;\n+\ts->prev = nil;\n+\ts->next = nil;\n+}\n+\n+static int32\n+cansemacquire(uint32 volatile *addr)\n+{\n+\tuint32 v;\n+\n+\twhile((v = runtime_atomicload(addr)) > 0)\n+\t\tif(runtime_cas(addr, v, v-1))\n+\t\t\treturn 1;\n+\treturn 0;\n+}\n+\n+void\n+runtime_semacquire(uint32 volatile *addr)\n+{\n+\tG *g;\n+\tSema s;\n+\tSemaRoot *root;\n+\n+\t// Easy case.\n+\tif(cansemacquire(addr))\n+\t\treturn;\n+\n+\t// Harder case:\n+\t//\tincrement waiter count\n+\t//\ttry cansemacquire one more time, return if succeeded\n+\t//\tenqueue itself as a waiter\n+\t//\tsleep\n+\t//\t(waiter descriptor is dequeued by signaler)\n+\tg = runtime_g();\n+\troot = semroot(addr);\n+\tfor(;;) {\n+\n+\t\truntime_lock(root);\n+\t\t// Add ourselves to nwait to disable \"easy case\" in semrelease.\n+\t\truntime_xadd(&root->nwait, 1);\n+\t\t// Check cansemacquire to avoid missed wakeup.\n+\t\tif(cansemacquire(addr)) {\n+\t\t\truntime_xadd(&root->nwait, -1);\n+\t\t\truntime_unlock(root);\n+\t\t\treturn;\n+\t\t}\n+\t\t// Any semrelease after the cansemacquire knows we're waiting\n+\t\t// (we set nwait above), so go to sleep.\n+\t\tsemqueue(root, addr, &s);\n+\t\tg->status = Gwaiting;\n+\t\tg->waitreason = \"semacquire\";\n+\t\truntime_unlock(root);\n+\t\truntime_gosched();\n+\t\tif(cansemacquire(addr))\n+\t\t\treturn;\n+\t}\n+}\n+\n+void\n+runtime_semrelease(uint32 volatile *addr)\n+{\n+\tSema *s;\n+\tSemaRoot *root;\n+\n+\troot = semroot(addr);\n+\truntime_xadd(addr, 1);\n+\n+\t// Easy case: no waiters?\n+\t// This check must happen after the xadd, to avoid a missed wakeup\n+\t// (see loop in semacquire).\n+\tif(runtime_atomicload(&root->nwait) == 0)\n+\t\treturn;\n+\n+\t// Harder case: search for a waiter and wake it.\n+\truntime_lock(root);\n+\tif(runtime_atomicload(&root->nwait) == 0) {\n+\t\t// The count is already consumed by another goroutine,\n+\t\t// so no need to wake up another goroutine.\n+\t\truntime_unlock(root);\n+\t\treturn;\n+\t}\n+\tfor(s = root->head; s; s = s->next) {\n+\t\tif(s->addr == addr) {\n+\t\t\truntime_xadd(&root->nwait, -1);\n+\t\t\tsemdequeue(root, s);\n+\t\t\tbreak;\n+\t\t}\n+\t}\n+\truntime_unlock(root);\n+\tif(s)\n+\t\truntime_ready(s->g);\n+}\n+\n+func Semacquire(addr *uint32) {\n+\truntime_semacquire(addr);\n+}\n+\n+func Semrelease(addr *uint32) {\n+\truntime_semrelease(addr);\n+}"}, {"sha": "502dc442c8379bc70e2236373e42e954f12c24d4", "filename": "libgo/runtime/sigqueue.goc", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fsigqueue.goc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fsigqueue.goc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fsigqueue.goc?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -81,9 +81,9 @@ __go_sigsend(int32 s)\n \n // Called to receive a bitmask of queued signals.\n func Sigrecv() (m uint32) {\n-\t// runtime\u00b7entersyscall();\n+\truntime_entersyscall();\n \truntime_notesleep(&sig);\n-\t// runtime\u00b7exitsyscall();\n+\truntime_exitsyscall();\n \truntime_noteclear(&sig);\n \tfor(;;) {\n \t\tm = sig.mask;\n@@ -110,5 +110,6 @@ func Signame(sig int32) (name String) {\n }\n \n func Siginit() {\n+\truntime_initsig(1);\n \tsig.inuse = true;\t// enable reception of signals; cannot disable\n }"}, {"sha": "b51f4970d258ec84162a4cd8cbe8863325712179", "filename": "libgo/runtime/thread-linux.c", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fthread-linux.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fthread-linux.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fthread-linux.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -66,7 +66,8 @@ static int32\n getproccount(void)\n {\n \tint32 fd, rd, cnt, cpustrlen;\n-\tconst byte *cpustr, *pos;\n+\tconst char *cpustr;\n+\tconst byte *pos;\n \tbyte *bufpos;\n \tbyte buf[256];\n \n@@ -75,14 +76,14 @@ getproccount(void)\n \t\treturn 1;\n \tcnt = 0;\n \tbufpos = buf;\n-\tcpustr = (const byte*)\"\\ncpu\";\n-\tcpustrlen = runtime_findnull((const byte*)cpustr);\n+\tcpustr = \"\\ncpu\";\n+\tcpustrlen = strlen(cpustr);\n \tfor(;;) {\n \t\trd = read(fd, bufpos, sizeof(buf)-cpustrlen);\n \t\tif(rd == -1)\n \t\t\tbreak;\n \t\tbufpos[rd] = 0;\n-\t\tfor(pos=buf; (pos=(const byte*)strstr((const char*)pos, (const char*)cpustr)) != nil; cnt++, pos++) {\n+\t\tfor(pos=buf; (pos=(const byte*)strstr((const char*)pos, cpustr)) != nil; cnt++, pos++) {\n \t\t}\n \t\tif(rd < cpustrlen)\n \t\t\tbreak;"}, {"sha": "459fc85c7802c945fbf31b78619bf399422ab650", "filename": "libgo/runtime/thread.c", "status": "modified", "additions": 43, "deletions": 0, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fthread.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/737087cbc8393b1a95a871b15a917872f1328c6b/libgo%2Fruntime%2Fthread.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fthread.c?ref=737087cbc8393b1a95a871b15a917872f1328c6b", "patch": "@@ -3,6 +3,8 @@\n // license that can be found in the LICENSE file.\n \n #include <errno.h>\n+#include <signal.h>\n+\n #include \"runtime.h\"\n #include \"go-assert.h\"\n \n@@ -71,3 +73,44 @@ __sync_fetch_and_add_4 (uint32* ptr, uint32 add)\n }\n \n #endif\n+\n+// Called to initialize a new m (including the bootstrap m).\n+void\n+runtime_minit(void)\n+{\n+\tbyte* stack;\n+\tsize_t stacksize;\n+\tstack_t ss;\n+\n+\t// Initialize signal handling.\n+\truntime_m()->gsignal = runtime_malg(32*1024, &stack, &stacksize);\t// OS X wants >=8K, Linux >=2K\n+\tss.ss_sp = stack;\n+\tss.ss_flags = 0;\n+\tss.ss_size = stacksize;\n+\tif(sigaltstack(&ss, nil) < 0)\n+\t\t*(int *)0xf1 = 0xf1;\n+}\n+\n+// Temporary functions, which will be removed when we stop using\n+// condition variables.\n+\n+void\n+runtime_cond_wait(pthread_cond_t* cond, pthread_mutex_t* mutex)\n+{\n+\tint i;\n+\n+\truntime_entersyscall();\n+\n+\ti = pthread_cond_wait(cond, mutex);\n+\tif(i != 0)\n+\t\truntime_throw(\"pthread_cond_wait\");\n+\ti = pthread_mutex_unlock(mutex);\n+\tif(i != 0)\n+\t\truntime_throw(\"pthread_mutex_unlock\");\n+\n+\truntime_exitsyscall();\n+\n+\ti = pthread_mutex_lock(mutex);\n+\tif(i != 0)\n+\t\truntime_throw(\"pthread_mutex_lock\");\n+}"}]}