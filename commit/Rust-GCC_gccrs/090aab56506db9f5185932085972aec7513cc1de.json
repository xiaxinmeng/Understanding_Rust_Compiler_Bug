{"sha": "090aab56506db9f5185932085972aec7513cc1de", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDkwYWFiNTY1MDZkYjlmNTE4NTkzMjA4NTk3MmFlYzc1MTNjYzFkZQ==", "commit": {"author": {"name": "Tom Tromey", "email": "tromey@gcc.gnu.org", "date": "1999-04-07T08:01:40Z"}, "committer": {"name": "Tom Tromey", "email": "tromey@gcc.gnu.org", "date": "1999-04-07T08:01:40Z"}, "message": "Initial revision\n\nFrom-SVN: r26255", "tree": {"sha": "3e2e769923c8cb3879bf5ccc55fded32a1c48b6e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3e2e769923c8cb3879bf5ccc55fded32a1c48b6e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/090aab56506db9f5185932085972aec7513cc1de", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/090aab56506db9f5185932085972aec7513cc1de", "html_url": "https://github.com/Rust-GCC/gccrs/commit/090aab56506db9f5185932085972aec7513cc1de", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/090aab56506db9f5185932085972aec7513cc1de/comments", "author": null, "committer": null, "parents": [{"sha": "2f5f7a08c81a77bb421bd1d8f7003128ae55a928", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2f5f7a08c81a77bb421bd1d8f7003128ae55a928", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2f5f7a08c81a77bb421bd1d8f7003128ae55a928"}], "stats": {"total": 2181, "additions": 2181, "deletions": 0}, "files": [{"sha": "d64dd5c0a815f4ddc4901cb966338cdda72e3057", "filename": "boehm-gc/os_dep.c", "status": "added", "additions": 2181, "deletions": 0, "changes": 2181, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/090aab56506db9f5185932085972aec7513cc1de/boehm-gc%2Fos_dep.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/090aab56506db9f5185932085972aec7513cc1de/boehm-gc%2Fos_dep.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fos_dep.c?ref=090aab56506db9f5185932085972aec7513cc1de", "patch": "@@ -0,0 +1,2181 @@\n+/*\n+ * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n+ * Copyright (c) 1996-1997 by Silicon Graphics.  All rights reserved.\n+ *\n+ * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n+ * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n+ *\n+ * Permission is hereby granted to use or copy this program\n+ * for any purpose,  provided the above notices are retained on all copies.\n+ * Permission to modify the code and to distribute modified code is granted,\n+ * provided the above notices are retained, and a notice that the code was\n+ * modified is included with the above copyright notice.\n+ */\n+\n+# include \"gc_priv.h\"\n+\n+# if defined(LINUX) && !defined(POWERPC)\n+#   include <linux/version.h>\n+#   if (LINUX_VERSION_CODE <= 0x10400)\n+      /* Ugly hack to get struct sigcontext_struct definition.  Required      */\n+      /* for some early 1.3.X releases.  Will hopefully go away soon. */\n+      /* in some later Linux releases, asm/sigcontext.h may have to   */\n+      /* be included instead.                                         */\n+#     define __KERNEL__\n+#     include <asm/signal.h>\n+#     undef __KERNEL__\n+#   else\n+      /* Kernels prior to 2.1.1 defined struct sigcontext_struct instead of */\n+      /* struct sigcontext.  libc6 (glibc2) uses \"struct sigcontext\" in     */\n+      /* prototypes, so we have to include the top-level sigcontext.h to    */\n+      /* make sure the former gets defined to be the latter if appropriate. */\n+#     include <features.h>\n+#     if 2 <= __GLIBC__\n+#       include <sigcontext.h>\n+#     else /* not 2 <= __GLIBC__ */\n+        /* libc5 doesn't have <sigcontext.h>: go directly with the kernel   */\n+        /* one.  Check LINUX_VERSION_CODE to see which we should reference. */\n+#       include <asm/sigcontext.h>\n+#     endif /* 2 <= __GLIBC__ */\n+#   endif\n+# endif\n+# if !defined(OS2) && !defined(PCR) && !defined(AMIGA) && !defined(MACOS)\n+#   include <sys/types.h>\n+#   if !defined(MSWIN32) && !defined(SUNOS4)\n+#   \tinclude <unistd.h>\n+#   endif\n+# endif\n+\n+# include <stdio.h>\n+# include <signal.h>\n+\n+/* Blatantly OS dependent routines, except for those that are related \t*/\n+/* dynamic loading.\t\t\t\t\t\t\t*/\n+\n+# if !defined(THREADS) && !defined(STACKBOTTOM) && defined(HEURISTIC2)\n+#   define NEED_FIND_LIMIT\n+# endif\n+\n+# if defined(IRIX_THREADS)\n+#   define NEED_FIND_LIMIT\n+# endif\n+\n+# if (defined(SUNOS4) & defined(DYNAMIC_LOADING)) && !defined(PCR)\n+#   define NEED_FIND_LIMIT\n+# endif\n+\n+# if (defined(SVR4) || defined(AUX) || defined(DGUX)) && !defined(PCR)\n+#   define NEED_FIND_LIMIT\n+# endif\n+\n+# if defined(LINUX) && defined(POWERPC)\n+#   define NEED_FIND_LIMIT\n+# endif\n+\n+#ifdef NEED_FIND_LIMIT\n+#   include <setjmp.h>\n+#endif\n+\n+#ifdef FREEBSD\n+#  include <machine/trap.h>\n+#endif\n+\n+#ifdef AMIGA\n+# include <proto/exec.h>\n+# include <proto/dos.h>\n+# include <dos/dosextens.h>\n+# include <workbench/startup.h>\n+#endif\n+\n+#ifdef MSWIN32\n+# define WIN32_LEAN_AND_MEAN\n+# define NOSERVICE\n+# include <windows.h>\n+#endif\n+\n+#ifdef MACOS\n+# include <Processes.h>\n+#endif\n+\n+#ifdef IRIX5\n+# include <sys/uio.h>\n+# include <malloc.h>   /* for locking */\n+#endif\n+#ifdef USE_MMAP\n+# include <sys/types.h>\n+# include <sys/mman.h>\n+# include <sys/stat.h>\n+# include <fcntl.h>\n+#endif\n+\n+#ifdef SUNOS5SIGS\n+# include <sys/siginfo.h>\n+# undef setjmp\n+# undef longjmp\n+# define setjmp(env) sigsetjmp(env, 1)\n+# define longjmp(env, val) siglongjmp(env, val)\n+# define jmp_buf sigjmp_buf\n+#endif\n+\n+#ifdef DJGPP\n+  /* Apparently necessary for djgpp 2.01.  May casuse problems with\t*/\n+  /* other versions.\t\t\t\t\t\t\t*/\n+  typedef long unsigned int caddr_t;\n+#endif\n+\n+#ifdef PCR\n+# include \"il/PCR_IL.h\"\n+# include \"th/PCR_ThCtl.h\"\n+# include \"mm/PCR_MM.h\"\n+#endif\n+\n+#if !defined(NO_EXECUTE_PERMISSION)\n+# define OPT_PROT_EXEC PROT_EXEC\n+#else\n+# define OPT_PROT_EXEC 0\n+#endif\n+\n+#if defined(LINUX) && defined(POWERPC)\n+  ptr_t GC_data_start;\n+\n+  void GC_init_linuxppc()\n+  {\n+    extern ptr_t GC_find_limit();\n+    extern char **_environ;\n+\t/* This may need to be environ, without the underscore, for\t*/\n+\t/* some versions.\t\t\t\t\t\t*/\n+    GC_data_start = GC_find_limit((ptr_t)&_environ, FALSE);\n+  }\n+#endif\n+\n+# ifdef OS2\n+\n+# include <stddef.h>\n+\n+# if !defined(__IBMC__) && !defined(__WATCOMC__) /* e.g. EMX */\n+\n+struct exe_hdr {\n+    unsigned short      magic_number;\n+    unsigned short      padding[29];\n+    long                new_exe_offset;\n+};\n+\n+#define E_MAGIC(x)      (x).magic_number\n+#define EMAGIC          0x5A4D  \n+#define E_LFANEW(x)     (x).new_exe_offset\n+\n+struct e32_exe {\n+    unsigned char       magic_number[2]; \n+    unsigned char       byte_order; \n+    unsigned char       word_order; \n+    unsigned long       exe_format_level;\n+    unsigned short      cpu;       \n+    unsigned short      os;\n+    unsigned long       padding1[13];\n+    unsigned long       object_table_offset;\n+    unsigned long       object_count;    \n+    unsigned long       padding2[31];\n+};\n+\n+#define E32_MAGIC1(x)   (x).magic_number[0]\n+#define E32MAGIC1       'L'\n+#define E32_MAGIC2(x)   (x).magic_number[1]\n+#define E32MAGIC2       'X'\n+#define E32_BORDER(x)   (x).byte_order\n+#define E32LEBO         0\n+#define E32_WORDER(x)   (x).word_order\n+#define E32LEWO         0\n+#define E32_CPU(x)      (x).cpu\n+#define E32CPU286       1\n+#define E32_OBJTAB(x)   (x).object_table_offset\n+#define E32_OBJCNT(x)   (x).object_count\n+\n+struct o32_obj {\n+    unsigned long       size;  \n+    unsigned long       base;\n+    unsigned long       flags;  \n+    unsigned long       pagemap;\n+    unsigned long       mapsize; \n+    unsigned long       reserved;\n+};\n+\n+#define O32_FLAGS(x)    (x).flags\n+#define OBJREAD         0x0001L\n+#define OBJWRITE        0x0002L\n+#define OBJINVALID      0x0080L\n+#define O32_SIZE(x)     (x).size\n+#define O32_BASE(x)     (x).base\n+\n+# else  /* IBM's compiler */\n+\n+/* A kludge to get around what appears to be a header file bug */\n+# ifndef WORD\n+#   define WORD unsigned short\n+# endif\n+# ifndef DWORD\n+#   define DWORD unsigned long\n+# endif\n+\n+# define EXE386 1\n+# include <newexe.h>\n+# include <exe386.h>\n+\n+# endif  /* __IBMC__ */\n+\n+# define INCL_DOSEXCEPTIONS\n+# define INCL_DOSPROCESS\n+# define INCL_DOSERRORS\n+# define INCL_DOSMODULEMGR\n+# define INCL_DOSMEMMGR\n+# include <os2.h>\n+\n+\n+/* Disable and enable signals during nontrivial allocations\t*/\n+\n+void GC_disable_signals(void)\n+{\n+    ULONG nest;\n+    \n+    DosEnterMustComplete(&nest);\n+    if (nest != 1) ABORT(\"nested GC_disable_signals\");\n+}\n+\n+void GC_enable_signals(void)\n+{\n+    ULONG nest;\n+    \n+    DosExitMustComplete(&nest);\n+    if (nest != 0) ABORT(\"GC_enable_signals\");\n+}\n+\n+\n+# else\n+\n+#  if !defined(PCR) && !defined(AMIGA) && !defined(MSWIN32) \\\n+      && !defined(MACOS) && !defined(DJGPP) && !defined(DOS4GW)\n+\n+#   if defined(sigmask) && !defined(UTS4)\n+\t/* Use the traditional BSD interface */\n+#\tdefine SIGSET_T int\n+#\tdefine SIG_DEL(set, signal) (set) &= ~(sigmask(signal))\n+#\tdefine SIG_FILL(set)  (set) = 0x7fffffff\n+    \t  /* Setting the leading bit appears to provoke a bug in some\t*/\n+    \t  /* longjmp implementations.  Most systems appear not to have\t*/\n+    \t  /* a signal 32.\t\t\t\t\t\t*/\n+#\tdefine SIGSETMASK(old, new) (old) = sigsetmask(new)\n+#   else\n+\t/* Use POSIX/SYSV interface\t*/\n+#\tdefine SIGSET_T sigset_t\n+#\tdefine SIG_DEL(set, signal) sigdelset(&(set), (signal))\n+#\tdefine SIG_FILL(set) sigfillset(&set)\n+#\tdefine SIGSETMASK(old, new) sigprocmask(SIG_SETMASK, &(new), &(old))\n+#   endif\n+\n+static GC_bool mask_initialized = FALSE;\n+\n+static SIGSET_T new_mask;\n+\n+static SIGSET_T old_mask;\n+\n+static SIGSET_T dummy;\n+\n+#if defined(PRINTSTATS) && !defined(THREADS)\n+# define CHECK_SIGNALS\n+  int GC_sig_disabled = 0;\n+#endif\n+\n+void GC_disable_signals()\n+{\n+    if (!mask_initialized) {\n+    \tSIG_FILL(new_mask);\n+\n+\tSIG_DEL(new_mask, SIGSEGV);\n+\tSIG_DEL(new_mask, SIGILL);\n+\tSIG_DEL(new_mask, SIGQUIT);\n+#\tifdef SIGBUS\n+\t    SIG_DEL(new_mask, SIGBUS);\n+#\tendif\n+#\tifdef SIGIOT\n+\t    SIG_DEL(new_mask, SIGIOT);\n+#\tendif\n+#\tifdef SIGEMT\n+\t    SIG_DEL(new_mask, SIGEMT);\n+#\tendif\n+#\tifdef SIGTRAP\n+\t    SIG_DEL(new_mask, SIGTRAP);\n+#\tendif \n+\tmask_initialized = TRUE;\n+    }\n+#   ifdef CHECK_SIGNALS\n+\tif (GC_sig_disabled != 0) ABORT(\"Nested disables\");\n+\tGC_sig_disabled++;\n+#   endif\n+    SIGSETMASK(old_mask,new_mask);\n+}\n+\n+void GC_enable_signals()\n+{\n+#   ifdef CHECK_SIGNALS\n+\tif (GC_sig_disabled != 1) ABORT(\"Unmatched enable\");\n+\tGC_sig_disabled--;\n+#   endif\n+    SIGSETMASK(dummy,old_mask);\n+}\n+\n+#  endif  /* !PCR */\n+\n+# endif /*!OS/2 */\n+\n+/* Ivan Demakov: simplest way (to me) */\n+#ifdef DOS4GW\n+  void GC_disable_signals() { }\n+  void GC_enable_signals() { }\n+#endif\n+\n+/* Find the page size */\n+word GC_page_size;\n+\n+# ifdef MSWIN32\n+  void GC_setpagesize()\n+  {\n+    SYSTEM_INFO sysinfo;\n+    \n+    GetSystemInfo(&sysinfo);\n+    GC_page_size = sysinfo.dwPageSize;\n+  }\n+\n+# else\n+#   if defined(MPROTECT_VDB) || defined(PROC_VDB) || defined(USE_MMAP)\n+\tvoid GC_setpagesize()\n+\t{\n+\t    GC_page_size = GETPAGESIZE();\n+\t}\n+#   else\n+\t/* It's acceptable to fake it. */\n+\tvoid GC_setpagesize()\n+\t{\n+\t    GC_page_size = HBLKSIZE;\n+\t}\n+#   endif\n+# endif\n+\n+/* \n+ * Find the base of the stack. \n+ * Used only in single-threaded environment.\n+ * With threads, GC_mark_roots needs to know how to do this.\n+ * Called with allocator lock held.\n+ */\n+# ifdef MSWIN32 \n+# define is_writable(prot) ((prot) == PAGE_READWRITE \\\n+\t\t\t    || (prot) == PAGE_WRITECOPY \\\n+\t\t\t    || (prot) == PAGE_EXECUTE_READWRITE \\\n+\t\t\t    || (prot) == PAGE_EXECUTE_WRITECOPY)\n+/* Return the number of bytes that are writable starting at p.\t*/\n+/* The pointer p is assumed to be page aligned.\t\t\t*/\n+/* If base is not 0, *base becomes the beginning of the \t*/\n+/* allocation region containing p.\t\t\t\t*/\n+word GC_get_writable_length(ptr_t p, ptr_t *base)\n+{\n+    MEMORY_BASIC_INFORMATION buf;\n+    word result;\n+    word protect;\n+    \n+    result = VirtualQuery(p, &buf, sizeof(buf));\n+    if (result != sizeof(buf)) ABORT(\"Weird VirtualQuery result\");\n+    if (base != 0) *base = (ptr_t)(buf.AllocationBase);\n+    protect = (buf.Protect & ~(PAGE_GUARD | PAGE_NOCACHE));\n+    if (!is_writable(protect)) {\n+        return(0);\n+    }\n+    if (buf.State != MEM_COMMIT) return(0);\n+    return(buf.RegionSize);\n+}\n+\n+ptr_t GC_get_stack_base()\n+{\n+    int dummy;\n+    ptr_t sp = (ptr_t)(&dummy);\n+    ptr_t trunc_sp = (ptr_t)((word)sp & ~(GC_page_size - 1));\n+    word size = GC_get_writable_length(trunc_sp, 0);\n+   \n+    return(trunc_sp + size);\n+}\n+\n+\n+# else\n+\n+# ifdef OS2\n+\n+ptr_t GC_get_stack_base()\n+{\n+    PTIB ptib;\n+    PPIB ppib;\n+    \n+    if (DosGetInfoBlocks(&ptib, &ppib) != NO_ERROR) {\n+    \tGC_err_printf0(\"DosGetInfoBlocks failed\\n\");\n+    \tABORT(\"DosGetInfoBlocks failed\\n\");\n+    }\n+    return((ptr_t)(ptib -> tib_pstacklimit));\n+}\n+\n+# else\n+\n+# ifdef AMIGA\n+\n+ptr_t GC_get_stack_base()\n+{\n+    extern struct WBStartup *_WBenchMsg;\n+    extern long __base;\n+    extern long __stack;\n+    struct Task *task;\n+    struct Process *proc;\n+    struct CommandLineInterface *cli;\n+    long size;\n+\n+    if ((task = FindTask(0)) == 0) {\n+\tGC_err_puts(\"Cannot find own task structure\\n\");\n+\tABORT(\"task missing\");\n+    }\n+    proc = (struct Process *)task;\n+    cli = BADDR(proc->pr_CLI);\n+\n+    if (_WBenchMsg != 0 || cli == 0) {\n+\tsize = (char *)task->tc_SPUpper - (char *)task->tc_SPLower;\n+    } else {\n+\tsize = cli->cli_DefaultStack * 4;\n+    }\n+    return (ptr_t)(__base + GC_max(size, __stack));\n+}\n+\n+# else\n+\n+\n+\n+# ifdef NEED_FIND_LIMIT\n+  /* Some tools to implement HEURISTIC2\t*/\n+#   define MIN_PAGE_SIZE 256\t/* Smallest conceivable page size, bytes */\n+    /* static */ jmp_buf GC_jmp_buf;\n+    \n+    /*ARGSUSED*/\n+    void GC_fault_handler(sig)\n+    int sig;\n+    {\n+        longjmp(GC_jmp_buf, 1);\n+    }\n+\n+#   ifdef __STDC__\n+\ttypedef void (*handler)(int);\n+#   else\n+\ttypedef void (*handler)();\n+#   endif\n+\n+#   if defined(SUNOS5SIGS) || defined(IRIX5)\n+\tstatic struct sigaction old_segv_act;\n+\tstatic struct sigaction old_bus_act;\n+#   else\n+        static handler old_segv_handler, old_bus_handler;\n+#   endif\n+    \n+    void GC_setup_temporary_fault_handler()\n+    {\n+#\tif defined(SUNOS5SIGS) || defined(IRIX5)\n+\t  struct sigaction\tact;\n+\n+\t  act.sa_handler\t= GC_fault_handler;\n+          act.sa_flags          = SA_RESTART | SA_NODEFER;\n+          /* The presence of SA_NODEFER represents yet another gross    */\n+          /* hack.  Under Solaris 2.3, siglongjmp doesn't appear to     */\n+          /* interact correctly with -lthread.  We hide the confusion   */\n+          /* by making sure that signal handling doesn't affect the     */\n+          /* signal mask.                                               */\n+\n+\t  (void) sigemptyset(&act.sa_mask);\n+#\t  ifdef IRIX_THREADS\n+\t\t/* Older versions have a bug related to retrieving and\t*/\n+\t\t/* and setting a handler at the same time.\t\t*/\n+\t        (void) sigaction(SIGSEGV, 0, &old_segv_act);\n+\t        (void) sigaction(SIGSEGV, &act, 0);\n+#\t  else\n+\t        (void) sigaction(SIGSEGV, &act, &old_segv_act);\n+#\t\tifdef _sigargs\t/* Irix 5.x, not 6.x */\n+\t\t    /* Under 5.x, we may get SIGBUS.\t\t\t*/\n+\t\t    /* Pthreads doesn't exist under 5.x, so we don't\t*/\n+\t\t    /* have to worry in the threads case.\t\t*/\n+\t\t    (void) sigaction(SIGBUS, &act, &old_bus_act);\n+#\t\tendif\n+#\t  endif\t/* IRIX_THREADS */\n+#\telse\n+    \t  old_segv_handler = signal(SIGSEGV, GC_fault_handler);\n+#\t  ifdef SIGBUS\n+\t    old_bus_handler = signal(SIGBUS, GC_fault_handler);\n+#\t  endif\n+#\tendif\n+    }\n+    \n+    void GC_reset_fault_handler()\n+    {\n+#       if defined(SUNOS5SIGS) || defined(IRIX5)\n+\t  (void) sigaction(SIGSEGV, &old_segv_act, 0);\n+#\t  ifdef _sigargs\t/* Irix 5.x, not 6.x */\n+\t      (void) sigaction(SIGBUS, &old_bus_act, 0);\n+#\t  endif\n+#       else\n+  \t  (void) signal(SIGSEGV, old_segv_handler);\n+#\t  ifdef SIGBUS\n+\t    (void) signal(SIGBUS, old_bus_handler);\n+#\t  endif\n+#       endif\n+    }\n+\n+    /* Return the first nonaddressible location > p (up) or \t*/\n+    /* the smallest location q s.t. [q,p] is addressible (!up).\t*/\n+    ptr_t GC_find_limit(p, up)\n+    ptr_t p;\n+    GC_bool up;\n+    {\n+        static VOLATILE ptr_t result;\n+    \t\t/* Needs to be static, since otherwise it may not be\t*/\n+    \t\t/* preserved across the longjmp.  Can safely be \t*/\n+    \t\t/* static since it's only called once, with the\t\t*/\n+    \t\t/* allocation lock held.\t\t\t\t*/\n+\n+\n+\tGC_setup_temporary_fault_handler();\n+\tif (setjmp(GC_jmp_buf) == 0) {\n+\t    result = (ptr_t)(((word)(p))\n+\t\t\t      & ~(MIN_PAGE_SIZE-1));\n+\t    for (;;) {\n+ \t        if (up) {\n+\t\t    result += MIN_PAGE_SIZE;\n+ \t        } else {\n+\t\t    result -= MIN_PAGE_SIZE;\n+ \t        }\n+\t\tGC_noop1((word)(*result));\n+\t    }\n+\t}\n+\tGC_reset_fault_handler();\n+ \tif (!up) {\n+\t    result += MIN_PAGE_SIZE;\n+ \t}\n+\treturn(result);\n+    }\n+# endif\n+\n+\n+ptr_t GC_get_stack_base()\n+{\n+    word dummy;\n+    ptr_t result;\n+\n+#   define STACKBOTTOM_ALIGNMENT_M1 ((word)STACK_GRAN - 1)\n+\n+#   ifdef STACKBOTTOM\n+\treturn(STACKBOTTOM);\n+#   else\n+#\tifdef HEURISTIC1\n+#\t   ifdef STACK_GROWS_DOWN\n+\t     result = (ptr_t)((((word)(&dummy))\n+\t     \t\t       + STACKBOTTOM_ALIGNMENT_M1)\n+\t\t\t      & ~STACKBOTTOM_ALIGNMENT_M1);\n+#\t   else\n+\t     result = (ptr_t)(((word)(&dummy))\n+\t\t\t      & ~STACKBOTTOM_ALIGNMENT_M1);\n+#\t   endif\n+#\tendif /* HEURISTIC1 */\n+#\tifdef HEURISTIC2\n+#\t    ifdef STACK_GROWS_DOWN\n+\t\tresult = GC_find_limit((ptr_t)(&dummy), TRUE);\n+#           \tifdef HEURISTIC2_LIMIT\n+\t\t    if (result > HEURISTIC2_LIMIT\n+\t\t        && (ptr_t)(&dummy) < HEURISTIC2_LIMIT) {\n+\t\t            result = HEURISTIC2_LIMIT;\n+\t\t    }\n+#\t        endif\n+#\t    else\n+\t\tresult = GC_find_limit((ptr_t)(&dummy), FALSE);\n+#           \tifdef HEURISTIC2_LIMIT\n+\t\t    if (result < HEURISTIC2_LIMIT\n+\t\t        && (ptr_t)(&dummy) > HEURISTIC2_LIMIT) {\n+\t\t            result = HEURISTIC2_LIMIT;\n+\t\t    }\n+#\t        endif\n+#\t    endif\n+\n+#\tendif /* HEURISTIC2 */\n+    \treturn(result);\n+#   endif /* STACKBOTTOM */\n+}\n+\n+# endif /* ! AMIGA */\n+# endif /* ! OS2 */\n+# endif /* ! MSWIN32 */\n+\n+/*\n+ * Register static data segment(s) as roots.\n+ * If more data segments are added later then they need to be registered\n+ * add that point (as we do with SunOS dynamic loading),\n+ * or GC_mark_roots needs to check for them (as we do with PCR).\n+ * Called with allocator lock held.\n+ */\n+\n+# ifdef OS2\n+\n+void GC_register_data_segments()\n+{\n+    PTIB ptib;\n+    PPIB ppib;\n+    HMODULE module_handle;\n+#   define PBUFSIZ 512\n+    UCHAR path[PBUFSIZ];\n+    FILE * myexefile;\n+    struct exe_hdr hdrdos;\t/* MSDOS header.\t*/\n+    struct e32_exe hdr386;\t/* Real header for my executable */\n+    struct o32_obj seg;\t/* Currrent segment */\n+    int nsegs;\n+    \n+    \n+    if (DosGetInfoBlocks(&ptib, &ppib) != NO_ERROR) {\n+    \tGC_err_printf0(\"DosGetInfoBlocks failed\\n\");\n+    \tABORT(\"DosGetInfoBlocks failed\\n\");\n+    }\n+    module_handle = ppib -> pib_hmte;\n+    if (DosQueryModuleName(module_handle, PBUFSIZ, path) != NO_ERROR) {\n+    \tGC_err_printf0(\"DosQueryModuleName failed\\n\");\n+    \tABORT(\"DosGetInfoBlocks failed\\n\");\n+    }\n+    myexefile = fopen(path, \"rb\");\n+    if (myexefile == 0) {\n+        GC_err_puts(\"Couldn't open executable \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Failed to open executable\\n\");\n+    }\n+    if (fread((char *)(&hdrdos), 1, sizeof hdrdos, myexefile) < sizeof hdrdos) {\n+        GC_err_puts(\"Couldn't read MSDOS header from \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Couldn't read MSDOS header\");\n+    }\n+    if (E_MAGIC(hdrdos) != EMAGIC) {\n+        GC_err_puts(\"Executable has wrong DOS magic number: \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Bad DOS magic number\");\n+    }\n+    if (fseek(myexefile, E_LFANEW(hdrdos), SEEK_SET) != 0) {\n+        GC_err_puts(\"Seek to new header failed in \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Bad DOS magic number\");\n+    }\n+    if (fread((char *)(&hdr386), 1, sizeof hdr386, myexefile) < sizeof hdr386) {\n+        GC_err_puts(\"Couldn't read MSDOS header from \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Couldn't read OS/2 header\");\n+    }\n+    if (E32_MAGIC1(hdr386) != E32MAGIC1 || E32_MAGIC2(hdr386) != E32MAGIC2) {\n+        GC_err_puts(\"Executable has wrong OS/2 magic number:\");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Bad OS/2 magic number\");\n+    }\n+    if ( E32_BORDER(hdr386) != E32LEBO || E32_WORDER(hdr386) != E32LEWO) {\n+        GC_err_puts(\"Executable %s has wrong byte order: \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Bad byte order\");\n+    }\n+    if ( E32_CPU(hdr386) == E32CPU286) {\n+        GC_err_puts(\"GC can't handle 80286 executables: \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        EXIT();\n+    }\n+    if (fseek(myexefile, E_LFANEW(hdrdos) + E32_OBJTAB(hdr386),\n+    \t      SEEK_SET) != 0) {\n+        GC_err_puts(\"Seek to object table failed: \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Seek to object table failed\");\n+    }\n+    for (nsegs = E32_OBJCNT(hdr386); nsegs > 0; nsegs--) {\n+      int flags;\n+      if (fread((char *)(&seg), 1, sizeof seg, myexefile) < sizeof seg) {\n+        GC_err_puts(\"Couldn't read obj table entry from \");\n+        GC_err_puts(path); GC_err_puts(\"\\n\");\n+        ABORT(\"Couldn't read obj table entry\");\n+      }\n+      flags = O32_FLAGS(seg);\n+      if (!(flags & OBJWRITE)) continue;\n+      if (!(flags & OBJREAD)) continue;\n+      if (flags & OBJINVALID) {\n+          GC_err_printf0(\"Object with invalid pages?\\n\");\n+          continue;\n+      } \n+      GC_add_roots_inner(O32_BASE(seg), O32_BASE(seg)+O32_SIZE(seg), FALSE);\n+    }\n+}\n+\n+# else\n+\n+# ifdef MSWIN32\n+  /* Unfortunately, we have to handle win32s very differently from NT, \t*/\n+  /* Since VirtualQuery has very different semantics.  In particular,\t*/\n+  /* under win32s a VirtualQuery call on an unmapped page returns an\t*/\n+  /* invalid result.  Under GC_register_data_segments is a noop and\t*/\n+  /* all real work is done by GC_register_dynamic_libraries.  Under\t*/\n+  /* win32s, we cannot find the data segments associated with dll's.\t*/\n+  /* We rgister the main data segment here.\t\t\t\t*/\n+  GC_bool GC_win32s = FALSE;\t/* We're running under win32s.\t*/\n+  \n+  GC_bool GC_is_win32s()\n+  {\n+      DWORD v = GetVersion();\n+      \n+      /* Check that this is not NT, and Windows major version <= 3\t*/\n+      return ((v & 0x80000000) && (v & 0xff) <= 3);\n+  }\n+  \n+  void GC_init_win32()\n+  {\n+      GC_win32s = GC_is_win32s();\n+  }\n+  \n+  /* Return the smallest address a such that VirtualQuery\t\t*/\n+  /* returns correct results for all addresses between a and start.\t*/\n+  /* Assumes VirtualQuery returns correct information for start.\t*/\n+  ptr_t GC_least_described_address(ptr_t start)\n+  {  \n+    MEMORY_BASIC_INFORMATION buf;\n+    SYSTEM_INFO sysinfo;\n+    DWORD result;\n+    LPVOID limit;\n+    ptr_t p;\n+    LPVOID q;\n+    \n+    GetSystemInfo(&sysinfo);\n+    limit = sysinfo.lpMinimumApplicationAddress;\n+    p = (ptr_t)((word)start & ~(GC_page_size - 1));\n+    for (;;) {\n+    \tq = (LPVOID)(p - GC_page_size);\n+    \tif ((ptr_t)q > (ptr_t)p /* underflow */ || q < limit) break;\n+    \tresult = VirtualQuery(q, &buf, sizeof(buf));\n+    \tif (result != sizeof(buf) || buf.AllocationBase == 0) break;\n+    \tp = (ptr_t)(buf.AllocationBase);\n+    }\n+    return(p);\n+  }\n+  \n+  /* Is p the start of either the malloc heap, or of one of our */\n+  /* heap sections?\t\t\t\t\t\t*/\n+  GC_bool GC_is_heap_base (ptr_t p)\n+  {\n+     \n+     register unsigned i;\n+     \n+#    ifndef REDIRECT_MALLOC\n+       static ptr_t malloc_heap_pointer = 0;\n+     \n+       if (0 == malloc_heap_pointer) {\n+         MEMORY_BASIC_INFORMATION buf;\n+         register DWORD result = VirtualQuery(malloc(1), &buf, sizeof(buf));\n+         \n+         if (result != sizeof(buf)) {\n+             ABORT(\"Weird VirtualQuery result\");\n+         }\n+         malloc_heap_pointer = (ptr_t)(buf.AllocationBase);\n+       }\n+       if (p == malloc_heap_pointer) return(TRUE);\n+#    endif\n+     for (i = 0; i < GC_n_heap_bases; i++) {\n+         if (GC_heap_bases[i] == p) return(TRUE);\n+     }\n+     return(FALSE);\n+  }\n+  \n+  void GC_register_root_section(ptr_t static_root)\n+  {\n+      MEMORY_BASIC_INFORMATION buf;\n+      SYSTEM_INFO sysinfo;\n+      DWORD result;\n+      DWORD protect;\n+      LPVOID p;\n+      char * base;\n+      char * limit, * new_limit;\n+    \n+      if (!GC_win32s) return;\n+      p = base = limit = GC_least_described_address(static_root);\n+      GetSystemInfo(&sysinfo);\n+      while (p < sysinfo.lpMaximumApplicationAddress) {\n+        result = VirtualQuery(p, &buf, sizeof(buf));\n+        if (result != sizeof(buf) || buf.AllocationBase == 0\n+            || GC_is_heap_base(buf.AllocationBase)) break;\n+        new_limit = (char *)p + buf.RegionSize;\n+        protect = buf.Protect;\n+        if (buf.State == MEM_COMMIT\n+            && is_writable(protect)) {\n+            if ((char *)p == limit) {\n+                limit = new_limit;\n+            } else {\n+                if (base != limit) GC_add_roots_inner(base, limit, FALSE);\n+                base = p;\n+                limit = new_limit;\n+            }\n+        }\n+        if (p > (LPVOID)new_limit /* overflow */) break;\n+        p = (LPVOID)new_limit;\n+      }\n+      if (base != limit) GC_add_roots_inner(base, limit, FALSE);\n+  }\n+  \n+  void GC_register_data_segments()\n+  {\n+      static char dummy;\n+      \n+      GC_register_root_section((ptr_t)(&dummy));\n+  }\n+# else\n+# ifdef AMIGA\n+\n+  void GC_register_data_segments()\n+  {\n+    extern struct WBStartup *_WBenchMsg;\n+    struct Process\t*proc;\n+    struct CommandLineInterface *cli;\n+    BPTR myseglist;\n+    ULONG *data;\n+\n+    if ( _WBenchMsg != 0 ) {\n+\tif ((myseglist = _WBenchMsg->sm_Segment) == 0) {\n+\t    GC_err_puts(\"No seglist from workbench\\n\");\n+\t    return;\n+\t}\n+    } else {\n+\tif ((proc = (struct Process *)FindTask(0)) == 0) {\n+\t    GC_err_puts(\"Cannot find process structure\\n\");\n+\t    return;\n+\t}\n+\tif ((cli = BADDR(proc->pr_CLI)) == 0) {\n+\t    GC_err_puts(\"No CLI\\n\");\n+\t    return;\n+\t}\n+\tif ((myseglist = cli->cli_Module) == 0) {\n+\t    GC_err_puts(\"No seglist from CLI\\n\");\n+\t    return;\n+\t}\n+    }\n+\n+    for (data = (ULONG *)BADDR(myseglist); data != 0;\n+         data = (ULONG *)BADDR(data[0])) {\n+#        ifdef AMIGA_SKIP_SEG\n+           if (((ULONG) GC_register_data_segments < (ULONG) &data[1]) ||\n+           ((ULONG) GC_register_data_segments > (ULONG) &data[1] + data[-1])) {\n+#\t else\n+      \t   {\n+#\t endif /* AMIGA_SKIP_SEG */\n+          GC_add_roots_inner((char *)&data[1],\n+          \t\t     ((char *)&data[1]) + data[-1], FALSE);\n+         }\n+    }\n+  }\n+\n+\n+# else\n+\n+# if (defined(SVR4) || defined(AUX) || defined(DGUX)) && !defined(PCR)\n+char * GC_SysVGetDataStart(max_page_size, etext_addr)\n+int max_page_size;\n+int * etext_addr;\n+{\n+    word text_end = ((word)(etext_addr) + sizeof(word) - 1)\n+    \t\t    & ~(sizeof(word) - 1);\n+    \t/* etext rounded to word boundary\t*/\n+    word next_page = ((text_end + (word)max_page_size - 1)\n+    \t\t      & ~((word)max_page_size - 1));\n+    word page_offset = (text_end & ((word)max_page_size - 1));\n+    VOLATILE char * result = (char *)(next_page + page_offset);\n+    /* Note that this isnt equivalent to just adding\t\t*/\n+    /* max_page_size to &etext if &etext is at a page boundary\t*/\n+    \n+    GC_setup_temporary_fault_handler();\n+    if (setjmp(GC_jmp_buf) == 0) {\n+    \t/* Try writing to the address.\t*/\n+    \t*result = *result;\n+        GC_reset_fault_handler();\n+    } else {\n+        GC_reset_fault_handler();\n+    \t/* We got here via a longjmp.  The address is not readable.\t*/\n+    \t/* This is known to happen under Solaris 2.4 + gcc, which place\t*/\n+    \t/* string constants in the text segment, but after etext.\t*/\n+    \t/* Use plan B.  Note that we now know there is a gap between\t*/\n+    \t/* text and data segments, so plan A bought us something.\t*/\n+    \tresult = (char *)GC_find_limit((ptr_t)(DATAEND) - MIN_PAGE_SIZE, FALSE);\n+    }\n+    return((char *)result);\n+}\n+# endif\n+\n+\n+void GC_register_data_segments()\n+{\n+#   if !defined(PCR) && !defined(SRC_M3) && !defined(NEXT) && !defined(MACOS)\n+#     if defined(REDIRECT_MALLOC) && defined(SOLARIS_THREADS)\n+\t/* As of Solaris 2.3, the Solaris threads implementation\t*/\n+\t/* allocates the data structure for the initial thread with\t*/\n+\t/* sbrk at process startup.  It needs to be scanned, so that\t*/\n+\t/* we don't lose some malloc allocated data structures\t\t*/\n+\t/* hanging from it.  We're on thin ice here ...\t\t\t*/\n+        extern caddr_t sbrk();\n+\n+\tGC_add_roots_inner(DATASTART, (char *)sbrk(0), FALSE);\n+#     else\n+\tGC_add_roots_inner(DATASTART, (char *)(DATAEND), FALSE);\n+#     endif\n+#   endif\n+#   if !defined(PCR) && defined(NEXT)\n+      GC_add_roots_inner(DATASTART, (char *) get_end(), FALSE);\n+#   endif\n+#   if defined(MACOS)\n+    {\n+#   if defined(THINK_C)\n+\textern void* GC_MacGetDataStart(void);\n+\t/* globals begin above stack and end at a5. */\n+\tGC_add_roots_inner((ptr_t)GC_MacGetDataStart(),\n+\t\t\t   (ptr_t)LMGetCurrentA5(), FALSE);\n+#   else\n+#     if defined(__MWERKS__)\n+#       if !__POWERPC__\n+\t  extern void* GC_MacGetDataStart(void);\n+\t  /* globals begin above stack and end at a5. */\n+\t  GC_add_roots_inner((ptr_t)GC_MacGetDataStart(),\n+          \t\t     (ptr_t)LMGetCurrentA5(), FALSE);\n+#       else\n+\t  extern char __data_start__[], __data_end__[];\n+\t  GC_add_roots_inner((ptr_t)&__data_start__,\n+\t  \t\t     (ptr_t)&__data_end__, FALSE);\n+#       endif /* __POWERPC__ */\n+#     endif /* __MWERKS__ */\n+#   endif /* !THINK_C */\n+    }\n+#   endif /* MACOS */\n+\n+    /* Dynamic libraries are added at every collection, since they may  */\n+    /* change.\t\t\t\t\t\t\t\t*/\n+}\n+\n+# endif  /* ! AMIGA */\n+# endif  /* ! MSWIN32 */\n+# endif  /* ! OS2 */\n+\n+/*\n+ * Auxiliary routines for obtaining memory from OS.\n+ */\n+ \n+# if !defined(OS2) && !defined(PCR) && !defined(AMIGA) \\\n+\t&& !defined(MSWIN32) && !defined(MACOS) && !defined(DOS4GW)\n+\n+# ifdef SUNOS4\n+    extern caddr_t sbrk();\n+# endif\n+# ifdef __STDC__\n+#   define SBRK_ARG_T ptrdiff_t\n+# else\n+#   define SBRK_ARG_T int\n+# endif\n+\n+# ifdef RS6000\n+/* The compiler seems to generate speculative reads one past the end of\t*/\n+/* an allocated object.  Hence we need to make sure that the page \t*/\n+/* following the last heap page is also mapped.\t\t\t\t*/\n+ptr_t GC_unix_get_mem(bytes)\n+word bytes;\n+{\n+    caddr_t cur_brk = (caddr_t)sbrk(0);\n+    caddr_t result;\n+    SBRK_ARG_T lsbs = (word)cur_brk & (GC_page_size-1);\n+    static caddr_t my_brk_val = 0;\n+    \n+    if ((SBRK_ARG_T)bytes < 0) return(0); /* too big */\n+    if (lsbs != 0) {\n+        if((caddr_t)(sbrk(GC_page_size - lsbs)) == (caddr_t)(-1)) return(0);\n+    }\n+    if (cur_brk == my_brk_val) {\n+    \t/* Use the extra block we allocated last time. */\n+        result = (ptr_t)sbrk((SBRK_ARG_T)bytes);\n+        if (result == (caddr_t)(-1)) return(0);\n+        result -= GC_page_size;\n+    } else {\n+        result = (ptr_t)sbrk(GC_page_size + (SBRK_ARG_T)bytes);\n+        if (result == (caddr_t)(-1)) return(0);\n+    }\n+    my_brk_val = result + bytes + GC_page_size;\t/* Always page aligned */\n+    return((ptr_t)result);\n+}\n+\n+#else  /* Not RS6000 */\n+\n+#if defined(USE_MMAP)\n+/* Tested only under IRIX5 */\n+\n+ptr_t GC_unix_get_mem(bytes)\n+word bytes;\n+{\n+    static GC_bool initialized = FALSE;\n+    static int fd;\n+    void *result;\n+    static ptr_t last_addr = HEAP_START;\n+\n+    if (!initialized) {\n+\tfd = open(\"/dev/zero\", O_RDONLY);\n+\tinitialized = TRUE;\n+    }\n+    if (bytes & (GC_page_size -1)) ABORT(\"Bad GET_MEM arg\");\n+    result = mmap(last_addr, bytes, PROT_READ | PROT_WRITE | OPT_PROT_EXEC,\n+\t\t  MAP_PRIVATE | MAP_FIXED, fd, 0/* offset */);\n+    if (result == MAP_FAILED) return(0);\n+    last_addr = (ptr_t)result + bytes + GC_page_size - 1;\n+    last_addr = (ptr_t)((word)last_addr & ~(GC_page_size - 1));\n+    return((ptr_t)result);\n+}\n+\n+#else /* Not RS6000, not USE_MMAP */\n+ptr_t GC_unix_get_mem(bytes)\n+word bytes;\n+{\n+  ptr_t result;\n+# ifdef IRIX5\n+    /* Bare sbrk isn't thread safe.  Play by malloc rules.\t*/\n+    /* The equivalent may be needed on other systems as well. \t*/\n+    __LOCK_MALLOC();\n+# endif\n+  {\n+    ptr_t cur_brk = (ptr_t)sbrk(0);\n+    SBRK_ARG_T lsbs = (word)cur_brk & (GC_page_size-1);\n+    \n+    if ((SBRK_ARG_T)bytes < 0) return(0); /* too big */\n+    if (lsbs != 0) {\n+        if((ptr_t)sbrk(GC_page_size - lsbs) == (ptr_t)(-1)) return(0);\n+    }\n+    result = (ptr_t)sbrk((SBRK_ARG_T)bytes);\n+    if (result == (ptr_t)(-1)) result = 0;\n+  }\n+# ifdef IRIX5\n+    __UNLOCK_MALLOC();\n+# endif\n+  return(result);\n+}\n+\n+#endif /* Not USE_MMAP */\n+#endif /* Not RS6000 */\n+\n+# endif /* UN*X */\n+\n+# ifdef OS2\n+\n+void * os2_alloc(size_t bytes)\n+{\n+    void * result;\n+\n+    if (DosAllocMem(&result, bytes, PAG_EXECUTE | PAG_READ |\n+    \t\t\t\t    PAG_WRITE | PAG_COMMIT)\n+\t\t    != NO_ERROR) {\n+\treturn(0);\n+    }\n+    if (result == 0) return(os2_alloc(bytes));\n+    return(result);\n+}\n+\n+# endif /* OS2 */\n+\n+\n+# ifdef MSWIN32\n+word GC_n_heap_bases = 0;\n+\n+ptr_t GC_win32_get_mem(bytes)\n+word bytes;\n+{\n+    ptr_t result;\n+    \n+    if (GC_win32s) {\n+    \t/* VirtualAlloc doesn't like PAGE_EXECUTE_READWRITE.\t*/\n+    \t/* There are also unconfirmed rumors of other\t\t*/\n+    \t/* problems, so we dodge the issue.\t\t\t*/\n+        result = (ptr_t) GlobalAlloc(0, bytes + HBLKSIZE);\n+        result = (ptr_t)(((word)result + HBLKSIZE) & ~(HBLKSIZE-1));\n+    } else {\n+        result = (ptr_t) VirtualAlloc(NULL, bytes,\n+    \t\t\t\t      MEM_COMMIT | MEM_RESERVE,\n+    \t\t\t\t      PAGE_EXECUTE_READWRITE);\n+    }\n+    if (HBLKDISPL(result) != 0) ABORT(\"Bad VirtualAlloc result\");\n+    \t/* If I read the documentation correctly, this can\t*/\n+    \t/* only happen if HBLKSIZE > 64k or not a power of 2.\t*/\n+    if (GC_n_heap_bases >= MAX_HEAP_SECTS) ABORT(\"Too many heap sections\");\n+    GC_heap_bases[GC_n_heap_bases++] = result;\n+    return(result);\t\t\t  \n+}\n+\n+# endif\n+\n+/* Routine for pushing any additional roots.  In THREADS \t*/\n+/* environment, this is also responsible for marking from \t*/\n+/* thread stacks.  In the SRC_M3 case, it also handles\t\t*/\n+/* global variables.\t\t\t\t\t\t*/\n+#ifndef THREADS\n+void (*GC_push_other_roots)() = 0;\n+#else /* THREADS */\n+\n+# ifdef PCR\n+PCR_ERes GC_push_thread_stack(PCR_Th_T *t, PCR_Any dummy)\n+{\n+    struct PCR_ThCtl_TInfoRep info;\n+    PCR_ERes result;\n+    \n+    info.ti_stkLow = info.ti_stkHi = 0;\n+    result = PCR_ThCtl_GetInfo(t, &info);\n+    GC_push_all_stack((ptr_t)(info.ti_stkLow), (ptr_t)(info.ti_stkHi));\n+    return(result);\n+}\n+\n+/* Push the contents of an old object. We treat this as stack\t*/\n+/* data only becasue that makes it robust against mark stack\t*/\n+/* overflow.\t\t\t\t\t\t\t*/\n+PCR_ERes GC_push_old_obj(void *p, size_t size, PCR_Any data)\n+{\n+    GC_push_all_stack((ptr_t)p, (ptr_t)p + size);\n+    return(PCR_ERes_okay);\n+}\n+\n+\n+void GC_default_push_other_roots()\n+{\n+    /* Traverse data allocated by previous memory managers.\t\t*/\n+\t{\n+\t  extern struct PCR_MM_ProcsRep * GC_old_allocator;\n+\t  \n+\t  if ((*(GC_old_allocator->mmp_enumerate))(PCR_Bool_false,\n+\t  \t\t\t\t\t   GC_push_old_obj, 0)\n+\t      != PCR_ERes_okay) {\n+\t      ABORT(\"Old object enumeration failed\");\n+\t  }\n+\t}\n+    /* Traverse all thread stacks. */\n+\tif (PCR_ERes_IsErr(\n+                PCR_ThCtl_ApplyToAllOtherThreads(GC_push_thread_stack,0))\n+              || PCR_ERes_IsErr(GC_push_thread_stack(PCR_Th_CurrThread(), 0))) {\n+              ABORT(\"Thread stack marking failed\\n\");\n+\t}\n+}\n+\n+# endif /* PCR */\n+\n+# ifdef SRC_M3\n+\n+# ifdef ALL_INTERIOR_POINTERS\n+    --> misconfigured\n+# endif\n+\n+\n+extern void ThreadF__ProcessStacks();\n+\n+void GC_push_thread_stack(start, stop)\n+word start, stop;\n+{\n+   GC_push_all_stack((ptr_t)start, (ptr_t)stop + sizeof(word));\n+}\n+\n+/* Push routine with M3 specific calling convention. */\n+GC_m3_push_root(dummy1, p, dummy2, dummy3)\n+word *p;\n+ptr_t dummy1, dummy2;\n+int dummy3;\n+{\n+    word q = *p;\n+    \n+    if ((ptr_t)(q) >= GC_least_plausible_heap_addr\n+\t && (ptr_t)(q) < GC_greatest_plausible_heap_addr) {\n+\t GC_push_one_checked(q,FALSE);\n+    }\n+}\n+\n+/* M3 set equivalent to RTHeap.TracedRefTypes */\n+typedef struct { int elts[1]; }  RefTypeSet;\n+RefTypeSet GC_TracedRefTypes = {{0x1}};\n+\n+/* From finalize.c */\n+extern void GC_push_finalizer_structures();\n+\n+/* From stubborn.c: */\n+# ifdef STUBBORN_ALLOC\n+    extern GC_PTR * GC_changing_list_start;\n+# endif\n+\n+\n+void GC_default_push_other_roots()\n+{\n+    /* Use the M3 provided routine for finding static roots.\t*/\n+    /* This is a bit dubious, since it presumes no C roots.\t*/\n+    /* We handle the collector roots explicitly.\t\t*/\n+       {\n+# \t ifdef STUBBORN_ALLOC\n+           GC_push_one(GC_changing_list_start);\n+#\t endif\n+      \t GC_push_finalizer_structures();\n+      \t RTMain__GlobalMapProc(GC_m3_push_root, 0, GC_TracedRefTypes);\n+       }\n+\tif (GC_words_allocd > 0) {\n+\t    ThreadF__ProcessStacks(GC_push_thread_stack);\n+\t}\n+\t/* Otherwise this isn't absolutely necessary, and we have\t*/\n+\t/* startup ordering problems.\t\t\t\t\t*/\n+}\n+\n+# endif /* SRC_M3 */\n+\n+# if defined(SOLARIS_THREADS) || defined(WIN32_THREADS) \\\n+     || defined(IRIX_THREADS) || defined LINUX_THREADS\n+\n+extern void GC_push_all_stacks();\n+\n+void GC_default_push_other_roots()\n+{\n+    GC_push_all_stacks();\n+}\n+\n+# endif /* SOLARIS_THREADS || ... */\n+\n+void (*GC_push_other_roots)() = GC_default_push_other_roots;\n+\n+#endif\n+\n+/*\n+ * Routines for accessing dirty  bits on virtual pages.\n+ * We plan to eventaually implement four strategies for doing so:\n+ * DEFAULT_VDB:\tA simple dummy implementation that treats every page\n+ *\t\tas possibly dirty.  This makes incremental collection\n+ *\t\tuseless, but the implementation is still correct.\n+ * PCR_VDB:\tUse PPCRs virtual dirty bit facility.\n+ * PROC_VDB:\tUse the /proc facility for reading dirty bits.  Only\n+ *\t\tworks under some SVR4 variants.  Even then, it may be\n+ *\t\ttoo slow to be entirely satisfactory.  Requires reading\n+ *\t\tdirty bits for entire address space.  Implementations tend\n+ *\t\tto assume that the client is a (slow) debugger.\n+ * MPROTECT_VDB:Protect pages and then catch the faults to keep track of\n+ *\t\tdirtied pages.  The implementation (and implementability)\n+ *\t\tis highly system dependent.  This usually fails when system\n+ *\t\tcalls write to a protected page.  We prevent the read system\n+ *\t\tcall from doing so.  It is the clients responsibility to\n+ *\t\tmake sure that other system calls are similarly protected\n+ *\t\tor write only to the stack.\n+ */\n+ \n+GC_bool GC_dirty_maintained = FALSE;\n+\n+# ifdef DEFAULT_VDB\n+\n+/* All of the following assume the allocation lock is held, and\t*/\n+/* signals are disabled.\t\t\t\t\t*/\n+\n+/* The client asserts that unallocated pages in the heap are never\t*/\n+/* written.\t\t\t\t\t\t\t\t*/\n+\n+/* Initialize virtual dirty bit implementation.\t\t\t*/\n+void GC_dirty_init()\n+{\n+    GC_dirty_maintained = TRUE;\n+}\n+\n+/* Retrieve system dirty bits for heap to a local buffer.\t*/\n+/* Restore the systems notion of which pages are dirty.\t\t*/\n+void GC_read_dirty()\n+{}\n+\n+/* Is the HBLKSIZE sized page at h marked dirty in the local buffer?\t*/\n+/* If the actual page size is different, this returns TRUE if any\t*/\n+/* of the pages overlapping h are dirty.  This routine may err on the\t*/\n+/* side of labelling pages as dirty (and this implementation does).\t*/\n+/*ARGSUSED*/\n+GC_bool GC_page_was_dirty(h)\n+struct hblk *h;\n+{\n+    return(TRUE);\n+}\n+\n+/*\n+ * The following two routines are typically less crucial.  They matter\n+ * most with large dynamic libraries, or if we can't accurately identify\n+ * stacks, e.g. under Solaris 2.X.  Otherwise the following default\n+ * versions are adequate.\n+ */\n+ \n+/* Could any valid GC heap pointer ever have been written to this page?\t*/\n+/*ARGSUSED*/\n+GC_bool GC_page_was_ever_dirty(h)\n+struct hblk *h;\n+{\n+    return(TRUE);\n+}\n+\n+/* Reset the n pages starting at h to \"was never dirty\" status.\t*/\n+void GC_is_fresh(h, n)\n+struct hblk *h;\n+word n;\n+{\n+}\n+\n+/* A call hints that h is about to be written.\t*/\n+/* May speed up some dirty bit implementations.\t*/\n+/*ARGSUSED*/\n+void GC_write_hint(h)\n+struct hblk *h;\n+{\n+}\n+\n+# endif /* DEFAULT_VDB */\n+\n+\n+# ifdef MPROTECT_VDB\n+\n+/*\n+ * See DEFAULT_VDB for interface descriptions.\n+ */\n+\n+/*\n+ * This implementation maintains dirty bits itself by catching write\n+ * faults and keeping track of them.  We assume nobody else catches\n+ * SIGBUS or SIGSEGV.  We assume no write faults occur in system calls\n+ * except as a result of a read system call.  This means clients must\n+ * either ensure that system calls do not touch the heap, or must\n+ * provide their own wrappers analogous to the one for read.\n+ * We assume the page size is a multiple of HBLKSIZE.\n+ * This implementation is currently SunOS 4.X and IRIX 5.X specific, though we\n+ * tried to use portable code where easily possible.  It is known\n+ * not to work under a number of other systems.\n+ */\n+\n+# ifndef MSWIN32\n+\n+#   include <sys/mman.h>\n+#   include <signal.h>\n+#   include <sys/syscall.h>\n+\n+#   define PROTECT(addr, len) \\\n+    \t  if (mprotect((caddr_t)(addr), (int)(len), \\\n+    \t      \t       PROT_READ | OPT_PROT_EXEC) < 0) { \\\n+    \t    ABORT(\"mprotect failed\"); \\\n+    \t  }\n+#   define UNPROTECT(addr, len) \\\n+    \t  if (mprotect((caddr_t)(addr), (int)(len), \\\n+    \t  \t       PROT_WRITE | PROT_READ | OPT_PROT_EXEC ) < 0) { \\\n+    \t    ABORT(\"un-mprotect failed\"); \\\n+    \t  }\n+    \t  \n+# else\n+\n+#   include <signal.h>\n+\n+    static DWORD protect_junk;\n+#   define PROTECT(addr, len) \\\n+\t  if (!VirtualProtect((addr), (len), PAGE_EXECUTE_READ, \\\n+\t  \t\t      &protect_junk)) { \\\n+\t    DWORD last_error = GetLastError(); \\\n+\t    GC_printf1(\"Last error code: %lx\\n\", last_error); \\\n+\t    ABORT(\"VirtualProtect failed\"); \\\n+\t  }\n+#   define UNPROTECT(addr, len) \\\n+\t  if (!VirtualProtect((addr), (len), PAGE_EXECUTE_READWRITE, \\\n+\t  \t\t      &protect_junk)) { \\\n+\t    ABORT(\"un-VirtualProtect failed\"); \\\n+\t  }\n+\t  \n+# endif\n+\n+VOLATILE page_hash_table GC_dirty_pages;\n+\t\t\t\t/* Pages dirtied since last GC_read_dirty. */\n+\n+#if defined(SUNOS4) || defined(FREEBSD)\n+    typedef void (* SIG_PF)();\n+#endif\n+#if defined(SUNOS5SIGS) || defined(OSF1) || defined(LINUX)\n+    typedef void (* SIG_PF)(int);\n+#endif\n+#if defined(MSWIN32)\n+    typedef LPTOP_LEVEL_EXCEPTION_FILTER SIG_PF;\n+#   undef SIG_DFL\n+#   define SIG_DFL (LPTOP_LEVEL_EXCEPTION_FILTER) (-1)\n+#endif\n+\n+#if defined(IRIX5) || defined(OSF1)\n+    typedef void (* REAL_SIG_PF)(int, int, struct sigcontext *);\n+#endif\n+#if defined(SUNOS5SIGS)\n+    typedef void (* REAL_SIG_PF)(int, struct siginfo *, void *);\n+#endif\n+#if defined(LINUX)\n+#   include <linux/version.h>\n+#   if (LINUX_VERSION_CODE >= 0x20100)\n+      typedef void (* REAL_SIG_PF)(int, struct sigcontext);\n+#   else\n+      typedef void (* REAL_SIG_PF)(int, struct sigcontext_struct);\n+#   endif\n+# endif\n+\n+SIG_PF GC_old_bus_handler;\n+SIG_PF GC_old_segv_handler;\t/* Also old MSWIN32 ACCESS_VIOLATION filter */\n+\n+/*ARGSUSED*/\n+# if defined (SUNOS4) || defined(FREEBSD)\n+    void GC_write_fault_handler(sig, code, scp, addr)\n+    int sig, code;\n+    struct sigcontext *scp;\n+    char * addr;\n+#   ifdef SUNOS4\n+#     define SIG_OK (sig == SIGSEGV || sig == SIGBUS)\n+#     define CODE_OK (FC_CODE(code) == FC_PROT \\\n+              \t    || (FC_CODE(code) == FC_OBJERR \\\n+              \t       && FC_ERRNO(code) == FC_PROT))\n+#   endif\n+#   ifdef FREEBSD\n+#     define SIG_OK (sig == SIGBUS)\n+#     define CODE_OK (code == BUS_PAGE_FAULT)\n+#   endif\n+# endif\n+# if defined(IRIX5) || defined(OSF1)\n+#   include <errno.h>\n+    void GC_write_fault_handler(int sig, int code, struct sigcontext *scp)\n+#   define SIG_OK (sig == SIGSEGV)\n+#   ifdef OSF1\n+#     define CODE_OK (code == 2 /* experimentally determined */)\n+#   endif\n+#   ifdef IRIX5\n+#     define CODE_OK (code == EACCES)\n+#   endif\n+# endif\n+# if defined(LINUX)\n+#   if (LINUX_VERSION_CODE >= 0x20100)\n+      void GC_write_fault_handler(int sig, struct sigcontext sc)\n+#   else\n+      void GC_write_fault_handler(int sig, struct sigcontext_struct sc)\n+#   endif\n+#   define SIG_OK (sig == SIGSEGV)\n+#   define CODE_OK TRUE\n+\t/* Empirically c.trapno == 14, but is that useful?      */\n+\t/* We assume Intel architecture, so alignment\t\t*/\n+\t/* faults are not possible.\t\t\t\t*/\n+# endif\n+# if defined(SUNOS5SIGS)\n+    void GC_write_fault_handler(int sig, struct siginfo *scp, void * context)\n+#   define SIG_OK (sig == SIGSEGV)\n+#   define CODE_OK (scp -> si_code == SEGV_ACCERR)\n+# endif\n+# if defined(MSWIN32)\n+    LONG WINAPI GC_write_fault_handler(struct _EXCEPTION_POINTERS *exc_info)\n+#   define SIG_OK (exc_info -> ExceptionRecord -> ExceptionCode == \\\n+\t\t\tEXCEPTION_ACCESS_VIOLATION)\n+#   define CODE_OK (exc_info -> ExceptionRecord -> ExceptionInformation[0] == 1)\n+\t\t\t/* Write fault */\n+# endif\n+{\n+    register unsigned i;\n+#   ifdef IRIX5\n+\tchar * addr = (char *) (size_t) (scp -> sc_badvaddr);\n+#   endif\n+#   if defined(OSF1) && defined(ALPHA)\n+\tchar * addr = (char *) (scp -> sc_traparg_a0);\n+#   endif\n+#   ifdef SUNOS5SIGS\n+\tchar * addr = (char *) (scp -> si_addr);\n+#   endif\n+#   ifdef LINUX\n+#     ifdef I386\n+\tchar * addr = (char *) (sc.cr2);\n+#     else\n+        char * addr = /* As of 1.3.90 there seemed to be no way to do this. */;\n+#     endif\n+#   endif\n+#   if defined(MSWIN32)\n+\tchar * addr = (char *) (exc_info -> ExceptionRecord\n+\t\t\t\t-> ExceptionInformation[1]);\n+#\tdefine sig SIGSEGV\n+#   endif\n+    \n+    if (SIG_OK && CODE_OK) {\n+        register struct hblk * h =\n+        \t\t(struct hblk *)((word)addr & ~(GC_page_size-1));\n+        GC_bool in_allocd_block;\n+        \n+#\tifdef SUNOS5SIGS\n+\t    /* Address is only within the correct physical page.\t*/\n+\t    in_allocd_block = FALSE;\n+            for (i = 0; i < divHBLKSZ(GC_page_size); i++) {\n+              if (HDR(h+i) != 0) {\n+                in_allocd_block = TRUE;\n+              }\n+            }\n+#\telse\n+\t    in_allocd_block = (HDR(addr) != 0);\n+#\tendif\n+        if (!in_allocd_block) {\n+\t    /* Heap blocks now begin and end on page boundaries */\n+            SIG_PF old_handler;\n+            \n+            if (sig == SIGSEGV) {\n+            \told_handler = GC_old_segv_handler;\n+            } else {\n+                old_handler = GC_old_bus_handler;\n+            }\n+            if (old_handler == SIG_DFL) {\n+#\t\tifndef MSWIN32\n+                    ABORT(\"Unexpected bus error or segmentation fault\");\n+#\t\telse\n+\t\t    return(EXCEPTION_CONTINUE_SEARCH);\n+#\t\tendif\n+            } else {\n+#\t\tif defined (SUNOS4) || defined(FREEBSD)\n+\t\t    (*old_handler) (sig, code, scp, addr);\n+\t\t    return;\n+#\t\tendif\n+#\t\tif defined (SUNOS5SIGS)\n+\t\t    (*(REAL_SIG_PF)old_handler) (sig, scp, context);\n+\t\t    return;\n+#\t\tendif\n+#\t\tif defined (LINUX)\n+\t\t    (*(REAL_SIG_PF)old_handler) (sig, sc);\n+\t\t    return;\n+#\t\tendif\n+#\t\tif defined (IRIX5) || defined(OSF1)\n+\t\t    (*(REAL_SIG_PF)old_handler) (sig, code, scp);\n+\t\t    return;\n+#\t\tendif\n+#\t\tifdef MSWIN32\n+\t\t    return((*old_handler)(exc_info));\n+#\t\tendif\n+            }\n+        }\n+        for (i = 0; i < divHBLKSZ(GC_page_size); i++) {\n+            register int index = PHT_HASH(h+i);\n+            \n+            set_pht_entry_from_index(GC_dirty_pages, index);\n+        }\n+        UNPROTECT(h, GC_page_size);\n+#\tif defined(OSF1) || defined(LINUX)\n+\t    /* These reset the signal handler each time by default. */\n+\t    signal(SIGSEGV, (SIG_PF) GC_write_fault_handler);\n+#\tendif\n+    \t/* The write may not take place before dirty bits are read.\t*/\n+    \t/* But then we'll fault again ...\t\t\t\t*/\n+#\tifdef MSWIN32\n+\t    return(EXCEPTION_CONTINUE_EXECUTION);\n+#\telse\n+\t    return;\n+#\tendif\n+    }\n+#ifdef MSWIN32\n+    return EXCEPTION_CONTINUE_SEARCH;\n+#else\n+    ABORT(\"Unexpected bus error or segmentation fault\");\n+#endif\n+}\n+\n+/*\n+ * We hold the allocation lock.  We expect block h to be written\n+ * shortly.\n+ */\n+void GC_write_hint(h)\n+struct hblk *h;\n+{\n+    register struct hblk * h_trunc;\n+    register unsigned i;\n+    register GC_bool found_clean;\n+    \n+    if (!GC_dirty_maintained) return;\n+    h_trunc = (struct hblk *)((word)h & ~(GC_page_size-1));\n+    found_clean = FALSE;\n+    for (i = 0; i < divHBLKSZ(GC_page_size); i++) {\n+        register int index = PHT_HASH(h_trunc+i);\n+            \n+        if (!get_pht_entry_from_index(GC_dirty_pages, index)) {\n+            found_clean = TRUE;\n+            set_pht_entry_from_index(GC_dirty_pages, index);\n+        }\n+    }\n+    if (found_clean) {\n+    \tUNPROTECT(h_trunc, GC_page_size);\n+    }\n+}\n+\n+void GC_dirty_init()\n+{\n+#if defined(SUNOS5SIGS) || defined(IRIX5)\n+    struct sigaction\tact, oldact;\n+#   ifdef IRIX5\n+    \tact.sa_flags\t= SA_RESTART;\n+        act.sa_handler  = GC_write_fault_handler;\n+#   else\n+    \tact.sa_flags\t= SA_RESTART | SA_SIGINFO;\n+        act.sa_sigaction = GC_write_fault_handler;\n+#   endif\n+    (void)sigemptyset(&act.sa_mask); \n+#endif\n+#   ifdef PRINTSTATS\n+\tGC_printf0(\"Inititalizing mprotect virtual dirty bit implementation\\n\");\n+#   endif\n+    GC_dirty_maintained = TRUE;\n+    if (GC_page_size % HBLKSIZE != 0) {\n+        GC_err_printf0(\"Page size not multiple of HBLKSIZE\\n\");\n+        ABORT(\"Page size not multiple of HBLKSIZE\");\n+    }\n+#   if defined(SUNOS4) || defined(FREEBSD)\n+      GC_old_bus_handler = signal(SIGBUS, GC_write_fault_handler);\n+      if (GC_old_bus_handler == SIG_IGN) {\n+        GC_err_printf0(\"Previously ignored bus error!?\");\n+        GC_old_bus_handler = SIG_DFL;\n+      }\n+      if (GC_old_bus_handler != SIG_DFL) {\n+#\tifdef PRINTSTATS\n+          GC_err_printf0(\"Replaced other SIGBUS handler\\n\");\n+#\tendif\n+      }\n+#   endif\n+#   if defined(OSF1) || defined(SUNOS4) || defined(LINUX)\n+      GC_old_segv_handler = signal(SIGSEGV, (SIG_PF)GC_write_fault_handler);\n+      if (GC_old_segv_handler == SIG_IGN) {\n+        GC_err_printf0(\"Previously ignored segmentation violation!?\");\n+        GC_old_segv_handler = SIG_DFL;\n+      }\n+      if (GC_old_segv_handler != SIG_DFL) {\n+#\tifdef PRINTSTATS\n+          GC_err_printf0(\"Replaced other SIGSEGV handler\\n\");\n+#\tendif\n+      }\n+#   endif\n+#   if defined(SUNOS5SIGS) || defined(IRIX5)\n+#     ifdef IRIX_THREADS\n+      \tsigaction(SIGSEGV, 0, &oldact);\n+      \tsigaction(SIGSEGV, &act, 0);\n+#     else\n+      \tsigaction(SIGSEGV, &act, &oldact);\n+#     endif\n+#     if defined(_sigargs)\n+\t/* This is Irix 5.x, not 6.x.  Irix 5.x does not have\t*/\n+\t/* sa_sigaction.\t\t\t\t\t*/\n+\tGC_old_segv_handler = oldact.sa_handler;\n+#     else /* Irix 6.x or SUNOS5SIGS */\n+        if (oldact.sa_flags & SA_SIGINFO) {\n+          GC_old_segv_handler = (SIG_PF)(oldact.sa_sigaction);\n+        } else {\n+          GC_old_segv_handler = oldact.sa_handler;\n+        }\n+#     endif\n+      if (GC_old_segv_handler == SIG_IGN) {\n+\t     GC_err_printf0(\"Previously ignored segmentation violation!?\");\n+\t     GC_old_segv_handler = SIG_DFL;\n+      }\n+      if (GC_old_segv_handler != SIG_DFL) {\n+#       ifdef PRINTSTATS\n+\t  GC_err_printf0(\"Replaced other SIGSEGV handler\\n\");\n+#       endif\n+      }\n+#    endif\n+#   if defined(MSWIN32)\n+      GC_old_segv_handler = SetUnhandledExceptionFilter(GC_write_fault_handler);\n+      if (GC_old_segv_handler != NULL) {\n+#\tifdef PRINTSTATS\n+          GC_err_printf0(\"Replaced other UnhandledExceptionFilter\\n\");\n+#\tendif\n+      } else {\n+          GC_old_segv_handler = SIG_DFL;\n+      }\n+#   endif\n+}\n+\n+\n+\n+void GC_protect_heap()\n+{\n+    ptr_t start;\n+    word len;\n+    unsigned i;\n+    \n+    for (i = 0; i < GC_n_heap_sects; i++) {\n+        start = GC_heap_sects[i].hs_start;\n+        len = GC_heap_sects[i].hs_bytes;\n+        PROTECT(start, len);\n+    }\n+}\n+\n+/* We assume that either the world is stopped or its OK to lose dirty\t*/\n+/* bits while this is happenning (as in GC_enable_incremental).\t\t*/\n+void GC_read_dirty()\n+{\n+    BCOPY((word *)GC_dirty_pages, GC_grungy_pages,\n+          (sizeof GC_dirty_pages));\n+    BZERO((word *)GC_dirty_pages, (sizeof GC_dirty_pages));\n+    GC_protect_heap();\n+}\n+\n+GC_bool GC_page_was_dirty(h)\n+struct hblk * h;\n+{\n+    register word index = PHT_HASH(h);\n+    \n+    return(HDR(h) == 0 || get_pht_entry_from_index(GC_grungy_pages, index));\n+}\n+\n+/*\n+ * Acquiring the allocation lock here is dangerous, since this\n+ * can be called from within GC_call_with_alloc_lock, and the cord\n+ * package does so.  On systems that allow nested lock acquisition, this\n+ * happens to work.\n+ * On other systems, SET_LOCK_HOLDER and friends must be suitably defined.\n+ */\n+ \n+void GC_begin_syscall()\n+{\n+    if (!I_HOLD_LOCK()) LOCK();\n+}\n+\n+void GC_end_syscall()\n+{\n+    if (!I_HOLD_LOCK()) UNLOCK();\n+}\n+\n+void GC_unprotect_range(addr, len)\n+ptr_t addr;\n+word len;\n+{\n+    struct hblk * start_block;\n+    struct hblk * end_block;\n+    register struct hblk *h;\n+    ptr_t obj_start;\n+    \n+    if (!GC_incremental) return;\n+    obj_start = GC_base(addr);\n+    if (obj_start == 0) return;\n+    if (GC_base(addr + len - 1) != obj_start) {\n+        ABORT(\"GC_unprotect_range(range bigger than object)\");\n+    }\n+    start_block = (struct hblk *)((word)addr & ~(GC_page_size - 1));\n+    end_block = (struct hblk *)((word)(addr + len - 1) & ~(GC_page_size - 1));\n+    end_block += GC_page_size/HBLKSIZE - 1;\n+    for (h = start_block; h <= end_block; h++) {\n+        register word index = PHT_HASH(h);\n+        \n+        set_pht_entry_from_index(GC_dirty_pages, index);\n+    }\n+    UNPROTECT(start_block,\n+    \t      ((ptr_t)end_block - (ptr_t)start_block) + HBLKSIZE);\n+}\n+\n+#ifndef MSWIN32\n+/* Replacement for UNIX system call.\t */\n+/* Other calls that write to the heap\t */\n+/* should be handled similarly.\t\t */\n+# if defined(__STDC__) && !defined(SUNOS4)\n+#   include <unistd.h>\n+    ssize_t read(int fd, void *buf, size_t nbyte)\n+# else\n+#   ifndef LINT\n+      int read(fd, buf, nbyte)\n+#   else\n+      int GC_read(fd, buf, nbyte)\n+#   endif\n+    int fd;\n+    char *buf;\n+    int nbyte;\n+# endif\n+{\n+    int result;\n+    \n+    GC_begin_syscall();\n+    GC_unprotect_range(buf, (word)nbyte);\n+#   ifdef IRIX5\n+\t/* Indirect system call may not always be easily available.\t*/\n+\t/* We could call _read, but that would interfere with the\t*/\n+\t/* libpthread interception of read.\t\t\t\t*/\n+\t{\n+\t    struct iovec iov;\n+\n+\t    iov.iov_base = buf;\n+\t    iov.iov_len = nbyte;\n+\t    result = readv(fd, &iov, 1);\n+\t}\n+#   else\n+    \tresult = syscall(SYS_read, fd, buf, nbyte);\n+#   endif\n+    GC_end_syscall();\n+    return(result);\n+}\n+#endif /* !MSWIN32 */\n+\n+/*ARGSUSED*/\n+GC_bool GC_page_was_ever_dirty(h)\n+struct hblk *h;\n+{\n+    return(TRUE);\n+}\n+\n+/* Reset the n pages starting at h to \"was never dirty\" status.\t*/\n+/*ARGSUSED*/\n+void GC_is_fresh(h, n)\n+struct hblk *h;\n+word n;\n+{\n+}\n+\n+# endif /* MPROTECT_VDB */\n+\n+# ifdef PROC_VDB\n+\n+/*\n+ * See DEFAULT_VDB for interface descriptions.\n+ */\n+ \n+/*\n+ * This implementaion assumes a Solaris 2.X like /proc pseudo-file-system\n+ * from which we can read page modified bits.  This facility is far from\n+ * optimal (e.g. we would like to get the info for only some of the\n+ * address space), but it avoids intercepting system calls.\n+ */\n+\n+#include <errno.h>\n+#include <sys/types.h>\n+#include <sys/signal.h>\n+#include <sys/fault.h>\n+#include <sys/syscall.h>\n+#include <sys/procfs.h>\n+#include <sys/stat.h>\n+#include <fcntl.h>\n+\n+#define INITIAL_BUF_SZ 4096\n+word GC_proc_buf_size = INITIAL_BUF_SZ;\n+char *GC_proc_buf;\n+\n+page_hash_table GC_written_pages = { 0 };\t/* Pages ever dirtied\t*/\n+\n+#ifdef SOLARIS_THREADS\n+/* We don't have exact sp values for threads.  So we count on\t*/\n+/* occasionally declaring stack pages to be fresh.  Thus we \t*/\n+/* need a real implementation of GC_is_fresh.  We can't clear\t*/\n+/* entries in GC_written_pages, since that would declare all\t*/\n+/* pages with the given hash address to be fresh.\t\t*/\n+#   define MAX_FRESH_PAGES 8*1024\t/* Must be power of 2 */\n+    struct hblk ** GC_fresh_pages;\t/* A direct mapped cache.\t*/\n+    \t\t\t\t\t/* Collisions are dropped.\t*/\n+\n+#   define FRESH_PAGE_SLOT(h) (divHBLKSZ((word)(h)) & (MAX_FRESH_PAGES-1))\n+#   define ADD_FRESH_PAGE(h) \\\n+\tGC_fresh_pages[FRESH_PAGE_SLOT(h)] = (h)\n+#   define PAGE_IS_FRESH(h) \\\n+\t(GC_fresh_pages[FRESH_PAGE_SLOT(h)] == (h) && (h) != 0)\n+#endif\n+\n+/* Add all pages in pht2 to pht1 */\n+void GC_or_pages(pht1, pht2)\n+page_hash_table pht1, pht2;\n+{\n+    register int i;\n+    \n+    for (i = 0; i < PHT_SIZE; i++) pht1[i] |= pht2[i];\n+}\n+\n+int GC_proc_fd;\n+\n+void GC_dirty_init()\n+{\n+    int fd;\n+    char buf[30];\n+\n+    GC_dirty_maintained = TRUE;\n+    if (GC_words_allocd != 0 || GC_words_allocd_before_gc != 0) {\n+    \tregister int i;\n+    \n+        for (i = 0; i < PHT_SIZE; i++) GC_written_pages[i] = (word)(-1);\n+#       ifdef PRINTSTATS\n+\t    GC_printf1(\"Allocated words:%lu:all pages may have been written\\n\",\n+\t    \t       (unsigned long)\n+\t    \t      \t\t(GC_words_allocd + GC_words_allocd_before_gc));\n+#\tendif       \n+    }\n+    sprintf(buf, \"/proc/%d\", getpid());\n+    fd = open(buf, O_RDONLY);\n+    if (fd < 0) {\n+    \tABORT(\"/proc open failed\");\n+    }\n+    GC_proc_fd = syscall(SYS_ioctl, fd, PIOCOPENPD, 0);\n+    close(fd);\n+    if (GC_proc_fd < 0) {\n+    \tABORT(\"/proc ioctl failed\");\n+    }\n+    GC_proc_buf = GC_scratch_alloc(GC_proc_buf_size);\n+#   ifdef SOLARIS_THREADS\n+\tGC_fresh_pages = (struct hblk **)\n+\t  GC_scratch_alloc(MAX_FRESH_PAGES * sizeof (struct hblk *));\n+\tif (GC_fresh_pages == 0) {\n+\t    GC_err_printf0(\"No space for fresh pages\\n\");\n+\t    EXIT();\n+\t}\n+\tBZERO(GC_fresh_pages, MAX_FRESH_PAGES * sizeof (struct hblk *));\n+#   endif\n+}\n+\n+/* Ignore write hints. They don't help us here.\t*/\n+/*ARGSUSED*/\n+void GC_write_hint(h)\n+struct hblk *h;\n+{\n+}\n+\n+#ifdef SOLARIS_THREADS\n+#   define READ(fd,buf,nbytes) syscall(SYS_read, fd, buf, nbytes)\n+#else\n+#   define READ(fd,buf,nbytes) read(fd, buf, nbytes)\n+#endif\n+\n+void GC_read_dirty()\n+{\n+    unsigned long ps, np;\n+    int nmaps;\n+    ptr_t vaddr;\n+    struct prasmap * map;\n+    char * bufp;\n+    ptr_t current_addr, limit;\n+    int i;\n+int dummy;\n+\n+    BZERO(GC_grungy_pages, (sizeof GC_grungy_pages));\n+    \n+    bufp = GC_proc_buf;\n+    if (READ(GC_proc_fd, bufp, GC_proc_buf_size) <= 0) {\n+#\tifdef PRINTSTATS\n+            GC_printf1(\"/proc read failed: GC_proc_buf_size = %lu\\n\",\n+            \t       GC_proc_buf_size);\n+#\tendif       \n+        {\n+            /* Retry with larger buffer. */\n+            word new_size = 2 * GC_proc_buf_size;\n+            char * new_buf = GC_scratch_alloc(new_size);\n+            \n+            if (new_buf != 0) {\n+                GC_proc_buf = bufp = new_buf;\n+                GC_proc_buf_size = new_size;\n+            }\n+            if (syscall(SYS_read, GC_proc_fd, bufp, GC_proc_buf_size) <= 0) {\n+                WARN(\"Insufficient space for /proc read\\n\", 0);\n+                /* Punt:\t*/\n+        \tmemset(GC_grungy_pages, 0xff, sizeof (page_hash_table));\n+\t\tmemset(GC_written_pages, 0xff, sizeof(page_hash_table));\n+#\t\tifdef SOLARIS_THREADS\n+\t\t    BZERO(GC_fresh_pages,\n+\t\t    \t  MAX_FRESH_PAGES * sizeof (struct hblk *)); \n+#\t\tendif\n+\t\treturn;\n+            }\n+        }\n+    }\n+    /* Copy dirty bits into GC_grungy_pages */\n+    \tnmaps = ((struct prpageheader *)bufp) -> pr_nmap;\n+\t/* printf( \"nmaps = %d, PG_REFERENCED = %d, PG_MODIFIED = %d\\n\",\n+\t\t     nmaps, PG_REFERENCED, PG_MODIFIED); */\n+\tbufp = bufp + sizeof(struct prpageheader);\n+\tfor (i = 0; i < nmaps; i++) {\n+\t    map = (struct prasmap *)bufp;\n+\t    vaddr = (ptr_t)(map -> pr_vaddr);\n+\t    ps = map -> pr_pagesize;\n+\t    np = map -> pr_npage;\n+\t    /* printf(\"vaddr = 0x%X, ps = 0x%X, np = 0x%X\\n\", vaddr, ps, np); */\n+\t    limit = vaddr + ps * np;\n+\t    bufp += sizeof (struct prasmap);\n+\t    for (current_addr = vaddr;\n+\t         current_addr < limit; current_addr += ps){\n+\t        if ((*bufp++) & PG_MODIFIED) {\n+\t            register struct hblk * h = (struct hblk *) current_addr;\n+\t            \n+\t            while ((ptr_t)h < current_addr + ps) {\n+\t                register word index = PHT_HASH(h);\n+\t                \n+\t                set_pht_entry_from_index(GC_grungy_pages, index);\n+#\t\t\tifdef SOLARIS_THREADS\n+\t\t\t  {\n+\t\t\t    register int slot = FRESH_PAGE_SLOT(h);\n+\t\t\t    \n+\t\t\t    if (GC_fresh_pages[slot] == h) {\n+\t\t\t        GC_fresh_pages[slot] = 0;\n+\t\t\t    }\n+\t\t\t  }\n+#\t\t\tendif\n+\t                h++;\n+\t            }\n+\t        }\n+\t    }\n+\t    bufp += sizeof(long) - 1;\n+\t    bufp = (char *)((unsigned long)bufp & ~(sizeof(long)-1));\n+\t}\n+    /* Update GC_written_pages. */\n+        GC_or_pages(GC_written_pages, GC_grungy_pages);\n+#   ifdef SOLARIS_THREADS\n+      /* Make sure that old stacks are considered completely clean\t*/\n+      /* unless written again.\t\t\t\t\t\t*/\n+\tGC_old_stacks_are_fresh();\n+#   endif\n+}\n+\n+#undef READ\n+\n+GC_bool GC_page_was_dirty(h)\n+struct hblk *h;\n+{\n+    register word index = PHT_HASH(h);\n+    register GC_bool result;\n+    \n+    result = get_pht_entry_from_index(GC_grungy_pages, index);\n+#   ifdef SOLARIS_THREADS\n+\tif (result && PAGE_IS_FRESH(h)) result = FALSE;\n+\t/* This happens only if page was declared fresh since\t*/\n+\t/* the read_dirty call, e.g. because it's in an unused  */\n+\t/* thread stack.  It's OK to treat it as clean, in\t*/\n+\t/* that case.  And it's consistent with \t\t*/\n+\t/* GC_page_was_ever_dirty.\t\t\t\t*/\n+#   endif\n+    return(result);\n+}\n+\n+GC_bool GC_page_was_ever_dirty(h)\n+struct hblk *h;\n+{\n+    register word index = PHT_HASH(h);\n+    register GC_bool result;\n+    \n+    result = get_pht_entry_from_index(GC_written_pages, index);\n+#   ifdef SOLARIS_THREADS\n+\tif (result && PAGE_IS_FRESH(h)) result = FALSE;\n+#   endif\n+    return(result);\n+}\n+\n+/* Caller holds allocation lock.\t*/\n+void GC_is_fresh(h, n)\n+struct hblk *h;\n+word n;\n+{\n+\n+    register word index;\n+    \n+#   ifdef SOLARIS_THREADS\n+      register word i;\n+      \n+      if (GC_fresh_pages != 0) {\n+        for (i = 0; i < n; i++) {\n+          ADD_FRESH_PAGE(h + i);\n+        }\n+      }\n+#   endif\n+}\n+\n+# endif /* PROC_VDB */\n+\n+\n+# ifdef PCR_VDB\n+\n+# include \"vd/PCR_VD.h\"\n+\n+# define NPAGES (32*1024)\t/* 128 MB */\n+\n+PCR_VD_DB  GC_grungy_bits[NPAGES];\n+\n+ptr_t GC_vd_base;\t/* Address corresponding to GC_grungy_bits[0]\t*/\n+\t\t\t/* HBLKSIZE aligned.\t\t\t\t*/\n+\n+void GC_dirty_init()\n+{\n+    GC_dirty_maintained = TRUE;\n+    /* For the time being, we assume the heap generally grows up */\n+    GC_vd_base = GC_heap_sects[0].hs_start;\n+    if (GC_vd_base == 0) {\n+   \tABORT(\"Bad initial heap segment\");\n+    }\n+    if (PCR_VD_Start(HBLKSIZE, GC_vd_base, NPAGES*HBLKSIZE)\n+\t!= PCR_ERes_okay) {\n+\tABORT(\"dirty bit initialization failed\");\n+    }\n+}\n+\n+void GC_read_dirty()\n+{\n+    /* lazily enable dirty bits on newly added heap sects */\n+    {\n+        static int onhs = 0;\n+        int nhs = GC_n_heap_sects;\n+        for( ; onhs < nhs; onhs++ ) {\n+            PCR_VD_WriteProtectEnable(\n+                    GC_heap_sects[onhs].hs_start,\n+                    GC_heap_sects[onhs].hs_bytes );\n+        }\n+    }\n+\n+\n+    if (PCR_VD_Clear(GC_vd_base, NPAGES*HBLKSIZE, GC_grungy_bits)\n+        != PCR_ERes_okay) {\n+\tABORT(\"dirty bit read failed\");\n+    }\n+}\n+\n+GC_bool GC_page_was_dirty(h)\n+struct hblk *h;\n+{\n+    if((ptr_t)h < GC_vd_base || (ptr_t)h >= GC_vd_base + NPAGES*HBLKSIZE) {\n+\treturn(TRUE);\n+    }\n+    return(GC_grungy_bits[h - (struct hblk *)GC_vd_base] & PCR_VD_DB_dirtyBit);\n+}\n+\n+/*ARGSUSED*/\n+void GC_write_hint(h)\n+struct hblk *h;\n+{\n+    PCR_VD_WriteProtectDisable(h, HBLKSIZE);\n+    PCR_VD_WriteProtectEnable(h, HBLKSIZE);\n+}\n+\n+# endif /* PCR_VDB */\n+\n+/*\n+ * Call stack save code for debugging.\n+ * Should probably be in mach_dep.c, but that requires reorganization.\n+ */\n+#if defined(SPARC)\n+#   if defined(SUNOS4)\n+#     include <machine/frame.h>\n+#   else\n+#     if defined (DRSNX)\n+#\tinclude <sys/sparc/frame.h>\n+#     else\n+#       include <sys/frame.h>\n+#     endif\n+#   endif\n+#   if NARGS > 6\n+\t--> We only know how to to get the first 6 arguments\n+#   endif\n+\n+#ifdef SAVE_CALL_CHAIN\n+/* Fill in the pc and argument information for up to NFRAMES of my\t*/\n+/* callers.  Ignore my frame and my callers frame.\t\t\t*/\n+void GC_save_callers (info) \n+struct callinfo info[NFRAMES];\n+{\n+  struct frame *frame;\n+  struct frame *fp;\n+  int nframes = 0;\n+  word GC_save_regs_in_stack();\n+\n+  frame = (struct frame *) GC_save_regs_in_stack ();\n+  \n+  for (fp = frame -> fr_savfp; fp != 0 && nframes < NFRAMES;\n+       fp = fp -> fr_savfp, nframes++) {\n+      register int i;\n+      \n+      info[nframes].ci_pc = fp->fr_savpc;\n+      for (i = 0; i < NARGS; i++) {\n+\tinfo[nframes].ci_arg[i] = ~(fp->fr_arg[i]);\n+      }\n+  }\n+  if (nframes < NFRAMES) info[nframes].ci_pc = 0;\n+}\n+\n+#endif /* SAVE_CALL_CHAIN */\n+#endif /* SPARC */\n+\n+\n+"}]}