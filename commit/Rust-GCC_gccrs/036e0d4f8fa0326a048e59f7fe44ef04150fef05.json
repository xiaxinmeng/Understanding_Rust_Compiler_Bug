{"sha": "036e0d4f8fa0326a048e59f7fe44ef04150fef05", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDM2ZTBkNGY4ZmEwMzI2YTA0OGU1OWY3ZmU0NGVmMDQxNTBmZWYwNQ==", "commit": {"author": {"name": "Benjamin Kosnik", "email": "bkoz@gcc.gnu.org", "date": "2011-02-16T19:01:51Z"}, "committer": {"name": "Benjamin Kosnik", "email": "bkoz@gcc.gnu.org", "date": "2011-02-16T19:01:51Z"}, "message": "atomic: Remove atomic_address, uplift to N3225.\n\n2011-02-16  Benjamin Kosnik  <bkoz@redhat.com>\n\n\t* include/std/atomic: Remove atomic_address, uplift to N3225.\n\t* include/bits/atomic_0.h: Same.\n\t* include/bits/atomic_2.h: Same.\n\t* include/bits/atomic_base.h: Same.\n\t* testsuite/29_atomics/atomic_address/*: Delete.\n\nFrom-SVN: r170217", "tree": {"sha": "2a2a081228b66ebf2acae9efc0a8b0bb0973938c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2a2a081228b66ebf2acae9efc0a8b0bb0973938c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/036e0d4f8fa0326a048e59f7fe44ef04150fef05", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/036e0d4f8fa0326a048e59f7fe44ef04150fef05", "html_url": "https://github.com/Rust-GCC/gccrs/commit/036e0d4f8fa0326a048e59f7fe44ef04150fef05", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/036e0d4f8fa0326a048e59f7fe44ef04150fef05/comments", "author": null, "committer": null, "parents": [{"sha": "3808007ca0a79b0a2df3f9257fe4999b353f42ac", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3808007ca0a79b0a2df3f9257fe4999b353f42ac", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3808007ca0a79b0a2df3f9257fe4999b353f42ac"}], "stats": {"total": 2234, "additions": 769, "deletions": 1465}, "files": [{"sha": "077372cde2b5ebc7f206a1901d5afe49735a51c3", "filename": "libstdc++-v3/ChangeLog", "status": "modified", "additions": 13, "deletions": 5, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2FChangeLog?ref=036e0d4f8fa0326a048e59f7fe44ef04150fef05", "patch": "@@ -1,3 +1,11 @@\n+2011-02-16  Benjamin Kosnik  <bkoz@redhat.com>\n+\n+\t* include/std/atomic: Remove atomic_address, uplift to N3225.\n+\t* include/bits/atomic_0.h: Same.\n+\t* include/bits/atomic_2.h: Same.\n+\t* include/bits/atomic_base.h: Same.\n+\t* testsuite/29_atomics/atomic_address/*: Delete.\n+\n 2011-02-14  Jonathan Wakely  <jwakely.gcc@gmail.com>\n \n \t* include/bits/regex.h (sub_match::sub_match): Add.\n@@ -36,7 +44,7 @@\n \t* testsuite/ext/is_heap/47709.cc: New.\n \n 2011-02-12  Jakub Jelinek  <jakub@redhat.com>\n-            Jonathan Wakely  <jwakely.gcc@gmail.com>\n+\t    Jonathan Wakely  <jwakely.gcc@gmail.com>\n \n \tPR libstdc++/47662\n \t* testsuite/17_intro/headers/c++200x/operator_names.cc: New.\n@@ -259,10 +267,10 @@\n \n 2011-01-31  Paolo Carlini  <paolo.carlini@oracle.com>\n \n-        * doc/html/ext/lwg-active.html: Update to Revision D73.\n-        * doc/html/ext/lwg-closed.html: Likewise.\n-        * doc/html/ext/lwg-defects.html: Likewise.\n-        * doc/xml/manual/intro.xml: Update status of issues 408, 539, 865.\n+\t* doc/html/ext/lwg-active.html: Update to Revision D73.\n+\t* doc/html/ext/lwg-closed.html: Likewise.\n+\t* doc/html/ext/lwg-defects.html: Likewise.\n+\t* doc/xml/manual/intro.xml: Update status of issues 408, 539, 865.\n \n 2011-01-30  Benjamin Kosnik  <bkoz@redhat.com>\n "}, {"sha": "84ff779ef05ed735fd31bd1962084bfe253e1e15", "filename": "libstdc++-v3/include/bits/atomic_0.h", "status": "modified", "additions": 215, "deletions": 295, "changes": 510, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_0.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_0.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_0.h?ref=036e0d4f8fa0326a048e59f7fe44ef04150fef05", "patch": "@@ -134,300 +134,6 @@ namespace __atomic0\n   };\n \n \n-  /// atomic_address\n-  struct atomic_address\n-  {\n-  private:\n-    void* _M_i;\n-\n-  public:\n-    atomic_address() = default;\n-    ~atomic_address() = default;\n-    atomic_address(const atomic_address&) = delete;\n-    atomic_address& operator=(const atomic_address&) = delete;\n-    atomic_address& operator=(const atomic_address&) volatile = delete;\n-\n-    constexpr atomic_address(void* __v): _M_i (__v) { }\n-\n-    bool\n-    is_lock_free() const { return false; }\n-\n-    bool\n-    is_lock_free() const volatile { return false; }\n-\n-    void\n-    store(void* __v, memory_order __m = memory_order_seq_cst)\n-    {\n-      __glibcxx_assert(__m != memory_order_acquire);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-      __glibcxx_assert(__m != memory_order_consume);\n-      _ATOMIC_STORE_(this, __v, __m);\n-    }\n-\n-    void\n-    store(void* __v, memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      __glibcxx_assert(__m != memory_order_acquire);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-      __glibcxx_assert(__m != memory_order_consume);\n-      _ATOMIC_STORE_(this, __v, __m);\n-    }\n-\n-    void*\n-    load(memory_order __m = memory_order_seq_cst) const\n-    {\n-      __glibcxx_assert(__m != memory_order_release);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-      return _ATOMIC_LOAD_(this, __m);\n-    }\n-\n-    void*\n-    load(memory_order __m = memory_order_seq_cst) const volatile\n-    {\n-      __glibcxx_assert(__m != memory_order_release);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-      return _ATOMIC_LOAD_(this, __m);\n-    }\n-\n-    void*\n-    exchange(void* __v, memory_order __m = memory_order_seq_cst)\n-    { return _ATOMIC_MODIFY_(this, =, __v, __m); }\n-\n-    void*\n-    exchange(void* __v, memory_order __m = memory_order_seq_cst) volatile\n-    { return _ATOMIC_MODIFY_(this, =, __v, __m); }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t  memory_order __m2)\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t  memory_order __m2) volatile\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m1, memory_order __m2)\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m1, memory_order __m2) volatile\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t    memory_order __m2)\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t    memory_order __m2) volatile\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m1, memory_order __m2)\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m1, memory_order __m2) volatile\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-      return _ATOMIC_CMPEXCHNG_(this, &__v1, __v2, __m1);\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    void*\n-    fetch_add(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n-    {\n-      void** __p = &(_M_i);\n-      __atomic_flag_base* __g = __atomic_flag_for_address(__p);\n-      __atomic_flag_wait_explicit(__g, __m);\n-      void* __r = *__p;\n-      *__p = (void*)((char*)(*__p) + __d);\n-      atomic_flag_clear_explicit(__g, __m);\n-      return __r;\n-    }\n-\n-    void*\n-    fetch_add(ptrdiff_t __d, memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      void* volatile* __p = &(_M_i);\n-      __atomic_flag_base* __g = __atomic_flag_for_address(__p);\n-      __atomic_flag_wait_explicit(__g, __m);\n-      void* __r = *__p;\n-      *__p = (void*)((char*)(*__p) + __d);\n-      atomic_flag_clear_explicit(__g, __m);\n-      return __r;\n-    }\n-\n-    void*\n-    fetch_sub(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n-    {\n-      void** __p = &(_M_i);\n-      __atomic_flag_base* __g = __atomic_flag_for_address(__p);\n-      __atomic_flag_wait_explicit(__g, __m);\n-      void* __r = *__p;\n-      *__p = (void*)((char*)(*__p) - __d);\n-      atomic_flag_clear_explicit(__g, __m);\n-      return __r;\n-    }\n-\n-    void*\n-    fetch_sub(ptrdiff_t __d, memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      void* volatile* __p = &(_M_i);\n-      __atomic_flag_base* __g = __atomic_flag_for_address(__p);\n-      __atomic_flag_wait_explicit(__g, __m);\n-      void* __r = *__p;\n-      *__p = (void*)((char*)(*__p) - __d);\n-      atomic_flag_clear_explicit(__g, __m);\n-      return __r;\n-    }\n-\n-    operator void*() const\n-    { return load(); }\n-\n-    operator void*() const volatile\n-    { return load(); }\n-\n-    // XXX\n-    void*\n-    operator=(void* __v)\n-    {\n-      store(__v);\n-      return __v;\n-    }\n-\n-    void*\n-    operator=(void* __v) volatile\n-    {\n-      store(__v);\n-      return __v;\n-    }\n-\n-    void*\n-    operator+=(ptrdiff_t __d)\n-    { return fetch_add(__d) + __d; }\n-\n-    void*\n-    operator+=(ptrdiff_t __d) volatile\n-    { return fetch_add(__d) + __d; }\n-\n-    void*\n-    operator-=(ptrdiff_t __d)\n-    { return fetch_sub(__d) - __d; }\n-\n-    void*\n-    operator-=(ptrdiff_t __d) volatile\n-    { return fetch_sub(__d) - __d; }\n-  };\n-\n-\n   /// Base class for atomic integrals.\n   //\n   // For each of the integral types, define atomic_[integral type] struct\n@@ -728,13 +434,227 @@ namespace __atomic0\n       { return _ATOMIC_MODIFY_(this, ^=, __i, __m); }\n     };\n \n+\n+  /// Partial specialization for pointer types.\n+  template<typename _PTp>\n+    struct __atomic_base<_PTp*>\n+    {\n+    private:\n+      typedef _PTp* \t__return_pointer_type;\n+      typedef void* \t__pointer_type;\n+      __pointer_type \t_M_i;\n+\n+    public:\n+      __atomic_base() = default;\n+      ~__atomic_base() = default;\n+      __atomic_base(const __atomic_base&) = delete;\n+      __atomic_base& operator=(const __atomic_base&) = delete;\n+      __atomic_base& operator=(const __atomic_base&) volatile = delete;\n+\n+      // Requires __pointer_type convertible to _M_i.\n+      constexpr __atomic_base(__return_pointer_type __p): _M_i (__p) { }\n+\n+      operator __return_pointer_type() const\n+      { return reinterpret_cast<__return_pointer_type>(load()); }\n+\n+      operator __return_pointer_type() const volatile\n+      { return reinterpret_cast<__return_pointer_type>(load()); }\n+\n+      __return_pointer_type\n+      operator=(__pointer_type __p)\n+      {\n+\tstore(__p);\n+\treturn reinterpret_cast<__return_pointer_type>(__p);\n+      }\n+\n+      __return_pointer_type\n+      operator=(__pointer_type __p) volatile\n+      {\n+\tstore(__p);\n+\treturn reinterpret_cast<__return_pointer_type>(__p);\n+      }\n+\n+      __return_pointer_type\n+      operator++(int)\n+      { return reinterpret_cast<__return_pointer_type>(fetch_add(1)); }\n+\n+      __return_pointer_type\n+      operator++(int) volatile\n+      { return reinterpret_cast<__return_pointer_type>(fetch_add(1)); }\n+\n+      __return_pointer_type\n+      operator--(int)\n+      { return reinterpret_cast<__return_pointer_type>(fetch_sub(1)); }\n+\n+      __return_pointer_type\n+      operator--(int) volatile\n+      { return reinterpret_cast<__return_pointer_type>(fetch_sub(1)); }\n+\n+      __return_pointer_type\n+      operator++()\n+      { return reinterpret_cast<__return_pointer_type>(fetch_add(1) + 1); }\n+\n+      __return_pointer_type\n+      operator++() volatile\n+      { return reinterpret_cast<__return_pointer_type>(fetch_add(1) + 1); }\n+\n+      __return_pointer_type\n+      operator--()\n+      { return reinterpret_cast<__return_pointer_type>(fetch_sub(1) - 1); }\n+\n+      __return_pointer_type\n+      operator--() volatile\n+      { return reinterpret_cast<__return_pointer_type>(fetch_sub(1) - 1); }\n+\n+      __return_pointer_type\n+      operator+=(ptrdiff_t __d)\n+      { return reinterpret_cast<__return_pointer_type>(fetch_add(__d) + __d); }\n+\n+      __return_pointer_type\n+      operator+=(ptrdiff_t __d) volatile\n+      { return reinterpret_cast<__return_pointer_type>(fetch_add(__d) + __d); }\n+\n+      __return_pointer_type\n+      operator-=(ptrdiff_t __d)\n+      { return reinterpret_cast<__return_pointer_type>(fetch_sub(__d) - __d); }\n+\n+      __return_pointer_type\n+      operator-=(ptrdiff_t __d) volatile\n+      { return reinterpret_cast<__return_pointer_type>(fetch_sub(__d) - __d); }\n+\n+      bool\n+      is_lock_free() const\n+      { return true; }\n+\n+      bool\n+      is_lock_free() const volatile\n+      { return true; }\n+\n+      void\n+      store(__pointer_type __p, memory_order __m = memory_order_seq_cst)\n+      {\n+\t__glibcxx_assert(__m != memory_order_acquire);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\t__glibcxx_assert(__m != memory_order_consume);\n+\t_ATOMIC_STORE_(this, __p, __m);\n+      }\n+\n+      void\n+      store(__pointer_type __p,\n+\t    memory_order __m = memory_order_seq_cst) volatile\n+      {\n+\t__glibcxx_assert(__m != memory_order_acquire);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\t__glibcxx_assert(__m != memory_order_consume);\n+\tvolatile __pointer_type* __p2 = &_M_i;\n+\t__typeof__(__p) __w = (__p);\n+\t__atomic_flag_base* __g = __atomic_flag_for_address(__p2);\n+\t__atomic_flag_wait_explicit(__g, __m);\n+\t*__p2 = reinterpret_cast<__pointer_type>(__w);\n+\tatomic_flag_clear_explicit(__g, __m);\n+\t__w;\n+      }\n+\n+      __return_pointer_type\n+      load(memory_order __m = memory_order_seq_cst) const\n+      {\n+\t__glibcxx_assert(__m != memory_order_release);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\tvoid* __v = _ATOMIC_LOAD_(this, __m);\n+\treturn reinterpret_cast<__return_pointer_type>(__v);\n+      }\n+\n+      __return_pointer_type\n+      load(memory_order __m = memory_order_seq_cst) const volatile\n+      {\n+\t__glibcxx_assert(__m != memory_order_release);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\tvoid* __v = _ATOMIC_LOAD_(this, __m);\n+\treturn reinterpret_cast<__return_pointer_type>(__v);\n+      }\n+\n+      __return_pointer_type\n+      exchange(__pointer_type __p, memory_order __m = memory_order_seq_cst)\n+      {\n+\tvoid* __v = _ATOMIC_MODIFY_(this, =, __p, __m);\n+\treturn reinterpret_cast<__return_pointer_type>(__v);\n+      }\n+\n+      __return_pointer_type\n+      exchange(__pointer_type __p,\n+\t       memory_order __m = memory_order_seq_cst) volatile\n+      {\n+\tvolatile __pointer_type* __p2 = &_M_i;\n+\t__typeof__(__p) __w = (__p);\n+\t__atomic_flag_base* __g = __atomic_flag_for_address(__p2);\n+\t__atomic_flag_wait_explicit(__g, __m);\n+\t__pointer_type __r = *__p2;\n+\t*__p2 = __w;\n+\tatomic_flag_clear_explicit(__g, __m);\n+\t__r;\n+\treturn reinterpret_cast<__return_pointer_type>(_M_i);\n+      }\n+\n+      bool\n+      compare_exchange_strong(__return_pointer_type& __rp1, __pointer_type __p2,\n+\t\t\t      memory_order __m1, memory_order __m2)\n+      {\n+\t__glibcxx_assert(__m2 != memory_order_release);\n+\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__m2 <= __m1);\n+\t__pointer_type& __p1 = reinterpret_cast<void*&>(__rp1);\n+\treturn _ATOMIC_CMPEXCHNG_(this, &__p1, __p2, __m1);\n+      }\n+\n+      bool\n+      compare_exchange_strong(__return_pointer_type& __rp1, __pointer_type __p2,\n+\t\t\t      memory_order __m1, memory_order __m2) volatile\n+      {\n+\t__glibcxx_assert(__m2 != memory_order_release);\n+\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__m2 <= __m1);\n+\t__pointer_type& __p1 = reinterpret_cast<void*&>(__rp1);\n+\treturn _ATOMIC_CMPEXCHNG_(this, &__p1, __p2, __m1);\n+      }\n+\n+      __return_pointer_type\n+      fetch_add(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n+      {\n+\tvoid* __v = _ATOMIC_MODIFY_(this, +=, __d, __m);\n+\treturn reinterpret_cast<__return_pointer_type>(__v);\n+      }\n+\n+      __return_pointer_type\n+      fetch_add(ptrdiff_t __d,\n+\t\tmemory_order __m = memory_order_seq_cst) volatile\n+      {\n+\tvoid* __v = _ATOMIC_MODIFY_(this, +=, __d, __m);\n+\treturn reinterpret_cast<__return_pointer_type>(__v);\n+      }\n+\n+      __return_pointer_type\n+      fetch_sub(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n+      {\n+\tvoid* __v = _ATOMIC_MODIFY_(this, -=, __d, __m);\n+\treturn reinterpret_cast<__return_pointer_type>(__v);\n+      }\n+\n+      __return_pointer_type\n+      fetch_sub(ptrdiff_t __d,\n+\t\tmemory_order __m = memory_order_seq_cst) volatile\n+      {\n+\tvoid* __v = _ATOMIC_MODIFY_(this, -=, __d, __m);\n+\treturn reinterpret_cast<__return_pointer_type>(__v);\n+      }\n+    };\n+\n #undef _ATOMIC_LOAD_\n #undef _ATOMIC_STORE_\n #undef _ATOMIC_MODIFY_\n #undef _ATOMIC_CMPEXCHNG_\n } // namespace __atomic0\n \n _GLIBCXX_END_NAMESPACE_VERSION\n-} // namespace\n+} // namespace std\n \n #endif"}, {"sha": "f95beca55c707f7990df9cbe712aa88bcd2332cd", "filename": "libstdc++-v3/include/bits/atomic_2.h", "status": "modified", "additions": 228, "deletions": 314, "changes": 542, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_2.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_2.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_2.h?ref=036e0d4f8fa0326a048e59f7fe44ef04150fef05", "patch": "@@ -1,6 +1,6 @@\n // -*- C++ -*- header.\n \n-// Copyright (C) 2008, 2009, 2010\n+// Copyright (C) 2008, 2009, 2010, 2011\n // Free Software Foundation, Inc.\n //\n // This file is part of the GNU ISO C++ Library.  This library is free\n@@ -23,7 +23,7 @@\n // see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n // <http://www.gnu.org/licenses/>.\n \n-/** @file bits/atomic_2.h \n+/** @file bits/atomic_2.h\n  *  This is an internal header file, included by other library headers.\n  *  Do not attempt to use it directly. @headername{atomic}\n  */\n@@ -101,317 +101,6 @@ namespace __atomic2\n   };\n \n \n-  /// atomic_address\n-  struct atomic_address\n-  {\n-  private:\n-    void* _M_i;\n-\n-  public:\n-    atomic_address() = default;\n-    ~atomic_address() = default;\n-    atomic_address(const atomic_address&) = delete;\n-    atomic_address& operator=(const atomic_address&) = delete;\n-    atomic_address& operator=(const atomic_address&) volatile = delete;\n-\n-    constexpr atomic_address(void* __v): _M_i (__v) {  }\n-\n-    bool\n-    is_lock_free() const { return true; }\n-\n-    bool\n-    is_lock_free() const volatile { return true; }\n-\n-    void\n-    store(void* __v, memory_order __m = memory_order_seq_cst)\n-    {\n-      __glibcxx_assert(__m != memory_order_acquire);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-      __glibcxx_assert(__m != memory_order_consume);\n-\n-      if (__m == memory_order_relaxed)\n-\t_M_i = __v;\n-      else\n-\t{\n-\t  // write_mem_barrier();\n-\t  _M_i = __v;\n-\t  if (__m == memory_order_seq_cst)\n-\t    __sync_synchronize();\n-\t}\n-    }\n-\n-    void\n-    store(void* __v, memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      __glibcxx_assert(__m != memory_order_acquire);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-      __glibcxx_assert(__m != memory_order_consume);\n-\n-      if (__m == memory_order_relaxed)\n-\t_M_i = __v;\n-      else\n-\t{\n-\t  // write_mem_barrier();\n-\t  _M_i = __v;\n-\t  if (__m == memory_order_seq_cst)\n-\t    __sync_synchronize();\n-\t}\n-    }\n-\n-    void*\n-    load(memory_order __m = memory_order_seq_cst) const\n-    {\n-      __glibcxx_assert(__m != memory_order_release);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-\n-      __sync_synchronize();\n-      void* __ret = _M_i;\n-      __sync_synchronize();\n-      return __ret;\n-    }\n-\n-    void*\n-    load(memory_order __m = memory_order_seq_cst) const volatile\n-    {\n-      __glibcxx_assert(__m != memory_order_release);\n-      __glibcxx_assert(__m != memory_order_acq_rel);\n-\n-      __sync_synchronize();\n-      void* __ret = _M_i;\n-      __sync_synchronize();\n-      return __ret;\n-    }\n-\n-    void*\n-    exchange(void* __v, memory_order __m = memory_order_seq_cst)\n-    {\n-      // XXX built-in assumes memory_order_acquire.\n-      return __sync_lock_test_and_set(&_M_i, __v);\n-    }\n-\n-    void*\n-    exchange(void* __v, memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      // XXX built-in assumes memory_order_acquire.\n-      return __sync_lock_test_and_set(&_M_i, __v);\n-    }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t  memory_order __m2)\n-    { return compare_exchange_strong(__v1, __v2, __m1, __m2); }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t  memory_order __m2) volatile\n-    { return compare_exchange_strong(__v1, __v2, __m1, __m2); }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_weak(void*& __v1, void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m1, memory_order __m2)\n-    { return compare_exchange_strong(__v1, __v2, __m1, __m2); }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m1, memory_order __m2) volatile\n-    { return compare_exchange_strong(__v1, __v2, __m1, __m2); }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_weak(const void*& __v1, const void* __v2,\n-\t\t\t  memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_weak(__v1, __v2, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t    memory_order __m2)\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-\n-      void* __v1o = __v1;\n-      void* __v1n = __sync_val_compare_and_swap(&_M_i, __v1o, __v2);\n-\n-      // Assume extra stores (of same value) allowed in true case.\n-      __v1 = __v1n;\n-      return __v1o == __v1n;\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2, memory_order __m1,\n-\t\t\t    memory_order __m2) volatile\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-\n-      void* __v1o = __v1;\n-      void* __v1n = __sync_val_compare_and_swap(&_M_i, __v1o, __v2);\n-\n-      // Assume extra stores (of same value) allowed in true case.\n-      __v1 = __v1n;\n-      return __v1o == __v1n;\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(void*& __v1, void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m1, memory_order __m2)\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-\n-      const void* __v1o = __v1;\n-      const void* __v1n = __sync_val_compare_and_swap(&_M_i, __v1o, __v2);\n-\n-      // Assume extra stores (of same value) allowed in true case.\n-      __v1 = __v1n;\n-      return __v1o == __v1n;\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m1, memory_order __m2) volatile\n-    {\n-      __glibcxx_assert(__m2 != memory_order_release);\n-      __glibcxx_assert(__m2 != memory_order_acq_rel);\n-      __glibcxx_assert(__m2 <= __m1);\n-\n-      const void* __v1o = __v1;\n-      const void* __v1n = __sync_val_compare_and_swap(&_M_i, __v1o, __v2);\n-\n-      // Assume extra stores (of same value) allowed in true case.\n-      __v1 = __v1n;\n-      return __v1o == __v1n;\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst)\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    bool\n-    compare_exchange_strong(const void*& __v1, const void* __v2,\n-\t\t\t    memory_order __m = memory_order_seq_cst) volatile\n-    {\n-      return compare_exchange_strong(__v1, __v2, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-    void*\n-    fetch_add(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n-    { return __sync_fetch_and_add(&_M_i, __d); }\n-\n-    void*\n-    fetch_add(ptrdiff_t __d, memory_order __m = memory_order_seq_cst) volatile\n-    { return __sync_fetch_and_add(&_M_i, __d); }\n-\n-    void*\n-    fetch_sub(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n-    { return __sync_fetch_and_sub(&_M_i, __d); }\n-\n-    void*\n-    fetch_sub(ptrdiff_t __d, memory_order __m = memory_order_seq_cst) volatile\n-    { return __sync_fetch_and_sub(&_M_i, __d); }\n-\n-    operator void*() const\n-    { return load(); }\n-\n-    operator void*() const volatile\n-    { return load(); }\n-\n-    void*\n-#if 0\n-    // XXX as specified but won't compile as store takes void*,\n-    // invalid conversion from const void* to void*\n-    // CD1 had this signature\n-    operator=(const void* __v)\n-#else\n-    operator=(void* __v)      \n-#endif\n-    {\n-      store(__v);\n-      return __v;\n-    }\n-\n-    void*\n-#if 0\n-    // XXX as specified but won't compile as store takes void*,\n-    // invalid conversion from const void* to void*\n-    // CD1 had this signature, but store and this could both be const void*?\n-    operator=(const void* __v) volatile\n-#else\n-    operator=(void* __v) volatile\n-#endif\n-    {\n-      store(__v);\n-      return __v;\n-    }\n-\n-    void*\n-    operator+=(ptrdiff_t __d)\n-    { return __sync_add_and_fetch(&_M_i, __d); }\n-\n-    void*\n-    operator+=(ptrdiff_t __d) volatile\n-    { return __sync_add_and_fetch(&_M_i, __d); }\n-\n-    void*\n-    operator-=(ptrdiff_t __d)\n-    { return __sync_sub_and_fetch(&_M_i, __d); }\n-\n-    void*\n-    operator-=(ptrdiff_t __d) volatile\n-    { return __sync_sub_and_fetch(&_M_i, __d); }\n-  };\n-\n-\n   /// Base class for atomic integrals.\n   //\n   // For each of the integral types, define atomic_[integral type] struct\n@@ -747,9 +436,234 @@ namespace __atomic2\n \t\tmemory_order __m = memory_order_seq_cst) volatile\n       { return __sync_fetch_and_xor(&_M_i, __i); }\n     };\n+\n+\n+  /// Partial specialization for pointer types.\n+  template<typename _PTp>\n+    struct __atomic_base<_PTp*>\n+    {\n+    private:\n+      typedef _PTp* \t__pointer_type;\n+\n+      __pointer_type \t_M_p;\n+\n+    public:\n+      __atomic_base() = default;\n+      ~__atomic_base() = default;\n+      __atomic_base(const __atomic_base&) = delete;\n+      __atomic_base& operator=(const __atomic_base&) = delete;\n+      __atomic_base& operator=(const __atomic_base&) volatile = delete;\n+\n+      // Requires __pointer_type convertible to _M_p.\n+      constexpr __atomic_base(__pointer_type __p): _M_p (__p) { }\n+\n+      operator __pointer_type() const\n+      { return load(); }\n+\n+      operator __pointer_type() const volatile\n+      { return load(); }\n+\n+      __pointer_type\n+      operator=(__pointer_type __p)\n+      {\n+\tstore(__p);\n+\treturn __p;\n+      }\n+\n+      __pointer_type\n+      operator=(__pointer_type __p) volatile\n+      {\n+\tstore(__p);\n+\treturn __p;\n+      }\n+\n+      __pointer_type\n+      operator++(int)\n+      { return fetch_add(1); }\n+\n+      __pointer_type\n+      operator++(int) volatile\n+      { return fetch_add(1); }\n+\n+      __pointer_type\n+      operator--(int)\n+      { return fetch_sub(1); }\n+\n+      __pointer_type\n+      operator--(int) volatile\n+      { return fetch_sub(1); }\n+\n+      __pointer_type\n+      operator++()\n+      { return fetch_add(1) + 1; }\n+\n+      __pointer_type\n+      operator++() volatile\n+      { return fetch_add(1) + 1; }\n+\n+      __pointer_type\n+      operator--()\n+      { return fetch_sub(1) -1; }\n+\n+      __pointer_type\n+      operator--() volatile\n+      { return fetch_sub(1) -1; }\n+\n+      __pointer_type\n+      operator+=(ptrdiff_t __d)\n+      { return fetch_add(__d) + __d; }\n+\n+      __pointer_type\n+      operator+=(ptrdiff_t __d) volatile\n+      { return fetch_add(__d) + __d; }\n+\n+      __pointer_type\n+      operator-=(ptrdiff_t __d)\n+      { return fetch_sub(__d) - __d; }\n+\n+      __pointer_type\n+      operator-=(ptrdiff_t __d) volatile\n+      { return fetch_sub(__d) - __d; }\n+\n+      bool\n+      is_lock_free() const\n+      { return true; }\n+\n+      bool\n+      is_lock_free() const volatile\n+      { return true; }\n+\n+      void\n+      store(__pointer_type __p, memory_order __m = memory_order_seq_cst)\n+      {\n+\t__glibcxx_assert(__m != memory_order_acquire);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\t__glibcxx_assert(__m != memory_order_consume);\n+\n+\tif (__m == memory_order_relaxed)\n+\t  _M_p = __p;\n+\telse\n+\t  {\n+\t    // write_mem_barrier();\n+\t    _M_p = __p;\n+\t    if (__m == memory_order_seq_cst)\n+\t      __sync_synchronize();\n+\t  }\n+      }\n+\n+      void\n+      store(__pointer_type __p,\n+\t    memory_order __m = memory_order_seq_cst) volatile\n+      {\n+\t__glibcxx_assert(__m != memory_order_acquire);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\t__glibcxx_assert(__m != memory_order_consume);\n+\n+\tif (__m == memory_order_relaxed)\n+\t  _M_p = __p;\n+\telse\n+\t  {\n+\t    // write_mem_barrier();\n+\t    _M_p = __p;\n+\t    if (__m == memory_order_seq_cst)\n+\t      __sync_synchronize();\n+\t  }\n+      }\n+\n+      __pointer_type\n+      load(memory_order __m = memory_order_seq_cst) const\n+      {\n+\t__glibcxx_assert(__m != memory_order_release);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\n+\t__sync_synchronize();\n+\t__pointer_type __ret = _M_p;\n+\t__sync_synchronize();\n+\treturn __ret;\n+      }\n+\n+      __pointer_type\n+      load(memory_order __m = memory_order_seq_cst) const volatile\n+      {\n+\t__glibcxx_assert(__m != memory_order_release);\n+\t__glibcxx_assert(__m != memory_order_acq_rel);\n+\n+\t__sync_synchronize();\n+\t__pointer_type __ret = _M_p;\n+\t__sync_synchronize();\n+\treturn __ret;\n+      }\n+\n+      __pointer_type\n+      exchange(__pointer_type __p, memory_order __m = memory_order_seq_cst)\n+      {\n+\t// XXX built-in assumes memory_order_acquire.\n+\treturn __sync_lock_test_and_set(&_M_p, __p);\n+      }\n+\n+\n+      __pointer_type\n+      exchange(__pointer_type __p,\n+\t       memory_order __m = memory_order_seq_cst) volatile\n+      {\n+\t// XXX built-in assumes memory_order_acquire.\n+\treturn __sync_lock_test_and_set(&_M_p, __p);\n+      }\n+\n+      bool\n+      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t      memory_order __m1, memory_order __m2)\n+      {\n+\t__glibcxx_assert(__m2 != memory_order_release);\n+\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__m2 <= __m1);\n+\n+\t__pointer_type __p1o = __p1;\n+\t__pointer_type __p1n = __sync_val_compare_and_swap(&_M_p, __p1o, __p2);\n+\n+\t// Assume extra stores (of same value) allowed in true case.\n+\t__p1 = __p1n;\n+\treturn __p1o == __p1n;\n+      }\n+\n+      bool\n+      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t      memory_order __m1, memory_order __m2) volatile\n+      {\n+\t__glibcxx_assert(__m2 != memory_order_release);\n+\t__glibcxx_assert(__m2 != memory_order_acq_rel);\n+\t__glibcxx_assert(__m2 <= __m1);\n+\n+\t__pointer_type __p1o = __p1;\n+\t__pointer_type __p1n = __sync_val_compare_and_swap(&_M_p, __p1o, __p2);\n+\n+\t// Assume extra stores (of same value) allowed in true case.\n+\t__p1 = __p1n;\n+\treturn __p1o == __p1n;\n+      }\n+\n+      __pointer_type\n+      fetch_add(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n+      { return __sync_fetch_and_add(&_M_p, __d); }\n+\n+      __pointer_type\n+      fetch_add(ptrdiff_t __d,\n+\t\tmemory_order __m = memory_order_seq_cst) volatile\n+      { return __sync_fetch_and_add(&_M_p, __d); }\n+\n+      __pointer_type\n+      fetch_sub(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n+      { return __sync_fetch_and_sub(&_M_p, __d); }\n+\n+      __pointer_type\n+      fetch_sub(ptrdiff_t __d,\n+\t\tmemory_order __m = memory_order_seq_cst) volatile\n+      { return __sync_fetch_and_sub(&_M_p, __d); }\n+    };\n+\n } // namespace __atomic2\n \n _GLIBCXX_END_NAMESPACE_VERSION\n-} // namespace\n+} // namespace std\n \n #endif"}, {"sha": "272a4cd4cfde4c08b64bec44b146de8a13b8c7cc", "filename": "libstdc++-v3/include/bits/atomic_base.h", "status": "modified", "additions": 36, "deletions": 33, "changes": 69, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h?ref=036e0d4f8fa0326a048e59f7fe44ef04150fef05", "patch": "@@ -22,7 +22,7 @@\n // see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n // <http://www.gnu.org/licenses/>.\n \n-/** @file bits/atomic_base.h \n+/** @file bits/atomic_base.h\n  *  This is an internal header file, included by other library headers.\n  *  Do not attempt to use it directly. @headername{atomic}\n  */\n@@ -68,6 +68,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     return __mo2;\n   }\n \n+  void\n+  atomic_thread_fence(memory_order);\n+\n+  void\n+  atomic_signal_fence(memory_order);\n+\n   /// kill_dependency\n   template<typename _Tp>\n     inline _Tp\n@@ -78,7 +84,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     }\n \n   /**\n-   *  @brief Base type for atomic_flag. \n+   *  @brief Base type for atomic_flag.\n    *\n    *  Base type is POD with data, allowing atomic_flag to derive from\n    *  it and meet the standard layout type requirement. In addition to\n@@ -114,27 +120,24 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   namespace __atomic0\n   {\n     struct atomic_flag;\n-    struct atomic_address;\n \n     template<typename _IntTp>\n       struct __atomic_base;\n-  } \n+  }\n \n   namespace __atomic2\n   {\n     struct atomic_flag;\n-    struct atomic_address;\n \n     template<typename _IntTp>\n       struct __atomic_base;\n-  } \n+  }\n \n   namespace __atomic1\n   {\n     using __atomic2::atomic_flag;\n-    using __atomic0::atomic_address;\n     using __atomic0::__atomic_base;\n-  } \n+  }\n \n   /// Lock-free Property\n #if defined(_GLIBCXX_ATOMIC_BUILTINS_1) && defined(_GLIBCXX_ATOMIC_BUILTINS_2) \\\n@@ -157,7 +160,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n #define ATOMIC_INT_LOCK_FREE _GLIBCXX_ATOMIC_PROPERTY\n #define ATOMIC_LONG_LOCK_FREE _GLIBCXX_ATOMIC_PROPERTY\n #define ATOMIC_LLONG_LOCK_FREE _GLIBCXX_ATOMIC_PROPERTY\n-#define ATOMIC_ADDRESS_LOCK_FREE _GLIBCXX_ATOMIC_PROPERTY\n \n   inline namespace _GLIBCXX_ATOMIC_NAMESPACE { }\n \n@@ -166,28 +168,28 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   typedef __atomic_base<char>  \t       \t\tatomic_char;\n \n   /// atomic_schar\n-  typedef __atomic_base<signed char>         \tatomic_schar;\n+  typedef __atomic_base<signed char>\t     \tatomic_schar;\n \n   /// atomic_uchar\n-  typedef __atomic_base<unsigned char>  \tatomic_uchar;\n+  typedef __atomic_base<unsigned char>\t\tatomic_uchar;\n \n   /// atomic_short\n-  typedef __atomic_base<short>  \t\tatomic_short;\n+  typedef __atomic_base<short>\t\t\tatomic_short;\n \n   /// atomic_ushort\n-  typedef __atomic_base<unsigned short>  \tatomic_ushort;\n+  typedef __atomic_base<unsigned short>\t \tatomic_ushort;\n \n   /// atomic_int\n   typedef __atomic_base<int>  \t       \t\tatomic_int;\n \n   /// atomic_uint\n-  typedef __atomic_base<unsigned int>        \tatomic_uint;\n+  typedef __atomic_base<unsigned int>\t     \tatomic_uint;\n \n   /// atomic_long\n   typedef __atomic_base<long>  \t       \t\tatomic_long;\n \n   /// atomic_ulong\n-  typedef __atomic_base<unsigned long>  \tatomic_ulong;\n+  typedef __atomic_base<unsigned long>\t\tatomic_ulong;\n \n   /// atomic_llong\n   typedef __atomic_base<long long>  \t\tatomic_llong;\n@@ -212,50 +214,50 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   typedef __atomic_base<int_least8_t>  \t\tatomic_int_least8_t;\n \n   /// atomic_uint_least8_t\n-  typedef __atomic_base<uint_least8_t>         \tatomic_uint_least8_t;\n+  typedef __atomic_base<uint_least8_t>\t       \tatomic_uint_least8_t;\n \n   /// atomic_int_least16_t\n-  typedef __atomic_base<int_least16_t>         \tatomic_int_least16_t;\n+  typedef __atomic_base<int_least16_t>\t       \tatomic_int_least16_t;\n \n   /// atomic_uint_least16_t\n-  typedef __atomic_base<uint_least16_t>        \tatomic_uint_least16_t;\n+  typedef __atomic_base<uint_least16_t>\t       \tatomic_uint_least16_t;\n \n   /// atomic_int_least32_t\n-  typedef __atomic_base<int_least32_t>         \tatomic_int_least32_t;\n+  typedef __atomic_base<int_least32_t>\t       \tatomic_int_least32_t;\n \n   /// atomic_uint_least32_t\n-  typedef __atomic_base<uint_least32_t>        \tatomic_uint_least32_t;\n+  typedef __atomic_base<uint_least32_t>\t       \tatomic_uint_least32_t;\n \n   /// atomic_int_least64_t\n-  typedef __atomic_base<int_least64_t>         \tatomic_int_least64_t;\n+  typedef __atomic_base<int_least64_t>\t       \tatomic_int_least64_t;\n \n   /// atomic_uint_least64_t\n-  typedef __atomic_base<uint_least64_t>        \tatomic_uint_least64_t;\n+  typedef __atomic_base<uint_least64_t>\t       \tatomic_uint_least64_t;\n \n \n   /// atomic_int_fast8_t\n   typedef __atomic_base<int_fast8_t>  \t\tatomic_int_fast8_t;\n \n   /// atomic_uint_fast8_t\n-  typedef __atomic_base<uint_fast8_t>         \tatomic_uint_fast8_t;\n+  typedef __atomic_base<uint_fast8_t>\t      \tatomic_uint_fast8_t;\n \n   /// atomic_int_fast16_t\n-  typedef __atomic_base<int_fast16_t>         \tatomic_int_fast16_t;\n+  typedef __atomic_base<int_fast16_t>\t      \tatomic_int_fast16_t;\n \n   /// atomic_uint_fast16_t\n-  typedef __atomic_base<uint_fast16_t>        \tatomic_uint_fast16_t;\n+  typedef __atomic_base<uint_fast16_t>\t      \tatomic_uint_fast16_t;\n \n   /// atomic_int_fast32_t\n-  typedef __atomic_base<int_fast32_t>         \tatomic_int_fast32_t;\n+  typedef __atomic_base<int_fast32_t>\t      \tatomic_int_fast32_t;\n \n   /// atomic_uint_fast32_t\n-  typedef __atomic_base<uint_fast32_t>        \tatomic_uint_fast32_t;\n+  typedef __atomic_base<uint_fast32_t>\t      \tatomic_uint_fast32_t;\n \n   /// atomic_int_fast64_t\n-  typedef __atomic_base<int_fast64_t>         \tatomic_int_fast64_t;\n+  typedef __atomic_base<int_fast64_t>\t      \tatomic_int_fast64_t;\n \n   /// atomic_uint_fast64_t\n-  typedef __atomic_base<uint_fast64_t>        \tatomic_uint_fast64_t;\n+  typedef __atomic_base<uint_fast64_t>\t      \tatomic_uint_fast64_t;\n \n \n   /// atomic_intptr_t\n@@ -265,7 +267,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   typedef __atomic_base<uintptr_t>  \t       \tatomic_uintptr_t;\n \n   /// atomic_size_t\n-  typedef __atomic_base<size_t>  \t       \tatomic_size_t;\n+  typedef __atomic_base<size_t>\t \t       \tatomic_size_t;\n \n   /// atomic_intmax_t\n   typedef __atomic_base<intmax_t>  \t       \tatomic_intmax_t;\n@@ -277,16 +279,17 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   typedef __atomic_base<ptrdiff_t>  \t       \tatomic_ptrdiff_t;\n \n \n-  struct atomic_bool;\n-\n #define ATOMIC_VAR_INIT(_VI) { _VI }\n \n   template<typename _Tp>\n     struct atomic;\n \n+  template<typename _Tp>\n+    struct atomic<_Tp*>;\n+\n   // @} group atomics\n \n _GLIBCXX_END_NAMESPACE_VERSION\n-} // namespace\n+} // namespace std\n \n #endif"}, {"sha": "a19891dbdbc9ba49e06fb134911fa817b38b80ac", "filename": "libstdc++-v3/include/std/atomic", "status": "modified", "additions": 276, "deletions": 577, "changes": 853, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fstd%2Fatomic", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Finclude%2Fstd%2Fatomic", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fstd%2Fatomic?ref=036e0d4f8fa0326a048e59f7fe44ef04150fef05", "patch": "@@ -1,6 +1,6 @@\n // -*- C++ -*- header.\n \n-// Copyright (C) 2008, 2009, 2010 Free Software Foundation, Inc.\n+// Copyright (C) 2008, 2009, 2010, 2011 Free Software Foundation, Inc.\n //\n // This file is part of the GNU ISO C++ Library.  This library is free\n // software; you can redistribute it and/or modify it under the\n@@ -230,132 +230,188 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \n   /// Partial specialization for pointer types.\n   template<typename _Tp>\n-    struct atomic<_Tp*> : atomic_address\n+    struct atomic<_Tp*>\n     {\n+      typedef _Tp* \t\t\t__pointer_type;\n+      typedef __atomic_base<_Tp*>\t__base_type;\n+      __base_type\t\t\t_M_b;\n+\n       atomic() = default;\n       ~atomic() = default;\n       atomic(const atomic&) = delete;\n+      atomic& operator=(const atomic&) = delete;\n       atomic& operator=(const atomic&) volatile = delete;\n \n-      constexpr atomic(_Tp* __v) : atomic_address(__v) { }\n+      constexpr atomic(__pointer_type __p) : _M_b(__p) { }\n \n-      void\n-      store(_Tp*, memory_order = memory_order_seq_cst);\n+      operator __pointer_type() const\n+      { return __pointer_type(_M_b); }\n \n-      void\n-      store(_Tp*, memory_order = memory_order_seq_cst) volatile;\n+      operator __pointer_type() const volatile\n+      { return __pointer_type(_M_b); }\n \n-      _Tp*\n-      load(memory_order = memory_order_seq_cst) const;\n+      __pointer_type\n+      operator=(__pointer_type __p)\n+      { return _M_b.operator=(__p); }\n \n-      _Tp*\n-      load(memory_order = memory_order_seq_cst) const volatile;\n+      __pointer_type\n+      operator=(__pointer_type __p) volatile\n+      { return _M_b.operator=(__p); }\n \n-      _Tp*\n-      exchange(_Tp*, memory_order = memory_order_seq_cst);\n+      __pointer_type\n+      operator++(int)\n+      { return _M_b++; }\n \n-      _Tp*\n-      exchange(_Tp*, memory_order = memory_order_seq_cst) volatile;\n+      __pointer_type\n+      operator++(int) volatile\n+      { return _M_b++; }\n \n-      bool\n-      compare_exchange_weak(_Tp*&, _Tp*, memory_order, memory_order);\n+      __pointer_type\n+      operator--(int)\n+      { return _M_b--; }\n \n-      bool\n-      compare_exchange_weak(_Tp*&, _Tp*, memory_order, memory_order) volatile;\n+      __pointer_type\n+      operator--(int) volatile\n+      { return _M_b--; }\n \n-      bool\n-      compare_exchange_weak(_Tp*&, _Tp*, memory_order = memory_order_seq_cst);\n+      __pointer_type\n+      operator++()\n+      { return ++_M_b; }\n \n-      bool\n-      compare_exchange_weak(_Tp*&, _Tp*,\n-\t\t\t    memory_order = memory_order_seq_cst) volatile;\n+      __pointer_type\n+      operator++() volatile\n+      { return ++_M_b; }\n \n-      bool\n-      compare_exchange_strong(_Tp*&, _Tp*, memory_order, memory_order);\n+      __pointer_type\n+      operator--()\n+      { return --_M_b; }\n \n-      bool\n-      compare_exchange_strong(_Tp*&, _Tp*, memory_order, memory_order) volatile;\n+      __pointer_type\n+      operator--() volatile\n+      { return --_M_b; }\n+\n+      __pointer_type\n+      operator+=(ptrdiff_t __d)\n+      { return _M_b.operator+=(__d); }\n+\n+      __pointer_type\n+      operator+=(ptrdiff_t __d) volatile\n+      { return _M_b.operator+=(__d); }\n+\n+      __pointer_type\n+      operator-=(ptrdiff_t __d)\n+      { return _M_b.operator-=(__d); }\n+\n+      __pointer_type\n+      operator-=(ptrdiff_t __d) volatile\n+      { return _M_b.operator-=(__d); }\n \n       bool\n-      compare_exchange_strong(_Tp*&, _Tp*, memory_order = memory_order_seq_cst);\n+      is_lock_free() const\n+      { return _M_b.is_lock_free(); }\n \n       bool\n-      compare_exchange_strong(_Tp*&, _Tp*,\n-\t\t\t      memory_order = memory_order_seq_cst) volatile;\n+      is_lock_free() const volatile\n+      { return _M_b.is_lock_free(); }\n+\n+      void\n+      store(__pointer_type __p, memory_order __m = memory_order_seq_cst)\n+      { return _M_b.store(__p, __m); }\n+\n+      void\n+      store(__pointer_type __p,\n+\t    memory_order __m = memory_order_seq_cst) volatile\n+      { return _M_b.store(__p, __m); }\n \n-      _Tp*\n-      fetch_add(ptrdiff_t, memory_order = memory_order_seq_cst);\n+      __pointer_type\n+      load(memory_order __m = memory_order_seq_cst) const\n+      { return _M_b.load(__m); }\n \n-      _Tp*\n-      fetch_add(ptrdiff_t, memory_order = memory_order_seq_cst) volatile;\n+      __pointer_type\n+      load(memory_order __m = memory_order_seq_cst) const volatile\n+      { return _M_b.load(__m); }\n \n-      _Tp*\n-      fetch_sub(ptrdiff_t, memory_order = memory_order_seq_cst);\n+      __pointer_type\n+      exchange(__pointer_type __p, memory_order __m = memory_order_seq_cst)\n+      { return _M_b.exchange(__p, __m); }\n \n-      _Tp*\n-      fetch_sub(ptrdiff_t, memory_order = memory_order_seq_cst) volatile;\n+      __pointer_type\n+      exchange(__pointer_type __p,\n+\t       memory_order __m = memory_order_seq_cst) volatile\n+      { return _M_b.exchange(__p, __m); }\n \n-      operator _Tp*() const\n-      { return load(); }\n+      bool\n+      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t    memory_order __m1, memory_order __m2)\n+      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }\n \n-      operator _Tp*() const volatile\n-      { return load(); }\n+      bool\n+      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t    memory_order __m1, memory_order __m2) volatile\n+      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }\n \n-      _Tp*\n-      operator=(_Tp* __v)\n+      bool\n+      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t    memory_order __m = memory_order_seq_cst)\n       {\n-\tstore(__v);\n-\treturn __v;\n+\treturn compare_exchange_weak(__p1, __p2, __m,\n+\t\t\t\t     __calculate_memory_order(__m));\n       }\n \n-      _Tp*\n-      operator=(_Tp* __v) volatile\n+      bool\n+      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t    memory_order __m = memory_order_seq_cst) volatile\n       {\n-\tstore(__v);\n-\treturn __v;\n+\treturn compare_exchange_weak(__p1, __p2, __m,\n+\t\t\t\t     __calculate_memory_order(__m));\n       }\n \n-      _Tp*\n-      operator++(int) { return fetch_add(1); }\n-\n-      _Tp*\n-      operator++(int) volatile { return fetch_add(1); }\n-\n-      _Tp*\n-      operator--(int) { return fetch_sub(1); }\n+      bool\n+      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t      memory_order __m1, memory_order __m2)\n+      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }\n \n-      _Tp*\n-      operator--(int) volatile { return fetch_sub(1); }\n+      bool\n+      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t      memory_order __m1, memory_order __m2) volatile\n+      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }\n \n-      _Tp*\n-      operator++() { return fetch_add(1) + 1; }\n+      bool\n+      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t      memory_order __m = memory_order_seq_cst)\n+      {\n+\treturn _M_b.compare_exchange_strong(__p1, __p2, __m,\n+\t\t\t\t\t    __calculate_memory_order(__m));\n+      }\n \n-      _Tp*\n-      operator++() volatile { return fetch_add(1) + 1; }\n+      bool\n+      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,\n+\t\t\t      memory_order __m = memory_order_seq_cst) volatile\n+      {\n+\treturn _M_b.compare_exchange_strong(__p1, __p2, __m,\n+\t\t\t\t\t    __calculate_memory_order(__m));\n+      }\n \n-      _Tp*\n-      operator--() { return fetch_sub(1) - 1; }\n+      __pointer_type\n+      fetch_add(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n+      { return _M_b.fetch_add(__d, __m); }\n \n-      _Tp*\n-      operator--() volatile { return fetch_sub(1) - 1; }\n+      __pointer_type\n+      fetch_add(ptrdiff_t __d,\n+\t\tmemory_order __m = memory_order_seq_cst) volatile\n+      { return _M_b.fetch_add(__d, __m); }\n \n-      _Tp*\n-      operator+=(ptrdiff_t __d)\n-      { return fetch_add(__d) + __d; }\n+      __pointer_type\n+      fetch_sub(ptrdiff_t __d, memory_order __m = memory_order_seq_cst)\n+      { return _M_b.fetch_sub(__d, __m); }\n \n-      _Tp*\n-      operator+=(ptrdiff_t __d) volatile\n-      { return fetch_add(__d) + __d; }\n-\n-      _Tp*\n-      operator-=(ptrdiff_t __d)\n-      { return fetch_sub(__d) - __d; }\n-\n-      _Tp*\n-      operator-=(ptrdiff_t __d) volatile\n-      { return fetch_sub(__d) - __d; }\n+      __pointer_type\n+      fetch_sub(ptrdiff_t __d,\n+\t\tmemory_order __m = memory_order_seq_cst) volatile\n+      { return _M_b.fetch_sub(__d, __m); }\n     };\n \n+\n   /// Explicit specialization for bool.\n   template<>\n     struct atomic<bool> : public atomic_bool\n@@ -642,143 +698,13 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     };\n \n \n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::load(memory_order __m) const\n-    { return static_cast<_Tp*>(atomic_address::load(__m)); }\n-\n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::load(memory_order __m) const volatile\n-    { return static_cast<_Tp*>(atomic_address::load(__m)); }\n-\n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::exchange(_Tp* __v, memory_order __m)\n-    { return static_cast<_Tp*>(atomic_address::exchange(__v, __m)); }\n-\n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::exchange(_Tp* __v, memory_order __m) volatile\n-    { return static_cast<_Tp*>(atomic_address::exchange(__v, __m)); }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_weak(_Tp*& __r, _Tp* __v, memory_order __m1,\n-\t\t\t\t\tmemory_order __m2)\n-    {\n-      void** __vr = reinterpret_cast<void**>(&__r);\n-      void* __vv = static_cast<void*>(__v);\n-      return atomic_address::compare_exchange_weak(*__vr, __vv, __m1, __m2);\n-    }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_weak(_Tp*& __r, _Tp* __v, memory_order __m1,\n-\t\t\t\t\tmemory_order __m2) volatile\n-    {\n-      void** __vr = reinterpret_cast<void**>(&__r);\n-      void* __vv = static_cast<void*>(__v);\n-      return atomic_address::compare_exchange_weak(*__vr, __vv, __m1, __m2);\n-    }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_weak(_Tp*& __r, _Tp* __v, memory_order __m)\n-    {\n-      return compare_exchange_weak(__r, __v, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_weak(_Tp*& __r, _Tp* __v,\n-\t\t\t\t\tmemory_order __m) volatile\n-    {\n-      return compare_exchange_weak(__r, __v, __m,\n-\t\t\t\t   __calculate_memory_order(__m));\n-    }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_strong(_Tp*& __r, _Tp* __v,\n-\t\t\t\t\t  memory_order __m1,\n-\t\t\t\t\t  memory_order __m2)\n-    {\n-      void** __vr = reinterpret_cast<void**>(&__r);\n-      void* __vv = static_cast<void*>(__v);\n-      return atomic_address::compare_exchange_strong(*__vr, __vv, __m1, __m2);\n-    }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_strong(_Tp*& __r, _Tp* __v,\n-\t\t\t\t\t  memory_order __m1,\n-\t\t\t\t\t  memory_order __m2) volatile\n-    {\n-      void** __vr = reinterpret_cast<void**>(&__r);\n-      void* __vv = static_cast<void*>(__v);\n-      return atomic_address::compare_exchange_strong(*__vr, __vv, __m1, __m2);\n-    }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_strong(_Tp*& __r, _Tp* __v,\n-\t\t\t\t\t  memory_order __m)\n-    {\n-      return compare_exchange_strong(__r, __v, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-  template<typename _Tp>\n-    bool\n-    atomic<_Tp*>::compare_exchange_strong(_Tp*& __r, _Tp* __v,\n-\t\t\t\t\t  memory_order __m) volatile\n-    {\n-      return compare_exchange_strong(__r, __v, __m,\n-\t\t\t\t     __calculate_memory_order(__m));\n-    }\n-\n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::fetch_add(ptrdiff_t __d, memory_order __m)\n-    {\n-      void* __p = atomic_fetch_add_explicit(this, sizeof(_Tp) * __d, __m);\n-      return static_cast<_Tp*>(__p);\n-    }\n-\n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::fetch_add(ptrdiff_t __d, memory_order __m) volatile\n-    {\n-      void* __p = atomic_fetch_add_explicit(this, sizeof(_Tp) * __d, __m);\n-      return static_cast<_Tp*>(__p);\n-    }\n-\n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::fetch_sub(ptrdiff_t __d, memory_order __m)\n-    {\n-      void* __p = atomic_fetch_sub_explicit(this, sizeof(_Tp) * __d, __m);\n-      return static_cast<_Tp*>(__p);\n-    }\n-\n-  template<typename _Tp>\n-    _Tp*\n-    atomic<_Tp*>::fetch_sub(ptrdiff_t __d, memory_order __m) volatile\n-    {\n-      void* __p = atomic_fetch_sub_explicit(this, sizeof(_Tp) * __d, __m);\n-      return static_cast<_Tp*>(__p);\n-    }\n-\n-\n   // Function definitions, atomic_flag operations.\n   inline bool\n   atomic_flag_test_and_set_explicit(atomic_flag* __a, memory_order __m)\n   { return __a->test_and_set(__m); }\n \n   inline bool\n-  atomic_flag_test_and_set_explicit(volatile atomic_flag* __a, \n+  atomic_flag_test_and_set_explicit(volatile atomic_flag* __a,\n \t\t\t\t    memory_order __m)\n   { return __a->test_and_set(__m); }\n \n@@ -805,461 +731,125 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   inline void\n   atomic_flag_clear(volatile atomic_flag* __a)\n   { atomic_flag_clear_explicit(__a, memory_order_seq_cst); }\n- \n-\n-  // Function definitions, atomic_address operations.\n-  inline bool\n-  atomic_is_lock_free(const atomic_address* __a)\n-  { return __a->is_lock_free(); }\n-\n-  inline bool\n-  atomic_is_lock_free(const volatile atomic_address* __a)\n-  { return __a->is_lock_free(); }\n-\n-  inline void \n-  atomic_init(atomic_address* __a, void* __v);\n-\n-  inline void \n-  atomic_init(volatile atomic_address* __a, void* __v);\n-\n-  inline void\n-  atomic_store_explicit(atomic_address* __a, void* __v, memory_order __m)\n-  { __a->store(__v, __m); }\n-\n-  inline void\n-  atomic_store_explicit(volatile atomic_address* __a, void* __v, \n-\t\t\tmemory_order __m)\n-  { __a->store(__v, __m); }\n-\n-  inline void\n-  atomic_store(atomic_address* __a, void* __v)\n-  { __a->store(__v); }\n-\n-  inline void\n-  atomic_store(volatile atomic_address* __a, void* __v)\n-  { __a->store(__v); }\n-\n-  inline void*\n-  atomic_load_explicit(const atomic_address* __a, memory_order __m)\n-  { return __a->load(__m); }\n-\n-  inline void*\n-  atomic_load_explicit(const volatile atomic_address* __a, memory_order __m)\n-  { return __a->load(__m); }\n-\n-  inline void*\n-  atomic_load(const atomic_address* __a)\n-  { return __a->load(); }\n-\n-  inline void*\n-  atomic_load(const volatile atomic_address* __a)\n-  { return __a->load(); }\n-\n-  inline void*\n-  atomic_exchange_explicit(atomic_address* __a, void* __v, memory_order __m)\n-  { return __a->exchange(__v, __m); }\n-\n-  inline void*\n-  atomic_exchange_explicit(volatile atomic_address* __a, void* __v, \n-\t\t\t   memory_order __m)\n-  { return __a->exchange(__v, __m); }\n-\n-  inline void*\n-  atomic_exchange(atomic_address* __a, void* __v)\n-  { return __a->exchange(__v); }\n-\n-  inline void*\n-  atomic_exchange(volatile atomic_address* __a, void* __v)\n-  { return __a->exchange(__v); }\n-\n-\n-  inline bool\n-  atomic_compare_exchange_weak_explicit(atomic_address* __a,\n-\t\t\t\t\tvoid** __v1, void* __v2,\n-\t\t\t\t\tmemory_order __m1, memory_order __m2)\n-  { return __a->compare_exchange_weak(*__v1, __v2, __m1, __m2); }\n-\n-  inline bool\n-  atomic_compare_exchange_weak_explicit(volatile atomic_address* __a,\n-\t\t\t\t\tvoid** __v1, void* __v2,\n-\t\t\t\t\tmemory_order __m1, memory_order __m2)\n-  { return __a->compare_exchange_weak(*__v1, __v2, __m1, __m2); }\n-\n-  inline bool\n-  atomic_compare_exchange_weak(atomic_address* __a, void** __v1, void* __v2)\n-  {\n-    return __a->compare_exchange_weak(*__v1, __v2, memory_order_seq_cst,\n-\t\t\t\t      memory_order_seq_cst);\n-  }\n-\n-  inline bool\n-  atomic_compare_exchange_weak(volatile atomic_address* __a, void** __v1, \n-\t\t\t       void* __v2)\n-  {\n-    return __a->compare_exchange_weak(*__v1, __v2, memory_order_seq_cst,\n-\t\t\t\t      memory_order_seq_cst);\n-  }\n-\n-  inline bool\n-  atomic_compare_exchange_strong_explicit(atomic_address* __a,\n-\t\t\t\t\t  void** __v1, void* __v2,\n-\t\t\t\t\t  memory_order __m1, memory_order __m2)\n-  { return __a->compare_exchange_strong(*__v1, __v2, __m1, __m2); }\n-\n-  inline bool\n-  atomic_compare_exchange_strong_explicit(volatile atomic_address* __a,\n-\t\t\t\t\t  void** __v1, void* __v2,\n-\t\t\t\t\t  memory_order __m1, memory_order __m2)\n-  { return __a->compare_exchange_strong(*__v1, __v2, __m1, __m2); }\n-\n-  inline bool\n-  atomic_compare_exchange_strong(atomic_address* __a, void** __v1, void* __v2)\n-  {\n-    return __a->compare_exchange_strong(*__v1, __v2, memory_order_seq_cst,\n-\t\t\t\t\tmemory_order_seq_cst);\n-  }\n-\n-  inline bool\n-  atomic_compare_exchange_strong(volatile atomic_address* __a,\n-\t\t\t\t void** __v1, void* __v2)\n-  {\n-    return __a->compare_exchange_strong(*__v1, __v2, memory_order_seq_cst,\n-\t\t\t\t\tmemory_order_seq_cst);\n-  }\n-\n-  inline void*\n-  atomic_fetch_add_explicit(atomic_address* __a, ptrdiff_t __d,\n-\t\t\t    memory_order __m)\n-  { return __a->fetch_add(__d, __m); }\n-\n-  inline void*\n-  atomic_fetch_add_explicit(volatile atomic_address* __a, ptrdiff_t __d,\n-\t\t\t    memory_order __m)\n-  { return __a->fetch_add(__d, __m); }\n-\n-  inline void*\n-  atomic_fetch_add(atomic_address* __a, ptrdiff_t __d)\n-  { return __a->fetch_add(__d); }\n-\n-  inline void*\n-  atomic_fetch_add(volatile atomic_address* __a, ptrdiff_t __d)\n-  { return __a->fetch_add(__d); }\n-\n-  inline void*\n-  atomic_fetch_sub_explicit(atomic_address* __a, ptrdiff_t __d,\n-\t\t\t    memory_order __m)\n-  { return __a->fetch_sub(__d, __m); }\n-\n-  inline void*\n-  atomic_fetch_sub_explicit(volatile atomic_address* __a, ptrdiff_t __d,\n-\t\t\t    memory_order __m)\n-  { return __a->fetch_sub(__d, __m); }\n-\n-  inline void*\n-  atomic_fetch_sub(atomic_address* __a, ptrdiff_t __d)\n-  { return __a->fetch_sub(__d); }\n-\n-  inline void*\n-  atomic_fetch_sub(volatile atomic_address* __a, ptrdiff_t __d)\n-  { return __a->fetch_sub(__d); }\n-\n-\n-  // Function definitions, atomic_bool operations.\n-  inline bool\n-  atomic_is_lock_free(const atomic_bool* __a)\n-  { return __a->is_lock_free(); }\n-\n-  inline bool\n-  atomic_is_lock_free(const volatile atomic_bool* __a)\n-  { return __a->is_lock_free(); }\n-\n-  inline void \n-  atomic_init(atomic_bool* __a, bool __b);\n-\n-  inline void \n-  atomic_init(volatile atomic_bool* __a, bool __b);\n-\n-  inline void\n-  atomic_store_explicit(atomic_bool* __a, bool __i, memory_order __m)\n-  { __a->store(__i, __m); }\n-\n-  inline void\n-  atomic_store_explicit(volatile atomic_bool* __a, bool __i, memory_order __m)\n-  { __a->store(__i, __m); }\n \n-  inline void\n-  atomic_store(atomic_bool* __a, bool __i)\n-  { __a->store(__i); }\n-\n-  inline void\n-  atomic_store(volatile atomic_bool* __a, bool __i)\n-  { __a->store(__i); }\n-\n-  inline bool\n-  atomic_load_explicit(const atomic_bool* __a, memory_order __m)\n-  { return __a->load(__m); }\n-\n-  inline bool\n-  atomic_load_explicit(const volatile atomic_bool* __a, memory_order __m)\n-  { return __a->load(__m); }\n-\n-  inline bool\n-  atomic_load(const atomic_bool* __a)\n-  { return __a->load(); }\n-\n-  inline bool\n-  atomic_load(const volatile atomic_bool* __a)\n-  { return __a->load(); }\n-\n-  inline bool\n-  atomic_exchange_explicit(atomic_bool* __a, bool __i, memory_order __m)\n-  { return __a->exchange(__i, __m); }\n-\n-  inline bool\n-  atomic_exchange_explicit(volatile atomic_bool* __a, bool __i, \n-\t\t\t   memory_order __m)\n-  { return __a->exchange(__i, __m); }\n-\n-  inline bool\n-  atomic_exchange(atomic_bool* __a, bool __i)\n-  { return __a->exchange(__i); }\n-\n-  inline bool\n-  atomic_exchange(volatile atomic_bool* __a, bool __i)\n-  { return __a->exchange(__i); }\n-\n-  inline bool\n-  atomic_compare_exchange_weak_explicit(atomic_bool* __a, bool* __i1,\n-\t\t\t\t\tbool __i2, memory_order __m1,\n-\t\t\t\t\tmemory_order __m2)\n-  { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }\n-\n-  inline bool\n-  atomic_compare_exchange_weak_explicit(volatile atomic_bool* __a, bool* __i1,\n-\t\t\t\t\tbool __i2, memory_order __m1,\n-\t\t\t\t\tmemory_order __m2)\n-  { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }\n \n-  inline bool\n-  atomic_compare_exchange_weak(atomic_bool* __a, bool* __i1, bool __i2)\n-  {\n-    return __a->compare_exchange_weak(*__i1, __i2, memory_order_seq_cst,\n-\t\t\t\t      memory_order_seq_cst);\n-  }\n-\n-  inline bool\n-  atomic_compare_exchange_weak(volatile atomic_bool* __a, bool* __i1, bool __i2)\n-  {\n-    return __a->compare_exchange_weak(*__i1, __i2, memory_order_seq_cst,\n-\t\t\t\t      memory_order_seq_cst);\n-  }\n-\n-  inline bool\n-  atomic_compare_exchange_strong_explicit(atomic_bool* __a,\n-\t\t\t\t\t  bool* __i1, bool __i2,\n-\t\t\t\t\t  memory_order __m1, memory_order __m2)\n-  { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }\n-\n-  inline bool\n-  atomic_compare_exchange_strong_explicit(volatile atomic_bool* __a,\n-\t\t\t\t\t  bool* __i1, bool __i2,\n-\t\t\t\t\t  memory_order __m1, memory_order __m2)\n-  { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }\n-\n-  inline bool\n-  atomic_compare_exchange_strong(atomic_bool* __a, bool* __i1, bool __i2)\n-  {\n-    return __a->compare_exchange_strong(*__i1, __i2, memory_order_seq_cst,\n-\t\t\t\t\tmemory_order_seq_cst);\n-  }\n-\n-  inline bool\n-  atomic_compare_exchange_strong(volatile atomic_bool* __a, \n-\t\t\t\t bool* __i1, bool __i2)\n-  {\n-    return __a->compare_exchange_strong(*__i1, __i2, memory_order_seq_cst,\n-\t\t\t\t\tmemory_order_seq_cst);\n-  }\n-\n-\n-  // Function templates for atomic_integral operations, using\n-  // __atomic_base . Template argument should be constricted to\n-  // intergral types as specified in the standard.\n+  // Function templates generally applicable to atomic types.\n   template<typename _ITp>\n     inline bool\n-    atomic_is_lock_free(const __atomic_base<_ITp>* __a)\n+    atomic_is_lock_free(const atomic<_ITp>* __a)\n     { return __a->is_lock_free(); }\n \n   template<typename _ITp>\n     inline bool\n-    atomic_is_lock_free(const volatile __atomic_base<_ITp>* __a)\n+    atomic_is_lock_free(const volatile atomic<_ITp>* __a)\n     { return __a->is_lock_free(); }\n \n   template<typename _ITp>\n-    inline void \n-    atomic_init(__atomic_base<_ITp>* __a, _ITp __i);\n+    inline void\n+    atomic_init(atomic<_ITp>* __a, _ITp __i);\n \n   template<typename _ITp>\n-    inline void \n-    atomic_init(volatile __atomic_base<_ITp>* __a, _ITp __i);\n+    inline void\n+    atomic_init(volatile atomic<_ITp>* __a, _ITp __i);\n \n   template<typename _ITp>\n     inline void\n-    atomic_store_explicit(__atomic_base<_ITp>* __a, _ITp __i, memory_order __m)\n+    atomic_store_explicit(atomic<_ITp>* __a, _ITp __i, memory_order __m)\n     { __a->store(__i, __m); }\n \n   template<typename _ITp>\n     inline void\n-    atomic_store_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i, \n+    atomic_store_explicit(volatile atomic<_ITp>* __a, _ITp __i,\n \t\t\t  memory_order __m)\n     { __a->store(__i, __m); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_load_explicit(const __atomic_base<_ITp>* __a, memory_order __m)\n+    atomic_load_explicit(const atomic<_ITp>* __a, memory_order __m)\n     { return __a->load(__m); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_load_explicit(const volatile __atomic_base<_ITp>* __a, \n+    atomic_load_explicit(const volatile atomic<_ITp>* __a,\n \t\t\t memory_order __m)\n     { return __a->load(__m); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_exchange_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n+    atomic_exchange_explicit(atomic<_ITp>* __a, _ITp __i,\n \t\t\t     memory_order __m)\n     { return __a->exchange(__i, __m); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_exchange_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n+    atomic_exchange_explicit(volatile atomic<_ITp>* __a, _ITp __i,\n \t\t\t     memory_order __m)\n     { return __a->exchange(__i, __m); }\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_weak_explicit(__atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_weak_explicit(atomic<_ITp>* __a,\n \t\t\t\t\t  _ITp* __i1, _ITp __i2,\n \t\t\t\t\t  memory_order __m1, memory_order __m2)\n     { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_weak_explicit(volatile __atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_weak_explicit(volatile atomic<_ITp>* __a,\n \t\t\t\t\t  _ITp* __i1, _ITp __i2,\n \t\t\t\t\t  memory_order __m1, memory_order __m2)\n     { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_strong_explicit(__atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_strong_explicit(atomic<_ITp>* __a,\n \t\t\t\t\t    _ITp* __i1, _ITp __i2,\n \t\t\t\t\t    memory_order __m1,\n \t\t\t\t\t    memory_order __m2)\n     { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_strong_explicit(volatile __atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_strong_explicit(volatile atomic<_ITp>* __a,\n \t\t\t\t\t    _ITp* __i1, _ITp __i2,\n \t\t\t\t\t    memory_order __m1,\n \t\t\t\t\t    memory_order __m2)\n     { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }\n \n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_add_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_add(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_add_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_add(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_sub_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_sub(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_sub_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_sub(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_and_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_and(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_and_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_and(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_or_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t     memory_order __m)\n-    { return __a->fetch_or(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_or_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t     memory_order __m)\n-    { return __a->fetch_or(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_xor_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_xor(__i, __m); }\n-\n-  template<typename _ITp>\n-    inline _ITp\n-    atomic_fetch_xor_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n-\t\t\t      memory_order __m)\n-    { return __a->fetch_xor(__i, __m); }\n \n   template<typename _ITp>\n     inline void\n-    atomic_store(__atomic_base<_ITp>* __a, _ITp __i)\n+    atomic_store(atomic<_ITp>* __a, _ITp __i)\n     { atomic_store_explicit(__a, __i, memory_order_seq_cst); }\n \n   template<typename _ITp>\n     inline void\n-    atomic_store(volatile __atomic_base<_ITp>* __a, _ITp __i)\n+    atomic_store(volatile atomic<_ITp>* __a, _ITp __i)\n     { atomic_store_explicit(__a, __i, memory_order_seq_cst); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_load(const __atomic_base<_ITp>* __a)\n+    atomic_load(const atomic<_ITp>* __a)\n     { return atomic_load_explicit(__a, memory_order_seq_cst); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_load(const volatile __atomic_base<_ITp>* __a)\n+    atomic_load(const volatile atomic<_ITp>* __a)\n     { return atomic_load_explicit(__a, memory_order_seq_cst); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_exchange(__atomic_base<_ITp>* __a, _ITp __i)\n+    atomic_exchange(atomic<_ITp>* __a, _ITp __i)\n     { return atomic_exchange_explicit(__a, __i, memory_order_seq_cst); }\n \n   template<typename _ITp>\n     inline _ITp\n-    atomic_exchange(volatile __atomic_base<_ITp>* __a, _ITp __i)\n+    atomic_exchange(volatile atomic<_ITp>* __a, _ITp __i)\n     { return atomic_exchange_explicit(__a, __i, memory_order_seq_cst); }\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_weak(__atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_weak(atomic<_ITp>* __a,\n \t\t\t\t _ITp* __i1, _ITp __i2)\n     {\n       return atomic_compare_exchange_weak_explicit(__a, __i1, __i2,\n@@ -1269,7 +859,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_weak(volatile __atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_weak(volatile atomic<_ITp>* __a,\n \t\t\t\t _ITp* __i1, _ITp __i2)\n     {\n       return atomic_compare_exchange_weak_explicit(__a, __i1, __i2,\n@@ -1279,7 +869,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_strong(__atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_strong(atomic<_ITp>* __a,\n \t\t\t\t   _ITp* __i1, _ITp __i2)\n     {\n       return atomic_compare_exchange_strong_explicit(__a, __i1, __i2,\n@@ -1289,14 +879,78 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \n   template<typename _ITp>\n     inline bool\n-    atomic_compare_exchange_strong(volatile __atomic_base<_ITp>* __a,\n+    atomic_compare_exchange_strong(volatile atomic<_ITp>* __a,\n \t\t\t\t   _ITp* __i1, _ITp __i2)\n     {\n       return atomic_compare_exchange_strong_explicit(__a, __i1, __i2,\n \t\t\t\t\t\t     memory_order_seq_cst,\n \t\t\t\t\t\t     memory_order_seq_cst);\n     }\n \n+  // Function templates for atomic_integral operations only, using\n+  // __atomic_base. Template argument should be constricted to\n+  // intergral types as specified in the standard, excluding address\n+  // types.\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_add_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_add(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_add_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_add(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_sub_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_sub(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_sub_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_sub(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_and_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_and(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_and_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_and(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_or_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t     memory_order __m)\n+    { return __a->fetch_or(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_or_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t     memory_order __m)\n+    { return __a->fetch_or(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_xor_explicit(__atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_xor(__i, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp\n+    atomic_fetch_xor_explicit(volatile __atomic_base<_ITp>* __a, _ITp __i,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_xor(__i, __m); }\n+\n   template<typename _ITp>\n     inline _ITp\n     atomic_fetch_add(__atomic_base<_ITp>* __a, _ITp __i)\n@@ -1347,6 +1001,51 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     atomic_fetch_xor(volatile __atomic_base<_ITp>* __a, _ITp __i)\n     { return atomic_fetch_xor_explicit(__a, __i, memory_order_seq_cst); }\n \n+\n+  // Partial specializations for pointers.\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_add_explicit(atomic<_ITp*>* __a, ptrdiff_t __d,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_add(__d, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_add_explicit(volatile atomic<_ITp*>* __a, ptrdiff_t __d,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_add(__d, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_add(volatile atomic<_ITp*>* __a, ptrdiff_t __d)\n+    { return __a->fetch_add(__d); }\n+\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_add(atomic<_ITp*>* __a, ptrdiff_t __d)\n+    { return __a->fetch_add(__d); }\n+\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_sub_explicit(volatile atomic<_ITp*>* __a,\n+\t\t\t      ptrdiff_t __d, memory_order __m)\n+    { return __a->fetch_sub(__d, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_sub_explicit(atomic<_ITp*>* __a, ptrdiff_t __d,\n+\t\t\t      memory_order __m)\n+    { return __a->fetch_sub(__d, __m); }\n+\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_sub(volatile atomic<_ITp*>* __a, ptrdiff_t __d)\n+    { return __a->fetch_sub(__d); }\n+\n+  template<typename _ITp>\n+    inline _ITp*\n+    atomic_fetch_sub(atomic<_ITp*>* __a, ptrdiff_t __d)\n+    { return __a->fetch_sub(__d); }\n   // @} group atomics\n \n _GLIBCXX_END_NAMESPACE_VERSION"}, {"sha": "5cd2ef9fc4e9b217096d9c8d5b254ca0d30ef309", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/cons/aggregate.cc", "status": "removed", "additions": 0, "deletions": 28, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Faggregate.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Faggregate.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Faggregate.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,28 +0,0 @@\n-// { dg-options \"-std=gnu++0x\" }\n-// { dg-do compile }\n-\n-// Copyright (C) 2008, 2009, 2010 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-#include <cstddef>\n-\n-int main()\n-{\n-  std::atomic_address a __attribute__((unused)) = { { NULL } };\n-  return 0;\n-}"}, {"sha": "fad25935446123a631e2e0e1bf91394059992025", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/cons/assign_neg.cc", "status": "removed", "additions": 0, "deletions": 31, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fassign_neg.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fassign_neg.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fassign_neg.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,31 +0,0 @@\n-// { dg-options \"-std=gnu++0x\" }\n-// { dg-do compile }\n-\n-// Copyright (C) 2008, 2009 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-\n-void test01()\n-{\n-  // Assign.\n-  typedef std::atomic_address test_type;\n-  test_type t1;\n-  test_type t2;\n-  t1 = t2;\t\t\t// { dg-error \"deleted\" }\n-}\n-// { dg-prune-output \"include\" }"}, {"sha": "6b4963512a418bc35eda3197320a3ac5160c22c7", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/cons/constexpr.cc", "status": "removed", "additions": 0, "deletions": 29, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fconstexpr.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fconstexpr.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fconstexpr.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,29 +0,0 @@\n-// { dg-do compile }\n-// { dg-options \"-std=gnu++0x\" }\n-\n-// Copyright (C) 2010 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-#include <testsuite_common_types.h>\n-\n-int main()\n-{\n-  __gnu_test::constexpr_single_value_constructible test;\n-  test.operator()<std::atomic_address, void*>();\n-  return 0;\n-}"}, {"sha": "69f78eed1018d9163014eb5992c376a7a7d5276c", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/cons/copy_neg.cc", "status": "removed", "additions": 0, "deletions": 31, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fcopy_neg.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fcopy_neg.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fcopy_neg.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,31 +0,0 @@\n-// { dg-options \"-std=gnu++0x\" }\n-// { dg-do compile }\n-\n-// Copyright (C) 2008, 2009 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-\n-void test01()\n-{\n-  // Copy.\n-  typedef std::atomic_address test_type;\n-  test_type t1;\n-  test_type t2(t1);\t\t// { dg-error \"deleted\" }\n-}\n-\n-// { dg-prune-output \"include\" }"}, {"sha": "7e08ebb6254ef47dd39ec56bd800014f57b5eaed", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/cons/default.cc", "status": "removed", "additions": 0, "deletions": 27, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fdefault.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fdefault.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fdefault.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,27 +0,0 @@\n-// { dg-options \"-std=gnu++0x\" }\n-\n-// Copyright (C) 2008, 2009 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-\n-int main()\n-{\n-  // Default constructor.\n-  std::atomic_address a;\n-  return 0;\n-}"}, {"sha": "b7e524a38f596874603f980b0f3ffbe4a8df3884", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/cons/single_value.cc", "status": "removed", "additions": 0, "deletions": 28, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fsingle_value.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fsingle_value.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Fcons%2Fsingle_value.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,28 +0,0 @@\n-// { dg-options \"-std=gnu++0x\" }\n-\n-// Copyright (C) 2008, 2009, 2010 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-\n-int main()\n-{\n-  // Single value constructor.\n-  void* v = 0;\n-  std::atomic_address a(v);\n-  return 0;\n-}"}, {"sha": "cbabc1e3eb7aac1116cf4855304f5d0178be5f2e", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/requirements/standard_layout.cc", "status": "removed", "additions": 0, "deletions": 28, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Frequirements%2Fstandard_layout.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Frequirements%2Fstandard_layout.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Frequirements%2Fstandard_layout.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,28 +0,0 @@\n-// { dg-options \"-std=gnu++0x\" }\n-// { dg-do compile }\n-\n-// Copyright (C) 2008, 2009 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-#include <testsuite_common_types.h>\n-\n-void test01()\n-{\n-  __gnu_test::standard_layout test;\n-  test.operator()<std::atomic_address>();\n-}"}, {"sha": "00960802c4f2d9fccf7babfef55b1fa1c0b3ea7c", "filename": "libstdc++-v3/testsuite/29_atomics/atomic_address/requirements/trivial.cc", "status": "removed", "additions": 0, "deletions": 28, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Frequirements%2Ftrivial.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3808007ca0a79b0a2df3f9257fe4999b353f42ac/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Frequirements%2Ftrivial.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fatomic_address%2Frequirements%2Ftrivial.cc?ref=3808007ca0a79b0a2df3f9257fe4999b353f42ac", "patch": "@@ -1,28 +0,0 @@\n-// { dg-options \"-std=gnu++0x\" }\n-// { dg-do compile }\n-\n-// Copyright (C) 2009 Free Software Foundation, Inc.\n-//\n-// This file is part of the GNU ISO C++ Library.  This library is free\n-// software; you can redistribute it and/or modify it under the\n-// terms of the GNU General Public License as published by the\n-// Free Software Foundation; either version 3, or (at your option)\n-// any later version.\n-\n-// This library is distributed in the hope that it will be useful,\n-// but WITHOUT ANY WARRANTY; without even the implied warranty of\n-// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-// GNU General Public License for more details.\n-\n-// You should have received a copy of the GNU General Public License along\n-// with this library; see the file COPYING3.  If not see\n-// <http://www.gnu.org/licenses/>.\n-\n-#include <atomic>\n-#include <testsuite_common_types.h>\n-\n-void test01()\n-{\n-  __gnu_test::has_trivial_cons_dtor test;\n-  test.operator()<std::atomic_address>();\n-}"}, {"sha": "e2461a1113ec7e93f8826aab3690effd5691fb07", "filename": "libstdc++-v3/testsuite/29_atomics/headers/atomic/macros.cc", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fheaders%2Fatomic%2Fmacros.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fheaders%2Fatomic%2Fmacros.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fheaders%2Fatomic%2Fmacros.cc?ref=036e0d4f8fa0326a048e59f7fe44ef04150fef05", "patch": "@@ -94,14 +94,6 @@ namespace gnu\n # endif\n #endif\n \n-#ifndef ATOMIC_ADDRESS_LOCK_FREE\n-# error \"ATOMIC_ADDRESS_LOCK_FREE must be a macro\"\n-# if ATOMIC_ADDRESS_LOCK_FREE != 0 \\\n-    && ATOMIC_ADDRESS_LOCK_FREE != 1 && ATOMIC_ADDRESS_LOCK_FREE != 2\n-# error \"ATOMIC_ADDRESS_LOCK_FREE must be 0, 1, or 2\"\n-# endif\n-#endif\n-\n #ifndef ATOMIC_FLAG_INIT\n     #error \"ATOMIC_FLAG_INIT_must_be_a_macro\"\n #endif"}, {"sha": "772bc338ee3517fb89d972afbe0c6682276acdca", "filename": "libstdc++-v3/testsuite/29_atomics/headers/atomic/types_std_c++0x.cc", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fheaders%2Fatomic%2Ftypes_std_c%2B%2B0x.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/036e0d4f8fa0326a048e59f7fe44ef04150fef05/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fheaders%2Fatomic%2Ftypes_std_c%2B%2B0x.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F29_atomics%2Fheaders%2Fatomic%2Ftypes_std_c%2B%2B0x.cc?ref=036e0d4f8fa0326a048e59f7fe44ef04150fef05", "patch": "@@ -1,7 +1,7 @@\n // { dg-options \"-std=gnu++0x\" }\n // { dg-do compile }\n \n-// Copyright (C) 2008, 2009, 2010 Free Software Foundation, Inc.\n+// Copyright (C) 2008, 2009, 2010, 2011 Free Software Foundation, Inc.\n //\n // This file is part of the GNU ISO C++ Library.  This library is free\n // software; you can redistribute it and/or modify it under the\n@@ -72,6 +72,4 @@ void test01()\n   using std::atomic_ptrdiff_t;\n   using std::atomic_intmax_t;\n   using std::atomic_uintmax_t;\n-\n-  using std::atomic_address;\n }"}]}