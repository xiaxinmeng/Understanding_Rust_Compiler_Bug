{"sha": "b86f6e9e46f47fca000ba531689e4e64ae7366ef", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Yjg2ZjZlOWU0NmY0N2ZjYTAwMGJhNTMxNjg5ZTRlNjRhZTczNjZlZg==", "commit": {"author": {"name": "Alexander Ivchenko", "email": "alexander.ivchenko@intel.com", "date": "2013-09-25T18:01:43Z"}, "committer": {"name": "Kirill Yukhin", "email": "kyukhin@gcc.gnu.org", "date": "2013-09-25T18:01:43Z"}, "message": "i386.c (ix86_avx256_split_vector_move_misalign): Use new names.\n\n\t* config/i386/i386.c (ix86_avx256_split_vector_move_misalign):\n\tUse new names.\n\t(ix86_expand_vector_move_misalign): Support new unaligned load and\n\tstores and use new names.\n\t(CODE_FOR_sse2_storedqu): Rename to ...\n\t(CODE_FOR_sse2_storedquv16qi): ... this.\n\t(CODE_FOR_sse2_loaddqu): Rename to ...\n\t(CODE_FOR_sse2_loaddquv16qi): ... this.\n\t(CODE_FOR_avx_loaddqu256): Rename to ...\n\t(CODE_FOR_avx_loaddquv32qi): ... this.\n\t(CODE_FOR_avx_storedqu256): Rename to ...\n\t(CODE_FOR_avx_storedquv32qi): ... this.\n\t* config/i386/i386.md (fpint_logic): New.\n\t* config/i386/sse.md (VMOVE): Extend for AVX512.\n\t(VF): Ditto.\n\t(VF_128_256): New.\n\t(VF_512): Ditto.\n\t(VI_UNALIGNED_LOADSTORE): Ditto.\n\t(sse2_avx_avx512f): Ditto.\n\t(sse2_avx2): Extend for AVX512.\n\t(sse4_1_avx2): Ditto.\n\t(avx2_avx512f): New.\n\t(sse): Extend for AVX512.\n\t(sse2): Ditto.\n\t(sse4_1): Ditto.\n\t(avxsizesuffix): Ditto.\n\t(sseintvecmode): Ditto.\n\t(ssePSmode): Ditto.\n\t(<sse>_loadu<ssemodesuffix><avxsizesuffix>): Ditto.\n\t(<sse>_storeu<ssemodesuffix><avxsizesuffix>): Ditto.\n\t(<sse2>_loaddqu<avxsizesuffix>): Extend for AVX512 and rename to ...\n\t(<sse2_avx_avx512f>_loaddqu<mode>): ... this.\n\t(<sse2>_storedqu<avxsizesuffix>): Extend for AVX512 and rename to ...\n\t(<sse2_avx_avx512f>_storedqu<mode): ... this.\n\t(<sse>_movnt<mode>): Replace constraint \"x\" with \"v\".\n\t(STORENT_MODE): Extend for AVX512.\n\t(*absneg<mode>2): Replace constraint \"x\" with \"v\".\n\t(*mul<mode>3): Ditto.\n\t(*ieee_smin<mode>3): Ditto.\n\t(*ieee_smax<mode>3): Ditto.\n\t(avx_cmp<mode>3): Replace VF with VF_128_256.\n\t(*<sse>_maskcmp<mode>3_comm): Ditto.\n\t(<sse>_maskcmp<mode>3): Ditto.\n\t(<sse>_andnot<mode>3): Extend for AVX512.\n\t(<code><mode>3, anylogic): Replace VF with VF_128_256.\n\t(<code><mode>3, fpint_logic): New.\n\t(*<code><mode>3): Extend for AVX512.\n\t(avx512flogicsuff): New.\n\t(avx512f_<logic><mode>): Ditto.\n\t(<sse>_movmsk<ssemodesuffix><avxsizesuffix>): Replace VF with\n\tVF_128_256.\n\t(<sse4_1>_blend<ssemodesuffix><avxsizesuffix>): Ditto.\n\t(<sse4_1>_blendv<ssemodesuffix><avxsizesuffix>): Ditto.\n\t(<sse4_1>_dp<ssemodesuffix><avxsizesuffix>): Ditto.\n\t(avx_vtest<ssemodesuffix><avxsizesuffix>): Ditto.\n\t(<sse4_1>_round<ssemodesuffix><avxsizesuffix>): Ditto.\n\t(xop_vpermil2<mode>3): Ditto.\n\t(*avx_vpermilp<mode>): Extend for AVX512 and rename to ...\n\t(*<sse2_avx_avx512f>_vpermilp<mode>): ... this.\n\t(avx_vpermilvar<mode>3): Extend for AVX512 and rename to ...\n\t(<sse2_avx_avx512f>_vpermilvar<mode>3): ... this.\n\n\nCo-Authored-By: Andrey Turetskiy <andrey.turetskiy@intel.com>\nCo-Authored-By: Anna Tikhonova <anna.tikhonova@intel.com>\nCo-Authored-By: Ilya Tocar <ilya.tocar@intel.com>\nCo-Authored-By: Ilya Verbin <ilya.verbin@intel.com>\nCo-Authored-By: Kirill Yukhin <kirill.yukhin@intel.com>\nCo-Authored-By: Maxim Kuznetsov <maxim.kuznetsov@intel.com>\nCo-Authored-By: Michael Zolotukhin <michael.v.zolotukhin@intel.com>\nCo-Authored-By: Sergey Lega <sergey.s.lega@intel.com>\n\nFrom-SVN: r202913", "tree": {"sha": "08571edb1bf0feabc76d652e9a360b43805c90c1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/08571edb1bf0feabc76d652e9a360b43805c90c1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b86f6e9e46f47fca000ba531689e4e64ae7366ef", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b86f6e9e46f47fca000ba531689e4e64ae7366ef", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b86f6e9e46f47fca000ba531689e4e64ae7366ef", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b86f6e9e46f47fca000ba531689e4e64ae7366ef/comments", "author": null, "committer": null, "parents": [{"sha": "4d44d03c72e6157a5ae0cd27a0cf0111323abf1a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4d44d03c72e6157a5ae0cd27a0cf0111323abf1a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4d44d03c72e6157a5ae0cd27a0cf0111323abf1a"}], "stats": {"total": 418, "additions": 313, "deletions": 105}, "files": [{"sha": "828da1e9ff0e394ab9d4b2b8ad75d230d6000708", "filename": "gcc/ChangeLog", "status": "modified", "additions": 72, "deletions": 0, "changes": 72, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b86f6e9e46f47fca000ba531689e4e64ae7366ef", "patch": "@@ -1,3 +1,75 @@\n+2013-09-25  Alexander Ivchenko  <alexander.ivchenko@intel.com>\n+\t    Maxim Kuznetsov  <maxim.kuznetsov@intel.com>\n+\t    Sergey Lega  <sergey.s.lega@intel.com>\n+\t    Anna Tikhonova  <anna.tikhonova@intel.com>\n+\t    Ilya Tocar  <ilya.tocar@intel.com>\n+\t    Andrey Turetskiy  <andrey.turetskiy@intel.com>\n+\t    Ilya Verbin  <ilya.verbin@intel.com>\n+\t    Kirill Yukhin  <kirill.yukhin@intel.com>\n+\t    Michael Zolotukhin  <michael.v.zolotukhin@intel.com>\n+\n+\t* config/i386/i386.c (ix86_avx256_split_vector_move_misalign):\n+\tUse new names.\n+\t(ix86_expand_vector_move_misalign): Support new unaligned load and\n+\tstores and use new names.\n+\t(CODE_FOR_sse2_storedqu): Rename to ...\n+\t(CODE_FOR_sse2_storedquv16qi): ... this.\n+\t(CODE_FOR_sse2_loaddqu): Rename to ...\n+\t(CODE_FOR_sse2_loaddquv16qi): ... this.\n+\t(CODE_FOR_avx_loaddqu256): Rename to ...\n+\t(CODE_FOR_avx_loaddquv32qi): ... this.\n+\t(CODE_FOR_avx_storedqu256): Rename to ...\n+\t(CODE_FOR_avx_storedquv32qi): ... this.\n+\t* config/i386/i386.md (fpint_logic): New.\n+\t* config/i386/sse.md (VMOVE): Extend for AVX512.\n+\t(VF): Ditto.\n+\t(VF_128_256): New.\n+\t(VF_512): Ditto.\n+\t(VI_UNALIGNED_LOADSTORE): Ditto.\n+\t(sse2_avx_avx512f): Ditto.\n+\t(sse2_avx2): Extend for AVX512.\n+\t(sse4_1_avx2): Ditto.\n+\t(avx2_avx512f): New.\n+\t(sse): Extend for AVX512.\n+\t(sse2): Ditto.\n+\t(sse4_1): Ditto.\n+\t(avxsizesuffix): Ditto.\n+\t(sseintvecmode): Ditto.\n+\t(ssePSmode): Ditto.\n+\t(<sse>_loadu<ssemodesuffix><avxsizesuffix>): Ditto.\n+\t(<sse>_storeu<ssemodesuffix><avxsizesuffix>): Ditto.\n+\t(<sse2>_loaddqu<avxsizesuffix>): Extend for AVX512 and rename to ...\n+\t(<sse2_avx_avx512f>_loaddqu<mode>): ... this.\n+\t(<sse2>_storedqu<avxsizesuffix>): Extend for AVX512 and rename to ...\n+\t(<sse2_avx_avx512f>_storedqu<mode): ... this.\n+\t(<sse>_movnt<mode>): Replace constraint \"x\" with \"v\".\n+\t(STORENT_MODE): Extend for AVX512.\n+\t(*absneg<mode>2): Replace constraint \"x\" with \"v\".\n+\t(*mul<mode>3): Ditto.\n+\t(*ieee_smin<mode>3): Ditto.\n+\t(*ieee_smax<mode>3): Ditto.\n+\t(avx_cmp<mode>3): Replace VF with VF_128_256.\n+\t(*<sse>_maskcmp<mode>3_comm): Ditto.\n+\t(<sse>_maskcmp<mode>3): Ditto.\n+\t(<sse>_andnot<mode>3): Extend for AVX512.\n+\t(<code><mode>3, anylogic): Replace VF with VF_128_256.\n+\t(<code><mode>3, fpint_logic): New.\n+\t(*<code><mode>3): Extend for AVX512.\n+\t(avx512flogicsuff): New.\n+\t(avx512f_<logic><mode>): Ditto.\n+\t(<sse>_movmsk<ssemodesuffix><avxsizesuffix>): Replace VF with\n+\tVF_128_256.\n+\t(<sse4_1>_blend<ssemodesuffix><avxsizesuffix>): Ditto.\n+\t(<sse4_1>_blendv<ssemodesuffix><avxsizesuffix>): Ditto.\n+\t(<sse4_1>_dp<ssemodesuffix><avxsizesuffix>): Ditto.\n+\t(avx_vtest<ssemodesuffix><avxsizesuffix>): Ditto.\n+\t(<sse4_1>_round<ssemodesuffix><avxsizesuffix>): Ditto.\n+\t(xop_vpermil2<mode>3): Ditto.\n+\t(*avx_vpermilp<mode>): Extend for AVX512 and rename to ...\n+\t(*<sse2_avx_avx512f>_vpermilp<mode>): ... this.\n+\t(avx_vpermilvar<mode>3): Extend for AVX512 and rename to ...\n+\t(<sse2_avx_avx512f>_vpermilvar<mode>3): ... this.\n+\n 2013-09-25  Tom Tromey  <tromey@redhat.com>\n \n \t* Makefile.in (PARTITION_H, LTO_SYMTAB_H, COMMON_TARGET_DEF_H)"}, {"sha": "f10113fd3c415388fdf2b272bf9a7328e30f92ab", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 54, "deletions": 8, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=b86f6e9e46f47fca000ba531689e4e64ae7366ef", "patch": "@@ -16457,8 +16457,8 @@ ix86_avx256_split_vector_move_misalign (rtx op0, rtx op1)\n       gcc_unreachable ();\n     case V32QImode:\n       extract = gen_avx_vextractf128v32qi;\n-      load_unaligned = gen_avx_loaddqu256;\n-      store_unaligned = gen_avx_storedqu256;\n+      load_unaligned = gen_avx_loaddquv32qi;\n+      store_unaligned = gen_avx_storedquv32qi;\n       mode = V16QImode;\n       break;\n     case V8SFmode:\n@@ -16561,10 +16561,56 @@ void\n ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n {\n   rtx op0, op1, m;\n+  rtx (*load_unaligned) (rtx, rtx);\n+  rtx (*store_unaligned) (rtx, rtx);\n \n   op0 = operands[0];\n   op1 = operands[1];\n \n+  if (GET_MODE_SIZE (mode) == 64)\n+    {\n+      switch (GET_MODE_CLASS (mode))\n+\t{\n+\tcase MODE_VECTOR_INT:\n+\tcase MODE_INT:\n+\t  op0 = gen_lowpart (V16SImode, op0);\n+\t  op1 = gen_lowpart (V16SImode, op1);\n+\t  /* FALLTHRU */\n+\n+\tcase MODE_VECTOR_FLOAT:\n+\t  switch (GET_MODE (op0))\n+\t    {\n+\t    default:\n+\t      gcc_unreachable ();\n+\t    case V16SImode:\n+\t      load_unaligned = gen_avx512f_loaddquv16si;\n+\t      store_unaligned = gen_avx512f_storedquv16si;\n+\t      break;\n+\t    case V16SFmode:\n+\t      load_unaligned = gen_avx512f_loadups512;\n+\t      store_unaligned = gen_avx512f_storeups512;\n+\t      break;\n+\t    case V8DFmode:\n+\t      load_unaligned = gen_avx512f_loadupd512;\n+\t      store_unaligned = gen_avx512f_storeupd512;\n+\t      break;\n+\t    }\n+\n+\t  if (MEM_P (op1))\n+\t    emit_insn (load_unaligned (op0, op1));\n+\t  else if (MEM_P (op0))\n+\t    emit_insn (store_unaligned (op0, op1));\n+\t  else\n+\t    gcc_unreachable ();\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+\n+      return;\n+    }\n+\n   if (TARGET_AVX\n       && GET_MODE_SIZE (mode) == 32)\n     {\n@@ -16597,7 +16643,7 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n \t  op0 = gen_lowpart (V16QImode, op0);\n \t  op1 = gen_lowpart (V16QImode, op1);\n \t  /* We will eventually emit movups based on insn attributes.  */\n-\t  emit_insn (gen_sse2_loaddqu (op0, op1));\n+\t  emit_insn (gen_sse2_loaddquv16qi (op0, op1));\n \t}\n       else if (TARGET_SSE2 && mode == V2DFmode)\n         {\n@@ -16672,7 +16718,7 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n \t  op0 = gen_lowpart (V16QImode, op0);\n \t  op1 = gen_lowpart (V16QImode, op1);\n \t  /* We will eventually emit movups based on insn attributes.  */\n-\t  emit_insn (gen_sse2_storedqu (op0, op1));\n+\t  emit_insn (gen_sse2_storedquv16qi (op0, op1));\n \t}\n       else if (TARGET_SSE2 && mode == V2DFmode)\n \t{\n@@ -27400,13 +27446,13 @@ static const struct builtin_description bdesc_special_args[] =\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_lfence, \"__builtin_ia32_lfence\", IX86_BUILTIN_LFENCE, UNKNOWN, (int) VOID_FTYPE_VOID },\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_mfence, 0, IX86_BUILTIN_MFENCE, UNKNOWN, (int) VOID_FTYPE_VOID },\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_storeupd, \"__builtin_ia32_storeupd\", IX86_BUILTIN_STOREUPD, UNKNOWN, (int) VOID_FTYPE_PDOUBLE_V2DF },\n-  { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_storedqu, \"__builtin_ia32_storedqu\", IX86_BUILTIN_STOREDQU, UNKNOWN, (int) VOID_FTYPE_PCHAR_V16QI },\n+  { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_storedquv16qi, \"__builtin_ia32_storedqu\", IX86_BUILTIN_STOREDQU, UNKNOWN, (int) VOID_FTYPE_PCHAR_V16QI },\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_movntv2df, \"__builtin_ia32_movntpd\", IX86_BUILTIN_MOVNTPD, UNKNOWN, (int) VOID_FTYPE_PDOUBLE_V2DF },\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_movntv2di, \"__builtin_ia32_movntdq\", IX86_BUILTIN_MOVNTDQ, UNKNOWN, (int) VOID_FTYPE_PV2DI_V2DI },\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_movntisi, \"__builtin_ia32_movnti\", IX86_BUILTIN_MOVNTI, UNKNOWN, (int) VOID_FTYPE_PINT_INT },\n   { OPTION_MASK_ISA_SSE2 | OPTION_MASK_ISA_64BIT, CODE_FOR_sse2_movntidi, \"__builtin_ia32_movnti64\", IX86_BUILTIN_MOVNTI64, UNKNOWN, (int) VOID_FTYPE_PLONGLONG_LONGLONG },\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_loadupd, \"__builtin_ia32_loadupd\", IX86_BUILTIN_LOADUPD, UNKNOWN, (int) V2DF_FTYPE_PCDOUBLE },\n-  { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_loaddqu, \"__builtin_ia32_loaddqu\", IX86_BUILTIN_LOADDQU, UNKNOWN, (int) V16QI_FTYPE_PCCHAR },\n+  { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_loaddquv16qi, \"__builtin_ia32_loaddqu\", IX86_BUILTIN_LOADDQU, UNKNOWN, (int) V16QI_FTYPE_PCCHAR },\n \n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_loadhpd_exp, \"__builtin_ia32_loadhpd\", IX86_BUILTIN_LOADHPD, UNKNOWN, (int) V2DF_FTYPE_V2DF_PCDOUBLE },\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_loadlpd_exp, \"__builtin_ia32_loadlpd\", IX86_BUILTIN_LOADLPD, UNKNOWN, (int) V2DF_FTYPE_V2DF_PCDOUBLE },\n@@ -27435,8 +27481,8 @@ static const struct builtin_description bdesc_special_args[] =\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_loadups256, \"__builtin_ia32_loadups256\", IX86_BUILTIN_LOADUPS256, UNKNOWN, (int) V8SF_FTYPE_PCFLOAT },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_storeupd256, \"__builtin_ia32_storeupd256\", IX86_BUILTIN_STOREUPD256, UNKNOWN, (int) VOID_FTYPE_PDOUBLE_V4DF },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_storeups256, \"__builtin_ia32_storeups256\", IX86_BUILTIN_STOREUPS256, UNKNOWN, (int) VOID_FTYPE_PFLOAT_V8SF },\n-  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_loaddqu256, \"__builtin_ia32_loaddqu256\", IX86_BUILTIN_LOADDQU256, UNKNOWN, (int) V32QI_FTYPE_PCCHAR },\n-  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_storedqu256, \"__builtin_ia32_storedqu256\", IX86_BUILTIN_STOREDQU256, UNKNOWN, (int) VOID_FTYPE_PCHAR_V32QI },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_loaddquv32qi, \"__builtin_ia32_loaddqu256\", IX86_BUILTIN_LOADDQU256, UNKNOWN, (int) V32QI_FTYPE_PCCHAR },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_storedquv32qi, \"__builtin_ia32_storedqu256\", IX86_BUILTIN_STOREDQU256, UNKNOWN, (int) VOID_FTYPE_PCHAR_V32QI },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_lddqu256, \"__builtin_ia32_lddqu256\", IX86_BUILTIN_LDDQU256, UNKNOWN, (int) V32QI_FTYPE_PCCHAR },\n \n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_movntv4di, \"__builtin_ia32_movntdq256\", IX86_BUILTIN_MOVNTDQ256, UNKNOWN, (int) VOID_FTYPE_PV4DI_V4DI },"}, {"sha": "03b38426c4b346f7dc35c0a2c9e52f2a67a6d1f4", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=b86f6e9e46f47fca000ba531689e4e64ae7366ef", "patch": "@@ -779,6 +779,7 @@\n ;; Mapping of logic operators\n (define_code_iterator any_logic [and ior xor])\n (define_code_iterator any_or [ior xor])\n+(define_code_iterator fpint_logic [and xor])\n \n ;; Base name for insn mnemonic.\n (define_code_attr logic [(and \"and\") (ior \"or\") (xor \"xor\")])"}, {"sha": "10637cc22e8b003adf1e6405e9b51390e4888a57", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 186, "deletions": 97, "changes": 283, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b86f6e9e46f47fca000ba531689e4e64ae7366ef/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=b86f6e9e46f47fca000ba531689e4e64ae7366ef", "patch": "@@ -97,13 +97,13 @@\n \n ;; All vector modes including V?TImode, used in move patterns.\n (define_mode_iterator VMOVE\n-  [(V32QI \"TARGET_AVX\") V16QI\n-   (V16HI \"TARGET_AVX\") V8HI\n-   (V8SI \"TARGET_AVX\") V4SI\n-   (V4DI \"TARGET_AVX\") V2DI\n+  [(V64QI \"TARGET_AVX512F\") (V32QI \"TARGET_AVX\") V16QI\n+   (V32HI \"TARGET_AVX512F\") (V16HI \"TARGET_AVX\") V8HI\n+   (V16SI \"TARGET_AVX512F\") (V8SI \"TARGET_AVX\") V4SI\n+   (V8DI \"TARGET_AVX512F\")  (V4DI \"TARGET_AVX\") V2DI\n    (V2TI \"TARGET_AVX\") V1TI\n-   (V8SF \"TARGET_AVX\") V4SF\n-   (V4DF \"TARGET_AVX\") V2DF])\n+   (V16SF \"TARGET_AVX512F\") (V8SF \"TARGET_AVX\") V4SF\n+   (V8DF \"TARGET_AVX512F\")  (V4DF \"TARGET_AVX\") V2DF])\n \n ;; All vector modes\n (define_mode_iterator V\n@@ -124,6 +124,11 @@\n \n ;; All vector float modes\n (define_mode_iterator VF\n+  [(V16SF \"TARGET_AVX512F\") (V8SF \"TARGET_AVX\") V4SF\n+   (V8DF \"TARGET_AVX512F\") (V4DF \"TARGET_AVX\") (V2DF \"TARGET_SSE2\")])\n+\n+;; 128- and 256-bit float vector modes\n+(define_mode_iterator VF_128_256\n   [(V8SF \"TARGET_AVX\") V4SF\n    (V4DF \"TARGET_AVX\") (V2DF \"TARGET_SSE2\")])\n \n@@ -143,6 +148,10 @@\n (define_mode_iterator VF_256\n   [V8SF V4DF])\n \n+;; All 512bit vector float modes\n+(define_mode_iterator VF_512\n+  [V16SF V8DF])\n+\n ;; All vector integer modes\n (define_mode_iterator VI\n   [(V32QI \"TARGET_AVX\") V16QI\n@@ -160,6 +169,10 @@\n (define_mode_iterator VI1\n   [(V32QI \"TARGET_AVX\") V16QI])\n \n+(define_mode_iterator VI_UNALIGNED_LOADSTORE\n+  [(V32QI \"TARGET_AVX\") V16QI\n+   (V16SI \"TARGET_AVX512F\") (V8DI \"TARGET_AVX512F\")])\n+\n ;; All DImode vector integer modes\n (define_mode_iterator VI8\n   [(V4DI \"TARGET_AVX\") V2DI])\n@@ -212,11 +225,18 @@\n    (V4SI \"TARGET_AVX2\") (V2DI \"TARGET_AVX2\")\n    (V8SI \"TARGET_AVX2\") (V4DI \"TARGET_AVX2\")])\n \n+(define_mode_attr sse2_avx_avx512f\n+  [(V16QI \"sse2\") (V32QI \"avx\") (V64QI \"avx512f\")\n+   (V4SI  \"sse2\") (V8SI  \"avx\") (V16SI \"avx512f\")\n+   (V8DI \"avx512f\")\n+   (V16SF \"avx512f\") (V8SF \"avx\") (V4SF \"avx\")\n+   (V8DF \"avx512f\") (V4DF \"avx\") (V2DF \"avx\")])\n+\n (define_mode_attr sse2_avx2\n   [(V16QI \"sse2\") (V32QI \"avx2\")\n    (V8HI \"sse2\") (V16HI \"avx2\")\n-   (V4SI \"sse2\") (V8SI \"avx2\")\n-   (V2DI \"sse2\") (V4DI \"avx2\")\n+   (V4SI \"sse2\") (V8SI \"avx2\") (V16SI \"avx512f\")\n+   (V2DI \"sse2\") (V4DI \"avx2\") (V8DI \"avx512f\")\n    (V1TI \"sse2\") (V2TI \"avx2\")])\n \n (define_mode_attr ssse3_avx2\n@@ -229,7 +249,7 @@\n (define_mode_attr sse4_1_avx2\n    [(V16QI \"sse4_1\") (V32QI \"avx2\")\n     (V8HI \"sse4_1\") (V16HI \"avx2\")\n-    (V4SI \"sse4_1\") (V8SI \"avx2\")\n+    (V4SI \"sse4_1\") (V8SI \"avx2\") (V16SI \"avx512f\")\n     (V2DI \"sse4_1\") (V4DI \"avx2\")])\n \n (define_mode_attr avx_avx2\n@@ -244,6 +264,12 @@\n    (V4SI \"vec\") (V8SI \"avx2\")\n    (V2DI \"vec\") (V4DI \"avx2\")])\n \n+(define_mode_attr avx2_avx512f\n+  [(V4SI \"avx2\") (V8SI \"avx2\") (V16SI \"avx512f\")\n+   (V2DI \"avx2\") (V4DI \"avx2\") (V8DI \"avx512f\")\n+   (V8SF \"avx2\") (V16SF \"avx512f\")\n+   (V4DF \"avx2\") (V8DF \"avx512f\")])\n+\n (define_mode_attr shuffletype\n   [(V16SF \"f\") (V16SI \"i\") (V8DF \"f\") (V8DI \"i\")\n   (V8SF \"f\") (V8SI \"i\") (V4DF \"f\") (V4DI \"i\")\n@@ -287,22 +313,26 @@\n (define_mode_attr sse\n   [(SF \"sse\") (DF \"sse2\")\n    (V4SF \"sse\") (V2DF \"sse2\")\n-   (V8SF \"avx\") (V4DF \"avx\")])\n+   (V16SF \"avx512f\") (V8SF \"avx\")\n+   (V8DF \"avx512f\") (V4DF \"avx\")])\n \n (define_mode_attr sse2\n-  [(V16QI \"sse2\") (V32QI \"avx\")\n-   (V2DI \"sse2\") (V4DI \"avx\")])\n+  [(V16QI \"sse2\") (V32QI \"avx\") (V64QI \"avx512f\")\n+   (V2DI \"sse2\") (V4DI \"avx\") (V8DI \"avx512f\")])\n \n (define_mode_attr sse3\n   [(V16QI \"sse3\") (V32QI \"avx\")])\n \n (define_mode_attr sse4_1\n   [(V4SF \"sse4_1\") (V2DF \"sse4_1\")\n-   (V8SF \"avx\") (V4DF \"avx\")])\n+   (V8SF \"avx\") (V4DF \"avx\")\n+   (V8DF \"avx512f\")])\n \n (define_mode_attr avxsizesuffix\n-  [(V32QI \"256\") (V16HI \"256\") (V8SI \"256\") (V4DI \"256\")\n+  [(V64QI \"512\") (V32HI \"512\") (V16SI \"512\") (V8DI \"512\")\n+   (V32QI \"256\") (V16HI \"256\") (V8SI \"256\") (V4DI \"256\")\n    (V16QI \"\") (V8HI \"\") (V4SI \"\") (V2DI \"\")\n+   (V16SF \"512\") (V8DF \"512\")\n    (V8SF \"256\") (V4DF \"256\")\n    (V4SF \"\") (V2DF \"\")])\n \n@@ -318,11 +348,13 @@\n \n ;; Mapping of vector float modes to an integer mode of the same size\n (define_mode_attr sseintvecmode\n-  [(V8SF \"V8SI\") (V4DF \"V4DI\")\n-   (V4SF \"V4SI\") (V2DF \"V2DI\")\n-   (V8SI \"V8SI\") (V4DI \"V4DI\")\n-   (V4SI \"V4SI\") (V2DI \"V2DI\")\n-   (V16HI \"V16HI\") (V8HI \"V8HI\")\n+  [(V16SF \"V16SI\") (V8DF  \"V8DI\")\n+   (V8SF  \"V8SI\")  (V4DF  \"V4DI\")\n+   (V4SF  \"V4SI\")  (V2DF  \"V2DI\")\n+   (V16SI \"V16SI\") (V8DI  \"V8DI\")\n+   (V8SI  \"V8SI\")  (V4DI  \"V4DI\")\n+   (V4SI  \"V4SI\")  (V2DI  \"V2DI\")\n+   (V16HI \"V16HI\") (V8HI  \"V8HI\")\n    (V32QI \"V32QI\") (V16QI \"V16QI\")])\n \n (define_mode_attr sseintvecmodelower\n@@ -349,8 +381,10 @@\n \n ;; Mapping of vector modes ti packed single mode of the same size\n (define_mode_attr ssePSmode\n-  [(V32QI \"V8SF\") (V16QI \"V4SF\")\n-   (V16HI \"V8SF\") (V8HI \"V4SF\")\n+  [(V16SI \"V16SF\") (V8DF \"V16SF\")\n+   (V16SF \"V16SF\") (V8DI \"V16SF\")\n+   (V64QI \"V16SF\") (V32QI \"V8SF\") (V16QI \"V4SF\")\n+   (V32HI \"V16SF\") (V16HI \"V8SF\") (V8HI \"V4SF\")\n    (V8SI \"V8SF\") (V4SI \"V4SF\")\n    (V4DI \"V8SF\") (V2DI \"V4SF\")\n    (V2TI \"V8SF\") (V1TI \"V4SF\")\n@@ -665,12 +699,13 @@\n (define_insn \"<sse>_loadu<ssemodesuffix><avxsizesuffix>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v\")\n \t(unspec:VF\n-\t  [(match_operand:VF 1 \"memory_operand\" \"m\")]\n+\t  [(match_operand:VF 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_LOADU))]\n   \"TARGET_SSE\"\n {\n   switch (get_attr_mode (insn))\n     {\n+    case MODE_V16SF:\n     case MODE_V8SF:\n     case MODE_V4SF:\n       return \"%vmovups\\t{%1, %0|%0, %1}\";\n@@ -694,12 +729,13 @@\n (define_insn \"<sse>_storeu<ssemodesuffix><avxsizesuffix>\"\n   [(set (match_operand:VF 0 \"memory_operand\" \"=m\")\n \t(unspec:VF\n-\t  [(match_operand:VF 1 \"register_operand\" \"x\")]\n+\t  [(match_operand:VF 1 \"register_operand\" \"v\")]\n \t  UNSPEC_STOREU))]\n   \"TARGET_SSE\"\n {\n   switch (get_attr_mode (insn))\n     {\n+    case MODE_V16SF:\n     case MODE_V8SF:\n     case MODE_V4SF:\n       return \"%vmovups\\t{%1, %0|%0, %1}\";\n@@ -721,17 +757,23 @@\n \t      ]\n \t      (const_string \"<MODE>\")))])\n \n-(define_insn \"<sse2>_loaddqu<avxsizesuffix>\"\n-  [(set (match_operand:VI1 0 \"register_operand\" \"=v\")\n-\t(unspec:VI1 [(match_operand:VI1 1 \"memory_operand\" \"m\")]\n-\t\t    UNSPEC_LOADU))]\n+(define_insn \"<sse2_avx_avx512f>_loaddqu<mode>\"\n+  [(set (match_operand:VI_UNALIGNED_LOADSTORE 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_UNALIGNED_LOADSTORE\n+\t  [(match_operand:VI_UNALIGNED_LOADSTORE 1 \"nonimmediate_operand\" \"vm\")]\n+\t  UNSPEC_LOADU))]\n   \"TARGET_SSE2\"\n {\n   switch (get_attr_mode (insn))\n     {\n     case MODE_V8SF:\n     case MODE_V4SF:\n       return \"%vmovups\\t{%1, %0|%0, %1}\";\n+    case MODE_XI:\n+      if (<MODE>mode == V8DImode)\n+\treturn \"vmovdqu64\\t{%1, %0|%0, %1}\";\n+      else\n+\treturn \"vmovdqu32\\t{%1, %0|%0, %1}\";\n     default:\n       return \"%vmovdqu\\t{%1, %0|%0, %1}\";\n     }\n@@ -754,17 +796,23 @@\n \t      ]\n \t      (const_string \"<sseinsnmode>\")))])\n \n-(define_insn \"<sse2>_storedqu<avxsizesuffix>\"\n-  [(set (match_operand:VI1 0 \"memory_operand\" \"=m\")\n-\t(unspec:VI1 [(match_operand:VI1 1 \"register_operand\" \"v\")]\n-\t\t    UNSPEC_STOREU))]\n+(define_insn \"<sse2_avx_avx512f>_storedqu<mode>\"\n+  [(set (match_operand:VI_UNALIGNED_LOADSTORE 0 \"memory_operand\" \"=m\")\n+\t(unspec:VI_UNALIGNED_LOADSTORE\n+\t  [(match_operand:VI_UNALIGNED_LOADSTORE 1 \"register_operand\" \"v\")]\n+\t  UNSPEC_STOREU))]\n   \"TARGET_SSE2\"\n {\n   switch (get_attr_mode (insn))\n     {\n     case MODE_V8SF:\n     case MODE_V4SF:\n       return \"%vmovups\\t{%1, %0|%0, %1}\";\n+    case MODE_XI:\n+      if (<MODE>mode == V8DImode)\n+\treturn \"vmovdqu64\\t{%1, %0|%0, %1}\";\n+      else\n+\treturn \"vmovdqu32\\t{%1, %0|%0, %1}\";\n     default:\n       return \"%vmovdqu\\t{%1, %0|%0, %1}\";\n     }\n@@ -821,8 +869,9 @@\n \n (define_insn \"<sse>_movnt<mode>\"\n   [(set (match_operand:VF 0 \"memory_operand\" \"=m\")\n-\t(unspec:VF [(match_operand:VF 1 \"register_operand\" \"x\")]\n-\t\t   UNSPEC_MOVNT))]\n+\t(unspec:VF\n+\t  [(match_operand:VF 1 \"register_operand\" \"v\")]\n+\t  UNSPEC_MOVNT))]\n   \"TARGET_SSE\"\n   \"%vmovnt<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n@@ -852,9 +901,9 @@\n (define_mode_iterator STORENT_MODE\n   [(DI \"TARGET_SSE2 && TARGET_64BIT\") (SI \"TARGET_SSE2\")\n    (SF \"TARGET_SSE4A\") (DF \"TARGET_SSE4A\")\n-   (V4DI \"TARGET_AVX\") (V2DI \"TARGET_SSE2\")\n-   (V8SF \"TARGET_AVX\") V4SF\n-   (V4DF \"TARGET_AVX\") (V2DF \"TARGET_SSE2\")])\n+   (V8DI \"TARGET_AVX512F\") (V4DI \"TARGET_AVX\") (V2DI \"TARGET_SSE2\")\n+   (V16SF \"TARGET_AVX512F\") (V8SF \"TARGET_AVX\") V4SF\n+   (V8DF \"TARGET_AVX512F\") (V4DF \"TARGET_AVX\") (V2DF \"TARGET_SSE2\")])\n \n (define_expand \"storent<mode>\"\n   [(set (match_operand:STORENT_MODE 0 \"memory_operand\")\n@@ -877,10 +926,10 @@\n   \"ix86_expand_fp_absneg_operator (<CODE>, <MODE>mode, operands); DONE;\")\n \n (define_insn_and_split \"*absneg<mode>2\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x,x,x\")\n+  [(set (match_operand:VF 0 \"register_operand\" \"=x,x,v,v\")\n \t(match_operator:VF 3 \"absneg_operator\"\n-\t  [(match_operand:VF 1 \"nonimmediate_operand\" \"0, xm,x, m\")]))\n-   (use (match_operand:VF 2 \"nonimmediate_operand\"    \"xm,0, xm,x\"))]\n+\t  [(match_operand:VF 1 \"nonimmediate_operand\" \"0, xm, v, m\")]))\n+   (use (match_operand:VF 2 \"nonimmediate_operand\"    \"xm, 0, vm,v\"))]\n   \"TARGET_SSE\"\n   \"#\"\n   \"&& reload_completed\"\n@@ -962,10 +1011,10 @@\n   \"ix86_fixup_binary_operands_no_copy (MULT, <MODE>mode, operands);\")\n \n (define_insn \"*mul<mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n+  [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(mult:VF\n-\t  (match_operand:VF 1 \"nonimmediate_operand\" \"%0,x\")\n-\t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")))]\n+\t  (match_operand:VF 1 \"nonimmediate_operand\" \"%0,v\")\n+\t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,vm\")))]\n   \"TARGET_SSE && ix86_binary_operator_ok (MULT, <MODE>mode, operands)\"\n   \"@\n    mul<ssemodesuffix>\\t{%2, %0|%0, %2}\n@@ -1239,10 +1288,10 @@\n ;; presence of -0.0 and NaN.\n \n (define_insn \"*ieee_smin<mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n+  [(set (match_operand:VF 0 \"register_operand\" \"=v,v\")\n \t(unspec:VF\n-\t  [(match_operand:VF 1 \"register_operand\" \"0,x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")]\n+\t  [(match_operand:VF 1 \"register_operand\" \"0,v\")\n+\t   (match_operand:VF 2 \"nonimmediate_operand\" \"vm,vm\")]\n \t UNSPEC_IEEE_MIN))]\n   \"TARGET_SSE\"\n   \"@\n@@ -1254,10 +1303,10 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"*ieee_smax<mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n+  [(set (match_operand:VF 0 \"register_operand\" \"=v,v\")\n \t(unspec:VF\n-\t  [(match_operand:VF 1 \"register_operand\" \"0,x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")]\n+\t  [(match_operand:VF 1 \"register_operand\" \"0,v\")\n+\t   (match_operand:VF 2 \"nonimmediate_operand\" \"vm,vm\")]\n \t UNSPEC_IEEE_MAX))]\n   \"TARGET_SSE\"\n   \"@\n@@ -1632,10 +1681,10 @@\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n (define_insn \"avx_cmp<mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x\")\n-\t(unspec:VF\n-\t  [(match_operand:VF 1 \"register_operand\" \"x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"xm\")\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x\")\n+\t(unspec:VF_128_256\n+\t  [(match_operand:VF_128_256 1 \"register_operand\" \"x\")\n+\t   (match_operand:VF_128_256 2 \"nonimmediate_operand\" \"xm\")\n \t   (match_operand:SI 3 \"const_0_to_31_operand\" \"n\")]\n \t  UNSPEC_PCMP))]\n   \"TARGET_AVX\"\n@@ -1663,10 +1712,10 @@\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n (define_insn \"*<sse>_maskcmp<mode>3_comm\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n-\t(match_operator:VF 3 \"sse_comparison_operator\"\n-\t  [(match_operand:VF 1 \"register_operand\" \"%0,x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")]))]\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x,x\")\n+\t(match_operator:VF_128_256 3 \"sse_comparison_operator\"\n+\t  [(match_operand:VF_128_256 1 \"register_operand\" \"%0,x\")\n+\t   (match_operand:VF_128_256 2 \"nonimmediate_operand\" \"xm,xm\")]))]\n   \"TARGET_SSE\n    && GET_RTX_CLASS (GET_CODE (operands[3])) == RTX_COMM_COMPARE\"\n   \"@\n@@ -1679,10 +1728,10 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<sse>_maskcmp<mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n-\t(match_operator:VF 3 \"sse_comparison_operator\"\n-\t  [(match_operand:VF 1 \"register_operand\" \"0,x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")]))]\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x,x\")\n+\t(match_operator:VF_128_256 3 \"sse_comparison_operator\"\n+\t  [(match_operand:VF_128_256 1 \"register_operand\" \"0,x\")\n+\t   (match_operand:VF_128_256 2 \"nonimmediate_operand\" \"xm,xm\")]))]\n   \"TARGET_SSE\"\n   \"@\n    cmp%D3<ssemodesuffix>\\t{%2, %0|%0, %2}\n@@ -1792,11 +1841,11 @@\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n (define_insn \"<sse>_andnot<mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n+  [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(and:VF\n \t  (not:VF\n-\t    (match_operand:VF 1 \"register_operand\" \"0,x\"))\n-\t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")))]\n+\t    (match_operand:VF 1 \"register_operand\" \"0,v\"))\n+\t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,vm\")))]\n   \"TARGET_SSE\"\n {\n   static char buf[32];\n@@ -1825,12 +1874,19 @@\n       gcc_unreachable ();\n     }\n \n+  /* There is no vandnp[sd].  Use vpandnq.  */\n+  if (GET_MODE_SIZE (<MODE>mode) == 64)\n+    {\n+      suffix = \"q\";\n+      ops = \"vpandn%s\\t{%%2, %%1, %%0|%%0, %%1, %%2}\";\n+    }\n+\n   snprintf (buf, sizeof (buf), ops, suffix);\n   return buf;\n }\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sselog\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"orig,maybe_evex\")\n    (set (attr \"mode\")\n \t(cond [(match_test \"TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\")\n \t\t (const_string \"<ssePSmode>\")\n@@ -1842,13 +1898,21 @@\n \t       (const_string \"<MODE>\")))])\n \n (define_expand \"<code><mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\")\n-\t(any_logic:VF\n-\t  (match_operand:VF 1 \"nonimmediate_operand\")\n-\t  (match_operand:VF 2 \"nonimmediate_operand\")))]\n+  [(set (match_operand:VF_128_256 0 \"register_operand\")\n+\t(any_logic:VF_128_256\n+\t  (match_operand:VF_128_256 1 \"nonimmediate_operand\")\n+\t  (match_operand:VF_128_256 2 \"nonimmediate_operand\")))]\n   \"TARGET_SSE\"\n   \"ix86_fixup_binary_operands_no_copy (<CODE>, <MODE>mode, operands);\")\n \n+(define_expand \"<code><mode>3\"\n+  [(set (match_operand:VF_512 0 \"register_operand\")\n+       (fpint_logic:VF_512\n+         (match_operand:VF_512 1 \"nonimmediate_operand\")\n+         (match_operand:VF_512 2 \"nonimmediate_operand\")))]\n+  \"TARGET_AVX512F\"\n+  \"ix86_fixup_binary_operands_no_copy (<CODE>, <MODE>mode, operands);\")\n+\n (define_insn \"*<code><mode>3\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(any_logic:VF\n@@ -1882,12 +1946,19 @@\n       gcc_unreachable ();\n     }\n \n+  /* There is no v<logic>p[sd].  Use vp<logic>q.  */\n+  if (GET_MODE_SIZE (<MODE>mode) == 64)\n+    {\n+      suffix = \"q\";\n+      ops = \"vp<logic>%s\\t{%%2, %%1, %%0|%%0, %%1, %%2}\";\n+    }\n+\n   snprintf (buf, sizeof (buf), ops, suffix);\n   return buf;\n }\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sselog\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"orig,maybe_evex\")\n    (set (attr \"mode\")\n \t(cond [(match_test \"TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\")\n \t\t (const_string \"<ssePSmode>\")\n@@ -2105,6 +2176,23 @@\n \t       ]\n \t       (const_string \"TI\")))])\n \n+;; There are no floating point xor for V16SF and V8DF in avx512f\n+;; but we need them for negation.  Instead we use int versions of\n+;; xor.  Maybe there could be a better way to do that.\n+\n+(define_mode_attr avx512flogicsuff\n+  [(V16SF \"d\") (V8DF \"q\")])\n+\n+(define_insn \"avx512f_<logic><mode>\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n+\t(fpint_logic:VF_512\n+\t  (match_operand:VF_512 1 \"register_operand\" \"v\")\n+\t  (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")))]\n+  \"TARGET_AVX512F\"\n+  \"vp<logic><avx512flogicsuff>\\t{%2, %1, %0|%0, %1, %2}\"\n+  [(set_attr \"type\" \"sselog\")\n+   (set_attr \"prefix\" \"evex\")])\n+\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n ;; FMA floating point multiply/accumulate instructions.  These include\n@@ -7747,7 +7835,7 @@\n (define_insn \"<sse>_movmsk<ssemodesuffix><avxsizesuffix>\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n \t(unspec:SI\n-\t  [(match_operand:VF 1 \"register_operand\" \"x\")]\n+\t  [(match_operand:VF_128_256 1 \"register_operand\" \"x\")]\n \t  UNSPEC_MOVMSK))]\n   \"TARGET_SSE\"\n   \"%vmovmsk<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n@@ -8537,10 +8625,10 @@\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n (define_insn \"<sse4_1>_blend<ssemodesuffix><avxsizesuffix>\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:VF\n-\t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")\n-\t  (match_operand:VF 1 \"register_operand\" \"0,x\")\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x,x\")\n+\t(vec_merge:VF_128_256\n+\t  (match_operand:VF_128_256 2 \"nonimmediate_operand\" \"xm,xm\")\n+\t  (match_operand:VF_128_256 1 \"register_operand\" \"0,x\")\n \t  (match_operand:SI 3 \"const_0_to_<blendbits>_operand\")))]\n   \"TARGET_SSE4_1\"\n   \"@\n@@ -8555,11 +8643,11 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<sse4_1>_blendv<ssemodesuffix><avxsizesuffix>\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:VF\n-\t  [(match_operand:VF 1 \"register_operand\" \"0,x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")\n-\t   (match_operand:VF 3 \"register_operand\" \"Yz,x\")]\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x,x\")\n+\t(unspec:VF_128_256\n+\t  [(match_operand:VF_128_256 1 \"register_operand\" \"0,x\")\n+\t   (match_operand:VF_128_256 2 \"nonimmediate_operand\" \"xm,xm\")\n+\t   (match_operand:VF_128_256 3 \"register_operand\" \"Yz,x\")]\n \t  UNSPEC_BLENDV))]\n   \"TARGET_SSE4_1\"\n   \"@\n@@ -8575,10 +8663,10 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<sse4_1>_dp<ssemodesuffix><avxsizesuffix>\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:VF\n-\t  [(match_operand:VF 1 \"nonimmediate_operand\" \"%0,x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"xm,xm\")\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x,x\")\n+\t(unspec:VF_128_256\n+\t  [(match_operand:VF_128_256 1 \"nonimmediate_operand\" \"%0,x\")\n+\t   (match_operand:VF_128_256 2 \"nonimmediate_operand\" \"xm,xm\")\n \t   (match_operand:SI 3 \"const_0_to_255_operand\" \"n,n\")]\n \t  UNSPEC_DP))]\n   \"TARGET_SSE4_1\"\n@@ -8909,8 +8997,8 @@\n ;; setting FLAGS_REG. But it is not a really compare instruction.\n (define_insn \"avx_vtest<ssemodesuffix><avxsizesuffix>\"\n   [(set (reg:CC FLAGS_REG)\n-\t(unspec:CC [(match_operand:VF 0 \"register_operand\" \"x\")\n-\t\t    (match_operand:VF 1 \"nonimmediate_operand\" \"xm\")]\n+\t(unspec:CC [(match_operand:VF_128_256 0 \"register_operand\" \"x\")\n+\t\t    (match_operand:VF_128_256 1 \"nonimmediate_operand\" \"xm\")]\n \t\t   UNSPEC_VTESTP))]\n   \"TARGET_AVX\"\n   \"vtest<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n@@ -8947,9 +9035,9 @@\n    (set_attr \"mode\" \"TI\")])\n \n (define_insn \"<sse4_1>_round<ssemodesuffix><avxsizesuffix>\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x\")\n-\t(unspec:VF\n-\t  [(match_operand:VF 1 \"nonimmediate_operand\" \"xm\")\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x\")\n+\t(unspec:VF_128_256\n+\t  [(match_operand:VF_128_256 1 \"nonimmediate_operand\" \"xm\")\n \t   (match_operand:SI 2 \"const_0_to_15_operand\" \"n\")]\n \t  UNSPEC_ROUND))]\n   \"TARGET_ROUND\"\n@@ -10341,10 +10429,10 @@\n    (set_attr \"mode\" \"TI\")])\n \n (define_insn \"xop_vpermil2<mode>3\"\n-  [(set (match_operand:VF 0 \"register_operand\" \"=x\")\n-\t(unspec:VF\n-\t  [(match_operand:VF 1 \"register_operand\" \"x\")\n-\t   (match_operand:VF 2 \"nonimmediate_operand\" \"%x\")\n+  [(set (match_operand:VF_128_256 0 \"register_operand\" \"=x\")\n+\t(unspec:VF_128_256\n+\t  [(match_operand:VF_128_256 1 \"register_operand\" \"x\")\n+\t   (match_operand:VF_128_256 2 \"nonimmediate_operand\" \"%x\")\n \t   (match_operand:<sseintvecmode> 3 \"nonimmediate_operand\" \"xm\")\n \t   (match_operand:SI 4 \"const_0_to_3_operand\" \"n\")]\n \t  UNSPEC_VPERMIL2))]\n@@ -10794,7 +10882,7 @@\n     = gen_rtx_PARALLEL (VOIDmode, gen_rtvec_v (<ssescalarnum>, perm));\n })\n \n-(define_insn \"*avx_vpermilp<mode>\"\n+(define_insn \"*<sse2_avx_avx512f>_vpermilp<mode>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v\")\n \t(vec_select:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\" \"vm\")\n@@ -10811,9 +10899,9 @@\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"<MODE>\")])\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx_vpermilvar<mode>3\"\n+(define_insn \"<sse2_avx_avx512f>_vpermilvar<mode>3\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v\")\n \t(unspec:VF\n \t  [(match_operand:VF 1 \"register_operand\" \"v\")\n@@ -10823,9 +10911,10 @@\n   \"vpermil<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix_extra\" \"1\")\n-   (set_attr \"prefix\" \"vex\")\n    (set_attr \"btver2_decode\" \"vector\")\n-   (set_attr \"mode\" \"<MODE>\")])\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n \n (define_expand \"avx_vperm2f128<mode>3\"\n   [(set (match_operand:AVX256MODE2P 0 \"register_operand\")"}]}