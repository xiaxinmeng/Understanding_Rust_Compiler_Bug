{"sha": "5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NWZkZGNmZmM4YWE2NWNiZjE2OTVkOTU2MDVhMTliNGQ1ZDhmNDNhNw==", "commit": {"author": {"name": "Neil Booth", "email": "neil@daikokuya.demon.co.uk", "date": "2001-09-11T07:00:12Z"}, "committer": {"name": "Neil Booth", "email": "neil@gcc.gnu.org", "date": "2001-09-11T07:00:12Z"}, "message": "cpphash.h (struct tokenrun): New.\n\n\t* cpphash.h (struct tokenrun): New.\n\t(struct cpp_context): New member bol.\n\t(struct cpp_reader): New members.\n\t(_cpp_init_tokenrun): New.\n\t* cppinit.c (cpp_create_reader): Set up the token runs.\n\t* cpplex.c (lex_directive, lex_token, next_tokenrun): New.\n\t(lex_token): New internalised version of _cpp_lex_token.  Don't\n\thandle directives or the multiple include opimisation here any\n\tmore.  Simply lex a token.\n\t* cpplib.c (run_directive): Clear bol.\n\t(_cpp_pop_buffer): Set bol.\n\t* cppmacro.c (funlike_invocation_p): Keep tokens whilst parsing\n\targuments.\n\nFrom-SVN: r45534", "tree": {"sha": "943c0f0881bcaf2f5425616b1754f072979eb4b6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/943c0f0881bcaf2f5425616b1754f072979eb4b6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/comments", "author": null, "committer": null, "parents": [{"sha": "75dcd8fe99a9b22bf81705c4c898241b042c0873", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/75dcd8fe99a9b22bf81705c4c898241b042c0873", "html_url": "https://github.com/Rust-GCC/gccrs/commit/75dcd8fe99a9b22bf81705c4c898241b042c0873"}], "stats": {"total": 327, "additions": 211, "deletions": 116}, "files": [{"sha": "f025864ae30b3cdb7f2c8156260468cb4f5eaa5a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "patch": "@@ -1,3 +1,19 @@\n+2001-09-11  Neil Booth  <neil@daikokuya.demon.co.uk>\n+\n+\t* cpphash.h (struct tokenrun): New.\n+\t(struct cpp_context): New member bol.\n+\t(struct cpp_reader): New members.\n+\t(_cpp_init_tokenrun): New.\n+\t* cppinit.c (cpp_create_reader): Set up the token runs.\n+\t* cpplex.c (lex_directive, lex_token, next_tokenrun): New.\n+\t(lex_token): New internalised version of _cpp_lex_token.  Don't\n+\thandle directives or the multiple include opimisation here any\n+\tmore.  Simply lex a token.\n+\t* cpplib.c (run_directive): Clear bol.\n+\t(_cpp_pop_buffer): Set bol.\n+\t* cppmacro.c (funlike_invocation_p): Keep tokens whilst parsing\n+\targuments.\n+\n 2001-09-11  Michael Meissner  <meissner@redhat.com>\n \n \t* config/mips/mips.h (CC1_SPEC): If -mgp32 default to -mfp32, and"}, {"sha": "4224e91a24cba26a0b3bcb75457772d0306ae26a", "filename": "gcc/cpphash.h", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcpphash.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcpphash.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpphash.h?ref=5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "patch": "@@ -102,6 +102,13 @@ struct toklist\n   cpp_token *limit;\n };\n \n+typedef struct tokenrun tokenrun;\n+struct tokenrun\n+{\n+  tokenrun *next;\n+  cpp_token *base, *limit;\n+};\n+\n typedef struct cpp_context cpp_context;\n struct cpp_context\n {\n@@ -124,6 +131,9 @@ struct lexer_state\n   /* True if we are skipping a failed conditional group.  */\n   unsigned char skipping;\n \n+  /* Nonzero if next token is the start of a line.  */\n+  unsigned char bol;\n+\n   /* Nonzero if in a directive that takes angle-bracketed headers.  */\n   unsigned char angled_headers;\n \n@@ -258,6 +268,13 @@ struct cpp_reader\n   const cpp_hashnode *mi_ind_cmacro;\n   bool mi_valid;\n \n+  /* Lexing.  */\n+  cpp_token *cur_token;\n+  tokenrun base_run, *cur_run;\n+\n+  /* Non-zero prevents the lexer from re-using the token runs.  */\n+  unsigned int keep_tokens;\n+\n   /* Token lookahead.  */\n   struct cpp_lookahead *la_read;\t/* Read from this lookahead.  */\n   struct cpp_lookahead *la_write;\t/* Write to this lookahead.  */\n@@ -397,6 +414,7 @@ extern int _cpp_parse_expr\t\tPARAMS ((cpp_reader *));\n extern void _cpp_lex_token\t\tPARAMS ((cpp_reader *, cpp_token *));\n extern int _cpp_equiv_tokens\t\tPARAMS ((const cpp_token *,\n \t\t\t\t\t\t const cpp_token *));\n+extern void _cpp_init_tokenrun\t\tPARAMS ((tokenrun *, unsigned int));\n extern void _cpp_init_pool\t\tPARAMS ((cpp_pool *, unsigned int,\n \t\t\t\t\t\t  unsigned int, unsigned int));\n extern void _cpp_free_pool\t\tPARAMS ((cpp_pool *));"}, {"sha": "8029746bab1eda11586f087a43cddbf812e4a4b6", "filename": "gcc/cppinit.c", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcppinit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcppinit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppinit.c?ref=5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "patch": "@@ -511,6 +511,12 @@ cpp_create_reader (table, lang)\n   /* Indicate date and time not yet calculated.  */\n   pfile->date.type = CPP_EOF;\n \n+  /* Create a token buffer for the lexer.  */\n+  _cpp_init_tokenrun (&pfile->base_run, 250);\n+  pfile->cur_run = &pfile->base_run;\n+  pfile->cur_token = pfile->base_run.base;\n+  pfile->state.bol = 1;\n+\n   /* Initialise the base context.  */\n   pfile->context = &pfile->base_context;\n   pfile->base_context.macro = 0;"}, {"sha": "1aea9e8c3bbe786ca301fde07b18af799901390d", "filename": "gcc/cpplex.c", "status": "modified", "additions": 167, "deletions": 116, "changes": 283, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcpplex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcpplex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplex.c?ref=5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "patch": "@@ -102,6 +102,9 @@ static void lex_dot PARAMS ((cpp_reader *, cpp_token *));\n static int name_p PARAMS ((cpp_reader *, const cpp_string *));\n static int maybe_read_ucs PARAMS ((cpp_reader *, const unsigned char **,\n \t\t\t\t   const unsigned char *, unsigned int *));\n+static int lex_directive PARAMS ((cpp_reader *));\n+static void lex_token PARAMS ((cpp_reader *, cpp_token *, int));\n+static tokenrun *next_tokenrun PARAMS ((tokenrun *));\n \n static cpp_chunk *new_chunk PARAMS ((unsigned int));\n static int chunk_suitable PARAMS ((cpp_pool *, cpp_chunk *, unsigned int));\n@@ -903,103 +906,200 @@ lex_dot (pfile, result)\n     }\n }\n \n+/* Allocate COUNT tokens for RUN.  */\n+void\n+_cpp_init_tokenrun (run, count)\n+     tokenrun *run;\n+     unsigned int count;\n+{\n+  run->base = xnewvec (cpp_token, count);\n+  run->limit = run->base + count;\n+  run->next = NULL;\n+}\n+\n+/* Returns the next tokenrun, or creates one if there is none.  */\n+static tokenrun *\n+next_tokenrun (run)\n+     tokenrun *run;\n+{\n+  if (run->next == NULL)\n+    {\n+      run->next = xnew (tokenrun);\n+      _cpp_init_tokenrun (run->next, 250);\n+    }\n+\n+  return run->next;\n+}\n+\n+static int\n+lex_directive (pfile)\n+     cpp_reader *pfile;\n+{\n+  /* 6.10.3 paragraph 11: If there are sequences of preprocessing\n+     tokens within the list of arguments that would otherwise act as\n+     preprocessing directives, the behavior is undefined.\n+\n+     This implementation will report a hard error, terminate the macro\n+     invocation, and proceed to process the directive.  */\n+  if (pfile->state.parsing_args)\n+    {\n+      pfile->lexer_pos.output_line = pfile->line;\n+      if (pfile->state.parsing_args == 2)\n+\t{\n+\t  cpp_error (pfile,\n+\t\t     \"directives may not be used inside a macro argument\");\n+\t  pfile->state.bol = 1;\n+\t  pfile->buffer->cur = pfile->buffer->line_base;\n+\t  pfile->buffer->read_ahead = EOF;\n+\t  pfile->cur_token->type = CPP_EOF;\n+\t}\n+\n+      return 0;\n+    }\n+\n+  /* This is a directive.  If the return value is false, it is an\n+     assembler #.  */\n+  {\n+    /* FIXME: short-term kludge only - it doesn't handle the case that\n+       the # is at the end of a run and we moved to the start of the\n+       next one.  Easily fixed once we kill lookaheads.  */\n+    cpp_token *token = pfile->cur_token++;\n+    if (_cpp_handle_directive (pfile, token->flags & PREV_WHITE))\n+      return 1;\n+    pfile->cur_token = token;\n+    return 0;\n+  }\n+}\n+\n+/* Lex a token into RESULT (external interface).  */\n void\n _cpp_lex_token (pfile, result)\n      cpp_reader *pfile;\n      cpp_token *result;\n+{\n+  if (pfile->cur_token == pfile->cur_run->limit)\n+    {\n+      pfile->cur_run = next_tokenrun (pfile->cur_run);\n+      pfile->cur_token = pfile->cur_run->base;\n+    }\n+\n+ next_token:\n+  if (pfile->state.bol)\n+    {\n+    start_new_line:\n+      pfile->state.bol = 0;\n+\n+      /* Return lexer back to base.  */\n+      if (!pfile->keep_tokens)\n+\t{\n+\t  pfile->cur_run = &pfile->base_run;\n+\t  pfile->cur_token = pfile->base_run.base;\n+\t}\n+\n+      lex_token (pfile, pfile->cur_token, 1);\n+      pfile->lexer_pos.output_line = pfile->cur_token->line;\n+      if (pfile->cur_token->type == CPP_HASH && lex_directive (pfile))\n+\tgoto start_new_line;\n+    }\n+  else\n+    {\n+      lex_token (pfile, pfile->cur_token, 0);\n+      if (pfile->cur_token->type == CPP_EOF)\n+\t{\n+\t  if (!pfile->state.in_directive)\n+\t    goto start_new_line;\n+\t  /* Decrementing pfile->line allows directives to recognise\n+\t     that the newline has been seen, and also means that\n+\t     diagnostics don't point to the next line.  */\n+\t  pfile->lexer_pos.output_line = pfile->line--;\n+\t}\n+    }\n+\n+  if (!pfile->state.in_directive)\n+    {\n+      if (pfile->state.skipping && pfile->cur_token->type != CPP_EOF)\n+\tgoto next_token;\n+\n+      /* Outside a directive, invalidate controlling macros.  */\n+      pfile->mi_valid = false;\n+    }\n+\n+  *result = *pfile->cur_token++;\n+}\n+\n+/* Lex a token into RESULT (internal interface).  */\n+static void\n+lex_token (pfile, result, skip_newlines)\n+     cpp_reader *pfile;\n+     cpp_token *result;\n+     int skip_newlines;\n {\n   cppchar_t c;\n   cpp_buffer *buffer;\n   const unsigned char *comment_start;\n-  int bol;\n \n- next_token:\n+ fresh_line:\n   buffer = pfile->buffer;\n   result->flags = buffer->saved_flags;\n   buffer->saved_flags = 0;\n-  bol = (buffer->cur <= buffer->line_base + 1\n-\t && pfile->lexer_pos.output_line == pfile->line);\n- next_char:\n+ update_tokens_line:\n   pfile->lexer_pos.line = pfile->line;\n   result->line = pfile->line;\n- next_char2:\n-  pfile->lexer_pos.col = CPP_BUF_COLUMN (buffer, buffer->cur);\n \n+ skipped_white:\n   c = buffer->read_ahead;\n   if (c == EOF && buffer->cur < buffer->rlimit)\n-    {\n-      c = *buffer->cur++;\n-      pfile->lexer_pos.col++;\n-    }\n-  result->col = pfile->lexer_pos.col;\n-\n- do_switch:\n+    c = *buffer->cur++;\n+  result->col = CPP_BUF_COLUMN (buffer, buffer->cur);\n+  pfile->lexer_pos.col = result->col;\n   buffer->read_ahead = EOF;\n+\n+ trigraph:\n   switch (c)\n     {\n     case EOF:\n-      /* Non-empty files should end in a newline.  Don't warn for\n-\t command line and _Pragma buffers.  */\n-      if (pfile->lexer_pos.col != 0)\n-\t{\n-\t  /* Account for the missing \\n, prevent multiple warnings.  */\n-\t  pfile->line++;\n-\t  pfile->lexer_pos.col = 0;\n-\t  if (!buffer->from_stage3)\n-\t    cpp_pedwarn (pfile, \"no newline at end of file\");\n-\t}\n-\n-      /* To prevent bogus diagnostics, only pop the buffer when\n-\t in-progress directives and arguments have been taken care of.\n-\t Decrement the line to terminate an in-progress directive.  */\n-      if (pfile->state.in_directive)\n-\tpfile->lexer_pos.output_line = pfile->line--;\n-      else if (! pfile->state.parsing_args)\n+      if (!pfile->state.parsing_args && !pfile->state.in_directive)\n \t{\n-\t  /* Don't pop the last buffer.  */\n-\t  if (buffer->prev)\n+\t  if (buffer->cur == buffer->line_base)\n \t    {\n-\t      unsigned char stop = buffer->return_at_eof;\n+\t      /* Don't pop the last buffer.  */\n+\t      if (buffer->prev)\n+\t\t{\n+\t\t  unsigned char stop = buffer->return_at_eof;\n \n-\t      _cpp_pop_buffer (pfile);\n-\t      if (!stop)\n-\t\tgoto next_token;\n+\t\t  _cpp_pop_buffer (pfile);\n+\t\t  if (!stop)\n+\t\t    goto fresh_line;\n+\t\t}\n+\t    }\n+\t  else\n+\t    {\n+\t      /* Non-empty files should end in a newline.  Don't warn\n+\t\t for command line and _Pragma buffers.  */\n+\t      if (!buffer->from_stage3)\n+\t\tcpp_pedwarn (pfile, \"no newline at end of file\");\n+\t      handle_newline (pfile, '\\n');\n \t    }\n \t}\n       result->type = CPP_EOF;\n-      return;\n+      break;\n \n     case ' ': case '\\t': case '\\f': case '\\v': case '\\0':\n       skip_whitespace (pfile, c);\n       result->flags |= PREV_WHITE;\n-      goto next_char2;\n+      goto skipped_white;\n \n     case '\\n': case '\\r':\n-      if (pfile->state.in_directive)\n+      if (pfile->state.in_directive && pfile->state.parsing_args)\n+\tbuffer->read_ahead = c;\n+      else\n \t{\n-\t  result->type = CPP_EOF;\n-\t  if (pfile->state.parsing_args)\n-\t    buffer->read_ahead = c;\n-\t  else\n-\t    {\n-\t      handle_newline (pfile, c);\n-\t      /* Decrementing pfile->line allows directives to\n-\t\t recognise that the newline has been seen, and also\n-\t\t means that diagnostics don't point to the next line.  */\n-\t      pfile->lexer_pos.output_line = pfile->line--;\n-\t    }\n-\t  return;\n+\t  handle_newline (pfile, c);\n+\t  if (skip_newlines)\n+\t    goto fresh_line;\n \t}\n-\n-      handle_newline (pfile, c);\n-      /* This is a new line, so clear any white space flag.  Newlines\n-\t in arguments are white space (6.10.3.10); parse_arg takes\n-\t care of that.  */\n-      result->flags &= ~(PREV_WHITE | AVOID_LPASTE);\n-      bol = 1;\n-      if (pfile->state.parsing_args != 2)\n-\tpfile->lexer_pos.output_line = pfile->line;\n-      goto next_char;\n+      result->type = CPP_EOF;\n+      break;\n \n     case '?':\n     case '\\\\':\n@@ -1013,15 +1113,15 @@ _cpp_lex_token (pfile, result)\n \t  /* We had at least one escaped newline of some sort, and the\n \t     next character is in buffer->read_ahead.  Update the\n \t     token's line and column.  */\n-\t    goto next_char;\n+\t    goto update_tokens_line;\n \n \t/* We are either the original '?' or '\\\\', or a trigraph.  */\n \tresult->type = CPP_QUERY;\n \tbuffer->read_ahead = EOF;\n \tif (c == '\\\\')\n \t  goto random_char;\n \telse if (c != '?')\n-\t  goto do_switch;\n+\t  goto trigraph;\n       }\n       break;\n \n@@ -1122,7 +1222,7 @@ _cpp_lex_token (pfile, result)\n       if (!pfile->state.save_comments)\n \t{\n \t  result->flags |= PREV_WHITE;\n-\t  goto next_char;\n+\t  goto update_tokens_line;\n \t}\n \n       /* Save the comment as a token in its own right.  */\n@@ -1187,8 +1287,6 @@ _cpp_lex_token (pfile, result)\n \n     case '%':\n       lex_percent (pfile, result);\n-      if (result->type == CPP_HASH)\n-\tgoto do_hash;\n       break;\n \n     case '.':\n@@ -1248,49 +1346,9 @@ _cpp_lex_token (pfile, result)\n       break;\n \t  \n     case '#':\n-      c = buffer->extra_char;\t/* Can be set by error condition below.  */\n-      if (c != EOF)\n-\t{\n-\t  buffer->read_ahead = c;\n-\t  buffer->extra_char = EOF;\n-\t}\n-      else\n-\tc = get_effective_char (pfile);\n-\n-      if (c == '#')\n-\t{\n-\t  ACCEPT_CHAR (CPP_PASTE);\n-\t  break;\n-\t}\n-\n       result->type = CPP_HASH;\n-    do_hash:\n-      if (!bol)\n-\tbreak;\n-      /* 6.10.3 paragraph 11: If there are sequences of preprocessing\n-\t tokens within the list of arguments that would otherwise act\n-\t as preprocessing directives, the behavior is undefined.\n-\n-\t This implementation will report a hard error, terminate the\n-\t macro invocation, and proceed to process the directive.  */\n-      if (pfile->state.parsing_args)\n-\t{\n-\t  pfile->lexer_pos.output_line = pfile->line;\n-\t  if (pfile->state.parsing_args == 2)\n-\t    {\n-\t      cpp_error (pfile,\n-\t\t\t \"directives may not be used inside a macro argument\");\n-\t      result->type = CPP_EOF;\n-\t    }\n-\t}\n-      /* in_directive can be true inside a _Pragma.  */\n-      else if (!pfile->state.in_directive)\n-\t{\n-\t  /* This is the hash introducing a directive.  If the return\n-\t     value is false, it is an assembler #.  */\n-\t  if (_cpp_handle_directive (pfile, result->flags & PREV_WHITE))\n-\t    goto next_token;\n-\t}\n+      if (get_effective_char (pfile) == '#')\n+\t  ACCEPT_CHAR (CPP_PASTE);\n       break;\n \n     case '|':\n@@ -1339,13 +1397,6 @@ _cpp_lex_token (pfile, result)\n       result->val.c = c;\n       break;\n     }\n-\n-  if (!pfile->state.in_directive && pfile->state.skipping)\n-    goto next_char;\n-\n-  /* If not in a directive, this token invalidates controlling macros.  */\n-  if (!pfile->state.in_directive)\n-    pfile->mi_valid = false;\n }\n \n /* An upper bound on the number of bytes needed to spell a token,"}, {"sha": "ada34b5717f1a9a26937ae368b2ea368ef3e838b", "filename": "gcc/cpplib.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcpplib.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcpplib.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.c?ref=5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "patch": "@@ -402,6 +402,7 @@ run_directive (pfile, dir_no, buf, count)\n   cpp_push_buffer (pfile, (const U_CHAR *) buf, count,\n \t\t   /* from_stage3 */ true, 1);\n   start_directive (pfile);\n+  pfile->state.bol = 0;\n   pfile->state.prevent_expansion++;\n   pfile->directive = &dtable[dir_no];\n   (void) (*pfile->directive->handler) (pfile);\n@@ -1782,6 +1783,7 @@ _cpp_pop_buffer (pfile)\n      case of a missing #endif.  */\n   pfile->lexer_pos.output_line = pfile->line;\n   pfile->state.skipping = 0;\n+  pfile->state.bol = 1;\n \n   /* Update the reader's buffer before _cpp_do_file_change.  */\n   pfile->buffer = buffer->prev;"}, {"sha": "c8f0719a5bffbd70606f272f753aa7a7091aa0a0", "filename": "gcc/cppmacro.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcppmacro.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7/gcc%2Fcppmacro.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppmacro.c?ref=5fddcffc8aa65cbf1695d95605a19b4d5d8f43a7", "patch": "@@ -599,6 +599,7 @@ funlike_invocation_p (pfile, node, list)\n   pfile->state.parsing_args = 1;\n   pfile->state.prevent_expansion++;\n \n+  pfile->keep_tokens++;\n   cpp_start_lookahead (pfile);\n   cpp_get_token (pfile, &maybe_paren);\n   cpp_stop_lookahead (pfile, maybe_paren.type == CPP_OPEN_PAREN);\n@@ -613,6 +614,7 @@ funlike_invocation_p (pfile, node, list)\n \n   pfile->state.prevent_expansion--;\n   pfile->state.parsing_args = 0;\n+  pfile->keep_tokens--;\n \n   /* Reset the position in case of failure.  If success, the macro's\n      expansion appears where the name would have.  */"}]}