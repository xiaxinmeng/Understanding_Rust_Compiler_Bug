{"sha": "629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NjI5YjNkNzVjOGM1YTI0NGQ4OTFhOWMyOTJiY2E2OTEyZDRiMGRkOQ==", "commit": {"author": {"name": "Martin Jambor", "email": "mjambor@suse.cz", "date": "2016-12-14T22:30:41Z"}, "committer": {"name": "Martin Jambor", "email": "jamborm@gcc.gnu.org", "date": "2016-12-14T22:30:41Z"}, "message": "Split omp-low into multiple files\n\n2016-12-14  Martin Jambor  <mjambor@suse.cz>\n\n\t* omp-general.h: New file.\n\t* omp-general.c: New file.\n\t* omp-expand.h: Likewise.\n\t* omp-expand.c: Likewise.\n\t* omp-offload.h: Likewise.\n\t* omp-offload.c: Likewise.\n\t* omp-grid.c: Likewise.\n\t* omp-grid.c: Likewise.\n\t* omp-low.h: Include omp-general.h and omp-grid.h.  Removed includes\n\tof params.h, symbol-summary.h, lto-section-names.h, cilk.h, tree-eh.h,\n\tipa-prop.h, tree-cfgcleanup.h, cfgloop.h, except.h, expr.h, stmt.h,\n\tvarasm.h, calls.h, explow.h, dojump.h, flags.h, tree-into-ssa.h,\n\ttree-cfg.h, cfganal.h, alias.h, emit-rtl.h, optabs.h, expmed.h,\n\talloc-pool.h, cfghooks.h, rtl.h and memmodel.h.\n\t(omp_find_combined_for): Declare.\n\t(find_omp_clause): Renamed to omp_find_clause and moved to\n\tomp-general.h.\n\t(free_omp_regions): Renamed to omp_free_regions and moved to\n\tomp-expand.h.\n\t(replace_oacc_fn_attrib): Renamed to oacc_replace_fn_attrib and moved\n\tto omp-general.h.\n\t(set_oacc_fn_attrib): Renamed to oacc_set_fn_attrib and moved to\n\tomp-general.h.\n\t(build_oacc_routine_dims): Renamed to oacc_build_routine_dims and\n\tmoved to omp-general.h.\n\t(get_oacc_fn_attrib): Renamed to oacc_get_fn_attrib and moved to\n\tomp-general.h.\n\t(oacc_fn_attrib_kernels_p): Moved to omp-general.h.\n\t(get_oacc_fn_dim_size): Renamed to oacc_get_fn_dim_size and moved to\n\tomp-general.c.\n\t(omp_expand_local): Moved to omp-expand.h.\n\t(make_gimple_omp_edges): Renamed to omp_make_gimple_edges and moved to\n\tomp-expand.h.\n\t(omp_finish_file): Moved to omp-offload.h.\n\t(default_goacc_validate_dims): Renamed to\n\toacc_default_goacc_validate_dims and moved to omp-offload.h.\n\t(offload_funcs, offload_vars): Moved to omp-offload.h.\n\t* omp-low.c: Include omp-general.h, omp-offload.h and omp-grid.h.\n\t(omp_region): Moved to omp-expand.c.\n\t(omp_for_data_loop): Moved to omp-general.h.\n\t(omp_for_data): Likewise.\n\t(oacc_loop): Moved to omp-offload.c.\n\t(oacc_loop_flags): Moved to omp-general.h.\n\t(offload_funcs, offload_vars): Moved to omp-offload.c.\n\t(root_omp_region): Moved to omp-expand.c.\n\t(omp_any_child_fn_dumped): Likewise.\n\t(find_omp_clause): Renamed to omp_find_clause and moved to\n\tomp-general.c.\n\t(is_combined_parallel): Moved to omp-expand.c.\n\t(is_reference): Renamed to omp_is_reference and and moved to\n\tomp-general.c.\n\t(adjust_for_condition): Renamed to omp_adjust_for_condition and moved\n\tto omp-general.c.\n\t(get_omp_for_step_from_incr): Renamed to omp_get_for_step_from_incr\n\tand moved to omp-general.c.\n\t(extract_omp_for_data): Renamed to omp_extract_for_data and moved to\n\tomp-general.c.\n\t(workshare_safe_to_combine_p): Moved to omp-expand.c.\n\t(omp_adjust_chunk_size): Likewise.\n\t(get_ws_args_for): Likewise.\n\t(get_base_type): Removed.\n\t(dump_omp_region): Moved to omp-expand.c.\n\t(debug_omp_region): Likewise.\n\t(debug_all_omp_regions): Likewise.\n\t(new_omp_region): Likewise.\n\t(free_omp_region_1): Likewise.\n\t(free_omp_regions): Renamed to omp_free_regions and moved to\n\tomp-expand.c.\n\t(find_combined_for): Renamed to omp_find_combined_for, made global.\n\t(build_omp_barrier): Renamed to omp_build_barrier and moved to\n\tomp-general.c.\n\t(omp_max_vf): Moved to omp-general.c.\n\t(omp_max_simt_vf): Likewise.\n\t(gimple_build_cond_empty): Moved to omp-expand.c.\n\t(parallel_needs_hsa_kernel_p): Likewise.\n\t(expand_omp_build_assign): Moved declaration to omp-expand.c.\n\t(expand_parallel_call): Moved to omp-expand.c.\n\t(expand_cilk_for_call): Likewise.\n\t(expand_task_call): Likewise.\n\t(vec2chain): Likewise.\n\t(remove_exit_barrier): Likewise.\n\t(remove_exit_barriers): Likewise.\n\t(optimize_omp_library_calls): Likewise.\n\t(expand_omp_regimplify_p): Likewise.\n\t(expand_omp_build_assign): Likewise.\n\t(expand_omp_taskreg): Likewise.\n\t(oacc_collapse): Likewise.\n\t(expand_oacc_collapse_init): Likewise.\n\t(expand_oacc_collapse_vars): Likewise.\n\t(expand_omp_for_init_counts): Likewise.\n\t(expand_omp_for_init_vars): Likewise.\n\t(extract_omp_for_update_vars): Likewise.\n\t(expand_omp_ordered_source): Likewise.\n\t(expand_omp_ordered_sink): Likewise.\n\t(expand_omp_ordered_source_sink): Likewise.\n\t(expand_omp_for_ordered_loops): Likewise.\n\t(expand_omp_for_generic): Likewise.\n\t(expand_omp_for_static_nochunk): Likewise.\n\t(find_phi_with_arg_on_edge): Likewise.\n\t(expand_omp_for_static_chunk): Likewise.\n\t(expand_cilk_for): Likewise.\n\t(expand_omp_simd): Likewise.\n\t(expand_omp_taskloop_for_outer): Likewise.\n\t(expand_omp_taskloop_for_inner): Likewise.\n\t(expand_oacc_for): Likewise.\n\t(expand_omp_for): Likewise.\n\t(expand_omp_sections): Likewise.\n\t(expand_omp_single): Likewise.\n\t(expand_omp_synch): Likewise.\n\t(expand_omp_atomic_load): Likewise.\n\t(expand_omp_atomic_store): Likewise.\n\t(expand_omp_atomic_fetch_op): Likewise.\n\t(expand_omp_atomic_pipeline): Likewise.\n\t(expand_omp_atomic_mutex): Likewise.\n\t(expand_omp_atomic): Likewise.\n\t(oacc_launch_pack): and moved to omp-general.c, made public.\n\t(OACC_FN_ATTRIB): Likewise.\n\t(replace_oacc_fn_attrib): Renamed to oacc_replace_fn_attrib and moved\n\tto omp-general.c.\n\t(set_oacc_fn_attrib): Renamed to oacc_set_fn_attrib and moved to\n\tomp-general.c.\n\t(build_oacc_routine_dims): Renamed to oacc_build_routine_dims and\n\tmoved to omp-general.c.\n\t(get_oacc_fn_attrib): Renamed to oacc_get_fn_attrib and moved to\n\tomp-general.c.\n\t(oacc_fn_attrib_kernels_p): Moved to omp-general.c.\n\t(oacc_fn_attrib_level): Moved to omp-offload.c.\n\t(get_oacc_fn_dim_size): Renamed to oacc_get_fn_dim_size and moved to\n\tomp-general.c.\n\t(get_oacc_ifn_dim_arg): Renamed to oacc_get_ifn_dim_arg and moved to\n\tomp-general.c.\n\t(mark_loops_in_oacc_kernels_region): Moved to omp-expand.c.\n\t(grid_launch_attributes_trees): Likewise.\n\t(grid_attr_trees): Likewise.\n\t(grid_create_kernel_launch_attr_types): Likewise.\n\t(grid_insert_store_range_dim): Likewise.\n\t(grid_get_kernel_launch_attributes): Likewise.\n\t(get_target_argument_identifier_1): Likewise.\n\t(get_target_argument_identifier): Likewise.\n\t(get_target_argument_value): Likewise.\n\t(push_target_argument_according_to_value): Likewise.\n\t(get_target_arguments): Likewise.\n\t(expand_omp_target): Likewise.\n\t(grid_expand_omp_for_loop): Moved to omp-grid.c.\n\t(grid_arg_decl_map): Likewise.\n\t(grid_remap_kernel_arg_accesses): Likewise.\n\t(grid_expand_target_grid_body): Likewise.\n\t(expand_omp): Renamed to omp_expand and moved to omp-expand.c.\n\t(build_omp_regions_1): Moved to omp-expand.c.\n\t(build_omp_regions_root): Likewise.\n\t(omp_expand_local): Likewise.\n\t(build_omp_regions): Likewise.\n\t(execute_expand_omp): Likewise.\n\t(pass_data_expand_omp): Likewise.\n\t(pass_expand_omp): Likewise.\n\t(make_pass_expand_omp): Likewise.\n\t(pass_data_expand_omp_ssa): Likewise.\n\t(pass_expand_omp_ssa): Likewise.\n\t(make_pass_expand_omp_ssa): Likewise.\n\t(grid_lastprivate_predicate): Renamed to\n\tomp_grid_lastprivate_predicate and moved to omp-grid.c, made public.\n\t(grid_prop): Moved to omp-grid.c.\n\t(GRID_MISSED_MSG_PREFIX): Likewise.\n\t(grid_safe_assignment_p): Likewise.\n\t(grid_seq_only_contains_local_assignments): Likewise.\n\t(grid_find_single_omp_among_assignments_1): Likewise.\n\t(grid_find_single_omp_among_assignments): Likewise.\n\t(grid_find_ungridifiable_statement): Likewise.\n\t(grid_parallel_clauses_gridifiable): Likewise.\n\t(grid_inner_loop_gridifiable_p): Likewise.\n\t(grid_dist_follows_simple_pattern): Likewise.\n\t(grid_gfor_follows_tiling_pattern): Likewise.\n\t(grid_call_permissible_in_distribute_p): Likewise.\n\t(grid_handle_call_in_distribute): Likewise.\n\t(grid_dist_follows_tiling_pattern): Likewise.\n\t(grid_target_follows_gridifiable_pattern): Likewise.\n\t(grid_remap_prebody_decls): Likewise.\n\t(grid_var_segment): Likewise.\n\t(grid_mark_variable_segment): Likewise.\n\t(grid_copy_leading_local_assignments): Likewise.\n\t(grid_process_grid_body): Likewise.\n\t(grid_eliminate_combined_simd_part): Likewise.\n\t(grid_mark_tiling_loops): Likewise.\n\t(grid_mark_tiling_parallels_and_loops): Likewise.\n\t(grid_process_kernel_body_copy): Likewise.\n\t(grid_attempt_target_gridification): Likewise.\n\t(grid_gridify_all_targets_stmt): Likewise.\n\t(grid_gridify_all_targets): Renamed to omp_grid_gridify_all_targets\n\tand moved to omp-grid.c, made public.\n\t(make_gimple_omp_edges): Renamed to omp_make_gimple_edges and moved to\n\tomp-expand.c.\n\t(add_decls_addresses_to_decl_constructor): Moved to omp-offload.c.\n\t(omp_finish_file): Likewise.\n\t(oacc_thread_numbers): Likewise.\n\t(oacc_xform_loop): Likewise.\n\t(oacc_default_dims, oacc_min_dims): Likewise.\n\t(oacc_parse_default_dims): Likewise.\n\t(oacc_validate_dims): Likewise.\n\t(new_oacc_loop_raw): Likewise.\n\t(new_oacc_loop_outer): Likewise.\n\t(new_oacc_loop): Likewise.\n\t(new_oacc_loop_routine): Likewise.\n\t(finish_oacc_loop): Likewise.\n\t(free_oacc_loop): Likewise.\n\t(dump_oacc_loop_part): Likewise.\n\t(dump_oacc_loop): Likewise.\n\t(debug_oacc_loop): Likewise.\n\t(oacc_loop_discover_walk): Likewise.\n\t(oacc_loop_sibling_nreverse): Likewise.\n\t(oacc_loop_discovery): Likewise.\n\t(oacc_loop_xform_head_tail): Likewise.\n\t(oacc_loop_xform_loop): Likewise.\n\t(oacc_loop_process): Likewise.\n\t(oacc_loop_fixed_partitions): Likewise.\n\t(oacc_loop_auto_partitions): Likewise.\n\t(oacc_loop_partition): Likewise.\n\t(default_goacc_fork_join): Likewise.\n\t(default_goacc_reduction): Likewise.\n\t(execute_oacc_device_lower): Likewise.\n\t(default_goacc_validate_dims): Likewise.\n\t(default_goacc_dim_limit): Likewise.\n\t(pass_data_oacc_device_lower): Likewise.\n\t(pass_oacc_device_lower): Likewise.\n\t(make_pass_oacc_device_lower): Likewise.\n\t(execute_omp_device_lower): Likewise.\n\t(pass_data_omp_device_lower): Likewise.\n\t(pass_omp_device_lower): Likewise.\n\t(make_pass_omp_device_lower): Likewise.\n\t(pass_data_omp_target_link): Likewise.\n\t(pass_omp_target_link): Likewise.\n\t(find_link_var_op): Likewise.\n\t(pass_omp_target_link::execute): Likewise.\n\t(make_pass_omp_target_link): Likewise.\n\n\t* Makefile.in (OBJS): Added omp-offload.o, omp-expand.o, omp-general.o\n\tand omp-grid.o.\n\t(GTFILES): Added omp-offload.h, omp-offload.c and omp-expand.c, removed\n\tomp-low.h.\n\t* gimple-fold.c: Include omp-general.h instead of omp-low.h.\n\t(fold_internal_goacc_dim): Adjusted calls to\n\tget_oacc_ifn_dim_arg and get_oacc_fn_dim_size to use their new names.\n\t* gimplify.c: Include omp-low.h.\n\t(omp_notice_variable): Adjust the call to get_oacc_fn_attrib to use\n\tits new name.\n\t(gimplify_omp_task): Adjusted calls to find_omp_clause to use its new\n\tname.\n\t(gimplify_omp_for): Likewise.\n\t* lto-cgraph.c: Include omp-offload.h instead of omp-low.h.\n\t* toplev.c: Include omp-offload.h instead of omp-low.h.\n\t* tree-cfg.c: Include omp-general.h instead of omp-low.h.  Also\n\tinclude omp-expand.h.\n\t(make_edges_bb): Adjusted the call to make_gimple_omp_edges to use its\n\tnew name.\n\t(make_edges): Adjust the call to free_omp_regions to use its new name.\n\t* tree-parloops.c: Include omp-general.h.\n\t(create_parallel_loop): Adjusted the call to set_oacc_fn_attrib to use\n\tits new name.\n\t(parallelize_loops): Adjusted the call to get_oacc_fn_attrib to use\n\tits new name.\n\t* tree-ssa-loop.c: Include omp-general.h instead of omp-low.h.\n\t(gate_oacc_kernels): Adjusted the call to get_oacc_fn_attrib to use\n\tits new name.\n\t* tree-vrp.c: Include omp-general.h instead of omp-low.h.\n\t(extract_range_basic): Adjusted calls to get_oacc_ifn_dim_arg and\n\tget_oacc_fn_dim_size to use their new names.\n\t* varpool.c: Include omp-offload.h instead of omp-low.h.\n\t* gengtype.c (open_base_files): Replace omp-low.h with omp-offload.h in\n\tifiles.\n\t* config/nvptx/nvptx.c: Include omp-general.c.\n\t(nvptx_expand_call): Adjusted the call to get_oacc_fn_attrib to use\n\tits new name.\n\t(nvptx_reorg): Likewise.\n\t(nvptx_record_offload_symbol): Likewise.\n\ngcc/c-family:\n\t* c-omp.c: Include omp-general.h instead of omp-low.h.\n\t(c_finish_oacc_wait): Adjusted call to find_omp_clause to use its new\n\tname.\n\ngcc/c/\n\t* c-parser.c: Include omp-general.h and omp-offload.h instead of\n\tomp-low.h.\n\t(c_finish_oacc_routine): Adjusted call to\n\tget_oacc_fn_attrib, build_oacc_routine_dims and replace_oacc_fn_attrib\n\tto use their new names.\n\t(c_parser_oacc_enter_exit_data): Adjusted call to find_omp_clause to\n\tuse its new name.\n\t(c_parser_oacc_update): Likewise.\n\t(c_parser_omp_simd): Likewise.\n\t(c_parser_omp_target_update): Likewise.\n\t* c-typeck.c: Include omp-general.h instead of omp-low.h.\n\t(c_finish_omp_cancel): Adjusted call to find_omp_clause to use its new\n\tname.\n\t(c_finish_omp_cancellation_point): Likewise.\n\t* gimple-parser.c: Do not include omp-low.h\n\ngcc/cp/\n\t* parser.c: Include omp-general.h and omp-offload.h instead of\n\tomp-low.h.\n\t(cp_parser_omp_simd): Adjusted calls to find_omp_clause to use its new\n\tname.\n\t(cp_parser_omp_target_update): Likewise.\n\t(cp_parser_oacc_declare): Likewise.\n\t(cp_parser_oacc_enter_exit_data): Likewise.\n\t(cp_parser_oacc_update): Likewise.\n\t(cp_finalize_oacc_routine): Adjusted call to get_oacc_fn_attrib,\n\tbuild_oacc_routine_dims and replace_oacc_fn_attrib to use their new\n\tnames.\n\t* semantics.c: Include omp-general insteda of omp-low.h.\n\t(finish_omp_for): Adjusted calls to find_omp_clause to use its new\n\tname.\n\t(finish_omp_cancel): Likewise.\n\t(finish_omp_cancellation_point): Likewise.\n\nfortran/\n\t* trans-openmp.c: Include omp-general.h.\n\nFrom-SVN: r243673", "tree": {"sha": "21a84ad4210bfa6213a06a75a3311f6c824b1b65", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/21a84ad4210bfa6213a06a75a3311f6c824b1b65"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/comments", "author": {"login": "jamborm", "id": 2180070, "node_id": "MDQ6VXNlcjIxODAwNzA=", "avatar_url": "https://avatars.githubusercontent.com/u/2180070?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamborm", "html_url": "https://github.com/jamborm", "followers_url": "https://api.github.com/users/jamborm/followers", "following_url": "https://api.github.com/users/jamborm/following{/other_user}", "gists_url": "https://api.github.com/users/jamborm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamborm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamborm/subscriptions", "organizations_url": "https://api.github.com/users/jamborm/orgs", "repos_url": "https://api.github.com/users/jamborm/repos", "events_url": "https://api.github.com/users/jamborm/events{/privacy}", "received_events_url": "https://api.github.com/users/jamborm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "cfce1a4a42a9f76477e732fbe7408459742a92a2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cfce1a4a42a9f76477e732fbe7408459742a92a2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cfce1a4a42a9f76477e732fbe7408459742a92a2"}], "stats": {"total": 30498, "additions": 15540, "deletions": 14958}, "files": [{"sha": "0afefdbd76c5b59b0bc7e4cfd150cb5ace9a4f6e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 275, "deletions": 0, "changes": 275, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -1,3 +1,278 @@\n+2016-12-14  Martin Jambor  <mjambor@suse.cz>\n+\n+\t* omp-general.h: New file.\n+\t* omp-general.c: New file.\n+\t* omp-expand.h: Likewise.\n+\t* omp-expand.c: Likewise.\n+\t* omp-offload.h: Likewise.\n+\t* omp-offload.c: Likewise.\n+\t* omp-grid.c: Likewise.\n+\t* omp-grid.c: Likewise.\n+\t* omp-low.h: Include omp-general.h and omp-grid.h.  Removed includes\n+\tof params.h, symbol-summary.h, lto-section-names.h, cilk.h, tree-eh.h,\n+\tipa-prop.h, tree-cfgcleanup.h, cfgloop.h, except.h, expr.h, stmt.h,\n+\tvarasm.h, calls.h, explow.h, dojump.h, flags.h, tree-into-ssa.h,\n+\ttree-cfg.h, cfganal.h, alias.h, emit-rtl.h, optabs.h, expmed.h,\n+\talloc-pool.h, cfghooks.h, rtl.h and memmodel.h.\n+\t(omp_find_combined_for): Declare.\n+\t(find_omp_clause): Renamed to omp_find_clause and moved to\n+\tomp-general.h.\n+\t(free_omp_regions): Renamed to omp_free_regions and moved to\n+\tomp-expand.h.\n+\t(replace_oacc_fn_attrib): Renamed to oacc_replace_fn_attrib and moved\n+\tto omp-general.h.\n+\t(set_oacc_fn_attrib): Renamed to oacc_set_fn_attrib and moved to\n+\tomp-general.h.\n+\t(build_oacc_routine_dims): Renamed to oacc_build_routine_dims and\n+\tmoved to omp-general.h.\n+\t(get_oacc_fn_attrib): Renamed to oacc_get_fn_attrib and moved to\n+\tomp-general.h.\n+\t(oacc_fn_attrib_kernels_p): Moved to omp-general.h.\n+\t(get_oacc_fn_dim_size): Renamed to oacc_get_fn_dim_size and moved to\n+\tomp-general.c.\n+\t(omp_expand_local): Moved to omp-expand.h.\n+\t(make_gimple_omp_edges): Renamed to omp_make_gimple_edges and moved to\n+\tomp-expand.h.\n+\t(omp_finish_file): Moved to omp-offload.h.\n+\t(default_goacc_validate_dims): Renamed to\n+\toacc_default_goacc_validate_dims and moved to omp-offload.h.\n+\t(offload_funcs, offload_vars): Moved to omp-offload.h.\n+\t* omp-low.c: Include omp-general.h, omp-offload.h and omp-grid.h.\n+\t(omp_region): Moved to omp-expand.c.\n+\t(omp_for_data_loop): Moved to omp-general.h.\n+\t(omp_for_data): Likewise.\n+\t(oacc_loop): Moved to omp-offload.c.\n+\t(oacc_loop_flags): Moved to omp-general.h.\n+\t(offload_funcs, offload_vars): Moved to omp-offload.c.\n+\t(root_omp_region): Moved to omp-expand.c.\n+\t(omp_any_child_fn_dumped): Likewise.\n+\t(find_omp_clause): Renamed to omp_find_clause and moved to\n+\tomp-general.c.\n+\t(is_combined_parallel): Moved to omp-expand.c.\n+\t(is_reference): Renamed to omp_is_reference and and moved to\n+\tomp-general.c.\n+\t(adjust_for_condition): Renamed to omp_adjust_for_condition and moved\n+\tto omp-general.c.\n+\t(get_omp_for_step_from_incr): Renamed to omp_get_for_step_from_incr\n+\tand moved to omp-general.c.\n+\t(extract_omp_for_data): Renamed to omp_extract_for_data and moved to\n+\tomp-general.c.\n+\t(workshare_safe_to_combine_p): Moved to omp-expand.c.\n+\t(omp_adjust_chunk_size): Likewise.\n+\t(get_ws_args_for): Likewise.\n+\t(get_base_type): Removed.\n+\t(dump_omp_region): Moved to omp-expand.c.\n+\t(debug_omp_region): Likewise.\n+\t(debug_all_omp_regions): Likewise.\n+\t(new_omp_region): Likewise.\n+\t(free_omp_region_1): Likewise.\n+\t(free_omp_regions): Renamed to omp_free_regions and moved to\n+\tomp-expand.c.\n+\t(find_combined_for): Renamed to omp_find_combined_for, made global.\n+\t(build_omp_barrier): Renamed to omp_build_barrier and moved to\n+\tomp-general.c.\n+\t(omp_max_vf): Moved to omp-general.c.\n+\t(omp_max_simt_vf): Likewise.\n+\t(gimple_build_cond_empty): Moved to omp-expand.c.\n+\t(parallel_needs_hsa_kernel_p): Likewise.\n+\t(expand_omp_build_assign): Moved declaration to omp-expand.c.\n+\t(expand_parallel_call): Moved to omp-expand.c.\n+\t(expand_cilk_for_call): Likewise.\n+\t(expand_task_call): Likewise.\n+\t(vec2chain): Likewise.\n+\t(remove_exit_barrier): Likewise.\n+\t(remove_exit_barriers): Likewise.\n+\t(optimize_omp_library_calls): Likewise.\n+\t(expand_omp_regimplify_p): Likewise.\n+\t(expand_omp_build_assign): Likewise.\n+\t(expand_omp_taskreg): Likewise.\n+\t(oacc_collapse): Likewise.\n+\t(expand_oacc_collapse_init): Likewise.\n+\t(expand_oacc_collapse_vars): Likewise.\n+\t(expand_omp_for_init_counts): Likewise.\n+\t(expand_omp_for_init_vars): Likewise.\n+\t(extract_omp_for_update_vars): Likewise.\n+\t(expand_omp_ordered_source): Likewise.\n+\t(expand_omp_ordered_sink): Likewise.\n+\t(expand_omp_ordered_source_sink): Likewise.\n+\t(expand_omp_for_ordered_loops): Likewise.\n+\t(expand_omp_for_generic): Likewise.\n+\t(expand_omp_for_static_nochunk): Likewise.\n+\t(find_phi_with_arg_on_edge): Likewise.\n+\t(expand_omp_for_static_chunk): Likewise.\n+\t(expand_cilk_for): Likewise.\n+\t(expand_omp_simd): Likewise.\n+\t(expand_omp_taskloop_for_outer): Likewise.\n+\t(expand_omp_taskloop_for_inner): Likewise.\n+\t(expand_oacc_for): Likewise.\n+\t(expand_omp_for): Likewise.\n+\t(expand_omp_sections): Likewise.\n+\t(expand_omp_single): Likewise.\n+\t(expand_omp_synch): Likewise.\n+\t(expand_omp_atomic_load): Likewise.\n+\t(expand_omp_atomic_store): Likewise.\n+\t(expand_omp_atomic_fetch_op): Likewise.\n+\t(expand_omp_atomic_pipeline): Likewise.\n+\t(expand_omp_atomic_mutex): Likewise.\n+\t(expand_omp_atomic): Likewise.\n+\t(oacc_launch_pack): and moved to omp-general.c, made public.\n+\t(OACC_FN_ATTRIB): Likewise.\n+\t(replace_oacc_fn_attrib): Renamed to oacc_replace_fn_attrib and moved\n+\tto omp-general.c.\n+\t(set_oacc_fn_attrib): Renamed to oacc_set_fn_attrib and moved to\n+\tomp-general.c.\n+\t(build_oacc_routine_dims): Renamed to oacc_build_routine_dims and\n+\tmoved to omp-general.c.\n+\t(get_oacc_fn_attrib): Renamed to oacc_get_fn_attrib and moved to\n+\tomp-general.c.\n+\t(oacc_fn_attrib_kernels_p): Moved to omp-general.c.\n+\t(oacc_fn_attrib_level): Moved to omp-offload.c.\n+\t(get_oacc_fn_dim_size): Renamed to oacc_get_fn_dim_size and moved to\n+\tomp-general.c.\n+\t(get_oacc_ifn_dim_arg): Renamed to oacc_get_ifn_dim_arg and moved to\n+\tomp-general.c.\n+\t(mark_loops_in_oacc_kernels_region): Moved to omp-expand.c.\n+\t(grid_launch_attributes_trees): Likewise.\n+\t(grid_attr_trees): Likewise.\n+\t(grid_create_kernel_launch_attr_types): Likewise.\n+\t(grid_insert_store_range_dim): Likewise.\n+\t(grid_get_kernel_launch_attributes): Likewise.\n+\t(get_target_argument_identifier_1): Likewise.\n+\t(get_target_argument_identifier): Likewise.\n+\t(get_target_argument_value): Likewise.\n+\t(push_target_argument_according_to_value): Likewise.\n+\t(get_target_arguments): Likewise.\n+\t(expand_omp_target): Likewise.\n+\t(grid_expand_omp_for_loop): Moved to omp-grid.c.\n+\t(grid_arg_decl_map): Likewise.\n+\t(grid_remap_kernel_arg_accesses): Likewise.\n+\t(grid_expand_target_grid_body): Likewise.\n+\t(expand_omp): Renamed to omp_expand and moved to omp-expand.c.\n+\t(build_omp_regions_1): Moved to omp-expand.c.\n+\t(build_omp_regions_root): Likewise.\n+\t(omp_expand_local): Likewise.\n+\t(build_omp_regions): Likewise.\n+\t(execute_expand_omp): Likewise.\n+\t(pass_data_expand_omp): Likewise.\n+\t(pass_expand_omp): Likewise.\n+\t(make_pass_expand_omp): Likewise.\n+\t(pass_data_expand_omp_ssa): Likewise.\n+\t(pass_expand_omp_ssa): Likewise.\n+\t(make_pass_expand_omp_ssa): Likewise.\n+\t(grid_lastprivate_predicate): Renamed to\n+\tomp_grid_lastprivate_predicate and moved to omp-grid.c, made public.\n+\t(grid_prop): Moved to omp-grid.c.\n+\t(GRID_MISSED_MSG_PREFIX): Likewise.\n+\t(grid_safe_assignment_p): Likewise.\n+\t(grid_seq_only_contains_local_assignments): Likewise.\n+\t(grid_find_single_omp_among_assignments_1): Likewise.\n+\t(grid_find_single_omp_among_assignments): Likewise.\n+\t(grid_find_ungridifiable_statement): Likewise.\n+\t(grid_parallel_clauses_gridifiable): Likewise.\n+\t(grid_inner_loop_gridifiable_p): Likewise.\n+\t(grid_dist_follows_simple_pattern): Likewise.\n+\t(grid_gfor_follows_tiling_pattern): Likewise.\n+\t(grid_call_permissible_in_distribute_p): Likewise.\n+\t(grid_handle_call_in_distribute): Likewise.\n+\t(grid_dist_follows_tiling_pattern): Likewise.\n+\t(grid_target_follows_gridifiable_pattern): Likewise.\n+\t(grid_remap_prebody_decls): Likewise.\n+\t(grid_var_segment): Likewise.\n+\t(grid_mark_variable_segment): Likewise.\n+\t(grid_copy_leading_local_assignments): Likewise.\n+\t(grid_process_grid_body): Likewise.\n+\t(grid_eliminate_combined_simd_part): Likewise.\n+\t(grid_mark_tiling_loops): Likewise.\n+\t(grid_mark_tiling_parallels_and_loops): Likewise.\n+\t(grid_process_kernel_body_copy): Likewise.\n+\t(grid_attempt_target_gridification): Likewise.\n+\t(grid_gridify_all_targets_stmt): Likewise.\n+\t(grid_gridify_all_targets): Renamed to omp_grid_gridify_all_targets\n+\tand moved to omp-grid.c, made public.\n+\t(make_gimple_omp_edges): Renamed to omp_make_gimple_edges and moved to\n+\tomp-expand.c.\n+\t(add_decls_addresses_to_decl_constructor): Moved to omp-offload.c.\n+\t(omp_finish_file): Likewise.\n+\t(oacc_thread_numbers): Likewise.\n+\t(oacc_xform_loop): Likewise.\n+\t(oacc_default_dims, oacc_min_dims): Likewise.\n+\t(oacc_parse_default_dims): Likewise.\n+\t(oacc_validate_dims): Likewise.\n+\t(new_oacc_loop_raw): Likewise.\n+\t(new_oacc_loop_outer): Likewise.\n+\t(new_oacc_loop): Likewise.\n+\t(new_oacc_loop_routine): Likewise.\n+\t(finish_oacc_loop): Likewise.\n+\t(free_oacc_loop): Likewise.\n+\t(dump_oacc_loop_part): Likewise.\n+\t(dump_oacc_loop): Likewise.\n+\t(debug_oacc_loop): Likewise.\n+\t(oacc_loop_discover_walk): Likewise.\n+\t(oacc_loop_sibling_nreverse): Likewise.\n+\t(oacc_loop_discovery): Likewise.\n+\t(oacc_loop_xform_head_tail): Likewise.\n+\t(oacc_loop_xform_loop): Likewise.\n+\t(oacc_loop_process): Likewise.\n+\t(oacc_loop_fixed_partitions): Likewise.\n+\t(oacc_loop_auto_partitions): Likewise.\n+\t(oacc_loop_partition): Likewise.\n+\t(default_goacc_fork_join): Likewise.\n+\t(default_goacc_reduction): Likewise.\n+\t(execute_oacc_device_lower): Likewise.\n+\t(default_goacc_validate_dims): Likewise.\n+\t(default_goacc_dim_limit): Likewise.\n+\t(pass_data_oacc_device_lower): Likewise.\n+\t(pass_oacc_device_lower): Likewise.\n+\t(make_pass_oacc_device_lower): Likewise.\n+\t(execute_omp_device_lower): Likewise.\n+\t(pass_data_omp_device_lower): Likewise.\n+\t(pass_omp_device_lower): Likewise.\n+\t(make_pass_omp_device_lower): Likewise.\n+\t(pass_data_omp_target_link): Likewise.\n+\t(pass_omp_target_link): Likewise.\n+\t(find_link_var_op): Likewise.\n+\t(pass_omp_target_link::execute): Likewise.\n+\t(make_pass_omp_target_link): Likewise.\n+\t* Makefile.in (OBJS): Added omp-offload.o, omp-expand.o, omp-general.o\n+\tand omp-grid.o.\n+\t(GTFILES): Added omp-offload.h, omp-offload.c and omp-expand.c, removed\n+\tomp-low.h.\n+\t* gimple-fold.c: Include omp-general.h instead of omp-low.h.\n+\t(fold_internal_goacc_dim): Adjusted calls to\n+\tget_oacc_ifn_dim_arg and get_oacc_fn_dim_size to use their new names.\n+\t* gimplify.c: Include omp-low.h.\n+\t(omp_notice_variable): Adjust the call to get_oacc_fn_attrib to use\n+\tits new name.\n+\t(gimplify_omp_task): Adjusted calls to find_omp_clause to use its new\n+\tname.\n+\t(gimplify_omp_for): Likewise.\n+\t* lto-cgraph.c: Include omp-offload.h instead of omp-low.h.\n+\t* toplev.c: Include omp-offload.h instead of omp-low.h.\n+\t* tree-cfg.c: Include omp-general.h instead of omp-low.h.  Also\n+\tinclude omp-expand.h.\n+\t(make_edges_bb): Adjusted the call to make_gimple_omp_edges to use its\n+\tnew name.\n+\t(make_edges): Adjust the call to free_omp_regions to use its new name.\n+\t* tree-parloops.c: Include omp-general.h.\n+\t(create_parallel_loop): Adjusted the call to set_oacc_fn_attrib to use\n+\tits new name.\n+\t(parallelize_loops): Adjusted the call to get_oacc_fn_attrib to use\n+\tits new name.\n+\t* tree-ssa-loop.c: Include omp-general.h instead of omp-low.h.\n+\t(gate_oacc_kernels): Adjusted the call to get_oacc_fn_attrib to use\n+\tits new name.\n+\t* tree-vrp.c: Include omp-general.h instead of omp-low.h.\n+\t(extract_range_basic): Adjusted calls to get_oacc_ifn_dim_arg and\n+\tget_oacc_fn_dim_size to use their new names.\n+\t* varpool.c: Include omp-offload.h instead of omp-low.h.\n+\t* gengtype.c (open_base_files): Replace omp-low.h with omp-offload.h in\n+\tifiles.\n+\t* config/nvptx/nvptx.c: Include omp-general.c.\n+\t(nvptx_expand_call): Adjusted the call to get_oacc_fn_attrib to use\n+\tits new name.\n+\t(nvptx_reorg): Likewise.\n+\t(nvptx_record_offload_symbol): Likewise.\n+\n 2016-12-14  Martin Sebor  <msebor@redhat.com>\n \n \tPR middle-end/78786"}, {"sha": "f2c7cd017d4c42928840b0309e98cfb62be36539", "filename": "gcc/Makefile.in", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -1399,6 +1399,10 @@ OBJS = \\\n \tmode-switching.o \\\n \tmodulo-sched.o \\\n \tmultiple_target.o \\\n+\tomp-offload.o \\\n+\tomp-expand.o \\\n+\tomp-general.o \\\n+\tomp-grid.o \\\n \tomp-low.o \\\n \tomp-simd-clone.o \\\n \toptabs.o \\\n@@ -2479,8 +2483,10 @@ GTFILES = $(CPP_ID_DATA_H) $(srcdir)/input.h $(srcdir)/coretypes.h \\\n   $(srcdir)/tree-scalar-evolution.c \\\n   $(srcdir)/tree-ssa-operands.h \\\n   $(srcdir)/tree-profile.c $(srcdir)/tree-nested.c \\\n+  $(srcdir)/omp-offload.h \\\n+  $(srcdir)/omp-offload.c \\\n+  $(srcdir)/omp-expand.c \\\n   $(srcdir)/omp-low.c \\\n-  $(srcdir)/omp-low.h \\\n   $(srcdir)/targhooks.c $(out_file) $(srcdir)/passes.c $(srcdir)/cgraphunit.c \\\n   $(srcdir)/cgraphclones.c \\\n   $(srcdir)/tree-phinodes.c \\"}, {"sha": "d8bd2c383f994a4d224c49332f3a86bdaade0ccd", "filename": "gcc/c-family/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc-family%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc-family%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2FChangeLog?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -1,3 +1,9 @@\n+2016-12-14  Martin Jambor  <mjambor@suse.cz>\n+\n+\t* c-omp.c: Include omp-general.h instead of omp-low.h.\n+\t(c_finish_oacc_wait): Adjusted call to find_omp_clause to use its new\n+\tname.\n+\n 2016-12-14  Martin Sebor  <msebor@redhat.com>\n \n \tPR c/17308"}, {"sha": "2b5ad04eb5fe706097578884991347329c5c17c2", "filename": "gcc/c-family/c-omp.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc-family%2Fc-omp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc-family%2Fc-omp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-omp.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -28,7 +28,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"c-common.h\"\n #include \"gimple-expr.h\"\n #include \"c-pragma.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n #include \"gomp-constants.h\"\n \n \n@@ -45,7 +45,7 @@ c_finish_oacc_wait (location_t loc, tree parms, tree clauses)\n   vec_alloc (args, nparms + 2);\n   stmt = builtin_decl_explicit (BUILT_IN_GOACC_WAIT);\n \n-  if (find_omp_clause (clauses, OMP_CLAUSE_ASYNC))\n+  if (omp_find_clause (clauses, OMP_CLAUSE_ASYNC))\n     t = OMP_CLAUSE_ASYNC_EXPR (clauses);\n   else\n     t = build_int_cst (integer_type_node, GOMP_ASYNC_SYNC);"}, {"sha": "d10faa08c7f30e97e38c2dfec735c8ef3cbfe187", "filename": "gcc/c/ChangeLog", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2FChangeLog?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -1,3 +1,21 @@\n+2016-12-14  Martin Jambor  <mjambor@suse.cz>\n+\n+\t* c-parser.c: Include omp-general.h and omp-offload.h instead of\n+\tomp-low.h.\n+\t(c_finish_oacc_routine): Adjusted call to\n+\tget_oacc_fn_attrib, build_oacc_routine_dims and replace_oacc_fn_attrib\n+\tto use their new names.\n+\t(c_parser_oacc_enter_exit_data): Adjusted call to find_omp_clause to\n+\tuse its new name.\n+\t(c_parser_oacc_update): Likewise.\n+\t(c_parser_omp_simd): Likewise.\n+\t(c_parser_omp_target_update): Likewise.\n+\t* c-typeck.c: Include omp-general.h instead of omp-low.h.\n+\t(c_finish_omp_cancel): Adjusted call to find_omp_clause to use its new\n+\tname.\n+\t(c_finish_omp_cancellation_point): Likewise.\n+\t* gimple-parser.c: Do not include omp-low.h\n+\n 2016-12-02  Cesar Philippidis  <cesar@codesourcery.com>\n \t    James Norris  <jnorris@codesourcery.com>\n "}, {"sha": "a775b6064f677314dea05a7e63a17edf87c133cb", "filename": "gcc/c/c-parser.c", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2Fc-parser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2Fc-parser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2Fc-parser.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -52,7 +52,8 @@ along with GCC; see the file COPYING3.  If not see\n #include \"c-lang.h\"\n #include \"c-family/c-objc.h\"\n #include \"plugin.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n+#include \"omp-offload.h\"\n #include \"builtins.h\"\n #include \"gomp-constants.h\"\n #include \"c-family/c-indentation.h\"\n@@ -13922,7 +13923,7 @@ c_parser_oacc_enter_exit_data (c_parser *parser, bool enter)\n     clauses = c_parser_oacc_all_clauses (parser, OACC_EXIT_DATA_CLAUSE_MASK,\n \t\t\t\t\t \"#pragma acc exit data\");\n \n-  if (find_omp_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n+  if (omp_find_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n     {\n       error_at (loc, enter\n \t\t? \"%<#pragma acc enter data%> has no data movement clause\"\n@@ -14241,7 +14242,7 @@ c_finish_oacc_routine (struct oacc_routine_data *data, tree fndecl,\n       return;\n     }\n \n-  if (get_oacc_fn_attrib (fndecl))\n+  if (oacc_get_fn_attrib (fndecl))\n     {\n       error_at (data->loc,\n \t\t\"%<#pragma acc routine%> already applied to %qD\", fndecl);\n@@ -14259,8 +14260,8 @@ c_finish_oacc_routine (struct oacc_routine_data *data, tree fndecl,\n     }\n \n   /* Process the routine's dimension clauses.  */\n-  tree dims = build_oacc_routine_dims (data->clauses);\n-  replace_oacc_fn_attrib (fndecl, dims);\n+  tree dims = oacc_build_routine_dims (data->clauses);\n+  oacc_replace_fn_attrib (fndecl, dims);\n \n   /* Add an \"omp declare target\" attribute.  */\n   DECL_ATTRIBUTES (fndecl)\n@@ -14292,7 +14293,7 @@ c_parser_oacc_update (c_parser *parser)\n \n   tree clauses = c_parser_oacc_all_clauses (parser, OACC_UPDATE_CLAUSE_MASK,\n \t\t\t\t\t    \"#pragma acc update\");\n-  if (find_omp_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n+  if (omp_find_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n     {\n       error_at (loc,\n \t\t\"%<#pragma acc update%> must contain at least one \"\n@@ -15263,7 +15264,7 @@ c_parser_omp_simd (location_t loc, c_parser *parser,\n     {\n       omp_split_clauses (loc, OMP_SIMD, mask, clauses, cclauses);\n       clauses = cclauses[C_OMP_CLAUSE_SPLIT_SIMD];\n-      tree c = find_omp_clause (cclauses[C_OMP_CLAUSE_SPLIT_FOR],\n+      tree c = omp_find_clause (cclauses[C_OMP_CLAUSE_SPLIT_FOR],\n \t\t\t\tOMP_CLAUSE_ORDERED);\n       if (c && OMP_CLAUSE_ORDERED_EXPR (c))\n \t{\n@@ -16107,8 +16108,8 @@ c_parser_omp_target_update (location_t loc, c_parser *parser,\n   tree clauses\n     = c_parser_omp_all_clauses (parser, OMP_TARGET_UPDATE_CLAUSE_MASK,\n \t\t\t\t\"#pragma omp target update\");\n-  if (find_omp_clause (clauses, OMP_CLAUSE_TO) == NULL_TREE\n-      && find_omp_clause (clauses, OMP_CLAUSE_FROM) == NULL_TREE)\n+  if (omp_find_clause (clauses, OMP_CLAUSE_TO) == NULL_TREE\n+      && omp_find_clause (clauses, OMP_CLAUSE_FROM) == NULL_TREE)\n     {\n       error_at (loc,\n \t\t\"%<#pragma omp target update%> must contain at least one \""}, {"sha": "c134280325dab079a61bdd15b38295cecc7d32ba", "filename": "gcc/c/c-typeck.c", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2Fc-typeck.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2Fc-typeck.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2Fc-typeck.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -43,7 +43,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-iterator.h\"\n #include \"gimplify.h\"\n #include \"tree-inline.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n #include \"c-family/c-objc.h\"\n #include \"c-family/c-ubsan.h\"\n #include \"cilk.h\"\n@@ -12012,13 +12012,13 @@ c_finish_omp_cancel (location_t loc, tree clauses)\n {\n   tree fn = builtin_decl_explicit (BUILT_IN_GOMP_CANCEL);\n   int mask = 0;\n-  if (find_omp_clause (clauses, OMP_CLAUSE_PARALLEL))\n+  if (omp_find_clause (clauses, OMP_CLAUSE_PARALLEL))\n     mask = 1;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_FOR))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_FOR))\n     mask = 2;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_SECTIONS))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_SECTIONS))\n     mask = 4;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_TASKGROUP))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_TASKGROUP))\n     mask = 8;\n   else\n     {\n@@ -12027,7 +12027,7 @@ c_finish_omp_cancel (location_t loc, tree clauses)\n \t\t     \"clauses\");\n       return;\n     }\n-  tree ifc = find_omp_clause (clauses, OMP_CLAUSE_IF);\n+  tree ifc = omp_find_clause (clauses, OMP_CLAUSE_IF);\n   if (ifc != NULL_TREE)\n     {\n       tree type = TREE_TYPE (OMP_CLAUSE_IF_EXPR (ifc));\n@@ -12051,13 +12051,13 @@ c_finish_omp_cancellation_point (location_t loc, tree clauses)\n {\n   tree fn = builtin_decl_explicit (BUILT_IN_GOMP_CANCELLATION_POINT);\n   int mask = 0;\n-  if (find_omp_clause (clauses, OMP_CLAUSE_PARALLEL))\n+  if (omp_find_clause (clauses, OMP_CLAUSE_PARALLEL))\n     mask = 1;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_FOR))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_FOR))\n     mask = 2;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_SECTIONS))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_SECTIONS))\n     mask = 4;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_TASKGROUP))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_TASKGROUP))\n     mask = 8;\n   else\n     {"}, {"sha": "ddecaec512817b3dd7e18d56be5c0d30dbd2cfaa", "filename": "gcc/c/gimple-parser.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2Fgimple-parser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fc%2Fgimple-parser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2Fgimple-parser.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -34,7 +34,6 @@ along with GCC; see the file COPYING3.  If not see\n #include \"c-lang.h\"\n #include \"c-family/c-objc.h\"\n #include \"plugin.h\"\n-#include \"omp-low.h\"\n #include \"builtins.h\"\n #include \"gomp-constants.h\"\n #include \"c-family/c-indentation.h\""}, {"sha": "17fe5518a86847c2842a3dacc63290405f8d54b1", "filename": "gcc/config/nvptx/nvptx.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fconfig%2Fnvptx%2Fnvptx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fconfig%2Fnvptx%2Fnvptx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnvptx%2Fnvptx.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -55,6 +55,7 @@\n #include \"gimple.h\"\n #include \"stor-layout.h\"\n #include \"builtins.h\"\n+#include \"omp-general.h\"\n #include \"omp-low.h\"\n #include \"gomp-constants.h\"\n #include \"dumpfile.h\"\n@@ -1389,7 +1390,7 @@ nvptx_expand_call (rtx retval, rtx address)\n \t  if (DECL_STATIC_CHAIN (decl))\n \t    cfun->machine->has_chain = true;\n \n-\t  tree attr = get_oacc_fn_attrib (decl);\n+\t  tree attr = oacc_get_fn_attrib (decl);\n \t  if (attr)\n \t    {\n \t      tree dims = TREE_VALUE (attr);\n@@ -4090,7 +4091,7 @@ nvptx_reorg (void)\n   /* Determine launch dimensions of the function.  If it is not an\n      offloaded function  (i.e. this is a regular compiler), the\n      function has no neutering.  */\n-  tree attr = get_oacc_fn_attrib (current_function_decl);\n+  tree attr = oacc_get_fn_attrib (current_function_decl);\n   if (attr)\n     {\n       /* If we determined this mask before RTL expansion, we could\n@@ -4243,7 +4244,7 @@ nvptx_record_offload_symbol (tree decl)\n \n     case FUNCTION_DECL:\n       {\n-\ttree attr = get_oacc_fn_attrib (decl);\n+\ttree attr = oacc_get_fn_attrib (decl);\n \t/* OpenMP offloading does not set this attribute.  */\n \ttree dims = attr ? TREE_VALUE (attr) : NULL_TREE;\n "}, {"sha": "60b514b389c1dc2d2d23619df9c486f60555228e", "filename": "gcc/cp/ChangeLog", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fcp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fcp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2FChangeLog?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -1,3 +1,22 @@\n+2016-12-14  Martin Jambor  <mjambor@suse.cz>\n+\n+\t* parser.c: Include omp-general.h and omp-offload.h instead of\n+\tomp-low.h.\n+\t(cp_parser_omp_simd): Adjusted calls to find_omp_clause to use its new\n+\tname.\n+\t(cp_parser_omp_target_update): Likewise.\n+\t(cp_parser_oacc_declare): Likewise.\n+\t(cp_parser_oacc_enter_exit_data): Likewise.\n+\t(cp_parser_oacc_update): Likewise.\n+\t(cp_finalize_oacc_routine): Adjusted call to get_oacc_fn_attrib,\n+\tbuild_oacc_routine_dims and replace_oacc_fn_attrib to use their new\n+\tnames.\n+\t* semantics.c: Include omp-general insteda of omp-low.h.\n+\t(finish_omp_for): Adjusted calls to find_omp_clause to use its new\n+\tname.\n+\t(finish_omp_cancel): Likewise.\n+\t(finish_omp_cancellation_point): Likewise.\n+\n 2016-12-14  Marek Polacek  <polacek@redhat.com>\n \n \tPR c++/72775"}, {"sha": "e2a0a4994500439655b1510c213e4b86bf1b0828", "filename": "gcc/cp/parser.c", "status": "modified", "additions": 12, "deletions": 11, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fcp%2Fparser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fcp%2Fparser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fparser.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -35,8 +35,9 @@ along with GCC; see the file COPYING3.  If not see\n #include \"plugin.h\"\n #include \"tree-pretty-print.h\"\n #include \"parser.h\"\n-#include \"omp-low.h\"\n #include \"gomp-constants.h\"\n+#include \"omp-general.h\"\n+#include \"omp-offload.h\"\n #include \"c-family/c-indentation.h\"\n #include \"context.h\"\n #include \"cp-cilkplus.h\"\n@@ -34675,7 +34676,7 @@ cp_parser_omp_simd (cp_parser *parser, cp_token *pragma_tok,\n     {\n       cp_omp_split_clauses (loc, OMP_SIMD, mask, clauses, cclauses);\n       clauses = cclauses[C_OMP_CLAUSE_SPLIT_SIMD];\n-      tree c = find_omp_clause (cclauses[C_OMP_CLAUSE_SPLIT_FOR],\n+      tree c = omp_find_clause (cclauses[C_OMP_CLAUSE_SPLIT_FOR],\n \t\t\t\tOMP_CLAUSE_ORDERED);\n       if (c && OMP_CLAUSE_ORDERED_EXPR (c))\n \t{\n@@ -35703,8 +35704,8 @@ cp_parser_omp_target_update (cp_parser *parser, cp_token *pragma_tok,\n   tree clauses\n     = cp_parser_omp_all_clauses (parser, OMP_TARGET_UPDATE_CLAUSE_MASK,\n \t\t\t\t \"#pragma omp target update\", pragma_tok);\n-  if (find_omp_clause (clauses, OMP_CLAUSE_TO) == NULL_TREE\n-      && find_omp_clause (clauses, OMP_CLAUSE_FROM) == NULL_TREE)\n+  if (omp_find_clause (clauses, OMP_CLAUSE_TO) == NULL_TREE\n+      && omp_find_clause (clauses, OMP_CLAUSE_FROM) == NULL_TREE)\n     {\n       error_at (pragma_tok->location,\n \t\t\"%<#pragma omp target update%> must contain at least one \"\n@@ -36038,7 +36039,7 @@ cp_parser_oacc_declare (cp_parser *parser, cp_token *pragma_tok)\n \t\t\t\t\t\"#pragma acc declare\", pragma_tok, true);\n \n \n-  if (find_omp_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n+  if (omp_find_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n     {\n       error_at (pragma_tok->location,\n \t\t\"no valid clauses specified in %<#pragma acc declare%>\");\n@@ -36211,7 +36212,7 @@ cp_parser_oacc_enter_exit_data (cp_parser *parser, cp_token *pragma_tok,\n     clauses = cp_parser_oacc_all_clauses (parser, OACC_EXIT_DATA_CLAUSE_MASK,\n \t\t\t\t\t \"#pragma acc exit data\", pragma_tok);\n \n-  if (find_omp_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n+  if (omp_find_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n     {\n       error_at (loc, \"%<#pragma acc %s data%> has no data movement clause\",\n \t\tenter ? \"enter\" : \"exit\");\n@@ -36385,7 +36386,7 @@ cp_parser_oacc_update (cp_parser *parser, cp_token *pragma_tok)\n   clauses = cp_parser_oacc_all_clauses (parser, OACC_UPDATE_CLAUSE_MASK,\n \t\t\t\t\t \"#pragma acc update\", pragma_tok);\n \n-  if (find_omp_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n+  if (omp_find_clause (clauses, OMP_CLAUSE_MAP) == NULL_TREE)\n     {\n       error_at (pragma_tok->location,\n \t\t\"%<#pragma acc update%> must contain at least one \"\n@@ -37461,7 +37462,7 @@ cp_finalize_oacc_routine (cp_parser *parser, tree fndecl, bool is_defn)\n \t  return;\n \t}\n \n-      if (get_oacc_fn_attrib (fndecl))\n+      if (oacc_get_fn_attrib (fndecl))\n \t{\n \t  error_at (parser->oacc_routine->loc,\n \t\t    \"%<#pragma acc routine%> already applied to %qD\", fndecl);\n@@ -37479,9 +37480,9 @@ cp_finalize_oacc_routine (cp_parser *parser, tree fndecl, bool is_defn)\n \t}\n \n       /* Process the routine's dimension clauses.  */\n-      tree dims = build_oacc_routine_dims (parser->oacc_routine->clauses);\n-      replace_oacc_fn_attrib (fndecl, dims);\n-      \n+      tree dims = oacc_build_routine_dims (parser->oacc_routine->clauses);\n+      oacc_replace_fn_attrib (fndecl, dims);\n+\n       /* Add an \"omp declare target\" attribute.  */\n       DECL_ATTRIBUTES (fndecl)\n \t= tree_cons (get_identifier (\"omp declare target\"),"}, {"sha": "a41bc73ed308afc65574e61a342861b9eea4c4e5", "filename": "gcc/cp/semantics.c", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fcp%2Fsemantics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fcp%2Fsemantics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fsemantics.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -38,7 +38,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-inline.h\"\n #include \"intl.h\"\n #include \"tree-iterator.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n #include \"convert.h\"\n #include \"gomp-constants.h\"\n \n@@ -8001,7 +8001,7 @@ finish_omp_for (location_t locus, enum tree_code code, tree declv,\n   gcc_assert (TREE_VEC_LENGTH (declv) == TREE_VEC_LENGTH (incrv));\n   if (TREE_VEC_LENGTH (declv) > 1)\n     {\n-      tree c = find_omp_clause (clauses, OMP_CLAUSE_COLLAPSE);\n+      tree c = omp_find_clause (clauses, OMP_CLAUSE_COLLAPSE);\n       if (c)\n \tcollapse = tree_to_shwi (OMP_CLAUSE_COLLAPSE_EXPR (c));\n       if (collapse != TREE_VEC_LENGTH (declv))\n@@ -8264,8 +8264,8 @@ finish_omp_for (location_t locus, enum tree_code code, tree declv,\n      step at this point, fill it in.  */\n   if (code == OMP_SIMD && !processing_template_decl\n       && TREE_VEC_LENGTH (OMP_FOR_INCR (omp_for)) == 1)\n-    for (tree c = find_omp_clause (clauses, OMP_CLAUSE_LINEAR); c;\n-\t c = find_omp_clause (OMP_CLAUSE_CHAIN (c), OMP_CLAUSE_LINEAR))\n+    for (tree c = omp_find_clause (clauses, OMP_CLAUSE_LINEAR); c;\n+\t c = omp_find_clause (OMP_CLAUSE_CHAIN (c), OMP_CLAUSE_LINEAR))\n       if (OMP_CLAUSE_LINEAR_STEP (c) == NULL_TREE)\n \t{\n \t  decl = TREE_OPERAND (TREE_VEC_ELT (OMP_FOR_INIT (omp_for), 0), 0);\n@@ -8586,13 +8586,13 @@ finish_omp_cancel (tree clauses)\n {\n   tree fn = builtin_decl_explicit (BUILT_IN_GOMP_CANCEL);\n   int mask = 0;\n-  if (find_omp_clause (clauses, OMP_CLAUSE_PARALLEL))\n+  if (omp_find_clause (clauses, OMP_CLAUSE_PARALLEL))\n     mask = 1;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_FOR))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_FOR))\n     mask = 2;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_SECTIONS))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_SECTIONS))\n     mask = 4;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_TASKGROUP))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_TASKGROUP))\n     mask = 8;\n   else\n     {\n@@ -8601,7 +8601,7 @@ finish_omp_cancel (tree clauses)\n       return;\n     }\n   vec<tree, va_gc> *vec = make_tree_vector ();\n-  tree ifc = find_omp_clause (clauses, OMP_CLAUSE_IF);\n+  tree ifc = omp_find_clause (clauses, OMP_CLAUSE_IF);\n   if (ifc != NULL_TREE)\n     {\n       tree type = TREE_TYPE (OMP_CLAUSE_IF_EXPR (ifc));\n@@ -8623,13 +8623,13 @@ finish_omp_cancellation_point (tree clauses)\n {\n   tree fn = builtin_decl_explicit (BUILT_IN_GOMP_CANCELLATION_POINT);\n   int mask = 0;\n-  if (find_omp_clause (clauses, OMP_CLAUSE_PARALLEL))\n+  if (omp_find_clause (clauses, OMP_CLAUSE_PARALLEL))\n     mask = 1;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_FOR))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_FOR))\n     mask = 2;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_SECTIONS))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_SECTIONS))\n     mask = 4;\n-  else if (find_omp_clause (clauses, OMP_CLAUSE_TASKGROUP))\n+  else if (omp_find_clause (clauses, OMP_CLAUSE_TASKGROUP))\n     mask = 8;\n   else\n     {"}, {"sha": "17bc404583f303636c8d6cdfc9c6430f91d3102b", "filename": "gcc/fortran/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ffortran%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ffortran%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2FChangeLog?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -1,3 +1,7 @@\n+2016-12-14  Martin Jambor  <mjambor@suse.cz>\n+\n+\t* trans-openmp.c: Include omp-general.h.\n+\n 2016-12-14  Andre Vehreschild  <vehre@gcc.gnu.org>\n \n \tPR fortran/78780"}, {"sha": "53f92b049ab86c838fa1f9e98662fc51885b1d27", "filename": "gcc/fortran/trans-openmp.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ffortran%2Ftrans-openmp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ffortran%2Ftrans-openmp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-openmp.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -35,8 +35,9 @@ along with GCC; see the file COPYING3.  If not see\n #include \"trans-array.h\"\n #include \"trans-const.h\"\n #include \"arith.h\"\n-#include \"omp-low.h\"\n #include \"gomp-constants.h\"\n+#include \"omp-general.h\"\n+#include \"omp-low.h\"\n \n int ompws_flags;\n "}, {"sha": "dcc2ff5c3582bf51e5034f8d123476953ab1ddc6", "filename": "gcc/gengtype.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fgengtype.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fgengtype.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgengtype.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -1719,7 +1719,7 @@ open_base_files (void)\n       \"tree-dfa.h\", \"tree-ssa.h\", \"reload.h\", \"cpp-id-data.h\", \"tree-chrec.h\",\n       \"except.h\", \"output.h\",  \"cfgloop.h\", \"target.h\", \"lto-streamer.h\",\n       \"target-globals.h\", \"ipa-ref.h\", \"cgraph.h\", \"symbol-summary.h\",\n-      \"ipa-prop.h\", \"ipa-inline.h\", \"dwarf2out.h\", \"omp-low.h\", NULL\n+      \"ipa-prop.h\", \"ipa-inline.h\", \"dwarf2out.h\", \"omp-offload.h\", NULL\n     };\n     const char *const *ifp;\n     outf_p gtype_desc_c;"}, {"sha": "9c86f158503a5835442adc65f403f76836c50b75", "filename": "gcc/gimple-fold.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fgimple-fold.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fgimple-fold.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-fold.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -52,7 +52,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"gimple-match.h\"\n #include \"gomp-constants.h\"\n #include \"optabs-query.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n #include \"ipa-chkp.h\"\n #include \"tree-cfg.h\"\n #include \"fold-const-call.h\"\n@@ -3416,8 +3416,8 @@ gimple_fold_builtin (gimple_stmt_iterator *gsi)\n static tree\n fold_internal_goacc_dim (const gimple *call)\n {\n-  int axis = get_oacc_ifn_dim_arg (call);\n-  int size = get_oacc_fn_dim_size (current_function_decl, axis);\n+  int axis = oacc_get_ifn_dim_arg (call);\n+  int size = oacc_get_fn_dim_size (current_function_decl, axis);\n   bool is_pos = gimple_call_internal_fn (call) == IFN_GOACC_DIM_POS;\n   tree result = NULL_TREE;\n "}, {"sha": "a300133118191e7b3462044f068e1ebffaad7a29", "filename": "gcc/gimplify.c", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fgimplify.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fgimplify.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimplify.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -51,6 +51,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"langhooks.h\"\n #include \"tree-cfg.h\"\n #include \"tree-ssa.h\"\n+#include \"omp-general.h\"\n #include \"omp-low.h\"\n #include \"gimple-low.h\"\n #include \"cilk.h\"\n@@ -6959,7 +6960,7 @@ omp_notice_variable (struct gimplify_omp_ctx *ctx, tree decl, bool in_code)\n \n       if (gimplify_omp_ctxp->outer_context == NULL\n \t  && VAR_P (decl)\n-\t  && get_oacc_fn_attrib (current_function_decl))\n+\t  && oacc_get_fn_attrib (current_function_decl))\n \t{\n \t  location_t loc = DECL_SOURCE_LOCATION (decl);\n \n@@ -9314,7 +9315,7 @@ gimplify_omp_task (tree *expr_p, gimple_seq *pre_p)\n   gimple_seq body = NULL;\n \n   gimplify_scan_omp_clauses (&OMP_TASK_CLAUSES (expr), pre_p,\n-\t\t\t     find_omp_clause (OMP_TASK_CLAUSES (expr),\n+\t\t\t     omp_find_clause (OMP_TASK_CLAUSES (expr),\n \t\t\t\t\t      OMP_CLAUSE_UNTIED)\n \t\t\t     ? ORT_UNTIED_TASK : ORT_TASK, OMP_TASK);\n \n@@ -9390,7 +9391,7 @@ gimplify_omp_for (tree *expr_p, gimple_seq *pre_p)\n       ort = ORT_ACC;\n       break;\n     case OMP_TASKLOOP:\n-      if (find_omp_clause (OMP_FOR_CLAUSES (for_stmt), OMP_CLAUSE_UNTIED))\n+      if (omp_find_clause (OMP_FOR_CLAUSES (for_stmt), OMP_CLAUSE_UNTIED))\n \tort = ORT_UNTIED_TASK;\n       else\n \tort = ORT_TASK;\n@@ -9555,7 +9556,7 @@ gimplify_omp_for (tree *expr_p, gimple_seq *pre_p)\n   gcc_assert (TREE_VEC_LENGTH (OMP_FOR_INIT (for_stmt))\n \t      == TREE_VEC_LENGTH (OMP_FOR_INCR (for_stmt)));\n \n-  tree c = find_omp_clause (OMP_FOR_CLAUSES (for_stmt), OMP_CLAUSE_ORDERED);\n+  tree c = omp_find_clause (OMP_FOR_CLAUSES (for_stmt), OMP_CLAUSE_ORDERED);\n   bool is_doacross = false;\n   if (c && OMP_CLAUSE_ORDERED_EXPR (c))\n     {\n@@ -9565,7 +9566,7 @@ gimplify_omp_for (tree *expr_p, gimple_seq *pre_p)\n \t\t\t\t\t       * 2);\n     }\n   int collapse = 1;\n-  c = find_omp_clause (OMP_FOR_CLAUSES (for_stmt), OMP_CLAUSE_COLLAPSE);\n+  c = omp_find_clause (OMP_FOR_CLAUSES (for_stmt), OMP_CLAUSE_COLLAPSE);\n   if (c)\n     collapse = tree_to_shwi (OMP_CLAUSE_COLLAPSE_EXPR (c));\n   for (i = 0; i < TREE_VEC_LENGTH (OMP_FOR_INIT (for_stmt)); i++)"}, {"sha": "947d0877539e938f1bd3f2543d387c381ce6e199", "filename": "gcc/lto-cgraph.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Flto-cgraph.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Flto-cgraph.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto-cgraph.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -36,7 +36,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"context.h\"\n #include \"pass_manager.h\"\n #include \"ipa-utils.h\"\n-#include \"omp-low.h\"\n+#include \"omp-offload.h\"\n #include \"ipa-chkp.h\"\n \n /* True when asm nodes has been output.  */"}, {"sha": "a953c8b0750fcfbab0e66151ed4a426fbcf3aab3", "filename": "gcc/omp-expand.c", "status": "added", "additions": 8195, "deletions": 0, "changes": 8195, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-expand.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-expand.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-expand.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9"}, {"sha": "a81b9c7253ddbda8f28d044926c7b20b89daba63", "filename": "gcc/omp-expand.h", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-expand.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-expand.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-expand.h?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -0,0 +1,32 @@\n+/* Expansion pass for OMP directives.  Outlines regions of certain OMP\n+   directives to separate functions, converts others into explicit calls to the\n+   runtime library (libgomp) and so forth\n+\n+Copyright (C) 2005-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_OMP_EXPAND_H\n+#define GCC_OMP_EXPAND_H\n+\n+struct omp_region;\n+extern void omp_expand_local (basic_block head);\n+extern void omp_free_regions (void);\n+extern bool omp_make_gimple_edges (basic_block bb, struct omp_region **region,\n+\t\t\t\t   int *region_idx);\n+\n+#endif /* GCC_OMP_EXPAND_H */"}, {"sha": "0cad8a51fc151e42206931ab8efd5652f40015cc", "filename": "gcc/omp-general.c", "status": "added", "additions": 650, "deletions": 0, "changes": 650, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-general.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-general.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-general.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -0,0 +1,650 @@\n+/* General types and functions that are uselful for processing of OpenMP,\n+   OpenACC and similar directivers at various stages of compilation.\n+\n+   Copyright (C) 2005-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+/* Find an OMP clause of type KIND within CLAUSES.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"target.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"ssa.h\"\n+#include \"diagnostic-core.h\"\n+#include \"fold-const.h\"\n+#include \"langhooks.h\"\n+#include \"omp-general.h\"\n+\n+\n+tree\n+omp_find_clause (tree clauses, enum omp_clause_code kind)\n+{\n+  for (; clauses ; clauses = OMP_CLAUSE_CHAIN (clauses))\n+    if (OMP_CLAUSE_CODE (clauses) == kind)\n+      return clauses;\n+\n+  return NULL_TREE;\n+}\n+\n+/* Return true if DECL is a reference type.  */\n+\n+bool\n+omp_is_reference (tree decl)\n+{\n+  return lang_hooks.decls.omp_privatize_by_reference (decl);\n+}\n+\n+/* Adjust *COND_CODE and *N2 so that the former is either LT_EXPR or\n+   GT_EXPR.  */\n+\n+void\n+omp_adjust_for_condition (location_t loc, enum tree_code *cond_code, tree *n2)\n+{\n+  switch (*cond_code)\n+    {\n+    case LT_EXPR:\n+    case GT_EXPR:\n+    case NE_EXPR:\n+      break;\n+    case LE_EXPR:\n+      if (POINTER_TYPE_P (TREE_TYPE (*n2)))\n+\t*n2 = fold_build_pointer_plus_hwi_loc (loc, *n2, 1);\n+      else\n+\t*n2 = fold_build2_loc (loc, PLUS_EXPR, TREE_TYPE (*n2), *n2,\n+\t\t\t       build_int_cst (TREE_TYPE (*n2), 1));\n+      *cond_code = LT_EXPR;\n+      break;\n+    case GE_EXPR:\n+      if (POINTER_TYPE_P (TREE_TYPE (*n2)))\n+\t*n2 = fold_build_pointer_plus_hwi_loc (loc, *n2, -1);\n+      else\n+\t*n2 = fold_build2_loc (loc, MINUS_EXPR, TREE_TYPE (*n2), *n2,\n+\t\t\t       build_int_cst (TREE_TYPE (*n2), 1));\n+      *cond_code = GT_EXPR;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Return the looping step from INCR, extracted from the step of a gimple omp\n+   for statement.  */\n+\n+tree\n+omp_get_for_step_from_incr (location_t loc, tree incr)\n+{\n+  tree step;\n+  switch (TREE_CODE (incr))\n+    {\n+    case PLUS_EXPR:\n+      step = TREE_OPERAND (incr, 1);\n+      break;\n+    case POINTER_PLUS_EXPR:\n+      step = fold_convert (ssizetype, TREE_OPERAND (incr, 1));\n+      break;\n+    case MINUS_EXPR:\n+      step = TREE_OPERAND (incr, 1);\n+      step = fold_build1_loc (loc, NEGATE_EXPR, TREE_TYPE (step), step);\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+  return step;\n+}\n+\n+/* Extract the header elements of parallel loop FOR_STMT and store\n+   them into *FD.  */\n+\n+void\n+omp_extract_for_data (gomp_for *for_stmt, struct omp_for_data *fd,\n+\t\t      struct omp_for_data_loop *loops)\n+{\n+  tree t, var, *collapse_iter, *collapse_count;\n+  tree count = NULL_TREE, iter_type = long_integer_type_node;\n+  struct omp_for_data_loop *loop;\n+  int i;\n+  struct omp_for_data_loop dummy_loop;\n+  location_t loc = gimple_location (for_stmt);\n+  bool simd = gimple_omp_for_kind (for_stmt) & GF_OMP_FOR_SIMD;\n+  bool distribute = gimple_omp_for_kind (for_stmt)\n+\t\t    == GF_OMP_FOR_KIND_DISTRIBUTE;\n+  bool taskloop = gimple_omp_for_kind (for_stmt)\n+\t\t  == GF_OMP_FOR_KIND_TASKLOOP;\n+  tree iterv, countv;\n+\n+  fd->for_stmt = for_stmt;\n+  fd->pre = NULL;\n+  if (gimple_omp_for_collapse (for_stmt) > 1)\n+    fd->loops = loops;\n+  else\n+    fd->loops = &fd->loop;\n+\n+  fd->have_nowait = distribute || simd;\n+  fd->have_ordered = false;\n+  fd->collapse = 1;\n+  fd->ordered = 0;\n+  fd->sched_kind = OMP_CLAUSE_SCHEDULE_STATIC;\n+  fd->sched_modifiers = 0;\n+  fd->chunk_size = NULL_TREE;\n+  fd->simd_schedule = false;\n+  if (gimple_omp_for_kind (fd->for_stmt) == GF_OMP_FOR_KIND_CILKFOR)\n+    fd->sched_kind = OMP_CLAUSE_SCHEDULE_CILKFOR;\n+  collapse_iter = NULL;\n+  collapse_count = NULL;\n+\n+  for (t = gimple_omp_for_clauses (for_stmt); t ; t = OMP_CLAUSE_CHAIN (t))\n+    switch (OMP_CLAUSE_CODE (t))\n+      {\n+      case OMP_CLAUSE_NOWAIT:\n+\tfd->have_nowait = true;\n+\tbreak;\n+      case OMP_CLAUSE_ORDERED:\n+\tfd->have_ordered = true;\n+\tif (OMP_CLAUSE_ORDERED_EXPR (t))\n+\t  fd->ordered = tree_to_shwi (OMP_CLAUSE_ORDERED_EXPR (t));\n+\tbreak;\n+      case OMP_CLAUSE_SCHEDULE:\n+\tgcc_assert (!distribute && !taskloop);\n+\tfd->sched_kind\n+\t  = (enum omp_clause_schedule_kind)\n+\t    (OMP_CLAUSE_SCHEDULE_KIND (t) & OMP_CLAUSE_SCHEDULE_MASK);\n+\tfd->sched_modifiers = (OMP_CLAUSE_SCHEDULE_KIND (t)\n+\t\t\t       & ~OMP_CLAUSE_SCHEDULE_MASK);\n+\tfd->chunk_size = OMP_CLAUSE_SCHEDULE_CHUNK_EXPR (t);\n+\tfd->simd_schedule = OMP_CLAUSE_SCHEDULE_SIMD (t);\n+\tbreak;\n+      case OMP_CLAUSE_DIST_SCHEDULE:\n+\tgcc_assert (distribute);\n+\tfd->chunk_size = OMP_CLAUSE_DIST_SCHEDULE_CHUNK_EXPR (t);\n+\tbreak;\n+      case OMP_CLAUSE_COLLAPSE:\n+\tfd->collapse = tree_to_shwi (OMP_CLAUSE_COLLAPSE_EXPR (t));\n+\tif (fd->collapse > 1)\n+\t  {\n+\t    collapse_iter = &OMP_CLAUSE_COLLAPSE_ITERVAR (t);\n+\t    collapse_count = &OMP_CLAUSE_COLLAPSE_COUNT (t);\n+\t  }\n+\tbreak;\n+      default:\n+\tbreak;\n+      }\n+  if (fd->ordered && fd->collapse == 1 && loops != NULL)\n+    {\n+      fd->loops = loops;\n+      iterv = NULL_TREE;\n+      countv = NULL_TREE;\n+      collapse_iter = &iterv;\n+      collapse_count = &countv;\n+    }\n+\n+  /* FIXME: for now map schedule(auto) to schedule(static).\n+     There should be analysis to determine whether all iterations\n+     are approximately the same amount of work (then schedule(static)\n+     is best) or if it varies (then schedule(dynamic,N) is better).  */\n+  if (fd->sched_kind == OMP_CLAUSE_SCHEDULE_AUTO)\n+    {\n+      fd->sched_kind = OMP_CLAUSE_SCHEDULE_STATIC;\n+      gcc_assert (fd->chunk_size == NULL);\n+    }\n+  gcc_assert (fd->collapse == 1 || collapse_iter != NULL);\n+  if (taskloop)\n+    fd->sched_kind = OMP_CLAUSE_SCHEDULE_RUNTIME;\n+  if (fd->sched_kind == OMP_CLAUSE_SCHEDULE_RUNTIME)\n+    gcc_assert (fd->chunk_size == NULL);\n+  else if (fd->chunk_size == NULL)\n+    {\n+      /* We only need to compute a default chunk size for ordered\n+\t static loops and dynamic loops.  */\n+      if (fd->sched_kind != OMP_CLAUSE_SCHEDULE_STATIC\n+\t  || fd->have_ordered)\n+\tfd->chunk_size = (fd->sched_kind == OMP_CLAUSE_SCHEDULE_STATIC)\n+\t\t\t ? integer_zero_node : integer_one_node;\n+    }\n+\n+  int cnt = fd->ordered ? fd->ordered : fd->collapse;\n+  for (i = 0; i < cnt; i++)\n+    {\n+      if (i == 0 && fd->collapse == 1 && (fd->ordered == 0 || loops == NULL))\n+\tloop = &fd->loop;\n+      else if (loops != NULL)\n+\tloop = loops + i;\n+      else\n+\tloop = &dummy_loop;\n+\n+      loop->v = gimple_omp_for_index (for_stmt, i);\n+      gcc_assert (SSA_VAR_P (loop->v));\n+      gcc_assert (TREE_CODE (TREE_TYPE (loop->v)) == INTEGER_TYPE\n+\t\t  || TREE_CODE (TREE_TYPE (loop->v)) == POINTER_TYPE);\n+      var = TREE_CODE (loop->v) == SSA_NAME ? SSA_NAME_VAR (loop->v) : loop->v;\n+      loop->n1 = gimple_omp_for_initial (for_stmt, i);\n+\n+      loop->cond_code = gimple_omp_for_cond (for_stmt, i);\n+      loop->n2 = gimple_omp_for_final (for_stmt, i);\n+      gcc_assert (loop->cond_code != NE_EXPR\n+\t\t  || gimple_omp_for_kind (for_stmt) == GF_OMP_FOR_KIND_CILKSIMD\n+\t\t  || gimple_omp_for_kind (for_stmt) == GF_OMP_FOR_KIND_CILKFOR);\n+      omp_adjust_for_condition (loc, &loop->cond_code, &loop->n2);\n+\n+      t = gimple_omp_for_incr (for_stmt, i);\n+      gcc_assert (TREE_OPERAND (t, 0) == var);\n+      loop->step = omp_get_for_step_from_incr (loc, t);\n+\n+      if (simd\n+\t  || (fd->sched_kind == OMP_CLAUSE_SCHEDULE_STATIC\n+\t      && !fd->have_ordered))\n+\t{\n+\t  if (fd->collapse == 1)\n+\t    iter_type = TREE_TYPE (loop->v);\n+\t  else if (i == 0\n+\t\t   || TYPE_PRECISION (iter_type)\n+\t\t      < TYPE_PRECISION (TREE_TYPE (loop->v)))\n+\t    iter_type\n+\t      = build_nonstandard_integer_type\n+\t\t  (TYPE_PRECISION (TREE_TYPE (loop->v)), 1);\n+\t}\n+      else if (iter_type != long_long_unsigned_type_node)\n+\t{\n+\t  if (POINTER_TYPE_P (TREE_TYPE (loop->v)))\n+\t    iter_type = long_long_unsigned_type_node;\n+\t  else if (TYPE_UNSIGNED (TREE_TYPE (loop->v))\n+\t\t   && TYPE_PRECISION (TREE_TYPE (loop->v))\n+\t\t      >= TYPE_PRECISION (iter_type))\n+\t    {\n+\t      tree n;\n+\n+\t      if (loop->cond_code == LT_EXPR)\n+\t\tn = fold_build2_loc (loc,\n+\t\t\t\t PLUS_EXPR, TREE_TYPE (loop->v),\n+\t\t\t\t loop->n2, loop->step);\n+\t      else\n+\t\tn = loop->n1;\n+\t      if (TREE_CODE (n) != INTEGER_CST\n+\t\t  || tree_int_cst_lt (TYPE_MAX_VALUE (iter_type), n))\n+\t\titer_type = long_long_unsigned_type_node;\n+\t    }\n+\t  else if (TYPE_PRECISION (TREE_TYPE (loop->v))\n+\t\t   > TYPE_PRECISION (iter_type))\n+\t    {\n+\t      tree n1, n2;\n+\n+\t      if (loop->cond_code == LT_EXPR)\n+\t\t{\n+\t\t  n1 = loop->n1;\n+\t\t  n2 = fold_build2_loc (loc,\n+\t\t\t\t    PLUS_EXPR, TREE_TYPE (loop->v),\n+\t\t\t\t    loop->n2, loop->step);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  n1 = fold_build2_loc (loc,\n+\t\t\t\t    MINUS_EXPR, TREE_TYPE (loop->v),\n+\t\t\t\t    loop->n2, loop->step);\n+\t\t  n2 = loop->n1;\n+\t\t}\n+\t      if (TREE_CODE (n1) != INTEGER_CST\n+\t\t  || TREE_CODE (n2) != INTEGER_CST\n+\t\t  || !tree_int_cst_lt (TYPE_MIN_VALUE (iter_type), n1)\n+\t\t  || !tree_int_cst_lt (n2, TYPE_MAX_VALUE (iter_type)))\n+\t\titer_type = long_long_unsigned_type_node;\n+\t    }\n+\t}\n+\n+      if (i >= fd->collapse)\n+\tcontinue;\n+\n+      if (collapse_count && *collapse_count == NULL)\n+\t{\n+\t  t = fold_binary (loop->cond_code, boolean_type_node,\n+\t\t\t   fold_convert (TREE_TYPE (loop->v), loop->n1),\n+\t\t\t   fold_convert (TREE_TYPE (loop->v), loop->n2));\n+\t  if (t && integer_zerop (t))\n+\t    count = build_zero_cst (long_long_unsigned_type_node);\n+\t  else if ((i == 0 || count != NULL_TREE)\n+\t\t   && TREE_CODE (TREE_TYPE (loop->v)) == INTEGER_TYPE\n+\t\t   && TREE_CONSTANT (loop->n1)\n+\t\t   && TREE_CONSTANT (loop->n2)\n+\t\t   && TREE_CODE (loop->step) == INTEGER_CST)\n+\t    {\n+\t      tree itype = TREE_TYPE (loop->v);\n+\n+\t      if (POINTER_TYPE_P (itype))\n+\t\titype = signed_type_for (itype);\n+\t      t = build_int_cst (itype, (loop->cond_code == LT_EXPR ? -1 : 1));\n+\t      t = fold_build2_loc (loc,\n+\t\t\t       PLUS_EXPR, itype,\n+\t\t\t       fold_convert_loc (loc, itype, loop->step), t);\n+\t      t = fold_build2_loc (loc, PLUS_EXPR, itype, t,\n+\t\t\t       fold_convert_loc (loc, itype, loop->n2));\n+\t      t = fold_build2_loc (loc, MINUS_EXPR, itype, t,\n+\t\t\t       fold_convert_loc (loc, itype, loop->n1));\n+\t      if (TYPE_UNSIGNED (itype) && loop->cond_code == GT_EXPR)\n+\t\tt = fold_build2_loc (loc, TRUNC_DIV_EXPR, itype,\n+\t\t\t\t fold_build1_loc (loc, NEGATE_EXPR, itype, t),\n+\t\t\t\t fold_build1_loc (loc, NEGATE_EXPR, itype,\n+\t\t\t\t\t      fold_convert_loc (loc, itype,\n+\t\t\t\t\t\t\t\tloop->step)));\n+\t      else\n+\t\tt = fold_build2_loc (loc, TRUNC_DIV_EXPR, itype, t,\n+\t\t\t\t fold_convert_loc (loc, itype, loop->step));\n+\t      t = fold_convert_loc (loc, long_long_unsigned_type_node, t);\n+\t      if (count != NULL_TREE)\n+\t\tcount = fold_build2_loc (loc,\n+\t\t\t\t     MULT_EXPR, long_long_unsigned_type_node,\n+\t\t\t\t     count, t);\n+\t      else\n+\t\tcount = t;\n+\t      if (TREE_CODE (count) != INTEGER_CST)\n+\t\tcount = NULL_TREE;\n+\t    }\n+\t  else if (count && !integer_zerop (count))\n+\t    count = NULL_TREE;\n+\t}\n+    }\n+\n+  if (count\n+      && !simd\n+      && (fd->sched_kind != OMP_CLAUSE_SCHEDULE_STATIC\n+\t  || fd->have_ordered))\n+    {\n+      if (!tree_int_cst_lt (count, TYPE_MAX_VALUE (long_integer_type_node)))\n+\titer_type = long_long_unsigned_type_node;\n+      else\n+\titer_type = long_integer_type_node;\n+    }\n+  else if (collapse_iter && *collapse_iter != NULL)\n+    iter_type = TREE_TYPE (*collapse_iter);\n+  fd->iter_type = iter_type;\n+  if (collapse_iter && *collapse_iter == NULL)\n+    *collapse_iter = create_tmp_var (iter_type, \".iter\");\n+  if (collapse_count && *collapse_count == NULL)\n+    {\n+      if (count)\n+\t*collapse_count = fold_convert_loc (loc, iter_type, count);\n+      else\n+\t*collapse_count = create_tmp_var (iter_type, \".count\");\n+    }\n+\n+  if (fd->collapse > 1 || (fd->ordered && loops))\n+    {\n+      fd->loop.v = *collapse_iter;\n+      fd->loop.n1 = build_int_cst (TREE_TYPE (fd->loop.v), 0);\n+      fd->loop.n2 = *collapse_count;\n+      fd->loop.step = build_int_cst (TREE_TYPE (fd->loop.v), 1);\n+      fd->loop.cond_code = LT_EXPR;\n+    }\n+  else if (loops)\n+    loops[0] = fd->loop;\n+}\n+\n+/* Build a call to GOMP_barrier.  */\n+\n+gimple *\n+omp_build_barrier (tree lhs)\n+{\n+  tree fndecl = builtin_decl_explicit (lhs ? BUILT_IN_GOMP_BARRIER_CANCEL\n+\t\t\t\t\t   : BUILT_IN_GOMP_BARRIER);\n+  gcall *g = gimple_build_call (fndecl, 0);\n+  if (lhs)\n+    gimple_call_set_lhs (g, lhs);\n+  return g;\n+}\n+\n+/* Return maximum possible vectorization factor for the target.  */\n+\n+int\n+omp_max_vf (void)\n+{\n+  if (!optimize\n+      || optimize_debug\n+      || !flag_tree_loop_optimize\n+      || (!flag_tree_loop_vectorize\n+\t  && (global_options_set.x_flag_tree_loop_vectorize\n+              || global_options_set.x_flag_tree_vectorize)))\n+    return 1;\n+\n+  int vf = 1;\n+  int vs = targetm.vectorize.autovectorize_vector_sizes ();\n+  if (vs)\n+    vf = 1 << floor_log2 (vs);\n+  else\n+    {\n+      machine_mode vqimode = targetm.vectorize.preferred_simd_mode (QImode);\n+      if (GET_MODE_CLASS (vqimode) == MODE_VECTOR_INT)\n+\tvf = GET_MODE_NUNITS (vqimode);\n+    }\n+  return vf;\n+}\n+\n+/* Return maximum SIMT width if offloading may target SIMT hardware.  */\n+\n+int\n+omp_max_simt_vf (void)\n+{\n+  if (!optimize)\n+    return 0;\n+  if (ENABLE_OFFLOADING)\n+    for (const char *c = getenv (\"OFFLOAD_TARGET_NAMES\"); c; )\n+      {\n+\tif (!strncmp (c, \"nvptx\", strlen (\"nvptx\")))\n+\t  return 32;\n+\telse if ((c = strchr (c, ',')))\n+\t  c++;\n+      }\n+  return 0;\n+}\n+\n+/* Encode an oacc launch argument.  This matches the GOMP_LAUNCH_PACK\n+   macro on gomp-constants.h.  We do not check for overflow.  */\n+\n+tree\n+oacc_launch_pack (unsigned code, tree device, unsigned op)\n+{\n+  tree res;\n+\n+  res = build_int_cst (unsigned_type_node, GOMP_LAUNCH_PACK (code, 0, op));\n+  if (device)\n+    {\n+      device = fold_build2 (LSHIFT_EXPR, unsigned_type_node,\n+\t\t\t    device, build_int_cst (unsigned_type_node,\n+\t\t\t\t\t\t   GOMP_LAUNCH_DEVICE_SHIFT));\n+      res = fold_build2 (BIT_IOR_EXPR, unsigned_type_node, res, device);\n+    }\n+  return res;\n+}\n+\n+/* FIXME: What is the following comment for? */\n+/* Look for compute grid dimension clauses and convert to an attribute\n+   attached to FN.  This permits the target-side code to (a) massage\n+   the dimensions, (b) emit that data and (c) optimize.  Non-constant\n+   dimensions are pushed onto ARGS.\n+\n+   The attribute value is a TREE_LIST.  A set of dimensions is\n+   represented as a list of INTEGER_CST.  Those that are runtime\n+   exprs are represented as an INTEGER_CST of zero.\n+\n+   TOOO. Normally the attribute will just contain a single such list.  If\n+   however it contains a list of lists, this will represent the use of\n+   device_type.  Each member of the outer list is an assoc list of\n+   dimensions, keyed by the device type.  The first entry will be the\n+   default.  Well, that's the plan.  */\n+\n+/* Replace any existing oacc fn attribute with updated dimensions.  */\n+\n+void\n+oacc_replace_fn_attrib (tree fn, tree dims)\n+{\n+  tree ident = get_identifier (OACC_FN_ATTRIB);\n+  tree attribs = DECL_ATTRIBUTES (fn);\n+\n+  /* If we happen to be present as the first attrib, drop it.  */\n+  if (attribs && TREE_PURPOSE (attribs) == ident)\n+    attribs = TREE_CHAIN (attribs);\n+  DECL_ATTRIBUTES (fn) = tree_cons (ident, dims, attribs);\n+}\n+\n+/* Scan CLAUSES for launch dimensions and attach them to the oacc\n+   function attribute.  Push any that are non-constant onto the ARGS\n+   list, along with an appropriate GOMP_LAUNCH_DIM tag.  IS_KERNEL is\n+   true, if these are for a kernels region offload function.  */\n+\n+void\n+oacc_set_fn_attrib (tree fn, tree clauses, bool is_kernel, vec<tree> *args)\n+{\n+  /* Must match GOMP_DIM ordering.  */\n+  static const omp_clause_code ids[]\n+    = { OMP_CLAUSE_NUM_GANGS, OMP_CLAUSE_NUM_WORKERS,\n+\tOMP_CLAUSE_VECTOR_LENGTH };\n+  unsigned ix;\n+  tree dims[GOMP_DIM_MAX];\n+\n+  tree attr = NULL_TREE;\n+  unsigned non_const = 0;\n+\n+  for (ix = GOMP_DIM_MAX; ix--;)\n+    {\n+      tree clause = omp_find_clause (clauses, ids[ix]);\n+      tree dim = NULL_TREE;\n+\n+      if (clause)\n+\tdim = OMP_CLAUSE_EXPR (clause, ids[ix]);\n+      dims[ix] = dim;\n+      if (dim && TREE_CODE (dim) != INTEGER_CST)\n+\t{\n+\t  dim = integer_zero_node;\n+\t  non_const |= GOMP_DIM_MASK (ix);\n+\t}\n+      attr = tree_cons (NULL_TREE, dim, attr);\n+      /* Note kernelness with TREE_PUBLIC.  */\n+      if (is_kernel)\n+\tTREE_PUBLIC (attr) = 1;\n+    }\n+\n+  oacc_replace_fn_attrib (fn, attr);\n+\n+  if (non_const)\n+    {\n+      /* Push a dynamic argument set.  */\n+      args->safe_push (oacc_launch_pack (GOMP_LAUNCH_DIM,\n+\t\t\t\t\t NULL_TREE, non_const));\n+      for (unsigned ix = 0; ix != GOMP_DIM_MAX; ix++)\n+\tif (non_const & GOMP_DIM_MASK (ix))\n+\t  args->safe_push (dims[ix]);\n+    }\n+}\n+\n+/*  Process the routine's dimension clauess to generate an attribute\n+    value.  Issue diagnostics as appropriate.  We default to SEQ\n+    (OpenACC 2.5 clarifies this). All dimensions have a size of zero\n+    (dynamic).  TREE_PURPOSE is set to indicate whether that dimension\n+    can have a loop partitioned on it.  non-zero indicates\n+    yes, zero indicates no.  By construction once a non-zero has been\n+    reached, further inner dimensions must also be non-zero.  We set\n+    TREE_VALUE to zero for the dimensions that may be partitioned and\n+    1 for the other ones -- if a loop is (erroneously) spawned at\n+    an outer level, we don't want to try and partition it.  */\n+\n+tree\n+oacc_build_routine_dims (tree clauses)\n+{\n+  /* Must match GOMP_DIM ordering.  */\n+  static const omp_clause_code ids[] =\n+    {OMP_CLAUSE_GANG, OMP_CLAUSE_WORKER, OMP_CLAUSE_VECTOR, OMP_CLAUSE_SEQ};\n+  int ix;\n+  int level = -1;\n+\n+  for (; clauses; clauses = OMP_CLAUSE_CHAIN (clauses))\n+    for (ix = GOMP_DIM_MAX + 1; ix--;)\n+      if (OMP_CLAUSE_CODE (clauses) == ids[ix])\n+\t{\n+\t  if (level >= 0)\n+\t    error_at (OMP_CLAUSE_LOCATION (clauses),\n+\t\t      \"multiple loop axes specified for routine\");\n+\t  level = ix;\n+\t  break;\n+\t}\n+\n+  /* Default to SEQ.  */\n+  if (level < 0)\n+    level = GOMP_DIM_MAX;\n+\n+  tree dims = NULL_TREE;\n+\n+  for (ix = GOMP_DIM_MAX; ix--;)\n+    dims = tree_cons (build_int_cst (boolean_type_node, ix >= level),\n+\t\t      build_int_cst (integer_type_node, ix < level), dims);\n+\n+  return dims;\n+}\n+\n+/* Retrieve the oacc function attrib and return it.  Non-oacc\n+   functions will return NULL.  */\n+\n+tree\n+oacc_get_fn_attrib (tree fn)\n+{\n+  return lookup_attribute (OACC_FN_ATTRIB, DECL_ATTRIBUTES (fn));\n+}\n+\n+/* Return true if this oacc fn attrib is for a kernels offload\n+   region.  We use the TREE_PUBLIC flag of each dimension -- only\n+   need to check the first one.  */\n+\n+bool\n+oacc_fn_attrib_kernels_p (tree attr)\n+{\n+  return TREE_PUBLIC (TREE_VALUE (attr));\n+}\n+\n+/* Extract an oacc execution dimension from FN.  FN must be an\n+   offloaded function or routine that has already had its execution\n+   dimensions lowered to the target-specific values.  */\n+\n+int\n+oacc_get_fn_dim_size (tree fn, int axis)\n+{\n+  tree attrs = oacc_get_fn_attrib (fn);\n+\n+  gcc_assert (axis < GOMP_DIM_MAX);\n+\n+  tree dims = TREE_VALUE (attrs);\n+  while (axis--)\n+    dims = TREE_CHAIN (dims);\n+\n+  int size = TREE_INT_CST_LOW (TREE_VALUE (dims));\n+\n+  return size;\n+}\n+\n+/* Extract the dimension axis from an IFN_GOACC_DIM_POS or\n+   IFN_GOACC_DIM_SIZE call.  */\n+\n+int\n+oacc_get_ifn_dim_arg (const gimple *stmt)\n+{\n+  gcc_checking_assert (gimple_call_internal_fn (stmt) == IFN_GOACC_DIM_SIZE\n+\t\t       || gimple_call_internal_fn (stmt) == IFN_GOACC_DIM_POS);\n+  tree arg = gimple_call_arg (stmt, 0);\n+  HOST_WIDE_INT axis = TREE_INT_CST_LOW (arg);\n+\n+  gcc_checking_assert (axis >= 0 && axis < GOMP_DIM_MAX);\n+  return (int) axis;\n+}"}, {"sha": "634fdccb35737927b23015e095fc5030221364c4", "filename": "gcc/omp-general.h", "status": "added", "additions": 91, "deletions": 0, "changes": 91, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-general.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-general.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-general.h?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -0,0 +1,91 @@\n+/* General types and functions that are uselful for processing of OpenMP,\n+   OpenACC and similar directivers at various stages of compilation.\n+\n+   Copyright (C) 2005-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_OMP_GENERAL_H\n+#define GCC_OMP_GENERAL_H\n+\n+#include \"gomp-constants.h\"\n+\n+/*  Flags for an OpenACC loop.  */\n+\n+enum oacc_loop_flags {\n+  OLF_SEQ\t= 1u << 0,  /* Explicitly sequential  */\n+  OLF_AUTO\t= 1u << 1,\t/* Compiler chooses axes.  */\n+  OLF_INDEPENDENT = 1u << 2,\t/* Iterations are known independent.  */\n+  OLF_GANG_STATIC = 1u << 3,\t/* Gang partitioning is static (has op). */\n+\n+  /* Explicitly specified loop axes.  */\n+  OLF_DIM_BASE = 4,\n+  OLF_DIM_GANG   = 1u << (OLF_DIM_BASE + GOMP_DIM_GANG),\n+  OLF_DIM_WORKER = 1u << (OLF_DIM_BASE + GOMP_DIM_WORKER),\n+  OLF_DIM_VECTOR = 1u << (OLF_DIM_BASE + GOMP_DIM_VECTOR),\n+\n+  OLF_MAX = OLF_DIM_BASE + GOMP_DIM_MAX\n+};\n+\n+/* A structure holding the elements of:\n+   for (V = N1; V cond N2; V += STEP) [...] */\n+\n+struct omp_for_data_loop\n+{\n+  tree v, n1, n2, step;\n+  enum tree_code cond_code;\n+};\n+\n+/* A structure describing the main elements of a parallel loop.  */\n+\n+struct omp_for_data\n+{\n+  struct omp_for_data_loop loop;\n+  tree chunk_size;\n+  gomp_for *for_stmt;\n+  tree pre, iter_type;\n+  int collapse;\n+  int ordered;\n+  bool have_nowait, have_ordered, simd_schedule;\n+  unsigned char sched_modifiers;\n+  enum omp_clause_schedule_kind sched_kind;\n+  struct omp_for_data_loop *loops;\n+};\n+\n+#define OACC_FN_ATTRIB \"oacc function\"\n+\n+extern tree omp_find_clause (tree clauses, enum omp_clause_code kind);\n+extern bool omp_is_reference (tree decl);\n+extern void omp_adjust_for_condition (location_t loc, enum tree_code *cond_code,\n+\t\t\t\t      tree *n2);\n+extern tree omp_get_for_step_from_incr (location_t loc, tree incr);\n+extern void omp_extract_for_data (gomp_for *for_stmt, struct omp_for_data *fd,\n+\t\t\t\t  struct omp_for_data_loop *loops);\n+extern gimple *omp_build_barrier (tree lhs);\n+extern int omp_max_vf (void);\n+extern int omp_max_simt_vf (void);\n+extern tree oacc_launch_pack (unsigned code, tree device, unsigned op);\n+extern void oacc_replace_fn_attrib (tree fn, tree dims);\n+extern void oacc_set_fn_attrib (tree fn, tree clauses, bool is_kernel,\n+\t\t\t\tvec<tree> *args);\n+extern tree oacc_build_routine_dims (tree clauses);\n+extern tree oacc_get_fn_attrib (tree fn);\n+extern bool oacc_fn_attrib_kernels_p (tree attr);\n+extern int oacc_get_fn_dim_size (tree fn, int axis);\n+extern int oacc_get_ifn_dim_arg (const gimple *stmt);\n+\n+#endif /* GCC_OMP_GENERAL_H */"}, {"sha": "81f6ea5e193f94727b264f6eceb1959c915db88f", "filename": "gcc/omp-grid.c", "status": "added", "additions": 1407, "deletions": 0, "changes": 1407, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-grid.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-grid.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-grid.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -0,0 +1,1407 @@\n+/* Lowering and expansion of OpenMP directives for HSA GPU agents.\n+\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"tree-pass.h\"\n+#include \"ssa.h\"\n+#include \"cgraph.h\"\n+#include \"pretty-print.h\"\n+#include \"fold-const.h\"\n+#include \"gimplify.h\"\n+#include \"gimple-iterator.h\"\n+#include \"gimple-walk.h\"\n+#include \"tree-inline.h\"\n+#include \"langhooks.h\"\n+#include \"omp-general.h\"\n+#include \"omp-low.h\"\n+#include \"omp-grid.h\"\n+#include \"gimple-pretty-print.h\"\n+\n+/* Return the lastprivate predicate for a given gridified loop described by\n+   FD).  */\n+\n+tree\n+omp_grid_lastprivate_predicate (struct omp_for_data *fd)\n+{\n+  /* When dealing with a gridified loop, we need to check up to three collapsed\n+     iteration variables but they are not actually captured in this fd.\n+     Fortunately, we can easily rely on HSA builtins to get this\n+     information. */\n+\n+  tree id, size;\n+  if (gimple_omp_for_kind (fd->for_stmt) == GF_OMP_FOR_KIND_GRID_LOOP\n+      && gimple_omp_for_grid_intra_group (fd->for_stmt))\n+    {\n+      id = builtin_decl_explicit (BUILT_IN_HSA_WORKITEMID);\n+      size = builtin_decl_explicit (BUILT_IN_HSA_CURRENTWORKGROUPSIZE);\n+    }\n+  else\n+    {\n+      id = builtin_decl_explicit (BUILT_IN_HSA_WORKITEMABSID);\n+      size = builtin_decl_explicit (BUILT_IN_HSA_GRIDSIZE);\n+    }\n+  tree cond = NULL;\n+  for (int dim = 0; dim < fd->collapse; dim++)\n+    {\n+      tree dim_tree = build_int_cstu (unsigned_type_node, dim);\n+      tree u1 = build_int_cstu (unsigned_type_node, 1);\n+      tree c2\n+\t= build2 (EQ_EXPR, boolean_type_node,\n+\t\t  build2 (PLUS_EXPR, unsigned_type_node,\n+\t\t\t  build_call_expr (id, 1, dim_tree), u1),\n+\t\t  build_call_expr (size, 1, dim_tree));\n+      if (cond)\n+\tcond = build2 (TRUTH_AND_EXPR, boolean_type_node, cond, c2);\n+      else\n+\tcond = c2;\n+    }\n+  return cond;\n+}\n+\n+/* Structure describing the basic properties of the loop we ara analyzing\n+   whether it can be gridified and when it is gridified. */\n+\n+struct grid_prop\n+{\n+  /* True when we are doing tiling gridification, i.e. when there is a distinct\n+     distribute loop over groups and a loop construct over work-items.  False\n+     when distribute and parallel for loops form a combined construct.  */\n+  bool tiling;\n+  /* Location of the target construct for optimization information\n+     messages.  */\n+  location_t target_loc;\n+  /* The collapse clause of the involved loops.  Collapse value of all of them\n+     must be the same for gridification to take place.  */\n+  size_t collapse;\n+  /* Group sizes, if requested by the user or NULL if not requested.  */\n+  tree group_sizes[3];\n+};\n+\n+#define GRID_MISSED_MSG_PREFIX \"Will not turn target construct into a \" \\\n+  \"gridified HSA kernel because \"\n+\n+/* Return true if STMT is an assignment of a register-type into a local\n+   VAR_DECL.  If GRID is non-NULL, the assignment additionally must not be to\n+   any of the trees specifying group sizes there.  */\n+\n+static bool\n+grid_safe_assignment_p (gimple *stmt, grid_prop *grid)\n+{\n+  gassign *assign = dyn_cast <gassign *> (stmt);\n+  if (!assign)\n+    return false;\n+  if (gimple_clobber_p (assign))\n+    return true;\n+  tree lhs = gimple_assign_lhs (assign);\n+  if (!VAR_P (lhs)\n+      || !is_gimple_reg_type (TREE_TYPE (lhs))\n+      || is_global_var (lhs))\n+    return false;\n+  if (grid)\n+    for (unsigned i = 0; i < grid->collapse; i++)\n+      if (lhs == grid->group_sizes[i])\n+\treturn false;\n+  return true;\n+}\n+\n+/* Return true if all statements in SEQ are assignments to local register-type\n+   variables that do not hold group size information.  */\n+\n+static bool\n+grid_seq_only_contains_local_assignments (gimple_seq seq, grid_prop *grid)\n+{\n+  if (!seq)\n+    return true;\n+\n+  gimple_stmt_iterator gsi;\n+  for (gsi = gsi_start (seq); !gsi_end_p (gsi); gsi_next (&gsi))\n+    if (!grid_safe_assignment_p (gsi_stmt (gsi), grid))\n+      return false;\n+  return true;\n+}\n+\n+/* Scan statements in SEQ and call itself recursively on any bind.  GRID\n+   describes hitherto discovered properties of the loop that is evaluated for\n+   possible gridification.  If during whole search only assignments to\n+   register-type local variables (that do not overwrite group size information)\n+   and one single OMP statement is encountered, return true, otherwise return\n+   false.  RET is where we store any OMP statement encountered.  */\n+\n+static bool\n+grid_find_single_omp_among_assignments_1 (gimple_seq seq, grid_prop *grid,\n+\t\t\t\t\t  const char *name, gimple **ret)\n+{\n+  gimple_stmt_iterator gsi;\n+  for (gsi = gsi_start (seq); !gsi_end_p (gsi); gsi_next (&gsi))\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+\n+      if (grid_safe_assignment_p (stmt, grid))\n+\tcontinue;\n+      if (gbind *bind = dyn_cast <gbind *> (stmt))\n+\t{\n+\t  if (!grid_find_single_omp_among_assignments_1 (gimple_bind_body (bind),\n+\t\t\t\t\t\t\t grid, name, ret))\n+\t      return false;\n+\t}\n+      else if (is_gimple_omp (stmt))\n+\t{\n+\t  if (*ret)\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\t{\n+\t\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t\t   GRID_MISSED_MSG_PREFIX \"%s construct \"\n+\t\t\t\t   \"contains multiple OpenMP constructs\\n\",\n+\t\t\t\t   name);\n+\t\t  dump_printf_loc (MSG_NOTE, gimple_location (*ret),\n+\t\t\t\t   \"The first OpenMP construct within \"\n+\t\t\t\t   \"a parallel\\n\");\n+\t\t  dump_printf_loc (MSG_NOTE, gimple_location (stmt),\n+\t\t\t\t   \"The second OpenMP construct within \"\n+\t\t\t\t   \"a parallel\\n\");\n+\t\t}\n+\t      return false;\n+\t    }\n+\t  *ret = stmt;\n+\t}\n+      else\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    {\n+\t      dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"%s construct contains \"\n+\t\t\t       \"a complex statement\\n\", name);\n+\t      dump_printf_loc (MSG_NOTE, gimple_location (stmt),\n+\t\t\t       \"This statement cannot be analyzed for \"\n+\t\t\t       \"gridification\\n\");\n+\t    }\n+\t  return false;\n+\t}\n+    }\n+  return true;\n+}\n+\n+/* Scan statements in SEQ and make sure that it and any binds in it contain\n+   only assignments to local register-type variables (that do not overwrite\n+   group size information) and one OMP construct.  If so, return that\n+   construct, otherwise return NULL.  GRID describes hitherto discovered\n+   properties of the loop that is evaluated for possible gridification.  If\n+   dumping is enabled and function fails, use NAME to dump a note with the\n+   reason for failure.  */\n+\n+static gimple *\n+grid_find_single_omp_among_assignments (gimple_seq seq, grid_prop *grid,\n+\t\t\t\t\tconst char *name)\n+{\n+  if (!seq)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t GRID_MISSED_MSG_PREFIX \"%s construct has empty body\\n\",\n+\t\t\t name);\n+      return NULL;\n+    }\n+\n+  gimple *ret = NULL;\n+  if (grid_find_single_omp_among_assignments_1 (seq, grid, name, &ret))\n+    {\n+      if (!ret && dump_enabled_p ())\n+\tdump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t GRID_MISSED_MSG_PREFIX \"%s construct does not contain\"\n+\t\t\t \"any other OpenMP construct\\n\", name);\n+      return ret;\n+    }\n+  else\n+    return NULL;\n+}\n+\n+/* Walker function looking for statements there is no point gridifying (and for\n+   noreturn function calls which we cannot do).  Return non-NULL if such a\n+   function is found.  */\n+\n+static tree\n+grid_find_ungridifiable_statement (gimple_stmt_iterator *gsi,\n+\t\t\t\t   bool *handled_ops_p,\n+\t\t\t\t   struct walk_stmt_info *wi)\n+{\n+  *handled_ops_p = false;\n+  gimple *stmt = gsi_stmt (*gsi);\n+  switch (gimple_code (stmt))\n+    {\n+    case GIMPLE_CALL:\n+      if (gimple_call_noreturn_p (as_a <gcall *> (stmt)))\n+\t{\n+\t  *handled_ops_p = true;\n+\t  wi->info = stmt;\n+\t  return error_mark_node;\n+\t}\n+      break;\n+\n+    /* We may reduce the following list if we find a way to implement the\n+       clauses, but now there is no point trying further.  */\n+    case GIMPLE_OMP_CRITICAL:\n+    case GIMPLE_OMP_TASKGROUP:\n+    case GIMPLE_OMP_TASK:\n+    case GIMPLE_OMP_SECTION:\n+    case GIMPLE_OMP_SECTIONS:\n+    case GIMPLE_OMP_SECTIONS_SWITCH:\n+    case GIMPLE_OMP_TARGET:\n+    case GIMPLE_OMP_ORDERED:\n+      *handled_ops_p = true;\n+      wi->info = stmt;\n+      return error_mark_node;\n+    default:\n+      break;\n+    }\n+  return NULL;\n+}\n+\n+/* Examine clauses of omp parallel statement PAR and if any prevents\n+   gridification, issue a missed-optimization diagnostics and return false,\n+   otherwise return true.  GRID describes hitherto discovered properties of the\n+   loop that is evaluated for possible gridification.  */\n+\n+static bool\n+grid_parallel_clauses_gridifiable (gomp_parallel *par, location_t tloc)\n+{\n+  tree clauses = gimple_omp_parallel_clauses (par);\n+  while (clauses)\n+    {\n+      switch (OMP_CLAUSE_CODE (clauses))\n+\t{\n+\tcase OMP_CLAUSE_NUM_THREADS:\n+\t  if (dump_enabled_p ())\n+\t    {\n+\t      dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"because there is \"\n+\t\t\t       \"a num_threads clause of the parallel \"\n+\t\t\t       \"construct\\n\");\n+\t      dump_printf_loc (MSG_NOTE, gimple_location (par),\n+\t\t\t       \"Parallel construct has a num_threads clause\\n\");\n+\t    }\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_REDUCTION:\n+\t  if (dump_enabled_p ())\n+\t    {\n+\t      dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"a reduction clause\"\n+\t\t\t       \"is present\\n \");\n+\t      dump_printf_loc (MSG_NOTE, gimple_location (par),\n+\t\t\t       \"Parallel construct has a reduction clause\\n\");\n+\t    }\n+\t  return false;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      clauses = OMP_CLAUSE_CHAIN (clauses);\n+    }\n+  return true;\n+}\n+\n+/* Examine clauses and the body of omp loop statement GFOR and if something\n+   prevents gridification, issue a missed-optimization diagnostics and return\n+   false, otherwise return true. GRID describes hitherto discovered properties\n+   of the loop that is evaluated for possible gridification.  */\n+\n+static bool\n+grid_inner_loop_gridifiable_p (gomp_for *gfor, grid_prop *grid)\n+{\n+  if (!grid_seq_only_contains_local_assignments (gimple_omp_for_pre_body (gfor),\n+\t\t\t\t\t\t grid))\n+    {\n+      if (dump_enabled_p ())\n+\t{\n+\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t   GRID_MISSED_MSG_PREFIX \"the inner loop \"\n+\t\t\t   \"loop bounds computation contains a complex \"\n+\t\t\t   \"statement\\n\");\n+\t  dump_printf_loc (MSG_NOTE, gimple_location (gfor),\n+\t\t\t   \"Loop construct cannot be analyzed for \"\n+\t\t\t   \"gridification\\n\");\n+\t}\n+      return false;\n+    }\n+\n+  tree clauses = gimple_omp_for_clauses (gfor);\n+  while (clauses)\n+    {\n+      switch (OMP_CLAUSE_CODE (clauses))\n+\t{\n+\tcase OMP_CLAUSE_SCHEDULE:\n+\t  if (OMP_CLAUSE_SCHEDULE_KIND (clauses) != OMP_CLAUSE_SCHEDULE_AUTO)\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\t{\n+\t\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t\t   GRID_MISSED_MSG_PREFIX \"the inner loop \"\n+\t\t\t\t   \"has a non-automatic schedule clause\\n\");\n+\t\t  dump_printf_loc (MSG_NOTE, gimple_location (gfor),\n+\t\t\t\t   \"Loop construct has a non automatic \"\n+\t\t\t\t   \"schedule clause\\n\");\n+\t\t}\n+\t      return false;\n+\t    }\n+\t  break;\n+\n+\tcase OMP_CLAUSE_REDUCTION:\n+\t  if (dump_enabled_p ())\n+\t    {\n+\t      dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"a reduction \"\n+\t\t\t       \"clause is present\\n \");\n+\t      dump_printf_loc (MSG_NOTE, gimple_location (gfor),\n+\t\t\t       \"Loop construct has a reduction schedule \"\n+\t\t\t       \"clause\\n\");\n+\t    }\n+\t  return false;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      clauses = OMP_CLAUSE_CHAIN (clauses);\n+    }\n+  struct walk_stmt_info wi;\n+  memset (&wi, 0, sizeof (wi));\n+  if (walk_gimple_seq (gimple_omp_body (gfor),\n+\t\t       grid_find_ungridifiable_statement,\n+\t\t       NULL, &wi))\n+    {\n+      gimple *bad = (gimple *) wi.info;\n+      if (dump_enabled_p ())\n+\t{\n+\t  if (is_gimple_call (bad))\n+\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"the inner loop contains \"\n+\t\t\t       \"call to a noreturn function\\n\");\n+\t  else\n+\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t     GRID_MISSED_MSG_PREFIX \"the inner loop contains \"\n+\t\t\t     \"statement %s which cannot be transformed\\n\",\n+\t\t\t     gimple_code_name[(int) gimple_code (bad)]);\n+\t  dump_printf_loc (MSG_NOTE, gimple_location (bad),\n+\t\t\t   \"This statement cannot be analyzed for \"\n+\t\t\t   \"gridification\\n\");\n+\t}\n+      return false;\n+    }\n+  return true;\n+}\n+\n+/* Given distribute omp construct represented by DIST, which in the original\n+   source forms a compound construct with a looping construct, return true if it\n+   can be turned into a gridified HSA kernel.  Otherwise return false. GRID\n+   describes hitherto discovered properties of the loop that is evaluated for\n+   possible gridification.  */\n+\n+static bool\n+grid_dist_follows_simple_pattern (gomp_for *dist, grid_prop *grid)\n+{\n+  location_t tloc = grid->target_loc;\n+  gimple *stmt = grid_find_single_omp_among_assignments (gimple_omp_body (dist),\n+\t\t\t\t\t\t\t grid, \"distribute\");\n+  gomp_parallel *par;\n+  if (!stmt\n+      || !(par = dyn_cast <gomp_parallel *> (stmt))\n+      || !grid_parallel_clauses_gridifiable (par, tloc))\n+    return false;\n+\n+  stmt = grid_find_single_omp_among_assignments (gimple_omp_body (par), grid,\n+\t\t\t\t\t\t \"parallel\");\n+  gomp_for *gfor;\n+  if (!stmt || !(gfor = dyn_cast <gomp_for *> (stmt)))\n+    return false;\n+\n+  if (gimple_omp_for_kind (gfor) != GF_OMP_FOR_KIND_FOR)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t GRID_MISSED_MSG_PREFIX \"the inner loop is not \"\n+\t\t\t \"a simple for loop\\n\");\n+      return false;\n+    }\n+  gcc_assert (gimple_omp_for_collapse (gfor) == grid->collapse);\n+\n+  if (!grid_inner_loop_gridifiable_p (gfor, grid))\n+    return false;\n+\n+  return true;\n+}\n+\n+/* Given an omp loop statement GFOR, return true if it can participate in\n+   tiling gridification, i.e. in one where the distribute and parallel for\n+   loops do not form a compound statement.  GRID describes hitherto discovered\n+   properties of the loop that is evaluated for possible gridification. */\n+\n+static bool\n+grid_gfor_follows_tiling_pattern (gomp_for *gfor, grid_prop *grid)\n+{\n+  if (gimple_omp_for_kind (gfor) != GF_OMP_FOR_KIND_FOR)\n+    {\n+      if (dump_enabled_p ())\n+\t{\n+\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t   GRID_MISSED_MSG_PREFIX \"an inner loop is not \"\n+\t\t\t   \"a simple for loop\\n\");\n+\t  dump_printf_loc (MSG_NOTE, gimple_location (gfor),\n+\t\t\t   \"This statement is not a simple for loop\\n\");\n+\t}\n+      return false;\n+    }\n+\n+  if (!grid_inner_loop_gridifiable_p (gfor, grid))\n+    return false;\n+\n+  if (gimple_omp_for_collapse (gfor) != grid->collapse)\n+    {\n+      if (dump_enabled_p ())\n+\t{\n+\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t   GRID_MISSED_MSG_PREFIX \"an inner loop does not \"\n+\t\t\t   \"have use the same collapse clause\\n\");\n+\t  dump_printf_loc (MSG_NOTE, gimple_location (gfor),\n+\t\t\t   \"Loop construct uses a different collapse clause\\n\");\n+\t}\n+      return false;\n+    }\n+\n+  struct omp_for_data fd;\n+  struct omp_for_data_loop *loops\n+    = (struct omp_for_data_loop *)alloca (grid->collapse\n+\t\t\t\t\t  * sizeof (struct omp_for_data_loop));\n+  omp_extract_for_data (gfor, &fd, loops);\n+  for (unsigned i = 0; i < grid->collapse; i++)\n+    {\n+      tree itype, type = TREE_TYPE (fd.loops[i].v);\n+      if (POINTER_TYPE_P (type))\n+\titype = signed_type_for (type);\n+      else\n+\titype = type;\n+\n+      tree n1 = fold_convert (itype, fd.loops[i].n1);\n+      tree n2 = fold_convert (itype, fd.loops[i].n2);\n+      tree t = build_int_cst (itype,\n+\t\t\t      (fd.loops[i].cond_code == LT_EXPR ? -1 : 1));\n+      t = fold_build2 (PLUS_EXPR, itype, fd.loops[i].step, t);\n+      t = fold_build2 (PLUS_EXPR, itype, t, n2);\n+      t = fold_build2 (MINUS_EXPR, itype, t, n1);\n+      if (TYPE_UNSIGNED (itype) && fd.loops[i].cond_code == GT_EXPR)\n+\tt = fold_build2 (TRUNC_DIV_EXPR, itype,\n+\t\t\t fold_build1 (NEGATE_EXPR, itype, t),\n+\t\t\t fold_build1 (NEGATE_EXPR, itype, fd.loops[i].step));\n+      else\n+\tt = fold_build2 (TRUNC_DIV_EXPR, itype, t, fd.loops[i].step);\n+\n+      if (!operand_equal_p (grid->group_sizes[i], t, 0))\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    {\n+\t      dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"the distribute and \"\n+\t\t\t       \"an internal loop do not agree on tile size\\n\");\n+\t      dump_printf_loc (MSG_NOTE, gimple_location (gfor),\n+\t\t\t       \"Loop construct does not seem to loop over \"\n+\t\t\t       \"a tile size\\n\");\n+\t    }\n+\t  return false;\n+\t}\n+    }\n+  return true;\n+}\n+\n+/* Facing a call to FNDECL in the body of a distribute construct, return true\n+   if we can handle it or false if it precludes gridification.  */\n+\n+static bool\n+grid_call_permissible_in_distribute_p (tree fndecl)\n+{\n+  if (DECL_PURE_P (fndecl) || TREE_READONLY (fndecl))\n+    return true;\n+\n+  const char *name = IDENTIFIER_POINTER (DECL_NAME (fndecl));\n+  if (strstr (name, \"omp_\") != name)\n+    return false;\n+\n+  if ((strcmp (name, \"omp_get_thread_num\") == 0)\n+      || (strcmp (name, \"omp_get_num_threads\") == 0)\n+      || (strcmp (name, \"omp_get_num_teams\") == 0)\n+      || (strcmp (name, \"omp_get_team_num\") == 0)\n+      || (strcmp (name, \"omp_get_level\") == 0)\n+      || (strcmp (name, \"omp_get_active_level\") == 0)\n+      || (strcmp (name, \"omp_in_parallel\") == 0))\n+    return true;\n+\n+  return false;\n+}\n+\n+/* Facing a call satisfying grid_call_permissible_in_distribute_p in the body\n+   of a distribute construct that is pointed at by GSI, modify it as necessary\n+   for gridification.  If the statement itself got removed, return true.  */\n+\n+static bool\n+grid_handle_call_in_distribute (gimple_stmt_iterator *gsi)\n+{\n+  gimple *stmt = gsi_stmt (*gsi);\n+  tree fndecl = gimple_call_fndecl (stmt);\n+  gcc_checking_assert (stmt);\n+  if (DECL_PURE_P (fndecl) || TREE_READONLY (fndecl))\n+    return false;\n+\n+  const char *name = IDENTIFIER_POINTER (DECL_NAME (fndecl));\n+  if ((strcmp (name, \"omp_get_thread_num\") == 0)\n+      || (strcmp (name, \"omp_get_level\") == 0)\n+      || (strcmp (name, \"omp_get_active_level\") == 0)\n+      || (strcmp (name, \"omp_in_parallel\") == 0))\n+    {\n+      tree lhs = gimple_call_lhs (stmt);\n+      if (lhs)\n+\t{\n+\t  gassign *assign\n+\t    = gimple_build_assign (lhs, build_zero_cst (TREE_TYPE (lhs)));\n+\t  gsi_insert_before (gsi, assign, GSI_SAME_STMT);\n+\t}\n+      gsi_remove (gsi, true);\n+      return true;\n+    }\n+\n+  /* The rest of the omp functions can stay as they are, HSA back-end will\n+     handle them correctly.  */\n+  gcc_checking_assert ((strcmp (name, \"omp_get_num_threads\") == 0)\n+\t\t       || (strcmp (name, \"omp_get_num_teams\") == 0)\n+\t\t       || (strcmp (name, \"omp_get_team_num\") == 0));\n+  return false;\n+}\n+\n+/* Given a sequence of statements within a distribute omp construct or a\n+   parallel construct, which in the original source does not form a compound\n+   construct with a looping construct, return true if it does not prevent us\n+   from turning it into a gridified HSA kernel.  Otherwise return false. GRID\n+   describes hitherto discovered properties of the loop that is evaluated for\n+   possible gridification.  IN_PARALLEL must be true if seq is within a\n+   parallel construct and flase if it is only within a distribute\n+   construct.  */\n+\n+static bool\n+grid_dist_follows_tiling_pattern (gimple_seq seq, grid_prop *grid,\n+\t\t\t\t  bool in_parallel)\n+{\n+  gimple_stmt_iterator gsi;\n+  for (gsi = gsi_start (seq); !gsi_end_p (gsi); gsi_next (&gsi))\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+\n+      if (grid_safe_assignment_p (stmt, grid)\n+\t  || gimple_code (stmt) == GIMPLE_GOTO\n+\t  || gimple_code (stmt) == GIMPLE_LABEL\n+\t  || gimple_code (stmt) == GIMPLE_COND)\n+\tcontinue;\n+      else if (gbind *bind = dyn_cast <gbind *> (stmt))\n+\t{\n+\t  if (!grid_dist_follows_tiling_pattern (gimple_bind_body (bind),\n+\t\t\t\t\t\t grid, in_parallel))\n+\t    return false;\n+\t  continue;\n+\t}\n+      else if (gtry *try_stmt = dyn_cast <gtry *> (stmt))\n+\t{\n+\t  if (gimple_try_kind (try_stmt) == GIMPLE_TRY_CATCH)\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\t{\n+\t\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t\t   GRID_MISSED_MSG_PREFIX \"the distribute \"\n+\t\t\t\t   \"construct contains a try..catch region\\n\");\n+\t\t  dump_printf_loc (MSG_NOTE, gimple_location (try_stmt),\n+\t\t\t\t   \"This statement cannot be analyzed for \"\n+\t\t\t\t   \"tiled gridification\\n\");\n+\t\t}\n+\t      return false;\n+\t    }\n+\t  if (!grid_dist_follows_tiling_pattern (gimple_try_eval (try_stmt),\n+\t\t\t\t\t\t grid, in_parallel))\n+\t    return false;\n+\t  if (!grid_dist_follows_tiling_pattern (gimple_try_cleanup (try_stmt),\n+\t\t\t\t\t\t grid, in_parallel))\n+\t    return false;\n+\t  continue;\n+\t}\n+      else if (is_gimple_call (stmt))\n+\t{\n+\t  tree fndecl = gimple_call_fndecl (stmt);\n+\t  if (fndecl && grid_call_permissible_in_distribute_p (fndecl))\n+\t    continue;\n+\n+\t  if (dump_enabled_p ())\n+\t    {\n+\t      dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"the distribute \"\n+\t\t\t       \"construct contains a call\\n\");\n+\t      dump_printf_loc (MSG_NOTE, gimple_location (stmt),\n+\t\t\t       \"This statement cannot be analyzed for \"\n+\t\t\t       \"tiled gridification\\n\");\n+\t    }\n+\t  return false;\n+\t}\n+      else if (gomp_parallel *par = dyn_cast <gomp_parallel *> (stmt))\n+\t{\n+\t  if (in_parallel)\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\t{\n+\t\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t\t   GRID_MISSED_MSG_PREFIX \"a parallel \"\n+\t\t\t\t   \"construct contains another parallel \"\n+\t\t\t\t   \"construct\\n\");\n+\t\t  dump_printf_loc (MSG_NOTE, gimple_location (stmt),\n+\t\t\t\t   \"This parallel construct is nested in \"\n+\t\t\t\t   \"another one\\n\");\n+\t\t}\n+\t      return false;\n+\t    }\n+\t  if (!grid_parallel_clauses_gridifiable (par, grid->target_loc)\n+\t      || !grid_dist_follows_tiling_pattern (gimple_omp_body (par),\n+\t\t\t\t\t\t    grid, true))\n+\t    return false;\n+\t}\n+      else if (gomp_for *gfor = dyn_cast <gomp_for *> (stmt))\n+\t{\n+\t  if (!in_parallel)\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\t{\n+\t\t  dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t\t   GRID_MISSED_MSG_PREFIX \"a loop \"\n+\t\t\t\t   \"construct is not nested within a parallel \"\n+\t\t\t\t   \"construct\\n\");\n+\t\t  dump_printf_loc (MSG_NOTE, gimple_location (stmt),\n+\t\t\t\t   \"This loop construct is not nested in \"\n+\t\t\t\t   \"a parallel construct\\n\");\n+\t\t}\n+\t      return false;\n+\t    }\n+\t  if (!grid_gfor_follows_tiling_pattern (gfor, grid))\n+\t    return false;\n+\t}\n+      else\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    {\n+\t      dump_printf_loc (MSG_MISSED_OPTIMIZATION, grid->target_loc,\n+\t\t\t       GRID_MISSED_MSG_PREFIX \"the distribute \"\n+\t\t\t       \"construct contains a complex statement\\n\");\n+\t      dump_printf_loc (MSG_NOTE, gimple_location (stmt),\n+\t\t\t       \"This statement cannot be analyzed for \"\n+\t\t\t       \"tiled gridification\\n\");\n+\t    }\n+\t  return false;\n+\t}\n+    }\n+    return true;\n+}\n+\n+/* If TARGET follows a pattern that can be turned into a gridified HSA kernel,\n+   return true, otherwise return false.  In the case of success, also fill in\n+   GRID with information describing the kernel grid.  */\n+\n+static bool\n+grid_target_follows_gridifiable_pattern (gomp_target *target, grid_prop *grid)\n+{\n+  if (gimple_omp_target_kind (target) != GF_OMP_TARGET_KIND_REGION)\n+    return false;\n+\n+  location_t tloc = gimple_location (target);\n+  grid->target_loc = tloc;\n+  gimple *stmt\n+    = grid_find_single_omp_among_assignments (gimple_omp_body (target),\n+\t\t\t\t\t      grid, \"target\");\n+  if (!stmt)\n+    return false;\n+  gomp_teams *teams = dyn_cast <gomp_teams *> (stmt);\n+  tree group_size = NULL;\n+  if (!teams)\n+    {\n+      dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t       GRID_MISSED_MSG_PREFIX \"it does not have a sole teams \"\n+\t\t       \"construct in it.\\n\");\n+      return false;\n+    }\n+\n+  tree clauses = gimple_omp_teams_clauses (teams);\n+  while (clauses)\n+    {\n+      switch (OMP_CLAUSE_CODE (clauses))\n+\t{\n+\tcase OMP_CLAUSE_NUM_TEAMS:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t     GRID_MISSED_MSG_PREFIX \"the teams construct \"\n+\t\t\t     \"contains a num_teams clause\\n \");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_REDUCTION:\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t     GRID_MISSED_MSG_PREFIX \"a reduction \"\n+\t\t\t     \"clause is present\\n \");\n+\t  return false;\n+\n+\tcase OMP_CLAUSE_THREAD_LIMIT:\n+\t  if (!integer_zerop (OMP_CLAUSE_OPERAND (clauses, 0)))\n+\t    group_size = OMP_CLAUSE_OPERAND (clauses, 0);\n+\t  break;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      clauses = OMP_CLAUSE_CHAIN (clauses);\n+    }\n+\n+  stmt = grid_find_single_omp_among_assignments (gimple_omp_body (teams), grid,\n+\t\t\t\t\t\t \"teams\");\n+  if (!stmt)\n+    return false;\n+  gomp_for *dist = dyn_cast <gomp_for *> (stmt);\n+  if (!dist)\n+    {\n+      dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t       GRID_MISSED_MSG_PREFIX \"the teams construct does not \"\n+\t\t       \"have a single distribute construct in it.\\n\");\n+      return false;\n+    }\n+\n+  gcc_assert (gimple_omp_for_kind (dist) == GF_OMP_FOR_KIND_DISTRIBUTE);\n+\n+  grid->collapse = gimple_omp_for_collapse (dist);\n+  if (grid->collapse > 3)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t GRID_MISSED_MSG_PREFIX \"the distribute construct \"\n+\t\t\t \"contains collapse clause with parameter greater \"\n+\t\t\t \"than 3\\n\");\n+      return false;\n+    }\n+\n+  struct omp_for_data fd;\n+  struct omp_for_data_loop *dist_loops\n+    = (struct omp_for_data_loop *)alloca (grid->collapse\n+\t\t\t\t\t  * sizeof (struct omp_for_data_loop));\n+  omp_extract_for_data (dist, &fd, dist_loops);\n+  if (fd.chunk_size)\n+    {\n+      if (group_size && !operand_equal_p (group_size, fd.chunk_size, 0))\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t     GRID_MISSED_MSG_PREFIX \"the teams \"\n+\t\t\t     \"thread limit is different from distribute \"\n+\t\t\t     \"schedule chunk\\n\");\n+\t  return false;\n+\t}\n+      group_size = fd.chunk_size;\n+    }\n+  if (group_size && grid->collapse > 1)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t GRID_MISSED_MSG_PREFIX \"group size cannot be \"\n+\t\t\t \"set using thread_limit or schedule clauses \"\n+\t\t\t \"when also using a collapse clause greater than 1\\n\");\n+      return false;\n+    }\n+\n+  if (gimple_omp_for_combined_p (dist))\n+    {\n+      grid->tiling = false;\n+      grid->group_sizes[0] = group_size;\n+      for (unsigned i = 1; i < grid->collapse; i++)\n+\tgrid->group_sizes[i] = NULL;\n+      return grid_dist_follows_simple_pattern (dist, grid);\n+    }\n+  else\n+    {\n+      grid->tiling = true;\n+      if (group_size)\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, tloc,\n+\t\t\t     GRID_MISSED_MSG_PREFIX \"group size cannot be set \"\n+\t\t\t     \"using thread_limit or schedule clauses when \"\n+\t\t\t     \"distribute and loop constructs do not form \"\n+\t\t\t     \"one combined construct\\n\");\n+\t  return false;\n+\t}\n+      for (unsigned i = 0; i < grid->collapse; i++)\n+\t{\n+\t  if (fd.loops[i].cond_code == GT_EXPR)\n+\t    grid->group_sizes[i] = fold_build1 (NEGATE_EXPR,\n+\t\t\t\t\t\tTREE_TYPE (fd.loops[i].step),\n+\t\t\t\t\t\tfd.loops[i].step);\n+\t  else\n+\t    grid->group_sizes[i] = fd.loops[i].step;\n+\t}\n+      return grid_dist_follows_tiling_pattern (gimple_omp_body (dist), grid,\n+\t\t\t\t\t       false);\n+    }\n+}\n+\n+/* Operand walker, used to remap pre-body declarations according to a hash map\n+   provided in DATA.  */\n+\n+static tree\n+grid_remap_prebody_decls (tree *tp, int *walk_subtrees, void *data)\n+{\n+  tree t = *tp;\n+\n+  if (DECL_P (t) || TYPE_P (t))\n+    *walk_subtrees = 0;\n+  else\n+    *walk_subtrees = 1;\n+\n+  if (VAR_P (t))\n+    {\n+      struct walk_stmt_info *wi = (struct walk_stmt_info *) data;\n+      hash_map<tree, tree> *declmap = (hash_map<tree, tree> *) wi->info;\n+      tree *repl = declmap->get (t);\n+      if (repl)\n+\t*tp = *repl;\n+    }\n+  return NULL_TREE;\n+}\n+\n+/* Identifiers of segments into which a particular variable should be places\n+   when gridifying.  */\n+\n+enum grid_var_segment {GRID_SEGMENT_PRIVATE, GRID_SEGMENT_GROUP,\n+\t\t       GRID_SEGMENT_GLOBAL};\n+\n+/* Mark VAR so that it is eventually placed into SEGMENT.  Place an artificial\n+   builtin call into SEQ that will make sure the variable is always considered\n+   address taken.  */\n+\n+static void\n+grid_mark_variable_segment (tree var, enum grid_var_segment segment)\n+{\n+  /* Making a non-addressable variables would require that we re-gimplify all\n+     their uses.  Fortunately, we do not have to do this because if they are\n+     not addressable, it means they are not used in atomic or parallel\n+     statements and so relaxed GPU consistency rules mean we can just keep them\n+     private. */\n+  if (!TREE_ADDRESSABLE (var))\n+    return;\n+\n+  switch (segment)\n+    {\n+    case GRID_SEGMENT_GROUP:\n+      DECL_ATTRIBUTES (var) = tree_cons (get_identifier (\"hsa_group_segment\"),\n+\t\t\t\t\t NULL, DECL_ATTRIBUTES (var));\n+      break;\n+    case GRID_SEGMENT_GLOBAL:\n+      DECL_ATTRIBUTES (var) = tree_cons (get_identifier (\"hsa_global_segment\"),\n+\t\t\t\t\t NULL, DECL_ATTRIBUTES (var));\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  if (!TREE_STATIC (var))\n+    {\n+      TREE_STATIC (var) = 1;\n+      varpool_node::finalize_decl (var);\n+    }\n+\n+}\n+\n+/* Copy leading register-type assignments to local variables in SRC to just\n+   before DST, Creating temporaries, adjusting mapping of operands in WI and\n+   remapping operands as necessary.  Add any new temporaries to TGT_BIND.\n+   Return the first statement that does not conform to grid_safe_assignment_p\n+   or NULL.  If VAR_SEGMENT is not GRID_SEGMENT_PRIVATE, also mark all\n+   variables in traversed bind statements so that they are put into the\n+   appropriate segment.  */\n+\n+static gimple *\n+grid_copy_leading_local_assignments (gimple_seq src, gimple_stmt_iterator *dst,\n+\t\t\t\t     gbind *tgt_bind,\n+\t\t\t\t     enum grid_var_segment var_segment,\n+\t\t\t\t     struct walk_stmt_info *wi)\n+{\n+  hash_map<tree, tree> *declmap = (hash_map<tree, tree> *) wi->info;\n+  gimple_stmt_iterator gsi;\n+  for (gsi = gsi_start (src); !gsi_end_p (gsi); gsi_next (&gsi))\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+      if (gbind *bind = dyn_cast <gbind *> (stmt))\n+\t{\n+\t  gimple *r = grid_copy_leading_local_assignments\n+\t    (gimple_bind_body (bind), dst, tgt_bind, var_segment, wi);\n+\n+\t  if (var_segment != GRID_SEGMENT_PRIVATE)\n+\t    for (tree var = gimple_bind_vars (bind); var; var = DECL_CHAIN (var))\n+\t      grid_mark_variable_segment (var, var_segment);\n+\t  if (r)\n+\t    return r;\n+\t  else\n+\t    continue;\n+\t}\n+      if (!grid_safe_assignment_p (stmt, NULL))\n+\treturn stmt;\n+      tree lhs = gimple_assign_lhs (as_a <gassign *> (stmt));\n+      tree repl = copy_var_decl (lhs, create_tmp_var_name (NULL),\n+\t\t\t\t TREE_TYPE (lhs));\n+      DECL_CONTEXT (repl) = current_function_decl;\n+      gimple_bind_append_vars (tgt_bind, repl);\n+\n+      declmap->put (lhs, repl);\n+      gassign *copy = as_a <gassign *> (gimple_copy (stmt));\n+      walk_gimple_op (copy, grid_remap_prebody_decls, wi);\n+      gsi_insert_before (dst, copy, GSI_SAME_STMT);\n+    }\n+  return NULL;\n+}\n+\n+/* Statement walker function to make adjustments to statements within the\n+   gridifed kernel copy.  */\n+\n+static tree\n+grid_process_grid_body (gimple_stmt_iterator *gsi, bool *handled_ops_p,\n+\t\t\tstruct walk_stmt_info *)\n+{\n+  *handled_ops_p = false;\n+  gimple *stmt = gsi_stmt (*gsi);\n+  if (gimple_code (stmt) == GIMPLE_OMP_FOR\n+      && (gimple_omp_for_kind (stmt) & GF_OMP_FOR_SIMD))\n+  {\n+    gomp_for *loop = as_a <gomp_for *> (stmt);\n+    tree clauses = gimple_omp_for_clauses (loop);\n+    tree cl = omp_find_clause (clauses, OMP_CLAUSE_SAFELEN);\n+    if (cl)\n+      OMP_CLAUSE_SAFELEN_EXPR (cl) = integer_one_node;\n+    else\n+      {\n+\ttree c = build_omp_clause (UNKNOWN_LOCATION, OMP_CLAUSE_SAFELEN);\n+\tOMP_CLAUSE_SAFELEN_EXPR (c) = integer_one_node;\n+\tOMP_CLAUSE_CHAIN (c) = clauses;\n+\tgimple_omp_for_set_clauses (loop, c);\n+      }\n+  }\n+  return NULL_TREE;\n+}\n+\n+/* Given a PARLOOP that is a normal for looping construct but also a part of a\n+   combined construct with a simd loop, eliminate the simd loop.  */\n+\n+static void\n+grid_eliminate_combined_simd_part (gomp_for *parloop)\n+{\n+  struct walk_stmt_info wi;\n+\n+  memset (&wi, 0, sizeof (wi));\n+  wi.val_only = true;\n+  enum gf_mask msk = GF_OMP_FOR_SIMD;\n+  wi.info = (void *) &msk;\n+  walk_gimple_seq (gimple_omp_body (parloop), omp_find_combined_for, NULL, &wi);\n+  gimple *stmt = (gimple *) wi.info;\n+  /* We expect that the SIMD id the only statement in the parallel loop.  */\n+  gcc_assert (stmt\n+\t      && gimple_code (stmt) == GIMPLE_OMP_FOR\n+\t      && (gimple_omp_for_kind (stmt) == GF_OMP_FOR_SIMD)\n+\t      && gimple_omp_for_combined_into_p (stmt)\n+\t      && !gimple_omp_for_combined_p (stmt));\n+  gomp_for *simd = as_a <gomp_for *> (stmt);\n+\n+  /* Copy over the iteration properties because the body refers to the index in\n+     the bottmom-most loop.  */\n+  unsigned i, collapse = gimple_omp_for_collapse (parloop);\n+  gcc_checking_assert (collapse == gimple_omp_for_collapse (simd));\n+  for (i = 0; i < collapse; i++)\n+    {\n+      gimple_omp_for_set_index (parloop, i, gimple_omp_for_index (simd, i));\n+      gimple_omp_for_set_initial (parloop, i, gimple_omp_for_initial (simd, i));\n+      gimple_omp_for_set_final (parloop, i, gimple_omp_for_final (simd, i));\n+      gimple_omp_for_set_incr (parloop, i, gimple_omp_for_incr (simd, i));\n+    }\n+\n+  tree *tgt= gimple_omp_for_clauses_ptr (parloop);\n+  while (*tgt)\n+    tgt = &OMP_CLAUSE_CHAIN (*tgt);\n+\n+  /* Copy over all clauses, except for linaer clauses, which are turned into\n+     private clauses, and all other simd-specificl clauses, which are\n+     ignored.  */\n+  tree *pc = gimple_omp_for_clauses_ptr (simd);\n+  while (*pc)\n+    {\n+      tree c = *pc;\n+      switch (TREE_CODE (c))\n+\t{\n+\tcase OMP_CLAUSE_LINEAR:\n+\t  {\n+\t    tree priv = build_omp_clause (UNKNOWN_LOCATION, OMP_CLAUSE_PRIVATE);\n+\t    OMP_CLAUSE_DECL (priv) = OMP_CLAUSE_DECL (c);\n+\t    OMP_CLAUSE_CHAIN (priv) = NULL;\n+\t    *tgt = priv;\n+\t    tgt = &OMP_CLAUSE_CHAIN (priv);\n+\t    pc = &OMP_CLAUSE_CHAIN (c);\n+\t    break;\n+\t  }\n+\n+\tcase OMP_CLAUSE_SAFELEN:\n+\tcase OMP_CLAUSE_SIMDLEN:\n+\tcase OMP_CLAUSE_ALIGNED:\n+\t  pc = &OMP_CLAUSE_CHAIN (c);\n+\t  break;\n+\n+\tdefault:\n+\t  *pc = OMP_CLAUSE_CHAIN (c);\n+\t  OMP_CLAUSE_CHAIN (c) = NULL;\n+\t  *tgt = c;\n+\t  tgt = &OMP_CLAUSE_CHAIN(c);\n+\t  break;\n+\t}\n+    }\n+\n+  /* Finally, throw away the simd and mark the parallel loop as not\n+     combined.  */\n+  gimple_omp_set_body (parloop, gimple_omp_body (simd));\n+  gimple_omp_for_set_combined_p (parloop, false);\n+}\n+\n+/* Statement walker function marking all parallels as grid_phony and loops as\n+   grid ones representing threads of a particular thread group.  */\n+\n+static tree\n+grid_mark_tiling_loops (gimple_stmt_iterator *gsi, bool *handled_ops_p,\n+\t\t\tstruct walk_stmt_info *wi_in)\n+{\n+  *handled_ops_p = false;\n+  if (gomp_for *loop = dyn_cast <gomp_for *> (gsi_stmt (*gsi)))\n+    {\n+      *handled_ops_p = true;\n+      gimple_omp_for_set_kind (loop, GF_OMP_FOR_KIND_GRID_LOOP);\n+      gimple_omp_for_set_grid_intra_group (loop, true);\n+      if (gimple_omp_for_combined_p (loop))\n+\tgrid_eliminate_combined_simd_part (loop);\n+\n+      struct walk_stmt_info body_wi;\n+      memset (&body_wi, 0, sizeof (body_wi));\n+      walk_gimple_seq_mod (gimple_omp_body_ptr (loop),\n+\t\t\t   grid_process_grid_body, NULL, &body_wi);\n+\n+      gbind *bind = (gbind *) wi_in->info;\n+      tree c;\n+      for (c = gimple_omp_for_clauses (loop); c; c = OMP_CLAUSE_CHAIN (c))\n+\tif (OMP_CLAUSE_CODE (c) == OMP_CLAUSE_LASTPRIVATE)\n+\t  {\n+\t    push_gimplify_context ();\n+\t    tree ov = OMP_CLAUSE_DECL (c);\n+\t    tree gv = copy_var_decl (ov, create_tmp_var_name (NULL),\n+\t\t\t\t    TREE_TYPE (ov));\n+\n+\t    grid_mark_variable_segment (gv, GRID_SEGMENT_GROUP);\n+\t    DECL_CONTEXT (gv) = current_function_decl;\n+\t    gimple_bind_append_vars (bind, gv);\n+\t    tree x = lang_hooks.decls.omp_clause_assign_op (c, gv, ov);\n+\t    gimplify_and_add (x, &OMP_CLAUSE_LASTPRIVATE_GIMPLE_SEQ (c));\n+\t    x = lang_hooks.decls.omp_clause_copy_ctor (c, ov, gv);\n+\t    gimple_seq l = NULL;\n+\t    gimplify_and_add (x, &l);\n+\t    gsi_insert_seq_after (gsi, l, GSI_SAME_STMT);\n+\t    pop_gimplify_context (bind);\n+\t  }\n+    }\n+  return NULL_TREE;\n+}\n+\n+/* Statement walker function marking all parallels as grid_phony and loops as\n+   grid ones representing threads of a particular thread group.  */\n+\n+static tree\n+grid_mark_tiling_parallels_and_loops (gimple_stmt_iterator *gsi,\n+\t\t\t\t      bool *handled_ops_p,\n+\t\t\t\t      struct walk_stmt_info *wi_in)\n+{\n+  *handled_ops_p = false;\n+  wi_in->removed_stmt = false;\n+  gimple *stmt = gsi_stmt (*gsi);\n+  if (gbind *bind = dyn_cast <gbind *> (stmt))\n+    {\n+      for (tree var = gimple_bind_vars (bind); var; var = DECL_CHAIN (var))\n+\tgrid_mark_variable_segment (var, GRID_SEGMENT_GROUP);\n+    }\n+  else if (gomp_parallel *parallel = dyn_cast <gomp_parallel *> (stmt))\n+    {\n+      *handled_ops_p = true;\n+      gimple_omp_parallel_set_grid_phony (parallel, true);\n+\n+      gbind *new_bind = gimple_build_bind (NULL, NULL, make_node (BLOCK));\n+      gimple_bind_set_body (new_bind, gimple_omp_body (parallel));\n+      gimple_seq s = NULL;\n+      gimple_seq_add_stmt (&s, new_bind);\n+      gimple_omp_set_body (parallel, s);\n+\n+      struct walk_stmt_info wi_par;\n+      memset (&wi_par, 0, sizeof (wi_par));\n+      wi_par.info = new_bind;\n+      walk_gimple_seq_mod (gimple_bind_body_ptr (new_bind),\n+\t\t\t   grid_mark_tiling_loops, NULL, &wi_par);\n+    }\n+  else if (is_a <gcall *> (stmt))\n+    wi_in->removed_stmt = grid_handle_call_in_distribute (gsi);\n+  return NULL_TREE;\n+}\n+\n+/* Given freshly copied top level kernel SEQ, identify the individual OMP\n+   components, mark them as part of kernel, copy assignment leading to them\n+   just before DST, remapping them using WI and adding new temporaries to\n+   TGT_BIND, and and return the loop that will be used for kernel dispatch.  */\n+\n+static gomp_for *\n+grid_process_kernel_body_copy (grid_prop *grid, gimple_seq seq,\n+\t\t\t       gimple_stmt_iterator *dst,\n+\t\t\t       gbind *tgt_bind, struct walk_stmt_info *wi)\n+{\n+  gimple *stmt = grid_copy_leading_local_assignments (seq, dst, tgt_bind,\n+\t\t\t\t\t\t      GRID_SEGMENT_GLOBAL, wi);\n+  gomp_teams *teams = dyn_cast <gomp_teams *> (stmt);\n+  gcc_assert (teams);\n+  gimple_omp_teams_set_grid_phony (teams, true);\n+  stmt = grid_copy_leading_local_assignments (gimple_omp_body (teams), dst,\n+\t\t\t\t\t      tgt_bind, GRID_SEGMENT_GLOBAL, wi);\n+  gcc_checking_assert (stmt);\n+  gomp_for *dist = dyn_cast <gomp_for *> (stmt);\n+  gcc_assert (dist);\n+  gimple_seq prebody = gimple_omp_for_pre_body (dist);\n+  if (prebody)\n+    grid_copy_leading_local_assignments (prebody, dst, tgt_bind,\n+\t\t\t\t\t GRID_SEGMENT_GROUP, wi);\n+\n+  if (grid->tiling)\n+    {\n+      gimple_omp_for_set_kind (dist, GF_OMP_FOR_KIND_GRID_LOOP);\n+      gimple_omp_for_set_grid_group_iter (dist, true);\n+\n+      struct walk_stmt_info wi_tiled;\n+      memset (&wi_tiled, 0, sizeof (wi_tiled));\n+      walk_gimple_seq_mod (gimple_omp_body_ptr (dist),\n+\t\t\t   grid_mark_tiling_parallels_and_loops, NULL,\n+\t\t\t   &wi_tiled);\n+      return dist;\n+    }\n+  else\n+    {\n+      gimple_omp_for_set_grid_phony (dist, true);\n+      stmt = grid_copy_leading_local_assignments (gimple_omp_body (dist), dst,\n+\t\t\t\t\t\t  tgt_bind,\n+\t\t\t\t\t\t  GRID_SEGMENT_PRIVATE, wi);\n+      gcc_checking_assert (stmt);\n+      gomp_parallel *parallel = as_a <gomp_parallel *> (stmt);\n+      gimple_omp_parallel_set_grid_phony (parallel, true);\n+      stmt = grid_copy_leading_local_assignments (gimple_omp_body (parallel),\n+\t\t\t\t\t\t  dst, tgt_bind,\n+\t\t\t\t\t\t  GRID_SEGMENT_PRIVATE, wi);\n+      gomp_for *inner_loop = as_a <gomp_for *> (stmt);\n+      gimple_omp_for_set_kind (inner_loop, GF_OMP_FOR_KIND_GRID_LOOP);\n+      prebody = gimple_omp_for_pre_body (inner_loop);\n+      if (prebody)\n+\tgrid_copy_leading_local_assignments (prebody, dst, tgt_bind,\n+\t\t\t\t\t     GRID_SEGMENT_PRIVATE, wi);\n+\n+      if (gimple_omp_for_combined_p (inner_loop))\n+\tgrid_eliminate_combined_simd_part (inner_loop);\n+      struct walk_stmt_info body_wi;;\n+      memset (&body_wi, 0, sizeof (body_wi));\n+      walk_gimple_seq_mod (gimple_omp_body_ptr (inner_loop),\n+\t\t\t   grid_process_grid_body, NULL, &body_wi);\n+\n+      return inner_loop;\n+    }\n+}\n+\n+/* If TARGET points to a GOMP_TARGET which follows a gridifiable pattern,\n+   create a GPU kernel for it.  GSI must point to the same statement, TGT_BIND\n+   is the bind into which temporaries inserted before TARGET should be\n+   added.  */\n+\n+static void\n+grid_attempt_target_gridification (gomp_target *target,\n+\t\t\t\t   gimple_stmt_iterator *gsi,\n+\t\t\t\t   gbind *tgt_bind)\n+{\n+  /* removed group_size */\n+  grid_prop grid;\n+  memset (&grid, 0, sizeof (grid));\n+  if (!target || !grid_target_follows_gridifiable_pattern (target, &grid))\n+    return;\n+\n+  location_t loc = gimple_location (target);\n+  if (dump_enabled_p ())\n+    dump_printf_loc (MSG_OPTIMIZED_LOCATIONS, loc,\n+\t\t     \"Target construct will be turned into a gridified HSA \"\n+\t\t     \"kernel\\n\");\n+\n+  /* Copy target body to a GPUKERNEL construct:  */\n+  gimple_seq kernel_seq = copy_gimple_seq_and_replace_locals\n+    (gimple_omp_body (target));\n+\n+  hash_map<tree, tree> *declmap = new hash_map<tree, tree>;\n+  struct walk_stmt_info wi;\n+  memset (&wi, 0, sizeof (struct walk_stmt_info));\n+  wi.info = declmap;\n+\n+  /* Copy assignments in between OMP statements before target, mark OMP\n+     statements within copy appropriately.  */\n+  gomp_for *inner_loop = grid_process_kernel_body_copy (&grid, kernel_seq, gsi,\n+\t\t\t\t\t\t\ttgt_bind, &wi);\n+\n+  gbind *old_bind = as_a <gbind *> (gimple_seq_first (gimple_omp_body (target)));\n+  gbind *new_bind = as_a <gbind *> (gimple_seq_first (kernel_seq));\n+  tree new_block = gimple_bind_block (new_bind);\n+  tree enc_block = BLOCK_SUPERCONTEXT (gimple_bind_block (old_bind));\n+  BLOCK_CHAIN (new_block) = BLOCK_SUBBLOCKS (enc_block);\n+  BLOCK_SUBBLOCKS (enc_block) = new_block;\n+  BLOCK_SUPERCONTEXT (new_block) = enc_block;\n+  gimple *gpukernel = gimple_build_omp_grid_body (kernel_seq);\n+  gimple_seq_add_stmt\n+    (gimple_bind_body_ptr (as_a <gbind *> (gimple_omp_body (target))),\n+     gpukernel);\n+\n+  for (size_t i = 0; i < grid.collapse; i++)\n+    walk_tree (&grid.group_sizes[i], grid_remap_prebody_decls, &wi, NULL);\n+  push_gimplify_context ();\n+  for (size_t i = 0; i < grid.collapse; i++)\n+    {\n+      tree itype, type = TREE_TYPE (gimple_omp_for_index (inner_loop, i));\n+      if (POINTER_TYPE_P (type))\n+\titype = signed_type_for (type);\n+      else\n+\titype = type;\n+\n+      enum tree_code cond_code = gimple_omp_for_cond (inner_loop, i);\n+      tree n1 = unshare_expr (gimple_omp_for_initial (inner_loop, i));\n+      walk_tree (&n1, grid_remap_prebody_decls, &wi, NULL);\n+      tree n2 = unshare_expr (gimple_omp_for_final (inner_loop, i));\n+      walk_tree (&n2, grid_remap_prebody_decls, &wi, NULL);\n+      omp_adjust_for_condition (loc, &cond_code, &n2);\n+      n1 = fold_convert (itype, n1);\n+      n2 = fold_convert (itype, n2);\n+\n+      tree step\n+\t= omp_get_for_step_from_incr (loc, gimple_omp_for_incr (inner_loop, i));\n+\n+      tree t = build_int_cst (itype, (cond_code == LT_EXPR ? -1 : 1));\n+      t = fold_build2 (PLUS_EXPR, itype, step, t);\n+      t = fold_build2 (PLUS_EXPR, itype, t, n2);\n+      t = fold_build2 (MINUS_EXPR, itype, t, n1);\n+      if (TYPE_UNSIGNED (itype) && cond_code == GT_EXPR)\n+\tt = fold_build2 (TRUNC_DIV_EXPR, itype,\n+\t\t\t fold_build1 (NEGATE_EXPR, itype, t),\n+\t\t\t fold_build1 (NEGATE_EXPR, itype, step));\n+      else\n+\tt = fold_build2 (TRUNC_DIV_EXPR, itype, t, step);\n+      if (grid.tiling)\n+        {\n+          if (cond_code == GT_EXPR)\n+            step = fold_build1 (NEGATE_EXPR, itype, step);\n+          t = fold_build2 (MULT_EXPR, itype, t, step);\n+        }\n+\n+      tree gs = fold_convert (uint32_type_node, t);\n+      gimple_seq tmpseq = NULL;\n+      gimplify_expr (&gs, &tmpseq, NULL, is_gimple_val, fb_rvalue);\n+      if (!gimple_seq_empty_p (tmpseq))\n+\tgsi_insert_seq_before (gsi, tmpseq, GSI_SAME_STMT);\n+\n+      tree ws;\n+      if (grid.group_sizes[i])\n+\t{\n+\t  ws = fold_convert (uint32_type_node, grid.group_sizes[i]);\n+\t  tmpseq = NULL;\n+\t  gimplify_expr (&ws, &tmpseq, NULL, is_gimple_val, fb_rvalue);\n+\t  if (!gimple_seq_empty_p (tmpseq))\n+\t    gsi_insert_seq_before (gsi, tmpseq, GSI_SAME_STMT);\n+\t}\n+      else\n+\tws = build_zero_cst (uint32_type_node);\n+\n+      tree c = build_omp_clause (UNKNOWN_LOCATION, OMP_CLAUSE__GRIDDIM_);\n+      OMP_CLAUSE__GRIDDIM__DIMENSION (c) = i;\n+      OMP_CLAUSE__GRIDDIM__SIZE (c) = gs;\n+      OMP_CLAUSE__GRIDDIM__GROUP (c) = ws;\n+      OMP_CLAUSE_CHAIN (c) = gimple_omp_target_clauses (target);\n+      gimple_omp_target_set_clauses (target, c);\n+    }\n+  pop_gimplify_context (tgt_bind);\n+  delete declmap;\n+  return;\n+}\n+\n+/* Walker function doing all the work for create_target_kernels. */\n+\n+static tree\n+grid_gridify_all_targets_stmt (gimple_stmt_iterator *gsi,\n+\t\t\t\t   bool *handled_ops_p,\n+\t\t\t\t   struct walk_stmt_info *incoming)\n+{\n+  *handled_ops_p = false;\n+\n+  gimple *stmt = gsi_stmt (*gsi);\n+  gomp_target *target = dyn_cast <gomp_target *> (stmt);\n+  if (target)\n+    {\n+      gbind *tgt_bind = (gbind *) incoming->info;\n+      gcc_checking_assert (tgt_bind);\n+      grid_attempt_target_gridification (target, gsi, tgt_bind);\n+      return NULL_TREE;\n+    }\n+  gbind *bind = dyn_cast <gbind *> (stmt);\n+  if (bind)\n+    {\n+      *handled_ops_p = true;\n+      struct walk_stmt_info wi;\n+      memset (&wi, 0, sizeof (wi));\n+      wi.info = bind;\n+      walk_gimple_seq_mod (gimple_bind_body_ptr (bind),\n+\t\t\t   grid_gridify_all_targets_stmt, NULL, &wi);\n+    }\n+  return NULL_TREE;\n+}\n+\n+/* Attempt to gridify all target constructs in BODY_P.  All such targets will\n+   have their bodies duplicated, with the new copy being put into a\n+   gimple_omp_grid_body statement.  All kernel-related construct within the\n+   grid_body will be marked with phony flags or kernel kinds.  Moreover, some\n+   re-structuring is often needed, such as copying pre-bodies before the target\n+   construct so that kernel grid sizes can be computed.  */\n+\n+void\n+omp_grid_gridify_all_targets (gimple_seq *body_p)\n+{\n+  struct walk_stmt_info wi;\n+  memset (&wi, 0, sizeof (wi));\n+  walk_gimple_seq_mod (body_p, grid_gridify_all_targets_stmt, NULL, &wi);\n+}"}, {"sha": "90a0d355007ac34ce81302fda80f83889b0934b6", "filename": "gcc/omp-grid.h", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-grid.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-grid.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-grid.h?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -0,0 +1,27 @@\n+/* Lowering and expansion of OpenMP directives for HSA GPU agents.\n+\n+   Copyright (C) 2013-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_OMP_GRID_H\n+#define GCC_OMP_GRID_H\n+\n+extern tree omp_grid_lastprivate_predicate (struct omp_for_data *fd);\n+extern void omp_grid_gridify_all_targets (gimple_seq *body_p);\n+\n+#endif /* GCC_OMP_GRID_H */"}, {"sha": "4fb59eb400f3f3facfc8844baefea5d97258b143", "filename": "gcc/omp-low.c", "status": "modified", "additions": 2979, "deletions": 14868, "changes": 17847, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-low.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-low.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-low.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9"}, {"sha": "687f357e454c7affaac83db4aa8d2cb42f738cf7", "filename": "gcc/omp-low.h", "status": "modified", "additions": 4, "deletions": 17, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-low.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-low.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-low.h?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -20,25 +20,12 @@ along with GCC; see the file COPYING3.  If not see\n #ifndef GCC_OMP_LOW_H\n #define GCC_OMP_LOW_H\n \n-struct omp_region;\n-\n-extern tree find_omp_clause (tree, enum omp_clause_code);\n-extern void omp_expand_local (basic_block);\n-extern void free_omp_regions (void);\n extern tree omp_reduction_init_op (location_t, enum tree_code, tree);\n extern tree omp_reduction_init (tree, tree);\n-extern bool make_gimple_omp_edges (basic_block, struct omp_region **, int *);\n-extern void omp_finish_file (void);\n extern tree omp_member_access_dummy_var (tree);\n-extern void replace_oacc_fn_attrib (tree, tree);\n-extern tree build_oacc_routine_dims (tree);\n-extern tree get_oacc_fn_attrib (tree);\n-extern void set_oacc_fn_attrib (tree, tree, bool, vec<tree> *);\n-extern bool oacc_fn_attrib_kernels_p (tree);\n-extern int get_oacc_ifn_dim_arg (const gimple *);\n-extern int get_oacc_fn_dim_size (tree, int);\n-\n-extern GTY(()) vec<tree, va_gc> *offload_funcs;\n-extern GTY(()) vec<tree, va_gc> *offload_vars;\n+extern tree omp_find_combined_for (gimple_stmt_iterator *gsi_p,\n+\t\t\t\t   bool *handled_ops_p,\n+\t\t\t\t   struct walk_stmt_info *wi);\n+\n \n #endif /* GCC_OMP_LOW_H */"}, {"sha": "fabdf2d21d93480844487b3b3dabe28305e8e348", "filename": "gcc/omp-offload.c", "status": "added", "additions": 1718, "deletions": 0, "changes": 1718, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-offload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-offload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-offload.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -0,0 +1,1718 @@\n+/* Bits of OpenMP and OpenACC handling that is specific to device offloading\n+   and a lowering pass for OpenACC device directives.\n+\n+   Copyright (C) 2005-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"target.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"tree-pass.h\"\n+#include \"ssa.h\"\n+#include \"cgraph.h\"\n+#include \"pretty-print.h\"\n+#include \"diagnostic-core.h\"\n+#include \"fold-const.h\"\n+#include \"internal-fn.h\"\n+#include \"gimplify.h\"\n+#include \"gimple-iterator.h\"\n+#include \"gimplify-me.h\"\n+#include \"gimple-walk.h\"\n+#include \"tree-cfg.h\"\n+#include \"tree-into-ssa.h\"\n+#include \"common/common-target.h\"\n+#include \"omp-general.h\"\n+#include \"omp-offload.h\"\n+#include \"lto-section-names.h\"\n+#include \"gomp-constants.h\"\n+#include \"gimple-pretty-print.h\"\n+\n+/* Describe the OpenACC looping structure of a function.  The entire\n+   function is held in a 'NULL' loop.  */\n+\n+struct oacc_loop\n+{\n+  oacc_loop *parent; /* Containing loop.  */\n+\n+  oacc_loop *child; /* First inner loop.  */\n+\n+  oacc_loop *sibling; /* Next loop within same parent.  */\n+\n+  location_t loc; /* Location of the loop start.  */\n+\n+  gcall *marker; /* Initial head marker.  */\n+\n+  gcall *heads[GOMP_DIM_MAX];  /* Head marker functions. */\n+  gcall *tails[GOMP_DIM_MAX];  /* Tail marker functions. */\n+\n+  tree routine;  /* Pseudo-loop enclosing a routine.  */\n+\n+  unsigned mask;   /* Partitioning mask.  */\n+  unsigned inner;  /* Partitioning of inner loops.  */\n+  unsigned flags;  /* Partitioning flags.  */\n+  unsigned ifns;   /* Contained loop abstraction functions.  */\n+  tree chunk_size; /* Chunk size.  */\n+  gcall *head_end; /* Final marker of head sequence.  */\n+};\n+\n+/* Holds offload tables with decls.  */\n+vec<tree, va_gc> *offload_funcs, *offload_vars;\n+\n+/* Return level at which oacc routine may spawn a partitioned loop, or\n+   -1 if it is not a routine (i.e. is an offload fn).  */\n+\n+static int\n+oacc_fn_attrib_level (tree attr)\n+{\n+  tree pos = TREE_VALUE (attr);\n+\n+  if (!TREE_PURPOSE (pos))\n+    return -1;\n+\n+  int ix = 0;\n+  for (ix = 0; ix != GOMP_DIM_MAX;\n+       ix++, pos = TREE_CHAIN (pos))\n+    if (!integer_zerop (TREE_PURPOSE (pos)))\n+      break;\n+\n+  return ix;\n+}\n+\n+/* Helper function for omp_finish_file routine.  Takes decls from V_DECLS and\n+   adds their addresses and sizes to constructor-vector V_CTOR.  */\n+\n+static void\n+add_decls_addresses_to_decl_constructor (vec<tree, va_gc> *v_decls,\n+\t\t\t\t\t vec<constructor_elt, va_gc> *v_ctor)\n+{\n+  unsigned len = vec_safe_length (v_decls);\n+  for (unsigned i = 0; i < len; i++)\n+    {\n+      tree it = (*v_decls)[i];\n+      bool is_var = VAR_P (it);\n+      bool is_link_var\n+\t= is_var\n+#ifdef ACCEL_COMPILER\n+\t  && DECL_HAS_VALUE_EXPR_P (it)\n+#endif\n+\t  && lookup_attribute (\"omp declare target link\", DECL_ATTRIBUTES (it));\n+\n+      tree size = NULL_TREE;\n+      if (is_var)\n+\tsize = fold_convert (const_ptr_type_node, DECL_SIZE_UNIT (it));\n+\n+      tree addr;\n+      if (!is_link_var)\n+\taddr = build_fold_addr_expr (it);\n+      else\n+\t{\n+#ifdef ACCEL_COMPILER\n+\t  /* For \"omp declare target link\" vars add address of the pointer to\n+\t     the target table, instead of address of the var.  */\n+\t  tree value_expr = DECL_VALUE_EXPR (it);\n+\t  tree link_ptr_decl = TREE_OPERAND (value_expr, 0);\n+\t  varpool_node::finalize_decl (link_ptr_decl);\n+\t  addr = build_fold_addr_expr (link_ptr_decl);\n+#else\n+\t  addr = build_fold_addr_expr (it);\n+#endif\n+\n+\t  /* Most significant bit of the size marks \"omp declare target link\"\n+\t     vars in host and target tables.  */\n+\t  unsigned HOST_WIDE_INT isize = tree_to_uhwi (size);\n+\t  isize |= 1ULL << (int_size_in_bytes (const_ptr_type_node)\n+\t\t\t    * BITS_PER_UNIT - 1);\n+\t  size = wide_int_to_tree (const_ptr_type_node, isize);\n+\t}\n+\n+      CONSTRUCTOR_APPEND_ELT (v_ctor, NULL_TREE, addr);\n+      if (is_var)\n+\tCONSTRUCTOR_APPEND_ELT (v_ctor, NULL_TREE, size);\n+    }\n+}\n+\n+/* Create new symbols containing (address, size) pairs for global variables,\n+   marked with \"omp declare target\" attribute, as well as addresses for the\n+   functions, which are outlined offloading regions.  */\n+void\n+omp_finish_file (void)\n+{\n+  unsigned num_funcs = vec_safe_length (offload_funcs);\n+  unsigned num_vars = vec_safe_length (offload_vars);\n+\n+  if (num_funcs == 0 && num_vars == 0)\n+    return;\n+\n+  if (targetm_common.have_named_sections)\n+    {\n+      vec<constructor_elt, va_gc> *v_f, *v_v;\n+      vec_alloc (v_f, num_funcs);\n+      vec_alloc (v_v, num_vars * 2);\n+\n+      add_decls_addresses_to_decl_constructor (offload_funcs, v_f);\n+      add_decls_addresses_to_decl_constructor (offload_vars, v_v);\n+\n+      tree vars_decl_type = build_array_type_nelts (pointer_sized_int_node,\n+\t\t\t\t\t\t    num_vars * 2);\n+      tree funcs_decl_type = build_array_type_nelts (pointer_sized_int_node,\n+\t\t\t\t\t\t     num_funcs);\n+      SET_TYPE_ALIGN (vars_decl_type, TYPE_ALIGN (pointer_sized_int_node));\n+      SET_TYPE_ALIGN (funcs_decl_type, TYPE_ALIGN (pointer_sized_int_node));\n+      tree ctor_v = build_constructor (vars_decl_type, v_v);\n+      tree ctor_f = build_constructor (funcs_decl_type, v_f);\n+      TREE_CONSTANT (ctor_v) = TREE_CONSTANT (ctor_f) = 1;\n+      TREE_STATIC (ctor_v) = TREE_STATIC (ctor_f) = 1;\n+      tree funcs_decl = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t    get_identifier (\".offload_func_table\"),\n+\t\t\t\t    funcs_decl_type);\n+      tree vars_decl = build_decl (UNKNOWN_LOCATION, VAR_DECL,\n+\t\t\t\t   get_identifier (\".offload_var_table\"),\n+\t\t\t\t   vars_decl_type);\n+      TREE_STATIC (funcs_decl) = TREE_STATIC (vars_decl) = 1;\n+      /* Do not align tables more than TYPE_ALIGN (pointer_sized_int_node),\n+\t otherwise a joint table in a binary will contain padding between\n+\t tables from multiple object files.  */\n+      DECL_USER_ALIGN (funcs_decl) = DECL_USER_ALIGN (vars_decl) = 1;\n+      SET_DECL_ALIGN (funcs_decl, TYPE_ALIGN (funcs_decl_type));\n+      SET_DECL_ALIGN (vars_decl, TYPE_ALIGN (vars_decl_type));\n+      DECL_INITIAL (funcs_decl) = ctor_f;\n+      DECL_INITIAL (vars_decl) = ctor_v;\n+      set_decl_section_name (funcs_decl, OFFLOAD_FUNC_TABLE_SECTION_NAME);\n+      set_decl_section_name (vars_decl, OFFLOAD_VAR_TABLE_SECTION_NAME);\n+\n+      varpool_node::finalize_decl (vars_decl);\n+      varpool_node::finalize_decl (funcs_decl);\n+    }\n+  else\n+    {\n+      for (unsigned i = 0; i < num_funcs; i++)\n+\t{\n+\t  tree it = (*offload_funcs)[i];\n+\t  targetm.record_offload_symbol (it);\n+\t}\n+      for (unsigned i = 0; i < num_vars; i++)\n+\t{\n+\t  tree it = (*offload_vars)[i];\n+\t  targetm.record_offload_symbol (it);\n+\t}\n+    }\n+}\n+\n+/* Find the number of threads (POS = false), or thread number (POS =\n+   true) for an OpenACC region partitioned as MASK.  Setup code\n+   required for the calculation is added to SEQ.  */\n+\n+static tree\n+oacc_thread_numbers (bool pos, int mask, gimple_seq *seq)\n+{\n+  tree res = pos ? NULL_TREE : build_int_cst (unsigned_type_node, 1);\n+  unsigned ix;\n+\n+  /* Start at gang level, and examine relevant dimension indices.  */\n+  for (ix = GOMP_DIM_GANG; ix != GOMP_DIM_MAX; ix++)\n+    if (GOMP_DIM_MASK (ix) & mask)\n+      {\n+\ttree arg = build_int_cst (unsigned_type_node, ix);\n+\n+\tif (res)\n+\t  {\n+\t    /* We had an outer index, so scale that by the size of\n+\t       this dimension.  */\n+\t    tree n = create_tmp_var (integer_type_node);\n+\t    gimple *call\n+\t      = gimple_build_call_internal (IFN_GOACC_DIM_SIZE, 1, arg);\n+\n+\t    gimple_call_set_lhs (call, n);\n+\t    gimple_seq_add_stmt (seq, call);\n+\t    res = fold_build2 (MULT_EXPR, integer_type_node, res, n);\n+\t  }\n+\tif (pos)\n+\t  {\n+\t    /* Determine index in this dimension.  */\n+\t    tree id = create_tmp_var (integer_type_node);\n+\t    gimple *call = gimple_build_call_internal\n+\t      (IFN_GOACC_DIM_POS, 1, arg);\n+\n+\t    gimple_call_set_lhs (call, id);\n+\t    gimple_seq_add_stmt (seq, call);\n+\t    if (res)\n+\t      res = fold_build2 (PLUS_EXPR, integer_type_node, res, id);\n+\t    else\n+\t      res = id;\n+\t  }\n+      }\n+\n+  if (res == NULL_TREE)\n+    res = integer_zero_node;\n+\n+  return res;\n+}\n+\n+/* Transform IFN_GOACC_LOOP calls to actual code.  See\n+   expand_oacc_for for where these are generated.  At the vector\n+   level, we stride loops, such that each member of a warp will\n+   operate on adjacent iterations.  At the worker and gang level,\n+   each gang/warp executes a set of contiguous iterations.  Chunking\n+   can override this such that each iteration engine executes a\n+   contiguous chunk, and then moves on to stride to the next chunk.   */\n+\n+static void\n+oacc_xform_loop (gcall *call)\n+{\n+  gimple_stmt_iterator gsi = gsi_for_stmt (call);\n+  enum ifn_goacc_loop_kind code\n+    = (enum ifn_goacc_loop_kind) TREE_INT_CST_LOW (gimple_call_arg (call, 0));\n+  tree dir = gimple_call_arg (call, 1);\n+  tree range = gimple_call_arg (call, 2);\n+  tree step = gimple_call_arg (call, 3);\n+  tree chunk_size = NULL_TREE;\n+  unsigned mask = (unsigned) TREE_INT_CST_LOW (gimple_call_arg (call, 5));\n+  tree lhs = gimple_call_lhs (call);\n+  tree type = TREE_TYPE (lhs);\n+  tree diff_type = TREE_TYPE (range);\n+  tree r = NULL_TREE;\n+  gimple_seq seq = NULL;\n+  bool chunking = false, striding = true;\n+  unsigned outer_mask = mask & (~mask + 1); // Outermost partitioning\n+  unsigned inner_mask = mask & ~outer_mask; // Inner partitioning (if any)\n+\n+#ifdef ACCEL_COMPILER\n+  chunk_size = gimple_call_arg (call, 4);\n+  if (integer_minus_onep (chunk_size)  /* Force static allocation.  */\n+      || integer_zerop (chunk_size))   /* Default (also static).  */\n+    {\n+      /* If we're at the gang level, we want each to execute a\n+\t contiguous run of iterations.  Otherwise we want each element\n+\t to stride.  */\n+      striding = !(outer_mask & GOMP_DIM_MASK (GOMP_DIM_GANG));\n+      chunking = false;\n+    }\n+  else\n+    {\n+      /* Chunk of size 1 is striding.  */\n+      striding = integer_onep (chunk_size);\n+      chunking = !striding;\n+    }\n+#endif\n+\n+  /* striding=true, chunking=true\n+       -> invalid.\n+     striding=true, chunking=false\n+       -> chunks=1\n+     striding=false,chunking=true\n+       -> chunks=ceil (range/(chunksize*threads*step))\n+     striding=false,chunking=false\n+       -> chunk_size=ceil(range/(threads*step)),chunks=1  */\n+  push_gimplify_context (true);\n+\n+  switch (code)\n+    {\n+    default: gcc_unreachable ();\n+\n+    case IFN_GOACC_LOOP_CHUNKS:\n+      if (!chunking)\n+\tr = build_int_cst (type, 1);\n+      else\n+\t{\n+\t  /* chunk_max\n+\t     = (range - dir) / (chunks * step * num_threads) + dir  */\n+\t  tree per = oacc_thread_numbers (false, mask, &seq);\n+\t  per = fold_convert (type, per);\n+\t  chunk_size = fold_convert (type, chunk_size);\n+\t  per = fold_build2 (MULT_EXPR, type, per, chunk_size);\n+\t  per = fold_build2 (MULT_EXPR, type, per, step);\n+\t  r = build2 (MINUS_EXPR, type, range, dir);\n+\t  r = build2 (PLUS_EXPR, type, r, per);\n+\t  r = build2 (TRUNC_DIV_EXPR, type, r, per);\n+\t}\n+      break;\n+\n+    case IFN_GOACC_LOOP_STEP:\n+      {\n+\t/* If striding, step by the entire compute volume, otherwise\n+\t   step by the inner volume.  */\n+\tunsigned volume = striding ? mask : inner_mask;\n+\n+\tr = oacc_thread_numbers (false, volume, &seq);\n+\tr = build2 (MULT_EXPR, type, fold_convert (type, r), step);\n+      }\n+      break;\n+\n+    case IFN_GOACC_LOOP_OFFSET:\n+      if (striding)\n+\t{\n+\t  r = oacc_thread_numbers (true, mask, &seq);\n+\t  r = fold_convert (diff_type, r);\n+\t}\n+      else\n+\t{\n+\t  tree inner_size = oacc_thread_numbers (false, inner_mask, &seq);\n+\t  tree outer_size = oacc_thread_numbers (false, outer_mask, &seq);\n+\t  tree volume = fold_build2 (MULT_EXPR, TREE_TYPE (inner_size),\n+\t\t\t\t     inner_size, outer_size);\n+\n+\t  volume = fold_convert (diff_type, volume);\n+\t  if (chunking)\n+\t    chunk_size = fold_convert (diff_type, chunk_size);\n+\t  else\n+\t    {\n+\t      tree per = fold_build2 (MULT_EXPR, diff_type, volume, step);\n+\n+\t      chunk_size = build2 (MINUS_EXPR, diff_type, range, dir);\n+\t      chunk_size = build2 (PLUS_EXPR, diff_type, chunk_size, per);\n+\t      chunk_size = build2 (TRUNC_DIV_EXPR, diff_type, chunk_size, per);\n+\t    }\n+\n+\t  tree span = build2 (MULT_EXPR, diff_type, chunk_size,\n+\t\t\t      fold_convert (diff_type, inner_size));\n+\t  r = oacc_thread_numbers (true, outer_mask, &seq);\n+\t  r = fold_convert (diff_type, r);\n+\t  r = build2 (MULT_EXPR, diff_type, r, span);\n+\n+\t  tree inner = oacc_thread_numbers (true, inner_mask, &seq);\n+\t  inner = fold_convert (diff_type, inner);\n+\t  r = fold_build2 (PLUS_EXPR, diff_type, r, inner);\n+\n+\t  if (chunking)\n+\t    {\n+\t      tree chunk = fold_convert (diff_type, gimple_call_arg (call, 6));\n+\t      tree per\n+\t\t= fold_build2 (MULT_EXPR, diff_type, volume, chunk_size);\n+\t      per = build2 (MULT_EXPR, diff_type, per, chunk);\n+\n+\t      r = build2 (PLUS_EXPR, diff_type, r, per);\n+\t    }\n+\t}\n+      r = fold_build2 (MULT_EXPR, diff_type, r, step);\n+      if (type != diff_type)\n+\tr = fold_convert (type, r);\n+      break;\n+\n+    case IFN_GOACC_LOOP_BOUND:\n+      if (striding)\n+\tr = range;\n+      else\n+\t{\n+\t  tree inner_size = oacc_thread_numbers (false, inner_mask, &seq);\n+\t  tree outer_size = oacc_thread_numbers (false, outer_mask, &seq);\n+\t  tree volume = fold_build2 (MULT_EXPR, TREE_TYPE (inner_size),\n+\t\t\t\t     inner_size, outer_size);\n+\n+\t  volume = fold_convert (diff_type, volume);\n+\t  if (chunking)\n+\t    chunk_size = fold_convert (diff_type, chunk_size);\n+\t  else\n+\t    {\n+\t      tree per = fold_build2 (MULT_EXPR, diff_type, volume, step);\n+\n+\t      chunk_size = build2 (MINUS_EXPR, diff_type, range, dir);\n+\t      chunk_size = build2 (PLUS_EXPR, diff_type, chunk_size, per);\n+\t      chunk_size = build2 (TRUNC_DIV_EXPR, diff_type, chunk_size, per);\n+\t    }\n+\n+\t  tree span = build2 (MULT_EXPR, diff_type, chunk_size,\n+\t\t\t      fold_convert (diff_type, inner_size));\n+\n+\t  r = fold_build2 (MULT_EXPR, diff_type, span, step);\n+\n+\t  tree offset = gimple_call_arg (call, 6);\n+\t  r = build2 (PLUS_EXPR, diff_type, r,\n+\t\t      fold_convert (diff_type, offset));\n+\t  r = build2 (integer_onep (dir) ? MIN_EXPR : MAX_EXPR,\n+\t\t      diff_type, r, range);\n+\t}\n+      if (diff_type != type)\n+\tr = fold_convert (type, r);\n+      break;\n+    }\n+\n+  gimplify_assign (lhs, r, &seq);\n+\n+  pop_gimplify_context (NULL);\n+\n+  gsi_replace_with_seq (&gsi, seq, true);\n+}\n+\n+/* Default partitioned and minimum partitioned dimensions.  */\n+\n+static int oacc_default_dims[GOMP_DIM_MAX];\n+static int oacc_min_dims[GOMP_DIM_MAX];\n+\n+/* Parse the default dimension parameter.  This is a set of\n+   :-separated optional compute dimensions.  Each specified dimension\n+   is a positive integer.  When device type support is added, it is\n+   planned to be a comma separated list of such compute dimensions,\n+   with all but the first prefixed by the colon-terminated device\n+   type.  */\n+\n+static void\n+oacc_parse_default_dims (const char *dims)\n+{\n+  int ix;\n+\n+  for (ix = GOMP_DIM_MAX; ix--;)\n+    {\n+      oacc_default_dims[ix] = -1;\n+      oacc_min_dims[ix] = 1;\n+    }\n+\n+#ifndef ACCEL_COMPILER\n+  /* Cannot be overridden on the host.  */\n+  dims = NULL;\n+#endif\n+  if (dims)\n+    {\n+      const char *pos = dims;\n+\n+      for (ix = 0; *pos && ix != GOMP_DIM_MAX; ix++)\n+\t{\n+\t  if (ix)\n+\t    {\n+\t      if (*pos != ':')\n+\t\tgoto malformed;\n+\t      pos++;\n+\t    }\n+\n+\t  if (*pos != ':')\n+\t    {\n+\t      long val;\n+\t      const char *eptr;\n+\n+\t      errno = 0;\n+\t      val = strtol (pos, CONST_CAST (char **, &eptr), 10);\n+\t      if (errno || val <= 0 || (int) val != val)\n+\t\tgoto malformed;\n+\t      pos = eptr;\n+\t      oacc_default_dims[ix] = (int) val;\n+\t    }\n+\t}\n+      if (*pos)\n+\t{\n+\tmalformed:\n+\t  error_at (UNKNOWN_LOCATION,\n+\t\t    \"-fopenacc-dim operand is malformed at '%s'\", pos);\n+\t}\n+    }\n+\n+  /* Allow the backend to validate the dimensions.  */\n+  targetm.goacc.validate_dims (NULL_TREE, oacc_default_dims, -1);\n+  targetm.goacc.validate_dims (NULL_TREE, oacc_min_dims, -2);\n+}\n+\n+/* Validate and update the dimensions for offloaded FN.  ATTRS is the\n+   raw attribute.  DIMS is an array of dimensions, which is filled in.\n+   LEVEL is the partitioning level of a routine, or -1 for an offload\n+   region itself. USED is the mask of partitioned execution in the\n+   function.  */\n+\n+static void\n+oacc_validate_dims (tree fn, tree attrs, int *dims, int level, unsigned used)\n+{\n+  tree purpose[GOMP_DIM_MAX];\n+  unsigned ix;\n+  tree pos = TREE_VALUE (attrs);\n+  bool is_kernel = oacc_fn_attrib_kernels_p (attrs);\n+\n+  /* Make sure the attribute creator attached the dimension\n+     information.  */\n+  gcc_assert (pos);\n+\n+  for (ix = 0; ix != GOMP_DIM_MAX; ix++)\n+    {\n+      purpose[ix] = TREE_PURPOSE (pos);\n+      tree val = TREE_VALUE (pos);\n+      dims[ix] = val ? TREE_INT_CST_LOW (val) : -1;\n+      pos = TREE_CHAIN (pos);\n+    }\n+\n+  bool changed = targetm.goacc.validate_dims (fn, dims, level);\n+\n+  /* Default anything left to 1 or a partitioned default.  */\n+  for (ix = 0; ix != GOMP_DIM_MAX; ix++)\n+    if (dims[ix] < 0)\n+      {\n+\t/* The OpenACC spec says 'If the [num_gangs] clause is not\n+\t   specified, an implementation-defined default will be used;\n+\t   the default may depend on the code within the construct.'\n+\t   (2.5.6).  Thus an implementation is free to choose\n+\t   non-unity default for a parallel region that doesn't have\n+\t   any gang-partitioned loops.  However, it appears that there\n+\t   is a sufficient body of user code that expects non-gang\n+\t   partitioned regions to not execute in gang-redundant mode.\n+\t   So we (a) don't warn about the non-portability and (b) pick\n+\t   the minimum permissible dimension size when there is no\n+\t   partitioned execution.  Otherwise we pick the global\n+\t   default for the dimension, which the user can control.  The\n+\t   same wording and logic applies to num_workers and\n+\t   vector_length, however the worker- or vector- single\n+\t   execution doesn't have the same impact as gang-redundant\n+\t   execution.  (If the minimum gang-level partioning is not 1,\n+\t   the target is probably too confusing.)  */\n+\tdims[ix] = (used & GOMP_DIM_MASK (ix)\n+\t\t    ? oacc_default_dims[ix] : oacc_min_dims[ix]);\n+\tchanged = true;\n+      }\n+\n+  if (changed)\n+    {\n+      /* Replace the attribute with new values.  */\n+      pos = NULL_TREE;\n+      for (ix = GOMP_DIM_MAX; ix--;)\n+\t{\n+\t  pos = tree_cons (purpose[ix],\n+\t\t\t   build_int_cst (integer_type_node, dims[ix]),\n+\t\t\t   pos);\n+\t  if (is_kernel)\n+\t    TREE_PUBLIC (pos) = 1;\n+\t}\n+      oacc_replace_fn_attrib (fn, pos);\n+    }\n+}\n+\n+/* Create an empty OpenACC loop structure at LOC.  */\n+\n+static oacc_loop *\n+new_oacc_loop_raw (oacc_loop *parent, location_t loc)\n+{\n+  oacc_loop *loop = XCNEW (oacc_loop);\n+\n+  loop->parent = parent;\n+  loop->child = loop->sibling = NULL;\n+\n+  if (parent)\n+    {\n+      loop->sibling = parent->child;\n+      parent->child = loop;\n+    }\n+\n+  loop->loc = loc;\n+  loop->marker = NULL;\n+  memset (loop->heads, 0, sizeof (loop->heads));\n+  memset (loop->tails, 0, sizeof (loop->tails));\n+  loop->routine = NULL_TREE;\n+\n+  loop->mask = loop->flags = loop->inner = 0;\n+  loop->ifns = 0;\n+  loop->chunk_size = 0;\n+  loop->head_end = NULL;\n+\n+  return loop;\n+}\n+\n+/* Create an outermost, dummy OpenACC loop for offloaded function\n+   DECL.  */\n+\n+static oacc_loop *\n+new_oacc_loop_outer (tree decl)\n+{\n+  return new_oacc_loop_raw (NULL, DECL_SOURCE_LOCATION (decl));\n+}\n+\n+/* Start a new OpenACC loop  structure beginning at head marker HEAD.\n+   Link into PARENT loop.  Return the new loop.  */\n+\n+static oacc_loop *\n+new_oacc_loop (oacc_loop *parent, gcall *marker)\n+{\n+  oacc_loop *loop = new_oacc_loop_raw (parent, gimple_location (marker));\n+\n+  loop->marker = marker;\n+\n+  /* TODO: This is where device_type flattening would occur for the loop\n+     flags.   */\n+\n+  loop->flags = TREE_INT_CST_LOW (gimple_call_arg (marker, 3));\n+\n+  tree chunk_size = integer_zero_node;\n+  if (loop->flags & OLF_GANG_STATIC)\n+    chunk_size = gimple_call_arg (marker, 4);\n+  loop->chunk_size = chunk_size;\n+\n+  return loop;\n+}\n+\n+/* Create a dummy loop encompassing a call to a openACC routine.\n+   Extract the routine's partitioning requirements.  */\n+\n+static void\n+new_oacc_loop_routine (oacc_loop *parent, gcall *call, tree decl, tree attrs)\n+{\n+  oacc_loop *loop = new_oacc_loop_raw (parent, gimple_location (call));\n+  int level = oacc_fn_attrib_level (attrs);\n+\n+  gcc_assert (level >= 0);\n+\n+  loop->marker = call;\n+  loop->routine = decl;\n+  loop->mask = ((GOMP_DIM_MASK (GOMP_DIM_MAX) - 1)\n+\t\t^ (GOMP_DIM_MASK (level) - 1));\n+}\n+\n+/* Finish off the current OpenACC loop ending at tail marker TAIL.\n+   Return the parent loop.  */\n+\n+static oacc_loop *\n+finish_oacc_loop (oacc_loop *loop)\n+{\n+  /* If the loop has been collapsed, don't partition it.  */\n+  if (!loop->ifns)\n+    loop->mask = loop->flags = 0;\n+  return loop->parent;\n+}\n+\n+/* Free all OpenACC loop structures within LOOP (inclusive).  */\n+\n+static void\n+free_oacc_loop (oacc_loop *loop)\n+{\n+  if (loop->sibling)\n+    free_oacc_loop (loop->sibling);\n+  if (loop->child)\n+    free_oacc_loop (loop->child);\n+\n+  free (loop);\n+}\n+\n+/* Dump out the OpenACC loop head or tail beginning at FROM.  */\n+\n+static void\n+dump_oacc_loop_part (FILE *file, gcall *from, int depth,\n+\t\t     const char *title, int level)\n+{\n+  enum ifn_unique_kind kind\n+    = (enum ifn_unique_kind) TREE_INT_CST_LOW (gimple_call_arg (from, 0));\n+\n+  fprintf (file, \"%*s%s-%d:\\n\", depth * 2, \"\", title, level);\n+  for (gimple_stmt_iterator gsi = gsi_for_stmt (from);;)\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+\n+      if (gimple_call_internal_p (stmt, IFN_UNIQUE))\n+\t{\n+\t  enum ifn_unique_kind k\n+\t    = ((enum ifn_unique_kind) TREE_INT_CST_LOW\n+\t       (gimple_call_arg (stmt, 0)));\n+\n+\t  if (k == kind && stmt != from)\n+\t    break;\n+\t}\n+      print_gimple_stmt (file, stmt, depth * 2 + 2, 0);\n+\n+      gsi_next (&gsi);\n+      while (gsi_end_p (gsi))\n+\tgsi = gsi_start_bb (single_succ (gsi_bb (gsi)));\n+    }\n+}\n+\n+/* Dump OpenACC loops LOOP, its siblings and its children.  */\n+\n+static void\n+dump_oacc_loop (FILE *file, oacc_loop *loop, int depth)\n+{\n+  int ix;\n+\n+  fprintf (file, \"%*sLoop %x(%x) %s:%u\\n\", depth * 2, \"\",\n+\t   loop->flags, loop->mask,\n+\t   LOCATION_FILE (loop->loc), LOCATION_LINE (loop->loc));\n+\n+  if (loop->marker)\n+    print_gimple_stmt (file, loop->marker, depth * 2, 0);\n+\n+  if (loop->routine)\n+    fprintf (file, \"%*sRoutine %s:%u:%s\\n\",\n+\t     depth * 2, \"\", DECL_SOURCE_FILE (loop->routine),\n+\t     DECL_SOURCE_LINE (loop->routine),\n+\t     IDENTIFIER_POINTER (DECL_NAME (loop->routine)));\n+\n+  for (ix = GOMP_DIM_GANG; ix != GOMP_DIM_MAX; ix++)\n+    if (loop->heads[ix])\n+      dump_oacc_loop_part (file, loop->heads[ix], depth, \"Head\", ix);\n+  for (ix = GOMP_DIM_MAX; ix--;)\n+    if (loop->tails[ix])\n+      dump_oacc_loop_part (file, loop->tails[ix], depth, \"Tail\", ix);\n+\n+  if (loop->child)\n+    dump_oacc_loop (file, loop->child, depth + 1);\n+  if (loop->sibling)\n+    dump_oacc_loop (file, loop->sibling, depth);\n+}\n+\n+void debug_oacc_loop (oacc_loop *);\n+\n+/* Dump loops to stderr.  */\n+\n+DEBUG_FUNCTION void\n+debug_oacc_loop (oacc_loop *loop)\n+{\n+  dump_oacc_loop (stderr, loop, 0);\n+}\n+\n+/* DFS walk of basic blocks BB onwards, creating OpenACC loop\n+   structures as we go.  By construction these loops are properly\n+   nested.  */\n+\n+static void\n+oacc_loop_discover_walk (oacc_loop *loop, basic_block bb)\n+{\n+  int marker = 0;\n+  int remaining = 0;\n+\n+  if (bb->flags & BB_VISITED)\n+    return;\n+\n+ follow:\n+  bb->flags |= BB_VISITED;\n+\n+  /* Scan for loop markers.  */\n+  for (gimple_stmt_iterator gsi = gsi_start_bb (bb); !gsi_end_p (gsi);\n+       gsi_next (&gsi))\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+\n+      if (!is_gimple_call (stmt))\n+\tcontinue;\n+\n+      gcall *call = as_a <gcall *> (stmt);\n+\n+      /* If this is a routine, make a dummy loop for it.  */\n+      if (tree decl = gimple_call_fndecl (call))\n+\tif (tree attrs = oacc_get_fn_attrib (decl))\n+\t  {\n+\t    gcc_assert (!marker);\n+\t    new_oacc_loop_routine (loop, call, decl, attrs);\n+\t  }\n+\n+      if (!gimple_call_internal_p (call))\n+\tcontinue;\n+\n+      switch (gimple_call_internal_fn (call))\n+\t{\n+\tdefault:\n+\t  break;\n+\n+\tcase IFN_GOACC_LOOP:\n+\t  /* Count the goacc loop abstraction fns, to determine if the\n+\t     loop was collapsed already.  */\n+\t  loop->ifns++;\n+\t  break;\n+\n+\tcase IFN_UNIQUE:\n+\t  enum ifn_unique_kind kind\n+\t    = (enum ifn_unique_kind) (TREE_INT_CST_LOW\n+\t\t\t\t      (gimple_call_arg (call, 0)));\n+\t  if (kind == IFN_UNIQUE_OACC_HEAD_MARK\n+\t      || kind == IFN_UNIQUE_OACC_TAIL_MARK)\n+\t    {\n+\t      if (gimple_call_num_args (call) == 2)\n+\t\t{\n+\t\t  gcc_assert (marker && !remaining);\n+\t\t  marker = 0;\n+\t\t  if (kind == IFN_UNIQUE_OACC_TAIL_MARK)\n+\t\t    loop = finish_oacc_loop (loop);\n+\t\t  else\n+\t\t    loop->head_end = call;\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  int count = TREE_INT_CST_LOW (gimple_call_arg (call, 2));\n+\n+\t\t  if (!marker)\n+\t\t    {\n+\t\t      if (kind == IFN_UNIQUE_OACC_HEAD_MARK)\n+\t\t\tloop = new_oacc_loop (loop, call);\n+\t\t      remaining = count;\n+\t\t    }\n+\t\t  gcc_assert (count == remaining);\n+\t\t  if (remaining)\n+\t\t    {\n+\t\t      remaining--;\n+\t\t      if (kind == IFN_UNIQUE_OACC_HEAD_MARK)\n+\t\t\tloop->heads[marker] = call;\n+\t\t      else\n+\t\t\tloop->tails[remaining] = call;\n+\t\t    }\n+\t\t  marker++;\n+\t\t}\n+\t    }\n+\t}\n+    }\n+  if (remaining || marker)\n+    {\n+      bb = single_succ (bb);\n+      gcc_assert (single_pred_p (bb) && !(bb->flags & BB_VISITED));\n+      goto follow;\n+    }\n+\n+  /* Walk successor blocks.  */\n+  edge e;\n+  edge_iterator ei;\n+\n+  FOR_EACH_EDGE (e, ei, bb->succs)\n+    oacc_loop_discover_walk (loop, e->dest);\n+}\n+\n+/* LOOP is the first sibling.  Reverse the order in place and return\n+   the new first sibling.  Recurse to child loops.  */\n+\n+static oacc_loop *\n+oacc_loop_sibling_nreverse (oacc_loop *loop)\n+{\n+  oacc_loop *last = NULL;\n+  do\n+    {\n+      if (loop->child)\n+\tloop->child = oacc_loop_sibling_nreverse  (loop->child);\n+\n+      oacc_loop *next = loop->sibling;\n+      loop->sibling = last;\n+      last = loop;\n+      loop = next;\n+    }\n+  while (loop);\n+\n+  return last;\n+}\n+\n+/* Discover the OpenACC loops marked up by HEAD and TAIL markers for\n+   the current function.  */\n+\n+static oacc_loop *\n+oacc_loop_discovery ()\n+{\n+  /* Clear basic block flags, in particular BB_VISITED which we're going to use\n+     in the following.  */\n+  clear_bb_flags ();\n+\n+  oacc_loop *top = new_oacc_loop_outer (current_function_decl);\n+  oacc_loop_discover_walk (top, ENTRY_BLOCK_PTR_FOR_FN (cfun));\n+\n+  /* The siblings were constructed in reverse order, reverse them so\n+     that diagnostics come out in an unsurprising order.  */\n+  top = oacc_loop_sibling_nreverse (top);\n+\n+  return top;\n+}\n+\n+/* Transform the abstract internal function markers starting at FROM\n+   to be for partitioning level LEVEL.  Stop when we meet another HEAD\n+   or TAIL  marker.  */\n+\n+static void\n+oacc_loop_xform_head_tail (gcall *from, int level)\n+{\n+  enum ifn_unique_kind kind\n+    = (enum ifn_unique_kind) TREE_INT_CST_LOW (gimple_call_arg (from, 0));\n+  tree replacement = build_int_cst (unsigned_type_node, level);\n+\n+  for (gimple_stmt_iterator gsi = gsi_for_stmt (from);;)\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+\n+      if (gimple_call_internal_p (stmt, IFN_UNIQUE))\n+\t{\n+\t  enum ifn_unique_kind k\n+\t    = ((enum ifn_unique_kind)\n+\t       TREE_INT_CST_LOW (gimple_call_arg (stmt, 0)));\n+\n+\t  if (k == IFN_UNIQUE_OACC_FORK || k == IFN_UNIQUE_OACC_JOIN)\n+\t    *gimple_call_arg_ptr (stmt, 2) = replacement;\n+\t  else if (k == kind && stmt != from)\n+\t    break;\n+\t}\n+      else if (gimple_call_internal_p (stmt, IFN_GOACC_REDUCTION))\n+\t*gimple_call_arg_ptr (stmt, 3) = replacement;\n+\n+      gsi_next (&gsi);\n+      while (gsi_end_p (gsi))\n+\tgsi = gsi_start_bb (single_succ (gsi_bb (gsi)));\n+    }\n+}\n+\n+/* Transform the IFN_GOACC_LOOP internal functions by providing the\n+   determined partitioning mask and chunking argument.  END_MARKER\n+   points at the end IFN_HEAD_TAIL call intgroducing the loop.  IFNS\n+   is the number of IFN_GOACC_LOOP calls for the loop.  MASK_ARG is\n+   the replacement partitioning mask and CHUNK_ARG is the replacement\n+   chunking arg.  */\n+\n+static void\n+oacc_loop_xform_loop (gcall *end_marker, unsigned ifns,\n+\t\t      tree mask_arg, tree chunk_arg)\n+{\n+  gimple_stmt_iterator gsi = gsi_for_stmt (end_marker);\n+\n+  gcc_checking_assert (ifns);\n+  for (;;)\n+    {\n+      for (; !gsi_end_p (gsi); gsi_next (&gsi))\n+\t{\n+\t  gimple *stmt = gsi_stmt (gsi);\n+\n+\t  if (!is_gimple_call (stmt))\n+\t    continue;\n+\n+\t  gcall *call = as_a <gcall *> (stmt);\n+\n+\t  if (!gimple_call_internal_p (call))\n+\t    continue;\n+\n+\t  if (gimple_call_internal_fn (call) != IFN_GOACC_LOOP)\n+\t    continue;\n+\n+\t  *gimple_call_arg_ptr (call, 5) = mask_arg;\n+\t  *gimple_call_arg_ptr (call, 4) = chunk_arg;\n+\t  ifns--;\n+\t  if (!ifns)\n+\t    return;\n+\t}\n+\n+      /* The LOOP_BOUND ifn could be in the single successor\n+\t block.  */\n+      basic_block bb = single_succ (gsi_bb (gsi));\n+      gsi = gsi_start_bb (bb);\n+    }\n+}\n+\n+/* Process the discovered OpenACC loops, setting the correct\n+   partitioning level etc.  */\n+\n+static void\n+oacc_loop_process (oacc_loop *loop)\n+{\n+  if (loop->child)\n+    oacc_loop_process (loop->child);\n+\n+  if (loop->mask && !loop->routine)\n+    {\n+      int ix;\n+      unsigned mask = loop->mask;\n+      unsigned dim = GOMP_DIM_GANG;\n+      tree mask_arg = build_int_cst (unsigned_type_node, mask);\n+      tree chunk_arg = loop->chunk_size;\n+\n+      oacc_loop_xform_loop (loop->head_end, loop->ifns, mask_arg, chunk_arg);\n+\n+      for (ix = 0; ix != GOMP_DIM_MAX && mask; ix++)\n+\t{\n+\t  while (!(GOMP_DIM_MASK (dim) & mask))\n+\t    dim++;\n+\n+\t  oacc_loop_xform_head_tail (loop->heads[ix], dim);\n+\t  oacc_loop_xform_head_tail (loop->tails[ix], dim);\n+\n+\t  mask ^= GOMP_DIM_MASK (dim);\n+\t}\n+    }\n+\n+  if (loop->sibling)\n+    oacc_loop_process (loop->sibling);\n+}\n+\n+/* Walk the OpenACC loop heirarchy checking and assigning the\n+   programmer-specified partitionings.  OUTER_MASK is the partitioning\n+   this loop is contained within.  Return mask of partitioning\n+   encountered.  If any auto loops are discovered, set GOMP_DIM_MAX\n+   bit.  */\n+\n+static unsigned\n+oacc_loop_fixed_partitions (oacc_loop *loop, unsigned outer_mask)\n+{\n+  unsigned this_mask = loop->mask;\n+  unsigned mask_all = 0;\n+  bool noisy = true;\n+\n+#ifdef ACCEL_COMPILER\n+  /* When device_type is supported, we want the device compiler to be\n+     noisy, if the loop parameters are device_type-specific.  */\n+  noisy = false;\n+#endif\n+\n+  if (!loop->routine)\n+    {\n+      bool auto_par = (loop->flags & OLF_AUTO) != 0;\n+      bool seq_par = (loop->flags & OLF_SEQ) != 0;\n+\n+      this_mask = ((loop->flags >> OLF_DIM_BASE)\n+\t\t   & (GOMP_DIM_MASK (GOMP_DIM_MAX) - 1));\n+\n+      if ((this_mask != 0) + auto_par + seq_par > 1)\n+\t{\n+\t  if (noisy)\n+\t    error_at (loop->loc,\n+\t\t      seq_par\n+\t\t      ? \"%<seq%> overrides other OpenACC loop specifiers\"\n+\t\t      : \"%<auto%> conflicts with other OpenACC loop \"\n+\t\t      \"specifiers\");\n+\t  auto_par = false;\n+\t  loop->flags &= ~OLF_AUTO;\n+\t  if (seq_par)\n+\t    {\n+\t      loop->flags &=\n+\t\t~((GOMP_DIM_MASK (GOMP_DIM_MAX) - 1) << OLF_DIM_BASE);\n+\t      this_mask = 0;\n+\t    }\n+\t}\n+      if (auto_par && (loop->flags & OLF_INDEPENDENT))\n+\tmask_all |= GOMP_DIM_MASK (GOMP_DIM_MAX);\n+    }\n+\n+  if (this_mask & outer_mask)\n+    {\n+      const oacc_loop *outer;\n+      for (outer = loop->parent; outer; outer = outer->parent)\n+\tif (outer->mask & this_mask)\n+\t  break;\n+\n+      if (noisy)\n+\t{\n+\t  if (outer)\n+\t    {\n+\t      error_at (loop->loc,\n+\t\t\t\"%s uses same OpenACC parallelism as containing loop\",\n+\t\t\tloop->routine ? \"routine call\" : \"inner loop\");\n+\t      inform (outer->loc, \"containing loop here\");\n+\t    }\n+\t  else\n+\t    error_at (loop->loc,\n+\t\t      \"%s uses OpenACC parallelism disallowed by containing \"\n+\t\t      \"routine\", loop->routine ? \"routine call\" : \"loop\");\n+\n+\t  if (loop->routine)\n+\t    inform (DECL_SOURCE_LOCATION (loop->routine),\n+\t\t    \"routine %qD declared here\", loop->routine);\n+\t}\n+      this_mask &= ~outer_mask;\n+    }\n+  else\n+    {\n+      unsigned outermost = least_bit_hwi (this_mask);\n+\n+      if (outermost && outermost <= outer_mask)\n+\t{\n+\t  if (noisy)\n+\t    {\n+\t      error_at (loop->loc,\n+\t\t\t\"incorrectly nested OpenACC loop parallelism\");\n+\n+\t      const oacc_loop *outer;\n+\t      for (outer = loop->parent;\n+\t\t   outer->flags && outer->flags < outermost;\n+\t\t   outer = outer->parent)\n+\t\tcontinue;\n+\t      inform (outer->loc, \"containing loop here\");\n+\t    }\n+\n+\t  this_mask &= ~outermost;\n+\t}\n+    }\n+\n+  loop->mask = this_mask;\n+  mask_all |= this_mask;\n+\n+  if (loop->child)\n+    {\n+      loop->inner = oacc_loop_fixed_partitions (loop->child,\n+\t\t\t\t\t\touter_mask | this_mask);\n+      mask_all |= loop->inner;\n+    }\n+\n+  if (loop->sibling)\n+    mask_all |= oacc_loop_fixed_partitions (loop->sibling, outer_mask);\n+\n+  return mask_all;\n+}\n+\n+/* Walk the OpenACC loop heirarchy to assign auto-partitioned loops.\n+   OUTER_MASK is the partitioning this loop is contained within.\n+   Return the cumulative partitioning used by this loop, siblings and\n+   children.  */\n+\n+static unsigned\n+oacc_loop_auto_partitions (oacc_loop *loop, unsigned outer_mask)\n+{\n+  bool assign = (loop->flags & OLF_AUTO) && (loop->flags & OLF_INDEPENDENT);\n+  bool noisy = true;\n+\n+#ifdef ACCEL_COMPILER\n+  /* When device_type is supported, we want the device compiler to be\n+     noisy, if the loop parameters are device_type-specific.  */\n+  noisy = false;\n+#endif\n+\n+  if (assign && outer_mask < GOMP_DIM_MASK (GOMP_DIM_MAX - 1))\n+    {\n+      /* Allocate the outermost loop at the outermost available\n+\t level.  */\n+      unsigned this_mask = outer_mask + 1;\n+\n+      if (!(this_mask & loop->inner))\n+\tloop->mask = this_mask;\n+    }\n+\n+  if (loop->child)\n+    {\n+      unsigned child_mask = outer_mask | loop->mask;\n+\n+      if (loop->mask || assign)\n+\tchild_mask |= GOMP_DIM_MASK (GOMP_DIM_MAX);\n+\n+      loop->inner = oacc_loop_auto_partitions (loop->child, child_mask);\n+    }\n+\n+  if (assign && !loop->mask)\n+    {\n+      /* Allocate the loop at the innermost available level.  */\n+      unsigned this_mask = 0;\n+\n+      /* Determine the outermost partitioning used within this loop. */\n+      this_mask = loop->inner | GOMP_DIM_MASK (GOMP_DIM_MAX);\n+      this_mask = least_bit_hwi (this_mask);\n+\n+      /* Pick the partitioning just inside that one.  */\n+      this_mask >>= 1;\n+\n+      /* And avoid picking one use by an outer loop. */\n+      this_mask &= ~outer_mask;\n+\n+      if (!this_mask && noisy)\n+\twarning_at (loop->loc, 0,\n+\t\t    \"insufficient partitioning available to parallelize loop\");\n+\n+      loop->mask = this_mask;\n+    }\n+\n+  if (assign && dump_file)\n+    fprintf (dump_file, \"Auto loop %s:%d assigned %d\\n\",\n+\t     LOCATION_FILE (loop->loc), LOCATION_LINE (loop->loc),\n+\t     loop->mask);\n+\n+  unsigned inner_mask = 0;\n+\n+  if (loop->sibling)\n+    inner_mask |= oacc_loop_auto_partitions (loop->sibling, outer_mask);\n+\n+  inner_mask |= loop->inner | loop->mask;\n+\n+  return inner_mask;\n+}\n+\n+/* Walk the OpenACC loop heirarchy to check and assign partitioning\n+   axes.  Return mask of partitioning.  */\n+\n+static unsigned\n+oacc_loop_partition (oacc_loop *loop, unsigned outer_mask)\n+{\n+  unsigned mask_all = oacc_loop_fixed_partitions (loop, outer_mask);\n+\n+  if (mask_all & GOMP_DIM_MASK (GOMP_DIM_MAX))\n+    {\n+      mask_all ^= GOMP_DIM_MASK (GOMP_DIM_MAX);\n+      mask_all |= oacc_loop_auto_partitions (loop, outer_mask);\n+    }\n+  return mask_all;\n+}\n+\n+/* Default fork/join early expander.  Delete the function calls if\n+   there is no RTL expander.  */\n+\n+bool\n+default_goacc_fork_join (gcall *ARG_UNUSED (call),\n+\t\t\t const int *ARG_UNUSED (dims), bool is_fork)\n+{\n+  if (is_fork)\n+    return targetm.have_oacc_fork ();\n+  else\n+    return targetm.have_oacc_join ();\n+}\n+\n+/* Default goacc.reduction early expander.\n+\n+   LHS-opt = IFN_REDUCTION (KIND, RES_PTR, VAR, LEVEL, OP, OFFSET)\n+   If RES_PTR is not integer-zerop:\n+       SETUP - emit 'LHS = *RES_PTR', LHS = NULL\n+       TEARDOWN - emit '*RES_PTR = VAR'\n+   If LHS is not NULL\n+       emit 'LHS = VAR'   */\n+\n+void\n+default_goacc_reduction (gcall *call)\n+{\n+  unsigned code = (unsigned)TREE_INT_CST_LOW (gimple_call_arg (call, 0));\n+  gimple_stmt_iterator gsi = gsi_for_stmt (call);\n+  tree lhs = gimple_call_lhs (call);\n+  tree var = gimple_call_arg (call, 2);\n+  gimple_seq seq = NULL;\n+\n+  if (code == IFN_GOACC_REDUCTION_SETUP\n+      || code == IFN_GOACC_REDUCTION_TEARDOWN)\n+    {\n+      /* Setup and Teardown need to copy from/to the receiver object,\n+\t if there is one.  */\n+      tree ref_to_res = gimple_call_arg (call, 1);\n+\n+      if (!integer_zerop (ref_to_res))\n+\t{\n+\t  tree dst = build_simple_mem_ref (ref_to_res);\n+\t  tree src = var;\n+\n+\t  if (code == IFN_GOACC_REDUCTION_SETUP)\n+\t    {\n+\t      src = dst;\n+\t      dst = lhs;\n+\t      lhs = NULL;\n+\t    }\n+\t  gimple_seq_add_stmt (&seq, gimple_build_assign (dst, src));\n+\t}\n+    }\n+\n+  /* Copy VAR to LHS, if there is an LHS.  */\n+  if (lhs)\n+    gimple_seq_add_stmt (&seq, gimple_build_assign (lhs, var));\n+\n+  gsi_replace_with_seq (&gsi, seq, true);\n+}\n+\n+/* Main entry point for oacc transformations which run on the device\n+   compiler after LTO, so we know what the target device is at this\n+   point (including the host fallback).  */\n+\n+static unsigned int\n+execute_oacc_device_lower ()\n+{\n+  tree attrs = oacc_get_fn_attrib (current_function_decl);\n+\n+  if (!attrs)\n+    /* Not an offloaded function.  */\n+    return 0;\n+\n+  /* Parse the default dim argument exactly once.  */\n+  if ((const void *)flag_openacc_dims != &flag_openacc_dims)\n+    {\n+      oacc_parse_default_dims (flag_openacc_dims);\n+      flag_openacc_dims = (char *)&flag_openacc_dims;\n+    }\n+\n+  /* Discover, partition and process the loops.  */\n+  oacc_loop *loops = oacc_loop_discovery ();\n+  int fn_level = oacc_fn_attrib_level (attrs);\n+\n+  if (dump_file)\n+    fprintf (dump_file, oacc_fn_attrib_kernels_p (attrs)\n+\t     ? \"Function is kernels offload\\n\"\n+\t     : fn_level < 0 ? \"Function is parallel offload\\n\"\n+\t     : \"Function is routine level %d\\n\", fn_level);\n+\n+  unsigned outer_mask = fn_level >= 0 ? GOMP_DIM_MASK (fn_level) - 1 : 0;\n+  unsigned used_mask = oacc_loop_partition (loops, outer_mask);\n+  int dims[GOMP_DIM_MAX];\n+\n+  oacc_validate_dims (current_function_decl, attrs, dims, fn_level, used_mask);\n+\n+  if (dump_file)\n+    {\n+      const char *comma = \"Compute dimensions [\";\n+      for (int ix = 0; ix != GOMP_DIM_MAX; ix++, comma = \", \")\n+\tfprintf (dump_file, \"%s%d\", comma, dims[ix]);\n+      fprintf (dump_file, \"]\\n\");\n+    }\n+\n+  oacc_loop_process (loops);\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"OpenACC loops\\n\");\n+      dump_oacc_loop (dump_file, loops, 0);\n+      fprintf (dump_file, \"\\n\");\n+    }\n+\n+  /* Offloaded targets may introduce new basic blocks, which require\n+     dominance information to update SSA.  */\n+  calculate_dominance_info (CDI_DOMINATORS);\n+\n+  /* Now lower internal loop functions to target-specific code\n+     sequences.  */\n+  basic_block bb;\n+  FOR_ALL_BB_FN (bb, cfun)\n+    for (gimple_stmt_iterator gsi = gsi_start_bb (bb); !gsi_end_p (gsi);)\n+      {\n+\tgimple *stmt = gsi_stmt (gsi);\n+\tif (!is_gimple_call (stmt))\n+\t  {\n+\t    gsi_next (&gsi);\n+\t    continue;\n+\t  }\n+\n+\tgcall *call = as_a <gcall *> (stmt);\n+\tif (!gimple_call_internal_p (call))\n+\t  {\n+\t    gsi_next (&gsi);\n+\t    continue;\n+\t  }\n+\n+\t/* Rewind to allow rescan.  */\n+\tgsi_prev (&gsi);\n+\tbool rescan = false, remove = false;\n+\tenum  internal_fn ifn_code = gimple_call_internal_fn (call);\n+\n+\tswitch (ifn_code)\n+\t  {\n+\t  default: break;\n+\n+\t  case IFN_GOACC_LOOP:\n+\t    oacc_xform_loop (call);\n+\t    rescan = true;\n+\t    break;\n+\n+\t  case IFN_GOACC_REDUCTION:\n+\t    /* Mark the function for SSA renaming.  */\n+\t    mark_virtual_operands_for_renaming (cfun);\n+\n+\t    /* If the level is -1, this ended up being an unused\n+\t       axis.  Handle as a default.  */\n+\t    if (integer_minus_onep (gimple_call_arg (call, 3)))\n+\t      default_goacc_reduction (call);\n+\t    else\n+\t      targetm.goacc.reduction (call);\n+\t    rescan = true;\n+\t    break;\n+\n+\t  case IFN_UNIQUE:\n+\t    {\n+\t      enum ifn_unique_kind kind\n+\t\t= ((enum ifn_unique_kind)\n+\t\t   TREE_INT_CST_LOW (gimple_call_arg (call, 0)));\n+\n+\t      switch (kind)\n+\t\t{\n+\t\tdefault:\n+\t\t  gcc_unreachable ();\n+\n+\t\tcase IFN_UNIQUE_OACC_FORK:\n+\t\tcase IFN_UNIQUE_OACC_JOIN:\n+\t\t  if (integer_minus_onep (gimple_call_arg (call, 2)))\n+\t\t    remove = true;\n+\t\t  else if (!targetm.goacc.fork_join\n+\t\t\t   (call, dims, kind == IFN_UNIQUE_OACC_FORK))\n+\t\t    remove = true;\n+\t\t  break;\n+\n+\t\tcase IFN_UNIQUE_OACC_HEAD_MARK:\n+\t\tcase IFN_UNIQUE_OACC_TAIL_MARK:\n+\t\t  remove = true;\n+\t\t  break;\n+\t\t}\n+\t      break;\n+\t    }\n+\t  }\n+\n+\tif (gsi_end_p (gsi))\n+\t  /* We rewound past the beginning of the BB.  */\n+\t  gsi = gsi_start_bb (bb);\n+\telse\n+\t  /* Undo the rewind.  */\n+\t  gsi_next (&gsi);\n+\n+\tif (remove)\n+\t  {\n+\t    if (gimple_vdef (call))\n+\t      replace_uses_by (gimple_vdef (call), gimple_vuse (call));\n+\t    if (gimple_call_lhs (call))\n+\t      {\n+\t\t/* Propagate the data dependency var.  */\n+\t\tgimple *ass = gimple_build_assign (gimple_call_lhs (call),\n+\t\t\t\t\t\t   gimple_call_arg (call, 1));\n+\t\tgsi_replace (&gsi, ass,  false);\n+\t      }\n+\t    else\n+\t      gsi_remove (&gsi, true);\n+\t  }\n+\telse if (!rescan)\n+\t  /* If not rescanning, advance over the call.  */\n+\t  gsi_next (&gsi);\n+      }\n+\n+  free_oacc_loop (loops);\n+\n+  return 0;\n+}\n+\n+/* Default launch dimension validator.  Force everything to 1.  A\n+   backend that wants to provide larger dimensions must override this\n+   hook.  */\n+\n+bool\n+default_goacc_validate_dims (tree ARG_UNUSED (decl), int *dims,\n+\t\t\t     int ARG_UNUSED (fn_level))\n+{\n+  bool changed = false;\n+\n+  for (unsigned ix = 0; ix != GOMP_DIM_MAX; ix++)\n+    {\n+      if (dims[ix] != 1)\n+\t{\n+\t  dims[ix] = 1;\n+\t  changed = true;\n+\t}\n+    }\n+\n+  return changed;\n+}\n+\n+/* Default dimension bound is unknown on accelerator and 1 on host. */\n+\n+int\n+default_goacc_dim_limit (int ARG_UNUSED (axis))\n+{\n+#ifdef ACCEL_COMPILER\n+  return 0;\n+#else\n+  return 1;\n+#endif\n+}\n+\n+namespace {\n+\n+const pass_data pass_data_oacc_device_lower =\n+{\n+  GIMPLE_PASS, /* type */\n+  \"oaccdevlow\", /* name */\n+  OPTGROUP_OPENMP, /* optinfo_flags */\n+  TV_NONE, /* tv_id */\n+  PROP_cfg, /* properties_required */\n+  0 /* Possibly PROP_gimple_eomp.  */, /* properties_provided */\n+  0, /* properties_destroyed */\n+  0, /* todo_flags_start */\n+  TODO_update_ssa | TODO_cleanup_cfg, /* todo_flags_finish */\n+};\n+\n+class pass_oacc_device_lower : public gimple_opt_pass\n+{\n+public:\n+  pass_oacc_device_lower (gcc::context *ctxt)\n+    : gimple_opt_pass (pass_data_oacc_device_lower, ctxt)\n+  {}\n+\n+  /* opt_pass methods: */\n+  virtual bool gate (function *) { return flag_openacc; };\n+\n+  virtual unsigned int execute (function *)\n+    {\n+      return execute_oacc_device_lower ();\n+    }\n+\n+}; // class pass_oacc_device_lower\n+\n+} // anon namespace\n+\n+gimple_opt_pass *\n+make_pass_oacc_device_lower (gcc::context *ctxt)\n+{\n+  return new pass_oacc_device_lower (ctxt);\n+}\n+\n+/* Cleanup uses of SIMT placeholder internal functions: on non-SIMT targets,\n+   VF is 1 and LANE is 0; on SIMT targets, VF is folded to a constant, and\n+   LANE is kept to be expanded to RTL later on.  Also cleanup all other SIMT\n+   internal functions on non-SIMT targets, and likewise some SIMD internal\n+   functions on SIMT targets.  */\n+\n+static unsigned int\n+execute_omp_device_lower ()\n+{\n+  int vf = targetm.simt.vf ? targetm.simt.vf () : 1;\n+  basic_block bb;\n+  gimple_stmt_iterator gsi;\n+  FOR_EACH_BB_FN (bb, cfun)\n+    for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n+      {\n+\tgimple *stmt = gsi_stmt (gsi);\n+\tif (!is_gimple_call (stmt) || !gimple_call_internal_p (stmt))\n+\t  continue;\n+\ttree lhs = gimple_call_lhs (stmt), rhs = NULL_TREE;\n+\ttree type = lhs ? TREE_TYPE (lhs) : integer_type_node;\n+\tswitch (gimple_call_internal_fn (stmt))\n+\t  {\n+\t  case IFN_GOMP_USE_SIMT:\n+\t    rhs = vf == 1 ? integer_zero_node : integer_one_node;\n+\t    break;\n+\t  case IFN_GOMP_SIMT_LANE:\n+\t  case IFN_GOMP_SIMT_LAST_LANE:\n+\t    rhs = vf == 1 ? build_zero_cst (type) : NULL_TREE;\n+\t    break;\n+\t  case IFN_GOMP_SIMT_VF:\n+\t    rhs = build_int_cst (type, vf);\n+\t    break;\n+\t  case IFN_GOMP_SIMT_ORDERED_PRED:\n+\t    rhs = vf == 1 ? integer_zero_node : NULL_TREE;\n+\t    if (rhs || !lhs)\n+\t      unlink_stmt_vdef (stmt);\n+\t    break;\n+\t  case IFN_GOMP_SIMT_VOTE_ANY:\n+\t  case IFN_GOMP_SIMT_XCHG_BFLY:\n+\t  case IFN_GOMP_SIMT_XCHG_IDX:\n+\t    rhs = vf == 1 ? gimple_call_arg (stmt, 0) : NULL_TREE;\n+\t    break;\n+\t  case IFN_GOMP_SIMD_LANE:\n+\t  case IFN_GOMP_SIMD_LAST_LANE:\n+\t    rhs = vf != 1 ? build_zero_cst (type) : NULL_TREE;\n+\t    break;\n+\t  case IFN_GOMP_SIMD_VF:\n+\t    rhs = vf != 1 ? build_one_cst (type) : NULL_TREE;\n+\t    break;\n+\t  default:\n+\t    continue;\n+\t  }\n+\tif (lhs && !rhs)\n+\t  continue;\n+\tstmt = lhs ? gimple_build_assign (lhs, rhs) : gimple_build_nop ();\n+\tgsi_replace (&gsi, stmt, false);\n+      }\n+  if (vf != 1)\n+    cfun->has_force_vectorize_loops = false;\n+  return 0;\n+}\n+\n+namespace {\n+\n+const pass_data pass_data_omp_device_lower =\n+{\n+  GIMPLE_PASS, /* type */\n+  \"ompdevlow\", /* name */\n+  OPTGROUP_OPENMP, /* optinfo_flags */\n+  TV_NONE, /* tv_id */\n+  PROP_cfg, /* properties_required */\n+  PROP_gimple_lomp_dev, /* properties_provided */\n+  0, /* properties_destroyed */\n+  0, /* todo_flags_start */\n+  TODO_update_ssa, /* todo_flags_finish */\n+};\n+\n+class pass_omp_device_lower : public gimple_opt_pass\n+{\n+public:\n+  pass_omp_device_lower (gcc::context *ctxt)\n+    : gimple_opt_pass (pass_data_omp_device_lower, ctxt)\n+  {}\n+\n+  /* opt_pass methods: */\n+  virtual bool gate (function *ARG_UNUSED (fun))\n+    {\n+      /* FIXME: this should use PROP_gimple_lomp_dev.  */\n+#ifdef ACCEL_COMPILER\n+      return true;\n+#else\n+      return ENABLE_OFFLOADING && (flag_openmp || in_lto_p);\n+#endif\n+    }\n+  virtual unsigned int execute (function *)\n+    {\n+      return execute_omp_device_lower ();\n+    }\n+\n+}; // class pass_expand_omp_ssa\n+\n+} // anon namespace\n+\n+gimple_opt_pass *\n+make_pass_omp_device_lower (gcc::context *ctxt)\n+{\n+  return new pass_omp_device_lower (ctxt);\n+}\n+\n+/* \"omp declare target link\" handling pass.  */\n+\n+namespace {\n+\n+const pass_data pass_data_omp_target_link =\n+{\n+  GIMPLE_PASS,\t\t\t/* type */\n+  \"omptargetlink\",\t\t/* name */\n+  OPTGROUP_OPENMP,\t\t/* optinfo_flags */\n+  TV_NONE,\t\t\t/* tv_id */\n+  PROP_ssa,\t\t\t/* properties_required */\n+  0,\t\t\t\t/* properties_provided */\n+  0,\t\t\t\t/* properties_destroyed */\n+  0,\t\t\t\t/* todo_flags_start */\n+  TODO_update_ssa,\t\t/* todo_flags_finish */\n+};\n+\n+class pass_omp_target_link : public gimple_opt_pass\n+{\n+public:\n+  pass_omp_target_link (gcc::context *ctxt)\n+    : gimple_opt_pass (pass_data_omp_target_link, ctxt)\n+  {}\n+\n+  /* opt_pass methods: */\n+  virtual bool gate (function *fun)\n+    {\n+#ifdef ACCEL_COMPILER\n+      tree attrs = DECL_ATTRIBUTES (fun->decl);\n+      return lookup_attribute (\"omp declare target\", attrs)\n+\t     || lookup_attribute (\"omp target entrypoint\", attrs);\n+#else\n+      (void) fun;\n+      return false;\n+#endif\n+    }\n+\n+  virtual unsigned execute (function *);\n+};\n+\n+/* Callback for walk_gimple_stmt used to scan for link var operands.  */\n+\n+static tree\n+find_link_var_op (tree *tp, int *walk_subtrees, void *)\n+{\n+  tree t = *tp;\n+\n+  if (VAR_P (t) && DECL_HAS_VALUE_EXPR_P (t)\n+      && lookup_attribute (\"omp declare target link\", DECL_ATTRIBUTES (t)))\n+    {\n+      *walk_subtrees = 0;\n+      return t;\n+    }\n+\n+  return NULL_TREE;\n+}\n+\n+unsigned\n+pass_omp_target_link::execute (function *fun)\n+{\n+  basic_block bb;\n+  FOR_EACH_BB_FN (bb, fun)\n+    {\n+      gimple_stmt_iterator gsi;\n+      for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n+\tif (walk_gimple_stmt (&gsi, NULL, find_link_var_op, NULL))\n+\t  gimple_regimplify_operands (gsi_stmt (gsi), &gsi);\n+    }\n+\n+  return 0;\n+}\n+\n+} // anon namespace\n+\n+gimple_opt_pass *\n+make_pass_omp_target_link (gcc::context *ctxt)\n+{\n+  return new pass_omp_target_link (ctxt);\n+}"}, {"sha": "a14d9fefea2ee14a9f234507adf2515c83d5557e", "filename": "gcc/omp-offload.h", "status": "added", "additions": 30, "deletions": 0, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-offload.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fomp-offload.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-offload.h?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -0,0 +1,30 @@\n+/* Bits of OpenMP and OpenACC handling that is specific to device offloading\n+   and a lowering pass for OpenACC device directives.\n+\n+   Copyright (C) 2005-2016 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_OMP_DEVICE_H\n+#define GCC_OMP_DEVICE_H\n+\n+extern GTY(()) vec<tree, va_gc> *offload_funcs;\n+extern GTY(()) vec<tree, va_gc> *offload_vars;\n+\n+extern void omp_finish_file (void);\n+\n+#endif /* GCC_OMP_DEVICE_H */"}, {"sha": "79d7a6fda1f695813c3b6995017ac1c64569ff89", "filename": "gcc/toplev.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftoplev.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftoplev.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftoplev.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -76,7 +76,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"ipa-prop.h\"\n #include \"gcse.h\"\n #include \"tree-chkp.h\"\n-#include \"omp-low.h\"\n+#include \"omp-offload.h\"\n #include \"hsa.h\"\n #include \"edit-context.h\"\n "}, {"sha": "d4a7db8f6ecf71e30859d04d6738a16191940cdf", "filename": "gcc/tree-cfg.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-cfg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-cfg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-cfg.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -54,7 +54,8 @@ along with GCC; see the file COPYING3.  If not see\n #include \"value-prof.h\"\n #include \"tree-inline.h\"\n #include \"tree-ssa-live.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n+#include \"omp-expand.h\"\n #include \"tree-cfgcleanup.h\"\n #include \"gimplify.h\"\n #include \"attribs.h\"\n@@ -863,7 +864,7 @@ make_edges_bb (basic_block bb, struct omp_region **pcur_region, int *pomp_index)\n       break;\n \n     CASE_GIMPLE_OMP:\n-      fallthru = make_gimple_omp_edges (bb, pcur_region, pomp_index);\n+      fallthru = omp_make_gimple_edges (bb, pcur_region, pomp_index);\n       break;\n \n     case GIMPLE_TRANSACTION:\n@@ -1006,7 +1007,7 @@ make_edges (void)\n \n   XDELETE (bb_to_omp_idx);\n \n-  free_omp_regions ();\n+  omp_free_regions ();\n }\n \n /* Add SEQ after GSI.  Start new bb after GSI, and created further bbs as"}, {"sha": "238017a003106f830c370ff374d726850027c306", "filename": "gcc/tree-parloops.c", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-parloops.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-parloops.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-parloops.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -49,6 +49,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-vectorizer.h\"\n #include \"tree-hasher.h\"\n #include \"tree-parloops.h\"\n+#include \"omp-general.h\"\n #include \"omp-low.h\"\n #include \"tree-ssa.h\"\n #include \"params.h\"\n@@ -2045,7 +2046,7 @@ create_parallel_loop (struct loop *loop, tree loop_fn, tree data,\n       tree clause = build_omp_clause (loc, OMP_CLAUSE_NUM_GANGS);\n       OMP_CLAUSE_NUM_GANGS_EXPR (clause)\n \t= build_int_cst (integer_type_node, n_threads);\n-      set_oacc_fn_attrib (cfun->decl, clause, true, NULL);\n+      oacc_set_fn_attrib (cfun->decl, clause, true, NULL);\n     }\n   else\n     {\n@@ -3199,7 +3200,7 @@ parallelize_loops (bool oacc_kernels_p)\n \n   /* Do not parallelize loops in offloaded functions.  */\n   if (!oacc_kernels_p\n-      && get_oacc_fn_attrib (cfun->decl) != NULL)\n+      && oacc_get_fn_attrib (cfun->decl) != NULL)\n      return false;\n \n   if (cfun->has_nonlocal_label)"}, {"sha": "84f13ada29939ad4f75b659d4e8cc0b286237b60", "filename": "gcc/tree-ssa-loop.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-ssa-loop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-ssa-loop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -36,7 +36,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-inline.h\"\n #include \"tree-scalar-evolution.h\"\n #include \"tree-vectorizer.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n #include \"diagnostic-core.h\"\n \n \n@@ -152,7 +152,7 @@ gate_oacc_kernels (function *fn)\n   if (!flag_openacc)\n     return false;\n \n-  tree oacc_function_attr = get_oacc_fn_attrib (fn->decl);\n+  tree oacc_function_attr = oacc_get_fn_attrib (fn->decl);\n   if (oacc_function_attr == NULL_TREE)\n     return false;\n   if (!oacc_fn_attrib_kernels_p (oacc_function_attr))"}, {"sha": "97e9953a139b0c3f39859461c20f37db200683d2", "filename": "gcc/tree-vrp.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-vrp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Ftree-vrp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vrp.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -55,7 +55,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-ssa-threadupdate.h\"\n #include \"tree-ssa-scopedtables.h\"\n #include \"tree-ssa-threadedge.h\"\n-#include \"omp-low.h\"\n+#include \"omp-general.h\"\n #include \"target.h\"\n #include \"case-cfn-macros.h\"\n #include \"params.h\"\n@@ -4003,8 +4003,8 @@ extract_range_basic (value_range *vr, gimple *stmt)\n \t     and pos is [0,N-1].  */\n \t  {\n \t    bool is_pos = cfn == CFN_GOACC_DIM_POS;\n-\t    int axis = get_oacc_ifn_dim_arg (stmt);\n-\t    int size = get_oacc_fn_dim_size (current_function_decl, axis);\n+\t    int axis = oacc_get_ifn_dim_arg (stmt);\n+\t    int size = oacc_get_fn_dim_size (current_function_decl, axis);\n \n \t    if (!size)\n \t      /* If it's dynamic, the backend might know a hardware"}, {"sha": "d5b2b9e25a3907c05d8c2ba372ad032cdaeca5a2", "filename": "gcc/varpool.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fvarpool.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/629b3d75c8c5a244d891a9c292bca6912d4b0dd9/gcc%2Fvarpool.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvarpool.c?ref=629b3d75c8c5a244d891a9c292bca6912d4b0dd9", "patch": "@@ -31,7 +31,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"varasm.h\"\n #include \"debug.h\"\n #include \"output.h\"\n-#include \"omp-low.h\"\n+#include \"omp-offload.h\"\n #include \"context.h\"\n \n const char * const tls_model_names[]={\"none\", \"emulated\","}]}