{"sha": "807e902eea17f3132488c256c963823976b2348c", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ODA3ZTkwMmVlYTE3ZjMxMzI0ODhjMjU2Yzk2MzgyMzk3NmIyMzQ4Yw==", "commit": {"author": {"name": "Kenneth Zadeck", "email": "zadeck@naturalbridge.com", "date": "2014-05-06T16:25:05Z"}, "committer": {"name": "Mike Stump", "email": "mrs@gcc.gnu.org", "date": "2014-05-06T16:25:05Z"}, "message": "Merge in wide-int.\n\nFrom-SVN: r210113", "tree": {"sha": "e5e1af94eb1502ba893bd6ce4a11f68877ff62a9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e5e1af94eb1502ba893bd6ce4a11f68877ff62a9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/807e902eea17f3132488c256c963823976b2348c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/807e902eea17f3132488c256c963823976b2348c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/807e902eea17f3132488c256c963823976b2348c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/807e902eea17f3132488c256c963823976b2348c/comments", "author": {"login": "zadeck", "id": 42682403, "node_id": "MDQ6VXNlcjQyNjgyNDAz", "avatar_url": "https://avatars.githubusercontent.com/u/42682403?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zadeck", "html_url": "https://github.com/zadeck", "followers_url": "https://api.github.com/users/zadeck/followers", "following_url": "https://api.github.com/users/zadeck/following{/other_user}", "gists_url": "https://api.github.com/users/zadeck/gists{/gist_id}", "starred_url": "https://api.github.com/users/zadeck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zadeck/subscriptions", "organizations_url": "https://api.github.com/users/zadeck/orgs", "repos_url": "https://api.github.com/users/zadeck/repos", "events_url": "https://api.github.com/users/zadeck/events{/privacy}", "received_events_url": "https://api.github.com/users/zadeck/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "6122336c832dc4dfedc49279549caddce86306ff", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6122336c832dc4dfedc49279549caddce86306ff", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6122336c832dc4dfedc49279549caddce86306ff"}], "stats": {"total": 16177, "additions": 11301, "deletions": 4876}, "files": [{"sha": "71057cfa9726f9923100a4f67a2028f997c126a8", "filename": "gcc/ChangeLog.wide-int", "status": "added", "additions": 899, "deletions": 0, "changes": 899, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2FChangeLog.wide-int", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2FChangeLog.wide-int", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog.wide-int?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -0,0 +1,899 @@\n+2013-11-21  Kenneth Zadeck  <zadeck@naturalbridge.com>\n+\t    Mike Stump  <mikestump@comcast.net>\n+\t    Richard Sandiford  <rdsandiford@googlemail.com>\n+\t    Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n+\n+\t* alias.c (ao_ref_from_mem): Use wide-int interfaces.\n+\t(rtx_equal_for_memref_p): Update comment.\n+\t(adjust_offset_for_component_ref): Use wide-int interfaces.\n+\t* builtins.c (get_object_alignment_2): Likewise.\n+\t(c_readstr): Likewise.\n+\t(target_char_cast): Add comment.\n+\t(determine_block_size): Use wide-int interfaces.\n+\t(expand_builtin_signbit): Likewise.\n+\t(fold_builtin_int_roundingfn): Likewise.\n+\t(fold_builtin_bitop): Likewise.\n+\t(fold_builtin_bswap): Likewise.\n+\t(fold_builtin_logarithm): Use signop.\n+\t(fold_builtin_pow): Likewise.\n+\t(fold_builtin_memory_op): Use wide-int interfaces.\n+\t(fold_builtin_object_size): Likewise.\n+\t* cfgloop.c (alloc_loop): Initialize nb_iterations_upper_bound and\n+\tnb_iterations_estimate.\n+\t(record_niter_bound): Use wide-int interfaces.\n+\t(get_estimated_loop_iterations_int): Likewise.\n+\t(get_estimated_loop_iterations): Likewise.\n+\t(get_max_loop_iterations): Likewise.\n+\t* cfgloop.h: Include wide-int.h.\n+\t(struct nb_iter_bound): Change bound to widest_int.\n+\t(struct loop): Change nb_iterations_upper_bound and\n+\tnb_iterations_estimate to widest_int.\n+\t(record_niter_bound): Switch to use widest_int.\n+\t(get_estimated_loop_iterations): Likewise.\n+\t(get_max_loop_iterations): Likewise.\n+\t(gcov_type_to_double_int): Rename to gcov_type_to_wide_int and\n+\tupdate for wide-int.\n+\t* cgraph.c (cgraph_add_thunk): Use wide-int interfaces.\n+\t* combine.c (try_combine): Likewise.\n+\t(subst): Use CONST_SCALAR_INT_P rather than CONST_INT_P.\n+\t* config/aarch64/aarch64.c (aapcs_vfp_sub_candidate): Use wide-int\n+\tinterfaces.\n+\t(aarch64_float_const_representable_p): Likewise.\n+\t* config/arc/arc.c: Include wide-int.h.\n+\t(arc_can_use_doloop_p): Use wide-int interfaces.\n+\t* config/arm/arm.c (aapcs_vfp_sub_candidate): Likewise.\n+\t(vfp3_const_double_index): Likewise.\n+\t* config/avr/avr.c (avr_out_round): Likewise.\n+\t(avr_fold_builtin): Likewise.\n+\t* config/bfin/bfin.c (bfin_local_alignment): Likewise.\n+\t(bfin_can_use_doloop_p): Likewise.\n+\t* config/darwin.c (darwin_mergeable_constant_section): Likewise.\n+\t(machopic_select_rtx_section): Update to handle CONST_WIDE_INT.\n+\t* config/i386/i386.c: Include wide-int.h.\n+\t(ix86_data_alignment): Use wide-int interfaces.\n+\t(ix86_local_alignment): Likewise.\n+\t(ix86_emit_swsqrtsf): Update real_from_integer.\n+\t* config/msp430/msp430.c (msp430_attr): Use wide-int interfaces.\n+\t* config/nds32/nds32.c (nds32_insert_attributes): Likewise.\n+\t* config/rs6000/predicates.md (any_operand): Add const_wide_int.\n+\t(zero_constant): Likewise.\n+\t(input_operand): Likewise.\n+\t(splat_input_operand): Likewise.\n+\t(non_logical_cint_operand): Change const_double to const_wide_int.\n+\t* config/rs6000/rs6000.c (num_insns_constant): Handle CONST_WIDE_INT.\n+\t(easy_altivec_constant): Remove comment.\n+\t(paired_expand_vector_init): Use CONSTANT_P.\n+\t(rs6000_legitimize_address): Handle CONST_WIDE_INT.\n+\t(rs6000_emit_move): Update checks.\n+\t(rs6000_aggregate_candidate): Use wide-int interfaces.\n+\t(rs6000_expand_ternop_builtin): Likewise.\n+\t(rs6000_output_move_128bit): Handle CONST_WIDE_INT.\n+\t(rs6000_assemble_integer): Likewise.\n+\t(rs6000_hash_constant): Likewise.\n+\t(output_toc): Likewise.\n+\t(rs6000_rtx_costs): Likewise.\n+\t(rs6000_emit_swrsqrt); Update call to real_from_integer.\n+\t* config/rs6000/rs6000-c.c: Include wide-int.h.\n+\t(altivec_resolve_overloaded_builtin): Use wide-int interfaces.\n+\t* config/rs6000/rs6000.h (TARGET_SUPPORTS_WIDE_INT): New.\n+\t* config/rs6000/rs6000.md: Use const_scalar_int_operand.\n+\tHandle CONST_WIDE_INT.\n+\t* config/sol2-c.c (solaris_pragma_align): Change low to unsigned HWI.\n+\tUse tree_fits_uhwi_p.\n+\t* config/sparc/sparc.c: Include wide-int.h.\n+\t(sparc_fold_builtin): Use wide-int interfaces.\n+\t* config/vax/vax.c: Include wide-int.h.\n+\t(vax_float_literal): Use real_from_integer.\n+\t* coretypes.h (struct hwivec_def): New.\n+\t(hwivec): New.\n+\t(const_hwivec): New.\n+\t* cse.c (hash_rtx_cb): Handle CONST_WIDE_INT.\n+\t(equiv_constant): Handle CONST_WIDE_INT.\n+\t* cselib.c (rtx_equal_for_cselib_1): Use CASE_CONST_UNIQUE.\n+\t(cselib_hash_rtx): Handle CONST_WIDE_INT.\n+\t* dbxout.c (stabstr_U): Use wide-int interfaces.\n+\t(dbxout_type): Update to use cst_fits_shwi_p.\n+\t* defaults.h (LOG2_BITS_PER_UNIT): Define.\n+\t(TARGET_SUPPORTS_WIDE_INT): Add default.\n+\t* dfp.c: Include wide-int.h.\n+\t(decimal_real_to_integer2): Use wide-int interfaces and rename to\n+\tdecimal_real_to_integer.\n+\t* dfp.h (decimal_real_to_integer2): Return a wide_int and rename to\n+\tdecimal_real_to_integer.\n+\t* doc/generic.texi (Constant expressions): Update for wide_int.\n+\t* doc/rtl.texi (const_double): Likewise.\n+\t(const_wide_int, CONST_WIDE_INT, CONST_WIDE_INT_VEC): New.\n+\t(CONST_WIDE_INT_NUNITS, CONST_WIDE_INT_ELT): New.\n+\t* doc/tm.texi.in (REAL_VALUE_TO_INT): Remove.\n+\t(REAL_VALUE_FROM_INT): Remove.\n+\t(TARGET_SUPPORTS_WIDE_INT): New.\n+\t* doc/tm.texi: Regenerate.\n+\t* dojump.c (prefer_and_bit_test): Use wide-int interfaces.\n+\t* double-int.h: Include wide-int.h.\n+\t(struct wi::int_traits): New.\n+\t* dwarf2out.c (get_full_len): New.\n+\t(dw_val_equal_p): Add case dw_val_class_wide_int.\n+\t(size_of_loc_descr): Likewise.\n+\t(output_loc_operands): Likewise.\n+\t(insert_double): Remove.\n+\t(insert_wide_int): New.\n+\t(add_AT_wide): New.\n+\t(print_die): Add case dw_val_class_wide_int.\n+\t(attr_checksum): Likewise.\n+\t(attr_checksum_ordered): Likewise.\n+\t(same_dw_val_p): Likewise.\n+\t(size_of_die): Likewise.\n+\t(value_format): Likewise.\n+\t(output_die): Likewise.\n+\t(double_int_type_size_in_bits): Rename to offset_int_type_size_in_bits.\n+\tUse wide-int.\n+\t(clz_loc_descriptor): Use wide-int interfaces.\n+\t(mem_loc_descriptor): Likewise.  Handle CONST_WIDE_INT.\n+\t(loc_descriptor): Use wide-int interfaces.  Handle CONST_WIDE_INT.\n+\t(round_up_to_align): Use wide-int interfaces.\n+\t(field_byte_offset): Likewise.\n+\t(insert_double): Rename to insert_wide_int.  Use wide-int interfaces.\n+\t(add_const_value_attribute): Handle CONST_WIDE_INT.  Update\n+\tCONST_DOUBLE handling.  Use wide-int interfaces.\n+\t(add_bound_info): Use tree_fits_uhwi_p.  Use wide-int interfaces.\n+\t(gen_enumeration_type_die): Use add_AT_wide.\n+\t(hash_loc_operands): Add case dw_val_class_wide_int.\n+\t(compare_loc_operands): Likewise.\n+\t* dwarf2out.h: Include wide-int.h.\n+\t(wide_int_ptr): New.\n+\t(enum dw_val_class): Add dw_val_class_wide_int.\n+\t(struct dw_val_struct): Add val_wide.\n+\t* emit-rtl.c (const_wide_int_htab): New.\n+\t(const_wide_int_htab_hash): New.\n+\t(const_wide_int_htab_eq): New.\n+\t(lookup_const_wide_int): New.\n+\t(const_double_htab_hash): Use wide-int interfaces.\n+\t(const_double_htab_eq): Likewise.\n+\t(rtx_to_double_int): Conditionally compile for wide-int.\n+\t(immed_double_int_const): Rename to immed_wide_int_const and\n+\tupdate for wide-int.\n+\t(immed_double_const): Conditionally compile for wide-int.\n+\t(init_emit_once): Use wide-int interfaces.\n+\t* explow.c (plus_constant): Likewise.\n+\t* expmed.c (mask_rtx): Move further up file.  Use wide-int interfaces.\n+\t(lshift_value): Use wide-int interfaces.\n+\t(expand_mult): Likewise.\n+\t(choose_multiplier): Likewise.\n+\t(expand_smod_pow2): Likewise.\n+\t(make_tree): Likewise.\n+\t* expr.c (convert_modes): Consolidate handling of constants.\n+\tUse wide-int interfaces.\n+\t(emit_group_load_1): Add note.\n+\t(store_expr): Update comment.\n+\t(get_inner_reference): Use wide-int interfaces.\n+\t(expand_constructor): Update comment.\n+\t(expand_expr_real_2): Use wide-int interfaces.\n+\t(expand_expr_real_1): Likewise.\n+\t(reduce_to_bit_field_precision): Likewise.\n+\t(const_vector_from_tree): Likewise.\n+\t* final.c: Include wide-int-print.h.\n+\t(output_addr_const): Handle CONST_WIDE_INT.  Use CONST_DOUBLE_AS_INT_P.\n+\t* fixed-value.c: Include wide-int.h.\n+\t(fixed_from_string): Use wide-int interfaces.\n+\t(fixed_to_decimal): Likewise.\n+\t(fixed_convert_from_real): Likewise.\n+\t(real_convert_from_fixed): Likewise.\n+\t* fold-const.h (mem_ref_offset): Return an offset_int.\n+\t(div_if_zero_remainder): Remove code parameter.\n+\t* fold-const.c (div_if_zero_remainder): Remove code parameter.\n+\tUse wide-int interfaces.\n+\t(may_negate_without_overflow_p): Use wide-int interfaces.\n+\t(negate_expr_p): Likewise.\n+\t(fold_negate_expr): Likewise.\n+\t(int_const_binop_1): Likewise.\n+\t(const_binop): Likewise.\n+\t(fold_convert_const_int_from_int): Likewise.\n+\t(fold_convert_const_int_from_real): Likewise.\n+\t(fold_convert_const_int_from_fixed): Likewise.\n+\t(fold_convert_const_fixed_from_int): Likewise.\n+\t(all_ones_mask_p): Take an unsigned size.  Use wide-int interfaces.\n+\t(sign_bit_p): Use wide-int interfaces.\n+\t(make_range_step): Likewise.\n+\t(build_range_check): Likewise.  Pass an integer of the correct type\n+\tinstead of using integer_one_node.\n+\t(range_predecessor): Pass an integer of the correct type instead\n+\tof using integer_one_node.\n+\t(range_successor): Likewise.\n+\t(merge_ranges): Likewise.\n+\t(unextend): Use wide-int interfaces.\n+\t(extract_muldiv_1): Likewise.\n+\t(fold_div_compare): Likewise.\n+\t(fold_single_bit_test): Likewise.\n+\t(fold_sign_changed_comparison): Likewise.\n+\t(try_move_mult_to_index): Update calls to div_if_zero_remainder.\n+\t(fold_plusminus_mult_expr): Use wide-int interfaces.\n+\t(native_encode_int): Likewise.\n+\t(native_interpret_int): Likewise.\n+\t(fold_unary_loc): Likewise.\n+\t(pointer_may_wrap_p): Likewise.\n+\t(size_low_cst): Likewise.\n+\t(mask_with_tz): Likewise.\n+\t(fold_binary_loc): Likewise.\n+\t(fold_ternary_loc): Likewise.\n+\t(multiple_of_p): Likewise.\n+\t(tree_call_nonnegative_warnv_p): Update calls to\n+\ttree_int_cst_min_precision and real_from_integer.\n+\t(fold_negate_const): Use wide-int interfaces.\n+\t(fold_abs_const): Likewise.\n+\t(fold_relational_const): Use tree_int_cst_lt.\n+\t(round_up_loc): Use wide-int interfaces.\n+\t* genemit.c (gen_exp): Add CONST_WIDE_INT case.\n+\t* gengenrtl.c (excluded_rtx): Add CONST_WIDE_INT case.\n+\t* gengtype.c: Remove include of double-int.h.\n+\t(do_typedef): Use wide-int interfaces.\n+\t(open_base_files): Add wide-int.h.\n+\t(main): Add offset_int and widest_int typedefs.\n+\t* gengtype-lex.l: Handle \"^\".\n+\t(CXX_KEYWORD): Add \"static\".\n+\t* gengtype-parse.c (require3): New.\n+\t(require_template_declaration): Handle constant template arguments\n+\tand nested templates.\n+\t* gengtype-state.c: Don't include \"double-int.h\".\n+\t* genpreds.c (write_one_predicate_function): Update comment.\n+\t(write_tm_constrs_h): Add check for hval and lval use in\n+\tCONST_WIDE_INT.\n+\t* genrecog.c (validate_pattern): Add CONST_WIDE_INT case.\n+\t(add_to_sequence): Likewise.\n+\t* gensupport.c (struct std_pred_table): Add const_scalar_int_operand\n+\tand const_double_operand.\n+\t* gimple.c (preprocess_case_label_vec_for_gimple): Use wide-int\n+\tinterfaces.\n+\t* gimple-fold.c (get_base_constructor): Likewise.\n+\t(fold_array_ctor_reference): Likewise.\n+\t(fold_nonarray_ctor_reference): Likewise.\n+\t(fold_const_aggregate_ref_1): Likewise.\n+\t(gimple_val_nonnegative_real_p): Likewise.\n+\t(gimple_fold_indirect_ref): Likewise.\n+\t* gimple-pretty-print.c (dump_ssaname_info): Likewise.\n+\t* gimple-ssa-strength-reduction.c: Include wide-int-print.h.\n+\t(struct slsr_cand_d): Change index to be widest_int.\n+\t(struct incr_info_d): Change incr to be widest_int.\n+\t(alloc_cand_and_find_basis): Use wide-int interfaces.\n+\t(slsr_process_phi): Likewise.\n+\t(backtrace_base_for_ref): Likewise.  Return a widest_int.\n+\t(restructure_reference): Take a widest_int instead of a double_int.\n+\t(slsr_process_ref): Use wide-int interfaces.\n+\t(create_mul_ssa_cand): Likewise.\n+\t(create_mul_imm_cand): Likewise.\n+\t(create_add_ssa_cand): Likewise.\n+\t(create_add_imm_cand): Take a widest_int instead of a double_int.\n+\t(slsr_process_add): Use wide-int interfaces.\n+\t(slsr_process_cast): Likewise.\n+\t(slsr_process_copy): Likewise.\n+\t(dump_candidate): Likewise.\n+\t(dump_incr_vec): Likewise.\n+\t(replace_ref): Likewise.\n+\t(cand_increment): Likewise.  Return a widest_int.\n+\t(cand_abs_increment): Likewise.\n+\t(replace_mult_candidate): Take a widest_int instead of a double_int.\n+\t(replace_unconditional_candidate): Use wide-int interfaces.\n+\t(incr_vec_index): Take a widest_int instead of a double_int.\n+\t(create_add_on_incoming_edge): Likewise.\n+\t(create_phi_basis): Use wide-int interfaces.\n+\t(replace_conditional_candidate): Likewise.\n+\t(record_increment): Take a widest_int instead of a double_int.\n+\t(record_phi_increments): Use wide-int interfaces.\n+\t(phi_incr_cost): Take a widest_int instead of a double_int.\n+\t(lowest_cost_path): Likewise.\n+\t(total_savings): Likewise.\n+\t(analyze_increments): Use wide-int interfaces.\n+\t(ncd_with_phi): Take a widest_int instead of a double_int.\n+\t(ncd_of_cand_and_phis): Likewise.\n+\t(nearest_common_dominator_for_cands): Likewise.\n+\t(insert_initializers): Use wide-int interfaces.\n+\t(all_phi_incrs_profitable): Likewise.\n+\t(replace_one_candidate): Likewise.\n+\t(replace_profitable_candidates): Likewise.\n+\t* godump.c: Include wide-int-print.h.\n+\t(go_output_typedef): Use wide-int interfaces.\n+\t* graphite-clast-to-gimple.c (gmp_cst_to_tree): Likewise.\n+\t* graphite-sese-to-poly.c (tree_int_to_gmp): Likewise.\n+\t(build_loop_iteration_domains): Likewise.\n+\t* hooks.h: Include wide-int.h rather than double-int.h.\n+\t(hook_bool_dint_dint_uint_bool_true): Delete.\n+\t(hook_bool_wint_wint_uint_bool_true): Declare.\n+\t* hooks.c (hook_bool_dint_dint_uint_bool_true): Removed.\n+\t(hook_bool_wint_wint_uint_bool_true): New.\n+\t* internal-fn.c (ubsan_expand_si_overflow_addsub_check): Use wide-int\n+\tinterfaces.\n+\t(ubsan_expand_si_overflow_mul_check): Likewise.\n+\t* ipa-devirt.c (get_polymorphic_call_info): Likewise.\n+\t* ipa-prop.c (compute_complex_assign_jump_func): Likewise.\n+\t(get_ancestor_addr_info): Likewise.\n+\t(ipa_modify_call_arguments): Likewise.\n+\t* loop-doloop.c (doloop_modify): Likewise.\n+\t(doloop_optimize): Likewise.\n+\t* loop-iv.c (iv_number_of_iterations): Likewise.\n+\t* loop-unroll.c (decide_unroll_constant_iterations): Likewise.\n+\t(unroll_loop_constant_iterations): Likewise.\n+\t(decide_unroll_runtime_iterations): Likewise.\n+\t(unroll_loop_runtime_iterations): Likewise.\n+\t(decide_peel_simple): Likewise.\n+\t(decide_unroll_stupid): Likewise.\n+\t* lto-streamer-in.c (streamer_read_wi): Add.\n+\t(input_cfg): Use wide-int interfaces.\n+\t(lto_input_tree_1): Likewise.\n+\t* lto-streamer-out.c (streamer_write_wi): Add.\n+\t(hash_tree): Use wide-int interfaces.\n+\t(output_cfg): Likewise.\n+\t* Makefile.in (OBJS): Add wide-int.o and wide-int-print.o.\n+\t(GTFILES): Add wide-int.h and signop.h.\n+\t(TAGS): Look for .cc files too.\n+\t* omp-low.c (scan_omp_1_op): Use wide-int interfaces.\n+\t* optabs.c (expand_subword_shift): Likewise.\n+\t(expand_doubleword_shift): Likewise.\n+\t(expand_absneg_bit): Likewise.\n+\t(expand_copysign_absneg): Likewise.\n+\t(expand_copysign_bit): Likewise.\n+\t* postreload.c (reload_cse_simplify_set): Likewise.\n+\t* predict.c (predict_iv_comparison): Likewise.\n+\t* pretty-print.h: Include wide-int-print.h.\n+\t(pp_wide_int) New.\n+\t* print-rtl.c (print_rtx): Add CONST_WIDE_INT case.\n+\t* print-tree.c: Include wide-int-print.h.\n+\t(print_node_brief): Use wide-int interfaces.\n+\t(print_node): Likewise.\n+\t* read-rtl.c (validate_const_wide_int): New.\n+\t(read_rtx_code): Add CONST_WIDE_INT case.\n+\t* real.c: Include wide-int.h.\n+\t(real_to_integer2): Delete.\n+\t(real_to_integer): New function, returning a wide_int.\n+\t(real_from_integer): Take a wide_int rather than two HOST_WIDE_INTs.\n+\t(ten_to_ptwo): Update call to real_from_integer.\n+\t(real_digit): Likewise.\n+\t* real.h: Include signop.h, wide-int.h and insn-modes.h.\n+\t(real_to_integer2, REAL_VALUE_FROM_INT, REAL_VALUE_FROM_UNSIGNED_INT)\n+\t(REAL_VALUE_TO_INT): Delete.\n+\t(real_to_integer): Declare a wide-int form.\n+\t(real_from_integer): Take a wide_int rather than two HOST_WIDE_INTs.\n+\t* recog.c (const_int_operand): Improve comment.\n+\t(const_scalar_int_operand): New.\n+\t(const_double_operand): Add a separate definition for CONST_WIDE_INT.\n+\t* rtlanal.c (commutative_operand_precedence): Handle CONST_WIDE_INT.\n+\t(split_double): Likewise.\n+\t* rtl.c (DEF_RTL_EXPR): Handle CONST_WIDE_INT.\n+\t(rtx_size): Likewise.\n+\t(rtx_alloc_stat_v): New.\n+\t(rtx_alloc_stat): Now calls rtx_alloc_stat_v.\n+\t(cwi_output_hex): New.\n+\t(iterative_hash_rtx): Handle CONST_WIDE_INT.\n+\t(cwi_check_failed_bounds): New.\n+\t* rtl.def (CONST_WIDE_INT): New.\n+\t* rtl.h: Include <utility> and wide-int.h.\n+\t(struct hwivec_def): New.\n+\t(CWI_GET_NUM_ELEM): New.\n+\t(CWI_PUT_NUM_ELEM): New.\n+\t(struct rtx_def): Add num_elem and hwiv.\n+\t(CASE_CONST_SCALAR_INT): Modify for TARGET_SUPPORTS_WIDE_INT.\n+\t(CASE_CONST_UNIQUE): Likewise.\n+\t(CASE_CONST_ANY): Likewise.\n+\t(CONST_SCALAR_INT_P): Likewise.\n+\t(CONST_WIDE_INT_P): New.\n+\t(CWI_ELT): New.\n+\t(HWIVEC_CHECK): New.\n+\t(cwi_check_failed_bounds): New.\n+\t(CWI_ELT): New.\n+\t(HWIVEC_CHECK): New.\n+\t(CONST_WIDE_INT_VEC) New.\n+\t(CONST_WIDE_INT_NUNITS) New.\n+\t(CONST_WIDE_INT_ELT) New.\n+\t(rtx_mode_t): New type.\n+\t(wi::int_traits <rtx_mode_t>): New.\n+\t(wi::shwi): New.\n+\t(wi::min_value): New.\n+\t(wi::max_value): New.\n+\t(rtx_alloc_v) New.\n+\t(const_wide_int_alloc): New.\n+\t(immed_wide_int_const): New.\n+\t* sched-vis.c (print_value): Handle CONST_WIDE_INT.\n+\t* sel-sched-ir.c (lhs_and_rhs_separable_p): Update comment.\n+\t* signop.h: New file.\n+\t* simplify-rtx.c (mode_signbit_p): Handle CONST_WIDE_INT.\n+\t(simplify_const_unary_operation): Use wide-int interfaces.\n+\t(simplify_binary_operation_1): Likewise.\n+\t(simplify_const_binary_operation): Likewise.\n+\t(simplify_const_relational_operation): Likewise.\n+\t(simplify_immed_subreg): Likewise.\n+\t* stmt.c (expand_case): Likewise.\n+\t* stor-layout.h (set_min_and_max_values_for_integral_type): Take a\n+\tsignop rather than a bool.\n+\t* stor-layout.c (layout_type): Use wide-int interfaces.\n+\t(initialize_sizetypes): Update calls to\n+\tset_min_and_max_values_for_integral_type.\n+\t(set_min_and_max_values_for_integral_type): Take a signop rather\n+\tthan a bool.  Use wide-int interfaces.\n+\t(fixup_signed_type): Update accordingly.  Remove\n+\tHOST_BITS_PER_DOUBLE_INT limit.\n+\t(fixup_unsigned_type): Likewise.\n+\t* system.h (STATIC_CONSTANT_P): New.\n+\t(STATIC_ASSERT): New.\n+\t* target.def (can_use_doloop_p): Take widest_ints rather than\n+\tdouble_ints.\n+\t* target.h: Include wide-int.h rather than double-int.h.\n+\t* targhooks.h (can_use_doloop_if_innermost): Take widest_ints rather\n+\tthan double_ints.\n+\t* targhooks.c (default_cxx_get_cookie_size): Use tree_int_cst_lt\n+\trather than INT_CST_LT_UNSIGNED.\n+\t(can_use_doloop_if_innermost): Take widest_ints rather than\n+\tdouble_ints.\n+\t* tree-affine.c: Include wide-int-print.h.\n+\t(double_int_ext_for_comb): Delete.\n+\t(wide_int_ext_for_comb): New.\n+\t(aff_combination_zero): Use wide-int interfaces.\n+\t(aff_combination_const): Take a widest_int instead of a double_int.\n+\t(aff_combination_elt): Use wide-int interfaces.\n+\t(aff_combination_scale): Take a widest_int instead of a double_int.\n+\t(aff_combination_add_elt): Likewise.\n+\t(aff_combination_add_cst): Likewise.\n+\t(aff_combination_add): Use wide-int interfaces.\n+\t(aff_combination_convert): Likewise.\n+\t(tree_to_aff_combination): Likewise.\n+\t(add_elt_to_tree): Take a widest_int instead of a double_int.\n+\t(aff_combination_to_tree): Use wide-int interfaces.\n+\t(aff_combination_remove_elt): Likewise.\n+\t(aff_combination_add_product): Take a widest_int instead of\n+\ta double_int.\n+\t(aff_combination_mult): Use wide-int interfaces.\n+\t(aff_combination_expand): Likewise.\n+\t(double_int_constant_multiple_p): Delete.\n+\t(wide_int_constant_multiple_p): New.\n+\t(aff_combination_constant_multiple_p): Take a widest_int pointer\n+\tinstead of a double_int pointer.\n+\t(print_aff): Use wide-int interfaces.\n+\t(get_inner_reference_aff): Take a widest_int pointer\n+\tinstead of a double_int pointer.\n+\t(aff_comb_cannot_overlap_p): Take widest_ints instead of double_ints.\n+\t* tree-affine.h: Include wide-int.h.\n+\t(struct aff_comb_elt): Change type of coef to widest_int.\n+\t(struct affine_tree_combination): Change type of offset to widest_int.\n+\t(double_int_ext_for_comb): Delete.\n+\t(wide_int_ext_for_comb): New.\n+\t(aff_combination_const): Use widest_int instead of double_int.\n+\t(aff_combination_scale): Likewise.\n+\t(aff_combination_add_elt): Likewise.\n+\t(aff_combination_constant_multiple_p): Likewise.\n+\t(get_inner_reference_aff): Likewise.\n+\t(aff_comb_cannot_overlap_p): Likewise.\n+\t(aff_combination_zero_p): Use wide-int interfaces.\n+\t* tree.c: Include tree.h.\n+\t(init_ttree): Use make_int_cst.\n+\t(tree_code_size): Removed code for INTEGER_CST case.\n+\t(tree_size): Add INTEGER_CST case.\n+\t(make_node_stat): Update comment.\n+\t(get_int_cst_ext_nunits, build_new_int_cst, build_int_cstu): New.\n+\t(build_int_cst_type): Use wide-int interfaces.\n+\t(double_int_to_tree): Likewise.\n+\t(double_int_fits_to_tree_p): Delete.\n+\t(force_fit_type_double): Delete.\n+\t(force_fit_type): New.\n+\t(int_cst_hash_hash): Use wide-int interfaces.\n+\t(int_cst_hash_eq): Likewise.\n+\t(build_int_cst_wide): Delete.\n+\t(wide_int_to_tree): New.\n+\t(cache_integer_cst): Use wide-int interfaces.\n+\t(build_low_bits_mask): Likewise.\n+\t(cst_and_fits_in_hwi): Likewise.\n+\t(real_value_from_int_cst): Likewise.\n+\t(make_int_cst_stat): New.\n+\t(integer_zerop): Use wide_int interfaces.\n+\t(integer_onep): Likewise.\n+\t(integer_all_onesp): Likewise.\n+\t(integer_pow2p): Likewise.\n+\t(integer_nonzerop): Likewise.\n+\t(tree_log2): Likewise.\n+\t(tree_floor_log2): Likewise.\n+\t(tree_ctz): Likewise.\n+\t(int_size_in_bytes): Likewise.\n+\t(mem_ref_offset): Return an offset_int rather than a double_int.\n+\t(build_type_attribute_qual_variant): Use wide_int interfaces.\n+\t(type_hash_eq): Likewise\n+\t(tree_int_cst_equal): Likewise.\n+\t(tree_int_cst_lt): Delete.\n+\t(tree_int_cst_compare): Likewise.\n+\t(tree_fits_shwi_p): Use wide_int interfaces.\n+\t(tree_fits_uhwi_p): Likewise.\n+\t(tree_int_cst_sign_bit): Likewise.\n+\t(tree_int_cst_sgn): Likewise.\n+\t(tree_int_cst_min_precision): Take a signop rather than a bool.\n+\t(simple_cst_equal): Use wide_int interfaces.\n+\t(compare_tree_int): Likewise.\n+\t(iterative_hash_expr): Likewise.\n+\t(int_fits_type_p): Likewise.  Use tree_int_cst_lt rather than\n+\tINT_CST_LT.\n+\t(get_type_static_bounds): Use wide_int interfaces.\n+\t(tree_int_cst_elt_check_failed): New.\n+\t(build_common_tree_nodes): Reordered to set prec before filling in\n+\tvalue.\n+\t(int_cst_value): Check cst_and_fits_in_hwi.\n+\t(widest_int_cst_value): Use wide_int interfaces.\n+\t(upper_bound_in_type): Likewise.\n+\t(lower_bound_in_type): Likewise.\n+\t(num_ending_zeros): Likewise.\n+\t(drop_tree_overflow): Likewise.\n+\t* tree-call-cdce.c (check_pow): Update call to real_from_integer.\n+\t(gen_conditions_for_pow_cst_base): Likewise.\n+\t* tree-cfg.c: Include wide-int.h and wide-int-print.h.\n+\t(group_case_labels_stmt): Use wide-int interfaces.\n+\t(verify_gimple_assign_binary): Likewise.\n+\t(print_loop): Likewise.\n+\t* tree-chrec.c (tree_fold_binomial): Likewise.\n+\t* tree-core.h (struct tree_base): Add int_length.\n+\t(struct tree_int_cst): Change rep of value.\n+\t* tree-data-ref.c (dr_analyze_innermost): Use wide-int interfaces.\n+\t(dr_may_alias_p): Likewise.\n+\t(max_stmt_executions_tree): Likewise.\n+\t* tree.def (INTEGER_CST): Update comment.\n+\t* tree-dfa.c (get_ref_base_and_extent): Use wide-int interfaces.\n+\t* tree-dfa.h (get_addr_base_and_unit_offset_1): Likewise.\n+\t* tree-dump.c: Include wide-int.h and wide-int-print.h.\n+\t(dequeue_and_dump): Use wide-int interfaces.\n+\t* tree.h: Include wide-int.h.\n+\t(NULL_TREE): Moved to earlier loc in file.\n+\t(TREE_INT_CST_ELT_CHECK): New.\n+\t(tree_int_cst_elt_check_failed): New.\n+\t(TYPE_SIGN): New.\n+\t(TREE_INT_CST): Delete.\n+\t(TREE_INT_CST_LOW): Use wide-int interfaces.\n+\t(TREE_INT_CST_HIGH): Delete.\n+\t(TREE_INT_CST_NUNITS): New.\n+\t(TREE_INT_CST_EXT_NUNITS): Likewise.\n+\t(TREE_INT_CST_OFFSET_NUNITS): Likewise.\n+\t(TREE_INT_CST_ELT): Likewise.\n+\t(INT_CST_LT): Delete.\n+\t(tree_int_cst_elt_check): New (two forms).\n+\t(type_code_size): Update comment.\n+\t(make_int_cst_stat, make_int_cst): New.\n+\t(tree_to_double_int): Delete.\n+\t(double_int_fits_to_tree_p): Delete.\n+\t(force_fit_type_double): Delete.\n+\t(build_int_cstu): Replace with out-of-line function.\n+\t(build_int_cst_wide): Delete.\n+\t(tree_int_cst_lt): Define inline.\n+\t(tree_int_cst_le): New.\n+\t(tree_int_cst_compare): Define inline.\n+\t(tree_int_cst_min_precision): Take a signop rather than a bool.\n+\t(wi::int_traits <const_tree>): New.\n+\t(wi::int_traits <tree>): New.\n+\t(wi::extended_tree): New.\n+\t(wi::int_traits <wi::extended_tree>): New.\n+\t(wi::to_widest): New.\n+\t(wi::to_offset): New.\n+\t(wi::fits_to_tree_p): New.\n+\t(wi::min_value): New.\n+\t(wi::max_value): New.\n+\t* tree-inline.c (remap_gimple_op_r): Use wide-int interfaces.\n+\t(copy_tree_body_r): Likewise.\n+\t* tree-object-size.c (compute_object_offset): Likewise.\n+\t(addr_object_size): Likewise.\n+\t* tree-predcom.c: Include wide-int-print.h.\n+\t(struct dref_d): Change type of offset to widest_int.\n+\t(dump_dref): Call wide-int printer.\n+\t(aff_combination_dr_offset): Use wide-int interfaces.\n+\t(determine_offset): Take a widest_int pointer rather than a\n+\tdouble_int pointer.\n+\t(split_data_refs_to_components): Use wide-int interfaces.\n+\t(suitable_component_p): Likewise.\n+\t(order_drefs): Likewise.\n+\t(add_ref_to_chain): Likewise.\n+\t(valid_initializer_p): Likewise.\n+\t(determine_roots_comp): Likewise.\n+\t* tree-pretty-print.c: Include wide-int-print.h.\n+\t(dump_generic_node): Use wide-int interfaces.\n+\t* tree-sra.c (sra_ipa_modify_expr): Likewise.\n+\t* tree-ssa-address.c (addr_for_mem_ref): Likewise.\n+\t(move_fixed_address_to_symbol): Likewise.\n+\t(move_hint_to_base): Likewise.\n+\t(move_pointer_to_base): Likewise.\n+\t(move_variant_to_index): Likewise.\n+\t(most_expensive_mult_to_index): Likewise.\n+\t(addr_to_parts): Likewise.\n+\t(copy_ref_info): Likewise.\n+\t* tree-ssa-alias.c (indirect_ref_may_alias_decl_p): Likewise.\n+\t(indirect_refs_may_alias_p): Likewise.\n+\t(stmt_kills_ref_p_1): Likewise.\n+\t* tree-ssa.c (non_rewritable_mem_ref_base): Likewise.\n+\t* tree-ssa-ccp.c: Update comment at top of file.  Include\n+\twide-int-print.h.\n+\t(struct prop_value_d): Change type of mask to widest_int.\n+\t(extend_mask): New function.\n+\t(dump_lattice_value): Use wide-int interfaces.\n+\t(get_default_value): Likewise.\n+\t(set_constant_value): Likewise.\n+\t(set_value_varying): Likewise.\n+\t(valid_lattice_transition): Likewise.\n+\t(set_lattice_value): Likewise.\n+\t(value_to_double_int): Delete.\n+\t(value_to_wide_int): New.\n+\t(get_value_from_alignment): Use wide-int interfaces.\n+\t(get_value_for_expr): Likewise.\n+\t(do_dbg_cnt): Likewise.\n+\t(ccp_finalize): Likewise.\n+\t(ccp_lattice_meet): Likewise.\n+\t(bit_value_unop_1): Use widest_ints rather than double_ints.\n+\t(bit_value_binop_1): Likewise.\n+\t(bit_value_unop): Use wide-int interfaces.\n+\t(bit_value_binop): Likewise.\n+\t(bit_value_assume_aligned): Likewise.\n+\t(evaluate_stmt): Likewise.\n+\t(ccp_fold_stmt): Likewise.\n+\t(visit_cond_stmt): Likewise.\n+\t(ccp_visit_stmt): Likewise.\n+\t* tree-ssa-forwprop.c (forward_propagate_addr_expr_1): Likewise.\n+\t(constant_pointer_difference): Likewise.\n+\t(associate_pointerplus): Likewise.\n+\t(combine_conversions): Likewise.\n+\t* tree-ssa-loop.h: Include wide-int.h.\n+\t(struct tree_niter_desc): Change type of max to widest_int.\n+\t* tree-ssa-loop-im.c (mem_refs_may_alias_p): Use wide-int interfaces.\n+\t* tree-ssa-loop-ivcanon.c (remove_exits_and_undefined_stmts): Likewise.\n+\t(remove_redundant_iv_tests): Likewise.\n+\t(canonicalize_loop_induction_variables): Likewise.\n+\t* tree-ssa-loop-ivopts.c (alloc_iv): Likewise.\n+\t(constant_multiple_of): Take a widest_int pointer instead of\n+\ta double_int pointer.\n+\t(get_computation_aff): Use wide-int interfaces.\n+\t(ptr_difference_cost): Likewise.\n+\t(difference_cost): Likewise.\n+\t(get_loop_invariant_expr_id): Likewise.\n+\t(get_computation_cost_at): Likewise.\n+\t(iv_elimination_compare_lt): Likewise.\n+\t(may_eliminate_iv): Likewise.\n+\t* tree-ssa-loop-niter.h (estimated_loop_iterations): Use widest_int\n+\tinstead of double_int.\n+\t(max_loop_iterations): Likewise.\n+\t(max_stmt_executions): Likewise.\n+\t(estimated_stmt_executions): Likewise.\n+\t* tree-ssa-loop-niter.c: Include wide-int-print.h.\n+\t(split_to_var_and_offset): Use wide-int interfaces.\n+\t(determine_value_range): Likewise.\n+\t(bound_difference_of_offsetted_base): Likewise.\n+\t(bounds_add): Take a widest_int instead of a double_int.\n+\t(number_of_iterations_ne_max): Use wide-int interfaces.\n+\t(number_of_iterations_ne): Likewise.\n+\t(number_of_iterations_lt_to_ne): Likewise.\n+\t(assert_loop_rolls_lt): Likewise.\n+\t(number_of_iterations_lt): Likewise.\n+\t(number_of_iterations_le): Likewise.\n+\t(number_of_iterations_cond): Likewise.\n+\t(number_of_iterations_exit): Likewise.\n+\t(finite_loop_p): Likewise.\n+\t(derive_constant_upper_bound_assign): Likewise.\n+\t(derive_constant_upper_bound): Return a widest_int.\n+\t(derive_constant_upper_bound_ops): Likewise.\n+\t(do_warn_aggressive_loop_optimizations): Use wide-int interfaces.\n+\t(record_estimate): Take a widest_int rather than a double_int.\n+\t(record_nonwrapping_iv): Use wide-int interfaces.\n+\t(double_int_cmp): Delete.\n+\t(wide_int_cmp): New.\n+\t(bound_index): Take a widest_int rather than a double_int.\n+\t(discover_iteration_bound_by_body_walk): Use wide-int interfaces.\n+\t(maybe_lower_iteration_bound): Likewise.\n+\t(estimate_numbers_of_iterations_loop): Likewise.\n+\t(estimated_loop_iterations): Take a widest_int pointer than than\n+\ta double_int pointer.\n+\t(estimated_loop_iterations_int): Use wide-int interfaces.\n+\t(max_loop_iterations): Take a widest_int pointer than than\n+\ta double_int pointer.\n+\t(max_loop_iterations_int): Use wide-int interfaces.\n+\t(max_stmt_executions): Take a widest_int pointer than than\n+\ta double_int pointer.\n+\t(estimated_stmt_executions): Likewise.\n+\t(n_of_executions_at_most): Use wide-int interfaces.\n+\t(scev_probably_wraps_p): Likewise.\n+\t* tree-ssa-math-opts.c (gimple_expand_builtin_pow): Update calls\n+\tto real_to_integer.\n+\t* tree-scalar-evolution.c (simplify_peeled_chrec): Use wide-int\n+\tinterfaces.\n+\t* tree-ssanames.c (set_range_info): Use wide_int_refs rather than\n+\tdouble_ints.  Adjust for trailing_wide_ints <3> representation.\n+\t(set_nonzero_bits): Likewise.\n+\t(get_range_info): Return wide_ints rather than double_ints.\n+\tAdjust for trailing_wide_ints <3> representation.\n+\t(get_nonzero_bits): Likewise.\n+\t(duplicate_ssa_name_range_info): Adjust for trailing_wide_ints <3>\n+\trepresentation.\n+\t* tree-ssanames.h (struct range_info_def): Replace min, max and\n+\tnonzero_bits with a trailing_wide_ints <3>.\n+\t(set_range_info): Use wide_int_refs rather than double_ints.\n+\t(set_nonzero_bits): Likewise.\n+\t(get_range_info): Return wide_ints rather than double_ints.\n+\t(get_nonzero_bits): Likewise.\n+\t* tree-ssa-phiopt.c (jump_function_from_stmt): Use wide-int interfaces.\n+\t* tree-ssa-pre.c (phi_translate_1): Likewise.\n+\t* tree-ssa-reassoc.c (decrement_power): Use calls to real_from_integer.\n+\t(acceptable_pow_call): Likewise.\n+\t* tree-ssa-sccvn.c (copy_reference_ops_from_ref): Use wide-int\n+\tinterfaces.\n+\t(vn_reference_fold_indirect): Likewise.\n+\t(vn_reference_maybe_forwprop_address): Likewise.\n+\t(valueize_refs_1): Likewise.\n+\t* tree-ssa-structalias.c (get_constraint_for_ptr_offset): Likewise.\n+\t* tree-ssa-uninit.c (is_value_included_in): Use wide-int interfaces,\n+\ttree_int_cst_lt and tree_int_cst_le.\n+\t* tree-streamer-in.c (unpack_ts_base_value_fields): Use wide-int\n+\tinterfaces.\n+\t(streamer_alloc_tree): Likewise.\n+\t* tree-streamer-out.c (pack_ts_int_cst_value_fields): Likewise.\n+\t(streamer_write_tree_header): Likewise.\n+\t(streamer_write_integer_cst): Likewise.\n+\t* tree-switch-conversion.c (emit_case_bit_tests): Likewise.\n+\t(build_constructors): Likewise.\n+\t(array_value_type): Likewise.\n+\t* tree-vect-data-refs.c (vect_prune_runtime_alias_test_list): Likewise.\n+\t(vect_check_gather): Likewise.\n+\t* tree-vect-generic.c (build_replicated_const): Likewise.\n+\t(expand_vector_divmod): Likewise.\n+\t* tree-vect-loop.c (vect_transform_loop): Likewise.\n+\t* tree-vect-loop-manip.c (vect_do_peeling_for_loop_bound): Likewise.\n+\t(vect_do_peeling_for_alignment): Likewise.\n+\t* tree-vect-patterns.c (vect_recog_divmod_pattern): Likewise.\n+\t* tree-vrp.c: Include wide-int.h.\n+\t(operand_less_p): Use wide-int interfaces and tree_int_cst_lt.\n+\t(extract_range_from_assert): Use wide-int interfaces.\n+\t(vrp_int_const_binop): Likewise.\n+\t(zero_nonzero_bits_from_vr): Take wide_int pointers rather than\n+\tdouble_int pointers.\n+\t(ranges_from_anti_range): Use wide-int interfaces.\n+\t(quad_int_cmp): Delete.\n+\t(quad_int_pair_sort): Likewise.\n+\t(extract_range_from_binary_expr_1): Use wide-int interfaces.\n+\t(extract_range_from_unary_expr_1): Likewise.\n+\t(adjust_range_with_scev): Likewise.\n+\t(masked_increment): Take and return wide_ints rather than double_ints.\n+\t(register_edge_assert_for_2): Use wide-int interfaces.\n+\t(check_array_ref): Likewise.\n+\t(search_for_addr_array): Likewise.\n+\t(maybe_set_nonzero_bits): Likewise.\n+\t(union_ranges): Pass an integer of the correct type instead of\n+\tusing integer_one_node.\n+\t(intersect_ranges): Likewise.\n+\t(simplify_truth_ops_using_ranges): Likewise.\n+\t(simplify_bit_ops_using_ranges): Use wide-int interfaces.\n+\t(range_fits_type_p): Likewise.\n+\t(simplify_cond_using_ranges): Likewise.  Take a signop rather than\n+\ta bool.\n+\t(simplify_conversion_using_ranges): Use wide-int interfaces.\n+\t(simplify_float_conversion_using_ranges): Likewise.\n+\t(vrp_finalize): Likewise.\n+\t* value-prof.c (gimple_divmod_fixed_value_transform): Likewise.\n+\t(gimple_stringops_transform): Likewise.\n+\t* varasm.c (decode_addr_const): Likewise.\n+\t(const_hash_1): Likewise.\n+\t(const_rtx_hash_1): Likewise\n+\t(output_constant): Likewise.\n+\t(array_size_for_constructor): Likewise.\n+\t(output_constructor_regular_field): Likewise.\n+\t(output_constructor_bitfield): Likewise.\n+\t* var-tracking.c (loc_cmp): Handle CONST_WIDE_INT.\n+\t* mkconfig.sh: Include machmode.h to pick up BITS_PER_UNIT for\n+\tGENERATOR_FILEs.\n+\t* gencheck.c: Define BITS_PER_UNIT.\n+\t* wide-int.cc: New.\n+\t* wide-int.h: New.\n+\t* wide-int-print.cc: New.\n+\t* wide-int-print.h: New.\n+\n+\n+ada:\n+\t* gcc-interface/cuintp.c (UI_From_gnu): Use wide-int interfaces.\n+\t* gcc-interface/decl.c (gnat_to_gnu_entity): Use TYPE_SIGN.\n+\t(annotate_value): Use wide-int interfaces.\n+\t* gcc-interface/utils.c (get_nonnull_operand): Use tree_fits_uhwi_p.\n+\n+\n+c:\n+\t* c-decl.c (check_bitfield_type_and_width): Use TYPE_SIGN.\n+\t(finish_enum): Use wide-int interfaces.\n+\t* c-parser.c (c_parser_cilk_clause_vectorlength): Likewise.\n+\t* c-typeck.c (build_c_cast): Likewise.\n+\t(set_nonincremental_init_from_string): Likewise.\n+\t(c_tree_equal): Likewise.\n+\n+\n+c-family:\n+\t* c-ada-spec.c: Include wide-int.h.\n+\t(ADA_HOST_WIDE_INT_PRINT_DOUBLE_HEX): Remove.\n+\t(dump_generic_ada_node): Use wide-int interfaces.\n+\t* c-common.c: Include wide-int-print.h.\n+\t(shorten_compare): Use wide-int interfaces and tree_int_cst_lt.\n+\t(pointer_int_sum): Use wide-int interfaces.\n+\t(c_common_nodes_and_builtins): Use make_int_cst.\n+\t(match_case_to_enum_1): Use tree_fits_uhwi_p and tree_fits_shwi_p.\n+\t(handle_alloc_size_attribute): Use wide-int interfaces.\n+\t(get_nonnull_operand): Likewise.\n+\t* c-format.c (get_constant): Use tree_fits_uhwi_p.\n+\t* c-lex.c: Include wide-int.h.\n+\t(narrowest_unsigned_type): Take a widest_int rather than two\n+\tHOST_WIDE_INTs.\n+\t(narrowest_signed_type): Likewise.\n+\t(interpret_integer): Update accordingly.  Use wide-int interfaces.\n+\t(lex_charconst): Use wide-int interfaces.\n+\t* c-pretty-print.c: Include wide-int.h.\n+\t(pp_c_integer_constant): Use wide-int interfaces.\n+\t* cilk.c (declare_one_free_variable): Use tree_int_cst_lt instead of\n+\tINT_CST_LT_UNSIGNED.\n+\n+\n+cp:\n+\t* call.c: Include wide-int.h.\n+\t(type_passed_as): Use tree_int_cst_lt instead of INT_CST_LT_UNSIGNED.\n+\t(convert_for_arg_passing): Likewise.\n+\t* class.c: Include wide-int.h.\n+\t(walk_subobject_offsets): Use tree_int_cst_lt instead of INT_CST_LT.\n+\t(end_of_class): Use tree_int_cst_lt instead of INT_CST_LT_UNSIGNED.\n+\t(include_empty_classes): Likewise\n+\t(layout_class_type): Use tree_int_cst_lt instead of INT_CST_LT.\n+\t* cvt.c: Include wide-int.h.\n+\t(ignore_overflows): Use wide_int_to_tree.\n+\t* decl.c: Include wide-int.h.\n+\t(check_array_designated_initializer): Use wide-int interfaces.\n+\t(compute_array_index_type): Use tree_int_cst_lt instead of INT_CST_LT.\n+\t(finish_enum_value_list): Use signop.\n+\t(build_enumerator): Use wide-int interfaces.\n+\t* init.c: Include wide-int.h.\n+\t(build_new_1): Use wide-int interfaces.\n+\t* mangle.c: Include wide-int.h.\n+\t(write_integer_cst): Use wide-int interfaces.\n+\t(write_array_type): Likewise.\n+\t* tree.c: Include wide-int.h.\n+\t(cp_tree_equal): Use tree_int_cst_equal.\n+\t* typeck2.c: Include wide-int.h.\n+\t(process_init_constructor_array): Use wide-int interfaces.\n+\n+\n+fortran:\n+\t* target-memory.c: Include wide-int.h.\n+\t(gfc_interpret_logical): Use wide-int interfaces.\n+\t* trans-array.c: Include wide-int.h.\n+\t(gfc_conv_array_initializer): Use wide-int interfaces.\n+\t* trans-const.c: Include wide-int.h.\n+\t(gfc_conv_string_init): Use wide-int interfaces.\n+\t(gfc_conv_mpz_to_tree): Likewise.\n+\t(gfc_conv_tree_to_mpz): Likewise.\n+\t* trans-decl.c (gfc_can_put_var_on_stack): Use tree_fits_uhwi_p.\n+\t* trans-expr.c: Include wide-int.h.\n+\t(gfc_conv_cst_int_power): Use wide-int interfaces.\n+\t(gfc_string_to_single_character): Likewise.\n+\t(gfc_optimize_len_trim): Likewise.\n+\t* trans-intrinsic.c: Include wide-int.h.\n+\t(trans_this_image): Use wide-int interfaces.\n+\t(gfc_conv_intrinsic_bound): Likewise.\n+\t(conv_intrinsic_cobound): Likewise.\n+\t* trans-types.c (gfc_init_types): Likewise.\n+\t(gfc_get_array_type_bounds): Pass an integer of the correct type\n+\tinstead of using integer_one_node.\n+\n+\n+go:\n+\t* go-gcc.cc (Gcc_backend::type_size): Use tree_fits_uhwi_p.\n+\n+\n+java:\n+\t* boehm.c: Include wide-int.h.\n+\t(mark_reference_fields): Use a wide_int mask.\n+\t(get_boehm_type_descriptor): Use wide-int interfaces.\n+\t* expr.c: Include wide-int.h.\n+\t(build_newarray): Remove bogus \"== INTEGER_CST\".\n+\t(expand_java_pushc): Use real_from_integer.\n+\t(build_field_ref): Use tree_int_cst_lt instead of INT_CST_LT_UNSIGNED.\n+\t* jcf-parse.c: Include wide-int.h.\n+\t(get_constant): Use wide-int interfaces.\n+\n+\n+lto:\n+\t* lto.c (compare_tree_sccs_1): Use wide-int interfaces.\n+\t* lto-lang.c (get_nonnull_operand): Likewise.\n+\n+\n+objc:\n+\t* objc-act.c: Include wide-int.h.\n+\t(objc_decl_method_attributes): Use wide-int interfaces.\n+\n+\n+testsuite:\n+\t* gcc.dg/tree-ssa/pr45427.c: Update to look for 0x0 instead of 0."}, {"sha": "fd8c2c5b3eae3e80bd9bd72b246ceb4077a730e0", "filename": "gcc/Makefile.in", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1464,6 +1464,8 @@ OBJS = \\\n \tvmsdbgout.o \\\n \tvtable-verify.o \\\n \tweb.o \\\n+\twide-int.o \\\n+\twide-int-print.o \\\n \txcoffout.o \\\n \t$(out_object_file) \\\n \t$(EXTRA_OBJS) \\\n@@ -2229,7 +2231,7 @@ s-tm-texi: build/genhooks$(build_exeext) $(srcdir)/doc/tm.texi.in\n GTFILES = $(CPP_ID_DATA_H) $(srcdir)/input.h $(srcdir)/coretypes.h \\\n   $(host_xm_file_list) \\\n   $(tm_file_list) $(HASHTAB_H) $(SPLAY_TREE_H) $(srcdir)/bitmap.h \\\n-  $(srcdir)/alias.h $(srcdir)/coverage.c $(srcdir)/rtl.h \\\n+  $(srcdir)/wide-int.h $(srcdir)/alias.h $(srcdir)/coverage.c $(srcdir)/rtl.h \\\n   $(srcdir)/optabs.h $(srcdir)/tree.h $(srcdir)/tree-core.h \\\n   $(srcdir)/libfuncs.h $(SYMTAB_H) \\\n   $(srcdir)/real.h $(srcdir)/function.h $(srcdir)/insn-addr.h $(srcdir)/hwint.h \\\n@@ -2240,6 +2242,7 @@ GTFILES = $(CPP_ID_DATA_H) $(srcdir)/input.h $(srcdir)/coretypes.h \\\n   $(srcdir)/alias.c $(srcdir)/bitmap.c $(srcdir)/cselib.c $(srcdir)/cgraph.c \\\n   $(srcdir)/ipa-prop.c $(srcdir)/ipa-cp.c $(srcdir)/ipa-utils.h \\\n   $(srcdir)/dbxout.c \\\n+  $(srcdir)/signop.h \\\n   $(srcdir)/dwarf2out.h \\\n   $(srcdir)/dwarf2asm.c \\\n   $(srcdir)/dwarf2cfi.c \\\n@@ -2442,10 +2445,9 @@ gengtype-state.o build/gengtype-state.o: gengtype-state.c $(SYSTEM_H) \\\n gengtype-state.o: $(CONFIG_H)\n CFLAGS-gengtype-state.o += -DGENERATOR_FILE\n build/gengtype-state.o: $(BCONFIG_H)\n-\n gengtype.o build/gengtype.o : gengtype.c $(SYSTEM_H) gengtype.h \t\\\n-  rtl.def insn-notes.def errors.h double-int.h version.h $(HASHTAB_H) \\\n-  $(OBSTACK_H) $(XREGEX_H)\n+  rtl.def insn-notes.def errors.h double-int.h version.h     \t\t\\\n+  $(HASHTAB_H) $(OBSTACK_H) $(XREGEX_H)\n gengtype.o: $(CONFIG_H)\n CFLAGS-gengtype.o += -DGENERATOR_FILE\n build/gengtype.o: $(BCONFIG_H)\n@@ -3752,7 +3754,7 @@ TAGS: lang.tags\n \t    incs=\"$$incs --include $$dir/TAGS.sub\";\t\\\n \t  fi;\t\t\t\t\t\t\\\n \tdone;\t\t\t\t\t\t\\\n-\tetags -o TAGS.sub c-family/*.h c-family/*.c *.h *.c; \\\n+\tetags -o TAGS.sub c-family/*.h c-family/*.c *.h *.c *.cc; \\\n \tetags --include TAGS.sub $$incs)\n \n # -----------------------------------------------------"}, {"sha": "1bf9c356223c93d3dd506d7062bd6bec2479dab9", "filename": "gcc/ada/gcc-interface/cuintp.c", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fada%2Fgcc-interface%2Fcuintp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fada%2Fgcc-interface%2Fcuintp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Fcuintp.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -160,7 +160,11 @@ UI_From_gnu (tree Input)\n      in a signed 64-bit integer.  */\n   if (tree_fits_shwi_p (Input))\n     return UI_From_Int (tree_to_shwi (Input));\n-  else if (TREE_INT_CST_HIGH (Input) < 0 && TYPE_UNSIGNED (gnu_type))\n+\n+  gcc_assert (TYPE_PRECISION (gnu_type) <= 64);\n+  if (TYPE_UNSIGNED (gnu_type)\n+      && TYPE_PRECISION (gnu_type) == 64\n+      && wi::neg_p (Input, SIGNED))\n     return No_Uint;\n #endif\n "}, {"sha": "6d0b8b250386da80394db9a2b88fcddaf238df96", "filename": "gcc/ada/gcc-interface/decl.c", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fada%2Fgcc-interface%2Fdecl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fada%2Fgcc-interface%2Fdecl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Fdecl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1642,7 +1642,7 @@ gnat_to_gnu_entity (Entity_Id gnat_entity, tree gnu_expr, int definition)\n \t  TYPE_PRECISION (gnu_type) = esize;\n \t  TYPE_UNSIGNED (gnu_type) = is_unsigned;\n \t  set_min_and_max_values_for_integral_type (gnu_type, esize,\n-\t\t\t\t\t\t    is_unsigned);\n+\t\t\t\t\t\t    TYPE_SIGN (gnu_type));\n \t  process_attributes (&gnu_type, &attr_list, true, gnat_entity);\n \t  layout_type (gnu_type);\n \n@@ -7521,11 +7521,9 @@ annotate_value (tree gnu_size)\n       if (TREE_CODE (TREE_OPERAND (gnu_size, 1)) == INTEGER_CST)\n \t{\n \t  tree op1 = TREE_OPERAND (gnu_size, 1);\n-\t  double_int signed_op1\n-\t    = tree_to_double_int (op1).sext (TYPE_PRECISION (sizetype));\n-\t  if (signed_op1.is_negative ())\n+\t  if (wi::neg_p (op1))\n \t    {\n-\t      op1 = double_int_to_tree (sizetype, -signed_op1);\n+\t      op1 = wide_int_to_tree (sizetype, wi::neg (op1));\n \t      pre_op1 = annotate_value (build1 (NEGATE_EXPR, sizetype, op1));\n \t    }\n \t}"}, {"sha": "b9b9dc1c52d8bfe624fb9f205986301bba7206fb", "filename": "gcc/ada/gcc-interface/utils.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fada%2Fgcc-interface%2Futils.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fada%2Fgcc-interface%2Futils.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Futils.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -6187,8 +6187,7 @@ static bool\n get_nonnull_operand (tree arg_num_expr, unsigned HOST_WIDE_INT *valp)\n {\n   /* Verify the arg number is a constant.  */\n-  if (TREE_CODE (arg_num_expr) != INTEGER_CST\n-      || TREE_INT_CST_HIGH (arg_num_expr) != 0)\n+  if (!tree_fits_uhwi_p (arg_num_expr))\n     return false;\n \n   *valp = TREE_INT_CST_LOW (arg_num_expr);"}, {"sha": "5f50fc245c97a5444eec7ef488b73f05bb444dec", "filename": "gcc/alias.c", "status": "modified", "additions": 16, "deletions": 10, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Falias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Falias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Falias.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -340,9 +340,10 @@ ao_ref_from_mem (ao_ref *ref, const_rtx mem)\n   if (MEM_EXPR (mem) != get_spill_slot_decl (false)\n       && (ref->offset < 0\n \t  || (DECL_P (ref->base)\n-\t      && (!tree_fits_uhwi_p (DECL_SIZE (ref->base))\n-\t\t  || (tree_to_uhwi (DECL_SIZE (ref->base))\n-\t\t      < (unsigned HOST_WIDE_INT) (ref->offset + ref->size))))))\n+\t      && (DECL_SIZE (ref->base) == NULL_TREE\n+\t\t  || TREE_CODE (DECL_SIZE (ref->base)) != INTEGER_CST\n+\t\t  || wi::ltu_p (wi::to_offset (DECL_SIZE (ref->base)),\n+\t\t\t\tref->offset + ref->size)))))\n     return false;\n \n   return true;\n@@ -1532,9 +1533,7 @@ rtx_equal_for_memref_p (const_rtx x, const_rtx y)\n \n     case VALUE:\n     CASE_CONST_UNIQUE:\n-      /* There's no need to compare the contents of CONST_DOUBLEs or\n-\t CONST_INTs because pointer equality is a good enough\n-\t comparison for these nodes.  */\n+      /* Pointer equality guarantees equality for these nodes.  */\n       return 0;\n \n     default:\n@@ -2275,15 +2274,22 @@ adjust_offset_for_component_ref (tree x, bool *known_p,\n     {\n       tree xoffset = component_ref_field_offset (x);\n       tree field = TREE_OPERAND (x, 1);\n+      if (TREE_CODE (xoffset) != INTEGER_CST)\n+\t{\n+\t  *known_p = false;\n+\t  return;\n+\t}\n \n-      if (! tree_fits_uhwi_p (xoffset))\n+      offset_int woffset\n+\t= (wi::to_offset (xoffset)\n+\t   + wi::lrshift (wi::to_offset (DECL_FIELD_BIT_OFFSET (field)),\n+\t\t\t  LOG2_BITS_PER_UNIT));\n+      if (!wi::fits_uhwi_p (woffset))\n \t{\n \t  *known_p = false;\n \t  return;\n \t}\n-      *offset += (tree_to_uhwi (xoffset)\n-\t\t  + (tree_to_uhwi (DECL_FIELD_BIT_OFFSET (field))\n-\t\t     / BITS_PER_UNIT));\n+      *offset += woffset.to_uhwi ();\n \n       x = TREE_OPERAND (x, 0);\n     }"}, {"sha": "140d6ba1a5b674baeeb531a03c6045d5ef8b765c", "filename": "gcc/builtins.c", "status": "modified", "additions": 58, "deletions": 136, "changes": 194, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -413,7 +413,7 @@ get_object_alignment_2 (tree exp, unsigned int *alignp,\n \t  bitpos += ptr_bitpos;\n \t  if (TREE_CODE (exp) == MEM_REF\n \t      || TREE_CODE (exp) == TARGET_MEM_REF)\n-\t    bitpos += mem_ref_offset (exp).low * BITS_PER_UNIT;\n+\t    bitpos += mem_ref_offset (exp).to_short_addr () * BITS_PER_UNIT;\n \t}\n     }\n   else if (TREE_CODE (exp) == STRING_CST)\n@@ -672,20 +672,24 @@ c_getstr (tree src)\n   return TREE_STRING_POINTER (src) + tree_to_uhwi (offset_node);\n }\n \n-/* Return a CONST_INT or CONST_DOUBLE corresponding to target reading\n+/* Return a constant integer corresponding to target reading\n    GET_MODE_BITSIZE (MODE) bits from string constant STR.  */\n \n static rtx\n c_readstr (const char *str, enum machine_mode mode)\n {\n-  HOST_WIDE_INT c[2];\n   HOST_WIDE_INT ch;\n   unsigned int i, j;\n+  HOST_WIDE_INT tmp[MAX_BITSIZE_MODE_ANY_INT / HOST_BITS_PER_WIDE_INT];\n \n   gcc_assert (GET_MODE_CLASS (mode) == MODE_INT);\n+  unsigned int len = (GET_MODE_PRECISION (mode) + HOST_BITS_PER_WIDE_INT - 1)\n+    / HOST_BITS_PER_WIDE_INT;\n+\n+  gcc_assert (len <= MAX_BITSIZE_MODE_ANY_INT / HOST_BITS_PER_WIDE_INT);\n+  for (i = 0; i < len; i++)\n+    tmp[i] = 0;\n \n-  c[0] = 0;\n-  c[1] = 0;\n   ch = 1;\n   for (i = 0; i < GET_MODE_SIZE (mode); i++)\n     {\n@@ -696,13 +700,14 @@ c_readstr (const char *str, enum machine_mode mode)\n \t  && GET_MODE_SIZE (mode) >= UNITS_PER_WORD)\n \tj = j + UNITS_PER_WORD - 2 * (j % UNITS_PER_WORD) - 1;\n       j *= BITS_PER_UNIT;\n-      gcc_assert (j < HOST_BITS_PER_DOUBLE_INT);\n \n       if (ch)\n \tch = (unsigned char) str[i];\n-      c[j / HOST_BITS_PER_WIDE_INT] |= ch << (j % HOST_BITS_PER_WIDE_INT);\n+      tmp[j / HOST_BITS_PER_WIDE_INT] |= ch << (j % HOST_BITS_PER_WIDE_INT);\n     }\n-  return immed_double_const (c[0], c[1], mode);\n+\n+  wide_int c = wide_int::from_array (tmp, len, GET_MODE_PRECISION (mode));\n+  return immed_wide_int_const (c, mode);\n }\n \n /* Cast a target constant CST to target CHAR and if that value fits into\n@@ -718,7 +723,9 @@ target_char_cast (tree cst, char *p)\n       || CHAR_TYPE_SIZE > HOST_BITS_PER_WIDE_INT)\n     return 1;\n \n+  /* Do not care if it fits or not right here.  */\n   val = TREE_INT_CST_LOW (cst);\n+\n   if (CHAR_TYPE_SIZE < HOST_BITS_PER_WIDE_INT)\n     val &= (((unsigned HOST_WIDE_INT) 1) << CHAR_TYPE_SIZE) - 1;\n \n@@ -3128,7 +3135,7 @@ determine_block_size (tree len, rtx len_rtx,\n     }\n   else\n     {\n-      double_int min, max;\n+      wide_int min, max;\n       enum value_range_type range_type = VR_UNDEFINED;\n \n       /* Determine bounds from the type.  */\n@@ -3146,18 +3153,18 @@ determine_block_size (tree len, rtx len_rtx,\n \trange_type = get_range_info (len, &min, &max);\n       if (range_type == VR_RANGE)\n \t{\n-\t  if (min.fits_uhwi () && *min_size < min.to_uhwi ())\n+\t  if (wi::fits_uhwi_p (min) && *min_size < min.to_uhwi ())\n \t    *min_size = min.to_uhwi ();\n-\t  if (max.fits_uhwi () && *max_size > max.to_uhwi ())\n+\t  if (wi::fits_uhwi_p (max) && *max_size > max.to_uhwi ())\n \t    *probable_max_size = *max_size = max.to_uhwi ();\n \t}\n       else if (range_type == VR_ANTI_RANGE)\n \t{\n \t  /* Anti range 0...N lets us to determine minimal size to N+1.  */\n-\t  if (min.is_zero ())\n+\t  if (min == 0)\n \t    {\n-\t      if ((max + double_int_one).fits_uhwi ())\n-\t\t*min_size = (max + double_int_one).to_uhwi ();\n+\t      if (wi::fits_uhwi_p (max) && max.to_uhwi () + 1 != 0)\n+\t\t*min_size = max.to_uhwi () + 1;\n \t    }\n \t  /* Code like\n \n@@ -3168,9 +3175,8 @@ determine_block_size (tree len, rtx len_rtx,\n \t     Produce anti range allowing negative values of N.  We still\n \t     can use the information and make a guess that N is not negative.\n \t     */\n-\t   else if (!max.ule (double_int_one.lshift (30))\n-\t            && min.fits_uhwi ())\n-\t     *probable_max_size = min.to_uhwi () - 1;\n+\t  else if (!wi::leu_p (max, 1 << 30) && wi::fits_uhwi_p (min))\n+\t    *probable_max_size = min.to_uhwi () - 1;\n \t}\n     }\n   gcc_checking_assert (*max_size <=\n@@ -4943,12 +4949,12 @@ expand_builtin_signbit (tree exp, rtx target)\n \n   if (bitpos < GET_MODE_BITSIZE (rmode))\n     {\n-      double_int mask = double_int_zero.set_bit (bitpos);\n+      wide_int mask = wi::set_bit_in_zero (bitpos, GET_MODE_PRECISION (rmode));\n \n       if (GET_MODE_SIZE (imode) > GET_MODE_SIZE (rmode))\n \ttemp = gen_lowpart (rmode, temp);\n       temp = expand_binop (rmode, and_optab, temp,\n-\t\t\t   immed_double_int_const (mask, rmode),\n+\t\t\t   immed_wide_int_const (mask, rmode),\n \t\t\t   NULL_RTX, 1, OPTAB_LIB_WIDEN);\n     }\n   else\n@@ -8012,8 +8018,8 @@ fold_builtin_int_roundingfn (location_t loc, tree fndecl, tree arg)\n \t{\n \t  tree itype = TREE_TYPE (TREE_TYPE (fndecl));\n \t  tree ftype = TREE_TYPE (arg);\n-\t  double_int val;\n \t  REAL_VALUE_TYPE r;\n+\t  bool fail = false;\n \n \t  switch (DECL_FUNCTION_CODE (fndecl))\n \t    {\n@@ -8039,9 +8045,9 @@ fold_builtin_int_roundingfn (location_t loc, tree fndecl, tree arg)\n \t      gcc_unreachable ();\n \t    }\n \n-\t  real_to_integer2 ((HOST_WIDE_INT *)&val.low, &val.high, &r);\n-\t  if (double_int_fits_to_tree_p (itype, val))\n-\t    return double_int_to_tree (itype, val);\n+\t  wide_int val = real_to_integer (&r, &fail, TYPE_PRECISION (itype));\n+\t  if (!fail)\n+\t    return wide_int_to_tree (itype, val);\n \t}\n     }\n \n@@ -8074,94 +8080,39 @@ fold_builtin_bitop (tree fndecl, tree arg)\n   /* Optimize for constant argument.  */\n   if (TREE_CODE (arg) == INTEGER_CST && !TREE_OVERFLOW (arg))\n     {\n-      HOST_WIDE_INT hi, width, result;\n-      unsigned HOST_WIDE_INT lo;\n-      tree type;\n-\n-      type = TREE_TYPE (arg);\n-      width = TYPE_PRECISION (type);\n-      lo = TREE_INT_CST_LOW (arg);\n-\n-      /* Clear all the bits that are beyond the type's precision.  */\n-      if (width > HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  hi = TREE_INT_CST_HIGH (arg);\n-\t  if (width < HOST_BITS_PER_DOUBLE_INT)\n-\t    hi &= ~(HOST_WIDE_INT_M1U << (width - HOST_BITS_PER_WIDE_INT));\n-\t}\n-      else\n-\t{\n-\t  hi = 0;\n-\t  if (width < HOST_BITS_PER_WIDE_INT)\n-\t    lo &= ~(HOST_WIDE_INT_M1U << width);\n-\t}\n+      tree type = TREE_TYPE (arg);\n+      int result;\n \n       switch (DECL_FUNCTION_CODE (fndecl))\n \t{\n \tCASE_INT_FN (BUILT_IN_FFS):\n-\t  if (lo != 0)\n-\t    result = ffs_hwi (lo);\n-\t  else if (hi != 0)\n-\t    result = HOST_BITS_PER_WIDE_INT + ffs_hwi (hi);\n-\t  else\n-\t    result = 0;\n+\t  result = wi::ffs (arg);\n \t  break;\n \n \tCASE_INT_FN (BUILT_IN_CLZ):\n-\t  if (hi != 0)\n-\t    result = width - floor_log2 (hi) - 1 - HOST_BITS_PER_WIDE_INT;\n-\t  else if (lo != 0)\n-\t    result = width - floor_log2 (lo) - 1;\n+\t  if (wi::ne_p (arg, 0))\n+\t    result = wi::clz (arg);\n \t  else if (! CLZ_DEFINED_VALUE_AT_ZERO (TYPE_MODE (type), result))\n-\t    result = width;\n+\t    result = TYPE_PRECISION (type);\n \t  break;\n \n \tCASE_INT_FN (BUILT_IN_CTZ):\n-\t  if (lo != 0)\n-\t    result = ctz_hwi (lo);\n-\t  else if (hi != 0)\n-\t    result = HOST_BITS_PER_WIDE_INT + ctz_hwi (hi);\n+\t  if (wi::ne_p (arg, 0))\n+\t    result = wi::ctz (arg);\n \t  else if (! CTZ_DEFINED_VALUE_AT_ZERO (TYPE_MODE (type), result))\n-\t    result = width;\n+\t    result = TYPE_PRECISION (type);\n \t  break;\n \n \tCASE_INT_FN (BUILT_IN_CLRSB):\n-\t  if (width > 2 * HOST_BITS_PER_WIDE_INT)\n-\t    return NULL_TREE;\n-\t  if (width > HOST_BITS_PER_WIDE_INT\n-\t      && (hi & ((unsigned HOST_WIDE_INT) 1\n-\t\t\t<< (width - HOST_BITS_PER_WIDE_INT - 1))) != 0)\n-\t    {\n-\t      hi = ~hi & ~(HOST_WIDE_INT_M1U\n-\t\t\t   << (width - HOST_BITS_PER_WIDE_INT - 1));\n-\t      lo = ~lo;\n-\t    }\n-\t  else if (width <= HOST_BITS_PER_WIDE_INT\n-\t\t   && (lo & ((unsigned HOST_WIDE_INT) 1 << (width - 1))) != 0)\n-\t    lo = ~lo & ~(HOST_WIDE_INT_M1U << (width - 1));\n-\t  if (hi != 0)\n-\t    result = width - floor_log2 (hi) - 2 - HOST_BITS_PER_WIDE_INT;\n-\t  else if (lo != 0)\n-\t    result = width - floor_log2 (lo) - 2;\n-\t  else\n-\t    result = width - 1;\n+\t  result = wi::clrsb (arg);\n \t  break;\n \n \tCASE_INT_FN (BUILT_IN_POPCOUNT):\n-\t  result = 0;\n-\t  while (lo)\n-\t    result++, lo &= lo - 1;\n-\t  while (hi)\n-\t    result++, hi &= (unsigned HOST_WIDE_INT) hi - 1;\n+\t  result = wi::popcount (arg);\n \t  break;\n \n \tCASE_INT_FN (BUILT_IN_PARITY):\n-\t  result = 0;\n-\t  while (lo)\n-\t    result++, lo &= lo - 1;\n-\t  while (hi)\n-\t    result++, hi &= (unsigned HOST_WIDE_INT) hi - 1;\n-\t  result &= 1;\n+\t  result = wi::parity (arg);\n \t  break;\n \n \tdefault:\n@@ -8185,49 +8136,24 @@ fold_builtin_bswap (tree fndecl, tree arg)\n   /* Optimize constant value.  */\n   if (TREE_CODE (arg) == INTEGER_CST && !TREE_OVERFLOW (arg))\n     {\n-      HOST_WIDE_INT hi, width, r_hi = 0;\n-      unsigned HOST_WIDE_INT lo, r_lo = 0;\n       tree type = TREE_TYPE (TREE_TYPE (fndecl));\n \n-      width = TYPE_PRECISION (type);\n-      lo = TREE_INT_CST_LOW (arg);\n-      hi = TREE_INT_CST_HIGH (arg);\n-\n       switch (DECL_FUNCTION_CODE (fndecl))\n \t{\n \t  case BUILT_IN_BSWAP16:\n \t  case BUILT_IN_BSWAP32:\n \t  case BUILT_IN_BSWAP64:\n \t    {\n-\t      int s;\n-\n-\t      for (s = 0; s < width; s += 8)\n-\t\t{\n-\t\t  int d = width - s - 8;\n-\t\t  unsigned HOST_WIDE_INT byte;\n-\n-\t\t  if (s < HOST_BITS_PER_WIDE_INT)\n-\t\t    byte = (lo >> s) & 0xff;\n-\t\t  else\n-\t\t    byte = (hi >> (s - HOST_BITS_PER_WIDE_INT)) & 0xff;\n-\n-\t\t  if (d < HOST_BITS_PER_WIDE_INT)\n-\t\t    r_lo |= byte << d;\n-\t\t  else\n-\t\t    r_hi |= byte << (d - HOST_BITS_PER_WIDE_INT);\n-\t\t}\n+\t      signop sgn = TYPE_SIGN (type);\n+\t      tree result =\n+\t\twide_int_to_tree (type,\n+\t\t\t\t  wide_int::from (arg, TYPE_PRECISION (type),\n+\t\t\t\t\t\t  sgn).bswap ());\n+\t      return result;\n \t    }\n-\n-\t    break;\n-\n \tdefault:\n \t  gcc_unreachable ();\n \t}\n-\n-      if (width < HOST_BITS_PER_WIDE_INT)\n-\treturn build_int_cst (type, r_lo);\n-      else\n-\treturn build_int_cst_wide (type, r_lo, r_hi);\n     }\n \n   return NULL_TREE;\n@@ -8289,7 +8215,7 @@ fold_builtin_logarithm (location_t loc, tree fndecl, tree arg,\n \t    /* Prepare to do logN(exp10(exponent) -> exponent*logN(10).  */\n \t    {\n \t      REAL_VALUE_TYPE dconst10;\n-\t      real_from_integer (&dconst10, VOIDmode, 10, 0, 0);\n+\t      real_from_integer (&dconst10, VOIDmode, 10, SIGNED);\n \t      x = build_real (type, dconst10);\n \t    }\n \t    exponent = CALL_EXPR_ARG (arg, 0);\n@@ -8442,7 +8368,7 @@ fold_builtin_pow (location_t loc, tree fndecl, tree arg0, tree arg1, tree type)\n \n       /* Check for an integer exponent.  */\n       n = real_to_integer (&c);\n-      real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);\n+      real_from_integer (&cint, VOIDmode, n, SIGNED);\n       if (real_identical (&c, &cint))\n \t{\n \t  /* Attempt to evaluate pow at compile-time, unless this should\n@@ -8814,20 +8740,18 @@ fold_builtin_memory_op (location_t loc, tree dest, tree src,\n \t      else if (TREE_CODE (src_base) == MEM_REF\n \t\t       && TREE_CODE (dest_base) == MEM_REF)\n \t\t{\n-\t\t  double_int off;\n \t\t  if (! operand_equal_p (TREE_OPERAND (src_base, 0),\n \t\t\t\t\t TREE_OPERAND (dest_base, 0), 0))\n \t\t    return NULL_TREE;\n-\t\t  off = mem_ref_offset (src_base) +\n-\t\t\t\t\tdouble_int::from_shwi (src_offset);\n-\t\t  if (!off.fits_shwi ())\n+\t\t  offset_int off = mem_ref_offset (src_base) + src_offset;\n+\t\t  if (!wi::fits_shwi_p (off))\n \t\t    return NULL_TREE;\n-\t\t  src_offset = off.low;\n-\t\t  off = mem_ref_offset (dest_base) +\n-\t\t\t\t\tdouble_int::from_shwi (dest_offset);\n-\t\t  if (!off.fits_shwi ())\n+\t\t  src_offset = off.to_shwi ();\n+\n+\t\t  off = mem_ref_offset (dest_base) + dest_offset;\n+\t\t  if (!wi::fits_shwi_p (off))\n \t\t    return NULL_TREE;\n-\t\t  dest_offset = off.low;\n+\t\t  dest_offset = off.to_shwi ();\n \t\t  if (ranges_overlap_p (src_offset, maxsize,\n \t\t\t\t\tdest_offset, maxsize))\n \t\t    return NULL_TREE;\n@@ -12690,8 +12614,7 @@ fold_builtin_object_size (tree ptr, tree ost)\n   if (TREE_CODE (ptr) == ADDR_EXPR)\n     {\n       bytes = compute_builtin_object_size (ptr, object_size_type);\n-      if (double_int_fits_to_tree_p (size_type_node,\n-\t\t\t\t     double_int::from_uhwi (bytes)))\n+      if (wi::fits_to_tree_p (bytes, size_type_node))\n \treturn build_int_cstu (size_type_node, bytes);\n     }\n   else if (TREE_CODE (ptr) == SSA_NAME)\n@@ -12701,8 +12624,7 @@ fold_builtin_object_size (tree ptr, tree ost)\n        it.  */\n       bytes = compute_builtin_object_size (ptr, object_size_type);\n       if (bytes != (unsigned HOST_WIDE_INT) (object_size_type < 2 ? -1 : 0)\n-          && double_int_fits_to_tree_p (size_type_node,\n-\t\t\t\t\tdouble_int::from_uhwi (bytes)))\n+          && wi::fits_to_tree_p (bytes, size_type_node))\n \treturn build_int_cstu (size_type_node, bytes);\n     }\n "}, {"sha": "a21bc498d075ea5daaacec36b42032e1ed410943", "filename": "gcc/c-family/c-ada-spec.c", "status": "modified", "additions": 10, "deletions": 24, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-ada-spec.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-ada-spec.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-ada-spec.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -29,21 +29,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"cpplib.h\"\n #include \"c-pragma.h\"\n #include \"cpp-id-data.h\"\n-\n-/* Adapted from hwint.h to use the Ada prefix.  */\n-#if HOST_BITS_PER_WIDE_INT == HOST_BITS_PER_LONG\n-# if HOST_BITS_PER_WIDE_INT == 64\n-#  define ADA_HOST_WIDE_INT_PRINT_DOUBLE_HEX \\\n-     \"16#%\" HOST_LONG_FORMAT \"x%016\" HOST_LONG_FORMAT \"x#\"\n-# else\n-#  define ADA_HOST_WIDE_INT_PRINT_DOUBLE_HEX \\\n-     \"16#%\" HOST_LONG_FORMAT \"x%08\" HOST_LONG_FORMAT \"x#\"\n-# endif\n-#else\n-  /* We can assume that 'long long' is at least 64 bits.  */\n-# define ADA_HOST_WIDE_INT_PRINT_DOUBLE_HEX \\\n-    \"16#%\" HOST_LONG_LONG_FORMAT \"x%016\" HOST_LONG_LONG_FORMAT \"x#\"\n-#endif /* HOST_BITS_PER_WIDE_INT == HOST_BITS_PER_LONG */\n+#include \"wide-int.h\"\n \n /* Local functions, macros and variables.  */\n static int dump_generic_ada_node (pretty_printer *, tree, tree, int, int,\n@@ -2211,19 +2197,19 @@ dump_generic_ada_node (pretty_printer *buffer, tree node, tree type, int spc,\n \tpp_unsigned_wide_integer (buffer, tree_to_uhwi (node));\n       else\n \t{\n-\t  tree val = node;\n-\t  unsigned HOST_WIDE_INT low = TREE_INT_CST_LOW (val);\n-\t  HOST_WIDE_INT high = TREE_INT_CST_HIGH (val);\n-\n-\t  if (tree_int_cst_sgn (val) < 0)\n+\t  wide_int val = node;\n+\t  int i;\n+\t  if (wi::neg_p (val))\n \t    {\n \t      pp_minus (buffer);\n-\t      high = ~high + !low;\n-\t      low = -low;\n+\t      val = -val;\n \t    }\n \t  sprintf (pp_buffer (buffer)->digit_buffer,\n-\t\t   ADA_HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t\t   (unsigned HOST_WIDE_INT) high, low);\n+\t\t   \"16#%\" HOST_WIDE_INT_PRINT \"x\",\n+\t\t   val.elt (val.get_len () - 1));\n+\t  for (i = val.get_len () - 2; i >= 0; i--)\n+\t    sprintf (pp_buffer (buffer)->digit_buffer,\n+\t\t     HOST_WIDE_INT_PRINT_PADDED_HEX, val.elt (i));\n \t  pp_string (buffer, pp_buffer (buffer)->digit_buffer);\n \t}\n       break;"}, {"sha": "0afe2f5ab38a71dd99a468a79762d84956e60b75", "filename": "gcc/c-family/c-common.c", "status": "modified", "additions": 28, "deletions": 42, "changes": 70, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-common.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -49,6 +49,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"cgraph.h\"\n #include \"target-def.h\"\n #include \"gimplify.h\"\n+#include \"wide-int-print.h\"\n \n cpp_reader *parse_in;\t\t/* Declared in c-pragma.h.  */\n \n@@ -4122,30 +4123,23 @@ shorten_compare (location_t loc, tree *op0_ptr, tree *op1_ptr,\n \t{\n \t  /* Convert primop1 to target type, but do not introduce\n \t     additional overflow.  We know primop1 is an int_cst.  */\n-\t  primop1 = force_fit_type_double (*restype_ptr,\n-\t\t\t\t\t   tree_to_double_int (primop1),\n-\t\t\t\t\t   0, TREE_OVERFLOW (primop1));\n+\t  primop1 = force_fit_type (*restype_ptr,\n+\t\t\t\t    wide_int::from\n+\t\t\t\t      (primop1,\n+\t\t\t\t       TYPE_PRECISION (*restype_ptr),\n+\t\t\t\t       TYPE_SIGN (TREE_TYPE (primop1))),\n+\t\t\t\t    0, TREE_OVERFLOW (primop1));\n \t}\n       if (type != *restype_ptr)\n \t{\n \t  minval = convert (*restype_ptr, minval);\n \t  maxval = convert (*restype_ptr, maxval);\n \t}\n \n-      if (unsignedp && unsignedp0)\n-\t{\n-\t  min_gt = INT_CST_LT_UNSIGNED (primop1, minval);\n-\t  max_gt = INT_CST_LT_UNSIGNED (primop1, maxval);\n-\t  min_lt = INT_CST_LT_UNSIGNED (minval, primop1);\n-\t  max_lt = INT_CST_LT_UNSIGNED (maxval, primop1);\n-\t}\n-      else\n-\t{\n-\t  min_gt = INT_CST_LT (primop1, minval);\n-\t  max_gt = INT_CST_LT (primop1, maxval);\n-\t  min_lt = INT_CST_LT (minval, primop1);\n-\t  max_lt = INT_CST_LT (maxval, primop1);\n-\t}\n+      min_gt = tree_int_cst_lt (primop1, minval);\n+      max_gt = tree_int_cst_lt (primop1, maxval);\n+      min_lt = tree_int_cst_lt (minval, primop1);\n+      max_lt = tree_int_cst_lt (maxval, primop1);\n \n       val = 0;\n       /* This used to be a switch, but Genix compiler can't handle that.  */\n@@ -4434,8 +4428,7 @@ pointer_int_sum (location_t loc, enum tree_code resultcode,\n \t\t\t      convert (TREE_TYPE (intop), size_exp), 1);\n     intop = convert (sizetype, t);\n     if (TREE_OVERFLOW_P (intop) && !TREE_OVERFLOW (t))\n-      intop = build_int_cst_wide (TREE_TYPE (intop), TREE_INT_CST_LOW (intop),\n-\t\t\t\t  TREE_INT_CST_HIGH (intop));\n+      intop = wide_int_to_tree (TREE_TYPE (intop), intop);\n   }\n \n   /* Create the sum or difference.  */\n@@ -5512,7 +5505,7 @@ c_common_nodes_and_builtins (void)\n   }\n \n   /* This node must not be shared.  */\n-  void_zero_node = make_node (INTEGER_CST);\n+  void_zero_node = make_int_cst (1, 1);\n   TREE_TYPE (void_zero_node) = void_type_node;\n \n   void_list_node = build_void_list_node ();\n@@ -5719,7 +5712,7 @@ c_common_nodes_and_builtins (void)\n \n   /* Create the built-in __null node.  It is important that this is\n      not shared.  */\n-  null_node = make_node (INTEGER_CST);\n+  null_node = make_int_cst (1, 1);\n   TREE_TYPE (null_node) = c_common_type_for_size (POINTER_SIZE, 0);\n \n   /* Since builtin_types isn't gc'ed, don't export these nodes.  */\n@@ -6097,22 +6090,14 @@ c_add_case_label (location_t loc, splay_tree cases, tree cond, tree orig_type,\n static void\n match_case_to_enum_1 (tree key, tree type, tree label)\n {\n-  char buf[2 + 2*HOST_BITS_PER_WIDE_INT/4 + 1];\n-\n-  /* ??? Not working too hard to print the double-word value.\n-     Should perhaps be done with %lwd in the diagnostic routines?  */\n-  if (TREE_INT_CST_HIGH (key) == 0)\n-    snprintf (buf, sizeof (buf), HOST_WIDE_INT_PRINT_UNSIGNED,\n-\t      TREE_INT_CST_LOW (key));\n-  else if (!TYPE_UNSIGNED (type)\n-\t   && TREE_INT_CST_HIGH (key) == -1\n-\t   && TREE_INT_CST_LOW (key) != 0)\n-    snprintf (buf, sizeof (buf), \"-\" HOST_WIDE_INT_PRINT_UNSIGNED,\n-\t      -TREE_INT_CST_LOW (key));\n+  char buf[WIDE_INT_PRINT_BUFFER_SIZE];\n+\n+  if (tree_fits_uhwi_p (key))\n+    print_dec (key, buf, UNSIGNED);\n+  else if (tree_fits_shwi_p (key))\n+    print_dec (key, buf, SIGNED);\n   else\n-    snprintf (buf, sizeof (buf), HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t      (unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (key),\n-\t      (unsigned HOST_WIDE_INT) TREE_INT_CST_LOW (key));\n+    print_hex (key, buf);\n \n   if (TYPE_NAME (type) == 0)\n     warning_at (DECL_SOURCE_LOCATION (CASE_LABEL (label)),\n@@ -8849,13 +8834,14 @@ check_nonnull_arg (void * ARG_UNUSED (ctx), tree param,\n static bool\n get_nonnull_operand (tree arg_num_expr, unsigned HOST_WIDE_INT *valp)\n {\n-  /* Verify the arg number is a constant.  */\n-  if (TREE_CODE (arg_num_expr) != INTEGER_CST\n-      || TREE_INT_CST_HIGH (arg_num_expr) != 0)\n+  /* Verify the arg number is a small constant.  */\n+  if (tree_fits_uhwi_p (arg_num_expr))\n+    {\n+      *valp = TREE_INT_CST_LOW (arg_num_expr);\n+      return true;\n+    }\n+  else\n     return false;\n-\n-  *valp = TREE_INT_CST_LOW (arg_num_expr);\n-  return true;\n }\n \n /* Handle a \"nothrow\" attribute; arguments as in"}, {"sha": "eeefce883d43dcdd90fc393db9de146535003c36", "filename": "gcc/c-family/c-format.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-format.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-format.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-format.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -227,7 +227,7 @@ check_format_string (tree fntype, unsigned HOST_WIDE_INT format_num,\n static bool\n get_constant (tree expr, unsigned HOST_WIDE_INT *value, int validated_p)\n {\n-  if (TREE_CODE (expr) != INTEGER_CST || TREE_INT_CST_HIGH (expr) != 0)\n+  if (!tree_fits_uhwi_p (expr))\n     {\n       gcc_assert (!validated_p);\n       return false;"}, {"sha": "ea24bfc2a2e42915543faaa244052c30a42bf4c0", "filename": "gcc/c-family/c-lex.c", "status": "modified", "additions": 19, "deletions": 20, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-lex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-lex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-lex.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -35,6 +35,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"splay-tree.h\"\n #include \"debug.h\"\n #include \"target.h\"\n+#include \"wide-int.h\"\n \n /* We may keep statistics about how long which files took to compile.  */\n static int header_time, body_time;\n@@ -49,9 +50,9 @@ static tree interpret_float (const cpp_token *, unsigned int, const char *,\n \t\t\t     enum overflow_type *);\n static tree interpret_fixed (const cpp_token *, unsigned int);\n static enum integer_type_kind narrowest_unsigned_type\n-\t(unsigned HOST_WIDE_INT, unsigned HOST_WIDE_INT, unsigned int);\n+\t(const widest_int &, unsigned int);\n static enum integer_type_kind narrowest_signed_type\n-\t(unsigned HOST_WIDE_INT, unsigned HOST_WIDE_INT, unsigned int);\n+\t(const widest_int &, unsigned int);\n static enum cpp_ttype lex_string (const cpp_token *, tree *, bool, bool);\n static tree lex_charconst (const cpp_token *);\n static void update_header_times (const char *);\n@@ -527,9 +528,7 @@ c_lex_with_flags (tree *value, location_t *loc, unsigned char *cpp_flags,\n    there isn't one.  */\n \n static enum integer_type_kind\n-narrowest_unsigned_type (unsigned HOST_WIDE_INT low,\n-\t\t\t unsigned HOST_WIDE_INT high,\n-\t\t\t unsigned int flags)\n+narrowest_unsigned_type (const widest_int &val, unsigned int flags)\n {\n   int itk;\n \n@@ -548,9 +547,7 @@ narrowest_unsigned_type (unsigned HOST_WIDE_INT low,\n \tcontinue;\n       upper = TYPE_MAX_VALUE (integer_types[itk]);\n \n-      if ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (upper) > high\n-\t  || ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (upper) == high\n-\t      && TREE_INT_CST_LOW (upper) >= low))\n+      if (wi::geu_p (wi::to_widest (upper), val))\n \treturn (enum integer_type_kind) itk;\n     }\n \n@@ -559,8 +556,7 @@ narrowest_unsigned_type (unsigned HOST_WIDE_INT low,\n \n /* Ditto, but narrowest signed type.  */\n static enum integer_type_kind\n-narrowest_signed_type (unsigned HOST_WIDE_INT low,\n-\t\t       unsigned HOST_WIDE_INT high, unsigned int flags)\n+narrowest_signed_type (const widest_int &val, unsigned int flags)\n {\n   int itk;\n \n@@ -571,7 +567,6 @@ narrowest_signed_type (unsigned HOST_WIDE_INT low,\n   else\n     itk = itk_long_long;\n \n-\n   for (; itk < itk_none; itk += 2 /* skip signed types */)\n     {\n       tree upper;\n@@ -580,9 +575,7 @@ narrowest_signed_type (unsigned HOST_WIDE_INT low,\n \tcontinue;\n       upper = TYPE_MAX_VALUE (integer_types[itk]);\n \n-      if ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (upper) > high\n-\t  || ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (upper) == high\n-\t      && TREE_INT_CST_LOW (upper) >= low))\n+      if (wi::geu_p (wi::to_widest (upper), val))\n \treturn (enum integer_type_kind) itk;\n     }\n \n@@ -597,25 +590,31 @@ interpret_integer (const cpp_token *token, unsigned int flags,\n   tree value, type;\n   enum integer_type_kind itk;\n   cpp_num integer;\n+  HOST_WIDE_INT ival[3];\n \n   *overflow = OT_NONE;\n \n   integer = cpp_interpret_integer (parse_in, token, flags);\n   if (integer.overflow)\n     *overflow = OT_OVERFLOW;\n \n+  ival[0] = integer.low;\n+  ival[1] = integer.high;\n+  ival[2] = 0;\n+  widest_int wval = widest_int::from_array (ival, 3);\n+\n   /* The type of a constant with a U suffix is straightforward.  */\n   if (flags & CPP_N_UNSIGNED)\n-    itk = narrowest_unsigned_type (integer.low, integer.high, flags);\n+    itk = narrowest_unsigned_type (wval, flags);\n   else\n     {\n       /* The type of a potentially-signed integer constant varies\n \t depending on the base it's in, the standard in use, and the\n \t length suffixes.  */\n       enum integer_type_kind itk_u\n-\t= narrowest_unsigned_type (integer.low, integer.high, flags);\n+\t= narrowest_unsigned_type (wval, flags);\n       enum integer_type_kind itk_s\n-\t= narrowest_signed_type (integer.low, integer.high, flags);\n+\t= narrowest_signed_type (wval, flags);\n \n       /* In both C89 and C99, octal and hex constants may be signed or\n \t unsigned, whichever fits tighter.  We do not warn about this\n@@ -667,7 +666,7 @@ interpret_integer (const cpp_token *token, unsigned int flags,\n \t   : \"integer constant is too large for %<long%> type\");\n     }\n \n-  value = build_int_cst_wide (type, integer.low, integer.high);\n+  value = wide_int_to_tree (type, wval);\n \n   /* Convert imaginary to a complex type.  */\n   if (flags & CPP_N_IMAGINARY)\n@@ -1165,9 +1164,9 @@ lex_charconst (const cpp_token *token)\n   /* Cast to cppchar_signed_t to get correct sign-extension of RESULT\n      before possibly widening to HOST_WIDE_INT for build_int_cst.  */\n   if (unsignedp || (cppchar_signed_t) result >= 0)\n-    value = build_int_cst_wide (type, result, 0);\n+    value = build_int_cst (type, result);\n   else\n-    value = build_int_cst_wide (type, (cppchar_signed_t) result, -1);\n+    value = build_int_cst (type, (cppchar_signed_t) result);\n \n   return value;\n }"}, {"sha": "2e97d0147c5224db7e98b0bb615e43bfdbc071dc", "filename": "gcc/c-family/c-pretty-print.c", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fc-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-pretty-print.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -30,6 +30,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-pretty-print.h\"\n #include \"tree-iterator.h\"\n #include \"diagnostic.h\"\n+#include \"wide-int-print.h\"\n \n /* The pretty-printer code is primarily designed to closely follow\n    (GNU) C and C++ grammars.  That is to be contrasted with spaghetti\n@@ -923,16 +924,14 @@ pp_c_integer_constant (c_pretty_printer *pp, tree i)\n     pp_unsigned_wide_integer (pp, tree_to_uhwi (i));\n   else\n     {\n-      unsigned HOST_WIDE_INT low = TREE_INT_CST_LOW (i);\n-      HOST_WIDE_INT high = TREE_INT_CST_HIGH (i);\n-      if (tree_int_cst_sgn (i) < 0)\n+      wide_int wi = i;\n+\n+      if (wi::lt_p (i, 0, TYPE_SIGN (TREE_TYPE (i))))\n \t{\n \t  pp_minus (pp);\n-\t  high = ~high + !low;\n-\t  low = -low;\n+\t  wi = -wi;\n \t}\n-      sprintf (pp_buffer (pp)->digit_buffer, HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t       (unsigned HOST_WIDE_INT) high, (unsigned HOST_WIDE_INT) low);\n+      print_hex (wi, pp_buffer (pp)->digit_buffer);\n       pp_string (pp, pp_buffer (pp)->digit_buffer);\n     }\n   if (TYPE_UNSIGNED (type))"}, {"sha": "a952902533a11c618dcb6af25959f104e7c7069e", "filename": "gcc/c-family/cilk.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fcilk.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc-family%2Fcilk.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fcilk.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -666,8 +666,7 @@ declare_one_free_variable (const void *var0, void **map0,\n \n   /* Maybe promote to int.  */\n   if (INTEGRAL_TYPE_P (var_type) && COMPLETE_TYPE_P (var_type)\n-      && INT_CST_LT_UNSIGNED (TYPE_SIZE (var_type),\n-\t\t\t      TYPE_SIZE (integer_type_node)))\n+      && tree_int_cst_lt (TYPE_SIZE (var_type), TYPE_SIZE (integer_type_node)))\n     arg_type = integer_type_node;\n   else\n     arg_type = var_type;"}, {"sha": "3abf6b985741657270dc8514844a8062e1fddc64", "filename": "gcc/c/c-decl.c", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc%2Fc-decl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc%2Fc-decl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2Fc-decl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -4880,8 +4880,8 @@ check_bitfield_type_and_width (tree *type, tree *width, tree orig_name)\n     {\n       struct lang_type *lt = TYPE_LANG_SPECIFIC (*type);\n       if (!lt\n-\t  || w < tree_int_cst_min_precision (lt->enum_min, TYPE_UNSIGNED (*type))\n-\t  || w < tree_int_cst_min_precision (lt->enum_max, TYPE_UNSIGNED (*type)))\n+\t  || w < tree_int_cst_min_precision (lt->enum_min, TYPE_SIGN (*type))\n+\t  || w < tree_int_cst_min_precision (lt->enum_max, TYPE_SIGN (*type)))\n \twarning (0, \"%qs is narrower than values of its type\", name);\n     }\n }\n@@ -7605,7 +7605,8 @@ finish_enum (tree enumtype, tree values, tree attributes)\n {\n   tree pair, tem;\n   tree minnode = 0, maxnode = 0;\n-  int precision, unsign;\n+  int precision;\n+  signop sign;\n   bool toplevel = (file_scope == current_scope);\n   struct lang_type *lt;\n \n@@ -7632,21 +7633,21 @@ finish_enum (tree enumtype, tree values, tree attributes)\n      as one of the integral types - the narrowest one that fits, except\n      that normally we only go as narrow as int - and signed iff any of\n      the values are negative.  */\n-  unsign = (tree_int_cst_sgn (minnode) >= 0);\n-  precision = MAX (tree_int_cst_min_precision (minnode, unsign),\n-\t\t   tree_int_cst_min_precision (maxnode, unsign));\n+  sign = (tree_int_cst_sgn (minnode) >= 0) ? UNSIGNED : SIGNED;\n+  precision = MAX (tree_int_cst_min_precision (minnode, sign),\n+\t\t   tree_int_cst_min_precision (maxnode, sign));\n \n   if (TYPE_PACKED (enumtype) || precision > TYPE_PRECISION (integer_type_node))\n     {\n-      tem = c_common_type_for_size (precision, unsign);\n+      tem = c_common_type_for_size (precision, sign == UNSIGNED ? 1 : 0);\n       if (tem == NULL)\n \t{\n \t  warning (0, \"enumeration values exceed range of largest integer\");\n \t  tem = long_long_integer_type_node;\n \t}\n     }\n   else\n-    tem = unsign ? unsigned_type_node : integer_type_node;\n+    tem = sign == UNSIGNED ? unsigned_type_node : integer_type_node;\n \n   TYPE_MIN_VALUE (enumtype) = TYPE_MIN_VALUE (tem);\n   TYPE_MAX_VALUE (enumtype) = TYPE_MAX_VALUE (tem);"}, {"sha": "6e8f33bdac1461ece539a68845f67e784e04ccc4", "filename": "gcc/c/c-parser.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc%2Fc-parser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc%2Fc-parser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2Fc-parser.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -13616,7 +13616,7 @@ c_parser_cilk_clause_vectorlength (c_parser *parser, tree clauses,\n \t   || !INTEGRAL_TYPE_P (TREE_TYPE (expr)))\n   \n     error_at (loc, \"vectorlength must be an integer constant\");  \n-  else if (exact_log2 (TREE_INT_CST_LOW (expr)) == -1)\n+  else if (wi::exact_log2 (expr) == -1)\n     error_at (loc, \"vectorlength must be a power of 2\");\n   else\n     {"}, {"sha": "7d2df6b1d1293bbf87fa921c07c43f6a5da267d9", "filename": "gcc/c/c-typeck.c", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc%2Fc-typeck.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fc%2Fc-typeck.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc%2Fc-typeck.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -50,6 +50,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"c-family/c-common.h\"\n #include \"c-family/c-ubsan.h\"\n #include \"cilk.h\"\n+#include \"wide-int.h\"\n \n /* Possible cases of implicit bad conversions.  Used to select\n    diagnostic messages in convert_for_assignment.  */\n@@ -5126,9 +5127,7 @@ build_c_cast (location_t loc, tree type, tree expr)\n \t    }\n \t  else if (TREE_OVERFLOW (value))\n \t    /* Reset VALUE's overflow flags, ensuring constant sharing.  */\n-\t    value = build_int_cst_wide (TREE_TYPE (value),\n-\t\t\t\t\tTREE_INT_CST_LOW (value),\n-\t\t\t\t\tTREE_INT_CST_HIGH (value));\n+\t    value = wide_int_to_tree (TREE_TYPE (value), value);\n \t}\n     }\n \n@@ -8078,20 +8077,20 @@ set_nonincremental_init_from_string (tree str,\n     {\n       if (wchar_bytes == 1)\n \t{\n-\t  val[1] = (unsigned char) *p++;\n-\t  val[0] = 0;\n+\t  val[0] = (unsigned char) *p++;\n+\t  val[1] = 0;\n \t}\n       else\n \t{\n-\t  val[0] = 0;\n \t  val[1] = 0;\n+\t  val[0] = 0;\n \t  for (byte = 0; byte < wchar_bytes; byte++)\n \t    {\n \t      if (BYTES_BIG_ENDIAN)\n \t\tbitpos = (wchar_bytes - byte - 1) * charwidth;\n \t      else\n \t\tbitpos = byte * charwidth;\n-\t      val[bitpos < HOST_BITS_PER_WIDE_INT]\n+\t      val[bitpos % HOST_BITS_PER_WIDE_INT]\n \t\t|= ((unsigned HOST_WIDE_INT) ((unsigned char) *p++))\n \t\t   << (bitpos % HOST_BITS_PER_WIDE_INT);\n \t    }\n@@ -8102,24 +8101,26 @@ set_nonincremental_init_from_string (tree str,\n \t  bitpos = ((wchar_bytes - 1) * charwidth) + HOST_BITS_PER_CHAR;\n \t  if (bitpos < HOST_BITS_PER_WIDE_INT)\n \t    {\n-\t      if (val[1] & (((HOST_WIDE_INT) 1) << (bitpos - 1)))\n+\t      if (val[0] & (((HOST_WIDE_INT) 1) << (bitpos - 1)))\n \t\t{\n-\t\t  val[1] |= ((HOST_WIDE_INT) -1) << bitpos;\n-\t\t  val[0] = -1;\n+\t\t  val[0] |= ((HOST_WIDE_INT) -1) << bitpos;\n+\t\t  val[1] = -1;\n \t\t}\n \t    }\n \t  else if (bitpos == HOST_BITS_PER_WIDE_INT)\n \t    {\n-\t      if (val[1] < 0)\n-\t\tval[0] = -1;\n+\t      if (val[0] < 0)\n+\t\tval[1] = -1;\n \t    }\n-\t  else if (val[0] & (((HOST_WIDE_INT) 1)\n+\t  else if (val[1] & (((HOST_WIDE_INT) 1)\n \t\t\t     << (bitpos - 1 - HOST_BITS_PER_WIDE_INT)))\n-\t    val[0] |= ((HOST_WIDE_INT) -1)\n+\t    val[1] |= ((HOST_WIDE_INT) -1)\n \t\t      << (bitpos - HOST_BITS_PER_WIDE_INT);\n \t}\n \n-      value = build_int_cst_wide (type, val[1], val[0]);\n+      value = wide_int_to_tree (type,\n+\t\t\t\twide_int::from_array (val, 2,\n+\t\t\t\t\t\t      HOST_BITS_PER_WIDE_INT * 2));\n       add_pending_init (input_location, purpose, value, NULL_TREE, true,\n                         braced_init_obstack);\n     }\n@@ -12365,8 +12366,7 @@ c_tree_equal (tree t1, tree t2)\n   switch (code1)\n     {\n     case INTEGER_CST:\n-      return TREE_INT_CST_LOW (t1) == TREE_INT_CST_LOW (t2)\n-\t&& TREE_INT_CST_HIGH (t1) == TREE_INT_CST_HIGH (t2);\n+      return wi::eq_p (t1, t2);\n \n     case REAL_CST:\n       return REAL_VALUES_EQUAL (TREE_REAL_CST (t1), TREE_REAL_CST (t2));"}, {"sha": "91e8800560b09944fdcc689952664e6b42f7ba0d", "filename": "gcc/cfgloop.c", "status": "modified", "additions": 15, "deletions": 13, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcfgloop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcfgloop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgloop.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -336,7 +336,8 @@ alloc_loop (void)\n   loop->exits = ggc_alloc_cleared_loop_exit ();\n   loop->exits->next = loop->exits->prev = loop->exits;\n   loop->can_be_parallel = false;\n-\n+  loop->nb_iterations_upper_bound = 0;\n+  loop->nb_iterations_estimate = 0;\n   return loop;\n }\n \n@@ -1787,21 +1788,21 @@ get_loop_location (struct loop *loop)\n    I_BOUND times.  */\n \n void\n-record_niter_bound (struct loop *loop, double_int i_bound, bool realistic,\n-\t\t    bool upper)\n+record_niter_bound (struct loop *loop, const widest_int &i_bound,\n+\t\t    bool realistic, bool upper)\n {\n   /* Update the bounds only when there is no previous estimation, or when the\n      current estimation is smaller.  */\n   if (upper\n       && (!loop->any_upper_bound\n-\t  || i_bound.ult (loop->nb_iterations_upper_bound)))\n+\t  || wi::ltu_p (i_bound, loop->nb_iterations_upper_bound)))\n     {\n       loop->any_upper_bound = true;\n       loop->nb_iterations_upper_bound = i_bound;\n     }\n   if (realistic\n       && (!loop->any_estimate\n-\t  || i_bound.ult (loop->nb_iterations_estimate)))\n+\t  || wi::ltu_p (i_bound, loop->nb_iterations_estimate)))\n     {\n       loop->any_estimate = true;\n       loop->nb_iterations_estimate = i_bound;\n@@ -1811,7 +1812,8 @@ record_niter_bound (struct loop *loop, double_int i_bound, bool realistic,\n      number of iterations, use the upper bound instead.  */\n   if (loop->any_upper_bound\n       && loop->any_estimate\n-      && loop->nb_iterations_upper_bound.ult (loop->nb_iterations_estimate))\n+      && wi::ltu_p (loop->nb_iterations_upper_bound,\n+\t\t    loop->nb_iterations_estimate))\n     loop->nb_iterations_estimate = loop->nb_iterations_upper_bound;\n }\n \n@@ -1822,13 +1824,13 @@ record_niter_bound (struct loop *loop, double_int i_bound, bool realistic,\n HOST_WIDE_INT\n get_estimated_loop_iterations_int (struct loop *loop)\n {\n-  double_int nit;\n+  widest_int nit;\n   HOST_WIDE_INT hwi_nit;\n \n   if (!get_estimated_loop_iterations (loop, &nit))\n     return -1;\n \n-  if (!nit.fits_shwi ())\n+  if (!wi::fits_shwi_p (nit))\n     return -1;\n   hwi_nit = nit.to_shwi ();\n \n@@ -1859,15 +1861,15 @@ max_stmt_executions_int (struct loop *loop)\n    returns true.  */\n \n bool\n-get_estimated_loop_iterations (struct loop *loop, double_int *nit)\n+get_estimated_loop_iterations (struct loop *loop, widest_int *nit)\n {\n   /* Even if the bound is not recorded, possibly we can derrive one from\n      profile.  */\n   if (!loop->any_estimate)\n     {\n       if (loop->header->count)\n \t{\n-          *nit = gcov_type_to_double_int\n+          *nit = gcov_type_to_wide_int\n \t\t   (expected_loop_iterations_unbounded (loop) + 1);\n \t  return true;\n \t}\n@@ -1883,7 +1885,7 @@ get_estimated_loop_iterations (struct loop *loop, double_int *nit)\n    false, otherwise returns true.  */\n \n bool\n-get_max_loop_iterations (struct loop *loop, double_int *nit)\n+get_max_loop_iterations (struct loop *loop, widest_int *nit)\n {\n   if (!loop->any_upper_bound)\n     return false;\n@@ -1899,13 +1901,13 @@ get_max_loop_iterations (struct loop *loop, double_int *nit)\n HOST_WIDE_INT\n get_max_loop_iterations_int (struct loop *loop)\n {\n-  double_int nit;\n+  widest_int nit;\n   HOST_WIDE_INT hwi_nit;\n \n   if (!get_max_loop_iterations (loop, &nit))\n     return -1;\n \n-  if (!nit.fits_shwi ())\n+  if (!wi::fits_shwi_p (nit))\n     return -1;\n   hwi_nit = nit.to_shwi ();\n "}, {"sha": "ab8b8090e98bb50bb5a1c44e1199a0316cebd1a5", "filename": "gcc/cfgloop.h", "status": "modified", "additions": 14, "deletions": 13, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcfgloop.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcfgloop.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgloop.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -21,6 +21,7 @@ along with GCC; see the file COPYING3.  If not see\n #define GCC_CFGLOOP_H\n \n #include \"double-int.h\"\n+#include \"wide-int.h\"\n #include \"bitmap.h\"\n #include \"sbitmap.h\"\n #include \"function.h\"\n@@ -62,7 +63,7 @@ struct GTY ((chain_next (\"%h.next\"))) nb_iter_bound {\n         overflows (as MAX + 1 is sometimes produced as the estimate on number\n \tof executions of STMT).\n      b) it is consistent with the result of number_of_iterations_exit.  */\n-  double_int bound;\n+  widest_int bound;\n \n   /* True if the statement will cause the loop to be leaved the (at most)\n      BOUND + 1-st time it is executed, that is, all the statements after it\n@@ -146,12 +147,12 @@ struct GTY ((chain_next (\"%h.next\"))) loop {\n \n   /* An integer guaranteed to be greater or equal to nb_iterations.  Only\n      valid if any_upper_bound is true.  */\n-  double_int nb_iterations_upper_bound;\n+  widest_int nb_iterations_upper_bound;\n \n   /* An integer giving an estimate on nb_iterations.  Unlike\n      nb_iterations_upper_bound, there is no guarantee that it is at least\n      nb_iterations.  */\n-  double_int nb_iterations_estimate;\n+  widest_int nb_iterations_estimate;\n \n   bool any_upper_bound;\n   bool any_estimate;\n@@ -737,27 +738,27 @@ loop_outermost (struct loop *loop)\n   return (*loop->superloops)[1];\n }\n \n-extern void record_niter_bound (struct loop *, double_int, bool, bool);\n+extern void record_niter_bound (struct loop *, const widest_int &, bool, bool);\n extern HOST_WIDE_INT get_estimated_loop_iterations_int (struct loop *);\n extern HOST_WIDE_INT get_max_loop_iterations_int (struct loop *);\n-extern bool get_estimated_loop_iterations (struct loop *loop, double_int *nit);\n-extern bool get_max_loop_iterations (struct loop *loop, double_int *nit);\n+extern bool get_estimated_loop_iterations (struct loop *loop, widest_int *nit);\n+extern bool get_max_loop_iterations (struct loop *loop, widest_int *nit);\n extern int bb_loop_depth (const_basic_block);\n \n-/* Converts VAL to double_int.  */\n+/* Converts VAL to widest_int.  */\n \n-static inline double_int\n-gcov_type_to_double_int (gcov_type val)\n+static inline widest_int\n+gcov_type_to_wide_int (gcov_type val)\n {\n-  double_int ret;\n+  HOST_WIDE_INT a[2];\n \n-  ret.low = (unsigned HOST_WIDE_INT) val;\n+  a[0] = (unsigned HOST_WIDE_INT) val;\n   /* If HOST_BITS_PER_WIDE_INT == HOST_BITS_PER_WIDEST_INT, avoid shifting by\n      the size of type.  */\n   val >>= HOST_BITS_PER_WIDE_INT - 1;\n   val >>= 1;\n-  ret.high = (unsigned HOST_WIDE_INT) val;\n+  a[1] = (unsigned HOST_WIDE_INT) val;\n \n-  return ret;\n+  return widest_int::from_array (a, 2);\n }\n #endif /* GCC_CFGLOOP_H */"}, {"sha": "2b4ce813c9028e699f4eb2eda205819891bd627e", "filename": "gcc/cgraph.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcgraph.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcgraph.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraph.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -650,8 +650,7 @@ cgraph_add_thunk (struct cgraph_node *decl_node ATTRIBUTE_UNUSED,\n   \n   node = cgraph_create_node (alias);\n   gcc_checking_assert (!virtual_offset\n-\t\t       || tree_to_double_int (virtual_offset) ==\n-\t\t\t     double_int::from_shwi (virtual_value));\n+\t\t       || wi::eq_p (virtual_offset, virtual_value));\n   node->thunk.fixed_offset = fixed_offset;\n   node->thunk.this_adjusting = this_adjusting;\n   node->thunk.virtual_value = virtual_value;"}, {"sha": "a2f42c58ccd1fefb5312899bcbcbd24a5a3ccecb", "filename": "gcc/combine.c", "status": "modified", "additions": 7, "deletions": 14, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2671,22 +2671,15 @@ try_combine (rtx i3, rtx i2, rtx i1, rtx i0, int *new_direct_jump_p,\n \t    offset = -1;\n \t}\n \n-      if (offset >= 0\n-\t  && (GET_MODE_PRECISION (GET_MODE (SET_DEST (temp)))\n-\t      <= HOST_BITS_PER_DOUBLE_INT))\n+      if (offset >= 0)\n \t{\n-\t  double_int m, o, i;\n \t  rtx inner = SET_SRC (PATTERN (i3));\n \t  rtx outer = SET_SRC (temp);\n \n-\t  o = rtx_to_double_int (outer);\n-\t  i = rtx_to_double_int (inner);\n-\n-\t  m = double_int::mask (width);\n-\t  i &= m;\n-\t  m = m.llshift (offset, HOST_BITS_PER_DOUBLE_INT);\n-\t  i = i.llshift (offset, HOST_BITS_PER_DOUBLE_INT);\n-\t  o = o.and_not (m) | i;\n+\t  wide_int o\n+\t    = wi::insert (std::make_pair (outer, GET_MODE (SET_DEST (temp))),\n+\t\t\t  std::make_pair (inner, GET_MODE (dest)),\n+\t\t\t  offset, width);\n \n \t  combine_merges++;\n \t  subst_insn = i3;\n@@ -2699,7 +2692,7 @@ try_combine (rtx i3, rtx i2, rtx i1, rtx i0, int *new_direct_jump_p,\n \t     resulting insn the new pattern for I3.  Then skip to where we\n \t     validate the pattern.  Everything was set up above.  */\n \t  SUBST (SET_SRC (temp),\n-\t\t immed_double_int_const (o, GET_MODE (SET_DEST (temp))));\n+\t\t immed_wide_int_const (o, GET_MODE (SET_DEST (temp))));\n \n \t  newpat = PATTERN (i2);\n \n@@ -5139,7 +5132,7 @@ subst (rtx x, rtx from, rtx to, int in_dest, int in_cond, int unique_copy)\n \t\t  if (! x)\n \t\t    x = gen_rtx_CLOBBER (mode, const0_rtx);\n \t\t}\n-\t      else if (CONST_INT_P (new_rtx)\n+\t      else if (CONST_SCALAR_INT_P (new_rtx)\n \t\t       && GET_CODE (x) == ZERO_EXTEND)\n \t\t{\n \t\t  x = simplify_unary_operation (ZERO_EXTEND, GET_MODE (x),"}, {"sha": "6a6fb032647d1d6cdb0e6b12c516a8ddcb2c5fb3", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -6132,8 +6132,10 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \tint count;\n \ttree index = TYPE_DOMAIN (type);\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tcount = aapcs_vfp_sub_candidate (TREE_TYPE (type), modep);\n@@ -6150,9 +6152,7 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \t\t      - tree_to_uhwi (TYPE_MIN_VALUE (index)));\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -6164,8 +6164,10 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \tint sub_count;\n \ttree field;\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tfor (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n@@ -6180,9 +6182,7 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \t  }\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -6196,8 +6196,10 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \tint sub_count;\n \ttree field;\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tfor (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n@@ -6212,9 +6214,7 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \t  }\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -7557,8 +7557,8 @@ aarch64_float_const_representable_p (rtx x)\n   int point_pos = 2 * HOST_BITS_PER_WIDE_INT - 1;\n   int exponent;\n   unsigned HOST_WIDE_INT mantissa, mask;\n-  HOST_WIDE_INT m1, m2;\n   REAL_VALUE_TYPE r, m;\n+  bool fail;\n \n   if (!CONST_DOUBLE_P (x))\n     return false;\n@@ -7582,16 +7582,16 @@ aarch64_float_const_representable_p (rtx x)\n      WARNING: If we ever have a representation using more than 2 * H_W_I - 1\n      bits for the mantissa, this can fail (low bits will be lost).  */\n   real_ldexp (&m, &r, point_pos - exponent);\n-  REAL_VALUE_TO_INT (&m1, &m2, m);\n+  wide_int w = real_to_integer (&m, &fail, HOST_BITS_PER_WIDE_INT * 2);\n \n   /* If the low part of the mantissa has bits set we cannot represent\n      the value.  */\n-  if (m1 != 0)\n+  if (w.elt (0) != 0)\n     return false;\n   /* We have rejected the lower HOST_WIDE_INT, so update our\n      understanding of how many bits lie in the mantissa and\n      look only at the high HOST_WIDE_INT.  */\n-  mantissa = m2;\n+  mantissa = w.elt (1);\n   point_pos -= HOST_BITS_PER_WIDE_INT;\n \n   /* We can only represent values with a mantissa of the form 1.xxxx.  */"}, {"sha": "113395bd5de08e55eb8d9f660db9abfd330f4fad", "filename": "gcc/config/arc/arc.c", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Farc%2Farc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Farc%2Farc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -65,6 +65,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-pass.h\"\n #include \"context.h\"\n #include \"pass_manager.h\"\n+#include \"wide-int.h\"\n \n /* Which cpu we're compiling for (A5, ARC600, ARC601, ARC700).  */\n static const char *arc_cpu_string = \"\";\n@@ -391,7 +392,8 @@ static bool arc_return_in_memory (const_tree, const_tree);\n static void arc_init_simd_builtins (void);\n static bool arc_vector_mode_supported_p (enum machine_mode);\n \n-static bool arc_can_use_doloop_p (double_int, double_int, unsigned int, bool);\n+static bool arc_can_use_doloop_p (const widest_int &, const widest_int &,\n+\t\t\t\t  unsigned int, bool);\n static const char *arc_invalid_within_doloop (const_rtx);\n \n static void output_short_suffix (FILE *file);\n@@ -5700,17 +5702,16 @@ arc_pass_by_reference (cumulative_args_t ca_v ATTRIBUTE_UNUSED,\n /* Implement TARGET_CAN_USE_DOLOOP_P.  */\n \n static bool\n-arc_can_use_doloop_p (double_int iterations, double_int,\n+arc_can_use_doloop_p (const widest_int &iterations, const widest_int &,\n \t\t      unsigned int loop_depth, bool entered_at_top)\n {\n   if (loop_depth > 1)\n     return false;\n   /* Setting up the loop with two sr instructions costs 6 cycles.  */\n   if (TARGET_ARC700\n       && !entered_at_top\n-      && iterations.high == 0\n-      && iterations.low > 0\n-      && iterations.low <= (flag_pic ? 6 : 3))\n+      && wi::gtu_p (iterations, 0)\n+      && wi::leu_p (iterations, flag_pic ? 6 : 3))\n     return false;\n   return true;\n }"}, {"sha": "1e44080d601788cc61e01d96b345b942f5075621", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -5121,8 +5121,10 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \tint count;\n \ttree index = TYPE_DOMAIN (type);\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tcount = aapcs_vfp_sub_candidate (TREE_TYPE (type), modep);\n@@ -5139,9 +5141,7 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \t\t      - tree_to_uhwi (TYPE_MIN_VALUE (index)));\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -5153,8 +5153,10 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \tint sub_count;\n \ttree field;\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tfor (field = TYPE_FIELDS (type); field; field = DECL_CHAIN (field))\n@@ -5169,9 +5171,7 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \t  }\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -5185,8 +5185,10 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \tint sub_count;\n \ttree field;\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tfor (field = TYPE_FIELDS (type); field; field = DECL_CHAIN (field))\n@@ -5201,9 +5203,7 @@ aapcs_vfp_sub_candidate (const_tree type, enum machine_mode *modep)\n \t  }\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -11920,8 +11920,8 @@ vfp3_const_double_index (rtx x)\n   int sign, exponent;\n   unsigned HOST_WIDE_INT mantissa, mant_hi;\n   unsigned HOST_WIDE_INT mask;\n-  HOST_WIDE_INT m1, m2;\n   int point_pos = 2 * HOST_BITS_PER_WIDE_INT - 1;\n+  bool fail;\n \n   if (!TARGET_VFP3 || !CONST_DOUBLE_P (x))\n     return -1;\n@@ -11941,9 +11941,9 @@ vfp3_const_double_index (rtx x)\n      WARNING: If there's ever a VFP version which uses more than 2 * H_W_I - 1\n      bits for the mantissa, this may fail (low bits would be lost).  */\n   real_ldexp (&m, &r, point_pos - exponent);\n-  REAL_VALUE_TO_INT (&m1, &m2, m);\n-  mantissa = m1;\n-  mant_hi = m2;\n+  wide_int w = real_to_integer (&m, &fail, HOST_BITS_PER_WIDE_INT * 2);\n+  mantissa = w.elt (0);\n+  mant_hi = w.elt (1);\n \n   /* If there are bits set in the low part of the mantissa, we can't\n      represent this value.  */"}, {"sha": "2edc78ac041e474c4f163fed9b376fc2a26d93c2", "filename": "gcc/config/avr/avr.c", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Favr%2Favr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Favr%2Favr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Favr%2Favr.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -7566,6 +7566,8 @@ avr_out_round (rtx insn ATTRIBUTE_UNUSED, rtx *xop, int *plen)\n   // The smallest fractional bit not cleared by the rounding is 2^(-RP).\n   int fbit = (int) GET_MODE_FBIT (mode);\n   double_int i_add = double_int_zero.set_bit (fbit-1 - INTVAL (xop[2]));\n+  wide_int wi_add = wi::set_bit_in_zero (fbit-1 - INTVAL (xop[2]),\n+\t\t\t\t\t GET_MODE_PRECISION (imode));\n   // Lengths of PLUS and AND parts.\n   int len_add = 0, *plen_add = plen ? &len_add : NULL;\n   int len_and = 0, *plen_and = plen ? &len_and : NULL;\n@@ -7595,7 +7597,7 @@ avr_out_round (rtx insn ATTRIBUTE_UNUSED, rtx *xop, int *plen)\n   // Rounding point                           ^^^^^^^\n   // Added above                                      ^^^^^^^^^\n   rtx xreg = simplify_gen_subreg (imode, xop[0], mode, 0);\n-  rtx xmask = immed_double_int_const (-i_add - i_add, imode);\n+  rtx xmask = immed_wide_int_const (-wi_add - wi_add, imode);\n \n   xpattern = gen_rtx_SET (VOIDmode, xreg, gen_rtx_AND (imode, xreg, xmask));\n \n@@ -12246,7 +12248,7 @@ avr_fold_builtin (tree fndecl, int n_args ATTRIBUTE_UNUSED, tree *arg,\n             break;\n           }\n \n-        tmap = double_int_to_tree (map_type, tree_to_double_int (arg[0]));\n+        tmap = wide_int_to_tree (map_type, arg[0]);\n         map = TREE_INT_CST_LOW (tmap);\n \n         if (TREE_CODE (tval) != INTEGER_CST\n@@ -12351,8 +12353,7 @@ avr_fold_builtin (tree fndecl, int n_args ATTRIBUTE_UNUSED, tree *arg,\n \n         /* Use map o G^-1 instead of original map to undo the effect of G.  */\n \n-        tmap = double_int_to_tree (map_type,\n-\t\t\t\t   double_int::from_uhwi (best_g.map));\n+        tmap = wide_int_to_tree (map_type, best_g.map);\n \n         return build_call_expr (fndecl, 3, tmap, tbits, tval);\n       } /* AVR_BUILTIN_INSERT_BITS */"}, {"sha": "84b2d01c7300d34de8f8cdd3225697a05a31999e", "filename": "gcc/config/bfin/bfin.c", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fbfin%2Fbfin.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fbfin%2Fbfin.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fbfin%2Fbfin.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -3288,8 +3288,8 @@ bfin_local_alignment (tree type, unsigned align)\n      memcpy can use 32 bit loads/stores.  */\n   if (TYPE_SIZE (type)\n       && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST\n-      && (TREE_INT_CST_LOW (TYPE_SIZE (type)) > 8\n-\t  || TREE_INT_CST_HIGH (TYPE_SIZE (type))) && align < 32)\n+      && wi::gtu_p (TYPE_SIZE (type), 8)\n+      && align < 32)\n     return 32;\n   return align;\n }\n@@ -3371,15 +3371,14 @@ find_prev_insn_start (rtx insn)\n /* Implement TARGET_CAN_USE_DOLOOP_P.  */\n \n static bool\n-bfin_can_use_doloop_p (double_int, double_int iterations_max,\n+bfin_can_use_doloop_p (const widest_int &, const widest_int &iterations_max,\n \t\t       unsigned int, bool)\n {\n   /* Due to limitations in the hardware (an initial loop count of 0\n      does not loop 2^32 times) we must avoid to generate a hardware\n      loops when we cannot rule out this case.  */\n   if (!flag_unsafe_loop_optimizations\n-      && (iterations_max.high != 0\n-\t  || iterations_max.low >= 0xFFFFFFFF))\n+      && wi::geu_p (iterations_max, 0xFFFFFFFF))\n     return false;\n   return true;\n }"}, {"sha": "3c50e24edf2670c90f32b3b6cd8623348ca8d0b9", "filename": "gcc/config/darwin.c", "status": "modified", "additions": 14, "deletions": 16, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fdarwin.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fdarwin.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fdarwin.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1299,22 +1299,17 @@ darwin_mergeable_constant_section (tree exp,\n     {\n       tree size = TYPE_SIZE_UNIT (TREE_TYPE (exp));\n \n-      if (TREE_CODE (size) == INTEGER_CST\n-\t  && TREE_INT_CST_LOW (size) == 4\n-\t  && TREE_INT_CST_HIGH (size) == 0)\n-        return darwin_sections[literal4_section];\n-      else if (TREE_CODE (size) == INTEGER_CST\n-\t       && TREE_INT_CST_LOW (size) == 8\n-\t       && TREE_INT_CST_HIGH (size) == 0)\n-        return darwin_sections[literal8_section];\n-      else if (HAVE_GAS_LITERAL16\n-\t       && TARGET_64BIT\n-               && TREE_CODE (size) == INTEGER_CST\n-               && TREE_INT_CST_LOW (size) == 16\n-               && TREE_INT_CST_HIGH (size) == 0)\n-        return darwin_sections[literal16_section];\n-      else\n-        return readonly_data_section;\n+      if (TREE_CODE (size) == INTEGER_CST)\n+\t{\n+\t  if (wi::eq_p (size, 4))\n+\t    return darwin_sections[literal4_section];\n+\t  else if (wi::eq_p (size, 8))\n+\t    return darwin_sections[literal8_section];\n+\t  else if (HAVE_GAS_LITERAL16\n+\t\t   && TARGET_64BIT\n+\t\t   && wi::eq_p (size, 16))\n+\t    return darwin_sections[literal16_section];\n+\t}\n     }\n \n   return readonly_data_section;\n@@ -1741,16 +1736,19 @@ machopic_select_rtx_section (enum machine_mode mode, rtx x,\n {\n   if (GET_MODE_SIZE (mode) == 8\n       && (GET_CODE (x) == CONST_INT\n+\t  || GET_CODE (x) == CONST_WIDE_INT\n \t  || GET_CODE (x) == CONST_DOUBLE))\n     return darwin_sections[literal8_section];\n   else if (GET_MODE_SIZE (mode) == 4\n \t   && (GET_CODE (x) == CONST_INT\n+\t       || GET_CODE (x) == CONST_WIDE_INT\n \t       || GET_CODE (x) == CONST_DOUBLE))\n     return darwin_sections[literal4_section];\n   else if (HAVE_GAS_LITERAL16\n \t   && TARGET_64BIT\n \t   && GET_MODE_SIZE (mode) == 16\n \t   && (GET_CODE (x) == CONST_INT\n+\t       || GET_CODE (x) == CONST_WIDE_INT\n \t       || GET_CODE (x) == CONST_DOUBLE\n \t       || GET_CODE (x) == CONST_VECTOR))\n     return darwin_sections[literal16_section];"}, {"sha": "01ad5e50193ab97484fac33e157e63d6e452232b", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 15, "deletions": 16, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -78,6 +78,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"diagnostic.h\"\n #include \"dumpfile.h\"\n #include \"tree-pass.h\"\n+#include \"wide-int.h\"\n #include \"context.h\"\n #include \"pass_manager.h\"\n #include \"target-globals.h\"\n@@ -26582,14 +26583,12 @@ ix86_data_alignment (tree type, int align, bool opt)\n       && TYPE_SIZE (type)\n       && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST)\n     {\n-      if ((TREE_INT_CST_LOW (TYPE_SIZE (type)) >= (unsigned) max_align_compat\n-\t   || TREE_INT_CST_HIGH (TYPE_SIZE (type)))\n+      if (wi::geu_p (TYPE_SIZE (type), max_align_compat)\n \t  && align < max_align_compat)\n \talign = max_align_compat;\n-      if ((TREE_INT_CST_LOW (TYPE_SIZE (type)) >= (unsigned) max_align\n-\t   || TREE_INT_CST_HIGH (TYPE_SIZE (type)))\n-\t  && align < max_align)\n-\talign = max_align;\n+       if (wi::geu_p (TYPE_SIZE (type), max_align)\n+\t   && align < max_align)\n+\t align = max_align;\n     }\n \n   /* x86-64 ABI requires arrays greater than 16 bytes to be aligned\n@@ -26599,8 +26598,8 @@ ix86_data_alignment (tree type, int align, bool opt)\n       if ((opt ? AGGREGATE_TYPE_P (type) : TREE_CODE (type) == ARRAY_TYPE)\n \t  && TYPE_SIZE (type)\n \t  && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST\n-\t  && (TREE_INT_CST_LOW (TYPE_SIZE (type)) >= 128\n-\t      || TREE_INT_CST_HIGH (TYPE_SIZE (type))) && align < 128)\n+\t  && wi::geu_p (TYPE_SIZE (type), 128)\n+\t  && align < 128)\n \treturn 128;\n     }\n \n@@ -26709,13 +26708,13 @@ ix86_local_alignment (tree exp, enum machine_mode mode,\n       && TARGET_SSE)\n     {\n       if (AGGREGATE_TYPE_P (type)\n-\t   && (va_list_type_node == NULL_TREE\n-\t       || (TYPE_MAIN_VARIANT (type)\n-\t\t   != TYPE_MAIN_VARIANT (va_list_type_node)))\n-\t   && TYPE_SIZE (type)\n-\t   && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST\n-\t   && (TREE_INT_CST_LOW (TYPE_SIZE (type)) >= 16\n-\t       || TREE_INT_CST_HIGH (TYPE_SIZE (type))) && align < 128)\n+\t  && (va_list_type_node == NULL_TREE\n+\t      || (TYPE_MAIN_VARIANT (type)\n+\t\t  != TYPE_MAIN_VARIANT (va_list_type_node)))\n+\t  && TYPE_SIZE (type)\n+\t  && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST\n+\t  && wi::geu_p (TYPE_SIZE (type), 16)\n+\t  && align < 128)\n \treturn 128;\n     }\n   if (TREE_CODE (type) == ARRAY_TYPE)\n@@ -41375,7 +41374,7 @@ void ix86_emit_swsqrtsf (rtx res, rtx a, enum machine_mode mode,\n   e2 = gen_reg_rtx (mode);\n   e3 = gen_reg_rtx (mode);\n \n-  real_from_integer (&r, VOIDmode, -3, -1, 0);\n+  real_from_integer (&r, VOIDmode, -3, SIGNED);\n   mthree = CONST_DOUBLE_FROM_REAL_VALUE (r, SFmode);\n \n   real_arithmetic (&r, NEGATE_EXPR, &dconsthalf, NULL);"}, {"sha": "1ec96526efd36344b46037ababe53fb32757e529", "filename": "gcc/config/msp430/msp430.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fmsp430%2Fmsp430.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fmsp430%2Fmsp430.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fmsp430%2Fmsp430.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1085,7 +1085,7 @@ msp430_attr (tree * node,\n \t  break;\n \n \tcase INTEGER_CST:\n-\t  if (TREE_INT_CST_LOW (value) > 63)\n+\t  if (wi::gtu_p (value, 63))\n \t    /* Allow the attribute to be added - the linker script\n \t       being used may still recognise this value.  */\n \t    warning (OPT_Wattributes,"}, {"sha": "6e5595c09f5311959fd9525f35eb24d73916a9d2", "filename": "gcc/config/nds32/nds32.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fnds32%2Fnds32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fnds32%2Fnds32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnds32%2Fnds32.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -3148,8 +3148,8 @@ nds32_insert_attributes (tree decl, tree *attributes)\n \t      id = TREE_VALUE (id_list);\n \t      /* Issue error if it is not a valid integer value.  */\n \t      if (TREE_CODE (id) != INTEGER_CST\n-\t\t  || TREE_INT_CST_LOW (id) < lower_bound\n-\t\t  || TREE_INT_CST_LOW (id) > upper_bound)\n+\t\t  || wi::ltu_p (id, lower_bound)\n+\t\t  || wi::gtu_p (id, upper_bound))\n \t\terror (\"invalid id value for interrupt/exception attribute\");\n \n \t      /* Advance to next id.  */\n@@ -3176,8 +3176,8 @@ nds32_insert_attributes (tree decl, tree *attributes)\n \n \t  /* 3. Check valid integer value for reset.  */\n \t  if (TREE_CODE (id) != INTEGER_CST\n-\t      || TREE_INT_CST_LOW (id) < lower_bound\n-\t      || TREE_INT_CST_LOW (id) > upper_bound)\n+\t      || wi::ltu_p (id, lower_bound)\n+\t      || wi::gtu_p (id, upper_bound))\n \t    error (\"invalid id value for reset attribute\");\n \n \t  /* 4. Check valid function for nmi/warm.  */"}, {"sha": "47050c3d03e5d328daa1ddb823e901e8a2ae41f0", "filename": "gcc/config/rs6000/predicates.md", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fpredicates.md?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -19,7 +19,7 @@\n \n ;; Return 1 for anything except PARALLEL.\n (define_predicate \"any_operand\"\n-  (match_code \"const_int,const_double,const,symbol_ref,label_ref,subreg,reg,mem\"))\n+  (match_code \"const_int,const_double,const_wide_int,const,symbol_ref,label_ref,subreg,reg,mem\"))\n \n ;; Return 1 for any PARALLEL.\n (define_predicate \"any_parallel_operand\"\n@@ -601,7 +601,7 @@\n \n ;; Return 1 if operand is constant zero (scalars and vectors).\n (define_predicate \"zero_constant\"\n-  (and (match_code \"const_int,const_double,const_vector\")\n+  (and (match_code \"const_int,const_double,const_wide_int,const_vector\")\n        (match_test \"op == CONST0_RTX (mode)\")))\n \n ;; Return 1 if operand is 0.0.\n@@ -796,7 +796,7 @@\n ;; Return 1 if op is a constant that is not a logical operand, but could\n ;; be split into one.\n (define_predicate \"non_logical_cint_operand\"\n-  (and (match_code \"const_int,const_double\")\n+  (and (match_code \"const_int,const_wide_int\")\n        (and (not (match_operand 0 \"logical_operand\"))\n \t    (match_operand 0 \"reg_or_logical_cint_operand\"))))\n \n@@ -1073,7 +1073,7 @@\n ;; Return 1 if this operand is a valid input for a move insn.\n (define_predicate \"input_operand\"\n   (match_code \"symbol_ref,const,reg,subreg,mem,\n-\t       const_double,const_vector,const_int\")\n+\t       const_double,const_wide_int,const_vector,const_int\")\n {\n   /* Memory is always valid.  */\n   if (memory_operand (op, mode))\n@@ -1086,8 +1086,7 @@\n \n   /* Allow any integer constant.  */\n   if (GET_MODE_CLASS (mode) == MODE_INT\n-      && (GET_CODE (op) == CONST_INT\n-\t  || GET_CODE (op) == CONST_DOUBLE))\n+      && CONST_SCALAR_INT_P (op))\n     return 1;\n \n   /* Allow easy vector constants.  */\n@@ -1126,7 +1125,7 @@\n ;; Return 1 if this operand is a valid input for a vsx_splat insn.\n (define_predicate \"splat_input_operand\"\n   (match_code \"symbol_ref,const,reg,subreg,mem,\n-\t       const_double,const_vector,const_int\")\n+\t       const_double,const_wide_int,const_vector,const_int\")\n {\n   if (MEM_P (op))\n     {"}, {"sha": "2b9cf7a0b383706efd895c59a3b7ab71584d926b", "filename": "gcc/config/rs6000/rs6000-c.c", "status": "modified", "additions": 5, "deletions": 8, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-c.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -28,6 +28,7 @@\n #include \"tree.h\"\n #include \"stor-layout.h\"\n #include \"stringpool.h\"\n+#include \"wide-int.h\"\n #include \"c-family/c-common.h\"\n #include \"c-family/c-pragma.h\"\n #include \"diagnostic-core.h\"\n@@ -4304,8 +4305,7 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n       mode = TYPE_MODE (arg1_type);\n       if ((mode == V2DFmode || mode == V2DImode) && VECTOR_MEM_VSX_P (mode)\n \t  && TREE_CODE (arg2) == INTEGER_CST\n-\t  && TREE_INT_CST_HIGH (arg2) == 0\n-\t  && (TREE_INT_CST_LOW (arg2) == 0 || TREE_INT_CST_LOW (arg2) == 1))\n+\t  && wi::ltu_p (arg2, 2))\n \t{\n \t  tree call = NULL_TREE;\n \n@@ -4319,8 +4319,7 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n \t}\n       else if (mode == V1TImode && VECTOR_MEM_VSX_P (mode)\n \t       && TREE_CODE (arg2) == INTEGER_CST\n-\t       && TREE_INT_CST_HIGH (arg2) == 0\n-\t       && TREE_INT_CST_LOW (arg2) == 0)\n+\t       && wi::eq_p (arg2, 0))\n \t{\n \t  tree call = rs6000_builtin_decls[VSX_BUILTIN_VEC_EXT_V1TI];\n \t  return build_call_expr (call, 2, arg1, arg2);\n@@ -4409,8 +4408,7 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n       mode = TYPE_MODE (arg1_type);\n       if ((mode == V2DFmode || mode == V2DImode) && VECTOR_UNIT_VSX_P (mode)\n \t  && TREE_CODE (arg2) == INTEGER_CST\n-\t  && TREE_INT_CST_HIGH (arg2) == 0\n-\t  && (TREE_INT_CST_LOW (arg2) == 0 || TREE_INT_CST_LOW (arg2) == 1))\n+\t  && wi::ltu_p (arg2, 2))\n \t{\n \t  tree call = NULL_TREE;\n \n@@ -4426,8 +4424,7 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n \t}\n       else if (mode == V1TImode && VECTOR_UNIT_VSX_P (mode)\n \t       && TREE_CODE (arg2) == INTEGER_CST\n-\t       && TREE_INT_CST_HIGH (arg2) == 0\n-\t       && TREE_INT_CST_LOW (arg2) == 0)\n+\t       && wi::eq_p (arg2, 0))\n \t{\n \t  tree call = rs6000_builtin_decls[VSX_BUILTIN_VEC_SET_V1TI];\n "}, {"sha": "e4a68347f57bfdd8e8790b27537405bfdc673b6c", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 46, "deletions": 44, "changes": 90, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -4969,6 +4969,15 @@ num_insns_constant (rtx op, enum machine_mode mode)\n       else\n \treturn num_insns_constant_wide (INTVAL (op));\n \n+    case CONST_WIDE_INT:\n+      {\n+\tint i;\n+\tint ins = CONST_WIDE_INT_NUNITS (op) - 1;\n+\tfor (i = 0; i < CONST_WIDE_INT_NUNITS (op); i++)\n+\t  ins += num_insns_constant_wide (CONST_WIDE_INT_ELT (op, i));\n+\treturn ins;\n+      }\n+\n       case CONST_DOUBLE:\n \tif (mode == SFmode || mode == SDmode)\n \t  {\n@@ -5143,8 +5152,6 @@ easy_altivec_constant (rtx op, enum machine_mode mode)\n \n   else if (mode == V2DImode)\n     {\n-      /* In case the compiler is built 32-bit, CONST_DOUBLE constants are not\n-\t easy.  */\n       if (GET_CODE (CONST_VECTOR_ELT (op, 0)) != CONST_INT\n \t  || GET_CODE (CONST_VECTOR_ELT (op, 1)) != CONST_INT)\n \treturn false;\n@@ -5309,9 +5316,7 @@ paired_expand_vector_init (rtx target, rtx vals)\n   for (i = 0; i < n_elts; ++i)\n     {\n       x = XVECEXP (vals, 0, i);\n-      if (!(CONST_INT_P (x)\n-\t    || GET_CODE (x) == CONST_DOUBLE\n-\t    || GET_CODE (x) == CONST_FIXED))\n+      if (!CONSTANT_P (x))\n \t++n_var;\n     }\n   if (n_var == 0)\n@@ -5463,9 +5468,7 @@ rs6000_expand_vector_init (rtx target, rtx vals)\n   for (i = 0; i < n_elts; ++i)\n     {\n       x = XVECEXP (vals, 0, i);\n-      if (!(CONST_INT_P (x)\n-\t    || GET_CODE (x) == CONST_DOUBLE\n-\t    || GET_CODE (x) == CONST_FIXED))\n+      if (!CONSTANT_P (x))\n \t++n_var, one_var = i;\n       else if (x != CONST0_RTX (inner_mode))\n \tall_const_zero = false;\n@@ -6703,6 +6706,7 @@ rs6000_legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED,\n \t   && TARGET_NO_TOC\n \t   && ! flag_pic\n \t   && GET_CODE (x) != CONST_INT\n+\t   && GET_CODE (x) != CONST_WIDE_INT\n \t   && GET_CODE (x) != CONST_DOUBLE\n \t   && CONSTANT_P (x)\n \t   && GET_MODE_NUNITS (mode) == 1\n@@ -8167,21 +8171,12 @@ rs6000_emit_move (rtx dest, rtx source, enum machine_mode mode)\n     }\n \n   /* Sanity checks.  Check that we get CONST_DOUBLE only when we should.  */\n-  if (GET_CODE (operands[1]) == CONST_DOUBLE\n-      && ! FLOAT_MODE_P (mode)\n+  if (CONST_WIDE_INT_P (operands[1])\n       && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n     {\n-      /* FIXME.  This should never happen.  */\n-      /* Since it seems that it does, do the safe thing and convert\n-\t to a CONST_INT.  */\n-      operands[1] = gen_int_mode (CONST_DOUBLE_LOW (operands[1]), mode);\n+      /* This should be fixed with the introduction of CONST_WIDE_INT.  */\n+      gcc_unreachable ();\n     }\n-  gcc_assert (GET_CODE (operands[1]) != CONST_DOUBLE\n-\t      || FLOAT_MODE_P (mode)\n-\t      || ((CONST_DOUBLE_HIGH (operands[1]) != 0\n-\t\t   || CONST_DOUBLE_LOW (operands[1]) < 0)\n-\t\t  && (CONST_DOUBLE_HIGH (operands[1]) != -1\n-\t\t      || CONST_DOUBLE_LOW (operands[1]) >= 0)));\n \n   /* Check if GCC is setting up a block move that will end up using FP\n      registers as temporaries.  We must make sure this is acceptable.  */\n@@ -8697,8 +8692,10 @@ rs6000_aggregate_candidate (const_tree type, enum machine_mode *modep)\n \tint count;\n \ttree index = TYPE_DOMAIN (type);\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tcount = rs6000_aggregate_candidate (TREE_TYPE (type), modep);\n@@ -8715,9 +8712,7 @@ rs6000_aggregate_candidate (const_tree type, enum machine_mode *modep)\n \t\t      - tree_to_uhwi (TYPE_MIN_VALUE (index)));\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -8729,8 +8724,10 @@ rs6000_aggregate_candidate (const_tree type, enum machine_mode *modep)\n \tint sub_count;\n \ttree field;\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \t  return -1;\n \n \tfor (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n@@ -8745,9 +8742,7 @@ rs6000_aggregate_candidate (const_tree type, enum machine_mode *modep)\n \t  }\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -8761,9 +8756,10 @@ rs6000_aggregate_candidate (const_tree type, enum machine_mode *modep)\n \tint sub_count;\n \ttree field;\n \n-\t/* Can't handle incomplete types.  */\n-\tif (!COMPLETE_TYPE_P (type))\n-\t  return -1;\n+\t/* Can't handle incomplete types nor sizes that are not\n+\t   fixed.  */\n+\tif (!COMPLETE_TYPE_P (type)\n+\t    || TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n \n \tfor (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n \t  {\n@@ -8777,9 +8773,7 @@ rs6000_aggregate_candidate (const_tree type, enum machine_mode *modep)\n \t  }\n \n \t/* There must be no padding.  */\n-\tif (!tree_fits_uhwi_p (TYPE_SIZE (type))\n-\t    || ((HOST_WIDE_INT) tree_to_uhwi (TYPE_SIZE (type))\n-\t\t!= count * GET_MODE_BITSIZE (*modep)))\n+\tif (wi::ne_p (TYPE_SIZE (type), count * GET_MODE_BITSIZE (*modep)))\n \t  return -1;\n \n \treturn count;\n@@ -12474,16 +12468,14 @@ rs6000_expand_ternop_builtin (enum insn_code icode, tree exp, rtx target)\n       /* Check whether the 2nd and 3rd arguments are integer constants and in\n \t range and prepare arguments.  */\n       STRIP_NOPS (arg1);\n-      if (TREE_CODE (arg1) != INTEGER_CST\n-\t  || !IN_RANGE (TREE_INT_CST_LOW (arg1), 0, 1))\n+      if (TREE_CODE (arg1) != INTEGER_CST || wi::geu_p (arg1, 2))\n \t{\n \t  error (\"argument 2 must be 0 or 1\");\n \t  return const0_rtx;\n \t}\n \n       STRIP_NOPS (arg2);\n-      if (TREE_CODE (arg2) != INTEGER_CST\n-\t  || !IN_RANGE (TREE_INT_CST_LOW (arg2), 0, 15))\n+      if (TREE_CODE (arg2) != INTEGER_CST || wi::geu_p (arg1, 16))\n \t{\n \t  error (\"argument 3 must be in the range 0..15\");\n \t  return const0_rtx;\n@@ -17456,6 +17448,7 @@ rs6000_output_move_128bit (rtx operands[])\n   /* Constants.  */\n   else if (dest_regno >= 0\n \t   && (GET_CODE (src) == CONST_INT\n+\t       || GET_CODE (src) == CONST_WIDE_INT\n \t       || GET_CODE (src) == CONST_DOUBLE\n \t       || GET_CODE (src) == CONST_VECTOR))\n     {\n@@ -18495,8 +18488,7 @@ rs6000_assemble_integer (rtx x, unsigned int size, int aligned_p)\n       if (TARGET_RELOCATABLE\n \t  && in_section != toc_section\n \t  && !recurse\n-\t  && GET_CODE (x) != CONST_INT\n-\t  && GET_CODE (x) != CONST_DOUBLE\n+\t  && !CONST_SCALAR_INT_P (x)\n \t  && CONSTANT_P (x))\n \t{\n \t  char buf[256];\n@@ -25243,6 +25235,15 @@ rs6000_hash_constant (rtx k)\n     case LABEL_REF:\n       return result * 1231 + (unsigned) INSN_UID (XEXP (k, 0));\n \n+    case CONST_WIDE_INT:\n+      {\n+\tint i;\n+\tflen = CONST_WIDE_INT_NUNITS (k);\n+\tfor (i = 0; i < flen; i++)\n+\t  result = result * 613 + CONST_WIDE_INT_ELT (k, i);\n+\treturn result;\n+      }\n+\n     case CONST_DOUBLE:\n       if (mode != VOIDmode)\n \treturn real_hash (CONST_DOUBLE_REAL_VALUE (k)) * result;\n@@ -25447,7 +25448,7 @@ output_toc (FILE *file, rtx x, int labelno, enum machine_mode mode)\n \n   /* If we're going to put a double constant in the TOC, make sure it's\n      aligned properly when strict alignment is on.  */\n-  if (GET_CODE (x) == CONST_DOUBLE\n+  if ((CONST_DOUBLE_P (x) || CONST_WIDE_INT_P (x))\n       && STRICT_ALIGNMENT\n       && GET_MODE_BITSIZE (mode) >= 64\n       && ! (TARGET_NO_FP_IN_TOC && ! TARGET_MINIMAL_TOC)) {\n@@ -29453,6 +29454,7 @@ rs6000_rtx_costs (rtx x, int code, int outer_code, int opno ATTRIBUTE_UNUSED,\n       /* FALLTHRU */\n \n     case CONST_DOUBLE:\n+    case CONST_WIDE_INT:\n     case CONST:\n     case HIGH:\n     case SYMBOL_REF:\n@@ -30092,7 +30094,7 @@ rs6000_emit_swrsqrt (rtx dst, rtx src)\n   gcc_assert (code != CODE_FOR_nothing);\n \n   /* Load up the constant 1.5 either as a scalar, or as a vector.  */\n-  real_from_integer (&dconst3_2, VOIDmode, 3, 0, 0);\n+  real_from_integer (&dconst3_2, VOIDmode, 3, SIGNED);\n   SET_REAL_EXP (&dconst3_2, REAL_EXP (&dconst3_2) - 1);\n \n   halfthree = rs6000_load_constant_and_splat (mode, dconst3_2);"}, {"sha": "f979905f1da74736664f9e0d8b24a34a5e64dbc2", "filename": "gcc/config/rs6000/rs6000.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2689,3 +2689,4 @@ enum rs6000_builtin_type_index\n extern GTY(()) tree rs6000_builtin_types[RS6000_BTI_MAX];\n extern GTY(()) tree rs6000_builtin_decls[RS6000_BUILTIN_COUNT];\n \n+#define TARGET_SUPPORTS_WIDE_INT 1"}, {"sha": "f6da9b3a382c1609d1a52d3c48e06ed3dd876fd6", "filename": "gcc/config/rs6000/rs6000.md", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Frs6000%2Frs6000.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.md?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -10336,7 +10336,7 @@\n \n (define_split\n   [(set (match_operand:DI 0 \"gpc_reg_operand\" \"\")\n-\t(match_operand:DI 1 \"const_double_operand\" \"\"))]\n+\t(match_operand:DI 1 \"const_scalar_int_operand\" \"\"))]\n   \"TARGET_POWERPC64 && num_insns_constant (operands[1], DImode) > 1\"\n   [(set (match_dup 0) (match_dup 2))\n    (set (match_dup 0) (plus:DI (match_dup 0) (match_dup 3)))]\n@@ -10402,7 +10402,7 @@\n \n (define_split\n   [(set (match_operand:TI2 0 \"int_reg_operand\" \"\")\n-\t(match_operand:TI2 1 \"const_double_operand\" \"\"))]\n+\t(match_operand:TI2 1 \"const_scalar_int_operand\" \"\"))]\n   \"TARGET_POWERPC64\n    && (VECTOR_MEM_NONE_P (<MODE>mode)\n        || (reload_completed && INT_REGNO_P (REGNO (operands[0]))))\"\n@@ -10414,12 +10414,12 @@\n \t\t\t\t       <MODE>mode);\n   operands[3] = operand_subword_force (operands[0], WORDS_BIG_ENDIAN != 0,\n \t\t\t\t       <MODE>mode);\n-  if (GET_CODE (operands[1]) == CONST_DOUBLE)\n+  if (CONST_WIDE_INT_P (operands[1]))\n     {\n-      operands[4] = GEN_INT (CONST_DOUBLE_HIGH (operands[1]));\n-      operands[5] = GEN_INT (CONST_DOUBLE_LOW (operands[1]));\n+      operands[4] = GEN_INT (CONST_WIDE_INT_ELT (operands[1], 1));\n+      operands[5] = GEN_INT (CONST_WIDE_INT_ELT (operands[1], 0));\n     }\n-  else if (GET_CODE (operands[1]) == CONST_INT)\n+  else if (CONST_INT_P (operands[1]))\n     {\n       operands[4] = GEN_INT (- (INTVAL (operands[1]) < 0));\n       operands[5] = operands[1];"}, {"sha": "ef080ad6c799694e6e84c1af6fa5a62e34e0f0b0", "filename": "gcc/config/s390/s390.c", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fs390%2Fs390.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fs390%2Fs390.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -474,9 +474,7 @@ s390_handle_hotpatch_attribute (tree *node, tree name, tree args,\n \n       if (TREE_CODE (expr) != INTEGER_CST\n \t  || !INTEGRAL_TYPE_P (TREE_TYPE (expr))\n-\t  || TREE_INT_CST_HIGH (expr) != 0\n-\t  || TREE_INT_CST_LOW (expr) > (unsigned int)\n-\t  s390_hotpatch_trampoline_halfwords_max)\n+\t  || wi::gtu_p (expr, s390_hotpatch_trampoline_halfwords_max))\n \t{\n \t  error (\"requested %qE attribute is not a non-negative integer\"\n \t\t \" constant or too large (max. %d)\", name,"}, {"sha": "96ef99d9a79a5666788365b2d119edc4322ac998", "filename": "gcc/config/sol2-c.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fsol2-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fsol2-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsol2-c.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -86,7 +86,7 @@ solaris_pragma_align (cpp_reader *pfile ATTRIBUTE_UNUSED)\n {\n   tree t, x;\n   enum cpp_ttype ttype;\n-  HOST_WIDE_INT low;\n+  unsigned HOST_WIDE_INT low;\n \n   if (pragma_lex (&x) != CPP_NUMBER\n       || pragma_lex (&t) != CPP_OPEN_PAREN)\n@@ -96,7 +96,7 @@ solaris_pragma_align (cpp_reader *pfile ATTRIBUTE_UNUSED)\n     }\n \n   low = TREE_INT_CST_LOW (x);\n-  if (TREE_INT_CST_HIGH (x) != 0\n+  if (!tree_fits_uhwi_p (x)\n       || (low != 1 && low != 2 && low != 4 && low != 8 && low != 16\n \t  && low != 32 && low != 64 && low != 128))\n     {"}, {"sha": "ff1e9d154b2142a2604f76e76f8644ddb694090e", "filename": "gcc/config/sparc/sparc.c", "status": "modified", "additions": 11, "deletions": 10, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fsparc%2Fsparc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fsparc%2Fsparc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsparc%2Fsparc.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -69,6 +69,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"opts.h\"\n #include \"tree-pass.h\"\n #include \"context.h\"\n+#include \"wide-int.h\"\n \n /* Processor costs */\n \n@@ -10930,30 +10931,30 @@ sparc_fold_builtin (tree fndecl, int n_args ATTRIBUTE_UNUSED,\n \t  && TREE_CODE (arg2) == INTEGER_CST)\n \t{\n \t  bool overflow = false;\n-\t  double_int result = TREE_INT_CST (arg2);\n-\t  double_int tmp;\n+\t  wide_int result = arg2;\n+\t  wide_int tmp;\n \t  unsigned i;\n \n \t  for (i = 0; i < VECTOR_CST_NELTS (arg0); ++i)\n \t    {\n-\t      double_int e0 = TREE_INT_CST (VECTOR_CST_ELT (arg0, i));\n-\t      double_int e1 = TREE_INT_CST (VECTOR_CST_ELT (arg1, i));\n+\t      tree e0 = VECTOR_CST_ELT (arg0, i);\n+\t      tree e1 = VECTOR_CST_ELT (arg1, i);\n \n \t      bool neg1_ovf, neg2_ovf, add1_ovf, add2_ovf;\n \n-\t      tmp = e1.neg_with_overflow (&neg1_ovf);\n-\t      tmp = e0.add_with_sign (tmp, false, &add1_ovf);\n-\t      if (tmp.is_negative ())\n-\t\ttmp = tmp.neg_with_overflow (&neg2_ovf);\n+\t      tmp = wi::neg (e1, &neg1_ovf);\n+\t      tmp = wi::add (e0, tmp, SIGNED, &add1_ovf);\n+\t      if (wi::neg_p (tmp))\n+\t\ttmp = wi::neg (tmp, &neg2_ovf);\n \t      else\n \t\tneg2_ovf = false;\n-\t      result = result.add_with_sign (tmp, false, &add2_ovf);\n+\t      result = wi::add (result, tmp, SIGNED, &add2_ovf);\n \t      overflow |= neg1_ovf | neg2_ovf | add1_ovf | add2_ovf;\n \t    }\n \n \t  gcc_assert (!overflow);\n \n-\t  return build_int_cst_wide (rtype, result.low, result.high);\n+\t  return wide_int_to_tree (rtype, result);\n \t}\n \n     default:"}, {"sha": "818137baceb43bb1760fcfa9d5ca2bb97252dba0", "filename": "gcc/config/vax/vax.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fvax%2Fvax.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fconfig%2Fvax%2Fvax.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fvax%2Fvax.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -45,6 +45,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tm_p.h\"\n #include \"target.h\"\n #include \"target-def.h\"\n+#include \"wide-int.h\"\n \n static void vax_option_override (void);\n static bool vax_legitimate_address_p (enum machine_mode, rtx, bool);\n@@ -645,7 +646,7 @@ vax_float_literal (rtx c)\n     {\n       int x = 1 << i;\n       bool ok;\n-      REAL_VALUE_FROM_INT (s, x, 0, mode);\n+      real_from_integer (&s, mode, x, SIGNED);\n \n       if (REAL_VALUES_EQUAL (r, s))\n \treturn true;"}, {"sha": "41ad1a3b22d3e2290e07bd613d39c6bd5ac13692", "filename": "gcc/coretypes.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcoretypes.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcoretypes.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcoretypes.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -58,6 +58,9 @@ typedef const struct rtx_def *const_rtx;\n struct rtvec_def;\n typedef struct rtvec_def *rtvec;\n typedef const struct rtvec_def *const_rtvec;\n+struct hwivec_def;\n+typedef struct hwivec_def *hwivec;\n+typedef const struct hwivec_def *const_hwivec;\n union tree_node;\n typedef union tree_node *tree;\n typedef const union tree_node *const_tree;"}, {"sha": "857df57c60ce519c73a1c44334a3293ac71f46e0", "filename": "gcc/cp/call.c", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fcall.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fcall.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fcall.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -41,6 +41,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"c-family/c-objc.h\"\n #include \"timevar.h\"\n #include \"cgraph.h\"\n+#include \"wide-int.h\"\n \n /* The various kinds of conversion.  */\n \n@@ -6576,8 +6577,7 @@ type_passed_as (tree type)\n   else if (targetm.calls.promote_prototypes (type)\n \t   && INTEGRAL_TYPE_P (type)\n \t   && COMPLETE_TYPE_P (type)\n-\t   && INT_CST_LT_UNSIGNED (TYPE_SIZE (type),\n-\t\t\t\t   TYPE_SIZE (integer_type_node)))\n+\t   && tree_int_cst_lt (TYPE_SIZE (type), TYPE_SIZE (integer_type_node)))\n     type = integer_type_node;\n \n   return type;\n@@ -6617,8 +6617,7 @@ convert_for_arg_passing (tree type, tree val, tsubst_flags_t complain)\n   else if (targetm.calls.promote_prototypes (type)\n \t   && INTEGRAL_TYPE_P (type)\n \t   && COMPLETE_TYPE_P (type)\n-\t   && INT_CST_LT_UNSIGNED (TYPE_SIZE (type),\n-\t\t\t\t   TYPE_SIZE (integer_type_node)))\n+\t   && tree_int_cst_lt (TYPE_SIZE (type), TYPE_SIZE (integer_type_node)))\n     val = cp_perform_integral_promotions (val, complain);\n   if ((complain & tf_warning)\n       && warn_suggest_attribute_format)"}, {"sha": "c96d79dbc82a84df601c386724e6e79b04bd216e", "filename": "gcc/cp/class.c", "status": "modified", "additions": 14, "deletions": 13, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fclass.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fclass.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fclass.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -40,6 +40,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"dumpfile.h\"\n #include \"splay-tree.h\"\n #include \"gimplify.h\"\n+#include \"wide-int.h\"\n \n /* The number of nested classes being processed.  If we are not in the\n    scope of any class, this is zero.  */\n@@ -3811,7 +3812,7 @@ walk_subobject_offsets (tree type,\n \n   /* If this OFFSET is bigger than the MAX_OFFSET, then we should\n      stop.  */\n-  if (max_offset && INT_CST_LT (max_offset, offset))\n+  if (max_offset && tree_int_cst_lt (max_offset, offset))\n     return 0;\n \n   if (type == error_mark_node)\n@@ -3968,8 +3969,8 @@ walk_subobject_offsets (tree type,\n       for (index = size_zero_node;\n \t   /* G++ 3.2 had an off-by-one error here.  */\n \t   (abi_version_at_least (2)\n-\t    ? !INT_CST_LT (TYPE_MAX_VALUE (domain), index)\n-\t    : INT_CST_LT (index, TYPE_MAX_VALUE (domain)));\n+\t    ? !tree_int_cst_lt (TYPE_MAX_VALUE (domain), index)\n+\t    : tree_int_cst_lt (index, TYPE_MAX_VALUE (domain)));\n \t   index = size_binop (PLUS_EXPR, index, size_one_node))\n \t{\n \t  r = walk_subobject_offsets (TREE_TYPE (type),\n@@ -3985,7 +3986,7 @@ walk_subobject_offsets (tree type,\n \t  /* If this new OFFSET is bigger than the MAX_OFFSET, then\n \t     there's no point in iterating through the remaining\n \t     elements of the array.  */\n-\t  if (max_offset && INT_CST_LT (max_offset, offset))\n+\t  if (max_offset && tree_int_cst_lt (max_offset, offset))\n \t    break;\n \t}\n     }\n@@ -5922,7 +5923,7 @@ end_of_class (tree t, int include_virtuals_p)\n \tcontinue;\n \n       offset = end_of_base (base_binfo);\n-      if (INT_CST_LT_UNSIGNED (result, offset))\n+      if (tree_int_cst_lt (result, offset))\n \tresult = offset;\n     }\n \n@@ -5932,7 +5933,7 @@ end_of_class (tree t, int include_virtuals_p)\n \t vec_safe_iterate (vbases, i, &base_binfo); i++)\n       {\n \toffset = end_of_base (base_binfo);\n-\tif (INT_CST_LT_UNSIGNED (result, offset))\n+\tif (tree_int_cst_lt (result, offset))\n \t  result = offset;\n       }\n \n@@ -6012,7 +6013,7 @@ include_empty_classes (record_layout_info rli)\n \t\t      CLASSTYPE_AS_BASE (rli->t) != NULL_TREE);\n   rli_size = rli_size_unit_so_far (rli);\n   if (TREE_CODE (rli_size) == INTEGER_CST\n-      && INT_CST_LT_UNSIGNED (rli_size, eoc))\n+      && tree_int_cst_lt (rli_size, eoc))\n     {\n       if (!abi_version_at_least (2))\n \t/* In version 1 of the ABI, the size of a class that ends with\n@@ -6128,7 +6129,7 @@ layout_class_type (tree t, tree *virtuals_p)\n \t type, then there are some special rules for allocating\n \t it.  */\n       if (DECL_C_BIT_FIELD (field)\n-\t  && INT_CST_LT (TYPE_SIZE (type), DECL_SIZE (field)))\n+\t  && tree_int_cst_lt (TYPE_SIZE (type), DECL_SIZE (field)))\n \t{\n \t  unsigned int itk;\n \t  tree integer_type;\n@@ -6139,10 +6140,10 @@ layout_class_type (tree t, tree *virtuals_p)\n \t     bits as additional padding.  */\n \t  for (itk = itk_char; itk != itk_none; ++itk)\n \t    if (integer_types[itk] != NULL_TREE\n-\t\t&& (INT_CST_LT (size_int (MAX_FIXED_MODE_SIZE),\n-\t\t\t\tTYPE_SIZE (integer_types[itk]))\n-\t\t    || INT_CST_LT (DECL_SIZE (field),\n-\t\t\t\t   TYPE_SIZE (integer_types[itk]))))\n+\t\t&& (tree_int_cst_lt (size_int (MAX_FIXED_MODE_SIZE),\n+\t\t\t\t     TYPE_SIZE (integer_types[itk]))\n+\t\t    || tree_int_cst_lt (DECL_SIZE (field),\n+\t\t\t\t\tTYPE_SIZE (integer_types[itk]))))\n \t      break;\n \n \t  /* ITK now indicates a type that is too large for the\n@@ -6158,7 +6159,7 @@ layout_class_type (tree t, tree *virtuals_p)\n \t     3.2 always created a padding field, even if it had zero\n \t     width.  */\n \t  if (!abi_version_at_least (2)\n-\t      || INT_CST_LT (TYPE_SIZE (integer_type), DECL_SIZE (field)))\n+\t      || tree_int_cst_lt (TYPE_SIZE (integer_type), DECL_SIZE (field)))\n \t    {\n \t      if (abi_version_at_least (2) && TREE_CODE (t) == UNION_TYPE)\n \t\t/* In a union, the padding field must have the full width"}, {"sha": "c833722538e5ae5552a2386989ac5fd3be2bbff7", "filename": "gcc/cp/cvt.c", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fcvt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fcvt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fcvt.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -36,6 +36,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"convert.h\"\n #include \"decl.h\"\n #include \"target.h\"\n+#include \"wide-int.h\"\n \n static tree cp_convert_to_pointer (tree, tree, tsubst_flags_t);\n static tree convert_to_pointer_force (tree, tree, tsubst_flags_t);\n@@ -582,9 +583,7 @@ ignore_overflows (tree expr, tree orig)\n     {\n       gcc_assert (!TREE_OVERFLOW (orig));\n       /* Ensure constant sharing.  */\n-      expr = build_int_cst_wide (TREE_TYPE (expr),\n-\t\t\t\t TREE_INT_CST_LOW (expr),\n-\t\t\t\t TREE_INT_CST_HIGH (expr));\n+      expr = wide_int_to_tree (TREE_TYPE (expr), expr);\n     }\n   return expr;\n }"}, {"sha": "01a36252b2edf992ebd160e21656954ffb808707", "filename": "gcc/cp/decl.c", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fdecl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fdecl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fdecl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -60,6 +60,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"plugin.h\"\n #include \"cgraph.h\"\n #include \"cilk.h\"\n+#include \"wide-int.h\"\n \n /* Possible cases of bad specifiers type used by bad_specifiers. */\n enum bad_spec_place {\n@@ -4844,7 +4845,7 @@ check_array_designated_initializer (constructor_elt *ce,\n       if (TREE_CODE (ce->index) == INTEGER_CST)\n \t{\n \t  /* A C99 designator is OK if it matches the current index.  */\n-\t  if (TREE_INT_CST_LOW (ce->index) == index)\n+\t  if (wi::eq_p (ce->index, index))\n \t    return true;\n \t  else\n \t    sorry (\"non-trivial designated initializers not supported\");\n@@ -8316,7 +8317,7 @@ compute_array_index_type (tree name, tree size, tsubst_flags_t complain)\n       constant_expression_error (size);\n \n       /* An array must have a positive number of elements.  */\n-      if (INT_CST_LT (size, integer_zero_node))\n+      if (tree_int_cst_lt (size, integer_zero_node))\n \t{\n \t  if (!(complain & tf_error))\n \t    return error_mark_node;\n@@ -12677,9 +12678,9 @@ finish_enum_value_list (tree enumtype)\n \t enumeration.  We must do this before the type of MINNODE and\n \t MAXNODE are transformed, since tree_int_cst_min_precision relies\n \t on the TREE_TYPE of the value it is passed.  */\n-      bool unsignedp = tree_int_cst_sgn (minnode) >= 0;\n-      int lowprec = tree_int_cst_min_precision (minnode, unsignedp);\n-      int highprec = tree_int_cst_min_precision (maxnode, unsignedp);\n+      signop sgn = tree_int_cst_sgn (minnode) >= 0 ? UNSIGNED : SIGNED;\n+      int lowprec = tree_int_cst_min_precision (minnode, sgn);\n+      int highprec = tree_int_cst_min_precision (maxnode, sgn);\n       int precision = MAX (lowprec, highprec);\n       unsigned int itk;\n       bool use_short_enum;\n@@ -12711,7 +12712,7 @@ finish_enum_value_list (tree enumtype)\n           underlying_type = integer_types[itk];\n           if (underlying_type != NULL_TREE\n \t      && TYPE_PRECISION (underlying_type) >= precision\n-              && TYPE_UNSIGNED (underlying_type) == unsignedp)\n+              && TYPE_SIGN (underlying_type) == sgn)\n             break;\n         }\n       if (itk == itk_none)\n@@ -12758,12 +12759,11 @@ finish_enum_value_list (tree enumtype)\n \t= build_distinct_type_copy (underlying_type);\n       TYPE_PRECISION (ENUM_UNDERLYING_TYPE (enumtype)) = precision;\n       set_min_and_max_values_for_integral_type\n-        (ENUM_UNDERLYING_TYPE (enumtype), precision, unsignedp);\n+        (ENUM_UNDERLYING_TYPE (enumtype), precision, sgn);\n \n       /* If -fstrict-enums, still constrain TYPE_MIN/MAX_VALUE.  */\n       if (flag_strict_enums)\n-\tset_min_and_max_values_for_integral_type (enumtype, precision,\n-\t\t\t\t\t\t  unsignedp);\n+\tset_min_and_max_values_for_integral_type (enumtype, precision, sgn);\n     }\n   else\n     underlying_type = ENUM_UNDERLYING_TYPE (enumtype);\n@@ -12887,22 +12887,22 @@ build_enumerator (tree name, tree value, tree enumtype, location_t loc)\n \t\tvalue = error_mark_node;\n \t      else\n \t\t{\n-\t\t  double_int di = TREE_INT_CST (prev_value)\n-\t\t\t\t  .add_with_sign (double_int_one,\n-\t\t\t\t\t\t  false, &overflowed);\n+\t\t  tree type = TREE_TYPE (prev_value);\n+\t\t  signop sgn = TYPE_SIGN (type);\n+\t\t  widest_int wi = wi::add (wi::to_widest (prev_value), 1, sgn,\n+\t\t\t\t\t   &overflowed);\n \t\t  if (!overflowed)\n \t\t    {\n-\t\t      tree type = TREE_TYPE (prev_value);\n-\t\t      bool pos = TYPE_UNSIGNED (type) || !di.is_negative ();\n-\t\t      if (!double_int_fits_to_tree_p (type, di))\n+\t\t      bool pos = !wi::neg_p (wi, sgn);\n+\t\t      if (!wi::fits_to_tree_p (wi, type))\n \t\t\t{\n \t\t\t  unsigned int itk;\n \t\t\t  for (itk = itk_int; itk != itk_none; itk++)\n \t\t\t    {\n \t\t\t      type = integer_types[itk];\n \t\t\t      if (type != NULL_TREE\n \t\t\t\t  && (pos || !TYPE_UNSIGNED (type))\n-\t\t\t\t  && double_int_fits_to_tree_p (type, di))\n+\t\t\t\t  && wi::fits_to_tree_p (wi, type))\n \t\t\t\tbreak;\n \t\t\t    }\n \t\t\t  if (type && cxx_dialect < cxx11\n@@ -12914,7 +12914,7 @@ incremented enumerator value is too large for %<long%>\");\n \t\t      if (type == NULL_TREE)\n \t\t\toverflowed = true;\n \t\t      else\n-\t\t\tvalue = double_int_to_tree (type, di);\n+\t\t\tvalue = wide_int_to_tree (type, wi);\n \t\t    }\n \n \t\t  if (overflowed)"}, {"sha": "6838d2aadd057660d41e90f198e2d1a96f8931f3", "filename": "gcc/cp/init.c", "status": "modified", "additions": 22, "deletions": 24, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Finit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Finit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Finit.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -31,6 +31,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"flags.h\"\n #include \"target.h\"\n #include \"gimplify.h\"\n+#include \"wide-int.h\"\n \n static bool begin_init_stmts (tree *, tree *);\n static tree finish_init_stmts (bool, tree, tree);\n@@ -2284,10 +2285,10 @@ build_new_1 (vec<tree, va_gc> **placement, tree type, tree nelts,\n   /* For arrays, a bounds checks on the NELTS parameter. */\n   tree outer_nelts_check = NULL_TREE;\n   bool outer_nelts_from_type = false;\n-  double_int inner_nelts_count = double_int_one;\n+  offset_int inner_nelts_count = 1;\n   tree alloc_call, alloc_expr;\n   /* Size of the inner array elements. */\n-  double_int inner_size;\n+  offset_int inner_size;\n   /* The address returned by the call to \"operator new\".  This node is\n      a VAR_DECL and is therefore reusable.  */\n   tree alloc_node;\n@@ -2343,9 +2344,8 @@ build_new_1 (vec<tree, va_gc> **placement, tree type, tree nelts,\n       if (TREE_CODE (inner_nelts_cst) == INTEGER_CST)\n \t{\n \t  bool overflow;\n-\t  double_int result = TREE_INT_CST (inner_nelts_cst)\n-\t\t\t      .mul_with_sign (inner_nelts_count,\n-\t\t\t\t\t      false, &overflow);\n+\t  offset_int result = wi::mul (wi::to_offset (inner_nelts_cst),\n+\t\t\t\t       inner_nelts_count, SIGNED, &overflow);\n \t  if (overflow)\n \t    {\n \t      if (complain & tf_error)\n@@ -2456,42 +2456,40 @@ build_new_1 (vec<tree, va_gc> **placement, tree type, tree nelts,\n     {\n       /* Maximum available size in bytes.  Half of the address space\n \t minus the cookie size.  */\n-      double_int max_size\n-\t= double_int_one.llshift (TYPE_PRECISION (sizetype) - 1,\n-\t\t\t\t  HOST_BITS_PER_DOUBLE_INT);\n+      offset_int max_size\n+\t= wi::set_bit_in_zero <offset_int> (TYPE_PRECISION (sizetype) - 1);\n       /* Maximum number of outer elements which can be allocated. */\n-      double_int max_outer_nelts;\n+      offset_int max_outer_nelts;\n       tree max_outer_nelts_tree;\n \n       gcc_assert (TREE_CODE (size) == INTEGER_CST);\n       cookie_size = targetm.cxx.get_cookie_size (elt_type);\n       gcc_assert (TREE_CODE (cookie_size) == INTEGER_CST);\n-      gcc_checking_assert (TREE_INT_CST (cookie_size).ult (max_size));\n+      gcc_checking_assert (wi::ltu_p (wi::to_offset (cookie_size), max_size));\n       /* Unconditionally subtract the cookie size.  This decreases the\n \t maximum object size and is safe even if we choose not to use\n \t a cookie after all.  */\n-      max_size -= TREE_INT_CST (cookie_size);\n+      max_size -= wi::to_offset (cookie_size);\n       bool overflow;\n-      inner_size = TREE_INT_CST (size)\n-\t\t   .mul_with_sign (inner_nelts_count, false, &overflow);\n-      if (overflow || inner_size.ugt (max_size))\n+      inner_size = wi::mul (wi::to_offset (size), inner_nelts_count, SIGNED,\n+\t\t\t    &overflow);\n+      if (overflow || wi::gtu_p (inner_size, max_size))\n \t{\n \t  if (complain & tf_error)\n \t    error (\"size of array is too large\");\n \t  return error_mark_node;\n \t}\n-      max_outer_nelts = max_size.udiv (inner_size, TRUNC_DIV_EXPR);\n+\n+      max_outer_nelts = wi::udiv_trunc (max_size, inner_size);\n       /* Only keep the top-most seven bits, to simplify encoding the\n \t constant in the instruction stream.  */\n       {\n-\tunsigned shift = HOST_BITS_PER_DOUBLE_INT - 7\n-\t  - (max_outer_nelts.high ? clz_hwi (max_outer_nelts.high)\n-\t     : (HOST_BITS_PER_WIDE_INT + clz_hwi (max_outer_nelts.low)));\n-\tmax_outer_nelts\n-\t  = max_outer_nelts.lrshift (shift, HOST_BITS_PER_DOUBLE_INT)\n-\t    .llshift (shift, HOST_BITS_PER_DOUBLE_INT);\n+\tunsigned shift = (max_outer_nelts.get_precision ()) - 7\n+\t  - wi::clz (max_outer_nelts);\n+\tmax_outer_nelts = wi::lshift (wi::lrshift (max_outer_nelts, shift),\n+\t\t\t\t      shift);\n       }\n-      max_outer_nelts_tree = double_int_to_tree (sizetype, max_outer_nelts);\n+      max_outer_nelts_tree = wide_int_to_tree (sizetype, max_outer_nelts);\n \n       size = size_binop (MULT_EXPR, size, convert (sizetype, nelts));\n       outer_nelts_check = fold_build2 (LE_EXPR, boolean_type_node,\n@@ -2572,7 +2570,7 @@ build_new_1 (vec<tree, va_gc> **placement, tree type, tree nelts,\n \t      cookie_size = NULL_TREE;\n \t      /* No size arithmetic necessary, so the size check is\n \t\t not needed. */\n-\t      if (outer_nelts_check != NULL && inner_size.is_one ())\n+\t      if (outer_nelts_check != NULL && inner_size == 1)\n \t\touter_nelts_check = NULL_TREE;\n \t    }\n \t  /* Perform the overflow check.  */\n@@ -2617,7 +2615,7 @@ build_new_1 (vec<tree, va_gc> **placement, tree type, tree nelts,\n \t      cookie_size = NULL_TREE;\n \t      /* No size arithmetic necessary, so the size check is\n \t\t not needed. */\n-\t      if (outer_nelts_check != NULL && inner_size.is_one ())\n+\t      if (outer_nelts_check != NULL && inner_size == 1)\n \t\touter_nelts_check = NULL_TREE;\n \t    }\n "}, {"sha": "97fb4c6ec3cab3fd3612ead5bd01b865b97ea0e4", "filename": "gcc/cp/mangle.c", "status": "modified", "additions": 10, "deletions": 15, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fmangle.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Fmangle.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fmangle.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -57,6 +57,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"flags.h\"\n #include \"target.h\"\n #include \"cgraph.h\"\n+#include \"wide-int.h\"\n \n /* Debugging support.  */\n \n@@ -1513,8 +1514,8 @@ static inline void\n write_integer_cst (const tree cst)\n {\n   int sign = tree_int_cst_sgn (cst);\n-\n-  if (TREE_INT_CST_HIGH (cst) + (sign < 0))\n+  widest_int abs_value = wi::abs (wi::to_widest (cst));\n+  if (!wi::fits_uhwi_p (abs_value))\n     {\n       /* A bignum. We do this in chunks, each of which fits in a\n \t HOST_WIDE_INT.  */\n@@ -1540,8 +1541,7 @@ write_integer_cst (const tree cst)\n \n       type = c_common_signed_or_unsigned_type (1, TREE_TYPE (cst));\n       base = build_int_cstu (type, chunk);\n-      n = build_int_cst_wide (type,\n-\t\t\t      TREE_INT_CST_LOW (cst), TREE_INT_CST_HIGH (cst));\n+      n = wide_int_to_tree (type, cst);\n \n       if (sign < 0)\n \t{\n@@ -1568,14 +1568,9 @@ write_integer_cst (const tree cst)\n   else\n     {\n       /* A small num.  */\n-      unsigned HOST_WIDE_INT low = TREE_INT_CST_LOW (cst);\n-\n       if (sign < 0)\n-\t{\n-\t  write_char ('n');\n-\t  low = -low;\n-\t}\n-      write_unsigned_number (low);\n+\twrite_char ('n');\n+      write_unsigned_number (abs_value.to_uhwi ());\n     }\n }\n \n@@ -3226,12 +3221,12 @@ write_array_type (const tree type)\n \t{\n \t  /* The ABI specifies that we should mangle the number of\n \t     elements in the array, not the largest allowed index.  */\n-\t  double_int dmax = tree_to_double_int (max) + double_int_one;\n+\t  offset_int wmax = wi::to_offset (max) + 1;\n \t  /* Truncate the result - this will mangle [0, SIZE_INT_MAX]\n \t     number of elements as zero.  */\n-\t  dmax = dmax.zext (TYPE_PRECISION (TREE_TYPE (max)));\n-\t  gcc_assert (dmax.fits_uhwi ());\n-\t  write_unsigned_number (dmax.low);\n+\t  wmax = wi::zext (wmax, TYPE_PRECISION (TREE_TYPE (max)));\n+\t  gcc_assert (wi::fits_uhwi_p (wmax));\n+\t  write_unsigned_number (wmax.to_uhwi ());\n \t}\n       else\n \t{"}, {"sha": "e14002482be3e1e0a15424dc242ce7f7e7393d50", "filename": "gcc/cp/tree.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Ftree.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -36,6 +36,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"hash-table.h\"\n #include \"gimple-expr.h\"\n #include \"gimplify.h\"\n+#include \"wide-int.h\"\n \n static tree bot_manip (tree *, int *, void *);\n static tree bot_replace (tree *, int *, void *);\n@@ -2620,8 +2621,7 @@ cp_tree_equal (tree t1, tree t2)\n   switch (code1)\n     {\n     case INTEGER_CST:\n-      return TREE_INT_CST_LOW (t1) == TREE_INT_CST_LOW (t2)\n-\t&& TREE_INT_CST_HIGH (t1) == TREE_INT_CST_HIGH (t2);\n+      return tree_int_cst_equal (t1, t2);\n \n     case REAL_CST:\n       return REAL_VALUES_EQUAL (TREE_REAL_CST (t1), TREE_REAL_CST (t2));"}, {"sha": "1d8b78278bf00ce355ec7cc5fe8f12d6248b3a1b", "filename": "gcc/cp/typeck2.c", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Ftypeck2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcp%2Ftypeck2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Ftypeck2.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -36,6 +36,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"cp-tree.h\"\n #include \"flags.h\"\n #include \"diagnostic-core.h\"\n+#include \"wide-int.h\"\n \n static tree\n process_init_constructor (tree type, tree init, tsubst_flags_t complain);\n@@ -1165,12 +1166,10 @@ process_init_constructor_array (tree type, tree init,\n     {\n       tree domain = TYPE_DOMAIN (type);\n       if (domain && TREE_CONSTANT (TYPE_MAX_VALUE (domain)))\n-\tlen = (tree_to_double_int (TYPE_MAX_VALUE (domain))\n-\t       - tree_to_double_int (TYPE_MIN_VALUE (domain))\n-\t       + double_int_one)\n-\t      .ext (TYPE_PRECISION (TREE_TYPE (domain)),\n-\t\t    TYPE_UNSIGNED (TREE_TYPE (domain)))\n-\t      .low;\n+\tlen = wi::ext (wi::to_offset (TYPE_MAX_VALUE (domain))\n+\t\t       - wi::to_offset (TYPE_MIN_VALUE (domain)) + 1,\n+\t\t       TYPE_PRECISION (TREE_TYPE (domain)),\n+\t\t       TYPE_SIGN (TREE_TYPE (domain))).to_uhwi ();\n       else\n \tunbounded = true;  /* Take as many as there are.  */\n     }"}, {"sha": "3ca8e179757555ae25defcd35c8464eb87beee07", "filename": "gcc/cse.c", "status": "modified", "additions": 9, "deletions": 3, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2336,15 +2336,20 @@ hash_rtx_cb (const_rtx x, enum machine_mode mode,\n                + (unsigned int) INTVAL (x));\n       return hash;\n \n+    case CONST_WIDE_INT:\n+      for (i = 0; i < CONST_WIDE_INT_NUNITS (x); i++)\n+\thash += CONST_WIDE_INT_ELT (x, i);\n+      return hash;\n+\n     case CONST_DOUBLE:\n       /* This is like the general case, except that it only counts\n \t the integers representing the constant.  */\n       hash += (unsigned int) code + (unsigned int) GET_MODE (x);\n-      if (GET_MODE (x) != VOIDmode)\n-\thash += real_hash (CONST_DOUBLE_REAL_VALUE (x));\n-      else\n+      if (TARGET_SUPPORTS_WIDE_INT == 0 && GET_MODE (x) == VOIDmode)\n \thash += ((unsigned int) CONST_DOUBLE_LOW (x)\n \t\t + (unsigned int) CONST_DOUBLE_HIGH (x));\n+      else\n+\thash += real_hash (CONST_DOUBLE_REAL_VALUE (x));\n       return hash;\n \n     case CONST_FIXED:\n@@ -3779,6 +3784,7 @@ equiv_constant (rtx x)\n \n       /* See if we previously assigned a constant value to this SUBREG.  */\n       if ((new_rtx = lookup_as_function (x, CONST_INT)) != 0\n+\t  || (new_rtx = lookup_as_function (x, CONST_WIDE_INT)) != 0\n           || (new_rtx = lookup_as_function (x, CONST_DOUBLE)) != 0\n           || (new_rtx = lookup_as_function (x, CONST_FIXED)) != 0)\n         return new_rtx;"}, {"sha": "00a04baab6e70655761792bc343ea73250120261", "filename": "gcc/cselib.c", "status": "modified", "additions": 9, "deletions": 5, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcselib.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fcselib.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcselib.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -942,8 +942,7 @@ rtx_equal_for_cselib_1 (rtx x, rtx y, enum machine_mode memmode)\n   /* These won't be handled correctly by the code below.  */\n   switch (GET_CODE (x))\n     {\n-    case CONST_DOUBLE:\n-    case CONST_FIXED:\n+    CASE_CONST_UNIQUE:\n     case DEBUG_EXPR:\n       return 0;\n \n@@ -1125,15 +1124,20 @@ cselib_hash_rtx (rtx x, int create, enum machine_mode memmode)\n       hash += ((unsigned) CONST_INT << 7) + UINTVAL (x);\n       return hash ? hash : (unsigned int) CONST_INT;\n \n+    case CONST_WIDE_INT:\n+      for (i = 0; i < CONST_WIDE_INT_NUNITS (x); i++)\n+\thash += CONST_WIDE_INT_ELT (x, i);\n+      return hash;\n+\n     case CONST_DOUBLE:\n       /* This is like the general case, except that it only counts\n \t the integers representing the constant.  */\n       hash += (unsigned) code + (unsigned) GET_MODE (x);\n-      if (GET_MODE (x) != VOIDmode)\n-\thash += real_hash (CONST_DOUBLE_REAL_VALUE (x));\n-      else\n+      if (TARGET_SUPPORTS_WIDE_INT == 0 && GET_MODE (x) == VOIDmode)\n \thash += ((unsigned) CONST_DOUBLE_LOW (x)\n \t\t + (unsigned) CONST_DOUBLE_HIGH (x));\n+      else\n+\thash += real_hash (CONST_DOUBLE_REAL_VALUE (x));\n       return hash ? hash : (unsigned int) CONST_DOUBLE;\n \n     case CONST_FIXED:"}, {"sha": "e6c98850063f2b994a31bae592be3b192bfbee6e", "filename": "gcc/dbxout.c", "status": "modified", "additions": 23, "deletions": 75, "changes": 98, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdbxout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdbxout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdbxout.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -692,88 +692,39 @@ stabstr_U (unsigned HOST_WIDE_INT num)\n static void\n stabstr_O (tree cst)\n {\n-  unsigned HOST_WIDE_INT high = TREE_INT_CST_HIGH (cst);\n-  unsigned HOST_WIDE_INT low = TREE_INT_CST_LOW (cst);\n-\n-  char buf[128];\n-  char *p = buf + sizeof buf;\n-\n-  /* GDB wants constants with no extra leading \"1\" bits, so\n-     we need to remove any sign-extension that might be\n-     present.  */\n-  {\n-    const unsigned int width = TYPE_PRECISION (TREE_TYPE (cst));\n-    if (width == HOST_BITS_PER_DOUBLE_INT)\n-      ;\n-    else if (width > HOST_BITS_PER_WIDE_INT)\n-      high &= (((HOST_WIDE_INT) 1 << (width - HOST_BITS_PER_WIDE_INT)) - 1);\n-    else if (width == HOST_BITS_PER_WIDE_INT)\n-      high = 0;\n-    else\n-      high = 0, low &= (((HOST_WIDE_INT) 1 << width) - 1);\n-  }\n+  int prec = TYPE_PRECISION (TREE_TYPE (cst));\n+  int res_pres = prec % 3;\n+  int i;\n+  unsigned int digit;\n \n   /* Leading zero for base indicator.  */\n   stabstr_C ('0');\n \n   /* If the value is zero, the base indicator will serve as the value\n      all by itself.  */\n-  if (high == 0 && low == 0)\n+  if (wi::eq_p (cst, 0))\n     return;\n \n-  /* If the high half is zero, we need only print the low half normally.  */\n-  if (high == 0)\n-    NUMBER_FMT_LOOP (p, low, 8);\n-  else\n+  /* GDB wants constants with no extra leading \"1\" bits, so\n+     we need to remove any sign-extension that might be\n+     present.  */\n+  if (res_pres == 1)\n     {\n-      /* When high != 0, we need to print enough zeroes from low to\n-\t give the digits from high their proper place-values.  Hence\n-\t NUMBER_FMT_LOOP cannot be used.  */\n-      const int n_digits = HOST_BITS_PER_WIDE_INT / 3;\n-      int i;\n-\n-      for (i = 1; i <= n_digits; i++)\n-\t{\n-\t  unsigned int digit = low % 8;\n-\t  low /= 8;\n-\t  *--p = '0' + digit;\n-\t}\n-\n-      /* Octal digits carry exactly three bits of information.  The\n-\t width of a HOST_WIDE_INT is not normally a multiple of three.\n-\t Therefore, the next digit printed probably needs to carry\n-\t information from both low and high.  */\n-      if (HOST_BITS_PER_WIDE_INT % 3 != 0)\n-\t{\n-\t  const int n_leftover_bits = HOST_BITS_PER_WIDE_INT % 3;\n-\t  const int n_bits_from_high = 3 - n_leftover_bits;\n-\n-\t  const unsigned HOST_WIDE_INT\n-\t    low_mask = (((unsigned HOST_WIDE_INT)1) << n_leftover_bits) - 1;\n-\t  const unsigned HOST_WIDE_INT\n-\t    high_mask = (((unsigned HOST_WIDE_INT)1) << n_bits_from_high) - 1;\n-\n-\t  unsigned int digit;\n-\n-\t  /* At this point, only the bottom n_leftover_bits bits of low\n-\t     should be set.  */\n-\t  gcc_assert (!(low & ~low_mask));\n-\n-\t  digit = (low | ((high & high_mask) << n_leftover_bits));\n-\t  high >>= n_bits_from_high;\n-\n-\t  *--p = '0' + digit;\n-\t}\n-\n-      /* Now we can format high in the normal manner.  However, if\n-\t the only bits of high that were set were handled by the\n-\t digit split between low and high, high will now be zero, and\n-\t we don't want to print extra digits in that case.  */\n-      if (high)\n-\tNUMBER_FMT_LOOP (p, high, 8);\n+      digit = wi::extract_uhwi (cst, prec - 1, 1);\n+      stabstr_C ('0' + digit);\n+    }\n+  else if (res_pres == 2)\n+    {\n+      digit = wi::extract_uhwi (cst, prec - 2, 2);\n+      stabstr_C ('0' + digit);\n     }\n \n-  obstack_grow (&stabstr_ob, p, (buf + sizeof buf) - p);\n+  prec -= res_pres;\n+  for (i = prec - 3; i >= 0; i = i - 3)\n+    {\n+      digit = wi::extract_uhwi (cst, i, 3);\n+      stabstr_C ('0' + digit);\n+    }\n }\n \n /* Called whenever it is safe to break a stabs string into multiple\n@@ -2301,10 +2252,7 @@ dbxout_type (tree type, int full)\n           if (TREE_CODE (value) == CONST_DECL)\n             value = DECL_INITIAL (value);\n \n-\t  if (TREE_INT_CST_HIGH (value) == 0)\n-\t    stabstr_D (TREE_INT_CST_LOW (value));\n-\t  else if (TREE_INT_CST_HIGH (value) == -1\n-\t\t   && (HOST_WIDE_INT) TREE_INT_CST_LOW (value) < 0)\n+\t  if (cst_and_fits_in_hwi (value))\n \t    stabstr_D (TREE_INT_CST_LOW (value));\n \t  else\n \t    stabstr_O (value);"}, {"sha": "8d89a751b7521777ae5ad9f16025be395ddb6e80", "filename": "gcc/defaults.h", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdefaults.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdefaults.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdefaults.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -471,6 +471,14 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n    your target, you should override these values by defining the\n    appropriate symbols in your tm.h file.  */\n \n+#if BITS_PER_UNIT == 8\n+#define LOG2_BITS_PER_UNIT 3\n+#elif BITS_PER_UNIT == 16\n+#define LOG2_BITS_PER_UNIT 4\n+#else\n+#error Unknown BITS_PER_UNIT\n+#endif\n+\n #ifndef BITS_PER_WORD\n #define BITS_PER_WORD (BITS_PER_UNIT * UNITS_PER_WORD)\n #endif\n@@ -1392,6 +1400,14 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n #define SWITCHABLE_TARGET 0\n #endif\n \n+/* If the target supports integers that are wider than two\n+   HOST_WIDE_INTs on the host compiler, then the target should define\n+   TARGET_SUPPORTS_WIDE_INT and make the appropriate fixups.\n+   Otherwise the compiler really is not robust.  */\n+#ifndef TARGET_SUPPORTS_WIDE_INT\n+#define TARGET_SUPPORTS_WIDE_INT 0\n+#endif\n+\n #endif /* GCC_INSN_FLAGS_H  */\n \n #endif  /* ! GCC_DEFAULTS_H */"}, {"sha": "8e798288acbb0f73747d16e58a171b64e295c6eb", "filename": "gcc/dfp.c", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdfp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdfp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdfp.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -24,6 +24,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree.h\"\n #include \"tm_p.h\"\n #include \"dfp.h\"\n+#include \"wide-int.h\"\n \n /* The order of the following headers is important for making sure\n    decNumber structure is large enough to hold decimal128 digits.  */\n@@ -604,11 +605,11 @@ decimal_real_to_integer (const REAL_VALUE_TYPE *r)\n   return real_to_integer (&to);\n }\n \n-/* Likewise, but to an integer pair, HI+LOW.  */\n+/* Likewise, but returns a wide_int with PRECISION.  *FAIL is set if the\n+   value does not fit.  */\n \n-void\n-decimal_real_to_integer2 (HOST_WIDE_INT *plow, HOST_WIDE_INT *phigh,\n-\t\t\t  const REAL_VALUE_TYPE *r)\n+wide_int\n+decimal_real_to_integer (const REAL_VALUE_TYPE *r, bool *fail, int precision)\n {\n   decContext set;\n   decNumber dn, dn2, dn3;\n@@ -628,7 +629,7 @@ decimal_real_to_integer2 (HOST_WIDE_INT *plow, HOST_WIDE_INT *phigh,\n      function.  */\n   decNumberToString (&dn, string);\n   real_from_string (&to, string);\n-  real_to_integer2 (plow, phigh, &to);\n+  return real_to_integer (&to, fail, precision);\n }\n \n /* Perform the decimal floating point operation described by CODE."}, {"sha": "bf8c051a203ea73f0b471dd64cab0b4f25c4b50e", "filename": "gcc/dfp.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdfp.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdfp.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdfp.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -38,7 +38,7 @@ void decimal_real_convert (REAL_VALUE_TYPE *, enum machine_mode, const REAL_VALU\n void decimal_real_to_decimal (char *, const REAL_VALUE_TYPE *, size_t, size_t, int);\n void decimal_do_fix_trunc (REAL_VALUE_TYPE *, const REAL_VALUE_TYPE *);\n void decimal_real_maxval (REAL_VALUE_TYPE *, int, enum machine_mode);\n-void decimal_real_to_integer2 (HOST_WIDE_INT *, HOST_WIDE_INT *, const REAL_VALUE_TYPE *);\n+wide_int decimal_real_to_integer (const REAL_VALUE_TYPE *, bool *, int);\n HOST_WIDE_INT decimal_real_to_integer (const REAL_VALUE_TYPE *);\n \n #ifdef TREE_CODE"}, {"sha": "7afb055f8cbba897c0779244b90d7c78ac0dca8b", "filename": "gcc/doc/generic.texi", "status": "modified", "additions": 19, "deletions": 32, "changes": 51, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Fgeneric.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Fgeneric.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fgeneric.texi?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1022,10 +1022,15 @@ As this example indicates, the operands are zero-indexed.\n @node Constant expressions\n @subsection Constant expressions\n @tindex INTEGER_CST\n-@findex TREE_INT_CST_HIGH\n-@findex TREE_INT_CST_LOW\n @findex tree_int_cst_lt\n @findex tree_int_cst_equal\n+@tindex tree_fits_uhwi_p\n+@tindex tree_fits_shwi_p\n+@tindex tree_to_uhwi\n+@tindex tree_to_shwi\n+@tindex TREE_INT_CST_NUNITS\n+@tindex TREE_INT_CST_ELT\n+@tindex TREE_INT_CST_LOW\n @tindex REAL_CST\n @tindex FIXED_CST\n @tindex COMPLEX_CST\n@@ -1044,36 +1049,18 @@ These nodes represent integer constants.  Note that the type of these\n constants is obtained with @code{TREE_TYPE}; they are not always of type\n @code{int}.  In particular, @code{char} constants are represented with\n @code{INTEGER_CST} nodes.  The value of the integer constant @code{e} is\n-given by\n-@smallexample\n-((TREE_INT_CST_HIGH (e) << HOST_BITS_PER_WIDE_INT)\n-+ TREE_INST_CST_LOW (e))\n-@end smallexample\n-@noindent\n-HOST_BITS_PER_WIDE_INT is at least thirty-two on all platforms.  Both\n-@code{TREE_INT_CST_HIGH} and @code{TREE_INT_CST_LOW} return a\n-@code{HOST_WIDE_INT}.  The value of an @code{INTEGER_CST} is interpreted\n-as a signed or unsigned quantity depending on the type of the constant.\n-In general, the expression given above will overflow, so it should not\n-be used to calculate the value of the constant.\n-\n-The variable @code{integer_zero_node} is an integer constant with value\n-zero.  Similarly, @code{integer_one_node} is an integer constant with\n-value one.  The @code{size_zero_node} and @code{size_one_node} variables\n-are analogous, but have type @code{size_t} rather than @code{int}.\n-\n-The function @code{tree_int_cst_lt} is a predicate which holds if its\n-first argument is less than its second.  Both constants are assumed to\n-have the same signedness (i.e., either both should be signed or both\n-should be unsigned.)  The full width of the constant is used when doing\n-the comparison; the usual rules about promotions and conversions are\n-ignored.  Similarly, @code{tree_int_cst_equal} holds if the two\n-constants are equal.  The @code{tree_int_cst_sgn} function returns the\n-sign of a constant.  The value is @code{1}, @code{0}, or @code{-1}\n-according on whether the constant is greater than, equal to, or less\n-than zero.  Again, the signedness of the constant's type is taken into\n-account; an unsigned constant is never less than zero, no matter what\n-its bit-pattern.\n+represented in an array of HOST_WIDE_INT.   There are enough elements\n+in the array to represent the value without taking extra elements for\n+redundant 0s or -1.  The number of elements used to represent @code{e}\n+is available via @code{TREE_INT_CST_NUNITS}. Element @code{i} can be\n+extracted by using @code{TREE_INT_CST_ELT (e, i)}.\n+@code{TREE_INT_CST_LOW} is a shorthand for @code{TREE_INT_CST_ELT (e, 0)}.\n+\n+The functions @code{tree_fits_shwi_p} and @code{tree_fits_uhwi_p}\n+can be used to tell if the value is small enough to fit in a\n+signed HOST_WIDE_INT or an unsigned HOST_WIDE_INT respectively.\n+The value can then be extracted using @code{tree_to_shwi} and\n+@code{tree_to_uhwi}.\n \n @item REAL_CST\n "}, {"sha": "605a5a18734d01c8a3ef1fa1b2878222f0a7cc13", "filename": "gcc/doc/rtl.texi", "status": "modified", "additions": 46, "deletions": 11, "changes": 57, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Frtl.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Frtl.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Frtl.texi?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1540,17 +1540,21 @@ Similarly, there is only one object for the integer whose value is\n \n @findex const_double\n @item (const_double:@var{m} @var{i0} @var{i1} @dots{})\n-Represents either a floating-point constant of mode @var{m} or an\n-integer constant too large to fit into @code{HOST_BITS_PER_WIDE_INT}\n-bits but small enough to fit within twice that number of bits (GCC\n-does not provide a mechanism to represent even larger constants).  In\n-the latter case, @var{m} will be @code{VOIDmode}.  For integral values\n-constants for modes with more bits than twice the number in\n-@code{HOST_WIDE_INT} the implied high order bits of that constant are\n-copies of the top bit of @code{CONST_DOUBLE_HIGH}.  Note however that\n-integral values are neither inherently signed nor inherently unsigned;\n-where necessary, signedness is determined by the rtl operation\n-instead.\n+This represents either a floating-point constant of mode @var{m} or\n+(on older ports that do not define\n+@code{TARGET_SUPPORTS_WIDE_INT}) an integer constant too large to fit\n+into @code{HOST_BITS_PER_WIDE_INT} bits but small enough to fit within\n+twice that number of bits.  In the latter case, @var{m} will be\n+@code{VOIDmode}.  For integral values constants for modes with more\n+bits than twice the number in @code{HOST_WIDE_INT} the implied high\n+order bits of that constant are copies of the top bit of\n+@code{CONST_DOUBLE_HIGH}.  Note however that integral values are\n+neither inherently signed nor inherently unsigned; where necessary,\n+signedness is determined by the rtl operation instead.\n+\n+On more modern ports, @code{CONST_DOUBLE} only represents floating\n+point values.  New ports define @code{TARGET_SUPPORTS_WIDE_INT} to\n+make this designation.\n \n @findex CONST_DOUBLE_LOW\n If @var{m} is @code{VOIDmode}, the bits of the value are stored in\n@@ -1565,6 +1569,37 @@ machine's or host machine's floating point format.  To convert them to\n the precise bit pattern used by the target machine, use the macro\n @code{REAL_VALUE_TO_TARGET_DOUBLE} and friends (@pxref{Data Output}).\n \n+@findex CONST_WIDE_INT\n+@item (const_wide_int:@var{m} @var{nunits} @var{elt0} @dots{})\n+This contains an array of @code{HOST_WIDE_INT}s that is large enough\n+to hold any constant that can be represented on the target.  This form\n+of rtl is only used on targets that define\n+@code{TARGET_SUPPORTS_WIDE_INT} to be nonzero and then\n+@code{CONST_DOUBLE}s are only used to hold floating-point values.  If\n+the target leaves @code{TARGET_SUPPORTS_WIDE_INT} defined as 0,\n+@code{CONST_WIDE_INT}s are not used and @code{CONST_DOUBLE}s are as\n+they were before.\n+\n+The values are stored in a compressed format.  The higher-order\n+0s or -1s are not represented if they are just the logical sign\n+extension of the number that is represented.\n+\n+@findex CONST_WIDE_INT_VEC\n+@item CONST_WIDE_INT_VEC (@var{code})\n+Returns the entire array of @code{HOST_WIDE_INT}s that are used to\n+store the value.  This macro should be rarely used.\n+\n+@findex CONST_WIDE_INT_NUNITS\n+@item CONST_WIDE_INT_NUNITS (@var{code})\n+The number of @code{HOST_WIDE_INT}s used to represent the number.\n+Note that this generally is smaller than the number of\n+@code{HOST_WIDE_INT}s implied by the mode size.\n+\n+@findex CONST_WIDE_INT_ELT\n+@item CONST_WIDE_INT_NUNITS (@var{code},@var{i})\n+Returns the @code{i}th element of the array.   Element 0 is contains\n+the low order bits of the constant.\n+\n @findex const_fixed\n @item (const_fixed:@var{m} @dots{})\n Represents a fixed-point constant of mode @var{m}."}, {"sha": "fd4e4fd6628b7227caa4054583fac9cf693db6e2", "filename": "gcc/doc/tm.texi", "status": "modified", "additions": 47, "deletions": 13, "changes": 60, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Ftm.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Ftm.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftm.texi?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -9704,18 +9704,6 @@ Returns the negative of the floating point value @var{x}.\n Returns the absolute value of @var{x}.\n @end deftypefn\n \n-@deftypefn Macro void REAL_VALUE_TO_INT (HOST_WIDE_INT @var{low}, HOST_WIDE_INT @var{high}, REAL_VALUE_TYPE @var{x})\n-Converts a floating point value @var{x} into a double-precision integer\n-which is then stored into @var{low} and @var{high}.  If the value is not\n-integral, it is truncated.\n-@end deftypefn\n-\n-@deftypefn Macro void REAL_VALUE_FROM_INT (REAL_VALUE_TYPE @var{x}, HOST_WIDE_INT @var{low}, HOST_WIDE_INT @var{high}, enum machine_mode @var{mode})\n-Converts a double-precision integer found in @var{low} and @var{high},\n-into a floating point value which is then stored into @var{x}.  The\n-value is truncated to fit in mode @var{mode}.\n-@end deftypefn\n-\n @node Mode Switching\n @section Mode Switching Instructions\n @cindex mode switching\n@@ -11024,7 +11012,7 @@ function version at run-time for a given set of function versions.\n body must be generated.\n @end deftypefn\n \n-@deftypefn {Target Hook} bool TARGET_CAN_USE_DOLOOP_P (double_int @var{iterations}, double_int @var{iterations_max}, unsigned int @var{loop_depth}, bool @var{entered_at_top})\n+@deftypefn {Target Hook} bool TARGET_CAN_USE_DOLOOP_P (const widest_int @var{&iterations}, const widest_int @var{&iterations_max}, unsigned int @var{loop_depth}, bool @var{entered_at_top})\n Return true if it is possible to use low-overhead loops (@code{doloop_end}\n and @code{doloop_begin}) for a particular loop.  @var{iterations} gives the\n exact number of iterations, or 0 if not known.  @var{iterations_max} gives\n@@ -11440,3 +11428,49 @@ If defined, this function returns an appropriate alignment in bits for an atomic\n @deftypefn {Target Hook} void TARGET_ATOMIC_ASSIGN_EXPAND_FENV (tree *@var{hold}, tree *@var{clear}, tree *@var{update})\n ISO C11 requires atomic compound assignments that may raise floating-point exceptions to raise exceptions corresponding to the arithmetic operation whose result was successfully stored in a compare-and-exchange sequence.  This requires code equivalent to calls to @code{feholdexcept}, @code{feclearexcept} and @code{feupdateenv} to be generated at appropriate points in the compare-and-exchange sequence.  This hook should set @code{*@var{hold}} to an expression equivalent to the call to @code{feholdexcept}, @code{*@var{clear}} to an expression equivalent to the call to @code{feclearexcept} and @code{*@var{update}} to an expression equivalent to the call to @code{feupdateenv}.  The three expressions are @code{NULL_TREE} on entry to the hook and may be left as @code{NULL_TREE} if no code is required in a particular place.  The default implementation leaves all three expressions as @code{NULL_TREE}.  The @code{__atomic_feraiseexcept} function from @code{libatomic} may be of use as part of the code generated in @code{*@var{update}}.\n @end deftypefn\n+\n+@defmac TARGET_SUPPORTS_WIDE_INT\n+\n+On older ports, large integers are stored in @code{CONST_DOUBLE} rtl\n+objects.  Newer ports define @code{TARGET_SUPPORTS_WIDE_INT} to be nonzero\n+to indicate that large integers are stored in\n+@code{CONST_WIDE_INT} rtl objects.  The @code{CONST_WIDE_INT} allows\n+very large integer constants to be represented.  @code{CONST_DOUBLE}\n+is limited to twice the size of the host's @code{HOST_WIDE_INT}\n+representation.\n+\n+Converting a port mostly requires looking for the places where\n+@code{CONST_DOUBLE}s are used with @code{VOIDmode} and replacing that\n+code with code that accesses @code{CONST_WIDE_INT}s.  @samp{\"grep -i\n+const_double\"} at the port level gets you to 95% of the changes that\n+need to be made.  There are a few places that require a deeper look.\n+\n+@itemize @bullet\n+@item\n+There is no equivalent to @code{hval} and @code{lval} for\n+@code{CONST_WIDE_INT}s.  This would be difficult to express in the md\n+language since there are a variable number of elements.\n+\n+Most ports only check that @code{hval} is either 0 or -1 to see if the\n+value is small.  As mentioned above, this will no longer be necessary\n+since small constants are always @code{CONST_INT}.  Of course there\n+are still a few exceptions, the alpha's constraint used by the zap\n+instruction certainly requires careful examination by C code.\n+However, all the current code does is pass the hval and lval to C\n+code, so evolving the c code to look at the @code{CONST_WIDE_INT} is\n+not really a large change.\n+\n+@item\n+Because there is no standard template that ports use to materialize\n+constants, there is likely to be some futzing that is unique to each\n+port in this code.\n+\n+@item\n+The rtx costs may have to be adjusted to properly account for larger\n+constants that are represented as @code{CONST_WIDE_INT}.\n+@end itemize\n+\n+All and all it does not take long to convert ports that the\n+maintainer is familiar with.\n+\n+@end defmac"}, {"sha": "9c030df6990ee09e14dd515998e28ae7e2833da7", "filename": "gcc/doc/tm.texi.in", "status": "modified", "additions": 46, "deletions": 12, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Ftm.texi.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdoc%2Ftm.texi.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftm.texi.in?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -7362,18 +7362,6 @@ Returns the negative of the floating point value @var{x}.\n Returns the absolute value of @var{x}.\n @end deftypefn\n \n-@deftypefn Macro void REAL_VALUE_TO_INT (HOST_WIDE_INT @var{low}, HOST_WIDE_INT @var{high}, REAL_VALUE_TYPE @var{x})\n-Converts a floating point value @var{x} into a double-precision integer\n-which is then stored into @var{low} and @var{high}.  If the value is not\n-integral, it is truncated.\n-@end deftypefn\n-\n-@deftypefn Macro void REAL_VALUE_FROM_INT (REAL_VALUE_TYPE @var{x}, HOST_WIDE_INT @var{low}, HOST_WIDE_INT @var{high}, enum machine_mode @var{mode})\n-Converts a double-precision integer found in @var{low} and @var{high},\n-into a floating point value which is then stored into @var{x}.  The\n-value is truncated to fit in mode @var{mode}.\n-@end deftypefn\n-\n @node Mode Switching\n @section Mode Switching Instructions\n @cindex mode switching\n@@ -8425,3 +8413,49 @@ and the associated definitions of those functions.\n @hook TARGET_ATOMIC_ALIGN_FOR_MODE\n \n @hook TARGET_ATOMIC_ASSIGN_EXPAND_FENV\n+\n+@defmac TARGET_SUPPORTS_WIDE_INT\n+\n+On older ports, large integers are stored in @code{CONST_DOUBLE} rtl\n+objects.  Newer ports define @code{TARGET_SUPPORTS_WIDE_INT} to be nonzero\n+to indicate that large integers are stored in\n+@code{CONST_WIDE_INT} rtl objects.  The @code{CONST_WIDE_INT} allows\n+very large integer constants to be represented.  @code{CONST_DOUBLE}\n+is limited to twice the size of the host's @code{HOST_WIDE_INT}\n+representation.\n+\n+Converting a port mostly requires looking for the places where\n+@code{CONST_DOUBLE}s are used with @code{VOIDmode} and replacing that\n+code with code that accesses @code{CONST_WIDE_INT}s.  @samp{\"grep -i\n+const_double\"} at the port level gets you to 95% of the changes that\n+need to be made.  There are a few places that require a deeper look.\n+\n+@itemize @bullet\n+@item\n+There is no equivalent to @code{hval} and @code{lval} for\n+@code{CONST_WIDE_INT}s.  This would be difficult to express in the md\n+language since there are a variable number of elements.\n+\n+Most ports only check that @code{hval} is either 0 or -1 to see if the\n+value is small.  As mentioned above, this will no longer be necessary\n+since small constants are always @code{CONST_INT}.  Of course there\n+are still a few exceptions, the alpha's constraint used by the zap\n+instruction certainly requires careful examination by C code.\n+However, all the current code does is pass the hval and lval to C\n+code, so evolving the c code to look at the @code{CONST_WIDE_INT} is\n+not really a large change.\n+\n+@item\n+Because there is no standard template that ports use to materialize\n+constants, there is likely to be some futzing that is unique to each\n+port in this code.\n+\n+@item\n+The rtx costs may have to be adjusted to properly account for larger\n+constants that are represented as @code{CONST_WIDE_INT}.\n+@end itemize\n+\n+All and all it does not take long to convert ports that the\n+maintainer is familiar with.\n+\n+@end defmac"}, {"sha": "174869001739413570d05fa8c9ddb9d635e617a7", "filename": "gcc/dojump.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdojump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdojump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdojump.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -166,6 +166,7 @@ static bool\n prefer_and_bit_test (enum machine_mode mode, int bitnum)\n {\n   bool speed_p;\n+  wide_int mask = wi::set_bit_in_zero (bitnum, GET_MODE_PRECISION (mode));\n \n   if (and_test == 0)\n     {\n@@ -186,8 +187,7 @@ prefer_and_bit_test (enum machine_mode mode, int bitnum)\n     }\n \n   /* Fill in the integers.  */\n-  XEXP (and_test, 1)\n-    = immed_double_int_const (double_int_zero.set_bit (bitnum), mode);\n+  XEXP (and_test, 1) = immed_wide_int_const (mask, mode);\n   XEXP (XEXP (shift_test, 0), 1) = GEN_INT (bitnum);\n \n   speed_p = optimize_insn_for_speed_p ();"}, {"sha": "a2b11ba8419eefdbfc12f7737c6f6de9fc549250", "filename": "gcc/double-int.h", "status": "modified", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdouble-int.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdouble-int.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdouble-int.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -20,6 +20,8 @@ along with GCC; see the file COPYING3.  If not see\n #ifndef DOUBLE_INT_H\n #define DOUBLE_INT_H\n \n+#include \"wide-int.h\"\n+\n /* A large integer is currently represented as a pair of HOST_WIDE_INTs.\n    It therefore represents a number with precision of\n    2 * HOST_BITS_PER_WIDE_INT bits (it is however possible that the\n@@ -435,4 +437,36 @@ void mpz_set_double_int (mpz_t, double_int, bool);\n double_int mpz_get_double_int (const_tree, mpz_t, bool);\n #endif\n \n+namespace wi\n+{\n+  template <>\n+  struct int_traits <double_int>\n+  {\n+    static const enum precision_type precision_type = CONST_PRECISION;\n+    static const bool host_dependent_precision = true;\n+    static const unsigned int precision = HOST_BITS_PER_DOUBLE_INT;\n+    static unsigned int get_precision (const double_int &);\n+    static wi::storage_ref decompose (HOST_WIDE_INT *, unsigned int,\n+\t\t\t\t      const double_int &);\n+  };\n+}\n+\n+inline unsigned int\n+wi::int_traits <double_int>::get_precision (const double_int &)\n+{\n+  return precision;\n+}\n+\n+inline wi::storage_ref\n+wi::int_traits <double_int>::decompose (HOST_WIDE_INT *scratch, unsigned int p,\n+\t\t\t\t\tconst double_int &x)\n+{\n+  gcc_checking_assert (precision == p);\n+  scratch[0] = x.low;\n+  if ((x.high == 0 && scratch[0] >= 0) || (x.high == -1 && scratch[0] < 0))\n+    return wi::storage_ref (scratch, 1, precision);\n+  scratch[1] = x.high;\n+  return wi::storage_ref (scratch, 2, precision);\n+}\n+\n #endif /* DOUBLE_INT_H */"}, {"sha": "5874d73821b31480a508ac02017296a7c100e8fd", "filename": "gcc/dwarf2out.c", "status": "modified", "additions": 270, "deletions": 89, "changes": 359, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdwarf2out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdwarf2out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdwarf2out.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -357,6 +357,16 @@ dump_struct_debug (tree type, enum debug_info_usage usage,\n \n #endif\n \n+/* Get the number of HOST_WIDE_INTs needed to represent the precision\n+   of the number.  */\n+\n+static unsigned int\n+get_full_len (const wide_int &op)\n+{\n+  return ((op.get_precision () + HOST_BITS_PER_WIDE_INT - 1)\n+\t  / HOST_BITS_PER_WIDE_INT);\n+}\n+\n static bool\n should_emit_struct_debug (tree type, enum debug_info_usage usage)\n {\n@@ -1392,6 +1402,9 @@ dw_val_equal_p (dw_val_node *a, dw_val_node *b)\n       return (a->v.val_double.high == b->v.val_double.high\n \t      && a->v.val_double.low == b->v.val_double.low);\n \n+    case dw_val_class_wide_int:\n+      return *a->v.val_wide == *b->v.val_wide;\n+\n     case dw_val_class_vec:\n       {\n \tsize_t a_len = a->v.val_vec.elt_size * a->v.val_vec.length;\n@@ -1648,6 +1661,10 @@ size_of_loc_descr (dw_loc_descr_ref loc)\n \t  case dw_val_class_const_double:\n \t    size += HOST_BITS_PER_DOUBLE_INT / BITS_PER_UNIT;\n \t    break;\n+\t  case dw_val_class_wide_int:\n+\t    size += (get_full_len (*loc->dw_loc_oprnd2.v.val_wide)\n+\t\t     * HOST_BITS_PER_WIDE_INT / BITS_PER_UNIT);\n+\t    break;\n \t  default:\n \t    gcc_unreachable ();\n \t  }\n@@ -1825,6 +1842,20 @@ output_loc_operands (dw_loc_descr_ref loc, int for_eh_or_skip)\n \t\t\t\t second, NULL);\n \t  }\n \t  break;\n+\tcase dw_val_class_wide_int:\n+\t  {\n+\t    int i;\n+\t    int len = get_full_len (*val2->v.val_wide);\n+\t    if (WORDS_BIG_ENDIAN)\n+\t      for (i = len - 1; i >= 0; --i)\n+\t\tdw2_asm_output_data (HOST_BITS_PER_WIDE_INT / HOST_BITS_PER_CHAR,\n+\t\t\t\t     val2->v.val_wide->elt (i), NULL);\n+\t    else\n+\t      for (i = 0; i < len; ++i)\n+\t\tdw2_asm_output_data (HOST_BITS_PER_WIDE_INT / HOST_BITS_PER_CHAR,\n+\t\t\t\t     val2->v.val_wide->elt (i), NULL);\n+\t  }\n+\t  break;\n \tcase dw_val_class_addr:\n \t  gcc_assert (val1->v.val_unsigned == DWARF2_ADDR_SIZE);\n \t  dw2_asm_output_addr_rtx (DWARF2_ADDR_SIZE, val2->v.val_addr, NULL);\n@@ -2034,6 +2065,21 @@ output_loc_operands (dw_loc_descr_ref loc, int for_eh_or_skip)\n \t      dw2_asm_output_data (l, second, NULL);\n \t    }\n \t    break;\n+\t  case dw_val_class_wide_int:\n+\t    {\n+\t      int i;\n+\t      int len = get_full_len (*val2->v.val_wide);\n+\t      l = HOST_BITS_PER_WIDE_INT / HOST_BITS_PER_CHAR;\n+\n+\t      dw2_asm_output_data (1, len * l, NULL);\n+\t      if (WORDS_BIG_ENDIAN)\n+\t\tfor (i = len - 1; i >= 0; --i)\n+\t\t  dw2_asm_output_data (l, val2->v.val_wide->elt (i), NULL);\n+\t      else\n+\t\tfor (i = 0; i < len; ++i)\n+\t\t  dw2_asm_output_data (l, val2->v.val_wide->elt (i), NULL);\n+\t    }\n+\t    break;\n \t  default:\n \t    gcc_unreachable ();\n \t  }\n@@ -3126,7 +3172,7 @@ static void add_AT_location_description\t(dw_die_ref, enum dwarf_attribute,\n static void add_data_member_location_attribute (dw_die_ref, tree);\n static bool add_const_value_attribute (dw_die_ref, rtx);\n static void insert_int (HOST_WIDE_INT, unsigned, unsigned char *);\n-static void insert_double (double_int, unsigned char *);\n+static void insert_wide_int (const wide_int &, unsigned char *, int);\n static void insert_float (const_rtx, unsigned char *);\n static rtx rtl_for_decl_location (tree);\n static bool add_location_or_const_value_attribute (dw_die_ref, tree, bool,\n@@ -3758,6 +3804,21 @@ AT_unsigned (dw_attr_ref a)\n   return a->dw_attr_val.v.val_unsigned;\n }\n \n+/* Add an unsigned wide integer attribute value to a DIE.  */\n+\n+static inline void\n+add_AT_wide (dw_die_ref die, enum dwarf_attribute attr_kind,\n+\t     const wide_int& w)\n+{\n+  dw_attr_node attr;\n+\n+  attr.dw_attr = attr_kind;\n+  attr.dw_attr_val.val_class = dw_val_class_wide_int;\n+  attr.dw_attr_val.v.val_wide = ggc_alloc_cleared_wide_int ();\n+  *attr.dw_attr_val.v.val_wide = w;\n+  add_dwarf_attr (die, &attr);\n+}\n+\n /* Add an unsigned double integer attribute value to a DIE.  */\n \n static inline void\n@@ -5332,6 +5393,21 @@ print_die (dw_die_ref die, FILE *outfile)\n \t\t   a->dw_attr_val.v.val_double.high,\n \t\t   a->dw_attr_val.v.val_double.low);\n \t  break;\n+\tcase dw_val_class_wide_int:\n+\t  {\n+\t    int i = a->dw_attr_val.v.val_wide->get_len ();\n+\t    fprintf (outfile, \"constant (\");\n+\t    gcc_assert (i > 0);\n+\t    if (a->dw_attr_val.v.val_wide->elt (i - 1) == 0)\n+\t      fprintf (outfile, \"0x\");\n+\t    fprintf (outfile, HOST_WIDE_INT_PRINT_HEX,\n+\t\t     a->dw_attr_val.v.val_wide->elt (--i));\n+\t    while (--i >= 0)\n+\t      fprintf (outfile, HOST_WIDE_INT_PRINT_PADDED_HEX,\n+\t\t       a->dw_attr_val.v.val_wide->elt (i));\n+\t    fprintf (outfile, \")\");\n+\t    break;\n+\t  }\n \tcase dw_val_class_vec:\n \t  fprintf (outfile, \"floating-point or vector constant\");\n \t  break;\n@@ -5505,6 +5581,9 @@ attr_checksum (dw_attr_ref at, struct md5_ctx *ctx, int *mark)\n     case dw_val_class_const_double:\n       CHECKSUM (at->dw_attr_val.v.val_double);\n       break;\n+    case dw_val_class_wide_int:\n+      CHECKSUM (*at->dw_attr_val.v.val_wide);\n+      break;\n     case dw_val_class_vec:\n       CHECKSUM_BLOCK (at->dw_attr_val.v.val_vec.array,\n \t\t      (at->dw_attr_val.v.val_vec.length\n@@ -5782,6 +5861,12 @@ attr_checksum_ordered (enum dwarf_tag tag, dw_attr_ref at,\n       CHECKSUM (at->dw_attr_val.v.val_double);\n       break;\n \n+    case dw_val_class_wide_int:\n+      CHECKSUM_ULEB128 (DW_FORM_block);\n+      CHECKSUM_ULEB128 (sizeof (*at->dw_attr_val.v.val_wide));\n+      CHECKSUM (*at->dw_attr_val.v.val_wide);\n+      break;\n+\n     case dw_val_class_vec:\n       CHECKSUM_ULEB128 (DW_FORM_block);\n       CHECKSUM_ULEB128 (at->dw_attr_val.v.val_vec.length\n@@ -6264,6 +6349,8 @@ same_dw_val_p (const dw_val_node *v1, const dw_val_node *v2, int *mark)\n     case dw_val_class_const_double:\n       return v1->v.val_double.high == v2->v.val_double.high\n \t     && v1->v.val_double.low == v2->v.val_double.low;\n+    case dw_val_class_wide_int:\n+      return *v1->v.val_wide == *v2->v.val_wide;\n     case dw_val_class_vec:\n       if (v1->v.val_vec.length != v2->v.val_vec.length\n \t  || v1->v.val_vec.elt_size != v2->v.val_vec.elt_size)\n@@ -7819,6 +7906,13 @@ size_of_die (dw_die_ref die)\n \t  if (HOST_BITS_PER_WIDE_INT >= 64)\n \t    size++; /* block */\n \t  break;\n+\tcase dw_val_class_wide_int:\n+\t  size += (get_full_len (*a->dw_attr_val.v.val_wide)\n+\t\t   * HOST_BITS_PER_WIDE_INT / HOST_BITS_PER_CHAR);\n+\t  if (get_full_len (*a->dw_attr_val.v.val_wide) * HOST_BITS_PER_WIDE_INT\n+\t      > 64)\n+\t    size++; /* block */\n+\t  break;\n \tcase dw_val_class_vec:\n \t  size += constant_size (a->dw_attr_val.v.val_vec.length\n \t\t\t\t * a->dw_attr_val.v.val_vec.elt_size)\n@@ -8188,6 +8282,20 @@ value_format (dw_attr_ref a)\n \tdefault:\n \t  return DW_FORM_block1;\n \t}\n+    case dw_val_class_wide_int:\n+      switch (get_full_len (*a->dw_attr_val.v.val_wide) * HOST_BITS_PER_WIDE_INT)\n+\t{\n+\tcase 8:\n+\t  return DW_FORM_data1;\n+\tcase 16:\n+\t  return DW_FORM_data2;\n+\tcase 32:\n+\t  return DW_FORM_data4;\n+\tcase 64:\n+\t  return DW_FORM_data8;\n+\tdefault:\n+\t  return DW_FORM_block1;\n+\t}\n     case dw_val_class_vec:\n       switch (constant_size (a->dw_attr_val.v.val_vec.length\n \t\t\t     * a->dw_attr_val.v.val_vec.elt_size))\n@@ -8627,6 +8735,32 @@ output_die (dw_die_ref die)\n \t  }\n \t  break;\n \n+\tcase dw_val_class_wide_int:\n+\t  {\n+\t    int i;\n+\t    int len = get_full_len (*a->dw_attr_val.v.val_wide);\n+\t    int l = HOST_BITS_PER_WIDE_INT / HOST_BITS_PER_CHAR;\n+\t    if (len * HOST_BITS_PER_WIDE_INT > 64)\n+\t      dw2_asm_output_data (1, get_full_len (*a->dw_attr_val.v.val_wide) * l,\n+\t\t\t\t   NULL);\n+\n+\t    if (WORDS_BIG_ENDIAN)\n+\t      for (i = len - 1; i >= 0; --i)\n+\t\t{\n+\t\t  dw2_asm_output_data (l, a->dw_attr_val.v.val_wide->elt (i),\n+\t\t\t\t       name);\n+\t\t  name = NULL;\n+\t\t}\n+\t    else\n+\t      for (i = 0; i < len; ++i)\n+\t\t{\n+\t\t  dw2_asm_output_data (l, a->dw_attr_val.v.val_wide->elt (i),\n+\t\t\t\t       name);\n+\t\t  name = NULL;\n+\t\t}\n+\t  }\n+\t  break;\n+\n \tcase dw_val_class_vec:\n \t  {\n \t    unsigned int elt_size = a->dw_attr_val.v.val_vec.elt_size;\n@@ -10320,19 +10454,19 @@ simple_type_size_in_bits (const_tree type)\n     return TYPE_ALIGN (type);\n }\n \n-/* Similarly, but return a double_int instead of UHWI.  */\n+/* Similarly, but return an offset_int instead of UHWI.  */\n \n-static inline double_int\n-double_int_type_size_in_bits (const_tree type)\n+static inline offset_int\n+offset_int_type_size_in_bits (const_tree type)\n {\n   if (TREE_CODE (type) == ERROR_MARK)\n-    return double_int::from_uhwi (BITS_PER_WORD);\n+    return BITS_PER_WORD;\n   else if (TYPE_SIZE (type) == NULL_TREE)\n-    return double_int_zero;\n+    return 0;\n   else if (TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST)\n-    return tree_to_double_int (TYPE_SIZE (type));\n+    return wi::to_offset (TYPE_SIZE (type));\n   else\n-    return double_int::from_uhwi (TYPE_ALIGN (type));\n+    return TYPE_ALIGN (type);\n }\n \n /*  Given a pointer to a tree node for a subrange type, return a pointer\n@@ -11826,9 +11960,7 @@ clz_loc_descriptor (rtx rtl, enum machine_mode mode,\n   rtx msb;\n \n   if (GET_MODE_CLASS (mode) != MODE_INT\n-      || GET_MODE (XEXP (rtl, 0)) != mode\n-      || (GET_CODE (rtl) == CLZ\n-\t  && GET_MODE_BITSIZE (mode) > HOST_BITS_PER_DOUBLE_INT))\n+      || GET_MODE (XEXP (rtl, 0)) != mode)\n     return NULL;\n \n   op0 = mem_loc_descriptor (XEXP (rtl, 0), mode, mem_mode,\n@@ -11872,9 +12004,9 @@ clz_loc_descriptor (rtx rtl, enum machine_mode mode,\n     msb = GEN_INT ((unsigned HOST_WIDE_INT) 1\n \t\t   << (GET_MODE_BITSIZE (mode) - 1));\n   else\n-    msb = immed_double_const (0, (unsigned HOST_WIDE_INT) 1\n-\t\t\t\t  << (GET_MODE_BITSIZE (mode)\n-\t\t\t\t      - HOST_BITS_PER_WIDE_INT - 1), mode);\n+    msb = immed_wide_int_const\n+      (wi::set_bit_in_zero (GET_MODE_PRECISION (mode) - 1,\n+\t\t\t    GET_MODE_PRECISION (mode)), mode);\n   if (GET_CODE (msb) == CONST_INT && INTVAL (msb) < 0)\n     tmp = new_loc_descr (HOST_BITS_PER_WIDE_INT == 32\n \t\t\t ? DW_OP_const4u : HOST_BITS_PER_WIDE_INT == 64\n@@ -12800,10 +12932,14 @@ mem_loc_descriptor (rtx rtl, enum machine_mode mode,\n \t{\n \t  dw_die_ref type_die;\n \n-\t  /* Note that a CONST_DOUBLE rtx could represent either an integer\n-\t     or a floating-point constant.  A CONST_DOUBLE is used whenever\n-\t     the constant requires more than one word in order to be\n-\t     adequately represented.  We output CONST_DOUBLEs as blocks.  */\n+\t  /* Note that if TARGET_SUPPORTS_WIDE_INT == 0, a\n+\t     CONST_DOUBLE rtx could represent either a large integer\n+\t     or a floating-point constant.  If TARGET_SUPPORTS_WIDE_INT != 0,\n+\t     the value is always a floating point constant.\n+\n+\t     When it is an integer, a CONST_DOUBLE is used whenever\n+\t     the constant requires 2 HWIs to be adequately represented.\n+\t     We output CONST_DOUBLEs as blocks.  */\n \t  if (mode == VOIDmode\n \t      || (GET_MODE (rtl) == VOIDmode\n \t\t  && GET_MODE_BITSIZE (mode) != HOST_BITS_PER_DOUBLE_INT))\n@@ -12816,7 +12952,16 @@ mem_loc_descriptor (rtx rtl, enum machine_mode mode,\n \t  mem_loc_result->dw_loc_oprnd1.val_class = dw_val_class_die_ref;\n \t  mem_loc_result->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n \t  mem_loc_result->dw_loc_oprnd1.v.val_die_ref.external = 0;\n-\t  if (SCALAR_FLOAT_MODE_P (mode))\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n+\t  if (!SCALAR_FLOAT_MODE_P (mode))\n+\t    {\n+\t      mem_loc_result->dw_loc_oprnd2.val_class\n+\t\t= dw_val_class_const_double;\n+\t      mem_loc_result->dw_loc_oprnd2.v.val_double\n+\t\t= rtx_to_double_int (rtl);\n+\t    }\n+\t  else\n+#endif\n \t    {\n \t      unsigned int length = GET_MODE_SIZE (mode);\n \t      unsigned char *array\n@@ -12828,13 +12973,26 @@ mem_loc_descriptor (rtx rtl, enum machine_mode mode,\n \t      mem_loc_result->dw_loc_oprnd2.v.val_vec.elt_size = 4;\n \t      mem_loc_result->dw_loc_oprnd2.v.val_vec.array = array;\n \t    }\n-\t  else\n-\t    {\n-\t      mem_loc_result->dw_loc_oprnd2.val_class\n-\t\t= dw_val_class_const_double;\n-\t      mem_loc_result->dw_loc_oprnd2.v.val_double\n-\t\t= rtx_to_double_int (rtl);\n-\t    }\n+\t}\n+      break;\n+\n+    case CONST_WIDE_INT:\n+      if (!dwarf_strict)\n+\t{\n+\t  dw_die_ref type_die;\n+\n+\t  type_die = base_type_for_mode (mode,\n+\t\t\t\t\t GET_MODE_CLASS (mode) == MODE_INT);\n+\t  if (type_die == NULL)\n+\t    return NULL;\n+\t  mem_loc_result = new_loc_descr (DW_OP_GNU_const_type, 0, 0);\n+\t  mem_loc_result->dw_loc_oprnd1.val_class = dw_val_class_die_ref;\n+\t  mem_loc_result->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n+\t  mem_loc_result->dw_loc_oprnd1.v.val_die_ref.external = 0;\n+\t  mem_loc_result->dw_loc_oprnd2.val_class\n+\t    = dw_val_class_wide_int;\n+\t  mem_loc_result->dw_loc_oprnd2.v.val_wide = ggc_alloc_cleared_wide_int ();\n+\t  *mem_loc_result->dw_loc_oprnd2.v.val_wide = std::make_pair (rtl, mode);\n \t}\n       break;\n \n@@ -13305,7 +13463,15 @@ loc_descriptor (rtx rtl, enum machine_mode mode,\n \t     adequately represented.  We output CONST_DOUBLEs as blocks.  */\n \t  loc_result = new_loc_descr (DW_OP_implicit_value,\n \t\t\t\t      GET_MODE_SIZE (mode), 0);\n-\t  if (SCALAR_FLOAT_MODE_P (mode))\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n+\t  if (!SCALAR_FLOAT_MODE_P (mode))\n+\t    {\n+\t      loc_result->dw_loc_oprnd2.val_class = dw_val_class_const_double;\n+\t      loc_result->dw_loc_oprnd2.v.val_double\n+\t        = rtx_to_double_int (rtl);\n+\t    }\n+\t  else\n+#endif\n \t    {\n \t      unsigned int length = GET_MODE_SIZE (mode);\n \t      unsigned char *array\n@@ -13317,12 +13483,20 @@ loc_descriptor (rtx rtl, enum machine_mode mode,\n \t      loc_result->dw_loc_oprnd2.v.val_vec.elt_size = 4;\n \t      loc_result->dw_loc_oprnd2.v.val_vec.array = array;\n \t    }\n-\t  else\n-\t    {\n-\t      loc_result->dw_loc_oprnd2.val_class = dw_val_class_const_double;\n-\t      loc_result->dw_loc_oprnd2.v.val_double\n-\t        = rtx_to_double_int (rtl);\n-\t    }\n+\t}\n+      break;\n+\n+    case CONST_WIDE_INT:\n+      if (mode == VOIDmode)\n+\tmode = GET_MODE (rtl);\n+\n+      if (mode != VOIDmode && (dwarf_version >= 4 || !dwarf_strict))\n+\t{\n+\t  loc_result = new_loc_descr (DW_OP_implicit_value,\n+\t\t\t\t      GET_MODE_SIZE (mode), 0);\n+\t  loc_result->dw_loc_oprnd2.val_class = dw_val_class_wide_int;\n+\t  loc_result->dw_loc_oprnd2.v.val_wide = ggc_alloc_cleared_wide_int ();\n+\t  *loc_result->dw_loc_oprnd2.v.val_wide = std::make_pair (rtl, mode);\n \t}\n       break;\n \n@@ -13338,6 +13512,7 @@ loc_descriptor (rtx rtl, enum machine_mode mode,\n \t    ggc_alloc_atomic (length * elt_size);\n \t  unsigned int i;\n \t  unsigned char *p;\n+\t  enum machine_mode imode = GET_MODE_INNER (mode);\n \n \t  gcc_assert (mode == GET_MODE (rtl) || VOIDmode == GET_MODE (rtl));\n \t  switch (GET_MODE_CLASS (mode))\n@@ -13346,15 +13521,7 @@ loc_descriptor (rtx rtl, enum machine_mode mode,\n \t      for (i = 0, p = array; i < length; i++, p += elt_size)\n \t\t{\n \t\t  rtx elt = CONST_VECTOR_ELT (rtl, i);\n-\t\t  double_int val = rtx_to_double_int (elt);\n-\n-\t\t  if (elt_size <= sizeof (HOST_WIDE_INT))\n-\t\t    insert_int (val.to_shwi (), elt_size, p);\n-\t\t  else\n-\t\t    {\n-\t\t      gcc_assert (elt_size == 2 * sizeof (HOST_WIDE_INT));\n-\t\t      insert_double (val, p);\n-\t\t    }\n+\t\t  insert_wide_int (std::make_pair (elt, imode), p, elt_size);\n \t\t}\n \t      break;\n \n@@ -14676,15 +14843,10 @@ simple_decl_align_in_bits (const_tree decl)\n \n /* Return the result of rounding T up to ALIGN.  */\n \n-static inline double_int\n-round_up_to_align (double_int t, unsigned int align)\n+static inline offset_int\n+round_up_to_align (const offset_int &t, unsigned int align)\n {\n-  double_int alignd = double_int::from_uhwi (align);\n-  t += alignd;\n-  t += double_int_minus_one;\n-  t = t.div (alignd, true, TRUNC_DIV_EXPR);\n-  t *= alignd;\n-  return t;\n+  return wi::udiv_trunc (t + align - 1, align) * align;\n }\n \n /* Given a pointer to a FIELD_DECL, compute and return the byte offset of the\n@@ -14697,9 +14859,9 @@ round_up_to_align (double_int t, unsigned int align)\n static HOST_WIDE_INT\n field_byte_offset (const_tree decl)\n {\n-  double_int object_offset_in_bits;\n-  double_int object_offset_in_bytes;\n-  double_int bitpos_int;\n+  offset_int object_offset_in_bits;\n+  offset_int object_offset_in_bytes;\n+  offset_int bitpos_int;\n \n   if (TREE_CODE (decl) == ERROR_MARK)\n     return 0;\n@@ -14712,21 +14874,21 @@ field_byte_offset (const_tree decl)\n   if (TREE_CODE (bit_position (decl)) != INTEGER_CST)\n     return 0;\n \n-  bitpos_int = tree_to_double_int (bit_position (decl));\n+  bitpos_int = wi::to_offset (bit_position (decl));\n \n #ifdef PCC_BITFIELD_TYPE_MATTERS\n   if (PCC_BITFIELD_TYPE_MATTERS)\n     {\n       tree type;\n       tree field_size_tree;\n-      double_int deepest_bitpos;\n-      double_int field_size_in_bits;\n+      offset_int deepest_bitpos;\n+      offset_int field_size_in_bits;\n       unsigned int type_align_in_bits;\n       unsigned int decl_align_in_bits;\n-      double_int type_size_in_bits;\n+      offset_int type_size_in_bits;\n \n       type = field_type (decl);\n-      type_size_in_bits = double_int_type_size_in_bits (type);\n+      type_size_in_bits = offset_int_type_size_in_bits (type);\n       type_align_in_bits = simple_type_align_in_bits (type);\n \n       field_size_tree = DECL_SIZE (decl);\n@@ -14738,7 +14900,7 @@ field_byte_offset (const_tree decl)\n \n       /* If the size of the field is not constant, use the type size.  */\n       if (TREE_CODE (field_size_tree) == INTEGER_CST)\n-\tfield_size_in_bits = tree_to_double_int (field_size_tree);\n+\tfield_size_in_bits = wi::to_offset (field_size_tree);\n       else\n \tfield_size_in_bits = type_size_in_bits;\n \n@@ -14802,7 +14964,7 @@ field_byte_offset (const_tree decl)\n       object_offset_in_bits\n \t= round_up_to_align (object_offset_in_bits, type_align_in_bits);\n \n-      if (object_offset_in_bits.ugt (bitpos_int))\n+      if (wi::gtu_p (object_offset_in_bits, bitpos_int))\n \t{\n \t  object_offset_in_bits = deepest_bitpos - type_size_in_bits;\n \n@@ -14816,8 +14978,7 @@ field_byte_offset (const_tree decl)\n     object_offset_in_bits = bitpos_int;\n \n   object_offset_in_bytes\n-    = object_offset_in_bits.div (double_int::from_uhwi (BITS_PER_UNIT),\n-\t\t\t\t true, TRUNC_DIV_EXPR);\n+    = wi::lrshift (object_offset_in_bits, LOG2_BITS_PER_UNIT);\n   return object_offset_in_bytes.to_shwi ();\n }\n \f\n@@ -14993,22 +15154,36 @@ extract_int (const unsigned char *src, unsigned int size)\n   return val;\n }\n \n-/* Writes double_int values to dw_vec_const array.  */\n+/* Writes wide_int values to dw_vec_const array.  */\n \n static void\n-insert_double (double_int val, unsigned char *dest)\n+insert_wide_int (const wide_int &val, unsigned char *dest, int elt_size)\n {\n-  unsigned char *p0 = dest;\n-  unsigned char *p1 = dest + sizeof (HOST_WIDE_INT);\n+  int i;\n \n-  if (WORDS_BIG_ENDIAN)\n+  if (elt_size <= HOST_BITS_PER_WIDE_INT/BITS_PER_UNIT)\n     {\n-      p0 = p1;\n-      p1 = dest;\n+      insert_int ((HOST_WIDE_INT) val.elt (0), elt_size, dest);\n+      return;\n     }\n \n-  insert_int ((HOST_WIDE_INT) val.low, sizeof (HOST_WIDE_INT), p0);\n-  insert_int ((HOST_WIDE_INT) val.high, sizeof (HOST_WIDE_INT), p1);\n+  /* We'd have to extend this code to support odd sizes.  */\n+  gcc_assert (elt_size % (HOST_BITS_PER_WIDE_INT / BITS_PER_UNIT) == 0);\n+\n+  int n = elt_size / (HOST_BITS_PER_WIDE_INT / BITS_PER_UNIT);\n+\n+  if (WORDS_BIG_ENDIAN)\n+    for (i = n - 1; i >= 0; i--)\n+      {\n+\tinsert_int ((HOST_WIDE_INT) val.elt (i), sizeof (HOST_WIDE_INT), dest);\n+\tdest += sizeof (HOST_WIDE_INT);\n+      }\n+  else\n+    for (i = 0; i < n; i++)\n+      {\n+\tinsert_int ((HOST_WIDE_INT) val.elt (i), sizeof (HOST_WIDE_INT), dest);\n+\tdest += sizeof (HOST_WIDE_INT);\n+      }\n }\n \n /* Writes floating point values to dw_vec_const array.  */\n@@ -15053,6 +15228,11 @@ add_const_value_attribute (dw_die_ref die, rtx rtl)\n       }\n       return true;\n \n+    case CONST_WIDE_INT:\n+      add_AT_wide (die, DW_AT_const_value,\n+\t\t   std::make_pair (rtl, GET_MODE (rtl)));\n+      return true;\n+\n     case CONST_DOUBLE:\n       /* Note that a CONST_DOUBLE rtx could represent either an integer or a\n \t floating-point constant.  A CONST_DOUBLE is used whenever the\n@@ -15061,17 +15241,17 @@ add_const_value_attribute (dw_die_ref die, rtx rtl)\n       {\n \tenum machine_mode mode = GET_MODE (rtl);\n \n-\tif (SCALAR_FLOAT_MODE_P (mode))\n+\tif (TARGET_SUPPORTS_WIDE_INT == 0 && !SCALAR_FLOAT_MODE_P (mode))\n+\t  add_AT_double (die, DW_AT_const_value,\n+\t\t\t CONST_DOUBLE_HIGH (rtl), CONST_DOUBLE_LOW (rtl));\n+\telse\n \t  {\n \t    unsigned int length = GET_MODE_SIZE (mode);\n \t    unsigned char *array = (unsigned char *) ggc_alloc_atomic (length);\n \n \t    insert_float (rtl, array);\n \t    add_AT_vec (die, DW_AT_const_value, length / 4, 4, array);\n \t  }\n-\telse\n-\t  add_AT_double (die, DW_AT_const_value,\n-\t\t\t CONST_DOUBLE_HIGH (rtl), CONST_DOUBLE_LOW (rtl));\n       }\n       return true;\n \n@@ -15084,22 +15264,15 @@ add_const_value_attribute (dw_die_ref die, rtx rtl)\n \t  (length * elt_size);\n \tunsigned int i;\n \tunsigned char *p;\n+\tenum machine_mode imode = GET_MODE_INNER (mode);\n \n \tswitch (GET_MODE_CLASS (mode))\n \t  {\n \t  case MODE_VECTOR_INT:\n \t    for (i = 0, p = array; i < length; i++, p += elt_size)\n \t      {\n \t\trtx elt = CONST_VECTOR_ELT (rtl, i);\n-\t\tdouble_int val = rtx_to_double_int (elt);\n-\n-\t\tif (elt_size <= sizeof (HOST_WIDE_INT))\n-\t\t  insert_int (val.to_shwi (), elt_size, p);\n-\t\telse\n-\t\t  {\n-\t\t    gcc_assert (elt_size == 2 * sizeof (HOST_WIDE_INT));\n-\t\t    insert_double (val, p);\n-\t\t  }\n+\t\tinsert_wide_int (std::make_pair (elt, imode), p, elt_size);\n \t      }\n \t    break;\n \n@@ -16237,7 +16410,7 @@ add_bound_info (dw_die_ref subrange_die, enum dwarf_attribute bound_attr, tree b\n \t   consumers will treat DW_FORM_data[1248] as unsigned values,\n \t   regardless of the underlying type.  */\n \telse if (prec <= HOST_BITS_PER_WIDE_INT\n-\t\t || TREE_INT_CST_HIGH (bound) == 0)\n+\t\t || tree_fits_uhwi_p (bound))\n \t  {\n \t    if (TYPE_UNSIGNED (TREE_TYPE (bound)))\n \t      add_AT_unsigned (subrange_die, bound_attr,\n@@ -16250,8 +16423,7 @@ add_bound_info (dw_die_ref subrange_die, enum dwarf_attribute bound_attr, tree b\n \t     the precision of its type.  The precision and signedness\n \t     of the type will be necessary to re-interpret it\n \t     unambiguously.  */\n-\t  add_AT_double (subrange_die, bound_attr, TREE_INT_CST_HIGH (bound),\n-\t\t         TREE_INT_CST_LOW (bound));\n+\t  add_AT_wide (subrange_die, bound_attr, bound);\n       }\n       break;\n \n@@ -17410,8 +17582,7 @@ gen_enumeration_type_die (tree type, dw_die_ref context_die)\n \t    /* Enumeration constants may be wider than HOST_WIDE_INT.  Handle\n \t       that here.  TODO: This should be re-worked to use correct\n \t       signed/unsigned double tags for all cases.  */\n-\t    add_AT_double (enum_die, DW_AT_const_value,\n-\t\t\t   TREE_INT_CST_HIGH (value), TREE_INT_CST_LOW (value));\n+\t    add_AT_wide (enum_die, DW_AT_const_value, value);\n \t}\n \n       add_gnat_descriptive_type_attribute (type_die, type, context_die);\n@@ -23549,6 +23720,9 @@ hash_loc_operands (dw_loc_descr_ref loc, hashval_t hash)\n \t  hash = iterative_hash_object (val2->v.val_double.low, hash);\n \t  hash = iterative_hash_object (val2->v.val_double.high, hash);\n \t  break;\n+\tcase dw_val_class_wide_int:\n+\t  hash = iterative_hash_object (*val2->v.val_wide, hash);\n+\t  break;\n \tcase dw_val_class_addr:\n \t  hash = iterative_hash_rtx (val2->v.val_addr, hash);\n \t  break;\n@@ -23638,6 +23812,9 @@ hash_loc_operands (dw_loc_descr_ref loc, hashval_t hash)\n \t    hash = iterative_hash_object (val2->v.val_double.low, hash);\n \t    hash = iterative_hash_object (val2->v.val_double.high, hash);\n \t    break;\n+\t  case dw_val_class_wide_int:\n+\t    hash = iterative_hash_object (*val2->v.val_wide, hash);\n+\t    break;\n \t  default:\n \t    gcc_unreachable ();\n \t  }\n@@ -23786,6 +23963,8 @@ compare_loc_operands (dw_loc_descr_ref x, dw_loc_descr_ref y)\n \tcase dw_val_class_const_double:\n \t  return valx2->v.val_double.low == valy2->v.val_double.low\n \t\t && valx2->v.val_double.high == valy2->v.val_double.high;\n+\tcase dw_val_class_wide_int:\n+\t  return *valx2->v.val_wide == *valy2->v.val_wide;\n \tcase dw_val_class_addr:\n \t  return rtx_equal_p (valx2->v.val_addr, valy2->v.val_addr);\n \tdefault:\n@@ -23829,6 +24008,8 @@ compare_loc_operands (dw_loc_descr_ref x, dw_loc_descr_ref y)\n \tcase dw_val_class_const_double:\n \t  return valx2->v.val_double.low == valy2->v.val_double.low\n \t\t && valx2->v.val_double.high == valy2->v.val_double.high;\n+\tcase dw_val_class_wide_int:\n+\t  return *valx2->v.val_wide == *valy2->v.val_wide;\n \tdefault:\n \t  gcc_unreachable ();\n \t}"}, {"sha": "bac50774e2c8651397c65b2e6dd386001f9ddf2f", "filename": "gcc/dwarf2out.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdwarf2out.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fdwarf2out.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdwarf2out.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -21,6 +21,7 @@ along with GCC; see the file COPYING3.  If not see\n #define GCC_DWARF2OUT_H 1\n \n #include \"dwarf2.h\"\t/* ??? Remove this once only used by dwarf2foo.c.  */\n+#include \"wide-int.h\"\n \n typedef struct die_struct *dw_die_ref;\n typedef const struct die_struct *const_dw_die_ref;\n@@ -29,6 +30,7 @@ typedef struct dw_val_node *dw_val_ref;\n typedef struct dw_cfi_node *dw_cfi_ref;\n typedef struct dw_loc_descr_node *dw_loc_descr_ref;\n typedef struct dw_loc_list_struct *dw_loc_list_ref;\n+typedef wide_int *wide_int_ptr;\n \n \n /* Call frames are described using a sequence of Call Frame\n@@ -136,6 +138,7 @@ enum dw_val_class\n   dw_val_class_const,\n   dw_val_class_unsigned_const,\n   dw_val_class_const_double,\n+  dw_val_class_wide_int,\n   dw_val_class_vec,\n   dw_val_class_flag,\n   dw_val_class_die_ref,\n@@ -176,6 +179,7 @@ struct GTY(()) dw_val_node {\n       HOST_WIDE_INT GTY ((default)) val_int;\n       unsigned HOST_WIDE_INT GTY ((tag (\"dw_val_class_unsigned_const\"))) val_unsigned;\n       double_int GTY ((tag (\"dw_val_class_const_double\"))) val_double;\n+      wide_int_ptr GTY ((tag (\"dw_val_class_wide_int\"))) val_wide;\n       dw_vec_const GTY ((tag (\"dw_val_class_vec\"))) val_vec;\n       struct dw_val_die_union\n \t{"}, {"sha": "f2b8257de7c8f1ffd705422664c65f017ce2c16b", "filename": "gcc/emit-rtl.c", "status": "modified", "additions": 115, "deletions": 11, "changes": 126, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Femit-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Femit-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Femit-rtl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -126,6 +126,9 @@ rtx cc0_rtx;\n static GTY ((if_marked (\"ggc_marked_p\"), param_is (struct rtx_def)))\n      htab_t const_int_htab;\n \n+static GTY ((if_marked (\"ggc_marked_p\"), param_is (struct rtx_def)))\n+     htab_t const_wide_int_htab;\n+\n /* A hash table storing register attribute structures.  */\n static GTY ((if_marked (\"ggc_marked_p\"), param_is (struct reg_attrs)))\n      htab_t reg_attrs_htab;\n@@ -147,6 +150,11 @@ static void set_used_decls (tree);\n static void mark_label_nuses (rtx);\n static hashval_t const_int_htab_hash (const void *);\n static int const_int_htab_eq (const void *, const void *);\n+#if TARGET_SUPPORTS_WIDE_INT\n+static hashval_t const_wide_int_htab_hash (const void *);\n+static int const_wide_int_htab_eq (const void *, const void *);\n+static rtx lookup_const_wide_int (rtx);\n+#endif\n static hashval_t const_double_htab_hash (const void *);\n static int const_double_htab_eq (const void *, const void *);\n static rtx lookup_const_double (rtx);\n@@ -181,14 +189,51 @@ const_int_htab_eq (const void *x, const void *y)\n   return (INTVAL ((const_rtx) x) == *((const HOST_WIDE_INT *) y));\n }\n \n+#if TARGET_SUPPORTS_WIDE_INT\n+/* Returns a hash code for X (which is a really a CONST_WIDE_INT).  */\n+\n+static hashval_t\n+const_wide_int_htab_hash (const void *x)\n+{\n+  int i;\n+  HOST_WIDE_INT hash = 0;\n+  const_rtx xr = (const_rtx) x;\n+\n+  for (i = 0; i < CONST_WIDE_INT_NUNITS (xr); i++)\n+    hash += CONST_WIDE_INT_ELT (xr, i);\n+\n+  return (hashval_t) hash;\n+}\n+\n+/* Returns nonzero if the value represented by X (which is really a\n+   CONST_WIDE_INT) is the same as that given by Y (which is really a\n+   CONST_WIDE_INT).  */\n+\n+static int\n+const_wide_int_htab_eq (const void *x, const void *y)\n+{\n+  int i;\n+  const_rtx xr = (const_rtx) x;\n+  const_rtx yr = (const_rtx) y;\n+  if (CONST_WIDE_INT_NUNITS (xr) != CONST_WIDE_INT_NUNITS (yr))\n+    return 0;\n+\n+  for (i = 0; i < CONST_WIDE_INT_NUNITS (xr); i++)\n+    if (CONST_WIDE_INT_ELT (xr, i) != CONST_WIDE_INT_ELT (yr, i))\n+      return 0;\n+\n+  return 1;\n+}\n+#endif\n+\n /* Returns a hash code for X (which is really a CONST_DOUBLE).  */\n static hashval_t\n const_double_htab_hash (const void *x)\n {\n   const_rtx const value = (const_rtx) x;\n   hashval_t h;\n \n-  if (GET_MODE (value) == VOIDmode)\n+  if (TARGET_SUPPORTS_WIDE_INT == 0 && GET_MODE (value) == VOIDmode)\n     h = CONST_DOUBLE_LOW (value) ^ CONST_DOUBLE_HIGH (value);\n   else\n     {\n@@ -208,7 +253,7 @@ const_double_htab_eq (const void *x, const void *y)\n \n   if (GET_MODE (a) != GET_MODE (b))\n     return 0;\n-  if (GET_MODE (a) == VOIDmode)\n+  if (TARGET_SUPPORTS_WIDE_INT == 0 && GET_MODE (a) == VOIDmode)\n     return (CONST_DOUBLE_LOW (a) == CONST_DOUBLE_LOW (b)\n \t    && CONST_DOUBLE_HIGH (a) == CONST_DOUBLE_HIGH (b));\n   else\n@@ -446,6 +491,7 @@ const_fixed_from_fixed_value (FIXED_VALUE_TYPE value, enum machine_mode mode)\n   return lookup_const_fixed (fixed);\n }\n \n+#if TARGET_SUPPORTS_WIDE_INT == 0\n /* Constructs double_int from rtx CST.  */\n \n double_int\n@@ -465,17 +511,70 @@ rtx_to_double_int (const_rtx cst)\n   \n   return r;\n }\n+#endif\n \n+#if TARGET_SUPPORTS_WIDE_INT\n+/* Determine whether CONST_WIDE_INT WINT already exists in the hash table.\n+   If so, return its counterpart; otherwise add it to the hash table and\n+   return it.  */\n \n-/* Return a CONST_DOUBLE or CONST_INT for a value specified as\n-   a double_int.  */\n+static rtx\n+lookup_const_wide_int (rtx wint)\n+{\n+  void **slot = htab_find_slot (const_wide_int_htab, wint, INSERT);\n+  if (*slot == 0)\n+    *slot = wint;\n+\n+  return (rtx) *slot;\n+}\n+#endif\n+\n+/* Return an rtx constant for V, given that the constant has mode MODE.\n+   The returned rtx will be a CONST_INT if V fits, otherwise it will be\n+   a CONST_DOUBLE (if !TARGET_SUPPORTS_WIDE_INT) or a CONST_WIDE_INT\n+   (if TARGET_SUPPORTS_WIDE_INT).  */\n \n rtx\n-immed_double_int_const (double_int i, enum machine_mode mode)\n+immed_wide_int_const (const wide_int_ref &v, enum machine_mode mode)\n {\n-  return immed_double_const (i.low, i.high, mode);\n+  unsigned int len = v.get_len ();\n+  unsigned int prec = GET_MODE_PRECISION (mode);\n+\n+  /* Allow truncation but not extension since we do not know if the\n+     number is signed or unsigned.  */\n+  gcc_assert (prec <= v.get_precision ());\n+\n+  if (len < 2 || prec <= HOST_BITS_PER_WIDE_INT)\n+    return gen_int_mode (v.elt (0), mode);\n+\n+#if TARGET_SUPPORTS_WIDE_INT\n+  {\n+    unsigned int i;\n+    rtx value;\n+    unsigned int blocks_needed\n+      = (prec + HOST_BITS_PER_WIDE_INT - 1) / HOST_BITS_PER_WIDE_INT;\n+\n+    if (len > blocks_needed)\n+      len = blocks_needed;\n+\n+    value = const_wide_int_alloc (len);\n+\n+    /* It is so tempting to just put the mode in here.  Must control\n+       myself ... */\n+    PUT_MODE (value, VOIDmode);\n+    CWI_PUT_NUM_ELEM (value, len);\n+\n+    for (i = 0; i < len; i++)\n+      CONST_WIDE_INT_ELT (value, i) = v.elt (i);\n+\n+    return lookup_const_wide_int (value);\n+  }\n+#else\n+  return immed_double_const (v.elt (0), v.elt (1), mode);\n+#endif\n }\n \n+#if TARGET_SUPPORTS_WIDE_INT == 0\n /* Return a CONST_DOUBLE or CONST_INT for a value specified as a pair\n    of ints: I0 is the low-order word and I1 is the high-order word.\n    For values that are larger than HOST_BITS_PER_DOUBLE_INT, the\n@@ -527,6 +626,7 @@ immed_double_const (HOST_WIDE_INT i0, HOST_WIDE_INT i1, enum machine_mode mode)\n \n   return lookup_const_double (value);\n }\n+#endif\n \n rtx\n gen_rtx_REG (enum machine_mode mode, unsigned int regno)\n@@ -5629,11 +5729,15 @@ init_emit_once (void)\n   enum machine_mode mode;\n   enum machine_mode double_mode;\n \n-  /* Initialize the CONST_INT, CONST_DOUBLE, CONST_FIXED, and memory attribute\n-     hash tables.  */\n+  /* Initialize the CONST_INT, CONST_WIDE_INT, CONST_DOUBLE,\n+     CONST_FIXED, and memory attribute hash tables.  */\n   const_int_htab = htab_create_ggc (37, const_int_htab_hash,\n \t\t\t\t    const_int_htab_eq, NULL);\n \n+#if TARGET_SUPPORTS_WIDE_INT\n+  const_wide_int_htab = htab_create_ggc (37, const_wide_int_htab_hash,\n+\t\t\t\t\t const_wide_int_htab_eq, NULL);\n+#endif\n   const_double_htab = htab_create_ggc (37, const_double_htab_hash,\n \t\t\t\t       const_double_htab_eq, NULL);\n \n@@ -5695,9 +5799,9 @@ init_emit_once (void)\n   else\n     const_true_rtx = gen_rtx_CONST_INT (VOIDmode, STORE_FLAG_VALUE);\n \n-  REAL_VALUE_FROM_INT (dconst0,   0,  0, double_mode);\n-  REAL_VALUE_FROM_INT (dconst1,   1,  0, double_mode);\n-  REAL_VALUE_FROM_INT (dconst2,   2,  0, double_mode);\n+  real_from_integer (&dconst0, double_mode, 0, SIGNED);\n+  real_from_integer (&dconst1, double_mode, 1, SIGNED);\n+  real_from_integer (&dconst2, double_mode, 2, SIGNED);\n \n   dconstm1 = dconst1;\n   dconstm1.sign = 1;"}, {"sha": "bc97c964e6136ab4bd5e17c9894aba36f2ec4454", "filename": "gcc/explow.c", "status": "modified", "additions": 3, "deletions": 32, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fexplow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fexplow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexplow.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -96,38 +96,9 @@ plus_constant (enum machine_mode mode, rtx x, HOST_WIDE_INT c)\n \n   switch (code)\n     {\n-    case CONST_INT:\n-      if (GET_MODE_BITSIZE (mode) > HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  double_int di_x = double_int::from_shwi (INTVAL (x));\n-\t  double_int di_c = double_int::from_shwi (c);\n-\n-\t  bool overflow;\n-\t  double_int v = di_x.add_with_sign (di_c, false, &overflow);\n-\t  if (overflow)\n-\t    gcc_unreachable ();\n-\n-\t  return immed_double_int_const (v, mode);\n-\t}\n-\n-      return gen_int_mode (UINTVAL (x) + c, mode);\n-\n-    case CONST_DOUBLE:\n-      {\n-\tdouble_int di_x = double_int::from_pair (CONST_DOUBLE_HIGH (x),\n-\t\t\t\t\t\t CONST_DOUBLE_LOW (x));\n-\tdouble_int di_c = double_int::from_shwi (c);\n-\n-\tbool overflow;\n-\tdouble_int v = di_x.add_with_sign (di_c, false, &overflow);\n-\tif (overflow)\n-\t  /* Sorry, we have no way to represent overflows this wide.\n-\t     To fix, add constant support wider than CONST_DOUBLE.  */\n-\t  gcc_assert (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_DOUBLE_INT);\n-\n-\treturn immed_double_int_const (v, mode);\n-      }\n-\n+    CASE_CONST_SCALAR_INT:\n+      return immed_wide_int_const (wi::add (std::make_pair (x, mode), c),\n+\t\t\t\t   mode);\n     case MEM:\n       /* If this is a reference to the constant pool, try replacing it with\n \t a reference to a new constant.  If the resulting address isn't"}, {"sha": "e76b6fcc724247cc15a9e0cd47b141d95d4cfd45", "filename": "gcc/expmed.c", "status": "modified", "additions": 53, "deletions": 108, "changes": 161, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -62,14 +62,26 @@ static rtx extract_fixed_bit_field (enum machine_mode, rtx,\n static rtx extract_fixed_bit_field_1 (enum machine_mode, rtx,\n \t\t\t\t      unsigned HOST_WIDE_INT,\n \t\t\t\t      unsigned HOST_WIDE_INT, rtx, int);\n-static rtx mask_rtx (enum machine_mode, int, int, int);\n static rtx lshift_value (enum machine_mode, unsigned HOST_WIDE_INT, int);\n static rtx extract_split_bit_field (rtx, unsigned HOST_WIDE_INT,\n \t\t\t\t    unsigned HOST_WIDE_INT, int);\n static void do_cmp_and_jump (rtx, rtx, enum rtx_code, enum machine_mode, rtx);\n static rtx expand_smod_pow2 (enum machine_mode, rtx, HOST_WIDE_INT);\n static rtx expand_sdiv_pow2 (enum machine_mode, rtx, HOST_WIDE_INT);\n \n+/* Return a constant integer mask value of mode MODE with BITSIZE ones\n+   followed by BITPOS zeros, or the complement of that if COMPLEMENT.\n+   The mask is truncated if necessary to the width of mode MODE.  The\n+   mask is zero-extended if BITSIZE+BITPOS is too small for MODE.  */\n+\n+static inline rtx\n+mask_rtx (enum machine_mode mode, int bitpos, int bitsize, bool complement)\n+{\n+  return immed_wide_int_const\n+    (wi::shifted_mask (bitpos, bitsize, complement,\n+\t\t       GET_MODE_PRECISION (mode)), mode);\n+}\n+\n /* Test whether a value is zero of a power of two.  */\n #define EXACT_POWER_OF_2_OR_ZERO_P(x) \\\n   (((x) & ((x) - (unsigned HOST_WIDE_INT) 1)) == 0)\n@@ -1885,26 +1897,6 @@ extract_fixed_bit_field_1 (enum machine_mode tmode, rtx op0,\n   return expand_shift (RSHIFT_EXPR, mode, op0,\n \t\t       GET_MODE_BITSIZE (mode) - bitsize, target, 0);\n }\n-\f\n-/* Return a constant integer (CONST_INT or CONST_DOUBLE) mask value\n-   of mode MODE with BITSIZE ones followed by BITPOS zeros, or the\n-   complement of that if COMPLEMENT.  The mask is truncated if\n-   necessary to the width of mode MODE.  The mask is zero-extended if\n-   BITSIZE+BITPOS is too small for MODE.  */\n-\n-static rtx\n-mask_rtx (enum machine_mode mode, int bitpos, int bitsize, int complement)\n-{\n-  double_int mask;\n-\n-  mask = double_int::mask (bitsize);\n-  mask = mask.llshift (bitpos, HOST_BITS_PER_DOUBLE_INT);\n-\n-  if (complement)\n-    mask = ~mask;\n-\n-  return immed_double_int_const (mask, mode);\n-}\n \n /* Return a constant integer (CONST_INT or CONST_DOUBLE) rtx with the value\n    VALUE << BITPOS.  */\n@@ -1913,12 +1905,7 @@ static rtx\n lshift_value (enum machine_mode mode, unsigned HOST_WIDE_INT value,\n \t      int bitpos)\n {\n-  double_int val;\n-  \n-  val = double_int::from_uhwi (value);\n-  val = val.llshift (bitpos, HOST_BITS_PER_DOUBLE_INT);\n-\n-  return immed_double_int_const (val, mode);\n+  return immed_wide_int_const (wi::lshift (value, bitpos), mode);\n }\n \f\n /* Extract a bit field that is split across two words\n@@ -3154,38 +3141,22 @@ expand_mult (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n \t only if the constant value exactly fits in an `unsigned int' without\n \t any truncation.  This means that multiplying by negative values does\n \t not work; results are off by 2^32 on a 32 bit machine.  */\n-\n       if (CONST_INT_P (scalar_op1))\n \t{\n \t  coeff = INTVAL (scalar_op1);\n \t  is_neg = coeff < 0;\n \t}\n+#if TARGET_SUPPORTS_WIDE_INT\n+      else if (CONST_WIDE_INT_P (scalar_op1))\n+#else\n       else if (CONST_DOUBLE_AS_INT_P (scalar_op1))\n+#endif\n \t{\n-\t  /* If we are multiplying in DImode, it may still be a win\n-\t     to try to work with shifts and adds.  */\n-\t  if (CONST_DOUBLE_HIGH (scalar_op1) == 0\n-\t      && (CONST_DOUBLE_LOW (scalar_op1) > 0\n-\t\t  || (CONST_DOUBLE_LOW (scalar_op1) < 0\n-\t\t      && EXACT_POWER_OF_2_OR_ZERO_P\n-\t\t\t   (CONST_DOUBLE_LOW (scalar_op1)))))\n-\t    {\n-\t      coeff = CONST_DOUBLE_LOW (scalar_op1);\n-\t      is_neg = false;\n-\t    }\n-\t  else if (CONST_DOUBLE_LOW (scalar_op1) == 0)\n-\t    {\n-\t      coeff = CONST_DOUBLE_HIGH (scalar_op1);\n-\t      if (EXACT_POWER_OF_2_OR_ZERO_P (coeff))\n-\t\t{\n-\t\t  int shift = floor_log2 (coeff) + HOST_BITS_PER_WIDE_INT;\n-\t\t  if (shift < HOST_BITS_PER_DOUBLE_INT - 1\n-\t\t      || mode_bitsize <= HOST_BITS_PER_DOUBLE_INT)\n-\t\t    return expand_shift (LSHIFT_EXPR, mode, op0,\n-\t\t\t\t\t shift, target, unsignedp);\n-\t\t}\n-\t      goto skip_synth;\n-\t    }\n+\t  int shift = wi::exact_log2 (std::make_pair (scalar_op1, mode));\n+\t  /* Perfect power of 2 (other than 1, which is handled above).  */\n+\t  if (shift > 0)\n+\t    return expand_shift (LSHIFT_EXPR, mode, op0,\n+\t\t\t\t shift, target, unsignedp);\n \t  else\n \t    goto skip_synth;\n \t}\n@@ -3362,7 +3333,6 @@ choose_multiplier (unsigned HOST_WIDE_INT d, int n, int precision,\n \t\t   unsigned HOST_WIDE_INT *multiplier_ptr,\n \t\t   int *post_shift_ptr, int *lgup_ptr)\n {\n-  double_int mhigh, mlow;\n   int lgup, post_shift;\n   int pow, pow2;\n \n@@ -3374,52 +3344,43 @@ choose_multiplier (unsigned HOST_WIDE_INT d, int n, int precision,\n   pow = n + lgup;\n   pow2 = n + lgup - precision;\n \n-  /* We could handle this with some effort, but this case is much\n-     better handled directly with a scc insn, so rely on caller using\n-     that.  */\n-  gcc_assert (pow != HOST_BITS_PER_DOUBLE_INT);\n-\n   /* mlow = 2^(N + lgup)/d */\n-  double_int val = double_int_zero.set_bit (pow);\n-  mlow = val.div (double_int::from_uhwi (d), true, TRUNC_DIV_EXPR); \n+  wide_int val = wi::set_bit_in_zero (pow, HOST_BITS_PER_DOUBLE_INT);\n+  wide_int mlow = wi::udiv_trunc (val, d);\n \n   /* mhigh = (2^(N + lgup) + 2^(N + lgup - precision))/d */\n-  val |= double_int_zero.set_bit (pow2);\n-  mhigh = val.div (double_int::from_uhwi (d), true, TRUNC_DIV_EXPR);\n-\n-  gcc_assert (!mhigh.high || val.high - d < d);\n-  gcc_assert (mhigh.high <= 1 && mlow.high <= 1);\n-  /* Assert that mlow < mhigh.  */\n-  gcc_assert (mlow.ult (mhigh));\n+  val |= wi::set_bit_in_zero (pow2, HOST_BITS_PER_DOUBLE_INT);\n+  wide_int mhigh = wi::udiv_trunc (val, d);\n \n   /* If precision == N, then mlow, mhigh exceed 2^N\n      (but they do not exceed 2^(N+1)).  */\n \n   /* Reduce to lowest terms.  */\n   for (post_shift = lgup; post_shift > 0; post_shift--)\n     {\n-      int shft = HOST_BITS_PER_WIDE_INT - 1;\n-      unsigned HOST_WIDE_INT ml_lo = (mlow.high << shft) | (mlow.low >> 1);\n-      unsigned HOST_WIDE_INT mh_lo = (mhigh.high << shft) | (mhigh.low >> 1);\n+      unsigned HOST_WIDE_INT ml_lo = wi::extract_uhwi (mlow, 1,\n+\t\t\t\t\t\t       HOST_BITS_PER_WIDE_INT);\n+      unsigned HOST_WIDE_INT mh_lo = wi::extract_uhwi (mhigh, 1,\n+\t\t\t\t\t\t       HOST_BITS_PER_WIDE_INT);\n       if (ml_lo >= mh_lo)\n \tbreak;\n \n-      mlow = double_int::from_uhwi (ml_lo);\n-      mhigh = double_int::from_uhwi (mh_lo);\n+      mlow = wi::uhwi (ml_lo, HOST_BITS_PER_DOUBLE_INT);\n+      mhigh = wi::uhwi (mh_lo, HOST_BITS_PER_DOUBLE_INT);\n     }\n \n   *post_shift_ptr = post_shift;\n   *lgup_ptr = lgup;\n   if (n < HOST_BITS_PER_WIDE_INT)\n     {\n       unsigned HOST_WIDE_INT mask = ((unsigned HOST_WIDE_INT) 1 << n) - 1;\n-      *multiplier_ptr = mhigh.low & mask;\n-      return mhigh.low >= mask;\n+      *multiplier_ptr = mhigh.to_uhwi () & mask;\n+      return mhigh.to_uhwi () >= mask;\n     }\n   else\n     {\n-      *multiplier_ptr = mhigh.low;\n-      return mhigh.high;\n+      *multiplier_ptr = mhigh.to_uhwi ();\n+      return wi::extract_uhwi (mhigh, HOST_BITS_PER_WIDE_INT, 1);\n     }\n }\n \n@@ -3686,9 +3647,9 @@ expmed_mult_highpart (enum machine_mode mode, rtx op0, rtx op1,\n static rtx\n expand_smod_pow2 (enum machine_mode mode, rtx op0, HOST_WIDE_INT d)\n {\n-  unsigned HOST_WIDE_INT masklow, maskhigh;\n   rtx result, temp, shift, label;\n   int logd;\n+  int prec = GET_MODE_PRECISION (mode);\n \n   logd = floor_log2 (d);\n   result = gen_reg_rtx (mode);\n@@ -3701,8 +3662,8 @@ expand_smod_pow2 (enum machine_mode mode, rtx op0, HOST_WIDE_INT d)\n \t\t\t\t      mode, 0, -1);\n       if (signmask)\n \t{\n+\t  HOST_WIDE_INT masklow = ((HOST_WIDE_INT) 1 << logd) - 1;\n \t  signmask = force_reg (mode, signmask);\n-\t  masklow = ((HOST_WIDE_INT) 1 << logd) - 1;\n \t  shift = GEN_INT (GET_MODE_BITSIZE (mode) - logd);\n \n \t  /* Use the rtx_cost of a LSHIFTRT instruction to determine\n@@ -3749,19 +3710,11 @@ expand_smod_pow2 (enum machine_mode mode, rtx op0, HOST_WIDE_INT d)\n      modulus.  By including the signbit in the operation, many targets\n      can avoid an explicit compare operation in the following comparison\n      against zero.  */\n-\n-  masklow = ((HOST_WIDE_INT) 1 << logd) - 1;\n-  if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n-    {\n-      masklow |= HOST_WIDE_INT_M1U << (GET_MODE_BITSIZE (mode) - 1);\n-      maskhigh = -1;\n-    }\n-  else\n-    maskhigh = HOST_WIDE_INT_M1U\n-\t\t << (GET_MODE_BITSIZE (mode) - HOST_BITS_PER_WIDE_INT - 1);\n+  wide_int mask = wi::mask (logd, false, prec);\n+  mask = wi::set_bit (mask, prec - 1);\n \n   temp = expand_binop (mode, and_optab, op0,\n-\t\t       immed_double_const (masklow, maskhigh, mode),\n+\t\t       immed_wide_int_const (mask, mode),\n \t\t       result, 1, OPTAB_LIB_WIDEN);\n   if (temp != result)\n     emit_move_insn (result, temp);\n@@ -3771,10 +3724,10 @@ expand_smod_pow2 (enum machine_mode mode, rtx op0, HOST_WIDE_INT d)\n \n   temp = expand_binop (mode, sub_optab, result, const1_rtx, result,\n \t\t       0, OPTAB_LIB_WIDEN);\n-  masklow = HOST_WIDE_INT_M1U << logd;\n-  maskhigh = -1;\n+\n+  mask = wi::mask (logd, true, prec);\n   temp = expand_binop (mode, ior_optab, temp,\n-\t\t       immed_double_const (masklow, maskhigh, mode),\n+\t\t       immed_wide_int_const (mask, mode),\n \t\t       result, 1, OPTAB_LIB_WIDEN);\n   temp = expand_binop (mode, add_optab, temp, const1_rtx, result,\n \t\t       0, OPTAB_LIB_WIDEN);\n@@ -5013,24 +4966,16 @@ make_tree (tree type, rtx x)\n   switch (GET_CODE (x))\n     {\n     case CONST_INT:\n-      {\n-\tHOST_WIDE_INT hi = 0;\n-\n-\tif (INTVAL (x) < 0\n-\t    && !(TYPE_UNSIGNED (type)\n-\t\t && (GET_MODE_BITSIZE (TYPE_MODE (type))\n-\t\t     < HOST_BITS_PER_WIDE_INT)))\n-\t  hi = -1;\n-\n-\tt = build_int_cst_wide (type, INTVAL (x), hi);\n-\n-\treturn t;\n-      }\n+    case CONST_WIDE_INT:\n+      t = wide_int_to_tree (type, std::make_pair (x, TYPE_MODE (type)));\n+      return t;\n \n     case CONST_DOUBLE:\n-      if (GET_MODE (x) == VOIDmode)\n-\tt = build_int_cst_wide (type,\n-\t\t\t\tCONST_DOUBLE_LOW (x), CONST_DOUBLE_HIGH (x));\n+      STATIC_ASSERT (HOST_BITS_PER_WIDE_INT * 2 <= MAX_BITSIZE_MODE_ANY_INT);\n+      if (TARGET_SUPPORTS_WIDE_INT == 0 && GET_MODE (x) == VOIDmode)\n+\tt = wide_int_to_tree (type,\n+\t\t\t      wide_int::from_array (&CONST_DOUBLE_LOW (x), 2,\n+\t\t\t\t\t\t    HOST_BITS_PER_WIDE_INT * 2));\n       else\n \t{\n \t  REAL_VALUE_TYPE d;"}, {"sha": "2868d9d3443e7ce568793d9bff453038e62f7a83", "filename": "gcc/expr.c", "status": "modified", "additions": 80, "deletions": 104, "changes": 184, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -711,64 +711,32 @@ convert_modes (enum machine_mode mode, enum machine_mode oldmode, rtx x, int uns\n   if (mode == oldmode)\n     return x;\n \n-  /* There is one case that we must handle specially: If we are converting\n-     a CONST_INT into a mode whose size is twice HOST_BITS_PER_WIDE_INT and\n-     we are to interpret the constant as unsigned, gen_lowpart will do\n-     the wrong if the constant appears negative.  What we want to do is\n-     make the high-order word of the constant zero, not all ones.  */\n-\n-  if (unsignedp && GET_MODE_CLASS (mode) == MODE_INT\n-      && GET_MODE_BITSIZE (mode) == HOST_BITS_PER_DOUBLE_INT\n-      && CONST_INT_P (x) && INTVAL (x) < 0)\n+  if (CONST_SCALAR_INT_P (x) && GET_MODE_CLASS (mode) == MODE_INT)\n     {\n-      double_int val = double_int::from_uhwi (INTVAL (x));\n-\n-      /* We need to zero extend VAL.  */\n-      if (oldmode != VOIDmode)\n-\tval = val.zext (GET_MODE_BITSIZE (oldmode));\n-\n-      return immed_double_int_const (val, mode);\n+      /* If the caller did not tell us the old mode, then there is not\n+\t much to do with respect to canonicalization.  We have to\n+\t assume that all the bits are significant.  */\n+      if (GET_MODE_CLASS (oldmode) != MODE_INT)\n+\toldmode = MAX_MODE_INT;\n+      wide_int w = wide_int::from (std::make_pair (x, oldmode),\n+\t\t\t\t   GET_MODE_PRECISION (mode),\n+\t\t\t\t   unsignedp ? UNSIGNED : SIGNED);\n+      return immed_wide_int_const (w, mode);\n     }\n \n   /* We can do this with a gen_lowpart if both desired and current modes\n      are integer, and this is either a constant integer, a register, or a\n-     non-volatile MEM.  Except for the constant case where MODE is no\n-     wider than HOST_BITS_PER_WIDE_INT, we must be narrowing the operand.  */\n-\n-  if ((CONST_INT_P (x)\n-       && GET_MODE_PRECISION (mode) <= HOST_BITS_PER_WIDE_INT)\n-      || (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && GET_MODE_CLASS (oldmode) == MODE_INT\n-\t  && (CONST_DOUBLE_AS_INT_P (x) \n-\t      || (GET_MODE_PRECISION (mode) <= GET_MODE_PRECISION (oldmode)\n-\t\t  && ((MEM_P (x) && ! MEM_VOLATILE_P (x)\n-\t\t       && direct_load[(int) mode])\n-\t\t      || (REG_P (x)\n-\t\t\t  && (! HARD_REGISTER_P (x)\n-\t\t\t      || HARD_REGNO_MODE_OK (REGNO (x), mode))\n-\t\t\t  && TRULY_NOOP_TRUNCATION_MODES_P (mode,\n-\t\t\t\t\t\t\t    GET_MODE (x))))))))\n-    {\n-      /* ?? If we don't know OLDMODE, we have to assume here that\n-\t X does not need sign- or zero-extension.   This may not be\n-\t the case, but it's the best we can do.  */\n-      if (CONST_INT_P (x) && oldmode != VOIDmode\n-\t  && GET_MODE_PRECISION (mode) > GET_MODE_PRECISION (oldmode))\n-\t{\n-\t  HOST_WIDE_INT val = INTVAL (x);\n-\n-\t  /* We must sign or zero-extend in this case.  Start by\n-\t     zero-extending, then sign extend if we need to.  */\n-\t  val &= GET_MODE_MASK (oldmode);\n-\t  if (! unsignedp\n-\t      && val_signbit_known_set_p (oldmode, val))\n-\t    val |= ~GET_MODE_MASK (oldmode);\n-\n-\t  return gen_int_mode (val, mode);\n-\t}\n-\n-      return gen_lowpart (mode, x);\n-    }\n+     non-volatile MEM. */\n+  if (GET_MODE_CLASS (mode) == MODE_INT\n+      && GET_MODE_CLASS (oldmode) == MODE_INT\n+      && GET_MODE_PRECISION (mode) <= GET_MODE_PRECISION (oldmode)\n+      && ((MEM_P (x) && !MEM_VOLATILE_P (x) && direct_load[(int) mode])\n+          || (REG_P (x)\n+              && (!HARD_REGISTER_P (x)\n+                  || HARD_REGNO_MODE_OK (REGNO (x), mode))\n+              && TRULY_NOOP_TRUNCATION_MODES_P (mode, GET_MODE (x)))))\n+\n+   return gen_lowpart (mode, x);\n \n   /* Converting from integer constant into mode is always equivalent to an\n      subreg operation.  */\n@@ -1794,6 +1762,7 @@ emit_group_load_1 (rtx *tmps, rtx dst, rtx orig_src, tree type, int ssize)\n \t    {\n \t      rtx first, second;\n \n+\t      /* TODO: const_wide_int can have sizes other than this...  */\n \t      gcc_assert (2 * len == ssize);\n \t      split_double (src, &first, &second);\n \t      if (i)\n@@ -5330,8 +5299,8 @@ store_expr (tree exp, rtx target, int call_param_p, bool nontemporal)\n \n   /* If TEMP is a VOIDmode constant and the mode of the type of EXP is not\n      the same as that of TARGET, adjust the constant.  This is needed, for\n-     example, in case it is a CONST_DOUBLE and we want only a word-sized\n-     value.  */\n+     example, in case it is a CONST_DOUBLE or CONST_WIDE_INT and we want \n+     only a word-sized value.  */\n   if (CONSTANT_P (temp) && GET_MODE (temp) == VOIDmode\n       && TREE_CODE (exp) != ERROR_MARK\n       && GET_MODE (target) != TYPE_MODE (TREE_TYPE (exp)))\n@@ -6692,7 +6661,7 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n   enum machine_mode mode = VOIDmode;\n   bool blkmode_bitfield = false;\n   tree offset = size_zero_node;\n-  double_int bit_offset = double_int_zero;\n+  offset_int bit_offset = 0;\n \n   /* First get the mode, signedness, and size.  We do this from just the\n      outermost expression.  */\n@@ -6755,7 +6724,7 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n       switch (TREE_CODE (exp))\n \t{\n \tcase BIT_FIELD_REF:\n-\t  bit_offset += tree_to_double_int (TREE_OPERAND (exp, 2));\n+\t  bit_offset += wi::to_offset (TREE_OPERAND (exp, 2));\n \t  break;\n \n \tcase COMPONENT_REF:\n@@ -6770,7 +6739,7 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n \t      break;\n \n \t    offset = size_binop (PLUS_EXPR, offset, this_offset);\n-\t    bit_offset += tree_to_double_int (DECL_FIELD_BIT_OFFSET (field));\n+\t    bit_offset += wi::to_offset (DECL_FIELD_BIT_OFFSET (field));\n \n \t    /* ??? Right now we don't do anything with DECL_OFFSET_ALIGN.  */\n \t  }\n@@ -6802,7 +6771,7 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n \t  break;\n \n \tcase IMAGPART_EXPR:\n-\t  bit_offset += double_int::from_uhwi (*pbitsize);\n+\t  bit_offset += *pbitsize;\n \t  break;\n \n \tcase VIEW_CONVERT_EXPR:\n@@ -6823,9 +6792,8 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n \t      tree off = TREE_OPERAND (exp, 1);\n \t      if (!integer_zerop (off))\n \t\t{\n-\t\t  double_int boff, coff = mem_ref_offset (exp);\n-\t\t  boff = coff.lshift (BITS_PER_UNIT == 8\n-\t\t\t\t      ? 3 : exact_log2 (BITS_PER_UNIT));\n+\t\t  offset_int boff, coff = mem_ref_offset (exp);\n+\t\t  boff = wi::lshift (coff, LOG2_BITS_PER_UNIT);\n \t\t  bit_offset += boff;\n \t\t}\n \t      exp = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n@@ -6849,11 +6817,11 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n      this conversion.  */\n   if (TREE_CODE (offset) == INTEGER_CST)\n     {\n-      double_int tem = tree_to_double_int (offset);\n-      tem = tem.sext (TYPE_PRECISION (sizetype));\n-      tem = tem.lshift (BITS_PER_UNIT == 8 ? 3 : exact_log2 (BITS_PER_UNIT));\n+      offset_int tem = wi::sext (wi::to_offset (offset),\n+\t\t\t\t TYPE_PRECISION (sizetype));\n+      tem = wi::lshift (tem, LOG2_BITS_PER_UNIT);\n       tem += bit_offset;\n-      if (tem.fits_shwi ())\n+      if (wi::fits_shwi_p (tem))\n \t{\n \t  *pbitpos = tem.to_shwi ();\n \t  *poffset = offset = NULL_TREE;\n@@ -6864,20 +6832,16 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n   if (offset)\n     {\n       /* Avoid returning a negative bitpos as this may wreak havoc later.  */\n-      if (bit_offset.is_negative ())\n+      if (wi::neg_p (bit_offset))\n         {\n-\t  double_int mask\n-\t    = double_int::mask (BITS_PER_UNIT == 8\n-\t\t\t       ? 3 : exact_log2 (BITS_PER_UNIT));\n-\t  double_int tem = bit_offset.and_not (mask);\n+\t  offset_int mask = wi::mask <offset_int> (LOG2_BITS_PER_UNIT, false);\n+\t  offset_int tem = bit_offset.and_not (mask);\n \t  /* TEM is the bitpos rounded to BITS_PER_UNIT towards -Inf.\n \t     Subtract it to BIT_OFFSET and add it (scaled) to OFFSET.  */\n \t  bit_offset -= tem;\n-\t  tem = tem.arshift (BITS_PER_UNIT == 8\n-\t\t\t     ? 3 : exact_log2 (BITS_PER_UNIT),\n-\t\t\t     HOST_BITS_PER_DOUBLE_INT);\n+\t  tem = wi::arshift (tem, LOG2_BITS_PER_UNIT);\n \t  offset = size_binop (PLUS_EXPR, offset,\n-\t\t\t       double_int_to_tree (sizetype, tem));\n+\t\t\t       wide_int_to_tree (sizetype, tem));\n \t}\n \n       *pbitpos = bit_offset.to_shwi ();\n@@ -7813,11 +7777,12 @@ expand_constructor (tree exp, rtx target, enum expand_modifier modifier,\n \n   /* All elts simple constants => refer to a constant in memory.  But\n      if this is a non-BLKmode mode, let it store a field at a time\n-     since that should make a CONST_INT or CONST_DOUBLE when we\n-     fold.  Likewise, if we have a target we can use, it is best to\n-     store directly into the target unless the type is large enough\n-     that memcpy will be used.  If we are making an initializer and\n-     all operands are constant, put it in memory as well.\n+     since that should make a CONST_INT, CONST_WIDE_INT or\n+     CONST_DOUBLE when we fold.  Likewise, if we have a target we can\n+     use, it is best to store directly into the target unless the type\n+     is large enough that memcpy will be used.  If we are making an\n+     initializer and all operands are constant, put it in memory as\n+     well.\n \n      FIXME: Avoid trying to fill vector constructors piece-meal.\n      Output them with output_constant_def below unless we're sure\n@@ -8294,17 +8259,18 @@ expand_expr_real_2 (sepops ops, rtx target, enum machine_mode tmode,\n \t      && TREE_CONSTANT (treeop1))\n \t    {\n \t      rtx constant_part;\n+\t      HOST_WIDE_INT wc;\n+\t      enum machine_mode wmode = TYPE_MODE (TREE_TYPE (treeop1));\n \n \t      op1 = expand_expr (treeop1, subtarget, VOIDmode,\n \t\t\t\t EXPAND_SUM);\n-\t      /* Use immed_double_const to ensure that the constant is\n+\t      /* Use wi::shwi to ensure that the constant is\n \t\t truncated according to the mode of OP1, then sign extended\n \t\t to a HOST_WIDE_INT.  Using the constant directly can result\n \t\t in non-canonical RTL in a 64x32 cross compile.  */\n-\t      constant_part\n-\t\t= immed_double_const (TREE_INT_CST_LOW (treeop0),\n-\t\t\t\t      (HOST_WIDE_INT) 0,\n-\t\t\t\t      TYPE_MODE (TREE_TYPE (treeop1)));\n+\t      wc = TREE_INT_CST_LOW (treeop0);\n+\t      constant_part =\n+\t\timmed_wide_int_const (wi::shwi (wc, wmode), wmode);\n \t      op1 = plus_constant (mode, op1, INTVAL (constant_part));\n \t      if (modifier != EXPAND_SUM && modifier != EXPAND_INITIALIZER)\n \t\top1 = force_operand (op1, target);\n@@ -8316,6 +8282,8 @@ expand_expr_real_2 (sepops ops, rtx target, enum machine_mode tmode,\n \t\t   && TREE_CONSTANT (treeop0))\n \t    {\n \t      rtx constant_part;\n+\t      HOST_WIDE_INT wc;\n+\t      enum machine_mode wmode = TYPE_MODE (TREE_TYPE (treeop0));\n \n \t      op0 = expand_expr (treeop0, subtarget, VOIDmode,\n \t\t\t\t (modifier == EXPAND_INITIALIZER\n@@ -8330,14 +8298,13 @@ expand_expr_real_2 (sepops ops, rtx target, enum machine_mode tmode,\n \t\t    return simplify_gen_binary (PLUS, mode, op0, op1);\n \t\t  goto binop2;\n \t\t}\n-\t      /* Use immed_double_const to ensure that the constant is\n+\t      /* Use wi::shwi to ensure that the constant is\n \t\t truncated according to the mode of OP1, then sign extended\n \t\t to a HOST_WIDE_INT.  Using the constant directly can result\n \t\t in non-canonical RTL in a 64x32 cross compile.  */\n+\t      wc = TREE_INT_CST_LOW (treeop1);\n \t      constant_part\n-\t\t= immed_double_const (TREE_INT_CST_LOW (treeop1),\n-\t\t\t\t      (HOST_WIDE_INT) 0,\n-\t\t\t\t      TYPE_MODE (TREE_TYPE (treeop0)));\n+\t\t= immed_wide_int_const (wi::shwi (wc, wmode), wmode);\n \t      op0 = plus_constant (mode, op0, INTVAL (constant_part));\n \t      if (modifier != EXPAND_SUM && modifier != EXPAND_INITIALIZER)\n \t\top0 = force_operand (op0, target);\n@@ -8860,10 +8827,14 @@ expand_expr_real_2 (sepops ops, rtx target, enum machine_mode tmode,\n \t for unsigned bitfield expand this as XOR with a proper constant\n \t instead.  */\n       if (reduce_bit_field && TYPE_UNSIGNED (type))\n-\ttemp = expand_binop (mode, xor_optab, op0,\n-\t\t\t     immed_double_int_const\n-\t\t\t       (double_int::mask (TYPE_PRECISION (type)), mode),\n-\t\t\t     target, 1, OPTAB_LIB_WIDEN);\n+\t{\n+\t  wide_int mask = wi::mask (TYPE_PRECISION (type),\n+\t\t\t\t    false, GET_MODE_PRECISION (mode));\n+\n+\t  temp = expand_binop (mode, xor_optab, op0,\n+\t\t\t       immed_wide_int_const (mask, mode),\n+\t\t\t       target, 1, OPTAB_LIB_WIDEN);\n+\t}\n       else\n \ttemp = expand_unop (mode, one_cmpl_optab, op0, target, 1);\n       gcc_assert (temp);\n@@ -9534,9 +9505,15 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       return decl_rtl;\n \n     case INTEGER_CST:\n-      temp = immed_double_const (TREE_INT_CST_LOW (exp),\n-\t\t\t\t TREE_INT_CST_HIGH (exp), mode);\n-\n+      /* Given that TYPE_PRECISION (type) is not always equal to\n+         GET_MODE_PRECISION (TYPE_MODE (type)), we need to extend from\n+         the former to the latter according to the signedness of the\n+         type. */\n+      temp = immed_wide_int_const (wide_int::from\n+\t\t\t\t   (exp,\n+\t\t\t\t    GET_MODE_PRECISION (TYPE_MODE (type)),\n+\t\t\t\t    TYPE_SIGN (type)),\n+\t\t\t\t   TYPE_MODE (type));\n       return temp;\n \n     case VECTOR_CST:\n@@ -9723,7 +9700,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t   might end up in a register.  */\n \tif (mem_ref_refers_to_non_mem_p (exp))\n \t  {\n-\t    HOST_WIDE_INT offset = mem_ref_offset (exp).low;\n+\t    HOST_WIDE_INT offset = mem_ref_offset (exp).to_short_addr ();\n \t    base = TREE_OPERAND (base, 0);\n \t    if (offset == 0\n \t\t&& tree_fits_uhwi_p (TYPE_SIZE (type))\n@@ -9758,8 +9735,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \top0 = memory_address_addr_space (mode, op0, as);\n \tif (!integer_zerop (TREE_OPERAND (exp, 1)))\n \t  {\n-\t    rtx off\n-\t      = immed_double_int_const (mem_ref_offset (exp), address_mode);\n+\t    rtx off = immed_wide_int_const (mem_ref_offset (exp), address_mode);\n \t    op0 = simplify_gen_binary (PLUS, address_mode, op0, off);\n \t    op0 = memory_address_addr_space (mode, op0, as);\n \t  }\n@@ -10649,9 +10625,10 @@ reduce_to_bit_field_precision (rtx exp, rtx target, tree type)\n     }\n   else if (TYPE_UNSIGNED (type))\n     {\n-      rtx mask = immed_double_int_const (double_int::mask (prec),\n-\t\t\t\t\t GET_MODE (exp));\n-      return expand_and (GET_MODE (exp), exp, mask, target);\n+      enum machine_mode mode = GET_MODE (exp);\n+      rtx mask = immed_wide_int_const\n+\t(wi::mask (prec, false, GET_MODE_PRECISION (mode)), mode);\n+      return expand_and (mode, exp, mask, target);\n     }\n   else\n     {\n@@ -11226,8 +11203,7 @@ const_vector_from_tree (tree exp)\n \tRTVEC_ELT (v, i) = CONST_FIXED_FROM_FIXED_VALUE (TREE_FIXED_CST (elt),\n \t\t\t\t\t\t\t inner);\n       else\n-\tRTVEC_ELT (v, i) = immed_double_int_const (tree_to_double_int (elt),\n-\t\t\t\t\t\t   inner);\n+\tRTVEC_ELT (v, i) = immed_wide_int_const (elt, inner);\n     }\n \n   return gen_rtx_CONST_VECTOR (mode, v);"}, {"sha": "327143093fe5c1baacddc093b4ca2a1d922d3ac0", "filename": "gcc/final.c", "status": "modified", "additions": 15, "deletions": 1, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffinal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffinal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffinal.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -80,6 +80,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"params.h\"\n #include \"tree-pretty-print.h\" /* for dump_function_header */\n #include \"asan.h\"\n+#include \"wide-int-print.h\"\n \n #ifdef XCOFF_DEBUGGING_INFO\n #include \"xcoffout.h\"\t\t/* Needed for external data\n@@ -3885,8 +3886,21 @@ output_addr_const (FILE *file, rtx x)\n       output_addr_const (file, XEXP (x, 0));\n       break;\n \n+    case CONST_WIDE_INT:\n+      /* We do not know the mode here so we have to use a round about\n+\t way to build a wide-int to get it printed properly.  */\n+      {\n+\twide_int w = wide_int::from_array (&CONST_WIDE_INT_ELT (x, 0),\n+\t\t\t\t\t   CONST_WIDE_INT_NUNITS (x),\n+\t\t\t\t\t   CONST_WIDE_INT_NUNITS (x)\n+\t\t\t\t\t   * HOST_BITS_PER_WIDE_INT,\n+\t\t\t\t\t   false);\n+\tprint_decs (w, file);\n+      }\n+      break;\n+\n     case CONST_DOUBLE:\n-      if (GET_MODE (x) == VOIDmode)\n+      if (CONST_DOUBLE_AS_INT_P (x))\n \t{\n \t  /* We can use %d if the number is one word and positive.  */\n \t  if (CONST_DOUBLE_HIGH (x))"}, {"sha": "7c8ae0f0113a93d8de232b0b473637995789e6aa", "filename": "gcc/fixed-value.c", "status": "modified", "additions": 21, "deletions": 7, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffixed-value.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffixed-value.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffixed-value.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -23,6 +23,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tm.h\"\n #include \"tree.h\"\n #include \"diagnostic-core.h\"\n+#include \"wide-int.h\"\n \n /* Compare two fixed objects for bitwise identity.  */\n \n@@ -113,6 +114,7 @@ fixed_from_string (FIXED_VALUE_TYPE *f, const char *str, enum machine_mode mode)\n   REAL_VALUE_TYPE real_value, fixed_value, base_value;\n   unsigned int fbit;\n   enum fixed_value_range_code temp;\n+  bool fail;\n \n   f->mode = mode;\n   fbit = GET_MODE_FBIT (mode);\n@@ -127,8 +129,10 @@ fixed_from_string (FIXED_VALUE_TYPE *f, const char *str, enum machine_mode mode)\n \t     \"large fixed-point constant implicitly truncated to fixed-point type\");\n   real_2expN (&base_value, fbit, mode);\n   real_arithmetic (&fixed_value, MULT_EXPR, &real_value, &base_value);\n-  real_to_integer2 ((HOST_WIDE_INT *)&f->data.low, &f->data.high,\n-\t\t    &fixed_value);\n+  wide_int w = real_to_integer (&fixed_value, &fail,\n+\t\t\t\tGET_MODE_PRECISION (mode));\n+  f->data.low = w.elt (0);\n+  f->data.high = w.elt (1);\n \n   if (temp == FIXED_MAX_EPS && ALL_FRACT_MODE_P (f->mode))\n     {\n@@ -153,9 +157,12 @@ fixed_to_decimal (char *str, const FIXED_VALUE_TYPE *f_orig,\n {\n   REAL_VALUE_TYPE real_value, base_value, fixed_value;\n \n+  signop sgn = UNSIGNED_FIXED_POINT_MODE_P (f_orig->mode) ? UNSIGNED : SIGNED;\n   real_2expN (&base_value, GET_MODE_FBIT (f_orig->mode), f_orig->mode);\n-  real_from_integer (&real_value, VOIDmode, f_orig->data.low, f_orig->data.high,\n-\t\t     UNSIGNED_FIXED_POINT_MODE_P (f_orig->mode));\n+  real_from_integer (&real_value, VOIDmode,\n+\t\t     wide_int::from (f_orig->data,\n+\t\t\t\t     GET_MODE_PRECISION (f_orig->mode), sgn),\n+\t\t     sgn);\n   real_arithmetic (&fixed_value, RDIV_EXPR, &real_value, &base_value);\n   real_to_decimal (str, &fixed_value, buf_size, 0, 1);\n }\n@@ -1041,12 +1048,17 @@ fixed_convert_from_real (FIXED_VALUE_TYPE *f, enum machine_mode mode,\n   int i_f_bits = GET_MODE_IBIT (mode) + GET_MODE_FBIT (mode);\n   unsigned int fbit = GET_MODE_FBIT (mode);\n   enum fixed_value_range_code temp;\n+  bool fail;\n \n   real_value = *a;\n   f->mode = mode;\n   real_2expN (&base_value, fbit, mode);\n   real_arithmetic (&fixed_value, MULT_EXPR, &real_value, &base_value);\n-  real_to_integer2 ((HOST_WIDE_INT *)&f->data.low, &f->data.high, &fixed_value);\n+\n+  wide_int w = real_to_integer (&fixed_value, &fail,\n+\t\t\t\tGET_MODE_PRECISION (mode));\n+  f->data.low = w.elt (0);\n+  f->data.high = w.elt (1);\n   temp = check_real_for_fixed_mode (&real_value, mode);\n   if (temp == FIXED_UNDERFLOW) /* Minimum.  */\n     {\n@@ -1091,9 +1103,11 @@ real_convert_from_fixed (REAL_VALUE_TYPE *r, enum machine_mode mode,\n {\n   REAL_VALUE_TYPE base_value, fixed_value, real_value;\n \n+  signop sgn = UNSIGNED_FIXED_POINT_MODE_P (f->mode) ? UNSIGNED : SIGNED;\n   real_2expN (&base_value, GET_MODE_FBIT (f->mode), f->mode);\n-  real_from_integer (&fixed_value, VOIDmode, f->data.low, f->data.high,\n-\t\t     UNSIGNED_FIXED_POINT_MODE_P (f->mode));\n+  real_from_integer (&fixed_value, VOIDmode,\n+\t\t     wide_int::from (f->data, GET_MODE_PRECISION (f->mode),\n+\t\t\t\t     sgn), sgn);\n   real_arithmetic (&real_value, RDIV_EXPR, &fixed_value, &base_value);\n   real_convert (r, mode, &real_value);\n }"}, {"sha": "831aaba683c046ac70b72b7408e5501e9863aa90", "filename": "gcc/fold-const.c", "status": "modified", "additions": 310, "deletions": 518, "changes": 828, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -116,7 +116,6 @@ static tree decode_field_reference (location_t, tree, HOST_WIDE_INT *,\n \t\t\t\t    HOST_WIDE_INT *,\n \t\t\t\t    enum machine_mode *, int *, int *,\n \t\t\t\t    tree *, tree *);\n-static int all_ones_mask_p (const_tree, int);\n static tree sign_bit_p (tree, const_tree);\n static int simple_operand_p (const_tree);\n static bool simple_operand_p_2 (tree);\n@@ -173,26 +172,18 @@ protected_set_expr_location_unshare (tree x, location_t loc)\n   return x;\n }\n \f\n-/* If ARG2 divides ARG1 with zero remainder, carries out the division\n-   of type CODE and returns the quotient.\n-   Otherwise returns NULL_TREE.  */\n+/* If ARG2 divides ARG1 with zero remainder, carries out the exact\n+   division and returns the quotient.  Otherwise returns\n+   NULL_TREE.  */\n \n tree\n-div_if_zero_remainder (enum tree_code code, const_tree arg1, const_tree arg2)\n+div_if_zero_remainder (const_tree arg1, const_tree arg2)\n {\n-  double_int quo, rem;\n-  int uns;\n+  widest_int quo;\n \n-  /* The sign of the division is according to operand two, that\n-     does the correct thing for POINTER_PLUS_EXPR where we want\n-     a signed division.  */\n-  uns = TYPE_UNSIGNED (TREE_TYPE (arg2));\n-\n-  quo = tree_to_double_int (arg1).divmod (tree_to_double_int (arg2),\n-\t\t\t\t\t  uns, code, &rem);\n-\n-  if (rem.is_zero ())\n-    return build_int_cst_wide (TREE_TYPE (arg1), quo.low, quo.high);\n+  if (wi::multiple_of_p (wi::to_widest (arg1), wi::to_widest (arg2),\n+\t\t\t SIGNED, &quo))\n+    return wide_int_to_tree (TREE_TYPE (arg1), quo);\n \n   return NULL_TREE; \n }\n@@ -366,8 +357,6 @@ negate_mathfn_p (enum built_in_function code)\n bool\n may_negate_without_overflow_p (const_tree t)\n {\n-  unsigned HOST_WIDE_INT val;\n-  unsigned int prec;\n   tree type;\n \n   gcc_assert (TREE_CODE (t) == INTEGER_CST);\n@@ -376,19 +365,7 @@ may_negate_without_overflow_p (const_tree t)\n   if (TYPE_UNSIGNED (type))\n     return false;\n \n-  prec = TYPE_PRECISION (type);\n-  if (prec > HOST_BITS_PER_WIDE_INT)\n-    {\n-      if (TREE_INT_CST_LOW (t) != 0)\n-\treturn true;\n-      prec -= HOST_BITS_PER_WIDE_INT;\n-      val = TREE_INT_CST_HIGH (t);\n-    }\n-  else\n-    val = TREE_INT_CST_LOW (t);\n-  if (prec < HOST_BITS_PER_WIDE_INT)\n-    val &= ((unsigned HOST_WIDE_INT) 1 << prec) - 1;\n-  return val != ((unsigned HOST_WIDE_INT) 1 << (prec - 1));\n+  return !wi::only_sign_bit_p (t);\n }\n \n /* Determine whether an expression T can be cheaply negated using\n@@ -526,13 +503,11 @@ negate_expr_p (tree t)\n       break;\n \n     case RSHIFT_EXPR:\n-      /* Optimize -((int)x >> 31) into (unsigned)x >> 31.  */\n+      /* Optimize -((int)x >> 31) into (unsigned)x >> 31 for int.  */\n       if (TREE_CODE (TREE_OPERAND (t, 1)) == INTEGER_CST)\n \t{\n \t  tree op1 = TREE_OPERAND (t, 1);\n-\t  if (TREE_INT_CST_HIGH (op1) == 0\n-\t      && (unsigned HOST_WIDE_INT) (TYPE_PRECISION (type) - 1)\n-\t\t == TREE_INT_CST_LOW (op1))\n+\t  if (wi::eq_p (op1, TYPE_PRECISION (type) - 1))\n \t    return true;\n \t}\n       break;\n@@ -741,13 +716,11 @@ fold_negate_expr (location_t loc, tree t)\n       break;\n \n     case RSHIFT_EXPR:\n-      /* Optimize -((int)x >> 31) into (unsigned)x >> 31.  */\n+      /* Optimize -((int)x >> 31) into (unsigned)x >> 31 for int.  */\n       if (TREE_CODE (TREE_OPERAND (t, 1)) == INTEGER_CST)\n \t{\n \t  tree op1 = TREE_OPERAND (t, 1);\n-\t  if (TREE_INT_CST_HIGH (op1) == 0\n-\t      && (unsigned HOST_WIDE_INT) (TYPE_PRECISION (type) - 1)\n-\t\t == TREE_INT_CST_LOW (op1))\n+\t  if (wi::eq_p (op1, TYPE_PRECISION (type) - 1))\n \t    {\n \t      tree ntype = TYPE_UNSIGNED (type)\n \t\t\t   ? signed_type_for (type)\n@@ -977,168 +950,150 @@ int_binop_types_match_p (enum tree_code code, const_tree type1, const_tree type2\n    to evaluate CODE at compile-time.  */\n \n static tree\n-int_const_binop_1 (enum tree_code code, const_tree arg1, const_tree arg2,\n+int_const_binop_1 (enum tree_code code, const_tree arg1, const_tree parg2,\n \t\t   int overflowable)\n {\n-  double_int op1, op2, res, tmp;\n+  wide_int res;\n   tree t;\n   tree type = TREE_TYPE (arg1);\n-  bool uns = TYPE_UNSIGNED (type);\n+  signop sign = TYPE_SIGN (type);\n   bool overflow = false;\n \n-  op1 = tree_to_double_int (arg1);\n-  op2 = tree_to_double_int (arg2);\n+  wide_int arg2 = wide_int::from (parg2, TYPE_PRECISION (type),\n+\t\t\t\t  TYPE_SIGN (TREE_TYPE (parg2)));\n \n   switch (code)\n     {\n     case BIT_IOR_EXPR:\n-      res = op1 | op2;\n+      res = wi::bit_or (arg1, arg2);\n       break;\n \n     case BIT_XOR_EXPR:\n-      res = op1 ^ op2;\n+      res = wi::bit_xor (arg1, arg2);\n       break;\n \n     case BIT_AND_EXPR:\n-      res = op1 & op2;\n+      res = wi::bit_and (arg1, arg2);\n       break;\n \n     case RSHIFT_EXPR:\n-      res = op1.rshift (op2.to_shwi (), TYPE_PRECISION (type), !uns);\n-      break;\n-\n     case LSHIFT_EXPR:\n-      /* It's unclear from the C standard whether shifts can overflow.\n-\t The following code ignores overflow; perhaps a C standard\n-\t interpretation ruling is needed.  */\n-      res = op1.lshift (op2.to_shwi (), TYPE_PRECISION (type), !uns);\n-      break;\n+      if (wi::neg_p (arg2))\n+\t{\n+\t  arg2 = -arg2;\n+\t  if (code == RSHIFT_EXPR)\n+\t    code = LSHIFT_EXPR;\n+\t  else\n+\t    code = RSHIFT_EXPR;\n+\t}\n \n-    case RROTATE_EXPR:\n-      res = op1.rrotate (op2.to_shwi (), TYPE_PRECISION (type));\n+      if (code == RSHIFT_EXPR)\n+\t/* It's unclear from the C standard whether shifts can overflow.\n+\t   The following code ignores overflow; perhaps a C standard\n+\t   interpretation ruling is needed.  */\n+\tres = wi::rshift (arg1, arg2, sign);\n+      else\n+\tres = wi::lshift (arg1, arg2);\n       break;\n \n+    case RROTATE_EXPR:\n     case LROTATE_EXPR:\n-      res = op1.lrotate (op2.to_shwi (), TYPE_PRECISION (type));\n+      if (wi::neg_p (arg2))\n+\t{\n+\t  arg2 = -arg2;\n+\t  if (code == RROTATE_EXPR)\n+\t    code = LROTATE_EXPR;\n+\t  else\n+\t    code = RROTATE_EXPR;\n+\t}\n+\n+      if (code == RROTATE_EXPR)\n+\tres = wi::rrotate (arg1, arg2);\n+      else\n+\tres = wi::lrotate (arg1, arg2);\n       break;\n \n     case PLUS_EXPR:\n-      res = op1.add_with_sign (op2, false, &overflow);\n+      res = wi::add (arg1, arg2, sign, &overflow);\n       break;\n \n     case MINUS_EXPR:\n-      res = op1.sub_with_overflow (op2, &overflow);\n+      res = wi::sub (arg1, arg2, sign, &overflow);\n       break;\n \n     case MULT_EXPR:\n-      res = op1.mul_with_sign (op2, false, &overflow);\n+      res = wi::mul (arg1, arg2, sign, &overflow);\n       break;\n \n     case MULT_HIGHPART_EXPR:\n-      if (TYPE_PRECISION (type) > HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  bool dummy_overflow;\n-\t  if (TYPE_PRECISION (type) != 2 * HOST_BITS_PER_WIDE_INT)\n-\t    return NULL_TREE;\n-\t  op1.wide_mul_with_sign (op2, uns, &res, &dummy_overflow);\n-\t}\n-      else\n-\t{\n-\t  bool dummy_overflow;\n-\t  /* MULT_HIGHPART_EXPR can't ever oveflow, as the multiplication\n-\t     is performed in twice the precision of arguments.  */\n-\t  tmp = op1.mul_with_sign (op2, false, &dummy_overflow);\n-\t  res = tmp.rshift (TYPE_PRECISION (type),\n-\t\t\t    2 * TYPE_PRECISION (type), !uns);\n-\t}\n+      res = wi::mul_high (arg1, arg2, sign);\n       break;\n \n     case TRUNC_DIV_EXPR:\n-    case FLOOR_DIV_EXPR: case CEIL_DIV_EXPR:\n     case EXACT_DIV_EXPR:\n-      /* This is a shortcut for a common special case.  */\n-      if (op2.high == 0 && (HOST_WIDE_INT) op2.low > 0\n-\t  && !TREE_OVERFLOW (arg1)\n-\t  && !TREE_OVERFLOW (arg2)\n-\t  && op1.high == 0 && (HOST_WIDE_INT) op1.low >= 0)\n-\t{\n-\t  if (code == CEIL_DIV_EXPR)\n-\t    op1.low += op2.low - 1;\n+      if (arg2 == 0)\n+\treturn NULL_TREE;\n+      res = wi::div_trunc (arg1, arg2, sign, &overflow);\n+      break;\n \n-\t  res.low = op1.low / op2.low, res.high = 0;\n-\t  break;\n-\t}\n+    case FLOOR_DIV_EXPR:\n+      if (arg2 == 0)\n+\treturn NULL_TREE;\n+      res = wi::div_floor (arg1, arg2, sign, &overflow);\n+      break;\n \n-      /* ... fall through ...  */\n+    case CEIL_DIV_EXPR:\n+      if (arg2 == 0)\n+\treturn NULL_TREE;\n+      res = wi::div_ceil (arg1, arg2, sign, &overflow);\n+      break;\n \n     case ROUND_DIV_EXPR:\n-      if (op2.is_zero ())\n+      if (arg2 == 0)\n \treturn NULL_TREE;\n-      if (op2.is_one ())\n-\t{\n-\t  res = op1;\n-\t  break;\n-\t}\n-      if (op1 == op2 && !op1.is_zero ())\n-\t{\n-\t  res = double_int_one;\n-\t  break;\n-\t}\n-      res = op1.divmod_with_overflow (op2, uns, code, &tmp, &overflow);\n+      res = wi::div_round (arg1, arg2, sign, &overflow);\n       break;\n \n     case TRUNC_MOD_EXPR:\n-    case FLOOR_MOD_EXPR: case CEIL_MOD_EXPR:\n-      /* This is a shortcut for a common special case.  */\n-      if (op2.high == 0 && (HOST_WIDE_INT) op2.low > 0\n-\t  && !TREE_OVERFLOW (arg1)\n-\t  && !TREE_OVERFLOW (arg2)\n-\t  && op1.high == 0 && (HOST_WIDE_INT) op1.low >= 0)\n-\t{\n-\t  if (code == CEIL_MOD_EXPR)\n-\t    op1.low += op2.low - 1;\n-\t  res.low = op1.low % op2.low, res.high = 0;\n-\t  break;\n-\t}\n+      if (arg2 == 0)\n+\treturn NULL_TREE;\n+      res = wi::mod_trunc (arg1, arg2, sign, &overflow);\n+      break;\n \n-      /* ... fall through ...  */\n+    case FLOOR_MOD_EXPR:\n+      if (arg2 == 0)\n+\treturn NULL_TREE;\n+      res = wi::mod_floor (arg1, arg2, sign, &overflow);\n+      break;\n \n-    case ROUND_MOD_EXPR:\n-      if (op2.is_zero ())\n+    case CEIL_MOD_EXPR:\n+      if (arg2 == 0)\n \treturn NULL_TREE;\n+      res = wi::mod_ceil (arg1, arg2, sign, &overflow);\n+      break;\n \n-      /* Check for the case the case of INT_MIN % -1 and return\n-       overflow and result = 0.  The TImode case is handled properly\n-       in double-int.  */\n-      if (TYPE_PRECISION (type) <= HOST_BITS_PER_WIDE_INT \n-\t  && !uns\n-          && op2.is_minus_one () \n-\t  && op1.high == (HOST_WIDE_INT) -1\n-\t  && (HOST_WIDE_INT) op1.low \n-\t  == (((HOST_WIDE_INT)-1) << (TYPE_PRECISION (type) - 1)))\n-\t{\n-\t  overflow = 1;\n-\t  res = double_int_zero;\n-\t}\n-      else\n-\ttmp = op1.divmod_with_overflow (op2, uns, code, &res, &overflow);\n+    case ROUND_MOD_EXPR:\n+      if (arg2 == 0)\n+\treturn NULL_TREE;\n+      res = wi::mod_round (arg1, arg2, sign, &overflow);\n       break;\n \n     case MIN_EXPR:\n-      res = op1.min (op2, uns);\n+      res = wi::min (arg1, arg2, sign);\n       break;\n \n     case MAX_EXPR:\n-      res = op1.max (op2, uns);\n+      res = wi::max (arg1, arg2, sign);\n       break;\n \n     default:\n       return NULL_TREE;\n     }\n \n-  t = force_fit_type_double (TREE_TYPE (arg1), res, overflowable,\n-\t\t\t     (!uns && overflow)\n-\t\t\t     | TREE_OVERFLOW (arg1) | TREE_OVERFLOW (arg2));\n+  t = force_fit_type (type, res, overflowable,\n+\t\t      (((sign == SIGNED || overflowable == -1)\n+\t\t\t&& overflow)\n+\t\t       | TREE_OVERFLOW (arg1) | TREE_OVERFLOW (parg2)));\n \n   return t;\n }\n@@ -1266,9 +1221,12 @@ const_binop (enum tree_code code, tree arg1, tree arg2)\n \n \tcase LSHIFT_EXPR:\n \tcase RSHIFT_EXPR:\n-\t  f2.data.high = TREE_INT_CST_HIGH (arg2);\n-\t  f2.data.low = TREE_INT_CST_LOW (arg2);\n-\t  f2.mode = SImode;\n+\t  {\n+\t    wide_int w2 = arg2;\n+\t    f2.data.high = w2.elt (1);\n+\t    f2.data.low = w2.elt (0);\n+\t    f2.mode = SImode;\n+\t  }\n \t  break;\n \n         default:\n@@ -1603,18 +1561,12 @@ size_diffop_loc (location_t loc, tree arg0, tree arg1)\n static tree\n fold_convert_const_int_from_int (tree type, const_tree arg1)\n {\n-  tree t;\n-\n   /* Given an integer constant, make new constant with new type,\n-     appropriately sign-extended or truncated.  */\n-  t = force_fit_type_double (type, tree_to_double_int (arg1),\n-\t\t\t     !POINTER_TYPE_P (TREE_TYPE (arg1)),\n-\t\t\t     (TREE_INT_CST_HIGH (arg1) < 0\n-\t\t \t      && (TYPE_UNSIGNED (type)\n-\t\t\t\t  < TYPE_UNSIGNED (TREE_TYPE (arg1))))\n-\t\t\t     | TREE_OVERFLOW (arg1));\n-\n-  return t;\n+     appropriately sign-extended or truncated.  Use widest_int\n+     so that any extension is done according ARG1's type.  */\n+  return force_fit_type (type, wi::to_widest (arg1),\n+\t\t\t !POINTER_TYPE_P (TREE_TYPE (arg1)),\n+\t\t\t TREE_OVERFLOW (arg1));\n }\n \n /* A subroutine of fold_convert_const handling conversions a REAL_CST\n@@ -1623,7 +1575,7 @@ fold_convert_const_int_from_int (tree type, const_tree arg1)\n static tree\n fold_convert_const_int_from_real (enum tree_code code, tree type, const_tree arg1)\n {\n-  int overflow = 0;\n+  bool overflow = false;\n   tree t;\n \n   /* The following code implements the floating point to integer\n@@ -1635,7 +1587,7 @@ fold_convert_const_int_from_real (enum tree_code code, tree type, const_tree arg\n      C and C++ standards that simply state that the behavior of\n      FP-to-integer conversion is unspecified upon overflow.  */\n \n-  double_int val;\n+  wide_int val;\n   REAL_VALUE_TYPE r;\n   REAL_VALUE_TYPE x = TREE_REAL_CST (arg1);\n \n@@ -1652,8 +1604,8 @@ fold_convert_const_int_from_real (enum tree_code code, tree type, const_tree arg\n   /* If R is NaN, return zero and show we have an overflow.  */\n   if (REAL_VALUE_ISNAN (r))\n     {\n-      overflow = 1;\n-      val = double_int_zero;\n+      overflow = true;\n+      val = wi::zero (TYPE_PRECISION (type));\n     }\n \n   /* See if R is less than the lower bound or greater than the\n@@ -1665,8 +1617,8 @@ fold_convert_const_int_from_real (enum tree_code code, tree type, const_tree arg\n       REAL_VALUE_TYPE l = real_value_from_int_cst (NULL_TREE, lt);\n       if (REAL_VALUES_LESS (r, l))\n \t{\n-\t  overflow = 1;\n-\t  val = tree_to_double_int (lt);\n+\t  overflow = true;\n+\t  val = lt;\n \t}\n     }\n \n@@ -1678,16 +1630,16 @@ fold_convert_const_int_from_real (enum tree_code code, tree type, const_tree arg\n \t  REAL_VALUE_TYPE u = real_value_from_int_cst (NULL_TREE, ut);\n \t  if (REAL_VALUES_LESS (u, r))\n \t    {\n-\t      overflow = 1;\n-\t      val = tree_to_double_int (ut);\n+\t      overflow = true;\n+\t      val = ut;\n \t    }\n \t}\n     }\n \n   if (! overflow)\n-    real_to_integer2 ((HOST_WIDE_INT *) &val.low, &val.high, &r);\n+    val = real_to_integer (&r, &overflow, TYPE_PRECISION (type));\n \n-  t = force_fit_type_double (type, val, -1, overflow | TREE_OVERFLOW (arg1));\n+  t = force_fit_type (type, val, -1, overflow | TREE_OVERFLOW (arg1));\n   return t;\n }\n \n@@ -1730,11 +1682,11 @@ fold_convert_const_int_from_fixed (tree type, const_tree arg1)\n \n   /* Given a fixed-point constant, make new constant with new type,\n      appropriately sign-extended or truncated.  */\n-  t = force_fit_type_double (type, temp, -1,\n-\t\t\t     (temp.is_negative ()\n-\t\t \t      && (TYPE_UNSIGNED (type)\n-\t\t\t\t  < TYPE_UNSIGNED (TREE_TYPE (arg1))))\n-\t\t\t     | TREE_OVERFLOW (arg1));\n+  t = force_fit_type (type, temp, -1,\n+\t\t      (temp.is_negative ()\n+\t\t       && (TYPE_UNSIGNED (type)\n+\t\t\t   < TYPE_UNSIGNED (TREE_TYPE (arg1))))\n+\t\t      | TREE_OVERFLOW (arg1));\n \n   return t;\n }\n@@ -1817,9 +1769,17 @@ fold_convert_const_fixed_from_int (tree type, const_tree arg1)\n   FIXED_VALUE_TYPE value;\n   tree t;\n   bool overflow_p;\n+  double_int di;\n \n-  overflow_p = fixed_convert_from_int (&value, TYPE_MODE (type),\n-\t\t\t\t       TREE_INT_CST (arg1),\n+  gcc_assert (TREE_INT_CST_NUNITS (arg1) <= 2);\n+\n+  di.low = TREE_INT_CST_ELT (arg1, 0);\n+  if (TREE_INT_CST_NUNITS (arg1) == 1)\n+    di.high = (HOST_WIDE_INT) di.low < 0 ? (HOST_WIDE_INT) -1 : 0;\n+  else\n+    di.high = TREE_INT_CST_ELT (arg1, 1);\n+\n+  overflow_p = fixed_convert_from_int (&value, TYPE_MODE (type), di,\n \t\t\t\t       TYPE_UNSIGNED (TREE_TYPE (arg1)),\n \t\t\t\t       TYPE_SATURATING (type));\n   t = build_fixed (type, value);\n@@ -3715,23 +3675,24 @@ decode_field_reference (location_t loc, tree exp, HOST_WIDE_INT *pbitsize,\n }\n \n /* Return nonzero if MASK represents a mask of SIZE ones in the low-order\n-   bit positions.  */\n+   bit positions and MASK is SIGNED.  */\n \n static int\n-all_ones_mask_p (const_tree mask, int size)\n+all_ones_mask_p (const_tree mask, unsigned int size)\n {\n   tree type = TREE_TYPE (mask);\n   unsigned int precision = TYPE_PRECISION (type);\n-  tree tmask;\n \n-  tmask = build_int_cst_type (signed_type_for (type), -1);\n+  /* If this function returns true when the type of the mask is\n+     UNSIGNED, then there will be errors.  In particular see\n+     gcc.c-torture/execute/990326-1.c.  There does not appear to be\n+     any documentation paper trail as to why this is so.  But the pre\n+     wide-int worked with that restriction and it has been preserved\n+     here.  */\n+  if (size > precision || TYPE_SIGN (type) == UNSIGNED)\n+    return false;\n \n-  return\n-    tree_int_cst_equal (mask,\n-\t\t\tconst_binop (RSHIFT_EXPR,\n-\t\t\t\t     const_binop (LSHIFT_EXPR, tmask,\n-\t\t\t\t\t\t  size_int (precision - size)),\n-\t\t\t\t     size_int (precision - size)));\n+  return wi::mask (size, false, precision) == mask;\n }\n \n /* Subroutine for fold: determine if VAL is the INTEGER_CONST that\n@@ -3743,8 +3704,6 @@ all_ones_mask_p (const_tree mask, int size)\n static tree\n sign_bit_p (tree exp, const_tree val)\n {\n-  unsigned HOST_WIDE_INT mask_lo, lo;\n-  HOST_WIDE_INT mask_hi, hi;\n   int width;\n   tree t;\n \n@@ -3759,27 +3718,7 @@ sign_bit_p (tree exp, const_tree val)\n     return NULL_TREE;\n \n   width = TYPE_PRECISION (t);\n-  if (width > HOST_BITS_PER_WIDE_INT)\n-    {\n-      hi = (unsigned HOST_WIDE_INT) 1 << (width - HOST_BITS_PER_WIDE_INT - 1);\n-      lo = 0;\n-\n-      mask_hi = (HOST_WIDE_INT_M1U >> (HOST_BITS_PER_DOUBLE_INT - width));\n-      mask_lo = -1;\n-    }\n-  else\n-    {\n-      hi = 0;\n-      lo = (unsigned HOST_WIDE_INT) 1 << (width - 1);\n-\n-      mask_hi = 0;\n-      mask_lo = (HOST_WIDE_INT_M1U >> (HOST_BITS_PER_WIDE_INT - width));\n-    }\n-\n-  /* We mask off those bits beyond TREE_TYPE (exp) so that we can\n-     treat VAL as if it were unsigned.  */\n-  if ((TREE_INT_CST_HIGH (val) & mask_hi) == hi\n-      && (TREE_INT_CST_LOW (val) & mask_lo) == lo)\n+  if (wi::only_sign_bit_p (val, width))\n     return exp;\n \n   /* Handle extension from a narrower type.  */\n@@ -4024,7 +3963,7 @@ make_range_step (location_t loc, enum tree_code code, tree arg0, tree arg1,\n \t    {\n \t      in_p = ! in_p;\n \t      high = range_binop (MINUS_EXPR, NULL_TREE, low, 0,\n-\t\t\t\t  integer_one_node, 0);\n+\t\t\t\t  build_int_cst (TREE_TYPE (low), 1), 0);\n \t      low = build_int_cst (arg0_type, 0);\n \t    }\n \t}\n@@ -4094,9 +4033,9 @@ make_range_step (location_t loc, enum tree_code code, tree arg0, tree arg1,\n \tif (n_low && n_high && tree_int_cst_lt (n_high, n_low))\n \t  {\n \t    low = range_binop (PLUS_EXPR, arg0_type, n_high, 0,\n-\t\t\t       integer_one_node, 0);\n+\t\t\t       build_int_cst (TREE_TYPE (n_high), 1), 0);\n \t    high = range_binop (MINUS_EXPR, arg0_type, n_low, 0,\n-\t\t\t\tinteger_one_node, 0);\n+\t\t\t\tbuild_int_cst (TREE_TYPE (n_low), 1), 0);\n \n \t    /* If the range is of the form +/- [ x+1, x ], we won't\n \t       be able to normalize it.  But then, it represents the\n@@ -4334,23 +4273,9 @@ build_range_check (location_t loc, tree type, tree exp, int in_p,\n   /* Optimize (c>=1) && (c<=127) into (signed char)c > 0.  */\n   if (integer_onep (low) && TREE_CODE (high) == INTEGER_CST)\n     {\n-      unsigned HOST_WIDE_INT lo;\n-      HOST_WIDE_INT hi;\n-      int prec;\n-\n-      prec = TYPE_PRECISION (etype);\n-      if (prec <= HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  hi = 0;\n-\t  lo = ((unsigned HOST_WIDE_INT) 1 << (prec - 1)) - 1;\n-\t}\n-      else\n-\t{\n-\t  hi = ((HOST_WIDE_INT) 1 << (prec - HOST_BITS_PER_WIDE_INT - 1)) - 1;\n-\t  lo = HOST_WIDE_INT_M1U;\n-\t}\n+      int prec = TYPE_PRECISION (etype);\n \n-      if (TREE_INT_CST_HIGH (high) == hi && TREE_INT_CST_LOW (high) == lo)\n+      if (wi::mask (prec - 1, false, prec) == high)\n \t{\n \t  if (TYPE_UNSIGNED (etype))\n \t    {\n@@ -4384,7 +4309,7 @@ build_range_check (location_t loc, tree type, tree exp, int in_p,\n       utype = unsigned_type_for (etype);\n       maxv = fold_convert_loc (loc, utype, TYPE_MAX_VALUE (etype));\n       maxv = range_binop (PLUS_EXPR, NULL_TREE, maxv, 1,\n-\t\t\t  integer_one_node, 1);\n+\t\t\t  build_int_cst (TREE_TYPE (maxv), 1), 1);\n       minv = fold_convert_loc (loc, utype, TYPE_MIN_VALUE (etype));\n \n       if (integer_zerop (range_binop (NE_EXPR, integer_type_node,\n@@ -4432,7 +4357,8 @@ range_predecessor (tree val)\n       && operand_equal_p (val, TYPE_MIN_VALUE (type), 0))\n     return 0;\n   else\n-    return range_binop (MINUS_EXPR, NULL_TREE, val, 0, integer_one_node, 0);\n+    return range_binop (MINUS_EXPR, NULL_TREE, val, 0,\n+\t\t\tbuild_int_cst (TREE_TYPE (val), 1), 0);\n }\n \n /* Return the successor of VAL in its type, handling the infinite case.  */\n@@ -4446,7 +4372,8 @@ range_successor (tree val)\n       && operand_equal_p (val, TYPE_MAX_VALUE (type), 0))\n     return 0;\n   else\n-    return range_binop (PLUS_EXPR, NULL_TREE, val, 0, integer_one_node, 0);\n+    return range_binop (PLUS_EXPR, NULL_TREE, val, 0,\n+\t\t\tbuild_int_cst (TREE_TYPE (val), 1), 0);\n }\n \n /* Given two ranges, see if we can merge them into one.  Return 1 if we\n@@ -4626,7 +4553,8 @@ merge_ranges (int *pin_p, tree *plow, tree *phigh, int in0_p, tree low0,\n \t\t    if (TYPE_UNSIGNED (TREE_TYPE (high1))\n \t\t\t&& integer_zerop (range_binop (PLUS_EXPR, NULL_TREE,\n \t\t\t\t\t\t       high1, 1,\n-\t\t\t\t\t\t       integer_one_node, 1)))\n+\t\t\t\t\t\t       build_int_cst (TREE_TYPE (high1), 1),\n+\t\t\t\t\t\t       1)))\n \t\t      high1 = 0;\n \t\t    break;\n \t\t  default:\n@@ -5082,8 +5010,7 @@ unextend (tree c, int p, int unsignedp, tree mask)\n   /* We work by getting just the sign bit into the low-order bit, then\n      into the high-order bit, then sign-extend.  We then XOR that value\n      with C.  */\n-  temp = const_binop (RSHIFT_EXPR, c, size_int (p - 1));\n-  temp = const_binop (BIT_AND_EXPR, temp, size_int (1));\n+  temp = build_int_cst (TREE_TYPE (c), wi::extract_uhwi (c, p - 1, 1));\n \n   /* We must use a signed type in order to get an arithmetic right shift.\n      However, we must also avoid introducing accidental overflows, so that\n@@ -5889,8 +5816,7 @@ extract_muldiv_1 (tree t, tree c, enum tree_code code, tree wide_type,\n \t  && (tcode == RSHIFT_EXPR || TYPE_UNSIGNED (TREE_TYPE (op0)))\n \t  /* const_binop may not detect overflow correctly,\n \t     so check for it explicitly here.  */\n-\t  && TYPE_PRECISION (TREE_TYPE (size_one_node)) > TREE_INT_CST_LOW (op1)\n-\t  && TREE_INT_CST_HIGH (op1) == 0\n+\t  && wi::gtu_p (TYPE_PRECISION (TREE_TYPE (size_one_node)), op1)\n \t  && 0 != (t1 = fold_convert (ctype,\n \t\t\t\t      const_binop (LSHIFT_EXPR,\n \t\t\t\t\t\t   size_one_node,\n@@ -6036,21 +5962,17 @@ extract_muldiv_1 (tree t, tree c, enum tree_code code, tree wide_type,\n \t assuming no overflow.  */\n       if (tcode == code)\n \t{\n-\t  double_int mul;\n-\t  bool overflow_p;\n-\t  unsigned prec = TYPE_PRECISION (ctype);\n-\t  bool uns = TYPE_UNSIGNED (ctype);\n-\t  double_int diop1 = tree_to_double_int (op1).ext (prec, uns);\n-\t  double_int dic = tree_to_double_int (c).ext (prec, uns);\n-\t  mul = diop1.mul_with_sign (dic, false, &overflow_p);\n-\t  overflow_p = ((!uns && overflow_p)\n-\t\t\t| TREE_OVERFLOW (c) | TREE_OVERFLOW (op1));\n-\t  if (!double_int_fits_to_tree_p (ctype, mul)\n-\t      && ((uns && tcode != MULT_EXPR) || !uns))\n-\t    overflow_p = 1;\n+\t  bool overflow_p = false;\n+\t  bool overflow_mul_p;\n+\t  signop sign = TYPE_SIGN (ctype);\n+\t  wide_int mul = wi::mul (op1, c, sign, &overflow_mul_p);\n+\t  overflow_p = TREE_OVERFLOW (c) | TREE_OVERFLOW (op1);\n+\t  if (overflow_mul_p\n+\t      && ((sign == UNSIGNED && tcode != MULT_EXPR) || sign == SIGNED))\n+\t    overflow_p = true;\n \t  if (!overflow_p)\n \t    return fold_build2 (tcode, ctype, fold_convert (ctype, op0),\n-\t\t\t\tdouble_int_to_tree (ctype, mul));\n+\t\t\t\twide_int_to_tree (ctype, mul));\n \t}\n \n       /* If these operations \"cancel\" each other, we have the main\n@@ -6449,29 +6371,26 @@ fold_div_compare (location_t loc,\n   tree prod, tmp, hi, lo;\n   tree arg00 = TREE_OPERAND (arg0, 0);\n   tree arg01 = TREE_OPERAND (arg0, 1);\n-  double_int val;\n-  bool unsigned_p = TYPE_UNSIGNED (TREE_TYPE (arg0));\n-  bool neg_overflow;\n+  signop sign = TYPE_SIGN (TREE_TYPE (arg0));\n+  bool neg_overflow = false;\n   bool overflow;\n \n   /* We have to do this the hard way to detect unsigned overflow.\n      prod = int_const_binop (MULT_EXPR, arg01, arg1);  */\n-  val = TREE_INT_CST (arg01)\n-\t.mul_with_sign (TREE_INT_CST (arg1), unsigned_p, &overflow);\n-  prod = force_fit_type_double (TREE_TYPE (arg00), val, -1, overflow);\n+  wide_int val = wi::mul (arg01, arg1, sign, &overflow);\n+  prod = force_fit_type (TREE_TYPE (arg00), val, -1, overflow);\n   neg_overflow = false;\n \n-  if (unsigned_p)\n+  if (sign == UNSIGNED)\n     {\n       tmp = int_const_binop (MINUS_EXPR, arg01,\n                              build_int_cst (TREE_TYPE (arg01), 1));\n       lo = prod;\n \n       /* Likewise hi = int_const_binop (PLUS_EXPR, prod, tmp).  */\n-      val = TREE_INT_CST (prod)\n-\t    .add_with_sign (TREE_INT_CST (tmp), unsigned_p, &overflow);\n-      hi = force_fit_type_double (TREE_TYPE (arg00), val,\n-\t\t\t\t  -1, overflow | TREE_OVERFLOW (prod));\n+      val = wi::add (prod, tmp, sign, &overflow);\n+      hi = force_fit_type (TREE_TYPE (arg00), val,\n+\t\t\t   -1, overflow | TREE_OVERFLOW (prod));\n     }\n   else if (tree_int_cst_sgn (arg01) >= 0)\n     {\n@@ -6662,10 +6581,9 @@ fold_single_bit_test (location_t loc, enum tree_code code,\n \t not overflow, adjust BITNUM and INNER.  */\n       if (TREE_CODE (inner) == RSHIFT_EXPR\n \t  && TREE_CODE (TREE_OPERAND (inner, 1)) == INTEGER_CST\n-\t  && tree_fits_uhwi_p (TREE_OPERAND (inner, 1))\n \t  && bitnum < TYPE_PRECISION (type)\n-\t  && (tree_to_uhwi (TREE_OPERAND (inner, 1))\n-\t      < (unsigned) (TYPE_PRECISION (type) - bitnum)))\n+\t  && wi::ltu_p (TREE_OPERAND (inner, 1),\n+\t\t\tTYPE_PRECISION (type) - bitnum))\n \t{\n \t  bitnum += tree_to_uhwi (TREE_OPERAND (inner, 1));\n \t  inner = TREE_OPERAND (inner, 0);\n@@ -6925,8 +6843,8 @@ fold_sign_changed_comparison (location_t loc, enum tree_code code, tree type,\n     return NULL_TREE;\n \n   if (TREE_CODE (arg1) == INTEGER_CST)\n-    arg1 = force_fit_type_double (inner_type, tree_to_double_int (arg1),\n-\t\t\t\t  0, TREE_OVERFLOW (arg1));\n+    arg1 = force_fit_type (inner_type, wi::to_widest (arg1), 0,\n+\t\t\t   TREE_OVERFLOW (arg1));\n   else\n     arg1 = fold_convert_loc (loc, inner_type, arg1);\n \n@@ -7014,7 +6932,7 @@ try_move_mult_to_index (location_t loc, tree addr, tree op1)\n       else\n \t{\n \t  /* Try if delta is a multiple of step.  */\n-\t  tree tmp = div_if_zero_remainder (EXACT_DIV_EXPR, op1, step);\n+\t  tree tmp = div_if_zero_remainder (op1, step);\n \t  if (! tmp)\n \t    goto cont;\n \t  delta = tmp;\n@@ -7086,7 +7004,7 @@ try_move_mult_to_index (location_t loc, tree addr, tree op1)\n \t  else\n \t    {\n \t      /* Try if delta is a multiple of step.  */\n-\t      tree tmp = div_if_zero_remainder (EXACT_DIV_EXPR, op1, step);\n+\t      tree tmp = div_if_zero_remainder (op1, step);\n \t      if (! tmp)\n \t\tcontinue;\n \t      delta = tmp;\n@@ -7242,7 +7160,7 @@ fold_plusminus_mult_expr (location_t loc, enum tree_code code, tree type,\n       arg10 = build_one_cst (type);\n       /* As we canonicalize A - 2 to A + -2 get rid of that sign for\n \t the purpose of this canonicalization.  */\n-      if (TREE_INT_CST_HIGH (arg1) == -1\n+      if (wi::neg_p (arg1, TYPE_SIGN (TREE_TYPE (arg1)))\n \t  && negate_expr_p (arg1)\n \t  && code == PLUS_EXPR)\n \t{\n@@ -7340,11 +7258,9 @@ native_encode_int (const_tree expr, unsigned char *ptr, int len)\n   for (byte = 0; byte < total_bytes; byte++)\n     {\n       int bitpos = byte * BITS_PER_UNIT;\n-      if (bitpos < HOST_BITS_PER_WIDE_INT)\n-\tvalue = (unsigned char) (TREE_INT_CST_LOW (expr) >> bitpos);\n-      else\n-\tvalue = (unsigned char) (TREE_INT_CST_HIGH (expr)\n-\t\t\t\t >> (bitpos - HOST_BITS_PER_WIDE_INT));\n+      /* Extend EXPR according to TYPE_SIGN if the precision isn't a whole\n+\t number of bytes.  */\n+      value = wi::extract_uhwi (wi::to_widest (expr), bitpos, BITS_PER_UNIT);\n \n       if (total_bytes > UNITS_PER_WORD)\n \t{\n@@ -7566,15 +7482,14 @@ static tree\n native_interpret_int (tree type, const unsigned char *ptr, int len)\n {\n   int total_bytes = GET_MODE_SIZE (TYPE_MODE (type));\n-  double_int result;\n \n   if (total_bytes > len\n       || total_bytes * BITS_PER_UNIT > HOST_BITS_PER_DOUBLE_INT)\n     return NULL_TREE;\n \n-  result = double_int::from_buffer (ptr, total_bytes);\n+  wide_int result = wi::from_buffer (ptr, total_bytes);\n \n-  return double_int_to_tree (type, result);\n+  return wide_int_to_tree (type, result);\n }\n \n \n@@ -8139,10 +8054,10 @@ fold_unary_loc (location_t loc, enum tree_code code, tree type, tree op0)\n \t    }\n \t  if (change)\n \t    {\n-\t      tem = force_fit_type_double (type, tree_to_double_int (and1),\n-\t\t\t\t\t   0, TREE_OVERFLOW (and1));\n+\t      tem = force_fit_type (type, wi::to_widest (and1), 0,\n+\t\t\t\t    TREE_OVERFLOW (and1));\n \t      return fold_build2_loc (loc, BIT_AND_EXPR, type,\n-\t\t\t\t  fold_convert_loc (loc, type, and0), tem);\n+\t\t\t\t      fold_convert_loc (loc, type, and0), tem);\n \t    }\n \t}\n \n@@ -8922,28 +8837,28 @@ maybe_canonicalize_comparison (location_t loc, enum tree_code code, tree type,\n static bool\n pointer_may_wrap_p (tree base, tree offset, HOST_WIDE_INT bitpos)\n {\n-  double_int di_offset, total;\n-\n   if (!POINTER_TYPE_P (TREE_TYPE (base)))\n     return true;\n \n   if (bitpos < 0)\n     return true;\n \n+  wide_int wi_offset;\n+  int precision = TYPE_PRECISION (TREE_TYPE (base));\n   if (offset == NULL_TREE)\n-    di_offset = double_int_zero;\n+    wi_offset = wi::zero (precision);\n   else if (TREE_CODE (offset) != INTEGER_CST || TREE_OVERFLOW (offset))\n     return true;\n   else\n-    di_offset = TREE_INT_CST (offset);\n+    wi_offset = offset;\n \n   bool overflow;\n-  double_int units = double_int::from_uhwi (bitpos / BITS_PER_UNIT);\n-  total = di_offset.add_with_sign (units, true, &overflow);\n+  wide_int units = wi::shwi (bitpos / BITS_PER_UNIT, precision);\n+  wide_int total = wi::add (wi_offset, units, UNSIGNED, &overflow);\n   if (overflow)\n     return true;\n \n-  if (total.high != 0)\n+  if (!wi::fits_uhwi_p (total))\n     return true;\n \n   HOST_WIDE_INT size = int_size_in_bytes (TREE_TYPE (TREE_TYPE (base)));\n@@ -8961,7 +8876,7 @@ pointer_may_wrap_p (tree base, tree offset, HOST_WIDE_INT bitpos)\n \tsize = base_size;\n     }\n \n-  return total.low > (unsigned HOST_WIDE_INT) size;\n+  return total.to_uhwi () > (unsigned HOST_WIDE_INT) size;\n }\n \n /* Return the HOST_WIDE_INT least significant bits of T, a sizetype\n@@ -8971,8 +8886,11 @@ pointer_may_wrap_p (tree base, tree offset, HOST_WIDE_INT bitpos)\n static HOST_WIDE_INT\n size_low_cst (const_tree t)\n {\n-  double_int d = tree_to_double_int (t);\n-  return d.sext (TYPE_PRECISION (TREE_TYPE (t))).low;\n+  HOST_WIDE_INT w = TREE_INT_CST_ELT (t, 0);\n+  int prec = TYPE_PRECISION (TREE_TYPE (t));\n+  if (prec < HOST_BITS_PER_WIDE_INT)\n+    return sext_hwi (w, prec);\n+  return w;\n }\n \n /* Subroutine of fold_binary.  This routine performs all of the\n@@ -9966,19 +9884,12 @@ exact_inverse (tree type, tree cst)\n \n /*  Mask out the tz least significant bits of X of type TYPE where\n     tz is the number of trailing zeroes in Y.  */\n-static double_int\n-mask_with_tz (tree type, double_int x, double_int y)\n+static wide_int\n+mask_with_tz (tree type, const wide_int &x, const wide_int &y)\n {\n-  int tz = y.trailing_zeros ();\n-\n+  int tz = wi::ctz (y);\n   if (tz > 0)\n-    {\n-      double_int mask;\n-\n-      mask = ~double_int::mask (tz);\n-      mask = mask.ext (TYPE_PRECISION (type), TYPE_UNSIGNED (type));\n-      return mask & x;\n-    }\n+    return wi::mask (tz, true, TYPE_PRECISION (type)) & x;\n   return x;\n }\n \n@@ -10633,9 +10544,7 @@ fold_binary_loc (location_t loc,\n \t    code11 = TREE_CODE (tree11);\n \t    if (code01 == INTEGER_CST\n \t\t&& code11 == INTEGER_CST\n-\t\t&& TREE_INT_CST_HIGH (tree01) == 0\n-\t\t&& TREE_INT_CST_HIGH (tree11) == 0\n-\t\t&& ((TREE_INT_CST_LOW (tree01) + TREE_INT_CST_LOW (tree11))\n+\t\t&& (wi::to_widest (tree01) + wi::to_widest (tree11)\n \t\t    == element_precision (TREE_TYPE (TREE_OPERAND (arg0, 0)))))\n \t      {\n \t\ttem = build2_loc (loc, LROTATE_EXPR,\n@@ -11424,21 +11333,20 @@ fold_binary_loc (location_t loc,\n \t  && TREE_CODE (arg1) == INTEGER_CST\n \t  && TREE_CODE (TREE_OPERAND (arg0, 1)) == INTEGER_CST)\n \t{\n-\t  double_int c1, c2, c3, msk;\n \t  int width = TYPE_PRECISION (type), w;\n-\n-\t  c1 = tree_to_double_int (TREE_OPERAND (arg0, 1));\n-\t  c2 = tree_to_double_int (arg1);\n+\t  wide_int c1 = TREE_OPERAND (arg0, 1);\n+\t  wide_int c2 = arg1;\n \n \t  /* If (C1&C2) == C1, then (X&C1)|C2 becomes (X,C2).  */\n \t  if ((c1 & c2) == c1)\n \t    return omit_one_operand_loc (loc, type, arg1,\n \t\t\t\t\t TREE_OPERAND (arg0, 0));\n \n-\t  msk = double_int::mask (width);\n+\t  wide_int msk = wi::mask (width, false,\n+\t\t\t\t   TYPE_PRECISION (TREE_TYPE (arg1)));\n \n \t  /* If (C1|C2) == ~0 then (X&C1)|C2 becomes X|C2.  */\n-\t  if (msk.and_not (c1 | c2).is_zero ())\n+\t  if (msk.and_not (c1 | c2) == 0)\n \t    return fold_build2_loc (loc, BIT_IOR_EXPR, type,\n \t\t\t\t    TREE_OPERAND (arg0, 0), arg1);\n \n@@ -11447,17 +11355,14 @@ fold_binary_loc (location_t loc,\n \t     mode which allows further optimizations.  */\n \t  c1 &= msk;\n \t  c2 &= msk;\n-\t  c3 = c1.and_not (c2);\n-\t  for (w = BITS_PER_UNIT;\n-\t       w <= width && w <= HOST_BITS_PER_WIDE_INT;\n-\t       w <<= 1)\n+\t  wide_int c3 = c1.and_not (c2);\n+\t  for (w = BITS_PER_UNIT; w <= width; w <<= 1)\n \t    {\n-\t      unsigned HOST_WIDE_INT mask\n-\t\t= HOST_WIDE_INT_M1U >> (HOST_BITS_PER_WIDE_INT - w);\n-\t      if (((c1.low | c2.low) & mask) == mask\n-\t\t  && (c1.low & ~mask) == 0 && c1.high == 0)\n+\t      wide_int mask = wi::mask (width - w, false,\n+\t\t\t\t\tTYPE_PRECISION (type));\n+\t      if (((c1 | c2) & mask) == mask && c1.and_not (mask) == 0)\n \t\t{\n-\t\t  c3 = double_int::from_uhwi (mask);\n+\t\t  c3 = mask;\n \t\t  break;\n \t\t}\n \t    }\n@@ -11466,8 +11371,8 @@ fold_binary_loc (location_t loc,\n \t    return fold_build2_loc (loc, BIT_IOR_EXPR, type,\n \t\t\t\t    fold_build2_loc (loc, BIT_AND_EXPR, type,\n \t\t\t\t\t\t     TREE_OPERAND (arg0, 0),\n-\t\t\t\t\t\t     double_int_to_tree (type,\n-\t\t\t\t\t\t\t\t\t c3)),\n+\t\t\t\t\t\t     wide_int_to_tree (type,\n+\t\t\t\t\t\t\t\t       c3)),\n \t\t\t\t    arg1);\n \t}\n \n@@ -11837,12 +11742,11 @@ fold_binary_loc (location_t loc,\n          multiple of 1 << CST.  */\n       if (TREE_CODE (arg1) == INTEGER_CST)\n \t{\n-\t  double_int cst1 = tree_to_double_int (arg1);\n-\t  double_int ncst1 = (-cst1).ext (TYPE_PRECISION (TREE_TYPE (arg1)),\n-\t\t\t\t\t  TYPE_UNSIGNED (TREE_TYPE (arg1)));\n+\t  wide_int cst1 = arg1;\n+\t  wide_int ncst1 = -cst1;\n \t  if ((cst1 & ncst1) == ncst1\n \t      && multiple_of_p (type, arg0,\n-\t\t\t\tdouble_int_to_tree (TREE_TYPE (arg1), ncst1)))\n+\t\t\t\twide_int_to_tree (TREE_TYPE (arg1), ncst1)))\n \t    return fold_convert_loc (loc, type, arg0);\n \t}\n \n@@ -11852,24 +11756,22 @@ fold_binary_loc (location_t loc,\n \t  && TREE_CODE (arg0) == MULT_EXPR\n \t  && TREE_CODE (TREE_OPERAND (arg0, 1)) == INTEGER_CST)\n \t{\n-\t  double_int darg1 = tree_to_double_int (arg1);\n-\t  double_int masked\n-\t    = mask_with_tz (type, darg1,\n-\t                    tree_to_double_int (TREE_OPERAND (arg0, 1)));\n+\t  wide_int warg1 = arg1;\n+\t  wide_int masked = mask_with_tz (type, warg1, TREE_OPERAND (arg0, 1));\n \n-\t  if (masked.is_zero ())\n+\t  if (masked == 0)\n \t    return omit_two_operands_loc (loc, type, build_zero_cst (type),\n \t                                  arg0, arg1);\n-\t  else if (masked != darg1)\n+\t  else if (masked != warg1)\n \t    {\n \t      /* Avoid the transform if arg1 is a mask of some\n \t         mode which allows further optimizations.  */\n-\t      int pop = darg1.popcount ();\n+\t      int pop = wi::popcount (warg1);\n \t      if (!(pop >= BITS_PER_UNIT\n \t\t    && exact_log2 (pop) != -1\n-\t\t    && double_int::mask (pop) == darg1))\n+\t\t    && wi::mask (pop, false, warg1.get_precision ()) == warg1))\n \t\treturn fold_build2_loc (loc, code, type, op0,\n-\t\t\t\t\tdouble_int_to_tree (type, masked));\n+\t\t\t\t\twide_int_to_tree (type, masked));\n \t    }\n \t}\n \n@@ -11880,10 +11782,10 @@ fold_binary_loc (location_t loc,\n \t and for - instead of + (or unary - instead of +)\n \t and/or ^ instead of |.\n \t If B is constant and (B & M) == 0, fold into A & M.  */\n-      if (tree_fits_uhwi_p (arg1))\n+      if (TREE_CODE (arg1) == INTEGER_CST)\n \t{\n-\t  unsigned HOST_WIDE_INT cst1 = tree_to_uhwi (arg1);\n-\t  if (~cst1 && (cst1 & (cst1 + 1)) == 0\n+\t  wide_int cst1 = arg1;\n+\t  if ((~cst1 != 0) && (cst1 & (cst1 + 1)) == 0\n \t      && INTEGRAL_TYPE_P (TREE_TYPE (arg0))\n \t      && (TREE_CODE (arg0) == PLUS_EXPR\n \t\t  || TREE_CODE (arg0) == MINUS_EXPR\n@@ -11893,7 +11795,7 @@ fold_binary_loc (location_t loc,\n \t    {\n \t      tree pmop[2];\n \t      int which = 0;\n-\t      unsigned HOST_WIDE_INT cst0;\n+\t      wide_int cst0;\n \n \t      /* Now we know that arg0 is (C + D) or (C - D) or\n \t\t -C and arg1 (M) is == (1LL << cst) - 1.\n@@ -11906,9 +11808,7 @@ fold_binary_loc (location_t loc,\n \t\t  which = 1;\n \t\t}\n \n-\t      if (!tree_fits_uhwi_p (TYPE_MAX_VALUE (TREE_TYPE (arg0)))\n-\t\t  || (tree_to_uhwi (TYPE_MAX_VALUE (TREE_TYPE (arg0)))\n-\t\t      & cst1) != cst1)\n+\t      if ((wi::max_value (TREE_TYPE (arg0)) & cst1) != cst1)\n \t\twhich = -1;\n \n \t      for (; which >= 0; which--)\n@@ -11920,9 +11820,7 @@ fold_binary_loc (location_t loc,\n \t\t    if (TREE_CODE (TREE_OPERAND (pmop[which], 1))\n \t\t\t!= INTEGER_CST)\n \t\t      break;\n-\t\t    /* tree_to_[su]hwi not used, because we don't care about\n-\t\t       the upper bits.  */\n-\t\t    cst0 = TREE_INT_CST_LOW (TREE_OPERAND (pmop[which], 1));\n+\t\t    cst0 = TREE_OPERAND (pmop[which], 1);\n \t\t    cst0 &= cst1;\n \t\t    if (TREE_CODE (pmop[which]) == BIT_AND_EXPR)\n \t\t      {\n@@ -11941,7 +11839,7 @@ fold_binary_loc (location_t loc,\n \t\t       omitted (assumed 0).  */\n \t\t    if ((TREE_CODE (arg0) == PLUS_EXPR\n \t\t\t || (TREE_CODE (arg0) == MINUS_EXPR && which == 0))\n-\t\t\t&& (TREE_INT_CST_LOW (pmop[which]) & cst1) == 0)\n+\t\t\t&& (cst1 & pmop[which]) == 0)\n \t\t      pmop[which] = NULL;\n \t\t    break;\n \t\t  default:\n@@ -12002,9 +11900,8 @@ fold_binary_loc (location_t loc,\n \t{\n \t  prec = TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (arg0, 0)));\n \n-\t  if (prec < BITS_PER_WORD && prec < HOST_BITS_PER_WIDE_INT\n-\t      && (~TREE_INT_CST_LOW (arg1)\n-\t\t  & (((HOST_WIDE_INT) 1 << prec) - 1)) == 0)\n+\t  wide_int mask = wide_int::from (arg1, prec, UNSIGNED);\n+\t  if (mask == -1)\n \t    return\n \t      fold_convert_loc (loc, type, TREE_OPERAND (arg0, 0));\n \t}\n@@ -12407,17 +12304,10 @@ fold_binary_loc (location_t loc,\n \t  tree sum = fold_binary_loc (loc, PLUS_EXPR, TREE_TYPE (arg1),\n \t\t\t\t      arg1, TREE_OPERAND (arg0, 1));\n \t  if (sum && integer_zerop (sum)) {\n-\t    unsigned long pow2;\n-\n-\t    if (TREE_INT_CST_LOW (arg1))\n-\t      pow2 = exact_log2 (TREE_INT_CST_LOW (arg1));\n-\t    else\n-\t      pow2 = exact_log2 (TREE_INT_CST_HIGH (arg1))\n-\t\t      + HOST_BITS_PER_WIDE_INT;\n-\n+\t    tree pow2 = build_int_cst (integer_type_node,\n+\t\t\t\t       wi::exact_log2 (arg1));\n \t    return fold_build2_loc (loc, RSHIFT_EXPR, type,\n-\t\t\t  TREE_OPERAND (arg0, 0),\n-\t\t\t  build_int_cst (integer_type_node, pow2));\n+\t\t\t\t    TREE_OPERAND (arg0, 0), pow2);\n \t  }\n \t}\n \n@@ -12435,25 +12325,18 @@ fold_binary_loc (location_t loc,\n \t  if (integer_pow2p (sval) && tree_int_cst_sgn (sval) > 0)\n \t    {\n \t      tree sh_cnt = TREE_OPERAND (arg1, 1);\n-\t      unsigned long pow2;\n-\n-\t      if (TREE_INT_CST_LOW (sval))\n-\t\tpow2 = exact_log2 (TREE_INT_CST_LOW (sval));\n-\t      else\n-\t\tpow2 = exact_log2 (TREE_INT_CST_HIGH (sval))\n-\t\t       + HOST_BITS_PER_WIDE_INT;\n+\t      tree pow2 = build_int_cst (TREE_TYPE (sh_cnt),\n+\t\t\t\t\t wi::exact_log2 (sval));\n \n \t      if (strict_overflow_p)\n \t\tfold_overflow_warning ((\"assuming signed overflow does not \"\n \t\t\t\t\t\"occur when simplifying A / (B << N)\"),\n \t\t\t\t       WARN_STRICT_OVERFLOW_MISC);\n \n \t      sh_cnt = fold_build2_loc (loc, PLUS_EXPR, TREE_TYPE (sh_cnt),\n-\t\t\t\t\tsh_cnt,\n-\t\t\t\t\tbuild_int_cst (TREE_TYPE (sh_cnt),\n-\t\t\t\t\t\t       pow2));\n+\t\t\t\t\tsh_cnt, pow2);\n \t      return fold_build2_loc (loc, RSHIFT_EXPR, type,\n-\t\t\t\t  fold_convert_loc (loc, type, arg0), sh_cnt);\n+\t\t\t\t      fold_convert_loc (loc, type, arg0), sh_cnt);\n \t    }\n \t}\n \n@@ -12476,8 +12359,7 @@ fold_binary_loc (location_t loc,\n       /* X / -1 is -X.  */\n       if (!TYPE_UNSIGNED (type)\n \t  && TREE_CODE (arg1) == INTEGER_CST\n-\t  && TREE_INT_CST_LOW (arg1) == HOST_WIDE_INT_M1U\n-\t  && TREE_INT_CST_HIGH (arg1) == -1)\n+\t  && wi::eq_p (arg1, -1))\n \treturn fold_convert_loc (loc, type, negate_expr (arg0));\n \n       /* Convert -A / -B to A / B when the type is signed and overflow is\n@@ -12559,16 +12441,15 @@ fold_binary_loc (location_t loc,\n       /* X % -1 is zero.  */\n       if (!TYPE_UNSIGNED (type)\n \t  && TREE_CODE (arg1) == INTEGER_CST\n-\t  && TREE_INT_CST_LOW (arg1) == HOST_WIDE_INT_M1U\n-\t  && TREE_INT_CST_HIGH (arg1) == -1)\n+\t  && wi::eq_p (arg1, -1))\n \treturn omit_one_operand_loc (loc, type, integer_zero_node, arg0);\n \n       /* X % -C is the same as X % C.  */\n       if (code == TRUNC_MOD_EXPR\n-\t  && !TYPE_UNSIGNED (type)\n+\t  && TYPE_SIGN (type) == SIGNED\n \t  && TREE_CODE (arg1) == INTEGER_CST\n \t  && !TREE_OVERFLOW (arg1)\n-\t  && TREE_INT_CST_HIGH (arg1) < 0\n+\t  && wi::neg_p (arg1)\n \t  && !TYPE_OVERFLOW_TRAPS (type)\n \t  /* Avoid this transformation if C is INT_MIN, i.e. C == -C.  */\n \t  && !sign_bit_p (arg1, arg1))\n@@ -12736,16 +12617,13 @@ fold_binary_loc (location_t loc,\n \t\t\t    fold_build2_loc (loc, code, type,\n \t\t\t\t\t TREE_OPERAND (arg0, 1), arg1));\n \n-      /* Two consecutive rotates adding up to the precision of the\n-\t type can be ignored.  */\n+      /* Two consecutive rotates adding up to the some integer\n+\t multiple of the precision of the type can be ignored.  */\n       if (code == RROTATE_EXPR && TREE_CODE (arg1) == INTEGER_CST\n \t  && TREE_CODE (arg0) == RROTATE_EXPR\n \t  && TREE_CODE (TREE_OPERAND (arg0, 1)) == INTEGER_CST\n-\t  && TREE_INT_CST_HIGH (arg1) == 0\n-\t  && TREE_INT_CST_HIGH (TREE_OPERAND (arg0, 1)) == 0\n-\t  && ((TREE_INT_CST_LOW (arg1)\n-\t       + TREE_INT_CST_LOW (TREE_OPERAND (arg0, 1)))\n-\t      == prec))\n+\t  && wi::umod_trunc (wi::add (arg1, TREE_OPERAND (arg0, 1)),\n+\t\t\t     prec) == 0)\n \treturn TREE_OPERAND (arg0, 0);\n \n       /* Fold (X & C2) << C1 into (X << C1) & (C2 << C1)\n@@ -13067,7 +12945,7 @@ fold_binary_loc (location_t loc,\n \t  && operand_equal_p (tree_strip_nop_conversions (TREE_OPERAND (arg0,\n \t\t\t\t\t\t\t\t\t1)),\n \t\t\t      arg1, 0)\n-\t  && (TREE_INT_CST_LOW (TREE_OPERAND (arg0, 0)) & 1) == 1)\n+\t  && wi::extract_uhwi (TREE_OPERAND (arg0, 0), 0, 1) == 1)\n \t{\n \t  return omit_two_operands_loc (loc, type,\n \t\t\t\t    code == NE_EXPR\n@@ -13158,8 +13036,7 @@ fold_binary_loc (location_t loc,\n \t  prec = TYPE_PRECISION (itype);\n \n \t  /* Check for a valid shift count.  */\n-\t  if (TREE_INT_CST_HIGH (arg001) == 0\n-\t      && TREE_INT_CST_LOW (arg001) < prec)\n+\t  if (wi::ltu_p (arg001, prec))\n \t    {\n \t      tree arg01 = TREE_OPERAND (arg0, 1);\n \t      tree arg000 = TREE_OPERAND (TREE_OPERAND (arg0, 0), 0);\n@@ -13284,9 +13161,7 @@ fold_binary_loc (location_t loc,\n \t  tree arg00 = TREE_OPERAND (arg0, 0);\n \t  tree arg01 = TREE_OPERAND (arg0, 1);\n \t  tree itype = TREE_TYPE (arg00);\n-\t  if (TREE_INT_CST_HIGH (arg01) == 0\n-\t      && TREE_INT_CST_LOW (arg01)\n-\t\t == (unsigned HOST_WIDE_INT) (TYPE_PRECISION (itype) - 1))\n+\t  if (wi::eq_p (arg01, TYPE_PRECISION (itype) - 1))\n \t    {\n \t      if (TYPE_UNSIGNED (itype))\n \t\t{\n@@ -13688,59 +13563,16 @@ fold_binary_loc (location_t loc,\n \t the specified precision will have known values.  */\n       {\n \ttree arg1_type = TREE_TYPE (arg1);\n-\tunsigned int width = TYPE_PRECISION (arg1_type);\n+\tunsigned int prec = TYPE_PRECISION (arg1_type);\n \n \tif (TREE_CODE (arg1) == INTEGER_CST\n-\t    && width <= HOST_BITS_PER_DOUBLE_INT\n \t    && (INTEGRAL_TYPE_P (arg1_type) || POINTER_TYPE_P (arg1_type)))\n \t  {\n-\t    HOST_WIDE_INT signed_max_hi;\n-\t    unsigned HOST_WIDE_INT signed_max_lo;\n-\t    unsigned HOST_WIDE_INT max_hi, max_lo, min_hi, min_lo;\n-\n-\t    if (width <= HOST_BITS_PER_WIDE_INT)\n-\t      {\n-\t\tsigned_max_lo = ((unsigned HOST_WIDE_INT) 1 << (width - 1))\n-\t\t\t\t- 1;\n-\t\tsigned_max_hi = 0;\n-\t\tmax_hi = 0;\n-\n-\t\tif (TYPE_UNSIGNED (arg1_type))\n-\t\t  {\n-\t\t    max_lo = ((unsigned HOST_WIDE_INT) 2 << (width - 1)) - 1;\n-\t\t    min_lo = 0;\n-\t\t    min_hi = 0;\n-\t\t  }\n-\t\telse\n-\t\t  {\n-\t\t    max_lo = signed_max_lo;\n-\t\t    min_lo = (HOST_WIDE_INT_M1U << (width - 1));\n-\t\t    min_hi = -1;\n-\t\t  }\n-\t      }\n-\t    else\n-\t      {\n-\t\twidth -= HOST_BITS_PER_WIDE_INT;\n-\t\tsigned_max_lo = -1;\n-\t\tsigned_max_hi = ((unsigned HOST_WIDE_INT) 1 << (width - 1))\n-\t\t\t\t- 1;\n-\t\tmax_lo = -1;\n-\t\tmin_lo = 0;\n-\n-\t\tif (TYPE_UNSIGNED (arg1_type))\n-\t\t  {\n-\t\t    max_hi = ((unsigned HOST_WIDE_INT) 2 << (width - 1)) - 1;\n-\t\t    min_hi = 0;\n-\t\t  }\n-\t\telse\n-\t\t  {\n-\t\t    max_hi = signed_max_hi;\n-\t\t    min_hi = (HOST_WIDE_INT_M1U << (width - 1));\n-\t\t  }\n-\t      }\n+\t    wide_int max = wi::max_value (arg1_type);\n+\t    wide_int signed_max = wi::max_value (prec, SIGNED);\n+\t    wide_int min = wi::min_value (arg1_type);\n \n-\t    if ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (arg1) == max_hi\n-\t\t&& TREE_INT_CST_LOW (arg1) == max_lo)\n+\t    if (wi::eq_p (arg1, max))\n \t      switch (code)\n \t\t{\n \t\tcase GT_EXPR:\n@@ -13761,9 +13593,7 @@ fold_binary_loc (location_t loc,\n \t\tdefault:\n \t\t  break;\n \t\t}\n-\t    else if ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (arg1)\n-\t\t     == max_hi\n-\t\t     && TREE_INT_CST_LOW (arg1) == max_lo - 1)\n+\t    else if (wi::eq_p (arg1, max - 1))\n \t      switch (code)\n \t\t{\n \t\tcase GT_EXPR:\n@@ -13783,9 +13613,7 @@ fold_binary_loc (location_t loc,\n \t\tdefault:\n \t\t  break;\n \t\t}\n-\t    else if ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (arg1)\n-\t\t     == min_hi\n-\t\t     && TREE_INT_CST_LOW (arg1) == min_lo)\n+\t    else if (wi::eq_p (arg1, min))\n \t      switch (code)\n \t\t{\n \t\tcase LT_EXPR:\n@@ -13803,19 +13631,19 @@ fold_binary_loc (location_t loc,\n \t\tdefault:\n \t\t  break;\n \t\t}\n-\t    else if ((unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (arg1)\n-\t\t     == min_hi\n-\t\t     && TREE_INT_CST_LOW (arg1) == min_lo + 1)\n+\t    else if (wi::eq_p (arg1, min + 1))\n \t      switch (code)\n \t\t{\n \t\tcase GE_EXPR:\n-\t\t  arg1 = const_binop (MINUS_EXPR, arg1, integer_one_node);\n+\t\t  arg1 = const_binop (MINUS_EXPR, arg1,\n+\t\t\t\t      build_int_cst (TREE_TYPE (arg1), 1));\n \t\t  return fold_build2_loc (loc, NE_EXPR, type,\n \t\t\t\t      fold_convert_loc (loc,\n \t\t\t\t\t\t\tTREE_TYPE (arg1), arg0),\n \t\t\t\t      arg1);\n \t\tcase LT_EXPR:\n-\t\t  arg1 = const_binop (MINUS_EXPR, arg1, integer_one_node);\n+\t\t  arg1 = const_binop (MINUS_EXPR, arg1,\n+\t\t\t\t      build_int_cst (TREE_TYPE (arg1), 1));\n \t\t  return fold_build2_loc (loc, EQ_EXPR, type,\n \t\t\t\t      fold_convert_loc (loc, TREE_TYPE (arg1),\n \t\t\t\t\t\t\targ0),\n@@ -13824,14 +13652,13 @@ fold_binary_loc (location_t loc,\n \t\t  break;\n \t\t}\n \n-\t    else if (TREE_INT_CST_HIGH (arg1) == signed_max_hi\n-\t\t     && TREE_INT_CST_LOW (arg1) == signed_max_lo\n+\t    else if (wi::eq_p (arg1, signed_max)\n \t\t     && TYPE_UNSIGNED (arg1_type)\n \t\t     /* We will flip the signedness of the comparison operator\n \t\t\tassociated with the mode of arg1, so the sign bit is\n \t\t\tspecified by this mode.  Check that arg1 is the signed\n \t\t\tmax associated with this sign bit.  */\n-\t\t     && width == GET_MODE_PRECISION (TYPE_MODE (arg1_type))\n+\t\t     && prec == GET_MODE_PRECISION (TYPE_MODE (arg1_type))\n \t\t     /* signed_type does not work on pointer types.  */\n \t\t     && INTEGRAL_TYPE_P (arg1_type))\n \t      {\n@@ -14356,8 +14183,6 @@ fold_ternary_loc (location_t loc, enum tree_code code, tree type,\n \t      && TYPE_PRECISION (TREE_TYPE (tem))\n \t\t < TYPE_PRECISION (type))\n \t    {\n-\t      unsigned HOST_WIDE_INT mask_lo;\n-\t      HOST_WIDE_INT mask_hi;\n \t      int inner_width, outer_width;\n \t      tree tem_type;\n \n@@ -14366,36 +14191,17 @@ fold_ternary_loc (location_t loc, enum tree_code code, tree type,\n \t      if (outer_width > TYPE_PRECISION (type))\n \t\touter_width = TYPE_PRECISION (type);\n \n-\t      if (outer_width > HOST_BITS_PER_WIDE_INT)\n-\t\t{\n-\t\t  mask_hi = (HOST_WIDE_INT_M1U\n-\t\t\t     >> (HOST_BITS_PER_DOUBLE_INT - outer_width));\n-\t\t  mask_lo = -1;\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  mask_hi = 0;\n-\t\t  mask_lo = (HOST_WIDE_INT_M1U\n-\t\t\t     >> (HOST_BITS_PER_WIDE_INT - outer_width));\n-\t\t}\n-\t      if (inner_width > HOST_BITS_PER_WIDE_INT)\n-\t\t{\n-\t\t  mask_hi &= ~(HOST_WIDE_INT_M1U\n-\t\t\t       >> (HOST_BITS_PER_WIDE_INT - inner_width));\n-\t\t  mask_lo = 0;\n-\t\t}\n-\t      else\n-\t\tmask_lo &= ~(HOST_WIDE_INT_M1U\n-\t\t\t     >> (HOST_BITS_PER_WIDE_INT - inner_width));\n+\t      wide_int mask = wi::shifted_mask\n+\t\t(inner_width, outer_width - inner_width, false,\n+\t\t TYPE_PRECISION (TREE_TYPE (arg1)));\n \n-\t      if ((TREE_INT_CST_HIGH (arg1) & mask_hi) == mask_hi\n-\t\t  && (TREE_INT_CST_LOW (arg1) & mask_lo) == mask_lo)\n+\t      wide_int common = mask & arg1;\n+\t      if (common == mask)\n \t\t{\n \t\t  tem_type = signed_type_for (TREE_TYPE (tem));\n \t\t  tem = fold_convert_loc (loc, tem_type, tem);\n \t\t}\n-\t      else if ((TREE_INT_CST_HIGH (arg1) & mask_hi) == 0\n-\t\t       && (TREE_INT_CST_LOW (arg1) & mask_lo) == 0)\n+\t      else if (common == 0)\n \t\t{\n \t\t  tem_type = unsigned_type_for (TREE_TYPE (tem));\n \t\t  tem = fold_convert_loc (loc, tem_type, tem);\n@@ -14424,9 +14230,9 @@ fold_ternary_loc (location_t loc, enum tree_code code, tree type,\n \t  tree tem = TREE_OPERAND (arg0, 0);\n \t  STRIP_NOPS (tem);\n \t  if (TREE_CODE (tem) == RSHIFT_EXPR\n-              && TREE_CODE (TREE_OPERAND (tem, 1)) == INTEGER_CST\n+\t      && tree_fits_uhwi_p (TREE_OPERAND (tem, 1))\n               && (unsigned HOST_WIDE_INT) tree_log2 (arg1) ==\n-\t         TREE_INT_CST_LOW (TREE_OPERAND (tem, 1)))\n+\t         tree_to_uhwi (TREE_OPERAND (tem, 1)))\n \t    return fold_build2_loc (loc, BIT_AND_EXPR, type,\n \t\t\t\tTREE_OPERAND (tem, 0), arg1);\n \t}\n@@ -14648,7 +14454,6 @@ fold_ternary_loc (location_t loc, enum tree_code code, tree type,\n \t{\n \t  unsigned int nelts = TYPE_VECTOR_SUBPARTS (type), i, mask;\n \t  unsigned char *sel = XALLOCAVEC (unsigned char, nelts);\n-\t  tree t;\n \t  bool need_mask_canon = false;\n \t  bool all_in_vec0 = true;\n \t  bool all_in_vec1 = true;\n@@ -14664,11 +14469,16 @@ fold_ternary_loc (location_t loc, enum tree_code code, tree type,\n \t      if (TREE_CODE (val) != INTEGER_CST)\n \t\treturn NULL_TREE;\n \n-\t      sel[i] = TREE_INT_CST_LOW (val) & mask;\n-\t      if (TREE_INT_CST_HIGH (val)\n-\t\t  || ((unsigned HOST_WIDE_INT)\n-\t\t      TREE_INT_CST_LOW (val) != sel[i]))\n-\t\tneed_mask_canon = true;\n+\t      /* Make sure that the perm value is in an acceptable\n+\t\t range.  */\n+\t      wide_int t = val;\n+\t      if (wi::gtu_p (t, mask))\n+\t\t{\n+\t\t  need_mask_canon = true;\n+\t\t  sel[i] = t.to_uhwi () & mask;\n+\t\t}\n+\t      else\n+\t\tsel[i] = t.to_uhwi ();\n \n \t      if (sel[i] < nelts)\n \t\tall_in_vec1 = false;\n@@ -14702,7 +14512,7 @@ fold_ternary_loc (location_t loc, enum tree_code code, tree type,\n \t      && (TREE_CODE (op1) == VECTOR_CST\n \t\t  || TREE_CODE (op1) == CONSTRUCTOR))\n \t    {\n-\t      t = fold_vec_perm (type, op0, op1, sel);\n+\t      tree t = fold_vec_perm (type, op0, op1, sel);\n \t      if (t != NULL_TREE)\n \t\treturn t;\n \t    }\n@@ -15471,9 +15281,7 @@ multiple_of_p (tree type, const_tree top, const_tree bottom)\n \t  op1 = TREE_OPERAND (top, 1);\n \t  /* const_binop may not detect overflow correctly,\n \t     so check for it explicitly here.  */\n-\t  if (TYPE_PRECISION (TREE_TYPE (size_one_node))\n-\t      > TREE_INT_CST_LOW (op1)\n-\t      && TREE_INT_CST_HIGH (op1) == 0\n+\t  if (wi::gtu_p (TYPE_PRECISION (TREE_TYPE (size_one_node)), op1)\n \t      && 0 != (t1 = fold_convert (type,\n \t\t\t\t\t  const_binop (LSHIFT_EXPR,\n \t\t\t\t\t\t       size_one_node,\n@@ -15678,11 +15486,11 @@ tree_binary_nonnegative_warnv_p (enum tree_code code, tree type, tree op0,\n \t      && TREE_CODE (inner1) == INTEGER_TYPE && unsigned1)\n \t    {\n \t      unsigned int precision0 = (TREE_CODE (op0) == INTEGER_CST)\n-\t\t? tree_int_cst_min_precision (op0, /*unsignedp=*/true)\n+\t\t? tree_int_cst_min_precision (op0, UNSIGNED)\n \t\t: TYPE_PRECISION (inner0);\n \n \t      unsigned int precision1 = (TREE_CODE (op1) == INTEGER_CST)\n-\t\t? tree_int_cst_min_precision (op1, /*unsignedp=*/true)\n+\t\t? tree_int_cst_min_precision (op1, UNSIGNED)\n \t\t: TYPE_PRECISION (inner1);\n \n \t      return precision0 + precision1 < TYPE_PRECISION (type);\n@@ -15880,8 +15688,7 @@ tree_call_nonnegative_warnv_p (tree type, tree fndecl,\n \t    if ((n & 1) == 0)\n \t      {\n \t\tREAL_VALUE_TYPE cint;\n-\t\treal_from_integer (&cint, VOIDmode, n,\n-\t\t\t\t   n < 0 ? -1 : 0, 0);\n+\t\treal_from_integer (&cint, VOIDmode, n, SIGNED);\n \t\tif (real_identical (&c, &cint))\n \t\t  return true;\n \t      }\n@@ -16366,12 +16173,11 @@ fold_negate_const (tree arg0, tree type)\n     {\n     case INTEGER_CST:\n       {\n-\tdouble_int val = tree_to_double_int (arg0);\n \tbool overflow;\n-\tval = val.neg_with_overflow (&overflow);\n-\tt = force_fit_type_double (type, val, 1,\n-\t\t\t\t   (overflow | TREE_OVERFLOW (arg0))\n-\t\t\t\t   && !TYPE_UNSIGNED (type));\n+\twide_int val = wi::neg (arg0, &overflow);\n+\tt = force_fit_type (type, val, 1,\n+\t\t\t    (overflow | TREE_OVERFLOW (arg0))\n+\t\t\t    && !TYPE_UNSIGNED (type));\n \tbreak;\n       }\n \n@@ -16413,22 +16219,19 @@ fold_abs_const (tree arg0, tree type)\n     {\n     case INTEGER_CST:\n       {\n-\tdouble_int val = tree_to_double_int (arg0);\n-\n         /* If the value is unsigned or non-negative, then the absolute value\n \t   is the same as the ordinary value.  */\n-\tif (TYPE_UNSIGNED (type)\n-\t    || !val.is_negative ())\n+\tif (!wi::neg_p (arg0, TYPE_SIGN (type)))\n \t  t = arg0;\n \n \t/* If the value is negative, then the absolute value is\n \t   its negation.  */\n \telse\n \t  {\n \t    bool overflow;\n-\t    val = val.neg_with_overflow (&overflow);\n-\t    t = force_fit_type_double (type, val, -1,\n-\t\t\t\t       overflow | TREE_OVERFLOW (arg0));\n+\t    wide_int val = wi::neg (arg0, &overflow);\n+\t    t = force_fit_type (type, val, -1,\n+\t\t\t\toverflow | TREE_OVERFLOW (arg0));\n \t  }\n       }\n       break;\n@@ -16453,12 +16256,9 @@ fold_abs_const (tree arg0, tree type)\n static tree\n fold_not_const (const_tree arg0, tree type)\n {\n-  double_int val;  \n-\n   gcc_assert (TREE_CODE (arg0) == INTEGER_CST);\n \n-  val = ~tree_to_double_int (arg0);\n-  return force_fit_type_double (type, val, 0, TREE_OVERFLOW (arg0));\n+  return force_fit_type (type, wi::bit_not (arg0), 0, TREE_OVERFLOW (arg0));\n }\n \n /* Given CODE, a relational operator, the target type, TYPE and two\n@@ -16601,10 +16401,8 @@ fold_relational_const (enum tree_code code, tree type, tree op0, tree op1)\n     {\n       if (code == EQ_EXPR)\n \tresult = tree_int_cst_equal (op0, op1);\n-      else if (TYPE_UNSIGNED (TREE_TYPE (op0)))\n-\tresult = INT_CST_LT_UNSIGNED (op0, op1);\n       else\n-\tresult = INT_CST_LT (op0, op1);\n+\tresult = tree_int_cst_lt (op0, op1);\n     }\n   else\n     return NULL_TREE;\n@@ -16862,8 +16660,7 @@ fold_ignored_result (tree t)\n       }\n }\n \n-/* Return the value of VALUE, rounded up to a multiple of DIVISOR.\n-   This can only be applied to objects of a sizetype.  */\n+/* Return the value of VALUE, rounded up to a multiple of DIVISOR. */\n \n tree\n round_up_loc (location_t loc, tree value, int divisor)\n@@ -16891,24 +16688,19 @@ round_up_loc (location_t loc, tree value, int divisor)\n     {\n       if (TREE_CODE (value) == INTEGER_CST)\n \t{\n-\t  double_int val = tree_to_double_int (value);\n+\t  wide_int val = value;\n \t  bool overflow_p;\n \n-\t  if ((val.low & (divisor - 1)) == 0)\n+\t  if ((val & (divisor - 1)) == 0)\n \t    return value;\n \n \t  overflow_p = TREE_OVERFLOW (value);\n-\t  val.low &= ~(divisor - 1);\n-\t  val.low += divisor;\n-\t  if (val.low == 0)\n-\t    {\n-\t      val.high++;\n-\t      if (val.high == 0)\n-\t\toverflow_p = true;\n-\t    }\n+\t  val &= ~(divisor - 1);\n+\t  val += divisor;\n+\t  if (val == 0)\n+\t    overflow_p = true;\n \n-\t  return force_fit_type_double (TREE_TYPE (value), val,\n-\t\t\t\t\t-1, overflow_p);\n+\t  return force_fit_type (TREE_TYPE (value), val, -1, overflow_p);\n \t}\n       else\n \t{"}, {"sha": "023f043853e50b286dc1b91efd58d40604299fa2", "filename": "gcc/fold-const.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffold-const.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffold-const.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -118,10 +118,10 @@ extern tree fold_indirect_ref_loc (location_t, tree);\n extern tree build_simple_mem_ref_loc (location_t, tree);\n #define build_simple_mem_ref(T)\\\n \tbuild_simple_mem_ref_loc (UNKNOWN_LOCATION, T)\n-extern double_int mem_ref_offset (const_tree);\n+extern offset_int mem_ref_offset (const_tree);\n extern tree build_invariant_address (tree, tree, HOST_WIDE_INT);\n extern tree constant_boolean_node (bool, tree);\n-extern tree div_if_zero_remainder (enum tree_code, const_tree, const_tree);\n+extern tree div_if_zero_remainder (const_tree, const_tree);\n \n extern bool tree_swap_operands_p (const_tree, const_tree, bool);\n extern enum tree_code swap_tree_comparison (enum tree_code);"}, {"sha": "012880405c5dc548610c85dfef5f0b3686641178", "filename": "gcc/fortran/target-memory.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftarget-memory.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftarget-memory.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftarget-memory.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -32,6 +32,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"trans-const.h\"\n #include \"trans-types.h\"\n #include \"target-memory.h\"\n+#include \"wide-int.h\"\n \n /* --------------------------------------------------------------- */\n /* Calculate the size of an expression.  */\n@@ -430,7 +431,7 @@ gfc_interpret_logical (int kind, unsigned char *buffer, size_t buffer_size,\n {\n   tree t = native_interpret_expr (gfc_get_logical_type (kind), buffer,\n \t\t\t\t  buffer_size);\n-  *logical = tree_to_double_int (t).is_zero () ? 0 : 1;\n+  *logical = wi::eq_p (t, 0) ? 0 : 1;\n   return size_logical (kind);\n }\n "}, {"sha": "bb648f05891916b00471f15738737413ec909d49", "filename": "gcc/fortran/trans-array.c", "status": "modified", "additions": 6, "deletions": 13, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-array.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-array.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-array.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -90,6 +90,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"trans-array.h\"\n #include \"trans-const.h\"\n #include \"dependency.h\"\n+#include \"wide-int.h\"\n \n static bool gfc_get_array_constructor_size (mpz_t *, gfc_constructor_base);\n \n@@ -5380,9 +5381,8 @@ gfc_conv_array_initializer (tree type, gfc_expr * expr)\n {\n   gfc_constructor *c;\n   tree tmp;\n+  offset_int wtmp;\n   gfc_se se;\n-  HOST_WIDE_INT hi;\n-  unsigned HOST_WIDE_INT lo;\n   tree index, range;\n   vec<constructor_elt, va_gc> *v = NULL;\n \n@@ -5404,20 +5404,13 @@ gfc_conv_array_initializer (tree type, gfc_expr * expr)\n       else\n \tgfc_conv_structure (&se, expr, 1);\n \n-      tmp = TYPE_MAX_VALUE (TYPE_DOMAIN (type));\n-      gcc_assert (tmp && INTEGER_CST_P (tmp));\n-      hi = TREE_INT_CST_HIGH (tmp);\n-      lo = TREE_INT_CST_LOW (tmp);\n-      lo++;\n-      if (lo == 0)\n-\thi++;\n+      wtmp = wi::to_offset (TYPE_MAX_VALUE (TYPE_DOMAIN (type))) + 1;\n+      gcc_assert (wtmp != 0);\n       /* This will probably eat buckets of memory for large arrays.  */\n-      while (hi != 0 || lo != 0)\n+      while (wtmp != 0)\n         {\n \t  CONSTRUCTOR_APPEND_ELT (v, NULL_TREE, se.expr);\n-          if (lo == 0)\n-            hi--;\n-          lo--;\n+\t  wtmp -= 1;\n         }\n       break;\n "}, {"sha": "6c54e202777a71b5db0a9507cc82ac54217ebf9b", "filename": "gcc/fortran/trans-const.c", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-const.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -33,6 +33,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"trans-const.h\"\n #include \"trans-types.h\"\n #include \"target-memory.h\"\n+#include \"wide-int.h\"\n \n tree gfc_rank_cst[GFC_MAX_DIMENSIONS + 1];\n \n@@ -145,8 +146,7 @@ gfc_conv_string_init (tree length, gfc_expr * expr)\n \n   gcc_assert (expr->expr_type == EXPR_CONSTANT);\n   gcc_assert (expr->ts.type == BT_CHARACTER);\n-  gcc_assert (INTEGER_CST_P (length));\n-  gcc_assert (TREE_INT_CST_HIGH (length) == 0);\n+  gcc_assert (tree_fits_uhwi_p (length));\n \n   len = TREE_INT_CST_LOW (length);\n   slen = expr->value.character.length;\n@@ -201,17 +201,16 @@ gfc_init_constants (void)\n tree\n gfc_conv_mpz_to_tree (mpz_t i, int kind)\n {\n-  double_int val = mpz_get_double_int (gfc_get_int_type (kind), i, true);\n-  return double_int_to_tree (gfc_get_int_type (kind), val);\n+  wide_int val = wi::from_mpz (gfc_get_int_type (kind), i, true);\n+  return wide_int_to_tree (gfc_get_int_type (kind), val);\n }\n \n /* Converts a backend tree into a GMP integer.  */\n \n void\n gfc_conv_tree_to_mpz (mpz_t i, tree source)\n {\n-  double_int val = tree_to_double_int (source);\n-  mpz_set_double_int (i, val, TYPE_UNSIGNED (TREE_TYPE (source)));\n+  wi::to_mpz (source, i, TYPE_SIGN (TREE_TYPE (source)));\n }\n \n /* Converts a real constant into backend form.  */"}, {"sha": "bd1ebab46b268eddbc1974fa79147a306961907c", "filename": "gcc/fortran/trans-decl.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-decl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-decl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-decl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -406,7 +406,7 @@ gfc_can_put_var_on_stack (tree size)\n   if (gfc_option.flag_max_stack_var_size < 0)\n     return 1;\n \n-  if (TREE_INT_CST_HIGH (size) != 0)\n+  if (!tree_fits_uhwi_p (size))\n     return 0;\n \n   low = TREE_INT_CST_LOW (size);"}, {"sha": "5a501227863e8a22c2990e91310277a672cf4be4", "filename": "gcc/fortran/trans-expr.c", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-expr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-expr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-expr.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -40,7 +40,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"trans-stmt.h\"\n #include \"dependency.h\"\n #include \"gimplify.h\"\n-\n+#include \"wide-int.h\"\n \n /* Convert a scalar to an array descriptor. To be used for assumed-rank\n    arrays.  */\n@@ -2112,13 +2112,14 @@ gfc_conv_cst_int_power (gfc_se * se, tree lhs, tree rhs)\n   HOST_WIDE_INT m;\n   unsigned HOST_WIDE_INT n;\n   int sgn;\n+  wide_int wrhs = rhs;\n \n   /* If exponent is too large, we won't expand it anyway, so don't bother\n      with large integer values.  */\n-  if (!TREE_INT_CST (rhs).fits_shwi ())\n+  if (!wi::fits_shwi_p (wrhs))\n     return 0;\n \n-  m = TREE_INT_CST (rhs).to_shwi ();\n+  m = wrhs.to_shwi ();\n   /* There's no ABS for HOST_WIDE_INT, so here we go. It also takes care\n      of the asymmetric range of the integer type.  */\n   n = (unsigned HOST_WIDE_INT) (m < 0 ? -m : m);\n@@ -2657,7 +2658,7 @@ gfc_string_to_single_character (tree len, tree str, int kind)\n {\n \n   if (len == NULL\n-      || !INTEGER_CST_P (len) || TREE_INT_CST_HIGH (len) != 0\n+      || !tree_fits_uhwi_p (len)\n       || !POINTER_TYPE_P (TREE_TYPE (str)))\n     return NULL_TREE;\n \n@@ -2771,8 +2772,9 @@ gfc_optimize_len_trim (tree len, tree str, int kind)\n       && TREE_CODE (TREE_OPERAND (TREE_OPERAND (str, 0), 0)) == STRING_CST\n       && array_ref_low_bound (TREE_OPERAND (str, 0))\n \t == TREE_OPERAND (TREE_OPERAND (str, 0), 1)\n-      && TREE_INT_CST_LOW (len) >= 1\n-      && TREE_INT_CST_LOW (len)\n+      && tree_fits_uhwi_p (len)\n+      && tree_to_uhwi (len) >= 1\n+      && tree_to_uhwi (len)\n \t == (unsigned HOST_WIDE_INT)\n \t    TREE_STRING_LENGTH (TREE_OPERAND (TREE_OPERAND (str, 0), 0)))\n     {"}, {"sha": "c166c4f0bcfa14d19c2391a8d395f68e6e79cbc2", "filename": "gcc/fortran/trans-intrinsic.c", "status": "modified", "additions": 8, "deletions": 19, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-intrinsic.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-intrinsic.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-intrinsic.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -43,6 +43,7 @@ along with GCC; see the file COPYING3.  If not see\n /* Only for gfc_trans_assign and gfc_trans_pointer_assign.  */\n #include \"trans-stmt.h\"\n #include \"tree-nested.h\"\n+#include \"wide-int.h\"\n \n /* This maps Fortran intrinsic math functions to external library or GCC\n    builtin functions.  */\n@@ -987,12 +988,8 @@ trans_this_image (gfc_se * se, gfc_expr *expr)\n \n       if (INTEGER_CST_P (dim_arg))\n \t{\n-\t  int hi, co_dim;\n-\n-\t  hi = TREE_INT_CST_HIGH (dim_arg);\n-\t  co_dim = TREE_INT_CST_LOW (dim_arg);\n-\t  if (hi || co_dim < 1\n-\t      || co_dim > GFC_TYPE_ARRAY_CORANK (TREE_TYPE (desc)))\n+\t  if (wi::ltu_p (dim_arg, 1)\n+\t      || wi::gtu_p (dim_arg, GFC_TYPE_ARRAY_CORANK (TREE_TYPE (desc))))\n \t    gfc_error (\"'dim' argument of %s intrinsic at %L is not a valid \"\n \t\t       \"dimension index\", expr->value.function.isym->name,\n \t\t       &expr->where);\n@@ -1352,14 +1349,9 @@ gfc_conv_intrinsic_bound (gfc_se * se, gfc_expr * expr, int upper)\n \n   if (INTEGER_CST_P (bound))\n     {\n-      int hi, low;\n-\n-      hi = TREE_INT_CST_HIGH (bound);\n-      low = TREE_INT_CST_LOW (bound);\n-      if (hi || low < 0\n-\t  || ((!as || as->type != AS_ASSUMED_RANK)\n-\t      && low >= GFC_TYPE_ARRAY_RANK (TREE_TYPE (desc)))\n-\t  || low > GFC_MAX_DIMENSIONS)\n+      if (((!as || as->type != AS_ASSUMED_RANK)\n+\t   && wi::geu_p (bound, GFC_TYPE_ARRAY_RANK (TREE_TYPE (desc))))\n+\t  || wi::gtu_p (bound, GFC_MAX_DIMENSIONS))\n \tgfc_error (\"'dim' argument of %s intrinsic at %L is not a valid \"\n \t\t   \"dimension index\", upper ? \"UBOUND\" : \"LBOUND\",\n \t\t   &expr->where);\n@@ -1554,11 +1546,8 @@ conv_intrinsic_cobound (gfc_se * se, gfc_expr * expr)\n \n       if (INTEGER_CST_P (bound))\n \t{\n-\t  int hi, low;\n-\n-\t  hi = TREE_INT_CST_HIGH (bound);\n-\t  low = TREE_INT_CST_LOW (bound);\n-\t  if (hi || low < 1 || low > GFC_TYPE_ARRAY_CORANK (TREE_TYPE (desc)))\n+\t  if (wi::ltu_p (bound, 1)\n+\t      || wi::gtu_p (bound, GFC_TYPE_ARRAY_CORANK (TREE_TYPE (desc))))\n \t    gfc_error (\"'dim' argument of %s intrinsic at %L is not a valid \"\n \t\t       \"dimension index\", expr->value.function.isym->name,\n \t\t       &expr->where);"}, {"sha": "77d0e785e0be36d52606e875b7787dbe9d63e5b2", "filename": "gcc/fortran/trans-types.c", "status": "modified", "additions": 4, "deletions": 9, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-types.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ffortran%2Ftrans-types.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-types.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -863,8 +863,6 @@ gfc_init_types (void)\n   int index;\n   tree type;\n   unsigned n;\n-  unsigned HOST_WIDE_INT hi;\n-  unsigned HOST_WIDE_INT lo;\n \n   /* Create and name the types.  */\n #define PUSH_TYPE(name, node) \\\n@@ -956,13 +954,10 @@ gfc_init_types (void)\n      descriptor.  */\n \n   n = TYPE_PRECISION (gfc_array_index_type) - GFC_DTYPE_SIZE_SHIFT;\n-  lo = ~ (unsigned HOST_WIDE_INT) 0;\n-  if (n > HOST_BITS_PER_WIDE_INT)\n-    hi = lo >> (2*HOST_BITS_PER_WIDE_INT - n);\n-  else\n-    hi = 0, lo >>= HOST_BITS_PER_WIDE_INT - n;\n   gfc_max_array_element_size\n-    = build_int_cst_wide (long_unsigned_type_node, lo, hi);\n+    = wide_int_to_tree (long_unsigned_type_node,\n+\t\t\twi::mask (n, UNSIGNED,\n+\t\t\t\t  TYPE_PRECISION (long_unsigned_type_node)));\n \n   boolean_type_node = gfc_get_logical_type (gfc_default_logical_kind);\n   boolean_true_node = build_int_cst (boolean_type_node, 1);\n@@ -1902,7 +1897,7 @@ gfc_get_array_type_bounds (tree etype, int dimen, int codimen, tree * lbound,\n   if (stride)\n     rtype = build_range_type (gfc_array_index_type, gfc_index_zero_node,\n \t\t\t      int_const_binop (MINUS_EXPR, stride,\n-\t\t\t\t\t       integer_one_node));\n+\t\t\t\t\t       build_int_cst (TREE_TYPE (stride), 1)));\n   else\n     rtype = gfc_array_range_type;\n   arraytype = build_array_type (etype, rtype);"}, {"sha": "a5ec8361e7f020a9ea0aa14d45baa459179129b8", "filename": "gcc/gencheck.c", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgencheck.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgencheck.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgencheck.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -17,6 +17,9 @@ You should have received a copy of the GNU General Public License\n along with GCC; see the file COPYING3.  If not see\n <http://www.gnu.org/licenses/>.  */\n \n+/* We don't have insn-modes.h, but we include tm.h.  */\n+#define BITS_PER_UNIT 8\n+\n #include \"bconfig.h\"\n #include \"system.h\"\n #include \"coretypes.h\""}, {"sha": "16b56449687f73134ad16fe5b3129164bc1c26bc", "filename": "gcc/genemit.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgenemit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgenemit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgenemit.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -204,6 +204,7 @@ gen_exp (rtx x, enum rtx_code subroutine_type, char *used)\n \n     case CONST_DOUBLE:\n     case CONST_FIXED:\n+    case CONST_WIDE_INT:\n       /* These shouldn't be written in MD files.  Instead, the appropriate\n \t routines in varasm.c should be called.  */\n       gcc_unreachable ();"}, {"sha": "d82ee39e7ee86d4a3fcc03c968d64e1c76335db8", "filename": "gcc/gengenrtl.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengenrtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengenrtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgengenrtl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -142,6 +142,7 @@ static int\n excluded_rtx (int idx)\n {\n   return ((strcmp (defs[idx].enumname, \"CONST_DOUBLE\") == 0)\n+\t  || (strcmp (defs[idx].enumname, \"CONST_WIDE_INT\") == 0)\n \t  || (strcmp (defs[idx].enumname, \"CONST_FIXED\") == 0));\n }\n "}, {"sha": "936b28cdc4ae4f85ff4b26471e2455c532da79eb", "filename": "gcc/gengtype-lex.l", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype-lex.l", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype-lex.l", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgengtype-lex.l?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -57,7 +57,7 @@ ITYPE\t{IWORD}({WS}{IWORD})*\n     /* Include '::' in identifiers to capture C++ scope qualifiers.  */\n ID\t{CID}({HWS}::{HWS}{CID})*\n EOID\t[^[:alnum:]_]\n-CXX_KEYWORD inline|public:|private:|protected:|template|operator|friend\n+CXX_KEYWORD inline|public:|private:|protected:|template|operator|friend|static\n \n %x in_struct in_struct_comment in_comment\n %option warn noyywrap nounput nodefault perf-report\n@@ -110,6 +110,7 @@ CXX_KEYWORD inline|public:|private:|protected:|template|operator|friend\n \"const\"/{EOID}\t\t\t/* don't care */\n {CXX_KEYWORD}/{EOID}\t\t\t|\n \"~\"\t\t\t\t\t|\n+\"^\"\t\t\t\t\t|\n \"&\"\t\t\t\t\t{\n     *yylval = XDUPVAR (const char, yytext, yyleng, yyleng + 1);\n     return IGNORABLE_CXX_KEYWORD;"}, {"sha": "96f04764c581e9ab85308e42bc065aa0eed8cab6", "filename": "gcc/gengtype-parse.c", "status": "modified", "additions": 51, "deletions": 7, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype-parse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype-parse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgengtype-parse.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -197,6 +197,23 @@ require2 (int t1, int t2)\n   return v;\n }\n \n+/* If the next token does not have one of the codes T1, T2 or T3, report a\n+   parse error; otherwise return the token's value.  */\n+static const char *\n+require3 (int t1, int t2, int t3)\n+{\n+  int u = token ();\n+  const char *v = advance ();\n+  if (u != t1 && u != t2 && u != t3)\n+    {\n+      parse_error (\"expected %s, %s or %s, have %s\",\n+\t\t   print_token (t1, 0), print_token (t2, 0),\n+\t\t   print_token (t3, 0), print_token (u, v));\n+      return 0;\n+    }\n+  return v;\n+}\n+\n /* Near-terminals.  */\n \n /* C-style string constant concatenation: STRING+\n@@ -243,18 +260,45 @@ require_template_declaration (const char *tmpl_name)\n   str = concat (tmpl_name, \"<\", (char *) 0);\n \n   /* Read the comma-separated list of identifiers.  */\n-  while (token () != '>')\n+  int depth = 1;\n+  while (depth > 0)\n     {\n-      const char *id = require2 (ID, ',');\n+      if (token () == ENUM)\n+\t{\n+\t  advance ();\n+\t  str = concat (str, \"enum \", (char *) 0);\n+\t  continue;\n+\t}\n+      if (token () == NUM)\n+\t{\n+\t  str = concat (str, advance (), (char *) 0);\n+\t  continue;\n+\t}\n+      if (token () == ':')\n+\t{\n+\t  advance ();\n+\t  str = concat (str, \":\", (char *) 0);\n+\t  continue;\n+\t}\n+      if (token () == '<')\n+\t{\n+\t  advance ();\n+\t  str = concat (str, \"<\", (char *) 0);\n+\t  depth += 1;\n+\t  continue;\n+\t}\n+      if (token () == '>')\n+\t{\n+\t  advance ();\n+\t  str = concat (str, \">\", (char *) 0);\n+\t  depth -= 1;\n+\t  continue;\n+\t}\n+      const char *id = require3 (SCALAR, ID, ',');\n       if (id == NULL)\n \tid = \",\";\n       str = concat (str, id, (char *) 0);\n     }\n-\n-  /* Recognize the closing '>'.  */\n-  require ('>');\n-  str = concat (str, \">\", (char *) 0);\n-\n   return str;\n }\n "}, {"sha": "2ca0e1de1e74c3af0ef6f1535ca7a48ddf340911", "filename": "gcc/gengtype-state.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype-state.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype-state.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgengtype-state.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -30,7 +30,6 @@\n #endif\n #include \"system.h\"\n #include \"errors.h\"\t/* For fatal.  */\n-#include \"double-int.h\"\n #include \"hashtab.h\"\n #include \"version.h\"\t/* For version_string & pkgversion_string.  */\n #include \"obstack.h\""}, {"sha": "1c13eeaf7d49fc25721ca49990d886eea8cd089b", "filename": "gcc/gengtype.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgengtype.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgengtype.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -25,7 +25,6 @@\n #include \"system.h\"\n #include \"errors.h\"\t\t/* for fatal */\n #include \"getopt.h\"\n-#include \"double-int.h\"\n #include \"version.h\"\t\t/* for version_string & pkgversion_string.  */\n #include \"hashtab.h\"\n #include \"xregex.h\"\n@@ -535,7 +534,7 @@ do_typedef (const char *s, type_p t, struct fileloc *pos)\n   for (p = typedefs; p != NULL; p = p->next)\n     if (strcmp (p->name, s) == 0)\n       {\n-\tif (p->type != t)\n+\tif (p->type != t && strcmp (s, \"result_type\") != 0)\n \t  {\n \t    error_at_line (pos, \"type `%s' previously defined\", s);\n \t    error_at_line (&p->line, \"previously defined here\");\n@@ -1766,7 +1765,7 @@ open_base_files (void)\n     static const char *const ifiles[] = {\n       \"config.h\", \"system.h\", \"coretypes.h\", \"tm.h\",\n       \"hashtab.h\", \"splay-tree.h\", \"obstack.h\", \"bitmap.h\", \"input.h\",\n-      \"tree.h\", \"rtl.h\", \"function.h\", \"insn-config.h\", \"expr.h\",\n+      \"tree.h\", \"rtl.h\", \"wide-int.h\", \"function.h\", \"insn-config.h\", \"expr.h\",\n       \"hard-reg-set.h\", \"basic-block.h\", \"cselib.h\", \"insn-addr.h\",\n       \"optabs.h\", \"libfuncs.h\", \"debug.h\", \"ggc.h\", \"cgraph.h\",\n       \"pointer-set.h\", \"hash-table.h\", \"vec.h\", \"ggc.h\", \"basic-block.h\",\n@@ -5670,6 +5669,8 @@ main (int argc, char **argv)\n       POS_HERE (do_scalar_typedef (\"REAL_VALUE_TYPE\", &pos));\n       POS_HERE (do_scalar_typedef (\"FIXED_VALUE_TYPE\", &pos));\n       POS_HERE (do_scalar_typedef (\"double_int\", &pos));\n+      POS_HERE (do_scalar_typedef (\"offset_int\", &pos));\n+      POS_HERE (do_scalar_typedef (\"widest_int\", &pos));\n       POS_HERE (do_scalar_typedef (\"uint64_t\", &pos));\n       POS_HERE (do_scalar_typedef (\"uint8\", &pos));\n       POS_HERE (do_scalar_typedef (\"uintptr_t\", &pos));"}, {"sha": "1fcf611f9c767670da73776d76fb46f61d9233dd", "filename": "gcc/genpreds.c", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgenpreds.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgenpreds.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgenpreds.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -612,7 +612,7 @@ write_one_predicate_function (struct pred_data *p)\n   add_mode_tests (p);\n \n   /* A normal predicate can legitimately not look at enum machine_mode\n-     if it accepts only CONST_INTs and/or CONST_DOUBLEs.  */\n+     if it accepts only CONST_INTs and/or CONST_WIDE_INT and/or CONST_DOUBLEs.  */\n   printf (\"int\\n%s (rtx op, enum machine_mode mode ATTRIBUTE_UNUSED)\\n{\\n\",\n \t  p->name);\n   write_predicate_stmts (p->exp);\n@@ -1075,12 +1075,17 @@ write_tm_constrs_h (void)\n \tif (needs_ival)\n \t  puts (\"  if (CONST_INT_P (op))\\n\"\n \t\t\"    ival = INTVAL (op);\");\n+#if TARGET_SUPPORTS_WIDE_INT\n+\tif (needs_lval || needs_hval)\n+\t  error (\"you can't use lval or hval\");\n+#else\n \tif (needs_hval)\n \t  puts (\"  if (GET_CODE (op) == CONST_DOUBLE && mode == VOIDmode)\"\n \t\t\"    hval = CONST_DOUBLE_HIGH (op);\");\n \tif (needs_lval)\n \t  puts (\"  if (GET_CODE (op) == CONST_DOUBLE && mode == VOIDmode)\"\n \t\t\"    lval = CONST_DOUBLE_LOW (op);\");\n+#endif\n \tif (needs_rval)\n \t  puts (\"  if (GET_CODE (op) == CONST_DOUBLE && mode != VOIDmode)\"\n \t\t\"    rval = CONST_DOUBLE_REAL_VALUE (op);\");"}, {"sha": "457b59c901d95d30d90af0dcc1d31380a86730f8", "filename": "gcc/genrecog.c", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgenrecog.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgenrecog.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgenrecog.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -586,6 +586,7 @@ validate_pattern (rtx pattern, rtx insn, rtx set, int set_code)\n \t\t && GET_CODE (src) != PC\n \t\t && GET_CODE (src) != CC0\n \t\t && !CONST_INT_P (src)\n+\t\t && !CONST_WIDE_INT_P (src)\n \t\t && GET_CODE (src) != CALL)\n \t  {\n \t    const char *which;\n@@ -770,13 +771,14 @@ add_to_sequence (rtx pattern, struct decision_head *last,\n \n \t       We can optimize the generated code a little if either\n \t       (a) the predicate only accepts one code, or (b) the\n-\t       predicate does not allow CONST_INT, in which case it\n-\t       can match only if the modes match.  */\n+\t       predicate does not allow CONST_INT or CONST_WIDE_INT,\n+\t       in which case it can match only if the modes match.  */\n \t    pred = lookup_predicate (pred_name);\n \t    if (pred)\n \t      {\n \t\ttest->u.pred.data = pred;\n-\t\tallows_const_int = pred->codes[CONST_INT];\n+\t\tallows_const_int = (pred->codes[CONST_INT]\n+\t\t\t\t    || pred->codes[CONST_WIDE_INT]);\n \t\tif (was_code == MATCH_PARALLEL\n \t\t    && pred->singleton != PARALLEL)\n \t\t  error_with_line (pattern_lineno,"}, {"sha": "b51f04d28fbaa180fe3127767044d86352c4fec4", "filename": "gcc/gensupport.c", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgensupport.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgensupport.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgensupport.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2806,7 +2806,12 @@ static const struct std_pred_table std_preds[] = {\n   {\"scratch_operand\", false, false, {SCRATCH, REG}},\n   {\"immediate_operand\", false, true, {UNKNOWN}},\n   {\"const_int_operand\", false, false, {CONST_INT}},\n+#if TARGET_SUPPORTS_WIDE_INT\n+  {\"const_scalar_int_operand\", false, false, {CONST_INT, CONST_WIDE_INT}},\n+  {\"const_double_operand\", false, false, {CONST_DOUBLE}},\n+#else\n   {\"const_double_operand\", false, false, {CONST_INT, CONST_DOUBLE}},\n+#endif\n   {\"nonimmediate_operand\", false, false, {SUBREG, REG, MEM}},\n   {\"nonmemory_operand\", false, true, {SUBREG, REG}},\n   {\"push_operand\", false, false, {MEM}},"}, {"sha": "9d42e6af685d9dbff402a29a0d286953bacf0279", "filename": "gcc/gimple-fold.c", "status": "modified", "additions": 70, "deletions": 69, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple-fold.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple-fold.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-fold.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2836,7 +2836,7 @@ get_base_constructor (tree base, HOST_WIDE_INT *bit_offset,\n \t{\n \t  if (!tree_fits_shwi_p (TREE_OPERAND (base, 1)))\n \t    return NULL_TREE;\n-\t  *bit_offset += (mem_ref_offset (base).low\n+\t  *bit_offset += (mem_ref_offset (base).to_short_addr ()\n \t\t\t  * BITS_PER_UNIT);\n \t}\n \n@@ -2931,9 +2931,10 @@ fold_array_ctor_reference (tree type, tree ctor,\n {\n   unsigned HOST_WIDE_INT cnt;\n   tree cfield, cval;\n-  double_int low_bound, elt_size;\n-  double_int index, max_index;\n-  double_int access_index;\n+  offset_int low_bound;\n+  offset_int elt_size;\n+  offset_int index, max_index;\n+  offset_int access_index;\n   tree domain_type = NULL_TREE, index_type = NULL_TREE;\n   HOST_WIDE_INT inner_offset;\n \n@@ -2945,32 +2946,30 @@ fold_array_ctor_reference (tree type, tree ctor,\n       /* Static constructors for variably sized objects makes no sense.  */\n       gcc_assert (TREE_CODE (TYPE_MIN_VALUE (domain_type)) == INTEGER_CST);\n       index_type = TREE_TYPE (TYPE_MIN_VALUE (domain_type));\n-      low_bound = tree_to_double_int (TYPE_MIN_VALUE (domain_type));\n+      low_bound = wi::to_offset (TYPE_MIN_VALUE (domain_type));\n     }\n   else\n-    low_bound = double_int_zero;\n+    low_bound = 0;\n   /* Static constructors for variably sized objects makes no sense.  */\n   gcc_assert (TREE_CODE (TYPE_SIZE_UNIT (TREE_TYPE (TREE_TYPE (ctor))))\n \t      == INTEGER_CST);\n-  elt_size =\n-    tree_to_double_int (TYPE_SIZE_UNIT (TREE_TYPE (TREE_TYPE (ctor))));\n-\n+  elt_size = wi::to_offset (TYPE_SIZE_UNIT (TREE_TYPE (TREE_TYPE (ctor))));\n \n   /* We can handle only constantly sized accesses that are known to not\n      be larger than size of array element.  */\n   if (!TYPE_SIZE_UNIT (type)\n       || TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST\n-      || elt_size.slt (tree_to_double_int (TYPE_SIZE_UNIT (type)))\n-      || elt_size.is_zero ())\n+      || wi::lts_p (elt_size, wi::to_offset (TYPE_SIZE_UNIT (type)))\n+      || elt_size == 0)\n     return NULL_TREE;\n \n   /* Compute the array index we look for.  */\n-  access_index = double_int::from_uhwi (offset / BITS_PER_UNIT)\n-\t\t .udiv (elt_size, TRUNC_DIV_EXPR);\n+  access_index = wi::udiv_trunc (offset_int (offset / BITS_PER_UNIT),\n+\t\t\t\t elt_size);\n   access_index += low_bound;\n   if (index_type)\n-    access_index = access_index.ext (TYPE_PRECISION (index_type),\n-\t\t\t\t     TYPE_UNSIGNED (index_type));\n+    access_index = wi::ext (access_index, TYPE_PRECISION (index_type),\n+\t\t\t    TYPE_SIGN (index_type));\n \n   /* And offset within the access.  */\n   inner_offset = offset % (elt_size.to_uhwi () * BITS_PER_UNIT);\n@@ -2980,9 +2979,10 @@ fold_array_ctor_reference (tree type, tree ctor,\n   if (inner_offset + size > elt_size.to_uhwi () * BITS_PER_UNIT)\n     return NULL_TREE;\n \n-  index = low_bound - double_int_one;\n+  index = low_bound - 1;\n   if (index_type)\n-    index = index.ext (TYPE_PRECISION (index_type), TYPE_UNSIGNED (index_type));\n+    index = wi::ext (index, TYPE_PRECISION (index_type),\n+\t\t     TYPE_SIGN (index_type));\n \n   FOR_EACH_CONSTRUCTOR_ELT (CONSTRUCTOR_ELTS (ctor), cnt, cfield, cval)\n     {\n@@ -2992,26 +2992,26 @@ fold_array_ctor_reference (tree type, tree ctor,\n       if (cfield)\n \t{\n \t  if (TREE_CODE (cfield) == INTEGER_CST)\n-\t    max_index = index = tree_to_double_int (cfield);\n+\t    max_index = index = wi::to_offset (cfield);\n \t  else\n \t    {\n \t      gcc_assert (TREE_CODE (cfield) == RANGE_EXPR);\n-\t      index = tree_to_double_int (TREE_OPERAND (cfield, 0));\n-\t      max_index = tree_to_double_int (TREE_OPERAND (cfield, 1));\n+\t      index = wi::to_offset (TREE_OPERAND (cfield, 0));\n+\t      max_index = wi::to_offset (TREE_OPERAND (cfield, 1));\n \t    }\n \t}\n       else\n \t{\n-\t  index += double_int_one;\n+\t  index += 1;\n \t  if (index_type)\n-\t    index = index.ext (TYPE_PRECISION (index_type),\n-\t\t\t       TYPE_UNSIGNED (index_type));\n+\t    index = wi::ext (index, TYPE_PRECISION (index_type),\n+\t\t\t     TYPE_SIGN (index_type));\n \t  max_index = index;\n \t}\n \n       /* Do we have match?  */\n-      if (access_index.cmp (index, 1) >= 0\n-\t  && access_index.cmp (max_index, 1) <= 0)\n+      if (wi::cmpu (access_index, index) >= 0\n+\t  && wi::cmpu (access_index, max_index) <= 0)\n \treturn fold_ctor_reference (type, cval, inner_offset, size,\n \t\t\t\t    from_decl);\n     }\n@@ -3038,10 +3038,8 @@ fold_nonarray_ctor_reference (tree type, tree ctor,\n       tree byte_offset = DECL_FIELD_OFFSET (cfield);\n       tree field_offset = DECL_FIELD_BIT_OFFSET (cfield);\n       tree field_size = DECL_SIZE (cfield);\n-      double_int bitoffset;\n-      double_int byte_offset_cst = tree_to_double_int (byte_offset);\n-      double_int bits_per_unit_cst = double_int::from_uhwi (BITS_PER_UNIT);\n-      double_int bitoffset_end, access_end;\n+      offset_int bitoffset;\n+      offset_int bitoffset_end, access_end;\n \n       /* Variable sized objects in static constructors makes no sense,\n \t but field_size can be NULL for flexible array members.  */\n@@ -3052,30 +3050,30 @@ fold_nonarray_ctor_reference (tree type, tree ctor,\n \t\t      : TREE_CODE (TREE_TYPE (cfield)) == ARRAY_TYPE));\n \n       /* Compute bit offset of the field.  */\n-      bitoffset = tree_to_double_int (field_offset)\n-\t\t  + byte_offset_cst * bits_per_unit_cst;\n+      bitoffset = (wi::to_offset (field_offset)\n+\t\t   + wi::lshift (wi::to_offset (byte_offset),\n+\t\t\t\t LOG2_BITS_PER_UNIT));\n       /* Compute bit offset where the field ends.  */\n       if (field_size != NULL_TREE)\n-\tbitoffset_end = bitoffset + tree_to_double_int (field_size);\n+\tbitoffset_end = bitoffset + wi::to_offset (field_size);\n       else\n-\tbitoffset_end = double_int_zero;\n+\tbitoffset_end = 0;\n \n-      access_end = double_int::from_uhwi (offset)\n-\t\t   + double_int::from_uhwi (size);\n+      access_end = offset_int (offset) + size;\n \n       /* Is there any overlap between [OFFSET, OFFSET+SIZE) and\n \t [BITOFFSET, BITOFFSET_END)?  */\n-      if (access_end.cmp (bitoffset, 0) > 0\n+      if (wi::cmps (access_end, bitoffset) > 0\n \t  && (field_size == NULL_TREE\n-\t      || double_int::from_uhwi (offset).slt (bitoffset_end)))\n+\t      || wi::lts_p (offset, bitoffset_end)))\n \t{\n-\t  double_int inner_offset = double_int::from_uhwi (offset) - bitoffset;\n+\t  offset_int inner_offset = offset_int (offset) - bitoffset;\n \t  /* We do have overlap.  Now see if field is large enough to\n \t     cover the access.  Give up for accesses spanning multiple\n \t     fields.  */\n-\t  if (access_end.cmp (bitoffset_end, 0) > 0)\n+\t  if (wi::cmps (access_end, bitoffset_end) > 0)\n \t    return NULL_TREE;\n-\t  if (double_int::from_uhwi (offset).slt (bitoffset))\n+\t  if (wi::lts_p (offset, bitoffset))\n \t    return NULL_TREE;\n \t  return fold_ctor_reference (type, cval,\n \t\t\t\t      inner_offset.to_uhwi (), size,\n@@ -3166,37 +3164,42 @@ fold_const_aggregate_ref_1 (tree t, tree (*valueize) (tree))\n \t  && TREE_CODE (idx) == INTEGER_CST)\n \t{\n \t  tree low_bound, unit_size;\n-\t  double_int doffset;\n \n \t  /* If the resulting bit-offset is constant, track it.  */\n \t  if ((low_bound = array_ref_low_bound (t),\n \t       TREE_CODE (low_bound) == INTEGER_CST)\n \t      && (unit_size = array_ref_element_size (t),\n-\t\t  tree_fits_uhwi_p (unit_size))\n-\t      && (doffset = (TREE_INT_CST (idx) - TREE_INT_CST (low_bound))\n-\t\t\t    .sext (TYPE_PRECISION (TREE_TYPE (idx))),\n-\t\t  doffset.fits_shwi ()))\n+\t\t  tree_fits_uhwi_p (unit_size)))\n \t    {\n-\t      offset = doffset.to_shwi ();\n-\t      offset *= tree_to_uhwi (unit_size);\n-\t      offset *= BITS_PER_UNIT;\n-\n-\t      base = TREE_OPERAND (t, 0);\n-\t      ctor = get_base_constructor (base, &offset, valueize);\n-\t      /* Empty constructor.  Always fold to 0.  */\n-\t      if (ctor == error_mark_node)\n-\t\treturn build_zero_cst (TREE_TYPE (t));\n-\t      /* Out of bound array access.  Value is undefined,\n-\t\t but don't fold.  */\n-\t      if (offset < 0)\n-\t\treturn NULL_TREE;\n-\t      /* We can not determine ctor.  */\n-\t      if (!ctor)\n-\t\treturn NULL_TREE;\n-\t      return fold_ctor_reference (TREE_TYPE (t), ctor, offset,\n-\t\t\t\t\t  tree_to_uhwi (unit_size)\n-\t\t\t\t\t  * BITS_PER_UNIT,\n-\t\t\t\t\t  base);\n+\t      offset_int woffset\n+\t\t= wi::sext (wi::to_offset (idx) - wi::to_offset (low_bound),\n+\t\t\t    TYPE_PRECISION (TREE_TYPE (idx)));\n+\n+\t      if (wi::fits_shwi_p (woffset))\n+\t\t{\n+\t\t  offset = woffset.to_shwi ();\n+\t\t  /* TODO: This code seems wrong, multiply then check\n+\t\t     to see if it fits.  */\n+\t\t  offset *= tree_to_uhwi (unit_size);\n+\t\t  offset *= BITS_PER_UNIT;\n+\n+\t\t  base = TREE_OPERAND (t, 0);\n+\t\t  ctor = get_base_constructor (base, &offset, valueize);\n+\t\t  /* Empty constructor.  Always fold to 0.  */\n+\t\t  if (ctor == error_mark_node)\n+\t\t    return build_zero_cst (TREE_TYPE (t));\n+\t\t  /* Out of bound array access.  Value is undefined,\n+\t\t     but don't fold.  */\n+\t\t  if (offset < 0)\n+\t\t    return NULL_TREE;\n+\t\t  /* We can not determine ctor.  */\n+\t\t  if (!ctor)\n+\t\t    return NULL_TREE;\n+\t\t  return fold_ctor_reference (TREE_TYPE (t), ctor, offset,\n+\t\t\t\t\t      tree_to_uhwi (unit_size)\n+\t\t\t\t\t      * BITS_PER_UNIT,\n+\t\t\t\t\t      base);\n+\t\t}\n \t    }\n \t}\n       /* Fallthru.  */\n@@ -3503,7 +3506,7 @@ gimple_val_nonnegative_real_p (tree val)\n \t\t  if ((n & 1) == 0)\n \t\t    {\n \t\t      REAL_VALUE_TYPE cint;\n-\t\t      real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);\n+\t\t      real_from_integer (&cint, VOIDmode, n, SIGNED);\n \t\t      if (real_identical (&c, &cint))\n \t\t\treturn true;\n \t\t    }\n@@ -3616,9 +3619,7 @@ gimple_fold_indirect_ref (tree t)\n \t  || DECL_P (TREE_OPERAND (addr, 0)))\n \treturn fold_build2 (MEM_REF, type,\n \t\t\t    addr,\n-\t\t\t    build_int_cst_wide (ptype,\n-\t\t\t\t\t\tTREE_INT_CST_LOW (off),\n-\t\t\t\t\t\tTREE_INT_CST_HIGH (off)));\n+\t\t\t    wide_int_to_tree (ptype, off));\n     }\n \n   /* *(foo *)fooarrptr => (*fooarrptr)[0] */"}, {"sha": "77afa20dfe518def8accb73dae4c621db47b854c", "filename": "gcc/gimple-pretty-print.c", "status": "modified", "additions": 5, "deletions": 11, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-pretty-print.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1755,7 +1755,7 @@ dump_ssaname_info (pretty_printer *buffer, tree node, int spc)\n   if (!POINTER_TYPE_P (TREE_TYPE (node))\n       && SSA_NAME_RANGE_INFO (node))\n     {\n-      double_int min, max, nonzero_bits;\n+      wide_int min, max, nonzero_bits;\n       value_range_type range_type = get_range_info (node, &min, &max);\n \n       if (range_type == VR_VARYING)\n@@ -1764,22 +1764,16 @@ dump_ssaname_info (pretty_printer *buffer, tree node, int spc)\n \t{\n \t  pp_printf (buffer, \"# RANGE \");\n \t  pp_printf (buffer, \"%s[\", range_type == VR_RANGE ? \"\" : \"~\");\n-\t  pp_double_int (buffer, min, TYPE_UNSIGNED (TREE_TYPE (node)));\n+\t  pp_wide_int (buffer, min, TYPE_SIGN (TREE_TYPE (node)));\n \t  pp_printf (buffer, \", \");\n-\t  pp_double_int (buffer, max, TYPE_UNSIGNED (TREE_TYPE (node)));\n+\t  pp_wide_int (buffer, max, TYPE_SIGN (TREE_TYPE (node)));\n \t  pp_printf (buffer, \"]\");\n \t}\n       nonzero_bits = get_nonzero_bits (node);\n-      if (nonzero_bits != double_int_minus_one\n-\t  && (nonzero_bits\n-\t      != double_int::mask (TYPE_PRECISION (TREE_TYPE (node)))))\n+      if (nonzero_bits != -1)\n \t{\n \t  pp_string (buffer, \" NONZERO \");\n-\t  sprintf (pp_buffer (buffer)->digit_buffer,\n-\t\t   HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t\t   (unsigned HOST_WIDE_INT) nonzero_bits.high,\n-\t\t   nonzero_bits.low);\n-\t  pp_string (buffer, pp_buffer (buffer)->digit_buffer);\n+\t  pp_wide_int (buffer, nonzero_bits, UNSIGNED);\n \t}\n       newline_and_indent (buffer, spc);\n     }"}, {"sha": "a41d9722dae19a5c18e19f8fdccaf7dbf0ef16ac", "filename": "gcc/gimple-ssa-strength-reduction.c", "status": "modified", "additions": 115, "deletions": 124, "changes": 239, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple-ssa-strength-reduction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple-ssa-strength-reduction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-strength-reduction.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -63,6 +63,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"params.h\"\n #include \"tree-ssa-address.h\"\n #include \"tree-affine.h\"\n+#include \"wide-int-print.h\"\n \f\n /* Information about a strength reduction candidate.  Each statement\n    in the candidate table represents an expression of one of the\n@@ -244,7 +245,7 @@ struct slsr_cand_d\n   tree stride;\n \n   /* The index constant i.  */\n-  double_int index;\n+  widest_int index;\n \n   /* The type of the candidate.  This is normally the type of base_expr,\n      but casts may have occurred when combining feeding instructions.\n@@ -319,7 +320,7 @@ typedef const struct cand_chain_d *const_cand_chain_t;\n struct incr_info_d\n {\n   /* The increment that relates a candidate to its basis.  */\n-  double_int incr;\n+  widest_int incr;\n \n   /* How many times the increment occurs in the candidate tree.  */\n   unsigned count;\n@@ -454,7 +455,7 @@ get_alternative_base (tree base)\n \n       tree_to_aff_combination_expand (base, TREE_TYPE (base),\n \t\t\t\t      &aff, &name_expansions);\n-      aff.offset = tree_to_double_int (integer_zero_node);\n+      aff.offset = 0;\n       expr = aff_combination_to_tree (&aff);\n \n       result = (tree *) pointer_map_insert (alt_base_map, base);\n@@ -627,7 +628,7 @@ record_potential_basis (slsr_cand_t c, tree base)\n \n static slsr_cand_t\n alloc_cand_and_find_basis (enum cand_kind kind, gimple gs, tree base,\n-\t\t\t   double_int index, tree stride, tree ctype,\n+\t\t\t   const widest_int &index, tree stride, tree ctype,\n \t\t\t   unsigned savings)\n {\n   slsr_cand_t c = (slsr_cand_t) obstack_alloc (&cand_obstack,\n@@ -824,8 +825,8 @@ slsr_process_phi (gimple phi, bool speed)\n      CAND_PHI.  */\n   base_type = TREE_TYPE (arg0_base);\n \n-  c = alloc_cand_and_find_basis (CAND_PHI, phi, arg0_base, double_int_zero,\n-\t\t\t\t integer_one_node, base_type, savings);\n+  c = alloc_cand_and_find_basis (CAND_PHI, phi, arg0_base,\n+\t\t\t\t 0, integer_one_node, base_type, savings);\n \n   /* Add the candidate to the statement-candidate mapping.  */\n   add_cand_for_stmt (phi, c);\n@@ -842,7 +843,7 @@ slsr_process_phi (gimple phi, bool speed)\n    int (i * S).\n    Otherwise, just return double int zero.  */\n \n-static double_int\n+static widest_int\n backtrace_base_for_ref (tree *pbase)\n {\n   tree base_in = *pbase;\n@@ -858,19 +859,19 @@ backtrace_base_for_ref (tree *pbase)\n     base_in = get_unwidened (base_in, NULL_TREE);\n \n   if (TREE_CODE (base_in) != SSA_NAME)\n-    return tree_to_double_int (integer_zero_node);\n+    return 0;\n \n   base_cand = base_cand_from_table (base_in);\n \n   while (base_cand && base_cand->kind != CAND_PHI)\n     {\n       if (base_cand->kind == CAND_ADD\n-\t  && base_cand->index.is_one ()\n+\t  && base_cand->index == 1\n \t  && TREE_CODE (base_cand->stride) == INTEGER_CST)\n \t{\n \t  /* X = B + (1 * S), S is integer constant.  */\n \t  *pbase = base_cand->base_expr;\n-\t  return tree_to_double_int (base_cand->stride);\n+\t  return wi::to_widest (base_cand->stride);\n \t}\n       else if (base_cand->kind == CAND_ADD\n \t       && TREE_CODE (base_cand->stride) == INTEGER_CST\n@@ -887,7 +888,7 @@ backtrace_base_for_ref (tree *pbase)\n \tbase_cand = NULL;\n     }\n \n-  return tree_to_double_int (integer_zero_node);\n+  return 0;\n }\n \n /* Look for the following pattern:\n@@ -917,38 +918,35 @@ backtrace_base_for_ref (tree *pbase)\n     *PINDEX:   C1 + (C2 * C3) + C4 + (C5 * C3)  */\n \n static bool\n-restructure_reference (tree *pbase, tree *poffset, double_int *pindex,\n+restructure_reference (tree *pbase, tree *poffset, widest_int *pindex,\n \t\t       tree *ptype)\n {\n   tree base = *pbase, offset = *poffset;\n-  double_int index = *pindex;\n-  double_int bpu = double_int::from_uhwi (BITS_PER_UNIT);\n-  tree mult_op0, mult_op1, t1, t2, type;\n-  double_int c1, c2, c3, c4, c5;\n+  widest_int index = *pindex;\n+  tree mult_op0, t1, t2, type;\n+  widest_int c1, c2, c3, c4, c5;\n \n   if (!base\n       || !offset\n       || TREE_CODE (base) != MEM_REF\n       || TREE_CODE (offset) != MULT_EXPR\n       || TREE_CODE (TREE_OPERAND (offset, 1)) != INTEGER_CST\n-      || !index.umod (bpu, FLOOR_MOD_EXPR).is_zero ())\n+      || wi::umod_floor (index, BITS_PER_UNIT) != 0)\n     return false;\n \n   t1 = TREE_OPERAND (base, 0);\n-  c1 = mem_ref_offset (base);\n+  c1 = widest_int::from (mem_ref_offset (base), SIGNED);\n   type = TREE_TYPE (TREE_OPERAND (base, 1));\n \n   mult_op0 = TREE_OPERAND (offset, 0);\n-  mult_op1 = TREE_OPERAND (offset, 1);\n-\n-  c3 = tree_to_double_int (mult_op1);\n+  c3 = wi::to_widest (TREE_OPERAND (offset, 1));\n \n   if (TREE_CODE (mult_op0) == PLUS_EXPR)\n \n     if (TREE_CODE (TREE_OPERAND (mult_op0, 1)) == INTEGER_CST)\n       {\n \tt2 = TREE_OPERAND (mult_op0, 0);\n-\tc2 = tree_to_double_int (TREE_OPERAND (mult_op0, 1));\n+\tc2 = wi::to_widest (TREE_OPERAND (mult_op0, 1));\n       }\n     else\n       return false;\n@@ -958,23 +956,23 @@ restructure_reference (tree *pbase, tree *poffset, double_int *pindex,\n     if (TREE_CODE (TREE_OPERAND (mult_op0, 1)) == INTEGER_CST)\n       {\n \tt2 = TREE_OPERAND (mult_op0, 0);\n-\tc2 = -tree_to_double_int (TREE_OPERAND (mult_op0, 1));\n+\tc2 = -wi::to_widest (TREE_OPERAND (mult_op0, 1));\n       }\n     else\n       return false;\n \n   else\n     {\n       t2 = mult_op0;\n-      c2 = double_int_zero;\n+      c2 = 0;\n     }\n \n-  c4 = index.udiv (bpu, FLOOR_DIV_EXPR);\n+  c4 = wi::lrshift (index, LOG2_BITS_PER_UNIT);\n   c5 = backtrace_base_for_ref (&t2);\n \n   *pbase = t1;\n   *poffset = fold_build2 (MULT_EXPR, sizetype, fold_convert (sizetype, t2),\n-\t\t\t  double_int_to_tree (sizetype, c3));\n+\t\t\t  wide_int_to_tree (sizetype, c3));\n   *pindex = c1 + c2 * c3 + c4 + c5 * c3;\n   *ptype = type;\n \n@@ -991,7 +989,6 @@ slsr_process_ref (gimple gs)\n   HOST_WIDE_INT bitsize, bitpos;\n   enum machine_mode mode;\n   int unsignedp, volatilep;\n-  double_int index;\n   slsr_cand_t c;\n \n   if (gimple_vdef (gs))\n@@ -1007,7 +1004,7 @@ slsr_process_ref (gimple gs)\n \n   base = get_inner_reference (ref_expr, &bitsize, &bitpos, &offset, &mode,\n \t\t\t      &unsignedp, &volatilep, false);\n-  index = double_int::from_uhwi (bitpos);\n+  widest_int index = bitpos;\n \n   if (!restructure_reference (&base, &offset, &index, &type))\n     return;\n@@ -1028,7 +1025,7 @@ static slsr_cand_t\n create_mul_ssa_cand (gimple gs, tree base_in, tree stride_in, bool speed)\n {\n   tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL_TREE;\n-  double_int index;\n+  widest_int index;\n   unsigned savings = 0;\n   slsr_cand_t c;\n   slsr_cand_t base_cand = base_cand_from_table (base_in);\n@@ -1060,7 +1057,7 @@ create_mul_ssa_cand (gimple gs, tree base_in, tree stride_in, bool speed)\n \t     ============================\n \t     X = B + ((i' * S) * Z)  */\n \t  base = base_cand->base_expr;\n-\t  index = base_cand->index * tree_to_double_int (base_cand->stride);\n+\t  index = base_cand->index * wi::to_widest (base_cand->stride);\n \t  stride = stride_in;\n \t  ctype = base_cand->cand_type;\n \t  if (has_single_use (base_in))\n@@ -1079,7 +1076,7 @@ create_mul_ssa_cand (gimple gs, tree base_in, tree stride_in, bool speed)\n       /* No interpretations had anything useful to propagate, so\n \t produce X = (Y + 0) * Z.  */\n       base = base_in;\n-      index = double_int_zero;\n+      index = 0;\n       stride = stride_in;\n       ctype = TREE_TYPE (base_in);\n     }\n@@ -1098,7 +1095,7 @@ static slsr_cand_t\n create_mul_imm_cand (gimple gs, tree base_in, tree stride_in, bool speed)\n {\n   tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL_TREE;\n-  double_int index, temp;\n+  widest_int index, temp;\n   unsigned savings = 0;\n   slsr_cand_t c;\n   slsr_cand_t base_cand = base_cand_from_table (base_in);\n@@ -1114,13 +1111,12 @@ create_mul_imm_cand (gimple gs, tree base_in, tree stride_in, bool speed)\n \t     X = Y * c\n \t     ============================\n \t     X = (B + i') * (S * c)  */\n-\t  temp = tree_to_double_int (base_cand->stride)\n-\t\t * tree_to_double_int (stride_in);\n-\t  if (double_int_fits_to_tree_p (TREE_TYPE (stride_in), temp))\n+\t  temp = wi::to_widest (base_cand->stride) * wi::to_widest (stride_in);\n+\t  if (wi::fits_to_tree_p (temp, TREE_TYPE (stride_in)))\n \t    {\n \t      base = base_cand->base_expr;\n \t      index = base_cand->index;\n-\t      stride = double_int_to_tree (TREE_TYPE (stride_in), temp);\n+\t      stride = wide_int_to_tree (TREE_TYPE (stride_in), temp);\n \t      ctype = base_cand->cand_type;\n \t      if (has_single_use (base_in))\n \t\tsavings = (base_cand->dead_savings \n@@ -1142,15 +1138,15 @@ create_mul_imm_cand (gimple gs, tree base_in, tree stride_in, bool speed)\n \t\t       + stmt_cost (base_cand->cand_stmt, speed));\n \t}\n       else if (base_cand->kind == CAND_ADD\n-\t       && base_cand->index.is_one ()\n+\t       && base_cand->index == 1\n \t       && TREE_CODE (base_cand->stride) == INTEGER_CST)\n \t{\n \t  /* Y = B + (1 * S), S constant\n \t     X = Y * c\n \t     ===========================\n \t     X = (B + S) * c  */\n \t  base = base_cand->base_expr;\n-\t  index = tree_to_double_int (base_cand->stride);\n+\t  index = wi::to_widest (base_cand->stride);\n \t  stride = stride_in;\n \t  ctype = base_cand->cand_type;\n \t  if (has_single_use (base_in))\n@@ -1169,7 +1165,7 @@ create_mul_imm_cand (gimple gs, tree base_in, tree stride_in, bool speed)\n       /* No interpretations had anything useful to propagate, so\n \t produce X = (Y + 0) * c.  */\n       base = base_in;\n-      index = double_int_zero;\n+      index = 0;\n       stride = stride_in;\n       ctype = TREE_TYPE (base_in);\n     }\n@@ -1232,7 +1228,7 @@ create_add_ssa_cand (gimple gs, tree base_in, tree addend_in,\n \t\t     bool subtract_p, bool speed)\n {\n   tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL;\n-  double_int index;\n+  widest_int index;\n   unsigned savings = 0;\n   slsr_cand_t c;\n   slsr_cand_t base_cand = base_cand_from_table (base_in);\n@@ -1243,15 +1239,15 @@ create_add_ssa_cand (gimple gs, tree base_in, tree addend_in,\n   while (addend_cand && !base && addend_cand->kind != CAND_PHI)\n     {\n       if (addend_cand->kind == CAND_MULT\n-\t  && addend_cand->index.is_zero ()\n+\t  && addend_cand->index == 0\n \t  && TREE_CODE (addend_cand->stride) == INTEGER_CST)\n \t{\n \t  /* Z = (B + 0) * S, S constant\n \t     X = Y +/- Z\n \t     ===========================\n \t     X = Y + ((+/-1 * S) * B)  */\n \t  base = base_in;\n-\t  index = tree_to_double_int (addend_cand->stride);\n+\t  index = wi::to_widest (addend_cand->stride);\n \t  if (subtract_p)\n \t    index = -index;\n \t  stride = addend_cand->base_expr;\n@@ -1270,7 +1266,7 @@ create_add_ssa_cand (gimple gs, tree base_in, tree addend_in,\n   while (base_cand && !base && base_cand->kind != CAND_PHI)\n     {\n       if (base_cand->kind == CAND_ADD\n-\t  && (base_cand->index.is_zero ()\n+\t  && (base_cand->index == 0\n \t      || operand_equal_p (base_cand->stride,\n \t\t\t\t  integer_zero_node, 0)))\n \t{\n@@ -1279,7 +1275,7 @@ create_add_ssa_cand (gimple gs, tree base_in, tree addend_in,\n \t     ============================\n \t     X = B + (+/-1 * Z)  */\n \t  base = base_cand->base_expr;\n-\t  index = subtract_p ? double_int_minus_one : double_int_one;\n+\t  index = subtract_p ? -1 : 1;\n \t  stride = addend_in;\n \t  ctype = base_cand->cand_type;\n \t  if (has_single_use (base_in))\n@@ -1293,15 +1289,15 @@ create_add_ssa_cand (gimple gs, tree base_in, tree addend_in,\n \t  while (subtrahend_cand && !base && subtrahend_cand->kind != CAND_PHI)\n \t    {\n \t      if (subtrahend_cand->kind == CAND_MULT\n-\t\t  && subtrahend_cand->index.is_zero ()\n+\t\t  && subtrahend_cand->index == 0\n \t\t  && TREE_CODE (subtrahend_cand->stride) == INTEGER_CST)\n \t\t{\n \t\t  /* Z = (B + 0) * S, S constant\n \t\t     X = Y - Z\n \t\t     ===========================\n \t\t     Value:  X = Y + ((-1 * S) * B)  */\n \t\t  base = base_in;\n-\t\t  index = tree_to_double_int (subtrahend_cand->stride);\n+\t\t  index = wi::to_widest (subtrahend_cand->stride);\n \t\t  index = -index;\n \t\t  stride = subtrahend_cand->base_expr;\n \t\t  ctype = TREE_TYPE (base_in);\n@@ -1328,7 +1324,7 @@ create_add_ssa_cand (gimple gs, tree base_in, tree addend_in,\n       /* No interpretations had anything useful to propagate, so\n \t produce X = Y + (1 * Z).  */\n       base = base_in;\n-      index = subtract_p ? double_int_minus_one : double_int_one;\n+      index = subtract_p ? -1 : 1;\n       stride = addend_in;\n       ctype = TREE_TYPE (base_in);\n     }\n@@ -1343,22 +1339,23 @@ create_add_ssa_cand (gimple gs, tree base_in, tree addend_in,\n    about BASE_IN into the new candidate.  Return the new candidate.  */\n \n static slsr_cand_t\n-create_add_imm_cand (gimple gs, tree base_in, double_int index_in, bool speed)\n+create_add_imm_cand (gimple gs, tree base_in, const widest_int &index_in,\n+\t\t     bool speed)\n {\n   enum cand_kind kind = CAND_ADD;\n   tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL_TREE;\n-  double_int index, multiple;\n+  widest_int index, multiple;\n   unsigned savings = 0;\n   slsr_cand_t c;\n   slsr_cand_t base_cand = base_cand_from_table (base_in);\n \n   while (base_cand && !base && base_cand->kind != CAND_PHI)\n     {\n-      bool unsigned_p = TYPE_UNSIGNED (TREE_TYPE (base_cand->stride));\n+      signop sign = TYPE_SIGN (TREE_TYPE (base_cand->stride));\n \n       if (TREE_CODE (base_cand->stride) == INTEGER_CST\n-\t  && index_in.multiple_of (tree_to_double_int (base_cand->stride),\n-\t\t\t\t   unsigned_p, &multiple))\n+\t  && wi::multiple_of_p (index_in, wi::to_widest (base_cand->stride),\n+\t\t\t\tsign, &multiple))\n \t{\n \t  /* Y = (B + i') * S, S constant, c = kS for some integer k\n \t     X = Y + c\n@@ -1443,10 +1440,8 @@ slsr_process_add (gimple gs, tree rhs1, tree rhs2, bool speed)\n     }\n   else\n     {\n-      double_int index;\n-\n       /* Record an interpretation for the add-immediate.  */\n-      index = tree_to_double_int (rhs2);\n+      widest_int index = wi::to_widest (rhs2);\n       if (subtract_p)\n \tindex = -index;\n \n@@ -1594,10 +1589,10 @@ slsr_process_cast (gimple gs, tree rhs1, bool speed)\n \t The first of these is somewhat arbitrary, but the choice of\n \t 1 for the stride simplifies the logic for propagating casts\n \t into their uses.  */\n-      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1, double_int_zero,\n-\t\t\t\t     integer_one_node, ctype, 0);\n-      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1, double_int_zero,\n-\t\t\t\t      integer_one_node, ctype, 0);\n+      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1,\n+\t\t\t\t     0, integer_one_node, ctype, 0);\n+      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1,\n+\t\t\t\t      0, integer_one_node, ctype, 0);\n       c->next_interp = c2->cand_num;\n     }\n \n@@ -1651,10 +1646,10 @@ slsr_process_copy (gimple gs, tree rhs1, bool speed)\n \t The first of these is somewhat arbitrary, but the choice of\n \t 1 for the stride simplifies the logic for propagating casts\n \t into their uses.  */\n-      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1, double_int_zero,\n-\t\t\t\t     integer_one_node, TREE_TYPE (rhs1), 0);\n-      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1, double_int_zero,\n-\t\t\t\t      integer_one_node, TREE_TYPE (rhs1), 0);\n+      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1,\n+\t\t\t\t     0, integer_one_node, TREE_TYPE (rhs1), 0);\n+      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1,\n+\t\t\t\t      0, integer_one_node, TREE_TYPE (rhs1), 0);\n       c->next_interp = c2->cand_num;\n     }\n \n@@ -1771,7 +1766,7 @@ dump_candidate (slsr_cand_t c)\n       fputs (\"     MULT : (\", dump_file);\n       print_generic_expr (dump_file, c->base_expr, 0);\n       fputs (\" + \", dump_file);\n-      dump_double_int (dump_file, c->index, false);\n+      print_decs (c->index, dump_file);\n       fputs (\") * \", dump_file);\n       print_generic_expr (dump_file, c->stride, 0);\n       fputs (\" : \", dump_file);\n@@ -1780,7 +1775,7 @@ dump_candidate (slsr_cand_t c)\n       fputs (\"     ADD  : \", dump_file);\n       print_generic_expr (dump_file, c->base_expr, 0);\n       fputs (\" + (\", dump_file);\n-      dump_double_int (dump_file, c->index, false);\n+      print_decs (c->index, dump_file);\n       fputs (\" * \", dump_file);\n       print_generic_expr (dump_file, c->stride, 0);\n       fputs (\") : \", dump_file);\n@@ -1791,7 +1786,7 @@ dump_candidate (slsr_cand_t c)\n       fputs (\" + (\", dump_file);\n       print_generic_expr (dump_file, c->stride, 0);\n       fputs (\") + \", dump_file);\n-      dump_double_int (dump_file, c->index, false);\n+      print_decs (c->index, dump_file);\n       fputs (\" : \", dump_file);\n       break;\n     case CAND_PHI:\n@@ -1870,7 +1865,7 @@ dump_incr_vec (void)\n       for (i = 0; i < incr_vec_len; i++)\n \t{\n \t  fprintf (dump_file, \"%3d  increment:   \", i);\n-\t  dump_double_int (dump_file, incr_vec[i].incr, false);\n+\t  print_decs (incr_vec[i].incr, dump_file);\n \t  fprintf (dump_file, \"\\n     count:       %d\", incr_vec[i].count);\n \t  fprintf (dump_file, \"\\n     cost:        %d\", incr_vec[i].cost);\n \t  fputs (\"\\n     initializer: \", dump_file);\n@@ -1901,7 +1896,7 @@ replace_ref (tree *expr, slsr_cand_t c)\n   add_expr = fold_build2 (POINTER_PLUS_EXPR, TREE_TYPE (c->base_expr),\n \t\t\t  c->base_expr, c->stride);\n   mem_ref = fold_build2 (MEM_REF, acc_type, add_expr,\n-\t\t\t double_int_to_tree (c->cand_type, c->index));\n+\t\t\t wide_int_to_tree (c->cand_type, c->index));\n \n   /* Gimplify the base addressing expression for the new MEM_REF tree.  */\n   gimple_stmt_iterator gsi = gsi_for_stmt (c->cand_stmt);\n@@ -1969,7 +1964,7 @@ phi_dependent_cand_p (slsr_cand_t c)\n /* Calculate the increment required for candidate C relative to \n    its basis.  */\n \n-static double_int\n+static widest_int\n cand_increment (slsr_cand_t c)\n {\n   slsr_cand_t basis;\n@@ -1992,12 +1987,12 @@ cand_increment (slsr_cand_t c)\n    for this candidate, return the absolute value of that increment\n    instead.  */\n \n-static inline double_int\n+static inline widest_int\n cand_abs_increment (slsr_cand_t c)\n {\n-  double_int increment = cand_increment (c);\n+  widest_int increment = cand_increment (c);\n \n-  if (!address_arithmetic_p && increment.is_negative ())\n+  if (!address_arithmetic_p && wi::neg_p (increment))\n     increment = -increment;\n \n   return increment;\n@@ -2016,7 +2011,7 @@ cand_already_replaced (slsr_cand_t c)\n    replace_conditional_candidate.  */\n \n static void\n-replace_mult_candidate (slsr_cand_t c, tree basis_name, double_int bump)\n+replace_mult_candidate (slsr_cand_t c, tree basis_name, widest_int bump)\n {\n   tree target_type = TREE_TYPE (gimple_assign_lhs (c->cand_stmt));\n   enum tree_code cand_code = gimple_assign_rhs_code (c->cand_stmt);\n@@ -2026,7 +2021,7 @@ replace_mult_candidate (slsr_cand_t c, tree basis_name, double_int bump)\n      in this case.  This does not affect siblings or dependents\n      of C.  Restriction to signed HWI is conservative for unsigned\n      types but allows for safe negation without twisted logic.  */\n-  if (bump.fits_shwi ()\n+  if (wi::fits_shwi_p (bump)\n       && bump.to_shwi () != HOST_WIDE_INT_MIN\n       /* It is not useful to replace casts, copies, or adds of\n \t an SSA name and a constant.  */\n@@ -2044,21 +2039,21 @@ replace_mult_candidate (slsr_cand_t c, tree basis_name, double_int bump)\n \t types, introduce a cast.  */\n       if (!useless_type_conversion_p (target_type, TREE_TYPE (basis_name)))\n \tbasis_name = introduce_cast_before_cand (c, target_type, basis_name);\n-      if (bump.is_negative ())\n+      if (wi::neg_p (bump))\n \t{\n \t  code = MINUS_EXPR;\n \t  bump = -bump;\n \t}\n \n-      bump_tree = double_int_to_tree (target_type, bump);\n+      bump_tree = wide_int_to_tree (target_type, bump);\n \n       if (dump_file && (dump_flags & TDF_DETAILS))\n \t{\n \t  fputs (\"Replacing: \", dump_file);\n \t  print_gimple_stmt (dump_file, c->cand_stmt, 0, 0);\n \t}\n \n-      if (bump.is_zero ())\n+      if (bump == 0)\n \t{\n \t  tree lhs = gimple_assign_lhs (c->cand_stmt);\n \t  gimple copy_stmt = gimple_build_assign (lhs, basis_name);\n@@ -2119,14 +2114,12 @@ static void\n replace_unconditional_candidate (slsr_cand_t c)\n {\n   slsr_cand_t basis;\n-  double_int stride, bump;\n \n   if (cand_already_replaced (c))\n     return;\n \n   basis = lookup_cand (c->basis);\n-  stride = tree_to_double_int (c->stride);\n-  bump = cand_increment (c) * stride;\n+  widest_int bump = cand_increment (c) * wi::to_widest (c->stride);\n \n   replace_mult_candidate (c, gimple_assign_lhs (basis->cand_stmt), bump);\n }\n@@ -2136,7 +2129,7 @@ replace_unconditional_candidate (slsr_cand_t c)\n    MAX_INCR_VEC_LEN increments have been found.  */\n \n static inline int\n-incr_vec_index (double_int increment)\n+incr_vec_index (const widest_int &increment)\n {\n   unsigned i;\n   \n@@ -2156,7 +2149,7 @@ incr_vec_index (double_int increment)\n \n static tree\n create_add_on_incoming_edge (slsr_cand_t c, tree basis_name,\n-\t\t\t     double_int increment, edge e, location_t loc,\n+\t\t\t     widest_int increment, edge e, location_t loc,\n \t\t\t     bool known_stride)\n {\n   basic_block insert_bb;\n@@ -2167,7 +2160,7 @@ create_add_on_incoming_edge (slsr_cand_t c, tree basis_name,\n   /* If the add candidate along this incoming edge has the same\n      index as C's hidden basis, the hidden basis represents this\n      edge correctly.  */\n-  if (increment.is_zero ())\n+  if (increment == 0)\n     return basis_name;\n \n   basis_type = TREE_TYPE (basis_name);\n@@ -2177,21 +2170,21 @@ create_add_on_incoming_edge (slsr_cand_t c, tree basis_name,\n     {\n       tree bump_tree;\n       enum tree_code code = PLUS_EXPR;\n-      double_int bump = increment * tree_to_double_int (c->stride);\n-      if (bump.is_negative ())\n+      widest_int bump = increment * wi::to_widest (c->stride);\n+      if (wi::neg_p (bump))\n \t{\n \t  code = MINUS_EXPR;\n \t  bump = -bump;\n \t}\n \n-      bump_tree = double_int_to_tree (basis_type, bump);\n+      bump_tree = wide_int_to_tree (basis_type, bump);\n       new_stmt = gimple_build_assign_with_ops (code, lhs, basis_name,\n \t\t\t\t\t       bump_tree);\n     }\n   else\n     {\n       int i;\n-      bool negate_incr = (!address_arithmetic_p && increment.is_negative ());\n+      bool negate_incr = (!address_arithmetic_p && wi::neg_p (increment));\n       i = incr_vec_index (negate_incr ? -increment : increment);\n       gcc_assert (i >= 0);\n \n@@ -2201,10 +2194,10 @@ create_add_on_incoming_edge (slsr_cand_t c, tree basis_name,\n \t  new_stmt = gimple_build_assign_with_ops (code, lhs, basis_name,\n \t\t\t\t\t\t   incr_vec[i].initializer);\n \t}\n-      else if (increment.is_one ())\n+      else if (increment == 1)\n \tnew_stmt = gimple_build_assign_with_ops (PLUS_EXPR, lhs, basis_name,\n \t\t\t\t\t\t c->stride);\n-      else if (increment.is_minus_one ())\n+      else if (increment == -1)\n \tnew_stmt = gimple_build_assign_with_ops (MINUS_EXPR, lhs, basis_name,\n \t\t\t\t\t\t c->stride);\n       else\n@@ -2265,11 +2258,11 @@ create_phi_basis (slsr_cand_t c, gimple from_phi, tree basis_name,\n       /* If the phi argument is the base name of the CAND_PHI, then\n \t this incoming arc should use the hidden basis.  */\n       if (operand_equal_p (arg, phi_cand->base_expr, 0))\n-\tif (basis->index.is_zero ())\n+\tif (basis->index == 0)\n \t  feeding_def = gimple_assign_lhs (basis->cand_stmt);\n \telse\n \t  {\n-\t    double_int incr = -basis->index;\n+\t    widest_int incr = -basis->index;\n \t    feeding_def = create_add_on_incoming_edge (c, basis_name, incr,\n \t\t\t\t\t\t       e, loc, known_stride);\n \t  }\n@@ -2286,7 +2279,7 @@ create_phi_basis (slsr_cand_t c, gimple from_phi, tree basis_name,\n \t  else\n \t    {\n \t      slsr_cand_t arg_cand = base_cand_from_table (arg);\n-\t      double_int diff = arg_cand->index - basis->index;\n+\t      widest_int diff = arg_cand->index - basis->index;\n \t      feeding_def = create_add_on_incoming_edge (c, basis_name, diff,\n \t\t\t\t\t\t\t e, loc, known_stride);\n \t    }\n@@ -2332,7 +2325,6 @@ replace_conditional_candidate (slsr_cand_t c)\n   tree basis_name, name;\n   slsr_cand_t basis;\n   location_t loc;\n-  double_int stride, bump;\n \n   /* Look up the LHS SSA name from C's basis.  This will be the \n      RHS1 of the adds we will introduce to create new phi arguments.  */\n@@ -2345,8 +2337,7 @@ replace_conditional_candidate (slsr_cand_t c)\n   name = create_phi_basis (c, lookup_cand (c->def_phi)->cand_stmt,\n \t\t\t   basis_name, loc, KNOWN_STRIDE);\n   /* Replace C with an add of the new basis phi and a constant.  */\n-  stride = tree_to_double_int (c->stride);\n-  bump = c->index * stride;\n+  widest_int bump = c->index * wi::to_widest (c->stride);\n \n   replace_mult_candidate (c, name, bump);\n }\n@@ -2478,14 +2469,14 @@ count_candidates (slsr_cand_t c)\n    candidates with the same increment, also record T_0 for subsequent use.  */\n \n static void\n-record_increment (slsr_cand_t c, double_int increment, bool is_phi_adjust)\n+record_increment (slsr_cand_t c, widest_int increment, bool is_phi_adjust)\n {\n   bool found = false;\n   unsigned i;\n \n   /* Treat increments that differ only in sign as identical so as to\n      share initializers, unless we are generating pointer arithmetic.  */\n-  if (!address_arithmetic_p && increment.is_negative ())\n+  if (!address_arithmetic_p && wi::neg_p (increment))\n     increment = -increment;\n \n   for (i = 0; i < incr_vec_len; i++)\n@@ -2529,8 +2520,8 @@ record_increment (slsr_cand_t c, double_int increment, bool is_phi_adjust)\n       if (c->kind == CAND_ADD\n \t  && !is_phi_adjust\n \t  && c->index == increment\n-\t  && (increment.sgt (double_int_one)\n-\t      || increment.slt (double_int_minus_one))\n+\t  && (wi::gts_p (increment, 1)\n+\t      || wi::lts_p (increment, -1))\n \t  && (gimple_assign_rhs_code (c->cand_stmt) == PLUS_EXPR\n \t      || gimple_assign_rhs_code (c->cand_stmt) == POINTER_PLUS_EXPR))\n \t{\n@@ -2588,7 +2579,7 @@ record_phi_increments (slsr_cand_t basis, gimple phi)\n \t  else\n \t    {\n \t      slsr_cand_t arg_cand = base_cand_from_table (arg);\n-\t      double_int diff = arg_cand->index - basis->index;\n+\t      widest_int diff = arg_cand->index - basis->index;\n \t      record_increment (arg_cand, diff, PHI_ADJUST);\n \t    }\n \t}\n@@ -2639,7 +2630,7 @@ record_increments (slsr_cand_t c)\n    uses.  */\n \n static int\n-phi_incr_cost (slsr_cand_t c, double_int incr, gimple phi, int *savings)\n+phi_incr_cost (slsr_cand_t c, const widest_int &incr, gimple phi, int *savings)\n {\n   unsigned i;\n   int cost = 0;\n@@ -2664,7 +2655,7 @@ phi_incr_cost (slsr_cand_t c, double_int incr, gimple phi, int *savings)\n \t  else\n \t    {\n \t      slsr_cand_t arg_cand = base_cand_from_table (arg);\n-\t      double_int diff = arg_cand->index - basis->index;\n+\t      widest_int diff = arg_cand->index - basis->index;\n \n \t      if (incr == diff)\n \t\t{\n@@ -2729,10 +2720,10 @@ optimize_cands_for_speed_p (slsr_cand_t c)\n \n static int\n lowest_cost_path (int cost_in, int repl_savings, slsr_cand_t c,\n-\t\t  double_int incr, bool count_phis)\n+\t\t  const widest_int &incr, bool count_phis)\n {\n   int local_cost, sib_cost, savings = 0;\n-  double_int cand_incr = cand_abs_increment (c);\n+  widest_int cand_incr = cand_abs_increment (c);\n \n   if (cand_already_replaced (c))\n     local_cost = cost_in;\n@@ -2775,11 +2766,11 @@ lowest_cost_path (int cost_in, int repl_savings, slsr_cand_t c,\n    would go dead.  */\n \n static int\n-total_savings (int repl_savings, slsr_cand_t c, double_int incr,\n+total_savings (int repl_savings, slsr_cand_t c, const widest_int &incr,\n \t       bool count_phis)\n {\n   int savings = 0;\n-  double_int cand_incr = cand_abs_increment (c);\n+  widest_int cand_incr = cand_abs_increment (c);\n \n   if (incr == cand_incr && !cand_already_replaced (c))\n     savings += repl_savings + c->dead_savings;\n@@ -2829,7 +2820,7 @@ analyze_increments (slsr_cand_t first_dep, enum machine_mode mode, bool speed)\n       /* If somehow this increment is bigger than a HWI, we won't\n \t be optimizing candidates that use it.  And if the increment\n \t has a count of zero, nothing will be done with it.  */\n-      if (!incr_vec[i].incr.fits_shwi () || !incr_vec[i].count)\n+      if (!wi::fits_shwi_p (incr_vec[i].incr) || !incr_vec[i].count)\n \tincr_vec[i].cost = COST_INFINITE;\n \n       /* Increments of 0, 1, and -1 are always profitable to replace,\n@@ -2983,7 +2974,7 @@ ncd_for_two_cands (basic_block bb1, basic_block bb2,\n    candidates, return the earliest candidate in the block in *WHERE.  */\n \n static basic_block\n-ncd_with_phi (slsr_cand_t c, double_int incr, gimple phi,\n+ncd_with_phi (slsr_cand_t c, const widest_int &incr, gimple phi,\n \t      basic_block ncd, slsr_cand_t *where)\n {\n   unsigned i;\n@@ -3003,7 +2994,7 @@ ncd_with_phi (slsr_cand_t c, double_int incr, gimple phi,\n \t  else \n \t    {\n \t      slsr_cand_t arg_cand = base_cand_from_table (arg);\n-\t      double_int diff = arg_cand->index - basis->index;\n+\t      widest_int diff = arg_cand->index - basis->index;\n \t      basic_block pred = gimple_phi_arg_edge (phi, i)->src;\n \n \t      if ((incr == diff) || (!address_arithmetic_p && incr == -diff))\n@@ -3022,7 +3013,7 @@ ncd_with_phi (slsr_cand_t c, double_int incr, gimple phi,\n    return the earliest candidate in the block in *WHERE.  */\n \n static basic_block\n-ncd_of_cand_and_phis (slsr_cand_t c, double_int incr, slsr_cand_t *where)\n+ncd_of_cand_and_phis (slsr_cand_t c, const widest_int &incr, slsr_cand_t *where)\n {\n   basic_block ncd = NULL;\n \n@@ -3047,7 +3038,7 @@ ncd_of_cand_and_phis (slsr_cand_t c, double_int incr, slsr_cand_t *where)\n    *WHERE.  */\n \n static basic_block\n-nearest_common_dominator_for_cands (slsr_cand_t c, double_int incr,\n+nearest_common_dominator_for_cands (slsr_cand_t c, const widest_int &incr,\n \t\t\t\t    slsr_cand_t *where)\n {\n   basic_block sib_ncd = NULL, dep_ncd = NULL, this_ncd = NULL, ncd;\n@@ -3123,13 +3114,13 @@ insert_initializers (slsr_cand_t c)\n       slsr_cand_t where = NULL;\n       gimple init_stmt;\n       tree stride_type, new_name, incr_tree;\n-      double_int incr = incr_vec[i].incr;\n+      widest_int incr = incr_vec[i].incr;\n \n       if (!profitable_increment_p (i)\n-\t  || incr.is_one ()\n-\t  || (incr.is_minus_one ()\n+\t  || incr == 1\n+\t  || (incr == -1\n \t      && gimple_assign_rhs_code (c->cand_stmt) != POINTER_PLUS_EXPR)\n-\t  || incr.is_zero ())\n+\t  || incr == 0)\n \tcontinue;\n \n       /* We may have already identified an existing initializer that\n@@ -3158,7 +3149,7 @@ insert_initializers (slsr_cand_t c)\n \n       /* Create the initializer and insert it in the latest possible\n \t dominating position.  */\n-      incr_tree = double_int_to_tree (stride_type, incr);\n+      incr_tree = wide_int_to_tree (stride_type, incr);\n       init_stmt = gimple_build_assign_with_ops (MULT_EXPR, new_name,\n \t\t\t\t\t\tc->stride, incr_tree);\n       if (where)\n@@ -3215,9 +3206,9 @@ all_phi_incrs_profitable (slsr_cand_t c, gimple phi)\n \t    {\n \t      int j;\n \t      slsr_cand_t arg_cand = base_cand_from_table (arg);\n-\t      double_int increment = arg_cand->index - basis->index;\n+\t      widest_int increment = arg_cand->index - basis->index;\n \n-\t      if (!address_arithmetic_p && increment.is_negative ())\n+\t      if (!address_arithmetic_p && wi::neg_p (increment))\n \t\tincrement = -increment;\n \n \t      j = incr_vec_index (increment);\n@@ -3228,7 +3219,7 @@ all_phi_incrs_profitable (slsr_cand_t c, gimple phi)\n \t\t\t   c->cand_num);\n \t\t  print_gimple_stmt (dump_file, phi, 0, 0);\n \t\t  fputs (\"    increment: \", dump_file);\n-\t\t  dump_double_int (dump_file, increment, false);\n+\t\t  print_decs (increment, dump_file);\n \t\t  if (j < 0)\n \t\t    fprintf (dump_file,\n \t\t\t     \"\\n  Not replaced; incr_vec overflow.\\n\");\n@@ -3323,7 +3314,7 @@ replace_one_candidate (slsr_cand_t c, unsigned i, tree basis_name)\n   tree orig_rhs1, orig_rhs2;\n   tree rhs2;\n   enum tree_code orig_code, repl_code;\n-  double_int cand_incr;\n+  widest_int cand_incr;\n \n   orig_code = gimple_assign_rhs_code (c->cand_stmt);\n   orig_rhs1 = gimple_assign_rhs1 (c->cand_stmt);\n@@ -3371,7 +3362,7 @@ replace_one_candidate (slsr_cand_t c, unsigned i, tree basis_name)\n      from the basis name, or an add of the stride to the basis\n      name, respectively.  It may be necessary to introduce a\n      cast (or reuse an existing cast).  */\n-  else if (cand_incr.is_one ())\n+  else if (cand_incr == 1)\n     {\n       tree stride_type = TREE_TYPE (c->stride);\n       tree orig_type = TREE_TYPE (orig_rhs2);\n@@ -3386,7 +3377,7 @@ replace_one_candidate (slsr_cand_t c, unsigned i, tree basis_name)\n \t\t\t\t\t      c);\n     }\n \n-  else if (cand_incr.is_minus_one ())\n+  else if (cand_incr == -1)\n     {\n       tree stride_type = TREE_TYPE (c->stride);\n       tree orig_type = TREE_TYPE (orig_rhs2);\n@@ -3413,7 +3404,7 @@ replace_one_candidate (slsr_cand_t c, unsigned i, tree basis_name)\n \tfputs (\"  (duplicate, not actually replacing)\\n\", dump_file);\n     }\n \n-  else if (cand_incr.is_zero ())\n+  else if (cand_incr == 0)\n     {\n       tree lhs = gimple_assign_lhs (c->cand_stmt);\n       tree lhs_type = TREE_TYPE (lhs);\n@@ -3463,7 +3454,7 @@ replace_profitable_candidates (slsr_cand_t c)\n {\n   if (!cand_already_replaced (c))\n     {\n-      double_int increment = cand_abs_increment (c);\n+      widest_int increment = cand_abs_increment (c);\n       enum tree_code orig_code = gimple_assign_rhs_code (c->cand_stmt);\n       int i;\n "}, {"sha": "d6bc15bf4240c734cf0131950f750785f227b883", "filename": "gcc/gimple.c", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgimple.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2777,11 +2777,7 @@ preprocess_case_label_vec_for_gimple (vec<tree> labels,\n \t\t  low = CASE_HIGH (labels[i - 1]);\n \t\t  if (!low)\n \t\t    low = CASE_LOW (labels[i - 1]);\n-\t\t  if ((TREE_INT_CST_LOW (low) + 1\n-\t\t       != TREE_INT_CST_LOW (high))\n-\t\t      || (TREE_INT_CST_HIGH (low)\n-\t\t\t  + (TREE_INT_CST_LOW (high) == 0)\n-\t\t\t  != TREE_INT_CST_HIGH (high)))\n+\t\t  if (wi::add (low, 1) != high)\n \t\t    break;\n \t\t}\n \t      if (i == len)"}, {"sha": "f4c242f60aa8921e43149e4fc9cea3b9d74e823d", "filename": "gcc/go/go-gcc.cc", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgo%2Fgo-gcc.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgo%2Fgo-gcc.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgo%2Fgo-gcc.cc?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1067,8 +1067,7 @@ Gcc_backend::type_size(Btype* btype)\n   if (t == error_mark_node)\n     return 1;\n   t = TYPE_SIZE_UNIT(t);\n-  gcc_assert(TREE_CODE(t) == INTEGER_CST);\n-  gcc_assert(TREE_INT_CST_HIGH(t) == 0);\n+  gcc_assert(tree_fits_uhwi_p (t));\n   unsigned HOST_WIDE_INT val_wide = TREE_INT_CST_LOW(t);\n   size_t ret = static_cast<size_t>(val_wide);\n   gcc_assert(ret == val_wide);"}, {"sha": "2afd7f171a0d23b284830ddd5ace11188a904605", "filename": "gcc/godump.c", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgodump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgodump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgodump.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -36,6 +36,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"pointer-set.h\"\n #include \"obstack.h\"\n #include \"debug.h\"\n+#include \"wide-int-print.h\"\n \n /* We dump this information from the debug hooks.  This gives us a\n    stable and maintainable API to hook into.  In order to work\n@@ -961,7 +962,7 @@ go_output_typedef (struct godump_container *container, tree decl)\n \t  const char *name;\n \t  struct macro_hash_value *mhval;\n \t  void **slot;\n-\t  char buf[100];\n+\t  char buf[WIDE_INT_PRINT_BUFFER_SIZE];\n \n \t  name = IDENTIFIER_POINTER (TREE_PURPOSE (element));\n \n@@ -982,10 +983,7 @@ go_output_typedef (struct godump_container *container, tree decl)\n \t    snprintf (buf, sizeof buf, HOST_WIDE_INT_PRINT_UNSIGNED,\n \t\t      tree_to_uhwi (TREE_VALUE (element)));\n \t  else\n-\t    snprintf (buf, sizeof buf, HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t\t     ((unsigned HOST_WIDE_INT)\n-\t\t      TREE_INT_CST_HIGH (TREE_VALUE (element))),\n-\t\t     TREE_INT_CST_LOW (TREE_VALUE (element)));\n+\t    print_hex (element, buf);\n \n \t  mhval->value = xstrdup (buf);\n \t  *slot = mhval;"}, {"sha": "9ac9b67bb79c8cc71fce36b33f18d0133246db9a", "filename": "gcc/graphite-clast-to-gimple.c", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgraphite-clast-to-gimple.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgraphite-clast-to-gimple.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgraphite-clast-to-gimple.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -75,14 +75,13 @@ gmp_cst_to_tree (tree type, mpz_t val)\n {\n   tree t = type ? type : integer_type_node;\n   mpz_t tmp;\n-  double_int di;\n \n   mpz_init (tmp);\n   mpz_set (tmp, val);\n-  di = mpz_get_double_int (t, tmp, true);\n+  wide_int wi = wi::from_mpz (t, tmp, true);\n   mpz_clear (tmp);\n \n-  return double_int_to_tree (t, di);\n+  return wide_int_to_tree (t, wi);\n }\n \n /* Sets RES to the min of V1 and V2.  */"}, {"sha": "0bc443302c6c2e443d8c7865f7e39271c436a375", "filename": "gcc/graphite-sese-to-poly.c", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgraphite-sese-to-poly.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fgraphite-sese-to-poly.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgraphite-sese-to-poly.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -73,8 +73,7 @@ along with GCC; see the file COPYING3.  If not see\n static inline void\n tree_int_to_gmp (tree t, mpz_t res)\n {\n-  double_int di = tree_to_double_int (t);\n-  mpz_set_double_int (res, di, TYPE_UNSIGNED (TREE_TYPE (t)));\n+  wi::to_mpz (t, res, TYPE_SIGN (TREE_TYPE (t)));\n }\n \n /* Returns the index of the PHI argument defined in the outermost\n@@ -1025,7 +1024,7 @@ build_loop_iteration_domains (scop_p scop, struct loop *loop,\n   /* loop_i <= expr_nb_iters */\n   else if (!chrec_contains_undetermined (nb_iters))\n     {\n-      double_int nit;\n+      widest_int nit;\n       isl_pw_aff *aff;\n       isl_set *valid;\n       isl_local_space *ls;\n@@ -1061,7 +1060,7 @@ build_loop_iteration_domains (scop_p scop, struct loop *loop,\n \t  isl_constraint *c;\n \n \t  mpz_init (g);\n-\t  mpz_set_double_int (g, nit, false);\n+\t  wi::to_mpz (nit, g, SIGNED);\n \t  mpz_sub_ui (g, g, 1);\n \t  approx = extract_affine_gmp (g, isl_set_get_space (inner));\n \t  x = isl_pw_aff_ge_set (approx, aff);"}, {"sha": "5c065625733f6d41ea36e7a1c74c5a999eac64ce", "filename": "gcc/hooks.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fhooks.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fhooks.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhooks.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -332,7 +332,8 @@ hook_bool_rtx_int_int_int_intp_bool_false (rtx a ATTRIBUTE_UNUSED,\n }\n \n bool\n-hook_bool_dint_dint_uint_bool_true (double_int, double_int, unsigned int, bool)\n+hook_bool_wint_wint_uint_bool_true (const widest_int &, const widest_int &,\n+\t\t\t\t    unsigned int, bool)\n {\n   return true;\n }"}, {"sha": "ba42b6c18422736a4695a39a4867c98f44ec8ea0", "filename": "gcc/hooks.h", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fhooks.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fhooks.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhooks.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -23,7 +23,7 @@\n #define GCC_HOOKS_H\n \n #include \"machmode.h\"\n-#include \"double-int.h\"\n+#include \"wide-int.h\"\n \n extern bool hook_bool_void_false (void);\n extern bool hook_bool_void_true (void);\n@@ -61,7 +61,8 @@ extern bool hook_bool_rtx_int_int_int_intp_bool_false (rtx, int, int, int,\n extern bool hook_bool_tree_tree_false (tree, tree);\n extern bool hook_bool_tree_tree_true (tree, tree);\n extern bool hook_bool_tree_bool_false (tree, bool);\n-extern bool hook_bool_dint_dint_uint_bool_true (double_int, double_int,\n+extern bool hook_bool_wint_wint_uint_bool_true (const widest_int &,\n+\t\t\t\t\t\tconst widest_int &,\n \t\t\t\t\t\tunsigned int, bool);\n \n extern void hook_void_void (void);"}, {"sha": "68b2b66fbe793ce118944f5a99f26dc6ce2862af", "filename": "gcc/internal-fn.c", "status": "modified", "additions": 21, "deletions": 23, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Finternal-fn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Finternal-fn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -239,12 +239,12 @@ ubsan_expand_si_overflow_addsub_check (tree_code code, gimple stmt)\n \t;\n       else if (code == PLUS_EXPR && TREE_CODE (arg0) == SSA_NAME)\n \t{\n-\t  double_int arg0_min, arg0_max;\n+\t  wide_int arg0_min, arg0_max;\n \t  if (get_range_info (arg0, &arg0_min, &arg0_max) == VR_RANGE)\n \t    {\n-\t      if (!arg0_min.is_negative ())\n+\t      if (!wi::neg_p (arg0_min, TYPE_SIGN (TREE_TYPE (arg0))))\n \t\tpos_neg = 1;\n-\t      else if (arg0_max.is_negative ())\n+\t      else if (wi::neg_p (arg0_max, TYPE_SIGN (TREE_TYPE (arg0))))\n \t\tpos_neg = 2;\n \t    }\n \t  if (pos_neg != 3)\n@@ -256,12 +256,12 @@ ubsan_expand_si_overflow_addsub_check (tree_code code, gimple stmt)\n \t}\n       if (pos_neg == 3 && !CONST_INT_P (op1) && TREE_CODE (arg1) == SSA_NAME)\n \t{\n-\t  double_int arg1_min, arg1_max;\n+\t  wide_int arg1_min, arg1_max;\n \t  if (get_range_info (arg1, &arg1_min, &arg1_max) == VR_RANGE)\n \t    {\n-\t      if (!arg1_min.is_negative ())\n+\t      if (!wi::neg_p (arg1_min, TYPE_SIGN (TREE_TYPE (arg1))))\n \t\tpos_neg = 1;\n-\t      else if (arg1_max.is_negative ())\n+\t      else if (wi::neg_p (arg1_max, TYPE_SIGN (TREE_TYPE (arg1))))\n \t\tpos_neg = 2;\n \t    }\n \t}\n@@ -478,7 +478,7 @@ ubsan_expand_si_overflow_mul_check (gimple stmt)\n \t  rtx do_overflow = gen_label_rtx ();\n \t  rtx hipart_different = gen_label_rtx ();\n \n-\t  int hprec = GET_MODE_PRECISION (hmode);\n+\t  unsigned int hprec = GET_MODE_PRECISION (hmode);\n \t  rtx hipart0 = expand_shift (RSHIFT_EXPR, mode, op0, hprec,\n \t\t\t\t      NULL_RTX, 0);\n \t  hipart0 = gen_lowpart (hmode, hipart0);\n@@ -510,37 +510,35 @@ ubsan_expand_si_overflow_mul_check (gimple stmt)\n \n \t  if (TREE_CODE (arg0) == SSA_NAME)\n \t    {\n-\t      double_int arg0_min, arg0_max;\n+\t      wide_int arg0_min, arg0_max;\n \t      if (get_range_info (arg0, &arg0_min, &arg0_max) == VR_RANGE)\n \t\t{\n-\t\t  if (arg0_max.sle (double_int::max_value (hprec, false))\n-\t\t      && double_int::min_value (hprec, false).sle (arg0_min))\n+\t\t  unsigned int mprec0 = wi::min_precision (arg0_min, SIGNED);\n+\t\t  unsigned int mprec1 = wi::min_precision (arg0_max, SIGNED);\n+\t\t  if (mprec0 <= hprec && mprec1 <= hprec)\n \t\t    op0_small_p = true;\n-\t\t  else if (arg0_max.sle (double_int::max_value (hprec, true))\n-\t\t\t   && (~double_int::max_value (hprec,\n-\t\t\t\t\t\t       true)).sle (arg0_min))\n+\t\t  else if (mprec0 <= hprec + 1 && mprec1 <= hprec + 1)\n \t\t    op0_medium_p = true;\n-\t\t  if (!arg0_min.is_negative ())\n+\t\t  if (!wi::neg_p (arg0_min, TYPE_SIGN (TREE_TYPE (arg0))))\n \t\t    op0_sign = 0;\n-\t\t  else if (arg0_max.is_negative ())\n+\t\t  else if (wi::neg_p (arg0_max, TYPE_SIGN (TREE_TYPE (arg0))))\n \t\t    op0_sign = -1;\n \t\t}\n \t    }\n \t  if (TREE_CODE (arg1) == SSA_NAME)\n \t    {\n-\t      double_int arg1_min, arg1_max;\n+\t      wide_int arg1_min, arg1_max;\n \t      if (get_range_info (arg1, &arg1_min, &arg1_max) == VR_RANGE)\n \t\t{\n-\t\t  if (arg1_max.sle (double_int::max_value (hprec, false))\n-\t\t      && double_int::min_value (hprec, false).sle (arg1_min))\n+\t\t  unsigned int mprec0 = wi::min_precision (arg1_min, SIGNED);\n+\t\t  unsigned int mprec1 = wi::min_precision (arg1_max, SIGNED);\n+\t\t  if (mprec0 <= hprec && mprec1 <= hprec)\n \t\t    op1_small_p = true;\n-\t\t  else if (arg1_max.sle (double_int::max_value (hprec, true))\n-\t\t\t   && (~double_int::max_value (hprec,\n-\t\t\t\t\t\t       true)).sle (arg1_min))\n+\t\t  else if (mprec0 <= hprec + 1 && mprec1 <= hprec + 1)\n \t\t    op1_medium_p = true;\n-\t\t  if (!arg1_min.is_negative ())\n+\t\t  if (!wi::neg_p (arg1_min, TYPE_SIGN (TREE_TYPE (arg1))))\n \t\t    op1_sign = 0;\n-\t\t  else if (arg1_max.is_negative ())\n+\t\t  else if (wi::neg_p (arg1_max, TYPE_SIGN (TREE_TYPE (arg1))))\n \t\t    op1_sign = -1;\n \t\t}\n \t    }"}, {"sha": "d0296e7e4c7684646240bccbf9c5b457489c59de", "filename": "gcc/ipa-devirt.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fipa-devirt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fipa-devirt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-devirt.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1362,7 +1362,7 @@ get_polymorphic_call_info (tree fndecl,\n \t\t{\n \t\t  base_pointer = TREE_OPERAND (base, 0);\n \t\t  context->offset\n-\t\t     += offset2 + mem_ref_offset (base).low * BITS_PER_UNIT;\n+\t\t    += offset2 + mem_ref_offset (base).to_short_addr () * BITS_PER_UNIT;\n \t\t  context->outer_type = NULL;\n \t\t}\n \t      /* We found base object.  In this case the outer_type"}, {"sha": "da6ffe86169386c3f502f9084b1fc96779348535", "filename": "gcc/ipa-prop.c", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fipa-prop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fipa-prop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-prop.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1099,7 +1099,7 @@ compute_complex_assign_jump_func (struct ipa_node_params *info,\n       || max_size == -1\n       || max_size != size)\n     return;\n-  offset += mem_ref_offset (base).low * BITS_PER_UNIT;\n+  offset += mem_ref_offset (base).to_short_addr () * BITS_PER_UNIT;\n   ssa = TREE_OPERAND (base, 0);\n   if (TREE_CODE (ssa) != SSA_NAME\n       || !SSA_NAME_IS_DEFAULT_DEF (ssa)\n@@ -1159,7 +1159,7 @@ get_ancestor_addr_info (gimple assign, tree *obj_p, HOST_WIDE_INT *offset)\n       || TREE_CODE (SSA_NAME_VAR (parm)) != PARM_DECL)\n     return NULL_TREE;\n \n-  *offset += mem_ref_offset (expr).low * BITS_PER_UNIT;\n+  *offset += mem_ref_offset (expr).to_short_addr () * BITS_PER_UNIT;\n   *obj_p = obj;\n   return expr;\n }\n@@ -3787,8 +3787,7 @@ ipa_modify_call_arguments (struct cgraph_edge *cs, gimple stmt,\n \t\t  if (TYPE_ALIGN (type) > align)\n \t\t    align = TYPE_ALIGN (type);\n \t\t}\n-\t      misalign += (tree_to_double_int (off)\n-\t\t\t   .sext (TYPE_PRECISION (TREE_TYPE (off))).low\n+\t      misalign += (offset_int::from (off, SIGNED).to_short_addr ()\n \t\t\t   * BITS_PER_UNIT);\n \t      misalign = misalign & (align - 1);\n \t      if (misalign != 0)\n@@ -3994,7 +3993,7 @@ ipa_get_adjustment_candidate (tree **expr, bool *convert,\n \n   if (TREE_CODE (base) == MEM_REF)\n     {\n-      offset += mem_ref_offset (base).low * BITS_PER_UNIT;\n+      offset += mem_ref_offset (base).to_short_addr () * BITS_PER_UNIT;\n       base = TREE_OPERAND (base, 0);\n     }\n "}, {"sha": "191ab867ecaf20ae64f71c5c922e28fe22349e8b", "filename": "gcc/java/boehm.c", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fjava%2Fboehm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fjava%2Fboehm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjava%2Fboehm.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -32,8 +32,9 @@ The Free Software Foundation is independent of Sun Microsystems, Inc.  */\n #include \"java-tree.h\"\n #include \"parse.h\"\n #include \"diagnostic-core.h\"\n+#include \"wide-int.h\"\n \n-static void mark_reference_fields (tree, double_int *, unsigned int,\n+static void mark_reference_fields (tree, wide_int *, unsigned int,\n \t\t\t\t   int *, int *, int *, HOST_WIDE_INT *);\n \n /* A procedure-based object descriptor.  We know that our\n@@ -47,7 +48,7 @@ static void mark_reference_fields (tree, double_int *, unsigned int,\n /* Recursively mark reference fields.  */\n static void\n mark_reference_fields (tree field,\n-\t\t       double_int *mask,\n+\t\t       wide_int *mask,\n \t\t       unsigned int ubit,\n \t\t       int *pointer_after_end,\n \t\t       int *all_bits_set,\n@@ -107,7 +108,7 @@ mark_reference_fields (tree field,\n \t     bits for all words in the record. This is conservative, but the \n \t     size_words != 1 case is impossible in regular java code. */\n \t  for (i = 0; i < size_words; ++i)\n-\t    *mask = (*mask).set_bit (ubit - count - i - 1);\n+\t    *mask = wi::set_bit (*mask, ubit - count - i - 1);\n \n \t  if (count >= ubit - 2)\n \t    *pointer_after_end = 1;\n@@ -136,16 +137,15 @@ get_boehm_type_descriptor (tree type)\n   int last_set_index = 0;\n   HOST_WIDE_INT last_view_index = -1;\n   int pointer_after_end = 0;\n-  double_int mask;\n   tree field, value, value_type;\n \n-  mask = double_int_zero;\n-\n   /* If the GC wasn't requested, just use a null pointer.  */\n   if (! flag_use_boehm_gc)\n     return null_pointer_node;\n \n   value_type = java_type_for_mode (ptr_mode, 1);\n+  wide_int mask = wi::zero (TYPE_PRECISION (value_type));\n+\n   /* If we have a type of unknown size, use a proc.  */\n   if (int_size_in_bytes (type) == -1)\n     goto procedure_object_descriptor;\n@@ -194,22 +194,22 @@ get_boehm_type_descriptor (tree type)\n          that we don't have to emit reflection data for run time\n          marking. */\n       count = 0;\n-      mask = double_int_zero;\n+      mask = wi::zero (TYPE_PRECISION (value_type));\n       ++last_set_index;\n       while (last_set_index)\n \t{\n \t  if ((last_set_index & 1))\n-\t    mask = mask.set_bit (log2_size + count);\n+\t    mask = wi::set_bit (mask, log2_size + count);\n \t  last_set_index >>= 1;\n \t  ++count;\n \t}\n-      value = double_int_to_tree (value_type, mask);\n+      value = wide_int_to_tree (value_type, mask);\n     }\n   else if (! pointer_after_end)\n     {\n       /* Bottom two bits for bitmap mark type are 01.  */\n-      mask = mask.set_bit (0);\n-      value = double_int_to_tree (value_type, mask);\n+      mask = wi::set_bit (mask, 0);\n+      value = wide_int_to_tree (value_type, mask);\n     }\n   else\n     {"}, {"sha": "e66bdb152aba3d043493d81c9d2324a80270705b", "filename": "gcc/java/expr.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fjava%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fjava%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjava%2Fexpr.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -46,6 +46,7 @@ The Free Software Foundation is independent of Sun Microsystems, Inc.  */\n #include \"ggc.h\"\n #include \"tree-iterator.h\"\n #include \"target.h\"\n+#include \"wide-int.h\"\n \n static void flush_quick_stack (void);\n static void push_value (tree);\n@@ -1051,7 +1052,7 @@ build_newarray (int atype_value, tree length)\n   tree prim_type = decode_newarray_type (atype_value);\n   tree type\n     = build_java_array_type (prim_type,\n-\t\t\t     tree_fits_shwi_p (length) == INTEGER_CST\n+\t\t\t     tree_fits_shwi_p (length)\n \t\t\t     ? tree_to_shwi (length) : -1);\n \n   /* Pass a reference to the primitive type class and save the runtime\n@@ -1260,7 +1261,7 @@ expand_java_pushc (int ival, tree type)\n   else if (type == float_type_node || type == double_type_node)\n     {\n       REAL_VALUE_TYPE x;\n-      REAL_VALUE_FROM_INT (x, ival, 0, TYPE_MODE (type));\n+      real_from_integer (&x, TYPE_MODE (type), ival, SIGNED);\n       value = build_real (type, x);\n     }\n   else\n@@ -1717,7 +1718,7 @@ build_field_ref (tree self_value, tree self_class, tree name)\n \t  tree field_offset = byte_position (field_decl);\n \t  if (! page_size)\n \t    page_size = size_int (4096); \t      \n-\t  check = ! INT_CST_LT_UNSIGNED (field_offset, page_size);\n+\t  check = !tree_int_cst_lt (field_offset, page_size);\n \t}\n \n       if (base_type != TREE_TYPE (self_value))"}, {"sha": "748f7c3e06189e35da272b5bcfd27ee226a83a25", "filename": "gcc/java/jcf-parse.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fjava%2Fjcf-parse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fjava%2Fjcf-parse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjava%2Fjcf-parse.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -41,6 +41,7 @@ The Free Software Foundation is independent of Sun Microsystems, Inc.  */\n #include \"cgraph.h\"\n #include \"bitmap.h\"\n #include \"target.h\"\n+#include \"wide-int.h\"\n \n #ifdef HAVE_LOCALE_H\n #include <locale.h>\n@@ -1041,14 +1042,13 @@ get_constant (JCF *jcf, int index)\n     case CONSTANT_Long:\n       {\n \tunsigned HOST_WIDE_INT num;\n-\tdouble_int val;\n \n \tnum = JPOOL_UINT (jcf, index);\n-\tval = double_int::from_uhwi (num).llshift (32, 64);\n+\twide_int val = wi::lshift (wide_int::from (num, 64, SIGNED), 32);\n \tnum = JPOOL_UINT (jcf, index + 1);\n-\tval |= double_int::from_uhwi (num);\n+\tval |= num;\n \n-\tvalue = double_int_to_tree (long_type_node, val);\n+\tvalue = wide_int_to_tree (long_type_node, val);\n \tbreak;\n       }\n "}, {"sha": "d03d13c648e2eeffa24c03034c21ab5e57742a92", "filename": "gcc/loop-doloop.c", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Floop-doloop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Floop-doloop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-doloop.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -409,7 +409,7 @@ doloop_modify (struct loop *loop, struct niter_desc *desc,\n   basic_block loop_end = desc->out_edge->src;\n   enum machine_mode mode;\n   rtx true_prob_val;\n-  double_int iterations;\n+  widest_int iterations;\n \n   jump_insn = BB_END (loop_end);\n \n@@ -461,9 +461,9 @@ doloop_modify (struct loop *loop, struct niter_desc *desc,\n       /* Determine if the iteration counter will be non-negative.\n \t Note that the maximum value loaded is iterations_max - 1.  */\n       if (get_max_loop_iterations (loop, &iterations)\n-\t  && (iterations.ule (double_int_one.llshift\n-\t\t\t       (GET_MODE_PRECISION (mode) - 1,\n-\t\t\t\tGET_MODE_PRECISION (mode)))))\n+\t  && wi::leu_p (iterations,\n+\t\t\twi::set_bit_in_zero <widest_int>\n+\t\t\t(GET_MODE_PRECISION (mode) - 1)))\n \tnonneg = 1;\n       break;\n \n@@ -597,7 +597,7 @@ doloop_optimize (struct loop *loop)\n   enum machine_mode mode;\n   rtx doloop_seq, doloop_pat, doloop_reg;\n   rtx count;\n-  double_int iterations, iterations_max;\n+  widest_int iterations, iterations_max;\n   rtx start_label;\n   rtx condition;\n   unsigned level, est_niter;\n@@ -655,11 +655,12 @@ doloop_optimize (struct loop *loop)\n     }\n \n   if (desc->const_iter)\n-    iterations = rtx_to_double_int (desc->niter_expr);\n+    iterations = widest_int::from (std::make_pair (desc->niter_expr, mode),\n+\t\t\t\t   UNSIGNED);\n   else\n-    iterations = double_int_zero;\n+    iterations = 0;\n   if (!get_max_loop_iterations (loop, &iterations_max))\n-    iterations_max = double_int_zero;\n+    iterations_max = 0;\n   level = get_loop_level (loop) + 1;\n   entered_at_top = (loop->latch == desc->in_edge->dest\n \t\t    && contains_no_active_insn_p (loop->latch));\n@@ -688,7 +689,7 @@ doloop_optimize (struct loop *loop)\n \t computed, we must be sure that the number of iterations fits into\n \t the new mode.  */\n       && (word_mode_size >= GET_MODE_PRECISION (mode)\n-\t  || iterations_max.ule (double_int::from_shwi (word_mode_max))))\n+ \t  || wi::leu_p (iterations_max, word_mode_max)))\n     {\n       if (word_mode_size > GET_MODE_PRECISION (mode))\n \tcount = simplify_gen_unary (ZERO_EXTEND, word_mode, count, mode);"}, {"sha": "796bd59f2d67154e2ac08355cb0382ebf1d568b2", "filename": "gcc/loop-iv.c", "status": "modified", "additions": 6, "deletions": 10, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Floop-iv.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Floop-iv.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-iv.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2625,8 +2625,7 @@ iv_number_of_iterations (struct loop *loop, rtx insn, rtx condition,\n \t  max = (up - down) / inc + 1;\n \t  if (!desc->infinite\n \t      && !desc->assumptions)\n-\t    record_niter_bound (loop, double_int::from_uhwi (max),\n-\t\t\t        false, true);\n+\t    record_niter_bound (loop, max, false, true);\n \n \t  if (iv0.step == const0_rtx)\n \t    {\n@@ -2665,8 +2664,8 @@ iv_number_of_iterations (struct loop *loop, rtx insn, rtx condition,\n       iv1.step = const0_rtx;\n       if (INTVAL (iv0.step) < 0)\n \t{\n-\t  iv0.step = simplify_gen_unary (NEG, comp_mode, iv0.step, mode);\n-\t  iv1.base = simplify_gen_unary (NEG, comp_mode, iv1.base, mode);\n+\t  iv0.step = simplify_gen_unary (NEG, comp_mode, iv0.step, comp_mode);\n+\t  iv1.base = simplify_gen_unary (NEG, comp_mode, iv1.base, comp_mode);\n \t}\n       iv0.step = lowpart_subreg (mode, iv0.step, comp_mode);\n \n@@ -2840,8 +2839,7 @@ iv_number_of_iterations (struct loop *loop, rtx insn, rtx condition,\n       desc->niter = val & GET_MODE_MASK (desc->mode);\n       if (!desc->infinite\n \t  && !desc->assumptions)\n-        record_niter_bound (loop, double_int::from_uhwi (desc->niter),\n-\t\t\t    false, true);\n+        record_niter_bound (loop, desc->niter, false, true);\n     }\n   else\n     {\n@@ -2850,8 +2848,7 @@ iv_number_of_iterations (struct loop *loop, rtx insn, rtx condition,\n \tgoto zero_iter_simplify;\n       if (!desc->infinite\n \t  && !desc->assumptions)\n-\trecord_niter_bound (loop, double_int::from_uhwi (max),\n-\t\t\t    false, true);\n+\trecord_niter_bound (loop, max, false, true);\n \n       /* simplify_using_initial_values does a copy propagation on the registers\n \t in the expression for the number of iterations.  This prolongs life\n@@ -2876,8 +2873,7 @@ iv_number_of_iterations (struct loop *loop, rtx insn, rtx condition,\n zero_iter:\n   desc->const_iter = true;\n   desc->niter = 0;\n-  record_niter_bound (loop, double_int_zero,\n-\t\t      true, true);\n+  record_niter_bound (loop, 0, true, true);\n   desc->noloop_assumptions = NULL_RTX;\n   desc->niter_expr = const0_rtx;\n   return;"}, {"sha": "5797d200d95f61102e743c1fab62e6efdf5cdbbd", "filename": "gcc/loop-unroll.c", "status": "modified", "additions": 20, "deletions": 30, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Floop-unroll.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Floop-unroll.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-unroll.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -641,7 +641,7 @@ decide_unroll_constant_iterations (struct loop *loop, int flags)\n {\n   unsigned nunroll, nunroll_by_av, best_copies, best_unroll = 0, n_copies, i;\n   struct niter_desc *desc;\n-  double_int iterations;\n+  widest_int iterations;\n \n   if (!(flags & UAP_UNROLL))\n     {\n@@ -694,7 +694,7 @@ decide_unroll_constant_iterations (struct loop *loop, int flags)\n   if (desc->niter < 2 * nunroll\n       || ((get_estimated_loop_iterations (loop, &iterations)\n \t   || get_max_loop_iterations (loop, &iterations))\n-\t  && iterations.ult (double_int::from_shwi (2 * nunroll))))\n+\t  && wi::ltu_p (iterations, 2 * nunroll)))\n     {\n       if (dump_file)\n \tfprintf (dump_file, \";; Not unrolling loop, doesn't roll\\n\");\n@@ -814,11 +814,10 @@ unroll_loop_constant_iterations (struct loop *loop)\n \n \t  desc->noloop_assumptions = NULL_RTX;\n \t  desc->niter -= exit_mod;\n-\t  loop->nb_iterations_upper_bound -= double_int::from_uhwi (exit_mod);\n+\t  loop->nb_iterations_upper_bound -= exit_mod;\n \t  if (loop->any_estimate\n-\t      && double_int::from_uhwi (exit_mod).ule\n-\t           (loop->nb_iterations_estimate))\n-\t    loop->nb_iterations_estimate -= double_int::from_uhwi (exit_mod);\n+\t      && wi::leu_p (exit_mod, loop->nb_iterations_estimate))\n+\t    loop->nb_iterations_estimate -= exit_mod;\n \t  else\n \t    loop->any_estimate = false;\n \t}\n@@ -858,11 +857,10 @@ unroll_loop_constant_iterations (struct loop *loop)\n   \t    apply_opt_in_copies (opt_info, exit_mod + 1, false, false);\n \n \t  desc->niter -= exit_mod + 1;\n-\t  loop->nb_iterations_upper_bound -= double_int::from_uhwi (exit_mod + 1);\n+\t  loop->nb_iterations_upper_bound -= exit_mod + 1;\n \t  if (loop->any_estimate\n-\t      && double_int::from_uhwi (exit_mod + 1).ule\n-\t           (loop->nb_iterations_estimate))\n-\t    loop->nb_iterations_estimate -= double_int::from_uhwi (exit_mod + 1);\n+\t      && wi::leu_p (exit_mod + 1, loop->nb_iterations_estimate))\n+\t    loop->nb_iterations_estimate -= exit_mod + 1;\n \t  else\n \t    loop->any_estimate = false;\n \t  desc->noloop_assumptions = NULL_RTX;\n@@ -914,14 +912,10 @@ unroll_loop_constant_iterations (struct loop *loop)\n \n   desc->niter /= max_unroll + 1;\n   loop->nb_iterations_upper_bound\n-    = loop->nb_iterations_upper_bound.udiv (double_int::from_uhwi (max_unroll\n-\t\t\t\t\t\t\t\t   + 1),\n-\t\t\t\t\t    TRUNC_DIV_EXPR);\n+    = wi::udiv_trunc (loop->nb_iterations_upper_bound, max_unroll + 1);\n   if (loop->any_estimate)\n     loop->nb_iterations_estimate\n-      = loop->nb_iterations_estimate.udiv (double_int::from_uhwi (max_unroll\n-\t\t\t\t\t\t\t          + 1),\n-\t\t\t\t           TRUNC_DIV_EXPR);\n+      = wi::udiv_trunc (loop->nb_iterations_estimate, max_unroll + 1);\n   desc->niter_expr = GEN_INT (desc->niter);\n \n   /* Remove the edges.  */\n@@ -941,7 +935,7 @@ decide_unroll_runtime_iterations (struct loop *loop, int flags)\n {\n   unsigned nunroll, nunroll_by_av, i;\n   struct niter_desc *desc;\n-  double_int iterations;\n+  widest_int iterations;\n \n   if (!(flags & UAP_UNROLL))\n     {\n@@ -997,7 +991,7 @@ decide_unroll_runtime_iterations (struct loop *loop, int flags)\n   /* Check whether the loop rolls.  */\n   if ((get_estimated_loop_iterations (loop, &iterations)\n        || get_max_loop_iterations (loop, &iterations))\n-      && iterations.ult (double_int::from_shwi (2 * nunroll)))\n+      && wi::ltu_p (iterations, 2 * nunroll))\n     {\n       if (dump_file)\n \tfprintf (dump_file, \";; Not unrolling loop, doesn't roll\\n\");\n@@ -1357,22 +1351,18 @@ unroll_loop_runtime_iterations (struct loop *loop)\n     simplify_gen_binary (UDIV, desc->mode, old_niter,\n \t\t\t gen_int_mode (max_unroll + 1, desc->mode));\n   loop->nb_iterations_upper_bound\n-    = loop->nb_iterations_upper_bound.udiv (double_int::from_uhwi (max_unroll\n-\t\t\t\t\t\t\t\t   + 1),\n-\t\t\t\t\t    TRUNC_DIV_EXPR);\n+    = wi::udiv_trunc (loop->nb_iterations_upper_bound, max_unroll + 1);\n   if (loop->any_estimate)\n     loop->nb_iterations_estimate\n-      = loop->nb_iterations_estimate.udiv (double_int::from_uhwi (max_unroll\n-\t\t\t\t\t\t\t          + 1),\n-\t\t\t\t           TRUNC_DIV_EXPR);\n+      = wi::udiv_trunc (loop->nb_iterations_estimate, max_unroll + 1);\n   if (exit_at_end)\n     {\n       desc->niter_expr =\n \tsimplify_gen_binary (MINUS, desc->mode, desc->niter_expr, const1_rtx);\n       desc->noloop_assumptions = NULL_RTX;\n       --loop->nb_iterations_upper_bound;\n       if (loop->any_estimate\n-\t  && loop->nb_iterations_estimate != double_int_zero)\n+\t  && loop->nb_iterations_estimate != 0)\n \t--loop->nb_iterations_estimate;\n       else\n \tloop->any_estimate = false;\n@@ -1390,7 +1380,7 @@ static void\n decide_peel_simple (struct loop *loop, int flags)\n {\n   unsigned npeel;\n-  double_int iterations;\n+  widest_int iterations;\n \n   if (!(flags & UAP_PEEL))\n     {\n@@ -1434,7 +1424,7 @@ decide_peel_simple (struct loop *loop, int flags)\n   /* If we have realistic estimate on number of iterations, use it.  */\n   if (get_estimated_loop_iterations (loop, &iterations))\n     {\n-      if (double_int::from_shwi (npeel).ule (iterations))\n+      if (wi::leu_p (npeel, iterations))\n \t{\n \t  if (dump_file)\n \t    {\n@@ -1451,7 +1441,7 @@ decide_peel_simple (struct loop *loop, int flags)\n   /* If we have small enough bound on iterations, we can still peel (completely\n      unroll).  */\n   else if (get_max_loop_iterations (loop, &iterations)\n-           && iterations.ult (double_int::from_shwi (npeel)))\n+           && wi::ltu_p (iterations, npeel))\n     npeel = iterations.to_shwi () + 1;\n   else\n     {\n@@ -1545,7 +1535,7 @@ decide_unroll_stupid (struct loop *loop, int flags)\n {\n   unsigned nunroll, nunroll_by_av, i;\n   struct niter_desc *desc;\n-  double_int iterations;\n+  widest_int iterations;\n \n   if (!(flags & UAP_UNROLL_ALL))\n     {\n@@ -1602,7 +1592,7 @@ decide_unroll_stupid (struct loop *loop, int flags)\n   /* Check whether the loop rolls.  */\n   if ((get_estimated_loop_iterations (loop, &iterations)\n        || get_max_loop_iterations (loop, &iterations))\n-      && iterations.ult (double_int::from_shwi (2 * nunroll)))\n+      && wi::ltu_p (iterations, 2 * nunroll))\n     {\n       if (dump_file)\n \tfprintf (dump_file, \";; Not unrolling loop, doesn't roll\\n\");"}, {"sha": "d0c86626c66a9afe2cba351b731efecb50a29f3d", "filename": "gcc/lto-streamer-in.c", "status": "modified", "additions": 28, "deletions": 13, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto-streamer-in.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto-streamer-in.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto-streamer-in.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -596,6 +596,21 @@ make_new_block (struct function *fn, unsigned int index)\n }\n \n \n+/* Read a wide-int.  */\n+\n+static widest_int\n+streamer_read_wi (struct lto_input_block *ib)\n+{\n+  HOST_WIDE_INT a[WIDE_INT_MAX_ELTS];\n+  int i;\n+  int prec ATTRIBUTE_UNUSED = streamer_read_uhwi (ib);\n+  int len = streamer_read_uhwi (ib);\n+  for (i = 0; i < len; i++)\n+    a[i] = streamer_read_hwi (ib);\n+  return widest_int::from_array (a, len);\n+}\n+\n+\n /* Read the CFG for function FN from input block IB.  */\n \n static void\n@@ -705,16 +720,10 @@ input_cfg (struct lto_input_block *ib, struct data_in *data_in,\n       loop->estimate_state = streamer_read_enum (ib, loop_estimation, EST_LAST);\n       loop->any_upper_bound = streamer_read_hwi (ib);\n       if (loop->any_upper_bound)\n-\t{\n-\t  loop->nb_iterations_upper_bound.low = streamer_read_uhwi (ib);\n-\t  loop->nb_iterations_upper_bound.high = streamer_read_hwi (ib);\n-\t}\n+\tloop->nb_iterations_upper_bound = streamer_read_wi (ib);\n       loop->any_estimate = streamer_read_hwi (ib);\n       if (loop->any_estimate)\n-\t{\n-\t  loop->nb_iterations_estimate.low = streamer_read_uhwi (ib);\n-\t  loop->nb_iterations_estimate.high = streamer_read_hwi (ib);\n-\t}\n+\tloop->nb_iterations_estimate = streamer_read_wi (ib);\n \n       /* Read OMP SIMD related info.  */\n       loop->safelen = streamer_read_hwi (ib);\n@@ -1267,12 +1276,18 @@ lto_input_tree_1 (struct lto_input_block *ib, struct data_in *data_in,\n     }\n   else if (tag == LTO_integer_cst)\n     {\n-      /* For shared integer constants in singletons we can use the existing\n-         tree integer constant merging code.  */\n+      /* For shared integer constants in singletons we can use the\n+         existing tree integer constant merging code.  */\n       tree type = stream_read_tree (ib, data_in);\n-      unsigned HOST_WIDE_INT low = streamer_read_uhwi (ib);\n-      HOST_WIDE_INT high = streamer_read_hwi (ib);\n-      result = build_int_cst_wide (type, low, high);\n+      unsigned HOST_WIDE_INT len = streamer_read_uhwi (ib);\n+      unsigned HOST_WIDE_INT i;\n+      HOST_WIDE_INT a[WIDE_INT_MAX_ELTS];\n+\n+      for (i = 0; i < len; i++)\n+\ta[i] = streamer_read_hwi (ib);\n+      gcc_assert (TYPE_PRECISION (type) <= MAX_BITSIZE_MODE_ANY_INT);\n+      result = wide_int_to_tree (type, wide_int::from_array\n+\t\t\t\t (a, len, TYPE_PRECISION (type)));\n       streamer_tree_cache_append (data_in->reader_cache, result, hash);\n     }\n   else if (tag == LTO_tree_scc)"}, {"sha": "6f2bf9c307dd3f81d6bcc835e514cc308cd783fb", "filename": "gcc/lto-streamer-out.c", "status": "modified", "additions": 22, "deletions": 10, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto-streamer-out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto-streamer-out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto-streamer-out.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -733,8 +733,11 @@ hash_tree (struct streamer_tree_cache_d *cache, tree t)\n \n   if (CODE_CONTAINS_STRUCT (code, TS_INT_CST))\n     {\n-      v = iterative_hash_host_wide_int (TREE_INT_CST_LOW (t), v);\n-      v = iterative_hash_host_wide_int (TREE_INT_CST_HIGH (t), v);\n+      int i;\n+      v = iterative_hash_host_wide_int (TREE_INT_CST_NUNITS (t), v);\n+      v = iterative_hash_host_wide_int (TREE_INT_CST_EXT_NUNITS (t), v);\n+      for (i = 0; i < TREE_INT_CST_NUNITS (t); i++)\n+\tv = iterative_hash_host_wide_int (TREE_INT_CST_ELT (t, i), v);\n     }\n \n   if (CODE_CONTAINS_STRUCT (code, TS_REAL_CST))\n@@ -1608,6 +1611,21 @@ output_ssa_names (struct output_block *ob, struct function *fn)\n }\n \n \n+/* Output a wide-int.  */\n+\n+static void\n+streamer_write_wi (struct output_block *ob,\n+\t\t   const widest_int &w)\n+{\n+  int len = w.get_len ();\n+\n+  streamer_write_uhwi (ob, w.get_precision ());\n+  streamer_write_uhwi (ob, len);\n+  for (int i = 0; i < len; i++)\n+    streamer_write_hwi (ob, w.elt (i));\n+}\n+\n+\n /* Output the cfg.  */\n \n static void\n@@ -1680,16 +1698,10 @@ output_cfg (struct output_block *ob, struct function *fn)\n \t\t\t   loop_estimation, EST_LAST, loop->estimate_state);\n       streamer_write_hwi (ob, loop->any_upper_bound);\n       if (loop->any_upper_bound)\n-\t{\n-\t  streamer_write_uhwi (ob, loop->nb_iterations_upper_bound.low);\n-\t  streamer_write_hwi (ob, loop->nb_iterations_upper_bound.high);\n-\t}\n+\tstreamer_write_wi (ob, loop->nb_iterations_upper_bound);\n       streamer_write_hwi (ob, loop->any_estimate);\n       if (loop->any_estimate)\n-\t{\n-\t  streamer_write_uhwi (ob, loop->nb_iterations_estimate.low);\n-\t  streamer_write_hwi (ob, loop->nb_iterations_estimate.high);\n-\t}\n+\tstreamer_write_wi (ob, loop->nb_iterations_estimate);\n \n       /* Write OMP SIMD related info.  */\n       streamer_write_hwi (ob, loop->safelen);"}, {"sha": "e213e9233181d0256cb25e1b59e72ff96e3aaae6", "filename": "gcc/lto/lto-lang.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto%2Flto-lang.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto%2Flto-lang.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto%2Flto-lang.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -324,8 +324,7 @@ static bool\n get_nonnull_operand (tree arg_num_expr, unsigned HOST_WIDE_INT *valp)\n {\n   /* Verify the arg number is a constant.  */\n-  if (TREE_CODE (arg_num_expr) != INTEGER_CST\n-      || TREE_INT_CST_HIGH (arg_num_expr) != 0)\n+  if (!tree_fits_uhwi_p (arg_num_expr))\n     return false;\n \n   *valp = TREE_INT_CST_LOW (arg_num_expr);"}, {"sha": "1d9ac2c9ecd1affd3853fc8315f953e6667a5310", "filename": "gcc/lto/lto.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto%2Flto.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Flto%2Flto.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flto%2Flto.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1212,8 +1212,8 @@ compare_tree_sccs_1 (tree t1, tree t2, tree **map)\n \n   if (CODE_CONTAINS_STRUCT (code, TS_INT_CST))\n     {\n-      compare_values (TREE_INT_CST_LOW);\n-      compare_values (TREE_INT_CST_HIGH);\n+      if (!wi::eq_p (t1, t2))\n+\treturn false;\n     }\n \n   if (CODE_CONTAINS_STRUCT (code, TS_REAL_CST))"}, {"sha": "c36759f72a18fa0de32c15aa1e5b53b4d51030fd", "filename": "gcc/mkconfig.sh", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fmkconfig.sh", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fmkconfig.sh", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmkconfig.sh?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -100,6 +100,9 @@ case $output in\n #if defined IN_GCC && !defined GENERATOR_FILE\n # include \"insn-modes.h\"\n #endif\n+#if defined IN_GCC && defined GENERATOR_FILE && !defined BITS_PER_UNIT\n+#include \"machmode.h\"\n+#endif\n EOF\n     ;;\n esac"}, {"sha": "ff5d1e5d7aade1cf0abc96e1f4d28c186ab4c832", "filename": "gcc/objc/objc-act.c", "status": "modified", "additions": 14, "deletions": 22, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fobjc%2Fobjc-act.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fobjc%2Fobjc-act.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fobjc%2Fobjc-act.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -52,6 +52,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"cgraph.h\"\n #include \"tree-iterator.h\"\n #include \"hash-table.h\"\n+#include \"wide-int.h\"\n #include \"langhooks-def.h\"\n /* Different initialization, code gen and meta data generation for each\n    runtime.  */\n@@ -4899,12 +4900,10 @@ objc_decl_method_attributes (tree *node, tree attributes, int flags)\n \t\t  number = TREE_VALUE (second_argument);\n \t\t  if (number\n \t\t      && TREE_CODE (number) == INTEGER_CST\n-\t\t      && TREE_INT_CST_HIGH (number) == 0)\n-\t\t    {\n-\t\t      TREE_VALUE (second_argument)\n-\t\t\t= build_int_cst (integer_type_node,\n-\t\t\t\t\t TREE_INT_CST_LOW (number) + 2);\n-\t\t    }\n+\t\t      && !wi::eq_p (number, 0))\n+\t\t    TREE_VALUE (second_argument)\n+\t\t      = wide_int_to_tree (TREE_TYPE (number),\n+\t\t\t\t\t  wi::add (number, 2));\n \n \t\t  /* This is the third argument, the \"first-to-check\",\n \t\t     which specifies the index of the first argument to\n@@ -4914,13 +4913,10 @@ objc_decl_method_attributes (tree *node, tree attributes, int flags)\n \t\t  number = TREE_VALUE (third_argument);\n \t\t  if (number\n \t\t      && TREE_CODE (number) == INTEGER_CST\n-\t\t      && TREE_INT_CST_HIGH (number) == 0\n-\t\t      && TREE_INT_CST_LOW (number) != 0)\n-\t\t    {\n-\t\t      TREE_VALUE (third_argument)\n-\t\t\t= build_int_cst (integer_type_node,\n-\t\t\t\t\t TREE_INT_CST_LOW (number) + 2);\n-\t\t    }\n+\t\t      && !wi::eq_p (number, 0))\n+\t\t    TREE_VALUE (third_argument)\n+\t\t      = wide_int_to_tree (TREE_TYPE (number),\n+\t\t\t\t\t  wi::add (number, 2));\n \t\t}\n \t      filtered_attributes = chainon (filtered_attributes,\n \t\t\t\t\t     new_attribute);\n@@ -4952,15 +4948,11 @@ objc_decl_method_attributes (tree *node, tree attributes, int flags)\n \t\t{\n \t\t  /* Get the value of the argument and add 2.  */\n \t\t  tree number = TREE_VALUE (argument);\n-\t\t  if (number\n-\t\t      && TREE_CODE (number) == INTEGER_CST\n-\t\t      && TREE_INT_CST_HIGH (number) == 0\n-\t\t      && TREE_INT_CST_LOW (number) != 0)\n-\t\t    {\n-\t\t      TREE_VALUE (argument)\n-\t\t\t= build_int_cst (integer_type_node,\n-\t\t\t\t\t TREE_INT_CST_LOW (number) + 2);\n-\t\t    }\n+\t\t  if (number && TREE_CODE (number) == INTEGER_CST\n+\t\t      && !wi::eq_p (number, 0))\n+\t\t    TREE_VALUE (argument)\n+\t\t      = wide_int_to_tree (TREE_TYPE (number),\n+\t\t\t\t\t  wi::add (number, 2));\n \t\t  argument = TREE_CHAIN (argument);\n \t\t}\n "}, {"sha": "453f580a838109ede54bc0c8bc208b8f16e9d3be", "filename": "gcc/omp-low.c", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fomp-low.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fomp-low.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-low.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2541,9 +2541,7 @@ scan_omp_1_op (tree *tp, int *walk_subtrees, void *data)\n \t      if (tem != TREE_TYPE (t))\n \t\t{\n \t\t  if (TREE_CODE (t) == INTEGER_CST)\n-\t\t    *tp = build_int_cst_wide (tem,\n-\t\t\t\t\t      TREE_INT_CST_LOW (t),\n-\t\t\t\t\t      TREE_INT_CST_HIGH (t));\n+\t\t    *tp = wide_int_to_tree (tem, t);\n \t\t  else\n \t\t    TREE_TYPE (t) = tem;\n \t\t}"}, {"sha": "abc36ed41f854201e63ab1a1056cc2e24a132c2f", "filename": "gcc/optabs.c", "status": "modified", "additions": 17, "deletions": 20, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -854,7 +854,8 @@ expand_subword_shift (enum machine_mode op1_mode, optab binoptab,\n   if (CONSTANT_P (op1) || shift_mask >= BITS_PER_WORD)\n     {\n       carries = outof_input;\n-      tmp = immed_double_const (BITS_PER_WORD, 0, op1_mode);\n+      tmp = immed_wide_int_const (wi::shwi (BITS_PER_WORD,\n+\t\t\t\t\t    op1_mode), op1_mode);\n       tmp = simplify_expand_binop (op1_mode, sub_optab, tmp, op1,\n \t\t\t\t   0, true, methods);\n     }\n@@ -869,13 +870,15 @@ expand_subword_shift (enum machine_mode op1_mode, optab binoptab,\n \t\t\t      outof_input, const1_rtx, 0, unsignedp, methods);\n       if (shift_mask == BITS_PER_WORD - 1)\n \t{\n-\t  tmp = immed_double_const (-1, -1, op1_mode);\n+\t  tmp = immed_wide_int_const\n+\t    (wi::minus_one (GET_MODE_PRECISION (op1_mode)), op1_mode);\n \t  tmp = simplify_expand_binop (op1_mode, xor_optab, op1, tmp,\n \t\t\t\t       0, true, methods);\n \t}\n       else\n \t{\n-\t  tmp = immed_double_const (BITS_PER_WORD - 1, 0, op1_mode);\n+\t  tmp = immed_wide_int_const (wi::shwi (BITS_PER_WORD - 1,\n+\t\t\t\t\t\top1_mode), op1_mode);\n \t  tmp = simplify_expand_binop (op1_mode, sub_optab, tmp, op1,\n \t\t\t\t       0, true, methods);\n \t}\n@@ -1038,7 +1041,7 @@ expand_doubleword_shift (enum machine_mode op1_mode, optab binoptab,\n      is true when the effective shift value is less than BITS_PER_WORD.\n      Set SUPERWORD_OP1 to the shift count that should be used to shift\n      OUTOF_INPUT into INTO_TARGET when the condition is false.  */\n-  tmp = immed_double_const (BITS_PER_WORD, 0, op1_mode);\n+  tmp = immed_wide_int_const (wi::shwi (BITS_PER_WORD, op1_mode), op1_mode);\n   if (!CONSTANT_P (op1) && shift_mask == BITS_PER_WORD - 1)\n     {\n       /* Set CMP1 to OP1 & BITS_PER_WORD.  The result is zero iff OP1\n@@ -2891,7 +2894,6 @@ expand_absneg_bit (enum rtx_code code, enum machine_mode mode,\n   const struct real_format *fmt;\n   int bitpos, word, nwords, i;\n   enum machine_mode imode;\n-  double_int mask;\n   rtx temp, insns;\n \n   /* The format has to have a simple sign bit.  */\n@@ -2927,7 +2929,7 @@ expand_absneg_bit (enum rtx_code code, enum machine_mode mode,\n       nwords = (GET_MODE_BITSIZE (mode) + BITS_PER_WORD - 1) / BITS_PER_WORD;\n     }\n \n-  mask = double_int_zero.set_bit (bitpos);\n+  wide_int mask = wi::set_bit_in_zero (bitpos, GET_MODE_PRECISION (imode));\n   if (code == ABS)\n     mask = ~mask;\n \n@@ -2949,7 +2951,7 @@ expand_absneg_bit (enum rtx_code code, enum machine_mode mode,\n \t    {\n \t      temp = expand_binop (imode, code == ABS ? and_optab : xor_optab,\n \t\t\t\t   op0_piece,\n-\t\t\t\t   immed_double_int_const (mask, imode),\n+\t\t\t\t   immed_wide_int_const (mask, imode),\n \t\t\t\t   targ_piece, 1, OPTAB_LIB_WIDEN);\n \t      if (temp != targ_piece)\n \t\temit_move_insn (targ_piece, temp);\n@@ -2967,7 +2969,7 @@ expand_absneg_bit (enum rtx_code code, enum machine_mode mode,\n     {\n       temp = expand_binop (imode, code == ABS ? and_optab : xor_optab,\n \t\t\t   gen_lowpart (imode, op0),\n-\t\t\t   immed_double_int_const (mask, imode),\n+\t\t\t   immed_wide_int_const (mask, imode),\n \t\t           gen_lowpart (imode, target), 1, OPTAB_LIB_WIDEN);\n       target = lowpart_subreg_maybe_copy (mode, temp, imode);\n \n@@ -3571,8 +3573,6 @@ expand_copysign_absneg (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n     }\n   else\n     {\n-      double_int mask;\n-\n       if (GET_MODE_SIZE (mode) <= UNITS_PER_WORD)\n \t{\n \t  imode = int_mode_for_mode (mode);\n@@ -3593,10 +3593,9 @@ expand_copysign_absneg (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n \t  op1 = operand_subword_force (op1, word, mode);\n \t}\n \n-      mask = double_int_zero.set_bit (bitpos);\n-\n+      wide_int mask = wi::set_bit_in_zero (bitpos, GET_MODE_PRECISION (imode));\n       sign = expand_binop (imode, and_optab, op1,\n-\t\t\t   immed_double_int_const (mask, imode),\n+\t\t\t   immed_wide_int_const (mask, imode),\n \t\t\t   NULL_RTX, 1, OPTAB_LIB_WIDEN);\n     }\n \n@@ -3640,7 +3639,6 @@ expand_copysign_bit (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n \t\t     int bitpos, bool op0_is_abs)\n {\n   enum machine_mode imode;\n-  double_int mask;\n   int word, nwords, i;\n   rtx temp, insns;\n \n@@ -3664,7 +3662,7 @@ expand_copysign_bit (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n       nwords = (GET_MODE_BITSIZE (mode) + BITS_PER_WORD - 1) / BITS_PER_WORD;\n     }\n \n-  mask = double_int_zero.set_bit (bitpos);\n+  wide_int mask = wi::set_bit_in_zero (bitpos, GET_MODE_PRECISION (imode));\n \n   if (target == 0\n       || target == op0\n@@ -3686,12 +3684,11 @@ expand_copysign_bit (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n \t      if (!op0_is_abs)\n \t\top0_piece\n \t\t  = expand_binop (imode, and_optab, op0_piece,\n-\t\t\t\t  immed_double_int_const (~mask, imode),\n+\t\t\t\t  immed_wide_int_const (~mask, imode),\n \t\t\t\t  NULL_RTX, 1, OPTAB_LIB_WIDEN);\n-\n \t      op1 = expand_binop (imode, and_optab,\n \t\t\t\t  operand_subword_force (op1, i, mode),\n-\t\t\t\t  immed_double_int_const (mask, imode),\n+\t\t\t\t  immed_wide_int_const (mask, imode),\n \t\t\t\t  NULL_RTX, 1, OPTAB_LIB_WIDEN);\n \n \t      temp = expand_binop (imode, ior_optab, op0_piece, op1,\n@@ -3711,13 +3708,13 @@ expand_copysign_bit (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n   else\n     {\n       op1 = expand_binop (imode, and_optab, gen_lowpart (imode, op1),\n-\t\t          immed_double_int_const (mask, imode),\n+\t\t          immed_wide_int_const (mask, imode),\n \t\t          NULL_RTX, 1, OPTAB_LIB_WIDEN);\n \n       op0 = gen_lowpart (imode, op0);\n       if (!op0_is_abs)\n \top0 = expand_binop (imode, and_optab, op0,\n-\t\t\t    immed_double_int_const (~mask, imode),\n+\t\t\t    immed_wide_int_const (~mask, imode),\n \t\t\t    NULL_RTX, 1, OPTAB_LIB_WIDEN);\n \n       temp = expand_binop (imode, ior_optab, op0, op1,"}, {"sha": "47687203d6679d89790d8294db419e9cf9262fb4", "filename": "gcc/postreload.c", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fpostreload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fpostreload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpostreload.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -295,27 +295,27 @@ reload_cse_simplify_set (rtx set, rtx insn)\n #ifdef LOAD_EXTEND_OP\n \t  if (extend_op != UNKNOWN)\n \t    {\n-\t      HOST_WIDE_INT this_val;\n+\t      wide_int result;\n \n-\t      /* ??? I'm lazy and don't wish to handle CONST_DOUBLE.  Other\n-\t\t constants, such as SYMBOL_REF, cannot be extended.  */\n-\t      if (!CONST_INT_P (this_rtx))\n+\t      if (!CONST_SCALAR_INT_P (this_rtx))\n \t\tcontinue;\n \n-\t      this_val = INTVAL (this_rtx);\n \t      switch (extend_op)\n \t\t{\n \t\tcase ZERO_EXTEND:\n-\t\t  this_val &= GET_MODE_MASK (GET_MODE (src));\n+\t\t  result = wide_int::from (std::make_pair (this_rtx,\n+\t\t\t\t\t\t\t   GET_MODE (src)),\n+\t\t\t\t\t   BITS_PER_WORD, UNSIGNED);\n \t\t  break;\n \t\tcase SIGN_EXTEND:\n-\t\t  /* ??? In theory we're already extended.  */\n-\t\t  if (this_val == trunc_int_for_mode (this_val, GET_MODE (src)))\n-\t\t    break;\n+\t\t  result = wide_int::from (std::make_pair (this_rtx,\n+\t\t\t\t\t\t\t   GET_MODE (src)),\n+\t\t\t\t\t   BITS_PER_WORD, SIGNED);\n+\t\t  break;\n \t\tdefault:\n \t\t  gcc_unreachable ();\n \t\t}\n-\t      this_rtx = GEN_INT (this_val);\n+\t      this_rtx = immed_wide_int_const (result, word_mode);\n \t    }\n #endif\n \t  this_cost = set_src_cost (this_rtx, speed);"}, {"sha": "165cc4e2ec65cf1817eda19cb244e5a29f906b70", "filename": "gcc/predict.c", "status": "modified", "additions": 32, "deletions": 49, "changes": 81, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fpredict.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fpredict.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpredict.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1306,76 +1306,59 @@ predict_iv_comparison (struct loop *loop, basic_block bb,\n       && tree_fits_shwi_p (compare_base))\n     {\n       int probability;\n-      bool of, overflow = false;\n-      double_int mod, compare_count, tem, loop_count;\n-\n-      double_int loop_bound = tree_to_double_int (loop_bound_var);\n-      double_int compare_bound = tree_to_double_int (compare_var);\n-      double_int base = tree_to_double_int (compare_base);\n-      double_int compare_step = tree_to_double_int (compare_step_var);\n+      bool overflow, overall_overflow = false;\n+      widest_int compare_count, tem;\n \n       /* (loop_bound - base) / compare_step */\n-      tem = loop_bound.sub_with_overflow (base, &of);\n-      overflow |= of;\n-      loop_count = tem.divmod_with_overflow (compare_step,\n-\t\t\t\t\t      0, TRUNC_DIV_EXPR,\n-\t\t\t\t\t      &mod, &of);\n-      overflow |= of;\n-\n-      if ((!compare_step.is_negative ())\n+      tem = wi::sub (wi::to_widest (loop_bound_var),\n+\t\t     wi::to_widest (compare_base), SIGNED, &overflow);\n+      overall_overflow |= overflow;\n+      widest_int loop_count = wi::div_trunc (tem,\n+\t\t\t\t\t     wi::to_widest (compare_step_var),\n+\t\t\t\t\t     SIGNED, &overflow);\n+      overall_overflow |= overflow;\n+\n+      if (!wi::neg_p (wi::to_widest (compare_step_var))\n           ^ (compare_code == LT_EXPR || compare_code == LE_EXPR))\n \t{\n \t  /* (loop_bound - compare_bound) / compare_step */\n-\t  tem = loop_bound.sub_with_overflow (compare_bound, &of);\n-\t  overflow |= of;\n-\t  compare_count = tem.divmod_with_overflow (compare_step,\n-\t\t\t\t\t\t     0, TRUNC_DIV_EXPR,\n-\t\t\t\t\t\t     &mod, &of);\n-\t  overflow |= of;\n+\t  tem = wi::sub (wi::to_widest (loop_bound_var),\n+\t\t\t wi::to_widest (compare_var), SIGNED, &overflow);\n+\t  overall_overflow |= overflow;\n+\t  compare_count = wi::div_trunc (tem, wi::to_widest (compare_step_var),\n+\t\t\t\t\t SIGNED, &overflow);\n+\t  overall_overflow |= overflow;\n \t}\n       else\n         {\n \t  /* (compare_bound - base) / compare_step */\n-\t  tem = compare_bound.sub_with_overflow (base, &of);\n-\t  overflow |= of;\n-          compare_count = tem.divmod_with_overflow (compare_step,\n-\t\t\t\t\t\t     0, TRUNC_DIV_EXPR,\n-\t\t\t\t\t\t     &mod, &of);\n-\t  overflow |= of;\n+\t  tem = wi::sub (wi::to_widest (compare_var),\n+\t\t\t wi::to_widest (compare_base), SIGNED, &overflow);\n+\t  overall_overflow |= overflow;\n+          compare_count = wi::div_trunc (tem, wi::to_widest (compare_step_var),\n+\t\t\t\t\t SIGNED, &overflow);\n+\t  overall_overflow |= overflow;\n \t}\n       if (compare_code == LE_EXPR || compare_code == GE_EXPR)\n \t++compare_count;\n       if (loop_bound_code == LE_EXPR || loop_bound_code == GE_EXPR)\n \t++loop_count;\n-      if (compare_count.is_negative ())\n-        compare_count = double_int_zero;\n-      if (loop_count.is_negative ())\n-        loop_count = double_int_zero;\n-      if (loop_count.is_zero ())\n+      if (wi::neg_p (compare_count))\n+        compare_count = 0;\n+      if (wi::neg_p (loop_count))\n+        loop_count = 0;\n+      if (loop_count == 0)\n \tprobability = 0;\n-      else if (compare_count.scmp (loop_count) == 1)\n+      else if (wi::cmps (compare_count, loop_count) == 1)\n \tprobability = REG_BR_PROB_BASE;\n       else\n         {\n-\t  /* If loop_count is too big, such that REG_BR_PROB_BASE * loop_count\n-\t     could overflow, shift both loop_count and compare_count right\n-\t     a bit so that it doesn't overflow.  Note both counts are known not\n-\t     to be negative at this point.  */\n-\t  int clz_bits = clz_hwi (loop_count.high);\n-\t  gcc_assert (REG_BR_PROB_BASE < 32768);\n-\t  if (clz_bits < 16)\n-\t    {\n-\t      loop_count.arshift (16 - clz_bits, HOST_BITS_PER_DOUBLE_INT);\n-\t      compare_count.arshift (16 - clz_bits, HOST_BITS_PER_DOUBLE_INT);\n-\t    }\n-\t  tem = compare_count.mul_with_sign (double_int::from_shwi\n-\t\t\t\t\t    (REG_BR_PROB_BASE), true, &of);\n-\t  gcc_assert (!of);\n-\t  tem = tem.divmod (loop_count, true, TRUNC_DIV_EXPR, &mod);\n+\t  tem = compare_count * REG_BR_PROB_BASE;\n+\t  tem = wi::udiv_trunc (tem, loop_count);\n \t  probability = tem.to_uhwi ();\n \t}\n \n-      if (!overflow)\n+      if (!overall_overflow)\n         predict_edge (then_edge, PRED_LOOP_IV_COMPARE, probability);\n \n       return;"}, {"sha": "1deaa667290dbc9412de8e20faa20ff552caed2c", "filename": "gcc/pretty-print.h", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fpretty-print.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fpretty-print.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpretty-print.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -23,6 +23,7 @@ along with GCC; see the file COPYING3.  If not see\n \n #include \"obstack.h\"\n #include \"input.h\"\n+#include \"wide-int-print.h\"\n \n /* Maximum number of format string arguments.  */\n #define PP_NL_ARGMAX   30\n@@ -261,6 +262,13 @@ pp_get_prefix (const pretty_printer *pp) { return pp->prefix; }\n #define pp_decimal_int(PP, I)  pp_scalar (PP, \"%d\", I)\n #define pp_unsigned_wide_integer(PP, I) \\\n    pp_scalar (PP, HOST_WIDE_INT_PRINT_UNSIGNED, (unsigned HOST_WIDE_INT) I)\n+#define pp_wide_int(PP, W, SGN)\t\t\t\t\t\\\n+  do\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\\\n+      print_dec (W, pp_buffer (PP)->digit_buffer, SGN);\t\t\\\n+      pp_string (PP, pp_buffer (PP)->digit_buffer);\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+  while (0)\n #define pp_wide_integer(PP, I) \\\n    pp_scalar (PP, HOST_WIDE_INT_PRINT_DEC, (HOST_WIDE_INT) I)\n #define pp_widest_integer(PP, I) \\"}, {"sha": "3b0efa3938a6ac7609496942ffefad5b75f144dc", "filename": "gcc/print-rtl.c", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fprint-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fprint-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fprint-rtl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -629,6 +629,11 @@ print_rtx (const_rtx in_rtx)\n \t  fprintf (outfile, \" [%s]\", s);\n \t}\n       break;\n+\n+    case CONST_WIDE_INT:\n+      fprintf (outfile, \" \");\n+      cwi_output_hex (outfile, in_rtx);\n+      break;\n #endif\n \n     case CODE_LABEL:"}, {"sha": "e26b0633d5831dad3be35c148415441fdde73186", "filename": "gcc/print-tree.c", "status": "modified", "additions": 4, "deletions": 22, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fprint-tree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fprint-tree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fprint-tree.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -35,6 +35,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-cfg.h\"\n #include \"tree-dump.h\"\n #include \"dumpfile.h\"\n+#include \"wide-int-print.h\"\n \n /* Define the hash table of nodes already seen.\n    Such nodes are not repeated; brief cross-references are used.  */\n@@ -125,16 +126,7 @@ print_node_brief (FILE *file, const char *prefix, const_tree node, int indent)\n \tfprintf (file, \" overflow\");\n \n       fprintf (file, \" \");\n-      if (TREE_INT_CST_HIGH (node) == 0)\n-\tfprintf (file, HOST_WIDE_INT_PRINT_UNSIGNED, TREE_INT_CST_LOW (node));\n-      else if (TREE_INT_CST_HIGH (node) == -1\n-\t       && TREE_INT_CST_LOW (node) != 0)\n-\tfprintf (file, \"-\" HOST_WIDE_INT_PRINT_UNSIGNED,\n-\t\t -TREE_INT_CST_LOW (node));\n-      else\n-\tfprintf (file, HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t\t (unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (node),\n-\t\t (unsigned HOST_WIDE_INT) TREE_INT_CST_LOW (node));\n+      print_dec (node, file, TYPE_SIGN (TREE_TYPE (node)));\n     }\n   if (TREE_CODE (node) == REAL_CST)\n     {\n@@ -341,7 +333,7 @@ print_node (FILE *file, const char *prefix, tree node, int indent)\n   if (TREE_VISITED (node))\n     fputs (\" visited\", file);\n \n-  if (code != TREE_VEC && code != SSA_NAME)\n+  if (code != TREE_VEC && code != INTEGER_CST && code != SSA_NAME)\n     {\n       if (TREE_LANG_FLAG_0 (node))\n \tfputs (\" tree_0\", file);\n@@ -743,17 +735,7 @@ print_node (FILE *file, const char *prefix, tree node, int indent)\n \t    fprintf (file, \" overflow\");\n \n \t  fprintf (file, \" \");\n-\t  if (TREE_INT_CST_HIGH (node) == 0)\n-\t    fprintf (file, HOST_WIDE_INT_PRINT_UNSIGNED,\n-\t\t     TREE_INT_CST_LOW (node));\n-\t  else if (TREE_INT_CST_HIGH (node) == -1\n-\t\t   && TREE_INT_CST_LOW (node) != 0)\n-\t    fprintf (file, \"-\" HOST_WIDE_INT_PRINT_UNSIGNED,\n-\t\t     -TREE_INT_CST_LOW (node));\n-\t  else\n-\t    fprintf (file, HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t\t     (unsigned HOST_WIDE_INT) TREE_INT_CST_HIGH (node),\n-\t\t     (unsigned HOST_WIDE_INT) TREE_INT_CST_LOW (node));\n+\t  print_dec (node, file, TYPE_SIGN (TREE_TYPE (node)));\n \t  break;\n \n \tcase REAL_CST:"}, {"sha": "046286dbf8ae60bb63ab7deba92b94370d1ecfc1", "filename": "gcc/read-rtl.c", "status": "modified", "additions": 71, "deletions": 0, "changes": 71, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fread-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fread-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fread-rtl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -811,6 +811,29 @@ validate_const_int (const char *string)\n     fatal_with_file_and_line (\"invalid decimal constant \\\"%s\\\"\\n\", string);\n }\n \n+static void\n+validate_const_wide_int (const char *string)\n+{\n+  const char *cp;\n+  int valid = 1;\n+\n+  cp = string;\n+  while (*cp && ISSPACE (*cp))\n+    cp++;\n+  /* Skip the leading 0x.  */\n+  if (cp[0] == '0' || cp[1] == 'x')\n+    cp += 2;\n+  else\n+    valid = 0;\n+  if (*cp == 0)\n+    valid = 0;\n+  for (; *cp; cp++)\n+    if (! ISXDIGIT (*cp))\n+      valid = 0;\n+  if (!valid)\n+    fatal_with_file_and_line (\"invalid hex constant \\\"%s\\\"\\n\", string);\n+}\n+\n /* Record that PTR uses iterator ITERATOR.  */\n \n static void\n@@ -1327,6 +1350,54 @@ read_rtx_code (const char *code_name)\n \tgcc_unreachable ();\n       }\n \n+  if (CONST_WIDE_INT_P (return_rtx))\n+    {\n+      read_name (&name);\n+      validate_const_wide_int (name.string);\n+      {\n+\tconst char *s = name.string;\n+\tint len;\n+\tint index = 0;\n+\tint gs = HOST_BITS_PER_WIDE_INT/4;\n+\tint pos;\n+\tchar * buf = XALLOCAVEC (char, gs + 1);\n+\tunsigned HOST_WIDE_INT wi;\n+\tint wlen;\n+\n+\t/* Skip the leading spaces.  */\n+\twhile (*s && ISSPACE (*s))\n+\t  s++;\n+\n+\t/* Skip the leading 0x.  */\n+\tgcc_assert (s[0] == '0');\n+\tgcc_assert (s[1] == 'x');\n+\ts += 2;\n+\n+\tlen = strlen (s);\n+\tpos = len - gs;\n+\twlen = (len + gs - 1) / gs;\t/* Number of words needed */\n+\n+\treturn_rtx = const_wide_int_alloc (wlen);\n+\n+\twhile (pos > 0)\n+\t  {\n+#if HOST_BITS_PER_WIDE_INT == 64\n+\t    sscanf (s + pos, \"%16\" HOST_WIDE_INT_PRINT \"x\", &wi);\n+#else\n+\t    sscanf (s + pos, \"%8\" HOST_WIDE_INT_PRINT \"x\", &wi);\n+#endif\n+\t    CWI_ELT (return_rtx, index++) = wi;\n+\t    pos -= gs;\n+\t  }\n+\tstrncpy (buf, s, gs - pos);\n+\tbuf [gs - pos] = 0;\n+\tsscanf (buf, \"%\" HOST_WIDE_INT_PRINT \"x\", &wi);\n+\tCWI_ELT (return_rtx, index++) = wi;\n+\t/* TODO: After reading, do we want to canonicalize with:\n+\t   value = lookup_const_wide_int (value); ? */\n+      }\n+    }\n+\n   c = read_skip_spaces ();\n   /* Syntactic sugar for AND and IOR, allowing Lisp-like\n      arbitrary number of arguments for them.  */"}, {"sha": "231fc96c932a7bc43d4cbf339d39f57d2ee70b9a", "filename": "gcc/real.c", "status": "modified", "additions": 111, "deletions": 65, "changes": 176, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Freal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Freal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freal.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -29,6 +29,7 @@\n #include \"realmpfr.h\"\n #include \"tm_p.h\"\n #include \"dfp.h\"\n+#include \"wide-int.h\"\n \n /* The floating point model used internally is not exactly IEEE 754\n    compliant, and close to the description in the ISO C99 standard,\n@@ -1370,43 +1371,36 @@ real_to_integer (const REAL_VALUE_TYPE *r)\n     }\n }\n \n-/* Likewise, but to an integer pair, HI+LOW.  */\n+/* Likewise, but producing a wide-int of PRECISION.  If the value cannot\n+   be represented in precision, *FAIL is set to TRUE.  */\n \n-void\n-real_to_integer2 (HOST_WIDE_INT *plow, HOST_WIDE_INT *phigh,\n-\t\t  const REAL_VALUE_TYPE *r)\n+wide_int\n+real_to_integer (const REAL_VALUE_TYPE *r, bool *fail, int precision)\n {\n-  REAL_VALUE_TYPE t;\n-  unsigned HOST_WIDE_INT low;\n-  HOST_WIDE_INT high;\n+  HOST_WIDE_INT val[2 * WIDE_INT_MAX_ELTS];\n   int exp;\n+  int words, w;\n+  wide_int result;\n \n   switch (r->cl)\n     {\n     case rvc_zero:\n     underflow:\n-      low = high = 0;\n-      break;\n+      return wi::zero (precision);\n \n     case rvc_inf:\n     case rvc_nan:\n     overflow:\n-      high = (unsigned HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT - 1);\n+      *fail = true;\n+\n       if (r->sign)\n-\tlow = 0;\n+\treturn wi::set_bit_in_zero (precision - 1, precision);\n       else\n-\t{\n-\t  high--;\n-\t  low = -1;\n-\t}\n-      break;\n+\treturn ~wi::set_bit_in_zero (precision - 1, precision);\n \n     case rvc_normal:\n       if (r->decimal)\n-\t{\n-\t  decimal_real_to_integer2 (plow, phigh, r);\n-\t  return;\n-\t}\n+\treturn decimal_real_to_integer (r, fail, precision);\n \n       exp = REAL_EXP (r);\n       if (exp <= 0)\n@@ -1415,42 +1409,49 @@ real_to_integer2 (HOST_WIDE_INT *plow, HOST_WIDE_INT *phigh,\n \t undefined, so it doesn't matter what we return, and some callers\n \t expect to be able to use this routine for both signed and\n \t unsigned conversions.  */\n-      if (exp > HOST_BITS_PER_DOUBLE_INT)\n+      if (exp > precision)\n \tgoto overflow;\n \n-      rshift_significand (&t, r, HOST_BITS_PER_DOUBLE_INT - exp);\n-      if (HOST_BITS_PER_WIDE_INT == HOST_BITS_PER_LONG)\n+      /* Put the significand into a wide_int that has precision W, which\n+\t is the smallest HWI-multiple that has at least PRECISION bits.\n+\t This ensures that the top bit of the significand is in the\n+\t top bit of the wide_int.  */\n+      words = (precision + HOST_BITS_PER_WIDE_INT - 1) / HOST_BITS_PER_WIDE_INT;\n+      w = words * HOST_BITS_PER_WIDE_INT;\n+\n+#if (HOST_BITS_PER_WIDE_INT == HOST_BITS_PER_LONG)\n+      for (int i = 0; i < words; i++)\n \t{\n-\t  high = t.sig[SIGSZ-1];\n-\t  low = t.sig[SIGSZ-2];\n+\t  int j = SIGSZ - words + i;\n+\t  val[i] = (j < 0) ? 0 : r->sig[j];\n \t}\n-      else\n+#else\n+      gcc_assert (HOST_BITS_PER_WIDE_INT == 2 * HOST_BITS_PER_LONG);\n+      for (int i = 0; i < words; i++)\n \t{\n-\t  gcc_assert (HOST_BITS_PER_WIDE_INT == 2*HOST_BITS_PER_LONG);\n-\t  high = t.sig[SIGSZ-1];\n-\t  high = high << (HOST_BITS_PER_LONG - 1) << 1;\n-\t  high |= t.sig[SIGSZ-2];\n-\n-\t  low = t.sig[SIGSZ-3];\n-\t  low = low << (HOST_BITS_PER_LONG - 1) << 1;\n-\t  low |= t.sig[SIGSZ-4];\n+\t  int j = SIGSZ - (words * 2) + (i * 2);\n+\t  if (j < 0)\n+\t    val[i] = 0;\n+\t  else\n+\t    val[i] = r->sig[j];\n+\t  j += 1;\n+\t  if (j >= 0)\n+\t    val[i] |= (unsigned HOST_WIDE_INT) r->sig[j] << HOST_BITS_PER_LONG;\n \t}\n+#endif\n+      /* Shift the value into place and truncate to the desired precision.  */\n+      result = wide_int::from_array (val, words, w);\n+      result = wi::lrshift (result, w - exp);\n+      result = wide_int::from (result, precision, UNSIGNED);\n \n       if (r->sign)\n-\t{\n-\t  if (low == 0)\n-\t    high = -high;\n-\t  else\n-\t    low = -low, high = ~high;\n-\t}\n-      break;\n+\treturn -result;\n+      else\n+\treturn result;\n \n     default:\n       gcc_unreachable ();\n     }\n-\n-  *plow = low;\n-  *phigh = high;\n }\n \n /* A subroutine of real_to_decimal.  Compute the quotient and remainder\n@@ -2113,43 +2114,88 @@ real_from_string3 (REAL_VALUE_TYPE *r, const char *s, enum machine_mode mode)\n     real_convert (r, mode, r);\n }\n \n-/* Initialize R from the integer pair HIGH+LOW.  */\n+/* Initialize R from the wide_int VAL_IN.  The MODE is not VOIDmode,*/\n \n void\n real_from_integer (REAL_VALUE_TYPE *r, enum machine_mode mode,\n-\t\t   unsigned HOST_WIDE_INT low, HOST_WIDE_INT high,\n-\t\t   int unsigned_p)\n+\t\t   const wide_int_ref &val_in, signop sgn)\n {\n-  if (low == 0 && high == 0)\n+  if (val_in == 0)\n     get_zero (r, 0);\n   else\n     {\n+      unsigned int len = val_in.get_precision ();\n+      int i, j, e = 0;\n+      int maxbitlen = MAX_BITSIZE_MODE_ANY_INT + HOST_BITS_PER_WIDE_INT;\n+      const unsigned int realmax = (SIGNIFICAND_BITS / HOST_BITS_PER_WIDE_INT\n+\t\t\t\t    * HOST_BITS_PER_WIDE_INT);\n+\n       memset (r, 0, sizeof (*r));\n       r->cl = rvc_normal;\n-      r->sign = high < 0 && !unsigned_p;\n-      SET_REAL_EXP (r, HOST_BITS_PER_DOUBLE_INT);\n+      r->sign = wi::neg_p (val_in, sgn);\n+\n+      /* We have to ensure we can negate the largest negative number.  */\n+      wide_int val = wide_int::from (val_in, maxbitlen, sgn);\n \n       if (r->sign)\n+\tval = -val;\n+\n+      /* Ensure a multiple of HOST_BITS_PER_WIDE_INT, ceiling, as elt\n+\t won't work with precisions that are not a multiple of\n+\t HOST_BITS_PER_WIDE_INT.  */\n+      len += HOST_BITS_PER_WIDE_INT - 1;\n+\n+      /* Ensure we can represent the largest negative number.  */\n+      len += 1;\n+\n+      len = len/HOST_BITS_PER_WIDE_INT * HOST_BITS_PER_WIDE_INT;\n+\n+      /* Cap the size to the size allowed by real.h.  */\n+      if (len > realmax)\n \t{\n-\t  high = ~high;\n-\t  if (low == 0)\n-\t    high += 1;\n-\t  else\n-\t    low = -low;\n+\t  HOST_WIDE_INT cnt_l_z;\n+\t  cnt_l_z = wi::clz (val);\n+\n+\t  if (maxbitlen - cnt_l_z > realmax)\n+\t    {\n+\t      e = maxbitlen - cnt_l_z - realmax;\n+\n+\t      /* This value is too large, we must shift it right to\n+\t\t preserve all the bits we can, and then bump the\n+\t\t exponent up by that amount.  */\n+\t      val = wi::lrshift (val, e);\n+\t    }\n+\t  len = realmax;\n \t}\n \n+      /* Clear out top bits so elt will work with precisions that aren't\n+\t a multiple of HOST_BITS_PER_WIDE_INT.  */\n+      val = wide_int::from (val, len, sgn);\n+      len = len / HOST_BITS_PER_WIDE_INT;\n+\n+      SET_REAL_EXP (r, len * HOST_BITS_PER_WIDE_INT + e);\n+\n+      j = SIGSZ - 1;\n       if (HOST_BITS_PER_LONG == HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  r->sig[SIGSZ-1] = high;\n-\t  r->sig[SIGSZ-2] = low;\n-\t}\n+\tfor (i = len - 1; i >= 0; i--)\n+\t  {\n+\t    r->sig[j--] = val.elt (i);\n+\t    if (j < 0)\n+\t      break;\n+\t  }\n       else\n \t{\n \t  gcc_assert (HOST_BITS_PER_LONG*2 == HOST_BITS_PER_WIDE_INT);\n-\t  r->sig[SIGSZ-1] = high >> (HOST_BITS_PER_LONG - 1) >> 1;\n-\t  r->sig[SIGSZ-2] = high;\n-\t  r->sig[SIGSZ-3] = low >> (HOST_BITS_PER_LONG - 1) >> 1;\n-\t  r->sig[SIGSZ-4] = low;\n+\t  for (i = len - 1; i >= 0; i--)\n+\t    {\n+\t      HOST_WIDE_INT e = val.elt (i);\n+\t      r->sig[j--] = e >> (HOST_BITS_PER_LONG - 1) >> 1;\n+\t      if (j < 0)\n+\t\tbreak;\n+\t      r->sig[j--] = e;\n+\t      if (j < 0)\n+\t\tbreak;\n+\t    }\n \t}\n \n       normalize (r);\n@@ -2239,7 +2285,7 @@ ten_to_ptwo (int n)\n \t  for (i = 0; i < n; ++i)\n \t    t *= t;\n \n-\t  real_from_integer (&tens[n], VOIDmode, t, 0, 1);\n+\t  real_from_integer (&tens[n], VOIDmode, t, UNSIGNED);\n \t}\n       else\n \t{\n@@ -2278,7 +2324,7 @@ real_digit (int n)\n   gcc_assert (n <= 9);\n \n   if (n > 0 && num[n].cl == rvc_zero)\n-    real_from_integer (&num[n], VOIDmode, n, 0, 1);\n+    real_from_integer (&num[n], VOIDmode, n, UNSIGNED);\n \n   return &num[n];\n }"}, {"sha": "01c405c201e1ca97e8eed7a0b8fd8b5ecb71298e", "filename": "gcc/real.h", "status": "modified", "additions": 11, "deletions": 15, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Freal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Freal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freal.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -21,6 +21,9 @@\n #define GCC_REAL_H\n \n #include \"machmode.h\"\n+#include \"signop.h\"\n+#include \"wide-int.h\"\n+#include \"insn-modes.h\"\n \n /* An expanded form of the represented number.  */\n \n@@ -267,19 +270,13 @@ extern void real_to_hexadecimal (char *, const REAL_VALUE_TYPE *,\n \n /* Render R as an integer.  */\n extern HOST_WIDE_INT real_to_integer (const REAL_VALUE_TYPE *);\n-extern void real_to_integer2 (HOST_WIDE_INT *, HOST_WIDE_INT *,\n-\t\t\t      const REAL_VALUE_TYPE *);\n \n /* Initialize R from a decimal or hexadecimal string.  Return -1 if\n    the value underflows, +1 if overflows, and 0 otherwise.  */\n extern int real_from_string (REAL_VALUE_TYPE *, const char *);\n /* Wrapper to allow different internal representation for decimal floats. */\n extern void real_from_string3 (REAL_VALUE_TYPE *, const char *, enum machine_mode);\n \n-/* Initialize R from an integer pair HIGH/LOW.  */\n-extern void real_from_integer (REAL_VALUE_TYPE *, enum machine_mode,\n-\t\t\t       unsigned HOST_WIDE_INT, HOST_WIDE_INT, int);\n-\n extern long real_to_target_fmt (long *, const REAL_VALUE_TYPE *,\n \t\t\t\tconst struct real_format *);\n extern long real_to_target (long *, const REAL_VALUE_TYPE *, enum machine_mode);\n@@ -361,12 +358,6 @@ extern const struct real_format arm_half_format;\n #define REAL_VALUE_TO_TARGET_SINGLE(IN, OUT) \\\n   ((OUT) = real_to_target (NULL, &(IN), mode_for_size (32, MODE_FLOAT, 0)))\n \n-#define REAL_VALUE_FROM_INT(r, lo, hi, mode) \\\n-  real_from_integer (&(r), mode, lo, hi, 0)\n-\n-#define REAL_VALUE_FROM_UNSIGNED_INT(r, lo, hi, mode) \\\n-  real_from_integer (&(r), mode, lo, hi, 1)\n-\n /* Real values to IEEE 754 decimal floats.  */\n \n /* IN is a REAL_VALUE_TYPE.  OUT is an array of longs.  */\n@@ -383,9 +374,6 @@ extern const struct real_format arm_half_format;\n extern REAL_VALUE_TYPE real_value_truncate (enum machine_mode,\n \t\t\t\t\t    REAL_VALUE_TYPE);\n \n-#define REAL_VALUE_TO_INT(plow, phigh, r) \\\n-  real_to_integer2 (plow, phigh, &(r))\n-\n extern REAL_VALUE_TYPE real_value_negate (const REAL_VALUE_TYPE *);\n extern REAL_VALUE_TYPE real_value_abs (const REAL_VALUE_TYPE *);\n \n@@ -485,4 +473,12 @@ extern bool real_isinteger (const REAL_VALUE_TYPE *c, enum machine_mode mode);\n    number, (1 - b**-p) * b**emax for a given FP format FMT as a hex\n    float string.  BUF must be large enough to contain the result.  */\n extern void get_max_float (const struct real_format *, char *, size_t);\n+\n+#ifndef GENERATOR_FILE\n+/* real related routines.  */\n+extern wide_int real_to_integer (const REAL_VALUE_TYPE *, bool *, int);\n+extern void real_from_integer (REAL_VALUE_TYPE *, enum machine_mode,\n+\t\t\t       const wide_int_ref &, signop);\n+#endif\n+\n #endif /* ! GCC_REAL_H */"}, {"sha": "2f5cf8eb5773f1bbf7a249c3f2bd4ac58b5f2347", "filename": "gcc/recog.c", "status": "modified", "additions": 48, "deletions": 4, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Frecog.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Frecog.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frecog.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1165,7 +1165,7 @@ immediate_operand (rtx op, enum machine_mode mode)\n \t\t\t\t\t    : mode, op));\n }\n \n-/* Returns 1 if OP is an operand that is a CONST_INT.  */\n+/* Returns 1 if OP is an operand that is a CONST_INT of mode MODE.  */\n \n int\n const_int_operand (rtx op, enum machine_mode mode)\n@@ -1180,8 +1180,51 @@ const_int_operand (rtx op, enum machine_mode mode)\n   return 1;\n }\n \n+#if TARGET_SUPPORTS_WIDE_INT\n+/* Returns 1 if OP is an operand that is a CONST_INT or CONST_WIDE_INT\n+   of mode MODE.  */\n+int\n+const_scalar_int_operand (rtx op, enum machine_mode mode)\n+{\n+  if (!CONST_SCALAR_INT_P (op))\n+    return 0;\n+\n+  if (CONST_INT_P (op))\n+    return const_int_operand (op, mode);\n+\n+  if (mode != VOIDmode)\n+    {\n+      int prec = GET_MODE_PRECISION (mode);\n+      int bitsize = GET_MODE_BITSIZE (mode);\n+\n+      if (CONST_WIDE_INT_NUNITS (op) * HOST_BITS_PER_WIDE_INT > bitsize)\n+\treturn 0;\n+\n+      if (prec == bitsize)\n+\treturn 1;\n+      else\n+\t{\n+\t  /* Multiword partial int.  */\n+\t  HOST_WIDE_INT x\n+\t    = CONST_WIDE_INT_ELT (op, CONST_WIDE_INT_NUNITS (op) - 1);\n+\t  return (sext_hwi (x, prec & (HOST_BITS_PER_WIDE_INT - 1)) == x);\n+\t}\n+    }\n+  return 1;\n+}\n+\n /* Returns 1 if OP is an operand that is a constant integer or constant\n-   floating-point number.  */\n+   floating-point number of MODE.  */\n+\n+int\n+const_double_operand (rtx op, enum machine_mode mode)\n+{\n+  return (GET_CODE (op) == CONST_DOUBLE)\n+\t  && (GET_MODE (op) == mode || mode == VOIDmode);\n+}\n+#else\n+/* Returns 1 if OP is an operand that is a constant integer or constant\n+   floating-point number of MODE.  */\n \n int\n const_double_operand (rtx op, enum machine_mode mode)\n@@ -1197,8 +1240,9 @@ const_double_operand (rtx op, enum machine_mode mode)\n \t  && (mode == VOIDmode || GET_MODE (op) == mode\n \t      || GET_MODE (op) == VOIDmode));\n }\n-\n-/* Return 1 if OP is a general operand that is not an immediate operand.  */\n+#endif\n+/* Return 1 if OP is a general operand that is not an immediate\n+   operand of mode MODE.  */\n \n int\n nonimmediate_operand (rtx op, enum machine_mode mode)"}, {"sha": "d241c83885b279e41dd5a61b1244e0a5c4cbc34b", "filename": "gcc/rtl.c", "status": "modified", "additions": 50, "deletions": 5, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -109,7 +109,7 @@ const enum rtx_class rtx_class[NUM_RTX_CODE] = {\n const unsigned char rtx_code_size[NUM_RTX_CODE] = {\n #define DEF_RTL_EXPR(ENUM, NAME, FORMAT, CLASS)\t\t\t\t\\\n   (((ENUM) == CONST_INT || (ENUM) == CONST_DOUBLE\t\t\t\\\n-    || (ENUM) == CONST_FIXED)\t\t\t\t\t\t\\\n+    || (ENUM) == CONST_FIXED || (ENUM) == CONST_WIDE_INT)\t\t\\\n    ? RTX_HDR_SIZE + (sizeof FORMAT - 1) * sizeof (HOST_WIDE_INT)\t\\\n    : RTX_HDR_SIZE + (sizeof FORMAT - 1) * sizeof (rtunion)),\n \n@@ -181,18 +181,24 @@ shallow_copy_rtvec (rtvec vec)\n unsigned int\n rtx_size (const_rtx x)\n {\n+  if (CONST_WIDE_INT_P (x))\n+    return (RTX_HDR_SIZE\n+\t    + sizeof (struct hwivec_def)\n+\t    + ((CONST_WIDE_INT_NUNITS (x) - 1)\n+\t       * sizeof (HOST_WIDE_INT)));\n   if (GET_CODE (x) == SYMBOL_REF && SYMBOL_REF_HAS_BLOCK_INFO_P (x))\n     return RTX_HDR_SIZE + sizeof (struct block_symbol);\n   return RTX_CODE_SIZE (GET_CODE (x));\n }\n \n-/* Allocate an rtx of code CODE.  The CODE is stored in the rtx;\n-   all the rest is initialized to zero.  */\n+/* Allocate an rtx of code CODE with EXTRA bytes in it.  The CODE is\n+   stored in the rtx; all the rest is initialized to zero.  */\n \n rtx\n-rtx_alloc_stat (RTX_CODE code MEM_STAT_DECL)\n+rtx_alloc_stat_v (RTX_CODE code MEM_STAT_DECL, int extra)\n {\n-  rtx rt = ggc_alloc_rtx_def_stat (RTX_CODE_SIZE (code) PASS_MEM_STAT);\n+  rtx rt = ggc_alloc_rtx_def_stat (RTX_CODE_SIZE (code) + extra\n+\t\t\t\t   PASS_MEM_STAT);\n \n   /* We want to clear everything up to the FLD array.  Normally, this\n      is one int, but we don't want to assume that and it isn't very\n@@ -210,6 +216,31 @@ rtx_alloc_stat (RTX_CODE code MEM_STAT_DECL)\n   return rt;\n }\n \n+/* Allocate an rtx of code CODE.  The CODE is stored in the rtx;\n+   all the rest is initialized to zero.  */\n+\n+rtx\n+rtx_alloc_stat (RTX_CODE code MEM_STAT_DECL)\n+{\n+  return rtx_alloc_stat_v (code PASS_MEM_STAT, 0);\n+}\n+\n+/* Write the wide constant X to OUTFILE.  */\n+\n+void\n+cwi_output_hex (FILE *outfile, const_rtx x)\n+{\n+  int i = CWI_GET_NUM_ELEM (x);\n+  gcc_assert (i > 0);\n+  if (CWI_ELT (x, i - 1) == 0)\n+    /* The HOST_WIDE_INT_PRINT_HEX prepends a 0x only if the val is\n+       non zero.  We want all numbers to have a 0x prefix.  */\n+    fprintf (outfile, \"0x\");\n+  fprintf (outfile, HOST_WIDE_INT_PRINT_HEX, CWI_ELT (x, --i));\n+  while (--i >= 0)\n+    fprintf (outfile, HOST_WIDE_INT_PRINT_PADDED_HEX, CWI_ELT (x, i));\n+}\n+\n \f\n /* Return true if ORIG is a sharable CONST.  */\n \n@@ -646,6 +677,10 @@ iterative_hash_rtx (const_rtx x, hashval_t hash)\n       return iterative_hash_object (i, hash);\n     case CONST_INT:\n       return iterative_hash_object (INTVAL (x), hash);\n+    case CONST_WIDE_INT:\n+      for (i = 0; i < CONST_WIDE_INT_NUNITS (x); i++)\n+\thash = iterative_hash_object (CONST_WIDE_INT_ELT (x, i), hash);\n+      return hash;\n     case SYMBOL_REF:\n       if (XSTR (x, 0))\n \treturn iterative_hash (XSTR (x, 0), strlen (XSTR (x, 0)) + 1,\n@@ -809,6 +844,16 @@ rtl_check_failed_block_symbol (const char *file, int line, const char *func)\n      \"in %s, at %s:%d\", func, trim_filename (file), line);\n }\n \n+/* XXX Maybe print the vector?  */\n+void\n+cwi_check_failed_bounds (const_rtx x, int n, const char *file, int line,\n+\t\t\t const char *func)\n+{\n+  internal_error\n+    (\"RTL check: access of hwi elt %d of vector with last elt %d in %s, at %s:%d\",\n+     n, CWI_GET_NUM_ELEM (x) - 1, func, trim_filename (file), line);\n+}\n+\n /* XXX Maybe print the vector?  */\n void\n rtvec_check_failed_bounds (const_rtvec r, int n, const char *file, int line,"}, {"sha": "2d7847d415732d4e9beee4a5bdecad1f634f3156", "filename": "gcc/rtl.def", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtl.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtl.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.def?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -345,6 +345,9 @@ DEF_RTL_EXPR(TRAP_IF, \"trap_if\", \"ee\", RTX_EXTRA)\n /* numeric integer constant */\n DEF_RTL_EXPR(CONST_INT, \"const_int\", \"w\", RTX_CONST_OBJ)\n \n+/* numeric integer constant */\n+DEF_RTL_EXPR(CONST_WIDE_INT, \"const_wide_int\", \"\", RTX_CONST_OBJ)\n+\n /* fixed-point constant */\n DEF_RTL_EXPR(CONST_FIXED, \"const_fixed\", \"www\", RTX_CONST_OBJ)\n "}, {"sha": "9fb75574e958213717ac4852b92863fff99a8ac5", "filename": "gcc/rtl.h", "status": "modified", "additions": 191, "deletions": 2, "changes": 193, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -20,6 +20,7 @@ along with GCC; see the file COPYING3.  If not see\n #ifndef GCC_RTL_H\n #define GCC_RTL_H\n \n+#include <utility>\n #include \"statistics.h\"\n #include \"machmode.h\"\n #include \"input.h\"\n@@ -28,6 +29,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"fixed-value.h\"\n #include \"alias.h\"\n #include \"hashtab.h\"\n+#include \"wide-int.h\"\n #include \"flags.h\"\n \n /* Value used by some passes to \"recognize\" noop moves as valid\n@@ -248,6 +250,16 @@ struct GTY(()) object_block {\n   vec<rtx, va_gc> *anchors;\n };\n \n+struct GTY((variable_size)) hwivec_def {\n+  HOST_WIDE_INT elem[1];\n+};\n+\n+/* Number of elements of the HWIVEC if RTX is a CONST_WIDE_INT.  */\n+#define CWI_GET_NUM_ELEM(RTX)\t\t\t\t\t\\\n+  ((int)RTL_FLAG_CHECK1(\"CWI_GET_NUM_ELEM\", (RTX), CONST_WIDE_INT)->u2.num_elem)\n+#define CWI_PUT_NUM_ELEM(RTX, NUM)\t\t\t\t\t\\\n+  (RTL_FLAG_CHECK1(\"CWI_PUT_NUM_ELEM\", (RTX), CONST_WIDE_INT)->u2.num_elem = (NUM))\n+\n /* RTL expression (\"rtx\").  */\n \n struct GTY((chain_next (\"RTX_NEXT (&%h)\"),\n@@ -334,6 +346,17 @@ struct GTY((chain_next (\"RTX_NEXT (&%h)\"),\n      1 in a VALUE or DEBUG_EXPR is NO_LOC_P in var-tracking.c.  */\n   unsigned return_val : 1;\n \n+  union {\n+    /* The final union field is aligned to 64 bits on LP64 hosts,\n+       giving a 32-bit gap after the fields above.  We optimize the\n+       layout for that case and use the gap for extra code-specific\n+       information.  */\n+\n+    /* In a CONST_WIDE_INT (aka hwivec_def), this is the number of\n+       HOST_WIDE_INTs in the hwivec_def.  */\n+    unsigned GTY ((tag (\"CONST_WIDE_INT\"))) num_elem:32;\n+  } GTY ((desc (\"GET_CODE (&%0)\"))) u2;\n+\n   /* The first element of the operands of this rtx.\n      The number of operands and their types are controlled\n      by the `code' field, according to rtl.def.  */\n@@ -343,6 +366,7 @@ struct GTY((chain_next (\"RTX_NEXT (&%h)\"),\n     struct block_symbol block_sym;\n     struct real_value rv;\n     struct fixed_value fv;\n+    struct hwivec_def hwiv;\n   } GTY ((special (\"rtx_def\"), desc (\"GET_CODE (&%0)\"))) u;\n };\n \n@@ -398,12 +422,38 @@ struct GTY((variable_size)) rtvec_def {\n /* Predicate yielding nonzero iff X is an rtx for a memory location.  */\n #define MEM_P(X) (GET_CODE (X) == MEM)\n \n+#if TARGET_SUPPORTS_WIDE_INT\n+\n+/* Match CONST_*s that can represent compile-time constant integers.  */\n+#define CASE_CONST_SCALAR_INT \\\n+   case CONST_INT: \\\n+   case CONST_WIDE_INT\n+\n+/* Match CONST_*s for which pointer equality corresponds to value\n+   equality.  */\n+#define CASE_CONST_UNIQUE \\\n+   case CONST_INT: \\\n+   case CONST_WIDE_INT: \\\n+   case CONST_DOUBLE: \\\n+   case CONST_FIXED\n+\n+/* Match all CONST_* rtxes.  */\n+#define CASE_CONST_ANY \\\n+   case CONST_INT: \\\n+   case CONST_WIDE_INT: \\\n+   case CONST_DOUBLE: \\\n+   case CONST_FIXED: \\\n+   case CONST_VECTOR\n+\n+#else\n+\n /* Match CONST_*s that can represent compile-time constant integers.  */\n #define CASE_CONST_SCALAR_INT \\\n    case CONST_INT: \\\n    case CONST_DOUBLE\n \n-/* Match CONST_*s for which pointer equality corresponds to value equality.  */\n+/* Match CONST_*s for which pointer equality corresponds to value\n+   equality.  */\n #define CASE_CONST_UNIQUE \\\n    case CONST_INT: \\\n    case CONST_DOUBLE: \\\n@@ -415,10 +465,14 @@ struct GTY((variable_size)) rtvec_def {\n    case CONST_DOUBLE: \\\n    case CONST_FIXED: \\\n    case CONST_VECTOR\n+#endif\n \n /* Predicate yielding nonzero iff X is an rtx for a constant integer.  */\n #define CONST_INT_P(X) (GET_CODE (X) == CONST_INT)\n \n+/* Predicate yielding nonzero iff X is an rtx for a constant integer.  */\n+#define CONST_WIDE_INT_P(X) (GET_CODE (X) == CONST_WIDE_INT)\n+\n /* Predicate yielding nonzero iff X is an rtx for a constant fixed-point.  */\n #define CONST_FIXED_P(X) (GET_CODE (X) == CONST_FIXED)\n \n@@ -431,8 +485,13 @@ struct GTY((variable_size)) rtvec_def {\n   (GET_CODE (X) == CONST_DOUBLE && GET_MODE (X) == VOIDmode)\n \n /* Predicate yielding true iff X is an rtx for a integer const.  */\n+#if TARGET_SUPPORTS_WIDE_INT\n+#define CONST_SCALAR_INT_P(X) \\\n+  (CONST_INT_P (X) || CONST_WIDE_INT_P (X))\n+#else\n #define CONST_SCALAR_INT_P(X) \\\n   (CONST_INT_P (X) || CONST_DOUBLE_AS_INT_P (X))\n+#endif\n \n /* Predicate yielding true iff X is an rtx for a double-int.  */\n #define CONST_DOUBLE_AS_FLOAT_P(X) \\\n@@ -593,6 +652,15 @@ struct GTY((variable_size)) rtvec_def {\n \t\t\t       __FUNCTION__);\t\t\t\t\\\n      &_rtx->u.hwint[_n]; }))\n \n+#define CWI_ELT(RTX, I) __extension__\t\t\t\t\t\\\n+(*({ __typeof (RTX) const _cwi = (RTX);\t\t\t\t\t\\\n+     int _max = CWI_GET_NUM_ELEM (_cwi);\t\t\t\t\\\n+     const int _i = (I);\t\t\t\t\t\t\\\n+     if (_i < 0 || _i >= _max)\t\t\t\t\t\t\\\n+       cwi_check_failed_bounds (_cwi, _i, __FILE__, __LINE__,\t\t\\\n+\t\t\t\t__FUNCTION__);\t\t\t\t\\\n+     &_cwi->u.hwiv.elem[_i]; }))\n+\n #define XCWINT(RTX, N, C) __extension__\t\t\t\t\t\\\n (*({ __typeof (RTX) const _rtx = (RTX);\t\t\t\t\t\\\n      if (GET_CODE (_rtx) != (C))\t\t\t\t\t\\\n@@ -629,6 +697,11 @@ struct GTY((variable_size)) rtvec_def {\n \t\t\t\t    __FUNCTION__);\t\t\t\\\n    &_symbol->u.block_sym; })\n \n+#define HWIVEC_CHECK(RTX,C) __extension__\t\t\t\t\\\n+({ __typeof (RTX) const _symbol = (RTX);\t\t\t\t\\\n+   RTL_CHECKC1 (_symbol, 0, C);\t\t\t\t\t\t\\\n+   &_symbol->u.hwiv; })\n+\n extern void rtl_check_failed_bounds (const_rtx, int, const char *, int,\n \t\t\t\t     const char *)\n     ATTRIBUTE_NORETURN;\n@@ -649,6 +722,9 @@ extern void rtl_check_failed_code_mode (const_rtx, enum rtx_code, enum machine_m\n     ATTRIBUTE_NORETURN;\n extern void rtl_check_failed_block_symbol (const char *, int, const char *)\n     ATTRIBUTE_NORETURN;\n+extern void cwi_check_failed_bounds (const_rtx, int, const char *, int,\n+\t\t\t\t     const char *)\n+    ATTRIBUTE_NORETURN;\n extern void rtvec_check_failed_bounds (const_rtvec, int, const char *, int,\n \t\t\t\t       const char *)\n     ATTRIBUTE_NORETURN;\n@@ -661,12 +737,14 @@ extern void rtvec_check_failed_bounds (const_rtvec, int, const char *, int,\n #define RTL_CHECKC2(RTX, N, C1, C2) ((RTX)->u.fld[N])\n #define RTVEC_ELT(RTVEC, I)\t    ((RTVEC)->elem[I])\n #define XWINT(RTX, N)\t\t    ((RTX)->u.hwint[N])\n+#define CWI_ELT(RTX, I)\t\t    ((RTX)->u.hwiv.elem[I])\n #define XCWINT(RTX, N, C)\t    ((RTX)->u.hwint[N])\n #define XCMWINT(RTX, N, C, M)\t    ((RTX)->u.hwint[N])\n #define XCNMWINT(RTX, N, C, M)\t    ((RTX)->u.hwint[N])\n #define XCNMPRV(RTX, C, M)\t    (&(RTX)->u.rv)\n #define XCNMPFV(RTX, C, M)\t    (&(RTX)->u.fv)\n #define BLOCK_SYMBOL_CHECK(RTX)\t    (&(RTX)->u.block_sym)\n+#define HWIVEC_CHECK(RTX,C)\t    (&(RTX)->u.hwiv)\n \n #endif\n \n@@ -1153,9 +1231,19 @@ rhs_regno (const_rtx x)\n #define INTVAL(RTX) XCWINT (RTX, 0, CONST_INT)\n #define UINTVAL(RTX) ((unsigned HOST_WIDE_INT) INTVAL (RTX))\n \n+/* For a CONST_WIDE_INT, CONST_WIDE_INT_NUNITS is the number of\n+   elements actually needed to represent the constant.\n+   CONST_WIDE_INT_ELT gets one of the elements.  0 is the least\n+   significant HOST_WIDE_INT.  */\n+#define CONST_WIDE_INT_VEC(RTX) HWIVEC_CHECK (RTX, CONST_WIDE_INT)\n+#define CONST_WIDE_INT_NUNITS(RTX) CWI_GET_NUM_ELEM (RTX)\n+#define CONST_WIDE_INT_ELT(RTX, N) CWI_ELT (RTX, N)\n+\n /* For a CONST_DOUBLE:\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n    For a VOIDmode, there are two integers CONST_DOUBLE_LOW is the\n      low-order word and ..._HIGH the high-order.\n+#endif\n    For a float, there is a REAL_VALUE_TYPE structure, and\n      CONST_DOUBLE_REAL_VALUE(r) is a pointer to it.  */\n #define CONST_DOUBLE_LOW(r) XCMWINT (r, 0, CONST_DOUBLE, VOIDmode)\n@@ -1310,6 +1398,94 @@ struct address_info {\n   bool autoinc_p;\n };\n \n+/* This is used to bundle an rtx and a mode together so that the pair\n+   can be used with the wi:: routines.  If we ever put modes into rtx\n+   integer constants, this should go away and then just pass an rtx in.  */\n+typedef std::pair <rtx, enum machine_mode> rtx_mode_t;\n+\n+namespace wi\n+{\n+  template <>\n+  struct int_traits <rtx_mode_t>\n+  {\n+    static const enum precision_type precision_type = VAR_PRECISION;\n+    static const bool host_dependent_precision = false;\n+    /* This ought to be true, except for the special case that BImode\n+       is canonicalized to STORE_FLAG_VALUE, which might be 1.  */\n+    static const bool is_sign_extended = false;\n+    static unsigned int get_precision (const rtx_mode_t &);\n+    static wi::storage_ref decompose (HOST_WIDE_INT *, unsigned int,\n+\t\t\t\t      const rtx_mode_t &);\n+  };\n+}\n+\n+inline unsigned int\n+wi::int_traits <rtx_mode_t>::get_precision (const rtx_mode_t &x)\n+{\n+  return GET_MODE_PRECISION (x.second);\n+}\n+\n+inline wi::storage_ref\n+wi::int_traits <rtx_mode_t>::decompose (HOST_WIDE_INT *,\n+\t\t\t\t\tunsigned int precision,\n+\t\t\t\t\tconst rtx_mode_t &x)\n+{\n+  gcc_checking_assert (precision == get_precision (x));\n+  switch (GET_CODE (x.first))\n+    {\n+    case CONST_INT:\n+      if (precision < HOST_BITS_PER_WIDE_INT)\n+\t/* Nonzero BImodes are stored as STORE_FLAG_VALUE, which on many\n+\t   targets is 1 rather than -1.  */\n+\tgcc_checking_assert (INTVAL (x.first)\n+\t\t\t     == sext_hwi (INTVAL (x.first), precision)\n+\t\t\t     || (x.second == BImode && INTVAL (x.first) == 1));\n+\n+      return wi::storage_ref (&INTVAL (x.first), 1, precision);\n+\n+    case CONST_WIDE_INT:\n+      return wi::storage_ref (&CONST_WIDE_INT_ELT (x.first, 0),\n+\t\t\t      CONST_WIDE_INT_NUNITS (x.first), precision);\n+\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n+    case CONST_DOUBLE:\n+      return wi::storage_ref (&CONST_DOUBLE_LOW (x.first), 2, precision);\n+#endif\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+namespace wi\n+{\n+  hwi_with_prec shwi (HOST_WIDE_INT, enum machine_mode mode);\n+  wide_int min_value (enum machine_mode, signop);\n+  wide_int max_value (enum machine_mode, signop);\n+}\n+\n+inline wi::hwi_with_prec\n+wi::shwi (HOST_WIDE_INT val, enum machine_mode mode)\n+{\n+  return shwi (val, GET_MODE_PRECISION (mode));\n+}\n+\n+/* Produce the smallest number that is represented in MODE.  The precision\n+   is taken from MODE and the sign from SGN.  */\n+inline wide_int\n+wi::min_value (enum machine_mode mode, signop sgn)\n+{\n+  return min_value (GET_MODE_PRECISION (mode), sgn);\n+}\n+\n+/* Produce the largest number that is represented in MODE.  The precision\n+   is taken from MODE and the sign from SGN.  */\n+inline wide_int\n+wi::max_value (enum machine_mode mode, signop sgn)\n+{\n+  return max_value (GET_MODE_PRECISION (mode), sgn);\n+}\n+\n extern void init_rtlanal (void);\n extern int rtx_cost (rtx, enum rtx_code, int, bool);\n extern int address_cost (rtx, enum machine_mode, addr_space_t, bool);\n@@ -1765,6 +1941,12 @@ extern rtx plus_constant (enum machine_mode, rtx, HOST_WIDE_INT);\n /* In rtl.c */\n extern rtx rtx_alloc_stat (RTX_CODE MEM_STAT_DECL);\n #define rtx_alloc(c) rtx_alloc_stat (c MEM_STAT_INFO)\n+extern rtx rtx_alloc_stat_v (RTX_CODE MEM_STAT_DECL, int);\n+#define rtx_alloc_v(c, SZ) rtx_alloc_stat_v (c MEM_STAT_INFO, SZ)\n+#define const_wide_int_alloc(NWORDS)\t\t\t\t\\\n+  rtx_alloc_v (CONST_WIDE_INT,\t\t\t\t\t\\\n+\t       (sizeof (struct hwivec_def)\t\t\t\\\n+\t\t+ ((NWORDS)-1) * sizeof (HOST_WIDE_INT)))\t\\\n \n extern rtvec rtvec_alloc (int);\n extern rtvec shallow_copy_rtvec (rtvec);\n@@ -1821,10 +2003,17 @@ extern void start_sequence (void);\n extern void push_to_sequence (rtx);\n extern void push_to_sequence2 (rtx, rtx);\n extern void end_sequence (void);\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n extern double_int rtx_to_double_int (const_rtx);\n-extern rtx immed_double_int_const (double_int, enum machine_mode);\n+#endif\n+extern void cwi_output_hex (FILE *, const_rtx);\n+#ifndef GENERATOR_FILE\n+extern rtx immed_wide_int_const (const wide_int_ref &, enum machine_mode);\n+#endif\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n extern rtx immed_double_const (HOST_WIDE_INT, HOST_WIDE_INT,\n \t\t\t       enum machine_mode);\n+#endif\n \n /* In loop-iv.c  */\n "}, {"sha": "82cfc1bf70bafbcbfbf969ddba8d38e6052f56e4", "filename": "gcc/rtlanal.c", "status": "modified", "additions": 24, "deletions": 1, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtlanal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Frtlanal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlanal.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -3173,6 +3173,8 @@ commutative_operand_precedence (rtx op)\n   /* Constants always come the second operand.  Prefer \"nice\" constants.  */\n   if (code == CONST_INT)\n     return -8;\n+  if (code == CONST_WIDE_INT)\n+    return -8;\n   if (code == CONST_DOUBLE)\n     return -7;\n   if (code == CONST_FIXED)\n@@ -3185,6 +3187,8 @@ commutative_operand_precedence (rtx op)\n     case RTX_CONST_OBJ:\n       if (code == CONST_INT)\n         return -6;\n+      if (code == CONST_WIDE_INT)\n+        return -6;\n       if (code == CONST_DOUBLE)\n         return -5;\n       if (code == CONST_FIXED)\n@@ -5382,7 +5386,10 @@ get_address_mode (rtx mem)\n /* Split up a CONST_DOUBLE or integer constant rtx\n    into two rtx's for single words,\n    storing in *FIRST the word that comes first in memory in the target\n-   and in *SECOND the other.  */\n+   and in *SECOND the other.\n+\n+   TODO: This function needs to be rewritten to work on any size\n+   integer.  */\n \n void\n split_double (rtx value, rtx *first, rtx *second)\n@@ -5459,6 +5466,22 @@ split_double (rtx value, rtx *first, rtx *second)\n \t    }\n \t}\n     }\n+  else if (GET_CODE (value) == CONST_WIDE_INT)\n+    {\n+      /* All of this is scary code and needs to be converted to\n+\t properly work with any size integer.  */\n+      gcc_assert (CONST_WIDE_INT_NUNITS (value) == 2);\n+      if (WORDS_BIG_ENDIAN)\n+\t{\n+\t  *first = GEN_INT (CONST_WIDE_INT_ELT (value, 1));\n+\t  *second = GEN_INT (CONST_WIDE_INT_ELT (value, 0));\n+\t}\n+      else\n+\t{\n+\t  *first = GEN_INT (CONST_WIDE_INT_ELT (value, 0));\n+\t  *second = GEN_INT (CONST_WIDE_INT_ELT (value, 1));\n+\t}\n+    }\n   else if (!CONST_DOUBLE_P (value))\n     {\n       if (WORDS_BIG_ENDIAN)"}, {"sha": "6f89e084b665085621c83d0444fa51067e6ac57b", "filename": "gcc/sched-vis.c", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsched-vis.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsched-vis.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-vis.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -428,6 +428,23 @@ print_value (pretty_printer *pp, const_rtx x, int verbose)\n       pp_scalar (pp, HOST_WIDE_INT_PRINT_HEX,\n \t\t (unsigned HOST_WIDE_INT) INTVAL (x));\n       break;\n+\n+    case CONST_WIDE_INT:\n+      {\n+\tconst char *sep = \"<\";\n+\tint i;\n+\tfor (i = CONST_WIDE_INT_NUNITS (x) - 1; i >= 0; i--)\n+\t  {\n+\t    pp_string (pp, sep);\n+\t    sep = \",\";\n+\t    sprintf (tmp, HOST_WIDE_INT_PRINT_HEX,\n+\t\t     (unsigned HOST_WIDE_INT) CONST_WIDE_INT_ELT (x, i));\n+\t    pp_string (pp, tmp);\n+\t  }\n+        pp_greater (pp);\n+      }\n+      break;\n+\n     case CONST_DOUBLE:\n       if (FLOAT_MODE_P (GET_MODE (x)))\n \t{"}, {"sha": "868083b1a02d84249b5296f643cf413b6c0d4a9a", "filename": "gcc/sel-sched-ir.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsel-sched-ir.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsel-sched-ir.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsel-sched-ir.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1141,10 +1141,10 @@ lhs_and_rhs_separable_p (rtx lhs, rtx rhs)\n   if (lhs == NULL || rhs == NULL)\n     return false;\n \n-  /* Do not schedule CONST, CONST_INT and CONST_DOUBLE etc as rhs: no point\n-     to use reg, if const can be used.  Moreover, scheduling const as rhs may\n-     lead to mode mismatch cause consts don't have modes but they could be\n-     merged from branches where the same const used in different modes.  */\n+  /* Do not schedule constants as rhs: no point to use reg, if const\n+     can be used.  Moreover, scheduling const as rhs may lead to mode\n+     mismatch cause consts don't have modes but they could be merged\n+     from branches where the same const used in different modes.  */\n   if (CONSTANT_P (rhs))\n     return false;\n "}, {"sha": "05dac902df5c79964a550e6f43941ca32b221260", "filename": "gcc/signop.h", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsignop.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsignop.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsignop.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -0,0 +1,35 @@\n+/* Operations with SIGNED and UNSIGNED.  -*- C++ -*-\n+   Copyright (C) 2012-2013 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it\n+under the terms of the GNU General Public License as published by the\n+Free Software Foundation; either version 3, or (at your option) any\n+later version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT\n+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef SIGNOP_H\n+#define SIGNOP_H\n+\n+/* This type is used for the large number of functions that produce\n+   different results depending on if the operands are signed types or\n+   unsigned types.  The signedness of a tree type can be found by\n+   using the TYPE_SIGN macro.  */\n+\n+enum signop_e {\n+  SIGNED,\n+  UNSIGNED\n+};\n+\n+typedef enum signop_e signop;\n+\n+#endif"}, {"sha": "7fb1c6db63d270b767e59bd2002492b58e9e8e6d", "filename": "gcc/simplify-rtx.c", "status": "modified", "additions": 268, "deletions": 695, "changes": 963, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -87,15 +87,32 @@ mode_signbit_p (enum machine_mode mode, const_rtx x)\n   if (width <= HOST_BITS_PER_WIDE_INT\n       && CONST_INT_P (x))\n     val = INTVAL (x);\n+#if TARGET_SUPPORTS_WIDE_INT\n+  else if (CONST_WIDE_INT_P (x))\n+    {\n+      unsigned int i;\n+      unsigned int elts = CONST_WIDE_INT_NUNITS (x);\n+      if (elts != (width + HOST_BITS_PER_WIDE_INT - 1) / HOST_BITS_PER_WIDE_INT)\n+\treturn false;\n+      for (i = 0; i < elts - 1; i++)\n+\tif (CONST_WIDE_INT_ELT (x, i) != 0)\n+\t  return false;\n+      val = CONST_WIDE_INT_ELT (x, elts - 1);\n+      width %= HOST_BITS_PER_WIDE_INT;\n+      if (width == 0)\n+\twidth = HOST_BITS_PER_WIDE_INT;\n+    }\n+#else\n   else if (width <= HOST_BITS_PER_DOUBLE_INT\n \t   && CONST_DOUBLE_AS_INT_P (x)\n \t   && CONST_DOUBLE_LOW (x) == 0)\n     {\n       val = CONST_DOUBLE_HIGH (x);\n       width -= HOST_BITS_PER_WIDE_INT;\n     }\n+#endif\n   else\n-    /* FIXME: We don't yet have a representation for wider modes.  */\n+    /* X is not an integer constant.  */\n     return false;\n \n   if (width < HOST_BITS_PER_WIDE_INT)\n@@ -1532,7 +1549,6 @@ simplify_const_unary_operation (enum rtx_code code, enum machine_mode mode,\n \t\t\t\trtx op, enum machine_mode op_mode)\n {\n   unsigned int width = GET_MODE_PRECISION (mode);\n-  unsigned int op_width = GET_MODE_PRECISION (op_mode);\n \n   if (code == VEC_DUPLICATE)\n     {\n@@ -1600,336 +1616,123 @@ simplify_const_unary_operation (enum rtx_code code, enum machine_mode mode,\n \n   if (code == FLOAT && CONST_SCALAR_INT_P (op))\n     {\n-      HOST_WIDE_INT hv, lv;\n       REAL_VALUE_TYPE d;\n \n-      if (CONST_INT_P (op))\n-\tlv = INTVAL (op), hv = HWI_SIGN_EXTEND (lv);\n-      else\n-\tlv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);\n+      if (op_mode == VOIDmode)\n+\t{\n+\t  /* CONST_INT have VOIDmode as the mode.  We assume that all\n+\t     the bits of the constant are significant, though, this is\n+\t     a dangerous assumption as many times CONST_INTs are\n+\t     created and used with garbage in the bits outside of the\n+\t     precision of the implied mode of the const_int.  */\n+\t  op_mode = MAX_MODE_INT;\n+\t}\n \n-      REAL_VALUE_FROM_INT (d, lv, hv, mode);\n+      real_from_integer (&d, mode, std::make_pair (op, op_mode), SIGNED);\n       d = real_value_truncate (mode, d);\n       return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n     }\n   else if (code == UNSIGNED_FLOAT && CONST_SCALAR_INT_P (op))\n     {\n-      HOST_WIDE_INT hv, lv;\n       REAL_VALUE_TYPE d;\n \n-      if (CONST_INT_P (op))\n-\tlv = INTVAL (op), hv = HWI_SIGN_EXTEND (lv);\n-      else\n-\tlv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);\n-\n-      if (op_mode == VOIDmode\n-\t  || GET_MODE_PRECISION (op_mode) > HOST_BITS_PER_DOUBLE_INT)\n-\t/* We should never get a negative number.  */\n-\tgcc_assert (hv >= 0);\n-      else if (GET_MODE_PRECISION (op_mode) <= HOST_BITS_PER_WIDE_INT)\n-\thv = 0, lv &= GET_MODE_MASK (op_mode);\n+      if (op_mode == VOIDmode)\n+\t{\n+\t  /* CONST_INT have VOIDmode as the mode.  We assume that all\n+\t     the bits of the constant are significant, though, this is\n+\t     a dangerous assumption as many times CONST_INTs are\n+\t     created and used with garbage in the bits outside of the\n+\t     precision of the implied mode of the const_int.  */\n+\t  op_mode = MAX_MODE_INT;\n+\t}\n \n-      REAL_VALUE_FROM_UNSIGNED_INT (d, lv, hv, mode);\n+      real_from_integer (&d, mode, std::make_pair (op, op_mode), UNSIGNED);\n       d = real_value_truncate (mode, d);\n       return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n     }\n \n-  if (CONST_INT_P (op)\n-      && width <= HOST_BITS_PER_WIDE_INT && width > 0)\n+  if (CONST_SCALAR_INT_P (op) && width > 0)\n     {\n-      HOST_WIDE_INT arg0 = INTVAL (op);\n-      HOST_WIDE_INT val;\n+      wide_int result;\n+      enum machine_mode imode = op_mode == VOIDmode ? mode : op_mode;\n+      rtx_mode_t op0 = std::make_pair (op, imode);\n+      int int_value;\n+\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n+      /* This assert keeps the simplification from producing a result\n+\t that cannot be represented in a CONST_DOUBLE but a lot of\n+\t upstream callers expect that this function never fails to\n+\t simplify something and so you if you added this to the test\n+\t above the code would die later anyway.  If this assert\n+\t happens, you just need to make the port support wide int.  */\n+      gcc_assert (width <= HOST_BITS_PER_DOUBLE_INT);\n+#endif\n \n       switch (code)\n \t{\n \tcase NOT:\n-\t  val = ~ arg0;\n+\t  result = wi::bit_not (op0);\n \t  break;\n \n \tcase NEG:\n-\t  val = - (unsigned HOST_WIDE_INT) arg0;\n+\t  result = wi::neg (op0);\n \t  break;\n \n \tcase ABS:\n-\t  val = (arg0 >= 0 ? arg0 : - arg0);\n+\t  result = wi::abs (op0);\n \t  break;\n \n \tcase FFS:\n-\t  arg0 &= GET_MODE_MASK (mode);\n-\t  val = ffs_hwi (arg0);\n+\t  result = wi::shwi (wi::ffs (op0), mode);\n \t  break;\n \n \tcase CLZ:\n-\t  arg0 &= GET_MODE_MASK (mode);\n-\t  if (arg0 == 0 && CLZ_DEFINED_VALUE_AT_ZERO (mode, val))\n-\t    ;\n-\t  else\n-\t    val = GET_MODE_PRECISION (mode) - floor_log2 (arg0) - 1;\n+\t  if (wi::ne_p (op0, 0))\n+\t    int_value = wi::clz (op0);\n+\t  else if (! CLZ_DEFINED_VALUE_AT_ZERO (mode, int_value))\n+\t    int_value = GET_MODE_PRECISION (mode);\n+\t  result = wi::shwi (int_value, mode);\n \t  break;\n \n \tcase CLRSB:\n-\t  arg0 &= GET_MODE_MASK (mode);\n-\t  if (arg0 == 0)\n-\t    val = GET_MODE_PRECISION (mode) - 1;\n-\t  else if (arg0 >= 0)\n-\t    val = GET_MODE_PRECISION (mode) - floor_log2 (arg0) - 2;\n-\t  else if (arg0 < 0)\n-\t    val = GET_MODE_PRECISION (mode) - floor_log2 (~arg0) - 2;\n-\t  break;\n-\n-\tcase CTZ:\n-\t  arg0 &= GET_MODE_MASK (mode);\n-\t  if (arg0 == 0)\n-\t    {\n-\t      /* Even if the value at zero is undefined, we have to come\n-\t\t up with some replacement.  Seems good enough.  */\n-\t      if (! CTZ_DEFINED_VALUE_AT_ZERO (mode, val))\n-\t\tval = GET_MODE_PRECISION (mode);\n-\t    }\n-\t  else\n-\t    val = ctz_hwi (arg0);\n-\t  break;\n-\n-\tcase POPCOUNT:\n-\t  arg0 &= GET_MODE_MASK (mode);\n-\t  val = 0;\n-\t  while (arg0)\n-\t    val++, arg0 &= arg0 - 1;\n-\t  break;\n-\n-\tcase PARITY:\n-\t  arg0 &= GET_MODE_MASK (mode);\n-\t  val = 0;\n-\t  while (arg0)\n-\t    val++, arg0 &= arg0 - 1;\n-\t  val &= 1;\n-\t  break;\n-\n-\tcase BSWAP:\n-\t  {\n-\t    unsigned int s;\n-\n-\t    val = 0;\n-\t    for (s = 0; s < width; s += 8)\n-\t      {\n-\t\tunsigned int d = width - s - 8;\n-\t\tunsigned HOST_WIDE_INT byte;\n-\t\tbyte = (arg0 >> s) & 0xff;\n-\t\tval |= byte << d;\n-\t      }\n-\t  }\n-\t  break;\n-\n-\tcase TRUNCATE:\n-\t  val = arg0;\n-\t  break;\n-\n-\tcase ZERO_EXTEND:\n-\t  /* When zero-extending a CONST_INT, we need to know its\n-             original mode.  */\n-\t  gcc_assert (op_mode != VOIDmode);\n-\t  if (op_width == HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      /* If we were really extending the mode,\n-\t\t we would have to distinguish between zero-extension\n-\t\t and sign-extension.  */\n-\t      gcc_assert (width == op_width);\n-\t      val = arg0;\n-\t    }\n-\t  else if (GET_MODE_BITSIZE (op_mode) < HOST_BITS_PER_WIDE_INT)\n-\t    val = arg0 & GET_MODE_MASK (op_mode);\n-\t  else\n-\t    return 0;\n-\t  break;\n-\n-\tcase SIGN_EXTEND:\n-\t  if (op_mode == VOIDmode)\n-\t    op_mode = mode;\n-\t  op_width = GET_MODE_PRECISION (op_mode);\n-\t  if (op_width == HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      /* If we were really extending the mode,\n-\t\t we would have to distinguish between zero-extension\n-\t\t and sign-extension.  */\n-\t      gcc_assert (width == op_width);\n-\t      val = arg0;\n-\t    }\n-\t  else if (op_width < HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      val = arg0 & GET_MODE_MASK (op_mode);\n-\t      if (val_signbit_known_set_p (op_mode, val))\n-\t\tval |= ~GET_MODE_MASK (op_mode);\n-\t    }\n-\t  else\n-\t    return 0;\n-\t  break;\n-\n-\tcase SQRT:\n-\tcase FLOAT_EXTEND:\n-\tcase FLOAT_TRUNCATE:\n-\tcase SS_TRUNCATE:\n-\tcase US_TRUNCATE:\n-\tcase SS_NEG:\n-\tcase US_NEG:\n-\tcase SS_ABS:\n-\t  return 0;\n-\n-\tdefault:\n-\t  gcc_unreachable ();\n-\t}\n-\n-      return gen_int_mode (val, mode);\n-    }\n-\n-  /* We can do some operations on integer CONST_DOUBLEs.  Also allow\n-     for a DImode operation on a CONST_INT.  */\n-  else if (width <= HOST_BITS_PER_DOUBLE_INT\n-\t   && (CONST_DOUBLE_AS_INT_P (op) || CONST_INT_P (op)))\n-    {\n-      double_int first, value;\n-\n-      if (CONST_DOUBLE_AS_INT_P (op))\n-\tfirst = double_int::from_pair (CONST_DOUBLE_HIGH (op),\n-\t\t\t\t       CONST_DOUBLE_LOW (op));\n-      else\n-\tfirst = double_int::from_shwi (INTVAL (op));\n-\n-      switch (code)\n-\t{\n-\tcase NOT:\n-\t  value = ~first;\n-\t  break;\n-\n-\tcase NEG:\n-\t  value = -first;\n-\t  break;\n-\n-\tcase ABS:\n-\t  if (first.is_negative ())\n-\t    value = -first;\n-\t  else\n-\t    value = first;\n-\t  break;\n-\n-\tcase FFS:\n-\t  value.high = 0;\n-\t  if (first.low != 0)\n-\t    value.low = ffs_hwi (first.low);\n-\t  else if (first.high != 0)\n-\t    value.low = HOST_BITS_PER_WIDE_INT + ffs_hwi (first.high);\n-\t  else\n-\t    value.low = 0;\n-\t  break;\n-\n-\tcase CLZ:\n-\t  value.high = 0;\n-\t  if (first.high != 0)\n-\t    value.low = GET_MODE_PRECISION (mode) - floor_log2 (first.high) - 1\n-\t              - HOST_BITS_PER_WIDE_INT;\n-\t  else if (first.low != 0)\n-\t    value.low = GET_MODE_PRECISION (mode) - floor_log2 (first.low) - 1;\n-\t  else if (! CLZ_DEFINED_VALUE_AT_ZERO (mode, value.low))\n-\t    value.low = GET_MODE_PRECISION (mode);\n+\t  result = wi::shwi (wi::clrsb (op0), mode);\n \t  break;\n \n \tcase CTZ:\n-\t  value.high = 0;\n-\t  if (first.low != 0)\n-\t    value.low = ctz_hwi (first.low);\n-\t  else if (first.high != 0)\n-\t    value.low = HOST_BITS_PER_WIDE_INT + ctz_hwi (first.high);\n-\t  else if (! CTZ_DEFINED_VALUE_AT_ZERO (mode, value.low))\n-\t    value.low = GET_MODE_PRECISION (mode);\n+\t  if (wi::ne_p (op0, 0))\n+\t    int_value = wi::ctz (op0);\n+\t  else if (! CTZ_DEFINED_VALUE_AT_ZERO (mode, int_value))\n+\t    int_value = GET_MODE_PRECISION (mode);\n+\t  result = wi::shwi (int_value, mode);\n \t  break;\n \n \tcase POPCOUNT:\n-\t  value = double_int_zero;\n-\t  while (first.low)\n-\t    {\n-\t      value.low++;\n-\t      first.low &= first.low - 1;\n-\t    }\n-\t  while (first.high)\n-\t    {\n-\t      value.low++;\n-\t      first.high &= first.high - 1;\n-\t    }\n+\t  result = wi::shwi (wi::popcount (op0), mode);\n \t  break;\n \n \tcase PARITY:\n-\t  value = double_int_zero;\n-\t  while (first.low)\n-\t    {\n-\t      value.low++;\n-\t      first.low &= first.low - 1;\n-\t    }\n-\t  while (first.high)\n-\t    {\n-\t      value.low++;\n-\t      first.high &= first.high - 1;\n-\t    }\n-\t  value.low &= 1;\n+\t  result = wi::shwi (wi::parity (op0), mode);\n \t  break;\n \n \tcase BSWAP:\n-\t  {\n-\t    unsigned int s;\n-\n-\t    value = double_int_zero;\n-\t    for (s = 0; s < width; s += 8)\n-\t      {\n-\t\tunsigned int d = width - s - 8;\n-\t\tunsigned HOST_WIDE_INT byte;\n-\n-\t\tif (s < HOST_BITS_PER_WIDE_INT)\n-\t\t  byte = (first.low >> s) & 0xff;\n-\t\telse\n-\t\t  byte = (first.high >> (s - HOST_BITS_PER_WIDE_INT)) & 0xff;\n-\n-\t\tif (d < HOST_BITS_PER_WIDE_INT)\n-\t\t  value.low |= byte << d;\n-\t\telse\n-\t\t  value.high |= byte << (d - HOST_BITS_PER_WIDE_INT);\n-\t      }\n-\t  }\n+\t  result = wide_int (op0).bswap ();\n \t  break;\n \n \tcase TRUNCATE:\n-\t  /* This is just a change-of-mode, so do nothing.  */\n-\t  value = first;\n-\t  break;\n-\n \tcase ZERO_EXTEND:\n-\t  gcc_assert (op_mode != VOIDmode);\n-\n-\t  if (op_width > HOST_BITS_PER_WIDE_INT)\n-\t    return 0;\n-\n-\t  value = double_int::from_uhwi (first.low & GET_MODE_MASK (op_mode));\n+\t  result = wide_int::from (op0, width, UNSIGNED);\n \t  break;\n \n \tcase SIGN_EXTEND:\n-\t  if (op_mode == VOIDmode\n-\t      || op_width > HOST_BITS_PER_WIDE_INT)\n-\t    return 0;\n-\t  else\n-\t    {\n-\t      value.low = first.low & GET_MODE_MASK (op_mode);\n-\t      if (val_signbit_known_set_p (op_mode, value.low))\n-\t\tvalue.low |= ~GET_MODE_MASK (op_mode);\n-\n-\t      value.high = HWI_SIGN_EXTEND (value.low);\n-\t    }\n+\t  result = wide_int::from (op0, width, SIGNED);\n \t  break;\n \n \tcase SQRT:\n-\t  return 0;\n-\n \tdefault:\n \t  return 0;\n \t}\n \n-      return immed_double_int_const (value, mode);\n+      return immed_wide_int_const (result, mode);\n     }\n \n   else if (CONST_DOUBLE_AS_FLOAT_P (op) \n@@ -1977,11 +1780,10 @@ simplify_const_unary_operation (enum rtx_code code, enum machine_mode mode,\n \t}\n       return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);\n     }\n-\n   else if (CONST_DOUBLE_AS_FLOAT_P (op)\n \t   && SCALAR_FLOAT_MODE_P (GET_MODE (op))\n \t   && GET_MODE_CLASS (mode) == MODE_INT\n-\t   && width <= HOST_BITS_PER_DOUBLE_INT && width > 0)\n+\t   && width > 0)\n     {\n       /* Although the overflow semantics of RTL's FIX and UNSIGNED_FIX\n \t operators are intentionally left unspecified (to ease implementation\n@@ -1990,92 +1792,51 @@ simplify_const_unary_operation (enum rtx_code code, enum machine_mode mode,\n \n       /* This was formerly used only for non-IEEE float.\n \t eggert@twinsun.com says it is safe for IEEE also.  */\n-      HOST_WIDE_INT xh, xl, th, tl;\n       REAL_VALUE_TYPE x, t;\n       REAL_VALUE_FROM_CONST_DOUBLE (x, op);\n+      wide_int wmax, wmin;\n+      /* This is part of the abi to real_to_integer, but we check\n+\t things before making this call.  */\n+      bool fail;\n+\n       switch (code)\n \t{\n \tcase FIX:\n \t  if (REAL_VALUE_ISNAN (x))\n \t    return const0_rtx;\n \n \t  /* Test against the signed upper bound.  */\n-\t  if (width > HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      th = ((unsigned HOST_WIDE_INT) 1\n-\t\t    << (width - HOST_BITS_PER_WIDE_INT - 1)) - 1;\n-\t      tl = -1;\n-\t    }\n-\t  else\n-\t    {\n-\t      th = 0;\n-\t      tl = ((unsigned HOST_WIDE_INT) 1 << (width - 1)) - 1;\n-\t    }\n-\t  real_from_integer (&t, VOIDmode, tl, th, 0);\n+\t  wmax = wi::max_value (width, SIGNED);\n+\t  real_from_integer (&t, VOIDmode, wmax, SIGNED);\n \t  if (REAL_VALUES_LESS (t, x))\n-\t    {\n-\t      xh = th;\n-\t      xl = tl;\n-\t      break;\n-\t    }\n+\t    return immed_wide_int_const (wmax, mode);\n \n \t  /* Test against the signed lower bound.  */\n-\t  if (width > HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      th = HOST_WIDE_INT_M1U << (width - HOST_BITS_PER_WIDE_INT - 1);\n-\t      tl = 0;\n-\t    }\n-\t  else\n-\t    {\n-\t      th = -1;\n-\t      tl = HOST_WIDE_INT_M1U << (width - 1);\n-\t    }\n-\t  real_from_integer (&t, VOIDmode, tl, th, 0);\n+\t  wmin = wi::min_value (width, SIGNED);\n+\t  real_from_integer (&t, VOIDmode, wmin, SIGNED);\n \t  if (REAL_VALUES_LESS (x, t))\n-\t    {\n-\t      xh = th;\n-\t      xl = tl;\n-\t      break;\n-\t    }\n-\t  REAL_VALUE_TO_INT (&xl, &xh, x);\n+\t    return immed_wide_int_const (wmin, mode);\n+\n+\t  return immed_wide_int_const (real_to_integer (&x, &fail, width), mode);\n \t  break;\n \n \tcase UNSIGNED_FIX:\n \t  if (REAL_VALUE_ISNAN (x) || REAL_VALUE_NEGATIVE (x))\n \t    return const0_rtx;\n \n \t  /* Test against the unsigned upper bound.  */\n-\t  if (width == HOST_BITS_PER_DOUBLE_INT)\n-\t    {\n-\t      th = -1;\n-\t      tl = -1;\n-\t    }\n-\t  else if (width >= HOST_BITS_PER_WIDE_INT)\n-\t    {\n-\t      th = ((unsigned HOST_WIDE_INT) 1\n-\t\t    << (width - HOST_BITS_PER_WIDE_INT)) - 1;\n-\t      tl = -1;\n-\t    }\n-\t  else\n-\t    {\n-\t      th = 0;\n-\t      tl = ((unsigned HOST_WIDE_INT) 1 << width) - 1;\n-\t    }\n-\t  real_from_integer (&t, VOIDmode, tl, th, 1);\n+\t  wmax = wi::max_value (width, UNSIGNED);\n+\t  real_from_integer (&t, VOIDmode, wmax, UNSIGNED);\n \t  if (REAL_VALUES_LESS (t, x))\n-\t    {\n-\t      xh = th;\n-\t      xl = tl;\n-\t      break;\n-\t    }\n+\t    return immed_wide_int_const (wmax, mode);\n \n-\t  REAL_VALUE_TO_INT (&xl, &xh, x);\n+\t  return immed_wide_int_const (real_to_integer (&x, &fail, width),\n+\t\t\t\t       mode);\n \t  break;\n \n \tdefault:\n \t  gcc_unreachable ();\n \t}\n-      return immed_double_const (xl, xh, mode);\n     }\n \n   return NULL_RTX;\n@@ -2264,61 +2025,60 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \n       if (SCALAR_INT_MODE_P (mode))\n \t{\n-\t  double_int coeff0, coeff1;\n \t  rtx lhs = op0, rhs = op1;\n \n-\t  coeff0 = double_int_one;\n-\t  coeff1 = double_int_one;\n+\t  wide_int coeff0 = wi::one (GET_MODE_PRECISION (mode));\n+\t  wide_int coeff1 = wi::one (GET_MODE_PRECISION (mode));\n \n \t  if (GET_CODE (lhs) == NEG)\n \t    {\n-\t      coeff0 = double_int_minus_one;\n+\t      coeff0 = wi::minus_one (GET_MODE_PRECISION (mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == MULT\n-\t\t   && CONST_INT_P (XEXP (lhs, 1)))\n+\t\t   && CONST_SCALAR_INT_P (XEXP (lhs, 1)))\n \t    {\n-\t      coeff0 = double_int::from_shwi (INTVAL (XEXP (lhs, 1)));\n+\t      coeff0 = std::make_pair (XEXP (lhs, 1), mode);\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (lhs, 1))\n                    && INTVAL (XEXP (lhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (lhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t   && INTVAL (XEXP (lhs, 1)) < GET_MODE_PRECISION (mode))\n \t    {\n-\t      coeff0 = double_int_zero.set_bit (INTVAL (XEXP (lhs, 1)));\n+\t      coeff0 = wi::set_bit_in_zero (INTVAL (XEXP (lhs, 1)),\n+\t\t\t\t\t    GET_MODE_PRECISION (mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \n \t  if (GET_CODE (rhs) == NEG)\n \t    {\n-\t      coeff1 = double_int_minus_one;\n+\t      coeff1 = wi::minus_one (GET_MODE_PRECISION (mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == MULT\n \t\t   && CONST_INT_P (XEXP (rhs, 1)))\n \t    {\n-\t      coeff1 = double_int::from_shwi (INTVAL (XEXP (rhs, 1)));\n+\t      coeff1 = std::make_pair (XEXP (rhs, 1), mode);\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (rhs, 1))\n \t\t   && INTVAL (XEXP (rhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (rhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t   && INTVAL (XEXP (rhs, 1)) < GET_MODE_PRECISION (mode))\n \t    {\n-\t      coeff1 = double_int_zero.set_bit (INTVAL (XEXP (rhs, 1)));\n+\t      coeff1 = wi::set_bit_in_zero (INTVAL (XEXP (rhs, 1)),\n+\t\t\t\t\t    GET_MODE_PRECISION (mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \n \t  if (rtx_equal_p (lhs, rhs))\n \t    {\n \t      rtx orig = gen_rtx_PLUS (mode, op0, op1);\n \t      rtx coeff;\n-\t      double_int val;\n \t      bool speed = optimize_function_for_speed_p (cfun);\n \n-\t      val = coeff0 + coeff1;\n-\t      coeff = immed_double_int_const (val, mode);\n+\t      coeff = immed_wide_int_const (coeff0 + coeff1, mode);\n \n \t      tem = simplify_gen_binary (MULT, mode, lhs, coeff);\n \t      return set_src_cost (tem, speed) <= set_src_cost (orig, speed)\n@@ -2440,49 +2200,50 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \n       if (SCALAR_INT_MODE_P (mode))\n \t{\n-\t  double_int coeff0, negcoeff1;\n \t  rtx lhs = op0, rhs = op1;\n \n-\t  coeff0 = double_int_one;\n-\t  negcoeff1 = double_int_minus_one;\n+\t  wide_int coeff0 = wi::one (GET_MODE_PRECISION (mode));\n+\t  wide_int negcoeff1 = wi::minus_one (GET_MODE_PRECISION (mode));\n \n \t  if (GET_CODE (lhs) == NEG)\n \t    {\n-\t      coeff0 = double_int_minus_one;\n+\t      coeff0 = wi::minus_one (GET_MODE_PRECISION (mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == MULT\n-\t\t   && CONST_INT_P (XEXP (lhs, 1)))\n+\t\t   && CONST_SCALAR_INT_P (XEXP (lhs, 1)))\n \t    {\n-\t      coeff0 = double_int::from_shwi (INTVAL (XEXP (lhs, 1)));\n+\t      coeff0 = std::make_pair (XEXP (lhs, 1), mode);\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (lhs, 1))\n \t\t   && INTVAL (XEXP (lhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (lhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t   && INTVAL (XEXP (lhs, 1)) < GET_MODE_PRECISION (mode))\n \t    {\n-\t      coeff0 = double_int_zero.set_bit (INTVAL (XEXP (lhs, 1)));\n+\t      coeff0 = wi::set_bit_in_zero (INTVAL (XEXP (lhs, 1)),\n+\t\t\t\t\t    GET_MODE_PRECISION (mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \n \t  if (GET_CODE (rhs) == NEG)\n \t    {\n-\t      negcoeff1 = double_int_one;\n+\t      negcoeff1 = wi::one (GET_MODE_PRECISION (mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == MULT\n \t\t   && CONST_INT_P (XEXP (rhs, 1)))\n \t    {\n-\t      negcoeff1 = double_int::from_shwi (-INTVAL (XEXP (rhs, 1)));\n+\t      negcoeff1 = wi::neg (std::make_pair (XEXP (rhs, 1), mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (rhs, 1))\n \t\t   && INTVAL (XEXP (rhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (rhs, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t\t   && INTVAL (XEXP (rhs, 1)) < GET_MODE_PRECISION (mode))\n \t    {\n-\t      negcoeff1 = double_int_zero.set_bit (INTVAL (XEXP (rhs, 1)));\n+\t      negcoeff1 = wi::set_bit_in_zero (INTVAL (XEXP (rhs, 1)),\n+\t\t\t\t\t       GET_MODE_PRECISION (mode));\n \t      negcoeff1 = -negcoeff1;\n \t      rhs = XEXP (rhs, 0);\n \t    }\n@@ -2491,11 +2252,9 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t    {\n \t      rtx orig = gen_rtx_MINUS (mode, op0, op1);\n \t      rtx coeff;\n-\t      double_int val;\n \t      bool speed = optimize_function_for_speed_p (cfun);\n \n-\t      val = coeff0 + negcoeff1;\n-\t      coeff = immed_double_int_const (val, mode);\n+\t      coeff = immed_wide_int_const (coeff0 + negcoeff1, mode);\n \n \t      tem = simplify_gen_binary (MULT, mode, lhs, coeff);\n \t      return set_src_cost (tem, speed) <= set_src_cost (orig, speed)\n@@ -2647,26 +2406,13 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t  && trueop1 == CONST1_RTX (mode))\n \treturn op0;\n \n-      /* Convert multiply by constant power of two into shift unless\n-\t we are still generating RTL.  This test is a kludge.  */\n-      if (CONST_INT_P (trueop1)\n-\t  && (val = exact_log2 (UINTVAL (trueop1))) >= 0\n-\t  /* If the mode is larger than the host word size, and the\n-\t     uppermost bit is set, then this isn't a power of two due\n-\t     to implicit sign extension.  */\n-\t  && (width <= HOST_BITS_PER_WIDE_INT\n-\t      || val != HOST_BITS_PER_WIDE_INT - 1))\n-\treturn simplify_gen_binary (ASHIFT, mode, op0, GEN_INT (val));\n-\n-      /* Likewise for multipliers wider than a word.  */\n-      if (CONST_DOUBLE_AS_INT_P (trueop1)\n-\t  && GET_MODE (op0) == mode\n-\t  && CONST_DOUBLE_LOW (trueop1) == 0\n-\t  && (val = exact_log2 (CONST_DOUBLE_HIGH (trueop1))) >= 0\n-\t  && (val < HOST_BITS_PER_DOUBLE_INT - 1\n-\t      || GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_DOUBLE_INT))\n-\treturn simplify_gen_binary (ASHIFT, mode, op0,\n-\t\t\t\t    GEN_INT (val + HOST_BITS_PER_WIDE_INT));\n+      /* Convert multiply by constant power of two into shift.  */\n+      if (CONST_SCALAR_INT_P (trueop1))\n+\t{\n+\t  val = wi::exact_log2 (std::make_pair (trueop1, mode));\n+\t  if (val >= 0)\n+\t    return simplify_gen_binary (ASHIFT, mode, op0, GEN_INT (val));\n+\t}\n \n       /* x*2 is x+x and x*(-1) is -x */\n       if (CONST_DOUBLE_AS_FLOAT_P (trueop1)\n@@ -3770,8 +3516,6 @@ rtx\n simplify_const_binary_operation (enum rtx_code code, enum machine_mode mode,\n \t\t\t\t rtx op0, rtx op1)\n {\n-  HOST_WIDE_INT arg0, arg1, arg0s, arg1s;\n-  HOST_WIDE_INT val;\n   unsigned int width = GET_MODE_PRECISION (mode);\n \n   if (VECTOR_MODE_P (mode)\n@@ -3965,299 +3709,143 @@ simplify_const_binary_operation (enum rtx_code code, enum machine_mode mode,\n \n   /* We can fold some multi-word operations.  */\n   if (GET_MODE_CLASS (mode) == MODE_INT\n-      && width == HOST_BITS_PER_DOUBLE_INT\n-      && (CONST_DOUBLE_AS_INT_P (op0) || CONST_INT_P (op0))\n-      && (CONST_DOUBLE_AS_INT_P (op1) || CONST_INT_P (op1)))\n+      && CONST_SCALAR_INT_P (op0)\n+      && CONST_SCALAR_INT_P (op1))\n     {\n-      double_int o0, o1, res, tmp;\n+      wide_int result;\n       bool overflow;\n-\n-      o0 = rtx_to_double_int (op0);\n-      o1 = rtx_to_double_int (op1);\n-\n+      rtx_mode_t pop0 = std::make_pair (op0, mode);\n+      rtx_mode_t pop1 = std::make_pair (op1, mode);\n+\n+#if TARGET_SUPPORTS_WIDE_INT == 0\n+      /* This assert keeps the simplification from producing a result\n+\t that cannot be represented in a CONST_DOUBLE but a lot of\n+\t upstream callers expect that this function never fails to\n+\t simplify something and so you if you added this to the test\n+\t above the code would die later anyway.  If this assert\n+\t happens, you just need to make the port support wide int.  */\n+      gcc_assert (width <= HOST_BITS_PER_DOUBLE_INT);\n+#endif\n       switch (code)\n \t{\n \tcase MINUS:\n-\t  /* A - B == A + (-B).  */\n-\t  o1 = -o1;\n-\n-\t  /* Fall through....  */\n+\t  result = wi::sub (pop0, pop1);\n+\t  break;\n \n \tcase PLUS:\n-\t  res = o0 + o1;\n+\t  result = wi::add (pop0, pop1);\n \t  break;\n \n \tcase MULT:\n-\t  res = o0 * o1;\n+\t  result = wi::mul (pop0, pop1);\n \t  break;\n \n \tcase DIV:\n-          res = o0.divmod_with_overflow (o1, false, TRUNC_DIV_EXPR,\n-\t\t\t\t\t &tmp, &overflow);\n+\t  result = wi::div_trunc (pop0, pop1, SIGNED, &overflow);\n \t  if (overflow)\n-\t    return 0;\n+\t    return NULL_RTX;\n \t  break;\n \n \tcase MOD:\n-          tmp = o0.divmod_with_overflow (o1, false, TRUNC_DIV_EXPR,\n-\t\t\t\t\t &res, &overflow);\n+\t  result = wi::mod_trunc (pop0, pop1, SIGNED, &overflow);\n \t  if (overflow)\n-\t    return 0;\n+\t    return NULL_RTX;\n \t  break;\n \n \tcase UDIV:\n-          res = o0.divmod_with_overflow (o1, true, TRUNC_DIV_EXPR,\n-\t\t\t\t\t &tmp, &overflow);\n+\t  result = wi::div_trunc (pop0, pop1, UNSIGNED, &overflow);\n \t  if (overflow)\n-\t    return 0;\n+\t    return NULL_RTX;\n \t  break;\n \n \tcase UMOD:\n-          tmp = o0.divmod_with_overflow (o1, true, TRUNC_DIV_EXPR,\n-\t\t\t\t\t &res, &overflow);\n+\t  result = wi::mod_trunc (pop0, pop1, UNSIGNED, &overflow);\n \t  if (overflow)\n-\t    return 0;\n+\t    return NULL_RTX;\n \t  break;\n \n \tcase AND:\n-\t  res = o0 & o1;\n+\t  result = wi::bit_and (pop0, pop1);\n \t  break;\n \n \tcase IOR:\n-\t  res = o0 | o1;\n+\t  result = wi::bit_or (pop0, pop1);\n \t  break;\n \n \tcase XOR:\n-\t  res = o0 ^ o1;\n+\t  result = wi::bit_xor (pop0, pop1);\n \t  break;\n \n \tcase SMIN:\n-\t  res = o0.smin (o1);\n+\t  result = wi::smin (pop0, pop1);\n \t  break;\n \n \tcase SMAX:\n-\t  res = o0.smax (o1);\n+\t  result = wi::smax (pop0, pop1);\n \t  break;\n \n \tcase UMIN:\n-\t  res = o0.umin (o1);\n+\t  result = wi::umin (pop0, pop1);\n \t  break;\n \n \tcase UMAX:\n-\t  res = o0.umax (o1);\n+\t  result = wi::umax (pop0, pop1);\n \t  break;\n \n-\tcase LSHIFTRT:   case ASHIFTRT:\n+\tcase LSHIFTRT:\n+\tcase ASHIFTRT:\n \tcase ASHIFT:\n-\tcase ROTATE:     case ROTATERT:\n \t  {\n-\t    unsigned HOST_WIDE_INT cnt;\n-\n+\t    wide_int wop1 = pop1;\n \t    if (SHIFT_COUNT_TRUNCATED)\n-\t      {\n-\t\to1.high = 0; \n-\t\to1.low &= GET_MODE_PRECISION (mode) - 1;\n-\t      }\n-\n-\t    if (!o1.fits_uhwi ()\n-\t        || o1.to_uhwi () >= GET_MODE_PRECISION (mode))\n-\t      return 0;\n-\n-\t    cnt = o1.to_uhwi ();\n-\t    unsigned short prec = GET_MODE_PRECISION (mode);\n-\n-\t    if (code == LSHIFTRT || code == ASHIFTRT)\n-\t      res = o0.rshift (cnt, prec, code == ASHIFTRT);\n-\t    else if (code == ASHIFT)\n-\t      res = o0.alshift (cnt, prec);\n-\t    else if (code == ROTATE)\n-\t      res = o0.lrotate (cnt, prec);\n-\t    else /* code == ROTATERT */\n-\t      res = o0.rrotate (cnt, prec);\n-\t  }\n-\t  break;\n-\n-\tdefault:\n-\t  return 0;\n-\t}\n-\n-      return immed_double_int_const (res, mode);\n-    }\n-\n-  if (CONST_INT_P (op0) && CONST_INT_P (op1)\n-      && width <= HOST_BITS_PER_WIDE_INT && width != 0)\n-    {\n-      /* Get the integer argument values in two forms:\n-         zero-extended in ARG0, ARG1 and sign-extended in ARG0S, ARG1S.  */\n-\n-      arg0 = INTVAL (op0);\n-      arg1 = INTVAL (op1);\n-\n-      if (width < HOST_BITS_PER_WIDE_INT)\n-        {\n-          arg0 &= GET_MODE_MASK (mode);\n-          arg1 &= GET_MODE_MASK (mode);\n-\n-          arg0s = arg0;\n-\t  if (val_signbit_known_set_p (mode, arg0s))\n-\t    arg0s |= ~GET_MODE_MASK (mode);\n-\n-          arg1s = arg1;\n-\t  if (val_signbit_known_set_p (mode, arg1s))\n-\t    arg1s |= ~GET_MODE_MASK (mode);\n-\t}\n-      else\n-\t{\n-\t  arg0s = arg0;\n-\t  arg1s = arg1;\n-\t}\n-\n-      /* Compute the value of the arithmetic.  */\n-\n-      switch (code)\n-\t{\n-\tcase PLUS:\n-\t  val = (unsigned HOST_WIDE_INT) arg0s + arg1s;\n-\t  break;\n-\n-\tcase MINUS:\n-\t  val = (unsigned HOST_WIDE_INT) arg0s - arg1s;\n-\t  break;\n-\n-\tcase MULT:\n-\t  val = (unsigned HOST_WIDE_INT) arg0s * arg1s;\n-\t  break;\n-\n-\tcase DIV:\n-\t  if (arg1s == 0\n-\t      || ((unsigned HOST_WIDE_INT) arg0s\n-\t\t  == (unsigned HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT - 1)\n-\t\t  && arg1s == -1))\n-\t    return 0;\n-\t  val = arg0s / arg1s;\n-\t  break;\n-\n-\tcase MOD:\n-\t  if (arg1s == 0\n-\t      || ((unsigned HOST_WIDE_INT) arg0s\n-\t\t  == (unsigned HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT - 1)\n-\t\t  && arg1s == -1))\n-\t    return 0;\n-\t  val = arg0s % arg1s;\n-\t  break;\n-\n-\tcase UDIV:\n-\t  if (arg1 == 0\n-\t      || ((unsigned HOST_WIDE_INT) arg0s\n-\t\t  == (unsigned HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT - 1)\n-\t\t  && arg1s == -1))\n-\t    return 0;\n-\t  val = (unsigned HOST_WIDE_INT) arg0 / arg1;\n-\t  break;\n-\n-\tcase UMOD:\n-\t  if (arg1 == 0\n-\t      || ((unsigned HOST_WIDE_INT) arg0s\n-\t\t  == (unsigned HOST_WIDE_INT) 1 << (HOST_BITS_PER_WIDE_INT - 1)\n-\t\t  && arg1s == -1))\n-\t    return 0;\n-\t  val = (unsigned HOST_WIDE_INT) arg0 % arg1;\n-\t  break;\n-\n-\tcase AND:\n-\t  val = arg0 & arg1;\n-\t  break;\n-\n-\tcase IOR:\n-\t  val = arg0 | arg1;\n-\t  break;\n-\n-\tcase XOR:\n-\t  val = arg0 ^ arg1;\n-\t  break;\n-\n-\tcase LSHIFTRT:\n-\tcase ASHIFT:\n-\tcase ASHIFTRT:\n-\t  /* Truncate the shift if SHIFT_COUNT_TRUNCATED, otherwise make sure\n-\t     the value is in range.  We can't return any old value for\n-\t     out-of-range arguments because either the middle-end (via\n-\t     shift_truncation_mask) or the back-end might be relying on\n-\t     target-specific knowledge.  Nor can we rely on\n-\t     shift_truncation_mask, since the shift might not be part of an\n-\t     ashlM3, lshrM3 or ashrM3 instruction.  */\n-\t  if (SHIFT_COUNT_TRUNCATED)\n-\t    arg1 = (unsigned HOST_WIDE_INT) arg1 % width;\n-\t  else if (arg1 < 0 || arg1 >= GET_MODE_BITSIZE (mode))\n-\t    return 0;\n-\n-\t  val = (code == ASHIFT\n-\t\t ? ((unsigned HOST_WIDE_INT) arg0) << arg1\n-\t\t : ((unsigned HOST_WIDE_INT) arg0) >> arg1);\n+\t      wop1 = wi::umod_trunc (wop1, width);\n+\t    else if (wi::geu_p (wop1, width))\n+\t      return NULL_RTX;\n \n-\t  /* Sign-extend the result for arithmetic right shifts.  */\n-\t  if (code == ASHIFTRT && arg0s < 0 && arg1 > 0)\n-\t    val |= HOST_WIDE_INT_M1U << (width - arg1);\n-\t  break;\n+\t    switch (code)\n+\t      {\n+\t      case LSHIFTRT:\n+\t\tresult = wi::lrshift (pop0, wop1);\n+\t\tbreak;\n \n-\tcase ROTATERT:\n-\t  if (arg1 < 0)\n-\t    return 0;\n+\t      case ASHIFTRT:\n+\t\tresult = wi::arshift (pop0, wop1);\n+\t\tbreak;\n \n-\t  arg1 %= width;\n-\t  val = ((((unsigned HOST_WIDE_INT) arg0) << (width - arg1))\n-\t\t | (((unsigned HOST_WIDE_INT) arg0) >> arg1));\n-\t  break;\n+\t      case ASHIFT:\n+\t\tresult = wi::lshift (pop0, wop1);\n+\t\tbreak;\n \n+\t      default:\n+\t\tgcc_unreachable ();\n+\t      }\n+\t    break;\n+\t  }\n \tcase ROTATE:\n-\t  if (arg1 < 0)\n-\t    return 0;\n-\n-\t  arg1 %= width;\n-\t  val = ((((unsigned HOST_WIDE_INT) arg0) << arg1)\n-\t\t | (((unsigned HOST_WIDE_INT) arg0) >> (width - arg1)));\n-\t  break;\n-\n-\tcase COMPARE:\n-\t  /* Do nothing here.  */\n-\t  return 0;\n-\n-\tcase SMIN:\n-\t  val = arg0s <= arg1s ? arg0s : arg1s;\n-\t  break;\n-\n-\tcase UMIN:\n-\t  val = ((unsigned HOST_WIDE_INT) arg0\n-\t\t <= (unsigned HOST_WIDE_INT) arg1 ? arg0 : arg1);\n-\t  break;\n-\n-\tcase SMAX:\n-\t  val = arg0s > arg1s ? arg0s : arg1s;\n-\t  break;\n+\tcase ROTATERT:\n+\t  {\n+\t    if (wi::neg_p (pop1))\n+\t      return NULL_RTX;\n \n-\tcase UMAX:\n-\t  val = ((unsigned HOST_WIDE_INT) arg0\n-\t\t > (unsigned HOST_WIDE_INT) arg1 ? arg0 : arg1);\n-\t  break;\n+\t    switch (code)\n+\t      {\n+\t      case ROTATE:\n+\t\tresult = wi::lrotate (pop0, pop1);\n+\t\tbreak;\n \n-\tcase SS_PLUS:\n-\tcase US_PLUS:\n-\tcase SS_MINUS:\n-\tcase US_MINUS:\n-\tcase SS_MULT:\n-\tcase US_MULT:\n-\tcase SS_DIV:\n-\tcase US_DIV:\n-\tcase SS_ASHIFT:\n-\tcase US_ASHIFT:\n-\t  /* ??? There are simplifications that can be done.  */\n-\t  return 0;\n+\t      case ROTATERT:\n+\t\tresult = wi::rrotate (pop0, pop1);\n+\t\tbreak;\n \n+\t      default:\n+\t\tgcc_unreachable ();\n+\t      }\n+\t    break;\n+\t  }\n \tdefault:\n-\t  gcc_unreachable ();\n+\t  return NULL_RTX;\n \t}\n-\n-      return gen_int_mode (val, mode);\n+      return immed_wide_int_const (result, mode);\n     }\n \n   return NULL_RTX;\n@@ -4940,10 +4528,11 @@ comparison_result (enum rtx_code code, int known_results)\n     }\n }\n \n-/* Check if the given comparison (done in the given MODE) is actually a\n-   tautology or a contradiction.\n-   If no simplification is possible, this function returns zero.\n-   Otherwise, it returns either const_true_rtx or const0_rtx.  */\n+/* Check if the given comparison (done in the given MODE) is actually\n+   a tautology or a contradiction.  If the mode is VOID_mode, the\n+   comparison is done in \"infinite precision\".  If no simplification\n+   is possible, this function returns zero.  Otherwise, it returns\n+   either const_true_rtx or const0_rtx.  */\n \n rtx\n simplify_const_relational_operation (enum rtx_code code,\n@@ -5067,59 +4656,21 @@ simplify_const_relational_operation (enum rtx_code code,\n \n   /* Otherwise, see if the operands are both integers.  */\n   if ((GET_MODE_CLASS (mode) == MODE_INT || mode == VOIDmode)\n-       && (CONST_DOUBLE_AS_INT_P (trueop0) || CONST_INT_P (trueop0))\n-       && (CONST_DOUBLE_AS_INT_P (trueop1) || CONST_INT_P (trueop1)))\n+      && CONST_SCALAR_INT_P (trueop0) && CONST_SCALAR_INT_P (trueop1))\n     {\n-      int width = GET_MODE_PRECISION (mode);\n-      HOST_WIDE_INT l0s, h0s, l1s, h1s;\n-      unsigned HOST_WIDE_INT l0u, h0u, l1u, h1u;\n-\n-      /* Get the two words comprising each integer constant.  */\n-      if (CONST_DOUBLE_AS_INT_P (trueop0))\n-\t{\n-\t  l0u = l0s = CONST_DOUBLE_LOW (trueop0);\n-\t  h0u = h0s = CONST_DOUBLE_HIGH (trueop0);\n-\t}\n-      else\n-\t{\n-\t  l0u = l0s = INTVAL (trueop0);\n-\t  h0u = h0s = HWI_SIGN_EXTEND (l0s);\n-\t}\n-\n-      if (CONST_DOUBLE_AS_INT_P (trueop1))\n-\t{\n-\t  l1u = l1s = CONST_DOUBLE_LOW (trueop1);\n-\t  h1u = h1s = CONST_DOUBLE_HIGH (trueop1);\n-\t}\n-      else\n-\t{\n-\t  l1u = l1s = INTVAL (trueop1);\n-\t  h1u = h1s = HWI_SIGN_EXTEND (l1s);\n-\t}\n-\n-      /* If WIDTH is nonzero and smaller than HOST_BITS_PER_WIDE_INT,\n-\t we have to sign or zero-extend the values.  */\n-      if (width != 0 && width < HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  l0u &= GET_MODE_MASK (mode);\n-\t  l1u &= GET_MODE_MASK (mode);\n-\n-\t  if (val_signbit_known_set_p (mode, l0s))\n-\t    l0s |= ~GET_MODE_MASK (mode);\n-\n-\t  if (val_signbit_known_set_p (mode, l1s))\n-\t    l1s |= ~GET_MODE_MASK (mode);\n-\t}\n-      if (width != 0 && width <= HOST_BITS_PER_WIDE_INT)\n-\th0u = h1u = 0, h0s = HWI_SIGN_EXTEND (l0s), h1s = HWI_SIGN_EXTEND (l1s);\n-\n-      if (h0u == h1u && l0u == l1u)\n+      /* It would be nice if we really had a mode here.  However, the\n+\t largest int representable on the target is as good as\n+\t infinite.  */\n+      enum machine_mode cmode = (mode == VOIDmode) ? MAX_MODE_INT : mode;\n+      rtx_mode_t ptrueop0 = std::make_pair (trueop0, cmode);\n+      rtx_mode_t ptrueop1 = std::make_pair (trueop1, cmode);\n+\n+      if (wi::eq_p (ptrueop0, ptrueop1))\n \treturn comparison_result (code, CMP_EQ);\n       else\n \t{\n-\t  int cr;\n-\t  cr = (h0s < h1s || (h0s == h1s && l0u < l1u)) ? CMP_LT : CMP_GT;\n-\t  cr |= (h0u < h1u || (h0u == h1u && l0u < l1u)) ? CMP_LTU : CMP_GTU;\n+\t  int cr = wi::lts_p (ptrueop0, ptrueop1) ? CMP_LT : CMP_GT;\n+\t  cr |= wi::ltu_p (ptrueop0, ptrueop1) ? CMP_LTU : CMP_GTU;\n \t  return comparison_result (code, cr);\n \t}\n     }\n@@ -5575,9 +5126,9 @@ simplify_ternary_operation (enum rtx_code code, enum machine_mode mode,\n   return 0;\n }\n \n-/* Evaluate a SUBREG of a CONST_INT or CONST_DOUBLE or CONST_FIXED\n-   or CONST_VECTOR,\n-   returning another CONST_INT or CONST_DOUBLE or CONST_FIXED or CONST_VECTOR.\n+/* Evaluate a SUBREG of a CONST_INT or CONST_WIDE_INT or CONST_DOUBLE\n+   or CONST_FIXED or CONST_VECTOR, returning another CONST_INT or\n+   CONST_WIDE_INT or CONST_DOUBLE or CONST_FIXED or CONST_VECTOR.\n \n    Works by unpacking OP into a collection of 8-bit values\n    represented as a little-endian array of 'unsigned char', selecting by BYTE,\n@@ -5587,13 +5138,11 @@ static rtx\n simplify_immed_subreg (enum machine_mode outermode, rtx op,\n \t\t       enum machine_mode innermode, unsigned int byte)\n {\n-  /* We support up to 512-bit values (for V8DFmode).  */\n   enum {\n-    max_bitsize = 512,\n     value_bit = 8,\n     value_mask = (1 << value_bit) - 1\n   };\n-  unsigned char value[max_bitsize / value_bit];\n+  unsigned char value[MAX_BITSIZE_MODE_ANY_MODE / value_bit];\n   int value_start;\n   int i;\n   int elem;\n@@ -5605,6 +5154,7 @@ simplify_immed_subreg (enum machine_mode outermode, rtx op,\n   rtvec result_v = NULL;\n   enum mode_class outer_class;\n   enum machine_mode outer_submode;\n+  int max_bitsize;\n \n   /* Some ports misuse CCmode.  */\n   if (GET_MODE_CLASS (outermode) == MODE_CC && CONST_INT_P (op))\n@@ -5614,6 +5164,10 @@ simplify_immed_subreg (enum machine_mode outermode, rtx op,\n   if (COMPLEX_MODE_P (outermode))\n     return NULL_RTX;\n \n+  /* We support any size mode.  */\n+  max_bitsize = MAX (GET_MODE_BITSIZE (outermode),\n+\t\t     GET_MODE_BITSIZE (innermode));\n+\n   /* Unpack the value.  */\n \n   if (GET_CODE (op) == CONST_VECTOR)\n@@ -5663,8 +5217,20 @@ simplify_immed_subreg (enum machine_mode outermode, rtx op,\n \t    *vp++ = INTVAL (el) < 0 ? -1 : 0;\n \t  break;\n \n+\tcase CONST_WIDE_INT:\n+\t  {\n+\t    rtx_mode_t val = std::make_pair (el, innermode);\n+\t    unsigned char extend = wi::sign_mask (val);\n+\n+\t    for (i = 0; i < elem_bitsize; i += value_bit)\n+\t      *vp++ = wi::extract_uhwi (val, i, value_bit);\n+\t    for (; i < elem_bitsize; i += value_bit)\n+\t      *vp++ = extend;\n+\t  }\n+\t  break;\n+\n \tcase CONST_DOUBLE:\n-\t  if (GET_MODE (el) == VOIDmode)\n+\t  if (TARGET_SUPPORTS_WIDE_INT == 0 && GET_MODE (el) == VOIDmode)\n \t    {\n \t      unsigned char extend = 0;\n \t      /* If this triggers, someone should have generated a\n@@ -5687,7 +5253,8 @@ simplify_immed_subreg (enum machine_mode outermode, rtx op,\n \t    }\n \t  else\n \t    {\n-\t      long tmp[max_bitsize / 32];\n+\t      /* This is big enough for anything on the platform.  */\n+\t      long tmp[MAX_BITSIZE_MODE_ANY_MODE / 32];\n \t      int bitsize = GET_MODE_BITSIZE (GET_MODE (el));\n \n \t      gcc_assert (SCALAR_FLOAT_MODE_P (GET_MODE (el)));\n@@ -5807,32 +5374,38 @@ simplify_immed_subreg (enum machine_mode outermode, rtx op,\n \tcase MODE_INT:\n \tcase MODE_PARTIAL_INT:\n \t  {\n-\t    unsigned HOST_WIDE_INT hi = 0, lo = 0;\n-\n-\t    for (i = 0;\n-\t\t i < HOST_BITS_PER_WIDE_INT && i < elem_bitsize;\n-\t\t i += value_bit)\n-\t      lo |= (unsigned HOST_WIDE_INT)(*vp++ & value_mask) << i;\n-\t    for (; i < elem_bitsize; i += value_bit)\n-\t      hi |= (unsigned HOST_WIDE_INT)(*vp++ & value_mask)\n-\t\t     << (i - HOST_BITS_PER_WIDE_INT);\n-\n-\t    /* immed_double_const doesn't call trunc_int_for_mode.  I don't\n-\t       know why.  */\n-\t    if (elem_bitsize <= HOST_BITS_PER_WIDE_INT)\n-\t      elems[elem] = gen_int_mode (lo, outer_submode);\n-\t    else if (elem_bitsize <= HOST_BITS_PER_DOUBLE_INT)\n-\t      elems[elem] = immed_double_const (lo, hi, outer_submode);\n-\t    else\n-\t      return NULL_RTX;\n+\t    int u;\n+\t    int base = 0;\n+\t    int units\n+\t      = (GET_MODE_BITSIZE (outer_submode) + HOST_BITS_PER_WIDE_INT - 1)\n+\t      / HOST_BITS_PER_WIDE_INT;\n+\t    HOST_WIDE_INT tmp[MAX_BITSIZE_MODE_ANY_INT / HOST_BITS_PER_WIDE_INT];\n+\t    wide_int r;\n+\n+\t    for (u = 0; u < units; u++)\n+\t      {\n+\t\tunsigned HOST_WIDE_INT buf = 0;\n+\t\tfor (i = 0;\n+\t\t     i < HOST_BITS_PER_WIDE_INT && base + i < elem_bitsize;\n+\t\t     i += value_bit)\n+\t\t  buf |= (unsigned HOST_WIDE_INT)(*vp++ & value_mask) << i;\n+\n+\t\ttmp[u] = buf;\n+\t\tbase += HOST_BITS_PER_WIDE_INT;\n+\t      }\n+\t    gcc_assert (GET_MODE_PRECISION (outer_submode)\n+\t\t\t<= MAX_BITSIZE_MODE_ANY_INT);\n+\t    r = wide_int::from_array (tmp, units,\n+\t\t\t\t      GET_MODE_PRECISION (outer_submode));\n+\t    elems[elem] = immed_wide_int_const (r, outer_submode);\n \t  }\n \t  break;\n \n \tcase MODE_FLOAT:\n \tcase MODE_DECIMAL_FLOAT:\n \t  {\n \t    REAL_VALUE_TYPE r;\n-\t    long tmp[max_bitsize / 32];\n+\t    long tmp[MAX_BITSIZE_MODE_ANY_MODE / 32];\n \n \t    /* real_from_target wants its input in words affected by\n \t       FLOAT_WORDS_BIG_ENDIAN.  However, we ignore this,"}, {"sha": "163d495b2b04b1efada66b3cfcb7743ff1282831", "filename": "gcc/stmt.c", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fstmt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fstmt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstmt.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1237,9 +1237,7 @@ expand_case (gimple stmt)\n \t original type.  Make sure to drop overflow flags.  */\n       low = fold_convert (index_type, low);\n       if (TREE_OVERFLOW (low))\n-\tlow = build_int_cst_wide (index_type,\n-\t\t\t\t  TREE_INT_CST_LOW (low),\n-\t\t\t\t  TREE_INT_CST_HIGH (low));\n+\tlow = wide_int_to_tree (index_type, low);\n \n       /* The canonical from of a case label in GIMPLE is that a simple case\n \t has an empty CASE_HIGH.  For the casesi and tablejump expanders,\n@@ -1248,9 +1246,7 @@ expand_case (gimple stmt)\n \thigh = low;\n       high = fold_convert (index_type, high);\n       if (TREE_OVERFLOW (high))\n-\thigh = build_int_cst_wide (index_type,\n-\t\t\t\t   TREE_INT_CST_LOW (high),\n-\t\t\t\t   TREE_INT_CST_HIGH (high));\n+\thigh = wide_int_to_tree (index_type, high);\n \n       basic_block case_bb = label_to_block_fn (cfun, lab);\n       edge case_edge = find_edge (bb, case_bb);"}, {"sha": "8fa4dc884b113eeb8e22afe0ab2806cc947ef6a5", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 13, "deletions": 72, "changes": 85, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2264,13 +2264,10 @@ layout_type (tree type)\n \t\t    && TYPE_UNSIGNED (TREE_TYPE (lb))\n \t\t    && tree_int_cst_lt (ub, lb))\n \t\t  {\n-\t\t    unsigned prec = TYPE_PRECISION (TREE_TYPE (lb));\n-\t\t    lb = double_int_to_tree\n-\t\t\t   (ssizetype,\n-\t\t\t    tree_to_double_int (lb).sext (prec));\n-\t\t    ub = double_int_to_tree\n-\t\t\t   (ssizetype,\n-\t\t\t    tree_to_double_int (ub).sext (prec));\n+\t\t    lb = wide_int_to_tree (ssizetype,\n+\t\t\t\t\t   offset_int::from (lb, SIGNED));\n+\t\t    ub = wide_int_to_tree (ssizetype,\n+\t\t\t\t\t   offset_int::from (ub, SIGNED));\n \t\t  }\n \t\tlength\n \t\t  = fold_convert (sizetype,\n@@ -2546,16 +2543,14 @@ initialize_sizetypes (void)\n   TYPE_ALIGN (sizetype) = GET_MODE_ALIGNMENT (TYPE_MODE (sizetype));\n   TYPE_SIZE (sizetype) = bitsize_int (precision);\n   TYPE_SIZE_UNIT (sizetype) = size_int (GET_MODE_SIZE (TYPE_MODE (sizetype)));\n-  set_min_and_max_values_for_integral_type (sizetype, precision,\n-\t\t\t\t\t    /*is_unsigned=*/true);\n+  set_min_and_max_values_for_integral_type (sizetype, precision, UNSIGNED);\n \n   SET_TYPE_MODE (bitsizetype, smallest_mode_for_size (bprecision, MODE_INT));\n   TYPE_ALIGN (bitsizetype) = GET_MODE_ALIGNMENT (TYPE_MODE (bitsizetype));\n   TYPE_SIZE (bitsizetype) = bitsize_int (bprecision);\n   TYPE_SIZE_UNIT (bitsizetype)\n     = size_int (GET_MODE_SIZE (TYPE_MODE (bitsizetype)));\n-  set_min_and_max_values_for_integral_type (bitsizetype, bprecision,\n-\t\t\t\t\t    /*is_unsigned=*/true);\n+  set_min_and_max_values_for_integral_type (bitsizetype, bprecision, UNSIGNED);\n \n   /* Create the signed variants of *sizetype.  */\n   ssizetype = make_signed_type (TYPE_PRECISION (sizetype));\n@@ -2575,58 +2570,18 @@ initialize_sizetypes (void)\n void\n set_min_and_max_values_for_integral_type (tree type,\n \t\t\t\t\t  int precision,\n-\t\t\t\t\t  bool is_unsigned)\n+\t\t\t\t\t  signop sgn)\n {\n-  tree min_value;\n-  tree max_value;\n-\n   /* For bitfields with zero width we end up creating integer types\n      with zero precision.  Don't assign any minimum/maximum values\n      to those types, they don't have any valid value.  */\n   if (precision < 1)\n     return;\n \n-  if (is_unsigned)\n-    {\n-      min_value = build_int_cst (type, 0);\n-      max_value\n-\t= build_int_cst_wide (type, precision - HOST_BITS_PER_WIDE_INT >= 0\n-\t\t\t      ? -1\n-\t\t\t      : (HOST_WIDE_INT_1U << precision) - 1,\n-\t\t\t      precision - HOST_BITS_PER_WIDE_INT > 0\n-\t\t\t      ? ((unsigned HOST_WIDE_INT) ~0\n-\t\t\t\t >> (HOST_BITS_PER_WIDE_INT\n-\t\t\t\t     - (precision - HOST_BITS_PER_WIDE_INT)))\n-\t\t\t      : 0);\n-    }\n-  else\n-    {\n-      min_value\n-\t= build_int_cst_wide (type,\n-\t\t\t      (precision - HOST_BITS_PER_WIDE_INT > 0\n-\t\t\t       ? 0\n-\t\t\t       : HOST_WIDE_INT_M1U << (precision - 1)),\n-\t\t\t      (((HOST_WIDE_INT) (-1)\n-\t\t\t\t<< (precision - HOST_BITS_PER_WIDE_INT - 1 > 0\n-\t\t\t\t    ? precision - HOST_BITS_PER_WIDE_INT - 1\n-\t\t\t\t    : 0))));\n-      max_value\n-\t= build_int_cst_wide (type,\n-\t\t\t      (precision - HOST_BITS_PER_WIDE_INT > 0\n-\t\t\t       ? -1\n-\t\t\t       : (HOST_WIDE_INT)\n-\t\t\t\t (((unsigned HOST_WIDE_INT) 1\n-\t\t\t\t   << (precision - 1)) - 1)),\n-\t\t\t      (precision - HOST_BITS_PER_WIDE_INT - 1 > 0\n-\t\t\t       ? (HOST_WIDE_INT)\n-\t\t\t\t ((((unsigned HOST_WIDE_INT) 1\n-\t\t\t\t    << (precision - HOST_BITS_PER_WIDE_INT\n-\t\t\t\t\t- 1))) - 1)\n-\t\t\t       : 0));\n-    }\n-\n-  TYPE_MIN_VALUE (type) = min_value;\n-  TYPE_MAX_VALUE (type) = max_value;\n+  TYPE_MIN_VALUE (type)\n+    = wide_int_to_tree (type, wi::min_value (precision, sgn));\n+  TYPE_MAX_VALUE (type)\n+    = wide_int_to_tree (type, wi::max_value (precision, sgn));\n }\n \n /* Set the extreme values of TYPE based on its precision in bits,\n@@ -2639,14 +2594,7 @@ fixup_signed_type (tree type)\n {\n   int precision = TYPE_PRECISION (type);\n \n-  /* We can not represent properly constants greater then\n-     HOST_BITS_PER_DOUBLE_INT, still we need the types\n-     as they are used by i386 vector extensions and friends.  */\n-  if (precision > HOST_BITS_PER_DOUBLE_INT)\n-    precision = HOST_BITS_PER_DOUBLE_INT;\n-\n-  set_min_and_max_values_for_integral_type (type, precision,\n-\t\t\t\t\t    /*is_unsigned=*/false);\n+  set_min_and_max_values_for_integral_type (type, precision, SIGNED);\n \n   /* Lay out the type: set its alignment, size, etc.  */\n   layout_type (type);\n@@ -2661,16 +2609,9 @@ fixup_unsigned_type (tree type)\n {\n   int precision = TYPE_PRECISION (type);\n \n-  /* We can not represent properly constants greater then\n-     HOST_BITS_PER_DOUBLE_INT, still we need the types\n-     as they are used by i386 vector extensions and friends.  */\n-  if (precision > HOST_BITS_PER_DOUBLE_INT)\n-    precision = HOST_BITS_PER_DOUBLE_INT;\n-\n   TYPE_UNSIGNED (type) = 1;\n \n-  set_min_and_max_values_for_integral_type (type, precision,\n-\t\t\t\t\t    /*is_unsigned=*/true);\n+  set_min_and_max_values_for_integral_type (type, precision, UNSIGNED);\n \n   /* Lay out the type: set its alignment, size, etc.  */\n   layout_type (type);"}, {"sha": "0ff98f8f051c907f871690b8b38e63abf17d2d61", "filename": "gcc/stor-layout.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fstor-layout.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fstor-layout.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -20,7 +20,7 @@ along with GCC; see the file COPYING3.  If not see\n #ifndef GCC_STOR_LAYOUT_H\n #define GCC_STOR_LAYOUT_H\n \n-extern void set_min_and_max_values_for_integral_type (tree, int, bool);\n+extern void set_min_and_max_values_for_integral_type (tree, int, signop);\n extern void fixup_signed_type (tree);\n extern void internal_reference_types (void);\n extern unsigned int update_alignment_for_field (record_layout_info, tree,"}, {"sha": "b20b5cfde1d2041276f62cc2042a34331e6adb1f", "filename": "gcc/system.h", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsystem.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fsystem.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsystem.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -711,6 +711,16 @@ extern void fancy_abort (const char *, int, const char *) ATTRIBUTE_NORETURN;\n #define gcc_unreachable() (fancy_abort (__FILE__, __LINE__, __FUNCTION__))\n #endif\n \n+#if GCC_VERSION >= 3001\n+#define STATIC_CONSTANT_P(X) (__builtin_constant_p (X) && (X))\n+#else\n+#define STATIC_CONSTANT_P(X) (false && (X))\n+#endif\n+\n+/* Until we can use C++11's static_assert.  */\n+#define STATIC_ASSERT(X) \\\n+  typedef int assertion1[(X) ? 1 : -1] ATTRIBUTE_UNUSED\n+\n /* Provide a fake boolean type.  We make no attempt to use the\n    C99 _Bool, as it may not be available in the bootstrap compiler,\n    and even if it is, it is liable to be buggy."}, {"sha": "febd3207beda3cefb7e8144e50a54c6dfd9b1411", "filename": "gcc/target.def", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarget.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarget.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarget.def?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -3545,9 +3545,9 @@ loop is only entered from the top.\\n\\\n This hook is only used if @code{doloop_end} is available.  The default\\n\\\n implementation returns true.  You can use @code{can_use_doloop_if_innermost}\\n\\\n if the loop must be the innermost, and if there are no other restrictions.\",\n- bool, (double_int iterations, double_int iterations_max,\n+ bool, (const widest_int &iterations, const widest_int &iterations_max,\n \tunsigned int loop_depth, bool entered_at_top),\n- hook_bool_dint_dint_uint_bool_true)\n+ hook_bool_wint_wint_uint_bool_true)\n \n /* Returns NULL if target supports the insn within a doloop block,\n    otherwise it returns an error message.  */"}, {"sha": "31123d97b3ea971a6dc90c64c9a57512e7118764", "filename": "gcc/target.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarget.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarget.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarget.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -50,7 +50,7 @@\n \n #include \"insn-modes.h\"\n #include \"insn-codes.h\"\n-#include \"double-int.h\"\n+#include \"wide-int.h\"\n \n #ifdef ENABLE_CHECKING\n "}, {"sha": "3df93d3943225815173f207a0b3d8f7944c4c5b1", "filename": "gcc/targhooks.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarghooks.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarghooks.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarghooks.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -290,7 +290,7 @@ default_cxx_get_cookie_size (tree type)\n \n   sizetype_size = size_in_bytes (sizetype);\n   type_align = size_int (TYPE_ALIGN_UNIT (type));\n-  if (INT_CST_LT_UNSIGNED (type_align, sizetype_size))\n+  if (tree_int_cst_lt (type_align, sizetype_size))\n     cookie_size = sizetype_size;\n   else\n     cookie_size = type_align;\n@@ -1711,7 +1711,7 @@ std_gimplify_va_arg_expr (tree valist, tree type, gimple_seq *pre_p,\n    not support nested low-overhead loops.  */\n \n bool\n-can_use_doloop_if_innermost (double_int, double_int,\n+can_use_doloop_if_innermost (const widest_int &, const widest_int &,\n \t\t\t     unsigned int loop_depth, bool)\n {\n   return loop_depth == 1;"}, {"sha": "4be33f8696c44d0a9862cd3a40c24b0f09027b54", "filename": "gcc/targhooks.h", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarghooks.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftarghooks.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarghooks.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -207,5 +207,6 @@ extern bool default_member_type_forces_blk (const_tree, enum machine_mode);\n extern void default_atomic_assign_expand_fenv (tree *, tree *, tree *);\n extern tree build_va_arg_indirect_ref (tree);\n extern tree std_gimplify_va_arg_expr (tree, tree, gimple_seq *, gimple_seq *);\n-extern bool can_use_doloop_if_innermost (double_int, double_int,\n+extern bool can_use_doloop_if_innermost (const widest_int &,\n+\t\t\t\t\t const widest_int &,\n \t\t\t\t\t unsigned int, bool);"}, {"sha": "0bd1a18827802e01324ec828881e04dc095697a9", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr45427.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr45427.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr45427.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr45427.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -25,5 +25,5 @@ int main()\n   return 0;\n }\n \n-/* { dg-final { scan-tree-dump-times \"bounded by 0\" 0 \"cunrolli\"} } */\n+/* { dg-final { scan-tree-dump-times \"bounded by 0x0\\[^0-9a-f\\]\" 0 \"cunrolli\"} } */\n /* { dg-final { cleanup-tree-dump \"cunrolli\" } } */"}, {"sha": "1d292c4ad0973fbbe8c47bf5b3c6b4cdfc0f6c4b", "filename": "gcc/tree-affine.c", "status": "modified", "additions": 91, "deletions": 99, "changes": 190, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-affine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-affine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-affine.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -35,33 +35,37 @@ along with GCC; see the file COPYING3.  If not see\n #include \"flags.h\"\n #include \"dumpfile.h\"\n #include \"cfgexpand.h\"\n+#include \"wide-int-print.h\"\n \n /* Extends CST as appropriate for the affine combinations COMB.  */\n \n-double_int\n-double_int_ext_for_comb (double_int cst, aff_tree *comb)\n+widest_int\n+wide_int_ext_for_comb (const widest_int &cst, aff_tree *comb)\n {\n-  return cst.sext (TYPE_PRECISION (comb->type));\n+  return wi::sext (cst, TYPE_PRECISION (comb->type));\n }\n \n /* Initializes affine combination COMB so that its value is zero in TYPE.  */\n \n static void\n aff_combination_zero (aff_tree *comb, tree type)\n {\n+  int i;\n   comb->type = type;\n-  comb->offset = double_int_zero;\n+  comb->offset = 0;\n   comb->n = 0;\n+  for (i = 0; i < MAX_AFF_ELTS; i++)\n+    comb->elts[i].coef = 0;\n   comb->rest = NULL_TREE;\n }\n \n /* Sets COMB to CST.  */\n \n void\n-aff_combination_const (aff_tree *comb, tree type, double_int cst)\n+aff_combination_const (aff_tree *comb, tree type, const widest_int &cst)\n {\n   aff_combination_zero (comb, type);\n-  comb->offset = double_int_ext_for_comb (cst, comb);\n+  comb->offset = wide_int_ext_for_comb (cst, comb);;\n }\n \n /* Sets COMB to single element ELT.  */\n@@ -73,37 +77,34 @@ aff_combination_elt (aff_tree *comb, tree type, tree elt)\n \n   comb->n = 1;\n   comb->elts[0].val = elt;\n-  comb->elts[0].coef = double_int_one;\n+  comb->elts[0].coef = 1;\n }\n \n /* Scales COMB by SCALE.  */\n \n void\n-aff_combination_scale (aff_tree *comb, double_int scale)\n+aff_combination_scale (aff_tree *comb, const widest_int &scale_in)\n {\n   unsigned i, j;\n \n-  scale = double_int_ext_for_comb (scale, comb);\n-  if (scale.is_one ())\n+  widest_int scale = wide_int_ext_for_comb (scale_in, comb);\n+  if (scale == 1)\n     return;\n \n-  if (scale.is_zero ())\n+  if (scale == 0)\n     {\n       aff_combination_zero (comb, comb->type);\n       return;\n     }\n \n-  comb->offset\n-    = double_int_ext_for_comb (scale * comb->offset, comb);\n+  comb->offset = wide_int_ext_for_comb (scale * comb->offset, comb);\n   for (i = 0, j = 0; i < comb->n; i++)\n     {\n-      double_int new_coef;\n-\n-      new_coef\n-\t= double_int_ext_for_comb (scale * comb->elts[i].coef, comb);\n+      widest_int new_coef\n+\t= wide_int_ext_for_comb (scale * comb->elts[i].coef, comb);\n       /* A coefficient may become zero due to overflow.  Remove the zero\n \t elements.  */\n-      if (new_coef.is_zero ())\n+      if (new_coef == 0)\n \tcontinue;\n       comb->elts[j].coef = new_coef;\n       comb->elts[j].val = comb->elts[i].val;\n@@ -125,30 +126,28 @@ aff_combination_scale (aff_tree *comb, double_int scale)\n \t}\n       else\n \tcomb->rest = fold_build2 (MULT_EXPR, type, comb->rest,\n-\t\t\t\t  double_int_to_tree (type, scale));\n+\t\t\t\t  wide_int_to_tree (type, scale));\n     }\n }\n \n /* Adds ELT * SCALE to COMB.  */\n \n void\n-aff_combination_add_elt (aff_tree *comb, tree elt, double_int scale)\n+aff_combination_add_elt (aff_tree *comb, tree elt, const widest_int &scale_in)\n {\n   unsigned i;\n   tree type;\n \n-  scale = double_int_ext_for_comb (scale, comb);\n-  if (scale.is_zero ())\n+  widest_int scale = wide_int_ext_for_comb (scale_in, comb);\n+  if (scale == 0)\n     return;\n \n   for (i = 0; i < comb->n; i++)\n     if (operand_equal_p (comb->elts[i].val, elt, 0))\n       {\n-\tdouble_int new_coef;\n-\n-\tnew_coef = comb->elts[i].coef + scale;\n-\tnew_coef = double_int_ext_for_comb (new_coef, comb);\n-\tif (!new_coef.is_zero ())\n+\twidest_int new_coef\n+\t  = wide_int_ext_for_comb (comb->elts[i].coef + scale, comb);\n+\tif (new_coef != 0)\n \t  {\n \t    comb->elts[i].coef = new_coef;\n \t    return;\n@@ -160,7 +159,7 @@ aff_combination_add_elt (aff_tree *comb, tree elt, double_int scale)\n \tif (comb->rest)\n \t  {\n \t    gcc_assert (comb->n == MAX_AFF_ELTS - 1);\n-\t    comb->elts[comb->n].coef = double_int_one;\n+\t    comb->elts[comb->n].coef = 1;\n \t    comb->elts[comb->n].val = comb->rest;\n \t    comb->rest = NULL_TREE;\n \t    comb->n++;\n@@ -179,12 +178,12 @@ aff_combination_add_elt (aff_tree *comb, tree elt, double_int scale)\n   if (POINTER_TYPE_P (type))\n     type = sizetype;\n \n-  if (scale.is_one ())\n+  if (scale == 1)\n     elt = fold_convert (type, elt);\n   else\n     elt = fold_build2 (MULT_EXPR, type,\n \t\t       fold_convert (type, elt),\n-\t\t       double_int_to_tree (type, scale));\n+\t\t       wide_int_to_tree (type, scale));\n \n   if (comb->rest)\n     comb->rest = fold_build2 (PLUS_EXPR, type, comb->rest,\n@@ -196,9 +195,9 @@ aff_combination_add_elt (aff_tree *comb, tree elt, double_int scale)\n /* Adds CST to C.  */\n \n static void\n-aff_combination_add_cst (aff_tree *c, double_int cst)\n+aff_combination_add_cst (aff_tree *c, const widest_int &cst)\n {\n-  c->offset = double_int_ext_for_comb (c->offset + cst, c);\n+  c->offset = wide_int_ext_for_comb (c->offset + cst, c);\n }\n \n /* Adds COMB2 to COMB1.  */\n@@ -212,7 +211,7 @@ aff_combination_add (aff_tree *comb1, aff_tree *comb2)\n   for (i = 0; i < comb2->n; i++)\n     aff_combination_add_elt (comb1, comb2->elts[i].val, comb2->elts[i].coef);\n   if (comb2->rest)\n-    aff_combination_add_elt (comb1, comb2->rest, double_int_one);\n+    aff_combination_add_elt (comb1, comb2->rest, 1);\n }\n \n /* Converts affine combination COMB to TYPE.  */\n@@ -237,21 +236,20 @@ aff_combination_convert (aff_tree *comb, tree type)\n   if (TYPE_PRECISION (type) == TYPE_PRECISION (comb_type))\n     return;\n \n-  comb->offset = double_int_ext_for_comb (comb->offset, comb);\n+  comb->offset = wide_int_ext_for_comb (comb->offset, comb);\n   for (i = j = 0; i < comb->n; i++)\n     {\n-      double_int new_coef = double_int_ext_for_comb (comb->elts[i].coef, comb);\n-      if (new_coef.is_zero ())\n+      if (comb->elts[i].coef == 0)\n \tcontinue;\n-      comb->elts[j].coef = new_coef;\n+      comb->elts[j].coef = comb->elts[i].coef;\n       comb->elts[j].val = fold_convert (type, comb->elts[i].val);\n       j++;\n     }\n \n   comb->n = j;\n   if (comb->n < MAX_AFF_ELTS && comb->rest)\n     {\n-      comb->elts[comb->n].coef = double_int_one;\n+      comb->elts[comb->n].coef = 1;\n       comb->elts[comb->n].val = comb->rest;\n       comb->rest = NULL_TREE;\n       comb->n++;\n@@ -276,7 +274,7 @@ tree_to_aff_combination (tree expr, tree type, aff_tree *comb)\n   switch (code)\n     {\n     case INTEGER_CST:\n-      aff_combination_const (comb, type, tree_to_double_int (expr));\n+      aff_combination_const (comb, type, wi::to_widest (expr));\n       return;\n \n     case POINTER_PLUS_EXPR:\n@@ -290,7 +288,7 @@ tree_to_aff_combination (tree expr, tree type, aff_tree *comb)\n       tree_to_aff_combination (TREE_OPERAND (expr, 0), type, comb);\n       tree_to_aff_combination (TREE_OPERAND (expr, 1), type, &tmp);\n       if (code == MINUS_EXPR)\n-\taff_combination_scale (&tmp, double_int_minus_one);\n+\taff_combination_scale (&tmp, -1);\n       aff_combination_add (comb, &tmp);\n       return;\n \n@@ -299,19 +297,19 @@ tree_to_aff_combination (tree expr, tree type, aff_tree *comb)\n       if (TREE_CODE (cst) != INTEGER_CST)\n \tbreak;\n       tree_to_aff_combination (TREE_OPERAND (expr, 0), type, comb);\n-      aff_combination_scale (comb, tree_to_double_int (cst));\n+      aff_combination_scale (comb, wi::to_widest (cst));\n       return;\n \n     case NEGATE_EXPR:\n       tree_to_aff_combination (TREE_OPERAND (expr, 0), type, comb);\n-      aff_combination_scale (comb, double_int_minus_one);\n+      aff_combination_scale (comb, -1);\n       return;\n \n     case BIT_NOT_EXPR:\n       /* ~x = -x - 1 */\n       tree_to_aff_combination (TREE_OPERAND (expr, 0), type, comb);\n-      aff_combination_scale (comb, double_int_minus_one);\n-      aff_combination_add_cst (comb, double_int_minus_one);\n+      aff_combination_scale (comb, -1);\n+      aff_combination_add_cst (comb, -1);\n       return;\n \n     case ADDR_EXPR:\n@@ -329,11 +327,10 @@ tree_to_aff_combination (tree expr, tree type, aff_tree *comb)\n \t\t\t\t  false);\n       if (bitpos % BITS_PER_UNIT != 0)\n \tbreak;\n-      aff_combination_const (comb, type,\n-\t\t\t     double_int::from_uhwi (bitpos / BITS_PER_UNIT));\n+      aff_combination_const (comb, type, bitpos / BITS_PER_UNIT);\n       core = build_fold_addr_expr (core);\n       if (TREE_CODE (core) == ADDR_EXPR)\n-\taff_combination_add_elt (comb, core, double_int_one);\n+\taff_combination_add_elt (comb, core, 1);\n       else\n \t{\n \t  tree_to_aff_combination (core, type, &tmp);\n@@ -376,25 +373,25 @@ tree_to_aff_combination (tree expr, tree type, aff_tree *comb)\n    combination COMB.  */\n \n static tree\n-add_elt_to_tree (tree expr, tree type, tree elt, double_int scale,\n-\t\t aff_tree *comb)\n+add_elt_to_tree (tree expr, tree type, tree elt, const widest_int &scale_in,\n+\t\t aff_tree *comb ATTRIBUTE_UNUSED)\n {\n   enum tree_code code;\n   tree type1 = type;\n   if (POINTER_TYPE_P (type))\n     type1 = sizetype;\n \n-  scale = double_int_ext_for_comb (scale, comb);\n+  widest_int scale = wide_int_ext_for_comb (scale_in, comb);\n \n-  if (scale.is_minus_one ()\n+  if (scale == -1\n       && POINTER_TYPE_P (TREE_TYPE (elt)))\n     {\n       elt = convert_to_ptrofftype (elt);\n       elt = fold_build1 (NEGATE_EXPR, TREE_TYPE (elt), elt);\n-      scale = double_int_one;\n+      scale = 1;\n     }\n \n-  if (scale.is_one ())\n+  if (scale == 1)\n     {\n       if (!expr)\n \t{\n@@ -412,7 +409,7 @@ add_elt_to_tree (tree expr, tree type, tree elt, double_int scale,\n \t\t\t  expr, fold_convert (type1, elt));\n     }\n \n-  if (scale.is_minus_one ())\n+  if (scale == -1)\n     {\n       if (!expr)\n \treturn fold_build1 (NEGATE_EXPR, type1,\n@@ -431,9 +428,9 @@ add_elt_to_tree (tree expr, tree type, tree elt, double_int scale,\n   elt = fold_convert (type1, elt);\n   if (!expr)\n     return fold_build2 (MULT_EXPR, type1, elt,\n-\t\t\tdouble_int_to_tree (type1, scale));\n+\t\t\twide_int_to_tree (type1, scale));\n \n-  if (scale.is_negative ())\n+  if (wi::neg_p (scale))\n     {\n       code = MINUS_EXPR;\n       scale = -scale;\n@@ -442,7 +439,7 @@ add_elt_to_tree (tree expr, tree type, tree elt, double_int scale,\n     code = PLUS_EXPR;\n \n   elt = fold_build2 (MULT_EXPR, type1, elt,\n-\t\t     double_int_to_tree (type1, scale));\n+\t\t     wide_int_to_tree (type1, scale));\n   if (POINTER_TYPE_P (TREE_TYPE (expr)))\n     {\n       if (code == MINUS_EXPR)\n@@ -460,7 +457,7 @@ aff_combination_to_tree (aff_tree *comb)\n   tree type = comb->type;\n   tree expr = NULL_TREE;\n   unsigned i;\n-  double_int off, sgn;\n+  widest_int off, sgn;\n   tree type1 = type;\n   if (POINTER_TYPE_P (type))\n     type1 = sizetype;\n@@ -472,21 +469,21 @@ aff_combination_to_tree (aff_tree *comb)\n \t\t\t    comb);\n \n   if (comb->rest)\n-    expr = add_elt_to_tree (expr, type, comb->rest, double_int_one, comb);\n+    expr = add_elt_to_tree (expr, type, comb->rest, 1, comb);\n \n   /* Ensure that we get x - 1, not x + (-1) or x + 0xff..f if x is\n      unsigned.  */\n-  if (comb->offset.is_negative ())\n+  if (wi::neg_p (comb->offset))\n     {\n       off = -comb->offset;\n-      sgn = double_int_minus_one;\n+      sgn = -1;\n     }\n   else\n     {\n       off = comb->offset;\n-      sgn = double_int_one;\n+      sgn = 1;\n     }\n-  return add_elt_to_tree (expr, type, double_int_to_tree (type1, off), sgn,\n+  return add_elt_to_tree (expr, type, wide_int_to_tree (type1, off), sgn,\n \t\t\t  comb);\n }\n \n@@ -513,7 +510,7 @@ aff_combination_remove_elt (aff_tree *comb, unsigned m)\n     comb->elts[m] = comb->elts[comb->n];\n   if (comb->rest)\n     {\n-      comb->elts[comb->n].coef = double_int_one;\n+      comb->elts[comb->n].coef = 1;\n       comb->elts[comb->n].val = comb->rest;\n       comb->rest = NULL_TREE;\n       comb->n++;\n@@ -525,7 +522,7 @@ aff_combination_remove_elt (aff_tree *comb, unsigned m)\n \n \n static void\n-aff_combination_add_product (aff_tree *c, double_int coef, tree val,\n+aff_combination_add_product (aff_tree *c, const widest_int &coef, tree val,\n \t\t\t     aff_tree *r)\n {\n   unsigned i;\n@@ -576,7 +573,7 @@ aff_combination_mult (aff_tree *c1, aff_tree *c2, aff_tree *r)\n   for (i = 0; i < c2->n; i++)\n     aff_combination_add_product (c1, c2->elts[i].coef, c2->elts[i].val, r);\n   if (c2->rest)\n-    aff_combination_add_product (c1, double_int_one, c2->rest, r);\n+    aff_combination_add_product (c1, 1, c2->rest, r);\n   aff_combination_add_product (c1, c2->offset, NULL, r);\n }\n \n@@ -623,7 +620,7 @@ aff_combination_expand (aff_tree *comb ATTRIBUTE_UNUSED,\n   aff_tree to_add, current, curre;\n   tree e, rhs;\n   gimple def;\n-  double_int scale;\n+  widest_int scale;\n   void **slot;\n   struct name_expansion *exp;\n \n@@ -768,25 +765,24 @@ free_affine_expand_cache (struct pointer_map_t **cache)\n    is set to true.  */\n \n static bool\n-double_int_constant_multiple_p (double_int val, double_int div,\n-\t\t\t\tbool *mult_set, double_int *mult)\n+wide_int_constant_multiple_p (const widest_int &val, const widest_int &div,\n+\t\t\t      bool *mult_set, widest_int *mult)\n {\n-  double_int rem, cst;\n+  widest_int rem, cst;\n \n-  if (val.is_zero ())\n+  if (val == 0)\n     {\n-      if (*mult_set && !mult->is_zero ())\n+      if (*mult_set && mult != 0)\n \treturn false;\n       *mult_set = true;\n-      *mult = double_int_zero;\n+      *mult = 0;\n       return true;\n     }\n \n-  if (div.is_zero ())\n+  if (div == 0)\n     return false;\n \n-  cst = val.sdivmod (div, FLOOR_DIV_EXPR, &rem);\n-  if (!rem.is_zero ())\n+  if (!wi::multiple_of_p (val, div, SIGNED, &cst))\n     return false;\n \n   if (*mult_set && *mult != cst)\n@@ -802,14 +798,14 @@ double_int_constant_multiple_p (double_int val, double_int div,\n \n bool\n aff_combination_constant_multiple_p (aff_tree *val, aff_tree *div,\n-\t\t\t\t     double_int *mult)\n+\t\t\t\t     widest_int *mult)\n {\n   bool mult_set = false;\n   unsigned i;\n \n-  if (val->n == 0 && val->offset.is_zero ())\n+  if (val->n == 0 && val->offset == 0)\n     {\n-      *mult = double_int_zero;\n+      *mult = 0;\n       return true;\n     }\n   if (val->n != div->n)\n@@ -818,8 +814,8 @@ aff_combination_constant_multiple_p (aff_tree *val, aff_tree *div,\n   if (val->rest || div->rest)\n     return false;\n \n-  if (!double_int_constant_multiple_p (val->offset, div->offset,\n-\t\t\t\t       &mult_set, mult))\n+  if (!wide_int_constant_multiple_p (val->offset, div->offset,\n+\t\t\t\t     &mult_set, mult))\n     return false;\n \n   for (i = 0; i < div->n; i++)\n@@ -828,8 +824,8 @@ aff_combination_constant_multiple_p (aff_tree *val, aff_tree *div,\n \t      = aff_combination_find_elt (val, div->elts[i].val, NULL);\n       if (!elt)\n \treturn false;\n-      if (!double_int_constant_multiple_p (elt->coef, div->elts[i].coef,\n-\t\t\t\t\t   &mult_set, mult))\n+      if (!wide_int_constant_multiple_p (elt->coef, div->elts[i].coef,\n+\t\t\t\t\t &mult_set, mult))\n \treturn false;\n     }\n \n@@ -843,13 +839,13 @@ static void\n print_aff (FILE *file, aff_tree *val)\n {\n   unsigned i;\n-  bool uns = TYPE_UNSIGNED (val->type);\n+  signop sgn = TYPE_SIGN (val->type);\n   if (POINTER_TYPE_P (val->type))\n-    uns = false;\n+    sgn = SIGNED;\n   fprintf (file, \"{\\n  type = \");\n   print_generic_expr (file, val->type, TDF_VOPS|TDF_MEMSYMS);\n   fprintf (file, \"\\n  offset = \");\n-  dump_double_int (file, val->offset, uns);\n+  print_dec (val->offset, file, sgn);\n   if (val->n > 0)\n     {\n       fprintf (file, \"\\n  elements = {\\n\");\n@@ -859,7 +855,7 @@ print_aff (FILE *file, aff_tree *val)\n \t  print_generic_expr (file, val->elts[i].val, TDF_VOPS|TDF_MEMSYMS);\n \n \t  fprintf (file, \" * \");\n-\t  dump_double_int (file, val->elts[i].coef, uns);\n+\t  print_dec (val->elts[i].coef, file, sgn);\n \t  if (i != val->n - 1)\n \t    fprintf (file, \", \\n\");\n \t}\n@@ -887,7 +883,7 @@ debug_aff (aff_tree *val)\n    which REF refers.  */\n \n tree\n-get_inner_reference_aff (tree ref, aff_tree *addr, double_int *size)\n+get_inner_reference_aff (tree ref, aff_tree *addr, widest_int *size)\n {\n   HOST_WIDE_INT bitsize, bitpos;\n   tree toff;\n@@ -908,11 +904,10 @@ get_inner_reference_aff (tree ref, aff_tree *addr, double_int *size)\n       aff_combination_add (addr, &tmp);\n     }\n \n-  aff_combination_const (&tmp, sizetype,\n-\t\t\t double_int::from_shwi (bitpos / BITS_PER_UNIT));\n+  aff_combination_const (&tmp, sizetype, bitpos / BITS_PER_UNIT);\n   aff_combination_add (addr, &tmp);\n \n-  *size = double_int::from_shwi ((bitsize + BITS_PER_UNIT - 1) / BITS_PER_UNIT);\n+  *size = (bitsize + BITS_PER_UNIT - 1) / BITS_PER_UNIT;\n \n   return base;\n }\n@@ -921,26 +916,23 @@ get_inner_reference_aff (tree ref, aff_tree *addr, double_int *size)\n    size SIZE2 at position DIFF cannot overlap.  */\n \n bool\n-aff_comb_cannot_overlap_p (aff_tree *diff, double_int size1, double_int size2)\n+aff_comb_cannot_overlap_p (aff_tree *diff, const widest_int &size1,\n+\t\t\t   const widest_int &size2)\n {\n-  double_int d, bound;\n-\n   /* Unless the difference is a constant, we fail.  */\n   if (diff->n != 0)\n     return false;\n \n-  d = diff->offset;\n-  if (d.is_negative ())\n+  if (wi::neg_p (diff->offset))\n     {\n       /* The second object is before the first one, we succeed if the last\n \t element of the second object is before the start of the first one.  */\n-      bound = d + size2 + double_int_minus_one;\n-      return bound.is_negative ();\n+      return wi::neg_p (diff->offset + size2 - 1);\n     }\n   else\n     {\n       /* We succeed if the second object starts after the first one ends.  */\n-      return size1.sle (d);\n+      return wi::les_p (size1, diff->offset);\n     }\n }\n "}, {"sha": "8c9d990b98dfa86ceaed708c0bb1e7247cb9e9aa", "filename": "gcc/tree-affine.h", "status": "modified", "additions": 13, "deletions": 10, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-affine.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-affine.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-affine.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -20,6 +20,8 @@ along with GCC; see the file COPYING3.  If not see\n /* Affine combination of trees.  We keep track of at most MAX_AFF_ELTS elements\n    to make things simpler; this is sufficient in most cases.  */\n \n+#include \"wide-int.h\"\n+\n #define MAX_AFF_ELTS 8\n \n /* Element of an affine combination.  */\n@@ -30,7 +32,7 @@ struct aff_comb_elt\n   tree val;\n \n   /* Its coefficient in the combination.  */\n-  double_int coef;\n+  widest_int coef;\n };\n \n struct aff_tree\n@@ -39,7 +41,7 @@ struct aff_tree\n   tree type;\n \n   /* Constant offset.  */\n-  double_int offset;\n+  widest_int offset;\n \n   /* Number of elements of the combination.  */\n   unsigned n;\n@@ -58,25 +60,26 @@ struct aff_tree\n   tree rest;\n };\n \n-double_int double_int_ext_for_comb (double_int, aff_tree *);\n-void aff_combination_const (aff_tree *, tree, double_int);\n+widest_int wide_int_ext_for_comb (const widest_int &, aff_tree *);\n+void aff_combination_const (aff_tree *, tree, const widest_int &);\n void aff_combination_elt (aff_tree *, tree, tree);\n-void aff_combination_scale (aff_tree *, double_int);\n+void aff_combination_scale (aff_tree *, const widest_int &);\n void aff_combination_mult (aff_tree *, aff_tree *, aff_tree *);\n void aff_combination_add (aff_tree *, aff_tree *);\n-void aff_combination_add_elt (aff_tree *, tree, double_int);\n+void aff_combination_add_elt (aff_tree *, tree, const widest_int &);\n void aff_combination_remove_elt (aff_tree *, unsigned);\n void aff_combination_convert (aff_tree *, tree);\n void tree_to_aff_combination (tree, tree, aff_tree *);\n tree aff_combination_to_tree (aff_tree *);\n void unshare_aff_combination (aff_tree *);\n-bool aff_combination_constant_multiple_p (aff_tree *, aff_tree *, double_int *);\n+bool aff_combination_constant_multiple_p (aff_tree *, aff_tree *, widest_int *);\n void aff_combination_expand (aff_tree *, struct pointer_map_t **);\n void tree_to_aff_combination_expand (tree, tree, aff_tree *,\n \t\t\t\t     struct pointer_map_t **);\n-tree get_inner_reference_aff (tree, aff_tree *, double_int *);\n+tree get_inner_reference_aff (tree, aff_tree *, widest_int *);\n void free_affine_expand_cache (struct pointer_map_t **);\n-bool aff_comb_cannot_overlap_p (aff_tree *, double_int, double_int);\n+bool aff_comb_cannot_overlap_p (aff_tree *, const widest_int &,\n+\t\t\t\tconst widest_int &);\n \n /* Debugging functions.  */\n void debug_aff (aff_tree *);\n@@ -88,7 +91,7 @@ aff_combination_zero_p (aff_tree *aff)\n   if (!aff)\n     return true;\n \n-  if (aff->n == 0 && aff->offset.is_zero ())\n+  if (aff->n == 0 && aff->offset == 0)\n     return true;\n \n   return false;"}, {"sha": "f62fb40b359e58fa2e3468ee209da10c99f9e81c", "filename": "gcc/tree-call-cdce.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-call-cdce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-call-cdce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-call-cdce.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -205,7 +205,7 @@ check_pow (gimple pow_call)\n         return false;\n       if (REAL_VALUES_LESS (bcv, dconst1))\n         return false;\n-      real_from_integer (&mv, TYPE_MODE (TREE_TYPE (base)), 256, 0, 1);\n+      real_from_integer (&mv, TYPE_MODE (TREE_TYPE (base)), 256, UNSIGNED);\n       if (REAL_VALUES_LESS (mv, bcv))\n         return false;\n       return true;\n@@ -422,7 +422,7 @@ gen_conditions_for_pow_cst_base (tree base, tree expn,\n   REAL_VALUE_TYPE bcv = TREE_REAL_CST (base);\n   gcc_assert (!REAL_VALUES_EQUAL (bcv, dconst1)\n               && !REAL_VALUES_LESS (bcv, dconst1));\n-  real_from_integer (&mv, TYPE_MODE (TREE_TYPE (base)), 256, 0, 1);\n+  real_from_integer (&mv, TYPE_MODE (TREE_TYPE (base)), 256, UNSIGNED);\n   gcc_assert (!REAL_VALUES_LESS (mv, bcv));\n \n   exp_domain = get_domain (0, false, false,"}, {"sha": "fee1ede809e977fb4369b6869eb3997a9fa66e5f", "filename": "gcc/tree-cfg.c", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-cfg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-cfg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-cfg.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -68,6 +68,8 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-ssa-live.h\"\n #include \"omp-low.h\"\n #include \"tree-cfgcleanup.h\"\n+#include \"wide-int.h\"\n+#include \"wide-int-print.h\"\n \n /* This file contains functions for building the Control Flow Graph (CFG)\n    for a function tree.  */\n@@ -1542,12 +1544,12 @@ group_case_labels_stmt (gimple stmt)\n \t{\n \t  tree merge_case = gimple_switch_label (stmt, i);\n \t  basic_block merge_bb = label_to_block (CASE_LABEL (merge_case));\n-\t  double_int bhp1 = tree_to_double_int (base_high) + double_int_one;\n+\t  wide_int bhp1 = wi::add (base_high, 1);\n \n \t  /* Merge the cases if they jump to the same place,\n \t     and their ranges are consecutive.  */\n \t  if (merge_bb == base_bb\n-\t      && tree_to_double_int (CASE_LOW (merge_case)) == bhp1)\n+\t      && wi::eq_p (CASE_LOW (merge_case), bhp1))\n \t    {\n \t      base_high = CASE_HIGH (merge_case) ?\n \t\t  CASE_HIGH (merge_case) : CASE_LOW (merge_case);\n@@ -3651,7 +3653,7 @@ verify_gimple_assign_binary (gimple stmt)\n \t   only allow shifting by a constant multiple of the element size.  */\n \tif (!INTEGRAL_TYPE_P (TREE_TYPE (rhs1_type))\n \t    && (TREE_CODE (rhs2) != INTEGER_CST\n-\t\t|| !div_if_zero_remainder (EXACT_DIV_EXPR, rhs2,\n+\t\t|| !div_if_zero_remainder (rhs2,\n \t\t\t\t\t   TYPE_SIZE (TREE_TYPE (rhs1_type)))))\n \t  {\n \t    error (\"non-element sized vector shift of floating point vector\");\n@@ -7335,13 +7337,13 @@ print_loop (FILE *file, struct loop *loop, int indent, int verbosity)\n   if (loop->any_upper_bound)\n     {\n       fprintf (file, \", upper_bound = \");\n-      dump_double_int (file, loop->nb_iterations_upper_bound, true);\n+      print_decu (loop->nb_iterations_upper_bound, file);\n     }\n \n   if (loop->any_estimate)\n     {\n       fprintf (file, \", estimate = \");\n-      dump_double_int (file, loop->nb_iterations_estimate, true);\n+      print_decu (loop->nb_iterations_estimate, file);\n     }\n   fprintf (file, \")\\n\");\n "}, {"sha": "c78d9410429f391cdfba391888ccc0e070f7ce82", "filename": "gcc/tree-chrec.c", "status": "modified", "additions": 8, "deletions": 12, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-chrec.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-chrec.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-chrec.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -480,7 +480,6 @@ chrec_fold_multiply (tree type,\n static tree\n tree_fold_binomial (tree type, tree n, unsigned int k)\n {\n-  double_int num, denom, idx, di_res;\n   bool overflow;\n   unsigned int i;\n   tree res;\n@@ -491,21 +490,18 @@ tree_fold_binomial (tree type, tree n, unsigned int k)\n   if (k == 1)\n     return fold_convert (type, n);\n \n-  /* Numerator = n.  */\n-  num = TREE_INT_CST (n);\n-\n   /* Check that k <= n.  */\n-  if (num.ult (double_int::from_uhwi (k)))\n+  if (wi::ltu_p (n, k))\n     return NULL_TREE;\n \n   /* Denominator = 2.  */\n-  denom = double_int::from_uhwi (2);\n+  wide_int denom = wi::two (TYPE_PRECISION (TREE_TYPE (n)));\n \n   /* Index = Numerator-1.  */\n-  idx = num - double_int_one;\n+  wide_int idx = wi::sub (n, 1);\n \n   /* Numerator = Numerator*Index = n*(n-1).  */\n-  num = num.mul_with_sign (idx, false, &overflow);\n+  wide_int num = wi::smul (n, idx, &overflow);\n   if (overflow)\n     return NULL_TREE;\n \n@@ -515,17 +511,17 @@ tree_fold_binomial (tree type, tree n, unsigned int k)\n       --idx;\n \n       /* Numerator *= Index.  */\n-      num = num.mul_with_sign (idx, false, &overflow);\n+      num = wi::smul (num, idx, &overflow);\n       if (overflow)\n \treturn NULL_TREE;\n \n       /* Denominator *= i.  */\n-      denom *= double_int::from_uhwi (i);\n+      denom *= i;\n     }\n \n   /* Result = Numerator / Denominator.  */\n-  di_res = num.div (denom, true, EXACT_DIV_EXPR);\n-  res = build_int_cst_wide (type, di_res.low, di_res.high);\n+  wide_int di_res = wi::udiv_trunc (num, denom);\n+  res = wide_int_to_tree (type, di_res);\n   return int_fits_type_p (res, type) ? res : NULL_TREE;\n }\n "}, {"sha": "72ef8e143a2142dd61d81d6208f8a42f83545d50", "filename": "gcc/tree-core.h", "status": "modified", "additions": 21, "deletions": 1, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-core.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-core.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-core.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -758,11 +758,31 @@ struct GTY(()) tree_base {\n \t of the field must be large enough to hold addr_space_t values.  */\n       unsigned address_space : 8;\n     } bits;\n+\n     /* The following fields are present in tree_base to save space.  The\n        nodes using them do not require any of the flags above and so can\n        make better use of the 4-byte sized word.  */\n+\n+    /* The number of HOST_WIDE_INTs in an INTEGER_CST.  */\n+    struct {\n+      /* The number of HOST_WIDE_INTs if the INTEGER_CST is accessed in\n+\t its native precision.  */\n+      unsigned char unextended;\n+\n+      /* The number of HOST_WIDE_INTs if the INTEGER_CST is extended to\n+\t wider precisions based on its TYPE_SIGN.  */\n+      unsigned char extended;\n+\n+      /* The number of HOST_WIDE_INTs if the INTEGER_CST is accessed in\n+\t offset_int precision, with smaller integers being extended\n+\t according to their TYPE_SIGN.  This is equal to one of the two\n+\t fields above but is cached for speed.  */\n+      unsigned char offset;\n+    } int_length;\n+\n     /* VEC length.  This field is only used with TREE_VEC.  */\n     int length;\n+\n     /* SSA version number.  This field is only used with SSA_NAME.  */\n     unsigned int version;\n   } GTY((skip(\"\"))) u;\n@@ -1051,7 +1071,7 @@ struct GTY(()) tree_common {\n \n struct GTY(()) tree_int_cst {\n   struct tree_typed typed;\n-  double_int int_cst;\n+  HOST_WIDE_INT val[1];\n };\n \n "}, {"sha": "55dbf6a65d3799a620e5336f79699295c1f2efb1", "filename": "gcc/tree-data-ref.c", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-data-ref.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-data-ref.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-data-ref.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -783,8 +783,8 @@ dr_analyze_innermost (struct data_reference *dr, struct loop *nest)\n     {\n       if (!integer_zerop (TREE_OPERAND (base, 1)))\n \t{\n-\t  double_int moff = mem_ref_offset (base);\n-\t  tree mofft = double_int_to_tree (sizetype, moff);\n+\t  offset_int moff = mem_ref_offset (base);\n+\t  tree mofft = wide_int_to_tree (sizetype, moff);\n \t  if (!poffset)\n \t    poffset = mofft;\n \t  else\n@@ -1380,10 +1380,10 @@ dr_may_alias_p (const struct data_reference *a, const struct data_reference *b,\n   if (!loop_nest)\n     {\n       aff_tree off1, off2;\n-      double_int size1, size2;\n+      widest_int size1, size2;\n       get_inner_reference_aff (DR_REF (a), &off1, &size1);\n       get_inner_reference_aff (DR_REF (b), &off2, &size2);\n-      aff_combination_scale (&off1, double_int_minus_one);\n+      aff_combination_scale (&off1, -1);\n       aff_combination_add (&off2, &off1);\n       if (aff_comb_cannot_overlap_p (&off2, size1, size2))\n \treturn false;\n@@ -1758,15 +1758,15 @@ analyze_ziv_subscript (tree chrec_a,\n static tree\n max_stmt_executions_tree (struct loop *loop)\n {\n-  double_int nit;\n+  widest_int nit;\n \n   if (!max_stmt_executions (loop, &nit))\n     return chrec_dont_know;\n \n-  if (!double_int_fits_to_tree_p (unsigned_type_node, nit))\n+  if (!wi::fits_to_tree_p (nit, unsigned_type_node))\n     return chrec_dont_know;\n \n-  return double_int_to_tree (unsigned_type_node, nit);\n+  return wide_int_to_tree (unsigned_type_node, nit);\n }\n \n /* Determine whether the CHREC is always positive/negative.  If the expression"}, {"sha": "77f3cc0a98dfe9affe14b696d2293598c5072243", "filename": "gcc/tree-dfa.c", "status": "modified", "additions": 48, "deletions": 53, "changes": 101, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-dfa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-dfa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dfa.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -48,6 +48,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-inline.h\"\n #include \"tree-pass.h\"\n #include \"params.h\"\n+#include \"wide-int.h\"\n \n /* Build and maintain data flow information for trees.  */\n \n@@ -389,10 +390,10 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t\t\t HOST_WIDE_INT *psize,\n \t\t\t HOST_WIDE_INT *pmax_size)\n {\n-  double_int bitsize = double_int_minus_one;\n-  double_int maxsize;\n+  offset_int bitsize = -1;\n+  offset_int maxsize;\n   tree size_tree = NULL_TREE;\n-  double_int bit_offset = double_int_zero;\n+  offset_int bit_offset = 0;\n   bool seen_variable_array_ref = false;\n \n   /* First get the final access size from just the outermost expression.  */\n@@ -406,11 +407,11 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n       if (mode == BLKmode)\n \tsize_tree = TYPE_SIZE (TREE_TYPE (exp));\n       else\n-\tbitsize = double_int::from_uhwi (GET_MODE_BITSIZE (mode));\n+\tbitsize = int (GET_MODE_BITSIZE (mode));\n     }\n   if (size_tree != NULL_TREE\n       && TREE_CODE (size_tree) == INTEGER_CST)\n-    bitsize = tree_to_double_int (size_tree);\n+    bitsize = wi::to_offset (size_tree);\n \n   /* Initially, maxsize is the same as the accessed element size.\n      In the following it will only grow (or become -1).  */\n@@ -423,7 +424,7 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n       switch (TREE_CODE (exp))\n \t{\n \tcase BIT_FIELD_REF:\n-\t  bit_offset += tree_to_double_int (TREE_OPERAND (exp, 2));\n+\t  bit_offset += wi::to_offset (TREE_OPERAND (exp, 2));\n \t  break;\n \n \tcase COMPONENT_REF:\n@@ -433,17 +434,16 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \n \t    if (this_offset && TREE_CODE (this_offset) == INTEGER_CST)\n \t      {\n-\t\tdouble_int doffset = tree_to_double_int (this_offset);\n-\t\tdoffset = doffset.lshift (BITS_PER_UNIT == 8\n-\t\t\t\t\t  ? 3 : exact_log2 (BITS_PER_UNIT));\n-\t\tdoffset += tree_to_double_int (DECL_FIELD_BIT_OFFSET (field));\n-\t\tbit_offset = bit_offset + doffset;\n+\t\toffset_int woffset = wi::lshift (wi::to_offset (this_offset),\n+\t\t\t\t\t\t LOG2_BITS_PER_UNIT);\n+\t\twoffset += wi::to_offset (DECL_FIELD_BIT_OFFSET (field));\n+\t\tbit_offset += woffset;\n \n \t\t/* If we had seen a variable array ref already and we just\n \t\t   referenced the last field of a struct or a union member\n \t\t   then we have to adjust maxsize by the padding at the end\n \t\t   of our field.  */\n-\t\tif (seen_variable_array_ref && !maxsize.is_minus_one ())\n+\t\tif (seen_variable_array_ref && maxsize != -1)\n \t\t  {\n \t\t    tree stype = TREE_TYPE (TREE_OPERAND (exp, 0));\n \t\t    tree next = DECL_CHAIN (field);\n@@ -458,16 +458,13 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t\t\t    || TREE_CODE (fsize) != INTEGER_CST\n \t\t\t    || ssize == NULL\n \t\t\t    || TREE_CODE (ssize) != INTEGER_CST)\n-\t\t\t  maxsize = double_int_minus_one;\n+\t\t\t  maxsize = -1;\n \t\t\telse\n \t\t\t  {\n-\t\t\t    double_int tem = tree_to_double_int (ssize)\n-\t\t\t\t\t     - tree_to_double_int (fsize);\n-\t\t\t    if (BITS_PER_UNIT == 8)\n-\t\t\t      tem = tem.lshift (3);\n-\t\t\t    else\n-\t\t\t      tem *= double_int::from_uhwi (BITS_PER_UNIT);\n-\t\t\t    tem -= doffset;\n+\t\t\t    offset_int tem = (wi::to_offset (ssize)\n+\t\t\t\t\t      - wi::to_offset (fsize));\n+\t\t\t    tem = wi::lshift (tem, LOG2_BITS_PER_UNIT);\n+\t\t\t    tem -= woffset;\n \t\t\t    maxsize += tem;\n \t\t\t  }\n \t\t      }\n@@ -479,12 +476,12 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t\t/* We need to adjust maxsize to the whole structure bitsize.\n \t\t   But we can subtract any constant offset seen so far,\n \t\t   because that would get us out of the structure otherwise.  */\n-\t\tif (!maxsize.is_minus_one ()\n+\t\tif (maxsize != -1\n \t\t    && csize\n \t\t    && TREE_CODE (csize) == INTEGER_CST)\n-\t\t  maxsize = tree_to_double_int (csize) - bit_offset;\n+\t\t  maxsize = wi::to_offset (csize) - bit_offset;\n \t\telse\n-\t\t  maxsize = double_int_minus_one;\n+\t\t  maxsize = -1;\n \t      }\n \t  }\n \t  break;\n@@ -502,13 +499,12 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t\t&& (unit_size = array_ref_element_size (exp),\n \t\t    TREE_CODE (unit_size) == INTEGER_CST))\n \t      {\n-\t\tdouble_int doffset\n-\t\t  = (TREE_INT_CST (index) - TREE_INT_CST (low_bound))\n-\t\t    .sext (TYPE_PRECISION (TREE_TYPE (index)));\n-\t\tdoffset *= tree_to_double_int (unit_size);\n-\t\tdoffset = doffset.lshift (BITS_PER_UNIT == 8\n-\t\t\t\t\t  ? 3 : exact_log2 (BITS_PER_UNIT));\n-\t\tbit_offset = bit_offset + doffset;\n+\t\toffset_int woffset\n+\t\t  = wi::sext (wi::to_offset (index) - wi::to_offset (low_bound),\n+\t\t\t      TYPE_PRECISION (TREE_TYPE (index)));\n+\t\twoffset *= wi::to_offset (unit_size);\n+\t\twoffset = wi::lshift (woffset, LOG2_BITS_PER_UNIT);\n+\t\tbit_offset += woffset;\n \n \t\t/* An array ref with a constant index up in the structure\n \t\t   hierarchy will constrain the size of any variable array ref\n@@ -521,12 +517,12 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t\t/* We need to adjust maxsize to the whole array bitsize.\n \t\t   But we can subtract any constant offset seen so far,\n \t\t   because that would get us outside of the array otherwise.  */\n-\t\tif (!maxsize.is_minus_one ()\n+\t\tif (maxsize != -1\n \t\t    && asize\n \t\t    && TREE_CODE (asize) == INTEGER_CST)\n-\t\t  maxsize = tree_to_double_int (asize) - bit_offset;\n+\t\t  maxsize = wi::to_offset (asize) - bit_offset;\n \t\telse\n-\t\t  maxsize = double_int_minus_one;\n+\t\t  maxsize = -1;\n \n \t\t/* Remember that we have seen an array ref with a variable\n \t\t   index.  */\n@@ -552,8 +548,8 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t      && (TMR_INDEX (exp) || TMR_INDEX2 (exp)))\n \t    {\n \t      exp = TREE_OPERAND (TMR_BASE (exp), 0);\n-\t      bit_offset = double_int_zero;\n-\t      maxsize = double_int_minus_one;\n+\t      bit_offset = 0;\n+\t      maxsize = -1;\n \t      goto done;\n \t    }\n \t  /* Fallthru.  */\n@@ -569,12 +565,12 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t     base type boundary.  This needs to include possible trailing\n \t     padding that is there for alignment purposes.  */\n \t  if (seen_variable_array_ref\n-\t      && !maxsize.is_minus_one ()\n+\t      && maxsize != -1\n \t      && (TYPE_SIZE (TREE_TYPE (exp)) == NULL_TREE\n \t\t  || TREE_CODE (TYPE_SIZE (TREE_TYPE (exp))) != INTEGER_CST\n \t\t  || (bit_offset + maxsize\n-\t\t      == tree_to_double_int (TYPE_SIZE (TREE_TYPE (exp))))))\n-\t    maxsize = double_int_minus_one;\n+\t\t      == wi::to_offset (TYPE_SIZE (TREE_TYPE (exp))))))\n+\t    maxsize = -1;\n \n \t  /* Hand back the decl for MEM[&decl, off].  */\n \t  if (TREE_CODE (TREE_OPERAND (exp, 0)) == ADDR_EXPR)\n@@ -583,11 +579,10 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \t\texp = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n \t      else\n \t\t{\n-\t\t  double_int off = mem_ref_offset (exp);\n-\t\t  off = off.lshift (BITS_PER_UNIT == 8\n-\t\t\t\t    ? 3 : exact_log2 (BITS_PER_UNIT));\n+\t\t  offset_int off = mem_ref_offset (exp);\n+\t\t  off = wi::lshift (off, LOG2_BITS_PER_UNIT);\n \t\t  off += bit_offset;\n-\t\t  if (off.fits_shwi ())\n+\t\t  if (wi::fits_shwi_p (off))\n \t\t    {\n \t\t      bit_offset = off;\n \t\t      exp = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n@@ -605,15 +600,15 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \n   /* We need to deal with variable arrays ending structures.  */\n   if (seen_variable_array_ref\n-      && !maxsize.is_minus_one ()\n+      && maxsize != -1\n       && (TYPE_SIZE (TREE_TYPE (exp)) == NULL_TREE\n \t  || TREE_CODE (TYPE_SIZE (TREE_TYPE (exp))) != INTEGER_CST\n \t  || (bit_offset + maxsize\n-\t      == tree_to_double_int (TYPE_SIZE (TREE_TYPE (exp))))))\n-    maxsize = double_int_minus_one;\n+\t      == wi::to_offset (TYPE_SIZE (TREE_TYPE (exp))))))\n+    maxsize = -1;\n \n  done:\n-  if (!bitsize.fits_shwi () || bitsize.is_negative ())\n+  if (!wi::fits_shwi_p (bitsize) || wi::neg_p (bitsize))\n     {\n       *poffset = 0;\n       *psize = -1;\n@@ -624,7 +619,7 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n \n   *psize = bitsize.to_shwi ();\n \n-  if (!bit_offset.fits_shwi ())\n+  if (!wi::fits_shwi_p (bit_offset))\n     {\n       *poffset = 0;\n       *pmax_size = -1;\n@@ -638,27 +633,27 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n     {\n       /* If maxsize is unknown adjust it according to the size of the\n          base decl.  */\n-      if (maxsize.is_minus_one ()\n+      if (maxsize == -1\n \t  && DECL_SIZE (exp)\n \t  && TREE_CODE (DECL_SIZE (exp)) == INTEGER_CST)\n-\tmaxsize = tree_to_double_int (DECL_SIZE (exp)) - bit_offset;\n+\tmaxsize = wi::to_offset (DECL_SIZE (exp)) - bit_offset;\n     }\n   else if (CONSTANT_CLASS_P (exp))\n     {\n       /* If maxsize is unknown adjust it according to the size of the\n          base type constant.  */\n-      if (maxsize.is_minus_one ()\n+      if (maxsize == -1\n \t  && TYPE_SIZE (TREE_TYPE (exp))\n \t  && TREE_CODE (TYPE_SIZE (TREE_TYPE (exp))) == INTEGER_CST)\n-\tmaxsize = tree_to_double_int (TYPE_SIZE (TREE_TYPE (exp)))\n-\t\t  - bit_offset;\n+\tmaxsize = (wi::to_offset (TYPE_SIZE (TREE_TYPE (exp)))\n+\t\t   - bit_offset);\n     }\n \n   /* ???  Due to negative offsets in ARRAY_REF we can end up with\n      negative bit_offset here.  We might want to store a zero offset\n      in this case.  */\n   *poffset = bit_offset.to_shwi ();\n-  if (!maxsize.fits_shwi () || maxsize.is_negative ())\n+  if (!wi::fits_shwi_p (maxsize) || wi::neg_p (maxsize))\n     *pmax_size = -1;\n   else\n     *pmax_size = maxsize.to_shwi ();"}, {"sha": "7b076c7f73f4ca8381218e1b84fae05a673ca0b7", "filename": "gcc/tree-dfa.h", "status": "modified", "additions": 8, "deletions": 11, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-dfa.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-dfa.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dfa.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -102,11 +102,10 @@ get_addr_base_and_unit_offset_1 (tree exp, HOST_WIDE_INT *poffset,\n \t\t&& (unit_size = array_ref_element_size (exp),\n \t\t    TREE_CODE (unit_size) == INTEGER_CST))\n \t      {\n-\t\tdouble_int doffset\n-\t\t  = (TREE_INT_CST (index) - TREE_INT_CST (low_bound))\n-\t\t    .sext (TYPE_PRECISION (TREE_TYPE (index)));\n-\t\tdoffset *= tree_to_double_int (unit_size);\n-\t\tbyte_offset += doffset.to_shwi ();\n+\t\toffset_int woffset\n+\t\t  = offset_int::from (wi::sub (index, low_bound), SIGNED);\n+\t\twoffset *= wi::to_offset (unit_size);\n+\t\tbyte_offset += woffset.to_shwi ();\n \t      }\n \t    else\n \t      return NULL_TREE;\n@@ -135,9 +134,8 @@ get_addr_base_and_unit_offset_1 (tree exp, HOST_WIDE_INT *poffset,\n \t      {\n \t\tif (!integer_zerop (TREE_OPERAND (exp, 1)))\n \t\t  {\n-\t\t    double_int off = mem_ref_offset (exp);\n-\t\t    gcc_assert (off.high == -1 || off.high == 0);\n-\t\t    byte_offset += off.to_shwi ();\n+\t\t    offset_int off = mem_ref_offset (exp);\n+\t\t    byte_offset += off.to_short_addr ();\n \t\t  }\n \t\texp = TREE_OPERAND (base, 0);\n \t      }\n@@ -158,9 +156,8 @@ get_addr_base_and_unit_offset_1 (tree exp, HOST_WIDE_INT *poffset,\n \t\t  return NULL_TREE;\n \t\tif (!integer_zerop (TMR_OFFSET (exp)))\n \t\t  {\n-\t\t    double_int off = mem_ref_offset (exp);\n-\t\t    gcc_assert (off.high == -1 || off.high == 0);\n-\t\t    byte_offset += off.to_shwi ();\n+\t\t    offset_int off = mem_ref_offset (exp);\n+\t\t    byte_offset += off.to_short_addr ();\n \t\t  }\n \t\texp = TREE_OPERAND (base, 0);\n \t      }"}, {"sha": "9f89a04295ac9e0b27a8d550186d366b840727b0", "filename": "gcc/tree-dump.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-dump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-dump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dump.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -30,6 +30,8 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-iterator.h\"\n #include \"tree-pretty-print.h\"\n #include \"tree-cfg.h\"\n+#include \"wide-int.h\"\n+#include \"wide-int-print.h\"\n \n static unsigned int queue (dump_info_p, const_tree, int);\n static void dump_index (dump_info_p, unsigned int);\n@@ -561,9 +563,8 @@ dequeue_and_dump (dump_info_p di)\n       break;\n \n     case INTEGER_CST:\n-      if (TREE_INT_CST_HIGH (t))\n-\tdump_int (di, \"high\", TREE_INT_CST_HIGH (t));\n-      dump_int (di, \"low\", TREE_INT_CST_LOW (t));\n+      fprintf (di->stream, \"int: \");\n+      print_decs (t, di->stream);\n       break;\n \n     case STRING_CST:"}, {"sha": "624f2775f7c59afe76687b316a9015f6c7635641", "filename": "gcc/tree-eh.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-eh.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-eh.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-eh.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2652,14 +2652,14 @@ tree_could_trap_p (tree expr)\n       if (TREE_CODE (TREE_OPERAND (expr, 0)) == ADDR_EXPR)\n \t{\n \t  tree base = TREE_OPERAND (TREE_OPERAND (expr, 0), 0);\n-\t  double_int off = mem_ref_offset (expr);\n-\t  if (off.is_negative ())\n+\t  offset_int off = mem_ref_offset (expr);\n+\t  if (wi::neg_p (off, SIGNED))\n \t    return true;\n \t  if (TREE_CODE (base) == STRING_CST)\n-\t    return double_int::from_uhwi (TREE_STRING_LENGTH (base)).ule (off);\n+\t    return wi::leu_p (TREE_STRING_LENGTH (base), off);\n \t  else if (DECL_SIZE_UNIT (base) == NULL_TREE\n \t\t   || TREE_CODE (DECL_SIZE_UNIT (base)) != INTEGER_CST\n-\t\t   || tree_to_double_int (DECL_SIZE_UNIT (base)).ule (off))\n+\t\t   || wi::leu_p (wi::to_offset (DECL_SIZE_UNIT (base)), off))\n \t    return true;\n \t  /* Now we are sure the first byte of the access is inside\n \t     the object.  */"}, {"sha": "987e81506b7c969c8a821e4c28f088499f0a10ec", "filename": "gcc/tree-inline.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-inline.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -858,8 +858,7 @@ remap_gimple_op_r (tree *tp, int *walk_subtrees, void *data)\n \t*walk_subtrees = 0;\n \n       else if (TREE_CODE (*tp) == INTEGER_CST)\n-\t*tp = build_int_cst_wide (new_type, TREE_INT_CST_LOW (*tp),\n-\t\t\t\t  TREE_INT_CST_HIGH (*tp));\n+\t*tp = wide_int_to_tree (new_type, *tp);\n       else\n \t{\n \t  *tp = copy_node (*tp);\n@@ -1037,8 +1036,7 @@ copy_tree_body_r (tree *tp, int *walk_subtrees, void *data)\n \t*walk_subtrees = 0;\n \n       else if (TREE_CODE (*tp) == INTEGER_CST)\n-\t*tp = build_int_cst_wide (new_type, TREE_INT_CST_LOW (*tp),\n-\t\t\t\t  TREE_INT_CST_HIGH (*tp));\n+\t*tp = wide_int_to_tree (new_type, *tp);\n       else\n \t{\n \t  *tp = copy_node (*tp);"}, {"sha": "3c606b02d41a9a824be5de22e40b654faa454dfc", "filename": "gcc/tree-object-size.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-object-size.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-object-size.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-object-size.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -154,7 +154,7 @@ compute_object_offset (const_tree expr, const_tree var)\n \n     case MEM_REF:\n       gcc_assert (TREE_CODE (TREE_OPERAND (expr, 0)) == ADDR_EXPR);\n-      return double_int_to_tree (sizetype, mem_ref_offset (expr));\n+      return wide_int_to_tree (sizetype, mem_ref_offset (expr));\n \n     default:\n       return error_mark_node;\n@@ -204,10 +204,10 @@ addr_object_size (struct object_size_info *osi, const_tree ptr,\n \t}\n       if (sz != unknown[object_size_type])\n \t{\n-\t  double_int dsz = double_int::from_uhwi (sz) - mem_ref_offset (pt_var);\n-\t  if (dsz.is_negative ())\n+\t  offset_int dsz = wi::sub (sz, mem_ref_offset (pt_var));\n+\t  if (wi::neg_p (dsz))\n \t    sz = 0;\n-\t  else if (dsz.fits_uhwi ())\n+\t  else if (wi::fits_uhwi_p (dsz))\n \t    sz = dsz.to_uhwi ();\n \t  else\n \t    sz = unknown[object_size_type];"}, {"sha": "2cb47db4e5186315cbd47138851c739a5ad1fa4b", "filename": "gcc/tree-predcom.c", "status": "modified", "additions": 20, "deletions": 20, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-predcom.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-predcom.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-predcom.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -222,6 +222,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-pass.h\"\n #include \"tree-affine.h\"\n #include \"tree-inline.h\"\n+#include \"wide-int-print.h\"\n \n /* The maximum number of iterations between the considered memory\n    references.  */\n@@ -249,7 +250,7 @@ typedef struct dref_d\n   unsigned distance;\n \n   /* Number of iterations offset from the first reference in the component.  */\n-  double_int offset;\n+  widest_int offset;\n \n   /* Number of the reference in a component, in dominance ordering.  */\n   unsigned pos;\n@@ -365,7 +366,7 @@ dump_dref (FILE *file, dref ref)\n \t       DR_IS_READ (ref->ref) ? \"\" : \", write\");\n \n       fprintf (file, \"      offset \");\n-      dump_double_int (file, ref->offset, false);\n+      print_decs (ref->offset, file);\n       fprintf (file, \"\\n\");\n \n       fprintf (file, \"      distance %u\\n\", ref->distance);\n@@ -638,7 +639,7 @@ aff_combination_dr_offset (struct data_reference *dr, aff_tree *offset)\n \n   tree_to_aff_combination_expand (DR_OFFSET (dr), type, offset,\n \t\t\t\t  &name_expansions);\n-  aff_combination_const (&delta, type, tree_to_double_int (DR_INIT (dr)));\n+  aff_combination_const (&delta, type, wi::to_widest (DR_INIT (dr)));\n   aff_combination_add (offset, &delta);\n }\n \n@@ -650,7 +651,7 @@ aff_combination_dr_offset (struct data_reference *dr, aff_tree *offset)\n \n static bool\n determine_offset (struct data_reference *a, struct data_reference *b,\n-\t\t  double_int *off)\n+\t\t  widest_int *off)\n {\n   aff_tree diff, baseb, step;\n   tree typea, typeb;\n@@ -671,7 +672,7 @@ determine_offset (struct data_reference *a, struct data_reference *b,\n     {\n       /* If the references have loop invariant address, check that they access\n \t exactly the same location.  */\n-      *off = double_int_zero;\n+      *off = 0;\n       return (operand_equal_p (DR_OFFSET (a), DR_OFFSET (b), 0)\n \t      && operand_equal_p (DR_INIT (a), DR_INIT (b), 0));\n     }\n@@ -680,7 +681,7 @@ determine_offset (struct data_reference *a, struct data_reference *b,\n      is a multiple of step.  */\n   aff_combination_dr_offset (a, &diff);\n   aff_combination_dr_offset (b, &baseb);\n-  aff_combination_scale (&baseb, double_int_minus_one);\n+  aff_combination_scale (&baseb, -1);\n   aff_combination_add (&diff, &baseb);\n \n   tree_to_aff_combination_expand (DR_STEP (a), TREE_TYPE (DR_STEP (a)),\n@@ -757,7 +758,7 @@ split_data_refs_to_components (struct loop *loop,\n \n   FOR_EACH_VEC_ELT (depends, i, ddr)\n     {\n-      double_int dummy_off;\n+      widest_int dummy_off;\n \n       if (DDR_ARE_DEPENDENT (ddr) == chrec_known)\n \tcontinue;\n@@ -827,7 +828,7 @@ split_data_refs_to_components (struct loop *loop,\n       dataref = XCNEW (struct dref_d);\n       dataref->ref = dr;\n       dataref->stmt = DR_STMT (dr);\n-      dataref->offset = double_int_zero;\n+      dataref->offset = 0;\n       dataref->distance = 0;\n \n       dataref->always_accessed\n@@ -883,7 +884,7 @@ suitable_component_p (struct loop *loop, struct component *comp)\n   first = comp->refs[0];\n   ok = suitable_reference_p (first->ref, &comp->comp_step);\n   gcc_assert (ok);\n-  first->offset = double_int_zero;\n+  first->offset = 0;\n \n   for (i = 1; comp->refs.iterate (i, &a); i++)\n     {\n@@ -947,7 +948,7 @@ order_drefs (const void *a, const void *b)\n {\n   const dref *const da = (const dref *) a;\n   const dref *const db = (const dref *) b;\n-  int offcmp = (*da)->offset.scmp ((*db)->offset);\n+  int offcmp = wi::cmps ((*da)->offset, (*db)->offset);\n \n   if (offcmp != 0)\n     return offcmp;\n@@ -969,16 +970,15 @@ static void\n add_ref_to_chain (chain_p chain, dref ref)\n {\n   dref root = get_chain_root (chain);\n-  double_int dist;\n \n-  gcc_assert (root->offset.sle (ref->offset));\n-  dist = ref->offset - root->offset;\n-  if (double_int::from_uhwi (MAX_DISTANCE).ule (dist))\n+  gcc_assert (wi::les_p (root->offset, ref->offset));\n+  widest_int dist = ref->offset - root->offset;\n+  if (wi::leu_p (MAX_DISTANCE, dist))\n     {\n       free (ref);\n       return;\n     }\n-  gcc_assert (dist.fits_uhwi ());\n+  gcc_assert (wi::fits_uhwi_p (dist));\n \n   chain->refs.safe_push (ref);\n \n@@ -1073,7 +1073,7 @@ valid_initializer_p (struct data_reference *ref,\n \t\t     unsigned distance, struct data_reference *root)\n {\n   aff_tree diff, base, step;\n-  double_int off;\n+  widest_int off;\n \n   /* Both REF and ROOT must be accessing the same object.  */\n   if (!operand_equal_p (DR_BASE_ADDRESS (ref), DR_BASE_ADDRESS (root), 0))\n@@ -1093,15 +1093,15 @@ valid_initializer_p (struct data_reference *ref,\n      -DISTANCE-th iteration.  */\n   aff_combination_dr_offset (root, &diff);\n   aff_combination_dr_offset (ref, &base);\n-  aff_combination_scale (&base, double_int_minus_one);\n+  aff_combination_scale (&base, -1);\n   aff_combination_add (&diff, &base);\n \n   tree_to_aff_combination_expand (DR_STEP (root), TREE_TYPE (DR_STEP (root)),\n \t\t\t\t  &step, &name_expansions);\n   if (!aff_combination_constant_multiple_p (&diff, &step, &off))\n     return false;\n \n-  if (off != double_int::from_uhwi (distance))\n+  if (off != distance)\n     return false;\n \n   return true;\n@@ -1229,7 +1229,7 @@ determine_roots_comp (struct loop *loop,\n   unsigned i;\n   dref a;\n   chain_p chain = NULL;\n-  double_int last_ofs = double_int_zero;\n+  widest_int last_ofs = 0;\n \n   /* Invariants are handled specially.  */\n   if (comp->comp_step == RS_INVARIANT)\n@@ -1244,7 +1244,7 @@ determine_roots_comp (struct loop *loop,\n   FOR_EACH_VEC_ELT (comp->refs, i, a)\n     {\n       if (!chain || DR_IS_WRITE (a->ref)\n-\t  || double_int::from_uhwi (MAX_DISTANCE).ule (a->offset - last_ofs))\n+\t  || wi::leu_p (MAX_DISTANCE, a->offset - last_ofs))\n \t{\n \t  if (nontrivial_chain_p (chain))\n \t    {"}, {"sha": "d516a9ddaa092b6ad9799184b6cdd571ba896aac", "filename": "gcc/tree-pretty-print.c", "status": "modified", "additions": 22, "deletions": 8, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pretty-print.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -36,6 +36,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"dumpfile.h\"\n #include \"value-prof.h\"\n #include \"predict.h\"\n+#include \"wide-int-print.h\"\n \n #include <new>                           // For placement-new.\n \n@@ -1238,9 +1239,22 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n \t  pp_wide_integer (buffer, TREE_INT_CST_LOW (node));\n \t  pp_string (buffer, \"B\"); /* pseudo-unit */\n \t}\n+      else if (tree_fits_shwi_p (node))\n+\tpp_wide_integer (buffer, tree_to_shwi (node));\n+      else if (tree_fits_uhwi_p (node))\n+\tpp_unsigned_wide_integer (buffer, tree_to_uhwi (node));\n       else\n-\tpp_double_int (buffer, tree_to_double_int (node),\n-\t\t       TYPE_UNSIGNED (TREE_TYPE (node)));\n+\t{\n+\t  wide_int val = node;\n+\n+\t  if (wi::neg_p (val, TYPE_SIGN (TREE_TYPE (node))))\n+\t    {\n+\t      pp_minus (buffer);\n+\t      val = -val;\n+\t    }\n+\t  print_hex (val, pp_buffer (buffer)->digit_buffer);\n+\t  pp_string (buffer, pp_buffer (buffer)->digit_buffer);\n+\t}\n       if (TREE_OVERFLOW (node))\n \tpp_string (buffer, \"(OVF)\");\n       break;\n@@ -1489,7 +1503,7 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n \ttree field, val;\n \tbool is_struct_init = false;\n \tbool is_array_init = false;\n-\tdouble_int curidx = double_int_zero;\n+\twidest_int curidx;\n \tpp_left_brace (buffer);\n \tif (TREE_CLOBBER_P (node))\n \t  pp_string (buffer, \"CLOBBER\");\n@@ -1504,7 +1518,7 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n \t  {\n \t    tree minv = TYPE_MIN_VALUE (TYPE_DOMAIN (TREE_TYPE (node)));\n \t    is_array_init = true;\n-\t    curidx = tree_to_double_int (minv);\n+\t    curidx = wi::to_widest (minv);\n \t  }\n \tFOR_EACH_CONSTRUCTOR_ELT (CONSTRUCTOR_ELTS (node), ix, field, val)\n \t  {\n@@ -1518,7 +1532,7 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n \t\t  }\n \t\telse if (is_array_init\n \t\t\t && (TREE_CODE (field) != INTEGER_CST\n-\t\t\t     || tree_to_double_int (field) != curidx))\n+\t\t\t     || curidx != wi::to_widest (field)))\n \t\t  {\n \t\t    pp_left_bracket (buffer);\n \t\t    if (TREE_CODE (field) == RANGE_EXPR)\n@@ -1529,17 +1543,17 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n \t\t\tdump_generic_node (buffer, TREE_OPERAND (field, 1), spc,\n \t\t\t\t\t   flags, false);\n \t\t\tif (TREE_CODE (TREE_OPERAND (field, 1)) == INTEGER_CST)\n-\t\t\t  curidx = tree_to_double_int (TREE_OPERAND (field, 1));\n+\t\t\t  curidx = wi::to_widest (TREE_OPERAND (field, 1));\n \t\t      }\n \t\t    else\n \t\t      dump_generic_node (buffer, field, spc, flags, false);\n \t\t    if (TREE_CODE (field) == INTEGER_CST)\n-\t\t      curidx = tree_to_double_int (field);\n+\t\t      curidx = wi::to_widest (field);\n \t\t    pp_string (buffer, \"]=\");\n \t\t  }\n \t      }\n             if (is_array_init)\n-\t      curidx += double_int_one;\n+\t      curidx += 1;\n \t    if (val && TREE_CODE (val) == ADDR_EXPR)\n \t      if (TREE_CODE (TREE_OPERAND (val, 0)) == FUNCTION_DECL)\n \t\tval = TREE_OPERAND (val, 0);"}, {"sha": "af7230829629e4625cd1e55e0f6b760cf39e87fc", "filename": "gcc/tree-scalar-evolution.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-scalar-evolution.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-scalar-evolution.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-scalar-evolution.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1428,7 +1428,7 @@ simplify_peeled_chrec (struct loop *loop, tree arg, tree init_cond)\n   tree_to_aff_combination_expand (left, type, &aff1, &peeled_chrec_map);\n   tree_to_aff_combination_expand (step_val, type, &aff2, &peeled_chrec_map);\n   free_affine_expand_cache (&peeled_chrec_map);\n-  aff_combination_scale (&aff2, double_int_minus_one);\n+  aff_combination_scale (&aff2, -1);\n   aff_combination_add (&aff1, &aff2);\n \n   /* Transform (init, {left, right}_LOOP)_LOOP to {init, right}_LOOP"}, {"sha": "866afcf02658105b75efaecf41e0448659c0abd5", "filename": "gcc/tree-ssa-address.c", "status": "modified", "additions": 21, "deletions": 22, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-address.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-address.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-address.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -208,15 +208,15 @@ addr_for_mem_ref (struct mem_address *addr, addr_space_t as,\n   struct mem_addr_template *templ;\n \n   if (addr->step && !integer_onep (addr->step))\n-    st = immed_double_int_const (tree_to_double_int (addr->step), pointer_mode);\n+    st = immed_wide_int_const (addr->step, pointer_mode);\n   else\n     st = NULL_RTX;\n \n   if (addr->offset && !integer_zerop (addr->offset))\n-    off = immed_double_int_const\n-\t    (tree_to_double_int (addr->offset)\n-\t     .sext (TYPE_PRECISION (TREE_TYPE (addr->offset))),\n-\t     pointer_mode);\n+    {\n+      offset_int dc = offset_int::from (addr->offset, SIGNED);\n+      off = immed_wide_int_const (dc, pointer_mode);\n+    }\n   else\n     off = NULL_RTX;\n \n@@ -424,7 +424,7 @@ move_fixed_address_to_symbol (struct mem_address *parts, aff_tree *addr)\n \n   for (i = 0; i < addr->n; i++)\n     {\n-      if (!addr->elts[i].coef.is_one ())\n+      if (addr->elts[i].coef != 1)\n \tcontinue;\n \n       val = addr->elts[i].val;\n@@ -452,7 +452,7 @@ move_hint_to_base (tree type, struct mem_address *parts, tree base_hint,\n \n   for (i = 0; i < addr->n; i++)\n     {\n-      if (!addr->elts[i].coef.is_one ())\n+      if (addr->elts[i].coef != 1)\n \tcontinue;\n \n       val = addr->elts[i].val;\n@@ -484,7 +484,7 @@ move_pointer_to_base (struct mem_address *parts, aff_tree *addr)\n \n   for (i = 0; i < addr->n; i++)\n     {\n-      if (!addr->elts[i].coef.is_one ())\n+      if (addr->elts[i].coef != 1)\n \tcontinue;\n \n       val = addr->elts[i].val;\n@@ -520,7 +520,7 @@ move_variant_to_index (struct mem_address *parts, aff_tree *addr, tree v)\n     return;\n \n   parts->index = fold_convert (sizetype, val);\n-  parts->step = double_int_to_tree (sizetype, addr->elts[i].coef);\n+  parts->step = wide_int_to_tree (sizetype, addr->elts[i].coef);\n   aff_combination_remove_elt (addr, i);\n }\n \n@@ -563,16 +563,15 @@ most_expensive_mult_to_index (tree type, struct mem_address *parts,\n   addr_space_t as = TYPE_ADDR_SPACE (type);\n   enum machine_mode address_mode = targetm.addr_space.address_mode (as);\n   HOST_WIDE_INT coef;\n-  double_int best_mult, amult, amult_neg;\n   unsigned best_mult_cost = 0, acost;\n   tree mult_elt = NULL_TREE, elt;\n   unsigned i, j;\n   enum tree_code op_code;\n \n-  best_mult = double_int_zero;\n+  offset_int best_mult = 0;\n   for (i = 0; i < addr->n; i++)\n     {\n-      if (!addr->elts[i].coef.fits_shwi ())\n+      if (!wi::fits_shwi_p (addr->elts[i].coef))\n \tcontinue;\n \n       coef = addr->elts[i].coef.to_shwi ();\n@@ -585,7 +584,7 @@ most_expensive_mult_to_index (tree type, struct mem_address *parts,\n       if (acost > best_mult_cost)\n \t{\n \t  best_mult_cost = acost;\n-\t  best_mult = addr->elts[i].coef;\n+\t  best_mult = offset_int::from (addr->elts[i].coef, SIGNED);\n \t}\n     }\n \n@@ -595,8 +594,8 @@ most_expensive_mult_to_index (tree type, struct mem_address *parts,\n   /* Collect elements multiplied by best_mult.  */\n   for (i = j = 0; i < addr->n; i++)\n     {\n-      amult = addr->elts[i].coef;\n-      amult_neg = double_int_ext_for_comb (-amult, addr);\n+      offset_int amult = offset_int::from (addr->elts[i].coef, SIGNED);\n+      offset_int amult_neg = -wi::sext (amult, TYPE_PRECISION (addr->type));\n \n       if (amult == best_mult)\n \top_code = PLUS_EXPR;\n@@ -620,7 +619,7 @@ most_expensive_mult_to_index (tree type, struct mem_address *parts,\n   addr->n = j;\n \n   parts->index = mult_elt;\n-  parts->step = double_int_to_tree (sizetype, best_mult);\n+  parts->step = wide_int_to_tree (sizetype, best_mult);\n }\n \n /* Splits address ADDR for a memory access of type TYPE into PARTS.\n@@ -648,8 +647,8 @@ addr_to_parts (tree type, aff_tree *addr, tree iv_cand,\n   parts->index = NULL_TREE;\n   parts->step = NULL_TREE;\n \n-  if (!addr->offset.is_zero ())\n-    parts->offset = double_int_to_tree (sizetype, addr->offset);\n+  if (addr->offset != 0)\n+    parts->offset = wide_int_to_tree (sizetype, addr->offset);\n   else\n     parts->offset = NULL_TREE;\n \n@@ -680,9 +679,9 @@ addr_to_parts (tree type, aff_tree *addr, tree iv_cand,\n   for (i = 0; i < addr->n; i++)\n     {\n       part = fold_convert (sizetype, addr->elts[i].val);\n-      if (!addr->elts[i].coef.is_one ())\n+      if (addr->elts[i].coef != 1)\n \tpart = fold_build2 (MULT_EXPR, sizetype, part,\n-\t\t\t    double_int_to_tree (sizetype, addr->elts[i].coef));\n+\t\t\t    wide_int_to_tree (sizetype, addr->elts[i].coef));\n       add_to_parts (parts, part);\n     }\n   if (addr->rest)\n@@ -890,8 +889,8 @@ copy_ref_info (tree new_ref, tree old_ref)\n \t\t\t   && (TREE_INT_CST_LOW (TMR_STEP (new_ref))\n \t\t\t       < align)))))\n \t    {\n-\t      unsigned int inc = (mem_ref_offset (old_ref)\n-\t\t\t\t  - mem_ref_offset (new_ref)).low;\n+\t      unsigned int inc = (mem_ref_offset (old_ref).to_short_addr ()\n+\t\t\t\t  - mem_ref_offset (new_ref).to_short_addr ());\n \t      adjust_ptr_info_misalignment (new_pi, inc);\n \t    }\n \t  else"}, {"sha": "7781d63226657d2d43ed79f6a09fdc7df9e6b45e", "filename": "gcc/tree-ssa-alias.c", "status": "modified", "additions": 38, "deletions": 42, "changes": 80, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-alias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-alias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-alias.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1031,7 +1031,6 @@ indirect_ref_may_alias_decl_p (tree ref1 ATTRIBUTE_UNUSED, tree base1,\n   tree ptrtype1, dbase2;\n   HOST_WIDE_INT offset1p = offset1, offset2p = offset2;\n   HOST_WIDE_INT doffset1, doffset2;\n-  double_int moff;\n \n   gcc_checking_assert ((TREE_CODE (base1) == MEM_REF\n \t\t\t|| TREE_CODE (base1) == TARGET_MEM_REF)\n@@ -1041,12 +1040,12 @@ indirect_ref_may_alias_decl_p (tree ref1 ATTRIBUTE_UNUSED, tree base1,\n \n   /* The offset embedded in MEM_REFs can be negative.  Bias them\n      so that the resulting offset adjustment is positive.  */\n-  moff = mem_ref_offset (base1);\n-  moff = moff.lshift (BITS_PER_UNIT == 8 ? 3 : exact_log2 (BITS_PER_UNIT));\n-  if (moff.is_negative ())\n-    offset2p += (-moff).low;\n+  offset_int moff = mem_ref_offset (base1);\n+  moff = wi::lshift (moff, LOG2_BITS_PER_UNIT);\n+  if (wi::neg_p (moff))\n+    offset2p += (-moff).to_short_addr ();\n   else\n-    offset1p += moff.low;\n+    offset1p += moff.to_short_addr ();\n \n   /* If only one reference is based on a variable, they cannot alias if\n      the pointer access is beyond the extent of the variable access.\n@@ -1117,12 +1116,12 @@ indirect_ref_may_alias_decl_p (tree ref1 ATTRIBUTE_UNUSED, tree base1,\n   if (TREE_CODE (dbase2) == MEM_REF\n       || TREE_CODE (dbase2) == TARGET_MEM_REF)\n     {\n-      double_int moff = mem_ref_offset (dbase2);\n-      moff = moff.lshift (BITS_PER_UNIT == 8 ? 3 : exact_log2 (BITS_PER_UNIT));\n-      if (moff.is_negative ())\n-\tdoffset1 -= (-moff).low;\n+      offset_int moff = mem_ref_offset (dbase2);\n+      moff = wi::lshift (moff, LOG2_BITS_PER_UNIT);\n+      if (wi::neg_p (moff))\n+\tdoffset1 -= (-moff).to_short_addr ();\n       else\n-\tdoffset2 -= moff.low;\n+\tdoffset2 -= moff.to_short_addr ();\n     }\n \n   /* If either reference is view-converted, give up now.  */\n@@ -1212,21 +1211,21 @@ indirect_refs_may_alias_p (tree ref1 ATTRIBUTE_UNUSED, tree base1,\n \t\t      && operand_equal_p (TMR_INDEX2 (base1),\n \t\t\t\t\t  TMR_INDEX2 (base2), 0))))))\n     {\n-      double_int moff;\n+      offset_int moff;\n       /* The offset embedded in MEM_REFs can be negative.  Bias them\n \t so that the resulting offset adjustment is positive.  */\n       moff = mem_ref_offset (base1);\n-      moff = moff.lshift (BITS_PER_UNIT == 8 ? 3 : exact_log2 (BITS_PER_UNIT));\n-      if (moff.is_negative ())\n-\toffset2 += (-moff).low;\n+      moff = wi::lshift (moff, LOG2_BITS_PER_UNIT);\n+      if (wi::neg_p (moff))\n+\toffset2 += (-moff).to_short_addr ();\n       else\n-\toffset1 += moff.low;\n+\toffset1 += moff.to_shwi ();\n       moff = mem_ref_offset (base2);\n-      moff = moff.lshift (BITS_PER_UNIT == 8 ? 3 : exact_log2 (BITS_PER_UNIT));\n-      if (moff.is_negative ())\n-\toffset1 += (-moff).low;\n+      moff = wi::lshift (moff, LOG2_BITS_PER_UNIT);\n+      if (wi::neg_p (moff))\n+\toffset1 += (-moff).to_short_addr ();\n       else\n-\toffset2 += moff.low;\n+\toffset2 += moff.to_short_addr ();\n       return ranges_overlap_p (offset1, max_size1, offset2, max_size2);\n     }\n   if (!ptr_derefs_may_alias_p (ptr1, ptr2))\n@@ -2198,15 +2197,13 @@ stmt_kills_ref_p_1 (gimple stmt, ao_ref *ref)\n \t      if (!tree_int_cst_equal (TREE_OPERAND (base, 1),\n \t\t\t\t       TREE_OPERAND (ref->base, 1)))\n \t\t{\n-\t\t  double_int off1 = mem_ref_offset (base);\n-\t\t  off1 = off1.lshift (BITS_PER_UNIT == 8\n-\t\t\t\t      ? 3 : exact_log2 (BITS_PER_UNIT));\n-\t\t  off1 = off1 + double_int::from_shwi (offset);\n-\t\t  double_int off2 = mem_ref_offset (ref->base);\n-\t\t  off2 = off2.lshift (BITS_PER_UNIT == 8\n-\t\t\t\t      ? 3 : exact_log2 (BITS_PER_UNIT));\n-\t\t  off2 = off2 + double_int::from_shwi (ref_offset);\n-\t\t  if (off1.fits_shwi () && off2.fits_shwi ())\n+\t\t  offset_int off1 = mem_ref_offset (base);\n+\t\t  off1 = wi::lshift (off1, LOG2_BITS_PER_UNIT);\n+\t\t  off1 += offset;\n+\t\t  offset_int off2 = mem_ref_offset (ref->base);\n+\t\t  off2 = wi::lshift (off2, LOG2_BITS_PER_UNIT);\n+\t\t  off2 += ref_offset;\n+\t\t  if (wi::fits_shwi_p (off1) && wi::fits_shwi_p (off2))\n \t\t    {\n \t\t      offset = off1.to_shwi ();\n \t\t      ref_offset = off2.to_shwi ();\n@@ -2259,32 +2256,31 @@ stmt_kills_ref_p_1 (gimple stmt, ao_ref *ref)\n \t      if (!tree_fits_shwi_p (len))\n \t\treturn false;\n \t      tree rbase = ref->base;\n-\t      double_int roffset = double_int::from_shwi (ref->offset);\n+\t      offset_int roffset = ref->offset;\n \t      ao_ref dref;\n \t      ao_ref_init_from_ptr_and_size (&dref, dest, len);\n \t      tree base = ao_ref_base (&dref);\n-\t      double_int offset = double_int::from_shwi (dref.offset);\n-\t      double_int bpu = double_int::from_uhwi (BITS_PER_UNIT);\n+\t      offset_int offset = dref.offset;\n \t      if (!base || dref.size == -1)\n \t\treturn false;\n \t      if (TREE_CODE (base) == MEM_REF)\n \t\t{\n \t\t  if (TREE_CODE (rbase) != MEM_REF)\n \t\t    return false;\n \t\t  // Compare pointers.\n-\t\t  offset += bpu * mem_ref_offset (base);\n-\t\t  roffset += bpu * mem_ref_offset (rbase);\n+\t\t  offset += wi::lshift (mem_ref_offset (base),\n+\t\t\t\t\tLOG2_BITS_PER_UNIT);\n+\t\t  roffset += wi::lshift (mem_ref_offset (rbase),\n+\t\t\t\t\t LOG2_BITS_PER_UNIT);\n \t\t  base = TREE_OPERAND (base, 0);\n \t\t  rbase = TREE_OPERAND (rbase, 0);\n \t\t}\n-\t      if (base == rbase)\n-\t\t{\n-\t\t  double_int size = bpu * tree_to_double_int (len);\n-\t\t  double_int rsize = double_int::from_uhwi (ref->max_size);\n-\t\t  if (offset.sle (roffset)\n-\t\t      && (roffset + rsize).sle (offset + size))\n-\t\t    return true;\n-\t\t}\n+\t      if (base == rbase\n+\t\t  && wi::les_p (offset, roffset)\n+\t\t  && wi::les_p (roffset + ref->max_size,\n+\t\t\t\toffset + wi::lshift (wi::to_offset (len),\n+\t\t\t\t\t\t     LOG2_BITS_PER_UNIT)))\n+\t\treturn true;\n \t      break;\n \t    }\n "}, {"sha": "d7410122c460e512c121199a067e85bbc455f525", "filename": "gcc/tree-ssa-ccp.c", "status": "modified", "additions": 233, "deletions": 195, "changes": 428, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-ccp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-ccp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ccp.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -98,6 +98,15 @@ along with GCC; see the file COPYING3.  If not see\n    array CONST_VAL[i].VALUE.  That is fed into substitute_and_fold for\n    final substitution and folding.\n \n+   This algorithm uses wide-ints at the max precision of the target.\n+   This means that, with one uninteresting exception, variables with\n+   UNSIGNED types never go to VARYING because the bits above the\n+   precision of the type of the variable are always zero.  The\n+   uninteresting case is a variable of UNSIGNED type that has the\n+   maximum precision of the target.  Such variables can go to VARYING,\n+   but this causes no loss of infomation since these variables will\n+   never be extended.\n+\n    References:\n \n      Constant propagation with conditional branches,\n@@ -144,6 +153,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"diagnostic-core.h\"\n #include \"dbgcnt.h\"\n #include \"params.h\"\n+#include \"wide-int-print.h\"\n \n \n /* Possible lattice values.  */\n@@ -162,9 +172,11 @@ struct prop_value_d {\n     /* Propagated value.  */\n     tree value;\n \n-    /* Mask that applies to the propagated value during CCP.  For\n-       X with a CONSTANT lattice value X & ~mask == value & ~mask.  */\n-    double_int mask;\n+    /* Mask that applies to the propagated value during CCP.  For X\n+       with a CONSTANT lattice value X & ~mask == value & ~mask.  The\n+       zero bits in the mask cover constant values.  The ones mean no\n+       information.  */\n+    widest_int mask;\n };\n \n typedef struct prop_value_d prop_value_t;\n@@ -199,18 +211,20 @@ dump_lattice_value (FILE *outf, const char *prefix, prop_value_t val)\n       break;\n     case CONSTANT:\n       if (TREE_CODE (val.value) != INTEGER_CST\n-\t  || val.mask.is_zero ())\n+\t  || val.mask == 0)\n \t{\n \t  fprintf (outf, \"%sCONSTANT \", prefix);\n \t  print_generic_expr (outf, val.value, dump_flags);\n \t}\n       else\n \t{\n-\t  double_int cval = tree_to_double_int (val.value).and_not (val.mask);\n-\t  fprintf (outf, \"%sCONSTANT \" HOST_WIDE_INT_PRINT_DOUBLE_HEX,\n-\t\t   prefix, cval.high, cval.low);\n-\t  fprintf (outf, \" (\" HOST_WIDE_INT_PRINT_DOUBLE_HEX \")\",\n-\t\t   val.mask.high, val.mask.low);\n+\t  widest_int cval = wi::bit_and_not (wi::to_widest (val.value),\n+\t\t\t\t\t     val.mask);\n+\t  fprintf (outf, \"%sCONSTANT \", prefix);\n+\t  print_hex (cval, outf);\n+\t  fprintf (outf, \" (\");\n+\t  print_hex (val.mask, outf);\n+\t  fprintf (outf, \")\");\n \t}\n       break;\n     default:\n@@ -230,6 +244,14 @@ debug_lattice_value (prop_value_t val)\n   fprintf (stderr, \"\\n\");\n }\n \n+/* Extend NONZERO_BITS to a full mask, with the upper bits being set.  */\n+\n+static widest_int\n+extend_mask (const wide_int &nonzero_bits)\n+{\n+  return (wi::mask <widest_int> (wi::get_precision (nonzero_bits), true)\n+\t  | widest_int::from (nonzero_bits, UNSIGNED));\n+}\n \n /* Compute a default value for variable VAR and store it in the\n    CONST_VAL array.  The following rules are used to get default\n@@ -252,7 +274,7 @@ debug_lattice_value (prop_value_t val)\n static prop_value_t\n get_default_value (tree var)\n {\n-  prop_value_t val = { UNINITIALIZED, NULL_TREE, { 0, 0 } };\n+  prop_value_t val = { UNINITIALIZED, NULL_TREE, 0 };\n   gimple stmt;\n \n   stmt = SSA_NAME_DEF_STMT (var);\n@@ -269,18 +291,15 @@ get_default_value (tree var)\n       else\n \t{\n \t  val.lattice_val = VARYING;\n-\t  val.mask = double_int_minus_one;\n+\t  val.mask = -1;\n \t  if (flag_tree_bit_ccp)\n \t    {\n-\t      double_int nonzero_bits = get_nonzero_bits (var);\n-\t      double_int mask\n-\t\t= double_int::mask (TYPE_PRECISION (TREE_TYPE (var)));\n-\t      if (nonzero_bits != double_int_minus_one && nonzero_bits != mask)\n+\t      wide_int nonzero_bits = get_nonzero_bits (var);\n+\t      if (nonzero_bits != -1)\n \t\t{\n \t\t  val.lattice_val = CONSTANT;\n \t\t  val.value = build_zero_cst (TREE_TYPE (var));\n-\t\t  /* CCP wants the bits above precision set.  */\n-\t\t  val.mask = nonzero_bits | ~mask;\n+\t\t  val.mask = extend_mask (nonzero_bits);\n \t\t}\n \t    }\n \t}\n@@ -314,7 +333,7 @@ get_default_value (tree var)\n     {\n       /* Otherwise, VAR will never take on a constant value.  */\n       val.lattice_val = VARYING;\n-      val.mask = double_int_minus_one;\n+      val.mask = -1;\n     }\n \n   return val;\n@@ -357,7 +376,7 @@ get_constant_value (tree var)\n   if (val\n       && val->lattice_val == CONSTANT\n       && (TREE_CODE (val->value) != INTEGER_CST\n-\t  || val->mask.is_zero ()))\n+\t  || val->mask == 0))\n     return val->value;\n   return NULL_TREE;\n }\n@@ -371,7 +390,7 @@ set_value_varying (tree var)\n \n   val->lattice_val = VARYING;\n   val->value = NULL_TREE;\n-  val->mask = double_int_minus_one;\n+  val->mask = -1;\n }\n \n /* For float types, modify the value of VAL to make ccp work correctly\n@@ -455,8 +474,8 @@ valid_lattice_transition (prop_value_t old_val, prop_value_t new_val)\n   /* Bit-lattices have to agree in the still valid bits.  */\n   if (TREE_CODE (old_val.value) == INTEGER_CST\n       && TREE_CODE (new_val.value) == INTEGER_CST)\n-    return tree_to_double_int (old_val.value).and_not (new_val.mask)\n-\t   == tree_to_double_int (new_val.value).and_not (new_val.mask);\n+    return (wi::bit_and_not (wi::to_widest (old_val.value), new_val.mask)\n+\t    == wi::bit_and_not (wi::to_widest (new_val.value), new_val.mask));\n \n   /* Otherwise constant values have to agree.  */\n   return operand_equal_p (old_val.value, new_val.value, 0);\n@@ -481,9 +500,8 @@ set_lattice_value (tree var, prop_value_t new_val)\n       && TREE_CODE (new_val.value) == INTEGER_CST\n       && TREE_CODE (old_val->value) == INTEGER_CST)\n     {\n-      double_int diff;\n-      diff = tree_to_double_int (new_val.value)\n-\t     ^ tree_to_double_int (old_val->value);\n+      widest_int diff = (wi::to_widest (new_val.value)\n+\t\t\t ^ wi::to_widest (old_val->value));\n       new_val.mask = new_val.mask | old_val->mask | diff;\n     }\n \n@@ -517,21 +535,21 @@ set_lattice_value (tree var, prop_value_t new_val)\n \n static prop_value_t get_value_for_expr (tree, bool);\n static prop_value_t bit_value_binop (enum tree_code, tree, tree, tree);\n-static void bit_value_binop_1 (enum tree_code, tree, double_int *, double_int *,\n-\t\t\t       tree, double_int, double_int,\n-\t\t\t       tree, double_int, double_int);\n+static void bit_value_binop_1 (enum tree_code, tree, widest_int *, widest_int *,\n+\t\t\t       tree, const widest_int &, const widest_int &,\n+\t\t\t       tree, const widest_int &, const widest_int &);\n \n-/* Return a double_int that can be used for bitwise simplifications\n+/* Return a widest_int that can be used for bitwise simplifications\n    from VAL.  */\n \n-static double_int\n-value_to_double_int (prop_value_t val)\n+static widest_int\n+value_to_wide_int (prop_value_t val)\n {\n   if (val.value\n       && TREE_CODE (val.value) == INTEGER_CST)\n-    return tree_to_double_int (val.value);\n-  else\n-    return double_int_zero;\n+    return wi::to_widest (val.value);\n+\n+  return 0;\n }\n \n /* Return the value for the address expression EXPR based on alignment\n@@ -549,14 +567,11 @@ get_value_from_alignment (tree expr)\n \n   get_pointer_alignment_1 (expr, &align, &bitpos);\n   val.mask = (POINTER_TYPE_P (type) || TYPE_UNSIGNED (type)\n-\t      ? double_int::mask (TYPE_PRECISION (type))\n-\t      : double_int_minus_one)\n-\t     .and_not (double_int::from_uhwi (align / BITS_PER_UNIT - 1));\n-  val.lattice_val = val.mask.is_minus_one () ? VARYING : CONSTANT;\n+\t      ? wi::mask <widest_int> (TYPE_PRECISION (type), false)\n+\t      : -1).and_not (align / BITS_PER_UNIT - 1);\n+  val.lattice_val = val.mask == -1 ? VARYING : CONSTANT;\n   if (val.lattice_val == CONSTANT)\n-    val.value\n-      = double_int_to_tree (type,\n-\t\t\t    double_int::from_uhwi (bitpos / BITS_PER_UNIT));\n+    val.value = build_int_cstu (type, bitpos / BITS_PER_UNIT);\n   else\n     val.value = NULL_TREE;\n \n@@ -585,15 +600,15 @@ get_value_for_expr (tree expr, bool for_bits_p)\n     {\n       val.lattice_val = CONSTANT;\n       val.value = expr;\n-      val.mask = double_int_zero;\n+      val.mask = 0;\n       canonicalize_value (&val);\n     }\n   else if (TREE_CODE (expr) == ADDR_EXPR)\n     val = get_value_from_alignment (expr);\n   else\n     {\n       val.lattice_val = VARYING;\n-      val.mask = double_int_minus_one;\n+      val.mask = -1;\n       val.value = NULL_TREE;\n     }\n   return val;\n@@ -842,7 +857,7 @@ do_dbg_cnt (void)\n       if (!dbg_cnt (ccp))\n         {\n           const_val[i].lattice_val = VARYING;\n-\t  const_val[i].mask = double_int_minus_one;\n+\t  const_val[i].mask = -1;\n           const_val[i].value = NULL_TREE;\n         }\n     }\n@@ -888,7 +903,7 @@ ccp_finalize (void)\n \t{\n \t  /* Trailing mask bits specify the alignment, trailing value\n \t     bits the misalignment.  */\n-\t  tem = val->mask.low;\n+\t  tem = val->mask.to_uhwi ();\n \t  align = (tem & -tem);\n \t  if (align > 1)\n \t    set_ptr_info_alignment (get_ptr_info (name), align,\n@@ -897,8 +912,9 @@ ccp_finalize (void)\n \t}\n       else\n \t{\n-\t  double_int nonzero_bits = val->mask;\n-\t  nonzero_bits = nonzero_bits | tree_to_double_int (val->value);\n+\t  unsigned int precision = TYPE_PRECISION (TREE_TYPE (val->value));\n+\t  wide_int nonzero_bits = wide_int::from (val->mask, precision,\n+\t\t\t\t\t\t  UNSIGNED) | val->value;\n \t  nonzero_bits &= get_nonzero_bits (name);\n \t  set_nonzero_bits (name, nonzero_bits);\n \t}\n@@ -942,7 +958,7 @@ ccp_lattice_meet (prop_value_t *val1, prop_value_t *val2)\n     {\n       /* any M VARYING = VARYING.  */\n       val1->lattice_val = VARYING;\n-      val1->mask = double_int_minus_one;\n+      val1->mask = -1;\n       val1->value = NULL_TREE;\n     }\n   else if (val1->lattice_val == CONSTANT\n@@ -955,10 +971,10 @@ ccp_lattice_meet (prop_value_t *val1, prop_value_t *val2)\n \n          For INTEGER_CSTs mask unequal bits.  If no equal bits remain,\n \t drop to varying.  */\n-      val1->mask = val1->mask | val2->mask\n-\t\t   | (tree_to_double_int (val1->value)\n-\t\t      ^ tree_to_double_int (val2->value));\n-      if (val1->mask.is_minus_one ())\n+      val1->mask = (val1->mask | val2->mask\n+\t\t    | (wi::to_widest (val1->value)\n+\t\t       ^ wi::to_widest (val2->value)));\n+      if (val1->mask == -1)\n \t{\n \t  val1->lattice_val = VARYING;\n \t  val1->value = NULL_TREE;\n@@ -991,7 +1007,7 @@ ccp_lattice_meet (prop_value_t *val1, prop_value_t *val2)\n     {\n       /* Any other combination is VARYING.  */\n       val1->lattice_val = VARYING;\n-      val1->mask = double_int_minus_one;\n+      val1->mask = -1;\n       val1->value = NULL_TREE;\n     }\n }\n@@ -1146,8 +1162,8 @@ ccp_fold (gimple stmt)\n \n static void\n bit_value_unop_1 (enum tree_code code, tree type,\n-\t\t  double_int *val, double_int *mask,\n-\t\t  tree rtype, double_int rval, double_int rmask)\n+\t\t  widest_int *val, widest_int *mask,\n+\t\t  tree rtype, const widest_int &rval, const widest_int &rmask)\n {\n   switch (code)\n     {\n@@ -1158,33 +1174,32 @@ bit_value_unop_1 (enum tree_code code, tree type,\n \n     case NEGATE_EXPR:\n       {\n-\tdouble_int temv, temm;\n+\twidest_int temv, temm;\n \t/* Return ~rval + 1.  */\n \tbit_value_unop_1 (BIT_NOT_EXPR, type, &temv, &temm, type, rval, rmask);\n \tbit_value_binop_1 (PLUS_EXPR, type, val, mask,\n-\t\t\t type, temv, temm,\n-\t\t\t type, double_int_one, double_int_zero);\n+\t\t\t   type, temv, temm, type, 1, 0);\n \tbreak;\n       }\n \n     CASE_CONVERT:\n       {\n-\tbool uns;\n+\tsignop sgn;\n \n \t/* First extend mask and value according to the original type.  */\n-\tuns = TYPE_UNSIGNED (rtype);\n-\t*mask = rmask.ext (TYPE_PRECISION (rtype), uns);\n-\t*val = rval.ext (TYPE_PRECISION (rtype), uns);\n+\tsgn = TYPE_SIGN (rtype);\n+\t*mask = wi::ext (rmask, TYPE_PRECISION (rtype), sgn);\n+\t*val = wi::ext (rval, TYPE_PRECISION (rtype), sgn);\n \n \t/* Then extend mask and value according to the target type.  */\n-\tuns = TYPE_UNSIGNED (type);\n-\t*mask = (*mask).ext (TYPE_PRECISION (type), uns);\n-\t*val = (*val).ext (TYPE_PRECISION (type), uns);\n+\tsgn = TYPE_SIGN (type);\n+\t*mask = wi::ext (*mask, TYPE_PRECISION (type), sgn);\n+\t*val = wi::ext (*val, TYPE_PRECISION (type), sgn);\n \tbreak;\n       }\n \n     default:\n-      *mask = double_int_minus_one;\n+      *mask = -1;\n       break;\n     }\n }\n@@ -1195,14 +1210,19 @@ bit_value_unop_1 (enum tree_code code, tree type,\n \n static void\n bit_value_binop_1 (enum tree_code code, tree type,\n-\t\t   double_int *val, double_int *mask,\n-\t\t   tree r1type, double_int r1val, double_int r1mask,\n-\t\t   tree r2type, double_int r2val, double_int r2mask)\n+\t\t   widest_int *val, widest_int *mask,\n+\t\t   tree r1type, const widest_int &r1val,\n+\t\t   const widest_int &r1mask, tree r2type,\n+\t\t   const widest_int &r2val, const widest_int &r2mask)\n {\n-  bool uns = TYPE_UNSIGNED (type);\n-  /* Assume we'll get a constant result.  Use an initial varying value,\n-     we fall back to varying in the end if necessary.  */\n-  *mask = double_int_minus_one;\n+  signop sgn = TYPE_SIGN (type);\n+  int width = TYPE_PRECISION (type);\n+  bool swap_p = false;\n+\n+  /* Assume we'll get a constant result.  Use an initial non varying\n+     value, we fall back to varying in the end if necessary.  */\n+  *mask = -1;\n+\n   switch (code)\n     {\n     case BIT_AND_EXPR:\n@@ -1228,13 +1248,35 @@ bit_value_binop_1 (enum tree_code code, tree type,\n \n     case LROTATE_EXPR:\n     case RROTATE_EXPR:\n-      if (r2mask.is_zero ())\n+      if (r2mask == 0)\n \t{\n-\t  HOST_WIDE_INT shift = r2val.low;\n-\t  if (code == RROTATE_EXPR)\n-\t    shift = -shift;\n-\t  *mask = r1mask.lrotate (shift, TYPE_PRECISION (type));\n-\t  *val = r1val.lrotate (shift, TYPE_PRECISION (type));\n+\t  widest_int shift = r2val;\n+\t  if (shift == 0)\n+\t    {\n+\t      *mask = r1mask;\n+\t      *val = r1val;\n+\t    }\n+\t  else\n+\t    {\n+\t      if (wi::neg_p (shift))\n+\t\t{\n+\t\t  shift = -shift;\n+\t\t  if (code == RROTATE_EXPR)\n+\t\t    code = LROTATE_EXPR;\n+\t\t  else\n+\t\t    code = RROTATE_EXPR;\n+\t\t}\n+\t      if (code == RROTATE_EXPR)\n+\t\t{\n+\t\t  *mask = wi::rrotate (r1mask, shift, width);\n+\t\t  *val = wi::rrotate (r1val, shift, width);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  *mask = wi::lrotate (r1mask, shift, width);\n+\t\t  *val = wi::lrotate (r1val, shift, width);\n+\t\t}\n+\t    }\n \t}\n       break;\n \n@@ -1243,61 +1285,63 @@ bit_value_binop_1 (enum tree_code code, tree type,\n       /* ???  We can handle partially known shift counts if we know\n \t its sign.  That way we can tell that (x << (y | 8)) & 255\n \t is zero.  */\n-      if (r2mask.is_zero ())\n+      if (r2mask == 0)\n \t{\n-\t  HOST_WIDE_INT shift = r2val.low;\n-\t  if (code == RSHIFT_EXPR)\n-\t    shift = -shift;\n-\t  /* We need to know if we are doing a left or a right shift\n-\t     to properly shift in zeros for left shift and unsigned\n-\t     right shifts and the sign bit for signed right shifts.\n-\t     For signed right shifts we shift in varying in case\n-\t     the sign bit was varying.  */\n-\t  if (shift > 0)\n-\t    {\n-\t      *mask = r1mask.llshift (shift, TYPE_PRECISION (type));\n-\t      *val = r1val.llshift (shift, TYPE_PRECISION (type));\n-\t    }\n-\t  else if (shift < 0)\n+\t  widest_int shift = r2val;\n+\t  if (shift == 0)\n \t    {\n-\t      shift = -shift;\n-\t      *mask = r1mask.rshift (shift, TYPE_PRECISION (type), !uns);\n-\t      *val = r1val.rshift (shift, TYPE_PRECISION (type), !uns);\n+\t      *mask = r1mask;\n+\t      *val = r1val;\n \t    }\n \t  else\n \t    {\n-\t      *mask = r1mask;\n-\t      *val = r1val;\n+\t      if (wi::neg_p (shift))\n+\t\t{\n+\t\t  shift = -shift;\n+\t\t  if (code == RSHIFT_EXPR)\n+\t\t    code = LSHIFT_EXPR;\n+\t\t  else\n+\t\t    code = RSHIFT_EXPR;\n+\t\t}\n+\t      if (code == RSHIFT_EXPR)\n+\t\t{\n+\t\t  *mask = wi::rshift (wi::ext (r1mask, width, sgn), shift, sgn);\n+\t\t  *val = wi::rshift (wi::ext (r1val, width, sgn), shift, sgn);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  *mask = wi::ext (wi::lshift (r1mask, shift), width, sgn);\n+\t\t  *val = wi::ext (wi::lshift (r1val, shift), width, sgn);\n+\t\t}\n \t    }\n \t}\n       break;\n \n     case PLUS_EXPR:\n     case POINTER_PLUS_EXPR:\n       {\n-\tdouble_int lo, hi;\n \t/* Do the addition with unknown bits set to zero, to give carry-ins of\n \t   zero wherever possible.  */\n-\tlo = r1val.and_not (r1mask) + r2val.and_not (r2mask);\n-\tlo = lo.ext (TYPE_PRECISION (type), uns);\n+\twidest_int lo = r1val.and_not (r1mask) + r2val.and_not (r2mask);\n+\tlo = wi::ext (lo, width, sgn);\n \t/* Do the addition with unknown bits set to one, to give carry-ins of\n \t   one wherever possible.  */\n-\thi = (r1val | r1mask) + (r2val | r2mask);\n-\thi = hi.ext (TYPE_PRECISION (type), uns);\n+\twidest_int hi = (r1val | r1mask) + (r2val | r2mask);\n+\thi = wi::ext (hi, width, sgn);\n \t/* Each bit in the result is known if (a) the corresponding bits in\n \t   both inputs are known, and (b) the carry-in to that bit position\n \t   is known.  We can check condition (b) by seeing if we got the same\n \t   result with minimised carries as with maximised carries.  */\n \t*mask = r1mask | r2mask | (lo ^ hi);\n-\t*mask = (*mask).ext (TYPE_PRECISION (type), uns);\n+\t*mask = wi::ext (*mask, width, sgn);\n \t/* It shouldn't matter whether we choose lo or hi here.  */\n \t*val = lo;\n \tbreak;\n       }\n \n     case MINUS_EXPR:\n       {\n-\tdouble_int temv, temm;\n+\twidest_int temv, temm;\n \tbit_value_unop_1 (NEGATE_EXPR, r2type, &temv, &temm,\n \t\t\t  r2type, r2val, r2mask);\n \tbit_value_binop_1 (PLUS_EXPR, type, val, mask,\n@@ -1310,90 +1354,89 @@ bit_value_binop_1 (enum tree_code code, tree type,\n       {\n \t/* Just track trailing zeros in both operands and transfer\n \t   them to the other.  */\n-\tint r1tz = (r1val | r1mask).trailing_zeros ();\n-\tint r2tz = (r2val | r2mask).trailing_zeros ();\n-\tif (r1tz + r2tz >= HOST_BITS_PER_DOUBLE_INT)\n+\tint r1tz = wi::ctz (r1val | r1mask);\n+\tint r2tz = wi::ctz (r2val | r2mask);\n+\tif (r1tz + r2tz >= width)\n \t  {\n-\t    *mask = double_int_zero;\n-\t    *val = double_int_zero;\n+\t    *mask = 0;\n+\t    *val = 0;\n \t  }\n \telse if (r1tz + r2tz > 0)\n \t  {\n-\t    *mask = ~double_int::mask (r1tz + r2tz);\n-\t    *mask = (*mask).ext (TYPE_PRECISION (type), uns);\n-\t    *val = double_int_zero;\n+\t    *mask = wi::ext (wi::mask <widest_int> (r1tz + r2tz, true),\n+\t\t\t     width, sgn);\n+\t    *val = 0;\n \t  }\n \tbreak;\n       }\n \n     case EQ_EXPR:\n     case NE_EXPR:\n       {\n-\tdouble_int m = r1mask | r2mask;\n+\twidest_int m = r1mask | r2mask;\n \tif (r1val.and_not (m) != r2val.and_not (m))\n \t  {\n-\t    *mask = double_int_zero;\n-\t    *val = ((code == EQ_EXPR) ? double_int_zero : double_int_one);\n+\t    *mask = 0;\n+\t    *val = ((code == EQ_EXPR) ? 0 : 1);\n \t  }\n \telse\n \t  {\n \t    /* We know the result of a comparison is always one or zero.  */\n-\t    *mask = double_int_one;\n-\t    *val = double_int_zero;\n+\t    *mask = 1;\n+\t    *val = 0;\n \t  }\n \tbreak;\n       }\n \n     case GE_EXPR:\n     case GT_EXPR:\n-      {\n-\tdouble_int tem = r1val;\n-\tr1val = r2val;\n-\tr2val = tem;\n-\ttem = r1mask;\n-\tr1mask = r2mask;\n-\tr2mask = tem;\n-\tcode = swap_tree_comparison (code);\n-      }\n-      /* Fallthru.  */\n+      swap_p = true;\n+      code = swap_tree_comparison (code);\n+      /* Fall through.  */\n     case LT_EXPR:\n     case LE_EXPR:\n       {\n \tint minmax, maxmin;\n+\n+\tconst widest_int &o1val = swap_p ? r2val : r1val;\n+\tconst widest_int &o1mask = swap_p ? r2mask : r1mask;\n+\tconst widest_int &o2val = swap_p ? r1val : r2val;\n+\tconst widest_int &o2mask = swap_p ? r1mask : r2mask;\n+\n \t/* If the most significant bits are not known we know nothing.  */\n-\tif (r1mask.is_negative () || r2mask.is_negative ())\n+\tif (wi::neg_p (o1mask) || wi::neg_p (o2mask))\n \t  break;\n \n \t/* For comparisons the signedness is in the comparison operands.  */\n-\tuns = TYPE_UNSIGNED (r1type);\n+\tsgn = TYPE_SIGN (r1type);\n \n \t/* If we know the most significant bits we know the values\n \t   value ranges by means of treating varying bits as zero\n \t   or one.  Do a cross comparison of the max/min pairs.  */\n-\tmaxmin = (r1val | r1mask).cmp (r2val.and_not (r2mask), uns);\n-\tminmax = r1val.and_not (r1mask).cmp (r2val | r2mask, uns);\n-\tif (maxmin < 0)  /* r1 is less than r2.  */\n+\tmaxmin = wi::cmp (o1val | o1mask, o2val.and_not (o2mask), sgn);\n+\tminmax = wi::cmp (o1val.and_not (o1mask), o2val | o2mask, sgn);\n+\tif (maxmin < 0)  /* o1 is less than o2.  */\n \t  {\n-\t    *mask = double_int_zero;\n-\t    *val = double_int_one;\n+\t    *mask = 0;\n+\t    *val = 1;\n \t  }\n-\telse if (minmax > 0)  /* r1 is not less or equal to r2.  */\n+\telse if (minmax > 0)  /* o1 is not less or equal to o2.  */\n \t  {\n-\t    *mask = double_int_zero;\n-\t    *val = double_int_zero;\n+\t    *mask = 0;\n+\t    *val = 0;\n \t  }\n-\telse if (maxmin == minmax)  /* r1 and r2 are equal.  */\n+\telse if (maxmin == minmax)  /* o1 and o2 are equal.  */\n \t  {\n \t    /* This probably should never happen as we'd have\n \t       folded the thing during fully constant value folding.  */\n-\t    *mask = double_int_zero;\n-\t    *val = (code == LE_EXPR ? double_int_one :  double_int_zero);\n+\t    *mask = 0;\n+\t    *val = (code == LE_EXPR ? 1 : 0);\n \t  }\n \telse\n \t  {\n \t    /* We know the result of a comparison is always one or zero.  */\n-\t    *mask = double_int_one;\n-\t    *val = double_int_zero;\n+\t    *mask = 1;\n+\t    *val = 0;\n \t  }\n \tbreak;\n       }\n@@ -1409,29 +1452,29 @@ static prop_value_t\n bit_value_unop (enum tree_code code, tree type, tree rhs)\n {\n   prop_value_t rval = get_value_for_expr (rhs, true);\n-  double_int value, mask;\n+  widest_int value, mask;\n   prop_value_t val;\n \n   if (rval.lattice_val == UNDEFINED)\n     return rval;\n \n   gcc_assert ((rval.lattice_val == CONSTANT\n \t       && TREE_CODE (rval.value) == INTEGER_CST)\n-\t      || rval.mask.is_minus_one ());\n+\t      || rval.mask == -1);\n   bit_value_unop_1 (code, type, &value, &mask,\n-\t\t    TREE_TYPE (rhs), value_to_double_int (rval), rval.mask);\n-  if (!mask.is_minus_one ())\n+\t\t    TREE_TYPE (rhs), value_to_wide_int (rval), rval.mask);\n+  if (mask != -1)\n     {\n       val.lattice_val = CONSTANT;\n       val.mask = mask;\n       /* ???  Delay building trees here.  */\n-      val.value = double_int_to_tree (type, value);\n+      val.value = wide_int_to_tree (type, value);\n     }\n   else\n     {\n       val.lattice_val = VARYING;\n       val.value = NULL_TREE;\n-      val.mask = double_int_minus_one;\n+      val.mask = -1;\n     }\n   return val;\n }\n@@ -1444,39 +1487,39 @@ bit_value_binop (enum tree_code code, tree type, tree rhs1, tree rhs2)\n {\n   prop_value_t r1val = get_value_for_expr (rhs1, true);\n   prop_value_t r2val = get_value_for_expr (rhs2, true);\n-  double_int value, mask;\n+  widest_int value, mask;\n   prop_value_t val;\n \n   if (r1val.lattice_val == UNDEFINED\n       || r2val.lattice_val == UNDEFINED)\n     {\n       val.lattice_val = VARYING;\n       val.value = NULL_TREE;\n-      val.mask = double_int_minus_one;\n+      val.mask = -1;\n       return val;\n     }\n \n   gcc_assert ((r1val.lattice_val == CONSTANT\n \t       && TREE_CODE (r1val.value) == INTEGER_CST)\n-\t      || r1val.mask.is_minus_one ());\n+\t      || r1val.mask == -1);\n   gcc_assert ((r2val.lattice_val == CONSTANT\n \t       && TREE_CODE (r2val.value) == INTEGER_CST)\n-\t      || r2val.mask.is_minus_one ());\n+\t      || r2val.mask == -1);\n   bit_value_binop_1 (code, type, &value, &mask,\n-\t\t     TREE_TYPE (rhs1), value_to_double_int (r1val), r1val.mask,\n-\t\t     TREE_TYPE (rhs2), value_to_double_int (r2val), r2val.mask);\n-  if (!mask.is_minus_one ())\n+\t\t     TREE_TYPE (rhs1), value_to_wide_int (r1val), r1val.mask,\n+\t\t     TREE_TYPE (rhs2), value_to_wide_int (r2val), r2val.mask);\n+  if (mask != -1)\n     {\n       val.lattice_val = CONSTANT;\n       val.mask = mask;\n       /* ???  Delay building trees here.  */\n-      val.value = double_int_to_tree (type, value);\n+      val.value = wide_int_to_tree (type, value);\n     }\n   else\n     {\n       val.lattice_val = VARYING;\n       val.value = NULL_TREE;\n-      val.mask = double_int_minus_one;\n+      val.mask = -1;\n     }\n   return val;\n }\n@@ -1495,7 +1538,7 @@ bit_value_assume_aligned (gimple stmt, tree attr, prop_value_t ptrval,\n   tree align, misalign = NULL_TREE, type;\n   unsigned HOST_WIDE_INT aligni, misaligni = 0;\n   prop_value_t alignval;\n-  double_int value, mask;\n+  widest_int value, mask;\n   prop_value_t val;\n \n   if (attr == NULL_TREE)\n@@ -1514,7 +1557,7 @@ bit_value_assume_aligned (gimple stmt, tree attr, prop_value_t ptrval,\n     return ptrval;\n   gcc_assert ((ptrval.lattice_val == CONSTANT\n \t       && TREE_CODE (ptrval.value) == INTEGER_CST)\n-\t      || ptrval.mask.is_minus_one ());\n+\t      || ptrval.mask == -1);\n   if (attr == NULL_TREE)\n     {\n       /* Get aligni and misaligni from __builtin_assume_aligned.  */\n@@ -1564,23 +1607,23 @@ bit_value_assume_aligned (gimple stmt, tree attr, prop_value_t ptrval,\n   align = build_int_cst_type (type, -aligni);\n   alignval = get_value_for_expr (align, true);\n   bit_value_binop_1 (BIT_AND_EXPR, type, &value, &mask,\n-\t\t     type, value_to_double_int (ptrval), ptrval.mask,\n-\t\t     type, value_to_double_int (alignval), alignval.mask);\n-  if (!mask.is_minus_one ())\n+\t\t     type, value_to_wide_int (ptrval), ptrval.mask,\n+\t\t     type, value_to_wide_int (alignval), alignval.mask);\n+  if (mask != -1)\n     {\n       val.lattice_val = CONSTANT;\n       val.mask = mask;\n-      gcc_assert ((mask.low & (aligni - 1)) == 0);\n-      gcc_assert ((value.low & (aligni - 1)) == 0);\n-      value.low |= misaligni;\n+      gcc_assert ((mask.to_uhwi () & (aligni - 1)) == 0);\n+      gcc_assert ((value.to_uhwi () & (aligni - 1)) == 0);\n+      value |= misaligni;\n       /* ???  Delay building trees here.  */\n-      val.value = double_int_to_tree (type, value);\n+      val.value = wide_int_to_tree (type, value);\n     }\n   else\n     {\n       val.lattice_val = VARYING;\n       val.value = NULL_TREE;\n-      val.mask = double_int_minus_one;\n+      val.mask = -1;\n     }\n   return val;\n }\n@@ -1632,7 +1675,7 @@ evaluate_stmt (gimple stmt)\n \t  /* The statement produced a constant value.  */\n \t  val.lattice_val = CONSTANT;\n \t  val.value = simplified;\n-\t  val.mask = double_int_zero;\n+\t  val.mask = 0;\n \t}\n     }\n   /* If the statement is likely to have a VARYING result, then do not\n@@ -1660,7 +1703,7 @@ evaluate_stmt (gimple stmt)\n \t  /* The statement produced a constant value.  */\n \t  val.lattice_val = CONSTANT;\n \t  val.value = simplified;\n-\t  val.mask = double_int_zero;\n+\t  val.mask = 0;\n \t}\n     }\n \n@@ -1672,7 +1715,7 @@ evaluate_stmt (gimple stmt)\n       enum gimple_code code = gimple_code (stmt);\n       val.lattice_val = VARYING;\n       val.value = NULL_TREE;\n-      val.mask = double_int_minus_one;\n+      val.mask = -1;\n       if (code == GIMPLE_ASSIGN)\n \t{\n \t  enum tree_code subcode = gimple_assign_rhs_code (stmt);\n@@ -1728,9 +1771,8 @@ evaluate_stmt (gimple stmt)\n \t    case BUILT_IN_STRNDUP:\n \t      val.lattice_val = CONSTANT;\n \t      val.value = build_int_cst (TREE_TYPE (gimple_get_lhs (stmt)), 0);\n-\t      val.mask = double_int::from_shwi\n-\t\t  \t   (~(((HOST_WIDE_INT) MALLOC_ABI_ALIGNMENT)\n-\t\t\t      / BITS_PER_UNIT - 1));\n+\t      val.mask = ~((HOST_WIDE_INT) MALLOC_ABI_ALIGNMENT\n+\t\t\t   / BITS_PER_UNIT - 1);\n \t      break;\n \n \t    case BUILT_IN_ALLOCA:\n@@ -1740,8 +1782,7 @@ evaluate_stmt (gimple stmt)\n \t\t       : BIGGEST_ALIGNMENT);\n \t      val.lattice_val = CONSTANT;\n \t      val.value = build_int_cst (TREE_TYPE (gimple_get_lhs (stmt)), 0);\n-\t      val.mask = double_int::from_shwi (~(((HOST_WIDE_INT) align)\n-\t\t\t\t\t\t  / BITS_PER_UNIT - 1));\n+\t      val.mask = ~((HOST_WIDE_INT) align / BITS_PER_UNIT - 1);\n \t      break;\n \n \t    /* These builtins return their first argument, unmodified.  */\n@@ -1775,7 +1816,7 @@ evaluate_stmt (gimple stmt)\n \t\t      {\n \t\t\tval.lattice_val = CONSTANT;\n \t\t\tval.value = build_int_cst (ptr_type_node, 0);\n-\t\t\tval.mask = double_int::from_shwi (-aligni);\n+\t\t\tval.mask = -aligni;\n \t\t      }\n \t\t  }\n \t\tbreak;\n@@ -1809,28 +1850,25 @@ evaluate_stmt (gimple stmt)\n       && TREE_CODE (gimple_get_lhs (stmt)) == SSA_NAME)\n     {\n       tree lhs = gimple_get_lhs (stmt);\n-      double_int nonzero_bits = get_nonzero_bits (lhs);\n-      double_int mask = double_int::mask (TYPE_PRECISION (TREE_TYPE (lhs)));\n-      if (nonzero_bits != double_int_minus_one && nonzero_bits != mask)\n+      wide_int nonzero_bits = get_nonzero_bits (lhs);\n+      if (nonzero_bits != -1)\n \t{\n \t  if (!is_constant)\n \t    {\n \t      val.lattice_val = CONSTANT;\n \t      val.value = build_zero_cst (TREE_TYPE (lhs));\n-\t      /* CCP wants the bits above precision set.  */\n-\t      val.mask = nonzero_bits | ~mask;\n+\t      val.mask = extend_mask (nonzero_bits);\n \t      is_constant = true;\n \t    }\n \t  else\n \t    {\n-\t      double_int valv = tree_to_double_int (val.value);\n-\t      if (!(valv & ~nonzero_bits & mask).is_zero ())\n-\t\tval.value = double_int_to_tree (TREE_TYPE (lhs),\n-\t\t\t\t\t\tvalv & nonzero_bits);\n-\t      if (nonzero_bits.is_zero ())\n-\t\tval.mask = double_int_zero;\n+\t      if (wi::bit_and_not (val.value, nonzero_bits) != 0)\n+\t\tval.value = wide_int_to_tree (TREE_TYPE (lhs),\n+\t\t\t\t\t      nonzero_bits & val.value);\n+\t      if (nonzero_bits == 0)\n+\t\tval.mask = 0;\n \t      else\n-\t\tval.mask = val.mask & (nonzero_bits | ~mask);\n+\t\tval.mask = val.mask & extend_mask (nonzero_bits);\n \t    }\n \t}\n     }\n@@ -1843,12 +1881,12 @@ evaluate_stmt (gimple stmt)\n       if (likelyvalue == UNDEFINED)\n \t{\n \t  val.lattice_val = likelyvalue;\n-\t  val.mask = double_int_zero;\n+\t  val.mask = 0;\n \t}\n       else\n \t{\n \t  val.lattice_val = VARYING;\n-\t  val.mask = double_int_minus_one;\n+\t  val.mask = -1;\n \t}\n \n       val.value = NULL_TREE;\n@@ -2030,7 +2068,7 @@ ccp_fold_stmt (gimple_stmt_iterator *gsi)\n \t   fold more conditionals here.  */\n \tval = evaluate_stmt (stmt);\n \tif (val.lattice_val != CONSTANT\n-\t    || !val.mask.is_zero ())\n+\t    || val.mask != 0)\n \t  return false;\n \n \tif (dump_file)\n@@ -2210,7 +2248,7 @@ visit_cond_stmt (gimple stmt, edge *taken_edge_p)\n   block = gimple_bb (stmt);\n   val = evaluate_stmt (stmt);\n   if (val.lattice_val != CONSTANT\n-      || !val.mask.is_zero ())\n+      || val.mask != 0)\n     return SSA_PROP_VARYING;\n \n   /* Find which edge out of the conditional block will be taken and add it\n@@ -2282,7 +2320,7 @@ ccp_visit_stmt (gimple stmt, edge *taken_edge_p, tree *output_p)\n      Mark them VARYING.  */\n   FOR_EACH_SSA_TREE_OPERAND (def, stmt, iter, SSA_OP_ALL_DEFS)\n     {\n-      prop_value_t v = { VARYING, NULL_TREE, { -1, (HOST_WIDE_INT) -1 } };\n+      prop_value_t v = { VARYING, NULL_TREE, -1 };\n       set_lattice_value (def, v);\n     }\n "}, {"sha": "563abe0d2cc0657348360682ec5cb566455b533e", "filename": "gcc/tree-ssa-forwprop.c", "status": "modified", "additions": 13, "deletions": 11, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-forwprop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-forwprop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-forwprop.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -829,9 +829,9 @@ forward_propagate_addr_expr_1 (tree name, tree def_rhs,\n       if ((def_rhs_base = get_addr_base_and_unit_offset (TREE_OPERAND (def_rhs, 0),\n \t\t\t\t\t\t\t &def_rhs_offset)))\n \t{\n-\t  double_int off = mem_ref_offset (lhs);\n+\t  offset_int off = mem_ref_offset (lhs);\n \t  tree new_ptr;\n-\t  off += double_int::from_shwi (def_rhs_offset);\n+\t  off += def_rhs_offset;\n \t  if (TREE_CODE (def_rhs_base) == MEM_REF)\n \t    {\n \t      off += mem_ref_offset (def_rhs_base);\n@@ -841,7 +841,7 @@ forward_propagate_addr_expr_1 (tree name, tree def_rhs,\n \t    new_ptr = build_fold_addr_expr (def_rhs_base);\n \t  TREE_OPERAND (lhs, 0) = new_ptr;\n \t  TREE_OPERAND (lhs, 1)\n-\t    = double_int_to_tree (TREE_TYPE (TREE_OPERAND (lhs, 1)), off);\n+\t    = wide_int_to_tree (TREE_TYPE (TREE_OPERAND (lhs, 1)), off);\n \t  tidy_after_forward_propagate_addr (use_stmt);\n \t  /* Continue propagating into the RHS if this was not the only use.  */\n \t  if (single_use_p)\n@@ -920,9 +920,9 @@ forward_propagate_addr_expr_1 (tree name, tree def_rhs,\n       if ((def_rhs_base = get_addr_base_and_unit_offset (TREE_OPERAND (def_rhs, 0),\n \t\t\t\t\t\t\t &def_rhs_offset)))\n \t{\n-\t  double_int off = mem_ref_offset (rhs);\n+\t  offset_int off = mem_ref_offset (rhs);\n \t  tree new_ptr;\n-\t  off += double_int::from_shwi (def_rhs_offset);\n+\t  off += def_rhs_offset;\n \t  if (TREE_CODE (def_rhs_base) == MEM_REF)\n \t    {\n \t      off += mem_ref_offset (def_rhs_base);\n@@ -932,7 +932,7 @@ forward_propagate_addr_expr_1 (tree name, tree def_rhs,\n \t    new_ptr = build_fold_addr_expr (def_rhs_base);\n \t  TREE_OPERAND (rhs, 0) = new_ptr;\n \t  TREE_OPERAND (rhs, 1)\n-\t    = double_int_to_tree (TREE_TYPE (TREE_OPERAND (rhs, 1)), off);\n+\t    = wide_int_to_tree (TREE_TYPE (TREE_OPERAND (rhs, 1)), off);\n \t  fold_stmt_inplace (use_stmt_gsi);\n \t  tidy_after_forward_propagate_addr (use_stmt);\n \t  return res;\n@@ -1445,8 +1445,8 @@ constant_pointer_difference (tree p1, tree p2)\n \t\t{\n \t\t  p = TREE_OPERAND (q, 0);\n \t\t  off = size_binop (PLUS_EXPR, off,\n-\t\t\t\t    double_int_to_tree (sizetype,\n-\t\t\t\t\t\t\tmem_ref_offset (q)));\n+\t\t\t\t    wide_int_to_tree (sizetype,\n+\t\t\t\t\t\t      mem_ref_offset (q)));\n \t\t}\n \t      else\n \t\t{\n@@ -2837,7 +2837,7 @@ associate_pointerplus_align (gimple_stmt_iterator *gsi)\n   if (gimple_assign_rhs1 (def_stmt) != ptr)\n     return false;\n \n-  algn = double_int_to_tree (TREE_TYPE (ptr), ~tree_to_double_int (algn));\n+  algn = wide_int_to_tree (TREE_TYPE (ptr), wi::bit_not (algn));\n   gimple_assign_set_rhs_with_ops (gsi, BIT_AND_EXPR, ptr, algn);\n   fold_stmt_inplace (gsi);\n   update_stmt (stmt);\n@@ -3098,8 +3098,10 @@ combine_conversions (gimple_stmt_iterator *gsi)\n \t  tree tem;\n \t  tem = fold_build2 (BIT_AND_EXPR, inside_type,\n \t\t\t     defop0,\n-\t\t\t     double_int_to_tree\n-\t\t\t       (inside_type, double_int::mask (inter_prec)));\n+\t\t\t     wide_int_to_tree\n+\t\t\t     (inside_type,\n+\t\t\t      wi::mask (inter_prec, false,\n+\t\t\t\t\tTYPE_PRECISION (inside_type))));\n \t  if (!useless_type_conversion_p (type, inside_type))\n \t    {\n \t      tem = force_gimple_operand_gsi (gsi, tem, true, NULL_TREE, true,"}, {"sha": "5863127c49376d3c178b14b4a8080a5ee6ab960b", "filename": "gcc/tree-ssa-loop-im.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-im.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-im.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-im.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1601,7 +1601,7 @@ mem_refs_may_alias_p (mem_ref_p mem1, mem_ref_p mem2,\n   /* Perform BASE + OFFSET analysis -- if MEM1 and MEM2 are based on the same\n      object and their offset differ in such a way that the locations cannot\n      overlap, then they cannot alias.  */\n-  double_int size1, size2;\n+  widest_int size1, size2;\n   aff_tree off1, off2;\n \n   /* Perform basic offset and type-based disambiguation.  */\n@@ -1617,7 +1617,7 @@ mem_refs_may_alias_p (mem_ref_p mem1, mem_ref_p mem2,\n   get_inner_reference_aff (mem2->mem.ref, &off2, &size2);\n   aff_combination_expand (&off1, ttae_cache);\n   aff_combination_expand (&off2, ttae_cache);\n-  aff_combination_scale (&off1, double_int_minus_one);\n+  aff_combination_scale (&off1, -1);\n   aff_combination_add (&off2, &off1);\n \n   if (aff_comb_cannot_overlap_p (&off2, size1, size2))"}, {"sha": "e332918fd16ba567e2e840ed93d5cdc3b08f8f79", "filename": "gcc/tree-ssa-loop-ivcanon.c", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-ivcanon.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-ivcanon.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-ivcanon.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -490,7 +490,7 @@ remove_exits_and_undefined_stmts (struct loop *loop, unsigned int npeeled)\n \t into unreachable (or trap when debugging experience is supposed\n \t to be good).  */\n       if (!elt->is_exit\n-\t  && elt->bound.ult (double_int::from_uhwi (npeeled)))\n+\t  && wi::ltu_p (elt->bound, npeeled))\n \t{\n \t  gimple_stmt_iterator gsi = gsi_for_stmt (elt->stmt);\n \t  gimple stmt = gimple_build_call\n@@ -507,7 +507,7 @@ remove_exits_and_undefined_stmts (struct loop *loop, unsigned int npeeled)\n \t}\n       /* If we know the exit will be taken after peeling, update.  */\n       else if (elt->is_exit\n-\t       && elt->bound.ule (double_int::from_uhwi (npeeled)))\n+\t       && wi::leu_p (elt->bound, npeeled))\n \t{\n \t  basic_block bb = gimple_bb (elt->stmt);\n \t  edge exit_edge = EDGE_SUCC (bb, 0);\n@@ -547,7 +547,7 @@ remove_redundant_iv_tests (struct loop *loop)\n       /* Exit is pointless if it won't be taken before loop reaches\n \t upper bound.  */\n       if (elt->is_exit && loop->any_upper_bound\n-          && loop->nb_iterations_upper_bound.ult (elt->bound))\n+          && wi::ltu_p (loop->nb_iterations_upper_bound, elt->bound))\n \t{\n \t  basic_block bb = gimple_bb (elt->stmt);\n \t  edge exit_edge = EDGE_SUCC (bb, 0);\n@@ -564,8 +564,8 @@ remove_redundant_iv_tests (struct loop *loop)\n \t      || !integer_zerop (niter.may_be_zero)\n \t      || !niter.niter\n \t      || TREE_CODE (niter.niter) != INTEGER_CST\n-\t      || !loop->nb_iterations_upper_bound.ult\n-\t\t   (tree_to_double_int (niter.niter)))\n+\t      || !wi::ltu_p (loop->nb_iterations_upper_bound,\n+\t\t\t     wi::to_widest (niter.niter)))\n \t    continue;\n \t  \n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n@@ -946,7 +946,7 @@ canonicalize_loop_induction_variables (struct loop *loop,\n      by find_loop_niter_by_eval.  Be sure to keep it for future.  */\n   if (niter && TREE_CODE (niter) == INTEGER_CST)\n     {\n-      record_niter_bound (loop, tree_to_double_int (niter),\n+      record_niter_bound (loop, wi::to_widest (niter),\n \t\t\t  exit == single_likely_exit (loop), true);\n     }\n "}, {"sha": "b0d39271798fbd26635375dd98727f8a30d5b9da", "filename": "gcc/tree-ssa-loop-ivopts.c", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-ivopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-ivopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-ivopts.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -948,7 +948,7 @@ alloc_iv (tree base, tree step)\n       && !DECL_P (TREE_OPERAND (base_object, 0)))\n     {\n       aff_tree comb;\n-      double_int size;\n+      widest_int size;\n       base_object = get_inner_reference_aff (TREE_OPERAND (base_object, 0),\n \t\t\t\t\t     &comb, &size);\n       gcc_assert (base_object != NULL_TREE);\n@@ -1611,19 +1611,19 @@ idx_record_use (tree base, tree *idx,\n    signedness of TOP and BOT.  */\n \n static bool\n-constant_multiple_of (tree top, tree bot, double_int *mul)\n+constant_multiple_of (tree top, tree bot, widest_int *mul)\n {\n   tree mby;\n   enum tree_code code;\n-  double_int res, p0, p1;\n   unsigned precision = TYPE_PRECISION (TREE_TYPE (top));\n+  widest_int res, p0, p1;\n \n   STRIP_NOPS (top);\n   STRIP_NOPS (bot);\n \n   if (operand_equal_p (top, bot, 0))\n     {\n-      *mul = double_int_one;\n+      *mul = 1;\n       return true;\n     }\n \n@@ -1638,7 +1638,7 @@ constant_multiple_of (tree top, tree bot, double_int *mul)\n       if (!constant_multiple_of (TREE_OPERAND (top, 0), bot, &res))\n \treturn false;\n \n-      *mul = (res * tree_to_double_int (mby)).sext (precision);\n+      *mul = wi::sext (res * wi::to_widest (mby), precision);\n       return true;\n \n     case PLUS_EXPR:\n@@ -1649,19 +1649,19 @@ constant_multiple_of (tree top, tree bot, double_int *mul)\n \n       if (code == MINUS_EXPR)\n \tp1 = -p1;\n-      *mul = (p0 + p1).sext (precision);\n+      *mul = wi::sext (p0 + p1, precision);\n       return true;\n \n     case INTEGER_CST:\n       if (TREE_CODE (bot) != INTEGER_CST)\n \treturn false;\n \n-      p0 = tree_to_double_int (top).sext (precision);\n-      p1 = tree_to_double_int (bot).sext (precision);\n-      if (p1.is_zero ())\n+      p0 = widest_int::from (top, SIGNED);\n+      p1 = widest_int::from (bot, SIGNED);\n+      if (p1 == 0)\n \treturn false;\n-      *mul = p0.sdivmod (p1, FLOOR_DIV_EXPR, &res).sext (precision);\n-      return res.is_zero ();\n+      *mul = wi::sext (wi::divmod_trunc (p0, p1, SIGNED, &res), precision);\n+      return res == 0;\n \n     default:\n       return false;\n@@ -3018,7 +3018,7 @@ get_computation_aff (struct loop *loop,\n   tree common_type, var;\n   tree uutype;\n   aff_tree cbase_aff, var_aff;\n-  double_int rat;\n+  widest_int rat;\n \n   if (TYPE_PRECISION (utype) > TYPE_PRECISION (ctype))\n     {\n@@ -3838,7 +3838,7 @@ ptr_difference_cost (struct ivopts_data *data,\n   type = signed_type_for (TREE_TYPE (e1));\n   tree_to_aff_combination (e1, type, &aff_e1);\n   tree_to_aff_combination (e2, type, &aff_e2);\n-  aff_combination_scale (&aff_e2, double_int_minus_one);\n+  aff_combination_scale (&aff_e2, -1);\n   aff_combination_add (&aff_e1, &aff_e2);\n \n   return force_var_cost (data, aff_combination_to_tree (&aff_e1), depends_on);\n@@ -3893,7 +3893,7 @@ difference_cost (struct ivopts_data *data,\n   type = signed_type_for (TREE_TYPE (e1));\n   tree_to_aff_combination (e1, type, &aff_e1);\n   tree_to_aff_combination (e2, type, &aff_e2);\n-  aff_combination_scale (&aff_e2, double_int_minus_one);\n+  aff_combination_scale (&aff_e2, -1);\n   aff_combination_add (&aff_e1, &aff_e2);\n \n   return force_var_cost (data, aff_combination_to_tree (&aff_e1), depends_on);\n@@ -4037,7 +4037,7 @@ get_loop_invariant_expr_id (struct ivopts_data *data, tree ubase,\n   tree_to_aff_combination (ub, TREE_TYPE (ub), &ubase_aff);\n   tree_to_aff_combination (cb, TREE_TYPE (cb), &cbase_aff);\n \n-  aff_combination_scale (&cbase_aff, double_int::from_shwi (-1 * ratio));\n+  aff_combination_scale (&cbase_aff, -1 * ratio);\n   aff_combination_add (&ubase_aff, &cbase_aff);\n   expr = aff_combination_to_tree (&ubase_aff);\n   return get_expr_id (data, expr);\n@@ -4067,7 +4067,7 @@ get_computation_cost_at (struct ivopts_data *data,\n   HOST_WIDE_INT ratio, aratio;\n   bool var_present, symbol_present, stmt_is_after_inc;\n   comp_cost cost;\n-  double_int rat;\n+  widest_int rat;\n   bool speed = optimize_bb_for_speed_p (gimple_bb (at));\n   enum machine_mode mem_mode = (address_p\n \t\t\t\t? TYPE_MODE (TREE_TYPE (*use->op_p))\n@@ -4126,7 +4126,7 @@ get_computation_cost_at (struct ivopts_data *data,\n   if (!constant_multiple_of (ustep, cstep, &rat))\n     return infinite_cost;\n \n-  if (rat.fits_shwi ())\n+  if (wi::fits_shwi_p (rat))\n     ratio = rat.to_shwi ();\n   else\n     return infinite_cost;\n@@ -4640,11 +4640,11 @@ iv_elimination_compare_lt (struct ivopts_data *data,\n   tree_to_aff_combination (niter->niter, nit_type, &nit);\n   tree_to_aff_combination (fold_convert (nit_type, a), nit_type, &tmpa);\n   tree_to_aff_combination (fold_convert (nit_type, b), nit_type, &tmpb);\n-  aff_combination_scale (&nit, double_int_minus_one);\n-  aff_combination_scale (&tmpa, double_int_minus_one);\n+  aff_combination_scale (&nit, -1);\n+  aff_combination_scale (&tmpa, -1);\n   aff_combination_add (&tmpb, &tmpa);\n   aff_combination_add (&tmpb, &nit);\n-  if (tmpb.n != 0 || tmpb.offset != double_int_one)\n+  if (tmpb.n != 0 || tmpb.offset != 1)\n     return false;\n \n   /* Finally, check that CAND->IV->BASE - CAND->IV->STEP * A does not\n@@ -4730,21 +4730,21 @@ may_eliminate_iv (struct ivopts_data *data,\n      entire loop and compare against that instead.  */\n   else\n     {\n-      double_int period_value, max_niter;\n+      widest_int period_value, max_niter;\n \n       max_niter = desc->max;\n       if (stmt_after_increment (loop, cand, use->stmt))\n-        max_niter += double_int_one;\n-      period_value = tree_to_double_int (period);\n-      if (max_niter.ugt (period_value))\n+        max_niter += 1;\n+      period_value = wi::to_widest (period);\n+      if (wi::gtu_p (max_niter, period_value))\n         {\n           /* See if we can take advantage of inferred loop bound information.  */\n           if (data->loop_single_exit_p)\n             {\n               if (!max_loop_iterations (loop, &max_niter))\n                 return false;\n               /* The loop bound is already adjusted by adding 1.  */\n-              if (max_niter.ugt (period_value))\n+              if (wi::gtu_p (max_niter, period_value))\n                 return false;\n             }\n           else"}, {"sha": "a48ad10424e95f746ae3ad4a15fa2636025fd464", "filename": "gcc/tree-ssa-loop-niter.c", "status": "modified", "additions": 124, "deletions": 136, "changes": 260, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-niter.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-niter.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-niter.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -55,6 +55,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-pass.h\"\n #include \"stringpool.h\"\n #include \"tree-ssanames.h\"\n+#include \"wide-int-print.h\"\n \n \n #define SWAP(X, Y) do { affine_iv *tmp = (X); (X) = (Y); (Y) = tmp; } while (0)\n@@ -85,7 +86,6 @@ split_to_var_and_offset (tree expr, tree *var, mpz_t offset)\n {\n   tree type = TREE_TYPE (expr);\n   tree op0, op1;\n-  double_int off;\n   bool negate = false;\n \n   *var = expr;\n@@ -107,17 +107,14 @@ split_to_var_and_offset (tree expr, tree *var, mpz_t offset)\n \n       *var = op0;\n       /* Always sign extend the offset.  */\n-      off = tree_to_double_int (op1);\n-      off = off.sext (TYPE_PRECISION (type));\n-      mpz_set_double_int (offset, off, false);\n+      wi::to_mpz (op1, offset, SIGNED);\n       if (negate)\n \tmpz_neg (offset, offset);\n       break;\n \n     case INTEGER_CST:\n       *var = build_int_cst_type (type, 0);\n-      off = tree_to_double_int (expr);\n-      mpz_set_double_int (offset, off, TYPE_UNSIGNED (type));\n+      wi::to_mpz (expr, offset, TYPE_SIGN (type));\n       break;\n \n     default:\n@@ -132,7 +129,7 @@ static void\n determine_value_range (struct loop *loop, tree type, tree var, mpz_t off,\n \t\t       mpz_t min, mpz_t max)\n {\n-  double_int minv, maxv;\n+  wide_int minv, maxv;\n   enum value_range_type rtype = VR_VARYING;\n \n   /* If the expression is a constant, we know its value exactly.  */\n@@ -149,6 +146,7 @@ determine_value_range (struct loop *loop, tree type, tree var, mpz_t off,\n   if (TREE_CODE (var) == SSA_NAME && INTEGRAL_TYPE_P (type))\n     {\n       edge e = loop_preheader_edge (loop);\n+      signop sgn = TYPE_SIGN (type);\n       gimple_stmt_iterator gsi;\n \n       /* Either for VAR itself...  */\n@@ -158,7 +156,7 @@ determine_value_range (struct loop *loop, tree type, tree var, mpz_t off,\n       for (gsi = gsi_start_phis (loop->header); !gsi_end_p (gsi); gsi_next (&gsi))\n \t{\n \t  gimple phi = gsi_stmt (gsi);\n-\t  double_int minc, maxc;\n+\t  wide_int minc, maxc;\n \t  if (PHI_ARG_DEF_FROM_EDGE (phi, e) == var\n \t      && (get_range_info (gimple_phi_result (phi), &minc, &maxc)\n \t\t  == VR_RANGE))\n@@ -171,13 +169,13 @@ determine_value_range (struct loop *loop, tree type, tree var, mpz_t off,\n \t\t}\n \t      else\n \t\t{\n-\t\t  minv = minv.max (minc, TYPE_UNSIGNED (type));\n-\t\t  maxv = maxv.min (maxc, TYPE_UNSIGNED (type));\n+\t\t  minv = wi::max (minv, minc, sgn);\n+\t\t  maxv = wi::min (maxv, maxc, sgn);\n \t\t  /* If the PHI result range are inconsistent with\n \t\t     the VAR range, give up on looking at the PHI\n \t\t     results.  This can happen if VR_UNDEFINED is\n \t\t     involved.  */\n-\t\t  if (minv.cmp (maxv, TYPE_UNSIGNED (type)) > 0)\n+\t\t  if (wi::gt_p (minv, maxv, sgn))\n \t\t    {\n \t\t      rtype = get_range_info (var, &minv, &maxv);\n \t\t      break;\n@@ -188,11 +186,11 @@ determine_value_range (struct loop *loop, tree type, tree var, mpz_t off,\n       if (rtype == VR_RANGE)\n \t{\n \t  mpz_t minm, maxm;\n-\t  gcc_assert (minv.cmp (maxv, TYPE_UNSIGNED (type)) <= 0);\n+\t  gcc_assert (wi::le_p (minv, maxv, sgn));\n \t  mpz_init (minm);\n \t  mpz_init (maxm);\n-\t  mpz_set_double_int (minm, minv, TYPE_UNSIGNED (type));\n-\t  mpz_set_double_int (maxm, maxv, TYPE_UNSIGNED (type));\n+\t  wi::to_mpz (minv, minm, sgn);\n+\t  wi::to_mpz (maxv, maxm, sgn);\n \t  mpz_add (minm, minm, off);\n \t  mpz_add (maxm, maxm, off);\n \t  /* If the computation may not wrap or off is zero, then this\n@@ -262,7 +260,7 @@ bound_difference_of_offsetted_base (tree type, mpz_t x, mpz_t y,\n     }\n \n   mpz_init (m);\n-  mpz_set_double_int (m, double_int::mask (TYPE_PRECISION (type)), true);\n+  wi::to_mpz (wi::minus_one (TYPE_PRECISION (type)), m, UNSIGNED);\n   mpz_add_ui (m, m, 1);\n   mpz_sub (bnds->up, x, y);\n   mpz_set (bnds->below, bnds->up);\n@@ -541,15 +539,15 @@ bound_difference (struct loop *loop, tree x, tree y, bounds *bnds)\n    difference of two values in TYPE.  */\n \n static void\n-bounds_add (bounds *bnds, double_int delta, tree type)\n+bounds_add (bounds *bnds, const widest_int &delta, tree type)\n {\n   mpz_t mdelta, max;\n \n   mpz_init (mdelta);\n-  mpz_set_double_int (mdelta, delta, false);\n+  wi::to_mpz (delta, mdelta, SIGNED);\n \n   mpz_init (max);\n-  mpz_set_double_int (max, double_int::mask (TYPE_PRECISION (type)), true);\n+  wi::to_mpz (wi::minus_one (TYPE_PRECISION (type)), max, UNSIGNED);\n \n   mpz_add (bnds->up, bnds->up, mdelta);\n   mpz_add (bnds->below, bnds->below, mdelta);\n@@ -643,7 +641,7 @@ static void\n number_of_iterations_ne_max (mpz_t bnd, bool no_overflow, tree c, tree s,\n \t\t\t     bounds *bnds, bool exit_must_be_taken)\n {\n-  double_int max;\n+  widest_int max;\n   mpz_t d;\n   tree type = TREE_TYPE (c);\n   bool bnds_u_valid = ((no_overflow && exit_must_be_taken)\n@@ -652,10 +650,8 @@ number_of_iterations_ne_max (mpz_t bnd, bool no_overflow, tree c, tree s,\n   if (integer_onep (s)\n       || (TREE_CODE (c) == INTEGER_CST\n \t  && TREE_CODE (s) == INTEGER_CST\n-\t  && tree_to_double_int (c).mod (tree_to_double_int (s),\n-\t\t\t\t\t TYPE_UNSIGNED (type),\n-\t\t\t\t\t EXACT_DIV_EXPR).is_zero ())\n-      || (TYPE_OVERFLOW_UNDEFINED (TREE_TYPE (c))\n+\t  && wi::mod_trunc (c, s, TYPE_SIGN (type)) == 0)\n+      || (TYPE_OVERFLOW_UNDEFINED (type)\n \t  && multiple_of_p (type, c, s)))\n     {\n       /* If C is an exact multiple of S, then its value will be reached before\n@@ -673,15 +669,14 @@ number_of_iterations_ne_max (mpz_t bnd, bool no_overflow, tree c, tree s,\n      the whole # of iterations analysis will fail).  */\n   if (!no_overflow)\n     {\n-      max = double_int::mask (TYPE_PRECISION (type)\n-\t\t\t      - tree_to_uhwi (num_ending_zeros (s)));\n-      mpz_set_double_int (bnd, max, true);\n+      max = wi::mask <widest_int> (TYPE_PRECISION (type) - wi::ctz (s), false);\n+      wi::to_mpz (max, bnd, UNSIGNED);\n       return;\n     }\n \n   /* Now we know that the induction variable does not overflow, so the loop\n      iterates at most (range of type / S) times.  */\n-  mpz_set_double_int (bnd, double_int::mask (TYPE_PRECISION (type)), true);\n+  wi::to_mpz (wi::minus_one (TYPE_PRECISION (type)), bnd, UNSIGNED);\n \n   /* If the induction variable is guaranteed to reach the value of C before\n      overflow, ... */\n@@ -690,13 +685,13 @@ number_of_iterations_ne_max (mpz_t bnd, bool no_overflow, tree c, tree s,\n       /* ... then we can strengthen this to C / S, and possibly we can use\n \t the upper bound on C given by BNDS.  */\n       if (TREE_CODE (c) == INTEGER_CST)\n-\tmpz_set_double_int (bnd, tree_to_double_int (c), true);\n+\twi::to_mpz (c, bnd, UNSIGNED);\n       else if (bnds_u_valid)\n \tmpz_set (bnd, bnds->up);\n     }\n \n   mpz_init (d);\n-  mpz_set_double_int (d, tree_to_double_int (s), true);\n+  wi::to_mpz (s, d, UNSIGNED);\n   mpz_fdiv_q (bnd, bnd, d);\n   mpz_clear (d);\n }\n@@ -747,7 +742,8 @@ number_of_iterations_ne (tree type, affine_iv *iv, tree final,\n   mpz_init (max);\n   number_of_iterations_ne_max (max, iv->no_overflow, c, s, bnds,\n \t\t\t       exit_must_be_taken);\n-  niter->max = mpz_get_double_int (niter_type, max, false);\n+  niter->max = widest_int::from (wi::from_mpz (niter_type, max, false),\n+\t\t\t\t TYPE_SIGN (niter_type));\n   mpz_clear (max);\n \n   /* First the trivial cases -- when the step is 1.  */\n@@ -820,7 +816,7 @@ number_of_iterations_lt_to_ne (tree type, affine_iv *iv0, affine_iv *iv1,\n   tmod = fold_convert (type1, mod);\n \n   mpz_init (mmod);\n-  mpz_set_double_int (mmod, tree_to_double_int (mod), true);\n+  wi::to_mpz (mod, mmod, UNSIGNED);\n   mpz_neg (mmod, mmod);\n \n   /* If the induction variable does not overflow and the exit is taken,\n@@ -902,7 +898,7 @@ number_of_iterations_lt_to_ne (tree type, affine_iv *iv0, affine_iv *iv1,\n     niter->may_be_zero = fold_build2 (TRUTH_OR_EXPR, boolean_type_node,\n \t\t\t\t      niter->may_be_zero,\n \t\t\t\t      noloop);\n-  bounds_add (bnds, tree_to_double_int (mod), type);\n+  bounds_add (bnds, wi::to_widest (mod), type);\n   *delta = fold_build2 (PLUS_EXPR, niter_type, *delta, mod);\n \n   ret = true;\n@@ -992,7 +988,7 @@ assert_loop_rolls_lt (tree type, affine_iv *iv0, affine_iv *iv1,\n   tree assumption = boolean_true_node, bound, diff;\n   tree mbz, mbzl, mbzr, type1;\n   bool rolls_p, no_overflow_p;\n-  double_int dstep;\n+  widest_int dstep;\n   mpz_t mstep, max;\n \n   /* We are going to compute the number of iterations as\n@@ -1018,22 +1014,22 @@ assert_loop_rolls_lt (tree type, affine_iv *iv0, affine_iv *iv1,\n   /* First check whether the answer does not follow from the bounds we gathered\n      before.  */\n   if (integer_nonzerop (iv0->step))\n-    dstep = tree_to_double_int (iv0->step);\n+    dstep = wi::to_widest (iv0->step);\n   else\n     {\n-      dstep = tree_to_double_int (iv1->step).sext (TYPE_PRECISION (type));\n+      dstep = wi::sext (wi::to_widest (iv1->step), TYPE_PRECISION (type));\n       dstep = -dstep;\n     }\n \n   mpz_init (mstep);\n-  mpz_set_double_int (mstep, dstep, true);\n+  wi::to_mpz (dstep, mstep, UNSIGNED);\n   mpz_neg (mstep, mstep);\n   mpz_add_ui (mstep, mstep, 1);\n \n   rolls_p = mpz_cmp (mstep, bnds->below) <= 0;\n \n   mpz_init (max);\n-  mpz_set_double_int (max, double_int::mask (TYPE_PRECISION (type)), true);\n+  wi::to_mpz (wi::minus_one (TYPE_PRECISION (type)), max, UNSIGNED);\n   mpz_add (max, max, mstep);\n   no_overflow_p = (mpz_cmp (bnds->up, max) <= 0\n \t\t   /* For pointers, only values lying inside a single object\n@@ -1160,7 +1156,8 @@ number_of_iterations_lt (tree type, affine_iv *iv0, affine_iv *iv1,\n \tniter->may_be_zero = fold_build2 (LT_EXPR, boolean_type_node,\n \t\t\t\t\t  iv1->base, iv0->base);\n       niter->niter = delta;\n-      niter->max = mpz_get_double_int (niter_type, bnds->up, false);\n+      niter->max = widest_int::from (wi::from_mpz (niter_type, bnds->up, false),\n+\t\t\t\t     TYPE_SIGN (niter_type));\n       return true;\n     }\n \n@@ -1203,11 +1200,12 @@ number_of_iterations_lt (tree type, affine_iv *iv0, affine_iv *iv1,\n \n   mpz_init (mstep);\n   mpz_init (tmp);\n-  mpz_set_double_int (mstep, tree_to_double_int (step), true);\n+  wi::to_mpz (step, mstep, UNSIGNED);\n   mpz_add (tmp, bnds->up, mstep);\n   mpz_sub_ui (tmp, tmp, 1);\n   mpz_fdiv_q (tmp, tmp, mstep);\n-  niter->max = mpz_get_double_int (niter_type, tmp, false);\n+  niter->max = widest_int::from (wi::from_mpz (niter_type, tmp, false),\n+\t\t\t\t TYPE_SIGN (niter_type));\n   mpz_clear (mstep);\n   mpz_clear (tmp);\n \n@@ -1270,7 +1268,7 @@ number_of_iterations_le (tree type, affine_iv *iv0, affine_iv *iv1,\n     iv0->base = fold_build2 (MINUS_EXPR, type1,\n \t\t\t     iv0->base, build_int_cst (type1, 1));\n \n-  bounds_add (bnds, double_int_one, type1);\n+  bounds_add (bnds, 1, type1);\n \n   return number_of_iterations_lt (type, iv0, iv1, niter, exit_must_be_taken,\n \t\t\t\t  bnds);\n@@ -1342,8 +1340,7 @@ number_of_iterations_cond (struct loop *loop,\n   niter->assumptions = boolean_true_node;\n   niter->may_be_zero = boolean_false_node;\n   niter->niter = NULL_TREE;\n-  niter->max = double_int_zero;\n-\n+  niter->max = 0;\n   niter->bound = NULL_TREE;\n   niter->cmp = ERROR_MARK;\n \n@@ -1415,7 +1412,7 @@ number_of_iterations_cond (struct loop *loop,\n   if (tem && integer_zerop (tem))\n     {\n       niter->niter = build_int_cst (unsigned_type_for (type), 0);\n-      niter->max = double_int_zero;\n+      niter->max = 0;\n       return true;\n     }\n \n@@ -1491,7 +1488,7 @@ number_of_iterations_cond (struct loop *loop,\n \t  fprintf (dump_file, \"    # of iterations \");\n \t  print_generic_expr (dump_file, niter->niter, TDF_SLIM);\n \t  fprintf (dump_file, \", bounded by \");\n-\t  dump_double_int (dump_file, niter->max, true);\n+\t  print_decu (niter->max, dump_file);\n \t  fprintf (dump_file, \"\\n\");\n \t}\n       else\n@@ -2003,7 +2000,7 @@ number_of_iterations_exit (struct loop *loop, edge exit,\n \n   /* If NITER has simplified into a constant, update MAX.  */\n   if (TREE_CODE (niter->niter) == INTEGER_CST)\n-    niter->max = tree_to_double_int (niter->niter);\n+    niter->max = wi::to_widest (niter->niter);\n \n   if (integer_onep (niter->assumptions))\n     return true;\n@@ -2115,7 +2112,7 @@ find_loop_niter (struct loop *loop, edge *exit)\n bool\n finite_loop_p (struct loop *loop)\n {\n-  double_int nit;\n+  widest_int nit;\n   int flags;\n \n   if (flag_unsafe_loop_optimizations)\n@@ -2430,13 +2427,13 @@ find_loop_niter_by_eval (struct loop *loop, edge *exit)\n \n */\n \n-static double_int derive_constant_upper_bound_ops (tree, tree,\n+static widest_int derive_constant_upper_bound_ops (tree, tree,\n \t\t\t\t\t\t   enum tree_code, tree);\n \n /* Returns a constant upper bound on the value of the right-hand side of\n    an assignment statement STMT.  */\n \n-static double_int\n+static widest_int\n derive_constant_upper_bound_assign (gimple stmt)\n {\n   enum tree_code code = gimple_assign_rhs_code (stmt);\n@@ -2451,7 +2448,7 @@ derive_constant_upper_bound_assign (gimple stmt)\n    is considered to be unsigned.  If its type is signed, its value must\n    be nonnegative.  */\n \n-static double_int\n+static widest_int\n derive_constant_upper_bound (tree val)\n {\n   enum tree_code code;\n@@ -2465,25 +2462,25 @@ derive_constant_upper_bound (tree val)\n    whose type is TYPE.  The expression is considered to be unsigned.  If\n    its type is signed, its value must be nonnegative.  */\n \n-static double_int\n+static widest_int\n derive_constant_upper_bound_ops (tree type, tree op0,\n \t\t\t\t enum tree_code code, tree op1)\n {\n   tree subtype, maxt;\n-  double_int bnd, max, mmax, cst;\n+  widest_int bnd, max, mmax, cst;\n   gimple stmt;\n \n   if (INTEGRAL_TYPE_P (type))\n     maxt = TYPE_MAX_VALUE (type);\n   else\n     maxt = upper_bound_in_type (type, type);\n \n-  max = tree_to_double_int (maxt);\n+  max = wi::to_widest (maxt);\n \n   switch (code)\n     {\n     case INTEGER_CST:\n-      return tree_to_double_int (op0);\n+      return wi::to_widest (op0);\n \n     CASE_CONVERT:\n       subtype = TREE_TYPE (op0);\n@@ -2505,7 +2502,7 @@ derive_constant_upper_bound_ops (tree type, tree op0,\n \n       /* If the bound does not fit in TYPE, max. value of TYPE could be\n \t attained.  */\n-      if (max.ult (bnd))\n+      if (wi::ltu_p (max, bnd))\n \treturn max;\n \n       return bnd;\n@@ -2520,25 +2517,24 @@ derive_constant_upper_bound_ops (tree type, tree op0,\n       /* Canonicalize to OP0 - CST.  Consider CST to be signed, in order to\n \t choose the most logical way how to treat this constant regardless\n \t of the signedness of the type.  */\n-      cst = tree_to_double_int (op1);\n-      cst = cst.sext (TYPE_PRECISION (type));\n+      cst = wi::sext (wi::to_widest (op1), TYPE_PRECISION (type));\n       if (code != MINUS_EXPR)\n \tcst = -cst;\n \n       bnd = derive_constant_upper_bound (op0);\n \n-      if (cst.is_negative ())\n+      if (wi::neg_p (cst))\n \t{\n \t  cst = -cst;\n \t  /* Avoid CST == 0x80000...  */\n-\t  if (cst.is_negative ())\n+\t  if (wi::neg_p (cst))\n \t    return max;;\n \n \t  /* OP0 + CST.  We need to check that\n \t     BND <= MAX (type) - CST.  */\n \n \t  mmax -= cst;\n-\t  if (bnd.ugt (mmax))\n+\t  if (wi::ltu_p (bnd, max))\n \t    return max;\n \n \t  return bnd + cst;\n@@ -2558,13 +2554,13 @@ derive_constant_upper_bound_ops (tree type, tree op0,\n \t  /* This should only happen if the type is unsigned; however, for\n \t     buggy programs that use overflowing signed arithmetics even with\n \t     -fno-wrapv, this condition may also be true for signed values.  */\n-\t  if (bnd.ult (cst))\n+\t  if (wi::ltu_p (bnd, cst))\n \t    return max;\n \n \t  if (TYPE_UNSIGNED (type))\n \t    {\n \t      tree tem = fold_binary (GE_EXPR, boolean_type_node, op0,\n-\t\t\t\t      double_int_to_tree (type, cst));\n+\t\t\t\t      wide_int_to_tree (type, cst));\n \t      if (!tem || integer_nonzerop (tem))\n \t\treturn max;\n \t    }\n@@ -2581,13 +2577,13 @@ derive_constant_upper_bound_ops (tree type, tree op0,\n \treturn max;\n \n       bnd = derive_constant_upper_bound (op0);\n-      return bnd.udiv (tree_to_double_int (op1), FLOOR_DIV_EXPR);\n+      return wi::udiv_floor (bnd, wi::to_widest (op1));\n \n     case BIT_AND_EXPR:\n       if (TREE_CODE (op1) != INTEGER_CST\n \t  || tree_int_cst_sign_bit (op1))\n \treturn max;\n-      return tree_to_double_int (op1);\n+      return wi::to_widest (op1);\n \n     case SSA_NAME:\n       stmt = SSA_NAME_DEF_STMT (op0);\n@@ -2605,7 +2601,7 @@ derive_constant_upper_bound_ops (tree type, tree op0,\n \n static void\n do_warn_aggressive_loop_optimizations (struct loop *loop,\n-\t\t\t\t       double_int i_bound, gimple stmt)\n+\t\t\t\t       widest_int i_bound, gimple stmt)\n {\n   /* Don't warn if the loop doesn't have known constant bound.  */\n   if (!loop->nb_iterations\n@@ -2618,7 +2614,7 @@ do_warn_aggressive_loop_optimizations (struct loop *loop,\n       || loop->warned_aggressive_loop_optimizations\n       /* Only warn if undefined behavior gives us lower estimate than the\n \t known constant bound.  */\n-      || i_bound.ucmp (tree_to_double_int (loop->nb_iterations)) >= 0\n+      || wi::cmpu (i_bound, wi::to_widest (loop->nb_iterations)) >= 0\n       /* And undefined behavior happens unconditionally.  */\n       || !dominated_by_p (CDI_DOMINATORS, loop->latch, gimple_bb (stmt)))\n     return;\n@@ -2630,8 +2626,8 @@ do_warn_aggressive_loop_optimizations (struct loop *loop,\n   gimple estmt = last_stmt (e->src);\n   if (warning_at (gimple_location (stmt), OPT_Waggressive_loop_optimizations,\n \t\t  \"iteration %E invokes undefined behavior\",\n-\t\t  double_int_to_tree (TREE_TYPE (loop->nb_iterations),\n-\t\t\t\t      i_bound)))\n+\t\t  wide_int_to_tree (TREE_TYPE (loop->nb_iterations),\n+\t\t\t\t    i_bound)))\n     inform (gimple_location (estmt), \"containing loop\");\n   loop->warned_aggressive_loop_optimizations = true;\n }\n@@ -2641,13 +2637,13 @@ do_warn_aggressive_loop_optimizations (struct loop *loop,\n    is taken at last when the STMT is executed BOUND + 1 times.\n    REALISTIC is true if BOUND is expected to be close to the real number\n    of iterations.  UPPER is true if we are sure the loop iterates at most\n-   BOUND times.  I_BOUND is an unsigned double_int upper estimate on BOUND.  */\n+   BOUND times.  I_BOUND is a widest_int upper estimate on BOUND.  */\n \n static void\n-record_estimate (struct loop *loop, tree bound, double_int i_bound,\n+record_estimate (struct loop *loop, tree bound, const widest_int &i_bound,\n \t\t gimple at_stmt, bool is_exit, bool realistic, bool upper)\n {\n-  double_int delta;\n+  widest_int delta;\n \n   if (dump_file && (dump_flags & TDF_DETAILS))\n     {\n@@ -2657,7 +2653,7 @@ record_estimate (struct loop *loop, tree bound, double_int i_bound,\n \t       upper ? \"\" : \"probably \");\n       print_generic_expr (dump_file, bound, TDF_SLIM);\n       fprintf (dump_file, \" (bounded by \");\n-      dump_double_int (dump_file, i_bound, true);\n+      print_decu (i_bound, dump_file);\n       fprintf (dump_file, \") + 1 times in loop %d.\\n\", loop->num);\n     }\n \n@@ -2666,7 +2662,7 @@ record_estimate (struct loop *loop, tree bound, double_int i_bound,\n   if (TREE_CODE (bound) != INTEGER_CST)\n     realistic = false;\n   else\n-    gcc_checking_assert (i_bound == tree_to_double_int (bound));\n+    gcc_checking_assert (i_bound == wi::to_widest (bound));\n   if (!upper && !realistic)\n     return;\n \n@@ -2697,18 +2693,18 @@ record_estimate (struct loop *loop, tree bound, double_int i_bound,\n      otherwise it can be executed BOUND + 1 times.  We will lower the estimate\n      later if such statement must be executed on last iteration  */\n   if (is_exit)\n-    delta = double_int_zero;\n+    delta = 0;\n   else\n-    delta = double_int_one;\n-  i_bound += delta;\n+    delta = 1;\n+  widest_int new_i_bound = i_bound + delta;\n \n   /* If an overflow occurred, ignore the result.  */\n-  if (i_bound.ult (delta))\n+  if (wi::ltu_p (new_i_bound, delta))\n     return;\n \n   if (upper && !is_exit)\n-    do_warn_aggressive_loop_optimizations (loop, i_bound, at_stmt);\n-  record_niter_bound (loop, i_bound, realistic, upper);\n+    do_warn_aggressive_loop_optimizations (loop, new_i_bound, at_stmt);\n+  record_niter_bound (loop, new_i_bound, realistic, upper);\n }\n \n /* Record the estimate on number of iterations of LOOP based on the fact that\n@@ -2723,7 +2719,6 @@ record_nonwrapping_iv (struct loop *loop, tree base, tree step, gimple stmt,\n {\n   tree niter_bound, extreme, delta;\n   tree type = TREE_TYPE (base), unsigned_type;\n-  double_int max;\n \n   if (TREE_CODE (step) != INTEGER_CST || integer_zerop (step))\n     return;\n@@ -2764,7 +2759,7 @@ record_nonwrapping_iv (struct loop *loop, tree base, tree step, gimple stmt,\n   /* STMT is executed at most NITER_BOUND + 1 times, since otherwise the value\n      would get out of the range.  */\n   niter_bound = fold_build2 (FLOOR_DIV_EXPR, unsigned_type, delta, step);\n-  max = derive_constant_upper_bound (niter_bound);\n+  widest_int max = derive_constant_upper_bound (niter_bound);\n   record_estimate (loop, niter_bound, max, stmt, false, realistic, upper);\n }\n \n@@ -3068,27 +3063,21 @@ infer_loop_bounds_from_undefined (struct loop *loop)\n   free (bbs);\n }\n \n-\n-\n-/* Compare double ints, callback for qsort.  */\n+/* Compare wide ints, callback for qsort.  */\n \n static int\n-double_int_cmp (const void *p1, const void *p2)\n+wide_int_cmp (const void *p1, const void *p2)\n {\n-  const double_int *d1 = (const double_int *)p1;\n-  const double_int *d2 = (const double_int *)p2;\n-  if (*d1 == *d2)\n-    return 0;\n-  if (d1->ult (*d2))\n-    return -1;\n-  return 1;\n+  const widest_int *d1 = (const widest_int *) p1;\n+  const widest_int *d2 = (const widest_int *) p2;\n+  return wi::cmpu (*d1, *d2);\n }\n \n /* Return index of BOUND in BOUNDS array sorted in increasing order.\n    Lookup by binary search.  */\n \n static int\n-bound_index (vec<double_int> bounds, double_int bound)\n+bound_index (vec<widest_int> bounds, const widest_int &bound)\n {\n   unsigned int end = bounds.length ();\n   unsigned int begin = 0;\n@@ -3097,11 +3086,11 @@ bound_index (vec<double_int> bounds, double_int bound)\n   while (begin != end)\n     {\n       unsigned int middle = (begin + end) / 2;\n-      double_int index = bounds[middle];\n+      widest_int index = bounds[middle];\n \n       if (index == bound)\n \treturn middle;\n-      else if (index.ult (bound))\n+      else if (wi::ltu_p (index, bound))\n \tbegin = middle + 1;\n       else\n \tend = middle;\n@@ -3120,7 +3109,7 @@ discover_iteration_bound_by_body_walk (struct loop *loop)\n {\n   pointer_map_t *bb_bounds;\n   struct nb_iter_bound *elt;\n-  vec<double_int> bounds = vNULL;\n+  vec<widest_int> bounds = vNULL;\n   vec<vec<basic_block> > queues = vNULL;\n   vec<basic_block> queue = vNULL;\n   ptrdiff_t queue_index;\n@@ -3130,20 +3119,20 @@ discover_iteration_bound_by_body_walk (struct loop *loop)\n   /* Discover what bounds may interest us.  */\n   for (elt = loop->bounds; elt; elt = elt->next)\n     {\n-      double_int bound = elt->bound;\n+      widest_int bound = elt->bound;\n \n       /* Exit terminates loop at given iteration, while non-exits produce undefined\n \t effect on the next iteration.  */\n       if (!elt->is_exit)\n \t{\n-\t  bound += double_int_one;\n+\t  bound += 1;\n \t  /* If an overflow occurred, ignore the result.  */\n-\t  if (bound.is_zero ())\n+\t  if (bound == 0)\n \t    continue;\n \t}\n \n       if (!loop->any_upper_bound\n-\t  || bound.ult (loop->nb_iterations_upper_bound))\n+\t  || wi::ltu_p (bound, loop->nb_iterations_upper_bound))\n         bounds.safe_push (bound);\n     }\n \n@@ -3156,25 +3145,25 @@ discover_iteration_bound_by_body_walk (struct loop *loop)\n \n   /* Sort the bounds in decreasing order.  */\n   qsort (bounds.address (), bounds.length (),\n-\t sizeof (double_int), double_int_cmp);\n+\t sizeof (widest_int), wide_int_cmp);\n \n   /* For every basic block record the lowest bound that is guaranteed to\n      terminate the loop.  */\n \n   bb_bounds = pointer_map_create ();\n   for (elt = loop->bounds; elt; elt = elt->next)\n     {\n-      double_int bound = elt->bound;\n+      widest_int bound = elt->bound;\n       if (!elt->is_exit)\n \t{\n-\t  bound += double_int_one;\n+\t  bound += 1;\n \t  /* If an overflow occurred, ignore the result.  */\n-\t  if (bound.is_zero ())\n+\t  if (bound == 0)\n \t    continue;\n \t}\n \n       if (!loop->any_upper_bound\n-\t  || bound.ult (loop->nb_iterations_upper_bound))\n+\t  || wi::ltu_p (bound, loop->nb_iterations_upper_bound))\n \t{\n \t  ptrdiff_t index = bound_index (bounds, bound);\n \t  void **entry = pointer_map_contains (bb_bounds,\n@@ -3274,7 +3263,7 @@ discover_iteration_bound_by_body_walk (struct loop *loop)\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \t{\n \t  fprintf (dump_file, \"Found better loop bound \");\n-\t  dump_double_int (dump_file, bounds[latch_index], true);\n+\t  print_decu (bounds[latch_index], dump_file);\n \t  fprintf (dump_file, \"\\n\");\n \t}\n       record_niter_bound (loop, bounds[latch_index], false, true);\n@@ -3309,7 +3298,7 @@ maybe_lower_iteration_bound (struct loop *loop)\n   for (elt = loop->bounds; elt; elt = elt->next)\n     {\n       if (!elt->is_exit\n-\t  && elt->bound.ult (loop->nb_iterations_upper_bound))\n+\t  && wi::ltu_p (elt->bound, loop->nb_iterations_upper_bound))\n \t{\n \t  if (!not_executed_last_iteration)\n \t    not_executed_last_iteration = pointer_set_create ();\n@@ -3383,7 +3372,7 @@ maybe_lower_iteration_bound (struct loop *loop)\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \tfprintf (dump_file, \"Reducing loop iteration estimate by 1; \"\n \t\t \"undefined statement must be executed at the last iteration.\\n\");\n-      record_niter_bound (loop, loop->nb_iterations_upper_bound - double_int_one,\n+      record_niter_bound (loop, loop->nb_iterations_upper_bound - 1,\n \t\t\t  false, true);\n     }\n   BITMAP_FREE (visited);\n@@ -3402,7 +3391,7 @@ estimate_numbers_of_iterations_loop (struct loop *loop)\n   unsigned i;\n   struct tree_niter_desc niter_desc;\n   edge ex;\n-  double_int bound;\n+  widest_int bound;\n   edge likely_exit;\n \n   /* Give up if we already have tried to compute an estimation.  */\n@@ -3449,7 +3438,7 @@ estimate_numbers_of_iterations_loop (struct loop *loop)\n   if (loop->header->count != 0)\n     {\n       gcov_type nit = expected_loop_iterations_unbounded (loop) + 1;\n-      bound = gcov_type_to_double_int (nit);\n+      bound = gcov_type_to_wide_int (nit);\n       record_niter_bound (loop, bound, true, false);\n     }\n \n@@ -3460,8 +3449,7 @@ estimate_numbers_of_iterations_loop (struct loop *loop)\n       && TREE_CODE (loop->nb_iterations) == INTEGER_CST)\n     {\n       loop->any_upper_bound = true;\n-      loop->nb_iterations_upper_bound\n-\t= tree_to_double_int (loop->nb_iterations);\n+      loop->nb_iterations_upper_bound = wi::to_widest (loop->nb_iterations);\n     }\n }\n \n@@ -3471,7 +3459,7 @@ estimate_numbers_of_iterations_loop (struct loop *loop)\n    the function returns false, otherwise returns true.  */\n \n bool\n-estimated_loop_iterations (struct loop *loop, double_int *nit)\n+estimated_loop_iterations (struct loop *loop, widest_int *nit)\n {\n   /* When SCEV information is available, try to update loop iterations\n      estimate.  Otherwise just return whatever we recorded earlier.  */\n@@ -3488,13 +3476,13 @@ estimated_loop_iterations (struct loop *loop, double_int *nit)\n HOST_WIDE_INT\n estimated_loop_iterations_int (struct loop *loop)\n {\n-  double_int nit;\n+  widest_int nit;\n   HOST_WIDE_INT hwi_nit;\n \n   if (!estimated_loop_iterations (loop, &nit))\n     return -1;\n \n-  if (!nit.fits_shwi ())\n+  if (!wi::fits_shwi_p (nit))\n     return -1;\n   hwi_nit = nit.to_shwi ();\n \n@@ -3507,7 +3495,7 @@ estimated_loop_iterations_int (struct loop *loop)\n    false, otherwise returns true.  */\n \n bool\n-max_loop_iterations (struct loop *loop, double_int *nit)\n+max_loop_iterations (struct loop *loop, widest_int *nit)\n {\n   /* When SCEV information is available, try to update loop iterations\n      estimate.  Otherwise just return whatever we recorded earlier.  */\n@@ -3524,13 +3512,13 @@ max_loop_iterations (struct loop *loop, double_int *nit)\n HOST_WIDE_INT\n max_loop_iterations_int (struct loop *loop)\n {\n-  double_int nit;\n+  widest_int nit;\n   HOST_WIDE_INT hwi_nit;\n \n   if (!max_loop_iterations (loop, &nit))\n     return -1;\n \n-  if (!nit.fits_shwi ())\n+  if (!wi::fits_shwi_p (nit))\n     return -1;\n   hwi_nit = nit.to_shwi ();\n \n@@ -3561,37 +3549,37 @@ estimated_stmt_executions_int (struct loop *loop)\n    false, otherwise returns true.  */\n \n bool\n-max_stmt_executions (struct loop *loop, double_int *nit)\n+max_stmt_executions (struct loop *loop, widest_int *nit)\n {\n-  double_int nit_minus_one;\n+  widest_int nit_minus_one;\n \n   if (!max_loop_iterations (loop, nit))\n     return false;\n \n   nit_minus_one = *nit;\n \n-  *nit += double_int_one;\n+  *nit += 1;\n \n-  return (*nit).ugt (nit_minus_one);\n+  return wi::gtu_p (*nit, nit_minus_one);\n }\n \n /* Sets NIT to the estimated number of executions of the latch of the\n    LOOP, plus one.  If we have no reliable estimate, the function returns\n    false, otherwise returns true.  */\n \n bool\n-estimated_stmt_executions (struct loop *loop, double_int *nit)\n+estimated_stmt_executions (struct loop *loop, widest_int *nit)\n {\n-  double_int nit_minus_one;\n+  widest_int nit_minus_one;\n \n   if (!estimated_loop_iterations (loop, nit))\n     return false;\n \n   nit_minus_one = *nit;\n \n-  *nit += double_int_one;\n+  *nit += 1;\n \n-  return (*nit).ugt (nit_minus_one);\n+  return wi::gtu_p (*nit, nit_minus_one);\n }\n \n /* Records estimates on numbers of iterations of loops.  */\n@@ -3662,15 +3650,15 @@ n_of_executions_at_most (gimple stmt,\n \t\t\t struct nb_iter_bound *niter_bound,\n \t\t\t tree niter)\n {\n-  double_int bound = niter_bound->bound;\n+  widest_int bound = niter_bound->bound;\n   tree nit_type = TREE_TYPE (niter), e;\n   enum tree_code cmp;\n \n   gcc_assert (TYPE_UNSIGNED (nit_type));\n \n   /* If the bound does not even fit into NIT_TYPE, it cannot tell us that\n      the number of iterations is small.  */\n-  if (!double_int_fits_to_tree_p (nit_type, bound))\n+  if (!wi::fits_to_tree_p (bound, nit_type))\n     return false;\n \n   /* We know that NITER_BOUND->stmt is executed at most NITER_BOUND->bound + 1\n@@ -3713,16 +3701,16 @@ n_of_executions_at_most (gimple stmt,\n \t       gsi_next (&bsi))\n \t    if (gimple_has_side_effects (gsi_stmt (bsi)))\n \t       return false;\n-\t  bound += double_int_one;\n-\t  if (bound.is_zero ()\n-\t      || !double_int_fits_to_tree_p (nit_type, bound))\n+\t  bound += 1;\n+\t  if (bound == 0\n+\t      || !wi::fits_to_tree_p (bound, nit_type))\n \t    return false;\n \t}\n       cmp = GT_EXPR;\n     }\n \n   e = fold_binary (cmp, boolean_type_node,\n-\t\t   niter, double_int_to_tree (nit_type, bound));\n+\t\t   niter, wide_int_to_tree (nit_type, bound));\n   return e && integer_nonzerop (e);\n }\n \n@@ -3760,7 +3748,7 @@ scev_probably_wraps_p (tree base, tree step,\n   tree unsigned_type, valid_niter;\n   tree type = TREE_TYPE (step);\n   tree e;\n-  double_int niter;\n+  widest_int niter;\n   struct nb_iter_bound *bound;\n \n   /* FIXME: We really need something like\n@@ -3826,10 +3814,10 @@ scev_probably_wraps_p (tree base, tree step,\n   estimate_numbers_of_iterations_loop (loop);\n \n   if (max_loop_iterations (loop, &niter)\n-      && double_int_fits_to_tree_p (TREE_TYPE (valid_niter), niter)\n+      && wi::fits_to_tree_p (niter, TREE_TYPE (valid_niter))\n       && (e = fold_binary (GT_EXPR, boolean_type_node, valid_niter,\n-\t\t\t   double_int_to_tree (TREE_TYPE (valid_niter),\n-\t\t\t\t\t       niter))) != NULL\n+\t\t\t   wide_int_to_tree (TREE_TYPE (valid_niter),\n+\t\t\t\t\t     niter))) != NULL\n       && integer_nonzerop (e))\n     {\n       fold_undefer_and_ignore_overflow_warnings ();"}, {"sha": "a143040723aeef9f718fa93a7aa587d32bfc1c10", "filename": "gcc/tree-ssa-loop-niter.h", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-niter.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop-niter.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-niter.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -29,14 +29,14 @@ extern tree find_loop_niter (struct loop *, edge *);\n extern bool finite_loop_p (struct loop *);\n extern tree loop_niter_by_eval (struct loop *, edge);\n extern tree find_loop_niter_by_eval (struct loop *, edge *);\n-extern bool estimated_loop_iterations (struct loop *, double_int *);\n+extern bool estimated_loop_iterations (struct loop *, widest_int *);\n extern HOST_WIDE_INT estimated_loop_iterations_int (struct loop *);\n-extern bool max_loop_iterations (struct loop *, double_int *);\n+extern bool max_loop_iterations (struct loop *, widest_int *);\n extern HOST_WIDE_INT max_loop_iterations_int (struct loop *);\n extern HOST_WIDE_INT max_stmt_executions_int (struct loop *);\n extern HOST_WIDE_INT estimated_stmt_executions_int (struct loop *);\n-extern bool max_stmt_executions (struct loop *, double_int *);\n-extern bool estimated_stmt_executions (struct loop *, double_int *);\n+extern bool max_stmt_executions (struct loop *, widest_int *);\n+extern bool estimated_stmt_executions (struct loop *, widest_int *);\n extern void estimate_numbers_of_iterations (void);\n extern bool stmt_dominates_stmt_p (gimple, gimple);\n extern bool nowrap_type_p (tree);"}, {"sha": "95857f1e621e3c0c5b619210c477a12e28797b0b", "filename": "gcc/tree-ssa-loop.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-loop.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -20,6 +20,8 @@ along with GCC; see the file COPYING3.  If not see\n #ifndef GCC_TREE_SSA_LOOP_H\n #define GCC_TREE_SSA_LOOP_H\n \n+#include \"wide-int.h\"\n+\n /* Affine iv.  */\n \n struct affine_iv\n@@ -49,7 +51,7 @@ struct tree_niter_desc\n \t\t\t   a loop (provided that assumptions == true and\n \t\t\t   may_be_zero == false), more precisely the number\n \t\t\t   of executions of the latch of the loop.  */\n-  double_int max;\t/* The upper bound on the number of iterations of\n+  widest_int max;\t/* The upper bound on the number of iterations of\n \t\t\t   the loop.  */\n \n   /* The simplified shape of the exit condition.  The loop exits if"}, {"sha": "336626d0886a2f883804f42322896c31177c62bb", "filename": "gcc/tree-ssa-math-opts.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-math-opts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-math-opts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-math-opts.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1148,7 +1148,7 @@ gimple_expand_builtin_pow (gimple_stmt_iterator *gsi, location_t loc,\n      multiplication sequence when profitable.  */\n   c = TREE_REAL_CST (arg1);\n   n = real_to_integer (&c);\n-  real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);\n+  real_from_integer (&cint, VOIDmode, n, SIGNED);\n   c_is_int = real_identical (&c, &cint);\n \n   if (c_is_int\n@@ -1194,7 +1194,7 @@ gimple_expand_builtin_pow (gimple_stmt_iterator *gsi, location_t loc,\n   /* Optimize pow(x,0.75) = sqrt(x) * sqrt(sqrt(x)) unless we are\n      optimizing for space.  Don't do this optimization if we don't have\n      a hardware sqrt insn.  */\n-  real_from_integer (&dconst3_4, VOIDmode, 3, 0, 0);\n+  real_from_integer (&dconst3_4, VOIDmode, 3, SIGNED);\n   SET_REAL_EXP (&dconst3_4, REAL_EXP (&dconst3_4) - 2);\n \n   if (flag_unsafe_math_optimizations\n@@ -1258,7 +1258,7 @@ gimple_expand_builtin_pow (gimple_stmt_iterator *gsi, location_t loc,\n      Do not calculate the powi factor when n/2 = 0.  */\n   real_arithmetic (&c2, MULT_EXPR, &c, &dconst2);\n   n = real_to_integer (&c2);\n-  real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);\n+  real_from_integer (&cint, VOIDmode, n, SIGNED);\n   c2_is_int = real_identical (&c2, &cint);\n \n   if (flag_unsafe_math_optimizations\n@@ -1306,11 +1306,11 @@ gimple_expand_builtin_pow (gimple_stmt_iterator *gsi, location_t loc,\n      different from pow(x, 1./3.) due to rounding and behavior with\n      negative x, we need to constrain this transformation to unsafe\n      math and positive x or finite math.  */\n-  real_from_integer (&dconst3, VOIDmode, 3, 0, 0);\n+  real_from_integer (&dconst3, VOIDmode, 3, SIGNED);\n   real_arithmetic (&c2, MULT_EXPR, &c, &dconst3);\n   real_round (&c2, mode, &c2);\n   n = real_to_integer (&c2);\n-  real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);\n+  real_from_integer (&cint, VOIDmode, n, SIGNED);\n   real_arithmetic (&c2, RDIV_EXPR, &cint, &dconst3);\n   real_convert (&c2, mode, &c2);\n "}, {"sha": "28a6ea76e85679a797b4062ba2478db707b7be20", "filename": "gcc/tree-ssa-phiopt.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-phiopt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-phiopt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-phiopt.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -559,7 +559,7 @@ jump_function_from_stmt (tree *arg, gimple stmt)\n \t\t\t\t\t\t&offset);\n       if (tem\n \t  && TREE_CODE (tem) == MEM_REF\n-\t  && (mem_ref_offset (tem) + double_int::from_shwi (offset)).is_zero ())\n+\t  && (mem_ref_offset (tem) + offset) == 0)\n \t{\n \t  *arg = TREE_OPERAND (tem, 0);\n \t  return true;"}, {"sha": "95e3af98238ac3b3ac660ff2938198d37b49d04e", "filename": "gcc/tree-ssa-pre.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-pre.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-pre.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-pre.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1599,11 +1599,11 @@ phi_translate_1 (pre_expr expr, bitmap_set_t set1, bitmap_set_t set2,\n \t\t&& TREE_CODE (op[1]) == INTEGER_CST\n \t\t&& TREE_CODE (op[2]) == INTEGER_CST)\n \t      {\n-\t\tdouble_int off = tree_to_double_int (op[0]);\n-\t\toff += -tree_to_double_int (op[1]);\n-\t\toff *= tree_to_double_int (op[2]);\n-\t\tif (off.fits_shwi ())\n-\t\t  newop.off = off.low;\n+\t\toffset_int off = ((wi::to_offset (op[0])\n+\t\t\t\t   - wi::to_offset (op[1]))\n+\t\t\t\t  * wi::to_offset (op[2]));\n+\t\tif (wi::fits_shwi_p (off))\n+\t\t  newop.off = off.to_shwi ();\n \t      }\n \t    newoperands[j] = newop;\n \t    /* If it transforms from an SSA_NAME to an address, fold with"}, {"sha": "357ac08381cccaa6c4d09c25c4d687b75b9b7e64", "filename": "gcc/tree-ssa-reassoc.c", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-reassoc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-reassoc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-reassoc.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1111,7 +1111,7 @@ decrement_power (gimple stmt)\n       arg1 = gimple_call_arg (stmt, 1);\n       c = TREE_REAL_CST (arg1);\n       power = real_to_integer (&c) - 1;\n-      real_from_integer (&cint, VOIDmode, power, 0, 0);\n+      real_from_integer (&cint, VOIDmode, power, SIGNED);\n       gimple_call_set_arg (stmt, 1, build_real (TREE_TYPE (arg1), cint));\n       return power;\n \n@@ -3704,8 +3704,7 @@ acceptable_pow_call (gimple stmt, tree *base, HOST_WIDE_INT *exponent)\n \treturn false;\n \n       *exponent = real_to_integer (&c);\n-      real_from_integer (&cint, VOIDmode, *exponent,\n-\t\t\t *exponent < 0 ? -1 : 0, 0);\n+      real_from_integer (&cint, VOIDmode, *exponent, SIGNED);\n       if (!real_identical (&c, &cint))\n \treturn false;\n "}, {"sha": "585fd85049c78fa7817a05533226e53e7c984a4b", "filename": "gcc/tree-ssa-sccvn.c", "status": "modified", "additions": 25, "deletions": 28, "changes": 53, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-sccvn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-sccvn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sccvn.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -814,21 +814,20 @@ copy_reference_ops_from_ref (tree ref, vec<vn_reference_op_s> *result)\n \t\ttree bit_offset = DECL_FIELD_BIT_OFFSET (TREE_OPERAND (ref, 1));\n \t\tif (TREE_INT_CST_LOW (bit_offset) % BITS_PER_UNIT == 0)\n \t\t  {\n-\t\t    double_int off\n-\t\t      = tree_to_double_int (this_offset)\n-\t\t\t+ tree_to_double_int (bit_offset)\n-\t\t\t.rshift (BITS_PER_UNIT == 8\n-\t\t\t\t   ? 3 : exact_log2 (BITS_PER_UNIT));\n-\t\t    if (off.fits_shwi ()\n+\t\t    offset_int off\n+\t\t      = (wi::to_offset (this_offset)\n+\t\t\t + wi::lrshift (wi::to_offset (bit_offset),\n+\t\t\t\t\tLOG2_BITS_PER_UNIT));\n+\t\t    if (wi::fits_shwi_p (off)\n \t\t\t/* Probibit value-numbering zero offset components\n \t\t\t   of addresses the same before the pass folding\n \t\t\t   __builtin_object_size had a chance to run\n \t\t\t   (checking cfun->after_inlining does the\n \t\t\t   trick here).  */\n \t\t\t&& (TREE_CODE (orig) != ADDR_EXPR\n-\t\t\t    || !off.is_zero ()\n+\t\t\t    || off != 0\n \t\t\t    || cfun->after_inlining))\n-\t\t      temp.off = off.low;\n+\t\t      temp.off = off.to_shwi ();\n \t\t  }\n \t      }\n \t  }\n@@ -844,11 +843,11 @@ copy_reference_ops_from_ref (tree ref, vec<vn_reference_op_s> *result)\n \t      && TREE_CODE (temp.op1) == INTEGER_CST\n \t      && TREE_CODE (temp.op2) == INTEGER_CST)\n \t    {\n-\t      double_int off = tree_to_double_int (temp.op0);\n-\t      off += -tree_to_double_int (temp.op1);\n-\t      off *= tree_to_double_int (temp.op2);\n-\t      if (off.fits_shwi ())\n-\t\ttemp.off = off.low;\n+\t      offset_int off = ((wi::to_offset (temp.op0)\n+\t\t\t\t - wi::to_offset (temp.op1))\n+\t\t\t\t* wi::to_offset (temp.op2));\n+\t      if (wi::fits_shwi_p (off))\n+\t\ttemp.off = off.to_shwi();\n \t    }\n \t  break;\n \tcase VAR_DECL:\n@@ -1168,10 +1167,9 @@ vn_reference_fold_indirect (vec<vn_reference_op_s> *ops,\n   gcc_checking_assert (addr_base && TREE_CODE (addr_base) != MEM_REF);\n   if (addr_base != TREE_OPERAND (op->op0, 0))\n     {\n-      double_int off = tree_to_double_int (mem_op->op0);\n-      off = off.sext (TYPE_PRECISION (TREE_TYPE (mem_op->op0)));\n-      off += double_int::from_shwi (addr_offset);\n-      mem_op->op0 = double_int_to_tree (TREE_TYPE (mem_op->op0), off);\n+      offset_int off = offset_int::from (mem_op->op0, SIGNED);\n+      off += addr_offset;\n+      mem_op->op0 = wide_int_to_tree (TREE_TYPE (mem_op->op0), off);\n       op->op0 = build_fold_addr_expr (addr_base);\n       if (tree_fits_shwi_p (mem_op->op0))\n \tmem_op->off = tree_to_shwi (mem_op->op0);\n@@ -1191,7 +1189,7 @@ vn_reference_maybe_forwprop_address (vec<vn_reference_op_s> *ops,\n   vn_reference_op_t mem_op = &(*ops)[i - 1];\n   gimple def_stmt;\n   enum tree_code code;\n-  double_int off;\n+  offset_int off;\n \n   def_stmt = SSA_NAME_DEF_STMT (op->op0);\n   if (!is_gimple_assign (def_stmt))\n@@ -1202,8 +1200,7 @@ vn_reference_maybe_forwprop_address (vec<vn_reference_op_s> *ops,\n       && code != POINTER_PLUS_EXPR)\n     return;\n \n-  off = tree_to_double_int (mem_op->op0);\n-  off = off.sext (TYPE_PRECISION (TREE_TYPE (mem_op->op0)));\n+  off = offset_int::from (mem_op->op0, SIGNED);\n \n   /* The only thing we have to do is from &OBJ.foo.bar add the offset\n      from .foo.bar to the preceding MEM_REF offset and replace the\n@@ -1220,7 +1217,7 @@ vn_reference_maybe_forwprop_address (vec<vn_reference_op_s> *ops,\n \t  || TREE_CODE (addr_base) != MEM_REF)\n \treturn;\n \n-      off += double_int::from_shwi (addr_offset);\n+      off += addr_offset;\n       off += mem_ref_offset (addr_base);\n       op->op0 = TREE_OPERAND (addr_base, 0);\n     }\n@@ -1233,11 +1230,11 @@ vn_reference_maybe_forwprop_address (vec<vn_reference_op_s> *ops,\n \t  || TREE_CODE (ptroff) != INTEGER_CST)\n \treturn;\n \n-      off += tree_to_double_int (ptroff);\n+      off += wi::to_offset (ptroff);\n       op->op0 = ptr;\n     }\n \n-  mem_op->op0 = double_int_to_tree (TREE_TYPE (mem_op->op0), off);\n+  mem_op->op0 = wide_int_to_tree (TREE_TYPE (mem_op->op0), off);\n   if (tree_fits_shwi_p (mem_op->op0))\n     mem_op->off = tree_to_shwi (mem_op->op0);\n   else\n@@ -1391,11 +1388,11 @@ valueize_refs_1 (vec<vn_reference_op_s> orig, bool *valueized_anything)\n \t       && TREE_CODE (vro->op1) == INTEGER_CST\n \t       && TREE_CODE (vro->op2) == INTEGER_CST)\n \t{\n-\t  double_int off = tree_to_double_int (vro->op0);\n-\t  off += -tree_to_double_int (vro->op1);\n-\t  off *= tree_to_double_int (vro->op2);\n-\t  if (off.fits_shwi ())\n-\t    vro->off = off.low;\n+\t  offset_int off = ((wi::to_offset (vro->op0)\n+\t\t\t     - wi::to_offset (vro->op1))\n+\t\t\t    * wi::to_offset (vro->op2));\n+\t  if (wi::fits_shwi_p (off))\n+\t    vro->off = off.to_shwi ();\n \t}\n     }\n "}, {"sha": "5d3a323e54a64d1e48ee6f3b88a085aa4747cd1b", "filename": "gcc/tree-ssa-structalias.c", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-structalias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-structalias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-structalias.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -3065,14 +3065,13 @@ get_constraint_for_ptr_offset (tree ptr, tree offset,\n   else\n     {\n       /* Sign-extend the offset.  */\n-      double_int soffset = tree_to_double_int (offset)\n-\t\t\t   .sext (TYPE_PRECISION (TREE_TYPE (offset)));\n-      if (!soffset.fits_shwi ())\n+      offset_int soffset = offset_int::from (offset, SIGNED);\n+      if (!wi::fits_shwi_p (soffset))\n \trhsoffset = UNKNOWN_OFFSET;\n       else\n \t{\n \t  /* Make sure the bit-offset also fits.  */\n-\t  HOST_WIDE_INT rhsunitoffset = soffset.low;\n+\t  HOST_WIDE_INT rhsunitoffset = soffset.to_shwi ();\n \t  rhsoffset = rhsunitoffset * BITS_PER_UNIT;\n \t  if (rhsunitoffset != rhsoffset / BITS_PER_UNIT)\n \t    rhsoffset = UNKNOWN_OFFSET;"}, {"sha": "96e9e609f83ee1a87b8abdc7a48f70c6763c7c14", "filename": "gcc/tree-ssa-uninit.c", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-uninit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa-uninit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-uninit.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -854,25 +854,24 @@ is_value_included_in (tree val, tree boundary, enum tree_code cmpc)\n       if (cmpc == EQ_EXPR)\n         result = tree_int_cst_equal (val, boundary);\n       else if (cmpc == LT_EXPR)\n-        result = INT_CST_LT_UNSIGNED (val, boundary);\n+        result = tree_int_cst_lt (val, boundary);\n       else\n         {\n           gcc_assert (cmpc == LE_EXPR);\n-          result = (tree_int_cst_equal (val, boundary)\n-                    || INT_CST_LT_UNSIGNED (val, boundary));\n+          result = tree_int_cst_le (val, boundary);\n         }\n     }\n   else\n     {\n       if (cmpc == EQ_EXPR)\n         result = tree_int_cst_equal (val, boundary);\n       else if (cmpc == LT_EXPR)\n-        result = INT_CST_LT (val, boundary);\n+        result = tree_int_cst_lt (val, boundary);\n       else\n         {\n           gcc_assert (cmpc == LE_EXPR);\n           result = (tree_int_cst_equal (val, boundary)\n-                    || INT_CST_LT (val, boundary));\n+                    || tree_int_cst_lt (val, boundary));\n         }\n     }\n "}, {"sha": "856325e0de43ee0ff8edca15929e007dee696ef3", "filename": "gcc/tree-ssa.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1340,9 +1340,9 @@ non_rewritable_mem_ref_base (tree ref)\n \t   || TREE_CODE (TREE_TYPE (decl)) == COMPLEX_TYPE)\n \t  && useless_type_conversion_p (TREE_TYPE (base),\n \t\t\t\t\tTREE_TYPE (TREE_TYPE (decl)))\n-\t  && mem_ref_offset (base).fits_uhwi ()\n-\t  && tree_to_double_int (TYPE_SIZE_UNIT (TREE_TYPE (decl)))\n-\t     .ugt (mem_ref_offset (base))\n+\t  && wi::fits_uhwi_p (mem_ref_offset (base))\n+\t  && wi::gtu_p (wi::to_offset (TYPE_SIZE_UNIT (TREE_TYPE (decl))),\n+\t\t\tmem_ref_offset (base))\n \t  && multiple_of_p (sizetype, TREE_OPERAND (base, 1),\n \t\t\t    TYPE_SIZE_UNIT (TREE_TYPE (base))))\n \treturn NULL_TREE;"}, {"sha": "fa7eaf3b47690accece834cae126d0c35cf67138", "filename": "gcc/tree-ssanames.c", "status": "modified", "additions": 35, "deletions": 42, "changes": 77, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssanames.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssanames.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssanames.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -186,45 +186,40 @@ make_ssa_name_fn (struct function *fn, tree var, gimple stmt)\n /* Store range information RANGE_TYPE, MIN, and MAX to tree ssa_name NAME.  */\n \n void\n-set_range_info (tree name, enum value_range_type range_type, double_int min,\n-\t\tdouble_int max)\n+set_range_info (tree name, enum value_range_type range_type,\n+\t\tconst wide_int_ref &min, const wide_int_ref &max)\n {\n   gcc_assert (!POINTER_TYPE_P (TREE_TYPE (name)));\n   gcc_assert (range_type == VR_RANGE || range_type == VR_ANTI_RANGE);\n   range_info_def *ri = SSA_NAME_RANGE_INFO (name);\n+  unsigned int precision = TYPE_PRECISION (TREE_TYPE (name));\n \n   /* Allocate if not available.  */\n   if (ri == NULL)\n     {\n-      ri = ggc_alloc_cleared_range_info_def ();\n+      size_t size = (sizeof (range_info_def)\n+\t\t     + trailing_wide_ints <3>::extra_size (precision));\n+      ri = ggc_alloc_range_info_def (size);\n+      ri->ints.set_precision (precision);\n       SSA_NAME_RANGE_INFO (name) = ri;\n-      ri->nonzero_bits = double_int::mask (TYPE_PRECISION (TREE_TYPE (name)));\n+      ri->set_nonzero_bits (wi::shwi (-1, precision));\n     }\n \n   /* Record the range type.  */\n   if (SSA_NAME_RANGE_TYPE (name) != range_type)\n     SSA_NAME_ANTI_RANGE_P (name) = (range_type == VR_ANTI_RANGE);\n \n   /* Set the values.  */\n-  ri->min = min;\n-  ri->max = max;\n+  ri->set_min (min);\n+  ri->set_max (max);\n \n   /* If it is a range, try to improve nonzero_bits from the min/max.  */\n   if (range_type == VR_RANGE)\n     {\n-      int prec = TYPE_PRECISION (TREE_TYPE (name));\n-      double_int xorv;\n-\n-      min = min.zext (prec);\n-      max = max.zext (prec);\n-      xorv = min ^ max;\n-      if (xorv.high)\n-\txorv = double_int::mask (2 * HOST_BITS_PER_WIDE_INT\n-\t\t\t\t - clz_hwi (xorv.high));\n-      else if (xorv.low)\n-\txorv = double_int::mask (HOST_BITS_PER_WIDE_INT\n-\t\t\t\t - clz_hwi (xorv.low));\n-      ri->nonzero_bits = ri->nonzero_bits & (min | xorv);\n+      wide_int xorv = ri->get_min () ^ ri->get_max ();\n+      if (xorv != 0)\n+\txorv = wi::mask (precision - wi::clz (xorv), false, precision);\n+      ri->set_nonzero_bits (ri->get_nonzero_bits () & (ri->get_min () | xorv));\n     }\n }\n \n@@ -234,7 +229,7 @@ set_range_info (tree name, enum value_range_type range_type, double_int min,\n    is used to determine if MIN and MAX are valid values.  */\n \n enum value_range_type\n-get_range_info (const_tree name, double_int *min, double_int *max)\n+get_range_info (const_tree name, wide_int *min, wide_int *max)\n {\n   gcc_assert (!POINTER_TYPE_P (TREE_TYPE (name)));\n   gcc_assert (min && max);\n@@ -246,50 +241,45 @@ get_range_info (const_tree name, double_int *min, double_int *max)\n \t      > 2 * HOST_BITS_PER_WIDE_INT))\n     return VR_VARYING;\n \n-  *min = ri->min;\n-  *max = ri->max;\n+  *min = ri->get_min ();\n+  *max = ri->get_max ();\n   return SSA_NAME_RANGE_TYPE (name);\n }\n \n /* Change non-zero bits bitmask of NAME.  */\n \n void\n-set_nonzero_bits (tree name, double_int mask)\n+set_nonzero_bits (tree name, const wide_int_ref &mask)\n {\n   gcc_assert (!POINTER_TYPE_P (TREE_TYPE (name)));\n   if (SSA_NAME_RANGE_INFO (name) == NULL)\n     set_range_info (name, VR_RANGE,\n-\t\t    tree_to_double_int (TYPE_MIN_VALUE (TREE_TYPE (name))),\n-\t\t    tree_to_double_int (TYPE_MAX_VALUE (TREE_TYPE (name))));\n+\t\t    TYPE_MIN_VALUE (TREE_TYPE (name)),\n+\t\t    TYPE_MAX_VALUE (TREE_TYPE (name)));\n   range_info_def *ri = SSA_NAME_RANGE_INFO (name);\n-  ri->nonzero_bits\n-    = mask & double_int::mask (TYPE_PRECISION (TREE_TYPE (name)));\n+  ri->set_nonzero_bits (mask);\n }\n \n-/* Return a double_int with potentially non-zero bits in SSA_NAME\n-   NAME, or double_int_minus_one if unknown.  */\n+/* Return a widest_int with potentially non-zero bits in SSA_NAME\n+   NAME, or -1 if unknown.  */\n \n-double_int\n+wide_int\n get_nonzero_bits (const_tree name)\n {\n+  unsigned int precision = TYPE_PRECISION (TREE_TYPE (name));\n   if (POINTER_TYPE_P (TREE_TYPE (name)))\n     {\n       struct ptr_info_def *pi = SSA_NAME_PTR_INFO (name);\n       if (pi && pi->align)\n-\t{\n-\t  double_int al = double_int::from_uhwi (pi->align - 1);\n-\t  return ((double_int::mask (TYPE_PRECISION (TREE_TYPE (name))) & ~al)\n-\t\t  | double_int::from_uhwi (pi->misalign));\n-\t}\n-      return double_int_minus_one;\n+\treturn wi::shwi (-(int) pi->align | pi->misalign, precision);\n+      return wi::shwi (-1, precision);\n     }\n \n   range_info_def *ri = SSA_NAME_RANGE_INFO (name);\n-  if (!ri || (GET_MODE_PRECISION (TYPE_MODE (TREE_TYPE (name)))\n-\t      > 2 * HOST_BITS_PER_WIDE_INT))\n-    return double_int_minus_one;\n+  if (!ri)\n+    return wi::shwi (-1, precision);\n \n-  return ri->nonzero_bits;\n+  return ri->get_nonzero_bits ();\n }\n \n /* We no longer need the SSA_NAME expression VAR, release it so that\n@@ -502,8 +492,11 @@ duplicate_ssa_name_range_info (tree name, enum value_range_type range_type,\n   if (!range_info)\n     return;\n \n-  new_range_info = ggc_alloc_range_info_def ();\n-  *new_range_info = *range_info;\n+  unsigned int precision = TYPE_PRECISION (TREE_TYPE (name));\n+  size_t size = (sizeof (range_info_def)\n+\t\t + trailing_wide_ints <3>::extra_size (precision));\n+  new_range_info = ggc_alloc_range_info_def (size);\n+  memcpy (new_range_info, range_info, size);\n \n   gcc_assert (range_type == VR_RANGE || range_type == VR_ANTI_RANGE);\n   SSA_NAME_ANTI_RANGE_P (name) = (range_type == VR_ANTI_RANGE);"}, {"sha": "4fc9f69e1af612657242b360bc2db8658e416345", "filename": "gcc/tree-ssanames.h", "status": "modified", "additions": 12, "deletions": 13, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssanames.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-ssanames.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssanames.h?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -47,13 +47,12 @@ struct GTY(()) ptr_info_def\n \n /* Value range information for SSA_NAMEs representing non-pointer variables.  */\n \n-struct GTY (()) range_info_def {\n-  /* Minimum for value range.  */\n-  double_int min;\n-  /* Maximum for value range.  */\n-  double_int max;\n-  /* Non-zero bits - bits not set are guaranteed to be always zero.  */\n-  double_int nonzero_bits;\n+struct GTY ((variable_size)) range_info_def {\n+  /* Minimum, maximum and nonzero bits.  */\n+  TRAILING_WIDE_INT_ACCESSOR (min, ints, 0)\n+  TRAILING_WIDE_INT_ACCESSOR (max, ints, 1)\n+  TRAILING_WIDE_INT_ACCESSOR (nonzero_bits, ints, 2)\n+  trailing_wide_ints <3> ints;\n };\n \n \n@@ -70,13 +69,13 @@ struct GTY (()) range_info_def {\n enum value_range_type { VR_UNDEFINED, VR_RANGE, VR_ANTI_RANGE, VR_VARYING };\n \n /* Sets the value range to SSA.  */\n-extern void set_range_info (tree, enum value_range_type, double_int,\n-\t\t\t    double_int);\n+extern void set_range_info (tree, enum value_range_type, const wide_int_ref &,\n+\t\t\t    const wide_int_ref &);\n /* Gets the value range from SSA.  */\n-extern enum value_range_type get_range_info (const_tree, double_int *,\n-\t\t\t\t\t     double_int *);\n-extern void set_nonzero_bits (tree, double_int);\n-extern double_int get_nonzero_bits (const_tree);\n+extern enum value_range_type get_range_info (const_tree, wide_int *,\n+\t\t\t\t\t     wide_int *);\n+extern void set_nonzero_bits (tree, const wide_int_ref &);\n+extern wide_int get_nonzero_bits (const_tree);\n extern void init_ssanames (struct function *, int);\n extern void fini_ssanames (void);\n extern void ssanames_print_statistics (void);"}, {"sha": "fc5ecfc9855d64486e91ded5f32d82a27008f0d9", "filename": "gcc/tree-streamer-in.c", "status": "modified", "additions": 9, "deletions": 2, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-streamer-in.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-streamer-in.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-streamer-in.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -152,8 +152,9 @@ unpack_ts_base_value_fields (struct bitpack_d *bp, tree expr)\n static void\n unpack_ts_int_cst_value_fields (struct bitpack_d *bp, tree expr)\n {\n-  TREE_INT_CST_LOW (expr) = bp_unpack_var_len_unsigned (bp);\n-  TREE_INT_CST_HIGH (expr) = bp_unpack_var_len_int (bp);\n+  int i;\n+  for (i = 0; i < TREE_INT_CST_EXT_NUNITS (expr); i++)\n+    TREE_INT_CST_ELT (expr, i) = bp_unpack_var_len_int (bp);\n }\n \n \n@@ -603,6 +604,12 @@ streamer_alloc_tree (struct lto_input_block *ib, struct data_in *data_in,\n       unsigned HOST_WIDE_INT len = streamer_read_uhwi (ib);\n       result = make_tree_binfo (len);\n     }\n+  else if (CODE_CONTAINS_STRUCT (code, TS_INT_CST))\n+    {\n+      unsigned HOST_WIDE_INT len = streamer_read_uhwi (ib);\n+      unsigned HOST_WIDE_INT ext_len = streamer_read_uhwi (ib);\n+      result = make_int_cst (len, ext_len);\n+    }\n   else if (code == CALL_EXPR)\n     {\n       unsigned HOST_WIDE_INT nargs = streamer_read_uhwi (ib);"}, {"sha": "5858047b4b50a10af5a7a54bacb2b3e1503c380d", "filename": "gcc/tree-streamer-out.c", "status": "modified", "additions": 20, "deletions": 4, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-streamer-out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-streamer-out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-streamer-out.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -127,8 +127,11 @@ pack_ts_base_value_fields (struct bitpack_d *bp, tree expr)\n static void\n pack_ts_int_cst_value_fields (struct bitpack_d *bp, tree expr)\n {\n-  bp_pack_var_len_unsigned (bp, TREE_INT_CST_LOW (expr));\n-  bp_pack_var_len_int (bp, TREE_INT_CST_HIGH (expr));\n+  int i;\n+  /* Note that the number of elements has already been written out in\n+     streamer_write_tree_header.  */\n+  for (i = 0; i < TREE_INT_CST_EXT_NUNITS (expr); i++)\n+    bp_pack_var_len_int (bp, TREE_INT_CST_ELT (expr, i));\n }\n \n \n@@ -1008,6 +1011,12 @@ streamer_write_tree_header (struct output_block *ob, tree expr)\n     streamer_write_uhwi (ob, call_expr_nargs (expr));\n   else if (TREE_CODE (expr) == OMP_CLAUSE)\n     streamer_write_uhwi (ob, OMP_CLAUSE_CODE (expr));\n+  else if (CODE_CONTAINS_STRUCT (code, TS_INT_CST))\n+    {\n+      gcc_checking_assert (TREE_INT_CST_NUNITS (expr));\n+      streamer_write_uhwi (ob, TREE_INT_CST_NUNITS (expr));\n+      streamer_write_uhwi (ob, TREE_INT_CST_EXT_NUNITS (expr));\n+    }\n }\n \n \n@@ -1017,9 +1026,16 @@ streamer_write_tree_header (struct output_block *ob, tree expr)\n void\n streamer_write_integer_cst (struct output_block *ob, tree cst, bool ref_p)\n {\n+  int i;\n+  int len = TREE_INT_CST_NUNITS (cst);\n   gcc_assert (!TREE_OVERFLOW (cst));\n   streamer_write_record_start (ob, LTO_integer_cst);\n   stream_write_tree (ob, TREE_TYPE (cst), ref_p);\n-  streamer_write_uhwi (ob, TREE_INT_CST_LOW (cst));\n-  streamer_write_hwi (ob, TREE_INT_CST_HIGH (cst));\n+  /* We're effectively streaming a non-sign-extended wide_int here,\n+     so there's no need to stream TREE_INT_CST_EXT_NUNITS or any\n+     array members beyond LEN.  We'll recreate the tree from the\n+     wide_int and the type.  */\n+  streamer_write_uhwi (ob, len);\n+  for (i = 0; i < len; i++)\n+    streamer_write_hwi (ob, TREE_INT_CST_ELT (cst, i));\n }"}, {"sha": "3651120d0e19a3ee53b2946e8cc9a65e2bcbc5c4", "filename": "gcc/tree-switch-conversion.c", "status": "modified", "additions": 16, "deletions": 8, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-switch-conversion.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-switch-conversion.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-switch-conversion.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -446,7 +446,13 @@ emit_case_bit_tests (gimple swtch, tree index_expr,\n         if (const & csui) goto target  */\n   for (k = 0; k < count; k++)\n     {\n-      tmp = build_int_cst_wide (word_type_node, test[k].lo, test[k].hi);\n+      HOST_WIDE_INT a[2];\n+\n+      a[0] = test[k].lo;\n+      a[1] = test[k].hi;\n+      tmp = wide_int_to_tree (word_type_node,\n+\t\t\t      wide_int::from_array (a, 2,\n+\t\t\t\t\t\t    TYPE_PRECISION (word_type_node)));\n       tmp = fold_build2 (BIT_AND_EXPR, word_type_node, csui, tmp);\n       tmp = force_gimple_operand_gsi (&gsi, tmp,\n \t\t\t\t      /*simple=*/true, NULL_TREE,\n@@ -886,7 +892,8 @@ build_constructors (gimple swtch, struct switch_conv_info *info)\n \t      info->constructors[k]->quick_push (elt);\n \t    }\n \n-\t  pos = int_const_binop (PLUS_EXPR, pos, integer_one_node);\n+\t  pos = int_const_binop (PLUS_EXPR, pos,\n+\t\t\t\t build_int_cst (TREE_TYPE (pos), 1));\n \t}\n       gcc_assert (tree_int_cst_equal (pos, CASE_LOW (cs)));\n \n@@ -911,7 +918,8 @@ build_constructors (gimple swtch, struct switch_conv_info *info)\n \t      elt.value = unshare_expr_without_location (val);\n \t      info->constructors[j]->quick_push (elt);\n \n-\t      pos = int_const_binop (PLUS_EXPR, pos, integer_one_node);\n+\t      pos = int_const_binop (PLUS_EXPR, pos,\n+\t\t\t\t     build_int_cst (TREE_TYPE (pos), 1));\n \t    } while (!tree_int_cst_lt (high, pos)\n \t\t     && tree_int_cst_lt (low, pos));\n \t  j++;\n@@ -966,26 +974,26 @@ array_value_type (gimple swtch, tree type, int num,\n \n   FOR_EACH_VEC_SAFE_ELT (info->constructors[num], i, elt)\n     {\n-      double_int cst;\n+      wide_int cst;\n \n       if (TREE_CODE (elt->value) != INTEGER_CST)\n \treturn type;\n \n-      cst = TREE_INT_CST (elt->value);\n+      cst = elt->value;\n       while (1)\n \t{\n \t  unsigned int prec = GET_MODE_BITSIZE (mode);\n \t  if (prec > HOST_BITS_PER_WIDE_INT)\n \t    return type;\n \n-\t  if (sign >= 0 && cst == cst.zext (prec))\n+\t  if (sign >= 0 && cst == wi::zext (cst, prec))\n \t    {\n-\t      if (sign == 0 && cst == cst.sext (prec))\n+\t      if (sign == 0 && cst == wi::sext (cst, prec))\n \t\tbreak;\n \t      sign = 1;\n \t      break;\n \t    }\n-\t  if (sign <= 0 && cst == cst.sext (prec))\n+\t  if (sign <= 0 && cst == wi::sext (cst, prec))\n \t    {\n \t      sign = -1;\n \t      break;"}, {"sha": "d48e3cdcfca918e599ff444cefba0148a582c764", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 7, "deletions": 9, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2898,15 +2898,13 @@ vect_prune_runtime_alias_test_list (loop_vec_info loop_vinfo)\n \n \t     */\n \n-\t  HOST_WIDE_INT\n-\t  min_seg_len_b = (TREE_CODE (dr_b1->seg_len) == INTEGER_CST) ?\n-\t\t\t     TREE_INT_CST_LOW (dr_b1->seg_len) :\n-\t\t\t     vect_factor;\n+\t  HOST_WIDE_INT  min_seg_len_b = (tree_fits_shwi_p (dr_b1->seg_len)\n+\t\t\t\t\t  ? tree_to_shwi (dr_b1->seg_len)\n+\t\t\t\t\t  : vect_factor);\n \n \t  if (diff <= min_seg_len_b\n-\t      || (TREE_CODE (dr_a1->seg_len) == INTEGER_CST\n-\t\t  && diff - (HOST_WIDE_INT) TREE_INT_CST_LOW (dr_a1->seg_len) <\n-\t\t     min_seg_len_b))\n+\t      || (tree_fits_shwi_p (dr_a1->seg_len)\n+\t\t  && diff - tree_to_shwi (dr_a1->seg_len) < min_seg_len_b))\n \t    {\n \t      if (dump_enabled_p ())\n \t\t{\n@@ -2999,8 +2997,8 @@ vect_check_gather (gimple stmt, loop_vec_info loop_vinfo, tree *basep,\n \t{\n \t  if (off == NULL_TREE)\n \t    {\n-\t      double_int moff = mem_ref_offset (base);\n-\t      off = double_int_to_tree (sizetype, moff);\n+\t      offset_int moff = mem_ref_offset (base);\n+\t      off = wide_int_to_tree (sizetype, moff);\n \t    }\n \t  else\n \t    off = size_binop (PLUS_EXPR, off,"}, {"sha": "43a695d65f2c12b40340097542cf03fe05cc4705", "filename": "gcc/tree-vect-generic.c", "status": "modified", "additions": 20, "deletions": 22, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-generic.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-generic.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-generic.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -57,11 +57,13 @@ static tree\n build_replicated_const (tree type, tree inner_type, HOST_WIDE_INT value)\n {\n   int width = tree_to_uhwi (TYPE_SIZE (inner_type));\n-  int n = HOST_BITS_PER_WIDE_INT / width;\n-  unsigned HOST_WIDE_INT low, high, mask;\n-  tree ret;\n+  int n = (TYPE_PRECISION (type) + HOST_BITS_PER_WIDE_INT - 1) \n+    / HOST_BITS_PER_WIDE_INT;\n+  unsigned HOST_WIDE_INT low, mask;\n+  HOST_WIDE_INT a[WIDE_INT_MAX_ELTS];\n+  int i;\n \n-  gcc_assert (n);\n+  gcc_assert (n && n <= WIDE_INT_MAX_ELTS);\n \n   if (width == HOST_BITS_PER_WIDE_INT)\n     low = value;\n@@ -71,17 +73,12 @@ build_replicated_const (tree type, tree inner_type, HOST_WIDE_INT value)\n       low = (unsigned HOST_WIDE_INT) ~0 / mask * (value & mask);\n     }\n \n-  if (TYPE_PRECISION (type) < HOST_BITS_PER_WIDE_INT)\n-    low &= ((HOST_WIDE_INT)1 << TYPE_PRECISION (type)) - 1, high = 0;\n-  else if (TYPE_PRECISION (type) == HOST_BITS_PER_WIDE_INT)\n-    high = 0;\n-  else if (TYPE_PRECISION (type) == HOST_BITS_PER_DOUBLE_INT)\n-    high = low;\n-  else\n-    gcc_unreachable ();\n+  for (i = 0; i < n; i++)\n+    a[i] = low;\n \n-  ret = build_int_cst_wide (type, low, high);\n-  return ret;\n+  gcc_assert (TYPE_PRECISION (type) <= MAX_BITSIZE_MODE_ANY_INT);\n+  return wide_int_to_tree\n+    (type, wide_int::from_array (a, n, TYPE_PRECISION (type)));\n }\n \n static GTY(()) tree vector_inner_type;\n@@ -415,7 +412,8 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n   unsigned HOST_WIDE_INT *mulc = XALLOCAVEC (unsigned HOST_WIDE_INT, nunits);\n   int prec = TYPE_PRECISION (TREE_TYPE (type));\n   int dummy_int;\n-  unsigned int i, unsignedp = TYPE_UNSIGNED (TREE_TYPE (type));\n+  unsigned int i;\n+  signop sign_p = TYPE_SIGN (TREE_TYPE (type));\n   unsigned HOST_WIDE_INT mask = GET_MODE_MASK (TYPE_MODE (TREE_TYPE (type)));\n   tree *vec;\n   tree cur_op, mulcst, tem;\n@@ -457,7 +455,7 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n \t}\n       if (mode == -2)\n \tcontinue;\n-      if (unsignedp)\n+      if (sign_p == UNSIGNED)\n \t{\n \t  unsigned HOST_WIDE_INT mh;\n \t  unsigned HOST_WIDE_INT d = TREE_INT_CST_LOW (cst) & mask;\n@@ -586,7 +584,7 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n   if (use_pow2)\n     {\n       tree addend = NULL_TREE;\n-      if (!unsignedp)\n+      if (sign_p == SIGNED)\n \t{\n \t  tree uns_type;\n \n@@ -638,7 +636,7 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n \t}\n       if (code == TRUNC_DIV_EXPR)\n \t{\n-\t  if (unsignedp)\n+\t  if (sign_p == UNSIGNED)\n \t    {\n \t      /* q = op0 >> shift;  */\n \t      cur_op = add_rshift (gsi, type, op0, shifts);\n@@ -672,7 +670,7 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n \t  if (op != unknown_optab\n \t      && optab_handler (op, TYPE_MODE (type)) != CODE_FOR_nothing)\n \t    {\n-\t      if (unsignedp)\n+\t      if (sign_p == UNSIGNED)\n \t\t/* r = op0 & mask;  */\n \t\treturn gimplify_build2 (gsi, BIT_AND_EXPR, type, op0, mask);\n \t      else if (addend != NULL_TREE)\n@@ -713,7 +711,7 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n   switch (mode)\n     {\n     case 0:\n-      gcc_assert (unsignedp);\n+      gcc_assert (sign_p == UNSIGNED);\n       /* t1 = oprnd0 >> pre_shift;\n \t t2 = t1 h* ml;\n \t q = t2 >> post_shift;  */\n@@ -722,7 +720,7 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n \treturn NULL_TREE;\n       break;\n     case 1:\n-      gcc_assert (unsignedp);\n+      gcc_assert (sign_p == UNSIGNED);\n       for (i = 0; i < nunits; i++)\n \t{\n \t  shift_temps[i] = 1;\n@@ -733,7 +731,7 @@ expand_vector_divmod (gimple_stmt_iterator *gsi, tree type, tree op0,\n     case 3:\n     case 4:\n     case 5:\n-      gcc_assert (!unsignedp);\n+      gcc_assert (sign_p == SIGNED);\n       for (i = 0; i < nunits; i++)\n \tshift_temps[i] = prec - 1;\n       break;"}, {"sha": "7b79ab1b9d04adeafc4c7f9f8bb6458b631fb14d", "filename": "gcc/tree-vect-loop-manip.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-loop-manip.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-loop-manip.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop-manip.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -1791,7 +1791,7 @@ vect_do_peeling_for_loop_bound (loop_vec_info loop_vinfo,\n \t      : LOOP_VINFO_VECT_FACTOR (loop_vinfo)) - 2;\n   if (check_profitability)\n     max_iter = MAX (max_iter, (int) th - 1);\n-  record_niter_bound (new_loop, double_int::from_shwi (max_iter), false, true);\n+  record_niter_bound (new_loop, max_iter, false, true);\n   dump_printf (MSG_NOTE,\n                \"Setting upper bound of nb iterations for epilogue \"\n                \"loop to %d\\n\", max_iter);\n@@ -2028,7 +2028,7 @@ vect_do_peeling_for_alignment (loop_vec_info loop_vinfo, tree ni_name,\n   max_iter = LOOP_VINFO_VECT_FACTOR (loop_vinfo) - 2;\n   if (check_profitability)\n     max_iter = MAX (max_iter, (int) th - 1);\n-  record_niter_bound (new_loop, double_int::from_shwi (max_iter), false, true);\n+  record_niter_bound (new_loop, max_iter, false, true);\n   dump_printf (MSG_NOTE,\n                \"Setting upper bound of nb iterations for prologue \"\n                \"loop to %d\\n\", max_iter);"}, {"sha": "1f6ac1a348bf1118111bc514c68c1ecafdc8e0b3", "filename": "gcc/tree-vect-loop.c", "status": "modified", "additions": 6, "deletions": 8, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-loop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-loop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -6114,19 +6114,17 @@ vect_transform_loop (loop_vec_info loop_vinfo)\n   scale_loop_profile (loop, GCOV_COMPUTE_SCALE (1, vectorization_factor),\n \t\t      expected_iterations / vectorization_factor);\n   loop->nb_iterations_upper_bound\n-    = loop->nb_iterations_upper_bound.udiv (double_int::from_uhwi (vectorization_factor),\n-\t\t\t\t\t    FLOOR_DIV_EXPR);\n+    = wi::udiv_floor (loop->nb_iterations_upper_bound, vectorization_factor);\n   if (LOOP_VINFO_PEELING_FOR_GAPS (loop_vinfo)\n-      && loop->nb_iterations_upper_bound != double_int_zero)\n-    loop->nb_iterations_upper_bound = loop->nb_iterations_upper_bound - double_int_one;\n+      && loop->nb_iterations_upper_bound != 0)\n+    loop->nb_iterations_upper_bound = loop->nb_iterations_upper_bound - 1;\n   if (loop->any_estimate)\n     {\n       loop->nb_iterations_estimate\n-        = loop->nb_iterations_estimate.udiv (double_int::from_uhwi (vectorization_factor),\n-\t\t\t\t\t     FLOOR_DIV_EXPR);\n+        = wi::udiv_floor (loop->nb_iterations_estimate, vectorization_factor);\n        if (LOOP_VINFO_PEELING_FOR_GAPS (loop_vinfo)\n-\t   && loop->nb_iterations_estimate != double_int_zero)\n-\t loop->nb_iterations_estimate = loop->nb_iterations_estimate - double_int_one;\n+\t   && loop->nb_iterations_estimate != 0)\n+\t loop->nb_iterations_estimate = loop->nb_iterations_estimate - 1;\n     }\n \n   if (dump_enabled_p ())"}, {"sha": "094cf047e056eea4c3457ff0de94f962c3b69c4c", "filename": "gcc/tree-vect-patterns.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-patterns.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-patterns.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-patterns.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2340,13 +2340,13 @@ vect_recog_divmod_pattern (vec<gimple> *stmts,\n       else\n \tt3 = t2;\n \n-      double_int oprnd0_min, oprnd0_max;\n+      wide_int oprnd0_min, oprnd0_max;\n       int msb = 1;\n       if (get_range_info (oprnd0, &oprnd0_min, &oprnd0_max) == VR_RANGE)\n \t{\n-\t  if (!oprnd0_min.is_negative ())\n+\t  if (!wi::neg_p (oprnd0_min, TYPE_SIGN (itype)))\n \t    msb = 0;\n-\t  else if (oprnd0_max.is_negative ())\n+\t  else if (wi::neg_p (oprnd0_max, TYPE_SIGN (itype)))\n \t    msb = -1;\n \t}\n "}, {"sha": "b8547cba962db95eba1279de13d1e92b4730684f", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -2992,11 +2992,10 @@ vectorizable_simd_clone_call (gimple stmt, gimple_stmt_iterator *gsi,\n \t\t      ? POINTER_PLUS_EXPR : PLUS_EXPR;\n \t\t  tree type = POINTER_TYPE_P (TREE_TYPE (op))\n \t\t\t      ? sizetype : TREE_TYPE (op);\n-\t\t  double_int cst\n-\t\t    = double_int::from_shwi\n-\t\t\t(bestn->simdclone->args[i].linear_step);\n-\t\t  cst *= double_int::from_uhwi (ncopies * nunits);\n-\t\t  tree tcst = double_int_to_tree (type, cst);\n+\t\t  widest_int cst\n+\t\t    = wi::mul (bestn->simdclone->args[i].linear_step,\n+\t\t\t       ncopies * nunits);\n+\t\t  tree tcst = wide_int_to_tree (type, cst);\n \t\t  tree phi_arg = copy_ssa_name (op, NULL);\n \t\t  new_stmt = gimple_build_assign_with_ops (code, phi_arg,\n \t\t\t\t\t\t\t   phi_res, tcst);\n@@ -3017,11 +3016,10 @@ vectorizable_simd_clone_call (gimple stmt, gimple_stmt_iterator *gsi,\n \t\t      ? POINTER_PLUS_EXPR : PLUS_EXPR;\n \t\t  tree type = POINTER_TYPE_P (TREE_TYPE (op))\n \t\t\t      ? sizetype : TREE_TYPE (op);\n-\t\t  double_int cst\n-\t\t    = double_int::from_shwi\n-\t\t\t(bestn->simdclone->args[i].linear_step);\n-\t\t  cst *= double_int::from_uhwi (j * nunits);\n-\t\t  tree tcst = double_int_to_tree (type, cst);\n+\t\t  widest_int cst\n+\t\t    = wi::mul (bestn->simdclone->args[i].linear_step,\n+\t\t\t       j * nunits);\n+\t\t  tree tcst = wide_int_to_tree (type, cst);\n \t\t  new_temp = make_ssa_name (TREE_TYPE (op), NULL);\n \t\t  new_stmt\n \t\t    = gimple_build_assign_with_ops (code, new_temp,"}, {"sha": "633c329030f604c102fc5b5bb5908dce2d6b6bed", "filename": "gcc/tree-vrp.c", "status": "modified", "additions": 344, "deletions": 410, "changes": 754, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vrp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree-vrp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vrp.c?ref=807e902eea17f3132488c256c963823976b2348c", "patch": "@@ -60,6 +60,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"expr.h\"\n #include \"optabs.h\"\n #include \"tree-ssa-threadedge.h\"\n+#include \"wide-int.h\"\n \n \n \n@@ -1150,15 +1151,7 @@ operand_less_p (tree val, tree val2)\n {\n   /* LT is folded faster than GE and others.  Inline the common case.  */\n   if (TREE_CODE (val) == INTEGER_CST && TREE_CODE (val2) == INTEGER_CST)\n-    {\n-      if (TYPE_UNSIGNED (TREE_TYPE (val)))\n-\treturn INT_CST_LT_UNSIGNED (val, val2);\n-      else\n-\t{\n-\t  if (INT_CST_LT (val, val2))\n-\t    return 1;\n-\t}\n-    }\n+    return tree_int_cst_lt (val, val2);\n   else\n     {\n       tree tcmp;\n@@ -1630,10 +1623,8 @@ extract_range_from_assert (value_range_t *vr_p, tree expr)\n       /* Make sure to not set TREE_OVERFLOW on the final type\n \t conversion.  We are willingly interpreting large positive\n \t unsigned values as negative singed values here.  */\n-      min = force_fit_type_double (TREE_TYPE (var), tree_to_double_int (min),\n-\t\t\t\t   0, false);\n-      max = force_fit_type_double (TREE_TYPE (var), tree_to_double_int (max),\n-\t\t\t\t   0, false);\n+      min = force_fit_type (TREE_TYPE (var), wi::to_widest (min), 0, false);\n+      max = force_fit_type (TREE_TYPE (var), wi::to_widest (max), 0, false);\n \n       /* We can transform a max, min range to an anti-range or\n          vice-versa.  Use set_and_canonicalize_value_range which does\n@@ -1889,6 +1880,10 @@ vrp_int_const_binop (enum tree_code code, tree val1, tree val2)\n     /* If the singed operation wraps then int_const_binop has done\n        everything we want.  */\n     ;\n+  /* Signed division of -1/0 overflows and by the time it gets here\n+     returns NULL_TREE.  */\n+  else if (!res)\n+    return NULL_TREE;\n   else if ((TREE_OVERFLOW (res)\n \t    && !TREE_OVERFLOW (val1)\n \t    && !TREE_OVERFLOW (val2))\n@@ -1980,54 +1975,42 @@ vrp_int_const_binop (enum tree_code code, tree val1, tree val2)\n }\n \n \n-/* For range VR compute two double_int bitmasks.  In *MAY_BE_NONZERO\n+/* For range VR compute two wide_int bitmasks.  In *MAY_BE_NONZERO\n    bitmask if some bit is unset, it means for all numbers in the range\n    the bit is 0, otherwise it might be 0 or 1.  In *MUST_BE_NONZERO\n    bitmask if some bit is set, it means for all numbers in the range\n    the bit is 1, otherwise it might be 0 or 1.  */\n \n static bool\n-zero_nonzero_bits_from_vr (value_range_t *vr,\n-\t\t\t   double_int *may_be_nonzero,\n-\t\t\t   double_int *must_be_nonzero)\n+zero_nonzero_bits_from_vr (const tree expr_type,\n+\t\t\t   value_range_t *vr,\n+\t\t\t   wide_int *may_be_nonzero,\n+\t\t\t   wide_int *must_be_nonzero)\n {\n-  *may_be_nonzero = double_int_minus_one;\n-  *must_be_nonzero = double_int_zero;\n+  *may_be_nonzero = wi::minus_one (TYPE_PRECISION (expr_type));\n+  *must_be_nonzero = wi::zero (TYPE_PRECISION (expr_type));\n   if (!range_int_cst_p (vr)\n       || is_overflow_infinity (vr->min)\n       || is_overflow_infinity (vr->max))\n     return false;\n \n   if (range_int_cst_singleton_p (vr))\n     {\n-      *may_be_nonzero = tree_to_double_int (vr->min);\n+      *may_be_nonzero = vr->min;\n       *must_be_nonzero = *may_be_nonzero;\n     }\n   else if (tree_int_cst_sgn (vr->min) >= 0\n \t   || tree_int_cst_sgn (vr->max) < 0)\n     {\n-      double_int dmin = tree_to_double_int (vr->min);\n-      double_int dmax = tree_to_double_int (vr->max);\n-      double_int xor_mask = dmin ^ dmax;\n-      *may_be_nonzero = dmin | dmax;\n-      *must_be_nonzero = dmin & dmax;\n-      if (xor_mask.high != 0)\n+      wide_int xor_mask = wi::bit_xor (vr->min, vr->max);\n+      *may_be_nonzero = wi::bit_or (vr->min, vr->max);\n+      *must_be_nonzero = wi::bit_and (vr->min, vr->max);\n+      if (xor_mask != 0)\n \t{\n-\t  unsigned HOST_WIDE_INT mask\n-\t      = ((unsigned HOST_WIDE_INT) 1\n-\t\t << floor_log2 (xor_mask.high)) - 1;\n-\t  may_be_nonzero->low = ALL_ONES;\n-\t  may_be_nonzero->high |= mask;\n-\t  must_be_nonzero->low = 0;\n-\t  must_be_nonzero->high &= ~mask;\n-\t}\n-      else if (xor_mask.low != 0)\n-\t{\n-\t  unsigned HOST_WIDE_INT mask\n-\t      = ((unsigned HOST_WIDE_INT) 1\n-\t\t << floor_log2 (xor_mask.low)) - 1;\n-\t  may_be_nonzero->low |= mask;\n-\t  must_be_nonzero->low &= ~mask;\n+\t  wide_int mask = wi::mask (wi::floor_log2 (xor_mask), false,\n+\t\t\t\t    may_be_nonzero->get_precision ());\n+\t  *may_be_nonzero = *may_be_nonzero | mask;\n+\t  *must_be_nonzero = must_be_nonzero->and_not (mask);\n \t}\n     }\n \n@@ -2059,16 +2042,12 @@ ranges_from_anti_range (value_range_t *ar,\n     {\n       vr0->type = VR_RANGE;\n       vr0->min = vrp_val_min (type);\n-      vr0->max\n-\t= double_int_to_tree (type,\n-\t\t\t      tree_to_double_int (ar->min) - double_int_one);\n+      vr0->max = wide_int_to_tree (type, wi::sub (ar->min, 1));\n     }\n   if (!vrp_val_is_max (ar->max))\n     {\n       vr1->type = VR_RANGE;\n-      vr1->min\n-\t= double_int_to_tree (type,\n-\t\t\t      tree_to_double_int (ar->max) + double_int_one);\n+      vr1->min = wide_int_to_tree (type, wi::add (ar->max, 1));\n       vr1->max = vrp_val_max (type);\n     }\n   if (vr0->type == VR_UNDEFINED)\n@@ -2234,28 +2213,6 @@ extract_range_from_multiplicative_op_1 (value_range_t *vr,\n     set_value_range (vr, type, min, max, NULL);\n }\n \n-/* Some quadruple precision helpers.  */\n-static int\n-quad_int_cmp (double_int l0, double_int h0,\n-\t      double_int l1, double_int h1, bool uns)\n-{\n-  int c = h0.cmp (h1, uns);\n-  if (c != 0) return c;\n-  return l0.ucmp (l1);\n-}\n-\n-static void\n-quad_int_pair_sort (double_int *l0, double_int *h0,\n-\t\t    double_int *l1, double_int *h1, bool uns)\n-{\n-  if (quad_int_cmp (*l0, *h0, *l1, *h1, uns) > 0)\n-    {\n-      double_int tmp;\n-      tmp = *l0; *l0 = *l1; *l1 = tmp;\n-      tmp = *h0; *h0 = *h1; *h1 = tmp;\n-    }\n-}\n-\n /* Extract range information from a binary operation CODE based on\n    the ranges of each of its operands, *VR0 and *VR1 with resulting\n    type EXPR_TYPE.  The resulting range is stored in *VR.  */\n@@ -2427,85 +2384,76 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n       /* If we have a PLUS_EXPR with two VR_RANGE integer constant\n          ranges compute the precise range for such case if possible.  */\n       if (range_int_cst_p (&vr0)\n-\t  && range_int_cst_p (&vr1)\n-\t  /* We need as many bits as the possibly unsigned inputs.  */\n-\t  && TYPE_PRECISION (expr_type) <= HOST_BITS_PER_DOUBLE_INT)\n-\t{\n-\t  double_int min0 = tree_to_double_int (vr0.min);\n-\t  double_int max0 = tree_to_double_int (vr0.max);\n-\t  double_int min1 = tree_to_double_int (vr1.min);\n-\t  double_int max1 = tree_to_double_int (vr1.max);\n-\t  bool uns = TYPE_UNSIGNED (expr_type);\n-\t  double_int type_min\n-\t    = double_int::min_value (TYPE_PRECISION (expr_type), uns);\n-\t  double_int type_max\n-\t    = double_int::max_value (TYPE_PRECISION (expr_type), uns);\n-\t  double_int dmin, dmax;\n+\t  && range_int_cst_p (&vr1))\n+\t{\n+\t  signop sgn = TYPE_SIGN (expr_type);\n+\t  unsigned int prec = TYPE_PRECISION (expr_type);\n+\t  wide_int type_min = wi::min_value (TYPE_PRECISION (expr_type), sgn);\n+\t  wide_int type_max = wi::max_value (TYPE_PRECISION (expr_type), sgn);\n+\t  wide_int wmin, wmax;\n \t  int min_ovf = 0;\n \t  int max_ovf = 0;\n \n \t  if (code == PLUS_EXPR)\n \t    {\n-\t      dmin = min0 + min1;\n-\t      dmax = max0 + max1;\n-\n-\t      /* Check for overflow in double_int.  */\n-\t      if (min1.cmp (double_int_zero, uns) != dmin.cmp (min0, uns))\n-\t\tmin_ovf = min0.cmp (dmin, uns);\n-\t      if (max1.cmp (double_int_zero, uns) != dmax.cmp (max0, uns))\n-\t\tmax_ovf = max0.cmp (dmax, uns);\n+\t      wmin = wi::add (vr0.min, vr1.min);\n+\t      wmax = wi::add (vr0.max, vr1.max);\n+\n+\t      /* Check for overflow.  */\n+\t      if (wi::cmp (vr1.min, 0, sgn) != wi::cmp (wmin, vr0.min, sgn))\n+\t\tmin_ovf = wi::cmp (vr0.min, wmin, sgn);\n+\t      if (wi::cmp (vr1.max, 0, sgn) != wi::cmp (wmax, vr0.max, sgn))\n+\t\tmax_ovf = wi::cmp (vr0.max, wmax, sgn);\n \t    }\n \t  else /* if (code == MINUS_EXPR) */\n \t    {\n-\t      dmin = min0 - max1;\n-\t      dmax = max0 - min1;\n+\t      wmin = wi::sub (vr0.min, vr1.max);\n+\t      wmax = wi::sub (vr0.max, vr1.min);\n \n-\t      if (double_int_zero.cmp (max1, uns) != dmin.cmp (min0, uns))\n-\t\tmin_ovf = min0.cmp (max1, uns);\n-\t      if (double_int_zero.cmp (min1, uns) != dmax.cmp (max0, uns))\n-\t\tmax_ovf = max0.cmp (min1, uns);\n+\t      if (wi::cmp (0, vr1.max, sgn) != wi::cmp (wmin, vr0.min, sgn))\n+\t\tmin_ovf = wi::cmp (vr0.min, vr1.max, sgn);\n+\t      if (wi::cmp (0, vr1.min, sgn) != wi::cmp (wmax, vr0.max, sgn))\n+\t\tmax_ovf = wi::cmp (vr0.max, vr1.min, sgn);\n \t    }\n \n \t  /* For non-wrapping arithmetic look at possibly smaller\n \t     value-ranges of the type.  */\n \t  if (!TYPE_OVERFLOW_WRAPS (expr_type))\n \t    {\n \t      if (vrp_val_min (expr_type))\n-\t\ttype_min = tree_to_double_int (vrp_val_min (expr_type));\n+\t\ttype_min = vrp_val_min (expr_type);\n \t      if (vrp_val_max (expr_type))\n-\t\ttype_max = tree_to_double_int (vrp_val_max (expr_type));\n+\t\ttype_max = vrp_val_max (expr_type);\n \t    }\n \n \t  /* Check for type overflow.  */\n \t  if (min_ovf == 0)\n \t    {\n-\t      if (dmin.cmp (type_min, uns) == -1)\n+\t      if (wi::cmp (wmin, type_min, sgn) == -1)\n \t\tmin_ovf = -1;\n-\t      else if (dmin.cmp (type_max, uns) == 1)\n+\t      else if (wi::cmp (wmin, type_max, sgn) == 1)\n \t\tmin_ovf = 1;\n \t    }\n \t  if (max_ovf == 0)\n \t    {\n-\t      if (dmax.cmp (type_min, uns) == -1)\n+\t      if (wi::cmp (wmax, type_min, sgn) == -1)\n \t\tmax_ovf = -1;\n-\t      else if (dmax.cmp (type_max, uns) == 1)\n+\t      else if (wi::cmp (wmax, type_max, sgn) == 1)\n \t\tmax_ovf = 1;\n \t    }\n \n \t  if (TYPE_OVERFLOW_WRAPS (expr_type))\n \t    {\n \t      /* If overflow wraps, truncate the values and adjust the\n \t\t range kind and bounds appropriately.  */\n-\t      double_int tmin\n-\t\t= dmin.ext (TYPE_PRECISION (expr_type), uns);\n-\t      double_int tmax\n-\t\t= dmax.ext (TYPE_PRECISION (expr_type), uns);\n+\t      wide_int tmin = wide_int::from (wmin, prec, sgn);\n+\t      wide_int tmax = wide_int::from (wmax, prec, sgn);\n \t      if (min_ovf == max_ovf)\n \t\t{\n \t\t  /* No overflow or both overflow or underflow.  The\n \t\t     range kind stays VR_RANGE.  */\n-\t\t  min = double_int_to_tree (expr_type, tmin);\n-\t\t  max = double_int_to_tree (expr_type, tmax);\n+\t\t  min = wide_int_to_tree (expr_type, tmin);\n+\t\t  max = wide_int_to_tree (expr_type, tmax);\n \t\t}\n \t      else if (min_ovf == -1\n \t\t       && max_ovf == 1)\n@@ -2519,26 +2467,26 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n \t\t  /* Min underflow or max overflow.  The range kind\n \t\t     changes to VR_ANTI_RANGE.  */\n \t\t  bool covers = false;\n-\t\t  double_int tem = tmin;\n+\t\t  wide_int tem = tmin;\n \t\t  gcc_assert ((min_ovf == -1 && max_ovf == 0)\n \t\t\t      || (max_ovf == 1 && min_ovf == 0));\n \t\t  type = VR_ANTI_RANGE;\n-\t\t  tmin = tmax + double_int_one;\n-\t\t  if (tmin.cmp (tmax, uns) < 0)\n+\t\t  tmin = tmax + 1;\n+\t\t  if (wi::cmp (tmin, tmax, sgn) < 0)\n \t\t    covers = true;\n-\t\t  tmax = tem + double_int_minus_one;\n-\t\t  if (tmax.cmp (tem, uns) > 0)\n+\t\t  tmax = tem - 1;\n+\t\t  if (wi::cmp (tmax, tem, sgn) > 0)\n \t\t    covers = true;\n \t\t  /* If the anti-range would cover nothing, drop to varying.\n \t\t     Likewise if the anti-range bounds are outside of the\n \t\t     types values.  */\n-\t\t  if (covers || tmin.cmp (tmax, uns) > 0)\n+\t\t  if (covers || wi::cmp (tmin, tmax, sgn) > 0)\n \t\t    {\n \t\t      set_value_range_to_varying (vr);\n \t\t      return;\n \t\t    }\n-\t\t  min = double_int_to_tree (expr_type, tmin);\n-\t\t  max = double_int_to_tree (expr_type, tmax);\n+\t\t  min = wide_int_to_tree (expr_type, tmin);\n+\t\t  max = wide_int_to_tree (expr_type, tmax);\n \t\t}\n \t    }\n \t  else\n@@ -2551,37 +2499,37 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n \t\t      && supports_overflow_infinity (expr_type))\n \t\t    min = negative_overflow_infinity (expr_type);\n \t\t  else\n-\t\t    min = double_int_to_tree (expr_type, type_min);\n+\t\t    min = wide_int_to_tree (expr_type, type_min);\n \t\t}\n \t      else if (min_ovf == 1)\n \t\t{\n \t\t  if (needs_overflow_infinity (expr_type)\n \t\t      && supports_overflow_infinity (expr_type))\n \t\t    min = positive_overflow_infinity (expr_type);\n \t\t  else\n-\t\t    min = double_int_to_tree (expr_type, type_max);\n+\t\t    min = wide_int_to_tree (expr_type, type_max);\n \t\t}\n \t      else\n-\t\tmin = double_int_to_tree (expr_type, dmin);\n+\t\tmin = wide_int_to_tree (expr_type, wmin);\n \n \t      if (max_ovf == -1)\n \t\t{\n \t\t  if (needs_overflow_infinity (expr_type)\n \t\t      && supports_overflow_infinity (expr_type))\n \t\t    max = negative_overflow_infinity (expr_type);\n \t\t  else\n-\t\t    max = double_int_to_tree (expr_type, type_min);\n+\t\t    max = wide_int_to_tree (expr_type, type_min);\n \t\t}\n \t      else if (max_ovf == 1)\n \t\t{\n \t\t  if (needs_overflow_infinity (expr_type)\n \t\t      && supports_overflow_infinity (expr_type))\n \t\t    max = positive_overflow_infinity (expr_type);\n \t\t  else\n-\t\t    max = double_int_to_tree (expr_type, type_max);\n+\t\t    max = wide_int_to_tree (expr_type, type_max);\n \t\t}\n \t      else\n-\t\tmax = double_int_to_tree (expr_type, dmax);\n+\t\tmax = wide_int_to_tree (expr_type, wmax);\n \t    }\n \t  if (needs_overflow_infinity (expr_type)\n \t      && supports_overflow_infinity (expr_type))\n@@ -2667,97 +2615,85 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n   else if (code == MULT_EXPR)\n     {\n       /* Fancy code so that with unsigned, [-3,-1]*[-3,-1] does not\n-\t drop to varying.  */\n+\t drop to varying.  This test requires 2*prec bits if both\n+\t operands are signed and 2*prec + 2 bits if either is not.  */\n+\n+      signop sign = TYPE_SIGN (expr_type);\n+      unsigned int prec = TYPE_PRECISION (expr_type);\n+\n       if (range_int_cst_p (&vr0)\n \t  && range_int_cst_p (&vr1)\n \t  && TYPE_OVERFLOW_WRAPS (expr_type))\n \t{\n-\t  double_int min0, max0, min1, max1, sizem1, size;\n-\t  double_int prod0l, prod0h, prod1l, prod1h,\n-\t\t     prod2l, prod2h, prod3l, prod3h;\n-\t  bool uns0, uns1, uns;\n-\n-\t  sizem1 = double_int::max_value (TYPE_PRECISION (expr_type), true);\n-\t  size = sizem1 + double_int_one;\n-\n-\t  min0 = tree_to_double_int (vr0.min);\n-\t  max0 = tree_to_double_int (vr0.max);\n-\t  min1 = tree_to_double_int (vr1.min);\n-\t  max1 = tree_to_double_int (vr1.max);\n-\n-\t  uns0 = TYPE_UNSIGNED (expr_type);\n-\t  uns1 = uns0;\n-\n+\t  typedef FIXED_WIDE_INT (WIDE_INT_MAX_PRECISION * 2) vrp_int;\n+\t  typedef generic_wide_int\n+             <wi::extended_tree <WIDE_INT_MAX_PRECISION * 2> > vrp_int_cst;\n+\t  vrp_int sizem1 = wi::mask <vrp_int> (prec, false);\n+\t  vrp_int size = sizem1 + 1;\n+\n+\t  /* Extend the values using the sign of the result to PREC2.\n+\t     From here on out, everthing is just signed math no matter\n+\t     what the input types were.  */\n+          vrp_int min0 = vrp_int_cst (vr0.min);\n+          vrp_int max0 = vrp_int_cst (vr0.max);\n+          vrp_int min1 = vrp_int_cst (vr1.min);\n+          vrp_int max1 = vrp_int_cst (vr1.max);\n \t  /* Canonicalize the intervals.  */\n-\t  if (TYPE_UNSIGNED (expr_type))\n+\t  if (sign == UNSIGNED)\n \t    {\n-\t      double_int min2 = size - min0;\n-\t      if (!min2.is_zero () && min2.cmp (max0, true) < 0)\n+\t      if (wi::ltu_p (size, min0 + max0))\n \t\t{\n-\t\t  min0 = -min2;\n+\t\t  min0 -= size;\n \t\t  max0 -= size;\n-\t\t  uns0 = false;\n \t\t}\n \n-\t      min2 = size - min1;\n-\t      if (!min2.is_zero () && min2.cmp (max1, true) < 0)\n+\t      if (wi::ltu_p (size, min1 + max1))\n \t\t{\n-\t\t  min1 = -min2;\n+\t\t  min1 -= size;\n \t\t  max1 -= size;\n-\t\t  uns1 = false;\n \t\t}\n \t    }\n-\t  uns = uns0 & uns1;\n \n-\t  bool overflow;\n-\t  prod0l = min0.wide_mul_with_sign (min1, true, &prod0h, &overflow);\n-\t  if (!uns0 && min0.is_negative ())\n-\t    prod0h -= min1;\n-\t  if (!uns1 && min1.is_negative ())\n-\t    prod0h -= min0;\n-\n-\t  prod1l = min0.wide_mul_with_sign (max1, true, &prod1h, &overflow);\n-\t  if (!uns0 && min0.is_negative ())\n-\t    prod1h -= max1;\n-\t  if (!uns1 && max1.is_negative ())\n-\t    prod1h -= min0;\n-\n-\t  prod2l = max0.wide_mul_with_sign (min1, true, &prod2h, &overflow);\n-\t  if (!uns0 && max0.is_negative ())\n-\t    prod2h -= min1;\n-\t  if (!uns1 && min1.is_negative ())\n-\t    prod2h -= max0;\n-\n-\t  prod3l = max0.wide_mul_with_sign (max1, true, &prod3h, &overflow);\n-\t  if (!uns0 && max0.is_negative ())\n-\t    prod3h -= max1;\n-\t  if (!uns1 && max1.is_negative ())\n-\t    prod3h -= max0;\n-\n-\t  /* Sort the 4 products.  */\n-\t  quad_int_pair_sort (&prod0l, &prod0h, &prod3l, &prod3h, uns);\n-\t  quad_int_pair_sort (&prod1l, &prod1h, &prod2l, &prod2h, uns);\n-\t  quad_int_pair_sort (&prod0l, &prod0h, &prod1l, &prod1h, uns);\n-\t  quad_int_pair_sort (&prod2l, &prod2h, &prod3l, &prod3h, uns);\n-\n-\t  /* Max - min.  */\n-\t  if (prod0l.is_zero ())\n+\t  vrp_int prod0 = min0 * min1;\n+\t  vrp_int prod1 = min0 * max1;\n+\t  vrp_int prod2 = max0 * min1;\n+\t  vrp_int prod3 = max0 * max1;\n+\n+\t  /* Sort the 4 products so that min is in prod0 and max is in\n+\t     prod3.  */\n+\t  /* min0min1 > max0max1 */\n+\t  if (wi::gts_p (prod0, prod3))\n \t    {\n-\t      prod1l = double_int_zero;\n-\t      prod1h = -prod0h;\n+\t      vrp_int tmp = prod3;\n+\t      prod3 = prod0;\n+\t      prod0 = tmp;\n \t    }\n-\t  else\n+\n+\t  /* min0max1 > max0min1 */\n+\t  if (wi::gts_p (prod1, prod2))\n \t    {\n-\t      prod1l = -prod0l;\n-\t      prod1h = ~prod0h;\n+\t      vrp_int tmp = prod2;\n+\t      prod2 = prod1;\n+\t      prod1 = tmp;\n \t    }\n-\t  prod2l = prod3l + prod1l;\n-\t  prod2h = prod3h + prod1h;\n-\t  if (prod2l.ult (prod3l))\n-\t    prod2h += double_int_one; /* carry */\n \n-\t  if (!prod2h.is_zero ()\n-\t      || prod2l.cmp (sizem1, true) >= 0)\n+\t  if (wi::gts_p (prod0, prod1))\n+\t    {\n+\t      vrp_int tmp = prod1;\n+\t      prod1 = prod0;\n+\t      prod0 = tmp;\n+\t    }\n+\n+\t  if (wi::gts_p (prod2, prod3))\n+\t    {\n+\t      vrp_int tmp = prod3;\n+\t      prod3 = prod2;\n+\t      prod2 = tmp;\n+\t    }\n+\n+\t  /* diff = max - min.  */\n+\t  prod2 = prod3 - prod0;\n+\t  if (wi::geu_p (prod2, sizem1))\n \t    {\n \t      /* the range covers all values.  */\n \t      set_value_range_to_varying (vr);\n@@ -2766,8 +2702,8 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n \n \t  /* The following should handle the wrapping and selecting\n \t     VR_ANTI_RANGE for us.  */\n-\t  min = double_int_to_tree (expr_type, prod0l);\n-\t  max = double_int_to_tree (expr_type, prod3l);\n+\t  min = wide_int_to_tree (expr_type, prod0);\n+\t  max = wide_int_to_tree (expr_type, prod3);\n \t  set_and_canonicalize_value_range (vr, VR_RANGE, min, max, NULL);\n \t  return;\n \t}\n@@ -2814,11 +2750,10 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n \t      bool saved_flag_wrapv;\n \t      value_range_t vr1p = VR_INITIALIZER;\n \t      vr1p.type = VR_RANGE;\n-\t      vr1p.min\n-\t\t= double_int_to_tree (expr_type,\n-\t\t\t\t      double_int_one\n-\t\t\t\t      .llshift (TREE_INT_CST_LOW (vr1.min),\n-\t\t\t\t\t        TYPE_PRECISION (expr_type)));\n+\t      vr1p.min = (wide_int_to_tree\n+\t\t\t  (expr_type,\n+\t\t\t   wi::set_bit_in_zero (tree_to_shwi (vr1.min),\n+\t\t\t\t\t\tTYPE_PRECISION (expr_type))));\n \t      vr1p.max = vr1p.min;\n \t      /* We have to use a wrapping multiply though as signed overflow\n \t\t on lshifts is implementation defined in C89.  */\n@@ -2835,34 +2770,34 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n \t      int prec = TYPE_PRECISION (expr_type);\n \t      int overflow_pos = prec;\n \t      int bound_shift;\n-\t      double_int bound, complement, low_bound, high_bound;\n+\t      wide_int low_bound, high_bound;\n \t      bool uns = TYPE_UNSIGNED (expr_type);\n \t      bool in_bounds = false;\n \n \t      if (!uns)\n \t\toverflow_pos -= 1;\n \n-\t      bound_shift = overflow_pos - TREE_INT_CST_LOW (vr1.max);\n-\t      /* If bound_shift == HOST_BITS_PER_DOUBLE_INT, the llshift can\n+\t      bound_shift = overflow_pos - tree_to_shwi (vr1.max);\n+\t      /* If bound_shift == HOST_BITS_PER_WIDE_INT, the llshift can\n \t\t overflow.  However, for that to happen, vr1.max needs to be\n \t\t zero, which means vr1 is a singleton range of zero, which\n \t\t means it should be handled by the previous LSHIFT_EXPR\n \t\t if-clause.  */\n-\t      bound = double_int_one.llshift (bound_shift, prec);\n-\t      complement = ~(bound - double_int_one);\n+\t      wide_int bound = wi::set_bit_in_zero (bound_shift, prec);\n+\t      wide_int complement = ~(bound - 1);\n \n \t      if (uns)\n \t\t{\n-\t\t  low_bound = bound.zext (prec);\n-\t\t  high_bound = complement.zext (prec);\n-\t\t  if (tree_to_double_int (vr0.max).ult (low_bound))\n+\t\t  low_bound = bound;\n+\t\t  high_bound = complement;\n+\t\t  if (wi::ltu_p (vr0.max, low_bound))\n \t\t    {\n \t\t      /* [5, 6] << [1, 2] == [10, 24].  */\n \t\t      /* We're shifting out only zeroes, the value increases\n \t\t\t monotonically.  */\n \t\t      in_bounds = true;\n \t\t    }\n-\t\t  else if (high_bound.ult (tree_to_double_int (vr0.min)))\n+\t\t  else if (wi::ltu_p (high_bound, vr0.min))\n \t\t    {\n \t\t      /* [0xffffff00, 0xffffffff] << [1, 2]\n \t\t         == [0xfffffc00, 0xfffffffe].  */\n@@ -2874,10 +2809,10 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n \t      else\n \t\t{\n \t\t  /* [-1, 1] << [1, 2] == [-4, 4].  */\n-\t\t  low_bound = complement.sext (prec);\n+\t\t  low_bound = complement;\n \t\t  high_bound = bound;\n-\t\t  if (tree_to_double_int (vr0.max).slt (high_bound)\n-\t\t      && low_bound.slt (tree_to_double_int (vr0.min)))\n+\t\t  if (wi::lts_p (vr0.max, high_bound)\n+\t\t      && wi::lts_p (low_bound, vr0.min))\n \t\t    {\n \t\t      /* For non-negative numbers, we're shifting out only\n \t\t\t zeroes, the value increases monotonically.\n@@ -3001,7 +2936,7 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n       max = fold_unary_to_constant (ABS_EXPR, expr_type, vr1.min);\n       if (tree_int_cst_lt (max, vr1.max))\n \tmax = vr1.max;\n-      max = int_const_binop (MINUS_EXPR, max, integer_one_node);\n+      max = int_const_binop (MINUS_EXPR, max, build_int_cst (TREE_TYPE (max), 1));\n       /* If the dividend is non-negative the modulus will be\n \t non-negative as well.  */\n       if (TYPE_UNSIGNED (expr_type)\n@@ -3013,82 +2948,74 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n   else if (code == BIT_AND_EXPR || code == BIT_IOR_EXPR || code == BIT_XOR_EXPR)\n     {\n       bool int_cst_range0, int_cst_range1;\n-      double_int may_be_nonzero0, may_be_nonzero1;\n-      double_int must_be_nonzero0, must_be_nonzero1;\n+      wide_int may_be_nonzero0, may_be_nonzero1;\n+      wide_int must_be_nonzero0, must_be_nonzero1;\n \n-      int_cst_range0 = zero_nonzero_bits_from_vr (&vr0, &may_be_nonzero0,\n+      int_cst_range0 = zero_nonzero_bits_from_vr (expr_type, &vr0,\n+\t\t\t\t\t\t  &may_be_nonzero0,\n \t\t\t\t\t\t  &must_be_nonzero0);\n-      int_cst_range1 = zero_nonzero_bits_from_vr (&vr1, &may_be_nonzero1,\n+      int_cst_range1 = zero_nonzero_bits_from_vr (expr_type, &vr1,\n+\t\t\t\t\t\t  &may_be_nonzero1,\n \t\t\t\t\t\t  &must_be_nonzero1);\n \n       type = VR_RANGE;\n       if (code == BIT_AND_EXPR)\n \t{\n-\t  double_int dmax;\n-\t  min = double_int_to_tree (expr_type,\n-\t\t\t\t    must_be_nonzero0 & must_be_nonzero1);\n-\t  dmax = may_be_nonzero0 & may_be_nonzero1;\n+\t  min = wide_int_to_tree (expr_type,\n+\t\t\t\t  must_be_nonzero0 & must_be_nonzero1);\n+\t  wide_int wmax = may_be_nonzero0 & may_be_nonzero1;\n \t  /* If both input ranges contain only negative values we can\n \t     truncate the result range maximum to the minimum of the\n \t     input range maxima.  */\n \t  if (int_cst_range0 && int_cst_range1\n \t      && tree_int_cst_sgn (vr0.max) < 0\n \t      && tree_int_cst_sgn (vr1.max) < 0)\n \t    {\n-\t      dmax = dmax.min (tree_to_double_int (vr0.max),\n-\t\t\t\t     TYPE_UNSIGNED (expr_type));\n-\t      dmax = dmax.min (tree_to_double_int (vr1.max),\n-\t\t\t\t     TYPE_UNSIGNED (expr_type));\n+\t      wmax = wi::min (wmax, vr0.max, TYPE_SIGN (expr_type));\n+\t      wmax = wi::min (wmax, vr1.max, TYPE_SIGN (expr_type));\n \t    }\n \t  /* If either input range contains only non-negative values\n \t     we can truncate the result range maximum to the respective\n \t     maximum of the input range.  */\n \t  if (int_cst_range0 && tree_int_cst_sgn (vr0.min) >= 0)\n-\t    dmax = dmax.min (tree_to_double_int (vr0.max),\n-\t\t\t\t   TYPE_UNSIGNED (expr_type));\n+\t    wmax = wi::min (wmax, vr0.max, TYPE_SIGN (expr_type));\n \t  if (int_cst_range1 && tree_int_cst_sgn (vr1.min) >= 0)\n-\t    dmax = dmax.min (tree_to_double_int (vr1.max),\n-\t\t\t\t   TYPE_UNSIGNED (expr_type));\n-\t  max = double_int_to_tree (expr_type, dmax);\n+\t    wmax = wi::min (wmax, vr1.max, TYPE_SIGN (expr_type));\n+\t  max = wide_int_to_tree (expr_type, wmax);\n \t}\n       else if (code == BIT_IOR_EXPR)\n \t{\n-\t  double_int dmin;\n-\t  max = double_int_to_tree (expr_type,\n-\t\t\t\t    may_be_nonzero0 | may_be_nonzero1);\n-\t  dmin = must_be_nonzero0 | must_be_nonzero1;\n+\t  max = wide_int_to_tree (expr_type,\n+\t\t\t\t  may_be_nonzero0 | may_be_nonzero1);\n+\t  wide_int wmin = must_be_nonzero0 | must_be_nonzero1;\n \t  /* If the input ranges contain only positive values we can\n \t     truncate the minimum of the result range to the maximum\n \t     of the input range minima.  */\n \t  if (int_cst_range0 && int_cst_range1\n \t      && tree_int_cst_sgn (vr0.min) >= 0\n \t      && tree_int_cst_sgn (vr1.min) >= 0)\n \t    {\n-\t      dmin = dmin.max (tree_to_double_int (vr0.min),\n-\t\t\t       TYPE_UNSIGNED (expr_type));\n-\t      dmin = dmin.max (tree_to_double_int (vr1.min),\n-\t\t\t       TYPE_UNSIGNED (expr_type));\n+\t      wmin = wi::max (wmin, vr0.min, TYPE_SIGN (expr_type));\n+\t      wmin = wi::max (wmin, vr1.min, TYPE_SIGN (expr_type));\n \t    }\n \t  /* If either input range contains only negative values\n \t     we can truncate the minimum of the result range to the\n \t     respective minimum range.  */\n \t  if (int_cst_range0 && tree_int_cst_sgn (vr0.max) < 0)\n-\t    dmin = dmin.max (tree_to_double_int (vr0.min),\n-\t\t\t     TYPE_UNSIGNED (expr_type));\n+\t    wmin = wi::max (wmin, vr0.min, TYPE_SIGN (expr_type));\n \t  if (int_cst_range1 && tree_int_cst_sgn (vr1.max) < 0)\n-\t    dmin = dmin.max (tree_to_double_int (vr1.min),\n-\t\t\t     TYPE_UNSIGNED (expr_type));\n-\t  min = double_int_to_tree (expr_type, dmin);\n+\t    wmin = wi::max (wmin, vr1.min, TYPE_SIGN (expr_type));\n+\t  min = wide_int_to_tree (expr_type, wmin);\n \t}\n       else if (code == BIT_XOR_EXPR)\n \t{\n-\t  double_int result_zero_bits, result_one_bits;\n-\t  result_zero_bits = (must_be_nonzero0 & must_be_nonzero1)\n-\t\t\t     | ~(may_be_nonzero0 | may_be_nonzero1);\n-\t  result_one_bits = must_be_nonzero0.and_not (may_be_nonzero1)\n-\t\t\t    | must_be_nonzero1.and_not (may_be_nonzero0);\n-\t  max = double_int_to_tree (expr_type, ~result_zero_bits);\n-\t  min = double_int_to_tree (expr_type, result_one_bits);\n+\t  wide_int result_zero_bits = ((must_be_nonzero0 & must_be_nonzero1)\n+\t\t\t\t       | ~(may_be_nonzero0 | may_be_nonzero1));\n+\t  wide_int result_one_bits\n+\t    = (must_be_nonzero0.and_not (may_be_nonzero1)\n+\t       | must_be_nonzero1.and_not (may_be_nonzero0));\n+\t  max = wide_int_to_tree (expr_type, ~result_zero_bits);\n+\t  min = wide_int_to_tree (expr_type, result_one_bits);\n \t  /* If the range has all positive or all negative values the\n \t     result is better than VARYING.  */\n \t  if (tree_int_cst_sgn (min) < 0\n@@ -3303,15 +3230,13 @@ extract_range_from_unary_expr_1 (value_range_t *vr,\n \t  if (is_overflow_infinity (vr0.min))\n \t    new_min = negative_overflow_infinity (outer_type);\n \t  else\n-\t    new_min = force_fit_type_double (outer_type,\n-\t\t\t\t\t     tree_to_double_int (vr0.min),\n-\t\t\t\t\t     0, false);\n+\t    new_min = force_fit_type (outer_type, wi::to_widest (vr0.min),\n+\t\t\t\t      0, false);\n \t  if (is_overflow_infinity (vr0.max))\n \t    new_max = positive_overflow_infinity (outer_type);\n \t  else\n-\t    new_max = force_fit_type_double (outer_type,\n-\t\t\t\t\t     tree_to_double_int (vr0.max),\n-\t\t\t\t\t     0, false);\n+\t    new_max = force_fit_type (outer_type, wi::to_widest (vr0.max),\n+\t\t\t\t      0, false);\n \t  set_and_canonicalize_value_range (vr, vr0.type,\n \t\t\t\t\t    new_min, new_max, NULL);\n \t  return;\n@@ -3409,7 +3334,7 @@ extract_range_from_unary_expr_1 (value_range_t *vr,\n \n \t\t  min = (vr0.min != type_min_value\n \t\t\t ? int_const_binop (PLUS_EXPR, type_min_value,\n-\t\t\t\t\t    integer_one_node)\n+\t\t\t\t\t    build_int_cst (TREE_TYPE (type_min_value), 1))\n \t\t\t : type_min_value);\n \t\t}\n \t      else\n@@ -3925,30 +3850,29 @@ adjust_range_with_scev (value_range_t *vr, struct loop *loop,\n       && (TREE_CODE (init) != SSA_NAME\n \t  || get_value_range (init)->type == VR_RANGE))\n     {\n-      double_int nit;\n+      widest_int nit;\n \n       /* We are only entering here for loop header PHI nodes, so using\n \t the number of latch executions is the correct thing to use.  */\n       if (max_loop_iterations (loop, &nit))\n \t{\n \t  value_range_t maxvr = VR_INITIALIZER;\n-\t  double_int dtmp;\n-\t  bool unsigned_p = TYPE_UNSIGNED (TREE_TYPE (step));\n-\t  bool overflow = false;\n+\t  signop sgn = TYPE_SIGN (TREE_TYPE (step));\n+\t  bool overflow;\n \n-\t  dtmp = tree_to_double_int (step)\n-\t\t .mul_with_sign (nit, unsigned_p, &overflow);\n+\t  widest_int wtmp = wi::mul (wi::to_widest (step), nit, sgn,\n+\t\t\t\t     &overflow);\n \t  /* If the multiplication overflowed we can't do a meaningful\n \t     adjustment.  Likewise if the result doesn't fit in the type\n \t     of the induction variable.  For a signed type we have to\n \t     check whether the result has the expected signedness which\n \t     is that of the step as number of iterations is unsigned.  */\n \t  if (!overflow\n-\t      && double_int_fits_to_tree_p (TREE_TYPE (init), dtmp)\n-\t      && (unsigned_p\n-\t\t  || ((dtmp.high ^ TREE_INT_CST_HIGH (step)) >= 0)))\n+\t      && wi::fits_to_tree_p (wtmp, TREE_TYPE (init))\n+\t      && (sgn == UNSIGNED\n+\t\t  || wi::gts_p (wtmp, 0) == wi::gts_p (step, 0)))\n \t    {\n-\t      tem = double_int_to_tree (TREE_TYPE (init), dtmp);\n+\t      tem = wide_int_to_tree (TREE_TYPE (init), wtmp);\n \t      extract_range_from_binary_expr (&maxvr, PLUS_EXPR,\n \t\t\t\t\t      TREE_TYPE (init), init, tem);\n \t      /* Likewise if the addition did.  */\n@@ -4773,23 +4697,23 @@ extract_code_and_val_from_cond_with_ops (tree name, enum tree_code cond_code,\n    (to transform signed values into unsigned) and at the end xor\n    SGNBIT back.  */\n \n-static double_int\n-masked_increment (double_int val, double_int mask, double_int sgnbit,\n-\t\t  unsigned int prec)\n+static wide_int\n+masked_increment (const wide_int &val_in, const wide_int &mask,\n+\t\t  const wide_int &sgnbit, unsigned int prec)\n {\n-  double_int bit = double_int_one, res;\n+  wide_int bit = wi::one (prec), res;\n   unsigned int i;\n \n-  val ^= sgnbit;\n+  wide_int val = val_in ^ sgnbit;\n   for (i = 0; i < prec; i++, bit += bit)\n     {\n       res = mask;\n-      if ((res & bit).is_zero ())\n+      if ((res & bit) == 0)\n \tcontinue;\n-      res = bit - double_int_one;\n+      res = bit - 1;\n       res = (val + bit).and_not (res);\n       res &= mask;\n-      if (res.ugt (val))\n+      if (wi::gtu_p (res, val))\n \treturn res ^ sgnbit;\n     }\n   return val ^ sgnbit;\n@@ -4964,8 +4888,8 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n       gimple def_stmt = SSA_NAME_DEF_STMT (name);\n       tree name2 = NULL_TREE, names[2], cst2 = NULL_TREE;\n       tree val2 = NULL_TREE;\n-      double_int mask = double_int_zero;\n       unsigned int prec = TYPE_PRECISION (TREE_TYPE (val));\n+      wide_int mask = wi::zero (prec);\n       unsigned int nprec = prec;\n       enum tree_code rhs_code = ERROR_MARK;\n \n@@ -5034,12 +4958,11 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t      && tree_fits_uhwi_p (cst2)\n \t      && INTEGRAL_TYPE_P (TREE_TYPE (name2))\n \t      && IN_RANGE (tree_to_uhwi (cst2), 1, prec - 1)\n-\t      && prec <= HOST_BITS_PER_DOUBLE_INT\n \t      && prec == GET_MODE_PRECISION (TYPE_MODE (TREE_TYPE (val)))\n \t      && live_on_edge (e, name2)\n \t      && !has_single_use (name2))\n \t    {\n-\t      mask = double_int::mask (tree_to_uhwi (cst2));\n+\t      mask = wi::mask (tree_to_uhwi (cst2), false, prec);\n \t      val2 = fold_binary (LSHIFT_EXPR, TREE_TYPE (val), val, cst2);\n \t    }\n \t}\n@@ -5062,26 +4985,26 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t\t  val2 = fold_convert (type, val2);\n \t\t}\n \t      tmp = fold_build2 (MINUS_EXPR, TREE_TYPE (tmp), tmp, val2);\n-\t      new_val = double_int_to_tree (TREE_TYPE (tmp), mask);\n+\t      new_val = wide_int_to_tree (TREE_TYPE (tmp), mask);\n \t      new_comp_code = comp_code == EQ_EXPR ? LE_EXPR : GT_EXPR;\n \t    }\n \t  else if (comp_code == LT_EXPR || comp_code == GE_EXPR)\n \t    {\n-\t      double_int minval\n-\t\t= double_int::min_value (prec, TYPE_UNSIGNED (TREE_TYPE (val)));\n+\t      wide_int minval\n+\t\t= wi::min_value (prec, TYPE_SIGN (TREE_TYPE (val)));\n \t      new_val = val2;\n-\t      if (minval == tree_to_double_int (new_val))\n+\t      if (minval == new_val)\n \t\tnew_val = NULL_TREE;\n \t    }\n \t  else\n \t    {\n-\t      double_int maxval\n-\t\t= double_int::max_value (prec, TYPE_UNSIGNED (TREE_TYPE (val)));\n-\t      mask |= tree_to_double_int (val2);\n+\t      wide_int maxval\n+\t\t= wi::max_value (prec, TYPE_SIGN (TREE_TYPE (val)));\n+\t      mask |= val2;\n \t      if (mask == maxval)\n \t\tnew_val = NULL_TREE;\n \t      else\n-\t\tnew_val = double_int_to_tree (TREE_TYPE (val2), mask);\n+\t\tnew_val = wide_int_to_tree (TREE_TYPE (val2), mask);\n \t    }\n \n \t  if (new_val)\n@@ -5133,7 +5056,6 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t      && INTEGRAL_TYPE_P (TREE_TYPE (name2))\n \t      && TREE_CODE (cst2) == INTEGER_CST\n \t      && !integer_zerop (cst2)\n-\t      && nprec <= HOST_BITS_PER_DOUBLE_INT\n \t      && (nprec > 1\n \t\t  || TYPE_UNSIGNED (TREE_TYPE (val))))\n \t    {\n@@ -5156,27 +5078,24 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t}\n       if (names[0] || names[1])\n \t{\n-\t  double_int minv, maxv = double_int_zero, valv, cst2v;\n-\t  double_int tem, sgnbit;\n-\t  bool valid_p = false, valn = false, cst2n = false;\n+\t  wide_int minv, maxv, valv, cst2v;\n+\t  wide_int tem, sgnbit;\n+\t  bool valid_p = false, valn, cst2n;\n \t  enum tree_code ccode = comp_code;\n \n-\t  valv = tree_to_double_int (val).zext (nprec);\n-\t  cst2v = tree_to_double_int (cst2).zext (nprec);\n-\t  if (!TYPE_UNSIGNED (TREE_TYPE (val)))\n-\t    {\n-\t      valn = valv.sext (nprec).is_negative ();\n-\t      cst2n = cst2v.sext (nprec).is_negative ();\n-\t    }\n+\t  valv = wide_int::from (val, nprec, UNSIGNED);\n+\t  cst2v = wide_int::from (cst2, nprec, UNSIGNED);\n+\t  valn = wi::neg_p (valv, TYPE_SIGN (TREE_TYPE (val)));\n+\t  cst2n = wi::neg_p (cst2v, TYPE_SIGN (TREE_TYPE (val)));\n \t  /* If CST2 doesn't have most significant bit set,\n \t     but VAL is negative, we have comparison like\n \t     if ((x & 0x123) > -4) (always true).  Just give up.  */\n \t  if (!cst2n && valn)\n \t    ccode = ERROR_MARK;\n \t  if (cst2n)\n-\t    sgnbit = double_int_one.llshift (nprec - 1, nprec).zext (nprec);\n+\t    sgnbit = wi::set_bit_in_zero (nprec - 1, nprec);\n \t  else\n-\t    sgnbit = double_int_zero;\n+\t    sgnbit = wi::zero (nprec);\n \t  minv = valv & cst2v;\n \t  switch (ccode)\n \t    {\n@@ -5186,49 +5105,47 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t\t have folded the comparison into false) and\n \t\t maximum unsigned value is VAL | ~CST2.  */\n \t      maxv = valv | ~cst2v;\n-\t      maxv = maxv.zext (nprec);\n \t      valid_p = true;\n \t      break;\n+\n \t    case NE_EXPR:\n \t      tem = valv | ~cst2v;\n-\t      tem = tem.zext (nprec);\n \t      /* If VAL is 0, handle (X & CST2) != 0 as (X & CST2) > 0U.  */\n-\t      if (valv.is_zero ())\n+\t      if (valv == 0)\n \t\t{\n \t\t  cst2n = false;\n-\t\t  sgnbit = double_int_zero;\n+\t\t  sgnbit = wi::zero (nprec);\n \t\t  goto gt_expr;\n \t\t}\n \t      /* If (VAL | ~CST2) is all ones, handle it as\n \t\t (X & CST2) < VAL.  */\n-\t      if (tem == double_int::mask (nprec))\n+\t      if (tem == -1)\n \t\t{\n \t\t  cst2n = false;\n \t\t  valn = false;\n-\t\t  sgnbit = double_int_zero;\n+\t\t  sgnbit = wi::zero (nprec);\n \t\t  goto lt_expr;\n \t\t}\n-\t      if (!cst2n\n-\t\t  && cst2v.sext (nprec).is_negative ())\n-\t\tsgnbit\n-\t\t  = double_int_one.llshift (nprec - 1, nprec).zext (nprec);\n-\t      if (!sgnbit.is_zero ())\n+\t      if (!cst2n && wi::neg_p (cst2v))\n+\t\tsgnbit = wi::set_bit_in_zero (nprec - 1, nprec);\n+\t      if (sgnbit != 0)\n \t\t{\n \t\t  if (valv == sgnbit)\n \t\t    {\n \t\t      cst2n = true;\n \t\t      valn = true;\n \t\t      goto gt_expr;\n \t\t    }\n-\t\t  if (tem == double_int::mask (nprec - 1))\n+\t\t  if (tem == wi::mask (nprec - 1, false, nprec))\n \t\t    {\n \t\t      cst2n = true;\n \t\t      goto lt_expr;\n \t\t    }\n \t\t  if (!cst2n)\n-\t\t    sgnbit = double_int_zero;\n+\t\t    sgnbit = wi::zero (nprec);\n \t\t}\n \t      break;\n+\n \t    case GE_EXPR:\n \t      /* Minimum unsigned value for >= if (VAL & CST2) == VAL\n \t\t is VAL and maximum unsigned value is ~0.  For signed\n@@ -5243,9 +5160,10 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t\t  if (minv == valv)\n \t\t    break;\n \t\t}\n-\t      maxv = double_int::mask (nprec - (cst2n ? 1 : 0));\n+\t      maxv = wi::mask (nprec - (cst2n ? 1 : 0), false, nprec);\n \t      valid_p = true;\n \t      break;\n+\n \t    case GT_EXPR:\n \t    gt_expr:\n \t      /* Find out smallest MINV where MINV > VAL\n@@ -5254,9 +5172,10 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t      minv = masked_increment (valv, cst2v, sgnbit, nprec);\n \t      if (minv == valv)\n \t\tbreak;\n-\t      maxv = double_int::mask (nprec - (cst2n ? 1 : 0));\n+\t      maxv = wi::mask (nprec - (cst2n ? 1 : 0), false, nprec);\n \t      valid_p = true;\n \t      break;\n+\n \t    case LE_EXPR:\n \t      /* Minimum unsigned value for <= is 0 and maximum\n \t\t unsigned value is VAL | ~CST2 if (VAL & CST2) == VAL.\n@@ -5273,13 +5192,13 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t\t  maxv = masked_increment (valv, cst2v, sgnbit, nprec);\n \t\t  if (maxv == valv)\n \t\t    break;\n-\t\t  maxv -= double_int_one;\n+\t\t  maxv -= 1;\n \t\t}\n \t      maxv |= ~cst2v;\n-\t      maxv = maxv.zext (nprec);\n \t      minv = sgnbit;\n \t      valid_p = true;\n \t      break;\n+\n \t    case LT_EXPR:\n \t    lt_expr:\n \t      /* Minimum unsigned value for < is 0 and maximum\n@@ -5302,39 +5221,39 @@ register_edge_assert_for_2 (tree name, edge e, gimple_stmt_iterator bsi,\n \t\t  if (maxv == valv)\n \t\t    break;\n \t\t}\n-\t      maxv -= double_int_one;\n+\t      maxv -= 1;\n \t      maxv |= ~cst2v;\n-\t      maxv = maxv.zext (nprec);\n \t      minv = sgnbit;\n \t      valid_p = true;\n \t      break;\n+\n \t    default:\n \t      break;\n \t    }\n \t  if (valid_p\n-\t      && (maxv - minv).zext (nprec) != double_int::mask (nprec))\n+\t      && (maxv - minv) != -1)\n \t    {\n \t      tree tmp, new_val, type;\n \t      int i;\n \n \t      for (i = 0; i < 2; i++)\n \t\tif (names[i])\n \t\t  {\n-\t\t    double_int maxv2 = maxv;\n+\t\t    wide_int maxv2 = maxv;\n \t\t    tmp = names[i];\n \t\t    type = TREE_TYPE (names[i]);\n \t\t    if (!TYPE_UNSIGNED (type))\n \t\t      {\n \t\t\ttype = build_nonstandard_integer_type (nprec, 1);\n \t\t\ttmp = build1 (NOP_EXPR, type, names[i]);\n \t\t      }\n-\t\t    if (!minv.is_zero ())\n+\t\t    if (minv != 0)\n \t\t      {\n \t\t\ttmp = build2 (PLUS_EXPR, type, tmp,\n-\t\t\t\t      double_int_to_tree (type, -minv));\n+\t\t\t\t      wide_int_to_tree (type, -minv));\n \t\t\tmaxv2 = maxv - minv;\n \t\t      }\n-\t\t    new_val = double_int_to_tree (type, maxv2);\n+\t\t    new_val = wide_int_to_tree (type, maxv2);\n \n \t\t    if (dump_file)\n \t\t      {\n@@ -6201,7 +6120,8 @@ check_array_ref (location_t location, tree ref, bool ignore_off_by_one)\n     }\n \n   low_bound = array_ref_low_bound (ref);\n-  up_bound_p1 = int_const_binop (PLUS_EXPR, up_bound, integer_one_node);\n+  up_bound_p1 = int_const_binop (PLUS_EXPR, up_bound,\n+\t\t\t\t build_int_cst (TREE_TYPE (up_bound), 1));\n \n   if (TREE_CODE (low_sub) == SSA_NAME)\n     {\n@@ -6298,7 +6218,7 @@ search_for_addr_array (tree t, location_t location)\n     {\n       tree tem = TREE_OPERAND (TREE_OPERAND (t, 0), 0);\n       tree low_bound, up_bound, el_sz;\n-      double_int idx;\n+      offset_int idx;\n       if (TREE_CODE (TREE_TYPE (tem)) != ARRAY_TYPE\n \t  || TREE_CODE (TREE_TYPE (TREE_TYPE (tem))) == ARRAY_TYPE\n \t  || !TYPE_DOMAIN (TREE_TYPE (tem)))\n@@ -6316,8 +6236,8 @@ search_for_addr_array (tree t, location_t location)\n \treturn;\n \n       idx = mem_ref_offset (t);\n-      idx = idx.sdiv (tree_to_double_int (el_sz), TRUNC_DIV_EXPR);\n-      if (idx.slt (double_int_zero))\n+      idx = wi::sdiv_trunc (idx, wi::to_offset (el_sz));\n+      if (wi::lts_p (idx, 0))\n \t{\n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n \t    {\n@@ -6329,9 +6249,8 @@ search_for_addr_array (tree t, location_t location)\n \t\t      \"array subscript is below array bounds\");\n \t  TREE_NO_WARNING (t) = 1;\n \t}\n-      else if (idx.sgt (tree_to_double_int (up_bound)\n-\t\t\t- tree_to_double_int (low_bound)\n-\t\t\t+ double_int_one))\n+      else if (wi::gts_p (idx, (wi::to_offset (up_bound)\n+\t\t\t\t- wi::to_offset (low_bound) + 1)))\n \t{\n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n \t    {\n@@ -6512,8 +6431,7 @@ maybe_set_nonzero_bits (basic_block bb, tree var)\n \treturn;\n     }\n   cst = gimple_assign_rhs2 (stmt);\n-  set_nonzero_bits (var, (get_nonzero_bits (var)\n-\t\t\t  & ~tree_to_double_int (cst)));\n+  set_nonzero_bits (var, wi::bit_and_not (get_nonzero_bits (var), cst));\n }\n \n /* Convert range assertion expressions into the implied copies and\n@@ -6598,8 +6516,8 @@ remove_range_assertions (void)\n \t\t\t\t\t\t\t  single_pred (bb)))\n \t\t  {\n \t\t    set_range_info (var, SSA_NAME_RANGE_TYPE (lhs),\n-\t\t\t\t    SSA_NAME_RANGE_INFO (lhs)->min,\n-\t\t\t\t    SSA_NAME_RANGE_INFO (lhs)->max);\n+\t\t\t\t    SSA_NAME_RANGE_INFO (lhs)->get_min (),\n+\t\t\t\t    SSA_NAME_RANGE_INFO (lhs)->get_max ());\n \t\t    maybe_set_nonzero_bits (bb, var);\n \t\t  }\n \t      }\n@@ -7644,9 +7562,11 @@ union_ranges (enum value_range_type *vr0type,\n \t\t  && vrp_val_is_max (vr1max))\n \t\t{\n \t\t  tree min = int_const_binop (PLUS_EXPR,\n-\t\t\t\t\t      *vr0max, integer_one_node);\n+\t\t\t\t\t      *vr0max,\n+\t\t\t\t\t      build_int_cst (TREE_TYPE (*vr0max), 1));\n \t\t  tree max = int_const_binop (MINUS_EXPR,\n-\t\t\t\t\t      vr1min, integer_one_node);\n+\t\t\t\t\t      vr1min,\n+\t\t\t\t\t      build_int_cst (TREE_TYPE (vr1min), 1));\n \t\t  if (!operand_less_p (max, min))\n \t\t    {\n \t\t      *vr0type = VR_ANTI_RANGE;\n@@ -7668,9 +7588,11 @@ union_ranges (enum value_range_type *vr0type,\n \t\t  && vrp_val_is_max (*vr0max))\n \t\t{\n \t\t  tree min = int_const_binop (PLUS_EXPR,\n-\t\t\t\t\t      vr1max, integer_one_node);\n+\t\t\t\t\t      vr1max,\n+\t\t\t\t\t      build_int_cst (TREE_TYPE (vr1max), 1));\n \t\t  tree max = int_const_binop (MINUS_EXPR,\n-\t\t\t\t\t      *vr0min, integer_one_node);\n+\t\t\t\t\t      *vr0min,\n+\t\t\t\t\t      build_int_cst (TREE_TYPE (*vr0min), 1));\n \t\t  if (!operand_less_p (max, min))\n \t\t    {\n \t\t      *vr0type = VR_ANTI_RANGE;\n@@ -7706,9 +7628,11 @@ union_ranges (enum value_range_type *vr0type,\n \t{\n \t  /* Arbitrarily choose the right or left gap.  */\n \t  if (!mineq && TREE_CODE (vr1min) == INTEGER_CST)\n-\t    *vr0max = int_const_binop (MINUS_EXPR, vr1min, integer_one_node);\n+\t    *vr0max = int_const_binop (MINUS_EXPR, vr1min,\n+\t\t\t\t       build_int_cst (TREE_TYPE (vr1min), 1));\n \t  else if (!maxeq && TREE_CODE (vr1max) == INTEGER_CST)\n-\t    *vr0min = int_const_binop (PLUS_EXPR, vr1max, integer_one_node);\n+\t    *vr0min = int_const_binop (PLUS_EXPR, vr1max,\n+\t\t\t\t       build_int_cst (TREE_TYPE (vr1max), 1));\n \t  else\n \t    goto give_up;\n \t}\n@@ -7739,12 +7663,14 @@ union_ranges (enum value_range_type *vr0type,\n \t  *vr0type = VR_ANTI_RANGE;\n \t  if (!mineq && TREE_CODE (*vr0min) == INTEGER_CST)\n \t    {\n-\t      *vr0max = int_const_binop (MINUS_EXPR, *vr0min, integer_one_node);\n+\t      *vr0max = int_const_binop (MINUS_EXPR, *vr0min,\n+\t\t\t\t\t build_int_cst (TREE_TYPE (*vr0min), 1));\n \t      *vr0min = vr1min;\n \t    }\n \t  else if (!maxeq && TREE_CODE (*vr0max) == INTEGER_CST)\n \t    {\n-\t      *vr0min = int_const_binop (PLUS_EXPR, *vr0max, integer_one_node);\n+\t      *vr0min = int_const_binop (PLUS_EXPR, *vr0max,\n+\t\t\t\t\t build_int_cst (TREE_TYPE (*vr0max), 1));\n \t      *vr0max = vr1max;\n \t    }\n \t  else\n@@ -7773,7 +7699,8 @@ union_ranges (enum value_range_type *vr0type,\n \t       && vr1type == VR_RANGE)\n \t{\n \t  if (TREE_CODE (vr1min) == INTEGER_CST)\n-\t    *vr0max = int_const_binop (MINUS_EXPR, vr1min, integer_one_node);\n+\t    *vr0max = int_const_binop (MINUS_EXPR, vr1min,\n+\t\t\t\t       build_int_cst (TREE_TYPE (vr1min), 1));\n \t  else\n \t    goto give_up;\n \t}\n@@ -7783,7 +7710,8 @@ union_ranges (enum value_range_type *vr0type,\n \t  if (TREE_CODE (*vr0max) == INTEGER_CST)\n \t    {\n \t      *vr0type = vr1type;\n-\t      *vr0min = int_const_binop (PLUS_EXPR, *vr0max, integer_one_node);\n+\t      *vr0min = int_const_binop (PLUS_EXPR, *vr0max,\n+\t\t\t\t\t build_int_cst (TREE_TYPE (*vr0max), 1));\n \t      *vr0max = vr1max;\n \t    }\n \t  else\n@@ -7808,7 +7736,8 @@ union_ranges (enum value_range_type *vr0type,\n \t       && vr1type == VR_RANGE)\n \t{\n \t  if (TREE_CODE (vr1max) == INTEGER_CST)\n-\t    *vr0min = int_const_binop (PLUS_EXPR, vr1max, integer_one_node);\n+\t    *vr0min = int_const_binop (PLUS_EXPR, vr1max,\n+\t\t\t\t       build_int_cst (TREE_TYPE (vr1max), 1));\n \t  else\n \t    goto give_up;\n \t}\n@@ -7819,7 +7748,8 @@ union_ranges (enum value_range_type *vr0type,\n \t    {\n \t      *vr0type = vr1type;\n \t      *vr0min = vr1min;\n-\t      *vr0max = int_const_binop (MINUS_EXPR, *vr0min, integer_one_node);\n+\t      *vr0max = int_const_binop (MINUS_EXPR, *vr0min,\n+\t\t\t\t\t build_int_cst (TREE_TYPE (*vr0min), 1));\n \t    }\n \t  else\n \t    goto give_up;\n@@ -7934,7 +7864,8 @@ intersect_ranges (enum value_range_type *vr0type,\n \t  if (mineq)\n \t    {\n \t      if (TREE_CODE (vr1max) == INTEGER_CST)\n-\t\t*vr0min = int_const_binop (PLUS_EXPR, vr1max, integer_one_node);\n+\t\t*vr0min = int_const_binop (PLUS_EXPR, vr1max,\n+\t\t\t\t\t   build_int_cst (TREE_TYPE (vr1max), 1));\n \t      else\n \t\t*vr0min = vr1max;\n \t    }\n@@ -7943,7 +7874,7 @@ intersect_ranges (enum value_range_type *vr0type,\n \t    {\n \t      if (TREE_CODE (vr1min) == INTEGER_CST)\n \t\t*vr0max = int_const_binop (MINUS_EXPR, vr1min,\n-\t\t\t\t\t   integer_one_node);\n+\t\t\t\t\t   build_int_cst (TREE_TYPE (vr1min), 1));\n \t      else\n \t\t*vr0max = vr1min;\n \t    }\n@@ -7989,7 +7920,7 @@ intersect_ranges (enum value_range_type *vr0type,\n \t      *vr0type = VR_RANGE;\n \t      if (TREE_CODE (*vr0max) == INTEGER_CST)\n \t\t*vr0min = int_const_binop (PLUS_EXPR, *vr0max,\n-\t\t\t\t\t   integer_one_node);\n+\t\t\t\t\t   build_int_cst (TREE_TYPE (*vr0max), 1));\n \t      else\n \t\t*vr0min = *vr0max;\n \t      *vr0max = vr1max;\n@@ -8000,7 +7931,7 @@ intersect_ranges (enum value_range_type *vr0type,\n \t      *vr0type = VR_RANGE;\n \t      if (TREE_CODE (*vr0min) == INTEGER_CST)\n \t\t*vr0max = int_const_binop (MINUS_EXPR, *vr0min,\n-\t\t\t\t\t   integer_one_node);\n+\t\t\t\t\t   build_int_cst (TREE_TYPE (*vr0min), 1));\n \t      else\n \t\t*vr0max = *vr0min;\n \t      *vr0min = vr1min;\n@@ -8052,7 +7983,7 @@ intersect_ranges (enum value_range_type *vr0type,\n \t{\n \t  if (TREE_CODE (vr1min) == INTEGER_CST)\n \t    *vr0max = int_const_binop (MINUS_EXPR, vr1min,\n-\t\t\t\t       integer_one_node);\n+\t\t\t\t       build_int_cst (TREE_TYPE (vr1min), 1));\n \t  else\n \t    *vr0max = vr1min;\n \t}\n@@ -8062,7 +7993,7 @@ intersect_ranges (enum value_range_type *vr0type,\n \t  *vr0type = VR_RANGE;\n \t  if (TREE_CODE (*vr0max) == INTEGER_CST)\n \t    *vr0min = int_const_binop (PLUS_EXPR, *vr0max,\n-\t\t\t\t       integer_one_node);\n+\t\t\t\t       build_int_cst (TREE_TYPE (*vr0max), 1));\n \t  else\n \t    *vr0min = *vr0max;\n \t  *vr0max = vr1max;\n@@ -8086,7 +8017,7 @@ intersect_ranges (enum value_range_type *vr0type,\n \t{\n \t  if (TREE_CODE (vr1max) == INTEGER_CST)\n \t    *vr0min = int_const_binop (PLUS_EXPR, vr1max,\n-\t\t\t\t       integer_one_node);\n+\t\t\t\t       build_int_cst (TREE_TYPE (vr1max), 1));\n \t  else\n \t    *vr0min = vr1max;\n \t}\n@@ -8096,7 +8027,7 @@ intersect_ranges (enum value_range_type *vr0type,\n \t  *vr0type = VR_RANGE;\n \t  if (TREE_CODE (*vr0min) == INTEGER_CST)\n \t    *vr0max = int_const_binop (MINUS_EXPR, *vr0min,\n-\t\t\t\t       integer_one_node);\n+\t\t\t\t       build_int_cst (TREE_TYPE (*vr0min), 1));\n \t  else\n \t    *vr0max = *vr0min;\n \t  *vr0min = vr1min;\n@@ -8503,7 +8434,8 @@ simplify_truth_ops_using_ranges (gimple_stmt_iterator *gsi, gimple stmt)\n   if (rhs_code == EQ_EXPR)\n     {\n       if (TREE_CODE (op1) == INTEGER_CST)\n-\top1 = int_const_binop (BIT_XOR_EXPR, op1, integer_one_node);\n+\top1 = int_const_binop (BIT_XOR_EXPR, op1,\n+\t\t\t       build_int_cst (TREE_TYPE (op1), 1));\n       else\n \treturn false;\n     }\n@@ -8689,9 +8621,9 @@ simplify_bit_ops_using_ranges (gimple_stmt_iterator *gsi, gimple stmt)\n   tree op = NULL_TREE;\n   value_range_t vr0 = VR_INITIALIZER;\n   value_range_t vr1 = VR_INITIALIZER;\n-  double_int may_be_nonzero0, may_be_nonzero1;\n-  double_int must_be_nonzero0, must_be_nonzero1;\n-  double_int mask;\n+  wide_int may_be_nonzero0, may_be_nonzero1;\n+  wide_int must_be_nonzero0, must_be_nonzero1;\n+  wide_int mask;\n \n   if (TREE_CODE (op0) == SSA_NAME)\n     vr0 = *(get_value_range (op0));\n@@ -8707,36 +8639,38 @@ simplify_bit_ops_using_ranges (gimple_stmt_iterator *gsi, gimple stmt)\n   else\n     return false;\n \n-  if (!zero_nonzero_bits_from_vr (&vr0, &may_be_nonzero0, &must_be_nonzero0))\n+  if (!zero_nonzero_bits_from_vr (TREE_TYPE (op0), &vr0, &may_be_nonzero0,\n+\t\t\t\t  &must_be_nonzero0))\n     return false;\n-  if (!zero_nonzero_bits_from_vr (&vr1, &may_be_nonzero1, &must_be_nonzero1))\n+  if (!zero_nonzero_bits_from_vr (TREE_TYPE (op1), &vr1, &may_be_nonzero1,\n+\t\t\t\t  &must_be_nonzero1))\n     return false;\n \n   switch (gimple_assign_rhs_code (stmt))\n     {\n     case BIT_AND_EXPR:\n       mask = may_be_nonzero0.and_not (must_be_nonzero1);\n-      if (mask.is_zero ())\n+      if (mask == 0)\n \t{\n \t  op = op0;\n \t  break;\n \t}\n       mask = may_be_nonzero1.and_not (must_be_nonzero0);\n-      if (mask.is_zero ())\n+      if (mask == 0)\n \t{\n \t  op = op1;\n \t  break;\n \t}\n       break;\n     case BIT_IOR_EXPR:\n       mask = may_be_nonzero0.and_not (must_be_nonzero1);\n-      if (mask.is_zero ())\n+      if (mask == 0)\n \t{\n \t  op = op1;\n \t  break;\n \t}\n       mask = may_be_nonzero1.and_not (must_be_nonzero0);\n-      if (mask.is_zero ())\n+      if (mask == 0)\n \t{\n \t  op = op0;\n \t  break;\n@@ -8822,25 +8756,26 @@ test_for_singularity (enum tree_code cond_code, tree op0,\n    by PRECISION and UNSIGNED_P.  */\n \n static bool\n-range_fits_type_p (value_range_t *vr, unsigned precision, bool unsigned_p)\n+range_fits_type_p (value_range_t *vr, unsigned dest_precision, signop dest_sgn)\n {\n   tree src_type;\n   unsigned src_precision;\n-  double_int tem;\n+  widest_int tem;\n+  signop src_sgn;\n \n   /* We can only handle integral and pointer types.  */\n   src_type = TREE_TYPE (vr->min);\n   if (!INTEGRAL_TYPE_P (src_type)\n       && !POINTER_TYPE_P (src_type))\n     return false;\n \n-  /* An extension is fine unless VR is signed and unsigned_p,\n+  /* An extension is fine unless VR is SIGNED and dest_sgn is UNSIGNED,\n      and so is an identity transform.  */\n   src_precision = TYPE_PRECISION (TREE_TYPE (vr->min));\n-  if ((src_precision < precision\n-       && !(unsigned_p && !TYPE_UNSIGNED (src_type)))\n-      || (src_precision == precision\n-\t  && TYPE_UNSIGNED (src_type) == unsigned_p))\n+  src_sgn = TYPE_SIGN (src_type);\n+  if ((src_precision < dest_precision\n+       && !(dest_sgn == UNSIGNED && src_sgn == SIGNED))\n+      || (src_precision == dest_precision && src_sgn == dest_sgn))\n     return true;\n \n   /* Now we can only handle ranges with constant bounds.  */\n@@ -8849,21 +8784,21 @@ range_fits_type_p (value_range_t *vr, unsigned precision, bool unsigned_p)\n       || TREE_CODE (vr->max) != INTEGER_CST)\n     return false;\n \n-  /* For sign changes, the MSB of the double_int has to be clear.\n+  /* For sign changes, the MSB of the wide_int has to be clear.\n      An unsigned value with its MSB set cannot be represented by\n-     a signed double_int, while a negative value cannot be represented\n-     by an unsigned double_int.  */\n-  if (TYPE_UNSIGNED (src_type) != unsigned_p\n-      && (TREE_INT_CST_HIGH (vr->min) | TREE_INT_CST_HIGH (vr->max)) < 0)\n+     a signed wide_int, while a negative value cannot be represented\n+     by an unsigned wide_int.  */\n+  if (src_sgn != dest_sgn\n+      && (wi::lts_p (vr->min, 0) || wi::lts_p (vr->max, 0)))\n     return false;\n \n   /* Then we can perform the conversion on both ends and compare\n      the result for equality.  */\n-  tem = tree_to_double_int (vr->min).ext (precision, unsigned_p);\n-  if (tree_to_double_int (vr->min) != tem)\n+  tem = wi::ext (wi::to_widest (vr->min), dest_precision, dest_sgn);\n+  if (tem != wi::to_widest (vr->min))\n     return false;\n-  tem = tree_to_double_int (vr->max).ext (precision, unsigned_p);\n-  if (tree_to_double_int (vr->max) != tem)\n+  tem = wi::ext (wi::to_widest (vr->max), dest_precision, dest_sgn);\n+  if (tem != wi::to_widest (vr->max))\n     return false;\n \n   return true;\n@@ -8978,7 +8913,7 @@ simplify_cond_using_ranges (gimple stmt)\n \t  if (range_int_cst_p (vr)\n \t      && range_fits_type_p (vr,\n \t\t\t\t    TYPE_PRECISION (TREE_TYPE (op0)),\n-\t\t\t\t    TYPE_UNSIGNED (TREE_TYPE (op0)))\n+\t\t\t\t    TYPE_SIGN (TREE_TYPE (op0)))\n \t      && int_fits_type_p (op1, TREE_TYPE (innerop))\n \t      /* The range must not have overflowed, or if it did overflow\n \t\t we must not be wrapping/trapping overflow and optimizing\n@@ -9123,9 +9058,9 @@ simplify_conversion_using_ranges (gimple stmt)\n   tree innerop, middleop, finaltype;\n   gimple def_stmt;\n   value_range_t *innervr;\n-  bool inner_unsigned_p, middle_unsigned_p, final_unsigned_p;\n+  signop inner_sgn, middle_sgn, final_sgn;\n   unsigned inner_prec, middle_prec, final_prec;\n-  double_int innermin, innermed, innermax, middlemin, middlemed, middlemax;\n+  widest_int innermin, innermed, innermax, middlemin, middlemed, middlemax;\n \n   finaltype = TREE_TYPE (gimple_assign_lhs (stmt));\n   if (!INTEGRAL_TYPE_P (finaltype))\n@@ -9149,43 +9084,44 @@ simplify_conversion_using_ranges (gimple stmt)\n \n   /* Simulate the conversion chain to check if the result is equal if\n      the middle conversion is removed.  */\n-  innermin = tree_to_double_int (innervr->min);\n-  innermax = tree_to_double_int (innervr->max);\n+  innermin = wi::to_widest (innervr->min);\n+  innermax = wi::to_widest (innervr->max);\n \n   inner_prec = TYPE_PRECISION (TREE_TYPE (innerop));\n   middle_prec = TYPE_PRECISION (TREE_TYPE (middleop));\n   final_prec = TYPE_PRECISION (finaltype);\n \n   /* If the first conversion is not injective, the second must not\n      be widening.  */\n-  if ((innermax - innermin).ugt (double_int::mask (middle_prec))\n+  if (wi::gtu_p (innermax - innermin,\n+\t\t wi::mask <widest_int> (middle_prec, false))\n       && middle_prec < final_prec)\n     return false;\n   /* We also want a medium value so that we can track the effect that\n      narrowing conversions with sign change have.  */\n-  inner_unsigned_p = TYPE_UNSIGNED (TREE_TYPE (innerop));\n-  if (inner_unsigned_p)\n-    innermed = double_int::mask (inner_prec).lrshift (1, inner_prec);\n+  inner_sgn = TYPE_SIGN (TREE_TYPE (innerop));\n+  if (inner_sgn == UNSIGNED)\n+    innermed = wi::shifted_mask <widest_int> (1, inner_prec - 1, false);\n   else\n-    innermed = double_int_zero;\n-  if (innermin.cmp (innermed, inner_unsigned_p) >= 0\n-      || innermed.cmp (innermax, inner_unsigned_p) >= 0)\n+    innermed = 0;\n+  if (wi::cmp (innermin, innermed, inner_sgn) >= 0\n+      || wi::cmp (innermed, innermax, inner_sgn) >= 0)\n     innermed = innermin;\n \n-  middle_unsigned_p = TYPE_UNSIGNED (TREE_TYPE (middleop));\n-  middlemin = innermin.ext (middle_prec, middle_unsigned_p);\n-  middlemed = innermed.ext (middle_prec, middle_unsigned_p);\n-  middlemax = innermax.ext (middle_prec, middle_unsigned_p);\n+  middle_sgn = TYPE_SIGN (TREE_TYPE (middleop));\n+  middlemin = wi::ext (innermin, middle_prec, middle_sgn);\n+  middlemed = wi::ext (innermed, middle_prec, middle_sgn);\n+  middlemax = wi::ext (innermax, middle_prec, middle_sgn);\n \n   /* Require that the final conversion applied to both the original\n      and the intermediate range produces the same result.  */\n-  final_unsigned_p = TYPE_UNSIGNED (finaltype);\n-  if (middlemin.ext (final_prec, final_unsigned_p)\n-\t != innermin.ext (final_prec, final_unsigned_p)\n-      || middlemed.ext (final_prec, final_unsigned_p)\n-\t != innermed.ext (final_prec, final_unsigned_p)\n-      || middlemax.ext (final_prec, final_unsigned_p)\n-\t != innermax.ext (final_prec, final_unsigned_p))\n+  final_sgn = TYPE_SIGN (finaltype);\n+  if (wi::ext (middlemin, final_prec, final_sgn)\n+\t != wi::ext (innermin, final_prec, final_sgn)\n+      || wi::ext (middlemed, final_prec, final_sgn)\n+\t != wi::ext (innermed, final_prec, final_sgn)\n+      || wi::ext (middlemax, final_prec, final_sgn)\n+\t != wi::ext (innermax, final_prec, final_sgn))\n     return false;\n \n   gimple_assign_set_rhs1 (stmt, innerop);\n@@ -9215,8 +9151,7 @@ simplify_float_conversion_using_ranges (gimple_stmt_iterator *gsi, gimple stmt)\n   if (TYPE_UNSIGNED (TREE_TYPE (rhs1))\n       && (can_float_p (fltmode, TYPE_MODE (TREE_TYPE (rhs1)), 0)\n \t  != CODE_FOR_nothing)\n-      && range_fits_type_p (vr, GET_MODE_PRECISION\n-\t\t\t          (TYPE_MODE (TREE_TYPE (rhs1))), 0))\n+      && range_fits_type_p (vr, TYPE_PRECISION (TREE_TYPE (rhs1)), SIGNED))\n     mode = TYPE_MODE (TREE_TYPE (rhs1));\n   /* If we can do the conversion in the current input mode do nothing.  */\n   else if (can_float_p (fltmode, TYPE_MODE (TREE_TYPE (rhs1)),\n@@ -9233,7 +9168,7 @@ simplify_float_conversion_using_ranges (gimple_stmt_iterator *gsi, gimple stmt)\n \t     or if the value-range does not fit in the signed type\n \t     try with a wider mode.  */\n \t  if (can_float_p (fltmode, mode, 0) != CODE_FOR_nothing\n-\t      && range_fits_type_p (vr, GET_MODE_PRECISION (mode), 0))\n+\t      && range_fits_type_p (vr, GET_MODE_PRECISION (mode), SIGNED))\n \t    break;\n \n \t  mode = GET_MODE_WIDER_MODE (mode);\n@@ -9701,9 +9636,8 @@ vrp_finalize (void)\n \t    && (TREE_CODE (vr_value[i]->max) == INTEGER_CST)\n \t    && (vr_value[i]->type == VR_RANGE\n \t\t|| vr_value[i]->type == VR_ANTI_RANGE))\n-\t  set_range_info (name, vr_value[i]->type,\n-\t\t\t  tree_to_double_int (vr_value[i]->min),\n-\t\t\t  tree_to_double_int (vr_value[i]->max));\n+\t  set_range_info (name, vr_value[i]->type, vr_value[i]->min,\n+\t\t\t  vr_value[i]->max);\n       }\n \n   /* Free allocated memory.  */"}, {"sha": "a578c92692398cdd0358a4d74e6cde746bc3226c", "filename": "gcc/tree.c", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "a6247a7e00a29d0ce260830099ab3c98881af8cd", "filename": "gcc/tree.def", "status": "modified", "additions": 18, "deletions": 7, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.def?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "3e8e625ab9f3bb6701b0c6b3e83291830ec81c07", "filename": "gcc/tree.h", "status": "modified", "additions": 236, "deletions": 42, "changes": 278, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "0d033ef6284fe2fe1d18ce4e966c8b1493e98464", "filename": "gcc/value-prof.c", "status": "modified", "additions": 23, "deletions": 6, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fvalue-prof.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fvalue-prof.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvalue-prof.c?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "f36a1e9a6921255817fa4f75a65a24caada840ee", "filename": "gcc/var-tracking.c", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fvar-tracking.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fvar-tracking.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvar-tracking.c?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "f8930b989b8a707ba2d2c397e938029e87915292", "filename": "gcc/varasm.c", "status": "modified", "additions": 33, "deletions": 42, "changes": 75, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fvarasm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fvarasm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvarasm.c?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "c79c781d3ef6a47bd4e1e1cee9983de03aa5458a", "filename": "gcc/wide-int-print.cc", "status": "added", "additions": 145, "deletions": 0, "changes": 145, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int-print.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int-print.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fwide-int-print.cc?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "9ab37d334326dc890a5263d5c3428af32b222a10", "filename": "gcc/wide-int-print.h", "status": "added", "additions": 39, "deletions": 0, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int-print.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int-print.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fwide-int-print.h?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "69a15bcd148b3cf21c3b2d4e19cf9e1818f2aa1d", "filename": "gcc/wide-int.cc", "status": "added", "additions": 2083, "deletions": 0, "changes": 2083, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fwide-int.cc?ref=807e902eea17f3132488c256c963823976b2348c"}, {"sha": "6860af95be447520d486058536de91f561504f0a", "filename": "gcc/wide-int.h", "status": "added", "additions": 3175, "deletions": 0, "changes": 3175, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/807e902eea17f3132488c256c963823976b2348c/gcc%2Fwide-int.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fwide-int.h?ref=807e902eea17f3132488c256c963823976b2348c"}]}