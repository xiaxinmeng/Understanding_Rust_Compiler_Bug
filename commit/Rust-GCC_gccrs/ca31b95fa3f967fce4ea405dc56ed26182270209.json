{"sha": "ca31b95fa3f967fce4ea405dc56ed26182270209", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2EzMWI5NWZhM2Y5NjdmY2U0ZWE0MDVkYzU2ZWQyNjE4MjI3MDIwOQ==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2005-04-22T08:16:54Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2005-04-22T08:16:54Z"}, "message": "Makefile.in (ipa.o, [...]): New files.\n\n\t* Makefile.in (ipa.o, ipa-inline.o): New files.\n\t* cgraph.h (cgraph_remove_unreachable_nodes, cgraph_postorder,\n\tcgraph_decide_inlining_incrementally, cgraph_clone_inlined_nodes,\n\tcgraph_mark_inline_edge, cgraph_default_inline_p): Declare.\n\t* cgraphunit.c (cgraph_default_inline_p, cgraph_decide_inlining_incrementally,\n\tncalls_inlined, nfunctions_inlined, initial_insns, overall_insns,\n\tcgraph_estimate_size_after_inlining, cgraph_estimate_growth,\n\tcgraph_clone_inlined_nodes, cgraph_mark_inline_edge,\n\tcgraph_mark_inline, cgraph_check_inline_limits,\n\tcgraph_default_inline_p, cgraph_recursive_inlining_p,\n\tupdate_callee_keys, lookup_recursive_calls,\n\tcgraph_decide_recursive_inlining, cgraph_set_inline_failed,\n\tcgraph_decide_inlining_of_small_functions, cgraph_decide_inlining,\n\tcgraph_decide_inlining_incrementally, cgraph_gate_inlining,\n\tpass_ipa_inline): Move to ipa-inline.c\n\t(cgraph_postorder, cgraph_remove_unreachable_nodes): Move to ipa.c\n\t* ipa.c: New file.\n\t* ipa-inline.c: New file.\n\nFrom-SVN: r98548", "tree": {"sha": "598ab8016451f69732ab1a9e5b0b7a779f6eb73f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/598ab8016451f69732ab1a9e5b0b7a779f6eb73f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ca31b95fa3f967fce4ea405dc56ed26182270209", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca31b95fa3f967fce4ea405dc56ed26182270209", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ca31b95fa3f967fce4ea405dc56ed26182270209", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca31b95fa3f967fce4ea405dc56ed26182270209/comments", "author": null, "committer": null, "parents": [{"sha": "6e32e5b97a009659a9001b98d72785bc3bf43deb", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6e32e5b97a009659a9001b98d72785bc3bf43deb", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6e32e5b97a009659a9001b98d72785bc3bf43deb"}], "stats": {"total": 1824, "additions": 982, "deletions": 842}, "files": [{"sha": "6c76f29d00738233bf54ac45b33893ec3de52404", "filename": "gcc/ChangeLog", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ca31b95fa3f967fce4ea405dc56ed26182270209", "patch": "@@ -1,3 +1,24 @@\n+2005-04-22  Jan Hubicka  <jh@suse.cz>\n+\n+\t* Makefile.in (ipa.o, ipa-inline.o): New files.\n+\t* cgraph.h (cgraph_remove_unreachable_nodes, cgraph_postorder,\n+\tcgraph_decide_inlining_incrementally, cgraph_clone_inlined_nodes,\n+\tcgraph_mark_inline_edge, cgraph_default_inline_p): Declare.\n+\t* cgraphunit.c (cgraph_default_inline_p, cgraph_decide_inlining_incrementally, \n+\tncalls_inlined, nfunctions_inlined, initial_insns, overall_insns,\n+\tcgraph_estimate_size_after_inlining, cgraph_estimate_growth,\n+\tcgraph_clone_inlined_nodes, cgraph_mark_inline_edge,\n+\tcgraph_mark_inline, cgraph_check_inline_limits,\n+\tcgraph_default_inline_p, cgraph_recursive_inlining_p,\n+\tupdate_callee_keys, lookup_recursive_calls,\n+\tcgraph_decide_recursive_inlining, cgraph_set_inline_failed,\n+\tcgraph_decide_inlining_of_small_functions, cgraph_decide_inlining,\n+\tcgraph_decide_inlining_incrementally, cgraph_gate_inlining,\n+\tpass_ipa_inline): Move to ipa-inline.c\n+\t(cgraph_postorder, cgraph_remove_unreachable_nodes): Move to ipa.c\n+\t* ipa.c: New file.\n+\t* ipa-inline.c: New file.\n+\n 2005-04-22  Eric Botcazou  <ebotcazou@libertysurf.fr>\n \n \t* doc/invoke.texi (SPARC options): Document that -mapp-regs"}, {"sha": "499b1b73ad33bccc3e4b0de7a62db6e38c6b222b", "filename": "gcc/Makefile.in", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=ca31b95fa3f967fce4ea405dc56ed26182270209", "patch": "@@ -963,7 +963,7 @@ OBJS-common = \\\n \n OBJS-md = $(out_object_file)\n OBJS-archive = $(EXTRA_OBJS) $(host_hook_obj) tree-inline.o\t\t   \\\n-  cgraph.o cgraphunit.o tree-nomudflap.o\n+  cgraph.o cgraphunit.o tree-nomudflap.o ipa.o ipa-inline.o\n \n OBJS = $(OBJS-common) $(out_object_file) $(OBJS-archive)\n \n@@ -1976,6 +1976,10 @@ cgraph.o : cgraph.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) \\\n cgraphunit.o : cgraphunit.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) \\\n    langhooks.h tree-inline.h toplev.h $(FLAGS_H) $(GGC_H)  $(TARGET_H) $(CGRAPH_H) intl.h \\\n    pointer-set.h function.h $(TREE_GIMPLE_H) $(TREE_FLOW_H) tree-pass.h\n+ipa.o : ipa.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(CGRAPH_H) \n+ipa-inline.o : ipa-inline.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) \\\n+   langhooks.h tree-inline.h $(FLAGS_H) $(CGRAPH_H) intl.h $(TREE_FLOW_H) \\\n+   $(COVERAGE_H)\n coverage.o : coverage.c gcov-io.c $(CONFIG_H) $(SYSTEM_H) coretypes.h \\\n    $(TM_H) $(RTL_H) $(TREE_H) $(FLAGS_H) output.h $(REGS_H) $(EXPR_H) function.h \\\n    toplev.h $(GGC_H) $(TARGET_H) langhooks.h $(COVERAGE_H) libfuncs.h \\"}, {"sha": "02fa662061f1f88cda3402754438414a331de3d3", "filename": "gcc/cgraph.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fcgraph.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fcgraph.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraph.h?ref=ca31b95fa3f967fce4ea405dc56ed26182270209", "patch": "@@ -226,4 +226,13 @@ void cgraph_build_static_cdtor (char which, tree body, int priority);\n void cgraph_reset_static_var_maps (void);\n void init_cgraph (void);\n \n+/* In ipa.c  */\n+bool cgraph_remove_unreachable_nodes (bool, FILE *);\n+int cgraph_postorder (struct cgraph_node **);\n+\n+/* In ipa-inline.c  */\n+void cgraph_decide_inlining_incrementally (struct cgraph_node *);\n+void cgraph_clone_inlined_nodes (struct cgraph_edge *, bool);\n+void cgraph_mark_inline_edge (struct cgraph_edge *);\n+bool cgraph_default_inline_p (struct cgraph_node *);\n #endif  /* GCC_CGRAPH_H  */"}, {"sha": "5f6d873f4dc28843813abd518b68d8dfffd34f84", "filename": "gcc/cgraphunit.c", "status": "modified", "additions": 0, "deletions": 839, "changes": 839, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fcgraphunit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fcgraphunit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraphunit.c?ref=ca31b95fa3f967fce4ea405dc56ed26182270209", "patch": "@@ -197,15 +197,7 @@ static void cgraph_mark_functions_to_output (void);\n static void cgraph_expand_function (struct cgraph_node *);\n static tree record_call_1 (tree *, int *, void *);\n static void cgraph_mark_local_functions (void);\n-static bool cgraph_default_inline_p (struct cgraph_node *n);\n static void cgraph_analyze_function (struct cgraph_node *node);\n-static void cgraph_decide_inlining_incrementally (struct cgraph_node *);\n-\n-/* Statistics we collect about inlining algorithm.  */\n-static int ncalls_inlined;\n-static int nfunctions_inlined;\n-static int initial_insns;\n-static int overall_insns;\n \n /* Records tree nodes seen in cgraph_create_edges.  Simply using\n    walk_tree_without_duplicates doesn't guarantee each node is visited\n@@ -947,813 +939,6 @@ cgraph_expand_function (struct cgraph_node *node)\n     }\n }\n \n-/* Fill array order with all nodes with output flag set in the reverse\n-   topological order.  */\n-\n-static int\n-cgraph_postorder (struct cgraph_node **order)\n-{\n-  struct cgraph_node *node, *node2;\n-  int stack_size = 0;\n-  int order_pos = 0;\n-  struct cgraph_edge *edge, last;\n-\n-  struct cgraph_node **stack =\n-    xcalloc (cgraph_n_nodes, sizeof (struct cgraph_node *));\n-\n-  /* We have to deal with cycles nicely, so use a depth first traversal\n-     output algorithm.  Ignore the fact that some functions won't need\n-     to be output and put them into order as well, so we get dependencies\n-     right through intline functions.  */\n-  for (node = cgraph_nodes; node; node = node->next)\n-    node->aux = NULL;\n-  for (node = cgraph_nodes; node; node = node->next)\n-    if (!node->aux)\n-      {\n-\tnode2 = node;\n-\tif (!node->callers)\n-\t  node->aux = &last;\n-\telse\n-\t  node->aux = node->callers;\n-\twhile (node2)\n-\t  {\n-\t    while (node2->aux != &last)\n-\t      {\n-\t\tedge = node2->aux;\n-\t\tif (edge->next_caller)\n-\t\t  node2->aux = edge->next_caller;\n-\t\telse\n-\t\t  node2->aux = &last;\n-\t\tif (!edge->caller->aux)\n-\t\t  {\n-\t\t    if (!edge->caller->callers)\n-\t\t      edge->caller->aux = &last;\n-\t\t    else\n-\t\t      edge->caller->aux = edge->caller->callers;\n-\t\t    stack[stack_size++] = node2;\n-\t\t    node2 = edge->caller;\n-\t\t    break;\n-\t\t  }\n-\t      }\n-\t    if (node2->aux == &last)\n-\t      {\n-\t\torder[order_pos++] = node2;\n-\t\tif (stack_size)\n-\t\t  node2 = stack[--stack_size];\n-\t\telse\n-\t\t  node2 = NULL;\n-\t      }\n-\t  }\n-      }\n-  free (stack);\n-  return order_pos;\n-}\n-\n-\n-/* Perform reachability analysis and reclaim all unreachable nodes.\n-   This function also remove unneeded bodies of extern inline functions\n-   and thus needs to be done only after inlining decisions has been made.  */\n-static bool\n-cgraph_remove_unreachable_nodes (void)\n-{\n-  struct cgraph_node *first = (void *) 1;\n-  struct cgraph_node *node;\n-  bool changed = false;\n-  int insns = 0;\n-\n-#ifdef ENABLE_CHECKING\n-  verify_cgraph ();\n-#endif\n-  if (cgraph_dump_file)\n-    fprintf (cgraph_dump_file, \"\\nReclaiming functions:\");\n-#ifdef ENABLE_CHECKING\n-  for (node = cgraph_nodes; node; node = node->next)\n-    gcc_assert (!node->aux);\n-#endif\n-  for (node = cgraph_nodes; node; node = node->next)\n-    if (node->needed && !node->global.inlined_to\n-\t&& (!DECL_EXTERNAL (node->decl) || !node->analyzed))\n-      {\n-\tnode->aux = first;\n-\tfirst = node;\n-      }\n-    else\n-      gcc_assert (!node->aux);\n-\n-  /* Perform reachability analysis.  As a special case do not consider\n-     extern inline functions not inlined as live because we won't output\n-     them at all.  */\n-  while (first != (void *) 1)\n-    {\n-      struct cgraph_edge *e;\n-      node = first;\n-      first = first->aux;\n-\n-      for (e = node->callees; e; e = e->next_callee)\n-\tif (!e->callee->aux\n-\t    && node->analyzed\n-\t    && (!e->inline_failed || !e->callee->analyzed\n-\t\t|| !DECL_EXTERNAL (e->callee->decl)))\n-\t  {\n-\t    e->callee->aux = first;\n-\t    first = e->callee;\n-\t  }\n-    }\n-\n-  /* Remove unreachable nodes.  Extern inline functions need special care;\n-     Unreachable extern inline functions shall be removed.\n-     Reachable extern inline functions we never inlined shall get their bodies\n-     eliminated.\n-     Reachable extern inline functions we sometimes inlined will be turned into\n-     unanalyzed nodes so they look like for true extern functions to the rest\n-     of code.  Body of such functions is released via remove_node once the\n-     inline clones are eliminated.  */\n-  for (node = cgraph_nodes; node; node = node->next)\n-    {\n-      if (!node->aux)\n-\t{\n-\t  int local_insns;\n-\t  tree decl = node->decl;\n-\n-          node->global.inlined_to = NULL;\n-\t  if (DECL_STRUCT_FUNCTION (decl))\n-\t    local_insns = node->local.self_insns;\n-\t  else\n-\t    local_insns = 0;\n-\t  if (cgraph_dump_file)\n-\t    fprintf (cgraph_dump_file, \" %s\", cgraph_node_name (node));\n-\t  if (!node->analyzed || !DECL_EXTERNAL (node->decl))\n-\t    cgraph_remove_node (node);\n-\t  else\n-\t    {\n-\t      struct cgraph_edge *e;\n-\n-\t      for (e = node->callers; e; e = e->next_caller)\n-\t\tif (e->caller->aux)\n-\t\t  break;\n-\t      if (e || node->needed)\n-\t\t{\n-\t\t  struct cgraph_node *clone;\n-\n-\t\t  for (clone = node->next_clone; clone;\n-\t\t       clone = clone->next_clone)\n-\t\t    if (clone->aux)\n-\t\t      break;\n-\t\t  if (!clone)\n-\t\t    {\n-\t\t      DECL_SAVED_TREE (node->decl) = NULL;\n-\t\t      DECL_STRUCT_FUNCTION (node->decl) = NULL;\n-\t\t      DECL_INITIAL (node->decl) = error_mark_node;\n-\t\t    }\n-\t\t  cgraph_node_remove_callees (node);\n-\t\t  node->analyzed = false;\n-\t\t}\n-\t      else\n-\t\tcgraph_remove_node (node);\n-\t    }\n-\t  if (!DECL_SAVED_TREE (decl))\n-\t    insns += local_insns;\n-\t  changed = true;\n-\t}\n-    }\n-  for (node = cgraph_nodes; node; node = node->next)\n-    node->aux = NULL;\n-  if (cgraph_dump_file)\n-    fprintf (cgraph_dump_file, \"\\nReclaimed %i insns\", insns);\n-  return changed;\n-}\n-\n-/* Estimate size of the function after inlining WHAT into TO.  */\n-\n-static int\n-cgraph_estimate_size_after_inlining (int times, struct cgraph_node *to,\n-\t\t\t\t     struct cgraph_node *what)\n-{\n-  tree fndecl = what->decl;\n-  tree arg;\n-  int call_insns = PARAM_VALUE (PARAM_INLINE_CALL_COST);\n-  for (arg = DECL_ARGUMENTS (fndecl); arg; arg = TREE_CHAIN (arg))\n-    call_insns += estimate_move_cost (TREE_TYPE (arg));\n-  return (what->global.insns - call_insns) * times + to->global.insns;\n-}\n-\n-/* Estimate the growth caused by inlining NODE into all callees.  */\n-\n-static int\n-cgraph_estimate_growth (struct cgraph_node *node)\n-{\n-  int growth = 0;\n-  struct cgraph_edge *e;\n-\n-  for (e = node->callers; e; e = e->next_caller)\n-    if (e->inline_failed)\n-      growth += (cgraph_estimate_size_after_inlining (1, e->caller, node)\n-\t\t - e->caller->global.insns);\n-\n-  /* ??? Wrong for self recursive functions or cases where we decide to not\n-     inline for different reasons, but it is not big deal as in that case\n-     we will keep the body around, but we will also avoid some inlining.  */\n-  if (!node->needed && !DECL_EXTERNAL (node->decl))\n-    growth -= node->global.insns;\n-\n-  return growth;\n-}\n-\n-/* E is expected to be an edge being inlined.  Clone destination node of\n-   the edge and redirect it to the new clone.\n-   DUPLICATE is used for bookkeeping on whether we are actually creating new\n-   clones or re-using node originally representing out-of-line function call.\n-   */\n-void\n-cgraph_clone_inlined_nodes (struct cgraph_edge *e, bool duplicate)\n-{\n-  struct cgraph_node *n;\n-\n-  /* We may eliminate the need for out-of-line copy to be output.  In that\n-     case just go ahead and re-use it.  */\n-  if (!e->callee->callers->next_caller\n-      && (!e->callee->needed || DECL_EXTERNAL (e->callee->decl))\n-      && duplicate\n-      && flag_unit_at_a_time)\n-    {\n-      gcc_assert (!e->callee->global.inlined_to);\n-      if (!DECL_EXTERNAL (e->callee->decl))\n-        overall_insns -= e->callee->global.insns, nfunctions_inlined++;\n-      duplicate = 0;\n-    }\n-   else if (duplicate)\n-    {\n-      n = cgraph_clone_node (e->callee);\n-      cgraph_redirect_edge_callee (e, n);\n-    }\n-\n-  if (e->caller->global.inlined_to)\n-    e->callee->global.inlined_to = e->caller->global.inlined_to;\n-  else\n-    e->callee->global.inlined_to = e->caller;\n-\n-  /* Recursively clone all bodies.  */\n-  for (e = e->callee->callees; e; e = e->next_callee)\n-    if (!e->inline_failed)\n-      cgraph_clone_inlined_nodes (e, duplicate);\n-}\n-\n-/* Mark edge E as inlined and update callgraph accordingly.  */\n-\n-void\n-cgraph_mark_inline_edge (struct cgraph_edge *e)\n-{\n-  int old_insns = 0, new_insns = 0;\n-  struct cgraph_node *to = NULL, *what;\n-\n-  gcc_assert (e->inline_failed);\n-  e->inline_failed = NULL;\n-\n-  if (!e->callee->global.inlined && flag_unit_at_a_time)\n-    DECL_POSSIBLY_INLINED (e->callee->decl) = true;\n-  e->callee->global.inlined = true;\n-\n-  cgraph_clone_inlined_nodes (e, true);\n-\n-  what = e->callee;\n-\n-  /* Now update size of caller and all functions caller is inlined into.  */\n-  for (;e && !e->inline_failed; e = e->caller->callers)\n-    {\n-      old_insns = e->caller->global.insns;\n-      new_insns = cgraph_estimate_size_after_inlining (1, e->caller,\n-\t\t\t\t\t\t       what);\n-      gcc_assert (new_insns >= 0);\n-      to = e->caller;\n-      to->global.insns = new_insns;\n-    }\n-  gcc_assert (what->global.inlined_to == to);\n-  if (new_insns > old_insns)\n-    overall_insns += new_insns - old_insns;\n-  ncalls_inlined++;\n-}\n-\n-/* Mark all calls of EDGE->CALLEE inlined into EDGE->CALLER.\n-   Return following unredirected edge in the list of callers\n-   of EDGE->CALLEE  */\n-\n-static struct cgraph_edge *\n-cgraph_mark_inline (struct cgraph_edge *edge)\n-{\n-  struct cgraph_node *to = edge->caller;\n-  struct cgraph_node *what = edge->callee;\n-  struct cgraph_edge *e, *next;\n-  int times = 0;\n-\n-  /* Look for all calls, mark them inline and clone recursively\n-     all inlined functions.  */\n-  for (e = what->callers; e; e = next)\n-    {\n-      next = e->next_caller;\n-      if (e->caller == to && e->inline_failed)\n-\t{\n-          cgraph_mark_inline_edge (e);\n-\t  if (e == edge)\n-\t    edge = next;\n-\t  times++;\n-\t}\n-    }\n-  gcc_assert (times);\n-  return edge;\n-}\n-\n-/* Return false when inlining WHAT into TO is not good idea\n-   as it would cause too large growth of function bodies.  */\n-\n-static bool\n-cgraph_check_inline_limits (struct cgraph_node *to, struct cgraph_node *what,\n-\t\t\t    const char **reason)\n-{\n-  int times = 0;\n-  struct cgraph_edge *e;\n-  int newsize;\n-  int limit;\n-\n-  if (to->global.inlined_to)\n-    to = to->global.inlined_to;\n-\n-  for (e = to->callees; e; e = e->next_callee)\n-    if (e->callee == what)\n-      times++;\n-\n-  /* When inlining large function body called once into small function,\n-     take the inlined function as base for limiting the growth.  */\n-  if (to->local.self_insns > what->local.self_insns)\n-    limit = to->local.self_insns;\n-  else\n-    limit = what->local.self_insns;\n-\n-  limit += limit * PARAM_VALUE (PARAM_LARGE_FUNCTION_GROWTH) / 100;\n-\n-  newsize = cgraph_estimate_size_after_inlining (times, to, what);\n-  if (newsize > PARAM_VALUE (PARAM_LARGE_FUNCTION_INSNS)\n-      && newsize > limit)\n-    {\n-      if (reason)\n-        *reason = N_(\"--param large-function-growth limit reached\");\n-      return false;\n-    }\n-  return true;\n-}\n-\n-/* Return true when function N is small enough to be inlined.  */\n-\n-static bool\n-cgraph_default_inline_p (struct cgraph_node *n)\n-{\n-  if (!DECL_INLINE (n->decl) || !DECL_SAVED_TREE (n->decl))\n-    return false;\n-  if (DECL_DECLARED_INLINE_P (n->decl))\n-    return n->global.insns < MAX_INLINE_INSNS_SINGLE;\n-  else\n-    return n->global.insns < MAX_INLINE_INSNS_AUTO;\n-}\n-\n-/* Return true when inlining WHAT would create recursive inlining.\n-   We call recursive inlining all cases where same function appears more than\n-   once in the single recursion nest path in the inline graph.  */\n-\n-static bool\n-cgraph_recursive_inlining_p (struct cgraph_node *to,\n-\t\t\t     struct cgraph_node *what,\n-\t\t\t     const char **reason)\n-{\n-  bool recursive;\n-  if (to->global.inlined_to)\n-    recursive = what->decl == to->global.inlined_to->decl;\n-  else\n-    recursive = what->decl == to->decl;\n-  /* Marking recursive function inline has sane semantic and thus we should\n-     not warn on it.  */\n-  if (recursive && reason)\n-    *reason = (what->local.disregard_inline_limits\n-\t       ? N_(\"recursive inlining\") : \"\");\n-  return recursive;\n-}\n-\n-/* Recompute heap nodes for each of callees.  */\n-static void\n-update_callee_keys (fibheap_t heap, struct fibnode **heap_node,\n-\t\t    struct cgraph_node *node)\n-{\n-  struct cgraph_edge *e;\n-\n-  for (e = node->callees; e; e = e->next_callee)\n-    if (e->inline_failed && heap_node[e->callee->uid])\n-      fibheap_replace_key (heap, heap_node[e->callee->uid],\n-\t\t\t   cgraph_estimate_growth (e->callee));\n-    else if (!e->inline_failed)\n-      update_callee_keys (heap, heap_node, e->callee);\n-}\n-\n-/* Enqueue all recursive calls from NODE into queue linked via aux pointers\n-   in between FIRST and LAST.  WHERE is used for bookkeeping while looking\n-   int calls inlined within NODE.  */\n-static void\n-lookup_recursive_calls (struct cgraph_node *node, struct cgraph_node *where,\n-\t\t\tstruct cgraph_edge **first, struct cgraph_edge **last)\n-{\n-  struct cgraph_edge *e;\n-  for (e = where->callees; e; e = e->next_callee)\n-    if (e->callee == node)\n-      {\n-\tif (!*first)\n-\t  *first = e;\n-\telse\n-\t  (*last)->aux = e;\n-\t*last = e;\n-      }\n-  for (e = where->callees; e; e = e->next_callee)\n-    if (!e->inline_failed)\n-      lookup_recursive_calls (node, e->callee, first, last);\n-}\n-\n-/* Decide on recursive inlining: in the case function has recursive calls,\n-   inline until body size reaches given argument.  */\n-static void\n-cgraph_decide_recursive_inlining (struct cgraph_node *node)\n-{\n-  int limit = PARAM_VALUE (PARAM_MAX_INLINE_INSNS_RECURSIVE_AUTO);\n-  int max_depth = PARAM_VALUE (PARAM_MAX_INLINE_RECURSIVE_DEPTH_AUTO);\n-  struct cgraph_edge *first_call = NULL, *last_call = NULL;\n-  struct cgraph_edge *last_in_current_depth;\n-  struct cgraph_edge *e;\n-  struct cgraph_node *master_clone;\n-  int depth = 0;\n-  int n = 0;\n-\n-  if (DECL_DECLARED_INLINE_P (node->decl))\n-    {\n-      limit = PARAM_VALUE (PARAM_MAX_INLINE_INSNS_RECURSIVE);\n-      max_depth = PARAM_VALUE (PARAM_MAX_INLINE_RECURSIVE_DEPTH);\n-    }\n-\n-  /* Make sure that function is small enough to be considered for inlining.  */\n-  if (!max_depth\n-      || cgraph_estimate_size_after_inlining (1, node, node)  >= limit)\n-    return;\n-  lookup_recursive_calls (node, node, &first_call, &last_call);\n-  if (!first_call)\n-    return;\n-\n-  if (dump_file)\n-    fprintf (dump_file, \n-\t     \"\\nPerforming recursive inlining on %s\\n\",\n-\t     cgraph_node_name (node));\n-\n-  /* We need original clone to copy around.  */\n-  master_clone = cgraph_clone_node (node);\n-  master_clone->needed = true;\n-  for (e = master_clone->callees; e; e = e->next_callee)\n-    if (!e->inline_failed)\n-      cgraph_clone_inlined_nodes (e, true);\n-\n-  /* Do the inlining and update list of recursive call during process.  */\n-  last_in_current_depth = last_call;\n-  while (first_call\n-\t && cgraph_estimate_size_after_inlining (1, node, master_clone) <= limit)\n-    {\n-      struct cgraph_edge *curr = first_call;\n-\n-      first_call = first_call->aux;\n-      curr->aux = NULL;\n-\n-      cgraph_redirect_edge_callee (curr, master_clone);\n-      cgraph_mark_inline_edge (curr);\n-      lookup_recursive_calls (node, curr->callee, &first_call, &last_call);\n-\n-      if (last_in_current_depth\n-\t  && ++depth >= max_depth)\n-\tbreak;\n-      n++;\n-    }\n-\n-  /* Cleanup queue pointers.  */\n-  while (first_call)\n-    {\n-      struct cgraph_edge *next = first_call->aux;\n-      first_call->aux = NULL;\n-      first_call = next;\n-    }\n-  if (dump_file)\n-    fprintf (dump_file, \n-\t     \"\\n   Inlined %i times, body grown from %i to %i insns\\n\", n,\n-\t     master_clone->global.insns, node->global.insns);\n-\n-  /* Remove master clone we used for inlining.  We rely that clones inlined\n-     into master clone gets queued just before master clone so we don't\n-     need recursion.  */\n-  for (node = cgraph_nodes; node != master_clone;\n-       node = node->next)\n-    if (node->global.inlined_to == master_clone)\n-      cgraph_remove_node (node);\n-  cgraph_remove_node (master_clone);\n-}\n-\n-/* Set inline_failed for all callers of given function to REASON.  */\n-\n-static void\n-cgraph_set_inline_failed (struct cgraph_node *node, const char *reason)\n-{\n-  struct cgraph_edge *e;\n-\n-  if (dump_file)\n-    fprintf (dump_file, \"Inlining failed: %s\\n\", reason);\n-  for (e = node->callers; e; e = e->next_caller)\n-    if (e->inline_failed)\n-      e->inline_failed = reason;\n-}\n-\n-/* We use greedy algorithm for inlining of small functions:\n-   All inline candidates are put into prioritized heap based on estimated\n-   growth of the overall number of instructions and then update the estimates.\n-\n-   INLINED and INLINED_CALEES are just pointers to arrays large enough\n-   to be passed to cgraph_inlined_into and cgraph_inlined_callees.  */\n-\n-static void\n-cgraph_decide_inlining_of_small_functions (void)\n-{\n-  struct cgraph_node *node;\n-  fibheap_t heap = fibheap_new ();\n-  struct fibnode **heap_node =\n-    xcalloc (cgraph_max_uid, sizeof (struct fibnode *));\n-  int max_insns = ((HOST_WIDEST_INT) initial_insns\n-\t\t   * (100 + PARAM_VALUE (PARAM_INLINE_UNIT_GROWTH)) / 100);\n-\n-  /* Put all inline candidates into the heap.  */\n-\n-  for (node = cgraph_nodes; node; node = node->next)\n-    {\n-      if (!node->local.inlinable || !node->callers\n-\t  || node->local.disregard_inline_limits)\n-\tcontinue;\n-\n-      if (!cgraph_default_inline_p (node))\n-\t{\n-\t  cgraph_set_inline_failed (node,\n-\t    N_(\"--param max-inline-insns-single limit reached\"));\n-\t  continue;\n-\t}\n-      heap_node[node->uid] =\n-\tfibheap_insert (heap, cgraph_estimate_growth (node), node);\n-    }\n-\n-  if (dump_file)\n-    fprintf (dump_file, \"\\nDeciding on smaller functions:\\n\");\n-  while (overall_insns <= max_insns && (node = fibheap_extract_min (heap)))\n-    {\n-      struct cgraph_edge *e, *next;\n-      int old_insns = overall_insns;\n-\n-      heap_node[node->uid] = NULL;\n-      if (dump_file)\n-\tfprintf (dump_file, \n-\t\t \"\\nConsidering %s with %i insns\\n\"\n-\t\t \" Estimated growth is %+i insns.\\n\",\n-\t\t cgraph_node_name (node), node->global.insns,\n-\t\t cgraph_estimate_growth (node));\n-      if (!cgraph_default_inline_p (node))\n-\t{\n-\t  cgraph_set_inline_failed (node,\n-\t    N_(\"--param max-inline-insns-single limit reached after inlining into the callee\"));\n-\t  continue;\n-\t}\n-      for (e = node->callers; e; e = next)\n-\t{\n-\t  next = e->next_caller;\n-\t  if (e->inline_failed)\n-\t    {\n-\t      struct cgraph_node *where;\n-\n-\t      if (cgraph_recursive_inlining_p (e->caller, e->callee,\n-\t\t\t\t      \t       &e->inline_failed)\n-\t\t  || !cgraph_check_inline_limits (e->caller, e->callee,\n-\t\t\t  \t\t\t  &e->inline_failed))\n-\t\t{\n-\t\t  if (dump_file)\n-\t\t    fprintf (dump_file, \" Not inlining into %s:%s.\\n\",\n-\t\t\t     cgraph_node_name (e->caller), e->inline_failed);\n-\t\t  continue;\n-\t\t}\n-\t      next = cgraph_mark_inline (e);\n-\t      where = e->caller;\n-\t      if (where->global.inlined_to)\n-\t\twhere = where->global.inlined_to;\n-\n-\t      if (heap_node[where->uid])\n-\t\tfibheap_replace_key (heap, heap_node[where->uid],\n-\t\t\t\t     cgraph_estimate_growth (where));\n-\n-\t      if (dump_file)\n-\t\tfprintf (dump_file, \n-\t\t\t \" Inlined into %s which now has %i insns.\\n\",\n-\t\t\t cgraph_node_name (e->caller),\n-\t\t\t e->caller->global.insns);\n-\t    }\n-\t}\n-\n-      cgraph_decide_recursive_inlining (node);\n-\n-      /* Similarly all functions called by the function we just inlined\n-         are now called more times; update keys.  */\n-      update_callee_keys (heap, heap_node, node);\n-\n-      if (dump_file)\n-\tfprintf (dump_file, \n-\t\t \" Inlined for a net change of %+i insns.\\n\",\n-\t\t overall_insns - old_insns);\n-    }\n-  while ((node = fibheap_extract_min (heap)) != NULL)\n-    if (!node->local.disregard_inline_limits)\n-      cgraph_set_inline_failed (node, N_(\"--param inline-unit-growth limit reached\"));\n-  fibheap_delete (heap);\n-  free (heap_node);\n-}\n-\n-/* Decide on the inlining.  We do so in the topological order to avoid\n-   expenses on updating data structures.  */\n-\n-static void\n-cgraph_decide_inlining (void)\n-{\n-  struct cgraph_node *node;\n-  int nnodes;\n-  struct cgraph_node **order =\n-    xcalloc (cgraph_n_nodes, sizeof (struct cgraph_node *));\n-  int old_insns = 0;\n-  int i;\n-\n-  for (node = cgraph_nodes; node; node = node->next)\n-    initial_insns += node->local.self_insns;\n-  overall_insns = initial_insns;\n-\n-  nnodes = cgraph_postorder (order);\n-\n-  if (dump_file)\n-    fprintf (dump_file,\n-\t     \"\\nDeciding on inlining.  Starting with %i insns.\\n\",\n-\t     initial_insns);\n-\n-  for (node = cgraph_nodes; node; node = node->next)\n-    node->aux = 0;\n-\n-  if (dump_file)\n-    fprintf (dump_file, \"\\nInlining always_inline functions:\\n\");\n-\n-  /* In the first pass mark all always_inline edges.  Do this with a priority\n-     so none of our later choices will make this impossible.  */\n-  for (i = nnodes - 1; i >= 0; i--)\n-    {\n-      struct cgraph_edge *e, *next;\n-\n-      node = order[i];\n-\n-      if (!node->local.disregard_inline_limits)\n-\tcontinue;\n-      if (dump_file)\n-\tfprintf (dump_file,\n-\t\t \"\\nConsidering %s %i insns (always inline)\\n\",\n-\t\t cgraph_node_name (node), node->global.insns);\n-      old_insns = overall_insns;\n-      for (e = node->callers; e; e = next)\n-\t{\n-\t  next = e->next_caller;\n-\t  if (!e->inline_failed)\n-\t    continue;\n-\t  if (cgraph_recursive_inlining_p (e->caller, e->callee,\n-\t\t\t\t  \t   &e->inline_failed))\n-\t    continue;\n-\t  cgraph_mark_inline_edge (e);\n-\t  if (dump_file)\n-\t    fprintf (dump_file, \n-\t\t     \" Inlined into %s which now has %i insns.\\n\",\n-\t\t     cgraph_node_name (e->caller),\n-\t\t     e->caller->global.insns);\n-\t}\n-      if (dump_file)\n-\tfprintf (dump_file, \n-\t\t \" Inlined for a net change of %+i insns.\\n\",\n-\t\t overall_insns - old_insns);\n-    }\n-\n-  if (!flag_really_no_inline)\n-    {\n-      cgraph_decide_inlining_of_small_functions ();\n-\n-      if (dump_file)\n-\tfprintf (dump_file, \"\\nDeciding on functions called once:\\n\");\n-\n-      /* And finally decide what functions are called once.  */\n-\n-      for (i = nnodes - 1; i >= 0; i--)\n-\t{\n-\t  node = order[i];\n-\n-\t  if (node->callers && !node->callers->next_caller && !node->needed\n-\t      && node->local.inlinable && node->callers->inline_failed\n-\t      && !DECL_EXTERNAL (node->decl) && !DECL_COMDAT (node->decl))\n-\t    {\n-\t      bool ok = true;\n-\t      struct cgraph_node *node1;\n-\n-\t      /* Verify that we won't duplicate the caller.  */\n-\t      for (node1 = node->callers->caller;\n-\t\t   node1->callers && !node1->callers->inline_failed\n-\t\t   && ok; node1 = node1->callers->caller)\n-\t\tif (node1->callers->next_caller || node1->needed)\n-\t\t  ok = false;\n-\t      if (ok)\n-\t\t{\n-\t\t  if (dump_file)\n-\t\t    fprintf (dump_file,\n-\t\t\t     \"\\nConsidering %s %i insns.\\n\"\n-\t\t\t     \" Called once from %s %i insns.\\n\",\n-\t\t\t     cgraph_node_name (node), node->global.insns,\n-\t\t\t     cgraph_node_name (node->callers->caller),\n-\t\t\t     node->callers->caller->global.insns);\n-\n-\t\t  old_insns = overall_insns;\n-\n-\t\t  if (cgraph_check_inline_limits (node->callers->caller, node,\n-\t\t\t\t\t  \t  NULL))\n-\t\t    {\n-\t\t      cgraph_mark_inline (node->callers);\n-\t\t      if (dump_file)\n-\t\t\tfprintf (dump_file,\n-\t\t\t\t \" Inlined into %s which now has %i insns\"\n-\t\t\t\t \" for a net change of %+i insns.\\n\",\n-\t\t\t\t cgraph_node_name (node->callers->caller),\n-\t\t\t\t node->callers->caller->global.insns,\n-\t\t\t\t overall_insns - old_insns);\n-\t\t    }\n-\t\t  else\n-\t\t    {\n-\t\t      if (dump_file)\n-\t\t\tfprintf (dump_file,\n-\t\t\t\t \" Inline limit reached, not inlined.\\n\");\n-\t\t    }\n-\t\t}\n-\t    }\n-\t}\n-    }\n-\n-  /* We will never output extern functions we didn't inline. \n-     ??? Perhaps we can prevent accounting of growth of external\n-     inline functions.  */\n-  cgraph_remove_unreachable_nodes ();\n-\n-  if (dump_file)\n-    fprintf (dump_file,\n-\t     \"\\nInlined %i calls, eliminated %i functions, \"\n-\t     \"%i insns turned to %i insns.\\n\\n\",\n-\t     ncalls_inlined, nfunctions_inlined, initial_insns,\n-\t     overall_insns);\n-  free (order);\n-}\n-\n-/* Decide on the inlining.  We do so in the topological order to avoid\n-   expenses on updating data structures.  */\n-\n-static void\n-cgraph_decide_inlining_incrementally (struct cgraph_node *node)\n-{\n-  struct cgraph_edge *e;\n-\n-  /* First of all look for always inline functions.  */\n-  for (e = node->callees; e; e = e->next_callee)\n-    if (e->callee->local.disregard_inline_limits\n-\t&& e->inline_failed\n-        && !cgraph_recursive_inlining_p (node, e->callee, &e->inline_failed)\n-\t/* ??? It is possible that renaming variable removed the function body\n-\t   in duplicate_decls. See gcc.c-torture/compile/20011119-2.c  */\n-\t&& DECL_SAVED_TREE (e->callee->decl))\n-      cgraph_mark_inline (e);\n-\n-  /* Now do the automatic inlining.  */\n-  if (!flag_really_no_inline)\n-    for (e = node->callees; e; e = e->next_callee)\n-      if (e->callee->local.inlinable\n-\t  && e->inline_failed\n-\t  && !e->callee->local.disregard_inline_limits\n-\t  && !cgraph_recursive_inlining_p (node, e->callee, &e->inline_failed)\n-\t  && cgraph_check_inline_limits (node, e->callee, &e->inline_failed)\n-\t  && DECL_SAVED_TREE (e->callee->decl))\n-\t{\n-\t  if (cgraph_default_inline_p (e->callee))\n-\t    cgraph_mark_inline (e);\n-\t  else\n-\t    e->inline_failed\n-\t      = N_(\"--param max-inline-insns-single limit reached\");\n-\t}\n-}\n-\n-\n /* Return true when CALLER_DECL should be inlined into CALLEE_DECL.  */\n \n bool\n@@ -2014,27 +1199,3 @@ init_cgraph (void)\n {\n   cgraph_dump_file = dump_begin (TDI_cgraph, NULL);\n }\n-\n-/* When inlining shall be performed.  */\n-static bool\n-cgraph_gate_inlining (void)\n-{\n-  return flag_inline_trees;\n-}\n-\n-struct tree_opt_pass pass_ipa_inline = \n-{\n-  \"inline\",\t\t\t\t/* name */\n-  cgraph_gate_inlining,\t\t\t/* gate */\n-  cgraph_decide_inlining,\t\t/* execute */\n-  NULL,\t\t\t\t\t/* sub */\n-  NULL,\t\t\t\t\t/* next */\n-  0,\t\t\t\t\t/* static_pass_number */\n-  TV_INTEGRATION,\t\t\t/* tv_id */\n-  0,\t                                /* properties_required */\n-  PROP_trees,\t\t\t\t/* properties_provided */\n-  0,\t\t\t\t\t/* properties_destroyed */\n-  0,\t\t\t\t\t/* todo_flags_start */\n-  TODO_dump_cgraph | TODO_dump_func,\t/* todo_flags_finish */\n-  0\t\t\t\t\t/* letter */\n-};"}, {"sha": "b70a1f764c51ae93cfb82f304da190230d05ebcc", "filename": "gcc/except.c", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fexcept.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fexcept.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexcept.c?ref=ca31b95fa3f967fce4ea405dc56ed26182270209", "patch": "@@ -177,14 +177,12 @@ struct eh_region GTY(())\n     /* Retain the cleanup expression even after expansion so that\n        we can match up fixup regions.  */\n     struct eh_region_u_cleanup {\n-      tree exp;\n       struct eh_region *prev_try;\n     } GTY ((tag (\"ERT_CLEANUP\"))) cleanup;\n \n     /* The real region (by expression and by pointer) that fixup code\n        should live in.  */\n     struct eh_region_u_fixup {\n-      tree cleanup_exp;\n       struct eh_region *real_region;\n       bool resolved;\n     } GTY ((tag (\"ERT_FIXUP\"))) fixup;"}, {"sha": "ad9e998bfe22052433a740761f461e409ea7d85d", "filename": "gcc/ipa-inline.c", "status": "added", "additions": 740, "deletions": 0, "changes": 740, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fipa-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fipa-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-inline.c?ref=ca31b95fa3f967fce4ea405dc56ed26182270209", "patch": "@@ -0,0 +1,740 @@\n+/* Inlining decision heuristics.\n+   Copyright (C) 2003, 2004 Free Software Foundation, Inc.\n+   Contributed by Jan Hubicka\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+/*  Inlining decision heuristics\n+\n+    We separate inlining decisions from the inliner itself and store it\n+    inside callgraph as so called inline plan.  Refer to cgraph.c\n+    documentation about particular representation of inline plans in the\n+    callgraph.\n+\n+    There are three major parts of this file:\n+\n+    cgraph_mark_inline implementation\n+\n+      This function allow to mark given call inline and performs neccesary\n+      modifications of cgraph (production of the clones and updating overall\n+      statistics)\n+\n+    inlining heuristics limits\n+\n+      These functions allow to check that particular inlining is allowed\n+      by the limits specified by user (allowed function growth, overall unit\n+      growth and so on).\n+\n+    inlining heuristics\n+\n+      This is implementation of IPA pass aiming to get as much of benefit\n+      from inlining obeying the limits checked above.\n+\n+      The implementation of particular heuristics is separated from\n+      the rest of code to make it easier to replace it with more complicated\n+      implementation in the future.  The rest of inlining code acts as a\n+      library aimed to modify the callgraph and verify that the parameters\n+      on code size growth fits.\n+\n+      To mark given call inline, use cgraph_mark_inline function, the\n+      verification is performed by cgraph_default_inline_p and\n+      cgraph_check_inline_limits.\n+\n+      The heuristics implements simple knapsack style algorithm ordering\n+      all functions by their \"profitability\" (estimated by code size growth)\n+      and inlining them in priority order.\n+\n+      cgraph_decide_inlining implements heuristics taking whole callgraph\n+      into account, while cgraph_decide_inlining_incrementally considers\n+      only one function at a time and is used in non-unit-at-a-time mode.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"tree.h\"\n+#include \"tree-inline.h\"\n+#include \"langhooks.h\"\n+#include \"flags.h\"\n+#include \"cgraph.h\"\n+#include \"diagnostic.h\"\n+#include \"timevar.h\"\n+#include \"params.h\"\n+#include \"fibheap.h\"\n+#include \"intl.h\"\n+#include \"tree-pass.h\"\n+\n+/* Statistics we collect about inlining algorithm.  */\n+static int ncalls_inlined;\n+static int nfunctions_inlined;\n+static int initial_insns;\n+static int overall_insns;\n+\n+/* Estimate size of the function after inlining WHAT into TO.  */\n+\n+static int\n+cgraph_estimate_size_after_inlining (int times, struct cgraph_node *to,\n+\t\t\t\t     struct cgraph_node *what)\n+{\n+  tree fndecl = what->decl;\n+  tree arg;\n+  int call_insns = PARAM_VALUE (PARAM_INLINE_CALL_COST);\n+  for (arg = DECL_ARGUMENTS (fndecl); arg; arg = TREE_CHAIN (arg))\n+    call_insns += estimate_move_cost (TREE_TYPE (arg));\n+  return (what->global.insns - call_insns) * times + to->global.insns;\n+}\n+\n+/* E is expected to be an edge being inlined.  Clone destination node of\n+   the edge and redirect it to the new clone.\n+   DUPLICATE is used for bookkeeping on whether we are actually creating new\n+   clones or re-using node originally representing out-of-line function call.\n+   */\n+void\n+cgraph_clone_inlined_nodes (struct cgraph_edge *e, bool duplicate)\n+{\n+  struct cgraph_node *n;\n+\n+  /* We may eliminate the need for out-of-line copy to be output.  In that\n+     case just go ahead and re-use it.  */\n+  if (!e->callee->callers->next_caller\n+      && (!e->callee->needed || DECL_EXTERNAL (e->callee->decl))\n+      && duplicate\n+      && flag_unit_at_a_time)\n+    {\n+      gcc_assert (!e->callee->global.inlined_to);\n+      if (!DECL_EXTERNAL (e->callee->decl))\n+        overall_insns -= e->callee->global.insns, nfunctions_inlined++;\n+      duplicate = 0;\n+    }\n+   else if (duplicate)\n+    {\n+      n = cgraph_clone_node (e->callee);\n+      cgraph_redirect_edge_callee (e, n);\n+    }\n+\n+  if (e->caller->global.inlined_to)\n+    e->callee->global.inlined_to = e->caller->global.inlined_to;\n+  else\n+    e->callee->global.inlined_to = e->caller;\n+\n+  /* Recursively clone all bodies.  */\n+  for (e = e->callee->callees; e; e = e->next_callee)\n+    if (!e->inline_failed)\n+      cgraph_clone_inlined_nodes (e, duplicate);\n+}\n+\n+/* Mark edge E as inlined and update callgraph accordingly.  */\n+\n+void\n+cgraph_mark_inline_edge (struct cgraph_edge *e)\n+{\n+  int old_insns = 0, new_insns = 0;\n+  struct cgraph_node *to = NULL, *what;\n+\n+  gcc_assert (e->inline_failed);\n+  e->inline_failed = NULL;\n+\n+  if (!e->callee->global.inlined && flag_unit_at_a_time)\n+    DECL_POSSIBLY_INLINED (e->callee->decl) = true;\n+  e->callee->global.inlined = true;\n+\n+  cgraph_clone_inlined_nodes (e, true);\n+\n+  what = e->callee;\n+\n+  /* Now update size of caller and all functions caller is inlined into.  */\n+  for (;e && !e->inline_failed; e = e->caller->callers)\n+    {\n+      old_insns = e->caller->global.insns;\n+      new_insns = cgraph_estimate_size_after_inlining (1, e->caller,\n+\t\t\t\t\t\t       what);\n+      gcc_assert (new_insns >= 0);\n+      to = e->caller;\n+      to->global.insns = new_insns;\n+    }\n+  gcc_assert (what->global.inlined_to == to);\n+  if (new_insns > old_insns)\n+    overall_insns += new_insns - old_insns;\n+  ncalls_inlined++;\n+}\n+\n+/* Mark all calls of EDGE->CALLEE inlined into EDGE->CALLER.\n+   Return following unredirected edge in the list of callers\n+   of EDGE->CALLEE  */\n+\n+static struct cgraph_edge *\n+cgraph_mark_inline (struct cgraph_edge *edge)\n+{\n+  struct cgraph_node *to = edge->caller;\n+  struct cgraph_node *what = edge->callee;\n+  struct cgraph_edge *e, *next;\n+  int times = 0;\n+\n+  /* Look for all calls, mark them inline and clone recursively\n+     all inlined functions.  */\n+  for (e = what->callers; e; e = next)\n+    {\n+      next = e->next_caller;\n+      if (e->caller == to && e->inline_failed)\n+\t{\n+          cgraph_mark_inline_edge (e);\n+\t  if (e == edge)\n+\t    edge = next;\n+\t  times++;\n+\t}\n+    }\n+  gcc_assert (times);\n+  return edge;\n+}\n+\n+/* Estimate the growth caused by inlining NODE into all callees.  */\n+\n+static int\n+cgraph_estimate_growth (struct cgraph_node *node)\n+{\n+  int growth = 0;\n+  struct cgraph_edge *e;\n+\n+  for (e = node->callers; e; e = e->next_caller)\n+    if (e->inline_failed)\n+      growth += (cgraph_estimate_size_after_inlining (1, e->caller, node)\n+\t\t - e->caller->global.insns);\n+\n+  /* ??? Wrong for self recursive functions or cases where we decide to not\n+     inline for different reasons, but it is not big deal as in that case\n+     we will keep the body around, but we will also avoid some inlining.  */\n+  if (!node->needed && !DECL_EXTERNAL (node->decl))\n+    growth -= node->global.insns;\n+\n+  return growth;\n+}\n+\n+/* Return false when inlining WHAT into TO is not good idea\n+   as it would cause too large growth of function bodies.  */\n+\n+static bool\n+cgraph_check_inline_limits (struct cgraph_node *to, struct cgraph_node *what,\n+\t\t\t    const char **reason)\n+{\n+  int times = 0;\n+  struct cgraph_edge *e;\n+  int newsize;\n+  int limit;\n+\n+  if (to->global.inlined_to)\n+    to = to->global.inlined_to;\n+\n+  for (e = to->callees; e; e = e->next_callee)\n+    if (e->callee == what)\n+      times++;\n+\n+  /* When inlining large function body called once into small function,\n+     take the inlined function as base for limiting the growth.  */\n+  if (to->local.self_insns > what->local.self_insns)\n+    limit = to->local.self_insns;\n+  else\n+    limit = what->local.self_insns;\n+\n+  limit += limit * PARAM_VALUE (PARAM_LARGE_FUNCTION_GROWTH) / 100;\n+\n+  newsize = cgraph_estimate_size_after_inlining (times, to, what);\n+  if (newsize > PARAM_VALUE (PARAM_LARGE_FUNCTION_INSNS)\n+      && newsize > limit)\n+    {\n+      if (reason)\n+        *reason = N_(\"--param large-function-growth limit reached\");\n+      return false;\n+    }\n+  return true;\n+}\n+\n+/* Return true when function N is small enough to be inlined.  */\n+\n+bool\n+cgraph_default_inline_p (struct cgraph_node *n)\n+{\n+  if (!DECL_INLINE (n->decl) || !DECL_SAVED_TREE (n->decl))\n+    return false;\n+  if (DECL_DECLARED_INLINE_P (n->decl))\n+    return n->global.insns < MAX_INLINE_INSNS_SINGLE;\n+  else\n+    return n->global.insns < MAX_INLINE_INSNS_AUTO;\n+}\n+\n+/* Return true when inlining WHAT would create recursive inlining.\n+   We call recursive inlining all cases where same function appears more than\n+   once in the single recursion nest path in the inline graph.  */\n+\n+static bool\n+cgraph_recursive_inlining_p (struct cgraph_node *to,\n+\t\t\t     struct cgraph_node *what,\n+\t\t\t     const char **reason)\n+{\n+  bool recursive;\n+  if (to->global.inlined_to)\n+    recursive = what->decl == to->global.inlined_to->decl;\n+  else\n+    recursive = what->decl == to->decl;\n+  /* Marking recursive function inline has sane semantic and thus we should\n+     not warn on it.  */\n+  if (recursive && reason)\n+    *reason = (what->local.disregard_inline_limits\n+\t       ? N_(\"recursive inlining\") : \"\");\n+  return recursive;\n+}\n+\n+/* Recompute heap nodes for each of callees.  */\n+static void\n+update_callee_keys (fibheap_t heap, struct fibnode **heap_node,\n+\t\t    struct cgraph_node *node)\n+{\n+  struct cgraph_edge *e;\n+\n+  for (e = node->callees; e; e = e->next_callee)\n+    if (e->inline_failed && heap_node[e->callee->uid])\n+      fibheap_replace_key (heap, heap_node[e->callee->uid],\n+\t\t\t   cgraph_estimate_growth (e->callee));\n+    else if (!e->inline_failed)\n+      update_callee_keys (heap, heap_node, e->callee);\n+}\n+\n+/* Enqueue all recursive calls from NODE into queue linked via aux pointers\n+   in between FIRST and LAST.  WHERE is used for bookkeeping while looking\n+   int calls inlined within NODE.  */\n+static void\n+lookup_recursive_calls (struct cgraph_node *node, struct cgraph_node *where,\n+\t\t\tstruct cgraph_edge **first, struct cgraph_edge **last)\n+{\n+  struct cgraph_edge *e;\n+  for (e = where->callees; e; e = e->next_callee)\n+    if (e->callee == node)\n+      {\n+\tif (!*first)\n+\t  *first = e;\n+\telse\n+\t  (*last)->aux = e;\n+\t*last = e;\n+      }\n+  for (e = where->callees; e; e = e->next_callee)\n+    if (!e->inline_failed)\n+      lookup_recursive_calls (node, e->callee, first, last);\n+}\n+\n+/* Decide on recursive inlining: in the case function has recursive calls,\n+   inline until body size reaches given argument.  */\n+static void\n+cgraph_decide_recursive_inlining (struct cgraph_node *node)\n+{\n+  int limit = PARAM_VALUE (PARAM_MAX_INLINE_INSNS_RECURSIVE_AUTO);\n+  int max_depth = PARAM_VALUE (PARAM_MAX_INLINE_RECURSIVE_DEPTH_AUTO);\n+  struct cgraph_edge *first_call = NULL, *last_call = NULL;\n+  struct cgraph_edge *last_in_current_depth;\n+  struct cgraph_edge *e;\n+  struct cgraph_node *master_clone;\n+  int depth = 0;\n+  int n = 0;\n+\n+  if (DECL_DECLARED_INLINE_P (node->decl))\n+    {\n+      limit = PARAM_VALUE (PARAM_MAX_INLINE_INSNS_RECURSIVE);\n+      max_depth = PARAM_VALUE (PARAM_MAX_INLINE_RECURSIVE_DEPTH);\n+    }\n+\n+  /* Make sure that function is small enough to be considered for inlining.  */\n+  if (!max_depth\n+      || cgraph_estimate_size_after_inlining (1, node, node)  >= limit)\n+    return;\n+  lookup_recursive_calls (node, node, &first_call, &last_call);\n+  if (!first_call)\n+    return;\n+\n+  if (dump_file)\n+    fprintf (dump_file, \n+\t     \"\\nPerforming recursive inlining on %s\\n\",\n+\t     cgraph_node_name (node));\n+\n+  /* We need original clone to copy around.  */\n+  master_clone = cgraph_clone_node (node);\n+  master_clone->needed = true;\n+  for (e = master_clone->callees; e; e = e->next_callee)\n+    if (!e->inline_failed)\n+      cgraph_clone_inlined_nodes (e, true);\n+\n+  /* Do the inlining and update list of recursive call during process.  */\n+  last_in_current_depth = last_call;\n+  while (first_call\n+\t && cgraph_estimate_size_after_inlining (1, node, master_clone) <= limit)\n+    {\n+      struct cgraph_edge *curr = first_call;\n+\n+      first_call = first_call->aux;\n+      curr->aux = NULL;\n+\n+      cgraph_redirect_edge_callee (curr, master_clone);\n+      cgraph_mark_inline_edge (curr);\n+      lookup_recursive_calls (node, curr->callee, &first_call, &last_call);\n+\n+      if (last_in_current_depth\n+\t  && ++depth >= max_depth)\n+\tbreak;\n+      n++;\n+    }\n+\n+  /* Cleanup queue pointers.  */\n+  while (first_call)\n+    {\n+      struct cgraph_edge *next = first_call->aux;\n+      first_call->aux = NULL;\n+      first_call = next;\n+    }\n+  if (dump_file)\n+    fprintf (dump_file, \n+\t     \"\\n   Inlined %i times, body grown from %i to %i insns\\n\", n,\n+\t     master_clone->global.insns, node->global.insns);\n+\n+  /* Remove master clone we used for inlining.  We rely that clones inlined\n+     into master clone gets queued just before master clone so we don't\n+     need recursion.  */\n+  for (node = cgraph_nodes; node != master_clone;\n+       node = node->next)\n+    if (node->global.inlined_to == master_clone)\n+      cgraph_remove_node (node);\n+  cgraph_remove_node (master_clone);\n+}\n+\n+/* Set inline_failed for all callers of given function to REASON.  */\n+\n+static void\n+cgraph_set_inline_failed (struct cgraph_node *node, const char *reason)\n+{\n+  struct cgraph_edge *e;\n+\n+  if (dump_file)\n+    fprintf (dump_file, \"Inlining failed: %s\\n\", reason);\n+  for (e = node->callers; e; e = e->next_caller)\n+    if (e->inline_failed)\n+      e->inline_failed = reason;\n+}\n+\n+/* We use greedy algorithm for inlining of small functions:\n+   All inline candidates are put into prioritized heap based on estimated\n+   growth of the overall number of instructions and then update the estimates.\n+\n+   INLINED and INLINED_CALEES are just pointers to arrays large enough\n+   to be passed to cgraph_inlined_into and cgraph_inlined_callees.  */\n+\n+static void\n+cgraph_decide_inlining_of_small_functions (void)\n+{\n+  struct cgraph_node *node;\n+  fibheap_t heap = fibheap_new ();\n+  struct fibnode **heap_node =\n+    xcalloc (cgraph_max_uid, sizeof (struct fibnode *));\n+  int max_insns = ((HOST_WIDEST_INT) initial_insns\n+\t\t   * (100 + PARAM_VALUE (PARAM_INLINE_UNIT_GROWTH)) / 100);\n+\n+  /* Put all inline candidates into the heap.  */\n+\n+  for (node = cgraph_nodes; node; node = node->next)\n+    {\n+      if (!node->local.inlinable || !node->callers\n+\t  || node->local.disregard_inline_limits)\n+\tcontinue;\n+\n+      if (!cgraph_default_inline_p (node))\n+\t{\n+\t  cgraph_set_inline_failed (node,\n+\t    N_(\"--param max-inline-insns-single limit reached\"));\n+\t  continue;\n+\t}\n+      heap_node[node->uid] =\n+\tfibheap_insert (heap, cgraph_estimate_growth (node), node);\n+    }\n+\n+  if (dump_file)\n+    fprintf (dump_file, \"\\nDeciding on smaller functions:\\n\");\n+  while (overall_insns <= max_insns && (node = fibheap_extract_min (heap)))\n+    {\n+      struct cgraph_edge *e, *next;\n+      int old_insns = overall_insns;\n+\n+      heap_node[node->uid] = NULL;\n+      if (dump_file)\n+\tfprintf (dump_file, \n+\t\t \"\\nConsidering %s with %i insns\\n\"\n+\t\t \" Estimated growth is %+i insns.\\n\",\n+\t\t cgraph_node_name (node), node->global.insns,\n+\t\t cgraph_estimate_growth (node));\n+      if (!cgraph_default_inline_p (node))\n+\t{\n+\t  cgraph_set_inline_failed (node,\n+\t    N_(\"--param max-inline-insns-single limit reached after inlining into the callee\"));\n+\t  continue;\n+\t}\n+      for (e = node->callers; e; e = next)\n+\t{\n+\t  next = e->next_caller;\n+\t  if (e->inline_failed)\n+\t    {\n+\t      struct cgraph_node *where;\n+\n+\t      if (cgraph_recursive_inlining_p (e->caller, e->callee,\n+\t\t\t\t      \t       &e->inline_failed)\n+\t\t  || !cgraph_check_inline_limits (e->caller, e->callee,\n+\t\t\t  \t\t\t  &e->inline_failed))\n+\t\t{\n+\t\t  if (dump_file)\n+\t\t    fprintf (dump_file, \" Not inlining into %s:%s.\\n\",\n+\t\t\t     cgraph_node_name (e->caller), e->inline_failed);\n+\t\t  continue;\n+\t\t}\n+\t      next = cgraph_mark_inline (e);\n+\t      where = e->caller;\n+\t      if (where->global.inlined_to)\n+\t\twhere = where->global.inlined_to;\n+\n+\t      if (heap_node[where->uid])\n+\t\tfibheap_replace_key (heap, heap_node[where->uid],\n+\t\t\t\t     cgraph_estimate_growth (where));\n+\n+\t      if (dump_file)\n+\t\tfprintf (dump_file, \n+\t\t\t \" Inlined into %s which now has %i insns.\\n\",\n+\t\t\t cgraph_node_name (e->caller),\n+\t\t\t e->caller->global.insns);\n+\t    }\n+\t}\n+\n+      cgraph_decide_recursive_inlining (node);\n+\n+      /* Similarly all functions called by the function we just inlined\n+         are now called more times; update keys.  */\n+      update_callee_keys (heap, heap_node, node);\n+\n+      if (dump_file)\n+\tfprintf (dump_file, \n+\t\t \" Inlined for a net change of %+i insns.\\n\",\n+\t\t overall_insns - old_insns);\n+    }\n+  while ((node = fibheap_extract_min (heap)) != NULL)\n+    if (!node->local.disregard_inline_limits)\n+      cgraph_set_inline_failed (node, N_(\"--param inline-unit-growth limit reached\"));\n+  fibheap_delete (heap);\n+  free (heap_node);\n+}\n+\n+/* Decide on the inlining.  We do so in the topological order to avoid\n+   expenses on updating data structures.  */\n+\n+static void\n+cgraph_decide_inlining (void)\n+{\n+  struct cgraph_node *node;\n+  int nnodes;\n+  struct cgraph_node **order =\n+    xcalloc (cgraph_n_nodes, sizeof (struct cgraph_node *));\n+  int old_insns = 0;\n+  int i;\n+\n+  for (node = cgraph_nodes; node; node = node->next)\n+    initial_insns += node->local.self_insns;\n+  overall_insns = initial_insns;\n+\n+  nnodes = cgraph_postorder (order);\n+\n+  if (dump_file)\n+    fprintf (dump_file,\n+\t     \"\\nDeciding on inlining.  Starting with %i insns.\\n\",\n+\t     initial_insns);\n+\n+  for (node = cgraph_nodes; node; node = node->next)\n+    node->aux = 0;\n+\n+  if (dump_file)\n+    fprintf (dump_file, \"\\nInlining always_inline functions:\\n\");\n+\n+  /* In the first pass mark all always_inline edges.  Do this with a priority\n+     so none of our later choices will make this impossible.  */\n+  for (i = nnodes - 1; i >= 0; i--)\n+    {\n+      struct cgraph_edge *e, *next;\n+\n+      node = order[i];\n+\n+      if (!node->local.disregard_inline_limits)\n+\tcontinue;\n+      if (dump_file)\n+\tfprintf (dump_file,\n+\t\t \"\\nConsidering %s %i insns (always inline)\\n\",\n+\t\t cgraph_node_name (node), node->global.insns);\n+      old_insns = overall_insns;\n+      for (e = node->callers; e; e = next)\n+\t{\n+\t  next = e->next_caller;\n+\t  if (!e->inline_failed)\n+\t    continue;\n+\t  if (cgraph_recursive_inlining_p (e->caller, e->callee,\n+\t\t\t\t  \t   &e->inline_failed))\n+\t    continue;\n+\t  cgraph_mark_inline_edge (e);\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \n+\t\t     \" Inlined into %s which now has %i insns.\\n\",\n+\t\t     cgraph_node_name (e->caller),\n+\t\t     e->caller->global.insns);\n+\t}\n+      if (dump_file)\n+\tfprintf (dump_file, \n+\t\t \" Inlined for a net change of %+i insns.\\n\",\n+\t\t overall_insns - old_insns);\n+    }\n+\n+  if (!flag_really_no_inline)\n+    {\n+      cgraph_decide_inlining_of_small_functions ();\n+\n+      if (dump_file)\n+\tfprintf (dump_file, \"\\nDeciding on functions called once:\\n\");\n+\n+      /* And finally decide what functions are called once.  */\n+\n+      for (i = nnodes - 1; i >= 0; i--)\n+\t{\n+\t  node = order[i];\n+\n+\t  if (node->callers && !node->callers->next_caller && !node->needed\n+\t      && node->local.inlinable && node->callers->inline_failed\n+\t      && !DECL_EXTERNAL (node->decl) && !DECL_COMDAT (node->decl))\n+\t    {\n+\t      bool ok = true;\n+\t      struct cgraph_node *node1;\n+\n+\t      /* Verify that we won't duplicate the caller.  */\n+\t      for (node1 = node->callers->caller;\n+\t\t   node1->callers && !node1->callers->inline_failed\n+\t\t   && ok; node1 = node1->callers->caller)\n+\t\tif (node1->callers->next_caller || node1->needed)\n+\t\t  ok = false;\n+\t      if (ok)\n+\t\t{\n+\t\t  if (dump_file)\n+\t\t    fprintf (dump_file,\n+\t\t\t     \"\\nConsidering %s %i insns.\\n\"\n+\t\t\t     \" Called once from %s %i insns.\\n\",\n+\t\t\t     cgraph_node_name (node), node->global.insns,\n+\t\t\t     cgraph_node_name (node->callers->caller),\n+\t\t\t     node->callers->caller->global.insns);\n+\n+\t\t  old_insns = overall_insns;\n+\n+\t\t  if (cgraph_check_inline_limits (node->callers->caller, node,\n+\t\t\t\t\t  \t  NULL))\n+\t\t    {\n+\t\t      cgraph_mark_inline (node->callers);\n+\t\t      if (dump_file)\n+\t\t\tfprintf (dump_file,\n+\t\t\t\t \" Inlined into %s which now has %i insns\"\n+\t\t\t\t \" for a net change of %+i insns.\\n\",\n+\t\t\t\t cgraph_node_name (node->callers->caller),\n+\t\t\t\t node->callers->caller->global.insns,\n+\t\t\t\t overall_insns - old_insns);\n+\t\t    }\n+\t\t  else\n+\t\t    {\n+\t\t      if (dump_file)\n+\t\t\tfprintf (dump_file,\n+\t\t\t\t \" Inline limit reached, not inlined.\\n\");\n+\t\t    }\n+\t\t}\n+\t    }\n+\t}\n+    }\n+\n+  /* We will never output extern functions we didn't inline. \n+     ??? Perhaps we can prevent accounting of growth of external\n+     inline functions.  */\n+  cgraph_remove_unreachable_nodes (false, dump_file);\n+\n+  if (dump_file)\n+    fprintf (dump_file,\n+\t     \"\\nInlined %i calls, eliminated %i functions, \"\n+\t     \"%i insns turned to %i insns.\\n\\n\",\n+\t     ncalls_inlined, nfunctions_inlined, initial_insns,\n+\t     overall_insns);\n+  free (order);\n+}\n+\n+/* Decide on the inlining.  We do so in the topological order to avoid\n+   expenses on updating data structures.  */\n+\n+void\n+cgraph_decide_inlining_incrementally (struct cgraph_node *node)\n+{\n+  struct cgraph_edge *e;\n+\n+  /* First of all look for always inline functions.  */\n+  for (e = node->callees; e; e = e->next_callee)\n+    if (e->callee->local.disregard_inline_limits\n+\t&& e->inline_failed\n+        && !cgraph_recursive_inlining_p (node, e->callee, &e->inline_failed)\n+\t/* ??? It is possible that renaming variable removed the function body\n+\t   in duplicate_decls. See gcc.c-torture/compile/20011119-2.c  */\n+\t&& DECL_SAVED_TREE (e->callee->decl))\n+      cgraph_mark_inline (e);\n+\n+  /* Now do the automatic inlining.  */\n+  if (!flag_really_no_inline)\n+    for (e = node->callees; e; e = e->next_callee)\n+      if (e->callee->local.inlinable\n+\t  && e->inline_failed\n+\t  && !e->callee->local.disregard_inline_limits\n+\t  && !cgraph_recursive_inlining_p (node, e->callee, &e->inline_failed)\n+\t  && cgraph_check_inline_limits (node, e->callee, &e->inline_failed)\n+\t  && DECL_SAVED_TREE (e->callee->decl))\n+\t{\n+\t  if (cgraph_default_inline_p (e->callee))\n+\t    cgraph_mark_inline (e);\n+\t  else\n+\t    e->inline_failed\n+\t      = N_(\"--param max-inline-insns-single limit reached\");\n+\t}\n+}\n+\n+/* When inlining shall be performed.  */\n+static bool\n+cgraph_gate_inlining (void)\n+{\n+  return flag_inline_trees;\n+}\n+\n+struct tree_opt_pass pass_ipa_inline = \n+{\n+  \"inline\",\t\t\t\t/* name */\n+  cgraph_gate_inlining,\t\t\t/* gate */\n+  cgraph_decide_inlining,\t\t/* execute */\n+  NULL,\t\t\t\t\t/* sub */\n+  NULL,\t\t\t\t\t/* next */\n+  0,\t\t\t\t\t/* static_pass_number */\n+  TV_INTEGRATION,\t\t\t/* tv_id */\n+  0,\t                                /* properties_required */\n+  PROP_trees,\t\t\t\t/* properties_provided */\n+  0,\t\t\t\t\t/* properties_destroyed */\n+  0,\t\t\t\t\t/* todo_flags_start */\n+  TODO_dump_cgraph | TODO_dump_func,\t/* todo_flags_finish */\n+  0\t\t\t\t\t/* letter */\n+};"}, {"sha": "fe1055dc12bcb9a9402482a6680237ba884cc952", "filename": "gcc/ipa.c", "status": "added", "additions": 207, "deletions": 0, "changes": 207, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fipa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca31b95fa3f967fce4ea405dc56ed26182270209/gcc%2Fipa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa.c?ref=ca31b95fa3f967fce4ea405dc56ed26182270209", "patch": "@@ -0,0 +1,207 @@\n+/* Basic IPA optimizations and utilities.\n+   Copyright (C) 2003, 2004, 2005 Free Software Foundation, Inc.  \n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"cgraph.h\"\n+\n+/* Fill array order with all nodes with output flag set in the reverse\n+   topological order.  */\n+\n+int\n+cgraph_postorder (struct cgraph_node **order)\n+{\n+  struct cgraph_node *node, *node2;\n+  int stack_size = 0;\n+  int order_pos = 0;\n+  struct cgraph_edge *edge, last;\n+\n+  struct cgraph_node **stack =\n+    xcalloc (cgraph_n_nodes, sizeof (struct cgraph_node *));\n+\n+  /* We have to deal with cycles nicely, so use a depth first traversal\n+     output algorithm.  Ignore the fact that some functions won't need\n+     to be output and put them into order as well, so we get dependencies\n+     right through intline functions.  */\n+  for (node = cgraph_nodes; node; node = node->next)\n+    node->aux = NULL;\n+  for (node = cgraph_nodes; node; node = node->next)\n+    if (!node->aux)\n+      {\n+\tnode2 = node;\n+\tif (!node->callers)\n+\t  node->aux = &last;\n+\telse\n+\t  node->aux = node->callers;\n+\twhile (node2)\n+\t  {\n+\t    while (node2->aux != &last)\n+\t      {\n+\t\tedge = node2->aux;\n+\t\tif (edge->next_caller)\n+\t\t  node2->aux = edge->next_caller;\n+\t\telse\n+\t\t  node2->aux = &last;\n+\t\tif (!edge->caller->aux)\n+\t\t  {\n+\t\t    if (!edge->caller->callers)\n+\t\t      edge->caller->aux = &last;\n+\t\t    else\n+\t\t      edge->caller->aux = edge->caller->callers;\n+\t\t    stack[stack_size++] = node2;\n+\t\t    node2 = edge->caller;\n+\t\t    break;\n+\t\t  }\n+\t      }\n+\t    if (node2->aux == &last)\n+\t      {\n+\t\torder[order_pos++] = node2;\n+\t\tif (stack_size)\n+\t\t  node2 = stack[--stack_size];\n+\t\telse\n+\t\t  node2 = NULL;\n+\t      }\n+\t  }\n+      }\n+  free (stack);\n+  return order_pos;\n+}\n+\n+/* Perform reachability analysis and reclaim all unreachable nodes.\n+   If BEFORE_INLINING_P is true this function is called before inlining\n+   decisions has been made.  If BEFORE_INLINING_P is false this function also \n+   removes unneeded bodies of extern inline functions.  */\n+\n+bool\n+cgraph_remove_unreachable_nodes (bool before_inlining_p, FILE *dump_file)\n+{\n+  struct cgraph_node *first = (void *) 1;\n+  struct cgraph_node *node;\n+  bool changed = false;\n+  int insns = 0;\n+\n+#ifdef ENABLE_CHECKING\n+  verify_cgraph ();\n+#endif\n+  if (dump_file)\n+    fprintf (dump_file, \"\\nReclaiming functions:\");\n+#ifdef ENABLE_CHECKING\n+  for (node = cgraph_nodes; node; node = node->next)\n+    gcc_assert (!node->aux);\n+#endif\n+  for (node = cgraph_nodes; node; node = node->next)\n+    if (node->needed && !node->global.inlined_to\n+\t&& ((!DECL_EXTERNAL (node->decl)) \n+            || !node->analyzed\n+            || before_inlining_p))\n+      {\n+\tnode->aux = first;\n+\tfirst = node;\n+      }\n+    else\n+      gcc_assert (!node->aux);\n+\n+  /* Perform reachability analysis.  As a special case do not consider\n+     extern inline functions not inlined as live because we won't output\n+     them at all.  */\n+  while (first != (void *) 1)\n+    {\n+      struct cgraph_edge *e;\n+      node = first;\n+      first = first->aux;\n+\n+      for (e = node->callees; e; e = e->next_callee)\n+\tif (!e->callee->aux\n+\t    && node->analyzed\n+\t    && (!e->inline_failed || !e->callee->analyzed\n+\t\t|| (!DECL_EXTERNAL (e->callee->decl))\n+                || before_inlining_p))\n+\t  {\n+\t    e->callee->aux = first;\n+\t    first = e->callee;\n+\t  }\n+    }\n+\n+  /* Remove unreachable nodes.  Extern inline functions need special care;\n+     Unreachable extern inline functions shall be removed.\n+     Reachable extern inline functions we never inlined shall get their bodies\n+     eliminated.\n+     Reachable extern inline functions we sometimes inlined will be turned into\n+     unanalyzed nodes so they look like for true extern functions to the rest\n+     of code.  Body of such functions is released via remove_node once the\n+     inline clones are eliminated.  */\n+  for (node = cgraph_nodes; node; node = node->next)\n+    {\n+      if (!node->aux)\n+\t{\n+\t  int local_insns;\n+\t  tree decl = node->decl;\n+\n+          node->global.inlined_to = NULL;\n+\t  if (DECL_STRUCT_FUNCTION (decl))\n+\t    local_insns = node->local.self_insns;\n+\t  else\n+\t    local_insns = 0;\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \" %s\", cgraph_node_name (node));\n+\t  if (!node->analyzed || !DECL_EXTERNAL (node->decl)\n+\t      || before_inlining_p)\n+\t    cgraph_remove_node (node);\n+\t  else\n+\t    {\n+\t      struct cgraph_edge *e;\n+\n+\t      for (e = node->callers; e; e = e->next_caller)\n+\t\tif (e->caller->aux)\n+\t\t  break;\n+\t      if (e || node->needed)\n+\t\t{\n+\t\t  struct cgraph_node *clone;\n+\n+\t\t  for (clone = node->next_clone; clone;\n+\t\t       clone = clone->next_clone)\n+\t\t    if (clone->aux)\n+\t\t      break;\n+\t\t  if (!clone)\n+\t\t    {\n+\t\t      DECL_SAVED_TREE (node->decl) = NULL;\n+\t\t      DECL_STRUCT_FUNCTION (node->decl) = NULL;\n+\t\t      DECL_INITIAL (node->decl) = error_mark_node;\n+\t\t      node->analyzed = false;\n+\t\t    }\n+\t\t  cgraph_node_remove_callees (node);\n+\t\t  node->analyzed = false;\n+\t\t}\n+\t      else\n+\t\tcgraph_remove_node (node);\n+\t    }\n+\t  if (!DECL_SAVED_TREE (decl))\n+\t    insns += local_insns;\n+\t  changed = true;\n+\t}\n+    }\n+  for (node = cgraph_nodes; node; node = node->next)\n+    node->aux = NULL;\n+  if (dump_file)\n+    fprintf (dump_file, \"\\nReclaimed %i insns\", insns);\n+  return changed;\n+}"}]}