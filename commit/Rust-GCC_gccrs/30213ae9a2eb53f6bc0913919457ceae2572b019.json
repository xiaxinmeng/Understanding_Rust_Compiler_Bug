{"sha": "30213ae9a2eb53f6bc0913919457ceae2572b019", "node_id": "C_kwDOANBUbNoAKDMwMjEzYWU5YTJlYjUzZjZiYzA5MTM5MTk0NTdjZWFlMjU3MmIwMTk", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-11-30T09:52:24Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-11-30T09:52:24Z"}, "message": "vect: Make reduction code handle calls\n\nThis patch extends the reduction code to handle calls.  So far\nit's a structural change only; a later patch adds support for\nspecific function reductions.\n\nMost of the patch consists of using code_helper and gimple_match_op\nto describe the reduction operations.  The other main change is that\nvectorizable_call now needs to handle fully-predicated reductions.\n\nThere are some new functions that are provided for ABI completeness\nand aren't currently used:\n\n  first_commutative_argument\n  commutative_ternary_op_p\n  1- and 3-argument forms of gimple_build\n\ngcc/\n\t* builtins.h (associated_internal_fn): Declare overload that\n\ttakes a (combined_cfn, return type) pair.\n\t* builtins.c (associated_internal_fn): Split new overload out\n\tof original fndecl version.  Also provide an overload that takes\n\ta (combined_cfn, return type) pair.\n\t* internal-fn.h (commutative_binary_fn_p): Declare.\n\t(commutative_ternary_fn_p): Likewise.\n\t(associative_binary_fn_p): Likewise.\n\t* internal-fn.c (commutative_binary_fn_p, commutative_ternary_fn_p):\n\tNew functions, split out from...\n\t(first_commutative_argument): ...here.\n\t(associative_binary_fn_p): New function.\n\t* gimple-match.h (code_helper): Add a constructor that takes\n\tinternal functions.\n\t(commutative_binary_op_p): Declare.\n\t(commutative_ternary_op_p): Likewise.\n\t(first_commutative_argument): Likewise.\n\t(associative_binary_op_p): Likewise.\n\t(canonicalize_code): Likewise.\n\t(directly_supported_p): Likewise.\n\t(get_conditional_internal_fn): Likewise.\n\t(gimple_build): New overloads that takes a code_helper.\n\t* gimple-fold.c (gimple_build): Likewise.\n\t* gimple-match-head.c (commutative_binary_op_p): New function.\n\t(commutative_ternary_op_p): Likewise.\n\t(first_commutative_argument): Likewise.\n\t(associative_binary_op_p): Likewise.\n\t(canonicalize_code): Likewise.\n\t(directly_supported_p): Likewise.\n\t(get_conditional_internal_fn): Likewise.\n\t* tree-vectorizer.h: Include gimple-match.h.\n\t(neutral_op_for_reduction): Take a code_helper instead of a tree_code.\n\t(needs_fold_left_reduction_p): Likewise.\n\t(reduction_fn_for_scalar_code): Likewise.\n\t(vect_can_vectorize_without_simd_p): Declare a nNew overload that takes\n\ta code_helper.\n\t* tree-vect-loop.c: Include case-cfn-macros.h.\n\t(fold_left_reduction_fn): Take a code_helper instead of a tree_code.\n\t(reduction_fn_for_scalar_code): Likewise.\n\t(neutral_op_for_reduction): Likewise.\n\t(needs_fold_left_reduction_p): Likewise.\n\t(use_mask_by_cond_expr_p): Likewise.\n\t(build_vect_cond_expr): Likewise.\n\t(vect_create_partial_epilog): Likewise.  Use gimple_build rather\n\tthan gimple_build_assign.\n\t(check_reduction_path): Handle calls and operate on code_helpers\n\trather than tree_codes.\n\t(vect_is_simple_reduction): Likewise.\n\t(vect_model_reduction_cost): Likewise.\n\t(vect_find_reusable_accumulator): Likewise.\n\t(vect_create_epilog_for_reduction): Likewise.\n\t(vect_transform_cycle_phi): Likewise.\n\t(vectorizable_reduction): Likewise.  Make more use of\n\tlane_reduc_code_p.\n\t(vect_transform_reduction): Use gimple_extract_op but expect\n\ta tree_code for now.\n\t(vect_can_vectorize_without_simd_p): New overload that takes\n\ta code_helper.\n\t* tree-vect-stmts.c (vectorizable_call): Handle reductions in\n\tfully-masked loops.\n\t* tree-vect-patterns.c (vect_mark_pattern_stmts): Use\n\tgimple_extract_op when updating STMT_VINFO_REDUC_IDX.", "tree": {"sha": "3df652eaa52f2cd2ccb9a6e44c19ca8ffc130824", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3df652eaa52f2cd2ccb9a6e44c19ca8ffc130824"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/30213ae9a2eb53f6bc0913919457ceae2572b019", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/30213ae9a2eb53f6bc0913919457ceae2572b019", "html_url": "https://github.com/Rust-GCC/gccrs/commit/30213ae9a2eb53f6bc0913919457ceae2572b019", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/30213ae9a2eb53f6bc0913919457ceae2572b019/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0c1fb64d961eb760aba2601870f19be2b5533bd3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0c1fb64d961eb760aba2601870f19be2b5533bd3", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0c1fb64d961eb760aba2601870f19be2b5533bd3"}], "stats": {"total": 820, "additions": 561, "deletions": 259}, "files": [{"sha": "03829c03a5a11677cb9652652d441a3fd3f63aa2", "filename": "gcc/builtins.c", "status": "modified", "additions": 37, "deletions": 9, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -2139,17 +2139,17 @@ mathfn_built_in_type (combined_fn fn)\n #undef SEQ_OF_CASE_MATHFN\n }\n \n-/* If BUILT_IN_NORMAL function FNDECL has an associated internal function,\n-   return its code, otherwise return IFN_LAST.  Note that this function\n-   only tests whether the function is defined in internals.def, not whether\n-   it is actually available on the target.  */\n+/* Check whether there is an internal function associated with function FN\n+   and return type RETURN_TYPE.  Return the function if so, otherwise return\n+   IFN_LAST.\n \n-internal_fn\n-associated_internal_fn (tree fndecl)\n+   Note that this function only tests whether the function is defined in\n+   internals.def, not whether it is actually available on the target.  */\n+\n+static internal_fn\n+associated_internal_fn (built_in_function fn, tree return_type)\n {\n-  gcc_checking_assert (DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_NORMAL);\n-  tree return_type = TREE_TYPE (TREE_TYPE (fndecl));\n-  switch (DECL_FUNCTION_CODE (fndecl))\n+  switch (fn)\n     {\n #define DEF_INTERNAL_FLT_FN(NAME, FLAGS, OPTAB, TYPE) \\\n     CASE_FLT_FN (BUILT_IN_##NAME): return IFN_##NAME;\n@@ -2177,6 +2177,34 @@ associated_internal_fn (tree fndecl)\n     }\n }\n \n+/* If BUILT_IN_NORMAL function FNDECL has an associated internal function,\n+   return its code, otherwise return IFN_LAST.  Note that this function\n+   only tests whether the function is defined in internals.def, not whether\n+   it is actually available on the target.  */\n+\n+internal_fn\n+associated_internal_fn (tree fndecl)\n+{\n+  gcc_checking_assert (DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_NORMAL);\n+  return associated_internal_fn (DECL_FUNCTION_CODE (fndecl),\n+\t\t\t\t TREE_TYPE (TREE_TYPE (fndecl)));\n+}\n+\n+/* Check whether there is an internal function associated with function CFN\n+   and return type RETURN_TYPE.  Return the function if so, otherwise return\n+   IFN_LAST.\n+\n+   Note that this function only tests whether the function is defined in\n+   internals.def, not whether it is actually available on the target.  */\n+\n+internal_fn\n+associated_internal_fn (combined_fn cfn, tree return_type)\n+{\n+  if (internal_fn_p (cfn))\n+    return as_internal_fn (cfn);\n+  return associated_internal_fn (as_builtin_fn (cfn), return_type);\n+}\n+\n /* If CALL is a call to a BUILT_IN_NORMAL function that could be replaced\n    on the current target by a call to an internal function, return the\n    code of that internal function, otherwise return IFN_LAST.  The caller"}, {"sha": "c99670b12f1ffce8ea69b46de1da4ffc5240624a", "filename": "gcc/builtins.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fbuiltins.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fbuiltins.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.h?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -148,6 +148,7 @@ extern char target_percent_s_newline[4];\n extern bool target_char_cst_p (tree t, char *p);\n extern rtx get_memory_rtx (tree exp, tree len);\n \n+extern internal_fn associated_internal_fn (combined_fn, tree);\n extern internal_fn associated_internal_fn (tree);\n extern internal_fn replacement_internal_fn (gcall *);\n "}, {"sha": "44fba12e150b2d7a51f733fce02561861f2a820f", "filename": "gcc/gimple-fold.c", "status": "modified", "additions": 42, "deletions": 0, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fgimple-fold.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fgimple-fold.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-fold.c?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -8777,6 +8777,48 @@ gimple_build (gimple_seq *seq, location_t loc, combined_fn fn,\n   return res;\n }\n \n+/* Build CODE (OP0) with a result of type TYPE (or no result if TYPE is\n+   void) with location LOC, simplifying it first if possible.  Returns the\n+   built expression value (or NULL_TREE if TYPE is void) and appends\n+   statements possibly defining it to SEQ.  */\n+\n+tree\n+gimple_build (gimple_seq *seq, location_t loc, code_helper code,\n+\t      tree type, tree op0)\n+{\n+  if (code.is_tree_code ())\n+    return gimple_build (seq, loc, tree_code (code), type, op0);\n+  return gimple_build (seq, loc, combined_fn (code), type, op0);\n+}\n+\n+/* Build CODE (OP0, OP1) with a result of type TYPE (or no result if TYPE is\n+   void) with location LOC, simplifying it first if possible.  Returns the\n+   built expression value (or NULL_TREE if TYPE is void) and appends\n+   statements possibly defining it to SEQ.  */\n+\n+tree\n+gimple_build (gimple_seq *seq, location_t loc, code_helper code,\n+\t      tree type, tree op0, tree op1)\n+{\n+  if (code.is_tree_code ())\n+    return gimple_build (seq, loc, tree_code (code), type, op0, op1);\n+  return gimple_build (seq, loc, combined_fn (code), type, op0, op1);\n+}\n+\n+/* Build CODE (OP0, OP1, OP2) with a result of type TYPE (or no result if TYPE\n+   is void) with location LOC, simplifying it first if possible.  Returns the\n+   built expression value (or NULL_TREE if TYPE is void) and appends statements\n+   possibly defining it to SEQ.  */\n+\n+tree\n+gimple_build (gimple_seq *seq, location_t loc, code_helper code,\n+\t      tree type, tree op0, tree op1, tree op2)\n+{\n+  if (code.is_tree_code ())\n+    return gimple_build (seq, loc, tree_code (code), type, op0, op1, op2);\n+  return gimple_build (seq, loc, combined_fn (code), type, op0, op1, op2);\n+}\n+\n /* Build the conversion (TYPE) OP with a result of type TYPE\n    with location LOC if such conversion is neccesary in GIMPLE,\n    simplifying it first."}, {"sha": "c481a625581e61907cec6ff234de751c52e83053", "filename": "gcc/gimple-match-head.c", "status": "modified", "additions": 107, "deletions": 0, "changes": 107, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fgimple-match-head.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fgimple-match-head.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-match-head.c?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -1267,3 +1267,110 @@ optimize_successive_divisions_p (tree divisor, tree inner_div)\n     }\n   return true;\n }\n+\n+/* Return a canonical form for CODE when operating on TYPE.  The idea\n+   is to remove redundant ways of representing the same operation so\n+   that code_helpers can be hashed and compared for equality.\n+\n+   The only current canonicalization is to replace built-in functions\n+   with internal functions, in cases where internal-fn.def defines\n+   such an internal function.\n+\n+   Note that the new code_helper cannot necessarily be used in place of\n+   the original code_helper.  For example, the new code_helper might be\n+   an internal function that the target does not support.  */\n+\n+code_helper\n+canonicalize_code (code_helper code, tree type)\n+{\n+  if (code.is_fn_code ())\n+    return associated_internal_fn (combined_fn (code), type);\n+  return code;\n+}\n+\n+/* Return true if CODE is a binary operation and if CODE is commutative when\n+   operating on type TYPE.  */\n+\n+bool\n+commutative_binary_op_p (code_helper code, tree type)\n+{\n+  if (code.is_tree_code ())\n+    return commutative_tree_code (tree_code (code));\n+  auto cfn = combined_fn (code);\n+  return commutative_binary_fn_p (associated_internal_fn (cfn, type));\n+}\n+\n+/* Return true if CODE represents a ternary operation and if the first two\n+   operands are commutative when CODE is operating on TYPE.  */\n+\n+bool\n+commutative_ternary_op_p (code_helper code, tree type)\n+{\n+  if (code.is_tree_code ())\n+    return commutative_ternary_tree_code (tree_code (code));\n+  auto cfn = combined_fn (code);\n+  return commutative_ternary_fn_p (associated_internal_fn (cfn, type));\n+}\n+\n+/* If CODE is commutative in two consecutive operands, return the\n+   index of the first, otherwise return -1.  */\n+\n+int\n+first_commutative_argument (code_helper code, tree type)\n+{\n+  if (code.is_tree_code ())\n+    {\n+      auto tcode = tree_code (code);\n+      if (commutative_tree_code (tcode)\n+\t  || commutative_ternary_tree_code (tcode))\n+\treturn 0;\n+      return -1;\n+    }\n+  auto cfn = combined_fn (code);\n+  return first_commutative_argument (associated_internal_fn (cfn, type));\n+}\n+\n+/* Return true if CODE is a binary operation that is associative when\n+   operating on type TYPE.  */\n+\n+bool\n+associative_binary_op_p (code_helper code, tree type)\n+{\n+  if (code.is_tree_code ())\n+    return associative_tree_code (tree_code (code));\n+  auto cfn = combined_fn (code);\n+  return associative_binary_fn_p (associated_internal_fn (cfn, type));\n+}\n+\n+/* Return true if the target directly supports operation CODE on type TYPE.\n+   QUERY_TYPE acts as for optab_for_tree_code.  */\n+\n+bool\n+directly_supported_p (code_helper code, tree type, optab_subtype query_type)\n+{\n+  if (code.is_tree_code ())\n+    {\n+      direct_optab optab = optab_for_tree_code (tree_code (code), type,\n+\t\t\t\t\t\tquery_type);\n+      return (optab != unknown_optab\n+\t      && optab_handler (optab, TYPE_MODE (type)) != CODE_FOR_nothing);\n+    }\n+  gcc_assert (query_type == optab_default\n+\t      || (query_type == optab_vector && VECTOR_TYPE_P (type))\n+\t      || (query_type == optab_scalar && !VECTOR_TYPE_P (type)));\n+  internal_fn ifn = associated_internal_fn (combined_fn (code), type);\n+  return (direct_internal_fn_p (ifn)\n+\t  && direct_internal_fn_supported_p (ifn, type, OPTIMIZE_FOR_SPEED));\n+}\n+\n+/* A wrapper around the internal-fn.c versions of get_conditional_internal_fn\n+   for a code_helper CODE operating on type TYPE.  */\n+\n+internal_fn\n+get_conditional_internal_fn (code_helper code, tree type)\n+{\n+  if (code.is_tree_code ())\n+    return get_conditional_internal_fn (tree_code (code));\n+  auto cfn = combined_fn (code);\n+  return get_conditional_internal_fn (associated_internal_fn (cfn, type));\n+}"}, {"sha": "b7b6d2cea42f18ada654f4d3aac3fd1a94755b84", "filename": "gcc/gimple-match.h", "status": "modified", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fgimple-match.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Fgimple-match.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-match.h?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -31,6 +31,7 @@ class code_helper\n   code_helper () {}\n   code_helper (tree_code code) : rep ((int) code) {}\n   code_helper (combined_fn fn) : rep (-(int) fn) {}\n+  code_helper (internal_fn fn) : rep (-(int) as_combined_fn (fn)) {}\n   explicit operator tree_code () const { return (tree_code) rep; }\n   explicit operator combined_fn () const { return (combined_fn) -rep; }\n   explicit operator internal_fn () const;\n@@ -371,5 +372,42 @@ tree maybe_push_res_to_seq (gimple_match_op *, gimple_seq *,\n \t\t\t    tree res = NULL_TREE);\n void maybe_build_generic_op (gimple_match_op *);\n \n+bool commutative_binary_op_p (code_helper, tree);\n+bool commutative_ternary_op_p (code_helper, tree);\n+int first_commutative_argument (code_helper, tree);\n+bool associative_binary_op_p (code_helper, tree);\n+code_helper canonicalize_code (code_helper, tree);\n+\n+#ifdef GCC_OPTABS_TREE_H\n+bool directly_supported_p (code_helper, tree, optab_subtype = optab_default);\n+#endif\n+\n+internal_fn get_conditional_internal_fn (code_helper, tree);\n+\n+extern tree gimple_build (gimple_seq *, location_t,\n+\t\t\t  code_helper, tree, tree);\n+inline tree\n+gimple_build (gimple_seq *seq, code_helper code, tree type, tree op0)\n+{\n+  return gimple_build (seq, UNKNOWN_LOCATION, code, type, op0);\n+}\n+\n+extern tree gimple_build (gimple_seq *, location_t,\n+\t\t\t  code_helper, tree, tree, tree);\n+inline tree\n+gimple_build (gimple_seq *seq, code_helper code, tree type, tree op0,\n+\t      tree op1)\n+{\n+  return gimple_build (seq, UNKNOWN_LOCATION, code, type, op0, op1);\n+}\n+\n+extern tree gimple_build (gimple_seq *, location_t,\n+\t\t\t  code_helper, tree, tree, tree, tree);\n+inline tree\n+gimple_build (gimple_seq *seq, code_helper code, tree type, tree op0,\n+\t      tree op1, tree op2)\n+{\n+  return gimple_build (seq, UNKNOWN_LOCATION, code, type, op0, op1, op2);\n+}\n \n #endif  /* GCC_GIMPLE_MATCH_H */"}, {"sha": "514ce899211daa051f709071576861bc387419e5", "filename": "gcc/internal-fn.c", "status": "modified", "additions": 55, "deletions": 9, "changes": 64, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Finternal-fn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Finternal-fn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.c?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -3817,27 +3817,70 @@ direct_internal_fn_supported_p (gcall *stmt, optimization_type opt_type)\n   return direct_internal_fn_supported_p (fn, types, opt_type);\n }\n \n-/* If FN is commutative in two consecutive arguments, return the\n-   index of the first, otherwise return -1.  */\n+/* Return true if FN is a binary operation and if FN is commutative.  */\n \n-int\n-first_commutative_argument (internal_fn fn)\n+bool\n+commutative_binary_fn_p (internal_fn fn)\n {\n   switch (fn)\n     {\n-    case IFN_FMA:\n-    case IFN_FMS:\n-    case IFN_FNMA:\n-    case IFN_FNMS:\n     case IFN_AVG_FLOOR:\n     case IFN_AVG_CEIL:\n     case IFN_MULH:\n     case IFN_MULHS:\n     case IFN_MULHRS:\n     case IFN_FMIN:\n     case IFN_FMAX:\n-      return 0;\n+      return true;\n \n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Return true if FN is a ternary operation and if its first two arguments\n+   are commutative.  */\n+\n+bool\n+commutative_ternary_fn_p (internal_fn fn)\n+{\n+  switch (fn)\n+    {\n+    case IFN_FMA:\n+    case IFN_FMS:\n+    case IFN_FNMA:\n+    case IFN_FNMS:\n+      return true;\n+\n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Return true if FN is an associative binary operation.  */\n+\n+bool\n+associative_binary_fn_p (internal_fn fn)\n+{\n+  switch (fn)\n+    {\n+    case IFN_FMIN:\n+    case IFN_FMAX:\n+      return true;\n+\n+    default:\n+      return false;\n+    }\n+}\n+\n+/* If FN is commutative in two consecutive arguments, return the\n+   index of the first, otherwise return -1.  */\n+\n+int\n+first_commutative_argument (internal_fn fn)\n+{\n+  switch (fn)\n+    {\n     case IFN_COND_ADD:\n     case IFN_COND_MUL:\n     case IFN_COND_MIN:\n@@ -3854,6 +3897,9 @@ first_commutative_argument (internal_fn fn)\n       return 1;\n \n     default:\n+      if (commutative_binary_fn_p (fn)\n+\t  || commutative_ternary_fn_p (fn))\n+\treturn 0;\n       return -1;\n     }\n }"}, {"sha": "c96b9a7900549da5bacf38b445ced53cff9d7d8a", "filename": "gcc/internal-fn.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Finternal-fn.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Finternal-fn.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.h?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -206,7 +206,10 @@ direct_internal_fn_supported_p (internal_fn fn, tree type0, tree type1,\n \t\t\t\t\t opt_type);\n }\n \n+extern bool commutative_binary_fn_p (internal_fn);\n+extern bool commutative_ternary_fn_p (internal_fn);\n extern int first_commutative_argument (internal_fn);\n+extern bool associative_binary_fn_p (internal_fn);\n \n extern bool set_edom_supported_p (void);\n "}, {"sha": "b1198e1a9ef5de8a2e89b659f98d975ad245b419", "filename": "gcc/tree-vect-loop.c", "status": "modified", "additions": 205, "deletions": 215, "changes": 420, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vect-loop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vect-loop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop.c?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -54,6 +54,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-vector-builder.h\"\n #include \"vec-perm-indices.h\"\n #include \"tree-eh.h\"\n+#include \"case-cfn-macros.h\"\n \n /* Loop Vectorization Pass.\n \n@@ -3125,17 +3126,14 @@ vect_analyze_loop (class loop *loop, vec_info_shared *shared)\n    it in *REDUC_FN if so.  */\n \n static bool\n-fold_left_reduction_fn (tree_code code, internal_fn *reduc_fn)\n+fold_left_reduction_fn (code_helper code, internal_fn *reduc_fn)\n {\n-  switch (code)\n+  if (code == PLUS_EXPR)\n     {\n-    case PLUS_EXPR:\n       *reduc_fn = IFN_FOLD_LEFT_PLUS;\n       return true;\n-\n-    default:\n-      return false;\n     }\n+  return false;\n }\n \n /* Function reduction_fn_for_scalar_code\n@@ -3152,21 +3150,22 @@ fold_left_reduction_fn (tree_code code, internal_fn *reduc_fn)\n    Return FALSE if CODE currently cannot be vectorized as reduction.  */\n \n bool\n-reduction_fn_for_scalar_code (enum tree_code code, internal_fn *reduc_fn)\n+reduction_fn_for_scalar_code (code_helper code, internal_fn *reduc_fn)\n {\n-  switch (code)\n-    {\n+  if (code.is_tree_code ())\n+    switch (tree_code (code))\n+      {\n       case MAX_EXPR:\n-        *reduc_fn = IFN_REDUC_MAX;\n-        return true;\n+\t*reduc_fn = IFN_REDUC_MAX;\n+\treturn true;\n \n       case MIN_EXPR:\n-        *reduc_fn = IFN_REDUC_MIN;\n-        return true;\n+\t*reduc_fn = IFN_REDUC_MIN;\n+\treturn true;\n \n       case PLUS_EXPR:\n-        *reduc_fn = IFN_REDUC_PLUS;\n-        return true;\n+\t*reduc_fn = IFN_REDUC_PLUS;\n+\treturn true;\n \n       case BIT_AND_EXPR:\n \t*reduc_fn = IFN_REDUC_AND;\n@@ -3182,12 +3181,13 @@ reduction_fn_for_scalar_code (enum tree_code code, internal_fn *reduc_fn)\n \n       case MULT_EXPR:\n       case MINUS_EXPR:\n-        *reduc_fn = IFN_LAST;\n-        return true;\n+\t*reduc_fn = IFN_LAST;\n+\treturn true;\n \n       default:\n-       return false;\n+\tbreak;\n     }\n+  return false;\n }\n \n /* If there is a neutral value X such that a reduction would not be affected\n@@ -3197,32 +3197,35 @@ reduction_fn_for_scalar_code (enum tree_code code, internal_fn *reduc_fn)\n    then INITIAL_VALUE is that value, otherwise it is null.  */\n \n tree\n-neutral_op_for_reduction (tree scalar_type, tree_code code, tree initial_value)\n+neutral_op_for_reduction (tree scalar_type, code_helper code,\n+\t\t\t  tree initial_value)\n {\n-  switch (code)\n-    {\n-    case WIDEN_SUM_EXPR:\n-    case DOT_PROD_EXPR:\n-    case SAD_EXPR:\n-    case PLUS_EXPR:\n-    case MINUS_EXPR:\n-    case BIT_IOR_EXPR:\n-    case BIT_XOR_EXPR:\n-      return build_zero_cst (scalar_type);\n+  if (code.is_tree_code ())\n+    switch (tree_code (code))\n+      {\n+      case WIDEN_SUM_EXPR:\n+      case DOT_PROD_EXPR:\n+      case SAD_EXPR:\n+      case PLUS_EXPR:\n+      case MINUS_EXPR:\n+      case BIT_IOR_EXPR:\n+      case BIT_XOR_EXPR:\n+\treturn build_zero_cst (scalar_type);\n \n-    case MULT_EXPR:\n-      return build_one_cst (scalar_type);\n+      case MULT_EXPR:\n+\treturn build_one_cst (scalar_type);\n \n-    case BIT_AND_EXPR:\n-      return build_all_ones_cst (scalar_type);\n+      case BIT_AND_EXPR:\n+\treturn build_all_ones_cst (scalar_type);\n \n-    case MAX_EXPR:\n-    case MIN_EXPR:\n-      return initial_value;\n+      case MAX_EXPR:\n+      case MIN_EXPR:\n+\treturn initial_value;\n \n-    default:\n-      return NULL_TREE;\n-    }\n+      default:\n+\tbreak;\n+      }\n+  return NULL_TREE;\n }\n \n /* Error reporting helper for vect_is_simple_reduction below.  GIMPLE statement\n@@ -3239,26 +3242,27 @@ report_vect_op (dump_flags_t msg_type, gimple *stmt, const char *msg)\n    overflow must wrap.  */\n \n bool\n-needs_fold_left_reduction_p (tree type, tree_code code)\n+needs_fold_left_reduction_p (tree type, code_helper code)\n {\n   /* CHECKME: check for !flag_finite_math_only too?  */\n   if (SCALAR_FLOAT_TYPE_P (type))\n-    switch (code)\n-      {\n-      case MIN_EXPR:\n-      case MAX_EXPR:\n-\treturn false;\n+    {\n+      if (code.is_tree_code ())\n+\tswitch (tree_code (code))\n+\t  {\n+\t  case MIN_EXPR:\n+\t  case MAX_EXPR:\n+\t    return false;\n \n-      default:\n-\treturn !flag_associative_math;\n-      }\n+\t  default:\n+\t    break;\n+\t  }\n+      return !flag_associative_math;\n+    }\n \n   if (INTEGRAL_TYPE_P (type))\n-    {\n-      if (!operation_no_trapping_overflow (type, code))\n-\treturn true;\n-      return false;\n-    }\n+    return (!code.is_tree_code ()\n+\t    || !operation_no_trapping_overflow (type, tree_code (code)));\n \n   if (SAT_FIXED_POINT_TYPE_P (type))\n     return true;\n@@ -3272,7 +3276,7 @@ needs_fold_left_reduction_p (tree type, tree_code code)\n \n static bool\n check_reduction_path (dump_user_location_t loc, loop_p loop, gphi *phi,\n-\t\t      tree loop_arg, enum tree_code *code,\n+\t\t      tree loop_arg, code_helper *code,\n \t\t      vec<std::pair<ssa_op_iter, use_operand_p> > &path)\n {\n   auto_bitmap visited;\n@@ -3347,45 +3351,57 @@ check_reduction_path (dump_user_location_t loc, loop_p loop, gphi *phi,\n   for (unsigned i = 1; i < path.length (); ++i)\n     {\n       gimple *use_stmt = USE_STMT (path[i].second);\n-      tree op = USE_FROM_PTR (path[i].second);\n-      if (! is_gimple_assign (use_stmt)\n+      gimple_match_op op;\n+      if (!gimple_extract_op (use_stmt, &op))\n+\t{\n+\t  fail = true;\n+\t  break;\n+\t}\n+      unsigned int opi = op.num_ops;\n+      if (gassign *assign = dyn_cast<gassign *> (use_stmt))\n+\t{\n \t  /* The following make sure we can compute the operand index\n \t     easily plus it mostly disallows chaining via COND_EXPR condition\n \t     operands.  */\n-\t  || (gimple_assign_rhs1_ptr (use_stmt) != path[i].second->use\n-\t      && (gimple_num_ops (use_stmt) <= 2\n-\t\t  || gimple_assign_rhs2_ptr (use_stmt) != path[i].second->use)\n-\t      && (gimple_num_ops (use_stmt) <= 3\n-\t\t  || gimple_assign_rhs3_ptr (use_stmt) != path[i].second->use)))\n+\t  for (opi = 0; opi < op.num_ops; ++opi)\n+\t    if (gimple_assign_rhs1_ptr (assign) + opi == path[i].second->use)\n+\t      break;\n+\t}\n+      else if (gcall *call = dyn_cast<gcall *> (use_stmt))\n+\t{\n+\t  for (opi = 0; opi < op.num_ops; ++opi)\n+\t    if (gimple_call_arg_ptr (call, opi) == path[i].second->use)\n+\t      break;\n+\t}\n+      if (opi == op.num_ops)\n \t{\n \t  fail = true;\n \t  break;\n \t}\n-      tree_code use_code = gimple_assign_rhs_code (use_stmt);\n-      if (use_code == MINUS_EXPR)\n+      op.code = canonicalize_code (op.code, op.type);\n+      if (op.code == MINUS_EXPR)\n \t{\n-\t  use_code = PLUS_EXPR;\n+\t  op.code = PLUS_EXPR;\n \t  /* Track whether we negate the reduction value each iteration.  */\n-\t  if (gimple_assign_rhs2 (use_stmt) == op)\n+\t  if (op.ops[1] == op.ops[opi])\n \t    neg = ! neg;\n \t}\n-      if (CONVERT_EXPR_CODE_P (use_code)\n-\t  && tree_nop_conversion_p (TREE_TYPE (gimple_assign_lhs (use_stmt)),\n-\t\t\t\t    TREE_TYPE (gimple_assign_rhs1 (use_stmt))))\n+      if (CONVERT_EXPR_CODE_P (op.code)\n+\t  && tree_nop_conversion_p (op.type, TREE_TYPE (op.ops[0])))\n \t;\n       else if (*code == ERROR_MARK)\n \t{\n-\t  *code = use_code;\n-\t  sign = TYPE_SIGN (TREE_TYPE (gimple_assign_lhs (use_stmt)));\n+\t  *code = op.code;\n+\t  sign = TYPE_SIGN (op.type);\n \t}\n-      else if (use_code != *code)\n+      else if (op.code != *code)\n \t{\n \t  fail = true;\n \t  break;\n \t}\n-      else if ((use_code == MIN_EXPR\n-\t\t|| use_code == MAX_EXPR)\n-\t       && sign != TYPE_SIGN (TREE_TYPE (gimple_assign_lhs (use_stmt))))\n+      else if ((op.code == MIN_EXPR\n+\t\t|| op.code == MAX_EXPR)\n+\t       && sign != TYPE_SIGN (op.type))\n \t{\n \t  fail = true;\n \t  break;\n@@ -3397,7 +3413,7 @@ check_reduction_path (dump_user_location_t loc, loop_p loop, gphi *phi,\n       imm_use_iterator imm_iter;\n       gimple *op_use_stmt;\n       unsigned cnt = 0;\n-      FOR_EACH_IMM_USE_STMT (op_use_stmt, imm_iter, op)\n+      FOR_EACH_IMM_USE_STMT (op_use_stmt, imm_iter, op.ops[opi])\n \tif (!is_gimple_debug (op_use_stmt)\n \t    && (*code != ERROR_MARK\n \t\t|| flow_bb_inside_loop_p (loop, gimple_bb (op_use_stmt))))\n@@ -3427,7 +3443,7 @@ check_reduction_path (dump_user_location_t loc, loop_p loop, gphi *phi,\n \t\t      tree loop_arg, enum tree_code code)\n {\n   auto_vec<std::pair<ssa_op_iter, use_operand_p> > path;\n-  enum tree_code code_;\n+  code_helper code_;\n   return (check_reduction_path (loc, loop, phi, loop_arg, &code_, path)\n \t  && code_ == code);\n }\n@@ -3607,9 +3623,9 @@ vect_is_simple_reduction (loop_vec_info loop_info, stmt_vec_info phi_info,\n       gimple *def1 = SSA_NAME_DEF_STMT (op1);\n       if (gimple_bb (def1)\n \t  && flow_bb_inside_loop_p (loop, gimple_bb (def_stmt))\n-          && loop->inner\n-          && flow_bb_inside_loop_p (loop->inner, gimple_bb (def1))\n-          && is_gimple_assign (def1)\n+\t  && loop->inner\n+\t  && flow_bb_inside_loop_p (loop->inner, gimple_bb (def1))\n+\t  && (is_gimple_assign (def1) || is_gimple_call (def1))\n \t  && is_a <gphi *> (phi_use_stmt)\n \t  && flow_bb_inside_loop_p (loop->inner, gimple_bb (phi_use_stmt)))\n         {\n@@ -3626,7 +3642,7 @@ vect_is_simple_reduction (loop_vec_info loop_info, stmt_vec_info phi_info,\n \n   /* Look for the expression computing latch_def from then loop PHI result.  */\n   auto_vec<std::pair<ssa_op_iter, use_operand_p> > path;\n-  enum tree_code code;\n+  code_helper code;\n   if (check_reduction_path (vect_location, loop, phi, latch_def, &code,\n \t\t\t    path))\n     {\n@@ -3644,15 +3660,24 @@ vect_is_simple_reduction (loop_vec_info loop_info, stmt_vec_info phi_info,\n \t{\n \t  gimple *stmt = USE_STMT (path[i].second);\n \t  stmt_vec_info stmt_info = loop_info->lookup_stmt (stmt);\n-\t  STMT_VINFO_REDUC_IDX (stmt_info)\n-\t    = path[i].second->use - gimple_assign_rhs1_ptr (stmt);\n-\t  enum tree_code stmt_code = gimple_assign_rhs_code (stmt);\n-\t  bool leading_conversion = (CONVERT_EXPR_CODE_P (stmt_code)\n+\t  gimple_match_op op;\n+\t  if (!gimple_extract_op (stmt, &op))\n+\t    gcc_unreachable ();\n+\t  if (gassign *assign = dyn_cast<gassign *> (stmt))\n+\t    STMT_VINFO_REDUC_IDX (stmt_info)\n+\t      = path[i].second->use - gimple_assign_rhs1_ptr (assign);\n+\t  else\n+\t    {\n+\t      gcall *call = as_a<gcall *> (stmt);\n+\t      STMT_VINFO_REDUC_IDX (stmt_info)\n+\t\t= path[i].second->use - gimple_call_arg_ptr (call, 0);\n+\t    }\n+\t  bool leading_conversion = (CONVERT_EXPR_CODE_P (op.code)\n \t\t\t\t     && (i == 1 || i == path.length () - 1));\n-\t  if ((stmt_code != code && !leading_conversion)\n+\t  if ((op.code != code && !leading_conversion)\n \t      /* We can only handle the final value in epilogue\n \t\t generation for reduction chains.  */\n-\t      || (i != 1 && !has_single_use (gimple_assign_lhs (stmt))))\n+\t      || (i != 1 && !has_single_use (gimple_get_lhs (stmt))))\n \t    is_slp_reduc = false;\n \t  /* For reduction chains we support a trailing/leading\n \t     conversions.  We do not store those in the actual chain.  */\n@@ -4401,8 +4426,6 @@ vect_model_reduction_cost (loop_vec_info loop_vinfo,\n \t\t\t   int ncopies, stmt_vector_for_cost *cost_vec)\n {\n   int prologue_cost = 0, epilogue_cost = 0, inside_cost = 0;\n-  enum tree_code code;\n-  optab optab;\n   tree vectype;\n   machine_mode mode;\n   class loop *loop = NULL;\n@@ -4418,7 +4441,9 @@ vect_model_reduction_cost (loop_vec_info loop_vinfo,\n   mode = TYPE_MODE (vectype);\n   stmt_vec_info orig_stmt_info = vect_orig_stmt (stmt_info);\n \n-  code = gimple_assign_rhs_code (orig_stmt_info->stmt);\n+  gimple_match_op op;\n+  if (!gimple_extract_op (orig_stmt_info->stmt, &op))\n+    gcc_unreachable ();\n \n   if (reduction_type == EXTRACT_LAST_REDUCTION)\n     /* No extra instructions are needed in the prologue.  The loop body\n@@ -4512,20 +4537,16 @@ vect_model_reduction_cost (loop_vec_info loop_vinfo,\n       else\n \t{\n \t  int vec_size_in_bits = tree_to_uhwi (TYPE_SIZE (vectype));\n-\t  tree bitsize =\n-\t    TYPE_SIZE (TREE_TYPE (gimple_assign_lhs (orig_stmt_info->stmt)));\n+\t  tree bitsize = TYPE_SIZE (op.type);\n \t  int element_bitsize = tree_to_uhwi (bitsize);\n \t  int nelements = vec_size_in_bits / element_bitsize;\n \n-\t  if (code == COND_EXPR)\n-\t    code = MAX_EXPR;\n-\n-\t  optab = optab_for_tree_code (code, vectype, optab_default);\n+\t  if (op.code == COND_EXPR)\n+\t    op.code = MAX_EXPR;\n \n \t  /* We have a whole vector shift available.  */\n-\t  if (optab != unknown_optab\n-\t      && VECTOR_MODE_P (mode)\n-\t      && optab_handler (optab, mode) != CODE_FOR_nothing\n+\t  if (VECTOR_MODE_P (mode)\n+\t      && directly_supported_p (op.code, vectype)\n \t      && have_whole_vector_shift (mode))\n \t    {\n \t      /* Final reduction via vector shifts and the reduction operator.\n@@ -4866,7 +4887,7 @@ vect_find_reusable_accumulator (loop_vec_info loop_vinfo,\n \t initialize the accumulator with a neutral value instead.  */\n       if (!operand_equal_p (initial_value, main_adjustment))\n \treturn false;\n-      tree_code code = STMT_VINFO_REDUC_CODE (reduc_info);\n+      code_helper code = STMT_VINFO_REDUC_CODE (reduc_info);\n       initial_values[0] = neutral_op_for_reduction (TREE_TYPE (initial_value),\n \t\t\t\t\t\t    code, initial_value);\n     }\n@@ -4881,7 +4902,7 @@ vect_find_reusable_accumulator (loop_vec_info loop_vinfo,\n    CODE emitting stmts before GSI.  Returns a vector def of VECTYPE.  */\n \n static tree\n-vect_create_partial_epilog (tree vec_def, tree vectype, enum tree_code code,\n+vect_create_partial_epilog (tree vec_def, tree vectype, code_helper code,\n \t\t\t    gimple_seq *seq)\n {\n   unsigned nunits = TYPE_VECTOR_SUBPARTS (TREE_TYPE (vec_def)).to_constant ();\n@@ -4964,9 +4985,7 @@ vect_create_partial_epilog (tree vec_def, tree vectype, enum tree_code code,\n \t  gimple_seq_add_stmt_without_update (seq, epilog_stmt);\n \t}\n \n-      new_temp = make_ssa_name (vectype1);\n-      epilog_stmt = gimple_build_assign (new_temp, code, dst1, dst2);\n-      gimple_seq_add_stmt_without_update (seq, epilog_stmt);\n+      new_temp = gimple_build (seq, code, vectype1, dst1, dst2);\n     }\n \n   return new_temp;\n@@ -5043,7 +5062,7 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n     }\n   gphi *reduc_def_stmt\n     = as_a <gphi *> (STMT_VINFO_REDUC_DEF (vect_orig_stmt (stmt_info))->stmt);\n-  enum tree_code code = STMT_VINFO_REDUC_CODE (reduc_info);\n+  code_helper code = STMT_VINFO_REDUC_CODE (reduc_info);\n   internal_fn reduc_fn = STMT_VINFO_REDUC_FN (reduc_info);\n   tree vectype;\n   machine_mode mode;\n@@ -5710,14 +5729,9 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n       tree vectype1 = get_related_vectype_for_scalar_type (TYPE_MODE (vectype),\n \t\t\t\t\t\t\t   stype, nunits1);\n       reduce_with_shift = have_whole_vector_shift (mode1);\n-      if (!VECTOR_MODE_P (mode1))\n+      if (!VECTOR_MODE_P (mode1)\n+\t  || !directly_supported_p (code, vectype1))\n \treduce_with_shift = false;\n-      else\n-\t{\n-\t  optab optab = optab_for_tree_code (code, vectype1, optab_default);\n-\t  if (optab_handler (optab, mode1) == CODE_FOR_nothing)\n-\t    reduce_with_shift = false;\n-\t}\n \n       /* First reduce the vector to the desired vector size we should\n \t do shift reduction on by combining upper and lower halves.  */\n@@ -5955,7 +5969,7 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n   for (k = 0; k < live_out_stmts.size (); k++)\n     {\n       stmt_vec_info scalar_stmt_info = vect_orig_stmt (live_out_stmts[k]);\n-      scalar_dest = gimple_assign_lhs (scalar_stmt_info->stmt);\n+      scalar_dest = gimple_get_lhs (scalar_stmt_info->stmt);\n \n       phis.create (3);\n       /* Find the loop-closed-use at the loop exit of the original scalar\n@@ -6288,34 +6302,36 @@ is_nonwrapping_integer_induction (stmt_vec_info stmt_vinfo, class loop *loop)\n    CODE is the code for the operation.  COND_FN is the conditional internal\n    function, if it exists.  VECTYPE_IN is the type of the vector input.  */\n static bool\n-use_mask_by_cond_expr_p (enum tree_code code, internal_fn cond_fn,\n+use_mask_by_cond_expr_p (code_helper code, internal_fn cond_fn,\n \t\t\t tree vectype_in)\n {\n   if (cond_fn != IFN_LAST\n       && direct_internal_fn_supported_p (cond_fn, vectype_in,\n \t\t\t\t\t OPTIMIZE_FOR_SPEED))\n     return false;\n \n-  switch (code)\n-    {\n-    case DOT_PROD_EXPR:\n-    case SAD_EXPR:\n-      return true;\n+  if (code.is_tree_code ())\n+    switch (tree_code (code))\n+      {\n+      case DOT_PROD_EXPR:\n+      case SAD_EXPR:\n+\treturn true;\n \n-    default:\n-      return false;\n-    }\n+      default:\n+\tbreak;\n+      }\n+  return false;\n }\n \n /* Insert a conditional expression to enable masked vectorization.  CODE is the\n    code for the operation.  VOP is the array of operands.  MASK is the loop\n    mask.  GSI is a statement iterator used to place the new conditional\n    expression.  */\n static void\n-build_vect_cond_expr (enum tree_code code, tree vop[3], tree mask,\n+build_vect_cond_expr (code_helper code, tree vop[3], tree mask,\n \t\t      gimple_stmt_iterator *gsi)\n {\n-  switch (code)\n+  switch (tree_code (code))\n     {\n     case DOT_PROD_EXPR:\n       {\n@@ -6401,12 +6417,10 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \t\t\tslp_instance slp_node_instance,\n \t\t\tstmt_vector_for_cost *cost_vec)\n {\n-  tree scalar_dest;\n   tree vectype_in = NULL_TREE;\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   enum vect_def_type cond_reduc_dt = vect_unknown_def_type;\n   stmt_vec_info cond_stmt_vinfo = NULL;\n-  tree scalar_type;\n   int i;\n   int ncopies;\n   bool single_defuse_cycle = false;\n@@ -6519,18 +6533,18 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \t info_for_reduction to work.  */\n       if (STMT_VINFO_LIVE_P (vdef))\n \tSTMT_VINFO_REDUC_DEF (def) = phi_info;\n-      gassign *assign = dyn_cast <gassign *> (vdef->stmt);\n-      if (!assign)\n+      gimple_match_op op;\n+      if (!gimple_extract_op (vdef->stmt, &op))\n \t{\n \t  if (dump_enabled_p ())\n \t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n-\t\t\t     \"reduction chain includes calls.\\n\");\n+\t\t\t     \"reduction chain includes unsupported\"\n+\t\t\t     \" statement type.\\n\");\n \t  return false;\n \t}\n-      if (CONVERT_EXPR_CODE_P (gimple_assign_rhs_code (assign)))\n+      if (CONVERT_EXPR_CODE_P (op.code))\n \t{\n-\t  if (!tree_nop_conversion_p (TREE_TYPE (gimple_assign_lhs (assign)),\n-\t\t\t\t      TREE_TYPE (gimple_assign_rhs1 (assign))))\n+\t  if (!tree_nop_conversion_p (op.type, TREE_TYPE (op.ops[0])))\n \t    {\n \t      if (dump_enabled_p ())\n \t\tdump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n@@ -6541,7 +6555,7 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n       else if (!stmt_info)\n \t/* First non-conversion stmt.  */\n \tstmt_info = vdef;\n-      reduc_def = gimple_op (vdef->stmt, 1 + STMT_VINFO_REDUC_IDX (vdef));\n+      reduc_def = op.ops[STMT_VINFO_REDUC_IDX (vdef)];\n       reduc_chain_length++;\n       if (!stmt_info && slp_node)\n \tslp_for_stmt_info = SLP_TREE_CHILDREN (slp_for_stmt_info)[0];\n@@ -6599,26 +6613,24 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \n   tree vectype_out = STMT_VINFO_VECTYPE (stmt_info);\n   STMT_VINFO_REDUC_VECTYPE (reduc_info) = vectype_out;\n-  gassign *stmt = as_a <gassign *> (stmt_info->stmt);\n-  enum tree_code code = gimple_assign_rhs_code (stmt);\n-  bool lane_reduc_code_p\n-    = (code == DOT_PROD_EXPR || code == WIDEN_SUM_EXPR || code == SAD_EXPR);\n-  int op_type = TREE_CODE_LENGTH (code);\n+  gimple_match_op op;\n+  if (!gimple_extract_op (stmt_info->stmt, &op))\n+    gcc_unreachable ();\n+  bool lane_reduc_code_p = (op.code == DOT_PROD_EXPR\n+\t\t\t    || op.code == WIDEN_SUM_EXPR\n+\t\t\t    || op.code == SAD_EXPR);\n   enum optab_subtype optab_query_kind = optab_vector;\n-  if (code == DOT_PROD_EXPR\n-      && TYPE_SIGN (TREE_TYPE (gimple_assign_rhs1 (stmt)))\n-\t   != TYPE_SIGN (TREE_TYPE (gimple_assign_rhs2 (stmt))))\n+  if (op.code == DOT_PROD_EXPR\n+      && (TYPE_SIGN (TREE_TYPE (op.ops[0]))\n+\t  != TYPE_SIGN (TREE_TYPE (op.ops[1]))))\n     optab_query_kind = optab_vector_mixed_sign;\n \n-\n-  scalar_dest = gimple_assign_lhs (stmt);\n-  scalar_type = TREE_TYPE (scalar_dest);\n-  if (!POINTER_TYPE_P (scalar_type) && !INTEGRAL_TYPE_P (scalar_type)\n-      && !SCALAR_FLOAT_TYPE_P (scalar_type))\n+  if (!POINTER_TYPE_P (op.type) && !INTEGRAL_TYPE_P (op.type)\n+      && !SCALAR_FLOAT_TYPE_P (op.type))\n     return false;\n \n   /* Do not try to vectorize bit-precision reductions.  */\n-  if (!type_has_mode_precision_p (scalar_type))\n+  if (!type_has_mode_precision_p (op.type))\n     return false;\n \n   /* For lane-reducing ops we're reducing the number of reduction PHIs\n@@ -6637,25 +6649,23 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n      The last use is the reduction variable.  In case of nested cycle this\n      assumption is not true: we use reduc_index to record the index of the\n      reduction variable.  */\n-  slp_tree *slp_op = XALLOCAVEC (slp_tree, op_type);\n+  slp_tree *slp_op = XALLOCAVEC (slp_tree, op.num_ops);\n   /* We need to skip an extra operand for COND_EXPRs with embedded\n      comparison.  */\n   unsigned opno_adjust = 0;\n-  if (code == COND_EXPR\n-      && COMPARISON_CLASS_P (gimple_assign_rhs1 (stmt)))\n+  if (op.code == COND_EXPR && COMPARISON_CLASS_P (op.ops[0]))\n     opno_adjust = 1;\n-  for (i = 0; i < op_type; i++)\n+  for (i = 0; i < (int) op.num_ops; i++)\n     {\n       /* The condition of COND_EXPR is checked in vectorizable_condition().  */\n-      if (i == 0 && code == COND_EXPR)\n+      if (i == 0 && op.code == COND_EXPR)\n         continue;\n \n       stmt_vec_info def_stmt_info;\n       enum vect_def_type dt;\n-      tree op;\n       if (!vect_is_simple_use (loop_vinfo, stmt_info, slp_for_stmt_info,\n-\t\t\t       i + opno_adjust, &op, &slp_op[i], &dt, &tem,\n-\t\t\t       &def_stmt_info))\n+\t\t\t       i + opno_adjust, &op.ops[i], &slp_op[i], &dt,\n+\t\t\t       &tem, &def_stmt_info))\n \t{\n \t  if (dump_enabled_p ())\n \t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n@@ -6680,13 +6690,13 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \t\t  < GET_MODE_SIZE (SCALAR_TYPE_MODE (TREE_TYPE (tem))))))\n \tvectype_in = tem;\n \n-      if (code == COND_EXPR)\n+      if (op.code == COND_EXPR)\n \t{\n \t  /* Record how the non-reduction-def value of COND_EXPR is defined.  */\n \t  if (dt == vect_constant_def)\n \t    {\n \t      cond_reduc_dt = dt;\n-\t      cond_reduc_val = op;\n+\t      cond_reduc_val = op.ops[i];\n \t    }\n \t  if (dt == vect_induction_def\n \t      && def_stmt_info\n@@ -6856,7 +6866,7 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n           (and also the same tree-code) when generating the epilog code and\n           when generating the code inside the loop.  */\n \n-  enum tree_code orig_code = STMT_VINFO_REDUC_CODE (phi_info);\n+  code_helper orig_code = STMT_VINFO_REDUC_CODE (phi_info);\n   STMT_VINFO_REDUC_CODE (reduc_info) = orig_code;\n \n   vect_reduction_type reduction_type = STMT_VINFO_REDUC_TYPE (reduc_info);\n@@ -6875,7 +6885,7 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \t  && !REDUC_GROUP_FIRST_ELEMENT (stmt_info)\n \t  && known_eq (LOOP_VINFO_VECT_FACTOR (loop_vinfo), 1u))\n \t;\n-      else if (needs_fold_left_reduction_p (scalar_type, orig_code))\n+      else if (needs_fold_left_reduction_p (op.type, orig_code))\n \t{\n \t  /* When vectorizing a reduction chain w/o SLP the reduction PHI\n \t     is not directy used in stmt.  */\n@@ -6890,8 +6900,8 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \t  STMT_VINFO_REDUC_TYPE (reduc_info)\n \t    = reduction_type = FOLD_LEFT_REDUCTION;\n \t}\n-      else if (!commutative_tree_code (orig_code)\n-\t       || !associative_tree_code (orig_code))\n+      else if (!commutative_binary_op_p (orig_code, op.type)\n+\t       || !associative_binary_op_p (orig_code, op.type))\n \t{\n \t  if (dump_enabled_p ())\n \t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n@@ -6946,7 +6956,7 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n   else if (reduction_type == COND_REDUCTION)\n     {\n       int scalar_precision\n-\t= GET_MODE_PRECISION (SCALAR_TYPE_MODE (scalar_type));\n+\t= GET_MODE_PRECISION (SCALAR_TYPE_MODE (op.type));\n       cr_index_scalar_type = make_unsigned_type (scalar_precision);\n       cr_index_vector_type = get_same_sized_vectype (cr_index_scalar_type,\n \t\t\t\t\t\tvectype_out);\n@@ -7132,36 +7142,27 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \n   if (single_defuse_cycle || lane_reduc_code_p)\n     {\n-      gcc_assert (code != COND_EXPR);\n+      gcc_assert (op.code != COND_EXPR);\n \n       /* 4. Supportable by target?  */\n       bool ok = true;\n \n       /* 4.1. check support for the operation in the loop  */\n-      optab optab = optab_for_tree_code (code, vectype_in, optab_query_kind);\n-      if (!optab)\n-\t{\n-\t  if (dump_enabled_p ())\n-\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n-\t\t\t     \"no optab.\\n\");\n-\t  ok = false;\n-        }\n-\n       machine_mode vec_mode = TYPE_MODE (vectype_in);\n-      if (ok && optab_handler (optab, vec_mode) == CODE_FOR_nothing)\n+      if (!directly_supported_p (op.code, vectype_in, optab_query_kind))\n         {\n           if (dump_enabled_p ())\n             dump_printf (MSG_NOTE, \"op not supported by target.\\n\");\n \t  if (maybe_ne (GET_MODE_SIZE (vec_mode), UNITS_PER_WORD)\n-\t      || !vect_can_vectorize_without_simd_p (code))\n+\t      || !vect_can_vectorize_without_simd_p (op.code))\n \t    ok = false;\n \t  else\n \t    if (dump_enabled_p ())\n \t      dump_printf (MSG_NOTE, \"proceeding using word mode.\\n\");\n         }\n \n       if (vect_emulated_vector_p (vectype_in)\n-\t  && !vect_can_vectorize_without_simd_p (code))\n+\t  && !vect_can_vectorize_without_simd_p (op.code))\n \t{\n \t  if (dump_enabled_p ())\n \t    dump_printf (MSG_NOTE, \"using word mode not possible.\\n\");\n@@ -7194,11 +7195,9 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n \n   if (slp_node\n       && !(!single_defuse_cycle\n-\t   && code != DOT_PROD_EXPR\n-\t   && code != WIDEN_SUM_EXPR\n-\t   && code != SAD_EXPR\n+\t   && !lane_reduc_code_p\n \t   && reduction_type != FOLD_LEFT_REDUCTION))\n-    for (i = 0; i < op_type; i++)\n+    for (i = 0; i < (int) op.num_ops; i++)\n       if (!vect_maybe_update_slp_op_vectype (slp_op[i], vectype_in))\n \t{\n \t  if (dump_enabled_p ())\n@@ -7217,10 +7216,7 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n   /* Cost the reduction op inside the loop if transformed via\n      vect_transform_reduction.  Otherwise this is costed by the\n      separate vectorizable_* routines.  */\n-  if (single_defuse_cycle\n-      || code == DOT_PROD_EXPR\n-      || code == WIDEN_SUM_EXPR\n-      || code == SAD_EXPR)\n+  if (single_defuse_cycle || lane_reduc_code_p)\n     record_stmt_cost (cost_vec, ncopies, vector_stmt, stmt_info, 0, vect_body);\n \n   if (dump_enabled_p ()\n@@ -7231,9 +7227,7 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n   /* All but single defuse-cycle optimized, lane-reducing and fold-left\n      reductions go through their own vectorizable_* routines.  */\n   if (!single_defuse_cycle\n-      && code != DOT_PROD_EXPR\n-      && code != WIDEN_SUM_EXPR\n-      && code != SAD_EXPR\n+      && !lane_reduc_code_p\n       && reduction_type != FOLD_LEFT_REDUCTION)\n     {\n       stmt_vec_info tem\n@@ -7249,10 +7243,10 @@ vectorizable_reduction (loop_vec_info loop_vinfo,\n   else if (loop_vinfo && LOOP_VINFO_CAN_USE_PARTIAL_VECTORS_P (loop_vinfo))\n     {\n       vec_loop_masks *masks = &LOOP_VINFO_MASKS (loop_vinfo);\n-      internal_fn cond_fn = get_conditional_internal_fn (code);\n+      internal_fn cond_fn = get_conditional_internal_fn (op.code, op.type);\n \n       if (reduction_type != FOLD_LEFT_REDUCTION\n-\t  && !use_mask_by_cond_expr_p (code, cond_fn, vectype_in)\n+\t  && !use_mask_by_cond_expr_p (op.code, cond_fn, vectype_in)\n \t  && (cond_fn == IFN_LAST\n \t      || !direct_internal_fn_supported_p (cond_fn, vectype_in,\n \t\t\t\t\t\t  OPTIMIZE_FOR_SPEED)))\n@@ -7305,24 +7299,11 @@ vect_transform_reduction (loop_vec_info loop_vinfo,\n       gcc_assert (STMT_VINFO_DEF_TYPE (reduc_info) == vect_double_reduction_def);\n     }\n \n-  gassign *stmt = as_a <gassign *> (stmt_info->stmt);\n-  enum tree_code code = gimple_assign_rhs_code (stmt);\n-  int op_type = TREE_CODE_LENGTH (code);\n-\n-  /* Flatten RHS.  */\n-  tree ops[3];\n-  switch (get_gimple_rhs_class (code))\n-    {\n-    case GIMPLE_TERNARY_RHS:\n-      ops[2] = gimple_assign_rhs3 (stmt);\n-      /* Fall thru.  */\n-    case GIMPLE_BINARY_RHS:\n-      ops[0] = gimple_assign_rhs1 (stmt);\n-      ops[1] = gimple_assign_rhs2 (stmt);\n-      break;\n-    default:\n-      gcc_unreachable ();\n-    }\n+  gimple_match_op op;\n+  if (!gimple_extract_op (stmt_info->stmt, &op))\n+    gcc_unreachable ();\n+  gcc_assert (op.code.is_tree_code ());\n+  auto code = tree_code (op.code);\n \n   /* All uses but the last are expected to be defined in the loop.\n      The last use is the reduction variable.  In case of nested cycle this\n@@ -7370,7 +7351,7 @@ vect_transform_reduction (loop_vec_info loop_vinfo,\n       internal_fn reduc_fn = STMT_VINFO_REDUC_FN (reduc_info);\n       return vectorize_fold_left_reduction\n \t  (loop_vinfo, stmt_info, gsi, vec_stmt, slp_node, reduc_def_phi, code,\n-\t   reduc_fn, ops, vectype_in, reduc_index, masks);\n+\t   reduc_fn, op.ops, vectype_in, reduc_index, masks);\n     }\n \n   bool single_defuse_cycle = STMT_VINFO_FORCE_SINGLE_CYCLE (reduc_info);\n@@ -7380,22 +7361,22 @@ vect_transform_reduction (loop_vec_info loop_vinfo,\n \t      || code == SAD_EXPR);\n \n   /* Create the destination vector  */\n-  tree scalar_dest = gimple_assign_lhs (stmt);\n+  tree scalar_dest = gimple_assign_lhs (stmt_info->stmt);\n   tree vec_dest = vect_create_destination_var (scalar_dest, vectype_out);\n \n   vect_get_vec_defs (loop_vinfo, stmt_info, slp_node, ncopies,\n \t\t     single_defuse_cycle && reduc_index == 0\n-\t\t     ? NULL_TREE : ops[0], &vec_oprnds0,\n+\t\t     ? NULL_TREE : op.ops[0], &vec_oprnds0,\n \t\t     single_defuse_cycle && reduc_index == 1\n-\t\t     ? NULL_TREE : ops[1], &vec_oprnds1,\n-\t\t     op_type == ternary_op\n+\t\t     ? NULL_TREE : op.ops[1], &vec_oprnds1,\n+\t\t     op.num_ops == 3\n \t\t     && !(single_defuse_cycle && reduc_index == 2)\n-\t\t     ? ops[2] : NULL_TREE, &vec_oprnds2);\n+\t\t     ? op.ops[2] : NULL_TREE, &vec_oprnds2);\n   if (single_defuse_cycle)\n     {\n       gcc_assert (!slp_node);\n       vect_get_vec_defs_for_operand (loop_vinfo, stmt_info, 1,\n-\t\t\t\t     ops[reduc_index],\n+\t\t\t\t     op.ops[reduc_index],\n \t\t\t\t     reduc_index == 0 ? &vec_oprnds0\n \t\t\t\t     : (reduc_index == 1 ? &vec_oprnds1\n \t\t\t\t\t: &vec_oprnds2));\n@@ -7425,7 +7406,7 @@ vect_transform_reduction (loop_vec_info loop_vinfo,\n \t}\n       else\n \t{\n-\t  if (op_type == ternary_op)\n+\t  if (op.num_ops == 3)\n \t    vop[2] = vec_oprnds2[i];\n \n \t  if (masked_loop_p && mask_by_cond_expr)\n@@ -7557,7 +7538,7 @@ vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n \t    {\n \t      tree initial_value\n \t\t= (num_phis == 1 ? initial_values[0] : NULL_TREE);\n-\t      tree_code code = STMT_VINFO_REDUC_CODE (reduc_info);\n+\t      code_helper code = STMT_VINFO_REDUC_CODE (reduc_info);\n \t      tree neutral_op\n \t\t= neutral_op_for_reduction (TREE_TYPE (vectype_out),\n \t\t\t\t\t    code, initial_value);\n@@ -7614,7 +7595,7 @@ vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n \t  if (!reduc_info->reduc_initial_values.is_empty ())\n \t    {\n \t      initial_def = reduc_info->reduc_initial_values[0];\n-\t      enum tree_code code = STMT_VINFO_REDUC_CODE (reduc_info);\n+\t      code_helper code = STMT_VINFO_REDUC_CODE (reduc_info);\n \t      tree neutral_op\n \t\t= neutral_op_for_reduction (TREE_TYPE (initial_def),\n \t\t\t\t\t    code, initial_def);\n@@ -7912,6 +7893,15 @@ vect_can_vectorize_without_simd_p (tree_code code)\n     }\n }\n \n+/* Likewise, but taking a code_helper.  */\n+\n+bool\n+vect_can_vectorize_without_simd_p (code_helper code)\n+{\n+  return (code.is_tree_code ()\n+\t  && vect_can_vectorize_without_simd_p (tree_code (code)));\n+}\n+\n /* Function vectorizable_induction\n \n    Check if STMT_INFO performs an induction computation that can be vectorized."}, {"sha": "26421ee5511b90702b0e80fe04c88db29f470d8b", "filename": "gcc/tree-vect-patterns.c", "status": "modified", "additions": 13, "deletions": 10, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vect-patterns.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vect-patterns.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-patterns.c?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -5594,8 +5594,10 @@ vect_mark_pattern_stmts (vec_info *vinfo,\n   /* Transfer reduction path info to the pattern.  */\n   if (STMT_VINFO_REDUC_IDX (orig_stmt_info_saved) != -1)\n     {\n-      tree lookfor = gimple_op (orig_stmt_info_saved->stmt,\n-\t\t\t\t1 + STMT_VINFO_REDUC_IDX (orig_stmt_info));\n+      gimple_match_op op;\n+      if (!gimple_extract_op (orig_stmt_info_saved->stmt, &op))\n+\tgcc_unreachable ();\n+      tree lookfor = op.ops[STMT_VINFO_REDUC_IDX (orig_stmt_info)];\n       /* Search the pattern def sequence and the main pattern stmt.  Note\n          we may have inserted all into a containing pattern def sequence\n \t so the following is a bit awkward.  */\n@@ -5615,14 +5617,15 @@ vect_mark_pattern_stmts (vec_info *vinfo,\n       do\n \t{\n \t  bool found = false;\n-\t  for (unsigned i = 1; i < gimple_num_ops (s); ++i)\n-\t    if (gimple_op (s, i) == lookfor)\n-\t      {\n-\t\tSTMT_VINFO_REDUC_IDX (vinfo->lookup_stmt (s)) = i - 1;\n-\t\tlookfor = gimple_get_lhs (s);\n-\t\tfound = true;\n-\t\tbreak;\n-\t      }\n+\t  if (gimple_extract_op (s, &op))\n+\t    for (unsigned i = 0; i < op.num_ops; ++i)\n+\t      if (op.ops[i] == lookfor)\n+\t\t{\n+\t\t  STMT_VINFO_REDUC_IDX (vinfo->lookup_stmt (s)) = i;\n+\t\t  lookfor = gimple_get_lhs (s);\n+\t\t  found = true;\n+\t\t  break;\n+\t\t}\n \t  if (s == pattern_stmt)\n \t    {\n \t      if (!found && dump_enabled_p ())"}, {"sha": "101f61feff604f5c184cc486b4079c1a8ce9599a", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 54, "deletions": 12, "changes": 66, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -3202,7 +3202,6 @@ vectorizable_call (vec_info *vinfo,\n   int ndts = ARRAY_SIZE (dt);\n   int ncopies, j;\n   auto_vec<tree, 8> vargs;\n-  auto_vec<tree, 8> orig_vargs;\n   enum { NARROW, NONE, WIDEN } modifier;\n   size_t i, nargs;\n   tree lhs;\n@@ -3426,6 +3425,8 @@ vectorizable_call (vec_info *vinfo,\n      needs to be generated.  */\n   gcc_assert (ncopies >= 1);\n \n+  int reduc_idx = STMT_VINFO_REDUC_IDX (stmt_info);\n+  internal_fn cond_fn = get_conditional_internal_fn (ifn);\n   vec_loop_masks *masks = (loop_vinfo ? &LOOP_VINFO_MASKS (loop_vinfo) : NULL);\n   if (!vec_stmt) /* transformation not required.  */\n     {\n@@ -3446,14 +3447,33 @@ vectorizable_call (vec_info *vinfo,\n \trecord_stmt_cost (cost_vec, ncopies / 2,\n \t\t\t  vec_promote_demote, stmt_info, 0, vect_body);\n \n-      if (loop_vinfo && mask_opno >= 0)\n+      if (loop_vinfo\n+\t  && LOOP_VINFO_CAN_USE_PARTIAL_VECTORS_P (loop_vinfo)\n+\t  && (reduc_idx >= 0 || mask_opno >= 0))\n \t{\n-\t  unsigned int nvectors = (slp_node\n-\t\t\t\t   ? SLP_TREE_NUMBER_OF_VEC_STMTS (slp_node)\n-\t\t\t\t   : ncopies);\n-\t  tree scalar_mask = gimple_call_arg (stmt_info->stmt, mask_opno);\n-\t  vect_record_loop_mask (loop_vinfo, masks, nvectors,\n-\t\t\t\t vectype_out, scalar_mask);\n+\t  if (reduc_idx >= 0\n+\t      && (cond_fn == IFN_LAST\n+\t\t  || !direct_internal_fn_supported_p (cond_fn, vectype_out,\n+\t\t\t\t\t\t      OPTIMIZE_FOR_SPEED)))\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\tdump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n+\t\t\t\t \"can't use a fully-masked loop because no\"\n+\t\t\t\t \" conditional operation is available.\\n\");\n+\t      LOOP_VINFO_CAN_USE_PARTIAL_VECTORS_P (loop_vinfo) = false;\n+\t    }\n+\t  else\n+\t    {\n+\t      unsigned int nvectors\n+\t\t= (slp_node\n+\t\t   ? SLP_TREE_NUMBER_OF_VEC_STMTS (slp_node)\n+\t\t   : ncopies);\n+\t      tree scalar_mask = NULL_TREE;\n+\t      if (mask_opno >= 0)\n+\t\tscalar_mask = gimple_call_arg (stmt_info->stmt, mask_opno);\n+\t      vect_record_loop_mask (loop_vinfo, masks, nvectors,\n+\t\t\t\t     vectype_out, scalar_mask);\n+\t    }\n \t}\n       return true;\n     }\n@@ -3468,12 +3488,17 @@ vectorizable_call (vec_info *vinfo,\n   vec_dest = vect_create_destination_var (scalar_dest, vectype_out);\n \n   bool masked_loop_p = loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo);\n+  unsigned int vect_nargs = nargs;\n+  if (masked_loop_p && reduc_idx >= 0)\n+    {\n+      ifn = cond_fn;\n+      vect_nargs += 2;\n+    }\n \n   if (modifier == NONE || ifn != IFN_LAST)\n     {\n       tree prev_res = NULL_TREE;\n-      vargs.safe_grow (nargs, true);\n-      orig_vargs.safe_grow (nargs, true);\n+      vargs.safe_grow (vect_nargs, true);\n       auto_vec<vec<tree> > vec_defs (nargs);\n       for (j = 0; j < ncopies; ++j)\n \t{\n@@ -3488,12 +3513,23 @@ vectorizable_call (vec_info *vinfo,\n \t      /* Arguments are ready.  Create the new vector stmt.  */\n \t      FOR_EACH_VEC_ELT (vec_oprnds0, i, vec_oprnd0)\n \t\t{\n+\t\t  int varg = 0;\n+\t\t  if (masked_loop_p && reduc_idx >= 0)\n+\t\t    {\n+\t\t      unsigned int vec_num = vec_oprnds0.length ();\n+\t\t      /* Always true for SLP.  */\n+\t\t      gcc_assert (ncopies == 1);\n+\t\t      vargs[varg++] = vect_get_loop_mask (gsi, masks, vec_num,\n+\t\t\t\t\t\t\t  vectype_out, i);\n+\t\t    }\n \t\t  size_t k;\n \t\t  for (k = 0; k < nargs; k++)\n \t\t    {\n \t\t      vec<tree> vec_oprndsk = vec_defs[k];\n-\t\t      vargs[k] = vec_oprndsk[i];\n+\t\t      vargs[varg++] = vec_oprndsk[i];\n \t\t    }\n+\t\t  if (masked_loop_p && reduc_idx >= 0)\n+\t\t    vargs[varg++] = vargs[reduc_idx + 1];\n \t\t  gimple *new_stmt;\n \t\t  if (modifier == NARROW)\n \t\t    {\n@@ -3546,6 +3582,10 @@ vectorizable_call (vec_info *vinfo,\n \t      continue;\n \t    }\n \n+\t  int varg = 0;\n+\t  if (masked_loop_p && reduc_idx >= 0)\n+\t    vargs[varg++] = vect_get_loop_mask (gsi, masks, ncopies,\n+\t\t\t\t\t\tvectype_out, j);\n \t  for (i = 0; i < nargs; i++)\n \t    {\n \t      op = gimple_call_arg (stmt, i);\n@@ -3556,8 +3596,10 @@ vectorizable_call (vec_info *vinfo,\n \t\t\t\t\t\t op, &vec_defs[i],\n \t\t\t\t\t\t vectypes[i]);\n \t\t}\n-\t      orig_vargs[i] = vargs[i] = vec_defs[i][j];\n+\t      vargs[varg++] = vec_defs[i][j];\n \t    }\n+\t  if (masked_loop_p && reduc_idx >= 0)\n+\t    vargs[varg++] = vargs[reduc_idx + 1];\n \n \t  if (mask_opno >= 0 && masked_loop_p)\n \t    {"}, {"sha": "0eb13d6cc74fc70272f3c9cdaa018252817bf2de", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30213ae9a2eb53f6bc0913919457ceae2572b019/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=30213ae9a2eb53f6bc0913919457ceae2572b019", "patch": "@@ -28,6 +28,7 @@ typedef class _stmt_vec_info *stmt_vec_info;\n #include \"target.h\"\n #include \"internal-fn.h\"\n #include \"tree-ssa-operands.h\"\n+#include \"gimple-match.h\"\n \n /* Used for naming of new temporaries.  */\n enum vect_var_kind {\n@@ -1196,7 +1197,7 @@ class _stmt_vec_info {\n   enum vect_reduction_type reduc_type;\n \n   /* The original reduction code, to be used in the epilogue.  */\n-  enum tree_code reduc_code;\n+  code_helper reduc_code;\n   /* An internal function we should use in the epilogue.  */\n   internal_fn reduc_fn;\n \n@@ -2155,7 +2156,7 @@ extern tree vect_create_addr_base_for_vector_ref (vec_info *,\n \t\t\t\t\t\t  tree);\n \n /* In tree-vect-loop.c.  */\n-extern tree neutral_op_for_reduction (tree, tree_code, tree);\n+extern tree neutral_op_for_reduction (tree, code_helper, tree);\n extern widest_int vect_iv_limit_for_partial_vectors (loop_vec_info loop_vinfo);\n bool vect_rgroup_iv_might_wrap_p (loop_vec_info, rgroup_controls *);\n /* Used in tree-vect-loop-manip.c */\n@@ -2164,7 +2165,7 @@ extern opt_result vect_determine_partial_vectors_and_peeling (loop_vec_info,\n /* Used in gimple-loop-interchange.c and tree-parloops.c.  */\n extern bool check_reduction_path (dump_user_location_t, loop_p, gphi *, tree,\n \t\t\t\t  enum tree_code);\n-extern bool needs_fold_left_reduction_p (tree, tree_code);\n+extern bool needs_fold_left_reduction_p (tree, code_helper);\n /* Drive for loop analysis stage.  */\n extern opt_loop_vec_info vect_analyze_loop (class loop *, vec_info_shared *);\n extern tree vect_build_loop_niters (loop_vec_info, bool * = NULL);\n@@ -2182,7 +2183,7 @@ extern tree vect_get_loop_len (loop_vec_info, vec_loop_lens *, unsigned int,\n \t\t\t       unsigned int);\n extern gimple_seq vect_gen_len (tree, tree, tree, tree);\n extern stmt_vec_info info_for_reduction (vec_info *, stmt_vec_info);\n-extern bool reduction_fn_for_scalar_code (enum tree_code, internal_fn *);\n+extern bool reduction_fn_for_scalar_code (code_helper, internal_fn *);\n \n /* Drive for loop transformation stage.  */\n extern class loop *vect_transform_loop (loop_vec_info, gimple *);\n@@ -2220,6 +2221,7 @@ extern bool vectorizable_phi (vec_info *, stmt_vec_info, gimple **, slp_tree,\n \t\t\t      stmt_vector_for_cost *);\n extern bool vect_emulated_vector_p (tree);\n extern bool vect_can_vectorize_without_simd_p (tree_code);\n+extern bool vect_can_vectorize_without_simd_p (code_helper);\n extern int vect_get_known_peeling_cost (loop_vec_info, int, int *,\n \t\t\t\t\tstmt_vector_for_cost *,\n \t\t\t\t\tstmt_vector_for_cost *,"}]}