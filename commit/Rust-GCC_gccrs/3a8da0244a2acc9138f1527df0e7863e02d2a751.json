{"sha": "3a8da0244a2acc9138f1527df0e7863e02d2a751", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6M2E4ZGEwMjQ0YTJhY2M5MTM4ZjE1MjdkZjBlNzg2M2UwMmQyYTc1MQ==", "commit": {"author": {"name": "Hans Boehm", "email": "Hans_Boehm@hp.com", "date": "2001-10-15T22:42:42Z"}, "committer": {"name": "Tom Tromey", "email": "tromey@gcc.gnu.org", "date": "2001-10-15T22:42:42Z"}, "message": "natObject.cc (heavy_lock): Moved fields old_client_data, old_finalization_proc near beginning.\n\n2001-10-15  Hans Boehm <Hans_Boehm@hp.com>\n\n\t* java/lang/natObject.cc (heavy_lock): Moved fields\n\told_client_data, old_finalization_proc near beginning.\n\t(heavy_lock_finalization_proc): Now inline; changed type of\n\targument.\n\t(JV_SYNC_TABLE_SZ): Now 2048.\n\t(mp): New global.\n\t(spin): `mp' now global.\n\t(heavy_lock_obj_finalization_proc): Updated to correctly handle\n\theavy lock finalization.\n\t(remove_all_heavy): New function.\n\t(maybe_remove_all_heavy): Likewise.\n\t(_Jv_MonitorEnter): Throw exception if object is NULL.\n\t(_Jv_MonitorExit): Likewise.  Also, clear long lists of unlocked\n\theavy locks.\n\t* include/jvm.h (_Jv_AllocTraceTwo): Declare.\n\t* nogc.cc (_Jv_AllocTraceTwo): New function.\n\t* boehm.cc (trace_two_vtable): New global.\n\t(_Jv_AllocTraceTwo): New function.\n\nFrom-SVN: r46271", "tree": {"sha": "7962cc125d2501ecf65b98628a06f1c18b66fba4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7962cc125d2501ecf65b98628a06f1c18b66fba4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/3a8da0244a2acc9138f1527df0e7863e02d2a751", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3a8da0244a2acc9138f1527df0e7863e02d2a751", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3a8da0244a2acc9138f1527df0e7863e02d2a751", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3a8da0244a2acc9138f1527df0e7863e02d2a751/comments", "author": null, "committer": null, "parents": [{"sha": "c83303d8a41d46d1ee24fa49347a24bb2f28fe9d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c83303d8a41d46d1ee24fa49347a24bb2f28fe9d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c83303d8a41d46d1ee24fa49347a24bb2f28fe9d"}], "stats": {"total": 261, "additions": 228, "deletions": 33}, "files": [{"sha": "ea2a3555122f0d72c8b54ae20b5dd7de4d84b9db", "filename": "libjava/ChangeLog", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libjava%2FChangeLog?ref=3a8da0244a2acc9138f1527df0e7863e02d2a751", "patch": "@@ -1,3 +1,24 @@\n+2001-10-15  Hans Boehm <Hans_Boehm@hp.com>\n+\n+\t* java/lang/natObject.cc (heavy_lock): Moved fields\n+\told_client_data, old_finalization_proc near beginning.\n+\t(heavy_lock_finalization_proc): Now inline; changed type of\n+\targument.\n+\t(JV_SYNC_TABLE_SZ): Now 2048.\n+\t(mp): New global.\n+\t(spin): `mp' now global.\n+\t(heavy_lock_obj_finalization_proc): Updated to correctly handle\n+\theavy lock finalization.\n+\t(remove_all_heavy): New function.\n+\t(maybe_remove_all_heavy): Likewise.\n+\t(_Jv_MonitorEnter): Throw exception if object is NULL.\n+\t(_Jv_MonitorExit): Likewise.  Also, clear long lists of unlocked\n+\theavy locks.\n+\t* include/jvm.h (_Jv_AllocTraceTwo): Declare.\n+\t* nogc.cc (_Jv_AllocTraceTwo): New function.\n+\t* boehm.cc (trace_two_vtable): New global.\n+\t(_Jv_AllocTraceTwo): New function.\n+\n 2001-10-15  Tom Tromey  <tromey@redhat.com>\n \n \t* Makefile.in: Rebuilt."}, {"sha": "ed780e2a5c5b4a9d1f2d61186d5fc6f434ac0799", "filename": "libjava/boehm.cc", "status": "modified", "additions": 19, "deletions": 1, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Fboehm.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Fboehm.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libjava%2Fboehm.cc?ref=3a8da0244a2acc9138f1527df0e7863e02d2a751", "patch": "@@ -531,7 +531,7 @@ static _Jv_VTable trace_one_vtable = {\n     (void *)(2 * sizeof(void *)),\n \t\t\t// descriptor; scan 2 words incl. vtable ptr.\n \t\t\t// Least significant bits must be zero to\n-\t\t\t// identify this as a lenght descriptor\n+\t\t\t// identify this as a length descriptor\n     {0}\t\t\t// First method\n };\n \n@@ -541,6 +541,24 @@ _Jv_AllocTraceOne (jsize size /* includes vtable slot */)\n   return GC_GCJ_MALLOC (size, &trace_one_vtable);\n }\n \n+// Ditto for two words.\n+// the first field (beyond the fake vtable pointer) to be traced.\n+// Eventually this should probably be generalized.\n+\n+static _Jv_VTable trace_two_vtable =\n+{\n+  0, \t\t\t// class pointer\n+  (void *)(3 * sizeof(void *)),\n+\t\t\t// descriptor; scan 3 words incl. vtable ptr.\n+  {0}\t\t\t// First method\n+};\n+\n+void *\n+_Jv_AllocTraceTwo (jsize size /* includes vtable slot */) \n+{\n+  return GC_GCJ_MALLOC (size, &trace_two_vtable);\n+}\n+\n #endif /* JV_HASH_SYNCHRONIZATION */\n \n void"}, {"sha": "27a1c6f3223f7857c707ee93d613dde910c67849", "filename": "libjava/include/jvm.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Finclude%2Fjvm.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Finclude%2Fjvm.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libjava%2Finclude%2Fjvm.h?ref=3a8da0244a2acc9138f1527df0e7863e02d2a751", "patch": "@@ -144,6 +144,8 @@ void _Jv_ThrowNoMemory() __attribute__((__noreturn__));\n /* Allocate an object with a single pointer.  The first word is reserved\n    for the GC, and the second word is the traced pointer.  */\n void *_Jv_AllocTraceOne (jsize size /* incl. reserved slot */);\n+/* Ditto, but for two traced pointers.\t\t\t   */\n+void *_Jv_AllocTraceTwo (jsize size /* incl. reserved slot */);\n /* Initialize the GC.  */\n void _Jv_InitGC (void);\n /* Register a finalizer.  */"}, {"sha": "17d8dbc8cfb0d4f2e3a9406a4badf80f42d7de41", "filename": "libjava/java/lang/natObject.cc", "status": "modified", "additions": 178, "deletions": 32, "changes": 210, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Fjava%2Flang%2FnatObject.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Fjava%2Flang%2FnatObject.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libjava%2Fjava%2Flang%2FnatObject.cc?ref=3a8da0244a2acc9138f1527df0e7863e02d2a751", "patch": "@@ -466,15 +466,20 @@ keep_live(obj_addr_t p)\n struct heavy_lock {\n   void * reserved_for_gc;\n   struct heavy_lock *next;\t// Hash chain link.\n-\t\t\t\t// The only field traced by GC.\n+\t\t\t\t// Traced by GC.\n+  void * old_client_data;\t// The only other field traced by GC.\n+  GC_finalization_proc old_finalization_proc;\n   obj_addr_t address;\t\t// Object to which this lock corresponds.\n \t\t\t\t// Should not be traced by GC.\n+  \t\t\t\t// Cleared as heavy_lock is destroyed.\n+  \t\t\t\t// Together with the rest of the hevy lock\n+  \t\t\t\t// chain, this is protected by the lock\n+  \t\t\t\t// bit in the hash table entry to which\n+  \t\t\t\t// the chain is attached.\n   _Jv_SyncInfo si;\n   // The remaining fields save prior finalization info for\n   // the object, which we needed to replace in order to arrange\n   // for cleanup of the lock structure.\n-  GC_finalization_proc old_finalization_proc;\n-  void * old_client_data;\n };\n \n #ifdef LOCK_DEBUG\n@@ -489,11 +494,11 @@ print_hl_list(heavy_lock *hl)\n \n #if defined (_Jv_HaveCondDestroy) || defined (_Jv_HaveMutexDestroy)\n // If we have to run a destructor for a sync_info member, then this\n-// function is registered as a finalizer for the sync_info.\n-static void\n-heavy_lock_finalization_proc (jobject obj)\n+// function could be registered as a finalizer for the sync_info.\n+// In fact, we now only invoke it explicitly.\n+static inline void\n+heavy_lock_finalization_proc (heavy_lock *hl)\n {\n-  heavy_lock *hl = (heavy_lock *) obj;\n #if defined (_Jv_HaveCondDestroy)\n   _Jv_CondDestroy (&hl->si.condition);\n #endif\n@@ -567,19 +572,34 @@ struct hash_entry {\n   \t\t\t\t// by lockbit for he.  Locks may\n   \t\t\t\t// remain allocated here even if HEAVY\n   \t\t\t\t// is not set and heavy_count is 0.\n-  \t\t\t\t// If a lightweight and hevyweight lock\n+  \t\t\t\t// If a lightweight and heavyweight lock\n   \t\t\t\t// correspond to the same address, the\n   \t\t\t\t// lightweight lock is the right one.\n };\n \n #ifndef JV_SYNC_TABLE_SZ\n-# define JV_SYNC_TABLE_SZ 1024\n+# define JV_SYNC_TABLE_SZ 2048\n #endif\n \n hash_entry light_locks[JV_SYNC_TABLE_SZ];\n \n #define JV_SYNC_HASH(p) (((long)p ^ ((long)p >> 10)) % JV_SYNC_TABLE_SZ)\n \n+// Note that the light_locks table is scanned conservatively by the\n+// collector.  It is essential the the heavy_locks field is scanned.\n+// Currently the address field may or may not cause the associated object\n+// to be retained, depending on whether flag bits are set.\n+// This means that we can conceivable get an unexpected deadlock if\n+// 1) Object at address A is locked.\n+// 2) The client drops A without unlocking it.\n+// 3) Flag bits in the address entry are set, so the collector reclaims\n+//    the object at A.\n+// 4) A is reallocated, and an attempt is made to lock the result.\n+// This could be fixed by scanning light_locks in a more customized\n+// manner that ignores the flag bits.  But it can only happen with hand\n+// generated semi-illegal .class files, and then it doesn't present a\n+// security hole.\n+\n #ifdef LOCK_DEBUG\n   void print_he(hash_entry *he)\n   {\n@@ -593,6 +613,8 @@ hash_entry light_locks[JV_SYNC_TABLE_SZ];\n   }\n #endif /* LOCK_DEBUG */\n \n+static bool mp = false; // Known multiprocesssor.\n+\n // Wait for roughly 2^n units, touching as little memory as possible.\n static void\n spin(unsigned n)\n@@ -604,7 +626,6 @@ spin(unsigned n)\n   const unsigned MAX_SLEEP_USECS = 200000;\n   static unsigned spin_limit = 0;\n   static unsigned yield_limit = YIELDS;\n-  static bool mp = false;\n   static bool spin_initialized = false;\n \n   if (!spin_initialized)\n@@ -675,9 +696,29 @@ heavy_lock_obj_finalization_proc (void *obj, void *cd)\n {\n   heavy_lock *hl = (heavy_lock *)cd;\n   obj_addr_t addr = (obj_addr_t)obj;\n+  hash_entry *he = light_locks + JV_SYNC_HASH(addr);\n+  obj_addr_t he_address = (he -> address & ~LOCKED);\n+\n+  // Acquire lock bit immediately.  It's possible that the hl was already\n+  // destroyed while we were waiting for the finalizer to run.  If it\n+  // was, the address field was set to zero.  The address filed access is\n+  // protected by the lock bit to ensure that we do this exactly once.\n+  // The lock bit also protects updates to the objects finalizer.\n+  while (!compare_and_swap(&(he -> address), he_address, he_address|LOCKED ))\n+    {\n+      // Hash table entry is currently locked.  We can't safely \n+      // touch the list of heavy locks.  \n+      wait_unlocked(he);\n+      he_address = (he -> address & ~LOCKED);\n+    }\n+  if (0 == hl -> address)\n+    {\n+      // remove_all_heavy destroyed hl, and took care of the real finalizer.\n+      release_set(&(he -> address), he_address);\n+      return;\n+    }\n+  assert(hl -> address == addr);\n   GC_finalization_proc old_finalization_proc = hl -> old_finalization_proc;\n-  void * old_client_data = hl -> old_client_data;\n-\n   if (old_finalization_proc != 0)\n     {\n       // We still need to run a real finalizer.  In an idealized\n@@ -686,48 +727,119 @@ heavy_lock_obj_finalization_proc (void *obj, void *cd)\n       // ourselves as the only finalizer, and simply run the real one.\n       // Thus we don't clean up the lock yet, but we're likely to do so\n       // on the next GC cycle.\n+      // It's OK if remove_all_heavy actually destroys the heavy lock,\n+      // since we've updated old_finalization_proc, and thus the user's\n+      // finalizer won't be rerun.\n+      void * old_client_data = hl -> old_client_data;\n       hl -> old_finalization_proc = 0;\n       hl -> old_client_data = 0;\n #     ifdef HAVE_BOEHM_GC\n         GC_REGISTER_FINALIZER_NO_ORDER(obj, heavy_lock_obj_finalization_proc, cd, 0, 0);\n #     endif\n+      release_set(&(he -> address), he_address);\n       old_finalization_proc(obj, old_client_data);\n     }\n   else\n     {\n       // The object is really dead, although it's conceivable that\n       // some thread may still be in the process of releasing the\n       // heavy lock.  Unlink it and, if necessary, register a finalizer\n-      // to distroy sync_info.\n-      hash_entry *he = light_locks + JV_SYNC_HASH(addr);\n-      obj_addr_t address = (he -> address & ~LOCKED);\n-      while (!compare_and_swap(&(he -> address), address, address | LOCKED ))\n-\t{\n-\t  // Hash table entry is currently locked.  We can't safely touch\n-\t  // touch the list of heavy locks.  \n-\t  wait_unlocked(he);\n-\t  address = (he -> address & ~LOCKED);\n-\t}\n-      unlink_heavy(addr, light_locks + JV_SYNC_HASH(addr));\n-      release_set(&(he -> address), address);\n+      // to destroy sync_info.\n+      unlink_heavy(addr, he);\n+      hl -> address = 0; \t// Dont destroy it again.\n+      release_set(&(he -> address), he_address);\n #     if defined (_Jv_HaveCondDestroy) || defined (_Jv_HaveMutexDestroy)\n-        // Register a finalizer, yet again.\n-          hl->si.init = true;\n-          _Jv_RegisterFinalizer (hl, heavy_lock_finalization_proc);\n+        // Make sure lock is not held and then destroy condvar and mutex.\n+        _Jv_MutexLock(&(hl->si.mutex));\n+        _Jv_MutexUnlock(&(hl->si.mutex));\n+        heavy_lock_finalization_proc (hl);\n #     endif\n     }\n }\n \n+// We hold the lock on he, and heavy_count is 0.\n+// Release the lock by replacing the address with new_address_val.\n+// Remove all heavy locks on the list.  Note that the only possible way\n+// in which a lock may still be in use is if it's in the process of\n+// being unlocked.\n+static void\n+remove_all_heavy (hash_entry *he, obj_addr_t new_address_val)\n+{\n+  assert(he -> heavy_count == 0);\n+  assert(he -> address & LOCKED);\n+  heavy_lock *hl = he -> heavy_locks;\n+  he -> heavy_locks = 0;\n+  // We would really like to release the lock bit here.  Unfortunately, that\n+  // Creates a race between or finalizer removal, and the potential\n+  // reinstallation of a new finalizer as a new heavy lock is created.\n+  // This may need to be revisited.\n+  for(; 0 != hl; hl = hl->next)\n+    {\n+      obj_addr_t obj = hl -> address;\n+      assert(0 != obj);\t// If this was previously finalized, it should no\n+      \t\t\t// longer appear on our list.\n+      hl -> address = 0; // Finalization proc might still see it after we\n+      \t\t\t // finish.\n+      GC_finalization_proc old_finalization_proc = hl -> old_finalization_proc;\n+      void * old_client_data = hl -> old_client_data;\n+#     ifdef HAVE_BOEHM_GC\n+\t// Remove our finalization procedure.\n+        // Reregister the clients if applicable.\n+          GC_REGISTER_FINALIZER_NO_ORDER((GC_PTR)obj, old_finalization_proc,\n+\t\t\t  \t\t old_client_data, 0, 0);\n+      \t  // Note that our old finalization procedure may have been\n+          // previously determined to be runnable, and may still run.\n+      \t  // FIXME - direct dependency on boehm GC.\n+#     endif\n+#     if defined (_Jv_HaveCondDestroy) || defined (_Jv_HaveMutexDestroy)\n+        // Wait for a possible lock holder to finish unlocking it.\n+        // This is only an issue if we have to explicitly destroy the mutex\n+        // or possibly if we have to destroy a condition variable that is\n+        // still being notified.\n+          _Jv_MutexLock(&(hl->si.mutex));\n+          _Jv_MutexUnlock(&(hl->si.mutex));\n+          heavy_lock_finalization_proc (hl);\n+#     endif\n+    }\n+  release_set(&(he -> address), new_address_val);\n+}\n+\n+// We hold the lock on he and heavy_count is 0.\n+// We release it by replacing the address field with new_address_val.\n+// Remove all heavy locks on the list if the list is sufficiently long.\n+// This is called periodically to avoid very long lists of heavy locks.\n+// This seems to otherwise become an issue with SPECjbb, for example.\n+static inline void\n+maybe_remove_all_heavy (hash_entry *he, obj_addr_t new_address_val)\n+{\n+  static const int max_len = 5;\n+  heavy_lock *hl = he -> heavy_locks;\n+\n+  for (int i = 0; i < max_len; ++i)\n+    {\n+      if (0 == hl) \n+\t{\n+  \t  release_set(&(he -> address), new_address_val);\n+\t  return;\n+\t}\n+      hl = hl -> next;\n+    }\n+  remove_all_heavy(he, new_address_val);\n+}\n+\n // Allocate a new heavy lock for addr, returning its address.\n // Assumes we already have the hash_entry locked, and there\n // is currently no lightweight or allocated lock for addr.\n // We register a finalizer for addr, which is responsible for\n // removing the heavy lock when addr goes away, in addition\n // to the responsibilities of any prior finalizer.\n+// This unfortunately holds the lock bit for the hash entry while it\n+// allocates two objects (on for the finalizer).\n+// It would be nice to avoid that somehow ...\n static heavy_lock *\n alloc_heavy(obj_addr_t addr, hash_entry *he)\n {\n-  heavy_lock * hl = (heavy_lock *) _Jv_AllocTraceOne(sizeof (heavy_lock));\n+  heavy_lock * hl = (heavy_lock *) _Jv_AllocTraceTwo(sizeof (heavy_lock));\n   \n   hl -> address = addr;\n   _Jv_MutexInit (&(hl -> si.mutex));\n@@ -770,6 +882,14 @@ _Jv_MonitorEnter (jobject obj)\n   unsigned count;\n   const unsigned N_SPINS = 18;\n \n+  // We need to somehow check that addr is not NULL on the fast path.\n+  // A very predictable\n+  // branch on a register value is probably cheaper than dereferencing addr.\n+  // We could also permanently lock the NULL entry in the hash table.\n+  // But it's not clear that's cheaper either.\n+  if (__builtin_expect(!addr, false))\n+    throw new java::lang::NullPointerException;\n+   \n   assert(!(addr & FLAGS));\n retry:\n   if (__builtin_expect(compare_and_swap(&(he -> address),\n@@ -912,10 +1032,11 @@ _Jv_MonitorExit (jobject obj)\n   // Unfortunately, it turns out we always need to read the address\n   // first.  Even if we are going to update it with compare_and_swap,\n   // we need to reset light_thr_id, and that's not safe unless we know\n-  // know that we hold the lock.\n+  // that we hold the lock.\n   address = he -> address;\n   // First the (relatively) fast cases:\n   if (__builtin_expect(light_thr_id == self, true))\n+    // Above must fail if addr == 0 .\n     {\n       count = he -> light_count;\n       if (__builtin_expect((address & ~HEAVY) == addr, true))\n@@ -946,6 +1067,8 @@ _Jv_MonitorExit (jobject obj)\n     }\n   else\n     {\n+      if (__builtin_expect(!addr, false))\n+\tthrow new java::lang::NullPointerException;\n       if ((address & ~(HEAVY | REQUEST_CONVERSION)) == addr)\n \t{\n #\t  ifdef LOCK_DEBUG\n@@ -1034,15 +1157,38 @@ _Jv_MonitorExit (jobject obj)\n   count = he -> heavy_count;\n   assert(count > 0);\n   --count;\n-  if (0 == count) address &= ~HEAVY;\n   he -> heavy_count = count;\n-  release_set(&(he -> address), address);\n+  if (0 == count)\n+    {\n+      const unsigned test_freq = 16;  // Power of 2\n+      static volatile unsigned counter = 0;\n+      unsigned my_counter = counter;\n+\n+      counter = my_counter + 1;\n+      if (my_counter%test_freq == 0)\n+\t{\n+\t  // Randomize the interval length a bit.\n+\t    counter = my_counter + (my_counter >> 4) % (test_freq/2);\n+\t  // Unlock mutex first, to avoid self-deadlock, or worse.\n+          _Jv_MutexUnlock(&(hl->si.mutex));\n+\t  maybe_remove_all_heavy(he, address &~HEAVY);\n     \t\t\t\t// release lock bit, preserving\n \t\t\t\t// REQUEST_CONVERSION\n     \t\t\t\t// and object address.\n-  _Jv_MutexUnlock(&(hl->si.mutex));\n+\t}\n+      else\n+        {\n+          release_set(&(he -> address), address &~HEAVY);\n+          _Jv_MutexUnlock(&(hl->si.mutex));\n   \t\t\t// Unlock after releasing the lock bit, so that\n   \t\t\t// we don't switch to another thread prematurely.\n+\t}\n+    } \n+  else\n+    {\n+      release_set(&(he -> address), address);\n+      _Jv_MutexUnlock(&(hl->si.mutex));\n+    }\n   keep_live(addr);\n }     \n "}, {"sha": "daf279c8f8559ec32ce814d04b22f947db00bfa5", "filename": "libjava/nogc.cc", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Fnogc.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3a8da0244a2acc9138f1527df0e7863e02d2a751/libjava%2Fnogc.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libjava%2Fnogc.cc?ref=3a8da0244a2acc9138f1527df0e7863e02d2a751", "patch": "@@ -146,4 +146,12 @@ _Jv_AllocTraceOne (jsize size /* includes vtable slot */)\n   if (!obj) _Jv_ThrowNoMemory();\n   return result;\n }\n+\n+void *\n+_Jv_AllocTraceTwo (jsize size /* includes vtable slot */) \n+{\n+  ptr_t obj = calloc(size, 1);\n+  if (!obj) _Jv_ThrowNoMemory();\n+  return result;\n+}\n #endif /* JV_HASH_SYNCHRONIZATION */"}]}