{"sha": "71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzFmOWE5ZDE1ZTBkZWFhMGI2YjgwZjRhZDE0NmYwODQwY2I0ODNiMA==", "commit": {"author": {"name": "Dhruv Matani", "email": "dhruvbird@gmx.net", "date": "2004-03-24T18:27:43Z"}, "committer": {"name": "Benjamin Kosnik", "email": "bkoz@gcc.gnu.org", "date": "2004-03-24T18:27:43Z"}, "message": "bitmap_allocator.h: (_Bit_scan_forward) -> Made this function call __builtin_ctz instead of the...\n\n\n2004-03-24  Dhruv Matani  <dhruvbird@gmx.net>\n\n\t* include/ext/bitmap_allocator.h: (_Bit_scan_forward) -> Made this\n\tfunction call __builtin_ctz instead of the while loop.\n\t(allocate) -> If condition has __builtin_expect.\n\t(deallocate) -> Ditto.\n\tRenamed a few left-over variables and typedefs according to the\n\tC++STYLE mentioned in the documentation.\n\tProtected calls to __gthread* by __gthread_active_p(), whose value\n\tis cached in the local variable __threads_active.\n\nFrom-SVN: r79924", "tree": {"sha": "de3b26ddbf345f83a698bcc2f4698d42d0a22562", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/de3b26ddbf345f83a698bcc2f4698d42d0a22562"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0/comments", "author": null, "committer": null, "parents": [{"sha": "643d3bd23efc1efa1d64147d0f777e4f0b38dac1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/643d3bd23efc1efa1d64147d0f777e4f0b38dac1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/643d3bd23efc1efa1d64147d0f777e4f0b38dac1"}], "stats": {"total": 251, "additions": 149, "deletions": 102}, "files": [{"sha": "7328e0c1dcfc004982f921b029fe3438fa1bd550", "filename": "libstdc++-v3/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0/libstdc%2B%2B-v3%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0/libstdc%2B%2B-v3%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2FChangeLog?ref=71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0", "patch": "@@ -1,3 +1,14 @@\n+2004-03-24  Dhruv Matani  <dhruvbird@gmx.net>\n+\t\n+\t* include/ext/bitmap_allocator.h: (_Bit_scan_forward) -> Made this\n+\tfunction call __builtin_ctz instead of the while loop.\n+\t(allocate) -> If condition has __builtin_expect.\n+\t(deallocate) -> Ditto.\n+\tRenamed a few left-over variables and typedefs according to the\n+\tC++STYLE mentioned in the documentation.\n+\tProtected calls to __gthread* by __gthread_active_p(), whose value\n+\tis cached in the local variable __threads_active.\n+\n 2004-03-24  Felix Yen  <fwy@alumni.brown.edu>\n \n \t* testsuite/performance/20_util/allocator/producer_consumer.cc:"}, {"sha": "9a0d162098486d1352986cc6d89ac06d7eefe972", "filename": "libstdc++-v3/include/ext/bitmap_allocator.h", "status": "modified", "additions": 138, "deletions": 102, "changes": 240, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0/libstdc%2B%2B-v3%2Finclude%2Fext%2Fbitmap_allocator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0/libstdc%2B%2B-v3%2Finclude%2Fext%2Fbitmap_allocator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fext%2Fbitmap_allocator.h?ref=71f9a9d15e0deaa0b6b80f4ad146f0840cb483b0", "patch": "@@ -37,7 +37,7 @@\n #include <utility>\n //For std::pair.\n #include <algorithm>\n-//std::find_if.\n+//std::find_if, and std::lower_bound.\n #include <vector>\n //For the free list of exponentially growing memory blocks. At max,\n //size of the vector should be  not more than the number of bits in an\n@@ -55,10 +55,18 @@\n #define NDEBUG\n \n //#define CHECK_FOR_ERRORS\n+//#define __CPU_HAS_BACKWARD_BRANCH_PREDICTION\n \n namespace __gnu_cxx\n {\n+  namespace {\n+#if defined __GTHREADS\n+    bool const __threads_enabled = __gthread_active_p();\n+#endif\n+\n+  }\n \n+#if defined __GTHREADS\n   class _Mutex {\n     __gthread_mutex_t _M_mut;\n     //Prevent Copying and assignment.\n@@ -67,12 +75,15 @@ namespace __gnu_cxx\n   public:\n     _Mutex ()\n     {\n+      if (__threads_enabled)\n+\t{\n #if !defined __GTHREAD_MUTEX_INIT\n-      __GTHREAD_MUTEX_INIT_FUNCTION(&_M_mut);\n+\t  __GTHREAD_MUTEX_INIT_FUNCTION(&_M_mut);\n #else\n-      __gthread_mutex_t __mtemp = __GTHREAD_MUTEX_INIT;\n-      _M_mut = __mtemp;\n+\t  __gthread_mutex_t __mtemp = __GTHREAD_MUTEX_INIT;\n+\t  _M_mut = __mtemp;\n #endif\n+\t}\n     }\n     ~_Mutex ()\n     {\n@@ -81,22 +92,42 @@ namespace __gnu_cxx\n     __gthread_mutex_t *_M_get() { return &_M_mut; }\n   };\n \n-\n   class _Lock {\n-    _Mutex& _M_mt;\n+    _Mutex* _M_pmt;\n+    bool _M_locked;\n     //Prevent Copying and assignment.\n     _Lock (_Lock const&);\n     _Lock& operator= (_Lock const&);\n   public:\n-    _Lock (_Mutex& __mref) : _M_mt(__mref)\n+    _Lock(_Mutex* __mptr)\n+      : _M_pmt(__mptr), _M_locked(false)\n+    { this->_M_lock(); }\n+    void _M_lock()\n     {\n-      __gthread_mutex_lock(_M_mt._M_get());\n+      if (__threads_enabled)\n+\t{\n+\t  _M_locked = true;\n+\t  __gthread_mutex_lock(_M_pmt->_M_get());\n+\t}\n     }\n-    ~_Lock () { __gthread_mutex_unlock(_M_mt._M_get()); }\n+    void _M_unlock()\n+    {\n+      if (__threads_enabled)\n+\t{\n+\t  if (__builtin_expect(_M_locked, true))\n+\t    {\n+\t      __gthread_mutex_unlock(_M_pmt->_M_get());\n+\t      _M_locked = false;\n+\t    }\n+\t}\n+    }\n+    ~_Lock() { this->_M_unlock(); }\n   };\n+#endif\n+\n \n-  namespace __aux_balloc {\n \n+  namespace __aux_balloc {\n     static const unsigned int _Bits_Per_Byte = 8;\n     static const unsigned int _Bits_Per_Block = sizeof(unsigned int) * _Bits_Per_Byte;\n \n@@ -148,7 +179,8 @@ namespace __gnu_cxx\n \n     //T should be a pointer type, and A is the Allocator for the vector.\n     template <typename _Tp, typename _Alloc>\n-    class _Ffit_finder : public std::unary_function<typename std::pair<_Tp, _Tp>, bool> {\n+    class _Ffit_finder \n+      : public std::unary_function<typename std::pair<_Tp, _Tp>, bool> {\n       typedef typename std::vector<std::pair<_Tp, _Tp>, _Alloc> _BPVector;\n       typedef typename _BPVector::difference_type _Counter_type;\n       typedef typename std::pair<_Tp, _Tp> _Block_pair;\n@@ -157,7 +189,9 @@ namespace __gnu_cxx\n       unsigned int _M_data_offset;\n \n     public:\n-      _Ffit_finder () : _M_pbitmap (0), _M_data_offset (0) { }\n+      _Ffit_finder () \n+\t: _M_pbitmap (0), _M_data_offset (0)\n+      { }\n \n       bool operator() (_Block_pair __bp) throw()\n       {\n@@ -214,7 +248,8 @@ namespace __gnu_cxx\n       //Use the 2nd parameter with care. Make sure that such an entry\n       //exists in the vector before passing that particular index to\n       //this ctor.\n-      _Bit_map_counter (_BPVector& Rvbp, int __index = -1) : _M_vbp(Rvbp)\n+      _Bit_map_counter (_BPVector& Rvbp, int __index = -1) \n+\t: _M_vbp(Rvbp)\n       {\n \tthis->_M_reset(__index);\n       }\n@@ -238,7 +273,7 @@ namespace __gnu_cxx\n       }\n     \n       //Dangerous Function! Use with extreme care. Pass to this\n-      //functions ONLY those values that are known to be correct,\n+      //function ONLY those values that are known to be correct,\n       //otherwise this will mess up big time.\n       void _M_set_internal_bit_map (unsigned int *__new_internal_marker) throw()\n       {\n@@ -275,28 +310,22 @@ namespace __gnu_cxx\n \treturn _M_curr_bmap;\n       }\n     \n-      pointer base () { return _M_vbp[_M_curr_index].first; }\n+      pointer _M_base () { return _M_vbp[_M_curr_index].first; }\n       unsigned int _M_offset ()\n       {\n-\treturn _Bits_Per_Block * ((reinterpret_cast<unsigned int*>(this->base()) - _M_curr_bmap) - 1);\n+\treturn _Bits_Per_Block * ((reinterpret_cast<unsigned int*>(this->_M_base()) - _M_curr_bmap) - 1);\n       }\n     \n       unsigned int _M_where () { return _M_curr_index; }\n     };\n   }\n \n-    //Generic Version of the bsf instruction.\n-    typedef unsigned int _Bit_map_type;\n-    static inline unsigned int _Bit_scan_forward (_Bit_map_type __num)\n-    {\n-      unsigned int __ret_val = 0;\n-      while (__num % 2 == 0)\n-\t{\n-\t  ++__ret_val;\n-\t  __num >>= 1;\n-\t}\n-      return __ret_val;\n-    }\n+  //Generic Version of the bsf instruction.\n+  typedef unsigned int _Bit_map_type;\n+  static inline unsigned int _Bit_scan_forward (register _Bit_map_type __num)\n+  {\n+    return static_cast<unsigned int>(__builtin_ctz(__num));\n+  }\n \n   struct _OOM_handler {\n     static std::new_handler _S_old_handler;\n@@ -347,8 +376,8 @@ namespace __gnu_cxx\n \n     static void _S_validate_free_list(unsigned int *__addr) throw()\n     {\n-      const unsigned int Max_Size = 64;\n-      if (_S_free_list.size() >= Max_Size)\n+      const unsigned int __max_size = 64;\n+      if (_S_free_list.size() >= __max_size)\n \t{\n \t  //Ok, the threshold value has been reached.\n \t  //We determine which block to remove from the list of free\n@@ -380,10 +409,9 @@ namespace __gnu_cxx\n \n     static bool _S_should_i_give(unsigned int __block_size, unsigned int __required_size) throw()\n     {\n-      const unsigned int Max_Wastage_Percentage = 36;\n-\n+      const unsigned int __max_wastage_percentage = 36;\n       if (__block_size >= __required_size && \n-\t  (((__block_size - __required_size) * 100 / __block_size) < Max_Wastage_Percentage))\n+\t  (((__block_size - __required_size) * 100 / __block_size) < __max_wastage_percentage))\n \treturn true;\n       else\n \treturn false;\n@@ -395,7 +423,7 @@ namespace __gnu_cxx\n     static inline void _S_insert_free_list(unsigned int *__addr) throw()\n     {\n #if defined __GTHREADS\n-      _Lock __bfl_lock(*&_S_bfl_mutex);\n+      _Lock __bfl_lock(&_S_bfl_mutex);\n #endif\n       //Call _S_validate_free_list to decide what should be done with this\n       //particular free list.\n@@ -405,12 +433,14 @@ namespace __gnu_cxx\n     static unsigned int *_S_get_free_list(unsigned int __sz) throw (std::bad_alloc)\n     {\n #if defined __GTHREADS\n-      _Lock __bfl_lock(*&_S_bfl_mutex);\n+      _Lock __bfl_lock(&_S_bfl_mutex);\n #endif\n       _FLIter __temp = std::lower_bound(_S_free_list.begin(), _S_free_list.end(), \n \t\t\t\t\t__sz, _LT_pointer_compare());\n       if (__temp == _S_free_list.end() || !_S_should_i_give (**__temp, __sz))\n \t{\n+\t  //We hold the lock because the OOM_Handler is a stateless\n+\t  //entity.\n \t  _OOM_handler __set_handler(_BFL_type::_S_clear);\n \t  unsigned int *__ret_val = reinterpret_cast<unsigned int*>\n \t    (operator new (__sz + sizeof(unsigned int)));\n@@ -430,7 +460,7 @@ namespace __gnu_cxx\n     static void _S_clear()\n     {\n #if defined __GTHREADS\n-      _Lock __bfl_lock(*&_S_bfl_mutex);\n+      _Lock __bfl_lock(&_S_bfl_mutex);\n #endif\n       _FLIter __iter = _S_free_list.begin();\n       while (__iter != _S_free_list.end())\n@@ -448,18 +478,18 @@ namespace __gnu_cxx\n #endif\n   std::vector<unsigned int*> _BA_free_list_store::_S_free_list;\n \n-  template <class _Tp> class bitmap_allocator;\n+  template <typename _Tp> class bitmap_allocator;\n   // specialize for void:\n   template <> class bitmap_allocator<void> {\n   public:\n     typedef void*       pointer;\n     typedef const void* const_pointer;\n     //  reference-to-void members are impossible.\n     typedef void  value_type;\n-    template <class U> struct rebind { typedef bitmap_allocator<U> other; };\n+    template <typename _Tp1> struct rebind { typedef bitmap_allocator<_Tp1> other; };\n   };\n \n-  template <class _Tp> class bitmap_allocator : private _BA_free_list_store {\n+  template <typename _Tp> class bitmap_allocator : private _BA_free_list_store {\n   public:\n     typedef size_t    size_type;\n     typedef ptrdiff_t difference_type;\n@@ -468,7 +498,7 @@ namespace __gnu_cxx\n     typedef _Tp&        reference;\n     typedef const _Tp&  const_reference;\n     typedef _Tp         value_type;\n-    template <class U> struct rebind { typedef bitmap_allocator<U> other; };\n+    template <typename _Tp1> struct rebind { typedef bitmap_allocator<_Tp1> other; };\n \n   private:\n     static const unsigned int _Bits_Per_Byte = 8;\n@@ -481,9 +511,9 @@ namespace __gnu_cxx\n       *__pbmap &= __mask;\n     }\n   \n-    static inline void _S_bit_free(unsigned int *__pbmap, unsigned int __Pos) throw()\n+    static inline void _S_bit_free(unsigned int *__pbmap, unsigned int __pos) throw()\n     {\n-      unsigned int __mask = 1 << __Pos;\n+      unsigned int __mask = 1 << __pos;\n       *__pbmap |= __mask;\n     }\n \n@@ -565,18 +595,6 @@ namespace __gnu_cxx\n     static _Mutex _S_mut;\n #endif\n \n-  public:\n-    bitmap_allocator() throw()\n-    { }\n-\n-    bitmap_allocator(const bitmap_allocator&) { }\n-\n-    template <typename _Tp1> bitmap_allocator(const bitmap_allocator<_Tp1>&) throw()\n-    { }\n-\n-    ~bitmap_allocator() throw()\n-    { }\n-\n     //Complexity: Worst case complexity is O(N), but that is hardly ever\n     //hit. if and when this particular case is encountered, the next few\n     //cases are guaranteed to have a worst case complexity of O(1)!\n@@ -586,22 +604,27 @@ namespace __gnu_cxx\n     static pointer _S_allocate_single_object()\n     {\n #if defined __GTHREADS\n-      _Lock _bit_lock(*&_S_mut);\n+      _Lock __bit_lock(&_S_mut);\n #endif\n+\n       //The algorithm is something like this: The last_requst variable\n       //points to the last accessed Bit Map. When such a condition\n       //occurs, we try to find a free block in the current bitmap, or\n       //succeeding bitmaps until the last bitmap is reached. If no free\n-      //block turns up, we resort to First Fit method. But, again, the\n-      //First Fit is used only upto the point where we started the\n-      //previous linear search.\n-\n+      //block turns up, we resort to First Fit method.\n+\n+      //WARNING: Do not re-order the condition in the while statement\n+      //below, because it relies on C++'s short-circuit\n+      //evaluation. The return from _S_last_request->_M_get() will NOT\n+      //be dereferenceable if _S_last_request->_M_finished() returns\n+      //true. This would inevitibly lead to a NULL pointer dereference\n+      //if tinkered with.\n       while (_S_last_request._M_finished() == false && (*(_S_last_request._M_get()) == 0))\n \t{\n \t  _S_last_request.operator++();\n \t}\n \n-      if (_S_last_request._M_finished())\n+      if (__builtin_expect(_S_last_request._M_finished() == true, false))\n \t{\n \t  //Fall Back to First Fit algorithm.\n \t  typedef typename __gnu_cxx::__aux_balloc::_Ffit_finder<pointer, _BPVec_allocator_type> _FFF;\n@@ -645,7 +668,7 @@ namespace __gnu_cxx\n       unsigned int __nz_bit = _Bit_scan_forward(*_S_last_request._M_get());\n       _S_bit_allocate(_S_last_request._M_get(), __nz_bit);\n \n-      pointer __ret_val = _S_last_request.base() + _S_last_request._M_offset() + __nz_bit;\n+      pointer __ret_val = _S_last_request._M_base() + _S_last_request._M_offset() + __nz_bit;\n \n       unsigned int *__puse_count = reinterpret_cast<unsigned int*>\n \t(_S_mem_blocks[_S_last_request._M_where()].first) - \n@@ -654,49 +677,19 @@ namespace __gnu_cxx\n       return __ret_val;\n     }\n \n-    //Complexity: O(1), but internally the complexity depends upon the\n-    //complexity of the function(s) _S_allocate_single_object and\n-    //_S_memory_get.\n-    pointer allocate(size_type __n)\n-    {\n-      if (__n == 1)\n-\treturn _S_allocate_single_object();\n-      else\n-\treturn reinterpret_cast<pointer>(_S_memory_get(__n * sizeof(value_type)));\n-    }\n-\n-    //Complexity: Worst case complexity is O(N) where N is the number of\n-    //blocks of size sizeof(value_type) within the free lists that the\n-    //allocator holds. However, this worst case is hit only when the\n-    //user supplies a bogus argument to hint. If the hint argument is\n-    //sensible, then the complexity drops to O(lg(N)), and in extreme\n-    //cases, even drops to as low as O(1). So, if the user supplied\n-    //argument is good, then this function performs very well.\n-    pointer allocate(size_type __n, typename bitmap_allocator<void>::const_pointer)\n-    {\n-      return allocate(__n);\n-    }\n-\n-    void deallocate(pointer __p, size_type __n) throw()\n-    {\n-      if (__n == 1)\n-\t_S_deallocate_single_object(__p);\n-      else\n-\t_S_memory_put(__p);\n-    }\n-\n     //Complexity: O(lg(N)), but the worst case is hit quite often! I\n     //need to do something about this. I'll be able to work on it, only\n     //when I have some solid figures from a few real apps.\n     static void _S_deallocate_single_object(pointer __p) throw()\n     {\n #if defined __GTHREADS\n-      _Lock _bit_lock(*&_S_mut);\n+      _Lock __bit_lock(&_S_mut);\n #endif\n-      typedef typename _BPVector::iterator iterator;\n-      typedef typename _BPVector::difference_type diff_type;\n \n-      diff_type __diff;\n+      typedef typename _BPVector::iterator _Iterator;\n+      typedef typename _BPVector::difference_type _Difference_type;\n+\n+      _Difference_type __diff;\n       int __displacement;\n \n       assert(_S_last_dealloc_index >= 0);\n@@ -711,7 +704,7 @@ namespace __gnu_cxx\n \t}\n       else\n \t{\n-\t  iterator _iter = (std::find_if(_S_mem_blocks.begin(), _S_mem_blocks.end(), \n+\t  _Iterator _iter = (std::find_if(_S_mem_blocks.begin(), _S_mem_blocks.end(), \n \t\t\t\t\t  __gnu_cxx::__aux_balloc::_Inclusive_between<pointer>(__p)));\n \t  assert(_iter != _S_mem_blocks.end());\n \n@@ -734,7 +727,7 @@ namespace __gnu_cxx\n \n       --(*__puse_count);\n \n-      if (!*__puse_count)\n+      if (__builtin_expect(*__puse_count == 0, false))\n \t{\n \t  _S_block_size /= 2;\n \t  \n@@ -744,12 +737,12 @@ namespace __gnu_cxx\n \t  _S_mem_blocks.erase(_S_mem_blocks.begin() + __diff);\n \n \t  //We reset the _S_last_request variable to reflect the erased\n-\t  //block. We do this to pretect future requests after the last\n+\t  //block. We do this to protect future requests after the last\n \t  //block has been removed from a particular memory Chunk,\n \t  //which in turn has been returned to the free list, and\n \t  //hence had been erased from the vector, so the size of the\n \t  //vector gets reduced by 1.\n-\t  if ((diff_type)_S_last_request._M_where() >= __diff--)\n+\t  if ((_Difference_type)_S_last_request._M_where() >= __diff--)\n \t    {\n \t      _S_last_request._M_reset(__diff);\n \t      //\t      assert(__diff >= 0);\n@@ -768,14 +761,57 @@ namespace __gnu_cxx\n \t}\n     }\n \n+  public:\n+    bitmap_allocator() throw()\n+    { }\n+\n+    bitmap_allocator(const bitmap_allocator&) { }\n+\n+    template <typename _Tp1> bitmap_allocator(const bitmap_allocator<_Tp1>&) throw()\n+    { }\n+\n+    ~bitmap_allocator() throw()\n+    { }\n+\n+    //Complexity: O(1), but internally the complexity depends upon the\n+    //complexity of the function(s) _S_allocate_single_object and\n+    //_S_memory_get.\n+    pointer allocate(size_type __n)\n+    {\n+      if (__builtin_expect(__n == 1, true))\n+\treturn _S_allocate_single_object();\n+      else\n+\treturn reinterpret_cast<pointer>(_S_memory_get(__n * sizeof(value_type)));\n+    }\n+\n+    //Complexity: Worst case complexity is O(N) where N is the number of\n+    //blocks of size sizeof(value_type) within the free lists that the\n+    //allocator holds. However, this worst case is hit only when the\n+    //user supplies a bogus argument to hint. If the hint argument is\n+    //sensible, then the complexity drops to O(lg(N)), and in extreme\n+    //cases, even drops to as low as O(1). So, if the user supplied\n+    //argument is good, then this function performs very well.\n+    pointer allocate(size_type __n, typename bitmap_allocator<void>::const_pointer)\n+    {\n+      return allocate(__n);\n+    }\n+\n+    void deallocate(pointer __p, size_type __n) throw()\n+    {\n+      if (__builtin_expect(__n == 1, true))\n+\t_S_deallocate_single_object(__p);\n+      else\n+\t_S_memory_put(__p);\n+    }\n+\n     pointer address(reference r) const { return &r; }\n     const_pointer address(const_reference r) const { return &r; }\n \n     size_type max_size(void) const throw() { return (size_type()-1)/sizeof(value_type); }\n \n-    void construct (pointer p, const_reference _data)\n+    void construct (pointer p, const_reference __data)\n     {\n-      new (p) value_type (_data);\n+      ::new(p) value_type(__data);\n     }\n \n     void destroy (pointer p)"}]}