{"sha": "4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NGFlYjFiYTdmNjJjMWQ2ODBjODE5YWUzZTEzN2MzYmFkNmY1MjBjYQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2019-08-13T10:40:02Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2019-08-13T10:40:02Z"}, "message": "[AArch64] Improve SVE constant moves\n\nIf there's no SVE instruction to load a given constant directly, this\npatch instead tries to use an Advanced SIMD constant move and then\nduplicates the constant to fill an SVE vector.  The main use of this\nis to support constants in which each byte is in { 0, 0xff }.\n\nAlso, the patch prefers a simple integer move followed by a duplicate\nover a load from memory, like we already do for Advanced SIMD.  This is\na useful option to have and would be easy to turn off via a tuning\nparameter if necessary.\n\nThe patch also extends the handling of wide LD1Rs to big endian,\nwhereas previously we punted to a full LD1RQ.\n\n2019-08-13  Richard Sandiford  <richard.sandiford@arm.com>\n\ngcc/\n\t* machmode.h (opt_mode::else_mode): New function.\n\t(opt_mode::else_blk): Use it.\n\t* config/aarch64/aarch64-protos.h (aarch64_vq_mode): Declare.\n\t(aarch64_full_sve_mode, aarch64_sve_ld1rq_operand_p): Likewise.\n\t(aarch64_gen_stepped_int_parallel): Likewise.\n\t(aarch64_stepped_int_parallel_p): Likewise.\n\t(aarch64_expand_mov_immediate): Remove the optional gen_vec_duplicate\n\targument.\n\t* config/aarch64/aarch64.c\n\t(aarch64_expand_sve_widened_duplicate): Delete.\n\t(aarch64_expand_sve_dupq, aarch64_expand_sve_ld1rq): New functions.\n\t(aarch64_expand_sve_const_vector): Rewrite to handle more cases.\n\t(aarch64_expand_mov_immediate): Remove the optional gen_vec_duplicate\n\targument.  Use early returns in the !CONST_INT_P handling.\n\tPass all SVE data vectors to aarch64_expand_sve_const_vector rather\n\tthan handling some inline.\n\t(aarch64_full_sve_mode, aarch64_vq_mode): New functions, split out\n\tfrom...\n\t(aarch64_simd_container_mode): ...here.\n\t(aarch64_gen_stepped_int_parallel, aarch64_stepped_int_parallel_p)\n\t(aarch64_sve_ld1rq_operand_p): New functions.\n\t* config/aarch64/predicates.md (descending_int_parallel)\n\t(aarch64_sve_ld1rq_operand): New predicates.\n\t* config/aarch64/constraints.md (UtQ): New constraint.\n\t* config/aarch64/aarch64.md (UNSPEC_REINTERPRET): New unspec.\n\t* config/aarch64/aarch64-sve.md (mov<SVE_ALL:mode>): Remove the\n\tgen_vec_duplicate from call to aarch64_expand_mov_immediate.\n\t(@aarch64_sve_reinterpret<mode>): New expander.\n\t(*aarch64_sve_reinterpret<mode>): New pattern.\n\t(@aarch64_vec_duplicate_vq<mode>_le): New pattern.\n\t(@aarch64_vec_duplicate_vq<mode>_be): Likewise.\n\t(*sve_ld1rq<Vesize>): Replace with...\n\t(@aarch64_sve_ld1rq<mode>): ...this new pattern.\n\ngcc/testsuite/\n\t* gcc.target/aarch64/sve/init_2.c: Expect ld1rd to be used\n\tinstead of a full vector load.\n\t* gcc.target/aarch64/sve/init_4.c: Likewise.\n\t* gcc.target/aarch64/sve/ld1r_2.c: Remove constants that no longer\n\tneed to be loaded from memory.\n\t* gcc.target/aarch64/sve/slp_2.c: Expect the same output for\n\tbig and little endian.\n\t* gcc.target/aarch64/sve/slp_3.c: Likewise.  Expect 3 of the\n\tdoubles to be moved via integer registers rather than loaded\n\tfrom memory.\n\t* gcc.target/aarch64/sve/slp_4.c: Likewise but for 4 doubles.\n\t* gcc.target/aarch64/sve/spill_4.c: Expect 16-bit constants to be\n\tloaded via an integer register rather than from memory.\n\t* gcc.target/aarch64/sve/const_1.c: New test.\n\t* gcc.target/aarch64/sve/const_2.c: Likewise.\n\t* gcc.target/aarch64/sve/const_3.c: Likewise.\n\nFrom-SVN: r274375", "tree": {"sha": "d1fbc5144505dbb6ba45c2f71bdd2d5358762151", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d1fbc5144505dbb6ba45c2f71bdd2d5358762151"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "4e55aefa3ee19167a41892e4920a3e8c520aee42", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4e55aefa3ee19167a41892e4920a3e8c520aee42", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4e55aefa3ee19167a41892e4920a3e8c520aee42"}], "stats": {"total": 681, "additions": 506, "deletions": 175}, "files": [{"sha": "4da505ed62b914382aaef891f80e0ad6da26ecf1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -1,3 +1,39 @@\n+2019-08-13  Richard Sandiford  <richard.sandiford@arm.com>\n+\n+\t* machmode.h (opt_mode::else_mode): New function.\n+\t(opt_mode::else_blk): Use it.\n+\t* config/aarch64/aarch64-protos.h (aarch64_vq_mode): Declare.\n+\t(aarch64_full_sve_mode, aarch64_sve_ld1rq_operand_p): Likewise.\n+\t(aarch64_gen_stepped_int_parallel): Likewise.\n+\t(aarch64_stepped_int_parallel_p): Likewise.\n+\t(aarch64_expand_mov_immediate): Remove the optional gen_vec_duplicate\n+\targument.\n+\t* config/aarch64/aarch64.c\n+\t(aarch64_expand_sve_widened_duplicate): Delete.\n+\t(aarch64_expand_sve_dupq, aarch64_expand_sve_ld1rq): New functions.\n+\t(aarch64_expand_sve_const_vector): Rewrite to handle more cases.\n+\t(aarch64_expand_mov_immediate): Remove the optional gen_vec_duplicate\n+\targument.  Use early returns in the !CONST_INT_P handling.\n+\tPass all SVE data vectors to aarch64_expand_sve_const_vector rather\n+\tthan handling some inline.\n+\t(aarch64_full_sve_mode, aarch64_vq_mode): New functions, split out\n+\tfrom...\n+\t(aarch64_simd_container_mode): ...here.\n+\t(aarch64_gen_stepped_int_parallel, aarch64_stepped_int_parallel_p)\n+\t(aarch64_sve_ld1rq_operand_p): New functions.\n+\t* config/aarch64/predicates.md (descending_int_parallel)\n+\t(aarch64_sve_ld1rq_operand): New predicates.\n+\t* config/aarch64/constraints.md (UtQ): New constraint.\n+\t* config/aarch64/aarch64.md (UNSPEC_REINTERPRET): New unspec.\n+\t* config/aarch64/aarch64-sve.md (mov<SVE_ALL:mode>): Remove the\n+\tgen_vec_duplicate from call to aarch64_expand_mov_immediate.\n+\t(@aarch64_sve_reinterpret<mode>): New expander.\n+\t(*aarch64_sve_reinterpret<mode>): New pattern.\n+\t(@aarch64_vec_duplicate_vq<mode>_le): New pattern.\n+\t(@aarch64_vec_duplicate_vq<mode>_be): Likewise.\n+\t(*sve_ld1rq<Vesize>): Replace with...\n+\t(@aarch64_sve_ld1rq<mode>): ...this new pattern.\n+\n 2019-08-13  Wilco Dijkstra  <wdijkstr@arm.com>\n \n \t* config/aarch64/aarch64.c (generic_tunings): Set function alignment to"}, {"sha": "ad818a4ec7fcf4a4ea7a27f588689904b75ebeaf", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -416,6 +416,8 @@ unsigned HOST_WIDE_INT aarch64_and_split_imm2 (HOST_WIDE_INT val_in);\n bool aarch64_and_bitmask_imm (unsigned HOST_WIDE_INT val_in, machine_mode mode);\n int aarch64_branch_cost (bool, bool);\n enum aarch64_symbol_type aarch64_classify_symbolic_expression (rtx);\n+opt_machine_mode aarch64_vq_mode (scalar_mode);\n+opt_machine_mode aarch64_full_sve_mode (scalar_mode);\n bool aarch64_can_const_movi_rtx_p (rtx x, machine_mode mode);\n bool aarch64_const_vec_all_same_int_p (rtx, HOST_WIDE_INT);\n bool aarch64_const_vec_all_same_in_range_p (rtx, HOST_WIDE_INT,\n@@ -504,9 +506,12 @@ rtx aarch64_return_addr (int, rtx);\n rtx aarch64_simd_gen_const_vector_dup (machine_mode, HOST_WIDE_INT);\n bool aarch64_simd_mem_operand_p (rtx);\n bool aarch64_sve_ld1r_operand_p (rtx);\n+bool aarch64_sve_ld1rq_operand_p (rtx);\n bool aarch64_sve_ldr_operand_p (rtx);\n bool aarch64_sve_struct_memory_operand_p (rtx);\n rtx aarch64_simd_vect_par_cnst_half (machine_mode, int, bool);\n+rtx aarch64_gen_stepped_int_parallel (unsigned int, int, int);\n+bool aarch64_stepped_int_parallel_p (rtx, int);\n rtx aarch64_tls_get_addr (void);\n tree aarch64_fold_builtin (tree, int, tree *, bool);\n unsigned aarch64_dbx_register_number (unsigned);\n@@ -518,7 +523,7 @@ const char * aarch64_output_probe_stack_range (rtx, rtx);\n const char * aarch64_output_probe_sve_stack_clash (rtx, rtx, rtx, rtx);\n void aarch64_err_no_fpadvsimd (machine_mode);\n void aarch64_expand_epilogue (bool);\n-void aarch64_expand_mov_immediate (rtx, rtx, rtx (*) (rtx, rtx) = 0);\n+void aarch64_expand_mov_immediate (rtx, rtx);\n rtx aarch64_ptrue_reg (machine_mode);\n rtx aarch64_pfalse_reg (machine_mode);\n void aarch64_emit_sve_pred_move (rtx, rtx, rtx);"}, {"sha": "950f39781af3c92278b6b7bfbd607cf0bd5d169a", "filename": "gcc/config/aarch64/aarch64-sve.md", "status": "modified", "additions": 76, "deletions": 9, "changes": 85, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -207,8 +207,7 @@\n \n     if (CONSTANT_P (operands[1]))\n       {\n-\taarch64_expand_mov_immediate (operands[0], operands[1],\n-\t\t\t\t      gen_vec_duplicate<mode>);\n+\taarch64_expand_mov_immediate (operands[0], operands[1]);\n \tDONE;\n       }\n \n@@ -326,6 +325,39 @@\n   }\n )\n \n+;; Reinterpret operand 1 in operand 0's mode, without changing its contents.\n+;; This is equivalent to a subreg on little-endian targets but not for\n+;; big-endian; see the comment at the head of the file for details.\n+(define_expand \"@aarch64_sve_reinterpret<mode>\"\n+  [(set (match_operand:SVE_ALL 0 \"register_operand\")\n+\t(unspec:SVE_ALL [(match_operand 1 \"aarch64_any_register_operand\")]\n+\t\t\tUNSPEC_REINTERPRET))]\n+  \"TARGET_SVE\"\n+  {\n+    if (!BYTES_BIG_ENDIAN)\n+      {\n+\temit_move_insn (operands[0], gen_lowpart (<MODE>mode, operands[1]));\n+\tDONE;\n+      }\n+  }\n+)\n+\n+;; A pattern for handling type punning on big-endian targets.  We use a\n+;; special predicate for operand 1 to reduce the number of patterns.\n+(define_insn_and_split \"*aarch64_sve_reinterpret<mode>\"\n+  [(set (match_operand:SVE_ALL 0 \"register_operand\" \"=w\")\n+\t(unspec:SVE_ALL [(match_operand 1 \"aarch64_any_register_operand\" \"0\")]\n+\t\t\tUNSPEC_REINTERPRET))]\n+  \"TARGET_SVE\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(set (match_dup 0) (match_dup 1))]\n+  {\n+    emit_note (NOTE_INSN_DELETED);\n+    DONE;\n+  }\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- Moves of multiple vectors\n ;; -------------------------------------------------------------------------\n@@ -787,6 +819,39 @@\n   [(set_attr \"length\" \"4,4,8\")]\n )\n \n+;; Duplicate an Advanced SIMD vector to fill an SVE vector (LE version).\n+(define_insn \"@aarch64_vec_duplicate_vq<mode>_le\"\n+  [(set (match_operand:SVE_ALL 0 \"register_operand\" \"=w\")\n+\t(vec_duplicate:SVE_ALL\n+\t  (match_operand:<V128> 1 \"register_operand\" \"w\")))]\n+  \"TARGET_SVE && !BYTES_BIG_ENDIAN\"\n+  {\n+    operands[1] = gen_rtx_REG (<MODE>mode, REGNO (operands[1]));\n+    return \"dup\\t%0.q, %1.q[0]\";\n+  }\n+)\n+\n+;; Duplicate an Advanced SIMD vector to fill an SVE vector (BE version).\n+;; The SVE register layout puts memory lane N into (architectural)\n+;; register lane N, whereas the Advanced SIMD layout puts the memory\n+;; lsb into the register lsb.  We therefore have to describe this in rtl\n+;; terms as a reverse of the V128 vector followed by a duplicate.\n+(define_insn \"@aarch64_vec_duplicate_vq<mode>_be\"\n+  [(set (match_operand:SVE_ALL 0 \"register_operand\" \"=w\")\n+\t(vec_duplicate:SVE_ALL\n+\t  (vec_select:<V128>\n+\t    (match_operand:<V128> 1 \"register_operand\" \"w\")\n+\t    (match_operand 2 \"descending_int_parallel\"))))]\n+  \"TARGET_SVE\n+   && BYTES_BIG_ENDIAN\n+   && known_eq (INTVAL (XVECEXP (operands[2], 0, 0)),\n+\t\tGET_MODE_NUNITS (<V128>mode) - 1)\"\n+  {\n+    operands[1] = gen_rtx_REG (<MODE>mode, REGNO (operands[1]));\n+    return \"dup\\t%0.q, %1.q[0]\";\n+  }\n+)\n+\n ;; This is used for vec_duplicate<mode>s from memory, but can also\n ;; be used by combine to optimize selects of a a vec_duplicate<mode>\n ;; with zero.\n@@ -802,17 +867,19 @@\n   \"ld1r<Vesize>\\t%0.<Vetype>, %1/z, %2\"\n )\n \n-;; Load 128 bits from memory and duplicate to fill a vector.  Since there\n-;; are so few operations on 128-bit \"elements\", we don't define a VNx1TI\n-;; and simply use vectors of bytes instead.\n-(define_insn \"*sve_ld1rq<Vesize>\"\n+;; Load 128 bits from memory under predicate control and duplicate to\n+;; fill a vector.\n+(define_insn \"@aarch64_sve_ld1rq<mode>\"\n   [(set (match_operand:SVE_ALL 0 \"register_operand\" \"=w\")\n \t(unspec:SVE_ALL\n-\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl\")\n-\t   (match_operand:TI 2 \"aarch64_sve_ld1r_operand\" \"Uty\")]\n+\t  [(match_operand:<VPRED> 2 \"register_operand\" \"Upl\")\n+\t   (match_operand:<V128> 1 \"aarch64_sve_ld1rq_operand\" \"UtQ\")]\n \t  UNSPEC_LD1RQ))]\n   \"TARGET_SVE\"\n-  \"ld1rq<Vesize>\\t%0.<Vetype>, %1/z, %2\"\n+  {\n+    operands[1] = gen_rtx_MEM (<VEL>mode, XEXP (operands[1], 0));\n+    return \"ld1rq<Vesize>\\t%0.<Vetype>, %2/z, %1\";\n+  }\n )\n \n ;; -------------------------------------------------------------------------"}, {"sha": "fe968459241b9edf3eabfb890c48aabff1dd63ff", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 270, "deletions": 117, "changes": 387, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -3242,32 +3242,55 @@ aarch64_expand_vec_series (rtx dest, rtx base, rtx step)\n   emit_set_insn (dest, gen_rtx_VEC_SERIES (mode, base, step));\n }\n \n-/* Try to duplicate SRC into SVE register DEST, given that SRC is an\n-   integer of mode INT_MODE.  Return true on success.  */\n+/* Duplicate 128-bit Advanced SIMD vector SRC so that it fills an SVE\n+   register of mode MODE.  Use TARGET for the result if it's nonnull\n+   and convenient.\n+\n+   The two vector modes must have the same element mode.  The behavior\n+   is to duplicate architectural lane N of SRC into architectural lanes\n+   N + I * STEP of the result.  On big-endian targets, architectural\n+   lane 0 of an Advanced SIMD vector is the last element of the vector\n+   in memory layout, so for big-endian targets this operation has the\n+   effect of reversing SRC before duplicating it.  Callers need to\n+   account for this.  */\n \n-static bool\n-aarch64_expand_sve_widened_duplicate (rtx dest, scalar_int_mode src_mode,\n-\t\t\t\t      rtx src)\n-{\n-  /* If the constant is smaller than 128 bits, we can do the move\n-     using a vector of SRC_MODEs.  */\n-  if (src_mode != TImode)\n-    {\n-      poly_uint64 count = exact_div (GET_MODE_SIZE (GET_MODE (dest)),\n-\t\t\t\t     GET_MODE_SIZE (src_mode));\n-      machine_mode dup_mode = mode_for_vector (src_mode, count).require ();\n-      emit_move_insn (gen_lowpart (dup_mode, dest),\n-\t\t      gen_const_vec_duplicate (dup_mode, src));\n-      return true;\n+rtx\n+aarch64_expand_sve_dupq (rtx target, machine_mode mode, rtx src)\n+{\n+  machine_mode src_mode = GET_MODE (src);\n+  gcc_assert (GET_MODE_INNER (mode) == GET_MODE_INNER (src_mode));\n+  insn_code icode = (BYTES_BIG_ENDIAN\n+\t\t     ? code_for_aarch64_vec_duplicate_vq_be (mode)\n+\t\t     : code_for_aarch64_vec_duplicate_vq_le (mode));\n+\n+  unsigned int i = 0;\n+  expand_operand ops[3];\n+  create_output_operand (&ops[i++], target, mode);\n+  create_output_operand (&ops[i++], src, src_mode);\n+  if (BYTES_BIG_ENDIAN)\n+    {\n+      /* Create a PARALLEL describing the reversal of SRC.  */\n+      unsigned int nelts_per_vq = 128 / GET_MODE_UNIT_BITSIZE (mode);\n+      rtx sel = aarch64_gen_stepped_int_parallel (nelts_per_vq,\n+\t\t\t\t\t\t  nelts_per_vq - 1, -1);\n+      create_fixed_operand (&ops[i++], sel);\n     }\n+  expand_insn (icode, i, ops);\n+  return ops[0].value;\n+}\n \n-  /* Use LD1RQ[BHWD] to load the 128 bits from memory.  */\n-  src = force_const_mem (src_mode, src);\n+/* Try to force 128-bit vector value SRC into memory and use LD1RQ to fetch\n+   the memory image into DEST.  Return true on success.  */\n+\n+static bool\n+aarch64_expand_sve_ld1rq (rtx dest, rtx src)\n+{\n+  src = force_const_mem (GET_MODE (src), src);\n   if (!src)\n     return false;\n \n   /* Make sure that the address is legitimate.  */\n-  if (!aarch64_sve_ld1r_operand_p (src))\n+  if (!aarch64_sve_ld1rq_operand_p (src))\n     {\n       rtx addr = force_reg (Pmode, XEXP (src, 0));\n       src = replace_equiv_address (src, addr);\n@@ -3277,46 +3300,127 @@ aarch64_expand_sve_widened_duplicate (rtx dest, scalar_int_mode src_mode,\n   unsigned int elem_bytes = GET_MODE_UNIT_SIZE (mode);\n   machine_mode pred_mode = aarch64_sve_pred_mode (elem_bytes).require ();\n   rtx ptrue = aarch64_ptrue_reg (pred_mode);\n-  src = gen_rtx_UNSPEC (mode, gen_rtvec (2, ptrue, src), UNSPEC_LD1RQ);\n-  emit_insn (gen_rtx_SET (dest, src));\n+  emit_insn (gen_aarch64_sve_ld1rq (mode, dest, src, ptrue));\n   return true;\n }\n \n-/* Expand a move of general CONST_VECTOR SRC into DEST, given that it\n-   isn't a simple duplicate or series.  */\n+/* Return a register containing CONST_VECTOR SRC, given that SRC has an\n+   SVE data mode and isn't a legitimate constant.  Use TARGET for the\n+   result if convenient.\n \n-static void\n-aarch64_expand_sve_const_vector (rtx dest, rtx src)\n+   The returned register can have whatever mode seems most natural\n+   given the contents of SRC.  */\n+\n+static rtx\n+aarch64_expand_sve_const_vector (rtx target, rtx src)\n {\n   machine_mode mode = GET_MODE (src);\n   unsigned int npatterns = CONST_VECTOR_NPATTERNS (src);\n   unsigned int nelts_per_pattern = CONST_VECTOR_NELTS_PER_PATTERN (src);\n-  gcc_assert (npatterns > 1);\n+  scalar_mode elt_mode = GET_MODE_INNER (mode);\n+  unsigned int elt_bits = GET_MODE_BITSIZE (elt_mode);\n+  unsigned int encoded_bits = npatterns * nelts_per_pattern * elt_bits;\n+\n+  if (nelts_per_pattern == 1 && encoded_bits == 128)\n+    {\n+      /* The constant is a duplicated quadword but can't be narrowed\n+\t beyond a quadword.  Get the memory image of the first quadword\n+\t as a 128-bit vector and try using LD1RQ to load it from memory.\n+\n+\t The effect for both endiannesses is to load memory lane N into\n+\t architectural lanes N + I * STEP of the result.  On big-endian\n+\t targets, the layout of the 128-bit vector in an Advanced SIMD\n+\t register would be different from its layout in an SVE register,\n+\t but this 128-bit vector is a memory value only.  */\n+      machine_mode vq_mode = aarch64_vq_mode (elt_mode).require ();\n+      rtx vq_value = simplify_gen_subreg (vq_mode, src, mode, 0);\n+      if (vq_value && aarch64_expand_sve_ld1rq (target, vq_value))\n+\treturn target;\n+    }\n+\n+  if (nelts_per_pattern == 1 && encoded_bits < 128)\n+    {\n+      /* The vector is a repeating sequence of 64 bits or fewer.\n+\t See if we can load them using an Advanced SIMD move and then\n+\t duplicate it to fill a vector.  This is better than using a GPR\n+\t move because it keeps everything in the same register file.  */\n+      machine_mode vq_mode = aarch64_vq_mode (elt_mode).require ();\n+      rtx_vector_builder builder (vq_mode, npatterns, 1);\n+      for (unsigned int i = 0; i < npatterns; ++i)\n+\t{\n+\t  /* We want memory lane N to go into architectural lane N,\n+\t     so reverse for big-endian targets.  The DUP .Q pattern\n+\t     has a compensating reverse built-in.  */\n+\t  unsigned int srci = BYTES_BIG_ENDIAN ? npatterns - i - 1 : i;\n+\t  builder.quick_push (CONST_VECTOR_ENCODED_ELT (src, srci));\n+\t}\n+      rtx vq_src = builder.build ();\n+      if (aarch64_simd_valid_immediate (vq_src, NULL))\n+\t{\n+\t  vq_src = force_reg (vq_mode, vq_src);\n+\t  return aarch64_expand_sve_dupq (target, mode, vq_src);\n+\t}\n \n-  if (nelts_per_pattern == 1)\n-    {\n-      /* The constant is a repeating seqeuence of at least two elements,\n-\t where the repeating elements occupy no more than 128 bits.\n-\t Get an integer representation of the replicated value.  */\n-      scalar_int_mode int_mode;\n-      if (BYTES_BIG_ENDIAN)\n-\t/* For now, always use LD1RQ to load the value on big-endian\n-\t   targets, since the handling of smaller integers includes a\n-\t   subreg that is semantically an element reverse.  */\n-\tint_mode = TImode;\n-      else\n+      /* Get an integer representation of the repeating part of Advanced\n+\t SIMD vector VQ_SRC.  This preserves the endianness of VQ_SRC,\n+\t which for big-endian targets is lane-swapped wrt a normal\n+\t Advanced SIMD vector.  This means that for both endiannesses,\n+\t memory lane N of SVE vector SRC corresponds to architectural\n+\t lane N of a register holding VQ_SRC.  This in turn means that\n+\t memory lane 0 of SVE vector SRC is in the lsb of VQ_SRC (viewed\n+\t as a single 128-bit value) and thus that memory lane 0 of SRC is\n+\t in the lsb of the integer.  Duplicating the integer therefore\n+\t ensures that memory lane N of SRC goes into architectural lane\n+\t N + I * INDEX of the SVE register.  */\n+      scalar_mode int_mode = int_mode_for_size (encoded_bits, 0).require ();\n+      rtx elt_value = simplify_gen_subreg (int_mode, vq_src, vq_mode, 0);\n+      if (elt_value)\n \t{\n-\t  unsigned int int_bits = GET_MODE_UNIT_BITSIZE (mode) * npatterns;\n-\t  gcc_assert (int_bits <= 128);\n-\t  int_mode = int_mode_for_size (int_bits, 0).require ();\n+\t  /* Pretend that we had a vector of INT_MODE to start with.  */\n+\t  elt_mode = int_mode;\n+\t  mode = aarch64_full_sve_mode (int_mode).require ();\n+\n+\t  /* If the integer can be moved into a general register by a\n+\t     single instruction, do that and duplicate the result.  */\n+\t  if (CONST_INT_P (elt_value)\n+\t      && aarch64_move_imm (INTVAL (elt_value), elt_mode))\n+\t    {\n+\t      elt_value = force_reg (elt_mode, elt_value);\n+\t      return expand_vector_broadcast (mode, elt_value);\n+\t    }\n \t}\n-      rtx int_value = simplify_gen_subreg (int_mode, src, mode, 0);\n-      if (int_value\n-\t  && aarch64_expand_sve_widened_duplicate (dest, int_mode, int_value))\n-\treturn;\n+      else if (npatterns == 1)\n+\t/* We're duplicating a single value, but can't do better than\n+\t   force it to memory and load from there.  This handles things\n+\t   like symbolic constants.  */\n+\telt_value = CONST_VECTOR_ENCODED_ELT (src, 0);\n+\n+      if (elt_value)\n+\t{\n+\t  /* Load the element from memory if we can, otherwise move it into\n+\t     a register and use a DUP.  */\n+\t  rtx op = force_const_mem (elt_mode, elt_value);\n+\t  if (!op)\n+\t    op = force_reg (elt_mode, elt_value);\n+\t  return expand_vector_broadcast (mode, op);\n+\t}\n+    }\n+\n+  /* Try using INDEX.  */\n+  rtx base, step;\n+  if (const_vec_series_p (src, &base, &step))\n+    {\n+      aarch64_expand_vec_series (target, base, step);\n+      return target;\n     }\n \n+  /* From here on, it's better to force the whole constant to memory\n+     if we can.  */\n+  if (GET_MODE_NUNITS (mode).is_constant ())\n+    return NULL_RTX;\n+\n   /* Expand each pattern individually.  */\n+  gcc_assert (npatterns > 1);\n   rtx_vector_builder builder;\n   auto_vec<rtx, 16> vectors (npatterns);\n   for (unsigned int i = 0; i < npatterns; ++i)\n@@ -3333,22 +3437,20 @@ aarch64_expand_sve_const_vector (rtx dest, rtx src)\n       npatterns /= 2;\n       for (unsigned int i = 0; i < npatterns; ++i)\n \t{\n-\t  rtx tmp = (npatterns == 1 ? dest : gen_reg_rtx (mode));\n+\t  rtx tmp = (npatterns == 1 ? target : gen_reg_rtx (mode));\n \t  rtvec v = gen_rtvec (2, vectors[i], vectors[i + npatterns]);\n \t  emit_set_insn (tmp, gen_rtx_UNSPEC (mode, v, UNSPEC_ZIP1));\n \t  vectors[i] = tmp;\n \t}\n     }\n-  gcc_assert (vectors[0] == dest);\n+  gcc_assert (vectors[0] == target);\n+  return target;\n }\n \n-/* Set DEST to immediate IMM.  For SVE vector modes, GEN_VEC_DUPLICATE\n-   is a pattern that can be used to set DEST to a replicated scalar\n-   element.  */\n+/* Set DEST to immediate IMM.  */\n \n void\n-aarch64_expand_mov_immediate (rtx dest, rtx imm,\n-\t\t\t      rtx (*gen_vec_duplicate) (rtx, rtx))\n+aarch64_expand_mov_immediate (rtx dest, rtx imm)\n {\n   machine_mode mode = GET_MODE (dest);\n \n@@ -3471,38 +3573,24 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm,\n \n   if (!CONST_INT_P (imm))\n     {\n-      rtx base, step, value;\n       if (GET_CODE (imm) == HIGH\n \t  || aarch64_simd_valid_immediate (imm, NULL))\n-\temit_insn (gen_rtx_SET (dest, imm));\n-      else if (const_vec_series_p (imm, &base, &step))\n-\taarch64_expand_vec_series (dest, base, step);\n-      else if (const_vec_duplicate_p (imm, &value))\n \t{\n-\t  /* If the constant is out of range of an SVE vector move,\n-\t     load it from memory if we can, otherwise move it into\n-\t     a register and use a DUP.  */\n-\t  scalar_mode inner_mode = GET_MODE_INNER (mode);\n-\t  rtx op = force_const_mem (inner_mode, value);\n-\t  if (!op)\n-\t    op = force_reg (inner_mode, value);\n-\t  else if (!aarch64_sve_ld1r_operand_p (op))\n-\t    {\n-\t      rtx addr = force_reg (Pmode, XEXP (op, 0));\n-\t      op = replace_equiv_address (op, addr);\n-\t    }\n-\t  emit_insn (gen_vec_duplicate (dest, op));\n-\t}\n-      else if (GET_CODE (imm) == CONST_VECTOR\n-\t       && !GET_MODE_NUNITS (GET_MODE (imm)).is_constant ())\n-\taarch64_expand_sve_const_vector (dest, imm);\n-      else\n-\t{\n-\t  rtx mem = force_const_mem (mode, imm);\n-\t  gcc_assert (mem);\n-\t  emit_move_insn (dest, mem);\n+\t  emit_insn (gen_rtx_SET (dest, imm));\n+\t  return;\n \t}\n \n+      if (GET_CODE (imm) == CONST_VECTOR && aarch64_sve_data_mode_p (mode))\n+\tif (rtx res = aarch64_expand_sve_const_vector (dest, imm))\n+\t  {\n+\t    if (dest != res)\n+\t      emit_insn (gen_aarch64_sve_reinterpret (mode, dest, res));\n+\t    return;\n+\t  }\n+\n+      rtx mem = force_const_mem (mode, imm);\n+      gcc_assert (mem);\n+      emit_move_insn (dest, mem);\n       return;\n     }\n \n@@ -14172,55 +14260,71 @@ aarch64_vector_mode_supported_p (machine_mode mode)\n   return vec_flags != 0 && (vec_flags & VEC_STRUCT) == 0;\n }\n \n+/* Return the full-width SVE vector mode for element mode MODE, if one\n+   exists.  */\n+opt_machine_mode\n+aarch64_full_sve_mode (scalar_mode mode)\n+{\n+  switch (mode)\n+    {\n+    case E_DFmode:\n+      return VNx2DFmode;\n+    case E_SFmode:\n+      return VNx4SFmode;\n+    case E_HFmode:\n+      return VNx8HFmode;\n+    case E_DImode:\n+\treturn VNx2DImode;\n+    case E_SImode:\n+      return VNx4SImode;\n+    case E_HImode:\n+      return VNx8HImode;\n+    case E_QImode:\n+      return VNx16QImode;\n+    default:\n+      return opt_machine_mode ();\n+    }\n+}\n+\n+/* Return the 128-bit Advanced SIMD vector mode for element mode MODE,\n+   if it exists.  */\n+opt_machine_mode\n+aarch64_vq_mode (scalar_mode mode)\n+{\n+  switch (mode)\n+    {\n+    case E_DFmode:\n+      return V2DFmode;\n+    case E_SFmode:\n+      return V4SFmode;\n+    case E_HFmode:\n+      return V8HFmode;\n+    case E_SImode:\n+      return V4SImode;\n+    case E_HImode:\n+      return V8HImode;\n+    case E_QImode:\n+      return V16QImode;\n+    case E_DImode:\n+      return V2DImode;\n+    default:\n+      return opt_machine_mode ();\n+    }\n+}\n+\n /* Return appropriate SIMD container\n    for MODE within a vector of WIDTH bits.  */\n static machine_mode\n aarch64_simd_container_mode (scalar_mode mode, poly_int64 width)\n {\n   if (TARGET_SVE && known_eq (width, BITS_PER_SVE_VECTOR))\n-    switch (mode)\n-      {\n-      case E_DFmode:\n-\treturn VNx2DFmode;\n-      case E_SFmode:\n-\treturn VNx4SFmode;\n-      case E_HFmode:\n-\treturn VNx8HFmode;\n-      case E_DImode:\n-\treturn VNx2DImode;\n-      case E_SImode:\n-\treturn VNx4SImode;\n-      case E_HImode:\n-\treturn VNx8HImode;\n-      case E_QImode:\n-\treturn VNx16QImode;\n-      default:\n-\treturn word_mode;\n-      }\n+    return aarch64_full_sve_mode (mode).else_mode (word_mode);\n \n   gcc_assert (known_eq (width, 64) || known_eq (width, 128));\n   if (TARGET_SIMD)\n     {\n       if (known_eq (width, 128))\n-\tswitch (mode)\n-\t  {\n-\t  case E_DFmode:\n-\t    return V2DFmode;\n-\t  case E_SFmode:\n-\t    return V4SFmode;\n-\t  case E_HFmode:\n-\t    return V8HFmode;\n-\t  case E_SImode:\n-\t    return V4SImode;\n-\t  case E_HImode:\n-\t    return V8HImode;\n-\t  case E_QImode:\n-\t    return V16QImode;\n-\t  case E_DImode:\n-\t    return V2DImode;\n-\t  default:\n-\t    break;\n-\t  }\n+\treturn aarch64_vq_mode (mode).else_mode (word_mode);\n       else\n \tswitch (mode)\n \t  {\n@@ -14946,6 +15050,36 @@ aarch64_simd_check_vect_par_cnst_half (rtx op, machine_mode mode,\n   return true;\n }\n \n+/* Return a PARALLEL containing NELTS elements, with element I equal\n+   to BASE + I * STEP.  */\n+\n+rtx\n+aarch64_gen_stepped_int_parallel (unsigned int nelts, int base, int step)\n+{\n+  rtvec vec = rtvec_alloc (nelts);\n+  for (unsigned int i = 0; i < nelts; ++i)\n+    RTVEC_ELT (vec, i) = gen_int_mode (base + i * step, DImode);\n+  return gen_rtx_PARALLEL (VOIDmode, vec);\n+}\n+\n+/* Return true if OP is a PARALLEL of CONST_INTs that form a linear\n+   series with step STEP.  */\n+\n+bool\n+aarch64_stepped_int_parallel_p (rtx op, int step)\n+{\n+  if (GET_CODE (op) != PARALLEL || !CONST_INT_P (XVECEXP (op, 0, 0)))\n+    return false;\n+\n+  unsigned HOST_WIDE_INT base = UINTVAL (XVECEXP (op, 0, 0));\n+  for (int i = 1; i < XVECLEN (op, 0); ++i)\n+    if (!CONST_INT_P (XVECEXP (op, 0, i))\n+\t|| UINTVAL (XVECEXP (op, 0, i)) != base + i * step)\n+      return false;\n+\n+  return true;\n+}\n+\n /* Bounds-check lanes.  Ensure OPERAND lies between LOW (inclusive) and\n    HIGH (exclusive).  */\n void\n@@ -14998,6 +15132,25 @@ aarch64_sve_ld1r_operand_p (rtx op)\n \t  && offset_6bit_unsigned_scaled_p (mode, addr.const_offset));\n }\n \n+/* Return true if OP is a valid MEM operand for an SVE LD1RQ instruction.  */\n+bool\n+aarch64_sve_ld1rq_operand_p (rtx op)\n+{\n+  struct aarch64_address_info addr;\n+  scalar_mode elem_mode = GET_MODE_INNER (GET_MODE (op));\n+  if (!MEM_P (op)\n+      || !aarch64_classify_address (&addr, XEXP (op, 0), elem_mode, false))\n+    return false;\n+\n+  if (addr.type == ADDRESS_REG_IMM)\n+    return offset_4bit_signed_scaled_p (TImode, addr.const_offset);\n+\n+  if (addr.type == ADDRESS_REG_REG)\n+    return (1U << addr.shift) == GET_MODE_SIZE (elem_mode);\n+\n+  return false;\n+}\n+\n /* Return true if OP is a valid MEM operand for an SVE LDR instruction.\n    The conditions for STR are the same.  */\n bool"}, {"sha": "a8dd070333d40092854994553a3dc0d05b458463", "filename": "gcc/config/aarch64/aarch64.md", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Faarch64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.md?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -234,6 +234,7 @@\n     UNSPEC_CLASTB\n     UNSPEC_FADDA\n     UNSPEC_REV_SUBREG\n+    UNSPEC_REINTERPRET\n     UNSPEC_SPECULATION_TRACKER\n     UNSPEC_COPYSIGN\n     UNSPEC_TTEST\t\t; Represent transaction test."}, {"sha": "cbeaceb3df9485a30cb72a4b30035b9d6a10cdba", "filename": "gcc/config/aarch64/constraints.md", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fconstraints.md?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -272,6 +272,12 @@\n        (match_test \"aarch64_legitimate_address_p (V2DImode,\n \t\t\t\t\t\t  XEXP (op, 0), 1)\")))\n \n+(define_memory_constraint \"UtQ\"\n+  \"@internal\n+   An address valid for SVE LD1RQs.\"\n+  (and (match_code \"mem\")\n+       (match_test \"aarch64_sve_ld1rq_operand_p (op)\")))\n+\n (define_memory_constraint \"Uty\"\n   \"@internal\n    An address valid for SVE LD1Rs.\""}, {"sha": "5d229f8cc0ee9cf8dea96b9a2289f08c2f85190c", "filename": "gcc/config/aarch64/predicates.md", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fconfig%2Faarch64%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fpredicates.md?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -431,6 +431,12 @@\n   return aarch64_simd_check_vect_par_cnst_half (op, mode, false);\n })\n \n+(define_predicate \"descending_int_parallel\"\n+  (match_code \"parallel\")\n+{\n+  return aarch64_stepped_int_parallel_p (op, -1);\n+})\n+\n (define_special_predicate \"aarch64_simd_lshift_imm\"\n   (match_code \"const,const_vector\")\n {\n@@ -543,6 +549,10 @@\n   (and (match_operand 0 \"memory_operand\")\n        (match_test \"aarch64_sve_ld1r_operand_p (op)\")))\n \n+(define_predicate \"aarch64_sve_ld1rq_operand\"\n+  (and (match_code \"mem\")\n+       (match_test \"aarch64_sve_ld1rq_operand_p (op)\")))\n+\n ;; Like memory_operand, but restricted to addresses that are valid for\n ;; SVE LDR and STR instructions.\n (define_predicate \"aarch64_sve_ldr_operand\""}, {"sha": "005ec80e89d273edaee9cc26e26981353b8f3476", "filename": "gcc/machmode.h", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fmachmode.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Fmachmode.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmachmode.h?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -251,7 +251,8 @@ class opt_mode\n   ALWAYS_INLINE opt_mode (from_int m) : m_mode (machine_mode (m)) {}\n \n   machine_mode else_void () const;\n-  machine_mode else_blk () const;\n+  machine_mode else_blk () const { return else_mode (BLKmode); }\n+  machine_mode else_mode (machine_mode) const;\n   T require () const;\n \n   bool exists () const;\n@@ -271,13 +272,13 @@ opt_mode<T>::else_void () const\n   return m_mode;\n }\n \n-/* If the T exists, return its enum value, otherwise return E_BLKmode.  */\n+/* If the T exists, return its enum value, otherwise return FALLBACK.  */\n \n template<typename T>\n inline machine_mode\n-opt_mode<T>::else_blk () const\n+opt_mode<T>::else_mode (machine_mode fallback) const\n {\n-  return m_mode == E_VOIDmode ? E_BLKmode : m_mode;\n+  return m_mode == E_VOIDmode ? fallback : m_mode;\n }\n \n /* Assert that the object contains a T and return it.  */"}, {"sha": "11bbee10f0af1a58068e5d86b7875d4d5a5838c9", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -1,3 +1,22 @@\n+2019-08-13  Richard Sandiford  <richard.sandiford@arm.com>\n+\n+\t* gcc.target/aarch64/sve/init_2.c: Expect ld1rd to be used\n+\tinstead of a full vector load.\n+\t* gcc.target/aarch64/sve/init_4.c: Likewise.\n+\t* gcc.target/aarch64/sve/ld1r_2.c: Remove constants that no longer\n+\tneed to be loaded from memory.\n+\t* gcc.target/aarch64/sve/slp_2.c: Expect the same output for\n+\tbig and little endian.\n+\t* gcc.target/aarch64/sve/slp_3.c: Likewise.  Expect 3 of the\n+\tdoubles to be moved via integer registers rather than loaded\n+\tfrom memory.\n+\t* gcc.target/aarch64/sve/slp_4.c: Likewise but for 4 doubles.\n+\t* gcc.target/aarch64/sve/spill_4.c: Expect 16-bit constants to be\n+\tloaded via an integer register rather than from memory.\n+\t* gcc.target/aarch64/sve/const_1.c: New test.\n+\t* gcc.target/aarch64/sve/const_2.c: Likewise.\n+\t* gcc.target/aarch64/sve/const_3.c: Likewise.\n+\n 2019-08-13  Jozef Lawrynowicz  <jozef.l@mittosystems.com>\n \n \t* gcc.target/msp430/msp430.exp (msp430_device_permutations_runtest):"}, {"sha": "ae25dcb73849aca0e140df262c2c2bb178379afb", "filename": "gcc/testsuite/gcc.target/aarch64/sve/const_1.c", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_1.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -0,0 +1,13 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O3\" } */\n+\n+#include <stdint.h>\n+\n+void\n+set (uint64_t *dst, int count)\n+{\n+  for (int i = 0; i < count; ++i)\n+    dst[i] = 0xffff00ff00ffff00ULL;\n+}\n+\n+/* { dg-final { scan-assembler {\\tmovi\\tv([0-9]+)\\.2d, 0xffff00ff00ffff00\\n.*\\tdup\\tz[0-9]+\\.q, z\\1\\.q\\[0\\]\\n} } } */"}, {"sha": "7b2b5c2a13ae402d7faea82c63b4d87ae8298950", "filename": "gcc/testsuite/gcc.target/aarch64/sve/const_2.c", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_2.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -0,0 +1,20 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O3\" } */\n+\n+#include <stdint.h>\n+\n+#define TEST(TYPE, CONST)\t\t\t\\\n+  void\t\t\t\t\t\t\\\n+  set_##TYPE (TYPE *dst, int count)\t\t\\\n+  {\t\t\t\t\t\t\\\n+    for (int i = 0; i < count; ++i)\t\t\\\n+      dst[i] = CONST;\t\t\t\t\\\n+  }\n+\n+TEST (uint16_t, 129)\n+TEST (uint32_t, 129)\n+TEST (uint64_t, 129)\n+\n+/* { dg-final { scan-assembler {\\tmovi\\tv([0-9]+)\\.8h, 0x81\\n[^:]*\\tdup\\tz[0-9]+\\.q, z\\1\\.q\\[0\\]\\n} } } */\n+/* { dg-final { scan-assembler {\\tmovi\\tv([0-9]+)\\.4s, 0x81\\n[^:]*\\tdup\\tz[0-9]+\\.q, z\\1\\.q\\[0\\]\\n} } } */\n+/* { dg-final { scan-assembler {\\tmov\\t(x[0-9]+), 129\\n[^:]*\\tmov\\tz[0-9]+\\.d, \\1\\n} } } */"}, {"sha": "c18ceaedc7103e373833b0e11704b11cca1e8b16", "filename": "gcc/testsuite/gcc.target/aarch64/sve/const_3.c", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fconst_3.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -0,0 +1,20 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O3\" } */\n+\n+#include <stdint.h>\n+\n+#define TEST(TYPE, CONST)\t\t\t\\\n+  void\t\t\t\t\t\t\\\n+  set_##TYPE (TYPE *dst, int count)\t\t\\\n+  {\t\t\t\t\t\t\\\n+    for (int i = 0; i < count; ++i)\t\t\\\n+      dst[i] = CONST;\t\t\t\t\\\n+  }\n+\n+TEST (uint16_t, 0x1234)\n+TEST (uint32_t, 0x1234)\n+TEST (uint64_t, 0x1234)\n+\n+/* { dg-final { scan-assembler {\\tmov\\t(w[0-9]+), 4660\\n[^:]*\\tmov\\tz[0-9]+\\.h, \\1\\n} } } */\n+/* { dg-final { scan-assembler {\\tmov\\t(w[0-9]+), 4660\\n[^:]*\\tmov\\tz[0-9]+\\.s, \\1\\n} } } */\n+/* { dg-final { scan-assembler {\\tmov\\t(x[0-9]+), 4660\\n[^:]*\\tmov\\tz[0-9]+\\.d, \\1\\n} } } */"}, {"sha": "0a8aa8decd14495192ee4e7486b563c0ddeab493", "filename": "gcc/testsuite/gcc.target/aarch64/sve/init_2.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Finit_2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Finit_2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Finit_2.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -11,9 +11,9 @@ typedef int32_t vnx4si __attribute__((vector_size (32)));\n /*\n ** foo:\n **\t...\n-**\tld1w\t(z[0-9]+\\.s), p[0-9]+/z, \\[x[0-9]+\\]\n-**\tinsr\t\\1, w1\n-**\tinsr\t\\1, w0\n+**\tld1rd\t(z[0-9]+)\\.d, p[0-9]+/z, \\[x[0-9]+\\]\n+**\tinsr\t\\1\\.s, w1\n+**\tinsr\t\\1\\.s, w0\n **\t...\n */\n __attribute__((noipa))"}, {"sha": "0fa99c15195d50761fa99759c89497716e9635a0", "filename": "gcc/testsuite/gcc.target/aarch64/sve/init_4.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Finit_4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Finit_4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Finit_4.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -11,10 +11,10 @@ typedef int32_t vnx4si __attribute__((vector_size (32)));\n /*\n ** foo:\n **\t...\n-**\tld1w\t(z[0-9]+\\.s), p[0-9]+/z, \\[x[0-9]+\\]\n-**\tinsr\t\\1, w1\n-**\tinsr\t\\1, w0\n-**\trev\t\\1, \\1\n+**\tld1rd\t(z[0-9]+)\\.d, p[0-9]+/z, \\[x[0-9]+\\]\n+**\tinsr\t\\1\\.s, w1\n+**\tinsr\t\\1\\.s, w0\n+**\trev\t\\1\\.s, \\1\\.s\n **\t...\n */\n __attribute__((noipa))"}, {"sha": "e0e0f4ee65b6aa72fff707b7601d4d94fe31dbf4", "filename": "gcc/testsuite/gcc.target/aarch64/sve/ld1r_2.c", "status": "modified", "additions": 3, "deletions": 19, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fld1r_2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fld1r_2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fld1r_2.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -28,22 +28,6 @@\n   T (int64_t)\n \n #define FOR_EACH_LOAD_BROADCAST_IMM(T)\t\t\t\t\t\\\n-  T (int16_t, 129, imm_129)\t\t\t\t\t\t\\\n-  T (int32_t, 129, imm_129)\t\t\t\t\t\t\\\n-  T (int64_t, 129, imm_129)\t\t\t\t\t\t\\\n-\t\t\t\t\t\t\t\t\t\\\n-  T (int16_t, -130, imm_m130)\t\t\t\t\t\t\\\n-  T (int32_t, -130, imm_m130)\t\t\t\t\t\t\\\n-  T (int64_t, -130, imm_m130)\t\t\t\t\t\t\\\n-\t\t\t\t\t\t\t\t\t\\\n-  T (int16_t, 0x1234, imm_0x1234)\t\t\t\t\t\\\n-  T (int32_t, 0x1234, imm_0x1234)\t\t\t\t\t\\\n-  T (int64_t, 0x1234, imm_0x1234)\t\t\t\t\t\\\n-\t\t\t\t\t\t\t\t\t\\\n-  T (int16_t, 0xFEDC, imm_0xFEDC)\t\t\t\t\t\\\n-  T (int32_t, 0xFEDC, imm_0xFEDC)\t\t\t\t\t\\\n-  T (int64_t, 0xFEDC, imm_0xFEDC)\t\t\t\t\t\\\n-\t\t\t\t\t\t\t\t\t\\\n   T (int32_t, 0x12345678, imm_0x12345678)\t\t\t\t\\\n   T (int64_t, 0x12345678, imm_0x12345678)\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n@@ -56,6 +40,6 @@ FOR_EACH_LOAD_BROADCAST (DEF_LOAD_BROADCAST)\n FOR_EACH_LOAD_BROADCAST_IMM (DEF_LOAD_BROADCAST_IMM)\n \n /* { dg-final { scan-assembler-times {\\tld1rb\\tz[0-9]+\\.b, p[0-7]/z, } 1 } } */\n-/* { dg-final { scan-assembler-times {\\tld1rh\\tz[0-9]+\\.h, p[0-7]/z, } 5 } } */\n-/* { dg-final { scan-assembler-times {\\tld1rw\\tz[0-9]+\\.s, p[0-7]/z, } 7 } } */\n-/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, p[0-7]/z, } 8 } } */\n+/* { dg-final { scan-assembler-times {\\tld1rh\\tz[0-9]+\\.h, p[0-7]/z, } 1 } } */\n+/* { dg-final { scan-assembler-times {\\tld1rw\\tz[0-9]+\\.s, p[0-7]/z, } 3 } } */\n+/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, p[0-7]/z, } 4 } } */"}, {"sha": "d4b9776fe9ba6745a43be0cee1f2e45882b7616e", "filename": "gcc/testsuite/gcc.target/aarch64/sve/slp_2.c", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_2.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -29,12 +29,9 @@ vec_slp_##TYPE (TYPE *restrict a, int n)\t\t\t\\\n \n TEST_ALL (VEC_PERM)\n \n-/* { dg-final { scan-assembler-times {\\tld1rh\\tz[0-9]+\\.h, } 2 { target aarch64_little_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rqb\\tz[0-9]+\\.b, } 2 { target aarch64_big_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rw\\tz[0-9]+\\.s, } 3 { target aarch64_little_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rqh\\tz[0-9]+\\.h, } 3 { target aarch64_big_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 3 { target aarch64_little_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rqw\\tz[0-9]+\\.s, } 3 { target aarch64_big_endian } } } */\n+/* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.h, w[0-9]+\\n} 2 } } */\n+/* { dg-final { scan-assembler-times {\\tld1rw\\tz[0-9]+\\.s, } 3 } } */\n+/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 3 } } */\n /* { dg-final { scan-assembler-times {\\tld1rqd\\tz[0-9]+\\.d, } 3 } } */\n /* { dg-final { scan-assembler-not {\\tzip1\\t} } } */\n /* { dg-final { scan-assembler-not {\\tzip2\\t} } } */"}, {"sha": "82dd43a4d98db9d15ca0a6441a3a5da78bced87f", "filename": "gcc/testsuite/gcc.target/aarch64/sve/slp_3.c", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_3.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -32,18 +32,17 @@ vec_slp_##TYPE (TYPE *restrict a, int n)\t\t\t\\\n TEST_ALL (VEC_PERM)\n \n /* 1 for each 8-bit type.  */\n-/* { dg-final { scan-assembler-times {\\tld1rw\\tz[0-9]+\\.s, } 2 { target aarch64_little_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rqb\\tz[0-9]+\\.b, } 2 { target aarch64_big_endian } } } */\n-/* 1 for each 16-bit type and 4 for double.  */\n-/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 7 { target aarch64_little_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rqh\\tz[0-9]+\\.h, } 3 { target aarch64_big_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 4 { target aarch64_big_endian } } } */\n+/* { dg-final { scan-assembler-times {\\tld1rw\\tz[0-9]+\\.s, } 2 } } */\n+/* 1 for each 16-bit type plus 1 for double.  */\n+/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 4 } } */\n /* 1 for each 32-bit type.  */\n /* { dg-final { scan-assembler-times {\\tld1rqw\\tz[0-9]+\\.s, } 3 } } */\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #41\\n} 2 } } */\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #25\\n} 2 } } */\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #31\\n} 2 } } */\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #62\\n} 2 } } */\n+/* 3 for double.  */\n+/* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, x[0-9]+\\n} 3 } } */\n /* The 64-bit types need:\n \n       ZIP1 ZIP1 (2 ZIP2s optimized away)"}, {"sha": "49fb828e874f05d6448325780084f9cfb253fc01", "filename": "gcc/testsuite/gcc.target/aarch64/sve/slp_4.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fslp_4.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -35,10 +35,8 @@ vec_slp_##TYPE (TYPE *restrict a, int n)\t\t\t\\\n \n TEST_ALL (VEC_PERM)\n \n-/* 1 for each 8-bit type, 4 for each 32-bit type and 8 for double.  */\n-/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 22 { target aarch64_little_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rqb\\tz[0-9]+\\.b, } 2 { target aarch64_big_endian } } } */\n-/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 20 { target aarch64_big_endian } } } */\n+/* 1 for each 8-bit type, 4 for each 32-bit type and 4 for double.  */\n+/* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d, } 18 } } */\n /* 1 for each 16-bit type.  */\n /* { dg-final { scan-assembler-times {\\tld1rqh\\tz[0-9]\\.h, } 3 } } */\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #99\\n} 2 } } */\n@@ -49,6 +47,8 @@ TEST_ALL (VEC_PERM)\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #37\\n} 2 } } */\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #24\\n} 2 } } */\n /* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, #81\\n} 2 } } */\n+/* 4 for double.  */\n+/* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.d, x[0-9]+\\n} 4 } } */\n /* The 32-bit types need:\n \n       ZIP1 ZIP1 (2 ZIP2s optimized away)"}, {"sha": "4398e018f2e3959c3eab44ebf3d651c8494f33bc", "filename": "gcc/testsuite/gcc.target/aarch64/sve/spill_4.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fspill_4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fspill_4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Fspill_4.c?ref=4aeb1ba7f62c1d680c819ae3e137c3bad6f520ca", "patch": "@@ -24,10 +24,10 @@ TEST_LOOP (uint16_t, 0x1234);\n TEST_LOOP (uint32_t, 0x12345);\n TEST_LOOP (uint64_t, 0x123456);\n \n-/* { dg-final { scan-assembler-times {\\tptrue\\tp[0-9]+\\.h,} 3 } } */\n+/* { dg-final { scan-assembler-not {\\tptrue\\tp[0-9]+\\.h,} } } */\n /* { dg-final { scan-assembler-times {\\tptrue\\tp[0-9]+\\.s,} 3 } } */\n /* { dg-final { scan-assembler-times {\\tptrue\\tp[0-9]+\\.d,} 3 } } */\n-/* { dg-final { scan-assembler-times {\\tld1rh\\tz[0-9]+\\.h,} 3 } } */\n+/* { dg-final { scan-assembler-times {\\tmov\\tz[0-9]+\\.h, w[0-9]+\\n} 3 } } */\n /* { dg-final { scan-assembler-times {\\tld1rw\\tz[0-9]+\\.s,} 3 } } */\n /* { dg-final { scan-assembler-times {\\tld1rd\\tz[0-9]+\\.d,} 3 } } */\n /* { dg-final { scan-assembler-not {\\tldr\\tz[0-9]} } } */"}]}