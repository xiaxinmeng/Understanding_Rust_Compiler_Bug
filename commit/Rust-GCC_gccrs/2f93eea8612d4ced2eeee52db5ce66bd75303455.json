{"sha": "2f93eea8612d4ced2eeee52db5ce66bd75303455", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MmY5M2VlYTg2MTJkNGNlZDJlZWVlNTJkYjVjZTY2YmQ3NTMwMzQ1NQ==", "commit": {"author": {"name": "Paolo Bonzini", "email": "bonzini@gnu.org", "date": "2004-05-25T12:04:17Z"}, "committer": {"name": "Paolo Bonzini", "email": "bonzini@gcc.gnu.org", "date": "2004-05-25T12:04:17Z"}, "message": "Makefile.in (OBJS): Add rtlhooks.o.\n\n2004-05-25  Paolo Bonzini  <bonzini@gnu.org>\n\n\t* Makefile.in (OBJS): Add rtlhooks.o.\n\t(rtlanal.o): Depend on function.h.\n\t(cse.o): Depend on rtlhooks-def.h.\n\t(combine.o): Depend on rtlhooks-def.h.\n\t(rtlhooks.o): New rule.\n\t* combine.c: Include rtlhooks-def.h.\n\t(nonzero_bits, cached_nonzero_bits, nonzero_bits1,\n\tnum_sign_bit_copies, cached_num_sign_bit_copies,\n\tnum_sign_bit_copies1): Move most of the code to rtlanal.c.\n\t(reg_nonzero_bits_for_combine,\n\treg_num_sign_bit_copies_for_combine): New functions holding\n\tthe remnants of the above.\n\t(combine_rtl_hooks): New.\n\t(combine_instructions): Set rtl_hooks instead of gen_lowpart.\n\t* cse.c: Include rtlhooks-def.h.\n\t(cse_rtl_hooks): New.\n\t(cse_main): Set rtl_hooks instead of gen_lowpart.\n\t* emit-rtl.c (gen_lowpart): Remove.\n\t(gen_lowpart_general): Move to rtlhooks.c.\n\t* rtl.h (nonzero_bits, num_sign_bit_copies,\n\tstruct rtl_hooks, rtl_hooks, general_rtl_hooks): New.\n\t(gen_lowpart_general): Remove.\n\t(gen_lowpart): Temporarily redefine as a macro.\n\t* rtlanal.c: Include function.h.\n\t(nonzero_bits, cached_nonzero_bits, nonzero_bits1,\n\tnum_sign_bit_copies, cached_num_sign_bit_copies,\n\tnum_sign_bit_copies1): New, from combine.c.\n\t* rtlhooks.c: New file.\n\nFrom-SVN: r82234", "tree": {"sha": "0fecbc9fb7d6fe74247aea9809ba392638ca87c6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0fecbc9fb7d6fe74247aea9809ba392638ca87c6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2f93eea8612d4ced2eeee52db5ce66bd75303455", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2f93eea8612d4ced2eeee52db5ce66bd75303455", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2f93eea8612d4ced2eeee52db5ce66bd75303455", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2f93eea8612d4ced2eeee52db5ce66bd75303455/comments", "author": {"login": "bonzini", "id": 42082, "node_id": "MDQ6VXNlcjQyMDgy", "avatar_url": "https://avatars.githubusercontent.com/u/42082?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bonzini", "html_url": "https://github.com/bonzini", "followers_url": "https://api.github.com/users/bonzini/followers", "following_url": "https://api.github.com/users/bonzini/following{/other_user}", "gists_url": "https://api.github.com/users/bonzini/gists{/gist_id}", "starred_url": "https://api.github.com/users/bonzini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bonzini/subscriptions", "organizations_url": "https://api.github.com/users/bonzini/orgs", "repos_url": "https://api.github.com/users/bonzini/repos", "events_url": "https://api.github.com/users/bonzini/events{/privacy}", "received_events_url": "https://api.github.com/users/bonzini/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "11338cda74ae54f5f8a86a271bcd04cb604ec806", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/11338cda74ae54f5f8a86a271bcd04cb604ec806", "html_url": "https://github.com/Rust-GCC/gccrs/commit/11338cda74ae54f5f8a86a271bcd04cb604ec806"}], "stats": {"total": 2257, "additions": 1278, "deletions": 979}, "files": [{"sha": "5248ce15104b3ef2209ee13dc0b5ac00c000e881", "filename": "gcc/ChangeLog", "status": "modified", "additions": 31, "deletions": 0, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -1,3 +1,34 @@\n+2004-05-25  Paolo Bonzini  <bonzini@gnu.org>\n+\n+\t* Makefile.in (OBJS): Add rtlhooks.o.\n+\t(rtlanal.o): Depend on function.h.\n+\t(cse.o): Depend on rtlhooks-def.h.\n+\t(combine.o): Depend on rtlhooks-def.h.\n+\t(rtlhooks.o): New rule.\n+\t* combine.c: Include rtlhooks-def.h.\n+\t(nonzero_bits, cached_nonzero_bits, nonzero_bits1,\n+\tnum_sign_bit_copies, cached_num_sign_bit_copies,\n+\tnum_sign_bit_copies1): Move most of the code to rtlanal.c.\n+\t(reg_nonzero_bits_for_combine,\n+\treg_num_sign_bit_copies_for_combine): New functions holding\n+\tthe remnants of the above.\n+\t(combine_rtl_hooks): New.\n+\t(combine_instructions): Set rtl_hooks instead of gen_lowpart.\n+\t* cse.c: Include rtlhooks-def.h.\n+\t(cse_rtl_hooks): New.\n+\t(cse_main): Set rtl_hooks instead of gen_lowpart.\n+\t* emit-rtl.c (gen_lowpart): Remove.\n+\t(gen_lowpart_general): Move to rtlhooks.c.\n+\t* rtl.h (nonzero_bits, num_sign_bit_copies,\n+\tstruct rtl_hooks, rtl_hooks, general_rtl_hooks): New.\n+\t(gen_lowpart_general): Remove.\n+\t(gen_lowpart): Temporarily redefine as a macro.\n+\t* rtlanal.c: Include function.h.\n+\t(nonzero_bits, cached_nonzero_bits, nonzero_bits1,\n+\tnum_sign_bit_copies, cached_num_sign_bit_copies,\n+\tnum_sign_bit_copies1): New, from combine.c.\n+\t* rtlhooks.c: New file. \n+\n 2004-05-25  Svein E. Seldal  <Svein.Seldal@solidas.com>\n \n \t* config/avr/avr.h (LONG_LONG_TYPE_SIZE): Changed long long type"}, {"sha": "568b263a1917f33b5b3a5ed89fe781a839e017d7", "filename": "gcc/Makefile.in", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -901,7 +901,7 @@ OBJS-common = \\\n  targhooks.o timevar.o toplev.o tracer.o tree.o tree-dump.o unroll.o\t   \\\n  varasm.o varray.o version.o vmsdbgout.o xcoffout.o alloc-pool.o\t   \\\n  et-forest.o cfghooks.o bt-load.o pretty-print.o $(GGC) web.o passes.o\t   \\\n- rtl-profile.o tree-profile.o\n+ rtl-profile.o tree-profile.o rtlhooks.o\n \n OBJS-md = $(out_object_file)\n OBJS-archive = $(EXTRA_OBJS) $(host_hook_obj) tree-inline.o\t\t   \\\n@@ -1735,7 +1735,7 @@ print-rtl.o : print-rtl.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n     $(RTL_H) $(TREE_H) hard-reg-set.h $(BASIC_BLOCK_H) real.h $(TM_P_H)\n rtlanal.o : rtlanal.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) toplev.h \\\n    $(RTL_H) hard-reg-set.h $(TM_P_H) insn-config.h $(RECOG_H) real.h flags.h \\\n-   $(BASIC_BLOCK_H) $(REGS_H) output.h target.h\n+   $(BASIC_BLOCK_H) $(REGS_H) output.h target.h function.h\n \n errors.o : errors.c $(CONFIG_H) $(SYSTEM_H) errors.h\n \t$(CC) -c $(ALL_CFLAGS) -DGENERATOR_FILE $(ALL_CPPFLAGS) $(INCLUDES) $< $(OUTPUT_OPTION)\n@@ -1837,7 +1837,7 @@ cselib.o : cselib.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(REGS_\n cse.o : cse.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(REGS_H) \\\n    hard-reg-set.h flags.h real.h insn-config.h $(RECOG_H) $(EXPR_H) toplev.h \\\n    output.h function.h $(BASIC_BLOCK_H) $(GGC_H) $(TM_P_H) $(TIMEVAR_H) \\\n-   except.h $(TARGET_H) $(PARAMS_H)\n+   except.h $(TARGET_H) $(PARAMS_H) rtlhooks-def.h\n web.o : web.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(REGS_H) \\\n    hard-reg-set.h flags.h $(BASIC_BLOCK_H) function.h output.h toplev.h df.h\n gcse.o : gcse.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(REGS_H) \\\n@@ -1938,7 +1938,7 @@ dominance.o : dominance.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n    hard-reg-set.h $(BASIC_BLOCK_H) et-forest.h\n et-forest.o : et-forest.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) et-forest.h alloc-pool.h\n combine.o : combine.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) flags.h \\\n-   function.h insn-config.h $(INSN_ATTR_H) $(REGS_H) $(EXPR_H) \\\n+   function.h insn-config.h $(INSN_ATTR_H) $(REGS_H) $(EXPR_H) rtlhooks-def.h \\\n    $(BASIC_BLOCK_H) $(RECOG_H) real.h hard-reg-set.h toplev.h $(TM_P_H) $(TREE_H) $(TARGET_H)\n regclass.o : regclass.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n    hard-reg-set.h flags.h $(BASIC_BLOCK_H) $(REGS_H) insn-config.h $(RECOG_H) reload.h \\\n@@ -1975,6 +1975,8 @@ reload1.o : reload1.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) real.\n    $(EXPR_H) $(OPTABS_H) reload.h $(REGS_H) hard-reg-set.h insn-config.h \\\n    $(BASIC_BLOCK_H) $(RECOG_H) output.h function.h toplev.h $(TM_P_H) \\\n    except.h $(TREE_H)\n+rtlhooks.o :  rtlhooks.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n+   rtlhooks-def.h $(EXPR_H)\n postreload.o : postreload.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) real.h flags.h \\\n    $(EXPR_H) $(OPTABS_H) reload.h $(REGS_H) hard-reg-set.h insn-config.h \\\n    $(BASIC_BLOCK_H) $(RECOG_H) output.h function.h toplev.h cselib.h $(TM_P_H) \\"}, {"sha": "64af27c779bd3e3ecc84f4e62ad8e0084b08c475", "filename": "gcc/combine.c", "status": "modified", "additions": 101, "deletions": 912, "changes": 1013, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -90,6 +90,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"real.h\"\n #include \"toplev.h\"\n #include \"target.h\"\n+#include \"rtlhooks-def.h\"\n \n /* Number of attempts to combine instructions in this function.  */\n \n@@ -133,12 +134,6 @@ static int max_uid_cuid;\n #define UWIDE_SHIFT_LEFT_BY_BITS_PER_WORD(val) \\\n   (((unsigned HOST_WIDE_INT) (val) << (BITS_PER_WORD - 1)) << 1)\n \n-#define nonzero_bits(X, M) \\\n-  cached_nonzero_bits (X, M, NULL_RTX, VOIDmode, 0)\n-\n-#define num_sign_bit_copies(X, M) \\\n-  cached_num_sign_bit_copies (X, M, NULL_RTX, VOIDmode, 0)\n-\n /* Maximum register number, which is the size of the tables below.  */\n \n static unsigned int combine_max_regno;\n@@ -337,6 +332,13 @@ static struct undobuf undobuf;\n \n static int n_occurrences;\n \n+static rtx reg_nonzero_bits_for_combine (rtx, enum machine_mode, rtx,\n+\t\t\t\t\t enum machine_mode,\n+\t\t\t\t\t unsigned HOST_WIDE_INT,\n+\t\t\t\t\t unsigned HOST_WIDE_INT *);\n+static rtx reg_num_sign_bit_copies_for_combine (rtx, enum machine_mode, rtx,\n+\t\t\t\t\t\tenum machine_mode,\n+\t\t\t\t\t\tunsigned int, unsigned int *);\n static void do_SUBST (rtx *, rtx);\n static void do_SUBST_INT (int *, int);\n static void init_reg_last (void);\n@@ -372,17 +374,6 @@ static rtx make_field_assignment (rtx);\n static rtx apply_distributive_law (rtx);\n static rtx simplify_and_const_int (rtx, enum machine_mode, rtx,\n \t\t\t\t   unsigned HOST_WIDE_INT);\n-static unsigned HOST_WIDE_INT cached_nonzero_bits (rtx, enum machine_mode,\n-\t\t\t\t\t\t   rtx, enum machine_mode,\n-\t\t\t\t\t\t   unsigned HOST_WIDE_INT);\n-static unsigned HOST_WIDE_INT nonzero_bits1 (rtx, enum machine_mode, rtx,\n-\t\t\t\t\t     enum machine_mode,\n-\t\t\t\t\t     unsigned HOST_WIDE_INT);\n-static unsigned int cached_num_sign_bit_copies (rtx, enum machine_mode, rtx,\n-\t\t\t\t\t\tenum machine_mode,\n-\t\t\t\t\t\tunsigned int);\n-static unsigned int num_sign_bit_copies1 (rtx, enum machine_mode, rtx,\n-\t\t\t\t\t  enum machine_mode, unsigned int);\n static int merge_outer_ops (enum rtx_code *, HOST_WIDE_INT *, enum rtx_code,\n \t\t\t    HOST_WIDE_INT, enum machine_mode, int *);\n static rtx simplify_shift_const\t(rtx, enum rtx_code, enum machine_mode, rtx,\n@@ -412,6 +403,21 @@ static rtx reversed_comparison (rtx, enum machine_mode, rtx, rtx);\n static enum rtx_code combine_reversed_comparison_code (rtx);\n static int unmentioned_reg_p_1 (rtx *, void *);\n static bool unmentioned_reg_p (rtx, rtx);\n+\f\n+\n+/* It is not safe to use ordinary gen_lowpart in combine.\n+   See comments in gen_lowpart_for_combine.  */\n+#undef RTL_HOOKS_GEN_LOWPART\n+#define RTL_HOOKS_GEN_LOWPART              gen_lowpart_for_combine\n+\n+#undef RTL_HOOKS_REG_NONZERO_REG_BITS\n+#define RTL_HOOKS_REG_NONZERO_REG_BITS     reg_nonzero_bits_for_combine\n+\n+#undef RTL_HOOKS_REG_NUM_SIGN_BIT_COPIES\n+#define RTL_HOOKS_REG_NUM_SIGN_BIT_COPIES  reg_num_sign_bit_copies_for_combine\n+\n+static const struct rtl_hooks combine_rtl_hooks = RTL_HOOKS_INITIALIZER;\n+\n \f\n /* Substitute NEWVAL, an rtx expression, into INTO, a place in some\n    insn.  The substitution can be undone by undo_all.  If INTO is already\n@@ -522,9 +528,7 @@ combine_instructions (rtx f, unsigned int nregs)\n \n   combine_max_regno = nregs;\n \n-  /* It is not safe to use ordinary gen_lowpart in combine.\n-     See comments in gen_lowpart_for_combine.  */\n-  gen_lowpart = gen_lowpart_for_combine;\n+  rtl_hooks = combine_rtl_hooks;\n \n   reg_stat = xcalloc (nregs, sizeof (struct reg_stat));\n \n@@ -777,7 +781,7 @@ combine_instructions (rtx f, unsigned int nregs)\n   total_successes += combine_successes;\n \n   nonzero_sign_valid = 0;\n-  gen_lowpart = gen_lowpart_general;\n+  rtl_hooks = general_rtl_hooks;\n \n   /* Make recognizer allow volatile MEMs again.  */\n   init_recog ();\n@@ -7997,932 +8001,117 @@ simplify_and_const_int (rtx x, enum machine_mode mode, rtx varop,\n   return x;\n }\n \f\n-#define nonzero_bits_with_known(X, MODE) \\\n-  cached_nonzero_bits (X, MODE, known_x, known_mode, known_ret)\n-\n-/* The function cached_nonzero_bits is a wrapper around nonzero_bits1.\n-   It avoids exponential behavior in nonzero_bits1 when X has\n-   identical subexpressions on the first or the second level.  */\n-\n-static unsigned HOST_WIDE_INT\n-cached_nonzero_bits (rtx x, enum machine_mode mode, rtx known_x,\n-\t\t     enum machine_mode known_mode,\n-\t\t     unsigned HOST_WIDE_INT known_ret)\n-{\n-  if (x == known_x && mode == known_mode)\n-    return known_ret;\n-\n-  /* Try to find identical subexpressions.  If found call\n-     nonzero_bits1 on X with the subexpressions as KNOWN_X and the\n-     precomputed value for the subexpression as KNOWN_RET.  */\n-\n-  if (ARITHMETIC_P (x))\n-    {\n-      rtx x0 = XEXP (x, 0);\n-      rtx x1 = XEXP (x, 1);\n-\n-      /* Check the first level.  */\n-      if (x0 == x1)\n-\treturn nonzero_bits1 (x, mode, x0, mode,\n-\t\t\t      nonzero_bits_with_known (x0, mode));\n-\n-      /* Check the second level.  */\n-      if (ARITHMETIC_P (x0)\n-\t  && (x1 == XEXP (x0, 0) || x1 == XEXP (x0, 1)))\n-\treturn nonzero_bits1 (x, mode, x1, mode,\n-\t\t\t      nonzero_bits_with_known (x1, mode));\n-\n-      if (ARITHMETIC_P (x1)\n-\t  && (x0 == XEXP (x1, 0) || x0 == XEXP (x1, 1)))\n-\treturn nonzero_bits1 (x, mode, x0, mode,\n-\t\t\t nonzero_bits_with_known (x0, mode));\n-    }\n-\n-  return nonzero_bits1 (x, mode, known_x, known_mode, known_ret);\n-}\n-\n-/* We let num_sign_bit_copies recur into nonzero_bits as that is useful.\n-   We don't let nonzero_bits recur into num_sign_bit_copies, because that\n-   is less useful.  We can't allow both, because that results in exponential\n-   run time recursion.  There is a nullstone testcase that triggered\n-   this.  This macro avoids accidental uses of num_sign_bit_copies.  */\n-#define cached_num_sign_bit_copies()\n-\n-/* Given an expression, X, compute which bits in X can be nonzero.\n+/* Given a REG, X, compute which bits in X can be nonzero.\n    We don't care about bits outside of those defined in MODE.\n \n    For most X this is simply GET_MODE_MASK (GET_MODE (MODE)), but if X is\n    a shift, AND, or zero_extract, we can do better.  */\n \n-static unsigned HOST_WIDE_INT\n-nonzero_bits1 (rtx x, enum machine_mode mode, rtx known_x,\n-\t       enum machine_mode known_mode,\n-\t       unsigned HOST_WIDE_INT known_ret)\n+static rtx\n+reg_nonzero_bits_for_combine (rtx x, enum machine_mode mode,\n+\t\t\t      rtx known_x ATTRIBUTE_UNUSED,\n+\t\t\t      enum machine_mode known_mode ATTRIBUTE_UNUSED,\n+\t\t\t      unsigned HOST_WIDE_INT known_ret ATTRIBUTE_UNUSED,\n+\t\t\t      unsigned HOST_WIDE_INT *nonzero)\n {\n-  unsigned HOST_WIDE_INT nonzero = GET_MODE_MASK (mode);\n-  unsigned HOST_WIDE_INT inner_nz;\n-  enum rtx_code code;\n-  unsigned int mode_width = GET_MODE_BITSIZE (mode);\n   rtx tem;\n \n-  /* For floating-point values, assume all bits are needed.  */\n-  if (FLOAT_MODE_P (GET_MODE (x)) || FLOAT_MODE_P (mode))\n-    return nonzero;\n+  /* If X is a register whose nonzero bits value is current, use it.\n+     Otherwise, if X is a register whose value we can find, use that\n+     value.  Otherwise, use the previously-computed global nonzero bits\n+     for this register.  */\n \n-  /* If X is wider than MODE, use its mode instead.  */\n-  if (GET_MODE_BITSIZE (GET_MODE (x)) > mode_width)\n+  if (reg_stat[REGNO (x)].last_set_value != 0\n+      && (reg_stat[REGNO (x)].last_set_mode == mode\n+          || (GET_MODE_CLASS (reg_stat[REGNO (x)].last_set_mode) == MODE_INT\n+\t      && GET_MODE_CLASS (mode) == MODE_INT))\n+      && (reg_stat[REGNO (x)].last_set_label == label_tick\n+\t  || (REGNO (x) >= FIRST_PSEUDO_REGISTER\n+\t      && REG_N_SETS (REGNO (x)) == 1\n+\t      && ! REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start,\n+\t\t\t\t    REGNO (x))))\n+      && INSN_CUID (reg_stat[REGNO (x)].last_set) < subst_low_cuid)\n     {\n-      mode = GET_MODE (x);\n-      nonzero = GET_MODE_MASK (mode);\n-      mode_width = GET_MODE_BITSIZE (mode);\n+      *nonzero &= reg_stat[REGNO (x)].last_set_nonzero_bits;\n+      return NULL;\n     }\n \n-  if (mode_width > HOST_BITS_PER_WIDE_INT)\n-    /* Our only callers in this case look for single bit values.  So\n-       just return the mode mask.  Those tests will then be false.  */\n-    return nonzero;\n-\n-#ifndef WORD_REGISTER_OPERATIONS\n-  /* If MODE is wider than X, but both are a single word for both the host\n-     and target machines, we can compute this from which bits of the\n-     object might be nonzero in its own mode, taking into account the fact\n-     that on many CISC machines, accessing an object in a wider mode\n-     causes the high-order bits to become undefined.  So they are\n-     not known to be zero.  */\n-\n-  if (GET_MODE (x) != VOIDmode && GET_MODE (x) != mode\n-      && GET_MODE_BITSIZE (GET_MODE (x)) <= BITS_PER_WORD\n-      && GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT\n-      && GET_MODE_BITSIZE (mode) > GET_MODE_BITSIZE (GET_MODE (x)))\n-    {\n-      nonzero &= nonzero_bits_with_known (x, GET_MODE (x));\n-      nonzero |= GET_MODE_MASK (mode) & ~GET_MODE_MASK (GET_MODE (x));\n-      return nonzero;\n-    }\n-#endif\n+  tem = get_last_value (x);\n \n-  code = GET_CODE (x);\n-  switch (code)\n+  if (tem)\n     {\n-    case REG:\n-#if defined(POINTERS_EXTEND_UNSIGNED) && !defined(HAVE_ptr_extend)\n-      /* If pointers extend unsigned and this is a pointer in Pmode, say that\n-\t all the bits above ptr_mode are known to be zero.  */\n-      if (POINTERS_EXTEND_UNSIGNED && GET_MODE (x) == Pmode\n-\t  && REG_POINTER (x))\n-\tnonzero &= GET_MODE_MASK (ptr_mode);\n-#endif\n-\n-      /* Include declared information about alignment of pointers.  */\n-      /* ??? We don't properly preserve REG_POINTER changes across\n-\t pointer-to-integer casts, so we can't trust it except for\n-\t things that we know must be pointers.  See execute/960116-1.c.  */\n-      if ((x == stack_pointer_rtx\n-\t   || x == frame_pointer_rtx\n-\t   || x == arg_pointer_rtx)\n-\t  && REGNO_POINTER_ALIGN (REGNO (x)))\n-\t{\n-\t  unsigned HOST_WIDE_INT alignment\n-\t    = REGNO_POINTER_ALIGN (REGNO (x)) / BITS_PER_UNIT;\n-\n-#ifdef PUSH_ROUNDING\n-\t  /* If PUSH_ROUNDING is defined, it is possible for the\n-\t     stack to be momentarily aligned only to that amount,\n-\t     so we pick the least alignment.  */\n-\t  if (x == stack_pointer_rtx && PUSH_ARGS)\n-\t    alignment = MIN ((unsigned HOST_WIDE_INT) PUSH_ROUNDING (1),\n-\t\t\t     alignment);\n-#endif\n-\n-\t  nonzero &= ~(alignment - 1);\n-\t}\n-\n-      /* If X is a register whose nonzero bits value is current, use it.\n-\t Otherwise, if X is a register whose value we can find, use that\n-\t value.  Otherwise, use the previously-computed global nonzero bits\n-\t for this register.  */\n-\n-      if (reg_stat[REGNO (x)].last_set_value != 0\n-\t  && (reg_stat[REGNO (x)].last_set_mode == mode\n-\t      || (GET_MODE_CLASS (reg_stat[REGNO (x)].last_set_mode) == MODE_INT\n-\t\t  && GET_MODE_CLASS (mode) == MODE_INT))\n-\t  && (reg_stat[REGNO (x)].last_set_label == label_tick\n-\t      || (REGNO (x) >= FIRST_PSEUDO_REGISTER\n-\t\t  && REG_N_SETS (REGNO (x)) == 1\n-\t\t  && ! REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start,\n-\t\t\t\t\tREGNO (x))))\n-\t  && INSN_CUID (reg_stat[REGNO (x)].last_set) < subst_low_cuid)\n-\treturn reg_stat[REGNO (x)].last_set_nonzero_bits & nonzero;\n-\n-      tem = get_last_value (x);\n-\n-      if (tem)\n-\t{\n-#ifdef SHORT_IMMEDIATES_SIGN_EXTEND\n-\t  /* If X is narrower than MODE and TEM is a non-negative\n-\t     constant that would appear negative in the mode of X,\n-\t     sign-extend it for use in reg_stat[].nonzero_bits because\n-\t     some machines (maybe most) will actually do the sign-extension\n-\t     and this is the conservative approach.\n-\n-\t     ??? For 2.5, try to tighten up the MD files in this regard\n-\t     instead of this kludge.  */\n-\n-\t  if (GET_MODE_BITSIZE (GET_MODE (x)) < mode_width\n-\t      && GET_CODE (tem) == CONST_INT\n-\t      && INTVAL (tem) > 0\n-\t      && 0 != (INTVAL (tem)\n-\t\t       & ((HOST_WIDE_INT) 1\n-\t\t\t  << (GET_MODE_BITSIZE (GET_MODE (x)) - 1))))\n-\t    tem = GEN_INT (INTVAL (tem)\n-\t\t\t   | ((HOST_WIDE_INT) (-1)\n-\t\t\t      << GET_MODE_BITSIZE (GET_MODE (x))));\n-#endif\n-\t  return nonzero_bits_with_known (tem, mode) & nonzero;\n-\t}\n-      else if (nonzero_sign_valid && reg_stat[REGNO (x)].nonzero_bits)\n-\t{\n-\t  unsigned HOST_WIDE_INT mask = reg_stat[REGNO (x)].nonzero_bits;\n-\n-\t  if (GET_MODE_BITSIZE (GET_MODE (x)) < mode_width)\n-\t    /* We don't know anything about the upper bits.  */\n-\t    mask |= GET_MODE_MASK (mode) ^ GET_MODE_MASK (GET_MODE (x));\n-\t  return nonzero & mask;\n-\t}\n-      else\n-\treturn nonzero;\n-\n-    case CONST_INT:\n #ifdef SHORT_IMMEDIATES_SIGN_EXTEND\n-      /* If X is negative in MODE, sign-extend the value.  */\n-      if (INTVAL (x) > 0 && mode_width < BITS_PER_WORD\n-\t  && 0 != (INTVAL (x) & ((HOST_WIDE_INT) 1 << (mode_width - 1))))\n-\treturn (INTVAL (x) | ((HOST_WIDE_INT) (-1) << mode_width));\n-#endif\n-\n-      return INTVAL (x);\n-\n-    case MEM:\n-#ifdef LOAD_EXTEND_OP\n-      /* In many, if not most, RISC machines, reading a byte from memory\n-\t zeros the rest of the register.  Noticing that fact saves a lot\n-\t of extra zero-extends.  */\n-      if (LOAD_EXTEND_OP (GET_MODE (x)) == ZERO_EXTEND)\n-\tnonzero &= GET_MODE_MASK (GET_MODE (x));\n-#endif\n-      break;\n-\n-    case EQ:  case NE:\n-    case UNEQ:  case LTGT:\n-    case GT:  case GTU:  case UNGT:\n-    case LT:  case LTU:  case UNLT:\n-    case GE:  case GEU:  case UNGE:\n-    case LE:  case LEU:  case UNLE:\n-    case UNORDERED: case ORDERED:\n-\n-      /* If this produces an integer result, we know which bits are set.\n-\t Code here used to clear bits outside the mode of X, but that is\n-\t now done above.  */\n-\n-      if (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && mode_width <= HOST_BITS_PER_WIDE_INT)\n-\tnonzero = STORE_FLAG_VALUE;\n-      break;\n-\n-    case NEG:\n-#if 0\n-      /* Disabled to avoid exponential mutual recursion between nonzero_bits\n-\t and num_sign_bit_copies.  */\n-      if (num_sign_bit_copies (XEXP (x, 0), GET_MODE (x))\n-\t  == GET_MODE_BITSIZE (GET_MODE (x)))\n-\tnonzero = 1;\n-#endif\n-\n-      if (GET_MODE_SIZE (GET_MODE (x)) < mode_width)\n-\tnonzero |= (GET_MODE_MASK (mode) & ~GET_MODE_MASK (GET_MODE (x)));\n-      break;\n-\n-    case ABS:\n-#if 0\n-      /* Disabled to avoid exponential mutual recursion between nonzero_bits\n-\t and num_sign_bit_copies.  */\n-      if (num_sign_bit_copies (XEXP (x, 0), GET_MODE (x))\n-\t  == GET_MODE_BITSIZE (GET_MODE (x)))\n-\tnonzero = 1;\n-#endif\n-      break;\n-\n-    case TRUNCATE:\n-      nonzero &= (nonzero_bits_with_known (XEXP (x, 0), mode)\n-\t\t  & GET_MODE_MASK (mode));\n-      break;\n-\n-    case ZERO_EXTEND:\n-      nonzero &= nonzero_bits_with_known (XEXP (x, 0), mode);\n-      if (GET_MODE (XEXP (x, 0)) != VOIDmode)\n-\tnonzero &= GET_MODE_MASK (GET_MODE (XEXP (x, 0)));\n-      break;\n-\n-    case SIGN_EXTEND:\n-      /* If the sign bit is known clear, this is the same as ZERO_EXTEND.\n-\t Otherwise, show all the bits in the outer mode but not the inner\n-\t may be nonzero.  */\n-      inner_nz = nonzero_bits_with_known (XEXP (x, 0), mode);\n-      if (GET_MODE (XEXP (x, 0)) != VOIDmode)\n-\t{\n-\t  inner_nz &= GET_MODE_MASK (GET_MODE (XEXP (x, 0)));\n-\t  if (inner_nz\n-\t      & (((HOST_WIDE_INT) 1\n-\t\t  << (GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0))) - 1))))\n-\t    inner_nz |= (GET_MODE_MASK (mode)\n-\t\t\t & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0))));\n-\t}\n-\n-      nonzero &= inner_nz;\n-      break;\n-\n-    case AND:\n-      nonzero &= (nonzero_bits_with_known (XEXP (x, 0), mode)\n-\t\t  & nonzero_bits_with_known (XEXP (x, 1), mode));\n-      break;\n-\n-    case XOR:   case IOR:\n-    case UMIN:  case UMAX:  case SMIN:  case SMAX:\n-      {\n-\tunsigned HOST_WIDE_INT nonzero0 =\n-\t  nonzero_bits_with_known (XEXP (x, 0), mode);\n-\n-\t/* Don't call nonzero_bits for the second time if it cannot change\n-\t   anything.  */\n-\tif ((nonzero & nonzero0) != nonzero)\n-\t  nonzero &= (nonzero0\n-\t\t      | nonzero_bits_with_known (XEXP (x, 1), mode));\n-      }\n-      break;\n-\n-    case PLUS:  case MINUS:\n-    case MULT:\n-    case DIV:   case UDIV:\n-    case MOD:   case UMOD:\n-      /* We can apply the rules of arithmetic to compute the number of\n-\t high- and low-order zero bits of these operations.  We start by\n-\t computing the width (position of the highest-order nonzero bit)\n-\t and the number of low-order zero bits for each value.  */\n-      {\n-\tunsigned HOST_WIDE_INT nz0 =\n-\t  nonzero_bits_with_known (XEXP (x, 0), mode);\n-\tunsigned HOST_WIDE_INT nz1 =\n-\t  nonzero_bits_with_known (XEXP (x, 1), mode);\n-\tint sign_index = GET_MODE_BITSIZE (GET_MODE (x)) - 1;\n-\tint width0 = floor_log2 (nz0) + 1;\n-\tint width1 = floor_log2 (nz1) + 1;\n-\tint low0 = floor_log2 (nz0 & -nz0);\n-\tint low1 = floor_log2 (nz1 & -nz1);\n-\tHOST_WIDE_INT op0_maybe_minusp\n-\t  = (nz0 & ((HOST_WIDE_INT) 1 << sign_index));\n-\tHOST_WIDE_INT op1_maybe_minusp\n-\t  = (nz1 & ((HOST_WIDE_INT) 1 << sign_index));\n-\tunsigned int result_width = mode_width;\n-\tint result_low = 0;\n-\n-\tswitch (code)\n-\t  {\n-\t  case PLUS:\n-\t    result_width = MAX (width0, width1) + 1;\n-\t    result_low = MIN (low0, low1);\n-\t    break;\n-\t  case MINUS:\n-\t    result_low = MIN (low0, low1);\n-\t    break;\n-\t  case MULT:\n-\t    result_width = width0 + width1;\n-\t    result_low = low0 + low1;\n-\t    break;\n-\t  case DIV:\n-\t    if (width1 == 0)\n-\t      break;\n-\t    if (! op0_maybe_minusp && ! op1_maybe_minusp)\n-\t      result_width = width0;\n-\t    break;\n-\t  case UDIV:\n-\t    if (width1 == 0)\n-\t      break;\n-\t    result_width = width0;\n-\t    break;\n-\t  case MOD:\n-\t    if (width1 == 0)\n-\t      break;\n-\t    if (! op0_maybe_minusp && ! op1_maybe_minusp)\n-\t      result_width = MIN (width0, width1);\n-\t    result_low = MIN (low0, low1);\n-\t    break;\n-\t  case UMOD:\n-\t    if (width1 == 0)\n-\t      break;\n-\t    result_width = MIN (width0, width1);\n-\t    result_low = MIN (low0, low1);\n-\t    break;\n-\t  default:\n-\t    abort ();\n-\t  }\n-\n-\tif (result_width < mode_width)\n-\t  nonzero &= ((HOST_WIDE_INT) 1 << result_width) - 1;\n-\n-\tif (result_low > 0)\n-\t  nonzero &= ~(((HOST_WIDE_INT) 1 << result_low) - 1);\n-\n-#ifdef POINTERS_EXTEND_UNSIGNED\n-\t/* If pointers extend unsigned and this is an addition or subtraction\n-\t   to a pointer in Pmode, all the bits above ptr_mode are known to be\n-\t   zero.  */\n-\tif (POINTERS_EXTEND_UNSIGNED > 0 && GET_MODE (x) == Pmode\n-\t    && (code == PLUS || code == MINUS)\n-\t    && GET_CODE (XEXP (x, 0)) == REG && REG_POINTER (XEXP (x, 0)))\n-\t  nonzero &= GET_MODE_MASK (ptr_mode);\n-#endif\n-      }\n-      break;\n-\n-    case ZERO_EXTRACT:\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && INTVAL (XEXP (x, 1)) < HOST_BITS_PER_WIDE_INT)\n-\tnonzero &= ((HOST_WIDE_INT) 1 << INTVAL (XEXP (x, 1))) - 1;\n-      break;\n-\n-    case SUBREG:\n-      /* If this is a SUBREG formed for a promoted variable that has\n-\t been zero-extended, we know that at least the high-order bits\n-\t are zero, though others might be too.  */\n-\n-      if (SUBREG_PROMOTED_VAR_P (x) && SUBREG_PROMOTED_UNSIGNED_P (x) > 0)\n-\tnonzero = (GET_MODE_MASK (GET_MODE (x))\n-\t\t   & nonzero_bits_with_known (SUBREG_REG (x), GET_MODE (x)));\n-\n-      /* If the inner mode is a single word for both the host and target\n-\t machines, we can compute this from which bits of the inner\n-\t object might be nonzero.  */\n-      if (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))) <= BITS_PER_WORD\n-\t  && (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x)))\n-\t      <= HOST_BITS_PER_WIDE_INT))\n-\t{\n-\t  nonzero &= nonzero_bits_with_known (SUBREG_REG (x), mode);\n-\n-#if defined (WORD_REGISTER_OPERATIONS) && defined (LOAD_EXTEND_OP)\n-\t  /* If this is a typical RISC machine, we only have to worry\n-\t     about the way loads are extended.  */\n-\t  if ((LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) == SIGN_EXTEND\n-\t       ? (((nonzero\n-\t\t    & (((unsigned HOST_WIDE_INT) 1\n-\t\t\t<< (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))) - 1))))\n-\t\t   != 0))\n-\t       : LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) != ZERO_EXTEND)\n-\t      || GET_CODE (SUBREG_REG (x)) != MEM)\n+      /* If X is narrower than MODE and TEM is a non-negative\n+         constant that would appear negative in the mode of X,\n+         sign-extend it for use in reg_nonzero_bits because some\n+         machines (maybe most) will actually do the sign-extension\n+         and this is the conservative approach.\n+\n+         ??? For 2.5, try to tighten up the MD files in this regard\n+         instead of this kludge.  */\n+\n+      if (GET_MODE_BITSIZE (GET_MODE (x)) < GET_MODE_BITSIZE (mode)\n+\t  && GET_CODE (tem) == CONST_INT\n+\t  && INTVAL (tem) > 0\n+\t  && 0 != (INTVAL (tem)\n+\t\t   & ((HOST_WIDE_INT) 1\n+\t\t      << (GET_MODE_BITSIZE (GET_MODE (x)) - 1))))\n+\ttem = GEN_INT (INTVAL (tem)\n+\t\t       | ((HOST_WIDE_INT) (-1)\n+\t\t\t  << GET_MODE_BITSIZE (GET_MODE (x))));\n #endif\n-\t    {\n-\t      /* On many CISC machines, accessing an object in a wider mode\n-\t\t causes the high-order bits to become undefined.  So they are\n-\t\t not known to be zero.  */\n-\t      if (GET_MODE_SIZE (GET_MODE (x))\n-\t\t  > GET_MODE_SIZE (GET_MODE (SUBREG_REG (x))))\n-\t\tnonzero |= (GET_MODE_MASK (GET_MODE (x))\n-\t\t\t    & ~GET_MODE_MASK (GET_MODE (SUBREG_REG (x))));\n-\t    }\n-\t}\n-      break;\n-\n-    case ASHIFTRT:\n-    case LSHIFTRT:\n-    case ASHIFT:\n-    case ROTATE:\n-      /* The nonzero bits are in two classes: any bits within MODE\n-\t that aren't in GET_MODE (x) are always significant.  The rest of the\n-\t nonzero bits are those that are significant in the operand of\n-\t the shift when shifted the appropriate number of bits.  This\n-\t shows that high-order bits are cleared by the right shift and\n-\t low-order bits by left shifts.  */\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && INTVAL (XEXP (x, 1)) >= 0\n-\t  && INTVAL (XEXP (x, 1)) < HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  enum machine_mode inner_mode = GET_MODE (x);\n-\t  unsigned int width = GET_MODE_BITSIZE (inner_mode);\n-\t  int count = INTVAL (XEXP (x, 1));\n-\t  unsigned HOST_WIDE_INT mode_mask = GET_MODE_MASK (inner_mode);\n-\t  unsigned HOST_WIDE_INT op_nonzero =\n-\t    nonzero_bits_with_known (XEXP (x, 0), mode);\n-\t  unsigned HOST_WIDE_INT inner = op_nonzero & mode_mask;\n-\t  unsigned HOST_WIDE_INT outer = 0;\n-\n-\t  if (mode_width > width)\n-\t    outer = (op_nonzero & nonzero & ~mode_mask);\n-\n-\t  if (code == LSHIFTRT)\n-\t    inner >>= count;\n-\t  else if (code == ASHIFTRT)\n-\t    {\n-\t      inner >>= count;\n-\n-\t      /* If the sign bit may have been nonzero before the shift, we\n-\t\t need to mark all the places it could have been copied to\n-\t\t by the shift as possibly nonzero.  */\n-\t      if (inner & ((HOST_WIDE_INT) 1 << (width - 1 - count)))\n-\t\tinner |= (((HOST_WIDE_INT) 1 << count) - 1) << (width - count);\n-\t    }\n-\t  else if (code == ASHIFT)\n-\t    inner <<= count;\n-\t  else\n-\t    inner = ((inner << (count % width)\n-\t\t      | (inner >> (width - (count % width)))) & mode_mask);\n-\n-\t  nonzero &= (outer | inner);\n-\t}\n-      break;\n-\n-    case FFS:\n-    case POPCOUNT:\n-      /* This is at most the number of bits in the mode.  */\n-      nonzero = ((HOST_WIDE_INT) 2 << (floor_log2 (mode_width))) - 1;\n-      break;\n-\n-    case CLZ:\n-      /* If CLZ has a known value at zero, then the nonzero bits are\n-\t that value, plus the number of bits in the mode minus one.  */\n-      if (CLZ_DEFINED_VALUE_AT_ZERO (mode, nonzero))\n-\tnonzero |= ((HOST_WIDE_INT) 1 << (floor_log2 (mode_width))) - 1;\n-      else\n-\tnonzero = -1;\n-      break;\n-\n-    case CTZ:\n-      /* If CTZ has a known value at zero, then the nonzero bits are\n-\t that value, plus the number of bits in the mode minus one.  */\n-      if (CTZ_DEFINED_VALUE_AT_ZERO (mode, nonzero))\n-\tnonzero |= ((HOST_WIDE_INT) 1 << (floor_log2 (mode_width))) - 1;\n-      else\n-\tnonzero = -1;\n-      break;\n-\n-    case PARITY:\n-      nonzero = 1;\n-      break;\n-\n-    case IF_THEN_ELSE:\n-      nonzero &= (nonzero_bits_with_known (XEXP (x, 1), mode)\n-\t\t  | nonzero_bits_with_known (XEXP (x, 2), mode));\n-      break;\n-\n-    default:\n-      break;\n+      return tem;\n     }\n-\n-  return nonzero;\n-}\n-\n-/* See the macro definition above.  */\n-#undef cached_num_sign_bit_copies\n-\f\n-#define num_sign_bit_copies_with_known(X, M) \\\n-  cached_num_sign_bit_copies (X, M, known_x, known_mode, known_ret)\n-\n-/* The function cached_num_sign_bit_copies is a wrapper around\n-   num_sign_bit_copies1.  It avoids exponential behavior in\n-   num_sign_bit_copies1 when X has identical subexpressions on the\n-   first or the second level.  */\n-\n-static unsigned int\n-cached_num_sign_bit_copies (rtx x, enum machine_mode mode, rtx known_x,\n-\t\t\t    enum machine_mode known_mode,\n-\t\t\t    unsigned int known_ret)\n-{\n-  if (x == known_x && mode == known_mode)\n-    return known_ret;\n-\n-  /* Try to find identical subexpressions.  If found call\n-     num_sign_bit_copies1 on X with the subexpressions as KNOWN_X and\n-     the precomputed value for the subexpression as KNOWN_RET.  */\n-\n-  if (ARITHMETIC_P (x))\n+  else if (nonzero_sign_valid && reg_stat[REGNO (x)].nonzero_bits)\n     {\n-      rtx x0 = XEXP (x, 0);\n-      rtx x1 = XEXP (x, 1);\n-\n-      /* Check the first level.  */\n-      if (x0 == x1)\n-\treturn\n-\t  num_sign_bit_copies1 (x, mode, x0, mode,\n-\t\t\t\tnum_sign_bit_copies_with_known (x0, mode));\n-\n-      /* Check the second level.  */\n-      if (ARITHMETIC_P (x0)\n-\t  && (x1 == XEXP (x0, 0) || x1 == XEXP (x0, 1)))\n-\treturn\n-\t  num_sign_bit_copies1 (x, mode, x1, mode,\n-\t\t\t\tnum_sign_bit_copies_with_known (x1, mode));\n+      unsigned HOST_WIDE_INT mask = reg_stat[REGNO (x)].nonzero_bits;\n \n-      if (ARITHMETIC_P (x1)\n-\t  && (x0 == XEXP (x1, 0) || x0 == XEXP (x1, 1)))\n-\treturn\n-\t  num_sign_bit_copies1 (x, mode, x0, mode,\n-\t\t\t\tnum_sign_bit_copies_with_known (x0, mode));\n+      if (GET_MODE_BITSIZE (GET_MODE (x)) < GET_MODE_BITSIZE (mode))\n+        /* We don't know anything about the upper bits.  */\n+        mask |= GET_MODE_MASK (mode) ^ GET_MODE_MASK (GET_MODE (x));\n+      *nonzero &= mask;\n     }\n \n-  return num_sign_bit_copies1 (x, mode, known_x, known_mode, known_ret);\n+  return NULL;\n }\n \n /* Return the number of bits at the high-order end of X that are known to\n    be equal to the sign bit.  X will be used in mode MODE; if MODE is\n    VOIDmode, X will be used in its own mode.  The returned value  will always\n    be between 1 and the number of bits in MODE.  */\n \n-static unsigned int\n-num_sign_bit_copies1 (rtx x, enum machine_mode mode, rtx known_x,\n-\t\t      enum machine_mode known_mode,\n-\t\t      unsigned int known_ret)\n+static rtx\n+reg_num_sign_bit_copies_for_combine (rtx x, enum machine_mode mode,\n+\t\t\t\t     rtx known_x ATTRIBUTE_UNUSED,\n+\t\t\t\t     enum machine_mode known_mode\n+\t\t\t\t     ATTRIBUTE_UNUSED,\n+\t\t\t\t     unsigned int known_ret ATTRIBUTE_UNUSED,\n+\t\t\t\t     unsigned int *result)\n {\n-  enum rtx_code code = GET_CODE (x);\n-  unsigned int bitwidth;\n-  int num0, num1, result;\n-  unsigned HOST_WIDE_INT nonzero;\n   rtx tem;\n \n-  /* If we weren't given a mode, use the mode of X.  If the mode is still\n-     VOIDmode, we don't know anything.  Likewise if one of the modes is\n-     floating-point.  */\n-\n-  if (mode == VOIDmode)\n-    mode = GET_MODE (x);\n-\n-  if (mode == VOIDmode || FLOAT_MODE_P (mode) || FLOAT_MODE_P (GET_MODE (x)))\n-    return 1;\n-\n-  bitwidth = GET_MODE_BITSIZE (mode);\n-\n-  /* For a smaller object, just ignore the high bits.  */\n-  if (bitwidth < GET_MODE_BITSIZE (GET_MODE (x)))\n+  if (reg_stat[REGNO (x)].last_set_value != 0\n+      && reg_stat[REGNO (x)].last_set_mode == mode\n+      && (reg_stat[REGNO (x)].last_set_label == label_tick\n+          || (REGNO (x) >= FIRST_PSEUDO_REGISTER\n+\t      && REG_N_SETS (REGNO (x)) == 1\n+\t      && ! REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start,\n+\t\t\t\t    REGNO (x))))\n+      && INSN_CUID (reg_stat[REGNO (x)].last_set) < subst_low_cuid)\n     {\n-      num0 = num_sign_bit_copies_with_known (x, GET_MODE (x));\n-      return MAX (1,\n-\t\t  num0 - (int) (GET_MODE_BITSIZE (GET_MODE (x)) - bitwidth));\n-    }\n-\n-  if (GET_MODE (x) != VOIDmode && bitwidth > GET_MODE_BITSIZE (GET_MODE (x)))\n-    {\n-#ifndef WORD_REGISTER_OPERATIONS\n-  /* If this machine does not do all register operations on the entire\n-     register and MODE is wider than the mode of X, we can say nothing\n-     at all about the high-order bits.  */\n-      return 1;\n-#else\n-      /* Likewise on machines that do, if the mode of the object is smaller\n-\t than a word and loads of that size don't sign extend, we can say\n-\t nothing about the high order bits.  */\n-      if (GET_MODE_BITSIZE (GET_MODE (x)) < BITS_PER_WORD\n-#ifdef LOAD_EXTEND_OP\n-\t  && LOAD_EXTEND_OP (GET_MODE (x)) != SIGN_EXTEND\n-#endif\n-\t  )\n-\treturn 1;\n-#endif\n+      *result = reg_stat[REGNO (x)].last_set_sign_bit_copies;\n+      return NULL;\n     }\n \n-  switch (code)\n-    {\n-    case REG:\n+  tem = get_last_value (x);\n+  if (tem != 0)\n+    return tem;\n \n-#if defined(POINTERS_EXTEND_UNSIGNED) && !defined(HAVE_ptr_extend)\n-      /* If pointers extend signed and this is a pointer in Pmode, say that\n-\t all the bits above ptr_mode are known to be sign bit copies.  */\n-      if (! POINTERS_EXTEND_UNSIGNED && GET_MODE (x) == Pmode && mode == Pmode\n-\t  && REG_POINTER (x))\n-\treturn GET_MODE_BITSIZE (Pmode) - GET_MODE_BITSIZE (ptr_mode) + 1;\n-#endif\n-\n-      if (reg_stat[REGNO (x)].last_set_value != 0\n-\t  && reg_stat[REGNO (x)].last_set_mode == mode\n-\t  && (reg_stat[REGNO (x)].last_set_label == label_tick\n-\t      || (REGNO (x) >= FIRST_PSEUDO_REGISTER\n-\t\t  && REG_N_SETS (REGNO (x)) == 1\n-\t\t  && ! REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start,\n-\t\t\t\t\tREGNO (x))))\n-\t  && INSN_CUID (reg_stat[REGNO (x)].last_set) < subst_low_cuid)\n-\treturn reg_stat[REGNO (x)].last_set_sign_bit_copies;\n-\n-      tem = get_last_value (x);\n-      if (tem != 0)\n-\treturn num_sign_bit_copies_with_known (tem, mode);\n-\n-      if (nonzero_sign_valid && reg_stat[REGNO (x)].sign_bit_copies != 0\n-\t  && GET_MODE_BITSIZE (GET_MODE (x)) == bitwidth)\n-\treturn reg_stat[REGNO (x)].sign_bit_copies;\n-      break;\n-\n-    case MEM:\n-#ifdef LOAD_EXTEND_OP\n-      /* Some RISC machines sign-extend all loads of smaller than a word.  */\n-      if (LOAD_EXTEND_OP (GET_MODE (x)) == SIGN_EXTEND)\n-\treturn MAX (1, ((int) bitwidth\n-\t\t\t- (int) GET_MODE_BITSIZE (GET_MODE (x)) + 1));\n-#endif\n-      break;\n-\n-    case CONST_INT:\n-      /* If the constant is negative, take its 1's complement and remask.\n-\t Then see how many zero bits we have.  */\n-      nonzero = INTVAL (x) & GET_MODE_MASK (mode);\n-      if (bitwidth <= HOST_BITS_PER_WIDE_INT\n-\t  && (nonzero & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n-\tnonzero = (~nonzero) & GET_MODE_MASK (mode);\n-\n-      return (nonzero == 0 ? bitwidth : bitwidth - floor_log2 (nonzero) - 1);\n-\n-    case SUBREG:\n-      /* If this is a SUBREG for a promoted object that is sign-extended\n-\t and we are looking at it in a wider mode, we know that at least the\n-\t high-order bits are known to be sign bit copies.  */\n-\n-      if (SUBREG_PROMOTED_VAR_P (x) && ! SUBREG_PROMOTED_UNSIGNED_P (x))\n-\t{\n-\t  num0 = num_sign_bit_copies_with_known (SUBREG_REG (x), mode);\n-\t  return MAX ((int) bitwidth\n-\t\t      - (int) GET_MODE_BITSIZE (GET_MODE (x)) + 1,\n-\t\t      num0);\n-\t}\n-\n-      /* For a smaller object, just ignore the high bits.  */\n-      if (bitwidth <= GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))))\n-\t{\n-\t  num0 = num_sign_bit_copies_with_known (SUBREG_REG (x), VOIDmode);\n-\t  return MAX (1, (num0\n-\t\t\t  - (int) (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x)))\n-\t\t\t\t   - bitwidth)));\n-\t}\n-\n-#ifdef WORD_REGISTER_OPERATIONS\n-#ifdef LOAD_EXTEND_OP\n-      /* For paradoxical SUBREGs on machines where all register operations\n-\t affect the entire register, just look inside.  Note that we are\n-\t passing MODE to the recursive call, so the number of sign bit copies\n-\t will remain relative to that mode, not the inner mode.  */\n-\n-      /* This works only if loads sign extend.  Otherwise, if we get a\n-\t reload for the inner part, it may be loaded from the stack, and\n-\t then we lose all sign bit copies that existed before the store\n-\t to the stack.  */\n-\n-      if ((GET_MODE_SIZE (GET_MODE (x))\n-\t   > GET_MODE_SIZE (GET_MODE (SUBREG_REG (x))))\n-\t  && LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) == SIGN_EXTEND\n-\t  && GET_CODE (SUBREG_REG (x)) == MEM)\n-\treturn num_sign_bit_copies_with_known (SUBREG_REG (x), mode);\n-#endif\n-#endif\n-      break;\n-\n-    case SIGN_EXTRACT:\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n-\treturn MAX (1, (int) bitwidth - INTVAL (XEXP (x, 1)));\n-      break;\n-\n-    case SIGN_EXTEND:\n-      return (bitwidth - GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0)))\n-\t      + num_sign_bit_copies_with_known (XEXP (x, 0), VOIDmode));\n-\n-    case TRUNCATE:\n-      /* For a smaller object, just ignore the high bits.  */\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 0), VOIDmode);\n-      return MAX (1, (num0 - (int) (GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0)))\n-\t\t\t\t    - bitwidth)));\n-\n-    case NOT:\n-      return num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-\n-    case ROTATE:       case ROTATERT:\n-      /* If we are rotating left by a number of bits less than the number\n-\t of sign bit copies, we can just subtract that amount from the\n-\t number.  */\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && INTVAL (XEXP (x, 1)) >= 0\n-\t  && INTVAL (XEXP (x, 1)) < (int) bitwidth)\n-\t{\n-\t  num0 = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-\t  return MAX (1, num0 - (code == ROTATE ? INTVAL (XEXP (x, 1))\n-\t\t\t\t : (int) bitwidth - INTVAL (XEXP (x, 1))));\n-\t}\n-      break;\n-\n-    case NEG:\n-      /* In general, this subtracts one sign bit copy.  But if the value\n-\t is known to be positive, the number of sign bit copies is the\n-\t same as that of the input.  Finally, if the input has just one bit\n-\t that might be nonzero, all the bits are copies of the sign bit.  */\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-      if (bitwidth > HOST_BITS_PER_WIDE_INT)\n-\treturn num0 > 1 ? num0 - 1 : 1;\n-\n-      nonzero = nonzero_bits (XEXP (x, 0), mode);\n-      if (nonzero == 1)\n-\treturn bitwidth;\n-\n-      if (num0 > 1\n-\t  && (((HOST_WIDE_INT) 1 << (bitwidth - 1)) & nonzero))\n-\tnum0--;\n-\n-      return num0;\n-\n-    case IOR:   case AND:   case XOR:\n-    case SMIN:  case SMAX:  case UMIN:  case UMAX:\n-      /* Logical operations will preserve the number of sign-bit copies.\n-\t MIN and MAX operations always return one of the operands.  */\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-      num1 = num_sign_bit_copies_with_known (XEXP (x, 1), mode);\n-      return MIN (num0, num1);\n-\n-    case PLUS:  case MINUS:\n-      /* For addition and subtraction, we can have a 1-bit carry.  However,\n-\t if we are subtracting 1 from a positive number, there will not\n-\t be such a carry.  Furthermore, if the positive number is known to\n-\t be 0 or 1, we know the result is either -1 or 0.  */\n-\n-      if (code == PLUS && XEXP (x, 1) == constm1_rtx\n-\t  && bitwidth <= HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  nonzero = nonzero_bits (XEXP (x, 0), mode);\n-\t  if ((((HOST_WIDE_INT) 1 << (bitwidth - 1)) & nonzero) == 0)\n-\t    return (nonzero == 1 || nonzero == 0 ? bitwidth\n-\t\t    : bitwidth - floor_log2 (nonzero) - 1);\n-\t}\n-\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-      num1 = num_sign_bit_copies_with_known (XEXP (x, 1), mode);\n-      result = MAX (1, MIN (num0, num1) - 1);\n-\n-#ifdef POINTERS_EXTEND_UNSIGNED\n-      /* If pointers extend signed and this is an addition or subtraction\n-\t to a pointer in Pmode, all the bits above ptr_mode are known to be\n-\t sign bit copies.  */\n-      if (! POINTERS_EXTEND_UNSIGNED && GET_MODE (x) == Pmode\n-\t  && (code == PLUS || code == MINUS)\n-\t  && GET_CODE (XEXP (x, 0)) == REG && REG_POINTER (XEXP (x, 0)))\n-\tresult = MAX ((int) (GET_MODE_BITSIZE (Pmode)\n-\t\t\t     - GET_MODE_BITSIZE (ptr_mode) + 1),\n-\t\t      result);\n-#endif\n-      return result;\n-\n-    case MULT:\n-      /* The number of bits of the product is the sum of the number of\n-\t bits of both terms.  However, unless one of the terms if known\n-\t to be positive, we must allow for an additional bit since negating\n-\t a negative number can remove one sign bit copy.  */\n-\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-      num1 = num_sign_bit_copies_with_known (XEXP (x, 1), mode);\n-\n-      result = bitwidth - (bitwidth - num0) - (bitwidth - num1);\n-      if (result > 0\n-\t  && (bitwidth > HOST_BITS_PER_WIDE_INT\n-\t      || (((nonzero_bits (XEXP (x, 0), mode)\n-\t\t    & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n-\t\t  && ((nonzero_bits (XEXP (x, 1), mode)\n-\t\t       & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0))))\n-\tresult--;\n-\n-      return MAX (1, result);\n-\n-    case UDIV:\n-      /* The result must be <= the first operand.  If the first operand\n-         has the high bit set, we know nothing about the number of sign\n-         bit copies.  */\n-      if (bitwidth > HOST_BITS_PER_WIDE_INT)\n-\treturn 1;\n-      else if ((nonzero_bits (XEXP (x, 0), mode)\n-\t\t& ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n-\treturn 1;\n-      else\n-\treturn num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-\n-    case UMOD:\n-      /* The result must be <= the second operand.  */\n-      return num_sign_bit_copies_with_known (XEXP (x, 1), mode);\n-\n-    case DIV:\n-      /* Similar to unsigned division, except that we have to worry about\n-\t the case where the divisor is negative, in which case we have\n-\t to add 1.  */\n-      result = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-      if (result > 1\n-\t  && (bitwidth > HOST_BITS_PER_WIDE_INT\n-\t      || (nonzero_bits (XEXP (x, 1), mode)\n-\t\t  & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0))\n-\tresult--;\n-\n-      return result;\n-\n-    case MOD:\n-      result = num_sign_bit_copies_with_known (XEXP (x, 1), mode);\n-      if (result > 1\n-\t  && (bitwidth > HOST_BITS_PER_WIDE_INT\n-\t      || (nonzero_bits (XEXP (x, 1), mode)\n-\t\t  & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0))\n-\tresult--;\n-\n-      return result;\n-\n-    case ASHIFTRT:\n-      /* Shifts by a constant add to the number of bits equal to the\n-\t sign bit.  */\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && INTVAL (XEXP (x, 1)) > 0)\n-\tnum0 = MIN ((int) bitwidth, num0 + INTVAL (XEXP (x, 1)));\n-\n-      return num0;\n-\n-    case ASHIFT:\n-      /* Left shifts destroy copies.  */\n-      if (GET_CODE (XEXP (x, 1)) != CONST_INT\n-\t  || INTVAL (XEXP (x, 1)) < 0\n-\t  || INTVAL (XEXP (x, 1)) >= (int) bitwidth)\n-\treturn 1;\n-\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 0), mode);\n-      return MAX (1, num0 - INTVAL (XEXP (x, 1)));\n-\n-    case IF_THEN_ELSE:\n-      num0 = num_sign_bit_copies_with_known (XEXP (x, 1), mode);\n-      num1 = num_sign_bit_copies_with_known (XEXP (x, 2), mode);\n-      return MIN (num0, num1);\n-\n-    case EQ:  case NE:  case GE:  case GT:  case LE:  case LT:\n-    case UNEQ:  case LTGT:  case UNGE:  case UNGT:  case UNLE:  case UNLT:\n-    case GEU: case GTU: case LEU: case LTU:\n-    case UNORDERED: case ORDERED:\n-      /* If the constant is negative, take its 1's complement and remask.\n-\t Then see how many zero bits we have.  */\n-      nonzero = STORE_FLAG_VALUE;\n-      if (bitwidth <= HOST_BITS_PER_WIDE_INT\n-\t  && (nonzero & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n-\tnonzero = (~nonzero) & GET_MODE_MASK (mode);\n-\n-      return (nonzero == 0 ? bitwidth : bitwidth - floor_log2 (nonzero) - 1);\n-      break;\n-\n-    default:\n-      break;\n-    }\n-\n-  /* If we haven't been able to figure it out by one of the above rules,\n-     see if some of the high-order bits are known to be zero.  If so,\n-     count those bits and return one less than that amount.  If we can't\n-     safely compute the mask for this mode, always return BITWIDTH.  */\n-\n-  if (bitwidth > HOST_BITS_PER_WIDE_INT)\n-    return 1;\n-\n-  nonzero = nonzero_bits (x, mode);\n-  return (nonzero & ((HOST_WIDE_INT) 1 << (bitwidth - 1))\n-\t  ? 1 : bitwidth - floor_log2 (nonzero) - 1);\n+  if (nonzero_sign_valid && reg_stat[REGNO (x)].sign_bit_copies != 0\n+      && GET_MODE_BITSIZE (GET_MODE (x)) == GET_MODE_BITSIZE (mode))\n+    *result = reg_stat[REGNO (x)].sign_bit_copies;\n+      \n+  return NULL;\n }\n \f\n /* Return the number of \"extended\" bits there are in X, when interpreted"}, {"sha": "5f1107c3e2259b9dda3c91eb991ea19b18a6cb3d", "filename": "gcc/cse.c", "status": "modified", "additions": 9, "deletions": 2, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -43,6 +43,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"except.h\"\n #include \"target.h\"\n #include \"params.h\"\n+#include \"rtlhooks-def.h\"\n \n /* The basic idea of common subexpression elimination is to go\n    through the code, keeping a record of expressions that would\n@@ -664,6 +665,12 @@ static int cse_change_cc_mode (rtx *, void *);\n static void cse_change_cc_mode_insns (rtx, rtx, rtx);\n static enum machine_mode cse_cc_succs (basic_block, rtx, rtx, bool);\n \f\n+\n+#undef RTL_HOOKS_GEN_LOWPART\n+#define RTL_HOOKS_GEN_LOWPART\t\tgen_lowpart_if_possible\n+\n+static const struct rtl_hooks cse_rtl_hooks = RTL_HOOKS_INITIALIZER;\n+\f\n /* Nonzero if X has the form (PLUS frame-pointer integer).  We check for\n    virtual regs here because the simplify_*_operation routines are called\n    by integrate.c, which is called before virtual register instantiation.  */\n@@ -6881,7 +6888,7 @@ cse_main (rtx f, int nregs, int after_loop, FILE *file)\n   constant_pool_entries_cost = 0;\n   constant_pool_entries_regcost = 0;\n   val.path_size = 0;\n-  gen_lowpart = gen_lowpart_if_possible;\n+  rtl_hooks = cse_rtl_hooks;\n \n   init_recog ();\n   init_alias_analysis ();\n@@ -7001,7 +7008,7 @@ cse_main (rtx f, int nregs, int after_loop, FILE *file)\n   free (uid_cuid);\n   free (reg_eqv_table);\n   free (val.path);\n-  gen_lowpart = gen_lowpart_general;\n+  rtl_hooks = general_rtl_hooks;\n \n   return cse_jumps_altered || recorded_label_ref;\n }"}, {"sha": "9211c0875370f05f3e1bb015e01b1c3b946c45e5", "filename": "gcc/emit-rtl.c", "status": "modified", "additions": 0, "deletions": 58, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Femit-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Femit-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Femit-rtl.c?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -97,8 +97,6 @@ rtx global_rtl[GR_MAX];\n    at the beginning of each function.  */\n static GTY(()) rtx static_regno_reg_rtx[FIRST_PSEUDO_REGISTER];\n \n-rtx (*gen_lowpart) (enum machine_mode mode, rtx x) = gen_lowpart_general;\n-\n /* We record floating-point CONST_DOUBLEs in each floating-point mode for\n    the values of 0, 1, and 2.  For the integer entries and VOIDmode, we\n    record a copy of const[012]_rtx.  */\n@@ -1124,62 +1122,6 @@ gen_imagpart (enum machine_mode mode, rtx x)\n     return gen_highpart (mode, x);\n }\n \f\n-/* Assuming that X is an rtx (e.g., MEM, REG or SUBREG) for a value,\n-   return an rtx (MEM, SUBREG, or CONST_INT) that refers to the\n-   least-significant part of X.\n-   MODE specifies how big a part of X to return;\n-   it usually should not be larger than a word.\n-   If X is a MEM whose address is a QUEUED, the value may be so also.  */\n-\n-rtx\n-gen_lowpart_general (enum machine_mode mode, rtx x)\n-{\n-  rtx result = gen_lowpart_common (mode, x);\n-\n-  if (result)\n-    return result;\n-  else if (GET_CODE (x) == REG)\n-    {\n-      /* Must be a hard reg that's not valid in MODE.  */\n-      result = gen_lowpart_common (mode, copy_to_reg (x));\n-      if (result == 0)\n-\tabort ();\n-      return result;\n-    }\n-  else if (GET_CODE (x) == MEM)\n-    {\n-      /* The only additional case we can do is MEM.  */\n-      int offset = 0;\n-\n-      /* The following exposes the use of \"x\" to CSE.  */\n-      if (GET_MODE_SIZE (GET_MODE (x)) <= UNITS_PER_WORD\n-\t  && SCALAR_INT_MODE_P (GET_MODE (x))\n-\t  && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (mode),\n-\t\t\t\t    GET_MODE_BITSIZE (GET_MODE (x)))\n-\t  && ! no_new_pseudos)\n-\treturn gen_lowpart (mode, force_reg (GET_MODE (x), x));\n-\n-      if (WORDS_BIG_ENDIAN)\n-\toffset = (MAX (GET_MODE_SIZE (GET_MODE (x)), UNITS_PER_WORD)\n-\t\t  - MAX (GET_MODE_SIZE (mode), UNITS_PER_WORD));\n-\n-      if (BYTES_BIG_ENDIAN)\n-\t/* Adjust the address so that the address-after-the-data\n-\t   is unchanged.  */\n-\toffset -= (MIN (UNITS_PER_WORD, GET_MODE_SIZE (mode))\n-\t\t   - MIN (UNITS_PER_WORD, GET_MODE_SIZE (GET_MODE (x))));\n-\n-      return adjust_address (x, mode, offset);\n-    }\n-  else if (GET_CODE (x) == ADDRESSOF)\n-    return gen_lowpart (mode, force_reg (GET_MODE (x), x));\n-  else\n-    abort ();\n-}\n-\n-/* Like `gen_lowpart', but refer to the most significant part.\n-   This is used to access the imaginary part of a complex number.  */\n-\n rtx\n gen_highpart (enum machine_mode mode, rtx x)\n {"}, {"sha": "65f68d81b59bb54d7741829fb2fdbf961925ec57", "filename": "gcc/rtl.h", "status": "modified", "additions": 24, "deletions": 3, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -1195,6 +1195,9 @@ extern unsigned int subreg_regno_offset\t(unsigned int, enum machine_mode,\n extern bool subreg_offset_representable_p (unsigned int, enum machine_mode,\n \t\t\t\t\t   unsigned int, enum machine_mode);\n extern unsigned int subreg_regno (rtx);\n+extern unsigned HOST_WIDE_INT nonzero_bits (rtx, enum machine_mode);\n+extern unsigned int num_sign_bit_copies (rtx, enum machine_mode);\n+\n \n /* 1 if RTX is a subreg containing a reg that is already known to be\n    sign- or zero-extended from the mode of the subreg to the mode of\n@@ -1598,9 +1601,6 @@ extern rtx gen_rtx_REG_offset (rtx, enum machine_mode, unsigned int, int);\n extern rtx gen_label_rtx (void);\n extern int subreg_hard_regno (rtx, int);\n extern rtx gen_lowpart_common (enum machine_mode, rtx);\n-extern rtx gen_lowpart_general (enum machine_mode, rtx);\n-extern rtx (*gen_lowpart) (enum machine_mode mode, rtx x);\n-\n \n /* In cse.c */\n extern rtx gen_lowpart_if_possible (enum machine_mode, rtx);\n@@ -2461,4 +2461,25 @@ extern void simplify_using_condition (rtx, rtx *, struct bitmap_head_def *);\n /* In ra.c.  */\n extern void reg_alloc (void);\n \n+\f\n+struct rtl_hooks\n+{\n+  rtx (*gen_lowpart) (enum machine_mode, rtx);\n+  rtx (*reg_nonzero_bits) (rtx, enum machine_mode, rtx, enum machine_mode,\n+\t\t\t   unsigned HOST_WIDE_INT, unsigned HOST_WIDE_INT *);\n+  rtx (*reg_num_sign_bit_copies) (rtx, enum machine_mode, rtx, enum machine_mode,\n+\t\t\t\t  unsigned int, unsigned int *);\n+\n+  /* Whenever you add entries here, make sure you adjust hosthooks-def.h.  */\n+};\n+\n+/* Each pass can provide its own.  */\n+extern struct rtl_hooks rtl_hooks;\n+\n+/* ... but then it has to restore these.  */\n+extern const struct rtl_hooks general_rtl_hooks;\n+\n+/* Keep this for the nonce.  */\n+#define gen_lowpart rtl_hooks.gen_lowpart\n+\n #endif /* ! GCC_RTL_H */"}, {"sha": "8da8b80ddb3323f538ed8a30c780196dec94f243", "filename": "gcc/rtlanal.c", "status": "modified", "additions": 956, "deletions": 0, "changes": 956, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtlanal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtlanal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlanal.c?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -36,6 +36,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"basic-block.h\"\n #include \"real.h\"\n #include \"regs.h\"\n+#include \"function.h\"\n \n /* Forward declarations */\n static int global_reg_mentioned_p_1 (rtx *, void *);\n@@ -47,6 +48,18 @@ static void parms_set (rtx, rtx, void *);\n static bool hoist_test_store (rtx, rtx, regset);\n static void hoist_update_store (rtx, rtx *, rtx, rtx);\n \n+static unsigned HOST_WIDE_INT cached_nonzero_bits (rtx, enum machine_mode,\n+                                                   rtx, enum machine_mode,\n+                                                   unsigned HOST_WIDE_INT);\n+static unsigned HOST_WIDE_INT nonzero_bits1 (rtx, enum machine_mode, rtx,\n+                                             enum machine_mode,\n+                                             unsigned HOST_WIDE_INT);\n+static unsigned int cached_num_sign_bit_copies (rtx, enum machine_mode, rtx,\n+                                                enum machine_mode,\n+                                                unsigned int);\n+static unsigned int num_sign_bit_copies1 (rtx, enum machine_mode, rtx,\n+                                          enum machine_mode, unsigned int);\n+\n /* Bit flags that specify the machine subtype we are compiling for.\n    Bits are tested using macros TARGET_... defined in the tm.h file\n    and set by `-m...' switches.  Must be defined in rtlanal.c.  */\n@@ -3849,3 +3862,946 @@ default_address_cost (rtx x)\n {\n   return rtx_cost (x, MEM);\n }\n+\f\n+\n+unsigned HOST_WIDE_INT\n+nonzero_bits (rtx x, enum machine_mode mode)\n+{\n+  return cached_nonzero_bits (x, mode, NULL_RTX, VOIDmode, 0);\n+}\n+\n+unsigned int\n+num_sign_bit_copies (rtx x, enum machine_mode mode)\n+{\n+  return cached_num_sign_bit_copies (x, mode, NULL_RTX, VOIDmode, 0);\n+}\n+\n+/* The function cached_nonzero_bits is a wrapper around nonzero_bits1.\n+   It avoids exponential behavior in nonzero_bits1 when X has\n+   identical subexpressions on the first or the second level.  */\n+\n+static unsigned HOST_WIDE_INT\n+cached_nonzero_bits (rtx x, enum machine_mode mode, rtx known_x,\n+\t\t     enum machine_mode known_mode,\n+\t\t     unsigned HOST_WIDE_INT known_ret)\n+{\n+  if (x == known_x && mode == known_mode)\n+    return known_ret;\n+\n+  /* Try to find identical subexpressions.  If found call\n+     nonzero_bits1 on X with the subexpressions as KNOWN_X and the\n+     precomputed value for the subexpression as KNOWN_RET.  */\n+\n+  if (ARITHMETIC_P (x))\n+    {\n+      rtx x0 = XEXP (x, 0);\n+      rtx x1 = XEXP (x, 1);\n+\n+      /* Check the first level.  */\n+      if (x0 == x1)\n+\treturn nonzero_bits1 (x, mode, x0, mode,\n+\t\t\t      cached_nonzero_bits (x0, mode, known_x,\n+\t\t\t\t\t\t   known_mode, known_ret));\n+\n+      /* Check the second level.  */\n+      if (ARITHMETIC_P (x0)\n+\t  && (x1 == XEXP (x0, 0) || x1 == XEXP (x0, 1)))\n+\treturn nonzero_bits1 (x, mode, x1, mode,\n+\t\t\t      cached_nonzero_bits (x1, mode, known_x,\n+\t\t\t\t\t\t   known_mode, known_ret));\n+\n+      if (ARITHMETIC_P (x1)\n+\t  && (x0 == XEXP (x1, 0) || x0 == XEXP (x1, 1)))\n+\treturn nonzero_bits1 (x, mode, x0, mode,\n+\t\t\t      cached_nonzero_bits (x0, mode, known_x,\n+\t\t\t\t\t\t   known_mode, known_ret));\n+    }\n+\n+  return nonzero_bits1 (x, mode, known_x, known_mode, known_ret);\n+}\n+\n+/* We let num_sign_bit_copies recur into nonzero_bits as that is useful.\n+   We don't let nonzero_bits recur into num_sign_bit_copies, because that\n+   is less useful.  We can't allow both, because that results in exponential\n+   run time recursion.  There is a nullstone testcase that triggered\n+   this.  This macro avoids accidental uses of num_sign_bit_copies.  */\n+#define cached_num_sign_bit_copies sorry_i_am_preventing_exponential_behavior\n+\n+/* Given an expression, X, compute which bits in X can be nonzero.\n+   We don't care about bits outside of those defined in MODE.\n+\n+   For most X this is simply GET_MODE_MASK (GET_MODE (MODE)), but if X is\n+   an arithmetic operation, we can do better.  */\n+\n+static unsigned HOST_WIDE_INT\n+nonzero_bits1 (rtx x, enum machine_mode mode, rtx known_x,\n+\t       enum machine_mode known_mode,\n+\t       unsigned HOST_WIDE_INT known_ret)\n+{\n+  unsigned HOST_WIDE_INT nonzero = GET_MODE_MASK (mode);\n+  unsigned HOST_WIDE_INT inner_nz;\n+  enum rtx_code code;\n+  unsigned int mode_width = GET_MODE_BITSIZE (mode);\n+\n+  /* For floating-point values, assume all bits are needed.  */\n+  if (FLOAT_MODE_P (GET_MODE (x)) || FLOAT_MODE_P (mode))\n+    return nonzero;\n+\n+  /* If X is wider than MODE, use its mode instead.  */\n+  if (GET_MODE_BITSIZE (GET_MODE (x)) > mode_width)\n+    {\n+      mode = GET_MODE (x);\n+      nonzero = GET_MODE_MASK (mode);\n+      mode_width = GET_MODE_BITSIZE (mode);\n+    }\n+\n+  if (mode_width > HOST_BITS_PER_WIDE_INT)\n+    /* Our only callers in this case look for single bit values.  So\n+       just return the mode mask.  Those tests will then be false.  */\n+    return nonzero;\n+\n+#ifndef WORD_REGISTER_OPERATIONS\n+  /* If MODE is wider than X, but both are a single word for both the host\n+     and target machines, we can compute this from which bits of the\n+     object might be nonzero in its own mode, taking into account the fact\n+     that on many CISC machines, accessing an object in a wider mode\n+     causes the high-order bits to become undefined.  So they are\n+     not known to be zero.  */\n+\n+  if (GET_MODE (x) != VOIDmode && GET_MODE (x) != mode\n+      && GET_MODE_BITSIZE (GET_MODE (x)) <= BITS_PER_WORD\n+      && GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT\n+      && GET_MODE_BITSIZE (mode) > GET_MODE_BITSIZE (GET_MODE (x)))\n+    {\n+      nonzero &= cached_nonzero_bits (x, GET_MODE (x),\n+\t\t\t\t      known_x, known_mode, known_ret);\n+      nonzero |= GET_MODE_MASK (mode) & ~GET_MODE_MASK (GET_MODE (x));\n+      return nonzero;\n+    }\n+#endif\n+\n+  code = GET_CODE (x);\n+  switch (code)\n+    {\n+    case REG:\n+#if defined(POINTERS_EXTEND_UNSIGNED) && !defined(HAVE_ptr_extend)\n+      /* If pointers extend unsigned and this is a pointer in Pmode, say that\n+\t all the bits above ptr_mode are known to be zero.  */\n+      if (POINTERS_EXTEND_UNSIGNED && GET_MODE (x) == Pmode\n+\t  && REG_POINTER (x))\n+\tnonzero &= GET_MODE_MASK (ptr_mode);\n+#endif\n+\n+      /* Include declared information about alignment of pointers.  */\n+      /* ??? We don't properly preserve REG_POINTER changes across\n+\t pointer-to-integer casts, so we can't trust it except for\n+\t things that we know must be pointers.  See execute/960116-1.c.  */\n+      if ((x == stack_pointer_rtx\n+\t   || x == frame_pointer_rtx\n+\t   || x == arg_pointer_rtx)\n+\t  && REGNO_POINTER_ALIGN (REGNO (x)))\n+\t{\n+\t  unsigned HOST_WIDE_INT alignment\n+\t    = REGNO_POINTER_ALIGN (REGNO (x)) / BITS_PER_UNIT;\n+\n+#ifdef PUSH_ROUNDING\n+\t  /* If PUSH_ROUNDING is defined, it is possible for the\n+\t     stack to be momentarily aligned only to that amount,\n+\t     so we pick the least alignment.  */\n+\t  if (x == stack_pointer_rtx && PUSH_ARGS)\n+\t    alignment = MIN ((unsigned HOST_WIDE_INT) PUSH_ROUNDING (1),\n+\t\t\t     alignment);\n+#endif\n+\n+\t  nonzero &= ~(alignment - 1);\n+\t}\n+\n+      {\n+\tunsigned HOST_WIDE_INT nonzero_for_hook = nonzero;\n+\trtx new = rtl_hooks.reg_nonzero_bits (x, mode, known_x,\n+\t\t\t\t\t      known_mode, known_ret,\n+\t\t\t\t\t      &nonzero_for_hook);\n+\n+\tif (new)\n+\t  nonzero_for_hook &= cached_nonzero_bits (new, mode, known_x,\n+\t\t\t\t\t\t   known_mode, known_ret);\n+\n+\treturn nonzero_for_hook;\n+      }\n+\n+    case CONST_INT:\n+#ifdef SHORT_IMMEDIATES_SIGN_EXTEND\n+      /* If X is negative in MODE, sign-extend the value.  */\n+      if (INTVAL (x) > 0 && mode_width < BITS_PER_WORD\n+\t  && 0 != (INTVAL (x) & ((HOST_WIDE_INT) 1 << (mode_width - 1))))\n+\treturn (INTVAL (x) | ((HOST_WIDE_INT) (-1) << mode_width));\n+#endif\n+\n+      return INTVAL (x);\n+\n+    case MEM:\n+#ifdef LOAD_EXTEND_OP\n+      /* In many, if not most, RISC machines, reading a byte from memory\n+\t zeros the rest of the register.  Noticing that fact saves a lot\n+\t of extra zero-extends.  */\n+      if (LOAD_EXTEND_OP (GET_MODE (x)) == ZERO_EXTEND)\n+\tnonzero &= GET_MODE_MASK (GET_MODE (x));\n+#endif\n+      break;\n+\n+    case EQ:  case NE:\n+    case UNEQ:  case LTGT:\n+    case GT:  case GTU:  case UNGT:\n+    case LT:  case LTU:  case UNLT:\n+    case GE:  case GEU:  case UNGE:\n+    case LE:  case LEU:  case UNLE:\n+    case UNORDERED: case ORDERED:\n+\n+      /* If this produces an integer result, we know which bits are set.\n+\t Code here used to clear bits outside the mode of X, but that is\n+\t now done above.  */\n+\n+      if (GET_MODE_CLASS (mode) == MODE_INT\n+\t  && mode_width <= HOST_BITS_PER_WIDE_INT)\n+\tnonzero = STORE_FLAG_VALUE;\n+      break;\n+\n+    case NEG:\n+#if 0\n+      /* Disabled to avoid exponential mutual recursion between nonzero_bits\n+\t and num_sign_bit_copies.  */\n+      if (num_sign_bit_copies (XEXP (x, 0), GET_MODE (x))\n+\t  == GET_MODE_BITSIZE (GET_MODE (x)))\n+\tnonzero = 1;\n+#endif\n+\n+      if (GET_MODE_SIZE (GET_MODE (x)) < mode_width)\n+\tnonzero |= (GET_MODE_MASK (mode) & ~GET_MODE_MASK (GET_MODE (x)));\n+      break;\n+\n+    case ABS:\n+#if 0\n+      /* Disabled to avoid exponential mutual recursion between nonzero_bits\n+\t and num_sign_bit_copies.  */\n+      if (num_sign_bit_copies (XEXP (x, 0), GET_MODE (x))\n+\t  == GET_MODE_BITSIZE (GET_MODE (x)))\n+\tnonzero = 1;\n+#endif\n+      break;\n+\n+    case TRUNCATE:\n+      nonzero &= (cached_nonzero_bits (XEXP (x, 0), mode,\n+\t\t\t\t       known_x, known_mode, known_ret)\n+\t\t  & GET_MODE_MASK (mode));\n+      break;\n+\n+    case ZERO_EXTEND:\n+      nonzero &= cached_nonzero_bits (XEXP (x, 0), mode,\n+\t\t\t\t      known_x, known_mode, known_ret);\n+      if (GET_MODE (XEXP (x, 0)) != VOIDmode)\n+\tnonzero &= GET_MODE_MASK (GET_MODE (XEXP (x, 0)));\n+      break;\n+\n+    case SIGN_EXTEND:\n+      /* If the sign bit is known clear, this is the same as ZERO_EXTEND.\n+\t Otherwise, show all the bits in the outer mode but not the inner\n+\t may be nonzero.  */\n+      inner_nz = cached_nonzero_bits (XEXP (x, 0), mode,\n+\t\t\t\t      known_x, known_mode, known_ret);\n+      if (GET_MODE (XEXP (x, 0)) != VOIDmode)\n+\t{\n+\t  inner_nz &= GET_MODE_MASK (GET_MODE (XEXP (x, 0)));\n+\t  if (inner_nz\n+\t      & (((HOST_WIDE_INT) 1\n+\t\t  << (GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0))) - 1))))\n+\t    inner_nz |= (GET_MODE_MASK (mode)\n+\t\t\t & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0))));\n+\t}\n+\n+      nonzero &= inner_nz;\n+      break;\n+\n+    case AND:\n+      nonzero &= cached_nonzero_bits (XEXP (x, 0), mode,\n+\t\t\t\t       known_x, known_mode, known_ret)\n+      \t\t & cached_nonzero_bits (XEXP (x, 1), mode,\n+\t\t\t\t\tknown_x, known_mode, known_ret);\n+      break;\n+\n+    case XOR:   case IOR:\n+    case UMIN:  case UMAX:  case SMIN:  case SMAX:\n+      {\n+\tunsigned HOST_WIDE_INT nonzero0 =\n+\t  cached_nonzero_bits (XEXP (x, 0), mode,\n+\t\t\t       known_x, known_mode, known_ret);\n+\n+\t/* Don't call nonzero_bits for the second time if it cannot change\n+\t   anything.  */\n+\tif ((nonzero & nonzero0) != nonzero)\n+\t  nonzero &= nonzero0\n+      \t\t     | cached_nonzero_bits (XEXP (x, 1), mode,\n+\t\t\t\t\t    known_x, known_mode, known_ret);\n+      }\n+      break;\n+\n+    case PLUS:  case MINUS:\n+    case MULT:\n+    case DIV:   case UDIV:\n+    case MOD:   case UMOD:\n+      /* We can apply the rules of arithmetic to compute the number of\n+\t high- and low-order zero bits of these operations.  We start by\n+\t computing the width (position of the highest-order nonzero bit)\n+\t and the number of low-order zero bits for each value.  */\n+      {\n+\tunsigned HOST_WIDE_INT nz0 =\n+\t  cached_nonzero_bits (XEXP (x, 0), mode,\n+\t\t\t       known_x, known_mode, known_ret);\n+\tunsigned HOST_WIDE_INT nz1 =\n+\t  cached_nonzero_bits (XEXP (x, 1), mode,\n+\t\t\t       known_x, known_mode, known_ret);\n+\tint sign_index = GET_MODE_BITSIZE (GET_MODE (x)) - 1;\n+\tint width0 = floor_log2 (nz0) + 1;\n+\tint width1 = floor_log2 (nz1) + 1;\n+\tint low0 = floor_log2 (nz0 & -nz0);\n+\tint low1 = floor_log2 (nz1 & -nz1);\n+\tHOST_WIDE_INT op0_maybe_minusp\n+\t  = (nz0 & ((HOST_WIDE_INT) 1 << sign_index));\n+\tHOST_WIDE_INT op1_maybe_minusp\n+\t  = (nz1 & ((HOST_WIDE_INT) 1 << sign_index));\n+\tunsigned int result_width = mode_width;\n+\tint result_low = 0;\n+\n+\tswitch (code)\n+\t  {\n+\t  case PLUS:\n+\t    result_width = MAX (width0, width1) + 1;\n+\t    result_low = MIN (low0, low1);\n+\t    break;\n+\t  case MINUS:\n+\t    result_low = MIN (low0, low1);\n+\t    break;\n+\t  case MULT:\n+\t    result_width = width0 + width1;\n+\t    result_low = low0 + low1;\n+\t    break;\n+\t  case DIV:\n+\t    if (width1 == 0)\n+\t      break;\n+\t    if (! op0_maybe_minusp && ! op1_maybe_minusp)\n+\t      result_width = width0;\n+\t    break;\n+\t  case UDIV:\n+\t    if (width1 == 0)\n+\t      break;\n+\t    result_width = width0;\n+\t    break;\n+\t  case MOD:\n+\t    if (width1 == 0)\n+\t      break;\n+\t    if (! op0_maybe_minusp && ! op1_maybe_minusp)\n+\t      result_width = MIN (width0, width1);\n+\t    result_low = MIN (low0, low1);\n+\t    break;\n+\t  case UMOD:\n+\t    if (width1 == 0)\n+\t      break;\n+\t    result_width = MIN (width0, width1);\n+\t    result_low = MIN (low0, low1);\n+\t    break;\n+\t  default:\n+\t    abort ();\n+\t  }\n+\n+\tif (result_width < mode_width)\n+\t  nonzero &= ((HOST_WIDE_INT) 1 << result_width) - 1;\n+\n+\tif (result_low > 0)\n+\t  nonzero &= ~(((HOST_WIDE_INT) 1 << result_low) - 1);\n+\n+#ifdef POINTERS_EXTEND_UNSIGNED\n+\t/* If pointers extend unsigned and this is an addition or subtraction\n+\t   to a pointer in Pmode, all the bits above ptr_mode are known to be\n+\t   zero.  */\n+\tif (POINTERS_EXTEND_UNSIGNED > 0 && GET_MODE (x) == Pmode\n+\t    && (code == PLUS || code == MINUS)\n+\t    && GET_CODE (XEXP (x, 0)) == REG && REG_POINTER (XEXP (x, 0)))\n+\t  nonzero &= GET_MODE_MASK (ptr_mode);\n+#endif\n+      }\n+      break;\n+\n+    case ZERO_EXTRACT:\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (x, 1)) < HOST_BITS_PER_WIDE_INT)\n+\tnonzero &= ((HOST_WIDE_INT) 1 << INTVAL (XEXP (x, 1))) - 1;\n+      break;\n+\n+    case SUBREG:\n+      /* If this is a SUBREG formed for a promoted variable that has\n+\t been zero-extended, we know that at least the high-order bits\n+\t are zero, though others might be too.  */\n+\n+      if (SUBREG_PROMOTED_VAR_P (x) && SUBREG_PROMOTED_UNSIGNED_P (x) > 0)\n+\tnonzero = GET_MODE_MASK (GET_MODE (x))\n+\t\t  & cached_nonzero_bits (SUBREG_REG (x), GET_MODE (x),\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+\n+      /* If the inner mode is a single word for both the host and target\n+\t machines, we can compute this from which bits of the inner\n+\t object might be nonzero.  */\n+      if (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))) <= BITS_PER_WORD\n+\t  && (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x)))\n+\t      <= HOST_BITS_PER_WIDE_INT))\n+\t{\n+\t  nonzero &= cached_nonzero_bits (SUBREG_REG (x), mode,\n+\t\t\t\t\t  known_x, known_mode, known_ret);\n+\n+#if defined (WORD_REGISTER_OPERATIONS) && defined (LOAD_EXTEND_OP)\n+\t  /* If this is a typical RISC machine, we only have to worry\n+\t     about the way loads are extended.  */\n+\t  if ((LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) == SIGN_EXTEND\n+\t       ? (((nonzero\n+\t\t    & (((unsigned HOST_WIDE_INT) 1\n+\t\t\t<< (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))) - 1))))\n+\t\t   != 0))\n+\t       : LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) != ZERO_EXTEND)\n+\t      || GET_CODE (SUBREG_REG (x)) != MEM)\n+#endif\n+\t    {\n+\t      /* On many CISC machines, accessing an object in a wider mode\n+\t\t causes the high-order bits to become undefined.  So they are\n+\t\t not known to be zero.  */\n+\t      if (GET_MODE_SIZE (GET_MODE (x))\n+\t\t  > GET_MODE_SIZE (GET_MODE (SUBREG_REG (x))))\n+\t\tnonzero |= (GET_MODE_MASK (GET_MODE (x))\n+\t\t\t    & ~GET_MODE_MASK (GET_MODE (SUBREG_REG (x))));\n+\t    }\n+\t}\n+      break;\n+\n+    case ASHIFTRT:\n+    case LSHIFTRT:\n+    case ASHIFT:\n+    case ROTATE:\n+      /* The nonzero bits are in two classes: any bits within MODE\n+\t that aren't in GET_MODE (x) are always significant.  The rest of the\n+\t nonzero bits are those that are significant in the operand of\n+\t the shift when shifted the appropriate number of bits.  This\n+\t shows that high-order bits are cleared by the right shift and\n+\t low-order bits by left shifts.  */\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (x, 1)) >= 0\n+\t  && INTVAL (XEXP (x, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t{\n+\t  enum machine_mode inner_mode = GET_MODE (x);\n+\t  unsigned int width = GET_MODE_BITSIZE (inner_mode);\n+\t  int count = INTVAL (XEXP (x, 1));\n+\t  unsigned HOST_WIDE_INT mode_mask = GET_MODE_MASK (inner_mode);\n+\t  unsigned HOST_WIDE_INT op_nonzero =\n+\t    cached_nonzero_bits (XEXP (x, 0), mode,\n+\t\t\t\t known_x, known_mode, known_ret);\n+\t  unsigned HOST_WIDE_INT inner = op_nonzero & mode_mask;\n+\t  unsigned HOST_WIDE_INT outer = 0;\n+\n+\t  if (mode_width > width)\n+\t    outer = (op_nonzero & nonzero & ~mode_mask);\n+\n+\t  if (code == LSHIFTRT)\n+\t    inner >>= count;\n+\t  else if (code == ASHIFTRT)\n+\t    {\n+\t      inner >>= count;\n+\n+\t      /* If the sign bit may have been nonzero before the shift, we\n+\t\t need to mark all the places it could have been copied to\n+\t\t by the shift as possibly nonzero.  */\n+\t      if (inner & ((HOST_WIDE_INT) 1 << (width - 1 - count)))\n+\t\tinner |= (((HOST_WIDE_INT) 1 << count) - 1) << (width - count);\n+\t    }\n+\t  else if (code == ASHIFT)\n+\t    inner <<= count;\n+\t  else\n+\t    inner = ((inner << (count % width)\n+\t\t      | (inner >> (width - (count % width)))) & mode_mask);\n+\n+\t  nonzero &= (outer | inner);\n+\t}\n+      break;\n+\n+    case FFS:\n+    case POPCOUNT:\n+      /* This is at most the number of bits in the mode.  */\n+      nonzero = ((HOST_WIDE_INT) 2 << (floor_log2 (mode_width))) - 1;\n+      break;\n+\n+    case CLZ:\n+      /* If CLZ has a known value at zero, then the nonzero bits are\n+\t that value, plus the number of bits in the mode minus one.  */\n+      if (CLZ_DEFINED_VALUE_AT_ZERO (mode, nonzero))\n+\tnonzero |= ((HOST_WIDE_INT) 1 << (floor_log2 (mode_width))) - 1;\n+      else\n+\tnonzero = -1;\n+      break;\n+\n+    case CTZ:\n+      /* If CTZ has a known value at zero, then the nonzero bits are\n+\t that value, plus the number of bits in the mode minus one.  */\n+      if (CTZ_DEFINED_VALUE_AT_ZERO (mode, nonzero))\n+\tnonzero |= ((HOST_WIDE_INT) 1 << (floor_log2 (mode_width))) - 1;\n+      else\n+\tnonzero = -1;\n+      break;\n+\n+    case PARITY:\n+      nonzero = 1;\n+      break;\n+\n+    case IF_THEN_ELSE:\n+      {\n+\tunsigned HOST_WIDE_INT nonzero_true =\n+\t  cached_nonzero_bits (XEXP (x, 1), mode,\n+\t\t\t       known_x, known_mode, known_ret);\n+\n+\t/* Don't call nonzero_bits for the second time if it cannot change\n+\t   anything.  */\n+\tif ((nonzero & nonzero_true) != nonzero)\n+\t  nonzero &= nonzero_true\n+      \t\t     | cached_nonzero_bits (XEXP (x, 2), mode,\n+\t\t\t\t\t    known_x, known_mode, known_ret);\n+      }\n+      break;\n+\n+    default:\n+      break;\n+    }\n+\n+  return nonzero;\n+}\n+\n+/* See the macro definition above.  */\n+#undef cached_num_sign_bit_copies\n+\n+\f\n+/* The function cached_num_sign_bit_copies is a wrapper around\n+   num_sign_bit_copies1.  It avoids exponential behavior in\n+   num_sign_bit_copies1 when X has identical subexpressions on the\n+   first or the second level.  */\n+\n+static unsigned int\n+cached_num_sign_bit_copies (rtx x, enum machine_mode mode, rtx known_x,\n+\t\t\t    enum machine_mode known_mode,\n+\t\t\t    unsigned int known_ret)\n+{\n+  if (x == known_x && mode == known_mode)\n+    return known_ret;\n+\n+  /* Try to find identical subexpressions.  If found call\n+     num_sign_bit_copies1 on X with the subexpressions as KNOWN_X and\n+     the precomputed value for the subexpression as KNOWN_RET.  */\n+\n+  if (ARITHMETIC_P (x))\n+    {\n+      rtx x0 = XEXP (x, 0);\n+      rtx x1 = XEXP (x, 1);\n+\n+      /* Check the first level.  */\n+      if (x0 == x1)\n+\treturn\n+\t  num_sign_bit_copies1 (x, mode, x0, mode,\n+\t\t\t\tcached_num_sign_bit_copies (x0, mode, known_x,\n+\t\t\t\t\t\t\t    known_mode,\n+\t\t\t\t\t\t\t    known_ret));\n+\n+      /* Check the second level.  */\n+      if (ARITHMETIC_P (x0)\n+\t  && (x1 == XEXP (x0, 0) || x1 == XEXP (x0, 1)))\n+\treturn\n+\t  num_sign_bit_copies1 (x, mode, x1, mode,\n+\t\t\t\tcached_num_sign_bit_copies (x1, mode, known_x,\n+\t\t\t\t\t\t\t    known_mode,\n+\t\t\t\t\t\t\t    known_ret));\n+\n+      if (ARITHMETIC_P (x1)\n+\t  && (x0 == XEXP (x1, 0) || x0 == XEXP (x1, 1)))\n+\treturn\n+\t  num_sign_bit_copies1 (x, mode, x0, mode,\n+\t\t\t\tcached_num_sign_bit_copies (x0, mode, known_x,\n+\t\t\t\t\t\t\t    known_mode,\n+\t\t\t\t\t\t\t    known_ret));\n+    }\n+\n+  return num_sign_bit_copies1 (x, mode, known_x, known_mode, known_ret);\n+}\n+\n+/* Return the number of bits at the high-order end of X that are known to\n+   be equal to the sign bit.  X will be used in mode MODE; if MODE is\n+   VOIDmode, X will be used in its own mode.  The returned value  will always\n+   be between 1 and the number of bits in MODE.  */\n+\n+static unsigned int\n+num_sign_bit_copies1 (rtx x, enum machine_mode mode, rtx known_x,\n+\t\t      enum machine_mode known_mode,\n+\t\t      unsigned int known_ret)\n+{\n+  enum rtx_code code = GET_CODE (x);\n+  unsigned int bitwidth = GET_MODE_BITSIZE (mode);\n+  int num0, num1, result;\n+  unsigned HOST_WIDE_INT nonzero;\n+\n+  /* If we weren't given a mode, use the mode of X.  If the mode is still\n+     VOIDmode, we don't know anything.  Likewise if one of the modes is\n+     floating-point.  */\n+\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (x);\n+\n+  if (mode == VOIDmode || FLOAT_MODE_P (mode) || FLOAT_MODE_P (GET_MODE (x)))\n+    return 1;\n+\n+  /* For a smaller object, just ignore the high bits.  */\n+  if (bitwidth < GET_MODE_BITSIZE (GET_MODE (x)))\n+    {\n+      num0 = cached_num_sign_bit_copies (x, GET_MODE (x),\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      return MAX (1,\n+\t\t  num0 - (int) (GET_MODE_BITSIZE (GET_MODE (x)) - bitwidth));\n+    }\n+\n+  if (GET_MODE (x) != VOIDmode && bitwidth > GET_MODE_BITSIZE (GET_MODE (x)))\n+    {\n+#ifndef WORD_REGISTER_OPERATIONS\n+  /* If this machine does not do all register operations on the entire\n+     register and MODE is wider than the mode of X, we can say nothing\n+     at all about the high-order bits.  */\n+      return 1;\n+#else\n+      /* Likewise on machines that do, if the mode of the object is smaller\n+\t than a word and loads of that size don't sign extend, we can say\n+\t nothing about the high order bits.  */\n+      if (GET_MODE_BITSIZE (GET_MODE (x)) < BITS_PER_WORD\n+#ifdef LOAD_EXTEND_OP\n+\t  && LOAD_EXTEND_OP (GET_MODE (x)) != SIGN_EXTEND\n+#endif\n+\t  )\n+\treturn 1;\n+#endif\n+    }\n+\n+  switch (code)\n+    {\n+    case REG:\n+\n+#if defined(POINTERS_EXTEND_UNSIGNED) && !defined(HAVE_ptr_extend)\n+      /* If pointers extend signed and this is a pointer in Pmode, say that\n+\t all the bits above ptr_mode are known to be sign bit copies.  */\n+      if (! POINTERS_EXTEND_UNSIGNED && GET_MODE (x) == Pmode && mode == Pmode\n+\t  && REG_POINTER (x))\n+\treturn GET_MODE_BITSIZE (Pmode) - GET_MODE_BITSIZE (ptr_mode) + 1;\n+#endif\n+\n+      {\n+\tunsigned int copies_for_hook = 1, copies = 1;\n+\trtx new = rtl_hooks.reg_num_sign_bit_copies (x, mode, known_x,\n+\t\t\t\t\t\t     known_mode, known_ret,\n+\t\t\t\t\t\t     &copies_for_hook);\n+\n+\tif (new)\n+\t  copies = cached_num_sign_bit_copies (new, mode, known_x,\n+\t\t\t\t\t       known_mode, known_ret);\n+\n+\tif (copies > 1 || copies_for_hook > 1)\n+\t  return MAX (copies, copies_for_hook);\n+\n+\t/* Else, use nonzero_bits to guess num_sign_bit_copies (see below).  */\n+      }\n+      break;\n+\n+    case MEM:\n+#ifdef LOAD_EXTEND_OP\n+      /* Some RISC machines sign-extend all loads of smaller than a word.  */\n+      if (LOAD_EXTEND_OP (GET_MODE (x)) == SIGN_EXTEND)\n+\treturn MAX (1, ((int) bitwidth\n+\t\t\t- (int) GET_MODE_BITSIZE (GET_MODE (x)) + 1));\n+#endif\n+      break;\n+\n+    case CONST_INT:\n+      /* If the constant is negative, take its 1's complement and remask.\n+\t Then see how many zero bits we have.  */\n+      nonzero = INTVAL (x) & GET_MODE_MASK (mode);\n+      if (bitwidth <= HOST_BITS_PER_WIDE_INT\n+\t  && (nonzero & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n+\tnonzero = (~nonzero) & GET_MODE_MASK (mode);\n+\n+      return (nonzero == 0 ? bitwidth : bitwidth - floor_log2 (nonzero) - 1);\n+\n+    case SUBREG:\n+      /* If this is a SUBREG for a promoted object that is sign-extended\n+\t and we are looking at it in a wider mode, we know that at least the\n+\t high-order bits are known to be sign bit copies.  */\n+\n+      if (SUBREG_PROMOTED_VAR_P (x) && ! SUBREG_PROMOTED_UNSIGNED_P (x))\n+\t{\n+\t  num0 = cached_num_sign_bit_copies (SUBREG_REG (x), mode,\n+\t\t\t\t\t     known_x, known_mode, known_ret);\n+\t  return MAX ((int) bitwidth\n+\t\t      - (int) GET_MODE_BITSIZE (GET_MODE (x)) + 1,\n+\t\t      num0);\n+\t}\n+\n+      /* For a smaller object, just ignore the high bits.  */\n+      if (bitwidth <= GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))))\n+\t{\n+\t  num0 = cached_num_sign_bit_copies (SUBREG_REG (x), VOIDmode,\n+\t\t\t\t\t     known_x, known_mode, known_ret);\n+\t  return MAX (1, (num0\n+\t\t\t  - (int) (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x)))\n+\t\t\t\t   - bitwidth)));\n+\t}\n+\n+#ifdef WORD_REGISTER_OPERATIONS\n+#ifdef LOAD_EXTEND_OP\n+      /* For paradoxical SUBREGs on machines where all register operations\n+\t affect the entire register, just look inside.  Note that we are\n+\t passing MODE to the recursive call, so the number of sign bit copies\n+\t will remain relative to that mode, not the inner mode.  */\n+\n+      /* This works only if loads sign extend.  Otherwise, if we get a\n+\t reload for the inner part, it may be loaded from the stack, and\n+\t then we lose all sign bit copies that existed before the store\n+\t to the stack.  */\n+\n+      if ((GET_MODE_SIZE (GET_MODE (x))\n+\t   > GET_MODE_SIZE (GET_MODE (SUBREG_REG (x))))\n+\t  && LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) == SIGN_EXTEND\n+\t  && GET_CODE (SUBREG_REG (x)) == MEM)\n+\treturn cached_num_sign_bit_copies (SUBREG_REG (x), mode,\n+\t\t\t\t\t   known_x, known_mode, known_ret);\n+#endif\n+#endif\n+      break;\n+\n+    case SIGN_EXTRACT:\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n+\treturn MAX (1, (int) bitwidth - INTVAL (XEXP (x, 1)));\n+      break;\n+\n+    case SIGN_EXTEND:\n+      return (bitwidth - GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0)))\n+\t      + cached_num_sign_bit_copies (XEXP (x, 0), VOIDmode,\n+\t\t\t\t\t    known_x, known_mode, known_ret));\n+\n+    case TRUNCATE:\n+      /* For a smaller object, just ignore the high bits.  */\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 0), VOIDmode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      return MAX (1, (num0 - (int) (GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0)))\n+\t\t\t\t    - bitwidth)));\n+\n+    case NOT:\n+      return cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+\n+    case ROTATE:       case ROTATERT:\n+      /* If we are rotating left by a number of bits less than the number\n+\t of sign bit copies, we can just subtract that amount from the\n+\t number.  */\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (x, 1)) >= 0\n+\t  && INTVAL (XEXP (x, 1)) < (int) bitwidth)\n+\t{\n+\t  num0 = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t     known_x, known_mode, known_ret);\n+\t  return MAX (1, num0 - (code == ROTATE ? INTVAL (XEXP (x, 1))\n+\t\t\t\t : (int) bitwidth - INTVAL (XEXP (x, 1))));\n+\t}\n+      break;\n+\n+    case NEG:\n+      /* In general, this subtracts one sign bit copy.  But if the value\n+\t is known to be positive, the number of sign bit copies is the\n+\t same as that of the input.  Finally, if the input has just one bit\n+\t that might be nonzero, all the bits are copies of the sign bit.  */\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      if (bitwidth > HOST_BITS_PER_WIDE_INT)\n+\treturn num0 > 1 ? num0 - 1 : 1;\n+\n+      nonzero = nonzero_bits (XEXP (x, 0), mode);\n+      if (nonzero == 1)\n+\treturn bitwidth;\n+\n+      if (num0 > 1\n+\t  && (((HOST_WIDE_INT) 1 << (bitwidth - 1)) & nonzero))\n+\tnum0--;\n+\n+      return num0;\n+\n+    case IOR:   case AND:   case XOR:\n+    case SMIN:  case SMAX:  case UMIN:  case UMAX:\n+      /* Logical operations will preserve the number of sign-bit copies.\n+\t MIN and MAX operations always return one of the operands.  */\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      num1 = cached_num_sign_bit_copies (XEXP (x, 1), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      return MIN (num0, num1);\n+\n+    case PLUS:  case MINUS:\n+      /* For addition and subtraction, we can have a 1-bit carry.  However,\n+\t if we are subtracting 1 from a positive number, there will not\n+\t be such a carry.  Furthermore, if the positive number is known to\n+\t be 0 or 1, we know the result is either -1 or 0.  */\n+\n+      if (code == PLUS && XEXP (x, 1) == constm1_rtx\n+\t  && bitwidth <= HOST_BITS_PER_WIDE_INT)\n+\t{\n+\t  nonzero = nonzero_bits (XEXP (x, 0), mode);\n+\t  if ((((HOST_WIDE_INT) 1 << (bitwidth - 1)) & nonzero) == 0)\n+\t    return (nonzero == 1 || nonzero == 0 ? bitwidth\n+\t\t    : bitwidth - floor_log2 (nonzero) - 1);\n+\t}\n+\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      num1 = cached_num_sign_bit_copies (XEXP (x, 1), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      result = MAX (1, MIN (num0, num1) - 1);\n+\n+#ifdef POINTERS_EXTEND_UNSIGNED\n+      /* If pointers extend signed and this is an addition or subtraction\n+\t to a pointer in Pmode, all the bits above ptr_mode are known to be\n+\t sign bit copies.  */\n+      if (! POINTERS_EXTEND_UNSIGNED && GET_MODE (x) == Pmode\n+\t  && (code == PLUS || code == MINUS)\n+\t  && GET_CODE (XEXP (x, 0)) == REG && REG_POINTER (XEXP (x, 0)))\n+\tresult = MAX ((int) (GET_MODE_BITSIZE (Pmode)\n+\t\t\t     - GET_MODE_BITSIZE (ptr_mode) + 1),\n+\t\t      result);\n+#endif\n+      return result;\n+\n+    case MULT:\n+      /* The number of bits of the product is the sum of the number of\n+\t bits of both terms.  However, unless one of the terms if known\n+\t to be positive, we must allow for an additional bit since negating\n+\t a negative number can remove one sign bit copy.  */\n+\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      num1 = cached_num_sign_bit_copies (XEXP (x, 1), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+\n+      result = bitwidth - (bitwidth - num0) - (bitwidth - num1);\n+      if (result > 0\n+\t  && (bitwidth > HOST_BITS_PER_WIDE_INT\n+\t      || (((nonzero_bits (XEXP (x, 0), mode)\n+\t\t    & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n+\t\t  && ((nonzero_bits (XEXP (x, 1), mode)\n+\t\t       & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0))))\n+\tresult--;\n+\n+      return MAX (1, result);\n+\n+    case UDIV:\n+      /* The result must be <= the first operand.  If the first operand\n+\t has the high bit set, we know nothing about the number of sign\n+\t bit copies.  */\n+      if (bitwidth > HOST_BITS_PER_WIDE_INT)\n+\treturn 1;\n+      else if ((nonzero_bits (XEXP (x, 0), mode)\n+\t\t& ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n+\treturn 1;\n+      else\n+\treturn cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t   known_x, known_mode, known_ret);\n+\n+    case UMOD:\n+      /* The result must be <= the second operand.  */\n+      return cached_num_sign_bit_copies (XEXP (x, 1), mode,\n+\t\t\t\t\t   known_x, known_mode, known_ret);\n+\n+    case DIV:\n+      /* Similar to unsigned division, except that we have to worry about\n+\t the case where the divisor is negative, in which case we have\n+\t to add 1.  */\n+      result = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t   known_x, known_mode, known_ret);\n+      if (result > 1\n+\t  && (bitwidth > HOST_BITS_PER_WIDE_INT\n+\t      || (nonzero_bits (XEXP (x, 1), mode)\n+\t\t  & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0))\n+\tresult--;\n+\n+      return result;\n+\n+    case MOD:\n+      result = cached_num_sign_bit_copies (XEXP (x, 1), mode,\n+\t\t\t\t\t   known_x, known_mode, known_ret);\n+      if (result > 1\n+\t  && (bitwidth > HOST_BITS_PER_WIDE_INT\n+\t      || (nonzero_bits (XEXP (x, 1), mode)\n+\t\t  & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0))\n+\tresult--;\n+\n+      return result;\n+\n+    case ASHIFTRT:\n+      /* Shifts by a constant add to the number of bits equal to the\n+\t sign bit.  */\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (x, 1)) > 0)\n+\tnum0 = MIN ((int) bitwidth, num0 + INTVAL (XEXP (x, 1)));\n+\n+      return num0;\n+\n+    case ASHIFT:\n+      /* Left shifts destroy copies.  */\n+      if (GET_CODE (XEXP (x, 1)) != CONST_INT\n+\t  || INTVAL (XEXP (x, 1)) < 0\n+\t  || INTVAL (XEXP (x, 1)) >= (int) bitwidth)\n+\treturn 1;\n+\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 0), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      return MAX (1, num0 - INTVAL (XEXP (x, 1)));\n+\n+    case IF_THEN_ELSE:\n+      num0 = cached_num_sign_bit_copies (XEXP (x, 1), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      num1 = cached_num_sign_bit_copies (XEXP (x, 2), mode,\n+\t\t\t\t\t known_x, known_mode, known_ret);\n+      return MIN (num0, num1);\n+\n+    case EQ:  case NE:  case GE:  case GT:  case LE:  case LT:\n+    case UNEQ:  case LTGT:  case UNGE:  case UNGT:  case UNLE:  case UNLT:\n+    case GEU: case GTU: case LEU: case LTU:\n+    case UNORDERED: case ORDERED:\n+      /* If the constant is negative, take its 1's complement and remask.\n+\t Then see how many zero bits we have.  */\n+      nonzero = STORE_FLAG_VALUE;\n+      if (bitwidth <= HOST_BITS_PER_WIDE_INT\n+\t  && (nonzero & ((HOST_WIDE_INT) 1 << (bitwidth - 1))) != 0)\n+\tnonzero = (~nonzero) & GET_MODE_MASK (mode);\n+\n+      return (nonzero == 0 ? bitwidth : bitwidth - floor_log2 (nonzero) - 1);\n+\n+    default:\n+      break;\n+    }\n+\n+  /* If we haven't been able to figure it out by one of the above rules,\n+     see if some of the high-order bits are known to be zero.  If so,\n+     count those bits and return one less than that amount.  If we can't\n+     safely compute the mask for this mode, always return BITWIDTH.  */\n+\n+  bitwidth = GET_MODE_BITSIZE (mode);\n+  if (bitwidth > HOST_BITS_PER_WIDE_INT)\n+    return 1;\n+\n+  nonzero = nonzero_bits (x, mode);\n+  return nonzero & ((HOST_WIDE_INT) 1 << (bitwidth - 1))\n+\t ? 1 : bitwidth - floor_log2 (nonzero) - 1;\n+}"}, {"sha": "aaae80cab8c44252827339e6dd69fdf0f0b8e23d", "filename": "gcc/rtlhooks-def.h", "status": "added", "additions": 46, "deletions": 0, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtlhooks-def.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtlhooks-def.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlhooks-def.h?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -0,0 +1,46 @@\n+/* Default macros to initialize an rtl_hooks data structure.\n+   Copyright 2004 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+#ifndef GCC_RTL_HOOKS_DEF_H\n+#define GCC_RTL_HOOKS_DEF_H\n+\n+#include \"rtl.h\"\n+\n+#define RTL_HOOKS_GEN_LOWPART gen_lowpart_general\n+#define RTL_HOOKS_REG_NONZERO_REG_BITS reg_nonzero_bits_general\n+#define RTL_HOOKS_REG_NUM_SIGN_BIT_COPIES reg_num_sign_bit_copies_general\n+\n+/* The structure is defined in rtl.h.  */\n+#define RTL_HOOKS_INITIALIZER {\t\t\t\\\n+  RTL_HOOKS_GEN_LOWPART,\t\t\t\\\n+  RTL_HOOKS_REG_NONZERO_REG_BITS,\t\t\\\n+  RTL_HOOKS_REG_NUM_SIGN_BIT_COPIES,\t\t\\\n+}\n+\n+extern rtx gen_lowpart_general (enum machine_mode, rtx);\n+extern rtx reg_nonzero_bits_general (rtx, enum machine_mode, rtx,\n+\t\t\t\t     enum machine_mode,\n+\t\t\t\t     unsigned HOST_WIDE_INT,\n+\t\t\t\t     unsigned HOST_WIDE_INT *);\n+extern rtx reg_num_sign_bit_copies_general (rtx, enum machine_mode, rtx,\n+\t\t\t\t\t    enum machine_mode,\n+\t\t\t\t\t    unsigned int, unsigned int *);\n+\n+#endif /* GCC_RTL_HOOKS_DEF_H */"}, {"sha": "b27cecea2cadaab209d39a5d2f0d04b6e111ea46", "filename": "gcc/rtlhooks.c", "status": "added", "additions": 105, "deletions": 0, "changes": 105, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtlhooks.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2f93eea8612d4ced2eeee52db5ce66bd75303455/gcc%2Frtlhooks.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlhooks.c?ref=2f93eea8612d4ced2eeee52db5ce66bd75303455", "patch": "@@ -0,0 +1,105 @@\n+/* Generic hooks for the RTL middle-end.\n+   Copyright (C) 2004 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"rtl.h\"\n+#include \"rtlhooks-def.h\"\n+#include \"expr.h\"\n+\f\n+\n+/* For speed, we will copy the RTX hooks struct member-by-member\n+   instead of doing indirect calls.  For these reason, we initialize\n+   *two* struct rtl_hooks globals: rtl_hooks is the one that is used\n+   to actually call the hooks, while general_rtl_hooks is used\n+   to restore the hooks by passes that modify them.  */\n+\n+const struct rtl_hooks general_rtl_hooks = RTL_HOOKS_INITIALIZER;\n+struct rtl_hooks rtl_hooks = RTL_HOOKS_INITIALIZER;\n+\n+rtx\n+gen_lowpart_general (enum machine_mode mode, rtx x)\n+{\n+  rtx result = gen_lowpart_common (mode, x);\n+\n+  if (result)\n+    return result;\n+  else if (GET_CODE (x) == REG)\n+    {\n+      /* Must be a hard reg that's not valid in MODE.  */\n+      result = gen_lowpart_common (mode, copy_to_reg (x));\n+      if (result == 0)\n+\tabort ();\n+      return result;\n+    }\n+  else if (GET_CODE (x) == MEM)\n+    {\n+      /* The only additional case we can do is MEM.  */\n+      int offset = 0;\n+\n+      /* The following exposes the use of \"x\" to CSE.  */\n+      if (GET_MODE_SIZE (GET_MODE (x)) <= UNITS_PER_WORD\n+\t  && SCALAR_INT_MODE_P (GET_MODE (x))\n+\t  && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (mode),\n+\t\t\t\t    GET_MODE_BITSIZE (GET_MODE (x)))\n+\t  && ! no_new_pseudos)\n+\treturn gen_lowpart_general (mode, force_reg (GET_MODE (x), x));\n+\n+      if (WORDS_BIG_ENDIAN)\n+\toffset = (MAX (GET_MODE_SIZE (GET_MODE (x)), UNITS_PER_WORD)\n+\t\t  - MAX (GET_MODE_SIZE (mode), UNITS_PER_WORD));\n+\n+      if (BYTES_BIG_ENDIAN)\n+\t/* Adjust the address so that the address-after-the-data\n+\t   is unchanged.  */\n+\toffset -= (MIN (UNITS_PER_WORD, GET_MODE_SIZE (mode))\n+\t\t   - MIN (UNITS_PER_WORD, GET_MODE_SIZE (GET_MODE (x))));\n+\n+      return adjust_address (x, mode, offset);\n+    }\n+  else if (GET_CODE (x) == ADDRESSOF)\n+    return gen_lowpart_general (mode, force_reg (GET_MODE (x), x));\n+  else\n+    abort ();\n+}\n+\n+rtx\n+reg_num_sign_bit_copies_general (rtx x ATTRIBUTE_UNUSED,\n+\t\t\t\t enum machine_mode mode ATTRIBUTE_UNUSED,\n+                                 rtx known_x ATTRIBUTE_UNUSED,\n+\t\t\t\t enum machine_mode known_mode ATTRIBUTE_UNUSED,\n+                                 unsigned int known_ret ATTRIBUTE_UNUSED,\n+                                 unsigned int *result ATTRIBUTE_UNUSED)\n+{\n+  return NULL;\n+}\n+\n+rtx\n+reg_nonzero_bits_general (rtx x ATTRIBUTE_UNUSED,\n+\t\t\t  enum machine_mode mode ATTRIBUTE_UNUSED,\n+\t\t\t  rtx known_x ATTRIBUTE_UNUSED,\n+                          enum machine_mode known_mode ATTRIBUTE_UNUSED,\n+                          unsigned HOST_WIDE_INT known_ret ATTRIBUTE_UNUSED,\n+                          unsigned HOST_WIDE_INT *nonzero ATTRIBUTE_UNUSED)\n+{\n+  return NULL;\n+}"}]}