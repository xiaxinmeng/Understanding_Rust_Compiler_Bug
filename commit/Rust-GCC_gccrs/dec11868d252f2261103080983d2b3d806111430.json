{"sha": "dec11868d252f2261103080983d2b3d806111430", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZGVjMTE4NjhkMjUyZjIyNjExMDMwODA5ODNkMmIzZDgwNjExMTQzMA==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2013-07-03T09:48:02Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2013-07-03T09:48:02Z"}, "message": "[AArch64] Convert ld1, st1 arm_neon.h intrinsics to RTL builtins.\n\ngcc/\n\t* config/aarch64/aarch64-builtins.c\n\t(aarch64_simd_expand_builtin): Handle AARCH64_SIMD_STORE1.\n\t* config/aarch64/aarch64-simd-builtins.def (ld1): New.\n\t(st1): Likewise.\n\t* config/aarch64/aarch64-simd.md\n\t(aarch64_ld1<VALL:mode>): New.\n\t(aarch64_st1<VALL:mode>): Likewise.\n\t* config/aarch64/arm_neon.h\n\t(vld1<q>_<fpsu><8, 16, 32, 64>): Convert to RTL builtins.\n\nFrom-SVN: r200634", "tree": {"sha": "91fd34bc9bd48730fa4908594156ccf1bc2c5e3d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/91fd34bc9bd48730fa4908594156ccf1bc2c5e3d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/dec11868d252f2261103080983d2b3d806111430", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/dec11868d252f2261103080983d2b3d806111430", "html_url": "https://github.com/Rust-GCC/gccrs/commit/dec11868d252f2261103080983d2b3d806111430", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/dec11868d252f2261103080983d2b3d806111430/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "b2809898249cdc0851ba2bd9749187589a8fd788", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b2809898249cdc0851ba2bd9749187589a8fd788", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b2809898249cdc0851ba2bd9749187589a8fd788"}], "stats": {"total": 839, "additions": 360, "deletions": 479}, "files": [{"sha": "280c72e7003979c9d30c5a3f0ef3fce883a620d1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/dec11868d252f2261103080983d2b3d806111430/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/dec11868d252f2261103080983d2b3d806111430/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=dec11868d252f2261103080983d2b3d806111430", "patch": "@@ -1,3 +1,15 @@\n+2013-07-03  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/aarch64/aarch64-builtins.c\n+\t(aarch64_simd_expand_builtin): Handle AARCH64_SIMD_STORE1.\n+\t* config/aarch64/aarch64-simd-builtins.def (ld1): New.\n+\t(st1): Likewise.\n+\t* config/aarch64/aarch64-simd.md\n+\t(aarch64_ld1<VALL:mode>): New.\n+\t(aarch64_st1<VALL:mode>): Likewise.\n+\t* config/aarch64/arm_neon.h\n+\t(vld1<q>_<fpsu><8, 16, 32, 64>): Convert to RTL builtins.\n+\n 2013-07-02  Sriraman Tallam  <tmsriram@google.com>\n \n \t* config/i386/i386.c (gate_insert_vzeroupper): Check if target"}, {"sha": "f49f06b1a99d3440c07bfe0e3fff14e850aa95fa", "filename": "gcc/config/aarch64/aarch64-builtins.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c?ref=dec11868d252f2261103080983d2b3d806111430", "patch": "@@ -1123,6 +1123,7 @@ aarch64_simd_expand_builtin (int fcode, tree exp, rtx target)\n       return aarch64_simd_expand_args (target, icode, 1, exp,\n \t\t\t\t       SIMD_ARG_COPY_TO_REG, SIMD_ARG_STOP);\n \n+    case AARCH64_SIMD_STORE1:\n     case AARCH64_SIMD_STORESTRUCT:\n       return aarch64_simd_expand_args (target, icode, 0, exp,\n \t\t\t\t       SIMD_ARG_COPY_TO_REG,"}, {"sha": "af2dd6efe0fc912217e4d56799f1bc5d4e3b6cc9", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=dec11868d252f2261103080983d2b3d806111430", "patch": "@@ -354,3 +354,10 @@\n \n   VAR1 (UNOP, float_extend_lo_, 0, v2df)\n   VAR1 (UNOP, float_truncate_lo_, 0, v2sf)\n+\n+  /* Implemented by aarch64_ld1<VALL:mode>.  */\n+  BUILTIN_VALL (LOAD1, ld1, 0)\n+\n+  /* Implemented by aarch64_st1<VALL:mode>.  */\n+  BUILTIN_VALL (STORE1, st1, 0)\n+"}, {"sha": "178efdc964e8a6a7ebc7cb1fc7a885d495652ce3", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=dec11868d252f2261103080983d2b3d806111430", "patch": "@@ -3882,6 +3882,17 @@\n   DONE;\n })\n \n+(define_expand \"aarch64_ld1<VALL:mode>\"\n+ [(match_operand:VALL 0 \"register_operand\")\n+  (match_operand:DI 1 \"register_operand\")]\n+  \"TARGET_SIMD\"\n+{\n+  enum machine_mode mode = <VALL:MODE>mode;\n+  rtx mem = gen_rtx_MEM (mode, operands[1]);\n+  emit_move_insn (operands[0], mem);\n+  DONE;\n+})\n+\n (define_expand \"aarch64_ld<VSTRUCT:nregs><VQ:mode>\"\n  [(match_operand:VSTRUCT 0 \"register_operand\" \"=w\")\n   (match_operand:DI 1 \"register_operand\" \"r\")\n@@ -4098,6 +4109,17 @@\n   DONE;\n })\n \n+(define_expand \"aarch64_st1<VALL:mode>\"\n+ [(match_operand:DI 0 \"register_operand\")\n+  (match_operand:VALL 1 \"register_operand\")]\n+  \"TARGET_SIMD\"\n+{\n+  enum machine_mode mode = <VALL:MODE>mode;\n+  rtx mem = gen_rtx_MEM (mode, operands[0]);\n+  emit_move_insn (mem, operands[1]);\n+  DONE;\n+})\n+\n ;; Expander for builtins to insert vector registers into large\n ;; opaque integer modes.\n "}, {"sha": "13ef11db3f6066931b249cb127d692a145bf54bb", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 318, "deletions": 479, "changes": 797, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/dec11868d252f2261103080983d2b3d806111430/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=dec11868d252f2261103080983d2b3d806111430", "patch": "@@ -7209,28 +7209,6 @@ vld1_dup_u64 (const uint64_t * a)\n   return result;\n }\n \n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vld1_f32 (const float32_t * a)\n-{\n-  float32x2_t result;\n-  __asm__ (\"ld1 {%0.2s}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const float32x2_t *_a = (float32x2_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n-vld1_f64 (const float64_t * a)\n-{\n-  float64x1_t result;\n-  __asm__ (\"ld1 {%0.1d}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(*a)\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n #define vld1_lane_f32(a, b, c)                                          \\\n   __extension__                                                         \\\n     ({                                                                  \\\n@@ -7387,116 +7365,6 @@ vld1_f64 (const float64_t * a)\n        result;                                                          \\\n      })\n \n-__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n-vld1_p8 (const poly8_t * a)\n-{\n-  poly8x8_t result;\n-  __asm__ (\"ld1 {%0.8b}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const poly8x8_t *_a = (poly8x8_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n-vld1_p16 (const poly16_t * a)\n-{\n-  poly16x4_t result;\n-  __asm__ (\"ld1 {%0.4h}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const poly16x4_t *_a = (poly16x4_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n-vld1_s8 (const int8_t * a)\n-{\n-  int8x8_t result;\n-  __asm__ (\"ld1 {%0.8b}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const int8x8_t *_a = (int8x8_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n-vld1_s16 (const int16_t * a)\n-{\n-  int16x4_t result;\n-  __asm__ (\"ld1 {%0.4h}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const int16x4_t *_a = (int16x4_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n-vld1_s32 (const int32_t * a)\n-{\n-  int32x2_t result;\n-  __asm__ (\"ld1 {%0.2s}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const int32x2_t *_a = (int32x2_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n-vld1_s64 (const int64_t * a)\n-{\n-  int64x1_t result;\n-  __asm__ (\"ld1 {%0.1d}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(*a)\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n-vld1_u8 (const uint8_t * a)\n-{\n-  uint8x8_t result;\n-  __asm__ (\"ld1 {%0.8b}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const uint8x8_t *_a = (uint8x8_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n-vld1_u16 (const uint16_t * a)\n-{\n-  uint16x4_t result;\n-  __asm__ (\"ld1 {%0.4h}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const uint16x4_t *_a = (uint16x4_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n-vld1_u32 (const uint32_t * a)\n-{\n-  uint32x2_t result;\n-  __asm__ (\"ld1 {%0.2s}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const uint32x2_t *_a = (uint32x2_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n-vld1_u64 (const uint64_t * a)\n-{\n-  uint64x1_t result;\n-  __asm__ (\"ld1 {%0.1d}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(*a)\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vld1q_dup_f32 (const float32_t * a)\n {\n@@ -7629,28 +7497,6 @@ vld1q_dup_u64 (const uint64_t * a)\n   return result;\n }\n \n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vld1q_f32 (const float32_t * a)\n-{\n-  float32x4_t result;\n-  __asm__ (\"ld1 {%0.4s}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const float32x4_t *_a = (float32x4_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vld1q_f64 (const float64_t * a)\n-{\n-  float64x2_t result;\n-  __asm__ (\"ld1 {%0.2d}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const float64x2_t *_a = (float64x2_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n #define vld1q_lane_f32(a, b, c)                                         \\\n   __extension__                                                         \\\n     ({                                                                  \\\n@@ -7807,116 +7653,6 @@ vld1q_f64 (const float64_t * a)\n        result;                                                          \\\n      })\n \n-__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n-vld1q_p8 (const poly8_t * a)\n-{\n-  poly8x16_t result;\n-  __asm__ (\"ld1 {%0.16b}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const poly8x16_t *_a = (poly8x16_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n-vld1q_p16 (const poly16_t * a)\n-{\n-  poly16x8_t result;\n-  __asm__ (\"ld1 {%0.16b}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const poly16x8_t *_a = (poly16x8_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n-vld1q_s8 (const int8_t * a)\n-{\n-  int8x16_t result;\n-  __asm__ (\"ld1 {%0.16b}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const int8x16_t *_a = (int8x16_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n-vld1q_s16 (const int16_t * a)\n-{\n-  int16x8_t result;\n-  __asm__ (\"ld1 {%0.8h}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const int16x8_t *_a = (int16x8_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n-vld1q_s32 (const int32_t * a)\n-{\n-  int32x4_t result;\n-  __asm__ (\"ld1 {%0.4s}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const int32x4_t *_a = (int32x4_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n-vld1q_s64 (const int64_t * a)\n-{\n-  int64x2_t result;\n-  __asm__ (\"ld1 {%0.2d}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const int64x2_t *_a = (int64x2_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n-vld1q_u8 (const uint8_t * a)\n-{\n-  uint8x16_t result;\n-  __asm__ (\"ld1 {%0.16b}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const uint8x16_t *_a = (uint8x16_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n-vld1q_u16 (const uint16_t * a)\n-{\n-  uint16x8_t result;\n-  __asm__ (\"ld1 {%0.8h}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const uint16x8_t *_a = (uint16x8_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n-vld1q_u32 (const uint32_t * a)\n-{\n-  uint32x4_t result;\n-  __asm__ (\"ld1 {%0.4s}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const uint32x4_t *_a = (uint32x4_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n-vld1q_u64 (const uint64_t * a)\n-{\n-  uint64x2_t result;\n-  __asm__ (\"ld1 {%0.2d}, %1\"\n-\t   : \"=w\"(result)\n-\t   : \"Utv\"(({const uint64x2_t *_a = (uint64x2_t *) a; *_a;}))\n-\t   : /* No clobbers */);\n-  return result;\n-}\n-\n #define vmla_lane_f32(a, b, c, d)                                       \\\n   __extension__                                                         \\\n     ({                                                                  \\\n@@ -14382,24 +14118,6 @@ vrsubhn_u64 (uint64x2_t a, uint64x2_t b)\n        result;                                                          \\\n      })\n \n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_f32 (float32_t * a, float32x2_t b)\n-{\n-  __asm__ (\"st1 {%1.2s},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_f64 (float64_t * a, float64x1_t b)\n-{\n-  __asm__ (\"st1 {%1.1d},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n #define vst1_lane_f32(a, b, c)                                          \\\n   __extension__                                                         \\\n     ({                                                                  \\\n@@ -14532,113 +14250,6 @@ vst1_f64 (float64_t * a, float64x1_t b)\n                 : \"memory\");                                            \\\n      })\n \n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_p8 (poly8_t * a, poly8x8_t b)\n-{\n-  __asm__ (\"st1 {%1.8b},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_p16 (poly16_t * a, poly16x4_t b)\n-{\n-  __asm__ (\"st1 {%1.4h},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_s8 (int8_t * a, int8x8_t b)\n-{\n-  __asm__ (\"st1 {%1.8b},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_s16 (int16_t * a, int16x4_t b)\n-{\n-  __asm__ (\"st1 {%1.4h},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_s32 (int32_t * a, int32x2_t b)\n-{\n-  __asm__ (\"st1 {%1.2s},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_s64 (int64_t * a, int64x1_t b)\n-{\n-  __asm__ (\"st1 {%1.1d},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_u8 (uint8_t * a, uint8x8_t b)\n-{\n-  __asm__ (\"st1 {%1.8b},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_u16 (uint16_t * a, uint16x4_t b)\n-{\n-  __asm__ (\"st1 {%1.4h},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_u32 (uint32_t * a, uint32x2_t b)\n-{\n-  __asm__ (\"st1 {%1.2s},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1_u64 (uint64_t * a, uint64x1_t b)\n-{\n-  __asm__ (\"st1 {%1.1d},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_f32 (float32_t * a, float32x4_t b)\n-{\n-  __asm__ (\"st1 {%1.4s},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_f64 (float64_t * a, float64x2_t b)\n-{\n-  __asm__ (\"st1 {%1.2d},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n \n #define vst1q_lane_f32(a, b, c)                                         \\\n   __extension__                                                         \\\n@@ -14772,96 +14383,6 @@ vst1q_f64 (float64_t * a, float64x2_t b)\n                 : \"memory\");                                            \\\n      })\n \n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_p8 (poly8_t * a, poly8x16_t b)\n-{\n-  __asm__ (\"st1 {%1.16b},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_p16 (poly16_t * a, poly16x8_t b)\n-{\n-  __asm__ (\"st1 {%1.8h},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_s8 (int8_t * a, int8x16_t b)\n-{\n-  __asm__ (\"st1 {%1.16b},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_s16 (int16_t * a, int16x8_t b)\n-{\n-  __asm__ (\"st1 {%1.8h},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_s32 (int32_t * a, int32x4_t b)\n-{\n-  __asm__ (\"st1 {%1.4s},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_s64 (int64_t * a, int64x2_t b)\n-{\n-  __asm__ (\"st1 {%1.2d},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_u8 (uint8_t * a, uint8x16_t b)\n-{\n-  __asm__ (\"st1 {%1.16b},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_u16 (uint16_t * a, uint16x8_t b)\n-{\n-  __asm__ (\"st1 {%1.8h},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_u32 (uint32_t * a, uint32x4_t b)\n-{\n-  __asm__ (\"st1 {%1.4s},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n-__extension__ static __inline void __attribute__ ((__always_inline__))\n-vst1q_u64 (uint64_t * a, uint64x2_t b)\n-{\n-  __asm__ (\"st1 {%1.2d},[%0]\"\n-           :\n-           : \"r\"(a), \"w\"(b)\n-           : \"memory\");\n-}\n-\n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vsubhn_high_s16 (int8x8_t a, int16x8_t b, int16x8_t c)\n {\n@@ -20279,6 +19800,165 @@ vdupd_lane_u64 (uint64x2_t a, int const b)\n   return (uint64x1_t) __builtin_aarch64_dup_lane_scalarv2di ((int64x2_t) a, b);\n }\n \n+/* vld1 */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vld1_f32 (const float32_t *a)\n+{\n+  return __builtin_aarch64_ld1v2sf ((const __builtin_aarch64_simd_sf *) a);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vld1_f64 (const float64_t *a)\n+{\n+  return *a;\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vld1_p8 (const poly8_t *a)\n+{\n+  return (poly8x8_t)\n+    __builtin_aarch64_ld1v8qi ((const __builtin_aarch64_simd_qi *) a);\n+}\n+\n+__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n+vld1_p16 (const poly16_t *a)\n+{\n+  return (poly16x4_t)\n+    __builtin_aarch64_ld1v4hi ((const __builtin_aarch64_simd_hi *) a);\n+}\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vld1_s8 (const int8_t *a)\n+{\n+  return __builtin_aarch64_ld1v8qi ((const __builtin_aarch64_simd_qi *) a);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vld1_s16 (const int16_t *a)\n+{\n+  return __builtin_aarch64_ld1v4hi ((const __builtin_aarch64_simd_hi *) a);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vld1_s32 (const int32_t *a)\n+{\n+  return __builtin_aarch64_ld1v2si ((const __builtin_aarch64_simd_si *) a);\n+}\n+\n+__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n+vld1_s64 (const int64_t *a)\n+{\n+  return *a;\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vld1_u8 (const uint8_t *a)\n+{\n+  return (uint8x8_t)\n+    __builtin_aarch64_ld1v8qi ((const __builtin_aarch64_simd_qi *) a);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vld1_u16 (const uint16_t *a)\n+{\n+  return (uint16x4_t)\n+    __builtin_aarch64_ld1v4hi ((const __builtin_aarch64_simd_hi *) a);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vld1_u32 (const uint32_t *a)\n+{\n+  return (uint32x2_t)\n+    __builtin_aarch64_ld1v2si ((const __builtin_aarch64_simd_si *) a);\n+}\n+\n+__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n+vld1_u64 (const uint64_t *a)\n+{\n+  return *a;\n+}\n+\n+/* vld1q */\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vld1q_f32 (const float32_t *a)\n+{\n+  return __builtin_aarch64_ld1v4sf ((const __builtin_aarch64_simd_sf *) a);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vld1q_f64 (const float64_t *a)\n+{\n+  return __builtin_aarch64_ld1v2df ((const __builtin_aarch64_simd_df *) a);\n+}\n+\n+__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n+vld1q_p8 (const poly8_t *a)\n+{\n+  return (poly8x16_t)\n+    __builtin_aarch64_ld1v16qi ((const __builtin_aarch64_simd_qi *) a);\n+}\n+\n+__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n+vld1q_p16 (const poly16_t *a)\n+{\n+  return (poly16x8_t)\n+    __builtin_aarch64_ld1v8hi ((const __builtin_aarch64_simd_hi *) a);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vld1q_s8 (const int8_t *a)\n+{\n+  return __builtin_aarch64_ld1v16qi ((const __builtin_aarch64_simd_qi *) a);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vld1q_s16 (const int16_t *a)\n+{\n+  return __builtin_aarch64_ld1v8hi ((const __builtin_aarch64_simd_hi *) a);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vld1q_s32 (const int32_t *a)\n+{\n+  return __builtin_aarch64_ld1v4si ((const __builtin_aarch64_simd_si *) a);\n+}\n+\n+__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n+vld1q_s64 (const int64_t *a)\n+{\n+  return __builtin_aarch64_ld1v2di ((const __builtin_aarch64_simd_di *) a);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vld1q_u8 (const uint8_t *a)\n+{\n+  return (uint8x16_t)\n+    __builtin_aarch64_ld1v16qi ((const __builtin_aarch64_simd_qi *) a);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vld1q_u16 (const uint16_t *a)\n+{\n+  return (uint16x8_t)\n+    __builtin_aarch64_ld1v8hi ((const __builtin_aarch64_simd_hi *) a);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vld1q_u32 (const uint32_t *a)\n+{\n+  return (uint32x4_t)\n+    __builtin_aarch64_ld1v4si ((const __builtin_aarch64_simd_si *) a);\n+}\n+\n+__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n+vld1q_u64 (const uint64_t *a)\n+{\n+  return (uint64x2_t)\n+    __builtin_aarch64_ld1v2di ((const __builtin_aarch64_simd_di *) a);\n+}\n+\n /* vldn */\n \n __extension__ static __inline int64x1x2_t __attribute__ ((__always_inline__))\n@@ -24542,6 +24222,165 @@ vsrid_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n   return (uint64x1_t) __builtin_aarch64_usri_ndi (__a, __b, __c);\n }\n \n+/* vst1 */\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_f32 (float32_t *a, float32x2_t b)\n+{\n+  __builtin_aarch64_st1v2sf ((__builtin_aarch64_simd_sf *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_f64 (float64_t *a, float64x1_t b)\n+{\n+  *a = b;\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_p8 (poly8_t *a, poly8x8_t b)\n+{\n+  __builtin_aarch64_st1v8qi ((__builtin_aarch64_simd_qi *) a,\n+\t\t\t     (int8x8_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_p16 (poly16_t *a, poly16x4_t b)\n+{\n+  __builtin_aarch64_st1v4hi ((__builtin_aarch64_simd_hi *) a,\n+\t\t\t     (int16x4_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_s8 (int8_t *a, int8x8_t b)\n+{\n+  __builtin_aarch64_st1v8qi ((__builtin_aarch64_simd_qi *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_s16 (int16_t *a, int16x4_t b)\n+{\n+  __builtin_aarch64_st1v4hi ((__builtin_aarch64_simd_hi *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_s32 (int32_t *a, int32x2_t b)\n+{\n+  __builtin_aarch64_st1v2si ((__builtin_aarch64_simd_si *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_s64 (int64_t *a, int64x1_t b)\n+{\n+  *a = b;\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_u8 (uint8_t *a, uint8x8_t b)\n+{\n+  __builtin_aarch64_st1v8qi ((__builtin_aarch64_simd_qi *) a,\n+\t\t\t     (int8x8_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_u16 (uint16_t *a, uint16x4_t b)\n+{\n+  __builtin_aarch64_st1v4hi ((__builtin_aarch64_simd_hi *) a,\n+\t\t\t     (int16x4_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_u32 (uint32_t *a, uint32x2_t b)\n+{\n+  __builtin_aarch64_st1v2si ((__builtin_aarch64_simd_si *) a,\n+\t\t\t     (int32x2_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1_u64 (uint64_t *a, uint64x1_t b)\n+{\n+  *a = b;\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_f32 (float32_t *a, float32x4_t b)\n+{\n+  __builtin_aarch64_st1v4sf ((__builtin_aarch64_simd_sf *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_f64 (float64_t *a, float64x2_t b)\n+{\n+  __builtin_aarch64_st1v2df ((__builtin_aarch64_simd_df *) a, b);\n+}\n+\n+/* vst1q */\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_p8 (poly8_t *a, poly8x16_t b)\n+{\n+  __builtin_aarch64_st1v16qi ((__builtin_aarch64_simd_qi *) a,\n+\t\t\t      (int8x16_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_p16 (poly16_t *a, poly16x8_t b)\n+{\n+  __builtin_aarch64_st1v8hi ((__builtin_aarch64_simd_hi *) a,\n+\t\t\t     (int16x8_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_s8 (int8_t *a, int8x16_t b)\n+{\n+  __builtin_aarch64_st1v16qi ((__builtin_aarch64_simd_qi *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_s16 (int16_t *a, int16x8_t b)\n+{\n+  __builtin_aarch64_st1v8hi ((__builtin_aarch64_simd_hi *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_s32 (int32_t *a, int32x4_t b)\n+{\n+  __builtin_aarch64_st1v4si ((__builtin_aarch64_simd_si *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_s64 (int64_t *a, int64x2_t b)\n+{\n+  __builtin_aarch64_st1v2di ((__builtin_aarch64_simd_di *) a, b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_u8 (uint8_t *a, uint8x16_t b)\n+{\n+  __builtin_aarch64_st1v16qi ((__builtin_aarch64_simd_qi *) a,\n+\t\t\t      (int8x16_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_u16 (uint16_t *a, uint16x8_t b)\n+{\n+  __builtin_aarch64_st1v8hi ((__builtin_aarch64_simd_hi *) a,\n+\t\t\t     (int16x8_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_u32 (uint32_t *a, uint32x4_t b)\n+{\n+  __builtin_aarch64_st1v4si ((__builtin_aarch64_simd_si *) a,\n+\t\t\t     (int32x4_t) b);\n+}\n+\n+__extension__ static __inline void __attribute__ ((__always_inline__))\n+vst1q_u64 (uint64_t *a, uint64x2_t b)\n+{\n+  __builtin_aarch64_st1v2di ((__builtin_aarch64_simd_di *) a,\n+\t\t\t     (int64x2_t) b);\n+}\n+\n /* vstn */\n \n __extension__ static __inline void"}]}