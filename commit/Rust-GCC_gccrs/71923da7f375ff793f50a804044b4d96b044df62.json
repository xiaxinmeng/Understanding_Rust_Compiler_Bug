{"sha": "71923da7f375ff793f50a804044b4d96b044df62", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzE5MjNkYTdmMzc1ZmY3OTNmNTBhODA0MDQ0YjRkOTZiMDQ0ZGY2Mg==", "commit": {"author": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1994-05-06T16:42:40Z"}, "committer": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1994-05-06T16:42:40Z"}, "message": "(simplify_rtx, case MULT): Don't convert MULT to shift here.\n\n(simplify_logical, case IOR): Convert back to PLUS if valid and it will\ncombine with another PLUS.\n(extract_left_shift): New function.\n(make_compound_operation, case ASHIFTRT): Simplify by calling it.\n(force_to_mode): Don't ignore if X is a SUBREG.\n(force_to_mode, case AND): Try to turn unchecked bits on instead of just off\nand see which is cheaper.\n\nFrom-SVN: r7224", "tree": {"sha": "79d32d4f97146aa27d19089711afa2c187751ada", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/79d32d4f97146aa27d19089711afa2c187751ada"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/71923da7f375ff793f50a804044b4d96b044df62", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/71923da7f375ff793f50a804044b4d96b044df62", "html_url": "https://github.com/Rust-GCC/gccrs/commit/71923da7f375ff793f50a804044b4d96b044df62", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/71923da7f375ff793f50a804044b4d96b044df62/comments", "author": null, "committer": null, "parents": [{"sha": "490415571b66d0ab2e97c207f7f5842904c784ae", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/490415571b66d0ab2e97c207f7f5842904c784ae", "html_url": "https://github.com/Rust-GCC/gccrs/commit/490415571b66d0ab2e97c207f7f5842904c784ae"}], "stats": {"total": 214, "additions": 123, "deletions": 91}, "files": [{"sha": "9f9133111314af3bb1c50832d93027b05b4a06d1", "filename": "gcc/combine.c", "status": "modified", "additions": 123, "deletions": 91, "changes": 214, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71923da7f375ff793f50a804044b4d96b044df62/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71923da7f375ff793f50a804044b4d96b044df62/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=71923da7f375ff793f50a804044b4d96b044df62", "patch": "@@ -399,6 +399,7 @@ static rtx expand_compound_operation  PROTO((rtx));\n static rtx expand_field_assignment  PROTO((rtx));\n static rtx make_extraction\tPROTO((enum machine_mode, rtx, int, rtx, int,\n \t\t\t\t       int, int, int));\n+static rtx extract_left_shift\tPROTO((rtx, int));\n static rtx make_compound_operation  PROTO((rtx, enum rtx_code));\n static int get_pos_from_mask\tPROTO((unsigned HOST_WIDE_INT, int *));\n static rtx force_to_mode\tPROTO((rtx, enum machine_mode,\n@@ -3620,24 +3621,6 @@ simplify_rtx (x, op0_mode, last, in_dest)\n \t  if (GET_CODE (x) != MULT)\n \t    return x;\n \t}\n-\n-      /* If this is multiplication by a power of two and its first operand is\n-\t a shift, treat the multiply as a shift to allow the shifts to\n-\t possibly combine.  */\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && (i = exact_log2 (INTVAL (XEXP (x, 1)))) >= 0\n-\t  && (GET_CODE (XEXP (x, 0)) == ASHIFT\n-\t      || GET_CODE (XEXP (x, 0)) == LSHIFTRT\n-\t      || GET_CODE (XEXP (x, 0)) == ASHIFTRT\n-\t      || GET_CODE (XEXP (x, 0)) == ROTATE\n-\t      || GET_CODE (XEXP (x, 0)) == ROTATERT))\n-\treturn simplify_shift_const (NULL_RTX, ASHIFT, mode, XEXP (x, 0), i);\n-\n-      /* Convert (mult (ashift (const_int 1) A) B) to (ashift B A).  */\n-      if (GET_CODE (XEXP (x, 0)) == ASHIFT\n-\t  && XEXP (XEXP (x, 0), 0) == const1_rtx)\n-\treturn gen_rtx_combine (ASHIFT, mode, XEXP (x, 1),\n-\t\t\t\tXEXP (XEXP (x, 0), 1));\n       break;\n \n     case UDIV:\n@@ -4613,6 +4596,28 @@ simplify_logical (x, last)\n \t\t\t(GET_CODE (op0) == ASHIFT\n \t\t\t ? XEXP (op0, 1) : XEXP (op1, 1)));\n \n+      /* If OP0 is (ashiftrt (plus ...) C), it might actually be\n+\t a (sign_extend (plus ...)).  If so, OP1 is a CONST_INT, and the PLUS\n+\t does not affect any of the bits in OP1, it can really be done\n+\t as a PLUS and we can associate.  We do this by seeing if OP1\n+\t can be safely shifted left C bits.  */\n+      if (GET_CODE (op1) == CONST_INT && GET_CODE (op0) == ASHIFTRT\n+\t  && GET_CODE (XEXP (op0, 0)) == PLUS\n+\t  && GET_CODE (XEXP (XEXP (op0, 0), 1)) == CONST_INT\n+\t  && GET_CODE (XEXP (op0, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (op0, 1)) < HOST_BITS_PER_WIDE_INT)\n+\t{\n+\t  int count = INTVAL (XEXP (op0, 1));\n+\t  HOST_WIDE_INT mask = INTVAL (op1) << count;\n+\n+\t  if (mask >> count == INTVAL (op1)\n+\t      && (mask & nonzero_bits (XEXP (op0, 0), mode)) == 0)\n+\t    {\n+\t      SUBST (XEXP (XEXP (op0, 0), 1),\n+\t\t     GEN_INT (INTVAL (XEXP (XEXP (op0, 0), 1)) | mask));\n+\t      return op0;\n+\t    }\n+\t}\n       break;\n \n     case XOR:\n@@ -5251,6 +5256,51 @@ make_extraction (mode, inner, pos, pos_rtx, len,\n   return new;\n }\n \f\n+/* See if X contains an ASHIFT of COUNT or more bits that can be commuted\n+   with any other operations in X.  Return X without that shift if so.  */\n+\n+static rtx\n+extract_left_shift (x, count)\n+     rtx x;\n+     int count;\n+{\n+  enum rtx_code code = GET_CODE (x);\n+  enum machine_mode mode = GET_MODE (x);\n+  rtx tem;\n+\n+  switch (code)\n+    {\n+    case ASHIFT:\n+      /* This is the shift itself.  If it is wide enough, we will return\n+\t either the value being shifted if the shift count is equal to\n+\t COUNT or a shift for the difference.  */\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (x, 1)) >= count)\n+\treturn simplify_shift_const (NULL_RTX, ASHIFT, mode, XEXP (x, 0),\n+\t\t\t\t     INTVAL (XEXP (x, 1)) - count);\n+      break;\n+\n+    case NEG:  case NOT:\n+      if ((tem = extract_left_shift (XEXP (x, 0), count)) != 0)\n+\treturn gen_unary (code, mode, tem);\n+\n+      break;\n+\n+    case PLUS:  case IOR:  case XOR:  case AND:\n+      /* If we can safely shift this constant and we find the inner shift,\n+\t make a new operation.  */\n+      if (GET_CODE (XEXP (x,1)) == CONST_INT\n+\t  && (INTVAL (XEXP (x, 1)) & (((HOST_WIDE_INT) 1 << count)) - 1) == 0\n+\t  && (tem = extract_left_shift (XEXP (x, 0), count)) != 0)\n+\treturn gen_binary (code, mode, tem, \n+\t\t\t   GEN_INT (INTVAL (XEXP (x, 1)) >> count));\n+\n+      break;\n+    }\n+\n+  return 0;\n+}\n+\f\n /* Look at the expression rooted at X.  Look for expressions\n    equivalent to ZERO_EXTRACT, SIGN_EXTRACT, ZERO_EXTEND, SIGN_EXTEND.\n    Form these expressions.\n@@ -5277,6 +5327,7 @@ make_compound_operation (x, in_code)\n   enum rtx_code code = GET_CODE (x);\n   enum machine_mode mode = GET_MODE (x);\n   int mode_width = GET_MODE_BITSIZE (mode);\n+  rtx rhs, lhs;\n   enum rtx_code next_code;\n   int i;\n   rtx new = 0;\n@@ -5432,81 +5483,38 @@ make_compound_operation (x, in_code)\n       /* ... fall through ... */\n \n     case ASHIFTRT:\n+      lhs = XEXP (x, 0);\n+      rhs = XEXP (x, 1);\n+\n       /* If we have (ashiftrt (ashift foo C1) C2) with C2 >= C1,\n \t this is a SIGN_EXTRACT.  */\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && GET_CODE (XEXP (x, 0)) == ASHIFT\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n-\t  && INTVAL (XEXP (x, 1)) >= INTVAL (XEXP (XEXP (x, 0), 1)))\n+      if (GET_CODE (rhs) == CONST_INT\n+\t  && GET_CODE (lhs) == ASHIFT\n+\t  && GET_CODE (XEXP (lhs, 1)) == CONST_INT\n+\t  && INTVAL (rhs) >= INTVAL (XEXP (lhs, 1)))\n \t{\n-\t  new = make_compound_operation (XEXP (XEXP (x, 0), 0), next_code);\n+\t  new = make_compound_operation (XEXP (lhs, 0), next_code);\n \t  new = make_extraction (mode, new,\n-\t\t\t\t (INTVAL (XEXP (x, 1))\n-\t\t\t\t  - INTVAL (XEXP (XEXP (x, 0), 1))),\n-\t\t\t\t NULL_RTX, mode_width - INTVAL (XEXP (x, 1)),\n-\t\t\t\t code == LSHIFTRT, 0, in_code == COMPARE);\n-\t}\n-\n-      /* Similarly if we have (ashifrt (OP (ashift foo C1) C3) C2).  In these\n-\t cases, we are better off returning a SIGN_EXTEND of the operation.  */\n-\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && (GET_CODE (XEXP (x, 0)) == IOR || GET_CODE (XEXP (x, 0)) == AND\n-\t      || GET_CODE (XEXP (x, 0)) == XOR\n-\t      || GET_CODE (XEXP (x, 0)) == PLUS)\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 0)) == ASHIFT\n-\t  && GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 1)) == CONST_INT\n-\t  && INTVAL (XEXP (XEXP (XEXP (x, 0), 0), 1)) < HOST_BITS_PER_WIDE_INT\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n-\t  && 0 == (INTVAL (XEXP (XEXP (x, 0), 1))\n-\t\t   & (((HOST_WIDE_INT) 1\n-\t\t       << (MIN (INTVAL (XEXP (XEXP (XEXP (x, 0), 0), 1)),\n-\t\t\t\tINTVAL (XEXP (x, 1)))\n-\t\t\t   - 1)))))\n-\t{\n-\t  rtx c1 = XEXP (XEXP (XEXP (x, 0), 0), 1);\n-\t  rtx c2 = XEXP (x, 1);\n-\t  rtx c3 = XEXP (XEXP (x, 0), 1);\n-\t  HOST_WIDE_INT newop1;\n-\t  rtx inner = XEXP (XEXP (XEXP (x, 0), 0), 0);\n-\n-\t  /* If C1 > C2, INNER needs to have the shift performed on it\n-\t     for C1-C2 bits.  */\n-\t  if (INTVAL (c1) > INTVAL (c2))\n-\t    {\n-\t      inner = gen_binary (ASHIFT, mode, inner,\n-\t\t\t\t  GEN_INT (INTVAL (c1) - INTVAL (c2)));\n-\t      c1 = c2;\n-\t    }\n-\n-\t  newop1 = INTVAL (c3) >> INTVAL (c1);\n-\t  new = make_compound_operation (inner,\n-\t\t\t\t\t GET_CODE (XEXP (x, 0)) == PLUS\n-\t\t\t\t\t ? MEM : GET_CODE (XEXP (x, 0)));\n-\t  new = make_extraction (mode,\n-\t\t\t\t gen_binary (GET_CODE (XEXP (x, 0)), mode, new,\n-\t\t\t\t\t     GEN_INT (newop1)),\n-\t\t\t\t INTVAL (c2) - INTVAL (c1),\n-\t\t\t\t NULL_RTX, mode_width - INTVAL (c2),\n+\t\t\t\t INTVAL (rhs) - INTVAL (XEXP (lhs, 1)),\n+\t\t\t\t NULL_RTX, mode_width - INTVAL (rhs),\n \t\t\t\t code == LSHIFTRT, 0, in_code == COMPARE);\n \t}\n \n-      /* Similarly for (ashiftrt (neg (ashift FOO C1)) C2).  */\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && GET_CODE (XEXP (x, 0)) == NEG\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 0)) == ASHIFT\n-\t  && GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 1)) == CONST_INT\n-\t  && INTVAL (XEXP (x, 1)) >= INTVAL (XEXP (XEXP (XEXP (x, 0), 0), 1)))\n-\t{\n-\t  new = make_compound_operation (XEXP (XEXP (XEXP (x, 0), 0), 0),\n-\t\t\t\t\t next_code);\n-\t  new = make_extraction (mode,\n-\t\t\t\t gen_unary (GET_CODE (XEXP (x, 0)), mode, new),\n-\t\t\t\t (INTVAL (XEXP (x, 1))\n-\t\t\t\t  - INTVAL (XEXP (XEXP (XEXP (x, 0), 0), 1))),\n-\t\t\t\t NULL_RTX, mode_width - INTVAL (XEXP (x, 1)),\n-\t\t\t\t code == LSHIFTRT, 0, in_code == COMPARE);\n-\t}\n+      /* See if we have operations between an ASHIFTRT and an ASHIFT.\n+\t If so, try to merge the shifts into a SIGN_EXTEND.  We could\n+\t also do this for some cases of SIGN_EXTRACT, but it doesn't\n+\t seem worth the effort; the case checked for occurs on Alpha.  */\n+      \n+      if (GET_RTX_CLASS (GET_CODE (lhs)) != 'o'\n+\t  && ! (GET_CODE (lhs) == SUBREG\n+\t\t&& (GET_RTX_CLASS (GET_CODE (SUBREG_REG (lhs))) == 'o'))\n+\t  && GET_CODE (rhs) == CONST_INT\n+\t  && INTVAL (rhs) < HOST_BITS_PER_WIDE_INT\n+\t  && (new = extract_left_shift (lhs, INTVAL (rhs))) != 0)\n+\tnew = make_extraction (mode, make_compound_operation (new, next_code),\n+\t\t\t       0, NULL_RTX, mode_width - INTVAL (rhs),\n+\t\t\t       code == LSHIFTRT, 0, in_code == COMPARE);\n+\t\n       break;\n \n     case SUBREG:\n@@ -5662,9 +5670,9 @@ force_to_mode (x, mode, mask, reg, just_select)\n   if (GET_MODE_SIZE (GET_MODE (x)) < GET_MODE_SIZE (mode))\n     return gen_lowpart_for_combine (mode, x);\n \n-  /* If we aren't changing the mode and all zero bits in MASK are already\n-     known to be zero in X, we need not do anything.  */\n-  if (GET_MODE (x) == mode && (~ mask & nonzero) == 0)\n+  /* If we aren't changing the mode, X is not a SUBREG, and all zero bits in\n+     MASK are already known to be zero in X, we need not do anything.  */\n+  if (GET_MODE (x) == mode && code != SUBREG && (~ mask & nonzero) == 0)\n     return x;\n \n   switch (code)\n@@ -5727,13 +5735,37 @@ force_to_mode (x, mode, mask, reg, just_select)\n \t\t\t\t      mask & INTVAL (XEXP (x, 1)));\n \n \t  /* If X is still an AND, see if it is an AND with a mask that\n-\t     is just some low-order bits.  If so, and it is BITS wide (it\n-\t     can't be wider), we don't need it.  */\n+\t     is just some low-order bits.  If so, and it is MASK, we don't\n+\t     need it.  */\n \n \t  if (GET_CODE (x) == AND && GET_CODE (XEXP (x, 1)) == CONST_INT\n \t      && INTVAL (XEXP (x, 1)) == mask)\n \t    x = XEXP (x, 0);\n \n+\t  /* If it remains an AND, try making another AND with the bits\n+\t     in the mode mask that aren't in MASK turned on.  If the\n+\t     constant in the AND is wide enough, this might make a\n+\t     cheaper constant.  */\n+\n+\t  if (GET_CODE (x) == AND && GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t      && GET_MODE_MASK (GET_MODE (x)) != mask)\n+\t    {\n+\t      HOST_WIDE_INT cval = (INTVAL (XEXP (x, 1))\n+\t\t\t\t    | (GET_MODE_MASK (GET_MODE (x)) & ~ mask));\n+\t      int width = GET_MODE_BITSIZE (GET_MODE (x));\n+\t      rtx y;\n+\n+\t      /* If MODE is narrower that HOST_WIDE_INT and CVAL is a negative\n+\t\t number, sign extend it.  */\n+\t      if (width > 0 && width < HOST_BITS_PER_WIDE_INT\n+\t\t  && (cval & ((HOST_WIDE_INT) 1 << (width - 1))) != 0)\n+\t\tcval |= (HOST_WIDE_INT) -1 << width;\n+\n+\t      y = gen_binary (AND, GET_MODE (x), XEXP (x, 0), GEN_INT (cval));\n+\t      if (rtx_cost (y, SET) < rtx_cost (x, SET))\n+\t\tx = y;\n+\t    }\n+\n \t  break;\n \t}\n "}]}