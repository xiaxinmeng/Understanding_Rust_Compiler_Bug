{"sha": "d88cd9c42448f3e166a17356a7f8539541b68a25", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDg4Y2Q5YzQyNDQ4ZjNlMTY2YTE3MzU2YTdmODUzOTU0MWI2OGEyNQ==", "commit": {"author": {"name": "Nathan Sidwell", "email": "nathan@codesourcery.com", "date": "2015-10-28T14:24:39Z"}, "committer": {"name": "Nathan Sidwell", "email": "nathan@gcc.gnu.org", "date": "2015-10-28T14:24:39Z"}, "message": "nvptx.h (struct machine_function): Add axis_predicate.\n\n\t* config/nvptx/nvptx.h (struct machine_function): Add\n\taxis_predicate.\n\t* config/nvptx/nvptx-protos.h (nvptx_expand_oacc_fork,\n\tnvptx_expand_oacc_join): Declare.\n\t* config/nvptx/nvptx.md (UNSPEC_NTID, UNSPEC_TID): Delete.\n\t(UNSPEC_DIM_SIZE, UNSPEC_SHARED_DATA, UNSPEC_BIT_CONV,\n\tUNSPEC_SHUFFLE, UNSPEC_BR_UNIFIED): New.\n\t(UNSPECV_BARSYNC, UNSPECV_DIM_POS, UNSPECV_FORK, UNSPECV_FORKED,\n\tUNSPECV_JOINING, UNSPECV_JOIN): New.\n\t(BITS, BITD): New mode iterators.\n\t(br_true_uni, br_false_uni): New.\n\t(*oacc_ntid_insn, oacc_ntid, *oacc_tid_insn, oacc_tid): Delete.\n\t(oacc_dim_size, oacc_dim_pos): New.\n\t(nvptx_fork, nvptx_forked, nvptx_joining, nvptx_join): New.\n\t(oacc_fork, oacc_join): New.\n\t(nvptx_shuffle<mode>, unpack<mode>si2, packsi<mode>2): New.\n\t(worker_load<mode>, worker_store<mode>): New.\n\t(nvptx_barsync): New.\n\t* config/nvptx/nvptx.c: Include gimple.h & dumpfile.h.\n\t(SHUFFLE_UP, SHUFFLE_DOWN, SHUFFLE_BFLY, SHUFFLE_IDX): Define.\n\t(worker_bcast_hwm, worker_bcast_align, worker_bcast_name,\n\tworker_bcast_sym): New.\n\t(nvptx_option_override): Initialize worker broadcast buffer.\n\t(nvptx_emit_forking, nvptx_emit_joining): New.\n\t(nvptx_init_axis_predicate): New.\n\t(nvptx_declare_function_name): Init axis predicates.\n\t(nvptx_expand_call): Add fork/join markers around routine call.\n\t(nvptx_expand_oacc_fork, nvptx_expand_oacc_join): New.\n\t(nvptx_gen_unpack, nvptx_gen_pack, nvptx_gen_shuffle): New.\n\t(nvptx_gen_vcast): New.\n\t(struct wcast_data_t): New.\n\t(enum propagate_mask): New.\n\t(nvptx_gen_wcast): New.\n\t(nvptx_print_operand): Add 'S' case.\n\t(struct parallel): New.\n\t(parallel::parallel, parallel::~parallel): New.\n\t(bb_insn_map_t, insn_bb_t, insn_bb_vec_t): New typedefs.\n\t(nvptx_split_blocks, nvptx_discover_pre, nvptx_dump_pars,\n\tnvptx_find_par, nvptx_discover_pars): New.\n\t(nvptx_propagate): New.\n\t(vprop_gen, nvptx_vpropagate): New.\n\t(wprop_gen, nvptx_wpropagate): New.\n\t(nvptx_wsync): New.\n\t(nvptx_single, nvptx_skip_par): New.\n\t(nvptx_process_pars, nvptx_neuter_pars): New.\n\t(ntptx_reorg): Split blocks, generate parallel structure, apply\n\tneutering.\n\t(nvptx_cannot_copy_insn_p): New.\n\t(nvptx_file_end): Emit worker broadcast decl.\n\t(nvptx_goacc_fork_join): New.\n\t(TARGET_CANNOT_COPY_INSN_P): Override.\n\t(TARGET_GOACC_FORK_JOIN): Override.\n\nFrom-SVN: r229486", "tree": {"sha": "f2ef967c3b53d765605ce0256832fc68c5156568", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f2ef967c3b53d765605ce0256832fc68c5156568"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d88cd9c42448f3e166a17356a7f8539541b68a25", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d88cd9c42448f3e166a17356a7f8539541b68a25", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d88cd9c42448f3e166a17356a7f8539541b68a25", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d88cd9c42448f3e166a17356a7f8539541b68a25/comments", "author": null, "committer": null, "parents": [{"sha": "1e355e1de076db6dcc8999babd03837531e3e3f6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1e355e1de076db6dcc8999babd03837531e3e3f6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1e355e1de076db6dcc8999babd03837531e3e3f6"}], "stats": {"total": 1398, "additions": 1375, "deletions": 23}, "files": [{"sha": "ea88dfafd38186ea1959af12c66f341d92ad71e6", "filename": "gcc/ChangeLog", "status": "modified", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d88cd9c42448f3e166a17356a7f8539541b68a25", "patch": "@@ -1,3 +1,58 @@\n+2015-10-28  Nathan Sidwell  <nathan@codesourcery.com>\n+\n+\t* config/nvptx/nvptx.h (struct machine_function): Add\n+\taxis_predicate.\n+\t* config/nvptx/nvptx-protos.h (nvptx_expand_oacc_fork,\n+\tnvptx_expand_oacc_join): Declare.\n+\t* config/nvptx/nvptx.md (UNSPEC_NTID, UNSPEC_TID): Delete.\n+\t(UNSPEC_DIM_SIZE, UNSPEC_SHARED_DATA, UNSPEC_BIT_CONV,\n+\tUNSPEC_SHUFFLE, UNSPEC_BR_UNIFIED): New.\n+\t(UNSPECV_BARSYNC, UNSPECV_DIM_POS, UNSPECV_FORK, UNSPECV_FORKED,\n+\tUNSPECV_JOINING, UNSPECV_JOIN): New.\n+\t(BITS, BITD): New mode iterators.\n+\t(br_true_uni, br_false_uni): New.\n+\t(*oacc_ntid_insn, oacc_ntid, *oacc_tid_insn, oacc_tid): Delete.\n+\t(oacc_dim_size, oacc_dim_pos): New.\n+\t(nvptx_fork, nvptx_forked, nvptx_joining, nvptx_join): New.\n+\t(oacc_fork, oacc_join): New.\n+\t(nvptx_shuffle<mode>, unpack<mode>si2, packsi<mode>2): New.\n+\t(worker_load<mode>, worker_store<mode>): New.\n+\t(nvptx_barsync): New.\n+\t* config/nvptx/nvptx.c: Include gimple.h & dumpfile.h.\n+\t(SHUFFLE_UP, SHUFFLE_DOWN, SHUFFLE_BFLY, SHUFFLE_IDX): Define.\n+\t(worker_bcast_hwm, worker_bcast_align, worker_bcast_name,\n+\tworker_bcast_sym): New.\n+\t(nvptx_option_override): Initialize worker broadcast buffer.\n+\t(nvptx_emit_forking, nvptx_emit_joining): New.\n+\t(nvptx_init_axis_predicate): New.\n+\t(nvptx_declare_function_name): Init axis predicates.\n+\t(nvptx_expand_call): Add fork/join markers around routine call.\n+\t(nvptx_expand_oacc_fork, nvptx_expand_oacc_join): New.\n+\t(nvptx_gen_unpack, nvptx_gen_pack, nvptx_gen_shuffle): New.\n+\t(nvptx_gen_vcast): New.\n+\t(struct wcast_data_t): New.\n+\t(enum propagate_mask): New.\n+\t(nvptx_gen_wcast): New.\n+\t(nvptx_print_operand): Add 'S' case.\n+\t(struct parallel): New.\n+\t(parallel::parallel, parallel::~parallel): New.\n+\t(bb_insn_map_t, insn_bb_t, insn_bb_vec_t): New typedefs.\n+\t(nvptx_split_blocks, nvptx_discover_pre, nvptx_dump_pars,\n+\tnvptx_find_par, nvptx_discover_pars): New.\n+\t(nvptx_propagate): New.\n+\t(vprop_gen, nvptx_vpropagate): New.\n+\t(wprop_gen, nvptx_wpropagate): New.\n+\t(nvptx_wsync): New.\n+\t(nvptx_single, nvptx_skip_par): New.\n+\t(nvptx_process_pars, nvptx_neuter_pars): New.\n+\t(ntptx_reorg): Split blocks, generate parallel structure, apply\n+\tneutering.\n+\t(nvptx_cannot_copy_insn_p): New.\n+\t(nvptx_file_end): Emit worker broadcast decl.\n+\t(nvptx_goacc_fork_join): New.\n+\t(TARGET_CANNOT_COPY_INSN_P): Override.\n+\t(TARGET_GOACC_FORK_JOIN): Override.\n+\n 2015-10-28  Richard Biener  <rguenther@suse.de>\n \n \t* fold-const.c (negate_expr_p): Adjust the division case to"}, {"sha": "e5355289b6ed351c61a7d7381307044c57fcccd9", "filename": "gcc/config/nvptx/nvptx-protos.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnvptx%2Fnvptx-protos.h?ref=d88cd9c42448f3e166a17356a7f8539541b68a25", "patch": "@@ -32,6 +32,8 @@ extern void nvptx_register_pragmas (void);\n extern const char *nvptx_section_for_decl (const_tree);\n \n #ifdef RTX_CODE\n+extern void nvptx_expand_oacc_fork (unsigned);\n+extern void nvptx_expand_oacc_join (unsigned);\n extern void nvptx_expand_call (rtx, rtx);\n extern rtx nvptx_expand_compare (rtx);\n extern const char *nvptx_ptx_type_from_mode (machine_mode, bool);"}, {"sha": "d2f4dbfba2adf8dcc724ed01649324852f3de482", "filename": "gcc/config/nvptx/nvptx.c", "status": "modified", "additions": 1162, "deletions": 4, "changes": 1166, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnvptx%2Fnvptx.c?ref=d88cd9c42448f3e166a17356a7f8539541b68a25", "patch": "@@ -51,14 +51,21 @@\n #include \"langhooks.h\"\n #include \"dbxout.h\"\n #include \"cfgrtl.h\"\n+#include \"gimple.h\"\n #include \"stor-layout.h\"\n #include \"builtins.h\"\n #include \"omp-low.h\"\n #include \"gomp-constants.h\"\n+#include \"dumpfile.h\"\n \n /* This file should be included last.  */\n #include \"target-def.h\"\n \n+#define SHUFFLE_UP 0\n+#define SHUFFLE_DOWN 1\n+#define SHUFFLE_BFLY 2\n+#define SHUFFLE_IDX 3\n+\n /* Record the function decls we've written, and the libfuncs and function\n    decls corresponding to them.  */\n static std::stringstream func_decls;\n@@ -81,6 +88,16 @@ struct tree_hasher : ggc_cache_ptr_hash<tree_node>\n static GTY((cache)) hash_table<tree_hasher> *declared_fndecls_htab;\n static GTY((cache)) hash_table<tree_hasher> *needed_fndecls_htab;\n \n+/* Size of buffer needed to broadcast across workers.  This is used\n+   for both worker-neutering and worker broadcasting.   It is shared\n+   by all functions emitted.  The buffer is placed in shared memory.\n+   It'd be nice if PTX supported common blocks, because then this\n+   could be shared across TUs (taking the largest size).  */\n+static unsigned worker_bcast_size;\n+static unsigned worker_bcast_align;\n+#define worker_bcast_name \"__worker_bcast\"\n+static GTY(()) rtx worker_bcast_sym;\n+\n /* Allocate a new, cleared machine_function structure.  */\n \n static struct machine_function *\n@@ -108,6 +125,9 @@ nvptx_option_override (void)\n   needed_fndecls_htab = hash_table<tree_hasher>::create_ggc (17);\n   declared_libfuncs_htab\n     = hash_table<declared_libfunc_hasher>::create_ggc (17);\n+\n+  worker_bcast_sym = gen_rtx_SYMBOL_REF (Pmode, worker_bcast_name);\n+  worker_bcast_align = GET_MODE_ALIGNMENT (SImode) / BITS_PER_UNIT;\n }\n \n /* Return the mode to be used when declaring a ptx object for OBJ.\n@@ -194,6 +214,47 @@ nvptx_split_reg_p (machine_mode mode)\n   return false;\n }\n \n+/* Emit forking instructions for MASK.  */\n+\n+static void\n+nvptx_emit_forking (unsigned mask, bool is_call)\n+{\n+  mask &= (GOMP_DIM_MASK (GOMP_DIM_WORKER)\n+\t   | GOMP_DIM_MASK (GOMP_DIM_VECTOR));\n+  if (mask)\n+    {\n+      rtx op = GEN_INT (mask | (is_call << GOMP_DIM_MAX));\n+      \n+      /* Emit fork at all levels.  This helps form SESE regions, as\n+\t it creates a block with a single successor before entering a\n+\t partitooned region.  That is a good candidate for the end of\n+\t an SESE region.  */\n+      if (!is_call)\n+\temit_insn (gen_nvptx_fork (op));\n+      emit_insn (gen_nvptx_forked (op));\n+    }\n+}\n+\n+/* Emit joining instructions for MASK.  */\n+\n+static void\n+nvptx_emit_joining (unsigned mask, bool is_call)\n+{\n+  mask &= (GOMP_DIM_MASK (GOMP_DIM_WORKER)\n+\t   | GOMP_DIM_MASK (GOMP_DIM_VECTOR));\n+  if (mask)\n+    {\n+      rtx op = GEN_INT (mask | (is_call << GOMP_DIM_MAX));\n+\n+      /* Emit joining for all non-call pars to ensure there's a single\n+\t predecessor for the block the join insn ends up in.  This is\n+\t needed for skipping entire loops.  */\n+      if (!is_call)\n+\temit_insn (gen_nvptx_joining (op));\n+      emit_insn (gen_nvptx_join (op));\n+    }\n+}\n+\n #define PASS_IN_REG_P(MODE, TYPE)\t\t\t\t\\\n   ((GET_MODE_CLASS (MODE) == MODE_INT\t\t\t\t\\\n     || GET_MODE_CLASS (MODE) == MODE_FLOAT\t\t\t\\\n@@ -500,6 +561,19 @@ nvptx_record_needed_fndecl (tree decl)\n     *slot = decl;\n }\n \n+/* Emit code to initialize the REGNO predicate register to indicate\n+   whether we are not lane zero on the NAME axis.  */\n+\n+static void\n+nvptx_init_axis_predicate (FILE *file, int regno, const char *name)\n+{\n+  fprintf (file, \"\\t{\\n\");\n+  fprintf (file, \"\\t\\t.reg.u32\\t%%%s;\\n\", name);\n+  fprintf (file, \"\\t\\tmov.u32\\t%%%s, %%tid.%s;\\n\", name, name);\n+  fprintf (file, \"\\t\\tsetp.ne.u32\\t%%r%d, %%%s, 0;\\n\", regno, name);\n+  fprintf (file, \"\\t}\\n\");\n+}\n+\n /* Implement ASM_DECLARE_FUNCTION_NAME.  Writes the start of a ptx\n    function, including local var decls and copies from the arguments to\n    local regs.  */\n@@ -623,6 +697,14 @@ nvptx_declare_function_name (FILE *file, const char *name, const_tree decl)\n   if (stdarg_p (fntype))\n     fprintf (file, \"\\tld.param.u%d %%argp, [%%in_argp];\\n\",\n \t     GET_MODE_BITSIZE (Pmode));\n+\n+  /* Emit axis predicates. */\n+  if (cfun->machine->axis_predicate[0])\n+    nvptx_init_axis_predicate (file,\n+\t\t\t       REGNO (cfun->machine->axis_predicate[0]), \"y\");\n+  if (cfun->machine->axis_predicate[1])\n+    nvptx_init_axis_predicate (file,\n+\t\t\t       REGNO (cfun->machine->axis_predicate[1]), \"x\");\n }\n \n /* Output a return instruction.  Also copy the return value to its outgoing\n@@ -779,6 +861,7 @@ nvptx_expand_call (rtx retval, rtx address)\n   bool external_decl = false;\n   rtx varargs = NULL_RTX;\n   tree decl_type = NULL_TREE;\n+  unsigned parallel = 0;\n \n   for (t = cfun->machine->call_args; t; t = XEXP (t, 1))\n     nargs++;\n@@ -799,6 +882,22 @@ nvptx_expand_call (rtx retval, rtx address)\n \t    cfun->machine->has_call_with_sc = true;\n \t  if (DECL_EXTERNAL (decl))\n \t    external_decl = true;\n+\t  tree attr = get_oacc_fn_attrib (decl);\n+\t  if (attr)\n+\t    {\n+\t      tree dims = TREE_VALUE (attr);\n+\n+\t      parallel = GOMP_DIM_MASK (GOMP_DIM_MAX) - 1;\n+\t      for (int ix = 0; ix != GOMP_DIM_MAX; ix++)\n+\t\t{\n+\t\t  if (TREE_PURPOSE (dims)\n+\t\t      && !integer_zerop (TREE_PURPOSE (dims)))\n+\t\t    break;\n+\t\t  /* Not on this axis.  */\n+\t\t  parallel ^= GOMP_DIM_MASK (ix);\n+\t\t  dims = TREE_CHAIN (dims);\n+\t\t}\n+\t    }\n \t}\n     }\n \n@@ -860,7 +959,11 @@ nvptx_expand_call (rtx retval, rtx address)\n \t  write_func_decl_from_insn (func_decls, retval, pat, callee);\n \t}\n     }\n+\n+  nvptx_emit_forking (parallel, true);\n   emit_call_insn (pat);\n+  nvptx_emit_joining (parallel, true);\n+\n   if (tmp_retval != retval)\n     emit_move_insn (retval, tmp_retval);\n }\n@@ -1069,6 +1172,214 @@ nvptx_expand_compare (rtx compare)\n   return gen_rtx_NE (BImode, pred, const0_rtx);\n }\n \n+/* Expand the oacc fork & join primitive into ptx-required unspecs.  */\n+\n+void\n+nvptx_expand_oacc_fork (unsigned mode)\n+{\n+  nvptx_emit_forking (GOMP_DIM_MASK (mode), false);\n+}\n+\n+void\n+nvptx_expand_oacc_join (unsigned mode)\n+{\n+  nvptx_emit_joining (GOMP_DIM_MASK (mode), false);\n+}\n+\n+/* Generate instruction(s) to unpack a 64 bit object into 2 32 bit\n+   objects.  */\n+\n+static rtx\n+nvptx_gen_unpack (rtx dst0, rtx dst1, rtx src)\n+{\n+  rtx res;\n+  \n+  switch (GET_MODE (src))\n+    {\n+    case DImode:\n+      res = gen_unpackdisi2 (dst0, dst1, src);\n+      break;\n+    case DFmode:\n+      res = gen_unpackdfsi2 (dst0, dst1, src);\n+      break;\n+    default: gcc_unreachable ();\n+    }\n+  return res;\n+}\n+\n+/* Generate instruction(s) to pack 2 32 bit objects into a 64 bit\n+   object.  */\n+\n+static rtx\n+nvptx_gen_pack (rtx dst, rtx src0, rtx src1)\n+{\n+  rtx res;\n+  \n+  switch (GET_MODE (dst))\n+    {\n+    case DImode:\n+      res = gen_packsidi2 (dst, src0, src1);\n+      break;\n+    case DFmode:\n+      res = gen_packsidf2 (dst, src0, src1);\n+      break;\n+    default: gcc_unreachable ();\n+    }\n+  return res;\n+}\n+\n+/* Generate an instruction or sequence to broadcast register REG\n+   across the vectors of a single warp.  */\n+\n+static rtx\n+nvptx_gen_shuffle (rtx dst, rtx src, rtx idx, unsigned kind)\n+{\n+  rtx res;\n+\n+  switch (GET_MODE (dst))\n+    {\n+    case SImode:\n+      res = gen_nvptx_shufflesi (dst, src, idx, GEN_INT (kind));\n+      break;\n+    case SFmode:\n+      res = gen_nvptx_shufflesf (dst, src, idx, GEN_INT (kind));\n+      break;\n+    case DImode:\n+    case DFmode:\n+      {\n+\trtx tmp0 = gen_reg_rtx (SImode);\n+\trtx tmp1 = gen_reg_rtx (SImode);\n+\n+\tstart_sequence ();\n+\temit_insn (nvptx_gen_unpack (tmp0, tmp1, src));\n+\temit_insn (nvptx_gen_shuffle (tmp0, tmp0, idx, kind));\n+\temit_insn (nvptx_gen_shuffle (tmp1, tmp1, idx, kind));\n+\temit_insn (nvptx_gen_pack (dst, tmp0, tmp1));\n+\tres = get_insns ();\n+\tend_sequence ();\n+      }\n+      break;\n+    case BImode:\n+      {\n+\trtx tmp = gen_reg_rtx (SImode);\n+\t\n+\tstart_sequence ();\n+\temit_insn (gen_sel_truesi (tmp, src, GEN_INT (1), const0_rtx));\n+\temit_insn (nvptx_gen_shuffle (tmp, tmp, idx, kind));\n+\temit_insn (gen_rtx_SET (dst, gen_rtx_NE (BImode, tmp, const0_rtx)));\n+\tres = get_insns ();\n+\tend_sequence ();\n+      }\n+      break;\n+      \n+    default:\n+      gcc_unreachable ();\n+    }\n+  return res;\n+}\n+\n+/* Generate an instruction or sequence to broadcast register REG\n+   across the vectors of a single warp.  */\n+\n+static rtx\n+nvptx_gen_vcast (rtx reg)\n+{\n+  return nvptx_gen_shuffle (reg, reg, const0_rtx, SHUFFLE_IDX);\n+}\n+\n+/* Structure used when generating a worker-level spill or fill.  */\n+\n+struct wcast_data_t\n+{\n+  rtx base;  /* Register holding base addr of buffer.  */\n+  rtx ptr;  /* Iteration var,  if needed.  */\n+  unsigned offset; /* Offset into worker buffer.  */\n+};\n+\n+/* Direction of the spill/fill and looping setup/teardown indicator.  */\n+\n+enum propagate_mask\n+  {\n+    PM_read = 1 << 0,\n+    PM_write = 1 << 1,\n+    PM_loop_begin = 1 << 2,\n+    PM_loop_end = 1 << 3,\n+\n+    PM_read_write = PM_read | PM_write\n+  };\n+\n+/* Generate instruction(s) to spill or fill register REG to/from the\n+   worker broadcast array.  PM indicates what is to be done, REP\n+   how many loop iterations will be executed (0 for not a loop).  */\n+   \n+static rtx\n+nvptx_gen_wcast (rtx reg, propagate_mask pm, unsigned rep, wcast_data_t *data)\n+{\n+  rtx  res;\n+  machine_mode mode = GET_MODE (reg);\n+\n+  switch (mode)\n+    {\n+    case BImode:\n+      {\n+\trtx tmp = gen_reg_rtx (SImode);\n+\t\n+\tstart_sequence ();\n+\tif (pm & PM_read)\n+\t  emit_insn (gen_sel_truesi (tmp, reg, GEN_INT (1), const0_rtx));\n+\temit_insn (nvptx_gen_wcast (tmp, pm, rep, data));\n+\tif (pm & PM_write)\n+\t  emit_insn (gen_rtx_SET (reg, gen_rtx_NE (BImode, tmp, const0_rtx)));\n+\tres = get_insns ();\n+\tend_sequence ();\n+      }\n+      break;\n+\n+    default:\n+      {\n+\trtx addr = data->ptr;\n+\n+\tif (!addr)\n+\t  {\n+\t    unsigned align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;\n+\n+\t    if (align > worker_bcast_align)\n+\t      worker_bcast_align = align;\n+\t    data->offset = (data->offset + align - 1) & ~(align - 1);\n+\t    addr = data->base;\n+\t    if (data->offset)\n+\t      addr = gen_rtx_PLUS (Pmode, addr, GEN_INT (data->offset));\n+\t  }\n+\t\n+\taddr = gen_rtx_MEM (mode, addr);\n+\taddr = gen_rtx_UNSPEC (mode, gen_rtvec (1, addr), UNSPEC_SHARED_DATA);\n+\tif (pm == PM_read)\n+\t  res = gen_rtx_SET (addr, reg);\n+\telse if (pm == PM_write)\n+\t  res = gen_rtx_SET (reg, addr);\n+\telse\n+\t  gcc_unreachable ();\n+\n+\tif (data->ptr)\n+\t  {\n+\t    /* We're using a ptr, increment it.  */\n+\t    start_sequence ();\n+\t    \n+\t    emit_insn (res);\n+\t    emit_insn (gen_adddi3 (data->ptr, data->ptr,\n+\t\t\t\t   GEN_INT (GET_MODE_SIZE (GET_MODE (reg)))));\n+\t    res = get_insns ();\n+\t    end_sequence ();\n+\t  }\n+\telse\n+\t  rep = 1;\n+\tdata->offset += rep * GET_MODE_SIZE (GET_MODE (reg));\n+      }\n+      break;\n+    }\n+  return res;\n+}\n+\n /* When loading an operand ORIG_OP, verify whether an address space\n    conversion to generic is required, and if so, perform it.  Also\n    check for SYMBOL_REFs for function decls and call\n@@ -1660,6 +1971,7 @@ nvptx_print_operand_address (FILE *file, rtx addr)\n    c -- print an opcode suffix for a comparison operator, including a type code\n    d -- print a CONST_INT as a vector dimension (x, y, or z)\n    f -- print a full reg even for something that must always be split\n+   S -- print a shuffle kind specified by CONST_INT\n    t -- print a type opcode suffix, promoting QImode to 32 bits\n    T -- print a type size in bits\n    u -- print a type opcode suffix without promotions.  */\n@@ -1723,6 +2035,15 @@ nvptx_print_operand (FILE *file, rtx x, int code)\n       fprintf (file, \"%s\", nvptx_ptx_type_from_mode (op_mode, false));\n       break;\n \n+    case 'S':\n+      {\n+\tunsigned kind = UINTVAL (x);\n+\tstatic const char *const kinds[] = \n+\t  {\"up\", \"down\", \"bfly\", \"idx\"};\n+\tfprintf (file, \".%s\", kinds[kind]);\n+      }\n+      break;\n+\n     case 'T':\n       fprintf (file, \"%d\", GET_MODE_BITSIZE (GET_MODE (x)));\n       break;\n@@ -1973,10 +2294,747 @@ nvptx_reorg_subreg (void)\n     }\n }\n \n+/* Loop structure of the function. The entire function is described as\n+   a NULL loop.  We should be able to extend this to represent\n+   superblocks.  */\n+\n+struct parallel\n+{\n+  /* Parent parallel.  */\n+  parallel *parent;\n+  \n+  /* Next sibling parallel.  */\n+  parallel *next;\n+\n+  /* First child parallel.  */\n+  parallel *inner;\n+\n+  /* Partitioning mask of the parallel.  */\n+  unsigned mask;\n+\n+  /* Partitioning used within inner parallels. */\n+  unsigned inner_mask;\n+\n+  /* Location of parallel forked and join.  The forked is the first\n+     block in the parallel and the join is the first block after of\n+     the partition.  */\n+  basic_block forked_block;\n+  basic_block join_block;\n+\n+  rtx_insn *forked_insn;\n+  rtx_insn *join_insn;\n+\n+  rtx_insn *fork_insn;\n+  rtx_insn *joining_insn;\n+\n+  /* Basic blocks in this parallel, but not in child parallels.  The\n+     FORKED and JOINING blocks are in the partition.  The FORK and JOIN\n+     blocks are not.  */\n+  auto_vec<basic_block> blocks;\n+\n+public:\n+  parallel (parallel *parent, unsigned mode);\n+  ~parallel ();\n+};\n+\n+/* Constructor links the new parallel into it's parent's chain of\n+   children.  */\n+\n+parallel::parallel (parallel *parent_, unsigned mask_)\n+  :parent (parent_), next (0), inner (0), mask (mask_), inner_mask (0)\n+{\n+  forked_block = join_block = 0;\n+  forked_insn = join_insn = 0;\n+  fork_insn = joining_insn = 0;\n+  \n+  if (parent)\n+    {\n+      next = parent->inner;\n+      parent->inner = this;\n+    }\n+}\n+\n+parallel::~parallel ()\n+{\n+  delete inner;\n+  delete next;\n+}\n+\n+/* Map of basic blocks to insns */\n+typedef hash_map<basic_block, rtx_insn *> bb_insn_map_t;\n+\n+/* A tuple of an insn of interest and the BB in which it resides.  */\n+typedef std::pair<rtx_insn *, basic_block> insn_bb_t;\n+typedef auto_vec<insn_bb_t> insn_bb_vec_t;\n+\n+/* Split basic blocks such that each forked and join unspecs are at\n+   the start of their basic blocks.  Thus afterwards each block will\n+   have a single partitioning mode.  We also do the same for return\n+   insns, as they are executed by every thread.  Return the\n+   partitioning mode of the function as a whole.  Populate MAP with\n+   head and tail blocks.  We also clear the BB visited flag, which is\n+   used when finding partitions.  */\n+\n+static void\n+nvptx_split_blocks (bb_insn_map_t *map)\n+{\n+  insn_bb_vec_t worklist;\n+  basic_block block;\n+  rtx_insn *insn;\n+\n+  /* Locate all the reorg instructions of interest.  */\n+  FOR_ALL_BB_FN (block, cfun)\n+    {\n+      bool seen_insn = false;\n+\n+      /* Clear visited flag, for use by parallel locator  */\n+      block->flags &= ~BB_VISITED;\n+\n+      FOR_BB_INSNS (block, insn)\n+\t{\n+\t  if (!INSN_P (insn))\n+\t    continue;\n+\t  switch (recog_memoized (insn))\n+\t    {\n+\t    default:\n+\t      seen_insn = true;\n+\t      continue;\n+\t    case CODE_FOR_nvptx_forked:\n+\t    case CODE_FOR_nvptx_join:\n+\t      break;\n+\n+\t    case CODE_FOR_return:\n+\t      /* We also need to split just before return insns, as\n+\t\t that insn needs executing by all threads, but the\n+\t\t block it is in probably does not.  */\n+\t      break;\n+\t    }\n+\n+\t  if (seen_insn)\n+\t    /* We've found an instruction that  must be at the start of\n+\t       a block, but isn't.  Add it to the worklist.  */\n+\t    worklist.safe_push (insn_bb_t (insn, block));\n+\t  else\n+\t    /* It was already the first instruction.  Just add it to\n+\t       the map.  */\n+\t    map->get_or_insert (block) = insn;\n+\t  seen_insn = true;\n+\t}\n+    }\n+\n+  /* Split blocks on the worklist.  */\n+  unsigned ix;\n+  insn_bb_t *elt;\n+  basic_block remap = 0;\n+  for (ix = 0; worklist.iterate (ix, &elt); ix++)\n+    {\n+      if (remap != elt->second)\n+\t{\n+\t  block = elt->second;\n+\t  remap = block;\n+\t}\n+      \n+      /* Split block before insn. The insn is in the new block  */\n+      edge e = split_block (block, PREV_INSN (elt->first));\n+\n+      block = e->dest;\n+      map->get_or_insert (block) = elt->first;\n+    }\n+}\n+\n+/* BLOCK is a basic block containing a head or tail instruction.\n+   Locate the associated prehead or pretail instruction, which must be\n+   in the single predecessor block.  */\n+\n+static rtx_insn *\n+nvptx_discover_pre (basic_block block, int expected)\n+{\n+  gcc_assert (block->preds->length () == 1);\n+  basic_block pre_block = (*block->preds)[0]->src;\n+  rtx_insn *pre_insn;\n+\n+  for (pre_insn = BB_END (pre_block); !INSN_P (pre_insn);\n+       pre_insn = PREV_INSN (pre_insn))\n+    gcc_assert (pre_insn != BB_HEAD (pre_block));\n+\n+  gcc_assert (recog_memoized (pre_insn) == expected);\n+  return pre_insn;\n+}\n+\n+/* Dump this parallel and all its inner parallels.  */\n+\n+static void\n+nvptx_dump_pars (parallel *par, unsigned depth)\n+{\n+  fprintf (dump_file, \"%u: mask %d head=%d, tail=%d\\n\",\n+\t   depth, par->mask,\n+\t   par->forked_block ? par->forked_block->index : -1,\n+\t   par->join_block ? par->join_block->index : -1);\n+\n+  fprintf (dump_file, \"    blocks:\");\n+\n+  basic_block block;\n+  for (unsigned ix = 0; par->blocks.iterate (ix, &block); ix++)\n+    fprintf (dump_file, \" %d\", block->index);\n+  fprintf (dump_file, \"\\n\");\n+  if (par->inner)\n+    nvptx_dump_pars (par->inner, depth + 1);\n+\n+  if (par->next)\n+    nvptx_dump_pars (par->next, depth);\n+}\n+\n+/* If BLOCK contains a fork/join marker, process it to create or\n+   terminate a loop structure.  Add this block to the current loop,\n+   and then walk successor blocks.   */\n+\n+static parallel *\n+nvptx_find_par (bb_insn_map_t *map, parallel *par, basic_block block)\n+{\n+  if (block->flags & BB_VISITED)\n+    return par;\n+  block->flags |= BB_VISITED;\n+\n+  if (rtx_insn **endp = map->get (block))\n+    {\n+      rtx_insn *end = *endp;\n+\n+      /* This is a block head or tail, or return instruction.  */\n+      switch (recog_memoized (end))\n+\t{\n+\tcase CODE_FOR_return:\n+\t  /* Return instructions are in their own block, and we\n+\t     don't need to do anything more.  */\n+\t  return par;\n+\n+\tcase CODE_FOR_nvptx_forked:\n+\t  /* Loop head, create a new inner loop and add it into\n+\t     our parent's child list.  */\n+\t  {\n+\t    unsigned mask = UINTVAL (XVECEXP (PATTERN (end), 0, 0));\n+\n+\t    gcc_assert (mask);\n+\t    par = new parallel (par, mask);\n+\t    par->forked_block = block;\n+\t    par->forked_insn = end;\n+\t    if (!(mask & GOMP_DIM_MASK (GOMP_DIM_MAX))\n+\t\t&& (mask & GOMP_DIM_MASK (GOMP_DIM_WORKER)))\n+\t      par->fork_insn\n+\t\t= nvptx_discover_pre (block, CODE_FOR_nvptx_fork);\n+\t  }\n+\t  break;\n+\n+\tcase CODE_FOR_nvptx_join:\n+\t  /* A loop tail.  Finish the current loop and return to\n+\t     parent.  */\n+\t  {\n+\t    unsigned mask = UINTVAL (XVECEXP (PATTERN (end), 0, 0));\n+\n+\t    gcc_assert (par->mask == mask);\n+\t    par->join_block = block;\n+\t    par->join_insn = end;\n+\t    if (!(mask & GOMP_DIM_MASK (GOMP_DIM_MAX))\n+\t\t&& (mask & GOMP_DIM_MASK (GOMP_DIM_WORKER)))\n+\t      par->joining_insn\n+\t\t= nvptx_discover_pre (block, CODE_FOR_nvptx_joining);\n+\t    par = par->parent;\n+\t  }\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+    }\n+\n+  if (par)\n+    /* Add this block onto the current loop's list of blocks.  */\n+    par->blocks.safe_push (block);\n+  else\n+    /* This must be the entry block.  Create a NULL parallel.  */\n+    par = new parallel (0, 0);\n+\n+  /* Walk successor blocks.  */\n+  edge e;\n+  edge_iterator ei;\n+\n+  FOR_EACH_EDGE (e, ei, block->succs)\n+    nvptx_find_par (map, par, e->dest);\n+\n+  return par;\n+}\n+\n+/* DFS walk the CFG looking for fork & join markers.  Construct\n+   loop structures as we go.  MAP is a mapping of basic blocks\n+   to head & tail markers, discovered when splitting blocks.  This\n+   speeds up the discovery.  We rely on the BB visited flag having\n+   been cleared when splitting blocks.  */\n+\n+static parallel *\n+nvptx_discover_pars (bb_insn_map_t *map)\n+{\n+  basic_block block;\n+\n+  /* Mark exit blocks as visited.  */\n+  block = EXIT_BLOCK_PTR_FOR_FN (cfun);\n+  block->flags |= BB_VISITED;\n+\n+  /* And entry block as not.  */\n+  block = ENTRY_BLOCK_PTR_FOR_FN (cfun);\n+  block->flags &= ~BB_VISITED;\n+\n+  parallel *par = nvptx_find_par (map, 0, block);\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"\\nLoops\\n\");\n+      nvptx_dump_pars (par, 0);\n+      fprintf (dump_file, \"\\n\");\n+    }\n+  \n+  return par;\n+}\n+\n+/* Propagate live state at the start of a partitioned region.  BLOCK\n+   provides the live register information, and might not contain\n+   INSN. Propagation is inserted just after INSN. RW indicates whether\n+   we are reading and/or writing state.  This\n+   separation is needed for worker-level proppagation where we\n+   essentially do a spill & fill.  FN is the underlying worker\n+   function to generate the propagation instructions for single\n+   register.  DATA is user data.\n+\n+   We propagate the live register set and the entire frame.  We could\n+   do better by (a) propagating just the live set that is used within\n+   the partitioned regions and (b) only propagating stack entries that\n+   are used.  The latter might be quite hard to determine.  */\n+\n+typedef rtx (*propagator_fn) (rtx, propagate_mask, unsigned, void *);\n+\n+static void\n+nvptx_propagate (basic_block block, rtx_insn *insn, propagate_mask rw,\n+\t\t propagator_fn fn, void *data)\n+{\n+  bitmap live = DF_LIVE_IN (block);\n+  bitmap_iterator iterator;\n+  unsigned ix;\n+\n+  /* Copy the frame array.  */\n+  HOST_WIDE_INT fs = get_frame_size ();\n+  if (fs)\n+    {\n+      rtx tmp = gen_reg_rtx (DImode);\n+      rtx idx = NULL_RTX;\n+      rtx ptr = gen_reg_rtx (Pmode);\n+      rtx pred = NULL_RTX;\n+      rtx_code_label *label = NULL;\n+\n+      gcc_assert (!(fs & (GET_MODE_SIZE (DImode) - 1)));\n+      fs /= GET_MODE_SIZE (DImode);\n+      /* Detect single iteration loop. */\n+      if (fs == 1)\n+\tfs = 0;\n+\n+      start_sequence ();\n+      emit_insn (gen_rtx_SET (ptr, frame_pointer_rtx));\n+      if (fs)\n+\t{\n+\t  idx = gen_reg_rtx (SImode);\n+\t  pred = gen_reg_rtx (BImode);\n+\t  label = gen_label_rtx ();\n+\t  \n+\t  emit_insn (gen_rtx_SET (idx, GEN_INT (fs)));\n+\t  /* Allow worker function to initialize anything needed.  */\n+\t  rtx init = fn (tmp, PM_loop_begin, fs, data);\n+\t  if (init)\n+\t    emit_insn (init);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label)++;\n+\t  emit_insn (gen_addsi3 (idx, idx, GEN_INT (-1)));\n+\t}\n+      if (rw & PM_read)\n+\temit_insn (gen_rtx_SET (tmp, gen_rtx_MEM (DImode, ptr)));\n+      emit_insn (fn (tmp, rw, fs, data));\n+      if (rw & PM_write)\n+\temit_insn (gen_rtx_SET (gen_rtx_MEM (DImode, ptr), tmp));\n+      if (fs)\n+\t{\n+\t  emit_insn (gen_rtx_SET (pred, gen_rtx_NE (BImode, idx, const0_rtx)));\n+\t  emit_insn (gen_adddi3 (ptr, ptr, GEN_INT (GET_MODE_SIZE (DImode))));\n+\t  emit_insn (gen_br_true_uni (pred, label));\n+\t  rtx fini = fn (tmp, PM_loop_end, fs, data);\n+\t  if (fini)\n+\t    emit_insn (fini);\n+\t  emit_insn (gen_rtx_CLOBBER (GET_MODE (idx), idx));\n+\t}\n+      emit_insn (gen_rtx_CLOBBER (GET_MODE (tmp), tmp));\n+      emit_insn (gen_rtx_CLOBBER (GET_MODE (ptr), ptr));\n+      rtx cpy = get_insns ();\n+      end_sequence ();\n+      insn = emit_insn_after (cpy, insn);\n+    }\n+\n+  /* Copy live registers.  */\n+  EXECUTE_IF_SET_IN_BITMAP (live, 0, ix, iterator)\n+    {\n+      rtx reg = regno_reg_rtx[ix];\n+\n+      if (REGNO (reg) >= FIRST_PSEUDO_REGISTER)\n+\t{\n+\t  rtx bcast = fn (reg, rw, 0, data);\n+\n+\t  insn = emit_insn_after (bcast, insn);\n+\t}\n+    }\n+}\n+\n+/* Worker for nvptx_vpropagate.  */\n+\n+static rtx\n+vprop_gen (rtx reg, propagate_mask pm,\n+\t   unsigned ARG_UNUSED (count), void *ARG_UNUSED (data))\n+{\n+  if (!(pm & PM_read_write))\n+    return 0;\n+  \n+  return nvptx_gen_vcast (reg);\n+}\n+\n+/* Propagate state that is live at start of BLOCK across the vectors\n+   of a single warp.  Propagation is inserted just after INSN.   */\n+\n+static void\n+nvptx_vpropagate (basic_block block, rtx_insn *insn)\n+{\n+  nvptx_propagate (block, insn, PM_read_write, vprop_gen, 0);\n+}\n+\n+/* Worker for nvptx_wpropagate.  */\n+\n+static rtx\n+wprop_gen (rtx reg, propagate_mask pm, unsigned rep, void *data_)\n+{\n+  wcast_data_t *data = (wcast_data_t *)data_;\n+\n+  if (pm & PM_loop_begin)\n+    {\n+      /* Starting a loop, initialize pointer.    */\n+      unsigned align = GET_MODE_ALIGNMENT (GET_MODE (reg)) / BITS_PER_UNIT;\n+\n+      if (align > worker_bcast_align)\n+\tworker_bcast_align = align;\n+      data->offset = (data->offset + align - 1) & ~(align - 1);\n+\n+      data->ptr = gen_reg_rtx (Pmode);\n+\n+      return gen_adddi3 (data->ptr, data->base, GEN_INT (data->offset));\n+    }\n+  else if (pm & PM_loop_end)\n+    {\n+      rtx clobber = gen_rtx_CLOBBER (GET_MODE (data->ptr), data->ptr);\n+      data->ptr = NULL_RTX;\n+      return clobber;\n+    }\n+  else\n+    return nvptx_gen_wcast (reg, pm, rep, data);\n+}\n+\n+/* Spill or fill live state that is live at start of BLOCK.  PRE_P\n+   indicates if this is just before partitioned mode (do spill), or\n+   just after it starts (do fill). Sequence is inserted just after\n+   INSN.  */\n+\n+static void\n+nvptx_wpropagate (bool pre_p, basic_block block, rtx_insn *insn)\n+{\n+  wcast_data_t data;\n+\n+  data.base = gen_reg_rtx (Pmode);\n+  data.offset = 0;\n+  data.ptr = NULL_RTX;\n+\n+  nvptx_propagate (block, insn, pre_p ? PM_read : PM_write, wprop_gen, &data);\n+  if (data.offset)\n+    {\n+      /* Stuff was emitted, initialize the base pointer now.  */\n+      rtx init = gen_rtx_SET (data.base, worker_bcast_sym);\n+      emit_insn_after (init, insn);\n+      \n+      if (worker_bcast_size < data.offset)\n+\tworker_bcast_size = data.offset;\n+    }\n+}\n+\n+/* Emit a worker-level synchronization barrier.  We use different\n+   markers for before and after synchronizations.  */\n+\n+static rtx\n+nvptx_wsync (bool after)\n+{\n+  return gen_nvptx_barsync (GEN_INT (after));\n+}\n+\n+/* Single neutering according to MASK.  FROM is the incoming block and\n+   TO is the outgoing block.  These may be the same block. Insert at\n+   start of FROM:\n+   \n+     if (tid.<axis>) goto end.\n+\n+   and insert before ending branch of TO (if there is such an insn):\n+\n+     end:\n+     <possibly-broadcast-cond>\n+     <branch>\n+\n+   We currently only use differnt FROM and TO when skipping an entire\n+   loop.  We could do more if we detected superblocks.  */\n+\n+static void\n+nvptx_single (unsigned mask, basic_block from, basic_block to)\n+{\n+  rtx_insn *head = BB_HEAD (from);\n+  rtx_insn *tail = BB_END (to);\n+  unsigned skip_mask = mask;\n+\n+  /* Find first insn of from block */\n+  while (head != BB_END (from) && !INSN_P (head))\n+    head = NEXT_INSN (head);\n+\n+  /* Find last insn of to block */\n+  rtx_insn *limit = from == to ? head : BB_HEAD (to);\n+  while (tail != limit && !INSN_P (tail) && !LABEL_P (tail))\n+    tail = PREV_INSN (tail);\n+\n+  /* Detect if tail is a branch.  */\n+  rtx tail_branch = NULL_RTX;\n+  rtx cond_branch = NULL_RTX;\n+  if (tail && INSN_P (tail))\n+    {\n+      tail_branch = PATTERN (tail);\n+      if (GET_CODE (tail_branch) != SET || SET_DEST (tail_branch) != pc_rtx)\n+\ttail_branch = NULL_RTX;\n+      else\n+\t{\n+\t  cond_branch = SET_SRC (tail_branch);\n+\t  if (GET_CODE (cond_branch) != IF_THEN_ELSE)\n+\t    cond_branch = NULL_RTX;\n+\t}\n+    }\n+\n+  if (tail == head)\n+    {\n+      /* If this is empty, do nothing.  */\n+      if (!head || !INSN_P (head))\n+\treturn;\n+\n+      /* If this is a dummy insn, do nothing.  */\n+      switch (recog_memoized (head))\n+\t{\n+\tdefault:\n+\t  break;\n+\tcase CODE_FOR_nvptx_fork:\n+\tcase CODE_FOR_nvptx_forked:\n+\tcase CODE_FOR_nvptx_joining:\n+\tcase CODE_FOR_nvptx_join:\n+\t  return;\n+\t}\n+\n+      if (cond_branch)\n+\t{\n+\t  /* If we're only doing vector single, there's no need to\n+\t     emit skip code because we'll not insert anything.  */\n+\t  if (!(mask & GOMP_DIM_MASK (GOMP_DIM_VECTOR)))\n+\t    skip_mask = 0;\n+\t}\n+      else if (tail_branch)\n+\t/* Block with only unconditional branch.  Nothing to do.  */\n+\treturn;\n+    }\n+\n+  /* Insert the vector test inside the worker test.  */\n+  unsigned mode;\n+  rtx_insn *before = tail;\n+  for (mode = GOMP_DIM_WORKER; mode <= GOMP_DIM_VECTOR; mode++)\n+    if (GOMP_DIM_MASK (mode) & skip_mask)\n+      {\n+\trtx_code_label *label = gen_label_rtx ();\n+\trtx pred = cfun->machine->axis_predicate[mode - GOMP_DIM_WORKER];\n+\n+\tif (!pred)\n+\t  {\n+\t    pred = gen_reg_rtx (BImode);\n+\t    cfun->machine->axis_predicate[mode - GOMP_DIM_WORKER] = pred;\n+\t  }\n+\t\n+\trtx br;\n+\tif (mode == GOMP_DIM_VECTOR)\n+\t  br = gen_br_true (pred, label);\n+\telse\n+\t  br = gen_br_true_uni (pred, label);\n+\temit_insn_before (br, head);\n+\n+\tLABEL_NUSES (label)++;\n+\tif (tail_branch)\n+\t  before = emit_label_before (label, before);\n+\telse\n+\t  emit_label_after (label, tail);\n+      }\n+\n+  /* Now deal with propagating the branch condition.  */\n+  if (cond_branch)\n+    {\n+      rtx pvar = XEXP (XEXP (cond_branch, 0), 0);\n+\n+      if (GOMP_DIM_MASK (GOMP_DIM_VECTOR) == mask)\n+\t{\n+\t  /* Vector mode only, do a shuffle.  */\n+\t  emit_insn_before (nvptx_gen_vcast (pvar), tail);\n+\t}\n+      else\n+\t{\n+\t  /* Includes worker mode, do spill & fill.  By construction\n+\t     we should never have worker mode only. */\n+\t  wcast_data_t data;\n+\n+\t  data.base = worker_bcast_sym;\n+\t  data.ptr = 0;\n+\n+\t  if (worker_bcast_size < GET_MODE_SIZE (SImode))\n+\t    worker_bcast_size = GET_MODE_SIZE (SImode);\n+\n+\t  data.offset = 0;\n+\t  emit_insn_before (nvptx_gen_wcast (pvar, PM_read, 0, &data),\n+\t\t\t    before);\n+\t  /* Barrier so other workers can see the write.  */\n+\t  emit_insn_before (nvptx_wsync (false), tail);\n+\t  data.offset = 0;\n+\t  emit_insn_before (nvptx_gen_wcast (pvar, PM_write, 0, &data), tail);\n+\t  /* This barrier is needed to avoid worker zero clobbering\n+\t     the broadcast buffer before all the other workers have\n+\t     had a chance to read this instance of it.  */\n+\t  emit_insn_before (nvptx_wsync (true), tail);\n+\t}\n+\n+      extract_insn (tail);\n+      rtx unsp = gen_rtx_UNSPEC (BImode, gen_rtvec (1, pvar),\n+\t\t\t\t UNSPEC_BR_UNIFIED);\n+      validate_change (tail, recog_data.operand_loc[0], unsp, false);\n+    }\n+}\n+\n+/* PAR is a parallel that is being skipped in its entirety according to\n+   MASK.  Treat this as skipping a superblock starting at forked\n+   and ending at joining.  */\n+\n+static void\n+nvptx_skip_par (unsigned mask, parallel *par)\n+{\n+  basic_block tail = par->join_block;\n+  gcc_assert (tail->preds->length () == 1);\n+\n+  basic_block pre_tail = (*tail->preds)[0]->src;\n+  gcc_assert (pre_tail->succs->length () == 1);\n+\n+  nvptx_single (mask, par->forked_block, pre_tail);\n+}\n+\n+/* Process the parallel PAR and all its contained\n+   parallels.  We do everything but the neutering.  Return mask of\n+   partitioned modes used within this parallel.  */\n+\n+static unsigned\n+nvptx_process_pars (parallel *par)\n+{\n+  unsigned inner_mask = par->mask;\n+\n+  /* Do the inner parallels first.  */\n+  if (par->inner)\n+    {\n+      par->inner_mask = nvptx_process_pars (par->inner);\n+      inner_mask |= par->inner_mask;\n+    }\n+\n+  if (par->mask & GOMP_DIM_MASK (GOMP_DIM_MAX))\n+    /* No propagation needed for a call.  */;\n+ else if (par->mask & GOMP_DIM_MASK (GOMP_DIM_WORKER))\n+    {\n+      nvptx_wpropagate (false, par->forked_block, par->forked_insn);\n+      nvptx_wpropagate (true, par->forked_block, par->fork_insn);\n+      /* Insert begin and end synchronizations.  */\n+      emit_insn_after (nvptx_wsync (false), par->forked_insn);\n+      emit_insn_before (nvptx_wsync (true), par->joining_insn);\n+    }\n+  else if (par->mask & GOMP_DIM_MASK (GOMP_DIM_VECTOR))\n+    nvptx_vpropagate (par->forked_block, par->forked_insn);\n+\n+  /* Now do siblings.  */\n+  if (par->next)\n+    inner_mask |= nvptx_process_pars (par->next);\n+  return inner_mask;\n+}\n+\n+/* Neuter the parallel described by PAR.  We recurse in depth-first\n+   order.  MODES are the partitioning of the execution and OUTER is\n+   the partitioning of the parallels we are contained in.  */\n+\n+static void\n+nvptx_neuter_pars (parallel *par, unsigned modes, unsigned outer)\n+{\n+  unsigned me = (par->mask\n+\t\t & (GOMP_DIM_MASK (GOMP_DIM_WORKER)\n+\t\t    | GOMP_DIM_MASK (GOMP_DIM_VECTOR)));\n+  unsigned  skip_mask = 0, neuter_mask = 0;\n+  \n+  if (par->inner)\n+    nvptx_neuter_pars (par->inner, modes, outer | me);\n+\n+  for (unsigned mode = GOMP_DIM_WORKER; mode <= GOMP_DIM_VECTOR; mode++)\n+    {\n+      if ((outer | me) & GOMP_DIM_MASK (mode))\n+\t{} /* Mode is partitioned: no neutering.  */\n+      else if (!(modes & GOMP_DIM_MASK (mode)))\n+\t{} /* Mode is not used: nothing to do.  */  \n+      else if (par->inner_mask & GOMP_DIM_MASK (mode)\n+\t       || !par->forked_insn)\n+\t/* Partitioned in inner parallels, or we're not a partitioned\n+\t   at all: neuter individual blocks.  */\n+\tneuter_mask |= GOMP_DIM_MASK (mode);\n+      else if (!par->parent || !par->parent->forked_insn\n+\t       || par->parent->inner_mask & GOMP_DIM_MASK (mode))\n+\t/* Parent isn't a parallel or contains this paralleling: skip\n+\t   parallel at this level.  */\n+\tskip_mask |= GOMP_DIM_MASK (mode);\n+      else\n+\t{} /* Parent will skip this parallel itself.  */\n+    }\n+\n+  if (neuter_mask)\n+    {\n+      int ix;\n+      int len = par->blocks.length ();\n+\n+      for (ix = 0; ix != len; ix++)\n+\t{\n+\t  basic_block block = par->blocks[ix];\n+\n+\t  nvptx_single (neuter_mask, block, block);\n+\t}\n+    }\n+\n+  if (skip_mask)\n+      nvptx_skip_par (skip_mask, par);\n+  \n+  if (par->next)\n+    nvptx_neuter_pars (par->next, modes, outer);\n+}\n+\n /* PTX-specific reorganization\n+   - Scan and release reduction buffers\n+   - Split blocks at fork and join instructions\n    - Compute live registers\n    - Mark now-unused registers, so function begin doesn't declare\n    unused registers.\n+   - Insert state propagation when entering partitioned mode\n+   - Insert neutering instructions when in single mode\n    - Replace subregs with suitable sequences.\n */\n \n@@ -1989,19 +3047,60 @@ nvptx_reorg (void)\n \n   thread_prologue_and_epilogue_insns ();\n \n+  /* Split blocks and record interesting unspecs.  */\n+  bb_insn_map_t bb_insn_map;\n+\n+  nvptx_split_blocks (&bb_insn_map);\n+\n   /* Compute live regs */\n   df_clear_flags (DF_LR_RUN_DCE);\n   df_set_flags (DF_NO_INSN_RESCAN | DF_NO_HARD_REGS);\n+  df_live_add_problem ();\n+  df_live_set_all_dirty ();\n   df_analyze ();\n   regstat_init_n_sets_and_refs ();\n \n-  int max_regs = max_reg_num ();\n-\n+  if (dump_file)\n+    df_dump (dump_file);\n+  \n   /* Mark unused regs as unused.  */\n+  int max_regs = max_reg_num ();\n   for (int i = LAST_VIRTUAL_REGISTER + 1; i < max_regs; i++)\n     if (REG_N_SETS (i) == 0 && REG_N_REFS (i) == 0)\n       regno_reg_rtx[i] = const0_rtx;\n \n+  /* Determine launch dimensions of the function.  If it is not an\n+     offloaded function  (i.e. this is a regular compiler), the\n+     function has no neutering.  */\n+  tree attr = get_oacc_fn_attrib (current_function_decl);\n+  if (attr)\n+    {\n+      /* If we determined this mask before RTL expansion, we could\n+\t elide emission of some levels of forks and joins.  */\n+      unsigned mask = 0;\n+      tree dims = TREE_VALUE (attr);\n+      unsigned ix;\n+\n+      for (ix = 0; ix != GOMP_DIM_MAX; ix++, dims = TREE_CHAIN (dims))\n+\t{\n+\t  int size = TREE_INT_CST_LOW (TREE_VALUE (dims));\n+\t  tree allowed = TREE_PURPOSE (dims);\n+\n+\t  if (size != 1 && !(allowed && integer_zerop (allowed)))\n+\t    mask |= GOMP_DIM_MASK (ix);\n+\t}\n+      /* If there is worker neutering, there must be vector\n+\t neutering.  Otherwise the hardware will fail.  */\n+      gcc_assert (!(mask & GOMP_DIM_MASK (GOMP_DIM_WORKER))\n+\t\t  || (mask & GOMP_DIM_MASK (GOMP_DIM_VECTOR)));\n+\n+      /* Discover & process partitioned regions.  */\n+      parallel *pars = nvptx_discover_pars (&bb_insn_map);\n+      nvptx_process_pars (pars);\n+      nvptx_neuter_pars (pars, mask, 0);\n+      delete pars;\n+    }\n+\n   /* Replace subregs.  */\n   nvptx_reorg_subreg ();\n \n@@ -2052,6 +3151,26 @@ nvptx_vector_alignment (const_tree type)\n \n   return MIN (align, BIGGEST_ALIGNMENT);\n }\n+\n+/* Indicate that INSN cannot be duplicated.   */\n+\n+static bool\n+nvptx_cannot_copy_insn_p (rtx_insn *insn)\n+{\n+  switch (recog_memoized (insn))\n+    {\n+    case CODE_FOR_nvptx_shufflesi:\n+    case CODE_FOR_nvptx_shufflesf:\n+    case CODE_FOR_nvptx_barsync:\n+    case CODE_FOR_nvptx_fork:\n+    case CODE_FOR_nvptx_forked:\n+    case CODE_FOR_nvptx_joining:\n+    case CODE_FOR_nvptx_join:\n+      return true;\n+    default:\n+      return false;\n+    }\n+}\n \f\n /* Record a symbol for mkoffload to enter into the mapping table.  */\n \n@@ -2129,6 +3248,19 @@ nvptx_file_end (void)\n   FOR_EACH_HASH_TABLE_ELEMENT (*needed_fndecls_htab, decl, tree, iter)\n     nvptx_record_fndecl (decl, true);\n   fputs (func_decls.str().c_str(), asm_out_file);\n+\n+  if (worker_bcast_size)\n+    {\n+      /* Define the broadcast buffer.  */\n+\n+      worker_bcast_size = (worker_bcast_size + worker_bcast_align - 1)\n+\t& ~(worker_bcast_align - 1);\n+      \n+      fprintf (asm_out_file, \"// BEGIN VAR DEF: %s\\n\", worker_bcast_name);\n+      fprintf (asm_out_file, \".shared .align %d .u8 %s[%d];\\n\",\n+\t       worker_bcast_align,\n+\t       worker_bcast_name, worker_bcast_size);\n+    }\n }\n \f\n /* Validate compute dimensions of an OpenACC offload or routine, fill\n@@ -2141,12 +3273,32 @@ nvptx_goacc_validate_dims (tree ARG_UNUSED (decl), int *ARG_UNUSED (dims),\n {\n   bool changed = false;\n \n-  /* TODO: Leave dimensions unaltered.  Partitioned execution needs\n+  /* TODO: Leave dimensions unaltered.  Reductions need\n      porting before filtering dimensions makes sense.  */\n \n   return changed;\n }\n-\f\n+\n+/* Determine whether fork & joins are needed.  */\n+\n+static bool\n+nvptx_goacc_fork_join (gcall *call, const int dims[],\n+\t\t       bool ARG_UNUSED (is_fork))\n+{\n+  tree arg = gimple_call_arg (call, 2);\n+  unsigned axis = TREE_INT_CST_LOW (arg);\n+\n+  /* We only care about worker and vector partitioning.  */\n+  if (axis < GOMP_DIM_WORKER)\n+    return false;\n+\n+  /* If the size is 1, there's no partitioning.  */\n+  if (dims[axis] == 1)\n+    return false;\n+\n+  return true;\n+}\n+\n #undef TARGET_OPTION_OVERRIDE\n #define TARGET_OPTION_OVERRIDE nvptx_option_override\n \n@@ -2233,9 +3385,15 @@ nvptx_goacc_validate_dims (tree ARG_UNUSED (decl), int *ARG_UNUSED (dims),\n #undef TARGET_VECTOR_ALIGNMENT\n #define TARGET_VECTOR_ALIGNMENT nvptx_vector_alignment\n \n+#undef TARGET_CANNOT_COPY_INSN_P\n+#define TARGET_CANNOT_COPY_INSN_P nvptx_cannot_copy_insn_p\n+\n #undef TARGET_GOACC_VALIDATE_DIMS\n #define TARGET_GOACC_VALIDATE_DIMS nvptx_goacc_validate_dims\n \n+#undef TARGET_GOACC_FORK_JOIN\n+#define TARGET_GOACC_FORK_JOIN nvptx_goacc_fork_join\n+\n struct gcc_target targetm = TARGET_INITIALIZER;\n \n #include \"gt-nvptx.h\""}, {"sha": "efab423522b86149bc9ac2762840b4318e7b6e2b", "filename": "gcc/config/nvptx/nvptx.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnvptx%2Fnvptx.h?ref=d88cd9c42448f3e166a17356a7f8539541b68a25", "patch": "@@ -230,6 +230,7 @@ struct GTY(()) machine_function\n   HOST_WIDE_INT outgoing_stdarg_size;\n   int ret_reg_mode; /* machine_mode not defined yet. */\n   int punning_buffer_size;\n+  rtx axis_predicate[2];\n };\n #endif\n \f"}, {"sha": "7930f8dd8e6362925c25859aee0d1d957121895e", "filename": "gcc/config/nvptx/nvptx.md", "status": "modified", "additions": 155, "deletions": 19, "changes": 174, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d88cd9c42448f3e166a17356a7f8539541b68a25/gcc%2Fconfig%2Fnvptx%2Fnvptx.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnvptx%2Fnvptx.md?ref=d88cd9c42448f3e166a17356a7f8539541b68a25", "patch": "@@ -49,14 +49,27 @@\n \n    UNSPEC_ALLOCA\n \n-   UNSPEC_NTID\n-   UNSPEC_TID\n+   UNSPEC_DIM_SIZE\n+\n+   UNSPEC_SHARED_DATA\n+\n+   UNSPEC_BIT_CONV\n+\n+   UNSPEC_SHUFFLE\n+   UNSPEC_BR_UNIFIED\n ])\n \n (define_c_enum \"unspecv\" [\n    UNSPECV_LOCK\n    UNSPECV_CAS\n    UNSPECV_XCHG\n+   UNSPECV_BARSYNC\n+   UNSPECV_DIM_POS\n+\n+   UNSPECV_FORK\n+   UNSPECV_FORKED\n+   UNSPECV_JOINING\n+   UNSPECV_JOIN\n ])\n \n (define_attr \"subregs_ok\" \"false,true\"\n@@ -246,6 +259,8 @@\n (define_mode_iterator QHSIM [QI HI SI])\n (define_mode_iterator SDFM [SF DF])\n (define_mode_iterator SDCM [SC DC])\n+(define_mode_iterator BITS [SI SF])\n+(define_mode_iterator BITD [DI DF])\n \n ;; This mode iterator allows :P to be used for patterns that operate on\n ;; pointer-sized quantities.  Exactly one of the two alternatives will match.\n@@ -817,6 +832,23 @@\n   \"\"\n   \"%J0\\\\tbra\\\\t%l1;\")\n \n+;; unified conditional branch\n+(define_insn \"br_true_uni\"\n+  [(set (pc) (if_then_else\n+\t(ne (unspec:BI [(match_operand:BI 0 \"nvptx_register_operand\" \"R\")]\n+\t\t       UNSPEC_BR_UNIFIED) (const_int 0))\n+        (label_ref (match_operand 1 \"\" \"\")) (pc)))]\n+  \"\"\n+  \"%j0\\\\tbra.uni\\\\t%l1;\")\n+\n+(define_insn \"br_false_uni\"\n+  [(set (pc) (if_then_else\n+\t(eq (unspec:BI [(match_operand:BI 0 \"nvptx_register_operand\" \"R\")]\n+\t\t       UNSPEC_BR_UNIFIED) (const_int 0))\n+        (label_ref (match_operand 1 \"\" \"\")) (pc)))]\n+  \"\"\n+  \"%J0\\\\tbra.uni\\\\t%l1;\")\n+\n (define_expand \"cbranch<mode>4\"\n   [(set (pc)\n \t(if_then_else (match_operator 0 \"nvptx_comparison_operator\"\n@@ -1308,36 +1340,134 @@\n   DONE;\n })\n \n-(define_insn \"*oacc_ntid_insn\"\n-  [(set (match_operand:SI 0 \"nvptx_register_operand\" \"=R\")\n-\t(unspec:SI [(match_operand:SI 1 \"const_int_operand\" \"n\")] UNSPEC_NTID))]\n+(define_insn \"oacc_dim_size\"\n+  [(set (match_operand:SI 0 \"nvptx_register_operand\" \"\")\n+\t(unspec:SI [(match_operand:SI 1 \"const_int_operand\" \"\")]\n+\t\t   UNSPEC_DIM_SIZE))]\n   \"\"\n-  \"%.\\\\tmov.u32 %0, %%ntid%d1;\")\n+{\n+  static const char *const asms[] =\n+{ /* Must match oacc_loop_levels ordering.  */\n+  \"%.\\\\tmov.u32\\\\t%0, %%nctaid.x;\",\t/* gang */\n+  \"%.\\\\tmov.u32\\\\t%0, %%ntid.y;\",\t/* worker */\n+  \"%.\\\\tmov.u32\\\\t%0, %%ntid.x;\",\t/* vector */\n+};\n+  return asms[INTVAL (operands[1])];\n+})\n \n-(define_expand \"oacc_ntid\"\n+(define_insn \"oacc_dim_pos\"\n   [(set (match_operand:SI 0 \"nvptx_register_operand\" \"\")\n-\t(unspec:SI [(match_operand:SI 1 \"const_int_operand\" \"\")] UNSPEC_NTID))]\n+\t(unspec_volatile:SI [(match_operand:SI 1 \"const_int_operand\" \"\")]\n+\t\t\t    UNSPECV_DIM_POS))]\n   \"\"\n {\n-  if (INTVAL (operands[1]) < 0 || INTVAL (operands[1]) > 2)\n-    FAIL;\n+  static const char *const asms[] =\n+{ /* Must match oacc_loop_levels ordering.  */\n+  \"%.\\\\tmov.u32\\\\t%0, %%ctaid.x;\",\t/* gang */\n+  \"%.\\\\tmov.u32\\\\t%0, %%tid.y;\",\t/* worker */\n+  \"%.\\\\tmov.u32\\\\t%0, %%tid.x;\",\t/* vector */\n+};\n+  return asms[INTVAL (operands[1])];\n })\n \n-(define_insn \"*oacc_tid_insn\"\n-  [(set (match_operand:SI 0 \"nvptx_register_operand\" \"=R\")\n-\t(unspec:SI [(match_operand:SI 1 \"const_int_operand\" \"n\")] UNSPEC_TID))]\n+(define_insn \"nvptx_fork\"\n+  [(unspec_volatile:SI [(match_operand:SI 0 \"const_int_operand\" \"\")]\n+\t\t       UNSPECV_FORK)]\n   \"\"\n-  \"%.\\\\tmov.u32 %0, %%tid%d1;\")\n+  \"// fork %0;\"\n+)\n \n-(define_expand \"oacc_tid\"\n-  [(set (match_operand:SI 0 \"nvptx_register_operand\" \"\")\n-\t(unspec:SI [(match_operand:SI 1 \"const_int_operand\" \"\")] UNSPEC_TID))]\n+(define_insn \"nvptx_forked\"\n+  [(unspec_volatile:SI [(match_operand:SI 0 \"const_int_operand\" \"\")]\n+\t\t       UNSPECV_FORKED)]\n+  \"\"\n+  \"// forked %0;\"\n+)\n+\n+(define_insn \"nvptx_joining\"\n+  [(unspec_volatile:SI [(match_operand:SI 0 \"const_int_operand\" \"\")]\n+\t\t       UNSPECV_JOINING)]\n+  \"\"\n+  \"// joining %0;\"\n+)\n+\n+(define_insn \"nvptx_join\"\n+  [(unspec_volatile:SI [(match_operand:SI 0 \"const_int_operand\" \"\")]\n+\t\t       UNSPECV_JOIN)]\n+  \"\"\n+  \"// join %0;\"\n+)\n+\n+(define_expand \"oacc_fork\"\n+  [(set (match_operand:SI 0 \"nvptx_nonmemory_operand\" \"\")\n+        (match_operand:SI 1 \"nvptx_general_operand\" \"\"))\n+   (unspec_volatile:SI [(match_operand:SI 2 \"const_int_operand\" \"\")]\n+\t\t        UNSPECV_FORKED)]\n   \"\"\n {\n-  if (INTVAL (operands[1]) < 0 || INTVAL (operands[1]) > 2)\n-    FAIL;\n+  if (operands[0] != const0_rtx)\n+    emit_move_insn (operands[0], operands[1]);\n+  nvptx_expand_oacc_fork (INTVAL (operands[2]));\n+  DONE;\n+})\n+\n+(define_expand \"oacc_join\"\n+  [(set (match_operand:SI 0 \"nvptx_nonmemory_operand\" \"\")\n+        (match_operand:SI 1 \"nvptx_general_operand\" \"\"))\n+   (unspec_volatile:SI [(match_operand:SI 2 \"const_int_operand\" \"\")]\n+\t\t        UNSPECV_JOIN)]\n+  \"\"\n+{\n+  if (operands[0] != const0_rtx)\n+    emit_move_insn (operands[0], operands[1]);\n+  nvptx_expand_oacc_join (INTVAL (operands[2]));\n+  DONE;\n })\n \n+;; only 32-bit shuffles exist.\n+(define_insn \"nvptx_shuffle<mode>\"\n+  [(set (match_operand:BITS 0 \"nvptx_register_operand\" \"=R\")\n+\t(unspec:BITS\n+\t\t[(match_operand:BITS 1 \"nvptx_register_operand\" \"R\")\n+\t\t (match_operand:SI 2 \"nvptx_nonmemory_operand\" \"Ri\")\n+\t\t (match_operand:SI 3 \"const_int_operand\" \"n\")]\n+\t\t  UNSPEC_SHUFFLE))]\n+  \"\"\n+  \"%.\\\\tshfl%S3.b32\\\\t%0, %1, %2, 31;\")\n+\n+;; extract parts of a 64 bit object into 2 32-bit ints\n+(define_insn \"unpack<mode>si2\"\n+  [(set (match_operand:SI 0 \"nvptx_register_operand\" \"=R\")\n+        (unspec:SI [(match_operand:BITD 2 \"nvptx_register_operand\" \"R\")\n+\t\t    (const_int 0)] UNSPEC_BIT_CONV))\n+   (set (match_operand:SI 1 \"nvptx_register_operand\" \"=R\")\n+        (unspec:SI [(match_dup 2) (const_int 1)] UNSPEC_BIT_CONV))]\n+  \"\"\n+  \"%.\\\\tmov.b64\\\\t{%0,%1}, %2;\")\n+\n+;; pack 2 32-bit ints into a 64 bit object\n+(define_insn \"packsi<mode>2\"\n+  [(set (match_operand:BITD 0 \"nvptx_register_operand\" \"=R\")\n+        (unspec:BITD [(match_operand:SI 1 \"nvptx_register_operand\" \"R\")\n+\t\t      (match_operand:SI 2 \"nvptx_register_operand\" \"R\")]\n+\t\t    UNSPEC_BIT_CONV))]\n+  \"\"\n+  \"%.\\\\tmov.b64\\\\t%0, {%1,%2};\")\n+\n+(define_insn \"worker_load<mode>\"\n+  [(set (match_operand:SDISDFM 0 \"nvptx_register_operand\" \"=R\")\n+        (unspec:SDISDFM [(match_operand:SDISDFM 1 \"memory_operand\" \"m\")]\n+\t\t\t UNSPEC_SHARED_DATA))]\n+  \"\"\n+  \"%.\\\\tld.shared%u0\\\\t%0, %1;\")\n+\n+(define_insn \"worker_store<mode>\"\n+  [(set (unspec:SDISDFM [(match_operand:SDISDFM 1 \"memory_operand\" \"=m\")]\n+\t\t\t UNSPEC_SHARED_DATA)\n+\t(match_operand:SDISDFM 0 \"nvptx_register_operand\" \"R\"))]\n+  \"\"\n+  \"%.\\\\tst.shared%u1\\\\t%1, %0;\")\n+\n ;; Atomic insns.\n \n (define_expand \"atomic_compare_and_swap<mode>\"\n@@ -1423,3 +1553,9 @@\n \t(match_dup 1))]\n   \"0\"\n   \"%.\\\\tatom%A1.b%T0.<logic>\\\\t%0, %1, %2;\")\n+\n+(define_insn \"nvptx_barsync\"\n+  [(unspec_volatile [(match_operand:SI 0 \"const_int_operand\" \"\")]\n+\t\t    UNSPECV_BARSYNC)]\n+  \"\"\n+  \"\\\\tbar.sync\\\\t%0;\")"}]}