{"sha": "39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzliYjg5MjQ1NTlkMDQ4N2ZiN2NiNmQ0ZGMzM2Q2YjFlOWM0MTAwNA==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-12-21T06:57:18Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-12-21T06:57:18Z"}, "message": "poly_int: get_bit_range\n\nThis patch makes get_bit_range return the range and position as poly_ints.\n\n2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* expr.h (get_bit_range): Return the bitstart and bitend as\n\tpoly_uint64s rather than unsigned HOST_WIDE_INTs.  Return the bitpos\n\tas a poly_int64 rather than a HOST_WIDE_INT.\n\t* expr.c (get_bit_range): Likewise.\n\t(expand_assignment): Update call accordingly.\n\t* fold-const.c (optimize_bit_field_compare): Likewise.\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r255912", "tree": {"sha": "9887f91a47e5c46de73b822b210ba630c6b62cf2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9887f91a47e5c46de73b822b210ba630c6b62cf2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "html_url": "https://github.com/Rust-GCC/gccrs/commit/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/comments", "author": null, "committer": null, "parents": [{"sha": "a97d8b982793ba5bf1e54a41d9bb110182b8baf8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a97d8b982793ba5bf1e54a41d9bb110182b8baf8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a97d8b982793ba5bf1e54a41d9bb110182b8baf8"}], "stats": {"total": 121, "additions": 61, "deletions": 60}, "files": [{"sha": "3d783ffe2d5f215f778d1b3434d34a833515241e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "patch": "@@ -1,3 +1,14 @@\n+2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* expr.h (get_bit_range): Return the bitstart and bitend as\n+\tpoly_uint64s rather than unsigned HOST_WIDE_INTs.  Return the bitpos\n+\tas a poly_int64 rather than a HOST_WIDE_INT.\n+\t* expr.c (get_bit_range): Likewise.\n+\t(expand_assignment): Update call accordingly.\n+\t* fold-const.c (optimize_bit_field_compare): Likewise.\n+\n 2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "372b5fc84a06cec55f07dcc141dad9e7ec20e5c0", "filename": "gcc/expr.c", "status": "modified", "additions": 43, "deletions": 45, "changes": 88, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "patch": "@@ -4809,13 +4809,10 @@ optimize_bitfield_assignment_op (poly_uint64 pbitsize,\n    *BITSTART and *BITEND.  */\n \n void\n-get_bit_range (unsigned HOST_WIDE_INT *bitstart,\n-\t       unsigned HOST_WIDE_INT *bitend,\n-\t       tree exp,\n-\t       HOST_WIDE_INT *bitpos,\n-\t       tree *offset)\n+get_bit_range (poly_uint64_pod *bitstart, poly_uint64_pod *bitend, tree exp,\n+\t       poly_int64_pod *bitpos, tree *offset)\n {\n-  HOST_WIDE_INT bitoffset;\n+  poly_int64 bitoffset;\n   tree field, repr;\n \n   gcc_assert (TREE_CODE (exp) == COMPONENT_REF);\n@@ -4836,13 +4833,13 @@ get_bit_range (unsigned HOST_WIDE_INT *bitstart,\n   if (handled_component_p (TREE_OPERAND (exp, 0)))\n     {\n       machine_mode rmode;\n-      HOST_WIDE_INT rbitsize, rbitpos;\n+      poly_int64 rbitsize, rbitpos;\n       tree roffset;\n       int unsignedp, reversep, volatilep = 0;\n       get_inner_reference (TREE_OPERAND (exp, 0), &rbitsize, &rbitpos,\n \t\t\t   &roffset, &rmode, &unsignedp, &reversep,\n \t\t\t   &volatilep);\n-      if ((rbitpos % BITS_PER_UNIT) != 0)\n+      if (!multiple_p (rbitpos, BITS_PER_UNIT))\n \t{\n \t  *bitstart = *bitend = 0;\n \t  return;\n@@ -4853,10 +4850,10 @@ get_bit_range (unsigned HOST_WIDE_INT *bitstart,\n      relative to the representative.  DECL_FIELD_OFFSET of field and\n      repr are the same by construction if they are not constants,\n      see finish_bitfield_layout.  */\n-  if (tree_fits_uhwi_p (DECL_FIELD_OFFSET (field))\n-      && tree_fits_uhwi_p (DECL_FIELD_OFFSET (repr)))\n-    bitoffset = (tree_to_uhwi (DECL_FIELD_OFFSET (field))\n-\t\t - tree_to_uhwi (DECL_FIELD_OFFSET (repr))) * BITS_PER_UNIT;\n+  poly_uint64 field_offset, repr_offset;\n+  if (poly_int_tree_p (DECL_FIELD_OFFSET (field), &field_offset)\n+      && poly_int_tree_p (DECL_FIELD_OFFSET (repr), &repr_offset))\n+    bitoffset = (field_offset - repr_offset) * BITS_PER_UNIT;\n   else\n     bitoffset = 0;\n   bitoffset += (tree_to_uhwi (DECL_FIELD_BIT_OFFSET (field))\n@@ -4865,17 +4862,16 @@ get_bit_range (unsigned HOST_WIDE_INT *bitstart,\n   /* If the adjustment is larger than bitpos, we would have a negative bit\n      position for the lower bound and this may wreak havoc later.  Adjust\n      offset and bitpos to make the lower bound non-negative in that case.  */\n-  if (bitoffset > *bitpos)\n+  if (maybe_gt (bitoffset, *bitpos))\n     {\n-      HOST_WIDE_INT adjust = bitoffset - *bitpos;\n-      gcc_assert ((adjust % BITS_PER_UNIT) == 0);\n+      poly_int64 adjust_bits = upper_bound (bitoffset, *bitpos) - *bitpos;\n+      poly_int64 adjust_bytes = exact_div (adjust_bits, BITS_PER_UNIT);\n \n-      *bitpos += adjust;\n+      *bitpos += adjust_bits;\n       if (*offset == NULL_TREE)\n-\t*offset = size_int (-adjust / BITS_PER_UNIT);\n+\t*offset = size_int (-adjust_bytes);\n       else\n-\t*offset\n-\t  = size_binop (MINUS_EXPR, *offset, size_int (adjust / BITS_PER_UNIT));\n+\t*offset = size_binop (MINUS_EXPR, *offset, size_int (adjust_bytes));\n       *bitstart = 0;\n     }\n   else\n@@ -4988,9 +4984,9 @@ expand_assignment (tree to, tree from, bool nontemporal)\n       || TREE_CODE (TREE_TYPE (to)) == ARRAY_TYPE)\n     {\n       machine_mode mode1;\n-      HOST_WIDE_INT bitsize, bitpos;\n-      unsigned HOST_WIDE_INT bitregion_start = 0;\n-      unsigned HOST_WIDE_INT bitregion_end = 0;\n+      poly_int64 bitsize, bitpos;\n+      poly_uint64 bitregion_start = 0;\n+      poly_uint64 bitregion_end = 0;\n       tree offset;\n       int unsignedp, reversep, volatilep = 0;\n       tree tem;\n@@ -5000,11 +4996,11 @@ expand_assignment (tree to, tree from, bool nontemporal)\n \t\t\t\t &unsignedp, &reversep, &volatilep);\n \n       /* Make sure bitpos is not negative, it can wreak havoc later.  */\n-      if (bitpos < 0)\n+      if (maybe_lt (bitpos, 0))\n \t{\n \t  gcc_assert (offset == NULL_TREE);\n-\t  offset = size_int (bitpos >> LOG2_BITS_PER_UNIT);\n-\t  bitpos &= BITS_PER_UNIT - 1;\n+\t  offset = size_int (bits_to_bytes_round_down (bitpos));\n+\t  bitpos = num_trailing_bits (bitpos);\n \t}\n \n       if (TREE_CODE (to) == COMPONENT_REF\n@@ -5014,9 +5010,9 @@ expand_assignment (tree to, tree from, bool nontemporal)\n \t However, if we do not have a DECL_BIT_FIELD_TYPE but BITPOS or\n \t BITSIZE are not byte-aligned, there is no need to limit the range\n \t we can access.  This can occur with packed structures in Ada.  */\n-      else if (bitsize > 0\n-\t       && bitsize % BITS_PER_UNIT == 0\n-\t       && bitpos % BITS_PER_UNIT == 0)\n+      else if (maybe_gt (bitsize, 0)\n+\t       && multiple_p (bitsize, BITS_PER_UNIT)\n+\t       && multiple_p (bitpos, BITS_PER_UNIT))\n \t{\n \t  bitregion_start = bitpos;\n \t  bitregion_end = bitpos + bitsize - 1;\n@@ -5078,16 +5074,18 @@ expand_assignment (tree to, tree from, bool nontemporal)\n \n \t     This is only done for aligned data values, as these can\n \t     be expected to result in single move instructions.  */\n+\t  poly_int64 bytepos;\n \t  if (mode1 != VOIDmode\n-\t      && bitpos != 0\n-\t      && bitsize > 0\n-\t      && (bitpos % bitsize) == 0\n-\t      && (bitsize % GET_MODE_ALIGNMENT (mode1)) == 0\n+\t      && maybe_ne (bitpos, 0)\n+\t      && maybe_gt (bitsize, 0)\n+\t      && multiple_p (bitpos, BITS_PER_UNIT, &bytepos)\n+\t      && multiple_p (bitpos, bitsize)\n+\t      && multiple_p (bitsize, GET_MODE_ALIGNMENT (mode1))\n \t      && MEM_ALIGN (to_rtx) >= GET_MODE_ALIGNMENT (mode1))\n \t    {\n-\t      to_rtx = adjust_address (to_rtx, mode1, bitpos / BITS_PER_UNIT);\n+\t      to_rtx = adjust_address (to_rtx, mode1, bytepos);\n \t      bitregion_start = 0;\n-\t      if (bitregion_end >= (unsigned HOST_WIDE_INT) bitpos)\n+\t      if (known_ge (bitregion_end, poly_uint64 (bitpos)))\n \t\tbitregion_end -= bitpos;\n \t      bitpos = 0;\n \t    }\n@@ -5102,8 +5100,7 @@ expand_assignment (tree to, tree from, bool nontemporal)\n \t code contains an out-of-bounds access to a small array.  */\n       if (!MEM_P (to_rtx)\n \t  && GET_MODE (to_rtx) != BLKmode\n-\t  && (unsigned HOST_WIDE_INT) bitpos\n-\t     >= GET_MODE_PRECISION (GET_MODE (to_rtx)))\n+\t  && known_ge (bitpos, GET_MODE_PRECISION (GET_MODE (to_rtx))))\n \t{\n \t  expand_normal (from);\n \t  result = NULL;\n@@ -5114,25 +5111,26 @@ expand_assignment (tree to, tree from, bool nontemporal)\n \t  unsigned short mode_bitsize = GET_MODE_BITSIZE (GET_MODE (to_rtx));\n \t  if (TYPE_MODE (TREE_TYPE (from)) == GET_MODE (to_rtx)\n \t      && COMPLEX_MODE_P (GET_MODE (to_rtx))\n-\t      && bitpos == 0\n-\t      && bitsize == mode_bitsize)\n+\t      && known_eq (bitpos, 0)\n+\t      && known_eq (bitsize, mode_bitsize))\n \t    result = store_expr (from, to_rtx, false, nontemporal, reversep);\n-\t  else if (bitsize == mode_bitsize / 2\n-\t\t   && (bitpos == 0 || bitpos == mode_bitsize / 2))\n-\t    result = store_expr (from, XEXP (to_rtx, bitpos != 0), false,\n-\t\t\t\t nontemporal, reversep);\n-\t  else if (bitpos + bitsize <= mode_bitsize / 2)\n+\t  else if (known_eq (bitsize, mode_bitsize / 2)\n+\t\t   && (known_eq (bitpos, 0)\n+\t\t       || known_eq (bitpos, mode_bitsize / 2)))\n+\t    result = store_expr (from, XEXP (to_rtx, maybe_ne (bitpos, 0)),\n+\t\t\t\t false, nontemporal, reversep);\n+\t  else if (known_le (bitpos + bitsize, mode_bitsize / 2))\n \t    result = store_field (XEXP (to_rtx, 0), bitsize, bitpos,\n \t\t\t\t  bitregion_start, bitregion_end,\n \t\t\t\t  mode1, from, get_alias_set (to),\n \t\t\t\t  nontemporal, reversep);\n-\t  else if (bitpos >= mode_bitsize / 2)\n+\t  else if (known_ge (bitpos, mode_bitsize / 2))\n \t    result = store_field (XEXP (to_rtx, 1), bitsize,\n \t\t\t\t  bitpos - mode_bitsize / 2,\n \t\t\t\t  bitregion_start, bitregion_end,\n \t\t\t\t  mode1, from, get_alias_set (to),\n \t\t\t\t  nontemporal, reversep);\n-\t  else if (bitpos == 0 && bitsize == mode_bitsize)\n+\t  else if (known_eq (bitpos, 0) && known_eq (bitsize, mode_bitsize))\n \t    {\n \t      result = expand_normal (from);\n \t      if (GET_CODE (result) == CONCAT)"}, {"sha": "a260192788b7af937f3d5650de1a075b6cf08f70", "filename": "gcc/expr.h", "status": "modified", "additions": 2, "deletions": 11, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "patch": "@@ -240,17 +240,8 @@ extern bool emit_push_insn (rtx, machine_mode, tree, rtx, unsigned int,\n \t\t\t    int, rtx, int, rtx, rtx, int, rtx, bool);\n \n /* Extract the accessible bit-range from a COMPONENT_REF.  */\n-extern void get_bit_range (unsigned HOST_WIDE_INT *, unsigned HOST_WIDE_INT *,\n-\t\t\t   tree, HOST_WIDE_INT *, tree *);\n-\n-/* Temporary.  */\n-inline void\n-get_bit_range (poly_uint64_pod *bitstart, poly_uint64_pod *bitend, tree exp,\n-\t       poly_int64_pod *bitpos, tree *offset)\n-{\n-  get_bit_range (&bitstart->coeffs[0], &bitend->coeffs[0], exp,\n-\t\t &bitpos->coeffs[0], offset);\n-}\n+extern void get_bit_range (poly_uint64_pod *, poly_uint64_pod *, tree,\n+\t\t\t   poly_int64_pod *, tree *);\n \n /* Expand an assignment that stores the value of FROM into TO.  */\n extern void expand_assignment (tree, tree, bool);"}, {"sha": "0b3cba53ded9e99028478aa39338f16ccf2343f3", "filename": "gcc/fold-const.c", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39bb8924559d0487fb7cb6d4dc33d6b1e9c41004/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=39bb8924559d0487fb7cb6d4dc33d6b1e9c41004", "patch": "@@ -4076,12 +4076,13 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n    }\n \n   /* Honor the C++ memory model and mimic what RTL expansion does.  */\n-  unsigned HOST_WIDE_INT bitstart = 0;\n-  unsigned HOST_WIDE_INT bitend = 0;\n+  poly_uint64 bitstart = 0;\n+  poly_uint64 bitend = 0;\n   if (TREE_CODE (lhs) == COMPONENT_REF)\n     {\n-      get_bit_range (&bitstart, &bitend, lhs, &lbitpos, &offset);\n-      if (offset != NULL_TREE)\n+      poly_int64 plbitpos;\n+      get_bit_range (&bitstart, &bitend, lhs, &plbitpos, &offset);\n+      if (!plbitpos.is_constant (&lbitpos) || offset != NULL_TREE)\n \treturn 0;\n     }\n "}]}