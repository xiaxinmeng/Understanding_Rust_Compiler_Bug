{"sha": "38635499e9c759fc039e669acfabc80f4f65dffb", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Mzg2MzU0OTllOWM3NTlmYzAzOWU2NjlhY2ZhYmM4MGY0ZjY1ZGZmYg==", "commit": {"author": {"name": "Diego Novillo", "email": "dnovillo@gcc.gnu.org", "date": "2006-12-12T01:48:51Z"}, "committer": {"name": "Diego Novillo", "email": "dnovillo@gcc.gnu.org", "date": "2006-12-12T01:48:51Z"}, "message": "[multiple changes]\n\n2006-12-11  Diego Novillo  <dnovillo@redhat.com>\n\n\t* doc/tree-ssa.texi: Update documentation for virtual operands\n\tand the use of push_stmt_changes/pop_stmt_changes.\n\t* doc/invoke.texi: Remove documentation for params\n\tglobal-var-threshold.\n\tUpdate documentation on max-aliased-vops.\n\n\t* tree-into-ssa.c: Cleanup comments, variables and\n\tspacing in various functions.\n\t(regs_to_rename): Declare.\n\t(mem_syms_to_rename): Declare.\n\t(dump_update_ssa): Declare.\n\t(debug_update_ssa): Declare.\n\t(dump_names_replaced_by): Declare.\n\t(debug_names_replaced_by): Declare.\n\t(dump_def_blocks): Declare.\n\t(debug_def_blocks): Declare.\n\t(dump_defs_stack): Declare.\n\t(debug_defs_stack): Declare.\n\t(dump_currdefs): Declare.\n\t(debug_currdefs): Declare.\n\t(mark_def_sites): Do not handle virtual operands.\n\t(compute_idf): Rename from find_idf.  Update users.\n\t(register_new_def): Make local.  Convert second argument\n\tto 'tree'.\n\tUse BLOCK_DEFS_STACK directly.\n\tIf pushing a non-register, also push the underlying\n\tsymbol.\n\t(rewrite_stmt): Do not handle virtual operands.\n\t(dump_tree_ssa): Call dump_def_blocks, dump_defs_stack,\n\tdump_currdefs and dump_tree_ssa_stats.\n\t(dump_tree_ssa_stats): Also dump REPL_TBL.\n\t(replace_use): Remove.  Update all users to call SET_USE\n\tinstead.\n\t(rewrite_blocks): Move code to free memory to\n\tfini_ssa_renamer.\n\t(mark_def_site_blocks): Move initialization code to\n\tinit_ssa_renamer.\n\t(init_ssa_renamer): New.\n\t(fini_ssa_renamer): New.\n\t(rewrite_into_ssa): Call them.\n\t(prepare_block_for_update): Process SSA_OP_ALL_USES first\n\tand SSA_OP_ALL_DEFS later.  Do not process virtual\n\toperands separately.\n\t(dump_update_ssa): Call dump_decl_set.\n\t(init_update_ssa): Initialize regs_to_rename and\n\tmem_syms_to_rename.\n\tCall init_ssa_renamer.\n\t(delete_update_ssa): Call fini_ssa_renamer.\n\tFree blocks_with_phis_to_rewrite.\n\t(mark_sym_for_renaming): If the variable has\n\tsub-variables, also mark them.\n\tIf the variable belongs to a partition, also mark it.\n\t(mark_set_for_renaming): Call mark_sym_for_renaming on\n\tevery symbol in the set.\n\t(switch_virtuals_to_full_rewrite): Call\n\tmark_set_for_renaming.\n\t(update_ssa): Separate syms_to_rename into regs_to_rename\n\tand mem_syms_to_rename.\n\n\t* tree-dump.c (dump_options): Add TDF_MEMSYMS.\n\t* tree-pretty-print.c (debug_generic_expr): Add TDF_MEMSYMS.\n\t(debug_generic_stmt): Likewise.\n\t(debug_tree_chain): Likewise.\n\t(dump_symbols): New.\n\t(dump_generic_node): Check for TDF_MEMSYMS.\n\tHandle MEMORY_PARTITION_TAG.\n\tIf the statement references memory and TDF_MEMSYMS is\n\tgiven, call dump_symbols.\n\tIndicate default names with (D).\n\t(dump_vops): Update for new virtual operator format.\n\n\t* tree.c (init_ttree): Add MEMORY_PARTITION_TAG to\n\ttree_contains_struct.\n\t(tree_code_size): Handle MEMORY_PARTITION_TAG.\n\t(tree_node_structure): Likewise.\n\t(needs_to_live_in_memory): Handle SSA names.\n\t* tree.h (MTAG_P): Likewise.\n\t(struct tree_memory_partition_tag): Declare.\n\t(MPT_SYMBOLS): Define.\n\t(union tree_node): Add field 'mpt'.\n\t* treestruct.def (TS_MEMORY_PARTITION_TAG): Define.\n\t* tree.def (MEMORY_PARTITION_TAG): Define.\n\n\t* tree-pass.h (TDF_MEMSYMS): Define.\n\n\t* params.h (GLOBAL_VAR_THRESHOLD): Remove.\n\n\t* tree-ssa-alias.c: Include pointer-set.h\n\t(struct alias_map_d): Remove fields total_alias_vops,\n\tgrouped_p and may_aliases.  Update all users.\n\t(struct mp_info_def): Declare.\n\t(mp_info_t): New type.\n\t(get_smt_for): Rename from get_tmt_for.  Update all\n\tusers.\n\t(add_may_alias): Add argument ALREADY_ADDED.  If given,\n\tuse it to avoid adding duplicate entries to alias sets.\n\t(replace_may_alias): Remove.  Update all users.\n\t(total_alias_vops_cmp): Remove.  Update all users.\n\t(group_aliases_into): Remove.  Update all users.\n\t(tree_pointer_compare): Remove.  Update all users.\n\t(compact_name_tags): Remove.  Update all users.\n\t(group_aliases): Remove.  Update all users.\n\t(mark_non_addressable): Move from tree-flow-inline.h.\n\tRemove the symbol from the partition holding it, if\n\tneeded.\n\t(dump_mp_info): New.\n\t(debug_mp_info): New.\n\t(sort_mp_info): New.\n\t(create_partition_for): New.\n\t(rewrite_alias_set_for): New.\n\t(compute_memory_partitions): New.\n\t(compute_may_aliases): Call it.\n\t(init_alias_info): If computing aliases for the first\n\ttime, mark every memory symbol for renaming.\n\t(have_common_aliases_p): New.\n\t(compute_flow_insensitive_aliasing): Call it.\n\t(setup_pointers_and_addressables): Do not cache\n\tnum_referenced_vars.\n\tFor register promoted symbols, mark their former\n\tpartition for renaming.\n\t(maybe_create_global_var): Only create .GLOBAL_VAR if\n\tthere are no call-clobbered variables and a mix of pure\n\tand non-pure functions were found.\n\t(may_alias_p): Tidy comments.\n\t(create_tag_raw): Remove unused variable new_type.\n\t(dump_alias_info): call dump_memory_partitions.\n\t(dump_points_to_info_for): Call dump_decl_set.\n\t(may_be_aliased): Tidy comments and formatting.\n\n\t* timevar.def (TV_MEMORY_PARTITIONING): Define.\n\t* tree-vectorizer.c (vect_memsyms_to_rename): Rename from\n\tvect_vnames_to_rename.  Set DECL_UIDs instead of SSA name\n\tversions in it.\n\t(slpeel_update_phi_nodes_for_guard1): Ignore memory PHIs.\n\t* tree-vect-transform.c (vect_transform_loop): Call\n\tmark_set_for_renaming with vect_memsyms_to_rename.\n\t* tree-flow-inline.h (zero_imm_uses_p): New.\n\t(memory_partition): New.\n\t(set_memory_partition): New.\n\t(factoring_name_p): New.\n\t(symbol_mem_tag): New.  Update every function that used\n\tto access the annotation directly.\n\t(set_symbol_mem_tag): Likewise.\n\n\t* tree-ssa-copy.c (may_propagate_copy): Allow copies\n\tbetween a partition and a symbol as long as the symbol\n\tbelongs to the partition.\n\t(merge_alias_info): Ignore merge requests when memory\n\tpartitions are involved.\n\n\t* tree-ssa.c (verify_ssa_name): Check that default\n\tdefinitions have empty defining statements.\n\t(verify_use): Remove argument IS_VIRTUAL.\n\tDon't call verify_ssa_name.\n\t(verify_phi_args): Call verify_ssa_name.\n\t(verify_flow_insensitive_alias_info): Handle MPTs.\n\t(verify_flow_sensitive_alias_info): Likewise.\n\t(verify_name_tags): Likewise.\n\t(verify_call_clobbering): Likewise.\n\t(verify_ssa): Check for VOPs only after aliasing\n\tinformation is available.\n\tCheck virtuals and real operands separately.\n\tCall verify_ssa_name on every operand.\n\t(stmt_references_memory_p): Move to tree-ssa-operands.c.\n\t(walk_use_def_chains_1): Guard against NULL PHI\n\targuments.\n\n\t* tree-ssa-operands.c (stmt_references_memory_p): Move from\n\ttree-ssa.c.\n\t(get_mpt_for): New.\n\t(dump_memory_partitions): New.\n\t(debug_memory_partitions): New.\n\n\t* tree-flow.h (struct var_ann_d): Add field mpt.\n\t(struct stmt_ann_d): Add bitfield references_memory.\n\t* Makefile.in (tree-ssa-structalias.o): Include\n\tpointer-set.h\n\t(tree-ssa-alias.o): Likewise.\n\t* tree-ssa-structalias.c: (update_alias_info): Use\n\tSTORED_SYMS to determine which variables are being\n\twritten to by the store operation.\n\t* tree-ssa-structalias.h (struct alias_info)\n\t<total_alias_vops>: Remove.  Update all users.\n\t<written_vars>: Change to a pointer set.  Update all\n\tusers.\n\t<dereferenced_ptrs_store>: Likewise.\n\t<dereferenced_ptrs_load>: Likewise.\n\t(NUM_REFERENCES): Remove.  Update all users.\n\t(NUM_REFERENCES_CLEAR): Remove.  Update all users.\n\t(NUM_REFERENCES_INC): Remove.  Update all users.\n\t(NUM_REFERENCES_SET): Remove.  Update all users.\n\n\t* params.def (PARAM_GLOBAL_VAR_THRESHOLD): Remove.\n\tUpdate all users.\n\t(PARAM_MAX_ALIASED_VOPS): Set to 10.\n\t* tree-ssanames.c (make_ssa_name): Initialize\n\tSSA_NAME_IS_DEFAULT_DEF to 0.\n\n2006-12-11  Aldy Hernandez  <aldyh@redhat.com>\n\n\t* tree-ssa-dse.c (aggregate_vardecl_d): New.\n\t(dse_global_data): Add aggregate_vardecl field.\n\t(dse_possible_dead_store_p): New.\n\tAdd prev_defvar variable.\n\tAllow immediate uses and previous immediate uses to differ\n\tif they are setting different parts of the whole.\n\t(get_aggregate_vardecl): New.\n\t(dse_record_partial_aggregate_store): New.\n\t(dse_whole_aggregate_clobbered_p): New.\n\t(dse_partial_kill_p): New.\n\t(dse_optimize_stmt): Abstract code checking a possible dead store\n\tinto new function dse_possible_dead_store_p().\n\tCall dse_maybe_record_aggregate_store().\n\tWhen checking whether a STMT and its USE_STMT refer to the\n\tsame memory address, check also for partial kills that clobber\n\tthe whole.\n\tMove some variable definitions to the block where they are used.\n\t(aggregate_vardecl_hash): New.\n\t(aggregate_vardecl_eq): New.\n\t(aggregate_vardecl_free): New.\n\t(aggregate_whole_store_p): New.\n\t(tree_ssa_dse): Initialize and free aggregate_vardecl.\n\tMark which aggregate stores we care about.\n\n2006-12-11  Andrew Macleod  <amacleod@redhat.com>\n\n\t* tree-ssa-operands.h (struct vuse_element_d): Declare.\n\t(vuse_element_t): Declare.\n\t(struct vuse_vec_d): Declare.\n\t(vuse_vec_p): Declare.\n\t(VUSE_VECT_NUM_ELEM): Define.\n\t(VUSE_VECT_ELEMENT_NC): Define.\n\t(VUSE_ELEMENT_PTR_NC): Define.\n\t(VUSE_ELEMENT_VAR_NC): Define.\n\t(VUSE_VECT_ELEMENT): Define.\n\t(VUSE_ELEMENT_PTR): Define.\n\t(VUSE_ELEMENT_VAR): Define.\n\t(struct maydef_optype_d) <use_var>: Remove.\n\t<use_ptr>: Remove.\n\t<usev>: Add.\n\t(struct vuse_optype_d) <kill_var>: Remove.\n\t<use_ptr>: Remove.\n\t<usev>: Add.\n\t(struct mustdef_optype_d) <kill_var>: Remove.\n\t<use_ptr>: Remove.\n\t<usev>: Add.\n\t(VUSE_OP_PTR): Add argument.  Use VUSE_ELEMENT_PTR.\n\t(VUSE_OP): Add argument.  Use VUSE_ELEMENT_PTR.\n\t(VUSE_NUM): Define.\n\t(VUSE_VECT): Define.\n\t(MAYDEF_OP_PTR): Add argument.  Use VUSE_OP_PTR.\n\t(MAYDEF_OP): Add argument.  Use VUSE_OP.\n\t(MAYDEF_NUM): Define.\n\t(MAYDEF_VECT): Define.\n\t(MUSTDEF_KILL_PTR): Use VUSE_OP_PTR.\n\t(MUSTDEF_KILL): Use VUSE_OP.\n\t(MUSTDEF_NUM): Define.\n\t(MUSTDEF_VECT): Define.\n\t(realloc_maydef): Declare.\n\t(realloc_vuse): Declare.\n\t(struct ssa_operand_iterator_d) <vuse_index>: Add.\n\t<mayuse_index>: Add.\n\t(LOADED_SYMS): Define.\n\t(STORED_SYMS): Define.\n\t(FOR_EACH_SSA_MUSTDEF_OPERAND): Call op_iter_next_mustdef.\n\t* tree-into-ssa.c: Adapt for multi-operand V_MAY_DEF and VUSE\n\toperators.\n\t* tree-pretty-print.c: Likewise.\n\t* tree-ssa-dse.c: Likewise.\n\t* tree-flow-inline.h: Likewise.\n\t(op_iter_next_mustdef): New.\n\t* tree-ssa-operands.c: Likewise.\n\t(ALLOC_OPTYPE): Remove.\n\tUpdate all users.\n\t(alloc_def): New.\n\t(alloc_use): New.\n\t(alloc_maydef): New.\n\t(alloc_vuse): New.\n\t(alloc_mustdef): New.\n\t(realloc_maydef): New.\n\t(realloc_vuse): New.\n\n2006-12-11  Aldy Hernandez  <aldyh@redhat.com>\n\n\t* tree-ssa-operands.c: Remove build_v_must_defs.\n\t(init_ssa_operands): Delete build_v_must_defs.\n\t(finalize_ssa_v_must_def_ops): Remove.\n\t(finalize_ssa_v_must_defs): Remove.\n\t(finalize_ssa_stmt_operands): Do not call\n\tfinalize_ssa_v_must_defs.\n\t(start_ssa_stmt_operands): Do not check build_v_must_defs.\n\t(append_v_must_def): Delete.\n\t(copy_virtual_operands): Do not copy V_MUST_DEFs.\n\t(get_modify_expr_operands): Remove reference to V_MUST_DEF from\n\tcomment.  Remove opf_kill_def.\n\t(build_ssa_operands): Remove references to v_must_defs.\n\t(copy_virtual_operands): Same.\n\t(copy_virtual_operands): Same.\n\t(fini_ssa_operands): Same.\n\t(free_ssa_operands): Same.\n\t(add_mustdef_op): Remove.\n\tRemove mustdef_optype_p.\n\t(alloc_mustdef): Remove.\n\tRemove references to V_MUST_DEFs in comment at top of file.\n\t(get_expr_operands): Remove opf_kill_def.\n\t(opf_kill_def): Remove.\n\t(add_virtual_operand): Remove opf_kill_def.\n\t(get_indirect_ref_operands): Same.\n\t(get_tmr_operands): Same.\n\n\t* tree-vectorizer.c (rename_variables_in_bb): Remove\n\tSSA_OP_ALL_KILLS.\n\n\t* tree-ssa-loop-manip.c (find_uses_to_rename_stmt): Remove\n\tSSA_OP_ALL_KILLS.\n\t(check_loop_closed_ssa_stmt): Same.\n\n\t* tree-ssa.c (verify_def): Remove V_MUST_DEF from comment.\n\t(verify_use): Same.\n\t(verify_ssa): Remove V_MUST_DEFs traces.\n\t(verify_ssa): Remove SSA_OP_ALL_KILLS.\n\n\t* tree-into-ssa.c (mark_def_sites): Change SSA_OP_VMUSTDEF to\n\tSSA_OP_VMAYDEF.\n\t(rewrite_update_stmt): Remove SSA_OP_VIRTUAL_KILLS.\n\t(rewrite_stmt): Remove SSA_OP_ALL_KILLS.\n\n\t* tree-ssa-operands.h (struct stmt_operands_d): Remove V_MUST_DEF\n\treferences.\n\t(MUSTDEF_OPS): Remove.\n\t(SSA_OP_VMUSTDEF): Remove.\n\t(FOR_EACH_SSA_MUSTDEF_OPERAND): Remove.\n\t(struct mustdef_optype_d): Remove.\n\tRemove mustdef_optype_p.\n\t(struct stmt_operands_d): Remove mustdef_ops.\n\t(ssa_operand_iterator_d): Remove mustdefs and mustkills.\n\t(SSA_OP_VIRTUAL_DEFS): Remove SSA_OP_VMUSTDEF.\n\t(MUSTDEF_RESULT_PTR): Remove.\n\t(MUSTDEF_RESULT): Remove.\n\t(MUSTDEF_KILL_PTR): Remove.\n\t(MUSTDEF_KILL): Remove.\n\t(MUSTDEF_NUM): Remove.\n\t(MUSTDEF_VECT): Remove.\n\t(SSA_OP_VIRTUAL_KILLS): Remove.\n\t(SSA_OP_ALL_VIRTUALS): Remove SSA_OP_VIRTUAL_KILLS.\n\t(SSA_OP_VMUSTKILL): Remove.\n\t(SSA_OP_ALL_KILLS): Remove.\n\t(SSA_OP_ALL_OPERANDS): Remove SSA_OP_ALL_KILLS.\n\n\t* tree-flow-inline.h (op_iter_init_def): Remove\n\tSSA_OP_VIRTUAL_KILLS.\n\t(delink_stmt_imm_use): Remove SSA_OP_ALL_KILLS.\n\n\t* tree-ssa-pre.c (compute_rvuse_and_antic_safe): Remove\n\tSSA_OP_VIRTUAL_KILLS.\n\n\t* tree-ssa-loop-im.c (determine_max_movement): Remove\n\tSSA_OP_VIRTUAL_KILLS.\n\t(gather_mem_refs_stmt): Same.\n\t(gather_mem_refs_stmt): Same.\n\n\t* tree-ssa-dce.c (mark_really_necessary_kill_operand_phis): Delete.\n\t(perform_tree_ssa_dce): Remove call to\n\tmark_really_necessary_kill_operand_phis.\n\n\t* tree-flow-inline.h (op_iter_init): Remove setting of mustdefs\n\tand mustkills.\n\t(op_iter_next_use): Do not check mustkills.\n\t(op_iter_next_def): Do not check mustdefs.\n\t(op_iter_next_tree): Do not check mustkills or mustdefs.\n\t(clear_and_done_ssa_iter): Do not set mustdefs or mustkills.\n\t(op_iter_next_maymustdef): Do not check mustkills.\n\t(op_iter_init_must_and_may_def): Remove SSA_OP_VMUSTKILL.\n\t(op_iter_init_mustdef): Remove.\n\n\t* tree-ssa-live.c (create_ssa_var_map): Change SSA_OP_VMUSTDEF to\n\tSSA_OP_VMAYDEF.\n\n\t* tree-ssa-dse.c (dse_optimize_stmt): Remove SSA_OP_VMUSTDEF.\n\n\t* tree-ssa-ccp.c: Remove V_MUST_DEF traces from comments.\n\t(visit_assignment): Same.\n\n\t* tree-ssa-copy.c (copy_prop_visit_assignment): Same.\n\n\t* tree-sra.c (mark_all_v_defs_1): Remove V_MUST_DEF from comment.\n\n\t* tree-outof-ssa.c (check_replaceable): Remove SSA_OP_VMUSTDEF.\n\n\t* tree-pretty-print.c (dump_vops): Remove printing of V_MUST_DEF.\n\tRemove kill_p variable.\n\n\t* tree-dfa.c (struct dfa_stats_d): Remove num_v_must_defs.\n\t(dump_dfa_stats): Remove code related to V_MUST_DEFs.\n\t(collect_dfa_stats_r): Do not set num_v_must_defs.\n\t(mark_new_vars_to_rename): Remove v_must_defs_{before,after}\n\tcode.\n\n\t* tree-into-ssa.c (mark_def_sites): Change SSA_OP_VMUSTKILL to\n\tSSA_OP_VMAYUSE.\n\n\t* tree-ssa-pre.c (compute_rvuse_and_antic_safe): Remove\n\tSSA_OP_VMUSTDEF and SSA_OP_VMUSTKILL.\n\n\t* tree-ssa-propagate.c (stmt_makes_single_store): Remove\n\tSSA_OP_VMUSTDEF.\n\nFrom-SVN: r119760", "tree": {"sha": "f22894dcace757df7efc32d1fcf9bd31217c3959", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f22894dcace757df7efc32d1fcf9bd31217c3959"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/38635499e9c759fc039e669acfabc80f4f65dffb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/38635499e9c759fc039e669acfabc80f4f65dffb", "html_url": "https://github.com/Rust-GCC/gccrs/commit/38635499e9c759fc039e669acfabc80f4f65dffb", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/38635499e9c759fc039e669acfabc80f4f65dffb/comments", "author": null, "committer": null, "parents": [{"sha": "419cb3431be4a266e61762978fbe279af6ddc028", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/419cb3431be4a266e61762978fbe279af6ddc028", "html_url": "https://github.com/Rust-GCC/gccrs/commit/419cb3431be4a266e61762978fbe279af6ddc028"}], "stats": {"total": 5622, "additions": 3466, "deletions": 2156}, "files": [{"sha": "5111278f5169134470c4b27f10b946e7bbcd9a3d", "filename": "gcc/ChangeLog", "status": "modified", "additions": 409, "deletions": 0, "changes": 409, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1,3 +1,412 @@\n+2006-12-11  Diego Novillo  <dnovillo@redhat.com>\n+\n+\t* doc/tree-ssa.texi: Update documentation for virtual operands\n+\tand the use of push_stmt_changes/pop_stmt_changes.\n+\t* doc/invoke.texi: Remove documentation for params\n+\tglobal-var-threshold.\n+\tUpdate documentation on max-aliased-vops.\n+\n+\t* tree-into-ssa.c: Cleanup comments, variables and\n+\tspacing in various functions.\n+\t(regs_to_rename): Declare.\n+\t(mem_syms_to_rename): Declare.\n+\t(dump_update_ssa): Declare.\n+\t(debug_update_ssa): Declare.\n+\t(dump_names_replaced_by): Declare.\n+\t(debug_names_replaced_by): Declare.\n+\t(dump_def_blocks): Declare.\n+\t(debug_def_blocks): Declare.\n+\t(dump_defs_stack): Declare.\n+\t(debug_defs_stack): Declare.\n+\t(dump_currdefs): Declare.\n+\t(debug_currdefs): Declare.\n+\t(mark_def_sites): Do not handle virtual operands.\n+\t(compute_idf): Rename from find_idf.  Update users.\n+\t(register_new_def): Make local.  Convert second argument\n+\tto 'tree'.\n+\tUse BLOCK_DEFS_STACK directly.\n+\tIf pushing a non-register, also push the underlying\n+\tsymbol.\n+\t(rewrite_stmt): Do not handle virtual operands.\n+\t(dump_tree_ssa): Call dump_def_blocks, dump_defs_stack,\n+\tdump_currdefs and dump_tree_ssa_stats.\n+\t(dump_tree_ssa_stats): Also dump REPL_TBL.\n+\t(replace_use): Remove.  Update all users to call SET_USE\n+\tinstead.\n+\t(rewrite_blocks): Move code to free memory to\n+\tfini_ssa_renamer.\n+\t(mark_def_site_blocks): Move initialization code to\n+\tinit_ssa_renamer.\n+\t(init_ssa_renamer): New.\n+\t(fini_ssa_renamer): New.\n+\t(rewrite_into_ssa): Call them.\n+\t(prepare_block_for_update): Process SSA_OP_ALL_USES first\n+\tand SSA_OP_ALL_DEFS later.  Do not process virtual\n+\toperands separately.\n+\t(dump_update_ssa): Call dump_decl_set.\n+\t(init_update_ssa): Initialize regs_to_rename and\n+\tmem_syms_to_rename.\n+\tCall init_ssa_renamer.\n+\t(delete_update_ssa): Call fini_ssa_renamer.\n+\tFree blocks_with_phis_to_rewrite.\n+\t(mark_sym_for_renaming): If the variable has\n+\tsub-variables, also mark them.\n+\tIf the variable belongs to a partition, also mark it.\n+\t(mark_set_for_renaming): Call mark_sym_for_renaming on\n+\tevery symbol in the set.\n+\t(switch_virtuals_to_full_rewrite): Call\n+\tmark_set_for_renaming.\n+\t(update_ssa): Separate syms_to_rename into regs_to_rename\n+\tand mem_syms_to_rename.\n+\n+\t* tree-dump.c (dump_options): Add TDF_MEMSYMS.\n+\t* tree-pretty-print.c (debug_generic_expr): Add TDF_MEMSYMS.\n+\t(debug_generic_stmt): Likewise.\n+\t(debug_tree_chain): Likewise.\n+\t(dump_symbols): New.\n+\t(dump_generic_node): Check for TDF_MEMSYMS.\n+\tHandle MEMORY_PARTITION_TAG.\n+\tIf the statement references memory and TDF_MEMSYMS is\n+\tgiven, call dump_symbols.\n+\tIndicate default names with (D).\n+\t(dump_vops): Update for new virtual operator format.\n+\n+\t* tree.c (init_ttree): Add MEMORY_PARTITION_TAG to\n+\ttree_contains_struct.\n+\t(tree_code_size): Handle MEMORY_PARTITION_TAG.\n+\t(tree_node_structure): Likewise.\n+\t(needs_to_live_in_memory): Handle SSA names.\n+\t* tree.h (MTAG_P): Likewise.\n+\t(struct tree_memory_partition_tag): Declare.\n+\t(MPT_SYMBOLS): Define.\n+\t(union tree_node): Add field 'mpt'.\n+\t* treestruct.def (TS_MEMORY_PARTITION_TAG): Define.\n+\t* tree.def (MEMORY_PARTITION_TAG): Define.\n+\n+\t* tree-pass.h (TDF_MEMSYMS): Define.\n+\n+\t* params.h (GLOBAL_VAR_THRESHOLD): Remove.\n+\n+\t* tree-ssa-alias.c: Include pointer-set.h\n+\t(struct alias_map_d): Remove fields total_alias_vops,\n+\tgrouped_p and may_aliases.  Update all users.\n+\t(struct mp_info_def): Declare.\n+\t(mp_info_t): New type.\n+\t(get_smt_for): Rename from get_tmt_for.  Update all\n+\tusers.\n+\t(add_may_alias): Add argument ALREADY_ADDED.  If given,\n+\tuse it to avoid adding duplicate entries to alias sets.\n+\t(replace_may_alias): Remove.  Update all users.\n+\t(total_alias_vops_cmp): Remove.  Update all users.\n+\t(group_aliases_into): Remove.  Update all users.\n+\t(tree_pointer_compare): Remove.  Update all users.\n+\t(compact_name_tags): Remove.  Update all users.\n+\t(group_aliases): Remove.  Update all users.\n+\t(mark_non_addressable): Move from tree-flow-inline.h.\n+\tRemove the symbol from the partition holding it, if\n+\tneeded.\n+\t(dump_mp_info): New.\n+\t(debug_mp_info): New.\n+\t(sort_mp_info): New.\n+\t(create_partition_for): New.\n+\t(rewrite_alias_set_for): New.\n+\t(compute_memory_partitions): New.\n+\t(compute_may_aliases): Call it.\n+\t(init_alias_info): If computing aliases for the first\n+\ttime, mark every memory symbol for renaming.\n+\t(have_common_aliases_p): New.\n+\t(compute_flow_insensitive_aliasing): Call it.\n+\t(setup_pointers_and_addressables): Do not cache\n+\tnum_referenced_vars.\n+\tFor register promoted symbols, mark their former\n+\tpartition for renaming.\n+\t(maybe_create_global_var): Only create .GLOBAL_VAR if\n+\tthere are no call-clobbered variables and a mix of pure\n+\tand non-pure functions were found.\n+\t(may_alias_p): Tidy comments.\n+\t(create_tag_raw): Remove unused variable new_type.\n+\t(dump_alias_info): call dump_memory_partitions.\n+\t(dump_points_to_info_for): Call dump_decl_set.\n+\t(may_be_aliased): Tidy comments and formatting.\n+\n+\t* timevar.def (TV_MEMORY_PARTITIONING): Define.\n+\t* tree-vectorizer.c (vect_memsyms_to_rename): Rename from\n+\tvect_vnames_to_rename.  Set DECL_UIDs instead of SSA name\n+\tversions in it.\n+\t(slpeel_update_phi_nodes_for_guard1): Ignore memory PHIs.\n+\t* tree-vect-transform.c (vect_transform_loop): Call\n+\tmark_set_for_renaming with vect_memsyms_to_rename.\n+\t* tree-flow-inline.h (zero_imm_uses_p): New.\n+\t(memory_partition): New.\n+\t(set_memory_partition): New.\n+\t(factoring_name_p): New.\n+\t(symbol_mem_tag): New.  Update every function that used\n+\tto access the annotation directly.\n+\t(set_symbol_mem_tag): Likewise.\n+\n+\t* tree-ssa-copy.c (may_propagate_copy): Allow copies\n+\tbetween a partition and a symbol as long as the symbol\n+\tbelongs to the partition.\n+\t(merge_alias_info): Ignore merge requests when memory\n+\tpartitions are involved.\n+\n+\t* tree-ssa.c (verify_ssa_name): Check that default\n+\tdefinitions have empty defining statements.\n+\t(verify_use): Remove argument IS_VIRTUAL.\n+\tDon't call verify_ssa_name.\n+\t(verify_phi_args): Call verify_ssa_name.\n+\t(verify_flow_insensitive_alias_info): Handle MPTs.\n+\t(verify_flow_sensitive_alias_info): Likewise.\n+\t(verify_name_tags): Likewise.\n+\t(verify_call_clobbering): Likewise.\n+\t(verify_ssa): Check for VOPs only after aliasing\n+\tinformation is available.\n+\tCheck virtuals and real operands separately.\n+\tCall verify_ssa_name on every operand.\n+\t(stmt_references_memory_p): Move to tree-ssa-operands.c.\n+\t(walk_use_def_chains_1): Guard against NULL PHI\n+\targuments.\n+\n+\t* tree-ssa-operands.c (stmt_references_memory_p): Move from\n+\ttree-ssa.c.\n+\t(get_mpt_for): New.\n+\t(dump_memory_partitions): New.\n+\t(debug_memory_partitions): New.\n+\n+\t* tree-flow.h (struct var_ann_d): Add field mpt.\n+\t(struct stmt_ann_d): Add bitfield references_memory.\n+\t* Makefile.in (tree-ssa-structalias.o): Include\n+\tpointer-set.h\n+\t(tree-ssa-alias.o): Likewise.\n+\t* tree-ssa-structalias.c: (update_alias_info): Use\n+\tSTORED_SYMS to determine which variables are being\n+\twritten to by the store operation.\n+\t* tree-ssa-structalias.h (struct alias_info)\n+\t<total_alias_vops>: Remove.  Update all users.\n+\t<written_vars>: Change to a pointer set.  Update all\n+\tusers.\n+\t<dereferenced_ptrs_store>: Likewise.\n+\t<dereferenced_ptrs_load>: Likewise.\n+\t(NUM_REFERENCES): Remove.  Update all users.\n+\t(NUM_REFERENCES_CLEAR): Remove.  Update all users.\n+\t(NUM_REFERENCES_INC): Remove.  Update all users.\n+\t(NUM_REFERENCES_SET): Remove.  Update all users.\n+\n+\t* params.def (PARAM_GLOBAL_VAR_THRESHOLD): Remove.\n+\tUpdate all users.\n+\t(PARAM_MAX_ALIASED_VOPS): Set to 10.\n+\t* tree-ssanames.c (make_ssa_name): Initialize\n+\tSSA_NAME_IS_DEFAULT_DEF to 0.\n+\n+2006-12-11  Aldy Hernandez  <aldyh@redhat.com>\n+\n+\t* tree-ssa-dse.c (aggregate_vardecl_d): New.\n+\t(dse_global_data): Add aggregate_vardecl field.\n+\t(dse_possible_dead_store_p): New.\n+\tAdd prev_defvar variable.\n+\tAllow immediate uses and previous immediate uses to differ\n+\tif they are setting different parts of the whole.\n+\t(get_aggregate_vardecl): New.\n+\t(dse_record_partial_aggregate_store): New.\n+\t(dse_whole_aggregate_clobbered_p): New.\n+\t(dse_partial_kill_p): New.\n+\t(dse_optimize_stmt): Abstract code checking a possible dead store\n+\tinto new function dse_possible_dead_store_p().\n+\tCall dse_maybe_record_aggregate_store().\n+\tWhen checking whether a STMT and its USE_STMT refer to the\n+\tsame memory address, check also for partial kills that clobber\n+\tthe whole.\n+\tMove some variable definitions to the block where they are used.\n+\t(aggregate_vardecl_hash): New.\n+\t(aggregate_vardecl_eq): New.\n+\t(aggregate_vardecl_free): New.\n+\t(aggregate_whole_store_p): New.\n+\t(tree_ssa_dse): Initialize and free aggregate_vardecl.\n+\tMark which aggregate stores we care about.\n+\n+2006-12-11  Andrew Macleod  <amacleod@redhat.com>\n+\n+\t* tree-ssa-operands.h (struct vuse_element_d): Declare.\n+\t(vuse_element_t): Declare.\n+\t(struct vuse_vec_d): Declare.\n+\t(vuse_vec_p): Declare.\n+\t(VUSE_VECT_NUM_ELEM): Define.\n+\t(VUSE_VECT_ELEMENT_NC): Define.\n+\t(VUSE_ELEMENT_PTR_NC): Define.\n+\t(VUSE_ELEMENT_VAR_NC): Define.\n+\t(VUSE_VECT_ELEMENT): Define.\n+\t(VUSE_ELEMENT_PTR): Define.\n+\t(VUSE_ELEMENT_VAR): Define.\n+\t(struct maydef_optype_d) <use_var>: Remove.\n+\t<use_ptr>: Remove.\n+\t<usev>: Add.\n+\t(struct vuse_optype_d) <kill_var>: Remove.\n+\t<use_ptr>: Remove.\n+\t<usev>: Add.\n+\t(struct mustdef_optype_d) <kill_var>: Remove.\n+\t<use_ptr>: Remove.\n+\t<usev>: Add.\n+\t(VUSE_OP_PTR): Add argument.  Use VUSE_ELEMENT_PTR.\n+\t(VUSE_OP): Add argument.  Use VUSE_ELEMENT_PTR.\n+\t(VUSE_NUM): Define.\n+\t(VUSE_VECT): Define.\n+\t(MAYDEF_OP_PTR): Add argument.  Use VUSE_OP_PTR.\n+\t(MAYDEF_OP): Add argument.  Use VUSE_OP.\n+\t(MAYDEF_NUM): Define.\n+\t(MAYDEF_VECT): Define.\n+\t(MUSTDEF_KILL_PTR): Use VUSE_OP_PTR.\n+\t(MUSTDEF_KILL): Use VUSE_OP.\n+\t(MUSTDEF_NUM): Define.\n+\t(MUSTDEF_VECT): Define.\n+\t(realloc_maydef): Declare.\n+\t(realloc_vuse): Declare.\n+\t(struct ssa_operand_iterator_d) <vuse_index>: Add.\n+\t<mayuse_index>: Add.\n+\t(LOADED_SYMS): Define.\n+\t(STORED_SYMS): Define.\n+\t(FOR_EACH_SSA_MUSTDEF_OPERAND): Call op_iter_next_mustdef.\n+\t* tree-into-ssa.c: Adapt for multi-operand V_MAY_DEF and VUSE\n+\toperators.\n+\t* tree-pretty-print.c: Likewise.\n+\t* tree-ssa-dse.c: Likewise.\n+\t* tree-flow-inline.h: Likewise.\n+\t(op_iter_next_mustdef): New.\n+\t* tree-ssa-operands.c: Likewise.\n+\t(ALLOC_OPTYPE): Remove.\n+\tUpdate all users.\n+\t(alloc_def): New.\n+\t(alloc_use): New.\n+\t(alloc_maydef): New.\n+\t(alloc_vuse): New.\n+\t(alloc_mustdef): New.\n+\t(realloc_maydef): New.\n+\t(realloc_vuse): New.\n+\n+2006-12-11  Aldy Hernandez  <aldyh@redhat.com>\n+\n+\t* tree-ssa-operands.c: Remove build_v_must_defs.\n+\t(init_ssa_operands): Delete build_v_must_defs.\n+\t(finalize_ssa_v_must_def_ops): Remove.\n+\t(finalize_ssa_v_must_defs): Remove.\n+\t(finalize_ssa_stmt_operands): Do not call\n+\tfinalize_ssa_v_must_defs.\n+\t(start_ssa_stmt_operands): Do not check build_v_must_defs.\n+\t(append_v_must_def): Delete.\n+\t(copy_virtual_operands): Do not copy V_MUST_DEFs.\n+\t(get_modify_expr_operands): Remove reference to V_MUST_DEF from\n+\tcomment.  Remove opf_kill_def.\n+\t(build_ssa_operands): Remove references to v_must_defs.\n+\t(copy_virtual_operands): Same.\n+\t(copy_virtual_operands): Same.\n+\t(fini_ssa_operands): Same.\n+\t(free_ssa_operands): Same.\n+\t(add_mustdef_op): Remove.\n+\tRemove mustdef_optype_p.\n+\t(alloc_mustdef): Remove.\n+\tRemove references to V_MUST_DEFs in comment at top of file.\n+\t(get_expr_operands): Remove opf_kill_def.\n+\t(opf_kill_def): Remove.\n+\t(add_virtual_operand): Remove opf_kill_def.\n+\t(get_indirect_ref_operands): Same.\n+\t(get_tmr_operands): Same.\n+\n+\t* tree-vectorizer.c (rename_variables_in_bb): Remove\n+\tSSA_OP_ALL_KILLS.\n+\n+\t* tree-ssa-loop-manip.c (find_uses_to_rename_stmt): Remove\n+\tSSA_OP_ALL_KILLS.\n+\t(check_loop_closed_ssa_stmt): Same.\n+\n+\t* tree-ssa.c (verify_def): Remove V_MUST_DEF from comment.\n+\t(verify_use): Same.\n+\t(verify_ssa): Remove V_MUST_DEFs traces.\n+\t(verify_ssa): Remove SSA_OP_ALL_KILLS.\n+\n+\t* tree-into-ssa.c (mark_def_sites): Change SSA_OP_VMUSTDEF to\n+\tSSA_OP_VMAYDEF.\n+\t(rewrite_update_stmt): Remove SSA_OP_VIRTUAL_KILLS.\n+\t(rewrite_stmt): Remove SSA_OP_ALL_KILLS.\n+\n+\t* tree-ssa-operands.h (struct stmt_operands_d): Remove V_MUST_DEF\n+\treferences.\n+\t(MUSTDEF_OPS): Remove.\n+\t(SSA_OP_VMUSTDEF): Remove.\n+\t(FOR_EACH_SSA_MUSTDEF_OPERAND): Remove.\n+\t(struct mustdef_optype_d): Remove.\n+\tRemove mustdef_optype_p.\n+\t(struct stmt_operands_d): Remove mustdef_ops.\n+\t(ssa_operand_iterator_d): Remove mustdefs and mustkills.\n+\t(SSA_OP_VIRTUAL_DEFS): Remove SSA_OP_VMUSTDEF.\n+\t(MUSTDEF_RESULT_PTR): Remove.\n+\t(MUSTDEF_RESULT): Remove.\n+\t(MUSTDEF_KILL_PTR): Remove.\n+\t(MUSTDEF_KILL): Remove.\n+\t(MUSTDEF_NUM): Remove.\n+\t(MUSTDEF_VECT): Remove.\n+\t(SSA_OP_VIRTUAL_KILLS): Remove.\n+\t(SSA_OP_ALL_VIRTUALS): Remove SSA_OP_VIRTUAL_KILLS.\n+\t(SSA_OP_VMUSTKILL): Remove.\n+\t(SSA_OP_ALL_KILLS): Remove.\n+\t(SSA_OP_ALL_OPERANDS): Remove SSA_OP_ALL_KILLS.\n+\n+\t* tree-flow-inline.h (op_iter_init_def): Remove\n+\tSSA_OP_VIRTUAL_KILLS.\n+\t(delink_stmt_imm_use): Remove SSA_OP_ALL_KILLS.\n+\n+\t* tree-ssa-pre.c (compute_rvuse_and_antic_safe): Remove\n+\tSSA_OP_VIRTUAL_KILLS.\n+\n+\t* tree-ssa-loop-im.c (determine_max_movement): Remove\n+\tSSA_OP_VIRTUAL_KILLS.\n+\t(gather_mem_refs_stmt): Same.\n+\t(gather_mem_refs_stmt): Same.\n+\n+\t* tree-ssa-dce.c (mark_really_necessary_kill_operand_phis): Delete.\n+\t(perform_tree_ssa_dce): Remove call to\n+\tmark_really_necessary_kill_operand_phis.\n+\n+\t* tree-flow-inline.h (op_iter_init): Remove setting of mustdefs\n+\tand mustkills.\n+\t(op_iter_next_use): Do not check mustkills.\n+\t(op_iter_next_def): Do not check mustdefs.\n+\t(op_iter_next_tree): Do not check mustkills or mustdefs.\n+\t(clear_and_done_ssa_iter): Do not set mustdefs or mustkills.\n+\t(op_iter_next_maymustdef): Do not check mustkills.\n+\t(op_iter_init_must_and_may_def): Remove SSA_OP_VMUSTKILL.\n+\t(op_iter_init_mustdef): Remove.\n+\n+\t* tree-ssa-live.c (create_ssa_var_map): Change SSA_OP_VMUSTDEF to\n+\tSSA_OP_VMAYDEF.\n+\n+\t* tree-ssa-dse.c (dse_optimize_stmt): Remove SSA_OP_VMUSTDEF.\n+\n+\t* tree-ssa-ccp.c: Remove V_MUST_DEF traces from comments.\n+\t(visit_assignment): Same.\n+\n+\t* tree-ssa-copy.c (copy_prop_visit_assignment): Same.\n+\n+\t* tree-sra.c (mark_all_v_defs_1): Remove V_MUST_DEF from comment.\n+\n+\t* tree-outof-ssa.c (check_replaceable): Remove SSA_OP_VMUSTDEF.\n+\n+\t* tree-pretty-print.c (dump_vops): Remove printing of V_MUST_DEF.\n+\tRemove kill_p variable.\n+\n+\t* tree-dfa.c (struct dfa_stats_d): Remove num_v_must_defs.\n+\t(dump_dfa_stats): Remove code related to V_MUST_DEFs.\n+\t(collect_dfa_stats_r): Do not set num_v_must_defs.\n+\t(mark_new_vars_to_rename): Remove v_must_defs_{before,after}\n+\tcode.\n+\n+\t* tree-into-ssa.c (mark_def_sites): Change SSA_OP_VMUSTKILL to\n+\tSSA_OP_VMAYUSE.\n+\n+\t* tree-ssa-pre.c (compute_rvuse_and_antic_safe): Remove\n+\tSSA_OP_VMUSTDEF and SSA_OP_VMUSTKILL.\n+\n+\t* tree-ssa-propagate.c (stmt_makes_single_store): Remove\n+\tSSA_OP_VMUSTDEF.\n+\n 2006-12-11  Zdenek Dvorak <dvorakz@suse.cz>\n \n \tPR rtl-optimization/30113"}, {"sha": "0c9fa37779fb88e5dc64c2c1511a91a166b6edc2", "filename": "gcc/Makefile.in", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1837,7 +1837,7 @@ stor-layout.o : stor-layout.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n tree-ssa-structalias.o: tree-ssa-structalias.c tree-ssa-structalias.h \\\n    $(SYSTEM_H) $(CONFIG_H) $(GGC_H) $(TREE_H) $(TREE_FLOW_H) \\\n    $(TM_H) coretypes.h $(CGRAPH_H) tree-pass.h $(TIMEVAR_H) \\\n-   gt-tree-ssa-structalias.h $(PARAMS_H) $(ALIAS_H)\n+   gt-tree-ssa-structalias.h $(PARAMS_H) $(ALIAS_H) pointer-set.h\n tree-ssa.o : tree-ssa.c $(TREE_FLOW_H) $(CONFIG_H) $(SYSTEM_H) \\\n    $(RTL_H) $(TREE_H) $(TM_P_H) $(EXPR_H) output.h $(DIAGNOSTIC_H) \\\n    toplev.h $(FUNCTION_H) $(TIMEVAR_H) $(TM_H) coretypes.h \\\n@@ -2036,7 +2036,7 @@ tree-ssa-alias.o : tree-ssa-alias.c $(TREE_FLOW_H) $(CONFIG_H) $(SYSTEM_H) \\\n    $(FUNCTION_H) $(TIMEVAR_H) convert.h $(TM_H) coretypes.h langhooks.h \\\n    $(TREE_DUMP_H) tree-pass.h $(PARAMS_H) $(BASIC_BLOCK_H) $(DIAGNOSTIC_H) \\\n    hard-reg-set.h $(TREE_GIMPLE_H) vec.h tree-ssa-structalias.h \\\n-   $(IPA_TYPE_ESCAPE_H) vecprim.h\n+   $(IPA_TYPE_ESCAPE_H) vecprim.h pointer-set.h\n tree-ssa-reassoc.o : tree-ssa-reassoc.c $(TREE_FLOW_H) $(CONFIG_H) \\\n    $(SYSTEM_H) $(TREE_H) $(GGC_H) $(DIAGNOSTIC_H) errors.h $(TIMEVAR_H) \\\n    $(TM_H) coretypes.h $(TREE_DUMP_H) tree-pass.h $(FLAGS_H) tree-iterator.h\\"}, {"sha": "b7eab9e964f6d634f0a8725e137505fb0ce6d542", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 4, "deletions": 13, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -6205,21 +6205,12 @@ Maximum number of basic blocks on path that cse considers.  The default is 10.\n @item max-cse-insns\n The maximum instructions CSE process before flushing. The default is 1000.\n \n-@item global-var-threshold\n-\n-Counts the number of function calls (@var{n}) and the number of\n-call-clobbered variables (@var{v}).  If @var{n}x@var{v} is larger than this limit, a\n-single artificial variable will be created to represent all the\n-call-clobbered variables at function call sites.  This artificial\n-variable will then be made to alias every call-clobbered variable.\n-(done as @code{int * size_t} on the host machine; beware overflow).\n-\n @item max-aliased-vops\n \n-Maximum number of virtual operands allowed to represent aliases\n-before triggering the alias grouping heuristic.  Alias grouping\n-reduces compile times and memory consumption needed for aliasing at\n-the expense of precision loss in alias information.\n+Maximum number of virtual operands per statement allowed to represent\n+aliases before triggering the alias grouping heuristic.  Alias\n+grouping reduces compile times and memory consumption needed for\n+aliasing at the expense of precision loss in alias information.\n \n @item ggc-min-expand\n "}, {"sha": "9895bd4b0dc67f64fd3bbc7fe7c6decce8f19718", "filename": "gcc/doc/tree-ssa.texi", "status": "modified", "additions": 40, "deletions": 27, "changes": 67, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fdoc%2Ftree-ssa.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fdoc%2Ftree-ssa.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftree-ssa.texi?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -852,8 +852,8 @@ operands, use the @option{-vops} option to @option{-fdump-tree}:\n     p = &a;\n   else\n     p = &b;\n-  # a = V_MAY_DEF <a>\n-  # b = V_MAY_DEF <b>\n+  # a = VDEF <a>\n+  # b = VDEF <b>\n   *p = 5;\n \n   # VUSE <a>\n@@ -862,11 +862,11 @@ operands, use the @option{-vops} option to @option{-fdump-tree}:\n @}\n @end smallexample\n \n-Notice that @code{V_MAY_DEF} operands have two copies of the referenced\n+Notice that @code{VDEF} operands have two copies of the referenced\n variable.  This indicates that this is not a killing definition of\n that variable.  In this case we refer to it as a @dfn{may definition}\n or @dfn{aliased store}.  The presence of the second copy of the\n-variable in the @code{V_MAY_DEF} operand will become important when the\n+variable in the @code{VDEF} operand will become important when the\n function is converted into SSA form.  This will be used to link all\n the non-killing definitions to prevent optimizations from making\n incorrect assumptions about them.\n@@ -963,8 +963,8 @@ tree            FOR_EACH_SSA_TREE_OPERAND\n #define SSA_OP_USE              0x01    /* @r{Real USE operands.}  */\n #define SSA_OP_DEF              0x02    /* @r{Real DEF operands.}  */\n #define SSA_OP_VUSE             0x04    /* @r{VUSE operands.}  */\n-#define SSA_OP_VMAYUSE          0x08    /* @r{USE portion of V_MAY_DEFS.}  */\n-#define SSA_OP_VMAYDEF          0x10    /* @r{DEF portion of V_MAY_DEFS.}  */\n+#define SSA_OP_VMAYUSE          0x08    /* @r{USE portion of VDEFS.}  */\n+#define SSA_OP_VMAYDEF          0x10    /* @r{DEF portion of VDEFS.}  */\n #define SSA_OP_VMUSTDEF         0x20    /* @r{V_MUST_DEF definitions.}  */\n \n /* @r{These are commonly grouped operand flags.}  */\n@@ -1004,12 +1004,12 @@ aren't using operand pointers, use and defs flags can be mixed.\n     @}\n @end smallexample\n \n-@code{V_MAY_DEF}s are broken into two flags, one for the\n+@code{VDEF}s are broken into two flags, one for the\n @code{DEF} portion (@code{SSA_OP_VMAYDEF}) and one for the USE portion\n (@code{SSA_OP_VMAYUSE}).  If all you want to look at are the\n-@code{V_MAY_DEF}s together, there is a fourth iterator macro for this,\n+@code{VDEF}s together, there is a fourth iterator macro for this,\n which returns both a def_operand_p and a use_operand_p for each\n-@code{V_MAY_DEF} in the statement.  Note that you don't need any flags for\n+@code{VDEF} in the statement.  Note that you don't need any flags for\n this one.\n \n @smallexample\n@@ -1400,21 +1400,34 @@ There are several @code{TODO} flags that control the behavior of\n \n The virtual SSA form is harder to preserve than the non-virtual SSA form\n mainly because the set of virtual operands for a statement may change at\n-what some would consider unexpected times.  In general, any time you\n-have modified a statement that has virtual operands, you should verify\n-whether the list of virtual operands has changed, and if so, mark the\n-newly exposed symbols by calling @code{mark_new_vars_to_rename}.\n-\n-There is one additional caveat to preserving virtual SSA form.  When the\n-entire set of virtual operands may be eliminated due to better\n-disambiguation, a bare SMT will be added to the list of virtual\n-operands, to signify the non-visible aliases that the are still being\n-referenced.  If the set of bare SMT's may change,\n-@code{TODO_update_smt_usage} should be added to the todo flags.\n-\n-With the current pruning code, this can only occur when constants are\n-propagated into array references that were previously non-constant, or\n-address expressions are propagated into their uses.\n+what some would consider unexpected times.  In general, statement\n+modifications should be bracketed between calls to\n+@code{push_stmt_changes} and @code{pop_stmt_changes}.  For example,\n+\n+@smallexample\n+    munge_stmt (tree stmt)\n+    @{\n+       push_stmt_changes (&stmt);\n+       ... rewrite STMT ...\n+       pop_stmt_changes (&stmt);\n+    @}\n+@end smallexample\n+\n+The call to @code{push_stmt_changes} saves the current state of the\n+statement operands and the call to @code{pop_stmt_changes} compares\n+the saved state with the current one and does the appropriate symbol\n+marking for the SSA renamer.\n+\n+It is possible to modify several statements at a time, provided that\n+@code{push_stmt_changes} and @code{pop_stmt_changes} are called in\n+LIFO order, as when processing a stack of statements.\n+\n+Additionally, if the pass discovers that it did not need to make\n+changes to the statement after calling @code{push_stmt_changes}, it\n+can simply discard the topmost change buffer by calling\n+@code{discard_stmt_changes}.  This will avoid the expensive operand\n+re-scan operation and the buffer comparison that determines if symbols\n+need to be marked for renaming.\n \n @subsection Examining @code{SSA_NAME} nodes\n @cindex examining SSA_NAMEs\n@@ -1635,11 +1648,11 @@ foo (int i)\n     p_6 = &b;\n   # p_1 = PHI <p_4(1), p_6(2)>;\n \n-  # a_7 = V_MAY_DEF <a_3>;\n-  # b_8 = V_MAY_DEF <b_5>;\n+  # a_7 = VDEF <a_3>;\n+  # b_8 = VDEF <b_5>;\n   *p_1 = 3;\n \n-  # a_9 = V_MAY_DEF <a_7>\n+  # a_9 = VDEF <a_7>\n   # VUSE <b_8>\n   a_9 = b_8 + 2;\n "}, {"sha": "c24892e76110f75314362feba3743ec4c13fce1a", "filename": "gcc/params.def", "status": "modified", "additions": 2, "deletions": 9, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fparams.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fparams.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.def?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -451,13 +451,6 @@ DEFPARAM(PARAM_VECT_MAX_VERSION_CHECKS,\n          \"Bound on number of runtime checks inserted by the vectorizer's loop versioning\",\n          6, 0, 0)\n \n-/* The product of the next two is used to decide whether or not to\n-   use .GLOBAL_VAR.  See tree-dfa.c.  */\n-DEFPARAM(PARAM_GLOBAL_VAR_THRESHOLD,\n-\t\"global-var-threshold\",\n-\t\"Given N calls and V call-clobbered vars in a function.  Use .GLOBAL_VAR if NxV is larger than this limit\",\n-\t500000, 0, 0)\n-\n DEFPARAM(PARAM_MAX_CSELIB_MEMORY_LOCATIONS,\n \t \"max-cselib-memory-locations\",\n \t \"The maximum memory locations recorded by cselib\",\n@@ -495,8 +488,8 @@ DEFPARAM(PARAM_MAX_RELOAD_SEARCH_INSNS,\n \n DEFPARAM(PARAM_MAX_ALIASED_VOPS,\n          \"max-aliased-vops\",\n-\t \"The maximum number of virtual operands allowed to represent aliases before triggering alias grouping\",\n-\t 500, 0, 0)\n+\t \"The maximum number of virtual operators per statement allowed to represent aliases before triggering alias grouping\",\n+\t 10, 0, 0)\n \n DEFPARAM(PARAM_MAX_SCHED_REGION_BLOCKS,\n \t \"max-sched-region-blocks\","}, {"sha": "b706b535fff20fcb1824d7c2c120c102ac919b62", "filename": "gcc/params.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fparams.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Fparams.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -142,8 +142,6 @@ typedef enum compiler_param\n   PARAM_VALUE (PARAM_SMS_DFA_HISTORY)\n #define SMS_LOOP_AVERAGE_COUNT_THRESHOLD \\\n   PARAM_VALUE (PARAM_SMS_LOOP_AVERAGE_COUNT_THRESHOLD)\n-#define GLOBAL_VAR_THRESHOLD \\\n-  PARAM_VALUE (PARAM_GLOBAL_VAR_THRESHOLD)\n #define MAX_ALIASED_VOPS \\\n   PARAM_VALUE (PARAM_MAX_ALIASED_VOPS)\n #define INTEGER_SHARE_LIMIT \\"}, {"sha": "2846aaf001101b92fc8adad378b391ec6ca2a6cd", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1,3 +1,19 @@\n+2006-12-11  Aldy Hernandez  <aldyh@redhat.com>\n+\t    Diego Novillo  <dnovillo@redhat.com>\n+\n+\t* gcc.dg/tree-ssa/20040517-1.c: Adapt pattern to\n+\tVDEF/VUSE changes.\n+\t* gcc.dg/tree-ssa/pr26421.c: Likewise\n+\t* gcc.dg/tree-ssa/inline_asm-1.c: Likewise.\n+\t* gcc.dg/tree-ssa/pr23382.c: Likewise.\n+\t* gcc.dg/tree-ssa/inline_asm-2.c: Likewise.\n+\t* gcc.dg/tree-ssa/pr28410.c: Likewise.\n+\t* gcc.dg/tree-ssa/20031015-1.c: Likewise.\n+\t* gcc.dg/tree-ssa/20040302-1.c: Likewise.\n+\t* gcc.dg/tree-ssa/vrp07.c: Likewise.\n+\t* gcc.dg/tree-ssa/vrp08.c: Likewise.\n+\t* gcc.dg/tree-ssa/alias-12.c: Likewise.\n+\n 2006-12-11  Jan Hubicka  <jh@suse.cz>\n \n \t* gcc.dg/tree-prof/stringop-1.c: New test."}, {"sha": "a81edaf79f40c19adcde0ab59758c8728102fb42", "filename": "gcc/testsuite/gcc.dg/tree-ssa/20031015-1.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20031015-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20031015-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20031015-1.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -13,6 +13,6 @@ main(void)\n   return 0;\n }\n \n-/* The V_*_DEF comes from the initial assignment and the asm.  */\n-/* { dg-final { scan-tree-dump-times \"_DEF\" 2 \"alias1\" } } */\n+/* The VDEF comes from the initial assignment and the asm.  */\n+/* { dg-final { scan-tree-dump-times \"DEF\" 2 \"alias1\" } } */\n /* { dg-final { cleanup-tree-dump \"alias1\" } } */"}, {"sha": "8b80128cd608a62edcab438e1a7a1c4ae651da4a", "filename": "gcc/testsuite/gcc.dg/tree-ssa/20040302-1.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20040302-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20040302-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20040302-1.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O1 --param global-var-threshold=0\" } */\n+/* { dg-options \"-O1\" } */\n \n /* Test for .GLOBAL_VAR not being renamed into SSA after alias analysis.\n    provided by Dale Johannesen in PR 14266.  */"}, {"sha": "85d5074f80343eecf5465958b7116fcc6235e986", "filename": "gcc/testsuite/gcc.dg/tree-ssa/20040517-1.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20040517-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20040517-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20040517-1.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -17,6 +17,5 @@ void bar (void)\n    malloc functions may clobber global memory.  Only the function result\n    does not alias any other pointer.\n    Hence, we must have a VDEF for a before and after the call to foo().  */\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF\" 1 \"alias1\"} } */\n-/* { dg-final { scan-tree-dump-times \"V_MUST_DEF\" 1 \"alias1\"} } */\n+/* { dg-final { scan-tree-dump-times \"VDEF\" 2 \"alias1\"} } */\n /* { dg-final { cleanup-tree-dump \"alias1\" } } */"}, {"sha": "409452686bba58fd6674a78c60b1f8004f50d2e9", "filename": "gcc/testsuite/gcc.dg/tree-ssa/alias-12.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-12.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-12.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Falias-12.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -13,6 +13,6 @@ int foo(int i)\n \treturn a.x[i];\n }\n \n-/* { dg-final { scan-tree-dump \"V_MAY_DEF\" \"alias1\" } } */\n+/* { dg-final { scan-tree-dump \"VDEF\" \"alias1\" } } */\n /* { dg-final { cleanup-tree-dump \"alias1\" } } */\n "}, {"sha": "8fcb15916afd08a816dbb370e38028da1c792d10", "filename": "gcc/testsuite/gcc.dg/tree-ssa/complex-5.c", "status": "added", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fcomplex-5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fcomplex-5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fcomplex-5.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -0,0 +1,12 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O1 -fno-tree-dce -fdump-tree-optimized\" } */\n+_Complex int t = 0;\n+int f(void)\n+{\n+  t = 0;\n+ __real__ t = 2;\n+ __imag__ t = 2;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"__complex__\" 0 \"optimized\" } } */\n+/* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "e14c45e4eece5f1729fa2c41fa833719387a3df8", "filename": "gcc/testsuite/gcc.dg/tree-ssa/inline_asm-1.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Finline_asm-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Finline_asm-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Finline_asm-1.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -15,6 +15,6 @@ char f(char *a)\n /* { dg-final { scan-tree-dump-times \"test_function\" 2 \"optimized\"} } */\n /* { dg-final { cleanup-tree-dump \"optimized\" } } */\n \n-/* There should a V_MAY_DEF for the inline-asm.  */\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF\" 1 \"alias1\"} } */\n+/* There should a VDEF for the inline-asm.  */\n+/* { dg-final { scan-tree-dump-times \"VDEF\" 1 \"alias1\"} } */\n /* { dg-final { cleanup-tree-dump \"alias1\" } } */"}, {"sha": "f3dd1fd671ff1e222d0ba8d937665fe7d92ab9ca", "filename": "gcc/testsuite/gcc.dg/tree-ssa/inline_asm-2.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Finline_asm-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Finline_asm-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Finline_asm-2.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -13,6 +13,6 @@ void f(char *a)\n    link_error ();\n }\n \n-/* There should a V_MAY_DEF for the inline-asm and one for the link_error.  */\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF\" 2 \"alias1\"} } */\n+/* There should a VDEF for the inline-asm and one for the link_error.  */\n+/* { dg-final { scan-tree-dump-times \"VDEF\" 2 \"alias1\"} } */\n /* { dg-final { cleanup-tree-dump \"alias1\" } } */"}, {"sha": "89c75cc0147402bf6deecf7bf213e3628bffe1b1", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr23382.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr23382.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr23382.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr23382.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -12,11 +12,11 @@ void f(void)\n {\n    struct a *a = malloc(sizeof(struct a));\n }\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF <HEAP\" 1 \"alias1\"} } */\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF <HEAP\" 1 \"alias2\"} } */\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF <HEAP\" 1 \"alias3\"} } */\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF <HEAP\" 1 \"alias4\"} } */\n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF <HEAP\" 1 \"alias5\"} } */\n+/* { dg-final { scan-tree-dump-times \"VDEF <HEAP\" 1 \"alias1\"} } */\n+/* { dg-final { scan-tree-dump-times \"VDEF <HEAP\" 1 \"alias2\"} } */\n+/* { dg-final { scan-tree-dump-times \"VDEF <HEAP\" 1 \"alias3\"} } */\n+/* { dg-final { scan-tree-dump-times \"VDEF <HEAP\" 1 \"alias4\"} } */\n+/* { dg-final { scan-tree-dump-times \"VDEF <HEAP\" 1 \"alias5\"} } */\n /* { dg-final { cleanup-tree-dump \"alias1\" } } */\n /* { dg-final { cleanup-tree-dump \"alias2\" } } */\n /* { dg-final { cleanup-tree-dump \"alias3\" } } */"}, {"sha": "4a6560ab102a2362902c338c55ad9a1b553a13fa", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr26421.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr26421.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr26421.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr26421.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -16,6 +16,5 @@ int foo(void)\n   return a.i;\n }\n \n-/* { dg-final { scan-tree-dump-times \"V_MAY_DEF\" 1 \"alias1\" } } */\n-/* { dg-final { scan-tree-dump-times \"V_MUST_DEF\" 1 \"alias1\" } } */\n+/* { dg-final { scan-tree-dump-times \"VDEF\" 2 \"alias1\" } } */\n /* { dg-final { cleanup-tree-dump \"alias1\" } } */"}, {"sha": "adc49b15c20bb1cef16ad36db75d6277da4fe1c1", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr28410.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr28410.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr28410.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr28410.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do run } */\n-/* { dg-options \"-O2 --param global-var-threshold=1\" } */\n+/* { dg-options \"-O2\" } */\n \n extern void abort(void);\n struct Bar { int p; };"}, {"sha": "48f4d9f64bbc29620e549cfe511f6ba5def62bcb", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-dse-9.c", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dse-9.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dse-9.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dse-9.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -0,0 +1,13 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -fdump-tree-dse1-vops\" } */\n+\n+struct { int a, b; } soup1, soup2;\n+foo ()\n+{\n+  soup1 = soup2;\n+  soup1.a = 66;\n+  soup1.b = 77;\n+}\n+\n+/* We should eliminate the first assignment.  */\n+/* { dg-final { scan-tree-dump-times \"VDEF\" 2 \"dse1\"} } */"}, {"sha": "1bff5712bcadba65c20f46d7a4778e5f1ee15066", "filename": "gcc/testsuite/gcc.dg/tree-ssa/vrp07.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fvrp07.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fvrp07.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fvrp07.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -32,5 +32,5 @@ foo (int i, int *p)\n \n /* { dg-final { scan-tree-dump-times \"Folding predicate p_.*to 1\" 1 \"vrp1\" } } */\n /* { dg-final { scan-tree-dump-times \"Folding predicate p_.*to 0\" 1 \"vrp1\" } } */\n-/* { dg-final { scan-tree-dump-times \"PREDICATE: p_\\[0-9\\] ne_expr 0B\" 2 \"vrp1\" } } */\n+/* { dg-final { scan-tree-dump-times \"PREDICATE: p_\\[0-9\\]\" 2 \"vrp1\" } } */\n /* { dg-final { cleanup-tree-dump \"vrp1\" } } */"}, {"sha": "5268e181c2c453d65ed78fe40ab1d07a437b6ebd", "filename": "gcc/testsuite/gcc.dg/tree-ssa/vrp08.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fvrp08.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fvrp08.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fvrp08.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -19,5 +19,5 @@ foo (int a, int *p)\n }\n \n /* { dg-final { scan-tree-dump-times \"Folding predicate p_.*to 1\" 1 \"vrp1\" } } */\n-/* { dg-final { scan-tree-dump-times \"PREDICATE: p_. ne_expr 0\" 1 \"vrp1\" } } */\n+/* { dg-final { scan-tree-dump-times \"PREDICATE: p_.* ne_expr 0\" 1 \"vrp1\" } } */\n /* { dg-final { cleanup-tree-dump \"vrp1\" } } */"}, {"sha": "8bd125a862a13bc060a6b4390c6af74167bf0520", "filename": "gcc/testsuite/gcc.dg/vect/vect-37.c", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-37.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-37.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-37.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -53,9 +53,5 @@ int main (void)\n   return main1 (x);\n } \n \n-/* Currently the loops fail to vectorize due to aliasing problems.\n-   If/when the aliasing problems are resolved, unalignment may\n-   prevent vectorization on some targets.  */\n-/* { dg-final { scan-tree-dump-times \"vectorized 2 loops\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"can't determine dependence between\" 2 \"vect\" } } */\n+/* { dg-final { scan-tree-dump-times \"vectorized 2 loops\" 1 \"vect\" } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "0eb1cc8b5b640068bec328a0da44892d1ff9fd10", "filename": "gcc/timevar.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftimevar.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftimevar.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftimevar.def?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -77,6 +77,7 @@ DEFTIMEVAR (TV_TREE_STORE_COPY_PROP  , \"tree store copy prop\")\n DEFTIMEVAR (TV_FIND_REFERENCED_VARS  , \"tree find ref. vars\")\n DEFTIMEVAR (TV_TREE_PTA\t\t     , \"tree PTA\")\n DEFTIMEVAR (TV_TREE_MAY_ALIAS        , \"tree alias analysis\")\n+DEFTIMEVAR (TV_MEMORY_PARTITIONING   , \"tree memory partitioning\")\n DEFTIMEVAR (TV_TREE_INSERT_PHI_NODES , \"tree PHI insertion\")\n DEFTIMEVAR (TV_TREE_SSA_REWRITE_BLOCKS, \"tree SSA rewrite\")\n DEFTIMEVAR (TV_TREE_SSA_OTHER\t     , \"tree SSA other\")"}, {"sha": "26aa26244fccc06bb7f010d67009bd6722223e72", "filename": "gcc/tree-cfg.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-cfg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-cfg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-cfg.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -2230,7 +2230,7 @@ find_case_label_for_value (tree switch_expr, tree val)\n void\n tree_dump_bb (basic_block bb, FILE *outf, int indent)\n {\n-  dump_generic_bb (outf, bb, indent, TDF_VOPS);\n+  dump_generic_bb (outf, bb, indent, TDF_VOPS|TDF_MEMSYMS);\n }\n \n "}, {"sha": "f4ad1d2a5d5c642dd6ad4ae6015bd8308e12376b", "filename": "gcc/tree-dfa.c", "status": "modified", "additions": 20, "deletions": 12, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-dfa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-dfa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dfa.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -59,9 +59,8 @@ struct dfa_stats_d\n   long num_phis;\n   long num_phi_args;\n   int max_num_phi_args;\n-  long num_v_may_defs;\n+  long num_vdefs;\n   long num_vuses;\n-  long num_v_must_defs;\n };\n \n \n@@ -378,6 +377,21 @@ dump_variable (FILE *file, tree var)\n       dump_subvars_for (file, var);\n     }\n \n+  if (!is_gimple_reg (var))\n+    {\n+      if (memory_partition (var))\n+\t{\n+\t  fprintf (file, \", belongs to partition: \");\n+\t  print_generic_expr (file, memory_partition (var), dump_flags);\n+\t}\n+\n+      if (TREE_CODE (var) == MEMORY_PARTITION_TAG)\n+\t{\n+\t  fprintf (file, \", partition symbols: \");\n+\t  dump_decl_set (file, MPT_SYMBOLS (var));\n+\t}\n+    }\n+\n   fprintf (file, \"\\n\");\n }\n \n@@ -444,14 +458,9 @@ dump_dfa_stats (FILE *file)\n   fprintf (file, fmt_str_1, \"VUSE operands\", dfa_stats.num_vuses,\n \t   SCALE (size), LABEL (size));\n \n-  size = dfa_stats.num_v_may_defs * sizeof (tree *);\n-  total += size;\n-  fprintf (file, fmt_str_1, \"V_MAY_DEF operands\", dfa_stats.num_v_may_defs,\n-\t   SCALE (size), LABEL (size));\n-\n-  size = dfa_stats.num_v_must_defs * sizeof (tree *);\n+  size = dfa_stats.num_vdefs * sizeof (tree *);\n   total += size;\n-  fprintf (file, fmt_str_1, \"V_MUST_DEF operands\", dfa_stats.num_v_must_defs,\n+  fprintf (file, fmt_str_1, \"VDEF operands\", dfa_stats.num_vdefs,\n \t   SCALE (size), LABEL (size));\n \n   size = dfa_stats.num_phis * sizeof (struct tree_phi_node);\n@@ -546,10 +555,8 @@ collect_dfa_stats_r (tree *tp, int *walk_subtrees ATTRIBUTE_UNUSED,\n \t    dfa_stats_p->num_stmt_anns++;\n \t    dfa_stats_p->num_defs += NUM_SSA_OPERANDS (t, SSA_OP_DEF);\n \t    dfa_stats_p->num_uses += NUM_SSA_OPERANDS (t, SSA_OP_USE);\n-\t    dfa_stats_p->num_v_may_defs += NUM_SSA_OPERANDS (t, SSA_OP_VMAYDEF);\n+\t    dfa_stats_p->num_vdefs += NUM_SSA_OPERANDS (t, SSA_OP_VDEF);\n \t    dfa_stats_p->num_vuses += NUM_SSA_OPERANDS (t, SSA_OP_VUSE);\n-\t    dfa_stats_p->num_v_must_defs += \n-\t\t\t\t  NUM_SSA_OPERANDS (t, SSA_OP_VMUSTDEF);\n \t    break;\n \t  }\n \n@@ -674,6 +681,7 @@ set_default_def (tree var, tree def)\n   gcc_assert (TREE_CODE (def) == SSA_NAME);\n   loc = htab_find_slot_with_hash (DEFAULT_DEFS (cfun), &in,\n                                   DECL_UID (var), INSERT);\n+\n   /* Default definition might be changed by tail call optimization.  */\n   if (!*loc)\n     {"}, {"sha": "76db084323e4d157914b6248f0e10d2da4160f5e", "filename": "gcc/tree-dump.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-dump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-dump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dump.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -789,6 +789,7 @@ static const struct dump_option_value_info dump_options[] =\n   {\"lineno\", TDF_LINENO},\n   {\"uid\", TDF_UID},\n   {\"stmtaddr\", TDF_STMTADDR},\n+  {\"memsyms\", TDF_MEMSYMS},\n   {\"all\", ~(TDF_RAW | TDF_SLIM | TDF_LINENO | TDF_TREE | TDF_RTL | TDF_IPA \n \t    | TDF_STMTADDR | TDF_GRAPH)},\n   {NULL, 0}"}, {"sha": "97dadd4b56423a12ac328d1faf3e86571642221d", "filename": "gcc/tree-flow-inline.h", "status": "modified", "additions": 118, "deletions": 103, "changes": 221, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-flow-inline.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-flow-inline.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow-inline.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -594,7 +594,7 @@ zero_imm_uses_p (tree var)\n   ssa_use_operand_t *ptr = &(SSA_NAME_IMM_USE_NODE (var));\n   return (ptr == ptr->next);\n }\n- \n+\n /* Return the tree pointer to by USE.  */ \n static inline tree\n get_use_from_ptr (use_operand_p use)\n@@ -693,9 +693,6 @@ set_is_used (tree var)\n   ann->used = 1;\n }\n \n-\n-/*  -----------------------------------------------------------------------  */\n-\n /* Return true if T is an executable statement.  */\n static inline bool\n is_exec_stmt (tree t)\n@@ -841,6 +838,63 @@ loop_containing_stmt (tree stmt)\n   return bb->loop_father;\n }\n \n+\n+/* Return the memory partition tag associated with symbol SYM.  */\n+\n+static inline tree\n+memory_partition (tree sym)\n+{\n+  tree tag;\n+\n+  /* MPTs belong to their own partition.  */\n+  if (TREE_CODE (sym) == MEMORY_PARTITION_TAG)\n+    return sym;\n+\n+  gcc_assert (!is_gimple_reg (sym));\n+  tag = get_var_ann (sym)->mpt;\n+\n+#if defined ENABLE_CHECKING\n+  if (tag)\n+    gcc_assert (TREE_CODE (tag) == MEMORY_PARTITION_TAG);\n+#endif\n+\n+  return tag;\n+}\n+\n+\n+/* Set MPT to be the memory partition associated with symbol SYM.  */\n+\n+static inline void\n+set_memory_partition (tree sym, tree mpt)\n+{\n+#if defined ENABLE_CHECKING\n+  if (mpt)\n+    gcc_assert (TREE_CODE (mpt) == MEMORY_PARTITION_TAG\n+\t        && !is_gimple_reg (sym));\n+#endif\n+  var_ann (sym)->mpt = mpt;\n+  if (mpt)\n+    {\n+      bitmap_set_bit (MPT_SYMBOLS (mpt), DECL_UID (sym));\n+\n+      /* MPT inherits the call-clobbering attributes from SYM.  */\n+      if (is_call_clobbered (sym))\n+\t{\n+\t  MTAG_GLOBAL (mpt) = 1;\n+\t  mark_call_clobbered (mpt, ESCAPE_IS_GLOBAL);\n+\t}\n+    }\n+}\n+\n+/* Return true if NAME is a memory factoring SSA name (i.e., an SSA\n+   name for a memory partition.  */\n+\n+static inline bool\n+factoring_name_p (tree name)\n+{\n+  return TREE_CODE (SSA_NAME_VAR (name)) == MEMORY_PARTITION_TAG;\n+}\n+\n /* Return true if VAR is a clobbered by function calls.  */\n static inline bool\n is_call_clobbered (tree var)\n@@ -874,16 +928,6 @@ clear_call_clobbered (tree var)\n   bitmap_clear_bit (gimple_call_clobbered_vars (cfun), DECL_UID (var));\n }\n \n-/* Mark variable VAR as being non-addressable.  */\n-static inline void\n-mark_non_addressable (tree var)\n-{\n-  if (!MTAG_P (var))\n-    DECL_CALL_CLOBBERED (var) = false;\n-  bitmap_clear_bit (gimple_call_clobbered_vars (cfun), DECL_UID (var));\n-  TREE_ADDRESSABLE (var) = 0;\n-}\n-\n /* Return the common annotation for T.  Return NULL if the annotation\n    doesn't already exist.  */\n static inline tree_ann_common_t\n@@ -929,20 +973,22 @@ op_iter_next_use (ssa_op_iter *ptr)\n     }\n   if (ptr->vuses)\n     {\n-      use_p = VUSE_OP_PTR (ptr->vuses);\n-      ptr->vuses = ptr->vuses->next;\n+      use_p = VUSE_OP_PTR (ptr->vuses, ptr->vuse_index);\n+      if (++(ptr->vuse_index) >= VUSE_NUM (ptr->vuses))\n+        {\n+\t  ptr->vuse_index = 0;\n+\t  ptr->vuses = ptr->vuses->next;\n+\t}\n       return use_p;\n     }\n   if (ptr->mayuses)\n     {\n-      use_p = MAYDEF_OP_PTR (ptr->mayuses);\n-      ptr->mayuses = ptr->mayuses->next;\n-      return use_p;\n-    }\n-  if (ptr->mustkills)\n-    {\n-      use_p = MUSTDEF_KILL_PTR (ptr->mustkills);\n-      ptr->mustkills = ptr->mustkills->next;\n+      use_p = VDEF_OP_PTR (ptr->mayuses, ptr->mayuse_index);\n+      if (++(ptr->mayuse_index) >= VDEF_NUM (ptr->mayuses))\n+        {\n+\t  ptr->mayuse_index = 0;\n+\t  ptr->mayuses = ptr->mayuses->next;\n+\t}\n       return use_p;\n     }\n   if (ptr->phi_i < ptr->num_phi)\n@@ -967,16 +1013,10 @@ op_iter_next_def (ssa_op_iter *ptr)\n       ptr->defs = ptr->defs->next;\n       return def_p;\n     }\n-  if (ptr->mustdefs)\n+  if (ptr->vdefs)\n     {\n-      def_p = MUSTDEF_RESULT_PTR (ptr->mustdefs);\n-      ptr->mustdefs = ptr->mustdefs->next;\n-      return def_p;\n-    }\n-  if (ptr->maydefs)\n-    {\n-      def_p = MAYDEF_RESULT_PTR (ptr->maydefs);\n-      ptr->maydefs = ptr->maydefs->next;\n+      def_p = VDEF_RESULT_PTR (ptr->vdefs);\n+      ptr->vdefs = ptr->vdefs->next;\n       return def_p;\n     }\n   ptr->done = true;\n@@ -999,20 +1039,22 @@ op_iter_next_tree (ssa_op_iter *ptr)\n     }\n   if (ptr->vuses)\n     {\n-      val = VUSE_OP (ptr->vuses);\n-      ptr->vuses = ptr->vuses->next;\n+      val = VUSE_OP (ptr->vuses, ptr->vuse_index);\n+      if (++(ptr->vuse_index) >= VUSE_NUM (ptr->vuses))\n+        {\n+\t  ptr->vuse_index = 0;\n+\t  ptr->vuses = ptr->vuses->next;\n+\t}\n       return val;\n     }\n   if (ptr->mayuses)\n     {\n-      val = MAYDEF_OP (ptr->mayuses);\n-      ptr->mayuses = ptr->mayuses->next;\n-      return val;\n-    }\n-  if (ptr->mustkills)\n-    {\n-      val = MUSTDEF_KILL (ptr->mustkills);\n-      ptr->mustkills = ptr->mustkills->next;\n+      val = VDEF_OP (ptr->mayuses, ptr->mayuse_index);\n+      if (++(ptr->mayuse_index) >= VDEF_NUM (ptr->mayuses))\n+        {\n+\t  ptr->mayuse_index = 0;\n+\t  ptr->mayuses = ptr->mayuses->next;\n+\t}\n       return val;\n     }\n   if (ptr->defs)\n@@ -1021,16 +1063,10 @@ op_iter_next_tree (ssa_op_iter *ptr)\n       ptr->defs = ptr->defs->next;\n       return val;\n     }\n-  if (ptr->mustdefs)\n+  if (ptr->vdefs)\n     {\n-      val = MUSTDEF_RESULT (ptr->mustdefs);\n-      ptr->mustdefs = ptr->mustdefs->next;\n-      return val;\n-    }\n-  if (ptr->maydefs)\n-    {\n-      val = MAYDEF_RESULT (ptr->maydefs);\n-      ptr->maydefs = ptr->maydefs->next;\n+      val = VDEF_RESULT (ptr->vdefs);\n+      ptr->vdefs = ptr->vdefs->next;\n       return val;\n     }\n \n@@ -1050,15 +1086,15 @@ clear_and_done_ssa_iter (ssa_op_iter *ptr)\n   ptr->defs = NULL;\n   ptr->uses = NULL;\n   ptr->vuses = NULL;\n-  ptr->maydefs = NULL;\n+  ptr->vdefs = NULL;\n   ptr->mayuses = NULL;\n-  ptr->mustdefs = NULL;\n-  ptr->mustkills = NULL;\n   ptr->iter_type = ssa_op_iter_none;\n   ptr->phi_i = 0;\n   ptr->num_phi = 0;\n   ptr->phi_stmt = NULL_TREE;\n   ptr->done = true;\n+  ptr->vuse_index = 0;\n+  ptr->mayuse_index = 0;\n }\n \n /* Initialize the iterator PTR to the virtual defs in STMT.  */\n@@ -1072,15 +1108,15 @@ op_iter_init (ssa_op_iter *ptr, tree stmt, int flags)\n   ptr->defs = (flags & SSA_OP_DEF) ? DEF_OPS (stmt) : NULL;\n   ptr->uses = (flags & SSA_OP_USE) ? USE_OPS (stmt) : NULL;\n   ptr->vuses = (flags & SSA_OP_VUSE) ? VUSE_OPS (stmt) : NULL;\n-  ptr->maydefs = (flags & SSA_OP_VMAYDEF) ? MAYDEF_OPS (stmt) : NULL;\n-  ptr->mayuses = (flags & SSA_OP_VMAYUSE) ? MAYDEF_OPS (stmt) : NULL;\n-  ptr->mustdefs = (flags & SSA_OP_VMUSTDEF) ? MUSTDEF_OPS (stmt) : NULL;\n-  ptr->mustkills = (flags & SSA_OP_VMUSTKILL) ? MUSTDEF_OPS (stmt) : NULL;\n+  ptr->vdefs = (flags & SSA_OP_VDEF) ? VDEF_OPS (stmt) : NULL;\n+  ptr->mayuses = (flags & SSA_OP_VMAYUSE) ? VDEF_OPS (stmt) : NULL;\n   ptr->done = false;\n \n   ptr->phi_i = 0;\n   ptr->num_phi = 0;\n   ptr->phi_stmt = NULL_TREE;\n+  ptr->vuse_index = 0;\n+  ptr->mayuse_index = 0;\n }\n \n /* Initialize iterator PTR to the use operands in STMT based on FLAGS. Return\n@@ -1099,7 +1135,7 @@ op_iter_init_use (ssa_op_iter *ptr, tree stmt, int flags)\n static inline def_operand_p\n op_iter_init_def (ssa_op_iter *ptr, tree stmt, int flags)\n {\n-  gcc_assert ((flags & (SSA_OP_ALL_USES | SSA_OP_VIRTUAL_KILLS)) == 0);\n+  gcc_assert ((flags & SSA_OP_ALL_USES) == 0);\n   op_iter_init (ptr, stmt, flags);\n   ptr->iter_type = ssa_op_iter_def;\n   return op_iter_next_def (ptr);\n@@ -1118,73 +1154,53 @@ op_iter_init_tree (ssa_op_iter *ptr, tree stmt, int flags)\n /* Get the next iterator mustdef value for PTR, returning the mustdef values in\n    KILL and DEF.  */\n static inline void\n-op_iter_next_maymustdef (use_operand_p *use, def_operand_p *def, \n+op_iter_next_vdef (vuse_vec_p *use, def_operand_p *def, \n \t\t\t ssa_op_iter *ptr)\n {\n #ifdef ENABLE_CHECKING\n-  gcc_assert (ptr->iter_type == ssa_op_iter_maymustdef);\n+  gcc_assert (ptr->iter_type == ssa_op_iter_vdef);\n #endif\n   if (ptr->mayuses)\n     {\n-      *def = MAYDEF_RESULT_PTR (ptr->mayuses);\n-      *use = MAYDEF_OP_PTR (ptr->mayuses);\n+      *def = VDEF_RESULT_PTR (ptr->mayuses);\n+      *use = VDEF_VECT (ptr->mayuses);\n       ptr->mayuses = ptr->mayuses->next;\n       return;\n     }\n \n-  if (ptr->mustkills)\n-    {\n-      *def = MUSTDEF_RESULT_PTR (ptr->mustkills);\n-      *use = MUSTDEF_KILL_PTR (ptr->mustkills);\n-      ptr->mustkills = ptr->mustkills->next;\n-      return;\n-    }\n-\n   *def = NULL_DEF_OPERAND_P;\n-  *use = NULL_USE_OPERAND_P;\n+  *use = NULL;\n   ptr->done = true;\n   return;\n }\n \n \n-/* Initialize iterator PTR to the operands in STMT.  Return the first operands\n-   in USE and DEF.  */\n static inline void\n-op_iter_init_maydef (ssa_op_iter *ptr, tree stmt, use_operand_p *use, \n-\t\t     def_operand_p *def)\n+op_iter_next_mustdef (use_operand_p *use, def_operand_p *def, \n+\t\t\t ssa_op_iter *ptr)\n {\n-  gcc_assert (TREE_CODE (stmt) != PHI_NODE);\n-\n-  op_iter_init (ptr, stmt, SSA_OP_VMAYUSE);\n-  ptr->iter_type = ssa_op_iter_maymustdef;\n-  op_iter_next_maymustdef (use, def, ptr);\n+  vuse_vec_p vp;\n+  op_iter_next_vdef (&vp, def, ptr);\n+  if (vp != NULL)\n+    {\n+      gcc_assert (VUSE_VECT_NUM_ELEM (*vp) == 1);\n+      *use = VUSE_ELEMENT_PTR (*vp, 0);\n+    }\n+  else\n+    *use = NULL_USE_OPERAND_P;\n }\n \n-\n /* Initialize iterator PTR to the operands in STMT.  Return the first operands\n-   in KILL and DEF.  */\n+   in USE and DEF.  */\n static inline void\n-op_iter_init_mustdef (ssa_op_iter *ptr, tree stmt, use_operand_p *kill, \n+op_iter_init_vdef (ssa_op_iter *ptr, tree stmt, vuse_vec_p *use, \n \t\t     def_operand_p *def)\n {\n   gcc_assert (TREE_CODE (stmt) != PHI_NODE);\n \n-  op_iter_init (ptr, stmt, SSA_OP_VMUSTKILL);\n-  ptr->iter_type = ssa_op_iter_maymustdef;\n-  op_iter_next_maymustdef (kill, def, ptr);\n-}\n-\n-/* Initialize iterator PTR to the operands in STMT.  Return the first operands\n-   in KILL and DEF.  */\n-static inline void\n-op_iter_init_must_and_may_def (ssa_op_iter *ptr, tree stmt,\n-\t\t\t       use_operand_p *kill, def_operand_p *def)\n-{\n-  gcc_assert (TREE_CODE (stmt) != PHI_NODE);\n-\n-  op_iter_init (ptr, stmt, SSA_OP_VMUSTKILL|SSA_OP_VMAYUSE);\n-  ptr->iter_type = ssa_op_iter_maymustdef;\n-  op_iter_next_maymustdef (kill, def, ptr);\n+  op_iter_init (ptr, stmt, SSA_OP_VMAYUSE);\n+  ptr->iter_type = ssa_op_iter_vdef;\n+  op_iter_next_vdef (use, def, ptr);\n }\n \n \n@@ -1277,8 +1293,7 @@ delink_stmt_imm_use (tree stmt)\n    use_operand_p use_p;\n \n    if (ssa_operands_active ())\n-     FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter,\n-\t\t\t       (SSA_OP_ALL_USES | SSA_OP_ALL_KILLS))\n+     FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_ALL_USES)\n        delink_imm_use (use_p);\n }\n "}, {"sha": "3bea04a24b73e3d335057242185c2e8401504161", "filename": "gcc/tree-flow.h", "status": "modified", "additions": 23, "deletions": 8, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-flow.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-flow.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -45,12 +45,14 @@ typedef struct basic_block_def *basic_block;\n struct gimple_df GTY(()) {\n   /* Array of all variables referenced in the function.  */\n   htab_t GTY((param_is (struct int_tree_map))) referenced_vars;\n+\n   /* A list of all the noreturn calls passed to modify_stmt.\n      cleanup_control_flow uses it to detect cases where a mid-block\n      indirect call has been turned into a noreturn call.  When this\n      happens, all the instructions after the call are no longer\n      reachable and must be deleted as dead.  */\n   VEC(tree,gc) *modified_noreturn_calls;\n+\n   /* Array of all SSA_NAMEs used in the function.  */\n   VEC(tree,gc) *ssa_names;\n \n@@ -234,23 +236,31 @@ struct var_ann_d GTY(())\n   ENUM_BITFIELD (need_phi_state) need_phi_state : 2;\n \n   /* Used during operand processing to determine if this variable is already \n-     in the vuse list.  */\n+     in the VUSE list.  */\n   unsigned in_vuse_list : 1;\n \n   /* Used during operand processing to determine if this variable is already \n-     in the v_may_def list.  */\n-  unsigned in_v_may_def_list : 1;\n+     in the VDEF list.  */\n+  unsigned in_vdef_list : 1;\n \n   /* True for HEAP and PARM_NOALIAS artificial variables.  */\n   unsigned is_heapvar : 1;\n \n-  /* An artificial variable representing the memory location pointed-to by\n-     all the pointer symbols that flow-insensitive alias analysis\n-     (mostly type-based) considers to be aliased.  If the variable is\n-     not a pointer or if it is never dereferenced, this must be NULL.  */\n+  /* Memory partition tag assigned to this symbol.  */\n+  tree mpt;\n+\n+  /* If this variable is a pointer P that has been dereferenced, this\n+     field is an artificial variable that represents the memory\n+     location *P.  Every other pointer Q that is type-compatible with\n+     P will also have the same memory tag.  If the variable is not a\n+     pointer or if it is never dereferenced, this must be NULL.\n+     FIXME, do we really need this here?  How much slower would it be\n+     to convert to hash table?  */\n   tree symbol_mem_tag;\n \n-  /* Variables that may alias this variable.  */\n+  /* Variables that may alias this variable.  This may only be set on\n+     memory tags (NAME_MEMORY_TAG or TYPE_MEMORY_TAG).  FIXME, move to\n+     struct tree_memory_tag.  */\n   VEC(tree, gc) *may_aliases;\n \n   /* Used when going out of SSA form to indicate which partition this\n@@ -357,6 +367,10 @@ struct stmt_ann_d GTY(())\n      and local addressable variables.  */\n   unsigned makes_clobbering_call : 1;\n \n+  /* Nonzero if the statement references memory (at least one of its\n+     expressions contains a non-register operand).  */\n+  unsigned references_memory : 1;\n+\n   /* Basic block that contains this statement.  */\n   basic_block bb;\n \n@@ -719,6 +733,7 @@ static inline bool var_can_have_subvars (tree);\n static inline bool overlap_subvar (unsigned HOST_WIDE_INT,\n \t\t\t\t   unsigned HOST_WIDE_INT,\n \t\t\t\t   tree, bool *);\n+extern tree create_tag_raw (enum tree_code, tree, const char *);\n \n /* Call-back function for walk_use_def_chains().  At each reaching\n    definition, a function with this prototype is called.  */"}, {"sha": "60d9afc277d25fddd2ea040a99dd42efe59bc7cc", "filename": "gcc/tree-gimple.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-gimple.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-gimple.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-gimple.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -93,7 +93,7 @@ is_gimple_reg_rhs (tree t)\n      variable is only modified if evaluation of the RHS does not throw.\n \n      Don't force a temp of a non-renamable type; the copy could be\n-     arbitrarily expensive.  Instead we will generate a V_MAY_DEF for\n+     arbitrarily expensive.  Instead we will generate a VDEF for\n      the assignment.  */\n \n   if (is_gimple_reg_type (TREE_TYPE (t))\n@@ -377,7 +377,7 @@ is_gimple_val (tree t)\n   /* FIXME make these decls.  That can happen only when we expose the\n      entire landing-pad construct at the tree level.  */\n   if (TREE_CODE (t) == EXC_PTR_EXPR || TREE_CODE (t) == FILTER_EXPR)\n-    return 1;\n+    return true;\n \n   return (is_gimple_variable (t) || is_gimple_min_invariant (t));\n }"}, {"sha": "1e71e6c012769d1f14c9931e70238fcd9d7517ae", "filename": "gcc/tree-into-ssa.c", "status": "modified", "additions": 457, "deletions": 254, "changes": 711, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-into-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-into-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-into-ssa.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -88,16 +88,17 @@ static htab_t def_blocks;\n    state after completing rewriting of a block and its dominator\n    children.  Its elements have the following properties:\n \n-   - An SSA_NAME indicates that the current definition of the\n-     underlying variable should be set to the given SSA_NAME.\n+   - An SSA_NAME (N) indicates that the current definition of the\n+     underlying variable should be set to the given SSA_NAME.  If the\n+     symbol associated with the SSA_NAME is not a GIMPLE register, the\n+     next slot in the stack must be a _DECL node (SYM).  In this case,\n+     the name N in the previous slot is the current reaching\n+     definition for SYM.\n \n    - A _DECL node indicates that the underlying variable has no\n      current definition.\n \n-   - A NULL node is used to mark the last node associated with the\n-     current block.\n-\n-   - A NULL node at the top entry is used to mark the last node\n+   - A NULL node at the top entry is used to mark the last slot\n      associated with the current block.  */\n static VEC(tree,heap) *block_defs_stack;\n \n@@ -113,22 +114,28 @@ static sbitmap new_ssa_names;\n    time.  */\n static bitmap syms_to_rename;\n \n+/* Subset of SYMS_TO_RENAME.  Contains all the GIMPLE register symbols\n+   that have been marked for renaming.  */\n+static bitmap regs_to_rename;\n+\n+/* Subset of SYMS_TO_RENAME.  Contains all the memory symbols\n+   that have been marked for renaming.  */\n+static bitmap mem_syms_to_rename;\n+\n /* Set of SSA names that have been marked to be released after they\n    were registered in the replacement table.  They will be finally\n    released after we finish updating the SSA web.  */\n static bitmap names_to_release;\n \n-/* For each block, the phi nodes that need to be rewritten are stored into\n+/* For each block, the PHI nodes that need to be rewritten are stored into\n    these vectors.  */\n-\n typedef VEC(tree, heap) *tree_vec;\n DEF_VEC_P (tree_vec);\n DEF_VEC_ALLOC_P (tree_vec, heap);\n \n static VEC(tree_vec, heap) *phis_to_rewrite;\n \n /* The bitmap of non-NULL elements of PHIS_TO_REWRITE.  */\n-\n static bitmap blocks_with_phis_to_rewrite;\n \n /* Growth factor for NEW_SSA_NAMES and OLD_SSA_NAMES.  These sets need\n@@ -191,7 +198,7 @@ struct mark_def_sites_global_data\n /* Information stored for SSA names.  */\n struct ssa_name_info\n {\n-  /* The actual definition of the ssa name.  */\n+  /* The current reaching definition replacing this SSA name.  */\n   tree current_def;\n \n   /* This field indicates whether or not the variable may need PHI nodes.\n@@ -214,7 +221,6 @@ static VEC(ssa_name_info_p, heap) *info_for_ssa_name;\n static unsigned current_info_for_ssa_name_age;\n \n /* The set of blocks affected by update_ssa.  */\n-\n static bitmap blocks_to_update;\n \n /* The main entry point to the SSA renamer (rewrite_blocks) may be\n@@ -254,14 +260,20 @@ extern void debug_tree_ssa (void);\n extern void debug_def_blocks (void);\n extern void dump_tree_ssa_stats (FILE *);\n extern void debug_tree_ssa_stats (void);\n-void dump_update_ssa (FILE *);\n-void debug_update_ssa (void);\n-void dump_names_replaced_by (FILE *, tree);\n-void debug_names_replaced_by (tree);\n+extern void dump_update_ssa (FILE *);\n+extern void debug_update_ssa (void);\n+extern void dump_names_replaced_by (FILE *, tree);\n+extern void debug_names_replaced_by (tree);\n+extern void dump_def_blocks (FILE *);\n+extern void debug_def_blocks (void);\n+extern void dump_defs_stack (FILE *, int);\n+extern void debug_defs_stack (int);\n+extern void dump_currdefs (FILE *);\n+extern void debug_currdefs (void);\n \n /* Get the information associated with NAME.  */\n \n-static inline struct ssa_name_info *\n+static inline ssa_name_info_p\n get_ssa_name_ann (tree name)\n {\n   unsigned ver = SSA_NAME_VERSION (name);\n@@ -292,15 +304,17 @@ get_ssa_name_ann (tree name)\n   return info;\n }\n \n-/* Clears info for ssa names.  */\n+\n+/* Clears info for SSA names.  */\n \n static void\n clear_ssa_name_info (void)\n {\n   current_info_for_ssa_name_age++;\n }\n \n-/* Gets phi_state field for VAR.  */\n+\n+/* Get phi_state field for VAR.  */\n \n static inline enum need_phi_state\n get_phi_state (tree var)\n@@ -367,9 +381,7 @@ compute_global_livein (bitmap livein, bitmap def_blocks)\n     = (basic_block *) xmalloc (sizeof (basic_block) * (last_basic_block + 1));\n \n   EXECUTE_IF_SET_IN_BITMAP (livein, 0, i, bi)\n-    {\n-      *tos++ = BASIC_BLOCK (i);\n-    }\n+    *tos++ = BASIC_BLOCK (i);\n \n   /* Iterate until the worklist is empty.  */\n   while (tos != worklist)\n@@ -542,7 +554,6 @@ set_livein_block (tree var, basic_block bb)\n static inline bool\n symbol_marked_for_renaming (tree sym)\n {\n-  gcc_assert (DECL_P (sym));\n   return bitmap_bit_p (syms_to_rename, DECL_UID (sym));\n }\n \n@@ -646,38 +657,35 @@ add_new_name_mapping (tree new, tree old)\n   /* OLD and NEW must be different SSA names for the same symbol.  */\n   gcc_assert (new != old && SSA_NAME_VAR (new) == SSA_NAME_VAR (old));\n \n-  /* We may need to grow NEW_SSA_NAMES and OLD_SSA_NAMES because our\n-     caller may have created new names since the set was created.  */\n-  if (new_ssa_names->n_bits <= num_ssa_names - 1)\n-    {\n-      unsigned int new_sz = num_ssa_names + NAME_SETS_GROWTH_FACTOR;\n-      new_ssa_names = sbitmap_resize (new_ssa_names, new_sz, 0);\n-      old_ssa_names = sbitmap_resize (old_ssa_names, new_sz, 0);\n-    }\n-\n   /* If this mapping is for virtual names, we will need to update\n-     virtual operands.  */\n+     virtual operands.  If this is a mapping for .MEM, then we gather\n+     the symbols associated with each name.  */\n   if (!is_gimple_reg (new))\n     {\n       tree sym;\n-      size_t uid;\n \n       need_to_update_vops_p = true;\n \n+      update_ssa_stats.num_virtual_mappings++;\n+      update_ssa_stats.num_virtual_symbols++;\n+\n       /* Keep counts of virtual mappings and symbols to use in the\n \t virtual mapping heuristic.  If we have large numbers of\n \t virtual mappings for a relatively low number of symbols, it\n \t will make more sense to rename the symbols from scratch.\n \t Otherwise, the insertion of PHI nodes for each of the old\n \t names in these mappings will be very slow.  */\n       sym = SSA_NAME_VAR (new);\n-      uid = DECL_UID (sym);\n-      update_ssa_stats.num_virtual_mappings++;\n-      if (!bitmap_bit_p (update_ssa_stats.virtual_symbols, uid))\n-\t{\n-\t  bitmap_set_bit (update_ssa_stats.virtual_symbols, uid);\n-\t  update_ssa_stats.num_virtual_symbols++;\n-\t}\n+      bitmap_set_bit (update_ssa_stats.virtual_symbols, DECL_UID (sym));\n+    }\n+\n+  /* We may need to grow NEW_SSA_NAMES and OLD_SSA_NAMES because our\n+     caller may have created new names since the set was created.  */\n+  if (new_ssa_names->n_bits <= num_ssa_names - 1)\n+    {\n+      unsigned int new_sz = num_ssa_names + NAME_SETS_GROWTH_FACTOR;\n+      new_ssa_names = sbitmap_resize (new_ssa_names, new_sz, 0);\n+      old_ssa_names = sbitmap_resize (old_ssa_names, new_sz, 0);\n     }\n \n   /* Update the REPL_TBL table.  */\n@@ -715,29 +723,28 @@ add_new_name_mapping (tree new, tree old)\n    we create.  */\n \n static void\n-mark_def_sites (struct dom_walk_data *walk_data,\n-\t\tbasic_block bb,\n+mark_def_sites (struct dom_walk_data *walk_data, basic_block bb,\n \t\tblock_stmt_iterator bsi)\n {\n-  struct mark_def_sites_global_data *gd =\n-     (struct mark_def_sites_global_data *) walk_data->global_data;\n-  bitmap kills = gd->kills;\n+  struct mark_def_sites_global_data *gd;\n+  bitmap kills;\n   tree stmt, def;\n   use_operand_p use_p;\n-  def_operand_p def_p;\n   ssa_op_iter iter;\n \n   stmt = bsi_stmt (bsi);\n   update_stmt_if_modified (stmt);\n \n+  gd = (struct mark_def_sites_global_data *) walk_data->global_data;\n+  kills = gd->kills;\n+\n   gcc_assert (blocks_to_update == NULL);\n   REGISTER_DEFS_IN_THIS_STMT (stmt) = 0;\n   REWRITE_THIS_STMT (stmt) = 0;\n \n   /* If a variable is used before being set, then the variable is live\n      across a block boundary, so mark it live-on-entry to BB.  */\n-  FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter,\n-\t\t\t    SSA_OP_USE | SSA_OP_VUSE | SSA_OP_VMUSTKILL)\n+  FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_USE)\n     {\n       tree sym = USE_FROM_PTR (use_p);\n       gcc_assert (DECL_P (sym));\n@@ -746,23 +753,9 @@ mark_def_sites (struct dom_walk_data *walk_data,\n       REWRITE_THIS_STMT (stmt) = 1;\n     }\n   \n-  /* Note that virtual definitions are irrelevant for computing KILLS\n-     because a V_MAY_DEF does not constitute a killing definition of the\n-     variable.  However, the operand of a virtual definitions is a use\n-     of the variable, so it may cause the variable to be considered\n-     live-on-entry.  */\n-  FOR_EACH_SSA_MAYDEF_OPERAND (def_p, use_p, stmt, iter)\n-    {\n-      tree sym = USE_FROM_PTR (use_p);\n-      gcc_assert (DECL_P (sym));\n-      set_livein_block (sym, bb);\n-      set_def_block (sym, bb, false);\n-      REGISTER_DEFS_IN_THIS_STMT (stmt) = 1;\n-      REWRITE_THIS_STMT (stmt) = 1;\n-    }\n-\n-  /* Now process the defs and must-defs made by this statement.  */\n-  FOR_EACH_SSA_TREE_OPERAND (def, stmt, iter, SSA_OP_DEF | SSA_OP_VMUSTDEF)\n+  /* Now process the defs.  Mark BB as the definition block and add\n+     each def to the set of killed symbols.  */\n+  FOR_EACH_SSA_TREE_OPERAND (def, stmt, iter, SSA_OP_DEF)\n     {\n       gcc_assert (DECL_P (def));\n       set_def_block (def, bb, false);\n@@ -996,28 +989,27 @@ prune_unused_phi_nodes (bitmap phis, bitmap kills, bitmap uses)\n    return a bitmap with all the blocks in the iterated dominance\n    frontier of the blocks in DEF_BLOCKS.  DFS contains dominance\n    frontier information as returned by compute_dominance_frontiers.\n-   \n+\n    The resulting set of blocks are the potential sites where PHI nodes\n-   are needed.  The caller is responsible from freeing the memory\n+   are needed.  The caller is responsible for freeing the memory\n    allocated for the return value.  */\n \n static bitmap\n-find_idf (bitmap def_blocks, bitmap *dfs)\n+compute_idf (bitmap def_blocks, bitmap *dfs)\n {\n   bitmap_iterator bi;\n-  unsigned bb_index;\n+  unsigned bb_index, i;\n   VEC(int,heap) *work_stack;\n   bitmap phi_insertion_points;\n \n   work_stack = VEC_alloc (int, heap, n_basic_blocks);\n   phi_insertion_points = BITMAP_ALLOC (NULL);\n \n-  /* Seed the work list with all the blocks in DEF_BLOCKS.  */\n+  /* Seed the work list with all the blocks in DEF_BLOCKS.  We use\n+     VEC_quick_push here for speed.  This is safe because we know that\n+     the number of definition blocks is no greater than the number of\n+     basic blocks, which is the initial capacity of WORK_STACK.  */\n   EXECUTE_IF_SET_IN_BITMAP (def_blocks, 0, bb_index, bi)\n-    /* We use VEC_quick_push here for speed.  This is safe because we\n-       know that the number of definition blocks is no greater than\n-       the number of basic blocks, which is the initial capacity of\n-       WORK_STACK.  */\n     VEC_quick_push (int, work_stack, bb_index);\n \n   /* Pop a block off the worklist, add every block that appears in\n@@ -1037,13 +1029,13 @@ find_idf (bitmap def_blocks, bitmap *dfs)\n       gcc_assert (bb_index < (unsigned) last_basic_block);\n \n       EXECUTE_IF_AND_COMPL_IN_BITMAP (dfs[bb_index], phi_insertion_points,\n-\t                              0, bb_index, bi)\n+\t                              0, i, bi)\n \t{\n \t  /* Use a safe push because if there is a definition of VAR\n \t     in every basic block, then WORK_STACK may eventually have\n \t     more than N_BASIC_BLOCK entries.  */\n-\t  VEC_safe_push (int, heap, work_stack, bb_index);\n-\t  bitmap_set_bit (phi_insertion_points, bb_index);\n+\t  VEC_safe_push (int, heap, work_stack, i);\n+\t  bitmap_set_bit (phi_insertion_points, i);\n \t}\n     }\n \n@@ -1093,6 +1085,7 @@ mark_phi_for_rewrite (basic_block bb, tree phi)\n \n   if (REWRITE_THIS_STMT (phi))\n     return;\n+\n   REWRITE_THIS_STMT (phi) = 1;\n \n   if (!blocks_with_phis_to_rewrite)\n@@ -1111,12 +1104,12 @@ mark_phi_for_rewrite (basic_block bb, tree phi)\n   VEC_replace (tree_vec, phis_to_rewrite, idx, phis);\n }\n \n+\n /* Insert PHI nodes for variable VAR using the iterated dominance\n    frontier given in PHI_INSERTION_POINTS.  If UPDATE_P is true, this\n-   function assumes that the caller is incrementally updating the SSA\n-   form, in which case (1) VAR is assumed to be an SSA name, (2) a new\n-   SSA name is created for VAR's symbol, and, (3) all the arguments\n-   for the newly created PHI node are set to VAR.\n+   function assumes that the caller is incrementally updating the\n+   existing SSA form, in which case VAR may be an SSA name instead of\n+   a symbol.\n \n    PHI_INSERTION_POINTS is updated to reflect nodes that already had a\n    PHI node for VAR.  On exit, only the nodes that received a PHI node\n@@ -1149,7 +1142,9 @@ insert_phi_nodes_for (tree var, bitmap phi_insertion_points, bool update_p)\n       if (update_p)\n \tmark_block_for_update (bb);\n \n-      if (update_p && TREE_CODE (var) == SSA_NAME)\n+      phi = NULL_TREE;\n+\n+      if (TREE_CODE (var) == SSA_NAME)\n \t{\n \t  /* If we are rewriting SSA names, create the LHS of the PHI\n \t     node by duplicating VAR.  This is useful in the case of\n@@ -1158,7 +1153,9 @@ insert_phi_nodes_for (tree var, bitmap phi_insertion_points, bool update_p)\n \t  edge_iterator ei;\n \t  tree new_lhs;\n \n+\t  gcc_assert (update_p);\n \t  phi = create_phi_node (var, bb);\n+\n \t  new_lhs = duplicate_ssa_name (var, phi);\n \t  SET_PHI_RESULT (phi, new_lhs);\n \t  add_new_name_mapping (new_lhs, var);\n@@ -1187,10 +1184,7 @@ insert_phi_nodes_for (tree var, bitmap phi_insertion_points, bool update_p)\n \n /* Insert PHI nodes at the dominance frontier of blocks with variable\n    definitions.  DFS contains the dominance frontier information for\n-   the flowgraph.  PHI nodes will only be inserted at the dominance\n-   frontier of definition blocks for variables whose NEED_PHI_STATE\n-   annotation is marked as ``maybe'' or ``unknown'' (computed by\n-   mark_def_sites).  */\n+   the flowgraph.  */\n \n static void\n insert_phi_nodes (bitmap *dfs)\n@@ -1211,7 +1205,7 @@ insert_phi_nodes (bitmap *dfs)\n \n       if (get_phi_state (var) != NEED_PHI_STATE_NO)\n \t{\n-\t  idf = find_idf (def_map->def_blocks, dfs);\n+\t  idf = compute_idf (def_map->def_blocks, dfs);\n \t  insert_phi_nodes_for (var, idf, false);\n \t  BITMAP_FREE (idf);\n \t}\n@@ -1221,14 +1215,12 @@ insert_phi_nodes (bitmap *dfs)\n }\n \n \n-/* Register DEF (an SSA_NAME) to be a new definition for its underlying\n-   variable (SSA_NAME_VAR (DEF)) and push VAR's current reaching definition\n-   into the stack pointed to by BLOCK_DEFS_P.  */\n+/* Push SYM's current reaching definition into BLOCK_DEFS_STACK and\n+   register DEF (an SSA_NAME) to be a new definition for SYM.  */\n \n static void\n-register_new_def (tree def, VEC(tree,heap) **block_defs_p)\n+register_new_def (tree def, tree sym)\n {\n-  tree var = SSA_NAME_VAR (def);\n   tree currdef;\n    \n   /* If this variable is set in a single basic block and all uses are\n@@ -1239,23 +1231,31 @@ register_new_def (tree def, VEC(tree,heap) **block_defs_p)\n      This is the same test to prune the set of variables which may\n      need PHI nodes.  So we just use that information since it's already\n      computed and available for us to use.  */\n-  if (get_phi_state (var) == NEED_PHI_STATE_NO)\n+  if (get_phi_state (sym) == NEED_PHI_STATE_NO)\n     {\n-      set_current_def (var, def);\n+      set_current_def (sym, def);\n       return;\n     }\n \n-  currdef = get_current_def (var);\n+  currdef = get_current_def (sym);\n \n-  /* Push the current reaching definition into *BLOCK_DEFS_P.  This stack is\n-     later used by the dominator tree callbacks to restore the reaching\n-     definitions for all the variables defined in the block after a recursive\n-     visit to all its immediately dominated blocks.  If there is no current\n-     reaching definition, then just record the underlying _DECL node.  */\n-  VEC_safe_push (tree, heap, *block_defs_p, currdef ? currdef : var);\n+  /* If SYM is not a GIMPLE register, then CURRDEF may be a name whose\n+     SSA_NAME_VAR is not necessarily SYM.  In this case, also push SYM\n+     in the stack so that we know which symbol is being defined by\n+     this SSA name when we unwind the stack.  */\n+  if (currdef && !is_gimple_reg (sym))\n+    VEC_safe_push (tree, heap, block_defs_stack, sym);\n \n-  /* Set the current reaching definition for VAR to be DEF.  */\n-  set_current_def (var, def);\n+  /* Push the current reaching definition into BLOCK_DEFS_STACK.  This\n+     stack is later used by the dominator tree callbacks to restore\n+     the reaching definitions for all the variables defined in the\n+     block after a recursive visit to all its immediately dominated\n+     blocks.  If there is no current reaching definition, then just\n+     record the underlying _DECL node.  */\n+  VEC_safe_push (tree, heap, block_defs_stack, currdef ? currdef : sym);\n+\n+  /* Set the current reaching definition for SYM to be DEF.  */\n+  set_current_def (sym, def);\n }\n \n \n@@ -1305,37 +1305,35 @@ rewrite_initialize_block (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n   for (phi = phi_nodes (bb); phi; phi = PHI_CHAIN (phi))\n     {\n       tree result = PHI_RESULT (phi);\n-      register_new_def (result, &block_defs_stack);\n+      gcc_assert (is_gimple_reg (result));\n+      register_new_def (result, SSA_NAME_VAR (result));\n     }\n }\n \n \n /* Return the current definition for variable VAR.  If none is found,\n-   create a new SSA name to act as the zeroth definition for VAR.  If VAR\n-   is call clobbered and there exists a more recent definition of\n-   GLOBAL_VAR, return the definition for GLOBAL_VAR.  This means that VAR\n-   has been clobbered by a function call since its last assignment.  */\n+   create a new SSA name to act as the zeroth definition for VAR.  */\n \n static tree\n get_reaching_def (tree var)\n {\n-  tree currdef_var, avar;\n+  tree currdef;\n   \n   /* Lookup the current reaching definition for VAR.  */\n-  currdef_var = get_current_def (var);\n+  currdef = get_current_def (var);\n \n   /* If there is no reaching definition for VAR, create and register a\n      default definition for it (if needed).  */\n-  if (currdef_var == NULL_TREE)\n+  if (currdef == NULL_TREE)\n     {\n-      avar = DECL_P (var) ? var : SSA_NAME_VAR (var);\n-      currdef_var = get_default_def_for (avar);\n-      set_current_def (var, currdef_var);\n+      tree sym = DECL_P (var) ? var : SSA_NAME_VAR (var);\n+      currdef = get_default_def_for (sym);\n+      set_current_def (var, currdef);\n     }\n \n   /* Return the current reaching definition for VAR, or the default\n      definition, if we had to create one.  */\n-  return currdef_var;\n+  return currdef;\n }\n \n \n@@ -1345,8 +1343,7 @@ get_reaching_def (tree var)\n \n static void\n rewrite_stmt (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n-\t      basic_block bb ATTRIBUTE_UNUSED,\n-\t      block_stmt_iterator si)\n+\t      basic_block bb ATTRIBUTE_UNUSED, block_stmt_iterator si)\n {\n   tree stmt;\n   use_operand_p use_p;\n@@ -1368,24 +1365,23 @@ rewrite_stmt (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n       fprintf (dump_file, \"\\n\");\n     }\n \n-  /* Step 1.  Rewrite USES and VUSES in the statement.  */\n+  /* Step 1.  Rewrite USES in the statement.  */\n   if (REWRITE_THIS_STMT (stmt))\n-    FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter,\n-\t                      SSA_OP_ALL_USES|SSA_OP_ALL_KILLS)\n+    FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_USE)\n       {\n \ttree var = USE_FROM_PTR (use_p);\n \tgcc_assert (DECL_P (var));\n \tSET_USE (use_p, get_reaching_def (var));\n       }\n \n-  /* Step 2.  Register the statement's DEF and VDEF operands.  */\n+  /* Step 2.  Register the statement's DEF operands.  */\n   if (REGISTER_DEFS_IN_THIS_STMT (stmt))\n-    FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, iter, SSA_OP_ALL_DEFS)\n+    FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, iter, SSA_OP_DEF)\n       {\n \ttree var = DEF_FROM_PTR (def_p);\n \tgcc_assert (DECL_P (var));\n \tSET_DEF (def_p, make_ssa_name (var, stmt));\n-\tregister_new_def (DEF_FROM_PTR (def_p), &block_defs_stack);\n+\tregister_new_def (DEF_FROM_PTR (def_p), var);\n       }\n }\n \n@@ -1416,8 +1412,8 @@ rewrite_add_phi_arguments (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n }\n \n \n-/* Called after visiting basic block BB.  Restore CURRDEFS to its\n-   original value.  */\n+/* Called after visiting all the statements in basic block BB and all\n+   of its dominator children.  Restore CURRDEFS to its original value.  */\n \n static void\n rewrite_finalize_block (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n@@ -1432,17 +1428,25 @@ rewrite_finalize_block (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n       if (tmp == NULL_TREE)\n \tbreak;\n \n-      /* If we recorded an SSA_NAME, then make the SSA_NAME the current\n-\t definition of its underlying variable.  If we recorded anything\n-\t else, it must have been an _DECL node and its current reaching\n-\t definition must have been NULL.  */\n       if (TREE_CODE (tmp) == SSA_NAME)\n \t{\n+\t  /* If we recorded an SSA_NAME, then make the SSA_NAME the\n+\t     current definition of its underlying variable.  Note that\n+\t     if the SSA_NAME is not for a GIMPLE register, the symbol\n+\t     being defined is stored in the next slot in the stack.\n+\t     This mechanism is needed because an SSA name for a\n+\t     non-register symbol may be the definition for more than\n+\t     one symbol (e.g., SFTs, aliased variables, etc).  */\n \t  saved_def = tmp;\n \t  var = SSA_NAME_VAR (saved_def);\n+\t  if (!is_gimple_reg (var))\n+\t    var = VEC_pop (tree, block_defs_stack);\n \t}\n       else\n \t{\n+\t  /* If we recorded anything else, it must have been a _DECL\n+\t     node and its current reaching definition must have been\n+\t     NULL.  */\n \t  saved_def = NULL;\n \t  var = tmp;\n \t}\n@@ -1452,24 +1456,157 @@ rewrite_finalize_block (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n }\n \n \n+/* Dump bitmap SET (assumed to contain VAR_DECLs) to FILE.  */\n+\n+void\n+dump_decl_set (FILE *file, bitmap set)\n+{\n+  if (set)\n+    {\n+      bitmap_iterator bi;\n+      unsigned i;\n+\n+      fprintf (file, \"{ \");\n+\n+      EXECUTE_IF_SET_IN_BITMAP (set, 0, i, bi)\n+\t{\n+\t  print_generic_expr (file, referenced_var (i), 0);\n+\t  fprintf (file, \" \");\n+\t}\n+\n+      fprintf (file, \"}\\n\");\n+    }\n+  else\n+    fprintf (file, \"NIL\\n\");\n+}\n+\n+\n+/* Dump bitmap SET (assumed to contain VAR_DECLs) to FILE.  */\n+\n+void\n+debug_decl_set (bitmap set)\n+{\n+  dump_decl_set (stderr, set);\n+}\n+\n+\n+/* Dump the renaming stack (block_defs_stack) to FILE.  Traverse the\n+   stack up to a maximum of N levels.  If N is -1, the whole stack is\n+   dumped.  New levels are created when the dominator tree traversal\n+   used for renaming enters a new sub-tree.  */\n+\n+void\n+dump_defs_stack (FILE *file, int n)\n+{\n+  int i, j;\n+\n+  fprintf (file, \"\\n\\nRenaming stack\");\n+  if (n > 0)\n+    fprintf (file, \" (up to %d levels)\", n);\n+  fprintf (file, \"\\n\\n\");\n+\n+  i = 1;\n+  fprintf (file, \"Level %d (current level)\\n\", i);\n+  for (j = (int) VEC_length (tree, block_defs_stack) - 1; j >= 0; j--)\n+    {\n+      tree name, var;\n+      \n+      name = VEC_index (tree, block_defs_stack, j);\n+      if (name == NULL_TREE)\n+\t{\n+\t  i++;\n+\t  if (n > 0 && i > n)\n+\t    break;\n+\t  fprintf (file, \"\\nLevel %d\\n\", i);\n+\t  continue;\n+\t}\n+\n+      if (DECL_P (name))\n+\t{\n+\t  var = name;\n+\t  name = NULL_TREE;\n+\t}\n+      else\n+\t{\n+\t  var = SSA_NAME_VAR (name);\n+\t  if (!is_gimple_reg (var))\n+\t    {\n+\t      j--;\n+\t      var = VEC_index (tree, block_defs_stack, j);\n+\t    }\n+\t}\n+\n+      fprintf (file, \"    Previous CURRDEF (\");\n+      print_generic_expr (file, var, 0);\n+      fprintf (file, \") = \");\n+      if (name)\n+\tprint_generic_expr (file, name, 0);\n+      else\n+\tfprintf (file, \"<NIL>\");\n+      fprintf (file, \"\\n\");\n+    }\n+}\n+\n+\n+/* Dump the renaming stack (block_defs_stack) to stderr.  Traverse the\n+   stack up to a maximum of N levels.  If N is -1, the whole stack is\n+   dumped.  New levels are created when the dominator tree traversal\n+   used for renaming enters a new sub-tree.  */\n+\n+void\n+debug_defs_stack (int n)\n+{\n+  dump_defs_stack (stderr, n);\n+}\n+\n+\n+/* Dump the current reaching definition of every symbol to FILE.  */\n+\n+void\n+dump_currdefs (FILE *file)\n+{\n+  referenced_var_iterator i;\n+  tree var;\n+\n+  fprintf (file, \"\\n\\nCurrent reaching definitions\\n\\n\");\n+  FOR_EACH_REFERENCED_VAR (var, i)\n+    if (syms_to_rename == NULL || bitmap_bit_p (syms_to_rename, DECL_UID (var)))\n+      {\n+\tfprintf (file, \"CURRDEF (\");\n+\tprint_generic_expr (file, var, 0);\n+\tfprintf (file, \") = \");\n+\tif (get_current_def (var))\n+\t  print_generic_expr (file, get_current_def (var), 0);\n+\telse\n+\t  fprintf (file, \"<NIL>\");\n+\tfprintf (file, \"\\n\");\n+      }\n+}\n+\n+\n+/* Dump the current reaching definition of every symbol to stderr.  */\n+\n+void\n+debug_currdefs (void)\n+{\n+  dump_currdefs (stderr);\n+}\n+\n+\n /* Dump SSA information to FILE.  */\n \n void\n dump_tree_ssa (FILE *file)\n {\n-  basic_block bb;\n   const char *funcname\n     = lang_hooks.decl_printable_name (current_function_decl, 2);\n \n-  fprintf (file, \"SSA information for %s\\n\\n\", funcname);\n+  fprintf (file, \"SSA renaming information for %s\\n\\n\", funcname);\n \n-  FOR_EACH_BB (bb)\n-    {\n-      dump_bb (bb, file, 0);\n-      fputs (\"    \", file);\n-      print_generic_stmt (file, phi_nodes (bb), dump_flags);\n-      fputs (\"\\n\\n\", file);\n-    }\n+  dump_def_blocks (file);\n+  dump_defs_stack (file, -1);\n+  dump_currdefs (file);\n+  dump_tree_ssa_stats (file);\n }\n \n \n@@ -1499,12 +1636,23 @@ htab_statistics (FILE *file, htab_t htab)\n void\n dump_tree_ssa_stats (FILE *file)\n {\n-  fprintf (file, \"\\nHash table statistics:\\n\");\n+  if (def_blocks || repl_tbl)\n+    fprintf (file, \"\\nHash table statistics:\\n\");\n \n-  fprintf (file, \"    def_blocks: \");\n-  htab_statistics (file, def_blocks);\n+  if (def_blocks)\n+    {\n+      fprintf (file, \"    def_blocks:   \");\n+      htab_statistics (file, def_blocks);\n+    }\n \n-  fprintf (file, \"\\n\");\n+  if (repl_tbl)\n+    {\n+      fprintf (file, \"    repl_tbl:     \");\n+      htab_statistics (file, repl_tbl);\n+    }\n+\n+  if (def_blocks || repl_tbl)\n+    fprintf (file, \"\\n\");\n }\n \n \n@@ -1550,25 +1698,38 @@ def_blocks_free (void *p)\n /* Callback for htab_traverse to dump the DEF_BLOCKS hash table.  */\n \n static int\n-debug_def_blocks_r (void **slot, void *data ATTRIBUTE_UNUSED)\n+debug_def_blocks_r (void **slot, void *data)\n {\n+  FILE *file = (FILE *) data;\n   struct def_blocks_d *db_p = (struct def_blocks_d *) *slot;\n   \n-  fprintf (stderr, \"VAR: \");\n-  print_generic_expr (stderr, db_p->var, dump_flags);\n-  bitmap_print (stderr, db_p->def_blocks, \", DEF_BLOCKS: { \", \"}\");\n-  bitmap_print (stderr, db_p->livein_blocks, \", LIVEIN_BLOCKS: { \", \"}\\n\");\n+  fprintf (file, \"VAR: \");\n+  print_generic_expr (file, db_p->var, dump_flags);\n+  bitmap_print (file, db_p->def_blocks, \", DEF_BLOCKS: { \", \"}\");\n+  bitmap_print (file, db_p->livein_blocks, \", LIVEIN_BLOCKS: { \", \"}\");\n+  bitmap_print (file, db_p->phi_blocks, \", PHI_BLOCKS: { \", \"}\\n\");\n \n   return 1;\n }\n \n \n+/* Dump the DEF_BLOCKS hash table on FILE.  */\n+\n+void\n+dump_def_blocks (FILE *file)\n+{\n+  fprintf (file, \"\\n\\nDefinition and live-in blocks:\\n\\n\");\n+  if (def_blocks)\n+    htab_traverse (def_blocks, debug_def_blocks_r, file);\n+}\n+\n+\n /* Dump the DEF_BLOCKS hash table on stderr.  */\n \n void\n debug_def_blocks (void)\n {\n-  htab_traverse (def_blocks, debug_def_blocks_r, NULL);\n+  dump_def_blocks (stderr);\n }\n \n \n@@ -1579,7 +1740,7 @@ register_new_update_single (tree new_name, tree old_name)\n {\n   tree currdef = get_current_def (old_name);\n \n-  /* Push the current reaching definition into *BLOCK_DEFS_P.\n+  /* Push the current reaching definition into BLOCK_DEFS_STACK.\n      This stack is later used by the dominator tree callbacks to\n      restore the reaching definitions for all the variables\n      defined in the block after a recursive visit to all its\n@@ -1648,7 +1809,6 @@ rewrite_update_init_block (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n      register it as a new definition for its corresponding name.  Also\n      register definitions for names whose underlying symbols are\n      marked for renaming.  */\n-\n   for (phi = phi_nodes (bb); phi; phi = PHI_CHAIN (phi))\n     {\n       tree lhs, lhs_sym;\n@@ -1663,6 +1823,7 @@ rewrite_update_init_block (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n \tregister_new_update_single (lhs, lhs_sym);\n       else\n \t{\n+\n \t  /* If LHS is a new name, register a new definition for all\n \t     the names replaced by LHS.  */\n \t  if (is_new_name (lhs))\n@@ -1738,8 +1899,8 @@ maybe_register_def (def_operand_p def_p, tree stmt)\n   tree def = DEF_FROM_PTR (def_p);\n   tree sym = DECL_P (def) ? def : SSA_NAME_VAR (def);\n \n-  /* If DEF is a naked symbol that needs renaming, create a\n-     new name for it.  */\n+  /* If DEF is a naked symbol that needs renaming, create a new\n+     name for it.  */\n   if (symbol_marked_for_renaming (sym))\n     {\n       if (DECL_P (def))\n@@ -1807,8 +1968,7 @@ rewrite_update_stmt (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n \tmaybe_replace_use (use_p);\n \n       if (need_to_update_vops_p)\n-\tFOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter,\n-\t\t\t\t  SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS)\n+\tFOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_VIRTUAL_USES)\n \t  maybe_replace_use (use_p);\n     }\n \n@@ -1827,18 +1987,6 @@ rewrite_update_stmt (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n }\n \n \n-/* Replace the operand pointed to by USE_P with USE's current reaching\n-   definition.  */\n-\n-static inline void\n-replace_use (use_operand_p use_p, tree use)\n-{\n-  tree rdef = get_reaching_def (use);\n-  if (rdef != use)\n-    SET_USE (use_p, rdef);\n-}\n-\n-\n /* Visit all the successor blocks of BB looking for PHI nodes.  For\n    every PHI node found, check if any of its arguments is in\n    OLD_SSA_NAMES.  If so, and if the argument has a current reaching\n@@ -1863,7 +2011,7 @@ rewrite_update_phi_arguments (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n       phis = VEC_index (tree_vec, phis_to_rewrite, e->dest->index);\n       for (i = 0; VEC_iterate (tree, phis, i, phi); i++)\n \t{\n-\t  tree arg;\n+\t  tree arg, lhs_sym;\n \t  use_operand_p arg_p;\n \n   \t  gcc_assert (REWRITE_THIS_STMT (phi));\n@@ -1874,21 +2022,23 @@ rewrite_update_phi_arguments (struct dom_walk_data *walk_data ATTRIBUTE_UNUSED,\n \t  if (arg && !DECL_P (arg) && TREE_CODE (arg) != SSA_NAME)\n \t    continue;\n \n+\t  lhs_sym = SSA_NAME_VAR (PHI_RESULT (phi));\n+\n \t  if (arg == NULL_TREE)\n \t    {\n \t      /* When updating a PHI node for a recently introduced\n \t\t symbol we may find NULL arguments.  That's why we\n \t\t take the symbol from the LHS of the PHI node.  */\n-\t      replace_use (arg_p, SSA_NAME_VAR (PHI_RESULT (phi)));\n+\t      SET_USE (arg_p, get_reaching_def (lhs_sym));\n \t    }\n \t  else\n \t    {\n \t      tree sym = DECL_P (arg) ? arg : SSA_NAME_VAR (arg);\n \n \t      if (symbol_marked_for_renaming (sym))\n-\t\treplace_use (arg_p, sym);\n+\t\tSET_USE (arg_p, get_reaching_def (sym));\n \t      else if (is_old_name (arg))\n-\t\treplace_use (arg_p, arg);\n+\t\tSET_USE (arg_p, get_reaching_def (arg));\n \t    }\n \n \t  if (e->flags & EDGE_ABNORMAL)\n@@ -1926,10 +2076,10 @@ rewrite_blocks (basic_block entry, enum rewrite_mode what, sbitmap blocks)\n   walk_data.dom_direction = CDI_DOMINATORS;\n   walk_data.interesting_blocks = blocks;\n \n-  if (what == REWRITE_UPDATE)\n-    walk_data.before_dom_children_before_stmts = rewrite_update_init_block;\n-  else\n+  if (what == REWRITE_ALL)\n     walk_data.before_dom_children_before_stmts = rewrite_initialize_block;\n+  else\n+    walk_data.before_dom_children_before_stmts = rewrite_update_init_block;\n \n   if (what == REWRITE_ALL)\n     walk_data.before_dom_children_walk_stmts = rewrite_stmt;\n@@ -1971,12 +2121,6 @@ rewrite_blocks (basic_block entry, enum rewrite_mode what, sbitmap blocks)\n       if (def_blocks)\n \tdump_tree_ssa_stats (dump_file);\n     }\n-\n-  if (def_blocks)\n-    {\n-      htab_delete (def_blocks);\n-      def_blocks = NULL;\n-    }\n   \n   VEC_free (tree, heap, block_defs_stack);\n \n@@ -1991,10 +2135,9 @@ static void\n mark_def_sites_initialize_block (struct dom_walk_data *walk_data,\n \t\t\t\t basic_block bb ATTRIBUTE_UNUSED)\n {\n-  struct mark_def_sites_global_data *gd =\n-     (struct mark_def_sites_global_data *) walk_data->global_data;\n-  bitmap kills = gd->kills;\n-  bitmap_clear (kills);\n+  struct mark_def_sites_global_data *gd;\n+  gd = (struct mark_def_sites_global_data *) walk_data->global_data;\n+  bitmap_clear (gd->kills);\n }\n \n \n@@ -2010,14 +2153,6 @@ mark_def_site_blocks (sbitmap interesting_blocks)\n {\n   struct dom_walk_data walk_data;\n   struct mark_def_sites_global_data mark_def_sites_global_data;\n-  referenced_var_iterator rvi;\n-  tree var;\n-\n-  /* Allocate memory for the DEF_BLOCKS hash table.  */\n-  def_blocks = htab_create (num_referenced_vars,\n-\t\t\t    def_blocks_hash, def_blocks_eq, def_blocks_free);\n-  FOR_EACH_REFERENCED_VAR(var, rvi)\n-    set_current_def (var, NULL_TREE);\n \n   /* Setup callbacks for the generic dominator tree walker to find and\n      mark definition sites.  */\n@@ -2059,6 +2194,41 @@ mark_def_site_blocks (sbitmap interesting_blocks)\n }\n \n \n+/* Initialize internal data needed during renaming.  */\n+\n+static void\n+init_ssa_renamer (void)\n+{\n+  tree var;\n+  referenced_var_iterator rvi;\n+\n+  cfun->gimple_df->in_ssa_p = false;\n+\n+  /* Allocate memory for the DEF_BLOCKS hash table.  */\n+  gcc_assert (def_blocks == NULL);\n+  def_blocks = htab_create (num_referenced_vars, def_blocks_hash,\n+                            def_blocks_eq, def_blocks_free);\n+\n+  FOR_EACH_REFERENCED_VAR(var, rvi)\n+    set_current_def (var, NULL_TREE);\n+}\n+\n+\n+/* Deallocate internal data structures used by the renamer.  */\n+\n+static void\n+fini_ssa_renamer (void)\n+{\n+  if (def_blocks)\n+    {\n+      htab_delete (def_blocks);\n+      def_blocks = NULL;\n+    }\n+\n+  cfun->gimple_df->in_ssa_p = true;\n+}\n+\n+\n /* Main entry point into the SSA builder.  The renaming process\n    proceeds in four main phases:\n \n@@ -2088,14 +2258,17 @@ rewrite_into_ssa (void)\n   /* Initialize operand data structures.  */\n   init_ssa_operands ();\n \n+  /* Initialize internal data needed by the renamer.  */\n+  init_ssa_renamer ();\n+\n   /* Initialize the set of interesting blocks.  The callback\n      mark_def_sites will add to this set those blocks that the renamer\n      should process.  */\n   interesting_blocks = sbitmap_alloc (last_basic_block);\n   sbitmap_zero (interesting_blocks);\n \n   /* Initialize dominance frontier.  */\n-  dfs = (bitmap *) xmalloc (last_basic_block * sizeof (bitmap));\n+  dfs = XNEWVEC (bitmap, last_basic_block);\n   FOR_EACH_BB (bb)\n     dfs[bb->index] = BITMAP_ALLOC (NULL);\n \n@@ -2118,8 +2291,9 @@ rewrite_into_ssa (void)\n   free (dfs);\n   sbitmap_free (interesting_blocks);\n \n+  fini_ssa_renamer ();\n+\n   timevar_pop (TV_TREE_SSA_OTHER);\n-  cfun->gimple_df->in_ssa_p = true;\n   return 0;\n }\n \n@@ -2212,7 +2386,13 @@ mark_use_interesting (tree var, tree stmt, basic_block bb, bool insert_phi_p)\n \n    If INSERT_PHI_P is true, mark those uses as live in the\n    corresponding block.  This is later used by the PHI placement\n-   algorithm to make PHI pruning decisions.  */\n+   algorithm to make PHI pruning decisions.\n+\n+   FIXME.  Most of this would be unnecessary if we could associate a\n+\t   symbol to all the SSA names that reference it.  But that\n+\t   sounds like it would be expensive to maintain.  Still, it\n+\t   would be interesting to see if it makes better sense to do\n+\t   that.  */\n \n static void\n prepare_block_for_update (basic_block bb, bool insert_phi_p)\n@@ -2260,49 +2440,27 @@ prepare_block_for_update (basic_block bb, bool insert_phi_p)\n       \n       stmt = bsi_stmt (si);\n \n-      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, i, SSA_OP_USE)\n+      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, i, SSA_OP_ALL_USES)\n \t{\n \t  tree use = USE_FROM_PTR (use_p);\n \t  tree sym = DECL_P (use) ? use : SSA_NAME_VAR (use);\n \t  if (symbol_marked_for_renaming (sym))\n-\t    mark_use_interesting (use, stmt, bb, insert_phi_p);\n-\t}\n-\n-      FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, i, SSA_OP_DEF)\n-\t{\n-\t  tree def = DEF_FROM_PTR (def_p);\n-\t  tree sym = DECL_P (def) ? def : SSA_NAME_VAR (def);\n-\n-\t  if (symbol_marked_for_renaming (sym))\n-\t    mark_def_interesting (def, stmt, bb, insert_phi_p);\n+\t    mark_use_interesting (sym, stmt, bb, insert_phi_p);\n \t}\n \n-      FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, i, SSA_OP_VIRTUAL_DEFS)\n+      FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, i, SSA_OP_ALL_DEFS)\n \t{\n \t  tree def = DEF_FROM_PTR (def_p);\n \t  tree sym = DECL_P (def) ? def : SSA_NAME_VAR (def);\n-\n \t  if (symbol_marked_for_renaming (sym))\n-\t    {\n-\t      mark_use_interesting (sym, stmt, bb, insert_phi_p);\n-\t      mark_def_interesting (sym, stmt, bb, insert_phi_p);\n-\t    }\n-\t}\n-\n-      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, i, SSA_OP_VUSE)\n-\t{\n-\t  tree use = USE_FROM_PTR (use_p);\n-\t  tree sym = DECL_P (use) ? use : SSA_NAME_VAR (use);\n-\n-\t  if (symbol_marked_for_renaming (sym))\n-\t    mark_use_interesting (sym, stmt, bb, insert_phi_p);\n+\t    mark_def_interesting (sym, stmt, bb, insert_phi_p);\n \t}\n     }\n \n   /* Now visit all the blocks dominated by BB.  */\n   for (son = first_dom_son (CDI_DOMINATORS, bb);\n-      son;\n-      son = next_dom_son (CDI_DOMINATORS, son))\n+       son;\n+       son = next_dom_son (CDI_DOMINATORS, son))\n     prepare_block_for_update (son, insert_phi_p);\n }\n \n@@ -2469,11 +2627,7 @@ dump_update_ssa (FILE *file)\n   if (syms_to_rename && !bitmap_empty_p (syms_to_rename))\n     {\n       fprintf (file, \"\\n\\nSymbols to be put in SSA form\\n\\n\");\n-      EXECUTE_IF_SET_IN_BITMAP (syms_to_rename, 0, i, bi)\n-\t{\n-\t  print_generic_expr (file, referenced_var (i), 0);\n-\t  fprintf (file, \" \");\n-\t}\n+      dump_decl_set (file, syms_to_rename);\n     }\n \n   if (names_to_release && !bitmap_empty_p (names_to_release))\n@@ -2517,6 +2671,8 @@ init_update_ssa (void)\n   need_to_initialize_update_ssa_p = false;\n   need_to_update_vops_p = false;\n   syms_to_rename = BITMAP_ALLOC (NULL);\n+  regs_to_rename = BITMAP_ALLOC (NULL);\n+  mem_syms_to_rename = BITMAP_ALLOC (NULL);\n   names_to_release = NULL;\n   memset (&update_ssa_stats, 0, sizeof (update_ssa_stats));\n   update_ssa_stats.virtual_symbols = BITMAP_ALLOC (NULL);\n@@ -2543,6 +2699,8 @@ delete_update_ssa (void)\n   need_to_initialize_update_ssa_p = true;\n   need_to_update_vops_p = false;\n   BITMAP_FREE (syms_to_rename);\n+  BITMAP_FREE (regs_to_rename);\n+  BITMAP_FREE (mem_syms_to_rename);\n   BITMAP_FREE (update_ssa_stats.virtual_symbols);\n \n   if (names_to_release)\n@@ -2553,6 +2711,20 @@ delete_update_ssa (void)\n     }\n \n   clear_ssa_name_info ();\n+\n+  fini_ssa_renamer ();\n+\n+  if (blocks_with_phis_to_rewrite)\n+    EXECUTE_IF_SET_IN_BITMAP (blocks_with_phis_to_rewrite, 0, i, bi)\n+      {\n+\ttree_vec phis = VEC_index (tree_vec, phis_to_rewrite, i);\n+\n+\tVEC_free (tree, heap, phis);\n+\tVEC_replace (tree_vec, phis_to_rewrite, i, NULL);\n+      }\n+\n+  BITMAP_FREE (blocks_with_phis_to_rewrite);\n+  BITMAP_FREE (blocks_to_update);\n }\n \n \n@@ -2616,10 +2788,25 @@ mark_sym_for_renaming (tree sym)\n   if (need_to_initialize_update_ssa_p)\n     init_update_ssa ();\n \n+  /* FIXME.  Why do we need this?  */\n+  {\n+    subvar_t svars;\n+    if (var_can_have_subvars (sym) && (svars = get_subvars_for_var (sym)))\n+      {\n+\tsubvar_t sv;\n+\tfor (sv = svars; sv; sv = sv->next)\n+\t  mark_sym_for_renaming (sv->var);\n+      }\n+  }\n+\n   bitmap_set_bit (syms_to_rename, DECL_UID (sym));\n \n   if (!is_gimple_reg (sym))\n-    need_to_update_vops_p = true;\n+    {\n+      need_to_update_vops_p = true;\n+      if (memory_partition (sym))\n+\tbitmap_set_bit (syms_to_rename, DECL_UID (memory_partition (sym)));\n+    }\n }\n \n \n@@ -2631,20 +2818,14 @@ mark_set_for_renaming (bitmap set)\n   bitmap_iterator bi;\n   unsigned i;\n \n-  if (bitmap_empty_p (set))\n+  if (set == NULL || bitmap_empty_p (set))\n     return;\n \n   if (need_to_initialize_update_ssa_p)\n     init_update_ssa ();\n \n-  bitmap_ior_into (syms_to_rename, set);\n-\n   EXECUTE_IF_SET_IN_BITMAP (set, 0, i, bi)\n-    if (!is_gimple_reg (referenced_var (i)))\n-      {\n-\tneed_to_update_vops_p = true;\n-\tbreak;\n-      }\n+    mark_sym_for_renaming (referenced_var (i));\n }\n \n \n@@ -2757,7 +2938,7 @@ insert_updated_phi_nodes_for (tree var, bitmap *dfs, bitmap blocks,\n     return;\n \n   /* Compute the initial iterated dominance frontier.  */\n-  idf = find_idf (db->def_blocks, dfs);\n+  idf = compute_idf (db->def_blocks, dfs);\n   pruned_idf = BITMAP_ALLOC (NULL);\n \n   if (TREE_CODE (var) == SSA_NAME)\n@@ -2769,7 +2950,6 @@ insert_updated_phi_nodes_for (tree var, bitmap *dfs, bitmap blocks,\n \t     common dominator of all the definition blocks.  */\n \t  entry = nearest_common_dominator_for_set (CDI_DOMINATORS,\n \t\t\t\t\t\t    db->def_blocks);\n-\n \t  if (entry != ENTRY_BLOCK_PTR)\n \t    EXECUTE_IF_SET_IN_BITMAP (idf, 0, i, bi)\n \t      if (BASIC_BLOCK (i) != entry\n@@ -2797,6 +2977,9 @@ insert_updated_phi_nodes_for (tree var, bitmap *dfs, bitmap blocks,\n \t are included in the region to be updated.  The feeding blocks\n \t are important to guarantee that the PHI arguments are renamed\n \t properly.  */\n+\n+      /* FIXME, this is not needed if we are updating symbols.  We are\n+\t already starting at the ENTRY block anyway.  */\n       bitmap_ior_into (blocks, pruned_idf);\n       EXECUTE_IF_SET_IN_BITMAP (pruned_idf, 0, i, bi)\n \t{\n@@ -2880,7 +3063,7 @@ switch_virtuals_to_full_rewrite (void)\n     if (!is_gimple_reg (ssa_name (i)))\n       RESET_BIT (old_ssa_names, i);\n \n-  bitmap_ior_into (syms_to_rename, update_ssa_stats.virtual_symbols);\n+  mark_set_for_renaming (update_ssa_stats.virtual_symbols);\n }\n \n \n@@ -3011,6 +3194,35 @@ update_ssa (unsigned update_flags)\n   if (insert_phi_p && switch_virtuals_to_full_rewrite_p ())\n     switch_virtuals_to_full_rewrite ();\n \n+  /* If there are symbols to rename, identify those symbols that are\n+     GIMPLE registers into the set REGS_TO_RENAME and those that are\n+     memory symbols into the set MEM_SYMS_TO_RENAME.  */\n+  if (!bitmap_empty_p (syms_to_rename))\n+    {\n+      unsigned i;\n+      bitmap_iterator bi;\n+\n+      EXECUTE_IF_SET_IN_BITMAP (syms_to_rename, 0, i, bi)\n+\t{\n+\t  tree sym = referenced_var (i);\n+\t  if (is_gimple_reg (sym))\n+\t    bitmap_set_bit (regs_to_rename, i);\n+\t  else\n+\t    {\n+\t      /* Memory partitioning information may have been\n+\t\t computed after the symbol was marked for renaming,\n+\t\t if SYM is inside a partition also mark the partition\n+\t\t for renaming.  */\n+\t      tree mpt = memory_partition (sym);\n+\t      if (mpt)\n+\t\tbitmap_set_bit (syms_to_rename, DECL_UID (mpt));\n+\t    }\n+\t}\n+\n+      /* Memory symbols are those not in REGS_TO_RENAME.  */\n+      bitmap_and_compl (mem_syms_to_rename, syms_to_rename, regs_to_rename);\n+    }\n+\n   /* If there are names defined in the replacement table, prepare\n      definition and use sites for all the names in NEW_SSA_NAMES and\n      OLD_SSA_NAMES.  */\n@@ -3036,10 +3248,10 @@ update_ssa (unsigned update_flags)\n \t updating.  For now this seems more work than it's worth.  */\n       start_bb = ENTRY_BLOCK_PTR;\n \n-      /* Traverse the CFG looking for definitions and uses of symbols\n-\t in SYMS_TO_RENAME.  Mark interesting blocks and statements\n-\t and set local live-in information for the PHI placement\n-\t heuristics.  */\n+      /* Traverse the CFG looking for existing definitions and uses of\n+\t symbols in SYMS_TO_RENAME.  Mark interesting blocks and\n+\t statements and set local live-in information for the PHI\n+\t placement heuristics.  */\n       prepare_block_for_update (start_bb, insert_phi_p);\n     }\n   else\n@@ -3082,8 +3294,8 @@ update_ssa (unsigned update_flags)\n \t}\n \n       EXECUTE_IF_SET_IN_BITMAP (syms_to_rename, 0, i, bi)\n-\tinsert_updated_phi_nodes_for (referenced_var (i), dfs,\n-\t\t\t\t      blocks_to_update, update_flags);\n+\tinsert_updated_phi_nodes_for (referenced_var (i), dfs, blocks_to_update,\n+\t                              update_flags);\n \n       FOR_EACH_BB (bb)\n \tBITMAP_FREE (dfs[bb->index]);\n@@ -3146,15 +3358,6 @@ update_ssa (unsigned update_flags)\n \n   /* Free allocated memory.  */\n done:\n-  EXECUTE_IF_SET_IN_BITMAP (blocks_with_phis_to_rewrite, 0, i, bi)\n-    {\n-      tree_vec phis = VEC_index (tree_vec, phis_to_rewrite, i);\n-\n-      VEC_free (tree, heap, phis);\n-      VEC_replace (tree_vec, phis_to_rewrite, i, NULL);\n-    }\n-  BITMAP_FREE (blocks_with_phis_to_rewrite);\n-  BITMAP_FREE (blocks_to_update);\n   delete_update_ssa ();\n \n   timevar_pop (TV_TREE_SSA_INCREMENTAL);"}, {"sha": "bed7c33ecb7ed6e31a8766ebaf1066872b2e2f42", "filename": "gcc/tree-pass.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-pass.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-pass.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pass.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -68,6 +68,8 @@ enum tree_dump_index\n #define TDF_STMTADDR\t(1 << 12)\t/* Address of stmt.  */\n \n #define TDF_GRAPH\t(1 << 13)\t/* a graph dump is being emitted */\n+#define TDF_MEMSYMS\t(1 << 14)\t/* display memory symbols in expr.\n+                                           Implies TDF_VOPS.  */\n \n extern char *get_dump_file_name (enum tree_dump_index);\n extern int dump_enabled_p (enum tree_dump_index);"}, {"sha": "fac5d29cac5106cd2bc7ef9ffd00f64ce7a3ee45", "filename": "gcc/tree-pretty-print.c", "status": "modified", "additions": 106, "deletions": 34, "changes": 140, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-pretty-print.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-pretty-print.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pretty-print.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -87,14 +87,14 @@ do_niy (pretty_printer *buffer, tree node)\n void\n debug_generic_expr (tree t)\n {\n-  print_generic_expr (stderr, t, TDF_VOPS|TDF_UID);\n+  print_generic_expr (stderr, t, TDF_VOPS|TDF_MEMSYMS);\n   fprintf (stderr, \"\\n\");\n }\n \n void\n debug_generic_stmt (tree t)\n {\n-  print_generic_stmt (stderr, t, TDF_VOPS|TDF_UID);\n+  print_generic_stmt (stderr, t, TDF_VOPS|TDF_MEMSYMS);\n   fprintf (stderr, \"\\n\");\n }\n \n@@ -103,7 +103,7 @@ debug_tree_chain (tree t)\n {\n   while (t)\n   {\n-    print_generic_expr (stderr, t, TDF_VOPS|TDF_UID);\n+    print_generic_expr (stderr, t, TDF_VOPS|TDF_MEMSYMS|TDF_UID);\n     fprintf(stderr, \" \");\n     t = TREE_CHAIN (t);\n   }\n@@ -402,6 +402,33 @@ dump_omp_clauses (pretty_printer *buffer, tree clause, int spc, int flags)\n }\n \n \n+/* Dump the set of decls SYMS.  BUFFER, SPC and FLAGS are as in\n+   dump_generic_node.  */\n+\n+static void\n+dump_symbols (pretty_printer *buffer, bitmap syms, int flags)\n+{\n+  unsigned i;\n+  bitmap_iterator bi;\n+\n+  if (syms == NULL)\n+    pp_string (buffer, \"NIL\");\n+  else\n+    {\n+      pp_string (buffer, \" { \");\n+\n+      EXECUTE_IF_SET_IN_BITMAP (syms, 0, i, bi)\n+\t{\n+\t  tree sym = referenced_var_lookup (i);\n+\t  dump_generic_node (buffer, sym, 0, flags, false);\n+\t  pp_string (buffer, \" \");\n+\t}\n+\n+      pp_string (buffer, \"}\");\n+    }\n+}\n+\n+\n /* Dump the node NODE on the pretty_printer BUFFER, SPC spaces of indent.\n    FLAGS specifies details to show in the dump (see TDF_* in tree.h).  If\n    IS_STMT is true, the object printed is considered to be a statement\n@@ -427,7 +454,7 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n      if you call it on something with a non-stmt annotation attached.  */\n   if (TREE_CODE (node) != ERROR_MARK\n       && is_gimple_stmt (node)\n-      && (flags & TDF_VOPS)\n+      && (flags & (TDF_VOPS|TDF_MEMSYMS))\n       && has_stmt_ann (node)\n       && TREE_CODE (node) != PHI_NODE)\n     dump_vops (buffer, node, spc, flags);\n@@ -855,6 +882,7 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n     case PARM_DECL:\n     case FIELD_DECL:\n     case NAMESPACE_DECL:\n+    case MEMORY_PARTITION_TAG:\n       dump_decl_name (buffer, node, flags);\n       break;\n \n@@ -1626,7 +1654,10 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n \t    if (i < PHI_NUM_ARGS (node) - 1)\n \t      pp_string (buffer, \", \");\n \t  }\n-\tpp_string (buffer, \">;\");\n+\tpp_string (buffer, \">\");\n+\n+\tif (stmt_references_memory_p (node) && (flags & TDF_MEMSYMS))\n+\t  dump_symbols (buffer, STORED_SYMS (node), flags);\n       }\n       break;\n \n@@ -1636,6 +1667,8 @@ dump_generic_node (pretty_printer *buffer, tree node, int spc, int flags,\n       pp_decimal_int (buffer, SSA_NAME_VERSION (node));\n       if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (node))\n \tpp_string (buffer, \"(ab)\");\n+      else if (SSA_NAME_IS_DEFAULT_DEF (node))\n+\tpp_string (buffer, \"(D)\");\n       break;\n \n     case WITH_SIZE_EXPR:\n@@ -2654,51 +2687,89 @@ newline_and_indent (pretty_printer *buffer, int spc)\n   INDENT (spc);\n }\n \n+\n static void\n dump_vops (pretty_printer *buffer, tree stmt, int spc, int flags)\n {\n-  tree use;\n-  use_operand_p use_p;\n-  def_operand_p def_p;\n-  use_operand_p kill_p;\n-  ssa_op_iter iter;\n+  struct vdef_optype_d *vdefs;\n+  struct vuse_optype_d *vuses;\n+  int i, n;\n \n-  if (!ssa_operands_active ())\n+  if (!ssa_operands_active () || !stmt_references_memory_p (stmt))\n     return;\n \n-  FOR_EACH_SSA_MAYDEF_OPERAND (def_p, use_p, stmt, iter)\n+  /* Even if the statement doesn't have virtual operators yet, it may\n+     contain symbol information (this happens before aliases have been\n+     computed).  */\n+  if ((flags & TDF_MEMSYMS)\n+      && VUSE_OPS (stmt) == NULL\n+      && VDEF_OPS (stmt) == NULL)\n     {\n-      pp_string (buffer, \"#   \");\n-      dump_generic_node (buffer, DEF_FROM_PTR (def_p),\n-                         spc + 2, flags, false);\n-      pp_string (buffer, \" = V_MAY_DEF <\");\n-      dump_generic_node (buffer, USE_FROM_PTR (use_p),\n-                         spc + 2, flags, false);\n-      pp_string (buffer, \">;\");\n-      newline_and_indent (buffer, spc);\n+      if (LOADED_SYMS (stmt))\n+\t{\n+\t  pp_string (buffer, \"# LOADS: \");\n+\t  dump_symbols (buffer, LOADED_SYMS (stmt), flags);\n+\t  newline_and_indent (buffer, spc);\n+\t}\n+\n+      if (STORED_SYMS (stmt))\n+\t{\n+\t  pp_string (buffer, \"# STORES: \");\n+\t  dump_symbols (buffer, STORED_SYMS (stmt), flags);\n+\t  newline_and_indent (buffer, spc);\n+\t}\n+\n+      return;\n     }\n \n-  FOR_EACH_SSA_MUSTDEF_OPERAND (def_p, kill_p, stmt, iter)\n+  vuses = VUSE_OPS (stmt);\n+  while (vuses)\n     {\n-      pp_string (buffer, \"#   \");\n-      dump_generic_node (buffer, DEF_FROM_PTR (def_p),\n-                         spc + 2, flags, false);\n-      pp_string (buffer, \" = V_MUST_DEF <\");\n-      dump_generic_node (buffer, USE_FROM_PTR (kill_p),\n-                         spc + 2, flags, false);\n-      pp_string (buffer, \">;\");\n+      pp_string (buffer, \"# VUSE <\");\n+\n+      n = VUSE_NUM (vuses);\n+      for (i = 0; i < n; i++)\n+\t{\n+\t  dump_generic_node (buffer, VUSE_OP (vuses, i), spc + 2, flags, false);\n+\t  if (i < n - 1)\n+\t    pp_string (buffer, \", \");\n+\t}\n+\n+      pp_string (buffer, \">\");\n+\n+      if (flags & TDF_MEMSYMS)\n+\tdump_symbols (buffer, LOADED_SYMS (stmt), flags);\n+\n       newline_and_indent (buffer, spc);\n+      vuses = vuses->next;\n     }\n \n-  FOR_EACH_SSA_TREE_OPERAND (use, stmt, iter, SSA_OP_VUSE)\n+  vdefs = VDEF_OPS (stmt);\n+  while (vdefs)\n     {\n-      pp_string (buffer, \"#   VUSE <\");\n-      dump_generic_node (buffer, use, spc + 2, flags, false);\n-      pp_string (buffer, \">;\");\n+      pp_string (buffer, \"# \");\n+      dump_generic_node (buffer, VDEF_RESULT (vdefs), spc + 2, flags, false);\n+      pp_string (buffer, \" = VDEF <\");\n+\n+      n = VDEF_NUM (vdefs);\n+      for (i = 0; i < n; i++)\n+\t{\n+\t  dump_generic_node (buffer, VDEF_OP (vdefs, i), spc + 2, flags, 0);\n+\t  if (i < n - 1)\n+\t    pp_string (buffer, \", \");\n+\t}\n+\n+      pp_string (buffer, \">\");\n+\n+      if ((flags & TDF_MEMSYMS) && vdefs->next == NULL)\n+\tdump_symbols (buffer, STORED_SYMS (stmt), flags);\n+\n       newline_and_indent (buffer, spc);\n+      vdefs = vdefs->next;\n     }\n }\n \n+\n /* Dumps basic block BB to FILE with details described by FLAGS and\n    indented by INDENT spaces.  */\n \n@@ -2807,8 +2878,8 @@ dump_bb_end (pretty_printer *buffer, basic_block bb, int indent, int flags)\n   pp_newline (buffer);\n }\n \n-/* Dumps phi nodes of basic block BB to buffer BUFFER with details described by\n-   FLAGS indented by INDENT spaces.  */\n+/* Dump PHI nodes of basic block BB to BUFFER with details described\n+   by FLAGS and indented by INDENT spaces.  */\n \n static void\n dump_phi_nodes (pretty_printer *buffer, basic_block bb, int indent, int flags)\n@@ -2829,6 +2900,7 @@ dump_phi_nodes (pretty_printer *buffer, basic_block bb, int indent, int flags)\n     }\n }\n \n+\n /* Dump jump to basic block BB that is represented implicitly in the cfg\n    to BUFFER.  */\n "}, {"sha": "14507ad3adf84576e88209c0f184a7659a40f532", "filename": "gcc/tree-sra.c", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-sra.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-sra.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-sra.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1563,8 +1563,9 @@ decide_instantiations (void)\n \f\n /* Phase Four: Update the function to match the replacements created.  */\n \n-/* Mark all the variables in V_MAY_DEF or V_MUST_DEF operands for STMT for\n-   renaming. This becomes necessary when we modify all of a non-scalar.  */\n+/* Mark all the variables in VDEF/VUSE operators for STMT for\n+   renaming. This becomes necessary when we modify all of a\n+   non-scalar.  */\n \n static void\n mark_all_v_defs_1 (tree stmt)\n@@ -1599,6 +1600,7 @@ mark_all_v_defs (tree list)\n     }\n }\n \n+\n /* Mark every replacement under ELT with TREE_NO_WARNING.  */\n \n static void\n@@ -2358,8 +2360,9 @@ struct tree_opt_pass pass_sra =\n   0,\t\t\t\t\t/* properties_provided */\n   0,\t\t\t\t        /* properties_destroyed */\n   0,\t\t\t\t\t/* todo_flags_start */\n-  TODO_dump_func /* todo_flags_finish */\n+  TODO_dump_func\n   | TODO_update_ssa\n-  | TODO_ggc_collect | TODO_verify_ssa,\n+  | TODO_ggc_collect\n+  | TODO_verify_ssa,\t\t\t/* todo_flags_finish */\n   0\t\t\t\t\t/* letter */\n };"}, {"sha": "05cc516b9140ed076b8876100bb0571777b1ef51", "filename": "gcc/tree-ssa-alias.c", "status": "modified", "additions": 623, "deletions": 628, "changes": 1251, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-alias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-alias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-alias.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -47,33 +47,31 @@ Boston, MA 02110-1301, USA.  */\n #include \"vec.h\"\n #include \"bitmap.h\"\n #include \"vecprim.h\"\n+#include \"pointer-set.h\"\n \n-/* Obstack used to hold grouping bitmaps and other temporary bitmaps used by\n-   aliasing  */\n-static bitmap_obstack alias_obstack;\n-\n-/* Structure to map a variable to its alias set and keep track of the\n-   virtual operands that will be needed to represent it.  */\n+/* Structure to map a variable to its alias set.  */\n struct alias_map_d\n {\n   /* Variable and its alias set.  */\n   tree var;\n   HOST_WIDE_INT set;\n+};\n \n-  /* Total number of virtual operands that will be needed to represent\n-     all the aliases of VAR.  */\n-  long total_alias_vops;\n \n-  /* Nonzero if the aliases for this memory tag have been grouped\n-     already.  Used in group_aliases.  */\n-  unsigned int grouped_p : 1;\n+/* Data structures used for computing memory partitions.  */\n \n-  /* Set of variables aliased with VAR.  This is the exact same\n-     information contained in VAR_ANN (VAR)->MAY_ALIASES, but in\n-     bitmap form to speed up alias grouping.  */\n-  bitmap may_aliases;\n+struct mp_info_def\n+{\n+  /* Symbol or memory tag.  */\n+  tree var;\n+\n+  /* Number of virtual operators needed to represent references to VAR.  */\n+  long num_vops;\n };\n \n+typedef struct mp_info_def *mp_info_t;\n+DEF_VEC_P(mp_info_t);\n+DEF_VEC_ALLOC_P(mp_info_t, heap);\n \n /* Counters used to display statistics on alias analysis.  */\n struct alias_stats_d\n@@ -99,21 +97,48 @@ static void finalize_ref_all_pointers (struct alias_info *);\n static void dump_alias_stats (FILE *);\n static bool may_alias_p (tree, HOST_WIDE_INT, tree, HOST_WIDE_INT, bool);\n static tree create_memory_tag (tree type, bool is_type_tag);\n-static tree get_tmt_for (tree, struct alias_info *);\n+static tree get_smt_for (tree, struct alias_info *);\n static tree get_nmt_for (tree);\n-static void add_may_alias (tree, tree);\n-static void replace_may_alias (tree, size_t, tree);\n+static void add_may_alias (tree, tree, struct pointer_set_t *);\n static struct alias_info *init_alias_info (void);\n static void delete_alias_info (struct alias_info *);\n static void compute_flow_sensitive_aliasing (struct alias_info *);\n static void setup_pointers_and_addressables (struct alias_info *);\n static void create_global_var (void);\n static void maybe_create_global_var (struct alias_info *ai);\n-static void group_aliases (struct alias_info *);\n static void set_pt_anything (tree ptr);\n \n+void dump_mp_info (FILE *, VEC(mp_info_t,heap) *mp_info_t);\n+void debug_mp_info (VEC(mp_info_t,heap) *mp_info_t);\n+\n /* Global declarations.  */\n \n+/* Mark variable VAR as being non-addressable.  */\n+\n+static void\n+mark_non_addressable (tree var)\n+{\n+  tree mpt;\n+\n+  if (!TREE_ADDRESSABLE (var))\n+    return;\n+\n+  mpt = memory_partition (var);\n+\n+  if (!MTAG_P (var))\n+    DECL_CALL_CLOBBERED (var) = false;\n+\n+  bitmap_clear_bit (gimple_call_clobbered_vars (cfun), DECL_UID (var));\n+  TREE_ADDRESSABLE (var) = 0;\n+\n+  if (mpt)\n+    {\n+      bitmap_clear_bit (MPT_SYMBOLS (mpt), DECL_UID (var));\n+      set_memory_partition (var, NULL_TREE);\n+    }\n+}\n+\n+\n /* qsort comparison function to sort type/name tags by DECL_UID.  */\n \n static int\n@@ -316,7 +341,7 @@ set_initial_properties (struct alias_info *ai)\n   for (i = 0; VEC_iterate (tree, ai->processed_ptrs, i, ptr); i++)\n     {\n       struct ptr_info_def *pi = SSA_NAME_PTR_INFO (ptr);\n-      var_ann_t v_ann = var_ann (SSA_NAME_VAR (ptr));\n+      tree tag = symbol_mem_tag (SSA_NAME_VAR (ptr));\n       \n       if (pi->value_escapes_p)\n \t{\n@@ -325,8 +350,8 @@ set_initial_properties (struct alias_info *ai)\n \t  if (pi->name_mem_tag)\n \t    mark_call_clobbered (pi->name_mem_tag, pi->escape_mask);\n \n-\t  if (v_ann->symbol_mem_tag)\n-\t    mark_call_clobbered (v_ann->symbol_mem_tag, pi->escape_mask);\n+\t  if (tag)\n+\t    mark_call_clobbered (tag, pi->escape_mask);\n \n \t  if (pi->pt_vars)\n \t    {\n@@ -341,9 +366,9 @@ set_initial_properties (struct alias_info *ai)\n       /* If the name tag is call clobbered, so is the symbol tag\n \t associated with the base VAR_DECL.  */\n       if (pi->name_mem_tag\n-\t  && v_ann->symbol_mem_tag\n+\t  && tag\n \t  && is_call_clobbered (pi->name_mem_tag))\n-\tmark_call_clobbered (v_ann->symbol_mem_tag, pi->escape_mask);\n+\tmark_call_clobbered (tag, pi->escape_mask);\n \n       /* Name tags and symbol tags that we don't know where they point\n \t to, might point to global memory, and thus, are clobbered.\n@@ -362,10 +387,10 @@ set_initial_properties (struct alias_info *ai)\n       \n       if ((pi->pt_global_mem || pi->pt_anything) \n \t  && pi->is_dereferenced\n-\t  && v_ann->symbol_mem_tag)\n+\t  && tag)\n \t{\n-\t  mark_call_clobbered (v_ann->symbol_mem_tag, ESCAPE_IS_GLOBAL);\n-\t  MTAG_GLOBAL (v_ann->symbol_mem_tag) = true;\n+\t  mark_call_clobbered (tag, ESCAPE_IS_GLOBAL);\n+\t  MTAG_GLOBAL (tag) = true;\n \t}\n     }\n }\n@@ -395,6 +420,356 @@ compute_call_clobbered (struct alias_info *ai)\n   compute_tag_properties ();\n }\n \n+/* Dump the MP_INFO array to FILE.  */\n+\n+void\n+dump_mp_info (FILE *file, VEC(mp_info_t,heap) *mp_info)\n+{\n+  unsigned i;\n+  mp_info_t mp_p;\n+\n+  for (i = 0; VEC_iterate (mp_info_t, mp_info, i, mp_p); i++)\n+    {\n+      fprintf (file, \"%6lu\\t\", mp_p->num_vops);\n+      if (mp_p->var == NULL_TREE)\n+\t{\n+\t  fprintf (file, \"CALL-CLOBBERED SYMBOLS: \");\n+\t  dump_decl_set (file, gimple_call_clobbered_vars (cfun));\n+\t}\n+      else\n+\tdump_variable (file, mp_p->var);\n+    }\n+}\n+\n+\n+/* Dump the MP_INFO array to stderr.  */\n+\n+void\n+debug_mp_info (VEC(mp_info_t,heap) *mp_info)\n+{\n+  dump_mp_info (stderr, mp_info);\n+}\n+\n+\n+/* Comparison function for qsort used in sort_mp_info.  */\n+\n+static int\n+mp_info_cmp (const void *p, const void *q)\n+{\n+  mp_info_t e1 = *((const mp_info_t *) p);\n+  mp_info_t e2 = *((const mp_info_t *) q);\n+\n+  /* We want to sort in decreasing order.  */\n+  if (e1->num_vops < e2->num_vops)\n+    return 1;\n+  else if (e1->num_vops > e2->num_vops)\n+    return -1;\n+  else\n+    return 0;\n+}\n+\n+\n+/* Sort the array of reference counts used to compute memory partitions.\n+   Elements are sorted in descending order of virtual operators needed.  */\n+\n+static inline void\n+sort_mp_info (VEC(mp_info_t,heap) *list)\n+{\n+  unsigned num = VEC_length (mp_info_t, list);\n+\n+  if (num < 2)\n+    return;\n+\n+  if (num == 2)\n+    {\n+      if (VEC_index (mp_info_t, list, 0)->num_vops\n+\t  < VEC_index (mp_info_t, list, 1)->num_vops)\n+\t{  \n+\t  /* Swap elements if they are in the wrong order.  */\n+\t  mp_info_t tmp = VEC_index (mp_info_t, list, 0);\n+\t  VEC_replace (mp_info_t, list, 0, VEC_index (mp_info_t, list, 1));\n+\t  VEC_replace (mp_info_t, list, 1, tmp);\n+\t}\n+\n+      return;\n+    }\n+\n+  /* There are 3 or more elements, call qsort.  */\n+  qsort (VEC_address (mp_info_t, list), VEC_length (mp_info_t, list), \n+\t sizeof (mp_info_t), mp_info_cmp);\n+}\n+\n+\n+/* Create a new partition to hold all the symbols aliased with\n+   MP_P->VAR.  If MP_P->VAR is NULL, it partitions the call-clobbered\n+   variables. Only symbols that are not already in another partition\n+   are added to the new partition created for MP_P->VAR.  */\n+\n+static void\n+create_partition_for (mp_info_t mp_p)\n+{\n+  tree mpt, sym;\n+  VEC(tree,gc) *aliases;\n+  unsigned i;\n+\n+  if (mp_p->num_vops <= (long) MAX_ALIASED_VOPS)\n+    return;\n+\n+  if (mp_p->var == NULL_TREE)\n+    {\n+      bitmap_iterator bi;\n+      bitmap tmp;\n+\n+      /* Since the partitions we create for call-clobbered variables\n+\t will also be marked call-clobbered, make a copy of the\n+\t original set to avoid confusing the iterator.  */\n+      tmp = BITMAP_ALLOC (NULL);\n+      bitmap_copy (tmp, gimple_call_clobbered_vars (cfun));\n+\n+      /* Process call-clobbered symbols when no MP_P->VAR is given.  */\n+      mpt = NULL_TREE;\n+      EXECUTE_IF_SET_IN_BITMAP (tmp, 0, i, bi)\n+\t{\n+\t  tree sym = referenced_var (i);\n+\t  if (memory_partition (sym) == NULL_TREE)\n+\t    {\n+\t      if (mpt == NULL_TREE)\n+\t\t{\n+\t\t  mpt = get_mpt_for (sym);\n+\t\t  mp_p->num_vops++;\n+\t\t}\n+\n+\t      mark_sym_for_renaming (mpt);\n+\t      mark_sym_for_renaming (sym);\n+\t      set_memory_partition (sym, mpt);\n+\t    }\n+\n+\t  mp_p->num_vops--;\n+\n+\t  /* If we have already grouped enough, stop.  */\n+\t  if (mp_p->num_vops <= (long) MAX_ALIASED_VOPS)\n+\t    break;\n+\t}\n+\n+      BITMAP_FREE (tmp);\n+    }\n+  else\n+    {\n+      aliases = may_aliases (mp_p->var);\n+      gcc_assert (VEC_length (tree, aliases) > 1);\n+\n+      mpt = NULL_TREE;\n+      for (i = 0; VEC_iterate (tree, aliases, i, sym); i++)\n+\t{\n+\t  /* Only set the memory partition for aliased symbol SYM if\n+\t     SYM does not belong to another partition.  */\n+\t  if (memory_partition (sym) == NULL_TREE)\n+\t    {\n+\t      if (mpt == NULL_TREE)\n+\t\t{\n+\t\t  mpt = get_mpt_for (mp_p->var);\n+\t\t  mp_p->num_vops++;\n+\t\t}\n+\n+\t      mark_sym_for_renaming (mpt);\n+\t      mark_sym_for_renaming (sym);\n+\t      set_memory_partition (sym, mpt);\n+\t    }\n+\n+\t  mp_p->num_vops--;\n+\n+\t  /* If we have already grouped enough, stop.  */\n+\t  if (mp_p->num_vops <= (long) MAX_ALIASED_VOPS)\n+\t    break;\n+\t}\n+\n+      if (mpt)\n+\tmark_call_clobbered (mpt, ESCAPE_UNKNOWN);\n+    }\n+}\n+\n+\n+/* Rewrite the alias set for TAG to use the newly created partitions.\n+   If TAG is NULL, rewrite the set of call-clobbered variables.\n+   NEW_ALIASES is a scratch bitmap to build the new set of aliases for\n+   TAG.  */\n+\n+static void\n+rewrite_alias_set_for (tree tag, bitmap new_aliases)\n+{\n+  bitmap_iterator bi;\n+  unsigned i;\n+  tree mpt, sym;\n+\n+  if (tag == NULL_TREE)\n+    {\n+      /* Do not rewrite CALL_CLOBBERED_VARS.  If a symbol S is taken\n+\t out of this set, the optimizers will no longer consider S as\n+\t call-clobbered, and that may lead to wrong transformations\n+\t (e.g., pass_tail_calls explicitly examines all the symbols in\n+\t the function to determine if it should enable tail-call\n+\t marking).  */\n+      return;\n+    }\n+  else\n+    {\n+      /* Create a new alias set for TAG with the new partitions.  */\n+      var_ann_t ann;\n+\n+      ann = var_ann (tag);\n+      for (i = 0; VEC_iterate (tree, ann->may_aliases, i, sym); i++)\n+\t{\n+\t  mpt = memory_partition (sym);\n+\t  if (mpt)\n+\t    bitmap_set_bit (new_aliases, DECL_UID (mpt));\n+\t  else\n+\t    bitmap_set_bit (new_aliases, DECL_UID (sym));\n+\t}\n+\n+      /* Rebuild the may-alias array for TAG.  */\n+      VEC_free (tree, gc, ann->may_aliases);\n+      EXECUTE_IF_SET_IN_BITMAP (new_aliases, 0, i, bi)\n+\tVEC_safe_push (tree, gc, ann->may_aliases, referenced_var (i));\n+    }\n+}\n+\n+\n+/* Compute memory partitions.\n+\n+   The partitioning is straightforward:\n+   \n+   1- All the memory tags and call-clobbered that cause virtual\n+      operators are collected into the MP_INFO table together with the\n+      number of virtual operands that would be needed to represent all\n+      the members in the alias set.\n+\n+   2- MP_INFO is sorted in decreasing order of virtual operators.\n+\n+   3- For every memory tag T in MP_INFO, a new partition MP is created.  \n+\n+   4- All the symbols S in T's alias set are examined.  If S is not\n+      already in another partition then S is added to partition MP.\n+\n+   6- The estimate of VOPS is updated, if it falls below\n+      MAX_ALIASED_VOPS, we stop.  */\n+\n+static void\n+compute_memory_partitions (void)\n+{\n+  referenced_var_iterator rvi;\n+  tree var;\n+  unsigned i;\n+  struct mp_info_def mp;\n+  mp_info_t mp_p;\n+  VEC(mp_info_t,heap) *mp_info;\n+  long max_num_vops = 0;\n+  bitmap new_aliases;\n+\n+  timevar_push (TV_MEMORY_PARTITIONING);\n+\n+  mp_info = NULL;\n+  max_num_vops = 0;\n+\n+  /* Add reference counts for all the call-clobbered variables.  */\n+  if (!bitmap_empty_p (gimple_call_clobbered_vars (cfun)))\n+    {\n+      mp.var = NULL_TREE;\n+      mp.num_vops = bitmap_count_bits (gimple_call_clobbered_vars (cfun));\n+      max_num_vops = mp.num_vops;\n+      mp_p = xcalloc (1, sizeof (*mp_p));\n+      *mp_p = mp;\n+      VEC_safe_push (mp_info_t, heap, mp_info, mp_p);\n+    }\n+\n+  /* Add reference counts for all the symbol tags.  */\n+  FOR_EACH_REFERENCED_VAR (var, rvi)\n+    {\n+      if (TREE_CODE (var) != SYMBOL_MEMORY_TAG\n+\t  && TREE_CODE (var) != NAME_MEMORY_TAG)\n+\tcontinue;\n+\n+      /* Each reference to VAR will produce as many VOPs as elements\n+\t exist in its alias set.  */\n+      mp.var = var;\n+      mp.num_vops = VEC_length (tree, may_aliases (var));\n+\n+      /* No point grouping singleton alias sets.  */\n+      if (mp.num_vops <= 1)\n+\tcontinue;\n+\n+      mp_p = xcalloc (1, sizeof (*mp_p));\n+      *mp_p = mp;\n+      VEC_safe_push (mp_info_t, heap, mp_info, mp_p);\n+\n+      if (mp.num_vops > max_num_vops)\n+\tmax_num_vops = mp.num_vops;\n+    }\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"\\n%s: Maximum number of VOPS needed per statement: \"\n+\t       \"%ld\\n\", get_name (current_function_decl), max_num_vops);\n+    }\n+\n+  /* No partitions required if we are below the threshold.  */\n+  if (max_num_vops <= (long) MAX_ALIASED_VOPS)\n+    goto done;\n+\n+  /* Sort the MP_INFO array in order of decreasing number of\n+     virtual operands.  */\n+  sort_mp_info (mp_info);\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"\\nVOPS generated by pointer dereferences \"\n+\t\t\t  \"before partitioning:\\n\");\n+      dump_mp_info (dump_file, mp_info);\n+    }\n+\n+  /* Now that we have all the VOP generating tags in the MP_INFO array\n+     sorted by decreasing number of VOPS, create memory partitions and\n+     group aliased symbols into those partitions.  */\n+  for (i = 0; VEC_iterate (mp_info_t, mp_info, i, mp_p); i++)\n+    {\n+      /* Stop processing if we are already below the threshold.  */\n+      if (mp_p->num_vops <= (long) MAX_ALIASED_VOPS)\n+\tbreak;\n+\n+      create_partition_for (mp_p);\n+    }\n+\n+  /* After partitions have been created, rewrite alias sets to use\n+     them instead of the original symbols.  This way, if the alias set\n+     was computed as { a b c d e f }, and the subset { b e f } was\n+     grouped into partition MPT.3, then the new alias set for the tag\n+     will be  { a c d MPT.3 }.  */\n+  new_aliases = BITMAP_ALLOC (NULL);\n+\n+  for (i = 0; VEC_iterate (mp_info_t, mp_info, i, mp_p); i++)\n+    {\n+      rewrite_alias_set_for (mp_p->var, new_aliases);\n+      bitmap_clear (new_aliases);\n+    }\n+\n+  BITMAP_FREE (new_aliases);\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"\\nVOPS generated by pointer dereferences \"\n+\t\t\t  \"after partitioning:\\n\");\n+      dump_mp_info (dump_file, mp_info);\n+    }\n+\n+done:\n+  /* Free allocated memory.  */\n+  for (i = 0; VEC_iterate (mp_info_t, mp_info, i, mp_p); i++)\n+    free (mp_p);\n+  VEC_free (mp_info_t, heap, mp_info);\n+\n+  timevar_pop (TV_MEMORY_PARTITIONING);\n+}\n+\n+\n /* Compute may-alias information for every variable referenced in function\n    FNDECL.\n \n@@ -481,11 +856,11 @@ compute_call_clobbered (struct alias_info *ai)\n \t\tp_6 = &b;\n \t      # p_1 = PHI <p_4(1), p_6(2)>;\n \n-\t      # a_7 = V_MAY_DEF <a_3>;\n-\t      # b_8 = V_MAY_DEF <b_5>;\n+\t      # a_7 = VDEF <a_3>;\n+\t      # b_8 = VDEF <b_5>;\n \t      *p_1 = 3;\n \n-\t      # a_9 = V_MAY_DEF <a_7>\n+\t      # a_9 = VDEF <a_7>\n \t      # VUSE <b_8>\n \t      a_9 = b_8 + 2;\n \n@@ -537,15 +912,10 @@ compute_may_aliases (void)\n   /* Compute call clobbering information.  */\n   compute_call_clobbered (ai);\n \n-  /* Determine if we need to enable alias grouping.  */\n-  if (ai->total_alias_vops >= MAX_ALIASED_VOPS)\n-    group_aliases (ai);\n-\n-  /* If the program has too many call-clobbered variables and/or function\n-     calls, create .GLOBAL_VAR and use it to model call-clobbering\n-     semantics at call sites.  This reduces the number of virtual operands\n-     considerably, improving compile times at the expense of lost\n-     aliasing precision.  */\n+  /* If the program makes no reference to global variables, but it\n+     contains a mixture of pure and non-pure functions, then we need\n+     to create use-def and def-def links between these functions to\n+     avoid invalid transformations on them.  */\n   maybe_create_global_var (ai);\n \n   /* If the program contains ref-all pointers, finalize may-alias information\n@@ -554,6 +924,9 @@ compute_may_aliases (void)\n   if (ai->ref_all_symbol_mem_tag)\n     finalize_ref_all_pointers (ai);\n \n+  /* Compute memory partitions for every memory variable.  */\n+  compute_memory_partitions ();\n+\n   /* Debugging dumps.  */\n   if (dump_file)\n     {\n@@ -727,14 +1100,13 @@ init_alias_info (void)\n   referenced_var_iterator rvi;\n   tree var;\n \n-  bitmap_obstack_initialize (&alias_obstack);\n   ai = XCNEW (struct alias_info);\n   ai->ssa_names_visited = sbitmap_alloc (num_ssa_names);\n   sbitmap_zero (ai->ssa_names_visited);\n   ai->processed_ptrs = VEC_alloc (tree, heap, 50);\n-  ai->written_vars = BITMAP_ALLOC (&alias_obstack);\n-  ai->dereferenced_ptrs_store = BITMAP_ALLOC (&alias_obstack);\n-  ai->dereferenced_ptrs_load = BITMAP_ALLOC (&alias_obstack);\n+  ai->written_vars = pointer_set_create ();\n+  ai->dereferenced_ptrs_store = pointer_set_create ();\n+  ai->dereferenced_ptrs_load = pointer_set_create ();\n \n   /* If aliases have been computed before, clear existing information.  */\n   if (gimple_aliases_computed_p (cfun))\n@@ -753,7 +1125,6 @@ init_alias_info (void)\n \t  \n \t  ann->is_aliased = 0;\n \t  ann->may_aliases = NULL;\n-\t  NUM_REFERENCES_CLEAR (ann);\n \n \t  /* Since we are about to re-discover call-clobbered\n \t     variables, clear the call-clobbered flag.  Variables that\n@@ -797,6 +1168,15 @@ init_alias_info (void)\n \t    }\n \t}\n     }\n+  else\n+    {\n+      /* If this is the first time we compute aliasing information,\n+\t every non-register symbol will need to be put into SSA form\n+\t (the initial SSA form only operates on GIMPLE registers).  */\n+      FOR_EACH_REFERENCED_VAR (var, rvi)\n+\tif (!is_gimple_reg (var))\n+\t  mark_sym_for_renaming (var);\n+    }\n \n   /* Next time, we will need to reset alias information.  */\n   cfun->gimple_df->aliases_computed_p = true;\n@@ -811,31 +1191,22 @@ static void\n delete_alias_info (struct alias_info *ai)\n {\n   size_t i;\n-  referenced_var_iterator rvi;\n-  tree var;\n \n   sbitmap_free (ai->ssa_names_visited);\n+\n   VEC_free (tree, heap, ai->processed_ptrs);\n \n   for (i = 0; i < ai->num_addressable_vars; i++)\n     free (ai->addressable_vars[i]);\n-  \n-  FOR_EACH_REFERENCED_VAR(var, rvi)\n-    {\n-      var_ann_t ann = var_ann (var);\n-      NUM_REFERENCES_CLEAR (ann);\n-    }\n-\n   free (ai->addressable_vars);\n-\n+  \n   for (i = 0; i < ai->num_pointers; i++)\n     free (ai->pointers[i]);\n   free (ai->pointers);\n \n-  BITMAP_FREE (ai->written_vars);\n-  BITMAP_FREE (ai->dereferenced_ptrs_store);\n-  BITMAP_FREE (ai->dereferenced_ptrs_load);\n-  bitmap_obstack_release (&alias_obstack);\n+  pointer_set_destroy (ai->written_vars);\n+  pointer_set_destroy (ai->dereferenced_ptrs_store);\n+  pointer_set_destroy (ai->dereferenced_ptrs_load);\n   free (ai);\n \n   delete_points_to_sets ();\n@@ -989,65 +1360,86 @@ compute_flow_sensitive_aliasing (struct alias_info *ai)\n     {\n       unsigned j;\n       struct ptr_info_def *pi = SSA_NAME_PTR_INFO (ptr);\n-      var_ann_t v_ann = var_ann (SSA_NAME_VAR (ptr));\n+      tree tag = symbol_mem_tag (SSA_NAME_VAR (ptr));\n       bitmap_iterator bi;\n \n-\n       /* Set up aliasing information for PTR's name memory tag (if it has\n \t one).  Note that only pointers that have been dereferenced will\n \t have a name memory tag.  */\n       if (pi->name_mem_tag && pi->pt_vars)\n \tEXECUTE_IF_SET_IN_BITMAP (pi->pt_vars, 0, j, bi)\n \t  {\n-\t    add_may_alias (pi->name_mem_tag, referenced_var (j));\n-\t    if (j != DECL_UID (v_ann->symbol_mem_tag))\n-\t      add_may_alias (v_ann->symbol_mem_tag, referenced_var (j));\n+\t    add_may_alias (pi->name_mem_tag, referenced_var (j), NULL);\n+\t    if (j != DECL_UID (tag))\n+\t      add_may_alias (tag, referenced_var (j), NULL);\n \t  }\n     }\n }\n \n \n+/* Return TRUE if at least one symbol in TAG's alias set is also\n+   present in SET1.  */\n+\n+static bool\n+have_common_aliases_p (struct pointer_set_t *set1, tree tag2)\n+{\n+  unsigned i;\n+  VEC(tree,gc) *aliases2;\n+\n+  if (set1 == NULL)\n+    return false;\n+\n+  aliases2 = may_aliases (tag2);\n+  for (i = 0; i < VEC_length (tree, aliases2); i++)\n+    if (pointer_set_contains (set1, VEC_index (tree, aliases2, i)))\n+      return true;\n+\n+  return false;\n+}\n+\n+\n /* Compute type-based alias sets.  Traverse all the pointers and\n    addressable variables found in setup_pointers_and_addressables.\n    \n    For every pointer P in AI->POINTERS and addressable variable V in\n    AI->ADDRESSABLE_VARS, add V to the may-alias sets of P's symbol\n    memory tag (SMT) if their alias sets conflict.  V is then marked as\n-   an alias tag so that the operand scanner knows that statements\n+   an aliased symbol so that the operand scanner knows that statements\n    containing V have aliased operands.  */\n \n static void\n compute_flow_insensitive_aliasing (struct alias_info *ai)\n {\n   size_t i;\n \n-  /* Initialize counter for the total number of virtual operands that\n-     aliasing will introduce.  When AI->TOTAL_ALIAS_VOPS goes beyond the\n-     threshold set by --params max-alias-vops, we enable alias\n-     grouping.  */\n-  ai->total_alias_vops = 0;\n+  /* Initialize pointer sets to keep track of duplicates in alias\n+     sets.  */\n+  for (i = 0; i < ai->num_pointers; i++)\n+    {\n+      tree tag = symbol_mem_tag (ai->pointers[i]->var);\n+      var_ann (tag)->common.aux = NULL;\n+    }\n \n   /* For every pointer P, determine which addressable variables may alias\n      with P's symbol memory tag.  */\n   for (i = 0; i < ai->num_pointers; i++)\n     {\n       size_t j;\n+      struct pointer_set_t *already_added;\n       struct alias_map_d *p_map = ai->pointers[i];\n-      tree tag = var_ann (p_map->var)->symbol_mem_tag;\n-      var_ann_t tag_ann = var_ann (tag);\n+      tree tag = symbol_mem_tag (p_map->var);\n       tree var;\n \n       /* Call-clobbering information is not finalized yet at this point.  */\n       if (PTR_IS_REF_ALL (p_map->var))\n \tcontinue;\n \n-      p_map->total_alias_vops = 0;\n-      p_map->may_aliases = BITMAP_ALLOC (&alias_obstack);\n+      /* Retrieve or create the set of symbols that have already been\n+\t added to TAG's alias set.  */\n+      if (var_ann (tag)->common.aux == NULL)\n+\tvar_ann (tag)->common.aux = (void *) pointer_set_create ();\n \n-      /* Add any pre-existing may_aliases to the bitmap used to represent\n-\t TAG's alias set in case we need to group aliases.  */\n-      for (j = 0; VEC_iterate (tree, tag_ann->may_aliases, j, var); ++j)\n-\tbitmap_set_bit (p_map->may_aliases, DECL_UID (var));\n+      already_added = (struct pointer_set_t *) var_ann (tag)->common.aux;\n \n       for (j = 0; j < ai->num_addressable_vars; j++)\n \t{\n@@ -1062,48 +1454,23 @@ compute_flow_insensitive_aliasing (struct alias_info *ai)\n \t  /* Skip memory tags and variables that have never been\n \t     written to.  We also need to check if the variables are\n \t     call-clobbered because they may be overwritten by\n-\t     function calls.\n-\n-\t     Note this is effectively random accessing elements in\n-\t     the sparse bitset, which can be highly inefficient.\n-\t     So we first check the call_clobbered status of the\n-\t     tag and variable before querying the bitmap.  */\n-\t  tag_stored_p = is_call_clobbered (tag)\n-\t                 || bitmap_bit_p (ai->written_vars, DECL_UID (tag));\n-\t  var_stored_p = is_call_clobbered (var)\n-\t                 || bitmap_bit_p (ai->written_vars, DECL_UID (var));\n+\t     function calls.  */\n+\t  tag_stored_p = pointer_set_contains (ai->written_vars, tag)\n+\t                 || is_call_clobbered (tag);\n+\t  var_stored_p = pointer_set_contains (ai->written_vars, var)\n+\t                 || is_call_clobbered (var);\n \t  if (!tag_stored_p && !var_stored_p)\n \t    continue;\n \t     \n \t  if (may_alias_p (p_map->var, p_map->set, var, v_map->set, false))\n \t    {\n-\t      size_t num_tag_refs, num_var_refs;\n-\n-\t      num_tag_refs = NUM_REFERENCES (tag_ann);\n-\t      num_var_refs = NUM_REFERENCES (v_ann);\n-\n-\t      /* Add VAR to TAG's may-aliases set.  */\n-\n \t      /* We should never have a var with subvars here, because\n \t         they shouldn't get into the set of addressable vars */\n \t      gcc_assert (!var_can_have_subvars (var)\n \t\t\t  || get_subvars_for_var (var) == NULL);\n \n-\t      add_may_alias (tag, var);\n-\t      /* Update the bitmap used to represent TAG's alias set\n-\t\t in case we need to group aliases.  */\n-\t      bitmap_set_bit (p_map->may_aliases, DECL_UID (var));\n-\n-\t      /* Update the total number of virtual operands due to\n-\t\t aliasing.  Since we are adding one more alias to TAG's\n-\t\t may-aliases set, the total number of virtual operands due\n-\t\t to aliasing will be increased by the number of references\n-\t\t made to VAR and TAG (every reference to TAG will also\n-\t\t count as a reference to VAR).  */\n-\t      ai->total_alias_vops += (num_var_refs + num_tag_refs);\n-\t      p_map->total_alias_vops += (num_var_refs + num_tag_refs);\n-\n-\n+\t      /* Add VAR to TAG's may-aliases set.  */\n+\t      add_may_alias (tag, var, already_added);\n \t    }\n \t}\n     }\n@@ -1131,18 +1498,20 @@ compute_flow_insensitive_aliasing (struct alias_info *ai)\n   for (i = 0; i < ai->num_pointers; i++)\n     {\n       size_t j;\n+      struct pointer_set_t *set1;\n       struct alias_map_d *p_map1 = ai->pointers[i];\n-      tree tag1 = var_ann (p_map1->var)->symbol_mem_tag;\n-      bitmap may_aliases1 = p_map1->may_aliases;\n+      tree tag1 = symbol_mem_tag (p_map1->var);\n \n       if (PTR_IS_REF_ALL (p_map1->var))\n \tcontinue;\n \n+      set1 = (struct pointer_set_t *) var_ann (tag1)->common.aux;\n+\n       for (j = i + 1; j < ai->num_pointers; j++)\n \t{\n \t  struct alias_map_d *p_map2 = ai->pointers[j];\n-\t  tree tag2 = var_ann (p_map2->var)->symbol_mem_tag;\n-\t  bitmap may_aliases2 = p_map2->may_aliases;\n+\t  tree tag2 = symbol_mem_tag (p_map2->var);\n+\t  VEC(tree,gc) *may_aliases2 = may_aliases (tag2);\n \n \t  if (PTR_IS_REF_ALL (p_map2->var))\n \t    continue;\n@@ -1153,34 +1522,38 @@ compute_flow_insensitive_aliasing (struct alias_info *ai)\n \n \t  /* The two pointers may alias each other.  If they already have\n \t     symbols in common, do nothing.  */\n-\t  if (bitmap_intersect_p (may_aliases1, may_aliases2))\n+\t  if (have_common_aliases_p (set1, tag2))\n \t    continue;\n \n-\t  if (!bitmap_empty_p (may_aliases2))\n+\t  if (set1 == NULL)\n \t    {\n-\t      unsigned int k;\n-\t      bitmap_iterator bi;\n+\t      set1 = pointer_set_create ();\n+\t      var_ann (tag1)->common.aux = (void *) set1;\n+\t    }\n+\n+\t  if (VEC_length (tree, may_aliases2) > 0)\n+\t    {\n+\t      unsigned k;\n+\t      tree sym;\n \n-\t      /* Add all the aliases for TAG2 into TAG1's alias set.\n-\t\t FIXME, update grouping heuristic counters.  */\n-\t      EXECUTE_IF_SET_IN_BITMAP (may_aliases2, 0, k, bi)\n-\t\tadd_may_alias (tag1, referenced_var (k));\n-\t      bitmap_ior_into (may_aliases1, may_aliases2);\n+\t      /* Add all the aliases for TAG2 into TAG1's alias set.  */\n+\t      for (k = 0; VEC_iterate (tree, may_aliases2, k, sym); k++)\n+\t\tadd_may_alias (tag1, sym, set1);\n \t    }\n \t  else\n \t    {\n \t      /* Since TAG2 does not have any aliases of its own, add\n \t\t TAG2 itself to the alias set of TAG1.  */\n-\t      add_may_alias (tag1, tag2);\n-\t      bitmap_set_bit (may_aliases1, DECL_UID (tag2));\n+\t      add_may_alias (tag1, tag2, set1);\n \t    }\n \t}\n+\n+      if (set1)\n+\t{\n+\t  pointer_set_destroy (set1);\n+\t  var_ann (tag1)->common.aux = NULL;\n+\t}\n     }\n-  \n-  if (dump_file)\n-    fprintf (dump_file, \"\\n%s: Total number of aliased vops: %ld\\n\",\n-\t     get_name (current_function_decl),\n-\t     ai->total_alias_vops);\n }\n \n \n@@ -1197,326 +1570,29 @@ static void\n finalize_ref_all_pointers (struct alias_info *ai)\n {\n   size_t i;\n+  struct pointer_set_t *already_added = pointer_set_create ();\n \n-  if (gimple_global_var (cfun))\n-    add_may_alias (ai->ref_all_symbol_mem_tag, gimple_global_var (cfun));\n-  else\n-    {\n-      /* First add the real call-clobbered variables.  */\n-      for (i = 0; i < ai->num_addressable_vars; i++)\n-\t{\n-\t  tree var = ai->addressable_vars[i]->var;\n-\t  if (is_call_clobbered (var))\n-\t    add_may_alias (ai->ref_all_symbol_mem_tag, var);\n-        }\n-\n-      /* Then add the call-clobbered pointer memory tags.  See\n-\t compute_flow_insensitive_aliasing for the rationale.  */\n-      for (i = 0; i < ai->num_pointers; i++)\n-\t{\n-\t  tree ptr = ai->pointers[i]->var, tag;\n-\t  if (PTR_IS_REF_ALL (ptr))\n-\t    continue;\n-\t  tag = var_ann (ptr)->symbol_mem_tag;\n-\t  if (is_call_clobbered (tag))\n-\t    add_may_alias (ai->ref_all_symbol_mem_tag, tag);\n-\t}\n-    }\n-}\n-\n-\n-/* Comparison function for qsort used in group_aliases.  */\n-\n-static int\n-total_alias_vops_cmp (const void *p, const void *q)\n-{\n-  const struct alias_map_d **p1 = (const struct alias_map_d **)p;\n-  const struct alias_map_d **p2 = (const struct alias_map_d **)q;\n-  long n1 = (*p1)->total_alias_vops;\n-  long n2 = (*p2)->total_alias_vops;\n-\n-  /* We want to sort in descending order.  */\n-  return (n1 > n2 ? -1 : (n1 == n2) ? 0 : 1);\n-}\n-\n-/* Group all the aliases for TAG to make TAG represent all the\n-   variables in its alias set.  Update the total number\n-   of virtual operands due to aliasing (AI->TOTAL_ALIAS_VOPS).  This\n-   function will make TAG be the unique alias tag for all the\n-   variables in its may-aliases.  So, given:\n-\n-   \tmay-aliases(TAG) = { V1, V2, V3 }\n-\n-   This function will group the variables into:\n-\n-   \tmay-aliases(V1) = { TAG }\n-\tmay-aliases(V2) = { TAG }\n-\tmay-aliases(V2) = { TAG }  */\n-\n-static void\n-group_aliases_into (tree tag, bitmap tag_aliases, struct alias_info *ai)\n-{\n-  unsigned int i;\n-  var_ann_t tag_ann = var_ann (tag);\n-  size_t num_tag_refs = NUM_REFERENCES (tag_ann);\n-  bitmap_iterator bi;\n-\n-  EXECUTE_IF_SET_IN_BITMAP (tag_aliases, 0, i, bi)\n-    {\n-      tree var = referenced_var (i);\n-      var_ann_t ann = var_ann (var);\n-\n-      /* Make TAG the unique alias of VAR.  */\n-      ann->is_aliased = 0;\n-      ann->may_aliases = NULL;\n-\n-      /* Note that VAR and TAG may be the same if the function has no\n-\t addressable variables (see the discussion at the end of\n-\t setup_pointers_and_addressables).  */\n-      if (var != tag)\n-\tadd_may_alias (var, tag);\n-\n-      /* Reduce total number of virtual operands contributed\n-\t by TAG on behalf of VAR.  Notice that the references to VAR\n-\t itself won't be removed.  We will merely replace them with\n-\t references to TAG.  */\n-      ai->total_alias_vops -= num_tag_refs;\n-    }\n-\n-  /* We have reduced the number of virtual operands that TAG makes on\n-     behalf of all the variables formerly aliased with it.  However,\n-     we have also \"removed\" all the virtual operands for TAG itself,\n-     so we add them back.  */\n-  ai->total_alias_vops += num_tag_refs;\n-\n-  /* TAG no longer has any aliases.  */\n-  tag_ann->may_aliases = NULL;\n-}\n-\n-/* Replacing may aliases in name tags during grouping can up with the\n-   same SMT multiple times in the may_alias list.  It's quicker to\n-   just remove them post-hoc than it is to avoid them during\n-   replacement.  Thus, this routine sorts the may-alias list and\n-   removes duplicates.  */\n-\n-static void\n-compact_name_tags (void)\n-{\n-  referenced_var_iterator rvi;\n-  tree var;\n-\n-  FOR_EACH_REFERENCED_VAR (var, rvi)\n+  /* First add the real call-clobbered variables.  */\n+  for (i = 0; i < ai->num_addressable_vars; i++)\n     {\n-      if (TREE_CODE (var) == NAME_MEMORY_TAG)\n-\t{\n-\t  VEC(tree, gc) *aliases, *new_aliases;\n-\t  tree alias, last_alias;\n-\t  int i;\n-\t  \n-\t  last_alias = NULL;\n-\t  aliases = var_ann (var)->may_aliases;\n-\t  new_aliases = NULL;\n-\t  \n-\t  if (VEC_length (tree, aliases) > 1)\n-\t    {\n-\t      bool changed = false;\n-\t      qsort (VEC_address (tree, aliases), \n-\t\t     VEC_length (tree, aliases),\n-\t\t     sizeof (tree), sort_tags_by_id);\n-\t      \n-\t      for (i = 0; VEC_iterate (tree, aliases, i, alias); i++)\n-\t\t{\n-\t\t  if (alias == last_alias)\n-\t\t    {\n-\t\t      changed = true;\n-\t\t      continue;\n-\t\t    }\n-\t\t  \n-\t\t  VEC_safe_push (tree, gc, new_aliases, alias);\n-\t\t  last_alias = alias;\n-\t\t}\n-\n-\t      /* Only replace the array if something has changed.  */\n-\t      if (changed)\n-\t\t{\n-\t\t  VEC_free (tree, gc, aliases);\n-\t\t  var_ann (var)->may_aliases = new_aliases;\n-\t\t}\n-\t      else\n-\t\tVEC_free (tree, gc, new_aliases);\n-\t    }\n-\t}\n+      tree var = ai->addressable_vars[i]->var;\n+      if (is_call_clobbered (var))\n+\tadd_may_alias (ai->ref_all_symbol_mem_tag, var, already_added);\n     }\n-}\n-\n-/* Group may-aliases sets to reduce the number of virtual operands due\n-   to aliasing.\n-\n-     1- Sort the list of pointers in decreasing number of contributed\n-\tvirtual operands.\n-\n-     2- Take the first entry in AI->POINTERS and revert the role of\n-\tthe memory tag and its aliases.  Usually, whenever an aliased\n-\tvariable Vi is found to alias with a memory tag T, we add Vi\n-\tto the may-aliases set for T.  Meaning that after alias\n-\tanalysis, we will have:\n-\n-\t\tmay-aliases(T) = { V1, V2, V3, ..., Vn }\n-\n-\tThis means that every statement that references T, will get 'n'\n-\tvirtual operands for each of the Vi tags.  But, when alias\n-\tgrouping is enabled, we make T an alias tag and add it to the\n-\talias set of all the Vi variables:\n-\n-\t\tmay-aliases(V1) = { T }\n-\t\tmay-aliases(V2) = { T }\n-\t\t...\n-\t\tmay-aliases(Vn) = { T }\n-\n-\tThis has two effects: (a) statements referencing T will only get\n-\ta single virtual operand, and, (b) all the variables Vi will now\n-\tappear to alias each other.  So, we lose alias precision to\n-\timprove compile time.  But, in theory, a program with such a high\n-\tlevel of aliasing should not be very optimizable in the first\n-\tplace.\n-\n-     3- Since variables may be in the alias set of more than one\n-\tmemory tag, the grouping done in step (2) needs to be extended\n-\tto all the memory tags that have a non-empty intersection with\n-\tthe may-aliases set of tag T.  For instance, if we originally\n-\thad these may-aliases sets:\n-\n-\t\tmay-aliases(T) = { V1, V2, V3 }\n-\t\tmay-aliases(R) = { V2, V4 }\n-\n-\tIn step (2) we would have reverted the aliases for T as:\n-\n-\t\tmay-aliases(V1) = { T }\n-\t\tmay-aliases(V2) = { T }\n-\t\tmay-aliases(V3) = { T }\n-\n-\tBut note that now V2 is no longer aliased with R.  We could\n-\tadd R to may-aliases(V2), but we are in the process of\n-\tgrouping aliases to reduce virtual operands so what we do is\n-\tadd V4 to the grouping to obtain:\n-\n-\t\tmay-aliases(V1) = { T }\n-\t\tmay-aliases(V2) = { T }\n-\t\tmay-aliases(V3) = { T }\n-\t\tmay-aliases(V4) = { T }\n-\n-     4- If the total number of virtual operands due to aliasing is\n-\tstill above the threshold set by max-alias-vops, go back to (2).  */\n-\n-static void\n-group_aliases (struct alias_info *ai)\n-{\n-  size_t i;\n-  tree ptr;\n \n-  /* Sort the POINTERS array in descending order of contributed\n-     virtual operands.  */\n-  qsort (ai->pointers, ai->num_pointers, sizeof (struct alias_map_d *),\n-         total_alias_vops_cmp);\n-\n-  /* For every pointer in AI->POINTERS, reverse the roles of its tag\n-     and the tag's may-aliases set.  */\n+  /* Then add the call-clobbered pointer memory tags.  See\n+     compute_flow_insensitive_aliasing for the rationale.  */\n   for (i = 0; i < ai->num_pointers; i++)\n     {\n-      size_t j;\n-      tree tag1 = var_ann (ai->pointers[i]->var)->symbol_mem_tag;\n-      bitmap tag1_aliases = ai->pointers[i]->may_aliases;\n-\n-      /* Skip tags that have been grouped already.  */\n-      if (ai->pointers[i]->grouped_p)\n-\tcontinue;\n-\n-      /* See if TAG1 had any aliases in common with other symbol tags.\n-\t If we find a TAG2 with common aliases with TAG1, add TAG2's\n-\t aliases into TAG1.  */\n-      for (j = i + 1; j < ai->num_pointers; j++)\n-\t{\n-\t  bitmap tag2_aliases = ai->pointers[j]->may_aliases;\n-\n-          if (bitmap_intersect_p (tag1_aliases, tag2_aliases))\n-\t    {\n-\t      tree tag2 = var_ann (ai->pointers[j]->var)->symbol_mem_tag;\n-\n-\t      bitmap_ior_into (tag1_aliases, tag2_aliases);\n-\n-\t      /* TAG2 does not need its aliases anymore.  */\n-\t      bitmap_clear (tag2_aliases);\n-\t      var_ann (tag2)->may_aliases = NULL;\n-\n-\t      /* TAG1 is the unique alias of TAG2.  */\n-\t      add_may_alias (tag2, tag1);\n-\n-\t      ai->pointers[j]->grouped_p = true;\n-\t    }\n-\t}\n-\n-      /* Now group all the aliases we collected into TAG1.  */\n-      group_aliases_into (tag1, tag1_aliases, ai);\n-\n-      /* If we've reduced total number of virtual operands below the\n-\t threshold, stop.  */\n-      if (ai->total_alias_vops < MAX_ALIASED_VOPS)\n-\tbreak;\n-    }\n-\n-  /* Finally, all the variables that have been grouped cannot be in\n-     the may-alias set of name memory tags.  Suppose that we have\n-     grouped the aliases in this code so that may-aliases(a) = SMT.20\n-\n-     \tp_5 = &a;\n-\t...\n-\t# a_9 = V_MAY_DEF <a_8>\n-\tp_5->field = 0\n-\t... Several modifications to SMT.20 ... \n-\t# VUSE <a_9>\n-\tx_30 = p_5->field\n-\n-     Since p_5 points to 'a', the optimizers will try to propagate 0\n-     into p_5->field, but that is wrong because there have been\n-     modifications to 'SMT.20' in between.  To prevent this we have to\n-     replace 'a' with 'SMT.20' in the name tag of p_5.  */\n-  for (i = 0; VEC_iterate (tree, ai->processed_ptrs, i, ptr); i++)\n-    {\n-      size_t j;\n-      tree name_tag = SSA_NAME_PTR_INFO (ptr)->name_mem_tag;\n-      VEC(tree,gc) *aliases;\n-      tree alias;\n-      \n-      if (name_tag == NULL_TREE)\n+      tree ptr = ai->pointers[i]->var, tag;\n+      if (PTR_IS_REF_ALL (ptr))\n \tcontinue;\n-\n-      aliases = var_ann (name_tag)->may_aliases;\n-      for (j = 0; VEC_iterate (tree, aliases, j, alias); j++)\n-\t{\n-\t  var_ann_t ann = var_ann (alias);\n-\n-\t  if ((!MTAG_P (alias)\n-\t       || TREE_CODE (alias) == STRUCT_FIELD_TAG)\n-\t      && ann->may_aliases)\n-\t    {\n-\t      tree new_alias;\n-\n-\t      gcc_assert (VEC_length (tree, ann->may_aliases) == 1);\n-\n-\t      new_alias = VEC_index (tree, ann->may_aliases, 0);\n-\t      replace_may_alias (name_tag, j, new_alias);\n-\t    }\n-\t}\n+      tag = symbol_mem_tag (ptr);\n+      if (is_call_clobbered (tag))\n+\tadd_may_alias (ai->ref_all_symbol_mem_tag, tag, already_added);\n     }\n \n-  compact_name_tags ();\n-\n-  if (dump_file)\n-    fprintf (dump_file,\n-\t     \"%s: Total number of aliased vops after grouping: %ld%s\\n\",\n-\t     get_name (current_function_decl),\n-\t     ai->total_alias_vops,\n-\t     (ai->total_alias_vops < 0) ? \" (negative values are OK)\" : \"\");\n+  pointer_set_destroy (already_added);\n }\n \n \n@@ -1542,7 +1618,7 @@ create_alias_map_for (tree var, struct alias_info *ai)\n static void\n setup_pointers_and_addressables (struct alias_info *ai)\n {\n-  size_t n_vars, num_addressable_vars, num_pointers;\n+  size_t num_addressable_vars, num_pointers;\n   referenced_var_iterator rvi;\n   tree var;\n   VEC (tree, heap) *varvec = NULL;\n@@ -1561,7 +1637,7 @@ setup_pointers_and_addressables (struct alias_info *ai)\n \t  /* Since we don't keep track of volatile variables, assume that\n \t     these pointers are used in indirect store operations.  */\n \t  if (TREE_THIS_VOLATILE (var))\n-\t    bitmap_set_bit (ai->dereferenced_ptrs_store, DECL_UID (var));\n+\t    pointer_set_insert (ai->dereferenced_ptrs_store, var);\n \n \t  num_pointers++;\n \t}\n@@ -1577,14 +1653,8 @@ setup_pointers_and_addressables (struct alias_info *ai)\n   ai->num_addressable_vars = 0;\n   ai->num_pointers = 0;\n \n-  /* Since we will be creating symbol memory tags within this loop,\n-     cache the value of NUM_REFERENCED_VARS to avoid processing the\n-     additional tags unnecessarily.  */\n-  n_vars = num_referenced_vars;\n-\n   FOR_EACH_REFERENCED_VAR_SAFE (var, varvec, srvi)\n     {\n-      var_ann_t v_ann = var_ann (var);\n       subvar_t svars;\n \n       /* Name memory tags already have flow-sensitive aliasing\n@@ -1637,131 +1707,98 @@ setup_pointers_and_addressables (struct alias_info *ai)\n \t\t addressable bit, so that it can be optimized as a\n \t\t regular variable.  */\n \t      if (okay_to_mark)\n-\t\tmark_non_addressable (var);\n+\t\t{\n+\t\t  /* The memory partition holding VAR will no longer\n+\t\t     contain VAR, and statements referencing it will need\n+\t\t     to be udpated.  */\n+\t\t  if (memory_partition (var))\n+\t\t    mark_sym_for_renaming (memory_partition (var));\n+\n+\t\t  mark_non_addressable (var);\n+\t\t}\n \t    }\n \t}\n \n       /* Global variables and addressable locals may be aliased.  Create an\n          entry in ADDRESSABLE_VARS for VAR.  */\n-      if (may_be_aliased (var)\t  \n-\t  && (!var_can_have_subvars (var) \n-\t      || get_subvars_for_var (var) == NULL))\n+      if (may_be_aliased (var))\n \t{\n-\t  create_alias_map_for (var, ai);\n+\t  if (!var_can_have_subvars (var)\n+\t      || get_subvars_for_var (var) == NULL)\n+\t    create_alias_map_for (var, ai);\n+\n \t  mark_sym_for_renaming (var);\n \t}\n \n       /* Add pointer variables that have been dereferenced to the POINTERS\n          array and create a symbol memory tag for them.  */\n       if (POINTER_TYPE_P (TREE_TYPE (var)))\n \t{\n-\t  if ((bitmap_bit_p (ai->dereferenced_ptrs_store, DECL_UID (var))\n-\t       || bitmap_bit_p (ai->dereferenced_ptrs_load, DECL_UID (var))))\n+\t  if ((pointer_set_contains (ai->dereferenced_ptrs_store, var)\n+\t       || pointer_set_contains (ai->dereferenced_ptrs_load, var)))\n \t    {\n-\t      tree tag;\n+\t      tree tag, old_tag;\n \t      var_ann_t t_ann;\n \n \t      /* If pointer VAR still doesn't have a memory tag\n \t\t associated with it, create it now or re-use an\n \t\t existing one.  */\n-\t      tag = get_tmt_for (var, ai);\n+\t      tag = get_smt_for (var, ai);\n \t      t_ann = var_ann (tag);\n \n \t      /* The symbol tag will need to be renamed into SSA\n \t\t afterwards. Note that we cannot do this inside\n-\t\t get_tmt_for because aliasing may run multiple times\n+\t\t get_smt_for because aliasing may run multiple times\n \t\t and we only create symbol tags the first time.  */\n \t      mark_sym_for_renaming (tag);\n \n \t      /* Similarly, if pointer VAR used to have another type\n \t\t tag, we will need to process it in the renamer to\n \t\t remove the stale virtual operands.  */\n-\t      if (v_ann->symbol_mem_tag)\n-\t\tmark_sym_for_renaming (v_ann->symbol_mem_tag);\n+\t      old_tag = symbol_mem_tag (var);\n+\t      if (old_tag)\n+\t\tmark_sym_for_renaming (old_tag);\n \n \t      /* Associate the tag with pointer VAR.  */\n-\t      v_ann->symbol_mem_tag = tag;\n+\t      set_symbol_mem_tag (var, tag);\n \n \t      /* If pointer VAR has been used in a store operation,\n \t\t then its memory tag must be marked as written-to.  */\n-\t      if (bitmap_bit_p (ai->dereferenced_ptrs_store, DECL_UID (var)))\n-\t\tbitmap_set_bit (ai->written_vars, DECL_UID (tag));\n-\n-\t      /* All the dereferences of pointer VAR count as\n-\t\t references of TAG.  Since TAG can be associated with\n-\t\t several pointers, add the dereferences of VAR to the\n-\t\t TAG.  */\n-\t      NUM_REFERENCES_SET (t_ann, \n-\t\t\t\t  NUM_REFERENCES (t_ann)\n-\t\t\t\t  + NUM_REFERENCES (v_ann));\n+\t      if (pointer_set_contains (ai->dereferenced_ptrs_store, var))\n+\t\tpointer_set_insert (ai->written_vars, tag);\n \t    }\n \t  else\n \t    {\n \t      /* The pointer has not been dereferenced.  If it had a\n \t\t symbol memory tag, remove it and mark the old tag for\n \t\t renaming to remove it out of the IL.  */\n-\t      var_ann_t ann = var_ann (var);\n-\t      tree tag = ann->symbol_mem_tag;\n+\t      tree tag = symbol_mem_tag (var);\n \t      if (tag)\n \t\t{\n \t\t  mark_sym_for_renaming (tag);\n-\t\t  ann->symbol_mem_tag = NULL_TREE;\n+\t\t  set_symbol_mem_tag (var, NULL_TREE);\n \t\t}\n \t    }\n \t}\n     }\n+\n   VEC_free (tree, heap, varvec);\n }\n \n \n-/* Determine whether to use .GLOBAL_VAR to model call clobbering semantics. At\n-   every call site, we need to emit V_MAY_DEF expressions to represent the\n-   clobbering effects of the call for variables whose address escapes the\n-   current function.\n-\n-   One approach is to group all call-clobbered variables into a single\n-   representative that is used as an alias of every call-clobbered variable\n-   (.GLOBAL_VAR).  This works well, but it ties the optimizer hands because\n-   references to any call clobbered variable is a reference to .GLOBAL_VAR.\n-\n-   The second approach is to emit a clobbering V_MAY_DEF for every \n-   call-clobbered variable at call sites.  This is the preferred way in terms \n-   of optimization opportunities but it may create too many V_MAY_DEF operands\n-   if there are many call clobbered variables and function calls in the \n-   function.\n-\n-   To decide whether or not to use .GLOBAL_VAR we multiply the number of\n-   function calls found by the number of call-clobbered variables.  If that\n-   product is beyond a certain threshold, as determined by the parameterized\n-   values shown below, we use .GLOBAL_VAR.\n-\n-   FIXME.  This heuristic should be improved.  One idea is to use several\n-   .GLOBAL_VARs of different types instead of a single one.  The thresholds\n-   have been derived from a typical bootstrap cycle, including all target\n-   libraries. Compile times were found increase by ~1% compared to using\n-   .GLOBAL_VAR.  */\n+/* Determine whether to use .GLOBAL_VAR to model call clobbering\n+   semantics.  If the function makes no references to global\n+   variables and contains at least one call to a non-pure function,\n+   then we need to mark the side-effects of the call using .GLOBAL_VAR\n+   to represent all possible global memory referenced by the callee.  */\n \n static void\n maybe_create_global_var (struct alias_info *ai)\n {\n-  unsigned i, n_clobbered;\n-  bitmap_iterator bi;\n-  \n   /* No need to create it, if we have one already.  */\n   if (gimple_global_var (cfun) == NULL_TREE)\n     {\n-      /* Count all the call-clobbered variables.  */\n-      n_clobbered = 0;\n-      EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, i, bi)\n-\t{\n-\t  n_clobbered++;\n-\t}\n-\n-      /* If the number of virtual operands that would be needed to\n-\t model all the call-clobbered variables is larger than\n-\t GLOBAL_VAR_THRESHOLD, create .GLOBAL_VAR.\n-\n-\t Also create .GLOBAL_VAR if there are no call-clobbered\n+      /* Create .GLOBAL_VAR if there are no call-clobbered\n \t variables and the program contains a mixture of pure/const\n \t and regular function calls.  This is to avoid the problem\n \t described in PR 20115:\n@@ -1784,32 +1821,12 @@ maybe_create_global_var (struct alias_info *ai)\n \t So, if we have some pure/const and some regular calls in the\n \t program we create .GLOBAL_VAR to avoid missing these\n \t relations.  */\n-      if (ai->num_calls_found * n_clobbered >= (size_t) GLOBAL_VAR_THRESHOLD\n-\t  || (n_clobbered == 0\n-\t      && ai->num_calls_found > 0\n-\t      && ai->num_pure_const_calls_found > 0\n-\t      && ai->num_calls_found > ai->num_pure_const_calls_found))\n+      if (bitmap_count_bits (gimple_call_clobbered_vars (cfun)) == 0\n+\t  && ai->num_calls_found > 0\n+\t  && ai->num_pure_const_calls_found > 0\n+\t  && ai->num_calls_found > ai->num_pure_const_calls_found)\n \tcreate_global_var ();\n     }\n-\n-  /* Mark all call-clobbered symbols for renaming.  Since the initial\n-     rewrite into SSA ignored all call sites, we may need to rename\n-     .GLOBAL_VAR and the call-clobbered variables.   */\n-  EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, i, bi)\n-    {\n-      tree var = referenced_var (i);\n-\n-      /* If the function has calls to clobbering functions and\n-\t .GLOBAL_VAR has been created, make it an alias for all\n-\t call-clobbered variables.  */\n-      if (gimple_global_var (cfun) && var != gimple_global_var (cfun))\n-\t{\n-\t  add_may_alias (var, gimple_global_var (cfun));\n-\t  gcc_assert (!get_subvars_for_var (var));\n-\t}\n-      \n-      mark_sym_for_renaming (var);\n-    }\n }\n \n \n@@ -1833,7 +1850,7 @@ may_alias_p (tree ptr, HOST_WIDE_INT mem_alias_set,\n   alias_stats.simple_queries++;\n \n   /* By convention, a variable cannot alias itself.  */\n-  mem = var_ann (ptr)->symbol_mem_tag;\n+  mem = symbol_mem_tag (ptr);\n   if (mem == var)\n     {\n       alias_stats.alias_noalias++;\n@@ -1882,15 +1899,14 @@ may_alias_p (tree ptr, HOST_WIDE_INT mem_alias_set,\n       return false;\n     }\n \n-  /* If var is a record or union type, ptr cannot point into var\n-     unless there is some operation explicit address operation in the\n-     program that can reference a field of the ptr's dereferenced\n-     type.  This also assumes that the types of both var and ptr are\n+  /* If VAR is a record or union type, PTR cannot point into VAR\n+     unless there is some explicit address operation in the\n+     program that can reference a field of the type pointed-to by PTR.\n+     This also assumes that the types of both VAR and PTR are\n      contained within the compilation unit, and that there is no fancy\n      addressing arithmetic associated with any of the types\n      involved.  */\n-\n-  if ((mem_alias_set != 0) && (var_alias_set != 0))\n+  if (mem_alias_set != 0 && var_alias_set != 0)\n     {\n       tree ptr_type = TREE_TYPE (ptr);\n       tree var_type = TREE_TYPE (var);\n@@ -1902,21 +1918,20 @@ may_alias_p (tree ptr, HOST_WIDE_INT mem_alias_set,\n \t{\n \t  int ptr_star_count = 0;\n \t  \n-\t  /* Ipa_type_escape_star_count_of_interesting_type is a little to\n-\t     restrictive for the pointer type, need to allow pointers to\n-\t     primitive types as long as those types cannot be pointers\n-\t     to everything.  */\n+\t  /* ipa_type_escape_star_count_of_interesting_type is a\n+\t     little too restrictive for the pointer type, need to\n+\t     allow pointers to primitive types as long as those types\n+\t     cannot be pointers to everything.  */\n \t  while (POINTER_TYPE_P (ptr_type))\n-\t    /* Strip the *'s off.  */ \n \t    {\n+\t      /* Strip the *s off.  */ \n \t      ptr_type = TREE_TYPE (ptr_type);\n \t      ptr_star_count++;\n \t    }\n \t  \n \t  /* There does not appear to be a better test to see if the \n \t     pointer type was one of the pointer to everything \n \t     types.  */\n-\t  \n \t  if (ptr_star_count > 0)\n \t    {\n \t      alias_stats.structnoaddress_queries++;\n@@ -1930,7 +1945,7 @@ may_alias_p (tree ptr, HOST_WIDE_INT mem_alias_set,\n \t    }\n \t  else if (ptr_star_count == 0)\n \t    {\n-\t      /* If ptr_type was not really a pointer to type, it cannot \n+\t      /* If PTR_TYPE was not really a pointer to type, it cannot \n \t\t alias.  */ \n \t      alias_stats.structnoaddress_queries++;\n \t      alias_stats.structnoaddress_resolved++;\n@@ -1945,15 +1960,15 @@ may_alias_p (tree ptr, HOST_WIDE_INT mem_alias_set,\n }\n \n \n-/* Add ALIAS to the set of variables that may alias VAR.  */\n+/* Add ALIAS to the set of variables that may alias VAR.  If\n+   ALREADY_ADDED is given, it is used to avoid adding the same alias\n+   more than once to VAR's alias set.  */\n \n static void\n-add_may_alias (tree var, tree alias)\n+add_may_alias (tree var, tree alias, struct pointer_set_t *already_added)\n {\n-  size_t i;\n   var_ann_t v_ann = get_var_ann (var);\n   var_ann_t a_ann = get_var_ann (alias);\n-  tree al;\n \n   /* Don't allow self-referential aliases.  */\n   gcc_assert (var != alias);\n@@ -1965,29 +1980,22 @@ add_may_alias (tree var, tree alias)\n   gcc_assert (may_be_aliased (alias));\n #endif\n \n+  /* VAR must be a symbol or a name tag.  */\n+  gcc_assert (TREE_CODE (var) == SYMBOL_MEMORY_TAG\n+              || TREE_CODE (var) == NAME_MEMORY_TAG);\n+\n   if (v_ann->may_aliases == NULL)\n     v_ann->may_aliases = VEC_alloc (tree, gc, 2);\n \n   /* Avoid adding duplicates.  */\n-  for (i = 0; VEC_iterate (tree, v_ann->may_aliases, i, al); i++)\n-    if (alias == al)\n-      return;\n+  if (already_added && pointer_set_insert (already_added, alias))\n+    return;\n \n   VEC_safe_push (tree, gc, v_ann->may_aliases, alias);\n   a_ann->is_aliased = 1;\n }\n \n \n-/* Replace alias I in the alias sets of VAR with NEW_ALIAS.  */\n-\n-static void\n-replace_may_alias (tree var, size_t i, tree new_alias)\n-{\n-  var_ann_t v_ann = var_ann (var);\n-  VEC_replace (tree, v_ann->may_aliases, i, new_alias);\n-}\n-\n-\n /* Mark pointer PTR as pointing to an arbitrary memory location.  */\n \n static void\n@@ -2092,18 +2100,13 @@ is_escape_site (tree stmt)\n /* Create a new memory tag of type TYPE.\n    Does NOT push it into the current binding.  */\n \n-static tree\n+tree\n create_tag_raw (enum tree_code code, tree type, const char *prefix)\n {\n   tree tmp_var;\n-  tree new_type;\n \n-  /* Make the type of the variable writable.  */\n-  new_type = build_type_variant (type, 0, 0);\n-  TYPE_ATTRIBUTES (new_type) = TYPE_ATTRIBUTES (type);\n+  tmp_var = build_decl (code, create_tmp_var_name (prefix), type);\n \n-  tmp_var = build_decl (code, create_tmp_var_name (prefix),\n-\t\t\ttype);\n   /* Make the variable writable.  */\n   TREE_READONLY (tmp_var) = 0;\n \n@@ -2123,7 +2126,6 @@ create_tag_raw (enum tree_code code, tree type, const char *prefix)\n static tree\n create_memory_tag (tree type, bool is_type_tag)\n {\n-  var_ann_t ann;\n   tree tag = create_tag_raw (is_type_tag ? SYMBOL_MEMORY_TAG : NAME_MEMORY_TAG,\n \t\t\t     type, (is_type_tag) ? \"SMT\" : \"NMT\");\n \n@@ -2134,8 +2136,7 @@ create_memory_tag (tree type, bool is_type_tag)\n   /* Memory tags are by definition addressable.  */\n   TREE_ADDRESSABLE (tag) = 1;\n \n-  ann = get_var_ann (tag);\n-  ann->symbol_mem_tag = NULL_TREE;\n+  set_symbol_mem_tag (tag, NULL_TREE);\n \n   /* Add the tag to the symbol table.  */\n   add_referenced_var (tag);\n@@ -2170,7 +2171,7 @@ get_nmt_for (tree ptr)\n    function populates the array AI->POINTERS.  */\n \n static tree\n-get_tmt_for (tree ptr, struct alias_info *ai)\n+get_smt_for (tree ptr, struct alias_info *ai)\n {\n   size_t i;\n   tree tag;\n@@ -2196,7 +2197,7 @@ get_tmt_for (tree ptr, struct alias_info *ai)\n   for (i = 0, tag = NULL_TREE; i < ai->num_pointers; i++)\n     {\n       struct alias_map_d *curr = ai->pointers[i];\n-      tree curr_tag = var_ann (curr->var)->symbol_mem_tag;\n+      tree curr_tag = symbol_mem_tag (curr->var);\n       if (tag_set == curr->set)\n \t{\n \t  tag = curr_tag;\n@@ -2213,10 +2214,9 @@ get_tmt_for (tree ptr, struct alias_info *ai)\n       /* If PTR did not have a symbol tag already, create a new SMT.*\n \t artificial variable representing the memory location\n \t pointed-to by PTR.  */\n-      if (var_ann (ptr)->symbol_mem_tag == NULL_TREE)\n+      tag = symbol_mem_tag (ptr);\n+      if (tag == NULL_TREE)\n \ttag = create_memory_tag (tag_type, true);\n-      else\n-\ttag = var_ann (ptr)->symbol_mem_tag;\n \n       /* Add PTR to the POINTERS array.  Note that we are not interested in\n \t PTR's alias set.  Instead, we cache the alias set for the memory that\n@@ -2316,11 +2316,8 @@ dump_alias_info (FILE *file)\n   fprintf (file, \"\\nDereferenced pointers\\n\\n\");\n \n   FOR_EACH_REFERENCED_VAR (var, rvi)\n-    {\n-      var_ann_t ann = var_ann (var);\n-      if (ann->symbol_mem_tag)\n-\tdump_variable (file, var);\n-    }\n+    if (symbol_mem_tag (var))\n+      dump_variable (file, var);\n \n   fprintf (file, \"\\nSymbol memory tags\\n\\n\");\n   \n@@ -2356,6 +2353,8 @@ dump_alias_info (FILE *file)\n \tdump_variable (file, var);\n     }\n \n+  dump_memory_partitions (file);\n+\n   fprintf (file, \"\\n\");\n }\n \n@@ -2421,16 +2420,8 @@ dump_points_to_info_for (FILE *file, tree ptr)\n \n       if (pi->pt_vars)\n \t{\n-\t  unsigned ix;\n-\t  bitmap_iterator bi;\n-\n-\t  fprintf (file, \", points-to vars: { \");\n-\t  EXECUTE_IF_SET_IN_BITMAP (pi->pt_vars, 0, ix, bi)\n-\t    {\n-\t      print_generic_expr (file, referenced_var (ix), dump_flags);\n-\t      fprintf (file, \" \");\n-\t    }\n-\t  fprintf (file, \"}\");\n+\t  fprintf (file, \", points-to vars: \");\n+\t  dump_decl_set (file, pi->pt_vars);\n \t}\n     }\n \n@@ -2544,6 +2535,7 @@ debug_may_aliases_for (tree var)\n   dump_may_aliases_for (stderr, var);\n }\n \n+\n /* Return true if VAR may be aliased.  */\n \n bool\n@@ -2555,26 +2547,26 @@ may_be_aliased (tree var)\n \n   /* Globally visible variables can have their addresses taken by other\n      translation units.  */\n-\n   if (MTAG_P (var)\n       && (MTAG_GLOBAL (var) || TREE_PUBLIC (var)))\n     return true;\n   else if (!MTAG_P (var)\n-      && (DECL_EXTERNAL (var) || TREE_PUBLIC (var)))\n+           && (DECL_EXTERNAL (var) || TREE_PUBLIC (var)))\n     return true;\n \n-  /* Automatic variables can't have their addresses escape any other way.\n-     This must be after the check for global variables, as extern declarations\n-     do not have TREE_STATIC set.  */\n+  /* Automatic variables can't have their addresses escape any other\n+     way.  This must be after the check for global variables, as\n+     extern declarations do not have TREE_STATIC set.  */\n   if (!TREE_STATIC (var))\n     return false;\n \n-  /* If we're in unit-at-a-time mode, then we must have seen all occurrences\n-     of address-of operators, and so we can trust TREE_ADDRESSABLE.  Otherwise\n-     we can only be sure the variable isn't addressable if it's local to the\n-     current function.  */\n+  /* If we're in unit-at-a-time mode, then we must have seen all\n+     occurrences of address-of operators, and so we can trust\n+     TREE_ADDRESSABLE.  Otherwise we can only be sure the variable\n+     isn't addressable if it's local to the current function.  */\n   if (flag_unit_at_a_time)\n     return false;\n+\n   if (decl_function_context (var) == current_function_decl)\n     return false;\n \n@@ -2583,6 +2575,7 @@ may_be_aliased (tree var)\n \n \n /* Given two symbols return TRUE if one is in the alias set of the other.  */\n+\n bool\n is_aliased_with (tree tag, tree sym)\n {\n@@ -2626,32 +2619,37 @@ is_aliased_with (tree tag, tree sym)\n static tree\n add_may_alias_for_new_tag (tree tag, tree var)\n {\n-  var_ann_t v_ann = var_ann (var);\n-  VEC(tree, gc) *aliases = v_ann->may_aliases;\n+  VEC(tree,gc) *aliases;\n+  struct pointer_set_t *already_added;\n+  unsigned i;\n+  tree al;\n+\n+  aliases = may_aliases (var);\n \n   /* Case 1: |aliases| == 1  */\n-  if ((aliases != NULL)\n-      && (VEC_length (tree, aliases) == 1))\n+  if (VEC_length (tree, aliases) == 1)\n     {\n       tree ali = VEC_index (tree, aliases, 0);\n-\n       if (TREE_CODE (ali) == SYMBOL_MEMORY_TAG)\n         return ali;\n     }\n \n+  already_added = pointer_set_create ();\n+  for (i = 0; VEC_iterate (tree, may_aliases (tag), i, al); i++)\n+    pointer_set_insert (already_added, al);\n+\n   /* Case 2: |aliases| == 0  */\n   if (aliases == NULL)\n-    add_may_alias (tag, var);\n+    add_may_alias (tag, var, already_added);\n   else\n     {\n       /* Case 3: |aliases| > 1  */\n-      unsigned i;\n-      tree al;\n-\n       for (i = 0; VEC_iterate (tree, aliases, i, al); i++)\n-        add_may_alias (tag, al);\n+        add_may_alias (tag, al, already_added);\n     }\n \n+  pointer_set_destroy (already_added);\n+\n   return tag;\n }\n \n@@ -2665,7 +2663,6 @@ add_may_alias_for_new_tag (tree tag, tree var)\n void\n new_type_alias (tree ptr, tree var, tree expr)\n {\n-  var_ann_t p_ann = var_ann (ptr);\n   tree tag_type = TREE_TYPE (TREE_TYPE (ptr));\n   tree tag;\n   subvar_t svars;\n@@ -2676,14 +2673,14 @@ new_type_alias (tree ptr, tree var, tree expr)\n   subvar_t sv;\n   unsigned int len;\n \n-  gcc_assert (p_ann->symbol_mem_tag == NULL_TREE);\n+  gcc_assert (symbol_mem_tag (ptr) == NULL_TREE);\n   gcc_assert (!MTAG_P (var));\n \n   ref = get_ref_base_and_extent (expr, &offset, &size, &maxsize);\n   gcc_assert (ref);\n \n   tag = create_memory_tag (tag_type, true);\n-  p_ann->symbol_mem_tag = tag;\n+  set_symbol_mem_tag (ptr, tag);\n \n   /* Add VAR to the may-alias set of PTR's new symbol tag.  If VAR has\n      subvars, add the subvars to the tag instead of the actual var.  */\n@@ -2739,15 +2736,15 @@ new_type_alias (tree ptr, tree var, tree expr)\n \t\t  /* Can happen only if 'Case 1' of add_may_alias_for_new_tag\n \t\t     took place.  Since more than one svar was found, we add \n \t\t     'ali' as one of the may_aliases of the new tag.  */ \n-\t\t  add_may_alias (tag, ali);\n+\t\t  add_may_alias (tag, ali, NULL);\n \t\t  ali = tag;\n \t\t}\n \t    }\n \t}\n       VEC_free (tree, heap, overlaps);\n     }\n \n-  p_ann->symbol_mem_tag = ali;\n+  set_symbol_mem_tag (ptr, ali);\n   TREE_READONLY (tag) = TREE_READONLY (var);\n   MTAG_GLOBAL (tag) = is_global_var (var);\n }\n@@ -2866,7 +2863,6 @@ static tree\n create_sft (tree var, tree field, unsigned HOST_WIDE_INT offset,\n \t    unsigned HOST_WIDE_INT size)\n {\n-  var_ann_t ann;\n   tree subvar = create_tag_raw (STRUCT_FIELD_TAG, field, \"SFT\");\n \n   /* We need to copy the various flags from VAR to SUBVAR, so that\n@@ -2879,8 +2875,7 @@ create_sft (tree var, tree field, unsigned HOST_WIDE_INT offset,\n   TREE_ADDRESSABLE (subvar) = TREE_ADDRESSABLE (var);\n \n   /* Add the new variable to REFERENCED_VARS.  */\n-  ann = get_var_ann (subvar);\n-  ann->symbol_mem_tag = NULL;  \t\n+  set_symbol_mem_tag (subvar, NULL);\n   add_referenced_var (subvar);\n   SFT_PARENT_VAR (subvar) = var;\n   SFT_OFFSET (subvar) = offset;"}, {"sha": "493bdecedcde6a00fbad1949ca945a693cb2683a", "filename": "gcc/tree-ssa-ccp.c", "status": "modified", "additions": 11, "deletions": 12, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-ccp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-ccp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ccp.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -132,13 +132,12 @@ Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n \n    We should be able to deduce that the predicate 'a.a != B' is always\n    false.  To achieve this, we associate constant values to the SSA\n-   names in the V_MAY_DEF and V_MUST_DEF operands for each store.\n-   Additionally, since we also glob partial loads/stores with the base\n-   symbol, we also keep track of the memory reference where the\n-   constant value was stored (in the MEM_REF field of PROP_VALUE_T).\n-   For instance,\n+   names in the VDEF operands for each store.  Additionally,\n+   since we also glob partial loads/stores with the base symbol, we\n+   also keep track of the memory reference where the constant value\n+   was stored (in the MEM_REF field of PROP_VALUE_T).  For instance,\n \n-        # a_5 = V_MAY_DEF <a_4>\n+        # a_5 = VDEF <a_4>\n         a.a = 2;\n \n         # VUSE <a_5>\n@@ -222,9 +221,9 @@ typedef enum\n /* Array of propagated constant values.  After propagation,\n    CONST_VAL[I].VALUE holds the constant value for SSA_NAME(I).  If\n    the constant is held in an SSA name representing a memory store\n-   (i.e., a V_MAY_DEF or V_MUST_DEF), CONST_VAL[I].MEM_REF will\n-   contain the actual memory reference used to store (i.e., the LHS of\n-   the assignment doing the store).  */\n+   (i.e., a VDEF), CONST_VAL[I].MEM_REF will contain the actual\n+   memory reference used to store (i.e., the LHS of the assignment\n+   doing the store).  */\n static prop_value_t *const_val;\n \n /* True if we are also propagating constants in stores and loads.  */\n@@ -1274,9 +1273,9 @@ visit_assignment (tree stmt, tree *output_p)\n     }\n   else if (do_store_ccp && stmt_makes_single_store (stmt))\n     {\n-      /* Otherwise, set the names in V_MAY_DEF/V_MUST_DEF operands\n-\t to the new constant value and mark the LHS as the memory\n-\t reference associated with VAL.  */\n+      /* Otherwise, set the names in VDEF operands to the new\n+\t constant value and mark the LHS as the memory reference\n+\t associated with VAL.  */\n       ssa_op_iter i;\n       tree vdef;\n       bool changed;"}, {"sha": "6bf530f6b50df832624b8cef7d973d342f1c55ac", "filename": "gcc/tree-ssa-coalesce.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-coalesce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-coalesce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-coalesce.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1073,8 +1073,7 @@ create_outofssa_var_map (coalesce_list_p cl, bitmap used_in_copy)\n \t    bitmap_set_bit (used_in_real_ops, DECL_UID (SSA_NAME_VAR (var)));\n \n \t  /* Validate that virtual ops don't get used in funny ways.  */\n-\t  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, \n-\t\t\t\t     SSA_OP_VIRTUAL_USES | SSA_OP_VMUSTDEF)\n+\t  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, SSA_OP_ALL_VIRTUALS)\n \t    {\n \t      bitmap_set_bit (used_in_virtual_ops, \n \t\t\t      DECL_UID (SSA_NAME_VAR (var)));"}, {"sha": "d08215ecb3324a7442447d83f4bb63d4a400a406", "filename": "gcc/tree-ssa-copy.c", "status": "modified", "additions": 35, "deletions": 5, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-copy.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-copy.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-copy.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -63,6 +63,24 @@ may_propagate_copy (tree dest, tree orig)\n   tree type_d = TREE_TYPE (dest);\n   tree type_o = TREE_TYPE (orig);\n \n+  /* For memory partitions, copies are OK as long as the memory symbol\n+     belongs to the partition.  */\n+  if (TREE_CODE (dest) == SSA_NAME\n+      && TREE_CODE (SSA_NAME_VAR (dest)) == MEMORY_PARTITION_TAG)\n+    return (TREE_CODE (orig) == SSA_NAME\n+            && !is_gimple_reg (orig)\n+\t    && (bitmap_bit_p (MPT_SYMBOLS (SSA_NAME_VAR (dest)),\n+\t                      DECL_UID (SSA_NAME_VAR (orig)))\n+\t        || SSA_NAME_VAR (dest) == SSA_NAME_VAR (orig)));\n+\n+  if (TREE_CODE (orig) == SSA_NAME\n+      && TREE_CODE (SSA_NAME_VAR (orig)) == MEMORY_PARTITION_TAG)\n+    return (TREE_CODE (dest) == SSA_NAME\n+            && !is_gimple_reg (dest)\n+\t    && (bitmap_bit_p (MPT_SYMBOLS (SSA_NAME_VAR (orig)),\n+\t                      DECL_UID (SSA_NAME_VAR (dest)))\n+\t        || SSA_NAME_VAR (dest) == SSA_NAME_VAR (orig)));\n+  \n   /* Do not copy between types for which we *do* need a conversion.  */\n   if (!tree_ssa_useless_type_conversion_1 (type_d, type_o))\n     return false;\n@@ -108,8 +126,8 @@ may_propagate_copy (tree dest, tree orig)\n       && POINTER_TYPE_P (type_d)\n       && POINTER_TYPE_P (type_o))\n     {\n-      tree mt_dest = var_ann (SSA_NAME_VAR (dest))->symbol_mem_tag;\n-      tree mt_orig = var_ann (SSA_NAME_VAR (orig))->symbol_mem_tag;\n+      tree mt_dest = symbol_mem_tag (SSA_NAME_VAR (dest));\n+      tree mt_orig = symbol_mem_tag (SSA_NAME_VAR (orig));\n       if (mt_dest && mt_orig && mt_dest != mt_orig)\n \treturn false;\n       else if (!lang_hooks.types_compatible_p (type_d, type_o))\n@@ -188,6 +206,18 @@ merge_alias_info (tree orig, tree new)\n   var_ann_t new_ann = var_ann (new_sym);\n   var_ann_t orig_ann = var_ann (orig_sym);\n \n+  /* No merging necessary when memory partitions are involved.  */\n+  if (factoring_name_p (new))\n+    {\n+      gcc_assert (!is_gimple_reg (orig_sym));\n+      return;\n+    }\n+  else if (factoring_name_p (orig))\n+    {\n+      gcc_assert (!is_gimple_reg (new_sym));\n+      return;\n+    }\n+\n   gcc_assert (POINTER_TYPE_P (TREE_TYPE (orig)));\n   gcc_assert (POINTER_TYPE_P (TREE_TYPE (new)));\n \n@@ -545,7 +575,7 @@ dump_copy_of (FILE *file, tree var)\n /* Evaluate the RHS of STMT.  If it produces a valid copy, set the LHS\n    value and store the LHS into *RESULT_P.  If STMT generates more\n    than one name (i.e., STMT is an aliased store), it is enough to\n-   store the first name in the V_MAY_DEF list into *RESULT_P.  After\n+   store the first name in the VDEF list into *RESULT_P.  After\n    all, the names generated will be VUSEd in the same statements.  */\n \n static enum ssa_prop_result\n@@ -582,8 +612,8 @@ copy_prop_visit_assignment (tree stmt, tree *result_p)\n     }\n   else if (stmt_makes_single_store (stmt))\n     {\n-      /* Otherwise, set the names in V_MAY_DEF/V_MUST_DEF operands\n-\t to be a copy of RHS.  */\n+      /* Otherwise, set the names in VDEF operands to be a copy\n+\t of RHS.  */\n       ssa_op_iter i;\n       tree vdef;\n       bool changed;"}, {"sha": "d8b32ef78b5cd9a12ac1d8fbd328b3f0029b85d3", "filename": "gcc/tree-ssa-dce.c", "status": "modified", "additions": 12, "deletions": 88, "changes": 100, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-dce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-dce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dce.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -222,11 +222,11 @@ mark_stmt_necessary (tree stmt, bool add_to_worklist)\n     VEC_safe_push (tree, heap, worklist, stmt);\n }\n \n-/* Mark the statement defining operand OP as necessary.  PHIONLY is true\n-   if we should only mark it necessary if it is a phi node.  */\n+\n+/* Mark the statement defining operand OP as necessary.  */\n \n static inline void\n-mark_operand_necessary (tree op, bool phionly)\n+mark_operand_necessary (tree op)\n {\n   tree stmt;\n   int ver;\n@@ -241,9 +241,7 @@ mark_operand_necessary (tree op, bool phionly)\n   stmt = SSA_NAME_DEF_STMT (op);\n   gcc_assert (stmt);\n \n-  if (NECESSARY (stmt)\n-      || IS_EMPTY_STMT (stmt)\n-      || (phionly && TREE_CODE (stmt) != PHI_NODE))\n+  if (NECESSARY (stmt) || IS_EMPTY_STMT (stmt))\n     return;\n \n   NECESSARY (stmt) = 1;\n@@ -489,7 +487,7 @@ propagate_necessity (struct edge_list *el)\n             {\n \t      tree arg = PHI_ARG_DEF (stmt, k);\n \t      if (TREE_CODE (arg) == SSA_NAME)\n-\t\tmark_operand_necessary (arg, false);\n+\t\tmark_operand_necessary (arg);\n \t    }\n \n \t  if (aggressive)\n@@ -509,87 +507,22 @@ propagate_necessity (struct edge_list *el)\n       else\n \t{\n \t  /* Propagate through the operands.  Examine all the USE, VUSE and\n-\t     V_MAY_DEF operands in this statement.  Mark all the statements \n-\t     which feed this statement's uses as necessary.  */\n-\t  ssa_op_iter iter;\n-\t  tree use;\n-\n-\t  /* The operands of V_MAY_DEF expressions are also needed as they\n+\t     VDEF operands in this statement.  Mark all the statements \n+\t     which feed this statement's uses as necessary.  The\n+\t     operands of VDEF expressions are also needed as they\n \t     represent potential definitions that may reach this\n-\t     statement (V_MAY_DEF operands allow us to follow def-def \n+\t     statement (VDEF operands allow us to follow def-def\n \t     links).  */\n+\t  ssa_op_iter iter;\n+\t  tree use;\n \n \t  FOR_EACH_SSA_TREE_OPERAND (use, stmt, iter, SSA_OP_ALL_USES)\n-\t    mark_operand_necessary (use, false);\n+\t    mark_operand_necessary (use);\n \t}\n     }\n }\n \n \n-/* Propagate necessity around virtual phi nodes used in kill operands.\n-   The reason this isn't done during propagate_necessity is because we don't\n-   want to keep phis around that are just there for must-defs, unless we\n-   absolutely have to.  After we've rewritten the reaching definitions to be\n-   correct in the previous part of the fixup routine, we can simply propagate\n-   around the information about which of these virtual phi nodes are really\n-   used, and set the NECESSARY flag accordingly.\n-   Note that we do the minimum here to ensure that we keep alive the phis that\n-   are actually used in the corrected SSA form.  In particular, some of these\n-   phis may now have all of the same operand, and will be deleted by some\n-   other pass.  */\n-\n-static void\n-mark_really_necessary_kill_operand_phis (void)\n-{\n-  basic_block bb;\n-  int i;\n-\n-  /* Seed the worklist with the new virtual phi arguments and virtual\n-     uses */\n-  FOR_EACH_BB (bb)\n-    {\n-      block_stmt_iterator bsi;\n-      tree phi;\n-      \n-      for (phi = phi_nodes (bb); phi; phi = PHI_CHAIN (phi))\n-\t{\n-\t  if (!is_gimple_reg (PHI_RESULT (phi)) && NECESSARY (phi))\n-\t    {\n-\t      for (i = 0; i < PHI_NUM_ARGS (phi); i++)\n-\t\tmark_operand_necessary (PHI_ARG_DEF (phi, i), true);\n-\t    }\n-\t}\n-      \n-      for (bsi = bsi_last (bb); !bsi_end_p (bsi); bsi_prev (&bsi))\n-\t{\n-\t  tree stmt = bsi_stmt (bsi);\n-\t\n-\t  if (NECESSARY (stmt))\n-\t    {\n-\t      use_operand_p use_p;\n-\t      ssa_op_iter iter;\n-\t      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter,\n-\t\t\t\t\tSSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS)\n-\t\t{\n-\t\t  tree use = USE_FROM_PTR (use_p);\n-\t\t  mark_operand_necessary (use, true);\n-\t\t}\n-\t    }\n-\t}\n-    }\n-  \n-  /* Mark all virtual phis still in use as necessary, and all of their\n-     arguments that are phis as necessary.  */\n-  while (VEC_length (tree, worklist) > 0)\n-    {\n-      tree use = VEC_pop (tree, worklist);\n-      \n-      for (i = 0; i < PHI_NUM_ARGS (use); i++)\n-\tmark_operand_necessary (PHI_ARG_DEF (use, i), true);\n-    }\n-}\n-\n-\n /* Remove dead PHI nodes from block BB.  */\n \n static void\n@@ -634,9 +567,6 @@ static void\n remove_dead_stmt (block_stmt_iterator *i, basic_block bb)\n {\n   tree t = bsi_stmt (*i);\n-  def_operand_p def_p;\n-\n-  ssa_op_iter iter;\n \n   if (dump_file && (dump_flags & TDF_DETAILS))\n     {\n@@ -711,11 +641,6 @@ remove_dead_stmt (block_stmt_iterator *i, basic_block bb)\n \t}\n     }\n   \n-  FOR_EACH_SSA_DEF_OPERAND (def_p, t, iter, SSA_OP_VIRTUAL_DEFS)\n-    {\n-      tree def = DEF_FROM_PTR (def_p);\n-      mark_sym_for_renaming (SSA_NAME_VAR (def));\n-    }\n   bsi_remove (i, true);  \n   release_defs (t); \n }\n@@ -875,7 +800,6 @@ perform_tree_ssa_dce (bool aggressive)\n \n   propagate_necessity (el);\n \n-  mark_really_necessary_kill_operand_phis ();\n   eliminate_unnecessary_stmts ();\n \n   if (aggressive)"}, {"sha": "7bae33ff43dee475ff8af9f790f807149ac4ad79", "filename": "gcc/tree-ssa-dom.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-dom.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-dom.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dom.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1486,7 +1486,7 @@ eliminate_redundant_computations (tree stmt)\n   if (! def\n       || TREE_CODE (def) != SSA_NAME\n       || SSA_NAME_OCCURS_IN_ABNORMAL_PHI (def)\n-      || !ZERO_SSA_OPERANDS (stmt, SSA_OP_VMAYDEF)\n+      || !ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF)\n       /* Do not record equivalences for increments of ivs.  This would create\n \t overlapping live ranges for a very questionable gain.  */\n       || simple_iv_increment_p (stmt))"}, {"sha": "ed1a5b2a38156af091b36d686e383557f7a28088", "filename": "gcc/tree-ssa-dse.c", "status": "modified", "additions": 417, "deletions": 84, "changes": 501, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-dse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-dse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dse.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -1,5 +1,5 @@\n /* Dead store elimination\n-   Copyright (C) 2004, 2005 Free Software Foundation, Inc.\n+   Copyright (C) 2004, 2005, 2006 Free Software Foundation, Inc.\n \n This file is part of GCC.\n \n@@ -34,6 +34,8 @@ Boston, MA 02110-1301, USA.  */\n #include \"tree-dump.h\"\n #include \"domwalk.h\"\n #include \"flags.h\"\n+#include \"hashtab.h\"\n+#include \"sbitmap.h\"\n \n /* This file implements dead store elimination.\n \n@@ -65,6 +67,26 @@ Boston, MA 02110-1301, USA.  */\n    the CFG.  */\n    \n \n+/* Given an aggregate, this records the parts of it which have been\n+   stored into.  */\n+struct aggregate_vardecl_d\n+{\n+  /* The aggregate.  */\n+  tree decl;\n+\n+  /* Some aggregates are too big for us to handle or never get stored\n+     to as a whole.  If this field is TRUE, we don't care about this\n+     aggregate.  */\n+  bool ignore;\n+\n+  /* Number of parts in the whole.  */\n+  unsigned nparts;\n+  \n+  /* A bitmap of parts of the aggregate that have been set.  If part N\n+     of an aggregate has been stored to, bit N should be on.  */\n+  sbitmap parts_set;\n+};\n+\n struct dse_global_data\n {\n   /* This is the global bitmap for store statements.\n@@ -73,6 +95,10 @@ struct dse_global_data\n      that we want to record, set the bit corresponding to the statement's\n      unique ID in this bitmap.  */\n   bitmap stores;\n+\n+  /* A hash table containing the parts of an aggregate which have been\n+     stored to.  */\n+  htab_t aggregate_vardecl;\n };\n \n /* We allocate a bitmap-per-block for stores which are encountered\n@@ -101,6 +127,7 @@ static void dse_optimize_stmt (struct dom_walk_data *,\n static void dse_record_phis (struct dom_walk_data *, basic_block);\n static void dse_finalize_block (struct dom_walk_data *, basic_block);\n static void record_voperand_set (bitmap, bitmap *, unsigned int);\n+static void dse_record_partial_aggregate_store (tree, struct dse_global_data *);\n \n static unsigned max_stmt_uid;\t/* Maximal uid of a statement.  Uids to phi\n \t\t\t\t   nodes are assigned using the versions of\n@@ -173,7 +200,7 @@ memory_ssa_name_same (tree *expr_p, int *walk_subtrees ATTRIBUTE_UNUSED,\n \n   /* If we've found a default definition, then there's no problem.  Both\n      stores will post-dominate it.  And def_bb will be NULL.  */\n-  if (expr == gimple_default_def (cfun, SSA_NAME_VAR (expr)))\n+  if (SSA_NAME_IS_DEFAULT_DEF (expr))\n     return NULL_TREE;\n \n   def_stmt = SSA_NAME_DEF_STMT (expr);\n@@ -210,6 +237,288 @@ memory_address_same (tree store1, tree store2)\n \t  == NULL);\n }\n \n+\n+/* A helper of dse_optimize_stmt.\n+   Given a GIMPLE_MODIFY_STMT in STMT, check that each VDEF has one\n+   use, and that one use is another VDEF clobbering the first one.\n+\n+   Return TRUE if the above conditions are met, otherwise FALSE.  */\n+\n+static bool\n+dse_possible_dead_store_p (tree stmt,\n+\t\t\t   use_operand_p *first_use_p,\n+\t\t\t   use_operand_p *use_p,\n+\t\t\t   tree *use_stmt,\n+\t\t\t   struct dse_global_data *dse_gd,\n+\t\t\t   struct dse_block_local_data *bd)\n+{\n+  ssa_op_iter op_iter;\n+  bool fail = false;\n+  def_operand_p var1;\n+  vuse_vec_p vv;\n+  tree defvar = NULL_TREE, temp;\n+  tree prev_defvar = NULL_TREE;\n+  stmt_ann_t ann = stmt_ann (stmt);\n+\n+  /* We want to verify that each virtual definition in STMT has\n+     precisely one use and that all the virtual definitions are\n+     used by the same single statement.  When complete, we\n+     want USE_STMT to refer to the one statement which uses\n+     all of the virtual definitions from STMT.  */\n+  *use_stmt = NULL;\n+  FOR_EACH_SSA_VDEF_OPERAND (var1, vv, stmt, op_iter)\n+    {\n+      defvar = DEF_FROM_PTR (var1);\n+\n+      /* If this virtual def does not have precisely one use, then\n+\t we will not be able to eliminate STMT.  */\n+      if (!has_single_use (defvar))\n+\t{\n+\t  fail = true;\n+\t  break;\n+\t}\n+\n+      /* Get the one and only immediate use of DEFVAR.  */\n+      single_imm_use (defvar, use_p, &temp);\n+      gcc_assert (*use_p != NULL_USE_OPERAND_P);\n+      *first_use_p = *use_p;\n+\n+      /* If the immediate use of DEF_VAR is not the same as the\n+\t previously find immediate uses, then we will not be able\n+\t to eliminate STMT.  */\n+      if (*use_stmt == NULL)\n+\t{\n+\t  *use_stmt = temp;\n+\t  prev_defvar = defvar;\n+\t}\n+      else if (temp != *use_stmt)\n+\t{\n+\t  /* The immediate use and the previously found immediate use\n+\t     must be the same, except... if they're uses of different\n+\t     parts of the whole.  */\n+\t  if (TREE_CODE (defvar) == SSA_NAME\n+\t      && TREE_CODE (SSA_NAME_VAR (defvar)) == STRUCT_FIELD_TAG\n+\t      && TREE_CODE (prev_defvar) == SSA_NAME\n+\t      && TREE_CODE (SSA_NAME_VAR (prev_defvar)) == STRUCT_FIELD_TAG\n+\t      && (SFT_PARENT_VAR (SSA_NAME_VAR (defvar))\n+\t\t  == SFT_PARENT_VAR (SSA_NAME_VAR (prev_defvar))))\n+\t    ;\n+\t  else\n+\t    {\n+\t      fail = true;\n+\t      break;\n+\t    }\n+\t}\n+    }\n+\n+  if (fail)\n+    {\n+      record_voperand_set (dse_gd->stores, &bd->stores, ann->uid);\n+      dse_record_partial_aggregate_store (stmt, dse_gd);\n+      return false;\n+    }\n+\n+  /* Skip through any PHI nodes we have already seen if the PHI\n+     represents the only use of this store.\n+\n+     Note this does not handle the case where the store has\n+     multiple VDEFs which all reach a set of PHI nodes in the same block.  */\n+  while (*use_p != NULL_USE_OPERAND_P\n+\t && TREE_CODE (*use_stmt) == PHI_NODE\n+\t && bitmap_bit_p (dse_gd->stores, get_stmt_uid (*use_stmt)))\n+    {\n+      /* A PHI node can both define and use the same SSA_NAME if\n+\t the PHI is at the top of a loop and the PHI_RESULT is\n+\t a loop invariant and copies have not been fully propagated.\n+\n+\t The safe thing to do is exit assuming no optimization is\n+\t possible.  */\n+      if (SSA_NAME_DEF_STMT (PHI_RESULT (*use_stmt)) == *use_stmt)\n+\treturn false;\n+\n+      /* Skip past this PHI and loop again in case we had a PHI\n+\t chain.  */\n+      single_imm_use (PHI_RESULT (*use_stmt), use_p, use_stmt);\n+    }\n+\n+  return true;\n+}\n+\n+\n+/* Given a DECL, return its AGGREGATE_VARDECL_D entry.  If no entry is\n+   found and INSERT is TRUE, add a new entry.  */\n+\n+static struct aggregate_vardecl_d *\n+get_aggregate_vardecl (tree decl, struct dse_global_data *dse_gd, bool insert)\n+{\n+  struct aggregate_vardecl_d av, *av_p;\n+  void **slot;\n+\n+  av.decl = decl;\n+  slot = htab_find_slot (dse_gd->aggregate_vardecl, &av, insert ? INSERT : NO_INSERT);\n+\n+\n+  /* Not found, and we don't want to insert.  */\n+  if (slot == NULL)\n+    return NULL;\n+\n+  /* Create new entry.  */\n+  if (*slot == NULL)\n+    {\n+      av_p = XNEW (struct aggregate_vardecl_d);\n+      av_p->decl = decl;\n+\n+      /* Record how many parts the whole has.  */\n+      if (TREE_CODE (TREE_TYPE (decl)) == COMPLEX_TYPE)\n+\tav_p->nparts = 2;\n+      else if (TREE_CODE (TREE_TYPE (decl)) == RECORD_TYPE)\n+\t{\n+\t  tree fields;\n+\n+\t  /* Count the number of fields.  */\n+\t  fields = TYPE_FIELDS (TREE_TYPE (decl));\n+\t  av_p->nparts = 0;\n+\t  while (fields)\n+\t    {\n+\t      av_p->nparts++;\n+\t      fields = TREE_CHAIN (fields);\n+\t    }\n+\t}\n+      else\n+\tabort ();\n+\n+      av_p->ignore = true;\n+      av_p->parts_set = sbitmap_alloc (HOST_BITS_PER_LONG);\n+      sbitmap_zero (av_p->parts_set);\n+      *slot = av_p;\n+    }\n+  else\n+    av_p = (struct aggregate_vardecl_d *) *slot;\n+\n+  return av_p;\n+}\n+\n+\n+/* If STMT is a partial store into an aggregate, record which part got set.  */\n+\n+static void\n+dse_record_partial_aggregate_store (tree stmt, struct dse_global_data *dse_gd)\n+{\n+  tree lhs, decl;\n+  enum tree_code code;\n+  struct aggregate_vardecl_d *av_p;\n+  int part;\n+\n+  gcc_assert (TREE_CODE (stmt) == GIMPLE_MODIFY_STMT);\n+\n+  lhs = GIMPLE_STMT_OPERAND (stmt, 0);\n+  code = TREE_CODE (lhs);\n+  if (code != IMAGPART_EXPR\n+      && code != REALPART_EXPR\n+      && code != COMPONENT_REF)\n+    return;\n+  decl = TREE_OPERAND (lhs, 0);\n+  /* Early bail on things like nested COMPONENT_REFs.  */\n+  if (TREE_CODE (decl) != VAR_DECL)\n+    return;\n+  /* Early bail on unions.  */\n+  if (code == COMPONENT_REF\n+      && TREE_CODE (TREE_TYPE (TREE_OPERAND (lhs, 0))) != RECORD_TYPE)\n+    return;\n+  \n+  av_p = get_aggregate_vardecl (decl, dse_gd, /*insert=*/false);\n+  /* Run away, this isn't an aggregate we care about.  */\n+  if (!av_p || av_p->ignore)\n+    return;\n+\n+  switch (code)\n+    {\n+    case IMAGPART_EXPR:\n+      part = 0;\n+      break;\n+    case REALPART_EXPR:\n+      part = 1;\n+      break;\n+    case COMPONENT_REF:\n+      {\n+\ttree orig_field, fields;\n+\ttree record_type = TREE_TYPE (TREE_OPERAND (lhs, 0));\n+\n+\t/* Get FIELD_DECL.  */\n+\torig_field = TREE_OPERAND (lhs, 1);\n+\n+\t/* FIXME: Eeech, do this more efficiently.  Perhaps\n+\t   calculate bit/byte offsets.  */\n+\tpart = -1;\n+\tfields = TYPE_FIELDS (record_type);\n+\twhile (fields)\n+\t  {\n+\t    ++part;\n+\t    if (fields == orig_field)\n+\t      break;\n+\t    fields = TREE_CHAIN (fields);\n+\t  }\n+\tgcc_assert (part >= 0);\n+      }\n+      break;\n+    default:\n+      return;\n+    }\n+\n+  /* Record which part was set.  */\n+  SET_BIT (av_p->parts_set, part);\n+}\n+\n+\n+/* Return TRUE if all parts in an AGGREGATE_VARDECL have been set.  */\n+\n+static inline bool\n+dse_whole_aggregate_clobbered_p (struct aggregate_vardecl_d *av_p)\n+{\n+  unsigned int i;\n+  sbitmap_iterator sbi;\n+  int nbits_set = 0;\n+\n+  /* Count the number of partial stores (bits set).  */\n+  EXECUTE_IF_SET_IN_SBITMAP (av_p->parts_set, 0, i, sbi)\n+    nbits_set++;\n+  return ((unsigned) nbits_set == av_p->nparts);\n+}\n+\n+\n+/* Return TRUE if STMT is a store into a whole aggregate whose parts we\n+   have already seen and recorded.  */\n+\n+static bool\n+dse_partial_kill_p (tree stmt, struct dse_global_data *dse_gd)\n+{\n+  tree decl;\n+  struct aggregate_vardecl_d *av_p;\n+\n+  /* Make sure this is a store into the whole.  */\n+  if (TREE_CODE (stmt) == GIMPLE_MODIFY_STMT)\n+    {\n+      enum tree_code code;\n+\n+      decl = GIMPLE_STMT_OPERAND (stmt, 0);\n+      code = TREE_CODE (TREE_TYPE (decl));\n+\n+      if (code != COMPLEX_TYPE && code != RECORD_TYPE)\n+\treturn false;\n+\n+      if (TREE_CODE (decl) != VAR_DECL)\n+\treturn false;\n+    }\n+  else\n+    return false;\n+\n+  av_p = get_aggregate_vardecl (decl, dse_gd, /*insert=*/false);\n+  gcc_assert (av_p != NULL);\n+\n+  return dse_whole_aggregate_clobbered_p (av_p);\n+}\n+\n+\n /* Attempt to eliminate dead stores in the statement referenced by BSI.\n \n    A dead store is a store into a memory location which will later be\n@@ -234,7 +543,7 @@ dse_optimize_stmt (struct dom_walk_data *walk_data,\n \n   /* If this statement has no virtual defs, then there is nothing\n      to do.  */\n-  if (ZERO_SSA_OPERANDS (stmt, (SSA_OP_VMAYDEF|SSA_OP_VMUSTDEF)))\n+  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF))\n     return;\n \n   /* We know we have virtual definitions.  If this is a GIMPLE_MODIFY_STMT\n@@ -249,105 +558,54 @@ dse_optimize_stmt (struct dom_walk_data *walk_data,\n     {\n       use_operand_p first_use_p = NULL_USE_OPERAND_P;\n       use_operand_p use_p = NULL;\n-      tree use_stmt, temp;\n-      tree defvar = NULL_TREE, usevar = NULL_TREE;\n-      bool fail = false;\n-      use_operand_p var2;\n-      def_operand_p var1;\n-      ssa_op_iter op_iter;\n-\n-      /* We want to verify that each virtual definition in STMT has\n-\t precisely one use and that all the virtual definitions are\n-\t used by the same single statement.  When complete, we\n-\t want USE_STMT to refer to the one statement which uses\n-\t all of the virtual definitions from STMT.  */\n-      use_stmt = NULL;\n-      FOR_EACH_SSA_MUST_AND_MAY_DEF_OPERAND (var1, var2, stmt, op_iter)\n-\t{\n-\t  defvar = DEF_FROM_PTR (var1);\n-\t  usevar = USE_FROM_PTR (var2);\n+      tree use_stmt;\n \n-\t  /* If this virtual def does not have precisely one use, then\n-\t     we will not be able to eliminate STMT.  */\n-\t  if (! has_single_use (defvar))\n-\t    {\n-\t      fail = true;\n-\t      break;\n-\t    }\n+      if (!dse_possible_dead_store_p (stmt, &first_use_p, &use_p, &use_stmt,\n+\t\t\t\t      dse_gd, bd))\n+\treturn;\n \n-\t  /* Get the one and only immediate use of DEFVAR.  */\n-\t  single_imm_use (defvar, &use_p, &temp);\n-\t  gcc_assert (use_p != NULL_USE_OPERAND_P);\n-\t  first_use_p = use_p;\n-\n-\t  /* If the immediate use of DEF_VAR is not the same as the\n-\t     previously find immediate uses, then we will not be able\n-\t     to eliminate STMT.  */\n-\t  if (use_stmt == NULL)\n-\t    use_stmt = temp;\n-\t  else if (temp != use_stmt)\n-\t    {\n-\t      fail = true;\n-\t      break;\n-\t    }\n-\t}\n-\n-      if (fail)\n-\t{\n-\t  record_voperand_set (dse_gd->stores, &bd->stores, ann->uid);\n-\t  return;\n-\t}\n-\n-      /* Skip through any PHI nodes we have already seen if the PHI\n-\t represents the only use of this store.\n-\n-\t Note this does not handle the case where the store has\n-\t multiple V_{MAY,MUST}_DEFs which all reach a set of PHI nodes in the\n-\t same block.  */\n-      while (use_p != NULL_USE_OPERAND_P\n-\t     && TREE_CODE (use_stmt) == PHI_NODE\n-\t     && bitmap_bit_p (dse_gd->stores, get_stmt_uid (use_stmt)))\n-\t{\n-\t  /* A PHI node can both define and use the same SSA_NAME if\n-\t     the PHI is at the top of a loop and the PHI_RESULT is\n-\t     a loop invariant and copies have not been fully propagated.\n-\n-\t     The safe thing to do is exit assuming no optimization is\n-\t     possible.  */\n-\t  if (SSA_NAME_DEF_STMT (PHI_RESULT (use_stmt)) == use_stmt)\n-\t    return;\n-\n-\t  /* Skip past this PHI and loop again in case we had a PHI\n-\t     chain.  */\n-\t  single_imm_use (PHI_RESULT (use_stmt), &use_p, &use_stmt);\n-\t}\n+      /* If this is a partial store into an aggregate, record it.  */\n+      dse_record_partial_aggregate_store (stmt, dse_gd);\n \n       /* If we have precisely one immediate use at this point, then we may\n \t have found redundant store.  Make sure that the stores are to\n \t the same memory location.  This includes checking that any\n \t SSA-form variables in the address will have the same values.  */\n       if (use_p != NULL_USE_OPERAND_P\n \t  && bitmap_bit_p (dse_gd->stores, get_stmt_uid (use_stmt))\n-\t  && operand_equal_p (GIMPLE_STMT_OPERAND (stmt, 0),\n-\t\t\t      GIMPLE_STMT_OPERAND (use_stmt, 0), 0)\n+\t  && (operand_equal_p (GIMPLE_STMT_OPERAND (stmt, 0),\n+\t\t\t       GIMPLE_STMT_OPERAND (use_stmt, 0), 0)\n+\t      || dse_partial_kill_p (stmt, dse_gd))\n \t  && memory_address_same (stmt, use_stmt))\n \t{\n-\t  /* Make sure we propagate the ABNORMAL bit setting.  */\n-\t  if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (USE_FROM_PTR (first_use_p)))\n-\t    SSA_NAME_OCCURS_IN_ABNORMAL_PHI (usevar) = 1;\n+\t  ssa_op_iter op_iter;\n+\t  def_operand_p var1;\n+\t  vuse_vec_p vv;\n+\t  tree stmt_lhs;\n \n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n             {\n               fprintf (dump_file, \"  Deleted dead store '\");\n               print_generic_expr (dump_file, bsi_stmt (bsi), dump_flags);\n               fprintf (dump_file, \"'\\n\");\n             }\n+\n \t  /* Then we need to fix the operand of the consuming stmt.  */\n-\t  FOR_EACH_SSA_MUST_AND_MAY_DEF_OPERAND (var1, var2, stmt, op_iter)\n+\t  stmt_lhs = USE_FROM_PTR (first_use_p);\n+\t  FOR_EACH_SSA_VDEF_OPERAND (var1, vv, stmt, op_iter)\n \t    {\n+\t      tree usevar, temp;\n+\n \t      single_imm_use (DEF_FROM_PTR (var1), &use_p, &temp);\n-\t      SET_USE (use_p, USE_FROM_PTR (var2));\n+\t      gcc_assert (VUSE_VECT_NUM_ELEM (*vv) == 1);\n+\t      usevar = VUSE_ELEMENT_VAR (*vv, 0);\n+\t      SET_USE (use_p, usevar);\n+\n+\t      /* Make sure we propagate the ABNORMAL bit setting.  */\n+\t      if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (stmt_lhs))\n+\t\tSSA_NAME_OCCURS_IN_ABNORMAL_PHI (usevar) = 1;\n \t    }\n+\n \t  /* Remove the dead store.  */\n \t  bsi_remove (&bsi, true);\n \n@@ -396,22 +654,95 @@ dse_finalize_block (struct dom_walk_data *walk_data,\n       }\n }\n \n+\n+/* Hashing and equality functions for AGGREGATE_VARDECL.  */\n+\n+static hashval_t\n+aggregate_vardecl_hash (const void *p)\n+{\n+  return htab_hash_pointer\n+    ((const void *)((const struct aggregate_vardecl_d *)p)->decl);\n+}\n+\n+static int\n+aggregate_vardecl_eq (const void *p1, const void *p2)\n+{\n+  return ((const struct aggregate_vardecl_d *)p1)->decl\n+    == ((const struct aggregate_vardecl_d *)p2)->decl;\n+}\n+\n+\n+/* Free memory allocated by one entry in AGGREGATE_VARDECL.  */\n+\n+static void\n+aggregate_vardecl_free (void *p)\n+{\n+  struct aggregate_vardecl_d *entry = (struct aggregate_vardecl_d *) p;\n+  sbitmap_free (entry->parts_set);\n+  free (entry);\n+}\n+\n+\n+/* Return true if STMT is a store into an entire aggregate.  */\n+\n+static bool\n+aggregate_whole_store_p (tree stmt)\n+{\n+  if (TREE_CODE (stmt) == GIMPLE_MODIFY_STMT)\n+    {\n+      tree lhs = GIMPLE_STMT_OPERAND (stmt, 0);\n+      enum tree_code code = TREE_CODE (TREE_TYPE (lhs));\n+\n+      if (code == COMPLEX_TYPE || code == RECORD_TYPE)\n+\treturn true;\n+    }\n+  return false;\n+}\n+\n+\n+/* Main entry point.  */\n+\n static unsigned int\n tree_ssa_dse (void)\n {\n   struct dom_walk_data walk_data;\n   struct dse_global_data dse_gd;\n   basic_block bb;\n \n-  /* Create a UID for each statement in the function.  Ordering of the\n-     UIDs is not important for this pass.  */\n+  dse_gd.aggregate_vardecl = \n+    htab_create (37, aggregate_vardecl_hash,\n+\t\t aggregate_vardecl_eq, aggregate_vardecl_free);\n+\n   max_stmt_uid = 0;\n   FOR_EACH_BB (bb)\n     {\n       block_stmt_iterator bsi;\n \n       for (bsi = bsi_start (bb); !bsi_end_p (bsi); bsi_next (&bsi))\n-\tstmt_ann (bsi_stmt (bsi))->uid = max_stmt_uid++;\n+\t{\n+\t  tree stmt = bsi_stmt (bsi);\n+\n+\t  /* Record aggregates which have been stored into as a whole.  */\n+\t  if (aggregate_whole_store_p (stmt))\n+\t    {\n+\t      tree lhs = GIMPLE_STMT_OPERAND (stmt, 0);\n+\t      if (TREE_CODE (lhs) == VAR_DECL)\n+\t\t{\n+\t\t  struct aggregate_vardecl_d *av_p;\n+\n+\t\t  av_p = get_aggregate_vardecl (lhs, &dse_gd, /*insert=*/true);\n+\t\t  av_p->ignore = false;\n+\n+\t\t  /* Ignore aggregates with too many parts.  */\n+\t\t  if (av_p->nparts > HOST_BITS_PER_LONG)\n+\t\t    av_p->ignore = true;\n+\t\t}\n+\t    }\n+\n+\t  /* Create a UID for each statement in the function.\n+\t     Ordering of the UIDs is not important for this pass.  */\n+\t  stmt_ann (stmt)->uid = max_stmt_uid++;\n+\t}\n     }\n \n   /* We might consider making this a property of each pass so that it\n@@ -437,6 +768,7 @@ tree_ssa_dse (void)\n \n   /* This is the main hash table for the dead store elimination pass.  */\n   dse_gd.stores = BITMAP_ALLOC (NULL);\n+\n   walk_data.global_data = &dse_gd;\n \n   /* Initialize the dominator walker.  */\n@@ -448,8 +780,9 @@ tree_ssa_dse (void)\n   /* Finalize the dominator walker.  */\n   fini_walk_dominator_tree (&walk_data);\n \n-  /* Release the main bitmap.  */\n+  /* Release unneeded data.  */\n   BITMAP_FREE (dse_gd.stores);\n+  htab_delete (dse_gd.aggregate_vardecl);\n \n   /* For now, just wipe the post-dominator information.  */\n   free_dominance_info (CDI_POST_DOMINATORS);"}, {"sha": "04cb28725dc1b38fdf74fbe91abb870edcdac174", "filename": "gcc/tree-ssa-loop-im.c", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-loop-im.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-loop-im.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-im.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -496,7 +496,7 @@ determine_max_movement (tree stmt, bool must_preserve_exec)\n     if (!add_dependency (val, lim_data, loop, true))\n       return false;\n \n-  FOR_EACH_SSA_TREE_OPERAND (val, stmt, iter, SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS)\n+  FOR_EACH_SSA_TREE_OPERAND (val, stmt, iter, SSA_OP_VIRTUAL_USES)\n     if (!add_dependency (val, lim_data, loop, false))\n       return false;\n \n@@ -1251,15 +1251,13 @@ gather_mem_refs_stmt (struct loop *loop, htab_t mem_refs,\n     }\n   ref->is_stored |= is_stored;\n \n-  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi,\n-\t\t\t     SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS)\n+  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi, SSA_OP_VIRTUAL_USES)\n     bitmap_set_bit (ref->vops, DECL_UID (SSA_NAME_VAR (vname)));\n   record_mem_ref_loc (&ref->locs, stmt, mem);\n   return;\n \n fail:\n-  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi,\n-\t\t\t     SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS)\n+  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi, SSA_OP_VIRTUAL_USES)\n     bitmap_set_bit (clobbered_vops, DECL_UID (SSA_NAME_VAR (vname)));\n }\n "}, {"sha": "22e5847b2f32abcf0780ad782dd98ac230510ee9", "filename": "gcc/tree-ssa-loop-manip.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-loop-manip.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-loop-manip.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-manip.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -262,7 +262,7 @@ find_uses_to_rename_stmt (tree stmt, bitmap *use_blocks, bitmap need_phis)\n   tree var;\n   basic_block bb = bb_for_stmt (stmt);\n \n-  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, SSA_OP_ALL_USES | SSA_OP_ALL_KILLS)\n+  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, SSA_OP_ALL_USES)\n     find_uses_to_rename_use (bb, var, use_blocks, need_phis);\n }\n \n@@ -406,7 +406,7 @@ check_loop_closed_ssa_stmt (basic_block bb, tree stmt)\n   ssa_op_iter iter;\n   tree var;\n \n-  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, SSA_OP_ALL_USES | SSA_OP_ALL_KILLS)\n+  FOR_EACH_SSA_TREE_OPERAND (var, stmt, iter, SSA_OP_ALL_USES)\n     check_loop_closed_ssa_use (bb, var);\n }\n \n@@ -454,13 +454,13 @@ split_loop_exit_edge (edge exit)\n \n       name = USE_FROM_PTR (op_p);\n \n-      /* If the argument of the phi node is a constant, we do not need\n+      /* If the argument of the PHI node is a constant, we do not need\n \t to keep it inside loop.  */\n       if (TREE_CODE (name) != SSA_NAME)\n \tcontinue;\n \n       /* Otherwise create an auxiliary phi node that will copy the value\n-\t of the ssa name out of the loop.  */\n+\t of the SSA name out of the loop.  */\n       new_name = duplicate_ssa_name (name, NULL);\n       new_phi = create_phi_node (new_name, bb);\n       SSA_NAME_DEF_STMT (new_name) = new_phi;"}, {"sha": "c11fe5b80f5495fbea7d0bc9cdd23bd9e15d307b", "filename": "gcc/tree-ssa-operands.c", "status": "modified", "additions": 816, "deletions": 608, "changes": 1424, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-operands.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-operands.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-operands.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -53,16 +53,15 @@ Boston, MA 02110-1301, USA.  */\n    The operand tree is the parsed by the various get_* routines which look \n    through the stmt tree for the occurrence of operands which may be of \n    interest, and calls are made to the append_* routines whenever one is \n-   found.  There are 5 of these routines, each representing one of the \n-   5 types of operands. Defs, Uses, Virtual Uses, Virtual May Defs, and \n-   Virtual Must Defs.\n+   found.  There are 4 of these routines, each representing one of the \n+   4 types of operands. Defs, Uses, Virtual Uses, and Virtual May Defs.\n \n    The append_* routines check for duplication, and simply keep a list of \n    unique objects for each operand type in the build_* extendable vectors.\n \n    Once the stmt tree is completely parsed, the finalize_ssa_operands() \n    routine is called, which proceeds to perform the finalization routine \n-   on each of the 5 operand vectors which have been built up.\n+   on each of the 4 operand vectors which have been built up.\n \n    If the stmt had a previous operand cache, the finalization routines \n    attempt to match up the new operands with the old ones.  If it's a perfect \n@@ -76,45 +75,75 @@ Boston, MA 02110-1301, USA.  */\n   vector for VUSE, then the new vector will also be modified such that \n   it contains 'a_5' rather than 'a'.  */\n \n+\n+/* Structure storing statistics on how many call clobbers we have, and\n+   how many where avoided.  */\n+\n+static struct \n+{\n+  /* Number of call-clobbered ops we attempt to add to calls in\n+     add_call_clobbered_mem_symbols.  */\n+  unsigned int clobbered_vars;\n+\n+  /* Number of write-clobbers (VDEFs) avoided by using\n+     not_written information.  */\n+  unsigned int static_write_clobbers_avoided;\n+\n+  /* Number of reads (VUSEs) avoided by using not_read information.  */\n+  unsigned int static_read_clobbers_avoided;\n+  \n+  /* Number of write-clobbers avoided because the variable can't escape to\n+     this call.  */\n+  unsigned int unescapable_clobbers_avoided;\n+\n+  /* Number of read-only uses we attempt to add to calls in\n+     add_call_read_mem_symbols.  */\n+  unsigned int readonly_clobbers;\n+\n+  /* Number of read-only uses we avoid using not_read information.  */\n+  unsigned int static_readonly_clobbers_avoided;\n+} clobber_stats;\n+\n+\n /* Flags to describe operand properties in helpers.  */\n \n /* By default, operands are loaded.  */\n-#define opf_none\t0\n+#define opf_use\t\t0\n \n /* Operand is the target of an assignment expression or a \n    call-clobbered variable.  */\n-#define opf_is_def \t(1 << 0)\n-\n-/* Operand is the target of an assignment expression.  */\n-#define opf_kill_def \t(1 << 1)\n+#define opf_def \t(1 << 0)\n \n /* No virtual operands should be created in the expression.  This is used\n    when traversing ADDR_EXPR nodes which have different semantics than\n    other expressions.  Inside an ADDR_EXPR node, the only operands that we\n    need to consider are indices into arrays.  For instance, &a.b[i] should\n    generate a USE of 'i' but it should not generate a VUSE for 'a' nor a\n    VUSE for 'b'.  */\n-#define opf_no_vops \t(1 << 2)\n+#define opf_no_vops \t(1 << 1)\n \n-/* Operand is a \"non-specific\" kill for call-clobbers and such.  This\n-   is used to distinguish \"reset the world\" events from explicit\n-   GIMPLE_MODIFY_STMTs.  */\n-#define opf_non_specific  (1 << 3)\n+/* Operand is an implicit reference.  This is used to distinguish\n+   explicit assignments in the form of GIMPLE_MODIFY_STMT from\n+   clobbering sites like function calls or ASM_EXPRs.  */\n+#define opf_implicit\t(1 << 2)\n \n /* Array for building all the def operands.  */\n static VEC(tree,heap) *build_defs;\n \n /* Array for building all the use operands.  */\n static VEC(tree,heap) *build_uses;\n \n-/* Array for building all the V_MAY_DEF operands.  */\n-static VEC(tree,heap) *build_v_may_defs;\n+/* Set for building all the VDEF operands.  */\n+static VEC(tree,heap) *build_vdefs;\n \n-/* Array for building all the VUSE operands.  */\n+/* Set for building all the VUSE operands.  */\n static VEC(tree,heap) *build_vuses;\n \n-/* Array for building all the V_MUST_DEF operands.  */\n-static VEC(tree,heap) *build_v_must_defs;\n+/* Set for building all the loaded symbols.  */\n+static bitmap build_loads;\n+\n+/* Set for building all the stored symbols.  */\n+static bitmap build_stores;\n \n static void get_expr_operands (tree, tree *, int);\n \n@@ -164,22 +193,6 @@ DEF_VEC_ALLOC_P(scb_t,heap);\n    of changes for the popped statement.  */\n static VEC(scb_t,heap) *scb_stack;\n \n-/* Allocates operand OP of given TYPE from the appropriate free list,\n-   or of the new value if the list is empty.  */\n-\n-#define ALLOC_OPTYPE(OP, TYPE)\t\t\t\t\\\n-  do\t\t\t\t\t\t\t\\\n-    {\t\t\t\t\t\t\t\\\n-      TYPE##_optype_p ret\t\t\t\t\\\n-\t = gimple_ssa_operands (cfun)->free_##TYPE##s;\t\\\n-      if (ret)\t\t\t\t\t\t\\\n-\tgimple_ssa_operands (cfun)->free_##TYPE##s \t\\\n-\t = ret->next;\t\t\t\t\t\\\n-      else\t\t\t\t\t\t\\\n-\tret = ssa_operand_alloc (sizeof (*ret));\t\\\n-      (OP) = ret;\t\t\t\t\t\\\n-    } while (0) \n-\n /* Return the DECL_UID of the base variable of T.  */\n \n static inline unsigned\n@@ -252,35 +265,6 @@ ssa_operands_active (void)\n }\n \n \n-/* Structure storing statistics on how many call clobbers we have, and\n-   how many where avoided.  */\n-\n-static struct \n-{\n-  /* Number of call-clobbered ops we attempt to add to calls in\n-     add_call_clobber_ops.  */\n-  unsigned int clobbered_vars;\n-\n-  /* Number of write-clobbers (V_MAY_DEFs) avoided by using\n-     not_written information.  */\n-  unsigned int static_write_clobbers_avoided;\n-\n-  /* Number of reads (VUSEs) avoided by using not_read information.  */\n-  unsigned int static_read_clobbers_avoided;\n-  \n-  /* Number of write-clobbers avoided because the variable can't escape to\n-     this call.  */\n-  unsigned int unescapable_clobbers_avoided;\n-\n-  /* Number of read-only uses we attempt to add to calls in\n-     add_call_read_ops.  */\n-  unsigned int readonly_clobbers;\n-\n-  /* Number of read-only uses we avoid using not_read information.  */\n-  unsigned int static_readonly_clobbers_avoided;\n-} clobber_stats;\n-  \n-\n /* Initialize the operand cache routines.  */\n \n void\n@@ -291,11 +275,14 @@ init_ssa_operands (void)\n       build_defs = VEC_alloc (tree, heap, 5);\n       build_uses = VEC_alloc (tree, heap, 10);\n       build_vuses = VEC_alloc (tree, heap, 25);\n-      build_v_may_defs = VEC_alloc (tree, heap, 25);\n-      build_v_must_defs = VEC_alloc (tree, heap, 25);\n+      build_vdefs = VEC_alloc (tree, heap, 25);\n+      build_loads = BITMAP_ALLOC (NULL);\n+      build_stores = BITMAP_ALLOC (NULL);\n+      scb_stack = VEC_alloc (scb_t, heap, 20);\n     }\n \n   gcc_assert (gimple_ssa_operands (cfun)->operand_memory == NULL);\n+  gcc_assert (gimple_ssa_operands (cfun)->mpt_table == NULL);\n   gimple_ssa_operands (cfun)->operand_memory_index = SSA_OPERAND_MEMORY_SIZE;\n   gimple_ssa_operands (cfun)->ops_active = true;\n   memset (&clobber_stats, 0, sizeof (clobber_stats));\n@@ -308,41 +295,61 @@ void\n fini_ssa_operands (void)\n {\n   struct ssa_operand_memory_d *ptr;\n+  unsigned ix;\n+  tree mpt;\n+\n   if (!--n_initialized)\n     {\n       VEC_free (tree, heap, build_defs);\n       VEC_free (tree, heap, build_uses);\n-      VEC_free (tree, heap, build_v_must_defs);\n-      VEC_free (tree, heap, build_v_may_defs);\n+      VEC_free (tree, heap, build_vdefs);\n       VEC_free (tree, heap, build_vuses);\n+      BITMAP_FREE (build_loads);\n+      BITMAP_FREE (build_stores);\n+\n+      /* The change buffer stack had better be empty.  */\n+      gcc_assert (VEC_length (scb_t, scb_stack) == 0);\n+      VEC_free (scb_t, heap, scb_stack);\n+      scb_stack = NULL;\n     }\n+\n   gimple_ssa_operands (cfun)->free_defs = NULL;\n   gimple_ssa_operands (cfun)->free_uses = NULL;\n   gimple_ssa_operands (cfun)->free_vuses = NULL;\n-  gimple_ssa_operands (cfun)->free_maydefs = NULL;\n-  gimple_ssa_operands (cfun)->free_mustdefs = NULL;\n+  gimple_ssa_operands (cfun)->free_vdefs = NULL;\n+\n   while ((ptr = gimple_ssa_operands (cfun)->operand_memory) != NULL)\n     {\n       gimple_ssa_operands (cfun)->operand_memory\n \t= gimple_ssa_operands (cfun)->operand_memory->next;\n       ggc_free (ptr);\n     }\n \n+  for (ix = 0;\n+       VEC_iterate (tree, gimple_ssa_operands (cfun)->mpt_table, ix, mpt);\n+       ix++)\n+    {\n+      if (mpt)\n+\tBITMAP_FREE (MPT_SYMBOLS (mpt));\n+    }\n+\n+  VEC_free (tree, heap, gimple_ssa_operands (cfun)->mpt_table);\n+\n   gimple_ssa_operands (cfun)->ops_active = false;\n-  \n+\n   if (dump_file && (dump_flags & TDF_STATS))\n     {\n-      fprintf (dump_file, \"Original clobbered vars:%d\\n\",\n+      fprintf (dump_file, \"Original clobbered vars:           %d\\n\",\n \t       clobber_stats.clobbered_vars);\n-      fprintf (dump_file, \"Static write clobbers avoided:%d\\n\",\n+      fprintf (dump_file, \"Static write clobbers avoided:     %d\\n\",\n \t       clobber_stats.static_write_clobbers_avoided);\n-      fprintf (dump_file, \"Static read clobbers avoided:%d\\n\",\n+      fprintf (dump_file, \"Static read clobbers avoided:      %d\\n\",\n \t       clobber_stats.static_read_clobbers_avoided);\n-      fprintf (dump_file, \"Unescapable clobbers avoided:%d\\n\",\n+      fprintf (dump_file, \"Unescapable clobbers avoided:      %d\\n\",\n \t       clobber_stats.unescapable_clobbers_avoided);\n-      fprintf (dump_file, \"Original read-only clobbers:%d\\n\",\n+      fprintf (dump_file, \"Original read-only clobbers:       %d\\n\",\n \t       clobber_stats.readonly_clobbers);\n-      fprintf (dump_file, \"Static read-only clobbers avoided:%d\\n\",\n+      fprintf (dump_file, \"Static read-only clobbers avoided: %d\\n\",\n \t       clobber_stats.static_readonly_clobbers_avoided);\n     }\n }\n@@ -354,8 +361,11 @@ static inline void *\n ssa_operand_alloc (unsigned size)\n {\n   char *ptr;\n+\n+  gcc_assert (size <= SSA_OPERAND_MEMORY_SIZE);\n+\n   if (gimple_ssa_operands (cfun)->operand_memory_index + size\n-        >= SSA_OPERAND_MEMORY_SIZE)\n+      >= SSA_OPERAND_MEMORY_SIZE)\n     {\n       struct ssa_operand_memory_d *ptr;\n       ptr = GGC_NEW (struct ssa_operand_memory_d);\n@@ -370,6 +380,82 @@ ssa_operand_alloc (unsigned size)\n }\n \n \n+static inline struct def_optype_d *\n+alloc_def (void)\n+{\n+  struct def_optype_d *ret;\n+  if (gimple_ssa_operands (cfun)->free_defs)\n+    {\n+      ret = gimple_ssa_operands (cfun)->free_defs;\n+      gimple_ssa_operands (cfun)->free_defs\n+\t= gimple_ssa_operands (cfun)->free_defs->next;\n+    }\n+  else\n+    ret = (struct def_optype_d *)\n+\t\t      ssa_operand_alloc (sizeof (struct def_optype_d));\n+  return ret;\n+}\n+\n+\n+static inline struct use_optype_d *\n+alloc_use (void)\n+{\n+  struct use_optype_d *ret;\n+  if (gimple_ssa_operands (cfun)->free_uses)\n+    {\n+      ret = gimple_ssa_operands (cfun)->free_uses;\n+      gimple_ssa_operands (cfun)->free_uses\n+\t= gimple_ssa_operands (cfun)->free_uses->next;\n+    }\n+  else\n+    ret = (struct use_optype_d *)ssa_operand_alloc (sizeof (struct use_optype_d));\n+  return ret;\n+}\n+\n+\n+\n+\n+static inline struct vdef_optype_d *\n+alloc_vdef (int num)\n+{\n+  struct vdef_optype_d *ret;\n+  /* Eliminate free list for the moment.  */\n+#if 0\n+  if (free_vdefs)\n+    {\n+      ret = free_vdefs;\n+      free_vdefs = free_vdefs->next;\n+    }\n+  else\n+#endif\n+    ret = (struct vdef_optype_d *)ssa_operand_alloc (\n+\tsizeof (struct vdef_optype_d) + (num - 1) * sizeof (vuse_element_t));\n+  VUSE_VECT_NUM_ELEM (ret->usev) = num;\n+  return ret;\n+}\n+\n+\n+\n+\n+static inline struct vuse_optype_d *\n+alloc_vuse (int num)\n+{\n+  struct vuse_optype_d *ret;\n+/* No free list for the moment.  */\n+#if 0    \n+  if (free_vuses)\n+    {\n+      ret = free_vuses;\n+      free_vuses = free_vuses->next;\n+    }\n+  else\n+#endif\n+    ret = (struct vuse_optype_d *)ssa_operand_alloc (\n+\tsizeof (struct vuse_optype_d) + (num - 1) * sizeof (vuse_element_t));\n+  VUSE_VECT_NUM_ELEM (ret->usev) = num;\n+  return ret;\n+}\n+\n \n /* This routine makes sure that PTR is in an immediate use list, and makes\n    sure the stmt pointer is set to the current stmt.  */\n@@ -430,71 +516,191 @@ set_virtual_use_link (use_operand_p ptr, tree stmt)\n /* Adds OP to the list of defs after LAST, and moves\n    LAST to the new element.  */\n \n-static inline void\n+static inline def_optype_p \n add_def_op (tree *op, def_optype_p *last)\n {\n   def_optype_p new;\n \n-  ALLOC_OPTYPE (new, def);\n+  new = alloc_def ();\n   DEF_OP_PTR (new) = op;\n   APPEND_OP_AFTER (new, *last);  \n+  return new;\n }\n \n /* Adds OP to the list of uses of statement STMT after LAST, and moves\n    LAST to the new element.  */\n \n-static inline void\n+static inline use_optype_p\n add_use_op (tree stmt, tree *op, use_optype_p *last)\n {\n   use_optype_p new;\n \n-  ALLOC_OPTYPE (new, use);\n+  new = alloc_use ();\n   INITIALIZE_USE (USE_OP_PTR (new), op, stmt);\n   APPEND_OP_AFTER (new, *last);  \n+  return new;\n }\n \n /* Adds OP to the list of vuses of statement STMT after LAST, and moves\n    LAST to the new element.  */\n \n-static inline void\n-add_vuse_op (tree stmt, tree op, vuse_optype_p *last)\n+static inline vuse_optype_p\n+add_vuse_op (tree stmt, tree op, int num, vuse_optype_p *last)\n {\n   vuse_optype_p new;\n+  int x;\n+\n+  new = alloc_vuse (num);\n+  for (x = 0; x < num; x++)\n+    {\n+      SET_VUSE_OP (new, x, op);\n+      INITIALIZE_USE (VUSE_OP_PTR (new, x), &new->usev.uses[x].use_var, stmt);\n+    }\n \n-  ALLOC_OPTYPE (new, vuse);\n-  VUSE_OP (new) = op;\n-  INITIALIZE_USE (VUSE_OP_PTR (new), &VUSE_OP (new), stmt);\n   APPEND_OP_AFTER (new, *last);  \n+  return new;\n }\n \n-/* Adds OP to the list of maydefs of statement STMT after LAST, and moves\n+\n+/* Adds OP to the list of vdefs of statement STMT after LAST, and moves\n    LAST to the new element.  */\n \n-static inline void\n-add_maydef_op (tree stmt, tree op, maydef_optype_p *last)\n+static inline vdef_optype_p\n+add_vdef_op (tree stmt, tree op, int num, vdef_optype_p *last)\n {\n-  maydef_optype_p new;\n+  int x;\n+  vdef_optype_p new;\n+\n+  new = alloc_vdef (num);\n+  VDEF_RESULT (new) = op;\n+  for (x = 0; x < num; x++)\n+    {\n+      SET_VDEF_OP (new, x, op);\n+      INITIALIZE_USE (VDEF_OP_PTR (new, x), &new->usev.uses[x].use_var, stmt);\n+    }\n \n-  ALLOC_OPTYPE (new, maydef);\n-  MAYDEF_RESULT (new) = op;\n-  MAYDEF_OP (new) = op;\n-  INITIALIZE_USE (MAYDEF_OP_PTR (new), &MAYDEF_OP (new), stmt);\n   APPEND_OP_AFTER (new, *last);  \n+  return new;\n }\n \n-/* Adds OP to the list of mustdefs of statement STMT after LAST, and moves\n-   LAST to the new element.  */\n \n-static inline void\n-add_mustdef_op (tree stmt, tree op, mustdef_optype_p *last)\n+struct vdef_optype_d *\n+realloc_vdef (struct vdef_optype_d *ptr, int num_elem)\n {\n-  mustdef_optype_p new;\n+  int x, lim;\n+  tree val, stmt;\n+  struct vdef_optype_d *ret, *tmp;\n+\n+  if (VUSE_VECT_NUM_ELEM (ptr->usev) == num_elem)\n+    return ptr; \n+  \n+  val = VDEF_RESULT (ptr);\n+  if (TREE_CODE (val) == SSA_NAME)\n+    val = SSA_NAME_VAR (val);\n+\n+  stmt = USE_STMT (VDEF_OP_PTR (ptr, 0));\n+\n+  /* Delink all the existing uses.  */\n+  for (x = 0; x < VUSE_VECT_NUM_ELEM (ptr->usev); x++)\n+    {\n+      use_operand_p use_p = VDEF_OP_PTR (ptr, x);\n+      delink_imm_use (use_p);\n+    }\n+\n+  /* If we want less space, simply use this one, and shrink the size.  */\n+  if (VUSE_VECT_NUM_ELEM (ptr->usev) > num_elem)\n+    {\n+      VUSE_VECT_NUM_ELEM (ptr->usev) = num_elem;\n+      return ptr;\n+    }\n+\n+  /* It is growing.  Allocate a new one and replace the old one.  */\n+  tmp = ptr;\n+  ret = add_vdef_op (stmt, val, num_elem, &ptr);\n+  ret->next = NULL;\n+  ptr = tmp;\n+\n+  lim = VUSE_VECT_NUM_ELEM (ptr->usev);\n+  memset (ptr, 0,\n+          sizeof (struct vdef_optype_d) + sizeof (vuse_element_t) * (lim- 1));\n+\n+  /* Now simply remove the old one.  */\n+  if (VDEF_OPS (stmt) == ptr)\n+    {\n+      VDEF_OPS (stmt) = ret;\n+      return ret;\n+    }\n+  else\n+    for (tmp = VDEF_OPS (stmt); \n+\t tmp != NULL && tmp->next != ptr; \n+\t tmp = tmp->next)\n+      {\n+\ttmp->next = ret;\n+\treturn ret;\n+      }\n+\n+  /* The pointer passed in isn't in STMT's VDEF lists.  */\n+  gcc_unreachable ();\n+}\n+\n+\n+struct vuse_optype_d *\n+realloc_vuse (struct vuse_optype_d *ptr, int num_elem)\n+{\n+  int x, lim;\n+  tree val, stmt;\n+  struct vuse_optype_d *ret, *tmp;\n+\n+  if (VUSE_VECT_NUM_ELEM (ptr->usev) == num_elem)\n+    return ptr; \n+  \n+  val = VUSE_OP (ptr, 0);\n+  if (TREE_CODE (val) == SSA_NAME)\n+    val = SSA_NAME_VAR (val);\n+\n+  stmt = USE_STMT (VUSE_OP_PTR (ptr, 0));\n+\n+  /* Delink all the existing uses.  */\n+  for (x = 0; x < VUSE_VECT_NUM_ELEM (ptr->usev); x++)\n+    {\n+      use_operand_p use_p = VUSE_OP_PTR (ptr, x);\n+      delink_imm_use (use_p);\n+    }\n+\n+  /* If we want less space, simply use this one, and shrink the size.  */\n+  if (VUSE_VECT_NUM_ELEM (ptr->usev) > num_elem)\n+    {\n+      VUSE_VECT_NUM_ELEM (ptr->usev) = num_elem;\n+      return ptr;\n+    }\n+\n+  /* It is growing.  Allocate a new one and replace the old one.  */\n+  tmp = ptr;\n+  ret = add_vuse_op (stmt, val, num_elem, &ptr);\n+  ret->next = NULL;\n+  ptr = tmp;\n+\n+  lim = VUSE_VECT_NUM_ELEM (ptr->usev);\n+  memset (ptr, 0, \n+\t  sizeof (struct vuse_optype_d) + sizeof (vuse_element_t) * (lim - 1));\n+\n+  /* Now simply link it in, find the node which points to this one.  */\n+  if (VUSE_OPS (stmt) == ptr)\n+    {\n+      VUSE_OPS (stmt) = ret;\n+      return ret;\n+    }\n+  else\n+    for (tmp = VUSE_OPS (stmt); \n+\t tmp != NULL && tmp->next != ptr; \n+\t tmp = tmp->next)\n+      {\n+\ttmp->next = ret;\n+\treturn ret;\n+      }\n \n-  ALLOC_OPTYPE (new, mustdef);\n-  MUSTDEF_RESULT (new) = op;\n-  MUSTDEF_KILL (new) = op;\n-  INITIALIZE_USE (MUSTDEF_KILL_PTR (new), &MUSTDEF_KILL (new), stmt);\n-  APPEND_OP_AFTER (new, *last);\n+  /* The pointer passed in isn't in STMT's VUSE lists.  */\n+  gcc_unreachable ();\n }\n \n /* Takes elements from build_defs and turns them into def operands of STMT.\n@@ -581,7 +787,6 @@ finalize_ssa_defs (tree stmt)\n   /* If there is an old list, often the new list is identical, or close, so\n      find the elements at the beginning that are the same as the vector.  */\n   finalize_ssa_def_ops (stmt);\n-  VEC_truncate (tree, build_defs, 0);\n }\n \n /* Takes elements from build_uses and turns them into use operands of STMT.\n@@ -647,338 +852,303 @@ finalize_ssa_uses (tree stmt)\n   }\n #endif\n   finalize_ssa_use_ops (stmt);\n-  VEC_truncate (tree, build_uses, 0);\n }\n \n \n-/* Takes elements from build_v_may_defs and turns them into maydef operands of\n-   STMT.  */\n+/* Takes elements from BUILD_VDEFS and turns them into vdef operands of\n+   STMT.  FIXME, for now VDEF operators should have a single operand\n+   in their RHS.  */\n \n static inline void\n-finalize_ssa_v_may_def_ops (tree stmt)\n+finalize_ssa_vdef_ops (tree stmt)\n {\n   unsigned new_i;\n-  struct maydef_optype_d new_list;\n-  maydef_optype_p old_ops, ptr, last;\n-  tree act;\n-  unsigned old_base, new_base;\n+  struct vdef_optype_d new_list;\n+  vdef_optype_p old_ops, ptr, last;\n+  stmt_ann_t ann = stmt_ann (stmt);\n+\n+  /* Set the symbols referenced by STMT.  */\n+  if (!bitmap_empty_p (build_stores))\n+    {\n+      if (ann->operands.stores == NULL)\n+\tann->operands.stores = BITMAP_ALLOC (NULL);\n+\n+      bitmap_copy (ann->operands.stores, build_stores);\n+    }\n+  else\n+    BITMAP_FREE (ann->operands.stores);\n+\n+  /* If aliases have not been computed, do not instantiate a virtual\n+     operator on STMT.  Initially, we only compute the SSA form on\n+     GIMPLE registers.  The virtual SSA form is only computed after\n+     alias analysis, so virtual operators will remain unrenamed and\n+     the verifier will complain.  However, alias analysis needs to\n+     access symbol load/store information, so we need to compute\n+     those.  */\n+  if (!gimple_aliases_computed_p (cfun))\n+    return;\n \n   new_list.next = NULL;\n   last = &new_list;\n \n-  old_ops = MAYDEF_OPS (stmt);\n-\n+  old_ops = VDEF_OPS (stmt);\n   new_i = 0;\n-  while (old_ops && new_i < VEC_length (tree, build_v_may_defs))\n+  while (old_ops && new_i < VEC_length (tree, build_vdefs))\n     {\n-      act = VEC_index (tree, build_v_may_defs, new_i);\n-      new_base = get_name_decl (act);\n-      old_base = get_name_decl (MAYDEF_OP (old_ops));\n+      tree op = VEC_index (tree, build_vdefs, new_i);\n+      unsigned new_uid = get_name_decl (op);\n+      unsigned old_uid = get_name_decl (VDEF_RESULT (old_ops));\n \n-      if (old_base == new_base)\n+      /* FIXME, for now each VDEF operator should have at most one\n+\t operand in their RHS.  */\n+      gcc_assert (VDEF_NUM (old_ops) == 1);\n+\n+      if (old_uid == new_uid)\n         {\n-\t  /* if variables are the same, reuse this node.  */\n+\t  /* If the symbols are the same, reuse the existing operand.  */\n \t  MOVE_HEAD_AFTER (old_ops, last);\n-\t  set_virtual_use_link (MAYDEF_OP_PTR (last), stmt);\n+\t  set_virtual_use_link (VDEF_OP_PTR (last, 0), stmt);\n \t  new_i++;\n \t}\n-      else if (old_base < new_base)\n+      else if (old_uid < new_uid)\n \t{\n-\t  /* if old is less than new, old goes to the free list.  */\n-\t  delink_imm_use (MAYDEF_OP_PTR (old_ops));\n-\t  MOVE_HEAD_TO_FREELIST (old_ops, maydef);\n+\t  /* If old is less than new, old goes to the free list.  */\n+\t  delink_imm_use (VDEF_OP_PTR (old_ops, 0));\n+\t  MOVE_HEAD_TO_FREELIST (old_ops, vdef);\n \t}\n       else\n \t{\n \t  /* This is a new operand.  */\n-\t  add_maydef_op (stmt, act, &last);\n+\t  add_vdef_op (stmt, op, 1, &last);\n \t  new_i++;\n \t}\n     }\n \n-  /* If there is anything remaining in the build_v_may_defs list, simply emit it.  */\n-  for ( ; new_i < VEC_length (tree, build_v_may_defs); new_i++)\n-    add_maydef_op (stmt, VEC_index (tree, build_v_may_defs, new_i), &last);\n+  /* If there is anything remaining in BUILD_VDEFS, simply emit it.  */\n+  for ( ; new_i < VEC_length (tree, build_vdefs); new_i++)\n+    add_vdef_op (stmt, VEC_index (tree, build_vdefs, new_i), 1, &last);\n \n   last->next = NULL;\n \n   /* If there is anything in the old list, free it.  */\n   if (old_ops)\n     {\n       for (ptr = old_ops; ptr; ptr = ptr->next)\n-\tdelink_imm_use (MAYDEF_OP_PTR (ptr));\n-      old_ops->next = gimple_ssa_operands (cfun)->free_maydefs;\n-      gimple_ssa_operands (cfun)->free_maydefs = old_ops;\n+\tdelink_imm_use (VDEF_OP_PTR (ptr, 0));\n+      old_ops->next = gimple_ssa_operands (cfun)->free_vdefs;\n+      gimple_ssa_operands (cfun)->free_vdefs = old_ops;\n     }\n \n-  /* Now set the stmt's operands.  */\n-  MAYDEF_OPS (stmt) = new_list.next;\n+  /* Now set STMT's operands.  */\n+  VDEF_OPS (stmt) = new_list.next;\n \n #ifdef ENABLE_CHECKING\n   {\n     unsigned x = 0;\n-    for (ptr = MAYDEF_OPS (stmt); ptr; ptr = ptr->next)\n+    for (ptr = VDEF_OPS (stmt); ptr; ptr = ptr->next)\n       x++;\n \n-    gcc_assert (x == VEC_length (tree, build_v_may_defs));\n+    gcc_assert (x == VEC_length (tree, build_vdefs));\n   }\n #endif\n }\n \n+\n static void\n-finalize_ssa_v_may_defs (tree stmt)\n+finalize_ssa_vdefs (tree stmt)\n {\n-  finalize_ssa_v_may_def_ops (stmt);\n+  finalize_ssa_vdef_ops (stmt);\n }\n-                                                                               \n \n-/* Clear the in_list bits and empty the build array for V_MAY_DEFs.  */\n \n-static inline void\n-cleanup_v_may_defs (void)\n-{\n-  unsigned x, num;\n-  num = VEC_length (tree, build_v_may_defs);\n \n-  for (x = 0; x < num; x++)\n-    {\n-      tree t = VEC_index (tree, build_v_may_defs, x);\n-      if (TREE_CODE (t) != SSA_NAME)\n-\t{\n-\t  var_ann_t ann = var_ann (t);\n-\t  ann->in_v_may_def_list = 0;\n-\t}\n-    }\n-  VEC_truncate (tree, build_v_may_defs, 0);\n-}                                                                             \n-\n-\n-/* Takes elements from build_vuses and turns them into vuse operands of\n+/* Takes elements from BUILD_VUSES and turns them into VUSE operands of\n    STMT.  */\n \n static inline void\n finalize_ssa_vuse_ops (tree stmt)\n {\n   unsigned new_i;\n+  int old_i;\n   struct vuse_optype_d new_list;\n-  vuse_optype_p old_ops, ptr, last;\n-  tree act;\n-  unsigned old_base, new_base;\n+  vuse_optype_p old_ops, last;\n+  VEC(tree,heap) *new_ops;\n+  stmt_ann_t ann;\n \n-  new_list.next = NULL;\n-  last = &new_list;\n+  /* Set the symbols referenced by STMT.  */\n+  ann = stmt_ann (stmt);\n+  if (!bitmap_empty_p (build_loads))\n+    {\n+      if (ann->operands.loads == NULL)\n+\tann->operands.loads = BITMAP_ALLOC (NULL);\n \n+      bitmap_copy (ann->operands.loads, build_loads);\n+    }\n+  else\n+    BITMAP_FREE (ann->operands.loads);\n+\n+  /* If aliases have not been computed, do not instantiate a virtual\n+     operator on STMT.  Initially, we only compute the SSA form on\n+     GIMPLE registers.  The virtual SSA form is only computed after\n+     alias analysis, so virtual operators will remain unrenamed and\n+     the verifier will complain.  However, alias analysis needs to\n+     access symbol load/store information, so we need to compute\n+     those.  */\n+  if (!gimple_aliases_computed_p (cfun))\n+    return;\n+\n+  /* STMT should have at most one VUSE operator.  */\n   old_ops = VUSE_OPS (stmt);\n+  gcc_assert (old_ops == NULL || old_ops->next == NULL);\n \n-  new_i = 0;\n-  while (old_ops && new_i < VEC_length (tree, build_vuses))\n+  new_ops = NULL;\n+  new_i = old_i = 0;\n+  while (old_ops\n+         && old_i < VUSE_NUM (old_ops)\n+\t && new_i < VEC_length (tree, build_vuses))\n     {\n-      act = VEC_index (tree, build_vuses, new_i);\n-      new_base = get_name_decl (act);\n-      old_base = get_name_decl (VUSE_OP (old_ops));\n+      tree new_op = VEC_index (tree, build_vuses, new_i);\n+      tree old_op = VUSE_OP (old_ops, old_i);\n+      unsigned new_uid = get_name_decl (new_op);\n+      unsigned old_uid = get_name_decl (old_op);\n \n-      if (old_base == new_base)\n+      if (old_uid == new_uid)\n         {\n-\t  /* if variables are the same, reuse this node.  */\n-\t  MOVE_HEAD_AFTER (old_ops, last);\n-\t  set_virtual_use_link (VUSE_OP_PTR (last), stmt);\n+\t  /* If the symbols are the same, reuse the existing operand.  */\n+\t  VEC_safe_push (tree, heap, new_ops, old_op);\n \t  new_i++;\n+\t  old_i++;\n \t}\n-      else if (old_base < new_base)\n+      else if (old_uid < new_uid)\n \t{\n-\t  /* if old is less than new, old goes to the free list.  */\n-\t  delink_imm_use (USE_OP_PTR (old_ops));\n-\t  MOVE_HEAD_TO_FREELIST (old_ops, vuse);\n+\t  /* If OLD_UID is less than NEW_UID, the old operand has\n+\t     disappeared, skip to the next old operand.  */\n+\t  old_i++;\n \t}\n       else\n \t{\n \t  /* This is a new operand.  */\n-\t  add_vuse_op (stmt, act, &last);\n+\t  VEC_safe_push (tree, heap, new_ops, new_op);\n \t  new_i++;\n \t}\n     }\n \n   /* If there is anything remaining in the build_vuses list, simply emit it.  */\n   for ( ; new_i < VEC_length (tree, build_vuses); new_i++)\n-    add_vuse_op (stmt, VEC_index (tree, build_vuses, new_i), &last);\n-\n-  last->next = NULL;\n+    VEC_safe_push (tree, heap, new_ops, VEC_index (tree, build_vuses, new_i));\n \n   /* If there is anything in the old list, free it.  */\n   if (old_ops)\n     {\n-      for (ptr = old_ops; ptr; ptr = ptr->next)\n-\tdelink_imm_use (VUSE_OP_PTR (ptr));\n+      for (old_i = 0; old_i < VUSE_NUM (old_ops); old_i++)\n+\tdelink_imm_use (VUSE_OP_PTR (old_ops, old_i));\n       old_ops->next = gimple_ssa_operands (cfun)->free_vuses;\n       gimple_ssa_operands (cfun)->free_vuses = old_ops;\n+\n+      VUSE_OPS (stmt) = NULL;\n     }\n \n-  /* Now set the stmt's operands.  */\n-  VUSE_OPS (stmt) = new_list.next;\n+  /* If there are any operands, instantiate a VUSE operator for STMT.  */\n+  if (new_ops)\n+    {\n+      tree op;\n+      unsigned i;\n+\n+      new_list.next = NULL;\n+      last = &new_list;\n+      add_vuse_op (stmt, NULL, VEC_length (tree, new_ops), &last);\n+      last->next = NULL;\n+\n+      for (i = 0; VEC_iterate (tree, new_ops, i, op); i++)\n+\tSET_USE (VUSE_OP_PTR (last, (int) i), op);\n+\n+      VUSE_OPS (stmt) = new_list.next;\n+    }\n \n #ifdef ENABLE_CHECKING\n   {\n-    unsigned x = 0;\n-    for (ptr = VUSE_OPS (stmt); ptr; ptr = ptr->next)\n-      x++;\n+    unsigned x;\n+    \n+    if (VUSE_OPS (stmt))\n+      {\n+\tgcc_assert (VUSE_OPS (stmt)->next == NULL);\n+\tx = VUSE_NUM (VUSE_OPS (stmt));\n+      }\n+    else\n+      x = 0;\n \n     gcc_assert (x == VEC_length (tree, build_vuses));\n   }\n #endif\n }\n-                                                                              \n-/* Return a new VUSE operand vector, comparing to OLD_OPS_P.  */\n+\n+/* Return a new VUSE operand vector for STMT.  */\n                                                                               \n static void\n finalize_ssa_vuses (tree stmt)\n {\n-  unsigned num, num_v_may_defs;\n+  unsigned num, num_vdefs;\n   unsigned vuse_index;\n \n   /* Remove superfluous VUSE operands.  If the statement already has a\n-     V_MAY_DEF operation for a variable 'a', then a VUSE for 'a' is\n-     not needed because V_MAY_DEFs imply a VUSE of the variable.  For\n-     instance, suppose that variable 'a' is aliased:\n+     VDEF operator for a variable 'a', then a VUSE for 'a' is not\n+     needed because VDEFs imply a VUSE of the variable.  For instance,\n+     suppose that variable 'a' is pointed-to by p and q:\n \n \t      # VUSE <a_2>\n-\t      # a_3 = V_MAY_DEF <a_2>\n-\t      a = a + 1;\n+\t      # a_3 = VDEF <a_2>\n+\t      *p = *q;\n \n      The VUSE <a_2> is superfluous because it is implied by the\n-     V_MAY_DEF operation.  */\n+     VDEF operator.  */\n   num = VEC_length (tree, build_vuses);\n-  num_v_may_defs = VEC_length (tree, build_v_may_defs);\n+  num_vdefs = VEC_length (tree, build_vdefs);\n \n-  if (num > 0 && num_v_may_defs > 0)\n-    {\n-      for (vuse_index = 0; vuse_index < VEC_length (tree, build_vuses); )\n-        {\n-\t  tree vuse;\n-\t  vuse = VEC_index (tree, build_vuses, vuse_index);\n-\t  if (TREE_CODE (vuse) != SSA_NAME)\n-\t    {\n-\t      var_ann_t ann = var_ann (vuse);\n-\t      ann->in_vuse_list = 0;\n-\t      if (ann->in_v_may_def_list)\n-\t        {\n-\t\t  VEC_ordered_remove (tree, build_vuses, vuse_index);\n-\t\t  continue;\n-\t\t}\n-\t    }\n-\t  vuse_index++;\n-\t}\n-    }\n-  else\n-    {\n-      /* Clear out the in_list bits.  */\n-      for (vuse_index = 0;\n-\t  vuse_index < VEC_length (tree, build_vuses);\n-\t  vuse_index++)\n-\t{\n-\t  tree t = VEC_index (tree, build_vuses, vuse_index);\n-\t  if (TREE_CODE (t) != SSA_NAME)\n-\t    {\n-\t      var_ann_t ann = var_ann (t);\n-\t      ann->in_vuse_list = 0;\n-\t    }\n-\t}\n-    }\n+  if (num > 0 && num_vdefs > 0)\n+    for (vuse_index = 0; vuse_index < VEC_length (tree, build_vuses); )\n+      {\n+\ttree vuse;\n+\tvuse = VEC_index (tree, build_vuses, vuse_index);\n+\tif (TREE_CODE (vuse) != SSA_NAME)\n+\t  {\n+\t    var_ann_t ann = var_ann (vuse);\n+\t    ann->in_vuse_list = 0;\n+\t    if (ann->in_vdef_list)\n+\t      {\n+\t\tVEC_ordered_remove (tree, build_vuses, vuse_index);\n+\t\tcontinue;\n+\t      }\n+\t  }\n+\tvuse_index++;\n+      }\n \n   finalize_ssa_vuse_ops (stmt);\n-\n-  /* The V_MAY_DEF build vector wasn't cleaned up because we needed it.  */\n-  cleanup_v_may_defs ();\n-                                                                              \n-  /* Free the VUSEs build vector.  */\n-  VEC_truncate (tree, build_vuses, 0);\n-\n }\n \n-/* Takes elements from build_v_must_defs and turns them into mustdef operands of\n-   STMT.  */\n+\n+/* Clear the in_list bits and empty the build array for VDEFs and\n+   VUSEs.  */\n \n static inline void\n-finalize_ssa_v_must_def_ops (tree stmt)\n+cleanup_build_arrays (void)\n {\n-  unsigned new_i;\n-  struct mustdef_optype_d new_list;\n-  mustdef_optype_p old_ops, ptr, last;\n-  tree act;\n-  unsigned old_base, new_base;\n-\n-  new_list.next = NULL;\n-  last = &new_list;\n-\n-  old_ops = MUSTDEF_OPS (stmt);\n-\n-  new_i = 0;\n-  while (old_ops && new_i < VEC_length (tree, build_v_must_defs))\n-    {\n-      act = VEC_index (tree, build_v_must_defs, new_i);\n-      new_base = get_name_decl (act);\n-      old_base = get_name_decl (MUSTDEF_KILL (old_ops));\n-\n-      if (old_base == new_base)\n-        {\n-\t  /* If variables are the same, reuse this node.  */\n-\t  MOVE_HEAD_AFTER (old_ops, last);\n-\t  set_virtual_use_link (MUSTDEF_KILL_PTR (last), stmt);\n-\t  new_i++;\n-\t}\n-      else if (old_base < new_base)\n-\t{\n-\t  /* If old is less than new, old goes to the free list.  */\n-\t  delink_imm_use (MUSTDEF_KILL_PTR (old_ops));\n-\t  MOVE_HEAD_TO_FREELIST (old_ops, mustdef);\n-\t}\n-      else\n-\t{\n-\t  /* This is a new operand.  */\n-\t  add_mustdef_op (stmt, act, &last);\n-\t  new_i++;\n-\t}\n-    }\n-\n-  /* If there is anything remaining in the build_v_must_defs list, simply emit it.  */\n-  for ( ; new_i < VEC_length (tree, build_v_must_defs); new_i++)\n-    add_mustdef_op (stmt, VEC_index (tree, build_v_must_defs, new_i), &last);\n-\n-  last->next = NULL;\n-\n-  /* If there is anything in the old list, free it.  */\n-  if (old_ops)\n-    {\n-      for (ptr = old_ops; ptr; ptr = ptr->next)\n-\tdelink_imm_use (MUSTDEF_KILL_PTR (ptr));\n-      old_ops->next = gimple_ssa_operands (cfun)->free_mustdefs;\n-      gimple_ssa_operands (cfun)->free_mustdefs = old_ops;\n-    }\n+  unsigned i;\n+  tree t;\n \n-  /* Now set the stmt's operands.  */\n-  MUSTDEF_OPS (stmt) = new_list.next;\n+  for (i = 0; VEC_iterate (tree, build_vdefs, i, t); i++)\n+    if (TREE_CODE (t) != SSA_NAME)\n+      var_ann (t)->in_vdef_list = false;\n \n-#ifdef ENABLE_CHECKING\n-  {\n-    unsigned x = 0;\n-    for (ptr = MUSTDEF_OPS (stmt); ptr; ptr = ptr->next)\n-      x++;\n+  for (i = 0; VEC_iterate (tree, build_vuses, i, t); i++)\n+    if (TREE_CODE (t) != SSA_NAME)\n+      var_ann (t)->in_vuse_list = false;\n \n-    gcc_assert (x == VEC_length (tree, build_v_must_defs));\n-  }\n-#endif\n-}\n-\n-static void\n-finalize_ssa_v_must_defs (tree stmt)\n-{\n-  /* In the presence of subvars, there may be more than one V_MUST_DEF\n-     per statement (one for each subvar).  It is a bit expensive to\n-     verify that all must-defs in a statement belong to subvars if\n-     there is more than one must-def, so we don't do it.  Suffice to\n-     say, if you reach here without having subvars, and have num >1,\n-     you have hit a bug.  */\n-  finalize_ssa_v_must_def_ops (stmt);\n-  VEC_truncate (tree, build_v_must_defs, 0);\n+  VEC_truncate (tree, build_vdefs, 0);\n+  VEC_truncate (tree, build_vuses, 0);\n+  VEC_truncate (tree, build_defs, 0);\n+  VEC_truncate (tree, build_uses, 0);\n+  bitmap_clear (build_loads);\n+  bitmap_clear (build_stores);\n }\n \n \n@@ -989,9 +1159,9 @@ finalize_ssa_stmt_operands (tree stmt)\n {\n   finalize_ssa_defs (stmt);\n   finalize_ssa_uses (stmt);\n-  finalize_ssa_v_must_defs (stmt);\n-  finalize_ssa_v_may_defs (stmt);\n+  finalize_ssa_vdefs (stmt);\n   finalize_ssa_vuses (stmt);\n+  cleanup_build_arrays ();\n }\n \n \n@@ -1003,8 +1173,9 @@ start_ssa_stmt_operands (void)\n   gcc_assert (VEC_length (tree, build_defs) == 0);\n   gcc_assert (VEC_length (tree, build_uses) == 0);\n   gcc_assert (VEC_length (tree, build_vuses) == 0);\n-  gcc_assert (VEC_length (tree, build_v_may_defs) == 0);\n-  gcc_assert (VEC_length (tree, build_v_must_defs) == 0);\n+  gcc_assert (VEC_length (tree, build_vdefs) == 0);\n+  gcc_assert (bitmap_empty_p (build_loads));\n+  gcc_assert (bitmap_empty_p (build_stores));\n }\n \n \n@@ -1013,7 +1184,7 @@ start_ssa_stmt_operands (void)\n static inline void\n append_def (tree *def_p)\n {\n-  VEC_safe_push (tree, heap, build_defs, (tree)def_p);\n+  VEC_safe_push (tree, heap, build_defs, (tree) def_p);\n }\n \n \n@@ -1022,61 +1193,73 @@ append_def (tree *def_p)\n static inline void\n append_use (tree *use_p)\n {\n-  VEC_safe_push (tree, heap, build_uses, (tree)use_p);\n+  VEC_safe_push (tree, heap, build_uses, (tree) use_p);\n }\n \n \n-/* Add a new virtual may def for variable VAR to the build array.  */\n+/* Add VAR to the set of variables that require a VDEF operator.  */\n \n static inline void\n-append_v_may_def (tree var)\n+append_vdef (tree var)\n {\n+  tree sym;\n+\n   if (TREE_CODE (var) != SSA_NAME)\n     {\n-      var_ann_t ann = get_var_ann (var);\n+      tree mpt;\n+      var_ann_t ann;\n+\n+      /* If VAR belongs to a memory partition, use it instead of VAR.  */\n+      mpt = memory_partition (var);\n+      if (mpt)\n+\tvar = mpt;\n \n       /* Don't allow duplicate entries.  */\n-      if (ann->in_v_may_def_list)\n-\treturn;\n-      ann->in_v_may_def_list = 1;\n+      ann = get_var_ann (var);\n+      if (ann->in_vdef_list)\n+        return;\n+\n+      ann->in_vdef_list = true;\n+      sym = var;\n     }\n+  else\n+    sym = SSA_NAME_VAR (var);\n \n-  VEC_safe_push (tree, heap, build_v_may_defs, (tree)var);\n+  VEC_safe_push (tree, heap, build_vdefs, var);\n+  bitmap_set_bit (build_stores, DECL_UID (sym));\n }\n \n \n-/* Add VAR to the list of virtual uses.  */\n+/* Add VAR to the set of variables that require a VUSE operator.  */\n \n static inline void\n append_vuse (tree var)\n {\n-  /* Don't allow duplicate entries.  */\n+  tree sym;\n+\n   if (TREE_CODE (var) != SSA_NAME)\n     {\n-      var_ann_t ann = get_var_ann (var);\n-\n-      if (ann->in_vuse_list || ann->in_v_may_def_list)\n-        return;\n-      ann->in_vuse_list = 1;\n-    }\n-\n-  VEC_safe_push (tree, heap, build_vuses, (tree)var);\n-}\n+      tree mpt;\n+      var_ann_t ann;\n \n+      /* If VAR belongs to a memory partition, use it instead of VAR.  */\n+      mpt = memory_partition (var);\n+      if (mpt)\n+\tvar = mpt;\n \n-/* Add VAR to the list of virtual must definitions for INFO.  */\n-\n-static inline void\n-append_v_must_def (tree var)\n-{\n-  unsigned i;\n+      /* Don't allow duplicate entries.  */\n+      ann = get_var_ann (var);\n+      if (ann->in_vuse_list || ann->in_vdef_list)\n+\treturn;\n \n-  /* Don't allow duplicate entries.  */\n-  for (i = 0; i < VEC_length (tree, build_v_must_defs); i++)\n-    if (var == VEC_index (tree, build_v_must_defs, i))\n-      return;\n+      ann->in_vuse_list = true;\n+      sym = var;\n+    }\n+  else\n+    sym = SSA_NAME_VAR (var);\n \n-  VEC_safe_push (tree, heap, build_v_must_defs, (tree)var);\n+  VEC_safe_push (tree, heap, build_vuses, var);\n+  bitmap_set_bit (build_loads, DECL_UID (sym));\n }\n \n \n@@ -1088,7 +1271,7 @@ append_v_must_def (tree var)\n static bool\n access_can_touch_variable (tree ref, tree alias, HOST_WIDE_INT offset,\n \t\t\t   HOST_WIDE_INT size)\n-{  \n+{\n   bool offsetgtz = offset > 0;\n   unsigned HOST_WIDE_INT uoffset = (unsigned HOST_WIDE_INT) offset;\n   tree base = ref ? get_base_address (ref) : NULL;\n@@ -1257,26 +1440,29 @@ add_virtual_operand (tree var, stmt_ann_t s_ann, int flags,\n   sym = (TREE_CODE (var) == SSA_NAME ? SSA_NAME_VAR (var) : var);\n   v_ann = var_ann (sym);\n   \n+  /* Mark the statement as having memory operands.  */\n+  s_ann->references_memory = true;\n+\n   /* Mark statements with volatile operands.  Optimizers should back\n      off from statements having volatile operands.  */\n   if (TREE_THIS_VOLATILE (sym) && s_ann)\n     s_ann->has_volatile_ops = true;\n \n-  /* If the variable cannot be modified and this is a V_MAY_DEF change\n+  /* If the variable cannot be modified and this is a VDEF change\n      it into a VUSE.  This happens when read-only variables are marked\n      call-clobbered and/or aliased to writable variables.  So we only\n      check that this only happens on non-specific stores.\n \n      Note that if this is a specific store, i.e. associated with a\n-     gimple_modify_stmt, then we can't suppress the V_MAY_DEF, lest we run\n+     GIMPLE_MODIFY_STMT, then we can't suppress the VDEF, lest we run\n      into validation problems.\n \n      This can happen when programs cast away const, leaving us with a\n      store to read-only memory.  If the statement is actually executed\n      at runtime, then the program is ill formed.  If the statement is\n      not executed then all is well.  At the very least, we cannot ICE.  */\n-  if ((flags & opf_non_specific) && unmodifiable_var_p (var))\n-    flags &= ~(opf_is_def | opf_kill_def);\n+  if ((flags & opf_implicit) && unmodifiable_var_p (var))\n+    flags &= ~opf_def;\n   \n   /* The variable is not a GIMPLE register.  Add it (or its aliases) to\n      virtual operands, unless the caller has specifically requested\n@@ -1289,23 +1475,8 @@ add_virtual_operand (tree var, stmt_ann_t s_ann, int flags,\n   if (aliases == NULL)\n     {\n       /* The variable is not aliased or it is an alias tag.  */\n-      if (flags & opf_is_def)\n-\t{\n-\t  if (flags & opf_kill_def)\n-\t    {\n-\t      /* V_MUST_DEF for non-aliased, non-GIMPLE register \n-\t\t variable definitions.  */\n-\t      gcc_assert (!MTAG_P (var)\n-\t\t\t  || TREE_CODE (var) == STRUCT_FIELD_TAG);\n-\t      append_v_must_def (var);\n-\t    }\n-\t  else\n-\t    {\n-\t      /* Add a V_MAY_DEF for call-clobbered variables and\n-\t\t memory tags.  */\n-\t      append_v_may_def (var);\n-\t    }\n-\t}\n+      if (flags & opf_def)\n+\tappend_vdef (var);\n       else\n \tappend_vuse (var);\n     }\n@@ -1318,9 +1489,8 @@ add_virtual_operand (tree var, stmt_ann_t s_ann, int flags,\n \t operands.  */\n       gcc_assert (VEC_length (tree, aliases) != 0);\n       \n-      if (flags & opf_is_def)\n+      if (flags & opf_def)\n \t{\n-\t  \n \t  bool none_added = true;\n \n \t  for (i = 0; VEC_iterate (tree, aliases, i, al); i++)\n@@ -1329,7 +1499,7 @@ add_virtual_operand (tree var, stmt_ann_t s_ann, int flags,\n \t\tcontinue;\n \t      \n \t      none_added = false;\n-\t      append_v_may_def (al);\n+\t      append_vdef (al);\n \t    }\n \n \t  /* If the variable is also an alias tag, add a virtual\n@@ -1348,7 +1518,7 @@ add_virtual_operand (tree var, stmt_ann_t s_ann, int flags,\n \t      || (TREE_CODE (var) == SYMBOL_MEMORY_TAG\n \t\t  && for_clobber))\n \t    {\n-\t      append_v_may_def (var);\n+\t      append_vdef (var);\n \t    }\n \t}\n       else\n@@ -1379,31 +1549,23 @@ add_virtual_operand (tree var, stmt_ann_t s_ann, int flags,\n static void\n add_stmt_operand (tree *var_p, stmt_ann_t s_ann, int flags)\n {\n-  bool is_real_op;\n   tree var, sym;\n   var_ann_t v_ann;\n \n-  var = *var_p;\n-  gcc_assert (SSA_VAR_P (var));\n-\n-  is_real_op = is_gimple_reg (var);\n-\n-  /* If this is a real operand, the operand is either an SSA name or a \n-     decl.  Virtual operands may only be decls.  */\n-  gcc_assert (is_real_op || DECL_P (var));\n+  gcc_assert (SSA_VAR_P (*var_p) && s_ann);\n \n+  var = *var_p;\n   sym = (TREE_CODE (var) == SSA_NAME ? SSA_NAME_VAR (var) : var);\n   v_ann = var_ann (sym);\n \n-  /* Mark statements with volatile operands.  Optimizers should back\n-     off from statements having volatile operands.  */\n-  if (TREE_THIS_VOLATILE (sym) && s_ann)\n+  /* Mark statements with volatile operands.  */\n+  if (TREE_THIS_VOLATILE (sym))\n     s_ann->has_volatile_ops = true;\n \n-  if (is_real_op)\n+  if (is_gimple_reg (sym))\n     {\n       /* The variable is a GIMPLE register.  Add it to real operands.  */\n-      if (flags & opf_is_def)\n+      if (flags & opf_def)\n \tappend_def (var_p);\n       else\n \tappend_use (var_p);\n@@ -1441,8 +1603,7 @@ get_indirect_ref_operands (tree stmt, tree expr, int flags,\n   tree ptr = *pptr;\n   stmt_ann_t s_ann = stmt_ann (stmt);\n \n-  /* Stores into INDIRECT_REF operands are never killing definitions.  */\n-  flags &= ~opf_kill_def;\n+  s_ann->references_memory = true;\n \n   if (SSA_VAR_P (ptr))\n     {\n@@ -1504,7 +1665,7 @@ get_indirect_ref_operands (tree stmt, tree expr, int flags,\n \n   /* If requested, add a USE operand for the base pointer.  */\n   if (recurse_on_base)\n-    get_expr_operands (stmt, pptr, opf_none);\n+    get_expr_operands (stmt, pptr, opf_use);\n }\n \n \n@@ -1513,28 +1674,26 @@ get_indirect_ref_operands (tree stmt, tree expr, int flags,\n static void\n get_tmr_operands (tree stmt, tree expr, int flags)\n {\n-  tree tag = TMR_TAG (expr), ref;\n+  tree tag, ref;\n   HOST_WIDE_INT offset, size, maxsize;\n   subvar_t svars, sv;\n   stmt_ann_t s_ann = stmt_ann (stmt);\n \n-  /* First record the real operands.  */\n-  get_expr_operands (stmt, &TMR_BASE (expr), opf_none);\n-  get_expr_operands (stmt, &TMR_INDEX (expr), opf_none);\n+  /* This statement references memory.  */\n+  s_ann->references_memory = 1;\n \n-  /* MEM_REFs should never be killing.  */\n-  flags &= ~opf_kill_def;\n+  /* First record the real operands.  */\n+  get_expr_operands (stmt, &TMR_BASE (expr), opf_use);\n+  get_expr_operands (stmt, &TMR_INDEX (expr), opf_use);\n \n   if (TMR_SYMBOL (expr))\n-    {\n-      stmt_ann_t ann = stmt_ann (stmt);\n-      add_to_addressable_set (TMR_SYMBOL (expr), &ann->addresses_taken);\n-    }\n+    add_to_addressable_set (TMR_SYMBOL (expr), &s_ann->addresses_taken);\n \n+  tag = TMR_TAG (expr);\n   if (!tag)\n     {\n       /* Something weird, so ensure that we will be careful.  */\n-      stmt_ann (stmt)->has_volatile_ops = true;\n+      s_ann->has_volatile_ops = true;\n       return;\n     }\n \n@@ -1550,13 +1709,9 @@ get_tmr_operands (tree stmt, tree expr, int flags)\n   for (sv = svars; sv; sv = sv->next)\n     {\n       bool exact;\t\t\n+\n       if (overlap_subvar (offset, maxsize, sv->var, &exact))\n-\t{\n-\t  int subvar_flags = flags;\n-\t  if (!exact || size != maxsize)\n-\t    subvar_flags &= ~opf_kill_def;\n-\t  add_stmt_operand (&sv->var, s_ann, subvar_flags);\n-\t}\n+\tadd_stmt_operand (&sv->var, s_ann, flags);\n     }\n }\n \n@@ -1582,7 +1737,7 @@ add_call_clobber_ops (tree stmt, tree callee)\n   if (gimple_global_var (cfun))\n     {\n       tree var = gimple_global_var (cfun);\n-      add_stmt_operand (&var, s_ann, opf_is_def);\n+      add_stmt_operand (&var, s_ann, opf_def);\n       return;\n     }\n \n@@ -1591,7 +1746,8 @@ add_call_clobber_ops (tree stmt, tree callee)\n      or write that variable.  */\n   not_read_b = callee ? ipa_reference_get_not_read_global (callee) : NULL; \n   not_written_b = callee ? ipa_reference_get_not_written_global (callee) : NULL; \n-  /* Add a V_MAY_DEF operand for every call clobbered variable.  */\n+\n+  /* Add a VDEF operand for every call clobbered variable.  */\n   EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, u, bi)\n     {\n       tree var = referenced_var_lookup (u);\n@@ -1622,7 +1778,7 @@ add_call_clobber_ops (tree stmt, tree callee)\n \t  tree call = get_call_expr_in (stmt);\n \t  if (call_expr_flags (call) & (ECF_CONST | ECF_PURE))\n \t    {\n-\t      add_stmt_operand (&var, s_ann, opf_none);\n+\t      add_stmt_operand (&var, s_ann, opf_use);\n \t      clobber_stats.unescapable_clobbers_avoided++;\n \t      continue;\n \t    }\n@@ -1637,12 +1793,12 @@ add_call_clobber_ops (tree stmt, tree callee)\n \t{\n \t  clobber_stats.static_write_clobbers_avoided++;\n \t  if (!not_read)\n-\t    add_stmt_operand (&var, s_ann, opf_none);\n+\t    add_stmt_operand (&var, s_ann, opf_use);\n \t  else\n \t    clobber_stats.static_read_clobbers_avoided++;\n \t}\n       else\n-\tadd_virtual_operand (var, s_ann, opf_is_def, NULL, 0, -1, true);\n+\tadd_virtual_operand (var, s_ann, opf_def, NULL, 0, -1, true);\n     }\n }\n \n@@ -1664,7 +1820,7 @@ add_call_read_ops (tree stmt, tree callee)\n   if (gimple_global_var (cfun))\n     {\n       tree var = gimple_global_var (cfun);\n-      add_stmt_operand (&var, s_ann, opf_none);\n+      add_stmt_operand (&var, s_ann, opf_use);\n       return;\n     }\n   \n@@ -1694,7 +1850,7 @@ add_call_read_ops (tree stmt, tree callee)\n \t  continue;\n \t}\n             \n-      add_stmt_operand (&var, s_ann, opf_none | opf_non_specific);\n+      add_stmt_operand (&var, s_ann, opf_use | opf_implicit);\n     }\n }\n \n@@ -1706,19 +1862,14 @@ get_call_expr_operands (tree stmt, tree expr)\n {\n   tree op;\n   int call_flags = call_expr_flags (expr);\n+  stmt_ann_t ann = stmt_ann (stmt);\n \n-  /* If aliases have been computed already, add V_MAY_DEF or V_USE\n+  ann->references_memory = true;\n+\n+  /* If aliases have been computed already, add VDEF or VUSE\n      operands for all the symbols that have been found to be\n-     call-clobbered.\n-     \n-     Note that if aliases have not been computed, the global effects\n-     of calls will not be included in the SSA web. This is fine\n-     because no optimizer should run before aliases have been\n-     computed.  By not bothering with virtual operands for CALL_EXPRs\n-     we avoid adding superfluous virtual operands, which can be a\n-     significant compile time sink (See PR 15855).  */\n+     call-clobbered.  */\n   if (gimple_aliases_computed_p (cfun)\n-      && !bitmap_empty_p (gimple_call_clobbered_vars (cfun))\n       && !(call_flags & ECF_NOVOPS))\n     {\n       /* A 'pure' or a 'const' function never call-clobbers anything. \n@@ -1732,12 +1883,12 @@ get_call_expr_operands (tree stmt, tree expr)\n     }\n \n   /* Find uses in the called function.  */\n-  get_expr_operands (stmt, &TREE_OPERAND (expr, 0), opf_none);\n+  get_expr_operands (stmt, &TREE_OPERAND (expr, 0), opf_use);\n \n   for (op = TREE_OPERAND (expr, 1); op; op = TREE_CHAIN (op))\n-    get_expr_operands (stmt, &TREE_VALUE (op), opf_none);\n+    get_expr_operands (stmt, &TREE_VALUE (op), opf_use);\n \n-  get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_none);\n+  get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_use);\n }\n \n \n@@ -1746,16 +1897,19 @@ get_call_expr_operands (tree stmt, tree expr)\n static void\n get_asm_expr_operands (tree stmt)\n {\n-  stmt_ann_t s_ann = stmt_ann (stmt);\n-  int noutputs = list_length (ASM_OUTPUTS (stmt));\n-  const char **oconstraints\n-    = (const char **) alloca ((noutputs) * sizeof (const char *));\n-  int i;\n-  tree link;\n+  stmt_ann_t s_ann;\n+  int i, noutputs;\n+  const char **oconstraints;\n   const char *constraint;\n   bool allows_mem, allows_reg, is_inout;\n+  tree link;\n+\n+  s_ann = stmt_ann (stmt);\n+  noutputs = list_length (ASM_OUTPUTS (stmt));\n+  oconstraints = (const char **) alloca ((noutputs) * sizeof (const char *));\n \n-  for (i=0, link = ASM_OUTPUTS (stmt); link; ++i, link = TREE_CHAIN (link))\n+  /* Gather all output operands.  */\n+  for (i = 0, link = ASM_OUTPUTS (stmt); link; i++, link = TREE_CHAIN (link))\n     {\n       constraint = TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n       oconstraints[i] = constraint;\n@@ -1774,14 +1928,15 @@ get_asm_expr_operands (tree stmt)\n \t    add_to_addressable_set (t, &s_ann->addresses_taken);\n \t}\n \n-      get_expr_operands (stmt, &TREE_VALUE (link), opf_is_def);\n+      get_expr_operands (stmt, &TREE_VALUE (link), opf_def);\n     }\n \n+  /* Gather all input operands.  */\n   for (link = ASM_INPUTS (stmt); link; link = TREE_CHAIN (link))\n     {\n       constraint = TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n-      parse_input_constraint (&constraint, 0, 0, noutputs, 0,\n-\t\t\t      oconstraints, &allows_mem, &allows_reg);\n+      parse_input_constraint (&constraint, 0, 0, noutputs, 0, oconstraints,\n+\t                      &allows_mem, &allows_reg);\n \n       /* Memory operands are addressable.  Note that STMT needs the\n \t address of this operand.  */\n@@ -1795,46 +1950,36 @@ get_asm_expr_operands (tree stmt)\n       get_expr_operands (stmt, &TREE_VALUE (link), 0);\n     }\n \n-\n-  /* Clobber memory for asm (\"\" : : : \"memory\");  */\n+  /* Clobber all memory and addressable symbols for asm (\"\" : : : \"memory\");  */\n   for (link = ASM_CLOBBERS (stmt); link; link = TREE_CHAIN (link))\n     if (strcmp (TREE_STRING_POINTER (TREE_VALUE (link)), \"memory\") == 0)\n       {\n \tunsigned i;\n \tbitmap_iterator bi;\n \n-\t/* Clobber all call-clobbered variables (or .GLOBAL_VAR if we\n-\t   decided to group them).  */\n-\tif (gimple_global_var (cfun))\n+\ts_ann->references_memory = true;\n+\n+\tEXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, i, bi)\n \t  {\n-            tree var = gimple_global_var (cfun);\n-\t    add_stmt_operand (&var, s_ann, opf_is_def);\n+\t    tree var = referenced_var (i);\n+\t    add_stmt_operand (&var, s_ann, opf_def | opf_implicit);\n \t  }\n-\telse\n-\t  EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, i, bi)\n-\t    {\n-\t      tree var = referenced_var (i);\n-\t      add_stmt_operand (&var, s_ann, opf_is_def | opf_non_specific);\n-\t    }\n \n-\t/* Now clobber all addressables.  */\n \tEXECUTE_IF_SET_IN_BITMAP (gimple_addressable_vars (cfun), 0, i, bi)\n-\t    {\n-\t      tree var = referenced_var (i);\n-\n-\t      /* Subvars are explicitly represented in this list, so\n-\t\t we don't need the original to be added to the clobber\n-\t\t ops, but the original *will* be in this list because \n-\t\t we keep the addressability of the original\n-\t\t variable up-to-date so we don't screw up the rest of\n-\t\t the backend.  */\n-\t      if (var_can_have_subvars (var)\n-\t\t  && get_subvars_for_var (var) != NULL)\n-\t\tcontinue;\t\t\n-\n-\t      add_stmt_operand (&var, s_ann, opf_is_def | opf_non_specific);\n-\t    }\n-\n+\t  {\n+\t    tree var = referenced_var (i);\n+\n+\t    /* Subvars are explicitly represented in this list, so we\n+\t       don't need the original to be added to the clobber ops,\n+\t       but the original *will* be in this list because we keep\n+\t       the addressability of the original variable up-to-date\n+\t       to avoid confusing the back-end.  */\n+\t    if (var_can_have_subvars (var)\n+\t\t&& get_subvars_for_var (var) != NULL)\n+\t      continue;\t\t\n+\n+\t    add_stmt_operand (&var, s_ann, opf_def | opf_implicit);\n+\t  }\n \tbreak;\n       }\n }\n@@ -1846,23 +1991,20 @@ static void\n get_modify_stmt_operands (tree stmt, tree expr)\n {\n   /* First get operands from the RHS.  */\n-  get_expr_operands (stmt, &GIMPLE_STMT_OPERAND (expr, 1), opf_none);\n+  get_expr_operands (stmt, &GIMPLE_STMT_OPERAND (expr, 1), opf_use);\n \n-  /* For the LHS, use a regular definition (OPF_IS_DEF) for GIMPLE\n-     registers.  If the LHS is a store to memory, we will either need\n-     a preserving definition (V_MAY_DEF) or a killing definition\n-     (V_MUST_DEF).\n+  /* For the LHS, use a regular definition (opf_def) for GIMPLE\n+     registers.  If the LHS is a store to memory, we will need\n+     a preserving definition (VDEF).\n \n      Preserving definitions are those that modify a part of an\n      aggregate object for which no subvars have been computed (or the\n      reference does not correspond exactly to one of them). Stores\n-     through a pointer are also represented with V_MAY_DEF operators.\n+     through a pointer are also represented with VDEF operators.\n \n-     The determination of whether to use a preserving or a killing\n-     definition is done while scanning the LHS of the assignment.  By\n-     default, assume that we will emit a V_MUST_DEF.  */\n-  get_expr_operands (stmt, &GIMPLE_STMT_OPERAND (expr, 0),\n-      \t\t     opf_is_def|opf_kill_def);\n+     We used to distinguish between preserving and killing definitions.\n+     We always emit preserving definitions now.  */\n+  get_expr_operands (stmt, &GIMPLE_STMT_OPERAND (expr, 0), opf_def);\n }\n \n \n@@ -1979,8 +2121,6 @@ get_expr_operands (tree stmt, tree *expr_p, int flags)\n \t\t  {\n \t            int subvar_flags = flags;\n \t\t    none = false;\n-\t\t    if (!exact || size != maxsize)\n-\t\t      subvar_flags &= ~opf_kill_def;\n \t\t    add_stmt_operand (&sv->var, s_ann, subvar_flags);\n \t\t  }\n \t      }\n@@ -1998,20 +2138,19 @@ get_expr_operands (tree stmt, tree *expr_p, int flags)\n \t/* Even if we found subvars above we need to ensure to see\n \t   immediate uses for d in s.a[d].  In case of s.a having\n \t   a subvar or we would miss it otherwise.  */\n-\tget_expr_operands (stmt, &TREE_OPERAND (expr, 0),\n-\t\t\t   flags & ~opf_kill_def);\n+\tget_expr_operands (stmt, &TREE_OPERAND (expr, 0), flags);\n \t\n \tif (code == COMPONENT_REF)\n \t  {\n \t    if (s_ann && TREE_THIS_VOLATILE (TREE_OPERAND (expr, 1)))\n \t      s_ann->has_volatile_ops = true; \n-\t    get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_none);\n+\t    get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_use);\n \t  }\n \telse if (code == ARRAY_REF || code == ARRAY_RANGE_REF)\n \t  {\n-            get_expr_operands (stmt, &TREE_OPERAND (expr, 1), opf_none);\n-            get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_none);\n-            get_expr_operands (stmt, &TREE_OPERAND (expr, 3), opf_none);\n+            get_expr_operands (stmt, &TREE_OPERAND (expr, 1), opf_use);\n+            get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_use);\n+            get_expr_operands (stmt, &TREE_OPERAND (expr, 3), opf_use);\n \t  }\n \n \treturn;\n@@ -2020,7 +2159,7 @@ get_expr_operands (tree stmt, tree *expr_p, int flags)\n     case WITH_SIZE_EXPR:\n       /* WITH_SIZE_EXPR is a pass-through reference to its first argument,\n \t and an rvalue reference to its second argument.  */\n-      get_expr_operands (stmt, &TREE_OPERAND (expr, 1), opf_none);\n+      get_expr_operands (stmt, &TREE_OPERAND (expr, 1), opf_use);\n       get_expr_operands (stmt, &TREE_OPERAND (expr, 0), flags);\n       return;\n \n@@ -2030,9 +2169,9 @@ get_expr_operands (tree stmt, tree *expr_p, int flags)\n \n     case COND_EXPR:\n     case VEC_COND_EXPR:\n-      get_expr_operands (stmt, &TREE_OPERAND (expr, 0), opf_none);\n-      get_expr_operands (stmt, &TREE_OPERAND (expr, 1), opf_none);\n-      get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_none);\n+      get_expr_operands (stmt, &TREE_OPERAND (expr, 0), opf_use);\n+      get_expr_operands (stmt, &TREE_OPERAND (expr, 1), opf_use);\n+      get_expr_operands (stmt, &TREE_OPERAND (expr, 2), opf_use);\n       return;\n \n     case GIMPLE_MODIFY_STMT:\n@@ -2049,17 +2188,12 @@ get_expr_operands (tree stmt, tree *expr_p, int flags)\n \tfor (idx = 0;\n \t     VEC_iterate (constructor_elt, CONSTRUCTOR_ELTS (expr), idx, ce);\n \t     idx++)\n-\t  get_expr_operands (stmt, &ce->value, opf_none);\n+\t  get_expr_operands (stmt, &ce->value, opf_use);\n \n \treturn;\n       }\n \n     case BIT_FIELD_REF:\n-      /* Stores using BIT_FIELD_REF are always preserving definitions.  */\n-      flags &= ~opf_kill_def;\n-\n-      /* Fallthru  */\n-\n     case TRUTH_NOT_EXPR:\n     case VIEW_CONVERT_EXPR:\n     do_unary:\n@@ -2141,27 +2275,27 @@ parse_ssa_operands (tree stmt)\n       break;\n \n     case COND_EXPR:\n-      get_expr_operands (stmt, &COND_EXPR_COND (stmt), opf_none);\n+      get_expr_operands (stmt, &COND_EXPR_COND (stmt), opf_use);\n       break;\n \n     case SWITCH_EXPR:\n-      get_expr_operands (stmt, &SWITCH_COND (stmt), opf_none);\n+      get_expr_operands (stmt, &SWITCH_COND (stmt), opf_use);\n       break;\n \n     case ASM_EXPR:\n       get_asm_expr_operands (stmt);\n       break;\n \n     case RETURN_EXPR:\n-      get_expr_operands (stmt, &TREE_OPERAND (stmt, 0), opf_none);\n+      get_expr_operands (stmt, &TREE_OPERAND (stmt, 0), opf_use);\n       break;\n \n     case GOTO_EXPR:\n-      get_expr_operands (stmt, &GOTO_DESTINATION (stmt), opf_none);\n+      get_expr_operands (stmt, &GOTO_DESTINATION (stmt), opf_use);\n       break;\n \n     case LABEL_EXPR:\n-      get_expr_operands (stmt, &LABEL_EXPR_LABEL (stmt), opf_none);\n+      get_expr_operands (stmt, &LABEL_EXPR_LABEL (stmt), opf_use);\n       break;\n \n     case BIND_EXPR:\n@@ -2172,15 +2306,15 @@ parse_ssa_operands (tree stmt)\n     case CATCH_EXPR:\n     case RESX_EXPR:\n       /* These nodes contain no variable references.  */\n-      break;\n+     break;\n \n     default:\n       /* Notice that if get_expr_operands tries to use &STMT as the\n \t operand pointer (which may only happen for USE operands), we\n \t will fail in add_stmt_operand.  This default will handle\n \t statements like empty statements, or CALL_EXPRs that may\n \t appear on the RHS of a statement or as statements themselves.  */\n-      get_expr_operands (stmt, &stmt, opf_none);\n+      get_expr_operands (stmt, &stmt, opf_use);\n       break;\n     }\n }\n@@ -2193,18 +2327,21 @@ build_ssa_operands (tree stmt)\n {\n   stmt_ann_t ann = get_stmt_ann (stmt);\n   \n-  /* Initially assume that the statement has no volatile operands.  */\n-  if (ann)\n-    ann->has_volatile_ops = false;\n+  /* Initially assume that the statement has no volatile operands and\n+     makes no memory references.  */\n+  ann->has_volatile_ops = false;\n+  ann->references_memory = false;\n \n   start_ssa_stmt_operands ();\n-\n   parse_ssa_operands (stmt);\n   operand_build_sort_virtual (build_vuses);\n-  operand_build_sort_virtual (build_v_may_defs);\n-  operand_build_sort_virtual (build_v_must_defs);\n-\n+  operand_build_sort_virtual (build_vdefs);\n   finalize_ssa_stmt_operands (stmt);\n+\n+  /* For added safety, assume that statements with volatile operands\n+     also reference memory.  */\n+  if (ann->has_volatile_ops)\n+    ann->references_memory = true;\n }\n \n \n@@ -2215,9 +2352,10 @@ free_ssa_operands (stmt_operands_p ops)\n {\n   ops->def_ops = NULL;\n   ops->use_ops = NULL;\n-  ops->maydef_ops = NULL;\n-  ops->mustdef_ops = NULL;\n+  ops->vdef_ops = NULL;\n   ops->vuse_ops = NULL;\n+  BITMAP_FREE (ops->loads);\n+  BITMAP_FREE (ops->stores);\n }\n \n \n@@ -2237,13 +2375,10 @@ update_stmt_operands (tree stmt)\n      _DECL.  This indicates a bug in the gimplifier.  */\n   gcc_assert (!SSA_VAR_P (stmt));\n \n-  gcc_assert (ann->modified);\n-\n   timevar_push (TV_TREE_OPS);\n \n+  gcc_assert (ann->modified);\n   build_ssa_operands (stmt);\n-\n-  /* Clear the modified bit for STMT.  */\n   ann->modified = 0;\n \n   timevar_pop (TV_TREE_OPS);\n@@ -2255,61 +2390,60 @@ update_stmt_operands (tree stmt)\n void\n copy_virtual_operands (tree dest, tree src)\n {\n-  tree t;\n-  ssa_op_iter iter, old_iter;\n-  use_operand_p use_p, u2;\n-  def_operand_p def_p, d2;\n-\n-  build_ssa_operands (dest);\n-\n-  /* Copy all the virtual fields.  */\n-  FOR_EACH_SSA_TREE_OPERAND (t, src, iter, SSA_OP_VUSE)\n-    append_vuse (t);\n-  FOR_EACH_SSA_TREE_OPERAND (t, src, iter, SSA_OP_VMAYDEF)\n-    append_v_may_def (t);\n-  FOR_EACH_SSA_TREE_OPERAND (t, src, iter, SSA_OP_VMUSTDEF)\n-    append_v_must_def (t);\n-\n-  if (VEC_length (tree, build_vuses) == 0\n-      && VEC_length (tree, build_v_may_defs) == 0\n-      && VEC_length (tree, build_v_must_defs) == 0)\n-    return;\n+  int i, n;\n+  vuse_optype_p src_vuses, dest_vuses;\n+  vdef_optype_p src_vdefs, dest_vdefs;\n+  struct vuse_optype_d vuse;\n+  struct vdef_optype_d vdef;\n+  stmt_ann_t dest_ann;\n+\n+  VDEF_OPS (dest) = NULL;\n+  VUSE_OPS (dest) = NULL;\n \n-  /* Now commit the virtual operands to this stmt.  */\n-  finalize_ssa_v_must_defs (dest);\n-  finalize_ssa_v_may_defs (dest);\n-  finalize_ssa_vuses (dest);\n+  dest_ann = get_stmt_ann (dest);\n+  BITMAP_FREE (dest_ann->operands.loads);\n+  BITMAP_FREE (dest_ann->operands.stores);\n \n-  /* Finally, set the field to the same values as then originals.  */\n-  t = op_iter_init_tree (&old_iter, src, SSA_OP_VUSE);\n-  FOR_EACH_SSA_USE_OPERAND (use_p, dest, iter, SSA_OP_VUSE)\n+  if (LOADED_SYMS (src))\n     {\n-      gcc_assert (!op_iter_done (&old_iter));\n-      SET_USE (use_p, t);\n-      t = op_iter_next_tree (&old_iter);\n+      dest_ann->operands.loads = BITMAP_ALLOC (NULL);\n+      bitmap_copy (dest_ann->operands.loads, LOADED_SYMS (src));\n     }\n-  gcc_assert (op_iter_done (&old_iter));\n \n-  op_iter_init_maydef (&old_iter, src, &u2, &d2);\n-  FOR_EACH_SSA_MAYDEF_OPERAND (def_p, use_p, dest, iter)\n+  if (STORED_SYMS (src))\n     {\n-      gcc_assert (!op_iter_done (&old_iter));\n-      SET_USE (use_p, USE_FROM_PTR (u2));\n-      SET_DEF (def_p, DEF_FROM_PTR (d2));\n-      op_iter_next_maymustdef (&u2, &d2, &old_iter);\n+      dest_ann->operands.stores = BITMAP_ALLOC (NULL);\n+      bitmap_copy (dest_ann->operands.stores, STORED_SYMS (src));\n     }\n-  gcc_assert (op_iter_done (&old_iter));\n \n-  op_iter_init_mustdef (&old_iter, src, &u2, &d2);\n-  FOR_EACH_SSA_MUSTDEF_OPERAND (def_p, use_p, dest, iter)\n+  /* Copy all the VUSE operators and corresponding operands.  */\n+  dest_vuses = &vuse;\n+  for (src_vuses = VUSE_OPS (src); src_vuses; src_vuses = src_vuses->next)\n     {\n-      gcc_assert (!op_iter_done (&old_iter));\n-      SET_USE (use_p, USE_FROM_PTR (u2));\n-      SET_DEF (def_p, DEF_FROM_PTR (d2));\n-      op_iter_next_maymustdef (&u2, &d2, &old_iter);\n+      n = VUSE_NUM (src_vuses);\n+      dest_vuses = add_vuse_op (dest, NULL_TREE, n, &dest_vuses);\n+      dest_vuses->next = NULL;\n+      for (i = 0; i < n; i++)\n+\tSET_USE (VUSE_OP_PTR (dest_vuses, i), VUSE_OP (src_vuses, i));\n+\n+      if (VUSE_OPS (dest) == NULL)\n+\tVUSE_OPS (dest) = vuse.next;\n     }\n-  gcc_assert (op_iter_done (&old_iter));\n \n+  /* Copy all the VDEF operators and corresponding operands.  */\n+  dest_vdefs = &vdef;\n+  for (src_vdefs = VDEF_OPS (src); src_vdefs; src_vdefs = src_vdefs->next)\n+    {\n+      n = VUSE_NUM (src_vdefs);\n+      dest_vdefs = add_vdef_op (dest, NULL_TREE, n, &dest_vdefs);\n+      dest_vdefs->next = NULL;\n+      VDEF_RESULT (dest_vdefs) = VDEF_RESULT (src_vdefs);\n+      for (i = 0; i < n; i++)\n+\tSET_USE (VUSE_OP_PTR (dest_vdefs, i), VUSE_OP (src_vdefs, i));\n+\n+      if (VDEF_OPS (dest) == NULL)\n+\tVDEF_OPS (dest) = vdef.next;\n+    }\n }\n \n \n@@ -2322,51 +2456,34 @@ copy_virtual_operands (tree dest, tree src)\n void\n create_ssa_artificial_load_stmt (tree new_stmt, tree old_stmt)\n {\n-  stmt_ann_t ann;\n   tree op;\n   ssa_op_iter iter;\n   use_operand_p use_p;\n-  unsigned x;\n+  unsigned i;\n \n-  ann = get_stmt_ann (new_stmt);\n+  get_stmt_ann (new_stmt);\n \n-  /* Process the stmt looking for operands.  */\n+  /* Process NEW_STMT looking for operands.  */\n   start_ssa_stmt_operands ();\n   parse_ssa_operands (new_stmt);\n \n-  for (x = 0; x < VEC_length (tree, build_vuses); x++)\n-    {\n-      tree t = VEC_index (tree, build_vuses, x);\n-      if (TREE_CODE (t) != SSA_NAME)\n-\t{\n-\t  var_ann_t ann = var_ann (t);\n-\t  ann->in_vuse_list = 0;\n-\t}\n-    }\n+  for (i = 0; VEC_iterate (tree, build_vuses, i, op); i++)\n+    if (TREE_CODE (op) != SSA_NAME)\n+      var_ann (op)->in_vuse_list = false;\n    \n-  for (x = 0; x < VEC_length (tree, build_v_may_defs); x++)\n-    {\n-      tree t = VEC_index (tree, build_v_may_defs, x);\n-      if (TREE_CODE (t) != SSA_NAME)\n-\t{\n-\t  var_ann_t ann = var_ann (t);\n-\t  ann->in_v_may_def_list = 0;\n-\t}\n-    }\n+  for (i = 0; VEC_iterate (tree, build_vuses, i, op); i++)\n+    if (TREE_CODE (op) != SSA_NAME)\n+      var_ann (op)->in_vdef_list = false;\n \n   /* Remove any virtual operands that were found.  */\n-  VEC_truncate (tree, build_v_may_defs, 0);\n-  VEC_truncate (tree, build_v_must_defs, 0);\n+  VEC_truncate (tree, build_vdefs, 0);\n   VEC_truncate (tree, build_vuses, 0);\n \n   /* For each VDEF on the original statement, we want to create a\n-     VUSE of the V_MAY_DEF result or V_MUST_DEF op on the new \n-     statement.  */\n-  FOR_EACH_SSA_TREE_OPERAND (op, old_stmt, iter, \n-\t\t\t     (SSA_OP_VMAYDEF | SSA_OP_VMUSTDEF))\n+     VUSE of the VDEF result operand on the new statement.  */\n+  FOR_EACH_SSA_TREE_OPERAND (op, old_stmt, iter, SSA_OP_VDEF)\n     append_vuse (op);\n-    \n-  /* Now build the operands for this new stmt.  */\n+\n   finalize_ssa_stmt_operands (new_stmt);\n \n   /* All uses in this fake stmt must not be in the immediate use lists.  */\n@@ -2567,7 +2684,7 @@ dump_immediate_uses_for (FILE *file, tree var)\n         fprintf (file, \"***end of stmt iterator marker***\\n\");\n       else\n \tif (!is_gimple_reg (USE_FROM_PTR (use_p)))\n-\t  print_generic_stmt (file, USE_STMT (use_p), TDF_VOPS);\n+\t  print_generic_stmt (file, USE_STMT (use_p), TDF_VOPS|TDF_MEMSYMS);\n \telse\n \t  print_generic_stmt (file, USE_STMT (use_p), TDF_SLIM);\n     }\n@@ -2649,7 +2766,7 @@ push_stmt_changes (tree *stmt_p)\n \t  bitmap_set_bit (buf->loads, DECL_UID (sym));\n \t}\n \n-      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VIRTUAL_DEFS)\n+      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VDEF)\n \t{\n \t  tree sym = TREE_CODE (op) == SSA_NAME ? SSA_NAME_VAR (op) : op;\n \t  if (buf->stores == NULL)\n@@ -2737,19 +2854,12 @@ pop_stmt_changes (tree *stmt_p)\n \t  bitmap_set_bit (loads, DECL_UID (sym));\n \t}\n \n-      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VIRTUAL_DEFS)\n+      FOR_EACH_SSA_TREE_OPERAND (op, stmt, i, SSA_OP_VDEF)\n \t{\n \t  tree sym = TREE_CODE (op) == SSA_NAME ? SSA_NAME_VAR (op) : op;\n \t  if (stores == NULL)\n \t    stores = BITMAP_ALLOC (NULL);\n \t  bitmap_set_bit (stores, DECL_UID (sym));\n-\n-\t  /* If a V_MAY_DEF turned into a V_MUST_DEF, we will keep\n-\t     referencing the same symbol, but we still need to mark it\n-\t     for renaming since the operand scanner stripped its\n-\t     SSA_NAME.  */\n-\t  if (op == sym)\n-\t    mark_sym_for_renaming (sym);\n \t}\n     }\n \n@@ -2813,3 +2923,101 @@ discard_stmt_changes (tree *stmt_p)\n   buf->stmt_p = NULL;\n   free (buf);\n }\n+\n+\n+/* Returns true if statement STMT may access memory.  */\n+\n+bool\n+stmt_references_memory_p (tree stmt)\n+{\n+  if (!gimple_ssa_operands (cfun)->ops_active || TREE_CODE (stmt) == PHI_NODE)\n+    return false;\n+\n+  return stmt_ann (stmt)->references_memory;\n+}\n+\n+\n+/* Return the memory partition tag (MPT) associated with memory\n+   symbol SYM.  From a correctness standpoint, memory partitions can\n+   be assigned in any arbitrary fashion as long as this rule is\n+   observed: Given two memory partitions MPT.i and MPT.j, they must\n+   not contain symbols in common.\n+\n+   Memory partitions are used when putting the program into Memory-SSA\n+   form.  In particular, in Memory-SSA PHI nodes are not computed for\n+   individual memory symbols.  They are computed for memory\n+   partitions.  This reduces the amount of PHI nodes in the SSA graph\n+   at the expense of precision (i.e., it makes unrelated stores affect\n+   each other).\n+   \n+   However, it is possible to increase precision by changing this\n+   partitioning scheme.  For instance, if the partitioning scheme is\n+   such that get_mpt_for is the identity function (that is,\n+   get_mpt_for (s) = s), this will result in ultimate precision at the\n+   expense of huge SSA webs.\n+\n+   At the other extreme, a partitioning scheme that groups all the\n+   symbols in the same set results in minimal SSA webs and almost\n+   total loss of precision.  */\n+\n+tree\n+get_mpt_for (tree sym)\n+{\n+  tree mpt;\n+\n+  /* Don't create a new tag unnecessarily.  */\n+  mpt = memory_partition (sym);\n+  if (mpt == NULL_TREE)\n+    {\n+      mpt = create_tag_raw (MEMORY_PARTITION_TAG, TREE_TYPE (sym), \"MPT\");\n+      TREE_ADDRESSABLE (mpt) = 0;\n+      MTAG_GLOBAL (mpt) = 1;\n+      add_referenced_var (mpt);\n+      VEC_safe_push (tree, heap, gimple_ssa_operands (cfun)->mpt_table, mpt);\n+      MPT_SYMBOLS (mpt) = BITMAP_ALLOC (NULL);\n+      set_memory_partition (sym, mpt);\n+    }\n+\n+  return mpt;\n+}\n+\n+\n+/* Dump memory partition information to FILE.  */\n+\n+void\n+dump_memory_partitions (FILE *file)\n+{\n+  unsigned i, npart;\n+  unsigned long nsyms;\n+  tree mpt;\n+\n+  fprintf (file, \"\\nMemory partitions\\n\\n\");\n+  for (i = 0, npart = 0, nsyms = 0;\n+      VEC_iterate (tree, gimple_ssa_operands (cfun)->mpt_table, i, mpt);\n+      i++)\n+    {\n+      if (mpt)\n+\t{\n+\t  bitmap syms = MPT_SYMBOLS (mpt);\n+\t  unsigned long n = bitmap_count_bits (syms);\n+\n+\t  fprintf (file, \"#%u: \", i);\n+\t  print_generic_expr (file, mpt, 0);\n+\t  fprintf (file, \": %lu elements: \", n);\n+\t  dump_decl_set (file, syms);\n+\t  npart++;\n+\t  nsyms += n;\n+\t}\n+    }\n+\n+  fprintf (file, \"\\n%u memory partitions holding %lu symbols\\n\", npart, nsyms);\n+}\n+\n+\n+/* Dump memory partition information to stderr.  */\n+\n+void\n+debug_memory_partitions (void)\n+{\n+  dump_memory_partitions (stderr);\n+}"}, {"sha": "f81e629741fc34c76dc91bf78f81f9db6693bd65", "filename": "gcc/tree-ssa-operands.h", "status": "modified", "additions": 102, "deletions": 72, "changes": 174, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-operands.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-operands.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-operands.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -50,35 +50,71 @@ struct use_optype_d\n };\n typedef struct use_optype_d *use_optype_p;\n \n-/* This represents the MAY_DEFS for a stmt.  */\n-struct maydef_optype_d\n+typedef struct vuse_element_d\n {\n-  struct maydef_optype_d *next;\n-  tree def_var;\n   tree use_var;\n   struct ssa_use_operand_d use_ptr;\n+} vuse_element_t;\n+\n+typedef struct vuse_vec_d\n+{\n+  int num_vuse;\n+  vuse_element_t uses[1];\n+} vuse_vec_t;\n+typedef struct vuse_vec_d *vuse_vec_p;\n+\n+#define VUSE_VECT_NUM_ELEM(V)\t\t(V).num_vuse\n+#define VUSE_VECT_ELEMENT_NC(V,X)\t(V).uses[(X)]\n+#define VUSE_ELEMENT_PTR_NC(V,X)\t(&(VUSE_VECT_ELEMENT_NC ((V),(X)).use_ptr))\n+#define VUSE_ELEMENT_VAR_NC(V,X)\t(VUSE_VECT_ELEMENT_NC ((V),(X)).use_var)\n+\n+#ifdef ENABLE_CHECKING\n+#define VUSE_VECT_ELEMENT(V,X)\t\t\t\t\t\t\\\n+    (gcc_assert ((X) >= 0 && (X) < VUSE_VECT_NUM_ELEM (V)),\t\t\\\n+     VUSE_VECT_ELEMENT_NC (V,X))\n+\n+#define VUSE_ELEMENT_PTR(V,X)\t\t\t\t\t\t\\\n+    (gcc_assert ((X) >= 0 && (X) < VUSE_VECT_NUM_ELEM (V)),\t\t\\\n+     VUSE_ELEMENT_PTR_NC (V, X))\n+\n+#define SET_VUSE_VECT_ELEMENT(V,X,N)\t\t\t\t\t\\\n+    (gcc_assert ((X) >= 0 && (X) < VUSE_VECT_NUM_ELEM (V)),\t\t\\\n+     VUSE_VECT_ELEMENT_NC (V,X) = (N))\n+\n+#define SET_VUSE_ELEMENT_VAR(V,X,N)\t\t\t\t\t\\\n+    (gcc_assert ((X) >= 0 && (X) < VUSE_VECT_NUM_ELEM (V)),\t\t\\\n+     VUSE_VECT_ELEMENT_NC ((V),(X)).use_var = (N))\n+\n+#define SET_VUSE_ELEMENT_PTR(V,X,N)\t\t\t\t\t\\\n+    (gcc_assert ((X) >= 0 && (X) < VUSE_VECT_NUM_ELEM (V)),\t\t\\\n+     VUSE_ELEMENT_PTR_NC (V, X) = (N))\n+#else\n+#define VUSE_VECT_ELEMENT(V,X) VUSE_VECT_ELEMENT_NC(V,X)\n+#define VUSE_ELEMENT_PTR(V,X) VUSE_ELEMENT_PTR_NC(V,X)\n+#define SET_VUSE_VECT_ELEMENT(V,X,N) VUSE_VECT_ELEMENT_NC(V,X) = (N)\n+#define SET_VUSE_ELEMENT_PTR(V,X,N) VUSE_ELEMENT_PTR_NC(V,X) = (N)\n+#define SET_VUSE_ELEMENT_VAR(V,X,N) VUSE_VECT_ELEMENT_NC ((V),(X)).use_var = (N)\n+#endif\n+\n+#define VUSE_ELEMENT_VAR(V,X)\t(VUSE_VECT_ELEMENT ((V),(X)).use_var)\n+\n+/* This represents the VDEFS for a stmt.  */\n+struct vdef_optype_d\n+{\n+  struct vdef_optype_d *next;\n+  tree def_var;\n+  vuse_vec_t usev;\n };\n-typedef struct maydef_optype_d *maydef_optype_p;\n+typedef struct vdef_optype_d *vdef_optype_p;\n \n /* This represents the VUSEs for a stmt.  */\n struct vuse_optype_d\n {\n   struct vuse_optype_d *next;\n-  tree use_var;\n-  struct ssa_use_operand_d use_ptr;\n+  vuse_vec_t usev;\n };\n typedef struct vuse_optype_d *vuse_optype_p;\n                                                                               \n-/* This represents the V_MUST_DEFS for a stmt.  */\n-struct mustdef_optype_d\n-{\n-  struct mustdef_optype_d *next;\n-  tree def_var;\n-  tree kill_var;\n-  struct ssa_use_operand_d use_ptr;\n-};\n-typedef struct mustdef_optype_d *mustdef_optype_p;\n-\n \n #define SSA_OPERAND_MEMORY_SIZE\t\t(2048 - sizeof (void *))\n                                                                               \n@@ -98,8 +134,8 @@ struct ssa_operands GTY(()) {\n    struct def_optype_d * GTY ((skip (\"\"))) free_defs;\n    struct use_optype_d * GTY ((skip (\"\"))) free_uses;\n    struct vuse_optype_d * GTY ((skip (\"\"))) free_vuses;\n-   struct maydef_optype_d * GTY ((skip (\"\"))) free_maydefs;\n-   struct mustdef_optype_d * GTY ((skip (\"\"))) free_mustdefs;\n+   struct vdef_optype_d * GTY ((skip (\"\"))) free_vdefs;\n+   VEC(tree,heap) * GTY ((skip (\"\"))) mpt_table;\n };\n \n /* This represents the operand cache for a stmt.  */\n@@ -109,10 +145,13 @@ struct stmt_operands_d\n   struct def_optype_d * def_ops;\n   struct use_optype_d * use_ops;\n                                                                               \n-  /* Virtual operands (V_MAY_DEF, VUSE, and V_MUST_DEF).  */\n-  struct maydef_optype_d * maydef_ops;\n+  /* Virtual operands (VDEF, VUSE).  */\n+  struct vdef_optype_d * vdef_ops;\n   struct vuse_optype_d * vuse_ops;\n-  struct mustdef_optype_d * mustdef_ops;\n+\n+  /* Sets of memory symbols loaded and stored.  */\n+  bitmap stores;\n+  bitmap loads;\n };\n                                                                               \n typedef struct stmt_operands_d *stmt_operands_p;\n@@ -127,27 +166,30 @@ typedef struct stmt_operands_d *stmt_operands_p;\n #define DEF_OPS(STMT)\t\t(stmt_ann (STMT)->operands.def_ops)\n #define USE_OPS(STMT)\t\t(stmt_ann (STMT)->operands.use_ops)\n #define VUSE_OPS(STMT)\t\t(stmt_ann (STMT)->operands.vuse_ops)\n-#define MAYDEF_OPS(STMT)\t(stmt_ann (STMT)->operands.maydef_ops)\n-#define MUSTDEF_OPS(STMT)\t(stmt_ann (STMT)->operands.mustdef_ops)\n+#define VDEF_OPS(STMT)\t\t(stmt_ann (STMT)->operands.vdef_ops)\n+\n+#define LOADED_SYMS(STMT)\t(stmt_ann (STMT)->operands.loads)\n+#define STORED_SYMS(STMT)\t(stmt_ann (STMT)->operands.stores)\n \n #define USE_OP_PTR(OP)\t\t(&((OP)->use_ptr))\n #define USE_OP(OP)\t\t(USE_FROM_PTR (USE_OP_PTR (OP)))\n \n #define DEF_OP_PTR(OP)\t\t((OP)->def_ptr)\n #define DEF_OP(OP)\t\t(DEF_FROM_PTR (DEF_OP_PTR (OP)))\n \n-#define VUSE_OP_PTR(OP)\t\tUSE_OP_PTR(OP)\n-#define VUSE_OP(OP)\t\t((OP)->use_var)\n-\n-#define MAYDEF_RESULT_PTR(OP)\t(&((OP)->def_var))\n-#define MAYDEF_RESULT(OP)\t((OP)->def_var)\n-#define MAYDEF_OP_PTR(OP)\tUSE_OP_PTR (OP)\n-#define MAYDEF_OP(OP)\t\t((OP)->use_var)\n+#define VUSE_OP_PTR(OP,X)\tVUSE_ELEMENT_PTR ((OP)->usev, (X)) \n+#define VUSE_OP(OP,X)\t\tVUSE_ELEMENT_VAR ((OP)->usev, (X))\n+#define SET_VUSE_OP(OP,X,N)\tSET_VUSE_ELEMENT_VAR ((OP)->usev, (X), (N))\n+#define VUSE_NUM(OP)\t\tVUSE_VECT_NUM_ELEM ((OP)->usev)\n+#define VUSE_VECT(OP)\t\t&((OP)->usev)\n \n-#define MUSTDEF_RESULT_PTR(OP)\t(&((OP)->def_var))\n-#define MUSTDEF_RESULT(OP)\t((OP)->def_var)\n-#define MUSTDEF_KILL_PTR(OP)\tUSE_OP_PTR (OP)\n-#define MUSTDEF_KILL(OP)\t((OP)->kill_var)\n+#define VDEF_RESULT_PTR(OP)\t(&((OP)->def_var))\n+#define VDEF_RESULT(OP)\t\t((OP)->def_var)\n+#define VDEF_OP_PTR(OP,X)\tVUSE_OP_PTR (OP, X)\n+#define VDEF_OP(OP,X)\t\tVUSE_OP (OP, X)\n+#define SET_VDEF_OP(OP,X,N)\tSET_VUSE_OP (OP, X, N)\n+#define VDEF_NUM(OP)\t\tVUSE_VECT_NUM_ELEM ((OP)->usev)\n+#define VDEF_VECT(OP)\t\t&((OP)->usev)\n \n #define PHI_RESULT_PTR(PHI)\tget_phi_result_ptr (PHI)\n #define PHI_RESULT(PHI)\t\tDEF_FROM_PTR (PHI_RESULT_PTR (PHI))\n@@ -164,6 +206,9 @@ typedef struct stmt_operands_d *stmt_operands_p;\n #define PHI_ARG_INDEX_FROM_USE(USE)   phi_arg_index_from_use (USE)\n \n \n+extern struct vdef_optype_d *realloc_vdef (struct vdef_optype_d *, int);\n+extern struct vuse_optype_d *realloc_vuse (struct vuse_optype_d *, int);\n+\n extern void init_ssa_operands (void);\n extern void fini_ssa_operands (void);\n extern void free_ssa_operands (stmt_operands_p);\n@@ -177,6 +222,8 @@ extern void dump_immediate_uses (FILE *file);\n extern void dump_immediate_uses_for (FILE *file, tree var);\n extern void debug_immediate_uses (void);\n extern void debug_immediate_uses_for (tree var);\n+extern void dump_decl_set (FILE *, bitmap);\n+extern void debug_decl_set (bitmap);\n \n extern bool ssa_operands_active (void);\n \n@@ -190,8 +237,9 @@ enum ssa_op_iter_type {\n   ssa_op_iter_tree,\n   ssa_op_iter_use,\n   ssa_op_iter_def,\n-  ssa_op_iter_maymustdef\n+  ssa_op_iter_vdef\n };\n+\n /* This structure is used in the operand iterator loops.  It contains the \n    items required to determine which operand is retrieved next.  During\n    optimization, this structure is scalarized, and any unused fields are \n@@ -202,38 +250,32 @@ typedef struct ssa_operand_iterator_d\n   def_optype_p defs;\n   use_optype_p uses;\n   vuse_optype_p vuses;\n-  maydef_optype_p maydefs;\n-  maydef_optype_p mayuses;\n-  mustdef_optype_p mustdefs;\n-  mustdef_optype_p mustkills;\n+  vdef_optype_p vdefs;\n+  vdef_optype_p mayuses;\n   enum ssa_op_iter_type iter_type;\n   int phi_i;\n   int num_phi;\n   tree phi_stmt;\n   bool done;\n+  int vuse_index;\n+  int mayuse_index;\n } ssa_op_iter;\n \n /* These flags are used to determine which operands are returned during \n    execution of the loop.  */\n #define SSA_OP_USE\t\t0x01\t/* Real USE operands.  */\n #define SSA_OP_DEF\t\t0x02\t/* Real DEF operands.  */\n #define SSA_OP_VUSE\t\t0x04\t/* VUSE operands.  */\n-#define SSA_OP_VMAYUSE\t\t0x08\t/* USE portion of V_MAY_DEFS.  */\n-#define SSA_OP_VMAYDEF\t\t0x10\t/* DEF portion of V_MAY_DEFS.  */\n-#define SSA_OP_VMUSTDEF\t\t0x20\t/* V_MUST_DEF definitions.  */\n-#define SSA_OP_VMUSTKILL     \t0x40    /* V_MUST_DEF kills.  */\n+#define SSA_OP_VMAYUSE\t\t0x08\t/* USE portion of VDEFS.  */\n+#define SSA_OP_VDEF\t\t0x10\t/* DEF portion of VDEFS.  */\n \n /* These are commonly grouped operand flags.  */\n #define SSA_OP_VIRTUAL_USES\t(SSA_OP_VUSE | SSA_OP_VMAYUSE)\n-#define SSA_OP_VIRTUAL_DEFS\t(SSA_OP_VMAYDEF | SSA_OP_VMUSTDEF)\n-#define SSA_OP_VIRTUAL_KILLS    (SSA_OP_VMUSTKILL)\n-#define SSA_OP_ALL_VIRTUALS     (SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS \\\n-\t\t\t\t | SSA_OP_VIRTUAL_DEFS)\n+#define SSA_OP_VIRTUAL_DEFS\t(SSA_OP_VDEF)\n+#define SSA_OP_ALL_VIRTUALS     (SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_DEFS)\n #define SSA_OP_ALL_USES\t\t(SSA_OP_VIRTUAL_USES | SSA_OP_USE)\n #define SSA_OP_ALL_DEFS\t\t(SSA_OP_VIRTUAL_DEFS | SSA_OP_DEF)\n-#define SSA_OP_ALL_KILLS        (SSA_OP_VIRTUAL_KILLS)\n-#define SSA_OP_ALL_OPERANDS\t(SSA_OP_ALL_USES | SSA_OP_ALL_DEFS\t\\\n-\t\t\t\t | SSA_OP_ALL_KILLS)\n+#define SSA_OP_ALL_OPERANDS\t(SSA_OP_ALL_USES | SSA_OP_ALL_DEFS)\n \n /* This macro executes a loop over the operands of STMT specified in FLAG, \n    returning each operand as a 'tree' in the variable TREEVAR.  ITER is an\n@@ -259,29 +301,13 @@ typedef struct ssa_operand_iterator_d\n        !op_iter_done (&(ITER));\t\t\t\t\t\\\n        DEFVAR = op_iter_next_def (&(ITER)))\n \n-/* This macro executes a loop over the V_MAY_DEF operands of STMT.  The def\n-   and use for each V_MAY_DEF is returned in DEFVAR and USEVAR. \n-   ITER is an ssa_op_iter structure used to control the loop.  */\n-#define FOR_EACH_SSA_MAYDEF_OPERAND(DEFVAR, USEVAR, STMT, ITER)\t\\\n-  for (op_iter_init_maydef (&(ITER), STMT, &(USEVAR), &(DEFVAR));\t\\\n-       !op_iter_done (&(ITER));\t\t\t\t\t\\\n-       op_iter_next_maymustdef (&(USEVAR), &(DEFVAR), &(ITER)))\n-\n-/* This macro executes a loop over the V_MUST_DEF operands of STMT.  The def\n-   and kill for each V_MUST_DEF is returned in DEFVAR and KILLVAR. \n-   ITER is an ssa_op_iter structure used to control the loop.  */\n-#define FOR_EACH_SSA_MUSTDEF_OPERAND(DEFVAR, KILLVAR, STMT, ITER)\t\\\n-  for (op_iter_init_mustdef (&(ITER), STMT, &(KILLVAR), &(DEFVAR));\t\\\n-       !op_iter_done (&(ITER));\t\t\t\t\t\\\n-       op_iter_next_maymustdef (&(KILLVAR), &(DEFVAR), &(ITER)))\n-\n-/* This macro executes a loop over the V_{MUST,MAY}_DEF of STMT.  The def\n-   and kill for each V_{MUST,MAY}_DEF is returned in DEFVAR and KILLVAR. \n+/* This macro executes a loop over the VDEF operands of STMT.  The def\n+   and use for each VDEF is returned in DEFVAR and USEVAR. \n    ITER is an ssa_op_iter structure used to control the loop.  */\n-#define FOR_EACH_SSA_MUST_AND_MAY_DEF_OPERAND(DEFVAR, KILLVAR, STMT, ITER)\\\n-  for (op_iter_init_must_and_may_def (&(ITER), STMT, &(KILLVAR), &(DEFVAR));\\\n+#define FOR_EACH_SSA_VDEF_OPERAND(DEFVAR, USEVAR, STMT, ITER)\t\\\n+  for (op_iter_init_vdef (&(ITER), STMT, &(USEVAR), &(DEFVAR));\t\\\n        !op_iter_done (&(ITER));\t\t\t\t\t\\\n-       op_iter_next_maymustdef (&(KILLVAR), &(DEFVAR), &(ITER)))\n+       op_iter_next_vdef (&(USEVAR), &(DEFVAR), &(ITER)))\n \n /* This macro will execute a loop over all the arguments of a PHI which\n    match FLAGS.   A use_operand_p is always returned via USEVAR.  FLAGS\n@@ -334,4 +360,8 @@ typedef struct ssa_operand_iterator_d\n /* This macro counts the number of operands in STMT matching FLAGS.  */\n #define NUM_SSA_OPERANDS(STMT, FLAGS)\tnum_ssa_operands (STMT, FLAGS)\n \n+extern tree get_mpt_for (tree);\n+extern void dump_memory_partitions (FILE *);\n+extern void debug_memory_partitions (void);\n+\n #endif  /* GCC_TREE_SSA_OPERANDS_H  */"}, {"sha": "c4a01839b185214104f503712a6553371d1e387a", "filename": "gcc/tree-ssa-pre.c", "status": "modified", "additions": 6, "deletions": 9, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-pre.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-pre.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-pre.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -2177,16 +2177,13 @@ compute_rvuse_and_antic_safe (void)\n \t{\n \t  tree stmt = bsi_stmt (bsi);\n \n-\t  if (first_store_uid[bb->index] == 0\n-\t      && !ZERO_SSA_OPERANDS (stmt, SSA_OP_VMAYUSE | SSA_OP_VMAYDEF\n-\t\t\t\t     | SSA_OP_VMUSTDEF | SSA_OP_VMUSTKILL))\n+\t  if (first_store_uid[bb->index] == 0 \n+\t      && !ZERO_SSA_OPERANDS (stmt, SSA_OP_VMAYUSE | SSA_OP_VDEF))\n \t    {\n \t      first_store_uid[bb->index] = stmt_ann (stmt)->uid;\n \t    }\n \n-\n-\t  FOR_EACH_SSA_USE_OPERAND (usep, stmt, iter, SSA_OP_VIRTUAL_KILLS\n-\t\t\t\t    | SSA_OP_VMAYUSE)\n+\t  FOR_EACH_SSA_USE_OPERAND (usep, stmt, iter, SSA_OP_VMAYUSE)\n \t    {\n \t      tree use = USE_FROM_PTR (usep);\n \t      bitmap repbit = get_representative (vuse_names,\n@@ -4004,14 +4001,14 @@ remove_dead_inserted_code (void)\n       else\n \t{\n \t  /* Propagate through the operands.  Examine all the USE, VUSE and\n-\t     V_MAY_DEF operands in this statement.  Mark all the statements\n+\t     VDEF operands in this statement.  Mark all the statements \n \t     which feed this statement's uses as necessary.  */\n \t  ssa_op_iter iter;\n \t  tree use;\n \n-\t  /* The operands of V_MAY_DEF expressions are also needed as they\n+\t  /* The operands of VDEF expressions are also needed as they\n \t     represent potential definitions that may reach this\n-\t     statement (V_MAY_DEF operands allow us to follow def-def\n+\t     statement (VDEF operands allow us to follow def-def \n \t     links).  */\n \n \t  FOR_EACH_SSA_TREE_OPERAND (use, t, iter, SSA_OP_ALL_USES)"}, {"sha": "68c1b51ea1612d1baee3073916f334fd344cd8dc", "filename": "gcc/tree-ssa-propagate.c", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-propagate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-propagate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-propagate.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -749,7 +749,7 @@ ssa_propagate (ssa_prop_visit_stmt_fn visit_stmt,\n }\n \n \n-/* Return the first V_MAY_DEF or V_MUST_DEF operand for STMT.  */\n+/* Return the first VDEF operand for STMT.  */\n \n tree\n first_vdef (tree stmt)\n@@ -778,7 +778,7 @@ stmt_makes_single_load (tree stmt)\n   if (TREE_CODE (stmt) != GIMPLE_MODIFY_STMT)\n     return false;\n \n-  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VMAYDEF|SSA_OP_VUSE))\n+  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF|SSA_OP_VUSE))\n     return false;\n \n   rhs = GIMPLE_STMT_OPERAND (stmt, 1);\n@@ -803,7 +803,7 @@ stmt_makes_single_store (tree stmt)\n   if (TREE_CODE (stmt) != GIMPLE_MODIFY_STMT)\n     return false;\n \n-  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VMAYDEF|SSA_OP_VMUSTDEF))\n+  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF))\n     return false;\n \n   lhs = GIMPLE_STMT_OPERAND (stmt, 0);\n@@ -906,7 +906,7 @@ replace_uses_in (tree stmt, bool *replaced_addresses_p,\n       GIMPLE register, then we are making a copy/constant propagation\n       from a memory store.  For instance,\n \n-      \t# a_3 = V_MAY_DEF <a_2>\n+      \t# a_3 = VDEF <a_2>\n \ta.b = x_1;\n \t...\n  \t# VUSE <a_3>\n@@ -917,8 +917,8 @@ replace_uses_in (tree stmt, bool *replaced_addresses_p,\n       the VUSE(s) that we are replacing.  Otherwise, we may do the\n       wrong replacement:\n \n-      \t# a_3 = V_MAY_DEF <a_2>\n-\t# b_5 = V_MAY_DEF <b_4>\n+      \t# a_3 = VDEF <a_2>\n+\t# b_5 = VDEF <b_4>\n \t*p = 10;\n \t...\n \t# VUSE <b_5>\n@@ -938,10 +938,10 @@ replace_uses_in (tree stmt, bool *replaced_addresses_p,\n       stored in different locations:\n \n      \t\tif (...)\n-\t\t  # a_3 = V_MAY_DEF <a_2>\n+\t\t  # a_3 = VDEF <a_2>\n \t\t  a.b = 3;\n \t\telse\n-\t\t  # a_4 = V_MAY_DEF <a_2>\n+\t\t  # a_4 = VDEF <a_2>\n \t\t  a.c = 3;\n \t\t# a_5 = PHI <a_3, a_4>\n "}, {"sha": "b30c23d65f8c6e224efbfa61e33b544515f8f8e1", "filename": "gcc/tree-ssa-sink.c", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-sink.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-sink.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sink.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -131,7 +131,7 @@ all_immediate_uses_same_place (tree stmt)\n   return true;\n }\n \n-/* Some global stores don't necessarily have V_MAY_DEF's of global variables,\n+/* Some global stores don't necessarily have VDEF's of global variables,\n    but we still must avoid moving them around.  */\n \n bool\n@@ -156,7 +156,7 @@ is_hidden_global_store (tree stmt)\n \t\t  int x;\n \t\t  p_1 = (i_2 > 3) ? &x : p;\n \n-\t\t  # x_4 = V_MAY_DEF <x_3>\n+\t\t  # x_4 = VDEF <x_3>\n \t\t  *p_1 = 5;\n \n \t\t  return 2;\n@@ -194,7 +194,7 @@ is_hidden_global_store (tree stmt)\n \t  tree ptr = TREE_OPERAND (lhs, 0);\n \t  struct ptr_info_def *pi = SSA_NAME_PTR_INFO (ptr);\n \t  tree nmt = (pi) ? pi->name_mem_tag : NULL_TREE;\n-\t  tree smt = var_ann (SSA_NAME_VAR (ptr))->symbol_mem_tag;\n+\t  tree smt = symbol_mem_tag (SSA_NAME_VAR (ptr));\n \n \t  /* If either the name tag or the symbol tag for PTR is a\n \t     global variable, then the store is necessary.  */\n@@ -207,6 +207,7 @@ is_hidden_global_store (tree stmt)\n       else\n \tgcc_unreachable ();\n     }\n+\n   return false;\n }\n \n@@ -402,7 +403,7 @@ statement_sink_location (tree stmt, basic_block frombb)\n   /* This will happen when you have\n      a_3 = PHI <a_13, a_26>\n        \n-     a_26 = V_MAY_DEF <a_3> \n+     a_26 = VDEF <a_3> \n \n      If the use is a phi, and is in the same bb as the def, \n      we can't sink it.  */"}, {"sha": "8ef421722c9c96eaba9af7cc2c39ec8637a46c9b", "filename": "gcc/tree-ssa-structalias.c", "status": "modified", "additions": 18, "deletions": 31, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-structalias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-structalias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-structalias.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -52,6 +52,7 @@ Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA\n #include \"tree-ssa-structalias.h\"\n #include \"cgraph.h\"\n #include \"alias.h\"\n+#include \"pointer-set.h\"\n \n /* The idea behind this analyzer is to generate set constraints from the\n    program, then solve the resulting constraints in order to generate the\n@@ -285,8 +286,8 @@ DEF_VEC_P(varinfo_t);\n \n DEF_VEC_ALLOC_P(varinfo_t, heap);\n \n-/* Table of variable info structures for constraint variables.  Indexed directly\n-   by variable info id.  */\n+/* Table of variable info structures for constraint variables.\n+   Indexed directly by variable info id.  */\n static VEC(varinfo_t,heap) *varmap;\n \n /* Return the varmap element N */\n@@ -1840,7 +1841,7 @@ get_constraint_exp_from_ssa_var (tree t)\n      decl.  */\n   if (TREE_CODE (t) == SSA_NAME\n       && TREE_CODE (SSA_NAME_VAR (t)) == PARM_DECL\n-      && gimple_default_def (cfun, SSA_NAME_VAR (t)) == t)\n+      && SSA_NAME_IS_DEFAULT_DEF (t))\n     return get_constraint_exp_from_ssa_var (SSA_NAME_VAR (t));\n \n   cexpr.type = SCALAR;\n@@ -2641,7 +2642,6 @@ update_alias_info (tree stmt, struct alias_info *ai)\n   use_operand_p use_p;\n   ssa_op_iter iter;\n   enum escape_type stmt_escape_type = is_escape_site (stmt);\n-  tree op;\n \n   if (stmt_escape_type == ESCAPE_TO_CALL\n       || stmt_escape_type == ESCAPE_TO_PURE_CONST)\n@@ -2715,7 +2715,7 @@ update_alias_info (tree stmt, struct alias_info *ai)\n       var = SSA_NAME_VAR (op);\n       v_ann = var_ann (var);\n \n-      /* The base variable of an ssa name must be a GIMPLE register, and thus\n+      /* The base variable of an SSA name must be a GIMPLE register, and thus\n \t it cannot be aliased.  */\n       gcc_assert (!may_be_aliased (var));\n \n@@ -2751,7 +2751,7 @@ update_alias_info (tree stmt, struct alias_info *ai)\n \t So, if the original code had no other dereferences of PTR,\n \t the aliaser will not create memory tags for it, and when\n \t &PTR->FLD gets propagated to INDIRECT_REF expressions, the\n-\t memory operations will receive no V_MAY_DEF/VUSE operands.\n+\t memory operations will receive no VDEF/VUSE operands.\n \n \t One solution would be to have count_uses_and_derefs consider\n \t &PTR->FLD a dereference of PTR.  But that is wrong, since it\n@@ -2784,17 +2784,13 @@ update_alias_info (tree stmt, struct alias_info *ai)\n \t     all the variables OP points to.  */\n \t  pi->is_dereferenced = 1;\n \n-\t  /* Keep track of how many time we've dereferenced each\n-\t     pointer.  */\n-\t  NUM_REFERENCES_INC (v_ann);\n-\n \t  /* If this is a store operation, mark OP as being\n \t     dereferenced to store, otherwise mark it as being\n \t     dereferenced to load.  */\n \t  if (is_store)\n-\t    bitmap_set_bit (ai->dereferenced_ptrs_store, DECL_UID (var));\n+\t    pointer_set_insert (ai->dereferenced_ptrs_store, var);\n \t  else\n-\t    bitmap_set_bit (ai->dereferenced_ptrs_load, DECL_UID (var));\n+\t    pointer_set_insert (ai->dereferenced_ptrs_load, var);\n \t}\n \n       if (stmt_escape_type != NO_ESCAPE && num_derefs < num_uses)\n@@ -2812,7 +2808,7 @@ update_alias_info (tree stmt, struct alias_info *ai)\n \t  if (get_call_expr_in (stmt)\n \t      || stmt_escape_type == ESCAPE_STORED_IN_GLOBAL)\n \t    {\n-\t      bitmap_set_bit (ai->dereferenced_ptrs_store, DECL_UID (var));\n+\t      pointer_set_insert (ai->dereferenced_ptrs_store, var);\n \t      pi->is_dereferenced = 1;\n \t    }\n \t}\n@@ -2821,24 +2817,14 @@ update_alias_info (tree stmt, struct alias_info *ai)\n   if (TREE_CODE (stmt) == PHI_NODE)\n     return;\n \n-  /* Update reference counter for definitions to any\n-     potentially aliased variable.  This is used in the alias\n-     grouping heuristics.  */\n-  FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_DEF)\n+  /* Mark stored variables in STMT as being written to and update the\n+     reference counter for potentially aliased symbols in STMT.  */\n+  if (stmt_references_memory_p (stmt) && STORED_SYMS (stmt))\n     {\n-      tree var = SSA_NAME_VAR (op);\n-      var_ann_t ann = var_ann (var);\n-      bitmap_set_bit (ai->written_vars, DECL_UID (var));\n-      if (may_be_aliased (var))\n-\tNUM_REFERENCES_INC (ann);\n-\n-    }\n-\n-  /* Mark variables in V_MAY_DEF operands as being written to.  */\n-  FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_VIRTUAL_DEFS)\n-    {\n-      tree var = DECL_P (op) ? op : SSA_NAME_VAR (op);\n-      bitmap_set_bit (ai->written_vars, DECL_UID (var));\n+      unsigned i;\n+      bitmap_iterator bi;\n+      EXECUTE_IF_SET_IN_BITMAP (STORED_SYMS (stmt), 0, i, bi)\n+\tpointer_set_insert (ai->written_vars, referenced_var (i));\n     }\n }\n \n@@ -3992,7 +3978,7 @@ find_what_p_points_to (tree p)\n      decl.  */\n   if (TREE_CODE (p) == SSA_NAME\n       && TREE_CODE (SSA_NAME_VAR (p)) == PARM_DECL\n-      && gimple_default_def (cfun, SSA_NAME_VAR (p)) == p)\n+      && SSA_NAME_IS_DEFAULT_DEF (p))\n     lookup_p = SSA_NAME_VAR (p);\n \n   if (lookup_id_for_tree (lookup_p, &id))\n@@ -4286,6 +4272,7 @@ compute_points_to_sets (struct alias_info *ai)\n \t  tree stmt = bsi_stmt (bsi);\n \n \t  find_func_aliases (stmt);\n+\n \t  /* Update various related attributes like escaped\n \t     addresses, pointer dereferences for loads and stores.\n \t     This is used when creating name tags and alias"}, {"sha": "20b334cd86e7dd3db9be9fe7360faa3742813b3b", "filename": "gcc/tree-ssa-structalias.h", "status": "modified", "additions": 5, "deletions": 16, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-structalias.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-structalias.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-structalias.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -55,31 +55,20 @@ struct alias_info\n   /* Number of const/pure function calls found in the program.  */\n   size_t num_pure_const_calls_found;\n \n-  /* Total number of virtual operands that will be needed to represent\n-     all the aliases of all the pointers found in the program.  */\n-  long total_alias_vops;\n-\n-  /* Variables that have been written to.  */\n-  bitmap written_vars;\n+  /* Variables that have been written to directly (i.e., not through a\n+     pointer dereference).  */\n+  struct pointer_set_t *written_vars;\n \n   /* Pointers that have been used in an indirect store operation.  */\n-  bitmap dereferenced_ptrs_store;\n+  struct pointer_set_t *dereferenced_ptrs_store;\n \n   /* Pointers that have been used in an indirect load operation.  */\n-  bitmap dereferenced_ptrs_load;\n+  struct pointer_set_t *dereferenced_ptrs_load;\n \n   /* Memory tag for all the PTR_IS_REF_ALL pointers.  */\n   tree ref_all_symbol_mem_tag;\n };\n \n-/* Keep track of how many times each pointer has been dereferenced in\n-   the program using the aux variable.  This is used by the alias\n-   grouping heuristic in compute_flow_insensitive_aliasing.  */\n-#define NUM_REFERENCES(ANN) ((size_t)((ANN)->common.aux))\n-#define NUM_REFERENCES_CLEAR(ANN) ((ANN)->common.aux) = 0\n-#define NUM_REFERENCES_INC(ANN) (ANN)->common.aux = (void*) (((size_t)((ANN)->common.aux)) + 1)\n-#define NUM_REFERENCES_SET(ANN, VAL) (ANN)->common.aux = (void*) ((void *)(VAL))\n-\n /* In tree-ssa-alias.c.  */\n enum escape_type is_escape_site (tree);\n "}, {"sha": "513fbda12b2e47c3910b38878cbb6b5229c13a38", "filename": "gcc/tree-ssa-ter.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-ter.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa-ter.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ter.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -167,7 +167,7 @@ typedef struct temp_expr_table_d\n   int *num_in_part;\t\t\t/* # of ssa_names in a partition.  */\n } *temp_expr_table_p;\n \n-/* Used to indicate a dependency on V_MAY_DEFs.  */\n+/* Used to indicate a dependency on VDEFs.  */\n #define VIRTUAL_PARTITION(table)\t(table->virtual_partition)\n \n #ifdef ENABLE_CHECKING\n@@ -384,8 +384,8 @@ is_replaceable_p (tree stmt)\n   if (TREE_CODE (use_stmt) == PHI_NODE)\n     return false;\n \n-  /* There must be no V_MAY_DEFS or V_MUST_DEFS.  */\n-  if (!(ZERO_SSA_OPERANDS (stmt, (SSA_OP_VMAYDEF | SSA_OP_VMUSTDEF))))\n+  /* There must be no VDEFs.  */\n+  if (!(ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF)))\n     return false;\n \n   /* Float expressions must go through memory if float-store is on.  */"}, {"sha": "8f34ce2b7fe12ec21ec71d0e4a5b0f55ee27eda1", "filename": "gcc/tree-ssa.c", "status": "modified", "additions": 91, "deletions": 54, "changes": 145, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -76,7 +76,7 @@ ssa_redirect_edge (edge e, basic_block dest)\n   return e;\n }\n \n-/* Add PHI arguments queued in PENDINT_STMT list on edge E to edge\n+/* Add PHI arguments queued in PENDING_STMT list on edge E to edge\n    E->dest.  */\n \n void\n@@ -143,6 +143,13 @@ verify_ssa_name (tree ssa_name, bool is_virtual)\n       return true;\n     }\n \n+  if (SSA_NAME_IS_DEFAULT_DEF (ssa_name)\n+      && !IS_EMPTY_STMT (SSA_NAME_DEF_STMT (ssa_name)))\n+    {\n+      error (\"found a default name with a non-empty defining statement\");\n+      return true;\n+    }\n+\n   return false;\n }\n \n@@ -156,8 +163,7 @@ verify_ssa_name (tree ssa_name, bool is_virtual)\n       it means that the block in that array slot contains the\n       definition of SSA_NAME.\n \n-   IS_VIRTUAL is true if SSA_NAME is created by a V_MAY_DEF or a\n-      V_MUST_DEF.  */\n+   IS_VIRTUAL is true if SSA_NAME is created by a VDEF.  */\n \n static bool\n verify_def (basic_block bb, basic_block *definition_block, tree ssa_name,\n@@ -208,30 +214,24 @@ verify_def (basic_block bb, basic_block *definition_block, tree ssa_name,\n       is flowing through an abnormal edge (only used when checking PHI\n       arguments).\n \n-   IS_VIRTUAL is true if SSA_NAME is created by a V_MAY_DEF or a\n-      V_MUST_DEF.\n-   \n    If NAMES_DEFINED_IN_BB is not NULL, it contains a bitmap of ssa names\n      that are defined before STMT in basic block BB.  */\n \n static bool\n verify_use (basic_block bb, basic_block def_bb, use_operand_p use_p,\n-\t    tree stmt, bool check_abnormal, bool is_virtual,\n-\t    bitmap names_defined_in_bb)\n+\t    tree stmt, bool check_abnormal, bitmap names_defined_in_bb)\n {\n   bool err = false;\n   tree ssa_name = USE_FROM_PTR (use_p);\n \n-  err = verify_ssa_name (ssa_name, is_virtual);\n-\n   if (!TREE_VISITED (ssa_name))\n     if (verify_imm_links (stderr, ssa_name))\n       err = true;\n \n   TREE_VISITED (ssa_name) = 1;\n \n   if (IS_EMPTY_STMT (SSA_NAME_DEF_STMT (ssa_name))\n-      && gimple_default_def (cfun, SSA_NAME_VAR (ssa_name)) == ssa_name)\n+      && SSA_NAME_IS_DEFAULT_DEF (ssa_name))\n     ; /* Default definitions have empty statements.  Nothing to do.  */\n   else if (!def_bb)\n     {\n@@ -296,9 +296,10 @@ verify_use (basic_block bb, basic_block def_bb, use_operand_p use_p,\n /* Return true if any of the arguments for PHI node PHI at block BB is\n    malformed.\n \n-   DEFINITION_BLOCK is an array of basic blocks indexed by SSA_NAME version\n-      numbers.  If DEFINITION_BLOCK[SSA_NAME_VERSION] is set, it means that the\n-      block in that array slot contains the definition of SSA_NAME.  */\n+   DEFINITION_BLOCK is an array of basic blocks indexed by SSA_NAME\n+      version numbers.  If DEFINITION_BLOCK[SSA_NAME_VERSION] is set,\n+      it means that the block in that array slot contains the\n+      definition of SSA_NAME.  */\n \n static bool\n verify_phi_args (tree phi, basic_block bb, basic_block *definition_block)\n@@ -319,7 +320,6 @@ verify_phi_args (tree phi, basic_block bb, basic_block *definition_block)\n       use_operand_p op_p = PHI_ARG_DEF_PTR (phi, i);\n       tree op = USE_FROM_PTR (op_p);\n \n-\n       e = EDGE_PRED (bb, i);\n \n       if (op == NULL_TREE)\n@@ -338,10 +338,11 @@ verify_phi_args (tree phi, basic_block bb, basic_block *definition_block)\n \t}\n \n       if (TREE_CODE (op) == SSA_NAME)\n-\terr = verify_use (e->src, definition_block[SSA_NAME_VERSION (op)], op_p,\n-\t\t\t  phi, e->flags & EDGE_ABNORMAL,\n-\t\t\t  !is_gimple_reg (PHI_RESULT (phi)),\n-\t\t\t  NULL);\n+\t{\n+\t  err = verify_ssa_name (op, !is_gimple_reg (PHI_RESULT (phi)));\n+\t  err |= verify_use (e->src, definition_block[SSA_NAME_VERSION (op)],\n+\t\t\t     op_p, phi, e->flags & EDGE_ABNORMAL, NULL);\n+\t}\n \n       if (e->dest != bb)\n \t{\n@@ -362,7 +363,7 @@ verify_phi_args (tree phi, basic_block bb, basic_block *definition_block)\n   if (err)\n     {\n       fprintf (stderr, \"for PHI node\\n\");\n-      print_generic_stmt (stderr, phi, TDF_VOPS);\n+      print_generic_stmt (stderr, phi, TDF_VOPS|TDF_MEMSYMS);\n     }\n \n \n@@ -391,7 +392,8 @@ verify_flow_insensitive_alias_info (void)\n \t{\n \t  bitmap_set_bit (visited, DECL_UID (alias));\n \n-\t  if (!may_be_aliased (alias))\n+\t  if (TREE_CODE (alias) != MEMORY_PARTITION_TAG\n+\t      && !may_be_aliased (alias))\n \t    {\n \t      error (\"non-addressable variable inside an alias set\");\n \t      debug_variable (alias);\n@@ -407,9 +409,11 @@ verify_flow_insensitive_alias_info (void)\n \n       if (!MTAG_P (var)\n \t  && ann->is_aliased\n+\t  && memory_partition (var) == NULL_TREE\n \t  && !bitmap_bit_p (visited, DECL_UID (var)))\n \t{\n-\t  error (\"addressable variable that is aliased but is not in any alias set\");\n+\t  error (\"addressable variable that is aliased but is not in any \"\n+\t         \"alias set\");\n \t  goto err;\n \t}\n     }\n@@ -472,12 +476,17 @@ verify_flow_sensitive_alias_info (void)\n \t  goto err;\n \t}\n \n-      if (pi->value_escapes_p\n-\t  && pi->name_mem_tag\n-\t  && !is_call_clobbered (pi->name_mem_tag))\n+      if (pi->value_escapes_p && pi->name_mem_tag)\n \t{\n-\t  error (\"pointer escapes but its name tag is not call-clobbered\");\n-\t  goto err;\n+\t  tree t = memory_partition (pi->name_mem_tag);\n+\t  if (t == NULL_TREE)\n+\t    t = pi->name_mem_tag;\n+\t  \n+\t  if (!is_call_clobbered (t))\n+\t    {\n+\t      error (\"pointer escapes but its name tag is not call-clobbered\");\n+\t      goto err;\n+\t    }\n \t}\n     }\n \n@@ -488,7 +497,9 @@ verify_flow_sensitive_alias_info (void)\n   internal_error (\"verify_flow_sensitive_alias_info failed\");\n }\n \n+\n /* Verify the consistency of call clobbering information.  */\n+\n static void\n verify_call_clobbering (void)\n {\n@@ -505,23 +516,38 @@ verify_call_clobbering (void)\n   EXECUTE_IF_SET_IN_BITMAP (gimple_call_clobbered_vars (cfun), 0, i, bi)\n     {\n       var = referenced_var (i);\n+\n+      if (memory_partition (var))\n+\tvar = memory_partition (var);\n+\n       if (!MTAG_P (var) && !DECL_CALL_CLOBBERED (var))\n \t{\n-\t  error (\"variable in call_clobbered_vars but not marked DECL_CALL_CLOBBERED\");\n+\t  error (\"variable in call_clobbered_vars but not marked \"\n+\t         \"DECL_CALL_CLOBBERED\");\n \t  debug_variable (var);\n \t  goto err;\n \t}\n     }\n+\n   FOR_EACH_REFERENCED_VAR (var, rvi)\n     {\n-      if (!MTAG_P (var) && DECL_CALL_CLOBBERED (var)\n+      if (is_gimple_reg (var))\n+\tcontinue;\n+\n+      if (memory_partition (var))\n+\tvar = memory_partition (var);\n+\n+      if (!MTAG_P (var)\n+\t  && DECL_CALL_CLOBBERED (var)\n \t  && !bitmap_bit_p (gimple_call_clobbered_vars (cfun), DECL_UID (var)))\n \t{\n-\t  error (\"variable marked DECL_CALL_CLOBBERED but not in call_clobbered_vars bitmap.\");\n+\t  error (\"variable marked DECL_CALL_CLOBBERED but not in \"\n+\t         \"call_clobbered_vars bitmap.\");\n \t  debug_variable (var);\n \t  goto err;\n \t}\n     }\n+\n   return;\n \n  err:\n@@ -606,6 +632,7 @@ verify_ssa (bool check_modified_stmt)\n \t{\n \t  if (verify_phi_args (phi, bb, definition_block))\n \t    goto err;\n+\n \t  bitmap_set_bit (names_defined_in_bb,\n \t\t\t  SSA_NAME_VERSION (PHI_RESULT (phi)));\n \t}\n@@ -618,7 +645,7 @@ verify_ssa (bool check_modified_stmt)\n \n \t  if (check_modified_stmt && stmt_modified_p (stmt))\n \t    {\n-\t      error (\"stmt (%p) marked modified after optimization pass : \",\n+\t      error (\"stmt (%p) marked modified after optimization pass: \",\n \t\t     (void *)stmt);\n \t      print_generic_stmt (stderr, stmt, TDF_VOPS);\n \t      goto err;\n@@ -633,23 +660,42 @@ verify_ssa (bool check_modified_stmt)\n \t      base_address = get_base_address (lhs);\n \n \t      if (base_address\n+\t\t  && gimple_aliases_computed_p (cfun)\n \t\t  && SSA_VAR_P (base_address)\n-\t\t  && ZERO_SSA_OPERANDS (stmt, SSA_OP_VMAYDEF|SSA_OP_VMUSTDEF))\n+\t\t  && !stmt_ann (stmt)->has_volatile_ops\n+\t\t  && ZERO_SSA_OPERANDS (stmt, SSA_OP_VDEF))\n \t\t{\n-\t\t  error (\"statement makes a memory store, but has no \"\n-\t\t\t \"V_MAY_DEFS nor V_MUST_DEFS\");\n+\t\t  error (\"statement makes a memory store, but has no VDEFS\");\n \t\t  print_generic_stmt (stderr, stmt, TDF_VOPS);\n \t\t  goto err;\n \t\t}\n \t    }\n \n-\t  FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter,\n-\t                            SSA_OP_ALL_USES | SSA_OP_ALL_KILLS)\n+\t  FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_ALL_VIRTUALS)\n+\t    {\n+\t      if (verify_ssa_name (op, true))\n+\t\t{\n+\t\t  error (\"in statement\");\n+\t\t  print_generic_stmt (stderr, stmt, TDF_VOPS|TDF_MEMSYMS);\n+\t\t  goto err;\n+\t\t}\n+\t    }\n+\n+\t  FOR_EACH_SSA_TREE_OPERAND (op, stmt, iter, SSA_OP_USE|SSA_OP_DEF)\n+\t    {\n+\t      if (verify_ssa_name (op, false))\n+\t\t{\n+\t\t  error (\"in statement\");\n+\t\t  print_generic_stmt (stderr, stmt, TDF_VOPS|TDF_MEMSYMS);\n+\t\t  goto err;\n+\t\t}\n+\t    }\n+\n+\t  FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_USE|SSA_OP_VUSE)\n \t    {\n \t      op = USE_FROM_PTR (use_p);\n \t      if (verify_use (bb, definition_block[SSA_NAME_VERSION (op)],\n-\t\t\t      use_p, stmt, false, !is_gimple_reg (op),\n-\t\t\t      names_defined_in_bb))\n+\t\t\t      use_p, stmt, false, names_defined_in_bb))\n \t\tgoto err;\n \t    }\n \n@@ -661,7 +707,8 @@ verify_ssa (bool check_modified_stmt)\n     }\n \n   /* Finally, verify alias information.  */\n-  verify_alias_info ();\n+  if (gimple_aliases_computed_p (cfun))\n+    verify_alias_info ();\n \n   free (definition_block);\n \n@@ -774,6 +821,7 @@ delete_tree_ssa (void)\n   cfun->gimple_df->addressable_vars = NULL;\n   cfun->gimple_df->modified_noreturn_calls = NULL;\n   cfun->gimple_df->aliases_computed_p = false;\n+\n   delete_alias_heapvars ();\n   gcc_assert (!need_ssa_update_p ());\n }\n@@ -882,18 +930,6 @@ tree_ssa_useless_type_conversion (tree expr)\n   return false;\n }\n \n-/* Returns true if statement STMT may read memory.  */\n-\n-bool\n-stmt_references_memory_p (tree stmt)\n-{\n-  stmt_ann_t ann = stmt_ann (stmt);\n-\n-  if (ann->has_volatile_ops)\n-    return true;\n-\n-  return (!ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS));\n-}\n \n /* Internal helper for walk_use_def_chains.  VAR, FN and DATA are as\n    described in walk_use_def_chains.\n@@ -940,7 +976,10 @@ walk_use_def_chains_1 (tree var, walk_use_def_chains_fn fn, void *data,\n       for (i = 0; i < PHI_NUM_ARGS (def_stmt); i++)\n \t{\n \t  tree arg = PHI_ARG_DEF (def_stmt, i);\n-\t  if (TREE_CODE (arg) == SSA_NAME\n+\n+\t  /* ARG may be NULL for newly introduced PHI nodes.  */\n+\t  if (arg\n+\t      && TREE_CODE (arg) == SSA_NAME\n \t      && walk_use_def_chains_1 (arg, fn, data, visited, is_dfs))\n \t    return true;\n \t}\n@@ -978,7 +1017,6 @@ walk_use_def_chains_1 (tree var, walk_use_def_chains_fn fn, void *data,\n    If IS_DFS is false, the two steps above are done in reverse order\n    (i.e., a breadth-first search).  */\n \n-\n void\n walk_use_def_chains (tree var, walk_use_def_chains_fn fn, void *data,\n                      bool is_dfs)\n@@ -1189,4 +1227,3 @@ struct tree_opt_pass pass_late_warn_uninitialized =\n   0,                                    /* todo_flags_finish */\n   0\t\t\t\t        /* letter */\n };\n-\t  "}, {"sha": "1be768953d1f6cfe79d6b208c82fe609ba5c8b47", "filename": "gcc/tree-vect-transform.c", "status": "modified", "additions": 14, "deletions": 17, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-vect-transform.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-vect-transform.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-transform.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -301,7 +301,7 @@ vect_create_data_ref_ptr (tree stmt,\n   if (!MTAG_P (tag))\n     new_type_alias (vect_ptr, tag, DR_REF (dr));\n   else\n-    var_ann (vect_ptr)->symbol_mem_tag = tag;\n+    set_symbol_mem_tag (vect_ptr, tag);\n \n   var_ann (vect_ptr)->subvars = DR_SUBVARS (dr);\n \n@@ -1660,7 +1660,7 @@ vectorizable_call (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt)\n \n       return false;\n     }\n-  gcc_assert (!stmt_references_memory_p (stmt));\n+  gcc_assert (ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS));\n \n   for (args = TREE_OPERAND (operation, 1); args; args = TREE_CHAIN (args))\n     {\n@@ -2851,16 +2851,16 @@ vectorizable_store (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt)\n \t\t\t     vec_oprnd);\n \t  vect_finish_stmt_generation (stmt, new_stmt, bsi);\n \n-\t  /* Set the V_MAY_DEFS for the vector pointer. If this virtual def has a \n-\t     use outside the loop and a loop peel is performed then the def may be \n-\t     renamed by the peel.  Mark it for renaming so the later use will also \n-\t     be renamed.  */\n+\t  /* Set the VDEFs for the vector pointer. If this virtual def\n+\t     has a use outside the loop and a loop peel is performed\n+\t     then the def may be renamed by the peel.  Mark it for\n+\t     renaming so the later use will also be renamed.  */\n \t  copy_virtual_operands (new_stmt, next_stmt);\n \t  if (j == 0)\n \t    {\n-\t      /* The original store is deleted so the same SSA_NAMEs can be used.  \n-\t       */\n-\t      FOR_EACH_SSA_TREE_OPERAND (def, next_stmt, iter, SSA_OP_VMAYDEF)\n+\t      /* The original store is deleted so the same SSA_NAMEs\n+\t\t can be used.  */\n+\t      FOR_EACH_SSA_TREE_OPERAND (def, next_stmt, iter, SSA_OP_VDEF)\n \t\t{\n \t\t  SSA_NAME_DEF_STMT (def) = new_stmt;\n \t\t  mark_sym_for_renaming (SSA_NAME_VAR (def));\n@@ -2872,7 +2872,7 @@ vectorizable_store (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt)\n \t    {\n \t      /* Create new names for all the definitions created by COPY and\n \t\t add replacement mappings for each new name.  */\n-\t      FOR_EACH_SSA_DEF_OPERAND (def_p, new_stmt, iter, SSA_OP_VMAYDEF)\n+\t      FOR_EACH_SSA_DEF_OPERAND (def_p, new_stmt, iter, SSA_OP_VDEF)\n \t\t{\n \t\t  create_new_def_for (DEF_FROM_PTR (def_p), new_stmt, def_p);\n \t\t  mark_sym_for_renaming (SSA_NAME_VAR (DEF_FROM_PTR (def_p)));\n@@ -4037,9 +4037,9 @@ vect_generate_tmps_on_preheader (loop_vec_info loop_vinfo,\n    LOOP - the loop whose preheader will contain STMT.\n \n    It's possible to vectorize a loop even though an SSA_NAME from a VUSE\n-   appears to be defined in a V_MAY_DEF in another statement in a loop.\n+   appears to be defined in a VDEF in another statement in a loop.\n    One such case is when the VUSE is at the dereference of a __restricted__\n-   pointer in a load and the V_MAY_DEF is at the dereference of a different\n+   pointer in a load and the VDEF is at the dereference of a different\n    __restricted__ pointer in a store.  Vectorization may result in\n    copy_virtual_uses being called to copy the problematic VUSE to a new\n    statement that is being inserted in the loop preheader.  This procedure\n@@ -4651,8 +4651,6 @@ vect_transform_loop (loop_vec_info loop_vinfo)\n   int i;\n   tree ratio = NULL;\n   int vectorization_factor = LOOP_VINFO_VECT_FACTOR (loop_vinfo);\n-  bitmap_iterator bi;\n-  unsigned int j;\n   bool strided_store;\n \n   if (vect_print_dump_info (REPORT_DETAILS))\n@@ -4715,7 +4713,7 @@ vect_transform_loop (loop_vec_info loop_vinfo)\n \n   /* CHECKME: we wouldn't need this if we called update_ssa once\n      for all loops.  */\n-  bitmap_zero (vect_vnames_to_rename);\n+  bitmap_zero (vect_memsyms_to_rename);\n \n   /* Peel the loop if there are data refs with unknown alignment.\n      Only one data ref with unknown store is allowed.  */\n@@ -4837,8 +4835,7 @@ vect_transform_loop (loop_vec_info loop_vinfo)\n \n   slpeel_make_loop_iterate_ntimes (loop, ratio);\n \n-  EXECUTE_IF_SET_IN_BITMAP (vect_vnames_to_rename, 0, j, bi)\n-    mark_sym_for_renaming (SSA_NAME_VAR (ssa_name (j)));\n+  mark_set_for_renaming (vect_memsyms_to_rename);\n \n   /* The memory tags and pointers in vectorized statements need to\n      have their SSA forms updated.  FIXME, why can't this be delayed"}, {"sha": "f8c01f9462146ecfdec3f5ff50c90f4229c2f4ff", "filename": "gcc/tree-vectorizer.c", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-vectorizer.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-vectorizer.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -178,7 +178,7 @@ enum verbosity_levels vect_verbosity_level = MAX_VERBOSITY_LEVEL;\n static LOC vect_loop_location;\n \n /* Bitmap of virtual variables to be renamed.  */\n-bitmap vect_vnames_to_rename;\n+bitmap vect_memsyms_to_rename;\n \f\n /*************************************************************************\n   Simple Loop Peeling Utilities\n@@ -226,8 +226,7 @@ rename_variables_in_bb (basic_block bb)\n   for (bsi = bsi_start (bb); !bsi_end_p (bsi); bsi_next (&bsi))\n     {\n       stmt = bsi_stmt (bsi);\n-      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, \n-\t\t\t\t (SSA_OP_ALL_USES | SSA_OP_ALL_KILLS))\n+      FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_ALL_USES)\n \trename_use_op (use_p);\n     }\n \n@@ -529,7 +528,7 @@ slpeel_update_phi_nodes_for_guard1 (edge guard_edge, struct loop *loop,\n \t renaming later.  */\n       name = PHI_RESULT (orig_phi);\n       if (!is_gimple_reg (SSA_NAME_VAR (name)))\n-        bitmap_set_bit (vect_vnames_to_rename, SSA_NAME_VERSION (name));\n+        bitmap_set_bit (vect_memsyms_to_rename, DECL_UID (SSA_NAME_VAR (name)));\n \n       /** 1. Handle new-merge-point phis  **/\n \n@@ -554,6 +553,9 @@ slpeel_update_phi_nodes_for_guard1 (edge guard_edge, struct loop *loop,\n \n       /** 2. Handle loop-closed-ssa-form phis  **/\n \n+      if (!is_gimple_reg (PHI_RESULT (orig_phi)))\n+\tcontinue;\n+\n       /* 2.1. Generate new phi node in NEW_EXIT_BB:  */\n       new_phi = create_phi_node (SSA_NAME_VAR (PHI_RESULT (orig_phi)),\n                                  *new_exit_bb);\n@@ -2163,7 +2165,7 @@ vectorize_loops (void)\n \n   /* Allocate the bitmap that records which virtual variables that \n      need to be renamed.  */\n-  vect_vnames_to_rename = BITMAP_ALLOC (NULL);\n+  vect_memsyms_to_rename = BITMAP_ALLOC (NULL);\n \n   /*  ----------- Analyze loops. -----------  */\n \n@@ -2193,7 +2195,7 @@ vectorize_loops (void)\n \n   /*  ----------- Finalize. -----------  */\n \n-  BITMAP_FREE (vect_vnames_to_rename);\n+  BITMAP_FREE (vect_memsyms_to_rename);\n \n   for (i = 1; i < vect_loops_num; i++)\n     {"}, {"sha": "78410e2246dc70ad80874774642e3dbcf2f8f591", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -328,7 +328,7 @@ extern FILE *vect_dump;\n extern enum verbosity_levels vect_verbosity_level;\n \n /* Bitmap of virtual variables to be renamed.  */\n-extern bitmap vect_vnames_to_rename;\n+extern bitmap vect_memsyms_to_rename;\n \n /*-----------------------------------------------------------------*/\n /* Function prototypes.                                            */"}, {"sha": "8591b35150b4a9e3c7234a8179c75917dce946e7", "filename": "gcc/tree.c", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -271,12 +271,15 @@ init_ttree (void)\n   tree_contains_struct[STRUCT_FIELD_TAG][TS_DECL_MINIMAL] = 1;\n   tree_contains_struct[NAME_MEMORY_TAG][TS_DECL_MINIMAL] = 1;\n   tree_contains_struct[SYMBOL_MEMORY_TAG][TS_DECL_MINIMAL] = 1;\n+  tree_contains_struct[MEMORY_PARTITION_TAG][TS_DECL_MINIMAL] = 1;\n \n   tree_contains_struct[STRUCT_FIELD_TAG][TS_MEMORY_TAG] = 1;\n   tree_contains_struct[NAME_MEMORY_TAG][TS_MEMORY_TAG] = 1;\n   tree_contains_struct[SYMBOL_MEMORY_TAG][TS_MEMORY_TAG] = 1;\n+  tree_contains_struct[MEMORY_PARTITION_TAG][TS_MEMORY_TAG] = 1;\n \n   tree_contains_struct[STRUCT_FIELD_TAG][TS_STRUCT_FIELD_TAG] = 1;\n+  tree_contains_struct[MEMORY_PARTITION_TAG][TS_MEMORY_PARTITION_TAG] = 1;\n \n   tree_contains_struct[VAR_DECL][TS_DECL_WITH_VIS] = 1;\n   tree_contains_struct[FUNCTION_DECL][TS_DECL_WITH_VIS] = 1;\n@@ -374,6 +377,8 @@ tree_code_size (enum tree_code code)\n \t    return sizeof (struct tree_memory_tag);\n \t  case STRUCT_FIELD_TAG:\n \t    return sizeof (struct tree_struct_field_tag);\n+\t  case MEMORY_PARTITION_TAG:\n+\t    return sizeof (struct tree_memory_partition_tag);\n \t  default:\n \t    return sizeof (struct tree_decl_non_common);\n \t  }\n@@ -2189,6 +2194,7 @@ tree_node_structure (tree t)\n \t  case SYMBOL_MEMORY_TAG:\n \t  case NAME_MEMORY_TAG:\n \t  case STRUCT_FIELD_TAG:\n+\t  case MEMORY_PARTITION_TAG:\n \t    return TS_MEMORY_TAG;\n \t  default:\n \t    return TS_DECL_NON_COMMON;"}, {"sha": "0e3f664da3f49d8356819cbe756fee71b67e2d7d", "filename": "gcc/tree.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.def?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -359,6 +359,7 @@ DEFTREECODE (RESULT_DECL, \"result_decl\", tcc_declaration, 0)\n DEFTREECODE (STRUCT_FIELD_TAG, \"struct_field_tag\", tcc_declaration, 0)\n DEFTREECODE (NAME_MEMORY_TAG, \"name_memory_tag\", tcc_declaration, 0)\n DEFTREECODE (SYMBOL_MEMORY_TAG, \"symbol_memory_tag\", tcc_declaration, 0)\n+DEFTREECODE (MEMORY_PARTITION_TAG, \"memory_partition_tag\", tcc_declaration, 0)\n \n /* A namespace declaration.  Namespaces appear in DECL_CONTEXT of other\n    _DECLs, providing a hierarchy of names.  */"}, {"sha": "f0bb850a1be24ff6c029212a2ce61314c365283d", "filename": "gcc/tree.h", "status": "modified", "additions": 19, "deletions": 2, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -107,7 +107,8 @@ extern const enum tree_code_class tree_code_type[];\n #define MTAG_P(CODE) \\\n   (TREE_CODE (CODE) == STRUCT_FIELD_TAG\t\t\\\n    || TREE_CODE (CODE) == NAME_MEMORY_TAG\t\\\n-   || TREE_CODE (CODE) == SYMBOL_MEMORY_TAG)\n+   || TREE_CODE (CODE) == SYMBOL_MEMORY_TAG\t\\\n+   || TREE_CODE (CODE) == MEMORY_PARTITION_TAG)\n \n \n /* Nonzero if DECL represents a VAR_DECL or FUNCTION_DECL.  */\n@@ -1859,13 +1860,14 @@ struct tree_phi_node GTY(())\n   int num_args;\n   int capacity;\n \n-  /* Basic block to that the phi node belongs.  */\n+  /* Basic block holding this PHI node.  */\n   struct basic_block_def *bb;\n \n   /* Arguments of the PHI node.  These are maintained in the same\n      order as predecessor edge vector BB->PREDS.  */\n   struct phi_arg_d GTY ((length (\"((tree)&%h)->phi.num_args\"))) a[1];\n };\n+\n \f\n #define OMP_CLAUSE_CODE(NODE)\t\t\t\t\t\\\n \t(OMP_CLAUSE_CHECK (NODE))->omp_clause.code\n@@ -2443,6 +2445,20 @@ struct tree_struct_field_tag GTY(())\n #define SFT_OFFSET(NODE) (STRUCT_FIELD_TAG_CHECK (NODE)->sft.offset)\n #define SFT_SIZE(NODE) (STRUCT_FIELD_TAG_CHECK (NODE)->sft.size)\n \n+/* Memory Partition Tags (MPTs) group memory symbols under one\n+   common name for the purposes of placing memory PHI nodes.  */\n+\n+struct tree_memory_partition_tag GTY(())\n+{\n+  struct tree_memory_tag common;\n+  \n+  /* Set of symbols grouped under this MPT.  */\n+  bitmap symbols;\n+};\n+\n+#define MPT_SYMBOLS(NODE)\t(MEMORY_PARTITION_TAG_CHECK (NODE)->mpt.symbols)\n+\n+\n /* For any sort of a ..._DECL node, this points to the original (abstract)\n    decl node which this decl is an instance of, or else it is NULL indicating\n    that this decl is not an instance of some other decl.  For example,\n@@ -3264,6 +3280,7 @@ union tree_node GTY ((ptr_alias (union lang_tree_node),\n   struct tree_memory_tag GTY ((tag (\"TS_MEMORY_TAG\"))) mtag;\n   struct tree_struct_field_tag GTY ((tag (\"TS_STRUCT_FIELD_TAG\"))) sft;\n   struct tree_omp_clause GTY ((tag (\"TS_OMP_CLAUSE\"))) omp_clause;\n+  struct tree_memory_partition_tag GTY ((tag (\"TS_MEMORY_PARTITION_TAG\"))) mpt;\n };\n \f\n /* Standard named or nameless data types of the C compiler.  */"}, {"sha": "3510ffa372231a9e2d6b060bf40a22d249497bd1", "filename": "gcc/treestruct.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftreestruct.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38635499e9c759fc039e669acfabc80f4f65dffb/gcc%2Ftreestruct.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftreestruct.def?ref=38635499e9c759fc039e669acfabc80f4f65dffb", "patch": "@@ -64,3 +64,4 @@ DEFTREESTRUCT(TS_CONSTRUCTOR, \"constructor\")\n DEFTREESTRUCT(TS_MEMORY_TAG, \"memory tag\")\n DEFTREESTRUCT(TS_STRUCT_FIELD_TAG, \"struct field tag\")\n DEFTREESTRUCT(TS_OMP_CLAUSE, \"omp clause\")\n+DEFTREESTRUCT(TS_MEMORY_PARTITION_TAG, \"memory partition tag\")"}]}