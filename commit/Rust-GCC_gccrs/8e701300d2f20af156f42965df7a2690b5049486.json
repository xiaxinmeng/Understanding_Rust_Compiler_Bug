{"sha": "8e701300d2f20af156f42965df7a2690b5049486", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OGU3MDEzMDBkMmYyMGFmMTU2ZjQyOTY1ZGY3YTI2OTBiNTA0OTQ4Ng==", "commit": {"author": {"name": "Christian Bruel", "email": "christian.bruel@st.com", "date": "2013-10-24T13:47:27Z"}, "committer": {"name": "Christian Bruel", "email": "chrbr@gcc.gnu.org", "date": "2013-10-24T13:47:27Z"}, "message": "config.gcc (sh-*): Add sh-mem.o to extra_obj.\n\n2013-10-25  Christian Bruel  <christian.bruel@st.com>\n\n\t* config.gcc (sh-*): Add sh-mem.o to extra_obj.\n\t* gcc/config/sh/t-sh (sh-mem.o): New rule.\n\t* gcc/config/sh/sh-mem.cc (expand_block_move): Moved here.\n\t(sh4_expand_cmpstr): New function.\n\t* gcc/config/sh/sh.c (force_into, expand_block_move): Move to sh-mem.cc\n\t* gcc/config/sh/sh-protos.h (sh4_expand_cmpstr): Declare.\n\t* gcc/config/sh/sh.md (cmpstrsi, cmpstr_t): New patterns.\n\t(rotlhi3_8): Rename.\n\nFrom-SVN: r204013", "tree": {"sha": "8e892d05fdc38fa97e8d9e9a17bbb16ed74aaa85", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8e892d05fdc38fa97e8d9e9a17bbb16ed74aaa85"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/8e701300d2f20af156f42965df7a2690b5049486", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8e701300d2f20af156f42965df7a2690b5049486", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8e701300d2f20af156f42965df7a2690b5049486", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8e701300d2f20af156f42965df7a2690b5049486/comments", "author": null, "committer": null, "parents": [{"sha": "f28aa681d399c174527abd917afe15a3174a401e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f28aa681d399c174527abd917afe15a3174a401e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f28aa681d399c174527abd917afe15a3174a401e"}], "stats": {"total": 516, "additions": 359, "deletions": 157}, "files": [{"sha": "49839c5098d44b982a6bcbcfb3dcf6c3d1856a5f", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8e701300d2f20af156f42965df7a2690b5049486/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8e701300d2f20af156f42965df7a2690b5049486/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=8e701300d2f20af156f42965df7a2690b5049486", "patch": "@@ -1,3 +1,14 @@\n+2013-10-25  Christian Bruel  <christian.bruel@st.com>\n+\n+\t* config.gcc (sh-*): Add sh-mem.o to extra_obj.\n+\t* gcc/config/sh/t-sh (sh-mem.o): New rule.\n+\t* gcc/config/sh/sh-mem.cc (expand_block_move): Moved here.\n+\t(sh4_expand_cmpstr): New function.\n+\t* gcc/config/sh/sh.c (force_into, expand_block_move): Move to sh-mem.c\n+\t* gcc/config/sh/sh-protos.h (sh4_expand_cmpstr): Declare.\n+\t* gcc/config/sh/sh.md (cmpstrsi, cmpstr_t): New patterns.\n+\t(rotlhi3_8): Rename.\n+\n 2013-10-24  Jan-Benedict Glaw  <jbglaw@lug-owl.de>\n \n \t* configure.ac (ZW_PROG_COMPILER_DEPENDENCIES): Use CXX instead of CC."}, {"sha": "a90ab25f37a7c5fd4efd6711efed518c75ccd8ea", "filename": "gcc/config.gcc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=8e701300d2f20af156f42965df7a2690b5049486", "patch": "@@ -465,7 +465,7 @@ sh[123456789lbe]*-*-* | sh-*-*)\n \tcpu_type=sh\n \tneed_64bit_hwint=yes\n \textra_options=\"${extra_options} fused-madd.opt\"\n-\textra_objs=\"${extra_objs} sh_treg_combine.o\"\n+\textra_objs=\"${extra_objs} sh_treg_combine.o sh-mem.o\"\n \t;;\n v850*-*-*)\n \tcpu_type=v850"}, {"sha": "e6f0843ca308d74df69cc1446227be15c6699437", "filename": "gcc/config/sh/sh-mem.cc", "status": "added", "additions": 307, "deletions": 0, "changes": 307, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh-mem.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh-mem.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh-mem.cc?ref=8e701300d2f20af156f42965df7a2690b5049486", "patch": "@@ -0,0 +1,307 @@\n+/* Helper routines for memory move and comparison insns.\n+   Copyright (C) 2013 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"machmode.h\"\n+#include \"rtl.h\"\n+#include \"tree.h\"\n+#include \"expr.h\"\n+#include \"tm_p.h\"\n+#include \"basic-block.h\"\n+\n+/* Like force_operand, but guarantees that VALUE ends up in TARGET.  */\n+static void\n+force_into (rtx value, rtx target)\n+{\n+  value = force_operand (value, target);\n+  if (! rtx_equal_p (value, target))\n+    emit_insn (gen_move_insn (target, value));\n+}\n+\n+/* Emit code to perform a block move.  Choose the best method.\n+\n+   OPERANDS[0] is the destination.\n+   OPERANDS[1] is the source.\n+   OPERANDS[2] is the size.\n+   OPERANDS[3] is the alignment safe to use.  */\n+bool\n+expand_block_move (rtx *operands)\n+{\n+  int align = INTVAL (operands[3]);\n+  int constp = (CONST_INT_P (operands[2]));\n+  int bytes = (constp ? INTVAL (operands[2]) : 0);\n+\n+  if (! constp)\n+    return false;\n+\n+  /* If we could use mov.l to move words and dest is word-aligned, we\n+     can use movua.l for loads and still generate a relatively short\n+     and efficient sequence.  */\n+  if (TARGET_SH4A_ARCH && align < 4\n+      && MEM_ALIGN (operands[0]) >= 32\n+      && can_move_by_pieces (bytes, 32))\n+    {\n+      rtx dest = copy_rtx (operands[0]);\n+      rtx src = copy_rtx (operands[1]);\n+      /* We could use different pseudos for each copied word, but\n+\t since movua can only load into r0, it's kind of\n+\t pointless.  */\n+      rtx temp = gen_reg_rtx (SImode);\n+      rtx src_addr = copy_addr_to_reg (XEXP (src, 0));\n+      int copied = 0;\n+\n+      while (copied + 4 <= bytes)\n+\t{\n+\t  rtx to = adjust_address (dest, SImode, copied);\n+\t  rtx from = adjust_automodify_address (src, BLKmode,\n+\t\t\t\t\t\tsrc_addr, copied);\n+\n+\t  set_mem_size (from, 4);\n+\t  emit_insn (gen_movua (temp, from));\n+\t  emit_move_insn (src_addr, plus_constant (Pmode, src_addr, 4));\n+\t  emit_move_insn (to, temp);\n+\t  copied += 4;\n+\t}\n+\n+      if (copied < bytes)\n+\tmove_by_pieces (adjust_address (dest, BLKmode, copied),\n+\t\t\tadjust_automodify_address (src, BLKmode,\n+\t\t\t\t\t\t   src_addr, copied),\n+\t\t\tbytes - copied, align, 0);\n+\n+      return true;\n+    }\n+\n+  /* If it isn't a constant number of bytes, or if it doesn't have 4 byte\n+     alignment, or if it isn't a multiple of 4 bytes, then fail.  */\n+  if (align < 4 || (bytes % 4 != 0))\n+    return false;\n+\n+  if (TARGET_HARD_SH4)\n+    {\n+      if (bytes < 12)\n+\treturn false;\n+      else if (bytes == 12)\n+\t{\n+\t  rtx func_addr_rtx = gen_reg_rtx (Pmode);\n+\t  rtx r4 = gen_rtx_REG (SImode, 4);\n+\t  rtx r5 = gen_rtx_REG (SImode, 5);\n+\n+\t  function_symbol (func_addr_rtx, \"__movmemSI12_i4\", SFUNC_STATIC);\n+\t  force_into (XEXP (operands[0], 0), r4);\n+\t  force_into (XEXP (operands[1], 0), r5);\n+\t  emit_insn (gen_block_move_real_i4 (func_addr_rtx));\n+\t  return true;\n+\t}\n+      else if (! optimize_size)\n+\t{\n+\t  const char *entry_name;\n+\t  rtx func_addr_rtx = gen_reg_rtx (Pmode);\n+\t  int dwords;\n+\t  rtx r4 = gen_rtx_REG (SImode, 4);\n+\t  rtx r5 = gen_rtx_REG (SImode, 5);\n+\t  rtx r6 = gen_rtx_REG (SImode, 6);\n+\n+\t  entry_name = (bytes & 4 ? \"__movmem_i4_odd\" : \"__movmem_i4_even\");\n+\t  function_symbol (func_addr_rtx, entry_name, SFUNC_STATIC);\n+\t  force_into (XEXP (operands[0], 0), r4);\n+\t  force_into (XEXP (operands[1], 0), r5);\n+\n+\t  dwords = bytes >> 3;\n+\t  emit_insn (gen_move_insn (r6, GEN_INT (dwords - 1)));\n+\t  emit_insn (gen_block_lump_real_i4 (func_addr_rtx));\n+\t  return true;\n+\t}\n+      else\n+\treturn false;\n+    }\n+  if (bytes < 64)\n+    {\n+      char entry[30];\n+      rtx func_addr_rtx = gen_reg_rtx (Pmode);\n+      rtx r4 = gen_rtx_REG (SImode, 4);\n+      rtx r5 = gen_rtx_REG (SImode, 5);\n+\n+      sprintf (entry, \"__movmemSI%d\", bytes);\n+      function_symbol (func_addr_rtx, entry, SFUNC_STATIC);\n+      force_into (XEXP (operands[0], 0), r4);\n+      force_into (XEXP (operands[1], 0), r5);\n+      emit_insn (gen_block_move_real (func_addr_rtx));\n+      return true;\n+    }\n+\n+  /* This is the same number of bytes as a memcpy call, but to a different\n+     less common function name, so this will occasionally use more space.  */\n+  if (! optimize_size)\n+    {\n+      rtx func_addr_rtx = gen_reg_rtx (Pmode);\n+      int final_switch, while_loop;\n+      rtx r4 = gen_rtx_REG (SImode, 4);\n+      rtx r5 = gen_rtx_REG (SImode, 5);\n+      rtx r6 = gen_rtx_REG (SImode, 6);\n+\n+      function_symbol (func_addr_rtx, \"__movmem\", SFUNC_STATIC);\n+      force_into (XEXP (operands[0], 0), r4);\n+      force_into (XEXP (operands[1], 0), r5);\n+\n+      /* r6 controls the size of the move.  16 is decremented from it\n+\t for each 64 bytes moved.  Then the negative bit left over is used\n+\t as an index into a list of move instructions.  e.g., a 72 byte move\n+\t would be set up with size(r6) = 14, for one iteration through the\n+\t big while loop, and a switch of -2 for the last part.  */\n+\n+      final_switch = 16 - ((bytes / 4) % 16);\n+      while_loop = ((bytes / 4) / 16 - 1) * 16;\n+      emit_insn (gen_move_insn (r6, GEN_INT (while_loop + final_switch)));\n+      emit_insn (gen_block_lump_real (func_addr_rtx));\n+      return true;\n+    }\n+\n+  return false;\n+}\n+\n+/* Emit code to perform a strcmp.\n+\n+   OPERANDS[0] is the destination.\n+   OPERANDS[1] is the first string.\n+   OPERANDS[2] is the second string.\n+   OPERANDS[3] is the align.  */\n+bool\n+sh_expand_cmpstr (rtx *operands)\n+{\n+  rtx s1 = copy_rtx (operands[1]);\n+  rtx s2 = copy_rtx (operands[2]);\n+  rtx s1_addr = copy_addr_to_reg (XEXP (s1, 0));\n+  rtx s2_addr = copy_addr_to_reg (XEXP (s2, 0));\n+  rtx tmp0 = gen_reg_rtx (SImode);\n+  rtx tmp1 = gen_reg_rtx (SImode);\n+  rtx tmp2 = gen_reg_rtx (SImode);\n+  rtx tmp3 = gen_reg_rtx (SImode);\n+\n+  rtx L_return = gen_label_rtx ();\n+  rtx L_loop_byte = gen_label_rtx ();\n+  rtx L_end_loop_byte = gen_label_rtx ();\n+  rtx L_loop_long = gen_label_rtx ();\n+  rtx L_end_loop_long = gen_label_rtx ();\n+\n+  rtx jump, addr1, addr2;\n+  int prob_unlikely = REG_BR_PROB_BASE / 10;\n+  int prob_likely = REG_BR_PROB_BASE / 4;\n+\n+  emit_insn (gen_iorsi3 (tmp1, s1_addr, s2_addr));\n+  emit_move_insn (tmp0, GEN_INT (3));\n+\n+  emit_insn (gen_tstsi_t (tmp0, tmp1));\n+\n+  emit_move_insn (tmp0, const0_rtx);\n+\n+  jump = emit_jump_insn (gen_branch_false (L_loop_byte));\n+  add_int_reg_note (jump, REG_BR_PROB, prob_likely);\n+\n+  addr1 = adjust_automodify_address (s1, SImode, s1_addr, 0);\n+  addr2 = adjust_automodify_address (s2, SImode, s2_addr, 0);\n+\n+  /* tmp2 is aligned, OK to load.  */\n+  emit_move_insn (tmp3, addr2);\n+  emit_move_insn (s2_addr, plus_constant (Pmode, s2_addr, 4));\n+\n+  /*start long loop.  */\n+  emit_label (L_loop_long);\n+\n+  emit_move_insn (tmp2, tmp3);\n+\n+  /* tmp1 is aligned, OK to load.  */\n+  emit_move_insn (tmp1, addr1);\n+  emit_move_insn (s1_addr, plus_constant (Pmode, s1_addr, 4));\n+\n+  /* Is there a 0 byte ?  */\n+  emit_insn (gen_andsi3 (tmp3, tmp3, tmp1));\n+\n+  emit_insn (gen_cmpstr_t (tmp0, tmp3));\n+  jump = emit_jump_insn (gen_branch_true (L_end_loop_long));\n+  add_int_reg_note (jump, REG_BR_PROB, prob_unlikely);\n+\n+  emit_insn (gen_cmpeqsi_t (tmp1, tmp2));\n+\n+  /* tmp2 is aligned, OK to load.  */\n+  emit_move_insn (tmp3, addr2);\n+  emit_move_insn (s2_addr, plus_constant (Pmode, s2_addr, 4));\n+\n+  jump = emit_jump_insn (gen_branch_true (L_loop_long));\n+  add_int_reg_note (jump, REG_BR_PROB, prob_likely);\n+  /* end loop.  */\n+\n+  /* Fallthu, check if one of the word is greater.  */\n+  if (TARGET_LITTLE_ENDIAN)\n+    {\n+      rtx low_1 = gen_lowpart (HImode, tmp1);\n+      rtx low_2 = gen_lowpart (HImode, tmp2);\n+\n+      emit_insn (gen_rotlhi3_8 (low_1, low_1));\n+      emit_insn (gen_rotlhi3_8 (low_2, low_2));\n+      emit_insn (gen_rotlsi3_16 (tmp1, tmp1));\n+      emit_insn (gen_rotlsi3_16 (tmp2, tmp2));\n+      emit_insn (gen_rotlhi3_8 (low_1, low_1));\n+      emit_insn (gen_rotlhi3_8 (low_2, low_2));\n+    }\n+\n+  jump = emit_jump_insn (gen_jump_compact (L_return));\n+  emit_barrier_after (jump);\n+\n+  /* start byte loop.  */\n+  addr1 = adjust_automodify_address (s1, QImode, s1_addr, 0);\n+  addr2 = adjust_automodify_address (s2, QImode, s2_addr, 0);\n+\n+  emit_label (L_end_loop_long);\n+\n+  emit_move_insn (s1_addr, plus_constant (Pmode, s1_addr, -4));\n+  emit_move_insn (s2_addr, plus_constant (Pmode, s2_addr, -4));\n+\n+  emit_label (L_loop_byte);\n+\n+  emit_insn (gen_extendqisi2 (tmp2, addr2));\n+  emit_move_insn (s2_addr, plus_constant (Pmode, s2_addr, 1));\n+\n+  emit_insn (gen_extendqisi2 (tmp1, addr1));\n+  emit_move_insn (s1_addr, plus_constant (Pmode, s1_addr, 1));\n+\n+  emit_insn (gen_cmpeqsi_t (tmp2, const0_rtx));\n+  jump = emit_jump_insn (gen_branch_true (L_end_loop_byte));\n+  add_int_reg_note (jump, REG_BR_PROB, prob_unlikely);\n+\n+  emit_insn (gen_cmpeqsi_t (tmp1, tmp2));\n+  emit_jump_insn (gen_branch_true (L_loop_byte));\n+  add_int_reg_note (jump, REG_BR_PROB, prob_likely);\n+  /* end loop.  */\n+\n+  emit_label (L_end_loop_byte);\n+\n+  emit_insn (gen_zero_extendqisi2 (tmp2, gen_lowpart (QImode, tmp2)));\n+  emit_insn (gen_zero_extendqisi2 (tmp1, gen_lowpart (QImode, tmp1)));\n+\n+  emit_label (L_return);\n+\n+  emit_insn (gen_subsi3 (operands[0], tmp1, tmp2));\n+\n+  return true;\n+}\n+"}, {"sha": "3484e4a2fdfd87f74fa89f9bbe35636546f90972", "filename": "gcc/config/sh/sh-protos.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh-protos.h?ref=8e701300d2f20af156f42965df7a2690b5049486", "patch": "@@ -116,6 +116,7 @@ extern void emit_df_insn (rtx);\n extern void output_pic_addr_const (FILE *, rtx);\n extern bool expand_block_move (rtx *);\n extern void prepare_move_operands (rtx[], enum machine_mode mode);\n+extern bool sh_expand_cmpstr (rtx *);\n extern enum rtx_code prepare_cbranch_operands (rtx *, enum machine_mode mode,\n \t\t\t\t\t       enum rtx_code comparison);\n extern void expand_cbranchsi4 (rtx *operands, enum rtx_code comparison, int);"}, {"sha": "2e60763fe7356470ddc69cf5f46a8c51c1432832", "filename": "gcc/config/sh/sh.c", "status": "modified", "additions": 0, "deletions": 152, "changes": 152, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh.c?ref=8e701300d2f20af156f42965df7a2690b5049486", "patch": "@@ -174,7 +174,6 @@ static bool shmedia_space_reserved_for_target_registers;\n \n static void split_branches (rtx);\n static int branch_dest (rtx);\n-static void force_into (rtx, rtx);\n static void print_slot (rtx);\n static rtx add_constant (rtx, enum machine_mode, rtx);\n static void dump_table (rtx, rtx);\n@@ -1621,157 +1620,6 @@ sh_encode_section_info (tree decl, rtx rtl, int first)\n     SYMBOL_REF_FLAGS (XEXP (rtl, 0)) |= SYMBOL_FLAG_FUNCVEC_FUNCTION;\n }\n \n-/* Like force_operand, but guarantees that VALUE ends up in TARGET.  */\n-static void\n-force_into (rtx value, rtx target)\n-{\n-  value = force_operand (value, target);\n-  if (! rtx_equal_p (value, target))\n-    emit_insn (gen_move_insn (target, value));\n-}\n-\n-/* Emit code to perform a block move.  Choose the best method.\n-\n-   OPERANDS[0] is the destination.\n-   OPERANDS[1] is the source.\n-   OPERANDS[2] is the size.\n-   OPERANDS[3] is the alignment safe to use.  */\n-bool\n-expand_block_move (rtx *operands)\n-{\n-  int align = INTVAL (operands[3]);\n-  int constp = (CONST_INT_P (operands[2]));\n-  int bytes = (constp ? INTVAL (operands[2]) : 0);\n-\n-  if (! constp)\n-    return false;\n-\n-  /* If we could use mov.l to move words and dest is word-aligned, we\n-     can use movua.l for loads and still generate a relatively short\n-     and efficient sequence.  */\n-  if (TARGET_SH4A_ARCH && align < 4\n-      && MEM_ALIGN (operands[0]) >= 32\n-      && can_move_by_pieces (bytes, 32))\n-    {\n-      rtx dest = copy_rtx (operands[0]);\n-      rtx src = copy_rtx (operands[1]);\n-      /* We could use different pseudos for each copied word, but\n-\t since movua can only load into r0, it's kind of\n-\t pointless.  */\n-      rtx temp = gen_reg_rtx (SImode);\n-      rtx src_addr = copy_addr_to_reg (XEXP (src, 0));\n-      int copied = 0;\n-\n-      while (copied + 4 <= bytes)\n-\t{\n-\t  rtx to = adjust_address (dest, SImode, copied);\n-\t  rtx from = adjust_automodify_address (src, BLKmode,\n-\t\t\t\t\t\tsrc_addr, copied);\n-\n-\t  set_mem_size (from, 4);\n-\t  emit_insn (gen_movua (temp, from));\n-\t  emit_move_insn (src_addr, plus_constant (Pmode, src_addr, 4));\n-\t  emit_move_insn (to, temp);\n-\t  copied += 4;\n-\t}\n-\n-      if (copied < bytes)\n-\tmove_by_pieces (adjust_address (dest, BLKmode, copied),\n-\t\t\tadjust_automodify_address (src, BLKmode,\n-\t\t\t\t\t\t   src_addr, copied),\n-\t\t\tbytes - copied, align, 0);\n-\n-      return true;\n-    }\n-\n-  /* If it isn't a constant number of bytes, or if it doesn't have 4 byte\n-     alignment, or if it isn't a multiple of 4 bytes, then fail.  */\n-  if (align < 4 || (bytes % 4 != 0))\n-    return false;\n-\n-  if (TARGET_HARD_SH4)\n-    {\n-      if (bytes < 12)\n-\treturn false;\n-      else if (bytes == 12)\n-\t{\n-\t  rtx func_addr_rtx = gen_reg_rtx (Pmode);\n-\t  rtx r4 = gen_rtx_REG (SImode, 4);\n-\t  rtx r5 = gen_rtx_REG (SImode, 5);\n-\n-\t  function_symbol (func_addr_rtx, \"__movmemSI12_i4\", SFUNC_STATIC);\n-\t  force_into (XEXP (operands[0], 0), r4);\n-\t  force_into (XEXP (operands[1], 0), r5);\n-\t  emit_insn (gen_block_move_real_i4 (func_addr_rtx));\n-\t  return true;\n-\t}\n-      else if (! optimize_size)\n-\t{\n-\t  const char *entry_name;\n-\t  rtx func_addr_rtx = gen_reg_rtx (Pmode);\n-\t  int dwords;\n-\t  rtx r4 = gen_rtx_REG (SImode, 4);\n-\t  rtx r5 = gen_rtx_REG (SImode, 5);\n-\t  rtx r6 = gen_rtx_REG (SImode, 6);\n-\n-\t  entry_name = (bytes & 4 ? \"__movmem_i4_odd\" : \"__movmem_i4_even\");\n-\t  function_symbol (func_addr_rtx, entry_name, SFUNC_STATIC);\n-\t  force_into (XEXP (operands[0], 0), r4);\n-\t  force_into (XEXP (operands[1], 0), r5);\n-\n-\t  dwords = bytes >> 3;\n-\t  emit_insn (gen_move_insn (r6, GEN_INT (dwords - 1)));\n-\t  emit_insn (gen_block_lump_real_i4 (func_addr_rtx));\n-\t  return true;\n-\t}\n-      else\n-\treturn false;\n-    }\n-  if (bytes < 64)\n-    {\n-      char entry[30];\n-      rtx func_addr_rtx = gen_reg_rtx (Pmode);\n-      rtx r4 = gen_rtx_REG (SImode, 4);\n-      rtx r5 = gen_rtx_REG (SImode, 5);\n-\n-      sprintf (entry, \"__movmemSI%d\", bytes);\n-      function_symbol (func_addr_rtx, entry, SFUNC_STATIC);\n-      force_into (XEXP (operands[0], 0), r4);\n-      force_into (XEXP (operands[1], 0), r5);\n-      emit_insn (gen_block_move_real (func_addr_rtx));\n-      return true;\n-    }\n-\n-  /* This is the same number of bytes as a memcpy call, but to a different\n-     less common function name, so this will occasionally use more space.  */\n-  if (! optimize_size)\n-    {\n-      rtx func_addr_rtx = gen_reg_rtx (Pmode);\n-      int final_switch, while_loop;\n-      rtx r4 = gen_rtx_REG (SImode, 4);\n-      rtx r5 = gen_rtx_REG (SImode, 5);\n-      rtx r6 = gen_rtx_REG (SImode, 6);\n-\n-      function_symbol (func_addr_rtx, \"__movmem\", SFUNC_STATIC);\n-      force_into (XEXP (operands[0], 0), r4);\n-      force_into (XEXP (operands[1], 0), r5);\n-\n-      /* r6 controls the size of the move.  16 is decremented from it\n-\t for each 64 bytes moved.  Then the negative bit left over is used\n-\t as an index into a list of move instructions.  e.g., a 72 byte move\n-\t would be set up with size(r6) = 14, for one iteration through the\n-\t big while loop, and a switch of -2 for the last part.  */\n-\n-      final_switch = 16 - ((bytes / 4) % 16);\n-      while_loop = ((bytes / 4) / 16 - 1) * 16;\n-      emit_insn (gen_move_insn (r6, GEN_INT (while_loop + final_switch)));\n-      emit_insn (gen_block_lump_real (func_addr_rtx));\n-      return true;\n-    }\n-\n-  return false;\n-}\n-\n /* Prepare operands for a move define_expand; specifically, one of the\n    operands must be in a register.  */\n void"}, {"sha": "5642856eef3e24e9a9ebb20622ff5db99c5f2b93", "filename": "gcc/config/sh/sh.md", "status": "modified", "additions": 35, "deletions": 4, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Fsh.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh.md?ref=8e701300d2f20af156f42965df7a2690b5049486", "patch": "@@ -31,9 +31,6 @@\n ;; ??? The MAC.W and MAC.L instructions are not supported.  There is no\n ;; way to generate them.\n \n-;; ??? The cmp/str instruction is not supported.  Perhaps it can be used\n-;; for a str* inline function.\n-\n ;; BSR is not generated by the compiler proper, but when relaxing, it\n ;; generates .uses pseudo-ops that allow linker relaxation to create\n ;; BSR.  This is actually implemented in bfd/{coff,elf32}-sh.c\n@@ -4037,7 +4034,7 @@ label:\n   DONE;\n })\n \n-(define_insn \"*rotlhi3_8\"\n+(define_insn \"rotlhi3_8\"\n   [(set (match_operand:HI 0 \"arith_reg_dest\" \"=r\")\n \t(rotate:HI (match_operand:HI 1 \"arith_reg_operand\" \"r\")\n \t\t   (const_int 8)))]\n@@ -11912,6 +11909,40 @@ label:\n   \"jsr\t@%0%#\"\n   [(set_attr \"type\" \"sfunc\")\n    (set_attr \"needs_delay_slot\" \"yes\")])\n+\n+;; byte compare pattern\n+;; temp = a ^ b;\n+;; !((temp & 0xF000) && (temp & 0x0F00) && (temp & 0x00F0) && (temp & 0x000F))\n+(define_insn \"cmpstr_t\"\n+  [(set (reg:SI T_REG)\n+\t(eq:SI (and:SI\n+\t\t(and:SI\n+\t\t (and:SI\n+\t\t  (zero_extract:SI (xor:SI (match_operand:SI 0 \"arith_reg_operand\" \"r\")\n+\t\t\t\t\t   (match_operand:SI 1 \"arith_reg_operand\" \"r\"))\n+\t\t\t\t   (const_int 8) (const_int 0))\n+\t\t  (zero_extract:SI (xor:SI (match_dup 0) (match_dup 1))\n+\t\t\t\t   (const_int 8) (const_int 8)))\n+\t\t  (zero_extract:SI (xor:SI (match_dup 0) (match_dup 1))\n+\t\t\t\t   (const_int 8) (const_int 16)))\n+\t\t(zero_extract:SI (xor:SI (match_dup 0) (match_dup 1))\n+\t\t\t\t (const_int 8) (const_int 24))) (const_int 0)))]\n+  \"TARGET_SH1\"\n+  \"cmp/str\t%0,%1\"\n+  [(set_attr \"type\" \"mt_group\")])\n+\n+(define_expand \"cmpstrsi\"\n+  [(set (match_operand:SI 0 \"register_operand\")\n+\t(compare:SI (match_operand:BLK 1 \"memory_operand\")\n+\t\t    (match_operand:BLK 2 \"memory_operand\")))\n+   (use (match_operand 3 \"immediate_operand\"))]\n+  \"TARGET_SH1\"\n+{\n+   if (! optimize_insn_for_size_p () && sh_expand_cmpstr (operands))\n+      DONE;\n+   else FAIL;\n+})\n+\n \f\n ;; -------------------------------------------------------------------------\n ;; Floating point instructions."}, {"sha": "710bc873e751589138370d9bb5bb37984d46bda0", "filename": "gcc/config/sh/t-sh", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Ft-sh", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8e701300d2f20af156f42965df7a2690b5049486/gcc%2Fconfig%2Fsh%2Ft-sh", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Ft-sh?ref=8e701300d2f20af156f42965df7a2690b5049486", "patch": "@@ -16,6 +16,10 @@\n # along with GCC; see the file COPYING3.  If not see\n # <http://www.gnu.org/licenses/>.\n \n+sh-mem.o: $(srcdir)/config/sh/sh-mem.cc \\\n+  $(CONFIG_H) $(SYSTEM_H) $(TREE_H) $(TM_H) $(TM_P_H)\n+\t$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) $<\n+\n sh-c.o: $(srcdir)/config/sh/sh-c.c \\\n   $(CONFIG_H) $(SYSTEM_H) $(TREE_H) $(TM_H) $(TM_P_H) coretypes.h\n \t$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \\"}]}