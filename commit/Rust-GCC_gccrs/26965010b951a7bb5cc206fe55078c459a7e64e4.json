{"sha": "26965010b951a7bb5cc206fe55078c459a7e64e4", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MjY5NjUwMTBiOTUxYTdiYjVjYzIwNmZlNTUwNzhjNDU5YTdlNjRlNA==", "commit": {"author": {"name": "Bernd Schmidt", "email": "bernds@codesourcery.com", "date": "2011-07-13T23:10:52Z"}, "committer": {"name": "Bernd Schmidt", "email": "bernds@gcc.gnu.org", "date": "2011-07-13T23:10:52Z"}, "message": "haifa-sched.c: Include \"hashtab.h\"\n\n\t* haifa-sched.c: Include \"hashtab.h\"\n\t(sched_no_dce): New global variable.\n\t(INSN_EXACT_TICK, INSN_TICK_ESTIMATE, FEEDS_BACKTRACK_INSN,\n\tSHADOW_P): New macros.\n\t(last_clock_var, cycle_issued_insns): Move declarations.\n\t(must_backtrack): New static variable.\n\t(struct delay_pair): New structure.\n\t(delay_htab, delay_htab_i2): New static variables.\n\t(delay_hash_i1, delay_hash_i2, delay_i1_eq, delay_i2_eq,\n\trecord_delay_slot_pair, pair_delay, add_delay_dependencies): New\n\tfunctions.\n\t(dep_cost_1): If delay pairs exist, try to look up the insns and\n\tuse the correct pair delay if we find them.\n\t(rank-for_schedule): Tweak priority for insns that must be scheduled\n\tsoon to avoid backtracking.\n\t(queue_insn): Detect conditions which force backtracking.\n\t(ready_add): Likewise.\n\t(struct sched_block_state): Add member shadows_only_p.\n\t(struct haifa_save_data): New structure.\n\t(backtrack_queue): New static variable.\n\t(mark_backtrack_feeds, copy_insn_list, save_backtrack_point,\n\tunschedule_insns_until, restore_last_backtrack_point,\n\tfree_topmost_backtrack_point, free_backtrack_queue,\n\testimate_insn_tick, estimate_shadow_tick): New functions.\n\t(prune_ready_list): New arg shadows_only_p.  All callers changed.\n\tIf true, remove everything that isn't SHADOW_P.  Look up delay\n\tpairs and estimate ticks to avoid scheduling the first insn too\n\tearly.\n\t(verify_shadows): New function.\n\t(schedule_block): Add machinery to enable backtracking.\n\t(sched_init): Take sched_no_dce into account when setting\n\tDF_LR_RUN_DCE.\n\t(free_delay_pairs): New function.\n\t(init_h_i_d): Initialize INSN_EXACT_TICK.\n\t* Makefile.in (haifa-sched.o): Add $(HASHTAB_H).\n\t* sched-deps.c (sd_unresolve_dep): New function.\n\t* sched-int.h (struct haifa_sched_info): New fields save_state\n\tand restore_state.\n\t(struct _haifa_insn_data): New fields exact_tick, tick_estimate,\n\tfeeds_backtrack_insn and shadow_p.\n\t(DO_BACKTRACKING): New value in enum SCHED_FLAGS.\n\t(sched_no_dce): Declare variable.\n\t(record_delay_slot_pair, free_delay_pairs, add_delay_dependencies,\n\tsd_unresolve_dep): Declare functions.\n\t* modulo-sched.c (sms_sched_info): Clear the two new fields.\n\t* sched-rgn.c (rgn_const_sched_info): Likewise.\n\t* sel-sched-ir.c (sched_sel_haifa_sched_info): Likewise.\n\t* sched-ebb.c (save_ebb_state, restore_ebb_state): New functions.\n\t(ebb_sched_info): Add them for the two new fields.\n\t(add_deps_for_risky_insns): Call add_delay_dependencies.\n\nFrom-SVN: r176255", "tree": {"sha": "4e1e85fd5f8f205e86e0086d2fff6edfa291e8bc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4e1e85fd5f8f205e86e0086d2fff6edfa291e8bc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/26965010b951a7bb5cc206fe55078c459a7e64e4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/26965010b951a7bb5cc206fe55078c459a7e64e4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/26965010b951a7bb5cc206fe55078c459a7e64e4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/26965010b951a7bb5cc206fe55078c459a7e64e4/comments", "author": null, "committer": null, "parents": [{"sha": "13b7a7b9d836ba00445b8c89dfd116e9362c65bd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/13b7a7b9d836ba00445b8c89dfd116e9362c65bd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/13b7a7b9d836ba00445b8c89dfd116e9362c65bd"}], "stats": {"total": 1071, "additions": 983, "deletions": 88}, "files": [{"sha": "0f5c3ae35abcf825a7fc2bbf42d3d1c9995634be", "filename": "gcc/ChangeLog", "status": "modified", "additions": 53, "deletions": 0, "changes": 53, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -1,3 +1,56 @@\n+2011-07-14  Bernd Schmidt  <bernds@codesourcery.com>\n+\n+\t* haifa-sched.c: Include \"hashtab.h\"\n+\t(sched_no_dce): New global variable.\n+\t(INSN_EXACT_TICK, INSN_TICK_ESTIMATE, FEEDS_BACKTRACK_INSN,\n+\tSHADOW_P): New macros.\n+\t(last_clock_var, cycle_issued_insns): Move declarations.\n+\t(must_backtrack): New static variable.\n+\t(struct delay_pair): New structure.\n+\t(delay_htab, delay_htab_i2): New static variables.\n+\t(delay_hash_i1, delay_hash_i2, delay_i1_eq, delay_i2_eq,\n+\trecord_delay_slot_pair, pair_delay, add_delay_dependencies): New\n+\tfunctions.\n+\t(dep_cost_1): If delay pairs exist, try to look up the insns and\n+\tuse the correct pair delay if we find them.\n+\t(rank-for_schedule): Tweak priority for insns that must be scheduled\n+\tsoon to avoid backtracking.\n+\t(queue_insn): Detect conditions which force backtracking.\n+\t(ready_add): Likewise.\n+\t(struct sched_block_state): Add member shadows_only_p.\n+\t(struct haifa_save_data): New structure.\n+\t(backtrack_queue): New static variable.\n+\t(mark_backtrack_feeds, copy_insn_list, save_backtrack_point,\n+\tunschedule_insns_until, restore_last_backtrack_point,\n+\tfree_topmost_backtrack_point, free_backtrack_queue,\n+\testimate_insn_tick, estimate_shadow_tick): New functions.\n+\t(prune_ready_list): New arg shadows_only_p.  All callers changed.\n+\tIf true, remove everything that isn't SHADOW_P.  Look up delay\n+\tpairs and estimate ticks to avoid scheduling the first insn too\n+\tearly.\n+\t(verify_shadows): New function.\n+\t(schedule_block): Add machinery to enable backtracking.\n+\t(sched_init): Take sched_no_dce into account when setting\n+\tDF_LR_RUN_DCE.\n+\t(free_delay_pairs): New function.\n+\t(init_h_i_d): Initialize INSN_EXACT_TICK.\n+\t* Makefile.in (haifa-sched.o): Add $(HASHTAB_H).\n+\t* sched-deps.c (sd_unresolve_dep): New function.\n+\t* sched-int. (struct haifa_sched_info): New fields save_state\n+\tand restore_state.\n+\t(struct _haifa_insn_data): New fields exact_tick, tick_estimate,\n+\tfeeds_backtrack_insn and shadow_p.\n+\t(DO_BACKTRACKING): New value in enum SCHED_FLAGS.\n+\t(sched_no_dce): Declare variable.\n+\t(record_delay_slot_pair, free_delay_pairs, add_delay_dependencies,\n+\tsd_unresolve_dep): Declare functions.\n+\t* modulo-sched.c (sms_sched_info): Clear the two new fields.\n+\t* sched-rgn.c (rgn_const_sched_info): Likewise.\n+\t* sel-sched-ir.c (sched_sel_haifa_sched_info): Likewise.\n+\t* sched-ebb.c (save_ebb_state, restore_ebb_state): New functions.\n+\t(ebb_sched_info): Add them for the two new fields.\n+\t(add_deps_for_risky_insns): Call add_delay_dependencies.\n+\n 2011-07-13  Michael Meissner  <meissner@linux.vnet.ibm.com>\n \n \t* config/rs6000/rs6000.opt (-mpointers-to-nested-functions):"}, {"sha": "0fded4e3988773858daf0e16ad955cf8c0b1ee23", "filename": "gcc/Makefile.in", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -3397,7 +3397,8 @@ modulo-sched.o : modulo-sched.c $(DDG_H) $(CONFIG_H) $(CONFIG_H) $(SYSTEM_H) \\\n haifa-sched.o : haifa-sched.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n    $(SCHED_INT_H) $(REGS_H) hard-reg-set.h $(FLAGS_H) insn-config.h $(FUNCTION_H) \\\n    $(INSN_ATTR_H) $(DIAGNOSTIC_CORE_H) $(RECOG_H) $(EXCEPT_H) $(TM_P_H) $(TARGET_H) output.h \\\n-   $(PARAMS_H) $(DBGCNT_H) $(CFGLOOP_H) ira.h $(EMIT_RTL_H) $(COMMON_TARGET_H)\n+   $(PARAMS_H) $(DBGCNT_H) $(CFGLOOP_H) ira.h $(EMIT_RTL_H) $(COMMON_TARGET_H) \\\n+   $(HASHTAB_H)\n sched-deps.o : sched-deps.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n    $(RTL_H) $(SCHED_INT_H) $(REGS_H) hard-reg-set.h $(FLAGS_H) insn-config.h \\\n    $(FUNCTION_H) $(INSN_ATTR_H) $(DIAGNOSTIC_CORE_H) $(RECOG_H) $(EXCEPT_H) cselib.h \\"}, {"sha": "3630924fa23132f186961e21a6e98910863662b2", "filename": "gcc/haifa-sched.c", "status": "modified", "additions": 773, "deletions": 16, "changes": 789, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fhaifa-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fhaifa-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhaifa-sched.c?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -149,6 +149,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"cfgloop.h\"\n #include \"ira.h\"\n #include \"emit-rtl.h\"  /* FIXME: Can go away once crtl is moved to rtl.h.  */\n+#include \"hashtab.h\"\n \n #ifdef INSN_SCHEDULING\n \n@@ -158,6 +159,10 @@ along with GCC; see the file COPYING3.  If not see\n \n int issue_rate;\n \n+/* This can be set to true by a backend if the scheduler should not\n+   enable a DCE pass.  */\n+bool sched_no_dce;\n+\n /* sched-verbose controls the amount of debugging output the\n    scheduler prints.  It is controlled by -fsched-verbose=N:\n    N>0 and no -DSR : the output is directed to stderr.\n@@ -178,7 +183,11 @@ FILE *sched_dump = 0;\n struct common_sched_info_def *common_sched_info;\n \n #define INSN_TICK(INSN)\t(HID (INSN)->tick)\n+#define INSN_EXACT_TICK(INSN) (HID (INSN)->exact_tick)\n+#define INSN_TICK_ESTIMATE(INSN) (HID (INSN)->tick_estimate)\n #define INTER_TICK(INSN) (HID (INSN)->inter_tick)\n+#define FEEDS_BACKTRACK_INSN(INSN) (HID (INSN)->feeds_backtrack_insn)\n+#define SHADOW_P(INSN) (HID (INSN)->shadow_p)\n \n /* If INSN_TICK of an instruction is equal to INVALID_TICK,\n    then it should be recalculated from scratch.  */\n@@ -303,6 +312,18 @@ static struct ready_list *readyp = &ready;\n /* Scheduling clock.  */\n static int clock_var;\n \n+/* Clock at which the previous instruction was issued.  */\n+static int last_clock_var;\n+\n+/* Set to true if, when queuing a shadow insn, we discover that it would be\n+   scheduled too late.  */\n+static bool must_backtrack;\n+\n+/* The following variable value is number of essential insns issued on\n+   the current cycle.  An insn is essential one if it changes the\n+   processors state.  */\n+int cycle_issued_insns;\n+\n /* This records the actual schedule.  It is built up during the main phase\n    of schedule_block, and afterwards used to reorder the insns in the RTL.  */\n static VEC(rtx, heap) *scheduled_insns;\n@@ -487,6 +508,147 @@ haifa_classify_insn (const_rtx insn)\n   return haifa_classify_rtx (PATTERN (insn));\n }\n \n+/* A structure to record a pair of insns where the first one is a real\n+   insn that has delay slots, and the second is its delayed shadow.\n+   I1 is scheduled normally and will emit an assembly instruction,\n+   while I2 describes the side effect that takes place at the\n+   transition between cycles CYCLES and (CYCLES + 1) after I1.  */\n+struct delay_pair\n+{\n+  struct delay_pair *next_same_i1;\n+  rtx i1, i2;\n+  int cycles;\n+};\n+\n+/* Two hash tables to record delay_pairs, one indexed by I1 and the other\n+   indexed by I2.  */\n+static htab_t delay_htab;\n+static htab_t delay_htab_i2;\n+\n+/* Returns a hash value for X (which really is a delay_pair), based on\n+   hashing just I1.  */\n+static hashval_t\n+delay_hash_i1 (const void *x)\n+{\n+  return htab_hash_pointer (((const struct delay_pair *) x)->i1);\n+}\n+\n+/* Returns a hash value for X (which really is a delay_pair), based on\n+   hashing just I2.  */\n+static hashval_t\n+delay_hash_i2 (const void *x)\n+{\n+  return htab_hash_pointer (((const struct delay_pair *) x)->i2);\n+}\n+\n+/* Return nonzero if I1 of pair X is the same as that of pair Y.  */\n+static int\n+delay_i1_eq (const void *x, const void *y)\n+{\n+  return ((const struct delay_pair *) x)->i1 == y;\n+}\n+\n+/* Return nonzero if I2 of pair X is the same as that of pair Y.  */\n+static int\n+delay_i2_eq (const void *x, const void *y)\n+{\n+  return ((const struct delay_pair *) x)->i2 == y;\n+}\n+\n+/* This function can be called by a port just before it starts the\n+   final scheduling pass.  It records the fact that an instruction\n+   with delay slots has been split into two insns, I1 and I2.  The\n+   first one will be scheduled normally and initiates the operation.\n+   The second one is a shadow which must follow a specific number of\n+   CYCLES after I1; its only purpose is to show the side effect that\n+   occurs at that cycle in the RTL.  If a JUMP_INSN or a CALL_INSN has\n+   been split, I1 should be a normal INSN, while I2 retains the\n+   original insn type.  */\n+\n+void\n+record_delay_slot_pair (rtx i1, rtx i2, int cycles)\n+{\n+  struct delay_pair *p = XNEW (struct delay_pair);\n+  struct delay_pair **slot;\n+\n+  p->i1 = i1;\n+  p->i2 = i2;\n+  p->cycles = cycles;\n+\n+  if (!delay_htab)\n+    {\n+      delay_htab = htab_create (10, delay_hash_i1, delay_i1_eq, NULL);\n+      delay_htab_i2 = htab_create (10, delay_hash_i2, delay_i2_eq, free);\n+    }\n+  slot = ((struct delay_pair **)\n+\t  htab_find_slot_with_hash (delay_htab, i1, htab_hash_pointer (i1),\n+\t\t\t\t    INSERT));\n+  p->next_same_i1 = *slot;\n+  *slot = p;\n+  slot = ((struct delay_pair **)\n+\t  htab_find_slot_with_hash (delay_htab_i2, i2, htab_hash_pointer (i2),\n+\t\t\t\t    INSERT));\n+  *slot = p;\n+}\n+\n+/* For a pair P of insns, return the fixed distance in cycles from the first\n+   insn after which the second must be scheduled.  */\n+static int\n+pair_delay (struct delay_pair *p)\n+{\n+  return p->cycles;\n+}\n+\n+/* Given an insn INSN, add a dependence on its delayed shadow if it\n+   has one.  Also try to find situations where shadows depend on each other\n+   and add dependencies to the real insns to limit the amount of backtracking\n+   needed.  */\n+void\n+add_delay_dependencies (rtx insn)\n+{\n+  struct delay_pair *pair;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+\n+  if (!delay_htab)\n+    return;\n+\n+  pair\n+    = (struct delay_pair *)htab_find_with_hash (delay_htab_i2, insn,\n+\t\t\t\t\t\thtab_hash_pointer (insn));\n+  if (!pair)\n+    return;\n+  add_dependence (insn, pair->i1, REG_DEP_ANTI);\n+\n+  FOR_EACH_DEP (pair->i2, SD_LIST_BACK, sd_it, dep)\n+    {\n+      rtx pro = DEP_PRO (dep);\n+      struct delay_pair *other_pair\n+\t= (struct delay_pair *)htab_find_with_hash (delay_htab_i2, pro,\n+\t\t\t\t\t\t    htab_hash_pointer (pro));\n+      if (!other_pair)\n+\tcontinue;\n+      if (pair_delay (other_pair) >= pair_delay (pair))\n+\t{\n+\t  if (sched_verbose >= 4)\n+\t    {\n+\t      fprintf (sched_dump, \";;\\tadding dependence %d <- %d\\n\",\n+\t\t       INSN_UID (other_pair->i1),\n+\t\t       INSN_UID (pair->i1));\n+\t      fprintf (sched_dump, \";;\\tpair1 %d <- %d, cost %d\\n\",\n+\t\t       INSN_UID (pair->i1),\n+\t\t       INSN_UID (pair->i2),\n+\t\t       pair_delay (pair));\n+\t      fprintf (sched_dump, \";;\\tpair2 %d <- %d, cost %d\\n\",\n+\t\t       INSN_UID (other_pair->i1),\n+\t\t       INSN_UID (other_pair->i2),\n+\t\t       pair_delay (other_pair));\n+\t    }\n+\t  add_dependence (pair->i1, other_pair->i1, REG_DEP_ANTI);\n+\t}\n+    }\n+}\n+\f\n /* Forward declarations.  */\n \n static int priority (rtx);\n@@ -857,6 +1019,22 @@ dep_cost_1 (dep_t link, dw_t dw)\n   if (DEP_COST (link) != UNKNOWN_DEP_COST)\n     return DEP_COST (link);\n \n+  if (delay_htab)\n+    {\n+      struct delay_pair *delay_entry;\n+      delay_entry\n+\t= (struct delay_pair *)htab_find_with_hash (delay_htab_i2, used,\n+\t\t\t\t\t\t    htab_hash_pointer (used));\n+      if (delay_entry)\n+\t{\n+\t  if (delay_entry->i1 == insn)\n+\t    {\n+\t      DEP_COST (link) = pair_delay (delay_entry);\n+\t      return DEP_COST (link);\n+\t    }\n+\t}\n+    }\n+\n   /* A USE insn should never require the value used to be computed.\n      This allows the computation of a function's result and parameter\n      values to overlap the return and call.  We don't care about the\n@@ -1213,6 +1391,17 @@ rank_for_schedule (const void *x, const void *y)\n       else\n \treturn INSN_TICK (tmp) - INSN_TICK (tmp2);\n     }\n+\n+  /* If we are doing backtracking in this schedule, prefer insns that\n+     have forward dependencies with negative cost against an insn that\n+     was already scheduled.  */\n+  if (current_sched_info->flags & DO_BACKTRACKING)\n+    {\n+      priority_val = FEEDS_BACKTRACK_INSN (tmp2) - FEEDS_BACKTRACK_INSN (tmp);\n+      if (priority_val)\n+\treturn priority_val;\n+    }\n+\n   /* Prefer insn with higher priority.  */\n   priority_val = INSN_PRIORITY (tmp2) - INSN_PRIORITY (tmp);\n \n@@ -1325,6 +1514,7 @@ queue_insn (rtx insn, int n_cycles, const char *reason)\n {\n   int next_q = NEXT_Q_AFTER (q_ptr, n_cycles);\n   rtx link = alloc_INSN_LIST (insn, insn_queue[next_q]);\n+  int new_tick;\n \n   gcc_assert (n_cycles <= max_insn_queue_index);\n   gcc_assert (!DEBUG_INSN_P (insn));\n@@ -1341,6 +1531,21 @@ queue_insn (rtx insn, int n_cycles, const char *reason)\n     }\n \n   QUEUE_INDEX (insn) = next_q;\n+\n+  if (current_sched_info->flags & DO_BACKTRACKING)\n+    {\n+      new_tick = clock_var + n_cycles;\n+      if (INSN_TICK (insn) == INVALID_TICK || INSN_TICK (insn) < new_tick)\n+\tINSN_TICK (insn) = new_tick;\n+\n+      if (INSN_EXACT_TICK (insn) != INVALID_TICK\n+\t  && INSN_EXACT_TICK (insn) < clock_var + n_cycles)\n+\t{\n+\t  must_backtrack = true;\n+\t  if (sched_verbose >= 2)\n+\t    fprintf (sched_dump, \";;\\t\\tcausing a backtrack.\\n\");\n+\t}\n+    }\n }\n \n /* Remove INSN from queue.  */\n@@ -1400,6 +1605,12 @@ ready_add (struct ready_list *ready, rtx insn, bool first_p)\n \n   gcc_assert (QUEUE_INDEX (insn) != QUEUE_READY);\n   QUEUE_INDEX (insn) = QUEUE_READY;\n+\n+  if (INSN_EXACT_TICK (insn) != INVALID_TICK\n+      && INSN_EXACT_TICK (insn) < clock_var)\n+    {\n+      must_backtrack = true;\n+    }\n }\n \n /* Remove the element with the highest priority from the ready list and\n@@ -1546,9 +1757,6 @@ advance_one_cycle (void)\n     fprintf (sched_dump, \";;\\tAdvanced a state.\\n\");\n }\n \n-/* Clock at which the previous instruction was issued.  */\n-static int last_clock_var;\n-\n /* Update register pressure after scheduling INSN.  */\n static void\n update_register_pressure (rtx insn)\n@@ -1644,6 +1852,9 @@ struct sched_block_state\n {\n   /* True if no real insns have been scheduled in the current cycle.  */\n   bool first_cycle_insn_p;\n+  /* True if a shadow insn has been scheduled in the current cycle, which\n+     means that no more normal insns can be issued.  */\n+  bool shadows_only_p;\n   /* Initialized with the machine's issue rate every cycle, and updated\n      by calls to the variable_issue hook.  */\n   int can_issue_more;\n@@ -1900,6 +2111,377 @@ remove_notes (rtx head, rtx tail)\n     }\n }\n \n+/* A structure to record enough data to allow us to backtrack the scheduler to\n+   a previous state.  */\n+struct haifa_saved_data\n+{\n+  /* Next entry on the list.  */\n+  struct haifa_saved_data *next;\n+\n+  /* Backtracking is associated with scheduling insns that have delay slots.\n+     DELAY_PAIR points to the structure that contains the insns involved, and\n+     the number of cycles between them.  */\n+  struct delay_pair *delay_pair;\n+\n+  /* Data used by the frontend (e.g. sched-ebb or sched-rgn).  */\n+  void *fe_saved_data;\n+  /* Data used by the backend.  */\n+  void *be_saved_data;\n+\n+  /* Copies of global state.  */\n+  int clock_var, last_clock_var;\n+  struct ready_list ready;\n+  state_t curr_state;\n+\n+  rtx last_scheduled_insn;\n+  rtx last_nondebug_scheduled_insn;\n+  int cycle_issued_insns;\n+\n+  /* Copies of state used in the inner loop of schedule_block.  */\n+  struct sched_block_state sched_block;\n+\n+  /* We don't need to save q_ptr, as its value is arbitrary and we can set it\n+     to 0 when restoring.  */\n+  int q_size;\n+  rtx *insn_queue;\n+};\n+\n+/* A record, in reverse order, of all scheduled insns which have delay slots\n+   and may require backtracking.  */\n+static struct haifa_saved_data *backtrack_queue;\n+\n+/* For every dependency of INSN, set the FEEDS_BACKTRACK_INSN bit according\n+   to SET_P.  */\n+static void\n+mark_backtrack_feeds (rtx insn, int set_p)\n+{\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+  FOR_EACH_DEP (insn, SD_LIST_HARD_BACK, sd_it, dep)\n+    {\n+      FEEDS_BACKTRACK_INSN (DEP_PRO (dep)) = set_p;\n+    }\n+}\n+\n+/* Make a copy of the INSN_LIST list LINK and return it.  */\n+static rtx\n+copy_insn_list (rtx link)\n+{\n+  rtx new_queue;\n+  rtx *pqueue = &new_queue;\n+\n+  for (; link; link = XEXP (link, 1))\n+    {\n+      rtx x = XEXP (link, 0);\n+      rtx newlink = alloc_INSN_LIST (x, NULL);\n+      *pqueue = newlink;\n+      pqueue = &XEXP (newlink, 1);\n+    }\n+  *pqueue = NULL_RTX;\n+  return new_queue;\n+}\n+\n+/* Save the current scheduler state so that we can backtrack to it\n+   later if necessary.  PAIR gives the insns that make it necessary to\n+   save this point.  SCHED_BLOCK is the local state of schedule_block\n+   that need to be saved.  */\n+static void\n+save_backtrack_point (struct delay_pair *pair,\n+\t\t      struct sched_block_state sched_block)\n+{\n+  int i;\n+  struct haifa_saved_data *save = XNEW (struct haifa_saved_data);\n+\n+  save->curr_state = xmalloc (dfa_state_size);\n+  memcpy (save->curr_state, curr_state, dfa_state_size);\n+\n+  save->ready.first = ready.first;\n+  save->ready.n_ready = ready.n_ready;\n+  save->ready.n_debug = ready.n_debug;\n+  save->ready.veclen = ready.veclen;\n+  save->ready.vec = XNEWVEC (rtx, ready.veclen);\n+  memcpy (save->ready.vec, ready.vec, ready.veclen * sizeof (rtx));\n+\n+  save->insn_queue = XNEWVEC (rtx, max_insn_queue_index + 1);\n+  save->q_size = q_size;\n+  for (i = 0; i <= max_insn_queue_index; i++)\n+    {\n+      int q = NEXT_Q_AFTER (q_ptr, i);\n+      save->insn_queue[i] = copy_insn_list (insn_queue[q]);\n+    }\n+\n+  save->clock_var = clock_var;\n+  save->last_clock_var = last_clock_var;\n+  save->cycle_issued_insns = cycle_issued_insns;\n+  save->last_scheduled_insn = last_scheduled_insn;\n+  save->last_nondebug_scheduled_insn = last_nondebug_scheduled_insn;\n+\n+  save->sched_block = sched_block;\n+\n+  if (current_sched_info->save_state)\n+    save->fe_saved_data = (*current_sched_info->save_state) ();\n+\n+  if (targetm.sched.alloc_sched_context)\n+    {\n+      save->be_saved_data = targetm.sched.alloc_sched_context ();\n+      targetm.sched.init_sched_context (save->be_saved_data, false);\n+    }\n+  else\n+    save->be_saved_data = NULL;\n+\n+  save->delay_pair = pair;\n+\n+  save->next = backtrack_queue;\n+  backtrack_queue = save;\n+\n+  while (pair)\n+    {\n+      mark_backtrack_feeds (pair->i2, 1);\n+      INSN_TICK (pair->i2) = INVALID_TICK;\n+      INSN_EXACT_TICK (pair->i2) = clock_var + pair_delay (pair);\n+      SHADOW_P (pair->i2) = true;\n+      pair = pair->next_same_i1;\n+    }\n+}\n+\n+/* Pop entries from the SCHEDULED_INSNS vector up to and including INSN.\n+   Restore their dependencies to an unresolved state, and mark them as\n+   queued nowhere.  */\n+\n+static void\n+unschedule_insns_until (rtx insn)\n+{\n+  for (;;)\n+    {\n+      rtx last;\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n+\n+      last = VEC_pop (rtx, scheduled_insns);\n+\n+      /* This will be changed by restore_backtrack_point if the insn is in\n+\t any queue.  */\n+      QUEUE_INDEX (last) = QUEUE_NOWHERE;\n+      if (last != insn)\n+\tINSN_TICK (last) = INVALID_TICK;\n+\n+      for (sd_it = sd_iterator_start (last, SD_LIST_RES_FORW);\n+\t   sd_iterator_cond (&sd_it, &dep);)\n+\t{\n+\t  rtx con = DEP_CON (dep);\n+\t  TODO_SPEC (con) |= HARD_DEP;\n+\t  INSN_TICK (con) = INVALID_TICK;\n+\t  sd_unresolve_dep (sd_it);\n+\t}\n+\n+      if (last == insn)\n+\tbreak;\n+    }\n+}\n+\n+/* Restore scheduler state from the topmost entry on the backtracking queue.\n+   PSCHED_BLOCK_P points to the local data of schedule_block that we must\n+   overwrite with the saved data.\n+   The caller must already have called unschedule_insns_until.  */\n+\n+static void\n+restore_last_backtrack_point (struct sched_block_state *psched_block)\n+\n+{\n+  rtx link;\n+  int i;\n+  struct haifa_saved_data *save = backtrack_queue;\n+\n+  backtrack_queue = save->next;\n+\n+  if (current_sched_info->restore_state)\n+    (*current_sched_info->restore_state) (save->fe_saved_data);\n+\n+  if (targetm.sched.alloc_sched_context)\n+    {\n+      targetm.sched.set_sched_context (save->be_saved_data);\n+      targetm.sched.free_sched_context (save->be_saved_data);\n+    }\n+\n+  /* Clear the QUEUE_INDEX of everything in the ready list or one\n+     of the queues.  */\n+  if (ready.n_ready > 0)\n+    {\n+      rtx *first = ready_lastpos (&ready);\n+      for (i = 0; i < ready.n_ready; i++)\n+\t{\n+\t  QUEUE_INDEX (first[i]) = QUEUE_NOWHERE;\n+\t  INSN_TICK (first[i]) = INVALID_TICK;\n+\t}\n+    }\n+  for (i = 0; i <= max_insn_queue_index; i++)\n+    {\n+      int q = NEXT_Q_AFTER (q_ptr, i);\n+\n+      for (link = insn_queue[q]; link; link = XEXP (link, 1))\n+\t{\n+\t  rtx x = XEXP (link, 0);\n+\t  QUEUE_INDEX (x) = QUEUE_NOWHERE;\n+\t  INSN_TICK (x) = INVALID_TICK;\n+\t}\n+      free_INSN_LIST_list (&insn_queue[q]);\n+    }\n+\n+  free (ready.vec);\n+  ready = save->ready;\n+\n+  if (ready.n_ready > 0)\n+    {\n+      rtx *first = ready_lastpos (&ready);\n+      for (i = 0; i < ready.n_ready; i++)\n+\t{\n+\t  QUEUE_INDEX (first[i]) = QUEUE_READY;\n+\t  INSN_TICK (first[i]) = save->clock_var;\n+\t}\n+    }\n+\n+  q_ptr = 0;\n+  q_size = save->q_size;\n+  for (i = 0; i <= max_insn_queue_index; i++)\n+    {\n+      int q = NEXT_Q_AFTER (q_ptr, i);\n+\n+      insn_queue[q] = save->insn_queue[q];\n+\n+      for (link = insn_queue[q]; link; link = XEXP (link, 1))\n+\t{\n+\t  rtx x = XEXP (link, 0);\n+\t  QUEUE_INDEX (x) = i;\n+\t  INSN_TICK (x) = save->clock_var + i;\n+\t}\n+    }\n+  free (save->insn_queue);\n+\n+  clock_var = save->clock_var;\n+  last_clock_var = save->last_clock_var;\n+  cycle_issued_insns = save->cycle_issued_insns;\n+  last_scheduled_insn = save->last_scheduled_insn;\n+  last_nondebug_scheduled_insn = save->last_nondebug_scheduled_insn;\n+\n+  *psched_block = save->sched_block;\n+\n+  memcpy (curr_state, save->curr_state, dfa_state_size);\n+  free (save->curr_state);\n+\n+  mark_backtrack_feeds (save->delay_pair->i2, 0);\n+\n+  free (save);\n+\n+  for (save = backtrack_queue; save; save = save->next)\n+    {\n+      mark_backtrack_feeds (save->delay_pair->i2, 1);\n+    }\n+}\n+\n+/* Discard all data associated with the topmost entry in the backtrack\n+   queue.  If RESET_TICK is false, we just want to free the data.  If true,\n+   we are doing this because we discovered a reason to backtrack.  In the\n+   latter case, also reset the INSN_TICK for the shadow insn.  */\n+static void\n+free_topmost_backtrack_point (bool reset_tick)\n+{\n+  struct haifa_saved_data *save = backtrack_queue;\n+  int i;\n+\n+  backtrack_queue = save->next;\n+\n+  if (reset_tick)\n+    {\n+      struct delay_pair *pair = save->delay_pair;\n+      while (pair)\n+\t{\n+\t  INSN_TICK (pair->i2) = INVALID_TICK;\n+\t  INSN_EXACT_TICK (pair->i2) = INVALID_TICK;\n+\t  pair = pair->next_same_i1;\n+\t}\n+    }\n+  if (targetm.sched.free_sched_context)\n+    targetm.sched.free_sched_context (save->be_saved_data);\n+  if (current_sched_info->restore_state)\n+    free (save->fe_saved_data);\n+  for (i = 0; i <= max_insn_queue_index; i++)\n+    free_INSN_LIST_list (&save->insn_queue[i]);\n+  free (save->insn_queue);\n+  free (save->curr_state);\n+  free (save->ready.vec);\n+  free (save);\n+}\n+\n+/* Free the entire backtrack queue.  */\n+static void\n+free_backtrack_queue (void)\n+{\n+  while (backtrack_queue)\n+    free_topmost_backtrack_point (false);\n+}\n+\n+/* Compute INSN_TICK_ESTIMATE for INSN.  PROCESSED is a bitmap of\n+   instructions we've previously encountered, a set bit prevents\n+   recursion.  BUDGET is a limit on how far ahead we look, it is\n+   reduced on recursive calls.  Return true if we produced a good\n+   estimate, or false if we exceeded the budget.  */\n+static bool\n+estimate_insn_tick (bitmap processed, rtx insn, int budget)\n+{\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+  int earliest = INSN_TICK (insn);\n+\n+  FOR_EACH_DEP (insn, SD_LIST_BACK, sd_it, dep)\n+    {\n+      rtx pro = DEP_PRO (dep);\n+      int t;\n+\n+      if (QUEUE_INDEX (pro) == QUEUE_SCHEDULED)\n+\tgcc_assert (INSN_TICK (pro) + dep_cost (dep) <= INSN_TICK (insn));\n+      else\n+\t{\n+\t  int cost = dep_cost (dep);\n+\t  if (cost >= budget)\n+\t    return false;\n+\t  if (!bitmap_bit_p (processed, INSN_LUID (pro)))\n+\t    {\n+\t      if (!estimate_insn_tick (processed, pro, budget - cost))\n+\t\treturn false;\n+\t    }\n+\t  gcc_assert (INSN_TICK_ESTIMATE (pro) != INVALID_TICK);\n+\t  t = INSN_TICK_ESTIMATE (pro) + cost;\n+\t  if (earliest == INVALID_TICK || t > earliest)\n+\t    earliest = t;\n+\t}\n+    }\n+  bitmap_set_bit (processed, INSN_LUID (insn));\n+  INSN_TICK_ESTIMATE (insn) = earliest;\n+  return true;\n+}\n+\n+/* Examine the pair of insns in P, and estimate (optimistically, assuming\n+   infinite resources) the cycle in which the delayed shadow can be issued.\n+   Return the number of cycles that must pass before the real insn can be\n+   issued in order to meet this constraint.  */\n+static int\n+estimate_shadow_tick (struct delay_pair *p)\n+{\n+  bitmap_head processed;\n+  int t;\n+  bool cutoff;\n+  bitmap_initialize (&processed, 0);\n+\n+  cutoff = !estimate_insn_tick (&processed, p->i2,\n+\t\t\t\tmax_insn_queue_index + pair_delay (p));\n+  bitmap_clear (&processed);\n+  if (cutoff)\n+    return max_insn_queue_index;\n+  t = INSN_TICK_ESTIMATE (p->i2) - (clock_var + pair_delay (p) + 1);\n+  if (t > 0)\n+    return t;\n+  return 0;\n+}\n \n /* Return the head and tail pointers of ebb starting at BEG and ending\n    at END.  */\n@@ -2467,11 +3049,6 @@ struct choice_entry\n    function max_issue.  */\n static struct choice_entry *choice_stack;\n \n-/* The following variable value is number of essential insns issued on\n-   the current cycle.  An insn is essential one if it changes the\n-   processors state.  */\n-int cycle_issued_insns;\n-\n /* This holds the value of the target dfa_lookahead hook.  */\n int dfa_lookahead;\n \n@@ -2884,10 +3461,18 @@ commit_schedule (rtx prev_head, rtx tail, basic_block *target_bb)\n    issued in this cycle.  TEMP_STATE is temporary scheduler state we\n    can use as scratch space.  If FIRST_CYCLE_INSN_P is true, no insns\n    have been issued for the current cycle, which means it is valid to\n-   issue an asm statement.  */\n+   issue an asm statement.\n+\n+   If SHADOWS_ONLY_P is true, we eliminate all real insns and only\n+   leave those for which SHADOW_P is true.\n+\n+   Return the number of cycles we must\n+   advance to find the next ready instruction, or zero if there remain\n+   insns on the ready list.  */\n \n static void\n-prune_ready_list (state_t temp_state, bool first_cycle_insn_p)\n+prune_ready_list (state_t temp_state, bool first_cycle_insn_p,\n+\t\t  bool shadows_only_p)\n {\n   int i;\n \n@@ -2898,7 +3483,12 @@ prune_ready_list (state_t temp_state, bool first_cycle_insn_p)\n       int cost = 0;\n       const char *reason = \"resource conflict\";\n \n-      if (recog_memoized (insn) < 0)\n+      if (shadows_only_p && !DEBUG_INSN_P (insn) && !SHADOW_P (insn))\n+\t{\n+\t  cost = 1;\n+\t  reason = \"not a shadow\";\n+\t}\n+      else if (recog_memoized (insn) < 0)\n \t{\n \t  if (!first_cycle_insn_p\n \t      && (GET_CODE (PATTERN (insn)) == ASM_INPUT\n@@ -2910,12 +3500,34 @@ prune_ready_list (state_t temp_state, bool first_cycle_insn_p)\n \tcost = 0;\n       else\n \t{\n+\t  int delay_cost = 0;\n+\n+\t  if (delay_htab)\n+\t    {\n+\t      struct delay_pair *delay_entry;\n+\t      delay_entry\n+\t\t= (struct delay_pair *)htab_find_with_hash (delay_htab, insn,\n+\t\t\t\t\t\t\t    htab_hash_pointer (insn));\n+\t      while (delay_entry && delay_cost == 0)\n+\t\t{\n+\t\t  delay_cost = estimate_shadow_tick (delay_entry);\n+\t\t  if (delay_cost > max_insn_queue_index)\n+\t\t    delay_cost = max_insn_queue_index;\n+\t\t  delay_entry = delay_entry->next_same_i1;\n+\t\t}\n+\t    }\n+\n \t  memcpy (temp_state, curr_state, dfa_state_size);\n \t  cost = state_transition (temp_state, insn);\n \t  if (cost < 0)\n \t    cost = 0;\n \t  else if (cost == 0)\n \t    cost = 1;\n+\t  if (cost < delay_cost)\n+\t    {\n+\t      cost = delay_cost;\n+\t      reason = \"shadow tick\";\n+\t    }\n \t}\n       if (cost >= 1)\n \t{\n@@ -2926,6 +3538,60 @@ prune_ready_list (state_t temp_state, bool first_cycle_insn_p)\n     }\n }\n \n+/* Called when we detect that the schedule is impossible.  We examine the\n+   backtrack queue to find the earliest insn that caused this condition.  */\n+\n+static struct haifa_saved_data *\n+verify_shadows (void)\n+{\n+  struct haifa_saved_data *save, *earliest_fail = NULL;\n+  for (save = backtrack_queue; save; save = save->next)\n+    {\n+      int t;\n+      struct delay_pair *pair = save->delay_pair;\n+      rtx i1 = pair->i1;\n+\n+      for (; pair; pair = pair->next_same_i1)\n+\t{\n+\t  rtx i2 = pair->i2;\n+\n+\t  if (QUEUE_INDEX (i2) == QUEUE_SCHEDULED)\n+\t    continue;\n+\n+\t  t = INSN_TICK (i1) + pair_delay (pair);\n+\t  if (t < clock_var)\n+\t    {\n+\t      if (sched_verbose >= 2)\n+\t\tfprintf (sched_dump,\n+\t\t\t \";;\\t\\tfailed delay requirements for %d/%d (%d->%d)\"\n+\t\t\t \", not ready\\n\",\n+\t\t\t INSN_UID (pair->i1), INSN_UID (pair->i2),\n+\t\t\t INSN_TICK (pair->i1), INSN_EXACT_TICK (pair->i2));\n+\t      earliest_fail = save;\n+\t      break;\n+\t    }\n+\t  if (QUEUE_INDEX (i2) >= 0)\n+\t    {\n+\t      int queued_for = INSN_TICK (i2);\n+\n+\t      if (t < queued_for)\n+\t\t{\n+\t\t  if (sched_verbose >= 2)\n+\t\t    fprintf (sched_dump,\n+\t\t\t     \";;\\t\\tfailed delay requirements for %d/%d\"\n+\t\t\t     \" (%d->%d), queued too late\\n\",\n+\t\t\t     INSN_UID (pair->i1), INSN_UID (pair->i2),\n+\t\t\t     INSN_TICK (pair->i1), INSN_EXACT_TICK (pair->i2));\n+\t\t  earliest_fail = save;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\t}\n+    }\n+\n+  return earliest_fail;\n+}\n+\n /* Use forward list scheduling to rearrange insns of block pointed to by\n    TARGET_BB, possibly bringing insns from subsequent blocks in the same\n    region.  */\n@@ -2955,6 +3621,8 @@ schedule_block (basic_block *target_bb)\n \n   haifa_recovery_bb_recently_added_p = false;\n \n+  backtrack_queue = NULL;\n+\n   /* Debug info.  */\n   if (sched_verbose)\n     dump_new_block_header (0, *target_bb, head, tail);\n@@ -3051,6 +3719,8 @@ schedule_block (basic_block *target_bb)\n \n   gcc_assert (VEC_length (rtx, scheduled_insns) == 0);\n   sort_p = TRUE;\n+  must_backtrack = false;\n+\n   /* Loop until all the insns in BB are scheduled.  */\n   while ((*current_sched_info->schedule_more_p) ())\n     {\n@@ -3080,18 +3750,21 @@ schedule_block (basic_block *target_bb)\n       while (advance > 0);\n \n       if (ready.n_ready > 0)\n-\tprune_ready_list (temp_state, true);\n+\tprune_ready_list (temp_state, true, false);\n       if (ready.n_ready == 0)\n \tcontinue;\n+      if (must_backtrack)\n+\tgoto do_backtrack;\n \n       ls.first_cycle_insn_p = true;\n+      ls.shadows_only_p = false;\n       cycle_issued_insns = 0;\n       ls.can_issue_more = issue_rate;\n       for (;;)\n \t{\n \t  rtx insn;\n \t  int cost;\n-\t  bool asm_p = false;\n+\t  bool asm_p;\n \n \t  if (sort_p && ready.n_ready > 0)\n \t    {\n@@ -3130,6 +3803,7 @@ schedule_block (basic_block *target_bb)\n \t  if (ls.first_cycle_insn_p && !ready.n_ready)\n \t    break;\n \n+\tresume_after_backtrack:\n \t  /* Allow the target to reorder the list, typically for\n \t     better instruction bundling.  */\n \t  if (sort_p\n@@ -3236,6 +3910,22 @@ schedule_block (basic_block *target_bb)\n \t      goto restart_choose_ready;\n \t    }\n \n+\t  if (delay_htab)\n+\t    {\n+\t      /* If this insn is the first part of a delay-slot pair, record a\n+\t\t backtrack point.  */\n+\t      struct delay_pair *delay_entry;\n+\t      delay_entry\n+\t\t= (struct delay_pair *)htab_find_with_hash (delay_htab, insn,\n+\t\t\t\t\t\t\t    htab_hash_pointer (insn));\n+\t      if (delay_entry)\n+\t\t{\n+\t\t  save_backtrack_point (delay_entry, ls);\n+\t\t  if (sched_verbose >= 2)\n+\t\t    fprintf (sched_dump, \";;\\t\\tsaving backtrack point\\n\");\n+\t\t}\n+\t    }\n+\n \t  /* DECISION is made.  */\n \n           if (TODO_SPEC (insn) & SPECULATIVE)\n@@ -3275,18 +3965,70 @@ schedule_block (basic_block *target_bb)\n \t    ls.can_issue_more--;\n \t  advance = schedule_insn (insn);\n \n+\t  if (SHADOW_P (insn))\n+\t    ls.shadows_only_p = true;\n+\n \t  /* After issuing an asm insn we should start a new cycle.  */\n \t  if (advance == 0 && asm_p)\n \t    advance = 1;\n+\n+\t  if (must_backtrack)\n+\t    break;\n+\n \t  if (advance != 0)\n \t    break;\n \n \t  ls.first_cycle_insn_p = false;\n \t  if (ready.n_ready > 0)\n-\t    prune_ready_list (temp_state, false);\n+\t    prune_ready_list (temp_state, false, ls.shadows_only_p);\n \t}\n-    }\n \n+    do_backtrack:\n+      if (!must_backtrack)\n+\tfor (i = 0; i < ready.n_ready; i++)\n+\t  {\n+\t    rtx insn = ready_element (&ready, i);\n+\t    if (INSN_EXACT_TICK (insn) == clock_var)\n+\t      {\n+\t\tmust_backtrack = true;\n+\t\tclock_var++;\n+\t\tbreak;\n+\t      }\n+\t  }\n+      while (must_backtrack)\n+\t{\n+\t  struct haifa_saved_data *failed;\n+\t  rtx failed_insn;\n+\n+\t  must_backtrack = false;\n+\t  failed = verify_shadows ();\n+\t  gcc_assert (failed);\n+\n+\t  failed_insn = failed->delay_pair->i1;\n+\t  unschedule_insns_until (failed_insn);\n+\t  while (failed != backtrack_queue)\n+\t    free_topmost_backtrack_point (true);\n+\t  restore_last_backtrack_point (&ls);\n+\t  if (sched_verbose >= 2)\n+\t    fprintf (sched_dump, \";;\\t\\trewind to cycle %d\\n\", clock_var);\n+\t  /* Delay by at least a cycle.  This could cause additional\n+\t     backtracking.  */\n+\t  queue_insn (failed_insn, 1, \"backtracked\");\n+\t  advance = 0;\n+\t  if (must_backtrack)\n+\t    continue;\n+\t  if (ready.n_ready > 0)\n+\t    goto resume_after_backtrack;\n+\t  else\n+\t    {\n+\t      if (clock_var == 0 && ls.first_cycle_insn_p)\n+\t\tgoto end_schedule;\n+\t      advance = 1;\n+\t      break;\n+\t    }\n+\t}\n+    }\n+ end_schedule:\n   /* Debug info.  */\n   if (sched_verbose)\n     {\n@@ -3364,6 +4106,8 @@ schedule_block (basic_block *target_bb)\n \n   current_sched_info->head = head;\n   current_sched_info->tail = tail;\n+\n+  free_backtrack_queue ();\n }\n \f\n /* Set_priorities: compute priority of each insn in the block.  */\n@@ -3488,7 +4232,8 @@ sched_init (void)\n \n   init_alias_analysis ();\n \n-  df_set_flags (DF_LR_RUN_DCE);\n+  if (!sched_no_dce)\n+    df_set_flags (DF_LR_RUN_DCE);\n   df_note_add_problem ();\n \n   /* More problems needed for interloop dep calculation in SMS.  */\n@@ -3653,6 +4398,17 @@ sched_finish (void)\n #endif\n }\n \n+/* Free all delay_pair structures that were recorded.  */\n+void\n+free_delay_pairs (void)\n+{\n+  if (delay_htab)\n+    {\n+      htab_empty (delay_htab);\n+      htab_empty (delay_htab_i2);\n+    }\n+}\n+\n /* Fix INSN_TICKs of the instructions in the current block as well as\n    INSN_TICKs of their dependents.\n    HEAD and TAIL are the begin and the end of the current scheduled block.  */\n@@ -5453,6 +6209,7 @@ init_h_i_d (rtx insn)\n       INSN_COST (insn) = -1;\n       QUEUE_INDEX (insn) = QUEUE_NOWHERE;\n       INSN_TICK (insn) = INVALID_TICK;\n+      INSN_EXACT_TICK (insn) = INVALID_TICK;\n       INTER_TICK (insn) = INVALID_TICK;\n       TODO_SPEC (insn) = HARD_DEP;\n     }"}, {"sha": "85e24d4bfb071d54e4089e3692a977d2d36eb002", "filename": "gcc/modulo-sched.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fmodulo-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fmodulo-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmodulo-sched.c?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -283,6 +283,7 @@ static struct haifa_sched_info sms_sched_info =\n   0, 0,\n \n   NULL, NULL, NULL, NULL,\n+  NULL, NULL,\n   0\n };\n "}, {"sha": "0bba96c995e7280e08287e08e9bbfb61cca1d4f9", "filename": "gcc/sched-deps.c", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-deps.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-deps.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-deps.c?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -1301,6 +1301,28 @@ sd_resolve_dep (sd_iterator_def sd_it)\n \t\t INSN_RESOLVED_FORW_DEPS (pro));\n }\n \n+/* Perform the inverse operation of sd_resolve_dep.  Restore the dependence\n+   pointed to by SD_IT to unresolved state.  */\n+void\n+sd_unresolve_dep (sd_iterator_def sd_it)\n+{\n+  dep_node_t node = DEP_LINK_NODE (*sd_it.linkp);\n+  dep_t dep = DEP_NODE_DEP (node);\n+  rtx pro = DEP_PRO (dep);\n+  rtx con = DEP_CON (dep);\n+\n+  if ((current_sched_info->flags & DO_SPECULATION)\n+      && (DEP_STATUS (dep) & SPECULATIVE))\n+    move_dep_link (DEP_NODE_BACK (node), INSN_RESOLVED_BACK_DEPS (con),\n+\t\t   INSN_SPEC_BACK_DEPS (con));\n+  else\n+    move_dep_link (DEP_NODE_BACK (node), INSN_RESOLVED_BACK_DEPS (con),\n+\t\t   INSN_HARD_BACK_DEPS (con));\n+\n+  move_dep_link (DEP_NODE_FORW (node), INSN_RESOLVED_FORW_DEPS (pro),\n+\t\t INSN_FORW_DEPS (pro));\n+}\n+\n /* Make TO depend on all the FROM's producers.\n    If RESOLVED_P is true add dependencies to the resolved lists.  */\n void"}, {"sha": "47ce3421b28a91d1e20db1108f188933c016dfa3", "filename": "gcc/sched-ebb.c", "status": "modified", "additions": 97, "deletions": 70, "changes": 167, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-ebb.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-ebb.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-ebb.c?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -74,6 +74,25 @@ static void ebb_add_block (basic_block, basic_block);\n static basic_block advance_target_bb (basic_block, rtx);\n static void ebb_fix_recovery_cfg (int, int, int);\n \n+/* Allocate memory and store the state of the frontend.  Return the allocated\n+   memory.  */\n+static void *\n+save_ebb_state (void)\n+{\n+  int *p = XNEW (int);\n+  *p = sched_rgn_n_insns;\n+  return p;\n+}\n+\n+/* Restore the state of the frontend from P_, then free it.  */\n+static void\n+restore_ebb_state (void *p_)\n+{\n+  int *p = (int *)p_;\n+  sched_rgn_n_insns = *p;\n+  free (p_);\n+}\n+\n /* Return nonzero if there are more insns that should be scheduled.  */\n \n static int\n@@ -295,6 +314,10 @@ static struct haifa_sched_info ebb_sched_info =\n   begin_schedule_ready,\n   begin_move_insn,\n   advance_target_bb,\n+\n+  save_ebb_state,\n+  restore_ebb_state,\n+\n   SCHED_EBB\n   /* We can create new blocks in begin_schedule_ready ().  */\n   | NEW_BBS\n@@ -377,76 +400,80 @@ add_deps_for_risky_insns (rtx head, rtx tail)\n   basic_block last_block = NULL, bb;\n \n   for (insn = head; insn != next_tail; insn = NEXT_INSN (insn))\n-    if (control_flow_insn_p (insn))\n-      {\n-\tbb = BLOCK_FOR_INSN (insn);\n-\tbb->aux = last_block;\n-\tlast_block = bb;\n-\tlast_jump = insn;\n-      }\n-    else if (INSN_P (insn) && last_jump != NULL_RTX)\n-      {\n-\tclassification = haifa_classify_insn (insn);\n-\tprev = last_jump;\n-\tswitch (classification)\n-\t  {\n-\t  case PFREE_CANDIDATE:\n-\t    if (flag_schedule_speculative_load)\n-\t      {\n-\t\tbb = earliest_block_with_similiar_load (last_block, insn);\n-\t\tif (bb)\n-\t\t  {\n-\t\t    bb = (basic_block) bb->aux;\n-\t\t    if (!bb)\n-\t\t      break;\n-\t\t    prev = BB_END (bb);\n-\t\t  }\n-\t      }\n-\t    /* Fall through.  */\n-\t  case TRAP_RISKY:\n-\t  case IRISKY:\n-\t  case PRISKY_CANDIDATE:\n-\t    /* ??? We could implement better checking PRISKY_CANDIDATEs\n-\t       analogous to sched-rgn.c.  */\n-\t    /* We can not change the mode of the backward\n-\t       dependency because REG_DEP_ANTI has the lowest\n-\t       rank.  */\n-\t    if (! sched_insns_conditions_mutex_p (insn, prev))\n-\t      {\n-\t\tdep_def _dep, *dep = &_dep;\n-\n-\t\tinit_dep (dep, prev, insn, REG_DEP_ANTI);\n-\n-\t\tif (!(current_sched_info->flags & USE_DEPS_LIST))\n-\t\t  {\n-\t\t    enum DEPS_ADJUST_RESULT res;\n-\n-\t\t    res = sd_add_or_update_dep (dep, false);\n-\n-\t\t    /* We can't change an existing dependency with\n-\t\t       DEP_ANTI.  */\n-\t\t    gcc_assert (res != DEP_CHANGED);\n-\t\t  }\n-\t\telse\n-\t\t  {\n-\t\t    if ((current_sched_info->flags & DO_SPECULATION)\n-\t\t\t&& (spec_info->mask & BEGIN_CONTROL))\n-\t\t      DEP_STATUS (dep) = set_dep_weak (DEP_ANTI, BEGIN_CONTROL,\n-\t\t\t\t\t\t       MAX_DEP_WEAK);\n-\n-\t\t    sd_add_or_update_dep (dep, false);\n-\n-\t\t    /* Dep_status could have been changed.\n-\t\t       No assertion here.  */\n-\t\t  }\n-\t      }\n-\n-            break;\n-\n-          default:\n-            break;\n-\t  }\n-      }\n+    {\n+      add_delay_dependencies (insn);\n+      if (control_flow_insn_p (insn))\n+\t{\n+\t  bb = BLOCK_FOR_INSN (insn);\n+\t  bb->aux = last_block;\n+\t  last_block = bb;\n+\t  last_jump = insn;\n+\t}\n+      else if (INSN_P (insn) && last_jump != NULL_RTX)\n+\t{\n+\t  classification = haifa_classify_insn (insn);\n+\t  prev = last_jump;\n+\n+\t  switch (classification)\n+\t    {\n+\t    case PFREE_CANDIDATE:\n+\t      if (flag_schedule_speculative_load)\n+\t\t{\n+\t\t  bb = earliest_block_with_similiar_load (last_block, insn);\n+\t\t  if (bb)\n+\t\t    {\n+\t\t      bb = (basic_block) bb->aux;\n+\t\t      if (!bb)\n+\t\t\tbreak;\n+\t\t      prev = BB_END (bb);\n+\t\t    }\n+\t\t}\n+\t      /* Fall through.  */\n+\t    case TRAP_RISKY:\n+\t    case IRISKY:\n+\t    case PRISKY_CANDIDATE:\n+\t      /* ??? We could implement better checking PRISKY_CANDIDATEs\n+\t\t analogous to sched-rgn.c.  */\n+\t      /* We can not change the mode of the backward\n+\t\t dependency because REG_DEP_ANTI has the lowest\n+\t\t rank.  */\n+\t      if (! sched_insns_conditions_mutex_p (insn, prev))\n+\t\t{\n+\t\t  dep_def _dep, *dep = &_dep;\n+\n+\t\t  init_dep (dep, prev, insn, REG_DEP_ANTI);\n+\n+\t\t  if (!(current_sched_info->flags & USE_DEPS_LIST))\n+\t\t    {\n+\t\t      enum DEPS_ADJUST_RESULT res;\n+\n+\t\t      res = sd_add_or_update_dep (dep, false);\n+\n+\t\t      /* We can't change an existing dependency with\n+\t\t\t DEP_ANTI.  */\n+\t\t      gcc_assert (res != DEP_CHANGED);\n+\t\t    }\n+\t\t  else\n+\t\t    {\n+\t\t      if ((current_sched_info->flags & DO_SPECULATION)\n+\t\t\t  && (spec_info->mask & BEGIN_CONTROL))\n+\t\t\tDEP_STATUS (dep) = set_dep_weak (DEP_ANTI, BEGIN_CONTROL,\n+\t\t\t\t\t\t\t MAX_DEP_WEAK);\n+\n+\t\t      sd_add_or_update_dep (dep, false);\n+\n+\t\t      /* Dep_status could have been changed.\n+\t\t\t No assertion here.  */\n+\t\t    }\n+\t\t}\n+\n+\t      break;\n+\n+\t    default:\n+\t      break;\n+\t    }\n+\t}\n+    }\n   /* Maintain the invariant that bb->aux is clear after use.  */\n   while (last_block)\n     {"}, {"sha": "348a3cccf2bb2b570392bb5256b4f7b0494a5892", "filename": "gcc/sched-int.h", "status": "modified", "additions": 30, "deletions": 1, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-int.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-int.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-int.h?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -603,6 +603,13 @@ struct haifa_sched_info\n      The first parameter is the current basic block in EBB.  */\n   basic_block (*advance_target_bb) (basic_block, rtx);\n \n+  /* Allocate memory, store the frontend scheduler state in it, and\n+     return it.  */\n+  void *(*save_state) (void);\n+  /* Restore frontend scheduler state from the argument, and free the\n+     memory.  */\n+  void (*restore_state) (void *);\n+\n   /* ??? FIXME: should use straight bitfields inside sched_info instead of\n      this flag field.  */\n   unsigned int flags;\n@@ -762,10 +769,18 @@ struct _haifa_insn_data\n      used to note timing constraints for the insns in the pending list.  */\n   int tick;\n \n+  /* For insns that are scheduled at a fixed difference from another,\n+     this records the tick in which they must be ready.  */\n+  int exact_tick;\n+\n   /* INTER_TICK is used to adjust INSN_TICKs of instructions from the\n      subsequent blocks in a region.  */\n   int inter_tick;\n \n+  /* Used temporarily to estimate an INSN_TICK value for an insn given\n+     current knowledge.  */\n+  int tick_estimate;\n+\n   /* See comment on QUEUE_INDEX macro in haifa-sched.c.  */\n   int queue_index;\n \n@@ -775,6 +790,14 @@ struct _haifa_insn_data\n      moved load insn and this one.  */\n   unsigned int fed_by_spec_load : 1;\n   unsigned int is_load_insn : 1;\n+  /* Nonzero if this insn has negative-cost forward dependencies against\n+     an already scheduled insn.  */\n+  unsigned int feeds_backtrack_insn : 1;\n+\n+  /* Nonzero if this insn is a shadow of another, scheduled after a fixed\n+     delay.  We only emit shadows at the end of a cycle, with no other\n+     real insns following them.  */\n+  unsigned int shadow_p : 1;\n \n   /* '> 0' if priority is valid,\n      '== 0' if priority was not yet computed,\n@@ -1017,7 +1040,8 @@ enum SCHED_FLAGS {\n      Results in generation of data and control speculative dependencies.\n      Requires USE_DEPS_LIST set.  */\n   DO_SPECULATION = USE_DEPS_LIST << 1,\n-  SCHED_RGN = DO_SPECULATION << 1,\n+  DO_BACKTRACKING = DO_SPECULATION << 1,\n+  SCHED_RGN = DO_BACKTRACKING << 1,\n   SCHED_EBB = SCHED_RGN << 1,\n   /* Scheduler can possibly create new basic blocks.  Used for assertions.  */\n   NEW_BBS = SCHED_EBB << 1,\n@@ -1304,7 +1328,11 @@ extern int *ebb_head;\n extern int current_nr_blocks;\n extern int current_blocks;\n extern int target_bb;\n+extern bool sched_no_dce;\n \n+extern void record_delay_slot_pair (rtx, rtx, int);\n+extern void free_delay_pairs (void);\n+extern void add_delay_dependencies (rtx);\n extern bool sched_is_disabled_for_current_region_p (void);\n extern void sched_rgn_init (bool);\n extern void sched_rgn_finish (void);\n@@ -1478,6 +1506,7 @@ extern dep_t sd_find_dep_between (rtx, rtx, bool);\n extern void sd_add_dep (dep_t, bool);\n extern enum DEPS_ADJUST_RESULT sd_add_or_update_dep (dep_t, bool);\n extern void sd_resolve_dep (sd_iterator_def);\n+extern void sd_unresolve_dep (sd_iterator_def);\n extern void sd_copy_back_deps (rtx, rtx, bool);\n extern void sd_delete_dep (sd_iterator_def);\n extern void sd_debug_lists (rtx, sd_list_types_def);"}, {"sha": "b4d4c81a7cf711bc53149b1dc054d8cf0cc98154", "filename": "gcc/sched-rgn.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-rgn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsched-rgn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-rgn.c?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -2371,6 +2371,7 @@ static const struct haifa_sched_info rgn_const_sched_info =\n   begin_schedule_ready,\n   NULL,\n   advance_target_bb,\n+  NULL, NULL,\n   SCHED_RGN\n };\n "}, {"sha": "ac483257eb8acda89e091cec875d01fad7f03bcf", "filename": "gcc/sel-sched-ir.c", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsel-sched-ir.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/26965010b951a7bb5cc206fe55078c459a7e64e4/gcc%2Fsel-sched-ir.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsel-sched-ir.c?ref=26965010b951a7bb5cc206fe55078c459a7e64e4", "patch": "@@ -5700,6 +5700,10 @@ static struct haifa_sched_info sched_sel_haifa_sched_info =\n   NULL, /* begin_schedule_ready */\n   NULL, /* begin_move_insn */\n   NULL, /* advance_target_bb */\n+\n+  NULL,\n+  NULL,\n+\n   SEL_SCHED | NEW_BBS\n };\n "}]}