{"sha": "22a66d93d30cc8004e999bc86c4ad694be378302", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MjJhNjZkOTNkMzBjYzgwMDRlOTk5YmM4NmM0YWQ2OTRiZTM3ODMwMg==", "commit": {"author": {"name": "Craig Burley", "email": "burley@gcc.gnu.org", "date": "1999-05-28T23:17:04Z"}, "committer": {"name": "Craig Burley", "email": "burley@gcc.gnu.org", "date": "1999-05-28T23:17:04Z"}, "message": "put development docs on mainline for now\n\nFrom-SVN: r27233", "tree": {"sha": "8e0c79c1fe54f0783da8691d69578b412eb58140", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8e0c79c1fe54f0783da8691d69578b412eb58140"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/22a66d93d30cc8004e999bc86c4ad694be378302", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/22a66d93d30cc8004e999bc86c4ad694be378302", "html_url": "https://github.com/Rust-GCC/gccrs/commit/22a66d93d30cc8004e999bc86c4ad694be378302", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/22a66d93d30cc8004e999bc86c4ad694be378302/comments", "author": null, "committer": null, "parents": [{"sha": "2583397b5a10d1835816effde169ba4c4184a96f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2583397b5a10d1835816effde169ba4c4184a96f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2583397b5a10d1835816effde169ba4c4184a96f"}], "stats": {"total": 523, "additions": 521, "deletions": 2}, "files": [{"sha": "3081b02b8a0bb0ec78008477738ddce3bacd6698", "filename": "gcc/f/ffe.texi", "status": "modified", "additions": 521, "deletions": 2, "changes": 523, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/22a66d93d30cc8004e999bc86c4ad694be378302/gcc%2Ff%2Fffe.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/22a66d93d30cc8004e999bc86c4ad694be378302/gcc%2Ff%2Fffe.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ff%2Fffe.texi?ref=22a66d93d30cc8004e999bc86c4ad694be378302", "patch": "@@ -12,14 +12,535 @@\n This chapter describes some aspects of the design and implementation\n of the @code{g77} front end.\n \n+To find about things that are ``To Be Determined'' or ``To Be Done'',\n+search for the string TBD.\n+If you want to help by working on one or more of these items,\n+email me at @email{@value{email-burley}}.\n+If you're planning to do more than just research issues and offer comments,\n+see @uref{http://egcs.cygnus.com/contribute.html} for steps you might\n+need to take first.\n+\n @menu\n+* Overview of Translation Process::\n * Philosophy of Code Generation::\n * Two-pass Design::\n * Challenges Posed::\n * Transforming Statements::\n * Transforming Expressions::\n @end menu\n \n+@node Overview of Translation Process\n+@section Overview of Translation Process\n+\n+The order of phases translating source code to the form accepted\n+by the GBE is:\n+\n+@enumerate\n+@item\n+Stripping punched-card sources (@file{g77stripcard.c})\n+\n+@item\n+Lexing (@file{lex.c})\n+\n+@item\n+Stand-alone statement identification (@file{sta.c})\n+\n+@item\n+Parsing (@file{stb.c} and @file{expr.c})\n+\n+@item\n+Constructing (@file{stc.c})\n+\n+@item\n+Collecting (@file{std.c})\n+\n+@item\n+Expanding (@file{ste.c})\n+@end enumerate\n+\n+To get a rough idea of how a particularly twisted Fortran statement\n+gets treated by the passes, consider:\n+\n+@smallexample\n+      FORMAT(I2 4H)=(J/\n+     &   I3)\n+@end smallexample\n+\n+The job of @file{lex.c} is to know enough about Fortran syntax rules\n+to break the statement up into distinct lexemes without requiring\n+any feedback from subsequent phases:\n+\n+@smallexample\n+`FORMAT'\n+`('\n+`I24H'\n+`)'\n+`='\n+`('\n+`J'\n+`/'\n+`I3'\n+`)'\n+@end smallexample\n+\n+The job of @file{sta.c} is to figure out the kind of statement,\n+or, at least, statement form, that sequence of lexemes represent.\n+\n+The sooner it can do this (in terms of using the smallest number of\n+lexemes, starting with the first for each statement), the better,\n+because that leaves diagnostics for problems beyond the recognition\n+of the statement form to subsequent phases,\n+which can usually better describe the nature of the problem.\n+\n+In this case, the @samp{=} at ``level zero''\n+(not nested within parentheses)\n+tells @file{sta.c} that this is an @emph{assignment-form},\n+not @code{FORMAT}, statement.\n+\n+An assignment-form statement might be a statement-function\n+definition or an executable assignment statement.\n+\n+To make that determination,\n+@file{sta.c} looks at the first two lexemes.\n+\n+Since the second lexeme is @samp{(},\n+the first must represent an array for this to be an assignment statement,\n+else it's a statement function.\n+\n+Either way, @file{sta.c} hands off the statement to @file{stb.c}\n+(either its statement-function parser or its assignment-statement parser).\n+\n+@file{stb.c} forms a\n+statement-specific record containing the pertinent information.\n+That information includes a source expression and,\n+for an assignment statement, a destination expression.\n+Expressions are parsed by @file{expr.c}.\n+\n+This record is passed to @file{stc.c},\n+which copes with the implications of the statement\n+within the context established by previous statements.\n+\n+For example, if it's the first statement in the file\n+or after an @code{END} statement,\n+@file{stc.c} recognizes that, first of all,\n+a main program unit is now being lexed\n+(and tells that to @file{std.c}\n+before telling it about the current statement).\n+\n+@file{stc.c} attaches whatever information it can,\n+usually derived from the context established by the preceding statements,\n+and passes the information to @file{std.c}.\n+\n+@file{std.c} saves this information away,\n+since the GBE cannot cope with information\n+that might be incomplete at this stage.\n+\n+For example, @samp{I3} might later be determined\n+to be an argument to an alternate @code{ENTRY} point.\n+\n+When @file{std.c} is told about the end of an external (top-level)\n+program unit,\n+it passes all the information it has saved away\n+on statements in that program unit\n+to @file{ste.c}.\n+\n+@file{ste.c} ``expands'' each statement, in sequence, by\n+constructing the appropriate GBE information and calling\n+the appropriate GBE routines.\n+\n+Details on the transformational phases follow.\n+Keep in mind that Fortran numbering is used,\n+so the first character on a line is column 1,\n+decimal numbering is used, and so on.\n+\n+@menu\n+* g77stripcard::\n+* lex.c::\n+* sta.c::\n+* stb.c::\n+* expr.c::\n+* stc.c::\n+* std.c::\n+* ste.c::\n+\n+* Gotchas (Transforming)::\n+* TBD (Transforming)::\n+@end menu\n+\n+@node g77stripcard\n+@subsection g77stripcard\n+\n+The @code{g77stripcard} program handles removing content beyond\n+column 72 (adjustable via a command-line option),\n+optionally warning about that content being something other\n+than trailing whitespace or Fortran commentary.\n+\n+This program is needed because @code{lex.c} doesn't pay attention\n+to maximum line lengths at all, to make it easier to maintain,\n+as well as faster (for sources that don't depend on the maximum\n+column length vis-a-vis trailing non-blank non-commentary content).\n+\n+Just how this program will be run---whether automatically for\n+old source (perhaps as the default for @file{.f} files?)---is not\n+yet determined.\n+\n+In the meantime, it might as well be implemented as a typical UNIX pipe.\n+\n+It should accept a @samp{-fline-length-@var{n}} option,\n+with the default line length set to 72.\n+\n+When the text it strips off the end of a line is not blank\n+(not spaces and tabs),\n+it should insert an additional comment line\n+(beginning with @samp{!},\n+so it works for both fixed-form and free-form files)\n+containing the text,\n+following the stripped line.\n+The inserted comment should have a prefix of some kind,\n+TBD, that distinguishes the comment as representing stripped text.\n+Users could use that to @code{sed} out such lines, if they wished---it\n+seems silly to provide a command-line option to delete information\n+when it can be so easily filtered out by another program.\n+\n+(This inserted comment should be designed to ``fit in'' well\n+with whatever the Fortran community is using these days for\n+preprocessor, translator, and other such products, like OpenMP.\n+What that's all about, and how @code{g77} can elegantly fit its\n+special comment conventions into it all, is TBD as well.\n+We don't want to reinvent the wheel here, but if there turn out\n+to be too many conflicting conventions, we might have to invent\n+one that looks nothing like the others, but which offers their\n+host products a better infrastructure in which to fit and coexist\n+peacefully.)\n+\n+@node lex.c\n+@subsection lex.c\n+\n+To help make the lexer simple, fast, and easy to maintain,\n+while also having @code{g77} generally encourage Fortran programmers\n+to write simple, maintainable, portable code by maximizing the\n+performance of compiling that kind of code:\n+\n+@itemize @bullet\n+@item\n+There'll be just one lexer, for both fixed-form and free-form source.\n+\n+@item\n+It'll care about the form only when handling the first 7 columns of\n+text, stuff like spaces between strings of alphanumerics, and\n+how lines are continued.\n+\n+Some other distinctions will be handled by subsequent phases,\n+so at least one of them will have to know which form is involved.\n+\n+For example, @samp{I = 2 . 4} is acceptable in fixed form,\n+and works in free form as well given the implementation @code{g77}\n+presently uses.\n+But the standard requires a diagnostic for it in free form,\n+so the parser has to be able to recognize that\n+the lexemes aren't contiguous\n+(information the lexer @emph{does} have to provide)\n+and that free-form source is being parsed,\n+so it can provide the diagnostic.\n+\n+The @code{g77} lexer doesn't try to gather @samp{2 . 4} into a single lexeme.\n+Otherwise, it'd have to know a whole lot more about how to parse Fortran,\n+or subsequent phases (mainly parsing) would have two paths through\n+lots of critical code---one to handle the lexeme @samp{2}, @samp{.},\n+and @samp{4} in sequence, another to handle the lexeme @samp{2.4}.\n+\n+@item\n+It won't worry about line lengths\n+(beyond the first 7 columns for fixed-form source).\n+\n+That is, once it starts parsing the ``statement'' part of a line\n+(column 7 for fixed-form, column 1 for free-form),\n+it'll keep going until it finds a newline,\n+rather than ignoring everything past a particular column\n+(72 or 132).\n+\n+The implication here is that there shouldn't @emph{be}\n+anything past that last column, other than whitespace or\n+commentary, because users using typical editors\n+(or viewing output as typically printed)\n+won't necessarily know just where the last column is.\n+\n+Code that has ``garbage'' beyond the last column\n+(almost certainly only fixed-form code with a punched-card legacy,\n+such as code using columns 73-80 for ``sequence numbers'')\n+will have to be run through @code{g77stripcard} first.\n+\n+Also, keeping track of the maximum column position while also watching out\n+for the end of a line @emph{and} while reading from a file\n+just makes things slower.\n+Since a file must be read, and watching for the end of the line\n+is necessary (unless the typical input file was preprocessed to\n+include the necessary number of trailing spaces),\n+dropping the tracking of the maximum column position\n+is the only way to reduce the complexity of the pertinent code\n+while maintaining high performance.\n+\n+@item\n+ASCII encoding is assumed for the input file.\n+\n+Code written in other character sets will have to be converted first.\n+\n+@item\n+Tabs (ASCII code 9)\n+will be converted to spaces via the straightforward\n+approach.\n+\n+Specifically, a tab is converted to between one and eight spaces\n+as necessary to reach column @var{n},\n+where dividing @samp{(@var{n} - 1)} by eight\n+results in a remainder of zero.\n+\n+@item\n+Linefeeds (ASCII code 10)\n+mark the ends of lines.\n+\n+@item\n+A carriage return (ASCII code 13)\n+is accept if it immediately precedes a linefeed,\n+in which case it is ignored.\n+\n+Otherwise, it is rejected (with a diagnostic).\n+\n+@item\n+Any other characters other than the above\n+that are not part of the GNU Fortran Character Set\n+(@pxref{Character Set})\n+are rejected with a diagnostic.\n+\n+This includes backspaces, form feeds, and the like.\n+\n+(It might make sense to allow a form feed in column 1\n+as long as that's the only character on a line.\n+It certainly wouldn't seem to cost much in terms of performance.)\n+\n+@item\n+The end of the input stream (EOF)\n+ends the current line.\n+\n+@item\n+The distinction between uppercase and lowercase letters\n+will be preserved.\n+\n+It will be up to subsequent phases to decide to fold case.\n+\n+Current plans are to permit any casing for Fortran (reserved) keywords\n+while preserving casing for user-defined names.\n+(This might not be made the default for @file{.f} files, though.)\n+\n+Preserving case seems necessary to provide more direct access\n+to facilities outside of @code{g77}, such as to C or Pascal code.\n+\n+Names of intrinsics will probably be matchable in any case,\n+However, there probably won't be any option to require\n+a particular mixed-case appearance of intrinsics\n+(as there was for @code{g77} prior to version 0.6),\n+because that's painful to maintain,\n+and probably nobody uses it.\n+\n+(How @samp{external SiN; r = sin(x)} would be handled is TBD.\n+I think old @code{g77} might already handle that pretty elegantly,\n+but whether we can cope with allowing the same fragment to reference\n+a @emph{different} procedure, even with the same interface,\n+via @samp{s = SiN(r)}, needs to be determined.\n+If it can't, we need to make sure that when code introduces\n+a user-defined name, any intrinsic matching that name\n+using a case-insensitive comparison\n+is ``turned off''.)\n+\n+@item\n+Backslashes in @code{CHARACTER} and Hollerith constants\n+are not allowed.\n+\n+This avoids the confusion introduced by some Fortran compiler vendors\n+providing C-like interpretation of backslashes,\n+while others provide straight-through interpretation.\n+\n+Some kind of lexical construct (TBD) will be provided to allow\n+flagging of a @code{CHARACTER}\n+(but probably not a Hollerith)\n+constant that permits backslashes.\n+It'll necessarily be a prefix, such as:\n+\n+@smallexample\n+PRINT *, C'This line has a backspace \\b here.'\n+PRINT *, F'This line has a straight backslash \\ here.'\n+@end smallexample\n+\n+Further, command-line options might be provided to specify that\n+one prefix or the other is to be assumed as the default\n+for @code{CHARACTER} constants.\n+\n+However, it seems more helpful for @code{g77} to provide a program\n+that converts prefix all constants\n+(or just those containing backslashes)\n+with the desired designation,\n+so printouts of code can be read\n+without knowing the compile-time options used when compiling it.\n+\n+If such a program is provided\n+(let's name it @code{g77slash} for now),\n+then a command-line option to @code{g77} should not be provided.\n+(Though, given that it'll be easy to implement, it might be hard\n+to resist user requests for it ``to compile faster than if we\n+have to invoke another filter''.)\n+\n+This program would take a command-line option to specify the\n+default interpretation of slashes,\n+affecting which prefix it uses for constants.\n+\n+@code{g77slash} probably should automatically convert Hollerith\n+constants that contain slashes\n+to the appropriate @code{CHARACTER} constants.\n+Then @code{g77} wouldn't have to define a prefix syntax for Hollerith\n+constants specifying whether they want C-style or straight-through\n+backslashes.\n+@end itemize\n+\n+The above implements nearly exactly what is specified by\n+@ref{Character Set},\n+and\n+@ref{Lines},\n+except it also provides automatic conversion of tabs\n+and ignoring of newline-related carriage returns.\n+\n+It also effects the ``pure visual'' model,\n+by which is meant that a user viewing his code\n+in a typical text editor\n+(assuming it's not preprocessed via @code{g77stripcard} or similar)\n+doesn't need any special knowledge\n+of whether spaces on the screen are really tabs,\n+whether lines end immediately after the last visible non-space character\n+or after a number of spaces and tabs that follow it,\n+or whether the last line in the file is ended by a newline.\n+\n+Most editors don't make these distinctions,\n+the ANSI FORTRAN 77 standard doesn't require them to,\n+and it permits a standard-conforming compiler\n+to define a method for transforming source code to\n+``standard form'' however it wants.\n+\n+So, GNU Fortran defines it such that users have the best chance\n+of having the code be interpreted the way it looks on the screen\n+of the typical editor.\n+\n+(Fancy editors should @emph{never} be required to correctly read code\n+written in classic two-dimensional-plaintext form.\n+By correct reading I mean ability to read it, book-like, without\n+mistaking text ignored by the compiler for program code and vice versa,\n+and without having to count beyond the first several columns.\n+The vague meaning of ASCII TAB, among other things, complicates\n+this somewhat, but as long as ``everyone'', including the editor,\n+other tools, and printer, agrees about the every-eighth-column convention,\n+the GNU Fortran ``pure visual'' model meets these requirements.\n+Any language or user-visible source form\n+requiring special tagging of tabs,\n+the ends of lines after spaces/tabs,\n+and so on, is broken by this definition.\n+Fortunately, Fortran @emph{itself} is not broken,\n+even if most vendor-supplied defaults for their Fortran compilers @emph{are}\n+in this regard.)\n+\n+Further, this model provides a clean interface\n+to whatever preprocessors or code-generators are used\n+to produce input to this phase of @code{g77}.\n+Mainly, they need not worry about long lines.\n+\n+@node sta.c\n+@subsection sta.c\n+\n+@node stb.c\n+@subsection stb.c\n+\n+@node expr.c\n+@subsection expr.c\n+\n+@node stc.c\n+@subsection stc.c\n+\n+@node std.c\n+@subsection std.c\n+\n+@node ste.c\n+@subsection ste.c\n+\n+@node Gotchas (Transforming)\n+@subsection Gotchas (Transforming)\n+\n+This section is not about transforming ``gotchas'' into something else.\n+It is about the weirder aspects of transforming Fortran,\n+however that's defined,\n+into a more modern, canonical form.\n+\n+@node TBD (Transforming)\n+@subsection TBD (Transforming)\n+\n+Continue researching gotchas, designing the transformational process,\n+and implementing it.\n+\n+Specific issues to resolve:\n+\n+@itemize @bullet\n+@item\n+Just where should @code{INCLUDE} processing take place?\n+\n+Clearly before (or part of) statement identification (@file{sta.c}),\n+since determining whether @samp{I(J)=K} is a statement-function\n+definition or an assignment statement requires knowing the context,\n+which in turn requires having processed @code{INCLUDE} files.\n+\n+@item\n+Just where should (if it was implemented) @code{USE} processing take place?\n+\n+This gets into the whole issue of how @code{g77} should handle the concept\n+of modules.\n+I think GNAT already takes on this issue, but don't know more than that.\n+Jim Giles has written extensively on @code{comp.lang.fortran}\n+about his opinions on module handling, as have others.\n+Jim's views should be taken into account.\n+\n+Actually, Richard M. Stallman (RMS) also has written up\n+some guidelines for implementing such things,\n+but I'm not sure where I read them.\n+Perhaps the old @email{gcc2@@cygnus.com} list.\n+\n+If someone could dig references to these up and get them to me,\n+that would be much appreciated!\n+Even though modules are not on the short-term list for implementation,\n+it'd be helpful to know @emph{now} how to avoid making them harder to\n+implement them @emph{later}.\n+\n+@item\n+Should the @code{g77} command become just a script that invokes\n+all the various preprocessing that might be needed,\n+thus making it seem slower than necessary for legacy code\n+that people are unwilling to convert,\n+or should we provide a separate script for that,\n+thus encouraging people to convert their code once and for all?\n+\n+At least, a separate script to behave as old @code{g77} did,\n+perhaps named @code{g77old}, might ease the transition,\n+as might a corresponding one that converts source codes\n+named @code{g77oldnew}.\n+\n+These scripts would take all the pertinent options @code{g77} used\n+to take and run the appropriate filters,\n+passing the results to @code{g77} or just making new sources out of them\n+(in a subdirectory, leaving the user to do the dirty deed of\n+moving or copying them over the old sources).\n+\n+@item\n+Do other Fortran compilers provide a prefix syntax\n+to govern the treatment of backslashes in @code{CHARACTER}\n+(or Hollerith) constants?\n+\n+Knowing what other compilers provide would help.\n+@end itemize\n+\n @node Philosophy of Code Generation\n @section Philosophy of Code Generation\n \n@@ -882,6 +1403,4 @@ to hold the value of the expression.\n \n @item\n Other stuff???\n-\n-\n @end itemize"}]}