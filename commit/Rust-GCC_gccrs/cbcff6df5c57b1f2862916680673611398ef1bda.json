{"sha": "cbcff6df5c57b1f2862916680673611398ef1bda", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2JjZmY2ZGY1YzU3YjFmMjg2MjkxNjY4MDY3MzYxMTM5OGVmMWJkYQ==", "commit": {"author": {"name": "Neil Booth", "email": "neilb@earthling.net", "date": "2000-09-23T21:41:41Z"}, "committer": {"name": "Neil Booth", "email": "neil@gcc.gnu.org", "date": "2000-09-23T21:41:41Z"}, "message": "cpphash.h (CPP_RESERVE, [...]): Delete.\n\n\t* cpphash.h (CPP_RESERVE, CPP_PUTS_Q, CPP_PUTS, CPP_PUTC_Q,\n\tCPP_PUTC, DUMMY_TOKEN, NO_DUMMY_TOKEN): Delete.\n\t* cpplex.c (_cpp_expand_token_space, _cpp_init_toklist,\n\t_cpp_free_toklist): No need to worry about extra dummy token\n\tat the start of token lists any more.\n\t(trigraph_ok): Only warn outside comments.\n\t(skip_block_comment): Set and clear lexing_comment.\n\t(skip_line_comment): Take a cpp_reader not cpp_buffer.\n\tSet and clear lexing_comment.\n\t(parse_number): Handle leading '.' indicated by pfile->seen_dot.\n\t(check_long_token): Delete.\n\t(lex_percent, lex_dot): New subroutines of lex_token to\n\thandle lexing of '.' and '%' without lookback.\n\t(lex_token): Use lex_dot and lex_percent.\n\t(lex_line): Don't check for LIST_OFFSET.\n\t(_cpp_init_input_buffer): Update for new _cpp_init_toklist.\n\t* cpplib.c (_cpp_parse_assertion): Similarly.\n\t(cpp_push_buffer): Initialize extra_char.\n\t* cpplib.h (LIST_OFFSET): Delete.\n\t(struct cpp_buffer): New member extra_char.\n\t(struct lexer_state): New members lexing_comment and seen_dot.\n\nFrom-SVN: r36582", "tree": {"sha": "ed10891b3898c3d5117b135bd865e1653390160c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ed10891b3898c3d5117b135bd865e1653390160c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/cbcff6df5c57b1f2862916680673611398ef1bda", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cbcff6df5c57b1f2862916680673611398ef1bda", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cbcff6df5c57b1f2862916680673611398ef1bda", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cbcff6df5c57b1f2862916680673611398ef1bda/comments", "author": null, "committer": null, "parents": [{"sha": "19e223db83b86b7262db77c9ea67e7d6d32a0d73", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/19e223db83b86b7262db77c9ea67e7d6d32a0d73", "html_url": "https://github.com/Rust-GCC/gccrs/commit/19e223db83b86b7262db77c9ea67e7d6d32a0d73"}], "stats": {"total": 289, "additions": 159, "deletions": 130}, "files": [{"sha": "6b29754e911d112ae7fad9554d14c64615272298", "filename": "gcc/ChangeLog", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=cbcff6df5c57b1f2862916680673611398ef1bda", "patch": "@@ -1,3 +1,27 @@\n+Sat 23-Sep-2000 22:39:18 BST  Neil Booth  <NeilB@earthling.net>\n+\n+\t* cpphash.h (CPP_RESERVE, CPP_PUTS_Q, CPP_PUTS, CPP_PUTC_Q,\n+\tCPP_PUTC, DUMMY_TOKEN, NO_DUMMY_TOKEN): Delete.\n+\t* cpplex.c (_cpp_expand_token_space, _cpp_init_toklist,\n+\t_cpp_free_toklist): No need to worry about extra dummy token\n+\tat the start of token lists any more.\n+\t(trigraph_ok): Only warn outside comments.\n+\t(skip_block_comment): Set and clear lexing_comment.\n+\t(skip_line_comment): Take a cpp_reader not cpp_buffer.\n+\tSet and clear lexing_comment.\n+\t(parse_number): Handle leading '.' indicated by pfile->seen_dot.\n+\t(check_long_token): Delete.\n+\t(lex_percent, lex_dot): New subroutines of lex_token to\n+\thandle lexing of '.' and '%' without lookback.\n+\t(lex_token): Use lex_dot and lex_percent.\n+\t(lex_line): Don't check for LIST_OFFSET.\n+\t(_cpp_init_input_buffer): Update for new _cpp_init_toklist.\n+\t* cpplib.c (_cpp_parse_assertion): Similarly.\n+\t(cpp_push_buffer): Initialize extra_char.\n+\t* cpplib.h (LIST_OFFSET): Delete.\n+\t(struct cpp_buffer): New member extra_char.\n+\t(struct lexer_state): New members lexing_comment and seen_dot.\n+\n 2000-09-23  Jason Merrill  <jason@redhat.com>\n \n \t* config/rs6000/x-aix41 (CLIB): Define here."}, {"sha": "8f569e7404d6dc73c7af2832f6ec4401e90c273d", "filename": "gcc/cpphash.h", "status": "modified", "additions": 0, "deletions": 20, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpphash.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpphash.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpphash.h?ref=cbcff6df5c57b1f2862916680673611398ef1bda", "patch": "@@ -183,22 +183,6 @@ extern unsigned char _cpp_trigraph_map[UCHAR_MAX + 1];\n \n /* Macros.  */\n \n-/* Make sure PFILE->token_buffer has space for at least N more characters. */\n-#define CPP_RESERVE(PFILE, N) \\\n-  (CPP_WRITTEN (PFILE) + (size_t)(N) > (PFILE)->token_buffer_size \\\n-   && (_cpp_grow_token_buffer (PFILE, N), 0))\n-\n-/* Append string STR (of length N) to PFILE's output buffer.\n-   Assume there is enough space. */\n-#define CPP_PUTS_Q(PFILE, STR, N) \\\n-  (memcpy ((PFILE)->limit, STR, (N)), (PFILE)->limit += (N))\n-/* Append string STR (of length N) to PFILE's output buffer.  Make space. */\n-#define CPP_PUTS(PFILE, STR, N) CPP_RESERVE(PFILE, N), CPP_PUTS_Q(PFILE, STR,N)\n-/* Append character CH to PFILE's output buffer.  Assume sufficient space. */\n-#define CPP_PUTC_Q(PFILE, CH) (*(PFILE)->limit++ = (CH))\n-/* Append character CH to PFILE's output buffer.  Make space if need be. */\n-#define CPP_PUTC(PFILE, CH) (CPP_RESERVE (PFILE, 1), CPP_PUTC_Q (PFILE, CH))\n-\n #define CPP_PREV_BUFFER(BUFFER) ((BUFFER)->prev)\n #define CPP_PRINT_DEPS(PFILE) CPP_OPTION (PFILE, print_deps)\n #define CPP_IN_SYSTEM_HEADER(PFILE) \\\n@@ -213,10 +197,6 @@ extern unsigned char _cpp_trigraph_map[UCHAR_MAX + 1];\n    parse_name.  */\n #define HASHSTEP(r, c) ((r) * 67 + (c - 113));\n \n-/* Flags for _cpp_init_toklist.  */\n-#define DUMMY_TOKEN     0\n-#define NO_DUMMY_TOKEN\t1\n-\n /* In cpperror.c  */\n enum error_type { WARNING = 0, PEDWARN, ERROR, FATAL, ICE };\n extern int _cpp_begin_message PARAMS ((cpp_reader *, enum error_type,"}, {"sha": "a7a6f99098c4a4bb7500b6af66f6eb763e0ed87c", "filename": "gcc/cpplex.c", "status": "modified", "additions": 122, "deletions": 105, "changes": 227, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpplex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpplex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplex.c?ref=cbcff6df5c57b1f2862916680673611398ef1bda", "patch": "@@ -103,7 +103,7 @@ static cppchar_t skip_escaped_newlines PARAMS ((cpp_buffer *, cppchar_t));\n static cppchar_t get_effective_char PARAMS ((cpp_buffer *));\n \n static int skip_block_comment PARAMS ((cpp_reader *));\n-static int skip_line_comment PARAMS ((cpp_buffer *));\n+static int skip_line_comment PARAMS ((cpp_reader *));\n static void adjust_column PARAMS ((cpp_reader *));\n static void skip_whitespace PARAMS ((cpp_reader *, cppchar_t));\n static cpp_hashnode *parse_identifier PARAMS ((cpp_reader *, cppchar_t));\n@@ -112,11 +112,9 @@ static void parse_string PARAMS ((cpp_reader *, cpp_token *, cppchar_t));\n static void unterminated PARAMS ((cpp_reader *, unsigned int, int));\n static int trigraph_ok PARAMS ((cpp_reader *, cppchar_t));\n static void save_comment PARAMS ((cpp_reader *, cpp_token *, const U_CHAR *));\n+static void lex_percent PARAMS ((cpp_buffer *, cpp_token *));\n+static void lex_dot PARAMS ((cpp_reader *, cpp_token *));\n static void lex_line PARAMS ((cpp_reader *, cpp_toklist *));\n-static void check_long_token PARAMS ((cpp_buffer *,\n-\t\t\t\t      cpp_token *,\n-\t\t\t\t      cppchar_t,\n-\t\t\t\t      enum cpp_ttype));\n static void lex_token PARAMS ((cpp_reader *, cpp_token *));\n static int lex_next PARAMS ((cpp_reader *, int));\n \n@@ -453,50 +451,35 @@ _cpp_expand_token_space (list, count)\n      cpp_toklist *list;\n      unsigned int count;\n {\n-  unsigned int n;\n-\n   list->tokens_cap += count;\n-  n = list->tokens_cap;\n-  if (list->flags & LIST_OFFSET)\n-    list->tokens--, n++;\n   list->tokens = (cpp_token *)\n-    xrealloc (list->tokens, n * sizeof (cpp_token));\n-  if (list->flags & LIST_OFFSET)\n-    list->tokens++;\t\t/* Skip the dummy.  */\n+    xrealloc (list->tokens, list->tokens_cap * sizeof (cpp_token));\n }\n \n-/* Initialize a token list.  If flags is DUMMY_TOKEN, we allocate\n-   an extra token in front of the token list, as this allows the lexer\n-   to always peek at the previous token without worrying about\n-   underflowing the list, and some initial space.  Otherwise, no\n-   token- or name-space is allocated, and there is no dummy token.  */\n+/* Initialize a token list.  If EMPTY is false, some token and name\n+   space is provided.  */\n void\n-_cpp_init_toklist (list, flags)\n+_cpp_init_toklist (list, empty)\n      cpp_toklist *list;\n-     int flags;\n+     int empty;\n {\n-  if (flags == NO_DUMMY_TOKEN)\n+  if (empty)\n     {\n       list->tokens_cap = 0;\n       list->tokens = 0;\n       list->name_cap = 0;\n       list->namebuf = 0;\n-      list->flags = 0;\n     }\n   else\n     {\n-      /* Initialize token space.  Put a dummy token before the start\n-\t that will fail matches.  */\n+      /* Initialize token space.  */\n       list->tokens_cap = 256;\t/* 4K's worth.  */\n       list->tokens = (cpp_token *)\n \txmalloc ((list->tokens_cap + 1) * sizeof (cpp_token));\n-      list->tokens[0].type = CPP_EOF;\n-      list->tokens++;\n \n       /* Initialize name space.  */\n       list->name_cap = 1024;\n       list->namebuf = (unsigned char *) xmalloc (list->name_cap);\n-      list->flags = LIST_OFFSET;\n     }\n \n   _cpp_clear_toklist (list);\n@@ -512,7 +495,7 @@ _cpp_clear_toklist (list)\n   list->directive = 0;\n   list->paramc = 0;\n   list->params_len = 0;\n-  list->flags &= LIST_OFFSET;  /* clear all but that one */\n+  list->flags = 0;\n }\n \n /* Free a token list.  Does not free the list itself, which may be\n@@ -521,10 +504,7 @@ void\n _cpp_free_toklist (list)\n      const cpp_toklist *list;\n {\n-  if (list->flags & LIST_OFFSET)\n-    free (list->tokens - 1);\t/* Backup over dummy token.  */\n-  else\n-    free (list->tokens);\n+  free (list->tokens);\n   free (list->namebuf);\n }\n \n@@ -633,7 +613,8 @@ trigraph_ok (pfile, from_char)\n {\n   int accept = CPP_OPTION (pfile, trigraphs);\n   \n-  if (CPP_OPTION (pfile, warn_trigraphs))\n+  /* Don't warn about trigraphs in comments.  */\n+  if (CPP_OPTION (pfile, warn_trigraphs) && !pfile->state.lexing_comment)\n     {\n       cpp_buffer *buffer = pfile->buffer;\n       if (accept)\n@@ -768,6 +749,7 @@ skip_block_comment (pfile)\n   cpp_buffer *buffer = pfile->buffer;\n   cppchar_t c = EOF, prevc;\n \n+  pfile->state.lexing_comment = 1;\n   while (buffer->cur != buffer->rlimit)\n     {\n       prevc = c, c = *buffer->cur++;\n@@ -812,6 +794,7 @@ skip_block_comment (pfile)\n \tadjust_column (pfile);\n     }\n \n+  pfile->state.lexing_comment = 0;\n   buffer->read_ahead = EOF;\n   return c != '/' || prevc != '*';\n }\n@@ -820,12 +803,14 @@ skip_block_comment (pfile)\n    non-zero if a multiline comment.  The following new line, if any,\n    is left in buffer->read_ahead.  */\n static int\n-skip_line_comment (buffer)\n-     cpp_buffer *buffer;\n+skip_line_comment (pfile)\n+     cpp_reader *pfile;\n {\n+  cpp_buffer *buffer = pfile->buffer;\n   unsigned int orig_lineno = buffer->lineno;\n   cppchar_t c;\n \n+  pfile->state.lexing_comment = 1;\n   do\n     {\n       c = EOF;\n@@ -838,6 +823,7 @@ skip_line_comment (buffer)\n     }\n   while (!is_vspace (c));\n \n+  pfile->state.lexing_comment = 0;\n   buffer->read_ahead = c;\t/* Leave any newline for caller.  */\n   return orig_lineno != buffer->lineno;\n }\n@@ -966,11 +952,15 @@ parse_number (pfile, number, c)\n   cpp_buffer *buffer = pfile->buffer;\n   unsigned int orig_used = pfile->token_list.name_used;\n \n+  /* Reserve space for a leading period.  */\n+  if (pfile->state.seen_dot)\n+    pfile->token_list.name_used++;\n+\n   do\n     {\n       do\n \t{\n-\t  if (pfile->token_list.name_used == pfile->token_list.name_cap)\n+\t  if (pfile->token_list.name_used >= pfile->token_list.name_cap)\n \t    _cpp_expand_name_space (&pfile->token_list,\n \t\t\t\t    pfile->token_list.name_used + 256);\n \t  pfile->token_list.namebuf[pfile->token_list.name_used++] = c;\n@@ -991,6 +981,10 @@ parse_number (pfile, number, c)\n     }\n   while (is_numchar (c) || c == '.' || VALID_SIGN (c, prevc));\n \n+  /* Put any leading period in place, now we have the room.  */\n+  if (pfile->state.seen_dot)\n+    pfile->token_list.namebuf[orig_used] = '.';\n+\n   /* Remember the next character.  */\n   buffer->read_ahead = c;\n \n@@ -1144,27 +1138,99 @@ save_comment (pfile, token, from)\n   memcpy (buffer, from, len - COMMENT_START_LEN);\n }\n \n-/* A helper routine for lex_token.  With some long tokens, we need\n-   to read ahead to see if that is the token we have, but back-track\n-   if not.  */\n+/* Subroutine of lex_token to handle '%'.  A little tricky, since we\n+   want to avoid stepping back when lexing %:%X.  */\n static void\n-check_long_token (buffer, result, wanted, type)\n+lex_percent (buffer, result)\n      cpp_buffer *buffer;\n      cpp_token *result;\n-     cppchar_t wanted;\n-     enum cpp_ttype type;\n {\n-  const unsigned char *saved_cur;\n-  cppchar_t c = buffer->read_ahead;\n+  cppchar_t c;\n+\n+  result->type = CPP_MOD;\n+  /* Parsing %:%X could leave an extra character.  */\n+  if (buffer->extra_char == EOF)\n+    c = get_effective_char (buffer);\n+  else\n+    {\n+      c = buffer->read_ahead = buffer->extra_char;\n+      buffer->extra_char = EOF;\n+    }\n+\n+  if (c == '=')\n+    ACCEPT_CHAR (CPP_MOD_EQ);\n+  else if (CPP_OPTION (buffer->pfile, digraphs))\n+    {\n+      if (c == ':')\n+\t{\n+\t  result->flags |= DIGRAPH;\n+\t  ACCEPT_CHAR (CPP_HASH);\n+\t  if (get_effective_char (buffer) == '%')\n+\t    {\n+\t      buffer->extra_char = get_effective_char (buffer);\n+\t      if (buffer->extra_char == ':')\n+\t\t{\n+\t\t  buffer->extra_char = EOF;\n+\t\t  ACCEPT_CHAR (CPP_PASTE);\n+\t\t}\n+\t      else\n+\t\t/* We'll catch the extra_char when we're called back.  */\n+\t\tbuffer->read_ahead = '%';\n+\t    }\n+\t}\n+      else if (c == '>')\n+\t{\n+\t  result->flags |= DIGRAPH;\n+\t  ACCEPT_CHAR (CPP_CLOSE_BRACE);\n+\t}\n+    }\n+}\n+\n+/* Subroutine of lex_token to handle '.'.  This is tricky, since we\n+   want to avoid stepping back when lexing '...' or '.123'.  In the\n+   latter case we should also set a flag for parse_number.  */\n+static void\n+lex_dot (pfile, result)\n+     cpp_reader *pfile;\n+     cpp_token *result;\n+{\n+  cpp_buffer *buffer = pfile->buffer;\n+  cppchar_t c;\n+\n+  /* Parsing ..X could leave an extra character.  */\n+  if (buffer->extra_char == EOF)\n+    c = get_effective_char (buffer);\n+  else\n+    {\n+      c = buffer->read_ahead = buffer->extra_char;\n+      buffer->extra_char = EOF;\n+    }\n \n-  SAVE_STATE ();\n-  if (get_effective_char (buffer) == wanted)\n-    ACCEPT_CHAR (type);\n+  /* All known character sets have 0...9 contiguous.  */\n+  if (c >= '0' && c <= '9')\n+    {\n+      result->type = CPP_NUMBER;\n+      buffer->pfile->state.seen_dot = 1;\n+      parse_number (pfile, &result->val.str, c);\n+      buffer->pfile->state.seen_dot = 0;\n+    }\n   else\n     {\n-      /* Restore state.  */\n-      RESTORE_STATE ();\n-      buffer->read_ahead = c;\n+      result->type = CPP_DOT;\n+      if (c == '.')\n+\t{\n+\t  buffer->extra_char = get_effective_char (buffer);\n+\t  if (buffer->extra_char == '.')\n+\t    {\n+\t      buffer->extra_char = EOF;\n+\t      ACCEPT_CHAR (CPP_ELLIPSIS);\n+\t    }\n+\t  else\n+\t    /* We'll catch the extra_char when we're called back.  */\n+\t    buffer->read_ahead = '.';\n+\t}\n+      else if (c == '*' && CPP_OPTION (pfile, cplusplus))\n+\tACCEPT_CHAR (CPP_DOT_STAR);\n     }\n }\n \n@@ -1245,7 +1311,6 @@ lex_token (pfile, result)\n       }\n       break;\n \n-    make_number:\n     case '0': case '1': case '2': case '3': case '4':\n     case '5': case '6': case '7': case '8': case '9':\n       result->type = CPP_NUMBER;\n@@ -1342,7 +1407,7 @@ lex_token (pfile, result)\n \t      comment_start = buffer->cur;\n \n \t      /* Skip_line_comment updates buffer->read_ahead.  */\n-\t      if (skip_line_comment (buffer))\n+\t      if (skip_line_comment (pfile))\n \t\tcpp_warning_with_line (pfile, result->line, result->col,\n \t\t\t\t       \"multi-line comment\");\n \n@@ -1413,57 +1478,12 @@ lex_token (pfile, result)\n \t}\n       break;\n \n-    case '.':\n-      {\n-\tconst unsigned char *saved_cur;\n-\tcppchar_t c1;\n-\n-\t/* Save state to avoid needing to pass 2 chars to parse_number.  */\n-\tSAVE_STATE ();\n-\tc1 = get_effective_char (buffer);\n-\t/* All known character sets have 0...9 contiguous.  */\n-\tif (c1 >= '0' && c1 <= '9')\n-\t  {\n-\t    RESTORE_STATE ();\n-\t    goto make_number;\n-\t  }\n-\n-\tresult->type = CPP_DOT;\n-\tif (c1 == '.')\n-\t  {\n-\t    if (get_effective_char (buffer) == '.')\n-\t      ACCEPT_CHAR (CPP_ELLIPSIS);\n-\t    else\n-\t      {\n-\t\tbuffer->read_ahead = EOF;\n-\t\tRESTORE_STATE ();\n-\t      }\n-\t  }\n-\telse if (c1 == '*' && CPP_OPTION (pfile, cplusplus))\n-\t  ACCEPT_CHAR (CPP_DOT_STAR);\n-      }\n+    case '%':\n+      lex_percent (buffer, result);\n       break;\n \n-    case '%':\n-      result->type = CPP_MOD;\n-      c = get_effective_char (buffer);\n-      if (c == '=')\n-\tACCEPT_CHAR (CPP_MOD_EQ);\n-      else if (CPP_OPTION (pfile, digraphs))\n-\t{\n-\t  if (c == ':')\n-\t    {\n-\t      result->flags |= DIGRAPH;\n-\t      ACCEPT_CHAR (CPP_HASH);\n-\t      if (get_effective_char (buffer) == '%')\n-\t\tcheck_long_token (buffer, result, ':', CPP_PASTE);\n-\t    }\n-\t  else if (c == '>')\n-\t    {\n-\t      result->flags |= DIGRAPH;\n-\t      ACCEPT_CHAR (CPP_CLOSE_BRACE);\n-\t    }\n-\t}\n+    case '.':\n+      lex_dot (pfile, result);\n       break;\n \n     case '+':\n@@ -1610,9 +1630,6 @@ lex_line (pfile, list)\n   cpp_token *cur_token, *first;\n   cpp_buffer *buffer = pfile->buffer;\n \n-  if (!(list->flags & LIST_OFFSET))\n-    (abort) ();\n-\n   pfile->state.in_lex_line = 1;\n   if (pfile->buffer->cur == pfile->buffer->buf)\n     list->flags |= BEG_OF_FILE;\n@@ -3397,7 +3414,7 @@ _cpp_init_input_buffer (pfile)\n {\n   cpp_context *base;\n \n-  _cpp_init_toklist (&pfile->token_list, DUMMY_TOKEN);\n+  _cpp_init_toklist (&pfile->token_list, 0);\n   pfile->no_expand_level = UINT_MAX;\n   pfile->context_cap = 20;\n   pfile->cur_context = 0;"}, {"sha": "8c61ab0c222c4a9b9b63e1bc11d9bea9241c9e83", "filename": "gcc/cpplib.c", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpplib.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpplib.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.c?ref=cbcff6df5c57b1f2862916680673611398ef1bda", "patch": "@@ -1247,7 +1247,7 @@ _cpp_parse_assertion (pfile, answerp)\n   /* Allocate a struct answer, and copy the answer to it.  */\n   answer = (struct answer *) xmalloc (sizeof (struct answer));\n   list = &answer->list;\n-  _cpp_init_toklist (list, NO_DUMMY_TOKEN);\n+  _cpp_init_toklist (list, 1);\t/* Empty.  */\n \n   for (;;)\n     {\n@@ -1516,7 +1516,9 @@ cpp_push_buffer (pfile, buffer, length)\n   new->rlimit = buffer + length;\n   new->prev = buf;\n   new->pfile = pfile;\n+  /* No read ahead or extra char initially.  */\n   new->read_ahead = EOF;\n+  new->extra_char = EOF;\n \n   CPP_BUFFER (pfile) = new;\n   return new;"}, {"sha": "15c30abc67d56abfa8de2207f589fcd7ab993ab8", "filename": "gcc/cpplib.h", "status": "modified", "additions": 10, "deletions": 4, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpplib.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cbcff6df5c57b1f2862916680673611398ef1bda/gcc%2Fcpplib.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.h?ref=cbcff6df5c57b1f2862916680673611398ef1bda", "patch": "@@ -182,9 +182,8 @@ struct cpp_token\n };\n \n /* cpp_toklist flags.  */\n-#define LIST_OFFSET     (1 << 0)\n-#define VAR_ARGS\t(1 << 1)\n-#define BEG_OF_FILE\t(1 << 2)\n+#define VAR_ARGS\t(1 << 0)\n+#define BEG_OF_FILE\t(1 << 1)\n \n struct directive;\t\t/* These are deliberately incomplete.  */\n struct answer;\n@@ -225,6 +224,7 @@ struct cpp_buffer\n   const unsigned char *rlimit; /* end of valid data */\n   const unsigned char *line_base; /* start of current line */\n   cppchar_t read_ahead;\t\t/* read ahead character */\n+  cppchar_t extra_char;\t\t/* extra read-ahead for long tokens.  */\n \n   struct cpp_reader *pfile;\t/* Owns this buffer.  */\n   struct cpp_buffer *prev;\n@@ -460,8 +460,14 @@ struct lexer_state\n   /* Nonzero to get force the lexer to skip newlines.  */\n   unsigned char skip_newlines;\n \n-  /* If we're in the subroutine lex_line.  */\n+  /* Nonzero if we're in the subroutine lex_line.  */\n   unsigned char in_lex_line;\n+\n+  /* Nonzero if we're mid-comment.  */\n+  unsigned char lexing_comment;\n+\n+  /* Tells parse_number we saw a leading period.  */\n+  unsigned char seen_dot;\n };\n #define IN_DIRECTIVE(pfile) (pfile->state.in_directive)\n #define KNOWN_DIRECTIVE(list) (list->directive != 0)"}]}