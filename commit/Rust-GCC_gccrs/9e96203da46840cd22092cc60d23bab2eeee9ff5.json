{"sha": "9e96203da46840cd22092cc60d23bab2eeee9ff5", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OWU5NjIwM2RhNDY4NDBjZDIyMDkyY2M2MGQyM2JhYjJlZWVlOWZmNQ==", "commit": {"author": {"name": "J\"orn Rennecke", "email": "joern.rennecke@superh.com", "date": "2002-06-24T20:08:17Z"}, "committer": {"name": "Joern Rennecke", "email": "amylaar@gcc.gnu.org", "date": "2002-06-24T20:08:17Z"}, "message": "lib1funcs.asm (sdivsi3): Add optimized SH64 implementations.\n\n\t* lib1funcs.asm (sdivsi3): Add optimized SH64 implementations.\n\t(udivsi3): Likewise.  Rewrite SH1 implementation.\n\t(udivdi3, divdi3, umoddi3, moddi3): New SHmedia functions.\n\t* sh.md (R20_REG, R21_REG, R22_REG, R23_REG, FR23_REG): New constants.\n\t(udivsi3_i1_media, divsi3_i1_media): Fix clobber list.\n\t* config/sh/t-sh64 (LIB1ASMFUNCS): (_udivdi3, _divdi3, _umoddi3): Add.\n\t(_moddi3): Likewise.\n\n\t* lib1funcs.asm (ic_invalidate): Add data cache line writeback.\n\nFrom-SVN: r54965", "tree": {"sha": "b772649365a9beff0a996918db6cdd5835fa12df", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b772649365a9beff0a996918db6cdd5835fa12df"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/9e96203da46840cd22092cc60d23bab2eeee9ff5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9e96203da46840cd22092cc60d23bab2eeee9ff5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9e96203da46840cd22092cc60d23bab2eeee9ff5", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9e96203da46840cd22092cc60d23bab2eeee9ff5/comments", "author": null, "committer": null, "parents": [{"sha": "a81062077ae7e3900ca0976ed41de3470f8f9b87", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a81062077ae7e3900ca0976ed41de3470f8f9b87", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a81062077ae7e3900ca0976ed41de3470f8f9b87"}], "stats": {"total": 616, "additions": 560, "deletions": 56}, "files": [{"sha": "c7bd7c789493c80ef90c56d4f4fd6d229915e3e6", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=9e96203da46840cd22092cc60d23bab2eeee9ff5", "patch": "@@ -1,4 +1,14 @@\n-Mon Jun 24 18:53:56 2002  J\"orn Rennecke <joern.rennecke@superh.com>\n+Mon Jun 24 21:05:09 2002  J\"orn Rennecke <joern.rennecke@superh.com>\n+\n+\t* lib1funcs.asm (sdivsi3): Add optimized SH64 implementations.\n+\t(udivsi3): Likewise.  Rewrite SH1 implementation.\n+\t(udivdi3, divdi3, umoddi3, moddi3): New SHmedia functions.\n+\t* sh.md (R20_REG, R21_REG, R22_REG, R23_REG, FR23_REG): New constants.\n+\t(udivsi3_i1_media, divsi3_i1_media): Fix clobber list.\n+\t* config/sh/t-sh64 (LIB1ASMFUNCS): (_udivdi3, _divdi3, _umoddi3): Add.\n+\t(_moddi3): Likewise.\n+\n+\t* lib1funcs.asm (ic_invalidate): Add data cache line writeback.\n \n \t* sh.h (FUNCTION_ARG_ADVANCE): Take SHCOMPACT_FORCE_ON_STACK\n \targuments into account for stack_regs."}, {"sha": "099c823fceb331d2f3da5e48582779ddc8f2cc87", "filename": "gcc/config/sh/lib1funcs.asm", "status": "modified", "additions": 525, "deletions": 53, "changes": 578, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2Fconfig%2Fsh%2Flib1funcs.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2Fconfig%2Fsh%2Flib1funcs.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Flib1funcs.asm?ref=9e96203da46840cd22092cc60d23bab2eeee9ff5", "patch": "@@ -930,6 +930,7 @@ GLOBAL(sdivsi3_i4):\n \t.text\n #endif\n \t.align\t2\n+#if 0\n /* The assembly code that follows is a hand-optimized version of the C\n    code that follows.  Note that the registers that are modified are\n    exactly those listed as clobbered in the patterns divsi3_i1 and\n@@ -987,7 +988,100 @@ LOCAL(sdivsi3_dontadd):\n \tmuls.l\tr0, r2, r0\n \tadd.l\tr0, r63, r0\n \tblink\ttr0, r63\n-#else\n+#else /* ! 0 */\n+ // inputs: r4,r5\n+ // clobbered: r1,r2,r3,r18,r19,r20,r21,r25,tr0\n+ // result in r0\n+GLOBAL(sdivsi3):\n+ // can create absolute value without extra latency,\n+ // but dependent on proper sign extension of inputs:\n+ // shari.l r5,31,r2\n+ // xor r5,r2,r20\n+ // sub r20,r2,r20 // r20 is now absolute value of r5, zero-extended.\n+ shari.l r5,31,r2\n+ ori r2,1,r2\n+ muls.l r5,r2,r20 // r20 is now absolute value of r5, zero-extended.\n+ movi 0xffffffffffffbb0c,r19 // shift count eqiv 76\n+ shari.l r4,31,r3\n+ nsb r20,r0\n+ shlld r20,r0,r25\n+ shlri r25,48,r25\n+ sub r19,r25,r1\n+ mmulfx.w r1,r1,r2\n+ mshflo.w r1,r63,r1\n+ // If r4 was to be used in-place instead of r21, could use this sequence\n+ // to compute absolute:\n+ // sub r63,r4,r19 // compute absolute value of r4\n+ // shlri r4,32,r3 // into lower 32 bit of r4, keeping\n+ // mcmv r19,r3,r4 // the sign in the upper 32 bits intact.\n+ ori r3,1,r3\n+ mmulfx.w r25,r2,r2\n+ sub r19,r0,r0\n+ muls.l r4,r3,r21\n+ msub.w r1,r2,r2\n+ addi r2,-2,r1\n+ mulu.l r21,r1,r19\n+ mmulfx.w r2,r2,r2\n+ shlli r1,15,r1\n+ shlrd r19,r0,r19\n+ mulu.l r19,r20,r3\n+ mmacnfx.wl r25,r2,r1\n+ ptabs r18,tr0\n+ sub r21,r3,r25\n+\n+ mulu.l r25,r1,r2\n+ addi r0,14,r0\n+ xor r4,r5,r18\n+ shlrd r2,r0,r2\n+ mulu.l r2,r20,r3\n+ add r19,r2,r19\n+ shari.l r18,31,r18\n+ sub r25,r3,r25\n+\n+ mulu.l r25,r1,r2\n+ sub r25,r20,r25\n+ add r19,r18,r19\n+ shlrd r2,r0,r2\n+ mulu.l r2,r20,r3\n+ addi r25,1,r25\n+ add r19,r2,r19\n+\n+ cmpgt r25,r3,r25\n+ add.l r19,r25,r0\n+ xor r0,r18,r0\n+ blink tr0,r63\n+#endif\n+#elif defined __SHMEDIA__\n+/* m5compact-nofpu */\n+ // clobbered: r18,r19,r20,r21,r25,tr0,tr1,tr2\n+\t.mode\tSHmedia\n+\t.section\t.text..SHmedia32,\"ax\"\n+\t.align\t2\n+GLOBAL(sdivsi3):\n+\tpt/l LOCAL(sdivsi3_dontsub), tr0\n+\tpt/l LOCAL(sdivsi3_loop), tr1\n+\tptabs/l r18,tr2\n+\tshari.l r4,31,r18\n+\tshari.l r5,31,r19\n+\txor r4,r18,r20\n+\txor r5,r19,r21\n+\tsub.l r20,r18,r20\n+\tsub.l r21,r19,r21\n+\txor r18,r19,r19\n+\tshlli r21,32,r25\n+\taddi r25,-1,r21\n+\taddz.l r20,r63,r20\n+LOCAL(sdivsi3_loop):\n+\tshlli r20,1,r20\n+\tbgeu/u r21,r20,tr0\n+\tsub r20,r21,r20\n+LOCAL(sdivsi3_dontsub):\n+\taddi.l r25,-1,r25\n+\tbnei r25,-32,tr1\n+\txor r20,r19,r20\n+\tsub.l r20,r19,r0\n+\tblink tr2,r63\n+#else /* ! __SHMEDIA__ */\n GLOBAL(sdivsi3):\n \tmov\tr4,r1\n \tmov\tr5,r0\n@@ -1187,11 +1281,6 @@ L1:\n /* __SH4_SINGLE_ONLY__ keeps this part for link compatibility with\n    sh3e code.  */\n #if (! defined(__SH4__) && ! defined (__SH4_SINGLE__)) || defined (__linux__)\n-!!\n-!! Steve Chamberlain\n-!! sac@cygnus.com\n-!!\n-!!\n \n !! args in r4 and r5, result in r0, clobbers r4, pr, and t bit\n \t.global\tGLOBAL(udivsi3)\n@@ -1203,6 +1292,7 @@ L1:\n \t.text\n #endif\n \t.align\t2\n+#if 0\n /* The assembly code that follows is a hand-optimized version of the C\n    code that follows.  Note that the registers that are modified are\n    exactly those listed as clobbered in the patterns udivsi3_i1 and\n@@ -1248,56 +1338,436 @@ LOCAL(udivsi3_dontadd):\n \tblink\ttr0, r63\n #else\n GLOBAL(udivsi3):\n-longway:\n-\tmov\t#0,r0\n-\tdiv0u\n-\t! get one bit from the msb of the numerator into the T\n-\t! bit and divide it by whats in r5.  Put the answer bit\n-\t! into the T bit so it can come out again at the bottom\n-\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-shortway:\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\n-vshortway:\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4 ; div1 r5,r0\n-\trotcl\tr4\n-ret:\trts\n-\tmov\tr4,r0\n+ // inputs: r4,r5\n+ // clobbered: r18,r19,r20,r21,r22,r25,tr0\n+ // result in r0.\n+ addz.l r5,r63,r22\n+ nsb r22,r0\n+ shlld r22,r0,r25\n+ shlri r25,48,r25\n+ movi 0xffffffffffffbb0c,r20 // shift count eqiv 76\n+ sub r20,r25,r21\n+ mmulfx.w r21,r21,r19\n+ mshflo.w r21,r63,r21\n+ ptabs r18,tr0\n+ mmulfx.w r25,r19,r19\n+ sub r20,r0,r0\n+ /* bubble */\n+ msub.w r21,r19,r19\n+ addi r19,-2,r21 /* It would be nice for scheduling to do this add to r21\n+\t\t    before the msub.w, but we need a different value for\n+\t\t    r19 to keep errors under control.  */\n+ mulu.l r4,r21,r18\n+ mmulfx.w r19,r19,r19\n+ shlli r21,15,r21\n+ shlrd r18,r0,r18\n+ mulu.l r18,r22,r20\n+ mmacnfx.wl r25,r19,r21\n+ /* bubble */\n+ sub r4,r20,r25\n+\n+ mulu.l r25,r21,r19\n+ addi r0,14,r0\n+ /* bubble */\n+ shlrd r19,r0,r19\n+ mulu.l r19,r22,r20\n+ add r18,r19,r18\n+ /* bubble */\n+ sub.l r25,r20,r25\n+\n+ mulu.l r25,r21,r19\n+ addz.l r25,r63,r25\n+ sub r25,r22,r25\n+ shlrd r19,r0,r19\n+ mulu.l r19,r22,r20\n+ addi r25,1,r25\n+ add r18,r19,r18\n+\n+ cmpgt r25,r20,r25\n+ add.l r18,r25,r0\n+ blink tr0,r63\n+#endif\n+#elif defined (__SHMEDIA__)\n+/* m5compact-nofpu - more emphasis on code size than on speed, but don't\n+   ignore speed altogether - div1 needs 9 cycles, subc 7 and rotcl 4.\n+   So use a short shmedia loop.  */\n+ // clobbered: r20,r21,r25,tr0,tr1,tr2\n+\t.mode\tSHmedia\n+\t.section\t.text..SHmedia32,\"ax\"\n+\t.align\t2\n+GLOBAL(udivsi3):\n+ pt/l LOCAL(udivsi3_dontsub), tr0\n+ pt/l LOCAL(udivsi3_loop), tr1\n+ ptabs/l r18,tr2\n+ shlli r5,32,r25\n+ addi r25,-1,r21\n+ addz.l r4,r63,r20\n+LOCAL(udivsi3_loop):\n+ shlli r20,1,r20\n+ bgeu/u r21,r20,tr0\n+ sub r20,r21,r20\n+LOCAL(udivsi3_dontsub):\n+ addi.l r25,-1,r25\n+ bnei r25,-32,tr1\n+ add.l r20,r63,r0\n+ blink tr2,r63\n+#else /* ! defined (__SHMEDIA__) */\n+LOCAL(div8):\n+ div1 r5,r4\n+LOCAL(div7):\n+ div1 r5,r4; div1 r5,r4; div1 r5,r4\n+ div1 r5,r4; div1 r5,r4; div1 r5,r4; rts; div1 r5,r4\n+\n+LOCAL(divx4):\n+ div1 r5,r4; rotcl r0\n+ div1 r5,r4; rotcl r0\n+ div1 r5,r4; rotcl r0\n+ rts; div1 r5,r4\n+\n+GLOBAL(udivsi3):\n+ sts.l pr,@-r15\n+ extu.w r5,r0\n+ cmp/eq r5,r0\n+#ifdef __sh1__\n+ bf LOCAL(large_divisor)\n+#else\n+ bf/s LOCAL(large_divisor)\n+#endif\n+ div0u\n+ swap.w r4,r0\n+ shlr16 r4\n+ bsr LOCAL(div8)\n+ shll16 r5\n+ bsr LOCAL(div7)\n+ div1 r5,r4\n+ xtrct r4,r0\n+ xtrct r0,r4\n+ bsr LOCAL(div8)\n+ swap.w r4,r4\n+ bsr LOCAL(div7)\n+ div1 r5,r4\n+ lds.l @r15+,pr\n+ xtrct r4,r0\n+ swap.w r0,r0\n+ rotcl r0\n+ rts\n+ shlr16 r5\n+\n+LOCAL(large_divisor):\n+#ifdef __sh1__\n+ div0u\n+#endif\n+ mov #0,r0\n+ xtrct r4,r0\n+ xtrct r0,r4\n+ bsr LOCAL(divx4)\n+ rotcl r0\n+ bsr LOCAL(divx4)\n+ rotcl r0\n+ bsr LOCAL(divx4)\n+ rotcl r0\n+ bsr LOCAL(divx4)\n+ rotcl r0\n+ lds.l @r15+,pr\n+ rts\n+ rotcl r0\n \n #endif /* ! __SHMEDIA__ */\n #endif /* __SH4__ */\n-#endif\n+#endif /* L_udivsi3 */\n+\n+#ifdef L_udivdi3\n+#ifdef __SHMEDIA__\n+\t.mode\tSHmedia\n+\t.section\t.text..SHmedia32,\"ax\"\n+\t.align\t2\n+\t.global\tGLOBAL(udivdi3)\n+GLOBAL(udivdi3):\n+\tshlri r3,1,r4\n+\tnsb r4,r22\n+\tshlld r3,r22,r6\n+\tshlri r6,49,r5\n+\tmovi 0xffffffffffffbaf1,r21 /* .l shift count 17.  */\n+\tsub r21,r5,r1\n+\tmmulfx.w r1,r1,r4\n+\tmshflo.w r1,r63,r1\n+\tsub r63,r22,r20 // r63 == 64 % 64\n+\tmmulfx.w r5,r4,r4\n+\tpta LOCAL(large_divisor),tr0\n+\taddi r20,32,r9\n+\tmsub.w r1,r4,r1\n+\tmadd.w r1,r1,r1\n+\tmmulfx.w r1,r1,r4\n+\tshlri r6,32,r7\n+\tbgt/u r9,r63,tr0 // large_divisor\n+\tmmulfx.w r5,r4,r4\n+\tshlri r2,32,r19\n+\taddi r20,14-1,r0\n+\tmsub.w r1,r4,r1\n+\n+\tmulu.l r1,r7,r4\n+\taddi r1,-3,r5\n+\tmulu.l r5,r19,r5\n+\tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n+\t                 the case may be, %0000000000000000 000.11111111111, still */\n+\tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n+\tshlrd r5,r0,r8\n+\tmulu.l r8,r3,r5\n+\tmshalds.l r1,r21,r1\n+\tshari r4,26,r4\n+\tshlli r5,32,r5\n+\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tsub r2,r5,r2\n+\t/* Can do second step of 64 : 32 div now, using r1 and the rest in r2.  */\n+\n+\tshlri r2,22,r21\n+\tmulu.l r21,r1,r21\n+\taddi r20,30-22,r0\n+\tshlli r8,32,r8\n+\tshlrd r21,r0,r21\n+\tmulu.l r21,r3,r5\n+\tadd r8,r21,r8\n+\tmcmpeq.l r21,r63,r21 // See Note 1\n+\taddi r20,30,r0\n+\tmshfhi.l r63,r21,r21\n+\tsub r2,r5,r2\n+\tandc r2,r21,r2\n+\n+\t/* small divisor: need a third divide step */\n+\tmulu.l r2,r1,r7\n+\tptabs r18,tr0\n+\taddi r2,1,r2\n+\tshlrd r7,r0,r7\n+\tmulu.l r7,r3,r5\n+\tadd r8,r7,r8\n+\tsub r2,r3,r2\n+\tcmpgt r2,r5,r5\n+\tadd r8,r5,r2\n+\t/* could test r3 here to check for divide by zero.  */\n+\tblink tr0,r63\n+\n+LOCAL(large_divisor):\n+\tmmulfx.w r5,r4,r4\n+\tshlrd r2,r9,r25\n+\tshlri r25,32,r8\n+\tmsub.w r1,r4,r1\n+\n+\tmulu.l r1,r7,r4\n+\taddi r1,-3,r5\n+\tmulu.l r5,r8,r5\n+\tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n+\t                 the case may be, %0000000000000000 000.11111111111, still */\n+\tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n+\tshlri r5,14-1+32,r8\n+\tmulu.l r8,r7,r5\n+\tmshalds.l r1,r21,r1\n+\tshari r4,26,r4\n+\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tsub r25,r5,r25\n+\t/* Can do second step of 64 : 32 div now, using r1 and the rest in r25.  */\n+\n+\tshlri r25,22,r21\n+\tmulu.l r21,r1,r21\n+\tpta LOCAL(no_lo_adj),tr0\n+\taddi r22,32,r0\n+\tshlri r21,40,r21\n+\tmulu.l r21,r7,r5\n+\tadd r8,r21,r8\n+\tshlld r2,r0,r2\n+\tsub r25,r5,r25\n+\tmextr4 r2,r25,r2\n+\tbgtu/u r6,r2,tr0 // no_lo_adj\n+\taddi r8,1,r8\n+\tsub r2,r6,r2\n+LOCAL(no_lo_adj):\n+\n+\t/* large_divisor: only needs a few adjustments.  */\n+\tmulu.l r8,r6,r5\n+\tptabs r18,tr0\n+\t/* bubble */\n+\tcmpgtu r5,r2,r5\n+\tsub r8,r5,r2\n+\tblink tr0,r63\n+/* Note 1: To shift the result of the second divide stage so that the result\n+   always fits into 32 bits, yet we still reduce the rest sufficiently\n+   would require a lot of instructions to do the shifts just right.  Using\n+   the full 64 bit shift result to multiply with the divisor would require\n+   four extra instructions for the upper 32 bits (shift / mulu / shift / sub).\n+   Fortunately, if the upper 32 bits of the shift result are non-zero, we\n+   know that the rest after taking this partial result into account will\n+   fit into 32 bits.  So we just clear the upper 32 bits of the rest if the\n+   upper 32 bits of the partial result are non-zero.  */\n+#endif /* __SHMEDIA__ */\n+#endif /* L_udivdi3 */\n+\n+#ifdef L_divdi3\n+#ifdef __SHMEDIA__\n+\t.mode\tSHmedia\n+\t.section\t.text..SHmedia32,\"ax\"\n+\t.align\t2\n+\t.global\tGLOBAL(divdi3)\n+GLOBAL(divdi3):\n+\tpta GLOBAL(udivdi3),tr0\n+\tshari r2,63,r22\n+\tshari r3,63,r23\n+\txor r2,r22,r2\n+\txor r3,r23,r3\n+\tsub r2,r22,r2\n+\tsub r3,r23,r3\n+\tbeq/u r22,r23,tr0\n+\tptabs r18,tr1\n+\tblink tr0,r18\n+\tsub r63,r2,r2\n+\tblink tr1,r63\n+#endif /* __SHMEDIA__ */\n+#endif /* L_divdi3 */\n+\n+#ifdef L_umoddi3\n+#ifdef __SHMEDIA__\n+\t.mode\tSHmedia\n+\t.section\t.text..SHmedia32,\"ax\"\n+\t.align\t2\n+\t.global\tGLOBAL(umoddi3)\n+GLOBAL(umoddi3):\n+\tshlri r3,1,r4\n+\tnsb r4,r22\n+\tshlld r3,r22,r6\n+\tshlri r6,49,r5\n+\tmovi 0xffffffffffffbaf1,r21 /* .l shift count 17.  */\n+\tsub r21,r5,r1\n+\tmmulfx.w r1,r1,r4\n+\tmshflo.w r1,r63,r1\n+\tsub r63,r22,r20 // r63 == 64 % 64\n+\tmmulfx.w r5,r4,r4\n+\tpta LOCAL(large_divisor),tr0\n+\taddi r20,32,r9\n+\tmsub.w r1,r4,r1\n+\tmadd.w r1,r1,r1\n+\tmmulfx.w r1,r1,r4\n+\tshlri r6,32,r7\n+\tbgt/u r9,r63,tr0 // large_divisor\n+\tmmulfx.w r5,r4,r4\n+\tshlri r2,32,r19\n+\taddi r20,14-1,r0\n+\tmsub.w r1,r4,r1\n+\n+\tmulu.l r1,r7,r4\n+\taddi r1,-3,r5\n+\tmulu.l r5,r19,r5\n+\tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n+\t                 the case may be, %0000000000000000 000.11111111111, still */\n+\tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n+\tshlrd r5,r0,r8\n+\tmulu.l r8,r3,r5\n+\tmshalds.l r1,r21,r1\n+\tshari r4,26,r4\n+\tshlli r5,32,r5\n+\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tsub r2,r5,r2\n+\t/* Can do second step of 64 : 32 div now, using r1 and the rest in r2.  */\n+\n+\tshlri r2,22,r21\n+\tmulu.l r21,r1,r21\n+\taddi r20,30-22,r0\n+\t/* bubble */ /* could test r3 here to check for divide by zero.  */\n+\tshlrd r21,r0,r21\n+\tmulu.l r21,r3,r5\n+\tmcmpeq.l r21,r63,r21 // See Note 1\n+\taddi r20,30,r0\n+\tmshfhi.l r63,r21,r21\n+\tsub r2,r5,r2\n+\tandc r2,r21,r2\n+\n+\t/* small divisor: need a third divide step */\n+\tmulu.l r2,r1,r7\n+\tptabs r18,tr0\n+\tsub r2,r3,r8 /* re-use r8 here for rest - r3 */\n+\tshlrd r7,r0,r7\n+\tmulu.l r7,r3,r5\n+\t/* bubble */\n+\taddi r8,1,r7\n+\tcmpgt r7,r5,r7\n+\tcmvne r7,r8,r2\n+\tsub r2,r5,r2\n+\tblink tr0,r63\n+\n+LOCAL(large_divisor):\n+\tmmulfx.w r5,r4,r4\n+\tshlrd r2,r9,r25\n+\tshlri r25,32,r8\n+\tmsub.w r1,r4,r1\n+\n+\tmulu.l r1,r7,r4\n+\taddi r1,-3,r5\n+\tmulu.l r5,r8,r5\n+\tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n+\t                 the case may be, %0000000000000000 000.11111111111, still */\n+\tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n+\tshlri r5,14-1+32,r8\n+\tmulu.l r8,r7,r5\n+\tmshalds.l r1,r21,r1\n+\tshari r4,26,r4\n+\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tsub r25,r5,r25\n+\t/* Can do second step of 64 : 32 div now, using r1 and the rest in r25.  */\n+\n+\tshlri r25,22,r21\n+\tmulu.l r21,r1,r21\n+\tpta LOCAL(no_lo_adj),tr0\n+\taddi r22,32,r0\n+\tshlri r21,40,r21\n+\tmulu.l r21,r7,r5\n+\tadd r8,r21,r8\n+\tshlld r2,r0,r2\n+\tsub r25,r5,r25\n+\tmextr4 r2,r25,r2\n+\tbgtu/u r6,r2,tr0 // no_lo_adj\n+\taddi r8,1,r8\n+\tsub r2,r6,r2\n+LOCAL(no_lo_adj):\n+\n+\t/* large_divisor: only needs a few adjustments.  */\n+\tmulu.l r8,r6,r5\n+\tptabs r18,tr0\n+\tadd r2,r3,r7\n+\tcmpgtu r5,r2,r8\n+\tcmvne r8,r7,r2\n+\tsub r2,r5,r2\n+\tblink tr0,r63\n+/* Note 1: To shift the result of the second divide stage so that the result\n+   always fits into 32 bits, yet we still reduce the rest sufficiently\n+   would require a lot of instructions to do the shifts just right.  Using\n+   the full 64 bit shift result to multiply with the divisor would require\n+   four extra instructions for the upper 32 bits (shift / mulu / shift / sub).\n+   Fortunately, if the upper 32 bits of the shift result are non-zero, we\n+   know that the rest after taking this partial result into account will\n+   fit into 32 bits.  So we just clear the upper 32 bits of the rest if the\n+   upper 32 bits of the partial result are non-zero.  */\n+#endif /* __SHMEDIA__ */\n+#endif /* L_umoddi3 */\n+\n+#ifdef L_moddi3\n+#ifdef __SHMEDIA__\n+\t.mode\tSHmedia\n+\t.section\t.text..SHmedia32,\"ax\"\n+\t.align\t2\n+\t.global\tGLOBAL(moddi3)\n+GLOBAL(moddi3):\n+\tpta GLOBAL(umoddi3),tr0\n+\tshari r2,63,r22\n+\tshari r3,63,r23\n+\txor r2,r22,r2\n+\txor r3,r23,r3\n+\tsub r2,r22,r2\n+\tsub r3,r23,r3\n+\tbeq/u r22,r63,tr0\n+\tptabs r18,tr1\n+\tblink tr0,r18\n+\tsub r63,r2,r2\n+\tblink tr1,r63\n+#endif /* __SHMEDIA__ */\n+#endif /* L_moddi3 */\n+\n #ifdef L_set_fpscr\n #if defined (__SH3E__) || defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) || __SH5__ == 32\n #ifdef __SH5__\n@@ -1350,6 +1820,8 @@ LOCAL(set_fpscr_L1):\n \t.align\t2\n \t.global\tGLOBAL(ic_invalidate)\n GLOBAL(ic_invalidate):\n+\tocbwb\tr0,0\n+\tsynco\n \ticbi\tr0, 0\n \tptabs\tr18, tr0\n \tsynci"}, {"sha": "d4508936b065e583870185fc28511e9e131cae97", "filename": "gcc/config/sh/sh.md", "status": "modified", "additions": 22, "deletions": 1, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2Fconfig%2Fsh%2Fsh.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2Fconfig%2Fsh%2Fsh.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh.md?ref=9e96203da46840cd22092cc60d23bab2eeee9ff5", "patch": "@@ -99,10 +99,15 @@\n   (R8_REG\t8)\n   (R9_REG\t9)\n   (R10_REG\t10)\n+  (R20_REG\t20)\n+  (R21_REG\t21)\n+  (R22_REG\t22)\n+  (R23_REG\t23)\n \n   (DR0_REG\t64)\n   (DR2_REG\t66)\n   (DR4_REG\t68)\n+  (FR23_REG\t87)\n \n   (TR0_REG\t128)\n   (TR1_REG\t129)\n@@ -1281,12 +1286,20 @@\n   [(set_attr \"type\" \"sfunc\")\n    (set_attr \"needs_delay_slot\" \"yes\")])\n \n+; Since shmedia-nofpu code could be linked against shcompact code, and\n+; the udivsi3 libcall has the same name, we must consider all registers\n+; clobbered that are in the union of the registers clobbered by the\n+; shmedia and the shcompact implementation.  Note, if the shcompact\n+; implemenation actually used shcompact code, we'd need to clobber\n+; also r23 and fr23.\n (define_insn \"udivsi3_i1_media\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=z\")\n \t(udiv:SI (reg:SI R4_REG) (reg:SI R5_REG)))\n    (clobber (reg:SI T_MEDIA_REG))\n    (clobber (reg:SI PR_MEDIA_REG))\n-   (clobber (reg:SI R4_REG))\n+   (clobber (reg:SI R20_REG))\n+   (clobber (reg:SI R21_REG))\n+   (clobber (reg:SI R22_REG))\n    (clobber (reg:DI TR0_REG))\n    (clobber (reg:DI TR1_REG))\n    (clobber (reg:DI TR2_REG))\n@@ -1430,6 +1443,12 @@\n   [(set_attr \"type\" \"sfunc\")\n    (set_attr \"needs_delay_slot\" \"yes\")])\n \n+; Since shmedia-nofpu code could be linked against shcompact code, and\n+; the udivsi3 libcall has the same name, we must consider all registers\n+; clobbered that are in the union of the registers clobbered by the\n+; shmedia and the shcompact implementation.  Note, if the shcompact\n+; implemenation actually used shcompact code, we'd need to clobber\n+; also r22, r23 and fr23.\n (define_insn \"divsi3_i1_media\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=z\")\n \t(div:SI (reg:SI R4_REG) (reg:SI R5_REG)))\n@@ -1438,6 +1457,8 @@\n    (clobber (reg:SI R1_REG))\n    (clobber (reg:SI R2_REG))\n    (clobber (reg:SI R3_REG))\n+   (clobber (reg:SI R20_REG))\n+   (clobber (reg:SI R21_REG))\n    (clobber (reg:DI TR0_REG))\n    (clobber (reg:DI TR1_REG))\n    (clobber (reg:DI TR2_REG))"}, {"sha": "7e6ac1a4b800dfe70c55e1d610e3b08920fd42ab", "filename": "gcc/config/sh/t-sh64", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2Fconfig%2Fsh%2Ft-sh64", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9e96203da46840cd22092cc60d23bab2eeee9ff5/gcc%2Fconfig%2Fsh%2Ft-sh64", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Ft-sh64?ref=9e96203da46840cd22092cc60d23bab2eeee9ff5", "patch": "@@ -4,7 +4,8 @@ LIB1ASMFUNCS = \\\n   _sdivsi3 _sdivsi3_i4 _udivsi3 _udivsi3_i4 _set_fpscr \\\n   _shcompact_call_trampoline _shcompact_return_trampoline \\\n   _shcompact_incoming_args _ic_invalidate _nested_trampoline \\\n-  _push_pop_shmedia_regs\n+  _push_pop_shmedia_regs \\\n+  _udivdi3 _divdi3 _umoddi3 _moddi3\n \n MULTILIB_OPTIONS = $(MULTILIB_ENDIAN) m5-32media-nofpu/m5-compact/m5-compact-nofpu/m5-64media/m5-64media-nofpu\n MULTILIB_DIRNAMES= $(MULTILIB_ENDIAN) nofpu compact nofpu/compact media64 nofpu/media64"}]}