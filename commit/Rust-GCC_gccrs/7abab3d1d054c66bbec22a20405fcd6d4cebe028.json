{"sha": "7abab3d1d054c66bbec22a20405fcd6d4cebe028", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6N2FiYWIzZDFkMDU0YzY2YmJlYzIyYTIwNDA1ZmNkNmQ0Y2ViZTAyOA==", "commit": {"author": {"name": "Felix Yang", "email": "felix.yang@huawei.com", "date": "2015-01-19T13:22:41Z"}, "committer": {"name": "Fei Yang", "email": "fyang@gcc.gnu.org", "date": "2015-01-19T13:22:41Z"}, "message": "aarch64-simd.md (aarch64_<maxmin_uns>p<mode>): New pattern.\n\n        * config/aarch64/aarch64-simd.md (aarch64_<maxmin_uns>p<mode>): New\n        pattern.\n        * config/aarch64/aarch64-simd-builtins.def (smaxp, sminp, umaxp,\n        uminp, smax_nanp, smin_nanp): New builtins.\n        * config/aarch64/arm_neon.h (vpmax_s8, vpmax_s16, vpmax_s32,\n        vpmax_u8, vpmax_u16, vpmax_u32, vpmaxq_s8, vpmaxq_s16, vpmaxq_s32,\n        vpmaxq_u8, vpmaxq_u16, vpmaxq_u32, vpmax_f32, vpmaxq_f32, vpmaxq_f64,\n        vpmaxqd_f64, vpmaxs_f32, vpmaxnm_f32, vpmaxnmq_f32, vpmaxnmq_f64,\n        vpmaxnmqd_f64, vpmaxnms_f32, vpmin_s8, vpmin_s16, vpmin_s32, vpmin_u8,\n        vpmin_u16, vpmin_u32, vpminq_s8, vpminq_s16, vpminq_s32, vpminq_u8,\n        vpminq_u16, vpminq_u32, vpmin_f32, vpminq_f32, vpminq_f64, vpminqd_f64,\n        vpmins_f32, vpminnm_f32, vpminnmq_f32, vpminnmq_f64, vpminnmqd_f64,\n        vpminnms_f32): Rewrite using builtin functions.\n\nFrom-SVN: r219840", "tree": {"sha": "e0a95420fc9db42bcdda1e22f8ab04cabae0dcfd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e0a95420fc9db42bcdda1e22f8ab04cabae0dcfd"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/7abab3d1d054c66bbec22a20405fcd6d4cebe028", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7abab3d1d054c66bbec22a20405fcd6d4cebe028", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7abab3d1d054c66bbec22a20405fcd6d4cebe028", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7abab3d1d054c66bbec22a20405fcd6d4cebe028/comments", "author": null, "committer": null, "parents": [{"sha": "0d633627cdd2d0c1f25640a0a8db313a02f1a9a7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0d633627cdd2d0c1f25640a0a8db313a02f1a9a7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0d633627cdd2d0c1f25640a0a8db313a02f1a9a7"}], "stats": {"total": 816, "additions": 332, "deletions": 484}, "files": [{"sha": "807d7d09d9c9c179b92b671f17a376ab5b950af8", "filename": "gcc/ChangeLog", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=7abab3d1d054c66bbec22a20405fcd6d4cebe028", "patch": "@@ -1,3 +1,19 @@\n+2015-01-19  Felix Yang  <felix.yang@huawei.com>\n+\n+\t* config/aarch64/aarch64-simd.md (aarch64_<maxmin_uns>p<mode>): New\n+\tpattern.\n+\t* config/aarch64/aarch64-simd-builtins.def (smaxp, sminp, umaxp,\n+\tuminp, smax_nanp, smin_nanp): New builtins.\n+\t* config/aarch64/arm_neon.h (vpmax_s8, vpmax_s16, vpmax_s32,\n+\tvpmax_u8, vpmax_u16, vpmax_u32, vpmaxq_s8, vpmaxq_s16, vpmaxq_s32,\n+\tvpmaxq_u8, vpmaxq_u16, vpmaxq_u32, vpmax_f32, vpmaxq_f32, vpmaxq_f64,\n+\tvpmaxqd_f64, vpmaxs_f32, vpmaxnm_f32, vpmaxnmq_f32, vpmaxnmq_f64,\n+\tvpmaxnmqd_f64, vpmaxnms_f32, vpmin_s8, vpmin_s16, vpmin_s32, vpmin_u8,\n+\tvpmin_u16, vpmin_u32, vpminq_s8, vpminq_s16, vpminq_s32, vpminq_u8,\n+\tvpminq_u16, vpminq_u32, vpmin_f32, vpminq_f32, vpminq_f64, vpminqd_f64,\n+\tvpmins_f32, vpminnm_f32, vpminnmq_f32, vpminnmq_f64, vpminnmqd_f64,\n+\tvpminnms_f32): Rewrite using builtin functions.\n+\n 2015-01-19  Thomas Schwinge  <thomas@codesourcery.com>\n \n \tPR libgomp/64625"}, {"sha": "1a1520c465b73a76171c6858e5b09b1bdb7b8494", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=7abab3d1d054c66bbec22a20405fcd6d4cebe028", "patch": "@@ -250,6 +250,16 @@\n   BUILTIN_VDQF (BINOP, smax_nan, 3)\n   BUILTIN_VDQF (BINOP, smin_nan, 3)\n \n+  /* Implemented by aarch64_<maxmin_uns>p<mode>.  */\n+  BUILTIN_VDQ_BHSI (BINOP, smaxp, 0)\n+  BUILTIN_VDQ_BHSI (BINOP, sminp, 0)\n+  BUILTIN_VDQ_BHSI (BINOP, umaxp, 0)\n+  BUILTIN_VDQ_BHSI (BINOP, uminp, 0)\n+  BUILTIN_VDQF (BINOP, smaxp, 0)\n+  BUILTIN_VDQF (BINOP, sminp, 0)\n+  BUILTIN_VDQF (BINOP, smax_nanp, 0)\n+  BUILTIN_VDQF (BINOP, smin_nanp, 0)\n+\n   /* Implemented by <frint_pattern><mode>2.  */\n   BUILTIN_VDQF (UNOP, btrunc, 2)\n   BUILTIN_VDQF (UNOP, ceil, 2)"}, {"sha": "968f5b2b1cb30512d7db75e4549393c15b8daccf", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=7abab3d1d054c66bbec22a20405fcd6d4cebe028", "patch": "@@ -997,6 +997,28 @@\n   DONE;\n })\n \n+;; Pairwise Integer Max/Min operations.\n+(define_insn \"aarch64_<maxmin_uns>p<mode>\"\n+ [(set (match_operand:VDQ_BHSI 0 \"register_operand\" \"=w\")\n+       (unspec:VDQ_BHSI [(match_operand:VDQ_BHSI 1 \"register_operand\" \"w\")\n+\t\t\t (match_operand:VDQ_BHSI 2 \"register_operand\" \"w\")]\n+\t\t\tMAXMINV))]\n+ \"TARGET_SIMD\"\n+ \"<maxmin_uns_op>p\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n+  [(set_attr \"type\" \"neon_minmax<q>\")]\n+)\n+\n+;; Pairwise FP Max/Min operations.\n+(define_insn \"aarch64_<maxmin_uns>p<mode>\"\n+ [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n+       (unspec:VDQF [(match_operand:VDQF 1 \"register_operand\" \"w\")\n+\t\t     (match_operand:VDQF 2 \"register_operand\" \"w\")]\n+\t\t    FMAXMINV))]\n+ \"TARGET_SIMD\"\n+ \"<maxmin_uns_op>p\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n+  [(set_attr \"type\" \"neon_minmax<q>\")]\n+)\n+\n ;; vec_concat gives a new vector with the low elements from operand 1, and\n ;; the high elements from operand 2.  That is to say, given op1 = { a, b }\n ;; op2 = { c, d }, vec_concat (op1, op2) = { a, b, c, d }."}, {"sha": "d4ce0b8a02c689cbe0fb1e41607d5b7b9b4d10c2", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 284, "deletions": 484, "changes": 768, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7abab3d1d054c66bbec22a20405fcd6d4cebe028/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=7abab3d1d054c66bbec22a20405fcd6d4cebe028", "patch": "@@ -8796,490 +8796,6 @@ vpadds_f32 (float32x2_t a)\n   return result;\n }\n \n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vpmax_f32 (float32x2_t a, float32x2_t b)\n-{\n-  float32x2_t result;\n-  __asm__ (\"fmaxp %0.2s, %1.2s, %2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n-vpmax_s8 (int8x8_t a, int8x8_t b)\n-{\n-  int8x8_t result;\n-  __asm__ (\"smaxp %0.8b, %1.8b, %2.8b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n-vpmax_s16 (int16x4_t a, int16x4_t b)\n-{\n-  int16x4_t result;\n-  __asm__ (\"smaxp %0.4h, %1.4h, %2.4h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n-vpmax_s32 (int32x2_t a, int32x2_t b)\n-{\n-  int32x2_t result;\n-  __asm__ (\"smaxp %0.2s, %1.2s, %2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n-vpmax_u8 (uint8x8_t a, uint8x8_t b)\n-{\n-  uint8x8_t result;\n-  __asm__ (\"umaxp %0.8b, %1.8b, %2.8b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n-vpmax_u16 (uint16x4_t a, uint16x4_t b)\n-{\n-  uint16x4_t result;\n-  __asm__ (\"umaxp %0.4h, %1.4h, %2.4h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n-vpmax_u32 (uint32x2_t a, uint32x2_t b)\n-{\n-  uint32x2_t result;\n-  __asm__ (\"umaxp %0.2s, %1.2s, %2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vpmaxnm_f32 (float32x2_t a, float32x2_t b)\n-{\n-  float32x2_t result;\n-  __asm__ (\"fmaxnmp %0.2s,%1.2s,%2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vpmaxnmq_f32 (float32x4_t a, float32x4_t b)\n-{\n-  float32x4_t result;\n-  __asm__ (\"fmaxnmp %0.4s,%1.4s,%2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vpmaxnmq_f64 (float64x2_t a, float64x2_t b)\n-{\n-  float64x2_t result;\n-  __asm__ (\"fmaxnmp %0.2d,%1.2d,%2.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vpmaxnmqd_f64 (float64x2_t a)\n-{\n-  float64_t result;\n-  __asm__ (\"fmaxnmp %d0,%1.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n-vpmaxnms_f32 (float32x2_t a)\n-{\n-  float32_t result;\n-  __asm__ (\"fmaxnmp %s0,%1.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vpmaxq_f32 (float32x4_t a, float32x4_t b)\n-{\n-  float32x4_t result;\n-  __asm__ (\"fmaxp %0.4s, %1.4s, %2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vpmaxq_f64 (float64x2_t a, float64x2_t b)\n-{\n-  float64x2_t result;\n-  __asm__ (\"fmaxp %0.2d, %1.2d, %2.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n-vpmaxq_s8 (int8x16_t a, int8x16_t b)\n-{\n-  int8x16_t result;\n-  __asm__ (\"smaxp %0.16b, %1.16b, %2.16b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n-vpmaxq_s16 (int16x8_t a, int16x8_t b)\n-{\n-  int16x8_t result;\n-  __asm__ (\"smaxp %0.8h, %1.8h, %2.8h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n-vpmaxq_s32 (int32x4_t a, int32x4_t b)\n-{\n-  int32x4_t result;\n-  __asm__ (\"smaxp %0.4s, %1.4s, %2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n-vpmaxq_u8 (uint8x16_t a, uint8x16_t b)\n-{\n-  uint8x16_t result;\n-  __asm__ (\"umaxp %0.16b, %1.16b, %2.16b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n-vpmaxq_u16 (uint16x8_t a, uint16x8_t b)\n-{\n-  uint16x8_t result;\n-  __asm__ (\"umaxp %0.8h, %1.8h, %2.8h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n-vpmaxq_u32 (uint32x4_t a, uint32x4_t b)\n-{\n-  uint32x4_t result;\n-  __asm__ (\"umaxp %0.4s, %1.4s, %2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vpmaxqd_f64 (float64x2_t a)\n-{\n-  float64_t result;\n-  __asm__ (\"fmaxp %d0,%1.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n-vpmaxs_f32 (float32x2_t a)\n-{\n-  float32_t result;\n-  __asm__ (\"fmaxp %s0,%1.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vpmin_f32 (float32x2_t a, float32x2_t b)\n-{\n-  float32x2_t result;\n-  __asm__ (\"fminp %0.2s, %1.2s, %2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n-vpmin_s8 (int8x8_t a, int8x8_t b)\n-{\n-  int8x8_t result;\n-  __asm__ (\"sminp %0.8b, %1.8b, %2.8b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n-vpmin_s16 (int16x4_t a, int16x4_t b)\n-{\n-  int16x4_t result;\n-  __asm__ (\"sminp %0.4h, %1.4h, %2.4h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n-vpmin_s32 (int32x2_t a, int32x2_t b)\n-{\n-  int32x2_t result;\n-  __asm__ (\"sminp %0.2s, %1.2s, %2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n-vpmin_u8 (uint8x8_t a, uint8x8_t b)\n-{\n-  uint8x8_t result;\n-  __asm__ (\"uminp %0.8b, %1.8b, %2.8b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n-vpmin_u16 (uint16x4_t a, uint16x4_t b)\n-{\n-  uint16x4_t result;\n-  __asm__ (\"uminp %0.4h, %1.4h, %2.4h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n-vpmin_u32 (uint32x2_t a, uint32x2_t b)\n-{\n-  uint32x2_t result;\n-  __asm__ (\"uminp %0.2s, %1.2s, %2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vpminnm_f32 (float32x2_t a, float32x2_t b)\n-{\n-  float32x2_t result;\n-  __asm__ (\"fminnmp %0.2s,%1.2s,%2.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vpminnmq_f32 (float32x4_t a, float32x4_t b)\n-{\n-  float32x4_t result;\n-  __asm__ (\"fminnmp %0.4s,%1.4s,%2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vpminnmq_f64 (float64x2_t a, float64x2_t b)\n-{\n-  float64x2_t result;\n-  __asm__ (\"fminnmp %0.2d,%1.2d,%2.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vpminnmqd_f64 (float64x2_t a)\n-{\n-  float64_t result;\n-  __asm__ (\"fminnmp %d0,%1.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n-vpminnms_f32 (float32x2_t a)\n-{\n-  float32_t result;\n-  __asm__ (\"fminnmp %s0,%1.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vpminq_f32 (float32x4_t a, float32x4_t b)\n-{\n-  float32x4_t result;\n-  __asm__ (\"fminp %0.4s, %1.4s, %2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vpminq_f64 (float64x2_t a, float64x2_t b)\n-{\n-  float64x2_t result;\n-  __asm__ (\"fminp %0.2d, %1.2d, %2.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n-vpminq_s8 (int8x16_t a, int8x16_t b)\n-{\n-  int8x16_t result;\n-  __asm__ (\"sminp %0.16b, %1.16b, %2.16b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n-vpminq_s16 (int16x8_t a, int16x8_t b)\n-{\n-  int16x8_t result;\n-  __asm__ (\"sminp %0.8h, %1.8h, %2.8h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n-vpminq_s32 (int32x4_t a, int32x4_t b)\n-{\n-  int32x4_t result;\n-  __asm__ (\"sminp %0.4s, %1.4s, %2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n-vpminq_u8 (uint8x16_t a, uint8x16_t b)\n-{\n-  uint8x16_t result;\n-  __asm__ (\"uminp %0.16b, %1.16b, %2.16b\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n-vpminq_u16 (uint16x8_t a, uint16x8_t b)\n-{\n-  uint16x8_t result;\n-  __asm__ (\"uminp %0.8h, %1.8h, %2.8h\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n-vpminq_u32 (uint32x4_t a, uint32x4_t b)\n-{\n-  uint32x4_t result;\n-  __asm__ (\"uminp %0.4s, %1.4s, %2.4s\"\n-           : \"=w\"(result)\n-           : \"w\"(a), \"w\"(b)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vpminqd_f64 (float64x2_t a)\n-{\n-  float64_t result;\n-  __asm__ (\"fminp %d0,%1.2d\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n-vpmins_f32 (float32x2_t a)\n-{\n-  float32_t result;\n-  __asm__ (\"fminp %s0,%1.2s\"\n-           : \"=w\"(result)\n-           : \"w\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vqdmulh_n_s16 (int16x4_t a, int16_t b)\n {\n@@ -17928,6 +17444,290 @@ vmaxq_u32 (uint32x4_t __a, uint32x4_t __b)\n \t\t\t\t\t\t  (int32x4_t) __b);\n }\n \n+/* vpmax  */\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vpmax_s8 (int8x8_t a, int8x8_t b)\n+{\n+  return __builtin_aarch64_smaxpv8qi (a, b);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vpmax_s16 (int16x4_t a, int16x4_t b)\n+{\n+  return __builtin_aarch64_smaxpv4hi (a, b);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vpmax_s32 (int32x2_t a, int32x2_t b)\n+{\n+  return __builtin_aarch64_smaxpv2si (a, b);\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vpmax_u8 (uint8x8_t a, uint8x8_t b)\n+{\n+  return (uint8x8_t) __builtin_aarch64_umaxpv8qi ((int8x8_t) a,\n+\t\t\t\t\t\t  (int8x8_t) b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vpmax_u16 (uint16x4_t a, uint16x4_t b)\n+{\n+  return (uint16x4_t) __builtin_aarch64_umaxpv4hi ((int16x4_t) a,\n+\t\t\t\t\t\t   (int16x4_t) b);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vpmax_u32 (uint32x2_t a, uint32x2_t b)\n+{\n+  return (uint32x2_t) __builtin_aarch64_umaxpv2si ((int32x2_t) a,\n+\t\t\t\t\t\t   (int32x2_t) b);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vpmaxq_s8 (int8x16_t a, int8x16_t b)\n+{\n+  return __builtin_aarch64_smaxpv16qi (a, b);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vpmaxq_s16 (int16x8_t a, int16x8_t b)\n+{\n+  return __builtin_aarch64_smaxpv8hi (a, b);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vpmaxq_s32 (int32x4_t a, int32x4_t b)\n+{\n+  return __builtin_aarch64_smaxpv4si (a, b);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vpmaxq_u8 (uint8x16_t a, uint8x16_t b)\n+{\n+  return (uint8x16_t) __builtin_aarch64_umaxpv16qi ((int8x16_t) a,\n+\t\t\t\t\t\t    (int8x16_t) b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vpmaxq_u16 (uint16x8_t a, uint16x8_t b)\n+{\n+  return (uint16x8_t) __builtin_aarch64_umaxpv8hi ((int16x8_t) a,\n+\t\t\t\t\t\t   (int16x8_t) b);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vpmaxq_u32 (uint32x4_t a, uint32x4_t b)\n+{\n+  return (uint32x4_t) __builtin_aarch64_umaxpv4si ((int32x4_t) a,\n+\t\t\t\t\t\t   (int32x4_t) b);\n+}\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vpmax_f32 (float32x2_t a, float32x2_t b)\n+{\n+  return __builtin_aarch64_smax_nanpv2sf (a, b);\n+}\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vpmaxq_f32 (float32x4_t a, float32x4_t b)\n+{\n+  return __builtin_aarch64_smax_nanpv4sf (a, b);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vpmaxq_f64 (float64x2_t a, float64x2_t b)\n+{\n+  return __builtin_aarch64_smax_nanpv2df (a, b);\n+}\n+\n+__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n+vpmaxqd_f64 (float64x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smax_nan_scal_v2df (a);\n+}\n+\n+__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n+vpmaxs_f32 (float32x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smax_nan_scal_v2sf (a);\n+}\n+\n+/* vpmaxnm  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vpmaxnm_f32 (float32x2_t a, float32x2_t b)\n+{\n+  return __builtin_aarch64_smaxpv2sf (a, b);\n+}\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vpmaxnmq_f32 (float32x4_t a, float32x4_t b)\n+{\n+  return __builtin_aarch64_smaxpv4sf (a, b);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vpmaxnmq_f64 (float64x2_t a, float64x2_t b)\n+{\n+  return __builtin_aarch64_smaxpv2df (a, b);\n+}\n+\n+__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n+vpmaxnmqd_f64 (float64x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smax_scal_v2df (a);\n+}\n+\n+__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n+vpmaxnms_f32 (float32x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smax_scal_v2sf (a);\n+}\n+\n+/* vpmin  */\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vpmin_s8 (int8x8_t a, int8x8_t b)\n+{\n+  return __builtin_aarch64_sminpv8qi (a, b);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vpmin_s16 (int16x4_t a, int16x4_t b)\n+{\n+  return __builtin_aarch64_sminpv4hi (a, b);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vpmin_s32 (int32x2_t a, int32x2_t b)\n+{\n+  return __builtin_aarch64_sminpv2si (a, b);\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vpmin_u8 (uint8x8_t a, uint8x8_t b)\n+{\n+  return (uint8x8_t) __builtin_aarch64_uminpv8qi ((int8x8_t) a,\n+\t\t\t\t\t\t  (int8x8_t) b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vpmin_u16 (uint16x4_t a, uint16x4_t b)\n+{\n+  return (uint16x4_t) __builtin_aarch64_uminpv4hi ((int16x4_t) a,\n+\t\t\t\t\t\t   (int16x4_t) b);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vpmin_u32 (uint32x2_t a, uint32x2_t b)\n+{\n+  return (uint32x2_t) __builtin_aarch64_uminpv2si ((int32x2_t) a,\n+\t\t\t\t\t\t   (int32x2_t) b);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vpminq_s8 (int8x16_t a, int8x16_t b)\n+{\n+  return __builtin_aarch64_sminpv16qi (a, b);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vpminq_s16 (int16x8_t a, int16x8_t b)\n+{\n+  return __builtin_aarch64_sminpv8hi (a, b);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vpminq_s32 (int32x4_t a, int32x4_t b)\n+{\n+  return __builtin_aarch64_sminpv4si (a, b);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vpminq_u8 (uint8x16_t a, uint8x16_t b)\n+{\n+  return (uint8x16_t) __builtin_aarch64_uminpv16qi ((int8x16_t) a,\n+\t\t\t\t\t\t    (int8x16_t) b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vpminq_u16 (uint16x8_t a, uint16x8_t b)\n+{\n+  return (uint16x8_t) __builtin_aarch64_uminpv8hi ((int16x8_t) a,\n+\t\t\t\t\t\t   (int16x8_t) b);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vpminq_u32 (uint32x4_t a, uint32x4_t b)\n+{\n+  return (uint32x4_t) __builtin_aarch64_uminpv4si ((int32x4_t) a,\n+\t\t\t\t\t\t   (int32x4_t) b);\n+}\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vpmin_f32 (float32x2_t a, float32x2_t b)\n+{\n+  return __builtin_aarch64_smin_nanpv2sf (a, b);\n+}\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vpminq_f32 (float32x4_t a, float32x4_t b)\n+{\n+  return __builtin_aarch64_smin_nanpv4sf (a, b);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vpminq_f64 (float64x2_t a, float64x2_t b)\n+{\n+  return __builtin_aarch64_smin_nanpv2df (a, b);\n+}\n+\n+__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n+vpminqd_f64 (float64x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smin_nan_scal_v2df (a);\n+}\n+\n+__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n+vpmins_f32 (float32x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smin_nan_scal_v2sf (a);\n+}\n+\n+/* vpminnm  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vpminnm_f32 (float32x2_t a, float32x2_t b)\n+{\n+  return __builtin_aarch64_sminpv2sf (a, b);\n+}\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vpminnmq_f32 (float32x4_t a, float32x4_t b)\n+{\n+  return __builtin_aarch64_sminpv4sf (a, b);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vpminnmq_f64 (float64x2_t a, float64x2_t b)\n+{\n+  return __builtin_aarch64_sminpv2df (a, b);\n+}\n+\n+__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n+vpminnmqd_f64 (float64x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smin_scal_v2df (a);\n+}\n+\n+__extension__ static __inline float32_t __attribute__ ((__always_inline__))\n+vpminnms_f32 (float32x2_t a)\n+{\n+  return __builtin_aarch64_reduc_smin_scal_v2sf (a);\n+}\n+\n /* vmaxnm  */\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))"}]}