{"sha": "8a91d5455313fb3c4fc07935d848921012cb297f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OGE5MWQ1NDU1MzEzZmIzYzRmYzA3OTM1ZDg0ODkyMTAxMmNiMjk3Zg==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-12-20T12:56:50Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-12-20T12:56:50Z"}, "message": "poly_int: store merging\n\nThis patch makes pass_store_merging track polynomial sizes\nand offsets.  store_immediate_info remains restricted to stores\nwith a constant offset and size.\n\n2017-12-20  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* poly-int-types.h (round_down_to_byte_boundary): New macro.\n\t(round_up_to_byte_boundary): Likewise.\n\t* expr.h (get_bit_range): Add temporary shim.\n\t* gimple-ssa-store-merging.c (store_operand_info): Change the\n\tbitsize, bitpos, bitregion_start and bitregion_end fields from\n\tunsigned HOST_WIDE_INT to poly_uint64.\n\t(merged_store_group): Likewise load_align_base.\n\t(compatible_load_p, compatible_load_p): Update accordingly.\n\t(imm_store_chain_info::coalesce_immediate_stores): Likewise.\n\t(split_group, imm_store_chain_info::output_merged_store): Likewise.\n\t(mem_valid_for_store_merging): Return the bitsize, bitpos,\n\tbitregion_start and bitregion_end as poly_uint64s rather than\n\tunsigned HOST_WIDE_INTs.  Track polynomial offsets internally.\n\t(handled_load): Take the bitsize, bitpos,\n\tbitregion_start and bitregion_end as poly_uint64s rather than\n\tunsigned HOST_WIDE_INTs.\n\t(pass_store_merging::process_store): Update call to\n\tmem_valid_for_store_merging.\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r255894", "tree": {"sha": "c67e2c4060eba6622d9a7853ef5030b77da88297", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c67e2c4060eba6622d9a7853ef5030b77da88297"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/8a91d5455313fb3c4fc07935d848921012cb297f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8a91d5455313fb3c4fc07935d848921012cb297f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8a91d5455313fb3c4fc07935d848921012cb297f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8a91d5455313fb3c4fc07935d848921012cb297f/comments", "author": null, "committer": null, "parents": [{"sha": "7df9b6f12abfa68c13d9485855dbe22da3167d49", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7df9b6f12abfa68c13d9485855dbe22da3167d49", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7df9b6f12abfa68c13d9485855dbe22da3167d49"}], "stats": {"total": 196, "additions": 124, "deletions": 72}, "files": [{"sha": "5ccbe5d3b026d31d526d2619a6334bb316b53898", "filename": "gcc/ChangeLog", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=8a91d5455313fb3c4fc07935d848921012cb297f", "patch": "@@ -1,3 +1,26 @@\n+2017-12-20  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* poly-int-types.h (round_down_to_byte_boundary): New macro.\n+\t(round_up_to_byte_boundary): Likewise.\n+\t* expr.h (get_bit_range): Add temporary shim.\n+\t* gimple-ssa-store-merging.c (store_operand_info): Change the\n+\tbitsize, bitpos, bitregion_start and bitregion_end fields from\n+\tunsigned HOST_WIDE_INT to poly_uint64.\n+\t(merged_store_group): Likewise load_align_base.\n+\t(compatible_load_p, compatible_load_p): Update accordingly.\n+\t(imm_store_chain_info::coalesce_immediate_stores): Likewise.\n+\t(split_group, imm_store_chain_info::output_merged_store): Likewise.\n+\t(mem_valid_for_store_merging): Return the bitsize, bitpos,\n+\tbitregion_start and bitregion_end as poly_uint64s rather than\n+\tunsigned HOST_WIDE_INTs.  Track polynomial offsets internally.\n+\t(handled_load): Take the bitsize, bitpos,\n+\tbitregion_start and bitregion_end as poly_uint64s rather than\n+\tunsigned HOST_WIDE_INTs.\n+\t(pass_store_merging::process_store): Update call to\n+\tmem_valid_for_store_merging.\n+\n 2017-12-20  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "9b0927197d57e71465fcaf7dfdb060874f82c26d", "filename": "gcc/expr.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=8a91d5455313fb3c4fc07935d848921012cb297f", "patch": "@@ -243,6 +243,15 @@ extern bool emit_push_insn (rtx, machine_mode, tree, rtx, unsigned int,\n extern void get_bit_range (unsigned HOST_WIDE_INT *, unsigned HOST_WIDE_INT *,\n \t\t\t   tree, HOST_WIDE_INT *, tree *);\n \n+/* Temporary.  */\n+inline void\n+get_bit_range (poly_uint64_pod *bitstart, poly_uint64_pod *bitend, tree exp,\n+\t       poly_int64_pod *bitpos, tree *offset)\n+{\n+  get_bit_range (&bitstart->coeffs[0], &bitend->coeffs[0], exp,\n+\t\t &bitpos->coeffs[0], offset);\n+}\n+\n /* Expand an assignment that stores the value of FROM into TO.  */\n extern void expand_assignment (tree, tree, bool);\n "}, {"sha": "078acca82122df084932c7744b0c5b87a079184f", "filename": "gcc/gimple-ssa-store-merging.c", "status": "modified", "additions": 80, "deletions": 72, "changes": 152, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2Fgimple-ssa-store-merging.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2Fgimple-ssa-store-merging.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-store-merging.c?ref=8a91d5455313fb3c4fc07935d848921012cb297f", "patch": "@@ -1321,10 +1321,10 @@ struct store_operand_info\n {\n   tree val;\n   tree base_addr;\n-  unsigned HOST_WIDE_INT bitsize;\n-  unsigned HOST_WIDE_INT bitpos;\n-  unsigned HOST_WIDE_INT bitregion_start;\n-  unsigned HOST_WIDE_INT bitregion_end;\n+  poly_uint64 bitsize;\n+  poly_uint64 bitpos;\n+  poly_uint64 bitregion_start;\n+  poly_uint64 bitregion_end;\n   gimple *stmt;\n   bool bit_not_p;\n   store_operand_info ();\n@@ -1414,7 +1414,7 @@ struct merged_store_group\n   /* The size of the allocated memory for val and mask.  */\n   unsigned HOST_WIDE_INT buf_size;\n   unsigned HOST_WIDE_INT align_base;\n-  unsigned HOST_WIDE_INT load_align_base[2];\n+  poly_uint64 load_align_base[2];\n \n   unsigned int align;\n   unsigned int load_align[2];\n@@ -2198,8 +2198,8 @@ compatible_load_p (merged_store_group *merged_store,\n {\n   store_immediate_info *infof = merged_store->stores[0];\n   if (!info->ops[idx].base_addr\n-      || (info->ops[idx].bitpos - infof->ops[idx].bitpos\n-\t  != info->bitpos - infof->bitpos)\n+      || maybe_ne (info->ops[idx].bitpos - infof->ops[idx].bitpos,\n+\t\t   info->bitpos - infof->bitpos)\n       || !operand_equal_p (info->ops[idx].base_addr,\n \t\t\t   infof->ops[idx].base_addr, 0))\n     return false;\n@@ -2229,7 +2229,7 @@ compatible_load_p (merged_store_group *merged_store,\n      the construction of the immediate chain info guarantees no intervening\n      stores, so no further checks are needed.  Example:\n      _1 = s.a; _2 = _1 & -7; s.a = _2; _3 = s.b; _4 = _3 & -7; s.b = _4;  */\n-  if (info->ops[idx].bitpos == info->bitpos\n+  if (known_eq (info->ops[idx].bitpos, info->bitpos)\n       && operand_equal_p (info->ops[idx].base_addr, base_addr, 0))\n     return true;\n \n@@ -2624,8 +2624,8 @@ imm_store_chain_info::coalesce_immediate_stores ()\n \t      && infof->ops[1].base_addr\n \t      && info->ops[0].base_addr\n \t      && info->ops[1].base_addr\n-\t      && (info->ops[1].bitpos - infof->ops[0].bitpos\n-\t\t  == info->bitpos - infof->bitpos)\n+\t      && known_eq (info->ops[1].bitpos - infof->ops[0].bitpos,\n+\t\t\t   info->bitpos - infof->bitpos)\n \t      && operand_equal_p (info->ops[1].base_addr,\n \t\t\t\t  infof->ops[0].base_addr, 0))\n \t    {\n@@ -3031,11 +3031,12 @@ split_group (merged_store_group *group, bool allow_unaligned_store,\n \t  for (int i = 0; i < 2; ++i)\n \t    if (group->load_align[i])\n \t      {\n-\t\talign_bitpos = try_bitpos - group->stores[0]->bitpos;\n-\t\talign_bitpos += group->stores[0]->ops[i].bitpos;\n-\t\talign_bitpos -= group->load_align_base[i];\n-\t\talign_bitpos &= (group_load_align - 1);\n-\t\tif (align_bitpos)\n+\t\talign_bitpos\n+\t\t  = known_alignment (try_bitpos\n+\t\t\t\t     - group->stores[0]->bitpos\n+\t\t\t\t     + group->stores[0]->ops[i].bitpos\n+\t\t\t\t     - group->load_align_base[i]);\n+\t\tif (align_bitpos & (group_load_align - 1))\n \t\t  {\n \t\t    unsigned HOST_WIDE_INT a = least_bit_hwi (align_bitpos);\n \t\t    load_align = MIN (load_align, a);\n@@ -3491,21 +3492,22 @@ imm_store_chain_info::output_merged_store (merged_store_group *group)\n \n \t\t  unsigned HOST_WIDE_INT load_align = group->load_align[j];\n \t\t  unsigned HOST_WIDE_INT align_bitpos\n-\t\t    = (try_pos * BITS_PER_UNIT\n-\t\t       - split_store->orig_stores[0]->bitpos\n-\t\t       + op.bitpos) & (load_align - 1);\n-\t\t  if (align_bitpos)\n+\t\t    = known_alignment (try_pos * BITS_PER_UNIT\n+\t\t\t\t       - split_store->orig_stores[0]->bitpos\n+\t\t\t\t       + op.bitpos);\n+\t\t  if (align_bitpos & (load_align - 1))\n \t\t    load_align = least_bit_hwi (align_bitpos);\n \n \t\t  tree load_int_type\n \t\t    = build_nonstandard_integer_type (try_size, UNSIGNED);\n \t\t  load_int_type\n \t\t    = build_aligned_type (load_int_type, load_align);\n \n-\t\t  unsigned HOST_WIDE_INT load_pos\n-\t\t    = (try_pos * BITS_PER_UNIT\n-\t\t       - split_store->orig_stores[0]->bitpos\n-\t\t       + op.bitpos) / BITS_PER_UNIT;\n+\t\t  poly_uint64 load_pos\n+\t\t    = exact_div (try_pos * BITS_PER_UNIT\n+\t\t\t\t - split_store->orig_stores[0]->bitpos\n+\t\t\t\t + op.bitpos,\n+\t\t\t\t BITS_PER_UNIT);\n \t\t  ops[j] = fold_build2 (MEM_REF, load_int_type, load_addr[j],\n \t\t\t\t\tbuild_int_cst (offset_type, load_pos));\n \t\t  if (TREE_CODE (ops[j]) == MEM_REF)\n@@ -3811,30 +3813,28 @@ rhs_valid_for_store_merging_p (tree rhs)\n    case.  */\n \n static tree\n-mem_valid_for_store_merging (tree mem, unsigned HOST_WIDE_INT *pbitsize,\n-\t\t\t     unsigned HOST_WIDE_INT *pbitpos,\n-\t\t\t     unsigned HOST_WIDE_INT *pbitregion_start,\n-\t\t\t     unsigned HOST_WIDE_INT *pbitregion_end)\n+mem_valid_for_store_merging (tree mem, poly_uint64 *pbitsize,\n+\t\t\t     poly_uint64 *pbitpos,\n+\t\t\t     poly_uint64 *pbitregion_start,\n+\t\t\t     poly_uint64 *pbitregion_end)\n {\n-  HOST_WIDE_INT bitsize;\n-  HOST_WIDE_INT bitpos;\n-  unsigned HOST_WIDE_INT bitregion_start = 0;\n-  unsigned HOST_WIDE_INT bitregion_end = 0;\n+  poly_int64 bitsize, bitpos;\n+  poly_uint64 bitregion_start = 0, bitregion_end = 0;\n   machine_mode mode;\n   int unsignedp = 0, reversep = 0, volatilep = 0;\n   tree offset;\n   tree base_addr = get_inner_reference (mem, &bitsize, &bitpos, &offset, &mode,\n \t\t\t\t\t&unsignedp, &reversep, &volatilep);\n   *pbitsize = bitsize;\n-  if (bitsize == 0)\n+  if (known_eq (bitsize, 0))\n     return NULL_TREE;\n \n   if (TREE_CODE (mem) == COMPONENT_REF\n       && DECL_BIT_FIELD_TYPE (TREE_OPERAND (mem, 1)))\n     {\n       get_bit_range (&bitregion_start, &bitregion_end, mem, &bitpos, &offset);\n-      if (bitregion_end)\n-\t++bitregion_end;\n+      if (maybe_ne (bitregion_end, 0U))\n+\tbitregion_end += 1;\n     }\n \n   if (reversep)\n@@ -3850,24 +3850,20 @@ mem_valid_for_store_merging (tree mem, unsigned HOST_WIDE_INT *pbitsize,\n      PR 23684 and this way we can catch more chains.  */\n   else if (TREE_CODE (base_addr) == MEM_REF)\n     {\n-      offset_int bit_off, byte_off = mem_ref_offset (base_addr);\n-      bit_off = byte_off << LOG2_BITS_PER_UNIT;\n+      poly_offset_int byte_off = mem_ref_offset (base_addr);\n+      poly_offset_int bit_off = byte_off << LOG2_BITS_PER_UNIT;\n       bit_off += bitpos;\n-      if (!wi::neg_p (bit_off) && wi::fits_shwi_p (bit_off))\n+      if (known_ge (bit_off, 0) && bit_off.to_shwi (&bitpos))\n \t{\n-\t  bitpos = bit_off.to_shwi ();\n-\t  if (bitregion_end)\n+\t  if (maybe_ne (bitregion_end, 0U))\n \t    {\n \t      bit_off = byte_off << LOG2_BITS_PER_UNIT;\n \t      bit_off += bitregion_start;\n-\t      if (wi::fits_uhwi_p (bit_off))\n+\t      if (bit_off.to_uhwi (&bitregion_start))\n \t\t{\n-\t\t  bitregion_start = bit_off.to_uhwi ();\n \t\t  bit_off = byte_off << LOG2_BITS_PER_UNIT;\n \t\t  bit_off += bitregion_end;\n-\t\t  if (wi::fits_uhwi_p (bit_off))\n-\t\t    bitregion_end = bit_off.to_uhwi ();\n-\t\t  else\n+\t\t  if (!bit_off.to_uhwi (&bitregion_end))\n \t\t    bitregion_end = 0;\n \t\t}\n \t      else\n@@ -3882,15 +3878,15 @@ mem_valid_for_store_merging (tree mem, unsigned HOST_WIDE_INT *pbitsize,\n      address now.  */\n   else\n     {\n-      if (bitpos < 0)\n+      if (maybe_lt (bitpos, 0))\n \treturn NULL_TREE;\n       base_addr = build_fold_addr_expr (base_addr);\n     }\n \n-  if (!bitregion_end)\n+  if (known_eq (bitregion_end, 0U))\n     {\n-      bitregion_start = ROUND_DOWN (bitpos, BITS_PER_UNIT);\n-      bitregion_end = ROUND_UP (bitpos + bitsize, BITS_PER_UNIT);\n+      bitregion_start = round_down_to_byte_boundary (bitpos);\n+      bitregion_end = round_up_to_byte_boundary (bitpos + bitsize);\n     }\n \n   if (offset != NULL_TREE)\n@@ -3922,9 +3918,8 @@ mem_valid_for_store_merging (tree mem, unsigned HOST_WIDE_INT *pbitsize,\n \n static bool\n handled_load (gimple *stmt, store_operand_info *op,\n-\t      unsigned HOST_WIDE_INT bitsize, unsigned HOST_WIDE_INT bitpos,\n-\t      unsigned HOST_WIDE_INT bitregion_start,\n-\t      unsigned HOST_WIDE_INT bitregion_end)\n+\t      poly_uint64 bitsize, poly_uint64 bitpos,\n+\t      poly_uint64 bitregion_start, poly_uint64 bitregion_end)\n {\n   if (!is_gimple_assign (stmt))\n     return false;\n@@ -3956,10 +3951,12 @@ handled_load (gimple *stmt, store_operand_info *op,\n \t\t\t\t       &op->bitregion_start,\n \t\t\t\t       &op->bitregion_end);\n       if (op->base_addr != NULL_TREE\n-\t  && op->bitsize == bitsize\n-\t  && ((op->bitpos - bitpos) % BITS_PER_UNIT) == 0\n-\t  && op->bitpos - op->bitregion_start >= bitpos - bitregion_start\n-\t  && op->bitregion_end - op->bitpos >= bitregion_end - bitpos)\n+\t  && known_eq (op->bitsize, bitsize)\n+\t  && multiple_p (op->bitpos - bitpos, BITS_PER_UNIT)\n+\t  && known_ge (op->bitpos - op->bitregion_start,\n+\t\t       bitpos - bitregion_start)\n+\t  && known_ge (op->bitregion_end - op->bitpos,\n+\t\t       bitregion_end - bitpos))\n \t{\n \t  op->stmt = stmt;\n \t  op->val = mem;\n@@ -3978,18 +3975,18 @@ pass_store_merging::process_store (gimple *stmt)\n {\n   tree lhs = gimple_assign_lhs (stmt);\n   tree rhs = gimple_assign_rhs1 (stmt);\n-  unsigned HOST_WIDE_INT bitsize, bitpos;\n-  unsigned HOST_WIDE_INT bitregion_start;\n-  unsigned HOST_WIDE_INT bitregion_end;\n+  poly_uint64 bitsize, bitpos;\n+  poly_uint64 bitregion_start, bitregion_end;\n   tree base_addr\n     = mem_valid_for_store_merging (lhs, &bitsize, &bitpos,\n \t\t\t\t   &bitregion_start, &bitregion_end);\n-  if (bitsize == 0)\n+  if (known_eq (bitsize, 0U))\n     return;\n \n   bool invalid = (base_addr == NULL_TREE\n-\t\t  || ((bitsize > MAX_BITSIZE_MODE_ANY_INT)\n-\t\t       && (TREE_CODE (rhs) != INTEGER_CST)));\n+\t\t  || (maybe_gt (bitsize,\n+\t\t\t\t(unsigned int) MAX_BITSIZE_MODE_ANY_INT)\n+\t\t      && (TREE_CODE (rhs) != INTEGER_CST)));\n   enum tree_code rhs_code = ERROR_MARK;\n   bool bit_not_p = false;\n   struct symbolic_number n;\n@@ -4058,17 +4055,20 @@ pass_store_merging::process_store (gimple *stmt)\n \t    invalid = true;\n \t    break;\n \t  }\n-      if ((bitsize % BITS_PER_UNIT) == 0\n-\t  && (bitpos % BITS_PER_UNIT) == 0\n-\t  && bitsize <= 64\n+      unsigned HOST_WIDE_INT const_bitsize;\n+      if (bitsize.is_constant (&const_bitsize)\n+\t  && multiple_p (const_bitsize, BITS_PER_UNIT)\n+\t  && multiple_p (bitpos, BITS_PER_UNIT)\n+\t  && const_bitsize <= 64\n \t  && BYTES_BIG_ENDIAN == WORDS_BIG_ENDIAN)\n \t{\n \t  ins_stmt = find_bswap_or_nop_1 (def_stmt, &n, 12);\n \t  if (ins_stmt)\n \t    {\n \t      uint64_t nn = n.n;\n \t      for (unsigned HOST_WIDE_INT i = 0;\n-\t\t   i < bitsize; i += BITS_PER_UNIT, nn >>= BITS_PER_MARKER)\n+\t\t   i < const_bitsize;\n+\t\t   i += BITS_PER_UNIT, nn >>= BITS_PER_MARKER)\n \t\tif ((nn & MARKER_MASK) == 0\n \t\t    || (nn & MARKER_MASK) == MARKER_BYTE_UNKNOWN)\n \t\t  {\n@@ -4089,7 +4089,13 @@ pass_store_merging::process_store (gimple *stmt)\n \t}\n     }\n \n-  if (invalid)\n+  unsigned HOST_WIDE_INT const_bitsize, const_bitpos;\n+  unsigned HOST_WIDE_INT const_bitregion_start, const_bitregion_end;\n+  if (invalid\n+      || !bitsize.is_constant (&const_bitsize)\n+      || !bitpos.is_constant (&const_bitpos)\n+      || !bitregion_start.is_constant (&const_bitregion_start)\n+      || !bitregion_end.is_constant (&const_bitregion_end))\n     {\n       terminate_all_aliasing_chains (NULL, stmt);\n       return;\n@@ -4106,9 +4112,10 @@ pass_store_merging::process_store (gimple *stmt)\n   if (chain_info)\n     {\n       unsigned int ord = (*chain_info)->m_store_info.length ();\n-      info = new store_immediate_info (bitsize, bitpos, bitregion_start,\n-\t\t\t\t       bitregion_end, stmt, ord, rhs_code,\n-\t\t\t\t       n, ins_stmt,\n+      info = new store_immediate_info (const_bitsize, const_bitpos,\n+\t\t\t\t       const_bitregion_start,\n+\t\t\t\t       const_bitregion_end,\n+\t\t\t\t       stmt, ord, rhs_code, n, ins_stmt,\n \t\t\t\t       bit_not_p, ops[0], ops[1]);\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \t{\n@@ -4135,9 +4142,10 @@ pass_store_merging::process_store (gimple *stmt)\n   /* Start a new chain.  */\n   struct imm_store_chain_info *new_chain\n     = new imm_store_chain_info (m_stores_head, base_addr);\n-  info = new store_immediate_info (bitsize, bitpos, bitregion_start,\n-\t\t\t\t   bitregion_end, stmt, 0, rhs_code,\n-\t\t\t\t   n, ins_stmt,\n+  info = new store_immediate_info (const_bitsize, const_bitpos,\n+\t\t\t\t   const_bitregion_start,\n+\t\t\t\t   const_bitregion_end,\n+\t\t\t\t   stmt, 0, rhs_code, n, ins_stmt,\n \t\t\t\t   bit_not_p, ops[0], ops[1]);\n   new_chain->m_store_info.safe_push (info);\n   m_stores.put (base_addr, new_chain);"}, {"sha": "d681c374fc1be945e34fcf435bdcf02eb5c68440", "filename": "gcc/poly-int-types.h", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2Fpoly-int-types.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8a91d5455313fb3c4fc07935d848921012cb297f/gcc%2Fpoly-int-types.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpoly-int-types.h?ref=8a91d5455313fb3c4fc07935d848921012cb297f", "patch": "@@ -60,6 +60,18 @@ typedef poly_int<NUM_POLY_INT_COEFFS, widest_int> poly_widest_int;\n    of bytes in size.  */\n #define num_trailing_bits(X) force_get_misalignment (X, BITS_PER_UNIT)\n \n+/* Round bit quantity X down to the nearest byte boundary.\n+\n+   This is safe because non-constant mode sizes must be a whole number\n+   of bytes in size.  */\n+#define round_down_to_byte_boundary(X) force_align_down (X, BITS_PER_UNIT)\n+\n+/* Round bit quantity X up the nearest byte boundary.\n+\n+   This is safe because non-constant mode sizes must be a whole number\n+   of bytes in size.  */\n+#define round_up_to_byte_boundary(X) force_align_up (X, BITS_PER_UNIT)\n+\n /* Return the size of an element in a vector of size SIZE, given that\n    the vector has NELTS elements.  The return value is in the same units\n    as SIZE (either bits or bytes)."}]}