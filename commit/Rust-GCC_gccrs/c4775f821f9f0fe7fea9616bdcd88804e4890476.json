{"sha": "c4775f821f9f0fe7fea9616bdcd88804e4890476", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzQ3NzVmODIxZjlmMGZlN2ZlYTk2MTZiZGNkODg4MDRlNDg5MDQ3Ng==", "commit": {"author": {"name": "Mike Stump", "email": "mrs@apple.com", "date": "2003-03-13T20:19:03Z"}, "committer": {"name": "Mike Stump", "email": "mrs@gcc.gnu.org", "date": "2003-03-13T20:19:03Z"}, "message": "ggc-page.c (struct page_entry): Remove varray.h header.\n\n        * ggc-page.c (struct page_entry): Remove varray.h header.\n        Add index_by_depth field.\n        Remove save_in_use_p field.\n        (struct globals): Add depth_in_use, depth_max, by_depth_in_use,\n        by_depth_max, by_depth, and save_in_use fields.\n        (INITIAL_PTE_COUNT): Add.\n        (save_in_use_p_i): Add.\n        (save_in_use_p): Add.\n        (adjust_depth): Add.\n        (move_ptes_to_front): Add.\n        (push_depth): Add.\n        (push_by_depth): Add.\n        (prefetch): Add.\n        (free_page): Add support for and use faster data structures.\n        (ggc_alloc): Likewise.\n        (init_ggc): Likewise.\n        (ggc_recalculate_in_use_p): Likewise.\n        (ggc_pop_context): Likewise.\n        (clear_marks): Likewise.\n        (ggc_pch_read): Likewise.\n        * Makefile.in (ggc-page.o): Remove varray.h.\n\nFrom-SVN: r64320", "tree": {"sha": "f54fccfa6b1c14054bf5b38280284bb0b9f73719", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f54fccfa6b1c14054bf5b38280284bb0b9f73719"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c4775f821f9f0fe7fea9616bdcd88804e4890476", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c4775f821f9f0fe7fea9616bdcd88804e4890476", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c4775f821f9f0fe7fea9616bdcd88804e4890476", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c4775f821f9f0fe7fea9616bdcd88804e4890476/comments", "author": null, "committer": null, "parents": [{"sha": "26f86471531d569c550a3e16fbd88a0cae6f18dd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/26f86471531d569c550a3e16fbd88a0cae6f18dd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/26f86471531d569c550a3e16fbd88a0cae6f18dd"}], "stats": {"total": 344, "additions": 316, "deletions": 28}, "files": [{"sha": "0b3f89542b25ffa6217224fb6ba76b3fbbf745f2", "filename": "gcc/ChangeLog", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c4775f821f9f0fe7fea9616bdcd88804e4890476/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c4775f821f9f0fe7fea9616bdcd88804e4890476/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c4775f821f9f0fe7fea9616bdcd88804e4890476", "patch": "@@ -1,3 +1,27 @@\n+2003-03-13  Mike Stump  <mrs@apple.com>\n+\n+\t* ggc-page.c (struct page_entry): Remove varray.h header.\n+\tAdd index_by_depth field.\n+\tRemove save_in_use_p field.\n+\t(struct globals): Add depth_in_use, depth_max, by_depth_in_use,\n+\tby_depth_max, by_depth, and save_in_use fields.\n+\t(INITIAL_PTE_COUNT): Add.\n+\t(save_in_use_p_i): Add.\n+\t(save_in_use_p): Add.\n+\t(adjust_depth): Add.\n+\t(move_ptes_to_front): Add.\n+\t(push_depth): Add.\n+\t(push_by_depth): Add.\n+\t(prefetch): Add.\n+\t(free_page): Add support for and use faster data structures.\n+\t(ggc_alloc): Likewise.\n+\t(init_ggc): Likewise.\n+\t(ggc_recalculate_in_use_p): Likewise.\n+\t(ggc_pop_context): Likewise.\n+\t(clear_marks): Likewise.\n+\t(ggc_pch_read): Likewise.\n+\t* Makefile.in (ggc-page.o): Remove varray.h.\n+\n 2003-03-13  Nathanael Nerode  <neroden@gcc.gnu.org>\n \n \t* ChangeLog: Rotated last year's entries to..."}, {"sha": "9fc322219d864d9a3f1c5079ebc60fb068c75848", "filename": "gcc/Makefile.in", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c4775f821f9f0fe7fea9616bdcd88804e4890476/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c4775f821f9f0fe7fea9616bdcd88804e4890476/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=c4775f821f9f0fe7fea9616bdcd88804e4890476", "patch": "@@ -1421,7 +1421,7 @@ ggc-simple.o: ggc-simple.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H)\n \tflags.h $(GGC_H) varray.h $(TIMEVAR_H) $(TM_P_H) $(PARAMS_H)\n \n ggc-page.o: ggc-page.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(TREE_H) \\\n-\tflags.h toplev.h $(GGC_H) varray.h $(TIMEVAR_H) $(TM_P_H) $(PARAMS_H)\n+\tflags.h toplev.h $(GGC_H) $(TIMEVAR_H) $(TM_P_H) $(PARAMS_H)\n \n stringpool.o: stringpool.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n \t$(TREE_H) $(GGC_H) gt-stringpool.h"}, {"sha": "ab278ee603a49685b1a8d9dceea511edf77f40ce", "filename": "gcc/ggc-page.c", "status": "modified", "additions": 291, "deletions": 27, "changes": 318, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c4775f821f9f0fe7fea9616bdcd88804e4890476/gcc%2Fggc-page.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c4775f821f9f0fe7fea9616bdcd88804e4890476/gcc%2Fggc-page.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc-page.c?ref=c4775f821f9f0fe7fea9616bdcd88804e4890476", "patch": "@@ -26,7 +26,6 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"rtl.h\"\n #include \"tm_p.h\"\n #include \"toplev.h\"\n-#include \"varray.h\"\n #include \"flags.h\"\n #include \"ggc.h\"\n #include \"timevar.h\"\n@@ -257,9 +256,9 @@ typedef struct page_entry\n   struct page_group *group;\n #endif\n \n-  /* Saved in-use bit vector for pages that aren't in the topmost\n-     context during collection.  */\n-  unsigned long *save_in_use_p;\n+  /* This is the index in the by_depth varray where this page table\n+     can be found.  */\n+  unsigned long index_by_depth;\n \n   /* Context depth of this page.  */\n   unsigned short context_depth;\n@@ -371,6 +370,36 @@ static struct globals\n \n   /* The file descriptor for debugging output.  */\n   FILE *debug_file;\n+\n+  /* Current number of elements in use in depth below.  */\n+  unsigned int depth_in_use;\n+\n+  /* Maximum number of elements that can be used before resizing.  */\n+  unsigned int depth_max;\n+\n+  /* Each element of this arry is an index in by_depth where the given\n+     depth starts.  This structure is indexed by that given depth we\n+     are interested in.  */\n+  unsigned int *depth;\n+\n+  /* Current number of elements in use in by_depth below.  */\n+  unsigned int by_depth_in_use;\n+\n+  /* Maximum number of elements that can be used before resizing.  */\n+  unsigned int by_depth_max;\n+\n+  /* Each element of this array is a pointer to a page_entry, all\n+     page_entries can be found in here by increasing depth.\n+     index_by_depth in the page_entry is the index into this data\n+     structure where that page_entry can be found.  This is used to\n+     speed up finding all page_entries at a particular depth.  */\n+  page_entry **by_depth;\n+\n+  /* Each element is a pointer to the saved in_use_p bits, if any,\n+     zero otherwise.  We allocate them all together, to enable a\n+     better runtime data access pattern.  */\n+  unsigned long **save_in_use;\n+\n } G;\n \n /* The size in bytes required to maintain a bitmap for the objects\n@@ -383,6 +412,9 @@ static struct globals\n    free list.  This cannot be larger than HOST_BITS_PER_INT for the\n    in_use bitmask for page_group.  */\n #define GGC_QUIRE_SIZE 16\n+\n+/* Initial guess as to how many page table entries we might need.  */\n+#define INITIAL_PTE_COUNT 128\n \f\n static int ggc_allocated_p PARAMS ((const void *));\n static page_entry *lookup_page_table_entry PARAMS ((const void *));\n@@ -402,13 +434,62 @@ static void clear_marks PARAMS ((void));\n static void sweep_pages PARAMS ((void));\n static void ggc_recalculate_in_use_p PARAMS ((page_entry *));\n static void compute_inverse PARAMS ((unsigned));\n+static inline void adjust_depth PARAMS ((void));\n+static void move_ptes_to_front PARAMS ((int, int));\n \n #ifdef ENABLE_GC_CHECKING\n static void poison_pages PARAMS ((void));\n #endif\n \n void debug_print_page_list PARAMS ((int));\n+static void push_depth PARAMS ((unsigned int));\n+static void push_by_depth PARAMS ((page_entry *, unsigned long *));\n \f\n+/* Push an entry onto G.depth.  */\n+\n+inline static void\n+push_depth (i)\n+     unsigned int i;\n+{\n+  if (G.depth_in_use >= G.depth_max)\n+    {\n+      G.depth_max *= 2;\n+      G.depth = (unsigned int *) xrealloc ((char *) G.depth,\n+\t\t\t\t\t   G.depth_max * sizeof (unsigned int));\n+    }\n+  G.depth[G.depth_in_use++] = i;\n+}\n+\n+/* Push an entry onto G.by_depth and G.save_in_use.  */\n+\n+inline static void\n+push_by_depth (p, s)\n+     page_entry *p;\n+     unsigned long *s;\n+{\n+  if (G.by_depth_in_use >= G.by_depth_max)\n+    {\n+      G.by_depth_max *= 2;\n+      G.by_depth = (page_entry **) xrealloc ((char *) G.by_depth,\n+\t\t\t\t\t     G.by_depth_max * sizeof (page_entry *));\n+      G.save_in_use = (unsigned long **) xrealloc ((char *) G.save_in_use,\n+\t\t\t\t\t\t   G.by_depth_max * sizeof (unsigned long *));\n+    }\n+  G.by_depth[G.by_depth_in_use] = p;\n+  G.save_in_use[G.by_depth_in_use++] = s;\n+}\n+\n+#if (GCC_VERSION < 3001)\n+#define prefetch(X) ((void) X)\n+#else\n+#define prefetch(X) __builtin_prefetch (X)\n+#endif\n+\n+#define save_in_use_p_i(__i) \\\n+  (G.save_in_use[__i])\n+#define save_in_use_p(__p) \\\n+  (save_in_use_p_i (__p->index_by_depth))\n+\n /* Returns nonzero if P was allocated in GC'able memory.  */\n \n static inline int\n@@ -776,6 +857,26 @@ alloc_page (order)\n   return entry;\n }\n \n+/* Adjust the size of G.depth so that no index greater than the one\n+   used by the top of the G.by_depth is used.  */\n+\n+static inline void\n+adjust_depth ()\n+{\n+  page_entry *top;\n+\n+  if (G.by_depth_in_use)\n+    {\n+      top = G.by_depth[G.by_depth_in_use-1];\n+\n+      /* Peel back indicies in depth that index into by_depth, so that\n+\t as new elements are added to by_depth, we note the indicies\n+\t of those elements, if they are for new context depths.  */\n+      while (G.depth_in_use > (size_t)top->context_depth+1)\n+\t--G.depth_in_use;\n+    }\n+}\n+\n /* For a page that is no longer needed, put it on the free page list.  */\n \n static inline void\n@@ -797,6 +898,30 @@ free_page (entry)\n   clear_page_group_in_use (entry->group, entry->page);\n #endif\n \n+  if (G.by_depth_in_use > 1)\n+    {\n+      page_entry *top = G.by_depth[G.by_depth_in_use-1];\n+\n+      /* If they are at the same depth, put top element into freed\n+\t slot.  */\n+      if (entry->context_depth == top->context_depth)\n+\t{\n+\t  int i = entry->index_by_depth;\n+\t  G.by_depth[i] = top;\n+\t  G.save_in_use[i] = G.save_in_use[G.by_depth_in_use-1];\n+\t  top->index_by_depth = i;\n+\t}\n+      else\n+\t{\n+\t  /* We cannot free a page from a context deeper than the\n+\t     current one.  */\n+\t  abort ();\n+\t}\n+    }\n+  --G.by_depth_in_use;\n+\n+  adjust_depth ();\n+\n   entry->next = G.free_pages;\n   G.free_pages = entry;\n }\n@@ -920,6 +1045,14 @@ ggc_alloc (size)\n       struct page_entry *new_entry;\n       new_entry = alloc_page (order);\n \n+      new_entry->index_by_depth = G.by_depth_in_use;\n+      push_by_depth (new_entry, 0);\n+\n+      /* We can skip context depths, if we do, make sure we go all the\n+\t way to the new depth.  */\n+      while (new_entry->context_depth >= G.depth_in_use)\n+\tpush_depth (G.by_depth_in_use-1);\n+\n       /* If this is the only entry, it's also the tail.  */\n       if (entry == NULL)\n \tG.page_tails[order] = new_entry;\n@@ -1222,6 +1355,15 @@ init_ggc ()\n       for (i = OBJECT_SIZE (order); size_lookup [i] == o; --i)\n \tsize_lookup[i] = order;\n     }\n+\n+  G.depth_in_use = 0;\n+  G.depth_max = 10;\n+  G.depth = (unsigned int *) xmalloc (G.depth_max * sizeof (unsigned int));\n+\n+  G.by_depth_in_use = 0;\n+  G.by_depth_max = INITIAL_PTE_COUNT;\n+  G.by_depth = (page_entry **) xmalloc (G.by_depth_max * sizeof (page_entry *));\n+  G.save_in_use = (unsigned long **) xmalloc (G.by_depth_max * sizeof (unsigned long *));\n }\n \n /* Increment the `GC context'.  Objects allocated in an outer context\n@@ -1264,7 +1406,7 @@ ggc_recalculate_in_use_p (p)\n \n       /* Something is in use if it is marked, or if it was in use in a\n \t context further down the context stack.  */\n-      p->in_use_p[i] |= p->save_in_use_p[i];\n+      p->in_use_p[i] |= save_in_use_p (p)[i];\n \n       /* Decrement the free object count for every object allocated.  */\n       for (j = p->in_use_p[i]; j; j >>= 1)\n@@ -1282,7 +1424,10 @@ void\n ggc_pop_context ()\n {\n   unsigned long omask;\n-  unsigned order, depth;\n+  unsigned int depth, i, e;\n+#ifdef ENABLE_CHECKING\n+  unsigned int order;\n+#endif\n \n   depth = --G.context_depth;\n   omask = (unsigned long)1 << (depth + 1);\n@@ -1294,28 +1439,79 @@ ggc_pop_context ()\n   G.context_depth_allocations &= omask - 1;\n   G.context_depth_collections &= omask - 1;\n \n-  /* Any remaining pages in the popped context are lowered to the new\n-     current context; i.e. objects allocated in the popped context and\n-     left over are imported into the previous context.  */\n+  /* The G.depth array is shortend so that the last index is the\n+     context_depth of the top element of by_depth.  */\n+  if (depth+1 < G.depth_in_use)\n+    e = G.depth[depth+1];\n+  else\n+    e = G.by_depth_in_use;\n+\n+  /* We might not have any PTEs of depth depth.  */\n+  if (depth < G.depth_in_use)\n+    {    \n+\n+      /* First we go through all the pages at depth depth to\n+\t recalculate the in use bits.  */\n+      for (i = G.depth[depth]; i < e; ++i)\n+\t{\n+\t  page_entry *p;\n+\n+#ifdef ENABLE_CHECKING\n+\t  p = G.by_depth[i];\n+\n+\t  /* Check that all of the pages really are at the depth that\n+\t     we expect.  */\n+\t  if (p->context_depth != depth)\n+\t    abort ();\n+\t  if (p->index_by_depth != i)\n+\t    abort ();\n+#endif\n+\n+\t  prefetch (&save_in_use_p_i (i+8));\n+\t  prefetch (&save_in_use_p_i (i+16));\n+\t  if (save_in_use_p_i (i))\n+\t    {\n+\t      p = G.by_depth[i];\n+\t      ggc_recalculate_in_use_p (p);\n+\t      free (save_in_use_p_i (i));\n+\t      save_in_use_p_i (i) = 0;\n+\t    }\n+\t}\n+    }\n+\n+  /* Then, we reset all page_entries with a depth greater than depth\n+     to be at depth.  */\n+  for (i = e; i < G.by_depth_in_use; ++i)\n+    {\n+      page_entry *p = G.by_depth[i];\n+\n+      /* Check that all of the pages really are at the depth we\n+\t expect.  */\n+#ifdef ENABLE_CHECKING\n+      if (p->context_depth <= depth)\n+\tabort ();\n+      if (p->index_by_depth != i)\n+\tabort ();\n+#endif\n+      p->context_depth = depth;\n+    }\n+\n+  adjust_depth ();\n+\n+#ifdef ENABLE_CHECKING\n   for (order = 2; order < NUM_ORDERS; order++)\n     {\n       page_entry *p;\n \n       for (p = G.pages[order]; p != NULL; p = p->next)\n \t{\n \t  if (p->context_depth > depth)\n-\t    p->context_depth = depth;\n-\n-\t  /* If this page is now in the topmost context, and we'd\n-\t     saved its allocation state, restore it.  */\n-\t  else if (p->context_depth == depth && p->save_in_use_p)\n-\t    {\n-\t      ggc_recalculate_in_use_p (p);\n-\t      free (p->save_in_use_p);\n-\t      p->save_in_use_p = 0;\n-\t    }\n+\t    abort ();\n+\t  else if (p->context_depth == depth && save_in_use_p (p))\n+\t    abort ();\n \t}\n     }\n+#endif\n }\n \f\n /* Unmark all objects.  */\n@@ -1345,9 +1541,9 @@ clear_marks ()\n \t     marks.  So, back them up first.  */\n \t  if (p->context_depth < G.context_depth)\n \t    {\n-\t      if (! p->save_in_use_p)\n-\t\tp->save_in_use_p = xmalloc (bitmap_size);\n-\t      memcpy (p->save_in_use_p, p->in_use_p, bitmap_size);\n+\t      if (! save_in_use_p (p))\n+\t\tsave_in_use_p (p) = xmalloc (bitmap_size);\n+\t      memcpy (save_in_use_p (p), p->in_use_p, bitmap_size);\n \t    }\n \n \t  /* Reset reset the number of free objects and clear the\n@@ -1781,6 +1977,58 @@ ggc_pch_finish (d, f)\n   free (d);\n }\n \n+/* Move the PCH PTE entries just added to the end of by_depth, to the\n+   front.  */\n+\n+static void\n+move_ptes_to_front (count_old_page_tables, count_new_page_tables)\n+     int count_old_page_tables;\n+     int count_new_page_tables;\n+{\n+  unsigned i;\n+\n+  /* First, we swap the new entries to the front of the varrays.  */\n+  page_entry **new_by_depth;\n+  unsigned long **new_save_in_use;\n+\n+  new_by_depth = (page_entry **) xmalloc (G.by_depth_max * sizeof (page_entry *));\n+  new_save_in_use = (unsigned long **) xmalloc (G.by_depth_max * sizeof (unsigned long *));\n+\n+  memcpy (&new_by_depth[0],\n+\t  &G.by_depth[count_old_page_tables],\n+\t  count_new_page_tables * sizeof (void *));\n+  memcpy (&new_by_depth[count_new_page_tables],\n+\t  &G.by_depth[0],\n+\t  count_old_page_tables * sizeof (void *));\n+  memcpy (&new_save_in_use[0],\n+\t  &G.save_in_use[count_old_page_tables],\n+\t  count_new_page_tables * sizeof (void *));\n+  memcpy (&new_save_in_use[count_new_page_tables],\n+\t  &G.save_in_use[0],\n+\t  count_old_page_tables * sizeof (void *));\n+\n+  free (G.by_depth);\n+  free (G.save_in_use);\n+    \n+  G.by_depth = new_by_depth;\n+  G.save_in_use = new_save_in_use;\n+\n+  /* Now update all the index_by_depth fields.  */\n+  for (i = G.by_depth_in_use; i > 0; --i)\n+    {\n+      page_entry *p = G.by_depth[i-1];\n+      p->index_by_depth = i-1;\n+    }\n+\n+  /* And last, we update the depth pointers in G.depth.  The first\n+     entry is already 0, and context 0 entries always start at index\n+     0, so there is nothing to update in the first slot.  We need a\n+     second slot, only if we have old ptes, and if we do, they start\n+     at index count_new_page_tables.  */\n+  if (count_old_page_tables)\n+    push_depth (count_new_page_tables);\n+}\n+\n void\n ggc_pch_read (f, addr)\n      FILE *f;\n@@ -1789,9 +2037,13 @@ ggc_pch_read (f, addr)\n   struct ggc_pch_ondisk d;\n   unsigned i;\n   char *offs = addr;\n-  \n-  /* We've just read in a PCH file.  So, every object that used to be allocated\n-     is now free.  */\n+  unsigned long count_old_page_tables;\n+  unsigned long count_new_page_tables;\n+\n+  count_old_page_tables = G.by_depth_in_use;\n+\n+  /* We've just read in a PCH file.  So, every object that used to be\n+     allocated is now free.  */\n   clear_marks ();\n #ifdef GGC_POISON\n   poison_pages ();\n@@ -1822,10 +2074,10 @@ ggc_pch_read (f, addr)\n       size_t bytes;\n       size_t num_objs;\n       size_t j;\n-      \n+\n       if (d.totals[i] == 0)\n \tcontinue;\n-      \n+\n       bytes = ROUND_UP (d.totals[i] * OBJECT_SIZE (i), G.pagesize);\n       num_objs = bytes / OBJECT_SIZE (i);\n       entry = xcalloc (1, (sizeof (struct page_entry) \n@@ -1856,8 +2108,20 @@ ggc_pch_read (f, addr)\n       else\n \tG.pages[i] = entry;\n       G.page_tails[i] = entry;\n+\n+      /* We start off by just adding all the new information to the\n+\t end of the varrays, later, we will move the new information\n+\t to the front of the varrays, as the PCH page tables are at\n+\t context 0.  */\n+      push_by_depth (entry, 0);\n     }\n \n+  /* Now, we update the various data structures that speed page table\n+     handling.  */\n+  count_new_page_tables = G.by_depth_in_use - count_old_page_tables;\n+\n+  move_ptes_to_front (count_old_page_tables, count_new_page_tables);\n+\n   /* Update the statistics.  */\n   G.allocated = G.allocated_last_gc = offs - (char *)addr;\n }"}]}