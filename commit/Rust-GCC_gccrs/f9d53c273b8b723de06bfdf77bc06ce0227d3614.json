{"sha": "f9d53c273b8b723de06bfdf77bc06ce0227d3614", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZjlkNTNjMjczYjhiNzIzZGUwNmJmZGY3N2JjMDZjZTAyMjdkMzYxNA==", "commit": {"author": {"name": "Tejas Belagod", "email": "tejas.belagod@arm.com", "date": "2014-11-05T08:26:54Z"}, "committer": {"name": "Tejas Belagod", "email": "belagod@gcc.gnu.org", "date": "2014-11-05T08:26:54Z"}, "message": "[AArch64] Restructure arm_neon.h vector types.\n\n2014-11-05  Tejas Belagod  <tejas.belagod@arm.com>\n\n\t* config/aarch64/aarch64-builtins.c\n\t(aarch64_build_scalar_type): Remove.\n\t(aarch64_scalar_builtin_types, aarch64_simd_type,\n\taarch64_simd_type, aarch64_mangle_builtin_scalar_type,\n\taarch64_mangle_builtin_vector_type,\n\taarch64_mangle_builtin_type, aarch64_simd_builtin_std_type,\n\taarch64_lookup_simd_builtin_type, aarch64_simd_builtin_type,\n\taarch64_init_simd_builtin_types,\n\taarch64_init_simd_builtin_scalar_types): New.\n\t(aarch64_init_simd_builtins): Refactor.\n\t(aarch64_init_crc32_builtins): Fixup with qualifier.\n\t* config/aarch64/aarch64-protos.h\n\t(aarch64_mangle_builtin_type): Export.\n\t* config/aarch64/aarch64-simd-builtin-types.def: New.\n\t* config/aarch64/aarch64.c (aarch64_simd_mangle_map): Remove.\n\t(aarch64_mangle_type): Refactor.\n\t* config/aarch64/arm_neon.h: Declare vector types based on\n\tinternal types.\n\t* config/aarch64/t-aarch64: Update dependency.\n\nFrom-SVN: r217114", "tree": {"sha": "516b71a224735a0f31be76a3f858bc245acf742d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/516b71a224735a0f31be76a3f858bc245acf742d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/f9d53c273b8b723de06bfdf77bc06ce0227d3614", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f9d53c273b8b723de06bfdf77bc06ce0227d3614", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f9d53c273b8b723de06bfdf77bc06ce0227d3614", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f9d53c273b8b723de06bfdf77bc06ce0227d3614/comments", "author": {"login": "tejas-belagod-arm", "id": 92718852, "node_id": "U_kgDOBYbHBA", "avatar_url": "https://avatars.githubusercontent.com/u/92718852?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tejas-belagod-arm", "html_url": "https://github.com/tejas-belagod-arm", "followers_url": "https://api.github.com/users/tejas-belagod-arm/followers", "following_url": "https://api.github.com/users/tejas-belagod-arm/following{/other_user}", "gists_url": "https://api.github.com/users/tejas-belagod-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/tejas-belagod-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tejas-belagod-arm/subscriptions", "organizations_url": "https://api.github.com/users/tejas-belagod-arm/orgs", "repos_url": "https://api.github.com/users/tejas-belagod-arm/repos", "events_url": "https://api.github.com/users/tejas-belagod-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/tejas-belagod-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "3cbdd8312a4c63310de54d6d0aa36ddcfb05fdf6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3cbdd8312a4c63310de54d6d0aa36ddcfb05fdf6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3cbdd8312a4c63310de54d6d0aa36ddcfb05fdf6"}], "stats": {"total": 740, "additions": 404, "deletions": 336}, "files": [{"sha": "47bc8269f5594504422b1ab3061fad5a6feea30d", "filename": "gcc/ChangeLog", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=f9d53c273b8b723de06bfdf77bc06ce0227d3614", "patch": "@@ -1,3 +1,25 @@\n+2014-11-05  Tejas Belagod  <tejas.belagod@arm.com>\n+\n+\t* config/aarch64/aarch64-builtins.c\n+\t(aarch64_build_scalar_type): Remove.\n+\t(aarch64_scalar_builtin_types, aarch64_simd_type,\n+\taarch64_simd_type, aarch64_mangle_builtin_scalar_type,\n+\taarch64_mangle_builtin_vector_type,\n+\taarch64_mangle_builtin_type, aarch64_simd_builtin_std_type,\n+\taarch64_lookup_simd_builtin_type, aarch64_simd_builtin_type,\n+\taarch64_init_simd_builtin_types,\n+\taarch64_init_simd_builtin_scalar_types): New.\n+\t(aarch64_init_simd_builtins): Refactor.\n+\t(aarch64_init_crc32_builtins): Fixup with qualifier.\n+\t* config/aarch64/aarch64-protos.h\n+\t(aarch64_mangle_builtin_type): Export.\n+\t* config/aarch64/aarch64-simd-builtin-types.def: New.\n+\t* config/aarch64/aarch64.c (aarch64_simd_mangle_map): Remove.\n+\t(aarch64_mangle_type): Refactor.\n+\t* config/aarch64/arm_neon.h: Declare vector types based on\n+\tinternal types.\n+\t* config/aarch64/t-aarch64: Update dependency.\n+\n 2014-11-04  Pat Haugen  <pthaugen@us.ibm.com>\n \n \t* config/rs6000/rs6000.c (atomic_hold_decl, atomic_clear_decl,"}, {"sha": "c0881e643440dd688570bcbc2a849ae2d441225a", "filename": "gcc/config/aarch64/aarch64-builtins.c", "status": "modified", "additions": 296, "deletions": 215, "changes": 511, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c?ref=f9d53c273b8b723de06bfdf77bc06ce0227d3614", "patch": "@@ -363,257 +363,335 @@ static GTY(()) tree aarch64_builtin_decls[AARCH64_BUILTIN_MAX];\n #define NUM_DREG_TYPES 6\n #define NUM_QREG_TYPES 6\n \n-/* Return a tree for a signed or unsigned argument of either\n-   the mode specified by MODE, or the inner mode of MODE.  */\n-tree\n-aarch64_build_scalar_type (machine_mode mode,\n-\t\t\t   bool unsigned_p,\n-\t\t\t   bool poly_p)\n-{\n-#undef INT_TYPES\n-#define INT_TYPES \\\n-  AARCH64_TYPE_BUILDER (QI) \\\n-  AARCH64_TYPE_BUILDER (HI) \\\n-  AARCH64_TYPE_BUILDER (SI) \\\n-  AARCH64_TYPE_BUILDER (DI) \\\n-  AARCH64_TYPE_BUILDER (EI) \\\n-  AARCH64_TYPE_BUILDER (OI) \\\n-  AARCH64_TYPE_BUILDER (CI) \\\n-  AARCH64_TYPE_BUILDER (XI) \\\n-  AARCH64_TYPE_BUILDER (TI) \\\n-\n-/* Statically declare all the possible types we might need.  */\n-#undef AARCH64_TYPE_BUILDER\n-#define AARCH64_TYPE_BUILDER(X) \\\n-  static tree X##_aarch64_type_node_p = NULL; \\\n-  static tree X##_aarch64_type_node_s = NULL; \\\n-  static tree X##_aarch64_type_node_u = NULL;\n-\n-  INT_TYPES\n-\n-  static tree float_aarch64_type_node = NULL;\n-  static tree double_aarch64_type_node = NULL;\n-\n-  gcc_assert (!VECTOR_MODE_P (mode));\n-\n-/* If we've already initialised this type, don't initialise it again,\n-   otherwise ask for a new type of the correct size.  */\n-#undef AARCH64_TYPE_BUILDER\n-#define AARCH64_TYPE_BUILDER(X) \\\n-  case X##mode: \\\n-    if (unsigned_p) \\\n-      return (X##_aarch64_type_node_u \\\n-\t      ? X##_aarch64_type_node_u \\\n-\t      : X##_aarch64_type_node_u \\\n-\t\t  = make_unsigned_type (GET_MODE_PRECISION (mode))); \\\n-    else if (poly_p) \\\n-       return (X##_aarch64_type_node_p \\\n-\t      ? X##_aarch64_type_node_p \\\n-\t      : X##_aarch64_type_node_p \\\n-\t\t  = make_unsigned_type (GET_MODE_PRECISION (mode))); \\\n-    else \\\n-       return (X##_aarch64_type_node_s \\\n-\t      ? X##_aarch64_type_node_s \\\n-\t      : X##_aarch64_type_node_s \\\n-\t\t  = make_signed_type (GET_MODE_PRECISION (mode))); \\\n-    break;\n+/* Internal scalar builtin types.  These types are used to support\n+   neon intrinsic builtins.  They are _not_ user-visible types.  Therefore\n+   the mangling for these types are implementation defined.  */\n+const char *aarch64_scalar_builtin_types[] = {\n+  \"__builtin_aarch64_simd_qi\",\n+  \"__builtin_aarch64_simd_hi\",\n+  \"__builtin_aarch64_simd_si\",\n+  \"__builtin_aarch64_simd_sf\",\n+  \"__builtin_aarch64_simd_di\",\n+  \"__builtin_aarch64_simd_df\",\n+  \"__builtin_aarch64_simd_poly8\",\n+  \"__builtin_aarch64_simd_poly16\",\n+  \"__builtin_aarch64_simd_poly64\",\n+  \"__builtin_aarch64_simd_poly128\",\n+  \"__builtin_aarch64_simd_ti\",\n+  \"__builtin_aarch64_simd_uqi\",\n+  \"__builtin_aarch64_simd_uhi\",\n+  \"__builtin_aarch64_simd_usi\",\n+  \"__builtin_aarch64_simd_udi\",\n+  \"__builtin_aarch64_simd_ei\",\n+  \"__builtin_aarch64_simd_oi\",\n+  \"__builtin_aarch64_simd_ci\",\n+  \"__builtin_aarch64_simd_xi\",\n+  NULL\n+};\n \n-  switch (mode)\n-    {\n-      INT_TYPES\n-      case SFmode:\n-\tif (!float_aarch64_type_node)\n-\t  {\n-\t    float_aarch64_type_node = make_node (REAL_TYPE);\n-\t    TYPE_PRECISION (float_aarch64_type_node) = FLOAT_TYPE_SIZE;\n-\t    layout_type (float_aarch64_type_node);\n-\t  }\n-\treturn float_aarch64_type_node;\n-\tbreak;\n-      case DFmode:\n-\tif (!double_aarch64_type_node)\n-\t  {\n-\t    double_aarch64_type_node = make_node (REAL_TYPE);\n-\t    TYPE_PRECISION (double_aarch64_type_node) = DOUBLE_TYPE_SIZE;\n-\t    layout_type (double_aarch64_type_node);\n-\t  }\n-\treturn double_aarch64_type_node;\n-\tbreak;\n-      default:\n-\tgcc_unreachable ();\n-    }\n-}\n+#define ENTRY(E, M, Q, G) E,\n+enum aarch64_simd_type\n+{\n+#include \"aarch64-simd-builtin-types.def\"\n+  ARM_NEON_H_TYPES_LAST\n+};\n+#undef ENTRY\n \n-tree\n-aarch64_build_vector_type (machine_mode mode,\n-\t\t\t   bool unsigned_p,\n-\t\t\t   bool poly_p)\n+struct aarch64_simd_type_info\n {\n+  enum aarch64_simd_type type;\n+\n+  /* Internal type name.  */\n+  const char *name;\n+\n+  /* Internal type name(mangled).  The mangled names conform to the\n+     AAPCS64 (see \"Procedure Call Standard for the ARM 64-bit Architecture\",\n+     Appendix A).  To qualify for emission with the mangled names defined in\n+     that document, a vector type must not only be of the correct mode but also\n+     be of the correct internal AdvSIMD vector type (e.g. __Int8x8_t); these\n+     types are registered by aarch64_init_simd_builtin_types ().  In other\n+     words, vector types defined in other ways e.g. via vector_size attribute\n+     will get default mangled names.  */\n+  const char *mangle;\n+\n+  /* Internal type.  */\n+  tree itype;\n+\n+  /* Element type.  */\n   tree eltype;\n \n-#define VECTOR_TYPES \\\n-  AARCH64_TYPE_BUILDER (V16QI) \\\n-  AARCH64_TYPE_BUILDER (V8HI) \\\n-  AARCH64_TYPE_BUILDER (V4SI) \\\n-  AARCH64_TYPE_BUILDER (V2DI) \\\n-  AARCH64_TYPE_BUILDER (V8QI) \\\n-  AARCH64_TYPE_BUILDER (V4HI) \\\n-  AARCH64_TYPE_BUILDER (V2SI) \\\n-  \\\n-  AARCH64_TYPE_BUILDER (V4SF) \\\n-  AARCH64_TYPE_BUILDER (V2DF) \\\n-  AARCH64_TYPE_BUILDER (V2SF) \\\n-/* Declare our \"cache\" of values.  */\n-#undef AARCH64_TYPE_BUILDER\n-#define AARCH64_TYPE_BUILDER(X) \\\n-  static tree X##_aarch64_type_node_s = NULL; \\\n-  static tree X##_aarch64_type_node_u = NULL; \\\n-  static tree X##_aarch64_type_node_p = NULL;\n-\n-  VECTOR_TYPES\n-\n-  gcc_assert (VECTOR_MODE_P (mode));\n-\n-#undef AARCH64_TYPE_BUILDER\n-#define AARCH64_TYPE_BUILDER(X) \\\n-  case X##mode: \\\n-    if (unsigned_p) \\\n-      return X##_aarch64_type_node_u \\\n-\t     ? X##_aarch64_type_node_u \\\n-\t     : X##_aarch64_type_node_u \\\n-\t\t= build_vector_type_for_mode (aarch64_build_scalar_type \\\n-\t\t\t\t\t\t(GET_MODE_INNER (mode), \\\n-\t\t\t\t\t\t unsigned_p, poly_p), mode); \\\n-    else if (poly_p) \\\n-       return X##_aarch64_type_node_p \\\n-\t      ? X##_aarch64_type_node_p \\\n-\t      : X##_aarch64_type_node_p \\\n-\t\t= build_vector_type_for_mode (aarch64_build_scalar_type \\\n-\t\t\t\t\t\t(GET_MODE_INNER (mode), \\\n-\t\t\t\t\t\t unsigned_p, poly_p), mode); \\\n-    else \\\n-       return X##_aarch64_type_node_s \\\n-\t      ? X##_aarch64_type_node_s \\\n-\t      : X##_aarch64_type_node_s \\\n-\t\t= build_vector_type_for_mode (aarch64_build_scalar_type \\\n-\t\t\t\t\t\t(GET_MODE_INNER (mode), \\\n-\t\t\t\t\t\t unsigned_p, poly_p), mode); \\\n-    break;\n+  /* Machine mode the internal type maps to.  */\n+  enum machine_mode mode;\n \n-  switch (mode)\n+  /* Qualifiers.  */\n+  enum aarch64_type_qualifiers q;\n+};\n+\n+#define ENTRY(E, M, Q, G)  \\\n+  {E, \"__\" #E, #G \"__\" #E, NULL_TREE, NULL_TREE, M##mode, qualifier_##Q},\n+static struct aarch64_simd_type_info aarch64_simd_types [] = {\n+#include \"aarch64-simd-builtin-types.def\"\n+};\n+#undef ENTRY\n+\n+static tree aarch64_simd_intOI_type_node = NULL_TREE;\n+static tree aarch64_simd_intEI_type_node = NULL_TREE;\n+static tree aarch64_simd_intCI_type_node = NULL_TREE;\n+static tree aarch64_simd_intXI_type_node = NULL_TREE;\n+\n+static const char *\n+aarch64_mangle_builtin_scalar_type (const_tree type)\n+{\n+  int i = 0;\n+\n+  while (aarch64_scalar_builtin_types[i] != NULL)\n     {\n-      default:\n-\teltype = aarch64_build_scalar_type (GET_MODE_INNER (mode),\n-\t\t\t\t\t    unsigned_p, poly_p);\n-\treturn build_vector_type_for_mode (eltype, mode);\n-\tbreak;\n-      VECTOR_TYPES\n-   }\n+      const char *name = aarch64_scalar_builtin_types[i];\n+\n+      if (TREE_CODE (TYPE_NAME (type)) == TYPE_DECL\n+\t  && DECL_NAME (TYPE_NAME (type))\n+\t  && !strcmp (IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (type))), name))\n+\treturn aarch64_scalar_builtin_types[i];\n+      i++;\n+    }\n+  return NULL;\n }\n \n-tree\n-aarch64_build_type (machine_mode mode, bool unsigned_p, bool poly_p)\n+static const char *\n+aarch64_mangle_builtin_vector_type (const_tree type)\n {\n-  if (VECTOR_MODE_P (mode))\n-    return aarch64_build_vector_type (mode, unsigned_p, poly_p);\n-  else\n-    return aarch64_build_scalar_type (mode, unsigned_p, poly_p);\n+  int i;\n+  int nelts = sizeof (aarch64_simd_types) / sizeof (aarch64_simd_types[0]);\n+\n+  for (i = 0; i < nelts; i++)\n+    if (aarch64_simd_types[i].mode ==  TYPE_MODE (type)\n+\t&& TYPE_NAME (type)\n+\t&& TREE_CODE (TYPE_NAME (type)) == TYPE_DECL\n+\t&& DECL_NAME (TYPE_NAME (type))\n+\t&& !strcmp\n+\t     (IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (type))),\n+\t      aarch64_simd_types[i].name))\n+      return aarch64_simd_types[i].mangle;\n+\n+  return NULL;\n }\n \n-tree\n-aarch64_build_signed_type (machine_mode mode)\n+const char *\n+aarch64_mangle_builtin_type (const_tree type)\n {\n-  return aarch64_build_type (mode, false, false);\n+  const char *mangle;\n+  /* Walk through all the AArch64 builtins types tables to filter out the\n+     incoming type.  */\n+  if ((mangle = aarch64_mangle_builtin_vector_type (type))\n+      || (mangle = aarch64_mangle_builtin_scalar_type (type)))\n+    return mangle;\n+\n+  return NULL;\n }\n \n-tree\n-aarch64_build_unsigned_type (machine_mode mode)\n+static tree\n+aarch64_simd_builtin_std_type (enum machine_mode mode,\n+\t\t\t       enum aarch64_type_qualifiers q)\n {\n-  return aarch64_build_type (mode, true, false);\n+#define QUAL_TYPE(M)  \\\n+  ((q == qualifier_none) ? int##M##_type_node : unsigned_int##M##_type_node);\n+  switch (mode)\n+    {\n+    case QImode:\n+      return QUAL_TYPE (QI);\n+    case HImode:\n+      return QUAL_TYPE (HI);\n+    case SImode:\n+      return QUAL_TYPE (SI);\n+    case DImode:\n+      return QUAL_TYPE (DI);\n+    case TImode:\n+      return QUAL_TYPE (TI);\n+    case OImode:\n+      return aarch64_simd_intOI_type_node;\n+    case EImode:\n+      return aarch64_simd_intEI_type_node;\n+    case CImode:\n+      return aarch64_simd_intCI_type_node;\n+    case XImode:\n+      return aarch64_simd_intXI_type_node;\n+    case SFmode:\n+      return float_type_node;\n+    case DFmode:\n+      return double_type_node;\n+    default:\n+      gcc_unreachable ();\n+    }\n+#undef QUAL_TYPE\n }\n \n-tree\n-aarch64_build_poly_type (machine_mode mode)\n+static tree\n+aarch64_lookup_simd_builtin_type (enum machine_mode mode,\n+\t\t\t\t  enum aarch64_type_qualifiers q)\n {\n-  return aarch64_build_type (mode, false, true);\n+  int i;\n+  int nelts = sizeof (aarch64_simd_types) / sizeof (aarch64_simd_types[0]);\n+\n+  /* Non-poly scalar modes map to standard types not in the table.  */\n+  if (q != qualifier_poly && !VECTOR_MODE_P (mode))\n+    return aarch64_simd_builtin_std_type (mode, q);\n+\n+  for (i = 0; i < nelts; i++)\n+    if (aarch64_simd_types[i].mode == mode\n+\t&& aarch64_simd_types[i].q == q)\n+      return aarch64_simd_types[i].itype;\n+\n+  return NULL_TREE;\n }\n \n+static tree\n+aarch64_simd_builtin_type (enum machine_mode mode,\n+\t\t\t   bool unsigned_p, bool poly_p)\n+{\n+  if (poly_p)\n+    return aarch64_lookup_simd_builtin_type (mode, qualifier_poly);\n+  else if (unsigned_p)\n+    return aarch64_lookup_simd_builtin_type (mode, qualifier_unsigned);\n+  else\n+    return aarch64_lookup_simd_builtin_type (mode, qualifier_none);\n+}\n+ \n static void\n-aarch64_init_simd_builtins (void)\n+aarch64_init_simd_builtin_types (void)\n {\n-  unsigned int i, fcode = AARCH64_SIMD_BUILTIN_BASE + 1;\n+  int i;\n+  int nelts = sizeof (aarch64_simd_types) / sizeof (aarch64_simd_types[0]);\n+  tree tdecl;\n+\n+  /* Init all the element types built by the front-end.  */\n+  aarch64_simd_types[Int8x8_t].eltype = intQI_type_node;\n+  aarch64_simd_types[Int8x16_t].eltype = intQI_type_node;\n+  aarch64_simd_types[Int16x4_t].eltype = intHI_type_node;\n+  aarch64_simd_types[Int16x8_t].eltype = intHI_type_node;\n+  aarch64_simd_types[Int32x2_t].eltype = intSI_type_node;\n+  aarch64_simd_types[Int32x4_t].eltype = intSI_type_node;\n+  aarch64_simd_types[Int64x1_t].eltype = intDI_type_node;\n+  aarch64_simd_types[Int64x2_t].eltype = intDI_type_node;\n+  aarch64_simd_types[Uint8x8_t].eltype = unsigned_intQI_type_node;\n+  aarch64_simd_types[Uint8x16_t].eltype = unsigned_intQI_type_node;\n+  aarch64_simd_types[Uint16x4_t].eltype = unsigned_intHI_type_node;\n+  aarch64_simd_types[Uint16x8_t].eltype = unsigned_intHI_type_node;\n+  aarch64_simd_types[Uint32x2_t].eltype = unsigned_intSI_type_node;\n+  aarch64_simd_types[Uint32x4_t].eltype = unsigned_intSI_type_node;\n+  aarch64_simd_types[Uint64x1_t].eltype = unsigned_intDI_type_node;\n+  aarch64_simd_types[Uint64x2_t].eltype = unsigned_intDI_type_node;\n+\n+  /* Poly types are a world of their own.  */\n+  aarch64_simd_types[Poly8_t].eltype = aarch64_simd_types[Poly8_t].itype =\n+    build_distinct_type_copy (unsigned_intQI_type_node);\n+  aarch64_simd_types[Poly16_t].eltype = aarch64_simd_types[Poly16_t].itype =\n+    build_distinct_type_copy (unsigned_intHI_type_node);\n+  aarch64_simd_types[Poly64_t].eltype = aarch64_simd_types[Poly64_t].itype =\n+    build_distinct_type_copy (unsigned_intDI_type_node);\n+  aarch64_simd_types[Poly128_t].eltype = aarch64_simd_types[Poly128_t].itype =\n+    build_distinct_type_copy (unsigned_intTI_type_node);\n+  /* Init poly vector element types with scalar poly types.  */\n+  aarch64_simd_types[Poly8x8_t].eltype = aarch64_simd_types[Poly8_t].itype;\n+  aarch64_simd_types[Poly8x16_t].eltype = aarch64_simd_types[Poly8_t].itype;\n+  aarch64_simd_types[Poly16x4_t].eltype = aarch64_simd_types[Poly16_t].itype;\n+  aarch64_simd_types[Poly16x8_t].eltype = aarch64_simd_types[Poly16_t].itype;\n+  aarch64_simd_types[Poly64x1_t].eltype = aarch64_simd_types[Poly64_t].itype;\n+  aarch64_simd_types[Poly64x2_t].eltype = aarch64_simd_types[Poly64_t].itype;\n+\n+  /* Continue with standard types.  */\n+  aarch64_simd_types[Float32x2_t].eltype = float_type_node;\n+  aarch64_simd_types[Float32x4_t].eltype = float_type_node;\n+  aarch64_simd_types[Float64x1_t].eltype = double_type_node;\n+  aarch64_simd_types[Float64x2_t].eltype = double_type_node;\n+\n+  for (i = 0; i < nelts; i++)\n+    {\n+      tree eltype = aarch64_simd_types[i].eltype;\n+      enum machine_mode mode = aarch64_simd_types[i].mode;\n+\n+      if (aarch64_simd_types[i].itype == NULL)\n+\taarch64_simd_types[i].itype =\n+\t  build_distinct_type_copy\n+\t    (build_vector_type (eltype, GET_MODE_NUNITS (mode)));\n+\n+      tdecl = add_builtin_type (aarch64_simd_types[i].name,\n+\t\t\t\taarch64_simd_types[i].itype);\n+      TYPE_NAME (aarch64_simd_types[i].itype) = tdecl;\n+      SET_TYPE_STRUCTURAL_EQUALITY (aarch64_simd_types[i].itype);\n+    }\n \n-  /* Signed scalar type nodes.  */\n-  tree aarch64_simd_intQI_type_node = aarch64_build_signed_type (QImode);\n-  tree aarch64_simd_intHI_type_node = aarch64_build_signed_type (HImode);\n-  tree aarch64_simd_intSI_type_node = aarch64_build_signed_type (SImode);\n-  tree aarch64_simd_intDI_type_node = aarch64_build_signed_type (DImode);\n-  tree aarch64_simd_intTI_type_node = aarch64_build_signed_type (TImode);\n-  tree aarch64_simd_intEI_type_node = aarch64_build_signed_type (EImode);\n-  tree aarch64_simd_intOI_type_node = aarch64_build_signed_type (OImode);\n-  tree aarch64_simd_intCI_type_node = aarch64_build_signed_type (CImode);\n-  tree aarch64_simd_intXI_type_node = aarch64_build_signed_type (XImode);\n-\n-  /* Unsigned scalar type nodes.  */\n-  tree aarch64_simd_intUQI_type_node = aarch64_build_unsigned_type (QImode);\n-  tree aarch64_simd_intUHI_type_node = aarch64_build_unsigned_type (HImode);\n-  tree aarch64_simd_intUSI_type_node = aarch64_build_unsigned_type (SImode);\n-  tree aarch64_simd_intUDI_type_node = aarch64_build_unsigned_type (DImode);\n-\n-  /* Poly scalar type nodes.  */\n-  tree aarch64_simd_polyQI_type_node = aarch64_build_poly_type (QImode);\n-  tree aarch64_simd_polyHI_type_node = aarch64_build_poly_type (HImode);\n-  tree aarch64_simd_polyDI_type_node = aarch64_build_poly_type (DImode);\n-  tree aarch64_simd_polyTI_type_node = aarch64_build_poly_type (TImode);\n-\n-  /* Float type nodes.  */\n-  tree aarch64_simd_float_type_node = aarch64_build_signed_type (SFmode);\n-  tree aarch64_simd_double_type_node = aarch64_build_signed_type (DFmode);\n-\n-  /* Define typedefs which exactly correspond to the modes we are basing vector\n-     types on.  If you change these names you'll need to change\n-     the table used by aarch64_mangle_type too.  */\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intQI_type_node,\n+#define AARCH64_BUILD_SIGNED_TYPE(mode)  \\\n+  make_signed_type (GET_MODE_PRECISION (mode));\n+  aarch64_simd_intOI_type_node = AARCH64_BUILD_SIGNED_TYPE (OImode);\n+  aarch64_simd_intEI_type_node = AARCH64_BUILD_SIGNED_TYPE (EImode);\n+  aarch64_simd_intCI_type_node = AARCH64_BUILD_SIGNED_TYPE (CImode);\n+  aarch64_simd_intXI_type_node = AARCH64_BUILD_SIGNED_TYPE (XImode);\n+#undef AARCH64_BUILD_SIGNED_TYPE\n+\n+  tdecl = add_builtin_type\n+\t    (\"__builtin_aarch64_simd_ei\" , aarch64_simd_intEI_type_node);\n+  TYPE_NAME (aarch64_simd_intEI_type_node) = tdecl;\n+  tdecl = add_builtin_type\n+\t    (\"__builtin_aarch64_simd_oi\" , aarch64_simd_intOI_type_node);\n+  TYPE_NAME (aarch64_simd_intOI_type_node) = tdecl;\n+  tdecl = add_builtin_type\n+\t    (\"__builtin_aarch64_simd_ci\" , aarch64_simd_intCI_type_node);\n+  TYPE_NAME (aarch64_simd_intCI_type_node) = tdecl;\n+  tdecl = add_builtin_type\n+\t    (\"__builtin_aarch64_simd_xi\" , aarch64_simd_intXI_type_node);\n+  TYPE_NAME (aarch64_simd_intXI_type_node) = tdecl;\n+}\n+\n+static void\n+aarch64_init_simd_builtin_scalar_types (void)\n+{\n+  /* Define typedefs for all the standard scalar types.  */\n+  (*lang_hooks.types.register_builtin_type) (intQI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_qi\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intHI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (intHI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_hi\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intSI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (intSI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_si\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_float_type_node,\n+  (*lang_hooks.types.register_builtin_type) (float_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_sf\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intDI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (intDI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_di\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_double_type_node,\n+  (*lang_hooks.types.register_builtin_type) (double_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_df\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_polyQI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intQI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_poly8\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_polyHI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intHI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_poly16\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_polyDI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intDI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_poly64\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_polyTI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intTI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_poly128\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intTI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (intTI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_ti\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intEI_type_node,\n-\t\t\t\t\t     \"__builtin_aarch64_simd_ei\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intOI_type_node,\n-\t\t\t\t\t     \"__builtin_aarch64_simd_oi\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intCI_type_node,\n-\t\t\t\t\t     \"__builtin_aarch64_simd_ci\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intXI_type_node,\n-\t\t\t\t\t     \"__builtin_aarch64_simd_xi\");\n-\n   /* Unsigned integer types for various mode sizes.  */\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intUQI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intQI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_uqi\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intUHI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intHI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_uhi\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intUSI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intSI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_usi\");\n-  (*lang_hooks.types.register_builtin_type) (aarch64_simd_intUDI_type_node,\n+  (*lang_hooks.types.register_builtin_type) (unsigned_intDI_type_node,\n \t\t\t\t\t     \"__builtin_aarch64_simd_udi\");\n+}\n+\n+static void\n+aarch64_init_simd_builtins (void)\n+{\n+  unsigned int i, fcode = AARCH64_SIMD_BUILTIN_BASE + 1;\n+\n+  aarch64_init_simd_builtin_types ();\n \n+  /* Strong-typing hasn't been implemented for all AdvSIMD builtin intrinsics.\n+     Therefore we need to preserve the old __builtin scalar types.  It can be\n+     removed once all the intrinsics become strongly typed using the qualifier\n+     system.  */\n+  aarch64_init_simd_builtin_scalar_types ();\n+ \n   for (i = 0; i < ARRAY_SIZE (aarch64_simd_builtin_data); i++, fcode++)\n     {\n       bool print_type_signature_p = false;\n@@ -677,9 +755,11 @@ aarch64_init_simd_builtins (void)\n \t  if (qualifiers & qualifier_pointer && VECTOR_MODE_P (op_mode))\n \t    op_mode = GET_MODE_INNER (op_mode);\n \n-\t  eltype = aarch64_build_type (op_mode,\n-\t\t\t\t       qualifiers & qualifier_unsigned,\n-\t\t\t\t       qualifiers & qualifier_poly);\n+\t  eltype = aarch64_simd_builtin_type\n+\t\t     (op_mode,\n+\t\t      (qualifiers & qualifier_unsigned) != 0,\n+\t\t      (qualifiers & qualifier_poly) != 0);\n+\t  gcc_assert (eltype != NULL);\n \n \t  /* Add qualifiers.  */\n \t  if (qualifiers & qualifier_const)\n@@ -717,13 +797,14 @@ aarch64_init_simd_builtins (void)\n static void\n aarch64_init_crc32_builtins ()\n {\n-  tree usi_type = aarch64_build_unsigned_type (SImode);\n+  tree usi_type = aarch64_simd_builtin_std_type (SImode, qualifier_unsigned);\n   unsigned int i = 0;\n \n   for (i = 0; i < ARRAY_SIZE (aarch64_crc_builtin_data); ++i)\n     {\n       aarch64_crc_builtin_datum* d = &aarch64_crc_builtin_data[i];\n-      tree argtype = aarch64_build_unsigned_type (d->mode);\n+      tree argtype = aarch64_simd_builtin_std_type (d->mode,\n+\t\t\t\t\t\t    qualifier_unsigned);\n       tree ftype = build_function_type_list (usi_type, usi_type, argtype, NULL_TREE);\n       tree fndecl = add_builtin_function (d->name, ftype, d->fcode,\n                                           BUILT_IN_MD, NULL, NULL_TREE);"}, {"sha": "470b9ebbec09fced64fd6544d0e796567a5e45bf", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=f9d53c273b8b723de06bfdf77bc06ce0227d3614", "patch": "@@ -214,6 +214,7 @@ bool aarch64_simd_valid_immediate (rtx, machine_mode, bool,\n bool aarch64_symbolic_address_p (rtx);\n bool aarch64_uimm12_shift (HOST_WIDE_INT);\n bool aarch64_use_return_insn_p (void);\n+const char *aarch64_mangle_builtin_type (const_tree);\n const char *aarch64_output_casesi (rtx *);\n const char *aarch64_rewrite_selected_cpu (const char *name);\n "}, {"sha": "b85a23109efae6301931f12c6b665015af570fb7", "filename": "gcc/config/aarch64/aarch64-simd-builtin-types.def", "status": "added", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtin-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtin-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtin-types.def?ref=f9d53c273b8b723de06bfdf77bc06ce0227d3614", "patch": "@@ -0,0 +1,50 @@\n+/* Builtin AdvSIMD types.\n+   Copyright (C) 2014 Free Software Foundation, Inc.\n+   Contributed by ARM Ltd.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful, but\n+   WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+   General Public License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+  ENTRY (Int8x8_t, V8QI, none, 10)\n+  ENTRY (Int8x16_t, V16QI, none, 11)\n+  ENTRY (Int16x4_t, V4HI, none, 11)\n+  ENTRY (Int16x8_t, V8HI, none, 11)\n+  ENTRY (Int32x2_t, V2SI, none, 11)\n+  ENTRY (Int32x4_t, V4SI, none, 11)\n+  ENTRY (Int64x1_t, DI, none, 11)\n+  ENTRY (Int64x2_t, V2DI, none, 11)\n+  ENTRY (Uint8x8_t, V8QI, unsigned, 11)\n+  ENTRY (Uint8x16_t, V16QI, unsigned, 12)\n+  ENTRY (Uint16x4_t, V4HI, unsigned, 12)\n+  ENTRY (Uint16x8_t, V8HI, unsigned, 12)\n+  ENTRY (Uint32x2_t, V2SI, unsigned, 12)\n+  ENTRY (Uint32x4_t, V4SI, unsigned, 12)\n+  ENTRY (Uint64x1_t, DI, unsigned, 12)\n+  ENTRY (Uint64x2_t, V2DI, unsigned, 12)\n+  ENTRY (Poly8_t, QI, poly, 9)\n+  ENTRY (Poly16_t, HI, poly, 10)\n+  ENTRY (Poly64_t, DI, poly, 10)\n+  ENTRY (Poly128_t, TI, poly, 11)\n+  ENTRY (Poly8x8_t, V8QI, poly, 11)\n+  ENTRY (Poly8x16_t, V16QI, poly, 12)\n+  ENTRY (Poly16x4_t, V4HI, poly, 12)\n+  ENTRY (Poly16x8_t, V8HI, poly, 12)\n+  ENTRY (Poly64x1_t, DI, poly, 12)\n+  ENTRY (Poly64x2_t, V2DI, poly, 12)\n+  ENTRY (Float32x2_t, V2SF, none, 13)\n+  ENTRY (Float32x4_t, V4SF, none, 13)\n+  ENTRY (Float64x1_t, V1DF, none, 13)\n+  ENTRY (Float64x2_t, V2DF, none, 13)"}, {"sha": "afc393159e7b027820f105e148ea281cdaa6c526", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 4, "deletions": 67, "changes": 71, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=f9d53c273b8b723de06bfdf77bc06ce0227d3614", "patch": "@@ -7597,54 +7597,6 @@ aarch64_autovectorize_vector_sizes (void)\n   return (16 | 8);\n }\n \n-/* A table to help perform AArch64-specific name mangling for AdvSIMD\n-   vector types in order to conform to the AAPCS64 (see \"Procedure\n-   Call Standard for the ARM 64-bit Architecture\", Appendix A).  To\n-   qualify for emission with the mangled names defined in that document,\n-   a vector type must not only be of the correct mode but also be\n-   composed of AdvSIMD vector element types (e.g.\n-   _builtin_aarch64_simd_qi); these types are registered by\n-   aarch64_init_simd_builtins ().  In other words, vector types defined\n-   in other ways e.g. via vector_size attribute will get default\n-   mangled names.  */\n-typedef struct\n-{\n-  machine_mode mode;\n-  const char *element_type_name;\n-  const char *mangled_name;\n-} aarch64_simd_mangle_map_entry;\n-\n-static aarch64_simd_mangle_map_entry aarch64_simd_mangle_map[] = {\n-  /* 64-bit containerized types.  */\n-  { V8QImode,  \"__builtin_aarch64_simd_qi\",     \"10__Int8x8_t\" },\n-  { V8QImode,  \"__builtin_aarch64_simd_uqi\",    \"11__Uint8x8_t\" },\n-  { V4HImode,  \"__builtin_aarch64_simd_hi\",     \"11__Int16x4_t\" },\n-  { V4HImode,  \"__builtin_aarch64_simd_uhi\",    \"12__Uint16x4_t\" },\n-  { V2SImode,  \"__builtin_aarch64_simd_si\",     \"11__Int32x2_t\" },\n-  { V2SImode,  \"__builtin_aarch64_simd_usi\",    \"12__Uint32x2_t\" },\n-  { V2SFmode,  \"__builtin_aarch64_simd_sf\",     \"13__Float32x2_t\" },\n-  { DImode,    \"__builtin_aarch64_simd_di\",     \"11__Int64x1_t\" },\n-  { DImode,    \"__builtin_aarch64_simd_udi\",    \"12__Uint64x1_t\" },\n-  { V1DFmode,  \"__builtin_aarch64_simd_df\",\t\"13__Float64x1_t\" },\n-  { V8QImode,  \"__builtin_aarch64_simd_poly8\",  \"11__Poly8x8_t\" },\n-  { V4HImode,  \"__builtin_aarch64_simd_poly16\", \"12__Poly16x4_t\" },\n-  /* 128-bit containerized types.  */\n-  { V16QImode, \"__builtin_aarch64_simd_qi\",     \"11__Int8x16_t\" },\n-  { V16QImode, \"__builtin_aarch64_simd_uqi\",    \"12__Uint8x16_t\" },\n-  { V8HImode,  \"__builtin_aarch64_simd_hi\",     \"11__Int16x8_t\" },\n-  { V8HImode,  \"__builtin_aarch64_simd_uhi\",    \"12__Uint16x8_t\" },\n-  { V4SImode,  \"__builtin_aarch64_simd_si\",     \"11__Int32x4_t\" },\n-  { V4SImode,  \"__builtin_aarch64_simd_usi\",    \"12__Uint32x4_t\" },\n-  { V2DImode,  \"__builtin_aarch64_simd_di\",     \"11__Int64x2_t\" },\n-  { V2DImode,  \"__builtin_aarch64_simd_udi\",    \"12__Uint64x2_t\" },\n-  { V4SFmode,  \"__builtin_aarch64_simd_sf\",     \"13__Float32x4_t\" },\n-  { V2DFmode,  \"__builtin_aarch64_simd_df\",     \"13__Float64x2_t\" },\n-  { V16QImode, \"__builtin_aarch64_simd_poly8\",  \"12__Poly8x16_t\" },\n-  { V8HImode,  \"__builtin_aarch64_simd_poly16\", \"12__Poly16x8_t\" },\n-  { V2DImode,  \"__builtin_aarch64_simd_poly64\", \"12__Poly64x2_t\" },\n-  { VOIDmode, NULL, NULL }\n-};\n-\n /* Implement TARGET_MANGLE_TYPE.  */\n \n static const char *\n@@ -7655,25 +7607,10 @@ aarch64_mangle_type (const_tree type)\n   if (lang_hooks.types_compatible_p (CONST_CAST_TREE (type), va_list_type))\n     return \"St9__va_list\";\n \n-  /* Check the mode of the vector type, and the name of the vector\n-     element type, against the table.  */\n-  if (TREE_CODE (type) == VECTOR_TYPE)\n-    {\n-      aarch64_simd_mangle_map_entry *pos = aarch64_simd_mangle_map;\n-\n-      while (pos->mode != VOIDmode)\n-\t{\n-\t  tree elt_type = TREE_TYPE (type);\n-\n-\t  if (pos->mode == TYPE_MODE (type)\n-\t      && TREE_CODE (TYPE_NAME (elt_type)) == TYPE_DECL\n-\t      && !strcmp (IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (elt_type))),\n-\t\t\t  pos->element_type_name))\n-\t    return pos->mangled_name;\n-\n-\t  pos++;\n-\t}\n-    }\n+  /* Mangle AArch64-specific internal types.  TYPE_NAME is non-NULL_TREE for\n+     builtin types.  */\n+  if (TYPE_NAME (type) != NULL)\n+    return aarch64_mangle_builtin_type (type);\n \n   /* Use the default mangling.  */\n   return NULL;"}, {"sha": "b3b80b8bc53f85f7cbfd60dfa91d18d9281f6ba7", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 30, "deletions": 54, "changes": 84, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=f9d53c273b8b723de06bfdf77bc06ce0227d3614", "patch": "@@ -32,63 +32,39 @@\n #define __AARCH64_UINT64_C(__C) ((uint64_t) __C)\n #define __AARCH64_INT64_C(__C) ((int64_t) __C)\n \n-typedef __builtin_aarch64_simd_qi int8x8_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_hi int16x4_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_si int32x2_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_di int64x1_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_df float64x1_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_sf float32x2_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_poly8 poly8x8_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_poly16 poly16x4_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_uqi uint8x8_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_uhi uint16x4_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_usi uint32x2_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_udi uint64x1_t\n-  __attribute__ ((__vector_size__ (8)));\n-typedef __builtin_aarch64_simd_qi int8x16_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_hi int16x8_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_si int32x4_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_di int64x2_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_sf float32x4_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_df float64x2_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_poly8 poly8x16_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_poly16 poly16x8_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_poly64 poly64x2_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_uqi uint8x16_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_uhi uint16x8_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_usi uint32x4_t\n-  __attribute__ ((__vector_size__ (16)));\n-typedef __builtin_aarch64_simd_udi uint64x2_t\n-  __attribute__ ((__vector_size__ (16)));\n+typedef __Int8x8_t int8x8_t;\n+typedef __Int16x4_t int16x4_t;\n+typedef __Int32x2_t int32x2_t;\n+typedef __Int64x1_t int64x1_t;\n+typedef __Float32x2_t float32x2_t;\n+typedef __Poly8x8_t poly8x8_t;\n+typedef __Poly16x4_t poly16x4_t;\n+typedef __Uint8x8_t uint8x8_t;\n+typedef __Uint16x4_t uint16x4_t;\n+typedef __Uint32x2_t uint32x2_t;\n+typedef __Float64x1_t float64x1_t;\n+typedef __Uint64x1_t uint64x1_t;\n+typedef __Int8x16_t int8x16_t;\n+typedef __Int16x8_t int16x8_t;\n+typedef __Int32x4_t int32x4_t;\n+typedef __Int64x2_t int64x2_t;\n+typedef __Float32x4_t float32x4_t;\n+typedef __Float64x2_t float64x2_t;\n+typedef __Poly8x16_t poly8x16_t;\n+typedef __Poly16x8_t poly16x8_t;\n+typedef __Poly64x2_t poly64x2_t;\n+typedef __Uint8x16_t uint8x16_t;\n+typedef __Uint16x8_t uint16x8_t;\n+typedef __Uint32x4_t uint32x4_t;\n+typedef __Uint64x2_t uint64x2_t;\n+\n+typedef __Poly8_t poly8_t;\n+typedef __Poly16_t poly16_t;\n+typedef __Poly64_t poly64_t;\n+typedef __Poly128_t poly128_t;\n \n typedef float float32_t;\n typedef double float64_t;\n-typedef __builtin_aarch64_simd_poly8 poly8_t;\n-typedef __builtin_aarch64_simd_poly16 poly16_t;\n-typedef __builtin_aarch64_simd_poly64 poly64_t;\n-typedef __builtin_aarch64_simd_poly128 poly128_t;\n \n typedef struct int8x8x2_t\n {"}, {"sha": "977b746f33d1a03adc746bf2cb78ec2abe164211", "filename": "gcc/config/aarch64/t-aarch64", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Ft-aarch64", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9d53c273b8b723de06bfdf77bc06ce0227d3614/gcc%2Fconfig%2Faarch64%2Ft-aarch64", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Ft-aarch64?ref=f9d53c273b8b723de06bfdf77bc06ce0227d3614", "patch": "@@ -32,6 +32,7 @@ aarch64-builtins.o: $(srcdir)/config/aarch64/aarch64-builtins.c $(CONFIG_H) \\\n   $(RTL_H) $(TREE_H) expr.h $(TM_P_H) $(RECOG_H) langhooks.h \\\n   $(DIAGNOSTIC_CORE_H) $(OPTABS_H) \\\n   $(srcdir)/config/aarch64/aarch64-simd-builtins.def \\\n+  $(srcdir)/config/aarch64/aarch64-simd-builtin-types.def \\\n   aarch64-builtin-iterators.h\n \t$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \\\n \t\t$(srcdir)/config/aarch64/aarch64-builtins.c"}]}