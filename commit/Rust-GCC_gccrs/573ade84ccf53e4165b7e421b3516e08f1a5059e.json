{"sha": "573ade84ccf53e4165b7e421b3516e08f1a5059e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTczYWRlODRjY2Y1M2U0MTY1YjdlNDIxYjM1MTZlMDhmMWE1MDU5ZQ==", "commit": {"author": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1991-08-28T12:11:01Z"}, "committer": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1991-08-28T12:11:01Z"}, "message": "Initial revision\n\nFrom-SVN: r35", "tree": {"sha": "4e7393e9e1170f3f0ac53e1a697a37a91ba8fd8f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4e7393e9e1170f3f0ac53e1a697a37a91ba8fd8f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/573ade84ccf53e4165b7e421b3516e08f1a5059e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/573ade84ccf53e4165b7e421b3516e08f1a5059e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/573ade84ccf53e4165b7e421b3516e08f1a5059e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/573ade84ccf53e4165b7e421b3516e08f1a5059e/comments", "author": null, "committer": null, "parents": [{"sha": "3a33f76f58e65a43ba5b26877f122c7e53fd67d2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3a33f76f58e65a43ba5b26877f122c7e53fd67d2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3a33f76f58e65a43ba5b26877f122c7e53fd67d2"}], "stats": {"total": 1372, "additions": 1372, "deletions": 0}, "files": [{"sha": "1edb7b874707815873433dfbb987c94d8d33886b", "filename": "gcc/config/pyr/pyr.md", "status": "added", "additions": 1372, "deletions": 0, "changes": 1372, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/573ade84ccf53e4165b7e421b3516e08f1a5059e/gcc%2Fconfig%2Fpyr%2Fpyr.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/573ade84ccf53e4165b7e421b3516e08f1a5059e/gcc%2Fconfig%2Fpyr%2Fpyr.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpyr%2Fpyr.md?ref=573ade84ccf53e4165b7e421b3516e08f1a5059e", "patch": "@@ -0,0 +1,1372 @@\n+;; GNU C machine description for Pyramid 90x, 9000, MIServer Series\n+;; Copyright (C) 1989, 1990 Free Software Foundation, Inc.\n+\n+;; This file is part of GNU CC.\n+\n+;; GNU CC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 2, or (at your option)\n+;; any later version.\n+\n+;; GNU CC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GNU CC; see the file COPYING.  If not, write to\n+;; the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.\n+\n+;; Instruction patterns.  When multiple patterns apply,\n+;; the first one in the file is chosen.\n+;;\n+;; See file \"rtl.def\" for documentation on define_insn, match_*, et. al.\n+;;\n+;; cpp macro #define NOTICE_UPDATE_CC in file tm.h handles condition code\n+;; updates for most instructions.\n+\f\n+;; * Try using define_insn instead of some peepholes in more places.\n+;; * Set REG_NOTES:REG_EQUIV for cvt[bh]w loads.  This would make the\n+;;   backward scan in sign_extend needless.\n+;; * Match (pc) (label_ref) case in peephole patterns.\n+;; * Should optimize\n+;;   \"cmpX op1,op2;  b{eq,ne} LY;  ucmpX op1.op2;  b{lt,le,gt,ge} LZ\"\n+;;   to\n+;;   \"ucmpX op1,op2;  b{eq,ne} LY;  b{lt,le,gt,ge} LZ\"\n+;;   by pre-scanning insn and running notice_update_cc for them.\n+;; * Is it necessary to do copy_rtx in the test and compare patterns?\n+;; * Fix true frame pointer omission.\n+;; * Make the jump tables contain branches, not addresses!  This would\n+;;   save us one instruction.\n+;; * Could the compilcated scheme for compares be simplyfied, if we had\n+;;   no named cmpqi or cmphi patterns, and instead anonymous patterns for\n+;;   the less-than-word compare cases pyr can handle???\n+;; * The jump insn seems to accept more than just IR addressing.  Would\n+;;   we win by telling GCC?  Or can we use movw into the global reg which\n+;;   is a synonym for pc?\n+;; * More DImode patterns.\n+;; * Scan backwards in \"zero_extendhisi2\", \"zero_extendqisi2\" to find out\n+;;   if the extension can be omitted.\n+;; * \"divmodsi\" with Pyramid \"ediv\" insn.  Is it possible in rtl??\n+;; * Would \"rcsp tmpreg; u?cmp[bh] op1_regdispl(tmpreg),op2\" win in\n+;;   comparison with the two extensions and single test generated now?\n+;;   The rcsp insn could be expanded, and moved out of loops by the\n+;;   optimizer, making 1 (64 bit) insn of 3 (32 bit) insns in loops.\n+;;   The rcsp insn could be followed by an add insn, making non-displacement\n+;;   IR addressing sufficient.\n+\n+;______________________________________________________________________\n+;\n+;\tTest and Compare Patterns.\n+;______________________________________________________________________\n+\n+; The argument for the rather complicated test and compare expansion\n+; scheme, is the irregular pyramid instructions for these operations.\n+; 1) Pyramid has different signed and unsigned compares.  2) HImode\n+; and QImode integers are memory-memory and immediate-memory only.  3)\n+; Unsigned HImode compares doesn't exist.  4) Only certain\n+; combinations of addresses are allowed for memory-memory compares.\n+; Whenever necessary, in order to fulfill these addressing\n+; constraints, the compare operands are swapped.\n+\n+(define_expand \"tstsi\"\n+  [(set (cc0)\n+\t(match_operand:SI 0 \"general_operand\" \"\"))]\n+  \"\" \"operands[0] = force_reg (SImode, operands[0]);\")\n+\n+(define_insn \"\"\n+  [(set (cc0)\n+\t(compare (match_operand:SI 0 \"memory_operand\" \"m\")\n+\t\t (match_operand:SI 1 \"memory_operand\" \"m\")))]\n+  \"weird_memory_memory (operands[0], operands[1])\"\n+  \"*\n+{\n+  rtx br_insn = NEXT_INSN (insn);\n+  RTX_CODE br_code;\n+\n+  if (GET_CODE (br_insn) != JUMP_INSN)\n+    abort();\n+  br_code =  GET_CODE (XEXP (XEXP (PATTERN (br_insn), 1), 0));\n+\n+  weird_memory_memory (operands[0], operands[1]);\n+\n+  if (swap_operands)\n+    {\n+      cc_status.flags = CC_REVERSED;\n+      if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+\t{\n+\t  cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+\t  return \\\"ucmpw %0,%1\\\";\n+\t}\n+      return \\\"cmpw %0,%1\\\";\n+    }\n+\n+  if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+    {\n+      cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+      return \\\"ucmpw %1,%0\\\";\n+    }\n+  return \\\"cmpw %1,%0\\\";\n+}\")\n+\n+(define_insn \"cmpsi\"\n+  [(set (cc0)\n+\t(compare (match_operand:SI 0 \"nonimmediate_operand\" \"r,g\")\n+\t\t (match_operand:SI 1 \"general_operand\" \"g,r\")))]\n+  \"\"\n+  \"*\n+{\n+  rtx br_insn = NEXT_INSN (insn);\n+  RTX_CODE br_code;\n+\n+  if (GET_CODE (br_insn) != JUMP_INSN)\n+    abort();\n+  br_code =  GET_CODE (XEXP (XEXP (PATTERN (br_insn), 1), 0));\n+\n+  if (which_alternative != 0)\n+    {\n+      cc_status.flags = CC_REVERSED;\n+      if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+\t{\n+\t  cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+\t  return \\\"ucmpw %0,%1\\\";\n+\t}\n+      return \\\"cmpw %0,%1\\\";\n+    }\n+\n+  if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+    {\n+      cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+      return \\\"ucmpw %1,%0\\\";\n+    }\n+  return \\\"cmpw %1,%0\\\";\n+}\")\n+\n+(define_insn \"\"\n+  [(set (cc0)\n+\t(match_operand:SI 0 \"general_operand\" \"r\"))]\n+  \"\"\n+  \"*\n+{\n+#if 0\n+  cc_status.flags |= CC_NO_OVERFLOW;\n+  return \\\"cmpw $0,%0\\\";\n+#endif\n+  rtx br_insn = NEXT_INSN (insn);\n+  RTX_CODE br_code;\n+\n+  if (GET_CODE (br_insn) != JUMP_INSN)\n+    abort();\n+  br_code =  GET_CODE (XEXP (XEXP (PATTERN (br_insn), 1), 0));\n+\n+  if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+    {\n+      cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+      return \\\"ucmpw $0,%0\\\";\n+    }\n+  return \\\"mtstw %0,%0\\\";\n+}\")\n+\n+(define_expand \"cmphi\"\n+  [(set (cc0)\n+\t(compare (match_operand:HI 0 \"nonimmediate_operand\" \"\")\n+\t\t (match_operand:HI 1 \"general_operand\" \"\")))]\n+  \"\"\n+  \"\n+{\n+  extern rtx test_op0, test_op1;  extern enum machine_mode test_mode;\n+  test_op0 = copy_rtx (operands[0]);\n+  test_op1 = copy_rtx (operands[1]);\n+  test_mode = HImode;\n+  DONE;\n+}\")\n+\n+(define_expand \"tsthi\"\n+  [(set (cc0)\n+\t(match_operand:HI 0 \"general_operand\" \"\"))]\n+  \"\"\n+  \"\n+{\n+  extern rtx test_op0;  extern enum machine_mode test_mode;\n+  test_op0 = copy_rtx (operands[0]);\n+  test_mode = HImode;\n+  DONE;\n+}\")\n+\n+(define_insn \"\"\n+  [(set (cc0)\n+\t(compare (match_operand:HI 0 \"memory_operand\" \"m\")\n+\t\t (match_operand:HI 1 \"memory_operand\" \"m\")))]\n+  \"weird_memory_memory (operands[0], operands[1])\"\n+  \"*\n+{\n+  rtx br_insn = NEXT_INSN (insn);\n+\n+  if (GET_CODE (br_insn) != JUMP_INSN)\n+    abort();\n+\n+  weird_memory_memory (operands[0], operands[1]);\n+\n+  if (swap_operands)\n+    {\n+      cc_status.flags = CC_REVERSED;\n+      return \\\"cmph %0,%1\\\";\n+    }\n+\n+  return \\\"cmph %1,%0\\\";\n+}\")\n+\n+(define_insn \"\"\n+  [(set (cc0)\n+\t(compare (match_operand:HI 0 \"nonimmediate_operand\" \"r,m\")\n+\t\t (match_operand:HI 1 \"nonimmediate_operand\" \"m,r\")))]\n+  \"(GET_CODE (operands[0]) != GET_CODE (operands[1]))\"\n+  \"*\n+{\n+  rtx br_insn = NEXT_INSN (insn);\n+\n+  if (GET_CODE (br_insn) != JUMP_INSN)\n+    abort();\n+\n+  if (which_alternative != 0)\n+    {\n+      cc_status.flags = CC_REVERSED;\n+      return \\\"cmph %0,%1\\\";\n+    }\n+\n+  return \\\"cmph %1,%0\\\";\n+}\")\n+\n+(define_expand \"cmpqi\"\n+  [(set (cc0)\n+\t(compare (match_operand:QI 0 \"nonimmediate_operand\" \"\")\n+\t\t (match_operand:QI 1 \"general_operand\" \"\")))]\n+  \"\"\n+  \"\n+{\n+  extern rtx test_op0, test_op1;  extern enum machine_mode test_mode;\n+  test_op0 = copy_rtx (operands[0]);\n+  test_op1 = copy_rtx (operands[1]);\n+  test_mode = QImode;\n+  DONE;\n+}\")\n+\n+(define_expand \"tstqi\"\n+  [(set (cc0)\n+\t(match_operand:QI 0 \"general_operand\" \"\"))]\n+  \"\"\n+  \"\n+{\n+  extern rtx test_op0;  extern enum machine_mode test_mode;\n+  test_op0 = copy_rtx (operands[0]);\n+  test_mode = QImode;\n+  DONE;\n+}\")\n+\n+(define_insn \"\"\n+  [(set (cc0)\n+\t(compare (match_operand:QI 0 \"memory_operand\" \"m\")\n+\t\t (match_operand:QI 1 \"memory_operand\" \"m\")))]\n+  \"weird_memory_memory (operands[0], operands[1])\"\n+  \"*\n+{\n+  rtx br_insn = NEXT_INSN (insn);\n+  RTX_CODE br_code;\n+\n+  if (GET_CODE (br_insn) != JUMP_INSN)\n+    abort();\n+  br_code =  GET_CODE (XEXP (XEXP (PATTERN (br_insn), 1), 0));\n+\n+  weird_memory_memory (operands[0], operands[1]);\n+\n+  if (swap_operands)\n+    {\n+      cc_status.flags = CC_REVERSED;\n+      if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+\t{\n+\t  cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+\t  return \\\"ucmpb %0,%1\\\";\n+\t}\n+      return \\\"cmpb %0,%1\\\";\n+    }\n+\n+  if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+    {\n+      cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+      return \\\"ucmpb %1,%0\\\";\n+    }\n+  return \\\"cmpb %1,%0\\\";\n+}\")\n+\n+(define_insn \"\"\n+  [(set (cc0)\n+\t(compare (match_operand:QI 0 \"nonimmediate_operand\" \"r,m\")\n+\t\t (match_operand:QI 1 \"nonimmediate_operand\" \"m,r\")))]\n+  \"(GET_CODE (operands[0]) != GET_CODE (operands[1]))\"\n+  \"*\n+{\n+  rtx br_insn = NEXT_INSN (insn);\n+  RTX_CODE br_code;\n+\n+  if (GET_CODE (br_insn) != JUMP_INSN)\n+    abort();\n+  br_code =  GET_CODE (XEXP (XEXP (PATTERN (br_insn), 1), 0));\n+\n+  if (which_alternative != 0)\n+    {\n+      cc_status.flags = CC_REVERSED;\n+      if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+\t{\n+\t  cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+\t  return \\\"ucmpb %0,%1\\\";\n+\t}\n+      return \\\"cmpb %0,%1\\\";\n+    }\n+\n+  if (TRULY_UNSIGNED_COMPARE_P (br_code))\n+    {\n+      cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+      return \\\"ucmpb %1,%0\\\";\n+    }\n+  return \\\"cmpb %1,%0\\\";\n+}\")\n+\n+(define_expand \"bgt\"\n+  [(set (pc) (if_then_else (gt (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (SIGN_EXTEND);\")\n+\n+(define_expand \"blt\"\n+  [(set (pc) (if_then_else (lt (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (SIGN_EXTEND);\")\n+\n+(define_expand \"bge\"\n+  [(set (pc) (if_then_else (ge (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (SIGN_EXTEND);\")\n+\n+(define_expand \"ble\"\n+  [(set (pc) (if_then_else (le (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (SIGN_EXTEND);\")\n+\n+(define_expand \"beq\"\n+  [(set (pc) (if_then_else (eq (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (SIGN_EXTEND);\")\n+\n+(define_expand \"bne\"\n+  [(set (pc) (if_then_else (ne (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (SIGN_EXTEND);\")\n+\n+(define_expand \"bgtu\"\n+  [(set (pc) (if_then_else (gtu (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (ZERO_EXTEND);\")\n+\n+(define_expand \"bltu\"\n+  [(set (pc) (if_then_else (ltu (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (ZERO_EXTEND);\")\n+\n+(define_expand \"bgeu\"\n+  [(set (pc) (if_then_else (geu (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (ZERO_EXTEND);\")\n+\n+(define_expand \"bleu\"\n+  [(set (pc) (if_then_else (leu (cc0) (const_int 0))\n+\t\t\t   (label_ref (match_operand 0 \"\" \"\")) (pc)))]\n+  \"\" \"extend_and_branch (ZERO_EXTEND);\")\n+\n+(define_insn \"cmpdf\"\n+  [(set (cc0)\n+\t(compare (match_operand:DF 0 \"register_operand\" \"r\")\n+\t\t (match_operand:DF 1 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"cmpd %1,%0\")\n+\n+(define_insn \"cmpsf\"\n+  [(set (cc0)\n+\t(compare (match_operand:SF 0 \"register_operand\" \"r\")\n+\t\t (match_operand:SF 1 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"cmpf %1,%0\")\n+\n+(define_insn \"tstdf\"\n+  [(set (cc0)\n+       \t(match_operand:DF 0 \"register_operand\" \"r\"))]\n+  \"\"\n+  \"mtstd %0,%0\")\n+\n+(define_insn \"tstsf\"\n+  [(set (cc0)\n+       \t(match_operand:SF 0 \"register_operand\" \"r\"))]\n+  \"\"\n+  \"mtstf %0,%0\")\n+\f\n+;______________________________________________________________________\n+;\n+;\tFixed-point Arithmetic.\n+;______________________________________________________________________\n+\n+(define_insn \"addsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r,!r\")\n+\t(plus:SI (match_operand:SI 1 \"general_operand\" \"%0,r\")\n+\t\t (match_operand:SI 2 \"general_operand\" \"g,rJ\")))]\n+  \"\"\n+  \"*\n+{\n+  if (which_alternative == 0)\n+    return (GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) == 32\n+\t    ? \\\"subw %n2,%0\\\" : \\\"addw %2,%0\\\");\n+  else\n+    {\n+      forget_cc_if_dependent (operands[0]);\n+      return \\\"mova %a2[%1*1],%0\\\";\n+    }\n+}\")\n+\n+(define_insn \"subsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r,r\")\n+\t(minus:SI (match_operand:SI 1 \"general_operand\" \"0,g\")\n+\t\t  (match_operand:SI 2 \"general_operand\" \"g,0\")))]\n+  \"\"\n+  \"* return (which_alternative == 0) ? \\\"subw %2,%0\\\" : \\\"rsubw %1,%0\\\";\")\n+\n+(define_insn \"mulsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(mult:SI (match_operand:SI 1 \"general_operand\" \"%0\")\n+\t\t (match_operand:SI 2 \"general_operand\" \"g\")))]\n+  \"\"\n+  \"mulw %2,%0\")\n+\n+(define_insn \"divsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r,r\")\n+\t(div:SI (match_operand:SI 1 \"general_operand\" \"0,g\")\n+\t\t(match_operand:SI 2 \"general_operand\" \"g,0\")))]\n+  \"\"\n+  \"* return (which_alternative == 0) ? \\\"divw %2,%0\\\" : \\\"rdivw %1,%0\\\";\")\n+\n+(define_insn \"udivsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(udiv:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t (match_operand:SI 2 \"general_operand\" \"g\")))]\n+  \"\"\n+  \"udivw %2,%0\")\n+\n+(define_insn \"modsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(mod:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t(match_operand:SI 2 \"general_operand\" \"g\")))]\n+  \"\"\n+  \"modw %2,%0\")\n+\n+(define_insn \"umodsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(umod:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t (match_operand:SI 2 \"general_operand\" \"g\")))]\n+  \"\"\n+  \"umodw %2,%0\")\n+\n+(define_insn \"negsi2\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(neg:SI (match_operand:SI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"mnegw %1,%0\")\n+\n+(define_insn \"one_cmplsi2\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(not:SI (match_operand:SI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"mcomw %1,%0\")\n+\n+(define_insn \"abssi2\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(abs:SI (match_operand:SI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"mabsw %1,%0\")\n+\f\n+;______________________________________________________________________\n+;\n+;\tFloating-point Arithmetic.\n+;______________________________________________________________________\n+\n+(define_insn \"adddf3\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=r\")\n+\t(plus:DF (match_operand:DF 1 \"register_operand\" \"%0\")\n+\t\t (match_operand:DF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"addd %2,%0\")\n+\n+(define_insn \"addsf3\"\n+  [(set (match_operand:SF 0 \"register_operand\" \"=r\")\n+\t(plus:SF (match_operand:SF 1 \"register_operand\" \"%0\")\n+\t\t (match_operand:SF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"addf %2,%0\")\n+\n+(define_insn \"subdf3\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=r\")\n+\t(minus:DF (match_operand:DF 1 \"register_operand\" \"0\")\n+\t\t  (match_operand:DF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"subd %2,%0\")\n+\n+(define_insn \"subsf3\"\n+  [(set (match_operand:SF 0 \"register_operand\" \"=r\")\n+\t(minus:SF (match_operand:SF 1 \"register_operand\" \"0\")\n+\t\t  (match_operand:SF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"subf %2,%0\")\n+\n+(define_insn \"muldf3\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=r\")\n+\t(mult:DF (match_operand:DF 1 \"register_operand\" \"%0\")\n+\t\t (match_operand:DF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"muld %2,%0\")\n+\n+(define_insn \"mulsf3\"\n+  [(set (match_operand:SF 0 \"register_operand\" \"=r\")\n+\t(mult:SF (match_operand:SF 1 \"register_operand\" \"%0\")\n+\t\t (match_operand:SF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"mulf %2,%0\")\n+\n+(define_insn \"divdf3\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=r\")\n+\t(div:DF (match_operand:DF 1 \"register_operand\" \"0\")\n+\t\t(match_operand:DF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"divd %2,%0\")\n+\n+(define_insn \"divsf3\"\n+  [(set (match_operand:SF 0 \"register_operand\" \"=r\")\n+\t(div:SF (match_operand:SF 1 \"register_operand\" \"0\")\n+\t\t(match_operand:SF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"divf %2,%0\")\n+\n+(define_insn \"negdf2\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=r\")\n+\t(neg:DF (match_operand:DF 1 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"mnegd %1,%0\")\n+\n+(define_insn \"negsf2\"\n+  [(set (match_operand:SF 0 \"register_operand\" \"=r\")\n+\t(neg:SF (match_operand:SF 1 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"mnegf %1,%0\")\n+\n+(define_insn \"absdf2\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=r\")\n+\t(abs:DF (match_operand:DF 1 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"mabsd %1,%0\")\n+\n+(define_insn \"abssf2\"\n+  [(set (match_operand:SF 0 \"register_operand\" \"=r\")\n+\t(abs:SF (match_operand:SF 1 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"mabsf %1,%0\")\n+\f\n+;______________________________________________________________________\n+;\n+;\tLogical and Shift Instructions.\n+;______________________________________________________________________\n+\n+(define_insn \"\"\n+  [(set (cc0)\n+\t(and:SI (match_operand:SI 0 \"general_operand\" \"%r\")\n+\t\t(match_operand:SI 1 \"general_operand\" \"g\")))]\n+  \"\"\n+  \"*\n+{\n+  cc_status.flags |= CC_NO_OVERFLOW;\n+  return \\\"bitw %1,%0\\\";\n+}\")\n+\n+(define_insn \"andsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r,r\")\n+\t(and:SI (match_operand:SI 1 \"general_operand\" \"%0,r\")\n+\t\t(match_operand:SI 2 \"general_operand\" \"g,K\")))]\n+  \"\"\n+  \"*\n+{\n+  if (which_alternative == 0)\n+    return \\\"andw %2,%0\\\";\n+\n+  cc_status.flags = CC_NOT_NEGATIVE;\n+  return (INTVAL (operands[2]) == 255\n+\t  ? \\\"movzbw %1,%0\\\" : \\\"movzhw %1,%0\\\");\n+}\")\n+\n+(define_insn \"\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(and:SI (not:SI (match_operand:SI 1 \"general_operand\" \"g\"))\n+\t\t(match_operand:SI 2 \"register_operand\" \"0\")))]\n+  \"\"\n+  \"bicw %1,%0\")\n+\n+(define_insn \"iorsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(ior:SI (match_operand:SI 1 \"general_operand\" \"%0\")\n+\t\t(match_operand:SI 2 \"general_operand\" \"g\")))]\n+  \"\"\n+  \"orw %2,%0\")\n+\n+(define_insn \"xorsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(xor:SI (match_operand:SI 1 \"general_operand\" \"%0\")\n+\t\t(match_operand:SI 2 \"general_operand\" \"g\")))]\n+  \"\"\n+  \"xorw %2,%0\")\n+\n+; The arithmetic left shift instructions work strangely on pyramids.\n+; They fail to modify the sign bit.  Therefore, use logic shifts.\n+\n+(define_insn \"ashlsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(ashift:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t   (match_operand:SI 2 \"general_operand\" \"rnm\")))]\n+  \"\"\n+  \"* return output_shift (\\\"lshlw %2,%0\\\", operands[2], 32); \")\n+\n+(define_insn \"ashrsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(ashiftrt:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t     (match_operand:SI 2 \"general_operand\" \"rnm\")))]\n+  \"\"\n+  \"* return output_shift (\\\"ashrw %2,%0\\\", operands[2], 32); \")\n+\n+(define_insn \"ashrdi3\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n+\t(ashiftrt:DI (match_operand:DI 1 \"register_operand\" \"0\")\n+\t\t     (match_operand:SI 2 \"general_operand\" \"rnm\")))]\n+  \"\"\n+  \"* return output_shift (\\\"ashrl %2,%0\\\", operands[2], 64); \")\n+\n+(define_insn \"lshrsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(lshiftrt:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t     (match_operand:SI 2 \"general_operand\" \"rnm\")))]\n+  \"\"\n+  \"* return output_shift (\\\"lshrw %2,%0\\\", operands[2], 32); \")\n+\n+(define_insn \"rotlsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(rotate:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t   (match_operand:SI 2 \"general_operand\" \"rnm\")))]\n+  \"\"\n+  \"* return output_shift (\\\"rotlw %2,%0\\\", operands[2], 32); \")\n+\n+(define_insn \"rotrsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(rotatert:SI (match_operand:SI 1 \"register_operand\" \"0\")\n+\t\t     (match_operand:SI 2 \"general_operand\" \"rnm\")))]\n+  \"\"\n+  \"* return output_shift (\\\"rotrw %2,%0\\\", operands[2], 32); \")\n+\f\n+;______________________________________________________________________\n+;\n+;\tFixed and Floating Moves.\n+;______________________________________________________________________\n+\n+;; If the destination is a memory operand, indexed source operands are\n+;; disallowed.  Big DImode constants are always loaded into a reg pair,\n+;; although offsetable memory addresses really could be dealt with.\n+\n+(define_insn \"\"\n+  [(set (match_operand:DI 0 \"memory_operand\" \"=m\")\n+\t(match_operand:DI 1 \"nonindexed_operand\" \"gF\"))]\n+  \"(GET_CODE (operands[1]) == CONST_DOUBLE\n+     ? ((CONST_DOUBLE_HIGH (operands[1]) == 0\n+\t && CONST_DOUBLE_LOW (operands[1]) >= 0)\n+\t|| (CONST_DOUBLE_HIGH (operands[1]) == -1\n+\t    && CONST_DOUBLE_LOW (operands[1]) < 0))\n+     : 1)\"\n+  \"*\n+{\n+  if (GET_CODE (operands[1]) == CONST_DOUBLE)\n+    operands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t      CONST_DOUBLE_LOW (operands[1]));\n+  return \\\"movl %1,%0\\\";\n+}\")\n+\n+;; Force the destination to a register, so all source operands are allowed.\n+\n+(define_insn \"movdi\"\n+  [(set (match_operand:DI 0 \"general_operand\" \"=r\")\n+\t(match_operand:DI 1 \"general_operand\" \"gF\"))]\n+  \"\"\n+  \"* return output_move_double (operands); \")\n+\n+;; If the destination is a memory address, indexed source operands are\n+;; disallowed.\n+\n+(define_insn \"\"\n+  [(set (match_operand:SI 0 \"memory_operand\" \"=m\")\n+\t(match_operand:SI 1 \"nonindexed_operand\" \"g\"))]\n+  \"\"\n+  \"movw %1,%0\")\n+\n+;; Force the destination to a register, so all source operands are allowed.\n+\n+(define_insn \"movsi\"\n+  [(set (match_operand:SI 0 \"general_operand\" \"=r\")\n+\t(match_operand:SI 1 \"general_operand\" \"g\"))]\n+  \"\"\n+  \"movw %1,%0\")\n+\n+;; If the destination is a memory address, indexed source operands are\n+;; disallowed.\n+\n+(define_insn \"\"\n+  [(set (match_operand:HI 0 \"memory_operand\" \"=m\")\n+\t(match_operand:HI 1 \"nonindexed_operand\" \"g\"))]\n+  \"\"\n+  \"*\n+{\n+  if (REG_P (operands[1]))\n+    return \\\"cvtwh %1,%0\\\";\t\t/* reg -> mem */\n+  else\n+    return \\\"movh %1,%0\\\";\t\t/* mem imm -> mem */\n+}\")\n+\n+;; Force the destination to a register, so all source operands are allowed.\n+\n+(define_insn \"movhi\"\n+  [(set (match_operand:HI 0 \"general_operand\" \"=r\")\n+\t(match_operand:HI 1 \"general_operand\" \"g\"))]\n+  \"\"\n+  \"*\n+{\n+  if (GET_CODE (operands[1]) != MEM)\n+    return \\\"movw %1,%0\\\";\t\t/* reg imm -> reg  */\n+  return \\\"cvthw %1,%0\\\";\t\t/* mem -> reg */\n+}\")\n+\n+;; If the destination is a memory address, indexed source operands are\n+;; disallowed.\n+\n+(define_insn \"\"\n+  [(set (match_operand:QI 0 \"memory_operand\" \"=m\")\n+\t(match_operand:QI 1 \"nonindexed_operand\" \"g\"))]\n+  \"\"\n+  \"*\n+{\n+  if (REG_P (operands[1]))\n+    return \\\"cvtwb %1,%0\\\";\t\t/* reg -> mem */\n+  else\n+    return \\\"movb %1,%0\\\";\t\t/* mem imm -> mem */\n+}\")\n+\n+;; Force the destination to a register, so all source operands are allowed.\n+\n+(define_insn \"movqi\"\n+  [(set (match_operand:QI 0 \"general_operand\" \"=r\")\n+\t(match_operand:QI 1 \"general_operand\" \"g\"))]\n+  \"\"\n+  \"*\n+{\n+  if (GET_CODE (operands[1]) != MEM)\n+    return \\\"movw %1,%0\\\";\t\t/* reg imm -> reg  */\n+  return \\\"cvtbw %1,%0\\\";\t\t/* mem -> reg */\n+}\")\n+\n+;; If the destination is a memory address, indexed source operands are\n+;; disallowed.\n+\n+(define_insn \"\"\n+  [(set (match_operand:DF 0 \"memory_operand\" \"=m\")\n+\t(match_operand:DF 1 \"nonindexed_operand\" \"g\"))]\n+  \"GET_CODE (operands[1]) != CONST_DOUBLE\"\n+  \"movl %1,%0\")\n+\n+;; Force the destination to a register, so all source operands are allowed.\n+\n+(define_insn \"movdf\"\n+  [(set (match_operand:DF 0 \"general_operand\" \"=r\")\n+\t(match_operand:DF 1 \"general_operand\" \"gF\"))]\n+  \"\"\n+  \"* return output_move_double (operands); \")\n+\n+;; If the destination is a memory address, indexed source operands are\n+;; disallowed.\n+\n+(define_insn \"\"\n+  [(set (match_operand:SF 0 \"memory_operand\" \"=m\")\n+\t(match_operand:SF 1 \"nonindexed_operand\" \"g\"))]\n+  \"\"\n+  \"movw %1,%0\")\n+\n+;; Force the destination to a register, so all source operands are allowed.\n+\n+(define_insn \"movsf\"\n+  [(set (match_operand:SF 0 \"general_operand\" \"=r\")\n+\t(match_operand:SF 1 \"general_operand\" \"g\"))]\n+  \"\"\n+  \"movw %1,%0\")\n+\n+(define_insn \"\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(match_operand:QI 1 \"address_operand\" \"p\"))]\n+  \"\"\n+  \"*\n+{\n+  forget_cc_if_dependent (operands[0]);\n+  return \\\"mova %a1,%0\\\";\n+}\")\n+\f\n+;______________________________________________________________________\n+;\n+;\tConversion patterns.\n+;______________________________________________________________________\n+\n+;; The trunc patterns are used only when non compile-time constants are used.\n+\n+(define_insn \"truncsiqi2\"\n+  [(set (match_operand:QI 0 \"register_operand\" \"=r\")\n+\t(truncate:QI (match_operand:SI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"*\n+{\n+  if (REG_P (operands[0]) && REG_P (operands[1])\n+      && REGNO (operands[0]) == REGNO (operands[1]))\n+    {\n+      cc_status = cc_prev_status;\n+      return \\\"\\\";\n+    }\n+  forget_cc_if_dependent (operands[0]);\n+  return \\\"movw %1,%0\\\";\n+}\")\n+\n+(define_insn \"truncsihi2\"\n+  [(set (match_operand:HI 0 \"register_operand\" \"=r\")\n+\t(truncate:HI (match_operand:SI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"*\n+{\n+  if (REG_P (operands[0]) && REG_P (operands[1])\n+      && REGNO (operands[0]) == REGNO (operands[1]))\n+    {\n+      cc_status = cc_prev_status;\n+      return \\\"\\\";\n+    }\n+  forget_cc_if_dependent (operands[0]);\n+  return \\\"movw %1,%0\\\";\n+}\")\n+\n+(define_insn \"extendhisi2\"\n+  [(set (match_operand:SI 0 \"general_operand\" \"=r,m\")\n+\t(sign_extend:SI (match_operand:HI 1 \"nonimmediate_operand\" \"rm,r\")))]\n+  \"\"\n+  \"*\n+{\n+  extern int optimize;\n+  if (optimize && REG_P (operands[0]) && REG_P (operands[1])\n+      && REGNO (operands[0]) == REGNO (operands[1])\n+      && already_sign_extended (insn, HImode, operands[0]))\n+    {\n+      cc_status = cc_prev_status;\n+      return \\\"\\\";\n+    }\n+  return \\\"cvthw %1,%0\\\";\n+}\")\n+\n+(define_insn \"extendqisi2\"\n+  [(set (match_operand:SI 0 \"general_operand\" \"=r,m\")\n+\t(sign_extend:SI (match_operand:QI 1 \"nonimmediate_operand\" \"rm,r\")))]\n+  \"\"\n+  \"*\n+{\n+  extern int optimize;\n+  if (optimize && REG_P (operands[0]) && REG_P (operands[1])\n+      && REGNO (operands[0]) == REGNO (operands[1])\n+      && already_sign_extended (insn, QImode, operands[0]))\n+    {\n+      cc_status = cc_prev_status;\n+      return \\\"\\\";\n+    }\n+  return \\\"cvtbw %1,%0\\\";\n+}\")\n+\n+; Pyramid doesn't have insns *called* \"cvtbh\" or \"movzbh\".\n+; But we can cvtbw/movzbw into a register, where there is no distinction\n+; between words and halfwords.\n+\n+(define_insn \"extendqihi2\"\n+  [(set (match_operand:HI 0 \"register_operand\" \"=r\")\n+\t(sign_extend:HI (match_operand:QI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"cvtbw %1,%0\")\n+\n+(define_insn \"zero_extendhisi2\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(zero_extend:SI (match_operand:HI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"*\n+{\n+  cc_status.flags = CC_NOT_NEGATIVE;\n+  return \\\"movzhw %1,%0\\\";\n+}\")\n+\n+(define_insn \"zero_extendqisi2\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(zero_extend:SI (match_operand:QI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"*\n+{\n+  cc_status.flags = CC_NOT_NEGATIVE;\n+  return \\\"movzbw %1,%0\\\";\n+}\")\n+\n+(define_insn \"zero_extendqihi2\"\n+  [(set (match_operand:HI 0 \"register_operand\" \"=r\")\n+\t(zero_extend:HI (match_operand:QI 1 \"nonimmediate_operand\" \"rm\")))]\n+  \"\"\n+  \"*\n+{\n+  cc_status.flags = CC_NOT_NEGATIVE;\n+  return \\\"movzbw %1,%0\\\";\n+}\")\n+\n+(define_insn \"extendsfdf2\"\n+  [(set (match_operand:DF 0 \"general_operand\" \"=&r,m\")\n+\t(float_extend:DF (match_operand:SF 1 \"nonimmediate_operand\" \"rm,r\")))]\n+  \"\"\n+  \"cvtfd %1,%0\")\n+\n+(define_insn \"truncdfsf2\"\n+  [(set (match_operand:SF 0 \"general_operand\" \"=&r,m\")\n+\t(float_truncate:SF (match_operand:DF 1 \"nonimmediate_operand\" \"rm,r\")))]\n+  \"\"\n+  \"cvtdf %1,%0\")\n+\n+(define_insn \"floatsisf2\"\n+  [(set (match_operand:SF 0 \"general_operand\" \"=&r,m\")\n+\t(float:SF (match_operand:SI 1 \"nonimmediate_operand\" \"rm,r\")))]\n+  \"\"\n+  \"cvtwf %1,%0\")\n+\n+(define_insn \"floatsidf2\"\n+  [(set (match_operand:DF 0 \"general_operand\" \"=&r,m\")\n+\t(float:DF (match_operand:SI 1 \"nonimmediate_operand\" \"rm,r\")))]\n+  \"\"\n+  \"cvtwd %1,%0\")\n+\n+(define_insn \"fix_truncsfsi2\"\n+  [(set (match_operand:SI 0 \"general_operand\" \"=&r,m\")\n+\t(fix:SI (fix:SF (match_operand:SF 1 \"nonimmediate_operand\" \"rm,r\"))))]\n+  \"\"\n+  \"cvtfw %1,%0\")\n+\n+(define_insn \"fix_truncdfsi2\"\n+  [(set (match_operand:SI 0 \"general_operand\" \"=&r,m\")\n+\t(fix:SI (fix:DF (match_operand:DF 1 \"nonimmediate_operand\" \"rm,r\"))))]\n+  \"\"\n+  \"cvtdw %1,%0\")\n+\f\n+;______________________________________________________________________\n+;\n+;\tFlow Control Patterns.\n+;______________________________________________________________________\n+\n+;; Prefer \"br\" to \"jump\" for unconditional jumps, since it's faster.\n+;; (The assembler can manage with out-of-range branches.)\n+\n+(define_insn \"jump\"\n+  [(set (pc)\n+\t(label_ref (match_operand 0 \"\" \"\")))]\n+  \"\"\n+  \"br %l0\")\n+\n+(define_insn \"\"\n+  [(set (pc)\n+\t(if_then_else (match_operator 0 \"relop\" [(cc0) (const_int 0)])\n+\t\t      (label_ref (match_operand 1 \"\" \"\"))\n+\t\t      (pc)))]\n+  \"\"\n+  \"*\n+{\n+  extern int optimize;\n+  if (optimize)\n+    switch (GET_CODE (operands[0]))\n+      {\n+      case EQ: case NE:\n+\tbreak;\n+      case LT: case LE: case GE: case GT:\n+\tif (cc_prev_status.mdep == CC_VALID_FOR_UNSIGNED)\n+\t  return 0;\n+\tbreak;\n+      case LTU: case LEU: case GEU: case GTU:\n+\tif (cc_prev_status.mdep != CC_VALID_FOR_UNSIGNED)\n+\t  return 0;\n+\tbreak;\n+      }\n+\n+  return \\\"b%N0 %l1\\\";\n+}\")\n+\n+(define_insn \"\"\n+  [(set (pc)\n+\t(if_then_else (match_operator 0 \"relop\" [(cc0) (const_int 0)])\n+\t\t      (pc)\n+\t\t      (label_ref (match_operand 1 \"\" \"\"))))]\n+  \"\"\n+  \"*\n+{\n+  extern int optimize;\n+  if (optimize)\n+    switch (GET_CODE (operands[0]))\n+      {\n+      case EQ: case NE:\n+\tbreak;\n+      case LT: case LE: case GE: case GT:\n+\tif (cc_prev_status.mdep == CC_VALID_FOR_UNSIGNED)\n+\t  return 0;\n+\tbreak;\n+      case LTU: case LEU: case GEU: case GTU:\n+\tif (cc_prev_status.mdep != CC_VALID_FOR_UNSIGNED)\n+\t  return 0;\n+\tbreak;\n+      }\n+\n+  return \\\"b%C0 %l1\\\";\n+}\")\n+\n+(define_insn \"call\"\n+  [(call (match_operand:QI 0 \"memory_operand\" \"m\")\n+\t (match_operand:SI 1 \"immediate_operand\" \"n\"))]\n+  \"\"\n+  \"call %0\")\n+\n+(define_insn \"call_value\"\n+  [(set (match_operand 0 \"\" \"=r\")\n+\t(call (match_operand:QI 1 \"memory_operand\" \"m\")\n+\t      (match_operand:SI 2 \"immediate_operand\" \"n\")))]\n+  ;; Operand 2 not really used on Pyramid architecture.\n+  \"\"\n+  \"call %1\")\n+\n+(define_insn \"return\"\n+  [(return)]\n+  \"\"\n+  \"*\n+{\n+  if (get_frame_size () + current_function_pretend_args_size\n+      + current_function_args_size != 0\n+      || current_function_calls_alloca)\n+    {\n+      int dealloc_size = current_function_pretend_args_size;\n+      if (current_function_pops_args)\n+        dealloc_size += current_function_args_size;\n+      operands[0] = gen_rtx (CONST_INT, VOIDmode, dealloc_size);\n+      return \\\"retd %0\\\";\n+    }\n+  else\n+    return \\\"ret\\\";\n+}\")\n+\n+(define_insn \"tablejump\"\n+  [(set (pc) (match_operand:SI 0 \"register_operand\" \"r\"))\n+   (use (label_ref (match_operand 1 \"\" \"\")))]\n+  \"\"\n+  \"jump (%0)\")\n+\n+(define_insn \"nop\"\n+  [(const_int 0)]\n+  \"\"\n+  \"movw gr0,gr0  # nop\")\n+\f\n+;______________________________________________________________________\n+;\n+;\tPeep-hole Optimization Patterns.\n+;______________________________________________________________________\n+\n+;; Optimize fullword move followed by a test of the moved value.\n+\n+(define_peephole\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(match_operand:SI 1 \"nonimmediate_operand\" \"rm\"))\n+   (set (cc0) (match_operand:SI 2 \"nonimmediate_operand\" \"rm\"))]\n+  \"rtx_equal_p (operands[2], operands[0])\n+   || rtx_equal_p (operands[2], operands[1])\"\n+  \"*\n+  cc_status.flags |= CC_NO_OVERFLOW;\n+  return \\\"mtstw %1,%0\\\";\n+\")\n+\n+;; Same for HI and QI mode move-test as well.\n+\n+(define_peephole\n+  [(set (match_operand:HI 0 \"register_operand\" \"=r\")\n+\t(match_operand:HI 1 \"nonimmediate_operand\" \"rm\"))\n+   (set (match_operand:SI 2 \"register_operand\" \"=r\")\n+\t(sign_extend:SI (match_operand:HI 3 \"nonimmediate_operand\" \"rm\")))\n+   (set (cc0) (match_dup 2))]\n+  \"dead_or_set_p (insn, operands[2])\n+   && (rtx_equal_p (operands[3], operands[0])\n+       || rtx_equal_p (operands[3], operands[1]))\"\n+  \"*\n+  cc_status.flags |= CC_NO_OVERFLOW;\n+  return \\\"cvthw %1,%0\\\";\n+\")\n+\n+(define_peephole\n+  [(set (match_operand:QI 0 \"register_operand\" \"=r\")\n+\t(match_operand:QI 1 \"nonimmediate_operand\" \"rm\"))\n+   (set (match_operand:SI 2 \"register_operand\" \"=r\")\n+\t(sign_extend:SI (match_operand:QI 3 \"nonimmediate_operand\" \"rm\")))\n+   (set (cc0) (match_dup 2))]\n+  \"dead_or_set_p (insn, operands[2])\n+   && (rtx_equal_p (operands[3], operands[0])\n+       || rtx_equal_p (operands[3], operands[1]))\"\n+  \"*\n+  cc_status.flags |= CC_NO_OVERFLOW;\n+  return \\\"cvtbw %1,%0\\\";\n+\")\n+\n+;; Optimize loops with an incremented/decremented variable.\n+\n+(define_peephole\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(plus:SI (match_dup 0)\n+\t\t (const_int -1)))\n+   (set (cc0)\n+\t(compare (match_operand:SI 1 \"register_operand\" \"r\")\n+\t\t (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))\n+   (set (pc)\n+\t(if_then_else (match_operator:SI 3 \"signed_comparison\"\n+\t\t\t [(cc0) (const_int 0)])\n+\t\t      (label_ref (match_operand 4 \"\" \"\"))\n+\t\t      (pc)))]\n+  \"(GET_CODE (operands[2]) == CONST_INT\n+    ? (unsigned)INTVAL (operands[2]) + 32 >= 64\n+    : 1) && (rtx_equal_p (operands[0], operands[1])\n+\t     || rtx_equal_p (operands[0], operands[2]))\"\n+  \"*\n+  if (rtx_equal_p (operands[0], operands[1]))\n+    {\n+      output_asm_insn (\\\"dcmpw %2,%0\\\", operands);\n+      return \\\"b%N3 %l4\\\";\n+    }\n+  else\n+    {\n+      output_asm_insn (\\\"dcmpw %1,%0\\\", operands);\n+      return \\\"b%R3 %l4\\\";\n+    }\n+\")\n+\n+(define_peephole\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(plus:SI (match_dup 0)\n+\t\t (const_int 1)))\n+   (set (cc0)\n+\t(compare (match_operand:SI 1 \"register_operand\" \"r\")\n+\t\t (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))\n+   (set (pc)\n+\t(if_then_else (match_operator:SI 3 \"signed_comparison\"\n+\t\t\t [(cc0) (const_int 0)])\n+\t\t      (label_ref (match_operand 4 \"\" \"\"))\n+\t\t      (pc)))]\n+  \"(GET_CODE (operands[2]) == CONST_INT\n+    ? (unsigned)INTVAL (operands[2]) + 32 >= 64\n+    : 1) && (rtx_equal_p (operands[0], operands[1])\n+\t     || rtx_equal_p (operands[0], operands[2]))\"\n+  \"*\n+  if (rtx_equal_p (operands[0], operands[1]))\n+    {\n+      output_asm_insn (\\\"icmpw %2,%0\\\", operands);\n+      return \\\"b%N3 %l4\\\";\n+    }\n+  else\n+    {\n+      output_asm_insn (\\\"icmpw %1,%0\\\", operands);\n+      return \\\"b%R3 %l4\\\";\n+    }\n+\")\n+\n+;; Combine two word moves with consecutive operands into one long move.\n+;; Also combines immediate moves, if the high-order destination operand\n+;; is loaded with 0 or -1 and the low-order destination operand is loaded\n+;; with a constant with the same sign.\n+\n+(define_peephole\n+  [(set (match_operand:SI 0 \"general_operand\" \"=g\")\n+\t(match_operand:SI 1 \"general_operand\" \"g\"))\n+   (set (match_operand:SI 2 \"general_operand\" \"=g\")\n+\t(match_operand:SI 3 \"general_operand\" \"g\"))]\n+  \"movdi_possible (operands)\"\n+  \"*\n+  output_asm_insn (\\\"# COMBINE movw %1,%0\\\", operands);\n+  output_asm_insn (\\\"# COMBINE movw %3,%2\\\", operands);\n+  movdi_possible (operands);\n+  if (CONSTANT_P (operands[1]))\n+    return (swap_operands) ? \\\"movl %3,%0\\\" : \\\"movl %1,%2\\\";\n+\n+  return (swap_operands) ? \\\"movl %1,%0\\\" : \\\"movl %3,%2\\\";\n+\")\n+\n+;; Optimize certain tests after memory stores.\n+\n+(define_peephole\n+  [(set (match_operand 0 \"memory_operand\" \"=m\")\n+\t(match_operand 1 \"register_operand\" \"r\"))\n+   (set (match_operand:SI 2 \"register_operand\" \"=r\")\n+\t(sign_extend:SI (match_dup 1)))\n+   (set (cc0)\n+\t(match_dup 2))]\n+  \"dead_or_set_p (insn, operands[2])\"\n+  \"*\n+  cc_status.flags |= CC_NO_OVERFLOW;\n+  if (GET_MODE (operands[0]) == QImode)\n+    return \\\"cvtwb %1,%0\\\";\n+  else\n+    return \\\"cvtwh %1,%0\\\";\n+\")\n+\f\n+;______________________________________________________________________\n+;\n+;\tDImode Patterns.\n+;______________________________________________________________________\n+\n+(define_expand \"extendsidi2\"\n+  [(set (subreg:SI (match_operand:DI 0 \"register_operand\" \"=r\") 1)\n+\t(match_operand:SI 1 \"general_operand\" \"g\"))\n+   (set (subreg:SI (match_dup 0) 0)\n+\t(subreg:SI (match_dup 0) 1))\n+   (set (subreg:SI (match_dup 0) 0)\n+\t(ashiftrt:SI (subreg:SI (match_dup 0) 0)\n+\t\t     (const_int 31)))]\n+  \"\"\n+  \"\")\n+\n+(define_insn \"adddi3\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n+\t(plus:DI (match_operand:DI 1 \"nonmemory_operand\" \"%0\")\n+\t\t (match_operand:DI 2 \"nonmemory_operand\" \"rF\")))]\n+  \"\"\n+  \"*\n+{\n+  rtx xoperands[2];\n+  CC_STATUS_INIT;\n+  xoperands[0] = gen_rtx (REG, SImode, REGNO (operands[0]) + 1);\n+  if (REG_P (operands[2]))\n+    xoperands[1] = gen_rtx (REG, SImode, REGNO (operands[2]) + 1);\n+  else\n+    {\n+      xoperands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t      CONST_DOUBLE_LOW (operands[2]));\n+      operands[2] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t     CONST_DOUBLE_HIGH (operands[2]));\n+    }\n+  output_asm_insn (\\\"addw %1,%0\\\", xoperands);\n+  return \\\"addwc %2,%0\\\";\n+}\")\n+\n+(define_insn \"subdi3\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n+\t(minus:DI (match_operand:DI 1 \"register_operand\" \"0\")\n+\t\t  (match_operand:DI 2 \"nonmemory_operand\" \"rF\")))]\n+  \"\"\n+  \"*\n+{\n+  rtx xoperands[2];\n+  CC_STATUS_INIT;\n+  xoperands[0] = gen_rtx (REG, SImode, REGNO (operands[0]) + 1);\n+  if (REG_P (operands[2]))\n+    xoperands[1] = gen_rtx (REG, SImode, REGNO (operands[2]) + 1);\n+  else\n+    {\n+      xoperands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t      CONST_DOUBLE_LOW (operands[2]));\n+      operands[2] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t     CONST_DOUBLE_HIGH (operands[2]));\n+    }\n+  output_asm_insn (\\\"subw %1,%0\\\", xoperands);\n+  return \\\"subwb %2,%0\\\";\n+}\")\n+\n+(define_insn \"iordi3\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n+\t(ior:DI (match_operand:DI 1 \"nonmemory_operand\" \"%0\")\n+\t\t(match_operand:DI 2 \"nonmemory_operand\" \"rF\")))]\n+  \"\"\n+  \"*\n+{\n+  rtx xoperands[2];\n+  CC_STATUS_INIT;\n+  xoperands[0] = gen_rtx (REG, SImode, REGNO (operands[0]) + 1);\n+  if (REG_P (operands[2]))\n+    xoperands[1] = gen_rtx (REG, SImode, REGNO (operands[2]) + 1);\n+  else\n+    {\n+      xoperands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t      CONST_DOUBLE_LOW (operands[2]));\n+      operands[2] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t     CONST_DOUBLE_HIGH (operands[2]));\n+    }\n+  output_asm_insn (\\\"orw %1,%0\\\", xoperands);\n+  return \\\"orw %2,%0\\\";\n+}\")\n+\n+(define_insn \"anddi3\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n+\t(and:DI (match_operand:DI 1 \"nonmemory_operand\" \"%0\")\n+\t\t(match_operand:DI 2 \"nonmemory_operand\" \"rF\")))]\n+  \"\"\n+  \"*\n+{\n+  rtx xoperands[2];\n+  CC_STATUS_INIT;\n+  xoperands[0] = gen_rtx (REG, SImode, REGNO (operands[0]) + 1);\n+  if (REG_P (operands[2]))\n+    xoperands[1] = gen_rtx (REG, SImode, REGNO (operands[2]) + 1);\n+  else\n+    {\n+      xoperands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t      CONST_DOUBLE_LOW (operands[2]));\n+      operands[2] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t     CONST_DOUBLE_HIGH (operands[2]));\n+    }\n+  output_asm_insn (\\\"andw %1,%0\\\", xoperands);\n+  return \\\"andw %2,%0\\\";\n+}\")\n+\n+(define_insn \"xordi3\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n+\t(xor:DI (match_operand:DI 1 \"nonmemory_operand\" \"%0\")\n+\t\t(match_operand:DI 2 \"nonmemory_operand\" \"rF\")))]\n+  \"\"\n+  \"*\n+{\n+  rtx xoperands[2];\n+  CC_STATUS_INIT;\n+  xoperands[0] = gen_rtx (REG, SImode, REGNO (operands[0]) + 1);\n+  if (REG_P (operands[2]))\n+    xoperands[1] = gen_rtx (REG, SImode, REGNO (operands[2]) + 1);\n+  else\n+    {\n+      xoperands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t      CONST_DOUBLE_LOW (operands[2]));\n+      operands[2] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t     CONST_DOUBLE_HIGH (operands[2]));\n+    }\n+  output_asm_insn (\\\"xorw %1,%0\\\", xoperands);\n+  return \\\"xorw %2,%0\\\";\n+}\")\n+\f\n+;;- Local variables:\n+;;- mode:emacs-lisp\n+;;- comment-start: \";;- \"\n+;;- eval: (set-syntax-table (copy-sequence (syntax-table)))\n+;;- eval: (modify-syntax-entry ?] \")[\")\n+;;- eval: (modify-syntax-entry ?{ \"(}\")\n+;;- eval: (modify-syntax-entry ?} \"){\")\n+;;- End:\n+"}]}