{"sha": "c906efc700dafe7d30e8b35895f43862ddf7dc8e", "node_id": "C_kwDOANBUbNoAKGM5MDZlZmM3MDBkYWZlN2QzMGU4YjM1ODk1ZjQzODYyZGRmN2RjOGU", "commit": {"author": {"name": "Andrew Carlotti", "email": "Andrew.Carlotti@arm.com", "date": "2022-07-21T16:22:14Z"}, "committer": {"name": "Andrew Carlotti", "email": "andrew.carlotti@arm.com", "date": "2022-07-26T09:31:00Z"}, "message": "aarch64: Move vreinterpret definitions into the compiler\n\nThis removes a significant number of intrinsic definitions from the arm_neon.h\nheader file, and reduces the amount of code duplication.  The new macros and\ndata structures are intended to also facilitate moving other intrinsic\ndefinitions out of the header file in future.\n\nThere is a a slight change in the behaviour of the bf16 vreinterpret intrinsics\nwhen compiling without bf16 support.  Expressions like:\n\nb = vreinterpretq_s32_bf16(vreinterpretq_bf16_s64(a))\n\nare now compiled successfully, instead of causing a 'target specific option\nmismatch' during inlining.\n\ngcc/ChangeLog:\n\n\t* config/aarch64/aarch64-builtins.cc\n\t(MODE_d_bf16, MODE_d_f16, MODE_d_f32, MODE_d_f64, MODE_d_s8)\n\t(MODE_d_s16, MODE_d_s32, MODE_d_s64, MODE_d_u8, MODE_d_u16)\n\t(MODE_d_u32, MODE_d_u64, MODE_d_p8, MODE_d_p16, MODE_d_p64)\n\t(MODE_q_bf16, MODE_q_f16, MODE_q_f32, MODE_q_f64, MODE_q_s8)\n\t(MODE_q_s16, MODE_q_s32, MODE_q_s64, MODE_q_u8, MODE_q_u16)\n\t(MODE_q_u32, MODE_q_u64, MODE_q_p8, MODE_q_p16, MODE_q_p64)\n\t(MODE_q_p128): Define macro to map to corresponding mode name.\n\t(QUAL_bf16, QUAL_f16, QUAL_f32, QUAL_f64, QUAL_s8, QUAL_s16)\n\t(QUAL_s32, QUAL_s64, QUAL_u8, QUAL_u16, QUAL_u32, QUAL_u64)\n\t(QUAL_p8, QUAL_p16, QUAL_p64, QUAL_p128): Define macro to map to\n\tcorresponding qualifier name.\n\t(LENGTH_d, LENGTH_q): Define macro to map to \"\" or \"q\" suffix.\n\t(SIMD_INTR_MODE, SIMD_INTR_QUAL, SIMD_INTR_LENGTH_CHAR): Macro\n\tfunctions for the above mappings\n\t(VREINTERPRET_BUILTIN2, VREINTERPRET_BUILTINS1, VREINTERPRET_BUILTINS)\n\t(VREINTERPRETQ_BUILTIN2, VREINTERPRETQ_BUILTINS1)\n\t(VREINTERPRETQ_BUILTINS, VREINTERPRET_BUILTIN)\n\t(AARCH64_SIMD_VREINTERPRET_BUILTINS): New macros to create definitions\n\tfor all vreinterpret intrinsics\n\t(enum aarch64_builtins): Add vreinterpret function codes\n\t(aarch64_init_simd_intrinsics): New\n\t(handle_arm_neon_h): Improved comment.\n\t(aarch64_general_fold_builtin): Fold vreinterpret calls\n\t* config/aarch64/arm_neon.h\n\t(vreinterpret_p8_f16, vreinterpret_p8_f64, vreinterpret_p8_s8)\n\t(vreinterpret_p8_s16, vreinterpret_p8_s32, vreinterpret_p8_s64)\n\t(vreinterpret_p8_f32, vreinterpret_p8_u8, vreinterpret_p8_u16)\n\t(vreinterpret_p8_u32, vreinterpret_p8_u64, vreinterpret_p8_p16)\n\t(vreinterpret_p8_p64, vreinterpretq_p8_f64, vreinterpretq_p8_s8)\n\t(vreinterpretq_p8_s16, vreinterpretq_p8_s32, vreinterpretq_p8_s64)\n\t(vreinterpretq_p8_f16, vreinterpretq_p8_f32, vreinterpretq_p8_u8)\n\t(vreinterpretq_p8_u16, vreinterpretq_p8_u32, vreinterpretq_p8_u64)\n\t(vreinterpretq_p8_p16, vreinterpretq_p8_p64, vreinterpretq_p8_p128)\n\t(vreinterpret_p16_f16, vreinterpret_p16_f64, vreinterpret_p16_s8)\n\t(vreinterpret_p16_s16, vreinterpret_p16_s32, vreinterpret_p16_s64)\n\t(vreinterpret_p16_f32, vreinterpret_p16_u8, vreinterpret_p16_u16)\n\t(vreinterpret_p16_u32, vreinterpret_p16_u64, vreinterpret_p16_p8)\n\t(vreinterpret_p16_p64, vreinterpretq_p16_f64, vreinterpretq_p16_s8)\n\t(vreinterpretq_p16_s16, vreinterpretq_p16_s32, vreinterpretq_p16_s64)\n\t(vreinterpretq_p16_f16, vreinterpretq_p16_f32, vreinterpretq_p16_u8)\n\t(vreinterpretq_p16_u16, vreinterpretq_p16_u32, vreinterpretq_p16_u64)\n\t(vreinterpretq_p16_p8, vreinterpretq_p16_p64, vreinterpretq_p16_p128)\n\t(vreinterpret_p64_f16, vreinterpret_p64_f64, vreinterpret_p64_s8)\n\t(vreinterpret_p64_s16, vreinterpret_p64_s32, vreinterpret_p64_s64)\n\t(vreinterpret_p64_f32, vreinterpret_p64_u8, vreinterpret_p64_u16)\n\t(vreinterpret_p64_u32, vreinterpret_p64_u64, vreinterpret_p64_p8)\n\t(vreinterpret_p64_p16, vreinterpretq_p64_f64, vreinterpretq_p64_s8)\n\t(vreinterpretq_p64_s16, vreinterpretq_p64_s32, vreinterpretq_p64_s64)\n\t(vreinterpretq_p64_f16, vreinterpretq_p64_f32, vreinterpretq_p64_p128)\n\t(vreinterpretq_p64_u8, vreinterpretq_p64_u16, vreinterpretq_p64_p16)\n\t(vreinterpretq_p64_u32, vreinterpretq_p64_u64, vreinterpretq_p64_p8)\n\t(vreinterpretq_p128_p8, vreinterpretq_p128_p16, vreinterpretq_p128_f16)\n\t(vreinterpretq_p128_f32, vreinterpretq_p128_p64, vreinterpretq_p128_s64)\n\t(vreinterpretq_p128_u64, vreinterpretq_p128_s8, vreinterpretq_p128_s16)\n\t(vreinterpretq_p128_s32, vreinterpretq_p128_u8, vreinterpretq_p128_u16)\n\t(vreinterpretq_p128_u32, vreinterpret_f16_f64, vreinterpret_f16_s8)\n\t(vreinterpret_f16_s16, vreinterpret_f16_s32, vreinterpret_f16_s64)\n\t(vreinterpret_f16_f32, vreinterpret_f16_u8, vreinterpret_f16_u16)\n\t(vreinterpret_f16_u32, vreinterpret_f16_u64, vreinterpret_f16_p8)\n\t(vreinterpret_f16_p16, vreinterpret_f16_p64, vreinterpretq_f16_f64)\n\t(vreinterpretq_f16_s8, vreinterpretq_f16_s16, vreinterpretq_f16_s32)\n\t(vreinterpretq_f16_s64, vreinterpretq_f16_f32, vreinterpretq_f16_u8)\n\t(vreinterpretq_f16_u16, vreinterpretq_f16_u32, vreinterpretq_f16_u64)\n\t(vreinterpretq_f16_p8, vreinterpretq_f16_p128, vreinterpretq_f16_p16)\n\t(vreinterpretq_f16_p64, vreinterpret_f32_f16, vreinterpret_f32_f64)\n\t(vreinterpret_f32_s8, vreinterpret_f32_s16, vreinterpret_f32_s32)\n\t(vreinterpret_f32_s64, vreinterpret_f32_u8, vreinterpret_f32_u16)\n\t(vreinterpret_f32_u32, vreinterpret_f32_u64, vreinterpret_f32_p8)\n\t(vreinterpret_f32_p16, vreinterpret_f32_p64, vreinterpretq_f32_f16)\n\t(vreinterpretq_f32_f64, vreinterpretq_f32_s8, vreinterpretq_f32_s16)\n\t(vreinterpretq_f32_s32, vreinterpretq_f32_s64, vreinterpretq_f32_u8)\n\t(vreinterpretq_f32_u16, vreinterpretq_f32_u32, vreinterpretq_f32_u64)\n\t(vreinterpretq_f32_p8, vreinterpretq_f32_p16, vreinterpretq_f32_p64)\n\t(vreinterpretq_f32_p128, vreinterpret_f64_f16, vreinterpret_f64_f32)\n\t(vreinterpret_f64_p8, vreinterpret_f64_p16, vreinterpret_f64_p64)\n\t(vreinterpret_f64_s8, vreinterpret_f64_s16, vreinterpret_f64_s32)\n\t(vreinterpret_f64_s64, vreinterpret_f64_u8, vreinterpret_f64_u16)\n\t(vreinterpret_f64_u32, vreinterpret_f64_u64, vreinterpretq_f64_f16)\n\t(vreinterpretq_f64_f32, vreinterpretq_f64_p8, vreinterpretq_f64_p16)\n\t(vreinterpretq_f64_p64, vreinterpretq_f64_s8, vreinterpretq_f64_s16)\n\t(vreinterpretq_f64_s32, vreinterpretq_f64_s64, vreinterpretq_f64_u8)\n\t(vreinterpretq_f64_u16, vreinterpretq_f64_u32, vreinterpretq_f64_u64)\n\t(vreinterpret_s64_f16, vreinterpret_s64_f64, vreinterpret_s64_s8)\n\t(vreinterpret_s64_s16, vreinterpret_s64_s32, vreinterpret_s64_f32)\n\t(vreinterpret_s64_u8, vreinterpret_s64_u16, vreinterpret_s64_u32)\n\t(vreinterpret_s64_u64, vreinterpret_s64_p8, vreinterpret_s64_p16)\n\t(vreinterpret_s64_p64, vreinterpretq_s64_f64, vreinterpretq_s64_s8)\n\t(vreinterpretq_s64_s16, vreinterpretq_s64_s32, vreinterpretq_s64_f16)\n\t(vreinterpretq_s64_f32, vreinterpretq_s64_u8, vreinterpretq_s64_u16)\n\t(vreinterpretq_s64_u32, vreinterpretq_s64_u64, vreinterpretq_s64_p8)\n\t(vreinterpretq_s64_p16, vreinterpretq_s64_p64, vreinterpretq_s64_p128)\n\t(vreinterpret_u64_f16, vreinterpret_u64_f64, vreinterpret_u64_s8)\n\t(vreinterpret_u64_s16, vreinterpret_u64_s32, vreinterpret_u64_s64)\n\t(vreinterpret_u64_f32, vreinterpret_u64_u8, vreinterpret_u64_u16)\n\t(vreinterpret_u64_u32, vreinterpret_u64_p8, vreinterpret_u64_p16)\n\t(vreinterpret_u64_p64, vreinterpretq_u64_f64, vreinterpretq_u64_s8)\n\t(vreinterpretq_u64_s16, vreinterpretq_u64_s32, vreinterpretq_u64_s64)\n\t(vreinterpretq_u64_f16, vreinterpretq_u64_f32, vreinterpretq_u64_u8)\n\t(vreinterpretq_u64_u16, vreinterpretq_u64_u32, vreinterpretq_u64_p8)\n\t(vreinterpretq_u64_p16, vreinterpretq_u64_p64, vreinterpretq_u64_p128)\n\t(vreinterpret_s8_f16, vreinterpret_s8_f64, vreinterpret_s8_s16)\n\t(vreinterpret_s8_s32, vreinterpret_s8_s64, vreinterpret_s8_f32)\n\t(vreinterpret_s8_u8, vreinterpret_s8_u16, vreinterpret_s8_u32)\n\t(vreinterpret_s8_u64, vreinterpret_s8_p8, vreinterpret_s8_p16)\n\t(vreinterpret_s8_p64, vreinterpretq_s8_f64, vreinterpretq_s8_s16)\n\t(vreinterpretq_s8_s32, vreinterpretq_s8_s64, vreinterpretq_s8_f16)\n\t(vreinterpretq_s8_f32, vreinterpretq_s8_u8, vreinterpretq_s8_u16)\n\t(vreinterpretq_s8_u32, vreinterpretq_s8_u64, vreinterpretq_s8_p8)\n\t(vreinterpretq_s8_p16, vreinterpretq_s8_p64, vreinterpretq_s8_p128)\n\t(vreinterpret_s16_f16, vreinterpret_s16_f64, vreinterpret_s16_s8)\n\t(vreinterpret_s16_s32, vreinterpret_s16_s64, vreinterpret_s16_f32)\n\t(vreinterpret_s16_u8, vreinterpret_s16_u16, vreinterpret_s16_u32)\n\t(vreinterpret_s16_u64, vreinterpret_s16_p8, vreinterpret_s16_p16)\n\t(vreinterpret_s16_p64, vreinterpretq_s16_f64, vreinterpretq_s16_s8)\n\t(vreinterpretq_s16_s32, vreinterpretq_s16_s64, vreinterpretq_s16_f16)\n\t(vreinterpretq_s16_f32, vreinterpretq_s16_u8, vreinterpretq_s16_u16)\n\t(vreinterpretq_s16_u32, vreinterpretq_s16_u64, vreinterpretq_s16_p8)\n\t(vreinterpretq_s16_p16, vreinterpretq_s16_p64, vreinterpretq_s16_p128)\n\t(vreinterpret_s32_f16, vreinterpret_s32_f64, vreinterpret_s32_s8)\n\t(vreinterpret_s32_s16, vreinterpret_s32_s64, vreinterpret_s32_f32)\n\t(vreinterpret_s32_u8, vreinterpret_s32_u16, vreinterpret_s32_u32)\n\t(vreinterpret_s32_u64, vreinterpret_s32_p8, vreinterpret_s32_p16)\n\t(vreinterpret_s32_p64, vreinterpretq_s32_f64, vreinterpretq_s32_s8)\n\t(vreinterpretq_s32_s16, vreinterpretq_s32_s64, vreinterpretq_s32_f16)\n\t(vreinterpretq_s32_f32, vreinterpretq_s32_u8, vreinterpretq_s32_u16)\n\t(vreinterpretq_s32_u32, vreinterpretq_s32_u64, vreinterpretq_s32_p8)\n\t(vreinterpretq_s32_p16, vreinterpretq_s32_p64, vreinterpretq_s32_p128)\n\t(vreinterpret_u8_f16, vreinterpret_u8_f64, vreinterpret_u8_s8)\n\t(vreinterpret_u8_s16, vreinterpret_u8_s32, vreinterpret_u8_s64)\n\t(vreinterpret_u8_f32, vreinterpret_u8_u16, vreinterpret_u8_u32)\n\t(vreinterpret_u8_u64, vreinterpret_u8_p8, vreinterpret_u8_p16)\n\t(vreinterpret_u8_p64, vreinterpretq_u8_f64, vreinterpretq_u8_s8)\n\t(vreinterpretq_u8_s16, vreinterpretq_u8_s32, vreinterpretq_u8_s64)\n\t(vreinterpretq_u8_f16, vreinterpretq_u8_f32, vreinterpretq_u8_u16)\n\t(vreinterpretq_u8_u32, vreinterpretq_u8_u64, vreinterpretq_u8_p8)\n\t(vreinterpretq_u8_p16, vreinterpretq_u8_p64, vreinterpretq_u8_p128)\n\t(vreinterpret_u16_f16, vreinterpret_u16_f64, vreinterpret_u16_s8)\n\t(vreinterpret_u16_s16, vreinterpret_u16_s32, vreinterpret_u16_s64)\n\t(vreinterpret_u16_f32, vreinterpret_u16_u8, vreinterpret_u16_u32)\n\t(vreinterpret_u16_u64, vreinterpret_u16_p8, vreinterpret_u16_p16)\n\t(vreinterpret_u16_p64, vreinterpretq_u16_f64, vreinterpretq_u16_s8)\n\t(vreinterpretq_u16_s16, vreinterpretq_u16_s32, vreinterpretq_u16_s64)\n\t(vreinterpretq_u16_f16, vreinterpretq_u16_f32, vreinterpretq_u16_u8)\n\t(vreinterpretq_u16_u32, vreinterpretq_u16_u64, vreinterpretq_u16_p8)\n\t(vreinterpretq_u16_p16, vreinterpretq_u16_p64, vreinterpretq_u16_p128)\n\t(vreinterpret_u32_f16, vreinterpret_u32_f64, vreinterpret_u32_s8)\n\t(vreinterpret_u32_s16, vreinterpret_u32_s32, vreinterpret_u32_s64)\n\t(vreinterpret_u32_f32, vreinterpret_u32_u8, vreinterpret_u32_u16)\n\t(vreinterpret_u32_u64, vreinterpret_u32_p8, vreinterpret_u32_p16)\n\t(vreinterpret_u32_p64, vreinterpretq_u32_f64, vreinterpretq_u32_s8)\n\t(vreinterpretq_u32_s16, vreinterpretq_u32_s32, vreinterpretq_u32_s64)\n\t(vreinterpretq_u32_f16, vreinterpretq_u32_f32, vreinterpretq_u32_u8)\n\t(vreinterpretq_u32_u16, vreinterpretq_u32_u64, vreinterpretq_u32_p8)\n\t(vreinterpretq_u32_p16, vreinterpretq_u32_p64, vreinterpretq_u32_p128)\n\t(vreinterpretq_f64_p128, vreinterpretq_p128_f64, vreinterpret_bf16_u8)\n\t(vreinterpret_bf16_u16, vreinterpret_bf16_u32, vreinterpret_bf16_u64)\n\t(vreinterpret_bf16_s8, vreinterpret_bf16_s16, vreinterpret_bf16_s32)\n\t(vreinterpret_bf16_s64, vreinterpret_bf16_p8, vreinterpret_bf16_p16)\n\t(vreinterpret_bf16_p64, vreinterpret_bf16_f16, vreinterpret_bf16_f32)\n\t(vreinterpret_bf16_f64, vreinterpretq_bf16_u8, vreinterpretq_bf16_u16)\n\t(vreinterpretq_bf16_u32, vreinterpretq_bf16_u64, vreinterpretq_bf16_s8)\n\t(vreinterpretq_bf16_s16, vreinterpretq_bf16_s32, vreinterpretq_bf16_s64)\n\t(vreinterpretq_bf16_p8, vreinterpretq_bf16_p16, vreinterpretq_bf16_p64)\n\t(vreinterpretq_bf16_p128, vreinterpretq_bf16_f16)\n\t(vreinterpretq_bf16_f32, vreinterpretq_bf16_f64, vreinterpret_s8_bf16)\n\t(vreinterpret_s16_bf16, vreinterpret_s32_bf16, vreinterpret_s64_bf16)\n\t(vreinterpret_u8_bf16, vreinterpret_u16_bf16, vreinterpret_u32_bf16)\n\t(vreinterpret_u64_bf16, vreinterpret_f16_bf16, vreinterpret_f32_bf16)\n\t(vreinterpret_f64_bf16, vreinterpret_p8_bf16, vreinterpret_p16_bf16)\n\t(vreinterpret_p64_bf16, vreinterpretq_s8_bf16, vreinterpretq_s16_bf16)\n\t(vreinterpretq_s32_bf16, vreinterpretq_s64_bf16, vreinterpretq_u8_bf16)\n\t(vreinterpretq_u16_bf16, vreinterpretq_u32_bf16, vreinterpretq_u64_bf16)\n\t(vreinterpretq_f16_bf16, vreinterpretq_f32_bf16, vreinterpretq_f64_bf16)\n\t(vreinterpretq_p8_bf16, vreinterpretq_p16_bf16, vreinterpretq_p64_bf16)\n\t(vreinterpretq_p128_bf16): Delete", "tree": {"sha": "6e6fee4eeddcecf78e5e41d99cba9345d54fa817", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6e6fee4eeddcecf78e5e41d99cba9345d54fa817"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c906efc700dafe7d30e8b35895f43862ddf7dc8e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c906efc700dafe7d30e8b35895f43862ddf7dc8e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c906efc700dafe7d30e8b35895f43862ddf7dc8e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c906efc700dafe7d30e8b35895f43862ddf7dc8e/comments", "author": {"login": "andrewcarlotti", "id": 11681428, "node_id": "MDQ6VXNlcjExNjgxNDI4", "avatar_url": "https://avatars.githubusercontent.com/u/11681428?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewcarlotti", "html_url": "https://github.com/andrewcarlotti", "followers_url": "https://api.github.com/users/andrewcarlotti/followers", "following_url": "https://api.github.com/users/andrewcarlotti/following{/other_user}", "gists_url": "https://api.github.com/users/andrewcarlotti/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewcarlotti/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewcarlotti/subscriptions", "organizations_url": "https://api.github.com/users/andrewcarlotti/orgs", "repos_url": "https://api.github.com/users/andrewcarlotti/repos", "events_url": "https://api.github.com/users/andrewcarlotti/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewcarlotti/received_events", "type": "User", "site_admin": false}, "committer": {"login": "andrewcarlotti", "id": 11681428, "node_id": "MDQ6VXNlcjExNjgxNDI4", "avatar_url": "https://avatars.githubusercontent.com/u/11681428?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewcarlotti", "html_url": "https://github.com/andrewcarlotti", "followers_url": "https://api.github.com/users/andrewcarlotti/followers", "following_url": "https://api.github.com/users/andrewcarlotti/following{/other_user}", "gists_url": "https://api.github.com/users/andrewcarlotti/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewcarlotti/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewcarlotti/subscriptions", "organizations_url": "https://api.github.com/users/andrewcarlotti/orgs", "repos_url": "https://api.github.com/users/andrewcarlotti/repos", "events_url": "https://api.github.com/users/andrewcarlotti/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewcarlotti/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f023cc54e86c6c6dd04298487a9c9000eab9133a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f023cc54e86c6c6dd04298487a9c9000eab9133a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f023cc54e86c6c6dd04298487a9c9000eab9133a"}], "stats": {"total": 3390, "additions": 234, "deletions": 3156}, "files": [{"sha": "f90fda4ca974d669718a42d725d17e8c89fea689", "filename": "gcc/config/aarch64/aarch64-builtins.cc", "status": "modified", "additions": 234, "deletions": 1, "changes": 235, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c906efc700dafe7d30e8b35895f43862ddf7dc8e/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c906efc700dafe7d30e8b35895f43862ddf7dc8e/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.cc?ref=c906efc700dafe7d30e8b35895f43862ddf7dc8e", "patch": "@@ -127,6 +127,63 @@\n #define v4x2df_UP  E_V4x2DFmode\n #define UP(X) X##_UP\n \n+#define MODE_d_bf16 E_V4BFmode\n+#define MODE_d_f16 E_V4HFmode\n+#define MODE_d_f32 E_V2SFmode\n+#define MODE_d_f64 E_V1DFmode\n+#define MODE_d_s8 E_V8QImode\n+#define MODE_d_s16 E_V4HImode\n+#define MODE_d_s32 E_V2SImode\n+#define MODE_d_s64 E_V1DImode\n+#define MODE_d_u8 E_V8QImode\n+#define MODE_d_u16 E_V4HImode\n+#define MODE_d_u32 E_V2SImode\n+#define MODE_d_u64 E_V1DImode\n+#define MODE_d_p8 E_V8QImode\n+#define MODE_d_p16 E_V4HImode\n+#define MODE_d_p64 E_V1DImode\n+#define MODE_q_bf16 E_V8BFmode\n+#define MODE_q_f16 E_V8HFmode\n+#define MODE_q_f32 E_V4SFmode\n+#define MODE_q_f64 E_V2DFmode\n+#define MODE_q_s8 E_V16QImode\n+#define MODE_q_s16 E_V8HImode\n+#define MODE_q_s32 E_V4SImode\n+#define MODE_q_s64 E_V2DImode\n+#define MODE_q_u8 E_V16QImode\n+#define MODE_q_u16 E_V8HImode\n+#define MODE_q_u32 E_V4SImode\n+#define MODE_q_u64 E_V2DImode\n+#define MODE_q_p8 E_V16QImode\n+#define MODE_q_p16 E_V8HImode\n+#define MODE_q_p64 E_V2DImode\n+#define MODE_q_p128 E_TImode\n+\n+#define QUAL_bf16 qualifier_none\n+#define QUAL_f16 qualifier_none\n+#define QUAL_f32 qualifier_none\n+#define QUAL_f64 qualifier_none\n+#define QUAL_s8 qualifier_none\n+#define QUAL_s16 qualifier_none\n+#define QUAL_s32 qualifier_none\n+#define QUAL_s64 qualifier_none\n+#define QUAL_u8 qualifier_unsigned\n+#define QUAL_u16 qualifier_unsigned\n+#define QUAL_u32 qualifier_unsigned\n+#define QUAL_u64 qualifier_unsigned\n+#define QUAL_p8 qualifier_poly\n+#define QUAL_p16 qualifier_poly\n+#define QUAL_p64 qualifier_poly\n+#define QUAL_p128 qualifier_poly\n+\n+#define LENGTH_d \"\"\n+#define LENGTH_q \"q\"\n+\n+#define SIMD_INTR_MODE(suffix, length) MODE_##length##_##suffix\n+#define SIMD_INTR_QUAL(suffix) QUAL_##suffix\n+#define SIMD_INTR_LENGTH_CHAR(length) LENGTH_##length\n+\n+\n #define SIMD_MAX_BUILTIN_ARGS 5\n \n enum aarch64_type_qualifiers\n@@ -522,6 +579,99 @@ static aarch64_simd_builtin_datum aarch64_simd_builtin_data[] = {\n   FCMLA_LANEQ_BUILTIN (180, v4hf, fcmla_laneq, V4HF, true) \\\n   FCMLA_LANEQ_BUILTIN (270, v4hf, fcmla_laneq, V4HF, true) \\\n \n+\n+/* vreinterpret intrinsics are defined for any pair of element types.\n+   {     _bf16           }   {     _bf16           }\n+   {      _f16 _f32 _f64 }   {      _f16 _f32 _f64 }\n+   { _s8  _s16 _s32 _s64 } x { _s8  _s16 _s32 _s64 }\n+   { _u8  _u16 _u32 _u64 }   { _u8  _u16 _u32 _u64 }\n+   { _p8  _p16      _p64 }   { _p8  _p16      _p64 }.  */\n+#define VREINTERPRET_BUILTIN2(A, B) \\\n+  VREINTERPRET_BUILTIN (A, B, d)\n+\n+#define VREINTERPRET_BUILTINS1(A) \\\n+  VREINTERPRET_BUILTIN2 (A, bf16) \\\n+  VREINTERPRET_BUILTIN2 (A, f16) \\\n+  VREINTERPRET_BUILTIN2 (A, f32) \\\n+  VREINTERPRET_BUILTIN2 (A, f64) \\\n+  VREINTERPRET_BUILTIN2 (A, s8) \\\n+  VREINTERPRET_BUILTIN2 (A, s16) \\\n+  VREINTERPRET_BUILTIN2 (A, s32) \\\n+  VREINTERPRET_BUILTIN2 (A, s64) \\\n+  VREINTERPRET_BUILTIN2 (A, u8) \\\n+  VREINTERPRET_BUILTIN2 (A, u16) \\\n+  VREINTERPRET_BUILTIN2 (A, u32) \\\n+  VREINTERPRET_BUILTIN2 (A, u64) \\\n+  VREINTERPRET_BUILTIN2 (A, p8) \\\n+  VREINTERPRET_BUILTIN2 (A, p16) \\\n+  VREINTERPRET_BUILTIN2 (A, p64)\n+\n+#define VREINTERPRET_BUILTINS \\\n+  VREINTERPRET_BUILTINS1 (bf16) \\\n+  VREINTERPRET_BUILTINS1 (f16) \\\n+  VREINTERPRET_BUILTINS1 (f32) \\\n+  VREINTERPRET_BUILTINS1 (f64) \\\n+  VREINTERPRET_BUILTINS1 (s8) \\\n+  VREINTERPRET_BUILTINS1 (s16) \\\n+  VREINTERPRET_BUILTINS1 (s32) \\\n+  VREINTERPRET_BUILTINS1 (s64) \\\n+  VREINTERPRET_BUILTINS1 (u8) \\\n+  VREINTERPRET_BUILTINS1 (u16) \\\n+  VREINTERPRET_BUILTINS1 (u32) \\\n+  VREINTERPRET_BUILTINS1 (u64) \\\n+  VREINTERPRET_BUILTINS1 (p8) \\\n+  VREINTERPRET_BUILTINS1 (p16) \\\n+  VREINTERPRET_BUILTINS1 (p64)\n+\n+/* vreinterpretq intrinsics are additionally defined for p128.\n+   {     _bf16                 }   {     _bf16                 }\n+   {      _f16 _f32 _f64       }   {      _f16 _f32 _f64       }\n+   { _s8  _s16 _s32 _s64       } x { _s8  _s16 _s32 _s64       }\n+   { _u8  _u16 _u32 _u64       }   { _u8  _u16 _u32 _u64       }\n+   { _p8  _p16      _p64 _p128 }   { _p8  _p16      _p64 _p128 }.  */\n+#define VREINTERPRETQ_BUILTIN2(A, B) \\\n+  VREINTERPRET_BUILTIN (A, B, q)\n+\n+#define VREINTERPRETQ_BUILTINS1(A) \\\n+  VREINTERPRETQ_BUILTIN2 (A, bf16) \\\n+  VREINTERPRETQ_BUILTIN2 (A, f16) \\\n+  VREINTERPRETQ_BUILTIN2 (A, f32) \\\n+  VREINTERPRETQ_BUILTIN2 (A, f64) \\\n+  VREINTERPRETQ_BUILTIN2 (A, s8) \\\n+  VREINTERPRETQ_BUILTIN2 (A, s16) \\\n+  VREINTERPRETQ_BUILTIN2 (A, s32) \\\n+  VREINTERPRETQ_BUILTIN2 (A, s64) \\\n+  VREINTERPRETQ_BUILTIN2 (A, u8) \\\n+  VREINTERPRETQ_BUILTIN2 (A, u16) \\\n+  VREINTERPRETQ_BUILTIN2 (A, u32) \\\n+  VREINTERPRETQ_BUILTIN2 (A, u64) \\\n+  VREINTERPRETQ_BUILTIN2 (A, p8) \\\n+  VREINTERPRETQ_BUILTIN2 (A, p16) \\\n+  VREINTERPRETQ_BUILTIN2 (A, p64) \\\n+  VREINTERPRETQ_BUILTIN2 (A, p128)\n+\n+#define VREINTERPRETQ_BUILTINS \\\n+  VREINTERPRETQ_BUILTINS1 (bf16) \\\n+  VREINTERPRETQ_BUILTINS1 (f16) \\\n+  VREINTERPRETQ_BUILTINS1 (f32) \\\n+  VREINTERPRETQ_BUILTINS1 (f64) \\\n+  VREINTERPRETQ_BUILTINS1 (s8) \\\n+  VREINTERPRETQ_BUILTINS1 (s16) \\\n+  VREINTERPRETQ_BUILTINS1 (s32) \\\n+  VREINTERPRETQ_BUILTINS1 (s64) \\\n+  VREINTERPRETQ_BUILTINS1 (u8) \\\n+  VREINTERPRETQ_BUILTINS1 (u16) \\\n+  VREINTERPRETQ_BUILTINS1 (u32) \\\n+  VREINTERPRETQ_BUILTINS1 (u64) \\\n+  VREINTERPRETQ_BUILTINS1 (p8) \\\n+  VREINTERPRETQ_BUILTINS1 (p16) \\\n+  VREINTERPRETQ_BUILTINS1 (p64) \\\n+  VREINTERPRETQ_BUILTINS1 (p128)\n+\n+#define AARCH64_SIMD_VREINTERPRET_BUILTINS \\\n+  VREINTERPRET_BUILTINS \\\n+  VREINTERPRETQ_BUILTINS\n+\n typedef struct\n {\n   const char *name;\n@@ -540,12 +690,27 @@ typedef struct\n   bool lane;\n } aarch64_fcmla_laneq_builtin_datum;\n \n+/* Hold information about how to declare SIMD intrinsics.  */\n+typedef struct\n+{\n+  const char *name;\n+  unsigned int fcode;\n+  unsigned int op_count;\n+  machine_mode op_modes[SIMD_MAX_BUILTIN_ARGS];\n+  enum aarch64_type_qualifiers qualifiers[SIMD_MAX_BUILTIN_ARGS];\n+  unsigned int flags;\n+  bool skip;\n+} aarch64_simd_intrinsic_datum;\n+\n #define CRC32_BUILTIN(N, M) \\\n   AARCH64_BUILTIN_##N,\n \n #define FCMLA_LANEQ_BUILTIN(I, N, X, M, T) \\\n   AARCH64_SIMD_BUILTIN_FCMLA_LANEQ##I##_##M,\n \n+#define VREINTERPRET_BUILTIN(A, B, L) \\\n+  AARCH64_SIMD_BUILTIN_VREINTERPRET##L##_##A##_##B,\n+\n #undef VAR1\n #define VAR1(T, N, MAP, FLAG, A) \\\n   AARCH64_SIMD_BUILTIN_##T##_##N##A,\n@@ -579,6 +744,8 @@ enum aarch64_builtins\n   AARCH64_CRC32_BUILTIN_BASE,\n   AARCH64_CRC32_BUILTINS\n   AARCH64_CRC32_BUILTIN_MAX,\n+  /* SIMD intrinsic builtins.  */\n+  AARCH64_SIMD_VREINTERPRET_BUILTINS\n   /* ARMv8.3-A Pointer Authentication Builtins.  */\n   AARCH64_PAUTH_BUILTIN_AUTIA1716,\n   AARCH64_PAUTH_BUILTIN_PACIA1716,\n@@ -641,6 +808,23 @@ static aarch64_fcmla_laneq_builtin_datum aarch64_fcmla_lane_builtin_data[] = {\n   AARCH64_SIMD_FCMLA_LANEQ_BUILTINS\n };\n \n+#undef VREINTERPRET_BUILTIN\n+#define VREINTERPRET_BUILTIN(A, B, L) \\\n+  {\"vreinterpret\" SIMD_INTR_LENGTH_CHAR(L) \"_\" #A \"_\" #B, \\\n+   AARCH64_SIMD_BUILTIN_VREINTERPRET##L##_##A##_##B, \\\n+   2, \\\n+   { SIMD_INTR_MODE(A, L), SIMD_INTR_MODE(B, L) }, \\\n+   { SIMD_INTR_QUAL(A), SIMD_INTR_QUAL(B) }, \\\n+   FLAG_AUTO_FP, \\\n+   SIMD_INTR_MODE(A, L) == SIMD_INTR_MODE(B, L) \\\n+     && SIMD_INTR_QUAL(A) == SIMD_INTR_QUAL(B) \\\n+  },\n+\n+static const aarch64_simd_intrinsic_datum aarch64_simd_intrinsic_data[] = {\n+  AARCH64_SIMD_VREINTERPRET_BUILTINS\n+};\n+\n+\n #undef CRC32_BUILTIN\n \n static GTY(()) tree aarch64_builtin_decls[AARCH64_BUILTIN_MAX];\n@@ -1146,6 +1330,44 @@ aarch64_init_fcmla_laneq_builtins (void)\n     }\n }\n \n+void\n+aarch64_init_simd_intrinsics (void)\n+{\n+  unsigned int i = 0;\n+\n+  for (i = 0; i < ARRAY_SIZE (aarch64_simd_intrinsic_data); ++i)\n+    {\n+      auto d = &aarch64_simd_intrinsic_data[i];\n+\n+      if (d->skip)\n+\tcontinue;\n+\n+      tree return_type = void_type_node;\n+      tree args = void_list_node;\n+\n+      for (int op_num = d->op_count - 1; op_num >= 0; op_num--)\n+\t{\n+\t  machine_mode op_mode = d->op_modes[op_num];\n+\t  enum aarch64_type_qualifiers qualifiers = d->qualifiers[op_num];\n+\n+\t  tree eltype = aarch64_simd_builtin_type (op_mode, qualifiers);\n+\n+\t  if (op_num == 0)\n+\t    return_type = eltype;\n+\t  else\n+\t    args = tree_cons (NULL_TREE, eltype, args);\n+\t}\n+\n+      tree ftype = build_function_type (return_type, args);\n+      tree attrs = aarch64_get_attributes (FLAG_AUTO_FP, d->op_modes[0]);\n+      unsigned int code\n+\t      = (d->fcode << AARCH64_BUILTIN_SHIFT | AARCH64_BUILTIN_GENERAL);\n+      tree fndecl = simulate_builtin_function_decl (input_location, d->name,\n+\t\t\t\t\t\t    ftype, code, NULL, attrs);\n+      aarch64_builtin_decls[d->fcode] = fndecl;\n+    }\n+}\n+\n void\n aarch64_init_simd_builtin_functions (bool called_from_pragma)\n {\n@@ -1345,7 +1567,10 @@ aarch64_simd_switcher::~aarch64_simd_switcher ()\n   aarch64_isa_flags = m_old_isa_flags;\n }\n \n-/* Implement #pragma GCC aarch64 \"arm_neon.h\".  */\n+/* Implement #pragma GCC aarch64 \"arm_neon.h\".\n+\n+   The types and functions defined here need to be available internally\n+   during LTO as well.  */\n void\n handle_arm_neon_h (void)\n {\n@@ -1358,6 +1583,7 @@ handle_arm_neon_h (void)\n \tregister_tuple_type (count, i);\n \n   aarch64_init_simd_builtin_functions (true);\n+  aarch64_init_simd_intrinsics ();\n }\n \n void\n@@ -2657,6 +2883,11 @@ aarch64_fold_builtin_lane_check (tree arg0, tree arg1, tree arg2)\n #define VAR1(T, N, MAP, FLAG, A) \\\n   case AARCH64_SIMD_BUILTIN_##T##_##N##A:\n \n+#undef VREINTERPRET_BUILTIN\n+#define VREINTERPRET_BUILTIN(A, B, L) \\\n+  case AARCH64_SIMD_BUILTIN_VREINTERPRET##L##_##A##_##B:\n+\n+\n /* Try to fold a call to the built-in function with subcode FCODE.  The\n    function is passed the N_ARGS arguments in ARGS and it returns a value\n    of type TYPE.  Return the new expression on success and NULL_TREE on\n@@ -2673,6 +2904,8 @@ aarch64_general_fold_builtin (unsigned int fcode, tree type,\n       VAR1 (UNOP, floatv4si, 2, ALL, v4sf)\n       VAR1 (UNOP, floatv2di, 2, ALL, v2df)\n \treturn fold_build1 (FLOAT_EXPR, type, args[0]);\n+      AARCH64_SIMD_VREINTERPRET_BUILTINS\n+\treturn fold_build1 (VIEW_CONVERT_EXPR, type, args[0]);\n       case AARCH64_SIMD_BUILTIN_LANE_CHECK:\n \tgcc_assert (n_args == 3);\n \tif (aarch64_fold_builtin_lane_check (args[0], args[1], args[2]))"}, {"sha": "cf6af728ca99dae1cb6ab647466cfec32f7e913e", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 0, "deletions": 3155, "changes": 3155, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c906efc700dafe7d30e8b35895f43862ddf7dc8e/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c906efc700dafe7d30e8b35895f43862ddf7dc8e/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=c906efc700dafe7d30e8b35895f43862ddf7dc8e"}]}