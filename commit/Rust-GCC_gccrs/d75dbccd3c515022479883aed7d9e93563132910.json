{"sha": "d75dbccd3c515022479883aed7d9e93563132910", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDc1ZGJjY2QzYzUxNTAyMjQ3OTg4M2FlZDdkOWU5MzU2MzEzMjkxMA==", "commit": {"author": {"name": "Daniel Berlin", "email": "dberlin@dberlin.org", "date": "2006-11-14T18:12:20Z"}, "committer": {"name": "Daniel Berlin", "email": "dberlin@gcc.gnu.org", "date": "2006-11-14T18:12:20Z"}, "message": "re PR tree-optimization/27755 (PRE confused by control flow)\n\n2006-11-14  Daniel Berlin  <dberlin@dberlin.org>\n\n\tFix PR tree-optimization/27755\n\n\t* tree-ssa-pre.c: Update comments.\n\t(bb_bitmap_sets): Add pa_in and  deferred member.\n\t(BB_DEFERRED): New macro.\n\t(maximal_set): New variable.\n\t(pre_stats): Add pa_insert member.\n\t(bitmap_set_and): Short circuit orig == dest.\n\t(bitmap_set_subtract_values): New function.\n\t(bitmap_set_contains_expr): Ditto.\n\t(translate_vuses_through_block): Add phiblock argument.\n\t(dependent_clean): New function.\n\t(compute_antic_aux): Update for maximal_set changes.\n\t(compute_partial_antic_aux): New function.\n\t(compute_antic): Handle partial anticipation.\n\t(do_partial_partial_insertion): New function.\n\t(insert_aux): Handle partial anticipation.\n\t(add_to_sets): Add to maximal set.\n\t(compute_avail): Ditto.\n\t(init_pre): Initialize maximal_set.\n\t(execute_pre): Do partial anticipation if -O3+.\n\nFrom-SVN: r118821", "tree": {"sha": "46f59b7d72bc60da785b7e0052893c10545a6d38", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/46f59b7d72bc60da785b7e0052893c10545a6d38"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d75dbccd3c515022479883aed7d9e93563132910", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d75dbccd3c515022479883aed7d9e93563132910", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d75dbccd3c515022479883aed7d9e93563132910", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d75dbccd3c515022479883aed7d9e93563132910/comments", "author": {"login": "dberlin", "id": 324715, "node_id": "MDQ6VXNlcjMyNDcxNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/324715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dberlin", "html_url": "https://github.com/dberlin", "followers_url": "https://api.github.com/users/dberlin/followers", "following_url": "https://api.github.com/users/dberlin/following{/other_user}", "gists_url": "https://api.github.com/users/dberlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/dberlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dberlin/subscriptions", "organizations_url": "https://api.github.com/users/dberlin/orgs", "repos_url": "https://api.github.com/users/dberlin/repos", "events_url": "https://api.github.com/users/dberlin/events{/privacy}", "received_events_url": "https://api.github.com/users/dberlin/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "17339e8836ffdc807caf2f81c90c72cb171f2a66", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/17339e8836ffdc807caf2f81c90c72cb171f2a66", "html_url": "https://github.com/Rust-GCC/gccrs/commit/17339e8836ffdc807caf2f81c90c72cb171f2a66"}], "stats": {"total": 582, "additions": 509, "deletions": 73}, "files": [{"sha": "a9e106a63072534972a043e09d94dcedae05ca23", "filename": "gcc/ChangeLog", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d75dbccd3c515022479883aed7d9e93563132910/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d75dbccd3c515022479883aed7d9e93563132910/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d75dbccd3c515022479883aed7d9e93563132910", "patch": "@@ -1,3 +1,27 @@\n+2006-11-14  Daniel Berlin  <dberlin@dberlin.org>\n+\n+\tFix PR tree-optimization/27755\n+\n+\t* tree-ssa-pre.c: Update comments.\n+\t(bb_bitmap_sets): Add pa_in and  deferred member.\n+\t(BB_DEFERRED): New macro.\n+\t(maximal_set): New variable.\n+\t(pre_stats): Add pa_insert member.\n+\t(bitmap_set_and): Short circuit orig == dest.\n+\t(bitmap_set_subtract_values): New function.\n+\t(bitmap_set_contains_expr): Ditto.\n+\t(translate_vuses_through_block): Add phiblock argument.\n+\t(dependent_clean): New function.\n+\t(compute_antic_aux): Update for maximal_set changes.\n+\t(compute_partial_antic_aux): New function.\n+\t(compute_antic): Handle partial anticipation.\n+\t(do_partial_partial_insertion): New function.\n+\t(insert_aux): Handle partial anticipation.\n+\t(add_to_sets): Add to maximal set.\n+\t(compute_avail): Ditto.\n+\t(init_pre): Initialize maximal_set.\n+\t(execute_pre): Do partial anticipation if -O3+.\n+\n 2006-11-14  Paolo Bonzini  <bonzini@gnu.org>\n \n \tPR rtl-optimization/29798"}, {"sha": "b087dc1b45c20398d3544d59caaad103a513124c", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-pre-16.c", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d75dbccd3c515022479883aed7d9e93563132910/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-16.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d75dbccd3c515022479883aed7d9e93563132910/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-16.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-pre-16.c?ref=d75dbccd3c515022479883aed7d9e93563132910", "patch": "@@ -0,0 +1,15 @@\n+/* { dg-do compile } */ \n+/* { dg-options \"-O2 -fdump-tree-pre-stats -std=c99\" } */\n+int foo(int k, int *x)\n+{\n+  int j=0;\n+  int res = 0;\n+  /* We should pull res = *x all the way out of the do-while */\n+  do {\n+    for (int n=0;n<3;++n);\n+    res = *x;\n+  }  while (++j<k);\n+  return res;\n+}\n+/* { dg-final { scan-tree-dump-times \"Eliminated: 1\" 1 \"pre\"} } */\n+/* { dg-final { cleanup-tree-dump \"pre\" } } */"}, {"sha": "d83d81eb11a2863d8dedf20b0892d5a262fc1c91", "filename": "gcc/tree-ssa-pre.c", "status": "modified", "additions": 470, "deletions": 73, "changes": 543, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d75dbccd3c515022479883aed7d9e93563132910/gcc%2Ftree-ssa-pre.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d75dbccd3c515022479883aed7d9e93563132910/gcc%2Ftree-ssa-pre.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-pre.c?ref=d75dbccd3c515022479883aed7d9e93563132910", "patch": "@@ -80,7 +80,7 @@ Boston, MA 02110-1301, USA.  */\n \n    Next, we generate the ANTIC sets.  These sets represent the\n    anticipatable expressions.  ANTIC is a backwards dataflow\n-   problem.An expression is anticipatable in a given block if it could\n+   problem.  An expression is anticipatable in a given block if it could\n    be generated in that block.  This means that if we had to perform\n    an insertion in that block, of the value of that expression, we\n    could.  Calculating the ANTIC sets requires phi translation of\n@@ -104,7 +104,13 @@ Boston, MA 02110-1301, USA.  */\n \n    In order to make it fully redundant, we insert the expression into\n    the predecessors where it is not available, but is ANTIC.\n-   insert/insert_aux performs this insertion.\n+\n+   For the partial anticipation case, we only perform insertion if it\n+   is partially anticipated in some block, and fully available in all\n+   of the predecessors.\n+\n+   insert/insert_aux/do_regular_insertion/do_partial_partial_insertion\n+   performs these steps.\n \n    Fourth, we eliminate fully redundant expressions.\n    This is a simple statement walk that replaces redundant\n@@ -289,6 +295,10 @@ typedef struct bb_bitmap_sets\n      in a given basic block.  */\n   bitmap_set_t antic_in;\n \n+  /* The PA_IN set, which represents which values are\n+     partially anticipatable in a given basic block.  */\n+  bitmap_set_t pa_in;\n+\n   /* The NEW_SETS set, which is used during insertion to augment the\n      AVAIL_OUT set of blocks with the new insertions performed during\n      the current iteration.  */\n@@ -306,22 +316,32 @@ typedef struct bb_bitmap_sets\n      the block, regardless of RVUSE_KILL.  */\n   bitmap_set_t antic_safe_loads;\n \n-  /* True if we have visited this block during antic calculation.  */\n+  /* True if we have visited this block during ANTIC calculation.  */\n   unsigned int visited:1;\n-} *bb_bitmap_sets_t;\n-\n-#define EXP_GEN(BB)\t((bb_bitmap_sets_t) ((BB)->aux))->exp_gen\n-#define PHI_GEN(BB)\t((bb_bitmap_sets_t) ((BB)->aux))->phi_gen\n-#define TMP_GEN(BB)\t((bb_bitmap_sets_t) ((BB)->aux))->tmp_gen\n-#define AVAIL_OUT(BB)\t((bb_bitmap_sets_t) ((BB)->aux))->avail_out\n-#define ANTIC_IN(BB)\t((bb_bitmap_sets_t) ((BB)->aux))->antic_in\n-#define RVUSE_IN(BB)    ((bb_bitmap_sets_t) ((BB)->aux))->rvuse_in\n-#define RVUSE_GEN(BB)   ((bb_bitmap_sets_t) ((BB)->aux))->rvuse_gen\n-#define RVUSE_KILL(BB)   ((bb_bitmap_sets_t) ((BB)->aux))->rvuse_kill\n-#define RVUSE_OUT(BB)    ((bb_bitmap_sets_t) ((BB)->aux))->rvuse_out\n-#define NEW_SETS(BB)\t((bb_bitmap_sets_t) ((BB)->aux))->new_sets\n-#define ANTIC_SAFE_LOADS(BB) ((bb_bitmap_sets_t) ((BB)->aux))->antic_safe_loads\n-#define BB_VISITED(BB) ((bb_bitmap_sets_t) ((BB)->aux))->visited\n+\n+  /* True we have deferred processing this block during ANTIC\n+     calculation until its successor is processed.  */\n+  unsigned int deferred : 1;\n+} *bb_value_sets_t;\n+\n+#define EXP_GEN(BB)\t((bb_value_sets_t) ((BB)->aux))->exp_gen\n+#define PHI_GEN(BB)\t((bb_value_sets_t) ((BB)->aux))->phi_gen\n+#define TMP_GEN(BB)\t((bb_value_sets_t) ((BB)->aux))->tmp_gen\n+#define AVAIL_OUT(BB)\t((bb_value_sets_t) ((BB)->aux))->avail_out\n+#define ANTIC_IN(BB)\t((bb_value_sets_t) ((BB)->aux))->antic_in\n+#define PA_IN(BB)\t((bb_value_sets_t) ((BB)->aux))->pa_in\n+#define RVUSE_IN(BB)    ((bb_value_sets_t) ((BB)->aux))->rvuse_in\n+#define RVUSE_GEN(BB)   ((bb_value_sets_t) ((BB)->aux))->rvuse_gen\n+#define RVUSE_KILL(BB)   ((bb_value_sets_t) ((BB)->aux))->rvuse_kill\n+#define RVUSE_OUT(BB)    ((bb_value_sets_t) ((BB)->aux))->rvuse_out\n+#define NEW_SETS(BB)\t((bb_value_sets_t) ((BB)->aux))->new_sets\n+#define ANTIC_SAFE_LOADS(BB) ((bb_value_sets_t) ((BB)->aux))->antic_safe_loads\n+#define BB_VISITED(BB) ((bb_value_sets_t) ((BB)->aux))->visited\n+#define BB_DEFERRED(BB) ((bb_value_sets_t) ((BB)->aux))->deferred\n+\n+/* Maximal set of values, used to initialize the ANTIC problem, which\n+   is an intersection problem.  */\n+static bitmap_set_t maximal_set;\n \n /* Basic block list in postorder.  */\n static int *postorder;\n@@ -336,6 +356,9 @@ static struct\n   /* The number of new expressions/temporaries generated by PRE.  */\n   int insertions;\n \n+  /* The number of inserts found due to partial anticipation  */\n+  int pa_insert;\n+\n   /* The number of new PHI nodes added by PRE.  */\n   int phis;\n \n@@ -344,6 +367,7 @@ static struct\n \n } pre_stats;\n \n+static bool do_partial_partial;\n static tree bitmap_find_leader (bitmap_set_t, tree);\n static void bitmap_value_insert_into_set (bitmap_set_t, tree);\n static void bitmap_value_replace_in_set (bitmap_set_t, tree);\n@@ -632,19 +656,23 @@ bitmap_set_and (bitmap_set_t dest, bitmap_set_t orig)\n {\n   bitmap_iterator bi;\n   unsigned int i;\n-  bitmap temp = BITMAP_ALLOC (&grand_bitmap_obstack);\n \n-  bitmap_and_into (dest->values, orig->values);\n-\n-  bitmap_copy (temp, dest->expressions);\n-  EXECUTE_IF_SET_IN_BITMAP (temp, 0, i, bi)\n+  if (dest != orig)\n     {\n-      tree expr = expression_for_id (i);\n-      tree val = get_value_handle (expr);\n-      if (!bitmap_bit_p (dest->values, VALUE_HANDLE_ID (val)))\n-\tbitmap_clear_bit (dest->expressions, i);\n+      bitmap temp = BITMAP_ALLOC (&grand_bitmap_obstack);\n+      \n+      bitmap_and_into (dest->values, orig->values);\n+      \n+      bitmap_copy (temp, dest->expressions);\n+      EXECUTE_IF_SET_IN_BITMAP (temp, 0, i, bi)\n+\t{\n+\t  tree expr = expression_for_id (i);\n+\t  tree val = get_value_handle (expr);\n+\t  if (!bitmap_bit_p (dest->values, VALUE_HANDLE_ID (val)))\n+\t    bitmap_clear_bit (dest->expressions, i);\n+\t}\n+      BITMAP_FREE (temp);\n     }\n-  BITMAP_FREE (temp);\n }\n \n /* Subtract all values and expressions contained in ORIG from DEST.  */\n@@ -669,6 +697,26 @@ bitmap_set_subtract (bitmap_set_t dest, bitmap_set_t orig)\n   return result;\n }\n \n+/* Subtract all the values in bitmap set B from bitmap set A.  */\n+\n+static void\n+bitmap_set_subtract_values (bitmap_set_t a, bitmap_set_t b)\n+{\n+  unsigned int i;\n+  bitmap_iterator bi;\n+  bitmap temp = BITMAP_ALLOC (&grand_bitmap_obstack);\n+\n+  bitmap_copy (temp, a->expressions);\n+  EXECUTE_IF_SET_IN_BITMAP (temp, 0, i, bi)\n+    {\n+      tree expr = expression_for_id (i);\n+      if (bitmap_set_contains_value (b, get_value_handle (expr)))\n+\tbitmap_remove_from_set (a, expr);\n+    }\n+  BITMAP_FREE (temp);\n+}\n+\n+\n /* Return true if bitmapped set SET contains the value VAL.  */\n \n static bool\n@@ -683,6 +731,12 @@ bitmap_set_contains_value (bitmap_set_t set, tree val)\n   return bitmap_bit_p (set->values, VALUE_HANDLE_ID (val));\n }\n \n+static inline bool\n+bitmap_set_contains_expr (bitmap_set_t set, tree expr)\n+{\n+  return bitmap_bit_p (set->expressions, get_expression_id (expr));\n+}\n+\n /* Replace an instance of value LOOKFOR with expression EXPR in SET.  */\n \n static void\n@@ -855,11 +909,14 @@ pool_copy_list (tree list)\n   return head;\n }\n \n-/* Translate the vuses in the VUSES vector backwards through phi\n-   nodes, so that they have the value they would have in BLOCK. */\n+/* Translate the vuses in the VUSES vector backwards through phi nodes\n+   in PHIBLOCK, so that they have the value they would have in\n+   BLOCK. */\n \n static VEC(tree, gc) *\n-translate_vuses_through_block (VEC (tree, gc) *vuses, basic_block block)\n+translate_vuses_through_block (VEC (tree, gc) *vuses,\n+\t\t\t       basic_block phiblock,\n+\t\t\t       basic_block block)\n {\n   tree oldvuse;\n   VEC(tree, gc) *result = NULL;\n@@ -868,7 +925,8 @@ translate_vuses_through_block (VEC (tree, gc) *vuses, basic_block block)\n   for (i = 0; VEC_iterate (tree, vuses, i, oldvuse); i++)\n     {\n       tree phi = SSA_NAME_DEF_STMT (oldvuse);\n-      if (TREE_CODE (phi) == PHI_NODE)\n+      if (TREE_CODE (phi) == PHI_NODE\n+\t  && bb_for_stmt (phi) == phiblock)\n \t{\n \t  edge e = find_edge (block, bb_for_stmt (phi));\n \t  if (e)\n@@ -1047,7 +1105,7 @@ phi_translate (tree expr, bitmap_set_t set1, bitmap_set_t set2,\n \t    if (listchanged)\n \t      vn_lookup_or_add (newarglist, NULL);\n \n-\t    tvuses = translate_vuses_through_block (vuses, pred);\n+\t    tvuses = translate_vuses_through_block (vuses, phiblock, pred);\n \n \t    if (listchanged || (newop0 != oldop0) || (oldop2 != newop2)\n \t\t|| vuses != tvuses)\n@@ -1073,7 +1131,8 @@ phi_translate (tree expr, bitmap_set_t set1, bitmap_set_t set2,\n \n \toldvuses = VALUE_HANDLE_VUSES (get_value_handle (expr));\n \tif (oldvuses)\n-\t  newvuses = translate_vuses_through_block (oldvuses, pred);\n+\t  newvuses = translate_vuses_through_block (oldvuses, phiblock,\n+\t\t\t\t\t\t    pred);\n \n \tif (oldvuses != newvuses)\n \t  vn_lookup_or_add_with_vuses (expr, newvuses);\n@@ -1137,7 +1196,8 @@ phi_translate (tree expr, bitmap_set_t set1, bitmap_set_t set2,\n \n \toldvuses = VALUE_HANDLE_VUSES (get_value_handle (expr));\n \tif (oldvuses)\n-\t  newvuses = translate_vuses_through_block (oldvuses, pred);\n+\t  newvuses = translate_vuses_through_block (oldvuses, phiblock,\n+\t\t\t\t\t\t    pred);\n \n \tif (newop0 != oldop0 || newvuses != oldvuses\n \t    || newop1 != oldop1\n@@ -1258,9 +1318,13 @@ phi_translate (tree expr, bitmap_set_t set1, bitmap_set_t set2,\n       {\n \ttree phi = NULL;\n \tedge e;\n+\ttree def_stmt;\n \tgcc_assert (TREE_CODE (expr) == SSA_NAME);\n-\tif (TREE_CODE (SSA_NAME_DEF_STMT (expr)) == PHI_NODE)\n-\t  phi = SSA_NAME_DEF_STMT (expr);\n+\n+\tdef_stmt = SSA_NAME_DEF_STMT (expr);\n+\tif (TREE_CODE (def_stmt) == PHI_NODE\n+\t    && bb_for_stmt (def_stmt) == phiblock)\n+\t  phi = def_stmt;\n \telse\n \t  return expr;\n \n@@ -1498,7 +1562,10 @@ valid_in_sets (bitmap_set_t set1, bitmap_set_t set2, tree expr,\n       return false;\n \n     case tcc_exceptional:\n-      return true;\n+      {\n+\tgcc_assert (TREE_CODE (expr) == SSA_NAME);\n+\treturn bitmap_set_contains_expr (AVAIL_OUT (block), expr);\n+      }\n \n     case tcc_declaration:\n       return !vuses_dies_in_block_x (VALUE_HANDLE_VUSES (vh), block);\n@@ -1509,6 +1576,27 @@ valid_in_sets (bitmap_set_t set1, bitmap_set_t set2, tree expr,\n    }\n }\n \n+/* Clean the set of expressions that are no longer valid in SET1 or\n+   SET2.  This means expressions that are made up of values we have no\n+   leaders for in SET1 or SET2.  This version is used for partial\n+   anticipation, which means it is not valid in either ANTIC_IN or\n+   PA_IN.  */\n+\n+static void\n+dependent_clean (bitmap_set_t set1, bitmap_set_t set2, basic_block block)\n+{\n+  VEC (tree, heap) *exprs = sorted_array_from_bitmap_set (set1);\n+  tree expr;\n+  int i;\n+\n+  for (i = 0; VEC_iterate (tree, exprs, i, expr); i++)\n+    {\n+      if (!valid_in_sets (set1, set2, expr, block))\n+\tbitmap_remove_from_set (set1, expr);\n+    }\n+  VEC_free (tree, heap, exprs);\n+}\n+\n /* Clean the set of expressions that are no longer valid in SET.  This\n    means expressions that are made up of values we have no leaders for\n    in SET.  */\n@@ -1556,6 +1644,7 @@ compute_antic_aux (basic_block block, bool block_has_abnormal_pred_edge)\n   edge_iterator ei;\n \n   old = ANTIC_OUT = S = NULL;\n+  BB_VISITED (block) = 1;\n \n   /* If any edges from predecessors are abnormal, antic_in is empty,\n      so do nothing.  */\n@@ -1564,7 +1653,6 @@ compute_antic_aux (basic_block block, bool block_has_abnormal_pred_edge)\n \n   old = ANTIC_IN (block);\n   ANTIC_OUT = bitmap_set_new ();\n-  BB_VISITED (block) = 1;\n \n   /* If the block has no successors, ANTIC_OUT is empty.  */\n   if (EDGE_COUNT (block->succs) == 0)\n@@ -1574,46 +1662,70 @@ compute_antic_aux (basic_block block, bool block_has_abnormal_pred_edge)\n   else if (single_succ_p (block))\n     {\n       basic_block succ_bb = single_succ (block);\n-      phi_translate_set (ANTIC_OUT, ANTIC_IN (succ_bb),\n-\t\t\t block, succ_bb);\n+\n+      /* We trade iterations of the dataflow equations for having to\n+\t phi translate the maximal set, which is incredibly slow\n+\t (since the maximal set often has 300+ members, even when you\n+\t have a small number of blocks).\n+\t Basically, we defer the computation of ANTIC for this block\n+\t until we have processed it's successor, which will inveitably\n+\t have a *much* smaller set of values to phi translate once\n+\t clean has been run on it.\n+\t The cost of doing this is that we technically perform more\n+\t iterations, however, they are lower cost iterations.\n+\n+\t Timings for PRE on tramp3d-v4:\n+\t without maximal set fix: 11 seconds\n+\t with maximal set fix/without deferring: 26 seconds\n+\t with maximal set fix/with deferring: 11 seconds\n+     */\n+\n+      if (!BB_VISITED (succ_bb))\n+\t{\n+\t  changed = true;\n+\t  SET_BIT (changed_blocks, block->index);\n+\t  BB_VISITED (block) = 0;\n+\t  BB_DEFERRED (block) = 1;\n+\t  goto maybe_dump_sets;\n+\t}\n+      else\n+\tphi_translate_set (ANTIC_OUT, ANTIC_IN (succ_bb),\n+\t\t\t   block, succ_bb);\n     }\n+\n+\n   /* If we have multiple successors, we take the intersection of all of\n      them.  */\n   else\n     {\n       VEC(basic_block, heap) * worklist;\n       size_t i;\n       basic_block bprime, first;\n-      bool any_visited = false;\n \n       worklist = VEC_alloc (basic_block, heap, EDGE_COUNT (block->succs));\n       FOR_EACH_EDGE (e, ei, block->succs)\n-\t{\n-\t  any_visited |= BB_VISITED (e->dest);\n-\t  VEC_quick_push (basic_block, worklist, e->dest);\n-\t}\n-\n-      if (any_visited)\n-\t{\n-\t  first = VEC_index (basic_block, worklist, 0);\n-\n-\t  bitmap_set_copy (ANTIC_OUT, ANTIC_IN (first));\n+\tVEC_quick_push (basic_block, worklist, e->dest);\n+      first = VEC_index (basic_block, worklist, 0);\n \n-\t  for (i = 1; VEC_iterate (basic_block, worklist, i, bprime); i++)\n-\t    {\n-\t      if (!BB_VISITED (bprime))\n-\t\tcontinue;\n+      if (!BB_VISITED (first))\n+\tbitmap_set_copy (ANTIC_OUT, maximal_set);\n+      else\n+\tbitmap_set_copy (ANTIC_OUT, ANTIC_IN (first));\n \n-\t      bitmap_set_and (ANTIC_OUT, ANTIC_IN (bprime));\n-\t    }\n-\t  VEC_free (basic_block, heap, worklist);\n+      for (i = 1; VEC_iterate (basic_block, worklist, i, bprime); i++)\n+\t{\n+\t  if (!BB_VISITED (bprime))\n+\t    bitmap_set_and (ANTIC_OUT, maximal_set);\n+\t  else\n+\t    bitmap_set_and (ANTIC_OUT, ANTIC_IN (bprime));\n \t}\n+      VEC_free (basic_block, heap, worklist);\n     }\n \n   /* Generate ANTIC_OUT - TMP_GEN.  */\n   S = bitmap_set_subtract (ANTIC_OUT, TMP_GEN (block));\n \n-  /* Start ANTIC_IN with EXP_GEN - TMP_GEN */\n+  /* Start ANTIC_IN with EXP_GEN - TMP_GEN.  */\n   ANTIC_IN (block) = bitmap_set_subtract (EXP_GEN (block),\n \t\t\t\t\t  TMP_GEN (block));\n \n@@ -1624,7 +1736,9 @@ compute_antic_aux (basic_block block, bool block_has_abnormal_pred_edge)\n \t\t\t\t  expression_for_id (bii));\n \n   clean (ANTIC_IN (block), block);\n-  if (!bitmap_set_equal (old, ANTIC_IN (block)))\n+\n+  /* !old->expressions can happen when we deferred a block.  */\n+  if (!old->expressions || !bitmap_set_equal (old, ANTIC_IN (block)))\n     {\n       changed = true;\n       SET_BIT (changed_blocks, block->index);\n@@ -1637,16 +1751,26 @@ compute_antic_aux (basic_block block, bool block_has_abnormal_pred_edge)\n  maybe_dump_sets:\n   if (dump_file && (dump_flags & TDF_DETAILS))\n     {\n-      if (ANTIC_OUT)\n-\tprint_bitmap_set (dump_file, ANTIC_OUT, \"ANTIC_OUT\", block->index);\n+      if (!BB_DEFERRED (block) || BB_VISITED (block))\n+\t{\n+\t  if (ANTIC_OUT)\n+\t    print_bitmap_set (dump_file, ANTIC_OUT, \"ANTIC_OUT\", block->index);\n \n-      if (ANTIC_SAFE_LOADS (block))\n-\tprint_bitmap_set (dump_file, ANTIC_SAFE_LOADS (block),\n-\t\t\t \"ANTIC_SAFE_LOADS\", block->index);\n-      print_bitmap_set (dump_file, ANTIC_IN (block), \"ANTIC_IN\", block->index);\n+\t  if (ANTIC_SAFE_LOADS (block))\n+\t    print_bitmap_set (dump_file, ANTIC_SAFE_LOADS (block),\n+\t\t\t      \"ANTIC_SAFE_LOADS\", block->index);\n+\t  print_bitmap_set (dump_file, ANTIC_IN (block), \"ANTIC_IN\",\n+\t\t\t    block->index);\n \n-      if (S)\n-\tprint_bitmap_set (dump_file, S, \"S\", block->index);\n+\t  if (S)\n+\t    print_bitmap_set (dump_file, S, \"S\", block->index);\n+\t}\n+      else\n+\t{\n+\t  fprintf (dump_file,\n+\t\t   \"Block %d was deferred for a future iteration.\\n\",\n+\t\t   block->index);\n+\t}\n     }\n   if (old)\n     bitmap_set_free (old);\n@@ -1657,6 +1781,126 @@ compute_antic_aux (basic_block block, bool block_has_abnormal_pred_edge)\n   return changed;\n }\n \n+/* Compute PARTIAL_ANTIC for BLOCK.\n+\n+   If succs(BLOCK) > 1 then\n+     PA_OUT[BLOCK] = value wise union of PA_IN[b] + all ANTIC_IN not\n+     in ANTIC_OUT for all succ(BLOCK)\n+   else if succs(BLOCK) == 1 then\n+     PA_OUT[BLOCK] = phi_translate (PA_IN[succ(BLOCK)])\n+\n+   PA_IN[BLOCK] = dependent_clean(PA_OUT[BLOCK] - TMP_GEN[BLOCK]\n+\t\t\t\t  - ANTIC_IN[BLOCK])\n+\n+*/\n+static bool\n+compute_partial_antic_aux (basic_block block,\n+\t\t\t   bool block_has_abnormal_pred_edge)\n+{\n+  bool changed = false;\n+  bitmap_set_t old_PA_IN;\n+  bitmap_set_t PA_OUT;\n+  edge e;\n+  edge_iterator ei;\n+\n+  old_PA_IN = PA_OUT = NULL;\n+\n+  /* If any edges from predecessors are abnormal, antic_in is empty,\n+     so do nothing.  */\n+  if (block_has_abnormal_pred_edge)\n+    goto maybe_dump_sets;\n+\n+  old_PA_IN = PA_IN (block);\n+  PA_OUT = bitmap_set_new ();\n+\n+  /* If the block has no successors, ANTIC_OUT is empty.  */\n+  if (EDGE_COUNT (block->succs) == 0)\n+    ;\n+  /* If we have one successor, we could have some phi nodes to\n+     translate through.  Note that we can't phi translate across DFS\n+     back edges in partial antic, because it uses a union operation\n+     on the successors.  For recurrences like IV's, we will end up generating a\n+     new value in the set on each go around (i + 3 (VH.1) VH.1 + 1\n+     (VH.2), VH.2 + 1 (VH.3), etc), forever.  */\n+  else if (single_succ_p (block))\n+    {\n+      basic_block succ = single_succ (block);\n+      if (!(single_succ_edge (block)->flags & EDGE_DFS_BACK))\n+\tphi_translate_set (PA_OUT, PA_IN (succ), block, succ);\n+    }\n+  /* If we have multiple successors, we take the union of all of\n+     them.  */\n+  else\n+    {\n+      VEC(basic_block, heap) * worklist;\n+      size_t i;\n+      basic_block bprime;\n+\n+      worklist = VEC_alloc (basic_block, heap, EDGE_COUNT (block->succs));\n+      FOR_EACH_EDGE (e, ei, block->succs)\n+\t{\n+\t  if (e->flags & EDGE_DFS_BACK)\n+\t    continue;\n+\t  VEC_quick_push (basic_block, worklist, e->dest);\n+\t}\n+      if (VEC_length (basic_block, worklist) > 0)\n+\t{\n+\t  for (i = 0; VEC_iterate (basic_block, worklist, i, bprime); i++)\n+\t    {\n+\t      unsigned int i;\n+\t      bitmap_iterator bi;\n+\n+\t      FOR_EACH_EXPR_ID_IN_SET (ANTIC_IN (bprime), i, bi)\n+\t\tbitmap_value_insert_into_set (PA_OUT,\n+\t\t\t\t\t      expression_for_id (i));\n+\n+\t      FOR_EACH_EXPR_ID_IN_SET (PA_IN (bprime), i, bi)\n+\t\tbitmap_value_insert_into_set (PA_OUT,\n+\t\t\t\t\t      expression_for_id (i));\n+\t    }\n+\t}\n+      VEC_free (basic_block, heap, worklist);\n+    }\n+\n+  /* PA_IN starts with PA_OUT - TMP_GEN.\n+     Then we subtract things from ANTIC_IN.  */\n+  PA_IN (block) = bitmap_set_subtract (PA_OUT, TMP_GEN (block));\n+\n+  /* For partial antic, we want to put back in the phi results, since\n+     we will properly avoid making them partially antic over backedges.  */\n+  bitmap_ior_into (PA_IN (block)->values, PHI_GEN (block)->values);\n+  bitmap_ior_into (PA_IN (block)->expressions, PHI_GEN (block)->expressions);\n+\n+  /* PA_IN[block] = PA_IN[block] - ANTIC_IN[block] */\n+  bitmap_set_subtract_values (PA_IN (block), ANTIC_IN (block));\n+\n+  dependent_clean (PA_IN (block), ANTIC_IN (block), block);\n+\n+  if (!bitmap_set_equal (old_PA_IN, PA_IN (block)))\n+    {\n+      changed = true;\n+      SET_BIT (changed_blocks, block->index);\n+      FOR_EACH_EDGE (e, ei, block->preds)\n+\tSET_BIT (changed_blocks, e->src->index);\n+    }\n+  else\n+    RESET_BIT (changed_blocks, block->index);\n+\n+ maybe_dump_sets:\n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    {\n+      if (PA_OUT)\n+\tprint_bitmap_set (dump_file, PA_OUT, \"PA_OUT\", block->index);\n+\n+      print_bitmap_set (dump_file, PA_IN (block), \"PA_IN\", block->index);\n+    }\n+  if (old_PA_IN)\n+    bitmap_set_free (old_PA_IN);\n+  if (PA_OUT)\n+    bitmap_set_free (PA_OUT);\n+  return changed;\n+}\n+\n /* Compute ANTIC and partial ANTIC sets.  */\n \n static void\n@@ -1688,13 +1932,16 @@ compute_antic (void)\n \t}\n \n       BB_VISITED (block) = 0;\n+      BB_DEFERRED (block) = 0;\n       /* While we are here, give empty ANTIC_IN sets to each block.  */\n       ANTIC_IN (block) = bitmap_set_new ();\n+      PA_IN (block) = bitmap_set_new ();\n     }\n \n   /* At the exit block we anticipate nothing.  */\n   ANTIC_IN (EXIT_BLOCK_PTR) = bitmap_set_new ();\n   BB_VISITED (EXIT_BLOCK_PTR) = 1;\n+  PA_IN (EXIT_BLOCK_PTR) = bitmap_set_new ();\n \n   changed_blocks = sbitmap_alloc (last_basic_block + 1);\n   sbitmap_ones (changed_blocks);\n@@ -1714,12 +1961,44 @@ compute_antic (void)\n \t\t\t\t\t\t      block->index));\n \t    }\n \t}\n+      /* Theoretically possible, but *highly* unlikely.  */\n+      gcc_assert (num_iterations < 50);\n     }\n \n   if (dump_file && (dump_flags & TDF_STATS))\n     fprintf (dump_file, \"compute_antic required %d iterations\\n\",\n \t     num_iterations);\n \n+  if (do_partial_partial)\n+    {\n+      sbitmap_ones (changed_blocks);\n+      mark_dfs_back_edges ();\n+      num_iterations = 0;\n+      changed = true;\n+      while (changed)\n+\t{\n+\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t    fprintf (dump_file, \"Starting iteration %d\\n\", num_iterations);\n+\t  num_iterations++;\n+\t  changed = false;\n+\t  for (i = 0; i < last_basic_block - NUM_FIXED_BLOCKS; i++)\n+\t    {\n+\t      if (TEST_BIT (changed_blocks, postorder[i]))\n+\t\t{\n+\t\t  basic_block block = BASIC_BLOCK (postorder[i]);\n+\t\t  changed\n+\t\t    |= compute_partial_antic_aux (block,\n+\t\t\t\t\t\t  TEST_BIT (has_abnormal_preds,\n+\t\t\t\t\t\t\t    block->index));\n+\t\t}\n+\t    }\n+\t  /* Theoretically possible, but *highly* unlikely.  */\n+\t  gcc_assert (num_iterations < 50);\n+\t}\n+      if (dump_file && (dump_flags & TDF_STATS))\n+\tfprintf (dump_file, \"compute_partial_antic required %d iterations\\n\",\n+\t\t num_iterations);\n+    }\n   sbitmap_free (has_abnormal_preds);\n   sbitmap_free (changed_blocks);\n }\n@@ -2558,7 +2837,7 @@ insert_into_preds_of_block (basic_block block, unsigned int exprnum,\n    3. Recursively call ourselves on the dominator children of BLOCK.\n \n    Steps 1, 2a, and 3 are done by insert_aux. 2b, 2c and 2d are done by\n-   do_regular_insertion.  \n+   do_regular_insertion and do_partial_insertion.\n \n */\n \n@@ -2689,8 +2968,107 @@ do_regular_insertion (basic_block block, basic_block dom)\n }\n \n \n-/* Perform insertion of partially redundant expressions for block\n-   BLOCK.  */\n+/* Perform insertion for partially anticipatable expressions.  There\n+   is only one case we will perform insertion for these.  This case is\n+   if the expression is partially anticipatable, and fully available.\n+   In this case, we know that putting it earlier will enable us to\n+   remove the later computation.  */\n+\n+\n+static bool\n+do_partial_partial_insertion (basic_block block, basic_block dom)\n+{\n+  bool new_stuff = false;\n+  VEC (tree, heap) *exprs = sorted_array_from_bitmap_set (PA_IN (block));\n+  tree expr;\n+  int i;\n+\n+  for (i = 0; VEC_iterate (tree, exprs, i, expr); i++)\n+    {\n+      if (can_PRE_operation (expr) && !AGGREGATE_TYPE_P (TREE_TYPE (expr)))\n+\t{\n+\t  tree *avail;\n+\t  tree val;\n+\t  bool by_all = true;\n+\t  bool cant_insert = false;\n+\t  edge pred;\n+\t  basic_block bprime;\n+\t  tree eprime = NULL_TREE;\n+\t  edge_iterator ei;\n+\n+\t  val = get_value_handle (expr);\n+\t  if (bitmap_set_contains_value (PHI_GEN (block), val))\n+\t    continue;\n+\t  if (bitmap_set_contains_value (AVAIL_OUT (dom), val))\n+\t    continue;\n+\n+\t  avail = XCNEWVEC (tree, last_basic_block);\n+\t  FOR_EACH_EDGE (pred, ei, block->preds)\n+\t    {\n+\t      tree vprime;\n+\t      tree edoubleprime;\n+\n+\t      /* This can happen in the very weird case\n+\t\t that our fake infinite loop edges have caused a\n+\t\t critical edge to appear.  */\n+\t      if (EDGE_CRITICAL_P (pred))\n+\t\t{\n+\t\t  cant_insert = true;\n+\t\t  break;\n+\t\t}\n+\t      bprime = pred->src;\n+\t      eprime = phi_translate (expr, ANTIC_IN (block),\n+\t\t\t\t      PA_IN (block),\n+\t\t\t\t      bprime, block);\n+\n+\t      /* eprime will generally only be NULL if the\n+\t\t value of the expression, translated\n+\t\t through the PHI for this predecessor, is\n+\t\t undefined.  If that is the case, we can't\n+\t\t make the expression fully redundant,\n+\t\t because its value is undefined along a\n+\t\t predecessor path.  We can thus break out\n+\t\t early because it doesn't matter what the\n+\t\t rest of the results are.  */\n+\t      if (eprime == NULL)\n+\t\t{\n+\t\t  cant_insert = true;\n+\t\t  break;\n+\t\t}\n+\n+\t      eprime = fully_constant_expression (eprime);\n+\t      vprime = get_value_handle (eprime);\n+\t      gcc_assert (vprime);\n+\t      edoubleprime = bitmap_find_leader (AVAIL_OUT (bprime),\n+\t\t\t\t\t\t vprime);\n+\t      if (edoubleprime == NULL)\n+\t\t{\n+\t\t  by_all = false;\n+\t\t  break;\n+\t\t}\n+\t      else\n+\t\tavail[bprime->index] = edoubleprime;\n+\n+\t    }\n+\n+\t  /* If we can insert it, it's not the same value\n+\t     already existing along every predecessor, and\n+\t     it's defined by some predecessor, it is\n+\t     partially redundant.  */\n+\t  if (!cant_insert && by_all)\n+\t    {\n+\t      pre_stats.pa_insert++;\n+\t      if (insert_into_preds_of_block (block, get_expression_id (expr),\n+\t\t\t\t\t      avail))\n+\t\tnew_stuff = true;\n+\t    }\n+\t  free (avail);\n+\t}\n+    }\n+\n+  VEC_free (tree, heap, exprs);\n+  return new_stuff;\n+}\n \n static bool\n insert_aux (basic_block block)\n@@ -2723,6 +3101,8 @@ insert_aux (basic_block block)\n \t  if (!single_pred_p (block))\n \t    {\n \t      new_stuff |= do_regular_insertion (block, dom);\n+\t      if (do_partial_partial)\n+\t\tnew_stuff |= do_partial_partial_insertion (block, dom);\n \t    }\n \t}\n     }\n@@ -2797,6 +3177,11 @@ add_to_sets (tree var, tree expr, tree stmt, bitmap_set_t s1,\n   if (s1)\n     bitmap_insert_into_set (s1, var);\n \n+  /* PHI nodes can't go in the maximal sets because they are not in\n+     TMP_GEN, so it is possible to get into non-monotonic situations\n+     during ANTIC calculation, because it will *add* bits.  */\n+  if (!in_fre && TREE_CODE (SSA_NAME_DEF_STMT (var)) != PHI_NODE)\n+    bitmap_value_insert_into_set (maximal_set, var);\n   bitmap_value_insert_into_set (s2, var);\n }\n \n@@ -3281,6 +3666,8 @@ compute_avail (void)\n \n \t  vn_lookup_or_add (def, NULL);\n \t  bitmap_insert_into_set (TMP_GEN (ENTRY_BLOCK_PTR), def);\n+\t  if (!in_fre)\n+\t    bitmap_value_insert_into_set (maximal_set, def);\n \t  bitmap_value_insert_into_set (AVAIL_OUT (ENTRY_BLOCK_PTR), def);\n \t}\n     }\n@@ -3295,6 +3682,8 @@ compute_avail (void)\n \n \t  vn_lookup_or_add (def, NULL);\n \t  bitmap_insert_into_set (TMP_GEN (ENTRY_BLOCK_PTR), def);\n+\t  if (!in_fre)\n+\t    bitmap_value_insert_into_set (maximal_set, def);\n \t  bitmap_value_insert_into_set (AVAIL_OUT (ENTRY_BLOCK_PTR), def);\n \t}\n     }\n@@ -3410,6 +3799,8 @@ compute_avail (void)\n \t\t\t{\n \t\t\t  tree val = vn_lookup_or_add (newt, stmt);\n \t\t\t  vn_add (lhs, val);\n+\t\t\t  if (!in_fre)\n+\t\t\t    bitmap_value_insert_into_set (maximal_set, newt);\n \t\t\t  bitmap_value_insert_into_set (EXP_GEN (block), newt);\n \t\t\t}\n \t\t      bitmap_insert_into_set (TMP_GEN (block), lhs);\n@@ -3679,19 +4070,21 @@ init_pre (bool do_fre)\n   connect_infinite_loops_to_exit ();\n   memset (&pre_stats, 0, sizeof (pre_stats));\n \n+\n   postorder = XNEWVEC (int, n_basic_blocks - NUM_FIXED_BLOCKS);\n   post_order_compute (postorder, false);\n \n   FOR_ALL_BB (bb)\n     bb->aux = xcalloc (1, sizeof (struct bb_bitmap_sets));\n \n+  calculate_dominance_info (CDI_POST_DOMINATORS);\n+  calculate_dominance_info (CDI_DOMINATORS);\n+\n   bitmap_obstack_initialize (&grand_bitmap_obstack);\n   phi_translate_table = htab_create (5110, expr_pred_trans_hash,\n \t\t\t\t     expr_pred_trans_eq, free);\n   bitmap_set_pool = create_alloc_pool (\"Bitmap sets\",\n \t\t\t\t       sizeof (struct bitmap_set), 30);\n-  calculate_dominance_info (CDI_POST_DOMINATORS);\n-  calculate_dominance_info (CDI_DOMINATORS);\n   binary_node_pool = create_alloc_pool (\"Binary tree nodes\",\n \t\t\t\t\ttree_code_size (PLUS_EXPR), 30);\n   unary_node_pool = create_alloc_pool (\"Unary tree nodes\",\n@@ -3716,6 +4109,8 @@ init_pre (bool do_fre)\n       TMP_GEN (bb) = bitmap_set_new ();\n       AVAIL_OUT (bb) = bitmap_set_new ();\n     }\n+  maximal_set = in_fre ? NULL : bitmap_set_new ();\n+\n   need_eh_cleanup = BITMAP_ALLOC (NULL);\n }\n \n@@ -3787,6 +4182,7 @@ static void\n execute_pre (bool do_fre)\n {\n \n+  do_partial_partial = optimize > 2;\n   init_pre (do_fre);\n \n   if (!do_fre)\n@@ -3829,6 +4225,7 @@ execute_pre (bool do_fre)\n   if (dump_file && (dump_flags & TDF_STATS))\n     {\n       fprintf (dump_file, \"Insertions: %d\\n\", pre_stats.insertions);\n+      fprintf (dump_file, \"PA inserted: %d\\n\", pre_stats.pa_insert);\n       fprintf (dump_file, \"New PHIs: %d\\n\", pre_stats.phis);\n       fprintf (dump_file, \"Eliminated: %d\\n\", pre_stats.eliminations);\n       fprintf (dump_file, \"Constified: %d\\n\", pre_stats.constified);"}]}