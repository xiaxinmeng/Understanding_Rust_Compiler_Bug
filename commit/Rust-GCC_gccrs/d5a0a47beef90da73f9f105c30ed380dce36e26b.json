{"sha": "d5a0a47beef90da73f9f105c30ed380dce36e26b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDVhMGE0N2JlZWY5MGRhNzNmOWYxMDVjMzBlZDM4MGRjZTM2ZTI2Yg==", "commit": {"author": {"name": "Richard Earnshaw", "email": "rearnsha@arm.com", "date": "2009-01-13T14:09:50Z"}, "committer": {"name": "Richard Earnshaw", "email": "rearnsha@gcc.gnu.org", "date": "2009-01-13T14:09:50Z"}, "message": "arm.c (struct processors): Pass for speed down into cost helper functions.\n\n\t* arm.c (struct processors): Pass for speed down into cost helper\n\tfunctions.\n\t(const_ok_for_op): Handle COMPARE and inequality nodes.\n\t(arm_rtx_costs_1): Rewrite.\n\t(arm_size_rtx_costs): Update prototype.\n\t(arm_rtx_costs): Pass speed down to helper functions.\n\t(arm_slowmul_rtx_costs): Rework cost calculations.\n\t(arm_fastmul_rtx_costs, arm_xscale_rtx_costs): Likewise.\n\t(arm_9e_rtx_costs): Likewise.\n\nFrom-SVN: r143338", "tree": {"sha": "95111fe3ea26972923704f6d3ad34e50c60cfce5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/95111fe3ea26972923704f6d3ad34e50c60cfce5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d5a0a47beef90da73f9f105c30ed380dce36e26b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d5a0a47beef90da73f9f105c30ed380dce36e26b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d5a0a47beef90da73f9f105c30ed380dce36e26b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d5a0a47beef90da73f9f105c30ed380dce36e26b/comments", "author": null, "committer": null, "parents": [{"sha": "43b2b720fa4d064ff21d24cc4f0f04ab4231dd96", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/43b2b720fa4d064ff21d24cc4f0f04ab4231dd96", "html_url": "https://github.com/Rust-GCC/gccrs/commit/43b2b720fa4d064ff21d24cc4f0f04ab4231dd96"}], "stats": {"total": 839, "additions": 595, "deletions": 244}, "files": [{"sha": "7bb4789fd36b96f9754f33f2a66e5b8e537fd156", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d5a0a47beef90da73f9f105c30ed380dce36e26b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d5a0a47beef90da73f9f105c30ed380dce36e26b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d5a0a47beef90da73f9f105c30ed380dce36e26b", "patch": "@@ -1,3 +1,15 @@\n+2009-01-13  Richard Earnshaw  <rearnsha@arm.com>\n+\n+\t* arm.c (struct processors): Pass for speed down into cost helper\n+\tfunctions.\n+\t(const_ok_for_op): Handle COMPARE and inequality nodes.\n+\t(arm_rtx_costs_1): Rewrite.\n+\t(arm_size_rtx_costs): Update prototype.\n+\t(arm_rtx_costs): Pass speed down to helper functions.\n+\t(arm_slowmul_rtx_costs): Rework cost calculations.\n+\t(arm_fastmul_rtx_costs, arm_xscale_rtx_costs): Likewise.\n+\t(arm_9e_rtx_costs): Likewise.\n+\n 2009-01-13  Uros Bizjak  <ubizjak@gmail.com>\n \n \t* config/alpha/alpha.c (alpha_legitimate_address_p): Explicit"}, {"sha": "8c2aa5e19a0b1c36b056102aab5ef61e1bad723c", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 583, "deletions": 244, "changes": 827, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d5a0a47beef90da73f9f105c30ed380dce36e26b/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d5a0a47beef90da73f9f105c30ed380dce36e26b/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=d5a0a47beef90da73f9f105c30ed380dce36e26b", "patch": "@@ -126,12 +126,12 @@ static bool arm_function_ok_for_sibcall (tree, tree);\n static void arm_internal_label (FILE *, const char *, unsigned long);\n static void arm_output_mi_thunk (FILE *, tree, HOST_WIDE_INT, HOST_WIDE_INT,\n \t\t\t\t tree);\n-static int arm_rtx_costs_1 (rtx, enum rtx_code, enum rtx_code);\n-static bool arm_size_rtx_costs (rtx, int, int, int *);\n-static bool arm_slowmul_rtx_costs (rtx, int, int, int *);\n-static bool arm_fastmul_rtx_costs (rtx, int, int, int *);\n-static bool arm_xscale_rtx_costs (rtx, int, int, int *);\n-static bool arm_9e_rtx_costs (rtx, int, int, int *);\n+static bool arm_rtx_costs_1 (rtx, enum rtx_code, int*, bool);\n+static bool arm_size_rtx_costs (rtx, enum rtx_code, enum rtx_code, int *);\n+static bool arm_slowmul_rtx_costs (rtx, enum rtx_code, enum rtx_code, int *, bool);\n+static bool arm_fastmul_rtx_costs (rtx, enum rtx_code, enum rtx_code, int *, bool);\n+static bool arm_xscale_rtx_costs (rtx, enum rtx_code, enum rtx_code, int *, bool);\n+static bool arm_9e_rtx_costs (rtx, enum rtx_code, enum rtx_code, int *, bool);\n static bool arm_rtx_costs (rtx, int, int, int *, bool);\n static int arm_address_cost (rtx, bool);\n static bool arm_memory_load_p (rtx);\n@@ -619,7 +619,7 @@ struct processors\n   enum processor_type core;\n   const char *arch;\n   const unsigned long flags;\n-  bool (* rtx_costs) (rtx, int, int, int *);\n+  bool (* rtx_costs) (rtx, enum rtx_code, enum rtx_code, int *, bool);\n };\n \n /* Not all of these give usefully different compilation alternatives,\n@@ -1883,6 +1883,24 @@ const_ok_for_op (HOST_WIDE_INT i, enum rtx_code code)\n   switch (code)\n     {\n     case PLUS:\n+    case COMPARE:\n+    case EQ:\n+    case NE:\n+    case GT:\n+    case LE:\n+    case LT:\n+    case GE:\n+    case GEU:\n+    case LTU:\n+    case GTU:\n+    case LEU:\n+    case UNORDERED:\n+    case ORDERED:\n+    case UNEQ:\n+    case UNGE:\n+    case UNLT:\n+    case UNGT:\n+    case UNLE:\n       return const_ok_for_arm (ARM_SIGN_EXTEND (-i));\n \n     case MINUS:\t\t/* Should only occur with (MINUS I reg) => rsb */\n@@ -4882,130 +4900,227 @@ thumb1_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer)\n     }\n }\n \n-\n-/* Worker routine for arm_rtx_costs.  */\n-/* ??? This needs updating for thumb2.  */\n-static inline int\n-arm_rtx_costs_1 (rtx x, enum rtx_code code, enum rtx_code outer)\n+static inline bool\n+arm_rtx_costs_1 (rtx x, enum rtx_code outer, int* total, bool speed)\n {\n   enum machine_mode mode = GET_MODE (x);\n   enum rtx_code subcode;\n+  rtx operand;\n+  enum rtx_code code = GET_CODE (x);\n   int extra_cost;\n+  *total = 0;\n \n   switch (code)\n     {\n     case MEM:\n       /* Memory costs quite a lot for the first word, but subsequent words\n \t load at the equivalent of a single insn each.  */\n-      return (10 + 4 * ((GET_MODE_SIZE (mode) - 1) / UNITS_PER_WORD)\n-\t      + (GET_CODE (x) == SYMBOL_REF\n-\t\t && CONSTANT_POOL_ADDRESS_P (x) ? 4 : 0));\n+      *total = COSTS_N_INSNS (2 + ARM_NUM_REGS (mode));\n+      return true;\n \n     case DIV:\n     case MOD:\n     case UDIV:\n     case UMOD:\n-      return optimize_size ? COSTS_N_INSNS (2) : 100;\n+      if (TARGET_HARD_FLOAT && mode == SFmode)\n+\t*total = COSTS_N_INSNS (2);\n+      else if (TARGET_HARD_FLOAT && mode == DFmode)\n+\t*total = COSTS_N_INSNS (4);\n+      else\n+\t*total = COSTS_N_INSNS (20);\n+      return false;\n \n     case ROTATE:\n-      if (mode == SImode && GET_CODE (XEXP (x, 1)) == REG)\n-\treturn 4;\n+      if (GET_CODE (XEXP (x, 1)) == REG)\n+\t*total = COSTS_N_INSNS (1); /* Need to subtract from 32 */\n+      else if (GET_CODE (XEXP (x, 1)) != CONST_INT)\n+\t*total = rtx_cost (XEXP (x, 1), code, speed);\n+\n       /* Fall through */\n     case ROTATERT:\n       if (mode != SImode)\n-\treturn 8;\n+\t{\n+\t  *total += COSTS_N_INSNS (4);\n+\t  return true;\n+\t}\n+\n       /* Fall through */\n     case ASHIFT: case LSHIFTRT: case ASHIFTRT:\n+      *total += rtx_cost (XEXP (x, 0), code, speed);\n       if (mode == DImode)\n-\treturn (8 + (GET_CODE (XEXP (x, 1)) == CONST_INT ? 0 : 8)\n-\t\t+ ((GET_CODE (XEXP (x, 0)) == REG\n-\t\t    || (GET_CODE (XEXP (x, 0)) == SUBREG\n-\t\t\t&& GET_CODE (SUBREG_REG (XEXP (x, 0))) == REG))\n-\t\t   ? 0 : 8));\n+\t{\n+\t  *total += COSTS_N_INSNS (3);\n+\t  return true;\n+\t}\n \n-      extra_cost = 1;\n+      *total += COSTS_N_INSNS (1);\n       /* Increase the cost of complex shifts because they aren't any faster,\n          and reduce dual issue opportunities.  */\n       if (arm_tune_cortex_a9\n \t  && outer != SET && GET_CODE (XEXP (x, 1)) != CONST_INT)\n-\textra_cost++;\n-\n-      return (extra_cost + ((GET_CODE (XEXP (x, 0)) == REG\n-\t\t    || (GET_CODE (XEXP (x, 0)) == SUBREG\n-\t\t\t&& GET_CODE (SUBREG_REG (XEXP (x, 0))) == REG))\n-\t\t   ? 0 : 4)\n-\t      + ((GET_CODE (XEXP (x, 1)) == REG\n-\t\t  || (GET_CODE (XEXP (x, 1)) == SUBREG\n-\t\t      && GET_CODE (SUBREG_REG (XEXP (x, 1))) == REG)\n-\t\t  || (GET_CODE (XEXP (x, 1)) == CONST_INT))\n-\t\t ? 0 : 4));\n+\t++*total;\n+\n+      return true;\n \n     case MINUS:\n-      if (GET_CODE (XEXP (x, 1)) == MULT && mode == SImode && arm_arch_thumb2)\n+      if (TARGET_THUMB2)\n \t{\n-\t  extra_cost = rtx_cost (XEXP (x, 1), code, true);\n-\t  if (!REG_OR_SUBREG_REG (XEXP (x, 0)))\n-\t    extra_cost += 4 * ARM_NUM_REGS (mode);\n-\t  return extra_cost;\n+\t  if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n+\t    {\n+\t      if (TARGET_HARD_FLOAT && (mode == SFmode || mode == DFmode))\n+\t\t*total = COSTS_N_INSNS (1);\n+\t      else\n+\t\t*total = COSTS_N_INSNS (20);\n+\t    }\n+\t  else\n+\t    *total = COSTS_N_INSNS (ARM_NUM_REGS (mode));\n+\t  /* Thumb2 does not have RSB, so all arguments must be\n+\t     registers (subtracting a constant is canonicalized as\n+\t     addition of the negated constant).  */\n+\t  return false;\n \t}\n \n       if (mode == DImode)\n-\treturn (4 + (REG_OR_SUBREG_REG (XEXP (x, 1)) ? 0 : 8)\n-\t\t+ ((REG_OR_SUBREG_REG (XEXP (x, 0))\n-\t\t    || (GET_CODE (XEXP (x, 0)) == CONST_INT\n-\t\t       && const_ok_for_arm (INTVAL (XEXP (x, 0)))))\n-\t\t   ? 0 : 8));\n+\t{\n+\t  *total = COSTS_N_INSNS (ARM_NUM_REGS (mode));\n+\t  if (GET_CODE (XEXP (x, 0)) == CONST_INT\n+\t      && const_ok_for_arm (INTVAL (XEXP (x, 0))))\n+\t    {\n+\t      *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t      return true;\n+\t    }\n+\n+\t  if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t      && const_ok_for_arm (INTVAL (XEXP (x, 1))))\n+\t    {\n+\t      *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t      return true;\n+\t    }\n+\n+\t  return false;\n+\t}\n \n       if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n-\treturn (2 + ((REG_OR_SUBREG_REG (XEXP (x, 1))\n-\t\t      || (GET_CODE (XEXP (x, 1)) == CONST_DOUBLE\n-\t\t\t  && arm_const_double_rtx (XEXP (x, 1))))\n-\t\t     ? 0 : 8)\n-\t\t+ ((REG_OR_SUBREG_REG (XEXP (x, 0))\n-\t\t    || (GET_CODE (XEXP (x, 0)) == CONST_DOUBLE\n-\t\t\t&& arm_const_double_rtx (XEXP (x, 0))))\n-\t\t   ? 0 : 8));\n-\n-      if (((GET_CODE (XEXP (x, 0)) == CONST_INT\n-\t    && const_ok_for_arm (INTVAL (XEXP (x, 0)))\n-\t    && REG_OR_SUBREG_REG (XEXP (x, 1))))\n-\t  || (((subcode = GET_CODE (XEXP (x, 1))) == ASHIFT\n-\t       || subcode == ASHIFTRT || subcode == LSHIFTRT\n-\t       || subcode == ROTATE || subcode == ROTATERT\n-\t       || (subcode == MULT\n-\t\t   && GET_CODE (XEXP (XEXP (x, 1), 1)) == CONST_INT\n-\t\t   && ((INTVAL (XEXP (XEXP (x, 1), 1)) &\n-\t\t\t(INTVAL (XEXP (XEXP (x, 1), 1)) - 1)) == 0)))\n-\t      && REG_OR_SUBREG_REG (XEXP (XEXP (x, 1), 0))\n-\t      && (REG_OR_SUBREG_REG (XEXP (XEXP (x, 1), 1))\n-\t\t  || GET_CODE (XEXP (XEXP (x, 1), 1)) == CONST_INT)\n-\t      && REG_OR_SUBREG_REG (XEXP (x, 0))))\n-\treturn 1;\n+\t{\n+\t  if (TARGET_HARD_FLOAT && (mode == SFmode || mode == DFmode))\n+\t    {\n+\t      *total = COSTS_N_INSNS (1);\n+\t      if (GET_CODE (XEXP (x, 0)) == CONST_DOUBLE\n+\t\t  && arm_const_double_rtx (XEXP (x, 0)))\n+\t\t{\n+\t\t  *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t\t  return true;\n+\t\t}\n+\n+\t      if (GET_CODE (XEXP (x, 1)) == CONST_DOUBLE\n+\t\t  && arm_const_double_rtx (XEXP (x, 1)))\n+\t\t{\n+\t\t  *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t\t  return true;\n+\t\t}\n+\n+\t      return false;\n+\t    }\n+\t  *total = COSTS_N_INSNS (20);\n+\t  return false;\n+\t}\n+\n+      *total = COSTS_N_INSNS (1);\n+      if (GET_CODE (XEXP (x, 0)) == CONST_INT\n+\t  && const_ok_for_arm (INTVAL (XEXP (x, 0))))\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t  return true;\n+\t}\n+\n+      subcode = GET_CODE (XEXP (x, 1));\n+      if (subcode == ASHIFT || subcode == ASHIFTRT\n+\t  || subcode == LSHIFTRT\n+\t  || subcode == ROTATE || subcode == ROTATERT)\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t  *total += rtx_cost (XEXP (XEXP (x, 1), 0), subcode, speed);\n+\t  return true;\n+\t}\n+\n+      if (subcode == MULT\n+\t  && GET_CODE (XEXP (XEXP (x, 1), 1)) == CONST_INT\n+\t  && ((INTVAL (XEXP (XEXP (x, 1), 1)) &\n+\t       (INTVAL (XEXP (XEXP (x, 1), 1)) - 1)) == 0))\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t  *total += rtx_cost (XEXP (XEXP (x, 1), 0), subcode, speed);\n+\t  return true;\n+\t}\n+\n+      if (GET_RTX_CLASS (GET_CODE (XEXP (x, 1))) == RTX_COMPARE\n+\t  || GET_RTX_CLASS (GET_CODE (XEXP (x, 1))) == RTX_COMM_COMPARE)\n+\t{\n+\t  *total = COSTS_N_INSNS (1) + rtx_cost (XEXP (x, 0), code, speed);\n+\t  if (GET_CODE (XEXP (XEXP (x, 1), 0)) == REG\n+\t      && REGNO (XEXP (XEXP (x, 1), 0)) != CC_REGNUM)\n+\t    *total += COSTS_N_INSNS (1);\n+\n+\t  return true;\n+\t}\n+\n       /* Fall through */\n \n     case PLUS:\n-      if (arm_arch6 && mode == SImode\n+      if (code == PLUS && arm_arch6 && mode == SImode\n \t  && (GET_CODE (XEXP (x, 0)) == ZERO_EXTEND\n \t      || GET_CODE (XEXP (x, 0)) == SIGN_EXTEND))\n-\treturn 1 + (GET_CODE (XEXP (XEXP (x, 0), 0)) == MEM ? 10 : 0)\n-\t\t + (GET_CODE (XEXP (x, 1)) == MEM ? 10 : 0);\n+\t{\n+\t  *total = COSTS_N_INSNS (1);\n+\t  *total += rtx_cost (XEXP (XEXP (x, 0), 0), GET_CODE (XEXP (x, 0)),\n+\t\t\t      speed);\n+\t  *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t  return true;\n+\t}\n \n-      if (GET_CODE (XEXP (x, 0)) == MULT)\n+      /* MLA: All arguments must be registers.  We filter out\n+\t multiplication by a power of two, so that we fall down into\n+\t the code below.  */\n+      if (GET_CODE (XEXP (x, 0)) == MULT\n+\t  && ! (GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n+\t\t&& ((INTVAL (XEXP (XEXP (x, 0), 1)) &\n+\t\t     (INTVAL (XEXP (XEXP (x, 0), 1)) - 1)) == 0)))\n \t{\n-\t  extra_cost = rtx_cost (XEXP (x, 0), code, true);\n-\t  if (!REG_OR_SUBREG_REG (XEXP (x, 1)))\n-\t    extra_cost += 4 * ARM_NUM_REGS (mode);\n-\t  return extra_cost;\n+\t  /* The cost comes from the cost of the multiply.  */\n+\t  return false;\n \t}\n \n       if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n-\treturn (2 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 8)\n-\t\t+ ((REG_OR_SUBREG_REG (XEXP (x, 1))\n-\t\t    || (GET_CODE (XEXP (x, 1)) == CONST_DOUBLE\n-\t\t\t&& arm_const_double_rtx (XEXP (x, 1))))\n-\t\t   ? 0 : 8));\n+\t{\n+\t  if (TARGET_HARD_FLOAT && (mode == SFmode || mode == DFmode))\n+\t    {\n+\t      *total = COSTS_N_INSNS (1);\n+\t      if (GET_CODE (XEXP (x, 1)) == CONST_DOUBLE\n+\t\t  && arm_const_double_rtx (XEXP (x, 1)))\n+\t\t{\n+\t\t  *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t\t  return true;\n+\t\t}\n+\n+\t      return false;\n+\t    }\n+\n+\t  *total = COSTS_N_INSNS (20);\n+\t  return false;\n+\t}\n+\n+      if (GET_RTX_CLASS (GET_CODE (XEXP (x, 0))) == RTX_COMPARE\n+\t  || GET_RTX_CLASS (GET_CODE (XEXP (x, 0))) == RTX_COMM_COMPARE)\n+\t{\n+\t  *total = COSTS_N_INSNS (1) + rtx_cost (XEXP (x, 1), code, speed);\n+\t  if (GET_CODE (XEXP (XEXP (x, 0), 0)) == REG\n+\t      && REGNO (XEXP (XEXP (x, 0), 0)) != CC_REGNUM)\n+\t    *total += COSTS_N_INSNS (1);\n+\t  return true;\n+\t}\n \n       /* Fall through */\n+\n     case AND: case XOR: case IOR:\n       extra_cost = 0;\n \n@@ -5019,38 +5134,56 @@ arm_rtx_costs_1 (rtx x, enum rtx_code code, enum rtx_code outer)\n \t   && GET_CODE (XEXP (x, 1)) != CONST_INT)\n \t  || (REG_OR_SUBREG_REG (XEXP (x, 0))\n \t      && ARM_FRAME_RTX (REG_OR_SUBREG_RTX (XEXP (x, 0)))))\n-\textra_cost = 4;\n+\t*total = 4;\n \n       if (mode == DImode)\n-\treturn (4 + extra_cost + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 8)\n-\t\t+ ((REG_OR_SUBREG_REG (XEXP (x, 1))\n-\t\t    || (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t\t\t&& const_ok_for_op (INTVAL (XEXP (x, 1)), code)))\n-\t\t   ? 0 : 8));\n-\n-      if (REG_OR_SUBREG_REG (XEXP (x, 0)))\n-\treturn (1 + (GET_CODE (XEXP (x, 1)) == CONST_INT ? 0 : extra_cost)\n-\t\t+ ((REG_OR_SUBREG_REG (XEXP (x, 1))\n-\t\t    || (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t\t\t&& const_ok_for_op (INTVAL (XEXP (x, 1)), code)))\n-\t\t   ? 0 : 4));\n-\n-      else if (REG_OR_SUBREG_REG (XEXP (x, 1)))\n-\treturn (1 + extra_cost\n-\t\t+ ((((subcode = GET_CODE (XEXP (x, 0))) == ASHIFT\n-\t\t     || subcode == LSHIFTRT || subcode == ASHIFTRT\n-\t\t     || subcode == ROTATE || subcode == ROTATERT\n-\t\t     || (subcode == MULT\n-\t\t\t && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n-\t\t\t && ((INTVAL (XEXP (XEXP (x, 0), 1)) &\n-\t\t\t      (INTVAL (XEXP (XEXP (x, 0), 1)) - 1)) == 0)))\n-\t\t    && (REG_OR_SUBREG_REG (XEXP (XEXP (x, 0), 0)))\n-\t\t    && ((REG_OR_SUBREG_REG (XEXP (XEXP (x, 0), 1))\n-\t\t\t && !arm_tune_cortex_a9)\n-\t\t\t|| GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT))\n-\t\t   ? 0 : 4));\n+\t{\n+\t  *total += COSTS_N_INSNS (2);\n+\t  if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t      && const_ok_for_op (INTVAL (XEXP (x, 1)), code))\n+\t    {\n+\t      *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t      return true;\n+\t    }\n \n-      return 8;\n+\t  return false;\n+\t}\n+\n+      *total += COSTS_N_INSNS (1);\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t  && const_ok_for_op (INTVAL (XEXP (x, 1)), code))\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t  return true;\n+\t}\n+      subcode = GET_CODE (XEXP (x, 0));\n+      if (subcode == ASHIFT || subcode == ASHIFTRT\n+\t  || subcode == LSHIFTRT\n+\t  || subcode == ROTATE || subcode == ROTATERT)\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t  *total += rtx_cost (XEXP (XEXP (x, 0), 0), subcode, speed);\n+\t  return true;\n+\t}\n+\n+      if (subcode == MULT\n+\t  && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n+\t  && ((INTVAL (XEXP (XEXP (x, 0), 1)) &\n+\t       (INTVAL (XEXP (XEXP (x, 0), 1)) - 1)) == 0))\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t  *total += rtx_cost (XEXP (XEXP (x, 0), 0), subcode, speed);\n+\t  return true;\n+\t}\n+\n+      if (subcode == UMIN || subcode == UMAX\n+\t  || subcode == SMIN || subcode == SMAX)\n+\t{\n+\t  *total = COSTS_N_INSNS (3);\n+\t  return true;\n+\t}\n+\n+      return false;\n \n     case MULT:\n       /* This should have been handled by the CPU specific routines.  */\n@@ -5064,108 +5197,290 @@ arm_rtx_costs_1 (rtx x, enum rtx_code code, enum rtx_code outer)\n \t      == GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 1)))\n \t  && (GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 0)) == ZERO_EXTEND\n \t      || GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 0)) == SIGN_EXTEND))\n-\treturn 8;\n-      return 99;\n+\t{\n+\t  *total = rtx_cost (XEXP (XEXP (x, 0), 0), LSHIFTRT, speed);\n+\t  return true;\n+\t}\n+      *total = COSTS_N_INSNS (2); /* Plus the cost of the MULT */\n+      return false;\n \n     case NEG:\n       if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n-\treturn 4 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 6);\n+\t{\n+\t  if (TARGET_HARD_FLOAT && (mode == SFmode || mode == DFmode))\n+\t    {\n+\t      *total = COSTS_N_INSNS (1);\n+\t      return false;\n+\t    }\n+\t  *total = COSTS_N_INSNS (2);\n+\t  return false;\n+\t}\n+\n       /* Fall through */\n     case NOT:\n-      if (mode == DImode)\n-\treturn 4 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 4);\n+      *total = COSTS_N_INSNS (ARM_NUM_REGS(mode));\n+      if (mode == SImode && code == NOT)\n+\t{\n+\t  subcode = GET_CODE (XEXP (x, 0));\n+\t  if (subcode == ASHIFT || subcode == ASHIFTRT\n+\t      || subcode == LSHIFTRT\n+\t      || subcode == ROTATE || subcode == ROTATERT\n+\t      || (subcode == MULT\n+\t\t  && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n+\t\t  && ((INTVAL (XEXP (XEXP (x, 0), 1)) & \n+\t\t       (INTVAL (XEXP (XEXP (x, 0), 1)) - 1)) == 0)))\n+\t    {\n+\t      *total += rtx_cost (XEXP (XEXP (x, 0), 0), subcode, speed);\n+\t      /* Register shifts cost an extra cycle.  */\n+\t      if (GET_CODE (XEXP (XEXP (x, 0), 1)) != CONST_INT)\n+\t\t*total += COSTS_N_INSNS (1) + rtx_cost (XEXP (XEXP (x, 0), 1),\n+\t\t\t\t\t\t\tsubcode, speed);\n+\t      return true;\n+\t    }\n+\t}\n \n-      return 1 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 4);\n+      return false;\n \n     case IF_THEN_ELSE:\n       if (GET_CODE (XEXP (x, 1)) == PC || GET_CODE (XEXP (x, 2)) == PC)\n-\treturn 14;\n-      return 2;\n+\t{\n+\t  *total = COSTS_N_INSNS (4);\n+\t  return true;\n+\t}\n+\n+      operand = XEXP (x, 0);\n+\n+      if (!((GET_RTX_CLASS (GET_CODE (operand)) == RTX_COMPARE\n+\t     || GET_RTX_CLASS (GET_CODE (operand)) == RTX_COMM_COMPARE)\n+\t    && GET_CODE (XEXP (operand, 0)) == REG\n+\t    && REGNO (XEXP (operand, 0)) == CC_REGNUM))\n+\t*total += COSTS_N_INSNS (1);\n+      *total += (rtx_cost (XEXP (x, 1), code, speed)\n+\t\t + rtx_cost (XEXP (x, 2), code, speed));\n+      return true;\n+\n+    case NE:\n+      if (mode == SImode && XEXP (x, 1) == const0_rtx)\n+\t{\n+\t  *total = COSTS_N_INSNS (2) + rtx_cost (XEXP (x, 0), code, speed);\n+\t  return true;\n+\t}\n+      goto scc_insn;\n+\n+    case GE:\n+      if ((GET_CODE (XEXP (x, 0)) != REG || REGNO (XEXP (x, 0)) != CC_REGNUM)\n+\t  && mode == SImode && XEXP (x, 1) == const0_rtx)\n+\t{\n+\t  *total = COSTS_N_INSNS (2) + rtx_cost (XEXP (x, 0), code, speed);\n+\t  return true;\n+\t}\n+      goto scc_insn;\n+\n+    case LT:\n+      if ((GET_CODE (XEXP (x, 0)) != REG || REGNO (XEXP (x, 0)) != CC_REGNUM)\n+\t  && mode == SImode && XEXP (x, 1) == const0_rtx)\n+\t{\n+\t  *total = COSTS_N_INSNS (1) + rtx_cost (XEXP (x, 0), code, speed);\n+\t  return true;\n+\t}\n+      goto scc_insn;\n+\n+    case EQ:\n+    case GT:\n+    case LE:\n+    case GEU:\n+    case LTU:\n+    case GTU:\n+    case LEU:\n+    case UNORDERED:\n+    case ORDERED:\n+    case UNEQ:\n+    case UNGE:\n+    case UNLT:\n+    case UNGT:\n+    case UNLE:\n+    scc_insn:\n+      /* SCC insns.  In the case where the comparison has already been\n+\t performed, then they cost 2 instructions.  Otherwise they need\n+\t an additional comparison before them.  */\n+      *total = COSTS_N_INSNS (2);\n+      if (GET_CODE (XEXP (x, 0)) == REG && REGNO (XEXP (x, 0)) == CC_REGNUM)\n+\t{\n+\t  return true;\n+\t}\n \n+      /* Fall through */\n     case COMPARE:\n-      return 1;\n+      if (GET_CODE (XEXP (x, 0)) == REG && REGNO (XEXP (x, 0)) == CC_REGNUM)\n+\t{\n+\t  *total = 0;\n+\t  return true;\n+\t}\n+\n+      *total += COSTS_N_INSNS (1);\n+      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+\t  && const_ok_for_op (INTVAL (XEXP (x, 1)), code))\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 0), code, speed);\n+\t  return true;\n+\t}\n+\n+      subcode = GET_CODE (XEXP (x, 0));\n+      if (subcode == ASHIFT || subcode == ASHIFTRT\n+\t  || subcode == LSHIFTRT\n+\t  || subcode == ROTATE || subcode == ROTATERT)\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t  *total += rtx_cost (XEXP (XEXP (x, 0), 0), subcode, speed);\n+\t  return true;\n+\t}\n+\n+      if (subcode == MULT\n+\t  && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n+\t  && ((INTVAL (XEXP (XEXP (x, 0), 1)) &\n+\t       (INTVAL (XEXP (XEXP (x, 0), 1)) - 1)) == 0))\n+\t{\n+\t  *total += rtx_cost (XEXP (x, 1), code, speed);\n+\t  *total += rtx_cost (XEXP (XEXP (x, 0), 0), subcode, speed);\n+\t  return true;\n+\t}\n+      \n+      return false;\n+\n+    case UMIN:\n+    case UMAX:\n+    case SMIN:\n+    case SMAX:\n+      *total = COSTS_N_INSNS (2) + rtx_cost (XEXP (x, 0), code, speed);\n+      if (GET_CODE (XEXP (x, 1)) != CONST_INT\n+\t  || !const_ok_for_arm (INTVAL (XEXP (x, 1))))\n+\t*total += rtx_cost (XEXP (x, 1), code, speed);\n+      return true;\n \n     case ABS:\n-      return 4 + (mode == DImode ? 4 : 0);\n+      if (GET_MODE_CLASS (mode == MODE_FLOAT))\n+\t{\n+\t  if (TARGET_HARD_FLOAT && (mode == SFmode || mode == DFmode))\n+\t    {\n+\t      *total = COSTS_N_INSNS (1);\n+\t      return false;\n+\t    }\n+\t  *total = COSTS_N_INSNS (20);\n+\t  return false;\n+\t}\n+      *total = COSTS_N_INSNS (1);\n+      if (mode == DImode)\n+\t*total += COSTS_N_INSNS (3);\n+      return false;\n \n     case SIGN_EXTEND:\n-      if (arm_arch_thumb2 && mode == SImode)\n-\treturn 1 + (GET_CODE (XEXP (x, 0)) == MEM ? 10 : 0);\n+      if (GET_MODE_CLASS (mode) == MODE_INT)\n+\t{\n+\t  *total = 0;\n+\t  if (mode == DImode)\n+\t    *total += COSTS_N_INSNS (1);\n+\n+\t  if (GET_MODE (XEXP (x, 0)) != SImode)\n+\t    {\n+\t      if (arm_arch6)\n+\t\t{\n+\t\t  if (GET_CODE (XEXP (x, 0)) != MEM)\n+\t\t    *total += COSTS_N_INSNS (1);\n+\t\t}\n+\t      else if (!arm_arch4 || GET_CODE (XEXP (x, 0)) != MEM)\n+\t\t*total += COSTS_N_INSNS (2);\n+\t    }\n+\n+\t  return false;\n+\t}\n \n-      if (GET_MODE (XEXP (x, 0)) == QImode)\n-\treturn (4 + (mode == DImode ? 4 : 0)\n-\t\t+ (GET_CODE (XEXP (x, 0)) == MEM ? 10 : 0));\n       /* Fall through */\n     case ZERO_EXTEND:\n-      if (arm_arch6 && mode == SImode)\n-\treturn 1 + (GET_CODE (XEXP (x, 0)) == MEM ? 10 : 0);\n-\n-      switch (GET_MODE (XEXP (x, 0)))\n+      *total = 0;\n+      if (GET_MODE_CLASS (mode) == MODE_INT)\n \t{\n-\tcase QImode:\n-\t  return (1 + (mode == DImode ? 4 : 0)\n-\t\t  + (GET_CODE (XEXP (x, 0)) == MEM ? 10 : 0));\n+\t  if (mode == DImode)\n+\t    *total += COSTS_N_INSNS (1);\n \n-\tcase HImode:\n-\t  return (4 + (mode == DImode ? 4 : 0)\n-\t\t  + (GET_CODE (XEXP (x, 0)) == MEM ? 10 : 0));\n+\t  if (GET_MODE (XEXP (x, 0)) != SImode)\n+\t    {\n+\t      if (arm_arch6)\n+\t\t{\n+\t\t  if (GET_CODE (XEXP (x, 0)) != MEM)\n+\t\t    *total += COSTS_N_INSNS (1);\n+\t\t}\n+\t      else if (!arm_arch4 || GET_CODE (XEXP (x, 0)) != MEM)\n+\t\t*total += COSTS_N_INSNS (GET_MODE (XEXP (x, 0)) == QImode ?\n+\t\t\t\t\t 1 : 2);\n+\t    }\n \n-\tcase SImode:\n-\t  return (1 + (GET_CODE (XEXP (x, 0)) == MEM ? 10 : 0));\n+\t  return false;\n+\t}\n \n+      switch (GET_MODE (XEXP (x, 0)))\n+\t{\n \tcase V8QImode:\n \tcase V4HImode:\n \tcase V2SImode:\n \tcase V4QImode:\n \tcase V2HImode:\n-\t    return 1;\n+\t  *total = COSTS_N_INSNS (1);\n+\t  return false;\n \n \tdefault:\n \t  gcc_unreachable ();\n \t}\n       gcc_unreachable ();\n \n+    case ZERO_EXTRACT:\n+    case SIGN_EXTRACT:\n+      *total = COSTS_N_INSNS (1) + rtx_cost (XEXP (x, 0), code, speed);\n+      return true;\n+\n     case CONST_INT:\n-      if (const_ok_for_arm (INTVAL (x)))\n-\treturn outer == SET ? 2 : -1;\n-      else if (outer == AND\n-\t       && const_ok_for_arm (~INTVAL (x)))\n-\treturn -1;\n-      else if ((outer == COMPARE\n-\t\t|| outer == PLUS || outer == MINUS)\n-\t       && const_ok_for_arm (-INTVAL (x)))\n-\treturn -1;\n+      if (const_ok_for_arm (INTVAL (x))\n+\t  || const_ok_for_arm (~INTVAL (x)))\n+\t*total = COSTS_N_INSNS (1);\n       else\n-\treturn 5;\n+\t*total = COSTS_N_INSNS (arm_gen_constant (SET, mode, NULL_RTX,\n+\t\t\t\t\t\t  INTVAL (x), NULL_RTX,\n+\t\t\t\t\t\t  NULL_RTX, 0, 0));\n+      return true;\n \n     case CONST:\n     case LABEL_REF:\n     case SYMBOL_REF:\n-      return 6;\n+      *total = COSTS_N_INSNS (3);\n+      return true;\n \n     case HIGH:\n+      *total = COSTS_N_INSNS (1);\n+      return true;\n+\n     case LO_SUM:\n-      return (outer == SET) ? 1 : -1;\n+      *total = COSTS_N_INSNS (1);\n+      *total += rtx_cost (XEXP (x, 0), code, speed);\n+      return true;\n \n     case CONST_DOUBLE:\n-      if (arm_const_double_rtx (x) || vfp3_const_double_rtx (x))\n-\treturn outer == SET ? 2 : -1;\n-      else if ((outer == COMPARE || outer == PLUS)\n-\t       && neg_const_double_rtx_ok_for_fpa (x))\n-\treturn -1;\n-      return 7;\n+      if (TARGET_HARD_FLOAT && vfp3_const_double_rtx (x))\n+\t*total = COSTS_N_INSNS (1);\n+      else\n+\t*total = COSTS_N_INSNS (4);\n+      return true;\n \n     default:\n-      return 99;\n+      *total = COSTS_N_INSNS (4);\n+      return false;\n     }\n }\n \n /* RTX costs when optimizing for size.  */\n static bool\n-arm_size_rtx_costs (rtx x, int code, int outer_code, int *total)\n+arm_size_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer_code,\n+\t\t    int *total)\n {\n   enum machine_mode mode = GET_MODE (x);\n-\n   if (TARGET_THUMB1)\n     {\n       /* XXX TBD.  For now, use the standard costs.  */\n@@ -5395,19 +5710,22 @@ arm_size_rtx_costs (rtx x, int code, int outer_code, int *total)\n \n /* RTX costs when optimizing for size.  */\n static bool\n-arm_rtx_costs (rtx x, int code, int outer_code, int *total, bool speed)\n+arm_rtx_costs (rtx x, int code, int outer_code, int *total,\n+\t       bool speed)\n {\n   if (!speed)\n     return arm_size_rtx_costs (x, code, outer_code, total);\n   else\n-    return all_cores[(int)arm_tune].rtx_costs (x, code, outer_code, total);\n+    return all_cores[(int)arm_tune].rtx_costs (x, code, outer_code, total,\n+\t\t\t\t\t       speed);\n }\n \n /* RTX costs for cores with a slow MUL implementation.  Thumb-2 is not\n    supported on any \"slowmul\" cores, so it can be ignored.  */\n \n static bool\n-arm_slowmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n+arm_slowmul_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer_code,\n+\t\t       int *total, bool speed)\n {\n   enum machine_mode mode = GET_MODE (x);\n \n@@ -5423,8 +5741,8 @@ arm_slowmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n       if (GET_MODE_CLASS (mode) == MODE_FLOAT\n \t  || mode == DImode)\n \t{\n-\t  *total = 30;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS (20);\n+\t  return false;\n \t}\n \n       if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n@@ -5440,28 +5758,28 @@ arm_slowmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  for (j = 0; i && j < 32; j += booth_unit_size)\n \t    {\n \t      i >>= booth_unit_size;\n-\t      cost += 2;\n+\t      cost++;\n \t    }\n \n-\t  *total = cost;\n+\t  *total = COSTS_N_INSNS (cost);\n+\t  *total += rtx_cost (XEXP (x, 0), code, speed);\n \t  return true;\n \t}\n \n-      *total = 30 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 4)\n-\t          + (REG_OR_SUBREG_REG (XEXP (x, 1)) ? 0 : 4);\n-      return true;\n+      *total = COSTS_N_INSNS (20);\n+      return false;\n \n     default:\n-      *total = arm_rtx_costs_1 (x, code, outer_code);\n-      return true;\n+      return arm_rtx_costs_1 (x, outer_code, total, speed);;\n     }\n }\n \n \n /* RTX cost for cores with a fast multiply unit (M variants).  */\n \n static bool\n-arm_fastmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n+arm_fastmul_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer_code,\n+\t\t       int *total, bool speed)\n {\n   enum machine_mode mode = GET_MODE (x);\n \n@@ -5482,16 +5800,15 @@ arm_fastmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  && (GET_CODE (XEXP (x, 0)) == ZERO_EXTEND\n \t      || GET_CODE (XEXP (x, 0)) == SIGN_EXTEND))\n \t{\n-\t  *total = 8;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS(2);\n+\t  return false;\n \t}\n \n \n-      if (GET_MODE_CLASS (mode) == MODE_FLOAT\n-\t  || mode == DImode)\n+      if (mode == DImode)\n \t{\n-\t  *total = 30;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS (5);\n+\t  return false;\n \t}\n \n       if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n@@ -5507,20 +5824,34 @@ arm_fastmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  for (j = 0; i && j < 32; j += booth_unit_size)\n \t    {\n \t      i >>= booth_unit_size;\n-\t      cost += 2;\n+\t      cost++;\n \t    }\n \n-\t  *total = cost;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS(cost);\n+\t  return false;\n \t}\n \n-      *total = 8 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 4)\n-\t         + (REG_OR_SUBREG_REG (XEXP (x, 1)) ? 0 : 4);\n-      return true;\n+      if (mode == SImode)\n+\t{\n+\t  *total = COSTS_N_INSNS (4);\n+\t  return false;\n+\t}\n+\n+      if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n+\t{\n+\t  if (TARGET_HARD_FLOAT && (mode == SFmode || mode == DFmode))\n+\t    {\n+\t      *total = COSTS_N_INSNS (1);\n+\t      return false;\n+\t    }\n+\t}\n+\n+      /* Requires a lib call */\n+      *total = COSTS_N_INSNS (20);\n+      return false;\n \n     default:\n-      *total = arm_rtx_costs_1 (x, code, outer_code);\n-      return true;\n+      return arm_rtx_costs_1 (x, outer_code, total, speed);\n     }\n }\n \n@@ -5529,7 +5860,7 @@ arm_fastmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n    so it can be ignored.  */\n \n static bool\n-arm_xscale_rtx_costs (rtx x, int code, int outer_code, int *total)\n+arm_xscale_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer_code, int *total, bool speed)\n {\n   enum machine_mode mode = GET_MODE (x);\n \n@@ -5541,6 +5872,15 @@ arm_xscale_rtx_costs (rtx x, int code, int outer_code, int *total)\n \n   switch (code)\n     {\n+    case COMPARE:\n+      if (GET_CODE (XEXP (x, 0)) != MULT)\n+\treturn arm_rtx_costs_1 (x, outer_code, total, speed);\n+\n+      /* A COMPARE of a MULT is slow on XScale; the muls instruction\n+\t will stall until the multiplication is complete.  */\n+      *total = COSTS_N_INSNS (3);\n+      return false;\n+\n     case MULT:\n       /* There is no point basing this on the tuning, since it is always the\n \t fast variant if it exists at all.  */\n@@ -5549,72 +5889,69 @@ arm_xscale_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  && (GET_CODE (XEXP (x, 0)) == ZERO_EXTEND\n \t      || GET_CODE (XEXP (x, 0)) == SIGN_EXTEND))\n \t{\n-\t  *total = 8;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS (2);\n+\t  return false;\n \t}\n \n \n-      if (GET_MODE_CLASS (mode) == MODE_FLOAT\n-\t  || mode == DImode)\n+      if (mode == DImode)\n \t{\n-\t  *total = 30;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS (5);\n+\t  return false;\n \t}\n \n       if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n \t{\n-\t  unsigned HOST_WIDE_INT i = (INTVAL (XEXP (x, 1))\n-\t\t\t\t      & (unsigned HOST_WIDE_INT) 0xffffffff);\n-\t  int cost, const_ok = const_ok_for_arm (i);\n+\t  /* If operand 1 is a constant we can more accurately\n+\t     calculate the cost of the multiply.  The multiplier can\n+\t     retire 15 bits on the first cycle and a further 12 on the\n+\t     second.  We do, of course, have to load the constant into\n+\t     a register first.  */\n+\t  unsigned HOST_WIDE_INT i = INTVAL (XEXP (x, 1));\n+\t  /* There's a general overhead of one cycle.  */\n+\t  int cost = 1;\n \t  unsigned HOST_WIDE_INT masked_const;\n \n-\t  /* The cost will be related to two insns.\n-\t     First a load of the constant (MOV or LDR), then a multiply.  */\n-\t  cost = 2;\n-\t  if (! const_ok)\n-\t    cost += 1;      /* LDR is probably more expensive because\n-\t\t\t       of longer result latency.  */\n+\t  if (i & 0x80000000)\n+\t    i = ~i;\n+\n+\t  i &= (unsigned HOST_WIDE_INT) 0xffffffff;\n+\n \t  masked_const = i & 0xffff8000;\n-\t  if (masked_const != 0 && masked_const != 0xffff8000)\n+\t  if (masked_const != 0)\n \t    {\n+\t      cost++;\n \t      masked_const = i & 0xf8000000;\n-\t      if (masked_const == 0 || masked_const == 0xf8000000)\n-\t\tcost += 1;\n-\t      else\n-\t\tcost += 2;\n+\t      if (masked_const != 0)\n+\t\tcost++;\n \t    }\n-\t  *total = cost;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS (cost);\n+\t  return false;\n \t}\n \n-      *total = 8 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 4)\n-\t\t + (REG_OR_SUBREG_REG (XEXP (x, 1)) ? 0 : 4);\n-      return true;\n+      if (mode == SImode)\n+\t{\n+\t  *total = COSTS_N_INSNS (3);\n+\t  return false;\n+\t}\n \n-    case COMPARE:\n-      /* A COMPARE of a MULT is slow on XScale; the muls instruction\n-\t will stall until the multiplication is complete.  */\n-      if (GET_CODE (XEXP (x, 0)) == MULT)\n-\t*total = 4 + rtx_cost (XEXP (x, 0), code, true);\n-      else\n-\t*total = arm_rtx_costs_1 (x, code, outer_code);\n-      return true;\n+      /* Requires a lib call */\n+      *total = COSTS_N_INSNS (20);\n+      return false;\n \n     default:\n-      *total = arm_rtx_costs_1 (x, code, outer_code);\n-      return true;\n+      return arm_rtx_costs_1 (x, outer_code, total, speed);\n     }\n }\n \n \n /* RTX costs for 9e (and later) cores.  */\n \n static bool\n-arm_9e_rtx_costs (rtx x, int code, int outer_code, int *total)\n+arm_9e_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer_code,\n+\t\t  int *total, bool speed)\n {\n   enum machine_mode mode = GET_MODE (x);\n-  int nonreg_cost;\n-  int cost;\n \n   if (TARGET_THUMB1)\n     {\n@@ -5640,35 +5977,37 @@ arm_9e_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  && (GET_CODE (XEXP (x, 0)) == ZERO_EXTEND\n \t      || GET_CODE (XEXP (x, 0)) == SIGN_EXTEND))\n \t{\n-\t  *total = 3;\n-\t  return true;\n+\t  *total = COSTS_N_INSNS (2);\n+\t  return false;\n \t}\n \n \n-      if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n-\t{\n-\t  *total = 30;\n-\t  return true;\n-\t}\n       if (mode == DImode)\n \t{\n-\t  cost = 7;\n-\t  nonreg_cost = 8;\n+\t  *total = COSTS_N_INSNS (5);\n+\t  return false;\n \t}\n-      else\n+\n+      if (mode == SImode)\n \t{\n-\t  cost = 2;\n-\t  nonreg_cost = 4;\n+\t  *total = COSTS_N_INSNS (2);\n+\t  return false;\n \t}\n \n+      if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n+\t{\n+\t  if (TARGET_HARD_FLOAT && (mode == SFmode || mode == DFmode))\n+\t    {\n+\t      *total = COSTS_N_INSNS (1);\n+\t      return false;\n+\t    }\n+\t}\n \n-      *total = cost + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : nonreg_cost)\n-\t\t    + (REG_OR_SUBREG_REG (XEXP (x, 1)) ? 0 : nonreg_cost);\n-      return true;\n+      *total = COSTS_N_INSNS (20);\n+      return false;\n \n     default:\n-      *total = arm_rtx_costs_1 (x, code, outer_code);\n-      return true;\n+      return arm_rtx_costs_1 (x, outer_code, total, speed);\n     }\n }\n /* All address computations that can be done are free, but rtx cost returns"}]}