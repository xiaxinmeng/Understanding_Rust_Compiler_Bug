{"sha": "2747a04662929c37d3bcc96c36adc861a4611710", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Mjc0N2EwNDY2MjkyOWMzN2QzYmNjOTZjMzZhZGM4NjFhNDYxMTcxMA==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2011-11-14T22:59:02Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2011-11-14T22:59:02Z"}, "message": "rs6000: Rewrite sync patterns for atomic; expand early.\n\nThe conversion of the __sync post-reload splitters was half\ncomplete.  Since there are nearly no restrictions on what may\nappear between LL and SC, expand all the patterns immediatly.\nThis allows significantly easier code generation for subword\natomic operations.\n\nFrom-SVN: r181370", "tree": {"sha": "61b67f6c9c5cdb2532017d38c67327e51d93fe99", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/61b67f6c9c5cdb2532017d38c67327e51d93fe99"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2747a04662929c37d3bcc96c36adc861a4611710", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2747a04662929c37d3bcc96c36adc861a4611710", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2747a04662929c37d3bcc96c36adc861a4611710", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2747a04662929c37d3bcc96c36adc861a4611710/comments", "author": null, "committer": null, "parents": [{"sha": "674a3581477f9d0c8f802e242eed89aa53b95032", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/674a3581477f9d0c8f802e242eed89aa53b95032", "html_url": "https://github.com/Rust-GCC/gccrs/commit/674a3581477f9d0c8f802e242eed89aa53b95032"}], "stats": {"total": 1446, "additions": 582, "deletions": 864}, "files": [{"sha": "13de48b055291a04669915bd448c758a78677fd3", "filename": "gcc/ChangeLog", "status": "modified", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=2747a04662929c37d3bcc96c36adc861a4611710", "patch": "@@ -1,3 +1,58 @@\n+2011-11-14  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/rs6000/rs6000.c (emit_load_locked): Assert the mode is handled.\n+\t(emit_store_conditional): Likewise.\n+\t(rs6000_pre_atomic_barrier, rs6000_post_atomic_barrier): New.\n+\t(rs6000_adjust_atomic_subword): New.\n+\t(rs6000_mask_atomic_subword, rs6000_finish_atomic_subword): New.\n+\t(rs6000_expand_atomic_op): Rename from rs6000_emit_sync; rewrite\n+\tfor pre-reload expansion.\n+\t(rs6000_split_compare_and_swap, rs6000_split_compare_and_swapqhi,\n+\trs6000_expand_compare_and_swapqhi): Merge into ...\n+\t(rs6000_expand_atomic_compare_and_swap): ... here.  New function.\n+\trs6000_split_lock_test_and_set; expand immediately.  Handle\n+\tQImode and HImode.\n+\t* config/rs6000/rs6000.md (UNSPEC_LWSYNC): Move and rename\n+\tfrom UNSPECV_LWSYNC.\n+\t* config/rs6000/sync.md (fetchopsi_constr, fetchopdi_constr): Remove.\n+\t(mem_thread_fence): New.\n+\t(hwsync): Rename from memory_barrier.\n+\t(*hwsync): Rename from *sync_internal.\n+\t(lwsync, *lwsync): Mirror hwsync implementation.\n+\t(isync): Don't reference memory.\n+\t(loadsync): New.\n+\t(atomic_load<INT>, atomic_store<INT>): New.\n+\t(ATOMIC): New mode iterator.\n+\t(load_locked<ATOMIC>): Rename from load_locked_<GPR>.\n+\t(store_conditional<ATOMIC>): Rename from store_conditional_<GPR>.\n+\t(sync_compare_and_swap<GPR>): Remove.\n+\t(sync_compare_and_swaphi, sync_compare_and_swapqi): Remove.\n+\t(sync_compare_and_swapqhi_internal): Remove.\n+\t(sync_lock_test_and_set<GPR>): Remove.\n+\t(sync_<FETCHOP><INT1>): Remove.\n+\t(*sync_<FETCHOP>si_internal, *sync_<FETCHOP>di_internal): Remove.\n+\t(sync_nand<INT1>, *sync_nand<GPR>_internal): Remove.\n+\t(sync_old_<FETCHOP><GPR>): Remove.\n+\t(*sync_old_<FETCHOP>si_internal): Remove.\n+\t(*sync_old_<FETCHOP>di_internal): Remove.\n+\t(sync_old_nand<INT1>): Remove.\n+\t(*sync_old_nand<GPR>_internal): Remove.\n+\t(sync_new_<FETCHOP><GPR>): Remove.\n+\t(*sync_new_<FETCHOP>si_internal): Remove.\n+\t(*sync_new_<FETCHOP>di_internal): Remove.\n+\t(sync_new_nand<INT1>): Remove.\n+\t(*sync_new_nand<GPR>_internal): Remove.\n+\t(*atomic_andsi, *atomic_anddi): Remove.\n+\t(*sync_addshort_internal, *sync_subshort_internal): Remove.\n+\t(*sync_andsi_internal, *sync_boolsi_internal): Remove.\n+\t(*sync_boolcshort_internal): Remove.\n+\t(sync_lock_release<INT1>): Remove.\n+\t(atomic_compare_and_swap<INT1>): New.\n+\t(atomic_exchange<INT1>): New.\n+\t(atomic_<FETCHOP><INT1>, atomic_nand<INT1>): New.\n+\t(atomic_fetch_<FETCHOP><INT1>, atomic_fetch_nand<INT1>): New.\n+\t(atomic_<FETCHOP>_fetch<INT1>, atomic_nand_fetch<INT1>): New.\n+\n 2011-11-14  Uros Bizjak  <ubizjak@gmail.com>\n \n \t* config/i386/sse.md (round<mode>2): Use register_operand for"}, {"sha": "af4c95488def4c5dfc484548fe04f99c9ea485fd", "filename": "gcc/config/rs6000/rs6000-protos.h", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Frs6000-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Frs6000-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-protos.h?ref=2747a04662929c37d3bcc96c36adc861a4611710", "patch": "@@ -103,13 +103,9 @@ extern rtx rs6000_emit_set_const (rtx, enum machine_mode, rtx, int);\n extern int rs6000_emit_cmove (rtx, rtx, rtx, rtx);\n extern int rs6000_emit_vector_cond_expr (rtx, rtx, rtx, rtx, rtx, rtx);\n extern void rs6000_emit_minmax (rtx, enum rtx_code, rtx, rtx);\n-extern void rs6000_emit_sync (enum rtx_code, enum machine_mode,\n-\t\t\t      rtx, rtx, rtx, rtx, bool);\n-extern void rs6000_split_atomic_op (enum rtx_code, rtx, rtx, rtx, rtx, rtx);\n-extern void rs6000_split_compare_and_swap (rtx, rtx, rtx, rtx, rtx);\n-extern void rs6000_expand_compare_and_swapqhi (rtx, rtx, rtx, rtx);\n-extern void rs6000_split_compare_and_swapqhi (rtx, rtx, rtx, rtx, rtx, rtx);\n-extern void rs6000_split_lock_test_and_set (rtx, rtx, rtx, rtx);\n+extern void rs6000_expand_atomic_compare_and_swap (rtx op[]);\n+extern void rs6000_expand_atomic_exchange (rtx op[]);\n+extern void rs6000_expand_atomic_op (enum rtx_code, rtx, rtx, rtx, rtx, rtx);\n extern void rs6000_emit_swdiv (rtx, rtx, rtx, bool);\n extern void rs6000_emit_swrsqrt (rtx, rtx);\n extern void output_toc (FILE *, rtx, int, enum machine_mode);"}, {"sha": "4436ed0e2055c4842e4dc8c0b029f77c2e6813f9", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 340, "deletions": 335, "changes": 675, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=2747a04662929c37d3bcc96c36adc861a4611710", "patch": "@@ -17133,199 +17133,6 @@ rs6000_emit_minmax (rtx dest, enum rtx_code code, rtx op0, rtx op1)\n     emit_move_insn (dest, target);\n }\n \n-/* Emit instructions to perform a load-reserved/store-conditional operation.\n-   The operation performed is an atomic\n-   (set M (CODE:MODE M OP))\n-   If not NULL, BEFORE is atomically set to M before the operation, and\n-   AFTER is set to M after the operation (that is, (CODE:MODE M OP)).\n-   If SYNC_P then a memory barrier is emitted before the operation.\n-   Either OP or M may be wrapped in a NOT operation.  */\n-\n-void\n-rs6000_emit_sync (enum rtx_code code, enum machine_mode mode,\n-\t\t  rtx m, rtx op, rtx before_param, rtx after_param,\n-\t\t  bool sync_p)\n-{\n-  enum machine_mode used_mode;\n-  rtx the_op, set_before, set_after, set_atomic, cc_scratch, before, after;\n-  rtx used_m;\n-  rtvec vec;\n-  HOST_WIDE_INT imask = GET_MODE_MASK (mode);\n-  rtx shift = NULL_RTX;\n-\n-  if (sync_p)\n-    emit_insn (gen_lwsync ());\n-\n-    used_m = m;\n-\n-  /* If this is smaller than SImode, we'll have to use SImode with\n-     adjustments.  */\n-  if (mode == QImode || mode == HImode)\n-    {\n-      rtx newop, oldop;\n-\n-      if (MEM_ALIGN (used_m) >= 32)\n-\t{\n-\t  int ishift = 0;\n-\t  if (BYTES_BIG_ENDIAN)\n-\t    ishift = GET_MODE_BITSIZE (SImode) - GET_MODE_BITSIZE (mode);\n-\n-\t  shift = GEN_INT (ishift);\n-\t  used_m = change_address (used_m, SImode, 0);\n-\t}\n-      else\n-\t{\n-\t  rtx addrSI, aligned_addr;\n-\t  int shift_mask = mode == QImode ? 0x18 : 0x10;\n-\n-\t  addrSI = gen_lowpart_common (SImode,\n-\t\t\t\t       force_reg (Pmode, XEXP (used_m, 0)));\n-\t  addrSI = force_reg (SImode, addrSI);\n-\t  shift = gen_reg_rtx (SImode);\n-\n-\t  emit_insn (gen_rlwinm (shift, addrSI, GEN_INT (3),\n-\t\t\t\t GEN_INT (shift_mask)));\n-\t  emit_insn (gen_xorsi3 (shift, shift, GEN_INT (shift_mask)));\n-\n-\t  aligned_addr = expand_binop (Pmode, and_optab,\n-\t\t\t\t       XEXP (used_m, 0),\n-\t\t\t\t       GEN_INT (-4), NULL_RTX,\n-\t\t\t\t       1, OPTAB_LIB_WIDEN);\n-\t  used_m = change_address (used_m, SImode, aligned_addr);\n-\t  set_mem_align (used_m, 32);\n-\t}\n-      /* It's safe to keep the old alias set of USED_M, because\n-\t the operation is atomic and only affects the original\n-\t USED_M.  */\n-      m = used_m;\n-\n-      if (GET_CODE (op) == NOT)\n-\t{\n-\t  oldop = lowpart_subreg (SImode, XEXP (op, 0), mode);\n-\t  oldop = gen_rtx_NOT (SImode, oldop);\n-\t}\n-      else\n-\toldop = lowpart_subreg (SImode, op, mode);\n-\n-      switch (code)\n-\t{\n-\tcase IOR:\n-\tcase XOR:\n-\t  newop = expand_binop (SImode, and_optab,\n-\t\t\t\toldop, GEN_INT (imask), NULL_RTX,\n-\t\t\t\t1, OPTAB_LIB_WIDEN);\n-\t  emit_insn (gen_ashlsi3 (newop, newop, shift));\n-\t  break;\n-\n-\tcase NOT: /* NAND */\n-\t  newop = expand_binop (SImode, ior_optab,\n-\t\t\t\toldop, GEN_INT (~imask), NULL_RTX,\n-\t\t\t\t1, OPTAB_LIB_WIDEN);\n-\t  emit_insn (gen_rotlsi3 (newop, newop, shift));\n-\t  break;\n-\n-\tcase AND:\n-\t  newop = expand_binop (SImode, ior_optab,\n-\t\t\t\toldop, GEN_INT (~imask), NULL_RTX,\n-\t\t\t\t1, OPTAB_LIB_WIDEN);\n-\t  emit_insn (gen_rotlsi3 (newop, newop, shift));\n-\t  break;\n-\n-\tcase PLUS:\n-\tcase MINUS:\n-\t  {\n-\t    rtx mask;\n-\n-\t    newop = expand_binop (SImode, and_optab,\n-\t\t\t\t  oldop, GEN_INT (imask), NULL_RTX,\n-\t\t\t\t  1, OPTAB_LIB_WIDEN);\n-\t    emit_insn (gen_ashlsi3 (newop, newop, shift));\n-\n-\t    mask = gen_reg_rtx (SImode);\n-\t    emit_move_insn (mask, GEN_INT (imask));\n-\t    emit_insn (gen_ashlsi3 (mask, mask, shift));\n-\n-\t    if (code == PLUS)\n-\t      newop = gen_rtx_PLUS (SImode, m, newop);\n-\t    else\n-\t      newop = gen_rtx_MINUS (SImode, m, newop);\n-\t    newop = gen_rtx_AND (SImode, newop, mask);\n-\t    newop = gen_rtx_IOR (SImode, newop,\n-\t\t\t\t gen_rtx_AND (SImode,\n-\t\t\t\t\t      gen_rtx_NOT (SImode, mask),\n-\t\t\t\t\t      m));\n-\t    break;\n-\t  }\n-\n-\tdefault:\n-\t  gcc_unreachable ();\n-\t}\n-\n-      op = newop;\n-      used_mode = SImode;\n-      before = gen_reg_rtx (used_mode);\n-      after = gen_reg_rtx (used_mode);\n-    }\n-  else\n-    {\n-      used_mode = mode;\n-      before = before_param;\n-      after = after_param;\n-\n-      if (before == NULL_RTX)\n-\tbefore = gen_reg_rtx (used_mode);\n-      if (after == NULL_RTX)\n-\tafter = gen_reg_rtx (used_mode);\n-    }\n-\n-  if ((code == PLUS || code == MINUS)\n-      && used_mode != mode)\n-    the_op = op;  /* Computed above.  */\n-  else if (GET_CODE (op) == NOT && GET_CODE (m) != NOT)\n-    the_op = gen_rtx_fmt_ee (code, used_mode, op, m);\n-  else if (code == NOT)\n-    the_op = gen_rtx_fmt_ee (IOR, used_mode,\n-\t\t\t     gen_rtx_NOT (used_mode, m),\n-\t\t\t     gen_rtx_NOT (used_mode, op));\n-  else\n-    the_op = gen_rtx_fmt_ee (code, used_mode, m, op);\n-\n-  set_after = gen_rtx_SET (VOIDmode, after, the_op);\n-  set_before = gen_rtx_SET (VOIDmode, before, used_m);\n-  set_atomic = gen_rtx_SET (VOIDmode, used_m,\n-\t\t\t    gen_rtx_UNSPEC (used_mode,\n-\t\t\t\t\t    gen_rtvec (1, the_op),\n-\t\t\t\t\t    UNSPEC_SYNC_OP));\n-  cc_scratch = gen_rtx_CLOBBER (VOIDmode, gen_rtx_SCRATCH (CCmode));\n-\n-  if ((code == PLUS || code == MINUS) && used_mode != mode)\n-    vec = gen_rtvec (5, set_after, set_before, set_atomic, cc_scratch,\n-\t\t     gen_rtx_CLOBBER (VOIDmode, gen_rtx_SCRATCH (SImode)));\n-  else\n-    vec = gen_rtvec (4, set_after, set_before, set_atomic, cc_scratch);\n-  emit_insn (gen_rtx_PARALLEL (VOIDmode, vec));\n-\n-  /* Shift and mask the return values properly.  */\n-  if (used_mode != mode && before_param)\n-    {\n-      emit_insn (gen_lshrsi3 (before, before, shift));\n-      convert_move (before_param, before, 1);\n-    }\n-\n-  if (used_mode != mode && after_param)\n-    {\n-      emit_insn (gen_lshrsi3 (after, after, shift));\n-      convert_move (after_param, after, 1);\n-    }\n-\n-  /* The previous sequence will end with a branch that's dependent on\n-     the conditional store, so placing an isync will ensure that no\n-     other instructions (especially, no load or store instructions)\n-     can start before the atomic operation completes.  */\n-  if (sync_p)\n-    emit_insn (gen_isync ());\n-}\n-\n /* A subroutine of the atomic operation splitters.  Jump to LABEL if\n    COND is true.  Mark the jump as unlikely to be taken.  */\n \n@@ -17347,10 +17154,18 @@ static void\n emit_load_locked (enum machine_mode mode, rtx reg, rtx mem)\n {\n   rtx (*fn) (rtx, rtx) = NULL;\n-  if (mode == SImode)\n-    fn = gen_load_locked_si;\n-  else if (mode == DImode)\n-    fn = gen_load_locked_di;\n+\n+  switch (mode)\n+    {\n+    case SImode:\n+      fn = gen_load_lockedsi;\n+      break;\n+    case DImode:\n+      fn = gen_load_lockeddi;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n   emit_insn (fn (reg, mem));\n }\n \n@@ -17361,214 +17176,404 @@ static void\n emit_store_conditional (enum machine_mode mode, rtx res, rtx mem, rtx val)\n {\n   rtx (*fn) (rtx, rtx, rtx) = NULL;\n-  if (mode == SImode)\n-    fn = gen_store_conditional_si;\n-  else if (mode == DImode)\n-    fn = gen_store_conditional_di;\n+\n+  switch (mode)\n+    {\n+    case SImode:\n+      fn = gen_store_conditionalsi;\n+      break;\n+    case DImode:\n+      fn = gen_store_conditionaldi;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n \n   /* Emit sync before stwcx. to address PPC405 Erratum.  */\n   if (PPC405_ERRATUM77)\n-    emit_insn (gen_memory_barrier ());\n+    emit_insn (gen_hwsync ());\n \n   emit_insn (fn (res, mem, val));\n }\n \n-/* Expand an atomic fetch-and-operate pattern.  CODE is the binary operation\n-   to perform.  MEM is the memory on which to operate.  VAL is the second\n-   operand of the binary operator.  BEFORE and AFTER are optional locations to\n-   return the value of MEM either before of after the operation.  SCRATCH is\n-   a scratch register.  */\n+/* Expand barriers before and after a load_locked/store_cond sequence.  */\n \n-void\n-rs6000_split_atomic_op (enum rtx_code code, rtx mem, rtx val,\n-                       rtx before, rtx after, rtx scratch)\n+static void\n+rs6000_pre_atomic_barrier (enum memmodel model)\n+{\n+  switch (model)\n+    {\n+    case MEMMODEL_RELAXED:\n+    case MEMMODEL_CONSUME:\n+    case MEMMODEL_ACQUIRE:\n+      break;\n+    case MEMMODEL_RELEASE:\n+    case MEMMODEL_ACQ_REL:\n+      emit_insn (gen_lwsync ());\n+      break;\n+    case MEMMODEL_SEQ_CST:\n+      emit_insn (gen_hwsync ());\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+static void\n+rs6000_post_atomic_barrier (enum memmodel model)\n+{\n+  switch (model)\n+    {\n+    case MEMMODEL_RELAXED:\n+    case MEMMODEL_CONSUME:\n+    case MEMMODEL_RELEASE:\n+      break;\n+    case MEMMODEL_ACQUIRE:\n+    case MEMMODEL_ACQ_REL:\n+    case MEMMODEL_SEQ_CST:\n+      emit_insn (gen_isync ());\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* A subroutine of the various atomic expanders.  For sub-word operations,\n+   we must adjust things to operate on SImode.  Given the original MEM,\n+   return a new aligned memory.  Also build and return the quantities by\n+   which to shift and mask.  */\n+\n+static rtx\n+rs6000_adjust_atomic_subword (rtx mem, rtx *pshift, rtx *pmask)\n {\n+  rtx addr, align, shift, mask;\n+  HOST_WIDE_INT shift_mask;\n   enum machine_mode mode = GET_MODE (mem);\n-  rtx label, x, cond = gen_rtx_REG (CCmode, CR0_REGNO);\n \n-  emit_insn (gen_lwsync ());\n+  /* For smaller modes, we have to implement this via SImode.  */\n+  shift_mask = (mode == QImode ? 0x18 : 0x10);\n \n-  label = gen_label_rtx ();\n-  emit_label (label);\n-  label = gen_rtx_LABEL_REF (VOIDmode, label);\n+  addr = XEXP (mem, 0);\n+  addr = force_reg (GET_MODE (addr), addr);\n+\n+  /* Aligned memory containing subword.  Generate a new memory.  We\n+     do not want any of the existing MEM_ATTR data, as we're now\n+     accessing memory outside the original object.  */\n+  align = expand_simple_binop (Pmode, AND, addr, GEN_INT (-4),\n+\t\t\t       NULL_RTX, 1, OPTAB_LIB_WIDEN);\n+  mem = gen_rtx_MEM (SImode, align);\n+  MEM_VOLATILE_P (mem) = 1;\n \n-  if (before == NULL_RTX)\n-    before = scratch;\n-  emit_load_locked (mode, before, mem);\n+  /* Shift amount for subword relative to aligned word.  */\n+  shift = gen_reg_rtx (SImode);\n+  addr = gen_lowpart (SImode, addr);\n+  emit_insn (gen_rlwinm (shift, addr, GEN_INT (3), GEN_INT (shift_mask)));\n+  shift = expand_simple_binop (SImode, XOR, shift, GEN_INT (shift_mask),\n+\t\t\t       shift, 1, OPTAB_LIB_WIDEN);\n+  *pshift = shift;\n \n-  if (code == NOT)\n-    x = gen_rtx_IOR (mode,\n-\t\t     gen_rtx_NOT (mode, before),\n-\t\t     gen_rtx_NOT (mode, val));\n-  else if (code == AND)\n-    x = gen_rtx_UNSPEC (mode, gen_rtvec (2, before, val), UNSPEC_AND);\n-  else\n-    x = gen_rtx_fmt_ee (code, mode, before, val);\n+  /* Mask for insertion.  */\n+  mask = expand_simple_binop (SImode, ASHIFT, GEN_INT (GET_MODE_MASK (mode)),\n+\t\t\t      shift, NULL_RTX, 1, OPTAB_LIB_WIDEN);\n+  *pmask = mask;\n \n-  if (after != NULL_RTX)\n-    emit_insn (gen_rtx_SET (VOIDmode, after, copy_rtx (x)));\n-  emit_insn (gen_rtx_SET (VOIDmode, scratch, x));\n+  return mem;\n+}\n \n-  emit_store_conditional (mode, cond, mem, scratch);\n+/* A subroutine of the various atomic expanders.  For sub-word operands,\n+   combine OLDVAL and NEWVAL via MASK.  Returns a new pseduo.  */\n \n-  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n-  emit_unlikely_jump (x, label);\n+static rtx\n+rs6000_mask_atomic_subword (rtx oldval, rtx newval, rtx mask)\n+{\n+  rtx x;\n \n-  emit_insn (gen_isync ());\n+  x = gen_reg_rtx (SImode);\n+  emit_insn (gen_rtx_SET (VOIDmode, x,\n+\t\t\t  gen_rtx_AND (SImode,\n+\t\t\t\t       gen_rtx_NOT (SImode, mask),\n+\t\t\t\t       oldval)));\n+\n+  x = expand_simple_binop (SImode, IOR, newval, x, x, 1, OPTAB_LIB_WIDEN);\n+\n+  return x;\n+}\n+\n+/* A subroutine of the various atomic expanders.  For sub-word operands,\n+   extract WIDE to NARROW via SHIFT.  */\n+\n+static void\n+rs6000_finish_atomic_subword (rtx narrow, rtx wide, rtx shift)\n+{\n+  wide = expand_simple_binop (SImode, LSHIFTRT, wide, shift,\n+\t\t\t      wide, 1, OPTAB_LIB_WIDEN);\n+  emit_move_insn (narrow, gen_lowpart (GET_MODE (narrow), wide));\n }\n \n-/* Expand an atomic compare and swap operation.  MEM is the memory on which\n-   to operate.  OLDVAL is the old value to be compared.  NEWVAL is the new\n-   value to be stored.  SCRATCH is a scratch GPR.  */\n+/* Expand an atomic compare and swap operation.  */\n \n void\n-rs6000_split_compare_and_swap (rtx retval, rtx mem, rtx oldval, rtx newval,\n-\t\t\t       rtx scratch)\n+rs6000_expand_atomic_compare_and_swap (rtx operands[])\n {\n-  enum machine_mode mode = GET_MODE (mem);\n-  rtx label1, label2, x, cond = gen_rtx_REG (CCmode, CR0_REGNO);\n+  rtx boolval, retval, mem, oldval, newval, cond;\n+  rtx label1, label2, x, mask, shift;\n+  enum machine_mode mode;\n+  enum memmodel mod_s, mod_f;\n+  bool is_weak;\n+\n+  boolval = operands[0];\n+  retval = operands[1];\n+  mem = operands[2];\n+  oldval = operands[3];\n+  newval = operands[4];\n+  is_weak = (INTVAL (operands[5]) != 0);\n+  mod_s = (enum memmodel) INTVAL (operands[6]);\n+  mod_f = (enum memmodel) INTVAL (operands[7]);\n+  mode = GET_MODE (mem);\n+\n+  mask = shift = NULL_RTX;\n+  if (mode == QImode || mode == HImode)\n+    {\n+      mem = rs6000_adjust_atomic_subword (mem, &shift, &mask);\n+\n+      /* Shift and mask OLDVAL into position with the word.  */\n+      oldval = convert_modes (SImode, mode, oldval, 1);\n+      oldval = expand_simple_binop (SImode, ASHIFT, oldval, shift,\n+\t\t\t\t    oldval, 1, OPTAB_LIB_WIDEN);\n+\n+      /* Shift and mask NEWVAL into position within the word.  */\n+      newval = convert_modes (SImode, mode, newval, 1);\n+      newval = expand_simple_binop (SImode, ASHIFT, newval, shift,\n+\t\t\t\t    newval, 1, OPTAB_LIB_WIDEN);\n \n-  emit_insn (gen_lwsync ());\n+      /* Prepare to adjust the return value.  */\n+      retval = gen_reg_rtx (SImode);\n+      mode = SImode;\n+    }\n+\n+  rs6000_pre_atomic_barrier (mod_s);\n \n-  label1 = gen_rtx_LABEL_REF (VOIDmode, gen_label_rtx ());\n+  emit_move_insn (boolval, const0_rtx);\n+\n+  label1 = NULL_RTX;\n+  if (!is_weak)\n+    {\n+      label1 = gen_rtx_LABEL_REF (VOIDmode, gen_label_rtx ());\n+      emit_label (XEXP (label1, 0));\n+    }\n   label2 = gen_rtx_LABEL_REF (VOIDmode, gen_label_rtx ());\n-  emit_label (XEXP (label1, 0));\n \n   emit_load_locked (mode, retval, mem);\n \n-  x = gen_rtx_COMPARE (CCmode, retval, oldval);\n-  emit_insn (gen_rtx_SET (VOIDmode, cond, x));\n+  x = retval;\n+  if (mask)\n+    {\n+      x = expand_simple_binop (SImode, AND, retval, mask,\n+\t\t\t       NULL_RTX, 1, OPTAB_LIB_WIDEN);\n+    }\n \n-  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+  x = gen_rtx_NE (VOIDmode, x, oldval);\n+  x = rs6000_generate_compare (x, mode);\n   emit_unlikely_jump (x, label2);\n \n-  emit_move_insn (scratch, newval);\n-  emit_store_conditional (mode, cond, mem, scratch);\n+  x = newval;\n+  if (mask)\n+    x = rs6000_mask_atomic_subword (retval, newval, mask);\n \n-  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n-  emit_unlikely_jump (x, label1);\n+  cond = gen_reg_rtx (CCmode);\n+  emit_store_conditional (mode, cond, mem, x);\n \n-  emit_insn (gen_isync ());\n-  emit_label (XEXP (label2, 0));\n+  if (is_weak)\n+    {\n+      /* ??? It's either this or an unlikely jump over (set bool 1).  */\n+      x = gen_rtx_EQ (SImode, cond, const0_rtx);\n+      emit_insn (gen_rtx_SET (VOIDmode, boolval, x));\n+    }\n+  else\n+    {\n+      x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+      emit_unlikely_jump (x, label1);\n+      emit_move_insn (boolval, const1_rtx);\n+    }\n+\n+  if (mod_f != MEMMODEL_RELAXED)\n+    emit_label (XEXP (label2, 0));\n+\n+  rs6000_post_atomic_barrier (mod_s);\n+\n+  if (mod_f == MEMMODEL_RELAXED)\n+    emit_label (XEXP (label2, 0));\n+\n+  if (shift)\n+    rs6000_finish_atomic_subword (operands[1], retval, shift);\n }\n \n-/* Expand an atomic test and set operation.  MEM is the memory on which\n-   to operate.  VAL is the value set.  SCRATCH is a scratch GPR.  */\n+/* Expand an atomic exchange operation.  */\n \n void\n-rs6000_split_lock_test_and_set (rtx retval, rtx mem, rtx val, rtx scratch)\n+rs6000_expand_atomic_exchange (rtx operands[])\n {\n-  enum machine_mode mode = GET_MODE (mem);\n-  rtx label, x, cond = gen_rtx_REG (CCmode, CR0_REGNO);\n+  rtx retval, mem, val, cond;\n+  enum machine_mode mode;\n+  enum memmodel model;\n+  rtx label, x, mask, shift;\n+\n+  retval = operands[0];\n+  mem = operands[1];\n+  val = operands[2];\n+  model = (enum memmodel) INTVAL (operands[3]);\n+  mode = GET_MODE (mem);\n+\n+  mask = shift = NULL_RTX;\n+  if (mode == QImode || mode == HImode)\n+    {\n+      mem = rs6000_adjust_atomic_subword (mem, &shift, &mask);\n+\n+      /* Shift and mask VAL into position with the word.  */\n+      val = convert_modes (SImode, mode, val, 1);\n+      val = expand_simple_binop (SImode, ASHIFT, val, shift,\n+\t\t\t\t val, 1, OPTAB_LIB_WIDEN);\n+\n+      /* Prepare to adjust the return value.  */\n+      retval = gen_reg_rtx (SImode);\n+      mode = SImode;\n+    }\n+\n+  rs6000_pre_atomic_barrier (model);\n \n   label = gen_rtx_LABEL_REF (VOIDmode, gen_label_rtx ());\n   emit_label (XEXP (label, 0));\n \n   emit_load_locked (mode, retval, mem);\n-  emit_move_insn (scratch, val);\n-  emit_store_conditional (mode, cond, mem, scratch);\n+\n+  x = val;\n+  if (mask)\n+    x = rs6000_mask_atomic_subword (retval, val, mask);\n+\n+  cond = gen_reg_rtx (CCmode);\n+  emit_store_conditional (mode, cond, mem, x);\n \n   x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n   emit_unlikely_jump (x, label);\n \n-  emit_insn (gen_isync ());\n+  rs6000_post_atomic_barrier (model);\n+\n+  if (shift)\n+    rs6000_finish_atomic_subword (operands[0], retval, shift);\n }\n \n+/* Expand an atomic fetch-and-operate pattern.  CODE is the binary operation\n+   to perform.  MEM is the memory on which to operate.  VAL is the second\n+   operand of the binary operator.  BEFORE and AFTER are optional locations to\n+   return the value of MEM either before of after the operation.  MODEL_RTX\n+   is a CONST_INT containing the memory model to use.  */\n+\n void\n-rs6000_expand_compare_and_swapqhi (rtx dst, rtx mem, rtx oldval, rtx newval)\n+rs6000_expand_atomic_op (enum rtx_code code, rtx mem, rtx val,\n+\t\t\t rtx orig_before, rtx orig_after, rtx model_rtx)\n {\n+  enum memmodel model = (enum memmodel) INTVAL (model_rtx);\n   enum machine_mode mode = GET_MODE (mem);\n-  rtx addrSI, align, wdst, shift, mask;\n-  HOST_WIDE_INT shift_mask = mode == QImode ? 0x18 : 0x10;\n-  HOST_WIDE_INT imask = GET_MODE_MASK (mode);\n+  rtx label, x, cond, mask, shift;\n+  rtx before = orig_before, after = orig_after;\n \n-  /* Shift amount for subword relative to aligned word.  */\n-  addrSI = force_reg (GET_MODE (XEXP (mem, 0)), XEXP (mem, 0));\n-  addrSI = force_reg (SImode, gen_lowpart_common (SImode, addrSI));\n-  shift = gen_reg_rtx (SImode);\n-  emit_insn (gen_rlwinm (shift, addrSI, GEN_INT (3),\n-\t\t\t GEN_INT (shift_mask)));\n-  emit_insn (gen_xorsi3 (shift, shift, GEN_INT (shift_mask)));\n-\n-  /* Shift and mask old value into position within word.  */\n-  oldval = convert_modes (SImode, mode, oldval, 1);\n-  oldval = expand_binop (SImode, and_optab,\n-\t\t\t oldval, GEN_INT (imask), NULL_RTX,\n-\t\t\t 1, OPTAB_LIB_WIDEN);\n-  emit_insn (gen_ashlsi3 (oldval, oldval, shift));\n-\n-  /* Shift and mask new value into position within word.  */\n-  newval = convert_modes (SImode, mode, newval, 1);\n-  newval = expand_binop (SImode, and_optab,\n-\t\t\t newval, GEN_INT (imask), NULL_RTX,\n-\t\t\t 1, OPTAB_LIB_WIDEN);\n-  emit_insn (gen_ashlsi3 (newval, newval, shift));\n+  mask = shift = NULL_RTX;\n+  if (mode == QImode || mode == HImode)\n+    {\n+      mem = rs6000_adjust_atomic_subword (mem, &shift, &mask);\n \n-  /* Mask for insertion.  */\n-  mask = gen_reg_rtx (SImode);\n-  emit_move_insn (mask, GEN_INT (imask));\n-  emit_insn (gen_ashlsi3 (mask, mask, shift));\n-\n-  /* Address of aligned word containing subword.  */\n-  align = expand_binop (Pmode, and_optab, XEXP (mem, 0), GEN_INT (-4),\n-\t\t\tNULL_RTX, 1, OPTAB_LIB_WIDEN);\n-  mem = change_address (mem, SImode, align);\n-  set_mem_align (mem, 32);\n-  MEM_VOLATILE_P (mem) = 1;\n+      /* Shift and mask VAL into position with the word.  */\n+      val = convert_modes (SImode, mode, val, 1);\n+      val = expand_simple_binop (SImode, ASHIFT, val, shift,\n+\t\t\t\t val, 1, OPTAB_LIB_WIDEN);\n \n-  wdst = gen_reg_rtx (SImode);\n-  emit_insn (gen_sync_compare_and_swapqhi_internal (wdst, mask,\n-\t\t\t\t\t\t    oldval, newval, mem));\n+      switch (code)\n+\t{\n+\tcase IOR:\n+\tcase XOR:\n+\t  /* We've already zero-extended VAL.  That is sufficient to\n+\t     make certain that it does not affect other bits.  */\n+\t  mask = NULL;\n+\t  break;\n \n-  /* Shift the result back.  */\n-  emit_insn (gen_lshrsi3 (wdst, wdst, shift));\n+\tcase AND:\n+\t  /* If we make certain that all of the other bits in VAL are\n+\t     set, that will be sufficient to not affect other bits.  */\n+\t  x = gen_rtx_NOT (SImode, mask);\n+\t  x = gen_rtx_IOR (SImode, x, val);\n+\t  emit_insn (gen_rtx_SET (VOIDmode, val, x));\n+\t  mask = NULL;\n+\t  break;\n \n-  emit_move_insn (dst, gen_lowpart (mode, wdst));\n-}\n+\tcase NOT:\n+\tcase PLUS:\n+\tcase MINUS:\n+\t  /* These will all affect bits outside the field and need\n+\t     adjustment via MASK within the loop.  */\n+\t  break;\n \n-void\n-rs6000_split_compare_and_swapqhi (rtx dest, rtx mask,\n-\t\t\t\t  rtx oldval, rtx newval, rtx mem,\n-\t\t\t\t  rtx scratch)\n-{\n-  rtx label1, label2, x, cond = gen_rtx_REG (CCmode, CR0_REGNO);\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n \n-  emit_insn (gen_lwsync ());\n-  label1 = gen_rtx_LABEL_REF (VOIDmode, gen_label_rtx ());\n-  label2 = gen_rtx_LABEL_REF (VOIDmode, gen_label_rtx ());\n-  emit_label (XEXP (label1, 0));\n+      /* Prepare to adjust the return value.  */\n+      before = gen_reg_rtx (SImode);\n+      if (after)\n+\tafter = gen_reg_rtx (SImode);\n+      mode = SImode;\n+    }\n \n-  emit_load_locked (SImode, scratch, mem);\n+  rs6000_pre_atomic_barrier (model);\n \n-  /* Mask subword within loaded value for comparison with oldval.\n-     Use UNSPEC_AND to avoid clobber.*/\n-  emit_insn (gen_rtx_SET (SImode, dest,\n-\t\t\t  gen_rtx_UNSPEC (SImode,\n-\t\t\t\t\t  gen_rtvec (2, scratch, mask),\n-\t\t\t\t\t  UNSPEC_AND)));\n+  label = gen_label_rtx ();\n+  emit_label (label);\n+  label = gen_rtx_LABEL_REF (VOIDmode, label);\n \n-  x = gen_rtx_COMPARE (CCmode, dest, oldval);\n-  emit_insn (gen_rtx_SET (VOIDmode, cond, x));\n+  if (before == NULL_RTX)\n+    before = gen_reg_rtx (mode);\n \n-  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n-  emit_unlikely_jump (x, label2);\n+  emit_load_locked (mode, before, mem);\n \n-  /* Clear subword within loaded value for insertion of new value.  */\n-  emit_insn (gen_rtx_SET (SImode, scratch,\n-\t\t\t  gen_rtx_AND (SImode,\n-\t\t\t\t       gen_rtx_NOT (SImode, mask), scratch)));\n-  emit_insn (gen_iorsi3 (scratch, scratch, newval));\n-  emit_store_conditional (SImode, cond, mem, scratch);\n+  if (code == NOT)\n+    {\n+      x = expand_simple_binop (mode, AND, before, val,\n+\t\t\t       NULL_RTX, 1, OPTAB_LIB_WIDEN);\n+      after = expand_simple_unop (mode, NOT, x, after, 1);\n+    }\n+  else\n+    {\n+      after = expand_simple_binop (mode, code, before, val,\n+\t\t\t\t   after, 1, OPTAB_LIB_WIDEN);\n+    }\n+\n+  x = after;\n+  if (mask)\n+    {\n+      x = expand_simple_binop (SImode, AND, after, mask,\n+\t\t\t       NULL_RTX, 1, OPTAB_LIB_WIDEN);\n+      x = rs6000_mask_atomic_subword (before, x, mask);\n+    }\n+\n+  cond = gen_reg_rtx (CCmode);\n+  emit_store_conditional (mode, cond, mem, x);\n \n   x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n-  emit_unlikely_jump (x, label1);\n+  emit_unlikely_jump (x, label);\n \n-  emit_insn (gen_isync ());\n-  emit_label (XEXP (label2, 0));\n-}\n+  rs6000_post_atomic_barrier (model);\n \n+  if (shift)\n+    {\n+      if (orig_before)\n+\trs6000_finish_atomic_subword (orig_before, before, shift);\n+      if (orig_after)\n+\trs6000_finish_atomic_subword (orig_after, after, shift);\n+    }\n+  else if (orig_after && after != orig_after)\n+    emit_move_insn (orig_after, after);\n+}\n \n-  /* Emit instructions to move SRC to DST.  Called by splitters for\n+/* Emit instructions to move SRC to DST.  Called by splitters for\n    multi-register moves.  It will emit at most one instruction for\n    each register that is accessed; that is, it won't emit li/lis pairs\n    (or equivalent for 64-bit code).  One of SRC or DST must be a hard"}, {"sha": "22207bbf2b25ee14da8c5608ceb117a0d0a0e8cd", "filename": "gcc/config/rs6000/rs6000.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Frs6000.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Frs6000.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.md?ref=2747a04662929c37d3bcc96c36adc861a4611710", "patch": "@@ -106,6 +106,7 @@\n    UNSPEC_SP_SET\n    UNSPEC_SP_TEST\n    UNSPEC_SYNC\n+   UNSPEC_LWSYNC\n    UNSPEC_SYNC_OP\n    UNSPEC_ATOMIC\n    UNSPEC_CMPXCHG\n@@ -138,7 +139,6 @@\n    UNSPECV_PROBE_STACK_RANGE\t; probe range of stack addresses\n    UNSPECV_EH_RR\t\t; eh_reg_restore\n    UNSPECV_ISYNC\t\t; isync instruction\n-   UNSPECV_LWSYNC\t\t; lwsync\n   ])\n \n \f"}, {"sha": "38bd8bac3547c5e7391811e5f30f0056b8a904b5", "filename": "gcc/config/rs6000/sync.md", "status": "modified", "additions": 183, "deletions": 521, "changes": 704, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Fsync.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2747a04662929c37d3bcc96c36adc861a4611710/gcc%2Fconfig%2Frs6000%2Fsync.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fsync.md?ref=2747a04662929c37d3bcc96c36adc861a4611710", "patch": "@@ -28,12 +28,32 @@\n (define_code_attr fetchop_pred\n   [(plus \"add_operand\") (minus \"gpc_reg_operand\")\n    (ior \"logical_operand\") (xor \"logical_operand\") (and \"and_operand\")])\n-(define_code_attr fetchopsi_constr\n-  [(plus \"rIL\") (minus \"r\") (ior \"rKL\") (xor \"rKL\") (and \"rTKL\")])\n-(define_code_attr fetchopdi_constr\n-  [(plus \"rIL\") (minus \"r\") (ior \"rKJF\") (xor \"rKJF\") (and \"rSTKJ\")])\n \n-(define_expand \"memory_barrier\"\n+(define_expand \"mem_thread_fence\"\n+  [(match_operand:SI 0 \"const_int_operand\" \"\")]\t\t;; model\n+  \"\"\n+{\n+  enum memmodel model = (enum memmodel) INTVAL (operands[0]);\n+  switch (model)\n+    {\n+    case MEMMODEL_RELAXED:\n+      break;\n+    case MEMMODEL_CONSUME:\n+    case MEMMODEL_ACQUIRE:\n+    case MEMMODEL_RELEASE:\n+    case MEMMODEL_ACQ_REL:\n+      emit_insn (gen_lwsync ());\n+      break;\n+    case MEMMODEL_SEQ_CST:\n+      emit_insn (gen_hwsync ());\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+  DONE;\n+})\n+\n+(define_expand \"hwsync\"\n   [(set (match_dup 0)\n \t(unspec:BLK [(match_dup 0)] UNSPEC_SYNC))]\n   \"\"\n@@ -42,582 +62,224 @@\n   MEM_VOLATILE_P (operands[0]) = 1;\n })\n \n-(define_insn \"*sync_internal\"\n+(define_insn \"*hwsync\"\n   [(set (match_operand:BLK 0 \"\" \"\")\n \t(unspec:BLK [(match_dup 0)] UNSPEC_SYNC))]\n   \"\"\n   \"{dcs|sync}\"\n   [(set_attr \"type\" \"sync\")])\n \n-(define_insn \"load_locked_<mode>\"\n-  [(set (match_operand:GPR 0 \"gpc_reg_operand\" \"=r\")\n-\t(unspec_volatile:GPR\n-\t  [(match_operand:GPR 1 \"memory_operand\" \"Z\")] UNSPECV_LL))]\n-  \"TARGET_POWERPC\"\n-  \"<larx> %0,%y1\"\n-  [(set_attr \"type\" \"load_l\")])\n-\n-(define_insn \"store_conditional_<mode>\"\n-  [(set (match_operand:CC 0 \"cc_reg_operand\" \"=x\")\n-\t(unspec_volatile:CC [(const_int 0)] UNSPECV_SC))\n-   (set (match_operand:GPR 1 \"memory_operand\" \"=Z\")\n-\t(match_operand:GPR 2 \"gpc_reg_operand\" \"r\"))]\n-  \"TARGET_POWERPC\"\n-  \"<stcx> %2,%y1\"\n-  [(set_attr \"type\" \"store_c\")])\n-\n-(define_insn_and_split \"sync_compare_and_swap<mode>\"\n-  [(set (match_operand:GPR 0 \"gpc_reg_operand\" \"=&r\")\n-\t(match_operand:GPR 1 \"memory_operand\" \"+Z\"))\n-   (set (match_dup 1)\n-\t(unspec:GPR\n-\t  [(match_operand:GPR 2 \"reg_or_short_operand\" \"rI\")\n-\t   (match_operand:GPR 3 \"gpc_reg_operand\" \"r\")]\n-\t  UNSPEC_CMPXCHG))\n-   (clobber (match_scratch:GPR 4 \"=&r\"))\n-   (clobber (match_scratch:CC 5 \"=&x\"))]\n-  \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n+(define_expand \"lwsync\"\n+  [(set (match_dup 0)\n+\t(unspec:BLK [(match_dup 0)] UNSPEC_LWSYNC))]\n+  \"\"\n {\n-  rs6000_split_compare_and_swap (operands[0], operands[1], operands[2],\n-\t\t\t\t operands[3], operands[4]);\n-  DONE;\n+  operands[0] = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));\n+  MEM_VOLATILE_P (operands[0]) = 1;\n })\n \n-(define_expand \"sync_compare_and_swaphi\"\n-  [(match_operand:HI 0 \"gpc_reg_operand\" \"\")\n-   (match_operand:HI 1 \"memory_operand\" \"\")\n-   (match_operand:HI 2 \"gpc_reg_operand\" \"\")\n-   (match_operand:HI 3 \"gpc_reg_operand\" \"\")]\n-  \"TARGET_POWERPC\"\n+(define_insn \"*lwsync\"\n+  [(set (match_operand:BLK 0 \"\" \"\")\n+\t(unspec:BLK [(match_dup 0)] UNSPEC_LWSYNC))]\n+  \"\"\n {\n-  rs6000_expand_compare_and_swapqhi (operands[0], operands[1],\n-\t\t\t\t     operands[2], operands[3]);\n-  DONE;\n-})\n+  /* Some AIX assemblers don't accept lwsync, so we use a .long.  */\n+  if (TARGET_NO_LWSYNC)\n+    return \"sync\";\n+  else if (TARGET_LWSYNC_INSTRUCTION)\n+    return \"lwsync\";\n+  else\n+    return \".long 0x7c2004ac\";\n+}\n+  [(set_attr \"type\" \"sync\")])\n \n-(define_expand \"sync_compare_and_swapqi\"\n-  [(match_operand:QI 0 \"gpc_reg_operand\" \"\")\n-   (match_operand:QI 1 \"memory_operand\" \"\")\n-   (match_operand:QI 2 \"gpc_reg_operand\" \"\")\n-   (match_operand:QI 3 \"gpc_reg_operand\" \"\")]\n-  \"TARGET_POWERPC\"\n-{\n-  rs6000_expand_compare_and_swapqhi (operands[0], operands[1],\n-\t\t\t\t     operands[2], operands[3]);\n-  DONE;\n-})\n+(define_insn \"isync\"\n+  [(unspec_volatile:BLK [(const_int 0)] UNSPECV_ISYNC)]\n+  \"\"\n+  \"{ics|isync}\"\n+  [(set_attr \"type\" \"isync\")])\n \n-(define_insn_and_split \"sync_compare_and_swapqhi_internal\"\n-  [(set (match_operand:SI 0 \"gpc_reg_operand\" \"=&r\")\n-\t(match_operand:SI 4 \"memory_operand\" \"+Z\"))\n-   (set (match_dup 4)\n-        (unspec:SI\n-          [(match_operand:SI 1 \"gpc_reg_operand\" \"r\")\n-           (match_operand:SI 2 \"gpc_reg_operand\" \"r\")\n-           (match_operand:SI 3 \"gpc_reg_operand\" \"r\")]\n-          UNSPEC_CMPXCHG))\n-   (clobber (match_scratch:SI 5 \"=&r\"))\n-   (clobber (match_scratch:CC 6 \"=&x\"))]\n-  \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n+;; The control dependency used for load dependency described\n+;; in B.2.3 of the Power ISA 2.06B.\n+(define_insn \"loadsync\"\n+  [(unspec_volatile:BLK [(match_operand 0 \"register_operand\" \"r\")]\n+\t\t\tUNSPECV_ISYNC)\n+   (clobber (match_scratch:CC 1 \"=y\"))]\n+  \"\"\n+  \"cmpw %1,%0,%0\\;bne- %1,$+4\\;isync\"\n+  [(set_attr \"type\" \"isync\")\n+   (set_attr \"length\" \"12\")])\n+\n+(define_expand \"atomic_load<mode>\"\n+  [(set (match_operand:INT 0 \"register_operand\" \"\")\t\t;; output\n+\t(match_operand:INT 1 \"memory_operand\" \"\"))\t\t;; memory\n+   (use (match_operand:SI 2 \"const_int_operand\" \"\"))]\t\t;; model\n+  \"\"\n {\n-  rs6000_split_compare_and_swapqhi (operands[0], operands[1],\n-\t\t\t\t    operands[2], operands[3], operands[4],\n-\t\t\t\t    operands[5]);\n-  DONE;\n-})\n+  enum memmodel model = (enum memmodel) INTVAL (operands[2]);\n \n-(define_insn_and_split \"sync_lock_test_and_set<mode>\"\n-  [(set (match_operand:GPR 0 \"gpc_reg_operand\" \"=&r\")\n-\t(match_operand:GPR 1 \"memory_operand\" \"+Z\"))\n-   (set (match_dup 1)\n-\t(unspec:GPR\n-\t  [(match_operand:GPR 2 \"reg_or_short_operand\" \"rL\")]\n-\t  UNSPEC_XCHG))\n-   (clobber (match_scratch:GPR 3 \"=&r\"))\n-   (clobber (match_scratch:CC 4 \"=&x\"))]\n-  \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n-{\n-  rs6000_split_lock_test_and_set (operands[0], operands[1], operands[2],\n-\t\t\t\t  operands[3]);\n-  DONE;\n-})\n+  if (model == MEMMODEL_SEQ_CST)\n+    emit_insn (gen_hwsync ());\n \n-(define_expand \"sync_<fetchop_name><mode>\"\n-  [(parallel [(set (match_operand:INT1 0 \"memory_operand\" \"\")\n-\t\t   (unspec:INT1\n-\t\t     [(FETCHOP:INT1 (match_dup 0)\n-\t\t\t(match_operand:INT1 1 \"<fetchop_pred>\" \"\"))]\n-\t\t     UNSPEC_ATOMIC))\n-\t      (clobber (scratch:INT1))\n-\t      (clobber (scratch:CC))])]\n-  \"TARGET_POWERPC\"\n-  \"\n-{\n-  if (<MODE>mode != SImode && <MODE>mode != DImode)\n+  emit_move_insn (operands[0], operands[1]);\n+\n+  switch (model)\n     {\n-      if (PPC405_ERRATUM77)\n-\tFAIL;\n-      rs6000_emit_sync (<CODE>, <MODE>mode, operands[0], operands[1],\n-\t\t\tNULL_RTX, NULL_RTX, true);\n-      DONE;\n+    case MEMMODEL_RELAXED:\n+      break;\n+    case MEMMODEL_CONSUME:\n+    case MEMMODEL_ACQUIRE:\n+    case MEMMODEL_SEQ_CST:\n+      emit_insn (gen_loadsync (operands[0]));\n+      break;\n+    default:\n+      gcc_unreachable ();\n     }\n-}\")\n-\n-(define_insn_and_split \"*sync_<fetchop_name>si_internal\"\n-  [(set (match_operand:SI 0 \"memory_operand\" \"+Z\")\n-\t(unspec:SI\n-\t  [(FETCHOP:SI (match_dup 0)\n-\t     (match_operand:SI 1 \"<fetchop_pred>\" \"<fetchopsi_constr>\"))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:SI 2 \"=&b\"))\n-   (clobber (match_scratch:CC 3 \"=&x\"))]\n-  \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n-{\n-  rs6000_split_atomic_op (<CODE>, operands[0], operands[1],\n-\t\t\t  NULL_RTX, NULL_RTX, operands[2]);\n   DONE;\n })\n \n-(define_insn_and_split \"*sync_<fetchop_name>di_internal\"\n-  [(set (match_operand:DI 0 \"memory_operand\" \"+Z\")\n-\t(unspec:DI\n-\t  [(FETCHOP:DI (match_dup 0)\n-\t     (match_operand:DI 1 \"<fetchop_pred>\" \"<fetchopdi_constr>\"))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:DI 2 \"=&b\"))\n-   (clobber (match_scratch:CC 3 \"=&x\"))]\n-  \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n+(define_expand \"atomic_store<mode>\"\n+  [(set (match_operand:INT 0 \"memory_operand\" \"\")\t\t;; memory\n+\t(match_operand:INT 1 \"register_operand\" \"\"))\t\t;; input\n+   (use (match_operand:SI 2 \"const_int_operand\" \"\"))]\t\t;; model\n+  \"\"\n {\n-  rs6000_split_atomic_op (<CODE>, operands[0], operands[1],\n-\t\t\t  NULL_RTX, NULL_RTX, operands[2]);\n+  enum memmodel model = (enum memmodel) INTVAL (operands[2]);\n+  switch (model)\n+    {\n+    case MEMMODEL_RELAXED:\n+      break;\n+    case MEMMODEL_RELEASE:\n+      emit_insn (gen_lwsync ());\n+      break;\n+    case MEMMODEL_SEQ_CST:\n+      emit_insn (gen_hwsync ());\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+  emit_move_insn (operands[0], operands[1]);\n   DONE;\n })\n \n-(define_expand \"sync_nand<mode>\"\n-  [(parallel [(set (match_operand:INT1 0 \"memory_operand\" \"\")\n-\t      (unspec:INT1\n-\t\t[(ior:INT1 (not:INT1 (match_dup 0))\n-\t\t\t   (not:INT1 (match_operand:INT1 1 \"gpc_reg_operand\" \"\")))]\n-\t\tUNSPEC_ATOMIC))\n-\t      (clobber (scratch:INT1))\n-\t      (clobber (scratch:CC))])]\n-  \"TARGET_POWERPC\"\n-  \"\n-{\n-  if (<MODE>mode != SImode && <MODE>mode != DImode)\n-    {\n-      FAIL;\n-      if (PPC405_ERRATUM77)\n-\tFAIL;\n-      rs6000_emit_sync (NOT, <MODE>mode, operands[0], operands[1],\n-\t\t\tNULL_RTX, NULL_RTX, true);\n-      DONE;\n-    }\n-}\")\n+;; ??? Power ISA 2.06B says that there *is* a load-{byte,half}-and-reserve\n+;; opcode that is \"phased-in\".  Not implemented as of Power7, so not yet used,\n+;; but let's prepare the macros anyway.\n+\n+(define_mode_iterator ATOMIC    [SI (DI \"TARGET_64BIT\")])\n \n-(define_insn_and_split \"*sync_nand<mode>_internal\"\n-  [(set (match_operand:GPR 0 \"memory_operand\" \"+Z\")\n-\t(unspec:GPR\n-\t  [(ior:GPR (not:GPR (match_dup 0))\n-\t\t    (not:GPR (match_operand:GPR 1 \"gpc_reg_operand\" \"r\")))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:GPR 2 \"=&r\"))\n-   (clobber (match_scratch:CC 3 \"=&x\"))]\n+(define_insn \"load_locked<mode>\"\n+  [(set (match_operand:ATOMIC 0 \"gpc_reg_operand\" \"=r\")\n+\t(unspec_volatile:ATOMIC\n+         [(match_operand:ATOMIC 1 \"memory_operand\" \"Z\")] UNSPECV_LL))]\n   \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n-{\n-  rs6000_split_atomic_op (NOT, operands[0], operands[1],\n-\t\t\t  NULL_RTX, NULL_RTX, operands[2]);\n-  DONE;\n-})\n+  \"<larx> %0,%y1\"\n+  [(set_attr \"type\" \"load_l\")])\n \n-(define_expand \"sync_old_<fetchop_name><mode>\"\n-  [(parallel [(set (match_operand:INT1 0 \"gpc_reg_operand\" \"\")\n-\t\t   (match_operand:INT1 1 \"memory_operand\" \"\"))\n-\t      (set (match_dup 1)\n-\t\t   (unspec:INT1\n-\t\t     [(FETCHOP:INT1 (match_dup 1)\n-\t\t\t(match_operand:INT1 2 \"<fetchop_pred>\" \"\"))]\n-\t\t     UNSPEC_ATOMIC))\n-\t      (clobber (scratch:INT1))\n-\t      (clobber (scratch:CC))])]\n+(define_insn \"store_conditional<mode>\"\n+  [(set (match_operand:CC 0 \"cc_reg_operand\" \"=x\")\n+\t(unspec_volatile:CC [(const_int 0)] UNSPECV_SC))\n+   (set (match_operand:ATOMIC 1 \"memory_operand\" \"=Z\")\n+\t(match_operand:ATOMIC 2 \"gpc_reg_operand\" \"r\"))]\n   \"TARGET_POWERPC\"\n-  \"\n-{ \n-  if (<MODE>mode != SImode && <MODE>mode != DImode)\n-    {\n-      if (PPC405_ERRATUM77)\n-\tFAIL;\n-      rs6000_emit_sync (<CODE>, <MODE>mode, operands[1], operands[2],\n-\t\t\toperands[0], NULL_RTX, true);\n-      DONE;\n-    }\n-}\")\n+  \"<stcx> %2,%y1\"\n+  [(set_attr \"type\" \"store_c\")])\n \n-(define_insn_and_split \"*sync_old_<fetchop_name>si_internal\"\n-  [(set (match_operand:SI 0 \"gpc_reg_operand\" \"=&r\")\n-\t(match_operand:SI 1 \"memory_operand\" \"+Z\"))\n-   (set (match_dup 1)\n-\t(unspec:SI\n-\t  [(FETCHOP:SI (match_dup 1)\n-\t     (match_operand:SI 2 \"<fetchop_pred>\" \"<fetchopsi_constr>\"))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:SI 3 \"=&b\"))\n-   (clobber (match_scratch:CC 4 \"=&x\"))]\n+(define_expand \"atomic_compare_and_swap<mode>\"\n+  [(match_operand:SI 0 \"gpc_reg_operand\" \"\")\t\t;; bool out\n+   (match_operand:INT1 1 \"gpc_reg_operand\" \"\")\t\t;; val out\n+   (match_operand:INT1 2 \"memory_operand\" \"\")\t\t;; memory\n+   (match_operand:INT1 3 \"reg_or_short_operand\" \"\")\t;; expected\n+   (match_operand:INT1 4 \"gpc_reg_operand\" \"\")\t\t;; desired\n+   (match_operand:SI 5 \"const_int_operand\" \"\")\t\t;; is_weak\n+   (match_operand:SI 6 \"const_int_operand\" \"\")\t\t;; model succ\n+   (match_operand:SI 7 \"const_int_operand\" \"\")]\t\t;; model fail\n   \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n {\n-  rs6000_split_atomic_op (<CODE>, operands[1], operands[2],\n-\t\t\t  operands[0], NULL_RTX, operands[3]);\n+  rs6000_expand_atomic_compare_and_swap (operands);\n   DONE;\n })\n \n-(define_insn_and_split \"*sync_old_<fetchop_name>di_internal\"\n-  [(set (match_operand:DI 0 \"gpc_reg_operand\" \"=&r\")\n-\t(match_operand:DI 1 \"memory_operand\" \"+Z\"))\n-   (set (match_dup 1)\n-\t(unspec:DI\n-\t  [(FETCHOP:DI (match_dup 1)\n-\t     (match_operand:DI 2 \"<fetchop_pred>\" \"<fetchopdi_constr>\"))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:DI 3 \"=&b\"))\n-   (clobber (match_scratch:CC 4 \"=&x\"))]\n+(define_expand \"atomic_exchange<mode>\"\n+  [(match_operand:INT1 0 \"gpc_reg_operand\" \"\")\t\t;; output\n+   (match_operand:INT1 1 \"memory_operand\" \"\")\t\t;; memory\n+   (match_operand:INT1 2 \"gpc_reg_operand\" \"\")\t\t;; input\n+   (match_operand:SI 3 \"const_int_operand\" \"\")]\t\t;; model\n   \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n {\n-  rs6000_split_atomic_op (<CODE>, operands[1], operands[2],\n-\t\t\t  operands[0], NULL_RTX, operands[3]);\n+  rs6000_expand_atomic_exchange (operands);\n   DONE;\n })\n \n-(define_expand \"sync_old_nand<mode>\"\n-  [(parallel [(set (match_operand:INT1 0 \"gpc_reg_operand\" \"\")\n-\t\t   (match_operand:INT1 1 \"memory_operand\" \"\"))\n-\t      (set (match_dup 1)\n-\t\t   (unspec:INT1\n-\t\t     [(ior:INT1 (not:INT1 (match_dup 1))\n-\t\t\t\t(not:INT1 (match_operand:INT1 2 \"gpc_reg_operand\" \"\")))]\n-\t\t     UNSPEC_ATOMIC))\n-\t      (clobber (scratch:INT1))\n-\t      (clobber (scratch:CC))])]\n-  \"TARGET_POWERPC\"\n-  \"\n-{\n-  if (<MODE>mode != SImode && <MODE>mode != DImode)\n-    {\n-      FAIL;\n-      if (PPC405_ERRATUM77)\n-\tFAIL;\n-      rs6000_emit_sync (NOT, <MODE>mode, operands[1], operands[2],\n-\t\t\toperands[0], NULL_RTX, true);\n-      DONE;\n-    }\n-}\")\n-\n-(define_insn_and_split \"*sync_old_nand<mode>_internal\"\n-  [(set (match_operand:GPR 0 \"gpc_reg_operand\" \"=&r\")\n-\t(match_operand:GPR 1 \"memory_operand\" \"+Z\"))\n-   (set (match_dup 1)\n-\t(unspec:GPR\n-\t  [(ior:GPR (not:GPR (match_dup 1))\n-\t\t    (not:GPR (match_operand:GPR 2 \"gpc_reg_operand\" \"r\")))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:GPR 3 \"=&r\"))\n-   (clobber (match_scratch:CC 4 \"=&x\"))]\n+(define_expand \"atomic_<fetchop_name><mode>\"\n+  [(match_operand:INT1 0 \"memory_operand\" \"\")\t\t;; memory\n+   (FETCHOP:INT1 (match_dup 0)\n+     (match_operand:INT1 1 \"<fetchop_pred>\" \"\"))\t;; operand\n+   (match_operand:SI 2 \"const_int_operand\" \"\")]\t\t;; model\n   \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n {\n-  rs6000_split_atomic_op (NOT, operands[1], operands[2],\n-\t\t\t  operands[0], NULL_RTX, operands[3]);\n+  rs6000_expand_atomic_op (<CODE>, operands[0], operands[1],\n+\t\t\t   NULL_RTX, NULL_RTX, operands[2]);\n   DONE;\n })\n \n-(define_expand \"sync_new_<fetchop_name><mode>\"\n-  [(parallel [(set (match_operand:INT1 0 \"gpc_reg_operand\" \"\")\n-\t\t   (FETCHOP:INT1\n-\t\t     (match_operand:INT1 1 \"memory_operand\" \"\")\n-\t\t     (match_operand:INT1 2 \"<fetchop_pred>\" \"\")))\n-\t      (set (match_dup 1)\n-\t\t   (unspec:INT1\n-\t\t     [(FETCHOP:INT1 (match_dup 1) (match_dup 2))]\n-\t\t     UNSPEC_ATOMIC))\n-\t      (clobber (scratch:INT1))\n-\t      (clobber (scratch:CC))])]\n+(define_expand \"atomic_nand<mode>\"\n+  [(match_operand:INT1 0 \"memory_operand\" \"\")\t\t;; memory\n+   (match_operand:INT1 1 \"gpc_reg_operand\" \"\")\t\t;; operand\n+   (match_operand:SI 2 \"const_int_operand\" \"\")]\t\t;; model\n   \"TARGET_POWERPC\"\n-  \"\n {\n-  if (<MODE>mode != SImode && <MODE>mode != DImode)\n-    {\n-      if (PPC405_ERRATUM77)\n-\tFAIL;\n-      rs6000_emit_sync (<CODE>, <MODE>mode, operands[1], operands[2],\n-\t\t\tNULL_RTX, operands[0], true);\n-      DONE;\n-    }\n-}\")\n-\n-(define_insn_and_split \"*sync_new_<fetchop_name>si_internal\"\n-  [(set (match_operand:SI 0 \"gpc_reg_operand\" \"=&r\")\n-\t(FETCHOP:SI\n-\t  (match_operand:SI 1 \"memory_operand\" \"+Z\")\n-\t  (match_operand:SI 2 \"<fetchop_pred>\" \"<fetchopsi_constr>\")))\n-   (set (match_dup 1)\n-\t(unspec:SI\n-\t  [(FETCHOP:SI (match_dup 1) (match_dup 2))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:SI 3 \"=&b\"))\n-   (clobber (match_scratch:CC 4 \"=&x\"))]\n-  \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n-{\n-  rs6000_split_atomic_op (<CODE>, operands[1], operands[2],\n-\t\t\t  NULL_RTX, operands[0], operands[3]);\n+  rs6000_expand_atomic_op (NOT, operands[0], operands[1],\n+\t\t\t   NULL_RTX, NULL_RTX, operands[2]);\n   DONE;\n })\n \n-(define_insn_and_split \"*sync_new_<fetchop_name>di_internal\"\n-  [(set (match_operand:DI 0 \"gpc_reg_operand\" \"=&r\")\n-\t(FETCHOP:DI\n-\t  (match_operand:DI 1 \"memory_operand\" \"+Z\")\n-\t  (match_operand:DI 2 \"<fetchop_pred>\" \"<fetchopdi_constr>\")))\n-   (set (match_dup 1)\n-\t(unspec:DI\n-\t  [(FETCHOP:DI (match_dup 1) (match_dup 2))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:DI 3 \"=&b\"))\n-   (clobber (match_scratch:CC 4 \"=&x\"))]\n+(define_expand \"atomic_fetch_<fetchop_name><mode>\"\n+  [(match_operand:INT1 0 \"gpc_reg_operand\" \"\")\t\t;; output\n+   (match_operand:INT1 1 \"memory_operand\" \"\")\t\t;; memory\n+   (FETCHOP:INT1 (match_dup 1)\n+     (match_operand:INT1 2 \"<fetchop_pred>\" \"\"))\t;; operand\n+   (match_operand:SI 3 \"const_int_operand\" \"\")]\t\t;; model\n   \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n-{\n-  rs6000_split_atomic_op (<CODE>, operands[1], operands[2],\n-\t\t\t  NULL_RTX, operands[0], operands[3]);\n+{ \n+  rs6000_expand_atomic_op (<CODE>, operands[1], operands[2],\n+\t\t\t   operands[0], NULL_RTX, operands[3]);\n   DONE;\n })\n \n-(define_expand \"sync_new_nand<mode>\"\n-  [(parallel [(set (match_operand:INT1 0 \"gpc_reg_operand\" \"\")\n-\t\t   (ior:INT1\n-\t\t     (not:INT1 (match_operand:INT1 1 \"memory_operand\" \"\"))\n-\t\t     (not:INT1 (match_operand:INT1 2 \"gpc_reg_operand\" \"\"))))\n-\t      (set (match_dup 1)\n-\t\t   (unspec:INT1\n-\t\t     [(ior:INT1 (not:INT1 (match_dup 1))\n-\t\t\t\t(not:INT1 (match_dup 2)))]\n-\t\t     UNSPEC_ATOMIC))\n-\t      (clobber (scratch:INT1))\n-\t      (clobber (scratch:CC))])]\n+(define_expand \"atomic_fetch_nand<mode>\"\n+  [(match_operand:INT1 0 \"gpc_reg_operand\" \"\")\t\t;; output\n+   (match_operand:INT1 1 \"memory_operand\" \"\")\t\t;; memory\n+   (match_operand:INT1 2 \"gpc_reg_operand\" \"\")\t\t;; operand\n+   (match_operand:SI 3 \"const_int_operand\" \"\")]\t\t;; model\n   \"TARGET_POWERPC\"\n-  \"\n {\n-  if (<MODE>mode != SImode && <MODE>mode != DImode)\n-    {\n-      FAIL;\n-      if (PPC405_ERRATUM77)\n-\tFAIL;\n-      rs6000_emit_sync (NOT, <MODE>mode, operands[1], operands[2],\n-\t\t\tNULL_RTX, operands[0], true);\n-      DONE;\n-    }\n-}\")\n+  rs6000_expand_atomic_op (NOT, operands[1], operands[2],\n+\t\t\t   operands[0], NULL_RTX, operands[3]);\n+  DONE;\n+})\n \n-(define_insn_and_split \"*sync_new_nand<mode>_internal\"\n-  [(set (match_operand:GPR 0 \"gpc_reg_operand\" \"=&r\")\n-\t(ior:GPR\n-\t  (not:GPR (match_operand:GPR 1 \"memory_operand\" \"+Z\"))\n-\t  (not:GPR (match_operand:GPR 2 \"gpc_reg_operand\" \"r\"))))\n-   (set (match_dup 1)\n-\t(unspec:GPR\n-\t  [(ior:GPR (not:GPR (match_dup 1)) (not:GPR (match_dup 2)))]\n-\t  UNSPEC_ATOMIC))\n-   (clobber (match_scratch:GPR 3 \"=&r\"))\n-   (clobber (match_scratch:CC 4 \"=&x\"))]\n+(define_expand \"atomic_<fetchop_name>_fetch<mode>\"\n+  [(match_operand:INT1 0 \"gpc_reg_operand\" \"\")\t\t;; output\n+   (match_operand:INT1 1 \"memory_operand\" \"\")\t\t;; memory\n+   (FETCHOP:INT1 (match_dup 1)\n+     (match_operand:INT1 2 \"<fetchop_pred>\" \"\"))\t;; operand\n+   (match_operand:SI 3 \"const_int_operand\" \"\")]\t\t;; model\n   \"TARGET_POWERPC\"\n-  \"#\"\n-  \"&& reload_completed\"\n-  [(const_int 0)]\n {\n-  rs6000_split_atomic_op (NOT, operands[1], operands[2],\n-\t\t\t  NULL_RTX, operands[0], operands[3]);\n+  rs6000_expand_atomic_op (<CODE>, operands[1], operands[2],\n+\t\t\t   NULL_RTX, operands[0], operands[3]);\n   DONE;\n })\n \n-; and<mode> without cr0 clobber to avoid generation of additional clobber \n-; in atomic splitters causing internal consistency failure.\n-; cr0 already clobbered by larx/stcx.\n-(define_insn \"*atomic_andsi\"\n-  [(set (match_operand:SI 0 \"gpc_reg_operand\" \"=r,r,r,r\")\n-\t(unspec:SI [(match_operand:SI 1 \"gpc_reg_operand\" \"%r,r,r,r\")\n-\t\t    (match_operand:SI 2 \"and_operand\" \"?r,T,K,L\")]\n-\t\t    UNSPEC_AND))]\n-  \"\"\n-  \"@\n-   and %0,%1,%2\n-   {rlinm|rlwinm} %0,%1,0,%m2,%M2\n-   {andil.|andi.} %0,%1,%b2\n-   {andiu.|andis.} %0,%1,%u2\"\n-  [(set_attr \"type\" \"*,*,compare,compare\")])\n-\n-(define_insn \"*atomic_anddi\"\n-  [(set (match_operand:DI 0 \"gpc_reg_operand\" \"=r,r,r,r,r\")\n-\t(unspec:DI [(match_operand:DI 1 \"gpc_reg_operand\" \"%r,r,r,r,r\")\n-\t\t    (match_operand:DI 2 \"and_operand\" \"?r,S,T,K,J\")]\n-\t\t    UNSPEC_AND))]\n-  \"TARGET_POWERPC64\"\n-  \"@\n-   and %0,%1,%2\n-   rldic%B2 %0,%1,0,%S2\n-   rlwinm %0,%1,0,%m2,%M2\n-   andi. %0,%1,%b2\n-   andis. %0,%1,%u2\"\n-  [(set_attr \"type\" \"*,*,*,compare,compare\")\n-   (set_attr \"length\" \"4,4,4,4,4\")])\n-\n-; the sync_*_internal patterns all have these operands:\n-; 0 - memory location\n-; 1 - operand\n-; 2 - value in memory after operation\n-; 3 - value in memory immediately before operation\n-\n-(define_insn \"*sync_addshort_internal\"\n-  [(set (match_operand:SI 2 \"gpc_reg_operand\" \"=&r\")\n-\t(ior:SI (and:SI (plus:SI (match_operand:SI 0 \"memory_operand\" \"+Z\")\n-\t\t\t\t (match_operand:SI 1 \"add_operand\" \"rI\"))\n-\t\t\t(match_operand:SI 4 \"gpc_reg_operand\" \"r\"))\n-\t\t(and:SI (not:SI (match_dup 4)) (match_dup 0))))\n-   (set (match_operand:SI 3 \"gpc_reg_operand\" \"=&b\") (match_dup 0))\n-   (set (match_dup 0)\n-\t(unspec:SI [(ior:SI (and:SI (plus:SI (match_dup 0) (match_dup 1))\n-\t\t\t\t    (match_dup 4))\n-\t\t\t    (and:SI (not:SI (match_dup 4)) (match_dup 0)))]\n-\t\t   UNSPEC_SYNC_OP))\n-   (clobber (match_scratch:CC 5 \"=&x\"))\n-   (clobber (match_scratch:SI 6 \"=&r\"))]\n-  \"TARGET_POWERPC && !PPC405_ERRATUM77\"\n-  \"lwarx %3,%y0\\n\\tadd%I1 %2,%3,%1\\n\\tandc %6,%3,%4\\n\\tand %2,%2,%4\\n\\tor %2,%2,%6\\n\\tstwcx. %2,%y0\\n\\tbne- $-24\"\n-  [(set_attr \"length\" \"28\")])\n-\n-(define_insn \"*sync_subshort_internal\"\n-  [(set (match_operand:SI 2 \"gpc_reg_operand\" \"=&r\")\n-\t(ior:SI (and:SI (minus:SI (match_operand:SI 0 \"memory_operand\" \"+Z\")\n-\t\t\t\t  (match_operand:SI 1 \"add_operand\" \"rI\"))\n-\t\t\t(match_operand:SI 4 \"gpc_reg_operand\" \"r\"))\n-\t\t(and:SI (not:SI (match_dup 4)) (match_dup 0))))\n-   (set (match_operand:SI 3 \"gpc_reg_operand\" \"=&b\") (match_dup 0))\n-   (set (match_dup 0)\n-\t(unspec:SI [(ior:SI (and:SI (minus:SI (match_dup 0) (match_dup 1))\n-\t\t\t\t    (match_dup 4))\n-\t\t\t    (and:SI (not:SI (match_dup 4)) (match_dup 0)))]\n-\t\t   UNSPEC_SYNC_OP))\n-   (clobber (match_scratch:CC 5 \"=&x\"))\n-   (clobber (match_scratch:SI 6 \"=&r\"))]\n-  \"TARGET_POWERPC && !PPC405_ERRATUM77\"\n-  \"lwarx %3,%y0\\n\\tsubf %2,%1,%3\\n\\tandc %6,%3,%4\\n\\tand %2,%2,%4\\n\\tor %2,%2,%6\\n\\tstwcx. %2,%y0\\n\\tbne- $-24\"\n-  [(set_attr \"length\" \"28\")])\n-\n-(define_insn \"*sync_andsi_internal\"\n-  [(set (match_operand:SI 2 \"gpc_reg_operand\" \"=&r,&r,&r,&r\")\n-\t(and:SI (match_operand:SI 0 \"memory_operand\" \"+Z,Z,Z,Z\")\n-\t\t(match_operand:SI 1 \"and_operand\" \"r,T,K,L\")))\n-   (set (match_operand:SI 3 \"gpc_reg_operand\" \"=&b,&b,&b,&b\") (match_dup 0))\n-   (set (match_dup 0)\n-\t(unspec:SI [(and:SI (match_dup 0) (match_dup 1))]\n-\t\t   UNSPEC_SYNC_OP))\n-   (clobber (match_scratch:CC 4 \"=&x,&x,&x,&x\"))]\n-  \"TARGET_POWERPC && !PPC405_ERRATUM77\"\n-  \"@\n-   lwarx %3,%y0\\n\\tand %2,%3,%1\\n\\tstwcx. %2,%y0\\n\\tbne- $-12\n-   lwarx %3,%y0\\n\\trlwinm %2,%3,0,%m1,%M1\\n\\tstwcx. %2,%y0\\n\\tbne- $-12\n-   lwarx %3,%y0\\n\\tandi. %2,%3,%b1\\n\\tstwcx. %2,%y0\\n\\tbne- $-12\n-   lwarx %3,%y0\\n\\tandis. %2,%3,%u1\\n\\tstwcx. %2,%y0\\n\\tbne- $-12\"\n-  [(set_attr \"length\" \"16,16,16,16\")])\n-\n-(define_insn \"*sync_boolsi_internal\"\n-  [(set (match_operand:SI 2 \"gpc_reg_operand\" \"=&r,&r,&r\")\n-\t(match_operator:SI 4 \"boolean_or_operator\"\n-\t [(match_operand:SI 0 \"memory_operand\" \"+Z,Z,Z\")\n-\t  (match_operand:SI 1 \"logical_operand\" \"r,K,L\")]))\n-   (set (match_operand:SI 3 \"gpc_reg_operand\" \"=&b,&b,&b\") (match_dup 0))\n-   (set (match_dup 0) (unspec:SI [(match_dup 4)] UNSPEC_SYNC_OP))\n-   (clobber (match_scratch:CC 5 \"=&x,&x,&x\"))]\n-  \"TARGET_POWERPC && !PPC405_ERRATUM77\"\n-  \"@\n-   lwarx %3,%y0\\n\\t%q4 %2,%3,%1\\n\\tstwcx. %2,%y0\\n\\tbne- $-12\n-   lwarx %3,%y0\\n\\t%q4i %2,%3,%b1\\n\\tstwcx. %2,%y0\\n\\tbne- $-12\n-   lwarx %3,%y0\\n\\t%q4is %2,%3,%u1\\n\\tstwcx. %2,%y0\\n\\tbne- $-12\"\n-  [(set_attr \"length\" \"16,16,16\")])\n-\n-; This pattern could also take immediate values of operand 1,\n-; since the non-NOT version of the operator is used; but this is not\n-; very useful, since in practice operand 1 is a full 32-bit value.\n-; Likewise, operand 5 is in practice either <= 2^16 or it is a register.\n-(define_insn \"*sync_boolcshort_internal\"\n-  [(set (match_operand:SI 2 \"gpc_reg_operand\" \"=&r\")\n-\t(match_operator:SI 4 \"boolean_or_operator\"\n-\t [(xor:SI (not:SI (match_operand:SI 0 \"memory_operand\" \"+Z\"))\n-\t\t  (not:SI (match_operand:SI 5 \"logical_operand\" \"rK\")))\n-\t (match_operand:SI 1 \"gpc_reg_operand\" \"r\")]))\n-   (set (match_operand:SI 3 \"gpc_reg_operand\" \"=&b\") (match_dup 0))\n-   (set (match_dup 0) (unspec:SI [(match_dup 4)] UNSPEC_SYNC_OP))\n-   (clobber (match_scratch:CC 6 \"=&x\"))]\n-  \"TARGET_POWERPC && !PPC405_ERRATUM77\"\n-  \"lwarx %3,%y0\\n\\txor%I2 %2,%3,%5\\n\\t%q4 %2,%2,%1\\n\\tstwcx. %2,%y0\\n\\tbne- $-16\"\n-  [(set_attr \"length\" \"20\")])\n-\n-(define_insn \"isync\"\n-  [(set (mem:BLK (match_scratch 0 \"X\"))\n-\t(unspec_volatile:BLK [(mem:BLK (match_scratch 1 \"X\"))] UNSPECV_ISYNC))]\n-  \"\"\n-  \"{ics|isync}\"\n-  [(set_attr \"type\" \"isync\")])\n-\n-(define_expand \"sync_lock_release<mode>\"\n-  [(set (match_operand:INT 0 \"memory_operand\")\n-\t(match_operand:INT 1 \"any_operand\"))]\n-  \"\"\n-  \"\n+(define_expand \"atomic_nand_fetch<mode>\"\n+  [(match_operand:INT1 0 \"gpc_reg_operand\" \"\")\t\t;; output\n+   (match_operand:INT1 1 \"memory_operand\" \"\")\t\t;; memory\n+   (match_operand:INT1 2 \"gpc_reg_operand\" \"\")\t\t;; operand\n+   (match_operand:SI 3 \"const_int_operand\" \"\")]\t\t;; model\n+  \"TARGET_POWERPC\"\n {\n-  emit_insn (gen_lwsync ());\n-  emit_move_insn (operands[0], operands[1]);\n+  rs6000_expand_atomic_op (NOT, operands[1], operands[2],\n+\t\t\t   NULL_RTX, operands[0], operands[3]);\n   DONE;\n-}\")\n-\n-; Some AIX assemblers don't accept lwsync, so we use a .long.\n-(define_insn \"lwsync\"\n-  [(set (mem:BLK (match_scratch 0 \"X\"))\n-\t(unspec_volatile:BLK [(mem:BLK (match_scratch 1 \"X\"))] UNSPECV_LWSYNC))]\n-  \"\"\n-{\n-  if (TARGET_NO_LWSYNC)\n-    return \"sync\";\n-  else\n-    return (TARGET_LWSYNC_INSTRUCTION) ? \"lwsync\" : \".long 0x7c2004ac\";\n-}\n-  [(set_attr \"type\" \"sync\")])\n-\n+})"}]}