{"sha": "9deda8cb4ff27130817fefe0703f6f81df8edd65", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OWRlZGE4Y2I0ZmYyNzEzMDgxN2ZlZmUwNzAzZjZmODFkZjhlZGQ2NQ==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2013-10-15T15:31:38Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2013-10-15T15:31:38Z"}, "message": "[ARM] [Neon types 5/10] Update Cortex-A8 pipeline model\n\ngcc/\n\t* config/arm/cortex-a8-neon.md (cortex_a8_neon_type): New.\n\t* config/arm/cortex-a8-neon.md: Update all pipeline units.\n\nFrom-SVN: r203616", "tree": {"sha": "5bb1d091195a9f357ca13543420d2a8c6991cd9a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5bb1d091195a9f357ca13543420d2a8c6991cd9a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/9deda8cb4ff27130817fefe0703f6f81df8edd65", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9deda8cb4ff27130817fefe0703f6f81df8edd65", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9deda8cb4ff27130817fefe0703f6f81df8edd65", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9deda8cb4ff27130817fefe0703f6f81df8edd65/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "0f686aa9812eef0e6cc011e1c2ec7a3b6ff46921", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0f686aa9812eef0e6cc011e1c2ec7a3b6ff46921", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0f686aa9812eef0e6cc011e1c2ec7a3b6ff46921"}], "stats": {"total": 538, "additions": 414, "deletions": 124}, "files": [{"sha": "7b8aec77ab4cb4f47a475a0b3748a24ff9f9dfb1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 68, "deletions": 0, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9deda8cb4ff27130817fefe0703f6f81df8edd65/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9deda8cb4ff27130817fefe0703f6f81df8edd65/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=9deda8cb4ff27130817fefe0703f6f81df8edd65", "patch": "@@ -1,3 +1,71 @@\n+2013-10-15  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/arm/cortex-a8-neon.md (cortex_a8_neon_type): New.\n+\n+\t(cortex_a8_neon_vshl_ddd): Remove.\n+\t(cortex_a8_neon_vst3_vst4): Likewise.\n+\t(cortex_a8_neon_vld3_vld4_all_lanes): Likewise.\n+\n+\t(cortex_a8_neon_bit_ops_q): New.\n+\n+\t(cortex_a8_neon_int_1): Use cortex_a8_neon_type.\n+\t(cortex_a8_neon_int_2): Likewise..\n+\t(cortex_a8_neon_int_3): Likewise.\n+\t(cortex_a8_neon_int_5): Likewise.\n+\t(cortex_a8_neon_vqneg_vqabs): Likewise.\n+\t(cortex_a8_neon_int_4): Likewise.\n+\t(cortex_a8_neon_vaba): Likewise.\n+\t(cortex_a8_neon_vaba_qqq): Likewise.\n+\t(cortex_a8_neon_shift_1): Likewise.\n+\t(cortex_a8_neon_shift_2): Likewise.\n+\t(cortex_a8_neon_shift_3): Likewise.\n+\t(cortex_a8_neon_vqshl_vrshl_vqrshl_qqq): Likewise.\n+\t(cortex_a8_neon_vsra_vrsra): Likewise.\n+\t(cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long): Likewise.\n+\t(cortex_a8_neon_mul_qqq_8_16_32_ddd_32): Likewise.\n+\t(cortex_a8_neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar):\n+\tLikewise.\n+\t(cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long): Likewise.\n+\t(cortex_a8_neon_mla_qqq_8_16): Likewise.\n+\t(cortex_a8_neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long):\n+\tLikewise.\n+\t(cortex_a8_neon_mla_qqq_32_qqd_32_scalar): Likewise.\n+\t(cortex_a8_neon_mul_ddd_16_scalar_32_16_long_scalar): Likewise.\n+\t(cortex_a8_neon_mul_qqd_32_scalar): Likewise.\n+\t(cortex_a8_neon_mla_ddd_16_scalar_qdd_32_16_long_scalar): Likewise.\n+\t(cortex_a8_neon_fp_vadd_ddd_vabs_dd): Likewise.\n+\t(cortex_a8_neon_fp_vadd_qqq_vabs_qq): Likewise.\n+\t(cortex_a8_neon_fp_vsum): Likewise.\n+\t(cortex_a8_neon_fp_vmul_ddd): Likewise.\n+\t(cortex_a8_neon_fp_vmul_qqd): Likewise.\n+\t(cortex_a8_neon_fp_vmla_ddd): Likewise.\n+\t(cortex_a8_neon_fp_vmla_qqq): Likewise.\n+\t(cortex_a8_neon_fp_vmla_ddd_scalar): Likewise.\n+\t(cortex_a8_neon_fp_vmla_qqq_scalar): Likewise.\n+\t(cortex_a8_neon_fp_vrecps_vrsqrts_ddd): Likewise.\n+\t(cortex_a8_neon_fp_vrecps_vrsqrts_qqq): Likewise.\n+\t(cortex_a8_neon_bp_simple): Likewise.\n+\t(cortex_a8_neon_bp_2cycle): Likewise.\n+\t(cortex_a8_neon_bp_3cycle): Likewise.\n+\t(cortex_a8_neon_ldr): Likewise.\n+\t(cortex_a8_neon_str): Likewise.\n+\t(cortex_a8_neon_vld1_1_2_regs): Likewise.\n+\t(cortex_a8_neon_vld1_3_4_regs): Likewise.\n+\t(cortex_a8_neon_vld2_2_regs_vld1_vld2_all_lanes): Likewise.\n+\t(cortex_a8_neon_vld2_4_regs): Likewise.\n+\t(cortex_a8_neon_vld3_vld4): Likewise.\n+\t(cortex_a8_neon_vld1_vld2_lane): Likewise.\n+\t(cortex_a8_neon_vld3_vld4_lane): Likewise.\n+\t(cortex_a8_neon_vst1_1_2_regs_vst2_2_regs): Likewise.\n+\t(cortex_a8_neon_vst1_3_4_regs): Likewise.\n+\t(cortex_a8_neon_vst2_4_regs_vst3_vst4): Likewise.\n+\t(cortex_a8_neon_vst1_vst2_lane): Likewise.\n+\t(cortex_a8_neon_vst3_vst4_lane): Likewise.\n+\t(cortex_a8_neon_mcr): Likewise.\n+\t(cortex_a8_neon_mcr_2_mcrr): Likewise.\n+\t(cortex_a8_neon_mrc): Likewise.\n+\t(cortex_a8_neon_mrrc): Likewise.\n+\n 2013-10-15  James Greenhalgh  <james.greenhalgh@arm.com>\n \n \t* config/aarch64/iterators.md (Vetype): Add SF and DF modes."}, {"sha": "6adfd1365693c55550230b8b97f5419043144f8c", "filename": "gcc/config/arm/cortex-a8-neon.md", "status": "modified", "additions": 346, "deletions": 124, "changes": 470, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9deda8cb4ff27130817fefe0703f6f81df8edd65/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9deda8cb4ff27130817fefe0703f6f81df8edd65/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md?ref=9deda8cb4ff27130817fefe0703f6f81df8edd65", "patch": "@@ -18,6 +18,221 @@\n ;; along with GCC; see the file COPYING3.  If not see\n ;; <http://www.gnu.org/licenses/>.\n \n+(define_attr \"cortex_a8_neon_type\"\n+   \"neon_int_1,neon_int_2,neon_int_3,neon_int_4,neon_int_5,neon_vqneg_vqabs,\n+   neon_bit_ops_q,\n+   neon_vaba,neon_vaba_qqq, neon_vmov,\n+   neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,neon_mul_qqq_8_16_32_ddd_32,\n+   neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar,\n+   neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,neon_mla_qqq_8_16,\n+   neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long,\n+   neon_mla_qqq_32_qqd_32_scalar,neon_mul_ddd_16_scalar_32_16_long_scalar,\n+   neon_mul_qqd_32_scalar,neon_mla_ddd_16_scalar_qdd_32_16_long_scalar,\n+   neon_shift_1,neon_shift_2,neon_shift_3,\n+   neon_vqshl_vrshl_vqrshl_qqq,neon_vsra_vrsra,neon_fp_vadd_ddd_vabs_dd,\n+   neon_fp_vadd_qqq_vabs_qq,neon_fp_vsum,neon_fp_vmul_ddd,neon_fp_vmul_qqd,\n+   neon_fp_vmla_ddd,neon_fp_vmla_qqq,neon_fp_vmla_ddd_scalar,\n+   neon_fp_vmla_qqq_scalar,neon_fp_vrecps_vrsqrts_ddd,\n+   neon_fp_vrecps_vrsqrts_qqq,neon_bp_simple,neon_bp_2cycle,neon_bp_3cycle,\n+   neon_ldr,neon_str,neon_vld1_1_2_regs,neon_vld1_3_4_regs,\n+   neon_vld2_2_regs_vld1_vld2_all_lanes,neon_vld2_4_regs,neon_vld3_vld4,\n+   neon_vst1_1_2_regs_vst2_2_regs,neon_vst1_3_4_regs,\n+   neon_vst2_4_regs_vst3_vst4,neon_vld1_vld2_lane,\n+   neon_vld3_vld4_lane,neon_vst1_vst2_lane,neon_vst3_vst4_lane,\n+   neon_vld3_vld4_all_lanes,neon_mcr,neon_mcr_2_mcrr,neon_mrc,neon_mrrc,\n+   neon_ldm_2,neon_stm_2,none,unknown\"\n+  (cond [\n+          (eq_attr \"type\" \"neon_logic, neon_logic_q,\\\n+                           neon_bsl, neon_cls, neon_cnt,\\\n+                           neon_add, neon_add_q\")\n+                          (const_string \"neon_int_1\")\n+          (eq_attr \"type\" \"neon_add_widen, neon_sub_widen,\\\n+                           neon_sub, neon_sub_q\")\n+                          (const_string \"neon_int_2\")\n+          (eq_attr \"type\" \"neon_neg, neon_neg_q,\\\n+                           neon_reduc_add, neon_reduc_add_q,\\\n+                           neon_reduc_add_long,\\\n+                           neon_add_long, neon_sub_long\")\n+                          (const_string \"neon_int_3\")\n+          (eq_attr \"type\" \"neon_abs, neon_abs_q,\n+                           neon_compare_zero, neon_compare_zero_q,\\\n+                           neon_add_halve_narrow_q,\\\n+                           neon_sub_halve_narrow_q,\\\n+                           neon_add_halve, neon_add_halve_q,\\\n+                           neon_qadd, neon_qadd_q,\\\n+                           neon_tst, neon_tst_q\")\n+                          (const_string \"neon_int_4\")\n+          (eq_attr \"type\" \"neon_abd_long, neon_sub_halve, neon_sub_halve_q,\\\n+                           neon_qsub, neon_qsub_q,\\\n+                           neon_abd, neon_abd_q,\\\n+                           neon_compare, neon_compare_q,\\\n+                           neon_minmax, neon_minmax_q, neon_reduc_minmax,\\\n+                           neon_reduc_minmax_q\")\n+                          (const_string \"neon_int_5\")\n+          (eq_attr \"type\" \"neon_qneg, neon_qneg_q, neon_qabs, neon_qabs_q\")\n+                           (const_string \"neon_vqneg_vqabs\")\n+          (eq_attr \"type\" \"neon_move, neon_move_q\")\n+                           (const_string \"neon_vmov\")\n+          (eq_attr \"type\" \"neon_bsl_q, neon_cls_q, neon_cnt_q\")\n+                           (const_string \"neon_bit_ops_q\")\n+          (eq_attr \"type\" \"neon_arith_acc, neon_reduc_add_acc\")\n+                          (const_string \"neon_vaba\")\n+          (eq_attr \"type\" \"neon_arith_acc_q\")\n+                          (const_string \"neon_vaba_qqq\")\n+          (eq_attr \"type\" \"neon_shift_imm, neon_shift_imm_q,\\\n+                           neon_shift_imm_long, neon_shift_imm_narrow_q,\\\n+                           neon_shift_reg\")\n+                           (const_string \"neon_shift_1\")\n+          (eq_attr \"type\" \"neon_sat_shift_imm, neon_sat_shift_imm_q,\n+                           neon_sat_shift_imm_narrow_q,\\\n+                           neon_sat_shift_reg\")\n+                           (const_string \"neon_shift_2\")\n+          (eq_attr \"type\" \"neon_shift_reg_q\")\n+                           (const_string \"neon_shift_3\")\n+          (eq_attr \"type\" \"neon_sat_shift_reg_q\")\n+                           (const_string \"neon_vqshl_vrshl_vqrshl_qqq\")\n+          (eq_attr \"type\" \"neon_shift_acc, neon_shift_acc_q\")\n+                           (const_string \"neon_vsra_vrsra\")\n+          (eq_attr \"type\" \"neon_mul_b, neon_mul_h,\\\n+                           neon_mul_b_long, neon_mul_h_long,\\\n+                           neon_sat_mul_b, neon_sat_mul_h,\\\n+                           neon_sat_mul_b_long, neon_sat_mul_h_long\")\n+                           (const_string\n+                            \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\")\n+          (eq_attr \"type\" \"neon_mul_b_q, neon_mul_h_q,\\\n+                           neon_sat_mul_b_q, neon_sat_mul_h_q\")\n+                           (const_string \"neon_mul_qqq_8_16_32_ddd_32\")\n+          (eq_attr \"type\" \"neon_mul_s, neon_mul_s_long,\\\n+                           neon_sat_mul_s, neon_sat_mul_s_long,\\\n+                           neon_mul_h_scalar_q, neon_sat_mul_h_scalar_q,\\\n+                           neon_mul_s_scalar, neon_sat_mul_s_scalar,\\\n+                           neon_mul_s_scalar_long,\\\n+                           neon_sat_mul_s_scalar_long\")\n+                           (const_string\n+             \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")\n+          (eq_attr \"type\" \"neon_mla_b, neon_mla_h,\\\n+                           neon_mla_b_long, neon_mla_h_long,\\\n+                           neon_sat_mla_b_long, neon_sat_mla_h_long,\\\n+                           neon_sat_mla_h_scalar_long\")\n+                           (const_string\n+                             \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\")\n+          (eq_attr \"type\" \"neon_mla_b_q, neon_mla_h_q\")\n+                           (const_string \"neon_mla_qqq_8_16\")\n+          (eq_attr \"type\" \"neon_mla_s, neon_mla_s_long,\\\n+                           neon_sat_mla_s_long,\\\n+                           neon_mla_h_scalar_q, neon_mla_s_scalar,\\\n+                           neon_mla_s_scalar_long,\\\n+                           neon_sat_mla_s_scalar_long\")\n+                           (const_string\n+ \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")\n+          (eq_attr \"type\" \"neon_mla_s_q, neon_mla_s_scalar_q\")\n+                           (const_string \"neon_mla_qqq_32_qqd_32_scalar\")\n+          (eq_attr \"type\" \"neon_mul_h_scalar, neon_sat_mul_h_scalar,\\\n+                           neon_mul_h_scalar_long,\\\n+                           neon_sat_mul_h_scalar_long\")\n+                          (const_string\n+                            \"neon_mul_ddd_16_scalar_32_16_long_scalar\")\n+          (eq_attr \"type\" \"neon_mul_s_q, neon_sat_mul_s_q,\\\n+                           neon_mul_s_scalar_q\")\n+                           (const_string \"neon_mul_qqd_32_scalar\")\n+          (eq_attr \"type\" \"neon_mla_h_scalar, neon_mla_h_scalar_long\")\n+                           (const_string\n+                             \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\")\n+          (eq_attr \"type\" \"neon_fp_abd_s, neon_fp_abs_s, neon_fp_neg_s,\\\n+                           neon_fp_addsub_s, neon_fp_compare_s,\\\n+                           neon_fp_minmax_s, neon_fp_mul_s,\\\n+                           neon_fp_recpe_s, neon_fp_rsqrte_s,\\\n+                           neon_fp_to_int_s, neon_int_to_fp_s\")\n+                           (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+          (eq_attr \"type\" \"neon_fp_abd_s_q, neon_fp_abs_s_q,\\\n+                           neon_fp_neg_s_q,\\\n+                           neon_fp_addsub_s_q, neon_fp_compare_s_q,\\\n+                           neon_fp_minmax_s_q, neon_fp_mul_s_q,\\\n+                           neon_fp_recpe_s_q, neon_fp_rsqrte_s_q,\\\n+                           neon_fp_to_int_s_q, neon_int_to_fp_s_q\")\n+                           (const_string \"neon_fp_vadd_qqq_vabs_qq\")\n+          (eq_attr \"type\" \"neon_fp_reduc_add_s, neon_fp_reduc_minmax_s,\\\n+                           neon_fp_reduc_add_s_q, neon_fp_reduc_minmax_s_q\")\n+                           (const_string \"neon_fp_vsum\")\n+          (eq_attr \"type\" \"neon_fp_mul_s_scalar\")\n+                           (const_string \"neon_fp_vmul_ddd\")\n+          (eq_attr \"type\" \"neon_fp_mul_s_scalar_q\")\n+                           (const_string \"neon_fp_vmul_qqd\")\n+          (eq_attr \"type\" \"neon_fp_mla_s\")\n+                           (const_string \"neon_fp_vmla_ddd\")\n+          (eq_attr \"type\" \"neon_fp_mla_s_q\")\n+                           (const_string \"neon_fp_vmla_qqq\")\n+          (eq_attr \"type\" \"neon_fp_mla_s_scalar\")\n+                           (const_string \"neon_fp_vmla_ddd_scalar\")\n+          (eq_attr \"type\" \"neon_fp_mla_s_scalar_q\")\n+                           (const_string \"neon_fp_vmla_qqq_scalar\")\n+          (eq_attr \"type\" \"neon_fp_recps_s, neon_fp_rsqrts_s\")\n+                           (const_string \"neon_fp_vrecps_vrsqrts_ddd\")\n+          (eq_attr \"type\" \"neon_fp_recps_s_q, neon_fp_rsqrts_s_q\")\n+                           (const_string \"neon_fp_vrecps_vrsqrts_qqq\")\n+          (eq_attr \"type\" \"neon_move_narrow_q, neon_dup,\\\n+                           neon_dup_q, neon_permute, neon_zip,\\\n+                           neon_ext, neon_rev, neon_rev_q\")\n+                           (const_string \"neon_bp_simple\")\n+          (eq_attr \"type\" \"neon_permute_q, neon_ext_q, neon_tbl1, neon_tbl2\")\n+                           (const_string \"neon_bp_2cycle\")\n+          (eq_attr \"type\" \"neon_zip_q, neon_tbl3, neon_tbl4\")\n+                           (const_string \"neon_bp_3cycle\")\n+          (eq_attr \"type\" \"neon_ldr\")\n+                           (const_string \"neon_ldr\")\n+          (eq_attr \"type\" \"neon_str\")\n+                           (const_string \"neon_str\")\n+          (eq_attr \"type\" \"neon_load1_1reg, neon_load1_1reg_q,\\\n+                           neon_load1_2reg, neon_load1_2reg_q,\\\n+                           neon_load2_2reg, neon_load2_2reg_q\")\n+                           (const_string \"neon_vld1_1_2_regs\")\n+          (eq_attr \"type\" \"neon_load1_3reg, neon_load1_3reg_q,\\\n+                           neon_load1_4reg, neon_load1_4reg_q\")\n+                           (const_string \"neon_vld1_3_4_regs\")\n+          (eq_attr \"type\" \"neon_load1_all_lanes, neon_load1_all_lanes_q,\\\n+                           neon_load2_all_lanes, neon_load2_all_lanes_q\")\n+                           (const_string\n+                              \"neon_vld2_2_regs_vld1_vld2_all_lanes\")\n+          (eq_attr \"type\" \"neon_load3_all_lanes, neon_load3_all_lanes_q,\\\n+                           neon_load4_all_lanes, neon_load4_all_lanes_q,\\\n+                           neon_load2_4reg, neon_load2_4reg_q\")\n+                           (const_string \"neon_vld2_4_regs\")\n+          (eq_attr \"type\" \"neon_load3_3reg, neon_load3_3reg_q,\\\n+                           neon_load4_4reg, neon_load4_4reg_q\")\n+                           (const_string \"neon_vld3_vld4\")\n+          (eq_attr \"type\" \"f_loads, f_loadd, f_stores, f_stored,\\\n+                           neon_load1_one_lane, neon_load1_one_lane_q,\\\n+                           neon_load2_one_lane, neon_load2_one_lane_q\")\n+                           (const_string \"neon_vld1_vld2_lane\")\n+          (eq_attr \"type\" \"neon_load3_one_lane, neon_load3_one_lane_q,\\\n+                           neon_load4_one_lane, neon_load4_one_lane_q\")\n+                           (const_string \"neon_vld3_vld4_lane\")\n+          (eq_attr \"type\" \"neon_store1_1reg, neon_store1_1reg_q,\\\n+                           neon_store1_2reg, neon_store1_2reg_q,\\\n+                           neon_store2_2reg, neon_store2_2reg_q\")\n+                           (const_string \"neon_vst1_1_2_regs_vst2_2_regs\")\n+          (eq_attr \"type\" \"neon_store1_3reg, neon_store1_3reg_q,\\\n+                           neon_store1_4reg, neon_store1_4reg_q\")\n+                           (const_string \"neon_vst1_3_4_regs\")\n+          (eq_attr \"type\" \"neon_store2_4reg, neon_store2_4reg_q,\\\n+                           neon_store3_3reg, neon_store3_3reg_q,\\\n+                           neon_store4_4reg, neon_store4_4reg_q\")\n+                           (const_string \"neon_vst2_4_regs_vst3_vst4\")\n+          (eq_attr \"type\" \"neon_store1_one_lane, neon_store1_one_lane_q,\\\n+                           neon_store2_one_lane, neon_store2_one_lane_q\")\n+                           (const_string \"neon_vst1_vst2_lane\")\n+          (eq_attr \"type\" \"neon_store3_one_lane, neon_store3_one_lane_q,\\\n+                           neon_store4_one_lane, neon_store4_one_lane_q\")\n+                           (const_string \"neon_vst3_vst4_lane\")\n+          (eq_attr \"type\" \"neon_from_gp, f_mcr\")\n+                           (const_string \"neon_mcr\")\n+          (eq_attr \"type\" \"neon_from_gp_q, f_mcrr\")\n+                           (const_string \"neon_mcr_2_mcrr\")\n+          (eq_attr \"type\" \"neon_to_gp, f_mrc\")\n+                           (const_string \"neon_mrc\")\n+          (eq_attr \"type\" \"neon_to_gp_q, f_mrrc\")\n+                           (const_string \"neon_mrrc\")]\n+          (const_string \"unknown\")))\n \n (define_automaton \"cortex_a8_neon\")\n \n@@ -184,421 +399,423 @@\n \n (define_insn_reservation \"cortex_a8_neon_mrc\" 20\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mrc\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mrc\"))\n   \"cortex_a8_neon_ls\")\n \n (define_insn_reservation \"cortex_a8_neon_mrrc\" 21\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mrrc\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mrrc\"))\n   \"cortex_a8_neon_ls_2\")\n \n-;; The remainder of this file is auto-generated by neon-schedgen.\n+;; Arithmetic Operations\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N3.\n (define_insn_reservation \"cortex_a8_neon_int_1\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_int_1\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_int_1\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)m operands at N1,\n ;; their (D|Q)n operands at N2, and produce a result at N3.\n (define_insn_reservation \"cortex_a8_neon_int_2\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_int_2\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_int_2\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N3.\n (define_insn_reservation \"cortex_a8_neon_int_3\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_int_3\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_int_3\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N4.\n (define_insn_reservation \"cortex_a8_neon_int_4\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_int_4\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_int_4\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)m operands at N1,\n ;; their (D|Q)n operands at N2, and produce a result at N4.\n (define_insn_reservation \"cortex_a8_neon_int_5\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_int_5\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_int_5\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N4.\n (define_insn_reservation \"cortex_a8_neon_vqneg_vqabs\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vqneg_vqabs\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vqneg_vqabs\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation produce a result at N3.\n (define_insn_reservation \"cortex_a8_neon_vmov\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vmov\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vmov\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6.\n (define_insn_reservation \"cortex_a8_neon_vaba\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vaba\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vaba\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_vaba_qqq\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vaba_qqq\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vaba_qqq\"))\n   \"cortex_a8_neon_dp_2\")\n \n-;; Instructions using this reservation read their (D|Q)m operands at N1,\n-;; their (D|Q)d operands at N3, and produce a result at N6.\n-(define_insn_reservation \"cortex_a8_neon_vsma\" 6\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N3 on cycle 2.\n+(define_insn_reservation \"cortex_a8_neon_bit_ops_q\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vsma\"))\n-  \"cortex_a8_neon_dp\")\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_bit_ops_q\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Integer Multiply/Accumulate Operations\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N6.\n (define_insn_reservation \"cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"))\n+       (eq_attr \"cortex_a8_neon_type\"\n+         \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N6 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_mul_qqq_8_16_32_ddd_32\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mul_qqq_8_16_32_ddd_32\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mul_qqq_8_16_32_ddd_32\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N6 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"))\n+       (eq_attr \"cortex_a8_neon_type\"\n+            \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N6.\n (define_insn_reservation \"cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"))\n+       (eq_attr \"cortex_a8_neon_type\"\n+                  \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_mla_qqq_8_16\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mla_qqq_8_16\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mla_qqq_8_16\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))\n+       (eq_attr \"cortex_a8_neon_type\"\n+ \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 4.\n (define_insn_reservation \"cortex_a8_neon_mla_qqq_32_qqd_32_scalar\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mla_qqq_32_qqd_32_scalar\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mla_qqq_32_qqd_32_scalar\"))\n   \"cortex_a8_neon_dp_4\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N6.\n (define_insn_reservation \"cortex_a8_neon_mul_ddd_16_scalar_32_16_long_scalar\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mul_ddd_16_scalar_32_16_long_scalar\"))\n+       (eq_attr \"cortex_a8_neon_type\"\n+                  \"neon_mul_ddd_16_scalar_32_16_long_scalar\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N6 on cycle 4.\n (define_insn_reservation \"cortex_a8_neon_mul_qqd_32_scalar\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mul_qqd_32_scalar\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mul_qqd_32_scalar\"))\n   \"cortex_a8_neon_dp_4\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6.\n (define_insn_reservation \"cortex_a8_neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"))\n+       (eq_attr \"cortex_a8_neon_type\"\n+                  \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"))\n   \"cortex_a8_neon_dp\")\n \n+;; Shift Operations\n+\n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N3.\n (define_insn_reservation \"cortex_a8_neon_shift_1\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_shift_1\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_shift_1\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N4.\n (define_insn_reservation \"cortex_a8_neon_shift_2\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_shift_2\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_shift_2\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N3 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_shift_3\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_shift_3\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_shift_3\"))\n   \"cortex_a8_neon_dp_2\")\n \n-;; Instructions using this reservation read their source operands at N1, and\n-;; produce a result at N1.\n-(define_insn_reservation \"cortex_a8_neon_vshl_ddd\" 1\n-  (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vshl_ddd\"))\n-  \"cortex_a8_neon_dp\")\n-\n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N4 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_vqshl_vrshl_vqrshl_qqq\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vqshl_vrshl_vqrshl_qqq\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vqshl_vrshl_vqrshl_qqq\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)m operands at N1,\n ;; their (D|Q)d operands at N3, and produce a result at N6.\n (define_insn_reservation \"cortex_a8_neon_vsra_vrsra\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vsra_vrsra\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vsra_vrsra\"))\n   \"cortex_a8_neon_dp\")\n \n+;; Floating point Operations\n+\n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N5.\n (define_insn_reservation \"cortex_a8_neon_fp_vadd_ddd_vabs_dd\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vadd_ddd_vabs_dd\"))\n-  \"cortex_a8_neon_fadd\")\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vadd_ddd_vabs_dd\"))\n+ \"cortex_a8_neon_fadd\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N5 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_fp_vadd_qqq_vabs_qq\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vadd_qqq_vabs_qq\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vadd_qqq_vabs_qq\"))\n   \"cortex_a8_neon_fadd_2\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N5.\n (define_insn_reservation \"cortex_a8_neon_fp_vsum\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vsum\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vsum\"))\n   \"cortex_a8_neon_fadd\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N5.\n (define_insn_reservation \"cortex_a8_neon_fp_vmul_ddd\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vmul_ddd\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vmul_ddd\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N5 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_fp_vmul_qqd\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vmul_qqd\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vmul_qqd\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N9.\n (define_insn_reservation \"cortex_a8_neon_fp_vmla_ddd\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vmla_ddd\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vmla_ddd\"))\n   \"cortex_a8_neon_fmul_then_fadd\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N9 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_fp_vmla_qqq\" 10\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vmla_qqq\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vmla_qqq\"))\n   \"cortex_a8_neon_fmul_then_fadd_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N9.\n (define_insn_reservation \"cortex_a8_neon_fp_vmla_ddd_scalar\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vmla_ddd_scalar\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vmla_ddd_scalar\"))\n   \"cortex_a8_neon_fmul_then_fadd\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N9 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_fp_vmla_qqq_scalar\" 10\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vmla_qqq_scalar\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vmla_qqq_scalar\"))\n   \"cortex_a8_neon_fmul_then_fadd_2\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N9.\n (define_insn_reservation \"cortex_a8_neon_fp_vrecps_vrsqrts_ddd\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vrecps_vrsqrts_ddd\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_fp_vrecps_vrsqrts_ddd\"))\n   \"cortex_a8_neon_fmul_then_fadd\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N9 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_fp_vrecps_vrsqrts_qqq\" 10\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_fp_vrecps_vrsqrts_qqq\"))\n+       (eq_attr \"type\" \"neon_fp_recps_s_q, neon_fp_rsqrts_s_q\"))\n   \"cortex_a8_neon_fmul_then_fadd_2\")\n \n+;; Permute operations.\n+\n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2.\n (define_insn_reservation \"cortex_a8_neon_bp_simple\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_bp_simple\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_bp_simple\"))\n   \"cortex_a8_neon_perm\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_bp_2cycle\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_bp_2cycle\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_bp_2cycle\"))\n   \"cortex_a8_neon_perm_2\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 3.\n (define_insn_reservation \"cortex_a8_neon_bp_3cycle\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_bp_3cycle\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_bp_3cycle\"))\n   \"cortex_a8_neon_perm_3\")\n \n+;; Load Operations.\n+\n ;; Instructions using this reservation produce a result at N1.\n (define_insn_reservation \"cortex_a8_neon_ldr\" 1\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_ldr\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_ldr\"))\n   \"cortex_a8_neon_ls\")\n \n ;; Instructions using this reservation read their source operands at N1.\n (define_insn_reservation \"cortex_a8_neon_str\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_str\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_str\"))\n   \"cortex_a8_neon_ls\")\n \n ;; Instructions using this reservation produce a result at N1 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_vld1_1_2_regs\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld1_1_2_regs\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vld1_1_2_regs\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation produce a result at N1 on cycle 3.\n (define_insn_reservation \"cortex_a8_neon_vld1_3_4_regs\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld1_3_4_regs\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vld1_3_4_regs\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation produce a result at N2 on cycle 2.\n (define_insn_reservation \"cortex_a8_neon_vld2_2_regs_vld1_vld2_all_lanes\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld2_2_regs_vld1_vld2_all_lanes\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vld2_2_regs_vld1_vld2_all_lanes\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation produce a result at N2 on cycle 3.\n (define_insn_reservation \"cortex_a8_neon_vld2_4_regs\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld2_4_regs\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vld2_4_regs\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation produce a result at N2 on cycle 4.\n (define_insn_reservation \"cortex_a8_neon_vld3_vld4\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld3_vld4\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vld3_vld4\"))\n   \"cortex_a8_neon_ls_4\")\n \n+;; Store operations.\n+\n ;; Instructions using this reservation read their source operands at N1.\n (define_insn_reservation \"cortex_a8_neon_vst1_1_2_regs_vst2_2_regs\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vst1_1_2_regs_vst2_2_regs\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vst1_1_2_regs_vst2_2_regs\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation read their source operands at N1.\n (define_insn_reservation \"cortex_a8_neon_vst1_3_4_regs\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vst1_3_4_regs\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vst1_3_4_regs\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation read their source operands at N1.\n (define_insn_reservation \"cortex_a8_neon_vst2_4_regs_vst3_vst4\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vst2_4_regs_vst3_vst4\"))\n-  \"cortex_a8_neon_ls_4\")\n-\n-;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"cortex_a8_neon_vst3_vst4\" 0\n-  (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vst3_vst4\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vst2_4_regs_vst3_vst4\"))\n   \"cortex_a8_neon_ls_4\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 3.\n (define_insn_reservation \"cortex_a8_neon_vld1_vld2_lane\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld1_vld2_lane\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vld1_vld2_lane\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 5.\n (define_insn_reservation \"cortex_a8_neon_vld3_vld4_lane\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld3_vld4_lane\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vld3_vld4_lane\"))\n   \"cortex_a8_neon_ls_5\")\n \n ;; Instructions using this reservation read their source operands at N1.\n (define_insn_reservation \"cortex_a8_neon_vst1_vst2_lane\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vst1_vst2_lane\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vst1_vst2_lane\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation read their source operands at N1.\n (define_insn_reservation \"cortex_a8_neon_vst3_vst4_lane\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vst3_vst4_lane\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_vst3_vst4_lane\"))\n   \"cortex_a8_neon_ls_3\")\n \n-;; Instructions using this reservation produce a result at N2 on cycle 2.\n-(define_insn_reservation \"cortex_a8_neon_vld3_vld4_all_lanes\" 3\n-  (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_vld3_vld4_all_lanes\"))\n-  \"cortex_a8_neon_ls_3\")\n+;; Register Transfer Operations\n \n ;; Instructions using this reservation produce a result at N2.\n (define_insn_reservation \"cortex_a8_neon_mcr\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mcr\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mcr\"))\n   \"cortex_a8_neon_perm\")\n \n ;; Instructions using this reservation produce a result at N2.\n (define_insn_reservation \"cortex_a8_neon_mcr_2_mcrr\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n-       (eq_attr \"type\" \"neon_mcr_2_mcrr\"))\n+       (eq_attr \"cortex_a8_neon_type\" \"neon_mcr_2_mcrr\"))\n   \"cortex_a8_neon_perm_2\")\n \n ;; Exceptions to the default latencies.\n \n (define_bypass 1 \"cortex_a8_neon_mcr_2_mcrr\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -613,20 +830,7 @@\n (define_bypass 1 \"cortex_a8_neon_mcr\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n-               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n-               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               cortex_a8_neon_mla_qqq_8_16,\\\n-               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n-               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n-               cortex_a8_neon_fp_vmla_ddd,\\\n-               cortex_a8_neon_fp_vmla_qqq,\\\n-               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n-               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"cortex_a8_neon_vld3_vld4_all_lanes\"\n-               \"cortex_a8_neon_int_1,\\\n-               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -641,6 +845,7 @@\n (define_bypass 5 \"cortex_a8_neon_vld3_vld4_lane\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -655,6 +860,7 @@\n (define_bypass 3 \"cortex_a8_neon_vld1_vld2_lane\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -669,6 +875,7 @@\n (define_bypass 4 \"cortex_a8_neon_vld3_vld4\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -683,6 +890,7 @@\n (define_bypass 3 \"cortex_a8_neon_vld2_4_regs\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -697,6 +905,7 @@\n (define_bypass 2 \"cortex_a8_neon_vld2_2_regs_vld1_vld2_all_lanes\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -711,6 +920,7 @@\n (define_bypass 2 \"cortex_a8_neon_vld1_3_4_regs\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -725,6 +935,7 @@\n (define_bypass 1 \"cortex_a8_neon_vld1_1_2_regs\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -739,6 +950,7 @@\n (define_bypass 0 \"cortex_a8_neon_ldr\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -753,6 +965,7 @@\n (define_bypass 3 \"cortex_a8_neon_bp_3cycle\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -767,6 +980,7 @@\n (define_bypass 2 \"cortex_a8_neon_bp_2cycle\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -781,6 +995,7 @@\n (define_bypass 1 \"cortex_a8_neon_bp_simple\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -795,6 +1010,7 @@\n (define_bypass 9 \"cortex_a8_neon_fp_vrecps_vrsqrts_qqq\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -809,6 +1025,7 @@\n (define_bypass 8 \"cortex_a8_neon_fp_vrecps_vrsqrts_ddd\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -823,6 +1040,7 @@\n (define_bypass 9 \"cortex_a8_neon_fp_vmla_qqq_scalar\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -837,6 +1055,7 @@\n (define_bypass 8 \"cortex_a8_neon_fp_vmla_ddd_scalar\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -851,6 +1070,7 @@\n (define_bypass 9 \"cortex_a8_neon_fp_vmla_qqq\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -865,6 +1085,7 @@\n (define_bypass 8 \"cortex_a8_neon_fp_vmla_ddd\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -879,6 +1100,7 @@\n (define_bypass 5 \"cortex_a8_neon_fp_vmul_qqd\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -893,6 +1115,7 @@\n (define_bypass 4 \"cortex_a8_neon_fp_vmul_ddd\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -907,6 +1130,7 @@\n (define_bypass 4 \"cortex_a8_neon_fp_vsum\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -921,6 +1145,7 @@\n (define_bypass 5 \"cortex_a8_neon_fp_vadd_qqq_vabs_qq\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -935,6 +1160,7 @@\n (define_bypass 4 \"cortex_a8_neon_fp_vadd_ddd_vabs_dd\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -949,6 +1175,7 @@\n (define_bypass 5 \"cortex_a8_neon_vsra_vrsra\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -963,20 +1190,7 @@\n (define_bypass 4 \"cortex_a8_neon_vqshl_vrshl_vqrshl_qqq\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n-               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n-               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               cortex_a8_neon_mla_qqq_8_16,\\\n-               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n-               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n-               cortex_a8_neon_fp_vmla_ddd,\\\n-               cortex_a8_neon_fp_vmla_qqq,\\\n-               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n-               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 0 \"cortex_a8_neon_vshl_ddd\"\n-               \"cortex_a8_neon_int_1,\\\n-               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -991,6 +1205,7 @@\n (define_bypass 3 \"cortex_a8_neon_shift_3\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1005,6 +1220,7 @@\n (define_bypass 3 \"cortex_a8_neon_shift_2\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1019,6 +1235,7 @@\n (define_bypass 2 \"cortex_a8_neon_shift_1\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1033,6 +1250,7 @@\n (define_bypass 5 \"cortex_a8_neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1047,6 +1265,7 @@\n (define_bypass 8 \"cortex_a8_neon_mul_qqd_32_scalar\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1061,6 +1280,7 @@\n (define_bypass 5 \"cortex_a8_neon_mul_ddd_16_scalar_32_16_long_scalar\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1075,6 +1295,7 @@\n (define_bypass 8 \"cortex_a8_neon_mla_qqq_32_qqd_32_scalar\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1089,6 +1310,7 @@\n (define_bypass 6 \"cortex_a8_neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1103,6 +1325,7 @@\n (define_bypass 6 \"cortex_a8_neon_mla_qqq_8_16\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1117,6 +1340,7 @@\n (define_bypass 5 \"cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1131,6 +1355,7 @@\n (define_bypass 6 \"cortex_a8_neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1145,6 +1370,7 @@\n (define_bypass 6 \"cortex_a8_neon_mul_qqq_8_16_32_ddd_32\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1159,20 +1385,7 @@\n (define_bypass 5 \"cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n-               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n-               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               cortex_a8_neon_mla_qqq_8_16,\\\n-               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n-               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n-               cortex_a8_neon_fp_vmla_ddd,\\\n-               cortex_a8_neon_fp_vmla_qqq,\\\n-               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n-               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"cortex_a8_neon_vsma\"\n-               \"cortex_a8_neon_int_1,\\\n-               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1187,6 +1400,7 @@\n (define_bypass 6 \"cortex_a8_neon_vaba_qqq\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1201,6 +1415,7 @@\n (define_bypass 5 \"cortex_a8_neon_vaba\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1212,9 +1427,10 @@\n                cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n                cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n \n-(define_bypass 2 \"cortex_a8_neon_vmov\"\n+(define_bypass 3 \"cortex_a8_neon_bit_ops_q\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1229,6 +1445,7 @@\n (define_bypass 3 \"cortex_a8_neon_vqneg_vqabs\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1243,6 +1460,7 @@\n (define_bypass 3 \"cortex_a8_neon_int_5\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1257,6 +1475,7 @@\n (define_bypass 3 \"cortex_a8_neon_int_4\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1271,6 +1490,7 @@\n (define_bypass 2 \"cortex_a8_neon_int_3\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1285,6 +1505,7 @@\n (define_bypass 2 \"cortex_a8_neon_int_2\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n@@ -1299,6 +1520,7 @@\n (define_bypass 2 \"cortex_a8_neon_int_1\"\n                \"cortex_a8_neon_int_1,\\\n                cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_bit_ops_q,\\\n                cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n                cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n                cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\"}]}