{"sha": "70b043845d7c378c6a9361a6769885897d1018c2", "node_id": "C_kwDOANBUbNoAKDcwYjA0Mzg0NWQ3YzM3OGM2YTkzNjFhNjc2OTg4NTg5N2QxMDE4YzI", "commit": {"author": {"name": "H.J. Lu", "email": "hjl.tools@gmail.com", "date": "2021-11-30T13:31:26Z"}, "committer": {"name": "H.J. Lu", "email": "hjl.tools@gmail.com", "date": "2021-12-06T16:16:49Z"}, "message": "libsanitizer: Use SSE to save and restore XMM registers\n\nUse SSE, instead of AVX, to save and restore XMM registers to support\nprocessors without AVX.  The affected codes are unused in upstream since\n\nhttps://github.com/llvm/llvm-project/commit/66d4ce7e26a5\n\nand will be removed in\n\nhttps://reviews.llvm.org/D112604\n\nThis fixed\n\nFAIL: g++.dg/tsan/pthread_cond_clockwait.C   -O0  execution test\nFAIL: g++.dg/tsan/pthread_cond_clockwait.C   -O2  execution test\n\non machines without AVX.\n\n\tPR sanitizer/103466\n\t* tsan/tsan_rtl_amd64.S (__tsan_trace_switch_thunk): Replace\n\tvmovdqu with movdqu.\n\t(__tsan_report_race_thunk): Likewise.", "tree": {"sha": "0a3fdd43c8343743500745aafb483837846bbf21", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0a3fdd43c8343743500745aafb483837846bbf21"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/70b043845d7c378c6a9361a6769885897d1018c2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/70b043845d7c378c6a9361a6769885897d1018c2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/70b043845d7c378c6a9361a6769885897d1018c2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/70b043845d7c378c6a9361a6769885897d1018c2/comments", "author": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "committer": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0dc77a0c4942d3b264f8f8cfc2c509ecc02c3634", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0dc77a0c4942d3b264f8f8cfc2c509ecc02c3634", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0dc77a0c4942d3b264f8f8cfc2c509ecc02c3634"}], "stats": {"total": 128, "additions": 64, "deletions": 64}, "files": [{"sha": "c15b01e49e5252f772a4c07d2a7ad28f3da11158", "filename": "libsanitizer/tsan/tsan_rtl_amd64.S", "status": "modified", "additions": 64, "deletions": 64, "changes": 128, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/70b043845d7c378c6a9361a6769885897d1018c2/libsanitizer%2Ftsan%2Ftsan_rtl_amd64.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/70b043845d7c378c6a9361a6769885897d1018c2/libsanitizer%2Ftsan%2Ftsan_rtl_amd64.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_amd64.S?ref=70b043845d7c378c6a9361a6769885897d1018c2", "patch": "@@ -45,22 +45,22 @@ ASM_SYMBOL(__tsan_trace_switch_thunk):\n   # All XMM registers are caller-saved.\n   sub $0x100, %rsp\n   CFI_ADJUST_CFA_OFFSET(0x100)\n-  vmovdqu %xmm0, 0x0(%rsp)\n-  vmovdqu %xmm1, 0x10(%rsp)\n-  vmovdqu %xmm2, 0x20(%rsp)\n-  vmovdqu %xmm3, 0x30(%rsp)\n-  vmovdqu %xmm4, 0x40(%rsp)\n-  vmovdqu %xmm5, 0x50(%rsp)\n-  vmovdqu %xmm6, 0x60(%rsp)\n-  vmovdqu %xmm7, 0x70(%rsp)\n-  vmovdqu %xmm8, 0x80(%rsp)\n-  vmovdqu %xmm9, 0x90(%rsp)\n-  vmovdqu %xmm10, 0xa0(%rsp)\n-  vmovdqu %xmm11, 0xb0(%rsp)\n-  vmovdqu %xmm12, 0xc0(%rsp)\n-  vmovdqu %xmm13, 0xd0(%rsp)\n-  vmovdqu %xmm14, 0xe0(%rsp)\n-  vmovdqu %xmm15, 0xf0(%rsp)\n+  movdqu %xmm0, 0x0(%rsp)\n+  movdqu %xmm1, 0x10(%rsp)\n+  movdqu %xmm2, 0x20(%rsp)\n+  movdqu %xmm3, 0x30(%rsp)\n+  movdqu %xmm4, 0x40(%rsp)\n+  movdqu %xmm5, 0x50(%rsp)\n+  movdqu %xmm6, 0x60(%rsp)\n+  movdqu %xmm7, 0x70(%rsp)\n+  movdqu %xmm8, 0x80(%rsp)\n+  movdqu %xmm9, 0x90(%rsp)\n+  movdqu %xmm10, 0xa0(%rsp)\n+  movdqu %xmm11, 0xb0(%rsp)\n+  movdqu %xmm12, 0xc0(%rsp)\n+  movdqu %xmm13, 0xd0(%rsp)\n+  movdqu %xmm14, 0xe0(%rsp)\n+  movdqu %xmm15, 0xf0(%rsp)\n   # Align stack frame.\n   push %rbx  # non-scratch\n   CFI_ADJUST_CFA_OFFSET(8)\n@@ -78,22 +78,22 @@ ASM_SYMBOL(__tsan_trace_switch_thunk):\n   pop %rbx\n   CFI_ADJUST_CFA_OFFSET(-8)\n   # Restore scratch registers.\n-  vmovdqu 0x0(%rsp), %xmm0\n-  vmovdqu 0x10(%rsp), %xmm1\n-  vmovdqu 0x20(%rsp), %xmm2\n-  vmovdqu 0x30(%rsp), %xmm3\n-  vmovdqu 0x40(%rsp), %xmm4\n-  vmovdqu 0x50(%rsp), %xmm5\n-  vmovdqu 0x60(%rsp), %xmm6\n-  vmovdqu 0x70(%rsp), %xmm7\n-  vmovdqu 0x80(%rsp), %xmm8\n-  vmovdqu 0x90(%rsp), %xmm9\n-  vmovdqu 0xa0(%rsp), %xmm10\n-  vmovdqu 0xb0(%rsp), %xmm11\n-  vmovdqu 0xc0(%rsp), %xmm12\n-  vmovdqu 0xd0(%rsp), %xmm13\n-  vmovdqu 0xe0(%rsp), %xmm14\n-  vmovdqu 0xf0(%rsp), %xmm15\n+  movdqu 0x0(%rsp), %xmm0\n+  movdqu 0x10(%rsp), %xmm1\n+  movdqu 0x20(%rsp), %xmm2\n+  movdqu 0x30(%rsp), %xmm3\n+  movdqu 0x40(%rsp), %xmm4\n+  movdqu 0x50(%rsp), %xmm5\n+  movdqu 0x60(%rsp), %xmm6\n+  movdqu 0x70(%rsp), %xmm7\n+  movdqu 0x80(%rsp), %xmm8\n+  movdqu 0x90(%rsp), %xmm9\n+  movdqu 0xa0(%rsp), %xmm10\n+  movdqu 0xb0(%rsp), %xmm11\n+  movdqu 0xc0(%rsp), %xmm12\n+  movdqu 0xd0(%rsp), %xmm13\n+  movdqu 0xe0(%rsp), %xmm14\n+  movdqu 0xf0(%rsp), %xmm15\n   add $0x100, %rsp\n   CFI_ADJUST_CFA_OFFSET(-0x100)\n   pop %r11\n@@ -163,22 +163,22 @@ ASM_SYMBOL(__tsan_report_race_thunk):\n   # All XMM registers are caller-saved.\n   sub $0x100, %rsp\n   CFI_ADJUST_CFA_OFFSET(0x100)\n-  vmovdqu %xmm0, 0x0(%rsp)\n-  vmovdqu %xmm1, 0x10(%rsp)\n-  vmovdqu %xmm2, 0x20(%rsp)\n-  vmovdqu %xmm3, 0x30(%rsp)\n-  vmovdqu %xmm4, 0x40(%rsp)\n-  vmovdqu %xmm5, 0x50(%rsp)\n-  vmovdqu %xmm6, 0x60(%rsp)\n-  vmovdqu %xmm7, 0x70(%rsp)\n-  vmovdqu %xmm8, 0x80(%rsp)\n-  vmovdqu %xmm9, 0x90(%rsp)\n-  vmovdqu %xmm10, 0xa0(%rsp)\n-  vmovdqu %xmm11, 0xb0(%rsp)\n-  vmovdqu %xmm12, 0xc0(%rsp)\n-  vmovdqu %xmm13, 0xd0(%rsp)\n-  vmovdqu %xmm14, 0xe0(%rsp)\n-  vmovdqu %xmm15, 0xf0(%rsp)\n+  movdqu %xmm0, 0x0(%rsp)\n+  movdqu %xmm1, 0x10(%rsp)\n+  movdqu %xmm2, 0x20(%rsp)\n+  movdqu %xmm3, 0x30(%rsp)\n+  movdqu %xmm4, 0x40(%rsp)\n+  movdqu %xmm5, 0x50(%rsp)\n+  movdqu %xmm6, 0x60(%rsp)\n+  movdqu %xmm7, 0x70(%rsp)\n+  movdqu %xmm8, 0x80(%rsp)\n+  movdqu %xmm9, 0x90(%rsp)\n+  movdqu %xmm10, 0xa0(%rsp)\n+  movdqu %xmm11, 0xb0(%rsp)\n+  movdqu %xmm12, 0xc0(%rsp)\n+  movdqu %xmm13, 0xd0(%rsp)\n+  movdqu %xmm14, 0xe0(%rsp)\n+  movdqu %xmm15, 0xf0(%rsp)\n   # Align stack frame.\n   push %rbx  # non-scratch\n   CFI_ADJUST_CFA_OFFSET(8)\n@@ -196,22 +196,22 @@ ASM_SYMBOL(__tsan_report_race_thunk):\n   pop %rbx\n   CFI_ADJUST_CFA_OFFSET(-8)\n   # Restore scratch registers.\n-  vmovdqu 0x0(%rsp), %xmm0\n-  vmovdqu 0x10(%rsp), %xmm1\n-  vmovdqu 0x20(%rsp), %xmm2\n-  vmovdqu 0x30(%rsp), %xmm3\n-  vmovdqu 0x40(%rsp), %xmm4\n-  vmovdqu 0x50(%rsp), %xmm5\n-  vmovdqu 0x60(%rsp), %xmm6\n-  vmovdqu 0x70(%rsp), %xmm7\n-  vmovdqu 0x80(%rsp), %xmm8\n-  vmovdqu 0x90(%rsp), %xmm9\n-  vmovdqu 0xa0(%rsp), %xmm10\n-  vmovdqu 0xb0(%rsp), %xmm11\n-  vmovdqu 0xc0(%rsp), %xmm12\n-  vmovdqu 0xd0(%rsp), %xmm13\n-  vmovdqu 0xe0(%rsp), %xmm14\n-  vmovdqu 0xf0(%rsp), %xmm15\n+  movdqu 0x0(%rsp), %xmm0\n+  movdqu 0x10(%rsp), %xmm1\n+  movdqu 0x20(%rsp), %xmm2\n+  movdqu 0x30(%rsp), %xmm3\n+  movdqu 0x40(%rsp), %xmm4\n+  movdqu 0x50(%rsp), %xmm5\n+  movdqu 0x60(%rsp), %xmm6\n+  movdqu 0x70(%rsp), %xmm7\n+  movdqu 0x80(%rsp), %xmm8\n+  movdqu 0x90(%rsp), %xmm9\n+  movdqu 0xa0(%rsp), %xmm10\n+  movdqu 0xb0(%rsp), %xmm11\n+  movdqu 0xc0(%rsp), %xmm12\n+  movdqu 0xd0(%rsp), %xmm13\n+  movdqu 0xe0(%rsp), %xmm14\n+  movdqu 0xf0(%rsp), %xmm15\n   add $0x100, %rsp\n   CFI_ADJUST_CFA_OFFSET(-0x100)\n   pop %r11"}]}