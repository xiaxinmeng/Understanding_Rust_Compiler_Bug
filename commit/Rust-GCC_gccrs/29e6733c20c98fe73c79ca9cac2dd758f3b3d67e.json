{"sha": "29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MjllNjczM2MyMGM5OGZlNzNjNzljYTljYWMyZGQ3NThmM2IzZDY3ZQ==", "commit": {"author": {"name": "Michael Meissner", "email": "meissner@linux.vnet.ibm.com", "date": "2009-07-30T20:48:17Z"}, "committer": {"name": "Michael Meissner", "email": "meissner@gcc.gnu.org", "date": "2009-07-30T20:48:17Z"}, "message": "Add patch 5/6 for full power7/VSX support\n\nCo-Authored-By: Pat Haugen <pthaugen@us.ibm.com>\nCo-Authored-By: Revital Eres <eres@il.ibm.com>\n\nFrom-SVN: r150271", "tree": {"sha": "57363e9c9bcc2f879f86f63a88b7f0172e3f610d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/57363e9c9bcc2f879f86f63a88b7f0172e3f610d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/comments", "author": null, "committer": null, "parents": [{"sha": "1b3b24c2a6de2f8b4a0ce687e8f62d3eb1ee2b53", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1b3b24c2a6de2f8b4a0ce687e8f62d3eb1ee2b53", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1b3b24c2a6de2f8b4a0ce687e8f62d3eb1ee2b53"}], "stats": {"total": 5972, "additions": 5733, "deletions": 239}, "files": [{"sha": "4358c842638403633fc2a43a47d7607f94047b88", "filename": "gcc/ChangeLog", "status": "modified", "additions": 200, "deletions": 0, "changes": 200, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -1,3 +1,203 @@\n+2009-07-30  Michael Meissner  <meissner@linux.vnet.ibm.com>\n+\t    Pat Haugen  <pthaugen@us.ibm.com>\n+\t    Revital Eres <ERES@il.ibm.com>\n+\n+\t* config/rs6000/vector.md (VEC_F): Add VSX support.\n+\t(VEC_A): Ditto.\n+\t(VEC_N): Ditto.\n+\t(mov<mode>): Ditto.\n+\t(vector_load_<mode>): Ditto.\n+\t(vector_store_<mode>): Ditto.\n+\t(vector GPR move split): Ditto.\n+\t(vec_reload_and_plus_<mptrsize>): Ditto.\n+\t(vec_reload_and_reg_<mptrsize>): Ditto.\n+\t(add<mode>3): Ditto.\n+\t(sub<mode>3): Ditto.\n+\t(mul<mode>3): Ditto.\n+\t(neg<mode>2): Ditto.\n+\t(abs<mode>2): Ditto.\n+\t(smin<mode>3): Ditto.\n+\t(smax<mode>3): Ditto.\n+\t(vector_eq<mode>): Ditto.\n+\t(vector_gt<mode>): Ditto.\n+\t(vector_ge<mode>): Ditto.\n+\t(vector_gtu<mode>): Ditto.\n+\t(vector_select_<mode>_uns): Ditto.\n+\t(vector_eq_<mode>_p): Ditto.\n+\t(vector_gt_<mode>_p): Ditto.\n+\t(vector_ge_<mode>_p): Ditto.\n+\t(vector_gtu_<mode>_p): Ditto.\n+\t(cr6_test_for_zero): Ditto.\n+\t(cr6_test_for_zero_reverse): Ditto.\n+\t(cr6_test_for_lt): Ditto.\n+\t(cr6_test_for_lt_reverse): Ditto.\n+\t(xor<mode>3): Ditto.\n+\t(ior<mode>3): Ditto.\n+\t(and<mode>3): Ditto.\n+\t(one_cmpl<mode>2): Ditto.\n+\t(nor<mode>2): Ditto.\n+\t(andc<mode>2): Ditto.\n+\t(float<VEC_int<mode>2): Ditto.\n+\t(unsigned_float<VEC_int><mode>2): Ditto.\n+\t(fix_trunc<mode><VEC_int>2): Ditto.\n+\t(fixuns_trunc<mode><VEC_int>2): Ditto.\n+\t(vec_init<mode>):\n+\t(vec_set<mode>): Ditto.\n+\t(vec_extract<mode>): Ditto.\n+\t(vec_interleave_highv4sf): Ditto.\n+\t(vec_interleave_lowv4sf): Ditto.\n+\t(vec_realign_load_<mode>): Ditto.\n+\t(vec_shl_<mode>): Ditto.\n+\t(vec_shr_<mode>): Ditto.\n+\t(div<mode>3): New patterns for VSX.\n+\t(vec_interleave_highv2df): Ditto.\n+\t(vec_interleave_lowv2df): Ditto.\n+\t(vec_pack_trunc_v2df): Ditto.\n+\t(vec_pack_sfix_trunc_v2df): Ditto.\n+\t(vec_pack_ufix_trunc_v2df): Ditto.\n+\t(vec_unpacks_hi_v4sf): Ditto.\n+\t(vec_unpacks_lo_v4sf): Ditto.\n+\t(vec_unpacks_float_hi_v4si): Ditto.\n+\t(vec_unpacku_float_lo_v4si): Ditto.\n+\t(vec_unpacku_float_hi_v4si): Ditto.\n+\t(vec_unpacks_float_lo_v4si): Ditto.\n+\t(movmisalign<mode>): Ditto.\n+\t(vector_ceil<mode>2): New patterns for vectorizing math library.\n+\t(vector_floor<mode>2): Ditto.\n+\t(vector_btrunc<mode>2): Ditto.\n+\t(vector_copysign<mode>3): Ditto.\n+\n+\t* config/rs6000/predicates.md (easy_vector_constant_msb): New\n+\tpredicate for setting the high bit in each word, used for\n+\tcopysign.\n+\n+\t* config/rs6000/ppc-asm.h (f19): Whitespace.\n+\t(f32-f63): Define if VSX.\n+\t(v0-v31): Define if Altivec.\n+\t(vs0-vs63): Define if VSX.\n+\n+\t* config/rs6000/t-rs6000 (MD_INCLUDES): Add power7.md and vsx.md.\n+\n+\t* config/rs6000/power7.md: New file, provide tuning parameters for\n+\t-mcpu=power7.\n+\n+\t* config/rs6000/rs6000-c.c (rs6000_macro_to_expand): Add VSX\n+\tsupport.\n+\t(rs6000_cpu_cpp_builtins): Ditto.\n+\t(altivec_overloaded_builtins): Ditto.\n+\t(altivec_resolve_overloaded_builtin): Ditto.\n+\n+\t* config/rs6000/rs6000.opt (-mno-vectorize-builtins): Add new\n+\tdebug switch to disable vectorizing simple math builtin\n+\tfunctions.\n+\n+\t* config/rs6000/rs6000.c (rs6000_builtin_vectorized_function):\n+\tVectorize simple math builtin functions.\n+\t(TARGET_VECTORIZE_BUILTIN_VECTORIZED_FUNCTION): Define target\n+\thook to vectorize math builtins.\n+\t(rs6000_override_options): Enable -mvsx on -mcpu=power7.\n+\t(rs6000_builtin_conversion): Add VSX/power7 support.\n+\t(rs6000_builtin_vec_perm): Ditto.\n+\t(vsplits_constant): Add support for loading up a vector constant\n+\twith just the high bit set in each part.\n+\t(rs6000_expand_vector_init): Add VSX/power7 support.\n+\t(rs6000_expand_vector_set): Ditto.\n+\t(rs6000_expand_vector_extract): Ditto.\n+\t(rs6000_emit_move): Ditto.\n+\t(bdesc_3arg): Ditto.\n+\t(bdesc_2arg): Ditto.\n+\t(bdesc_1arg): Ditto.\n+\t(rs6000_expand_ternop_builtin): Ditto.\n+\t(altivec_expand_builtin): Ditto.\n+\t(rs6000_expand_unop_builtin): Ditto.\n+\t(rs6000_init_builtins): Ditto.\n+\t(altivec_init_builtins): Ditto.\n+\t(builtin_function_type): Ditto.\n+\t(rs6000_common_init_builtins): Ditto.\n+\t(rs6000_handle_altivec_attribute); Ditto.\n+\t(rs6000_mangle_type): Ditto.\n+\t(rs6000_vector_mode_supported_p): Ditto.\n+\t(rs6000_mode_dependent_address): Altivec addresses with AND -16\n+\tare mode dependent.\n+\n+\t* config/rs6000/vsx.md: New file for VSX support.\n+\n+\t* config/rs6000/rs6000.h (EASY_VECTOR_MSB): New macro for\n+\tidentifing values with just the most significant bit set.\n+\t(enum rs6000_builtins): Add builtins for VSX.  Add simple math\n+\tvectorized builtins.\n+\n+\t* config/rs6000/altivec.md (UNSPEC_VRFIP): Delete.\n+\t(UNSPEC_VRFIM): Delete.\n+\t(splitter for loading up vector with most significant bit): New\n+\tsplitter for vectorizing copysign.\n+\t(altivec_vrfiz): Rename from altivec_fturncv4sf2.  Add support for\n+\tvectorizing simple math functions.\n+\t(altivec_vrfip): Add support for vectorizing simple math\n+\tfunctions.\n+\t(altivec_vrfim): Ditto.\n+\t(altivec_copysign_v4sf3): New insn for Altivec copysign support.\n+\n+\t* config/rs6000/rs6000.md (UNSPEC_BPERM): New constant.\n+\t(power7.md, vsx.md): Include for power7 support.\n+\t(copysigndf3): Use VSX instructions if -mvsx.\n+\t(negdf2_fpr): Ditto.\n+\t(absdf2_fpr): Ditto.\n+\t(nabsdf2_fpr): Ditto.\n+\t(adddf3_fpr): Ditto.\n+\t(subdf3_fpr): Ditto.\n+\t(muldf3_fpr): Ditto.\n+\t(divdf3_fpr): Ditto.\n+\t(fix_truncdfdi2_fpr): Ditto.\n+\t(cmpdf_internal1): Ditto.\n+\t(fred, fred_fpr): Convert into expander/insn to add VSX support.\n+\t(btruncdf2, btruncdf2_fpr): Ditto.\n+\t(ceildf2, ceildf2_fpr): Ditto.\n+\t(floordf2, floordf2_fpr): Ditto.\n+\t(floatdidf2, floatdidf2_fpr): Ditto.\n+\t(fmadddf4_fpr): Name insn.  Use VSX instructions if -mvsx.\n+\t(fmsubdf4_fpr): Ditto.\n+\t(fnmadddf4_fpr_1): Ditto.\n+\t(fnmadddf4_fpr_2): Ditto.\n+\t(fnmsubdf4_fpr_1): Ditto.\n+\t(fnmsubdf4_fpr_2): Ditto.\n+\t(fixuns_truncdfdi2): Add expander for VSX support.\n+\t(fix_truncdfdi2): Ditto.\n+\t(fix_truncdfsi2): Ditto.\n+\t(ftruncdf2): Ditto.\n+\t(btruncsf2): Whitespace.\n+\t(movdf_hardfloat32): Add support for VSX registers.\n+\t(movdf_softfloat32): Ditto.\n+\t(movdf_hardfloat64): Ditto.\n+\t(movdf_hardfloat64_mfpgpr): Ditto.\n+\t(movdf_softfloat64): Ditto.\n+\t(movti splitters): Add check for vector registers supporting\n+\tTImode in the future.\n+\t(bpermd): Add power7 bpermd instruction.\n+\n+\t* config/rs6000/altivec.h (vec_div): Define if VSX.\n+\t(vec_mul): Ditto.\n+\t(vec_msub): Ditto.\n+\t(vec_nmadd): Ditto.\n+\t(vec_nearbyint): Ditto.\n+\t(vec_rint): Ditto.\n+\t(vec_sqrt): Ditto.\n+\t(all predicates): Use the generic builtin function, and not the\n+\tV4SF specific function so that the predicates will work with\n+\tVSX's V2DF.\n+\t(vec_all_*): Ditto.\n+\t(vec_any_*): Ditto.\n+\n+\t* doc/extend.texi (PowerPC Altivec/VSX Built-in Functions):\n+\tDocument new VSX functions and types.\n+\n+\t* doc/invoke.texi (PowerPc options): Document -mpopcntd, -mvsx\n+\tswitches.\n+\n+\t* doc/md.texi (PowerPC constraints): Document \"wd\", \"wf\", \"ws\",\n+\t\"wa\", and \"j\" constraints.  Modify \"v\" to talk about Altivec\n+\tinstead of just vector.\n+\n 2009-07-30  Andrew MacLeod  <amacleod@redhat.com>\n \n \tPR debug/26475"}, {"sha": "bc4f30f7cb264c58e56771a231a8ef687c11587f", "filename": "gcc/config/rs6000/altivec.h", "status": "modified", "additions": 35, "deletions": 24, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Faltivec.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Faltivec.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Faltivec.h?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -306,6 +306,17 @@\n #define vec_splats __builtin_vec_splats\n #define vec_promote __builtin_vec_promote\n \n+#ifdef __VSX__\n+/* VSX additions */\n+#define vec_div __builtin_vec_div\n+#define vec_mul __builtin_vec_mul\n+#define vec_msub __builtin_vec_msub\n+#define vec_nmadd __builtin_vec_nmadd\n+#define vec_nearbyint __builtin_vec_nearbyint\n+#define vec_rint __builtin_vec_rint\n+#define vec_sqrt __builtin_vec_sqrt\n+#endif\n+\n /* Predicates.\n    For C++, we use templates in order to allow non-parenthesized arguments.\n    For C, instead, we use macros since non-parenthesized arguments were\n@@ -356,14 +367,14 @@ __altivec_scalar_pred(vec_any_out,\n   __builtin_altivec_vcmpbfp_p (__CR6_EQ_REV, a1, a2))\n \n __altivec_unary_pred(vec_all_nan,\n-  __builtin_altivec_vcmpeqfp_p (__CR6_EQ, a1, a1))\n+  __builtin_altivec_vcmpeq_p (__CR6_EQ, a1, a1))\n __altivec_unary_pred(vec_any_nan,\n-  __builtin_altivec_vcmpeqfp_p (__CR6_LT_REV, a1, a1))\n+  __builtin_altivec_vcmpeq_p (__CR6_LT_REV, a1, a1))\n \n __altivec_unary_pred(vec_all_numeric,\n-  __builtin_altivec_vcmpeqfp_p (__CR6_LT, a1, a1))\n+  __builtin_altivec_vcmpeq_p (__CR6_LT, a1, a1))\n __altivec_unary_pred(vec_any_numeric,\n-  __builtin_altivec_vcmpeqfp_p (__CR6_EQ_REV, a1, a1))\n+  __builtin_altivec_vcmpeq_p (__CR6_EQ_REV, a1, a1))\n \n __altivec_scalar_pred(vec_all_eq,\n   __builtin_vec_vcmpeq_p (__CR6_LT, a1, a2))\n@@ -384,13 +395,13 @@ __altivec_scalar_pred(vec_any_lt,\n   __builtin_vec_vcmpgt_p (__CR6_EQ_REV, a2, a1))\n \n __altivec_scalar_pred(vec_all_ngt,\n-  __builtin_altivec_vcmpgtfp_p (__CR6_EQ, a1, a2))\n+  __builtin_altivec_vcmpgt_p (__CR6_EQ, a1, a2))\n __altivec_scalar_pred(vec_all_nlt,\n-  __builtin_altivec_vcmpgtfp_p (__CR6_EQ, a2, a1))\n+  __builtin_altivec_vcmpgt_p (__CR6_EQ, a2, a1))\n __altivec_scalar_pred(vec_any_ngt,\n-  __builtin_altivec_vcmpgtfp_p (__CR6_LT_REV, a1, a2))\n+  __builtin_altivec_vcmpgt_p (__CR6_LT_REV, a1, a2))\n __altivec_scalar_pred(vec_any_nlt,\n-  __builtin_altivec_vcmpgtfp_p (__CR6_LT_REV, a2, a1))\n+  __builtin_altivec_vcmpgt_p (__CR6_LT_REV, a2, a1))\n \n /* __builtin_vec_vcmpge_p is vcmpgefp for floating-point vector types,\n    while for integer types it is converted to __builtin_vec_vcmpgt_p,\n@@ -405,13 +416,13 @@ __altivec_scalar_pred(vec_any_ge,\n   __builtin_vec_vcmpge_p (__CR6_EQ_REV, a1, a2))\n \n __altivec_scalar_pred(vec_all_nge,\n-  __builtin_altivec_vcmpgefp_p (__CR6_EQ, a1, a2))\n+  __builtin_altivec_vcmpge_p (__CR6_EQ, a1, a2))\n __altivec_scalar_pred(vec_all_nle,\n-  __builtin_altivec_vcmpgefp_p (__CR6_EQ, a2, a1))\n+  __builtin_altivec_vcmpge_p (__CR6_EQ, a2, a1))\n __altivec_scalar_pred(vec_any_nge,\n-  __builtin_altivec_vcmpgefp_p (__CR6_LT_REV, a1, a2))\n+  __builtin_altivec_vcmpge_p (__CR6_LT_REV, a1, a2))\n __altivec_scalar_pred(vec_any_nle,\n-  __builtin_altivec_vcmpgefp_p (__CR6_LT_REV, a2, a1))\n+  __builtin_altivec_vcmpge_p (__CR6_LT_REV, a2, a1))\n \n #undef __altivec_scalar_pred\n #undef __altivec_unary_pred\n@@ -423,11 +434,11 @@ __altivec_scalar_pred(vec_any_nle,\n #define vec_all_in(a1, a2) __builtin_altivec_vcmpbfp_p (__CR6_EQ, (a1), (a2))\n #define vec_any_out(a1, a2) __builtin_altivec_vcmpbfp_p (__CR6_EQ_REV, (a1), (a2))\n \n-#define vec_all_nan(a1) __builtin_altivec_vcmpeqfp_p (__CR6_EQ, (a1), (a1))\n-#define vec_any_nan(a1) __builtin_altivec_vcmpeqfp_p (__CR6_LT_REV, (a1), (a1))\n+#define vec_all_nan(a1) __builtin_vec_vcmpeq_p (__CR6_EQ, (a1), (a1))\n+#define vec_any_nan(a1) __builtin_vec_vcmpeq_p (__CR6_LT_REV, (a1), (a1))\n \n-#define vec_all_numeric(a1) __builtin_altivec_vcmpeqfp_p (__CR6_LT, (a1), (a1))\n-#define vec_any_numeric(a1) __builtin_altivec_vcmpeqfp_p (__CR6_EQ_REV, (a1), (a1))\n+#define vec_all_numeric(a1) __builtin_vec_vcmpeq_p (__CR6_LT, (a1), (a1))\n+#define vec_any_numeric(a1) __builtin_vec_vcmpeq_p (__CR6_EQ_REV, (a1), (a1))\n \n #define vec_all_eq(a1, a2) __builtin_vec_vcmpeq_p (__CR6_LT, (a1), (a2))\n #define vec_all_ne(a1, a2) __builtin_vec_vcmpeq_p (__CR6_EQ, (a1), (a2))\n@@ -439,10 +450,10 @@ __altivec_scalar_pred(vec_any_nle,\n #define vec_any_gt(a1, a2) __builtin_vec_vcmpgt_p (__CR6_EQ_REV, (a1), (a2))\n #define vec_any_lt(a1, a2) __builtin_vec_vcmpgt_p (__CR6_EQ_REV, (a2), (a1))\n \n-#define vec_all_ngt(a1, a2) __builtin_altivec_vcmpgtfp_p (__CR6_EQ, (a1), (a2))\n-#define vec_all_nlt(a1, a2) __builtin_altivec_vcmpgtfp_p (__CR6_EQ, (a2), (a1))\n-#define vec_any_ngt(a1, a2) __builtin_altivec_vcmpgtfp_p (__CR6_LT_REV, (a1), (a2))\n-#define vec_any_nlt(a1, a2) __builtin_altivec_vcmpgtfp_p (__CR6_LT_REV, (a2), (a1))\n+#define vec_all_ngt(a1, a2) __builtin_vec_vcmpgt_p (__CR6_EQ, (a1), (a2))\n+#define vec_all_nlt(a1, a2) __builtin_vec_vcmpgt_p (__CR6_EQ, (a2), (a1))\n+#define vec_any_ngt(a1, a2) __builtin_vec_vcmpgt_p (__CR6_LT_REV, (a1), (a2))\n+#define vec_any_nlt(a1, a2) __builtin_vec_vcmpgt_p (__CR6_LT_REV, (a2), (a1))\n \n /* __builtin_vec_vcmpge_p is vcmpgefp for floating-point vector types,\n    while for integer types it is converted to __builtin_vec_vcmpgt_p,\n@@ -452,10 +463,10 @@ __altivec_scalar_pred(vec_any_nle,\n #define vec_any_le(a1, a2) __builtin_vec_vcmpge_p (__CR6_EQ_REV, (a2), (a1))\n #define vec_any_ge(a1, a2) __builtin_vec_vcmpge_p (__CR6_EQ_REV, (a1), (a2))\n \n-#define vec_all_nge(a1, a2) __builtin_altivec_vcmpgefp_p (__CR6_EQ, (a1), (a2))\n-#define vec_all_nle(a1, a2) __builtin_altivec_vcmpgefp_p (__CR6_EQ, (a2), (a1))\n-#define vec_any_nge(a1, a2) __builtin_altivec_vcmpgefp_p (__CR6_LT_REV, (a1), (a2))\n-#define vec_any_nle(a1, a2) __builtin_altivec_vcmpgefp_p (__CR6_LT_REV, (a2), (a1))\n+#define vec_all_nge(a1, a2) __builtin_vec_vcmpge_p (__CR6_EQ, (a1), (a2))\n+#define vec_all_nle(a1, a2) __builtin_vec_vcmpge_p (__CR6_EQ, (a2), (a1))\n+#define vec_any_nge(a1, a2) __builtin_vec_vcmpge_p (__CR6_LT_REV, (a1), (a2))\n+#define vec_any_nle(a1, a2) __builtin_vec_vcmpge_p (__CR6_LT_REV, (a2), (a1))\n #endif\n \n /* These do not accept vectors, so they do not have a __builtin_vec_*"}, {"sha": "53b1054d2004b3aed758077715065d0a4a27e4ad", "filename": "gcc/config/rs6000/altivec.md", "status": "modified", "additions": 59, "deletions": 8, "changes": 67, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Faltivec.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Faltivec.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Faltivec.md?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -20,8 +20,8 @@\n ;; <http://www.gnu.org/licenses/>.\n \n (define_constants\n-  [(UNSPEC_VCMPBFP       50)\n    ;; 51-62 deleted\n+  [(UNSPEC_VCMPBFP       64)\n    (UNSPEC_VMSUMU        65)\n    (UNSPEC_VMSUMM        66)\n    (UNSPEC_VMSUMSHM      68)\n@@ -66,9 +66,9 @@\n    (UNSPEC_VSUMSWS      135)\n    (UNSPEC_VPERM        144)\n    (UNSPEC_VPERM_UNS    145)\n-   (UNSPEC_VRFIP        148)\n+   ;; 148 deleted\n    (UNSPEC_VRFIN        149)\n-   (UNSPEC_VRFIM        150)\n+   ;; 150 deleted\n    (UNSPEC_VCFUX        151)\n    (UNSPEC_VCFSX        152)\n    (UNSPEC_VCTUXS       153)\n@@ -220,6 +220,35 @@\n }\n   [(set_attr \"type\" \"vecstore,vecload,vecsimple,store,load,*,vecsimple,*\")])\n \n+;; Load up a vector with the most significant bit set by loading up -1 and\n+;; doing a shift left\n+(define_split\n+  [(set (match_operand:VM 0 \"altivec_register_operand\" \"\")\n+\t(match_operand:VM 1 \"easy_vector_constant_msb\" \"\"))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode) && reload_completed\"\n+  [(const_int 0)]\n+{\n+  rtx dest = operands[0];\n+  enum machine_mode mode = GET_MODE (operands[0]);\n+  rtvec v;\n+  int i, num_elements;\n+\n+  if (mode == V4SFmode)\n+    {\n+      mode = V4SImode;\n+      dest = gen_lowpart (V4SImode, dest);\n+    }\n+\n+  num_elements = GET_MODE_NUNITS (mode);\n+  v = rtvec_alloc (num_elements);\n+  for (i = 0; i < num_elements; i++)\n+    RTVEC_ELT (v, i) = constm1_rtx;\n+\n+  emit_insn (gen_vec_initv4si (dest, gen_rtx_PARALLEL (mode, v)));\n+  emit_insn (gen_rtx_SET (VOIDmode, dest, gen_rtx_ASHIFT (mode, dest, dest)));\n+  DONE;\n+})\n+\n (define_split\n   [(set (match_operand:VM 0 \"altivec_register_operand\" \"\")\n \t(match_operand:VM 1 \"easy_vector_constant_add_self\" \"\"))]\n@@ -1310,7 +1339,7 @@\n   \"vspltis<VI_char> %0,%1\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"*altivec_ftruncv4sf2\"\n+(define_insn \"*altivec_vrfiz\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n   \t(fix:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")))]\n   \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n@@ -1337,10 +1366,10 @@\n   \"vperm %0,%1,%2,%3\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"altivec_vrfip\"\n+(define_insn \"altivec_vrfip\"\t\t; ceil\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n         (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"v\")]\n-\t\t     UNSPEC_VRFIP))]\n+\t\t     UNSPEC_FRIP))]\n   \"TARGET_ALTIVEC\"\n   \"vrfip %0,%1\"\n   [(set_attr \"type\" \"vecfloat\")])\n@@ -1353,10 +1382,10 @@\n   \"vrfin %0,%1\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n-(define_insn \"altivec_vrfim\"\n+(define_insn \"*altivec_vrfim\"\t\t; floor\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n         (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"v\")]\n-\t\t     UNSPEC_VRFIM))]\n+\t\t     UNSPEC_FRIM))]\n   \"TARGET_ALTIVEC\"\n   \"vrfim %0,%1\"\n   [(set_attr \"type\" \"vecfloat\")])\n@@ -1431,6 +1460,28 @@\n   \"vrefp %0,%1\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n+(define_expand \"altivec_copysign_v4sf3\"\n+  [(use (match_operand:V4SF 0 \"register_operand\" \"\"))\n+   (use (match_operand:V4SF 1 \"register_operand\" \"\"))\n+   (use (match_operand:V4SF 2 \"register_operand\" \"\"))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"\n+{\n+  rtx mask = gen_reg_rtx (V4SImode);\n+  rtvec v = rtvec_alloc (4);\n+  unsigned HOST_WIDE_INT mask_val = ((unsigned HOST_WIDE_INT)1) << 31;\n+\n+  RTVEC_ELT (v, 0) = GEN_INT (mask_val);\n+  RTVEC_ELT (v, 1) = GEN_INT (mask_val);\n+  RTVEC_ELT (v, 2) = GEN_INT (mask_val);\n+  RTVEC_ELT (v, 3) = GEN_INT (mask_val);\n+\n+  emit_insn (gen_vec_initv4si (mask, gen_rtx_PARALLEL (V4SImode, v)));\n+  emit_insn (gen_vector_select_v4sf (operands[0], operands[1], operands[2],\n+\t\t\t\t     gen_lowpart (V4SFmode, mask)));\n+  DONE;\n+}\")\n+\n (define_insn \"altivec_vsldoi_<mode>\"\n   [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n         (unspec:VM [(match_operand:VM 1 \"register_operand\" \"v\")"}, {"sha": "3b6a95e284e9cad6ec940f3c89017f0b012b2930", "filename": "gcc/config/rs6000/power7.md", "status": "added", "additions": 318, "deletions": 0, "changes": 318, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fpower7.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fpower7.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fpower7.md?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,318 @@\n+;; Scheduling description for IBM POWER7 processor.\n+;; Copyright (C) 2009 Free Software Foundation, Inc.\n+;;\n+;; Contributed by Pat Haugen (pthaugen@us.ibm.com).\n+\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify it\n+;; under the terms of the GNU General Public License as published\n+;; by the Free Software Foundation; either version 3, or (at your\n+;; option) any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+;; or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+;; License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_automaton \"power7iu,power7lsu,power7vsu,power7misc\")\n+\n+(define_cpu_unit \"iu1_power7,iu2_power7\" \"power7iu\")\n+(define_cpu_unit \"lsu1_power7,lsu2_power7\" \"power7lsu\")\n+(define_cpu_unit \"vsu1_power7,vsu2_power7\" \"power7vsu\")\n+(define_cpu_unit \"bpu_power7,cru_power7\" \"power7misc\")\n+(define_cpu_unit \"du1_power7,du2_power7,du3_power7,du4_power7,du5_power7\"\n+                 \"power7misc\")\n+\n+\n+(define_reservation \"DU_power7\"\n+\t\t    \"du1_power7|du2_power7|du3_power7|du4_power7\")\n+\n+(define_reservation \"DU2F_power7\"\n+\t\t    \"du1_power7+du2_power7\")\n+\n+(define_reservation \"DU4_power7\"\n+\t\t    \"du1_power7+du2_power7+du3_power7+du4_power7\")\n+\n+(define_reservation \"FXU_power7\"\n+                    \"iu1_power7|iu2_power7\")\n+\n+(define_reservation \"VSU_power7\"\n+                    \"vsu1_power7|vsu2_power7\")\n+\n+(define_reservation \"LSU_power7\"\n+                    \"lsu1_power7|lsu2_power7\")\n+\n+\n+; Dispatch slots are allocated in order conforming to program order.\n+(absence_set \"du1_power7\" \"du2_power7,du3_power7,du4_power7,du5_power7\")\n+(absence_set \"du2_power7\" \"du3_power7,du4_power7,du5_power7\")\n+(absence_set \"du3_power7\" \"du4_power7,du5_power7\")\n+(absence_set \"du4_power7\" \"du5_power7\")\n+\n+\n+; LS Unit\n+(define_insn_reservation \"power7-load\" 2\n+  (and (eq_attr \"type\" \"load\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,LSU_power7\")\n+\n+(define_insn_reservation \"power7-load-ext\" 3\n+  (and (eq_attr \"type\" \"load_ext\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,LSU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-load-update\" 2\n+  (and (eq_attr \"type\" \"load_u\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,LSU_power7+FXU_power7\")\n+\n+(define_insn_reservation \"power7-load-update-indexed\" 3\n+  (and (eq_attr \"type\" \"load_ux\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,FXU_power7,LSU_power7+FXU_power7\")\n+\n+(define_insn_reservation \"power7-load-ext-update\" 4\n+  (and (eq_attr \"type\" \"load_ext_u\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,LSU_power7+FXU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-load-ext-update-indexed\" 4\n+  (and (eq_attr \"type\" \"load_ext_ux\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,FXU_power7,LSU_power7+FXU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-fpload\" 3\n+  (and (eq_attr \"type\" \"fpload\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,LSU_power7\")\n+\n+(define_insn_reservation \"power7-fpload-update\" 3\n+  (and (eq_attr \"type\" \"fpload_u,fpload_ux\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,LSU_power7+FXU_power7\")\n+\n+(define_insn_reservation \"power7-store\" 6 ; store-forwarding latency\n+  (and (eq_attr \"type\" \"store\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,LSU_power7+FXU_power7\")\n+\n+(define_insn_reservation \"power7-store-update\" 6\n+  (and (eq_attr \"type\" \"store_u\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,LSU_power7+FXU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-store-update-indexed\" 6\n+  (and (eq_attr \"type\" \"store_ux\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,LSU_power7+FXU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-fpstore\" 6\n+  (and (eq_attr \"type\" \"fpstore\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,LSU_power7+VSU_power7\")\n+\n+(define_insn_reservation \"power7-fpstore-update\" 6\n+  (and (eq_attr \"type\" \"fpstore_u,fpstore_ux\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,LSU_power7+VSU_power7+FXU_power7\")\n+\n+(define_insn_reservation \"power7-larx\" 3\n+  (and (eq_attr \"type\" \"load_l\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,LSU_power7\")\n+\n+(define_insn_reservation \"power7-stcx\" 10\n+  (and (eq_attr \"type\" \"store_c\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,LSU_power7\")\n+\n+(define_insn_reservation \"power7-vecload\" 3\n+  (and (eq_attr \"type\" \"vecload\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,LSU_power7\")\n+\n+(define_insn_reservation \"power7-vecstore\" 6\n+  (and (eq_attr \"type\" \"vecstore\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,LSU_power7+VSU_power7\")\n+\n+(define_insn_reservation \"power7-sync\" 11\n+  (and (eq_attr \"type\" \"sync\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,LSU_power7\")\n+\n+\n+; FX Unit\n+(define_insn_reservation \"power7-integer\" 1\n+  (and (eq_attr \"type\" \"integer,insert_word,insert_dword,shift,trap,\\\n+                        var_shift_rotate,exts\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-cntlz\" 2\n+  (and (eq_attr \"type\" \"cntlz\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-two\" 2\n+  (and (eq_attr \"type\" \"two\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7+DU_power7,FXU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-three\" 3\n+  (and (eq_attr \"type\" \"three\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7+DU_power7+DU_power7,FXU_power7,FXU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-cmp\" 1\n+  (and (eq_attr \"type\" \"cmp,fast_compare\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-compare\" 2\n+  (and (eq_attr \"type\" \"compare,delayed_compare,var_delayed_compare\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,FXU_power7,FXU_power7\")\n+\n+(define_bypass 3 \"power7-cmp,power7-compare\" \"power7-crlogical,power7-delayedcr\")\n+\n+(define_insn_reservation \"power7-mul\" 4\n+  (and (eq_attr \"type\" \"imul,imul2,imul3,lmul\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-mul-compare\" 5\n+  (and (eq_attr \"type\" \"imul_compare,lmul_compare\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,FXU_power7,nothing*3,FXU_power7\")\n+\n+(define_insn_reservation \"power7-idiv\" 36\n+  (and (eq_attr \"type\" \"idiv\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,iu1_power7*36|iu2_power7*36\")\n+\n+(define_insn_reservation \"power7-ldiv\" 68\n+  (and (eq_attr \"type\" \"ldiv\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU2F_power7,iu1_power7*68|iu2_power7*68\")\n+\n+(define_insn_reservation \"power7-isync\" 1 ;\n+  (and (eq_attr \"type\" \"isync\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,FXU_power7\")\n+\n+\n+; CR Unit\n+(define_insn_reservation \"power7-mtjmpr\" 4\n+  (and (eq_attr \"type\" \"mtjmpr\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,FXU_power7\")\n+\n+(define_insn_reservation \"power7-mfjmpr\" 5\n+  (and (eq_attr \"type\" \"mfjmpr\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,cru_power7+FXU_power7\")\n+\n+(define_insn_reservation \"power7-crlogical\" 3\n+  (and (eq_attr \"type\" \"cr_logical\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,cru_power7\")\n+\n+(define_insn_reservation \"power7-delayedcr\" 3\n+  (and (eq_attr \"type\" \"delayed_cr\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,cru_power7\")\n+\n+(define_insn_reservation \"power7-mfcr\" 6\n+  (and (eq_attr \"type\" \"mfcr\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,cru_power7\")\n+\n+(define_insn_reservation \"power7-mfcrf\" 3\n+  (and (eq_attr \"type\" \"mfcrf\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,cru_power7\")\n+\n+(define_insn_reservation \"power7-mtcr\" 3\n+  (and (eq_attr \"type\" \"mtcr\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU4_power7,cru_power7+FXU_power7\")\n+\n+\n+; BR Unit\n+; Branches take dispatch Slot 4.  The presence_sets prevent other insn from\n+; grabbing previous dispatch slots once this is assigned.\n+(define_insn_reservation \"power7-branch\" 3\n+  (and (eq_attr \"type\" \"jmpreg,branch\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"(du5_power7\\\n+   |du4_power7+du5_power7\\\n+   |du3_power7+du4_power7+du5_power7\\\n+   |du2_power7+du3_power7+du4_power7+du5_power7\\\n+   |du1_power7+du2_power7+du3_power7+du4_power7+du5_power7),bpu_power7\")\n+\n+\n+; VS Unit (includes FP/VSX/VMX/DFP)\n+(define_insn_reservation \"power7-fp\" 6\n+  (and (eq_attr \"type\" \"fp,dmul\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,VSU_power7\")\n+\n+(define_bypass 8 \"power7-fp\" \"power7-branch\")\n+\n+(define_insn_reservation \"power7-fpcompare\" 4\n+  (and (eq_attr \"type\" \"fpcompare\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-sdiv\" 26\n+  (and (eq_attr \"type\" \"sdiv\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-ddiv\" 32\n+  (and (eq_attr \"type\" \"ddiv\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-sqrt\" 31\n+  (and (eq_attr \"type\" \"ssqrt\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-dsqrt\" 43\n+  (and (eq_attr \"type\" \"dsqrt\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"DU_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-vecsimple\" 2\n+  (and (eq_attr \"type\" \"vecsimple\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-veccmp\" 7\n+  (and (eq_attr \"type\" \"veccmp\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-vecfloat\" 7\n+  (and (eq_attr \"type\" \"vecfloat\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,VSU_power7\")\n+\n+(define_bypass 6 \"power7-vecfloat\" \"power7-vecfloat\")\n+\n+(define_insn_reservation \"power7-veccomplex\" 7\n+  (and (eq_attr \"type\" \"veccomplex\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du1_power7,VSU_power7\")\n+\n+(define_insn_reservation \"power7-vecperm\" 3\n+  (and (eq_attr \"type\" \"vecperm\")\n+       (eq_attr \"cpu\" \"power7\"))\n+  \"du2_power7,VSU_power7\")"}, {"sha": "c963eb98abbccb44e57e87bde275ffa1571db4ff", "filename": "gcc/config/rs6000/ppc-asm.h", "status": "modified", "additions": 138, "deletions": 1, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fppc-asm.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fppc-asm.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fppc-asm.h?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -87,7 +87,7 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n #define f16\t16\n #define f17\t17\n #define f18\t18\n-#define f19     19\n+#define f19\t19\n #define f20\t20\n #define f21\t21\n #define f22\t22\n@@ -101,6 +101,143 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n #define f30\t30\n #define f31\t31\n \n+#ifdef __VSX__\n+#define f32\t32\n+#define f33\t33\n+#define f34\t34\n+#define f35\t35\n+#define f36\t36\n+#define f37\t37\n+#define f38\t38\n+#define f39\t39\n+#define f40\t40\n+#define f41\t41\n+#define f42\t42\n+#define f43\t43\n+#define f44\t44\n+#define f45\t45\n+#define f46\t46\n+#define f47\t47\n+#define f48\t48\n+#define f49\t49\n+#define f50\t30\n+#define f51\t51\n+#define f52\t52\n+#define f53\t53\n+#define f54\t54\n+#define f55\t55\n+#define f56\t56\n+#define f57\t57\n+#define f58\t58\n+#define f59\t59\n+#define f60\t60\n+#define f61\t61\n+#define f62\t62\n+#define f63\t63\n+#endif\n+\n+#ifdef __ALTIVEC__\n+#define v0\t0\n+#define v1\t1\n+#define v2\t2\n+#define v3\t3\n+#define v4\t4\n+#define v5\t5\n+#define v6\t6\n+#define v7\t7\n+#define v8\t8\n+#define v9\t9\n+#define v10\t10\n+#define v11\t11\n+#define v12\t12\n+#define v13\t13\n+#define v14\t14\n+#define v15\t15\n+#define v16\t16\n+#define v17\t17\n+#define v18\t18\n+#define v19\t19\n+#define v20\t20\n+#define v21\t21\n+#define v22\t22\n+#define v23\t23\n+#define v24\t24\n+#define v25\t25\n+#define v26\t26\n+#define v27\t27\n+#define v28\t28\n+#define v29\t29\n+#define v30\t30\n+#define v31\t31\n+#endif\n+\n+#ifdef __VSX__\n+#define vs0\t0\n+#define vs1\t1\n+#define vs2\t2\n+#define vs3\t3\n+#define vs4\t4\n+#define vs5\t5\n+#define vs6\t6\n+#define vs7\t7\n+#define vs8\t8\n+#define vs9\t9\n+#define vs10\t10\n+#define vs11\t11\n+#define vs12\t12\n+#define vs13\t13\n+#define vs14\t14\n+#define vs15\t15\n+#define vs16\t16\n+#define vs17\t17\n+#define vs18\t18\n+#define vs19\t19\n+#define vs20\t20\n+#define vs21\t21\n+#define vs22\t22\n+#define vs23\t23\n+#define vs24\t24\n+#define vs25\t25\n+#define vs26\t26\n+#define vs27\t27\n+#define vs28\t28\n+#define vs29\t29\n+#define vs30\t30\n+#define vs31\t31\n+#define vs32\t32\n+#define vs33\t33\n+#define vs34\t34\n+#define vs35\t35\n+#define vs36\t36\n+#define vs37\t37\n+#define vs38\t38\n+#define vs39\t39\n+#define vs40\t40\n+#define vs41\t41\n+#define vs42\t42\n+#define vs43\t43\n+#define vs44\t44\n+#define vs45\t45\n+#define vs46\t46\n+#define vs47\t47\n+#define vs48\t48\n+#define vs49\t49\n+#define vs50\t30\n+#define vs51\t51\n+#define vs52\t52\n+#define vs53\t53\n+#define vs54\t54\n+#define vs55\t55\n+#define vs56\t56\n+#define vs57\t57\n+#define vs58\t58\n+#define vs59\t59\n+#define vs60\t60\n+#define vs61\t61\n+#define vs62\t62\n+#define vs63\t63\n+#endif\n+\n /*\n  * Macros to glue together two tokens.\n  */"}, {"sha": "cf25cb7bf0f35ea6b20d14b69b9cee57719187d2", "filename": "gcc/config/rs6000/predicates.md", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fpredicates.md?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -377,6 +377,16 @@\n   return EASY_VECTOR_15_ADD_SELF (val);\n })\n \n+;; Same as easy_vector_constant but only for EASY_VECTOR_MSB.\n+(define_predicate \"easy_vector_constant_msb\"\n+  (and (match_code \"const_vector\")\n+       (and (match_test \"TARGET_ALTIVEC\")\n+\t    (match_test \"easy_altivec_constant (op, mode)\")))\n+{\n+  HOST_WIDE_INT val = const_vector_elt_as_int (op, GET_MODE_NUNITS (mode) - 1);\n+  return EASY_VECTOR_MSB (val, GET_MODE_INNER (mode));\n+})\n+\n ;; Return 1 if operand is constant zero (scalars and vectors).\n (define_predicate \"zero_constant\"\n   (and (match_code \"const_int,const_double,const_vector\")"}, {"sha": "94354528ebfef8032a7ee85d525ad07c6b80f0dd", "filename": "gcc/config/rs6000/rs6000-c.c", "status": "modified", "additions": 221, "deletions": 21, "changes": 242, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-c.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -214,7 +214,8 @@ rs6000_macro_to_expand (cpp_reader *pfile, const cpp_token *tok)\n \t  if (rid_code == RID_UNSIGNED || rid_code == RID_LONG\n \t      || rid_code == RID_SHORT || rid_code == RID_SIGNED\n \t      || rid_code == RID_INT || rid_code == RID_CHAR\n-\t      || rid_code == RID_FLOAT)\n+\t      || rid_code == RID_FLOAT\n+\t      || (rid_code == RID_DOUBLE && TARGET_VSX))\n \t    {\n \t      expand_this = C_CPP_HASHNODE (__vector_keyword);\n \t      /* If the next keyword is bool or pixel, it\n@@ -329,7 +330,42 @@ rs6000_cpu_cpp_builtins (cpp_reader *pfile)\n   if (TARGET_NO_LWSYNC)\n     builtin_define (\"__NO_LWSYNC__\");\n   if (TARGET_VSX)\n-    builtin_define (\"__VSX__\");\n+    {\n+      builtin_define (\"__VSX__\");\n+\n+      /* For the VSX builtin functions identical to Altivec functions, just map\n+\t the altivec builtin into the vsx version (the altivec functions\n+\t generate VSX code if -mvsx).  */\n+      builtin_define (\"__builtin_vsx_xxland=__builtin_vec_and\");\n+      builtin_define (\"__builtin_vsx_xxlandc=__builtin_vec_andc\");\n+      builtin_define (\"__builtin_vsx_xxlnor=__builtin_vec_nor\");\n+      builtin_define (\"__builtin_vsx_xxlor=__builtin_vec_or\");\n+      builtin_define (\"__builtin_vsx_xxlxor=__builtin_vec_xor\");\n+      builtin_define (\"__builtin_vsx_xxsel=__builtin_vec_sel\");\n+      builtin_define (\"__builtin_vsx_vperm=__builtin_vec_perm\");\n+\n+      /* Also map the a and m versions of the multiply/add instructions to the\n+\t builtin for people blindly going off the instruction manual.  */\n+      builtin_define (\"__builtin_vsx_xvmaddadp=__builtin_vsx_xvmadddp\");\n+      builtin_define (\"__builtin_vsx_xvmaddmdp=__builtin_vsx_xvmadddp\");\n+      builtin_define (\"__builtin_vsx_xvmaddasp=__builtin_vsx_xvmaddsp\");\n+      builtin_define (\"__builtin_vsx_xvmaddmsp=__builtin_vsx_xvmaddsp\");\n+      builtin_define (\"__builtin_vsx_xvmsubadp=__builtin_vsx_xvmsubdp\");\n+      builtin_define (\"__builtin_vsx_xvmsubmdp=__builtin_vsx_xvmsubdp\");\n+      builtin_define (\"__builtin_vsx_xvmsubasp=__builtin_vsx_xvmsubsp\");\n+      builtin_define (\"__builtin_vsx_xvmsubmsp=__builtin_vsx_xvmsubsp\");\n+      builtin_define (\"__builtin_vsx_xvnmaddadp=__builtin_vsx_xvnmadddp\");\n+      builtin_define (\"__builtin_vsx_xvnmaddmdp=__builtin_vsx_xvnmadddp\");\n+      builtin_define (\"__builtin_vsx_xvnmaddasp=__builtin_vsx_xvnmaddsp\");\n+      builtin_define (\"__builtin_vsx_xvnmaddmsp=__builtin_vsx_xvnmaddsp\");\n+      builtin_define (\"__builtin_vsx_xvnmsubadp=__builtin_vsx_xvnmsubdp\");\n+      builtin_define (\"__builtin_vsx_xvnmsubmdp=__builtin_vsx_xvnmsubdp\");\n+      builtin_define (\"__builtin_vsx_xvnmsubasp=__builtin_vsx_xvnmsubsp\");\n+      builtin_define (\"__builtin_vsx_xvnmsubmsp=__builtin_vsx_xvnmsubsp\");\n+    }\n+\n+  /* Tell users they can use __builtin_bswap{16,64}.  */\n+  builtin_define (\"__HAVE_BSWAP__\");\n \n   /* May be overridden by target configuration.  */\n   RS6000_CPU_CPP_ENDIAN_BUILTINS();\n@@ -393,7 +429,7 @@ struct altivec_builtin_types\n };\n \n const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n-  /* Unary AltiVec builtins.  */\n+  /* Unary AltiVec/VSX builtins.  */\n   { ALTIVEC_BUILTIN_VEC_ABS, ALTIVEC_BUILTIN_ABS_V16QI,\n     RS6000_BTI_V16QI, RS6000_BTI_V16QI, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_ABS, ALTIVEC_BUILTIN_ABS_V8HI,\n@@ -402,6 +438,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_ABS, ALTIVEC_BUILTIN_ABS_V4SF,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n+  { ALTIVEC_BUILTIN_VEC_ABS, VSX_BUILTIN_XVABSDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_ABSS, ALTIVEC_BUILTIN_ABSS_V16QI,\n     RS6000_BTI_V16QI, RS6000_BTI_V16QI, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_ABSS, ALTIVEC_BUILTIN_ABSS_V8HI,\n@@ -410,8 +448,12 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_CEIL, ALTIVEC_BUILTIN_VRFIP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n+  { ALTIVEC_BUILTIN_VEC_CEIL, VSX_BUILTIN_XVRDPIP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_EXPTE, ALTIVEC_BUILTIN_VEXPTEFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n+  { ALTIVEC_BUILTIN_VEC_FLOOR, VSX_BUILTIN_XVRDPIM,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_FLOOR, ALTIVEC_BUILTIN_VRFIM,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_LOGE, ALTIVEC_BUILTIN_VLOGEFP,\n@@ -444,6 +486,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_TRUNC, ALTIVEC_BUILTIN_VRFIZ,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n+  { ALTIVEC_BUILTIN_VEC_TRUNC, VSX_BUILTIN_XVRDPIZ,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_UNPACKH, ALTIVEC_BUILTIN_VUPKHSB,\n     RS6000_BTI_V8HI, RS6000_BTI_V16QI, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_UNPACKH, ALTIVEC_BUILTIN_VUPKHSB,\n@@ -489,7 +533,7 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n   { ALTIVEC_BUILTIN_VEC_VUPKLSB, ALTIVEC_BUILTIN_VUPKLSB,\n     RS6000_BTI_bool_V8HI, RS6000_BTI_bool_V16QI, 0, 0 },\n \n-  /* Binary AltiVec builtins.  */\n+  /* Binary AltiVec/VSX builtins.  */\n   { ALTIVEC_BUILTIN_VEC_ADD, ALTIVEC_BUILTIN_VADDUBM,\n     RS6000_BTI_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_ADD, ALTIVEC_BUILTIN_VADDUBM,\n@@ -528,6 +572,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_ADD, ALTIVEC_BUILTIN_VADDFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_ADD, VSX_BUILTIN_XVADDDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VADDFP, ALTIVEC_BUILTIN_VADDFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VADDUWM, ALTIVEC_BUILTIN_VADDUWM,\n@@ -673,9 +719,9 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n     RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n-    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, 0 },\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n-    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n@@ -727,9 +773,9 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n     RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n-    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, 0 },\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n-    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n@@ -812,6 +858,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_bool_V4SI, RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPEQ, ALTIVEC_BUILTIN_VCMPEQFP,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_CMPEQ, VSX_BUILTIN_XVCMPEQDP,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VCMPEQFP, ALTIVEC_BUILTIN_VCMPEQFP,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n \n@@ -832,6 +880,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n \n   { ALTIVEC_BUILTIN_VEC_CMPGE, ALTIVEC_BUILTIN_VCMPGEFP,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_CMPGE, VSX_BUILTIN_XVCMPGEDP,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPGT, ALTIVEC_BUILTIN_VCMPGTUB,\n     RS6000_BTI_bool_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPGT, ALTIVEC_BUILTIN_VCMPGTSB,\n@@ -846,6 +896,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPGT, ALTIVEC_BUILTIN_VCMPGTFP,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_CMPGT, VSX_BUILTIN_XVCMPGTDP,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VCMPGTFP, ALTIVEC_BUILTIN_VCMPGTFP,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VCMPGTSW, ALTIVEC_BUILTIN_VCMPGTSW,\n@@ -874,6 +926,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_bool_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPLE, ALTIVEC_BUILTIN_VCMPGEFP,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_CMPLE, VSX_BUILTIN_XVCMPGEDP,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPLT, ALTIVEC_BUILTIN_VCMPGTUB,\n     RS6000_BTI_bool_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPLT, ALTIVEC_BUILTIN_VCMPGTSB,\n@@ -888,6 +942,12 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CMPLT, ALTIVEC_BUILTIN_VCMPGTFP,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_CMPLT, VSX_BUILTIN_XVCMPGTDP,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_COPYSIGN, VSX_BUILTIN_CPSGNDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_COPYSIGN, ALTIVEC_BUILTIN_COPYSIGN_V4SF,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_CTF, ALTIVEC_BUILTIN_VCFUX,\n     RS6000_BTI_V4SF, RS6000_BTI_unsigned_V4SI, RS6000_BTI_INTSI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CTF, ALTIVEC_BUILTIN_VCFSX,\n@@ -900,6 +960,10 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SI, RS6000_BTI_V4SF, RS6000_BTI_INTSI, 0 },\n   { ALTIVEC_BUILTIN_VEC_CTU, ALTIVEC_BUILTIN_VCTUXS,\n     RS6000_BTI_unsigned_V4SI, RS6000_BTI_V4SF, RS6000_BTI_INTSI, 0 },\n+  { VSX_BUILTIN_VEC_DIV, VSX_BUILTIN_XVDIVSP,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { VSX_BUILTIN_VEC_DIV, VSX_BUILTIN_XVDIVDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n     RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n@@ -1234,6 +1298,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_MAX, ALTIVEC_BUILTIN_VMAXFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_MAX, VSX_BUILTIN_XVMAXDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VMAXFP, ALTIVEC_BUILTIN_VMAXFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VMAXSW, ALTIVEC_BUILTIN_VMAXSW,\n@@ -1410,6 +1476,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_MIN, ALTIVEC_BUILTIN_VMINFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_MIN, VSX_BUILTIN_XVMINDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VMINFP, ALTIVEC_BUILTIN_VMINFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VMINSW, ALTIVEC_BUILTIN_VMINSW,\n@@ -1460,6 +1528,10 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_VMINUB, ALTIVEC_BUILTIN_VMINUB,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_bool_V16QI, 0 },\n+  { VSX_BUILTIN_VEC_MUL, VSX_BUILTIN_XVMULSP,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { VSX_BUILTIN_VEC_MUL, VSX_BUILTIN_XVMULDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_MULE, ALTIVEC_BUILTIN_VMULEUB,\n     RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_MULE, ALTIVEC_BUILTIN_VMULESB,\n@@ -1492,6 +1564,10 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V8HI, RS6000_BTI_V16QI, RS6000_BTI_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_VMULOUB, ALTIVEC_BUILTIN_VMULOUB,\n     RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_NEARBYINT, VSX_BUILTIN_XVRDPI,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0, 0 },\n+  { ALTIVEC_BUILTIN_VEC_NEARBYINT, VSX_BUILTIN_XVRSPI,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_NOR, ALTIVEC_BUILTIN_VNOR,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_NOR, ALTIVEC_BUILTIN_VNOR,\n@@ -1523,9 +1599,9 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n     RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n-    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, 0 },\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n-    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n@@ -1622,6 +1698,10 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V8HI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_VPKSHUS, ALTIVEC_BUILTIN_VPKSHUS,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_V8HI, RS6000_BTI_V8HI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_RINT, VSX_BUILTIN_XVRDPIC,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0, 0 },\n+  { ALTIVEC_BUILTIN_VEC_RINT, VSX_BUILTIN_XVRSPIC,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_RL, ALTIVEC_BUILTIN_VRLB,\n     RS6000_BTI_V16QI, RS6000_BTI_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_RL, ALTIVEC_BUILTIN_VRLB,\n@@ -1658,6 +1738,10 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_unsigned_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_SL, ALTIVEC_BUILTIN_VSLW,\n     RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_SQRT, VSX_BUILTIN_XVSQRTDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0, 0 },\n+  { ALTIVEC_BUILTIN_VEC_SQRT, VSX_BUILTIN_XVSQRTSP,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0, 0 },\n   { ALTIVEC_BUILTIN_VEC_VSLW, ALTIVEC_BUILTIN_VSLW,\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_unsigned_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_VSLW, ALTIVEC_BUILTIN_VSLW,\n@@ -1984,6 +2068,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_SUB, ALTIVEC_BUILTIN_VSUBFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_SUB, VSX_BUILTIN_XVSUBDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VSUBFP, ALTIVEC_BUILTIN_VSUBFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_VSUBUWM, ALTIVEC_BUILTIN_VSUBUWM,\n@@ -2145,9 +2231,9 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n     RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n-    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, 0 },\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n-    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n@@ -2191,7 +2277,7 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n \n-  /* Ternary AltiVec builtins.  */\n+  /* Ternary AltiVec/VSX builtins.  */\n   { ALTIVEC_BUILTIN_VEC_DST, ALTIVEC_BUILTIN_DST,\n     RS6000_BTI_void, ~RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, RS6000_BTI_INTSI },\n   { ALTIVEC_BUILTIN_VEC_DST, ALTIVEC_BUILTIN_DST,\n@@ -2354,6 +2440,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_void, ~RS6000_BTI_float, RS6000_BTI_INTSI, RS6000_BTI_INTSI },\n   { ALTIVEC_BUILTIN_VEC_MADD, ALTIVEC_BUILTIN_VMADDFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { ALTIVEC_BUILTIN_VEC_MADD, VSX_BUILTIN_XVMADDDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n   { ALTIVEC_BUILTIN_VEC_MADDS, ALTIVEC_BUILTIN_VMHADDSHS,\n     RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_V8HI },\n   { ALTIVEC_BUILTIN_VEC_MLADD, ALTIVEC_BUILTIN_VMLADDUHM,\n@@ -2366,6 +2454,10 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI },\n   { ALTIVEC_BUILTIN_VEC_MRADDS, ALTIVEC_BUILTIN_VMHRADDSHS,\n     RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_V8HI },\n+  { VSX_BUILTIN_VEC_MSUB, VSX_BUILTIN_XVMSUBSP,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { VSX_BUILTIN_VEC_MSUB, VSX_BUILTIN_XVMSUBDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n   { ALTIVEC_BUILTIN_VEC_MSUM, ALTIVEC_BUILTIN_VMSUMUBM,\n     RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V4SI },\n   { ALTIVEC_BUILTIN_VEC_MSUM, ALTIVEC_BUILTIN_VMSUMMBM,\n@@ -2390,8 +2482,14 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SI, RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_V4SI },\n   { ALTIVEC_BUILTIN_VEC_VMSUMUHS, ALTIVEC_BUILTIN_VMSUMUHS,\n     RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V4SI },\n+  { VSX_BUILTIN_VEC_NMADD, VSX_BUILTIN_XVNMADDSP,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { VSX_BUILTIN_VEC_NMADD, VSX_BUILTIN_XVNMADDDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n   { ALTIVEC_BUILTIN_VEC_NMSUB, ALTIVEC_BUILTIN_VNMSUBFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { ALTIVEC_BUILTIN_VEC_NMSUB, VSX_BUILTIN_XVNMSUBDP,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n   { ALTIVEC_BUILTIN_VEC_PERM, ALTIVEC_BUILTIN_VPERM_2DF,\n     RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_unsigned_V16QI },\n   { ALTIVEC_BUILTIN_VEC_PERM, ALTIVEC_BUILTIN_VPERM_2DI,\n@@ -2812,6 +2910,54 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_void, RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_unsigned_V16QI },\n   { ALTIVEC_BUILTIN_VEC_STVRXL, ALTIVEC_BUILTIN_STVRXL,\n     RS6000_BTI_void, RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTQI },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_16QI,\n+    RS6000_BTI_V16QI, RS6000_BTI_V16QI, RS6000_BTI_V16QI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_16QI,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI,\n+    RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_8HI,\n+    RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_8HI,\n+    RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI,\n+    RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_4SI,\n+    RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_4SI,\n+    RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI,\n+    RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_2DI,\n+    RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_2DI,\n+    RS6000_BTI_unsigned_V2DI, RS6000_BTI_unsigned_V2DI, RS6000_BTI_unsigned_V2DI,\n+    RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_4SF,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXSLDWI, VSX_BUILTIN_XXSLDWI_2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_2DI,\n+    RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_2DI,\n+    RS6000_BTI_unsigned_V2DI, RS6000_BTI_unsigned_V2DI, RS6000_BTI_unsigned_V2DI,\n+    RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_4SF,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_4SI,\n+    RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_4SI,\n+    RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V4SI,\n+    RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_8HI,\n+    RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_V8HI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_8HI,\n+    RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI,\n+    RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_16QI,\n+    RS6000_BTI_V16QI, RS6000_BTI_V16QI, RS6000_BTI_V16QI, RS6000_BTI_NOT_OPAQUE },\n+  { VSX_BUILTIN_VEC_XXPERMDI, VSX_BUILTIN_XXPERMDI_16QI,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI,\n+    RS6000_BTI_NOT_OPAQUE },\n \n   /* Predicates.  */\n   { ALTIVEC_BUILTIN_VCMPGT_P, ALTIVEC_BUILTIN_VCMPGTUB_P,\n@@ -2852,6 +2998,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V4SI, RS6000_BTI_V4SI },\n   { ALTIVEC_BUILTIN_VCMPGT_P, ALTIVEC_BUILTIN_VCMPGTFP_P,\n     RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { ALTIVEC_BUILTIN_VCMPGT_P, VSX_BUILTIN_XVCMPGTDP_P,\n+    RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n \n \n   { ALTIVEC_BUILTIN_VCMPEQ_P, ALTIVEC_BUILTIN_VCMPEQUB_P,\n@@ -2900,6 +3048,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI },\n   { ALTIVEC_BUILTIN_VCMPEQ_P, ALTIVEC_BUILTIN_VCMPEQFP_P,\n     RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { ALTIVEC_BUILTIN_VCMPEQ_P, VSX_BUILTIN_XVCMPEQDP_P,\n+    RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n \n \n   /* cmpge is the same as cmpgt for all cases except floating point.\n@@ -2943,6 +3093,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V4SI, RS6000_BTI_V4SI },\n   { ALTIVEC_BUILTIN_VCMPGE_P, ALTIVEC_BUILTIN_VCMPGEFP_P,\n     RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { ALTIVEC_BUILTIN_VCMPGE_P, VSX_BUILTIN_XVCMPGEDP_P,\n+    RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n \n   { (enum rs6000_builtins) 0, (enum rs6000_builtins) 0, 0, 0, 0, 0 }\n };\n@@ -3064,8 +3216,10 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n   const struct altivec_builtin_types *desc;\n   unsigned int n;\n \n-  if (fcode < ALTIVEC_BUILTIN_OVERLOADED_FIRST\n-      || fcode > ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+  if ((fcode < ALTIVEC_BUILTIN_OVERLOADED_FIRST\n+       || fcode > ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+      && (fcode < VSX_BUILTIN_OVERLOADED_FIRST\n+\t  || fcode > VSX_BUILTIN_OVERLOADED_LAST))\n     return NULL_TREE;\n \n   /* For now treat vec_splats and vec_promote as the same.  */\n@@ -3105,11 +3259,12 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n \t  && !INTEGRAL_TYPE_P (type))\n \tgoto bad;\n       unsigned_p = TYPE_UNSIGNED (type);\n-      if (type == long_long_unsigned_type_node\n-          || type == long_long_integer_type_node)\n-\tgoto bad;\n       switch (TYPE_MODE (type))\n \t{\n+\t  case DImode:\n+\t    type = (unsigned_p ? unsigned_V2DI_type_node : V2DI_type_node);\n+\t    size = 2;\n+\t    break;\n \t  case SImode:\n \t    type = (unsigned_p ? unsigned_V4SI_type_node : V4SI_type_node);\n \t    size = 4;\n@@ -3123,6 +3278,7 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n \t    size = 16;\n \t    break;\n \t  case SFmode: type = V4SF_type_node; size = 4; break;\n+\t  case DFmode: type = V2DF_type_node; size = 2; break;\n \t  default:\n \t    goto bad;\n \t}\n@@ -3139,7 +3295,8 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n \treturn build_constructor (type, vec);\n     }\n \n-  /* For now use pointer tricks to do the extaction.  */\n+  /* For now use pointer tricks to do the extaction, unless we are on VSX\n+     extracting a double from a constant offset.  */\n   if (fcode == ALTIVEC_BUILTIN_VEC_EXTRACT)\n     {\n       tree arg1;\n@@ -3148,6 +3305,7 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n       tree arg1_inner_type;\n       tree decl, stmt;\n       tree innerptrtype;\n+      enum machine_mode mode;\n \n       /* No second argument. */\n       if (nargs != 2)\n@@ -3164,6 +3322,25 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n \tgoto bad; \n       if (!INTEGRAL_TYPE_P (TREE_TYPE (arg2)))\n \tgoto bad; \n+\n+      /* If we can use the VSX xxpermdi instruction, use that for extract.  */\n+      mode = TYPE_MODE (arg1_type);\n+      if ((mode == V2DFmode || mode == V2DImode) && VECTOR_MEM_VSX_P (mode)\n+\t  && TREE_CODE (arg2) == INTEGER_CST\n+\t  && TREE_INT_CST_HIGH (arg2) == 0\n+\t  && (TREE_INT_CST_LOW (arg2) == 0 || TREE_INT_CST_LOW (arg2) == 1))\n+\t{\n+\t  tree call = NULL_TREE;\n+\n+\t  if (mode == V2DFmode)\n+\t    call = rs6000_builtin_decls[VSX_BUILTIN_VEC_EXT_V2DF];\n+\t  else if (mode == V2DImode)\n+\t    call = rs6000_builtin_decls[VSX_BUILTIN_VEC_EXT_V2DI];\n+\n+\t  if (call)\n+\t    return build_call_expr (call, 2, arg1, arg2);\n+\t}\n+\n       /* Build *(((arg1_inner_type*)&(vector type){arg1})+arg2). */\n       arg1_inner_type = TREE_TYPE (arg1_type);\n       arg2 = build_binary_op (loc, BIT_AND_EXPR, arg2,\n@@ -3193,7 +3370,8 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n       return stmt;\n     }\n \n-  /* For now use pointer tricks to do the insertation.  */\n+  /* For now use pointer tricks to do the insertation, unless we are on VSX\n+     inserting a double to a constant offset..  */\n   if (fcode == ALTIVEC_BUILTIN_VEC_INSERT)\n     {\n       tree arg0;\n@@ -3203,7 +3381,8 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n       tree arg1_inner_type;\n       tree decl, stmt;\n       tree innerptrtype;\n-      \n+      enum machine_mode mode;\n+\n       /* No second or third arguments. */\n       if (nargs != 3)\n \t{\n@@ -3220,6 +3399,27 @@ altivec_resolve_overloaded_builtin (location_t loc, tree fndecl,\n \tgoto bad; \n       if (!INTEGRAL_TYPE_P (TREE_TYPE (arg2)))\n \tgoto bad; \n+\n+      /* If we can use the VSX xxpermdi instruction, use that for insert.  */\n+      mode = TYPE_MODE (arg1_type);\n+      if ((mode == V2DFmode || mode == V2DImode) && VECTOR_UNIT_VSX_P (mode)\n+\t  && TREE_CODE (arg2) == INTEGER_CST\n+\t  && TREE_INT_CST_HIGH (arg2) == 0\n+\t  && (TREE_INT_CST_LOW (arg2) == 0 || TREE_INT_CST_LOW (arg2) == 1))\n+\t{\n+\t  tree call = NULL_TREE;\n+\n+\t  if (mode == V2DFmode)\n+\t    call = rs6000_builtin_decls[VSX_BUILTIN_VEC_SET_V2DF];\n+\t  else if (mode == V2DImode)\n+\t    call = rs6000_builtin_decls[VSX_BUILTIN_VEC_SET_V2DI];\n+\n+\t  /* Note, __builtin_vec_insert_<xxx> has vector and scalar types\n+\t     reversed.  */\n+\t  if (call)\n+\t    return build_call_expr (call, 3, arg1, arg0, arg2);\n+\t}\n+\n       /* Build *(((arg1_inner_type*)&(vector type){arg1})+arg2) = arg0. */\n       arg1_inner_type = TREE_TYPE (arg1_type);\n       arg2 = build_binary_op (loc, BIT_AND_EXPR, arg2,"}, {"sha": "25cacc46e913d8824fd98b155203487218c82868", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 632, "deletions": 44, "changes": 676, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -837,6 +837,7 @@ static rtx rs6000_emit_stack_reset (rs6000_stack_t *, rtx, rtx, int, bool);\n static rtx rs6000_make_savres_rtx (rs6000_stack_t *, rtx, int,\n \t\t\t\t   enum machine_mode, bool, bool, bool);\n static bool rs6000_reg_live_or_pic_offset_p (int);\n+static tree rs6000_builtin_vectorized_function (unsigned int, tree, tree);\n static int rs6000_savres_strategy (rs6000_stack_t *, bool, int, int);\n static void rs6000_restore_saved_cr (rtx, int);\n static void rs6000_output_function_prologue (FILE *, HOST_WIDE_INT);\n@@ -1395,6 +1396,10 @@ static const struct attribute_spec rs6000_attribute_table[] =\n #undef TARGET_HANDLE_OPTION\n #define TARGET_HANDLE_OPTION rs6000_handle_option\n \n+#undef TARGET_VECTORIZE_BUILTIN_VECTORIZED_FUNCTION\n+#define TARGET_VECTORIZE_BUILTIN_VECTORIZED_FUNCTION \\\n+  rs6000_builtin_vectorized_function\n+\n #undef TARGET_DEFAULT_TARGET_FLAGS\n #define TARGET_DEFAULT_TARGET_FLAGS \\\n   (TARGET_DEFAULT)\n@@ -1871,20 +1876,14 @@ rs6000_init_hard_regno_mode_ok (void)\n \t}\n     }\n \n-  /* V2DImode, prefer vsx over altivec, since the main use will be for\n-     vectorized floating point conversions.  */\n+  /* V2DImode, only allow under VSX, which can do V2DI insert/splat/extract.\n+     Altivec doesn't have 64-bit support.  */\n   if (TARGET_VSX)\n     {\n       rs6000_vector_mem[V2DImode] = VECTOR_VSX;\n       rs6000_vector_unit[V2DImode] = VECTOR_NONE;\n       rs6000_vector_align[V2DImode] = align64;\n     }\n-  else if (TARGET_ALTIVEC)\n-    {\n-      rs6000_vector_mem[V2DImode] = VECTOR_ALTIVEC;\n-      rs6000_vector_unit[V2DImode] = VECTOR_NONE;\n-      rs6000_vector_align[V2DImode] = align64;\n-    }\n \n   /* DFmode, see if we want to use the VSX unit.  */\n   if (TARGET_VSX && TARGET_VSX_SCALAR_DOUBLE)\n@@ -2169,7 +2168,7 @@ rs6000_override_options (const char *default_cpu)\n \t {\"power7\", PROCESSOR_POWER7,\n \t  POWERPC_7400_MASK | MASK_POWERPC64 | MASK_PPC_GPOPT | MASK_MFCRF\n \t  | MASK_POPCNTB | MASK_FPRND | MASK_CMPB | MASK_DFP | MASK_POPCNTD\n-\t  /* |  MASK_VSX */},\t/* Don't add MASK_ISEL by default */\n+\t  | MASK_VSX},\t\t/* Don't add MASK_ISEL by default */\n \t {\"powerpc\", PROCESSOR_POWERPC, POWERPC_BASE_MASK},\n \t {\"powerpc64\", PROCESSOR_POWERPC64,\n \t  POWERPC_BASE_MASK | MASK_PPC_GFXOPT | MASK_POWERPC64},\n@@ -2765,6 +2764,14 @@ rs6000_builtin_conversion (unsigned int tcode, tree type)\n     case FIX_TRUNC_EXPR:\n       switch (TYPE_MODE (type))\n \t{\n+\tcase V2DImode:\n+\t  if (!VECTOR_UNIT_VSX_P (V2DFmode))\n+\t    return NULL_TREE;\n+\n+\t  return TYPE_UNSIGNED (type)\n+\t    ? rs6000_builtin_decls[VSX_BUILTIN_XVCVDPUXDS_UNS]\n+\t    : rs6000_builtin_decls[VSX_BUILTIN_XVCVDPSXDS];\n+\n \tcase V4SImode:\n \t  if (VECTOR_UNIT_NONE_P (V4SImode) || VECTOR_UNIT_NONE_P (V4SFmode))\n \t    return NULL_TREE;\n@@ -2780,6 +2787,14 @@ rs6000_builtin_conversion (unsigned int tcode, tree type)\n     case FLOAT_EXPR:\n       switch (TYPE_MODE (type))\n \t{\n+\tcase V2DImode:\n+\t  if (!VECTOR_UNIT_VSX_P (V2DFmode))\n+\t    return NULL_TREE;\n+\n+\t  return TYPE_UNSIGNED (type)\n+\t    ? rs6000_builtin_decls[VSX_BUILTIN_XVCVUXDDP]\n+\t    : rs6000_builtin_decls[VSX_BUILTIN_XVCVSXDDP];\n+\n \tcase V4SImode:\n \t  if (VECTOR_UNIT_NONE_P (V4SImode) || VECTOR_UNIT_NONE_P (V4SFmode))\n \t    return NULL_TREE;\n@@ -2908,6 +2923,22 @@ rs6000_builtin_vec_perm (tree type, tree *mask_element_type)\n       d = rs6000_builtin_decls[ALTIVEC_BUILTIN_VPERM_4SF];\n       break;\n \n+    case V2DFmode:\n+      if (!TARGET_ALLOW_DF_PERMUTE)\n+\treturn NULL_TREE;\n+\n+      d = rs6000_builtin_decls[ALTIVEC_BUILTIN_VPERM_2DF];\n+      break;\n+\n+    case V2DImode:\n+      if (!TARGET_ALLOW_DF_PERMUTE)\n+\treturn NULL_TREE;\n+\n+      d = (uns_p\n+\t   ? rs6000_builtin_decls[ALTIVEC_BUILTIN_VPERM_2DI_UNS]\n+\t   : rs6000_builtin_decls[ALTIVEC_BUILTIN_VPERM_2DI]);\n+      break;\n+\n     default:\n       return NULL_TREE;\n     }\n@@ -2981,6 +3012,136 @@ rs6000_parse_fpu_option (const char *option)\n   return FPU_NONE;\n }\n \n+/* Returns a function decl for a vectorized version of the builtin function\n+   with builtin function code FN and the result vector type TYPE, or NULL_TREE\n+   if it is not available.  */\n+\n+static tree\n+rs6000_builtin_vectorized_function (unsigned int fn, tree type_out,\n+\t\t\t\t    tree type_in)\n+{\n+  enum machine_mode in_mode, out_mode;\n+  int in_n, out_n;\n+\n+  if (TREE_CODE (type_out) != VECTOR_TYPE\n+      || TREE_CODE (type_in) != VECTOR_TYPE\n+      || !TARGET_VECTORIZE_BUILTINS)\n+    return NULL_TREE;\n+\n+  out_mode = TYPE_MODE (TREE_TYPE (type_out));\n+  out_n = TYPE_VECTOR_SUBPARTS (type_out);\n+  in_mode = TYPE_MODE (TREE_TYPE (type_in));\n+  in_n = TYPE_VECTOR_SUBPARTS (type_in);\n+\n+  switch (fn)\n+    {\n+    case BUILT_IN_COPYSIGN:\n+      if (VECTOR_UNIT_VSX_P (V2DFmode)\n+\t  && out_mode == DFmode && out_n == 2\n+\t  && in_mode == DFmode && in_n == 2)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_CPSGNDP];\n+      break;\n+    case BUILT_IN_COPYSIGNF:\n+      if (out_mode != SFmode || out_n != 4\n+\t  || in_mode != SFmode || in_n != 4)\n+\tbreak;\n+      if (VECTOR_UNIT_VSX_P (V4SFmode))\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_CPSGNSP];\n+      if (VECTOR_UNIT_ALTIVEC_P (V4SFmode))\n+\treturn rs6000_builtin_decls[ALTIVEC_BUILTIN_COPYSIGN_V4SF];\n+      break;\n+    case BUILT_IN_SQRT:\n+      if (VECTOR_UNIT_VSX_P (V2DFmode)\n+\t  && out_mode == DFmode && out_n == 2\n+\t  && in_mode == DFmode && in_n == 2)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVSQRTDP];\n+      break;\n+    case BUILT_IN_SQRTF:\n+      if (VECTOR_UNIT_VSX_P (V4SFmode)\n+\t  && out_mode == SFmode && out_n == 4\n+\t  && in_mode == SFmode && in_n == 4)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVSQRTSP];\n+      break;\n+    case BUILT_IN_CEIL:\n+      if (VECTOR_UNIT_VSX_P (V2DFmode)\n+\t  && out_mode == DFmode && out_n == 2\n+\t  && in_mode == DFmode && in_n == 2)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRDPIP];\n+      break;\n+    case BUILT_IN_CEILF:\n+      if (out_mode != SFmode || out_n != 4\n+\t  || in_mode != SFmode || in_n != 4)\n+\tbreak;\n+      if (VECTOR_UNIT_VSX_P (V4SFmode))\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRSPIP];\n+      if (VECTOR_UNIT_ALTIVEC_P (V4SFmode))\n+\treturn rs6000_builtin_decls[ALTIVEC_BUILTIN_VRFIP];\n+      break;\n+    case BUILT_IN_FLOOR:\n+      if (VECTOR_UNIT_VSX_P (V2DFmode)\n+\t  && out_mode == DFmode && out_n == 2\n+\t  && in_mode == DFmode && in_n == 2)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRDPIM];\n+      break;\n+    case BUILT_IN_FLOORF:\n+      if (out_mode != SFmode || out_n != 4\n+\t  || in_mode != SFmode || in_n != 4)\n+\tbreak;\n+      if (VECTOR_UNIT_VSX_P (V4SFmode))\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRSPIM];\n+      if (VECTOR_UNIT_ALTIVEC_P (V4SFmode))\n+\treturn rs6000_builtin_decls[ALTIVEC_BUILTIN_VRFIM];\n+      break;\n+    case BUILT_IN_TRUNC:\n+      if (VECTOR_UNIT_VSX_P (V2DFmode)\n+\t  && out_mode == DFmode && out_n == 2\n+\t  && in_mode == DFmode && in_n == 2)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRDPIZ];\n+      break;\n+    case BUILT_IN_TRUNCF:\n+      if (out_mode != SFmode || out_n != 4\n+\t  || in_mode != SFmode || in_n != 4)\n+\tbreak;\n+      if (VECTOR_UNIT_VSX_P (V4SFmode))\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRSPIZ];\n+      if (VECTOR_UNIT_ALTIVEC_P (V4SFmode))\n+\treturn rs6000_builtin_decls[ALTIVEC_BUILTIN_VRFIZ];\n+      break;\n+    case BUILT_IN_NEARBYINT:\n+      if (VECTOR_UNIT_VSX_P (V2DFmode)\n+\t  && flag_unsafe_math_optimizations\n+\t  && out_mode == DFmode && out_n == 2\n+\t  && in_mode == DFmode && in_n == 2)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRDPI];\n+      break;\n+    case BUILT_IN_NEARBYINTF:\n+      if (VECTOR_UNIT_VSX_P (V4SFmode)\n+\t  && flag_unsafe_math_optimizations\n+\t  && out_mode == SFmode && out_n == 4\n+\t  && in_mode == SFmode && in_n == 4)\n+\treturn rs6000_builtin_decls[VSX_BUILTIN_XVRSPI];\n+      break;\n+    case BUILT_IN_RINT:\n+      if (VECTOR_UNIT_VSX_P (V2DFmode)\n+\t  && !flag_trapping_math\n+          && out_mode == DFmode && out_n == 2\n+          && in_mode == DFmode && in_n == 2)\n+        return rs6000_builtin_decls[VSX_BUILTIN_XVRDPIC];\n+      break;\n+    case BUILT_IN_RINTF:\n+      if (VECTOR_UNIT_VSX_P (V4SFmode)\n+\t  && !flag_trapping_math\n+          && out_mode == SFmode && out_n == 4\n+          && in_mode == SFmode && in_n == 4)\n+        return rs6000_builtin_decls[VSX_BUILTIN_XVRSPIC];\n+      break;\n+    default:\n+      break;\n+    }\n+  return NULL_TREE;\n+}\n+\n+\n /* Implement TARGET_HANDLE_OPTION.  */\n \n static bool\n@@ -3621,6 +3782,11 @@ vspltis_constant (rtx op, unsigned step, unsigned copies)\n            && (splat_val >= 0 || (step == 1 && copies == 1)))\n     ;\n \n+  /* Also check if are loading up the most significant bit which can be done by\n+     loading up -1 and shifting the value left by -1.  */\n+  else if (EASY_VECTOR_MSB (splat_val, inner))\n+    ;\n+\n   else\n     return false;\n \n@@ -3971,8 +4137,6 @@ rs6000_expand_vector_init (rtx target, rtx vals)\n \t  emit_insn (gen_rtx_SET (VOIDmode, target, const_vec));\n \t  return;\n \t}\n-      else if (all_same && int_vector_p)\n-\t;\t/* Splat vector element.  */\n       else\n \t{\n \t  /* Load from constant pool.  */\n@@ -3981,8 +4145,66 @@ rs6000_expand_vector_init (rtx target, rtx vals)\n \t}\n     }\n \n-  /* Store value to stack temp.  Load vector element.  Splat.  */\n-  if (all_same)\n+  /* Double word values on VSX can use xxpermdi or lxvdsx.  */\n+  if (VECTOR_MEM_VSX_P (mode) && (mode == V2DFmode || mode == V2DImode))\n+    {\n+      if (all_same)\n+\t{\n+\t  rtx element = XVECEXP (vals, 0, 0);\n+\t  if (mode == V2DFmode)\n+\t    emit_insn (gen_vsx_splat_v2df (target, element));\n+\t  else\n+\t    emit_insn (gen_vsx_splat_v2di (target, element));\n+\t}\n+      else\n+\t{\n+\t  rtx op0 = copy_to_reg (XVECEXP (vals, 0, 0));\n+\t  rtx op1 = copy_to_reg (XVECEXP (vals, 0, 1));\n+\t  if (mode == V2DFmode)\n+\t    emit_insn (gen_vsx_concat_v2df (target, op0, op1));\n+\t  else\n+\t    emit_insn (gen_vsx_concat_v2di (target, op0, op1));\n+\t}\n+      return;\n+    }\n+\n+  /* With single precision floating point on VSX, know that internally single\n+     precision is actually represented as a double, and either make 2 V2DF\n+     vectors, and convert these vectors to single precision, or do one\n+     conversion, and splat the result to the other elements.  */\n+  if (mode == V4SFmode && VECTOR_MEM_VSX_P (mode))\n+    {\n+      if (all_same)\n+\t{\n+\t  rtx freg = gen_reg_rtx (V4SFmode);\n+\t  rtx sreg = copy_to_reg (XVECEXP (vals, 0, 0));\n+\n+\t  emit_insn (gen_vsx_xscvdpsp_scalar (freg, sreg));\n+\t  emit_insn (gen_vsx_xxspltw_v4sf (target, freg, const0_rtx));\n+\t}\n+      else\n+\t{\n+\t  rtx dbl_even = gen_reg_rtx (V2DFmode);\n+\t  rtx dbl_odd  = gen_reg_rtx (V2DFmode);\n+\t  rtx flt_even = gen_reg_rtx (V4SFmode);\n+\t  rtx flt_odd  = gen_reg_rtx (V4SFmode);\n+\n+\t  emit_insn (gen_vsx_concat_v2sf (dbl_even,\n+\t\t\t\t\t  copy_to_reg (XVECEXP (vals, 0, 0)),\n+\t\t\t\t\t  copy_to_reg (XVECEXP (vals, 0, 1))));\n+\t  emit_insn (gen_vsx_concat_v2sf (dbl_odd,\n+\t\t\t\t\t  copy_to_reg (XVECEXP (vals, 0, 2)),\n+\t\t\t\t\t  copy_to_reg (XVECEXP (vals, 0, 3))));\n+\t  emit_insn (gen_vsx_xvcvdpsp (flt_even, dbl_even));\n+\t  emit_insn (gen_vsx_xvcvdpsp (flt_odd, dbl_odd));\n+\t  emit_insn (gen_vec_extract_evenv4sf (target, flt_even, flt_odd));\n+\t}\n+      return;\n+    }\n+\n+  /* Store value to stack temp.  Load vector element.  Splat.  However, splat\n+     of 64-bit items is not supported on Altivec.  */\n+  if (all_same && GET_MODE_SIZE (mode) <= 4)\n     {\n       mem = assign_stack_temp (mode, GET_MODE_SIZE (inner_mode), 0);\n       emit_move_insn (adjust_address_nv (mem, inner_mode, 0),\n@@ -4040,6 +4262,14 @@ rs6000_expand_vector_set (rtx target, rtx val, int elt)\n   int width = GET_MODE_SIZE (inner_mode);\n   int i;\n \n+  if (VECTOR_MEM_VSX_P (mode) && (mode == V2DFmode || mode == V2DImode))\n+    {\n+      rtx (*set_func) (rtx, rtx, rtx, rtx)\n+\t= ((mode == V2DFmode) ? gen_vsx_set_v2df : gen_vsx_set_v2di);\n+      emit_insn (set_func (target, target, val, GEN_INT (elt)));\n+      return;\n+    }\n+\n   /* Load single variable value.  */\n   mem = assign_stack_temp (mode, GET_MODE_SIZE (inner_mode), 0);\n   emit_move_insn (adjust_address_nv (mem, inner_mode, 0), val);\n@@ -4077,6 +4307,14 @@ rs6000_expand_vector_extract (rtx target, rtx vec, int elt)\n   enum machine_mode inner_mode = GET_MODE_INNER (mode);\n   rtx mem, x;\n \n+  if (VECTOR_MEM_VSX_P (mode) && (mode == V2DFmode || mode == V2DImode))\n+    {\n+      rtx (*extract_func) (rtx, rtx, rtx)\n+\t= ((mode == V2DFmode) ? gen_vsx_extract_v2df : gen_vsx_extract_v2di);\n+      emit_insn (extract_func (target, vec, GEN_INT (elt)));\n+      return;\n+    }\n+\n   /* Allocate mode-sized buffer.  */\n   mem = assign_stack_temp (mode, GET_MODE_SIZE (mode), 0);\n \n@@ -5447,6 +5685,10 @@ rs6000_mode_dependent_address (rtx addr)\n     case PRE_MODIFY:\n       return TARGET_UPDATE;\n \n+    /* AND is only allowed in Altivec loads.  */\n+    case AND:\n+      return true;\n+\n     default:\n       break;\n     }\n@@ -6048,6 +6290,8 @@ rs6000_emit_move (rtx dest, rtx source, enum machine_mode mode)\n     case V2SFmode:\n     case V2SImode:\n     case V1DImode:\n+    case V2DFmode:\n+    case V2DImode:\n       if (CONSTANT_P (operands[1])\n \t  && !easy_vector_constant (operands[1], mode))\n \toperands[1] = force_const_mem (mode, operands[1]);\n@@ -8192,6 +8436,59 @@ static const struct builtin_description bdesc_3arg[] =\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_perm\", ALTIVEC_BUILTIN_VEC_PERM },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_sel\", ALTIVEC_BUILTIN_VEC_SEL },\n \n+  { MASK_VSX, CODE_FOR_vsx_fmaddv2df4, \"__builtin_vsx_xvmadddp\", VSX_BUILTIN_XVMADDDP },\n+  { MASK_VSX, CODE_FOR_vsx_fmsubv2df4, \"__builtin_vsx_xvmsubdp\", VSX_BUILTIN_XVMSUBDP },\n+  { MASK_VSX, CODE_FOR_vsx_fnmaddv2df4, \"__builtin_vsx_xvnmadddp\", VSX_BUILTIN_XVNMADDDP },\n+  { MASK_VSX, CODE_FOR_vsx_fnmsubv2df4, \"__builtin_vsx_xvnmsubdp\", VSX_BUILTIN_XVNMSUBDP },\n+\n+  { MASK_VSX, CODE_FOR_vsx_fmaddv4sf4, \"__builtin_vsx_xvmaddsp\", VSX_BUILTIN_XVMADDSP },\n+  { MASK_VSX, CODE_FOR_vsx_fmsubv4sf4, \"__builtin_vsx_xvmsubsp\", VSX_BUILTIN_XVMSUBSP },\n+  { MASK_VSX, CODE_FOR_vsx_fnmaddv4sf4, \"__builtin_vsx_xvnmaddsp\", VSX_BUILTIN_XVNMADDSP },\n+  { MASK_VSX, CODE_FOR_vsx_fnmsubv4sf4, \"__builtin_vsx_xvnmsubsp\", VSX_BUILTIN_XVNMSUBSP },\n+\n+  { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_msub\", VSX_BUILTIN_VEC_MSUB },\n+  { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_nmadd\", VSX_BUILTIN_VEC_NMADD },\n+\n+  { MASK_VSX, CODE_FOR_vector_select_v2di, \"__builtin_vsx_xxsel_2di\", VSX_BUILTIN_XXSEL_2DI },\n+  { MASK_VSX, CODE_FOR_vector_select_v2df, \"__builtin_vsx_xxsel_2df\", VSX_BUILTIN_XXSEL_2DF },\n+  { MASK_VSX, CODE_FOR_vector_select_v4sf, \"__builtin_vsx_xxsel_4sf\", VSX_BUILTIN_XXSEL_4SF },\n+  { MASK_VSX, CODE_FOR_vector_select_v4si, \"__builtin_vsx_xxsel_4si\", VSX_BUILTIN_XXSEL_4SI },\n+  { MASK_VSX, CODE_FOR_vector_select_v8hi, \"__builtin_vsx_xxsel_8hi\", VSX_BUILTIN_XXSEL_8HI },\n+  { MASK_VSX, CODE_FOR_vector_select_v16qi, \"__builtin_vsx_xxsel_16qi\", VSX_BUILTIN_XXSEL_16QI },\n+  { MASK_VSX, CODE_FOR_vector_select_v2di_uns, \"__builtin_vsx_xxsel_2di_uns\", VSX_BUILTIN_XXSEL_2DI_UNS },\n+  { MASK_VSX, CODE_FOR_vector_select_v4si_uns, \"__builtin_vsx_xxsel_4si_uns\", VSX_BUILTIN_XXSEL_4SI_UNS },\n+  { MASK_VSX, CODE_FOR_vector_select_v8hi_uns, \"__builtin_vsx_xxsel_8hi_uns\", VSX_BUILTIN_XXSEL_8HI_UNS },\n+  { MASK_VSX, CODE_FOR_vector_select_v16qi_uns, \"__builtin_vsx_xxsel_16qi_uns\", VSX_BUILTIN_XXSEL_16QI_UNS },\n+\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v2di, \"__builtin_vsx_vperm_2di\", VSX_BUILTIN_VPERM_2DI },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v2df, \"__builtin_vsx_vperm_2df\", VSX_BUILTIN_VPERM_2DF },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v4sf, \"__builtin_vsx_vperm_4sf\", VSX_BUILTIN_VPERM_4SF },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v4si, \"__builtin_vsx_vperm_4si\", VSX_BUILTIN_VPERM_4SI },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v8hi, \"__builtin_vsx_vperm_8hi\", VSX_BUILTIN_VPERM_8HI },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v16qi, \"__builtin_vsx_vperm_16qi\", VSX_BUILTIN_VPERM_16QI },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v2di_uns, \"__builtin_vsx_vperm_2di_uns\", VSX_BUILTIN_VPERM_2DI_UNS },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v4si_uns, \"__builtin_vsx_vperm_4si_uns\", VSX_BUILTIN_VPERM_4SI_UNS },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v8hi_uns, \"__builtin_vsx_vperm_8hi_uns\", VSX_BUILTIN_VPERM_8HI_UNS },\n+  { MASK_VSX, CODE_FOR_altivec_vperm_v16qi_uns, \"__builtin_vsx_vperm_16qi_uns\", VSX_BUILTIN_VPERM_16QI_UNS },\n+\n+  { MASK_VSX, CODE_FOR_vsx_xxpermdi_v2df, \"__builtin_vsx_xxpermdi_2df\", VSX_BUILTIN_XXPERMDI_2DF },\n+  { MASK_VSX, CODE_FOR_vsx_xxpermdi_v2di, \"__builtin_vsx_xxpermdi_2di\", VSX_BUILTIN_XXPERMDI_2DI },\n+  { MASK_VSX, CODE_FOR_vsx_xxpermdi_v4sf, \"__builtin_vsx_xxpermdi_4sf\", VSX_BUILTIN_XXPERMDI_4SF },\n+  { MASK_VSX, CODE_FOR_vsx_xxpermdi_v4si, \"__builtin_vsx_xxpermdi_4si\", VSX_BUILTIN_XXPERMDI_4SI },\n+  { MASK_VSX, CODE_FOR_vsx_xxpermdi_v8hi, \"__builtin_vsx_xxpermdi_8hi\", VSX_BUILTIN_XXPERMDI_8HI },\n+  { MASK_VSX, CODE_FOR_vsx_xxpermdi_v16qi, \"__builtin_vsx_xxpermdi_16qi\", VSX_BUILTIN_XXPERMDI_16QI },\n+  { MASK_VSX, CODE_FOR_nothing, \"__builtin_vsx_xxpermdi\", VSX_BUILTIN_VEC_XXPERMDI },\n+  { MASK_VSX, CODE_FOR_vsx_set_v2df, \"__builtin_vsx_set_2df\", VSX_BUILTIN_SET_2DF },\n+  { MASK_VSX, CODE_FOR_vsx_set_v2di, \"__builtin_vsx_set_2di\", VSX_BUILTIN_SET_2DI },\n+\n+  { MASK_VSX, CODE_FOR_vsx_xxsldwi_v2di, \"__builtin_vsx_xxsldwi_2di\", VSX_BUILTIN_XXSLDWI_2DI },\n+  { MASK_VSX, CODE_FOR_vsx_xxsldwi_v2df, \"__builtin_vsx_xxsldwi_2df\", VSX_BUILTIN_XXSLDWI_2DF },\n+  { MASK_VSX, CODE_FOR_vsx_xxsldwi_v4sf, \"__builtin_vsx_xxsldwi_4sf\", VSX_BUILTIN_XXSLDWI_4SF },\n+  { MASK_VSX, CODE_FOR_vsx_xxsldwi_v4si, \"__builtin_vsx_xxsldwi_4si\", VSX_BUILTIN_XXSLDWI_4SI },\n+  { MASK_VSX, CODE_FOR_vsx_xxsldwi_v8hi, \"__builtin_vsx_xxsldwi_8hi\", VSX_BUILTIN_XXSLDWI_8HI },\n+  { MASK_VSX, CODE_FOR_vsx_xxsldwi_v16qi, \"__builtin_vsx_xxsldwi_16qi\", VSX_BUILTIN_XXSLDWI_16QI },\n+  { MASK_VSX, CODE_FOR_nothing, \"__builtin_vsx_xxsldwi\", VSX_BUILTIN_VEC_XXSLDWI },\n+\n   { 0, CODE_FOR_paired_msub, \"__builtin_paired_msub\", PAIRED_BUILTIN_MSUB },\n   { 0, CODE_FOR_paired_madd, \"__builtin_paired_madd\", PAIRED_BUILTIN_MADD },\n   { 0, CODE_FOR_paired_madds0, \"__builtin_paired_madds0\", PAIRED_BUILTIN_MADDS0 },\n@@ -8337,9 +8634,50 @@ static struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsum2sws, \"__builtin_altivec_vsum2sws\", ALTIVEC_BUILTIN_VSUM2SWS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsumsws, \"__builtin_altivec_vsumsws\", ALTIVEC_BUILTIN_VSUMSWS },\n   { MASK_ALTIVEC, CODE_FOR_xorv4si3, \"__builtin_altivec_vxor\", ALTIVEC_BUILTIN_VXOR },\n-\n-  { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_add\", ALTIVEC_BUILTIN_VEC_ADD },\n-  { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vaddfp\", ALTIVEC_BUILTIN_VEC_VADDFP },\n+  { MASK_ALTIVEC, CODE_FOR_vector_copysignv4sf3, \"__builtin_altivec_copysignfp\", ALTIVEC_BUILTIN_COPYSIGN_V4SF },\n+\n+  { MASK_VSX, CODE_FOR_addv2df3, \"__builtin_vsx_xvadddp\", VSX_BUILTIN_XVADDDP },\n+  { MASK_VSX, CODE_FOR_subv2df3, \"__builtin_vsx_xvsubdp\", VSX_BUILTIN_XVSUBDP },\n+  { MASK_VSX, CODE_FOR_mulv2df3, \"__builtin_vsx_xvmuldp\", VSX_BUILTIN_XVMULDP },\n+  { MASK_VSX, CODE_FOR_divv2df3, \"__builtin_vsx_xvdivdp\", VSX_BUILTIN_XVDIVDP },\n+  { MASK_VSX, CODE_FOR_sminv2df3, \"__builtin_vsx_xvmindp\", VSX_BUILTIN_XVMINDP },\n+  { MASK_VSX, CODE_FOR_smaxv2df3, \"__builtin_vsx_xvmaxdp\", VSX_BUILTIN_XVMAXDP },\n+  { MASK_VSX, CODE_FOR_vsx_tdivv2df3_fe, \"__builtin_vsx_xvtdivdp_fe\", VSX_BUILTIN_XVTDIVDP_FE },\n+  { MASK_VSX, CODE_FOR_vsx_tdivv2df3_fg, \"__builtin_vsx_xvtdivdp_fg\", VSX_BUILTIN_XVTDIVDP_FG },\n+  { MASK_VSX, CODE_FOR_vector_eqv2df, \"__builtin_vsx_xvcmpeqdp\", VSX_BUILTIN_XVCMPEQDP },\n+  { MASK_VSX, CODE_FOR_vector_gtv2df, \"__builtin_vsx_xvcmpgtdp\", VSX_BUILTIN_XVCMPGTDP },\n+  { MASK_VSX, CODE_FOR_vector_gev2df, \"__builtin_vsx_xvcmpgedp\", VSX_BUILTIN_XVCMPGEDP },\n+\n+  { MASK_VSX, CODE_FOR_addv4sf3, \"__builtin_vsx_xvaddsp\", VSX_BUILTIN_XVADDSP },\n+  { MASK_VSX, CODE_FOR_subv4sf3, \"__builtin_vsx_xvsubsp\", VSX_BUILTIN_XVSUBSP },\n+  { MASK_VSX, CODE_FOR_mulv4sf3, \"__builtin_vsx_xvmulsp\", VSX_BUILTIN_XVMULSP },\n+  { MASK_VSX, CODE_FOR_divv4sf3, \"__builtin_vsx_xvdivsp\", VSX_BUILTIN_XVDIVSP },\n+  { MASK_VSX, CODE_FOR_sminv4sf3, \"__builtin_vsx_xvminsp\", VSX_BUILTIN_XVMINSP },\n+  { MASK_VSX, CODE_FOR_smaxv4sf3, \"__builtin_vsx_xvmaxsp\", VSX_BUILTIN_XVMAXSP },\n+  { MASK_VSX, CODE_FOR_vsx_tdivv4sf3_fe, \"__builtin_vsx_xvtdivsp_fe\", VSX_BUILTIN_XVTDIVSP_FE },\n+  { MASK_VSX, CODE_FOR_vsx_tdivv4sf3_fg, \"__builtin_vsx_xvtdivsp_fg\", VSX_BUILTIN_XVTDIVSP_FG },\n+  { MASK_VSX, CODE_FOR_vector_eqv4sf, \"__builtin_vsx_xvcmpeqsp\", VSX_BUILTIN_XVCMPEQSP },\n+  { MASK_VSX, CODE_FOR_vector_gtv4sf, \"__builtin_vsx_xvcmpgtsp\", VSX_BUILTIN_XVCMPGTSP },\n+  { MASK_VSX, CODE_FOR_vector_gev4sf, \"__builtin_vsx_xvcmpgesp\", VSX_BUILTIN_XVCMPGESP },\n+\n+  { MASK_VSX, CODE_FOR_smindf3, \"__builtin_vsx_xsmindp\", VSX_BUILTIN_XSMINDP },\n+  { MASK_VSX, CODE_FOR_smaxdf3, \"__builtin_vsx_xsmaxdp\", VSX_BUILTIN_XSMAXDP },\n+  { MASK_VSX, CODE_FOR_vsx_tdivdf3_fe, \"__builtin_vsx_xstdivdp_fe\", VSX_BUILTIN_XSTDIVDP_FE },\n+  { MASK_VSX, CODE_FOR_vsx_tdivdf3_fg, \"__builtin_vsx_xstdivdp_fg\", VSX_BUILTIN_XSTDIVDP_FG },\n+  { MASK_VSX, CODE_FOR_vector_copysignv2df3, \"__builtin_vsx_cpsgndp\", VSX_BUILTIN_CPSGNDP },\n+  { MASK_VSX, CODE_FOR_vector_copysignv4sf3, \"__builtin_vsx_cpsgnsp\", VSX_BUILTIN_CPSGNSP },\n+\n+  { MASK_VSX, CODE_FOR_vsx_concat_v2df, \"__builtin_vsx_concat_2df\", VSX_BUILTIN_CONCAT_2DF },\n+  { MASK_VSX, CODE_FOR_vsx_concat_v2di, \"__builtin_vsx_concat_2di\", VSX_BUILTIN_CONCAT_2DI },\n+  { MASK_VSX, CODE_FOR_vsx_splat_v2df, \"__builtin_vsx_splat_2df\", VSX_BUILTIN_SPLAT_2DF },\n+  { MASK_VSX, CODE_FOR_vsx_splat_v2di, \"__builtin_vsx_splat_2di\", VSX_BUILTIN_SPLAT_2DI },\n+  { MASK_VSX, CODE_FOR_vsx_xxmrghw_v4sf, \"__builtin_vsx_xxmrghw\", VSX_BUILTIN_XXMRGHW_4SF },\n+  { MASK_VSX, CODE_FOR_vsx_xxmrghw_v4si, \"__builtin_vsx_xxmrghw_4si\", VSX_BUILTIN_XXMRGHW_4SI },\n+  { MASK_VSX, CODE_FOR_vsx_xxmrglw_v4sf, \"__builtin_vsx_xxmrglw\", VSX_BUILTIN_XXMRGLW_4SF },\n+  { MASK_VSX, CODE_FOR_vsx_xxmrglw_v4si, \"__builtin_vsx_xxmrglw_4si\", VSX_BUILTIN_XXMRGLW_4SI },\n+\n+  { MASK_ALTIVEC|MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_add\", ALTIVEC_BUILTIN_VEC_ADD },\n+  { MASK_ALTIVEC|MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_vaddfp\", ALTIVEC_BUILTIN_VEC_VADDFP },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vadduwm\", ALTIVEC_BUILTIN_VEC_VADDUWM },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vadduhm\", ALTIVEC_BUILTIN_VEC_VADDUHM },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vaddubm\", ALTIVEC_BUILTIN_VEC_VADDUBM },\n@@ -8377,6 +8715,7 @@ static struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vcmpgtub\", ALTIVEC_BUILTIN_VEC_VCMPGTUB },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_cmple\", ALTIVEC_BUILTIN_VEC_CMPLE },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_cmplt\", ALTIVEC_BUILTIN_VEC_CMPLT },\n+  { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_copysign\", ALTIVEC_BUILTIN_VEC_COPYSIGN },\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_max\", ALTIVEC_BUILTIN_VEC_MAX },\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_vmaxfp\", ALTIVEC_BUILTIN_VEC_VMAXFP },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vmaxsw\", ALTIVEC_BUILTIN_VEC_VMAXSW },\n@@ -8466,6 +8805,9 @@ static struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_sums\", ALTIVEC_BUILTIN_VEC_SUMS },\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_xor\", ALTIVEC_BUILTIN_VEC_XOR },\n \n+  { MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_mul\", VSX_BUILTIN_VEC_MUL },\n+  { MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_div\", VSX_BUILTIN_VEC_DIV },\n+\n   { 0, CODE_FOR_divv2sf3, \"__builtin_paired_divv2sf3\", PAIRED_BUILTIN_DIVV2SF3 },\n   { 0, CODE_FOR_addv2sf3, \"__builtin_paired_addv2sf3\", PAIRED_BUILTIN_ADDV2SF3 },\n   { 0, CODE_FOR_subv2sf3, \"__builtin_paired_subv2sf3\", PAIRED_BUILTIN_SUBV2SF3 },\n@@ -8661,6 +9003,19 @@ static const struct builtin_description_predicates bdesc_altivec_preds[] =\n   { MASK_ALTIVEC, CODE_FOR_vector_gtu_v16qi_p, \"__builtin_altivec_vcmpgtub_p\",\n     ALTIVEC_BUILTIN_VCMPGTUB_P },\n \n+  { MASK_VSX, CODE_FOR_vector_eq_v4sf_p, \"__builtin_vsx_xvcmpeqsp_p\",\n+    VSX_BUILTIN_XVCMPEQSP_P },\n+  { MASK_VSX, CODE_FOR_vector_ge_v4sf_p, \"__builtin_vsx_xvcmpgesp_p\",\n+    VSX_BUILTIN_XVCMPGESP_P },\n+  { MASK_VSX, CODE_FOR_vector_gt_v4sf_p, \"__builtin_vsx_xvcmpgtsp_p\",\n+    VSX_BUILTIN_XVCMPGTSP_P },\n+  { MASK_VSX, CODE_FOR_vector_eq_v2df_p, \"__builtin_vsx_xvcmpeqdp_p\",\n+    VSX_BUILTIN_XVCMPEQDP_P },\n+  { MASK_VSX, CODE_FOR_vector_ge_v2df_p, \"__builtin_vsx_xvcmpgedp_p\",\n+    VSX_BUILTIN_XVCMPGEDP_P },\n+  { MASK_VSX, CODE_FOR_vector_gt_v2df_p, \"__builtin_vsx_xvcmpgtdp_p\",\n+    VSX_BUILTIN_XVCMPGTDP_P },\n+\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_vcmpeq_p\",\n     ALTIVEC_BUILTIN_VCMPEQ_P },\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_vcmpgt_p\",\n@@ -8724,7 +9079,11 @@ static const struct builtin_description bdesc_abs[] =\n   { MASK_ALTIVEC, CODE_FOR_absv16qi2, \"__builtin_altivec_abs_v16qi\", ALTIVEC_BUILTIN_ABS_V16QI },\n   { MASK_ALTIVEC, CODE_FOR_altivec_abss_v4si, \"__builtin_altivec_abss_v4si\", ALTIVEC_BUILTIN_ABSS_V4SI },\n   { MASK_ALTIVEC, CODE_FOR_altivec_abss_v8hi, \"__builtin_altivec_abss_v8hi\", ALTIVEC_BUILTIN_ABSS_V8HI },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_abss_v16qi, \"__builtin_altivec_abss_v16qi\", ALTIVEC_BUILTIN_ABSS_V16QI }\n+  { MASK_ALTIVEC, CODE_FOR_altivec_abss_v16qi, \"__builtin_altivec_abss_v16qi\", ALTIVEC_BUILTIN_ABSS_V16QI },\n+  { MASK_VSX, CODE_FOR_absv2df2, \"__builtin_vsx_xvabsdp\", VSX_BUILTIN_XVABSDP },\n+  { MASK_VSX, CODE_FOR_vsx_nabsv2df2, \"__builtin_vsx_xvnabsdp\", VSX_BUILTIN_XVNABSDP },\n+  { MASK_VSX, CODE_FOR_absv4sf2, \"__builtin_vsx_xvabssp\", VSX_BUILTIN_XVABSSP },\n+  { MASK_VSX, CODE_FOR_vsx_nabsv4sf2, \"__builtin_vsx_xvnabssp\", VSX_BUILTIN_XVNABSSP },\n };\n \n /* Simple unary operations: VECb = foo (unsigned literal) or VECb =\n@@ -8735,10 +9094,10 @@ static struct builtin_description bdesc_1arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vexptefp, \"__builtin_altivec_vexptefp\", ALTIVEC_BUILTIN_VEXPTEFP },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vlogefp, \"__builtin_altivec_vlogefp\", ALTIVEC_BUILTIN_VLOGEFP },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vrefp, \"__builtin_altivec_vrefp\", ALTIVEC_BUILTIN_VREFP },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vrfim, \"__builtin_altivec_vrfim\", ALTIVEC_BUILTIN_VRFIM },\n+  { MASK_ALTIVEC, CODE_FOR_vector_floorv4sf2, \"__builtin_altivec_vrfim\", ALTIVEC_BUILTIN_VRFIM },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vrfin, \"__builtin_altivec_vrfin\", ALTIVEC_BUILTIN_VRFIN },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vrfip, \"__builtin_altivec_vrfip\", ALTIVEC_BUILTIN_VRFIP },\n-  { MASK_ALTIVEC, CODE_FOR_ftruncv4sf2, \"__builtin_altivec_vrfiz\", ALTIVEC_BUILTIN_VRFIZ },\n+  { MASK_ALTIVEC, CODE_FOR_vector_ceilv4sf2, \"__builtin_altivec_vrfip\", ALTIVEC_BUILTIN_VRFIP },\n+  { MASK_ALTIVEC, CODE_FOR_vector_btruncv4sf2, \"__builtin_altivec_vrfiz\", ALTIVEC_BUILTIN_VRFIZ },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vrsqrtefp, \"__builtin_altivec_vrsqrtefp\", ALTIVEC_BUILTIN_VRSQRTEFP },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vspltisb, \"__builtin_altivec_vspltisb\", ALTIVEC_BUILTIN_VSPLTISB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vspltish, \"__builtin_altivec_vspltish\", ALTIVEC_BUILTIN_VSPLTISH },\n@@ -8750,6 +9109,65 @@ static struct builtin_description bdesc_1arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vupklpx, \"__builtin_altivec_vupklpx\", ALTIVEC_BUILTIN_VUPKLPX },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vupklsh, \"__builtin_altivec_vupklsh\", ALTIVEC_BUILTIN_VUPKLSH },\n \n+  { MASK_VSX, CODE_FOR_negv2df2, \"__builtin_vsx_xvnegdp\", VSX_BUILTIN_XVNEGDP },\n+  { MASK_VSX, CODE_FOR_sqrtv2df2, \"__builtin_vsx_xvsqrtdp\", VSX_BUILTIN_XVSQRTDP },\n+  { MASK_VSX, CODE_FOR_vsx_rsqrtev2df2, \"__builtin_vsx_xvrsqrtedp\", VSX_BUILTIN_XVRSQRTEDP },\n+  { MASK_VSX, CODE_FOR_vsx_tsqrtv2df2_fe, \"__builtin_vsx_xvtsqrtdp_fe\", VSX_BUILTIN_XVTSQRTDP_FE },\n+  { MASK_VSX, CODE_FOR_vsx_tsqrtv2df2_fg, \"__builtin_vsx_xvtsqrtdp_fg\", VSX_BUILTIN_XVTSQRTDP_FG },\n+  { MASK_VSX, CODE_FOR_vsx_frev2df2, \"__builtin_vsx_xvredp\", VSX_BUILTIN_XVREDP },\n+\n+  { MASK_VSX, CODE_FOR_negv4sf2, \"__builtin_vsx_xvnegsp\", VSX_BUILTIN_XVNEGSP },\n+  { MASK_VSX, CODE_FOR_sqrtv4sf2, \"__builtin_vsx_xvsqrtsp\", VSX_BUILTIN_XVSQRTSP },\n+  { MASK_VSX, CODE_FOR_vsx_rsqrtev4sf2, \"__builtin_vsx_xvrsqrtesp\", VSX_BUILTIN_XVRSQRTESP },\n+  { MASK_VSX, CODE_FOR_vsx_tsqrtv4sf2_fe, \"__builtin_vsx_xvtsqrtsp_fe\", VSX_BUILTIN_XVTSQRTSP_FE },\n+  { MASK_VSX, CODE_FOR_vsx_tsqrtv4sf2_fg, \"__builtin_vsx_xvtsqrtsp_fg\", VSX_BUILTIN_XVTSQRTSP_FG },\n+  { MASK_VSX, CODE_FOR_vsx_frev4sf2, \"__builtin_vsx_xvresp\", VSX_BUILTIN_XVRESP },\n+\n+  { MASK_VSX, CODE_FOR_vsx_xscvdpsp, \"__builtin_vsx_xscvdpsp\", VSX_BUILTIN_XSCVDPSP },\n+  { MASK_VSX, CODE_FOR_vsx_xscvdpsp, \"__builtin_vsx_xscvspdp\", VSX_BUILTIN_XSCVSPDP },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvdpsp, \"__builtin_vsx_xvcvdpsp\", VSX_BUILTIN_XVCVDPSP },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvspdp, \"__builtin_vsx_xvcvspdp\", VSX_BUILTIN_XVCVSPDP },\n+  { MASK_VSX, CODE_FOR_vsx_tsqrtdf2_fe, \"__builtin_vsx_xstsqrtdp_fe\", VSX_BUILTIN_XSTSQRTDP_FE },\n+  { MASK_VSX, CODE_FOR_vsx_tsqrtdf2_fg, \"__builtin_vsx_xstsqrtdp_fg\", VSX_BUILTIN_XSTSQRTDP_FG },\n+\n+  { MASK_VSX, CODE_FOR_vsx_fix_truncv2dfv2di2, \"__builtin_vsx_xvcvdpsxds\", VSX_BUILTIN_XVCVDPSXDS },\n+  { MASK_VSX, CODE_FOR_vsx_fixuns_truncv2dfv2di2, \"__builtin_vsx_xvcvdpuxds\", VSX_BUILTIN_XVCVDPUXDS },\n+  { MASK_VSX, CODE_FOR_vsx_fixuns_truncv2dfv2di2, \"__builtin_vsx_xvcvdpuxds_uns\", VSX_BUILTIN_XVCVDPUXDS_UNS },\n+  { MASK_VSX, CODE_FOR_vsx_floatv2div2df2, \"__builtin_vsx_xvcvsxddp\", VSX_BUILTIN_XVCVSXDDP },\n+  { MASK_VSX, CODE_FOR_vsx_floatunsv2div2df2, \"__builtin_vsx_xvcvuxddp\", VSX_BUILTIN_XVCVUXDDP },\n+  { MASK_VSX, CODE_FOR_vsx_floatunsv2div2df2, \"__builtin_vsx_xvcvuxddp_uns\", VSX_BUILTIN_XVCVUXDDP_UNS },\n+\n+  { MASK_VSX, CODE_FOR_vsx_fix_truncv4sfv4si2, \"__builtin_vsx_xvcvspsxws\", VSX_BUILTIN_XVCVSPSXWS },\n+  { MASK_VSX, CODE_FOR_vsx_fixuns_truncv4sfv4si2, \"__builtin_vsx_xvcvspuxws\", VSX_BUILTIN_XVCVSPUXWS },\n+  { MASK_VSX, CODE_FOR_vsx_floatv4siv4sf2, \"__builtin_vsx_xvcvsxwsp\", VSX_BUILTIN_XVCVSXWSP },\n+  { MASK_VSX, CODE_FOR_vsx_floatunsv4siv4sf2, \"__builtin_vsx_xvcvuxwsp\", VSX_BUILTIN_XVCVUXWSP },\n+\n+  { MASK_VSX, CODE_FOR_vsx_xvcvdpsxws, \"__builtin_vsx_xvcvdpsxws\", VSX_BUILTIN_XVCVDPSXWS },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvdpuxws, \"__builtin_vsx_xvcvdpuxws\", VSX_BUILTIN_XVCVDPUXWS },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvsxwdp, \"__builtin_vsx_xvcvsxwdp\", VSX_BUILTIN_XVCVSXWDP },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvuxwdp, \"__builtin_vsx_xvcvuxwdp\", VSX_BUILTIN_XVCVUXWDP },\n+  { MASK_VSX, CODE_FOR_vsx_xvrdpi, \"__builtin_vsx_xvrdpi\", VSX_BUILTIN_XVRDPI },\n+  { MASK_VSX, CODE_FOR_vsx_xvrdpic, \"__builtin_vsx_xvrdpic\", VSX_BUILTIN_XVRDPIC },\n+  { MASK_VSX, CODE_FOR_vsx_floorv2df2, \"__builtin_vsx_xvrdpim\", VSX_BUILTIN_XVRDPIM },\n+  { MASK_VSX, CODE_FOR_vsx_ceilv2df2, \"__builtin_vsx_xvrdpip\", VSX_BUILTIN_XVRDPIP },\n+  { MASK_VSX, CODE_FOR_vsx_btruncv2df2, \"__builtin_vsx_xvrdpiz\", VSX_BUILTIN_XVRDPIZ },\n+\n+  { MASK_VSX, CODE_FOR_vsx_xvcvspsxds, \"__builtin_vsx_xvcvspsxds\", VSX_BUILTIN_XVCVSPSXDS },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvspuxds, \"__builtin_vsx_xvcvspuxds\", VSX_BUILTIN_XVCVSPUXDS },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvsxdsp, \"__builtin_vsx_xvcvsxdsp\", VSX_BUILTIN_XVCVSXDSP },\n+  { MASK_VSX, CODE_FOR_vsx_xvcvuxdsp, \"__builtin_vsx_xvcvuxdsp\", VSX_BUILTIN_XVCVUXDSP },\n+  { MASK_VSX, CODE_FOR_vsx_xvrspi, \"__builtin_vsx_xvrspi\", VSX_BUILTIN_XVRSPI },\n+  { MASK_VSX, CODE_FOR_vsx_xvrspic, \"__builtin_vsx_xvrspic\", VSX_BUILTIN_XVRSPIC },\n+  { MASK_VSX, CODE_FOR_vsx_floorv4sf2, \"__builtin_vsx_xvrspim\", VSX_BUILTIN_XVRSPIM },\n+  { MASK_VSX, CODE_FOR_vsx_ceilv4sf2, \"__builtin_vsx_xvrspip\", VSX_BUILTIN_XVRSPIP },\n+  { MASK_VSX, CODE_FOR_vsx_btruncv4sf2, \"__builtin_vsx_xvrspiz\", VSX_BUILTIN_XVRSPIZ },\n+\n+  { MASK_VSX, CODE_FOR_vsx_xsrdpi, \"__builtin_vsx_xsrdpi\", VSX_BUILTIN_XSRDPI },\n+  { MASK_VSX, CODE_FOR_vsx_xsrdpic, \"__builtin_vsx_xsrdpic\", VSX_BUILTIN_XSRDPIC },\n+  { MASK_VSX, CODE_FOR_vsx_floordf2, \"__builtin_vsx_xsrdpim\", VSX_BUILTIN_XSRDPIM },\n+  { MASK_VSX, CODE_FOR_vsx_ceildf2, \"__builtin_vsx_xsrdpip\", VSX_BUILTIN_XSRDPIP },\n+  { MASK_VSX, CODE_FOR_vsx_btruncdf2, \"__builtin_vsx_xsrdpiz\", VSX_BUILTIN_XSRDPIZ },\n+\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_abs\", ALTIVEC_BUILTIN_VEC_ABS },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_abss\", ALTIVEC_BUILTIN_VEC_ABSS },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_ceil\", ALTIVEC_BUILTIN_VEC_CEIL },\n@@ -8770,6 +9188,10 @@ static struct builtin_description bdesc_1arg[] =\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vupklsh\", ALTIVEC_BUILTIN_VEC_VUPKLSH },\n   { MASK_ALTIVEC, CODE_FOR_nothing, \"__builtin_vec_vupklsb\", ALTIVEC_BUILTIN_VEC_VUPKLSB },\n \n+  { MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_nearbyint\", ALTIVEC_BUILTIN_VEC_NEARBYINT },\n+  { MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_rint\", ALTIVEC_BUILTIN_VEC_RINT },\n+  { MASK_VSX, CODE_FOR_nothing, \"__builtin_vec_sqrt\", ALTIVEC_BUILTIN_VEC_SQRT },\n+\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_floatv4siv4sf2, \"__builtin_vec_float_sisf\", VECTOR_BUILTIN_FLOAT_V4SI_V4SF },\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_unsigned_floatv4siv4sf2, \"__builtin_vec_uns_float_sisf\", VECTOR_BUILTIN_UNSFLOAT_V4SI_V4SF },\n   { MASK_ALTIVEC|MASK_VSX, CODE_FOR_fix_truncv4sfv4si2, \"__builtin_vec_fix_sfsi\", VECTOR_BUILTIN_FIX_V4SF_V4SI },\n@@ -9293,6 +9715,36 @@ rs6000_expand_ternop_builtin (enum insn_code icode, tree exp, rtx target)\n \t}\n       break;\n \n+    case CODE_FOR_vsx_xxpermdi_v2df:\n+    case CODE_FOR_vsx_xxpermdi_v2di:\n+    case CODE_FOR_vsx_xxsldwi_v16qi:\n+    case CODE_FOR_vsx_xxsldwi_v8hi:\n+    case CODE_FOR_vsx_xxsldwi_v4si:\n+    case CODE_FOR_vsx_xxsldwi_v4sf:\n+    case CODE_FOR_vsx_xxsldwi_v2di:\n+    case CODE_FOR_vsx_xxsldwi_v2df:\n+      /* Only allow 2-bit unsigned literals.  */\n+      STRIP_NOPS (arg2);\n+      if (TREE_CODE (arg2) != INTEGER_CST\n+\t  || TREE_INT_CST_LOW (arg2) & ~0x3)\n+\t{\n+\t  error (\"argument 3 must be a 2-bit unsigned literal\");\n+\t  return const0_rtx;\n+\t}\n+      break;\n+\n+    case CODE_FOR_vsx_set_v2df:\n+    case CODE_FOR_vsx_set_v2di:\n+      /* Only allow 1-bit unsigned literals.  */\n+      STRIP_NOPS (arg2);\n+      if (TREE_CODE (arg2) != INTEGER_CST\n+\t  || TREE_INT_CST_LOW (arg2) & ~0x1)\n+\t{\n+\t  error (\"argument 3 must be a 1-bit unsigned literal\");\n+\t  return const0_rtx;\n+\t}\n+      break;\n+\n     default:\n       break;\n     }\n@@ -9602,8 +10054,10 @@ altivec_expand_builtin (tree exp, rtx target, bool *expandedp)\n   enum machine_mode tmode, mode0;\n   unsigned int fcode = DECL_FUNCTION_CODE (fndecl);\n \n-  if (fcode >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n-      && fcode <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+  if ((fcode >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n+       && fcode <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+      || (fcode >= VSX_BUILTIN_OVERLOADED_FIRST\n+\t  && fcode <= VSX_BUILTIN_OVERLOADED_LAST))\n     {\n       *expandedp = true;\n       error (\"unresolved overload for Altivec builtin %qF\", fndecl);\n@@ -9711,18 +10165,24 @@ altivec_expand_builtin (tree exp, rtx target, bool *expandedp)\n     case ALTIVEC_BUILTIN_VEC_INIT_V8HI:\n     case ALTIVEC_BUILTIN_VEC_INIT_V16QI:\n     case ALTIVEC_BUILTIN_VEC_INIT_V4SF:\n+    case VSX_BUILTIN_VEC_INIT_V2DF:\n+    case VSX_BUILTIN_VEC_INIT_V2DI:\n       return altivec_expand_vec_init_builtin (TREE_TYPE (exp), exp, target);\n \n     case ALTIVEC_BUILTIN_VEC_SET_V4SI:\n     case ALTIVEC_BUILTIN_VEC_SET_V8HI:\n     case ALTIVEC_BUILTIN_VEC_SET_V16QI:\n     case ALTIVEC_BUILTIN_VEC_SET_V4SF:\n+    case VSX_BUILTIN_VEC_SET_V2DF:\n+    case VSX_BUILTIN_VEC_SET_V2DI:\n       return altivec_expand_vec_set_builtin (exp);\n \n     case ALTIVEC_BUILTIN_VEC_EXT_V4SI:\n     case ALTIVEC_BUILTIN_VEC_EXT_V8HI:\n     case ALTIVEC_BUILTIN_VEC_EXT_V16QI:\n     case ALTIVEC_BUILTIN_VEC_EXT_V4SF:\n+    case VSX_BUILTIN_VEC_EXT_V2DF:\n+    case VSX_BUILTIN_VEC_EXT_V2DI:\n       return altivec_expand_vec_ext_builtin (exp, target);\n \n     default:\n@@ -10245,6 +10705,11 @@ rs6000_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n   if (fcode == RS6000_BUILTIN_BSWAP_HI)\n     return rs6000_expand_unop_builtin (CODE_FOR_bswaphi2, exp, target);\n \n+  if (fcode == POWER7_BUILTIN_BPERMD)\n+    return rs6000_expand_binop_builtin (((TARGET_64BIT)\n+\t\t\t\t\t ? CODE_FOR_bpermd_di\n+\t\t\t\t\t : CODE_FOR_bpermd_si), exp, target);\n+\n   if (fcode == ALTIVEC_BUILTIN_MASK_FOR_LOAD\n       || fcode == ALTIVEC_BUILTIN_MASK_FOR_STORE)\n     {\n@@ -10500,6 +10965,33 @@ rs6000_init_builtins (void)\n   TYPE_NAME (pixel_V8HI_type_node) = tdecl;\n   (*lang_hooks.decls.pushdecl) (tdecl);\n \n+  if (TARGET_VSX)\n+    {\n+      tdecl = build_decl (BUILTINS_LOCATION,\n+\t\t\t  TYPE_DECL, get_identifier (\"__vector double\"),\n+\t\t\t  unsigned_V2DI_type_node);\n+      TYPE_NAME (V2DF_type_node) = tdecl;\n+      (*lang_hooks.decls.pushdecl) (tdecl);\n+\n+      tdecl = build_decl (BUILTINS_LOCATION,\n+\t\t\t  TYPE_DECL, get_identifier (\"__vector long\"),\n+\t\t\t  V2DI_type_node);\n+      TYPE_NAME (V2DI_type_node) = tdecl;\n+      (*lang_hooks.decls.pushdecl) (tdecl);\n+\n+      tdecl = build_decl (BUILTINS_LOCATION,\n+\t\t\t  TYPE_DECL, get_identifier (\"__vector unsigned long\"),\n+\t\t\t  unsigned_V2DI_type_node);\n+      TYPE_NAME (unsigned_V2DI_type_node) = tdecl;\n+      (*lang_hooks.decls.pushdecl) (tdecl);\n+\n+      tdecl = build_decl (BUILTINS_LOCATION,\n+\t\t\t  TYPE_DECL, get_identifier (\"__vector __bool long\"),\n+\t\t\t  bool_V2DI_type_node);\n+      TYPE_NAME (bool_V2DI_type_node) = tdecl;\n+      (*lang_hooks.decls.pushdecl) (tdecl);\n+    }\n+\n   if (TARGET_PAIRED_FLOAT)\n     paired_init_builtins ();\n   if (TARGET_SPE)\n@@ -10531,6 +11023,15 @@ rs6000_init_builtins (void)\n \t\t   RS6000_BUILTIN_RECIP);\n \n     }\n+  if (TARGET_POPCNTD)\n+    {\n+      enum machine_mode mode = (TARGET_64BIT) ? DImode : SImode;\n+      tree ftype = builtin_function_type (mode, mode, mode, VOIDmode,\n+\t\t\t\t\t  POWER7_BUILTIN_BPERMD,\n+\t\t\t\t\t  \"__builtin_bpermd\");\n+      def_builtin (MASK_POPCNTD, \"__builtin_bpermd\", ftype,\n+\t\t   POWER7_BUILTIN_BPERMD);\n+    }\n   if (TARGET_POWERPC)\n     {\n       /* Don't use builtin_function_type here, as it maps HI/QI to SI.  */\n@@ -10969,6 +11470,10 @@ altivec_init_builtins (void)\n     = build_function_type_list (integer_type_node,\n \t\t\t\tinteger_type_node, V4SF_type_node,\n \t\t\t\tV4SF_type_node, NULL_TREE);\n+  tree int_ftype_int_v2df_v2df\n+    = build_function_type_list (integer_type_node,\n+\t\t\t\tinteger_type_node, V2DF_type_node,\n+\t\t\t\tV2DF_type_node, NULL_TREE);\n   tree v4si_ftype_v4si\n     = build_function_type_list (V4SI_type_node, V4SI_type_node, NULL_TREE);\n   tree v8hi_ftype_v8hi\n@@ -10977,6 +11482,8 @@ altivec_init_builtins (void)\n     = build_function_type_list (V16QI_type_node, V16QI_type_node, NULL_TREE);\n   tree v4sf_ftype_v4sf\n     = build_function_type_list (V4SF_type_node, V4SF_type_node, NULL_TREE);\n+  tree v2df_ftype_v2df\n+    = build_function_type_list (V2DF_type_node, V2DF_type_node, NULL_TREE);\n   tree void_ftype_pcvoid_int_int\n     = build_function_type_list (void_type_node,\n \t\t\t\tpcvoid_type_node, integer_type_node,\n@@ -11079,8 +11586,10 @@ altivec_init_builtins (void)\n     {\n       enum machine_mode mode1;\n       tree type;\n-      bool is_overloaded = dp->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n-\t\t\t   && dp->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST;\n+      bool is_overloaded = ((dp->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n+\t\t\t     && dp->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+\t\t\t    || (dp->code >= VSX_BUILTIN_OVERLOADED_FIRST\n+\t\t\t\t&& dp->code <= VSX_BUILTIN_OVERLOADED_LAST));\n \n       if (is_overloaded)\n \tmode1 = VOIDmode;\n@@ -11104,6 +11613,9 @@ altivec_init_builtins (void)\n \tcase V4SFmode:\n \t  type = int_ftype_int_v4sf_v4sf;\n \t  break;\n+\tcase V2DFmode:\n+\t  type = int_ftype_int_v2df_v2df;\n+\t  break;\n \tdefault:\n \t  gcc_unreachable ();\n \t}\n@@ -11134,6 +11646,9 @@ altivec_init_builtins (void)\n \tcase V4SFmode:\n \t  type = v4sf_ftype_v4sf;\n \t  break;\n+\tcase V2DFmode:\n+\t  type = v2df_ftype_v2df;\n+\t  break;\n \tdefault:\n \t  gcc_unreachable ();\n \t}\n@@ -11193,6 +11708,19 @@ altivec_init_builtins (void)\n   def_builtin (MASK_ALTIVEC, \"__builtin_vec_init_v4sf\", ftype,\n \t       ALTIVEC_BUILTIN_VEC_INIT_V4SF);\n \n+  if (TARGET_VSX)\n+    {\n+      ftype = build_function_type_list (V2DF_type_node, double_type_node,\n+\t\t\t\t\tdouble_type_node, NULL_TREE);\n+      def_builtin (MASK_VSX, \"__builtin_vec_init_v2df\", ftype,\n+\t\t   VSX_BUILTIN_VEC_INIT_V2DF);\n+\n+      ftype = build_function_type_list (V2DI_type_node, intDI_type_node,\n+\t\t\t\t\tintDI_type_node, NULL_TREE);\n+      def_builtin (MASK_VSX, \"__builtin_vec_init_v2di\", ftype,\n+\t\t   VSX_BUILTIN_VEC_INIT_V2DI);\n+    }\n+\n   /* Access to the vec_set patterns.  */\n   ftype = build_function_type_list (V4SI_type_node, V4SI_type_node,\n \t\t\t\t    intSI_type_node,\n@@ -11218,6 +11746,21 @@ altivec_init_builtins (void)\n   def_builtin (MASK_ALTIVEC|MASK_VSX, \"__builtin_vec_set_v4sf\", ftype,\n \t       ALTIVEC_BUILTIN_VEC_SET_V4SF);\n \n+  if (TARGET_VSX)\n+    {\n+      ftype = build_function_type_list (V2DF_type_node, V2DF_type_node,\n+\t\t\t\t\tdouble_type_node,\n+\t\t\t\t\tinteger_type_node, NULL_TREE);\n+      def_builtin (MASK_VSX, \"__builtin_vec_set_v2df\", ftype,\n+\t\t   VSX_BUILTIN_VEC_SET_V2DF);\n+\n+      ftype = build_function_type_list (V2DI_type_node, V2DI_type_node,\n+\t\t\t\t\tintDI_type_node,\n+\t\t\t\t\tinteger_type_node, NULL_TREE);\n+      def_builtin (MASK_VSX, \"__builtin_vec_set_v2di\", ftype,\n+\t\t   VSX_BUILTIN_VEC_SET_V2DI);\n+    }\n+\n   /* Access to the vec_extract patterns.  */\n   ftype = build_function_type_list (intSI_type_node, V4SI_type_node,\n \t\t\t\t    integer_type_node, NULL_TREE);\n@@ -11238,6 +11781,19 @@ altivec_init_builtins (void)\n \t\t\t\t    integer_type_node, NULL_TREE);\n   def_builtin (MASK_ALTIVEC|MASK_VSX, \"__builtin_vec_ext_v4sf\", ftype,\n \t       ALTIVEC_BUILTIN_VEC_EXT_V4SF);\n+\n+  if (TARGET_VSX)\n+    {\n+      ftype = build_function_type_list (double_type_node, V2DF_type_node,\n+\t\t\t\t\tinteger_type_node, NULL_TREE);\n+      def_builtin (MASK_VSX, \"__builtin_vec_ext_v2df\", ftype,\n+\t\t   VSX_BUILTIN_VEC_EXT_V2DF);\n+\n+      ftype = build_function_type_list (intDI_type_node, V2DI_type_node,\n+\t\t\t\t\tinteger_type_node, NULL_TREE);\n+      def_builtin (MASK_VSX, \"__builtin_vec_ext_v2di\", ftype,\n+\t\t   VSX_BUILTIN_VEC_EXT_V2DI);\n+    }\n }\n \n /* Hash function for builtin functions with up to 3 arguments and a return\n@@ -11333,6 +11889,14 @@ builtin_function_type (enum machine_mode mode_ret, enum machine_mode mode_arg0,\n     case ALTIVEC_BUILTIN_VSEL_8HI_UNS:\n     case ALTIVEC_BUILTIN_VSEL_4SI_UNS:\n     case ALTIVEC_BUILTIN_VSEL_2DI_UNS:\n+    case VSX_BUILTIN_VPERM_16QI_UNS:\n+    case VSX_BUILTIN_VPERM_8HI_UNS:\n+    case VSX_BUILTIN_VPERM_4SI_UNS:\n+    case VSX_BUILTIN_VPERM_2DI_UNS:\n+    case VSX_BUILTIN_XXSEL_16QI_UNS:\n+    case VSX_BUILTIN_XXSEL_8HI_UNS:\n+    case VSX_BUILTIN_XXSEL_4SI_UNS:\n+    case VSX_BUILTIN_XXSEL_2DI_UNS:\n       h.uns_p[0] = 1;\n       h.uns_p[1] = 1;\n       h.uns_p[2] = 1;\n@@ -11346,6 +11910,12 @@ builtin_function_type (enum machine_mode mode_ret, enum machine_mode mode_arg0,\n     case ALTIVEC_BUILTIN_VPERM_4SF:\n     case ALTIVEC_BUILTIN_VPERM_2DI:\n     case ALTIVEC_BUILTIN_VPERM_2DF:\n+    case VSX_BUILTIN_VPERM_16QI:\n+    case VSX_BUILTIN_VPERM_8HI:\n+    case VSX_BUILTIN_VPERM_4SI:\n+    case VSX_BUILTIN_VPERM_4SF:\n+    case VSX_BUILTIN_VPERM_2DI:\n+    case VSX_BUILTIN_VPERM_2DF:\n       h.uns_p[3] = 1;\n       break;\n \n@@ -11442,8 +12012,10 @@ rs6000_common_init_builtins (void)\n \t  || (mask == 0 && !TARGET_PAIRED_FLOAT))\n \tcontinue;\n \n-      if (d->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n-\t  && d->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+      if ((d->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n+\t   && d->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+\t  || (d->code >= VSX_BUILTIN_OVERLOADED_FIRST\n+\t      && d->code <= VSX_BUILTIN_OVERLOADED_LAST))\n \t{\n \t  if (! (type = opaque_ftype_opaque_opaque_opaque))\n \t    type = opaque_ftype_opaque_opaque_opaque\n@@ -11481,8 +12053,10 @@ rs6000_common_init_builtins (void)\n \t  || (mask == 0 && !TARGET_PAIRED_FLOAT))\n \tcontinue;\n \n-      if (d->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n-\t  && d->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+      if ((d->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n+\t   && d->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+\t  || (d->code >= VSX_BUILTIN_OVERLOADED_FIRST\n+\t      && d->code <= VSX_BUILTIN_OVERLOADED_LAST))\n \t{\n \t  if (! (type = opaque_ftype_opaque_opaque))\n \t    type = opaque_ftype_opaque_opaque\n@@ -11537,14 +12111,15 @@ rs6000_common_init_builtins (void)\n       enum machine_mode mode0, mode1;\n       tree type;\n       int mask = d->mask;\n-      bool is_overloaded = d->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n-\t\t\t   && d->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST;\n \n       if ((mask != 0 && (mask & target_flags) == 0)\n \t  || (mask == 0 && !TARGET_PAIRED_FLOAT))\n \tcontinue;\n \n-      if (is_overloaded)\n+      if ((d->code >= ALTIVEC_BUILTIN_OVERLOADED_FIRST\n+\t   && d->code <= ALTIVEC_BUILTIN_OVERLOADED_LAST)\n+\t  || (d->code >= VSX_BUILTIN_OVERLOADED_FIRST\n+\t      && d->code <= VSX_BUILTIN_OVERLOADED_LAST))\n \t{\n \t  if (! (type = opaque_ftype_opaque))\n \t    type = opaque_ftype_opaque\n@@ -22228,18 +22803,24 @@ rs6000_handle_altivec_attribute (tree *node,\n   mode = TYPE_MODE (type);\n \n   /* Check for invalid AltiVec type qualifiers.  */\n-  if (type == long_unsigned_type_node || type == long_integer_type_node)\n-    {\n-    if (TARGET_64BIT)\n-      error (\"use of %<long%> in AltiVec types is invalid for 64-bit code\");\n-    else if (rs6000_warn_altivec_long)\n-      warning (0, \"use of %<long%> in AltiVec types is deprecated; use %<int%>\");\n-    }\n-  else if (type == long_long_unsigned_type_node\n-           || type == long_long_integer_type_node)\n-    error (\"use of %<long long%> in AltiVec types is invalid\");\n-  else if (type == double_type_node)\n-    error (\"use of %<double%> in AltiVec types is invalid\");\n+  if (!TARGET_VSX)\n+    {\n+      if (type == long_unsigned_type_node || type == long_integer_type_node)\n+\t{\n+\t  if (TARGET_64BIT)\n+\t    error (\"use of %<long%> in AltiVec types is invalid for \"\n+\t\t   \"64-bit code without -mvsx\");\n+\t  else if (rs6000_warn_altivec_long)\n+\t    warning (0, \"use of %<long%> in AltiVec types is deprecated; \"\n+\t\t     \"use %<int%>\");\n+\t}\n+      else if (type == long_long_unsigned_type_node\n+\t       || type == long_long_integer_type_node)\n+\terror (\"use of %<long long%> in AltiVec types is invalid without \"\n+\t       \"-mvsx\");\n+      else if (type == double_type_node)\n+\terror (\"use of %<double%> in AltiVec types is invalid without -mvsx\");\n+    }\n   else if (type == long_double_type_node)\n     error (\"use of %<long double%> in AltiVec types is invalid\");\n   else if (type == boolean_type_node)\n@@ -22255,6 +22836,9 @@ rs6000_handle_altivec_attribute (tree *node,\n       unsigned_p = TYPE_UNSIGNED (type);\n       switch (mode)\n \t{\n+\tcase DImode:\n+\t  result = (unsigned_p ? unsigned_V2DI_type_node : V2DI_type_node);\n+\t  break;\n \tcase SImode:\n \t  result = (unsigned_p ? unsigned_V4SI_type_node : V4SI_type_node);\n \t  break;\n@@ -22265,17 +22849,20 @@ rs6000_handle_altivec_attribute (tree *node,\n \t  result = (unsigned_p ? unsigned_V16QI_type_node : V16QI_type_node);\n \t  break;\n \tcase SFmode: result = V4SF_type_node; break;\n+\tcase DFmode: result = V2DF_type_node; break;\n \t  /* If the user says 'vector int bool', we may be handed the 'bool'\n \t     attribute _before_ the 'vector' attribute, and so select the\n \t     proper type in the 'b' case below.  */\n \tcase V4SImode: case V8HImode: case V16QImode: case V4SFmode:\n+\tcase V2DImode: case V2DFmode:\n \t  result = type;\n \tdefault: break;\n \t}\n       break;\n     case 'b':\n       switch (mode)\n \t{\n+\tcase DImode: case V2DImode: result = bool_V2DI_type_node; break;\n \tcase SImode: case V4SImode: result = bool_V4SI_type_node; break;\n \tcase HImode: case V8HImode: result = bool_V8HI_type_node; break;\n \tcase QImode: case V16QImode: result = bool_V16QI_type_node;\n@@ -22320,6 +22907,7 @@ rs6000_mangle_type (const_tree type)\n   if (type == bool_short_type_node) return \"U6__bools\";\n   if (type == pixel_type_node) return \"u7__pixel\";\n   if (type == bool_int_type_node) return \"U6__booli\";\n+  if (type == bool_long_type_node) return \"U6__booll\";\n \n   /* Mangle IBM extended float long double as `g' (__float128) on\n      powerpc*-linux where long-double-64 previously was the default.  */\n@@ -24557,7 +25145,7 @@ rs6000_vector_mode_supported_p (enum machine_mode mode)\n   if (TARGET_SPE && SPE_VECTOR_MODE (mode))\n     return true;\n \n-  else if (VECTOR_UNIT_ALTIVEC_OR_VSX_P (mode))\n+  else if (VECTOR_MEM_ALTIVEC_OR_VSX_P (mode))\n     return true;\n \n   else"}, {"sha": "0c5e59333aba251b56d121d0717a35f2c6d6c7e5", "filename": "gcc/config/rs6000/rs6000.h", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.h?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -1883,6 +1883,10 @@ typedef struct rs6000_args\n \t\t\t\t    && EASY_VECTOR_15((n) >> 1) \\\n \t\t\t\t    && ((n) & 1) == 0)\n \n+#define EASY_VECTOR_MSB(n,mode)\t\t\t\t\t\t\\\n+  (((unsigned HOST_WIDE_INT)n) ==\t\t\t\t\t\\\n+   ((((unsigned HOST_WIDE_INT)GET_MODE_MASK (mode)) + 1) >> 1))\n+\n \f\n /* Try a machine-dependent way of reloading an illegitimate address\n    operand.  If we find one, push the reload and jump to WIN.  This\n@@ -2678,6 +2682,7 @@ enum rs6000_builtins\n   ALTIVEC_BUILTIN_VEC_EXT_V8HI,\n   ALTIVEC_BUILTIN_VEC_EXT_V16QI,\n   ALTIVEC_BUILTIN_VEC_EXT_V4SF,\n+  ALTIVEC_BUILTIN_COPYSIGN_V4SF,\n \n   /* Altivec overloaded builtins.  */\n   ALTIVEC_BUILTIN_VCMPEQ_P,\n@@ -2703,6 +2708,7 @@ enum rs6000_builtins\n   ALTIVEC_BUILTIN_VEC_CMPGT,\n   ALTIVEC_BUILTIN_VEC_CMPLE,\n   ALTIVEC_BUILTIN_VEC_CMPLT,\n+  ALTIVEC_BUILTIN_VEC_COPYSIGN,\n   ALTIVEC_BUILTIN_VEC_CTF,\n   ALTIVEC_BUILTIN_VEC_CTS,\n   ALTIVEC_BUILTIN_VEC_CTU,\n@@ -2745,6 +2751,7 @@ enum rs6000_builtins\n   ALTIVEC_BUILTIN_VEC_MTVSCR,\n   ALTIVEC_BUILTIN_VEC_MULE,\n   ALTIVEC_BUILTIN_VEC_MULO,\n+  ALTIVEC_BUILTIN_VEC_NEARBYINT,\n   ALTIVEC_BUILTIN_VEC_NMSUB,\n   ALTIVEC_BUILTIN_VEC_NOR,\n   ALTIVEC_BUILTIN_VEC_OR,\n@@ -2755,6 +2762,7 @@ enum rs6000_builtins\n   ALTIVEC_BUILTIN_VEC_PERM,\n   ALTIVEC_BUILTIN_VEC_RE,\n   ALTIVEC_BUILTIN_VEC_RL,\n+  ALTIVEC_BUILTIN_VEC_RINT,\n   ALTIVEC_BUILTIN_VEC_ROUND,\n   ALTIVEC_BUILTIN_VEC_RSQRTE,\n   ALTIVEC_BUILTIN_VEC_SEL,\n@@ -2772,6 +2780,7 @@ enum rs6000_builtins\n   ALTIVEC_BUILTIN_VEC_SPLTB,\n   ALTIVEC_BUILTIN_VEC_SPLTH,\n   ALTIVEC_BUILTIN_VEC_SPLTW,\n+  ALTIVEC_BUILTIN_VEC_SQRT,\n   ALTIVEC_BUILTIN_VEC_SR,\n   ALTIVEC_BUILTIN_VEC_SRA,\n   ALTIVEC_BUILTIN_VEC_SRL,\n@@ -3228,6 +3237,8 @@ enum rs6000_builtins\n   VSX_BUILTIN_XSRSQRTEDP,\n   VSX_BUILTIN_XSSQRTDP,\n   VSX_BUILTIN_XSSUBDP,\n+  VSX_BUILTIN_CPSGNDP,\n+  VSX_BUILTIN_CPSGNSP,\n   VSX_BUILTIN_XSTDIVDP_FE,\n   VSX_BUILTIN_XSTDIVDP_FG,\n   VSX_BUILTIN_XSTSQRTDP_FE,"}, {"sha": "9524fe81f13a3ad3aa85fd7d36f14567ee8e7e77", "filename": "gcc/config/rs6000/rs6000.md", "status": "modified", "additions": 177, "deletions": 56, "changes": 233, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.md?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -101,6 +101,7 @@\n    (UNSPEC_RSQRT\t\t48)\n    (UNSPEC_TOCREL\t\t49)\n    (UNSPEC_MACHOPIC_OFFSET\t50)\n+   (UNSPEC_BPERM\t\t51)\n   ])\n \n ;;\n@@ -167,6 +168,7 @@\n (include \"power4.md\")\n (include \"power5.md\")\n (include \"power6.md\")\n+(include \"power7.md\")\n (include \"cell.md\")\n (include \"xfpu.md\")\n \n@@ -5900,9 +5902,18 @@\n \t                     (match_dup 5))\n \t\t\t (match_dup 3)\n \t\t\t (match_dup 4)))]\n-  \"TARGET_PPC_GFXOPT && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n-   && !HONOR_NANS (DFmode) && !HONOR_SIGNED_ZEROS (DFmode)\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && ((TARGET_PPC_GFXOPT\n+        && !HONOR_NANS (DFmode)\n+        && !HONOR_SIGNED_ZEROS (DFmode))\n+       || VECTOR_UNIT_VSX_P (DFmode))\"\n   {\n+     if (VECTOR_UNIT_VSX_P (DFmode))\n+       {\n+\t emit_insn (gen_vsx_copysigndf3 (operands[0], operands[1],\n+\t\t\t\t\t operands[2], CONST0_RTX (DFmode)));\n+\t DONE;\n+       }\n      operands[3] = gen_reg_rtx (DFmode);\n      operands[4] = gen_reg_rtx (DFmode);\n      operands[5] = CONST0_RTX (DFmode);\n@@ -6037,7 +6048,8 @@\n (define_insn \"*negdf2_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(neg:DF (match_operand:DF 1 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fneg %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n@@ -6050,14 +6062,16 @@\n (define_insn \"*absdf2_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(abs:DF (match_operand:DF 1 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fabs %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n (define_insn \"*nabsdf2_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(neg:DF (abs:DF (match_operand:DF 1 \"gpc_reg_operand\" \"d\"))))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fnabs %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n@@ -6072,7 +6086,8 @@\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(plus:DF (match_operand:DF 1 \"gpc_reg_operand\" \"%d\")\n \t\t (match_operand:DF 2 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"{fa|fadd} %0,%1,%2\"\n   [(set_attr \"type\" \"fp\")\n    (set_attr \"fp_type\" \"fp_addsub_d\")])\n@@ -6088,7 +6103,8 @@\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(minus:DF (match_operand:DF 1 \"gpc_reg_operand\" \"d\")\n \t\t  (match_operand:DF 2 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"{fs|fsub} %0,%1,%2\"\n   [(set_attr \"type\" \"fp\")\n    (set_attr \"fp_type\" \"fp_addsub_d\")])\n@@ -6104,7 +6120,8 @@\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(mult:DF (match_operand:DF 1 \"gpc_reg_operand\" \"%d\")\n \t\t (match_operand:DF 2 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"{fm|fmul} %0,%1,%2\"\n   [(set_attr \"type\" \"dmul\")\n    (set_attr \"fp_type\" \"fp_mul_d\")])\n@@ -6122,7 +6139,8 @@\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(div:DF (match_operand:DF 1 \"gpc_reg_operand\" \"d\")\n \t\t(match_operand:DF 2 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT && !TARGET_SIMPLE_FPU\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT && !TARGET_SIMPLE_FPU\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"{fd|fdiv} %0,%1,%2\"\n   [(set_attr \"type\" \"ddiv\")])\n \n@@ -6138,73 +6156,81 @@\n    DONE;\n })\n \n-(define_insn \"fred\"\n+(define_expand \"fred\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"d\")] UNSPEC_FRES))]\n-  \"TARGET_POPCNTB && flag_finite_math_only\"\n+  \"(TARGET_POPCNTB || VECTOR_UNIT_VSX_P (DFmode)) && flag_finite_math_only\"\n+  \"\")\n+\n+(define_insn \"*fred_fpr\"\n+  [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=f\")\n+\t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"f\")] UNSPEC_FRES))]\n+  \"TARGET_POPCNTB && flag_finite_math_only && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fre %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n-(define_insn \"\"\n+(define_insn \"*fmadddf4_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(plus:DF (mult:DF (match_operand:DF 1 \"gpc_reg_operand\" \"%d\")\n \t\t\t  (match_operand:DF 2 \"gpc_reg_operand\" \"d\"))\n \t\t (match_operand:DF 3 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\n+   && VECTOR_UNIT_NONE_P (DFmode)\"\n   \"{fma|fmadd} %0,%1,%2,%3\"\n   [(set_attr \"type\" \"dmul\")\n    (set_attr \"fp_type\" \"fp_maddsub_d\")])\n \n-(define_insn \"\"\n+(define_insn \"*fmsubdf4_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(minus:DF (mult:DF (match_operand:DF 1 \"gpc_reg_operand\" \"%d\")\n \t\t\t   (match_operand:DF 2 \"gpc_reg_operand\" \"d\"))\n \t\t  (match_operand:DF 3 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\n+   && VECTOR_UNIT_NONE_P (DFmode)\"\n   \"{fms|fmsub} %0,%1,%2,%3\"\n   [(set_attr \"type\" \"dmul\")\n    (set_attr \"fp_type\" \"fp_maddsub_d\")])\n \n-(define_insn \"\"\n+(define_insn \"*fnmadddf4_fpr_1\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(neg:DF (plus:DF (mult:DF (match_operand:DF 1 \"gpc_reg_operand\" \"%d\")\n \t\t\t\t  (match_operand:DF 2 \"gpc_reg_operand\" \"d\"))\n \t\t\t (match_operand:DF 3 \"gpc_reg_operand\" \"d\"))))]\n   \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\n-   && HONOR_SIGNED_ZEROS (DFmode)\"\n+   && HONOR_SIGNED_ZEROS (DFmode) && VECTOR_UNIT_NONE_P (DFmode)\"\n   \"{fnma|fnmadd} %0,%1,%2,%3\"\n   [(set_attr \"type\" \"dmul\")\n    (set_attr \"fp_type\" \"fp_maddsub_d\")])\n \n-(define_insn \"\"\n+(define_insn \"*fnmadddf4_fpr_2\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(minus:DF (mult:DF (neg:DF (match_operand:DF 1 \"gpc_reg_operand\" \"d\"))\n \t\t\t   (match_operand:DF 2 \"gpc_reg_operand\" \"d\"))\n \t\t  (match_operand:DF 3 \"gpc_reg_operand\" \"d\")))]\n   \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\n-   && ! HONOR_SIGNED_ZEROS (DFmode)\"\n+   && ! HONOR_SIGNED_ZEROS (DFmode) && VECTOR_UNIT_NONE_P (DFmode)\"\n   \"{fnma|fnmadd} %0,%1,%2,%3\"\n   [(set_attr \"type\" \"dmul\")\n    (set_attr \"fp_type\" \"fp_maddsub_d\")])\n \n-(define_insn \"\"\n+(define_insn \"*fnmsubdf4_fpr_1\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(neg:DF (minus:DF (mult:DF (match_operand:DF 1 \"gpc_reg_operand\" \"%d\")\n \t\t\t\t   (match_operand:DF 2 \"gpc_reg_operand\" \"d\"))\n \t\t\t  (match_operand:DF 3 \"gpc_reg_operand\" \"d\"))))]\n   \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\n-   && HONOR_SIGNED_ZEROS (DFmode)\"\n+   && HONOR_SIGNED_ZEROS (DFmode) && VECTOR_UNIT_NONE_P (DFmode)\"\n   \"{fnms|fnmsub} %0,%1,%2,%3\"\n   [(set_attr \"type\" \"dmul\")\n    (set_attr \"fp_type\" \"fp_maddsub_d\")])\n \n-(define_insn \"\"\n+(define_insn \"*fnmsubdf4_fpr_2\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(minus:DF (match_operand:DF 3 \"gpc_reg_operand\" \"d\")\n \t          (mult:DF (match_operand:DF 1 \"gpc_reg_operand\" \"%d\")\n \t\t\t   (match_operand:DF 2 \"gpc_reg_operand\" \"d\"))))]\n   \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_FUSED_MADD && TARGET_DOUBLE_FLOAT\n-   && ! HONOR_SIGNED_ZEROS (DFmode)\"\n+   && ! HONOR_SIGNED_ZEROS (DFmode) && VECTOR_UNIT_NONE_P (DFmode)\"\n   \"{fnms|fnmsub} %0,%1,%2,%3\"\n   [(set_attr \"type\" \"dmul\")\n    (set_attr \"fp_type\" \"fp_maddsub_d\")])\n@@ -6213,7 +6239,8 @@\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(sqrt:DF (match_operand:DF 1 \"gpc_reg_operand\" \"d\")))]\n   \"(TARGET_PPC_GPOPT || TARGET_POWER2) && TARGET_HARD_FLOAT && TARGET_FPRS \n-   && TARGET_DOUBLE_FLOAT\"\n+   && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fsqrt %0,%1\"\n   [(set_attr \"type\" \"dsqrt\")])\n \n@@ -6308,6 +6335,12 @@\n   \"TARGET_HARD_FLOAT && TARGET_E500_DOUBLE\"\n   \"\")\n \n+(define_expand \"fixuns_truncdfdi2\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"\")\n+\t(unsigned_fix:DI (match_operand:DF 1 \"register_operand\" \"\")))]\n+  \"TARGET_HARD_FLOAT && TARGET_VSX\"\n+  \"\")\n+\n ; For each of these conversions, there is a define_expand, a define_insn\n ; with a '#' template, and a define_split (with C code).  The idea is\n ; to allow constant folding with the template of the define_insn,\n@@ -6549,24 +6582,38 @@\n   \"{fcirz|fctiwz} %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n-(define_insn \"btruncdf2\"\n+(define_expand \"btruncdf2\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"d\")] UNSPEC_FRIZ))]\n   \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"\")\n+\n+(define_insn \"*btruncdf2_fpr\"\n+  [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=f\")\n+\t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"f\")] UNSPEC_FRIZ))]\n+  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"friz %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n (define_insn \"btruncsf2\"\n   [(set (match_operand:SF 0 \"gpc_reg_operand\" \"=f\")\n \t(unspec:SF [(match_operand:SF 1 \"gpc_reg_operand\" \"f\")] UNSPEC_FRIZ))]\n-  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_SINGLE_FLOAT \"\n+  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_SINGLE_FLOAT\"\n   \"friz %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n-(define_insn \"ceildf2\"\n+(define_expand \"ceildf2\"\n+  [(set (match_operand:DF 0 \"gpc_reg_operand\" \"\")\n+\t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"\")] UNSPEC_FRIP))]\n+  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"\")\n+\n+(define_insn \"*ceildf2_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"d\")] UNSPEC_FRIP))]\n-  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"frip %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n@@ -6577,10 +6624,17 @@\n   \"frip %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n-(define_insn \"floordf2\"\n+(define_expand \"floordf2\"\n+  [(set (match_operand:DF 0 \"gpc_reg_operand\" \"\")\n+\t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"\")] UNSPEC_FRIM))]\n+  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"\")\n+\n+(define_insn \"*floordf2_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"d\")] UNSPEC_FRIM))]\n-  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_FPRND && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"frim %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n@@ -6591,6 +6645,7 @@\n   \"frim %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n+;; No VSX equivalent to frin\n (define_insn \"rounddf2\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(unspec:DF [(match_operand:DF 1 \"gpc_reg_operand\" \"d\")] UNSPEC_FRIN))]\n@@ -6605,6 +6660,12 @@\n   \"frin %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n+(define_expand \"ftruncdf2\"\n+  [(set (match_operand:DF 0 \"gpc_reg_operand\" \"\")\n+  \t(fix:DF (match_operand:DF 1 \"gpc_reg_operand\" \"\")))]\n+  \"VECTOR_UNIT_VSX_P (DFmode)\"\n+  \"\")\n+\n ; An UNSPEC is used so we don't have to support SImode in FP registers.\n (define_insn \"stfiwx\"\n   [(set (match_operand:SI 0 \"memory_operand\" \"=Z\")\n@@ -6620,17 +6681,40 @@\n   \"TARGET_HARD_FLOAT && !TARGET_FPRS\"\n   \"\")\n \n-(define_insn \"floatdidf2\"\n+(define_expand \"floatdidf2\"\n+  [(set (match_operand:DF 0 \"gpc_reg_operand\" \"\")\n+\t(float:DF (match_operand:DI 1 \"gpc_reg_operand\" \"\")))]\n+  \"(TARGET_POWERPC64 || TARGET_XILINX_FPU || VECTOR_UNIT_VSX_P (DFmode))\n+   && TARGET_HARD_FLOAT && TARGET_DOUBLE_FLOAT && TARGET_FPRS\"\n+  \"\")\n+\n+(define_insn \"*floatdidf2_fpr\"\n   [(set (match_operand:DF 0 \"gpc_reg_operand\" \"=d\")\n \t(float:DF (match_operand:DI 1 \"gpc_reg_operand\" \"!d#r\")))]\n-  \"(TARGET_POWERPC64 || TARGET_XILINX_FPU) && TARGET_HARD_FLOAT && TARGET_DOUBLE_FLOAT && TARGET_FPRS\"\n+  \"(TARGET_POWERPC64 || TARGET_XILINX_FPU)\n+   && TARGET_HARD_FLOAT && TARGET_DOUBLE_FLOAT && TARGET_FPRS\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fcfid %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n-(define_insn \"fix_truncdfdi2\"\n+(define_expand \"floatunsdidf2\"\n+  [(set (match_operand:DF 0 \"gpc_reg_operand\" \"\")\n+\t(unsigned_float:DF (match_operand:DI 1 \"gpc_reg_operand\" \"\")))]\n+  \"TARGET_VSX\"\n+  \"\")\n+\n+(define_expand \"fix_truncdfdi2\"\n+  [(set (match_operand:DI 0 \"gpc_reg_operand\" \"\")\n+\t(fix:DI (match_operand:DF 1 \"gpc_reg_operand\" \"\")))]\n+  \"(TARGET_POWERPC64 || TARGET_XILINX_FPU || VECTOR_UNIT_VSX_P (DFmode))\n+    && TARGET_HARD_FLOAT && TARGET_DOUBLE_FLOAT && TARGET_FPRS\"\n+  \"\")\n+\n+(define_insn \"*fix_truncdfdi2_fpr\"\n   [(set (match_operand:DI 0 \"gpc_reg_operand\" \"=!d#r\")\n \t(fix:DI (match_operand:DF 1 \"gpc_reg_operand\" \"d\")))]\n-  \"(TARGET_POWERPC64 || TARGET_XILINX_FPU) && TARGET_HARD_FLOAT && TARGET_DOUBLE_FLOAT && TARGET_FPRS\"\n+  \"(TARGET_POWERPC64 || TARGET_XILINX_FPU) && TARGET_HARD_FLOAT\n+    && TARGET_DOUBLE_FLOAT && TARGET_FPRS && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fctidz %0,%1\"\n   [(set_attr \"type\" \"fp\")])\n \n@@ -8956,8 +9040,8 @@\n ;; The \"??\" is a kludge until we can figure out a more reasonable way\n ;; of handling these non-offsettable values.\n (define_insn \"*movdf_hardfloat32\"\n-  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=!r,??r,m,d,d,m,!r,!r,!r\")\n-\t(match_operand:DF 1 \"input_operand\" \"r,m,r,d,m,d,G,H,F\"))]\n+  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=!r,??r,m,ws,?wa,ws,?wa,Z,?Z,d,d,m,wa,!r,!r,!r\")\n+\t(match_operand:DF 1 \"input_operand\" \"r,m,r,ws,wa,Z,Z,ws,wa,d,m,d,j,G,H,F\"))]\n   \"! TARGET_POWERPC64 && TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT \n    && (gpc_reg_operand (operands[0], DFmode)\n        || gpc_reg_operand (operands[1], DFmode))\"\n@@ -9036,19 +9120,30 @@\n \t  return \\\"\\\";\n \t}\n     case 3:\n-      return \\\"fmr %0,%1\\\";\n     case 4:\n-      return \\\"lfd%U1%X1 %0,%1\\\";\n+      return \\\"xxlor %x0,%x1,%x1\\\";\n     case 5:\n-      return \\\"stfd%U0%X0 %1,%0\\\";\n     case 6:\n+      return \\\"lxsd%U1x %x0,%y1\\\";\n     case 7:\n     case 8:\n+      return \\\"stxsd%U0x %x1,%y0\\\";\n+    case 9:\n+      return \\\"fmr %0,%1\\\";\n+    case 10:\n+      return \\\"lfd%U1%X1 %0,%1\\\";\n+    case 11:\n+      return \\\"stfd%U0%X0 %1,%0\\\";\n+    case 12:\n+      return \\\"xxlxor %x0,%x0,%x0\\\";\n+    case 13:\n+    case 14:\n+    case 15:\n       return \\\"#\\\";\n     }\n }\"\n-  [(set_attr \"type\" \"two,load,store,fp,fpload,fpstore,*,*,*\")\n-   (set_attr \"length\" \"8,16,16,4,4,4,8,12,16\")])\n+  [(set_attr \"type\" \"two,load,store,fp,fp,fpload,fpload,fpstore,fpstore,fp,fpload,fpstore,vecsimple,*,*,*\")\n+   (set_attr \"length\" \"8,16,16,4,4,4,4,4,4,4,4,4,4,8,12,16\")])\n \n (define_insn \"*movdf_softfloat32\"\n   [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=r,r,m,r,r,r\")\n@@ -9096,19 +9191,26 @@\n ; ld/std require word-aligned displacements -> 'Y' constraint.\n ; List Y->r and r->Y before r->r for reload.\n (define_insn \"*movdf_hardfloat64_mfpgpr\"\n-  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=Y,r,!r,d,d,m,*c*l,!r,*h,!r,!r,!r,r,d\")\n-\t(match_operand:DF 1 \"input_operand\" \"r,Y,r,d,m,d,r,h,0,G,H,F,d,r\"))]\n+  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=Y,r,!r,ws,?wa,ws,?wa,Z,?Z,d,d,m,wa,*c*l,!r,*h,!r,!r,!r,r,d\")\n+\t(match_operand:DF 1 \"input_operand\" \"r,Y,r,ws,?wa,Z,Z,ws,wa,d,m,d,j,r,h,0,G,H,F,d,r\"))]\n   \"TARGET_POWERPC64 && TARGET_MFPGPR && TARGET_HARD_FLOAT && TARGET_FPRS \n-   && TARGET_DOUBLE_FLOAT \n+   && TARGET_DOUBLE_FLOAT\n    && (gpc_reg_operand (operands[0], DFmode)\n        || gpc_reg_operand (operands[1], DFmode))\"\n   \"@\n    std%U0%X0 %1,%0\n    ld%U1%X1 %0,%1\n    mr %0,%1\n+   xxlor %x0,%x1,%x1\n+   xxlor %x0,%x1,%x1\n+   lxsd%U1x %x0,%y1\n+   lxsd%U1x %x0,%y1\n+   stxsd%U0x %x1,%y0\n+   stxsd%U0x %x1,%y0\n    fmr %0,%1\n    lfd%U1%X1 %0,%1\n    stfd%U0%X0 %1,%0\n+   xxlxor %x0,%x0,%x0\n    mt%0 %1\n    mf%1 %0\n    {cror 0,0,0|nop}\n@@ -9117,33 +9219,40 @@\n    #\n    mftgpr %0,%1\n    mffgpr %0,%1\"\n-  [(set_attr \"type\" \"store,load,*,fp,fpload,fpstore,mtjmpr,mfjmpr,*,*,*,*,mftgpr,mffgpr\")\n-   (set_attr \"length\" \"4,4,4,4,4,4,4,4,4,8,12,16,4,4\")])\n+  [(set_attr \"type\" \"store,load,*,fp,fp,fpload,fpload,fpstore,fpstore,fp,fpload,fpstore,vecsimple,mtjmpr,mfjmpr,*,*,*,*,mftgpr,mffgpr\")\n+   (set_attr \"length\" \"4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,8,12,16,4,4\")])\n \n ; ld/std require word-aligned displacements -> 'Y' constraint.\n ; List Y->r and r->Y before r->r for reload.\n (define_insn \"*movdf_hardfloat64\"\n-  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=Y,r,!r,d,d,m,*c*l,!r,*h,!r,!r,!r\")\n-\t(match_operand:DF 1 \"input_operand\" \"r,Y,r,d,m,d,r,h,0,G,H,F\"))]\n+  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=Y,r,!r,ws,?wa,ws,?wa,Z,?Z,d,d,m,wa,*c*l,!r,*h,!r,!r,!r\")\n+\t(match_operand:DF 1 \"input_operand\" \"r,Y,r,ws,wa,Z,Z,ws,wa,d,m,d,j,r,h,0,G,H,F\"))]\n   \"TARGET_POWERPC64 && !TARGET_MFPGPR && TARGET_HARD_FLOAT && TARGET_FPRS \n-   && TARGET_DOUBLE_FLOAT \n+   && TARGET_DOUBLE_FLOAT\n    && (gpc_reg_operand (operands[0], DFmode)\n        || gpc_reg_operand (operands[1], DFmode))\"\n   \"@\n    std%U0%X0 %1,%0\n    ld%U1%X1 %0,%1\n    mr %0,%1\n+   xxlor %x0,%x1,%x1\n+   xxlor %x0,%x1,%x1\n+   lxsd%U1x %x0,%y1\n+   lxsd%U1x %x0,%y1\n+   stxsd%U0x %x1,%y0\n+   stxsd%U0x %x1,%y0\n    fmr %0,%1\n    lfd%U1%X1 %0,%1\n    stfd%U0%X0 %1,%0\n+   xxlxor %x0,%x0,%x0\n    mt%0 %1\n    mf%1 %0\n    {cror 0,0,0|nop}\n    #\n    #\n    #\"\n-  [(set_attr \"type\" \"store,load,*,fp,fpload,fpstore,mtjmpr,mfjmpr,*,*,*,*\")\n-   (set_attr \"length\" \"4,4,4,4,4,4,4,4,4,8,12,16\")])\n+  [(set_attr \"type\" \"store,load,*,fp,fp,fpload,fpload,fpstore,fpstore,fp,fpload,fpstore,vecsimple,mtjmpr,mfjmpr,*,*,*,*\")\n+   (set_attr \"length\" \"4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,8,12,16\")])\n \n (define_insn \"*movdf_softfloat64\"\n   [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=r,Y,r,cl,r,r,r,r,*h\")\n@@ -9720,15 +9829,16 @@\n (define_insn \"*movti_ppc64\"\n   [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=r,o<>,r\")\n \t(match_operand:TI 1 \"input_operand\" \"r,r,m\"))]\n-  \"TARGET_POWERPC64 && (gpc_reg_operand (operands[0], TImode)\n-   || gpc_reg_operand (operands[1], TImode))\"\n+  \"(TARGET_POWERPC64 && (gpc_reg_operand (operands[0], TImode)\n+    || gpc_reg_operand (operands[1], TImode)))\n+   && VECTOR_MEM_NONE_P (TImode)\"\n   \"#\"\n   [(set_attr \"type\" \"*,store,load\")])\n \n (define_split\n   [(set (match_operand:TI 0 \"gpc_reg_operand\" \"\")\n \t(match_operand:TI 1 \"const_double_operand\" \"\"))]\n-  \"TARGET_POWERPC64\"\n+  \"TARGET_POWERPC64 && VECTOR_MEM_NONE_P (TImode)\"\n   [(set (match_dup 2) (match_dup 4))\n    (set (match_dup 3) (match_dup 5))]\n   \"\n@@ -9754,7 +9864,7 @@\n (define_split\n   [(set (match_operand:TI 0 \"nonimmediate_operand\" \"\")\n         (match_operand:TI 1 \"input_operand\" \"\"))]\n-  \"reload_completed\n+  \"reload_completed && VECTOR_MEM_NONE_P (TImode)\n    && gpr_or_gpr_p (operands[0], operands[1])\"\n   [(pc)]\n { rs6000_split_multireg_move (operands[0], operands[1]); DONE; })\n@@ -12647,7 +12757,8 @@\n   [(set (match_operand:CCFP 0 \"cc_reg_operand\" \"=y\")\n \t(compare:CCFP (match_operand:DF 1 \"gpc_reg_operand\" \"d\")\n \t\t      (match_operand:DF 2 \"gpc_reg_operand\" \"d\")))]\n-  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\"\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && !VECTOR_UNIT_VSX_P (DFmode)\"\n   \"fcmpu %0,%1,%2\"\n   [(set_attr \"type\" \"fpcompare\")])\n \n@@ -15320,9 +15431,19 @@\n }\"\n   [(set_attr \"type\" \"load\")])\n \f\n+(define_insn \"bpermd_<mode>\"\n+  [(set (match_operand:P 0 \"gpc_reg_operand\" \"=r\")\n+\t(unspec:P [(match_operand:P 1 \"gpc_reg_operand\" \"r\")\n+\t\t   (match_operand:P 2 \"gpc_reg_operand\" \"r\")] UNSPEC_BPERM))]\n+  \"TARGET_POPCNTD\"\n+  \"bpermd %0,%1,%2\"\n+  [(set_attr \"type\" \"integer\")])\n+\n+\f\n \n (include \"sync.md\")\n (include \"vector.md\")\n+(include \"vsx.md\")\n (include \"altivec.md\")\n (include \"spe.md\")\n (include \"dfp.md\")"}, {"sha": "90af9dce47b25da471f1b9e1dcaca629f86b4367", "filename": "gcc/config/rs6000/rs6000.opt", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.opt?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -151,6 +151,10 @@ malign-branch-targets\n Target Undocumented Report Var(TARGET_ALIGN_BRANCH_TARGETS) Init(-1)\n ; Explicitly set/unset whether rs6000_align_branch_targets is set\n \n+mvectorize-builtins\n+Target Undocumented Report Var(TARGET_VECTORIZE_BUILTINS) Init(-1)\n+; Explicitly control whether we vectorize the builtins or not.\n+\n mupdate\n Target Report Var(TARGET_UPDATE) Init(1)\n Generate load/store with update instructions"}, {"sha": "66a367a7b62eff62bb49541a65f607a5a7c0f66a", "filename": "gcc/config/rs6000/t-rs6000", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Ft-rs6000", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Ft-rs6000", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Ft-rs6000?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -53,13 +53,15 @@ MD_INCLUDES = $(srcdir)/config/rs6000/rios1.md \\\n \t$(srcdir)/config/rs6000/power4.md \\\n \t$(srcdir)/config/rs6000/power5.md \\\n \t$(srcdir)/config/rs6000/power6.md \\\n+\t$(srcdir)/config/rs6000/power7.md \\\n \t$(srcdir)/config/rs6000/cell.md \\\n \t$(srcdir)/config/rs6000/xfpu.md \\\n \t$(srcdir)/config/rs6000/predicates.md \\\n \t$(srcdir)/config/rs6000/constraints.md \\\n \t$(srcdir)/config/rs6000/darwin.md \\\n \t$(srcdir)/config/rs6000/sync.md \\\n \t$(srcdir)/config/rs6000/vector.md \\\n+\t$(srcdir)/config/rs6000/vsx.md \\\n \t$(srcdir)/config/rs6000/altivec.md \\\n \t$(srcdir)/config/rs6000/spe.md \\\n \t$(srcdir)/config/rs6000/dfp.md \\"}, {"sha": "6366e4fe0e708eb78ab807bb8b5add0cddb17cd7", "filename": "gcc/config/rs6000/vector.md", "status": "modified", "additions": 317, "deletions": 71, "changes": 388, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fvector.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fvector.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fvector.md?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -1,6 +1,7 @@\n-;; Expander definitions for vector support.  No instructions are in this file,\n-;; this file provides the generic vector expander, and the actual vector\n-;; instructions will be in altivec.md.\n+;; Expander definitions for vector support between altivec & vsx.  No\n+;; instructions are in this file, this file provides the generic vector\n+;; expander, and the actual vector instructions will be in altivec.md and\n+;; vsx.md\n \n ;; Copyright (C) 2009\n ;; Free Software Foundation, Inc.\n@@ -27,10 +28,10 @@\n (define_mode_iterator VEC_I [V16QI V8HI V4SI])\n \n ;; Vector float modes\n-(define_mode_iterator VEC_F [V4SF])\n+(define_mode_iterator VEC_F [V4SF V2DF])\n \n ;; Vector arithmetic modes\n-(define_mode_iterator VEC_A [V16QI V8HI V4SI V4SF])\n+(define_mode_iterator VEC_A [V16QI V8HI V4SI V4SF V2DF])\n \n ;; Vector modes that need alginment via permutes\n (define_mode_iterator VEC_K [V16QI V8HI V4SI V4SF])\n@@ -41,6 +42,9 @@\n ;; Vector modes for moves.  Don't do TImode here.\n (define_mode_iterator VEC_M [V16QI V8HI V4SI V2DI V4SF V2DF])\n \n+;; Vector modes for types that don't need a realignment under VSX\n+(define_mode_iterator VEC_N [V4SI V4SF V2DI V2DF])\n+\n ;; Vector comparison modes\n (define_mode_iterator VEC_C [V16QI V8HI V4SI V4SF V2DF])\n \n@@ -75,7 +79,7 @@\n (define_expand \"mov<mode>\"\n   [(set (match_operand:VEC_M 0 \"nonimmediate_operand\" \"\")\n \t(match_operand:VEC_M 1 \"any_operand\" \"\"))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n {\n   if (can_create_pseudo_p ())\n     {\n@@ -89,24 +93,25 @@\n     }\n })\n \n-;; Generic vector floating point load/store instructions.\n+;; Generic vector floating point load/store instructions.  These will match\n+;; insns defined in vsx.md or altivec.md depending on the switches.\n (define_expand \"vector_load_<mode>\"\n   [(set (match_operand:VEC_M 0 \"vfloat_operand\" \"\")\n \t(match_operand:VEC_M 1 \"memory_operand\" \"\"))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_store_<mode>\"\n   [(set (match_operand:VEC_M 0 \"memory_operand\" \"\")\n \t(match_operand:VEC_M 1 \"vfloat_operand\" \"\"))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n ;; Splits if a GPR register was chosen for the move\n (define_split\n   [(set (match_operand:VEC_L 0 \"nonimmediate_operand\" \"\")\n         (match_operand:VEC_L 1 \"input_operand\" \"\"))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\n    && reload_completed\n    && gpr_or_gpr_p (operands[0], operands[1])\"\n   [(pc)]\n@@ -149,7 +154,7 @@\n \t(and:P (plus:P (match_operand:P 1 \"gpc_reg_operand\" \"r\")\n \t\t       (match_operand:P 2 \"reg_or_cint_operand\" \"rI\"))\n \t       (const_int -16)))]\n-  \"TARGET_ALTIVEC && (reload_in_progress || reload_completed)\"\n+  \"(TARGET_ALTIVEC || TARGET_VSX) && (reload_in_progress || reload_completed)\"\n   \"#\"\n   \"&& reload_completed\"\n   [(set (match_dup 0)\n@@ -167,7 +172,7 @@\n   [(set (match_operand:P 0 \"gpc_reg_operand\" \"=b\")\n \t(and:P (match_operand:P 1 \"gpc_reg_operand\" \"r\")\n \t       (const_int -16)))]\n-  \"TARGET_ALTIVEC && (reload_in_progress || reload_completed)\"\n+  \"(TARGET_ALTIVEC || TARGET_VSX) && (reload_in_progress || reload_completed)\"\n   \"#\"\n   \"&& reload_completed\"\n   [(parallel [(set (match_dup 0)\n@@ -180,68 +185,131 @@\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t(plus:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n \t\t    (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"sub<mode>3\"\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t(minus:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n \t\t     (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"mul<mode>3\"\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t(mult:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n \t\t    (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode) && TARGET_FUSED_MADD\"\n+  \"(VECTOR_UNIT_VSX_P (<MODE>mode)\n+    || (VECTOR_UNIT_ALTIVEC_P (<MODE>mode) && TARGET_FUSED_MADD))\"\n   \"\n {\n-  emit_insn (gen_altivec_mulv4sf3 (operands[0], operands[1], operands[2]));\n-  DONE;\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_mulv4sf3 (operands[0], operands[1], operands[2]));\n+      DONE;\n+    }\n }\")\n \n+(define_expand \"div<mode>3\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(div:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n+\t\t   (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"\")\n+\n (define_expand \"neg<mode>2\"\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t(neg:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\n {\n-  emit_insn (gen_altivec_negv4sf2 (operands[0], operands[1]));\n-  DONE;\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_negv4sf2 (operands[0], operands[1]));\n+      DONE;\n+    }\n }\")\n \n (define_expand \"abs<mode>2\"\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t(abs:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\n {\n-  emit_insn (gen_altivec_absv4sf2 (operands[0], operands[1]));\n-  DONE;\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_absv4sf2 (operands[0], operands[1]));\n+      DONE;\n+    }\n }\")\n \n (define_expand \"smin<mode>3\"\n   [(set (match_operand:VEC_F 0 \"register_operand\" \"\")\n         (smin:VEC_F (match_operand:VEC_F 1 \"register_operand\" \"\")\n \t\t    (match_operand:VEC_F 2 \"register_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"smax<mode>3\"\n   [(set (match_operand:VEC_F 0 \"register_operand\" \"\")\n         (smax:VEC_F (match_operand:VEC_F 1 \"register_operand\" \"\")\n \t\t    (match_operand:VEC_F 2 \"register_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n \n+(define_expand \"sqrt<mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(sqrt:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"\")\n+\n (define_expand \"ftrunc<mode>2\"\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n   \t(fix:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_ceil<mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(unspec:VEC_F [(match_operand:VEC_F 1 \"vfloat_operand\" \"\")]\n+\t\t      UNSPEC_FRIP))]\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_floor<mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(unspec:VEC_F [(match_operand:VEC_F 1 \"vfloat_operand\" \"\")]\n+\t\t      UNSPEC_FRIM))]\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n+(define_expand \"vector_btrunc<mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(fix:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_copysign<mode>3\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(if_then_else:VEC_F\n+\t (ge:VEC_F (match_operand:VEC_F 2 \"vfloat_operand\" \"\")\n+\t\t   (match_dup 3))\n+\t (abs:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\"))\n+\t (neg:VEC_F (abs:VEC_F (match_dup 1)))))]\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n+  \"\n+{\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_copysign_v4sf3 (operands[0], operands[1],\n+\t\t\t\t\t     operands[2]));\n+      DONE;\n+    }\n+\n+  operands[3] = CONST0_RTX (<MODE>mode);\n+}\")\n+\n \f\n ;; Vector comparisons\n (define_expand \"vcond<mode>\"\n@@ -252,7 +320,7 @@\n \t\t\t  (match_operand:VEC_F 5 \"vfloat_operand\" \"\")])\n \t (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n \t (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\n {\n   if (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n@@ -302,21 +370,21 @@\n   [(set (match_operand:VEC_C 0 \"vlogical_operand\" \"\")\n \t(eq:VEC_C (match_operand:VEC_C 1 \"vlogical_operand\" \"\")\n \t\t  (match_operand:VEC_C 2 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_gt<mode>\"\n   [(set (match_operand:VEC_C 0 \"vlogical_operand\" \"\")\n \t(gt:VEC_C (match_operand:VEC_C 1 \"vlogical_operand\" \"\")\n \t\t  (match_operand:VEC_C 2 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_ge<mode>\"\n   [(set (match_operand:VEC_C 0 \"vlogical_operand\" \"\")\n \t(ge:VEC_C (match_operand:VEC_C 1 \"vlogical_operand\" \"\")\n \t\t  (match_operand:VEC_C 2 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_gtu<mode>\"\n@@ -342,7 +410,7 @@\n \t\t(const_int 0))\n \t (match_operand:VEC_L 2 \"vlogical_operand\" \"\")\n \t (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_select_<mode>_uns\"\n@@ -352,7 +420,7 @@\n \t\t   (const_int 0))\n \t (match_operand:VEC_L 2 \"vlogical_operand\" \"\")\n \t (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n ;; Expansions that compare vectors producing a vector result and a predicate,\n@@ -366,7 +434,7 @@\n      (set (match_operand:VEC_A 0 \"vlogical_operand\" \"\")\n \t  (eq:VEC_A (match_dup 1)\n \t\t    (match_dup 2)))])]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_gt_<mode>_p\"\n@@ -378,7 +446,7 @@\n      (set (match_operand:VEC_A 0 \"vlogical_operand\" \"\")\n \t  (gt:VEC_A (match_dup 1)\n \t\t    (match_dup 2)))])]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_ge_<mode>_p\"\n@@ -390,7 +458,7 @@\n      (set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t  (ge:VEC_F (match_dup 1)\n \t\t    (match_dup 2)))])]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"vector_gtu_<mode>_p\"\n@@ -402,39 +470,39 @@\n      (set (match_operand:VEC_I 0 \"vlogical_operand\" \"\")\n \t  (gtu:VEC_I (match_dup 1)\n \t\t     (match_dup 2)))])]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n-;; AltiVec predicates.\n+;; AltiVec/VSX predicates.\n \n (define_expand \"cr6_test_for_zero\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n \t(eq:SI (reg:CC 74)\n \t       (const_int 0)))]\n-  \"TARGET_ALTIVEC\"\n+  \"TARGET_ALTIVEC || TARGET_VSX\"\n   \"\")\t\n \n (define_expand \"cr6_test_for_zero_reverse\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n \t(eq:SI (reg:CC 74)\n \t       (const_int 0)))\n    (set (match_dup 0) (minus:SI (const_int 1) (match_dup 0)))]\n-  \"TARGET_ALTIVEC\"\n+  \"TARGET_ALTIVEC || TARGET_VSX\"\n   \"\")\n \n (define_expand \"cr6_test_for_lt\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n \t(lt:SI (reg:CC 74)\n \t       (const_int 0)))]\n-  \"TARGET_ALTIVEC\"\n+  \"TARGET_ALTIVEC || TARGET_VSX\"\n   \"\")\n \n (define_expand \"cr6_test_for_lt_reverse\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n \t(lt:SI (reg:CC 74)\n \t       (const_int 0)))\n    (set (match_dup 0) (minus:SI (const_int 1) (match_dup 0)))]\n-  \"TARGET_ALTIVEC\"\n+  \"TARGET_ALTIVEC || TARGET_VSX\"\n   \"\")\n \n \f\n@@ -443,90 +511,102 @@\n   [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n         (xor:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n \t\t   (match_operand:VEC_L 2 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"ior<mode>3\"\n   [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n         (ior:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n \t\t   (match_operand:VEC_L 2 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"and<mode>3\"\n   [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n         (and:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n \t\t   (match_operand:VEC_L 2 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"one_cmpl<mode>2\"\n   [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n         (not:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n   \n (define_expand \"nor<mode>3\"\n   [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n         (not:VEC_L (ior:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n \t\t\t      (match_operand:VEC_L 2 \"vlogical_operand\" \"\"))))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n (define_expand \"andc<mode>3\"\n   [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n         (and:VEC_L (not:VEC_L (match_operand:VEC_L 2 \"vlogical_operand\" \"\"))\n \t\t   (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\")\n \n ;; Same size conversions\n (define_expand \"float<VEC_int><mode>2\"\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t(float:VEC_F (match_operand:<VEC_INT> 1 \"vint_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\n {\n-  emit_insn (gen_altivec_vcfsx (operands[0], operands[1], const0_rtx));\n-  DONE;\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_vcfsx (operands[0], operands[1], const0_rtx));\n+      DONE;\n+    }\n }\")\n \n (define_expand \"unsigned_float<VEC_int><mode>2\"\n   [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n \t(unsigned_float:VEC_F (match_operand:<VEC_INT> 1 \"vint_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\n {\n-  emit_insn (gen_altivec_vcfux (operands[0], operands[1], const0_rtx));\n-  DONE;\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_vcfux (operands[0], operands[1], const0_rtx));\n+      DONE;\n+    }\n }\")\n \n (define_expand \"fix_trunc<mode><VEC_int>2\"\n   [(set (match_operand:<VEC_INT> 0 \"vint_operand\" \"\")\n \t(fix:<VEC_INT> (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\n {\n-  emit_insn (gen_altivec_vctsxs (operands[0], operands[1], const0_rtx));\n-  DONE;\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_vctsxs (operands[0], operands[1], const0_rtx));\n+      DONE;\n+    }\n }\")\n \n (define_expand \"fixuns_trunc<mode><VEC_int>2\"\n   [(set (match_operand:<VEC_INT> 0 \"vint_operand\" \"\")\n \t(unsigned_fix:<VEC_INT> (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n-  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n   \"\n {\n-  emit_insn (gen_altivec_vctuxs (operands[0], operands[1], const0_rtx));\n-  DONE;\n+  if (<MODE>mode == V4SFmode && VECTOR_UNIT_ALTIVEC_P (<MODE>mode))\n+    {\n+      emit_insn (gen_altivec_vctuxs (operands[0], operands[1], const0_rtx));\n+      DONE;\n+    }\n }\")\n \n \f\n ;; Vector initialization, set, extract\n (define_expand \"vec_init<mode>\"\n   [(match_operand:VEC_E 0 \"vlogical_operand\" \"\")\n    (match_operand:VEC_E 1 \"\" \"\")]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n {\n   rs6000_expand_vector_init (operands[0], operands[1]);\n   DONE;\n@@ -536,7 +616,7 @@\n   [(match_operand:VEC_E 0 \"vlogical_operand\" \"\")\n    (match_operand:<VEC_base> 1 \"register_operand\" \"\")\n    (match_operand 2 \"const_int_operand\" \"\")]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n {\n   rs6000_expand_vector_set (operands[0], operands[1], INTVAL (operands[2]));\n   DONE;\n@@ -546,7 +626,7 @@\n   [(match_operand:<VEC_base> 0 \"register_operand\" \"\")\n    (match_operand:VEC_E 1 \"vlogical_operand\" \"\")\n    (match_operand 2 \"const_int_operand\" \"\")]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n {\n   rs6000_expand_vector_extract (operands[0], operands[1],\n \t\t\t\tINTVAL (operands[2]));\n@@ -568,7 +648,7 @@\n \t\t\t\t     (const_int 3)\n \t\t\t\t     (const_int 1)]))\n \t (const_int 5)))]\n-  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SFmode)\"\n   \"\")\n \n (define_expand \"vec_interleave_lowv4sf\"\n@@ -585,23 +665,171 @@\n \t\t\t\t     (const_int 1)\n \t\t\t\t     (const_int 3)]))\n \t (const_int 5)))]\n-  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SFmode)\"\n+  \"\")\n+\n+(define_expand \"vec_interleave_highv2df\"\n+  [(set (match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+\t(vec_concat:V2DF\n+\t (vec_select:DF (match_operand:V2DF 1 \"vfloat_operand\" \"\")\n+\t\t\t(parallel [(const_int 0)]))\n+\t (vec_select:DF (match_operand:V2DF 2 \"vfloat_operand\" \"\")\n+\t\t\t(parallel [(const_int 0)]))))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"\")\n+\n+(define_expand \"vec_interleave_lowv2df\"\n+  [(set (match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+\t(vec_concat:V2DF\n+\t (vec_select:DF (match_operand:V2DF 1 \"vfloat_operand\" \"\")\n+\t\t\t(parallel [(const_int 1)]))\n+\t (vec_select:DF (match_operand:V2DF 2 \"vfloat_operand\" \"\")\n+\t\t\t(parallel [(const_int 1)]))))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n   \"\")\n \n+\f\n+;; Convert double word types to single word types\n+(define_expand \"vec_pack_trunc_v2df\"\n+  [(match_operand:V4SF 0 \"vfloat_operand\" \"\")\n+   (match_operand:V2DF 1 \"vfloat_operand\" \"\")\n+   (match_operand:V2DF 2 \"vfloat_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && TARGET_ALTIVEC\"\n+{\n+  rtx r1 = gen_reg_rtx (V4SFmode);\n+  rtx r2 = gen_reg_rtx (V4SFmode);\n+\n+  emit_insn (gen_vsx_xvcvdpsp (r1, operands[1]));\n+  emit_insn (gen_vsx_xvcvdpsp (r2, operands[2]));\n+  emit_insn (gen_vec_extract_evenv4sf (operands[0], r1, r2));\n+  DONE;\n+})\n+\n+(define_expand \"vec_pack_sfix_trunc_v2df\"\n+  [(match_operand:V4SI 0 \"vint_operand\" \"\")\n+   (match_operand:V2DF 1 \"vfloat_operand\" \"\")\n+   (match_operand:V2DF 2 \"vfloat_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && TARGET_ALTIVEC\"\n+{\n+  rtx r1 = gen_reg_rtx (V4SImode);\n+  rtx r2 = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_vsx_xvcvdpsxws (r1, operands[1]));\n+  emit_insn (gen_vsx_xvcvdpsxws (r2, operands[2]));\n+  emit_insn (gen_vec_extract_evenv4si (operands[0], r1, r2));\n+  DONE;\n+})\n+\n+(define_expand \"vec_pack_ufix_trunc_v2df\"\n+  [(match_operand:V4SI 0 \"vint_operand\" \"\")\n+   (match_operand:V2DF 1 \"vfloat_operand\" \"\")\n+   (match_operand:V2DF 2 \"vfloat_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && TARGET_ALTIVEC\"\n+{\n+  rtx r1 = gen_reg_rtx (V4SImode);\n+  rtx r2 = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_vsx_xvcvdpuxws (r1, operands[1]));\n+  emit_insn (gen_vsx_xvcvdpuxws (r2, operands[2]));\n+  emit_insn (gen_vec_extract_evenv4si (operands[0], r1, r2));\n+  DONE;\n+})\n+\n+;; Convert single word types to double word\n+(define_expand \"vec_unpacks_hi_v4sf\"\n+  [(match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+   (match_operand:V4SF 1 \"vfloat_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SFmode)\"\n+{\n+  rtx reg = gen_reg_rtx (V4SFmode);\n+\n+  emit_insn (gen_vec_interleave_highv4sf (reg, operands[1], operands[1]));\n+  emit_insn (gen_vsx_xvcvspdp (operands[0], reg));\n+  DONE;\n+})\n+\n+(define_expand \"vec_unpacks_lo_v4sf\"\n+  [(match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+   (match_operand:V4SF 1 \"vfloat_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SFmode)\"\n+{\n+  rtx reg = gen_reg_rtx (V4SFmode);\n+\n+  emit_insn (gen_vec_interleave_lowv4sf (reg, operands[1], operands[1]));\n+  emit_insn (gen_vsx_xvcvspdp (operands[0], reg));\n+  DONE;\n+})\n+\n+(define_expand \"vec_unpacks_float_hi_v4si\"\n+  [(match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+   (match_operand:V4SI 1 \"vint_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SImode)\"\n+{\n+  rtx reg = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_vec_interleave_highv4si (reg, operands[1], operands[1]));\n+  emit_insn (gen_vsx_xvcvsxwdp (operands[0], reg));\n+  DONE;\n+})\n+\n+(define_expand \"vec_unpacks_float_lo_v4si\"\n+  [(match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+   (match_operand:V4SI 1 \"vint_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SImode)\"\n+{\n+  rtx reg = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_vec_interleave_lowv4si (reg, operands[1], operands[1]));\n+  emit_insn (gen_vsx_xvcvsxwdp (operands[0], reg));\n+  DONE;\n+})\n+\n+(define_expand \"vec_unpacku_float_hi_v4si\"\n+  [(match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+   (match_operand:V4SI 1 \"vint_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SImode)\"\n+{\n+  rtx reg = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_vec_interleave_highv4si (reg, operands[1], operands[1]));\n+  emit_insn (gen_vsx_xvcvuxwdp (operands[0], reg));\n+  DONE;\n+})\n+\n+(define_expand \"vec_unpacku_float_lo_v4si\"\n+  [(match_operand:V2DF 0 \"vfloat_operand\" \"\")\n+   (match_operand:V4SI 1 \"vint_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode) && VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SImode)\"\n+{\n+  rtx reg = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_vec_interleave_lowv4si (reg, operands[1], operands[1]));\n+  emit_insn (gen_vsx_xvcvuxwdp (operands[0], reg));\n+  DONE;\n+})\n+\n \f\n ;; Align vector loads with a permute.\n (define_expand \"vec_realign_load_<mode>\"\n   [(match_operand:VEC_K 0 \"vlogical_operand\" \"\")\n    (match_operand:VEC_K 1 \"vlogical_operand\" \"\")\n    (match_operand:VEC_K 2 \"vlogical_operand\" \"\")\n    (match_operand:V16QI 3 \"vlogical_operand\" \"\")]\n-  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n {\n   emit_insn (gen_altivec_vperm_<mode> (operands[0], operands[1], operands[2],\n \t\t\t\t       operands[3]));\n   DONE;\n })\n \n+;; Under VSX, vectors of 4/8 byte alignments do not need to be aligned\n+;; since the load already handles it.\n+(define_expand \"movmisalign<mode>\"\n+ [(set (match_operand:VEC_N 0 \"vfloat_operand\" \"\")\n+       (match_operand:VEC_N 1 \"vfloat_operand\" \"\"))]\n+ \"VECTOR_MEM_VSX_P (<MODE>mode) && TARGET_ALLOW_MOVMISALIGN\"\n+ \"\")\n+\n \f\n ;; Vector shift left in bits.  Currently supported ony for shift\n ;; amounts that can be expressed as byte shifts (divisible by 8).\n@@ -627,9 +855,18 @@\n   if (bitshift_val & 0x7)\n     FAIL;\n   byteshift_val = bitshift_val >> 3;\n-  shift = gen_rtx_CONST_INT (QImode, byteshift_val);\n-  insn = gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n-\t\t\t\t    shift);\n+  if (TARGET_VSX && (byteshift_val & 0x3) == 0)\n+    {\n+      shift = gen_rtx_CONST_INT (QImode, byteshift_val >> 2);\n+      insn = gen_vsx_xxsldwi_<mode> (operands[0], operands[1], operands[1],\n+\t\t\t\t     shift);\n+    }\n+  else\n+    {\n+      shift = gen_rtx_CONST_INT (QImode, byteshift_val);\n+      insn = gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n+\t\t\t\t\tshift);\n+    }\n \n   emit_insn (insn);\n   DONE;\n@@ -659,9 +896,18 @@\n   if (bitshift_val & 0x7)\n     FAIL;\n   byteshift_val = 16 - (bitshift_val >> 3);\n-  shift = gen_rtx_CONST_INT (QImode, byteshift_val);\n-  insn = gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n-\t\t\t\t    shift);\n+  if (TARGET_VSX && (byteshift_val & 0x3) == 0)\n+    {\n+      shift = gen_rtx_CONST_INT (QImode, byteshift_val >> 2);\n+      insn = gen_vsx_xxsldwi_<mode> (operands[0], operands[1], operands[1],\n+\t\t\t\t     shift);\n+    }\n+  else\n+    {\n+      shift = gen_rtx_CONST_INT (QImode, byteshift_val);\n+      insn = gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n+\t\t\t\t\tshift);\n+    }\n \n   emit_insn (insn);\n   DONE;"}, {"sha": "c6aafa6fac094bb990648fc15a3bb38ecf6c638c", "filename": "gcc/config/rs6000/vsx.md", "status": "added", "additions": 1339, "deletions": 0, "changes": 1339, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fvsx.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fconfig%2Frs6000%2Fvsx.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fvsx.md?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,1339 @@\n+;; VSX patterns.\n+;; Copyright (C) 2009\n+;; Free Software Foundation, Inc.\n+;; Contributed by Michael Meissner <meissner@linux.vnet.ibm.com>\n+\n+;; This file is part of GCC.\n+\n+;; GCC is free software; you can redistribute it and/or modify it\n+;; under the terms of the GNU General Public License as published\n+;; by the Free Software Foundation; either version 3, or (at your\n+;; option) any later version.\n+\n+;; GCC is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+;; or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+;; License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+;; Iterator for both scalar and vector floating point types supported by VSX\n+(define_mode_iterator VSX_B [DF V4SF V2DF])\n+\n+;; Iterator for the 2 64-bit vector types\n+(define_mode_iterator VSX_D [V2DF V2DI])\n+\n+;; Iterator for the 2 32-bit vector types\n+(define_mode_iterator VSX_W [V4SF V4SI])\n+\n+;; Iterator for vector floating point types supported by VSX\n+(define_mode_iterator VSX_F [V4SF V2DF])\n+\n+;; Iterator for logical types supported by VSX\n+(define_mode_iterator VSX_L [V16QI V8HI V4SI V2DI V4SF V2DF TI])\n+\n+;; Iterator for memory move.  Handle TImode specially to allow\n+;; it to use gprs as well as vsx registers.\n+(define_mode_iterator VSX_M [V16QI V8HI V4SI V2DI V4SF V2DF])\n+\n+;; Iterator for types for load/store with update\n+(define_mode_iterator VSX_U [V16QI V8HI V4SI V2DI V4SF V2DF TI DF])\n+\n+;; Map into the appropriate load/store name based on the type\n+(define_mode_attr VSm  [(V16QI \"vw4\")\n+\t\t\t(V8HI  \"vw4\")\n+\t\t\t(V4SI  \"vw4\")\n+\t\t\t(V4SF  \"vw4\")\n+\t\t\t(V2DF  \"vd2\")\n+\t\t\t(V2DI  \"vd2\")\n+\t\t\t(DF    \"d\")\n+\t\t\t(TI    \"vw4\")])\n+\n+;; Map into the appropriate suffix based on the type\n+(define_mode_attr VSs\t[(V16QI \"sp\")\n+\t\t\t (V8HI  \"sp\")\n+\t\t\t (V4SI  \"sp\")\n+\t\t\t (V4SF  \"sp\")\n+\t\t\t (V2DF  \"dp\")\n+\t\t\t (V2DI  \"dp\")\n+\t\t\t (DF    \"dp\")\n+\t\t\t (SF\t\"sp\")\n+\t\t\t (TI    \"sp\")])\n+\n+;; Map the register class used\n+(define_mode_attr VSr\t[(V16QI \"v\")\n+\t\t\t (V8HI  \"v\")\n+\t\t\t (V4SI  \"v\")\n+\t\t\t (V4SF  \"wf\")\n+\t\t\t (V2DI  \"wd\")\n+\t\t\t (V2DF  \"wd\")\n+\t\t\t (DF    \"ws\")\n+\t\t\t (SF\t\"d\")\n+\t\t\t (TI    \"wd\")])\n+\n+;; Map the register class used for float<->int conversions\n+(define_mode_attr VSr2\t[(V2DF  \"wd\")\n+\t\t\t (V4SF  \"wf\")\n+\t\t\t (DF    \"!f#r\")])\n+\n+(define_mode_attr VSr3\t[(V2DF  \"wa\")\n+\t\t\t (V4SF  \"wa\")\n+\t\t\t (DF    \"!f#r\")])\n+\n+;; Map the register class for sp<->dp float conversions, destination\n+(define_mode_attr VSr4\t[(SF\t\"ws\")\n+\t\t\t (DF\t\"f\")\n+\t\t\t (V2DF  \"wd\")\n+\t\t\t (V4SF\t\"v\")])\n+\n+;; Map the register class for sp<->dp float conversions, destination\n+(define_mode_attr VSr5\t[(SF\t\"ws\")\n+\t\t\t (DF\t\"f\")\n+\t\t\t (V2DF  \"v\")\n+\t\t\t (V4SF\t\"wd\")])\n+\n+;; Same size integer type for floating point data\n+(define_mode_attr VSi [(V4SF  \"v4si\")\n+\t\t       (V2DF  \"v2di\")\n+\t\t       (DF    \"di\")])\n+\n+(define_mode_attr VSI [(V4SF  \"V4SI\")\n+\t\t       (V2DF  \"V2DI\")\n+\t\t       (DF    \"DI\")])\n+\n+;; Word size for same size conversion\n+(define_mode_attr VSc [(V4SF \"w\")\n+\t\t       (V2DF \"d\")\n+\t\t       (DF   \"d\")])\n+\n+;; Bitsize for DF load with update\n+(define_mode_attr VSbit [(SI \"32\")\n+\t\t\t (DI \"64\")])\n+\n+;; Map into either s or v, depending on whether this is a scalar or vector\n+;; operation\n+(define_mode_attr VSv\t[(V16QI \"v\")\n+\t\t\t (V8HI  \"v\")\n+\t\t\t (V4SI  \"v\")\n+\t\t\t (V4SF  \"v\")\n+\t\t\t (V2DI  \"v\")\n+\t\t\t (V2DF  \"v\")\n+\t\t\t (TI    \"v\")\n+\t\t\t (DF    \"s\")])\n+\n+;; Appropriate type for add ops (and other simple FP ops)\n+(define_mode_attr VStype_simple\t[(V2DF \"vecfloat\")\n+\t\t\t\t (V4SF \"vecfloat\")\n+\t\t\t\t (DF   \"fp\")])\n+\n+(define_mode_attr VSfptype_simple [(V2DF \"fp_addsub_d\")\n+\t\t\t\t   (V4SF \"fp_addsub_s\")\n+\t\t\t\t   (DF   \"fp_addsub_d\")])\n+\n+;; Appropriate type for multiply ops\n+(define_mode_attr VStype_mul\t[(V2DF \"vecfloat\")\n+\t\t\t\t (V4SF \"vecfloat\")\n+\t\t\t\t (DF   \"dmul\")])\n+\n+(define_mode_attr VSfptype_mul\t[(V2DF \"fp_mul_d\")\n+\t\t\t\t (V4SF \"fp_mul_s\")\n+\t\t\t\t (DF   \"fp_mul_d\")])\n+\n+;; Appropriate type for divide ops.  For now, just lump the vector divide with\n+;; the scalar divides\n+(define_mode_attr VStype_div\t[(V2DF \"ddiv\")\n+\t\t\t\t (V4SF \"sdiv\")\n+\t\t\t\t (DF   \"ddiv\")])\n+\n+(define_mode_attr VSfptype_div\t[(V2DF \"fp_div_d\")\n+\t\t\t\t (V4SF \"fp_div_s\")\n+\t\t\t\t (DF   \"fp_div_d\")])\n+\n+;; Appropriate type for sqrt ops.  For now, just lump the vector sqrt with\n+;; the scalar sqrt\n+(define_mode_attr VStype_sqrt\t[(V2DF \"dsqrt\")\n+\t\t\t\t (V4SF \"sdiv\")\n+\t\t\t\t (DF   \"ddiv\")])\n+\n+(define_mode_attr VSfptype_sqrt\t[(V2DF \"fp_sqrt_d\")\n+\t\t\t\t (V4SF \"fp_sqrt_s\")\n+\t\t\t\t (DF   \"fp_sqrt_d\")])\n+\n+;; Iterator and modes for sp<->dp conversions\n+;; Because scalar SF values are represented internally as double, use the\n+;; V4SF type to represent this than SF.\n+(define_mode_iterator VSX_SPDP [DF V4SF V2DF])\n+\n+(define_mode_attr VS_spdp_res [(DF\t\"V4SF\")\n+\t\t\t       (V4SF\t\"V2DF\")\n+\t\t\t       (V2DF\t\"V4SF\")])\n+\n+(define_mode_attr VS_spdp_insn [(DF\t\"xscvdpsp\")\n+\t\t\t\t(V4SF\t\"xvcvspdp\")\n+\t\t\t\t(V2DF\t\"xvcvdpsp\")])\n+\n+(define_mode_attr VS_spdp_type [(DF\t\"fp\")\n+\t\t\t\t(V4SF\t\"vecfloat\")\n+\t\t\t\t(V2DF\t\"vecfloat\")])\n+\n+;; Map the scalar mode for a vector type\n+(define_mode_attr VS_scalar [(V2DF\t\"DF\")\n+\t\t\t     (V2DI\t\"DI\")\n+\t\t\t     (V4SF\t\"SF\")\n+\t\t\t     (V4SI\t\"SI\")\n+\t\t\t     (V8HI\t\"HI\")\n+\t\t\t     (V16QI\t\"QI\")])\n+\t\t\t     \n+;; Appropriate type for load + update\n+(define_mode_attr VStype_load_update [(V16QI \"vecload\")\n+\t\t\t\t      (V8HI  \"vecload\")\n+\t\t\t\t      (V4SI  \"vecload\")\n+\t\t\t\t      (V4SF  \"vecload\")\n+\t\t\t\t      (V2DI  \"vecload\")\n+\t\t\t\t      (V2DF  \"vecload\")\n+\t\t\t\t      (TI    \"vecload\")\n+\t\t\t\t      (DF    \"fpload\")])\n+\n+;; Appropriate type for store + update\n+(define_mode_attr VStype_store_update [(V16QI \"vecstore\")\n+\t\t\t\t       (V8HI  \"vecstore\")\n+\t\t\t\t       (V4SI  \"vecstore\")\n+\t\t\t\t       (V4SF  \"vecstore\")\n+\t\t\t\t       (V2DI  \"vecstore\")\n+\t\t\t\t       (V2DF  \"vecstore\")\n+\t\t\t\t       (TI    \"vecstore\")\n+\t\t\t\t       (DF    \"fpstore\")])\n+\n+;; Constants for creating unspecs\n+(define_constants\n+  [(UNSPEC_VSX_CONCAT\t\t500)\n+   (UNSPEC_VSX_CVDPSXWS\t\t501)\n+   (UNSPEC_VSX_CVDPUXWS\t\t502)\n+   (UNSPEC_VSX_CVSPDP\t\t503)\n+   (UNSPEC_VSX_CVSXWDP\t\t504)\n+   (UNSPEC_VSX_CVUXWDP\t\t505)\n+   (UNSPEC_VSX_CVSXDSP\t\t506)\n+   (UNSPEC_VSX_CVUXDSP\t\t507)\n+   (UNSPEC_VSX_CVSPSXDS\t\t508)\n+   (UNSPEC_VSX_CVSPUXDS\t\t509)\n+   (UNSPEC_VSX_MADD\t\t510)\n+   (UNSPEC_VSX_MSUB\t\t511)\n+   (UNSPEC_VSX_NMADD\t\t512)\n+   (UNSPEC_VSX_NMSUB\t\t513)\n+   (UNSPEC_VSX_RSQRTE\t\t514)\n+   (UNSPEC_VSX_TDIV\t\t515)\n+   (UNSPEC_VSX_TSQRT\t\t516)\n+   (UNSPEC_VSX_XXPERMDI\t\t517)\n+   (UNSPEC_VSX_SET\t\t518)\n+   (UNSPEC_VSX_ROUND_I\t\t519)\n+   (UNSPEC_VSX_ROUND_IC\t\t520)\n+   (UNSPEC_VSX_SLDWI\t\t521)])\n+\n+;; VSX moves\n+(define_insn \"*vsx_mov<mode>\"\n+  [(set (match_operand:VSX_M 0 \"nonimmediate_operand\" \"=Z,<VSr>,<VSr>,?Z,?wa,?wa,*o,*r,*r,<VSr>,?wa,v,wZ,v\")\n+\t(match_operand:VSX_M 1 \"input_operand\" \"<VSr>,Z,<VSr>,wa,Z,wa,r,o,r,j,j,W,v,wZ\"))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\n+   && (register_operand (operands[0], <MODE>mode) \n+       || register_operand (operands[1], <MODE>mode))\"\n+{\n+  switch (which_alternative)\n+    {\n+    case 0:\n+    case 3:\n+      return \"stx<VSm>%U0x %x1,%y0\";\n+\n+    case 1:\n+    case 4:\n+      return \"lx<VSm>%U0x %x0,%y1\";\n+\n+    case 2:\n+    case 5:\n+      return \"xxlor %x0,%x1,%x1\";\n+\n+    case 6:\n+    case 7:\n+    case 8:\n+      return \"#\";\n+\n+    case 9:\n+    case 10:\n+      return \"xxlxor %x0,%x0,%x0\";\n+\n+    case 11:\n+      return output_vec_const_move (operands);\n+\n+    case 12:\n+      return \"stvx %1,%y0\";\n+\n+    case 13:\n+      return \"lvx %0,%y1\";\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+  [(set_attr \"type\" \"vecstore,vecload,vecsimple,vecstore,vecload,vecsimple,*,*,*,vecsimple,vecsimple,*,vecstore,vecload\")])\n+\n+;; Unlike other VSX moves, allow the GPRs, since a normal use of TImode is for\n+;; unions.  However for plain data movement, slightly favor the vector loads\n+(define_insn \"*vsx_movti\"\n+  [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=Z,wa,wa,?o,?r,?r,wa,v,v,wZ\")\n+\t(match_operand:TI 1 \"input_operand\" \"wa,Z,wa,r,o,r,j,W,wZ,v\"))]\n+  \"VECTOR_MEM_VSX_P (TImode)\n+   && (register_operand (operands[0], TImode) \n+       || register_operand (operands[1], TImode))\"\n+{\n+  switch (which_alternative)\n+    {\n+    case 0:\n+      return \"stxvd2%U0x %x1,%y0\";\n+\n+    case 1:\n+      return \"lxvd2%U0x %x0,%y1\";\n+\n+    case 2:\n+      return \"xxlor %x0,%x1,%x1\";\n+\n+    case 3:\n+    case 4:\n+    case 5:\n+      return \"#\";\n+\n+    case 6:\n+      return \"xxlxor %x0,%x0,%x0\";\n+\n+    case 7:\n+      return output_vec_const_move (operands);\n+\n+    case 8:\n+      return \"stvx %1,%y0\";\n+\n+    case 9:\n+      return \"lvx %0,%y1\";\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+  [(set_attr \"type\" \"vecstore,vecload,vecsimple,*,*,*,vecsimple,*,vecstore,vecload\")])\n+\n+;; Load/store with update\n+;; Define insns that do load or store with update.  Because VSX only has\n+;; reg+reg addressing, pre-decrement or pre-increment is unlikely to be\n+;; generated.\n+;;\n+;; In all these cases, we use operands 0 and 1 for the register being\n+;; incremented because those are the operands that local-alloc will\n+;; tie and these are the pair most likely to be tieable (and the ones\n+;; that will benefit the most).\n+\n+(define_insn \"*vsx_load<VSX_U:mode>_update_<P:mptrsize>\"\n+  [(set (match_operand:VSX_U 3 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(mem:VSX_U (plus:P (match_operand:P 1 \"gpc_reg_operand\" \"0,0\")\n+\t\t\t   (match_operand:P 2 \"gpc_reg_operand\" \"r,r\"))))\n+   (set (match_operand:P 0 \"gpc_reg_operand\" \"=b,b\")\n+\t(plus:P (match_dup 1)\n+\t\t(match_dup 2)))]\n+  \"<P:tptrsize> && TARGET_UPDATE && VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"lx<VSm>ux %x3,%0,%2\"\n+  [(set_attr \"type\" \"<VSX_U:VStype_load_update>\")])\n+\n+(define_insn \"*vsx_store<mode>_update_<P:mptrsize>\"\n+  [(set (mem:VSX_U (plus:P (match_operand:P 1 \"gpc_reg_operand\" \"0,0\")\n+\t\t\t   (match_operand:P 2 \"gpc_reg_operand\" \"r,r\")))\n+\t(match_operand:VSX_U 3 \"gpc_reg_operand\" \"<VSr>,?wa\"))\n+   (set (match_operand:P 0 \"gpc_reg_operand\" \"=b,b\")\n+\t(plus:P (match_dup 1)\n+\t\t(match_dup 2)))]\n+  \"<P:tptrsize> && TARGET_UPDATE && VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"stx<VSm>ux %x3,%0,%2\"\n+  [(set_attr \"type\" \"<VSX_U:VStype_store_update>\")])\n+\n+;; We may need to have a varient on the pattern for use in the prologue\n+;; that doesn't depend on TARGET_UPDATE.\n+\n+\f\n+;; VSX scalar and vector floating point arithmetic instructions\n+(define_insn \"*vsx_add<mode>3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (plus:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t    (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>add<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_sub<mode>3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (minus:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t     (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>sub<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_mul<mode>3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (mult:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t    (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>mul<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_insn \"*vsx_div<mode>3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (div:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t \t   (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>div<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_div>\")\n+   (set_attr \"fp_type\" \"<VSfptype_div>\")])\n+\n+;; *tdiv* instruction returning the FG flag\n+(define_expand \"vsx_tdiv<mode>3_fg\"\n+  [(set (match_dup 3)\n+\t(unspec:CCFP [(match_operand:VSX_B 1 \"vsx_register_operand\" \"\")\n+\t\t      (match_operand:VSX_B 2 \"vsx_register_operand\" \"\")]\n+\t\t     UNSPEC_VSX_TDIV))\n+   (set (match_operand:SI 0 \"gpc_reg_operand\" \"\")\n+\t(gt:SI (match_dup 3)\n+\t       (const_int 0)))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  operands[3] = gen_reg_rtx (CCFPmode);\n+})\n+\n+;; *tdiv* instruction returning the FE flag\n+(define_expand \"vsx_tdiv<mode>3_fe\"\n+  [(set (match_dup 3)\n+\t(unspec:CCFP [(match_operand:VSX_B 1 \"vsx_register_operand\" \"\")\n+\t\t      (match_operand:VSX_B 2 \"vsx_register_operand\" \"\")]\n+\t\t     UNSPEC_VSX_TDIV))\n+   (set (match_operand:SI 0 \"gpc_reg_operand\" \"\")\n+\t(eq:SI (match_dup 3)\n+\t       (const_int 0)))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  operands[3] = gen_reg_rtx (CCFPmode);\n+})\n+\n+(define_insn \"*vsx_tdiv<mode>3_internal\"\n+  [(set (match_operand:CCFP 0 \"cc_reg_operand\" \"=x,x\")\n+\t(unspec:CCFP [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t      (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t   UNSPEC_VSX_TDIV))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>tdiv<VSs> %0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_fre<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t      UNSPEC_FRES))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>re<VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_neg<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (neg:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>neg<VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_abs<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (abs:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>abs<VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_nabs<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (neg:VSX_B\n+\t (abs:VSX_B\n+\t  (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\"))))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>nabs<VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_smax<mode>3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (smax:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t    (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>max<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_smin<mode>3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (smin:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t    (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>min<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_sqrt<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (sqrt:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>sqrt<VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_sqrt>\")\n+   (set_attr \"fp_type\" \"<VSfptype_sqrt>\")])\n+\n+(define_insn \"vsx_rsqrte<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t      UNSPEC_VSX_RSQRTE))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>rsqrte<VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+;; *tsqrt* returning the fg flag\n+(define_expand \"vsx_tsqrt<mode>2_fg\"\n+  [(set (match_dup 3)\n+\t(unspec:CCFP [(match_operand:VSX_B 1 \"vsx_register_operand\" \"\")]\n+\t\t     UNSPEC_VSX_TSQRT))\n+   (set (match_operand:SI 0 \"gpc_reg_operand\" \"\")\n+\t(gt:SI (match_dup 3)\n+\t       (const_int 0)))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  operands[3] = gen_reg_rtx (CCFPmode);\n+})\n+\n+;; *tsqrt* returning the fe flag\n+(define_expand \"vsx_tsqrt<mode>2_fe\"\n+  [(set (match_dup 3)\n+\t(unspec:CCFP [(match_operand:VSX_B 1 \"vsx_register_operand\" \"\")]\n+\t\t     UNSPEC_VSX_TSQRT))\n+   (set (match_operand:SI 0 \"gpc_reg_operand\" \"\")\n+\t(eq:SI (match_dup 3)\n+\t       (const_int 0)))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  operands[3] = gen_reg_rtx (CCFPmode);\n+})\n+\n+(define_insn \"*vsx_tsqrt<mode>2_internal\"\n+  [(set (match_operand:CCFP 0 \"cc_reg_operand\" \"=x,x\")\n+\t(unspec:CCFP [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t     UNSPEC_VSX_TSQRT))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>tsqrt<VSs> %0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+;; Fused vector multiply/add instructions\n+\n+;; Note we have a pattern for the multiply/add operations that uses unspec and\n+;; does not check -mfused-madd to allow users to use these ops when they know\n+;; they want the fused multiply/add.\n+\n+(define_expand \"vsx_fmadd<mode>4\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"\")\n+\t(plus:VSX_B\n+\t (mult:VSX_B\n+\t  (match_operand:VSX_B 1 \"vsx_register_operand\" \"\")\n+\t  (match_operand:VSX_B 2 \"vsx_register_operand\" \"\"))\n+\t (match_operand:VSX_B 3 \"vsx_register_operand\" \"\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  if (!TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_vsx_fmadd<mode>4_2 (operands[0], operands[1], operands[2],\n+\t\t\t\t\t operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*vsx_fmadd<mode>4_1\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(plus:VSX_B\n+\t (mult:VSX_B\n+\t  (match_operand:VSX_B 1 \"vsx_register_operand\" \"%<VSr>,<VSr>,wa,wa\")\n+\t  (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\"))\n+\t (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode) && TARGET_FUSED_MADD\"\n+  \"@\n+   x<VSv>madda<VSs> %x0,%x1,%x2\n+   x<VSv>maddm<VSs> %x0,%x1,%x3\n+   x<VSv>madda<VSs> %x0,%x1,%x2\n+   x<VSv>maddm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_insn \"vsx_fmadd<mode>4_2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"%<VSr>,<VSr>,wa,wa\")\n+\t\t       (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\")\n+\t\t       (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")]\n+\t\t      UNSPEC_VSX_MADD))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"@\n+   x<VSv>madda<VSs> %x0,%x1,%x2\n+   x<VSv>maddm<VSs> %x0,%x1,%x3\n+   x<VSv>madda<VSs> %x0,%x1,%x2\n+   x<VSv>maddm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_expand \"vsx_fmsub<mode>4\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"\")\n+\t(minus:VSX_B\n+\t (mult:VSX_B\n+\t  (match_operand:VSX_B 1 \"vsx_register_operand\" \"\")\n+\t  (match_operand:VSX_B 2 \"vsx_register_operand\" \"\"))\n+\t (match_operand:VSX_B 3 \"vsx_register_operand\" \"\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  if (!TARGET_FUSED_MADD)\n+    {\n+      emit_insn (gen_vsx_fmsub<mode>4_2 (operands[0], operands[1], operands[2],\n+\t\t\t\t\t operands[3]));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"*vsx_fmsub<mode>4_1\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(minus:VSX_B\n+\t (mult:VSX_B\n+\t  (match_operand:VSX_B 1 \"vsx_register_operand\" \"%<VSr>,<VSr>,wa,wa\")\n+\t  (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\"))\n+\t (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode) && TARGET_FUSED_MADD\"\n+  \"@\n+   x<VSv>msuba<VSs> %x0,%x1,%x2\n+   x<VSv>msubm<VSs> %x0,%x1,%x3\n+   x<VSv>msuba<VSs> %x0,%x1,%x2\n+   x<VSv>msubm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_insn \"vsx_fmsub<mode>4_2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"%<VSr>,<VSr>,wa,wa\")\n+\t\t       (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\")\n+\t\t       (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")]\n+\t\t      UNSPEC_VSX_MSUB))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"@\n+   x<VSv>msuba<VSs> %x0,%x1,%x2\n+   x<VSv>msubm<VSs> %x0,%x1,%x3\n+   x<VSv>msuba<VSs> %x0,%x1,%x2\n+   x<VSv>msubm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_expand \"vsx_fnmadd<mode>4\"\n+  [(match_operand:VSX_B 0 \"vsx_register_operand\" \"\")\n+   (match_operand:VSX_B 1 \"vsx_register_operand\" \"\")\n+   (match_operand:VSX_B 2 \"vsx_register_operand\" \"\")\n+   (match_operand:VSX_B 3 \"vsx_register_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  if (TARGET_FUSED_MADD && HONOR_SIGNED_ZEROS (DFmode))\n+    {\n+       emit_insn (gen_vsx_fnmadd<mode>4_1 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+       DONE;\n+    }\n+  else if (TARGET_FUSED_MADD && !HONOR_SIGNED_ZEROS (DFmode))\n+    {\n+       emit_insn (gen_vsx_fnmadd<mode>4_2 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+       DONE;\n+    }\n+  else\n+    {\n+       emit_insn (gen_vsx_fnmadd<mode>4_3 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+       DONE;\n+    }\n+})\n+\n+(define_insn \"vsx_fnmadd<mode>4_1\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(neg:VSX_B\n+\t (plus:VSX_B\n+\t  (mult:VSX_B\n+\t   (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,<VSr>,wa,wa\")\n+\t   (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\"))\n+\t  (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\"))))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode) && TARGET_FUSED_MADD\n+   && HONOR_SIGNED_ZEROS (DFmode)\"\n+  \"@\n+   x<VSv>nmadda<VSs> %x0,%x1,%x2\n+   x<VSv>nmaddm<VSs> %x0,%x1,%x3\n+   x<VSv>nmadda<VSs> %x0,%x1,%x2\n+   x<VSv>nmaddm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_insn \"vsx_fnmadd<mode>4_2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(minus:VSX_B\n+\t (mult:VSX_B\n+\t  (neg:VSX_B\n+\t   (match_operand:VSX_B 1 \"gpc_reg_operand\" \"<VSr>,<VSr>,wa,wa\"))\n+\t  (match_operand:VSX_B 2 \"gpc_reg_operand\" \"<VSr>,0,wa,0\"))\n+\t (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode) && TARGET_FUSED_MADD\n+   && !HONOR_SIGNED_ZEROS (DFmode)\"\n+  \"@\n+   x<VSv>nmadda<VSs> %x0,%x1,%x2\n+   x<VSv>nmaddm<VSs> %x0,%x1,%x3\n+   x<VSv>nmadda<VSs> %x0,%x1,%x2\n+   x<VSv>nmaddm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_insn \"vsx_fnmadd<mode>4_3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,<VSr>,wa,wa\")\n+\t\t       (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\")\n+\t\t       (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")]\n+\t\t      UNSPEC_VSX_NMADD))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"@\n+   x<VSv>nmadda<VSs> %x0,%x1,%x2\n+   x<VSv>nmaddm<VSs> %x0,%x1,%x3\n+   x<VSv>nmadda<VSs> %x0,%x1,%x2\n+   x<VSv>nmaddm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_expand \"vsx_fnmsub<mode>4\"\n+  [(match_operand:VSX_B 0 \"vsx_register_operand\" \"\")\n+   (match_operand:VSX_B 1 \"vsx_register_operand\" \"\")\n+   (match_operand:VSX_B 2 \"vsx_register_operand\" \"\")\n+   (match_operand:VSX_B 3 \"vsx_register_operand\" \"\")]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+{\n+  if (TARGET_FUSED_MADD && HONOR_SIGNED_ZEROS (DFmode))\n+    {\n+       emit_insn (gen_vsx_fnmsub<mode>4_1 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+       DONE;\n+    }\n+  else if (TARGET_FUSED_MADD && !HONOR_SIGNED_ZEROS (DFmode))\n+    {\n+       emit_insn (gen_vsx_fnmsub<mode>4_2 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+       DONE;\n+    }\n+  else\n+    {\n+       emit_insn (gen_vsx_fnmsub<mode>4_3 (operands[0], operands[1],\n+\t\t\t\t\t   operands[2], operands[3]));\n+       DONE;\n+    }\n+})\n+\n+(define_insn \"vsx_fnmsub<mode>4_1\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(neg:VSX_B\n+\t (minus:VSX_B\n+\t  (mult:VSX_B\n+\t   (match_operand:VSX_B 1 \"vsx_register_operand\" \"%<VSr>,<VSr>,wa,wa\")\n+\t   (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\"))\n+\t  (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\"))))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode) && TARGET_FUSED_MADD\n+   && HONOR_SIGNED_ZEROS (DFmode)\"\n+  \"@\n+   x<VSv>nmsuba<VSs> %x0,%x1,%x2\n+   x<VSv>nmsubm<VSs> %x0,%x1,%x3\n+   x<VSv>nmsuba<VSs> %x0,%x1,%x2\n+   x<VSv>nmsubm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_insn \"vsx_fnmsub<mode>4_2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(minus:VSX_B\n+\t (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")\n+\t (mult:VSX_B\n+\t  (match_operand:VSX_B 1 \"vsx_register_operand\" \"%<VSr>,<VSr>,wa,wa\")\n+\t  (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\"))))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode) && TARGET_FUSED_MADD\n+   && !HONOR_SIGNED_ZEROS (DFmode)\"\n+  \"@\n+   x<VSv>nmsuba<VSs> %x0,%x1,%x2\n+   x<VSv>nmsubm<VSs> %x0,%x1,%x3\n+   x<VSv>nmsuba<VSs> %x0,%x1,%x2\n+   x<VSv>nmsubm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+(define_insn \"vsx_fnmsub<mode>4_3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,<VSr>,?wa,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"%<VSr>,<VSr>,wa,wa\")\n+\t\t       (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,0,wa,0\")\n+\t\t       (match_operand:VSX_B 3 \"vsx_register_operand\" \"0,<VSr>,0,wa\")]\n+\t\t      UNSPEC_VSX_NMSUB))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"@\n+   x<VSv>nmsuba<VSs> %x0,%x1,%x2\n+   x<VSv>nmsubm<VSs> %x0,%x1,%x3\n+   x<VSv>nmsuba<VSs> %x0,%x1,%x2\n+   x<VSv>nmsubm<VSs> %x0,%x1,%x3\"\n+  [(set_attr \"type\" \"<VStype_mul>\")\n+   (set_attr \"fp_type\" \"<VSfptype_mul>\")])\n+\n+;; Vector conditional expressions (no scalar version for these instructions)\n+(define_insn \"vsx_eq<mode>\"\n+  [(set (match_operand:VSX_F 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(eq:VSX_F (match_operand:VSX_F 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t  (match_operand:VSX_F 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"xvcmpeq<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_gt<mode>\"\n+  [(set (match_operand:VSX_F 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(gt:VSX_F (match_operand:VSX_F 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t  (match_operand:VSX_F 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"xvcmpgt<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_ge<mode>\"\n+  [(set (match_operand:VSX_F 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(ge:VSX_F (match_operand:VSX_F 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t  (match_operand:VSX_F 2 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"xvcmpge<VSs> %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+;; Floating point scalar compare\n+(define_insn \"*vsx_cmpdf_internal1\"\n+  [(set (match_operand:CCFP 0 \"cc_reg_operand\" \"=y,?y\")\n+\t(compare:CCFP (match_operand:DF 1 \"gpc_reg_operand\" \"ws,wa\")\n+\t\t      (match_operand:DF 2 \"gpc_reg_operand\" \"ws,wa\")))]\n+  \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n+   && VECTOR_UNIT_VSX_P (DFmode)\"\n+  \"xscmpudp %0,%x1,%x2\"\n+  [(set_attr \"type\" \"fpcompare\")])\n+\n+;; Compare vectors producing a vector result and a predicate, setting CR6 to\n+;; indicate a combined status\n+(define_insn \"*vsx_eq_<mode>_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC\n+\t [(eq:CC (match_operand:VSX_F 1 \"vsx_register_operand\" \"<VSr>,?wa\")\n+\t\t (match_operand:VSX_F 2 \"vsx_register_operand\" \"<VSr>,?wa\"))]\n+\t UNSPEC_PREDICATE))\n+   (set (match_operand:VSX_F 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(eq:VSX_F (match_dup 1)\n+\t\t  (match_dup 2)))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"xvcmpeq<VSs>. %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"veccmp\")])\n+\n+(define_insn \"*vsx_gt_<mode>_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC\n+\t [(gt:CC (match_operand:VSX_F 1 \"vsx_register_operand\" \"<VSr>,?wa\")\n+\t\t (match_operand:VSX_F 2 \"vsx_register_operand\" \"<VSr>,?wa\"))]\n+\t UNSPEC_PREDICATE))\n+   (set (match_operand:VSX_F 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(gt:VSX_F (match_dup 1)\n+\t\t  (match_dup 2)))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"xvcmpgt<VSs>. %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"veccmp\")])\n+\n+(define_insn \"*vsx_ge_<mode>_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC\n+\t [(ge:CC (match_operand:VSX_F 1 \"vsx_register_operand\" \"<VSr>,?wa\")\n+\t\t (match_operand:VSX_F 2 \"vsx_register_operand\" \"<VSr>,?wa\"))]\n+\t UNSPEC_PREDICATE))\n+   (set (match_operand:VSX_F 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(ge:VSX_F (match_dup 1)\n+\t\t  (match_dup 2)))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"xvcmpge<VSs>. %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"veccmp\")])\n+\n+;; Vector select\n+(define_insn \"*vsx_xxsel<mode>\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(if_then_else:VSX_L\n+\t (ne:CC (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t(const_int 0))\n+\t (match_operand:VSX_L 2 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t (match_operand:VSX_L 3 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxsel %x0,%x3,%x2,%x1\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+(define_insn \"*vsx_xxsel<mode>_uns\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(if_then_else:VSX_L\n+\t (ne:CCUNS (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t   (const_int 0))\n+\t (match_operand:VSX_L 2 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t (match_operand:VSX_L 3 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxsel %x0,%x3,%x2,%x1\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; Copy sign\n+(define_insn \"vsx_copysign<mode>3\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(if_then_else:VSX_B\n+\t (ge:VSX_B (match_operand:VSX_B 2 \"vsx_register_operand\" \"<VSr>,wa\")\n+\t\t   (match_operand:VSX_B 3 \"zero_constant\" \"j,j\"))\n+\t (abs:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\"))\n+\t (neg:VSX_B (abs:VSX_B (match_dup 1)))))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>cpsgn<VSs> %x0,%x2,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+;; For the conversions, limit the register class for the integer value to be\n+;; the fprs because we don't want to add the altivec registers to movdi/movsi.\n+;; For the unsigned tests, there isn't a generic double -> unsigned conversion\n+;; in rs6000.md so don't test VECTOR_UNIT_VSX_P, just test against VSX.\n+(define_insn \"vsx_float<VSi><mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(float:VSX_B (match_operand:<VSI> 1 \"vsx_register_operand\" \"<VSr2>,<VSr3>\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>cvsx<VSc><VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_floatuns<VSi><mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unsigned_float:VSX_B (match_operand:<VSI> 1 \"vsx_register_operand\" \"<VSr2>,<VSr3>\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>cvux<VSc><VSs> %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_fix_trunc<mode><VSi>2\"\n+  [(set (match_operand:<VSI> 0 \"vsx_register_operand\" \"=<VSr2>,?<VSr3>\")\n+\t(fix:<VSI> (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>cv<VSs>sx<VSc>s %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_fixuns_trunc<mode><VSi>2\"\n+  [(set (match_operand:<VSI> 0 \"vsx_register_operand\" \"=<VSr2>,?<VSr3>\")\n+\t(unsigned_fix:<VSI> (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>cv<VSs>ux<VSc>s %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+;; Math rounding functions\n+(define_insn \"vsx_x<VSv>r<VSs>i\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t      UNSPEC_VSX_ROUND_I))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>r<VSs>i %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_x<VSv>r<VSs>ic\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t      UNSPEC_VSX_ROUND_IC))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>r<VSs>ic %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_btrunc<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(fix:VSX_B (match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>r<VSs>iz %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"*vsx_b2trunc<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t      UNSPEC_FRIZ))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>r<VSs>iz %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_floor<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t      UNSPEC_FRIM))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>r<VSs>im %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+(define_insn \"vsx_ceil<mode>2\"\n+  [(set (match_operand:VSX_B 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+\t(unspec:VSX_B [(match_operand:VSX_B 1 \"vsx_register_operand\" \"<VSr>,wa\")]\n+\t\t      UNSPEC_FRIP))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"x<VSv>r<VSs>ip %x0,%x1\"\n+  [(set_attr \"type\" \"<VStype_simple>\")\n+   (set_attr \"fp_type\" \"<VSfptype_simple>\")])\n+\n+\f\n+;; VSX convert to/from double vector\n+\n+;; Convert between single and double precision\n+;; Don't use xscvspdp and xscvdpsp for scalar conversions, since the normal\n+;; scalar single precision instructions internally use the double format.\n+;; Prefer the altivec registers, since we likely will need to do a vperm\n+(define_insn \"vsx_<VS_spdp_insn>\"\n+  [(set (match_operand:<VS_spdp_res> 0 \"vsx_register_operand\" \"=<VSr4>,?wa\")\n+\t(unspec:<VS_spdp_res> [(match_operand:VSX_SPDP 1 \"vsx_register_operand\" \"<VSr5>,wa\")]\n+\t\t\t      UNSPEC_VSX_CVSPDP))]\n+  \"VECTOR_UNIT_VSX_P (<MODE>mode)\"\n+  \"<VS_spdp_insn> %x0,%x1\"\n+  [(set_attr \"type\" \"<VS_spdp_type>\")])\n+\n+;; xscvspdp, represent the scalar SF type as V4SF\n+(define_insn \"vsx_xscvspdp\"\n+  [(set (match_operand:DF 0 \"vsx_register_operand\" \"=ws,?wa\")\n+\t(unspec:DF [(match_operand:V4SF 1 \"vsx_register_operand\" \"wa,wa\")]\n+\t\t   UNSPEC_VSX_CVSPDP))]\n+  \"VECTOR_UNIT_VSX_P (DFmode)\"\n+  \"xscvspdp %x0,%x1\"\n+  [(set_attr \"type\" \"fp\")])\n+\n+;; xscvdpsp used for splat'ing a scalar to V4SF, knowing that the internal SF\n+;; format of scalars is actually DF.\n+(define_insn \"vsx_xscvdpsp_scalar\"\n+  [(set (match_operand:V4SF 0 \"vsx_register_operand\" \"=wa\")\n+\t(unspec:V4SF [(match_operand:SF 1 \"vsx_register_operand\" \"f\")]\n+\t\t     UNSPEC_VSX_CVSPDP))]\n+  \"VECTOR_UNIT_VSX_P (DFmode)\"\n+  \"xscvdpsp %x0,%x1\"\n+  [(set_attr \"type\" \"fp\")])\n+\n+;; Convert from 64-bit to 32-bit types\n+;; Note, favor the Altivec registers since the usual use of these instructions\n+;; is in vector converts and we need to use the Altivec vperm instruction.\n+\n+(define_insn \"vsx_xvcvdpsxws\"\n+  [(set (match_operand:V4SI 0 \"vsx_register_operand\" \"=v,?wa\")\n+\t(unspec:V4SI [(match_operand:V2DF 1 \"vsx_register_operand\" \"wd,wa\")]\n+\t\t     UNSPEC_VSX_CVDPSXWS))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvdpsxws %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\n+(define_insn \"vsx_xvcvdpuxws\"\n+  [(set (match_operand:V4SI 0 \"vsx_register_operand\" \"=v,?wa\")\n+\t(unspec:V4SI [(match_operand:V2DF 1 \"vsx_register_operand\" \"wd,wa\")]\n+\t\t     UNSPEC_VSX_CVDPUXWS))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvdpuxws %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\n+(define_insn \"vsx_xvcvsxdsp\"\n+  [(set (match_operand:V4SI 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:V4SI [(match_operand:V2DF 1 \"vsx_register_operand\" \"wf,wa\")]\n+\t\t     UNSPEC_VSX_CVSXDSP))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvsxdsp %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\n+(define_insn \"vsx_xvcvuxdsp\"\n+  [(set (match_operand:V4SI 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:V4SI [(match_operand:V2DF 1 \"vsx_register_operand\" \"wf,wa\")]\n+\t\t     UNSPEC_VSX_CVUXDSP))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvuxwdp %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\n+;; Convert from 32-bit to 64-bit types\n+(define_insn \"vsx_xvcvsxwdp\"\n+  [(set (match_operand:V2DF 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:V2DF [(match_operand:V4SI 1 \"vsx_register_operand\" \"wf,wa\")]\n+\t\t     UNSPEC_VSX_CVSXWDP))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvsxwdp %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\n+(define_insn \"vsx_xvcvuxwdp\"\n+  [(set (match_operand:V2DF 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:V2DF [(match_operand:V4SI 1 \"vsx_register_operand\" \"wf,wa\")]\n+\t\t     UNSPEC_VSX_CVUXWDP))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvuxwdp %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\n+(define_insn \"vsx_xvcvspsxds\"\n+  [(set (match_operand:V2DI 0 \"vsx_register_operand\" \"=v,?wa\")\n+\t(unspec:V2DI [(match_operand:V4SF 1 \"vsx_register_operand\" \"wd,wa\")]\n+\t\t     UNSPEC_VSX_CVSPSXDS))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvspsxds %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\n+(define_insn \"vsx_xvcvspuxds\"\n+  [(set (match_operand:V2DI 0 \"vsx_register_operand\" \"=v,?wa\")\n+\t(unspec:V2DI [(match_operand:V4SF 1 \"vsx_register_operand\" \"wd,wa\")]\n+\t\t     UNSPEC_VSX_CVSPUXDS))]\n+  \"VECTOR_UNIT_VSX_P (V2DFmode)\"\n+  \"xvcvspuxds %x0,%x1\"\n+  [(set_attr \"type\" \"vecfloat\")])\n+\f\n+;; Logical and permute operations\n+(define_insn \"*vsx_and<mode>3\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (and:VSX_L\n+\t (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,?wa\")\n+\t (match_operand:VSX_L 2 \"vsx_register_operand\" \"<VSr>,?wa\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxland %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"vecsimple\")])\n+\n+(define_insn \"*vsx_ior<mode>3\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (ior:VSX_L (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,?wa\")\n+\t\t   (match_operand:VSX_L 2 \"vsx_register_operand\" \"<VSr>,?wa\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxlor %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"vecsimple\")])\n+\n+(define_insn \"*vsx_xor<mode>3\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (xor:VSX_L\n+\t (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,?wa\")\n+\t (match_operand:VSX_L 2 \"vsx_register_operand\" \"<VSr>,?wa\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxlxor %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"vecsimple\")])\n+\n+(define_insn \"*vsx_one_cmpl<mode>2\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (not:VSX_L\n+\t (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,?wa\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxlnor %x0,%x1,%x1\"\n+  [(set_attr \"type\" \"vecsimple\")])\n+  \n+(define_insn \"*vsx_nor<mode>3\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (not:VSX_L\n+\t (ior:VSX_L\n+\t  (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,?wa\")\n+\t  (match_operand:VSX_L 2 \"vsx_register_operand\" \"<VSr>,?wa\"))))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxlnor %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"vecsimple\")])\n+\n+(define_insn \"*vsx_andc<mode>3\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=<VSr>,?wa\")\n+        (and:VSX_L\n+\t (not:VSX_L\n+\t  (match_operand:VSX_L 2 \"vsx_register_operand\" \"<VSr>,?wa\"))\n+\t (match_operand:VSX_L 1 \"vsx_register_operand\" \"<VSr>,?wa\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxlandc %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"vecsimple\")])\n+\n+\f\n+;; Permute operations\n+\n+;; Build a V2DF/V2DI vector from two scalars\n+(define_insn \"vsx_concat_<mode>\"\n+  [(set (match_operand:VSX_D 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:VSX_D\n+\t [(match_operand:<VS_scalar> 1 \"vsx_register_operand\" \"ws,wa\")\n+\t  (match_operand:<VS_scalar> 2 \"vsx_register_operand\" \"ws,wa\")]\n+\t UNSPEC_VSX_CONCAT))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxpermdi %x0,%x1,%x2,0\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; Special purpose concat using xxpermdi to glue two single precision values\n+;; together, relying on the fact that internally scalar floats are represented\n+;; as doubles.  This is used to initialize a V4SF vector with 4 floats\n+(define_insn \"vsx_concat_v2sf\"\n+  [(set (match_operand:V2DF 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:V2DF\n+\t [(match_operand:SF 1 \"vsx_register_operand\" \"f,f\")\n+\t  (match_operand:SF 2 \"vsx_register_operand\" \"f,f\")]\n+\t UNSPEC_VSX_CONCAT))]\n+  \"VECTOR_MEM_VSX_P (V2DFmode)\"\n+  \"xxpermdi %x0,%x1,%x2,0\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; Set the element of a V2DI/VD2F mode\n+(define_insn \"vsx_set_<mode>\"\n+  [(set (match_operand:VSX_D 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:VSX_D [(match_operand:VSX_D 1 \"vsx_register_operand\" \"wd,wa\")\n+\t\t       (match_operand:<VS_scalar> 2 \"vsx_register_operand\" \"ws,wa\")\n+\t\t       (match_operand:QI 3 \"u5bit_cint_operand\" \"i,i\")]\n+\t\t      UNSPEC_VSX_SET))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+{\n+  if (INTVAL (operands[3]) == 0)\n+    return \\\"xxpermdi %x0,%x1,%x2,1\\\";\n+  else if (INTVAL (operands[3]) == 1)\n+    return \\\"xxpermdi %x0,%x2,%x1,0\\\";\n+  else\n+    gcc_unreachable ();\n+}\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; Extract a DF/DI element from V2DF/V2DI\n+(define_insn \"vsx_extract_<mode>\"\n+  [(set (match_operand:<VS_scalar> 0 \"vsx_register_operand\" \"=ws,d,?wa\")\n+\t(vec_select:<VS_scalar> (match_operand:VSX_D 1 \"vsx_register_operand\" \"wd,wd,wa\")\n+\t\t       (parallel\n+\t\t\t[(match_operand:QI 2 \"u5bit_cint_operand\" \"i,i,i\")])))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+{\n+  gcc_assert (UINTVAL (operands[2]) <= 1);\n+  operands[3] = GEN_INT (INTVAL (operands[2]) << 1);\n+  return \\\"xxpermdi %x0,%x1,%x1,%3\\\";\n+}\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; Optimize extracting element 0 from memory\n+(define_insn \"*vsx_extract_<mode>_zero\"\n+  [(set (match_operand:<VS_scalar> 0 \"vsx_register_operand\" \"=ws,d,?wa\")\n+\t(vec_select:<VS_scalar>\n+\t (match_operand:VSX_D 1 \"indexed_or_indirect_operand\" \"Z,Z,Z\")\n+\t (parallel [(const_int 0)])))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode) && WORDS_BIG_ENDIAN\"\n+  \"lxsd%U1x %x0,%y1\"\n+  [(set_attr \"type\" \"fpload\")\n+   (set_attr \"length\" \"4\")])  \n+\n+;; General double word oriented permute, allow the other vector types for\n+;; optimizing the permute instruction.\n+(define_insn \"vsx_xxpermdi_<mode>\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=wd,?wa\")\n+\t(unspec:VSX_L [(match_operand:VSX_L 1 \"vsx_register_operand\" \"wd,wa\")\n+\t\t       (match_operand:VSX_L 2 \"vsx_register_operand\" \"wd,wa\")\n+\t\t       (match_operand:QI 3 \"u5bit_cint_operand\" \"i,i\")]\n+\t\t      UNSPEC_VSX_XXPERMDI))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxpermdi %x0,%x1,%x2,%3\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; Varient of xxpermdi that is emitted by the vec_interleave functions\n+(define_insn \"*vsx_xxpermdi2_<mode>\"\n+  [(set (match_operand:VSX_D 0 \"vsx_register_operand\" \"=wd\")\n+\t(vec_concat:VSX_D\n+\t (vec_select:<VS_scalar>\n+\t  (match_operand:VSX_D 1 \"vsx_register_operand\" \"wd\")\n+\t  (parallel\n+\t   [(match_operand:QI 2 \"u5bit_cint_operand\" \"i\")]))\n+\t (vec_select:<VS_scalar>\n+\t  (match_operand:VSX_D 3 \"vsx_register_operand\" \"wd\")\n+\t  (parallel\n+\t   [(match_operand:QI 4 \"u5bit_cint_operand\" \"i\")]))))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+{\n+  gcc_assert ((UINTVAL (operands[2]) <= 1) && (UINTVAL (operands[4]) <= 1));\n+  operands[5] = GEN_INT (((INTVAL (operands[2]) & 1) << 1)\n+\t\t\t | (INTVAL (operands[4]) & 1));\n+  return \\\"xxpermdi %x0,%x1,%x3,%5\\\";\n+}\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; V2DF/V2DI splat\n+(define_insn \"vsx_splat_<mode>\"\n+  [(set (match_operand:VSX_D 0 \"vsx_register_operand\" \"=wd,wd,wd,?wa,?wa,?wa\")\n+\t(vec_duplicate:VSX_D\n+\t (match_operand:<VS_scalar> 1 \"input_operand\" \"ws,f,Z,wa,wa,Z\")))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"@\n+   xxpermdi %x0,%x1,%x1,0\n+   xxpermdi %x0,%x1,%x1,0\n+   lxvdsx %x0,%y1\n+   xxpermdi %x0,%x1,%x1,0\n+   xxpermdi %x0,%x1,%x1,0\n+   lxvdsx %x0,%y1\"\n+  [(set_attr \"type\" \"vecperm,vecperm,vecload,vecperm,vecperm,vecload\")])\n+\n+;; V4SF/V4SI splat\n+(define_insn \"vsx_xxspltw_<mode>\"\n+  [(set (match_operand:VSX_W 0 \"vsx_register_operand\" \"=wf,?wa\")\n+\t(vec_duplicate:VSX_W\n+\t (vec_select:<VS_scalar>\n+\t  (match_operand:VSX_W 1 \"vsx_register_operand\" \"wf,wa\")\n+\t  (parallel\n+\t   [(match_operand:QI 2 \"u5bit_cint_operand\" \"i,i\")]))))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxspltw %x0,%x1,%2\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; V4SF/V4SI interleave\n+(define_insn \"vsx_xxmrghw_<mode>\"\n+  [(set (match_operand:VSX_W 0 \"vsx_register_operand\" \"=wf,?wa\")\n+        (vec_merge:VSX_W\n+\t (vec_select:VSX_W\n+\t  (match_operand:VSX_W 1 \"vsx_register_operand\" \"wf,wa\")\n+\t  (parallel [(const_int 0)\n+\t\t     (const_int 2)\n+\t\t     (const_int 1)\n+\t\t     (const_int 3)]))\n+\t (vec_select:VSX_W\n+\t  (match_operand:VSX_W 2 \"vsx_register_operand\" \"wf,wa\")\n+\t  (parallel [(const_int 2)\n+\t\t     (const_int 0)\n+\t\t     (const_int 3)\n+\t\t     (const_int 1)]))\n+\t (const_int 5)))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxmrghw %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+(define_insn \"vsx_xxmrglw_<mode>\"\n+  [(set (match_operand:VSX_W 0 \"vsx_register_operand\" \"=wf,?wa\")\n+        (vec_merge:VSX_W\n+\t (vec_select:VSX_W\n+\t  (match_operand:VSX_W 1 \"vsx_register_operand\" \"wf,wa\")\n+\t  (parallel [(const_int 2)\n+\t\t     (const_int 0)\n+\t\t     (const_int 3)\n+\t\t     (const_int 1)]))\n+\t (vec_select:VSX_W\n+\t  (match_operand:VSX_W 2 \"vsx_register_operand\" \"wf,?wa\")\n+\t  (parallel [(const_int 0)\n+\t\t     (const_int 2)\n+\t\t     (const_int 1)\n+\t\t     (const_int 3)]))\n+\t (const_int 5)))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxmrglw %x0,%x1,%x2\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+;; Shift left double by word immediate\n+(define_insn \"vsx_xxsldwi_<mode>\"\n+  [(set (match_operand:VSX_L 0 \"vsx_register_operand\" \"=wa\")\n+\t(unspec:VSX_L [(match_operand:VSX_L 1 \"vsx_register_operand\" \"wa\")\n+\t\t       (match_operand:VSX_L 2 \"vsx_register_operand\" \"wa\")\n+\t\t       (match_operand:QI 3 \"u5bit_cint_operand\" \"i\")]\n+\t\t      UNSPEC_VSX_SLDWI))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"xxsldwi %x0,%x1,%x2,%3\"\n+  [(set_attr \"type\" \"vecperm\")])"}, {"sha": "b545c328e2cb2051c2cac57b867f2688f71ef8c5", "filename": "gcc/doc/extend.texi", "status": "modified", "additions": 103, "deletions": 2, "changes": 105, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fdoc%2Fextend.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fdoc%2Fextend.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fextend.texi?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -7298,7 +7298,7 @@ instructions, but allow the compiler to schedule those calls.\n * MIPS Loongson Built-in Functions::\n * Other MIPS Built-in Functions::\n * picoChip Built-in Functions::\n-* PowerPC AltiVec Built-in Functions::\n+* PowerPC AltiVec/VSX Built-in Functions::\n * SPARC VIS Built-in Functions::\n * SPU Built-in Functions::\n @end menu\n@@ -9776,7 +9776,7 @@ GCC defines the preprocessor macro @code{___GCC_HAVE_BUILTIN_MIPS_CACHE}\n when this function is available.\n @end table\n \n-@node PowerPC AltiVec Built-in Functions\n+@node PowerPC AltiVec/VSX Built-in Functions\n @subsection PowerPC AltiVec Built-in Functions\n \n GCC provides an interface for the PowerPC family of processors to access\n@@ -9802,6 +9802,19 @@ vector bool int\n vector float\n @end smallexample\n \n+If @option{-mvsx} is used the following additional vector types are\n+implemented.\n+\n+@smallexample\n+vector unsigned long\n+vector signed long\n+vector double\n+@end smallexample\n+\n+The long types are only implemented for 64-bit code generation, and\n+the long type is only used in the floating point/integer conversion\n+instructions.\n+\n GCC's implementation of the high-level language interface available from\n C and C++ code differs from Motorola's documentation in several ways.\n \n@@ -10067,6 +10080,8 @@ vector signed char vec_vavgsb (vector signed char, vector signed char);\n vector unsigned char vec_vavgub (vector unsigned char,\n                                  vector unsigned char);\n \n+vector float vec_copysign (vector float);\n+\n vector float vec_ceil (vector float);\n \n vector signed int vec_cmpb (vector float, vector float);\n@@ -11669,6 +11684,92 @@ int vec_any_numeric (vector float);\n int vec_any_out (vector float, vector float);\n @end smallexample\n \n+If the vector/scalar (VSX) instruction set is available, the following\n+additional functions are available:\n+\n+@smallexample\n+vector double vec_abs (vector double);\n+vector double vec_add (vector double, vector double);\n+vector double vec_and (vector double, vector double);\n+vector double vec_and (vector double, vector bool long);\n+vector double vec_and (vector bool long, vector double);\n+vector double vec_andc (vector double, vector double);\n+vector double vec_andc (vector double, vector bool long);\n+vector double vec_andc (vector bool long, vector double);\n+vector double vec_ceil (vector double);\n+vector bool long vec_cmpeq (vector double, vector double);\n+vector bool long vec_cmpge (vector double, vector double);\n+vector bool long vec_cmpgt (vector double, vector double);\n+vector bool long vec_cmple (vector double, vector double);\n+vector bool long vec_cmplt (vector double, vector double);\n+vector float vec_div (vector float, vector float);\n+vector double vec_div (vector double, vector double);\n+vector double vec_floor (vector double);\n+vector double vec_madd (vector double, vector double, vector double);\n+vector double vec_max (vector double, vector double);\n+vector double vec_min (vector double, vector double);\n+vector float vec_msub (vector float, vector float, vector float);\n+vector double vec_msub (vector double, vector double, vector double);\n+vector float vec_mul (vector float, vector float);\n+vector double vec_mul (vector double, vector double);\n+vector float vec_nearbyint (vector float);\n+vector double vec_nearbyint (vector double);\n+vector float vec_nmadd (vector float, vector float, vector float);\n+vector double vec_nmadd (vector double, vector double, vector double);\n+vector double vec_nmsub (vector double, vector double, vector double);\n+vector double vec_nor (vector double, vector double);\n+vector double vec_or (vector double, vector double);\n+vector double vec_or (vector double, vector bool long);\n+vector double vec_or (vector bool long, vector double);\n+vector double vec_perm (vector double,\n+                        vector double,\n+                        vector unsigned char);\n+vector float vec_rint (vector float);\n+vector double vec_rint (vector double);\n+vector double vec_sel (vector double, vector double, vector bool long);\n+vector double vec_sel (vector double, vector double, vector unsigned long);\n+vector double vec_sub (vector double, vector double);\n+vector float vec_sqrt (vector float);\n+vector double vec_sqrt (vector double);\n+vector double vec_trunc (vector double);\n+vector double vec_xor (vector double, vector double);\n+vector double vec_xor (vector double, vector bool long);\n+vector double vec_xor (vector bool long, vector double);\n+int vec_all_eq (vector double, vector double);\n+int vec_all_ge (vector double, vector double);\n+int vec_all_gt (vector double, vector double);\n+int vec_all_le (vector double, vector double);\n+int vec_all_lt (vector double, vector double);\n+int vec_all_nan (vector double);\n+int vec_all_ne (vector double, vector double);\n+int vec_all_nge (vector double, vector double);\n+int vec_all_ngt (vector double, vector double);\n+int vec_all_nle (vector double, vector double);\n+int vec_all_nlt (vector double, vector double);\n+int vec_all_numeric (vector double);\n+int vec_any_eq (vector double, vector double);\n+int vec_any_ge (vector double, vector double);\n+int vec_any_gt (vector double, vector double);\n+int vec_any_le (vector double, vector double);\n+int vec_any_lt (vector double, vector double);\n+int vec_any_nan (vector double);\n+int vec_any_ne (vector double, vector double);\n+int vec_any_nge (vector double, vector double);\n+int vec_any_ngt (vector double, vector double);\n+int vec_any_nle (vector double, vector double);\n+int vec_any_nlt (vector double, vector double);\n+int vec_any_numeric (vector double);\n+@end smallexample\n+\n+GCC provides a few other builtins on Powerpc to access certain instructions:\n+@smallexample\n+float __builtin_recipdivf (float, float);\n+float __builtin_rsqrtf (float);\n+double __builtin_recipdiv (double, double);\n+long __builtin_bpermd (long, long);\n+int __builtin_bswap16 (int);\n+@end smallexample\n+\n @node SPARC VIS Built-in Functions\n @subsection SPARC VIS Built-in Functions\n "}, {"sha": "fe24b9850d55c6df82e457b879acf3fa78b0ed7f", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 20, "deletions": 4, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -738,7 +738,8 @@ See RS/6000 and PowerPC Options.\n -maltivec  -mno-altivec @gol\n -mpowerpc-gpopt  -mno-powerpc-gpopt @gol\n -mpowerpc-gfxopt  -mno-powerpc-gfxopt @gol\n--mmfcrf  -mno-mfcrf  -mpopcntb  -mno-popcntb  -mfprnd  -mno-fprnd @gol\n+-mmfcrf  -mno-mfcrf  -mpopcntb  -mno-popcntb -mpopcntd -mno-popcntd @gol\n+-mfprnd  -mno-fprnd @gol\n -mcmpb -mno-cmpb -mmfpgpr -mno-mfpgpr -mhard-dfp -mno-hard-dfp @gol\n -mnew-mnemonics  -mold-mnemonics @gol\n -mfull-toc   -mminimal-toc  -mno-fp-in-toc  -mno-sum-in-toc @gol\n@@ -752,7 +753,7 @@ See RS/6000 and PowerPC Options.\n -mstrict-align  -mno-strict-align  -mrelocatable @gol\n -mno-relocatable  -mrelocatable-lib  -mno-relocatable-lib @gol\n -mtoc  -mno-toc  -mlittle  -mlittle-endian  -mbig  -mbig-endian @gol\n--mdynamic-no-pic  -maltivec  -mswdiv @gol\n+-mdynamic-no-pic  -maltivec -mswdiv @gol\n -mprioritize-restricted-insns=@var{priority} @gol\n -msched-costly-dep=@var{dependence_type} @gol\n -minsert-sched-nops=@var{scheme} @gol\n@@ -14116,6 +14117,8 @@ These @samp{-m} options are defined for the IBM RS/6000 and PowerPC:\n @itemx -mno-mfcrf\n @itemx -mpopcntb\n @itemx -mno-popcntb\n+@itemx -mpopcntd\n+@itemx -mno-popcntd\n @itemx -mfprnd\n @itemx -mno-fprnd\n @itemx -mcmpb\n@@ -14140,6 +14143,8 @@ These @samp{-m} options are defined for the IBM RS/6000 and PowerPC:\n @opindex mno-mfcrf\n @opindex mpopcntb\n @opindex mno-popcntb\n+@opindex mpopcntd\n+@opindex mno-popcntd\n @opindex mfprnd\n @opindex mno-fprnd\n @opindex mcmpb\n@@ -14189,6 +14194,9 @@ The @option{-mpopcntb} option allows GCC to generate the popcount and\n double precision FP reciprocal estimate instruction implemented on the\n POWER5 processor and other processors that support the PowerPC V2.02\n architecture.\n+The @option{-mpopcntd} option allows GCC to generate the popcount\n+instruction implemented on the POWER7 processor and other processors\n+that support the PowerPC V2.06 architecture.\n The @option{-mfprnd} option allows GCC to generate the FP round to\n integer instructions implemented on the POWER5+ processor and other\n processors that support the PowerPC V2.03 architecture.\n@@ -14267,9 +14275,9 @@ The @option{-mcpu} options automatically enable or disable the\n following options:\n \n @gccoptlist{-maltivec  -mfprnd  -mhard-float  -mmfcrf  -mmultiple @gol\n--mnew-mnemonics  -mpopcntb  -mpower  -mpower2  -mpowerpc64 @gol\n+-mnew-mnemonics  -mpopcntb -mpopcntd  -mpower  -mpower2  -mpowerpc64 @gol\n -mpowerpc-gpopt  -mpowerpc-gfxopt  -msingle-float -mdouble-float @gol\n--msimple-fpu -mstring  -mmulhw  -mdlmzb  -mmfpgpr}\n+-msimple-fpu -mstring  -mmulhw  -mdlmzb  -mmfpgpr -mvsx}\n \n The particular options set for any particular CPU will vary between\n compiler versions, depending on what setting seems to produce optimal\n@@ -14370,6 +14378,14 @@ instructions.\n This option has been deprecated.  Use @option{-mspe} and\n @option{-mno-spe} instead.\n \n+@item -mvsx\n+@itemx -mno-vsx\n+@opindex mvsx\n+@opindex mno-vsx\n+Generate code that uses (does not use) vector/scalar (VSX)\n+instructions, and also enable the use of built-in functions that allow\n+more direct access to the VSX instruction set.\n+\n @item -mfloat-gprs=@var{yes/single/double/no}\n @itemx -mfloat-gprs\n @opindex mfloat-gprs"}, {"sha": "0e516b09fc07547a3df06b5e3de5ff8b1de2ef60", "filename": "gcc/doc/md.texi", "status": "modified", "additions": 16, "deletions": 1, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fdoc%2Fmd.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Fdoc%2Fmd.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fmd.texi?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -1916,7 +1916,19 @@ Floating point register (containing 64-bit value)\n Floating point register (containing 32-bit value)\n \n @item v\n-Vector register\n+Altivec vector register\n+\n+@item wd\n+VSX vector register to hold vector double data\n+\n+@item wf\n+VSX vector register to hold vector float data\n+\n+@item ws\n+VSX vector register to hold scalar float data\n+\n+@item wa\n+Any VSX register\n \n @item h\n @samp{MQ}, @samp{CTR}, or @samp{LINK} register\n@@ -2029,6 +2041,9 @@ AND masks that can be performed by two rldic@{l, r@} instructions\n @item W\n Vector constant that does not require memory\n \n+@item j\n+Vector constant that is all zeros.\n+\n @end table\n \n @item Intel 386---@file{config/i386/constraints.md}"}, {"sha": "4466ec78bd591e7296ef310e98c5b830cf66d4e7", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -1,3 +1,53 @@\n+2009-07-30  Michael Meissner  <meissner@linux.vnet.ibm.com>\n+\t    Pat Haugen  <pthaugen@us.ibm.com>\n+\t    Revital Eres <ERES@il.ibm.com>\n+\n+\t* testsuite/gcc.target/powerpc/altivec-32.c: New file to test\n+\tAltivec simple math function vectorization.\n+\n+\t* testsuite/gcc.target/powerpc/bswap-run.c: New file to test swap\n+\tbuiltins.\n+\t* testsuite/gcc.target/powerpc/bswap16.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/bswap32.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/bswap64-1.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/bswap64-2.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/bswap64-3.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/optimize-bswapdi-2.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/optimize-bswapdi-3.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/optimize-bswapsi-2.c: Ditto.\n+\n+\t* testsuite/gcc.target/powerpc/popcount-2.c: New file to test\n+\tpower7 popcntd instructions.\n+\t* testsuite/gcc.target/powerpc/popcount-3.c: Ditto.\n+\n+\t* testsuite/gcc.target/powerpc/pr39457.c: New VSX test.\n+\t* testsuite/gcc.target/powerpc/vsx-builtin-1.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-builtin-2.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-builtin-3.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-builtin-4.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-builtin-5.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-builtin-6.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-vector-1.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-vector-2.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-vector-3.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-vector-4.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-vector-5.c: Ditto.\n+\t* testsuite/gcc.target/powerpc/vsx-vector-6.c: Ditto.\n+\n+\t* testsuite/gcc.target/powerpc/altivec-6.c: Store the result of\n+\tvec_add, so the optimizer doesn't remove it.\n+\n+\t* testsuite/gcc.dg/optimize-bswapdi-1.c: Add powerpc 64-bit to\n+\tsystems that support bswap64.\n+\n+\t* testsuite/gcc.dg/vmx/vmx.exp: Explicitly add -mno-vsx to\n+\tprevent VSX code generation.\n+\n+\t* testsuite/lib/target-supports.exp (check_vsx_hw_available): New\n+\tfunction to test if VSX available.\n+\t(check_effective_target_powerpc_vsx_ok): Ditto.\n+\t(check_vmx_hw_available): Add explicit -mno-vsx.\n+\n 2009-07-30  Janis Johnson  <janis187@us.ibm.com>\n \n \tPR c/39902"}, {"sha": "a6aea4a7846830fb607f5f832039328513787fb4", "filename": "gcc/testsuite/gcc.dg/optimize-bswapdi-1.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.dg%2Foptimize-bswapdi-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.dg%2Foptimize-bswapdi-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Foptimize-bswapdi-1.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -1,4 +1,4 @@\n-/* { dg-do compile { target alpha*-*-* ia64*-*-* x86_64-*-* s390x-*-* } } */\n+/* { dg-do compile { target alpha*-*-* ia64*-*-* x86_64-*-* s390x-*-* powerpc*-*-* rs6000-*-* } } */\n /* { dg-require-effective-target stdint_types } */\n /* { dg-require-effective-target lp64 } */\n /* { dg-options \"-O2 -fdump-tree-bswap\" } */"}, {"sha": "85c88d8a3923b1a7d49a51beccd52c0b58f254d7", "filename": "gcc/testsuite/gcc.dg/vmx/vmx.exp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.dg%2Fvmx%2Fvmx.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.dg%2Fvmx%2Fvmx.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvmx%2Fvmx.exp?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -31,7 +31,7 @@ if {![istarget powerpc*-*-*]\n # nothing but extensions.\n global DEFAULT_VMXCFLAGS\n if ![info exists DEFAULT_VMXCFLAGS] then {\n-    set DEFAULT_VMXCFLAGS \"-maltivec -mabi=altivec -std=gnu99\"\n+    set DEFAULT_VMXCFLAGS \"-maltivec -mabi=altivec -std=gnu99 -mno-vsx\"\n }\n \n # If the target system supports AltiVec instructions, the default action"}, {"sha": "83105f89a504ee75bc11e9eebf26f8cdc1c689b1", "filename": "gcc/testsuite/gcc.target/powerpc/altivec-32.c", "status": "added", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Faltivec-32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Faltivec-32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Faltivec-32.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,59 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_altivec_ok } */\n+/* { dg-options \"-O2 -ftree-vectorize -mcpu=power6 -m64 -maltivec\" } */\n+/* { dg-final { scan-assembler \"vsel\" } } */\n+/* { dg-final { scan-assembler \"vrfim\" } } */\n+/* { dg-final { scan-assembler \"vrfip\" } } */\n+/* { dg-final { scan-assembler \"vrfiz\" } } */\n+\n+#ifndef SIZE\n+#define SIZE 1024\n+#endif\n+\n+float a[SIZE] __attribute__((__aligned__(32)));\n+float b[SIZE] __attribute__((__aligned__(32)));\n+float c[SIZE] __attribute__((__aligned__(32)));\n+float d[SIZE] __attribute__((__aligned__(32)));\n+float e[SIZE] __attribute__((__aligned__(32)));\n+\n+extern float floorf (float);\n+extern float ceilf (float);\n+extern float truncf (float);\n+extern float copysignf (float, float);\n+\n+void\n+vector_floor (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = floorf (b[i]);\n+}\n+\n+void\n+vector_ceil (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = ceilf (b[i]);\n+}\n+\n+void\n+vector_trunc (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = truncf (b[i]);\n+}\n+\n+void\n+vector_copysign (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = copysignf (b[i], c[i]);\n+}"}, {"sha": "51d411688fb51caf4a3476384db131e686b94728", "filename": "gcc/testsuite/gcc.target/powerpc/altivec-6.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Faltivec-6.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Faltivec-6.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Faltivec-6.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -5,7 +5,7 @@\n #include <altivec.h>\n \n /* These denote \"generic\" GCC vectors.  */\n-static int __attribute__((vector_size(16))) x, y;\n+static int __attribute__((vector_size(16))) x, y, z;\n \n static vector signed int i,j;\n static vector signed short s,t;\n@@ -21,7 +21,7 @@ static int int1, int2;\n void\n b()\n {\n-  vec_add (x, y);\n+  z = vec_add (x, y);\n \n   /* Make sure the predicates accept correct argument types.  */\n "}, {"sha": "484908a816723ad571a4f086cefc8c4aebbf38e3", "filename": "gcc/testsuite/gcc.target/powerpc/bswap-run.c", "status": "added", "additions": 102, "deletions": 0, "changes": 102, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap-run.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap-run.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap-run.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,102 @@\n+/* { dg-do run { target powerpc*-*-* } } */\n+/* { dg-options \"-O2 -std=gnu99\" } */\n+\n+extern void abort (void);\n+\n+static unsigned char bytes[] = { 0, 1, 2, 0x80, 0xff };\n+\n+unsigned short b16a (unsigned short *p) { return __builtin_bswap16 (*p); }\n+void b16b (unsigned short *p, unsigned short a) { *p = __builtin_bswap16 (a); }\n+int b16c (unsigned short a) { return __builtin_bswap16 (a); }\n+\n+unsigned int b32a (unsigned int *p) { return __builtin_bswap32 (*p); }\n+void b32b (unsigned int *p, unsigned int a) { *p = __builtin_bswap32 (a); }\n+static unsigned int b32c (unsigned int a) { return __builtin_bswap32 (a); }\n+\n+unsigned long long b64a (unsigned long long *p) { return __builtin_bswap64 (*p); }\n+void b64b (unsigned long long *p, unsigned long long a) { *p = __builtin_bswap64 (a); }\n+unsigned long long b64c (unsigned long long a) { return __builtin_bswap64 (a); }\n+\n+int\n+main (void)\n+{\n+  unsigned i1, i2, i3, i4, i5;\n+  unsigned b1, b2, b3, b4, b5;\n+  unsigned short b16_inp, b16_exp, b16_var;\n+  unsigned int b32_inp, b32_exp, b32_var;\n+  unsigned long long b64_inp, b64_exp, b64_var;\n+\n+  for (i1 = 0; i1 < sizeof (bytes); i1++)\n+    {\n+      b1 = bytes[i1];\n+      for (i2 = 0; i2 < sizeof (bytes); i2++)\n+\t{\n+\t  b2 = bytes[i2];\n+\t  b16_inp = (b1 << 8) | b2;\n+\t  b16_exp = (b2 << 8) | b1;\n+\n+\t  if (b16a (&b16_inp) != b16_exp)\n+\t    abort ();\n+\n+\t  b16b (&b16_var, b16_inp);\n+\t  if (b16_var != b16_exp)\n+\t    abort ();\n+\n+\t  if (b16c (b16_inp) != b16_exp)\n+\t    abort ();\n+\n+\t  for (i3 = 0; i3 < sizeof (bytes); i3++)\n+\t    {\n+\t      b3 = bytes[i3];\n+\t      for (i4 = 0; i4 < sizeof (bytes); i4++)\n+\t\t{\n+\t\t  b4 = bytes[i4];\n+\t\t  b32_inp = (b1 << 24) | (b2 << 16) | (b3 << 8) | b4;\n+\t\t  b32_exp = (b4 << 24) | (b3 << 16) | (b2 << 8) | b1;\n+\n+\t\t  if (b32a (&b32_inp) != b32_exp)\n+\t\t    abort ();\n+\n+\t\t  b32b (&b32_var, b32_inp);\n+\t\t  if (b32_var != b32_exp)\n+\t\t    abort ();\n+\n+\t\t  if (b32c (b32_inp) != b32_exp)\n+\t\t    abort ();\n+\n+\t\t  for (i5 = 0; i5 < sizeof (bytes); i5++)\n+\t\t    {\n+\t\t      b5 = bytes[i5];\n+\t\t      b64_inp = (((unsigned long long)b32_inp) << 32) | b5;\n+\t\t      b64_exp = (((unsigned long long)b5) << 56) | b32_exp;\n+\n+\t\t      if (b64a (&b64_inp) != b64_exp)\n+\t\t\tabort ();\n+\n+\t\t      b64b (&b64_var, b64_inp);\n+\t\t      if (b64_var != b64_exp)\n+\t\t\tabort ();\n+\n+\t\t      if (b64c (b64_inp) != b64_exp)\n+\t\t\tabort ();\n+\n+\t\t      b64_inp = (((unsigned long long)b5) << 56) | b32_inp;\n+\t\t      b64_exp = (((unsigned long long)b32_exp) << 32) | b5;\n+\n+\t\t      if (b64a (&b64_inp) != b64_exp)\n+\t\t\tabort ();\n+\n+\t\t      b64b (&b64_var, b64_inp);\n+\t\t      if (b64_var != b64_exp)\n+\t\t\tabort ();\n+\n+\t\t      if (b64c (b64_inp) != b64_exp)\n+\t\t\tabort ();\n+\t\t    }\n+\t\t}\n+\t    }\n+\t}\n+    }\n+\n+  return 0;\n+}"}, {"sha": "5eea4f77491b976ceb95dbf48a74b182e2b3cf46", "filename": "gcc/testsuite/gcc.target/powerpc/bswap16.c", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap16.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap16.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap16.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,8 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-options \"-O2\" } */\n+/* { dg-final { scan-assembler \"lhbrx\" } } */\n+/* { dg-final { scan-assembler \"sthbrx\" } } */\n+\n+unsigned short us;\n+unsigned int load_bswap16 (unsigned short *p) { return __builtin_bswap16 (*p); }\n+void store_bswap16 (unsigned int a) { us = __builtin_bswap16 (a); }"}, {"sha": "1b1e189aafa1d0243672a4701d47388519dd2fe2", "filename": "gcc/testsuite/gcc.target/powerpc/bswap32.c", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap32.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,8 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-options \"-O2\" } */\n+/* { dg-final { scan-assembler \"lwbrx\" } } */\n+/* { dg-final { scan-assembler \"stwbrx\" } } */\n+\n+unsigned int ui;\n+unsigned int load_bswap32 (unsigned int *p) { return __builtin_bswap32 (*p); }\n+void store_bswap32 (unsigned int a) { ui = __builtin_bswap32 (a); }"}, {"sha": "480e1cd7cfc4d2716b2fb8c7f7d085a91acadc4a", "filename": "gcc/testsuite/gcc.target/powerpc/bswap64-1.c", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-1.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,9 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-options \"-O2 -mno-popcntd -mcpu=power5\" } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-final { scan-assembler \"lwbrx\" } } */\n+/* { dg-final { scan-assembler \"stwbrx\" } } */\n+\n+unsigned long ul;\n+unsigned long load_bswap64 (unsigned long *p) { return __builtin_bswap64 (*p); }\n+void store_bswap64 (unsigned long a) { ul = __builtin_bswap64 (a); }"}, {"sha": "6c3d8ca05289a0fae321338ae755f2e54b4c2db4", "filename": "gcc/testsuite/gcc.target/powerpc/bswap64-2.c", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-2.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,10 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-options \"-O2 -mpopcntd\" } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-final { scan-assembler \"ldbrx\" } } */\n+/* { dg-final { scan-assembler \"stdbrx\" } } */\n+\n+unsigned long ul;\n+unsigned long load_bswap64 (unsigned long *p) { return __builtin_bswap64 (*p); }\n+void store_bswap64 (unsigned long a) { ul = __builtin_bswap64 (a); }"}, {"sha": "7f1138cf94f544b5b710a369baf6111ecce7b3f4", "filename": "gcc/testsuite/gcc.target/powerpc/bswap64-3.c", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fbswap64-3.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,10 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-options \"-O2 -mcpu=cell\" } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-require-effective-target powerpc_ppu_ok } */\n+/* { dg-final { scan-assembler \"ldbrx\" } } */\n+/* { dg-final { scan-assembler \"stdbrx\" } } */\n+\n+unsigned long ul;\n+unsigned long load_bswap64 (unsigned long *p) { return __builtin_bswap64 (*p); }\n+void store_bswap64 (unsigned long a) { ul = __builtin_bswap64 (a); }"}, {"sha": "7337e99b1b324e976688c27095135fcb3762ee69", "filename": "gcc/testsuite/gcc.target/powerpc/optimize-bswapdi-2.c", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapdi-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapdi-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapdi-2.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,36 @@\n+/* { dg-require-effective-target stdint_types } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -mcpu=power5\" } */\n+\n+/* This is a clone of gcc-dg/optimize-bswapdi-1.c, redone to use load and stores\n+   to test whether lwbrx/stwbrx is generated for normal power systems.  */\n+\n+#include <stdint.h>\n+#define __const_swab64(x) ((uint64_t)(\t\t\t                        \\\n+\t(((uint64_t)(x) & (uint64_t)0x00000000000000ffULL) << 56) |             \\\n+\t(((uint64_t)(x) & (uint64_t)0x000000000000ff00ULL) << 40) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x0000000000ff0000ULL) << 24) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x00000000ff000000ULL) <<  8) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x000000ff00000000ULL) >>  8) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x0000ff0000000000ULL) >> 24) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x00ff000000000000ULL) >> 40) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0xff00000000000000ULL) >> 56)))\n+\n+\n+/* This byte swap implementation is used by the Linux kernel and the\n+   GNU C library.  */\n+\n+uint64_t\n+swap64_load (uint64_t *in)\n+{\n+  return __const_swab64 (*in);\n+}\n+\n+void\n+swap64_store (uint64_t *out, uint64_t in)\n+{\n+  *out = __const_swab64 (in);\n+}\n+\n+/* { dg-final { scan-assembler-times \"lwbrx\" 2 } } */\n+/* { dg-final { scan-assembler-times \"stwbrx\" 2 } } */"}, {"sha": "9dcd824c6ed8158005854c162938e2afa7951555", "filename": "gcc/testsuite/gcc.target/powerpc/optimize-bswapdi-3.c", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapdi-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapdi-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapdi-3.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,36 @@\n+/* { dg-require-effective-target stdint_types } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+\n+/* This is a clone of gcc-dg/optimize-bswapdi-1.c, redone to use load and stores\n+   to test whether ldbrx/stdbrx is generated for power7.  */\n+\n+#include <stdint.h>\n+#define __const_swab64(x) ((uint64_t)(\t\t\t                        \\\n+\t(((uint64_t)(x) & (uint64_t)0x00000000000000ffULL) << 56) |             \\\n+\t(((uint64_t)(x) & (uint64_t)0x000000000000ff00ULL) << 40) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x0000000000ff0000ULL) << 24) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x00000000ff000000ULL) <<  8) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x000000ff00000000ULL) >>  8) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x0000ff0000000000ULL) >> 24) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0x00ff000000000000ULL) >> 40) |\t\t\\\n+\t(((uint64_t)(x) & (uint64_t)0xff00000000000000ULL) >> 56)))\n+\n+\n+/* This byte swap implementation is used by the Linux kernel and the\n+   GNU C library.  */\n+\n+uint64_t\n+swap64_load (uint64_t *in)\n+{\n+  return __const_swab64 (*in);\n+}\n+\n+void\n+swap64_store (uint64_t *out, uint64_t in)\n+{\n+  *out = __const_swab64 (in);\n+}\n+\n+/* { dg-final { scan-assembler \"ldbrx\" } } */\n+/* { dg-final { scan-assembler \"stdbrx\" } } */"}, {"sha": "34cc8236fbca97e7d527df6b4bd6b8db05a7da18", "filename": "gcc/testsuite/gcc.target/powerpc/optimize-bswapsi-2.c", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapsi-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapsi-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Foptimize-bswapsi-2.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,55 @@\n+/* { dg-require-effective-target stdint_types } */\n+/* { dg-options \"-O2 -mcpu=power5\" } */\n+\n+#include <stdint.h>\n+\n+/* This is a clone of gcc-dg/optimize-bswapsi-1.c, redone to use load and stores\n+   to test whether lwbrx/stwbrx is generated for normal power systems.  */\n+\n+#define __const_swab32(x) ((uint32_t)(\t\t\t\t      \\\n+        (((uint32_t)(x) & (uint32_t)0x000000ffUL) << 24) |            \\\n+        (((uint32_t)(x) & (uint32_t)0x0000ff00UL) <<  8) |            \\\n+        (((uint32_t)(x) & (uint32_t)0x00ff0000UL) >>  8) |            \\\n+        (((uint32_t)(x) & (uint32_t)0xff000000UL) >> 24)))\n+\n+/* This byte swap implementation is used by the Linux kernel and the\n+   GNU C library.  */\n+\n+uint32_t\n+swap32_a_load (uint32_t *in)\n+{\n+  return __const_swab32 (*in);\n+}\n+\n+/* The OpenSSH byte swap implementation.  */\n+uint32_t\n+swap32_b_load (uint32_t *in)\n+{\n+  uint32_t a;\n+\n+  a = (*in << 16) | (*in >> 16);\n+  a = ((a & 0x00ff00ff) << 8) | ((a & 0xff00ff00) >> 8);\n+\n+  return a;\n+}\n+\n+void\n+swap32_a_store (uint32_t *out, uint32_t in)\n+{\n+  *out = __const_swab32 (in);\n+}\n+\n+/* The OpenSSH byte swap implementation.  */\n+void\n+swap32_b_store (uint32_t *out, uint32_t in)\n+{\n+  uint32_t a;\n+\n+  a = (in << 16) | (in >> 16);\n+  a = ((a & 0x00ff00ff) << 8) | ((a & 0xff00ff00) >> 8);\n+\n+  *out = a;\n+}\n+\n+/* { dg-final { scan-assembler-times \"lwbrx\" 2 } } */\n+/* { dg-final { scan-assembler-times \"stwbrx\" 2 } } */"}, {"sha": "7546a3bdf1e08d52b8249e0825c7441005819809", "filename": "gcc/testsuite/gcc.target/powerpc/popcount-2.c", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpopcount-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpopcount-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpopcount-2.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,9 @@\n+/* { dg-do compile { target { ilp32 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-options \"-O2 -mcpu=power7 -m32\" } */\n+/* { dg-final { scan-assembler \"popcntw\" } } */\n+\n+int foo(int x)\n+{\n+  return __builtin_popcount(x);\n+}"}, {"sha": "c803532e6dbf71ff064f9dca282d77f0548ef580", "filename": "gcc/testsuite/gcc.target/powerpc/popcount-3.c", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpopcount-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpopcount-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpopcount-3.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,9 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-options \"-O2 -mcpu=power7 -m64\" } */\n+/* { dg-final { scan-assembler \"popcntd\" } } */\n+\n+long foo(int x)\n+{\n+  return __builtin_popcountl(x);\n+}"}, {"sha": "22057e51f59ed01553bc66747eb5605e10612530", "filename": "gcc/testsuite/gcc.target/powerpc/pr39457.c", "status": "added", "additions": 56, "deletions": 0, "changes": 56, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpr39457.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpr39457.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fpr39457.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,56 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-options \"-m64 -O2 -mminimal-toc\" } */\n+\n+/* PR 39457 -- fix breakage because the compiler ran out of registers and\n+   wanted to stash a floating point value to the LR/CTR register.  */\n+\n+/* -O2 -m64 -mminimal-toc */\n+typedef struct { void *s; } S;\n+typedef void (*T1) (void);\n+typedef void (*T2) (void *, void *, int, void *);\n+char *fn1 (const char *, ...);\n+void *fn2 (void);\n+int fn3 (char *, int);\n+int fn4 (const void *);\n+int fn5 (const void *);\n+long fn6 (void) __attribute__ ((__const__));\n+int fn7 (void *, void *, void *);\n+void *fn8 (void *, long);\n+void *fn9 (void *, long, const char *, ...);\n+void *fn10 (void *);\n+long fn11 (void) __attribute__ ((__const__));\n+long fn12 (void *, const char *, T1, T2, void *);\n+void *fn13 (void *);\n+long fn14 (void) __attribute__ ((__const__));\n+extern void *v1;\n+extern char *v2;\n+extern int v3;\n+\n+void\n+foo (void *x, char *z)\n+{\n+  void *i1, *i2;\n+  int y;\n+  if (v1)\n+    return;\n+  v1 = fn9 (fn10 (fn2 ()), fn6 (), \"x\", 0., \"y\", 0., 0);\n+  y = 520 - (520 - fn4 (x)) / 2;\n+  fn9 (fn8 (v1, fn6 ()), fn6 (), \"wig\", fn8 (v1, fn14 ()), \"x\", 18.0,\n+       \"y\", 16.0, \"wid\", 80.0, \"hi\", 500.0, 0);\n+  fn9 (fn10 (v1), fn6 (), \"x1\", 0., \"y1\", 0., \"x2\", 80.0, \"y2\",\n+       500.0, \"f\", fn3 (\"fff\", 0x0D0DFA00), 0);\n+  fn13 (((S *) fn8 (v1, fn6 ()))->s);\n+  fn12 (fn8 (v1, fn11 ()), \"ev\", (T1) fn7, 0, fn8 (v1, fn6 ()));\n+  fn9 (fn8 (v1, fn6 ()), fn6 (), \"wig\",\n+       fn8 (v1, fn14 ()), \"x\", 111.0, \"y\", 14.0, \"wid\", 774.0, \"hi\",\n+       500.0, 0);\n+  v1 = fn9 (fn10 (v1), fn6 (), \"x1\", 0., \"y1\", 0., \"x2\", 774.0, \"y2\",\n+            500.0, \"f\", fn3 (\"gc\", 0x0D0DFA00), 0);\n+  fn1 (z, 0);\n+  i1 = fn9 (fn8 (v1, fn6 ()), fn6 (), \"pixbuf\", x, \"x\",\n+            800 - fn5 (x) / 2, \"y\", y - fn4 (x), 0);\n+  fn12 (fn8 (i1, fn11 ()), \"ev\", (T1) fn7, 0, \"/ok/\");\n+  fn12 (fn8 (i1, fn11 ()), \"ev\", (T1) fn7, 0, 0);\n+  i2 = fn9 (fn8 (v1, fn6 ()), fn6 (), \"txt\", \"OK\", \"fnt\", v2, \"x\",\n+            800, \"y\", y - fn4 (x) + 15, \"ar\", 0, \"f\", v3, 0);\n+}"}, {"sha": "42d5b605641f33b64119aafec8aab8e56ea035d0", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-1.c", "status": "added", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-1.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,38 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+/* { dg-final { scan-assembler \"xvadddp\" } } */\n+/* { dg-final { scan-assembler \"xvsubdp\" } } */\n+/* { dg-final { scan-assembler \"xvmuldp\" } } */\n+/* { dg-final { scan-assembler \"xvmadd\" } } */\n+/* { dg-final { scan-assembler \"xvmsub\" } } */\n+/* { dg-final { scan-assembler \"xvnmadd\" } } */\n+/* { dg-final { scan-assembler \"xvnmsub\" } } */\n+/* { dg-final { scan-assembler \"xvdivdp\" } } */\n+/* { dg-final { scan-assembler \"xvmaxdp\" } } */\n+/* { dg-final { scan-assembler \"xvmindp\" } } */\n+/* { dg-final { scan-assembler \"xvsqrtdp\" } } */\n+/* { dg-final { scan-assembler \"xvrsqrtedp\" } } */\n+/* { dg-final { scan-assembler \"xvabsdp\" } } */\n+/* { dg-final { scan-assembler \"xvnabsdp\" } } */\n+/* { dg-final { scan-assembler \"xvredp\" } } */\n+\n+void use_builtins (__vector double *p, __vector double *q, __vector double *r, __vector double *s)\n+{\n+  p[0] = __builtin_vsx_xvadddp (q[0], r[0]);\n+  p[1] = __builtin_vsx_xvsubdp (q[1], r[1]);\n+  p[2] = __builtin_vsx_xvmuldp (q[2], r[2]);\n+  p[3] = __builtin_vsx_xvdivdp (q[3], r[3]);\n+  p[4] = __builtin_vsx_xvmaxdp (q[4], r[4]);\n+  p[5] = __builtin_vsx_xvmindp (q[5], r[5]);\n+  p[6] = __builtin_vsx_xvabsdp (q[6]);\n+  p[7] = __builtin_vsx_xvnabsdp (q[7]);\n+  p[8] = __builtin_vsx_xvsqrtdp (q[8]);\n+  p[9] = __builtin_vsx_xvmadddp (q[9], r[9], s[9]);\n+  p[10] = __builtin_vsx_xvmsubdp (q[10], r[10], s[10]);\n+  p[11] = __builtin_vsx_xvnmadddp (q[11], r[11], s[11]);\n+  p[12] = __builtin_vsx_xvnmsubdp (q[12], r[12], s[12]);\n+  p[13] = __builtin_vsx_xvredp (q[13]);\n+  p[14] = __builtin_vsx_xvrsqrtedp (q[14]);\n+}"}, {"sha": "6d883dc90f1c21e0f9d86a88b1bf9d5285199596", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-2.c", "status": "added", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-2.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,38 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+/* { dg-final { scan-assembler \"xvaddsp\" } } */\n+/* { dg-final { scan-assembler \"xvsubsp\" } } */\n+/* { dg-final { scan-assembler \"xvmulsp\" } } */\n+/* { dg-final { scan-assembler \"xvmadd\" } } */\n+/* { dg-final { scan-assembler \"xvmsub\" } } */\n+/* { dg-final { scan-assembler \"xvnmadd\" } } */\n+/* { dg-final { scan-assembler \"xvnmsub\" } } */\n+/* { dg-final { scan-assembler \"xvdivsp\" } } */\n+/* { dg-final { scan-assembler \"xvmaxsp\" } } */\n+/* { dg-final { scan-assembler \"xvminsp\" } } */\n+/* { dg-final { scan-assembler \"xvsqrtsp\" } } */\n+/* { dg-final { scan-assembler \"xvabssp\" } } */\n+/* { dg-final { scan-assembler \"xvnabssp\" } } */\n+/* { dg-final { scan-assembler \"xvresp\" } } */\n+/* { dg-final { scan-assembler \"xvrsqrtesp\" } } */\n+\n+void use_builtins (__vector float *p, __vector float *q, __vector float *r, __vector float *s)\n+{\n+  p[0] = __builtin_vsx_xvaddsp (q[0], r[0]);\n+  p[1] = __builtin_vsx_xvsubsp (q[1], r[1]);\n+  p[2] = __builtin_vsx_xvmulsp (q[2], r[2]);\n+  p[3] = __builtin_vsx_xvdivsp (q[3], r[3]);\n+  p[4] = __builtin_vsx_xvmaxsp (q[4], r[4]);\n+  p[5] = __builtin_vsx_xvminsp (q[5], r[5]);\n+  p[6] = __builtin_vsx_xvabssp (q[6]);\n+  p[7] = __builtin_vsx_xvnabssp (q[7]);\n+  p[8] = __builtin_vsx_xvsqrtsp (q[8]);\n+  p[9] = __builtin_vsx_xvmaddsp (q[9], r[9], s[9]);\n+  p[10] = __builtin_vsx_xvmsubsp (q[10], r[10], s[10]);\n+  p[11] = __builtin_vsx_xvnmaddsp (q[11], r[11], s[11]);\n+  p[12] = __builtin_vsx_xvnmsubsp (q[12], r[12], s[12]);\n+  p[13] = __builtin_vsx_xvresp (q[13]);\n+  p[14] = __builtin_vsx_xvrsqrtesp (q[14]);\n+}"}, {"sha": "8450920ec0cd9f64a621cf6b0704c65a4be733ab", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-3.c", "status": "added", "additions": 212, "deletions": 0, "changes": 212, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-3.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,212 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+/* { dg-final { scan-assembler \"xxsel\" } } */\n+/* { dg-final { scan-assembler \"vperm\" } } */\n+/* { dg-final { scan-assembler \"xvrdpi\" } } */\n+/* { dg-final { scan-assembler \"xvrdpic\" } } */\n+/* { dg-final { scan-assembler \"xvrdpim\" } } */\n+/* { dg-final { scan-assembler \"xvrdpip\" } } */\n+/* { dg-final { scan-assembler \"xvrdpiz\" } } */\n+/* { dg-final { scan-assembler \"xvrspi\" } } */\n+/* { dg-final { scan-assembler \"xvrspic\" } } */\n+/* { dg-final { scan-assembler \"xvrspim\" } } */\n+/* { dg-final { scan-assembler \"xvrspip\" } } */\n+/* { dg-final { scan-assembler \"xvrspiz\" } } */\n+/* { dg-final { scan-assembler \"xsrdpi\" } } */\n+/* { dg-final { scan-assembler \"xsrdpic\" } } */\n+/* { dg-final { scan-assembler \"xsrdpim\" } } */\n+/* { dg-final { scan-assembler \"xsrdpip\" } } */\n+/* { dg-final { scan-assembler \"xsrdpiz\" } } */\n+/* { dg-final { scan-assembler \"xsmaxdp\" } } */\n+/* { dg-final { scan-assembler \"xsmindp\" } } */\n+/* { dg-final { scan-assembler \"xxland\" } } */\n+/* { dg-final { scan-assembler \"xxlandc\" } } */\n+/* { dg-final { scan-assembler \"xxlnor\" } } */\n+/* { dg-final { scan-assembler \"xxlor\" } } */\n+/* { dg-final { scan-assembler \"xxlxor\" } } */\n+/* { dg-final { scan-assembler \"xvcmpeqdp\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgtdp\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgedp\" } } */\n+/* { dg-final { scan-assembler \"xvcmpeqsp\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgtsp\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgesp\" } } */\n+/* { dg-final { scan-assembler \"xxsldwi\" } } */\n+/* { dg-final { scan-assembler-not \"call\" } } */\n+\n+extern __vector int si[][4];\n+extern __vector short ss[][4];\n+extern __vector signed char sc[][4];\n+extern __vector float f[][4];\n+extern __vector unsigned int ui[][4];\n+extern __vector unsigned short us[][4];\n+extern __vector unsigned char uc[][4];\n+extern __vector __bool int bi[][4];\n+extern __vector __bool short bs[][4];\n+extern __vector __bool char bc[][4];\n+extern __vector __pixel p[][4];\n+#ifdef __VSX__\n+extern __vector double d[][4];\n+extern __vector long sl[][4];\n+extern __vector unsigned long ul[][4];\n+extern __vector __bool long bl[][4];\n+#endif\n+\n+int do_sel(void)\n+{\n+  int i = 0;\n+\n+  si[i][0] = __builtin_vsx_xxsel_4si (si[i][1], si[i][2], si[i][3]); i++;\n+  ss[i][0] = __builtin_vsx_xxsel_8hi (ss[i][1], ss[i][2], ss[i][3]); i++;\n+  sc[i][0] = __builtin_vsx_xxsel_16qi (sc[i][1], sc[i][2], sc[i][3]); i++;\n+  f[i][0] = __builtin_vsx_xxsel_4sf (f[i][1], f[i][2], f[i][3]); i++;\n+  d[i][0] = __builtin_vsx_xxsel_2df (d[i][1], d[i][2], d[i][3]); i++;\n+\n+  si[i][0] = __builtin_vsx_xxsel (si[i][1], si[i][2], bi[i][3]); i++;\n+  ss[i][0] = __builtin_vsx_xxsel (ss[i][1], ss[i][2], bs[i][3]); i++;\n+  sc[i][0] = __builtin_vsx_xxsel (sc[i][1], sc[i][2], bc[i][3]); i++;\n+  f[i][0] = __builtin_vsx_xxsel (f[i][1], f[i][2], bi[i][3]); i++;\n+  d[i][0] = __builtin_vsx_xxsel (d[i][1], d[i][2], bl[i][3]); i++;\n+\n+  si[i][0] = __builtin_vsx_xxsel (si[i][1], si[i][2], ui[i][3]); i++;\n+  ss[i][0] = __builtin_vsx_xxsel (ss[i][1], ss[i][2], us[i][3]); i++;\n+  sc[i][0] = __builtin_vsx_xxsel (sc[i][1], sc[i][2], uc[i][3]); i++;\n+  f[i][0] = __builtin_vsx_xxsel (f[i][1], f[i][2], ui[i][3]); i++;\n+  d[i][0] = __builtin_vsx_xxsel (d[i][1], d[i][2], ul[i][3]); i++;\n+\n+  return i;\n+}\n+\n+int do_perm(void)\n+{\n+  int i = 0;\n+\n+  si[i][0] = __builtin_vsx_vperm_4si (si[i][1], si[i][2], uc[i][3]); i++;\n+  ss[i][0] = __builtin_vsx_vperm_8hi (ss[i][1], ss[i][2], uc[i][3]); i++;\n+  sc[i][0] = __builtin_vsx_vperm_16qi (sc[i][1], sc[i][2], uc[i][3]); i++;\n+  f[i][0] = __builtin_vsx_vperm_4sf (f[i][1], f[i][2], uc[i][3]); i++;\n+  d[i][0] = __builtin_vsx_vperm_2df (d[i][1], d[i][2], uc[i][3]); i++;\n+\n+  si[i][0] = __builtin_vsx_vperm (si[i][1], si[i][2], uc[i][3]); i++;\n+  ss[i][0] = __builtin_vsx_vperm (ss[i][1], ss[i][2], uc[i][3]); i++;\n+  sc[i][0] = __builtin_vsx_vperm (sc[i][1], sc[i][2], uc[i][3]); i++;\n+  f[i][0] = __builtin_vsx_vperm (f[i][1], f[i][2], uc[i][3]); i++;\n+  d[i][0] = __builtin_vsx_vperm (d[i][1], d[i][2], uc[i][3]); i++;\n+\n+  return i;\n+}\n+\n+int do_xxperm (void)\n+{\n+  int i = 0;\n+\n+  d[i][0] = __builtin_vsx_xxpermdi_2df (d[i][1], d[i][2], 0); i++;\n+  d[i][0] = __builtin_vsx_xxpermdi (d[i][1], d[i][2], 1); i++;\n+  return i;\n+}\n+\n+double x, y;\n+void do_concat (void)\n+{\n+  d[0][0] = __builtin_vsx_concat_2df (x, y);\n+}\n+\n+void do_set (void)\n+{\n+  d[0][0] = __builtin_vsx_set_2df (d[0][1], x, 0);\n+  d[1][0] = __builtin_vsx_set_2df (d[1][1], y, 1);\n+}\n+\n+extern double z[][4];\n+\n+int do_math (void)\n+{\n+  int i = 0;\n+\n+  d[i][0] = __builtin_vsx_xvrdpi  (d[i][1]); i++;\n+  d[i][0] = __builtin_vsx_xvrdpic (d[i][1]); i++;\n+  d[i][0] = __builtin_vsx_xvrdpim (d[i][1]); i++;\n+  d[i][0] = __builtin_vsx_xvrdpip (d[i][1]); i++;\n+  d[i][0] = __builtin_vsx_xvrdpiz (d[i][1]); i++;\n+\n+  f[i][0] = __builtin_vsx_xvrspi  (f[i][1]); i++;\n+  f[i][0] = __builtin_vsx_xvrspic (f[i][1]); i++;\n+  f[i][0] = __builtin_vsx_xvrspim (f[i][1]); i++;\n+  f[i][0] = __builtin_vsx_xvrspip (f[i][1]); i++;\n+  f[i][0] = __builtin_vsx_xvrspiz (f[i][1]); i++;\n+\n+  z[i][0] = __builtin_vsx_xsrdpi  (z[i][1]); i++;\n+  z[i][0] = __builtin_vsx_xsrdpic (z[i][1]); i++;\n+  z[i][0] = __builtin_vsx_xsrdpim (z[i][1]); i++;\n+  z[i][0] = __builtin_vsx_xsrdpip (z[i][1]); i++;\n+  z[i][0] = __builtin_vsx_xsrdpiz (z[i][1]); i++;\n+  z[i][0] = __builtin_vsx_xsmaxdp (z[i][1], z[i][0]); i++;\n+  z[i][0] = __builtin_vsx_xsmindp (z[i][1], z[i][0]); i++;\n+  return i;\n+}\n+\n+int do_cmp (void)\n+{\n+  int i = 0;\n+\n+  d[i][0] = __builtin_vsx_xvcmpeqdp (d[i][1], d[i][2]); i++;\n+  d[i][0] = __builtin_vsx_xvcmpgtdp (d[i][1], d[i][2]); i++;\n+  d[i][0] = __builtin_vsx_xvcmpgedp (d[i][1], d[i][2]); i++;\n+\n+  f[i][0] = __builtin_vsx_xvcmpeqsp (f[i][1], f[i][2]); i++;\n+  f[i][0] = __builtin_vsx_xvcmpgtsp (f[i][1], f[i][2]); i++;\n+  f[i][0] = __builtin_vsx_xvcmpgesp (f[i][1], f[i][2]); i++;\n+  return i;\n+}\n+\n+int do_logical (void)\n+{\n+  int i = 0;\n+\n+  si[i][0] = __builtin_vsx_xxland (si[i][1], si[i][2]); i++;\n+  si[i][0] = __builtin_vsx_xxlandc (si[i][1], si[i][2]); i++;\n+  si[i][0] = __builtin_vsx_xxlnor (si[i][1], si[i][2]); i++;\n+  si[i][0] = __builtin_vsx_xxlor (si[i][1], si[i][2]); i++;\n+  si[i][0] = __builtin_vsx_xxlxor (si[i][1], si[i][2]); i++;\n+\n+  ss[i][0] = __builtin_vsx_xxland (ss[i][1], ss[i][2]); i++;\n+  ss[i][0] = __builtin_vsx_xxlandc (ss[i][1], ss[i][2]); i++;\n+  ss[i][0] = __builtin_vsx_xxlnor (ss[i][1], ss[i][2]); i++;\n+  ss[i][0] = __builtin_vsx_xxlor (ss[i][1], ss[i][2]); i++;\n+  ss[i][0] = __builtin_vsx_xxlxor (ss[i][1], ss[i][2]); i++;\n+\n+  sc[i][0] = __builtin_vsx_xxland (sc[i][1], sc[i][2]); i++;\n+  sc[i][0] = __builtin_vsx_xxlandc (sc[i][1], sc[i][2]); i++;\n+  sc[i][0] = __builtin_vsx_xxlnor (sc[i][1], sc[i][2]); i++;\n+  sc[i][0] = __builtin_vsx_xxlor (sc[i][1], sc[i][2]); i++;\n+  sc[i][0] = __builtin_vsx_xxlxor (sc[i][1], sc[i][2]); i++;\n+\n+  d[i][0] = __builtin_vsx_xxland (d[i][1], d[i][2]); i++;\n+  d[i][0] = __builtin_vsx_xxlandc (d[i][1], d[i][2]); i++;\n+  d[i][0] = __builtin_vsx_xxlnor (d[i][1], d[i][2]); i++;\n+  d[i][0] = __builtin_vsx_xxlor (d[i][1], d[i][2]); i++;\n+  d[i][0] = __builtin_vsx_xxlxor (d[i][1], d[i][2]); i++;\n+\n+  f[i][0] = __builtin_vsx_xxland (f[i][1], f[i][2]); i++;\n+  f[i][0] = __builtin_vsx_xxlandc (f[i][1], f[i][2]); i++;\n+  f[i][0] = __builtin_vsx_xxlnor (f[i][1], f[i][2]); i++;\n+  f[i][0] = __builtin_vsx_xxlor (f[i][1], f[i][2]); i++;\n+  f[i][0] = __builtin_vsx_xxlxor (f[i][1], f[i][2]); i++;\n+  return i;\n+}\n+\n+int do_xxsldwi (void)\n+{\n+  int i = 0;\n+\n+  si[i][0] = __builtin_vsx_xxsldwi (si[i][1], si[i][2], 0); i++;\n+  ss[i][0] = __builtin_vsx_xxsldwi (ss[i][1], ss[i][2], 1); i++;\n+  sc[i][0] = __builtin_vsx_xxsldwi (sc[i][1], sc[i][2], 2); i++;\n+  ui[i][0] = __builtin_vsx_xxsldwi (ui[i][1], ui[i][2], 3); i++;\n+  us[i][0] = __builtin_vsx_xxsldwi (us[i][1], us[i][2], 0); i++;\n+  uc[i][0] = __builtin_vsx_xxsldwi (uc[i][1], uc[i][2], 1); i++;\n+  f[i][0] = __builtin_vsx_xxsldwi (f[i][1], f[i][2], 2); i++;\n+  d[i][0] = __builtin_vsx_xxsldwi (d[i][1], d[i][2], 3); i++;\n+  return i;\n+}"}, {"sha": "bcf486377e885638b6a917ba1dc75b995e014c90", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-4.c", "status": "added", "additions": 142, "deletions": 0, "changes": 142, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-4.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,142 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+/* { dg-final { scan-assembler \"xvcmpeqdp.\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgtdp.\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgedp.\" } } */\n+/* { dg-final { scan-assembler \"xvcmpeqsp.\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgtsp.\" } } */\n+/* { dg-final { scan-assembler \"xvcmpgesp.\" } } */\n+/* { dg-final { scan-assembler \"vcmpbfp.\" } } */\n+/* { dg-final { scan-assembler \"vcmpequb.\" } } */\n+/* { dg-final { scan-assembler \"vcmpequh.\" } } */\n+/* { dg-final { scan-assembler \"vcmpequw.\" } } */\n+/* { dg-final { scan-assembler \"vcmpgtub.\" } } */\n+/* { dg-final { scan-assembler \"vcmpgtuh.\" } } */\n+/* { dg-final { scan-assembler \"vcmpgtuw.\" } } */\n+/* { dg-final { scan-assembler \"vcmpgtsb.\" } } */\n+/* { dg-final { scan-assembler \"vcmpgtsh.\" } } */\n+/* { dg-final { scan-assembler \"vcmpgtsw.\" } } */\n+/* { dg-final { scan-assembler-not \"vcmpeqfp\" } } */\n+/* { dg-final { scan-assembler-not \"vcmpgtfp\" } } */\n+/* { dg-final { scan-assembler-not \"vcmpgefp\" } } */\n+\n+/* check that Altivec builtins generate VSX if -mvsx.  */\n+\n+#include <altivec.h>\n+\n+int *v16qi_s (vector signed char *a, vector signed char *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 2;\n+\n+  return p;\n+}\n+\n+int *v16qi_u (vector unsigned char *a, vector unsigned char *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 2;\n+\n+  return p;\n+}\n+\n+int *v8hi_s (vector short *a, vector short *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 2;\n+\n+  return p;\n+}\n+\n+int *v8hi_u (vector unsigned short *a, vector unsigned short *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 2;\n+\n+  return p;\n+}\n+\n+int *v4si_s (vector int *a, vector int *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 2;\n+\n+  return p;\n+}\n+\n+int *v4si_u (vector unsigned int *a, vector unsigned int *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 2;\n+\n+  return p;\n+}\n+\n+int *v4sf (vector float *a, vector float *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 3;\n+\n+  if (vec_all_in (*a, *b))\t/* veccmpbfp. */\n+    *p++ = 4;\n+\n+  return p;\n+}\n+\n+int *v2df (vector double *a, vector double *b, int *p)\n+{\n+  if (vec_all_eq (*a, *b))\n+    *p++ = 1;\n+\n+  if (vec_all_gt (*a, *b))\n+    *p++ = 2;\n+\n+  if (vec_all_ge (*a, *b))\n+    *p++ = 3;\n+\n+  return p;\n+}"}, {"sha": "5c24dc618ce0cb4ffb840d54dd38f226b424e76d", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-5.c", "status": "added", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-5.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,14 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+/* { dg-final { scan-assembler \"xxpermdi\" } } */\n+/* { dg-final { scan-assembler-not \"stxvd2x\" } } */\n+\n+/* Make sure double extract doesn't use a store instruction.  */\n+\n+double d0(__vector double v){ return __builtin_vec_extract (v, 0); }\n+double d1(__vector double v){ return __builtin_vec_extract (v, 1); }\n+\n+double e0(vector double v){ return __builtin_vec_ext_v2df (v, 0); }\n+double e1(vector double v){ return __builtin_vec_ext_v2df (v, 1); }"}, {"sha": "a722b83b976064333c1234c57d48d3d79e5a58c5", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-6.c", "status": "added", "additions": 146, "deletions": 0, "changes": 146, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-6.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-6.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-6.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,146 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+\n+/* Check whether tdiv and tsqrt instructions generate the correct code.  */\n+/* Each of the *tdiv* and *tsqrt* instructions should be generated exactly 3\n+   times (the two calls in the _1 function should be combined).  */\n+/* { dg-final { scan-assembler-times \"xstdivdp\" 3 } } */\n+/* { dg-final { scan-assembler-times \"xvtdivdp\" 3 } } */\n+/* { dg-final { scan-assembler-times \"xvtdivsp\" 3 } } */\n+/* { dg-final { scan-assembler-times \"xstsqrtdp\" 3 } } */\n+/* { dg-final { scan-assembler-times \"xvtsqrtdp\" 3 } } */\n+/* { dg-final { scan-assembler-times \"xvtsqrtsp\" 3 } } */\n+\n+void test_div_df_1 (double a, double b, int *p)\n+{\n+  p[0] = __builtin_vsx_xstdivdp_fe (a, b);\n+  p[1] = __builtin_vsx_xstdivdp_fg (a, b);\n+}\n+\n+int *test_div_df_2 (double a, double b, int *p)\n+{\n+  if (__builtin_vsx_xstdivdp_fe (a, b))\n+    *p++ = 1;\n+  \n+  return p;\n+}\n+\n+int *test_div_df_3 (double a, double b, int *p)\n+{\n+  if (__builtin_vsx_xstdivdp_fg (a, b))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+void test_sqrt_df_1 (double a, int *p)\n+{\n+  p[0] = __builtin_vsx_xstsqrtdp_fe (a);\n+  p[1] = __builtin_vsx_xstsqrtdp_fg (a);\n+}\n+\n+int *test_sqrt_df_2 (double a, int *p)\n+{\n+  if (__builtin_vsx_xstsqrtdp_fe (a))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+int *test_sqrt_df_3 (double a, int *p)\n+{\n+  if (__builtin_vsx_xstsqrtdp_fg (a))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+void test_div_v2df_1 (__vector double *a, __vector double *b, int *p)\n+{\n+  p[0] = __builtin_vsx_xvtdivdp_fe (*a, *b);\n+  p[1] = __builtin_vsx_xvtdivdp_fg (*a, *b);\n+}\n+\n+int *test_div_v2df_2 (__vector double *a, __vector double *b, int *p)\n+{\n+  if (__builtin_vsx_xvtdivdp_fe (*a, *b))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+int *test_div_v2df_3 (__vector double *a, __vector double *b, int *p)\n+{\n+  if (__builtin_vsx_xvtdivdp_fg (*a, *b))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+void test_sqrt_v2df_1 (__vector double *a, int *p)\n+{\n+  p[0] = __builtin_vsx_xvtsqrtdp_fe (*a);\n+  p[1] = __builtin_vsx_xvtsqrtdp_fg (*a);\n+}\n+\n+int *test_sqrt_v2df_2 (__vector double *a, int *p)\n+{\n+  if (__builtin_vsx_xvtsqrtdp_fe (*a))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+int *test_sqrt_v2df_3 (__vector double *a, int *p)\n+{\n+  if (__builtin_vsx_xvtsqrtdp_fg (*a))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+void test_div_v4sf_1 (__vector float *a, __vector float *b, int *p)\n+{\n+  p[0] = __builtin_vsx_xvtdivsp_fe (*a, *b);\n+  p[1] = __builtin_vsx_xvtdivsp_fg (*a, *b);\n+}\n+\n+int *test_div_v4sf_2 (__vector float *a, __vector float *b, int *p)\n+{\n+  if (__builtin_vsx_xvtdivsp_fe (*a, *b))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+int *test_div_v4sf_3 (__vector float *a, __vector float *b, int *p)\n+{\n+  if (__builtin_vsx_xvtdivsp_fg (*a, *b))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+void test_sqrt_v4sf_1 (__vector float *a, int *p)\n+{\n+  p[0] = __builtin_vsx_xvtsqrtsp_fe (*a);\n+  p[1] = __builtin_vsx_xvtsqrtsp_fg (*a);\n+}\n+\n+int *test_sqrt_v4sf_2 (__vector float *a, int *p)\n+{\n+  if (__builtin_vsx_xvtsqrtsp_fe (*a))\n+    *p++ = 1;\n+\n+  return p;\n+}\n+\n+int *test_sqrt_v4sf_3 (__vector float *a, int *p)\n+{\n+  if (__builtin_vsx_xvtsqrtsp_fg (*a))\n+    *p++ = 1;\n+\n+  return p;\n+}"}, {"sha": "55e999d385172ce3d9f0067eb5be306d7dca21e9", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-7.c", "status": "added", "additions": 150, "deletions": 0, "changes": 150, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-7.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-7.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-7.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,150 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -mcpu=power7\" } */\n+\n+/* Test simple extract/insert/slat operations.  Make sure all types are\n+   supported with various options.  */\n+\n+#include <altivec.h>\n+\n+double extract_df_0_reg (vector double p) { return vec_extract (p, 0); }\n+double extract_df_1_reg (vector double p) { return vec_extract (p, 1); }\n+double extract_df_n_reg (vector double p, int n) { return vec_extract (p, n); }\n+\n+double extract_df_0_mem (vector double *p) { return vec_extract (*p, 0); }\n+double extract_df_1_mem (vector double *p) { return vec_extract (*p, 1); }\n+double extract_df_n_mem (vector double *p, int n) { return vec_extract (*p, n); }\n+\n+vector double insert_df_0 (vector double p, double x) { return vec_insert (x, p, 0); }\n+vector double insert_df_1 (vector double p, double x) { return vec_insert (x, p, 1); }\n+vector double insert_df_n (vector double p, double x, int n) { return vec_insert (x, p, n); }\n+\n+vector double splat_df_reg (double x) { return vec_splats (x); }\n+vector double splat_df_mem (double *x) { return vec_splats (*x); }\n+\n+#ifdef _ARCH_PPC64\n+#define ll long\n+#else\n+#define ll long long\n+#endif\n+\n+ll extract_di_0_reg (vector ll p) { return vec_extract (p, 0); }\n+ll extract_di_1_reg (vector ll p) { return vec_extract (p, 1); }\n+ll extract_di_n_reg (vector ll p, int n) { return vec_extract (p, n); }\n+\n+ll extract_di_0_mem (vector ll *p) { return vec_extract (*p, 0); }\n+ll extract_di_1_mem (vector ll *p) { return vec_extract (*p, 1); }\n+ll extract_di_n_mem (vector ll *p, int n) { return vec_extract (*p, n); }\n+\n+vector ll insert_di_0 (vector ll p, ll x) { return vec_insert (x, p, 0); }\n+vector ll insert_di_1 (vector ll p, ll x) { return vec_insert (x, p, 1); }\n+vector ll insert_di_n (vector ll p, ll x, int n) { return vec_insert (x, p, n); }\n+\n+vector ll splat_di_reg (ll x) { return vec_splats (x); }\n+vector ll splat_di_mem (ll *x) { return vec_splats (*x); }\n+\n+float extract_sf_0_reg (vector float p) { return vec_extract (p, 0); }\n+float extract_sf_3_reg (vector float p) { return vec_extract (p, 3); }\n+float extract_sf_n_reg (vector float p, int n) { return vec_extract (p, n); }\n+\n+float extract_sf_0_mem (vector float *p) { return vec_extract (*p, 0); }\n+float extract_sf_3_mem (vector float *p) { return vec_extract (*p, 3); }\n+float extract_sf_n_mem (vector float *p, int n) { return vec_extract (*p, n); }\n+\n+vector float insert_sf_0 (vector float p, float x) { return vec_insert (x, p, 0); }\n+vector float insert_sf_3 (vector float p, float x) { return vec_insert (x, p, 3); }\n+vector float insert_sf_n (vector float p, float x, int n) { return vec_insert (x, p, n); }\n+\n+vector float splat_sf_reg (float x) { return vec_splats (x); }\n+vector float splat_sf_mem (float *x) { return vec_splats (*x); }\n+\n+int extract_si_0_reg (vector int p) { return vec_extract (p, 0); }\n+int extract_si_3_reg (vector int p) { return vec_extract (p, 3); }\n+int extract_si_n_reg (vector int p, int n) { return vec_extract (p, n); }\n+\n+int extract_si_0_mem (vector int *p) { return vec_extract (*p, 0); }\n+int extract_si_3_mem (vector int *p) { return vec_extract (*p, 3); }\n+int extract_si_n_mem (vector int *p, int n) { return vec_extract (*p, n); }\n+\n+vector int insert_si_0 (vector int p, int x) { return vec_insert (x, p, 0); }\n+vector int insert_si_3 (vector int p, int x) { return vec_insert (x, p, 3); }\n+vector int insert_si_n (vector int p, int x, int n) { return vec_insert (x, p, n); }\n+\n+vector int splat_si_reg (int x) { return vec_splats (x); }\n+vector int splat_si_mem (int *x) { return vec_splats (*x); }\n+\n+unsigned int extract_usi_0_reg (vector unsigned int p) { return vec_extract (p, 0); }\n+unsigned int extract_usi_3_reg (vector unsigned int p) { return vec_extract (p, 3); }\n+unsigned int extract_usi_n_reg (vector unsigned int p, int n) { return vec_extract (p, n); }\n+\n+unsigned int extract_usi_0_mem (vector unsigned int *p) { return vec_extract (*p, 0); }\n+unsigned int extract_usi_3_mem (vector unsigned int *p) { return vec_extract (*p, 3); }\n+unsigned int extract_usi_n_mem (vector unsigned int *p, int n) { return vec_extract (*p, n); }\n+\n+vector unsigned int insert_usi_0 (vector unsigned int p, unsigned int x) { return vec_insert (x, p, 0); }\n+vector unsigned int insert_usi_3 (vector unsigned int p, unsigned int x) { return vec_insert (x, p, 3); }\n+vector unsigned int insert_usi_n (vector unsigned int p, unsigned int x, int n) { return vec_insert (x, p, n); }\n+\n+vector unsigned int splat_usi_reg (unsigned int x) { return vec_splats (x); }\n+vector unsigned int splat_usi_mem (unsigned int *x) { return vec_splats (*x); }\n+\n+short extract_hi_0_reg (vector short p) { return vec_extract (p, 0); }\n+short extract_hi_7_reg (vector short p) { return vec_extract (p, 7); }\n+short extract_hi_n_reg (vector short p, int n) { return vec_extract (p, n); }\n+\n+short extract_hi_0_mem (vector short *p) { return vec_extract (*p, 0); }\n+short extract_hi_7_mem (vector short *p) { return vec_extract (*p, 7); }\n+short extract_hi_n_mem (vector short *p, int n) { return vec_extract (*p, n); }\n+\n+vector short insert_hi_0 (vector short p, short x) { return vec_insert (x, p, 0); }\n+vector short insert_hi_7 (vector short p, short x) { return vec_insert (x, p, 7); }\n+vector short insert_hi_n (vector short p, short x, int n) { return vec_insert (x, p, n); }\n+\n+vector short splat_hi_reg (short x) { return vec_splats (x); }\n+vector short splat_hi_mem (short *x) { return vec_splats (*x); }\n+\n+unsigned short extract_uhi_0_reg (vector unsigned short p) { return vec_extract (p, 0); }\n+unsigned short extract_uhi_7_reg (vector unsigned short p) { return vec_extract (p, 7); }\n+unsigned short extract_uhi_n_reg (vector unsigned short p, int n) { return vec_extract (p, n); }\n+\n+unsigned short extract_uhi_0_mem (vector unsigned short *p) { return vec_extract (*p, 0); }\n+unsigned short extract_uhi_7_mem (vector unsigned short *p) { return vec_extract (*p, 7); }\n+unsigned short extract_uhi_n_mem (vector unsigned short *p, int n) { return vec_extract (*p, n); }\n+\n+vector unsigned short insert_uhi_0 (vector unsigned short p, unsigned short x) { return vec_insert (x, p, 0); }\n+vector unsigned short insert_uhi_7 (vector unsigned short p, unsigned short x) { return vec_insert (x, p, 7); }\n+vector unsigned short insert_uhi_n (vector unsigned short p, unsigned short x, int n) { return vec_insert (x, p, n); }\n+\n+vector unsigned short splat_uhi_reg (unsigned short x) { return vec_splats (x); }\n+vector unsigned short splat_uhi_mem (unsigned short *x) { return vec_splats (*x); }\n+\n+signed char extract_qi_0_reg (vector signed char p) { return vec_extract (p, 0); }\n+signed char extract_qi_1_reg5 (vector signed char p) { return vec_extract (p, 15); }\n+signed char extract_qi_n_reg (vector signed char p, int n) { return vec_extract (p, n); }\n+\n+signed char extract_qi_0_mem (vector signed char *p) { return vec_extract (*p, 0); }\n+signed char extract_qi_1_mem5 (vector signed char *p) { return vec_extract (*p, 15); }\n+signed char extract_qi_n_mem (vector signed char *p, int n) { return vec_extract (*p, n); }\n+\n+vector signed char insert_qi_0 (vector signed char p, signed char x) { return vec_insert (x, p, 0); }\n+vector signed char insert_qi_15 (vector signed char p, signed char x) { return vec_insert (x, p, 15); }\n+vector signed char insert_qi_n (vector signed char p, signed char x, int n) { return vec_insert (x, p, n); }\n+\n+vector signed char splat_qi_reg (signed char x) { return vec_splats (x); }\n+vector signed char splat_qi_mem (signed char *x) { return vec_splats (*x); }\n+\n+unsigned char extract_uqi_0_reg (vector unsigned char p) { return vec_extract (p, 0); }\n+unsigned char extract_uqi_1_reg5 (vector unsigned char p) { return vec_extract (p, 15); }\n+unsigned char extract_uqi_n_reg (vector unsigned char p, int n) { return vec_extract (p, n); }\n+\n+unsigned char extract_uqi_0_mem (vector unsigned char *p) { return vec_extract (*p, 0); }\n+unsigned char extract_uqi_1_mem5 (vector unsigned char *p) { return vec_extract (*p, 15); }\n+unsigned char extract_uqi_n_mem (vector unsigned char *p, int n) { return vec_extract (*p, n); }\n+\n+vector unsigned char insert_uqi_0 (vector unsigned char p, unsigned char x) { return vec_insert (x, p, 0); }\n+vector unsigned char insert_uqi_15 (vector unsigned char p, unsigned char x) { return vec_insert (x, p, 15); }\n+vector unsigned char insert_uqi_n (vector unsigned char p, unsigned char x, int n) { return vec_insert (x, p, n); }\n+\n+vector unsigned char splat_uqi_reg (unsigned char x) { return vec_splats (x); }\n+vector unsigned char splat_uqi_mem (unsigned char *x) { return vec_splats (*x); }"}, {"sha": "0bf3a7f53a96f543958b34a4a97495e67f84e54c", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-vector-1.c", "status": "added", "additions": 152, "deletions": 0, "changes": 152, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-1.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,152 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -ftree-vectorize -mcpu=power7 -m64 -ffast-math\" } */\n+/* { dg-final { scan-assembler \"xvadddp\" } } */\n+/* { dg-final { scan-assembler \"xvsubdp\" } } */\n+/* { dg-final { scan-assembler \"xvmuldp\" } } */\n+/* { dg-final { scan-assembler \"xvdivdp\" } } */\n+/* { dg-final { scan-assembler \"xvmadd\" } } */\n+/* { dg-final { scan-assembler \"xvmsub\" } } */\n+/* { dg-final { scan-assembler \"xvsqrtdp\" } } */\n+/* { dg-final { scan-assembler \"xvcpsgndp\" } } */\n+/* { dg-final { scan-assembler \"xvrdpim\" } } */\n+/* { dg-final { scan-assembler \"xvrdpip\" } } */\n+/* { dg-final { scan-assembler \"xvrdpiz\" } } */\n+/* { dg-final { scan-assembler \"xvrdpic\" } } */\n+/* { dg-final { scan-assembler \"xvrdpi \" } } */\n+\n+#ifndef SIZE\n+#define SIZE 1024\n+#endif\n+\n+double a[SIZE] __attribute__((__aligned__(32)));\n+double b[SIZE] __attribute__((__aligned__(32)));\n+double c[SIZE] __attribute__((__aligned__(32)));\n+double d[SIZE] __attribute__((__aligned__(32)));\n+double e[SIZE] __attribute__((__aligned__(32)));\n+\n+void\n+vector_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] + c[i];\n+}\n+\n+void\n+vector_subtract (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] - c[i];\n+}\n+\n+void\n+vector_multiply (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] * c[i];\n+}\n+\n+void\n+vector_multiply_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = (b[i] * c[i]) + d[i];\n+}\n+\n+void\n+vector_multiply_subtract (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = (b[i] * c[i]) - d[i];\n+}\n+\n+void\n+vector_divide (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] / c[i];\n+}\n+\n+extern double sqrt (double);\n+extern double floor (double);\n+extern double ceil (double);\n+extern double trunc (double);\n+extern double nearbyint (double);\n+extern double rint (double);\n+extern double copysign (double, double);\n+\n+void\n+vector_sqrt (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = sqrt (b[i]);\n+}\n+\n+void\n+vector_floor (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = floor (b[i]);\n+}\n+\n+void\n+vector_ceil (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = ceil (b[i]);\n+}\n+\n+void\n+vector_trunc (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = trunc (b[i]);\n+}\n+\n+void\n+vector_nearbyint (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = nearbyint (b[i]);\n+}\n+\n+void\n+vector_rint (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = rint (b[i]);\n+}\n+\n+void\n+vector_copysign (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = copysign (b[i], c[i]);\n+}"}, {"sha": "ba27b46fb27a978ee47b02e1ab9ad19d8eafcc60", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-vector-2.c", "status": "added", "additions": 152, "deletions": 0, "changes": 152, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-2.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,152 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -ftree-vectorize -mcpu=power7 -m64 -ffast-math\" } */\n+/* { dg-final { scan-assembler \"xvaddsp\" } } */\n+/* { dg-final { scan-assembler \"xvsubsp\" } } */\n+/* { dg-final { scan-assembler \"xvmulsp\" } } */\n+/* { dg-final { scan-assembler \"xvdivsp\" } } */\n+/* { dg-final { scan-assembler \"xvmadd\" } } */\n+/* { dg-final { scan-assembler \"xvmsub\" } } */\n+/* { dg-final { scan-assembler \"xvsqrtsp\" } } */\n+/* { dg-final { scan-assembler \"xvcpsgnsp\" } } */\n+/* { dg-final { scan-assembler \"xvrspim\" } } */\n+/* { dg-final { scan-assembler \"xvrspip\" } } */\n+/* { dg-final { scan-assembler \"xvrspiz\" } } */\n+/* { dg-final { scan-assembler \"xvrspic\" } } */\n+/* { dg-final { scan-assembler \"xvrspi \" } } */\n+\n+#ifndef SIZE\n+#define SIZE 1024\n+#endif\n+\n+float a[SIZE] __attribute__((__aligned__(32)));\n+float b[SIZE] __attribute__((__aligned__(32)));\n+float c[SIZE] __attribute__((__aligned__(32)));\n+float d[SIZE] __attribute__((__aligned__(32)));\n+float e[SIZE] __attribute__((__aligned__(32)));\n+\n+void\n+vector_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] + c[i];\n+}\n+\n+void\n+vector_subtract (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] - c[i];\n+}\n+\n+void\n+vector_multiply (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] * c[i];\n+}\n+\n+void\n+vector_multiply_add (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = (b[i] * c[i]) + d[i];\n+}\n+\n+void\n+vector_multiply_subtract (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = (b[i] * c[i]) - d[i];\n+}\n+\n+void\n+vector_divide (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = b[i] / c[i];\n+}\n+\n+extern float sqrtf (float);\n+extern float floorf (float);\n+extern float ceilf (float);\n+extern float truncf (float);\n+extern float nearbyintf (float);\n+extern float rintf (float);\n+extern float copysignf (float, float);\n+\n+void\n+vector_sqrt (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = sqrtf (b[i]);\n+}\n+\n+void\n+vector_floor (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = floorf (b[i]);\n+}\n+\n+void\n+vector_ceil (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = ceilf (b[i]);\n+}\n+\n+void\n+vector_trunc (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = truncf (b[i]);\n+}\n+\n+void\n+vector_nearbyint (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = nearbyintf (b[i]);\n+}\n+\n+void\n+vector_rint (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = rintf (b[i]);\n+}\n+\n+void\n+vector_copysign (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a[i] = copysignf (b[i], c[i]);\n+}"}, {"sha": "5f3bf5b4b2c2c08629b09149641871ee2b3b24a3", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-vector-3.c", "status": "added", "additions": 48, "deletions": 0, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-3.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,48 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -ftree-vectorize -mcpu=power7 -m64\" } */\n+/* { dg-final { scan-assembler \"xvadddp\" } } */\n+/* { dg-final { scan-assembler \"xvsubdp\" } } */\n+/* { dg-final { scan-assembler \"xvmuldp\" } } */\n+/* { dg-final { scan-assembler \"xvdivdp\" } } */\n+/* { dg-final { scan-assembler \"xvmadd\" } } */\n+/* { dg-final { scan-assembler \"xvmsub\" } } */\n+\n+__vector double a, b, c, d;\n+\n+void\n+vector_add (void)\n+{\n+  a = b + c;\n+}\n+\n+void\n+vector_subtract (void)\n+{\n+  a = b - c;\n+}\n+\n+void\n+vector_multiply (void)\n+{\n+  a = b * c;\n+}\n+\n+void\n+vector_multiply_add (void)\n+{\n+  a = (b * c) + d;\n+}\n+\n+void\n+vector_multiply_subtract (void)\n+{\n+  a = (b * c) - d;\n+}\n+\n+void\n+vector_divide (void)\n+{\n+  a = b / c;\n+}"}, {"sha": "a34ba8f7de305cc816f2d6e158e89c2526ed944d", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-vector-4.c", "status": "added", "additions": 48, "deletions": 0, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-4.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,48 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O2 -ftree-vectorize -mcpu=power7 -m64\" } */\n+/* { dg-final { scan-assembler \"xvaddsp\" } } */\n+/* { dg-final { scan-assembler \"xvsubsp\" } } */\n+/* { dg-final { scan-assembler \"xvmulsp\" } } */\n+/* { dg-final { scan-assembler \"xvdivsp\" } } */\n+/* { dg-final { scan-assembler \"xvmadd\" } } */\n+/* { dg-final { scan-assembler \"xvmsub\" } } */\n+\n+__vector float a, b, c, d;\n+\n+void\n+vector_add (void)\n+{\n+  a = b + c;\n+}\n+\n+void\n+vector_subtract (void)\n+{\n+  a = b - c;\n+}\n+\n+void\n+vector_multiply (void)\n+{\n+  a = b * c;\n+}\n+\n+void\n+vector_multiply_add (void)\n+{\n+  a = (b * c) + d;\n+}\n+\n+void\n+vector_multiply_subtract (void)\n+{\n+  a = (b * c) - d;\n+}\n+\n+void\n+vector_divide (void)\n+{\n+  a = b / c;\n+}"}, {"sha": "65843e93fbd21ec21676a98686c107eb48148d26", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-vector-5.c", "status": "added", "additions": 392, "deletions": 0, "changes": 392, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-5.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,392 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-mvsx -O2\" } */\n+\n+/* This will run, and someday we should add the support to test whether we are\n+   running on VSX hardware.  */\n+\n+#include <altivec.h>\n+#include <stdlib.h>\n+\n+#ifdef DEBUG\n+#include <stdio.h>\n+\n+static int errors = 0;\n+#endif\n+\n+union args {\n+  double scalar[2];\n+  vector double vect;\n+};\n+\n+union largs {\n+  unsigned long scalar[2];\n+  vector bool long vect;\n+};\n+\n+static void\n+do_test (union args *expected, union args *got, const char *name)\n+{\n+  if (expected->scalar[0] != got->scalar[0]\n+      || expected->scalar[1] != got->scalar[1])\n+    {\n+#ifdef DEBUG\n+      printf (\"%s failed!\\n\", name);\n+      errors++;\n+#else\n+      abort ();\n+#endif\n+    }\n+}\n+\n+static void\n+do_ltest (union largs *expected, union largs *got, const char *name)\n+{\n+  if (expected->scalar[0] != got->scalar[0]\n+      || expected->scalar[1] != got->scalar[1])\n+    {\n+#ifdef DEBUG\n+      printf (\"%s failed!\\n\", name);\n+      errors++;\n+#else\n+      abort ();\n+#endif\n+    }\n+}\n+\n+\f\n+/* Vec functions taking a single argument.  */\n+static vector double\n+vabs (vector double arg)\n+{\n+  return vec_abs (arg);\n+}\n+\n+static vector double\n+vceil (vector double arg)\n+{\n+  return vec_ceil (arg);\n+}\n+\n+static vector double\n+vfloor (vector double arg)\n+{\n+  return vec_floor (arg);\n+}\n+\n+static vector double\n+vnearbyint (vector double arg)\n+{\n+  return vec_nearbyint (arg);\n+}\n+\n+static vector double\n+vrint (vector double arg)\n+{\n+  return vec_rint (arg);\n+}\n+\n+static vector double\n+vsqrt (vector double arg)\n+{\n+  return vec_sqrt (arg);\n+}\n+\n+/* Single argument tests.  */\n+static struct\n+{\n+  union args result;\n+  union args input;\n+  vector double (*func) (vector double);\n+  const char *name;\n+} arg1_tests[] = {\n+  /* result\t\tinput\t\t\tfunction\tname */\n+  { {  1.0,  2.0 },\t{ -1.0,  2.0 },\t\tvabs,\t\t\"vabs\" },\n+  { {  1.0,  2.0 },\t{  1.0, -2.0 },\t\tvabs,\t\t\"vabs\" },\n+  { {  2.0,  2.0 },\t{  1.1,  1.7 },\t\tvceil,\t\t\"vceil\" },\n+  { { -1.0, -1.0 },\t{ -1.1, -1.7 },\t\tvceil,\t\t\"vceil\" },\n+  { { -1.0,  2.0 },\t{ -1.5,  1.5 },\t\tvceil,\t\t\"vceil\" },\n+  { {  1.0,  1.0 },\t{  1.1,  1.7 },\t\tvfloor,\t\t\"vfloor\" },\n+  { { -2.0, -2.0 },\t{ -1.1, -1.7 },\t\tvfloor,\t\t\"vfloor\" },\n+  { { -2.0,  1.0 },\t{ -1.5,  1.5 },\t\tvfloor,\t\t\"vfloor\" },\n+  { {  1.0,  2.0 },\t{  1.1,  1.7 },\t\tvnearbyint,\t\"vnearbyint\" },\n+  { { -1.0, -2.0 },\t{ -1.1, -1.7 },\t\tvnearbyint,\t\"vnearbyint\" },\n+  { { -2.0,  2.0 },\t{ -1.5,  1.5 },\t\tvnearbyint,\t\"vnearbyint\" },\n+  { {  1.0,  2.0 },\t{  1.1,  1.7 },\t\tvrint,\t\t\"vrint\" },\n+  { { -1.0, -2.0 },\t{ -1.1, -1.7 },\t\tvrint,\t\t\"vrint\" },\n+  { { -2.0,  2.0 },\t{ -1.5,  1.5 },\t\tvrint,\t\t\"vrint\" },\n+  { {  2.0,  4.0 },\t{  4.0, 16.0 },\t\tvsqrt,\t\t\"vsqrt\" },\n+};\n+\n+static void\n+test_arg1 (void)\n+{\n+  unsigned i;\n+\n+#ifdef DEBUG\n+  printf (\"Single argument tests:\\n\");\n+#endif\n+\n+  for (i = 0; i < sizeof (arg1_tests) / sizeof (arg1_tests[0]); i++)\n+    {\n+      union args u;\n+      u.vect = arg1_tests[i].func (arg1_tests[i].input.vect);\n+\n+#ifdef DEBUG\n+      printf (\"test %-16s: expected { %4g, %4g }, got { %4g, %4g }, input { %4g, %4g }\\n\",\n+\t      arg1_tests[i].name,\n+\t      arg1_tests[i].result.scalar[0],\n+\t      arg1_tests[i].result.scalar[1],\n+\t      u.scalar[0],\n+\t      u.scalar[1],\n+\t      arg1_tests[i].input.scalar[0],\n+\t      arg1_tests[i].input.scalar[1]);\n+#endif\n+\n+      do_test (&arg1_tests[i].result, &u, arg1_tests[i].name);\n+    }\n+\n+  return;\n+}\n+\n+\f\n+/* Vect functions taking 2 arguments.  */\n+static vector double\n+vadd (vector double arg1, vector double arg2)\n+{\n+  return vec_add (arg1, arg2);\n+}\n+\n+static vector double\n+vadd2 (vector double arg1, vector double arg2)\n+{\n+  return arg1 + arg2;\n+}\n+\n+static vector double\n+vsub (vector double arg1, vector double arg2)\n+{\n+  return vec_sub (arg1, arg2);\n+}\n+\n+static vector double\n+vsub2 (vector double arg1, vector double arg2)\n+{\n+  return arg1 - arg2;\n+}\n+\n+static vector double\n+vmul (vector double arg1, vector double arg2)\n+{\n+  return vec_mul (arg1, arg2);\n+}\n+\n+static vector double\n+vmul2 (vector double arg1, vector double arg2)\n+{\n+  return arg1 * arg2;\n+}\n+\n+static vector double\n+vdiv (vector double arg1, vector double arg2)\n+{\n+  return vec_div (arg1, arg2);\n+}\n+\n+static vector double\n+vdiv2 (vector double arg1, vector double arg2)\n+{\n+  return arg1 / arg2;\n+}\n+\n+static vector double\n+vmax (vector double arg1, vector double arg2)\n+{\n+  return vec_max (arg1, arg2);\n+}\n+\n+static vector double\n+vmin (vector double arg1, vector double arg2)\n+{\n+  return vec_min (arg1, arg2);\n+}\n+\n+/* 2 argument tests.  */\n+static struct\n+{\n+  union args result;\n+  union args input[2];\n+  vector double (*func) (vector double, vector double);\n+  const char *name;\n+} arg2_tests[] = {\n+  /* result */\n+  { {  4.0,  6.0 },\t{ {  1.0,  2.0 }, {  3.0,  4.0 } },\tvadd,\t\"vadd\"  },\n+  { {  4.0, -6.0 },\t{ {  1.0, -2.0 }, {  3.0, -4.0 } },\tvadd,\t\"vadd\"  },\n+  { {  4.0,  6.0 },\t{ {  1.0,  2.0 }, {  3.0,  4.0 } },\tvadd2,\t\"vadd2\" },\n+  { {  4.0, -6.0 },\t{ {  1.0, -2.0 }, {  3.0, -4.0 } },\tvadd2,\t\"vadd2\" },\n+  { { -2.0, -2.0 },\t{ {  1.0,  2.0 }, {  3.0,  4.0 } },\tvsub,\t\"vsub\"  },\n+  { { -2.0,  2.0 },\t{ {  1.0, -2.0 }, {  3.0, -4.0 } },\tvsub,\t\"vsub\"  },\n+  { { -2.0, -2.0 },\t{ {  1.0,  2.0 }, {  3.0,  4.0 } },\tvsub2,\t\"vsub2\" },\n+  { { -2.0,  2.0 },\t{ {  1.0, -2.0 }, {  3.0, -4.0 } },\tvsub2,\t\"vsub2\" },\n+  { {  6.0,  4.0 },\t{ {  2.0,  8.0 }, {  3.0,  0.5 } },\tvmul,\t\"vmul\"  },\n+  { {  6.0,  4.0 },\t{ {  2.0,  8.0 }, {  3.0,  0.5 } },\tvmul2,\t\"vmul2\" },\n+  { {  2.0,  0.5 },\t{ {  6.0,  4.0 }, {  3.0,  8.0 } },\tvdiv,\t\"vdiv\"  },\n+  { {  2.0,  0.5 },\t{ {  6.0,  4.0 }, {  3.0,  8.0 } },\tvdiv2,\t\"vdiv2\" },\n+  { {  3.0,  4.0 },\t{ {  1.0,  2.0 }, {  3.0,  4.0 } },\tvmax,\t\"vmax\"  },\n+  { {  1.0,  4.0 },\t{ {  1.0, -2.0 }, { -3.0,  4.0 } },\tvmax,\t\"vmax\"  },\n+  { {  1.0,  2.0 },\t{ {  1.0,  2.0 }, {  3.0,  4.0 } },\tvmin,\t\"vmin\"  },\n+  { { -3.0, -2.0 },\t{ {  1.0, -2.0 }, { -3.0,  4.0 } },\tvmin,\t\"vmin\"  },\n+};\n+\n+static void\n+test_arg2 (void)\n+{\n+  unsigned i;\n+\n+#ifdef DEBUG\n+  printf (\"\\nTwo argument tests:\\n\");\n+#endif\n+\n+  for (i = 0; i < sizeof (arg2_tests) / sizeof (arg2_tests[0]); i++)\n+    {\n+      union args u;\n+      u.vect = arg2_tests[i].func (arg2_tests[i].input[0].vect,\n+\t\t\t\t   arg2_tests[i].input[1].vect);\n+\n+#ifdef DEBUG\n+      printf (\"test %-16s: expected { %4g, %4g }, got { %4g, %4g }, input { %4g, %4g }, { %4g, %4g }\\n\",\n+\t      arg2_tests[i].name,\n+\t      arg2_tests[i].result.scalar[0],\n+\t      arg2_tests[i].result.scalar[1],\n+\t      u.scalar[0],\n+\t      u.scalar[1],\n+\t      arg2_tests[i].input[0].scalar[0],\n+\t      arg2_tests[i].input[0].scalar[1],\n+\t      arg2_tests[i].input[1].scalar[0],\n+\t      arg2_tests[i].input[1].scalar[1]);\n+#endif\n+\n+      do_test (&arg2_tests[i].result, &u, arg2_tests[i].name);\n+    }\n+\n+  return;\n+}\n+\n+\f\n+/* Comparisons, returnning a boolean vector.  */\n+static vector bool long\n+vcmpeq (vector double arg1, vector double arg2)\n+{\n+  return vec_cmpeq (arg1, arg2);\n+}\n+\n+static vector bool long\n+vcmplt (vector double arg1, vector double arg2)\n+{\n+  return vec_cmplt (arg1, arg2);\n+}\n+\n+static vector bool long\n+vcmple (vector double arg1, vector double arg2)\n+{\n+  return vec_cmple (arg1, arg2);\n+}\n+\n+static vector bool long\n+vcmpgt (vector double arg1, vector double arg2)\n+{\n+  return vec_cmpgt (arg1, arg2);\n+}\n+\n+static vector bool long\n+vcmpge (vector double arg1, vector double arg2)\n+{\n+  return vec_cmpge (arg1, arg2);\n+}\n+\n+#define ONE  0xffffffffffffffffUL\n+#define ZERO 0x0000000000000000UL\n+\n+/* comparison tests.  */\n+static struct\n+{\n+  union largs result;\n+  union args input[2];\n+  vector bool long (*func) (vector double, vector double);\n+  const char *name;\n+} argcmp_tests[] = {\n+  { { ONE,  ZERO }, { {  1.0,  2.0 }, {  1.0, -2.0 } },\tvcmpeq,\t\"vcmpeq\" },\n+  { { ZERO, ONE  }, { { -1.0,  2.0 }, {  1.0,  2.0 } },\tvcmpeq,\t\"vcmpeq\" },\n+\n+  { { ONE,  ONE  }, { {  1.0, -2.0 }, {  1.0, -2.0 } },\tvcmple,\t\"vcmple\" },\n+  { { ONE,  ONE  }, { {  1.0, -2.0 }, {  2.0, -1.0 } },\tvcmple,\t\"vcmple\" },\n+  { { ZERO, ZERO }, { {  2.0, -1.0 }, {  1.0, -2.0 } },\tvcmple,\t\"vcmple\" },\n+\n+  { { ZERO, ZERO }, { {  1.0, -2.0 }, {  1.0, -2.0 } },\tvcmplt,\t\"vcmplt\" },\n+  { { ONE,  ONE  }, { {  1.0, -2.0 }, {  2.0, -1.0 } },\tvcmplt,\t\"vcmplt\" },\n+  { { ZERO, ZERO }, { {  2.0, -1.0 }, {  1.0, -2.0 } },\tvcmplt,\t\"vcmplt\" },\n+\n+  { { ZERO, ZERO }, { {  1.0, -2.0 }, {  1.0, -2.0 } },\tvcmpgt,\t\"vcmpgt\" },\n+  { { ZERO, ZERO }, { {  1.0, -2.0 }, {  2.0, -1.0 } },\tvcmpgt,\t\"vcmpgt\" },\n+  { { ONE,  ONE  }, { {  2.0, -1.0 }, {  1.0, -2.0 } },\tvcmpgt,\t\"vcmpgt\" },\n+\n+  { { ONE,  ONE  }, { {  1.0, -2.0 }, {  1.0, -2.0 } },\tvcmpge,\t\"vcmpge\" },\n+  { { ZERO, ZERO }, { {  1.0, -2.0 }, {  2.0, -1.0 } },\tvcmpge,\t\"vcmpge\" },\n+  { { ONE,  ONE  }, { {  2.0, -1.0 }, {  1.0, -2.0 } },\tvcmpge,\t\"vcmpge\" },\n+};\n+\n+static void\n+test_argcmp (void)\n+{\n+  unsigned i;\n+\n+#ifdef DEBUG\n+  printf (\"\\nComparison tests:\\n\");\n+#endif\n+\n+  for (i = 0; i < sizeof (argcmp_tests) / sizeof (argcmp_tests[0]); i++)\n+    {\n+      union largs u;\n+      u.vect = argcmp_tests[i].func (argcmp_tests[i].input[0].vect,\n+\t\t\t\t     argcmp_tests[i].input[1].vect);\n+\n+#ifdef DEBUG\n+      printf (\"test %-16s: expected { 0x%016lx, 0x%016lx }, got { 0x%016lx, 0x%016lx }, input { %4g, %4g }, { %4g, %4g }\\n\",\n+\t      argcmp_tests[i].name,\n+\t      argcmp_tests[i].result.scalar[0],\n+\t      argcmp_tests[i].result.scalar[1],\n+\t      u.scalar[0],\n+\t      u.scalar[1],\n+\t      argcmp_tests[i].input[0].scalar[0],\n+\t      argcmp_tests[i].input[0].scalar[1],\n+\t      argcmp_tests[i].input[1].scalar[0],\n+\t      argcmp_tests[i].input[1].scalar[1]);\n+#endif\n+\n+      do_ltest (&argcmp_tests[i].result, &u, argcmp_tests[i].name);\n+    }\n+\n+  return;\n+}\n+\n+\f\n+int\n+main (int argc, char *argv[])\n+{\n+  test_arg1 ();\n+  test_arg2 ();\n+  test_argcmp ();\n+\n+#ifdef DEBUG\n+  if (errors)\n+    {\n+      printf (\"There were %d error(s)\\n\", errors);\n+      return errors;\n+    }\n+  else\n+    printf (\"There were no errors\\n\");\n+#endif\n+  \n+  return 0;\n+}"}, {"sha": "f8e644bb53284cacc8381ae2b0da16ab5c443f64", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-vector-6.c", "status": "added", "additions": 81, "deletions": 0, "changes": 81, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-6.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-6.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-vector-6.c?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -0,0 +1,81 @@\n+/* { dg-do compile { target { powerpc*-*-* && lp64 } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-mvsx -O2\" } */\n+\n+#include <altivec.h>\n+\n+void foo (vector double *out, vector double *in, vector long *p_l, vector bool long *p_b, vector unsigned char *p_uc, int *i)\n+{\n+  vector double in0 = in[0];\n+  vector double in1 = in[1];\n+  vector double in2 = in[2];\n+  vector long inl = *p_l;\n+  vector bool long inb = *p_b;\n+  vector unsigned char uc = *p_uc;\n+\n+  *out++ = vec_abs (in0);\n+  *out++ = vec_add (in0, in1);\n+  *out++ = vec_and (in0, in1);\n+  *out++ = vec_and (in0, inb);\n+  *out++ = vec_and (inb, in0);\n+  *out++ = vec_andc (in0, in1);\n+  *out++ = vec_andc (in0, inb);\n+  *out++ = vec_andc (inb, in0);\n+  *out++ = vec_ceil (in0);\n+  *p_b++ = vec_cmpeq (in0, in1);\n+  *p_b++ = vec_cmpgt (in0, in1);\n+  *p_b++ = vec_cmpge (in0, in1);\n+  *p_b++ = vec_cmplt (in0, in1);\n+  *p_b++ = vec_cmple (in0, in1);\n+  *out++ = vec_div (in0, in1);\n+  *out++ = vec_floor (in0);\n+  *out++ = vec_madd (in0, in1, in2);\n+  *out++ = vec_msub (in0, in1, in2);\n+  *out++ = vec_max (in0, in1);\n+  *out++ = vec_min (in0, in1);\n+  *out++ = vec_msub (in0, in1, in2);\n+  *out++ = vec_mul (in0, in1);\n+  *out++ = vec_nearbyint (in0);\n+  *out++ = vec_nmadd (in0, in1, in2);\n+  *out++ = vec_nmsub (in0, in1, in2);\n+  *out++ = vec_nor (in0, in1);\n+  *out++ = vec_or (in0, in1);\n+  *out++ = vec_or (in0, inb);\n+  *out++ = vec_or (inb, in0);\n+  *out++ = vec_perm (in0, in1, uc);\n+  *out++ = vec_rint (in0);\n+  *out++ = vec_sel (in0, in1, inl);\n+  *out++ = vec_sel (in0, in1, inb);\n+  *out++ = vec_sub (in0, in1);\n+  *out++ = vec_sqrt (in0);\n+  *out++ = vec_trunc (in0);\n+  *out++ = vec_xor (in0, in1);\n+  *out++ = vec_xor (in0, inb);\n+  *out++ = vec_xor (inb, in0);\n+\n+  *i++ = vec_all_eq (in0, in1);\n+  *i++ = vec_all_ge (in0, in1);\n+  *i++ = vec_all_gt (in0, in1);\n+  *i++ = vec_all_le (in0, in1);\n+  *i++ = vec_all_lt (in0, in1);\n+  *i++ = vec_all_nan (in0);\n+  *i++ = vec_all_ne (in0, in1);\n+  *i++ = vec_all_nge (in0, in1);\n+  *i++ = vec_all_ngt (in0, in1);\n+  *i++ = vec_all_nle (in0, in1);\n+  *i++ = vec_all_nlt (in0, in1);\n+  *i++ = vec_all_numeric (in0);\n+  *i++ = vec_any_eq (in0, in1);\n+  *i++ = vec_any_ge (in0, in1);\n+  *i++ = vec_any_gt (in0, in1);\n+  *i++ = vec_any_le (in0, in1);\n+  *i++ = vec_any_lt (in0, in1);\n+  *i++ = vec_any_nan (in0);\n+  *i++ = vec_any_ne (in0, in1);\n+  *i++ = vec_any_nge (in0, in1);\n+  *i++ = vec_any_ngt (in0, in1);\n+  *i++ = vec_any_nle (in0, in1);\n+  *i++ = vec_any_nlt (in0, in1);\n+  *i++ = vec_any_numeric (in0);\n+}"}, {"sha": "050292b3febce918e279fd7b85b330e5e4041674", "filename": "gcc/testsuite/lib/target-supports.exp", "status": "modified", "additions": 57, "deletions": 3, "changes": 60, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/29e6733c20c98fe73c79ca9cac2dd758f3b3d67e/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp?ref=29e6733c20c98fe73c79ca9cac2dd758f3b3d67e", "patch": "@@ -902,6 +902,32 @@ proc check_sse2_hw_available { } {\n     }]\n }\n \n+# Return 1 if the target supports executing VSX instructions, 0\n+# otherwise.  Cache the result.\n+\n+proc check_vsx_hw_available { } {\n+    return [check_cached_effective_target vsx_hw_available {\n+\t# Some simulators are known to not support VSX instructions.\n+\t# For now, disable on Darwin\n+\tif { [istarget powerpc-*-eabi] || [istarget powerpc*-*-eabispe] || [istarget *-*-darwin*]} {\n+\t    expr 0\n+\t} else {\n+\t    set options \"-mvsx\"\n+\t    check_runtime_nocache vsx_hw_available {\n+\t\tint main()\n+\t\t{\n+\t\t#ifdef __MACH__\n+\t\t  asm volatile (\"xxlor vs0,vs0,vs0\");\n+\t\t#else\n+\t\t  asm volatile (\"xxlor 0,0,0\");\n+\t        #endif\n+\t\t  return 0;\n+\t\t}\n+\t    } $options\n+\t}\n+    }]\n+}\n+\n # Return 1 if the target supports executing AltiVec instructions, 0\n # otherwise.  Cache the result.\n \n@@ -912,12 +938,13 @@ proc check_vmx_hw_available { } {\n \t    expr 0\n \t} else {\n \t    # Most targets don't require special flags for this test case, but\n-\t    # Darwin does.\n+\t    # Darwin does.  Just to be sure, make sure VSX is not enabled for\n+\t    # the altivec tests.\n \t    if { [istarget *-*-darwin*]\n \t\t || [istarget *-*-aix*] } {\n-\t\tset options \"-maltivec\"\n+\t\tset options \"-maltivec -mno-vsx\"\n \t    } else {\n-\t\tset options \"\"\n+\t\tset options \"-mno-vsx\"\n \t    }\n \t    check_runtime_nocache vmx_hw_available {\n \t\tint main()\n@@ -1632,6 +1659,33 @@ proc check_effective_target_powerpc_altivec_ok { } {\n     }\n }\n \n+# Return 1 if this is a PowerPC target supporting -mvsx\n+\n+proc check_effective_target_powerpc_vsx_ok { } {\n+    if { ([istarget powerpc*-*-*]\n+         && ![istarget powerpc-*-linux*paired*])\n+\t || [istarget rs6000-*-*] } {\n+\t# AltiVec is not supported on AIX before 5.3.\n+\tif { [istarget powerpc*-*-aix4*]\n+\t     || [istarget powerpc*-*-aix5.1*] \n+\t     || [istarget powerpc*-*-aix5.2*] } {\n+\t    return 0\n+\t}\n+\treturn [check_no_compiler_messages powerpc_vsx_ok object {\n+\t    int main (void) {\n+#ifdef __MACH__\n+\t\tasm volatile (\"xxlor vs0,vs0,vs0\");\n+#else\n+\t\tasm volatile (\"xxlor 0,0,0\");\n+#endif\n+\t\treturn 0;\n+\t    }\n+\t} \"-mvsx\"]\n+    } else {\n+\treturn 0\n+    }\n+}\n+\n # Return 1 if this is a PowerPC target supporting -mcpu=cell.\n \n proc check_effective_target_powerpc_ppu_ok { } {"}]}