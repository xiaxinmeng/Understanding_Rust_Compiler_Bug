{"sha": "cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "node_id": "C_kwDOANBUbNoAKGNmNDY3ZmI5M2I3YjkyMzMwZGRjYjljOGZlN2M5M2RmNDVjZThlNDA", "commit": {"author": {"name": "John David Anglin", "email": "danglin@gcc.gnu.org", "date": "2023-01-13T19:22:49Z"}, "committer": {"name": "John David Anglin", "email": "danglin@gcc.gnu.org", "date": "2023-01-13T19:24:15Z"}, "message": "Fix support for atomic loads and stores on hppa.\n\nThis change updates the atomic libcall support to fix the following\nissues:\n\n1) A internal compiler error with -fno-sync-libcalls.\n2) When sync libcalls are disabled, we don't generate libcalls for\n   libatomic.\n3) There is no sync libcall support for targets other than linux.\n   As a result, non-atomic stores are silently emitted for types\n   smaller or equal to the word size.  There are now a few atomic\n   libcalls in the libgcc code, so we need sync support on all\n   targets.\n\n2023-01-13  John David Anglin  <danglin@gcc.gnu.org>\n\ngcc/ChangeLog:\n\n\t* config/pa/pa-linux.h (TARGET_SYNC_LIBCALL): Delete define.\n\t* config/pa/pa.cc (pa_init_libfuncs): Use MAX_SYNC_LIBFUNC_SIZE\n\tdefine.\n\t* config/pa/pa.h (TARGET_SYNC_LIBCALLS): Use flag_sync_libcalls.\n\t(MAX_SYNC_LIBFUNC_SIZE): Define.\n\t(TARGET_CPU_CPP_BUILTINS): Define __SOFTFP__ when soft float is\n\tenabled.\n\t* config/pa/pa.md (atomic_storeqi): Emit __atomic_exchange_1\n\tlibcall when sync libcalls are disabled.\n\t(atomic_storehi, atomic_storesi, atomic_storedi): Likewise.\n\t(atomic_loaddi): Emit __atomic_load_8 libcall when sync libcalls\n\tare disabled on 32-bit target.\n\t* config/pa/pa.opt (matomic-libcalls): New option.\n\t* doc/invoke.texi (HPPA Options): Update.\n\nlibgcc/ChangeLog:\n\n\t* config.host (hppa*64*-*-linux*): Adjust tmake_file to use\n\tpa/t-pa64-linux.\n\t(hppa*64*-*-hpux11*): Adjust tmake_file to use pa/t-pa64-hpux\n\tinstead of pa/t-hpux and pa/t-pa64.\n\t* config/pa/linux-atomic.c: Define u32 type.\n\t(ATOMIC_LOAD): Define new macro to implement atomic_load_1,\n\tatomic_load_2, atomic_load_4 and atomic_load_8.  Update sync\n\tdefines to use atomic_load calls for type.\n\t(SYNC_LOCK_LOAD_2): New macro to implement __sync_lock_load_8.\n\t* config/pa/sync-libfuncs.c: New file.\n\t* config/pa/t-netbsd (LIB2ADD_ST): Define.\n\t* config/pa/t-openbsd (LIB2ADD_ST): Define.\n\t* config/pa/t-pa64-hpux: New file.\n\t* config/pa/t-pa64-linux: New file.", "tree": {"sha": "821c49d285046168caf441f057bb2ab1e499b87c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/821c49d285046168caf441f057bb2ab1e499b87c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/comments", "author": null, "committer": null, "parents": [{"sha": "733a1b777f16cd397b43a242d9c31761f66d3da8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/733a1b777f16cd397b43a242d9c31761f66d3da8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/733a1b777f16cd397b43a242d9c31761f66d3da8"}], "stats": {"total": 739, "additions": 628, "deletions": 111}, "files": [{"sha": "1073f42bd6be2a191331570a6e5833e97c673a9a", "filename": "gcc/config/pa/pa-linux.h", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa-linux.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa-linux.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fpa-linux.h?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -133,9 +133,6 @@ along with GCC; see the file COPYING3.  If not see\n #undef TARGET_GAS\n #define TARGET_GAS 1\n \n-#undef TARGET_SYNC_LIBCALL\n-#define TARGET_SYNC_LIBCALL 1\n-\n /* The SYNC operations are implemented as library functions, not\n    INSN patterns.  As a result, the HAVE defines for the patterns are\n    not defined.  We need to define them to generate the corresponding"}, {"sha": "b43a91f2edb74401b4565c21f7458e84721970be", "filename": "gcc/config/pa/pa.cc", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fpa.cc?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -5940,8 +5940,8 @@ pa_init_libfuncs (void)\n \t\t\t\"_U_Qfcnvxf_udbl_to_quad\");\n     }\n \n-  if (TARGET_SYNC_LIBCALL)\n-    init_sync_libfuncs (8);\n+  if (TARGET_SYNC_LIBCALLS)\n+    init_sync_libfuncs (MAX_SYNC_LIBFUNC_SIZE);\n }\n \n /* HP's millicode routines mean something special to the assembler."}, {"sha": "93d6f53f97f9f7299d738607aba2581f27e14c2f", "filename": "gcc/config/pa/pa.h", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fpa.h?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -72,10 +72,12 @@ extern unsigned long total_code_bytes;\n #define HPUX_LONG_DOUBLE_LIBRARY 0\n #endif\n \n-/* Linux kernel atomic operation support.  */\n-#ifndef TARGET_SYNC_LIBCALL\n-#define TARGET_SYNC_LIBCALL 0\n-#endif\n+/* Sync libcall support.  */\n+#define TARGET_SYNC_LIBCALLS (flag_sync_libcalls)\n+\n+/* The maximum size of the sync library functions supported.  DImode\n+   is supported on 32-bit targets using floating point loads and stores.  */\n+#define MAX_SYNC_LIBFUNC_SIZE 8\n \n /* The following three defines are potential target switches.  The current\n    defines are optimal given the current capabilities of GAS and GNU ld.  */\n@@ -173,6 +175,8 @@ do {\t\t\t\t\t\t\t\t\\\n        builtin_define(\"_PA_RISC1_0\");\t\t\t\t\\\n      if (HPUX_LONG_DOUBLE_LIBRARY)\t\t\t\t\\\n        builtin_define(\"__SIZEOF_FLOAT128__=16\");\t\t\\\n+     if (TARGET_SOFT_FLOAT)\t\t\t\t\t\\\n+       builtin_define(\"__SOFTFP__\");\t\t\t\t\\\n } while (0)\n \n /* An old set of OS defines for various BSD-like systems.  */"}, {"sha": "71f391f2bf70dab9d562f1d8d3b46eb056912c74", "filename": "gcc/config/pa/pa.md", "status": "modified", "additions": 107, "deletions": 17, "changes": 124, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fpa.md?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -10360,43 +10360,81 @@ add,l %2,%3,%3\\;bv,n %%r0(%3)\"\n ;; doubleword loads and stores are not guaranteed to be atomic\n ;; when referencing the I/O address space.\n \n-;; These patterns are at the bottom so the non atomic versions are preferred.\n+;; Atomic and sync libcalls use different lock sets.  Great care is\n+;; needed if both are used in a single application.\n+\n+;; Atomic load and store libcalls are enabled by the -matomic-libcalls\n+;; option.  This option is not enabled by default as the generated\n+;; libcalls depend on libatomic which is not built until the end of\n+;; the gcc build.  For loads, we only need an atomic libcall for DImode.\n+;; Sync libcalls are not generated when atomic libcalls are enabled.\n+\n+;; Sync libcalls are enabled by default when supported.  They can be\n+;; disabled by the -fno-sync-libcalls option.  Sync libcalls always\n+;; use a single memory store in their implementation, even for DImode.\n+;; DImode stores are done using either std or fstd.  Thus, we only\n+;; need a sync load libcall for DImode when we don't have an atomic\n+;; processor load available for the mode (TARGET_SOFT_FLOAT).\n+\n+;; Implement atomic QImode store using exchange.\n \n (define_expand \"atomic_storeqi\"\n   [(match_operand:QI 0 \"memory_operand\")                ;; memory\n    (match_operand:QI 1 \"register_operand\")              ;; val out\n    (match_operand:SI 2 \"const_int_operand\")]            ;; model\n   \"\"\n {\n-  if (TARGET_SYNC_LIBCALL)\n+  rtx addr, libfunc;\n+\n+  if (TARGET_SYNC_LIBCALLS)\n     {\n-      rtx libfunc = optab_libfunc (sync_lock_test_and_set_optab, QImode);\n-      rtx addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = optab_libfunc (sync_lock_test_and_set_optab, QImode);\n+      emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n+\t\t\t operands[1], QImode);\n+      DONE;\n+    }\n \n+  if (TARGET_ATOMIC_LIBCALLS)\n+    {\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = init_one_libfunc (\"__atomic_exchange_1\");\n       emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n \t\t\t operands[1], QImode);\n       DONE;\n     }\n+\n   FAIL;\n })\n \n-;; Implement atomic HImode stores using exchange.\n+;; Implement atomic HImode store using exchange.\n \n (define_expand \"atomic_storehi\"\n   [(match_operand:HI 0 \"memory_operand\")                ;; memory\n    (match_operand:HI 1 \"register_operand\")              ;; val out\n    (match_operand:SI 2 \"const_int_operand\")]            ;; model\n   \"\"\n {\n-  if (TARGET_SYNC_LIBCALL)\n+  rtx addr, libfunc;\n+\n+  if (TARGET_SYNC_LIBCALLS)\n     {\n-      rtx libfunc = optab_libfunc (sync_lock_test_and_set_optab, HImode);\n-      rtx addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = optab_libfunc (sync_lock_test_and_set_optab, HImode);\n+      emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n+\t\t\t operands[1], HImode);\n+      DONE;\n+    }\n \n+  if (TARGET_ATOMIC_LIBCALLS)\n+    {\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = init_one_libfunc (\"__atomic_exchange_2\");\n       emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n \t\t\t operands[1], HImode);\n       DONE;\n     }\n+\n   FAIL;\n })\n \n@@ -10408,33 +10446,75 @@ add,l %2,%3,%3\\;bv,n %%r0(%3)\"\n    (match_operand:SI 2 \"const_int_operand\")]            ;; model\n   \"\"\n {\n-  if (TARGET_SYNC_LIBCALL)\n+  rtx addr, libfunc;\n+\n+  if (TARGET_SYNC_LIBCALLS)\n     {\n-      rtx libfunc = optab_libfunc (sync_lock_test_and_set_optab, SImode);\n-      rtx addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = optab_libfunc (sync_lock_test_and_set_optab, SImode);\n+      emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n+\t\t\t operands[1], SImode);\n+      DONE;\n+    }\n \n+  if (TARGET_ATOMIC_LIBCALLS)\n+    {\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = init_one_libfunc (\"__atomic_exchange_4\");\n       emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n \t\t\t operands[1], SImode);\n       DONE;\n     }\n+\n   FAIL;\n })\n \n ;; Implement atomic DImode load.\n \n+;; We need an atomic or sync libcall whenever the processor load or\n+;; store used for DImode is not atomic.  The 32-bit libatomic\n+;; implementation uses a pair of stw instructions.  They are not\n+;; atomic, so we need to call __atomic_load_8.  The linux libgcc\n+;; sync implementation uses a std or fstd instruction.  They are\n+;; atomic, so we only need to call __sync_load_8 when the load\n+;; operation would not be atomic (e.g., 32-bit TARGET_SOFT_FLOAT).\n+\n (define_expand \"atomic_loaddi\"\n   [(match_operand:DI 0 \"register_operand\")              ;; val out\n    (match_operand:DI 1 \"memory_operand\")                ;; memory\n    (match_operand:SI 2 \"const_int_operand\")]            ;; model\n   \"\"\n {\n   enum memmodel model;\n+  rtx addr, libfunc;\n \n-  if (TARGET_64BIT || TARGET_SOFT_FLOAT)\n+  if (TARGET_64BIT)\n     FAIL;\n \n+  if (TARGET_SYNC_LIBCALLS && MAX_SYNC_LIBFUNC_SIZE >= 8 && TARGET_SOFT_FLOAT)\n+    {\n+      addr = convert_memory_address (Pmode, XEXP (operands[1], 0));\n+      libfunc = init_one_libfunc (\"__sync_load_8\");\n+      emit_library_call_value (libfunc, operands[0], LCT_NORMAL, DImode,\n+\t\t\t       addr, Pmode);\n+      DONE;\n+    }\n+\n+  if (TARGET_ATOMIC_LIBCALLS && TARGET_SOFT_FLOAT)\n+    {\n+      addr = convert_memory_address (Pmode, XEXP (operands[1], 0));\n+      libfunc = init_one_libfunc (\"__atomic_load_8\");\n+      emit_library_call_value (libfunc, operands[0], LCT_NORMAL, DImode,\n+\t\t\t       addr, Pmode);\n+      DONE;\n+    }\n+\n+  if (TARGET_SOFT_FLOAT)\n+    FAIL;\n+\n+  /* Fallback to processor load with barriers.  */\n   model = memmodel_from_int (INTVAL (operands[2]));\n-  operands[1] = force_reg (SImode, XEXP (operands[1], 0));\n+  operands[1] = force_reg (Pmode, XEXP (operands[1], 0));\n   if (is_mm_seq_cst (model))\n     expand_mem_thread_fence (model);\n   emit_insn (gen_atomic_loaddi_1 (operands[0], operands[1]));\n@@ -10460,12 +10540,21 @@ add,l %2,%3,%3\\;bv,n %%r0(%3)\"\n   \"\"\n {\n   enum memmodel model;\n+  rtx addr, libfunc;\n \n-  if (TARGET_SYNC_LIBCALL)\n+  if (TARGET_SYNC_LIBCALLS && MAX_SYNC_LIBFUNC_SIZE >= 8)\n     {\n-      rtx libfunc = optab_libfunc (sync_lock_test_and_set_optab, DImode);\n-      rtx addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = optab_libfunc (sync_lock_test_and_set_optab, DImode);\n+      emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n+\t\t\t operands[1], DImode);\n+      DONE;\n+    }\n \n+  if (TARGET_ATOMIC_LIBCALLS)\n+    {\n+      addr = convert_memory_address (Pmode, XEXP (operands[0], 0));\n+      libfunc = init_one_libfunc (\"__atomic_exchange_8\");\n       emit_library_call (libfunc, LCT_NORMAL, VOIDmode, addr, Pmode,\n \t\t\t operands[1], DImode);\n       DONE;\n@@ -10474,8 +10563,9 @@ add,l %2,%3,%3\\;bv,n %%r0(%3)\"\n   if (TARGET_64BIT || TARGET_SOFT_FLOAT)\n     FAIL;\n \n+  /* Fallback to processor store with barriers.  */\n   model = memmodel_from_int (INTVAL (operands[2]));\n-  operands[0] = force_reg (SImode, XEXP (operands[0], 0));\n+  operands[0] = force_reg (Pmode, XEXP (operands[0], 0));\n   if (operands[1] != CONST0_RTX (DImode))\n     operands[1] = force_reg (DImode, operands[1]);\n   expand_mem_thread_fence (model);"}, {"sha": "2d074f5fe88ac3efb332af471425bee08567d06e", "filename": "gcc/config/pa/pa.opt", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fconfig%2Fpa%2Fpa.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fpa.opt?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -37,6 +37,10 @@ march=2.0\n Target RejectNegative\n Generate PA2.0 code (requires binutils 2.10 or later).\n \n+matomic-libcalls\n+Target Var(TARGET_ATOMIC_LIBCALLS) Init(1)\n+Generate libcalls for atomic loads and stores when sync libcalls are disabled.\n+\n mbig-switch\n Target Ignore\n Does nothing.  Preserved for backward compatibility."}, {"sha": "dec0cdb9d35058a5c20f4655b8d96033236734f8", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 105, "deletions": 66, "changes": 171, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -975,17 +975,18 @@ Objective-C and Objective-C++ Dialects}.\n \n @emph{HPPA Options}\n @gccoptlist{-march=@var{architecture-type} @gol\n+-matomic-libcalls  -mbig-switch @gol\n -mcaller-copies  -mdisable-fpregs  -mdisable-indexing @gol\n--mfast-indirect-calls  -mgas  -mgnu-ld   -mhp-ld @gol\n+-mordered  -mfast-indirect-calls  -mgas  -mgnu-ld   -mhp-ld @gol\n -mfixed-range=@var{register-range} @gol\n--mjump-in-delay  -mlinker-opt  -mlong-calls @gol\n--mlong-load-store  -mno-disable-fpregs @gol\n+-mcoherent-ldcw -mjump-in-delay  -mlinker-opt  -mlong-calls @gol\n+-mlong-load-store  -mno-atomic-libcalls  -mno-disable-fpregs @gol\n -mno-disable-indexing  -mno-fast-indirect-calls  -mno-gas @gol\n -mno-jump-in-delay  -mno-long-load-store @gol\n -mno-portable-runtime  -mno-soft-float @gol\n -mno-space-regs  -msoft-float  -mpa-risc-1-0 @gol\n -mpa-risc-1-1  -mpa-risc-2-0  -mportable-runtime @gol\n--mschedule=@var{cpu-type}  -mspace-regs  -msio  -mwsio @gol\n+-mschedule=@var{cpu-type}  -mspace-regs  -msoft-mult  -msio  -mwsio @gol\n -munix=@var{unix-std}  -nolibdld  -static  -threads}\n \n @emph{IA-64 Options}\n@@ -24895,6 +24896,33 @@ other way around.\n @opindex mpa-risc-2-0\n Synonyms for @option{-march=1.0}, @option{-march=1.1}, and @option{-march=2.0} respectively.\n \n+@item -matomic-libcalls\n+@opindex matomic-libcalls\n+@opindex mno-atomic-libcalls\n+Generate libcalls for atomic loads and stores when sync libcalls are disabled.\n+This option is enabled by default.  It only affects the generation of\n+atomic libcalls by the HPPA backend.\n+\n+Both the sync and @file{libatomic} libcall implementations use locking.\n+As a result, processor stores are not atomic with respect to other\n+atomic operations.  Processor loads up to DImode are atomic with\n+respect to other atomic operations provided they are implemented as\n+a single access.\n+\n+The PA-RISC architecture does not support any atomic operations in\n+hardware except for the @code{ldcw} instruction.  Thus, all atomic\n+support is implemented using sync and atomic libcalls.  Sync libcall\n+support is in @file{libgcc.a}.  Atomic libcall support is in\n+@file{libatomic}.\n+\n+This option generates @code{__atomic_exchange} calls for atomic stores.\n+It also provides special handling for atomic DImode accesses on 32-bit\n+targets.\n+\n+@item -mbig-switch\n+@opindex mbig-switch\n+Does nothing.  Preserved for backward compatibility.\n+\n @item -mcaller-copies\n @opindex mcaller-copies\n The caller copies function arguments passed by hidden reference.  This\n@@ -24903,30 +24931,19 @@ option should be used with care as it is not compatible with the default\n passed by hidden reference and the option provides better compatibility\n with OpenMP.\n \n-@item -mjump-in-delay\n-@opindex mjump-in-delay\n-This option is ignored and provided for compatibility purposes only.\n+@item -mcoherent-ldcw\n+@opindex mcoherent-ldcw\n+Use ldcw/ldcd coherent cache-control hint.\n \n @item -mdisable-fpregs\n @opindex mdisable-fpregs\n-Prevent floating-point registers from being used in any manner.  This is\n-necessary for compiling kernels that perform lazy context switching of\n-floating-point registers.  If you use this option and attempt to perform\n-floating-point operations, the compiler aborts.\n+Disable floating-point registers.  Equivalent to @code{-msoft-float}.\n \n @item -mdisable-indexing\n @opindex mdisable-indexing\n Prevent the compiler from using indexing address modes.  This avoids some\n rather obscure problems when compiling MIG generated code under MACH@.\n \n-@item -mno-space-regs\n-@opindex mno-space-regs\n-@opindex mspace-regs\n-Generate code that assumes the target has no space registers.  This allows\n-GCC to generate faster indirect calls and use unscaled index address modes.\n-\n-Such code is suitable for level 0 PA systems and kernels.\n-\n @item -mfast-indirect-calls\n @opindex mfast-indirect-calls\n Generate code that assumes calls never cross space boundaries.  This\n@@ -24943,57 +24960,10 @@ useful when compiling kernel code.  A register range is specified as\n two registers separated by a dash.  Multiple register ranges can be\n specified separated by a comma.\n \n-@item -mlong-load-store\n-@opindex mlong-load-store\n-Generate 3-instruction load and store sequences as sometimes required by\n-the HP-UX 10 linker.  This is equivalent to the @samp{+k} option to\n-the HP compilers.\n-\n-@item -mportable-runtime\n-@opindex mportable-runtime\n-Use the portable calling conventions proposed by HP for ELF systems.\n-\n @item -mgas\n @opindex mgas\n Enable the use of assembler directives only GAS understands.\n \n-@item -mschedule=@var{cpu-type}\n-@opindex mschedule\n-Schedule code according to the constraints for the machine type\n-@var{cpu-type}.  The choices for @var{cpu-type} are @samp{700}\n-@samp{7100}, @samp{7100LC}, @samp{7200}, @samp{7300} and @samp{8000}.  Refer\n-to @file{/usr/lib/sched.models} on an HP-UX system to determine the\n-proper scheduling option for your machine.  The default scheduling is\n-@samp{8000}.\n-\n-@item -mlinker-opt\n-@opindex mlinker-opt\n-Enable the optimization pass in the HP-UX linker.  Note this makes symbolic\n-debugging impossible.  It also triggers a bug in the HP-UX 8 and HP-UX 9\n-linkers in which they give bogus error messages when linking some programs.\n-\n-@item -msoft-float\n-@opindex msoft-float\n-Generate output containing library calls for floating point.\n-@strong{Warning:} the requisite libraries are not available for all HPPA\n-targets.  Normally the facilities of the machine's usual C compiler are\n-used, but this cannot be done directly in cross-compilation.  You must make\n-your own arrangements to provide suitable library functions for\n-cross-compilation.\n-\n-@option{-msoft-float} changes the calling convention in the output file;\n-therefore, it is only useful if you compile @emph{all} of a program with\n-this option.  In particular, you need to compile @file{libgcc.a}, the\n-library that comes with GCC, with @option{-msoft-float} in order for\n-this to work.\n-\n-@item -msio\n-@opindex msio\n-Generate the predefine, @code{_SIO}, for server IO@.  The default is\n-@option{-mwsio}.  This generates the predefines, @code{__hp9000s700},\n-@code{__hp9000s700__} and @code{_WSIO}, for workstation IO@.  These\n-options are available under HP-UX and HI-UX@.\n-\n @item -mgnu-ld\n @opindex mgnu-ld\n Use options specific to GNU @command{ld}.\n@@ -25023,6 +24993,12 @@ configure option, GCC's program search path, and finally by the user's\n `gcc -print-prog-name=ld`}.  This option is only available on the 64-bit\n HP-UX GCC, i.e.@: configured with @samp{hppa*64*-*-hpux*}.\n \n+@item -mlinker-opt\n+@opindex mlinker-opt\n+Enable the optimization pass in the HP-UX linker.  Note this makes symbolic\n+debugging impossible.  It also triggers a bug in the HP-UX 8 and HP-UX 9\n+linkers in which they give bogus error messages when linking some programs.\n+\n @item -mlong-calls\n @opindex mno-long-calls\n @opindex mlong-calls\n@@ -25051,6 +25027,69 @@ symbol-difference or pc-relative calls should be relatively small.\n However, an indirect call is used on 32-bit ELF systems in pic code\n and it is quite long.\n \n+@item -mlong-load-store\n+@opindex mlong-load-store\n+Generate 3-instruction load and store sequences as sometimes required by\n+the HP-UX 10 linker.  This is equivalent to the @samp{+k} option to\n+the HP compilers.\n+\n+@item -mjump-in-delay\n+@opindex mjump-in-delay\n+This option is ignored and provided for compatibility purposes only.\n+\n+@item -mno-space-regs\n+@opindex mno-space-regs\n+@opindex mspace-regs\n+Generate code that assumes the target has no space registers.  This allows\n+GCC to generate faster indirect calls and use unscaled index address modes.\n+\n+Such code is suitable for level 0 PA systems and kernels.\n+\n+@item -mordered\n+@opindex mordered\n+Assume memory references are ordered and barriers are not needed.\n+\n+@item -mportable-runtime\n+@opindex mportable-runtime\n+Use the portable calling conventions proposed by HP for ELF systems.\n+\n+@item -mschedule=@var{cpu-type}\n+@opindex mschedule\n+Schedule code according to the constraints for the machine type\n+@var{cpu-type}.  The choices for @var{cpu-type} are @samp{700}\n+@samp{7100}, @samp{7100LC}, @samp{7200}, @samp{7300} and @samp{8000}.  Refer\n+to @file{/usr/lib/sched.models} on an HP-UX system to determine the\n+proper scheduling option for your machine.  The default scheduling is\n+@samp{8000}.\n+\n+@item -msio\n+@opindex msio\n+Generate the predefine, @code{_SIO}, for server IO@.  The default is\n+@option{-mwsio}.  This generates the predefines, @code{__hp9000s700},\n+@code{__hp9000s700__} and @code{_WSIO}, for workstation IO@.  These\n+options are available under HP-UX and HI-UX@.\n+\n+@item -msoft-float\n+@opindex msoft-float\n+Generate output containing library calls for floating point.\n+@strong{Warning:} the requisite libraries are not available for all HPPA\n+targets.  Normally the facilities of the machine's usual C compiler are\n+used, but this cannot be done directly in cross-compilation.  You must make\n+your own arrangements to provide suitable library functions for\n+cross-compilation.\n+\n+@option{-msoft-float} changes the calling convention in the output file;\n+therefore, it is only useful if you compile @emph{all} of a program with\n+this option.  In particular, you need to compile @file{libgcc.a}, the\n+library that comes with GCC, with @option{-msoft-float} in order for\n+this to work.\n+\n+@item -msoft-mult\n+@opindex msoft-mult\n+Use software integer multiplication.\n+\n+This disables the use of the @code{xmpyu} instruction.\n+\n @item -munix=@var{unix-std}\n @opindex march\n Generate compiler predefines and select a startfile for the specified"}, {"sha": "3e2c9109ab1c9481d3edd8c3ab5c5e35898f5adc", "filename": "libgcc/config.host", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig.host", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig.host", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig.host?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -633,7 +633,7 @@ h8300-*-linux*)\n \ttm_file=\"$tm_file h8300/h8300-lib.h\"\n \t;;\n hppa*64*-*-linux*)\n-\ttmake_file=\"$tmake_file pa/t-linux64 pa/t-dimode\"\n+\ttmake_file=\"$tmake_file pa/t-pa64-linux pa/t-dimode\"\n \ttmake_file=\"$tmake_file pa/t-softfp-sfdftf t-softfp\"\n \textra_parts=\"crtbegin.o crtbeginS.o crtbeginT.o crtend.o crtendS.o\"\n \t;;\n@@ -649,7 +649,7 @@ hppa*-*-linux*)\n \tmd_unwind_header=pa/linux-unwind.h\n \t;;\n hppa*64*-*-hpux11*)\n-\ttmake_file=\"$tmake_file pa/t-hpux pa/t-pa64 pa/t-dimode\"\n+\ttmake_file=\"$tmake_file pa/t-pa64-hpux pa/t-dimode\"\n \ttmake_file=\"$tmake_file pa/t-stublib t-libgcc-pic t-slibgcc\"\n \t# Set the libgcc version number\n \tif test x$ac_cv_sjlj_exceptions = xyes; then"}, {"sha": "1978e681f776c84a9d8ecac2521d530662767551", "filename": "libgcc/config/pa/linux-atomic.c", "status": "modified", "additions": 62, "deletions": 17, "changes": 79, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Flinux-atomic.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Flinux-atomic.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Fpa%2Flinux-atomic.c?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -32,6 +32,7 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n \n typedef unsigned char u8;\n typedef short unsigned int u16;\n+typedef unsigned int u32;\n #ifdef __LP64__\n typedef long unsigned int u64;\n #else\n@@ -115,6 +116,36 @@ __kernel_cmpxchg2 (volatile void *mem, const void *oldval, const void *newval,\n #define MASK_1 0xffu\n #define MASK_2 0xffffu\n \n+/* Load value with an atomic processor load if possible.  */\n+#define ATOMIC_LOAD(TYPE, WIDTH)\t\t\t\t\t\\\n+  static inline TYPE\t\t\t\t\t\t\t\\\n+  atomic_load_##WIDTH (volatile void *ptr)\t\t\t\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    return *(volatile TYPE *)ptr;\t\t\t\t\t\\\n+  }\n+\n+#if defined(__LP64__) || defined(__SOFTFP__)\n+ATOMIC_LOAD (u64, 8)\n+#else\n+static inline u64\n+atomic_load_8 (volatile void *ptr)\n+{\n+  u64 result;\n+  double tmp;\n+\n+  asm volatile (\"{fldds|fldd} 0(%2),%1\\n\\t\"\n+\t\t\"{fstds|fstd} %1,-16(%%sp)\\n\\t\"\n+\t\t\"{ldws|ldw} -16(%%sp),%0\\n\\t\"\n+\t\t\"{ldws|ldw} -12(%%sp),%R0\"\n+\t\t: \"=r\" (result), \"=f\" (tmp) : \"r\" (ptr): \"memory\");\n+  return result;\n+}\n+#endif\n+\n+ATOMIC_LOAD (u32, 4)\n+ATOMIC_LOAD (u16, 2)\n+ATOMIC_LOAD (u8, 1)\n+\n #define FETCH_AND_OP_2(OP, PFX_OP, INF_OP, TYPE, WIDTH, INDEX)\t\t\\\n   TYPE HIDDEN\t\t\t\t\t\t\t\t\\\n   __sync_fetch_and_##OP##_##WIDTH (volatile void *ptr, TYPE val)\t\\\n@@ -123,7 +154,7 @@ __kernel_cmpxchg2 (volatile void *mem, const void *oldval, const void *newval,\n     long failure;\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n     do {\t\t\t\t\t\t\t\t\\\n-      tmp = __atomic_load_n ((volatile TYPE *)ptr, __ATOMIC_RELAXED);\t\\\n+      tmp = atomic_load_##WIDTH ((volatile TYPE *)ptr);\t\t\t\\\n       newval = PFX_OP (tmp INF_OP val);\t\t\t\t\t\\\n       failure = __kernel_cmpxchg2 (ptr, &tmp, &newval, INDEX);\t\t\\\n     } while (failure != 0);\t\t\t\t\t\t\\\n@@ -160,7 +191,7 @@ FETCH_AND_OP_2 (nand, ~, &, u8, 1, 0)\n     long failure;\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n     do {\t\t\t\t\t\t\t\t\\\n-      tmp = __atomic_load_n ((volatile TYPE *)ptr, __ATOMIC_RELAXED);\t\\\n+      tmp = atomic_load_##WIDTH ((volatile TYPE *)ptr);\t\t\t\\\n       newval = PFX_OP (tmp INF_OP val);\t\t\t\t\t\\\n       failure = __kernel_cmpxchg2 (ptr, &tmp, &newval, INDEX);\t\t\\\n     } while (failure != 0);\t\t\t\t\t\t\\\n@@ -197,8 +228,7 @@ OP_AND_FETCH_2 (nand, ~, &, u8, 1, 0)\n     long failure;\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n     do {\t\t\t\t\t\t\t\t\\\n-      tmp = __atomic_load_n ((volatile unsigned int *)ptr,\t\t\\\n-\t\t\t     __ATOMIC_RELAXED);\t\t\t\t\\\n+      tmp = atomic_load_4 ((volatile unsigned int *)ptr);\t\t\\\n       failure = __kernel_cmpxchg (ptr, tmp, PFX_OP (tmp INF_OP val));\t\\\n     } while (failure != 0);\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n@@ -220,8 +250,7 @@ FETCH_AND_OP_WORD (nand, ~, &)\n     long failure;\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n     do {\t\t\t\t\t\t\t\t\\\n-      tmp = __atomic_load_n ((volatile unsigned int *)ptr,\t\t\\\n-\t\t\t     __ATOMIC_RELAXED);\t\t\t\t\\\n+      tmp = atomic_load_4 ((volatile unsigned int *)ptr);\t\t\\\n       failure = __kernel_cmpxchg (ptr, tmp, PFX_OP (tmp INF_OP val));\t\\\n     } while (failure != 0);\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n@@ -247,8 +276,7 @@ typedef unsigned char bool;\n \t\t\t\t\t\t\t\t\t\\\n     while (1)\t\t\t\t\t\t\t\t\\\n       {\t\t\t\t\t\t\t\t\t\\\n-\tactual_oldval = __atomic_load_n ((volatile TYPE *)ptr,\t\t\\\n-\t\t\t\t\t __ATOMIC_RELAXED);\t\t\\\n+\tactual_oldval = atomic_load_##WIDTH ((volatile TYPE *)ptr);\t\\\n \t\t\t\t\t\t\t\t\t\\\n \tif (__builtin_expect (oldval != actual_oldval, 0))\t\t\\\n \t  return actual_oldval;\t\t\t\t\t\t\\\n@@ -281,8 +309,7 @@ __sync_val_compare_and_swap_4 (volatile void *ptr, unsigned int oldval,\n     \n   while (1)\n     {\n-      actual_oldval = __atomic_load_n ((volatile unsigned int *)ptr,\n-\t\t\t\t       __ATOMIC_RELAXED);\n+      actual_oldval = atomic_load_4 ((volatile unsigned int *)ptr);\n \n       if (__builtin_expect (oldval != actual_oldval, 0))\n \treturn actual_oldval;\n@@ -310,8 +337,7 @@ TYPE HIDDEN\t\t\t\t\t\t\t\t\\\n     long failure;\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n     do {\t\t\t\t\t\t\t\t\\\n-      oldval = __atomic_load_n ((volatile TYPE *)ptr,\t\t\t\\\n-\t\t\t\t__ATOMIC_RELAXED);\t\t\t\\\n+      oldval = atomic_load_##WIDTH ((volatile TYPE *)ptr);\t\t\\\n       failure = __kernel_cmpxchg2 (ptr, &oldval, &val, INDEX);\t\t\\\n     } while (failure != 0);\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n@@ -322,14 +348,14 @@ SYNC_LOCK_TEST_AND_SET_2 (u64, 8, 3)\n SYNC_LOCK_TEST_AND_SET_2 (u16, 2, 1)\n SYNC_LOCK_TEST_AND_SET_2 (u8, 1, 0)\n \n-unsigned int HIDDEN\n+u32 HIDDEN\n __sync_lock_test_and_set_4 (volatile void *ptr, unsigned int val)\n {\n   long failure;\n   unsigned int oldval;\n \n   do {\n-    oldval = __atomic_load_n ((volatile unsigned int *)ptr, __ATOMIC_RELAXED);\n+    oldval = atomic_load_4 ((volatile unsigned int *)ptr);\n     failure = __kernel_cmpxchg (ptr, oldval, val);\n   } while (failure != 0);\n \n@@ -344,8 +370,7 @@ __sync_lock_test_and_set_4 (volatile void *ptr, unsigned int val)\n     long failure;\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\\\n     do {\t\t\t\t\t\t\t\\\n-      oldval = __atomic_load_n ((volatile TYPE *)ptr,\t\t\\\n-\t\t\t\t__ATOMIC_RELAXED);\t\t\\\n+      oldval = atomic_load_##WIDTH ((volatile TYPE *)ptr);\t\\\n       failure = __kernel_cmpxchg2 (ptr, &oldval, &val, INDEX);\t\\\n     } while (failure != 0);\t\t\t\t\t\\\n   }\n@@ -361,7 +386,27 @@ __sync_lock_release_4 (volatile void *ptr)\n   unsigned int oldval;\n \n   do {\n-    oldval = __atomic_load_n ((volatile unsigned int *)ptr, __ATOMIC_RELAXED);\n+    oldval = atomic_load_4 ((volatile unsigned int *)ptr);\n     failure = __kernel_cmpxchg (ptr, oldval, 0);\n   } while (failure != 0);\n }\n+\n+#ifndef __LP64__\n+#define SYNC_LOCK_LOAD_2(TYPE, WIDTH, INDEX)\t\t\t\t\\\n+  TYPE __sync_lock_load_##WIDTH (volatile void *) HIDDEN;\t\t\\\n+  TYPE\t\t\t\t\t\t\t\t\t\\\n+  __sync_lock_load_##WIDTH (volatile void *ptr)\t\t\t\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    TYPE oldval;\t\t\t\t\t\t\t\\\n+    long failure;\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    do {\t\t\t\t\t\t\t\t\\\n+      oldval = atomic_load_##WIDTH ((volatile TYPE *)ptr);\t\t\\\n+      failure = __kernel_cmpxchg2 (ptr, &oldval, &oldval, INDEX);\t\\\n+    } while (failure != 0);\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    return oldval;\t\t\t\t\t\t\t\\\n+  }\n+\n+SYNC_LOCK_LOAD_2 (u64, 8, 3)\n+#endif"}, {"sha": "c70be0fde73e555379da6083ce03875e2cc2f9e2", "filename": "libgcc/config/pa/sync-libfuncs.c", "status": "added", "additions": 324, "deletions": 0, "changes": 324, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Fsync-libfuncs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Fsync-libfuncs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Fpa%2Fsync-libfuncs.c?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -0,0 +1,324 @@\n+/* PA-RISC sync libfunc support.\n+   Copyright (C) 2008-2023 Free Software Foundation, Inc.\n+   Based on code contributed by CodeSourcery for ARM EABI Linux.\n+   Modifications for PA Linux by Helge Deller <deller@gmx.de>\n+   Revised for general use by John David Anglin <danglin@gcc.gnu.org>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+Under Section 7 of GPL version 3, you are granted additional\n+permissions described in the GCC Runtime Library Exception, version\n+3.1, as published by the Free Software Foundation.\n+\n+You should have received a copy of the GNU General Public License and\n+a copy of the GCC Runtime Library Exception along with this program;\n+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n+<http://www.gnu.org/licenses/>.  */\n+\n+typedef unsigned char u8;\n+typedef short unsigned int u16;\n+typedef unsigned int u32;\n+#ifdef __LP64__\n+typedef long unsigned int u64;\n+#else\n+typedef long long unsigned int u64;\n+#endif\n+\n+/* PA-RISC 2.0 supports out-of-order execution for loads and stores.\n+   Thus, we need to synchonize memory accesses.  For more info, see:\n+   \"Advanced Performance Features of the 64-bit PA-8000\" by Doug Hunt.  */\n+\n+typedef volatile int __attribute__((aligned (16))) ldcw_t;\n+static ldcw_t __atomicity_lock = 1;\n+\n+/* We want default visibility for the sync routines.  */\n+#undef VISIBILITY\n+#if defined(__hpux__) && !defined(__LP64__)\n+#define VISIBILITY\n+#else\n+#define VISIBILITY __attribute__ ((visibility (\"default\")))\n+#endif\n+\n+/* Perform ldcw operation in cache when possible.  The ldcw instruction\n+   is a full barrier.  */\n+#ifndef _PA_LDCW_INSN\n+# ifdef _PA_RISC2_0\n+# define _PA_LDCW_INSN \"ldcw,co\"\n+# else\n+# define _PA_LDCW_INSN \"ldcw\"\n+# endif\n+#endif\n+\n+static inline void\n+__sync_spin_lock (void)\n+{\n+  ldcw_t *lock = &__atomicity_lock;\n+  int tmp;\n+\n+  __asm__ __volatile__ (_PA_LDCW_INSN \" 0(%1),%0\\n\\t\"\n+\t\t\t\"cmpib,<>,n 0,%0,.+20\\n\\t\"\n+\t\t\t\"ldw,ma 0(%1),%0\\n\\t\"\n+\t\t\t\"cmpib,<> 0,%0,.-12\\n\\t\"\n+\t\t\t\"nop\\n\\t\"\n+\t\t\t\"b,n .-12\"\n+\t\t\t: \"=&r\" (tmp)\n+\t\t\t: \"r\" (lock)\n+\t\t\t: \"memory\");\n+}\n+\n+static inline void\n+__sync_spin_unlock (void)\n+{\n+  ldcw_t *lock = &__atomicity_lock;\n+  int tmp = 1;\n+\n+  /* Use ordered store for release.  */\n+  __asm__ __volatile__ (\"stw,ma %1,0(%0)\"\n+\t\t\t: : \"r\" (lock), \"r\" (tmp) : \"memory\");\n+}\n+\n+/* Load value with an atomic processor load if possible.  */\n+#define ATOMIC_LOAD(TYPE, WIDTH)\t\t\t\t\t\\\n+  static inline TYPE\t\t\t\t\t\t\t\\\n+  atomic_load_##WIDTH (volatile void *ptr)\t\t\t\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    return *(volatile TYPE *)ptr;\t\t\t\t\t\\\n+  }\n+\n+#if defined(__LP64__) || defined(__SOFTFP__)\n+ATOMIC_LOAD (u64, 8)\n+#else\n+static inline u64\n+atomic_load_8 (volatile void *ptr)\n+{\n+  u64 result;\n+  double tmp;\n+\n+  asm volatile (\"{fldds|fldd} 0(%2),%1\\n\\t\"\n+\t\t\"{fstds|fstd} %1,-16(%%sp)\\n\\t\"\n+\t\t\"{ldws|ldw} -16(%%sp),%0\\n\\t\"\n+\t\t\"{ldws|ldw} -12(%%sp),%R0\"\n+\t\t: \"=r\" (result), \"=f\" (tmp) : \"r\" (ptr): \"memory\");\n+  return result;\n+}\n+#endif\n+\n+ATOMIC_LOAD (u32, 4)\n+ATOMIC_LOAD (u16, 2)\n+ATOMIC_LOAD (u8, 1)\n+\n+/* Store value with an atomic processor store if possible.  */\n+#define ATOMIC_STORE(TYPE, WIDTH)\t\t\t\t\t\\\n+  static inline void\t\t\t\t\t\t\t\\\n+  atomic_store_##WIDTH (volatile void *ptr, TYPE value)\t\t\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    *(volatile TYPE *)ptr = value;\t\t\t\t\t\\\n+  }\n+\n+#if defined(__LP64__) || defined(__SOFTFP__)\n+ATOMIC_STORE (u64, 8)\n+#else\n+static inline void\n+atomic_store_8 (volatile void *ptr, u64 value)\n+{\n+  double tmp;\n+\n+  asm volatile (\"stws|stw} %2,-16(%%sp)\\n\\t\"\n+\t\t\"{stws|stw} %R2,-12(%%sp)\\n\\t\"\n+\t\t\"{fldds|fldd} -16(%%sp),%1\\n\\t\"\n+\t\t\"{fstds|fstd} %1,0(%0)\"\n+\t\t: \"=m\" (ptr), \"=&f\" (tmp) : \"r\" (value): \"memory\");\n+}\n+#endif\n+\n+ATOMIC_STORE (u32, 4)\n+ATOMIC_STORE (u16, 2)\n+ATOMIC_STORE (u8, 1)\n+\n+#define FETCH_AND_OP(OP, PFX_OP, INF_OP, TYPE, WIDTH)\t\t\t\\\n+  TYPE VISIBILITY\t\t\t\t\t\t\t\\\n+  __sync_fetch_and_##OP##_##WIDTH (volatile void *ptr, TYPE val)\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    TYPE tmp, newval;\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    __sync_spin_lock();\t\t\t\t\t\t\t\\\n+    tmp = atomic_load_##WIDTH (ptr);\t\t\t\t\t\\\n+    newval = PFX_OP (tmp INF_OP val);\t\t\t\t\t\\\n+    atomic_store_##WIDTH (ptr, newval);\t\t\t\t\t\\\n+    __sync_spin_unlock();\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    return tmp;\t\t\t\t\t\t\t\t\\\n+  }\n+\n+FETCH_AND_OP (add,   , +, u64, 8)\n+FETCH_AND_OP (sub,   , -, u64, 8)\n+FETCH_AND_OP (or,    , |, u64, 8)\n+FETCH_AND_OP (and,   , &, u64, 8)\n+FETCH_AND_OP (xor,   , ^, u64, 8)\n+FETCH_AND_OP (nand, ~, &, u64, 8)\n+\n+FETCH_AND_OP (add,   , +, u32, 4)\n+FETCH_AND_OP (sub,   , -, u32, 4)\n+FETCH_AND_OP (or,    , |, u32, 4)\n+FETCH_AND_OP (and,   , &, u32, 4)\n+FETCH_AND_OP (xor,   , ^, u32, 4)\n+FETCH_AND_OP (nand, ~, &, u32, 4)\n+\n+FETCH_AND_OP (add,   , +, u16, 2)\n+FETCH_AND_OP (sub,   , -, u16, 2)\n+FETCH_AND_OP (or,    , |, u16, 2)\n+FETCH_AND_OP (and,   , &, u16, 2)\n+FETCH_AND_OP (xor,   , ^, u16, 2)\n+FETCH_AND_OP (nand, ~, &, u16, 2)\n+\n+FETCH_AND_OP (add,   , +, u8, 1)\n+FETCH_AND_OP (sub,   , -, u8, 1)\n+FETCH_AND_OP (or,    , |, u8, 1)\n+FETCH_AND_OP (and,   , &, u8, 1)\n+FETCH_AND_OP (xor,   , ^, u8, 1)\n+FETCH_AND_OP (nand, ~, &, u8, 1)\n+\n+#define OP_AND_FETCH(OP, PFX_OP, INF_OP, TYPE, WIDTH)\t\t\t\\\n+  TYPE VISIBILITY \t\t\t\t\t\t\t\\\n+  __sync_##OP##_and_fetch_##WIDTH (volatile void *ptr, TYPE val)\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    TYPE tmp, newval;\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    __sync_spin_lock();\t\t\t\t\t\t\t\\\n+    tmp = atomic_load_##WIDTH (ptr);\t\t\t\t\t\\\n+    newval = PFX_OP (tmp INF_OP val);\t\t\t\t\t\\\n+    atomic_store_##WIDTH (ptr, newval);\t\t\t\t\t\\\n+    __sync_spin_unlock();\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    return newval;\t\t\t\t\t\t\t\\\n+  }\n+\n+OP_AND_FETCH (add,   , +, u64, 8)\n+OP_AND_FETCH (sub,   , -, u64, 8)\n+OP_AND_FETCH (or,    , |, u64, 8)\n+OP_AND_FETCH (and,   , &, u64, 8)\n+OP_AND_FETCH (xor,   , ^, u64, 8)\n+OP_AND_FETCH (nand, ~, &, u64, 8)\n+\n+OP_AND_FETCH (add,   , +, u32, 4)\n+OP_AND_FETCH (sub,   , -, u32, 4)\n+OP_AND_FETCH (or,    , |, u32, 4)\n+OP_AND_FETCH (and,   , &, u32, 4)\n+OP_AND_FETCH (xor,   , ^, u32, 4)\n+OP_AND_FETCH (nand, ~, &, u32, 4)\n+\n+OP_AND_FETCH (add,   , +, u16, 2)\n+OP_AND_FETCH (sub,   , -, u16, 2)\n+OP_AND_FETCH (or,    , |, u16, 2)\n+OP_AND_FETCH (and,   , &, u16, 2)\n+OP_AND_FETCH (xor,   , ^, u16, 2)\n+OP_AND_FETCH (nand, ~, &, u16, 2)\n+\n+OP_AND_FETCH (add,   , +, u8, 1)\n+OP_AND_FETCH (sub,   , -, u8, 1)\n+OP_AND_FETCH (or,    , |, u8, 1)\n+OP_AND_FETCH (and,   , &, u8, 1)\n+OP_AND_FETCH (xor,   , ^, u8, 1)\n+OP_AND_FETCH (nand, ~, &, u8, 1)\n+\n+#define COMPARE_AND_SWAP(TYPE, WIDTH)\t\t\t\t\t\\\n+  TYPE VISIBILITY \t\t\t\t\t\t\t\\\n+  __sync_val_compare_and_swap_##WIDTH (volatile void *ptr, TYPE oldval,\t\\\n+\t\t\t\t       TYPE newval)\t\t\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    TYPE actual_oldval;\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    __sync_spin_lock();\t\t\t\t\t\t\t\\\n+    actual_oldval = atomic_load_##WIDTH (ptr);\t\t\t\t\\\n+    if (actual_oldval == oldval)\t\t\t\t\t\\\n+      atomic_store_##WIDTH (ptr, newval);\t\t\t\t\\\n+    __sync_spin_unlock();\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    return actual_oldval;\t\t\t\t\t\t\\\n+  }\t\t\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+  _Bool VISIBILITY\t\t\t\t\t\t\t\\\n+  __sync_bool_compare_and_swap_##WIDTH (volatile void *ptr,\t\t\\\n+\t\t\t\t\tTYPE oldval, TYPE newval)\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    TYPE actual_oldval;\t\t\t\t\t\t\t\\\n+    _Bool result;\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    __sync_spin_lock();\t\t\t\t\t\t\t\\\n+    actual_oldval = atomic_load_##WIDTH (ptr);\t\t\t\t\\\n+    result = (actual_oldval == oldval);\t\t\t\t\t\\\n+    if (result)\t\t\t\t\t\t\t\t\\\n+      atomic_store_##WIDTH (ptr, newval);\t\t\t\t\\\n+    __sync_spin_unlock();\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    return result;\t\t\t\t\t\t\t\\\n+  }\n+\n+COMPARE_AND_SWAP (u64, 8)\n+COMPARE_AND_SWAP (u32, 4)\n+COMPARE_AND_SWAP (u16, 2)\n+COMPARE_AND_SWAP (u8, 1)\n+\n+#define SYNC_LOCK_TEST_AND_SET(TYPE, WIDTH)\t\t\t\t\\\n+TYPE VISIBILITY \t\t\t\t\t\t\t\\\n+  __sync_lock_test_and_set_##WIDTH (volatile void *ptr, TYPE val)\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    TYPE oldval;\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    __sync_spin_lock();\t\t\t\t\t\t\t\\\n+    oldval = atomic_load_##WIDTH (ptr);\t\t\t\t\t\\\n+    atomic_store_##WIDTH (ptr, val);\t\t\t\t\t\\\n+    __sync_spin_unlock();\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    return oldval;\t\t\t\t\t\t\t\\\n+  }\n+\n+SYNC_LOCK_TEST_AND_SET (u64, 8)\n+SYNC_LOCK_TEST_AND_SET (u32, 4)\n+SYNC_LOCK_TEST_AND_SET (u16, 2)\n+SYNC_LOCK_TEST_AND_SET (u8, 1)\n+\n+#define SYNC_LOCK_RELEASE(TYPE, WIDTH)\t\t\t\t\\\n+  void VISIBILITY\t\t\t\t\t\t\\\n+  __sync_lock_release_##WIDTH (volatile void *ptr)\t\t\\\n+  {\t\t\t\t\t\t\t\t\\\n+    TYPE val = 0;\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\\\n+    __sync_spin_lock();\t\t\t\t\t\t\\\n+    atomic_store_##WIDTH (ptr, val);\t\t\t\t\\\n+    __sync_spin_unlock();\t\t\t\t\t\\\n+  }\n+\n+SYNC_LOCK_RELEASE (u64, 8)\n+SYNC_LOCK_RELEASE (u32, 4)\n+SYNC_LOCK_RELEASE (u16, 2)\n+SYNC_LOCK_RELEASE (u8, 1)\n+\n+#define SYNC_LOCK_LOAD(TYPE, WIDTH)\t\t\t\t\t\\\n+TYPE VISIBILITY __sync_lock_load_##WIDTH (volatile void *); \t\t\\\n+TYPE VISIBILITY \t\t\t\t\t\t\t\\\n+  __sync_lock_load_##WIDTH (volatile void *ptr)\t\t\t\t\\\n+  {\t\t\t\t\t\t\t\t\t\\\n+    TYPE oldval;\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    __sync_spin_lock();\t\t\t\t\t\t\t\\\n+    oldval = atomic_load_##WIDTH (ptr);\t\t\t\t\t\\\n+    __sync_spin_unlock();\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+    return oldval;\t\t\t\t\t\t\t\\\n+  }\n+\n+SYNC_LOCK_LOAD (u64, 8)\n+SYNC_LOCK_LOAD (u32, 4)\n+SYNC_LOCK_LOAD (u16, 2)\n+SYNC_LOCK_LOAD (u8, 1)"}, {"sha": "13943940a379d3ee7c1f627b6f33c5c35bc01ea3", "filename": "libgcc/config/pa/t-netbsd", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-netbsd", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-netbsd", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Fpa%2Ft-netbsd?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -7,3 +7,4 @@ LIB1ASMFUNCS = _divI _divU _remI _remU _div_const _mulI _dyncall\n HOST_LIBGCC2_CFLAGS += -DELF=1 -DLINUX=1\n \n LIB2ADD = $(srcdir)/config/pa/fptr.c\n+LIB2ADD_ST = $(srcdir)/config/pa/sync-libfuncs.c"}, {"sha": "13943940a379d3ee7c1f627b6f33c5c35bc01ea3", "filename": "libgcc/config/pa/t-openbsd", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-openbsd", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-openbsd", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Fpa%2Ft-openbsd?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -7,3 +7,4 @@ LIB1ASMFUNCS = _divI _divU _remI _remU _div_const _mulI _dyncall\n HOST_LIBGCC2_CFLAGS += -DELF=1 -DLINUX=1\n \n LIB2ADD = $(srcdir)/config/pa/fptr.c\n+LIB2ADD_ST = $(srcdir)/config/pa/sync-libfuncs.c"}, {"sha": "55194e8f379b18756b01c0481a171652691a36d8", "filename": "libgcc/config/pa/t-pa64-hpux", "status": "added", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-pa64-hpux", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-pa64-hpux", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Fpa%2Ft-pa64-hpux?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -0,0 +1,4 @@\n+LIB2ADD = $(srcdir)/config/pa/quadlib.c\n+LIB2ADD_ST = $(srcdir)/config/pa/sync-libfuncs.c\n+\n+HOST_LIBGCC2_CFLAGS += -frandom-seed=fixed-seed -Dpa64=1 -DELF=1 -mlong-calls"}, {"sha": "026b48b02e5bb942a49e068f1fe2b6053a187114", "filename": "libgcc/config/pa/t-pa64-linux", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-pa64-linux", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40/libgcc%2Fconfig%2Fpa%2Ft-pa64-linux", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Fpa%2Ft-pa64-linux?ref=cf467fb93b7b92330ddcb9c8fe7c93df45ce8e40", "patch": "@@ -0,0 +1,8 @@\n+# Plug millicode routines into libgcc.a  We want these on both native and\n+# cross compiles.\n+LIB1ASMSRC = pa/milli64.S\n+LIB1ASMFUNCS = _divI _divU _remI _remU _div_const _mulI\n+\n+HOST_LIBGCC2_CFLAGS += -Dpa64=1 -DELF=1 -DLINUX=1\n+\n+LIB2ADD_ST = $(srcdir)/config/pa/linux-atomic.c"}]}