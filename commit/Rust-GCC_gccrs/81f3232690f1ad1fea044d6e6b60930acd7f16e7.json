{"sha": "81f3232690f1ad1fea044d6e6b60930acd7f16e7", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ODFmMzIzMjY5MGYxYWQxZmVhMDQ0ZDZlNmI2MDkzMGFjZDdmMTZlNw==", "commit": {"author": {"name": "Christian Borntraeger", "email": "borntraeger@de.ibm.com", "date": "2010-05-19T10:36:40Z"}, "committer": {"name": "Andreas Krebbel", "email": "krebbel@gcc.gnu.org", "date": "2010-05-19T10:36:40Z"}, "message": "tree-ssa-loop-prefetch.c (mem_ref_group, ar_data): Change step to tree.\n\n2010-05-19  Christian Borntraeger  <borntraeger@de.ibm.com>\n\n        * tree-ssa-loop-prefetch.c (mem_ref_group, ar_data): Change step\n\tto tree.\n        (dump_mem_ref): Adopt debug code to handle a tree as step.  This\n\talso checks for a constant int vs.  non-constant but\n\tloop-invariant steps.\n        (find_or_create_group): Change the sort algorithm to only consider\n\tsteps that are constant ints.\n        (idx_analyze_ref): Adopt code to handle a tree instead of a\n\tHOST_WIDE_INT for step.\n        (gather_memory_references_ref): Handle tree instead of int and be\n\tprepared to see a NULL_TREE.\n        (prune_ref_by_self_reuse, prune_ref_by_group_reuse): Do not prune\n\tprefetches if the step cannot be calculated at compile time.\n        (issue_prefetch_ref): Issue prefetches for non-constant but\n\tloop-invariant steps.\n\nFrom-SVN: r159557", "tree": {"sha": "c0ee374b336bbee90595123d3e694375b657303f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c0ee374b336bbee90595123d3e694375b657303f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/81f3232690f1ad1fea044d6e6b60930acd7f16e7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/81f3232690f1ad1fea044d6e6b60930acd7f16e7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/81f3232690f1ad1fea044d6e6b60930acd7f16e7", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/81f3232690f1ad1fea044d6e6b60930acd7f16e7/comments", "author": {"login": "borntraeger", "id": 3006059, "node_id": "MDQ6VXNlcjMwMDYwNTk=", "avatar_url": "https://avatars.githubusercontent.com/u/3006059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/borntraeger", "html_url": "https://github.com/borntraeger", "followers_url": "https://api.github.com/users/borntraeger/followers", "following_url": "https://api.github.com/users/borntraeger/following{/other_user}", "gists_url": "https://api.github.com/users/borntraeger/gists{/gist_id}", "starred_url": "https://api.github.com/users/borntraeger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/borntraeger/subscriptions", "organizations_url": "https://api.github.com/users/borntraeger/orgs", "repos_url": "https://api.github.com/users/borntraeger/repos", "events_url": "https://api.github.com/users/borntraeger/events{/privacy}", "received_events_url": "https://api.github.com/users/borntraeger/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "8abd2cbee209b2db1252d82bd3fb3908489df71f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8abd2cbee209b2db1252d82bd3fb3908489df71f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8abd2cbee209b2db1252d82bd3fb3908489df71f"}], "stats": {"total": 125, "additions": 93, "deletions": 32}, "files": [{"sha": "30ed7cb422b1cae41a1ab38ef95f98aa3e3d1969", "filename": "gcc/ChangeLog", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/81f3232690f1ad1fea044d6e6b60930acd7f16e7/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/81f3232690f1ad1fea044d6e6b60930acd7f16e7/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=81f3232690f1ad1fea044d6e6b60930acd7f16e7", "patch": "@@ -1,3 +1,21 @@\n+2010-05-19  Christian Borntraeger  <borntraeger@de.ibm.com>\n+\n+        * tree-ssa-loop-prefetch.c (mem_ref_group, ar_data): Change step\n+\tto tree.\n+        (dump_mem_ref): Adopt debug code to handle a tree as step.  This\n+\talso checks for a constant int vs.  non-constant but\n+\tloop-invariant steps.\n+        (find_or_create_group): Change the sort algorithm to only consider\n+\tsteps that are constant ints.\n+        (idx_analyze_ref): Adopt code to handle a tree instead of a\n+\tHOST_WIDE_INT for step.\n+        (gather_memory_references_ref): Handle tree instead of int and be\n+\tprepared to see a NULL_TREE.\n+        (prune_ref_by_self_reuse, prune_ref_by_group_reuse): Do not prune\n+\tprefetches if the step cannot be calculated at compile time.\n+        (issue_prefetch_ref): Issue prefetches for non-constant but\n+\tloop-invariant steps.\n+\n 2010-05-18  Nathan Froyd  <froydnj@codesourcery.com>\n \n \tRevert:"}, {"sha": "becde8914e1b85bfd04dc4feccba404f53b5dd72", "filename": "gcc/tree-ssa-loop-prefetch.c", "status": "modified", "additions": 75, "deletions": 32, "changes": 107, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/81f3232690f1ad1fea044d6e6b60930acd7f16e7/gcc%2Ftree-ssa-loop-prefetch.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/81f3232690f1ad1fea044d6e6b60930acd7f16e7/gcc%2Ftree-ssa-loop-prefetch.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-prefetch.c?ref=81f3232690f1ad1fea044d6e6b60930acd7f16e7", "patch": "@@ -216,7 +216,7 @@ along with GCC; see the file COPYING3.  If not see\n struct mem_ref_group\n {\n   tree base;\t\t\t/* Base of the reference.  */\n-  HOST_WIDE_INT step;\t\t/* Step of the reference.  */\n+  tree step;\t\t\t/* Step of the reference.  */\n   struct mem_ref *refs;\t\t/* References in the group.  */\n   struct mem_ref_group *next;\t/* Next group of references.  */\n };\n@@ -271,7 +271,10 @@ dump_mem_ref (FILE *file, struct mem_ref *ref)\n   fprintf (file, \"  group %p (base \", (void *) ref->group);\n   print_generic_expr (file, ref->group->base, TDF_SLIM);\n   fprintf (file, \", step \");\n-  fprintf (file, HOST_WIDE_INT_PRINT_DEC, ref->group->step);\n+  if (cst_and_fits_in_hwi (ref->group->step))\n+    fprintf (file, HOST_WIDE_INT_PRINT_DEC, int_cst_value (ref->group->step));\n+  else\n+    print_generic_expr (file, ref->group->step, TDF_TREE);\n   fprintf (file, \")\\n\");\n \n   fprintf (file, \"  delta \");\n@@ -287,19 +290,20 @@ dump_mem_ref (FILE *file, struct mem_ref *ref)\n    exist.  */\n \n static struct mem_ref_group *\n-find_or_create_group (struct mem_ref_group **groups, tree base,\n-\t\t      HOST_WIDE_INT step)\n+find_or_create_group (struct mem_ref_group **groups, tree base, tree step)\n {\n   struct mem_ref_group *group;\n \n   for (; *groups; groups = &(*groups)->next)\n     {\n-      if ((*groups)->step == step\n+      if (operand_equal_p ((*groups)->step, step, 0)\n \t  && operand_equal_p ((*groups)->base, base, 0))\n \treturn *groups;\n \n-      /* Keep the list of groups sorted by decreasing step.  */\n-      if ((*groups)->step < step)\n+      /* If step is an integer constant, keep the list of groups sorted\n+         by decreasing step.  */\n+        if (cst_and_fits_in_hwi ((*groups)->step) && cst_and_fits_in_hwi (step)\n+            && int_cst_value ((*groups)->step) < int_cst_value (step))\n \tbreak;\n     }\n \n@@ -384,7 +388,7 @@ struct ar_data\n {\n   struct loop *loop;\t\t\t/* Loop of the reference.  */\n   gimple stmt;\t\t\t\t/* Statement of the reference.  */\n-  HOST_WIDE_INT *step;\t\t\t/* Step of the memory reference.  */\n+  tree *step;\t\t\t\t/* Step of the memory reference.  */\n   HOST_WIDE_INT *delta;\t\t\t/* Offset of the memory reference.  */\n };\n \n@@ -396,23 +400,19 @@ idx_analyze_ref (tree base, tree *index, void *data)\n {\n   struct ar_data *ar_data = (struct ar_data *) data;\n   tree ibase, step, stepsize;\n-  HOST_WIDE_INT istep, idelta = 0, imult = 1;\n+  HOST_WIDE_INT idelta = 0, imult = 1;\n   affine_iv iv;\n \n   if (TREE_CODE (base) == MISALIGNED_INDIRECT_REF\n       || TREE_CODE (base) == ALIGN_INDIRECT_REF)\n     return false;\n \n   if (!simple_iv (ar_data->loop, loop_containing_stmt (ar_data->stmt),\n-\t\t  *index, &iv, false))\n+\t\t  *index, &iv, true))\n     return false;\n   ibase = iv.base;\n   step = iv.step;\n \n-  if (!cst_and_fits_in_hwi (step))\n-    return false;\n-  istep = int_cst_value (step);\n-\n   if (TREE_CODE (ibase) == POINTER_PLUS_EXPR\n       && cst_and_fits_in_hwi (TREE_OPERAND (ibase, 1)))\n     {\n@@ -425,18 +425,25 @@ idx_analyze_ref (tree base, tree *index, void *data)\n       ibase = build_int_cst (TREE_TYPE (ibase), 0);\n     }\n \n+  if (*ar_data->step == NULL_TREE)\n+    *ar_data->step = step;\n+  else\n+    *ar_data->step = fold_build2 (PLUS_EXPR, sizetype,\n+\t\t\t\t  fold_convert (sizetype, *ar_data->step),\n+\t\t\t\t  fold_convert (sizetype, step));\n   if (TREE_CODE (base) == ARRAY_REF)\n     {\n       stepsize = array_ref_element_size (base);\n       if (!cst_and_fits_in_hwi (stepsize))\n \treturn false;\n       imult = int_cst_value (stepsize);\n \n-      istep *= imult;\n+      *ar_data->step = fold_build2 (MULT_EXPR, sizetype,\n+\t\t\t\t    fold_convert (sizetype, *ar_data->step),\n+\t\t\t\t    fold_convert (sizetype, step));\n       idelta *= imult;\n     }\n \n-  *ar_data->step += istep;\n   *ar_data->delta += idelta;\n   *index = ibase;\n \n@@ -450,15 +457,15 @@ idx_analyze_ref (tree base, tree *index, void *data)\n \n static bool\n analyze_ref (struct loop *loop, tree *ref_p, tree *base,\n-\t     HOST_WIDE_INT *step, HOST_WIDE_INT *delta,\n+\t     tree *step, HOST_WIDE_INT *delta,\n \t     gimple stmt)\n {\n   struct ar_data ar_data;\n   tree off;\n   HOST_WIDE_INT bit_offset;\n   tree ref = *ref_p;\n \n-  *step = 0;\n+  *step = NULL_TREE;\n   *delta = 0;\n \n   /* First strip off the component references.  Ignore bitfields.  */\n@@ -493,15 +500,18 @@ static bool\n gather_memory_references_ref (struct loop *loop, struct mem_ref_group **refs,\n \t\t\t      tree ref, bool write_p, gimple stmt)\n {\n-  tree base;\n-  HOST_WIDE_INT step, delta;\n+  tree base, step;\n+  HOST_WIDE_INT delta;\n   struct mem_ref_group *agrp;\n \n   if (get_base_address (ref) == NULL)\n     return false;\n \n   if (!analyze_ref (loop, &ref, &base, &step, &delta, stmt))\n     return false;\n+  /* If analyze_ref fails the default is a NULL_TREE.  We can stop here.  */\n+  if (step == NULL_TREE)\n+    return false;\n \n   /* Now we know that REF = &BASE + STEP * iter + DELTA, where DELTA and STEP\n      are integer constants.  */\n@@ -576,8 +586,16 @@ gather_memory_references (struct loop *loop, bool *no_other_refs, unsigned *ref_\n static void\n prune_ref_by_self_reuse (struct mem_ref *ref)\n {\n-  HOST_WIDE_INT step = ref->group->step;\n-  bool backward = step < 0;\n+  HOST_WIDE_INT step;\n+  bool backward;\n+\n+  /* If the step size is non constant, we cannot calculate prefetch_mod.  */\n+  if (!cst_and_fits_in_hwi (ref->group->step))\n+    return;\n+\n+  step = int_cst_value (ref->group->step);\n+\n+  backward = step < 0;\n \n   if (step == 0)\n     {\n@@ -661,8 +679,8 @@ static void\n prune_ref_by_group_reuse (struct mem_ref *ref, struct mem_ref *by,\n \t\t\t  bool by_is_before)\n {\n-  HOST_WIDE_INT step = ref->group->step;\n-  bool backward = step < 0;\n+  HOST_WIDE_INT step;\n+  bool backward;\n   HOST_WIDE_INT delta_r = ref->delta, delta_b = by->delta;\n   HOST_WIDE_INT delta = delta_b - delta_r;\n   HOST_WIDE_INT hit_from;\n@@ -673,6 +691,16 @@ prune_ref_by_group_reuse (struct mem_ref *ref, struct mem_ref *by,\n   tree ref_type;\n   int align_unit;\n \n+  /* If the step is non constant we cannot calculate prefetch_before.  */\n+  if (!cst_and_fits_in_hwi (ref->group->step)) {\n+    return;\n+  }\n+\n+  step = int_cst_value (ref->group->step);\n+\n+  backward = step < 0;\n+\n+\n   if (delta == 0)\n     {\n       /* If the references has the same address, only prefetch the\n@@ -986,7 +1014,7 @@ static void\n issue_prefetch_ref (struct mem_ref *ref, unsigned unroll_factor, unsigned ahead)\n {\n   HOST_WIDE_INT delta;\n-  tree addr, addr_base, write_p, local;\n+  tree addr, addr_base, write_p, local, forward;\n   gimple prefetch;\n   gimple_stmt_iterator bsi;\n   unsigned n_prefetches, ap;\n@@ -1009,13 +1037,28 @@ issue_prefetch_ref (struct mem_ref *ref, unsigned unroll_factor, unsigned ahead)\n \n   for (ap = 0; ap < n_prefetches; ap++)\n     {\n-      /* Determine the address to prefetch.  */\n-      delta = (ahead + ap * ref->prefetch_mod) * ref->group->step;\n-      addr = fold_build2 (POINTER_PLUS_EXPR, ptr_type_node,\n-\t\t\t  addr_base, size_int (delta));\n-      addr = force_gimple_operand_gsi (&bsi, unshare_expr (addr), true, NULL,\n-\t\t\t\t       true, GSI_SAME_STMT);\n-\n+      if (cst_and_fits_in_hwi (ref->group->step))\n+        {\n+          /* Determine the address to prefetch.  */\n+          delta = (ahead + ap * ref->prefetch_mod) *\n+\t\t   int_cst_value (ref->group->step);\n+          addr = fold_build2 (POINTER_PLUS_EXPR, ptr_type_node,\n+                              addr_base, size_int (delta));\n+          addr = force_gimple_operand_gsi (&bsi, unshare_expr (addr), true, NULL,\n+                                           true, GSI_SAME_STMT);\n+        }\n+      else\n+        {\n+          /* The step size is non-constant but loop-invariant.  We use the\n+             heuristic to simply prefetch ahead iterations ahead.  */\n+          forward = fold_build2 (MULT_EXPR, sizetype,\n+                                 fold_convert (sizetype, ref->group->step),\n+                                 fold_convert (sizetype, size_int (ahead)));\n+          addr = fold_build2 (POINTER_PLUS_EXPR, ptr_type_node, addr_base,\n+\t\t\t      forward);\n+          addr = force_gimple_operand_gsi (&bsi, unshare_expr (addr), true,\n+\t\t\t\t\t   NULL, true, GSI_SAME_STMT);\n+      }\n       /* Create the prefetch instruction.  */\n       prefetch = gimple_build_call (built_in_decls[BUILT_IN_PREFETCH],\n \t\t\t\t    3, addr, write_p, local);"}]}