{"sha": "0b17ab2f5b1184fdb568786f791bc0613e574241", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGIxN2FiMmY1YjExODRmZGI1Njg3ODZmNzkxYmMwNjEzZTU3NDI0MQ==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2002-05-17T02:31:56Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2002-05-17T02:31:56Z"}, "message": "Revert \"Basic block renumbering removal\", and two followup patches.\n\nFrom-SVN: r53537", "tree": {"sha": "94c8895c6dde3b282518d4c9951067cd0ac517fd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/94c8895c6dde3b282518d4c9951067cd0ac517fd"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0b17ab2f5b1184fdb568786f791bc0613e574241", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0b17ab2f5b1184fdb568786f791bc0613e574241", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0b17ab2f5b1184fdb568786f791bc0613e574241", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0b17ab2f5b1184fdb568786f791bc0613e574241/comments", "author": null, "committer": null, "parents": [{"sha": "8ae86b3cd8c96e287714f127879b018ac7fccd7d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8ae86b3cd8c96e287714f127879b018ac7fccd7d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8ae86b3cd8c96e287714f127879b018ac7fccd7d"}], "stats": {"total": 3701, "additions": 1930, "deletions": 1771}, "files": [{"sha": "c3cb9b080290304738059acef4661a798dc9c5eb", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -1,3 +1,15 @@\n+2002-05-16  Richard Henderson  <rth@redhat.com>\n+\n+\t* basic-block.h, bb-reorder.c, cfg.c, cfganal.c, cfgbuild.c,\n+\tcfgcleanup.c, cfglayout.c, cfgloop.c, cfgrtl.c, combine.c,\n+\tconflict.c, df.c, df.h, dominance.c, final.c, flow.c, function.c,\n+\tgcse.c, global.c, graph.c, haifa-sched.c, ifcvt.c, lcm.c,\n+\tlocal-alloc.c, loop.c, predict.c, print-rtl.c, profile.c,\n+\trecog.c, reg-stack.c, regclass.c, regmove.c, regrename.c,\n+\treload1.c, reorg.c, resource.c, sbitmap.c, sched-deps.c,\n+\tsched-ebb.c, sched-rgn.c, sibcall.c, ssa-ccp.c, ssa-dce.c, ssa.c:\n+\tRevert \"Basic block renumbering removal\", and two followup patches.\n+\n 2002-05-16  Jason Thorpe  <thorpej@wasabisystems.com>\n \n \t* lcm.c (optimize_mode_switching): Revert previous change."}, {"sha": "5615b145f020d375c6a93be5d7c2a163dec5786b", "filename": "gcc/basic-block.h", "status": "modified", "additions": 7, "deletions": 27, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fbasic-block.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fbasic-block.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbasic-block.h?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -203,11 +203,8 @@ typedef struct basic_block_def {\n   /* Auxiliary info specific to a pass.  */\n   void *aux;\n \n-  /* The index of a block.  */\n-  int sindex;\n-\n-  /* Previous and next blocks in the chain.  */\n-  struct basic_block_def *prev_bb, *next_bb;\n+  /* The index of this block.  */\n+  int index;\n \n   /* The loop depth of this block.  */\n   int loop_depth;\n@@ -231,11 +228,7 @@ typedef struct basic_block_def {\n \n /* Number of basic blocks in the current function.  */\n \n-extern int num_basic_blocks;\n-\n-/* First free basic block number.  */\n-\n-extern int last_basic_block;\n+extern int n_basic_blocks;\n \n /* Number of edges in the current function.  */\n \n@@ -247,16 +240,6 @@ extern varray_type basic_block_info;\n \n #define BASIC_BLOCK(N)  (VARRAY_BB (basic_block_info, (N)))\n \n-/* For iterating over basic blocks.  */\n-#define FOR_BB_BETWEEN(BB, FROM, TO, DIR) \\\n-  for (BB = FROM; BB != TO; BB = BB->DIR)\n-\n-#define FOR_ALL_BB(BB) \\\n-  FOR_BB_BETWEEN (BB, ENTRY_BLOCK_PTR->next_bb, EXIT_BLOCK_PTR, next_bb)\n-\n-#define FOR_ALL_BB_REVERSE(BB) \\\n-  FOR_BB_BETWEEN (BB, EXIT_BLOCK_PTR->prev_bb, ENTRY_BLOCK_PTR, prev_bb)\n-\n /* What registers are live at the setjmp call.  */\n \n extern regset regs_live_at_setjmp;\n@@ -301,7 +284,7 @@ extern struct basic_block_def entry_exit_blocks[2];\n \n extern varray_type basic_block_for_insn;\n #define BLOCK_FOR_INSN(INSN)  VARRAY_BB (basic_block_for_insn, INSN_UID (INSN))\n-#define BLOCK_NUM(INSN)\t      (BLOCK_FOR_INSN (INSN)->sindex + 0)\n+#define BLOCK_NUM(INSN)\t      (BLOCK_FOR_INSN (INSN)->index + 0)\n \n extern void compute_bb_for_insn\t\tPARAMS ((int));\n extern void free_bb_for_insn\t\tPARAMS ((void));\n@@ -331,8 +314,8 @@ extern void remove_edge\t\t\tPARAMS ((edge));\n extern void redirect_edge_succ\t\tPARAMS ((edge, basic_block));\n extern edge redirect_edge_succ_nodup\tPARAMS ((edge, basic_block));\n extern void redirect_edge_pred\t\tPARAMS ((edge, basic_block));\n-extern basic_block create_basic_block_structure PARAMS ((int, rtx, rtx, rtx, basic_block));\n-extern basic_block create_basic_block\tPARAMS ((rtx, rtx, basic_block));\n+extern basic_block create_basic_block_structure PARAMS ((int, rtx, rtx, rtx));\n+extern basic_block create_basic_block\tPARAMS ((int, rtx, rtx));\n extern int flow_delete_block\t\tPARAMS ((basic_block));\n extern int flow_delete_block_noexpunge\tPARAMS ((basic_block));\n extern void clear_bb_flags\t\tPARAMS ((void));\n@@ -656,15 +639,12 @@ extern void reorder_basic_blocks\tPARAMS ((void));\n extern void dump_bb\t\t\tPARAMS ((basic_block, FILE *));\n extern void debug_bb\t\t\tPARAMS ((basic_block));\n extern void debug_bb_n\t\t\tPARAMS ((int));\n-extern basic_block debug_num2bb\t\tPARAMS ((int));\n extern void dump_regset\t\t\tPARAMS ((regset, FILE *));\n extern void debug_regset\t\tPARAMS ((regset));\n extern void allocate_reg_life_data      PARAMS ((void));\n extern void allocate_bb_life_data\tPARAMS ((void));\n extern void expunge_block\t\tPARAMS ((basic_block));\n-extern void link_block\t\t\tPARAMS ((basic_block, basic_block));\n-extern void unlink_block\t\tPARAMS ((basic_block));\n-extern void compact_blocks              PARAMS ((void));\n+extern void expunge_block_nocompact\tPARAMS ((basic_block));\n extern basic_block alloc_block\t\tPARAMS ((void));\n extern void find_unreachable_blocks\tPARAMS ((void));\n extern int delete_noop_moves\t\tPARAMS ((rtx));"}, {"sha": "3647ad6ec4b45dfcecdf47ab0bf56b2395a3cf6d", "filename": "gcc/bb-reorder.c", "status": "modified", "additions": 14, "deletions": 12, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fbb-reorder.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fbb-reorder.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbb-reorder.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -102,11 +102,14 @@ static void\n make_reorder_chain ()\n {\n   basic_block prev = NULL;\n-  basic_block next, bb;\n+  int nbb_m1 = n_basic_blocks - 1;\n+  basic_block next;\n \n   /* Loop until we've placed every block.  */\n   do\n     {\n+      int i;\n+\n       next = NULL;\n \n       /* Find the next unplaced block.  */\n@@ -116,13 +119,12 @@ make_reorder_chain ()\n \t remove from the list as we place.  The head of that list is\n \t what we're looking for here.  */\n \n-      FOR_ALL_BB (bb)\n-\tif (! RBI (bb)->visited)\n-\t  {\n+      for (i = 0; i <= nbb_m1 && !next; ++i)\n+\t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n+\t  if (! RBI (bb)->visited)\n \t    next = bb;\n-\t    break;\n-\t  }\n-      \n+\t}\n       if (next)\n         prev = make_reorder_chain_1 (next, prev);\n     }\n@@ -156,13 +158,13 @@ make_reorder_chain_1 (bb, prev)\n  restart:\n       RBI (prev)->next = bb;\n \n-      if (rtl_dump_file && prev->next_bb != bb)\n+      if (rtl_dump_file && prev->index + 1 != bb->index)\n \tfprintf (rtl_dump_file, \"Reordering block %d after %d\\n\",\n-\t\t bb->sindex, prev->sindex);\n+\t\t bb->index, prev->index);\n     }\n   else\n     {\n-      if (bb->prev_bb != ENTRY_BLOCK_PTR)\n+      if (bb->index != 0)\n \tabort ();\n     }\n   RBI (bb)->visited = 1;\n@@ -212,7 +214,7 @@ make_reorder_chain_1 (bb, prev)\n   if (! next)\n     {\n       for (e = bb->succ; e ; e = e->succ_next)\n-\tif (e->dest == bb->next_bb)\n+\tif (e->dest->index == bb->index + 1)\n \t  {\n \t    if ((e->flags & EDGE_FALLTHRU)\n \t        || (e->dest->succ\n@@ -256,7 +258,7 @@ make_reorder_chain_1 (bb, prev)\n void\n reorder_basic_blocks ()\n {\n-  if (num_basic_blocks <= 1)\n+  if (n_basic_blocks <= 1)\n     return;\n \n   if ((* targetm.cannot_modify_jumps_p) ())"}, {"sha": "47dfb238ea593ac18b5ff43857534b8c8e028917", "filename": "gcc/cfg.c", "status": "modified", "additions": 58, "deletions": 89, "changes": 147, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfg.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -63,10 +63,7 @@ static char *flow_firstobj;\n \n /* Number of basic blocks in the current function.  */\n \n-int num_basic_blocks;\n-\n-/* First free basic block number.  */\n-int last_basic_block;\n+int n_basic_blocks;\n \n /* Number of edges in the current function.  */\n \n@@ -96,8 +93,6 @@ struct basic_block_def entry_exit_blocks[2]\n     NULL,\t\t\t/* global_live_at_end */\n     NULL,\t\t\t/* aux */\n     ENTRY_BLOCK,\t\t/* index */\n-    NULL,\t\t\t/* prev_bb */\n-    EXIT_BLOCK_PTR,\t\t/* next_bb */\n     0,\t\t\t\t/* loop_depth */\n     0,\t\t\t\t/* count */\n     0,\t\t\t\t/* frequency */\n@@ -116,8 +111,6 @@ struct basic_block_def entry_exit_blocks[2]\n     NULL,\t\t\t/* global_live_at_end */\n     NULL,\t\t\t/* aux */\n     EXIT_BLOCK,\t\t\t/* index */\n-    ENTRY_BLOCK_PTR,\t\t/* prev_bb */\n-    NULL,\t\t\t/* next_bb */\n     0,\t\t\t\t/* loop_depth */\n     0,\t\t\t\t/* count */\n     0,\t\t\t\t/* frequency */\n@@ -170,11 +163,12 @@ free_edge (e)\n void\n clear_edges ()\n {\n-  basic_block bb;\n+  int i;\n   edge e;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; ++i)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       edge e = bb->succ;\n \n       while (e)\n@@ -226,66 +220,36 @@ alloc_block ()\n   return bb;\n }\n \n-/* Link block B to chain after AFTER.  */\n-void\n-link_block (b, after)\n-     basic_block b, after;\n-{\n-  b->next_bb = after->next_bb;\n-  b->prev_bb = after;\n-  after->next_bb = b;\n-  b->next_bb->prev_bb = b;\n-}\n+/* Remove block B from the basic block array and compact behind it.  */\n \n-/* Unlink block B from chain.  */\n void\n-unlink_block (b)\n+expunge_block_nocompact (b)\n      basic_block b;\n {\n-  b->next_bb->prev_bb = b->prev_bb;\n-  b->prev_bb->next_bb = b->next_bb;\n+  /* Invalidate data to make bughunting easier.  */\n+  memset (b, 0, sizeof *b);\n+  b->index = -3;\n+  b->succ = (edge) first_deleted_block;\n+  first_deleted_block = (basic_block) b;\n }\n \n-/* Sequentially order blocks and compact the arrays.  */\n void\n-compact_blocks ()\n+expunge_block (b)\n+     basic_block b;\n {\n-  basic_block *bbs = xcalloc (num_basic_blocks, sizeof (basic_block));\n-  int i;\n-  basic_block bb;\n- \n-  i = 0;\n-  FOR_ALL_BB (bb)\n-    bbs[i++] = bb;\n-\n-  if (i != num_basic_blocks)\n-    abort ();\n+  int i, n = n_basic_blocks;\n \n-  for (i = 0; i < num_basic_blocks; i++)\n+  for (i = b->index; i + 1 < n; ++i)\n     {\n-      bbs[i]->sindex = i;\n-      BASIC_BLOCK (i) = bbs[i];\n+      basic_block x = BASIC_BLOCK (i + 1);\n+      BASIC_BLOCK (i) = x;\n+      x->index = i;\n     }\n-  last_basic_block = num_basic_blocks;\n-\n-  free (bbs);\n-}\n \n-/* Remove block B from the basic block array.  */\n-\n-void\n-expunge_block (b)\n-     basic_block b;\n-{\n-  unlink_block (b);\n-  BASIC_BLOCK (b->sindex) = NULL;\n-  num_basic_blocks--;\n+  n_basic_blocks--;\n+  basic_block_info->num_elements--;\n \n-  /* Invalidate data to make bughunting easier.  */\n-  memset (b, 0, sizeof *b);\n-  b->sindex = -3;\n-  b->succ = (edge) first_deleted_block;\n-  first_deleted_block = (basic_block) b;\n+  expunge_block_nocompact (b);\n }\n \f\n /* Create an edge connecting SRC and DST with FLAGS optionally using\n@@ -310,7 +274,7 @@ cached_make_edge (edge_cache, src, dst, flags)\n     {\n     default:\n       /* Quick test for non-existence of the edge.  */\n-      if (! TEST_BIT (edge_cache[src->sindex], dst->sindex))\n+      if (! TEST_BIT (edge_cache[src->index], dst->index))\n \tbreak;\n \n       /* The edge exists; early exit if no work to do.  */\n@@ -350,7 +314,7 @@ cached_make_edge (edge_cache, src, dst, flags)\n   dst->pred = e;\n \n   if (use_edge_cache)\n-    SET_BIT (edge_cache[src->sindex], dst->sindex);\n+    SET_BIT (edge_cache[src->index], dst->index);\n \n   return e;\n }\n@@ -489,18 +453,18 @@ redirect_edge_pred (e, new_pred)\n void\n clear_bb_flags ()\n {\n-  basic_block bb;\n-\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n-    bb->flags = 0;\n+  int i;\n+  ENTRY_BLOCK_PTR->flags = 0;\n+  EXIT_BLOCK_PTR->flags = 0;\n+  for (i = 0; i < n_basic_blocks; i++)\n+    BASIC_BLOCK (i)->flags = 0;\n }\n \f\n void\n dump_flow_info (file)\n      FILE *file;\n {\n   int i;\n-  basic_block bb;\n   static const char * const reg_class_names[] = REG_CLASS_NAMES;\n \n   fprintf (file, \"%d registers.\\n\", max_regno);\n@@ -547,17 +511,16 @@ dump_flow_info (file)\n \tfprintf (file, \".\\n\");\n       }\n \n-  fprintf (file, \"\\n%d basic blocks, %d edges.\\n\", num_basic_blocks, n_edges);\n-  FOR_ALL_BB (bb)\n+  fprintf (file, \"\\n%d basic blocks, %d edges.\\n\", n_basic_blocks, n_edges);\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       edge e;\n       int sum;\n       gcov_type lsum;\n \n       fprintf (file, \"\\nBasic block %d: first insn %d, last %d, \",\n-\t       bb->sindex, INSN_UID (bb->head), INSN_UID (bb->end));\n-      fprintf (file, \"prev %d, next %d, \",\n-\t       bb->prev_bb->sindex, bb->next_bb->sindex);\n+\t       i, INSN_UID (bb->head), INSN_UID (bb->end));\n       fprintf (file, \"loop_depth %d, count \", bb->loop_depth);\n       fprintf (file, HOST_WIDEST_INT_PRINT_DEC, bb->count);\n       fprintf (file, \", freq %i.\\n\", bb->frequency);\n@@ -632,7 +595,7 @@ dump_edge_info (file, e, do_succ)\n   else if (side == EXIT_BLOCK_PTR)\n     fputs (\" EXIT\", file);\n   else\n-    fprintf (file, \" %d\", side->sindex);\n+    fprintf (file, \" %d\", side->index);\n \n   if (e->probability)\n     fprintf (file, \" [%.1f%%] \", e->probability * 100.0 / REG_BR_PROB_BASE);\n@@ -712,10 +675,10 @@ alloc_aux_for_blocks (size)\n   first_block_aux_obj = (char *) obstack_alloc (&block_aux_obstack, 0);\n   if (size)\n     {\n-      basic_block bb;\n+      int i;\n \n-      FOR_ALL_BB (bb)\n-\talloc_aux_for_block (bb, size);\n+      for (i = 0; i < n_basic_blocks; i++)\n+\talloc_aux_for_block (BASIC_BLOCK (i), size);\n \n       alloc_aux_for_block (ENTRY_BLOCK_PTR, size);\n       alloc_aux_for_block (EXIT_BLOCK_PTR, size);\n@@ -727,10 +690,13 @@ alloc_aux_for_blocks (size)\n void\n clear_aux_for_blocks ()\n {\n-  basic_block bb;\n+  int i;\n+\n+  for (i = 0; i < n_basic_blocks; i++)\n+    BASIC_BLOCK (i)->aux = NULL;\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n-    bb->aux = NULL;\n+  ENTRY_BLOCK_PTR->aux = NULL;\n+  EXIT_BLOCK_PTR->aux = NULL;\n }\n \n /* Free data allocated in block_aux_obstack and clear AUX pointers\n@@ -784,12 +750,17 @@ alloc_aux_for_edges (size)\n   first_edge_aux_obj = (char *) obstack_alloc (&edge_aux_obstack, 0);\n   if (size)\n     {\n-      basic_block bb;\n-\n-      FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n+      int i;\n+      for (i = -1; i < n_basic_blocks; i++)\n \t{\n+\t  basic_block bb;\n \t  edge e;\n \n+\t  if (i >= 0)\n+\t    bb = BASIC_BLOCK (i);\n+\t  else\n+\t    bb = ENTRY_BLOCK_PTR;\n+\n \t  for (e = bb->succ; e; e = e->succ_next)\n \t    alloc_aux_for_edge (e, size);\n \t}\n@@ -801,12 +772,18 @@ alloc_aux_for_edges (size)\n void\n clear_aux_for_edges ()\n {\n-  basic_block bb;\n+  int i;\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n+  for (i = -1; i < n_basic_blocks; i++)\n     {\n+      basic_block bb;\n       edge e;\n \n+      if (i >= 0)\n+\tbb = BASIC_BLOCK (i);\n+      else\n+\tbb = ENTRY_BLOCK_PTR;\n+\n       for (e = bb->succ; e; e = e->succ_next)\n \te->aux = NULL;\n     }\n@@ -825,11 +802,3 @@ free_aux_for_edges ()\n \n   clear_aux_for_edges ();\n }\n-\n-/* The same as BASIC_BLOCK, but usable from debugger.  */\n-basic_block\n-debug_num2bb (num)\n-     int num;\n-{\n-  return BASIC_BLOCK (num);\n-}"}, {"sha": "a64124cfb79e0cf16832e73ff1107238e8e64bc2", "filename": "gcc/cfganal.c", "status": "modified", "additions": 218, "deletions": 108, "changes": 326, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfganal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfganal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfganal.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -87,7 +87,7 @@ can_fallthru (src, target)\n   rtx insn = src->end;\n   rtx insn2 = target->head;\n \n-  if (src->next_bb != target)\n+  if (src->index + 1 != target->index)\n     return 0;\n \n   if (!active_insn_p (insn2))\n@@ -120,15 +120,15 @@ mark_dfs_back_edges ()\n   bool found = false;\n \n   /* Allocate the preorder and postorder number arrays.  */\n-  pre = (int *) xcalloc (last_basic_block, sizeof (int));\n-  post = (int *) xcalloc (last_basic_block, sizeof (int));\n+  pre = (int *) xcalloc (n_basic_blocks, sizeof (int));\n+  post = (int *) xcalloc (n_basic_blocks, sizeof (int));\n \n   /* Allocate stack for back-tracking up CFG.  */\n-  stack = (edge *) xmalloc ((num_basic_blocks + 1) * sizeof (edge));\n+  stack = (edge *) xmalloc ((n_basic_blocks + 1) * sizeof (edge));\n   sp = 0;\n \n   /* Allocate bitmap to track nodes that have been visited.  */\n-  visited = sbitmap_alloc (last_basic_block);\n+  visited = sbitmap_alloc (n_basic_blocks);\n \n   /* None of the nodes in the CFG have been visited yet.  */\n   sbitmap_zero (visited);\n@@ -149,30 +149,30 @@ mark_dfs_back_edges ()\n       e->flags &= ~EDGE_DFS_BACK;\n \n       /* Check if the edge destination has been visited yet.  */\n-      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->sindex))\n+      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->index))\n \t{\n \t  /* Mark that we have visited the destination.  */\n-\t  SET_BIT (visited, dest->sindex);\n+\t  SET_BIT (visited, dest->index);\n \n-\t  pre[dest->sindex] = prenum++;\n+\t  pre[dest->index] = prenum++;\n \t  if (dest->succ)\n \t    {\n \t      /* Since the DEST node has been visited for the first\n \t\t time, check its successors.  */\n \t      stack[sp++] = dest->succ;\n \t    }\n \t  else\n-\t    post[dest->sindex] = postnum++;\n+\t    post[dest->index] = postnum++;\n \t}\n       else\n \t{\n \t  if (dest != EXIT_BLOCK_PTR && src != ENTRY_BLOCK_PTR\n-\t      && pre[src->sindex] >= pre[dest->sindex]\n-\t      && post[dest->sindex] == 0)\n+\t      && pre[src->index] >= pre[dest->index]\n+\t      && post[dest->index] == 0)\n \t    e->flags |= EDGE_DFS_BACK, found = true;\n \n \t  if (! e->succ_next && src != ENTRY_BLOCK_PTR)\n-\t    post[src->sindex] = postnum++;\n+\t    post[src->index] = postnum++;\n \n \t  if (e->succ_next)\n \t    stack[sp - 1] = e->succ_next;\n@@ -194,10 +194,10 @@ mark_dfs_back_edges ()\n void\n set_edge_can_fallthru_flag ()\n {\n-  basic_block bb;\n-\n-  FOR_ALL_BB (bb)\n+  int i;\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       edge e;\n \n       /* The FALLTHRU edge is also CAN_FALLTHRU edge.  */\n@@ -258,16 +258,29 @@ flow_call_edges_add (blocks)\n {\n   int i;\n   int blocks_split = 0;\n-  int last_bb = last_basic_block;\n+  int bb_num = 0;\n+  basic_block *bbs;\n   bool check_last_block = false;\n \n-  if (num_basic_blocks == 0)\n-    return 0;\n+  /* Map bb indices into basic block pointers since split_block\n+     will renumber the basic blocks.  */\n+\n+  bbs = xmalloc (n_basic_blocks * sizeof (*bbs));\n \n   if (! blocks)\n-    check_last_block = true;\n+    {\n+      for (i = 0; i < n_basic_blocks; i++)\n+\tbbs[bb_num++] = BASIC_BLOCK (i);\n+\n+      check_last_block = true;\n+    }\n   else\n-    check_last_block = TEST_BIT (blocks, EXIT_BLOCK_PTR->prev_bb->sindex);\n+    EXECUTE_IF_SET_IN_SBITMAP (blocks, 0, i,\n+\t\t\t       {\n+\t\t\t\t bbs[bb_num++] = BASIC_BLOCK (i);\n+\t\t\t\t if (i == n_basic_blocks - 1)\n+\t\t\t\t   check_last_block = true;\n+\t\t\t       });\n \n   /* In the last basic block, before epilogue generation, there will be\n      a fallthru edge to EXIT.  Special care is required if the last insn\n@@ -283,7 +296,7 @@ flow_call_edges_add (blocks)\n      Handle this by adding a dummy instruction in a new last basic block.  */\n   if (check_last_block)\n     {\n-      basic_block bb = EXIT_BLOCK_PTR->prev_bb;\n+      basic_block bb = BASIC_BLOCK (n_basic_blocks - 1);\n       rtx insn = bb->end;\n \n       /* Back up past insns that must be kept in the same block as a call.  */\n@@ -308,18 +321,12 @@ flow_call_edges_add (blocks)\n      calls since there is no way that we can determine if they will\n      return or not...  */\n \n-  for (i = 0; i < last_bb; i++)\n+  for (i = 0; i < bb_num; i++)\n     {\n-      basic_block bb = BASIC_BLOCK (i);\n+      basic_block bb = bbs[i];\n       rtx insn;\n       rtx prev_insn;\n \n-      if (!bb)\n-\tcontinue;\n-\n-      if (blocks && !TEST_BIT (blocks, i))\n-\tcontinue;\n-\n       for (insn = bb->end; ; insn = prev_insn)\n \t{\n \t  prev_insn = PREV_INSN (insn);\n@@ -367,6 +374,7 @@ flow_call_edges_add (blocks)\n   if (blocks_split)\n     verify_flow_info ();\n \n+  free (bbs);\n   return blocks_split;\n }\n \n@@ -378,15 +386,16 @@ void\n find_unreachable_blocks ()\n {\n   edge e;\n-  basic_block *tos, *worklist, bb;\n+  int i, n;\n+  basic_block *tos, *worklist;\n \n-  tos = worklist =\n-    (basic_block *) xmalloc (sizeof (basic_block) * num_basic_blocks);\n+  n = n_basic_blocks;\n+  tos = worklist = (basic_block *) xmalloc (sizeof (basic_block) * n);\n \n   /* Clear all the reachability flags.  */\n \n-  FOR_ALL_BB (bb)\n-    bb->flags &= ~BB_REACHABLE;\n+  for (i = 0; i < n; ++i)\n+    BASIC_BLOCK (i)->flags &= ~BB_REACHABLE;\n \n   /* Add our starting points to the worklist.  Almost always there will\n      be only one.  It isn't inconceivable that we might one day directly\n@@ -436,33 +445,46 @@ create_edge_list ()\n   struct edge_list *elist;\n   edge e;\n   int num_edges;\n+  int x;\n   int block_count;\n-  basic_block bb;\n \n-  block_count = num_basic_blocks + 2;   /* Include the entry and exit blocks.  */\n+  block_count = n_basic_blocks + 2;   /* Include the entry and exit blocks.  */\n \n   num_edges = 0;\n \n   /* Determine the number of edges in the flow graph by counting successor\n      edges on each basic block.  */\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n+  for (x = 0; x < n_basic_blocks; x++)\n     {\n+      basic_block bb = BASIC_BLOCK (x);\n \n       for (e = bb->succ; e; e = e->succ_next)\n \tnum_edges++;\n     }\n \n+  /* Don't forget successors of the entry block.  */\n+  for (e = ENTRY_BLOCK_PTR->succ; e; e = e->succ_next)\n+    num_edges++;\n+\n   elist = (struct edge_list *) xmalloc (sizeof (struct edge_list));\n   elist->num_blocks = block_count;\n   elist->num_edges = num_edges;\n   elist->index_to_edge = (edge *) xmalloc (sizeof (edge) * num_edges);\n \n   num_edges = 0;\n \n-  /* Follow successors of blocks, and register these edges.  */\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n-    for (e = bb->succ; e; e = e->succ_next)\n-      elist->index_to_edge[num_edges++] = e;\n+  /* Follow successors of the entry block, and register these edges.  */\n+  for (e = ENTRY_BLOCK_PTR->succ; e; e = e->succ_next)\n+    elist->index_to_edge[num_edges++] = e;\n+\n+  for (x = 0; x < n_basic_blocks; x++)\n+    {\n+      basic_block bb = BASIC_BLOCK (x);\n+\n+      /* Follow all successors of blocks, and register these edges.  */\n+      for (e = bb->succ; e; e = e->succ_next)\n+\telist->index_to_edge[num_edges++] = e;\n+    }\n \n   return elist;\n }\n@@ -498,12 +520,12 @@ print_edge_list (f, elist)\n       if (INDEX_EDGE_PRED_BB (elist, x) == ENTRY_BLOCK_PTR)\n \tfprintf (f, \"entry,\");\n       else\n-\tfprintf (f, \"%d,\", INDEX_EDGE_PRED_BB (elist, x)->sindex);\n+\tfprintf (f, \"%d,\", INDEX_EDGE_PRED_BB (elist, x)->index);\n \n       if (INDEX_EDGE_SUCC_BB (elist, x) == EXIT_BLOCK_PTR)\n \tfprintf (f, \"exit)\\n\");\n       else\n-\tfprintf (f, \"%d)\\n\", INDEX_EDGE_SUCC_BB (elist, x)->sindex);\n+\tfprintf (f, \"%d)\\n\", INDEX_EDGE_SUCC_BB (elist, x)->index);\n     }\n }\n \n@@ -516,38 +538,60 @@ verify_edge_list (f, elist)\n      FILE *f;\n      struct edge_list *elist;\n {\n-  int index, pred, succ;\n+  int x, pred, succ, index;\n   edge e;\n-  basic_block bb, p, s;\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n+  for (x = 0; x < n_basic_blocks; x++)\n     {\n+      basic_block bb = BASIC_BLOCK (x);\n+\n       for (e = bb->succ; e; e = e->succ_next)\n \t{\n-\t  pred = e->src->sindex;\n-\t  succ = e->dest->sindex;\n+\t  pred = e->src->index;\n+\t  succ = e->dest->index;\n \t  index = EDGE_INDEX (elist, e->src, e->dest);\n \t  if (index == EDGE_INDEX_NO_EDGE)\n \t    {\n \t      fprintf (f, \"*p* No index for edge from %d to %d\\n\", pred, succ);\n \t      continue;\n \t    }\n \n-\t  if (INDEX_EDGE_PRED_BB (elist, index)->sindex != pred)\n+\t  if (INDEX_EDGE_PRED_BB (elist, index)->index != pred)\n \t    fprintf (f, \"*p* Pred for index %d should be %d not %d\\n\",\n-\t\t     index, pred, INDEX_EDGE_PRED_BB (elist, index)->sindex);\n-\t  if (INDEX_EDGE_SUCC_BB (elist, index)->sindex != succ)\n+\t\t     index, pred, INDEX_EDGE_PRED_BB (elist, index)->index);\n+\t  if (INDEX_EDGE_SUCC_BB (elist, index)->index != succ)\n \t    fprintf (f, \"*p* Succ for index %d should be %d not %d\\n\",\n-\t\t     index, succ, INDEX_EDGE_SUCC_BB (elist, index)->sindex);\n+\t\t     index, succ, INDEX_EDGE_SUCC_BB (elist, index)->index);\n+\t}\n+    }\n+\n+  for (e = ENTRY_BLOCK_PTR->succ; e; e = e->succ_next)\n+    {\n+      pred = e->src->index;\n+      succ = e->dest->index;\n+      index = EDGE_INDEX (elist, e->src, e->dest);\n+      if (index == EDGE_INDEX_NO_EDGE)\n+\t{\n+\t  fprintf (f, \"*p* No index for edge from %d to %d\\n\", pred, succ);\n+\t  continue;\n \t}\n+\n+      if (INDEX_EDGE_PRED_BB (elist, index)->index != pred)\n+\tfprintf (f, \"*p* Pred for index %d should be %d not %d\\n\",\n+\t\t index, pred, INDEX_EDGE_PRED_BB (elist, index)->index);\n+      if (INDEX_EDGE_SUCC_BB (elist, index)->index != succ)\n+\tfprintf (f, \"*p* Succ for index %d should be %d not %d\\n\",\n+\t\t index, succ, INDEX_EDGE_SUCC_BB (elist, index)->index);\n     }\n \n   /* We've verified that all the edges are in the list, no lets make sure\n      there are no spurious edges in the list.  */\n \n-  FOR_BB_BETWEEN (p, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n-    FOR_BB_BETWEEN (p, ENTRY_BLOCK_PTR->next_bb, NULL, next_bb)\n+  for (pred = 0; pred < n_basic_blocks; pred++)\n+    for (succ = 0; succ < n_basic_blocks; succ++)\n       {\n+\tbasic_block p = BASIC_BLOCK (pred);\n+\tbasic_block s = BASIC_BLOCK (succ);\n \tint found_edge = 0;\n \n \tfor (e = p->succ; e; e = e->succ_next)\n@@ -564,16 +608,78 @@ verify_edge_list (f, elist)\n \t      break;\n \t    }\n \n-\tif (EDGE_INDEX (elist, p, s)\n+\tif (EDGE_INDEX (elist, BASIC_BLOCK (pred), BASIC_BLOCK (succ))\n \t    == EDGE_INDEX_NO_EDGE && found_edge != 0)\n \t  fprintf (f, \"*** Edge (%d, %d) appears to not have an index\\n\",\n-\t\t   p->sindex, s->sindex);\n-\tif (EDGE_INDEX (elist, p, s)\n+\t\t   pred, succ);\n+\tif (EDGE_INDEX (elist, BASIC_BLOCK (pred), BASIC_BLOCK (succ))\n \t    != EDGE_INDEX_NO_EDGE && found_edge == 0)\n \t  fprintf (f, \"*** Edge (%d, %d) has index %d, but there is no edge\\n\",\n-\t\t   p->sindex, s->sindex, EDGE_INDEX (elist, p, s));\n+\t\t   pred, succ, EDGE_INDEX (elist, BASIC_BLOCK (pred),\n+\t\t\t\t\t   BASIC_BLOCK (succ)));\n       }\n \n+  for (succ = 0; succ < n_basic_blocks; succ++)\n+    {\n+      basic_block p = ENTRY_BLOCK_PTR;\n+      basic_block s = BASIC_BLOCK (succ);\n+      int found_edge = 0;\n+\n+      for (e = p->succ; e; e = e->succ_next)\n+\tif (e->dest == s)\n+\t  {\n+\t    found_edge = 1;\n+\t    break;\n+\t  }\n+\n+      for (e = s->pred; e; e = e->pred_next)\n+\tif (e->src == p)\n+\t  {\n+\t    found_edge = 1;\n+\t    break;\n+\t  }\n+\n+      if (EDGE_INDEX (elist, ENTRY_BLOCK_PTR, BASIC_BLOCK (succ))\n+\t  == EDGE_INDEX_NO_EDGE && found_edge != 0)\n+\tfprintf (f, \"*** Edge (entry, %d) appears to not have an index\\n\",\n+\t\t succ);\n+      if (EDGE_INDEX (elist, ENTRY_BLOCK_PTR, BASIC_BLOCK (succ))\n+\t  != EDGE_INDEX_NO_EDGE && found_edge == 0)\n+\tfprintf (f, \"*** Edge (entry, %d) has index %d, but no edge exists\\n\",\n+\t\t succ, EDGE_INDEX (elist, ENTRY_BLOCK_PTR,\n+\t\t\t\t   BASIC_BLOCK (succ)));\n+    }\n+\n+  for (pred = 0; pred < n_basic_blocks; pred++)\n+    {\n+      basic_block p = BASIC_BLOCK (pred);\n+      basic_block s = EXIT_BLOCK_PTR;\n+      int found_edge = 0;\n+\n+      for (e = p->succ; e; e = e->succ_next)\n+\tif (e->dest == s)\n+\t  {\n+\t    found_edge = 1;\n+\t    break;\n+\t  }\n+\n+      for (e = s->pred; e; e = e->pred_next)\n+\tif (e->src == p)\n+\t  {\n+\t    found_edge = 1;\n+\t    break;\n+\t  }\n+\n+      if (EDGE_INDEX (elist, BASIC_BLOCK (pred), EXIT_BLOCK_PTR)\n+\t  == EDGE_INDEX_NO_EDGE && found_edge != 0)\n+\tfprintf (f, \"*** Edge (%d, exit) appears to not have an index\\n\",\n+\t\t pred);\n+      if (EDGE_INDEX (elist, BASIC_BLOCK (pred), EXIT_BLOCK_PTR)\n+\t  != EDGE_INDEX_NO_EDGE && found_edge == 0)\n+\tfprintf (f, \"*** Edge (%d, exit) has index %d, but no edge exists\\n\",\n+\t\t pred, EDGE_INDEX (elist, BASIC_BLOCK (pred),\n+\t\t\t\t   EXIT_BLOCK_PTR));\n+    }\n }\n \n /* This routine will determine what, if any, edge there is between\n@@ -628,8 +734,8 @@ flow_edge_list_print (str, edge_list, num_edges, file)\n \n   fprintf (file, \"%s { \", str);\n   for (i = 0; i < num_edges; i++)\n-    fprintf (file, \"%d->%d \", edge_list[i]->src->sindex,\n-\t     edge_list[i]->dest->sindex);\n+    fprintf (file, \"%d->%d \", edge_list[i]->src->index,\n+\t     edge_list[i]->dest->index);\n \n   fputs (\"}\\n\", file);\n }\n@@ -662,10 +768,13 @@ remove_fake_successors (bb)\n void\n remove_fake_edges ()\n {\n-  basic_block bb;\n+  int x;\n+\n+  for (x = 0; x < n_basic_blocks; x++)\n+    remove_fake_successors (BASIC_BLOCK (x));\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n-    remove_fake_successors (bb);\n+  /* We've handled all successors except the entry block's.  */\n+  remove_fake_successors (ENTRY_BLOCK_PTR);\n }\n \n /* This function will add a fake edge between any block which has no\n@@ -675,11 +784,11 @@ remove_fake_edges ()\n void\n add_noreturn_fake_exit_edges ()\n {\n-  basic_block bb;\n+  int x;\n \n-  FOR_ALL_BB (bb)\n-    if (bb->succ == NULL)\n-      make_single_succ_edge (bb, EXIT_BLOCK_PTR, EDGE_FAKE);\n+  for (x = 0; x < n_basic_blocks; x++)\n+    if (BASIC_BLOCK (x)->succ == NULL)\n+      make_single_succ_edge (BASIC_BLOCK (x), EXIT_BLOCK_PTR, EDGE_FAKE);\n }\n \n /* This function adds a fake edge between any infinite loops to the\n@@ -731,11 +840,11 @@ flow_reverse_top_sort_order_compute (rts_order)\n   sbitmap visited;\n \n   /* Allocate stack for back-tracking up CFG.  */\n-  stack = (edge *) xmalloc ((num_basic_blocks + 1) * sizeof (edge));\n+  stack = (edge *) xmalloc ((n_basic_blocks + 1) * sizeof (edge));\n   sp = 0;\n \n   /* Allocate bitmap to track nodes that have been visited.  */\n-  visited = sbitmap_alloc (last_basic_block);\n+  visited = sbitmap_alloc (n_basic_blocks);\n \n   /* None of the nodes in the CFG have been visited yet.  */\n   sbitmap_zero (visited);\n@@ -755,22 +864,22 @@ flow_reverse_top_sort_order_compute (rts_order)\n       dest = e->dest;\n \n       /* Check if the edge destination has been visited yet.  */\n-      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->sindex))\n+      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->index))\n \t{\n \t  /* Mark that we have visited the destination.  */\n-\t  SET_BIT (visited, dest->sindex);\n+\t  SET_BIT (visited, dest->index);\n \n \t  if (dest->succ)\n \t    /* Since the DEST node has been visited for the first\n \t       time, check its successors.  */\n \t    stack[sp++] = dest->succ;\n \t  else\n-\t    rts_order[postnum++] = dest->sindex;\n+\t    rts_order[postnum++] = dest->index;\n \t}\n       else\n \t{\n \t  if (! e->succ_next && src != ENTRY_BLOCK_PTR)\n-\t   rts_order[postnum++] = src->sindex;\n+\t   rts_order[postnum++] = src->index;\n \n \t  if (e->succ_next)\n \t    stack[sp - 1] = e->succ_next;\n@@ -798,15 +907,15 @@ flow_depth_first_order_compute (dfs_order, rc_order)\n   edge *stack;\n   int sp;\n   int dfsnum = 0;\n-  int rcnum = num_basic_blocks - 1;\n+  int rcnum = n_basic_blocks - 1;\n   sbitmap visited;\n \n   /* Allocate stack for back-tracking up CFG.  */\n-  stack = (edge *) xmalloc ((num_basic_blocks + 1) * sizeof (edge));\n+  stack = (edge *) xmalloc ((n_basic_blocks + 1) * sizeof (edge));\n   sp = 0;\n \n   /* Allocate bitmap to track nodes that have been visited.  */\n-  visited = sbitmap_alloc (last_basic_block);\n+  visited = sbitmap_alloc (n_basic_blocks);\n \n   /* None of the nodes in the CFG have been visited yet.  */\n   sbitmap_zero (visited);\n@@ -826,13 +935,13 @@ flow_depth_first_order_compute (dfs_order, rc_order)\n       dest = e->dest;\n \n       /* Check if the edge destination has been visited yet.  */\n-      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->sindex))\n+      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->index))\n \t{\n \t  /* Mark that we have visited the destination.  */\n-\t  SET_BIT (visited, dest->sindex);\n+\t  SET_BIT (visited, dest->index);\n \n \t  if (dfs_order)\n-\t    dfs_order[dfsnum] = dest->sindex;\n+\t    dfs_order[dfsnum] = dest->index;\n \n \t  dfsnum++;\n \n@@ -843,15 +952,15 @@ flow_depth_first_order_compute (dfs_order, rc_order)\n \t  else if (rc_order)\n \t    /* There are no successors for the DEST node so assign\n \t       its reverse completion number.  */\n-\t    rc_order[rcnum--] = dest->sindex;\n+\t    rc_order[rcnum--] = dest->index;\n \t}\n       else\n \t{\n \t  if (! e->succ_next && src != ENTRY_BLOCK_PTR\n \t      && rc_order)\n \t    /* There are no more successors for the SRC node\n \t       so assign its reverse completion number.  */\n-\t    rc_order[rcnum--] = src->sindex;\n+\t    rc_order[rcnum--] = src->index;\n \n \t  if (e->succ_next)\n \t    stack[sp - 1] = e->succ_next;\n@@ -864,12 +973,12 @@ flow_depth_first_order_compute (dfs_order, rc_order)\n   sbitmap_free (visited);\n \n   /* The number of nodes visited should not be greater than\n-     num_basic_blocks.  */\n-  if (dfsnum > num_basic_blocks)\n+     n_basic_blocks.  */\n+  if (dfsnum > n_basic_blocks)\n     abort ();\n \n   /* There are some nodes left in the CFG that are unreachable.  */\n-  if (dfsnum < num_basic_blocks)\n+  if (dfsnum < n_basic_blocks)\n     abort ();\n \n   return dfsnum;\n@@ -905,30 +1014,30 @@ flow_preorder_transversal_compute (pot_order)\n   sbitmap visited;\n   struct dfst_node *node;\n   struct dfst_node *dfst;\n-  basic_block bb;\n \n   /* Allocate stack for back-tracking up CFG.  */\n-  stack = (edge *) xmalloc ((num_basic_blocks + 1) * sizeof (edge));\n+  stack = (edge *) xmalloc ((n_basic_blocks + 1) * sizeof (edge));\n   sp = 0;\n \n   /* Allocate the tree.  */\n-  dfst = (struct dfst_node *) xcalloc (last_basic_block,\n+  dfst = (struct dfst_node *) xcalloc (n_basic_blocks,\n \t\t\t\t       sizeof (struct dfst_node));\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n       max_successors = 0;\n-      for (e = bb->succ; e; e = e->succ_next)\n+      for (e = BASIC_BLOCK (i)->succ; e; e = e->succ_next)\n \tmax_successors++;\n \n-      if (max_successors)\n-\tdfst[bb->sindex].node\n-\t  =  (struct dfst_node **) xcalloc (max_successors,\n-\t\t\t\t\t    sizeof (struct dfst_node *));\n+      dfst[i].node\n+\t= (max_successors\n+\t   ? (struct dfst_node **) xcalloc (max_successors,\n+\t\t\t\t\t    sizeof (struct dfst_node *))\n+\t   : NULL);\n     }\n \n   /* Allocate bitmap to track nodes that have been visited.  */\n-  visited = sbitmap_alloc (last_basic_block);\n+  visited = sbitmap_alloc (n_basic_blocks);\n \n   /* None of the nodes in the CFG have been visited yet.  */\n   sbitmap_zero (visited);\n@@ -947,17 +1056,17 @@ flow_preorder_transversal_compute (pot_order)\n       dest = e->dest;\n \n       /* Check if the edge destination has been visited yet.  */\n-      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->sindex))\n+      if (dest != EXIT_BLOCK_PTR && ! TEST_BIT (visited, dest->index))\n \t{\n \t  /* Mark that we have visited the destination.  */\n-\t  SET_BIT (visited, dest->sindex);\n+\t  SET_BIT (visited, dest->index);\n \n \t  /* Add the destination to the preorder tree.  */\n \t  if (src != ENTRY_BLOCK_PTR)\n \t    {\n-\t      dfst[src->sindex].node[dfst[src->sindex].nnodes++]\n-\t\t= &dfst[dest->sindex];\n-\t      dfst[dest->sindex].up = &dfst[src->sindex];\n+\t      dfst[src->index].node[dfst[src->index].nnodes++]\n+\t\t= &dfst[dest->index];\n+\t      dfst[dest->index].up = &dfst[src->index];\n \t    }\n \n \t  if (dest->succ)\n@@ -979,7 +1088,7 @@ flow_preorder_transversal_compute (pot_order)\n      walking the tree from right to left.  */\n \n   i = 0;\n-  node = &dfst[ENTRY_BLOCK_PTR->next_bb->sindex];\n+  node = &dfst[0];\n   pot_order[i++] = 0;\n \n   while (node)\n@@ -995,7 +1104,7 @@ flow_preorder_transversal_compute (pot_order)\n \n   /* Free the tree.  */\n \n-  for (i = 0; i < last_basic_block; i++)\n+  for (i = 0; i < n_basic_blocks; i++)\n     if (dfst[i].node)\n       free (dfst[i].node);\n \n@@ -1037,12 +1146,12 @@ flow_dfs_compute_reverse_init (data)\n      depth_first_search_ds data;\n {\n   /* Allocate stack for back-tracking up CFG.  */\n-  data->stack = (basic_block *) xmalloc ((num_basic_blocks - (INVALID_BLOCK + 1))\n+  data->stack = (basic_block *) xmalloc ((n_basic_blocks - (INVALID_BLOCK + 1))\n \t\t\t\t\t * sizeof (basic_block));\n   data->sp = 0;\n \n   /* Allocate bitmap to track nodes that have been visited.  */\n-  data->visited_blocks = sbitmap_alloc (last_basic_block - (INVALID_BLOCK + 1));\n+  data->visited_blocks = sbitmap_alloc (n_basic_blocks - (INVALID_BLOCK + 1));\n \n   /* None of the nodes in the CFG have been visited yet.  */\n   sbitmap_zero (data->visited_blocks);\n@@ -1060,7 +1169,7 @@ flow_dfs_compute_reverse_add_bb (data, bb)\n      basic_block bb;\n {\n   data->stack[data->sp++] = bb;\n-  SET_BIT (data->visited_blocks, bb->sindex - (INVALID_BLOCK + 1));\n+  SET_BIT (data->visited_blocks, bb->index - (INVALID_BLOCK + 1));\n }\n \n /* Continue the depth-first search through the reverse graph starting with the\n@@ -1074,6 +1183,7 @@ flow_dfs_compute_reverse_execute (data)\n {\n   basic_block bb;\n   edge e;\n+  int i;\n \n   while (data->sp > 0)\n     {\n@@ -1082,14 +1192,14 @@ flow_dfs_compute_reverse_execute (data)\n       /* Perform depth-first search on adjacent vertices.  */\n       for (e = bb->pred; e; e = e->pred_next)\n \tif (!TEST_BIT (data->visited_blocks,\n-\t\t       e->src->sindex - (INVALID_BLOCK + 1)))\n+\t\t       e->src->index - (INVALID_BLOCK + 1)))\n \t  flow_dfs_compute_reverse_add_bb (data, e->src);\n     }\n \n   /* Determine if there are unvisited basic blocks.  */\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n-    if (!TEST_BIT (data->visited_blocks, bb->sindex - (INVALID_BLOCK + 1)))\n-      return bb;\n+  for (i = n_basic_blocks - (INVALID_BLOCK + 1); --i >= 0; )\n+    if (!TEST_BIT (data->visited_blocks, i))\n+      return BASIC_BLOCK (i + (INVALID_BLOCK + 1));\n \n   return NULL;\n }"}, {"sha": "5ce9d40f3b076d25bfce3abaada19e418317159d", "filename": "gcc/cfgbuild.c", "status": "modified", "additions": 64, "deletions": 62, "changes": 126, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgbuild.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgbuild.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgbuild.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -50,8 +50,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n static int count_basic_blocks\t\tPARAMS ((rtx));\n static void find_basic_blocks_1\t\tPARAMS ((rtx));\n static rtx find_label_refs\t\tPARAMS ((rtx, rtx));\n-static void make_edges\t\t\tPARAMS ((rtx, basic_block,\n-\t\t\t\t\t\t basic_block, int));\n+static void make_edges\t\t\tPARAMS ((rtx, int, int, int));\n static void make_label_edge\t\tPARAMS ((sbitmap *, basic_block,\n \t\t\t\t\t\t rtx, int));\n static void make_eh_edge\t\tPARAMS ((sbitmap *, basic_block, rtx));\n@@ -281,10 +280,9 @@ make_eh_edge (edge_cache, src, insn)\n static void\n make_edges (label_value_list, min, max, update_p)\n      rtx label_value_list;\n-     basic_block min, max;\n-     int update_p;\n+     int min, max, update_p;\n {\n-  basic_block bb;\n+  int i;\n   sbitmap *edge_cache = NULL;\n \n   /* Assume no computed jump; revise as we create edges.  */\n@@ -295,26 +293,28 @@ make_edges (label_value_list, min, max, update_p)\n      amount of time searching the edge lists for duplicates.  */\n   if (forced_labels || label_value_list)\n     {\n-      edge_cache = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n-      sbitmap_vector_zero (edge_cache, last_basic_block);\n+      edge_cache = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n+      sbitmap_vector_zero (edge_cache, n_basic_blocks);\n \n       if (update_p)\n-        FOR_BB_BETWEEN (bb, min, max->next_bb, next_bb)\n+\tfor (i = min; i <= max; ++i)\n \t  {\n \t    edge e;\n \n-\t    for (e = bb->succ; e ; e = e->succ_next)\n+\t    for (e = BASIC_BLOCK (i)->succ; e ; e = e->succ_next)\n \t      if (e->dest != EXIT_BLOCK_PTR)\n-\t        SET_BIT (edge_cache[bb->sindex], e->dest->sindex);\n+\t        SET_BIT (edge_cache[i], e->dest->index);\n \t  }\n     }\n \n-  if (min == ENTRY_BLOCK_PTR->next_bb)\n-    cached_make_edge (edge_cache, ENTRY_BLOCK_PTR, min,\n+  /* By nature of the way these get numbered, block 0 is always the entry.  */\n+  if (min == 0)\n+    cached_make_edge (edge_cache, ENTRY_BLOCK_PTR, BASIC_BLOCK (0),\n \t\t      EDGE_FALLTHRU);\n \n-  FOR_BB_BETWEEN (bb, min, max->next_bb, next_bb)\n+  for (i = min; i <= max; ++i)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx insn, x;\n       enum rtx_code code;\n       int force_fallthru = 0;\n@@ -443,16 +443,15 @@ make_edges (label_value_list, min, max, update_p)\n \n       /* Find out if we can drop through to the next block.  */\n       insn = next_nonnote_insn (insn);\n-\n-      if (!insn || (bb->next_bb == EXIT_BLOCK_PTR && force_fallthru))\n+      if (!insn || (i + 1 == n_basic_blocks && force_fallthru))\n \tcached_make_edge (edge_cache, bb, EXIT_BLOCK_PTR, EDGE_FALLTHRU);\n-      else if (bb->next_bb != EXIT_BLOCK_PTR)\n+      else if (i + 1 < n_basic_blocks)\n \t{\n-\t  rtx tmp = bb->next_bb->head;\n+\t  rtx tmp = BLOCK_HEAD (i + 1);\n \t  if (GET_CODE (tmp) == NOTE)\n \t    tmp = next_nonnote_insn (tmp);\n \t  if (force_fallthru || insn == tmp)\n-\t    cached_make_edge (edge_cache, bb, bb->next_bb,\n+\t    cached_make_edge (edge_cache, bb, BASIC_BLOCK (i + 1),\n \t\t\t      EDGE_FALLTHRU);\n \t}\n     }\n@@ -471,12 +470,12 @@ find_basic_blocks_1 (f)\n      rtx f;\n {\n   rtx insn, next;\n+  int i = 0;\n   rtx bb_note = NULL_RTX;\n   rtx lvl = NULL_RTX;\n   rtx trll = NULL_RTX;\n   rtx head = NULL_RTX;\n   rtx end = NULL_RTX;\n-  basic_block prev = ENTRY_BLOCK_PTR;\n \n   /* We process the instructions in a slightly different way than we did\n      previously.  This is so that we see a NOTE_BASIC_BLOCK after we have\n@@ -493,7 +492,7 @@ find_basic_blocks_1 (f)\n       if ((GET_CODE (insn) == CODE_LABEL || GET_CODE (insn) == BARRIER)\n \t  && head)\n \t{\n-\t  prev = create_basic_block_structure (last_basic_block++, head, end, bb_note, prev);\n+\t  create_basic_block_structure (i++, head, end, bb_note);\n \t  head = end = NULL_RTX;\n \t  bb_note = NULL_RTX;\n \t}\n@@ -507,7 +506,7 @@ find_basic_blocks_1 (f)\n \n       if (head && control_flow_insn_p (insn))\n \t{\n-\t  prev = create_basic_block_structure (last_basic_block++, head, end, bb_note, prev);\n+\t  create_basic_block_structure (i++, head, end, bb_note);\n \t  head = end = NULL_RTX;\n \t  bb_note = NULL_RTX;\n \t}\n@@ -589,11 +588,11 @@ find_basic_blocks_1 (f)\n     }\n \n   if (head != NULL_RTX)\n-    create_basic_block_structure (last_basic_block++, head, end, bb_note, prev);\n+    create_basic_block_structure (i++, head, end, bb_note);\n   else if (bb_note)\n     delete_insn (bb_note);\n \n-  if (last_basic_block != num_basic_blocks)\n+  if (i != n_basic_blocks)\n     abort ();\n \n   label_value_list = lvl;\n@@ -613,29 +612,27 @@ find_basic_blocks (f, nregs, file)\n      FILE *file ATTRIBUTE_UNUSED;\n {\n   int max_uid;\n-  basic_block bb;\n   timevar_push (TV_CFG);\n \n   basic_block_for_insn = 0;\n \n   /* Flush out existing data.  */\n   if (basic_block_info != NULL)\n     {\n+      int i;\n+\n       clear_edges ();\n \n       /* Clear bb->aux on all extant basic blocks.  We'll use this as a\n \t tag for reuse during create_basic_block, just in case some pass\n \t copies around basic block notes improperly.  */\n-      FOR_ALL_BB (bb)\n- \tbb->aux = NULL;\n+      for (i = 0; i < n_basic_blocks; ++i)\n+\tBASIC_BLOCK (i)->aux = NULL;\n \n       VARRAY_FREE (basic_block_info);\n     }\n \n-  num_basic_blocks = count_basic_blocks (f);\n-  last_basic_block = 0;\n-  ENTRY_BLOCK_PTR->next_bb = EXIT_BLOCK_PTR;\n-  EXIT_BLOCK_PTR->prev_bb = ENTRY_BLOCK_PTR;\n+  n_basic_blocks = count_basic_blocks (f);\n \n   /* Size the basic block table.  The actual structures will be allocated\n      by find_basic_blocks_1, since we want to keep the structure pointers\n@@ -645,7 +642,7 @@ find_basic_blocks (f, nregs, file)\n      instructions at all until close to the end of compilation when we\n      actually lay them out.  */\n \n-  VARRAY_BB_INIT (basic_block_info, num_basic_blocks, \"basic_block_info\");\n+  VARRAY_BB_INIT (basic_block_info, n_basic_blocks, \"basic_block_info\");\n \n   find_basic_blocks_1 (f);\n \n@@ -664,7 +661,7 @@ find_basic_blocks (f, nregs, file)\n   compute_bb_for_insn (max_uid);\n \n   /* Discover the edges of our cfg.  */\n-  make_edges (label_value_list, ENTRY_BLOCK_PTR->next_bb, EXIT_BLOCK_PTR->prev_bb, 0);\n+  make_edges (label_value_list, 0, n_basic_blocks - 1, 0);\n \n   /* Do very simple cleanup now, for the benefit of code that runs between\n      here and cleanup_cfg, e.g. thread_prologue_and_epilogue_insns.  */\n@@ -793,53 +790,55 @@ void\n find_many_sub_basic_blocks (blocks)\n      sbitmap blocks;\n {\n-  basic_block bb, min, max;\n+  int i;\n+  int min, max;\n \n-  FOR_ALL_BB (bb)\n-    SET_STATE (bb,\n-\t       TEST_BIT (blocks, bb->sindex) ? BLOCK_TO_SPLIT : BLOCK_ORIGINAL);\n+  for (i = 0; i < n_basic_blocks; i++)\n+    SET_STATE (BASIC_BLOCK (i),\n+\t       TEST_BIT (blocks, i) ? BLOCK_TO_SPLIT : BLOCK_ORIGINAL);\n \n-  FOR_ALL_BB (bb)\n-    if (STATE (bb) == BLOCK_TO_SPLIT)\n-      find_bb_boundaries (bb);\n+  for (i = 0; i < n_basic_blocks; i++)\n+    if (STATE (BASIC_BLOCK (i)) == BLOCK_TO_SPLIT)\n+      find_bb_boundaries (BASIC_BLOCK (i));\n \n-  FOR_ALL_BB (bb)\n-    if (STATE (bb) != BLOCK_ORIGINAL)\n+  for (i = 0; i < n_basic_blocks; i++)\n+    if (STATE (BASIC_BLOCK (i)) != BLOCK_ORIGINAL)\n       break;\n \n-  min = max = bb;\n-  for (; bb != EXIT_BLOCK_PTR; bb = bb->next_bb)\n-    if (STATE (bb) != BLOCK_ORIGINAL)\n-      max = bb;\n+  min = max = i;\n+  for (; i < n_basic_blocks; i++)\n+    if (STATE (BASIC_BLOCK (i)) != BLOCK_ORIGINAL)\n+      max = i;\n \n   /* Now re-scan and wire in all edges.  This expect simple (conditional)\n      jumps at the end of each new basic blocks.  */\n   make_edges (NULL, min, max, 1);\n \n   /* Update branch probabilities.  Expect only (un)conditional jumps\n      to be created with only the forward edges.  */\n-  FOR_BB_BETWEEN (bb, min, max->next_bb, next_bb)\n+  for (i = min; i <= max; i++)\n     {\n       edge e;\n+      basic_block b = BASIC_BLOCK (i);\n \n-      if (STATE (bb) == BLOCK_ORIGINAL)\n+      if (STATE (b) == BLOCK_ORIGINAL)\n \tcontinue;\n-      if (STATE (bb) == BLOCK_NEW)\n+      if (STATE (b) == BLOCK_NEW)\n \t{\n-\t  bb->count = 0;\n-\t  bb->frequency = 0;\n-\t  for (e = bb->pred; e; e=e->pred_next)\n+\t  b->count = 0;\n+\t  b->frequency = 0;\n+\t  for (e = b->pred; e; e=e->pred_next)\n \t    {\n-\t      bb->count += e->count;\n-\t      bb->frequency += EDGE_FREQUENCY (e);\n+\t      b->count += e->count;\n+\t      b->frequency += EDGE_FREQUENCY (e);\n \t    }\n \t}\n \n-      compute_outgoing_frequencies (bb);\n+      compute_outgoing_frequencies (b);\n     }\n \n-  FOR_ALL_BB (bb)\n-    SET_STATE (bb, 0);\n+  for (i = 0; i < n_basic_blocks; i++)\n+    SET_STATE (BASIC_BLOCK (i), 0);\n }\n \n /* Like above but for single basic block only.  */\n@@ -848,24 +847,27 @@ void\n find_sub_basic_blocks (bb)\n     basic_block bb;\n {\n-  basic_block min, max, b;\n-  basic_block next = bb->next_bb;\n+  int i;\n+  int min, max;\n+  basic_block next = (bb->index == n_basic_blocks - 1\n+\t\t      ? NULL : BASIC_BLOCK (bb->index + 1));\n \n-  min = bb;\n+  min = bb->index;\n   find_bb_boundaries (bb);\n-  max = next->prev_bb;\n+  max = (next ? next->index : n_basic_blocks) - 1;\n \n   /* Now re-scan and wire in all edges.  This expect simple (conditional)\n      jumps at the end of each new basic blocks.  */\n   make_edges (NULL, min, max, 1);\n \n   /* Update branch probabilities.  Expect only (un)conditional jumps\n      to be created with only the forward edges.  */\n-  FOR_BB_BETWEEN (b, min, max->next_bb, next_bb)\n+  for (i = min; i <= max; i++)\n     {\n       edge e;\n+      basic_block b = BASIC_BLOCK (i);\n \n-      if (b != min)\n+      if (i != min)\n \t{\n \t  b->count = 0;\n \t  b->frequency = 0;"}, {"sha": "fcf6944d4bb8ce117aa1f4bb03b03f0989c4c7ea", "filename": "gcc/cfgcleanup.c", "status": "modified", "additions": 54, "deletions": 44, "changes": 98, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgcleanup.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgcleanup.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgcleanup.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -147,7 +147,7 @@ try_simplify_condjump (cbranch_block)\n      unconditional jump.  */\n   jump_block = cbranch_fallthru_edge->dest;\n   if (jump_block->pred->pred_next\n-      || jump_block->next_bb == EXIT_BLOCK_PTR\n+      || jump_block->index == n_basic_blocks - 1\n       || !FORWARDER_BLOCK_P (jump_block))\n     return false;\n   jump_dest_block = jump_block->succ->dest;\n@@ -439,7 +439,7 @@ try_forward_edges (mode, b)\n       target = first = e->dest;\n       counter = 0;\n \n-      while (counter < num_basic_blocks)\n+      while (counter < n_basic_blocks)\n \t{\n \t  basic_block new_target = NULL;\n \t  bool new_target_threaded = false;\n@@ -449,7 +449,7 @@ try_forward_edges (mode, b)\n \t    {\n \t      /* Bypass trivial infinite loops.  */\n \t      if (target == target->succ->dest)\n-\t\tcounter = num_basic_blocks;\n+\t\tcounter = n_basic_blocks;\n \t      new_target = target->succ->dest;\n \t    }\n \n@@ -462,7 +462,7 @@ try_forward_edges (mode, b)\n \t\t{\n \t\t  if (!threaded_edges)\n \t\t    threaded_edges = xmalloc (sizeof (*threaded_edges)\n-\t\t\t\t\t      * num_basic_blocks);\n+\t\t\t\t\t      * n_basic_blocks);\n \t\t  else\n \t\t    {\n \t\t      int i;\n@@ -474,7 +474,7 @@ try_forward_edges (mode, b)\n \t\t\t  break;\n \t\t      if (i < nthreaded_edges)\n \t\t\t{\n-\t\t\t  counter = num_basic_blocks;\n+\t\t\t  counter = n_basic_blocks;\n \t\t\t  break;\n \t\t\t}\n \t\t    }\n@@ -483,7 +483,7 @@ try_forward_edges (mode, b)\n \t\t  if (t->dest == b)\n \t\t    break;\n \n-\t\t  if (nthreaded_edges >= num_basic_blocks)\n+\t\t  if (nthreaded_edges >= n_basic_blocks)\n \t\t    abort ();\n \t\t  threaded_edges[nthreaded_edges++] = t;\n \n@@ -524,11 +524,11 @@ try_forward_edges (mode, b)\n \t  threaded |= new_target_threaded;\n   \t}\n \n-      if (counter >= num_basic_blocks)\n+      if (counter >= n_basic_blocks)\n \t{\n \t  if (rtl_dump_file)\n \t    fprintf (rtl_dump_file, \"Infinite loop in BB %i.\\n\",\n-\t\t     target->sindex);\n+\t\t     target->index);\n \t}\n       else if (target == first)\n \t; /* We didn't do anything.  */\n@@ -552,7 +552,7 @@ try_forward_edges (mode, b)\n \t      if (rtl_dump_file)\n \t\tfprintf (rtl_dump_file,\n \t\t\t \"Forwarding edge %i->%i to %i failed.\\n\",\n-\t\t\t b->sindex, e->dest->sindex, target->sindex);\n+\t\t\t b->index, e->dest->index, target->index);\n \t      continue;\n \t    }\n \n@@ -688,6 +688,7 @@ merge_blocks_move_predecessor_nojumps (a, b)\n      basic_block a, b;\n {\n   rtx barrier;\n+  int index;\n \n   barrier = next_nonnote_insn (a->end);\n   if (GET_CODE (barrier) != BARRIER)\n@@ -711,11 +712,16 @@ merge_blocks_move_predecessor_nojumps (a, b)\n \n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \"Moved block %d before %d and merged.\\n\",\n-\t     a->sindex, b->sindex);\n+\t     a->index, b->index);\n \n-  /* Swap the records for the two blocks around.  */\n-  unlink_block (a);\n-  link_block (a, b->prev_bb);\n+  /* Swap the records for the two blocks around.  Although we are deleting B,\n+     A is now where B was and we want to compact the BB array from where\n+     A used to be.  */\n+  BASIC_BLOCK (a->index) = b;\n+  BASIC_BLOCK (b->index) = a;\n+  index = a->index;\n+  a->index = b->index;\n+  b->index = index;\n \n   /* Now blocks A and B are contiguous.  Merge them.  */\n   merge_blocks_nomove (a, b);\n@@ -770,7 +776,7 @@ merge_blocks_move_successor_nojumps (a, b)\n \n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \"Moved block %d after %d and merged.\\n\",\n-\t     b->sindex, a->sindex);\n+\t     b->index, a->index);\n \n   /* Now blocks A and B are contiguous.  Merge them.  */\n   merge_blocks_nomove (a, b);\n@@ -797,7 +803,7 @@ merge_blocks (e, b, c, mode)\n   /* If B has a fallthru edge to C, no need to move anything.  */\n   if (e->flags & EDGE_FALLTHRU)\n     {\n-      int b_index = b->sindex, c_index = c->sindex;\n+      int b_index = b->index, c_index = c->index;\n       merge_blocks_nomove (b, c);\n       update_forwarder_flag (b);\n \n@@ -1224,15 +1230,15 @@ outgoing_edges_match (mode, bb1, bb2)\n \t      if (rtl_dump_file)\n \t\tfprintf (rtl_dump_file,\n \t\t\t \"Outcomes of branch in bb %i and %i differs to much (%i %i)\\n\",\n-\t\t\t bb1->sindex, bb2->sindex, b1->probability, prob2);\n+\t\t\t bb1->index, bb2->index, b1->probability, prob2);\n \n \t      return false;\n \t    }\n \t}\n \n       if (rtl_dump_file && match)\n \tfprintf (rtl_dump_file, \"Conditionals in bb %i and %i match.\\n\",\n-\t\t bb1->sindex, bb2->sindex);\n+\t\t bb1->index, bb2->index);\n \n       return match;\n     }\n@@ -1365,14 +1371,14 @@ try_crossjump_to_edge (mode, e1, e2)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \"Splitting bb %i before %i insns\\n\",\n-\t\t src2->sindex, nmatch);\n+\t\t src2->index, nmatch);\n       redirect_to = split_block (src2, PREV_INSN (newpos2))->dest;\n     }\n \n   if (rtl_dump_file)\n     fprintf (rtl_dump_file,\n \t     \"Cross jumping from bb %i to bb %i; %i common insns\\n\",\n-\t     src1->sindex, src2->sindex, nmatch);\n+\t     src1->index, src2->index, nmatch);\n \n   redirect_to->count += src1->count;\n   redirect_to->frequency += src1->frequency;\n@@ -1533,7 +1539,6 @@ try_crossjump_bb (mode, bb)\n \n       for (e2 = bb->pred; e2; e2 = nexte2)\n \t{\n-\t  basic_block foll;\n \t  nexte2 = e2->pred_next;\n \n \t  if (e2 == e)\n@@ -1547,10 +1552,7 @@ try_crossjump_bb (mode, bb)\n \t     checks of crossjump(A,B).  In order to prevent redundant\n \t     checks of crossjump(B,A), require that A be the block\n \t     with the lowest index.  */\n-\t  for (foll = e->src; foll && foll != e2->src; foll = foll->next_bb)\n-\t    {\n-\t    }\n-\t  if (!foll)\n+\t  if (e->src->index > e2->src->index)\n \t    continue;\n \n \t  if (try_crossjump_to_edge (mode, e, e2))\n@@ -1572,16 +1574,16 @@ static bool\n try_optimize_cfg (mode)\n      int mode;\n {\n+  int i;\n   bool changed_overall = false;\n   bool changed;\n   int iterations = 0;\n-  basic_block bb, b;\n \n   if (mode & CLEANUP_CROSSJUMP)\n     add_noreturn_fake_exit_edges ();\n \n-  FOR_ALL_BB (bb)\n-    update_forwarder_flag (bb);\n+  for (i = 0; i < n_basic_blocks; i++)\n+    update_forwarder_flag (BASIC_BLOCK (i));\n \n   if (mode & CLEANUP_UPDATE_LIFE)\n     clear_bb_flags ();\n@@ -1601,19 +1603,19 @@ try_optimize_cfg (mode)\n \t\t     \"\\n\\ntry_optimize_cfg iteration %i\\n\\n\",\n \t\t     iterations);\n \n-\t  for (b = ENTRY_BLOCK_PTR->next_bb; b != EXIT_BLOCK_PTR;)\n+\t  for (i = 0; i < n_basic_blocks;)\n \t    {\n-\t      basic_block c;\n+\t      basic_block c, b = BASIC_BLOCK (i);\n \t      edge s;\n \t      bool changed_here = false;\n \n \t      /* Delete trivially dead basic blocks.  */\n \t      while (b->pred == NULL)\n \t\t{\n-\t\t  c = b->prev_bb;\n+\t\t  c = BASIC_BLOCK (b->index - 1);\n \t\t  if (rtl_dump_file)\n \t\t    fprintf (rtl_dump_file, \"Deleting block %i.\\n\",\n-\t\t\t     b->sindex);\n+\t\t\t     b->index);\n \n \t\t  flow_delete_block (b);\n \t\t  changed = true;\n@@ -1646,7 +1648,7 @@ try_optimize_cfg (mode)\n \t\t  delete_insn_chain (label, label);\n \t\t  if (rtl_dump_file)\n \t\t    fprintf (rtl_dump_file, \"Deleted label in block %i.\\n\",\n-\t\t\t     b->sindex);\n+\t\t\t     b->index);\n \t\t}\n \n \t      /* If we fall through an empty block, we can remove it.  */\n@@ -1657,14 +1659,14 @@ try_optimize_cfg (mode)\n \t\t  /* Note that forwarder_block_p true ensures that\n \t\t     there is a successor for this block.  */\n \t\t  && (b->succ->flags & EDGE_FALLTHRU)\n-\t\t  && num_basic_blocks > 1)\n+\t\t  && n_basic_blocks > 1)\n \t\t{\n \t\t  if (rtl_dump_file)\n \t\t    fprintf (rtl_dump_file,\n \t\t\t     \"Deleting fallthru block %i.\\n\",\n-\t\t\t     b->sindex);\n+\t\t\t     b->index);\n \n-\t\t  c = b->prev_bb == ENTRY_BLOCK_PTR ? b->next_bb : b->prev_bb;\n+\t\t  c = BASIC_BLOCK (b->index ? b->index - 1 : 1);\n \t\t  redirect_edge_succ_nodup (b->pred, b->succ->dest);\n \t\t  flow_delete_block (b);\n \t\t  changed = true;\n@@ -1716,7 +1718,7 @@ try_optimize_cfg (mode)\n \t      /* Don't get confused by the index shift caused by\n \t\t deleting blocks.  */\n \t      if (!changed_here)\n-\t\tb = b->next_bb;\n+\t\ti = b->index + 1;\n \t      else\n \t\tchanged = true;\n \t    }\n@@ -1748,22 +1750,33 @@ try_optimize_cfg (mode)\n bool\n delete_unreachable_blocks ()\n {\n+  int i, j;\n   bool changed = false;\n-  basic_block b, next_bb;\n \n   find_unreachable_blocks ();\n \n-  /* Delete all unreachable basic blocks.  */\n+  /* Delete all unreachable basic blocks.  Do compaction concurrently,\n+     as otherwise we can wind up with O(N^2) behaviour here when we \n+     have oodles of dead code.  */\n \n-  for (b = ENTRY_BLOCK_PTR->next_bb; b != EXIT_BLOCK_PTR; b = next_bb)\n+  for (i = j = 0; i < n_basic_blocks; ++i)\n     {\n-      next_bb = b->next_bb;\n+      basic_block b = BASIC_BLOCK (i);\n+\n       if (!(b->flags & BB_REACHABLE))\n \t{\n-\t  flow_delete_block (b);\n+\t  flow_delete_block_noexpunge (b);\n+\t  expunge_block_nocompact (b);\n \t  changed = true;\n \t}\n+      else\n+\t{\n+\t  BASIC_BLOCK (j) = b;\n+\t  b->index = j++;\n+\t}\n     }\n+  n_basic_blocks = j;\n+  basic_block_info->num_elements = j;\n \n   if (changed)\n     tidy_fallthru_edges ();\n@@ -1788,9 +1801,6 @@ cleanup_cfg (mode)\n \t  && !reload_completed)\n \tdelete_trivially_dead_insns (get_insns(), max_reg_num ());\n     }\n-\n-  compact_blocks ();\n-  \n   while (try_optimize_cfg (mode))\n     {\n       delete_unreachable_blocks (), changed = true;"}, {"sha": "2820f0d5d9697e1c16b509184f9290d677641b8f", "filename": "gcc/cfglayout.c", "status": "modified", "additions": 32, "deletions": 42, "changes": 74, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfglayout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfglayout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfglayout.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -86,8 +86,8 @@ skip_insns_after_block (bb)\n   rtx insn, last_insn, next_head, prev;\n \n   next_head = NULL_RTX;\n-  if (bb->next_bb != EXIT_BLOCK_PTR)\n-    next_head = bb->next_bb->head;\n+  if (bb->index + 1 != n_basic_blocks)\n+    next_head = BASIC_BLOCK (bb->index + 1)->head;\n \n   for (last_insn = insn = bb->end; (insn = NEXT_INSN (insn)) != 0; )\n     {\n@@ -176,7 +176,7 @@ label_for_bb (bb)\n   if (GET_CODE (label) != CODE_LABEL)\n     {\n       if (rtl_dump_file)\n-\tfprintf (rtl_dump_file, \"Emitting label for block %d\\n\", bb->sindex);\n+\tfprintf (rtl_dump_file, \"Emitting label for block %d\\n\", bb->index);\n \n       label = block_label (bb);\n     }\n@@ -191,10 +191,11 @@ static void\n record_effective_endpoints ()\n {\n   rtx next_insn = get_insns ();\n-  basic_block bb;\n-\n-  FOR_ALL_BB (bb)\n+  int i;\n+  \n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx end;\n \n       if (PREV_INSN (bb->head) && next_insn != bb->head)\n@@ -356,15 +357,15 @@ scope_to_insns_finalize ()\n static void\n fixup_reorder_chain ()\n {\n-  basic_block bb, prev_bb;\n+  basic_block bb;\n   int index;\n   rtx insn = NULL;\n \n   /* First do the bulk reordering -- rechain the blocks without regard to\n      the needed changes to jumps and labels.  */\n \n-  for (bb = ENTRY_BLOCK_PTR->next_bb, index = 0;\n-       bb;\n+  for (bb = BASIC_BLOCK (0), index = 0;\n+       bb != 0;\n        bb = RBI (bb)->next, index++)\n     {\n       if (RBI (bb)->header)\n@@ -393,7 +394,7 @@ fixup_reorder_chain ()\n \t}\n     }\n \n-  if (index != num_basic_blocks)\n+  if (index != n_basic_blocks)\n     abort ();\n \n   NEXT_INSN (insn) = function_footer;\n@@ -411,7 +412,7 @@ fixup_reorder_chain ()\n   /* Now add jumps and labels as needed to match the blocks new\n      outgoing edges.  */\n \n-  for (bb = ENTRY_BLOCK_PTR->next_bb; bb ; bb = RBI (bb)->next)\n+  for (bb = BASIC_BLOCK (0); bb ; bb = RBI (bb)->next)\n     {\n       edge e_fall, e_taken, e;\n       rtx bb_end_insn;\n@@ -522,39 +523,29 @@ fixup_reorder_chain ()\n     }\n \n   /* Put basic_block_info in the new order.  */\n+\n   if (rtl_dump_file)\n     {\n       fprintf (rtl_dump_file, \"Reordered sequence:\\n\");\n-      for (bb = ENTRY_BLOCK_PTR->next_bb, index = 0;\n-\t   bb;\n-\t   bb = RBI (bb)->next, index ++)\n+      for (bb = BASIC_BLOCK (0), index = 0; bb; bb = RBI (bb)->next, index ++)\n \t{\n \t  fprintf (rtl_dump_file, \" %i \", index);\n \t  if (RBI (bb)->original)\n \t    fprintf (rtl_dump_file, \"duplicate of %i \",\n-\t\t     RBI (bb)->original->sindex);\n+\t\t     RBI (bb)->original->index);\n \t  else if (forwarder_block_p (bb) && GET_CODE (bb->head) != CODE_LABEL)\n \t    fprintf (rtl_dump_file, \"compensation \");\n \t  else\n-\t    fprintf (rtl_dump_file, \"bb %i \", bb->sindex);\n+\t    fprintf (rtl_dump_file, \"bb %i \", bb->index);\n \t  fprintf (rtl_dump_file, \" [%i]\\n\", bb->frequency);\n \t}\n     }\n \n-  prev_bb = ENTRY_BLOCK_PTR;\n-  bb = ENTRY_BLOCK_PTR->next_bb;\n-  index = 0;\n-\n-  for (; bb; prev_bb = bb, bb = RBI (bb)->next, index++)\n+  for (bb = BASIC_BLOCK (0), index = 0; bb; bb = RBI (bb)->next, index ++)\n     {\n-      bb->sindex = index;\n+      bb->index = index;\n       BASIC_BLOCK (index) = bb;\n-\n-      bb->prev_bb = prev_bb;\n-      prev_bb->next_bb = bb;\n     }\n-  prev_bb->next_bb = EXIT_BLOCK_PTR;\n-  EXIT_BLOCK_PTR->prev_bb = prev_bb;\n }\n \f\n /* Perform sanity checks on the insn chain.\n@@ -597,25 +588,25 @@ verify_insn_chain ()\n static void\n cleanup_unconditional_jumps ()\n {\n-  basic_block bb;\n-\n-  FOR_ALL_BB (bb)\n+  int i;\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n+\n       if (!bb->succ)\n \tcontinue;\n       if (bb->succ->flags & EDGE_FALLTHRU)\n \tcontinue;\n       if (!bb->succ->succ_next)\n \t{\n \t  rtx insn;\n-\t  if (GET_CODE (bb->head) != CODE_LABEL && forwarder_block_p (bb)\n-\t      && bb->prev_bb != ENTRY_BLOCK_PTR)\n+\t  if (GET_CODE (bb->head) != CODE_LABEL && forwarder_block_p (bb) && i)\n \t    {\n-\t      basic_block prev = bb->prev_bb;\n+\t      basic_block prev = BASIC_BLOCK (--i);\n \n \t      if (rtl_dump_file)\n \t\tfprintf (rtl_dump_file, \"Removing forwarder BB %i\\n\",\n-\t\t\t bb->sindex);\n+\t\t\t bb->index);\n \n \t      redirect_edge_succ (bb->pred, bb->succ->dest);\n \t      flow_delete_block (bb);\n@@ -627,7 +618,7 @@ cleanup_unconditional_jumps ()\n \n \t      if (rtl_dump_file)\n \t\tfprintf (rtl_dump_file, \"Removing jump %i in BB %i\\n\",\n-\t\t\t INSN_UID (jump), bb->sindex);\n+\t\t\t INSN_UID (jump), bb->index);\n \t      delete_insn (jump);\n \t      bb->succ->flags |= EDGE_FALLTHRU;\n \t    }\n@@ -672,7 +663,7 @@ fixup_fallthru_exit_predecessor ()\n \n   if (bb && RBI (bb)->next)\n     {\n-      basic_block c = ENTRY_BLOCK_PTR->next_bb;\n+      basic_block c = BASIC_BLOCK (0);\n \n       while (RBI (c)->next != bb)\n \tc = RBI (c)->next;\n@@ -822,14 +813,14 @@ cfg_layout_redirect_edge (e, dest)\n      edge e;\n      basic_block dest;\n {\n+  int old_index = dest->index;\n   basic_block src = e->src;\n-  basic_block old_next_bb = src->next_bb;\n \n   /* Redirect_edge_and_branch may decide to turn branch into fallthru edge\n      in the case the basic block appears to be in sequence.  Avoid this\n      transformation.  */\n \n-  src->next_bb = NULL;\n+  dest->index = n_basic_blocks + 1;\n   if (e->flags & EDGE_FALLTHRU)\n     {\n       /* In case we are redirecting fallthru edge to the branch edge\n@@ -855,7 +846,7 @@ cfg_layout_redirect_edge (e, dest)\n       delete_barrier (NEXT_INSN (src->end));\n       src->succ->flags |= EDGE_FALLTHRU;\n     }\n-  src->next_bb = old_next_bb;\n+  dest->index = old_index;\n }\n \n /* Create an duplicate of the basic block BB and redirect edge E into it.  */\n@@ -880,9 +871,8 @@ cfg_layout_duplicate_bb (bb, e)\n #endif\n \n   insn = duplicate_insn_chain (bb->head, bb->end);\n-  new_bb = create_basic_block (insn,\n-\t\t\t       insn ? get_last_insn () : NULL,\n-\t\t\t       EXIT_BLOCK_PTR->prev_bb);\n+  new_bb = create_basic_block (n_basic_blocks, insn,\n+\t\t \t       insn ? get_last_insn () : NULL);\n   alloc_aux_for_block (new_bb, sizeof (struct reorder_block_def));\n \n   if (RBI (bb)->header)"}, {"sha": "2bd0d4c44bf72a45902ed9167781164e534ad335", "filename": "gcc/cfgloop.c", "status": "modified", "additions": 48, "deletions": 43, "changes": 91, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgloop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgloop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgloop.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -50,26 +50,25 @@ flow_loops_cfg_dump (loops, file)\n      FILE *file;\n {\n   int i;\n-  basic_block bb;\n \n   if (! loops->num || ! file || ! loops->cfg.dom)\n     return;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n       edge succ;\n \n-      fprintf (file, \";; %d succs { \", bb->sindex);\n-      for (succ = bb->succ; succ; succ = succ->succ_next)\n-\tfprintf (file, \"%d \", succ->dest->sindex);\n+      fprintf (file, \";; %d succs { \", i);\n+      for (succ = BASIC_BLOCK (i)->succ; succ; succ = succ->succ_next)\n+\tfprintf (file, \"%d \", succ->dest->index);\n       flow_nodes_print (\"} dom\", loops->cfg.dom[i], file);\n     }\n \n   /* Dump the DFS node order.  */\n   if (loops->cfg.dfs_order)\n     {\n       fputs (\";; DFS order: \", file);\n-      for (i = 0; i < num_basic_blocks; i++)\n+      for (i = 0; i < n_basic_blocks; i++)\n \tfprintf (file, \"%d \", loops->cfg.dfs_order[i]);\n \n       fputs (\"\\n\", file);\n@@ -79,7 +78,7 @@ flow_loops_cfg_dump (loops, file)\n   if (loops->cfg.rc_order)\n     {\n       fputs (\";; RC order: \", file);\n-      for (i = 0; i < num_basic_blocks; i++)\n+      for (i = 0; i < n_basic_blocks; i++)\n \tfprintf (file, \"%d \", loops->cfg.rc_order[i]);\n \n       fputs (\"\\n\", file);\n@@ -119,9 +118,9 @@ flow_loop_dump (loop, file, loop_dump_aux, verbose)\n \t     loop->shared ? \" shared\" : \"\", loop->invalid ? \" invalid\" : \"\");\n \n   fprintf (file, \";;  header %d, latch %d, pre-header %d, first %d, last %d\\n\",\n-\t   loop->header->sindex, loop->latch->sindex,\n-\t   loop->pre_header ? loop->pre_header->sindex : -1,\n-\t   loop->first->sindex, loop->last->sindex);\n+\t   loop->header->index, loop->latch->index,\n+\t   loop->pre_header ? loop->pre_header->index : -1,\n+\t   loop->first->index, loop->last->index);\n   fprintf (file, \";;  depth %d, level %d, outer %ld\\n\",\n \t   loop->depth, loop->level,\n \t   (long) (loop->outer ? loop->outer->num : -1));\n@@ -186,7 +185,7 @@ flow_loops_dump (loops, file, loop_dump_aux, verbose)\n \t\t\t\t\t\t smaller ? oloop : loop);\n \t\tfprintf (file,\n \t\t\t \";; loop header %d shared by loops %d, %d %s\\n\",\n-\t\t\t loop->header->sindex, i, j,\n+\t\t\t loop->header->index, i, j,\n \t\t\t disjoint ? \"disjoint\" : \"nested\");\n \t      }\n \t  }\n@@ -260,7 +259,7 @@ flow_loop_entry_edges_find (header, nodes, entry_edges)\n     {\n       basic_block src = e->src;\n \n-      if (src == ENTRY_BLOCK_PTR || ! TEST_BIT (nodes, src->sindex))\n+      if (src == ENTRY_BLOCK_PTR || ! TEST_BIT (nodes, src->index))\n \tnum_entries++;\n     }\n \n@@ -274,7 +273,7 @@ flow_loop_entry_edges_find (header, nodes, entry_edges)\n     {\n       basic_block src = e->src;\n \n-      if (src == ENTRY_BLOCK_PTR || ! TEST_BIT (nodes, src->sindex))\n+      if (src == ENTRY_BLOCK_PTR || ! TEST_BIT (nodes, src->index))\n \t(*entry_edges)[num_entries++] = e;\n     }\n \n@@ -306,7 +305,7 @@ flow_loop_exit_edges_find (nodes, exit_edges)\n       {\n \tbasic_block dest = e->dest;\n \n-\tif (dest == EXIT_BLOCK_PTR || ! TEST_BIT (nodes, dest->sindex))\n+\tif (dest == EXIT_BLOCK_PTR || ! TEST_BIT (nodes, dest->index))\n \t    num_exits++;\n       }\n   });\n@@ -323,7 +322,7 @@ flow_loop_exit_edges_find (nodes, exit_edges)\n       {\n \tbasic_block dest = e->dest;\n \n-\tif (dest == EXIT_BLOCK_PTR || ! TEST_BIT (nodes, dest->sindex))\n+\tif (dest == EXIT_BLOCK_PTR || ! TEST_BIT (nodes, dest->index))\n \t  (*exit_edges)[num_exits++] = e;\n       }\n   });\n@@ -345,19 +344,19 @@ flow_loop_nodes_find (header, latch, nodes)\n   int sp;\n   int num_nodes = 0;\n \n-  stack = (basic_block *) xmalloc (num_basic_blocks * sizeof (basic_block));\n+  stack = (basic_block *) xmalloc (n_basic_blocks * sizeof (basic_block));\n   sp = 0;\n \n   /* Start with only the loop header in the set of loop nodes.  */\n   sbitmap_zero (nodes);\n-  SET_BIT (nodes, header->sindex);\n+  SET_BIT (nodes, header->index);\n   num_nodes++;\n   header->loop_depth++;\n \n   /* Push the loop latch on to the stack.  */\n-  if (! TEST_BIT (nodes, latch->sindex))\n+  if (! TEST_BIT (nodes, latch->index))\n     {\n-      SET_BIT (nodes, latch->sindex);\n+      SET_BIT (nodes, latch->index);\n       latch->loop_depth++;\n       num_nodes++;\n       stack[sp++] = latch;\n@@ -376,9 +375,9 @@ flow_loop_nodes_find (header, latch, nodes)\n \t  /* If each ancestor not marked as part of loop, add to set of\n \t     loop nodes and push on to stack.  */\n \t  if (ancestor != ENTRY_BLOCK_PTR\n-\t      && ! TEST_BIT (nodes, ancestor->sindex))\n+\t      && ! TEST_BIT (nodes, ancestor->index))\n \t    {\n-\t      SET_BIT (nodes, ancestor->sindex);\n+\t      SET_BIT (nodes, ancestor->index);\n \t      ancestor->loop_depth++;\n \t      num_nodes++;\n \t      stack[sp++] = ancestor;\n@@ -445,7 +444,7 @@ flow_loop_pre_header_find (header, dom)\n       basic_block node = e->src;\n \n       if (node != ENTRY_BLOCK_PTR\n-\t  && ! TEST_BIT (dom[node->sindex], header->sindex))\n+\t  && ! TEST_BIT (dom[node->index], header->index))\n \t{\n \t  if (pre_header == NULL)\n \t    pre_header = node;\n@@ -600,15 +599,15 @@ flow_loop_scan (loops, loop, flags)\n \n       /* Determine which loop nodes dominate all the exits\n \t of the loop.  */\n-      loop->exits_doms = sbitmap_alloc (last_basic_block);\n+      loop->exits_doms = sbitmap_alloc (n_basic_blocks);\n       sbitmap_copy (loop->exits_doms, loop->nodes);\n       for (j = 0; j < loop->num_exits; j++)\n \tsbitmap_a_and_b (loop->exits_doms, loop->exits_doms,\n-\t\t\t loops->cfg.dom[loop->exit_edges[j]->src->sindex]);\n+\t\t\t loops->cfg.dom[loop->exit_edges[j]->src->index]);\n \n       /* The header of a natural loop must dominate\n \t all exits.  */\n-      if (! TEST_BIT (loop->exits_doms, loop->header->sindex))\n+      if (! TEST_BIT (loop->exits_doms, loop->header->index))\n \tabort ();\n     }\n \n@@ -636,14 +635,14 @@ flow_loops_find (loops, flags)\n      struct loops *loops;\n      int flags;\n {\n-  int i, b;\n+  int i;\n+  int b;\n   int num_loops;\n   edge e;\n   sbitmap headers;\n   sbitmap *dom;\n   int *dfs_order;\n   int *rc_order;\n-  basic_block header;\n \n   /* This function cannot be repeatedly called with different\n      flags to build up the loop information.  The loop tree\n@@ -655,21 +654,24 @@ flow_loops_find (loops, flags)\n \n   /* Taking care of this degenerate case makes the rest of\n      this code simpler.  */\n-  if (num_basic_blocks == 0)\n+  if (n_basic_blocks == 0)\n     return 0;\n \n   dfs_order = NULL;\n   rc_order = NULL;\n \n   /* Compute the dominators.  */\n-  dom = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n+  dom = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n   calculate_dominance_info (NULL, dom, CDI_DOMINATORS);\n \n   /* Count the number of loop edges (back edges).  This should be the\n      same as the number of natural loops.  */\n   num_loops = 0;\n-  FOR_ALL_BB (header)\n+  for (b = 0; b < n_basic_blocks; b++)\n     {\n+      basic_block header;\n+\n+      header = BASIC_BLOCK (b);\n       header->loop_depth = 0;\n \n       for (e = header->pred; e; e = e->pred_next)\n@@ -682,7 +684,10 @@ flow_loops_find (loops, flags)\n \t     loop.  It also has single back edge to the header\n \t     from a latch node.  Note that multiple natural loops\n \t     may share the same header.  */\n-\t  if (latch != ENTRY_BLOCK_PTR && TEST_BIT (dom[latch->sindex], header->sindex))\n+\t  if (b != header->index)\n+\t    abort ();\n+\n+\t  if (latch != ENTRY_BLOCK_PTR && TEST_BIT (dom[latch->index], b))\n \t    num_loops++;\n \t}\n     }\n@@ -691,8 +696,8 @@ flow_loops_find (loops, flags)\n     {\n       /* Compute depth first search order of the CFG so that outer\n \t natural loops will be found before inner natural loops.  */\n-      dfs_order = (int *) xmalloc (num_basic_blocks * sizeof (int));\n-      rc_order = (int *) xmalloc (num_basic_blocks * sizeof (int));\n+      dfs_order = (int *) xmalloc (n_basic_blocks * sizeof (int));\n+      rc_order = (int *) xmalloc (n_basic_blocks * sizeof (int));\n       flow_depth_first_order_compute (dfs_order, rc_order);\n \n       /* Save CFG derived information to avoid recomputing it.  */\n@@ -704,16 +709,16 @@ flow_loops_find (loops, flags)\n       loops->array\n \t= (struct loop *) xcalloc (num_loops, sizeof (struct loop));\n \n-      headers = sbitmap_alloc (last_basic_block);\n+      headers = sbitmap_alloc (n_basic_blocks);\n       sbitmap_zero (headers);\n \n-      loops->shared_headers = sbitmap_alloc (last_basic_block);\n+      loops->shared_headers = sbitmap_alloc (n_basic_blocks);\n       sbitmap_zero (loops->shared_headers);\n \n       /* Find and record information about all the natural loops\n \t in the CFG.  */\n       num_loops = 0;\n-      for (b = num_basic_blocks - 1; b >= 0; b--)\n+      for (b = n_basic_blocks - 1; b >= 0; b--)\n \t{\n \t  basic_block latch;\n \n@@ -733,7 +738,7 @@ flow_loops_find (loops, flags)\n \t\t latch node.  Note that multiple natural loops may share\n \t\t the same header.  */\n \t      if (header != EXIT_BLOCK_PTR\n-\t\t  && TEST_BIT (dom[latch->sindex], header->sindex))\n+\t\t  && TEST_BIT (dom[latch->index], header->index))\n \t\t{\n \t\t  struct loop *loop;\n \n@@ -754,12 +759,12 @@ flow_loops_find (loops, flags)\n \n \t  /* Keep track of blocks that are loop headers so\n \t     that we can tell which loops should be merged.  */\n-\t  if (TEST_BIT (headers, loop->header->sindex))\n-\t    SET_BIT (loops->shared_headers, loop->header->sindex);\n-\t  SET_BIT (headers, loop->header->sindex);\n+\t  if (TEST_BIT (headers, loop->header->index))\n+\t    SET_BIT (loops->shared_headers, loop->header->index);\n+\t  SET_BIT (headers, loop->header->index);\n \n \t  /* Find nodes contained within the loop.  */\n-\t  loop->nodes = sbitmap_alloc (last_basic_block);\n+\t  loop->nodes = sbitmap_alloc (n_basic_blocks);\n \t  loop->num_nodes\n \t    = flow_loop_nodes_find (loop->header, loop->latch, loop->nodes);\n \n@@ -780,7 +785,7 @@ flow_loops_find (loops, flags)\n \t loops and should be merged.  For now just mark loops that share\n \t headers.  */\n       for (i = 0; i < num_loops; i++)\n-\tif (TEST_BIT (loops->shared_headers, loops->array[i].header->sindex))\n+\tif (TEST_BIT (loops->shared_headers, loops->array[i].header->index))\n \t  loops->array[i].shared = 1;\n \n       sbitmap_free (headers);\n@@ -827,5 +832,5 @@ flow_loop_outside_edge_p (loop, e)\n     abort ();\n \n   return (e->src == ENTRY_BLOCK_PTR)\n-    || ! TEST_BIT (loop->nodes, e->src->sindex);\n+    || ! TEST_BIT (loop->nodes, e->src->index);\n }"}, {"sha": "844f5df70f51c4cc60b9c479058be44580b96a92", "filename": "gcc/cfgrtl.c", "status": "modified", "additions": 118, "deletions": 124, "changes": 242, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgrtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcfgrtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgrtl.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -248,14 +248,12 @@ delete_insn_chain_and_edges (first, last)\n    the note and basic block struct in BB_NOTE, if any and do not grow\n    BASIC_BLOCK chain and should be used directly only by CFG construction code.\n    END can be NULL in to create new empty basic block before HEAD.  Both END\n-   and HEAD can be NULL to create basic block at the end of INSN chain.\n-   AFTER is the basic block we should be put after.  */\n+   and HEAD can be NULL to create basic block at the end of INSN chain.  */\n \n basic_block\n-create_basic_block_structure (index, head, end, bb_note, after)\n+create_basic_block_structure (index, head, end, bb_note)\n      int index;\n      rtx head, end, bb_note;\n-     basic_block after;\n {\n   basic_block bb;\n \n@@ -311,9 +309,8 @@ create_basic_block_structure (index, head, end, bb_note, after)\n \n   bb->head = head;\n   bb->end = end;\n-  bb->sindex = index;\n+  bb->index = index;\n   bb->flags = BB_NEW;\n-  link_block (bb, after);\n   BASIC_BLOCK (index) = bb;\n   if (basic_block_for_insn)\n     update_bb_for_insn (bb);\n@@ -326,23 +323,33 @@ create_basic_block_structure (index, head, end, bb_note, after)\n }\n \n /* Create new basic block consisting of instructions in between HEAD and END\n-   and place it to the BB chain after block AFTER.  END can be NULL in to\n+   and place it to the BB chain at position INDEX.  END can be NULL in to\n    create new empty basic block before HEAD.  Both END and HEAD can be NULL to\n    create basic block at the end of INSN chain.  */\n \n basic_block\n-create_basic_block (head, end, after)\n+create_basic_block (index, head, end)\n+     int index;\n      rtx head, end;\n-     basic_block after;\n {\n   basic_block bb;\n-  int index = last_basic_block++;\n+  int i;\n+\n+  /* Place the new block just after the block being split.  */\n+  VARRAY_GROW (basic_block_info, ++n_basic_blocks);\n+\n+  /* Some parts of the compiler expect blocks to be number in\n+     sequential order so insert the new block immediately after the\n+     block being split..  */\n+  for (i = n_basic_blocks - 1; i > index; --i)\n+    {\n+      basic_block tmp = BASIC_BLOCK (i - 1);\n \n-  /* Place the new block to the end.  */\n-  VARRAY_GROW (basic_block_info, last_basic_block);\n+      BASIC_BLOCK (i) = tmp;\n+      tmp->index = i;\n+    }\n \n-  num_basic_blocks++;\n-  bb = create_basic_block_structure (index, head, end, NULL, after);\n+  bb = create_basic_block_structure (index, head, end, NULL);\n   bb->aux = NULL;\n   return bb;\n }\n@@ -424,7 +431,7 @@ flow_delete_block (b)\n {\n   int deleted_handler = flow_delete_block_noexpunge (b);\n   \n-  /* Remove the basic block from the array.  */\n+  /* Remove the basic block from the array, and compact behind it.  */\n   expunge_block (b);\n \n   return deleted_handler;\n@@ -437,15 +444,16 @@ void\n compute_bb_for_insn (max)\n      int max;\n {\n-  basic_block bb;\n+  int i;\n \n   if (basic_block_for_insn)\n     VARRAY_FREE (basic_block_for_insn);\n \n   VARRAY_BB_INIT (basic_block_for_insn, max, \"basic_block_for_insn\");\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; ++i)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx end = bb->end;\n       rtx insn;\n \n@@ -529,7 +537,7 @@ split_block (bb, insn)\n     return 0;\n \n   /* Create the new basic block.  */\n-  new_bb = create_basic_block (NEXT_INSN (insn), bb->end, bb);\n+  new_bb = create_basic_block (bb->index + 1, NEXT_INSN (insn), bb->end);\n   new_bb->count = bb->count;\n   new_bb->frequency = bb->frequency;\n   new_bb->loop_depth = bb->loop_depth;\n@@ -764,7 +772,7 @@ try_redirect_by_replacing_jump (e, target)\n \treturn false;\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \"Redirecting jump %i from %i to %i.\\n\",\n-\t\t INSN_UID (insn), e->dest->sindex, target->sindex);\n+\t\t INSN_UID (insn), e->dest->index, target->index);\n       if (!redirect_jump (insn, block_label (target), 0))\n \t{\n \t  if (target == EXIT_BLOCK_PTR)\n@@ -961,7 +969,7 @@ redirect_edge_and_branch (e, target)\n \n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \"Edge %i->%i redirected to %i\\n\",\n-\t     e->src->sindex, e->dest->sindex, target->sindex);\n+\t     e->src->index, e->dest->index, target->index);\n \n   if (e->dest != target)\n     redirect_edge_succ_nodup (e, target);\n@@ -990,7 +998,7 @@ force_nonfallthru_and_redirect (e, target)\n       /* We can't redirect the entry block.  Create an empty block at the\n          start of the function which we use to add the new jump.  */\n       edge *pe1;\n-      basic_block bb = create_basic_block (e->dest->head, NULL, ENTRY_BLOCK_PTR);\n+      basic_block bb = create_basic_block (0, e->dest->head, NULL);\n \n       /* Change the existing edge's source to be the new block, and add\n \t a new edge from the entry block to the new block.  */\n@@ -1010,7 +1018,8 @@ force_nonfallthru_and_redirect (e, target)\n     {\n       /* Create the new structures.  */\n       note = last_loop_beg_note (e->src->end);\n-      jump_block = create_basic_block (NEXT_INSN (note), NULL, e->src);\n+      jump_block\n+\t= create_basic_block (e->src->index + 1, NEXT_INSN (note), NULL);\n       jump_block->count = e->count;\n       jump_block->frequency = EDGE_FREQUENCY (e);\n       jump_block->loop_depth = target->loop_depth;\n@@ -1155,11 +1164,12 @@ tidy_fallthru_edge (e, b, c)\n void\n tidy_fallthru_edges ()\n {\n-  basic_block b, c;\n+  int i;\n \n-  for (b = ENTRY_BLOCK_PTR->next_bb, c = b->next_bb;\n-       c && c != EXIT_BLOCK_PTR; b = c, c = c->next_bb)\n+  for (i = 1; i < n_basic_blocks; i++)\n     {\n+      basic_block b = BASIC_BLOCK (i - 1);\n+      basic_block c = BASIC_BLOCK (i);\n       edge s;\n \n       /* We care about simple conditional or unconditional jumps with\n@@ -1194,17 +1204,11 @@ back_edge_of_syntactic_loop_p (bb1, bb2)\n {\n   rtx insn;\n   int count = 0;\n-  basic_block bb;\n \n-  if (bb1 == bb2)\n-    return true;\n-\n-  for (bb = bb1; bb && bb != bb2; bb = bb->next_bb)\n-    {\n-    }\n-  \n-  if (!bb)\n+  if (bb1->index > bb2->index)\n     return false;\n+  else if (bb1->index == bb2->index)\n+    return true;\n \n   for (insn = bb1->end; insn != bb2->head && count >= 0;\n        insn = NEXT_INSN (insn))\n@@ -1282,7 +1286,8 @@ split_edge (edge_in)\n   else\n     before = NULL_RTX;\n \n-  bb = create_basic_block (before, NULL, edge_in->dest->prev_bb);\n+  bb = create_basic_block (edge_in->dest == EXIT_BLOCK_PTR ? n_basic_blocks\n+\t\t\t   : edge_in->dest->index, before, NULL);\n   bb->count = edge_in->count;\n   bb->frequency = EDGE_FREQUENCY (edge_in);\n \n@@ -1453,7 +1458,7 @@ commit_one_edge_insertion (e, watch_calls)\n \n       e->flags &= ~EDGE_FALLTHRU;\n       emit_barrier_after (last);\n-    \n+\n       if (before)\n \tdelete_insn (before);\n     }\n@@ -1476,8 +1481,8 @@ commit_edge_insertions ()\n #endif\n \n   i = -1;\n-  \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n+  bb = ENTRY_BLOCK_PTR;\n+  while (1)\n     {\n       edge e, next;\n \n@@ -1487,6 +1492,10 @@ commit_edge_insertions ()\n \t  if (e->insns)\n \t    commit_one_edge_insertion (e, false);\n \t}\n+\n+      if (++i >= n_basic_blocks)\n+\tbreak;\n+      bb = BASIC_BLOCK (i);\n     }\n }\n \f\n@@ -1504,7 +1513,8 @@ commit_edge_insertions_watch_calls ()\n #endif\n \n   i = -1;\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)\n+  bb = ENTRY_BLOCK_PTR;\n+  while (1)\n     {\n       edge e, next;\n \n@@ -1514,6 +1524,10 @@ commit_edge_insertions_watch_calls ()\n \t  if (e->insns)\n \t    commit_one_edge_insertion (e, true);\n \t}\n+\n+      if (++i >= n_basic_blocks)\n+\tbreak;\n+      bb = BASIC_BLOCK (i);\n     }\n }\n \f\n@@ -1529,7 +1543,7 @@ dump_bb (bb, outf)\n   edge e;\n \n   fprintf (outf, \";; Basic block %d, loop depth %d, count \",\n-\t   bb->sindex, bb->loop_depth);\n+\t   bb->index, bb->loop_depth);\n   fprintf (outf, HOST_WIDEST_INT_PRINT_DEC, (HOST_WIDEST_INT) bb->count);\n   putc ('\\n', outf);\n \n@@ -1584,6 +1598,7 @@ print_rtl_with_bb (outf, rtx_first)\n     fprintf (outf, \"(nil)\\n\");\n   else\n     {\n+      int i;\n       enum bb_state { NOT_IN_BB, IN_ONE_BB, IN_MULTIPLE_BB };\n       int max_uid = get_max_uid ();\n       basic_block *start\n@@ -1592,10 +1607,10 @@ print_rtl_with_bb (outf, rtx_first)\n \t= (basic_block *) xcalloc (max_uid, sizeof (basic_block));\n       enum bb_state *in_bb_p\n \t= (enum bb_state *) xcalloc (max_uid, sizeof (enum bb_state));\n-      basic_block bb;\n \n-      FOR_ALL_BB_REVERSE (bb)\n+      for (i = n_basic_blocks - 1; i >= 0; i--)\n \t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  rtx x;\n \n \t  start[INSN_UID (bb->head)] = bb;\n@@ -1616,11 +1631,12 @@ print_rtl_with_bb (outf, rtx_first)\n       for (tmp_rtx = rtx_first; NULL != tmp_rtx; tmp_rtx = NEXT_INSN (tmp_rtx))\n \t{\n \t  int did_output;\n+\t  basic_block bb;\n \n \t  if ((bb = start[INSN_UID (tmp_rtx)]) != NULL)\n \t    {\n \t      fprintf (outf, \";; Start of basic block %d, registers live:\",\n-\t\t       bb->sindex);\n+\t\t       bb->index);\n \t      dump_regset (bb->global_live_at_start, outf);\n \t      putc ('\\n', outf);\n \t    }\n@@ -1637,7 +1653,7 @@ print_rtl_with_bb (outf, rtx_first)\n \t  if ((bb = end[INSN_UID (tmp_rtx)]) != NULL)\n \t    {\n \t      fprintf (outf, \";; End of basic block %d, registers live:\\n\",\n-\t\t       bb->sindex);\n+\t\t       bb->index);\n \t      dump_regset (bb->global_live_at_end, outf);\n \t      putc ('\\n', outf);\n \t    }\n@@ -1702,37 +1718,16 @@ verify_flow_info ()\n   basic_block *bb_info, *last_visited;\n   size_t *edge_checksum;\n   rtx x;\n-  int num_bb_notes, err = 0;\n-  basic_block bb, last_bb_seen;\n+  int i, last_bb_num_seen, num_bb_notes, err = 0;\n \n   bb_info = (basic_block *) xcalloc (max_uid, sizeof (basic_block));\n-  last_visited = (basic_block *) xcalloc (last_basic_block + 2,\n+  last_visited = (basic_block *) xcalloc (n_basic_blocks + 2,\n \t\t\t\t\t  sizeof (basic_block));\n-  edge_checksum = (size_t *) xcalloc (last_basic_block + 2, sizeof (size_t));\n-\n-  /* Check bb chain & numbers.  */\n-  last_bb_seen = ENTRY_BLOCK_PTR;\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR->next_bb, NULL, next_bb)\n-    {\n-      if (bb != EXIT_BLOCK_PTR\n-\t  && bb != BASIC_BLOCK (bb->sindex))\n-\t{\n-\t  error (\"bb %d on wrong place\", bb->sindex);\n-\t  err = 1;\n-\t}\n+  edge_checksum = (size_t *) xcalloc (n_basic_blocks + 2, sizeof (size_t));\n \n-      if (bb->prev_bb != last_bb_seen)\n-\t{\n-\t  error (\"prev_bb of %d should be %d, not %d\",\n-\t\t bb->sindex, last_bb_seen->sindex, bb->prev_bb->sindex);\n-\t  err = 1;\n-\t}\n-        \n-      last_bb_seen = bb;\n-    }\n-\n-  FOR_ALL_BB_REVERSE (bb)\n+  for (i = n_basic_blocks - 1; i >= 0; i--)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx head = bb->head;\n       rtx end = bb->end;\n \n@@ -1744,7 +1739,7 @@ verify_flow_info ()\n       if (!x)\n \t{\n \t  error (\"end insn %d for block %d not found in the insn stream\",\n-\t\t INSN_UID (end), bb->sindex);\n+\t\t INSN_UID (end), bb->index);\n \t  err = 1;\n \t}\n \n@@ -1758,7 +1753,7 @@ verify_flow_info ()\n \t  if (bb_info[INSN_UID (x)] != NULL)\n \t    {\n \t      error (\"insn %d is in multiple basic blocks (%d and %d)\",\n-\t\t     INSN_UID (x), bb->sindex, bb_info[INSN_UID (x)]->sindex);\n+\t\t     INSN_UID (x), bb->index, bb_info[INSN_UID (x)]->index);\n \t      err = 1;\n \t    }\n \n@@ -1770,16 +1765,17 @@ verify_flow_info ()\n       if (!x)\n \t{\n \t  error (\"head insn %d for block %d not found in the insn stream\",\n-\t\t INSN_UID (head), bb->sindex);\n+\t\t INSN_UID (head), bb->index);\n \t  err = 1;\n \t}\n \n       last_head = x;\n     }\n \n   /* Now check the basic blocks (boundaries etc.) */\n-  FOR_ALL_BB_REVERSE (bb)\n+  for (i = n_basic_blocks - 1; i >= 0; i--)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       int n_fallthru = 0, n_eh = 0, n_call = 0, n_abnormal = 0, n_branch = 0;\n       edge e;\n       rtx note;\n@@ -1799,37 +1795,37 @@ verify_flow_info ()\n       if (bb->count < 0)\n         {\n           error (\"verify_flow_info: Wrong count of block %i %i\",\n-\t         bb->sindex, (int)bb->count);\n+\t         bb->index, (int)bb->count);\n           err = 1;\n         }\n       if (bb->frequency < 0)\n         {\n           error (\"verify_flow_info: Wrong frequency of block %i %i\",\n-\t         bb->sindex, bb->frequency);\n+\t         bb->index, bb->frequency);\n           err = 1;\n         }\n       for (e = bb->succ; e; e = e->succ_next)\n \t{\n-\t  if (last_visited [e->dest->sindex + 2] == bb)\n+\t  if (last_visited [e->dest->index + 2] == bb)\n \t    {\n \t      error (\"verify_flow_info: Duplicate edge %i->%i\",\n-\t\t     e->src->sindex, e->dest->sindex);\n+\t\t     e->src->index, e->dest->index);\n \t      err = 1;\n \t    }\n \t  if (e->probability < 0 || e->probability > REG_BR_PROB_BASE)\n \t    {\n \t      error (\"verify_flow_info: Wrong probability of edge %i->%i %i\",\n-\t\t     e->src->sindex, e->dest->sindex, e->probability);\n+\t\t     e->src->index, e->dest->index, e->probability);\n \t      err = 1;\n \t    }\n \t  if (e->count < 0)\n \t    {\n \t      error (\"verify_flow_info: Wrong count of edge %i->%i %i\",\n-\t\t     e->src->sindex, e->dest->sindex, (int)e->count);\n+\t\t     e->src->index, e->dest->index, (int)e->count);\n \t      err = 1;\n \t    }\n \n-\t  last_visited [e->dest->sindex + 2] = bb;\n+\t  last_visited [e->dest->index + 2] = bb;\n \n \t  if (e->flags & EDGE_FALLTHRU)\n \t    n_fallthru++;\n@@ -1851,11 +1847,11 @@ verify_flow_info ()\n \t    {\n \t      rtx insn;\n \n-\t      if (e->src->next_bb != e->dest)\n+\t      if (e->src->index + 1 != e->dest->index)\n \t\t{\n \t\t  error\n \t\t    (\"verify_flow_info: Incorrect blocks for fallthru %i->%i\",\n-\t\t     e->src->sindex, e->dest->sindex);\n+\t\t     e->src->index, e->dest->index);\n \t\t  err = 1;\n \t\t}\n \t      else\n@@ -1870,7 +1866,7 @@ verify_flow_info ()\n \t\t      )\n \t\t    {\n \t\t      error (\"verify_flow_info: Incorrect fallthru %i->%i\",\n-\t\t\t     e->src->sindex, e->dest->sindex);\n+\t\t\t     e->src->index, e->dest->index);\n \t\t      fatal_insn (\"wrong insn in the fallthru edge\", insn);\n \t\t      err = 1;\n \t\t    }\n@@ -1879,7 +1875,7 @@ verify_flow_info ()\n \t  if (e->src != bb)\n \t    {\n \t      error (\"verify_flow_info: Basic block %d succ edge is corrupted\",\n-\t\t     bb->sindex);\n+\t\t     bb->index);\n \t      fprintf (stderr, \"Predecessor: \");\n \t      dump_edge_info (stderr, e, 0);\n \t      fprintf (stderr, \"\\nSuccessor: \");\n@@ -1888,42 +1884,42 @@ verify_flow_info ()\n \t      err = 1;\n \t    }\n \n-\t  edge_checksum[e->dest->sindex + 2] += (size_t) e;\n+\t  edge_checksum[e->dest->index + 2] += (size_t) e;\n \t}\n \n       if (n_eh && GET_CODE (PATTERN (bb->end)) != RESX\n \t  && !find_reg_note (bb->end, REG_EH_REGION, NULL_RTX))\n \t{\n-\t  error (\"Missing REG_EH_REGION note in the end of bb %i\", bb->sindex);\n+\t  error (\"Missing REG_EH_REGION note in the end of bb %i\", bb->index);\n \t  err = 1;\n \t}\n       if (n_branch\n \t  && (GET_CODE (bb->end) != JUMP_INSN\n \t      || (n_branch > 1 && (any_uncondjump_p (bb->end)\n \t\t\t\t   || any_condjump_p (bb->end)))))\n \t{\n-\t  error (\"Too many outgoing branch edges from bb %i\", bb->sindex);\n+\t  error (\"Too many outgoing branch edges from bb %i\", bb->index);\n \t  err = 1;\n \t}\n       if (n_fallthru && any_uncondjump_p (bb->end))\n \t{\n-\t  error (\"Fallthru edge after unconditional jump %i\", bb->sindex);\n+\t  error (\"Fallthru edge after unconditional jump %i\", bb->index);\n \t  err = 1;\n \t}\n       if (n_branch != 1 && any_uncondjump_p (bb->end))\n \t{\n-\t  error (\"Wrong amount of branch edges after unconditional jump %i\", bb->sindex);\n+\t  error (\"Wrong amount of branch edges after unconditional jump %i\", bb->index);\n \t  err = 1;\n \t}\n       if (n_branch != 1 && any_condjump_p (bb->end)\n-\t  && JUMP_LABEL (bb->end) != bb->next_bb->head)\n+\t  && JUMP_LABEL (bb->end) != BASIC_BLOCK (bb->index + 1)->head)\n \t{\n-\t  error (\"Wrong amount of branch edges after conditional jump %i\", bb->sindex);\n+\t  error (\"Wrong amount of branch edges after conditional jump %i\", bb->index);\n \t  err = 1;\n \t}\n       if (n_call && GET_CODE (bb->end) != CALL_INSN)\n \t{\n-\t  error (\"Call edges for non-call insn in bb %i\", bb->sindex);\n+\t  error (\"Call edges for non-call insn in bb %i\", bb->index);\n \t  err = 1;\n \t}\n       if (n_abnormal\n@@ -1932,7 +1928,7 @@ verify_flow_info ()\n \t      || any_condjump_p (bb->end)\n \t      || any_uncondjump_p (bb->end)))\n \t{\n-\t  error (\"Abnormal edges for no purpose in bb %i\", bb->sindex);\n+\t  error (\"Abnormal edges for no purpose in bb %i\", bb->index);\n \t  err = 1;\n \t}\n \t\n@@ -1947,7 +1943,7 @@ verify_flow_info ()\n \t\t|| (GET_CODE (insn) == NOTE\n \t\t    && NOTE_LINE_NUMBER (insn) == NOTE_INSN_BASIC_BLOCK))\n \t\t{\n-\t\t  error (\"missing barrier after block %i\", bb->sindex);\n+\t\t  error (\"missing barrier after block %i\", bb->index);\n \t\t  err = 1;\n \t\t  break;\n \t\t}\n@@ -1957,15 +1953,15 @@ verify_flow_info ()\n \t{\n \t  if (e->dest != bb)\n \t    {\n-\t      error (\"basic block %d pred edge is corrupted\", bb->sindex);\n+\t      error (\"basic block %d pred edge is corrupted\", bb->index);\n \t      fputs (\"Predecessor: \", stderr);\n \t      dump_edge_info (stderr, e, 0);\n \t      fputs (\"\\nSuccessor: \", stderr);\n \t      dump_edge_info (stderr, e, 1);\n \t      fputc ('\\n', stderr);\n \t      err = 1;\n \t    }\n-\t  edge_checksum[e->dest->sindex + 2] -= (size_t) e;\n+\t  edge_checksum[e->dest->index + 2] -= (size_t) e;\n \t}\n \n       for (x = bb->head; x != NEXT_INSN (bb->end); x = NEXT_INSN (x))\n@@ -1975,11 +1971,11 @@ verify_flow_info ()\n \t    if (! BLOCK_FOR_INSN (x))\n \t      error\n \t\t(\"insn %d inside basic block %d but block_for_insn is NULL\",\n-\t\t INSN_UID (x), bb->sindex);\n+\t\t INSN_UID (x), bb->index);\n \t    else\n \t      error\n \t\t(\"insn %d inside basic block %d but block_for_insn is %i\",\n-\t\t INSN_UID (x), bb->sindex, BLOCK_FOR_INSN (x)->sindex);\n+\t\t INSN_UID (x), bb->index, BLOCK_FOR_INSN (x)->index);\n \n \t    err = 1;\n \t  }\n@@ -1993,7 +1989,7 @@ verify_flow_info ()\n \t  if (bb->end == x)\n \t    {\n \t      error (\"NOTE_INSN_BASIC_BLOCK is missing for block %d\",\n-\t\t     bb->sindex);\n+\t\t     bb->index);\n \t      err = 1;\n \t    }\n \n@@ -2003,7 +1999,7 @@ verify_flow_info ()\n       if (!NOTE_INSN_BASIC_BLOCK_P (x) || NOTE_BASIC_BLOCK (x) != bb)\n \t{\n \t  error (\"NOTE_INSN_BASIC_BLOCK is missing for block %d\",\n-\t\t bb->sindex);\n+\t\t bb->index);\n \t  err = 1;\n \t}\n \n@@ -2016,7 +2012,7 @@ verify_flow_info ()\n \t    if (NOTE_INSN_BASIC_BLOCK_P (x))\n \t      {\n \t\terror (\"NOTE_INSN_BASIC_BLOCK %d in middle of basic block %d\",\n-\t\t       INSN_UID (x), bb->sindex);\n+\t\t       INSN_UID (x), bb->index);\n \t\terr = 1;\n \t      }\n \n@@ -2027,7 +2023,7 @@ verify_flow_info ()\n \t\t|| GET_CODE (x) == CODE_LABEL\n \t\t|| GET_CODE (x) == BARRIER)\n \t      {\n-\t\terror (\"in basic block %d:\", bb->sindex);\n+\t\terror (\"in basic block %d:\", bb->index);\n \t\tfatal_insn (\"flow control insn inside a basic block\", x);\n \t      }\n \t  }\n@@ -2038,33 +2034,32 @@ verify_flow_info ()\n     edge e;\n \n     for (e = ENTRY_BLOCK_PTR->succ; e ; e = e->succ_next)\n-      edge_checksum[e->dest->sindex + 2] += (size_t) e;\n+      edge_checksum[e->dest->index + 2] += (size_t) e;\n \n     for (e = EXIT_BLOCK_PTR->pred; e ; e = e->pred_next)\n-      edge_checksum[e->dest->sindex + 2] -= (size_t) e;\n+      edge_checksum[e->dest->index + 2] -= (size_t) e;\n   }\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n-    if (edge_checksum[bb->sindex + 2])\n+  for (i = -2; i < n_basic_blocks; ++i)\n+    if (edge_checksum[i + 2])\n       {\n-\terror (\"basic block %i edge lists are corrupted\", bb->sindex);\n+\terror (\"basic block %i edge lists are corrupted\", i);\n \terr = 1;\n       }\n \n+  last_bb_num_seen = -1;\n   num_bb_notes = 0;\n-  last_bb_seen = ENTRY_BLOCK_PTR;\n-\n   for (x = rtx_first; x; x = NEXT_INSN (x))\n     {\n       if (NOTE_INSN_BASIC_BLOCK_P (x))\n \t{\n-\t  bb = NOTE_BASIC_BLOCK (x);\n+\t  basic_block bb = NOTE_BASIC_BLOCK (x);\n \n \t  num_bb_notes++;\n-\t  if (bb != last_bb_seen->next_bb)\n+\t  if (bb->index != last_bb_num_seen + 1)\n \t    internal_error (\"basic blocks not numbered consecutively\");\n \n-\t  last_bb_seen = bb;\n+\t  last_bb_num_seen = bb->index;\n \t}\n \n       if (!bb_info[INSN_UID (x)])\n@@ -2098,10 +2093,10 @@ verify_flow_info ()\n \t    fatal_insn (\"return not followed by barrier\", x);\n     }\n \n-  if (num_bb_notes != num_basic_blocks)\n+  if (num_bb_notes != n_basic_blocks)\n     internal_error\n-      (\"number of bb notes in insn chain (%d) != num_basic_blocks (%d)\",\n-       num_bb_notes, num_basic_blocks);\n+      (\"number of bb notes in insn chain (%d) != n_basic_blocks (%d)\",\n+       num_bb_notes, n_basic_blocks);\n \n   if (err)\n     internal_error (\"verify_flow_info failed\");\n@@ -2220,7 +2215,7 @@ purge_dead_edges (bb)\n \treturn purged;\n \n       if (rtl_dump_file)\n-\tfprintf (rtl_dump_file, \"Purged edges from bb %i\\n\", bb->sindex);\n+\tfprintf (rtl_dump_file, \"Purged edges from bb %i\\n\", bb->index);\n \n       if (!optimize)\n \treturn purged;\n@@ -2279,7 +2274,7 @@ purge_dead_edges (bb)\n \n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \"Purged non-fallthru edges from bb %i\\n\",\n-\t     bb->sindex);\n+\t     bb->index);\n   return purged;\n }\n \n@@ -2290,23 +2285,22 @@ bool\n purge_all_dead_edges (update_life_p)\n      int update_life_p;\n {\n-  int purged = false;\n+  int i, purged = false;\n   sbitmap blocks = 0;\n-  basic_block bb;\n \n   if (update_life_p)\n     {\n-      blocks = sbitmap_alloc (last_basic_block);\n+      blocks = sbitmap_alloc (n_basic_blocks);\n       sbitmap_zero (blocks);\n     }\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n-      bool purged_here = purge_dead_edges (bb);\n+      bool purged_here = purge_dead_edges (BASIC_BLOCK (i));\n \n       purged |= purged_here;\n       if (purged_here && update_life_p)\n-\tSET_BIT (blocks, bb->sindex);\n+\tSET_BIT (blocks, i);\n     }\n \n   if (update_life_p && purged)"}, {"sha": "7a5604fc56c36d423adb6b4c50691e4c553baeb8", "filename": "gcc/combine.c", "status": "modified", "additions": 131, "deletions": 130, "changes": 261, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -192,8 +192,8 @@ static HARD_REG_SET newpat_used_regs;\n \n static rtx added_links_insn;\n \n-/* Basic block which we are performing combines.  */\n-static basic_block this_basic_block;\n+/* Basic block number of the block in which we are performing combines.  */\n+static int this_basic_block;\n \n /* A bitmap indicating which blocks had registers go dead at entry.\n    After combine, we'll need to re-do global life analysis with\n@@ -578,7 +578,7 @@ combine_instructions (f, nregs)\n \n   setup_incoming_promotions ();\n \n-  refresh_blocks = sbitmap_alloc (last_basic_block);\n+  refresh_blocks = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (refresh_blocks);\n   need_refresh = 0;\n \n@@ -610,138 +610,139 @@ combine_instructions (f, nregs)\n \n   /* Now scan all the insns in forward order.  */\n \n+  this_basic_block = -1;\n   label_tick = 1;\n   last_call_cuid = 0;\n   mem_last_set = 0;\n   init_reg_last_arrays ();\n   setup_incoming_promotions ();\n \n-  FOR_ALL_BB (this_basic_block)\n+  for (insn = f; insn; insn = next ? next : NEXT_INSN (insn))\n     {\n-      for (insn = this_basic_block->head;\n-           insn != NEXT_INSN (this_basic_block->end);\n-\t   insn = next ? next : NEXT_INSN (insn))\n+      next = 0;\n+\n+      /* If INSN starts a new basic block, update our basic block number.  */\n+      if (this_basic_block + 1 < n_basic_blocks\n+\t  && BLOCK_HEAD (this_basic_block + 1) == insn)\n+\tthis_basic_block++;\n+\n+      if (GET_CODE (insn) == CODE_LABEL)\n+\tlabel_tick++;\n+\n+      else if (INSN_P (insn))\n \t{\n-\t  next = 0;\n+\t  /* See if we know about function return values before this\n+\t     insn based upon SUBREG flags.  */\n+\t  check_promoted_subreg (insn, PATTERN (insn));\n \n-\t  if (GET_CODE (insn) == CODE_LABEL)\n-\t    label_tick++;\n+\t  /* Try this insn with each insn it links back to.  */\n \n-\t  else if (INSN_P (insn))\n-\t    {\n-\t      /* See if we know about function return values before this\n-\t\t insn based upon SUBREG flags.  */\n-\t      check_promoted_subreg (insn, PATTERN (insn));\n+\t  for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n+\t    if ((next = try_combine (insn, XEXP (links, 0),\n+\t\t\t\t     NULL_RTX, &new_direct_jump_p)) != 0)\n+\t      goto retry;\n \n-\t      /* Try this insn with each insn it links back to.  */\n+\t  /* Try each sequence of three linked insns ending with this one.  */\n \n-\t      for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n-\t\tif ((next = try_combine (insn, XEXP (links, 0),\n-\t\t\t\t\t NULL_RTX, &new_direct_jump_p)) != 0)\n-\t\t  goto retry;\n+\t  for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n+\t    {\n+\t      rtx link = XEXP (links, 0);\n \n-\t      /* Try each sequence of three linked insns ending with this one.  */\n+\t      /* If the linked insn has been replaced by a note, then there\n+\t\t is no point in pursuing this chain any further.  */\n+\t      if (GET_CODE (link) == NOTE)\n+\t\tcontinue;\n \n-\t      for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n-\t\t{\n-\t\t  rtx link = XEXP (links, 0);\n-\n-\t\t  /* If the linked insn has been replaced by a note, then there\n-\t\t     is no point in pursuing this chain any further.  */\n-\t\t  if (GET_CODE (link) == NOTE)\n-\t\t    continue;\n-\n-\t \t  for (nextlinks = LOG_LINKS (link);\n-\t\t    nextlinks;\n-\t\t  nextlinks = XEXP (nextlinks, 1))\n-\t\t  if ((next = try_combine (insn, link,\n-\t\t\t\t\t   XEXP (nextlinks, 0),\n-\t\t\t\t\t   &new_direct_jump_p)) != 0)\n-\t\t    goto retry;\n-\t\t}\n+\t      for (nextlinks = LOG_LINKS (link);\n+\t\t   nextlinks;\n+\t\t   nextlinks = XEXP (nextlinks, 1))\n+\t\tif ((next = try_combine (insn, link,\n+\t\t\t\t\t XEXP (nextlinks, 0),\n+\t\t\t\t\t &new_direct_jump_p)) != 0)\n+\t\t  goto retry;\n+\t    }\n \n #ifdef HAVE_cc0\n-\t      /* Try to combine a jump insn that uses CC0\n-\t\t with a preceding insn that sets CC0, and maybe with its\n-\t\t logical predecessor as well.\n-\t\t This is how we make decrement-and-branch insns.\n-\t\t We need this special code because data flow connections\n-\t\t via CC0 do not get entered in LOG_LINKS.  */\n-\n-\t      if (GET_CODE (insn) == JUMP_INSN\n-\t\t  && (prev = prev_nonnote_insn (insn)) != 0\n-\t\t  && GET_CODE (prev) == INSN\n-\t\t  && sets_cc0_p (PATTERN (prev)))\n-\t\t{\n-\t\t  if ((next = try_combine (insn, prev,\n-\t\t\t\t\t   NULL_RTX, &new_direct_jump_p)) != 0)\n-\t\t    goto retry;\n-\n-\t\t  for (nextlinks = LOG_LINKS (prev); nextlinks;\n-\t\t       nextlinks = XEXP (nextlinks, 1))\n-\t\t    if ((next = try_combine (insn, prev,\n-\t\t\t\t\t     XEXP (nextlinks, 0),\n-\t\t\t\t\t     &new_direct_jump_p)) != 0)\n-\t\t      goto retry;\n-\t\t}\n+\t  /* Try to combine a jump insn that uses CC0\n+\t     with a preceding insn that sets CC0, and maybe with its\n+\t     logical predecessor as well.\n+\t     This is how we make decrement-and-branch insns.\n+\t     We need this special code because data flow connections\n+\t     via CC0 do not get entered in LOG_LINKS.  */\n+\n+\t  if (GET_CODE (insn) == JUMP_INSN\n+\t      && (prev = prev_nonnote_insn (insn)) != 0\n+\t      && GET_CODE (prev) == INSN\n+\t      && sets_cc0_p (PATTERN (prev)))\n+\t    {\n+\t      if ((next = try_combine (insn, prev,\n+\t\t\t\t       NULL_RTX, &new_direct_jump_p)) != 0)\n+\t\tgoto retry;\n+\n+\t      for (nextlinks = LOG_LINKS (prev); nextlinks;\n+\t\t   nextlinks = XEXP (nextlinks, 1))\n+\t\tif ((next = try_combine (insn, prev,\n+\t\t\t\t\t XEXP (nextlinks, 0),\n+\t\t\t\t\t &new_direct_jump_p)) != 0)\n+\t\t  goto retry;\n+\t    }\n \n-\t      /* Do the same for an insn that explicitly references CC0.  */\n-\t      if (GET_CODE (insn) == INSN\n-\t\t  && (prev = prev_nonnote_insn (insn)) != 0\n-\t\t  && GET_CODE (prev) == INSN\n-\t\t  && sets_cc0_p (PATTERN (prev))\n-\t\t  && GET_CODE (PATTERN (insn)) == SET\n-\t\t  && reg_mentioned_p (cc0_rtx, SET_SRC (PATTERN (insn))))\n-\t\t{\n-\t\t  if ((next = try_combine (insn, prev,\n-\t\t\t\t\t   NULL_RTX, &new_direct_jump_p)) != 0)\n-\t\t    goto retry;\n-\n-\t\t  for (nextlinks = LOG_LINKS (prev); nextlinks;\n-\t\t       nextlinks = XEXP (nextlinks, 1))\n-\t\t    if ((next = try_combine (insn, prev,\n-\t\t\t\t\t     XEXP (nextlinks, 0),\n-\t\t\t\t\t     &new_direct_jump_p)) != 0)\n-\t\t      goto retry;\n-\t\t}\n+\t  /* Do the same for an insn that explicitly references CC0.  */\n+\t  if (GET_CODE (insn) == INSN\n+\t      && (prev = prev_nonnote_insn (insn)) != 0\n+\t      && GET_CODE (prev) == INSN\n+\t      && sets_cc0_p (PATTERN (prev))\n+\t      && GET_CODE (PATTERN (insn)) == SET\n+\t      && reg_mentioned_p (cc0_rtx, SET_SRC (PATTERN (insn))))\n+\t    {\n+\t      if ((next = try_combine (insn, prev,\n+\t\t\t\t       NULL_RTX, &new_direct_jump_p)) != 0)\n+\t\tgoto retry;\n \n-\t      /* Finally, see if any of the insns that this insn links to\n-\t\t explicitly references CC0.  If so, try this insn, that insn,\n-\t\t and its predecessor if it sets CC0.  */\n-\t      for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n-\t\tif (GET_CODE (XEXP (links, 0)) == INSN\n-\t\t    && GET_CODE (PATTERN (XEXP (links, 0))) == SET\n-\t\t    && reg_mentioned_p (cc0_rtx, SET_SRC (PATTERN (XEXP (links, 0))))\n-\t\t    && (prev = prev_nonnote_insn (XEXP (links, 0))) != 0\n-\t\t    && GET_CODE (prev) == INSN\n-\t\t    && sets_cc0_p (PATTERN (prev))\n-\t\t    && (next = try_combine (insn, XEXP (links, 0),\n-\t\t\t\t\t    prev, &new_direct_jump_p)) != 0)\n+\t      for (nextlinks = LOG_LINKS (prev); nextlinks;\n+\t\t   nextlinks = XEXP (nextlinks, 1))\n+\t\tif ((next = try_combine (insn, prev,\n+\t\t\t\t\t XEXP (nextlinks, 0),\n+\t\t\t\t\t &new_direct_jump_p)) != 0)\n \t\t  goto retry;\n+\t    }\n+\n+\t  /* Finally, see if any of the insns that this insn links to\n+\t     explicitly references CC0.  If so, try this insn, that insn,\n+\t     and its predecessor if it sets CC0.  */\n+\t  for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n+\t    if (GET_CODE (XEXP (links, 0)) == INSN\n+\t\t&& GET_CODE (PATTERN (XEXP (links, 0))) == SET\n+\t\t&& reg_mentioned_p (cc0_rtx, SET_SRC (PATTERN (XEXP (links, 0))))\n+\t\t&& (prev = prev_nonnote_insn (XEXP (links, 0))) != 0\n+\t\t&& GET_CODE (prev) == INSN\n+\t\t&& sets_cc0_p (PATTERN (prev))\n+\t\t&& (next = try_combine (insn, XEXP (links, 0),\n+\t\t\t\t\tprev, &new_direct_jump_p)) != 0)\n+\t      goto retry;\n #endif\n \n-\t      /* Try combining an insn with two different insns whose results it\n-\t\t uses.  */\n-\t      for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n-\t\tfor (nextlinks = XEXP (links, 1); nextlinks;\n-\t\t     nextlinks = XEXP (nextlinks, 1))\n-\t\t  if ((next = try_combine (insn, XEXP (links, 0),\n-\t\t\t\t\t   XEXP (nextlinks, 0),\n-\t\t\t\t\t   &new_direct_jump_p)) != 0)\n-\t\t    goto retry;\n+\t  /* Try combining an insn with two different insns whose results it\n+\t     uses.  */\n+\t  for (links = LOG_LINKS (insn); links; links = XEXP (links, 1))\n+\t    for (nextlinks = XEXP (links, 1); nextlinks;\n+\t\t nextlinks = XEXP (nextlinks, 1))\n+\t      if ((next = try_combine (insn, XEXP (links, 0),\n+\t\t\t\t       XEXP (nextlinks, 0),\n+\t\t\t\t       &new_direct_jump_p)) != 0)\n+\t\tgoto retry;\n \n-\t      if (GET_CODE (insn) != NOTE)\n-\t\trecord_dead_and_set_regs (insn);\n+\t  if (GET_CODE (insn) != NOTE)\n+\t    record_dead_and_set_regs (insn);\n \n-\t      retry:\n-\t      ;\n-\t    }\n+\tretry:\n+\t  ;\n \t}\n     }\n   clear_bb_flags ();\n \n-  EXECUTE_IF_SET_IN_SBITMAP (refresh_blocks, 0, i,\n-\t\t\t     BASIC_BLOCK (i)->flags |= BB_DIRTY);\n+  EXECUTE_IF_SET_IN_SBITMAP (refresh_blocks, 0, this_basic_block,\n+\t\t\t     BASIC_BLOCK (this_basic_block)->flags |= BB_DIRTY);\n   new_direct_jump_p |= purge_all_dead_edges (0);\n   delete_noop_moves (f);\n \n@@ -859,7 +860,7 @@ set_nonzero_bits_and_sign_copies (x, set, data)\n       && REGNO (x) >= FIRST_PSEUDO_REGISTER\n       /* If this register is undefined at the start of the file, we can't\n \t say what its contents were.  */\n-      && ! REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start, REGNO (x))\n+      && ! REGNO_REG_SET_P (BASIC_BLOCK (0)->global_live_at_start, REGNO (x))\n       && GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT)\n     {\n       if (set == 0 || GET_CODE (set) == CLOBBER)\n@@ -2389,8 +2390,8 @@ try_combine (i3, i2, i1, new_direct_jump_p)\n \t     which we know will be a NOTE.  */\n \n \t  for (insn = NEXT_INSN (i3);\n-\t       insn && (this_basic_block->next_bb == EXIT_BLOCK_PTR\n-\t\t\t|| insn != this_basic_block->next_bb->head);\n+\t       insn && (this_basic_block == n_basic_blocks - 1\n+\t\t\t|| insn != BLOCK_HEAD (this_basic_block + 1));\n \t       insn = NEXT_INSN (insn))\n \t    {\n \t      if (INSN_P (insn) && reg_referenced_p (ni2dest, PATTERN (insn)))\n@@ -2607,8 +2608,8 @@ try_combine (i3, i2, i1, new_direct_jump_p)\n \t      && ! find_reg_note (i2, REG_UNUSED,\n \t\t\t\t  SET_DEST (XVECEXP (PATTERN (i2), 0, i))))\n \t    for (temp = NEXT_INSN (i2);\n-\t\t temp && (this_basic_block->next_bb == EXIT_BLOCK_PTR\n-\t\t\t  || this_basic_block->head != temp);\n+\t\t temp && (this_basic_block == n_basic_blocks - 1\n+\t\t\t  || BLOCK_HEAD (this_basic_block) != temp);\n \t\t temp = NEXT_INSN (temp))\n \t      if (temp != i3 && INSN_P (temp))\n \t\tfor (link = LOG_LINKS (temp); link; link = XEXP (link, 1))\n@@ -8069,7 +8070,7 @@ nonzero_bits (x, mode)\n \t  && (reg_last_set_label[REGNO (x)] == label_tick\n \t      || (REGNO (x) >= FIRST_PSEUDO_REGISTER\n \t\t  && REG_N_SETS (REGNO (x)) == 1\n-\t\t  && ! REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start,\n+\t\t  && ! REGNO_REG_SET_P (BASIC_BLOCK (0)->global_live_at_start,\n \t\t\t\t\tREGNO (x))))\n \t  && INSN_CUID (reg_last_set[REGNO (x)]) < subst_low_cuid)\n \treturn reg_last_set_nonzero_bits[REGNO (x)] & nonzero;\n@@ -8484,7 +8485,7 @@ num_sign_bit_copies (x, mode)\n \t  && (reg_last_set_label[REGNO (x)] == label_tick\n \t      || (REGNO (x) >= FIRST_PSEUDO_REGISTER\n \t\t  && REG_N_SETS (REGNO (x)) == 1\n-\t\t  && ! REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start,\n+\t\t  && ! REGNO_REG_SET_P (BASIC_BLOCK (0)->global_live_at_start,\n \t\t\t\t\tREGNO (x))))\n \t  && INSN_CUID (reg_last_set[REGNO (x)]) < subst_low_cuid)\n \treturn reg_last_set_sign_bit_copies[REGNO (x)];\n@@ -11493,7 +11494,7 @@ get_last_value_validate (loc, insn, tick, replace)\n \t    || (! (regno >= FIRST_PSEUDO_REGISTER\n \t\t   && REG_N_SETS (regno) == 1\n \t\t   && (! REGNO_REG_SET_P\n-\t\t       (ENTRY_BLOCK_PTR->next_bb->global_live_at_start, regno)))\n+\t\t       (BASIC_BLOCK (0)->global_live_at_start, regno)))\n \t\t&& reg_last_set_label[j] > tick))\n \t  {\n \t    if (replace)\n@@ -11567,7 +11568,7 @@ get_last_value (x)\n \t  && (regno < FIRST_PSEUDO_REGISTER\n \t      || REG_N_SETS (regno) != 1\n \t      || (REGNO_REG_SET_P\n-\t\t  (ENTRY_BLOCK_PTR->next_bb->global_live_at_start, regno)))))\n+\t\t  (BASIC_BLOCK (0)->global_live_at_start, regno)))))\n     return 0;\n \n   /* If the value was set in a later insn than the ones we are processing,\n@@ -11686,7 +11687,7 @@ reg_dead_at_p (reg, insn)\n      rtx reg;\n      rtx insn;\n {\n-  basic_block block;\n+  int block;\n   unsigned int i;\n \n   /* Set variables for reg_dead_at_p_1.  */\n@@ -11721,19 +11722,19 @@ reg_dead_at_p (reg, insn)\n \n   /* Get the basic block number that we were in.  */\n   if (insn == 0)\n-    block = ENTRY_BLOCK_PTR->next_bb;\n+    block = 0;\n   else\n     {\n-      FOR_ALL_BB (block)\n-\tif (insn == block->head)\n+      for (block = 0; block < n_basic_blocks; block++)\n+\tif (insn == BLOCK_HEAD (block))\n \t  break;\n \n-      if (block == EXIT_BLOCK_PTR)\n+      if (block == n_basic_blocks)\n \treturn 0;\n     }\n \n   for (i = reg_dead_regno; i < reg_dead_endregno; i++)\n-    if (REGNO_REG_SET_P (block->global_live_at_start, i))\n+    if (REGNO_REG_SET_P (BASIC_BLOCK (block)->global_live_at_start, i))\n       return 0;\n \n   return 1;\n@@ -12376,7 +12377,7 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \n \t  if (place == 0)\n \t    {\n-\t      basic_block bb = this_basic_block;\n+\t      basic_block bb = BASIC_BLOCK (this_basic_block);\n \n \t      for (tem = PREV_INSN (i3); place == 0; tem = PREV_INSN (tem))\n \t\t{\n@@ -12520,7 +12521,7 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \t\t  && REGNO_REG_SET_P (bb->global_live_at_start,\n \t\t\t\t      REGNO (XEXP (note, 0))))\n \t\t{\n-\t\t  SET_BIT (refresh_blocks, this_basic_block->sindex);\n+\t\t  SET_BIT (refresh_blocks, this_basic_block);\n \t\t  need_refresh = 1;\n \t\t}\n \t    }\n@@ -12540,7 +12541,7 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \t\t after we remove them in delete_noop_moves.  */\n \t      if (noop_move_p (place))\n \t\t{\n-\t\t  SET_BIT (refresh_blocks, this_basic_block->sindex);\n+\t\t  SET_BIT (refresh_blocks, this_basic_block);\n \t\t  need_refresh = 1;\n \t\t}\n \n@@ -12590,7 +12591,7 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \t\t\t   i += HARD_REGNO_NREGS (i, reg_raw_mode[i]))\n \t\t\t{\n \t\t\t  rtx piece = gen_rtx_REG (reg_raw_mode[i], i);\n-\t\t\t  basic_block bb = this_basic_block;\n+\t\t\t  basic_block bb = BASIC_BLOCK (this_basic_block);\n \n \t\t\t  if (! dead_or_set_p (place, piece)\n \t\t\t      && ! reg_bitfield_target_p (piece,\n@@ -12613,7 +12614,7 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \t\t\t\t    if (tem == bb->head)\n \t\t\t\t      {\n \t\t\t\t\tSET_BIT (refresh_blocks,\n-\t\t\t\t\t\t this_basic_block->sindex);\n+\t\t\t\t\t\t this_basic_block);\n \t\t\t\t\tneed_refresh = 1;\n \t\t\t\t\tbreak;\n \t\t\t\t      }\n@@ -12718,8 +12719,8 @@ distribute_links (links)\n \t since most links don't point very far away.  */\n \n       for (insn = NEXT_INSN (XEXP (link, 0));\n-\t   (insn && (this_basic_block->next_bb == EXIT_BLOCK_PTR\n-\t\t     || this_basic_block->next_bb->head != insn));\n+\t   (insn && (this_basic_block == n_basic_blocks - 1\n+\t\t     || BLOCK_HEAD (this_basic_block + 1) != insn));\n \t   insn = NEXT_INSN (insn))\n \tif (INSN_P (insn) && reg_overlap_mentioned_p (reg, PATTERN (insn)))\n \t  {"}, {"sha": "d1fb1293cf9f142f1bc8020201029bdb56bf389a", "filename": "gcc/conflict.c", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fconflict.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fconflict.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconflict.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -447,18 +447,19 @@ conflict_graph_compute (regs, p)\n      regset regs;\n      partition p;\n {\n+  int b;\n   conflict_graph graph = conflict_graph_new (max_reg_num ());\n   regset_head live_head;\n   regset live = &live_head;\n   regset_head born_head;\n   regset born = &born_head;\n-  basic_block bb;\n \n   INIT_REG_SET (live);\n   INIT_REG_SET (born);\n \n-  FOR_ALL_BB_REVERSE (bb)\n+  for (b = n_basic_blocks; --b >= 0; )\n     {\n+      basic_block bb = BASIC_BLOCK (b);\n       rtx insn;\n       rtx head;\n "}, {"sha": "be36febfea95c528bdee1bb70f1f6b21fe257d81", "filename": "gcc/df.c", "status": "modified", "additions": 125, "deletions": 119, "changes": 244, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fdf.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fdf.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdf.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -171,6 +171,12 @@ Perhaps there should be a bitmap argument to df_analyse to specify\n #include \"df.h\"\n #include \"fibheap.h\"\n \n+#define FOR_ALL_BBS(BB, CODE)\t\t\t\t\t\\\n+do {\t\t\t\t\t\t\t\t\\\n+  int node_;\t\t\t\t\t\t\t\\\n+  for (node_ = 0; node_ < n_basic_blocks; node_++)\t\t\\\n+    {(BB) = BASIC_BLOCK (node_); CODE;};} while (0)\n+\n #define FOR_EACH_BB_IN_BITMAP(BITMAP, MIN, BB, CODE)\t\t\\\n do {\t\t\t\t\t\t\t\t\\\n   unsigned int node_;\t\t\t\t\t\t\\\n@@ -400,8 +406,8 @@ df_bitmaps_alloc (df, flags)\n      struct df *df;\n      int flags;\n {\n+  unsigned int i;\n   int dflags = 0;\n-  basic_block bb;\n \n   /* Free the bitmaps if they need resizing.  */\n   if ((flags & DF_LR) && df->n_regs < (unsigned int)max_reg_num ())\n@@ -417,8 +423,9 @@ df_bitmaps_alloc (df, flags)\n   df->n_defs = df->def_id;\n   df->n_uses = df->use_id;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < df->n_bbs; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       struct bb_info *bb_info = DF_BB_INFO (df, bb);\n \n       if (flags & DF_RD && ! bb_info->rd_in)\n@@ -467,10 +474,11 @@ df_bitmaps_free (df, flags)\n      struct df *df ATTRIBUTE_UNUSED;\n      int flags;\n {\n-  basic_block bb;\n+  unsigned int i;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < df->n_bbs; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       struct bb_info *bb_info = DF_BB_INFO (df, bb);\n \n       if (!bb_info)\n@@ -526,7 +534,7 @@ df_alloc (df, n_regs)\n      int n_regs;\n {\n   int n_insns;\n-  basic_block bb;\n+  int i;\n \n   gcc_obstack_init (&df_ref_obstack);\n \n@@ -547,7 +555,7 @@ df_alloc (df, n_regs)\n   df->uses = xmalloc (df->use_size * sizeof (*df->uses));\n \n   df->n_regs = n_regs;\n-  df->n_bbs = last_basic_block;\n+  df->n_bbs = n_basic_blocks;\n \n   /* Allocate temporary working array used during local dataflow analysis.  */\n   df->reg_def_last = xmalloc (df->n_regs * sizeof (struct ref *));\n@@ -561,11 +569,11 @@ df_alloc (df, n_regs)\n \n   df->flags = 0;\n \n-  df->bbs = xcalloc (last_basic_block, sizeof (struct bb_info));\n+  df->bbs = xcalloc (df->n_bbs, sizeof (struct bb_info));\n \n   df->all_blocks = BITMAP_XMALLOC ();\n-  FOR_ALL_BB (bb)\n-    bitmap_set_bit (df->all_blocks, bb->sindex);\n+  for (i = 0; i < n_basic_blocks; i++)\n+    bitmap_set_bit (df->all_blocks, i);\n }\n \n \n@@ -1938,10 +1946,8 @@ df_analyse_1 (df, blocks, flags, update)\n   int aflags;\n   int dflags;\n   int i;\n-  basic_block bb;\n-\n   dflags = 0;\n-  aflags = flags; \n+  aflags = flags;\n   if (flags & DF_UD_CHAIN)\n     aflags |= DF_RD | DF_RD_CHAIN;\n \n@@ -2003,16 +2009,16 @@ df_analyse_1 (df, blocks, flags, update)\n       df_reg_use_chain_create (df, blocks);\n     }\n \n-  df->dfs_order = xmalloc (sizeof(int) * num_basic_blocks);\n-  df->rc_order = xmalloc (sizeof(int) * num_basic_blocks);\n-  df->rts_order = xmalloc (sizeof(int) * num_basic_blocks);\n-  df->inverse_dfs_map = xmalloc (sizeof(int) * last_basic_block);\n-  df->inverse_rc_map = xmalloc (sizeof(int) * last_basic_block);\n-  df->inverse_rts_map = xmalloc (sizeof(int) * last_basic_block);\n-  \n+  df->dfs_order = xmalloc (sizeof(int) * n_basic_blocks);\n+  df->rc_order = xmalloc (sizeof(int) * n_basic_blocks);\n+  df->rts_order = xmalloc (sizeof(int) * n_basic_blocks);\n+  df->inverse_dfs_map = xmalloc (sizeof(int) * n_basic_blocks);\n+  df->inverse_rc_map = xmalloc (sizeof(int) * n_basic_blocks);\n+  df->inverse_rts_map = xmalloc (sizeof(int) * n_basic_blocks);\n+\n   flow_depth_first_order_compute (df->dfs_order, df->rc_order);\n   flow_reverse_top_sort_order_compute (df->rts_order);\n-  for (i = 0; i < num_basic_blocks; i ++)\n+  for (i = 0; i < n_basic_blocks; i ++)\n    {\n      df->inverse_dfs_map[df->dfs_order[i]] = i;\n      df->inverse_rc_map[df->rc_order[i]] = i;\n@@ -2023,16 +2029,17 @@ df_analyse_1 (df, blocks, flags, update)\n       /* Compute the sets of gens and kills for the defs of each bb.  */\n       df_rd_local_compute (df, df->flags & DF_RD ? blocks : df->all_blocks);\n       {\n-\tbitmap *in = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *out = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *gen = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *kill = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tFOR_ALL_BB (bb)\n+\tint i;\n+\tbitmap *in = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *out = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *gen = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *kill = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tfor (i = 0; i < n_basic_blocks; i ++)\n \t  {\n-\t    in[bb->sindex] = DF_BB_INFO (df, bb)->rd_in;\n-\t    out[bb->sindex] = DF_BB_INFO (df, bb)->rd_out;\n-\t    gen[bb->sindex] = DF_BB_INFO (df, bb)->rd_gen;\n-\t    kill[bb->sindex] = DF_BB_INFO (df, bb)->rd_kill;\n+\t    in[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->rd_in;\n+\t    out[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->rd_out;\n+\t    gen[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->rd_gen;\n+\t    kill[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->rd_kill;\n \t  }\n \titerative_dataflow_bitmap (in, out, gen, kill, df->all_blocks,\n \t\t\t\t   FORWARD, UNION, df_rd_transfer_function,\n@@ -2059,16 +2066,17 @@ df_analyse_1 (df, blocks, flags, update)\n \t uses in each bb.  */\n       df_ru_local_compute (df, df->flags & DF_RU ? blocks : df->all_blocks);\n       {\n-\tbitmap *in = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *out = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *gen = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *kill = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tFOR_ALL_BB (bb)\n+\tint i;\n+\tbitmap *in = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *out = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *gen = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *kill = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tfor (i = 0; i < n_basic_blocks; i ++)\n \t  {\n-\t    in[bb->sindex] = DF_BB_INFO (df, bb)->ru_in;\n-\t    out[bb->sindex] = DF_BB_INFO (df, bb)->ru_out;\n-\t    gen[bb->sindex] = DF_BB_INFO (df, bb)->ru_gen;\n-\t    kill[bb->sindex] = DF_BB_INFO (df, bb)->ru_kill;\n+\t    in[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->ru_in;\n+\t    out[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->ru_out;\n+\t    gen[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->ru_gen;\n+\t    kill[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->ru_kill;\n \t  }\n \titerative_dataflow_bitmap (in, out, gen, kill, df->all_blocks,\n \t\t\t\t   BACKWARD, UNION, df_ru_transfer_function,\n@@ -2098,16 +2106,17 @@ df_analyse_1 (df, blocks, flags, update)\n       /* Compute the sets of defs and uses of live variables.  */\n       df_lr_local_compute (df, df->flags & DF_LR ? blocks : df->all_blocks);\n       {\n-\tbitmap *in = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *out = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *use = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tbitmap *def = xmalloc (sizeof (bitmap) * last_basic_block);\n-\tFOR_ALL_BB (bb)\n+\tint i;\n+\tbitmap *in = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *out = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *use = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tbitmap *def = xmalloc (sizeof (bitmap) * n_basic_blocks);\n+\tfor (i = 0; i < n_basic_blocks; i ++)\n \t  {\n-\t    in[bb->sindex] = DF_BB_INFO (df, bb)->lr_in;\n-\t    out[bb->sindex] = DF_BB_INFO (df, bb)->lr_out;\n-\t    use[bb->sindex] = DF_BB_INFO (df, bb)->lr_use;\n-\t    def[bb->sindex] = DF_BB_INFO (df, bb)->lr_def;\n+\t    in[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->lr_in;\n+\t    out[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->lr_out;\n+\t    use[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->lr_use;\n+\t    def[i] = DF_BB_INFO (df, BASIC_BLOCK (i))->lr_def;\n \t  }\n \titerative_dataflow_bitmap (in, out, use, def, df->all_blocks,\n \t\t\t\t   BACKWARD, UNION, df_lr_transfer_function,\n@@ -2261,15 +2270,12 @@ df_modified_p (df, blocks)\n      struct df *df;\n      bitmap blocks;\n {\n+  unsigned int j;\n   int update = 0;\n-  basic_block bb;\n-\n-  if (!df->n_bbs)\n-    return 0;\n \n-  FOR_ALL_BB (bb)\n-    if (bitmap_bit_p (df->bbs_modified, bb->sindex)\n-\t&& (! blocks || (blocks == (bitmap) -1) || bitmap_bit_p (blocks, bb->sindex)))\n+  for (j = 0; j < df->n_bbs; j++)\n+    if (bitmap_bit_p (df->bbs_modified, j)\n+\t&& (! blocks || (blocks == (bitmap) -1) || bitmap_bit_p (blocks, j)))\n     {\n       update = 1;\n       break;\n@@ -2292,7 +2298,7 @@ df_analyse (df, blocks, flags)\n \n   /* We could deal with additional basic blocks being created by\n      rescanning everything again.  */\n-  if (df->n_bbs && df->n_bbs != (unsigned int) last_basic_block)\n+  if (df->n_bbs && df->n_bbs != (unsigned int)n_basic_blocks)\n     abort ();\n \n   update = df_modified_p (df, blocks);\n@@ -2402,8 +2408,10 @@ df_refs_unlink (df, blocks)\n     }\n   else\n     {\n-      FOR_ALL_BB (bb)\n+      FOR_ALL_BBS (bb,\n+      {\n \tdf_bb_refs_unlink (df, bb);\n+      });\n     }\n }\n #endif\n@@ -2451,7 +2459,7 @@ df_insn_modify (df, bb, insn)\n   if (uid >= df->insn_size)\n     df_insn_table_realloc (df, 0);\n \n-  bitmap_set_bit (df->bbs_modified, bb->sindex);\n+  bitmap_set_bit (df->bbs_modified, bb->index);\n   bitmap_set_bit (df->insns_modified, uid);\n \n   /* For incremental updating on the fly, perhaps we could make a copy\n@@ -3266,6 +3274,7 @@ df_dump (df, flags, file)\n      int flags;\n      FILE *file;\n {\n+  unsigned int i;\n   unsigned int j;\n \n   if (! df || ! file)\n@@ -3277,23 +3286,22 @@ df_dump (df, flags, file)\n \n   if (flags & DF_RD)\n     {\n-      basic_block bb;\n-\n       fprintf (file, \"Reaching defs:\\n\");\n-      FOR_ALL_BB (bb)\n+      for (i = 0; i < df->n_bbs; i++)\n \t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  struct bb_info *bb_info = DF_BB_INFO (df, bb);\n \n \t  if (! bb_info->rd_in)\n \t    continue;\n \n-\t  fprintf (file, \"bb %d in  \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d in  \\t\", i);\n \t  dump_bitmap (file, bb_info->rd_in);\n-\t  fprintf (file, \"bb %d gen \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d gen \\t\", i);\n \t  dump_bitmap (file, bb_info->rd_gen);\n-\t  fprintf (file, \"bb %d kill\\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d kill\\t\", i);\n \t  dump_bitmap (file, bb_info->rd_kill);\n-\t  fprintf (file, \"bb %d out \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d out \\t\", i);\n \t  dump_bitmap (file, bb_info->rd_out);\n \t}\n     }\n@@ -3320,23 +3328,22 @@ df_dump (df, flags, file)\n \n   if (flags & DF_RU)\n     {\n-      basic_block bb;\n-\n       fprintf (file, \"Reaching uses:\\n\");\n-      FOR_ALL_BB (bb)\n+      for (i = 0; i < df->n_bbs; i++)\n \t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  struct bb_info *bb_info = DF_BB_INFO (df, bb);\n \n \t  if (! bb_info->ru_in)\n \t    continue;\n \n-\t  fprintf (file, \"bb %d in  \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d in  \\t\", i);\n \t  dump_bitmap (file, bb_info->ru_in);\n-\t  fprintf (file, \"bb %d gen \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d gen \\t\", i);\n \t  dump_bitmap (file, bb_info->ru_gen);\n-\t  fprintf (file, \"bb %d kill\\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d kill\\t\", i);\n \t  dump_bitmap (file, bb_info->ru_kill);\n-\t  fprintf (file, \"bb %d out \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d out \\t\", i);\n \t  dump_bitmap (file, bb_info->ru_out);\n \t}\n     }\n@@ -3363,23 +3370,22 @@ df_dump (df, flags, file)\n \n   if (flags & DF_LR)\n     {\n-      basic_block bb;\n-\n       fprintf (file, \"Live regs:\\n\");\n-      FOR_ALL_BB (bb)\n+      for (i = 0; i < df->n_bbs; i++)\n \t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  struct bb_info *bb_info = DF_BB_INFO (df, bb);\n \n \t  if (! bb_info->lr_in)\n \t    continue;\n \n-\t  fprintf (file, \"bb %d in  \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d in  \\t\", i);\n \t  dump_bitmap (file, bb_info->lr_in);\n-\t  fprintf (file, \"bb %d use \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d use \\t\", i);\n \t  dump_bitmap (file, bb_info->lr_use);\n-\t  fprintf (file, \"bb %d def \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d def \\t\", i);\n \t  dump_bitmap (file, bb_info->lr_def);\n-\t  fprintf (file, \"bb %d out \\t\", bb->sindex);\n+\t  fprintf (file, \"bb %d out \\t\", i);\n \t  dump_bitmap (file, bb_info->lr_out);\n \t}\n     }\n@@ -3402,7 +3408,7 @@ df_dump (df, flags, file)\n \t\tbasic_block bb = df_regno_bb (df, j);\n \n \t\tif (bb)\n-\t\t  fprintf (file, \" bb %d\", bb->sindex);\n+\t\t  fprintf (file, \" bb %d\", bb->index);\n \t\telse\n \t\t  fprintf (file, \" bb ?\");\n \t      }\n@@ -3603,11 +3609,11 @@ hybrid_search_bitmap (block, in, out, gen, kill, dir,\n      void *data;\n {\n   int changed;\n-  int i = block->sindex;\n+  int i = block->index;\n   edge e;\n-  basic_block bb = block;\n-  SET_BIT (visited, block->sindex);\n-  if (TEST_BIT (pending, block->sindex))\n+  basic_block bb= block;\n+  SET_BIT (visited, block->index);\n+  if (TEST_BIT (pending, block->index))\n     {\n       if (dir == FORWARD)\n \t{\n@@ -3620,10 +3626,10 @@ hybrid_search_bitmap (block, in, out, gen, kill, dir,\n \t      switch (conf_op)\n \t\t{\n \t\tcase UNION:\n-\t\t  bitmap_a_or_b (in[i], in[i], out[e->src->sindex]);\n+\t\t  bitmap_a_or_b (in[i], in[i], out[e->src->index]);\n \t\t  break;\n \t\tcase INTERSECTION:\n-\t\t  bitmap_a_and_b (in[i], in[i], out[e->src->sindex]);\n+\t\t  bitmap_a_and_b (in[i], in[i], out[e->src->index]);\n \t\t  break;\n \t\t}\n \t    }\n@@ -3639,10 +3645,10 @@ hybrid_search_bitmap (block, in, out, gen, kill, dir,\n \t      switch (conf_op)\n \t\t{\n \t\tcase UNION:\n-\t\t  bitmap_a_or_b (out[i], out[i], in[e->dest->sindex]);\n+\t\t  bitmap_a_or_b (out[i], out[i], in[e->dest->index]);\n \t\t  break;\n \t\tcase INTERSECTION:\n-\t\t  bitmap_a_and_b (out[i], out[i], in[e->dest->sindex]);\n+\t\t  bitmap_a_and_b (out[i], out[i], in[e->dest->index]);\n \t\t  break;\n \t\t}\n \t    }\n@@ -3656,18 +3662,18 @@ hybrid_search_bitmap (block, in, out, gen, kill, dir,\n \t    {\n \t      for (e = bb->succ; e != 0; e = e->succ_next)\n \t\t{\n-\t\t  if (e->dest == EXIT_BLOCK_PTR || e->dest == block)\n+\t\t  if (e->dest == EXIT_BLOCK_PTR || e->dest->index == i)\n \t\t    continue;\n-\t\t  SET_BIT (pending, e->dest->sindex);\n+\t\t  SET_BIT (pending, e->dest->index);\n \t\t}\n \t    }\n \t  else\n \t    {\n \t      for (e = bb->pred; e != 0; e = e->pred_next)\n \t\t{\n-\t\t  if (e->src == ENTRY_BLOCK_PTR || e->dest == block)\n+\t\t  if (e->src == ENTRY_BLOCK_PTR || e->dest->index == i)\n \t\t    continue;\n-\t\t  SET_BIT (pending, e->src->sindex);\n+\t\t  SET_BIT (pending, e->src->index);\n \t\t}\n \t    }\n \t}\n@@ -3676,21 +3682,21 @@ hybrid_search_bitmap (block, in, out, gen, kill, dir,\n     {\n       for (e = bb->succ; e != 0; e = e->succ_next)\n \t{\n-\t  if (e->dest == EXIT_BLOCK_PTR || e->dest == block)\n+\t  if (e->dest == EXIT_BLOCK_PTR || e->dest->index == i)\n \t    continue;\n-\t  if (!TEST_BIT (visited, e->dest->sindex))\n-\t    hybrid_search_bitmap (e->dest, in, out, gen, kill, dir, \n-\t\t\t\t  conf_op, transfun, visited, pending, \n+\t  if (!TEST_BIT (visited, e->dest->index))\n+\t    hybrid_search_bitmap (e->dest, in, out, gen, kill, dir,\n+\t\t\t\t  conf_op, transfun, visited, pending,\n \t\t\t\t  data);\n \t}\n     }\n   else\n     {\n       for (e = bb->pred; e != 0; e = e->pred_next)\n \t{\n-\t  if (e->src == ENTRY_BLOCK_PTR || e->src == block)\n+\t  if (e->src == ENTRY_BLOCK_PTR || e->src->index == i)\n \t    continue;\n-\t  if (!TEST_BIT (visited, e->src->sindex))\n+\t  if (!TEST_BIT (visited, e->src->index))\n \t    hybrid_search_bitmap (e->src, in, out, gen, kill, dir,\n \t\t\t\t  conf_op, transfun, visited, pending,\n \t\t\t\t  data);\n@@ -3714,11 +3720,11 @@ hybrid_search_sbitmap (block, in, out, gen, kill, dir,\n      void *data;\n {\n   int changed;\n-  int i = block->sindex;\n+  int i = block->index;\n   edge e;\n-  basic_block bb = block;\n-  SET_BIT (visited, block->sindex);\n-  if (TEST_BIT (pending, block->sindex))\n+  basic_block bb= block;\n+  SET_BIT (visited, block->index);\n+  if (TEST_BIT (pending, block->index))\n     {\n       if (dir == FORWARD)\n \t{\n@@ -3731,10 +3737,10 @@ hybrid_search_sbitmap (block, in, out, gen, kill, dir,\n \t      switch (conf_op)\n \t\t{\n \t\tcase UNION:\n-\t\t  sbitmap_a_or_b (in[i], in[i], out[e->src->sindex]);\n+\t\t  sbitmap_a_or_b (in[i], in[i], out[e->src->index]);\n \t\t  break;\n \t\tcase INTERSECTION:\n-\t\t  sbitmap_a_and_b (in[i], in[i], out[e->src->sindex]);\n+\t\t  sbitmap_a_and_b (in[i], in[i], out[e->src->index]);\n \t\t  break;\n \t\t}\n \t    }\n@@ -3750,10 +3756,10 @@ hybrid_search_sbitmap (block, in, out, gen, kill, dir,\n \t      switch (conf_op)\n \t\t{\n \t\tcase UNION:\n-\t\t  sbitmap_a_or_b (out[i], out[i], in[e->dest->sindex]);\n+\t\t  sbitmap_a_or_b (out[i], out[i], in[e->dest->index]);\n \t\t  break;\n \t\tcase INTERSECTION:\n-\t\t  sbitmap_a_and_b (out[i], out[i], in[e->dest->sindex]);\n+\t\t  sbitmap_a_and_b (out[i], out[i], in[e->dest->index]);\n \t\t  break;\n \t\t}\n \t    }\n@@ -3767,18 +3773,18 @@ hybrid_search_sbitmap (block, in, out, gen, kill, dir,\n \t    {\n \t      for (e = bb->succ; e != 0; e = e->succ_next)\n \t\t{\n-\t\t  if (e->dest == EXIT_BLOCK_PTR || e->dest == block)\n+\t\t  if (e->dest == EXIT_BLOCK_PTR || e->dest->index == i)\n \t\t    continue;\n-\t\t  SET_BIT (pending, e->dest->sindex);\n+\t\t  SET_BIT (pending, e->dest->index);\n \t\t}\n \t    }\n \t  else\n \t    {\n \t      for (e = bb->pred; e != 0; e = e->pred_next)\n \t\t{\n-\t\t  if (e->src == ENTRY_BLOCK_PTR || e->dest == block)\n+\t\t  if (e->src == ENTRY_BLOCK_PTR || e->dest->index == i)\n \t\t    continue;\n-\t\t  SET_BIT (pending, e->src->sindex);\n+\t\t  SET_BIT (pending, e->src->index);\n \t\t}\n \t    }\n \t}\n@@ -3787,9 +3793,9 @@ hybrid_search_sbitmap (block, in, out, gen, kill, dir,\n     {\n       for (e = bb->succ; e != 0; e = e->succ_next)\n \t{\n-\t  if (e->dest == EXIT_BLOCK_PTR || e->dest == block)\n+\t  if (e->dest == EXIT_BLOCK_PTR || e->dest->index == i)\n \t    continue;\n-\t  if (!TEST_BIT (visited, e->dest->sindex))\n+\t  if (!TEST_BIT (visited, e->dest->index))\n \t    hybrid_search_sbitmap (e->dest, in, out, gen, kill, dir,\n \t\t\t\t   conf_op, transfun, visited, pending,\n \t\t\t\t   data);\n@@ -3799,9 +3805,9 @@ hybrid_search_sbitmap (block, in, out, gen, kill, dir,\n     {\n       for (e = bb->pred; e != 0; e = e->pred_next)\n \t{\n-\t  if (e->src == ENTRY_BLOCK_PTR || e->src == block)\n+\t  if (e->src == ENTRY_BLOCK_PTR || e->src->index == i)\n \t    continue;\n-\t  if (!TEST_BIT (visited, e->src->sindex))\n+\t  if (!TEST_BIT (visited, e->src->index))\n \t    hybrid_search_sbitmap (e->src, in, out, gen, kill, dir,\n \t\t\t\t   conf_op, transfun, visited, pending,\n \t\t\t\t   data);\n@@ -3847,8 +3853,8 @@ iterative_dataflow_sbitmap (in, out, gen, kill, blocks,\n   fibheap_t worklist;\n   basic_block bb;\n   sbitmap visited, pending;\n-  pending = sbitmap_alloc (last_basic_block);\n-  visited = sbitmap_alloc (last_basic_block);\n+  pending = sbitmap_alloc (n_basic_blocks);\n+  visited = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (pending);\n   sbitmap_zero (visited);\n   worklist = fibheap_new ();\n@@ -3867,7 +3873,7 @@ iterative_dataflow_sbitmap (in, out, gen, kill, blocks,\n \t{\n \t  i = (size_t) fibheap_extract_min (worklist);\n \t  bb = BASIC_BLOCK (i);\n-\t  if (!TEST_BIT (visited, bb->sindex))\n+\t  if (!TEST_BIT (visited, bb->index))\n \t    hybrid_search_sbitmap (bb, in, out, gen, kill, dir,\n \t\t\t\t   conf_op, transfun, visited, pending, data);\n \t}\n@@ -3906,8 +3912,8 @@ iterative_dataflow_bitmap (in, out, gen, kill, blocks,\n   fibheap_t worklist;\n   basic_block bb;\n   sbitmap visited, pending;\n-  pending = sbitmap_alloc (last_basic_block);\n-  visited = sbitmap_alloc (last_basic_block);\n+  pending = sbitmap_alloc (n_basic_blocks);\n+  visited = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (pending);\n   sbitmap_zero (visited);\n   worklist = fibheap_new ();\n@@ -3926,7 +3932,7 @@ iterative_dataflow_bitmap (in, out, gen, kill, blocks,\n \t{\n \t  i = (size_t) fibheap_extract_min (worklist);\n \t  bb = BASIC_BLOCK (i);\n-\t  if (!TEST_BIT (visited, bb->sindex))\n+\t  if (!TEST_BIT (visited, bb->index))\n \t    hybrid_search_bitmap (bb, in, out, gen, kill, dir,\n \t\t\t\t  conf_op, transfun, visited, pending, data);\n \t}"}, {"sha": "7f4e4be71efc3c910290575fff9ece829900b4da", "filename": "gcc/df.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fdf.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fdf.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdf.h?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -158,7 +158,7 @@ struct df_map\n };\n \n \n-#define DF_BB_INFO(REFS, BB) (&REFS->bbs[(BB)->sindex])\n+#define DF_BB_INFO(REFS, BB) (&REFS->bbs[(BB)->index])\n \n \n /* Macros to access the elements within the ref structure.  */\n@@ -175,7 +175,7 @@ struct df_map\n #define DF_REF_LOC(REF) ((REF)->loc)\n #endif\n #define DF_REF_BB(REF) (BLOCK_FOR_INSN ((REF)->insn))\n-#define DF_REF_BBNO(REF) (BLOCK_FOR_INSN ((REF)->insn)->sindex)\n+#define DF_REF_BBNO(REF) (BLOCK_FOR_INSN ((REF)->insn)->index)\n #define DF_REF_INSN(REF) ((REF)->insn)\n #define DF_REF_INSN_UID(REF) (INSN_UID ((REF)->insn))\n #define DF_REF_TYPE(REF) ((REF)->type)"}, {"sha": "3b8abdb28e8734e8d0bb301730fdc9552c4fa7be", "filename": "gcc/dominance.c", "status": "modified", "additions": 30, "deletions": 29, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fdominance.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fdominance.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdominance.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -45,7 +45,7 @@\n    number of the corresponding basic block.  Please note, that we include the\n    artificial ENTRY_BLOCK (or EXIT_BLOCK in the post-dom case) in our lists to\n    support multiple entry points.  As it has no real basic block index we use\n-   'last_basic_block' for that.  Its dfs number is of course 1.  */\n+   'n_basic_blocks' for that.  Its dfs number is of course 1.  */\n \n /* Type of Basic Block aka. TBB */\n typedef unsigned int TBB;\n@@ -140,9 +140,9 @@ static void\n init_dom_info (di)\n      struct dom_info *di;\n {\n-  /* We need memory for num_basic_blocks nodes and the ENTRY_BLOCK or\n+  /* We need memory for n_basic_blocks nodes and the ENTRY_BLOCK or\n      EXIT_BLOCK.  */\n-  unsigned int num = num_basic_blocks + 2;\n+  unsigned int num = n_basic_blocks + 1 + 1;\n   init_ar (di->dfs_parent, TBB, num, 0);\n   init_ar (di->path_min, TBB, num, i);\n   init_ar (di->key, TBB, num, i);\n@@ -155,7 +155,7 @@ init_dom_info (di)\n   init_ar (di->set_size, unsigned int, num, 1);\n   init_ar (di->set_child, TBB, num, 0);\n \n-  init_ar (di->dfs_order, TBB, (unsigned int) last_basic_block + 1, 0);\n+  init_ar (di->dfs_order, TBB, (unsigned int) n_basic_blocks + 1, 0);\n   init_ar (di->dfs_to_bb, basic_block, num, 0);\n \n   di->dfsnum = 1;\n@@ -207,7 +207,7 @@ calc_dfs_tree_nonrec (di, bb, reverse)\n   /* Ending block.  */\n   basic_block ex_block;\n \n-  stack = (edge *) xmalloc ((num_basic_blocks + 3) * sizeof (edge));\n+  stack = (edge *) xmalloc ((n_basic_blocks + 3) * sizeof (edge));\n   sp = 0;\n \n   /* Initialize our border blocks, and the first edge.  */\n@@ -244,7 +244,7 @@ calc_dfs_tree_nonrec (di, bb, reverse)\n \t      /* If the next node BN is either already visited or a border\n \t         block the current edge is useless, and simply overwritten\n \t         with the next edge out of the current node.  */\n-\t      if (bn == ex_block || di->dfs_order[bn->sindex])\n+\t      if (bn == ex_block || di->dfs_order[bn->index])\n \t\t{\n \t\t  e = e->pred_next;\n \t\t  continue;\n@@ -255,7 +255,7 @@ calc_dfs_tree_nonrec (di, bb, reverse)\n \t  else\n \t    {\n \t      bn = e->dest;\n-\t      if (bn == ex_block || di->dfs_order[bn->sindex])\n+\t      if (bn == ex_block || di->dfs_order[bn->index])\n \t\t{\n \t\t  e = e->succ_next;\n \t\t  continue;\n@@ -269,10 +269,10 @@ calc_dfs_tree_nonrec (di, bb, reverse)\n \n \t  /* Fill the DFS tree info calculatable _before_ recursing.  */\n \t  if (bb != en_block)\n-\t    my_i = di->dfs_order[bb->sindex];\n+\t    my_i = di->dfs_order[bb->index];\n \t  else\n-\t    my_i = di->dfs_order[last_basic_block];\n-\t  child_i = di->dfs_order[bn->sindex] = di->dfsnum++;\n+\t    my_i = di->dfs_order[n_basic_blocks];\n+\t  child_i = di->dfs_order[bn->index] = di->dfsnum++;\n \t  di->dfs_to_bb[child_i] = bn;\n \t  di->dfs_parent[child_i] = my_i;\n \n@@ -314,7 +314,7 @@ calc_dfs_tree (di, reverse)\n {\n   /* The first block is the ENTRY_BLOCK (or EXIT_BLOCK if REVERSE).  */\n   basic_block begin = reverse ? EXIT_BLOCK_PTR : ENTRY_BLOCK_PTR;\n-  di->dfs_order[last_basic_block] = di->dfsnum;\n+  di->dfs_order[n_basic_blocks] = di->dfsnum;\n   di->dfs_to_bb[di->dfsnum] = begin;\n   di->dfsnum++;\n \n@@ -326,12 +326,13 @@ calc_dfs_tree (di, reverse)\n          They are reverse-unreachable.  In the dom-case we disallow such\n          nodes, but in post-dom we have to deal with them, so we simply\n          include them in the DFS tree which actually becomes a forest.  */\n-      basic_block b;\n-      FOR_ALL_BB_REVERSE (b)\n+      int i;\n+      for (i = n_basic_blocks - 1; i >= 0; i--)\n \t{\n-\t  if (di->dfs_order[b->sindex])\n+\t  basic_block b = BASIC_BLOCK (i);\n+\t  if (di->dfs_order[b->index])\n \t    continue;\n-\t  di->dfs_order[b->sindex] = di->dfsnum;\n+\t  di->dfs_order[b->index] = di->dfsnum;\n \t  di->dfs_to_bb[di->dfsnum] = b;\n \t  di->dfsnum++;\n \t  calc_dfs_tree_nonrec (di, b, reverse);\n@@ -341,7 +342,7 @@ calc_dfs_tree (di, reverse)\n   di->nodes = di->dfsnum - 1;\n \n   /* This aborts e.g. when there is _no_ path from ENTRY to EXIT at all.  */\n-  if (di->nodes != (unsigned int) num_basic_blocks + 1)\n+  if (di->nodes != (unsigned int) n_basic_blocks + 1)\n     abort ();\n }\n \n@@ -493,9 +494,9 @@ calc_idoms (di, reverse)\n \t      e_next = e->pred_next;\n \t    }\n \t  if (b == en_block)\n-\t    k1 = di->dfs_order[last_basic_block];\n+\t    k1 = di->dfs_order[n_basic_blocks];\n \t  else\n-\t    k1 = di->dfs_order[b->sindex];\n+\t    k1 = di->dfs_order[b->index];\n \n \t  /* Call eval() only if really needed.  If k1 is above V in DFS tree,\n \t     then we know, that eval(k1) == k1 and key[k1] == k1.  */\n@@ -541,20 +542,20 @@ idoms_to_doms (di, dominators)\n {\n   TBB i, e_index;\n   int bb, bb_idom;\n-  sbitmap_vector_zero (dominators, last_basic_block);\n+  sbitmap_vector_zero (dominators, n_basic_blocks);\n   /* We have to be careful, to not include the ENTRY_BLOCK or EXIT_BLOCK\n      in the list of (post)-doms, so remember that in e_index.  */\n-  e_index = di->dfs_order[last_basic_block];\n+  e_index = di->dfs_order[n_basic_blocks];\n \n   for (i = 1; i <= di->nodes; i++)\n     {\n       if (i == e_index)\n \tcontinue;\n-      bb = di->dfs_to_bb[i]->sindex;\n+      bb = di->dfs_to_bb[i]->index;\n \n       if (di->dom[i] && (di->dom[i] != e_index))\n \t{\n-\t  bb_idom = di->dfs_to_bb[di->dom[i]]->sindex;\n+\t  bb_idom = di->dfs_to_bb[di->dom[i]]->index;\n \t  sbitmap_copy (dominators[bb], dominators[bb_idom]);\n \t}\n       else\n@@ -576,8 +577,8 @@ idoms_to_doms (di, dominators)\n }\n \n /* The main entry point into this module.  IDOM is an integer array with room\n-   for last_basic_block integers, DOMS is a preallocated sbitmap array having\n-   room for last_basic_block^2 bits, and POST is true if the caller wants to\n+   for n_basic_blocks integers, DOMS is a preallocated sbitmap array having\n+   room for n_basic_blocks^2 bits, and POST is true if the caller wants to\n    know post-dominators.\n \n    On return IDOM[i] will be the BB->index of the immediate (post) dominator\n@@ -603,17 +604,17 @@ calculate_dominance_info (idom, doms, reverse)\n \n   if (idom)\n     {\n-      basic_block b;\n-\n-      FOR_ALL_BB (b)\n+      int i;\n+      for (i = 0; i < n_basic_blocks; i++)\n \t{\n-\t  TBB d = di.dom[di.dfs_order[b->sindex]];\n+\t  basic_block b = BASIC_BLOCK (i);\n+\t  TBB d = di.dom[di.dfs_order[b->index]];\n \n \t  /* The old code didn't modify array elements of nodes having only\n \t     itself as dominator (d==0) or only ENTRY_BLOCK (resp. EXIT_BLOCK)\n \t     (d==1).  */\n \t  if (d > 1)\n-\t    idom[b->sindex] = di.dfs_to_bb[d]->sindex;\n+\t    idom[i] = di.dfs_to_bb[d]->index;\n \t}\n     }\n   if (doms)"}, {"sha": "3e1b2232c39550644e26db86e2e14fc75c4188d2", "filename": "gcc/final.c", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Ffinal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Ffinal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffinal.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -928,8 +928,8 @@ insn_current_reference_address (branch)\n void\n compute_alignments ()\n {\n+  int i;\n   int log, max_skip, max_log;\n-  basic_block bb;\n \n   if (label_align)\n     {\n@@ -946,8 +946,9 @@ compute_alignments ()\n   if (! optimize || optimize_size)\n     return;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx label = bb->head;\n       int fallthru_frequency = 0, branch_frequency = 0, has_fallthru = 0;\n       edge e;\n@@ -977,8 +978,8 @@ compute_alignments ()\n \n       if (!has_fallthru\n \t  && (branch_frequency > BB_FREQ_MAX / 10\n-\t      || (bb->frequency > bb->prev_bb->frequency * 10\n-\t\t  && (bb->prev_bb->frequency\n+\t      || (bb->frequency > BASIC_BLOCK (i - 1)->frequency * 10\n+\t\t  && (BASIC_BLOCK (i - 1)->frequency\n \t\t      <= ENTRY_BLOCK_PTR->frequency / 2))))\n \t{\n \t  log = JUMP_ALIGN (label);\n@@ -2018,7 +2019,7 @@ final_scan_insn (insn, file, optimize, prescan, nopeepholes)\n #endif\n \t  if (flag_debug_asm)\n \t    fprintf (asm_out_file, \"\\t%s basic block %d\\n\",\n-\t\t     ASM_COMMENT_START, NOTE_BASIC_BLOCK (insn)->sindex);\n+\t\t     ASM_COMMENT_START, NOTE_BASIC_BLOCK (insn)->index);\n \t  break;\n \n \tcase NOTE_INSN_EH_REGION_BEG:"}, {"sha": "8a9a9db1a454c0cdc5c3bb7cb127701a7cc3f456", "filename": "gcc/flow.c", "status": "modified", "additions": 54, "deletions": 43, "changes": 97, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fflow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fflow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fflow.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -575,7 +575,7 @@ verify_local_live_at_start (new_live_at_start, bb)\n \t    {\n \t      fprintf (rtl_dump_file,\n \t\t       \"live_at_start mismatch in bb %d, aborting\\nNew:\\n\",\n-\t\t       bb->sindex);\n+\t\t       bb->index);\n \t      debug_bitmap_file (rtl_dump_file, new_live_at_start);\n \t      fputs (\"Old:\\n\", rtl_dump_file);\n \t      dump_bb (bb, rtl_dump_file);\n@@ -656,7 +656,6 @@ update_life_info (blocks, extent, prop_flags)\n       for ( ; ; )\n \t{\n \t  int changed = 0;\n-\t  basic_block bb;\n \n \t  calculate_global_regs_live (blocks, blocks,\n \t\t\t\tprop_flags & (PROP_SCAN_DEAD_CODE\n@@ -668,8 +667,9 @@ update_life_info (blocks, extent, prop_flags)\n \n \t  /* Removing dead code may allow the CFG to be simplified which\n \t     in turn may allow for further dead code detection / removal.  */\n-\t  FOR_ALL_BB_REVERSE (bb)\n+\t  for (i = n_basic_blocks - 1; i >= 0; --i)\n \t    {\n+\t      basic_block bb = BASIC_BLOCK (i);\n \n \t      COPY_REG_SET (tmp, bb->global_live_at_end);\n \t      changed |= propagate_block (bb, tmp, NULL, NULL,\n@@ -718,10 +718,10 @@ update_life_info (blocks, extent, prop_flags)\n     }\n   else\n     {\n-      basic_block bb;\n-\n-      FOR_ALL_BB_REVERSE (bb)\n+      for (i = n_basic_blocks - 1; i >= 0; --i)\n \t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n+\n \t  COPY_REG_SET (tmp, bb->global_live_at_end);\n \n \t  propagate_block (bb, tmp, NULL, NULL, stabilized_prop_flags);\n@@ -775,16 +775,16 @@ update_life_info_in_dirty_blocks (extent, prop_flags)\n      enum update_life_extent extent;\n      int prop_flags;\n {\n-  sbitmap update_life_blocks = sbitmap_alloc (last_basic_block);\n+  sbitmap update_life_blocks = sbitmap_alloc (n_basic_blocks);\n+  int block_num;\n   int n = 0;\n-  basic_block bb;\n   int retval = 0;\n \n   sbitmap_zero (update_life_blocks);\n-  FOR_ALL_BB (bb)\n-    if (bb->flags & BB_DIRTY)\n+  for (block_num = 0; block_num < n_basic_blocks; block_num++)\n+    if (BASIC_BLOCK (block_num)->flags & BB_DIRTY)\n       {\n-\tSET_BIT (update_life_blocks, bb->sindex);\n+\tSET_BIT (update_life_blocks, block_num);\n \tn++;\n       }\n \n@@ -810,8 +810,7 @@ free_basic_block_vars (keep_head_end_p)\n \t  clear_edges ();\n \t  VARRAY_FREE (basic_block_info);\n \t}\n-      num_basic_blocks = 0;\n-      last_basic_block = 0;\n+      n_basic_blocks = 0;\n \n       ENTRY_BLOCK_PTR->aux = NULL;\n       ENTRY_BLOCK_PTR->global_live_at_end = NULL;\n@@ -826,12 +825,14 @@ int\n delete_noop_moves (f)\n      rtx f ATTRIBUTE_UNUSED;\n {\n+  int i;\n   rtx insn, next;\n   basic_block bb;\n   int nnoops = 0;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      bb = BASIC_BLOCK (i);\n       for (insn = bb->head; insn != NEXT_INSN (bb->end); insn = next)\n \t{\n \t  next = NEXT_INSN (insn);\n@@ -1078,7 +1079,7 @@ calculate_global_regs_live (blocks_in, blocks_out, flags)\n      sbitmap blocks_in, blocks_out;\n      int flags;\n {\n-  basic_block *queue, *qhead, *qtail, *qend, bb;\n+  basic_block *queue, *qhead, *qtail, *qend;\n   regset tmp, new_live_at_end, call_used;\n   regset_head tmp_head, call_used_head;\n   regset_head new_live_at_end_head;\n@@ -1087,8 +1088,10 @@ calculate_global_regs_live (blocks_in, blocks_out, flags)\n   /* Some passes used to forget clear aux field of basic block causing\n      sick behaviour here.  */\n #ifdef ENABLE_CHECKING\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n-    if (bb->aux)\n+  if (ENTRY_BLOCK_PTR->aux || EXIT_BLOCK_PTR->aux)\n+    abort ();\n+  for (i = 0; i < n_basic_blocks; i++)\n+    if (BASIC_BLOCK (i)->aux)\n       abort ();\n #endif\n \n@@ -1104,28 +1107,31 @@ calculate_global_regs_live (blocks_in, blocks_out, flags)\n   /* Create a worklist.  Allocate an extra slot for ENTRY_BLOCK, and one\n      because the `head == tail' style test for an empty queue doesn't\n      work with a full queue.  */\n-  queue = (basic_block *) xmalloc ((num_basic_blocks + 2) * sizeof (*queue));\n+  queue = (basic_block *) xmalloc ((n_basic_blocks + 2) * sizeof (*queue));\n   qtail = queue;\n-  qhead = qend = queue + num_basic_blocks + 2;\n+  qhead = qend = queue + n_basic_blocks + 2;\n \n   /* Queue the blocks set in the initial mask.  Do this in reverse block\n      number order so that we are more likely for the first round to do\n      useful work.  We use AUX non-null to flag that the block is queued.  */\n   if (blocks_in)\n     {\n-      FOR_ALL_BB (bb)\n-\tif (TEST_BIT (blocks_in, bb->sindex))\n-\t  {\n-\t    *--qhead = bb;\n-\t    bb->aux = bb;\n-\t  }\n-\telse\n-\t  bb->aux = NULL;\n+      /* Clear out the garbage that might be hanging out in bb->aux.  */\n+      for (i = n_basic_blocks - 1; i >= 0; --i)\n+\tBASIC_BLOCK (i)->aux = NULL;\n+\n+      EXECUTE_IF_SET_IN_SBITMAP (blocks_in, 0, i,\n+\t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n+\t  *--qhead = bb;\n+\t  bb->aux = bb;\n+\t});\n     }\n   else\n     {\n-      FOR_ALL_BB (bb)\n+      for (i = 0; i < n_basic_blocks; ++i)\n \t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  *--qhead = bb;\n \t  bb->aux = bb;\n \t}\n@@ -1301,7 +1307,7 @@ calculate_global_regs_live (blocks_in, blocks_out, flags)\n       /* Let our caller know that BB changed enough to require its\n \t death notes updated.  */\n       if (blocks_out)\n-\tSET_BIT (blocks_out, bb->sindex);\n+\tSET_BIT (blocks_out, bb->index);\n \n       if (! rescan)\n \t{\n@@ -1357,15 +1363,16 @@ calculate_global_regs_live (blocks_in, blocks_out, flags)\n     {\n       EXECUTE_IF_SET_IN_SBITMAP (blocks_out, 0, i,\n \t{\n-\t  bb = BASIC_BLOCK (i);\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  FREE_REG_SET (bb->local_set);\n \t  FREE_REG_SET (bb->cond_local_set);\n \t});\n     }\n   else\n     {\n-      FOR_ALL_BB (bb)\n+      for (i = n_basic_blocks - 1; i >= 0; --i)\n \t{\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  FREE_REG_SET (bb->local_set);\n \t  FREE_REG_SET (bb->cond_local_set);\n \t}\n@@ -1491,10 +1498,12 @@ initialize_uninitialized_subregs ()\n void\n allocate_bb_life_data ()\n {\n-  basic_block bb;\n+  int i;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n+\n       bb->global_live_at_start = OBSTACK_ALLOC_REG_SET (&flow_obstack);\n       bb->global_live_at_end = OBSTACK_ALLOC_REG_SET (&flow_obstack);\n     }\n@@ -2333,14 +2342,14 @@ int\n regno_uninitialized (regno)\n      unsigned int regno;\n {\n-  if (num_basic_blocks == 0\n+  if (n_basic_blocks == 0\n       || (regno < FIRST_PSEUDO_REGISTER\n \t  && (global_regs[regno]\n \t      || fixed_regs[regno]\n \t      || FUNCTION_ARG_REGNO_P (regno))))\n     return 0;\n \n-  return REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start, regno);\n+  return REGNO_REG_SET_P (BASIC_BLOCK (0)->global_live_at_start, regno);\n }\n \n /* 1 if register REGNO was alive at a place where `setjmp' was called\n@@ -2351,11 +2360,11 @@ int\n regno_clobbered_at_setjmp (regno)\n      int regno;\n {\n-  if (num_basic_blocks == 0)\n+  if (n_basic_blocks == 0)\n     return 0;\n \n   return ((REG_N_SETS (regno) > 1\n-\t   || REGNO_REG_SET_P (ENTRY_BLOCK_PTR->next_bb->global_live_at_start, regno))\n+\t   || REGNO_REG_SET_P (BASIC_BLOCK (0)->global_live_at_start, regno))\n \t  && REGNO_REG_SET_P (regs_live_at_setjmp, regno));\n }\n \f\n@@ -2710,7 +2719,7 @@ mark_set_1 (pbi, code, reg, cond, insn, flags)\n \t\t   | PROP_DEATH_NOTES | PROP_AUTOINC))\n \t{\n \t  rtx y;\n-\t  int blocknum = pbi->bb->sindex;\n+\t  int blocknum = pbi->bb->index;\n \n \t  y = NULL_RTX;\n \t  if (flags & (PROP_LOG_LINKS | PROP_AUTOINC))\n@@ -3567,7 +3576,7 @@ mark_used_reg (pbi, reg, cond, insn)\n \t{\n \t  /* Keep track of which basic block each reg appears in.  */\n \n-\t  int blocknum = pbi->bb->sindex;\n+\t  int blocknum = pbi->bb->index;\n \t  if (REG_BASIC_BLOCK (regno_first) == REG_BLOCK_UNKNOWN)\n \t    REG_BASIC_BLOCK (regno_first) = blocknum;\n \t  else if (REG_BASIC_BLOCK (regno_first) != blocknum)\n@@ -4237,16 +4246,18 @@ count_or_remove_death_notes (blocks, kill)\n      sbitmap blocks;\n      int kill;\n {\n-  int count = 0;\n-  basic_block bb;\n+  int i, count = 0;\n \n-  FOR_ALL_BB_REVERSE (bb)\n+  for (i = n_basic_blocks - 1; i >= 0; --i)\n     {\n+      basic_block bb;\n       rtx insn;\n \n-      if (blocks && ! TEST_BIT (blocks, bb->sindex))\n+      if (blocks && ! TEST_BIT (blocks, i))\n \tcontinue;\n \n+      bb = BASIC_BLOCK (i);\n+\n       for (insn = bb->head;; insn = NEXT_INSN (insn))\n \t{\n \t  if (INSN_P (insn))"}, {"sha": "5bd70a0560f28c313b5259acd4dec599663d1ceb", "filename": "gcc/function.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -7817,7 +7817,7 @@ thread_prologue_and_epilogue_insns (f)\n \t}\n \n       /* Find the last line number note in the first block.  */\n-      for (insn = ENTRY_BLOCK_PTR->next_bb->end;\n+      for (insn = BASIC_BLOCK (0)->end;\n \t   insn != prologue_end && insn;\n \t   insn = PREV_INSN (insn))\n \tif (GET_CODE (insn) == NOTE && NOTE_LINE_NUMBER (insn) > 0)"}, {"sha": "93200536ec738ecc56a07c7d7dd5e57905935629", "filename": "gcc/gcse.c", "status": "modified", "additions": 237, "deletions": 241, "changes": 478, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fgcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fgcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgcse.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -541,7 +541,7 @@ static sbitmap *ae_kill, *ae_gen, *ae_in, *ae_out;\n struct null_pointer_info\n {\n   /* The basic block being processed.  */\n-  basic_block current_block;\n+  int current_block;\n   /* The first register to be handled in this pass.  */\n   unsigned int min_reg;\n   /* One greater than the last register to be handled in this pass.  */\n@@ -740,9 +740,9 @@ gcse_main (f, file)\n   if (file)\n     dump_flow_info (file);\n \n-  orig_bb_count = num_basic_blocks;\n+  orig_bb_count = n_basic_blocks;\n   /* Return if there's nothing to do.  */\n-  if (num_basic_blocks <= 1)\n+  if (n_basic_blocks <= 1)\n     return 0;\n \n   /* Trying to perform global optimizations on flow graphs which have\n@@ -753,23 +753,23 @@ gcse_main (f, file)\n      as blocks.  But we do not want to punish small functions which have\n      a couple switch statements.  So we require a relatively large number\n      of basic blocks and the ratio of edges to blocks to be high.  */\n-  if (num_basic_blocks > 1000 && n_edges / num_basic_blocks >= 20)\n+  if (n_basic_blocks > 1000 && n_edges / n_basic_blocks >= 20)\n     {\n       if (warn_disabled_optimization)\n \twarning (\"GCSE disabled: %d > 1000 basic blocks and %d >= 20 edges/basic block\",\n-\t\t num_basic_blocks, n_edges / num_basic_blocks);\n+\t\t n_basic_blocks, n_edges / n_basic_blocks);\n       return 0;\n     }\n \n   /* If allocating memory for the cprop bitmap would take up too much\n      storage it's better just to disable the optimization.  */\n-  if ((num_basic_blocks \n+  if ((n_basic_blocks \n        * SBITMAP_SET_SIZE (max_gcse_regno)\n        * sizeof (SBITMAP_ELT_TYPE)) > MAX_GCSE_MEMORY)\n     {\n       if (warn_disabled_optimization)\n \twarning (\"GCSE disabled: %d basic blocks and %d registers\",\n-\t\t num_basic_blocks, max_gcse_regno);\n+\t\t n_basic_blocks, max_gcse_regno);\n \n       return 0;\n     }\n@@ -834,12 +834,12 @@ gcse_main (f, file)\n \t    {\n \t      free_modify_mem_tables ();\n \t      modify_mem_list\n-\t\t= (rtx *) gmalloc (last_basic_block * sizeof (rtx));\n+\t\t= (rtx *) gmalloc (n_basic_blocks * sizeof (rtx));\n \t      canon_modify_mem_list\n-\t\t= (rtx *) gmalloc (last_basic_block * sizeof (rtx));\n-\t      memset ((char *) modify_mem_list, 0, last_basic_block * sizeof (rtx));\n-\t      memset ((char *) canon_modify_mem_list, 0, last_basic_block * sizeof (rtx));\n-\t      orig_bb_count = num_basic_blocks;\n+\t\t= (rtx *) gmalloc (n_basic_blocks * sizeof (rtx));\n+\t      memset ((char *) modify_mem_list, 0, n_basic_blocks * sizeof (rtx));\n+\t      memset ((char *) canon_modify_mem_list, 0, n_basic_blocks * sizeof (rtx));\n+\t      orig_bb_count = n_basic_blocks;\n \t    }\n \t  free_reg_set_mem ();\n \t  alloc_reg_set_mem (max_reg_num ());\n@@ -894,7 +894,7 @@ gcse_main (f, file)\n   if (file)\n     {\n       fprintf (file, \"GCSE of %s: %d basic blocks, \",\n-\t       current_function_name, num_basic_blocks);\n+\t       current_function_name, n_basic_blocks);\n       fprintf (file, \"%d pass%s, %d bytes\\n\\n\",\n \t       pass, pass > 1 ? \"es\" : \"\", max_pass_bytes);\n     }\n@@ -1019,14 +1019,14 @@ alloc_gcse_mem (f)\n   reg_set_bitmap = BITMAP_XMALLOC ();\n \n   /* Allocate vars to track sets of regs, memory per block.  */\n-  reg_set_in_block = (sbitmap *) sbitmap_vector_alloc (last_basic_block,\n+  reg_set_in_block = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks,\n \t\t\t\t\t\t       max_gcse_regno);\n   /* Allocate array to keep a list of insns which modify memory in each\n      basic block.  */\n-  modify_mem_list = (rtx *) gmalloc (last_basic_block * sizeof (rtx));\n-  canon_modify_mem_list = (rtx *) gmalloc (last_basic_block * sizeof (rtx));\n-  memset ((char *) modify_mem_list, 0, last_basic_block * sizeof (rtx));\n-  memset ((char *) canon_modify_mem_list, 0, last_basic_block * sizeof (rtx));\n+  modify_mem_list = (rtx *) gmalloc (n_basic_blocks * sizeof (rtx));\n+  canon_modify_mem_list = (rtx *) gmalloc (n_basic_blocks * sizeof (rtx));\n+  memset ((char *) modify_mem_list, 0, n_basic_blocks * sizeof (rtx));\n+  memset ((char *) canon_modify_mem_list, 0, n_basic_blocks * sizeof (rtx));\n   modify_mem_list_set = BITMAP_XMALLOC ();\n   canon_modify_mem_list_set = BITMAP_XMALLOC ();\n }\n@@ -1132,15 +1132,15 @@ compute_local_properties (transp, comp, antloc, setp)\n   if (transp)\n     {\n       if (setp)\n-\tsbitmap_vector_zero (transp, last_basic_block);\n+\tsbitmap_vector_zero (transp, n_basic_blocks);\n       else\n-\tsbitmap_vector_ones (transp, last_basic_block);\n+\tsbitmap_vector_ones (transp, n_basic_blocks);\n     }\n \n   if (comp)\n-    sbitmap_vector_zero (comp, last_basic_block);\n+    sbitmap_vector_zero (comp, n_basic_blocks);\n   if (antloc)\n-    sbitmap_vector_zero (antloc, last_basic_block);\n+    sbitmap_vector_zero (antloc, n_basic_blocks);\n \n   /* We use the same code for cprop, pre and hoisting.  For cprop\n      we care about the set hash table, for pre and hoisting we\n@@ -1292,13 +1292,13 @@ compute_sets (f)\n \n struct reg_avail_info\n {\n-  basic_block last_bb;\n+  int last_bb;\n   int first_set;\n   int last_set;\n };\n \n static struct reg_avail_info *reg_avail_info;\n-static basic_block current_bb;\n+static int current_bb;\n \n \n /* See whether X, the source of a set, is something we want to consider for\n@@ -1385,7 +1385,7 @@ oprs_unchanged_p (x, insn, avail_p)\n       }\n \n     case MEM:\n-      if (load_killed_in_block_p (current_bb, INSN_CUID (insn),\n+      if (load_killed_in_block_p (BASIC_BLOCK (current_bb), INSN_CUID (insn),\n \t\t\t\t  x, avail_p))\n \treturn 0;\n       else\n@@ -1499,7 +1499,7 @@ load_killed_in_block_p (bb, uid_limit, x, avail_p)\n      rtx x;\n      int avail_p;\n {\n-  rtx list_entry = modify_mem_list[bb->sindex];\n+  rtx list_entry = modify_mem_list[bb->index];\n   while (list_entry)\n     {\n       rtx setter;\n@@ -2373,7 +2373,7 @@ record_last_reg_set_info (insn, regno)\n     {\n       info->last_bb = current_bb;\n       info->first_set = cuid;\n-      SET_BIT (reg_set_in_block[current_bb->sindex], regno);\n+      SET_BIT (reg_set_in_block[current_bb], regno);\n     }\n }\n \n@@ -2493,7 +2493,7 @@ compute_hash_table (set_p)\n      registers are set in which blocks.\n      ??? This isn't needed during const/copy propagation, but it's cheap to\n      compute.  Later.  */\n-  sbitmap_vector_zero (reg_set_in_block, last_basic_block);\n+  sbitmap_vector_zero (reg_set_in_block, n_basic_blocks);\n \n   /* re-Cache any INSN_LIST nodes we have allocated.  */\n   clear_modify_mem_tables ();\n@@ -2502,9 +2502,9 @@ compute_hash_table (set_p)\n     gmalloc (max_gcse_regno * sizeof (struct reg_avail_info));\n \n   for (i = 0; i < max_gcse_regno; ++i)\n-    reg_avail_info[i].last_bb = NULL;\n+    reg_avail_info[i].last_bb = NEVER_SET;\n \n-  FOR_ALL_BB (current_bb)\n+  for (current_bb = 0; current_bb < n_basic_blocks; current_bb++)\n     {\n       rtx insn;\n       unsigned int regno;\n@@ -2515,8 +2515,8 @@ compute_hash_table (set_p)\n \t ??? hard-reg reg_set_in_block computation\n \t could be moved to compute_sets since they currently don't change.  */\n \n-      for (insn = current_bb->head;\n-\t   insn && insn != NEXT_INSN (current_bb->end);\n+      for (insn = BLOCK_HEAD (current_bb);\n+\t   insn && insn != NEXT_INSN (BLOCK_END (current_bb));\n \t   insn = NEXT_INSN (insn))\n \t{\n \t  if (! INSN_P (insn))\n@@ -2544,8 +2544,8 @@ compute_hash_table (set_p)\n \n       /* The next pass builds the hash table.  */\n \n-      for (insn = current_bb->head, in_libcall_block = 0;\n-\t   insn && insn != NEXT_INSN (current_bb->end);\n+      for (insn = BLOCK_HEAD (current_bb), in_libcall_block = 0;\n+\t   insn && insn != NEXT_INSN (BLOCK_END (current_bb));\n \t   insn = NEXT_INSN (insn))\n \tif (INSN_P (insn))\n \t  {\n@@ -2938,16 +2938,16 @@ alloc_rd_mem (n_blocks, n_insns)\n      int n_blocks, n_insns;\n {\n   rd_kill = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (rd_kill, last_basic_block);\n+  sbitmap_vector_zero (rd_kill, n_basic_blocks);\n \n   rd_gen = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (rd_gen, last_basic_block);\n+  sbitmap_vector_zero (rd_gen, n_basic_blocks);\n \n   reaching_defs = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (reaching_defs, last_basic_block);\n+  sbitmap_vector_zero (reaching_defs, n_basic_blocks);\n \n   rd_out = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (rd_out, last_basic_block);\n+  sbitmap_vector_zero (rd_out, n_basic_blocks);\n }\n \n /* Free reaching def variables.  */\n@@ -2973,18 +2973,17 @@ handle_rd_kill_set (insn, regno, bb)\n \n   for (this_reg = reg_set_table[regno]; this_reg; this_reg = this_reg ->next)\n     if (BLOCK_NUM (this_reg->insn) != BLOCK_NUM (insn))\n-      SET_BIT (rd_kill[bb->sindex], INSN_CUID (this_reg->insn));\n+      SET_BIT (rd_kill[bb->index], INSN_CUID (this_reg->insn));\n }\n \n /* Compute the set of kill's for reaching definitions.  */\n \n static void\n compute_kill_rd ()\n {\n-  int cuid;\n+  int bb, cuid;\n   unsigned int regno;\n   int i;\n-  basic_block bb;\n \n   /* For each block\n        For each set bit in `gen' of the block (i.e each insn which\n@@ -2994,9 +2993,9 @@ compute_kill_rd ()\n \t For each setting of regx in the linked list, which is not in\n \t     this block\n \t   Set the bit in `kill' corresponding to that insn.  */\n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     for (cuid = 0; cuid < max_cuid; cuid++)\n-      if (TEST_BIT (rd_gen[bb->sindex], cuid))\n+      if (TEST_BIT (rd_gen[bb], cuid))\n \t{\n \t  rtx insn = CUID_INSN (cuid);\n \t  rtx pat = PATTERN (insn);\n@@ -3005,7 +3004,7 @@ compute_kill_rd ()\n \t    {\n \t      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n \t\tif (TEST_HARD_REG_BIT (regs_invalidated_by_call, regno))\n-\t\t  handle_rd_kill_set (insn, regno, bb);\n+\t\t  handle_rd_kill_set (insn, regno, BASIC_BLOCK (bb));\n \t    }\n \n \t  if (GET_CODE (pat) == PARALLEL)\n@@ -3018,13 +3017,13 @@ compute_kill_rd ()\n \t\t      && GET_CODE (XEXP (XVECEXP (pat, 0, i), 0)) == REG)\n \t\t    handle_rd_kill_set (insn,\n \t\t\t\t\tREGNO (XEXP (XVECEXP (pat, 0, i), 0)),\n-\t\t\t\t\tbb);\n+\t\t\t\t\tBASIC_BLOCK (bb));\n \t\t}\n \t    }\n \t  else if (GET_CODE (pat) == SET && GET_CODE (SET_DEST (pat)) == REG)\n \t    /* Each setting of this register outside of this block\n \t       must be marked in the set of kills in this block.  */\n-\t    handle_rd_kill_set (insn, REGNO (SET_DEST (pat)), bb);\n+\t    handle_rd_kill_set (insn, REGNO (SET_DEST (pat)), BASIC_BLOCK (bb));\n \t}\n }\n \n@@ -3036,22 +3035,21 @@ compute_kill_rd ()\n static void\n compute_rd ()\n {\n-  int changed, passes;\n-  basic_block bb;\n+  int bb, changed, passes;\n \n-  FOR_ALL_BB (bb)\n-    sbitmap_copy (rd_out[bb->sindex] /*dst*/, rd_gen[bb->sindex] /*src*/);\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n+    sbitmap_copy (rd_out[bb] /*dst*/, rd_gen[bb] /*src*/);\n \n   passes = 0;\n   changed = 1;\n   while (changed)\n     {\n       changed = 0;\n-      FOR_ALL_BB (bb)\n+      for (bb = 0; bb < n_basic_blocks; bb++)\n \t{\n-\t  sbitmap_union_of_preds (reaching_defs[bb->sindex], rd_out, bb->sindex);\n-\t  changed |= sbitmap_union_of_diff_cg (rd_out[bb->sindex], rd_gen[bb->sindex],\n-\t\t\t\t\t       reaching_defs[bb->sindex], rd_kill[bb->sindex]);\n+\t  sbitmap_union_of_preds (reaching_defs[bb], rd_out, bb);\n+\t  changed |= sbitmap_union_of_diff_cg (rd_out[bb], rd_gen[bb],\n+\t\t\t\t\t       reaching_defs[bb], rd_kill[bb]);\n \t}\n       passes++;\n     }\n@@ -3069,16 +3067,16 @@ alloc_avail_expr_mem (n_blocks, n_exprs)\n      int n_blocks, n_exprs;\n {\n   ae_kill = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_kill, n_blocks);\n+  sbitmap_vector_zero (ae_kill, n_basic_blocks);\n \n   ae_gen = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_gen, n_blocks);\n+  sbitmap_vector_zero (ae_gen, n_basic_blocks);\n \n   ae_in = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_in, n_blocks);\n+  sbitmap_vector_zero (ae_in, n_basic_blocks);\n \n   ae_out = (sbitmap *) sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_out, n_blocks);\n+  sbitmap_vector_zero (ae_out, n_basic_blocks);\n }\n \n static void\n@@ -3127,7 +3125,7 @@ expr_killed_p (x, bb)\n   switch (code)\n     {\n     case REG:\n-      return TEST_BIT (reg_set_in_block[bb->sindex], REGNO (x));\n+      return TEST_BIT (reg_set_in_block[bb->index], REGNO (x));\n \n     case MEM:\n       if (load_killed_in_block_p (bb, get_max_uid () + 1, x, 0))\n@@ -3178,20 +3176,20 @@ static void\n compute_ae_kill (ae_gen, ae_kill)\n      sbitmap *ae_gen, *ae_kill;\n {\n-  basic_block bb;\n+  int bb;\n   unsigned int i;\n   struct expr *expr;\n \n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     for (i = 0; i < expr_hash_table_size; i++)\n       for (expr = expr_hash_table[i]; expr; expr = expr->next_same_hash)\n \t{\n \t  /* Skip EXPR if generated in this block.  */\n-\t  if (TEST_BIT (ae_gen[bb->sindex], expr->bitmap_index))\n+\t  if (TEST_BIT (ae_gen[bb], expr->bitmap_index))\n \t    continue;\n \n-\t  if (expr_killed_p (expr->expr, bb))\n-\t    SET_BIT (ae_kill[bb->sindex], expr->bitmap_index);\n+\t  if (expr_killed_p (expr->expr, BASIC_BLOCK (bb)))\n+\t    SET_BIT (ae_kill[bb], expr->bitmap_index);\n \t}\n }\n \f\n@@ -3227,40 +3225,40 @@ expr_reaches_here_p_work (occr, expr, bb, check_self_loop, visited)\n     {\n       basic_block pred_bb = pred->src;\n \n-      if (visited[pred_bb->sindex])\n+      if (visited[pred_bb->index])\n \t/* This predecessor has already been visited. Nothing to do.  */\n \t  ;\n       else if (pred_bb == bb)\n \t{\n \t  /* BB loops on itself.  */\n \t  if (check_self_loop\n-\t      && TEST_BIT (ae_gen[pred_bb->sindex], expr->bitmap_index)\n-\t      && BLOCK_NUM (occr->insn) == pred_bb->sindex)\n+\t      && TEST_BIT (ae_gen[pred_bb->index], expr->bitmap_index)\n+\t      && BLOCK_NUM (occr->insn) == pred_bb->index)\n \t    return 1;\n \n-\t  visited[pred_bb->sindex] = 1;\n+\t  visited[pred_bb->index] = 1;\n \t}\n \n       /* Ignore this predecessor if it kills the expression.  */\n-      else if (TEST_BIT (ae_kill[pred_bb->sindex], expr->bitmap_index))\n-\tvisited[pred_bb->sindex] = 1;\n+      else if (TEST_BIT (ae_kill[pred_bb->index], expr->bitmap_index))\n+\tvisited[pred_bb->index] = 1;\n \n       /* Does this predecessor generate this expression?  */\n-      else if (TEST_BIT (ae_gen[pred_bb->sindex], expr->bitmap_index))\n+      else if (TEST_BIT (ae_gen[pred_bb->index], expr->bitmap_index))\n \t{\n \t  /* Is this the occurrence we're looking for?\n \t     Note that there's only one generating occurrence per block\n \t     so we just need to check the block number.  */\n-\t  if (BLOCK_NUM (occr->insn) == pred_bb->sindex)\n+\t  if (BLOCK_NUM (occr->insn) == pred_bb->index)\n \t    return 1;\n \n-\t  visited[pred_bb->sindex] = 1;\n+\t  visited[pred_bb->index] = 1;\n \t}\n \n       /* Neither gen nor kill.  */\n       else\n \t{\n-\t  visited[pred_bb->sindex] = 1;\n+\t  visited[pred_bb->index] = 1;\n \t  if (expr_reaches_here_p_work (occr, expr, pred_bb, check_self_loop, \n \t      visited))\n \n@@ -3283,7 +3281,7 @@ expr_reaches_here_p (occr, expr, bb, check_self_loop)\n      int check_self_loop;\n {\n   int rval;\n-  char *visited = (char *) xcalloc (last_basic_block, 1);\n+  char *visited = (char *) xcalloc (n_basic_blocks, 1);\n \n   rval = expr_reaches_here_p_work (occr, expr, bb, check_self_loop, visited);\n   \n@@ -3607,21 +3605,20 @@ handle_avail_expr (insn, expr)\n static int\n classic_gcse ()\n {\n-  int changed;\n+  int bb, changed;\n   rtx insn;\n-  basic_block bb;\n \n   /* Note we start at block 1.  */\n \n   changed = 0;\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR->next_bb->next_bb, EXIT_BLOCK_PTR, next_bb)\n+  for (bb = 1; bb < n_basic_blocks; bb++)\n     {\n       /* Reset tables used to keep track of what's still valid [since the\n \t start of the block].  */\n       reset_opr_set_tables ();\n \n-      for (insn = bb->head;\n-\t   insn != NULL && insn != NEXT_INSN (bb->end);\n+      for (insn = BLOCK_HEAD (bb);\n+\t   insn != NULL && insn != NEXT_INSN (BLOCK_END (bb));\n \t   insn = NEXT_INSN (insn))\n \t{\n \t  /* Is insn of form (set (pseudo-reg) ...)?  */\n@@ -3639,7 +3636,7 @@ classic_gcse ()\n \t\t  && ((expr = lookup_expr (src)) != NULL)\n \t\t  /* Is the expression available [at the start of the\n \t\t     block]?  */\n-\t\t  && TEST_BIT (ae_in[bb->sindex], expr->bitmap_index)\n+\t\t  && TEST_BIT (ae_in[bb], expr->bitmap_index)\n \t\t  /* Are the operands unchanged since the start of the\n \t\t     block?  */\n \t\t  && oprs_not_set_p (src, insn))\n@@ -3670,7 +3667,7 @@ one_classic_gcse_pass (pass)\n   gcse_create_count = 0;\n \n   alloc_expr_hash_table (max_cuid);\n-  alloc_rd_mem (last_basic_block, max_cuid);\n+  alloc_rd_mem (n_basic_blocks, max_cuid);\n   compute_expr_hash_table ();\n   if (gcse_file)\n     dump_hash_table (gcse_file, \"Expression\", expr_hash_table,\n@@ -3680,7 +3677,7 @@ one_classic_gcse_pass (pass)\n     {\n       compute_kill_rd ();\n       compute_rd ();\n-      alloc_avail_expr_mem (last_basic_block, n_exprs);\n+      alloc_avail_expr_mem (n_basic_blocks, n_exprs);\n       compute_ae_gen ();\n       compute_ae_kill (ae_gen, ae_kill);\n       compute_available (ae_gen, ae_kill, ae_out, ae_in);\n@@ -3750,8 +3747,7 @@ compute_transp (x, indx, bmap, set_p)\n      sbitmap *bmap;\n      int set_p;\n {\n-  int i, j;\n-  basic_block bb;\n+  int bb, i, j;\n   enum rtx_code code;\n   reg_set *r;\n   const char *fmt;\n@@ -3771,9 +3767,9 @@ compute_transp (x, indx, bmap, set_p)\n \t{\n \t  if (REGNO (x) < FIRST_PSEUDO_REGISTER)\n \t    {\n-\t      FOR_ALL_BB (bb)\n-\t\tif (TEST_BIT (reg_set_in_block[bb->sindex], REGNO (x)))\n-\t\t  SET_BIT (bmap[bb->sindex], indx);\n+\t      for (bb = 0; bb < n_basic_blocks; bb++)\n+\t\tif (TEST_BIT (reg_set_in_block[bb], REGNO (x)))\n+\t\t  SET_BIT (bmap[bb], indx);\n \t    }\n \t  else\n \t    {\n@@ -3785,9 +3781,9 @@ compute_transp (x, indx, bmap, set_p)\n \t{\n \t  if (REGNO (x) < FIRST_PSEUDO_REGISTER)\n \t    {\n-\t      FOR_ALL_BB (bb)\n-\t\tif (TEST_BIT (reg_set_in_block[bb->sindex], REGNO (x)))\n-\t\t  RESET_BIT (bmap[bb->sindex], indx);\n+\t      for (bb = 0; bb < n_basic_blocks; bb++)\n+\t\tif (TEST_BIT (reg_set_in_block[bb], REGNO (x)))\n+\t\t  RESET_BIT (bmap[bb], indx);\n \t    }\n \t  else\n \t    {\n@@ -3799,9 +3795,9 @@ compute_transp (x, indx, bmap, set_p)\n       return;\n \n     case MEM:\n-      FOR_ALL_BB (bb)\n+      for (bb = 0; bb < n_basic_blocks; bb++)\n \t{\n-\t  rtx list_entry = canon_modify_mem_list[bb->sindex];\n+\t  rtx list_entry = canon_modify_mem_list[bb];\n \n \t  while (list_entry)\n \t    {\n@@ -3810,9 +3806,9 @@ compute_transp (x, indx, bmap, set_p)\n \t      if (GET_CODE (XEXP (list_entry, 0)) == CALL_INSN)\n \t\t{\n \t\t  if (set_p)\n-\t\t    SET_BIT (bmap[bb->sindex], indx);\n+\t\t    SET_BIT (bmap[bb], indx);\n \t\t  else\n-\t\t    RESET_BIT (bmap[bb->sindex], indx);\n+\t\t    RESET_BIT (bmap[bb], indx);\n \t\t  break;\n \t\t}\n \t      /* LIST_ENTRY must be an INSN of some kind that sets memory.\n@@ -3826,9 +3822,9 @@ compute_transp (x, indx, bmap, set_p)\n \t\t\t\t\t x, rtx_addr_varies_p))\n \t\t{\n \t\t  if (set_p)\n-\t\t    SET_BIT (bmap[bb->sindex], indx);\n+\t\t    SET_BIT (bmap[bb], indx);\n \t\t  else\n-\t\t    RESET_BIT (bmap[bb->sindex], indx);\n+\t\t    RESET_BIT (bmap[bb], indx);\n \t\t  break;\n \t\t}\n \t      list_entry = XEXP (list_entry, 1);\n@@ -4292,25 +4288,24 @@ static int\n cprop (alter_jumps)\n      int alter_jumps;\n {\n-  int changed;\n-  basic_block bb;\n+  int bb, changed;\n   rtx insn;\n \n   /* Note we start at block 1.  */\n \n   changed = 0;\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR->next_bb->next_bb, EXIT_BLOCK_PTR, next_bb)\n+  for (bb = 1; bb < n_basic_blocks; bb++)\n     {\n       /* Reset tables used to keep track of what's still valid [since the\n \t start of the block].  */\n       reset_opr_set_tables ();\n \n-      for (insn = bb->head;\n-\t   insn != NULL && insn != NEXT_INSN (bb->head);\n+      for (insn = BLOCK_HEAD (bb);\n+\t   insn != NULL && insn != NEXT_INSN (BLOCK_END (bb));\n \t   insn = NEXT_INSN (insn))\n \tif (INSN_P (insn))\n \t  {\n-\t    changed |= cprop_insn (bb, insn, alter_jumps);\n+\t    changed |= cprop_insn (BASIC_BLOCK (bb), insn, alter_jumps);\n \n \t    /* Keep track of everything modified by this insn.  */\n \t    /* ??? Need to be careful w.r.t. mods done to INSN.  Don't\n@@ -4347,7 +4342,7 @@ one_cprop_pass (pass, alter_jumps)\n \t\t     n_sets);\n   if (n_sets > 0)\n     {\n-      alloc_cprop_mem (last_basic_block, n_sets);\n+      alloc_cprop_mem (n_basic_blocks, n_sets);\n       compute_cprop_data ();\n       changed = cprop (alter_jumps);\n       free_cprop_mem ();\n@@ -4457,11 +4452,11 @@ static void\n compute_pre_data ()\n {\n   sbitmap trapping_expr;\n-  basic_block bb;\n+  int i;\n   unsigned int ui;\n \n   compute_local_properties (transp, comp, antloc, 0);\n-  sbitmap_vector_zero (ae_kill, last_basic_block);\n+  sbitmap_vector_zero (ae_kill, n_basic_blocks);\n \n   /* Collect expressions which might trap.  */\n   trapping_expr = sbitmap_alloc (n_exprs);\n@@ -4480,24 +4475,24 @@ compute_pre_data ()\n \n      This is significantly faster than compute_ae_kill.  */\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n       edge e;\n \n       /* If the current block is the destination of an abnormal edge, we\n \t kill all trapping expressions because we won't be able to properly\n \t place the instruction on the edge.  So make them neither\n \t anticipatable nor transparent.  This is fairly conservative.  */\n-      for (e = bb->pred; e ; e = e->pred_next)\n+      for (e = BASIC_BLOCK (i)->pred; e ; e = e->pred_next)\n \tif (e->flags & EDGE_ABNORMAL)\n \t  {\n-\t    sbitmap_difference (antloc[bb->sindex], antloc[bb->sindex], trapping_expr);\n-\t    sbitmap_difference (transp[bb->sindex], transp[bb->sindex], trapping_expr);\n+\t    sbitmap_difference (antloc[i], antloc[i], trapping_expr);\n+\t    sbitmap_difference (transp[i], transp[i], trapping_expr);\n \t    break;\n \t  }\n \n-      sbitmap_a_or_b (ae_kill[bb->sindex], transp[bb->sindex], comp[bb->sindex]);\n-      sbitmap_not (ae_kill[bb->sindex], ae_kill[bb->sindex]);\n+      sbitmap_a_or_b (ae_kill[i], transp[i], comp[i]);\n+      sbitmap_not (ae_kill[i], ae_kill[i]);\n     }\n \n   edge_list = pre_edge_lcm (gcse_file, n_exprs, transp, comp, antloc,\n@@ -4539,28 +4534,28 @@ pre_expr_reaches_here_p_work (occr_bb, expr, bb, visited)\n \n       if (pred->src == ENTRY_BLOCK_PTR\n \t  /* Has predecessor has already been visited?  */\n-\t  || visited[pred_bb->sindex])\n+\t  || visited[pred_bb->index])\n \t;/* Nothing to do.  */\n \n       /* Does this predecessor generate this expression?  */\n-      else if (TEST_BIT (comp[pred_bb->sindex], expr->bitmap_index))\n+      else if (TEST_BIT (comp[pred_bb->index], expr->bitmap_index))\n \t{\n \t  /* Is this the occurrence we're looking for?\n \t     Note that there's only one generating occurrence per block\n \t     so we just need to check the block number.  */\n \t  if (occr_bb == pred_bb)\n \t    return 1;\n \n-\t  visited[pred_bb->sindex] = 1;\n+\t  visited[pred_bb->index] = 1;\n \t}\n       /* Ignore this predecessor if it kills the expression.  */\n-      else if (! TEST_BIT (transp[pred_bb->sindex], expr->bitmap_index))\n-\tvisited[pred_bb->sindex] = 1;\n+      else if (! TEST_BIT (transp[pred_bb->index], expr->bitmap_index))\n+\tvisited[pred_bb->index] = 1;\n \n       /* Neither gen nor kill.  */\n       else\n \t{\n-\t  visited[pred_bb->sindex] = 1;\n+\t  visited[pred_bb->index] = 1;\n \t  if (pre_expr_reaches_here_p_work (occr_bb, expr, pred_bb, visited))\n \t    return 1;\n \t}\n@@ -4580,7 +4575,7 @@ pre_expr_reaches_here_p (occr_bb, expr, bb)\n      basic_block bb;\n {\n   int rval;\n-  char *visited = (char *) xcalloc (last_basic_block, 1);\n+  char *visited = (char *) xcalloc (n_basic_blocks, 1);\n \n   rval = pre_expr_reaches_here_p_work (occr_bb, expr, bb, visited);\n \n@@ -4658,8 +4653,8 @@ insert_insn_end_bb (expr, bb, pre)\n \t anywhere in the basic block with performing PRE optimizations.\n \t Check this.  */\n       if (GET_CODE (insn) == INSN && pre\n-\t  && !TEST_BIT (antloc[bb->sindex], expr->bitmap_index)\n-          && !TEST_BIT (transp[bb->sindex], expr->bitmap_index))\n+\t  && !TEST_BIT (antloc[bb->index], expr->bitmap_index)\n+          && !TEST_BIT (transp[bb->index], expr->bitmap_index))\n \tabort ();\n \n       /* If this is a jump table, then we can't insert stuff here.  Since\n@@ -4703,8 +4698,8 @@ insert_insn_end_bb (expr, bb, pre)\n \t Check this.  */\n \n       if (pre\n-\t  && !TEST_BIT (antloc[bb->sindex], expr->bitmap_index)\n-          && !TEST_BIT (transp[bb->sindex], expr->bitmap_index))\n+\t  && !TEST_BIT (antloc[bb->index], expr->bitmap_index)\n+          && !TEST_BIT (transp[bb->index], expr->bitmap_index))\n \tabort ();\n \n       /* Since different machines initialize their parameter registers\n@@ -4756,7 +4751,7 @@ insert_insn_end_bb (expr, bb, pre)\n   if (gcse_file)\n     {\n       fprintf (gcse_file, \"PRE/HOIST: end of bb %d, insn %d, \",\n-\t       bb->sindex, INSN_UID (new_insn));\n+\t       bb->index, INSN_UID (new_insn));\n       fprintf (gcse_file, \"copying expression %d to reg %d\\n\",\n \t       expr->bitmap_index, regno);\n     }\n@@ -4827,8 +4822,8 @@ pre_edge_insert (edge_list, index_map)\n \t\t\tif (gcse_file)\n \t\t\t  {\n \t\t\t    fprintf (gcse_file, \"PRE/HOIST: edge (%d,%d), \",\n-\t\t\t\t     bb->sindex,\n-\t\t\t\t     INDEX_EDGE_SUCC_BB (edge_list, e)->sindex);\n+\t\t\t\t     bb->index,\n+\t\t\t\t     INDEX_EDGE_SUCC_BB (edge_list, e)->index);\n \t\t\t    fprintf (gcse_file, \"copy expression %d\\n\",\n \t\t\t\t     expr->bitmap_index);\n \t\t\t  }\n@@ -4967,7 +4962,7 @@ pre_delete ()\n \t    rtx set;\n \t    basic_block bb = BLOCK_FOR_INSN (insn);\n \n-\t    if (TEST_BIT (pre_delete_map[bb->sindex], indx))\n+\t    if (TEST_BIT (pre_delete_map[bb->index], indx))\n \t      {\n \t\tset = single_set (insn);\n \t\tif (! set)\n@@ -5002,7 +4997,7 @@ pre_delete ()\n \t\t\t     \"PRE: redundant insn %d (expression %d) in \",\n \t\t\t       INSN_UID (insn), indx);\n \t\t    fprintf (gcse_file, \"bb %d, reaching reg is %d\\n\",\n-\t\t\t     bb->sindex, REGNO (expr->reaching_reg));\n+\t\t\t     bb->index, REGNO (expr->reaching_reg));\n \t\t  }\n \t      }\n \t  }\n@@ -5100,7 +5095,7 @@ one_pre_gcse_pass (pass)\n \n   if (n_exprs > 0)\n     {\n-      alloc_pre_mem (last_basic_block, n_exprs);\n+      alloc_pre_mem (n_basic_blocks, n_exprs);\n       compute_pre_data ();\n       changed |= pre_gcse ();\n       free_edge_list (edge_list);\n@@ -5184,18 +5179,18 @@ add_label_notes (x, insn)\n static void\n compute_transpout ()\n {\n-  basic_block bb;\n+  int bb;\n   unsigned int i;\n   struct expr *expr;\n \n-  sbitmap_vector_ones (transpout, last_basic_block);\n+  sbitmap_vector_ones (transpout, n_basic_blocks);\n \n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; ++bb)\n     {\n       /* Note that flow inserted a nop a the end of basic blocks that\n \t end in call instructions for reasons other than abnormal\n \t control flow.  */\n-      if (GET_CODE (bb->end) != CALL_INSN)\n+      if (GET_CODE (BLOCK_END (bb)) != CALL_INSN)\n \tcontinue;\n \n       for (i = 0; i < expr_hash_table_size; i++)\n@@ -5209,7 +5204,7 @@ compute_transpout ()\n \t      /* ??? Optimally, we would use interprocedural alias\n \t\t analysis to determine if this mem is actually killed\n \t\t by this call.  */\n-\t      RESET_BIT (transpout[bb->sindex], expr->bitmap_index);\n+\t      RESET_BIT (transpout[bb], expr->bitmap_index);\n \t    }\n     }\n }\n@@ -5242,8 +5237,8 @@ invalidate_nonnull_info (x, setter, data)\n \n   regno = REGNO (x) - npi->min_reg;\n \n-  RESET_BIT (npi->nonnull_local[npi->current_block->sindex], regno);\n-  SET_BIT (npi->nonnull_killed[npi->current_block->sindex], regno);\n+  RESET_BIT (npi->nonnull_local[npi->current_block], regno);\n+  SET_BIT (npi->nonnull_killed[npi->current_block], regno);\n }\n \n /* Do null-pointer check elimination for the registers indicated in\n@@ -5258,7 +5253,8 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n      sbitmap *nonnull_avout;\n      struct null_pointer_info *npi;\n {\n-  basic_block bb, current_block;\n+  int bb;\n+  int current_block;\n   sbitmap *nonnull_local = npi->nonnull_local;\n   sbitmap *nonnull_killed = npi->nonnull_killed;\n   \n@@ -5270,10 +5266,10 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n      Note that a register can have both properties in a single block.  That\n      indicates that it's killed, then later in the block a new value is\n      computed.  */\n-  sbitmap_vector_zero (nonnull_local, last_basic_block);\n-  sbitmap_vector_zero (nonnull_killed, last_basic_block);\n+  sbitmap_vector_zero (nonnull_local, n_basic_blocks);\n+  sbitmap_vector_zero (nonnull_killed, n_basic_blocks);\n \n-  FOR_ALL_BB (current_block)\n+  for (current_block = 0; current_block < n_basic_blocks; current_block++)\n     {\n       rtx insn, stop_insn;\n \n@@ -5282,8 +5278,8 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n \n       /* Scan each insn in the basic block looking for memory references and\n \t register sets.  */\n-      stop_insn = NEXT_INSN (current_block->end);\n-      for (insn = current_block->head;\n+      stop_insn = NEXT_INSN (BLOCK_END (current_block));\n+      for (insn = BLOCK_HEAD (current_block);\n \t   insn != stop_insn;\n \t   insn = NEXT_INSN (insn))\n \t{\n@@ -5311,7 +5307,7 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n \t      && GET_CODE ((reg = XEXP (SET_SRC (set), 0))) == REG\n \t      && REGNO (reg) >= npi->min_reg\n \t      && REGNO (reg) < npi->max_reg)\n-\t    SET_BIT (nonnull_local[current_block->sindex],\n+\t    SET_BIT (nonnull_local[current_block],\n \t\t     REGNO (reg) - npi->min_reg);\n \n \t  /* Now invalidate stuff clobbered by this insn.  */\n@@ -5324,7 +5320,7 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n \t      && GET_CODE ((reg = XEXP (SET_DEST (set), 0))) == REG\n \t      && REGNO (reg) >= npi->min_reg\n \t      && REGNO (reg) < npi->max_reg)\n-\t    SET_BIT (nonnull_local[current_block->sindex],\n+\t    SET_BIT (nonnull_local[current_block],\n \t\t     REGNO (reg) - npi->min_reg);\n \t}\n     }\n@@ -5336,17 +5332,17 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n \n   /* Now look at each bb and see if it ends with a compare of a value\n      against zero.  */\n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n-      rtx last_insn = bb->end;\n+      rtx last_insn = BLOCK_END (bb);\n       rtx condition, earliest;\n       int compare_and_branch;\n \n       /* Since MIN_REG is always at least FIRST_PSEUDO_REGISTER, and\n \t since BLOCK_REG[BB] is zero if this block did not end with a\n \t comparison against zero, this condition works.  */\n-      if (block_reg[bb->sindex] < npi->min_reg\n-\t  || block_reg[bb->sindex] >= npi->max_reg)\n+      if (block_reg[bb] < npi->min_reg\n+\t  || block_reg[bb] >= npi->max_reg)\n \tcontinue;\n \n       /* LAST_INSN is a conditional jump.  Get its condition.  */\n@@ -5357,7 +5353,7 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n \tcontinue;\n \n       /* Is the register known to have a nonzero value?  */\n-      if (!TEST_BIT (nonnull_avout[bb->sindex], block_reg[bb->sindex] - npi->min_reg))\n+      if (!TEST_BIT (nonnull_avout[bb], block_reg[bb] - npi->min_reg))\n \tcontinue;\n \n       /* Try to compute whether the compare/branch at the loop end is one or\n@@ -5385,12 +5381,12 @@ delete_null_pointer_checks_1 (block_reg, nonnull_avin,\n       delete_insn (last_insn);\n       if (compare_and_branch == 2)\n         delete_insn (earliest);\n-      purge_dead_edges (bb);\n+      purge_dead_edges (BASIC_BLOCK (bb));\n \n       /* Don't check this block again.  (Note that BLOCK_END is\n \t invalid here; we deleted the last instruction in the \n \t block.)  */\n-      block_reg[bb->sindex] = 0;\n+      block_reg[bb] = 0;\n     }\n }\n \n@@ -5424,14 +5420,14 @@ delete_null_pointer_checks (f)\n {\n   sbitmap *nonnull_avin, *nonnull_avout;\n   unsigned int *block_reg;\n-  basic_block bb;\n+  int bb;\n   int reg;\n   int regs_per_pass;\n   int max_reg;\n   struct null_pointer_info npi;\n \n   /* If we have only a single block, then there's nothing to do.  */\n-  if (num_basic_blocks <= 1)\n+  if (n_basic_blocks <= 1)\n     return;\n \n   /* Trying to perform global optimizations on flow graphs which have\n@@ -5442,27 +5438,27 @@ delete_null_pointer_checks (f)\n      as blocks.  But we do not want to punish small functions which have\n      a couple switch statements.  So we require a relatively large number\n      of basic blocks and the ratio of edges to blocks to be high.  */\n-  if (num_basic_blocks > 1000 && n_edges / num_basic_blocks >= 20)\n+  if (n_basic_blocks > 1000 && n_edges / n_basic_blocks >= 20)\n     return;\n \n   /* We need four bitmaps, each with a bit for each register in each\n      basic block.  */\n   max_reg = max_reg_num ();\n-  regs_per_pass = get_bitmap_width (4, last_basic_block, max_reg);\n+  regs_per_pass = get_bitmap_width (4, n_basic_blocks, max_reg);\n \n   /* Allocate bitmaps to hold local and global properties.  */\n-  npi.nonnull_local = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n-  npi.nonnull_killed = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n-  nonnull_avin = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n-  nonnull_avout = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n+  npi.nonnull_local = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n+  npi.nonnull_killed = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n+  nonnull_avin = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n+  nonnull_avout = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n \n   /* Go through the basic blocks, seeing whether or not each block\n      ends with a conditional branch whose condition is a comparison\n      against zero.  Record the register compared in BLOCK_REG.  */\n-  block_reg = (unsigned int *) xcalloc (last_basic_block, sizeof (int));\n-  FOR_ALL_BB (bb)\n+  block_reg = (unsigned int *) xcalloc (n_basic_blocks, sizeof (int));\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n-      rtx last_insn = bb->end;\n+      rtx last_insn = BLOCK_END (bb);\n       rtx condition, earliest, reg;\n \n       /* We only want conditional branches.  */\n@@ -5488,7 +5484,7 @@ delete_null_pointer_checks (f)\n       if (GET_CODE (reg) != REG)\n \tcontinue;\n \n-      block_reg[bb->sindex] = REGNO (reg);\n+      block_reg[bb] = REGNO (reg);\n     }\n \n   /* Go through the algorithm for each block of registers.  */\n@@ -5572,11 +5568,10 @@ free_code_hoist_mem ()\n static void\n compute_code_hoist_vbeinout ()\n {\n-  int changed, passes;\n-  basic_block bb;\n+  int bb, changed, passes;\n \n-  sbitmap_vector_zero (hoist_vbeout, last_basic_block);\n-  sbitmap_vector_zero (hoist_vbein, last_basic_block);\n+  sbitmap_vector_zero (hoist_vbeout, n_basic_blocks);\n+  sbitmap_vector_zero (hoist_vbein, n_basic_blocks);\n \n   passes = 0;\n   changed = 1;\n@@ -5587,12 +5582,12 @@ compute_code_hoist_vbeinout ()\n \n       /* We scan the blocks in the reverse order to speed up\n \t the convergence.  */\n-      FOR_ALL_BB_REVERSE (bb)\n+      for (bb = n_basic_blocks - 1; bb >= 0; bb--)\n \t{\n-\t  changed |= sbitmap_a_or_b_and_c_cg (hoist_vbein[bb->sindex], antloc[bb->sindex],\n-\t\t\t\t\t      hoist_vbeout[bb->sindex], transp[bb->sindex]);\n-\t  if (bb->next_bb != EXIT_BLOCK_PTR)\n-\t    sbitmap_intersection_of_succs (hoist_vbeout[bb->sindex], hoist_vbein, bb->sindex);\n+\t  changed |= sbitmap_a_or_b_and_c_cg (hoist_vbein[bb], antloc[bb],\n+\t\t\t\t\t      hoist_vbeout[bb], transp[bb]);\n+\t  if (bb != n_basic_blocks - 1)\n+\t    sbitmap_intersection_of_succs (hoist_vbeout[bb], hoist_vbein, bb);\n \t}\n \n       passes++;\n@@ -5642,7 +5637,7 @@ hoist_expr_reaches_here_p (expr_bb, expr_index, bb, visited)\n   if (visited == NULL)\n     {\n       visited_allocated_locally = 1;\n-      visited = xcalloc (last_basic_block, 1);\n+      visited = xcalloc (n_basic_blocks, 1);\n     }\n \n   for (pred = bb->pred; pred != NULL; pred = pred->pred_next)\n@@ -5651,19 +5646,19 @@ hoist_expr_reaches_here_p (expr_bb, expr_index, bb, visited)\n \n       if (pred->src == ENTRY_BLOCK_PTR)\n \tbreak;\n-      else if (visited[pred_bb->sindex])\n+      else if (visited[pred_bb->index])\n \tcontinue;\n \n       /* Does this predecessor generate this expression?  */\n-      else if (TEST_BIT (comp[pred_bb->sindex], expr_index))\n+      else if (TEST_BIT (comp[pred_bb->index], expr_index))\n \tbreak;\n-      else if (! TEST_BIT (transp[pred_bb->sindex], expr_index))\n+      else if (! TEST_BIT (transp[pred_bb->index], expr_index))\n \tbreak;\n \n       /* Not killed.  */\n       else\n \t{\n-\t  visited[pred_bb->sindex] = 1;\n+\t  visited[pred_bb->index] = 1;\n \t  if (! hoist_expr_reaches_here_p (expr_bb, expr_index,\n \t\t\t\t\t   pred_bb, visited))\n \t    break;\n@@ -5680,12 +5675,12 @@ hoist_expr_reaches_here_p (expr_bb, expr_index, bb, visited)\n static void\n hoist_code ()\n {\n-  basic_block bb, dominated;\n+  int bb, dominated;\n   unsigned int i;\n   struct expr **index_map;\n   struct expr *expr;\n \n-  sbitmap_vector_zero (hoist_exprs, last_basic_block);\n+  sbitmap_vector_zero (hoist_exprs, n_basic_blocks);\n \n   /* Compute a mapping from expression number (`bitmap_index') to\n      hash table entry.  */\n@@ -5697,42 +5692,42 @@ hoist_code ()\n \n   /* Walk over each basic block looking for potentially hoistable\n      expressions, nothing gets hoisted from the entry block.  */\n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n       int found = 0;\n       int insn_inserted_p;\n \n       /* Examine each expression that is very busy at the exit of this\n \t block.  These are the potentially hoistable expressions.  */\n-      for (i = 0; i < hoist_vbeout[bb->sindex]->n_bits; i++)\n+      for (i = 0; i < hoist_vbeout[bb]->n_bits; i++)\n \t{\n \t  int hoistable = 0;\n \n-\t  if (TEST_BIT (hoist_vbeout[bb->sindex], i)\n-\t      && TEST_BIT (transpout[bb->sindex], i))\n+\t  if (TEST_BIT (hoist_vbeout[bb], i) && TEST_BIT (transpout[bb], i))\n \t    {\n \t      /* We've found a potentially hoistable expression, now\n \t\t we look at every block BB dominates to see if it\n \t\t computes the expression.  */\n-\t      FOR_ALL_BB (dominated)\n+\t      for (dominated = 0; dominated < n_basic_blocks; dominated++)\n \t\t{\n \t\t  /* Ignore self dominance.  */\n \t\t  if (bb == dominated\n-\t\t      || ! TEST_BIT (dominators[dominated->sindex], bb->sindex))\n+\t\t      || ! TEST_BIT (dominators[dominated], bb))\n \t\t    continue;\n \n \t\t  /* We've found a dominated block, now see if it computes\n \t\t     the busy expression and whether or not moving that\n \t\t     expression to the \"beginning\" of that block is safe.  */\n-\t\t  if (!TEST_BIT (antloc[dominated->sindex], i))\n+\t\t  if (!TEST_BIT (antloc[dominated], i))\n \t\t    continue;\n \n \t\t  /* Note if the expression would reach the dominated block\n \t\t     unimpared if it was placed at the end of BB. \n \n \t\t     Keep track of how many times this expression is hoistable\n \t\t     from a dominated block into BB.  */\n-\t\t  if (hoist_expr_reaches_here_p (bb, i, dominated, NULL))\n+\t\t  if (hoist_expr_reaches_here_p (BASIC_BLOCK (bb), i, \n+\t\t\t\t\t\t BASIC_BLOCK (dominated), NULL))\n \t\t    hoistable++;\n \t\t}\n \n@@ -5748,7 +5743,7 @@ hoist_code ()\n \t\t to nullify any benefit we get from code hoisting.  */\n \t      if (hoistable > 1)\n \t\t{\n-\t\t  SET_BIT (hoist_exprs[bb->sindex], i);\n+\t\t  SET_BIT (hoist_exprs[bb], i);\n \t\t  found = 1;\n \t\t}\n \t    }\n@@ -5759,45 +5754,46 @@ hoist_code ()\n \tcontinue;\n \n       /* Loop over all the hoistable expressions.  */\n-      for (i = 0; i < hoist_exprs[bb->sindex]->n_bits; i++)\n+      for (i = 0; i < hoist_exprs[bb]->n_bits; i++)\n \t{\n \t  /* We want to insert the expression into BB only once, so\n \t     note when we've inserted it.  */\n \t  insn_inserted_p = 0;\n \n \t  /* These tests should be the same as the tests above.  */\n-\t  if (TEST_BIT (hoist_vbeout[bb->sindex], i))\n+\t  if (TEST_BIT (hoist_vbeout[bb], i))\n \t    {\n \t      /* We've found a potentially hoistable expression, now\n \t\t we look at every block BB dominates to see if it\n \t\t computes the expression.  */\n-\t      FOR_ALL_BB (dominated)\n+\t      for (dominated = 0; dominated < n_basic_blocks; dominated++)\n \t\t{\n \t\t  /* Ignore self dominance.  */\n \t\t  if (bb == dominated\n-\t\t      || ! TEST_BIT (dominators[dominated->sindex], bb->sindex))\n+\t\t      || ! TEST_BIT (dominators[dominated], bb))\n \t\t    continue;\n \n \t\t  /* We've found a dominated block, now see if it computes\n \t\t     the busy expression and whether or not moving that\n \t\t     expression to the \"beginning\" of that block is safe.  */\n-\t\t  if (!TEST_BIT (antloc[dominated->sindex], i))\n+\t\t  if (!TEST_BIT (antloc[dominated], i))\n \t\t    continue;\n \n \t\t  /* The expression is computed in the dominated block and\n \t\t     it would be safe to compute it at the start of the\n \t\t     dominated block.  Now we have to determine if the\n \t\t     expression would reach the dominated block if it was\n \t\t     placed at the end of BB.  */\n-\t\t  if (hoist_expr_reaches_here_p (bb, i, dominated, NULL))\n+\t\t  if (hoist_expr_reaches_here_p (BASIC_BLOCK (bb), i, \n+\t\t\t\t\t\t BASIC_BLOCK (dominated), NULL))\n \t\t    {\n \t\t      struct expr *expr = index_map[i];\n \t\t      struct occr *occr = expr->antic_occr;\n \t\t      rtx insn;\n \t\t      rtx set;\n \n \t\t      /* Find the right occurrence of this expression.  */\n-\t\t      while (BLOCK_FOR_INSN (occr->insn) != dominated && occr)\n+\t\t      while (BLOCK_NUM (occr->insn) != dominated && occr)\n \t\t\toccr = occr->next;\n \n \t\t      /* Should never happen.  */\n@@ -5831,7 +5827,8 @@ hoist_code ()\n \t\t\t  occr->deleted_p = 1;\n \t\t\t  if (!insn_inserted_p)\n \t\t\t    {\n-\t\t\t      insert_insn_end_bb (index_map[i], bb, 0);\n+\t\t\t      insert_insn_end_bb (index_map[i], \n+\t\t\t\t\t\t  BASIC_BLOCK (bb), 0);\n \t\t\t      insn_inserted_p = 1;\n \t\t\t    }\n \t\t\t}\n@@ -5861,7 +5858,7 @@ one_code_hoisting_pass ()\n \n   if (n_exprs > 0)\n     {\n-      alloc_code_hoist_mem (last_basic_block, n_exprs);\n+      alloc_code_hoist_mem (n_basic_blocks, n_exprs);\n       compute_code_hoist_data ();\n       hoist_code ();\n       free_code_hoist_mem ();\n@@ -6111,15 +6108,15 @@ static void\n compute_ld_motion_mems ()\n {\n   struct ls_expr * ptr;\n-  basic_block bb;\n+  int bb;\n   rtx insn;\n   \n   pre_ldst_mems = NULL;\n \n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n-      for (insn = bb->head;\n-\t   insn && insn != NEXT_INSN (bb->end);\n+      for (insn = BLOCK_HEAD (bb);\n+\t   insn && insn != NEXT_INSN (BLOCK_END (bb));\n \t   insn = NEXT_INSN (insn))\n \t{\n \t  if (GET_RTX_CLASS (GET_CODE (insn)) == 'i')\n@@ -6337,7 +6334,7 @@ store_ops_ok (x, bb)\n     case REG:\n \t/* If a reg has changed after us in this\n \t   block, the operand has been killed.  */\n-\treturn TEST_BIT (reg_set_in_block[bb->sindex], REGNO (x));\n+\treturn TEST_BIT (reg_set_in_block[bb->index], REGNO (x));\n \n     case MEM:\n       x = XEXP (x, 0);\n@@ -6436,24 +6433,23 @@ find_moveable_store (insn)\n static int\n compute_store_table ()\n {\n-  int ret;\n-  basic_block bb;\n+  int bb, ret;\n   unsigned regno;\n   rtx insn, pat;\n \n   max_gcse_regno = max_reg_num ();\n \n-  reg_set_in_block = (sbitmap *) sbitmap_vector_alloc (last_basic_block,\n+  reg_set_in_block = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks,\n \t\t\t\t\t\t       max_gcse_regno);\n-  sbitmap_vector_zero (reg_set_in_block, last_basic_block);\n+  sbitmap_vector_zero (reg_set_in_block, n_basic_blocks);\n   pre_ldst_mems = 0;\n \n   /* Find all the stores we care about.  */\n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n-      regvec = & (reg_set_in_block[bb->sindex]);\n-      for (insn = bb->end;\n-\t   insn && insn != PREV_INSN (bb->end);\n+      regvec = & (reg_set_in_block[bb]);\n+      for (insn = BLOCK_END (bb);\n+\t   insn && insn != PREV_INSN (BLOCK_HEAD (bb));\n \t   insn = PREV_INSN (insn))\n \t{\n \t  /* Ignore anything that is not a normal insn.  */\n@@ -6472,7 +6468,7 @@ compute_store_table ()\n \t      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n \t\tif (clobbers_all\n \t\t    || TEST_HARD_REG_BIT (regs_invalidated_by_call, regno))\n-\t\t  SET_BIT (reg_set_in_block[bb->sindex], regno);\n+\t\t  SET_BIT (reg_set_in_block[bb], regno);\n \t    }\n \t  \n \t  pat = PATTERN (insn);\n@@ -6638,17 +6634,18 @@ store_killed_before (x, insn, bb)\n static void\n build_store_vectors () \n {\n-  basic_block bb, b;\n+  basic_block bb;\n+  int b;\n   rtx insn, st;\n   struct ls_expr * ptr;\n \n   /* Build the gen_vector. This is any store in the table which is not killed\n      by aliasing later in its block.  */\n-  ae_gen = (sbitmap *) sbitmap_vector_alloc (last_basic_block, num_stores);\n-  sbitmap_vector_zero (ae_gen, last_basic_block);\n+  ae_gen = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks, num_stores);\n+  sbitmap_vector_zero (ae_gen, n_basic_blocks);\n \n-  st_antloc = (sbitmap *) sbitmap_vector_alloc (last_basic_block, num_stores);\n-  sbitmap_vector_zero (st_antloc, last_basic_block);\n+  st_antloc = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks, num_stores);\n+  sbitmap_vector_zero (st_antloc, n_basic_blocks);\n \n   for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n     { \n@@ -6669,7 +6666,7 @@ build_store_vectors ()\n \t\t the block), and replace it with this one). We'll copy the\n \t\t old SRC expression to an unused register in case there\n \t\t are any side effects.  */\n-\t      if (TEST_BIT (ae_gen[bb->sindex], ptr->index))\n+\t      if (TEST_BIT (ae_gen[bb->index], ptr->index))\n \t\t{\n \t\t  /* Find previous store.  */\n \t\t  rtx st;\n@@ -6686,7 +6683,7 @@ build_store_vectors ()\n \t\t      continue;\n \t\t    }\n \t\t}\n-\t      SET_BIT (ae_gen[bb->sindex], ptr->index);\n+\t      SET_BIT (ae_gen[bb->index], ptr->index);\n \t      AVAIL_STORE_LIST (ptr) = alloc_INSN_LIST (insn,\n \t\t\t\t\t\t\tAVAIL_STORE_LIST (ptr));\n \t    }\n@@ -6703,16 +6700,16 @@ build_store_vectors ()\n       free_INSN_LIST_list (&store_list);\n     }\n \t  \n-  ae_kill = (sbitmap *) sbitmap_vector_alloc (last_basic_block, num_stores);\n-  sbitmap_vector_zero (ae_kill, last_basic_block);\n+  ae_kill = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks, num_stores);\n+  sbitmap_vector_zero (ae_kill, n_basic_blocks);\n \n-  transp = (sbitmap *) sbitmap_vector_alloc (last_basic_block, num_stores);\n-  sbitmap_vector_zero (transp, last_basic_block);\n+  transp = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks, num_stores);\n+  sbitmap_vector_zero (transp, n_basic_blocks);\n \n   for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n-    FOR_ALL_BB (b)\n+    for (b = 0; b < n_basic_blocks; b++)\n       {\n-\tif (store_killed_after (ptr->pattern, b->head, b))\n+\tif (store_killed_after (ptr->pattern, BLOCK_HEAD (b), BASIC_BLOCK (b)))\n \t  {\n \t    /* The anticipatable expression is not killed if it's gen'd.  */\n \t    /*\n@@ -6730,10 +6727,10 @@ build_store_vectors ()\n \t      If we always kill it in this case, we'll sometimes do\n \t      uneccessary work, but it shouldn't actually hurt anything.\n \t    if (!TEST_BIT (ae_gen[b], ptr->index)).  */\n-\t    SET_BIT (ae_kill[b->sindex], ptr->index);\n+\t    SET_BIT (ae_kill[b], ptr->index);\n \t  }\n \telse\n-\t  SET_BIT (transp[b->sindex], ptr->index);\n+\t  SET_BIT (transp[b], ptr->index);\n       }\n \n   /* Any block with no exits calls some non-returning function, so\n@@ -6744,10 +6741,10 @@ build_store_vectors ()\n     {\n       fprintf (gcse_file, \"ST_avail and ST_antic (shown under loads..)\\n\");\n       print_ldst_list (gcse_file);\n-      dump_sbitmap_vector (gcse_file, \"st_antloc\", \"\", st_antloc, last_basic_block);\n-      dump_sbitmap_vector (gcse_file, \"st_kill\", \"\", ae_kill, last_basic_block);\n-      dump_sbitmap_vector (gcse_file, \"Transpt\", \"\", transp, last_basic_block);\n-      dump_sbitmap_vector (gcse_file, \"st_avloc\", \"\", ae_gen, last_basic_block);\n+      dump_sbitmap_vector (gcse_file, \"st_antloc\", \"\", st_antloc, n_basic_blocks);\n+      dump_sbitmap_vector (gcse_file, \"st_kill\", \"\", ae_kill, n_basic_blocks);\n+      dump_sbitmap_vector (gcse_file, \"Transpt\", \"\", transp, n_basic_blocks);\n+      dump_sbitmap_vector (gcse_file, \"st_avloc\", \"\", ae_gen, n_basic_blocks);\n     }\n }\n \n@@ -6779,7 +6776,7 @@ insert_insn_start_bb (insn, bb)\n   if (gcse_file)\n     {\n       fprintf (gcse_file, \"STORE_MOTION  insert store at start of BB %d:\\n\",\n-\t       bb->sindex);\n+\t       bb->index);\n       print_inline_rtx (gcse_file, insn, 6);\n       fprintf (gcse_file, \"\\n\");\n     }\n@@ -6845,7 +6842,7 @@ insert_store (expr, e)\n   if (gcse_file)\n     {\n       fprintf (gcse_file, \"STORE_MOTION  insert insn on edge (%d, %d):\\n\",\n-\t       e->src->sindex, e->dest->sindex);\n+\t       e->src->index, e->dest->index);\n       print_inline_rtx (gcse_file, insn, 6);\n       fprintf (gcse_file, \"\\n\");\n     }\n@@ -6868,7 +6865,7 @@ replace_store_insn (reg, del, bb)\n   if (gcse_file)\n     {\n       fprintf (gcse_file, \n-\t       \"STORE_MOTION  delete insn in BB %d:\\n      \", bb->sindex);\n+\t       \"STORE_MOTION  delete insn in BB %d:\\n      \", bb->index);\n       print_inline_rtx (gcse_file, del, 6);\n       fprintf (gcse_file, \"\\nSTORE MOTION  replaced with insn:\\n      \");\n       print_inline_rtx (gcse_file, insn, 6);\n@@ -6942,8 +6939,7 @@ free_store_memory ()\n static void\n store_motion ()\n {\n-  basic_block x;\n-  int y;\n+  int x;\n   struct ls_expr * ptr;\n   int update_flow = 0;\n \n@@ -6976,13 +6972,13 @@ store_motion ()\n   /* Now we want to insert the new stores which are going to be needed.  */\n   for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n     {\n-      FOR_ALL_BB (x)\n-\tif (TEST_BIT (pre_delete_map[x->sindex], ptr->index))\n-\t  delete_store (ptr, x);\n+      for (x = 0; x < n_basic_blocks; x++)\n+\tif (TEST_BIT (pre_delete_map[x], ptr->index))\n+\t  delete_store (ptr, BASIC_BLOCK (x));\n \n-      for (y = 0; y < NUM_EDGES (edge_list); y++)\n-\tif (TEST_BIT (pre_insert_map[y], ptr->index))\n-\t  update_flow |= insert_store (ptr, INDEX_EDGE (edge_list, y));\n+      for (x = 0; x < NUM_EDGES (edge_list); x++)\n+\tif (TEST_BIT (pre_insert_map[x], ptr->index))\n+\t  update_flow |= insert_store (ptr, INDEX_EDGE (edge_list, x));\n     }\n \n   if (update_flow)"}, {"sha": "0d9618c27b72c73337ce91ace05b7ea407012896", "filename": "gcc/global.c", "status": "modified", "additions": 17, "deletions": 18, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fglobal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fglobal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fglobal.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -583,7 +583,7 @@ global_alloc (file)\n \n #if 0 /* We need to eliminate regs even if there is no rtl code,\n \t for the sake of debugging information.  */\n-  if (num_basic_blocks > 0)\n+  if (n_basic_blocks > 0)\n #endif\n     {\n       build_insn_chain (get_insns ());\n@@ -636,8 +636,7 @@ allocno_compare (v1p, v2p)\n static void\n global_conflicts ()\n {\n-  int i;\n-  basic_block b;\n+  int b, i;\n   rtx insn;\n   int *block_start_allocnos;\n \n@@ -646,7 +645,7 @@ global_conflicts ()\n \n   block_start_allocnos = (int *) xmalloc (max_allocno * sizeof (int));\n \n-  FOR_ALL_BB (b)\n+  for (b = 0; b < n_basic_blocks; b++)\n     {\n       memset ((char *) allocnos_live, 0, allocno_row_words * sizeof (INT_TYPE));\n \n@@ -665,7 +664,7 @@ global_conflicts ()\n \t are explicitly marked in basic_block_live_at_start.  */\n \n       {\n-\tregset old = b->global_live_at_start;\n+\tregset old = BASIC_BLOCK (b)->global_live_at_start;\n \tint ax = 0;\n \n \tREG_SET_TO_HARD_REG_SET (hard_regs_live, old);\n@@ -714,7 +713,7 @@ global_conflicts ()\n \t     that is reached by an abnormal edge.  */\n \n \t  edge e;\n-\t  for (e = b->pred; e ; e = e->pred_next)\n+\t  for (e = BASIC_BLOCK (b)->pred; e ; e = e->pred_next)\n \t    if (e->flags & EDGE_ABNORMAL)\n \t      break;\n \t  if (e != NULL)\n@@ -724,7 +723,7 @@ global_conflicts ()\n #endif\n       }\n \n-      insn = b->head;\n+      insn = BLOCK_HEAD (b);\n \n       /* Scan the code of this basic block, noting which allocnos\n \t and hard regs are born or die.  When one is born,\n@@ -824,7 +823,7 @@ global_conflicts ()\n \t\t}\n \t    }\n \n-\t  if (insn == b->end)\n+\t  if (insn == BLOCK_END (b))\n \t    break;\n \t  insn = NEXT_INSN (insn);\n \t}\n@@ -1709,11 +1708,11 @@ void\n mark_elimination (from, to)\n      int from, to;\n {\n-  basic_block bb;\n+  int i;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n-      regset r = bb->global_live_at_start; \n+      regset r = BASIC_BLOCK (i)->global_live_at_start; \n       if (REGNO_REG_SET_P (r, from))\n \t{\n \t  CLEAR_REGNO_REG_SET (r, from);\n@@ -1795,7 +1794,7 @@ build_insn_chain (first)\n {\n   struct insn_chain **p = &reload_insn_chain;\n   struct insn_chain *prev = 0;\n-  basic_block b = ENTRY_BLOCK_PTR->next_bb;\n+  int b = 0;\n   regset_head live_relevant_regs_head;\n \n   live_relevant_regs = INITIALIZE_REG_SET (live_relevant_regs_head);\n@@ -1804,14 +1803,14 @@ build_insn_chain (first)\n     {\n       struct insn_chain *c;\n \n-      if (first == b->head)\n+      if (first == BLOCK_HEAD (b))\n \t{\n \t  int i;\n \n \t  CLEAR_REG_SET (live_relevant_regs);\n \n \t  EXECUTE_IF_SET_IN_BITMAP\n-\t    (b->global_live_at_start, 0, i,\n+\t    (BASIC_BLOCK (b)->global_live_at_start, 0, i,\n \t     {\n \t       if (i < FIRST_PSEUDO_REGISTER\n \t\t   ? ! TEST_HARD_REG_BIT (eliminable_regset, i)\n@@ -1828,7 +1827,7 @@ build_insn_chain (first)\n \t  *p = c;\n \t  p = &c->next;\n \t  c->insn = first;\n-\t  c->block = b->sindex;\n+\t  c->block = b;\n \n \t  if (INSN_P (first))\n \t    {\n@@ -1866,16 +1865,16 @@ build_insn_chain (first)\n \t    }\n \t}\n \n-      if (first == b->end)\n-\tb = b->next_bb;\n+      if (first == BLOCK_END (b))\n+\tb++;\n \n       /* Stop after we pass the end of the last basic block.  Verify that\n \t no real insns are after the end of the last basic block.\n \n \t We may want to reorganize the loop somewhat since this test should\n \t always be the right exit test.  Allow an ADDR_VEC or ADDR_DIF_VEC if\n \t the previous real insn is a JUMP_INSN.  */\n-      if (b == EXIT_BLOCK_PTR)\n+      if (b == n_basic_blocks)\n \t{\n \t  for (first = NEXT_INSN (first) ; first; first = NEXT_INSN (first))\n \t    if (INSN_P (first)"}, {"sha": "87230479bb4e839ed4c82fbb83695d226b50bfad", "filename": "gcc/graph.c", "status": "modified", "additions": 13, "deletions": 12, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fgraph.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fgraph.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgraph.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -258,26 +258,27 @@ print_rtl_graph_with_bb (base, suffix, rtx_first)\n     fprintf (fp, \"(nil)\\n\");\n   else\n     {\n+      int i;\n       enum bb_state { NOT_IN_BB, IN_ONE_BB, IN_MULTIPLE_BB };\n       int max_uid = get_max_uid ();\n       int *start = (int *) xmalloc (max_uid * sizeof (int));\n       int *end = (int *) xmalloc (max_uid * sizeof (int));\n       enum bb_state *in_bb_p = (enum bb_state *)\n \txmalloc (max_uid * sizeof (enum bb_state));\n       basic_block bb;\n-      int j;\n \n-      for (j = 0; j < max_uid; ++j)\n+      for (i = 0; i < max_uid; ++i)\n \t{\n-\t  start[j] = end[j] = -1;\n-\t  in_bb_p[j] = NOT_IN_BB;\n+\t  start[i] = end[i] = -1;\n+\t  in_bb_p[i] = NOT_IN_BB;\n \t}\n \n-      FOR_ALL_BB_REVERSE (bb)\n+      for (i = n_basic_blocks - 1; i >= 0; --i)\n \t{\n \t  rtx x;\n-\t  start[INSN_UID (bb->head)] = bb->sindex;\n-\t  end[INSN_UID (bb->end)] = bb->sindex;\n+\t  bb = BASIC_BLOCK (i);\n+\t  start[INSN_UID (bb->head)] = i;\n+\t  end[INSN_UID (bb->end)] = i;\n \t  for (x = bb->head; x != NULL_RTX; x = NEXT_INSN (x))\n \t    {\n \t      in_bb_p[INSN_UID (x)]\n@@ -309,24 +310,24 @@ print_rtl_graph_with_bb (base, suffix, rtx_first)\n \t\tcontinue;\n \t    }\n \n-\t  if ((j = start[INSN_UID (tmp_rtx)]) >= 0)\n+\t  if ((i = start[INSN_UID (tmp_rtx)]) >= 0)\n \t    {\n \t      /* We start a subgraph for each basic block.  */\n-\t      start_bb (fp, j);\n+\t      start_bb (fp, i);\n \n-\t      if (j == 0)\n+\t      if (i == 0)\n \t\tdraw_edge (fp, 0, INSN_UID (tmp_rtx), 1, 0);\n \t    }\n \n \t  /* Print the data for this node.  */\n \t  node_data (fp, tmp_rtx);\n \t  next_insn = next_nonnote_insn (tmp_rtx);\n \n-\t  if ((j = end[INSN_UID (tmp_rtx)]) >= 0)\n+\t  if ((i = end[INSN_UID (tmp_rtx)]) >= 0)\n \t    {\n \t      edge e;\n \n-\t      bb = BASIC_BLOCK (j);\n+\t      bb = BASIC_BLOCK (i);\n \n \t      /* End of the basic block.  */\n \t      end_bb (fp);"}, {"sha": "6b3e3162e084cdac9549022a9e09185dba25d914", "filename": "gcc/haifa-sched.c", "status": "modified", "additions": 15, "deletions": 16, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fhaifa-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fhaifa-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhaifa-sched.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -2303,8 +2303,7 @@ void\n sched_init (dump_file)\n      FILE *dump_file;\n {\n-  int luid;\n-  basic_block b;\n+  int luid, b;\n   rtx insn;\n   int i;\n \n@@ -2357,8 +2356,8 @@ sched_init (dump_file)\n \n   h_i_d[0].luid = 0;\n   luid = 1;\n-  FOR_ALL_BB (b)\n-    for (insn = b->head;; insn = NEXT_INSN (insn))\n+  for (b = 0; b < n_basic_blocks; b++)\n+    for (insn = BLOCK_HEAD (b);; insn = NEXT_INSN (insn))\n       {\n \tINSN_LUID (insn) = luid;\n \n@@ -2370,7 +2369,7 @@ sched_init (dump_file)\n \tif (GET_CODE (insn) != NOTE)\n \t  ++luid;\n \n-\tif (insn == b->end)\n+\tif (insn == BLOCK_END (b))\n \t  break;\n       }\n \n@@ -2384,30 +2383,30 @@ sched_init (dump_file)\n     {\n       rtx line;\n \n-      line_note_head = (rtx *) xcalloc (last_basic_block, sizeof (rtx));\n+      line_note_head = (rtx *) xcalloc (n_basic_blocks, sizeof (rtx));\n \n       /* Save-line-note-head:\n          Determine the line-number at the start of each basic block.\n          This must be computed and saved now, because after a basic block's\n          predecessor has been scheduled, it is impossible to accurately\n          determine the correct line number for the first insn of the block.  */\n \n-      FOR_ALL_BB (b)\n+      for (b = 0; b < n_basic_blocks; b++)\n \t{\n-\t  for (line = b->head; line; line = PREV_INSN (line))\n+\t  for (line = BLOCK_HEAD (b); line; line = PREV_INSN (line))\n \t    if (GET_CODE (line) == NOTE && NOTE_LINE_NUMBER (line) > 0)\n \t      {\n-\t\tline_note_head[b->sindex] = line;\n+\t\tline_note_head[b] = line;\n \t\tbreak;\n \t      }\n \t  /* Do a forward search as well, since we won't get to see the first\n \t     notes in a basic block.  */\n-\t  for (line = b->head; line; line = NEXT_INSN (line))\n+\t  for (line = BLOCK_HEAD (b); line; line = NEXT_INSN (line))\n \t    {\n \t      if (INSN_P (line))\n \t\tbreak;\n \t      if (GET_CODE (line) == NOTE && NOTE_LINE_NUMBER (line) > 0)\n-\t\tline_note_head[b->sindex] = line;\n+\t\tline_note_head[b] = line;\n \t    }\n \t}\n     }\n@@ -2421,22 +2420,22 @@ sched_init (dump_file)\n   /* ??? Add a NOTE after the last insn of the last basic block.  It is not\n      known why this is done.  */\n \n-  insn = EXIT_BLOCK_PTR->prev_bb->end;\n+  insn = BLOCK_END (n_basic_blocks - 1);\n   if (NEXT_INSN (insn) == 0\n       || (GET_CODE (insn) != NOTE\n \t  && GET_CODE (insn) != CODE_LABEL\n \t  /* Don't emit a NOTE if it would end up before a BARRIER.  */\n \t  && GET_CODE (NEXT_INSN (insn)) != BARRIER))\n     {\n-      emit_note_after (NOTE_INSN_DELETED, EXIT_BLOCK_PTR->prev_bb->end);\n+      emit_note_after (NOTE_INSN_DELETED, BLOCK_END (n_basic_blocks - 1));\n       /* Make insn to appear outside BB.  */\n-      EXIT_BLOCK_PTR->prev_bb->end = PREV_INSN (EXIT_BLOCK_PTR->prev_bb->end);\n+      BLOCK_END (n_basic_blocks - 1) = PREV_INSN (BLOCK_END (n_basic_blocks - 1));\n     }\n \n   /* Compute INSN_REG_WEIGHT for all blocks.  We must do this before\n      removing death notes.  */\n-  FOR_ALL_BB_REVERSE (b)\n-    find_insn_reg_weight (b->sindex);\n+  for (b = n_basic_blocks - 1; b >= 0; b--)\n+    find_insn_reg_weight (b);\n }\n \n /* Free global data used during insn scheduling.  */"}, {"sha": "e8c2b5f89b94a7eb46b224f6419c884c364ffed0", "filename": "gcc/ifcvt.c", "status": "modified", "additions": 39, "deletions": 21, "changes": 60, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fifcvt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fifcvt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fifcvt.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -110,6 +110,14 @@ static int find_memory\t\t\tPARAMS ((rtx *, void *));\n static int dead_or_predicable\t\tPARAMS ((basic_block, basic_block,\n \t\t\t\t\t\t basic_block, basic_block, int));\n static void noce_emit_move_insn\t\tPARAMS ((rtx, rtx));\n+\f\n+/* Abuse the basic_block AUX field to store the original block index,\n+   as well as a flag indicating that the block should be rescaned for\n+   life analysis.  */\n+\n+#define SET_ORIG_INDEX(BB,I)\t((BB)->aux = (void *)((size_t)(I)))\n+#define ORIG_INDEX(BB)\t\t((size_t)(BB)->aux)\n+\n \f\n /* Count the number of non-jump active insns in BB.  */\n \n@@ -1965,7 +1973,7 @@ find_if_block (test_bb, then_edge, else_edge)\n   basic_block join_bb = NULL_BLOCK;\n   edge then_succ = then_bb->succ;\n   edge else_succ = else_bb->succ;\n-  basic_block next;\n+  int next_index;\n \n   /* The THEN block of an IF-THEN combo must have exactly one predecessor.  */\n   if (then_bb->pred->pred_next != NULL_EDGE)\n@@ -2035,12 +2043,12 @@ find_if_block (test_bb, then_edge, else_edge)\n       if (else_bb)\n \tfprintf (rtl_dump_file,\n \t\t \"\\nIF-THEN-ELSE block found, start %d, then %d, else %d, join %d\\n\",\n-\t\t test_bb->sindex, then_bb->sindex, else_bb->sindex,\n-\t\t join_bb->sindex);\n+\t\t test_bb->index, then_bb->index, else_bb->index,\n+\t\t join_bb->index);\n       else\n \tfprintf (rtl_dump_file,\n \t\t \"\\nIF-THEN block found, start %d, then %d, join %d\\n\",\n-\t\t test_bb->sindex, then_bb->sindex, join_bb->sindex);\n+\t\t test_bb->index, then_bb->index, join_bb->index);\n     }\n \n   /* Make sure IF, THEN, and ELSE, blocks are adjacent.  Actually, we\n@@ -2049,10 +2057,10 @@ find_if_block (test_bb, then_edge, else_edge)\n   /* ??? As an enhancement, move the ELSE block.  Have to deal with\n      BLOCK notes, if by no other means than aborting the merge if they\n      exist.  Sticky enough I don't want to think about it now.  */\n-  next = then_bb;\n-  if (else_bb && (next = next->next_bb) != else_bb)\n+  next_index = then_bb->index;\n+  if (else_bb && ++next_index != else_bb->index)\n     return FALSE;\n-  if ((next = next->next_bb) != join_bb && join_bb != EXIT_BLOCK_PTR)\n+  if (++next_index != join_bb->index && join_bb->index != EXIT_BLOCK)\n     {\n       if (else_bb)\n \tjoin_bb = NULL;\n@@ -2092,7 +2100,7 @@ find_cond_trap (test_bb, then_edge, else_edge)\n   if (rtl_dump_file)\n     {\n       fprintf (rtl_dump_file, \"\\nTRAP-IF block found, start %d, trap %d\\n\",\n-\t       test_bb->sindex, trap_bb->sindex);\n+\t       test_bb->index, trap_bb->index);\n     }\n \n   /* If this is not a standard conditional jump, we can't parse it.  */\n@@ -2138,7 +2146,7 @@ find_cond_trap (test_bb, then_edge, else_edge)\n \n   /* If the non-trap block and the test are now adjacent, merge them.\n      Otherwise we must insert a direct branch.  */\n-  if (test_bb->next_bb == other_bb)\n+  if (test_bb->index + 1 == other_bb->index)\n     {\n       delete_insn (jump);\n       merge_if_block (test_bb, NULL, NULL, other_bb);\n@@ -2292,7 +2300,7 @@ find_if_case_1 (test_bb, then_edge, else_edge)\n   if (rtl_dump_file)\n     fprintf (rtl_dump_file,\n \t     \"\\nIF-CASE-1 found, start %d, then %d\\n\",\n-\t     test_bb->sindex, then_bb->sindex);\n+\t     test_bb->index, then_bb->index);\n \n   /* THEN is small.  */\n   if (count_bb_insns (then_bb) > BRANCH_COST)\n@@ -2313,6 +2321,8 @@ find_if_case_1 (test_bb, then_edge, else_edge)\n   new_bb = redirect_edge_and_branch_force (FALLTHRU_EDGE (test_bb), else_bb);\n   /* Make rest of code believe that the newly created block is the THEN_BB\n      block we are going to remove.  */\n+  if (new_bb)\n+    new_bb->aux = then_bb->aux;\n   flow_delete_block (then_bb);\n   /* We've possibly created jump to next insn, cleanup_cfg will solve that\n      later.  */\n@@ -2348,16 +2358,16 @@ find_if_case_2 (test_bb, then_edge, else_edge)\n     return FALSE;\n \n   /* THEN is not EXIT.  */\n-  if (then_bb == EXIT_BLOCK_PTR)\n+  if (then_bb->index < 0)\n     return FALSE;\n \n   /* ELSE is predicted or SUCC(ELSE) postdominates THEN.  */\n   note = find_reg_note (test_bb->end, REG_BR_PROB, NULL_RTX);\n   if (note && INTVAL (XEXP (note, 0)) >= REG_BR_PROB_BASE / 2)\n     ;\n-  else if (else_succ->dest == EXIT_BLOCK_PTR\n-\t   || TEST_BIT (post_dominators[then_bb->sindex], \n-\t\t\telse_succ->dest->sindex))\n+  else if (else_succ->dest->index < 0\n+\t   || TEST_BIT (post_dominators[ORIG_INDEX (then_bb)], \n+\t\t\tORIG_INDEX (else_succ->dest)))\n     ;\n   else\n     return FALSE;\n@@ -2366,7 +2376,7 @@ find_if_case_2 (test_bb, then_edge, else_edge)\n   if (rtl_dump_file)\n     fprintf (rtl_dump_file,\n \t     \"\\nIF-CASE-2 found, start %d, else %d\\n\",\n-\t     test_bb->sindex, else_bb->sindex);\n+\t     test_bb->index, else_bb->index);\n \n   /* ELSE is small.  */\n   if (count_bb_insns (then_bb) > BRANCH_COST)\n@@ -2675,7 +2685,7 @@ void\n if_convert (x_life_data_ok)\n      int x_life_data_ok;\n {\n-  basic_block bb;\n+  int block_num;\n \n   num_possible_if_blocks = 0;\n   num_updated_if_blocks = 0;\n@@ -2690,17 +2700,25 @@ if_convert (x_life_data_ok)\n   post_dominators = NULL;\n   if (HAVE_conditional_execution || life_data_ok)\n     {\n-      post_dominators = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n+      post_dominators = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n       calculate_dominance_info (NULL, post_dominators, CDI_POST_DOMINATORS);\n     }\n   if (life_data_ok)\n     clear_bb_flags ();\n \n+  /* Record initial block numbers.  */\n+  for (block_num = 0; block_num < n_basic_blocks; block_num++)\n+    SET_ORIG_INDEX (BASIC_BLOCK (block_num), block_num);\n+\n   /* Go through each of the basic blocks looking for things to convert.  */\n-  FOR_ALL_BB (bb)\n-    while (find_if_header (bb))\n-      {\n-      }\n+  for (block_num = 0; block_num < n_basic_blocks; )\n+    {\n+      basic_block bb = BASIC_BLOCK (block_num);\n+      if (find_if_header (bb))\n+\tblock_num = bb->index;\n+      else \n+\tblock_num++;\n+    }\n \n   if (post_dominators)\n     sbitmap_vector_free (post_dominators);"}, {"sha": "bc95aea8dd543a10535ce88aef3e88e62f67e5af", "filename": "gcc/lcm.c", "status": "modified", "additions": 186, "deletions": 184, "changes": 370, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Flcm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Flcm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flcm.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -106,7 +106,7 @@ compute_antinout_edge (antloc, transp, antin, antout)\n      sbitmap *antin;\n      sbitmap *antout;\n {\n-  basic_block bb;\n+  int bb;\n   edge e;\n   basic_block *worklist, *qin, *qout, *qend;\n   unsigned int qlen;\n@@ -115,23 +115,23 @@ compute_antinout_edge (antloc, transp, antin, antout)\n      list if they were not already on the list.  So the size is\n      bounded by the number of basic blocks.  */\n   qin = qout = worklist\n-    = (basic_block *) xmalloc (sizeof (basic_block) * num_basic_blocks);\n+    = (basic_block *) xmalloc (sizeof (basic_block) * n_basic_blocks);\n \n   /* We want a maximal solution, so make an optimistic initialization of\n      ANTIN.  */\n-  sbitmap_vector_ones (antin, last_basic_block);\n+  sbitmap_vector_ones (antin, n_basic_blocks);\n \n   /* Put every block on the worklist; this is necessary because of the\n      optimistic initialization of ANTIN above.  */\n-  FOR_ALL_BB_REVERSE (bb)\n+  for (bb = n_basic_blocks - 1; bb >= 0; bb--)\n     {\n-      *qin++ = bb;\n-      bb->aux = bb;\n+      *qin++ = BASIC_BLOCK (bb);\n+      BASIC_BLOCK (bb)->aux = BASIC_BLOCK (bb);\n     }\n \n   qin = worklist;\n-  qend = &worklist[num_basic_blocks];\n-  qlen = num_basic_blocks;\n+  qend = &worklist[n_basic_blocks];\n+  qlen = n_basic_blocks;\n \n   /* Mark blocks which are predecessors of the exit block so that we\n      can easily identify them below.  */\n@@ -142,31 +142,32 @@ compute_antinout_edge (antloc, transp, antin, antout)\n   while (qlen)\n     {\n       /* Take the first entry off the worklist.  */\n-      basic_block bb = *qout++;\n+      basic_block b = *qout++;\n+      bb = b->index;\n       qlen--;\n \n       if (qout >= qend)\n         qout = worklist;\n \n-      if (bb->aux == EXIT_BLOCK_PTR)\n+      if (b->aux == EXIT_BLOCK_PTR)\n \t/* Do not clear the aux field for blocks which are predecessors of\n \t   the EXIT block.  That way we never add then to the worklist\n \t   again.  */\n-\tsbitmap_zero (antout[bb->sindex]);\n+\tsbitmap_zero (antout[bb]);\n       else\n \t{\n \t  /* Clear the aux field of this block so that it can be added to\n \t     the worklist again if necessary.  */\n-\t  bb->aux = NULL;\n-\t  sbitmap_intersection_of_succs (antout[bb->sindex], antin, bb->sindex);\n+\t  b->aux = NULL;\n+\t  sbitmap_intersection_of_succs (antout[bb], antin, bb);\n \t}\n \n-      if (sbitmap_a_or_b_and_c_cg (antin[bb->sindex], antloc[bb->sindex],\n-\t\t\t\ttransp[bb->sindex], antout[bb->sindex]))\n+      if (sbitmap_a_or_b_and_c_cg (antin[bb], antloc[bb],\n+\t\t\t\t   transp[bb], antout[bb]))\n \t/* If the in state of this block changed, then we need\n \t   to add the predecessors of this block to the worklist\n \t   if they are not already on the worklist.  */\n-\tfor (e = bb->pred; e; e = e->pred_next)\n+\tfor (e = b->pred; e; e = e->pred_next)\n \t  if (!e->src->aux && e->src != ENTRY_BLOCK_PTR)\n \t    {\n \t      *qin++ = e->src;\n@@ -204,22 +205,22 @@ compute_earliest (edge_list, n_exprs, antin, antout, avout, kill, earliest)\n       pred = INDEX_EDGE_PRED_BB (edge_list, x);\n       succ = INDEX_EDGE_SUCC_BB (edge_list, x);\n       if (pred == ENTRY_BLOCK_PTR)\n-\tsbitmap_copy (earliest[x], antin[succ->sindex]);\n+\tsbitmap_copy (earliest[x], antin[succ->index]);\n       else\n         {\n \t  /* We refer to the EXIT_BLOCK index, instead of testing for\n \t     EXIT_BLOCK_PTR, so that EXIT_BLOCK_PTR's index can be\n \t     changed so as to pretend it's a regular block, so that\n \t     its antin can be taken into account.  */\n-\t  if (succ->sindex == EXIT_BLOCK)\n+\t  if (succ->index == EXIT_BLOCK)\n \t    sbitmap_zero (earliest[x]);\n \t  else\n \t    {\n-\t      sbitmap_difference (difference, antin[succ->sindex],\n-\t\t\t\t  avout[pred->sindex]);\n-\t      sbitmap_not (temp_bitmap, antout[pred->sindex]);\n+\t      sbitmap_difference (difference, antin[succ->index],\n+\t\t\t\t  avout[pred->index]);\n+\t      sbitmap_not (temp_bitmap, antout[pred->index]);\n \t      sbitmap_a_and_b_or_c (earliest[x], difference,\n-\t\t\t\t    kill[pred->sindex], temp_bitmap);\n+\t\t\t\t    kill[pred->index], temp_bitmap);\n \t    }\n \t}\n     }\n@@ -262,9 +263,9 @@ compute_laterin (edge_list, earliest, antloc, later, laterin)\n      struct edge_list *edge_list;\n      sbitmap *earliest, *antloc, *later, *laterin;\n {\n-  int num_edges, i;\n+  int bb, num_edges, i;\n   edge e;\n-  basic_block *worklist, *qin, *qout, *qend, bb;\n+  basic_block *worklist, *qin, *qout, *qend;\n   unsigned int qlen;\n \n   num_edges = NUM_EDGES (edge_list);\n@@ -273,7 +274,7 @@ compute_laterin (edge_list, earliest, antloc, later, laterin)\n      list if they were not already on the list.  So the size is\n      bounded by the number of basic blocks.  */\n   qin = qout = worklist\n-    = (basic_block *) xmalloc (sizeof (basic_block) * (num_basic_blocks + 1));\n+    = (basic_block *) xmalloc (sizeof (basic_block) * (n_basic_blocks + 1));\n \n   /* Initialize a mapping from each edge to its index.  */\n   for (i = 0; i < num_edges; i++)\n@@ -300,39 +301,41 @@ compute_laterin (edge_list, earliest, antloc, later, laterin)\n \n   /* Add all the blocks to the worklist.  This prevents an early exit from\n      the loop given our optimistic initialization of LATER above.  */\n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n-      *qin++ = bb;\n-      bb->aux = bb;\n+      basic_block b = BASIC_BLOCK (bb);\n+      *qin++ = b;\n+      b->aux = b;\n     }\n   qin = worklist;\n   /* Note that we do not use the last allocated element for our queue,\n      as EXIT_BLOCK is never inserted into it. In fact the above allocation\n-     of num_basic_blocks + 1 elements is not encessary.  */\n-  qend = &worklist[num_basic_blocks];\n-  qlen = num_basic_blocks;\n+     of n_basic_blocks + 1 elements is not encessary.  */\n+  qend = &worklist[n_basic_blocks];\n+  qlen = n_basic_blocks;\n \n   /* Iterate until the worklist is empty.  */\n   while (qlen)\n     {\n       /* Take the first entry off the worklist.  */\n-      bb = *qout++;\n-      bb->aux = NULL;\n+      basic_block b = *qout++;\n+      b->aux = NULL;\n       qlen--;\n       if (qout >= qend)\n         qout = worklist;\n \n       /* Compute the intersection of LATERIN for each incoming edge to B.  */\n-      sbitmap_ones (laterin[bb->sindex]);\n-      for (e = bb->pred; e != NULL; e = e->pred_next)\n-\tsbitmap_a_and_b (laterin[bb->sindex], laterin[bb->sindex], later[(size_t)e->aux]);\n+      bb = b->index;\n+      sbitmap_ones (laterin[bb]);\n+      for (e = b->pred; e != NULL; e = e->pred_next)\n+\tsbitmap_a_and_b (laterin[bb], laterin[bb], later[(size_t)e->aux]);\n \n       /* Calculate LATER for all outgoing edges.  */\n-      for (e = bb->succ; e != NULL; e = e->succ_next)\n+      for (e = b->succ; e != NULL; e = e->succ_next)\n \tif (sbitmap_union_of_diff_cg (later[(size_t) e->aux],\n-\t\t\t\t   earliest[(size_t) e->aux],\n-\t\t\t\t   laterin[e->src->sindex],\n-\t\t\t\t   antloc[e->src->sindex])\n+\t\t\t\t      earliest[(size_t) e->aux],\n+\t\t\t\t      laterin[e->src->index],\n+\t\t\t\t      antloc[e->src->index])\n \t    /* If LATER for an outgoing edge was changed, then we need\n \t       to add the target of the outgoing edge to the worklist.  */\n \t    && e->dest != EXIT_BLOCK_PTR && e->dest->aux == 0)\n@@ -348,10 +351,10 @@ compute_laterin (edge_list, earliest, antloc, later, laterin)\n   /* Computation of insertion and deletion points requires computing LATERIN\n      for the EXIT block.  We allocated an extra entry in the LATERIN array\n      for just this purpose.  */\n-  sbitmap_ones (laterin[last_basic_block]);\n+  sbitmap_ones (laterin[n_basic_blocks]);\n   for (e = EXIT_BLOCK_PTR->pred; e != NULL; e = e->pred_next)\n-    sbitmap_a_and_b (laterin[last_basic_block],\n-\t\t     laterin[last_basic_block],\n+    sbitmap_a_and_b (laterin[n_basic_blocks],\n+\t\t     laterin[n_basic_blocks],\n \t\t     later[(size_t) e->aux]);\n \n   clear_aux_for_edges ();\n@@ -367,19 +370,18 @@ compute_insert_delete (edge_list, antloc, later, laterin,\n      sbitmap *antloc, *later, *laterin, *insert, *delete;\n {\n   int x;\n-  basic_block bb;\n \n-  FOR_ALL_BB (bb)\n-    sbitmap_difference (delete[bb->sindex], antloc[bb->sindex], laterin[bb->sindex]);\n+  for (x = 0; x < n_basic_blocks; x++)\n+    sbitmap_difference (delete[x], antloc[x], laterin[x]);\n \n   for (x = 0; x < NUM_EDGES (edge_list); x++)\n     {\n       basic_block b = INDEX_EDGE_SUCC_BB (edge_list, x);\n \n       if (b == EXIT_BLOCK_PTR)\n-\tsbitmap_difference (insert[x], later[x], laterin[last_basic_block]);\n+\tsbitmap_difference (insert[x], later[x], laterin[n_basic_blocks]);\n       else\n-\tsbitmap_difference (insert[x], later[x], laterin[b->sindex]);\n+\tsbitmap_difference (insert[x], later[x], laterin[b->index]);\n     }\n }\n \n@@ -413,29 +415,29 @@ pre_edge_lcm (file, n_exprs, transp, avloc, antloc, kill, insert, delete)\n       fprintf (file, \"Edge List:\\n\");\n       verify_edge_list (file, edge_list);\n       print_edge_list (file, edge_list);\n-      dump_sbitmap_vector (file, \"transp\", \"\", transp, last_basic_block);\n-      dump_sbitmap_vector (file, \"antloc\", \"\", antloc, last_basic_block);\n-      dump_sbitmap_vector (file, \"avloc\", \"\", avloc, last_basic_block);\n-      dump_sbitmap_vector (file, \"kill\", \"\", kill, last_basic_block);\n+      dump_sbitmap_vector (file, \"transp\", \"\", transp, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"antloc\", \"\", antloc, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"avloc\", \"\", avloc, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"kill\", \"\", kill, n_basic_blocks);\n     }\n #endif\n \n   /* Compute global availability.  */\n-  avin = sbitmap_vector_alloc (last_basic_block, n_exprs);\n-  avout = sbitmap_vector_alloc (last_basic_block, n_exprs);\n+  avin = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n+  avout = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n   compute_available (avloc, kill, avout, avin);\n   sbitmap_vector_free (avin);\n \n   /* Compute global anticipatability.  */\n-  antin = sbitmap_vector_alloc (last_basic_block, n_exprs);\n-  antout = sbitmap_vector_alloc (last_basic_block, n_exprs);\n+  antin = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n+  antout = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n   compute_antinout_edge (antloc, transp, antin, antout);\n \n #ifdef LCM_DEBUG_INFO\n   if (file)\n     {\n-      dump_sbitmap_vector (file, \"antin\", \"\", antin, last_basic_block);\n-      dump_sbitmap_vector (file, \"antout\", \"\", antout, last_basic_block);\n+      dump_sbitmap_vector (file, \"antin\", \"\", antin, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"antout\", \"\", antout, n_basic_blocks);\n     }\n #endif\n \n@@ -455,21 +457,21 @@ pre_edge_lcm (file, n_exprs, transp, avloc, antloc, kill, insert, delete)\n   later = sbitmap_vector_alloc (num_edges, n_exprs);\n \n   /* Allocate an extra element for the exit block in the laterin vector.  */\n-  laterin = sbitmap_vector_alloc (last_basic_block + 1, n_exprs);\n+  laterin = sbitmap_vector_alloc (n_basic_blocks + 1, n_exprs);\n   compute_laterin (edge_list, earliest, antloc, later, laterin);\n \n #ifdef LCM_DEBUG_INFO\n   if (file)\n     {\n-      dump_sbitmap_vector (file, \"laterin\", \"\", laterin, last_basic_block + 1);\n+      dump_sbitmap_vector (file, \"laterin\", \"\", laterin, n_basic_blocks + 1);\n       dump_sbitmap_vector (file, \"later\", \"\", later, num_edges);\n     }\n #endif\n \n   sbitmap_vector_free (earliest);\n \n   *insert = sbitmap_vector_alloc (num_edges, n_exprs);\n-  *delete = sbitmap_vector_alloc (last_basic_block, n_exprs);\n+  *delete = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n   compute_insert_delete (edge_list, antloc, later, laterin, *insert, *delete);\n \n   sbitmap_vector_free (laterin);\n@@ -480,7 +482,7 @@ pre_edge_lcm (file, n_exprs, transp, avloc, antloc, kill, insert, delete)\n     {\n       dump_sbitmap_vector (file, \"pre_insert_map\", \"\", *insert, num_edges);\n       dump_sbitmap_vector (file, \"pre_delete_map\", \"\", *delete,\n-\t\t\t   last_basic_block);\n+\t\t\t   n_basic_blocks);\n     }\n #endif\n \n@@ -494,30 +496,31 @@ void\n compute_available (avloc, kill, avout, avin)\n      sbitmap *avloc, *kill, *avout, *avin;\n {\n+  int bb;\n   edge e;\n-  basic_block *worklist, *qin, *qout, *qend, bb;\n+  basic_block *worklist, *qin, *qout, *qend;\n   unsigned int qlen;\n \n   /* Allocate a worklist array/queue.  Entries are only added to the\n      list if they were not already on the list.  So the size is\n      bounded by the number of basic blocks.  */\n   qin = qout = worklist\n-    = (basic_block *) xmalloc (sizeof (basic_block) * num_basic_blocks);\n+    = (basic_block *) xmalloc (sizeof (basic_block) * n_basic_blocks);\n \n   /* We want a maximal solution.  */\n-  sbitmap_vector_ones (avout, last_basic_block);\n+  sbitmap_vector_ones (avout, n_basic_blocks);\n \n   /* Put every block on the worklist; this is necessary because of the\n      optimistic initialization of AVOUT above.  */\n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n-      *qin++ = bb;\n-      bb->aux = bb;\n+      *qin++ = BASIC_BLOCK (bb);\n+      BASIC_BLOCK (bb)->aux = BASIC_BLOCK (bb);\n     }\n \n   qin = worklist;\n-  qend = &worklist[num_basic_blocks];\n-  qlen = num_basic_blocks;\n+  qend = &worklist[n_basic_blocks];\n+  qlen = n_basic_blocks;\n \n   /* Mark blocks which are successors of the entry block so that we\n      can easily identify them below.  */\n@@ -528,7 +531,8 @@ compute_available (avloc, kill, avout, avin)\n   while (qlen)\n     {\n       /* Take the first entry off the worklist.  */\n-      basic_block bb = *qout++;\n+      basic_block b = *qout++;\n+      bb = b->index;\n       qlen--;\n \n       if (qout >= qend)\n@@ -537,24 +541,23 @@ compute_available (avloc, kill, avout, avin)\n       /* If one of the predecessor blocks is the ENTRY block, then the\n \t intersection of avouts is the null set.  We can identify such blocks\n \t by the special value in the AUX field in the block structure.  */\n-      if (bb->aux == ENTRY_BLOCK_PTR)\n+      if (b->aux == ENTRY_BLOCK_PTR)\n \t/* Do not clear the aux field for blocks which are successors of the\n \t   ENTRY block.  That way we never add then to the worklist again.  */\n-\tsbitmap_zero (avin[bb->sindex]);\n+\tsbitmap_zero (avin[bb]);\n       else\n \t{\n \t  /* Clear the aux field of this block so that it can be added to\n \t     the worklist again if necessary.  */\n-\t  bb->aux = NULL;\n-\t  sbitmap_intersection_of_preds (avin[bb->sindex], avout, bb->sindex);\n+\t  b->aux = NULL;\n+\t  sbitmap_intersection_of_preds (avin[bb], avout, bb);\n \t}\n \n-      if (sbitmap_union_of_diff_cg (avout[bb->sindex], avloc[bb->sindex],\n-\t\t\t\t avin[bb->sindex], kill[bb->sindex]))\n+      if (sbitmap_union_of_diff_cg (avout[bb], avloc[bb], avin[bb], kill[bb]))\n \t/* If the out state of this block changed, then we need\n \t   to add the successors of this block to the worklist\n \t   if they are not already on the worklist.  */\n-\tfor (e = bb->succ; e; e = e->succ_next)\n+\tfor (e = b->succ; e; e = e->succ_next)\n \t  if (!e->dest->aux && e->dest != EXIT_BLOCK_PTR)\n \t    {\n \t      *qin++ = e->dest;\n@@ -594,18 +597,18 @@ compute_farthest (edge_list, n_exprs, st_avout, st_avin, st_antin,\n       pred = INDEX_EDGE_PRED_BB (edge_list, x);\n       succ = INDEX_EDGE_SUCC_BB (edge_list, x);\n       if (succ == EXIT_BLOCK_PTR)\n-\tsbitmap_copy (farthest[x], st_avout[pred->sindex]);\n+\tsbitmap_copy (farthest[x], st_avout[pred->index]);\n       else\n \t{\n \t  if (pred == ENTRY_BLOCK_PTR)\n \t    sbitmap_zero (farthest[x]);\n \t  else\n \t    {\n-\t      sbitmap_difference (difference, st_avout[pred->sindex],\n-\t\t\t\t  st_antin[succ->sindex]);\n-\t      sbitmap_not (temp_bitmap, st_avin[succ->sindex]);\n+\t      sbitmap_difference (difference, st_avout[pred->index],\n+\t\t\t\t  st_antin[succ->index]);\n+\t      sbitmap_not (temp_bitmap, st_avin[succ->index]);\n \t      sbitmap_a_and_b_or_c (farthest[x], difference,\n-\t\t\t\t    kill[succ->sindex], temp_bitmap);\n+\t\t\t\t    kill[succ->index], temp_bitmap);\n \t    }\n \t}\n     }\n@@ -624,17 +627,17 @@ compute_nearerout (edge_list, farthest, st_avloc, nearer, nearerout)\n      struct edge_list *edge_list;\n      sbitmap *farthest, *st_avloc, *nearer, *nearerout;\n {\n-  int num_edges, i;\n+  int bb, num_edges, i;\n   edge e;\n-  basic_block *worklist, *tos, bb;\n+  basic_block *worklist, *tos;\n \n   num_edges = NUM_EDGES (edge_list);\n \n   /* Allocate a worklist array/queue.  Entries are only added to the\n      list if they were not already on the list.  So the size is\n      bounded by the number of basic blocks.  */\n   tos = worklist\n-    = (basic_block *) xmalloc (sizeof (basic_block) * (num_basic_blocks + 1));\n+    = (basic_block *) xmalloc (sizeof (basic_block) * (n_basic_blocks + 1));\n \n   /* Initialize NEARER for each edge and build a mapping from an edge to\n      its index.  */\n@@ -653,31 +656,33 @@ compute_nearerout (edge_list, farthest, st_avloc, nearer, nearerout)\n \n   /* Add all the blocks to the worklist.  This prevents an early exit\n      from the loop given our optimistic initialization of NEARER.  */\n-  FOR_ALL_BB (bb)\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n-      *tos++ = bb;\n-      bb->aux = bb;\n+      basic_block b = BASIC_BLOCK (bb);\n+      *tos++ = b;\n+      b->aux = b;\n     }\n \n   /* Iterate until the worklist is empty.  */\n   while (tos != worklist)\n     {\n       /* Take the first entry off the worklist.  */\n-      bb = *--tos;\n-      bb->aux = NULL;\n+      basic_block b = *--tos;\n+      b->aux = NULL;\n \n       /* Compute the intersection of NEARER for each outgoing edge from B.  */\n-      sbitmap_ones (nearerout[bb->sindex]);\n-      for (e = bb->succ; e != NULL; e = e->succ_next)\n-\tsbitmap_a_and_b (nearerout[bb->sindex], nearerout[bb->sindex],\n+      bb = b->index;\n+      sbitmap_ones (nearerout[bb]);\n+      for (e = b->succ; e != NULL; e = e->succ_next)\n+\tsbitmap_a_and_b (nearerout[bb], nearerout[bb],\n \t\t\t nearer[(size_t) e->aux]);\n \n       /* Calculate NEARER for all incoming edges.  */\n-      for (e = bb->pred; e != NULL; e = e->pred_next)\n+      for (e = b->pred; e != NULL; e = e->pred_next)\n \tif (sbitmap_union_of_diff_cg (nearer[(size_t) e->aux],\n-\t\t\t\t   farthest[(size_t) e->aux],\n-\t\t\t\t   nearerout[e->dest->sindex],\n-\t\t\t\t   st_avloc[e->dest->sindex])\n+\t\t\t\t      farthest[(size_t) e->aux],\n+\t\t\t\t      nearerout[e->dest->index],\n+\t\t\t\t      st_avloc[e->dest->index])\n \t    /* If NEARER for an incoming edge was changed, then we need\n \t       to add the source of the incoming edge to the worklist.  */\n \t    && e->src != ENTRY_BLOCK_PTR && e->src->aux == 0)\n@@ -690,10 +695,10 @@ compute_nearerout (edge_list, farthest, st_avloc, nearer, nearerout)\n   /* Computation of insertion and deletion points requires computing NEAREROUT\n      for the ENTRY block.  We allocated an extra entry in the NEAREROUT array\n      for just this purpose.  */\n-  sbitmap_ones (nearerout[last_basic_block]);\n+  sbitmap_ones (nearerout[n_basic_blocks]);\n   for (e = ENTRY_BLOCK_PTR->succ; e != NULL; e = e->succ_next)\n-    sbitmap_a_and_b (nearerout[last_basic_block],\n-\t\t     nearerout[last_basic_block],\n+    sbitmap_a_and_b (nearerout[n_basic_blocks],\n+\t\t     nearerout[n_basic_blocks],\n \t\t     nearer[(size_t) e->aux]);\n \n   clear_aux_for_edges ();\n@@ -709,19 +714,17 @@ compute_rev_insert_delete (edge_list, st_avloc, nearer, nearerout,\n      sbitmap *st_avloc, *nearer, *nearerout, *insert, *delete;\n {\n   int x;\n-  basic_block bb;\n \n-  FOR_ALL_BB (bb)\n-    sbitmap_difference (delete[bb->sindex], st_avloc[bb->sindex],\n-\t\t\tnearerout[bb->sindex]);\n+  for (x = 0; x < n_basic_blocks; x++)\n+    sbitmap_difference (delete[x], st_avloc[x], nearerout[x]);\n \n   for (x = 0; x < NUM_EDGES (edge_list); x++)\n     {\n       basic_block b = INDEX_EDGE_PRED_BB (edge_list, x);\n       if (b == ENTRY_BLOCK_PTR)\n-\tsbitmap_difference (insert[x], nearer[x], nearerout[last_basic_block]);\n+\tsbitmap_difference (insert[x], nearer[x], nearerout[n_basic_blocks]);\n       else\n-\tsbitmap_difference (insert[x], nearer[x], nearerout[b->sindex]);\n+\tsbitmap_difference (insert[x], nearer[x], nearerout[b->index]);\n     }\n }\n \n@@ -751,15 +754,15 @@ pre_edge_rev_lcm (file, n_exprs, transp, st_avloc, st_antloc, kill,\n   edge_list = create_edge_list ();\n   num_edges = NUM_EDGES (edge_list);\n \n-  st_antin = (sbitmap *) sbitmap_vector_alloc (last_basic_block, n_exprs);\n-  st_antout = (sbitmap *) sbitmap_vector_alloc (last_basic_block, n_exprs);\n-  sbitmap_vector_zero (st_antin, last_basic_block);\n-  sbitmap_vector_zero (st_antout, last_basic_block);\n+  st_antin = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n+  st_antout = (sbitmap *) sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n+  sbitmap_vector_zero (st_antin, n_basic_blocks);\n+  sbitmap_vector_zero (st_antout, n_basic_blocks);\n   compute_antinout_edge (st_antloc, transp, st_antin, st_antout);\n \n   /* Compute global anticipatability.  */\n-  st_avout = sbitmap_vector_alloc (last_basic_block, n_exprs);\n-  st_avin = sbitmap_vector_alloc (last_basic_block, n_exprs);\n+  st_avout = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n+  st_avin = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n   compute_available (st_avloc, kill, st_avout, st_avin);\n \n #ifdef LCM_DEBUG_INFO\n@@ -768,20 +771,20 @@ pre_edge_rev_lcm (file, n_exprs, transp, st_avloc, st_antloc, kill,\n       fprintf (file, \"Edge List:\\n\");\n       verify_edge_list (file, edge_list);\n       print_edge_list (file, edge_list);\n-      dump_sbitmap_vector (file, \"transp\", \"\", transp, last_basic_block);\n-      dump_sbitmap_vector (file, \"st_avloc\", \"\", st_avloc, last_basic_block);\n-      dump_sbitmap_vector (file, \"st_antloc\", \"\", st_antloc, last_basic_block);\n-      dump_sbitmap_vector (file, \"st_antin\", \"\", st_antin, last_basic_block);\n-      dump_sbitmap_vector (file, \"st_antout\", \"\", st_antout, last_basic_block);\n-      dump_sbitmap_vector (file, \"st_kill\", \"\", kill, last_basic_block);\n+      dump_sbitmap_vector (file, \"transp\", \"\", transp, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"st_avloc\", \"\", st_avloc, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"st_antloc\", \"\", st_antloc, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"st_antin\", \"\", st_antin, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"st_antout\", \"\", st_antout, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"st_kill\", \"\", kill, n_basic_blocks);\n     }\n #endif\n \n #ifdef LCM_DEBUG_INFO\n   if (file)\n     {\n-      dump_sbitmap_vector (file, \"st_avout\", \"\", st_avout, last_basic_block);\n-      dump_sbitmap_vector (file, \"st_avin\", \"\", st_avin, last_basic_block);\n+      dump_sbitmap_vector (file, \"st_avout\", \"\", st_avout, n_basic_blocks);\n+      dump_sbitmap_vector (file, \"st_avin\", \"\", st_avin, n_basic_blocks);\n     }\n #endif\n \n@@ -804,22 +807,22 @@ pre_edge_rev_lcm (file, n_exprs, transp, st_avloc, st_antloc, kill,\n   nearer = sbitmap_vector_alloc (num_edges, n_exprs);\n \n   /* Allocate an extra element for the entry block.  */\n-  nearerout = sbitmap_vector_alloc (last_basic_block + 1, n_exprs);\n+  nearerout = sbitmap_vector_alloc (n_basic_blocks + 1, n_exprs);\n   compute_nearerout (edge_list, farthest, st_avloc, nearer, nearerout);\n \n #ifdef LCM_DEBUG_INFO\n   if (file)\n     {\n       dump_sbitmap_vector (file, \"nearerout\", \"\", nearerout,\n-\t\t\t   last_basic_block + 1);\n+\t\t\t   n_basic_blocks + 1);\n       dump_sbitmap_vector (file, \"nearer\", \"\", nearer, num_edges);\n     }\n #endif\n \n   sbitmap_vector_free (farthest);\n \n   *insert = sbitmap_vector_alloc (num_edges, n_exprs);\n-  *delete = sbitmap_vector_alloc (last_basic_block, n_exprs);\n+  *delete = sbitmap_vector_alloc (n_basic_blocks, n_exprs);\n   compute_rev_insert_delete (edge_list, st_avloc, nearer, nearerout,\n \t\t\t     *insert, *delete);\n \n@@ -831,7 +834,7 @@ pre_edge_rev_lcm (file, n_exprs, transp, st_avloc, st_antloc, kill,\n     {\n       dump_sbitmap_vector (file, \"pre_insert_map\", \"\", *insert, num_edges);\n       dump_sbitmap_vector (file, \"pre_delete_map\", \"\", *delete,\n-\t\t\t   last_basic_block);\n+\t\t\t   n_basic_blocks);\n     }\n #endif\n   return edge_list;\n@@ -957,10 +960,10 @@ make_preds_opaque (b, j)\n     {\n       basic_block pb = e->src;\n \n-      if (e->aux || ! TEST_BIT (transp[pb->sindex], j))\n+      if (e->aux || ! TEST_BIT (transp[pb->index], j))\n \tcontinue;\n \n-      RESET_BIT (transp[pb->sindex], j);\n+      RESET_BIT (transp[pb->index], j);\n       make_preds_opaque (pb, j);\n     }\n }\n@@ -1016,8 +1019,7 @@ optimize_mode_switching (file)\n      FILE *file;\n {\n   rtx insn;\n-  int e;\n-  basic_block bb;\n+  int bb, e;\n   int need_commit = 0;\n   sbitmap *kill;\n   struct edge_list *edge_list;\n@@ -1032,24 +1034,24 @@ optimize_mode_switching (file)\n \n   clear_bb_flags ();\n #ifdef NORMAL_MODE\n-  /* Increment last_basic_block before allocating bb_info.  */\n-  last_basic_block++;\n+  /* Increment n_basic_blocks before allocating bb_info.  */\n+  n_basic_blocks++;\n #endif\n \n   for (e = N_ENTITIES - 1, n_entities = 0; e >= 0; e--)\n     if (OPTIMIZE_MODE_SWITCHING (e))\n       {\n \t/* Create the list of segments within each basic block.  */\n \tbb_info[n_entities]\n-\t  = (struct bb_info *) xcalloc (last_basic_block, sizeof **bb_info);\n+\t  = (struct bb_info *) xcalloc (n_basic_blocks, sizeof **bb_info);\n \tentity_map[n_entities++] = e;\n \tif (num_modes[e] > max_num_modes)\n \t  max_num_modes = num_modes[e];\n       }\n \n #ifdef NORMAL_MODE\n   /* Decrement it back in case we return below.  */\n-  last_basic_block--;\n+  n_basic_blocks--;\n #endif\n \n   if (! n_entities)\n@@ -1061,20 +1063,20 @@ optimize_mode_switching (file)\n      EXIT_BLOCK isn't optimized away.  We do this by incrementing the\n      basic block count, growing the VARRAY of basic_block_info and\n      appending the EXIT_BLOCK_PTR to it.  */\n-  last_basic_block++;\n-  if (VARRAY_SIZE (basic_block_info) < last_basic_block)\n-    VARRAY_GROW (basic_block_info, last_basic_block);\n-  BASIC_BLOCK (last_basic_block - 1) = EXIT_BLOCK_PTR;\n-  EXIT_BLOCK_PTR->sindex = last_basic_blocks;\n+  n_basic_blocks++;\n+  if (VARRAY_SIZE (basic_block_info) < n_basic_blocks)\n+    VARRAY_GROW (basic_block_info, n_basic_blocks);\n+  BASIC_BLOCK (n_basic_blocks - 1) = EXIT_BLOCK_PTR;\n+  EXIT_BLOCK_PTR->index = n_basic_blocks - 1;\n #endif\n \n   /* Create the bitmap vectors.  */\n \n-  antic = sbitmap_vector_alloc (last_basic_block, n_entities);\n-  transp = sbitmap_vector_alloc (last_basic_block, n_entities);\n-  comp = sbitmap_vector_alloc (last_basic_block, n_entities);\n+  antic = sbitmap_vector_alloc (n_basic_blocks, n_entities);\n+  transp = sbitmap_vector_alloc (n_basic_blocks, n_entities);\n+  comp = sbitmap_vector_alloc (n_basic_blocks, n_entities);\n \n-  sbitmap_vector_ones (transp, last_basic_block);\n+  sbitmap_vector_ones (transp, n_basic_blocks);\n \n   for (j = n_entities - 1; j >= 0; j--)\n     {\n@@ -1085,16 +1087,16 @@ optimize_mode_switching (file)\n       /* Determine what the first use (if any) need for a mode of entity E is.\n \t This will be the mode that is anticipatable for this block.\n \t Also compute the initial transparency settings.  */\n-      FOR_ALL_BB (bb)\n+      for (bb = 0 ; bb < n_basic_blocks; bb++)\n \t{\n \t  struct seginfo *ptr;\n \t  int last_mode = no_mode;\n \t  HARD_REG_SET live_now;\n \n \t  REG_SET_TO_HARD_REG_SET (live_now,\n-\t\t\t\t   bb->global_live_at_start);\n-\t  for (insn = bb->head;\n-\t       insn != NULL && insn != NEXT_INSN (bb->end);\n+\t\t\t\t   BASIC_BLOCK (bb)->global_live_at_start);\n+\t  for (insn = BLOCK_HEAD (bb);\n+\t       insn != NULL && insn != NEXT_INSN (BLOCK_END (bb));\n \t       insn = NEXT_INSN (insn))\n \t    {\n \t      if (INSN_P (insn))\n@@ -1105,9 +1107,9 @@ optimize_mode_switching (file)\n \t\t  if (mode != no_mode && mode != last_mode)\n \t\t    {\n \t\t      last_mode = mode;\n-\t\t      ptr = new_seginfo (mode, insn, bb->sindex, live_now);\n-\t\t      add_seginfo (info + bb->sindex, ptr);\n-\t\t      RESET_BIT (transp[bb->sindex], j);\n+\t\t      ptr = new_seginfo (mode, insn, bb, live_now);\n+\t\t      add_seginfo (info + bb, ptr);\n+\t\t      RESET_BIT (transp[bb], j);\n \t\t    }\n \n \t\t  /* Update LIVE_NOW.  */\n@@ -1122,12 +1124,12 @@ optimize_mode_switching (file)\n \t\t}\n \t    }\n \n-\t  info[bb->sindex].computing = last_mode;\n+\t  info[bb].computing = last_mode;\n \t  /* Check for blocks without ANY mode requirements.  */\n \t  if (last_mode == no_mode)\n \t    {\n-\t      ptr = new_seginfo (no_mode, insn, bb->sindex, live_now);\n-\t      add_seginfo (info + bb->sindex, ptr);\n+\t      ptr = new_seginfo (no_mode, insn, bb, live_now);\n+\t      add_seginfo (info + bb, ptr);\n \t    }\n \t}\n #ifdef NORMAL_MODE\n@@ -1140,65 +1142,65 @@ optimize_mode_switching (file)\n \n \t    for (eg = ENTRY_BLOCK_PTR->succ; eg; eg = eg->succ_next)\n \t      {\n-\t\tbb = eg->dest;\n+\t\tbb = eg->dest->index;\n \n \t        /* By always making this nontransparent, we save\n \t\t   an extra check in make_preds_opaque.  We also\n \t\t   need this to avoid confusing pre_edge_lcm when\n \t\t   antic is cleared but transp and comp are set.  */\n-\t\tRESET_BIT (transp[bb->sindex], j);\n+\t\tRESET_BIT (transp[bb], j);\n \n \t\t/* If the block already has MODE, pretend it\n \t\t   has none (because we don't need to set it),\n \t\t   but retain whatever mode it computes.  */\n-\t\tif (info[bb->sindex].seginfo->mode == mode)\n-\t\t  info[bb->sindex].seginfo->mode = no_mode;\n+\t\tif (info[bb].seginfo->mode == mode)\n+\t\t  info[bb].seginfo->mode = no_mode;\n \n \t\t/* Insert a fake computing definition of MODE into entry\n \t\t   blocks which compute no mode. This represents the mode on\n \t\t   entry.  */\n-\t\telse if (info[bb->sindex].computing == no_mode)\n+\t\telse if (info[bb].computing == no_mode)\n \t\t  {\n-\t\t    info[bb->sindex].computing = mode;\n-\t\t    info[bb->sindex].seginfo->mode = no_mode;\n+\t\t    info[bb].computing = mode;\n+\t\t    info[bb].seginfo->mode = no_mode;\n \t\t  }\n \t      }\n \n-\t    bb = EXIT_BLOCK_PTR;\n-\t    info[bb->sindex].seginfo->mode = mode;\n+\t    bb = n_basic_blocks - 1;\n+\t    info[bb].seginfo->mode = mode;\n \t  }\n       }\n #endif /* NORMAL_MODE */\n     }\n \n-  kill = sbitmap_vector_alloc (last_basic_block, n_entities);\n+  kill = sbitmap_vector_alloc (n_basic_blocks, n_entities);\n   for (i = 0; i < max_num_modes; i++)\n     {\n       int current_mode[N_ENTITIES];\n \n       /* Set the anticipatable and computing arrays.  */\n-      sbitmap_vector_zero (antic, last_basic_block);\n-      sbitmap_vector_zero (comp, last_basic_block);\n+      sbitmap_vector_zero (antic, n_basic_blocks);\n+      sbitmap_vector_zero (comp, n_basic_blocks);\n       for (j = n_entities - 1; j >= 0; j--)\n \t{\n \t  int m = current_mode[j] = MODE_PRIORITY_TO_MODE (entity_map[j], i);\n \t  struct bb_info *info = bb_info[j];\n \n-\t  FOR_ALL_BB (bb)\n+\t  for (bb = 0 ; bb < n_basic_blocks; bb++)\n \t    {\n-\t      if (info[bb->sindex].seginfo->mode == m)\n-\t\tSET_BIT (antic[bb->sindex], j);\n+\t      if (info[bb].seginfo->mode == m)\n+\t\tSET_BIT (antic[bb], j);\n \n-\t      if (info[bb->sindex].computing == m)\n-\t\tSET_BIT (comp[bb->sindex], j);\n+\t      if (info[bb].computing == m)\n+\t\tSET_BIT (comp[bb], j);\n \t    }\n \t}\n \n       /* Calculate the optimal locations for the\n \t placement mode switches to modes with priority I.  */\n \n-      FOR_ALL_BB_REVERSE (bb)\n-\tsbitmap_not (kill[bb->sindex], transp[bb->sindex]);\n+      for (bb = n_basic_blocks - 1; bb >= 0; bb--)\n+\tsbitmap_not (kill[bb], transp[bb]);\n       edge_list = pre_edge_lcm (file, 1, transp, comp, antic,\n \t\t\t\tkill, &insert, &delete);\n \n@@ -1267,8 +1269,8 @@ optimize_mode_switching (file)\n \t\t    emit_insn_after (mode_set, src_bb->end);\n \t\t  else\n \t\t    abort ();\n-\t\t  bb_info[j][src_bb->sindex].computing = mode;\n-\t\t  RESET_BIT (transp[src_bb->sindex], j);\n+\t\t  bb_info[j][src_bb->index].computing = mode;\n+\t\t  RESET_BIT (transp[src_bb->index], j);\n \t\t}\n \t      else\n \t\t{\n@@ -1277,12 +1279,12 @@ optimize_mode_switching (file)\n \t\t}\n \t    }\n \n-\t  FOR_ALL_BB_REVERSE (bb)\n-\t    if (TEST_BIT (delete[bb->sindex], j))\n+\t  for (bb = n_basic_blocks - 1; bb >= 0; bb--)\n+\t    if (TEST_BIT (delete[bb], j))\n \t      {\n-\t\tmake_preds_opaque (bb, j);\n+\t\tmake_preds_opaque (BASIC_BLOCK (bb), j);\n \t\t/* Cancel the 'deleted' mode set.  */\n-\t\tbb_info[j][bb->sindex].seginfo->mode = no_mode;\n+\t\tbb_info[j][bb].seginfo->mode = no_mode;\n \t      }\n \t}\n \n@@ -1292,9 +1294,9 @@ optimize_mode_switching (file)\n \n #ifdef NORMAL_MODE\n   /* Restore the special status of EXIT_BLOCK.  */\n-  last_basic_block--;\n+  n_basic_blocks--;\n   VARRAY_POP (basic_block_info);\n-  EXIT_BLOCK_PTR->sindex = EXIT_BLOCK;\n+  EXIT_BLOCK_PTR->index = EXIT_BLOCK;\n #endif\n \n   /* Now output the remaining mode sets in all the segments.  */\n@@ -1303,16 +1305,16 @@ optimize_mode_switching (file)\n       int no_mode = num_modes[entity_map[j]];\n \n #ifdef NORMAL_MODE\n-      if (bb_info[j][last_basic_block].seginfo->mode != no_mode)\n+      if (bb_info[j][n_basic_blocks].seginfo->mode != no_mode)\n \t{\n \t  edge eg;\n-\t  struct seginfo *ptr = bb_info[j][last_basic_block].seginfo;\n+\t  struct seginfo *ptr = bb_info[j][n_basic_blocks].seginfo;\n \n \t  for (eg = EXIT_BLOCK_PTR->pred; eg; eg = eg->pred_next)\n \t    {\n \t      rtx mode_set;\n \n-\t      if (bb_info[j][eg->src->sindex].computing == ptr->mode)\n+\t      if (bb_info[j][eg->src->index].computing == ptr->mode)\n \t\tcontinue;\n \n \t      start_sequence ();\n@@ -1347,10 +1349,10 @@ optimize_mode_switching (file)\n \t}\n #endif\n \n-      FOR_ALL_BB_REVERSE (bb)\n+      for (bb = n_basic_blocks - 1; bb >= 0; bb--)\n \t{\n \t  struct seginfo *ptr, *next;\n-\t  for (ptr = bb_info[j][bb->sindex].seginfo; ptr; ptr = next)\n+\t  for (ptr = bb_info[j][bb].seginfo; ptr; ptr = next)\n \t    {\n \t      next = ptr->next;\n \t      if (ptr->mode != no_mode)"}, {"sha": "cd216f96d0f6c28f2a97bbc571d828c2a7c105d5", "filename": "gcc/local-alloc.c", "status": "modified", "additions": 21, "deletions": 17, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Flocal-alloc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Flocal-alloc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flocal-alloc.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -336,9 +336,8 @@ alloc_qty (regno, mode, size, birth)\n int\n local_alloc ()\n {\n-  int i;\n+  int b, i;\n   int max_qty;\n-  basic_block b;\n \n   /* We need to keep track of whether or not we recorded a LABEL_REF so\n      that we know if the jump optimizer needs to be rerun.  */\n@@ -395,7 +394,7 @@ local_alloc ()\n \n   /* Allocate each block's local registers, block by block.  */\n \n-  FOR_ALL_BB (b)\n+  for (b = 0; b < n_basic_blocks; b++)\n     {\n       /* NEXT_QTY indicates which elements of the `qty_...'\n \t vectors might need to be initialized because they were used\n@@ -427,7 +426,7 @@ local_alloc ()\n \n       next_qty = 0;\n \n-      block_alloc (b->sindex);\n+      block_alloc (b);\n     }\n \n   free (qty);\n@@ -816,7 +815,7 @@ static void\n update_equiv_regs ()\n {\n   rtx insn;\n-  basic_block bb;\n+  int block;\n   int loop_depth;\n   regset_head cleared_regs;\n   int clear_regnos = 0;\n@@ -829,8 +828,9 @@ update_equiv_regs ()\n   /* Scan the insns and find which registers have equivalences.  Do this\n      in a separate scan of the insns because (due to -fcse-follow-jumps)\n      a register can be set below its use.  */\n-  FOR_ALL_BB (bb)\n+  for (block = 0; block < n_basic_blocks; block++)\n     {\n+      basic_block bb = BASIC_BLOCK (block);\n       loop_depth = bb->loop_depth;\n \n       for (insn = bb->head; insn != NEXT_INSN (bb->end); insn = NEXT_INSN (insn))\n@@ -1044,8 +1044,10 @@ update_equiv_regs ()\n      within the same loop (or in an inner loop), then move the register\n      initialization just before the use, so that they are in the same\n      basic block.  */\n-  FOR_ALL_BB_REVERSE (bb)\n+  for (block = n_basic_blocks - 1; block >= 0; block--)\n     {\n+      basic_block bb = BASIC_BLOCK (block);\n+\n       loop_depth = bb->loop_depth;\n       for (insn = bb->end; insn != PREV_INSN (bb->head); insn = PREV_INSN (insn))\n \t{\n@@ -1137,12 +1139,12 @@ update_equiv_regs ()\n \n \t\t      XEXP (reg_equiv[regno].init_insns, 0) = new_insn;\n \n-\t\t      REG_BASIC_BLOCK (regno) = bb->sindex;\n+\t\t      REG_BASIC_BLOCK (regno) = block >= 0 ? block : 0;\n \t\t      REG_N_CALLS_CROSSED (regno) = 0;\n \t\t      REG_LIVE_LENGTH (regno) = 2;\n \n-\t\t      if (insn == bb->head)\n-\t\t\tbb->head = PREV_INSN (insn);\n+\t\t      if (block >= 0 && insn == BLOCK_HEAD (block))\n+\t\t\tBLOCK_HEAD (block) = PREV_INSN (insn);\n \n \t\t      /* Remember to clear REGNO from all basic block's live\n \t\t\t info.  */\n@@ -1157,22 +1159,24 @@ update_equiv_regs ()\n   /* Clear all dead REGNOs from all basic block's live info.  */\n   if (clear_regnos)\n     {\n-      int j;\n+      int j, l;\n       if (clear_regnos > 8)\n         {\n-\t  FOR_ALL_BB (bb)\n+\t  for (l = 0; l < n_basic_blocks; l++)\n \t    {\n-\t      AND_COMPL_REG_SET (bb->global_live_at_start, &cleared_regs);\n-\t      AND_COMPL_REG_SET (bb->global_live_at_end, &cleared_regs);\n+\t      AND_COMPL_REG_SET (BASIC_BLOCK (l)->global_live_at_start,\n+\t                         &cleared_regs);\n+\t      AND_COMPL_REG_SET (BASIC_BLOCK (l)->global_live_at_end,\n+\t                         &cleared_regs);\n \t    }\n \t}\n       else\n         EXECUTE_IF_SET_IN_REG_SET (&cleared_regs, 0, j,\n           {\n-\t    FOR_ALL_BB (bb)\n+\t    for (l = 0; l < n_basic_blocks; l++)\n \t      {\n-\t        CLEAR_REGNO_REG_SET (bb->global_live_at_start, j);\n-\t        CLEAR_REGNO_REG_SET (bb->global_live_at_end, j);\n+\t        CLEAR_REGNO_REG_SET (BASIC_BLOCK (l)->global_live_at_start, j);\n+\t        CLEAR_REGNO_REG_SET (BASIC_BLOCK (l)->global_live_at_end, j);\n \t      }\n \t  });\n     }"}, {"sha": "7d3c5b2eebe622a0b89d1cf592f9a9ee51c6227d", "filename": "gcc/loop.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Floop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Floop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -10785,7 +10785,7 @@ loop_dump_aux (loop, file, verbose)\n       /* This can happen when a marked loop appears as two nested loops,\n \t say from while (a || b) {}.  The inner loop won't match\n \t the loop markers but the outer one will.  */\n-      if (LOOP_BLOCK_NUM (loop->cont) != loop->latch->sindex)\n+      if (LOOP_BLOCK_NUM (loop->cont) != loop->latch->index)\n \tfprintf (file, \";;  NOTE_INSN_LOOP_CONT not in loop latch\\n\");\n     }\n }"}, {"sha": "f457817956d5612f7e47f3a40181be372a087aec", "filename": "gcc/predict.c", "status": "modified", "additions": 106, "deletions": 75, "changes": 181, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fpredict.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fpredict.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpredict.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -319,7 +319,7 @@ combine_predictions_for_insn (insn, bb)\n \n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \"Predictions for insn %i bb %i\\n\", INSN_UID (insn),\n-\t     bb->sindex);\n+\t     bb->index);\n \n   /* We implement \"first match\" heuristics and use probability guessed\n      by predictor with smallest index.  In the future we will use better\n@@ -409,26 +409,26 @@ estimate_probability (loops_info)\n      struct loops *loops_info;\n {\n   sbitmap *dominators, *post_dominators;\n-  basic_block bb;\n   int i;\n \n-  dominators = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n-  post_dominators = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n+  dominators = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n+  post_dominators = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n   calculate_dominance_info (NULL, dominators, CDI_DOMINATORS);\n   calculate_dominance_info (NULL, post_dominators, CDI_POST_DOMINATORS);\n \n   /* Try to predict out blocks in a loop that are not part of a\n      natural loop.  */\n   for (i = 0; i < loops_info->num; i++)\n     {\n+      int j;\n       int exits;\n       struct loop *loop = &loops_info->array[i];\n \n       flow_loop_scan (loops_info, loop, LOOP_EXIT_EDGES);\n       exits = loop->num_exits;\n \n-      FOR_BB_BETWEEN (bb, loop->first, loop->last->next_bb, next_bb)\n-\tif (TEST_BIT (loop->nodes, bb->sindex))\n+      for (j = loop->first->index; j <= loop->last->index; ++j)\n+\tif (TEST_BIT (loop->nodes, j))\n \t  {\n \t    int header_found = 0;\n \t    edge e;\n@@ -437,12 +437,12 @@ estimate_probability (loops_info)\n \t     statements construct loops via \"non-loop\" constructs\n \t     in the source language and are better to be handled\n \t     separately.  */\n-\t  if (predicted_by_p (bb, PRED_CONTINUE))\n+\t  if (predicted_by_p (BASIC_BLOCK (j), PRED_CONTINUE))\n \t    continue;\n \n \t    /* Loop branch heuristics - predict an edge back to a\n \t       loop's head as taken.  */\n-\t    for (e = bb->succ; e; e = e->succ_next)\n+\t    for (e = BASIC_BLOCK(j)->succ; e; e = e->succ_next)\n \t      if (e->dest == loop->header\n \t\t  && e->src == loop->latch)\n \t\t{\n@@ -453,9 +453,9 @@ estimate_probability (loops_info)\n \t    /* Loop exit heuristics - predict an edge exiting the loop if the\n \t       conditinal has no loop header successors as not taken.  */\n \t    if (!header_found)\n-\t      for (e = bb->succ; e; e = e->succ_next)\n-\t\tif (e->dest->sindex < 0\n-\t\t    || !TEST_BIT (loop->nodes, e->dest->sindex))\n+\t      for (e = BASIC_BLOCK(j)->succ; e; e = e->succ_next)\n+\t\tif (e->dest->index < 0\n+\t\t    || !TEST_BIT (loop->nodes, e->dest->index))\n \t\t  predict_edge\n \t\t    (e, PRED_LOOP_EXIT,\n \t\t     (REG_BR_PROB_BASE\n@@ -465,8 +465,9 @@ estimate_probability (loops_info)\n     }\n \n   /* Attempt to predict conditional jumps using a number of heuristics.  */\n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx last_insn = bb->end;\n       rtx cond, earliest;\n       edge e;\n@@ -491,8 +492,8 @@ estimate_probability (loops_info)\n \t  /* Look for block we are guarding (ie we dominate it,\n \t     but it doesn't postdominate us).  */\n \t  if (e->dest != EXIT_BLOCK_PTR && e->dest != bb\n-\t      && TEST_BIT (dominators[e->dest->sindex], e->src->sindex)\n-\t      && !TEST_BIT (post_dominators[e->src->sindex], e->dest->sindex))\n+\t      && TEST_BIT (dominators[e->dest->index], e->src->index)\n+\t      && !TEST_BIT (post_dominators[e->src->index], e->dest->index))\n \t    {\n \t      rtx insn;\n \n@@ -603,11 +604,11 @@ estimate_probability (loops_info)\n     }\n \n   /* Attach the combined probability to each conditional jump.  */\n-  FOR_ALL_BB (bb)\n-    if (GET_CODE (bb->end) == JUMP_INSN\n-\t&& any_condjump_p (bb->end)\n-\t&& bb->succ->succ_next != NULL)\n-      combine_predictions_for_insn (bb->end, bb);\n+  for (i = 0; i < n_basic_blocks; i++)\n+    if (GET_CODE (BLOCK_END (i)) == JUMP_INSN\n+\t&& any_condjump_p (BLOCK_END (i))\n+\t&& BASIC_BLOCK (i)->succ->succ_next != NULL)\n+      combine_predictions_for_insn (BLOCK_END (i), BASIC_BLOCK (i));\n \n   sbitmap_vector_free (post_dominators);\n   sbitmap_vector_free (dominators);\n@@ -694,16 +695,13 @@ static bool\n last_basic_block_p (bb)\n      basic_block bb;\n {\n-  if (bb == EXIT_BLOCK_PTR)\n-    return false;\n-\n-  return (bb->next_bb == EXIT_BLOCK_PTR\n-\t  || (bb->next_bb->next_bb == EXIT_BLOCK_PTR\n+  return (bb->index == n_basic_blocks - 1\n+\t  || (bb->index == n_basic_blocks - 2\n \t      && bb->succ && !bb->succ->succ_next\n-\t      && bb->succ->dest->next_bb == EXIT_BLOCK_PTR));\n+\t      && bb->succ->dest->index == n_basic_blocks - 1));\n }\n \n-/* Sets branch probabilities according to PREDiction and FLAGS. HEADS[bb->sindex]\n+/* Sets branch probabilities according to PREDiction and FLAGS. HEADS[bb->index]\n    should be index of basic block in that we need to alter branch predictions\n    (i.e. the first of our dominators such that we do not post-dominate it)\n    (but we fill this information on demand, so -1 may be there in case this\n@@ -724,43 +722,43 @@ process_note_prediction (bb, heads, dominators, post_dominators, pred, flags)\n \n   taken = flags & IS_TAKEN;\n \n-  if (heads[bb->sindex] < 0)\n+  if (heads[bb->index] < 0)\n     {\n       /* This is first time we need this field in heads array; so\n          find first dominator that we do not post-dominate (we are\n          using already known members of heads array).  */\n-      int ai = bb->sindex;\n-      int next_ai = dominators[bb->sindex];\n+      int ai = bb->index;\n+      int next_ai = dominators[bb->index];\n       int head;\n \n       while (heads[next_ai] < 0)\n \t{\n-\t  if (!TEST_BIT (post_dominators[next_ai], bb->sindex))\n+\t  if (!TEST_BIT (post_dominators[next_ai], bb->index))\n \t    break;\n \t  heads[next_ai] = ai;\n \t  ai = next_ai;\n \t  next_ai = dominators[next_ai];\n \t}\n-      if (!TEST_BIT (post_dominators[next_ai], bb->sindex))\n+      if (!TEST_BIT (post_dominators[next_ai], bb->index))\n \thead = next_ai;\n       else\n \thead = heads[next_ai];\n-      while (next_ai != bb->sindex)\n+      while (next_ai != bb->index)\n \t{\n \t  next_ai = ai;\n \t  ai = heads[ai];\n \t  heads[next_ai] = head;\n \t}\n     }\n-  y = heads[bb->sindex];\n+  y = heads[bb->index];\n \n   /* Now find the edge that leads to our branch and aply the prediction.  */\n \n-  if (y == last_basic_block)\n+  if (y == n_basic_blocks)\n     return;\n   for (e = BASIC_BLOCK (y)->succ; e; e = e->succ_next)\n-    if (e->dest->sindex >= 0\n-\t&& TEST_BIT (post_dominators[e->dest->sindex], bb->sindex))\n+    if (e->dest->index >= 0\n+\t&& TEST_BIT (post_dominators[e->dest->index], bb->index))\n       predict_edge_def (e, pred, taken);\n }\n \n@@ -833,28 +831,31 @@ process_note_predictions (bb, heads, dominators, post_dominators)\n void\n note_prediction_to_br_prob ()\n {\n-  basic_block bb;\n+  int i;\n   sbitmap *post_dominators;\n   int *dominators, *heads;\n \n   /* To enable handling of noreturn blocks.  */\n   add_noreturn_fake_exit_edges ();\n   connect_infinite_loops_to_exit ();\n \n-  dominators = xmalloc (sizeof (int) * last_basic_block);\n-  memset (dominators, -1, sizeof (int) * last_basic_block);\n-  post_dominators = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n+  dominators = xmalloc (sizeof (int) * n_basic_blocks);\n+  memset (dominators, -1, sizeof (int) * n_basic_blocks);\n+  post_dominators = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n   calculate_dominance_info (NULL, post_dominators, CDI_POST_DOMINATORS);\n   calculate_dominance_info (dominators, NULL, CDI_DOMINATORS);\n \n-  heads = xmalloc (sizeof (int) * last_basic_block);\n-  memset (heads, -1, sizeof (int) * last_basic_block);\n-  heads[ENTRY_BLOCK_PTR->next_bb->sindex] = last_basic_block;\n+  heads = xmalloc (sizeof (int) * n_basic_blocks);\n+  memset (heads, -1, sizeof (int) * n_basic_blocks);\n+  heads[0] = n_basic_blocks;\n \n   /* Process all prediction notes.  */\n \n-  FOR_ALL_BB (bb)\n-    process_note_predictions (bb, heads, dominators, post_dominators);\n+  for (i = 0; i < n_basic_blocks; ++i)\n+    {\n+      basic_block bb = BASIC_BLOCK (i);\n+      process_note_predictions (bb, heads, dominators, post_dominators);\n+    }\n \n   sbitmap_vector_free (post_dominators);\n   free (dominators);\n@@ -902,15 +903,17 @@ static void\n propagate_freq (head)\n      basic_block head;\n {\n-  basic_block bb;\n-  basic_block last;\n+  basic_block bb = head;\n+  basic_block last = bb;\n   edge e;\n   basic_block nextbb;\n+  int n;\n \n   /* For each basic block we need to visit count number of his predecessors\n      we need to visit first.  */\n-  FOR_ALL_BB (bb)\n+  for (n = 0; n < n_basic_blocks; n++)\n     {\n+      basic_block bb = BASIC_BLOCK (n);\n       if (BLOCK_INFO (bb)->tovisit)\n \t{\n \t  int count = 0;\n@@ -922,14 +925,13 @@ propagate_freq (head)\n \t\t     && rtl_dump_file && !EDGE_INFO (e)->back_edge)\n \t      fprintf (rtl_dump_file,\n \t\t       \"Irreducible region hit, ignoring edge to %i->%i\\n\",\n-\t\t       e->src->sindex, bb->sindex);\n+\t\t       e->src->index, bb->index);\n \t  BLOCK_INFO (bb)->npredecessors = count;\n \t}\n     }\n \n   memcpy (&BLOCK_INFO (head)->frequency, &real_one, sizeof (real_one));\n-  last = head;\n-  for (bb = head; bb; bb = nextbb)\n+  for (; bb; bb = nextbb)\n     {\n       REAL_VALUE_TYPE cyclic_probability, frequency;\n \n@@ -1072,13 +1074,24 @@ static void\n counts_to_freqs ()\n {\n   HOST_WIDEST_INT count_max = 1;\n-  basic_block bb;\n+  int i;\n+\n+  for (i = 0; i < n_basic_blocks; i++)\n+    count_max = MAX (BASIC_BLOCK (i)->count, count_max);\n \n-  FOR_ALL_BB (bb)\n-    count_max = MAX (bb->count, count_max);\n+  for (i = -2; i < n_basic_blocks; i++)\n+    {\n+      basic_block bb;\n+\n+      if (i == -2)\n+\tbb = ENTRY_BLOCK_PTR;\n+      else if (i == -1)\n+\tbb = EXIT_BLOCK_PTR;\n+      else\n+\tbb = BASIC_BLOCK (i);\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n-    bb->frequency = (bb->count * BB_FREQ_MAX + count_max / 2) / count_max;\n+      bb->frequency = (bb->count * BB_FREQ_MAX + count_max / 2) / count_max;\n+    }\n }\n \n /* Return true if function is likely to be expensive, so there is no point to\n@@ -1091,7 +1104,7 @@ expensive_function_p (threshold)\n \tint threshold;\n {\n   unsigned int sum = 0;\n-  basic_block bb;\n+  int i;\n   unsigned int limit;\n \n   /* We can not compute accurately for large thresholds due to scaled\n@@ -1107,8 +1120,9 @@ expensive_function_p (threshold)\n     \n   /* Maximally BB_FREQ_MAX^2 so overflow won't happen.  */\n   limit = ENTRY_BLOCK_PTR->frequency * threshold;\n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx insn;\n \n       for (insn = bb->head; insn != NEXT_INSN (bb->end);\n@@ -1130,7 +1144,7 @@ static void\n estimate_bb_frequencies (loops)\n      struct loops *loops;\n {\n-  basic_block bb;\n+  int i;\n   REAL_VALUE_TYPE freq_max;\n   enum machine_mode double_mode = TYPE_MODE (double_type_node);\n \n@@ -1152,28 +1166,28 @@ estimate_bb_frequencies (loops)\n       mark_dfs_back_edges ();\n       /* Fill in the probability values in flowgraph based on the REG_BR_PROB\n          notes.  */\n-      FOR_ALL_BB (bb)\n+      for (i = 0; i < n_basic_blocks; i++)\n \t{\n-\t  rtx last_insn = bb->end;\n+\t  rtx last_insn = BLOCK_END (i);\n \n \t  if (GET_CODE (last_insn) != JUMP_INSN || !any_condjump_p (last_insn)\n \t      /* Avoid handling of conditional jumps jumping to fallthru edge.  */\n-\t      || bb->succ->succ_next == NULL)\n+\t      || BASIC_BLOCK (i)->succ->succ_next == NULL)\n \t    {\n \t      /* We can predict only conditional jumps at the moment.\n \t         Expect each edge to be equally probable.\n \t         ?? In the future we want to make abnormal edges improbable.  */\n \t      int nedges = 0;\n \t      edge e;\n \n-\t      for (e = bb->succ; e; e = e->succ_next)\n+\t      for (e = BASIC_BLOCK (i)->succ; e; e = e->succ_next)\n \t\t{\n \t\t  nedges++;\n \t\t  if (e->probability != 0)\n \t\t    break;\n \t\t}\n \t      if (!e)\n-\t\tfor (e = bb->succ; e; e = e->succ_next)\n+\t\tfor (e = BASIC_BLOCK (i)->succ; e; e = e->succ_next)\n \t\t  e->probability = (REG_BR_PROB_BASE + nedges / 2) / nedges;\n \t    }\n \t}\n@@ -1183,10 +1197,17 @@ estimate_bb_frequencies (loops)\n       /* Set up block info for each basic block.  */\n       alloc_aux_for_blocks (sizeof (struct block_info_def));\n       alloc_aux_for_edges (sizeof (struct edge_info_def));\n-\n-      FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+      for (i = -2; i < n_basic_blocks; i++)\n \t{\n \t  edge e;\n+\t  basic_block bb;\n+\n+\t  if (i == -2)\n+\t    bb = ENTRY_BLOCK_PTR;\n+\t  else if (i == -1)\n+\t    bb = EXIT_BLOCK_PTR;\n+\t  else\n+\t    bb = BASIC_BLOCK (i);\n \n \t  BLOCK_INFO (bb)->tovisit = 0;\n \t  for (e = bb->succ; e; e = e->succ_next)\n@@ -1205,22 +1226,32 @@ estimate_bb_frequencies (loops)\n       estimate_loops_at_level (loops->tree_root);\n \n       /* Now fake loop around whole function to finalize probabilities.  */\n-      FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n-\tBLOCK_INFO (bb)->tovisit = 1;\n+      for (i = 0; i < n_basic_blocks; i++)\n+\tBLOCK_INFO (BASIC_BLOCK (i))->tovisit = 1;\n \n+      BLOCK_INFO (ENTRY_BLOCK_PTR)->tovisit = 1;\n+      BLOCK_INFO (EXIT_BLOCK_PTR)->tovisit = 1;\n       propagate_freq (ENTRY_BLOCK_PTR);\n \n       memcpy (&freq_max, &real_zero, sizeof (real_zero));\n-      FOR_ALL_BB (bb)\n+      for (i = 0; i < n_basic_blocks; i++)\n \tif (REAL_VALUES_LESS\n-\t    (freq_max, BLOCK_INFO (bb)->frequency))\n-\t  memcpy (&freq_max, &BLOCK_INFO (bb)->frequency,\n+\t    (freq_max, BLOCK_INFO (BASIC_BLOCK (i))->frequency))\n+\t  memcpy (&freq_max, &BLOCK_INFO (BASIC_BLOCK (i))->frequency,\n \t\t  sizeof (freq_max));\n \n-      FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+      for (i = -2; i < n_basic_blocks; i++)\n \t{\n+\t  basic_block bb;\n \t  REAL_VALUE_TYPE tmp;\n \n+\t  if (i == -2)\n+\t    bb = ENTRY_BLOCK_PTR;\n+\t  else if (i == -1)\n+\t    bb = EXIT_BLOCK_PTR;\n+\t  else\n+\t    bb = BASIC_BLOCK (i);\n+\n \t  REAL_ARITHMETIC (tmp, MULT_EXPR, BLOCK_INFO (bb)->frequency,\n \t\t\t   real_bb_freq_max);\n \t  REAL_ARITHMETIC (tmp, RDIV_EXPR, tmp, freq_max);\n@@ -1240,14 +1271,14 @@ estimate_bb_frequencies (loops)\n static void\n compute_function_frequency ()\n {\n-  basic_block bb;\n-\n+  int i;\n   if (!profile_info.count_profiles_merged\n       || !flag_branch_probabilities)\n     return;\n   cfun->function_frequency = FUNCTION_FREQUENCY_UNLIKELY_EXECUTED;\n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       if (maybe_hot_bb_p (bb))\n \t{\n \t  cfun->function_frequency = FUNCTION_FREQUENCY_HOT;"}, {"sha": "8cd339ab9891ba6d4a8e46568271917c4782c051", "filename": "gcc/print-rtl.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fprint-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fprint-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fprint-rtl.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -265,7 +265,7 @@ print_rtx (in_rtx)\n \t\t{\n \t\t  basic_block bb = NOTE_BASIC_BLOCK (in_rtx);\n \t\t  if (bb != 0)\n-\t\t    fprintf (outfile, \" [bb %d]\", bb->sindex);\n+\t\t    fprintf (outfile, \" [bb %d]\", bb->index);\n \t\t  break;\n \t        }\n "}, {"sha": "60159a3e3228aba8cd839719057e9a153ea2e030", "filename": "gcc/profile.c", "status": "modified", "additions": 55, "deletions": 44, "changes": 99, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fprofile.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fprofile.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fprofile.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -73,11 +73,11 @@ struct bb_info\n /* Keep all basic block indexes nonnegative in the gcov output.  Index 0\n    is used for entry block, last block exit block.  */\n #define GCOV_INDEX_TO_BB(i)  ((i) == 0 ? ENTRY_BLOCK_PTR\t\t\\\n-\t\t\t      : (((i) == last_basic_block + 1)\t\t\\\n+\t\t\t      : (((i) == n_basic_blocks + 1)\t\t\\\n \t\t\t         ? EXIT_BLOCK_PTR : BASIC_BLOCK ((i)-1)))\n #define BB_TO_GCOV_INDEX(bb)  ((bb) == ENTRY_BLOCK_PTR ? 0\t\t\\\n \t\t\t       : ((bb) == EXIT_BLOCK_PTR\t\t\\\n-\t\t\t\t  ? last_basic_block + 1 : (bb)->sindex + 1))\n+\t\t\t\t  ? n_basic_blocks + 1 : (bb)->index + 1))\n \n /* Instantiate the profile info structure.  */\n \n@@ -137,13 +137,14 @@ static void\n instrument_edges (el)\n      struct edge_list *el;\n {\n+  int i;\n   int num_instr_edges = 0;\n   int num_edges = NUM_EDGES (el);\n-  basic_block bb;\n   remove_fake_edges ();\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+  for (i = 0; i < n_basic_blocks + 2; i++)\n     {\n+      basic_block bb = GCOV_INDEX_TO_BB (i);\n       edge e = bb->succ;\n       while (e)\n \t{\n@@ -154,7 +155,7 @@ instrument_edges (el)\n \t\tabort ();\n \t      if (rtl_dump_file)\n \t\tfprintf (rtl_dump_file, \"Edge %d to %d instrumented%s\\n\",\n-\t\t\t e->src->sindex, e->dest->sindex,\n+\t\t\t e->src->index, e->dest->index,\n \t\t\t EDGE_CRITICAL_P (e) ? \" (and split)\" : \"\");\n \t      need_func_profiler = 1;\n \t      insert_insn_on_edge (\n@@ -215,8 +216,8 @@ static gcov_type *\n get_exec_counts ()\n {\n   int num_edges = 0;\n-  basic_block bb;\n-  int okay = 1, j;\n+  int i;\n+  int okay = 1;\n   int mismatch = 0;\n   gcov_type *profile;\n   char *function_name_buffer;\n@@ -232,12 +233,15 @@ get_exec_counts ()\n \n   /* Count the edges to be (possibly) instrumented.  */\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+  for (i = 0; i < n_basic_blocks + 2; i++)\n     {\n+      basic_block bb = GCOV_INDEX_TO_BB (i);\n       edge e;\n       for (e = bb->succ; e; e = e->succ_next)\n \tif (!EDGE_INFO (e)->ignore && !EDGE_INFO (e)->on_tree)\n-\t  num_edges++;\n+\t  {\n+\t    num_edges++;\n+\t  }\n     }\n \n   /* now read and combine all matching profiles. */\n@@ -247,8 +251,8 @@ get_exec_counts ()\n   function_name_buffer_len = strlen (current_function_name) + 1;\n   function_name_buffer = xmalloc (function_name_buffer_len + 1);\n \n-  for (j = 0; j < num_edges; j++)\n-    profile[j] = 0;\n+  for (i = 0; i < num_edges; i++)\n+    profile[i] = 0;\n \n   while (1)\n     {\n@@ -372,8 +376,8 @@ get_exec_counts ()\n static void\n compute_branch_probabilities ()\n {\n-  basic_block bb;\n-  int num_edges = 0, i;\n+  int i;\n+  int num_edges = 0;\n   int changes;\n   int passes;\n   int hist_br_prob[20];\n@@ -385,8 +389,9 @@ compute_branch_probabilities ()\n   /* Attach extra info block to each bb.  */\n \n   alloc_aux_for_blocks (sizeof (struct bb_info));\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+  for (i = 0; i < n_basic_blocks + 2; i++)\n     {\n+      basic_block bb = GCOV_INDEX_TO_BB (i);\n       edge e;\n \n       for (e = bb->succ; e; e = e->succ_next)\n@@ -407,8 +412,9 @@ compute_branch_probabilities ()\n   /* The first count in the .da file is the number of times that the function\n      was entered.  This is the exec_count for block zero.  */\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+  for (i = 0; i < n_basic_blocks + 2; i++)\n     {\n+      basic_block bb = GCOV_INDEX_TO_BB (i);\n       edge e;\n       for (e = bb->succ; e; e = e->succ_next)\n \tif (!EDGE_INFO (e)->ignore && !EDGE_INFO (e)->on_tree)\n@@ -427,7 +433,7 @@ compute_branch_probabilities ()\n \t    if (rtl_dump_file)\n \t      {\n \t\tfprintf (rtl_dump_file, \"\\nRead edge from %i to %i, count:\",\n-\t\t\t bb->sindex, e->dest->sindex);\n+\t\t\t bb->index, e->dest->index);\n \t\tfprintf (rtl_dump_file, HOST_WIDEST_INT_PRINT_DEC,\n \t\t\t (HOST_WIDEST_INT) e->count);\n \t      }\n@@ -460,8 +466,9 @@ compute_branch_probabilities ()\n     {\n       passes++;\n       changes = 0;\n-      FOR_BB_BETWEEN (bb, EXIT_BLOCK_PTR, NULL, prev_bb)\n+      for (i = n_basic_blocks + 1; i >= 0; i--)\n \t{\n+\t  basic_block bb = GCOV_INDEX_TO_BB (i);\n \t  struct bb_info *bi = BB_INFO (bb);\n \t  if (! bi->count_valid)\n \t    {\n@@ -556,8 +563,9 @@ compute_branch_probabilities ()\n \n   /* If the graph has been correctly solved, every block will have a\n      succ and pred count of zero.  */\n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       if (BB_INFO (bb)->succ_count || BB_INFO (bb)->pred_count)\n \tabort ();\n     }\n@@ -570,8 +578,9 @@ compute_branch_probabilities ()\n   num_never_executed = 0;\n   num_branches = 0;\n \n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+  for (i = 0; i <= n_basic_blocks + 1; i++)\n     {\n+      basic_block bb = GCOV_INDEX_TO_BB (i);\n       edge e;\n       gcov_type total;\n       rtx note;\n@@ -585,11 +594,11 @@ compute_branch_probabilities ()\n \t\tif (e->probability < 0 || e->probability > REG_BR_PROB_BASE)\n \t\t  {\n \t\t    error (\"corrupted profile info: prob for %d-%d thought to be %d\",\n-\t\t\t   e->src->sindex, e->dest->sindex, e->probability);\n+\t\t\t   e->src->index, e->dest->index, e->probability);\n \t\t    e->probability = REG_BR_PROB_BASE / 2;\n \t\t  }\n \t    }\n-\t  if (bb->sindex >= 0\n+\t  if (bb->index >= 0\n \t      && any_condjump_p (bb->end)\n \t      && bb->succ->succ_next)\n \t    {\n@@ -646,7 +655,7 @@ compute_branch_probabilities ()\n \t      for (e = bb->succ; e; e = e->succ_next)\n \t\te->probability = REG_BR_PROB_BASE / total;\n \t    }\n-\t  if (bb->sindex >= 0\n+\t  if (bb->index >= 0\n \t      && any_condjump_p (bb->end)\n \t      && bb->succ->succ_next)\n \t    num_branches++, num_never_executed;\n@@ -687,10 +696,12 @@ static long\n compute_checksum ()\n {\n   long chsum = 0;\n-  basic_block bb;\n+  int i;\n \n-  FOR_ALL_BB (bb)\n+  \n+  for (i = 0; i < n_basic_blocks ; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       edge e;\n \n       for (e = bb->succ; e; e = e->succ_next)\n@@ -723,7 +734,6 @@ compute_checksum ()\n void\n branch_prob ()\n {\n-  basic_block bb;\n   int i;\n   int num_edges, ignored_edges;\n   struct edge_list *el;\n@@ -752,10 +762,11 @@ branch_prob ()\n      We also add fake exit edges for each call and asm statement in the\n      basic, since it may not return.  */\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks ; i++)\n     {\n       int need_exit_edge = 0, need_entry_edge = 0;\n       int have_exit_edge = 0, have_entry_edge = 0;\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx insn;\n       edge e;\n \n@@ -780,7 +791,7 @@ branch_prob ()\n \t\t{\n \t\t  /* We should not get abort here, as call to setjmp should not\n \t\t     be the very first instruction of function.  */\n-\t\t  if (bb == ENTRY_BLOCK_PTR)\n+\t\t  if (!i)\n \t\t    abort ();\n \t\t  make_edge (ENTRY_BLOCK_PTR, bb, EDGE_FAKE);\n \t\t}\n@@ -808,14 +819,14 @@ branch_prob ()\n \t{\n \t  if (rtl_dump_file)\n \t    fprintf (rtl_dump_file, \"Adding fake exit edge to bb %i\\n\",\n-\t\t     bb->sindex);\n+\t\t     bb->index);\n           make_edge (bb, EXIT_BLOCK_PTR, EDGE_FAKE);\n \t}\n       if (need_entry_edge && !have_entry_edge)\n \t{\n \t  if (rtl_dump_file)\n \t    fprintf (rtl_dump_file, \"Adding fake entry edge to bb %i\\n\",\n-\t\t     bb->sindex);\n+\t\t     bb->index);\n           make_edge (ENTRY_BLOCK_PTR, bb, EDGE_FAKE);\n \t}\n     }\n@@ -847,10 +858,10 @@ branch_prob ()\n      GCOV utility.  */\n   if (flag_test_coverage)\n     {\n-      basic_block bb;\n-\n-      FOR_ALL_BB (bb)\n+      int i = 0;\n+      for (i = 0 ; i < n_basic_blocks; i++)\n         {\n+\t  basic_block bb = BASIC_BLOCK (i);\n \t  rtx insn = bb->head;\n           static int ignore_next_note = 0;\n \n@@ -928,9 +939,9 @@ branch_prob ()\n         }\n     }\n \n-  total_num_blocks += num_basic_blocks + 2;\n+  total_num_blocks += n_basic_blocks + 2;\n   if (rtl_dump_file)\n-    fprintf (rtl_dump_file, \"%d basic blocks\\n\", num_basic_blocks);\n+    fprintf (rtl_dump_file, \"%d basic blocks\\n\", n_basic_blocks);\n \n   total_num_edges += num_edges;\n   if (rtl_dump_file)\n@@ -956,11 +967,12 @@ branch_prob ()\n       __write_long (profile_info.current_function_cfg_checksum, bbg_file, 4);\n       \n       /* The plus 2 stands for entry and exit block.  */\n-      __write_long (num_basic_blocks + 2, bbg_file, 4);\n+      __write_long (n_basic_blocks + 2, bbg_file, 4);\n       __write_long (num_edges - ignored_edges + 1, bbg_file, 4);\n \n-      FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, NULL, next_bb)\n+      for (i = 0; i < n_basic_blocks + 1; i++)\n \t{\n+\t  basic_block bb = GCOV_INDEX_TO_BB (i);\n \t  edge e;\n \t  long count = 0;\n \n@@ -1069,14 +1081,13 @@ find_spanning_tree (el)\n      struct edge_list *el;\n {\n   int i;\n-  basic_block bb;\n   int num_edges = NUM_EDGES (el);\n \n   /* We use aux field for standard union-find algorithm.  */\n   EXIT_BLOCK_PTR->aux = EXIT_BLOCK_PTR;\n   ENTRY_BLOCK_PTR->aux = ENTRY_BLOCK_PTR;\n-  FOR_ALL_BB (bb)\n-    bb->aux = bb;\n+  for (i = 0; i < n_basic_blocks; i++)\n+    BASIC_BLOCK (i)->aux = BASIC_BLOCK (i);\n \n   /* Add fake edge exit to entry we can't instrument.  */\n   union_groups (EXIT_BLOCK_PTR, ENTRY_BLOCK_PTR);\n@@ -1095,7 +1106,7 @@ find_spanning_tree (el)\n \t{\n \t  if (rtl_dump_file)\n \t    fprintf (rtl_dump_file, \"Abnormal edge %d to %d put to tree\\n\",\n-                     e->src->sindex, e->dest->sindex);\n+                     e->src->index, e->dest->index);\n \t  EDGE_INFO (e)->on_tree = 1;\n \t  union_groups (e->src, e->dest);\n \t}\n@@ -1111,7 +1122,7 @@ find_spanning_tree (el)\n \t{\n \t  if (rtl_dump_file)\n \t    fprintf (rtl_dump_file, \"Critical edge %d to %d put to tree\\n\",\n-                     e->src->sindex, e->dest->sindex);\n+                     e->src->index, e->dest->index);\n \t  EDGE_INFO (e)->on_tree = 1;\n \t  union_groups (e->src, e->dest);\n \t}\n@@ -1126,16 +1137,16 @@ find_spanning_tree (el)\n \t{\n \t  if (rtl_dump_file)\n \t    fprintf (rtl_dump_file, \"Normal edge %d to %d put to tree\\n\",\n-                     e->src->sindex, e->dest->sindex);\n+                     e->src->index, e->dest->index);\n \t  EDGE_INFO (e)->on_tree = 1;\n \t  union_groups (e->src, e->dest);\n \t}\n     }\n \n   EXIT_BLOCK_PTR->aux = NULL;\n   ENTRY_BLOCK_PTR->aux = NULL;\n-  FOR_ALL_BB (bb)\n-    bb->aux = NULL;\n+  for (i = 0; i < n_basic_blocks; i++)\n+    BASIC_BLOCK (i)->aux = NULL;\n }\n \f\n /* Perform file-level initialization for branch-prob processing.  */"}, {"sha": "c3dbee29ee7c44bdc24527c59da55ad79add4db1", "filename": "gcc/recog.c", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Frecog.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Frecog.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frecog.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -2727,14 +2727,15 @@ split_all_insns (upd_life)\n {\n   sbitmap blocks;\n   int changed;\n-  basic_block bb;\n+  int i;\n \n-  blocks = sbitmap_alloc (last_basic_block);\n+  blocks = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (blocks);\n   changed = 0;\n \n-  FOR_ALL_BB_REVERSE (bb)\n+  for (i = n_basic_blocks - 1; i >= 0; --i)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx insn, next;\n       bool finish = false;\n \n@@ -2755,7 +2756,7 @@ split_all_insns (upd_life)\n \n \t      while (GET_CODE (last) == BARRIER)\n \t\tlast = PREV_INSN (last);\n-\t      SET_BIT (blocks, bb->sindex);\n+\t      SET_BIT (blocks, i);\n \t      changed = 1;\n \t      insn = last;\n \t    }\n@@ -2998,8 +2999,7 @@ peephole2_optimize (dump_file)\n   regset_head rs_heads[MAX_INSNS_PER_PEEP2 + 2];\n   rtx insn, prev;\n   regset live;\n-  int i;\n-  basic_block bb;\n+  int i, b;\n #ifdef HAVE_conditional_execution\n   sbitmap blocks;\n   bool changed;\n@@ -3013,15 +3013,16 @@ peephole2_optimize (dump_file)\n   live = INITIALIZE_REG_SET (rs_heads[i]);\n \n #ifdef HAVE_conditional_execution\n-  blocks = sbitmap_alloc (last_basic_block);\n+  blocks = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (blocks);\n   changed = false;\n #else\n   count_or_remove_death_notes (NULL, 1);\n #endif\n \n-  FOR_ALL_BB_REVERSE (bb)\n+  for (b = n_basic_blocks - 1; b >= 0; --b)\n     {\n+      basic_block bb = BASIC_BLOCK (b);\n       struct propagate_block_info *pbi;\n \n       /* Indicate that all slots except the last holds invalid data.  */"}, {"sha": "3e1a756d473b273d026ce37e3bd079b46d3ea861", "filename": "gcc/reg-stack.c", "status": "modified", "additions": 14, "deletions": 13, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Freg-stack.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Freg-stack.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freg-stack.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -418,8 +418,8 @@ reg_to_stack (first, file)\n      rtx first;\n      FILE *file;\n {\n-  basic_block bb;\n-  int max_uid, i;\n+  int i;\n+  int max_uid;\n \n   /* Clean up previous run.  */\n   if (stack_regs_mentioned_data)\n@@ -451,9 +451,10 @@ reg_to_stack (first, file)\n \n   /* Set up block info for each basic block.  */\n   alloc_aux_for_blocks (sizeof (struct block_info_def));\n-  FOR_ALL_BB_REVERSE (bb)\n+  for (i = n_basic_blocks - 1; i >= 0; --i)\n     {\n       edge e;\n+      basic_block bb = BASIC_BLOCK (i);\n       for (e = bb->pred; e; e=e->pred_next)\n \tif (!(e->flags & EDGE_DFS_BACK)\n \t    && e->src != ENTRY_BLOCK_PTR)\n@@ -2381,12 +2382,12 @@ print_stack (file, s)\n static int\n convert_regs_entry ()\n {\n-  int inserted = 0;\n+  int inserted = 0, i;\n   edge e;\n-  basic_block block;\n \n-  FOR_ALL_BB_REVERSE (block)\n+  for (i = n_basic_blocks - 1; i >= 0; --i)\n     {\n+      basic_block block = BASIC_BLOCK (i);\n       block_info bi = BLOCK_INFO (block);\n       int reg;\n \n@@ -2490,7 +2491,7 @@ compensate_edge (e, file)\n   current_block = block;\n   regstack = bi->stack_out;\n   if (file)\n-    fprintf (file, \"Edge %d->%d: \", block->sindex, target->sindex);\n+    fprintf (file, \"Edge %d->%d: \", block->index, target->index);\n \n   if (target_stack->top == -2)\n     {\n@@ -2650,7 +2651,7 @@ convert_regs_1 (file, block)\n \t  if (EDGE_CRITICAL_P (e))\n \t    beste = e;\n \t}\n-      else if (e->src->sindex < beste->src->sindex)\n+      else if (e->src->index < beste->src->index)\n \tbeste = e;\n     }\n \n@@ -2664,7 +2665,7 @@ convert_regs_1 (file, block)\n \n   if (file)\n     {\n-      fprintf (file, \"\\nBasic block %d\\nInput stack: \", block->sindex);\n+      fprintf (file, \"\\nBasic block %d\\nInput stack: \", block->index);\n       print_stack (file, &bi->stack_in);\n     }\n \n@@ -2779,7 +2780,7 @@ convert_regs_2 (file, block)\n   basic_block *stack, *sp;\n   int inserted;\n \n-  stack = (basic_block *) xmalloc (sizeof (*stack) * num_basic_blocks);\n+  stack = (basic_block *) xmalloc (sizeof (*stack) * n_basic_blocks);\n   sp = stack;\n \n   *sp++ = block;\n@@ -2814,8 +2815,7 @@ static int\n convert_regs (file)\n      FILE *file;\n {\n-  int inserted;\n-  basic_block b;\n+  int inserted, i;\n   edge e;\n \n   /* Initialize uninitialized registers on function entry.  */\n@@ -2835,8 +2835,9 @@ convert_regs (file)\n \n   /* ??? Process all unreachable blocks.  Though there's no excuse\n      for keeping these even when not optimizing.  */\n-  FOR_ALL_BB (b)\n+  for (i = 0; i < n_basic_blocks; ++i)\n     {\n+      basic_block b = BASIC_BLOCK (i);\n       block_info bi = BLOCK_INFO (b);\n \n       if (! bi->done)"}, {"sha": "decab26b4af9148dc9a75f172d7aaf78184b68e5", "filename": "gcc/regclass.c", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fregclass.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fregclass.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fregclass.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -1127,10 +1127,10 @@ scan_one_insn (insn, pass)\n \t INSN could not be at the beginning of that block.  */\n       if (previnsn == 0 || GET_CODE (previnsn) == JUMP_INSN)\n \t{\n-\t  basic_block b;\n-\t  FOR_ALL_BB (b)\n-\t    if (insn == b->head)\n-\t      b->head = newinsn;\n+\t  int b;\n+\t  for (b = 0; b < n_basic_blocks; b++)\n+\t    if (insn == BLOCK_HEAD (b))\n+\t      BLOCK_HEAD (b) = newinsn;\n \t}\n \n       /* This makes one more setting of new insns's dest.  */\n@@ -1255,7 +1255,7 @@ regclass (f, nregs, dump)\n \n   for (pass = 0; pass <= flag_expensive_optimizations; pass++)\n     {\n-      basic_block bb;\n+      int index;\n \n       if (dump)\n \tfprintf (dump, \"\\n\\nPass %i\\n\\n\",pass);\n@@ -1277,8 +1277,9 @@ regclass (f, nregs, dump)\n \t    insn = scan_one_insn (insn, pass);\n \t}\n       else\n-\tFOR_ALL_BB (bb)\n+\tfor (index = 0; index < n_basic_blocks; index++)\n \t  {\n+\t    basic_block bb = BASIC_BLOCK (index);\n \n \t    /* Show that an insn inside a loop is likely to be executed three\n \t       times more than insns outside a loop.  This is much more"}, {"sha": "7b073f29e7330b8a4abc869997bbe86cd8b645f6", "filename": "gcc/regmove.c", "status": "modified", "additions": 14, "deletions": 15, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fregmove.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fregmove.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fregmove.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -223,7 +223,7 @@ mark_flags_life_zones (flags)\n {\n   int flags_regno;\n   int flags_nregs;\n-  basic_block block;\n+  int block;\n \n #ifdef HAVE_cc0\n   /* If we found a flags register on a cc0 host, bail.  */\n@@ -254,13 +254,13 @@ mark_flags_life_zones (flags)\n   flags_set_1_rtx = flags;\n \n   /* Process each basic block.  */\n-  FOR_ALL_BB_REVERSE (block)\n+  for (block = n_basic_blocks - 1; block >= 0; block--)\n     {\n       rtx insn, end;\n       int live;\n \n-      insn = block->head;\n-      end = block->end;\n+      insn = BLOCK_HEAD (block);\n+      end = BLOCK_END (block);\n \n       /* Look out for the (unlikely) case of flags being live across\n \t basic block boundaries.  */\n@@ -269,7 +269,7 @@ mark_flags_life_zones (flags)\n       {\n \tint i;\n \tfor (i = 0; i < flags_nregs; ++i)\n-          live |= REGNO_REG_SET_P (block->global_live_at_start,\n+\t  live |= REGNO_REG_SET_P (BASIC_BLOCK (block)->global_live_at_start,\n \t\t\t\t   flags_regno + i);\n       }\n #endif\n@@ -1061,7 +1061,6 @@ regmove_optimize (f, nregs, regmove_dump_file)\n   int pass;\n   int i;\n   rtx copy_src, copy_dst;\n-  basic_block bb;\n \n   /* ??? Hack.  Regmove doesn't examine the CFG, and gets mightily\n      confused by non-call exceptions ending blocks.  */\n@@ -1077,8 +1076,8 @@ regmove_optimize (f, nregs, regmove_dump_file)\n \n   regmove_bb_head = (int *) xmalloc (sizeof (int) * (old_max_uid + 1));\n   for (i = old_max_uid; i >= 0; i--) regmove_bb_head[i] = -1;\n-  FOR_ALL_BB (bb)\n-    regmove_bb_head[INSN_UID (bb->head)] = bb->sindex;\n+  for (i = 0; i < n_basic_blocks; i++)\n+    regmove_bb_head[INSN_UID (BLOCK_HEAD (i))] = i;\n \n   /* A forward/backward pass.  Replace output operands with input operands.  */\n \n@@ -1505,15 +1504,15 @@ regmove_optimize (f, nregs, regmove_dump_file)\n \n   /* In fixup_match_1, some insns may have been inserted after basic block\n      ends.  Fix that here.  */\n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n-      rtx end = bb->end;\n+      rtx end = BLOCK_END (i);\n       rtx new = end;\n       rtx next = NEXT_INSN (new);\n       while (next != 0 && INSN_UID (next) >= old_max_uid\n-\t     && (bb->next_bb == EXIT_BLOCK_PTR || bb->next_bb->head != next))\n+\t     && (i == n_basic_blocks - 1 || BLOCK_HEAD (i + 1) != next))\n \tnew = next, next = NEXT_INSN (new);\n-      bb->end = new;\n+      BLOCK_END (i) = new;\n     }\n \n  done:\n@@ -2139,10 +2138,10 @@ static int record_stack_memrefs\tPARAMS ((rtx *, void *));\n void\n combine_stack_adjustments ()\n {\n-  basic_block bb;\n+  int i;\n \n-  FOR_ALL_BB (bb)\n-    combine_stack_adjustments_for_block (bb);\n+  for (i = 0; i < n_basic_blocks; ++i)\n+    combine_stack_adjustments_for_block (BASIC_BLOCK (i));\n }\n \n /* Recognize a MEM of the form (sp) or (plus sp const).  */"}, {"sha": "4297da7f32756cf8f4ee5f394dc0926c8d263f80", "filename": "gcc/regrename.c", "status": "modified", "additions": 14, "deletions": 13, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fregrename.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fregrename.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fregrename.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -201,24 +201,25 @@ regrename_optimize ()\n {\n   int tick[FIRST_PSEUDO_REGISTER];\n   int this_tick = 0;\n-  basic_block bb;\n+  int b;\n   char *first_obj;\n \n   memset (tick, 0, sizeof tick);\n \n   gcc_obstack_init (&rename_obstack);\n   first_obj = (char *) obstack_alloc (&rename_obstack, 0);\n \n-  FOR_ALL_BB (bb)\n+  for (b = 0; b < n_basic_blocks; b++)\n     {\n+      basic_block bb = BASIC_BLOCK (b);\n       struct du_chain *all_chains = 0;\n       HARD_REG_SET unavailable;\n       HARD_REG_SET regs_seen;\n \n       CLEAR_HARD_REG_SET (unavailable);\n \n       if (rtl_dump_file)\n-\tfprintf (rtl_dump_file, \"\\nBasic block %d:\\n\", bb->sindex);\n+\tfprintf (rtl_dump_file, \"\\nBasic block %d:\\n\", b);\n \n       all_chains = build_def_use (bb);\n \n@@ -1725,30 +1726,30 @@ copyprop_hardreg_forward ()\n {\n   struct value_data *all_vd;\n   bool need_refresh;\n-  basic_block bb, bbp;\n+  int b;\n \n   need_refresh = false;\n \n-  all_vd = xmalloc (sizeof (struct value_data) * last_basic_block);\n+  all_vd = xmalloc (sizeof (struct value_data) * n_basic_blocks);\n \n-  FOR_ALL_BB (bb)\n+  for (b = 0; b < n_basic_blocks; b++)\n     {\n+      basic_block bb = BASIC_BLOCK (b);\n+\n       /* If a block has a single predecessor, that we've already\n \t processed, begin with the value data that was live at\n \t the end of the predecessor block.  */\n       /* ??? Ought to use more intelligent queueing of blocks.  */\n-      if (bb->pred)\n-\tfor (bbp = bb; bbp && bbp != bb->pred->src; bbp = bbp->prev_bb);\n       if (bb->pred\n \t  && ! bb->pred->pred_next\n \t  && ! (bb->pred->flags & (EDGE_ABNORMAL_CALL | EDGE_EH))\n-\t  && bb->pred->src != ENTRY_BLOCK_PTR\n-\t  && bbp)\n-\tall_vd[bb->sindex] = all_vd[bb->pred->src->sindex];\n+\t  && bb->pred->src->index != ENTRY_BLOCK\n+\t  && bb->pred->src->index < b)\n+\tall_vd[b] = all_vd[bb->pred->src->index];\n       else\n-\tinit_value_data (all_vd + bb->sindex);\n+\tinit_value_data (all_vd + b);\n \n-      if (copyprop_hardreg_forward_1 (bb, all_vd + bb->sindex))\n+      if (copyprop_hardreg_forward_1 (bb, all_vd + b))\n \tneed_refresh = true;\n     }\n "}, {"sha": "1349c3c85598eb5b6178c6f9ca96c1925276132a", "filename": "gcc/reload1.c", "status": "modified", "additions": 9, "deletions": 10, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Freload1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Freload1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload1.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -676,7 +676,6 @@ reload (first, global)\n   int i;\n   rtx insn;\n   struct elim_table *ep;\n-  basic_block bb;\n \n   /* The two pointers used to track the true location of the memory used\n      for label offsets.  */\n@@ -1124,8 +1123,8 @@ reload (first, global)\n      pseudo.  */\n \n   if (! frame_pointer_needed)\n-    FOR_ALL_BB (bb)\n-      CLEAR_REGNO_REG_SET (bb->global_live_at_start,\n+    for (i = 0; i < n_basic_blocks; i++)\n+      CLEAR_REGNO_REG_SET (BASIC_BLOCK (i)->global_live_at_start,\n \t\t\t   HARD_FRAME_POINTER_REGNUM);\n \n   /* Come here (with failure set nonzero) if we can't get enough spill regs\n@@ -8613,7 +8612,6 @@ reload_combine ()\n   int first_index_reg = -1;\n   int last_index_reg = 0;\n   int i;\n-  basic_block bb;\n   unsigned int r;\n   int last_label_ruid;\n   int min_labelno, n_labels;\n@@ -8649,17 +8647,17 @@ reload_combine ()\n   label_live = (HARD_REG_SET *) xmalloc (n_labels * sizeof (HARD_REG_SET));\n   CLEAR_HARD_REG_SET (ever_live_at_start);\n \n-  FOR_ALL_BB_REVERSE (bb)\n+  for (i = n_basic_blocks - 1; i >= 0; i--)\n     {\n-      insn = bb->head;\n+      insn = BLOCK_HEAD (i);\n       if (GET_CODE (insn) == CODE_LABEL)\n \t{\n \t  HARD_REG_SET live;\n \n \t  REG_SET_TO_HARD_REG_SET (live,\n-\t\t\t\t   bb->global_live_at_start);\n+\t\t\t\t   BASIC_BLOCK (i)->global_live_at_start);\n \t  compute_use_by_pseudos (&live,\n-\t\t\t\t  bb->global_live_at_start);\n+\t\t\t\t  BASIC_BLOCK (i)->global_live_at_start);\n \t  COPY_HARD_REG_SET (LABEL_LIVE (insn), live);\n \t  IOR_HARD_REG_SET (ever_live_at_start, live);\n \t}\n@@ -9490,11 +9488,12 @@ copy_eh_notes (insn, x)\n void\n fixup_abnormal_edges ()\n {\n+  int i;\n   bool inserted = false;\n-  basic_block bb;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       edge e;\n \n       /* Look for cases we are interested in - an calls or instructions causing"}, {"sha": "8861dfe796bf38eede92ef2bb9c41ad53c20992f", "filename": "gcc/reorg.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Freorg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Freorg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freorg.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -3601,7 +3601,7 @@ dbr_schedule (first, file)\n \n   /* If the current function has no insns other than the prologue and\n      epilogue, then do not try to fill any delay slots.  */\n-  if (num_basic_blocks == 0)\n+  if (n_basic_blocks == 0)\n     return;\n \n   /* Find the highest INSN_UID and allocate and initialize our map from"}, {"sha": "6c20517a5f09ad10733f4d01c36d63e1a1c731e0", "filename": "gcc/resource.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fresource.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fresource.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fresource.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -133,7 +133,7 @@ find_basic_block (insn, search_limit)\n      rtx insn;\n      int search_limit;\n {\n-  basic_block bb;\n+  int i;\n \n   /* Scan backwards to the previous BARRIER.  Then see if we can find a\n      label that starts a basic block.  Return the basic block number.  */\n@@ -156,9 +156,9 @@ find_basic_block (insn, search_limit)\n        insn && GET_CODE (insn) == CODE_LABEL;\n        insn = next_nonnote_insn (insn))\n     {\n-      FOR_ALL_BB (bb)\n-\tif (insn == bb->head)\n-\t  return bb->sindex;\n+      for (i = 0; i < n_basic_blocks; i++)\n+\tif (insn == BLOCK_HEAD (i))\n+\t  return i;\n     }\n \n   return -1;\n@@ -1240,7 +1240,7 @@ init_resource_info (epilogue_insn)\n   /* Allocate and initialize the tables used by mark_target_live_regs.  */\n   target_hash_table = (struct target_info **)\n     xcalloc (TARGET_HASH_PRIME, sizeof (struct target_info *));\n-  bb_ticks = (int *) xcalloc (last_basic_block, sizeof (int));\n+  bb_ticks = (int *) xcalloc (n_basic_blocks, sizeof (int));\n }\n \f\n /* Free up the resources allcated to mark_target_live_regs ().  This"}, {"sha": "e581000e877fbbd12cf15889d5b23b446a49a69f", "filename": "gcc/sbitmap.c", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsbitmap.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsbitmap.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsbitmap.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -446,7 +446,7 @@ sbitmap_intersection_of_succs (dst, src, bb)\n       if (e->dest == EXIT_BLOCK_PTR)\n \tcontinue;\n \n-      sbitmap_copy (dst, src[e->dest->sindex]);\n+      sbitmap_copy (dst, src[e->dest->index]);\n       break;\n     }\n \n@@ -461,7 +461,7 @@ sbitmap_intersection_of_succs (dst, src, bb)\n \tif (e->dest == EXIT_BLOCK_PTR)\n \t  continue;\n \n-\tp = src[e->dest->sindex]->elms;\n+\tp = src[e->dest->index]->elms;\n \tr = dst->elms;\n \tfor (i = 0; i < set_size; i++)\n \t  *r++ &= *p++;\n@@ -486,7 +486,7 @@ sbitmap_intersection_of_preds (dst, src, bb)\n       if (e->src == ENTRY_BLOCK_PTR)\n \tcontinue;\n \n-      sbitmap_copy (dst, src[e->src->sindex]);\n+      sbitmap_copy (dst, src[e->src->index]);\n       break;\n     }\n \n@@ -501,7 +501,7 @@ sbitmap_intersection_of_preds (dst, src, bb)\n \tif (e->src == ENTRY_BLOCK_PTR)\n \t  continue;\n \n-\tp = src[e->src->sindex]->elms;\n+\tp = src[e->src->index]->elms;\n \tr = dst->elms;\n \tfor (i = 0; i < set_size; i++)\n \t  *r++ &= *p++;\n@@ -526,7 +526,7 @@ sbitmap_union_of_succs (dst, src, bb)\n       if (e->dest == EXIT_BLOCK_PTR)\n \tcontinue;\n \n-      sbitmap_copy (dst, src[e->dest->sindex]);\n+      sbitmap_copy (dst, src[e->dest->index]);\n       break;\n     }\n \n@@ -541,7 +541,7 @@ sbitmap_union_of_succs (dst, src, bb)\n \tif (e->dest == EXIT_BLOCK_PTR)\n \t  continue;\n \n-\tp = src[e->dest->sindex]->elms;\n+\tp = src[e->dest->index]->elms;\n \tr = dst->elms;\n \tfor (i = 0; i < set_size; i++)\n \t  *r++ |= *p++;\n@@ -566,7 +566,7 @@ sbitmap_union_of_preds (dst, src, bb)\n       if (e->src== ENTRY_BLOCK_PTR)\n \tcontinue;\n \n-      sbitmap_copy (dst, src[e->src->sindex]);\n+      sbitmap_copy (dst, src[e->src->index]);\n       break;\n     }\n \n@@ -580,8 +580,8 @@ sbitmap_union_of_preds (dst, src, bb)\n \n \tif (e->src == ENTRY_BLOCK_PTR)\n \t  continue;\n-\t\n-\tp = src[e->src->sindex]->elms;\n+\n+\tp = src[e->src->index]->elms;\n \tr = dst->elms;\n \tfor (i = 0; i < set_size; i++)\n \t  *r++ |= *p++;"}, {"sha": "88bf2b7f2e2b9ad1310b153b5f3cb3c30018abc9", "filename": "gcc/sched-deps.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsched-deps.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsched-deps.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-deps.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -1494,7 +1494,7 @@ init_dependency_caches (luid)\n      average number of instructions in a basic block is very high.  See\n      the comment before the declaration of true_dependency_cache for\n      what we consider \"very high\".  */\n-  if (luid / num_basic_blocks > 100 * 5)\n+  if (luid / n_basic_blocks > 100 * 5)\n     {\n       true_dependency_cache = sbitmap_vector_alloc (luid, luid);\n       sbitmap_vector_zero (true_dependency_cache, luid);"}, {"sha": "5f1464b9c147b510dbe3f48661be6e2462dd2e3c", "filename": "gcc/sched-ebb.c", "status": "modified", "additions": 11, "deletions": 10, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsched-ebb.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsched-ebb.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-ebb.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -279,11 +279,11 @@ void\n schedule_ebbs (dump_file)\n      FILE *dump_file;\n {\n-  basic_block bb;\n+  int i;\n \n   /* Taking care of this degenerate case makes the rest of\n      this code simpler.  */\n-  if (num_basic_blocks == 0)\n+  if (n_basic_blocks == 0)\n     return;\n \n   scope_to_insns_initialize ();\n@@ -296,19 +296,20 @@ schedule_ebbs (dump_file)\n   compute_bb_for_insn (get_max_uid ());\n \n   /* Schedule every region in the subroutine.  */\n-  FOR_ALL_BB (bb)\n-    { \n-      rtx head = bb->head;\n+  for (i = 0; i < n_basic_blocks; i++)\n+    {\n+      rtx head = BASIC_BLOCK (i)->head;\n       rtx tail;\n \n       for (;;)\n \t{\n+\t  basic_block b = BASIC_BLOCK (i);\n \t  edge e;\n-\t  tail = bb->end;\n-\t  if (bb->next_bb == EXIT_BLOCK_PTR\n-\t      || GET_CODE (bb->next_bb->head) == CODE_LABEL)\n+\t  tail = b->end;\n+\t  if (i + 1 == n_basic_blocks\n+\t      || GET_CODE (BLOCK_HEAD (i + 1)) == CODE_LABEL)\n \t    break;\n-\t  for (e = bb->succ; e; e = e->succ_next)\n+\t  for (e = b->succ; e; e = e->succ_next)\n \t    if ((e->flags & EDGE_FALLTHRU) != 0)\n \t      break;\n \t  if (! e)\n@@ -324,7 +325,7 @@ schedule_ebbs (dump_file)\n \t\t}\n \t    }\n \n-\t  bb = bb->next_bb;\n+\t  i++;\n \t}\n \n       /* Blah.  We should fix the rest of the code not to get confused by"}, {"sha": "acc8477e3ab8cdbc5e5458ddc81952f7a5eb66ed", "filename": "gcc/sched-rgn.c", "status": "modified", "additions": 78, "deletions": 83, "changes": 161, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsched-rgn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsched-rgn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-rgn.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -319,7 +319,7 @@ static void free_pending_lists PARAMS ((void));\n static int\n is_cfg_nonregular ()\n {\n-  basic_block b;\n+  int b;\n   rtx insn;\n   RTX_CODE code;\n \n@@ -346,8 +346,8 @@ is_cfg_nonregular ()\n   /* If we have non-jumping insns which refer to labels, then we consider\n      the cfg not well structured.  */\n   /* Check for labels referred to other thn by jumps.  */\n-  FOR_ALL_BB (b)\n-    for (insn = b->head;; insn = NEXT_INSN (insn))\n+  for (b = 0; b < n_basic_blocks; b++)\n+    for (insn = BLOCK_HEAD (b);; insn = NEXT_INSN (insn))\n       {\n \tcode = GET_CODE (insn);\n \tif (GET_RTX_CLASS (code) == 'i' && code != JUMP_INSN)\n@@ -361,7 +361,7 @@ is_cfg_nonregular ()\n \t      return 1;\n \t  }\n \n-\tif (insn == b->end)\n+\tif (insn == BLOCK_END (b))\n \t  break;\n       }\n \n@@ -382,7 +382,6 @@ build_control_flow (edge_list)\n      struct edge_list *edge_list;\n {\n   int i, unreachable, num_edges;\n-  basic_block b;\n \n   /* This already accounts for entry/exit edges.  */\n   num_edges = NUM_EDGES (edge_list);\n@@ -394,17 +393,19 @@ build_control_flow (edge_list)\n      test is redundant with the one in find_rgns, but it's much\n     cheaper to go ahead and catch the trivial case here.  */\n   unreachable = 0;\n-  FOR_ALL_BB (b)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block b = BASIC_BLOCK (i);\n+\n       if (b->pred == NULL\n \t  || (b->pred->src == b\n \t      && b->pred->pred_next == NULL))\n \tunreachable = 1;\n     }\n \n   /* ??? We can kill these soon.  */\n-  in_edges = (int *) xcalloc (last_basic_block, sizeof (int));\n-  out_edges = (int *) xcalloc (last_basic_block, sizeof (int));\n+  in_edges = (int *) xcalloc (n_basic_blocks, sizeof (int));\n+  out_edges = (int *) xcalloc (n_basic_blocks, sizeof (int));\n   edge_table = (haifa_edge *) xcalloc (num_edges, sizeof (haifa_edge));\n \n   nr_edges = 0;\n@@ -414,7 +415,7 @@ build_control_flow (edge_list)\n \n       if (e->dest != EXIT_BLOCK_PTR\n \t  && e->src != ENTRY_BLOCK_PTR)\n-\tnew_edge (e->src->sindex, e->dest->sindex);\n+\tnew_edge (e->src->index, e->dest->index);\n     }\n \n   /* Increment by 1, since edge 0 is unused.  */\n@@ -543,19 +544,17 @@ debug_regions ()\n static void\n find_single_block_region ()\n {\n-  basic_block bb;\n-\n-  nr_regions = 0;\n+  int i;\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n-      rgn_bb_table[nr_regions] = bb->sindex;\n-      RGN_NR_BLOCKS (nr_regions) = 1;\n-      RGN_BLOCKS (nr_regions) = nr_regions;\n-      CONTAINING_RGN (bb->sindex) = nr_regions;\n-      BLOCK_TO_BB (bb->sindex) = 0;\n-      nr_regions++;\n+      rgn_bb_table[i] = i;\n+      RGN_NR_BLOCKS (i) = 1;\n+      RGN_BLOCKS (i) = i;\n+      CONTAINING_RGN (i) = i;\n+      BLOCK_TO_BB (i) = 0;\n     }\n+  nr_regions = n_basic_blocks;\n }\n \n /* Update number of blocks and the estimate for number of insns\n@@ -632,7 +631,6 @@ find_rgns (edge_list, dom)\n   int count = 0, sp, idx = 0, current_edge = out_edges[0];\n   int num_bbs, num_insns, unreachable;\n   int too_large_failure;\n-  basic_block bb;\n \n   /* Note if an edge has been passed.  */\n   sbitmap passed;\n@@ -661,26 +659,26 @@ find_rgns (edge_list, dom)\n      STACK, SP and DFS_NR are only used during the first traversal.  */\n \n   /* Allocate and initialize variables for the first traversal.  */\n-  max_hdr = (int *) xmalloc (last_basic_block * sizeof (int));\n-  dfs_nr = (int *) xcalloc (last_basic_block, sizeof (int));\n+  max_hdr = (int *) xmalloc (n_basic_blocks * sizeof (int));\n+  dfs_nr = (int *) xcalloc (n_basic_blocks, sizeof (int));\n   stack = (int *) xmalloc (nr_edges * sizeof (int));\n \n-  inner = sbitmap_alloc (last_basic_block);\n+  inner = sbitmap_alloc (n_basic_blocks);\n   sbitmap_ones (inner);\n \n-  header = sbitmap_alloc (last_basic_block);\n+  header = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (header);\n \n   passed = sbitmap_alloc (nr_edges);\n   sbitmap_zero (passed);\n \n-  in_queue = sbitmap_alloc (last_basic_block);\n+  in_queue = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (in_queue);\n \n-  in_stack = sbitmap_alloc (last_basic_block);\n+  in_stack = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (in_stack);\n \n-  for (i = 0; i < last_basic_block; i++)\n+  for (i = 0; i < n_basic_blocks; i++)\n     max_hdr[i] = -1;\n \n   /* DFS traversal to find inner loops in the cfg.  */\n@@ -774,8 +772,8 @@ find_rgns (edge_list, dom)\n      the entry node by placing a nonzero value in dfs_nr.  Thus if\n      dfs_nr is zero for any block, then it must be unreachable.  */\n   unreachable = 0;\n-  FOR_ALL_BB (bb)\n-    if (dfs_nr[bb->sindex] == 0)\n+  for (i = 0; i < n_basic_blocks; i++)\n+    if (dfs_nr[i] == 0)\n       {\n \tunreachable = 1;\n \tbreak;\n@@ -785,14 +783,14 @@ find_rgns (edge_list, dom)\n      to hold degree counts.  */\n   degree = dfs_nr;\n \n-  FOR_ALL_BB (bb)\n-    degree[bb->sindex] = 0;\n+  for (i = 0; i < n_basic_blocks; i++)\n+    degree[i] = 0;\n   for (i = 0; i < num_edges; i++)\n     {\n       edge e = INDEX_EDGE (edge_list, i);\n \n       if (e->dest != EXIT_BLOCK_PTR)\n-\tdegree[e->dest->sindex]++;\n+\tdegree[e->dest->index]++;\n     }\n \n   /* Do not perform region scheduling if there are any unreachable\n@@ -807,16 +805,16 @@ find_rgns (edge_list, dom)\n       /* Second travsersal:find reducible inner loops and topologically sort\n \t block of each region.  */\n \n-      queue = (int *) xmalloc (num_basic_blocks * sizeof (int));\n+      queue = (int *) xmalloc (n_basic_blocks * sizeof (int));\n \n       /* Find blocks which are inner loop headers.  We still have non-reducible\n \t loops to consider at this point.  */\n-      FOR_ALL_BB (bb)\n+      for (i = 0; i < n_basic_blocks; i++)\n \t{\n-\t  if (TEST_BIT (header, bb->sindex) && TEST_BIT (inner, bb->sindex))\n+\t  if (TEST_BIT (header, i) && TEST_BIT (inner, i))\n \t    {\n \t      edge e;\n-\t      basic_block jbb;\n+\t      int j;\n \n \t      /* Now check that the loop is reducible.  We do this separate\n \t\t from finding inner loops so that we do not find a reducible\n@@ -829,59 +827,59 @@ find_rgns (edge_list, dom)\n \t\t If there exists a block that is not dominated by the loop\n \t\t header, then the block is reachable from outside the loop\n \t\t and thus the loop is not a natural loop.  */\n-\t      FOR_ALL_BB (jbb)\n+\t      for (j = 0; j < n_basic_blocks; j++)\n \t\t{\n \t\t  /* First identify blocks in the loop, except for the loop\n \t\t     entry block.  */\n-\t\t  if (bb->sindex == max_hdr[jbb->sindex] && bb != jbb)\n+\t\t  if (i == max_hdr[j] && i != j)\n \t\t    {\n \t\t      /* Now verify that the block is dominated by the loop\n \t\t\t header.  */\n-\t\t      if (!TEST_BIT (dom[jbb->sindex], bb->sindex))\n+\t\t      if (!TEST_BIT (dom[j], i))\n \t\t\tbreak;\n \t\t    }\n \t\t}\n \n \t      /* If we exited the loop early, then I is the header of\n \t\t a non-reducible loop and we should quit processing it\n \t\t now.  */\n-\t      if (jbb != EXIT_BLOCK_PTR)\n+\t      if (j != n_basic_blocks)\n \t\tcontinue;\n \n \t      /* I is a header of an inner loop, or block 0 in a subroutine\n \t\t with no loops at all.  */\n \t      head = tail = -1;\n \t      too_large_failure = 0;\n-\t      loop_head = max_hdr[bb->sindex];\n+\t      loop_head = max_hdr[i];\n \n \t      /* Decrease degree of all I's successors for topological\n \t\t ordering.  */\n-\t      for (e = bb->succ; e; e = e->succ_next)\n+\t      for (e = BASIC_BLOCK (i)->succ; e; e = e->succ_next)\n \t\tif (e->dest != EXIT_BLOCK_PTR)\n-\t\t  --degree[e->dest->sindex];\n+\t\t  --degree[e->dest->index];\n \n \t      /* Estimate # insns, and count # blocks in the region.  */\n \t      num_bbs = 1;\n-\t      num_insns = (INSN_LUID (bb->end)\n-\t\t\t   - INSN_LUID (bb->head));\n+\t      num_insns = (INSN_LUID (BLOCK_END (i))\n+\t\t\t   - INSN_LUID (BLOCK_HEAD (i)));\n \n \t      /* Find all loop latches (blocks with back edges to the loop\n \t\t header) or all the leaf blocks in the cfg has no loops.\n \n \t\t Place those blocks into the queue.  */\n \t      if (no_loops)\n \t\t{\n-\t\t  FOR_ALL_BB (jbb)\n+\t\t  for (j = 0; j < n_basic_blocks; j++)\n \t\t    /* Leaf nodes have only a single successor which must\n \t\t       be EXIT_BLOCK.  */\n-\t\t    if (jbb->succ\n-\t\t\t&& jbb->succ->dest == EXIT_BLOCK_PTR\n-\t\t\t&& jbb->succ->succ_next == NULL)\n+\t\t    if (BASIC_BLOCK (j)->succ\n+\t\t\t&& BASIC_BLOCK (j)->succ->dest == EXIT_BLOCK_PTR\n+\t\t\t&& BASIC_BLOCK (j)->succ->succ_next == NULL)\n \t\t      {\n-\t\t\tqueue[++tail] = jbb->sindex;\n-\t\t\tSET_BIT (in_queue, jbb->sindex);\n+\t\t\tqueue[++tail] = j;\n+\t\t\tSET_BIT (in_queue, j);\n \n-\t\t\tif (too_large (jbb->sindex, &num_bbs, &num_insns))\n+\t\t\tif (too_large (j, &num_bbs, &num_insns))\n \t\t\t  {\n \t\t\t    too_large_failure = 1;\n \t\t\t    break;\n@@ -892,14 +890,14 @@ find_rgns (edge_list, dom)\n \t\t{\n \t\t  edge e;\n \n-\t\t  for (e = bb->pred; e; e = e->pred_next)\n+\t\t  for (e = BASIC_BLOCK (i)->pred; e; e = e->pred_next)\n \t\t    {\n \t\t      if (e->src == ENTRY_BLOCK_PTR)\n \t\t\tcontinue;\n \n-\t\t      node = e->src->sindex;\n+\t\t      node = e->src->index;\n \n-\t\t      if (max_hdr[node] == loop_head && node != bb->sindex)\n+\t\t      if (max_hdr[node] == loop_head && node != i)\n \t\t\t{\n \t\t\t  /* This is a loop latch.  */\n \t\t\t  queue[++tail] = node;\n@@ -951,7 +949,7 @@ find_rgns (edge_list, dom)\n \n \t\t  for (e = BASIC_BLOCK (child)->pred; e; e = e->pred_next)\n \t\t    {\n-\t\t      node = e->src->sindex;\n+\t\t      node = e->src->index;\n \n \t\t      /* See discussion above about nodes not marked as in\n \t\t\t this loop during the initial DFS traversal.  */\n@@ -961,7 +959,7 @@ find_rgns (edge_list, dom)\n \t\t\t  tail = -1;\n \t\t\t  break;\n \t\t\t}\n-\t\t      else if (!TEST_BIT (in_queue, node) && node != bb->sindex)\n+\t\t      else if (!TEST_BIT (in_queue, node) && node != i)\n \t\t\t{\n \t\t\t  queue[++tail] = node;\n \t\t\t  SET_BIT (in_queue, node);\n@@ -978,12 +976,12 @@ find_rgns (edge_list, dom)\n \t      if (tail >= 0 && !too_large_failure)\n \t\t{\n \t\t  /* Place the loop header into list of region blocks.  */\n-\t\t  degree[bb->sindex] = -1;\n-\t\t  rgn_bb_table[idx] = bb->sindex;\n+\t\t  degree[i] = -1;\n+\t\t  rgn_bb_table[idx] = i;\n \t\t  RGN_NR_BLOCKS (nr_regions) = num_bbs;\n \t\t  RGN_BLOCKS (nr_regions) = idx++;\n-\t\t  CONTAINING_RGN (bb->sindex) = nr_regions;\n-\t\t  BLOCK_TO_BB (bb->sindex) = count = 0;\n+\t\t  CONTAINING_RGN (i) = nr_regions;\n+\t\t  BLOCK_TO_BB (i) = count = 0;\n \n \t\t  /* Remove blocks from queue[] when their in degree\n \t\t     becomes zero.  Repeat until no blocks are left on the\n@@ -1008,7 +1006,7 @@ find_rgns (edge_list, dom)\n \t\t\t       e;\n \t\t\t       e = e->succ_next)\n \t\t\t    if (e->dest != EXIT_BLOCK_PTR)\n-\t\t\t      --degree[e->dest->sindex];\n+\t\t\t      --degree[e->dest->index];\n \t\t\t}\n \t\t      else\n \t\t\t--head;\n@@ -1022,14 +1020,14 @@ find_rgns (edge_list, dom)\n \n   /* Any block that did not end up in a region is placed into a region\n      by itself.  */\n-  FOR_ALL_BB (bb)\n-    if (degree[bb->sindex] >= 0)\n+  for (i = 0; i < n_basic_blocks; i++)\n+    if (degree[i] >= 0)\n       {\n-\trgn_bb_table[idx] = bb->sindex;\n+\trgn_bb_table[idx] = i;\n \tRGN_NR_BLOCKS (nr_regions) = 1;\n \tRGN_BLOCKS (nr_regions) = idx++;\n-\tCONTAINING_RGN (bb->sindex) = nr_regions++;\n-\tBLOCK_TO_BB (bb->sindex) = 0;\n+\tCONTAINING_RGN (i) = nr_regions++;\n+\tBLOCK_TO_BB (i) = 0;\n       }\n \n   free (max_hdr);\n@@ -1197,8 +1195,8 @@ compute_trg_info (trg)\n \t     add the TO block to the update block list.  This list can end\n \t     up with a lot of duplicates.  We need to weed them out to avoid\n \t     overrunning the end of the bblst_table.  */\n-\t  update_blocks = (char *) alloca (last_basic_block);\n-\t  memset (update_blocks, 0, last_basic_block);\n+\t  update_blocks = (char *) alloca (n_basic_blocks);\n+\t  memset (update_blocks, 0, n_basic_blocks);\n \n \t  update_idx = 0;\n \t  for (j = 0; j < el.nr_members; j++)\n@@ -2888,14 +2886,14 @@ init_regions ()\n   int rgn;\n \n   nr_regions = 0;\n-  rgn_table = (region *) xmalloc ((num_basic_blocks) * sizeof (region));\n-  rgn_bb_table = (int *) xmalloc ((num_basic_blocks) * sizeof (int));\n-  block_to_bb = (int *) xmalloc ((last_basic_block) * sizeof (int));\n-  containing_rgn = (int *) xmalloc ((last_basic_block) * sizeof (int));\n+  rgn_table = (region *) xmalloc ((n_basic_blocks) * sizeof (region));\n+  rgn_bb_table = (int *) xmalloc ((n_basic_blocks) * sizeof (int));\n+  block_to_bb = (int *) xmalloc ((n_basic_blocks) * sizeof (int));\n+  containing_rgn = (int *) xmalloc ((n_basic_blocks) * sizeof (int));\n \n   /* Compute regions for scheduling.  */\n   if (reload_completed\n-      || num_basic_blocks == 1\n+      || n_basic_blocks == 1\n       || !flag_schedule_interblock)\n     {\n       find_single_block_region ();\n@@ -2912,7 +2910,7 @@ init_regions ()\n \t  sbitmap *dom;\n \t  struct edge_list *edge_list;\n \n-\t  dom = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n+\t  dom = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n \n \t  /* The scheduler runs after flow; therefore, we can't blindly call\n \t     back into find_basic_blocks since doing so could invalidate the\n@@ -2953,7 +2951,7 @@ init_regions ()\n \n   if (CHECK_DEAD_NOTES)\n     {\n-      blocks = sbitmap_alloc (last_basic_block);\n+      blocks = sbitmap_alloc (n_basic_blocks);\n       deaths_in_region = (int *) xmalloc (sizeof (int) * nr_regions);\n       /* Remove all death notes from the subroutine.  */\n       for (rgn = 0; rgn < nr_regions; rgn++)\n@@ -2982,11 +2980,10 @@ schedule_insns (dump_file)\n   sbitmap large_region_blocks, blocks;\n   int rgn;\n   int any_large_regions;\n-  basic_block bb;\n \n   /* Taking care of this degenerate case makes the rest of\n      this code simpler.  */\n-  if (num_basic_blocks == 0)\n+  if (n_basic_blocks == 0)\n     return;\n \n   scope_to_insns_initialize ();\n@@ -3021,12 +3018,10 @@ schedule_insns (dump_file)\n   compute_bb_for_insn (get_max_uid ());\n \n   any_large_regions = 0;\n-  large_region_blocks = sbitmap_alloc (last_basic_block);\n-  sbitmap_zero (large_region_blocks);\n-  FOR_ALL_BB (bb)\n-    SET_BIT (large_region_blocks, bb->sindex);\n+  large_region_blocks = sbitmap_alloc (n_basic_blocks);\n+  sbitmap_ones (large_region_blocks);\n \n-  blocks = sbitmap_alloc (last_basic_block);\n+  blocks = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (blocks);\n \n   /* Update life information.  For regions consisting of multiple blocks"}, {"sha": "c62941f097442ffdb95299a25e8ffeb54d9e75f7", "filename": "gcc/sibcall.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsibcall.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fsibcall.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsibcall.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -583,7 +583,7 @@ optimize_sibling_and_tail_recursive_calls ()\n   cleanup_cfg (CLEANUP_PRE_SIBCALL | CLEANUP_PRE_LOOP);\n \n   /* If there are no basic blocks, then there is nothing to do.  */\n-  if (num_basic_blocks == 0)\n+  if (n_basic_blocks == 0)\n     return;\n \n   /* If we are using sjlj exceptions, we may need to add a call to\n@@ -610,7 +610,7 @@ optimize_sibling_and_tail_recursive_calls ()\n \n       /* Walk forwards through the last normal block and see if it\n \t does nothing except fall into the exit block.  */\n-      for (insn = EXIT_BLOCK_PTR->prev_bb->head;\n+      for (insn = BLOCK_HEAD (n_basic_blocks - 1);\n \t   insn;\n \t   insn = NEXT_INSN (insn))\n \t{"}, {"sha": "641727655ba0787348052a9bc559e6fe4add7341", "filename": "gcc/ssa-ccp.c", "status": "modified", "additions": 12, "deletions": 10, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fssa-ccp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fssa-ccp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fssa-ccp.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -648,13 +648,13 @@ examine_flow_edges ()\n \n       /* If this is the first time we've simulated this block, then we\n \t must simulate each of its insns.  */\n-      if (!TEST_BIT (executable_blocks, succ_block->sindex))\n+      if (!TEST_BIT (executable_blocks, succ_block->index))\n \t{\n \t  rtx currinsn;\n \t  edge succ_edge = succ_block->succ;\n \n \t  /* Note that we have simulated this block.  */\n-\t  SET_BIT (executable_blocks, succ_block->sindex);\n+\t  SET_BIT (executable_blocks, succ_block->index);\n \n \t  /* Simulate each insn within the block.  */\n \t  currinsn = succ_block->head;\n@@ -740,7 +740,6 @@ optimize_unexecutable_edges (edges, executable_edges)\n      sbitmap executable_edges;\n {\n   int i;\n-  basic_block bb;\n \n   for (i = 0; i < NUM_EDGES (edges); i++)\n     {\n@@ -762,15 +761,15 @@ optimize_unexecutable_edges (edges, executable_edges)\n \t\t  remove_phi_alternative (PATTERN (insn), edge->src);\n \t\t  if (rtl_dump_file)\n \t\t    fprintf (rtl_dump_file,\n-\t\t\t     \"Removing alternative for bb %d of phi %d\\n\", \n-\t\t\t     edge->src->sindex, SSA_NAME (PATTERN (insn)));\n+\t\t\t     \"Removing alternative for bb %d of phi %d\\n\",\n+\t\t\t     edge->src->index, SSA_NAME (PATTERN (insn)));\n \t\t  insn = NEXT_INSN (insn);\n \t\t}\n \t    }\n \t  if (rtl_dump_file)\n \t    fprintf (rtl_dump_file,\n \t\t     \"Removing unexecutable edge from %d to %d\\n\",\n-\t\t     edge->src->sindex, edge->dest->sindex);\n+\t\t     edge->src->index, edge->dest->index);\n \t  /* Since the edge was not executable, remove it from the CFG.  */\n \t  remove_edge (edge);\n \t}\n@@ -798,8 +797,9 @@ optimize_unexecutable_edges (edges, executable_edges)\n      In cases B & C we are removing uses of registers, so make sure\n      to note those changes for the DF analyzer.  */\n \n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n       rtx insn = bb->end;\n       edge edge = bb->succ;\n \n@@ -929,16 +929,18 @@ ssa_ccp_substitute_constants ()\n static void\n ssa_ccp_df_delete_unreachable_insns ()\n {\n-  basic_block b;\n+  int i;\n \n   /* Use the CFG to find all the reachable blocks.  */\n   find_unreachable_blocks ();\n \n   /* Now we know what blocks are not reachable.  Mark all the insns\n      in those blocks as deleted for the DF analyzer.   We'll let the\n      normal flow code actually remove the unreachable blocks.  */\n-  FOR_ALL_BB_REVERSE (b)\n+  for (i = n_basic_blocks - 1; i >= 0; --i)\n     {\n+      basic_block b = BASIC_BLOCK (i);\n+\n       if (!(b->flags & BB_REACHABLE))\n \t{\n \t  rtx start = b->head;\n@@ -1016,7 +1018,7 @@ ssa_const_prop ()\n   ssa_edges = sbitmap_alloc (VARRAY_SIZE (ssa_definition));\n   sbitmap_zero (ssa_edges);\n \n-  executable_blocks = sbitmap_alloc (last_basic_block);\n+  executable_blocks = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (executable_blocks);\n \n   executable_edges = sbitmap_alloc (NUM_EDGES (edges));"}, {"sha": "45dcd659f00ccaa0f4499bccf41dca5c51f08a9a", "filename": "gcc/ssa-dce.c", "status": "modified", "additions": 15, "deletions": 14, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fssa-dce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fssa-dce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fssa-dce.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -153,7 +153,7 @@ static void delete_insn_bb\n \n /* Create a control_dependent_block_to_edge_map, given the number\n    NUM_BASIC_BLOCKS of non-entry, non-exit basic blocks, e.g.,\n-   num_basic_blocks.  This memory must be released using\n+   n_basic_blocks.  This memory must be released using\n    control_dependent_block_to_edge_map_free ().  */\n \n static control_dependent_block_to_edge_map\n@@ -181,10 +181,10 @@ set_control_dependent_block_to_edge_map_bit (c, bb, edge_index)\n      basic_block bb;\n      int edge_index;\n {\n-  if (bb->sindex - (INVALID_BLOCK+1) >= c->length)\n+  if (bb->index - (INVALID_BLOCK+1) >= c->length)\n     abort ();\n \n-  bitmap_set_bit (c->data[bb->sindex - (INVALID_BLOCK+1)],\n+  bitmap_set_bit (c->data[bb->index - (INVALID_BLOCK+1)],\n \t\t  edge_index);\n }\n \n@@ -247,7 +247,7 @@ find_control_dependence (el, edge_index, pdom, cdbte)\n     abort ();\n   ending_block =\n     (INDEX_EDGE_PRED_BB (el, edge_index) == ENTRY_BLOCK_PTR)\n-    ? ENTRY_BLOCK_PTR->next_bb\n+    ? BASIC_BLOCK (0)\n     : find_pdom (pdom, INDEX_EDGE_PRED_BB (el, edge_index));\n \n   for (current_block = INDEX_EDGE_SUCC_BB (el, edge_index);\n@@ -271,15 +271,15 @@ find_pdom (pdom, block)\n {\n   if (!block)\n     abort ();\n-  if (block->sindex == INVALID_BLOCK)\n+  if (block->index == INVALID_BLOCK)\n     abort ();\n \n   if (block == ENTRY_BLOCK_PTR)\n-    return ENTRY_BLOCK_PTR->next_bb;\n-  else if (block == EXIT_BLOCK_PTR || pdom[block->sindex] == EXIT_BLOCK)\n+    return BASIC_BLOCK (0);\n+  else if (block == EXIT_BLOCK_PTR || pdom[block->index] == EXIT_BLOCK)\n     return EXIT_BLOCK_PTR;\n   else\n-    return BASIC_BLOCK (pdom[block->sindex]);\n+    return BASIC_BLOCK (pdom[block->index]);\n }\n \n /* Determine if the given CURRENT_RTX uses a hard register not\n@@ -490,7 +490,6 @@ ssa_eliminate_dead_code ()\n {\n   int i;\n   rtx insn;\n-  basic_block bb;\n   /* Necessary instructions with operands to explore.  */\n   varray_type unprocessed_instructions;\n   /* Map element (b,e) is nonzero if the block is control dependent on\n@@ -506,20 +505,20 @@ ssa_eliminate_dead_code ()\n   mark_all_insn_unnecessary ();\n   VARRAY_RTX_INIT (unprocessed_instructions, 64,\n \t\t   \"unprocessed instructions\");\n-  cdbte = control_dependent_block_to_edge_map_create (last_basic_block);\n+  cdbte = control_dependent_block_to_edge_map_create (n_basic_blocks);\n \n   /* Prepare for use of BLOCK_NUM ().  */\n   connect_infinite_loops_to_exit ();\n    /* Be careful not to clear the added edges.  */\n   compute_bb_for_insn (max_insn_uid);\n \n   /* Compute control dependence.  */\n-  pdom = (int *) xmalloc (last_basic_block * sizeof (int));\n-  for (i = 0; i < last_basic_block; ++i)\n+  pdom = (int *) xmalloc (n_basic_blocks * sizeof (int));\n+  for (i = 0; i < n_basic_blocks; ++i)\n     pdom[i] = INVALID_BLOCK;\n   calculate_dominance_info (pdom, NULL, CDI_POST_DOMINATORS);\n   /* Assume there is a path from each node to the exit block.  */\n-  for (i = 0; i < last_basic_block; ++i)\n+  for (i = 0; i < n_basic_blocks; ++i)\n     if (pdom[i] == INVALID_BLOCK)\n       pdom[i] = EXIT_BLOCK;\n   el = create_edge_list ();\n@@ -719,8 +718,10 @@ ssa_eliminate_dead_code ()\n   /* Find any blocks with no successors and ensure they are followed\n      by a BARRIER.  delete_insn has the nasty habit of deleting barriers\n      when deleting insns.  */\n-  FOR_ALL_BB (bb)\n+  for (i = 0; i < n_basic_blocks; i++)\n     {\n+      basic_block bb = BASIC_BLOCK (i);\n+\n       if (bb->succ == NULL)\n \t{\n \t  rtx next = NEXT_INSN (bb->end);"}, {"sha": "686339cd156cc4320d9bc38da607442e4ef8abbd", "filename": "gcc/ssa.c", "status": "modified", "additions": 61, "deletions": 59, "changes": 120, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b17ab2f5b1184fdb568786f791bc0613e574241/gcc%2Fssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fssa.c?ref=0b17ab2f5b1184fdb568786f791bc0613e574241", "patch": "@@ -430,7 +430,7 @@ remove_phi_alternative (set, block)\n   int num_elem = GET_NUM_ELEM (phi_vec);\n   int v, c;\n \n-  c = block->sindex;\n+  c = block->index;\n   for (v = num_elem - 2; v >= 0; v -= 2)\n     if (INTVAL (RTVEC_ELT (phi_vec, v + 1)) == c)\n       {\n@@ -470,18 +470,18 @@ find_evaluations (evals, nregs)\n      sbitmap *evals;\n      int nregs;\n {\n-  basic_block bb;\n+  int bb;\n \n   sbitmap_vector_zero (evals, nregs);\n   fe_evals = evals;\n \n-  FOR_ALL_BB_REVERSE (bb)\n+  for (bb = n_basic_blocks; --bb >= 0; )\n     {\n       rtx p, last;\n \n-      fe_current_bb = bb->sindex;\n-      p = bb->head;\n-      last = bb->end;\n+      fe_current_bb = bb;\n+      p = BLOCK_HEAD (bb);\n+      last = BLOCK_END (bb);\n       while (1)\n \t{\n \t  if (INSN_P (p))\n@@ -520,33 +520,33 @@ compute_dominance_frontiers_1 (frontiers, idom, bb, done)\n {\n   basic_block b = BASIC_BLOCK (bb);\n   edge e;\n-  basic_block c;\n+  int c;\n \n   SET_BIT (done, bb);\n   sbitmap_zero (frontiers[bb]);\n \n   /* Do the frontier of the children first.  Not all children in the\n      dominator tree (blocks dominated by this one) are children in the\n      CFG, so check all blocks.  */\n-  FOR_ALL_BB (c)\n-    if (idom[c->sindex] == bb && ! TEST_BIT (done, c->sindex))\n-      compute_dominance_frontiers_1 (frontiers, idom, c->sindex, done);\n+  for (c = 0; c < n_basic_blocks; ++c)\n+    if (idom[c] == bb && ! TEST_BIT (done, c))\n+      compute_dominance_frontiers_1 (frontiers, idom, c, done);\n \n   /* Find blocks conforming to rule (1) above.  */\n   for (e = b->succ; e; e = e->succ_next)\n     {\n       if (e->dest == EXIT_BLOCK_PTR)\n \tcontinue;\n-      if (idom[e->dest->sindex] != bb)\n-\tSET_BIT (frontiers[bb], e->dest->sindex);\n+      if (idom[e->dest->index] != bb)\n+\tSET_BIT (frontiers[bb], e->dest->index);\n     }\n \n   /* Find blocks conforming to rule (2).  */\n-  FOR_ALL_BB (c)\n-    if (idom[c->sindex] == bb)\n+  for (c = 0; c < n_basic_blocks; ++c)\n+    if (idom[c] == bb)\n       {\n \tint x;\n-\tEXECUTE_IF_SET_IN_SBITMAP (frontiers[c->sindex], 0, x,\n+\tEXECUTE_IF_SET_IN_SBITMAP (frontiers[c], 0, x,\n \t  {\n \t    if (idom[x] != bb)\n \t      SET_BIT (frontiers[bb], x);\n@@ -559,7 +559,7 @@ compute_dominance_frontiers (frontiers, idom)\n      sbitmap *frontiers;\n      int *idom;\n {\n-  sbitmap done = sbitmap_alloc (last_basic_block);\n+  sbitmap done = sbitmap_alloc (n_basic_blocks);\n   sbitmap_zero (done);\n \n   compute_dominance_frontiers_1 (frontiers, idom, 0, done);\n@@ -585,7 +585,7 @@ compute_iterated_dominance_frontiers (idfs, frontiers, evals, nregs)\n   sbitmap worklist;\n   int reg, passes = 0;\n \n-  worklist = sbitmap_alloc (last_basic_block);\n+  worklist = sbitmap_alloc (n_basic_blocks);\n \n   for (reg = 0; reg < nregs; ++reg)\n     {\n@@ -665,7 +665,7 @@ insert_phi_node (regno, bb)\n     if (e->src != ENTRY_BLOCK_PTR)\n       {\n \tRTVEC_ELT (vec, i + 0) = pc_rtx;\n-\tRTVEC_ELT (vec, i + 1) = GEN_INT (e->src->sindex);\n+\tRTVEC_ELT (vec, i + 1) = GEN_INT (e->src->index);\n       }\n \n   phi = gen_rtx_PHI (VOIDmode, vec);\n@@ -975,7 +975,7 @@ rename_block (bb, idom)\n   edge e;\n   rtx insn, next, last;\n   struct rename_set_data *set_data = NULL;\n-  basic_block c;\n+  int c;\n \n   /* Step One: Walk the basic block, adding new names for sets and\n      replacing uses.  */\n@@ -1078,9 +1078,9 @@ rename_block (bb, idom)\n   /* Step Three: Do the same to the children of this block in\n      dominator order.  */\n \n-  FOR_ALL_BB (c)\n-    if (idom[c->sindex] == bb)\n-      rename_block (c->sindex, idom);\n+  for (c = 0; c < n_basic_blocks; ++c)\n+    if (idom[c] == bb)\n+      rename_block (c, idom);\n \n   /* Step Four: Update the sets to refer to their new register,\n      and restore ssa_rename_to to its previous state.  */\n@@ -1140,8 +1140,6 @@ convert_to_ssa ()\n \n   int nregs;\n \n-  basic_block bb;\n-\n   /* Don't do it twice.  */\n   if (in_ssa_form)\n     abort ();\n@@ -1150,40 +1148,41 @@ convert_to_ssa ()\n      dead code.  We'll let the SSA optimizers do that.  */\n   life_analysis (get_insns (), NULL, 0);\n \n-  idom = (int *) alloca (last_basic_block * sizeof (int));\n-  memset ((void *) idom, -1, (size_t) last_basic_block * sizeof (int));\n+  idom = (int *) alloca (n_basic_blocks * sizeof (int));\n+  memset ((void *) idom, -1, (size_t) n_basic_blocks * sizeof (int));\n   calculate_dominance_info (idom, NULL, CDI_DOMINATORS);\n \n   if (rtl_dump_file)\n     {\n+      int i;\n       fputs (\";; Immediate Dominators:\\n\", rtl_dump_file);\n-      FOR_ALL_BB (bb)\n-\tfprintf (rtl_dump_file, \";\\t%3d = %3d\\n\", bb->sindex, idom[bb->sindex]);\n+      for (i = 0; i < n_basic_blocks; ++i)\n+\tfprintf (rtl_dump_file, \";\\t%3d = %3d\\n\", i, idom[i]);\n       fflush (rtl_dump_file);\n     }\n \n   /* Compute dominance frontiers.  */\n \n-  dfs = sbitmap_vector_alloc (last_basic_block, last_basic_block);\n+  dfs = sbitmap_vector_alloc (n_basic_blocks, n_basic_blocks);\n   compute_dominance_frontiers (dfs, idom);\n \n   if (rtl_dump_file)\n     {\n       dump_sbitmap_vector (rtl_dump_file, \";; Dominance Frontiers:\",\n-\t\t\t   \"; Basic Block\", dfs, last_basic_block);\n+\t\t\t   \"; Basic Block\", dfs, n_basic_blocks);\n       fflush (rtl_dump_file);\n     }\n \n   /* Compute register evaluations.  */\n \n   ssa_max_reg_num = max_reg_num ();\n   nregs = ssa_max_reg_num;\n-  evals = sbitmap_vector_alloc (nregs, last_basic_block);\n+  evals = sbitmap_vector_alloc (nregs, n_basic_blocks);\n   find_evaluations (evals, nregs);\n \n   /* Compute the iterated dominance frontier for each register.  */\n \n-  idfs = sbitmap_vector_alloc (nregs, last_basic_block);\n+  idfs = sbitmap_vector_alloc (nregs, n_basic_blocks);\n   compute_iterated_dominance_frontiers (idfs, dfs, evals, nregs);\n \n   if (rtl_dump_file)\n@@ -1384,7 +1383,7 @@ eliminate_phi (e, reg_partition)\n   n_nodes = 0;\n   for (; PHI_NODE_P (insn); insn = next_nonnote_insn (insn))\n     {\n-      rtx* preg = phi_alternative (PATTERN (insn), e->src->sindex);\n+      rtx* preg = phi_alternative (PATTERN (insn), e->src->index);\n       rtx tgt = SET_DEST (PATTERN (insn));\n       rtx reg;\n \n@@ -1446,7 +1445,7 @@ eliminate_phi (e, reg_partition)\n   insert_insn_on_edge (insn, e);\n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \"Emitting copy on edge (%d,%d)\\n\",\n-\t     e->src->sindex, e->dest->sindex);\n+\t     e->src->index, e->dest->index);\n \n   sbitmap_free (visited);\n out:\n@@ -1501,7 +1500,7 @@ make_regs_equivalent_over_bad_edges (bb, reg_partition)\n       for (e = b->pred; e; e = e->pred_next)\n \tif ((e->flags & EDGE_ABNORMAL) && EDGE_CRITICAL_P (e))\n \t  {\n-\t    rtx *alt = phi_alternative (set, e->src->sindex);\n+\t    rtx *alt = phi_alternative (set, e->src->index);\n \t    int alt_regno;\n \n \t    /* If there is no alternative corresponding to this edge,\n@@ -1582,7 +1581,7 @@ make_equivalent_phi_alternatives_equivalent (bb, reg_partition)\n \t      /* Scan over edges.  */\n \t      for (e = b->pred; e; e = e->pred_next)\n \t\t{\n-\t\t  int pred_block = e->src->sindex;\n+\t\t  int pred_block = e->src->index;\n \t\t  /* Identify the phi alternatives from both phi\n \t\t     nodes corresponding to this edge.  */\n \t\t  rtx *alt = phi_alternative (set, pred_block);\n@@ -1630,7 +1629,7 @@ make_equivalent_phi_alternatives_equivalent (bb, reg_partition)\n static partition\n compute_conservative_reg_partition ()\n {\n-  basic_block bb;\n+  int bb;\n   int changed = 0;\n \n   /* We don't actually work with hard registers, but it's easier to\n@@ -1643,17 +1642,17 @@ compute_conservative_reg_partition ()\n      be copied on abnormal critical edges are placed in the same\n      partition.  This saves us from having to split abnormal critical\n      edges.  */\n-  FOR_ALL_BB_REVERSE (bb)\n-    changed += make_regs_equivalent_over_bad_edges (bb->sindex, p);\n-  \n+  for (bb = n_basic_blocks; --bb >= 0; )\n+    changed += make_regs_equivalent_over_bad_edges (bb, p);\n+\n   /* Now we have to insure that corresponding arguments of phi nodes\n      assigning to corresponding regs are equivalent.  Iterate until\n      nothing changes.  */\n   while (changed > 0)\n     {\n       changed = 0;\n-      FOR_ALL_BB_REVERSE (bb)\n-\tchanged += make_equivalent_phi_alternatives_equivalent (bb->sindex, p);\n+      for (bb = n_basic_blocks; --bb >= 0; )\n+\tchanged += make_equivalent_phi_alternatives_equivalent (bb, p);\n     }\n \n   return p;\n@@ -1849,7 +1848,7 @@ coalesce_regs_in_successor_phi_nodes (bb, p, conflicts)\n static partition\n compute_coalesced_reg_partition ()\n {\n-  basic_block bb;\n+  int bb;\n   int changed = 0;\n   regset_head phi_set_head;\n   regset phi_set = &phi_set_head;\n@@ -1861,8 +1860,8 @@ compute_coalesced_reg_partition ()\n      be copied on abnormal critical edges are placed in the same\n      partition.  This saves us from having to split abnormal critical\n      edges (which can't be done).  */\n-  FOR_ALL_BB_REVERSE (bb)\n-    make_regs_equivalent_over_bad_edges (bb->sindex, p);\n+  for (bb = n_basic_blocks; --bb >= 0; )\n+    make_regs_equivalent_over_bad_edges (bb, p);\n \n   INIT_REG_SET (phi_set);\n \n@@ -1884,11 +1883,12 @@ compute_coalesced_reg_partition ()\n \t blocks first, so that most frequently executed copies would\n \t be more likely to be removed by register coalescing.  But any\n \t order will generate correct, if non-optimal, results.  */\n-      FOR_ALL_BB_REVERSE (bb)\n+      for (bb = n_basic_blocks; --bb >= 0; )\n \t{\n-\t  changed += coalesce_regs_in_copies (bb, p, conflicts);\n-\t  changed += \n-\t    coalesce_regs_in_successor_phi_nodes (bb, p, conflicts);\n+\t  basic_block block = BASIC_BLOCK (bb);\n+\t  changed += coalesce_regs_in_copies (block, p, conflicts);\n+\t  changed +=\n+\t    coalesce_regs_in_successor_phi_nodes (block, p, conflicts);\n \t}\n \n       conflict_graph_delete (conflicts);\n@@ -2094,10 +2094,11 @@ static void\n rename_equivalent_regs (reg_partition)\n      partition reg_partition;\n {\n-  basic_block b;\n+  int bb;\n \n-  FOR_ALL_BB_REVERSE (b)\n+  for (bb = n_basic_blocks; --bb >= 0; )\n     {\n+      basic_block b = BASIC_BLOCK (bb);\n       rtx next = b->head;\n       rtx last = b->end;\n       rtx insn;\n@@ -2140,7 +2141,7 @@ rename_equivalent_regs (reg_partition)\n void\n convert_from_ssa ()\n {\n-  basic_block b, bb;\n+  int bb;\n   partition reg_partition;\n   rtx insns = get_insns ();\n \n@@ -2166,8 +2167,9 @@ convert_from_ssa ()\n   rename_equivalent_regs (reg_partition);\n \n   /* Eliminate the PHI nodes.  */\n-  FOR_ALL_BB_REVERSE (b)\n+  for (bb = n_basic_blocks; --bb >= 0; )\n     {\n+      basic_block b = BASIC_BLOCK (bb);\n       edge e;\n \n       for (e = b->pred; e; e = e->pred_next)\n@@ -2178,17 +2180,17 @@ convert_from_ssa ()\n   partition_delete (reg_partition);\n \n   /* Actually delete the PHI nodes.  */\n-  FOR_ALL_BB_REVERSE (bb)\n+  for (bb = n_basic_blocks; --bb >= 0; )\n     {\n-      rtx insn = bb->head;\n+      rtx insn = BLOCK_HEAD (bb);\n \n       while (1)\n \t{\n \t  /* If this is a PHI node delete it.  */\n \t  if (PHI_NODE_P (insn))\n \t    {\n-\t      if (insn == bb->end)\n-\t\tbb->end = PREV_INSN (insn);\n+\t      if (insn == BLOCK_END (bb))\n+\t\tBLOCK_END (bb) = PREV_INSN (insn);\n \t      insn = delete_insn (insn);\n \t    }\n \t  /* Since all the phi nodes come at the beginning of the\n@@ -2197,7 +2199,7 @@ convert_from_ssa ()\n \t  else if (INSN_P (insn))\n \t    break;\n \t  /* If we've reached the end of the block, stop.  */\n-\t  else if (insn == bb->end)\n+\t  else if (insn == BLOCK_END (bb))\n \t    break;\n \t  else\n \t    insn = NEXT_INSN (insn);\n@@ -2257,7 +2259,7 @@ for_each_successor_phi (bb, fn, data)\n \t{\n \t  int result;\n \t  rtx phi_set = PATTERN (insn);\n-\t  rtx *alternative = phi_alternative (phi_set, bb->sindex);\n+\t  rtx *alternative = phi_alternative (phi_set, bb->index);\n \t  rtx phi_src;\n \n \t  /* This phi function may not have an alternative"}]}