{"sha": "18a4bc4eabb5ca133152afc8a152497e3b273a91", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MThhNGJjNGVhYmI1Y2ExMzMxNTJhZmM4YTE1MjQ5N2UzYjI3M2E5MQ==", "commit": {"author": {"name": "Tom Tromey", "email": "tromey@gcc.gnu.org", "date": "1999-04-07T08:01:38Z"}, "committer": {"name": "Tom Tromey", "email": "tromey@gcc.gnu.org", "date": "1999-04-07T08:01:38Z"}, "message": "Initial revision\n\nFrom-SVN: r26253", "tree": {"sha": "0e8f947b0099e6401dfe4db5512e374f9b63a92b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0e8f947b0099e6401dfe4db5512e374f9b63a92b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/18a4bc4eabb5ca133152afc8a152497e3b273a91", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/18a4bc4eabb5ca133152afc8a152497e3b273a91", "html_url": "https://github.com/Rust-GCC/gccrs/commit/18a4bc4eabb5ca133152afc8a152497e3b273a91", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/18a4bc4eabb5ca133152afc8a152497e3b273a91/comments", "author": null, "committer": null, "parents": [{"sha": "d048a803cf4d121036fa71f537933580724a2dca", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d048a803cf4d121036fa71f537933580724a2dca", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d048a803cf4d121036fa71f537933580724a2dca"}], "stats": {"total": 1092, "additions": 1092, "deletions": 0}, "files": [{"sha": "1723a446cc08ba61a0f02a192c545259cebf9bc9", "filename": "boehm-gc/mark.c", "status": "added", "additions": 1092, "deletions": 0, "changes": 1092, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18a4bc4eabb5ca133152afc8a152497e3b273a91/boehm-gc%2Fmark.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18a4bc4eabb5ca133152afc8a152497e3b273a91/boehm-gc%2Fmark.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmark.c?ref=18a4bc4eabb5ca133152afc8a152497e3b273a91", "patch": "@@ -0,0 +1,1092 @@\n+\n+/*\n+ * Copyright 1988, 1989 Hans-J. Boehm, Alan J. Demers\n+ * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n+ *\n+ * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n+ * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n+ *\n+ * Permission is hereby granted to use or copy this program\n+ * for any purpose,  provided the above notices are retained on all copies.\n+ * Permission to modify the code and to distribute modified code is granted,\n+ * provided the above notices are retained, and a notice that the code was\n+ * modified is included with the above copyright notice.\n+ *\n+ */\n+\n+\n+# include <stdio.h>\n+# include \"gc_priv.h\"\n+# include \"gc_mark.h\"\n+\n+/* We put this here to minimize the risk of inlining. */\n+/*VARARGS*/\n+void GC_noop() {}\n+\n+/* Single argument version, robust against whole program analysis. */\n+void GC_noop1(x)\n+word x;\n+{\n+    static VOLATILE word sink;\n+\n+    sink = x;\n+}\n+\n+mark_proc GC_mark_procs[MAX_MARK_PROCS] = {0};\n+word GC_n_mark_procs = 0;\n+\n+/* Initialize GC_obj_kinds properly and standard free lists properly.  \t*/\n+/* This must be done statically since they may be accessed before \t*/\n+/* GC_init is called.\t\t\t\t\t\t\t*/\n+/* It's done here, since we need to deal with mark descriptors.\t\t*/\n+struct obj_kind GC_obj_kinds[MAXOBJKINDS] = {\n+/* PTRFREE */ { &GC_aobjfreelist[0], 0 /* filled in dynamically */,\n+\t\t0 | DS_LENGTH, FALSE, FALSE },\n+/* NORMAL  */ { &GC_objfreelist[0], 0,\n+#\t\tif defined(ADD_BYTE_AT_END) && ALIGNMENT > DS_TAGS\n+\t\t(word)(-ALIGNMENT) | DS_LENGTH,\n+#\t\telse\n+\t\t0 | DS_LENGTH,\n+#\t\tendif\n+\t\tTRUE /* add length to descr */, TRUE },\n+/* UNCOLLECTABLE */\n+\t      { &GC_uobjfreelist[0], 0,\n+\t\t0 | DS_LENGTH, TRUE /* add length to descr */, TRUE },\n+# ifdef ATOMIC_UNCOLLECTABLE\n+   /* AUNCOLLECTABLE */\n+\t      { &GC_auobjfreelist[0], 0,\n+\t\t0 | DS_LENGTH, FALSE /* add length to descr */, FALSE },\n+# endif\n+# ifdef STUBBORN_ALLOC\n+/*STUBBORN*/ { &GC_sobjfreelist[0], 0,\n+\t\t0 | DS_LENGTH, TRUE /* add length to descr */, TRUE },\n+# endif\n+};\n+\n+# ifdef ATOMIC_UNCOLLECTABLE\n+#   ifdef STUBBORN_ALLOC\n+      int GC_n_kinds = 5;\n+#   else\n+      int GC_n_kinds = 4;\n+#   endif\n+# else\n+#   ifdef STUBBORN_ALLOC\n+      int GC_n_kinds = 4;\n+#   else\n+      int GC_n_kinds = 3;\n+#   endif\n+# endif\n+\n+\n+# ifndef INITIAL_MARK_STACK_SIZE\n+#   define INITIAL_MARK_STACK_SIZE (1*HBLKSIZE)\n+\t\t/* INITIAL_MARK_STACK_SIZE * sizeof(mse) should be a \t*/\n+\t\t/* multiple of HBLKSIZE.\t\t\t\t*/\n+# endif\n+\n+/*\n+ * Limits of stack for GC_mark routine.\n+ * All ranges between GC_mark_stack(incl.) and GC_mark_stack_top(incl.) still\n+ * need to be marked from.\n+ */\n+\n+word GC_n_rescuing_pages;\t/* Number of dirty pages we marked from */\n+\t\t\t\t/* excludes ptrfree pages, etc.\t\t*/\n+\n+mse * GC_mark_stack;\n+\n+word GC_mark_stack_size = 0;\n+ \n+mse * GC_mark_stack_top;\n+\n+static struct hblk * scan_ptr;\n+\n+mark_state_t GC_mark_state = MS_NONE;\n+\n+GC_bool GC_mark_stack_too_small = FALSE;\n+\n+GC_bool GC_objects_are_marked = FALSE;\t/* Are there collectable marked\t*/\n+\t\t\t\t\t/* objects in the heap?\t\t*/\n+\n+GC_bool GC_collection_in_progress()\n+{\n+    return(GC_mark_state != MS_NONE);\n+}\n+\n+/* clear all mark bits in the header */\n+void GC_clear_hdr_marks(hhdr)\n+register hdr * hhdr;\n+{\n+    BZERO(hhdr -> hb_marks, MARK_BITS_SZ*sizeof(word));\n+}\n+\n+/* Set all mark bits in the header.  Used for uncollectable blocks. */\n+void GC_set_hdr_marks(hhdr)\n+register hdr * hhdr;\n+{\n+    register int i;\n+\n+    for (i = 0; i < MARK_BITS_SZ; ++i) {\n+    \thhdr -> hb_marks[i] = ONES;\n+    }\n+}\n+\n+/*\n+ * Clear all mark bits associated with block h.\n+ */\n+/*ARGSUSED*/\n+static void clear_marks_for_block(h, dummy)\n+struct hblk *h;\n+word dummy;\n+{\n+    register hdr * hhdr = HDR(h);\n+    \n+    if (IS_UNCOLLECTABLE(hhdr -> hb_obj_kind)) return;\n+        /* Mark bit for these is cleared only once the object is \t*/\n+        /* explicitly deallocated.  This either frees the block, or\t*/\n+        /* the bit is cleared once the object is on the free list.\t*/\n+    GC_clear_hdr_marks(hhdr);\n+}\n+\n+/* Slow but general routines for setting/clearing/asking about mark bits */\n+void GC_set_mark_bit(p)\n+ptr_t p;\n+{\n+    register struct hblk *h = HBLKPTR(p);\n+    register hdr * hhdr = HDR(h);\n+    register int word_no = (word *)p - (word *)h;\n+    \n+    set_mark_bit_from_hdr(hhdr, word_no);\n+}\n+\n+void GC_clear_mark_bit(p)\n+ptr_t p;\n+{\n+    register struct hblk *h = HBLKPTR(p);\n+    register hdr * hhdr = HDR(h);\n+    register int word_no = (word *)p - (word *)h;\n+    \n+    clear_mark_bit_from_hdr(hhdr, word_no);\n+}\n+\n+GC_bool GC_is_marked(p)\n+ptr_t p;\n+{\n+    register struct hblk *h = HBLKPTR(p);\n+    register hdr * hhdr = HDR(h);\n+    register int word_no = (word *)p - (word *)h;\n+    \n+    return(mark_bit_from_hdr(hhdr, word_no));\n+}\n+\n+\n+/*\n+ * Clear mark bits in all allocated heap blocks.  This invalidates\n+ * the marker invariant, and sets GC_mark_state to reflect this.\n+ * (This implicitly starts marking to reestablish the invariant.)\n+ */\n+void GC_clear_marks()\n+{\n+    GC_apply_to_all_blocks(clear_marks_for_block, (word)0);\n+    GC_objects_are_marked = FALSE;\n+    GC_mark_state = MS_INVALID;\n+    scan_ptr = 0;\n+#   ifdef GATHERSTATS\n+\t/* Counters reflect currently marked objects: reset here */\n+        GC_composite_in_use = 0;\n+        GC_atomic_in_use = 0;\n+#   endif\n+\n+}\n+\n+/* Initiate a garbage collection.  Initiates a full collection if the\t*/\n+/* mark\tstate is invalid.\t\t\t\t\t\t*/\n+/*ARGSUSED*/\n+void GC_initiate_gc()\n+{\n+    if (GC_dirty_maintained) GC_read_dirty();\n+#   ifdef STUBBORN_ALLOC\n+    \tGC_read_changed();\n+#   endif\n+#   ifdef CHECKSUMS\n+\t{\n+\t    extern void GC_check_dirty();\n+\t    \n+\t    if (GC_dirty_maintained) GC_check_dirty();\n+\t}\n+#   endif\n+#   ifdef GATHERSTATS\n+\tGC_n_rescuing_pages = 0;\n+#   endif\n+    if (GC_mark_state == MS_NONE) {\n+        GC_mark_state = MS_PUSH_RESCUERS;\n+    } else if (GC_mark_state != MS_INVALID) {\n+    \tABORT(\"unexpected state\");\n+    } /* else this is really a full collection, and mark\t*/\n+      /* bits are invalid.\t\t\t\t\t*/\n+    scan_ptr = 0;\n+}\n+\n+\n+static void alloc_mark_stack();\n+\n+/* Perform a small amount of marking.\t\t\t*/\n+/* We try to touch roughly a page of memory.\t\t*/\n+/* Return TRUE if we just finished a mark phase.\t*/\n+GC_bool GC_mark_some()\n+{\n+    switch(GC_mark_state) {\n+    \tcase MS_NONE:\n+    \t    return(FALSE);\n+    \t    \n+    \tcase MS_PUSH_RESCUERS:\n+    \t    if (GC_mark_stack_top\n+    \t        >= GC_mark_stack + INITIAL_MARK_STACK_SIZE/4) {\n+    \t        GC_mark_from_mark_stack();\n+    \t        return(FALSE);\n+    \t    } else {\n+    \t        scan_ptr = GC_push_next_marked_dirty(scan_ptr);\n+    \t        if (scan_ptr == 0) {\n+#\t\t    ifdef PRINTSTATS\n+\t\t\tGC_printf1(\"Marked from %lu dirty pages\\n\",\n+\t\t\t\t   (unsigned long)GC_n_rescuing_pages);\n+#\t\t    endif\n+    \t    \t    GC_push_roots(FALSE);\n+    \t    \t    GC_objects_are_marked = TRUE;\n+    \t    \t    if (GC_mark_state != MS_INVALID) {\n+    \t    \t        GC_mark_state = MS_ROOTS_PUSHED;\n+    \t    \t    }\n+    \t    \t}\n+    \t    }\n+    \t    return(FALSE);\n+    \t\n+    \tcase MS_PUSH_UNCOLLECTABLE:\n+    \t    if (GC_mark_stack_top\n+    \t        >= GC_mark_stack + INITIAL_MARK_STACK_SIZE/4) {\n+    \t        GC_mark_from_mark_stack();\n+    \t        return(FALSE);\n+    \t    } else {\n+    \t        scan_ptr = GC_push_next_marked_uncollectable(scan_ptr);\n+    \t        if (scan_ptr == 0) {\n+    \t    \t    GC_push_roots(TRUE);\n+    \t    \t    GC_objects_are_marked = TRUE;\n+    \t    \t    if (GC_mark_state != MS_INVALID) {\n+    \t    \t        GC_mark_state = MS_ROOTS_PUSHED;\n+    \t    \t    }\n+    \t    \t}\n+    \t    }\n+    \t    return(FALSE);\n+    \t\n+    \tcase MS_ROOTS_PUSHED:\n+    \t    if (GC_mark_stack_top >= GC_mark_stack) {\n+    \t        GC_mark_from_mark_stack();\n+    \t        return(FALSE);\n+    \t    } else {\n+    \t        GC_mark_state = MS_NONE;\n+    \t        if (GC_mark_stack_too_small) {\n+    \t            alloc_mark_stack(2*GC_mark_stack_size);\n+    \t        }\n+    \t        return(TRUE);\n+    \t    }\n+    \t    \n+    \tcase MS_INVALID:\n+    \tcase MS_PARTIALLY_INVALID:\n+\t    if (!GC_objects_are_marked) {\n+\t\tGC_mark_state = MS_PUSH_UNCOLLECTABLE;\n+\t\treturn(FALSE);\n+\t    }\n+    \t    if (GC_mark_stack_top >= GC_mark_stack) {\n+    \t        GC_mark_from_mark_stack();\n+    \t        return(FALSE);\n+    \t    }\n+    \t    if (scan_ptr == 0\n+    \t        && (GC_mark_state == MS_INVALID || GC_mark_stack_too_small)) {\n+    \t        alloc_mark_stack(2*GC_mark_stack_size);\n+\t\tGC_mark_state = MS_PARTIALLY_INVALID;\n+    \t    }\n+    \t    scan_ptr = GC_push_next_marked(scan_ptr);\n+    \t    if (scan_ptr == 0 && GC_mark_state == MS_PARTIALLY_INVALID) {\n+    \t    \tGC_push_roots(TRUE);\n+    \t    \tGC_objects_are_marked = TRUE;\n+    \t    \tif (GC_mark_state != MS_INVALID) {\n+    \t    \t    GC_mark_state = MS_ROOTS_PUSHED;\n+    \t    \t}\n+    \t    }\n+    \t    return(FALSE);\n+    \tdefault:\n+    \t    ABORT(\"GC_mark_some: bad state\");\n+    \t    return(FALSE);\n+    }\n+}\n+\n+\n+GC_bool GC_mark_stack_empty()\n+{\n+    return(GC_mark_stack_top < GC_mark_stack);\n+}\t\n+\n+#ifdef PROF_MARKER\n+    word GC_prof_array[10];\n+#   define PROF(n) GC_prof_array[n]++\n+#else\n+#   define PROF(n)\n+#endif\n+\n+/* Given a pointer to someplace other than a small object page or the\t*/\n+/* first page of a large object, return a pointer either to the\t\t*/\n+/* start of the large object or NIL.\t\t\t\t\t*/\n+/* In the latter case black list the address current.\t\t\t*/\n+/* Returns NIL without black listing if current points to a block\t*/\n+/* with IGNORE_OFF_PAGE set.\t\t\t\t\t\t*/\n+/*ARGSUSED*/\n+# ifdef PRINT_BLACK_LIST\n+  word GC_find_start(current, hhdr, source)\n+  word source;\n+# else\n+  word GC_find_start(current, hhdr)\n+# define source 0\n+# endif\n+register word current;\n+register hdr * hhdr;\n+{\n+#   ifdef ALL_INTERIOR_POINTERS\n+\tif (hhdr != 0) {\n+\t    register word orig = current;\n+\t    \n+\t    current = (word)HBLKPTR(current) + HDR_BYTES;\n+\t    do {\n+\t      current = current - HBLKSIZE*(word)hhdr;\n+\t      hhdr = HDR(current);\n+\t    } while(IS_FORWARDING_ADDR_OR_NIL(hhdr));\n+\t    /* current points to the start of the large object */\n+\t    if (hhdr -> hb_flags & IGNORE_OFF_PAGE) return(0);\n+\t    if ((word *)orig - (word *)current\n+\t         >= (ptrdiff_t)(hhdr->hb_sz)) {\n+\t        /* Pointer past the end of the block */\n+\t        GC_ADD_TO_BLACK_LIST_NORMAL(orig, source);\n+\t        return(0);\n+\t    }\n+\t    return(current);\n+\t} else {\n+\t    GC_ADD_TO_BLACK_LIST_NORMAL(current, source);\n+\t    return(0);\n+        }\n+#   else\n+        GC_ADD_TO_BLACK_LIST_NORMAL(current, source);\n+        return(0);\n+#   endif\n+#   undef source\n+}\n+\n+void GC_invalidate_mark_state()\n+{\n+    GC_mark_state = MS_INVALID;\n+    GC_mark_stack_top = GC_mark_stack-1;\n+}\n+\n+mse * GC_signal_mark_stack_overflow(msp)\n+mse * msp;\n+{\n+    GC_mark_state = MS_INVALID;\n+#   ifdef PRINTSTATS\n+\tGC_printf1(\"Mark stack overflow; current size = %lu entries\\n\",\n+\t    \t    GC_mark_stack_size);\n+#    endif\n+     return(msp-INITIAL_MARK_STACK_SIZE/8);\n+}\n+\n+\n+/*\n+ * Mark objects pointed to by the regions described by\n+ * mark stack entries between GC_mark_stack and GC_mark_stack_top,\n+ * inclusive.  Assumes the upper limit of a mark stack entry\n+ * is never 0.  A mark stack entry never has size 0.\n+ * We try to traverse on the order of a hblk of memory before we return.\n+ * Caller is responsible for calling this until the mark stack is empty.\n+ */\n+void GC_mark_from_mark_stack()\n+{\n+  mse * GC_mark_stack_reg = GC_mark_stack;\n+  mse * GC_mark_stack_top_reg = GC_mark_stack_top;\n+  mse * mark_stack_limit = &(GC_mark_stack[GC_mark_stack_size]);\n+  int credit = HBLKSIZE;\t/* Remaining credit for marking work\t*/\n+  register word * current_p;\t/* Pointer to current candidate ptr.\t*/\n+  register word current;\t/* Candidate pointer.\t\t\t*/\n+  register word * limit;\t/* (Incl) limit of current candidate \t*/\n+  \t\t\t\t/* range\t\t\t\t*/\n+  register word descr;\n+  register ptr_t greatest_ha = GC_greatest_plausible_heap_addr;\n+  register ptr_t least_ha = GC_least_plausible_heap_addr;\n+# define SPLIT_RANGE_WORDS 128  /* Must be power of 2.\t\t*/\n+\n+  GC_objects_are_marked = TRUE;\n+# ifdef OS2 /* Use untweaked version to circumvent compiler problem */\n+  while (GC_mark_stack_top_reg >= GC_mark_stack_reg && credit >= 0) {\n+# else\n+  while ((((ptr_t)GC_mark_stack_top_reg - (ptr_t)GC_mark_stack_reg) | credit)\n+  \t>= 0) {\n+# endif\n+    current_p = GC_mark_stack_top_reg -> mse_start;\n+  retry:\n+    descr = GC_mark_stack_top_reg -> mse_descr;\n+    if (descr & ((~(WORDS_TO_BYTES(SPLIT_RANGE_WORDS) - 1)) | DS_TAGS)) {\n+      word tag = descr & DS_TAGS;\n+      \n+      switch(tag) {\n+        case DS_LENGTH:\n+          /* Large length.\t\t\t\t\t        */\n+          /* Process part of the range to avoid pushing too much on the\t*/\n+          /* stack.\t\t\t\t\t\t\t*/\n+          GC_mark_stack_top_reg -> mse_start =\n+         \tlimit = current_p + SPLIT_RANGE_WORDS-1;\n+          GC_mark_stack_top_reg -> mse_descr -=\n+          \t\tWORDS_TO_BYTES(SPLIT_RANGE_WORDS-1);\n+          /* Make sure that pointers overlapping the two ranges are\t*/\n+          /* considered. \t\t\t\t\t\t*/\n+          limit = (word *)((char *)limit + sizeof(word) - ALIGNMENT);\n+          break;\n+        case DS_BITMAP:\n+          GC_mark_stack_top_reg--;\n+          descr &= ~DS_TAGS;\n+          credit -= WORDS_TO_BYTES(WORDSZ/2); /* guess */\n+          while (descr != 0) {\n+            if ((signed_word)descr < 0) {\n+              current = *current_p;\n+\t      if ((ptr_t)current >= least_ha && (ptr_t)current < greatest_ha) {\n+                PUSH_CONTENTS(current, GC_mark_stack_top_reg, mark_stack_limit,\n+\t\t\t      current_p, exit1);\n+\t      }\n+            }\n+\t    descr <<= 1;\n+\t    ++ current_p;\n+          }\n+          continue;\n+        case DS_PROC:\n+          GC_mark_stack_top_reg--;\n+          credit -= PROC_BYTES;\n+          GC_mark_stack_top_reg =\n+              (*PROC(descr))\n+              \t    (current_p, GC_mark_stack_top_reg,\n+              \t    mark_stack_limit, ENV(descr));\n+          continue;\n+        case DS_PER_OBJECT:\n+          GC_mark_stack_top_reg -> mse_descr =\n+\t\t\t*(word *)((ptr_t)current_p + descr - tag);\n+          goto retry;\n+      }\n+    } else {\n+      GC_mark_stack_top_reg--;\n+      limit = (word *)(((ptr_t)current_p) + (word)descr);\n+    }\n+    /* The simple case in which we're scanning a range.\t*/\n+    credit -= (ptr_t)limit - (ptr_t)current_p;\n+    limit -= 1;\n+    while (current_p <= limit) {\n+      current = *current_p;\n+      if ((ptr_t)current >= least_ha && (ptr_t)current <  greatest_ha) {\n+        PUSH_CONTENTS(current, GC_mark_stack_top_reg,\n+\t\t      mark_stack_limit, current_p, exit2);\n+      }\n+      current_p = (word *)((char *)current_p + ALIGNMENT);\n+    }\n+  }\n+  GC_mark_stack_top = GC_mark_stack_top_reg;\n+}\n+\n+/* Allocate or reallocate space for mark stack of size s words  */\n+/* May silently fail.\t\t\t\t\t\t*/\n+static void alloc_mark_stack(n)\n+word n;\n+{\n+    mse * new_stack = (mse *)GC_scratch_alloc(n * sizeof(struct ms_entry));\n+    \n+    GC_mark_stack_too_small = FALSE;\n+    if (GC_mark_stack_size != 0) {\n+        if (new_stack != 0) {\n+          word displ = (word)GC_mark_stack & (GC_page_size - 1);\n+          word size = GC_mark_stack_size * sizeof(struct ms_entry);\n+          \n+          /* Recycle old space */\n+\t      if (0 != displ) displ = GC_page_size - displ;\n+\t      size = (size - displ) & ~(GC_page_size - 1);\n+\t      GC_add_to_heap((struct hblk *)\n+\t      \t\t\t((word)GC_mark_stack + displ), size);\n+          GC_mark_stack = new_stack;\n+          GC_mark_stack_size = n;\n+#\t  ifdef PRINTSTATS\n+\t      GC_printf1(\"Grew mark stack to %lu frames\\n\",\n+\t\t    \t (unsigned long) GC_mark_stack_size);\n+#\t  endif\n+        } else {\n+#\t  ifdef PRINTSTATS\n+\t      GC_printf1(\"Failed to grow mark stack to %lu frames\\n\",\n+\t\t    \t (unsigned long) n);\n+#\t  endif\n+        }\n+    } else {\n+        if (new_stack == 0) {\n+            GC_err_printf0(\"No space for mark stack\\n\");\n+            EXIT();\n+        }\n+        GC_mark_stack = new_stack;\n+        GC_mark_stack_size = n;\n+    }\n+    GC_mark_stack_top = GC_mark_stack-1;\n+}\n+\n+void GC_mark_init()\n+{\n+    alloc_mark_stack(INITIAL_MARK_STACK_SIZE);\n+}\n+\n+/*\n+ * Push all locations between b and t onto the mark stack.\n+ * b is the first location to be checked. t is one past the last\n+ * location to be checked.\n+ * Should only be used if there is no possibility of mark stack\n+ * overflow.\n+ */\n+void GC_push_all(bottom, top)\n+ptr_t bottom;\n+ptr_t top;\n+{\n+    register word length;\n+    \n+    bottom = (ptr_t)(((word) bottom + ALIGNMENT-1) & ~(ALIGNMENT-1));\n+    top = (ptr_t)(((word) top) & ~(ALIGNMENT-1));\n+    if (top == 0 || bottom == top) return;\n+    GC_mark_stack_top++;\n+    if (GC_mark_stack_top >= GC_mark_stack + GC_mark_stack_size) {\n+\tABORT(\"unexpected mark stack overflow\");\n+    }\n+    length = top - bottom;\n+#   if DS_TAGS > ALIGNMENT - 1\n+\tlength += DS_TAGS;\n+\tlength &= ~DS_TAGS;\n+#   endif\n+    GC_mark_stack_top -> mse_start = (word *)bottom;\n+    GC_mark_stack_top -> mse_descr = length;\n+}\n+\n+/*\n+ * Analogous to the above, but push only those pages that may have been\n+ * dirtied.  A block h is assumed dirty if dirty_fn(h) != 0.\n+ * We use push_fn to actually push the block.\n+ * Will not overflow mark stack if push_fn pushes a small fixed number\n+ * of entries.  (This is invoked only if push_fn pushes a single entry,\n+ * or if it marks each object before pushing it, thus ensuring progress\n+ * in the event of a stack overflow.)\n+ */\n+void GC_push_dirty(bottom, top, dirty_fn, push_fn)\n+ptr_t bottom;\n+ptr_t top;\n+int (*dirty_fn)(/* struct hblk * h */);\n+void (*push_fn)(/* ptr_t bottom, ptr_t top */);\n+{\n+    register struct hblk * h;\n+\n+    bottom = (ptr_t)(((long) bottom + ALIGNMENT-1) & ~(ALIGNMENT-1));\n+    top = (ptr_t)(((long) top) & ~(ALIGNMENT-1));\n+\n+    if (top == 0 || bottom == top) return;\n+    h = HBLKPTR(bottom + HBLKSIZE);\n+    if (top <= (ptr_t) h) {\n+  \tif ((*dirty_fn)(h-1)) {\n+\t    (*push_fn)(bottom, top);\n+\t}\n+\treturn;\n+    }\n+    if ((*dirty_fn)(h-1)) {\n+        (*push_fn)(bottom, (ptr_t)h);\n+    }\n+    while ((ptr_t)(h+1) <= top) {\n+\tif ((*dirty_fn)(h)) {\n+\t    if ((word)(GC_mark_stack_top - GC_mark_stack)\n+\t\t> 3 * GC_mark_stack_size / 4) {\n+\t \t/* Danger of mark stack overflow */\n+\t\t(*push_fn)((ptr_t)h, top);\n+\t\treturn;\n+\t    } else {\n+\t\t(*push_fn)((ptr_t)h, (ptr_t)(h+1));\n+\t    }\n+\t}\n+\th++;\n+    }\n+    if ((ptr_t)h != top) {\n+\tif ((*dirty_fn)(h)) {\n+            (*push_fn)((ptr_t)h, top);\n+        }\n+    }\n+    if (GC_mark_stack_top >= GC_mark_stack + GC_mark_stack_size) {\n+        ABORT(\"unexpected mark stack overflow\");\n+    }\n+}\n+\n+# ifndef SMALL_CONFIG\n+void GC_push_conditional(bottom, top, all)\n+ptr_t bottom;\n+ptr_t top;\n+int all;\n+{\n+    if (all) {\n+      if (GC_dirty_maintained) {\n+#\tifdef PROC_VDB\n+\t    /* Pages that were never dirtied cannot contain pointers\t*/\n+\t    GC_push_dirty(bottom, top, GC_page_was_ever_dirty, GC_push_all);\n+#\telse\n+\t    GC_push_all(bottom, top);\n+#\tendif\n+      } else {\n+      \tGC_push_all(bottom, top);\n+      }\n+    } else {\n+\tGC_push_dirty(bottom, top, GC_page_was_dirty, GC_push_all);\n+    }\n+}\n+#endif\n+\n+# ifdef MSWIN32\n+  void __cdecl GC_push_one(p)\n+# else\n+  void GC_push_one(p)\n+# endif\n+word p;\n+{\n+    GC_PUSH_ONE_STACK(p);\n+}\n+\n+# ifdef __STDC__\n+#   define BASE(p) (word)GC_base((void *)(p))\n+# else\n+#   define BASE(p) (word)GC_base((char *)(p))\n+# endif\n+\n+/* As above, but argument passed preliminary test. */\n+# ifdef PRINT_BLACK_LIST\n+    void GC_push_one_checked(p, interior_ptrs, source)\n+    ptr_t source;\n+# else\n+    void GC_push_one_checked(p, interior_ptrs)\n+#   define source 0\n+# endif\n+register word p;\n+register GC_bool interior_ptrs;\n+{\n+    register word r;\n+    register hdr * hhdr; \n+    register int displ;\n+  \n+    GET_HDR(p, hhdr);\n+    if (IS_FORWARDING_ADDR_OR_NIL(hhdr)) {\n+        if (hhdr != 0 && interior_ptrs) {\n+          r = BASE(p);\n+\t  hhdr = HDR(r);\n+\t  displ = BYTES_TO_WORDS(HBLKDISPL(r));\n+\t} else {\n+\t  hhdr = 0;\n+\t}\n+    } else {\n+        register map_entry_type map_entry;\n+        \n+        displ = HBLKDISPL(p);\n+        map_entry = MAP_ENTRY((hhdr -> hb_map), displ);\n+        if (map_entry == OBJ_INVALID) {\n+          if (interior_ptrs) {\n+            r = BASE(p);\n+\t    displ = BYTES_TO_WORDS(HBLKDISPL(r));\n+\t    if (r == 0) hhdr = 0;\n+          } else {\n+            hhdr = 0;\n+          }\n+        } else {\n+          displ = BYTES_TO_WORDS(displ);\n+          displ -= map_entry;\n+          r = (word)((word *)(HBLKPTR(p)) + displ);\n+        }\n+    }\n+    /* If hhdr != 0 then r == GC_base(p), only we did it faster. */\n+    /* displ is the word index within the block.\t\t */\n+    if (hhdr == 0) {\n+    \tif (interior_ptrs) {\n+#\t    ifdef PRINT_BLACK_LIST\n+\t      GC_add_to_black_list_stack(p, source);\n+#\t    else\n+\t      GC_add_to_black_list_stack(p);\n+#\t    endif\n+\t} else {\n+\t    GC_ADD_TO_BLACK_LIST_NORMAL(p, source);\n+#\t    undef source  /* In case we had to define it. */\n+\t}\n+    } else {\n+\tif (!mark_bit_from_hdr(hhdr, displ)) {\n+\t    set_mark_bit_from_hdr(hhdr, displ);\n+\t    PUSH_OBJ((word *)r, hhdr, GC_mark_stack_top,\n+\t             &(GC_mark_stack[GC_mark_stack_size]));\n+\t}\n+    }\n+}\n+\n+# ifdef TRACE_BUF\n+\n+# define TRACE_ENTRIES 1000\n+\n+struct trace_entry {\n+    char * kind;\n+    word gc_no;\n+    word words_allocd;\n+    word arg1;\n+    word arg2;\n+} GC_trace_buf[TRACE_ENTRIES];\n+\n+int GC_trace_buf_ptr = 0;\n+\n+void GC_add_trace_entry(char *kind, word arg1, word arg2)\n+{\n+    GC_trace_buf[GC_trace_buf_ptr].kind = kind;\n+    GC_trace_buf[GC_trace_buf_ptr].gc_no = GC_gc_no;\n+    GC_trace_buf[GC_trace_buf_ptr].words_allocd = GC_words_allocd;\n+    GC_trace_buf[GC_trace_buf_ptr].arg1 = arg1 ^ 0x80000000;\n+    GC_trace_buf[GC_trace_buf_ptr].arg2 = arg2 ^ 0x80000000;\n+    GC_trace_buf_ptr++;\n+    if (GC_trace_buf_ptr >= TRACE_ENTRIES) GC_trace_buf_ptr = 0;\n+}\n+\n+void GC_print_trace(word gc_no, GC_bool lock)\n+{\n+    int i;\n+    struct trace_entry *p;\n+    \n+    if (lock) LOCK();\n+    for (i = GC_trace_buf_ptr-1; i != GC_trace_buf_ptr; i--) {\n+    \tif (i < 0) i = TRACE_ENTRIES-1;\n+    \tp = GC_trace_buf + i;\n+    \tif (p -> gc_no < gc_no || p -> kind == 0) return;\n+    \tprintf(\"Trace:%s (gc:%d,words:%d) 0x%X, 0x%X\\n\",\n+    \t\tp -> kind, p -> gc_no, p -> words_allocd,\n+    \t\t(p -> arg1) ^ 0x80000000, (p -> arg2) ^ 0x80000000);\n+    }\n+    printf(\"Trace incomplete\\n\");\n+    if (lock) UNLOCK();\n+}\n+\n+# endif /* TRACE_BUF */\n+\n+/*\n+ * A version of GC_push_all that treats all interior pointers as valid\n+ */\n+void GC_push_all_stack(bottom, top)\n+ptr_t bottom;\n+ptr_t top;\n+{\n+# ifdef ALL_INTERIOR_POINTERS\n+    GC_push_all(bottom, top);\n+#   ifdef TRACE_BUF\n+        GC_add_trace_entry(\"GC_push_all_stack\", bottom, top);\n+#   endif\n+# else\n+    word * b = (word *)(((long) bottom + ALIGNMENT-1) & ~(ALIGNMENT-1));\n+    word * t = (word *)(((long) top) & ~(ALIGNMENT-1));\n+    register word *p;\n+    register word q;\n+    register word *lim;\n+    register ptr_t greatest_ha = GC_greatest_plausible_heap_addr;\n+    register ptr_t least_ha = GC_least_plausible_heap_addr;\n+#   define GC_greatest_plausible_heap_addr greatest_ha\n+#   define GC_least_plausible_heap_addr least_ha\n+\n+    if (top == 0) return;\n+    /* check all pointers in range and put in push if they appear */\n+    /* to be valid.\t\t\t\t\t\t  */\n+      lim = t - 1 /* longword */;\n+      for (p = b; p <= lim; p = (word *)(((char *)p) + ALIGNMENT)) {\n+\tq = *p;\n+\tGC_PUSH_ONE_STACK(q);\n+      }\n+#   undef GC_greatest_plausible_heap_addr\n+#   undef GC_least_plausible_heap_addr\n+# endif\n+}\n+\n+#ifndef SMALL_CONFIG\n+/* Push all objects reachable from marked objects in the given block */\n+/* of size 1 objects.\t\t\t\t\t\t     */\n+void GC_push_marked1(h, hhdr)\n+struct hblk *h;\n+register hdr * hhdr;\n+{\n+    word * mark_word_addr = &(hhdr->hb_marks[divWORDSZ(HDR_WORDS)]);\n+    register word *p;\n+    word *plim;\n+    register int i;\n+    register word q;\n+    register word mark_word;\n+    register ptr_t greatest_ha = GC_greatest_plausible_heap_addr;\n+    register ptr_t least_ha = GC_least_plausible_heap_addr;\n+#   define GC_greatest_plausible_heap_addr greatest_ha\n+#   define GC_least_plausible_heap_addr least_ha\n+    \n+    p = (word *)(h->hb_body);\n+    plim = (word *)(((word)h) + HBLKSIZE);\n+\n+    /* go through all words in block */\n+\twhile( p < plim )  {\n+\t    mark_word = *mark_word_addr++;\n+\t    i = 0;\n+\t    while(mark_word != 0) {\n+\t      if (mark_word & 1) {\n+\t          q = p[i];\n+\t          GC_PUSH_ONE_HEAP(q);\n+\t      }\n+\t      i++;\n+\t      mark_word >>= 1;\n+\t    }\n+\t    p += WORDSZ;\n+\t}\n+#   undef GC_greatest_plausible_heap_addr\n+#   undef GC_least_plausible_heap_addr        \n+}\n+\n+\n+#ifndef UNALIGNED\n+\n+/* Push all objects reachable from marked objects in the given block */\n+/* of size 2 objects.\t\t\t\t\t\t     */\n+void GC_push_marked2(h, hhdr)\n+struct hblk *h;\n+register hdr * hhdr;\n+{\n+    word * mark_word_addr = &(hhdr->hb_marks[divWORDSZ(HDR_WORDS)]);\n+    register word *p;\n+    word *plim;\n+    register int i;\n+    register word q;\n+    register word mark_word;\n+    register ptr_t greatest_ha = GC_greatest_plausible_heap_addr;\n+    register ptr_t least_ha = GC_least_plausible_heap_addr;\n+#   define GC_greatest_plausible_heap_addr greatest_ha\n+#   define GC_least_plausible_heap_addr least_ha\n+    \n+    p = (word *)(h->hb_body);\n+    plim = (word *)(((word)h) + HBLKSIZE);\n+\n+    /* go through all words in block */\n+\twhile( p < plim )  {\n+\t    mark_word = *mark_word_addr++;\n+\t    i = 0;\n+\t    while(mark_word != 0) {\n+\t      if (mark_word & 1) {\n+\t          q = p[i];\n+\t          GC_PUSH_ONE_HEAP(q);\n+\t          q = p[i+1];\n+\t          GC_PUSH_ONE_HEAP(q);\n+\t      }\n+\t      i += 2;\n+\t      mark_word >>= 2;\n+\t    }\n+\t    p += WORDSZ;\n+\t}\n+#   undef GC_greatest_plausible_heap_addr\n+#   undef GC_least_plausible_heap_addr        \n+}\n+\n+/* Push all objects reachable from marked objects in the given block */\n+/* of size 4 objects.\t\t\t\t\t\t     */\n+/* There is a risk of mark stack overflow here.  But we handle that. */\n+/* And only unmarked objects get pushed, so it's not very likely.    */\n+void GC_push_marked4(h, hhdr)\n+struct hblk *h;\n+register hdr * hhdr;\n+{\n+    word * mark_word_addr = &(hhdr->hb_marks[divWORDSZ(HDR_WORDS)]);\n+    register word *p;\n+    word *plim;\n+    register int i;\n+    register word q;\n+    register word mark_word;\n+    register ptr_t greatest_ha = GC_greatest_plausible_heap_addr;\n+    register ptr_t least_ha = GC_least_plausible_heap_addr;\n+#   define GC_greatest_plausible_heap_addr greatest_ha\n+#   define GC_least_plausible_heap_addr least_ha\n+    \n+    p = (word *)(h->hb_body);\n+    plim = (word *)(((word)h) + HBLKSIZE);\n+\n+    /* go through all words in block */\n+\twhile( p < plim )  {\n+\t    mark_word = *mark_word_addr++;\n+\t    i = 0;\n+\t    while(mark_word != 0) {\n+\t      if (mark_word & 1) {\n+\t          q = p[i];\n+\t          GC_PUSH_ONE_HEAP(q);\n+\t          q = p[i+1];\n+\t          GC_PUSH_ONE_HEAP(q);\n+\t          q = p[i+2];\n+\t          GC_PUSH_ONE_HEAP(q);\n+\t          q = p[i+3];\n+\t          GC_PUSH_ONE_HEAP(q);\n+\t      }\n+\t      i += 4;\n+\t      mark_word >>= 4;\n+\t    }\n+\t    p += WORDSZ;\n+\t}\n+#   undef GC_greatest_plausible_heap_addr\n+#   undef GC_least_plausible_heap_addr        \n+}\n+\n+#endif /* UNALIGNED */\n+\n+#endif /* SMALL_CONFIG */\n+\n+/* Push all objects reachable from marked objects in the given block */\n+void GC_push_marked(h, hhdr)\n+struct hblk *h;\n+register hdr * hhdr;\n+{\n+    register int sz = hhdr -> hb_sz;\n+    register word * p;\n+    register int word_no;\n+    register word * lim;\n+    register mse * GC_mark_stack_top_reg;\n+    register mse * mark_stack_limit = &(GC_mark_stack[GC_mark_stack_size]);\n+    \n+    /* Some quick shortcuts: */\n+\t{ \n+\t    struct obj_kind *ok = &(GC_obj_kinds[hhdr -> hb_obj_kind]);\n+\t    if ((0 | DS_LENGTH) == ok -> ok_descriptor\n+\t\t&& FALSE == ok -> ok_relocate_descr)\n+\t\treturn;\n+\t}\n+        if (GC_block_empty(hhdr)/* nothing marked */) return;\n+#   ifdef GATHERSTATS\n+        GC_n_rescuing_pages++;\n+#   endif\n+    GC_objects_are_marked = TRUE;\n+    if (sz > MAXOBJSZ) {\n+        lim = (word *)(h + 1);\n+    } else {\n+        lim = (word *)(h + 1) - sz;\n+    }\n+    \n+    switch(sz) {\n+#   if !defined(SMALL_CONFIG)    \n+     case 1:\n+       GC_push_marked1(h, hhdr);\n+       break;\n+#   endif\n+#   if !defined(SMALL_CONFIG) && !defined(UNALIGNED)\n+     case 2:\n+       GC_push_marked2(h, hhdr);\n+       break;\n+     case 4:\n+       GC_push_marked4(h, hhdr);\n+       break;\n+#   endif       \n+     default:\n+      GC_mark_stack_top_reg = GC_mark_stack_top;\n+      for (p = (word *)h + HDR_WORDS, word_no = HDR_WORDS; p <= lim;\n+         p += sz, word_no += sz) {\n+         /* This ignores user specified mark procs.  This currently\t*/\n+         /* doesn't matter, since marking from the whole object\t\t*/\n+         /* is always sufficient, and we will eventually use the user\t*/\n+         /* mark proc to avoid any bogus pointers.\t\t\t*/\n+         if (mark_bit_from_hdr(hhdr, word_no)) {\n+           /* Mark from fields inside the object */\n+             PUSH_OBJ((word *)p, hhdr, GC_mark_stack_top_reg, mark_stack_limit);\n+#\t     ifdef GATHERSTATS\n+\t\t/* Subtract this object from total, since it was\t*/\n+\t\t/* added in twice.\t\t\t\t\t*/\n+\t\tGC_composite_in_use -= sz;\n+#\t     endif\n+         }\n+      }\n+      GC_mark_stack_top = GC_mark_stack_top_reg;\n+    }\n+}\n+\n+#ifndef SMALL_CONFIG\n+/* Test whether any page in the given block is dirty\t*/\n+GC_bool GC_block_was_dirty(h, hhdr)\n+struct hblk *h;\n+register hdr * hhdr;\n+{\n+    register int sz = hhdr -> hb_sz;\n+    \n+    if (sz < MAXOBJSZ) {\n+         return(GC_page_was_dirty(h));\n+    } else {\n+    \t register ptr_t p = (ptr_t)h;\n+         sz += HDR_WORDS;\n+         sz = WORDS_TO_BYTES(sz);\n+         while (p < (ptr_t)h + sz) {\n+             if (GC_page_was_dirty((struct hblk *)p)) return(TRUE);\n+             p += HBLKSIZE;\n+         }\n+         return(FALSE);\n+    }\n+}\n+#endif /* SMALL_CONFIG */\n+\n+/* Similar to GC_push_next_marked, but return address of next block\t*/\n+struct hblk * GC_push_next_marked(h)\n+struct hblk *h;\n+{\n+    register hdr * hhdr;\n+    \n+    h = GC_next_block(h);\n+    if (h == 0) return(0);\n+    hhdr = HDR(h);\n+    GC_push_marked(h, hhdr);\n+    return(h + OBJ_SZ_TO_BLOCKS(hhdr -> hb_sz));\n+}\n+\n+#ifndef SMALL_CONFIG\n+/* Identical to above, but mark only from dirty pages\t*/\n+struct hblk * GC_push_next_marked_dirty(h)\n+struct hblk *h;\n+{\n+    register hdr * hhdr = HDR(h);\n+    \n+    if (!GC_dirty_maintained) { ABORT(\"dirty bits not set up\"); }\n+    for (;;) {\n+        h = GC_next_block(h);\n+        if (h == 0) return(0);\n+        hhdr = HDR(h);\n+#\tifdef STUBBORN_ALLOC\n+          if (hhdr -> hb_obj_kind == STUBBORN) {\n+            if (GC_page_was_changed(h) && GC_block_was_dirty(h, hhdr)) {\n+                break;\n+            }\n+          } else {\n+            if (GC_block_was_dirty(h, hhdr)) break;\n+          }\n+#\telse\n+\t  if (GC_block_was_dirty(h, hhdr)) break;\n+#\tendif\n+        h += OBJ_SZ_TO_BLOCKS(hhdr -> hb_sz);\n+    }\n+    GC_push_marked(h, hhdr);\n+    return(h + OBJ_SZ_TO_BLOCKS(hhdr -> hb_sz));\n+}\n+#endif\n+\n+/* Similar to above, but for uncollectable pages.  Needed since we\t*/\n+/* do not clear marks for such pages, even for full collections.\t*/\n+struct hblk * GC_push_next_marked_uncollectable(h)\n+struct hblk *h;\n+{\n+    register hdr * hhdr = HDR(h);\n+    \n+    for (;;) {\n+        h = GC_next_block(h);\n+        if (h == 0) return(0);\n+        hhdr = HDR(h);\n+\tif (hhdr -> hb_obj_kind == UNCOLLECTABLE) break;\n+        h += OBJ_SZ_TO_BLOCKS(hhdr -> hb_sz);\n+    }\n+    GC_push_marked(h, hhdr);\n+    return(h + OBJ_SZ_TO_BLOCKS(hhdr -> hb_sz));\n+}\n+\n+"}]}