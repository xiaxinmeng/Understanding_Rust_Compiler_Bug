{"sha": "f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZjZmZDhmMmJkNGU5YTkxYjQ2ODNlMmNiYjE0NDYzMWZmMjAxZjU4Nw==", "commit": {"author": {"name": "Jan Hubicka", "email": "hubicka@ucw.cz", "date": "2017-10-21T11:53:33Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2017-10-21T11:53:33Z"}, "message": "pr79683.c: Disable costmodel.\n\n\n\t* gcc.target/i386/pr79683.c: Disable costmodel.\n\t* i386.c (ix86_builtin_vectorization_cost): Use existing rtx_cost\n\tlatencies instead of having separate table; make difference between\n\tinteger and float costs.\n\t* i386.h (processor_costs): Remove scalar_stmt_cost,\n\tscalar_load_cost, scalar_store_cost, vec_stmt_cost, vec_to_scalar_cost,\n\tscalar_to_vec_cost, vec_align_load_cost, vec_unalign_load_cost,\n\tvec_store_cost.\n\t* x86-tune-costs.h: Remove entries which has been removed in\n\tprocesor_costs from all tables; make cond_taken_branch_cost\n\tand cond_not_taken_branch_cost COST_N_INSNS based.\nIndex: testsuite/gcc.target/i386/pr79683.c\n===================================================================\n--- testsuite/gcc.target/i386/pr79683.c\t(revision 253957)\n+++ testsuite/gcc.target/i386/pr79683.c\t(working copy)\n@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O3 -msse2\" } */\n+/* { dg-options \"-O3 -msse2 -fvect-cost-model=unlimited\" } */\n \n struct s {\n     __INT64_TYPE__ a;\nIndex: config/i386/i386.c\n===================================================================\n--- config/i386/i386.c\t(revision 253957)\n+++ config/i386/i386.c\t(working copy)\n@@ -44051,37 +44051,61 @@ static int\n ix86_builtin_vectorization_cost (enum vect_cost_for_stmt type_of_cost,\n                                  tree vectype, int)\n {\n+  bool fp = false;\n+  machine_mode mode = TImode;\n+  if (vectype != NULL)\n+    {\n+      fp = FLOAT_TYPE_P (vectype);\n+      mode = TYPE_MODE (vectype);\n+    }\n+\n   switch (type_of_cost)\n     {\n       case scalar_stmt:\n-        return ix86_cost->scalar_stmt_cost;\n+        return fp ? ix86_cost->addss : COSTS_N_INSNS (1);\n \n       case scalar_load:\n-        return ix86_cost->scalar_load_cost;\n+\t/* load/store costs are relative to register move which is 2. Recompute\n+ \t   it to COSTS_N_INSNS so everything have same base.  */\n+        return COSTS_N_INSNS (fp ? ix86_cost->sse_load[0]\n+\t\t\t      : ix86_cost->int_load [2]) / 2;\n \n       case scalar_store:\n-        return ix86_cost->scalar_store_cost;\n+        return COSTS_N_INSNS (fp ? ix86_cost->sse_store[0]\n+\t\t\t      : ix86_cost->int_store [2]) / 2;\n \n       case vector_stmt:\n-        return ix86_cost->vec_stmt_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      fp ? ix86_cost->addss : ix86_cost->sse_op,\n+\t\t\t      true);\n \n       case vector_load:\n-        return ix86_cost->vec_align_load_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_load[2]) / 2,\n+\t\t\t      true);\n \n       case vector_store:\n-        return ix86_cost->vec_store_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_store[2]) / 2,\n+\t\t\t      true);\n \n       case vec_to_scalar:\n-        return ix86_cost->vec_to_scalar_cost;\n-\n       case scalar_to_vec:\n-        return ix86_cost->scalar_to_vec_cost;\n+        return ix86_vec_cost (mode, ix86_cost->sse_op, true);\n \n+      /* We should have separate costs for unaligned loads and gather/scatter.\n+\t Do that incrementally.  */\n       case unaligned_load:\n-      case unaligned_store:\n       case vector_gather_load:\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_load[2]),\n+\t\t\t      true);\n+\n+      case unaligned_store:\n       case vector_scatter_store:\n-        return ix86_cost->vec_unalign_load_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_store[2]),\n+\t\t\t      true);\n \n       case cond_branch_taken:\n         return ix86_cost->cond_taken_branch_cost;\n@@ -44091,10 +44115,11 @@ ix86_builtin_vectorization_cost (enum ve\n \n       case vec_perm:\n       case vec_promote_demote:\n-        return ix86_cost->vec_stmt_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      ix86_cost->sse_op, true);\n \n       case vec_construct:\n-\treturn ix86_cost->vec_stmt_cost * (TYPE_VECTOR_SUBPARTS (vectype) - 1);\n+\treturn ix86_vec_cost (mode, ix86_cost->sse_op, false);\n \n       default:\n         gcc_unreachable ();\nIndex: config/i386/i386.h\n===================================================================\n--- config/i386/i386.h\t(revision 253957)\n+++ config/i386/i386.h\t(working copy)\n@@ -277,18 +277,6 @@ struct processor_costs {\n \t\t\t\t   parallel.  See also\n \t\t\t\t   ix86_reassociation_width.  */\n   struct stringop_algs *memcpy, *memset;\n-  const int scalar_stmt_cost;   /* Cost of any scalar operation, excluding\n-\t\t\t\t   load and store.  */\n-  const int scalar_load_cost;   /* Cost of scalar load.  */\n-  const int scalar_store_cost;  /* Cost of scalar store.  */\n-  const int vec_stmt_cost;      /* Cost of any vector operation, excluding\n-                                   load, store, vector-to-scalar and\n-                                   scalar-to-vector operation.  */\n-  const int vec_to_scalar_cost;    /* Cost of vect-to-scalar operation.  */\n-  const int scalar_to_vec_cost;    /* Cost of scalar-to-vector operation.  */\n-  const int vec_align_load_cost;   /* Cost of aligned vector load.  */\n-  const int vec_unalign_load_cost; /* Cost of unaligned vector load.  */\n-  const int vec_store_cost;        /* Cost of vector store.  */\n   const int cond_taken_branch_cost;    /* Cost of taken branch for vectorizer\n \t\t\t\t\t  cost model.  */\n   const int cond_not_taken_branch_cost;/* Cost of not taken branch for\nIndex: config/i386/x86-tune-costs.h\n===================================================================\n--- config/i386/x86-tune-costs.h\t(revision 253958)\n+++ config/i386/x86-tune-costs.h\t(working copy)\n@@ -79,17 +79,8 @@ struct processor_costs ix86_size_cost =\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   ix86_size_memcpy,\n   ix86_size_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  1,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  1,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_BYTES (1),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_BYTES (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* Processor costs (relative to an add) */\n@@ -167,17 +158,8 @@ struct processor_costs i386_cost = {\t/*\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   i386_memcpy,\n   i386_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs i486_memcpy[2] = {\n@@ -256,17 +238,8 @@ struct processor_costs i486_cost = {\t/*\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   i486_memcpy,\n   i486_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs pentium_memcpy[2] = {\n@@ -343,17 +316,8 @@ struct processor_costs pentium_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentium_memcpy,\n   pentium_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static const\n@@ -423,17 +387,8 @@ struct processor_costs lakemont_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentium_memcpy,\n   pentium_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* PentiumPro has optimized rep instructions for blocks aligned by 8 bytes\n@@ -518,17 +473,8 @@ struct processor_costs pentiumpro_cost =\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentiumpro_memcpy,\n   pentiumpro_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs geode_memcpy[2] = {\n@@ -605,17 +551,8 @@ struct processor_costs geode_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   geode_memcpy,\n   geode_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs k6_memcpy[2] = {\n@@ -694,17 +631,8 @@ struct processor_costs k6_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   k6_memcpy,\n   k6_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* For some reason, Athlon deals better with REP prefix (relative to loops)\n@@ -784,17 +712,8 @@ struct processor_costs athlon_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   athlon_memcpy,\n   athlon_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* K8 has optimized REP instruction for medium sized blocks, but for very\n@@ -883,17 +802,8 @@ struct processor_costs k8_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   k8_memcpy,\n   k8_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  5,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  3,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  3,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* AMDFAM10 has optimized REP instruction for medium sized blocks, but for\n@@ -989,17 +899,8 @@ struct processor_costs amdfam10_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   amdfam10_memcpy,\n   amdfam10_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  2,\t\t\t\t\t/* vec_store_cost.  */\n-  2,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /*  BDVER1 has optimized REP instruction for medium sized blocks, but for\n@@ -1097,17 +998,8 @@ const struct processor_costs bdver1_cost\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver1_memcpy,\n   bdver1_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /*  BDVER2 has optimized REP instruction for medium sized blocks, but for\n@@ -1206,17 +1098,8 @@ const struct processor_costs bdver2_cost\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver2_memcpy,\n   bdver2_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n \n@@ -1306,17 +1189,8 @@ struct processor_costs bdver3_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver3_memcpy,\n   bdver3_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /*  BDVER4 has optimized REP instruction for medium sized blocks, but for\n@@ -1405,17 +1279,8 @@ struct processor_costs bdver4_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver4_memcpy,\n   bdver4_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n \n@@ -1524,17 +1389,8 @@ struct processor_costs znver1_cost = {\n   4, 4, 3, 6,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   znver1_memcpy,\n   znver1_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n   /* BTVER1 has optimized REP instruction for medium sized blocks, but for\n@@ -1624,17 +1480,8 @@ const struct processor_costs btver1_cost\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   btver1_memcpy,\n   btver1_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  2,\t\t\t\t\t/* vec_store_cost.  */\n-  2,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs btver2_memcpy[2] = {\n@@ -1721,17 +1568,8 @@ const struct processor_costs btver2_cost\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   btver2_memcpy,\n   btver2_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  2,\t\t\t\t\t/* vec_store_cost.  */\n-  2,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs pentium4_memcpy[2] = {\n@@ -1809,17 +1647,8 @@ struct processor_costs pentium4_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentium4_memcpy,\n   pentium4_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs nocona_memcpy[2] = {\n@@ -1900,17 +1729,8 @@ struct processor_costs nocona_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   nocona_memcpy,\n   nocona_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs atom_memcpy[2] = {\n@@ -1989,17 +1809,8 @@ struct processor_costs atom_cost = {\n   2, 2, 2, 2,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   atom_memcpy,\n   atom_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs slm_memcpy[2] = {\n@@ -2078,17 +1889,8 @@ struct processor_costs slm_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   slm_memcpy,\n   slm_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  4,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs intel_memcpy[2] = {\n@@ -2167,17 +1969,8 @@ struct processor_costs intel_cost = {\n   1, 4, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   intel_memcpy,\n   intel_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  4,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* Generic should produce code tuned for Core-i7 (and newer chips)\n@@ -2265,17 +2058,8 @@ struct processor_costs generic_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   generic_memcpy,\n   generic_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* core_cost should produce code tuned for Core familly of CPUs.  */\n@@ -2366,16 +2150,7 @@ struct processor_costs core_cost = {\n   1, 4, 2, 2,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   core_memcpy,\n   core_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n\nFrom-SVN: r253975", "tree": {"sha": "e64052852787834f82c8f9841f63852decf73eae", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e64052852787834f82c8f9841f63852decf73eae"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/comments", "author": null, "committer": null, "parents": [{"sha": "0071b8a19bf23ea427c0c0fa971e75f16cbe1158", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0071b8a19bf23ea427c0c0fa971e75f16cbe1158", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0071b8a19bf23ea427c0c0fa971e75f16cbe1158"}], "stats": {"total": 394, "additions": 93, "deletions": 301}, "files": [{"sha": "7f9d694d21753e90f6b863e3fc34267b644f3641", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 38, "deletions": 13, "changes": 51, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "patch": "@@ -44051,37 +44051,61 @@ static int\n ix86_builtin_vectorization_cost (enum vect_cost_for_stmt type_of_cost,\n                                  tree vectype, int)\n {\n+  bool fp = false;\n+  machine_mode mode = TImode;\n+  if (vectype != NULL)\n+    {\n+      fp = FLOAT_TYPE_P (vectype);\n+      mode = TYPE_MODE (vectype);\n+    }\n+\n   switch (type_of_cost)\n     {\n       case scalar_stmt:\n-        return ix86_cost->scalar_stmt_cost;\n+        return fp ? ix86_cost->addss : COSTS_N_INSNS (1);\n \n       case scalar_load:\n-        return ix86_cost->scalar_load_cost;\n+\t/* load/store costs are relative to register move which is 2. Recompute\n+ \t   it to COSTS_N_INSNS so everything have same base.  */\n+        return COSTS_N_INSNS (fp ? ix86_cost->sse_load[0]\n+\t\t\t      : ix86_cost->int_load [2]) / 2;\n \n       case scalar_store:\n-        return ix86_cost->scalar_store_cost;\n+        return COSTS_N_INSNS (fp ? ix86_cost->sse_store[0]\n+\t\t\t      : ix86_cost->int_store [2]) / 2;\n \n       case vector_stmt:\n-        return ix86_cost->vec_stmt_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      fp ? ix86_cost->addss : ix86_cost->sse_op,\n+\t\t\t      true);\n \n       case vector_load:\n-        return ix86_cost->vec_align_load_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_load[2]) / 2,\n+\t\t\t      true);\n \n       case vector_store:\n-        return ix86_cost->vec_store_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_store[2]) / 2,\n+\t\t\t      true);\n \n       case vec_to_scalar:\n-        return ix86_cost->vec_to_scalar_cost;\n-\n       case scalar_to_vec:\n-        return ix86_cost->scalar_to_vec_cost;\n+        return ix86_vec_cost (mode, ix86_cost->sse_op, true);\n \n+      /* We should have separate costs for unaligned loads and gather/scatter.\n+\t Do that incrementally.  */\n       case unaligned_load:\n-      case unaligned_store:\n       case vector_gather_load:\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_load[2]),\n+\t\t\t      true);\n+\n+      case unaligned_store:\n       case vector_scatter_store:\n-        return ix86_cost->vec_unalign_load_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      COSTS_N_INSNS (ix86_cost->sse_store[2]),\n+\t\t\t      true);\n \n       case cond_branch_taken:\n         return ix86_cost->cond_taken_branch_cost;\n@@ -44091,10 +44115,11 @@ ix86_builtin_vectorization_cost (enum vect_cost_for_stmt type_of_cost,\n \n       case vec_perm:\n       case vec_promote_demote:\n-        return ix86_cost->vec_stmt_cost;\n+        return ix86_vec_cost (mode,\n+\t\t\t      ix86_cost->sse_op, true);\n \n       case vec_construct:\n-\treturn ix86_cost->vec_stmt_cost * (TYPE_VECTOR_SUBPARTS (vectype) - 1);\n+\treturn ix86_vec_cost (mode, ix86_cost->sse_op, false);\n \n       default:\n         gcc_unreachable ();"}, {"sha": "a63c13234c5d5d7c3b7b0f8e1a959dde0ff26c62", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 0, "deletions": 12, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "patch": "@@ -277,18 +277,6 @@ struct processor_costs {\n \t\t\t\t   parallel.  See also\n \t\t\t\t   ix86_reassociation_width.  */\n   struct stringop_algs *memcpy, *memset;\n-  const int scalar_stmt_cost;   /* Cost of any scalar operation, excluding\n-\t\t\t\t   load and store.  */\n-  const int scalar_load_cost;   /* Cost of scalar load.  */\n-  const int scalar_store_cost;  /* Cost of scalar store.  */\n-  const int vec_stmt_cost;      /* Cost of any vector operation, excluding\n-                                   load, store, vector-to-scalar and\n-                                   scalar-to-vector operation.  */\n-  const int vec_to_scalar_cost;    /* Cost of vect-to-scalar operation.  */\n-  const int scalar_to_vec_cost;    /* Cost of scalar-to-vector operation.  */\n-  const int vec_align_load_cost;   /* Cost of aligned vector load.  */\n-  const int vec_unalign_load_cost; /* Cost of unaligned vector load.  */\n-  const int vec_store_cost;        /* Cost of vector store.  */\n   const int cond_taken_branch_cost;    /* Cost of taken branch for vectorizer\n \t\t\t\t\t  cost model.  */\n   const int cond_not_taken_branch_cost;/* Cost of not taken branch for"}, {"sha": "0bfcac44fe1e7b42ccd8553aeb09617c7144eda9", "filename": "gcc/config/i386/x86-tune-costs.h", "status": "modified", "additions": 50, "deletions": 275, "changes": 325, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Fconfig%2Fi386%2Fx86-tune-costs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Fconfig%2Fi386%2Fx86-tune-costs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fx86-tune-costs.h?ref=f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "patch": "@@ -79,17 +79,8 @@ struct processor_costs ix86_size_cost = {/* costs for tuning for size */\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   ix86_size_memcpy,\n   ix86_size_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  1,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  1,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_BYTES (1),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_BYTES (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* Processor costs (relative to an add) */\n@@ -167,17 +158,8 @@ struct processor_costs i386_cost = {\t/* 386 specific costs */\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   i386_memcpy,\n   i386_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs i486_memcpy[2] = {\n@@ -256,17 +238,8 @@ struct processor_costs i486_cost = {\t/* 486 specific costs */\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   i486_memcpy,\n   i486_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs pentium_memcpy[2] = {\n@@ -343,17 +316,8 @@ struct processor_costs pentium_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentium_memcpy,\n   pentium_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static const\n@@ -423,17 +387,8 @@ struct processor_costs lakemont_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentium_memcpy,\n   pentium_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* PentiumPro has optimized rep instructions for blocks aligned by 8 bytes\n@@ -518,17 +473,8 @@ struct processor_costs pentiumpro_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentiumpro_memcpy,\n   pentiumpro_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs geode_memcpy[2] = {\n@@ -605,17 +551,8 @@ struct processor_costs geode_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   geode_memcpy,\n   geode_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs k6_memcpy[2] = {\n@@ -694,17 +631,8 @@ struct processor_costs k6_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   k6_memcpy,\n   k6_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* For some reason, Athlon deals better with REP prefix (relative to loops)\n@@ -784,17 +712,8 @@ struct processor_costs athlon_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   athlon_memcpy,\n   athlon_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* K8 has optimized REP instruction for medium sized blocks, but for very\n@@ -883,17 +802,8 @@ struct processor_costs k8_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   k8_memcpy,\n   k8_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  5,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  3,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  3,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* AMDFAM10 has optimized REP instruction for medium sized blocks, but for\n@@ -989,17 +899,8 @@ struct processor_costs amdfam10_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   amdfam10_memcpy,\n   amdfam10_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  2,\t\t\t\t\t/* vec_store_cost.  */\n-  2,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /*  BDVER1 has optimized REP instruction for medium sized blocks, but for\n@@ -1097,17 +998,8 @@ const struct processor_costs bdver1_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver1_memcpy,\n   bdver1_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /*  BDVER2 has optimized REP instruction for medium sized blocks, but for\n@@ -1206,17 +1098,8 @@ const struct processor_costs bdver2_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver2_memcpy,\n   bdver2_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n \n@@ -1306,17 +1189,8 @@ struct processor_costs bdver3_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver3_memcpy,\n   bdver3_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /*  BDVER4 has optimized REP instruction for medium sized blocks, but for\n@@ -1405,17 +1279,8 @@ struct processor_costs bdver4_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   bdver4_memcpy,\n   bdver4_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n \n@@ -1524,17 +1389,8 @@ struct processor_costs znver1_cost = {\n   4, 4, 3, 6,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   znver1_memcpy,\n   znver1_memset,\n-  6,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  4,\t\t\t\t\t/* scalar load_cost.  */\n-  4,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  4,\t\t\t\t\t/* vec_align_load_cost.  */\n-  4,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  4,\t\t\t\t\t/* vec_store_cost.  */\n-  4,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  2,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (4),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n   /* BTVER1 has optimized REP instruction for medium sized blocks, but for\n@@ -1624,17 +1480,8 @@ const struct processor_costs btver1_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   btver1_memcpy,\n   btver1_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  2,\t\t\t\t\t/* vec_store_cost.  */\n-  2,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs btver2_memcpy[2] = {\n@@ -1721,17 +1568,8 @@ const struct processor_costs btver2_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   btver2_memcpy,\n   btver2_memset,\n-  4,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  2,\t\t\t\t\t/* scalar load_cost.  */\n-  2,\t\t\t\t\t/* scalar_store_cost.  */\n-  6,\t\t\t\t\t/* vec_stmt_cost.  */\n-  0,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  2,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  2,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  2,\t\t\t\t\t/* vec_store_cost.  */\n-  2,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (2),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs pentium4_memcpy[2] = {\n@@ -1809,17 +1647,8 @@ struct processor_costs pentium4_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   pentium4_memcpy,\n   pentium4_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs nocona_memcpy[2] = {\n@@ -1900,17 +1729,8 @@ struct processor_costs nocona_cost = {\n   1, 1, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   nocona_memcpy,\n   nocona_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs atom_memcpy[2] = {\n@@ -1989,17 +1809,8 @@ struct processor_costs atom_cost = {\n   2, 2, 2, 2,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   atom_memcpy,\n   atom_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs slm_memcpy[2] = {\n@@ -2078,17 +1889,8 @@ struct processor_costs slm_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   slm_memcpy,\n   slm_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  4,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n static stringop_algs intel_memcpy[2] = {\n@@ -2167,17 +1969,8 @@ struct processor_costs intel_cost = {\n   1, 4, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   intel_memcpy,\n   intel_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  4,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* Generic should produce code tuned for Core-i7 (and newer chips)\n@@ -2265,17 +2058,8 @@ struct processor_costs generic_cost = {\n   1, 2, 1, 1,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   generic_memcpy,\n   generic_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n /* core_cost should produce code tuned for Core familly of CPUs.  */\n@@ -2366,16 +2150,7 @@ struct processor_costs core_cost = {\n   1, 4, 2, 2,\t\t\t\t/* reassoc int, fp, vec_int, vec_fp.  */\n   core_memcpy,\n   core_memset,\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n+  COSTS_N_INSNS (3),\t\t\t/* cond_taken_branch_cost.  */\n+  COSTS_N_INSNS (1),\t\t\t/* cond_not_taken_branch_cost.  */\n };\n "}, {"sha": "22405be6a87c4425e99a086bc3ec2a55ad6779cf", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "patch": "@@ -1,3 +1,7 @@\n+2017-10-20  Jan Hubicka  <hubicka@ucw.cz>\n+\n+\t* gcc.target/i386/pr79683.c: Disable costmodel.\n+\n 2017-10-21  Eric Botcazou  <ebotcazou@adacore.com>\n \n \t* gnat.dg/specs/discr_private.ads: Rename into ..."}, {"sha": "9e28d85fc89f2cc82ac413ecb591629cf189cdf2", "filename": "gcc/testsuite/gcc.target/i386/pr79683.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr79683.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fd8f2bd4e9a91b4683e2cbb144631ff201f587/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr79683.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr79683.c?ref=f6fd8f2bd4e9a91b4683e2cbb144631ff201f587", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O3 -msse2\" } */\n+/* { dg-options \"-O3 -msse2 -fvect-cost-model=unlimited\" } */\n \n struct s {\n     __INT64_TYPE__ a;"}]}