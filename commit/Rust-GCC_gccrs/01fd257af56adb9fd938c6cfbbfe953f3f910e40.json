{"sha": "01fd257af56adb9fd938c6cfbbfe953f3f910e40", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDFmZDI1N2FmNTZhZGI5ZmQ5MzhjNmNmYmJmZTk1M2YzZjkxMGU0MA==", "commit": {"author": {"name": "Zdenek Dvorak", "email": "dvorakz@suse.cz", "date": "2005-05-10T20:04:27Z"}, "committer": {"name": "Zdenek Dvorak", "email": "rakdver@gcc.gnu.org", "date": "2005-05-10T20:04:27Z"}, "message": "tree-ssa-loop-im.c: Include hashtab.h.\n\n\t* tree-ssa-loop-im.c: Include hashtab.h.\n\t(struct mem_ref_loc): New.\n\t(struct mem_ref): Describe the set of references with the same\n\tshape.\n\t(max_stmt_uid, get_stmt_uid, record_mem_ref, free_mem_refs,\n\tmaybe_queue_var, fem_single_reachable_address,\n\tfor_each_memref, single_reachable_address,\n\tis_call_clobbered_ref, determine_lsm_reg): Removed.\n\t(record_mem_ref_loc, free_mem_ref_locs, determine_lsm_ref,\n\thoist_memory_reference, memref_hash, memref_eq, memref_del,\n\tgather_mem_refs_stmt, gather_mem_refs, find_more_ref_vops):\n\tNew functions.\n\t(rewrite_mem_refs, schedule_sm): Use mem_ref_loc list.\n\t(determine_lsm_loop): Rewritten.\n\t(determine_lsm): Do not set stmt uids.\n\nFrom-SVN: r99539", "tree": {"sha": "7be9be4e09316268e055f8a9f91608193dccd299", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7be9be4e09316268e055f8a9f91608193dccd299"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/01fd257af56adb9fd938c6cfbbfe953f3f910e40", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/01fd257af56adb9fd938c6cfbbfe953f3f910e40", "html_url": "https://github.com/Rust-GCC/gccrs/commit/01fd257af56adb9fd938c6cfbbfe953f3f910e40", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/01fd257af56adb9fd938c6cfbbfe953f3f910e40/comments", "author": null, "committer": null, "parents": [{"sha": "09366c43780a171dbacd2cfe5bc93c6a7f95b099", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/09366c43780a171dbacd2cfe5bc93c6a7f95b099", "html_url": "https://github.com/Rust-GCC/gccrs/commit/09366c43780a171dbacd2cfe5bc93c6a7f95b099"}], "stats": {"total": 652, "additions": 284, "deletions": 368}, "files": [{"sha": "4cd2728a7d20b357a7db614762d7079be0f51609", "filename": "gcc/ChangeLog", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/01fd257af56adb9fd938c6cfbbfe953f3f910e40/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/01fd257af56adb9fd938c6cfbbfe953f3f910e40/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=01fd257af56adb9fd938c6cfbbfe953f3f910e40", "patch": "@@ -1,3 +1,21 @@\n+2005-05-10  Zdenek Dvorak  <dvorakz@suse.cz>\n+\n+\t* tree-ssa-loop-im.c: Include hashtab.h.\n+\t(struct mem_ref_loc): New.\n+\t(struct mem_ref): Describe the set of references with the same\n+\tshape.\n+\t(max_stmt_uid, get_stmt_uid, record_mem_ref, free_mem_refs,\n+\tmaybe_queue_var, fem_single_reachable_address,\n+\tfor_each_memref, single_reachable_address,\n+\tis_call_clobbered_ref, determine_lsm_reg): Removed.\n+\t(record_mem_ref_loc, free_mem_ref_locs, determine_lsm_ref,\n+\thoist_memory_reference, memref_hash, memref_eq, memref_del,\n+\tgather_mem_refs_stmt, gather_mem_refs, find_more_ref_vops):\n+\tNew functions.\n+\t(rewrite_mem_refs, schedule_sm): Use mem_ref_loc list.\n+\t(determine_lsm_loop): Rewritten.\n+\t(determine_lsm): Do not set stmt uids.\n+\n 2005-05-10  Adrian Straetling  <straetling@de.ibm.com>\n \n \t* config/s390/s390.md: Add comment lines for 'f' and 't' constraint"}, {"sha": "810f3cf02b26785ce61ba19802b4f5005d034dd2", "filename": "gcc/tree-ssa-loop-im.c", "status": "modified", "additions": 266, "deletions": 368, "changes": 634, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/01fd257af56adb9fd938c6cfbbfe953f3f910e40/gcc%2Ftree-ssa-loop-im.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/01fd257af56adb9fd938c6cfbbfe953f3f910e40/gcc%2Ftree-ssa-loop-im.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-im.c?ref=01fd257af56adb9fd938c6cfbbfe953f3f910e40", "patch": "@@ -38,6 +38,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"tree-pass.h\"\n #include \"flags.h\"\n #include \"real.h\"\n+#include \"hashtab.h\"\n \n /* TODO:  Support for predicated code motion.  I.e.\n \n@@ -103,13 +104,26 @@ struct lim_aux_data\n \t\t\t? NULL \\\n \t\t\t: (struct lim_aux_data *) (stmt_ann (STMT)->aux))\n \n-/* Description of a memory reference for store motion.  */\n+/* Description of a memory reference location for store motion.  */\n \n-struct mem_ref\n+struct mem_ref_loc\n {\n   tree *ref;\t\t\t/* The reference itself.  */\n   tree stmt;\t\t\t/* The statement in that it occurs.  */\n-  struct mem_ref *next;\t\t/* Next use in the chain.  */\n+  struct mem_ref_loc *next;\t/* Next use in the chain.  */\n+};\n+\n+/* Description of a memory reference for store motion.  */\n+\n+struct mem_ref\n+{\n+  tree mem;\t\t\t/* The memory itself.  */\n+  hashval_t hash;\t\t/* Its hash value.  */\n+  bool is_stored;\t\t/* True if there is a store to the location\n+\t\t\t\t   in the loop.  */\n+  struct mem_ref_loc *locs;\t/* The locations where it is found.  */\n+  bitmap vops;\t\t\t/* Vops corresponding to this memory\n+\t\t\t\t   location.  */\n };\n \n /* Minimum cost of an expensive expression.  */\n@@ -119,21 +133,6 @@ struct mem_ref\n    block will be executed.  */\n #define ALWAYS_EXECUTED_IN(BB) ((struct loop *) (BB)->aux)\n \n-static unsigned max_stmt_uid;\t/* Maximal uid of a statement.  Uids to phi\n-\t\t\t\t   nodes are assigned using the versions of\n-\t\t\t\t   ssa names they define.  */\n-\n-/* Returns uid of statement STMT.  */\n-\n-static unsigned\n-get_stmt_uid (tree stmt)\n-{\n-  if (TREE_CODE (stmt) == PHI_NODE)\n-    return SSA_NAME_VERSION (PHI_RESULT (stmt)) + max_stmt_uid;\n-\n-  return stmt_ann (stmt)->uid;\n-}\n-\n /* Calls CBCK for each index in memory reference ADDR_P.  There are two\n    kinds situations handled; in each of these cases, the memory reference\n    and DATA are passed to the callback:\n@@ -859,13 +858,13 @@ force_move_till (tree ref, tree *index, void *data)\n   return true;\n }\n \n-/* Records memory reference *REF (that occurs in statement STMT)\n-   to the list MEM_REFS.  */\n+/* Records memory reference location *REF to the list MEM_REFS.  The reference\n+   occurs in statement STMT.  */\n \n static void\n-record_mem_ref (struct mem_ref **mem_refs, tree stmt, tree *ref)\n+record_mem_ref_loc (struct mem_ref_loc **mem_refs, tree stmt, tree *ref)\n {\n-  struct mem_ref *aref = xmalloc (sizeof (struct mem_ref));\n+  struct mem_ref_loc *aref = xmalloc (sizeof (struct mem_ref_loc));\n \n   aref->stmt = stmt;\n   aref->ref = ref;\n@@ -874,12 +873,12 @@ record_mem_ref (struct mem_ref **mem_refs, tree stmt, tree *ref)\n   *mem_refs = aref;\n }\n \n-/* Releases list of memory references MEM_REFS.  */\n+/* Releases list of memory reference locations MEM_REFS.  */\n \n static void\n-free_mem_refs (struct mem_ref *mem_refs)\n+free_mem_ref_locs (struct mem_ref_loc *mem_refs)\n {\n-  struct mem_ref *act;\n+  struct mem_ref_loc *act;\n \n   while (mem_refs)\n     {\n@@ -889,236 +888,10 @@ free_mem_refs (struct mem_ref *mem_refs)\n     }\n }\n \n-/* If VAR is defined in LOOP and the statement it is defined in does not belong\n-   to the set SEEN, add the statement to QUEUE of length IN_QUEUE and\n-   to the set SEEN.  */\n-\n-static void\n-maybe_queue_var (tree var, struct loop *loop,\n-\t\t sbitmap seen, tree *queue, unsigned *in_queue)\n-{\n-  tree stmt = SSA_NAME_DEF_STMT (var);\n-  basic_block def_bb = bb_for_stmt (stmt);\n-\t      \n-  if (!def_bb\n-      || !flow_bb_inside_loop_p (loop, def_bb)\n-      || TEST_BIT (seen, get_stmt_uid (stmt)))\n-    return;\n-\t  \n-  SET_BIT (seen, get_stmt_uid (stmt));\n-  queue[(*in_queue)++] = stmt;\n-}\n-\n-/* If COMMON_REF is NULL, set COMMON_REF to *OP and return true.\n-   Otherwise return true if the memory reference *OP is equal to COMMON_REF.\n-   Record the reference OP to list MEM_REFS.  STMT is the statement in that\n-   the reference occurs.  */\n-\n-struct sra_data\n-{\n-  struct mem_ref **mem_refs;\n-  tree common_ref;\n-  tree stmt;\n-};\n-\n-static bool\n-fem_single_reachable_address (tree *op, void *data)\n-{\n-  struct sra_data *sra_data = data;\n-\n-  if (sra_data->common_ref\n-      && !operand_equal_p (*op, sra_data->common_ref, 0))\n-    return false;\n-  sra_data->common_ref = *op;\n-\n-  record_mem_ref (sra_data->mem_refs, sra_data->stmt, op);\n-  return true;\n-}\n-\n-/* Runs CALLBACK for each operand of STMT that is a memory reference.  DATA\n-   is passed to the CALLBACK as well.  The traversal stops if CALLBACK\n-   returns false, for_each_memref then returns false as well.  Otherwise\n-   for_each_memref returns true.  */\n-\n-static bool\n-for_each_memref (tree stmt, bool (*callback)(tree *, void *), void *data)\n-{\n-  tree *op;\n-\n-  if (TREE_CODE (stmt) == RETURN_EXPR)\n-    stmt = TREE_OPERAND (stmt, 1);\n-\n-  if (TREE_CODE (stmt) == MODIFY_EXPR)\n-    {\n-      op = &TREE_OPERAND (stmt, 0);\n-      if (TREE_CODE (*op) != SSA_NAME\n-\t  && !callback (op, data))\n-\treturn false;\n-\n-      op = &TREE_OPERAND (stmt, 1);\n-      if (TREE_CODE (*op) != SSA_NAME\n-\t  && is_gimple_lvalue (*op)\n-\t  && !callback (op, data))\n-\treturn false;\n-\n-      stmt = TREE_OPERAND (stmt, 1);\n-    }\n-\n-  if (TREE_CODE (stmt) == WITH_SIZE_EXPR)\n-    stmt = TREE_OPERAND (stmt, 0);\n-\n-  if (TREE_CODE (stmt) == CALL_EXPR)\n-    {\n-      tree args;\n-\n-      for (args = TREE_OPERAND (stmt, 1); args; args = TREE_CHAIN (args))\n-\t{\n-\t  op = &TREE_VALUE (args);\n-\n-\t  if (TREE_CODE (*op) != SSA_NAME\n-\t      && is_gimple_lvalue (*op)\n-\t      && !callback (op, data))\n-\t    return false;\n-\t}\n-    }\n-\n-  return true;\n-}\n-\n-/* Determine whether all memory references inside the LOOP that correspond\n-   to virtual ssa names defined in statement STMT are equal.\n-   If so, store the list of the references to MEM_REFS, and return one\n-   of them.  Otherwise store NULL to MEM_REFS and return NULL_TREE.\n-   *SEEN_CALL_STMT is set to true if the virtual operands suggest\n-   that the reference might be clobbered by a call inside the LOOP.  */\n-\n-static tree\n-single_reachable_address (struct loop *loop, tree stmt,\n-\t\t\t  struct mem_ref **mem_refs,\n-\t\t\t  bool *seen_call_stmt)\n-{\n-  unsigned max_uid = max_stmt_uid + num_ssa_names;\n-  tree *queue = xmalloc (sizeof (tree) * max_uid);\n-  sbitmap seen = sbitmap_alloc (max_uid);\n-  unsigned in_queue = 1;\n-  unsigned i;\n-  struct sra_data sra_data;\n-  tree call;\n-  tree val;\n-  ssa_op_iter iter;\n-  imm_use_iterator imm_iter;\n-  use_operand_p use_p;\n-\n-  sbitmap_zero (seen);\n-\n-  *mem_refs = NULL;\n-  sra_data.mem_refs = mem_refs;\n-  sra_data.common_ref = NULL_TREE;\n-\n-  queue[0] = stmt;\n-  SET_BIT (seen, get_stmt_uid (stmt));\n-  *seen_call_stmt = false;\n-\n-  while (in_queue)\n-    {\n-      stmt = queue[--in_queue];\n-      sra_data.stmt = stmt;\n-\n-      if (LIM_DATA (stmt)\n-\t  && LIM_DATA (stmt)->sm_done)\n-\tgoto fail;\n-\n-      switch (TREE_CODE (stmt))\n-\t{\n-\tcase MODIFY_EXPR:\n-\tcase CALL_EXPR:\n-\tcase RETURN_EXPR:\n-\t  if (!for_each_memref (stmt, fem_single_reachable_address,\n-\t\t\t\t&sra_data))\n-\t    goto fail;\n-\n-\t  /* If this is a function that may depend on the memory location,\n-\t     record the fact.  We cannot directly refuse call clobbered\n-\t     operands here, since sra_data.common_ref did not have\n-\t     to be set yet.  */\n-\t  call = get_call_expr_in (stmt);\n-\t  if (call\n-\t      && !(call_expr_flags (call) & ECF_CONST))\n-\t    *seen_call_stmt = true;\n-\n-\t  /* Traverse also definitions of the VUSES (there may be other\n-\t     distinct from the one we used to get to this statement).  */\n-\t  FOR_EACH_SSA_TREE_OPERAND (val, stmt, iter, SSA_OP_VIRTUAL_USES)\n-\t    maybe_queue_var (val, loop, seen, queue, &in_queue);\n-\n-\t  break;\n-\n-\tcase PHI_NODE:\n-\t  for (i = 0; i < (unsigned) PHI_NUM_ARGS (stmt); i++)\n-\t    if (TREE_CODE (PHI_ARG_DEF (stmt, i)) == SSA_NAME)\n-\t      maybe_queue_var (PHI_ARG_DEF (stmt, i), loop,\n-\t\t               seen, queue, &in_queue);\n-\t  break;\n-\n-\tdefault:\n-\t  goto fail;\n-\t}\n-\n-      /* Find uses of virtual names.  */\n-      if (TREE_CODE (stmt) == PHI_NODE)\n-        {\n-\t  if (!is_gimple_reg (SSA_NAME_VAR (PHI_RESULT (stmt))))\n-\t    FOR_EACH_IMM_USE_FAST (use_p, imm_iter, PHI_RESULT (stmt))\n-\t      {\t      \n-\t\ttree imm_stmt = USE_STMT (use_p);\n-\n-\t\tif (TEST_BIT (seen, get_stmt_uid (imm_stmt)))\n-\t\t  continue;\n-\n-\t\tif (!flow_bb_inside_loop_p (loop, bb_for_stmt (imm_stmt)))\n-\t\t  continue;\n-\n-\t\tSET_BIT (seen, get_stmt_uid (imm_stmt));\n-\n-\t\tqueue[in_queue++] = imm_stmt;\n-\t      }\n-\t}\n-      else\n-\tFOR_EACH_SSA_TREE_OPERAND (val, stmt, iter, SSA_OP_VIRTUAL_DEFS)\n-\t  FOR_EACH_IMM_USE_FAST (use_p, imm_iter, val)\n-\t    {\n-\t      tree imm_stmt = USE_STMT (use_p);\n-\n-\t      if (TEST_BIT (seen, get_stmt_uid (imm_stmt)))\n-\t\tcontinue;\n-\n-\t      if (!flow_bb_inside_loop_p (loop, bb_for_stmt (imm_stmt)))\n-\t\tcontinue;\n-\n-\t      SET_BIT (seen, get_stmt_uid (imm_stmt));\n-\n-\t      queue[in_queue++] = imm_stmt;\n-\t    }\n-    }\n-\n-  free (queue);\n-  sbitmap_free (seen);\n-\n-  return sra_data.common_ref;\n-\n-fail:\n-  free_mem_refs (*mem_refs);\n-  *mem_refs = NULL;\n-  free (queue);\n-  sbitmap_free (seen);\n-\n-  return NULL;\n-}\n-\n /* Rewrites memory references in list MEM_REFS by variable TMP_VAR.  */\n \n static void\n-rewrite_mem_refs (tree tmp_var, struct mem_ref *mem_refs)\n+rewrite_mem_refs (tree tmp_var, struct mem_ref_loc *mem_refs)\n {\n   tree var;\n   ssa_op_iter iter;\n@@ -1143,9 +916,9 @@ rewrite_mem_refs (tree tmp_var, struct mem_ref *mem_refs)\n \n static void\n schedule_sm (struct loop *loop, edge *exits, unsigned n_exits, tree ref,\n-\t     struct mem_ref *mem_refs)\n+\t     struct mem_ref_loc *mem_refs)\n {\n-  struct mem_ref *aref;\n+  struct mem_ref_loc *aref;\n   tree tmp_var;\n   unsigned i;\n   tree load, store;\n@@ -1187,104 +960,31 @@ schedule_sm (struct loop *loop, edge *exits, unsigned n_exits, tree ref,\n     }\n }\n \n-/* Returns true if REF may be clobbered by calls.  */\n-\n-static bool\n-is_call_clobbered_ref (tree ref)\n-{\n-  tree base;\n-  HOST_WIDE_INT offset, size;\n-  subvar_t sv;\n-  subvar_t svars;\n-  tree sref = ref;\n-\n-  if (TREE_CODE (sref) == COMPONENT_REF\n-      && (sref = okay_component_ref_for_subvars (sref, &offset, &size)))\n-    {\n-      svars = get_subvars_for_var (sref);\n-      for (sv = svars; sv; sv = sv->next)\n-\t{\n-\t  if (overlap_subvar (offset, size, sv, NULL)\n-\t      && is_call_clobbered (sv->var))\n-\t    return true;\n-\t}\n-    }\n-\t      \n-  base = get_base_address (ref);\n-  if (!base)\n-    return true;\n-\n-  if (DECL_P (base))\n-    {\n-      if (var_can_have_subvars (base)\n-\t  && (svars = get_subvars_for_var (base)))\n-\t{\n-\t  for (sv = svars; sv; sv = sv->next)\n-\t    if (is_call_clobbered (sv->var))\n-\t      return true;\n-\t  return false;\n-\t}\n-      else\n-\treturn is_call_clobbered (base);\n-    }\n-\n-  if (INDIRECT_REF_P (base))\n-    {\n-      /* Check whether the alias tags associated with the pointer\n-\t are call clobbered.  */\n-      tree ptr = TREE_OPERAND (base, 0);\n-      struct ptr_info_def *pi = SSA_NAME_PTR_INFO (ptr);\n-      tree nmt = (pi) ? pi->name_mem_tag : NULL_TREE;\n-      tree tmt = var_ann (SSA_NAME_VAR (ptr))->type_mem_tag;\n-\n-      if ((nmt && is_call_clobbered (nmt))\n-\t  || (tmt && is_call_clobbered (tmt)))\n-\treturn true;\n-\n-      return false;\n-    }\n-\n-  gcc_unreachable ();\n-}\n-\n-/* Determine whether all memory references inside LOOP corresponding to the\n-   virtual ssa name REG are equal to each other, and whether the address of\n-   this common reference can be hoisted outside of the loop.  If this is true,\n-   prepare the statements that load the value of the memory reference to a\n-   temporary variable in the loop preheader, store it back on the loop exits,\n-   and replace all the references inside LOOP by this temporary variable.\n-   LOOP has N_EXITS stored in EXITS.  */\n+/* Check whether memory reference REF can be hoisted out of the LOOP.  If this\n+   is true, prepare the statements that load the value of the memory reference\n+   to a temporary variable in the loop preheader, store it back on the loop\n+   exits, and replace all the references inside LOOP by this temporary variable.\n+   LOOP has N_EXITS stored in EXITS.  CLOBBERED_VOPS is the bitmap of virtual\n+   operands that are clobbered by a call or accessed through multiple references\n+   in loop.  */\n \n static void\n-determine_lsm_reg (struct loop *loop, edge *exits, unsigned n_exits, tree reg)\n+determine_lsm_ref (struct loop *loop, edge *exits, unsigned n_exits,\n+\t\t   bitmap clobbered_vops, struct mem_ref *ref)\n {\n-  tree ref;\n-  struct mem_ref *mem_refs, *aref;\n+  struct mem_ref_loc *aref;\n   struct loop *must_exec;\n-  bool sees_call;\n-  \n-  if (is_gimple_reg (reg))\n-    return;\n-  \n-  ref = single_reachable_address (loop, SSA_NAME_DEF_STMT (reg), &mem_refs,\n-\t\t\t\t  &sees_call);\n-  if (!ref)\n-    return;\n \n-  /* If we cannot create a ssa name for the result, give up.  */\n-  if (!is_gimple_reg_type (TREE_TYPE (ref))\n-      || TREE_THIS_VOLATILE (ref))\n-    goto fail;\n-\n-  /* If there is a call that may use the location, give up as well.  */\n-  if (sees_call\n-      && is_call_clobbered_ref (ref))\n-    goto fail;\n+  /* In case the memory is not stored to, there is nothing for SM to do.  */\n+  if (!ref->is_stored)\n+    return;\n \n-  if (!for_each_index (&ref, may_move_till, loop))\n-    goto fail;\n+  /* If the reference is aliased with any different ref, or killed by call\n+     in function, then fail.  */\n+  if (bitmap_intersect_p (ref->vops, clobbered_vops))\n+    return;\n \n-  if (tree_could_trap_p (ref))\n+  if (tree_could_trap_p (ref->mem))\n     {\n       /* If the memory access is unsafe (i.e. it might trap), ensure that some\n \t of the statements in that it occurs is always executed when the loop\n@@ -1297,7 +997,7 @@ determine_lsm_reg (struct loop *loop, edge *exits, unsigned n_exits, tree reg)\n \t least one of the statements containing the memory reference is\n \t executed.  */\n \n-      for (aref = mem_refs; aref; aref = aref->next)\n+      for (aref = ref->locs; aref; aref = aref->next)\n \t{\n \t  if (!LIM_DATA (aref->stmt))\n \t    continue;\n@@ -1312,13 +1012,34 @@ determine_lsm_reg (struct loop *loop, edge *exits, unsigned n_exits, tree reg)\n \t}\n \n       if (!aref)\n-\tgoto fail;\n+\treturn;\n     }\n \n-  schedule_sm (loop, exits, n_exits, ref, mem_refs);\n+  schedule_sm (loop, exits, n_exits, ref->mem, ref->locs);\n+}\n+\n+/* Attempts to hoist memory reference described in SLOT out of loop\n+   described in DATA.  Callback for htab_traverse.  */\n \n-fail: ;\n-  free_mem_refs (mem_refs);\n+struct hmr_data\n+{\n+  struct loop *loop;\t/* Loop from that the reference should be hoisted.  */\n+  edge *exits;\t\t/* Exits of the loop.  */\n+  unsigned n_exits;\t/* Length of the exits array.  */\n+  bitmap clobbered_vops;/* The vops clobbered by call in loop or accessed by\n+\t\t\t   multiple memory references.  */\n+};\n+\n+static int\n+hoist_memory_reference (void **slot, void *data)\n+{\n+  struct mem_ref *ref = *slot;\n+  struct hmr_data *hmr_data = data;\n+\n+  determine_lsm_ref (hmr_data->loop, hmr_data->exits, hmr_data->n_exits,\n+\t\t     hmr_data->clobbered_vops, ref);\n+\n+  return 1;\n }\n \n /* Checks whether LOOP (with N_EXITS exits stored in EXITS array) is suitable\n@@ -1338,26 +1059,216 @@ loop_suitable_for_sm (struct loop *loop ATTRIBUTE_UNUSED, edge *exits,\n   return true;\n }\n \n+/* A hash function for struct mem_ref object OBJ.  */\n+\n+static hashval_t\n+memref_hash (const void *obj)\n+{\n+  const struct mem_ref *mem = obj;\n+\n+  return mem->hash;\n+}\n+\n+/* An equality function for struct mem_ref object OBJ1 with\n+   memory reference OBJ2.  */\n+\n+static int\n+memref_eq (const void *obj1, const void *obj2)\n+{\n+  const struct mem_ref *mem1 = obj1;\n+\n+  return operand_equal_p (mem1->mem, (tree) obj2, 0);\n+}\n+\n+/* A function to free the struct mem_ref object OBJ.  */\n+\n+static void\n+memref_del (void *obj)\n+{\n+  struct mem_ref *mem = obj;\n+\n+  free_mem_ref_locs (mem->locs);\n+  BITMAP_FREE (mem->vops);\n+  free (mem);\n+}\n+\n+/* Gathers memory references in statement STMT in LOOP, storing the\n+   information about them in MEM_REFS hash table.  Note vops accessed through\n+   unrecognized statements in CLOBBERED_VOPS.  */\n+\n+static void\n+gather_mem_refs_stmt (struct loop *loop, htab_t mem_refs,\n+\t\t      bitmap clobbered_vops, tree stmt)\n+{\n+  tree *lhs, *rhs, *mem = NULL;\n+  hashval_t hash;\n+  PTR *slot;\n+  struct mem_ref *ref = NULL;\n+  ssa_op_iter oi;\n+  tree vname;\n+  bool is_stored;\n+\n+  if (ZERO_SSA_OPERANDS (stmt, SSA_OP_ALL_VIRTUALS))\n+    return;\n+\n+  /* Recognize MEM = (SSA_NAME | invariant) and SSA_NAME = MEM patterns.  */\n+  if (TREE_CODE (stmt) != MODIFY_EXPR)\n+    goto fail;\n+\n+  lhs = &TREE_OPERAND (stmt, 0);\n+  rhs = &TREE_OPERAND (stmt, 1);\n+\n+  if (TREE_CODE (*lhs) == SSA_NAME)\n+    {\n+      if (!is_gimple_addressable (*rhs))\n+\tgoto fail;\n+\n+      mem = rhs;\n+      is_stored = false;\n+    }\n+  else if (TREE_CODE (*rhs) == SSA_NAME\n+\t   || is_gimple_min_invariant (*rhs))\n+    {\n+      mem = lhs;\n+      is_stored = true;\n+    }\n+  else\n+    goto fail;\n+\n+  /* If we cannot create an SSA name for the result, give up.  */\n+  if (!is_gimple_reg_type (TREE_TYPE (*mem))\n+      || TREE_THIS_VOLATILE (*mem))\n+    goto fail;\n+\n+  /* If we cannot move the reference out of the loop, fail.  */\n+  if (!for_each_index (mem, may_move_till, loop))\n+    goto fail;\n+\n+  hash = iterative_hash_expr (*mem, 0);\n+  slot = htab_find_slot_with_hash (mem_refs, *mem, hash, INSERT);\n+\n+  if (*slot)\n+    ref = *slot;\n+  else\n+    {\n+      ref = xmalloc (sizeof (struct mem_ref));\n+      ref->mem = *mem;\n+      ref->hash = hash;\n+      ref->locs = NULL;\n+      ref->is_stored = false;\n+      ref->vops = BITMAP_ALLOC (NULL);\n+      *slot = ref;\n+    }\n+  ref->is_stored |= is_stored;\n+\n+  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi,\n+\t\t\t     SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS)\n+    {\n+      bitmap_set_bit (ref->vops,\n+\t\t      var_ann (SSA_NAME_VAR (vname))->uid);\n+    }\n+  record_mem_ref_loc (&ref->locs, stmt, mem);\n+  return;\n+\n+fail:\n+  FOR_EACH_SSA_TREE_OPERAND (vname, stmt, oi,\n+\t\t\t     SSA_OP_VIRTUAL_USES | SSA_OP_VIRTUAL_KILLS)\n+    {\n+      bitmap_set_bit (clobbered_vops,\n+\t\t      var_ann (SSA_NAME_VAR (vname))->uid);\n+    }\n+}\n+\n+/* Gathers memory references in LOOP, storing the information about them\n+   in MEM_REFS hash table.  Note vops accessed through unrecognized\n+   statements in CLOBBERED_VOPS.  */\n+\n+static void\n+gather_mem_refs (struct loop *loop, htab_t mem_refs, bitmap clobbered_vops)\n+{\n+  basic_block *body = get_loop_body (loop);\n+  block_stmt_iterator bsi;\n+  unsigned i;\n+\n+  for (i = 0; i < loop->num_nodes; i++)\n+    {\n+      for (bsi = bsi_start (body[i]); !bsi_end_p (bsi); bsi_next (&bsi))\n+\tgather_mem_refs_stmt (loop, mem_refs, clobbered_vops, bsi_stmt (bsi));\n+    }\n+\n+  free (body);\n+}\n+\n+/* Finds the vops accessed by memory reference described in SLOT as well as\n+   some other reference(s) and marks them in DATA->clobbered_vops.\n+   Callback for htab_traverse.  */\n+\n+struct fmrv_data\n+{\n+  bitmap clobbered_vops;\t/* The vops clobbered by call in loop or accessed by\n+\t\t\t   multiple memory references.  */\n+  bitmap all_vops;\t/* All vops referenced in the loop.  */\n+};\n+\n+static int\n+find_more_ref_vops (void **slot, void *data)\n+{\n+  struct mem_ref *ref = *slot;\n+  struct fmrv_data *fmrv_data = data;\n+  bitmap_head tmp;\n+\n+  /* The vops that are already in all_vops are accessed by more than\n+     one memory reference.  */\n+  bitmap_initialize (&tmp, &bitmap_default_obstack);\n+  bitmap_and (&tmp, fmrv_data->all_vops, ref->vops);\n+  bitmap_ior_into (fmrv_data->clobbered_vops, &tmp);\n+  bitmap_clear (&tmp);\n+\n+  bitmap_ior_into (fmrv_data->all_vops, ref->vops);\n+  return 1;\n+}\n+\n /* Try to perform store motion for all memory references modified inside\n    LOOP.  */\n \n static void\n determine_lsm_loop (struct loop *loop)\n {\n-  tree phi;\n   unsigned n_exits;\n   edge *exits = get_loop_exit_edges (loop, &n_exits);\n+  htab_t mem_refs;\n+  struct hmr_data hmr_data;\n+  struct fmrv_data fmrv_data;\n+  bitmap clobbered_vops;\n \n   if (!loop_suitable_for_sm (loop, exits, n_exits))\n     {\n       free (exits);\n       return;\n     }\n \n-  for (phi = phi_nodes (loop->header); phi; phi = PHI_CHAIN (phi))\n-    determine_lsm_reg (loop, exits, n_exits, PHI_RESULT (phi));\n+  mem_refs = htab_create (100, memref_hash, memref_eq, memref_del);\n+\n+  /* Find the memory references in LOOP.  */\n+  clobbered_vops = BITMAP_ALLOC (NULL);\n+  gather_mem_refs (loop, mem_refs, clobbered_vops);\n \n+  /* Find the vops that are used for more than one reference.  */\n+  fmrv_data.all_vops = BITMAP_ALLOC (NULL);\n+  fmrv_data.clobbered_vops = clobbered_vops;\n+  htab_traverse (mem_refs, find_more_ref_vops, &fmrv_data);\n+  BITMAP_FREE (fmrv_data.all_vops);\n+\n+  /* Hoist all suitable memory references.  */\n+  hmr_data.loop = loop;\n+  hmr_data.exits = exits;\n+  hmr_data.n_exits = n_exits;\n+  hmr_data.clobbered_vops = clobbered_vops;\n+  htab_traverse (mem_refs, hoist_memory_reference, &hmr_data);\n+\n+  htab_delete (mem_refs);\n   free (exits);\n+  BITMAP_FREE (clobbered_vops);\n }\n \n /* Try to perform store motion for all memory references modified inside\n@@ -1367,25 +1278,12 @@ static void\n determine_lsm (struct loops *loops)\n {\n   struct loop *loop;\n-  basic_block bb;\n \n   if (!loops->tree_root->inner)\n     return;\n \n-  /* Create a UID for each statement in the function.  Ordering of the\n-     UIDs is not important for this pass.  */\n-  max_stmt_uid = 0;\n-  FOR_EACH_BB (bb)\n-    {\n-      block_stmt_iterator bsi;\n-\n-      for (bsi = bsi_start (bb); !bsi_end_p (bsi); bsi_next (&bsi))\n-\tstmt_ann (bsi_stmt (bsi))->uid = max_stmt_uid++;\n-    }\n-\n-  /* Pass the loops from the outermost.  For each virtual operand loop phi node\n-     check whether all the references inside the loop correspond to a single\n-     address, and if so, move them.  */\n+  /* Pass the loops from the outermost and perform the store motion as\n+     suitable.  */\n \n   loop = loops->tree_root->inner;\n   while (1)"}]}