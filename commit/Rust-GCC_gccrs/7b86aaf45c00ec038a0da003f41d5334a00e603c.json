{"sha": "7b86aaf45c00ec038a0da003f41d5334a00e603c", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6N2I4NmFhZjQ1YzAwZWMwMzhhMGRhMDAzZjQxZDUzMzRhMDBlNjAzYw==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2019-12-04T13:14:20Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2019-12-04T13:14:20Z"}, "message": "Fix VIEW_CONVERT_EXPRs for VECTOR_BOOLEAN_TYPE_Ps\n\nIn r278410 I added code to handle VIEW_CONVERT_EXPRs between\nvariable-length vectors.  This included support for decoding\na VECTOR_BOOLEAN_TYPE_P with subbyte elements.\n\nHowever, it turns out that we were already mishandling such bool vectors\nfor fixed-length vectors: we treated each element as a stand-alone byte\ninstead of putting multiple elements into the same byte.  I think in\nprinciple this could have been an issue for AVX512 as well.\n\nThis patch adds encoding support for boolean vectors and reuses\na version of the new decode support for fixed-length vectors.\n\n2019-12-04  Richard Sandiford  <richard.sandiford@arm.com>\n\ngcc/\n\t* fold-const.c (native_encode_vector_part): Handle\n\tVECTOR_BOOLEAN_TYPE_Ps that have subbyte precision.\n\t(native_decode_vector_tree): Delete, moving the bulk of the code to...\n\t(native_interpret_vector_part): ...this new function.  Use a pointer\n\tand length instead of a vec<> and start index.\n\t(native_interpret_vector): Use native_interpret_vector_part.\n\t(fold_view_convert_vector_encoding): Likewise.\n\ngcc/testsuite/\n\t* gcc.target/aarch64/sve/acle/general/whilelt_5.c: New test.\n\nFrom-SVN: r278964", "tree": {"sha": "835dc708734a21ac420210c3dda56434cbe3b63f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/835dc708734a21ac420210c3dda56434cbe3b63f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/7b86aaf45c00ec038a0da003f41d5334a00e603c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b86aaf45c00ec038a0da003f41d5334a00e603c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7b86aaf45c00ec038a0da003f41d5334a00e603c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b86aaf45c00ec038a0da003f41d5334a00e603c/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "0849cdae714ddf056a4944f31eef53a465f1bcd0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0849cdae714ddf056a4944f31eef53a465f1bcd0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0849cdae714ddf056a4944f31eef53a465f1bcd0"}], "stats": {"total": 340, "additions": 271, "deletions": 69}, "files": [{"sha": "d80a8a8058a3a8a36c31baea413cdb2b7f09adae", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=7b86aaf45c00ec038a0da003f41d5334a00e603c", "patch": "@@ -1,3 +1,13 @@\n+2019-12-04  Richard Sandiford  <richard.sandiford@arm.com>\n+\n+\t* fold-const.c (native_encode_vector_part): Handle\n+\tVECTOR_BOOLEAN_TYPE_Ps that have subbyte precision.\n+\t(native_decode_vector_tree): Delete, moving the bulk of the code to...\n+\t(native_interpret_vector_part): ...this new function.  Use a pointer\n+\tand length instead of a vec<> and start index.\n+\t(native_interpret_vector): Use native_interpret_vector_part.\n+\t(fold_view_convert_vector_encoding): Likewise.\n+\n 2019-12-04  Richard Biener  <rguenther@suse.de>\n \n \t* tree-ssa-sccvn.c (vn_walk_cb_data::push_partial_def): Handle"}, {"sha": "84b3bb062174cac57ace9be3bf1951d347950672", "filename": "gcc/fold-const.c", "status": "modified", "additions": 94, "deletions": 69, "changes": 163, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=7b86aaf45c00ec038a0da003f41d5334a00e603c", "patch": "@@ -7727,21 +7727,53 @@ static int\n native_encode_vector_part (const_tree expr, unsigned char *ptr, int len,\n \t\t\t   int off, unsigned HOST_WIDE_INT count)\n {\n-  unsigned HOST_WIDE_INT i;\n-  int size, offset;\n-  tree itype, elem;\n+  tree itype = TREE_TYPE (TREE_TYPE (expr));\n+  if (VECTOR_BOOLEAN_TYPE_P (TREE_TYPE (expr))\n+      && TYPE_PRECISION (itype) <= BITS_PER_UNIT)\n+    {\n+      /* This is the only case in which elements can be smaller than a byte.\n+\t Element 0 is always in the lsb of the containing byte.  */\n+      unsigned int elt_bits = TYPE_PRECISION (itype);\n+      int total_bytes = CEIL (elt_bits * count, BITS_PER_UNIT);\n+      if ((off == -1 && total_bytes > len) || off >= total_bytes)\n+\treturn 0;\n+\n+      if (off == -1)\n+\toff = 0;\n+\n+      /* Zero the buffer and then set bits later where necessary.  */\n+      int extract_bytes = MIN (len, total_bytes - off);\n+      if (ptr)\n+\tmemset (ptr, 0, extract_bytes);\n+\n+      unsigned int elts_per_byte = BITS_PER_UNIT / elt_bits;\n+      unsigned int first_elt = off * elts_per_byte;\n+      unsigned int extract_elts = extract_bytes * elts_per_byte;\n+      for (unsigned int i = 0; i < extract_elts; ++i)\n+\t{\n+\t  tree elt = VECTOR_CST_ELT (expr, first_elt + i);\n+\t  if (TREE_CODE (elt) != INTEGER_CST)\n+\t    return 0;\n \n-  offset = 0;\n-  itype = TREE_TYPE (TREE_TYPE (expr));\n-  size = GET_MODE_SIZE (SCALAR_TYPE_MODE (itype));\n-  for (i = 0; i < count; i++)\n+\t  if (ptr && wi::extract_uhwi (wi::to_wide (elt), 0, 1))\n+\t    {\n+\t      unsigned int bit = i * elt_bits;\n+\t      ptr[bit / BITS_PER_UNIT] |= 1 << (bit % BITS_PER_UNIT);\n+\t    }\n+\t}\n+      return extract_bytes;\n+    }\n+\n+  int offset = 0;\n+  int size = GET_MODE_SIZE (SCALAR_TYPE_MODE (itype));\n+  for (unsigned HOST_WIDE_INT i = 0; i < count; i++)\n     {\n       if (off >= size)\n \t{\n \t  off -= size;\n \t  continue;\n \t}\n-      elem = VECTOR_CST_ELT (expr, i);\n+      tree elem = VECTOR_CST_ELT (expr, i);\n       int res = native_encode_expr (elem, ptr ? ptr + offset : NULL,\n \t\t\t\t    len - offset, off);\n       if ((off == -1 && res != size) || res == 0)\n@@ -7976,6 +8008,55 @@ native_interpret_complex (tree type, const unsigned char *ptr, int len)\n   return build_complex (type, rpart, ipart);\n }\n \n+/* Read a vector of type TYPE from the target memory image given by BYTES,\n+   which contains LEN bytes.  The vector is known to be encodable using\n+   NPATTERNS interleaved patterns with NELTS_PER_PATTERN elements each.\n+\n+   Return the vector on success, otherwise return null.  */\n+\n+static tree\n+native_interpret_vector_part (tree type, const unsigned char *bytes,\n+\t\t\t      unsigned int len, unsigned int npatterns,\n+\t\t\t      unsigned int nelts_per_pattern)\n+{\n+  tree elt_type = TREE_TYPE (type);\n+  if (VECTOR_BOOLEAN_TYPE_P (type)\n+      && TYPE_PRECISION (elt_type) <= BITS_PER_UNIT)\n+    {\n+      /* This is the only case in which elements can be smaller than a byte.\n+\t Element 0 is always in the lsb of the containing byte.  */\n+      unsigned int elt_bits = TYPE_PRECISION (elt_type);\n+      if (elt_bits * npatterns * nelts_per_pattern > len * BITS_PER_UNIT)\n+\treturn NULL_TREE;\n+\n+      tree_vector_builder builder (type, npatterns, nelts_per_pattern);\n+      for (unsigned int i = 0; i < builder.encoded_nelts (); ++i)\n+\t{\n+\t  unsigned int bit_index = i * elt_bits;\n+\t  unsigned int byte_index = bit_index / BITS_PER_UNIT;\n+\t  unsigned int lsb = bit_index % BITS_PER_UNIT;\n+\t  builder.quick_push (bytes[byte_index] & (1 << lsb)\n+\t\t\t      ? build_all_ones_cst (elt_type)\n+\t\t\t      : build_zero_cst (elt_type));\n+\t}\n+      return builder.build ();\n+    }\n+\n+  unsigned int elt_bytes = tree_to_uhwi (TYPE_SIZE_UNIT (elt_type));\n+  if (elt_bytes * npatterns * nelts_per_pattern > len)\n+    return NULL_TREE;\n+\n+  tree_vector_builder builder (type, npatterns, nelts_per_pattern);\n+  for (unsigned int i = 0; i < builder.encoded_nelts (); ++i)\n+    {\n+      tree elt = native_interpret_expr (elt_type, bytes, elt_bytes);\n+      if (!elt)\n+\treturn NULL_TREE;\n+      builder.quick_push (elt);\n+      bytes += elt_bytes;\n+    }\n+  return builder.build ();\n+}\n \n /* Subroutine of native_interpret_expr.  Interpret the contents of\n    the buffer PTR of length LEN as a VECTOR_CST of type TYPE.\n@@ -7984,8 +8065,8 @@ native_interpret_complex (tree type, const unsigned char *ptr, int len)\n static tree\n native_interpret_vector (tree type, const unsigned char *ptr, unsigned int len)\n {\n-  tree etype, elem;\n-  unsigned int i, size;\n+  tree etype;\n+  unsigned int size;\n   unsigned HOST_WIDE_INT count;\n \n   etype = TREE_TYPE (type);\n@@ -7994,15 +8075,7 @@ native_interpret_vector (tree type, const unsigned char *ptr, unsigned int len)\n       || size * count > len)\n     return NULL_TREE;\n \n-  tree_vector_builder elements (type, count, 1);\n-  for (i = 0; i < count; ++i)\n-    {\n-      elem = native_interpret_expr (etype, ptr+(i*size), size);\n-      if (!elem)\n-\treturn NULL_TREE;\n-      elements.quick_push (elem);\n-    }\n-  return elements.build ();\n+  return native_interpret_vector_part (type, ptr, len, count, 1);\n }\n \n \n@@ -8064,54 +8137,6 @@ can_native_interpret_type_p (tree type)\n     }\n }\n \n-/* Read a vector of type TYPE from the target memory image given by BYTES,\n-   starting at byte FIRST_BYTE.  The vector is known to be encodable using\n-   NPATTERNS interleaved patterns with NELTS_PER_PATTERN elements each,\n-   and BYTES is known to have enough bytes to supply NPATTERNS *\n-   NELTS_PER_PATTERN vector elements.  Each element of BYTES contains\n-   BITS_PER_UNIT bits and the bytes are in target memory order.\n-\n-   Return the vector on success, otherwise return null.  */\n-\n-static tree\n-native_decode_vector_tree (tree type, vec<unsigned char> bytes,\n-\t\t\t   unsigned int first_byte, unsigned int npatterns,\n-\t\t\t   unsigned int nelts_per_pattern)\n-{\n-  tree_vector_builder builder (type, npatterns, nelts_per_pattern);\n-  tree elt_type = TREE_TYPE (type);\n-  unsigned int elt_bits = tree_to_uhwi (TYPE_SIZE (elt_type));\n-  if (VECTOR_BOOLEAN_TYPE_P (type) && elt_bits <= BITS_PER_UNIT)\n-    {\n-      /* This is the only case in which elements can be smaller than a byte.\n-\t Element 0 is always in the lsb of the containing byte.  */\n-      elt_bits = TYPE_PRECISION (elt_type);\n-      for (unsigned int i = 0; i < builder.encoded_nelts (); ++i)\n-\t{\n-\t  unsigned int bit_index = first_byte * BITS_PER_UNIT + i * elt_bits;\n-\t  unsigned int byte_index = bit_index / BITS_PER_UNIT;\n-\t  unsigned int lsb = bit_index % BITS_PER_UNIT;\n-\t  builder.quick_push (bytes[byte_index] & (1 << lsb)\n-\t\t\t      ? build_all_ones_cst (elt_type)\n-\t\t\t      : build_zero_cst (elt_type));\n-\t}\n-    }\n-  else\n-    {\n-      unsigned int elt_bytes = elt_bits / BITS_PER_UNIT;\n-      for (unsigned int i = 0; i < builder.encoded_nelts (); ++i)\n-\t{\n-\t  tree elt = native_interpret_expr (elt_type, &bytes[first_byte],\n-\t\t\t\t\t    elt_bytes);\n-\t  if (!elt)\n-\t    return NULL_TREE;\n-\t  builder.quick_push (elt);\n-\t  first_byte += elt_bytes;\n-\t}\n-    }\n-  return builder.build ();\n-}\n-\n /* Try to view-convert VECTOR_CST EXPR to VECTOR_TYPE TYPE by operating\n    directly on the VECTOR_CST encoding, in a way that works for variable-\n    length vectors.  Return the resulting VECTOR_CST on success or null\n@@ -8168,8 +8193,8 @@ fold_view_convert_vector_encoding (tree type, tree expr)\n \n   /* Reencode the bytes as TYPE.  */\n   unsigned int type_npatterns = type_sequence_bits / type_elt_bits;\n-  return native_decode_vector_tree (type, buffer, 0, type_npatterns,\n-\t\t\t\t    nelts_per_pattern);\n+  return native_interpret_vector_part (type, &buffer[0], buffer.length (),\n+\t\t\t\t       type_npatterns, nelts_per_pattern);\n }\n \n /* Fold a VIEW_CONVERT_EXPR of a constant expression EXPR to type"}, {"sha": "7678625820f31afbd5cd0f174a96ae03754aa475", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=7b86aaf45c00ec038a0da003f41d5334a00e603c", "patch": "@@ -1,3 +1,7 @@\n+2019-12-04  Richard Sandiford  <richard.sandiford@arm.com>\n+\n+\t* gcc.target/aarch64/sve/acle/general/whilelt_5.c: New test.\n+\n 2019-12-04  Richard Biener  <rguenther@suse.de>\n \n \t* gcc.dg/tree-ssa/ssa-fre-84.c: New testcase."}, {"sha": "f06a74aa2daa17b1b15c1820fbd36b306ffc20bc", "filename": "gcc/testsuite/gcc.target/aarch64/sve/acle/general/whilelt_5.c", "status": "added", "additions": 163, "deletions": 0, "changes": 163, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Facle%2Fgeneral%2Fwhilelt_5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b86aaf45c00ec038a0da003f41d5334a00e603c/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Facle%2Fgeneral%2Fwhilelt_5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsve%2Facle%2Fgeneral%2Fwhilelt_5.c?ref=7b86aaf45c00ec038a0da003f41d5334a00e603c", "patch": "@@ -0,0 +1,163 @@\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-additional-options \"-O -msve-vector-bits=512 -fdump-tree-optimized\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include <arm_sve.h>\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+/*\n+** load_vl1:\n+**\tptrue\t(p[0-7])\\.[bhsd], vl1\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl1 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 1), ptr);\n+}\n+\n+/*\n+** load_vl2:\n+**\tptrue\t(p[0-7])\\.h, vl2\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl2 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 2), ptr);\n+}\n+\n+/*\n+** load_vl3:\n+**\tptrue\t(p[0-7])\\.h, vl3\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl3 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 3), ptr);\n+}\n+\n+/*\n+** load_vl4:\n+**\tptrue\t(p[0-7])\\.h, vl4\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl4 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 4), ptr);\n+}\n+\n+/*\n+** load_vl5:\n+**\tptrue\t(p[0-7])\\.h, vl5\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl5 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 5), ptr);\n+}\n+\n+/*\n+** load_vl6:\n+**\tptrue\t(p[0-7])\\.h, vl6\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl6 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 6), ptr);\n+}\n+\n+/*\n+** load_vl7:\n+**\tptrue\t(p[0-7])\\.h, vl7\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl7 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 7), ptr);\n+}\n+\n+/*\n+** load_vl8:\n+**\tptrue\t(p[0-7])\\.h, vl8\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl8 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 8), ptr);\n+}\n+\n+/*\n+** load_vl9:\n+**\tmov\t(x[0-9]+), #?9\n+**\twhilelo\t(p[0-7])\\.h, xzr, \\1\n+**\tld1h\tz0\\.h, \\2/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl9 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 9), ptr);\n+}\n+\n+/*\n+** load_vl15:\n+**\tmov\t(x[0-9]+), #?15\n+**\twhilelo\t(p[0-7])\\.h, xzr, \\1\n+**\tld1h\tz0\\.h, \\2/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl15 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 15), ptr);\n+}\n+\n+/*\n+** load_vl16:\n+**\tptrue\t(p[0-7])\\.h, vl16\n+**\tld1h\tz0\\.h, \\1/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl16 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 16), ptr);\n+}\n+\n+/*\n+** load_vl17:\n+**\tmov\t(x[0-9]+), #?17\n+**\twhilelo\t(p[0-7])\\.h, xzr, \\1\n+**\tld1h\tz0\\.h, \\2/z, \\[x0\\]\n+**\tret\n+*/\n+svint16_t\n+load_vl17 (int16_t *ptr)\n+{\n+  return svld1 (svwhilelt_b16 (0, 17), ptr);\n+}\n+\n+#ifdef __cplusplus\n+}\n+#endif\n+\n+/* { dg-final { scan-tree-dump-not \"VIEW_CONVERT_EXPR\" \"optimized\" } } */"}]}