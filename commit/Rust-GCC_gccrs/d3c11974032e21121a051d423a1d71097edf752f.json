{"sha": "d3c11974032e21121a051d423a1d71097edf752f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDNjMTE5NzQwMzJlMjExMjFhMDUxZDQyM2ExZDcxMDk3ZWRmNzUyZg==", "commit": {"author": {"name": "H.J. Lu", "email": "hongjiu.lu@intel.com", "date": "2013-12-23T13:05:09Z"}, "committer": {"name": "H.J. Lu", "email": "hjl@gcc.gnu.org", "date": "2013-12-23T13:05:09Z"}, "message": "Use proper Intel processor names for -march=/-mtune=\n\ngcc/\n\n\t* config/i386/core2.md: Replace corei7 with nehalem.\n\n\t* config/i386/driver-i386.c (host_detect_local_cpu): Use nehalem,\n\twestmere, sandybridge, ivybridge, haswell, bonnell, silvermont\n\tfor cpu names.\n\n\t* config/i386/i386-c.c (ix86_target_macros_internal): Replace\n\tPROCESSOR_COREI7, PROCESSOR_COREI7_AVX, PROCESSOR_ATOM,\n\tPROCESSOR_SLM with PROCESSOR_NEHALEM, PROCESSOR_SANDYBRIDGE,\n\tPROCESSOR_BONNELL, PROCESSOR_SILVERMONT.  Define\n\t__nehalem/__nehalem__, __sandybridge/__sandybridge__,\n\t__haswell/__haswell__, __tune_nehalem__, __tune_sandybridge__,\n\t__tune_haswell__, __bonnell/__bonnell__,\n\t__silvermont/__silvermont__, __tune_bonnell__,\n\t__tune_silvermont__.\n\n\t* config/i386/i386.c (m_COREI7): Renamed to ...\n\t(m_NEHALEM): This.\n\t(m_COREI7_AVX): Renamed to ...\n\t(m_SANDYBRIDGE): This.\n\t(m_ATOM): Renamed to ...\n\t(m_BONNELL): This.\n\t(m_SLM): Renamed to ...\n\t(m_SILVERMONT): This.\n\t(m_CORE_ALL): Updated.\n\t(cpu_names): Add \"nehalem\", \"westmere\", \"sandybridge\",\n\t\"ivybridge\", \"haswell\", \"broadwell\", \"bonnell\", \"silvermont\".\n\t(PTA_CORE2): New.\n\t(PTA_NEHALEM): Likewise.\n\t(PTA_WESTMERE): Likewise.\n\t(PTA_SANDYBRIDGE): Likewise.\n\t(PTA_IVYBRIDGE): Likewise.\n\t(PTA_HASWELL): Likewise.\n\t(PTA_BROADWELL): Likewise.\n\t(PTA_BONNELL): Likewise.\n\t(PTA_SILVERMONT): Likewise.\n\t(ix86_option_override_internal): Use new PTA_XXX.  Add nehalem,\n\twestmere, sandybridge, ivybridge, haswell, bonnell, silvermont.\n\t(ix86_lea_outperforms): Updated.\n\t(ix86_issue_rate): Likewise.\n\t(ix86_adjust_cost): Likewise.\n\t(ia32_multipass_dfa_lookahead): Likewise.\n\t(do_reorder_for_imul): Likewise.\n\t(swap_top_of_ready_list): Likewise.\n\t(ix86_sched_reorder): Likewise.\n\t(ix86_sched_init_global): Likewise.\n\t(get_builtin_code_for_version): Likewise.\n\t(processor_model): Replace M_INTEL_ATOM, M_INTEL_SLM with\n\tM_INTEL_BONNELL, M_INTEL_SILVERMONT.\n\t(arch_names_table): Updated.\n\n\t* config/i386/i386.h (TARGET_COREI7): Removed.\n\t(TARGET_COREI7_AVX): Likewise.\n\t(TARGET_ATOM): Likewise.\n\t(TARGET_SLM): Likewise.\n\t(TARGET_NEHALEM): New.\n\t(TARGET_SANDYBRIDGE): Likewise.\n\t(TARGET_BONNELL): Likewise.\n\t(TARGET_SILVERMONT): Likewise.\n\t(target_cpu_default): Add TARGET_CPU_DEFAULT_core_avx2,\n\tTARGET_CPU_DEFAULT_nehalem, TARGET_CPU_DEFAULT_westmere,\n\tTARGET_CPU_DEFAULT_sandybridge, TARGET_CPU_DEFAULT_ivybridge,\n\tTARGET_CPU_DEFAULT_broadwell, TARGET_CPU_DEFAULT_bonnell,\n\tTARGET_CPU_DEFAULT_silvermont.  Move TARGET_CPU_DEFAULT_haswell\n\tbefore TARGET_CPU_DEFAULT_broadwell.\n\t(processor_type): Replace PROCESSOR_COREI7, PROCESSOR_COREI7_AVX,\n\tPROCESSOR_ATOM, PROCESSOR_SLM with PROCESSOR_NEHALEM,\n\tPROCESSOR_SANDYBRIDGE, PROCESSOR_BONNELL, PROCESSOR_SILVERMONT.\n\n\t* config/i386/i386.md (cpu): Replace corei7 with nehalem.\n\n\t* config/i386/x86-tune.def: Updated.\n\n\t* doc/invoke.texi: Replace corei7, corei7-avx, core-avx-i,\n\tcore-avx2, atom, slm with nehalem, sandybridge, ivybridge,\n\thaswell, bonnel, silvermont.  Add westmere.\n\nlibgcc/\n\n\t* config/i386/cpuinfo.c (processor_subtypes): Replace INTEL_ATOM,\n\tINTEL_SLM with INTEL_BONNELL, INTEL_SILVERMONT.\n\t(get_intel_cpu): Updated.\n\nCo-Authored-By: Tocar Ilya <ilya.tocar@intel.com>\n\nFrom-SVN: r206178", "tree": {"sha": "a90e9c2e4400e317c3e0614da8313c4a75d986bb", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a90e9c2e4400e317c3e0614da8313c4a75d986bb"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d3c11974032e21121a051d423a1d71097edf752f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d3c11974032e21121a051d423a1d71097edf752f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d3c11974032e21121a051d423a1d71097edf752f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d3c11974032e21121a051d423a1d71097edf752f/comments", "author": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "ae8310ec6eba51ef6d39d3fd25ffcec7f9da3759", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ae8310ec6eba51ef6d39d3fd25ffcec7f9da3759", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ae8310ec6eba51ef6d39d3fd25ffcec7f9da3759"}], "stats": {"total": 629, "additions": 377, "deletions": 252}, "files": [{"sha": "9a5b7984d317c9bc78aedb15ef80f5d344577e90", "filename": "gcc/ChangeLog", "status": "modified", "additions": 80, "deletions": 0, "changes": 80, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -1,3 +1,83 @@\n+2013-12-23   H.J. Lu  <hongjiu.lu@intel.com>\n+\t     Tocar Ilya  <ilya.tocar@intel.com> \n+\n+\t* config/i386/core2.md: Replace corei7 with nehalem.\n+\n+\t* config/i386/driver-i386.c (host_detect_local_cpu): Use nehalem,\n+\twestmere, sandybridge, ivybridge, haswell, bonnell, silvermont\n+\tfor cpu names.\n+\n+\t* config/i386/i386-c.c (ix86_target_macros_internal): Replace\n+\tPROCESSOR_COREI7, PROCESSOR_COREI7_AVX, PROCESSOR_ATOM,\n+\tPROCESSOR_SLM with PROCESSOR_NEHALEM, PROCESSOR_SANDYBRIDGE,\n+\tPROCESSOR_BONNELL, PROCESSOR_SILVERMONT.  Define\n+\t__nehalem/__nehalem__, __sandybridge/__sandybridge__,\n+\t__haswell/__haswell__, __tune_nehalem__, __tune_sandybridge__,\n+\t__tune_haswell__, __bonnell/__bonnell__,\n+\t__silvermont/__silvermont__, __tune_bonnell__,\n+\t__tune_silvermont__.\n+\n+\t* config/i386/i386.c (m_COREI7): Renamed to ...\n+\t(m_NEHALEM): This.\n+\t(m_COREI7_AVX): Renamed to ...\n+\t(m_SANDYBRIDGE): This.\n+\t(m_ATOM): Renamed to ...\n+\t(m_BONNELL): This.\n+\t(m_SLM): Renamed to ...\n+\t(m_SILVERMONT): This.\n+\t(m_CORE_ALL): Updated.\n+\t(cpu_names): Add \"nehalem\", \"westmere\", \"sandybridge\",\n+\t\"ivybridge\", \"haswell\", \"broadwell\", \"bonnell\", \"silvermont\".\n+\t(PTA_CORE2): New.\n+\t(PTA_NEHALEM): Likewise.\n+\t(PTA_WESTMERE): Likewise.\n+\t(PTA_SANDYBRIDGE): Likewise.\n+\t(PTA_IVYBRIDGE): Likewise.\n+\t(PTA_HASWELL): Likewise.\n+\t(PTA_BROADWELL): Likewise.\n+\t(PTA_BONNELL): Likewise.\n+\t(PTA_SILVERMONT): Likewise.\n+\t(ix86_option_override_internal): Use new PTA_XXX.  Add nehalem,\n+\twestmere, sandybridge, ivybridge, haswell, bonnell, silvermont.\n+\t(ix86_lea_outperforms): Updated.\n+\t(ix86_issue_rate): Likewise.\n+\t(ix86_adjust_cost): Likewise.\n+\t(ia32_multipass_dfa_lookahead): Likewise.\n+\t(do_reorder_for_imul): Likewise.\n+\t(swap_top_of_ready_list): Likewise.\n+\t(ix86_sched_reorder): Likewise.\n+\t(ix86_sched_init_global): Likewise.\n+\t(get_builtin_code_for_version): Likewise.\n+\t(processor_model): Replace M_INTEL_ATOM, M_INTEL_SLM with\n+\tM_INTEL_BONNELL, M_INTEL_SILVERMONT.\n+\t(arch_names_table): Updated.\n+\n+\t* config/i386/i386.h (TARGET_COREI7): Removed.\n+\t(TARGET_COREI7_AVX): Likewise.\n+\t(TARGET_ATOM): Likewise.\n+\t(TARGET_SLM): Likewise.\n+\t(TARGET_NEHALEM): New.\n+\t(TARGET_SANDYBRIDGE): Likewise.\n+\t(TARGET_BONNELL): Likewise.\n+\t(TARGET_SILVERMONT): Likewise.\n+\t(target_cpu_default): Add TARGET_CPU_DEFAULT_core_avx2,\n+\tTARGET_CPU_DEFAULT_nehalem, TARGET_CPU_DEFAULT_westmere,\n+\tTARGET_CPU_DEFAULT_sandybridge, TARGET_CPU_DEFAULT_ivybridge,\n+\tTARGET_CPU_DEFAULT_broadwell, TARGET_CPU_DEFAULT_bonnell,\n+\tTARGET_CPU_DEFAULT_silvermont.  Move TARGET_CPU_DEFAULT_haswell\n+\tbefore TARGET_CPU_DEFAULT_broadwell.\n+\t(processor_type): Replace PROCESSOR_COREI7, PROCESSOR_COREI7_AVX,\n+\tPROCESSOR_ATOM, PROCESSOR_SLM with PROCESSOR_NEHALEM,\n+\tPROCESSOR_SANDYBRIDGE, PROCESSOR_BONNELL, PROCESSOR_SILVERMONT.\n+\n+\t* config/i386/i386.md (cpu): Replace corei7 with nehalem.\n+\n+\t* config/i386/x86-tune.def: Updated.\n+\n+\t* doc/invoke.texi: Replace corei7, corei7-avx, core-avx-i,\n+\tcore-avx2, atom, slm with nehalem, sandybridge, ivybridge,\n+\thaswell, bonnel, silvermont.  Add westmere.\n+\n 2013-12-23  Andrey Belevantsev  <abel@ispras.ru>\n \n \tPR rtl-optimization/57422"}, {"sha": "daf7b8d5599829e1a3da917cce850eecd94d8065", "filename": "gcc/config/i386/core2.md", "status": "modified", "additions": 86, "deletions": 86, "changes": 172, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fcore2.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fcore2.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fcore2.md?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -102,63 +102,63 @@\n ;; on decoder 0, and say that it takes a little while before the result\n ;; is available.\n (define_insn_reservation \"c2_complex_insn\" 6\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (eq_attr \"type\" \"other,multi,str\"))\n \t\t\t \"c2_decoder0\")\n \n (define_insn_reservation \"c2_call\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (eq_attr \"type\" \"call,callv\"))\n \t\t\t \"c2_decoder0\")\n \n ;; imov with memory operands does not use the integer units.\n ;; imovx always decodes to one uop, and also doesn't use the integer\n ;; units if it has memory operands.\n (define_insn_reservation \"c2_imov\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"imov,imovx\")))\n \t\t\t \"c2_decodern,(c2_p0|c2_p1|c2_p5)\")\n \n (define_insn_reservation \"c2_imov_load\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"imov,imovx\")))\n \t\t\t \"c2_decodern,c2_p2\")\n \n (define_insn_reservation \"c2_imov_store\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"store\")\n \t\t\t\t   (eq_attr \"type\" \"imov\")))\n \t\t\t \"c2_decodern,c2_p4+c2_p3\")\n \n (define_insn_reservation \"c2_icmov\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"icmov\")))\n \t\t\t \"c2_decoder0,(c2_p0|c2_p1|c2_p5)*2\")\n \n (define_insn_reservation \"c2_icmov_load\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"icmov\")))\n \t\t\t \"c2_decoder0,c2_p2,(c2_p0|c2_p1|c2_p5)*2\")\n \n (define_insn_reservation \"c2_push_reg\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"store\")\n \t\t\t\t   (eq_attr \"type\" \"push\")))\n \t\t\t \"c2_decodern,c2_p4+c2_p3\")\n \n (define_insn_reservation \"c2_push_mem\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"both\")\n \t\t\t\t   (eq_attr \"type\" \"push\")))\n \t\t\t \"c2_decoder0,c2_p2,c2_p4+c2_p3\")\n \n ;; lea executes on port 0 with latency one and throughput 1.\n (define_insn_reservation \"c2_lea\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"lea\")))\n \t\t\t \"c2_decodern,c2_p0\")\n@@ -167,61 +167,61 @@\n ;; The load and store units need to be reserved when memory operands\n ;; are involved.\n (define_insn_reservation \"c2_shift_rotate\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"ishift,ishift1,rotate,rotate1\")))\n \t\t\t \"c2_decodern,(c2_p0|c2_p5)\")\n \n (define_insn_reservation \"c2_shift_rotate_mem\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"!none\")\n \t\t\t\t   (eq_attr \"type\" \"ishift,ishift1,rotate,rotate1\")))\n \t\t\t \"c2_decoder0,c2_p2,(c2_p0|c2_p5),c2_p4+c2_p3\")\n \n ;; See comments in ppro.md for the corresponding reservation.\n (define_insn_reservation \"c2_branch\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"ibr\")))\n \t\t\t \"c2_decodern,c2_p5\")\n \n ;; ??? Indirect branches probably have worse latency than this.\n (define_insn_reservation \"c2_indirect_branch\" 6\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"!none\")\n \t\t\t\t   (eq_attr \"type\" \"ibr\")))\n \t\t\t \"c2_decoder0,c2_p2+c2_p5\")\n \n (define_insn_reservation \"c2_leave\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (eq_attr \"type\" \"leave\"))\n \t\t\t \"c2_decoder0,c2_p2+(c2_p0|c2_p1),(c2_p0|c2_p1)\")\n \n ;; mul and imul with two/three operands only execute on port 1 for HImode\n ;; and SImode, port 0 for DImode.\n (define_insn_reservation \"c2_imul_hisi\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"HI,SI\")\n \t\t\t\t\t(eq_attr \"type\" \"imul\"))))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_imul_hisi_mem\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"!none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"HI,SI\")\n \t\t\t\t\t(eq_attr \"type\" \"imul\"))))\n \t\t\t \"c2_decoder0,c2_p2+c2_p1\")\n \n (define_insn_reservation \"c2_imul_di\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DI\")\n \t\t\t\t\t(eq_attr \"type\" \"imul\"))))\n \t\t\t \"c2_decodern,c2_p0\")\n \n (define_insn_reservation \"c2_imul_di_mem\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"!none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DI\")\n \t\t\t\t\t(eq_attr \"type\" \"imul\"))))\n@@ -231,42 +231,42 @@\n ;; QI, HI, and SI have issue latency 12, 21, and 37, respectively.\n ;; These issue latencies are modelled via the c2_div automaton.\n (define_insn_reservation \"c2_idiv_QI\" 19\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"QI\")\n \t\t\t\t\t(eq_attr \"type\" \"idiv\"))))\n \t\t\t \"c2_decoder0,(c2_p0+c2_idiv)*2,(c2_p0|c2_p1)+c2_idiv,c2_idiv*9\")\n \n (define_insn_reservation \"c2_idiv_QI_load\" 19\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"QI\")\n \t\t\t\t\t(eq_attr \"type\" \"idiv\"))))\n \t\t\t \"c2_decoder0,c2_p2+c2_p0+c2_idiv,c2_p0+c2_idiv,(c2_p0|c2_p1)+c2_idiv,c2_idiv*9\")\n \n (define_insn_reservation \"c2_idiv_HI\" 23\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"HI\")\n \t\t\t\t\t(eq_attr \"type\" \"idiv\"))))\n \t\t\t \"c2_decoder0,(c2_p0+c2_idiv)*3,(c2_p0|c2_p1)+c2_idiv,c2_idiv*17\")\n \n (define_insn_reservation \"c2_idiv_HI_load\" 23\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"HI\")\n \t\t\t\t\t(eq_attr \"type\" \"idiv\"))))\n \t\t\t \"c2_decoder0,c2_p2+c2_p0+c2_idiv,c2_p0+c2_idiv,(c2_p0|c2_p1)+c2_idiv,c2_idiv*18\")\n \n (define_insn_reservation \"c2_idiv_SI\" 39\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SI\")\n \t\t\t\t\t(eq_attr \"type\" \"idiv\"))))\n \t\t\t \"c2_decoder0,(c2_p0+c2_idiv)*3,(c2_p0|c2_p1)+c2_idiv,c2_idiv*33\")\n \n (define_insn_reservation \"c2_idiv_SI_load\" 39\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SI\")\n \t\t\t\t\t(eq_attr \"type\" \"idiv\"))))\n@@ -275,90 +275,90 @@\n ;; x87 floating point operations.\n \n (define_insn_reservation \"c2_fxch\" 0\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (eq_attr \"type\" \"fxch\"))\n \t\t\t \"c2_decodern\")\n \n (define_insn_reservation \"c2_fop\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none,unknown\")\n \t\t\t\t   (eq_attr \"type\" \"fop\")))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_fop_load\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"fop\")))\n \t\t\t \"c2_decoder0,c2_p2+c2_p1,c2_p1\")\n \n (define_insn_reservation \"c2_fop_store\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"store\")\n \t\t\t\t   (eq_attr \"type\" \"fop\")))\n \t\t\t \"c2_decoder0,c2_p0,c2_p0,c2_p0+c2_p4+c2_p3\")\n \n (define_insn_reservation \"c2_fop_both\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"both\")\n \t\t\t\t   (eq_attr \"type\" \"fop\")))\n \t\t\t \"c2_decoder0,c2_p2+c2_p0,c2_p0+c2_p4+c2_p3\")\n \n (define_insn_reservation \"c2_fsgn\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (eq_attr \"type\" \"fsgn\"))\n \t\t\t \"c2_decodern,c2_p0\")\n \n (define_insn_reservation \"c2_fistp\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (eq_attr \"type\" \"fistp\"))\n \t\t\t \"c2_decoder0,c2_p0*2,c2_p4+c2_p3\")\n \n (define_insn_reservation \"c2_fcmov\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (eq_attr \"type\" \"fcmov\"))\n \t\t\t \"c2_decoder0,c2_p0*2\")\n \n (define_insn_reservation \"c2_fcmp\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"fcmp\")))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_fcmp_load\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"fcmp\")))\n \t\t\t \"c2_decoder0,c2_p2+c2_p1\")\n \n (define_insn_reservation \"c2_fmov\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"fmov\")))\n \t\t\t \"c2_decodern,c2_p0\")\n \n (define_insn_reservation \"c2_fmov_load\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"!XF\")\n \t\t\t\t\t(eq_attr \"type\" \"fmov\"))))\n \t\t\t \"c2_decodern,c2_p2\")\n \n (define_insn_reservation \"c2_fmov_XF_load\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"XF\")\n \t\t\t\t\t(eq_attr \"type\" \"fmov\"))))\n \t\t\t \"c2_decoder0,(c2_p2+c2_p0)*2\")\n \n (define_insn_reservation \"c2_fmov_store\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"store\")\n \t\t\t\t   (and (eq_attr \"mode\" \"!XF\")\n \t\t\t\t\t(eq_attr \"type\" \"fmov\"))))\n \t\t\t \"c2_decodern,c2_p3+c2_p4\")\n \n (define_insn_reservation \"c2_fmov_XF_store\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"store\")\n \t\t\t\t   (and (eq_attr \"mode\" \"XF\")\n \t\t\t\t\t(eq_attr \"type\" \"fmov\"))))\n@@ -367,13 +367,13 @@\n ;; fmul executes on port 0 with latency 5.  It has issue latency 2,\n ;; but we don't model this.\n (define_insn_reservation \"c2_fmul\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"fmul\")))\n \t\t\t \"c2_decoder0,c2_p0*2\")\n \n (define_insn_reservation \"c2_fmul_load\" 6\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"fmul\")))\n \t\t\t \"c2_decoder0,c2_p2+c2_p0,c2_p0\")\n@@ -384,42 +384,42 @@\n ;; that.  Throughput is equal to latency - 1, which we model using the\n ;; c2_div automaton.\n (define_insn_reservation \"c2_fdiv_SF\" 18\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF\")\n \t\t\t\t\t(eq_attr \"type\" \"fdiv,fpspc\"))))\n \t\t\t \"c2_decodern,c2_p0+c2_fdiv,c2_fdiv*16\")\n \n (define_insn_reservation \"c2_fdiv_SF_load\" 19\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF\")\n \t\t\t\t\t(eq_attr \"type\" \"fdiv,fpspc\"))))\n \t\t\t \"c2_decoder0,c2_p2+c2_p0+c2_fdiv,c2_fdiv*16\")\n \n (define_insn_reservation \"c2_fdiv_DF\" 32\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF\")\n \t\t\t\t\t(eq_attr \"type\" \"fdiv,fpspc\"))))\n \t\t\t \"c2_decodern,c2_p0+c2_fdiv,c2_fdiv*30\")\n \n (define_insn_reservation \"c2_fdiv_DF_load\" 33\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF\")\n \t\t\t\t\t(eq_attr \"type\" \"fdiv,fpspc\"))))\n \t\t\t \"c2_decoder0,c2_p2+c2_p0+c2_fdiv,c2_fdiv*30\")\n \n (define_insn_reservation \"c2_fdiv_XF\" 38\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"XF\")\n \t\t\t\t\t(eq_attr \"type\" \"fdiv,fpspc\"))))\n \t\t\t \"c2_decodern,c2_p0+c2_fdiv,c2_fdiv*36\")\n \n (define_insn_reservation \"c2_fdiv_XF_load\" 39\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"XF\")\n \t\t\t\t\t(eq_attr \"type\" \"fdiv,fpspc\"))))\n@@ -428,228 +428,228 @@\n ;; MMX instructions.\n \n (define_insn_reservation \"c2_mmx_add\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"mmxadd,sseiadd\")))\n \t\t\t \"c2_decodern,c2_p0|c2_p5\")\n \n (define_insn_reservation \"c2_mmx_add_load\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"mmxadd,sseiadd\")))\n \t\t\t \"c2_decodern,c2_p2+c2_p0|c2_p5\")\n \n (define_insn_reservation \"c2_mmx_shft\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"mmxshft\")))\n \t\t\t \"c2_decodern,c2_p0|c2_p5\")\n \n (define_insn_reservation \"c2_mmx_shft_load\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"mmxshft\")))\n \t\t\t \"c2_decoder0,c2_p2+c2_p1\")\n \n (define_insn_reservation \"c2_mmx_sse_shft\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"type\" \"sseishft\")\n \t\t\t\t\t(eq_attr \"length_immediate\" \"!0\"))))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_mmx_sse_shft_load\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"type\" \"sseishft\")\n \t\t\t\t\t(eq_attr \"length_immediate\" \"!0\"))))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_mmx_sse_shft1\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"type\" \"sseishft\")\n \t\t\t\t\t(eq_attr \"length_immediate\" \"0\"))))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_mmx_sse_shft1_load\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"type\" \"sseishft\")\n \t\t\t\t\t(eq_attr \"length_immediate\" \"0\"))))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_mmx_mul\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"mmxmul,sseimul\")))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_mmx_mul_load\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"mmxmul,sseimul\")))\n \t\t\t \"c2_decoder0,c2_p2+c2_p1\")\n \n (define_insn_reservation \"c2_sse_mmxcvt\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"mode\" \"DI\")\n \t\t\t\t   (eq_attr \"type\" \"mmxcvt\")))\n \t\t\t \"c2_decodern,c2_p1\")\n \n ;; FIXME: These are Pentium III only, but we cannot tell here if\n ;; we're generating code for PentiumPro/Pentium II or Pentium III\n ;; (define_insn_reservation \"c2_sse_mmxshft\" 2\n-;;\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+;;\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n ;;\t\t\t      (and (eq_attr \"mode\" \"TI\")\n ;;\t\t\t\t   (eq_attr \"type\" \"mmxshft\")))\n ;;\t\t\t \"c2_decodern,c2_p0\")\n \n ;; The sfence instruction.\n (define_insn_reservation \"c2_sse_sfence\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"unknown\")\n \t\t\t\t   (eq_attr \"type\" \"sse\")))\n \t\t\t \"c2_decoder0,c2_p4+c2_p3\")\n \n ;; FIXME: This reservation is all wrong when we're scheduling sqrtss.\n (define_insn_reservation \"c2_sse_SFDF\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"mode\" \"SF,DF\")\n \t\t\t\t   (eq_attr \"type\" \"sse\")))\n \t\t\t \"c2_decodern,c2_p0\")\n \n (define_insn_reservation \"c2_sse_V4SF\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"mode\" \"V4SF\")\n \t\t\t\t   (eq_attr \"type\" \"sse\")))\n \t\t\t \"c2_decoder0,c2_p1*2\")\n \n (define_insn_reservation \"c2_sse_addcmp\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"sseadd,sseadd1,ssecmp,ssecomi\")))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_sse_addcmp_load\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"sseadd,sseadd1,ssecmp,ssecomi\")))\n \t\t\t \"c2_decodern,c2_p2+c2_p1\")\n \n (define_insn_reservation \"c2_sse_mul_SF\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF,V4SF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssemul\"))))\n \t\t\t\"c2_decodern,c2_p0\")\n \n (define_insn_reservation \"c2_sse_mul_SF_load\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF,V4SF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssemul\"))))\n \t\t\t\"c2_decodern,c2_p2+c2_p0\")\n \n (define_insn_reservation \"c2_sse_mul_DF\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF,V2DF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssemul\"))))\n \t\t\t\"c2_decodern,c2_p0\")\n \n (define_insn_reservation \"c2_sse_mul_DF_load\" 5\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF,V2DF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssemul\"))))\n \t\t\t\"c2_decodern,c2_p2+c2_p0\")\n \n (define_insn_reservation \"c2_sse_div_SF\" 18\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF,V4SF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssediv\"))))\n \t\t\t \"c2_decodern,c2_p0,c2_ssediv*17\")\n \n (define_insn_reservation \"c2_sse_div_SF_load\" 18\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF,V4SF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssediv\"))))\n \t\t\t \"c2_decodern,(c2_p2+c2_p0),c2_ssediv*17\")\n \n (define_insn_reservation \"c2_sse_div_DF\" 32\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF,V2DF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssediv\"))))\n \t\t\t \"c2_decodern,c2_p0,c2_ssediv*31\")\n \n (define_insn_reservation \"c2_sse_div_DF_load\" 32\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF,V2DF\")\n \t\t\t\t\t(eq_attr \"type\" \"ssediv\"))))\n \t\t\t \"c2_decodern,(c2_p2+c2_p0),c2_ssediv*31\")\n \n ;; FIXME: these have limited throughput\n (define_insn_reservation \"c2_sse_icvt_SF\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF\")\n \t\t\t\t\t(eq_attr \"type\" \"sseicvt\"))))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_sse_icvt_SF_load\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"!none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SF\")\n \t\t\t\t\t(eq_attr \"type\" \"sseicvt\"))))\n \t\t\t \"c2_decodern,c2_p2+c2_p1\")\n \n (define_insn_reservation \"c2_sse_icvt_DF\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF\")\n \t\t\t\t\t(eq_attr \"type\" \"sseicvt\"))))\n \t\t\t \"c2_decoder0,c2_p0+c2_p1\")\n \n (define_insn_reservation \"c2_sse_icvt_DF_load\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"!none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"DF\")\n \t\t\t\t\t(eq_attr \"type\" \"sseicvt\"))))\n \t\t\t \"c2_decoder0,(c2_p2+c2_p1)\")\n \n (define_insn_reservation \"c2_sse_icvt_SI\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SI\")\n \t\t\t\t\t(eq_attr \"type\" \"sseicvt\"))))\n \t\t\t \"c2_decodern,c2_p1\")\n \n (define_insn_reservation \"c2_sse_icvt_SI_load\" 3\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"!none\")\n \t\t\t\t   (and (eq_attr \"mode\" \"SI\")\n \t\t\t\t\t(eq_attr \"type\" \"sseicvt\"))))\n \t\t\t \"c2_decodern,(c2_p2+c2_p1)\")\n \n (define_insn_reservation \"c2_sse_mov\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none\")\n \t\t\t\t   (eq_attr \"type\" \"ssemov\")))\n \t\t\t \"c2_decodern,(c2_p0|c2_p1|c2_p5)\")\n \n (define_insn_reservation \"c2_sse_mov_load\" 2\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"ssemov\")))\n \t\t\t \"c2_decodern,c2_p2\")\n \n (define_insn_reservation \"c2_sse_mov_store\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"store\")\n \t\t\t\t   (eq_attr \"type\" \"ssemov\")))\n \t\t\t \"c2_decodern,c2_p4+c2_p3\")\n@@ -663,29 +663,29 @@\n ;; the three decoders.  Loads benefit from micro-op fusion and can be\n ;; treated in the same way.\n (define_insn_reservation \"c2_insn\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"none,unknown\")\n \t\t\t\t   (eq_attr \"type\" \"alu,alu1,negnot,incdec,icmp,test,setcc,sseishft1,mmx,mmxcmp\")))\n \t\t\t \"c2_decodern,(c2_p0|c2_p1|c2_p5)\")\n \n (define_insn_reservation \"c2_insn_load\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"load\")\n \t\t\t\t   (eq_attr \"type\" \"alu,alu1,negnot,incdec,icmp,test,setcc,pop,sseishft1,mmx,mmxcmp\")))\n \t\t\t \"c2_decodern,c2_p2,(c2_p0|c2_p1|c2_p5)\")\n \n ;; register-memory instructions have three uops,  so they have to be\n ;; decoded on c2_decoder0.\n (define_insn_reservation \"c2_insn_store\" 1\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"store\")\n \t\t\t\t   (eq_attr \"type\" \"alu,alu1,negnot,incdec,icmp,test,setcc,sseishft1,mmx,mmxcmp\")))\n \t\t\t \"c2_decoder0,(c2_p0|c2_p1|c2_p5),c2_p4+c2_p3\")\n \n ;; read-modify-store instructions produce 4 uops so they have to be\n ;; decoded on c2_decoder0 as well.\n (define_insn_reservation \"c2_insn_both\" 4\n-\t\t\t (and (eq_attr \"cpu\" \"core2,corei7\")\n+\t\t\t (and (eq_attr \"cpu\" \"core2,nehalem\")\n \t\t\t      (and (eq_attr \"memory\" \"both\")\n \t\t\t\t   (eq_attr \"type\" \"alu,alu1,negnot,incdec,icmp,test,setcc,pop,sseishft1,mmx,mmxcmp\")))\n \t\t\t \"c2_decoder0,c2_p2,(c2_p0|c2_p1|c2_p5),c2_p4+c2_p3\")"}, {"sha": "4d0b2646baeb7e432a9a0e10e7813ff4510c3915", "filename": "gcc/config/i386/driver-i386.c", "status": "modified", "additions": 17, "deletions": 15, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fdriver-i386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fdriver-i386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fdriver-i386.c?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -643,13 +643,13 @@ const char *host_detect_local_cpu (int argc, const char **argv)\n \t{\n \tcase 0x1c:\n \tcase 0x26:\n-\t  /* Atom.  */\n-\t  cpu = \"atom\";\n+\t  /* Bonnell.  */\n+\t  cpu = \"bonnell\";\n \t  break;\n \tcase 0x37:\n \tcase 0x4d:\n \t  /* Silvermont.  */\n-\t  cpu = \"slm\";\n+\t  cpu = \"silvermont\";\n \t  break;\n \tcase 0x0f:\n \t  /* Merom.  */\n@@ -663,27 +663,29 @@ const char *host_detect_local_cpu (int argc, const char **argv)\n \tcase 0x1f:\n \tcase 0x2e:\n \t  /* Nehalem.  */\n+\t  cpu = \"nehalem\";\n+\t  break;\n \tcase 0x25:\n \tcase 0x2c:\n \tcase 0x2f:\n \t  /* Westmere.  */\n-\t  cpu = \"corei7\";\n+\t  cpu = \"westmere\";\n \t  break;\n \tcase 0x2a:\n \tcase 0x2d:\n \t  /* Sandy Bridge.  */\n-\t  cpu = \"corei7-avx\";\n+\t  cpu = \"sandybridge\";\n \t  break;\n \tcase 0x3a:\n \tcase 0x3e:\n \t  /* Ivy Bridge.  */\n-\t  cpu = \"core-avx-i\";\n+\t  cpu = \"ivybridge\";\n \t  break;\n \tcase 0x3c:\n \tcase 0x45:\n \tcase 0x46:\n \t  /* Haswell.  */\n-\t  cpu = \"core-avx2\";\n+\t  cpu = \"haswell\";\n \t  break;\n \tdefault:\n \t  if (arch)\n@@ -693,24 +695,24 @@ const char *host_detect_local_cpu (int argc, const char **argv)\n \t\tcpu = \"broadwell\";\n \t      else if (has_avx2)\n \t\t/* Assume Haswell.  */\n-\t\tcpu = \"core-avx2\";\n+\t\tcpu = \"haswell\";\n \t      else if (has_avx)\n \t\t/* Assume Sandy Bridge.  */\n-\t\tcpu = \"corei7-avx\";\n+\t\tcpu = \"sandybridge\";\n \t      else if (has_sse4_2)\n \t\t{\n \t\t  if (has_movbe)\n-\t\t    /* Assume SLM.  */\n-\t\t    cpu = \"slm\";\n+\t\t    /* Assume Silvermont.  */\n+\t\t    cpu = \"silvermont\";\n \t\t  else\n-\t\t    /* Assume Core i7.  */\n-\t\t    cpu = \"corei7\";\n+\t\t    /* Assume Nehalem.  */\n+\t\t    cpu = \"nehalem\";\n \t\t}\n \t      else if (has_ssse3)\n \t\t{\n \t\t  if (has_movbe)\n-\t\t    /* Assume Atom.  */\n-\t\t    cpu = \"atom\";\n+\t\t    /* Assume Bonnell.  */\n+\t\t    cpu = \"bonnell\";\n \t\t  else\n \t\t    /* Assume Core 2.  */\n \t\t    cpu = \"core2\";"}, {"sha": "3710c6e176ec7f39585fa12fbc6e2a144e91d76f", "filename": "gcc/config/i386/i386-c.c", "status": "modified", "additions": 23, "deletions": 8, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-c.c?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -141,25 +141,35 @@ ix86_target_macros_internal (HOST_WIDE_INT isa_flag,\n       def_or_undef (parse_in, \"__core2\");\n       def_or_undef (parse_in, \"__core2__\");\n       break;\n-    case PROCESSOR_COREI7:\n+    case PROCESSOR_NEHALEM:\n       def_or_undef (parse_in, \"__corei7\");\n       def_or_undef (parse_in, \"__corei7__\");\n+      def_or_undef (parse_in, \"__nehalem\");\n+      def_or_undef (parse_in, \"__nehalem__\");\n       break;\n-    case PROCESSOR_COREI7_AVX:\n+    case PROCESSOR_SANDYBRIDGE:\n       def_or_undef (parse_in, \"__corei7_avx\");\n       def_or_undef (parse_in, \"__corei7_avx__\");\n+      def_or_undef (parse_in, \"__sandybridge\");\n+      def_or_undef (parse_in, \"__sandybridge__\");\n       break;\n     case PROCESSOR_HASWELL:\n       def_or_undef (parse_in, \"__core_avx2\");\n       def_or_undef (parse_in, \"__core_avx2__\");\n+      def_or_undef (parse_in, \"__haswell\");\n+      def_or_undef (parse_in, \"__haswell__\");\n       break;\n-    case PROCESSOR_ATOM:\n+    case PROCESSOR_BONNELL:\n       def_or_undef (parse_in, \"__atom\");\n       def_or_undef (parse_in, \"__atom__\");\n+      def_or_undef (parse_in, \"__bonnell\");\n+      def_or_undef (parse_in, \"__bonnell__\");\n       break;\n-    case PROCESSOR_SLM:\n+    case PROCESSOR_SILVERMONT:\n       def_or_undef (parse_in, \"__slm\");\n       def_or_undef (parse_in, \"__slm__\");\n+      def_or_undef (parse_in, \"__silvermont\");\n+      def_or_undef (parse_in, \"__silvermont__\");\n       break;\n     /* use PROCESSOR_max to not set/unset the arch macro.  */\n     case PROCESSOR_max:\n@@ -246,20 +256,25 @@ ix86_target_macros_internal (HOST_WIDE_INT isa_flag,\n     case PROCESSOR_CORE2:\n       def_or_undef (parse_in, \"__tune_core2__\");\n       break;\n-    case PROCESSOR_COREI7:\n+    case PROCESSOR_NEHALEM:\n       def_or_undef (parse_in, \"__tune_corei7__\");\n+      def_or_undef (parse_in, \"__tune_nehalem__\");\n       break;\n-    case PROCESSOR_COREI7_AVX:\n+    case PROCESSOR_SANDYBRIDGE:\n       def_or_undef (parse_in, \"__tune_corei7_avx__\");\n+      def_or_undef (parse_in, \"__tune_sandybridge__\");\n       break;\n     case PROCESSOR_HASWELL:\n       def_or_undef (parse_in, \"__tune_core_avx2__\");\n+      def_or_undef (parse_in, \"__tune_haswell__\");\n       break;\n-    case PROCESSOR_ATOM:\n+    case PROCESSOR_BONNELL:\n       def_or_undef (parse_in, \"__tune_atom__\");\n+      def_or_undef (parse_in, \"__tune_bonnell__\");\n       break;\n-    case PROCESSOR_SLM:\n+    case PROCESSOR_SILVERMONT:\n       def_or_undef (parse_in, \"__tune_slm__\");\n+      def_or_undef (parse_in, \"__tune_silvermont__\");\n       break;\n     case PROCESSOR_GENERIC:\n       break;"}, {"sha": "2d480b345d4d289bf4b38bf945f285cc76dcdf0f", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 84, "deletions": 74, "changes": 158, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -1935,12 +1935,12 @@ const struct processor_costs *ix86_cost = &pentium_cost;\n #define m_NOCONA (1<<PROCESSOR_NOCONA)\n #define m_P4_NOCONA (m_PENT4 | m_NOCONA)\n #define m_CORE2 (1<<PROCESSOR_CORE2)\n-#define m_COREI7 (1<<PROCESSOR_COREI7)\n-#define m_COREI7_AVX (1<<PROCESSOR_COREI7_AVX)\n+#define m_NEHALEM (1<<PROCESSOR_NEHALEM)\n+#define m_SANDYBRIDGE (1<<PROCESSOR_SANDYBRIDGE)\n #define m_HASWELL (1<<PROCESSOR_HASWELL)\n-#define m_CORE_ALL (m_CORE2 | m_COREI7  | m_COREI7_AVX | m_HASWELL)\n-#define m_ATOM (1<<PROCESSOR_ATOM)\n-#define m_SLM (1<<PROCESSOR_SLM)\n+#define m_CORE_ALL (m_CORE2 | m_NEHALEM  | m_SANDYBRIDGE | m_HASWELL)\n+#define m_BONNELL (1<<PROCESSOR_BONNELL)\n+#define m_SILVERMONT (1<<PROCESSOR_SILVERMONT)\n \n #define m_GEODE (1<<PROCESSOR_GEODE)\n #define m_K6 (1<<PROCESSOR_K6)\n@@ -2435,6 +2435,14 @@ static const char *const cpu_names[TARGET_CPU_DEFAULT_max] =\n   \"core-avx2\",\n   \"atom\",\n   \"slm\",\n+  \"nehalem\",\n+  \"westmere\",\n+  \"sandybridge\",\n+  \"ivybridge\",\n+  \"haswell\",\n+  \"broadwell\",\n+  \"bonnell\",\n+  \"silvermont\",\n   \"intel\",\n   \"geode\",\n   \"k6\",\n@@ -3069,6 +3077,27 @@ ix86_option_override_internal (bool main_args_p,\n #define PTA_AVX512PF\t\t(HOST_WIDE_INT_1 << 42)\n #define PTA_AVX512CD\t\t(HOST_WIDE_INT_1 << 43)\n \n+#define PTA_CORE2 \\\n+  (PTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3 | PTA_SSSE3 \\\n+   | PTA_CX16 | PTA_FXSR)\n+#define PTA_NEHALEM \\\n+  (PTA_CORE2 | PTA_SSE4_1 | PTA_SSE4_2 | PTA_POPCNT)\n+#define PTA_WESTMERE \\\n+  (PTA_NEHALEM | PTA_AES | PTA_PCLMUL)\n+#define PTA_SANDYBRIDGE \\\n+  (PTA_WESTMERE | PTA_AVX | PTA_XSAVE | PTA_XSAVEOPT)\n+#define PTA_IVYBRIDGE \\\n+  (PTA_SANDYBRIDGE | PTA_FSGSBASE | PTA_RDRND | PTA_F16C)\n+#define PTA_HASWELL \\\n+  (PTA_IVYBRIDGE | PTA_AVX2 | PTA_BMI | PTA_BMI2 | PTA_LZCNT \\\n+   | PTA_FMA | PTA_MOVBE | PTA_RTM | PTA_HLE)\n+#define PTA_BROADWELL \\\n+  (PTA_HASWELL | PTA_ADX | PTA_PRFCHW | PTA_RDSEED)\n+#define PTA_BONNELL \\\n+  (PTA_CORE2 | PTA_MOVBE)\n+#define PTA_SILVERMONT \\\n+  (PTA_WESTMERE | PTA_MOVBE)\n+\n /* if this reaches 64, need to widen struct pta flags below */\n \n   static struct pta\n@@ -3108,46 +3137,26 @@ ix86_option_override_internal (bool main_args_p,\n       {\"nocona\", PROCESSOR_NOCONA, CPU_NONE,\n \tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n \t| PTA_CX16 | PTA_NO_SAHF | PTA_FXSR},\n-      {\"core2\", PROCESSOR_CORE2, CPU_CORE2,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n-\t| PTA_SSSE3 | PTA_CX16 | PTA_FXSR},\n-      {\"corei7\", PROCESSOR_COREI7, CPU_COREI7,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3 | PTA_SSSE3\n-\t| PTA_SSE4_1 | PTA_SSE4_2 | PTA_CX16 | PTA_POPCNT | PTA_FXSR},\n-      {\"corei7-avx\", PROCESSOR_COREI7_AVX, CPU_COREI7,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n-\t| PTA_SSSE3 | PTA_SSE4_1 | PTA_SSE4_2 | PTA_AVX\n-\t| PTA_CX16 | PTA_POPCNT | PTA_AES | PTA_PCLMUL\n-\t| PTA_FXSR | PTA_XSAVE | PTA_XSAVEOPT},\n-      {\"core-avx-i\", PROCESSOR_COREI7_AVX, CPU_COREI7,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n-\t| PTA_SSSE3 | PTA_SSE4_1 | PTA_SSE4_2 | PTA_AVX\n-\t| PTA_CX16 | PTA_POPCNT | PTA_AES | PTA_PCLMUL | PTA_FSGSBASE\n-\t| PTA_RDRND | PTA_F16C | PTA_FXSR | PTA_XSAVE | PTA_XSAVEOPT},\n-      {\"core-avx2\", PROCESSOR_HASWELL, CPU_COREI7,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n-\t| PTA_SSSE3 | PTA_SSE4_1 | PTA_SSE4_2 | PTA_AVX | PTA_AVX2\n-\t| PTA_CX16 | PTA_POPCNT | PTA_AES | PTA_PCLMUL | PTA_FSGSBASE\n-\t| PTA_RDRND | PTA_F16C | PTA_BMI | PTA_BMI2 | PTA_LZCNT\n-\t| PTA_FMA | PTA_MOVBE | PTA_RTM | PTA_HLE | PTA_FXSR | PTA_XSAVE\n-\t| PTA_XSAVEOPT},\n-      {\"broadwell\", PROCESSOR_HASWELL, CPU_COREI7,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n-\t| PTA_SSSE3 | PTA_SSE4_1 | PTA_SSE4_2 | PTA_AVX | PTA_AVX2\n-\t| PTA_CX16 | PTA_POPCNT | PTA_AES | PTA_PCLMUL | PTA_FSGSBASE\n-\t| PTA_RDRND | PTA_F16C | PTA_BMI | PTA_BMI2 | PTA_LZCNT\n-\t| PTA_FMA | PTA_MOVBE | PTA_RTM | PTA_HLE | PTA_FXSR | PTA_XSAVE\n-\t| PTA_XSAVEOPT | PTA_ADX | PTA_PRFCHW | PTA_RDSEED},\n-      {\"atom\", PROCESSOR_ATOM, CPU_ATOM,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n-\t| PTA_SSSE3 | PTA_CX16 | PTA_MOVBE | PTA_FXSR},\n-      {\"slm\", PROCESSOR_SLM, CPU_SLM,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3 | PTA_SSSE3\n-\t| PTA_SSE4_1 | PTA_SSE4_2 | PTA_CX16 | PTA_POPCNT | PTA_AES\n-\t| PTA_PCLMUL | PTA_RDRND | PTA_MOVBE | PTA_FXSR},\n-      {\"intel\", PROCESSOR_SLM, CPU_SLM,\n-\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3 | PTA_SSSE3\n-\t| PTA_SSE4_1 | PTA_SSE4_2 | PTA_CX16 | PTA_POPCNT | PTA_FXSR},\n+      {\"core2\", PROCESSOR_CORE2, CPU_CORE2, PTA_CORE2},\n+      {\"nehalem\", PROCESSOR_NEHALEM, CPU_NEHALEM, PTA_NEHALEM},\n+      {\"corei7\", PROCESSOR_NEHALEM, CPU_NEHALEM, PTA_NEHALEM},\n+      {\"westmere\", PROCESSOR_NEHALEM, CPU_NEHALEM, PTA_WESTMERE},\n+      {\"sandybridge\", PROCESSOR_SANDYBRIDGE, CPU_NEHALEM,\n+\tPTA_SANDYBRIDGE},\n+      {\"corei7-avx\", PROCESSOR_SANDYBRIDGE, CPU_NEHALEM,\n+\tPTA_SANDYBRIDGE},\n+      {\"ivybridge\", PROCESSOR_SANDYBRIDGE, CPU_NEHALEM,\n+\tPTA_IVYBRIDGE},\n+      {\"core-avx-i\", PROCESSOR_SANDYBRIDGE, CPU_NEHALEM,\n+\tPTA_IVYBRIDGE},\n+      {\"haswell\", PROCESSOR_HASWELL, CPU_NEHALEM, PTA_HASWELL},\n+      {\"core-avx2\", PROCESSOR_HASWELL, CPU_NEHALEM, PTA_HASWELL},\n+      {\"broadwell\", PROCESSOR_HASWELL, CPU_NEHALEM, PTA_BROADWELL},\n+      {\"bonnell\", PROCESSOR_BONNELL, CPU_ATOM, PTA_BONNELL},\n+      {\"atom\", PROCESSOR_BONNELL, CPU_ATOM, PTA_BONNELL},\n+      {\"silvermont\", PROCESSOR_SILVERMONT, CPU_SLM, PTA_SILVERMONT},\n+      {\"slm\", PROCESSOR_SILVERMONT, CPU_SLM, PTA_SILVERMONT},\n+      {\"intel\", PROCESSOR_SILVERMONT, CPU_SLM, PTA_NEHALEM},\n       {\"geode\", PROCESSOR_GEODE, CPU_GEODE,\n \tPTA_MMX | PTA_3DNOW | PTA_3DNOW_A | PTA_PREFETCH_SSE | PTA_PRFCHW},\n       {\"k6\", PROCESSOR_K6, CPU_K6, PTA_MMX},\n@@ -17879,7 +17888,7 @@ ix86_lea_outperforms (rtx insn, unsigned int regno0, unsigned int regno1,\n   /* For Silvermont if using a 2-source or 3-source LEA for\n      non-destructive destination purposes, or due to wanting\n      ability to use SCALE, the use of LEA is justified.  */\n-  if (ix86_tune == PROCESSOR_SLM)\n+  if (ix86_tune == PROCESSOR_SILVERMONT)\n     {\n       if (has_scale)\n \treturn true;\n@@ -18247,7 +18256,7 @@ ix86_split_lea_for_addr (rtx insn, rtx operands[], enum machine_mode mode)\n \n /* Return true if it is ok to optimize an ADD operation to LEA\n    operation to avoid flag register consumation.  For most processors,\n-   ADD is faster than LEA.  For the processors like ATOM, if the\n+   ADD is faster than LEA.  For the processors like BONNELL, if the\n    destination register of LEA holds an actual address which will be\n    used soon, LEA is better and otherwise ADD is better.  */\n \n@@ -25005,8 +25014,8 @@ ix86_issue_rate (void)\n   switch (ix86_tune)\n     {\n     case PROCESSOR_PENTIUM:\n-    case PROCESSOR_ATOM:\n-    case PROCESSOR_SLM:\n+    case PROCESSOR_BONNELL:\n+    case PROCESSOR_SILVERMONT:\n     case PROCESSOR_K6:\n     case PROCESSOR_BTVER2:\n     case PROCESSOR_PENTIUM4:\n@@ -25026,8 +25035,8 @@ ix86_issue_rate (void)\n     case PROCESSOR_BDVER3:\n     case PROCESSOR_BDVER4:\n     case PROCESSOR_CORE2:\n-    case PROCESSOR_COREI7:\n-    case PROCESSOR_COREI7_AVX:\n+    case PROCESSOR_NEHALEM:\n+    case PROCESSOR_SANDYBRIDGE:\n     case PROCESSOR_HASWELL:\n       return 4;\n \n@@ -25324,8 +25333,8 @@ ix86_adjust_cost (rtx insn, rtx link, rtx dep_insn, int cost)\n       break;\n \n     case PROCESSOR_CORE2:\n-    case PROCESSOR_COREI7:\n-    case PROCESSOR_COREI7_AVX:\n+    case PROCESSOR_NEHALEM:\n+    case PROCESSOR_SANDYBRIDGE:\n     case PROCESSOR_HASWELL:\n       memory = get_attr_memory (insn);\n \n@@ -25347,7 +25356,7 @@ ix86_adjust_cost (rtx insn, rtx link, rtx dep_insn, int cost)\n \t}\n       break;\n \n-    case PROCESSOR_SLM:\n+    case PROCESSOR_SILVERMONT:\n       if (!reload_completed)\n \treturn cost;\n \n@@ -25411,11 +25420,11 @@ ia32_multipass_dfa_lookahead (void)\n         return 4;\n \n     case PROCESSOR_CORE2:\n-    case PROCESSOR_COREI7:\n-    case PROCESSOR_COREI7_AVX:\n+    case PROCESSOR_NEHALEM:\n+    case PROCESSOR_SANDYBRIDGE:\n     case PROCESSOR_HASWELL:\n-    case PROCESSOR_ATOM:\n-    case PROCESSOR_SLM:\n+    case PROCESSOR_BONNELL:\n+    case PROCESSOR_SILVERMONT:\n       /* Generally, we want haifa-sched:max_issue() to look ahead as far\n \t as many instructions can be executed on a cycle, i.e.,\n \t issue_rate.  I wonder why tuning for many CPUs does not do this.  */\n@@ -25557,7 +25566,7 @@ do_reorder_for_imul (rtx *ready, int n_ready)\n   int index = -1;\n   int i;\n \n-  if (ix86_tune != PROCESSOR_ATOM)\n+  if (ix86_tune != PROCESSOR_BONNELL)\n     return index;\n \n   /* Check that IMUL instruction is on the top of ready list.  */\n@@ -25637,7 +25646,7 @@ swap_top_of_ready_list (rtx *ready, int n_ready)\n   int clock2 = -1;\n   #define INSN_TICK(INSN) (HID (INSN)->tick)\n \n-  if (ix86_tune != PROCESSOR_SLM)\n+  if (ix86_tune != PROCESSOR_SILVERMONT)\n     return false;\n \n   if (!NONDEBUG_INSN_P (top))\n@@ -25709,8 +25718,9 @@ ix86_sched_reorder (FILE *dump, int sched_verbose, rtx *ready, int *pn_ready,\n   /* Set up issue rate.  */\n   issue_rate = ix86_issue_rate ();\n \n-  /* Do reodering for Atom/SLM only.  */\n-  if (ix86_tune != PROCESSOR_ATOM && ix86_tune != PROCESSOR_SLM)\n+  /* Do reodering for BONNELL/SILVERMONT only.  */\n+  if (ix86_tune != PROCESSOR_BONNELL\n+      && ix86_tune != PROCESSOR_SILVERMONT)\n     return issue_rate;\n \n   /* Nothing to do if ready list contains only 1 instruction.  */\n@@ -26165,8 +26175,8 @@ ix86_sched_init_global (FILE *dump ATTRIBUTE_UNUSED,\n   switch (ix86_tune)\n     {\n     case PROCESSOR_CORE2:\n-    case PROCESSOR_COREI7:\n-    case PROCESSOR_COREI7_AVX:\n+    case PROCESSOR_NEHALEM:\n+    case PROCESSOR_SANDYBRIDGE:\n     case PROCESSOR_HASWELL:\n       /* Do not perform multipass scheduling for pre-reload schedule\n          to save compile time.  */\n@@ -30040,16 +30050,16 @@ get_builtin_code_for_version (tree decl, tree *predicate_list)\n \t      arg_str = \"core2\";\n \t      priority = P_PROC_SSSE3;\n \t      break;\n-\t    case PROCESSOR_COREI7:\n-\t      arg_str = \"corei7\";\n+\t    case PROCESSOR_NEHALEM:\n+\t      arg_str = \"nehalem\";\n \t      priority = P_PROC_SSE4_2;\n \t      break;\n-            case PROCESSOR_COREI7_AVX:\n-              arg_str = \"corei7-avx\";\n+            case PROCESSOR_SANDYBRIDGE:\n+              arg_str = \"sandybridge\";\n               priority = P_PROC_SSE4_2;\n               break;\n-\t    case PROCESSOR_ATOM:\n-\t      arg_str = \"atom\";\n+\t    case PROCESSOR_BONNELL:\n+\t      arg_str = \"bonnell\";\n \t      priority = P_PROC_SSSE3;\n \t      break;\n \t    case PROCESSOR_AMDFAM10:\n@@ -30939,12 +30949,12 @@ fold_builtin_cpu (tree fndecl, tree *args)\n     M_INTEL = 1,\n     M_AMD,\n     M_CPU_TYPE_START,\n-    M_INTEL_ATOM,\n+    M_INTEL_BONNELL,\n     M_INTEL_CORE2,\n     M_INTEL_COREI7,\n     M_AMDFAM10H,\n     M_AMDFAM15H,\n-    M_INTEL_SLM,\n+    M_INTEL_SILVERMONT,\n     M_CPU_SUBTYPE_START,\n     M_INTEL_COREI7_NEHALEM,\n     M_INTEL_COREI7_WESTMERE,\n@@ -30967,8 +30977,8 @@ fold_builtin_cpu (tree fndecl, tree *args)\n     {\n       {\"amd\", M_AMD},\n       {\"intel\", M_INTEL},\n-      {\"atom\", M_INTEL_ATOM},\n-      {\"slm\", M_INTEL_SLM},\n+      {\"atom\", M_INTEL_BONNELL},\n+      {\"slm\", M_INTEL_SILVERMONT},\n       {\"core2\", M_INTEL_CORE2},\n       {\"corei7\", M_INTEL_COREI7},\n       {\"nehalem\", M_INTEL_COREI7_NEHALEM},"}, {"sha": "aafc1accd6726296a1d214e79dc60345d2156009", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 17, "deletions": 9, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -301,9 +301,11 @@ extern const struct processor_costs ix86_size_cost;\n #define TARGET_ATHLON_K8 (TARGET_K8 || TARGET_ATHLON)\n #define TARGET_NOCONA (ix86_tune == PROCESSOR_NOCONA)\n #define TARGET_CORE2 (ix86_tune == PROCESSOR_CORE2)\n-#define TARGET_COREI7 (ix86_tune == PROCESSOR_COREI7)\n-#define TARGET_COREI7_AVX (ix86_tune == PROCESSOR_COREI7_AVX)\n+#define TARGET_NEHALEM (ix86_tune == PROCESSOR_NEHALEM)\n+#define TARGET_SANDYBRIDGE (ix86_tune == PROCESSOR_SANDYBRIDGE)\n #define TARGET_HASWELL (ix86_tune == PROCESSOR_HASWELL)\n+#define TARGET_BONNELL (ix86_tune == PROCESSOR_BONNELL)\n+#define TARGET_SILVERMONT (ix86_tune == PROCESSOR_SILVERMONT)\n #define TARGET_GENERIC (ix86_tune == PROCESSOR_GENERIC)\n #define TARGET_AMDFAM10 (ix86_tune == PROCESSOR_AMDFAM10)\n #define TARGET_BDVER1 (ix86_tune == PROCESSOR_BDVER1)\n@@ -312,8 +314,6 @@ extern const struct processor_costs ix86_size_cost;\n #define TARGET_BDVER4 (ix86_tune == PROCESSOR_BDVER4)\n #define TARGET_BTVER1 (ix86_tune == PROCESSOR_BTVER1)\n #define TARGET_BTVER2 (ix86_tune == PROCESSOR_BTVER2)\n-#define TARGET_ATOM (ix86_tune == PROCESSOR_ATOM)\n-#define TARGET_SLM (ix86_tune == PROCESSOR_SLM)\n \n /* Feature tests against the various tunings.  */\n enum ix86_tune_indices {\n@@ -625,9 +625,17 @@ enum target_cpu_default\n   TARGET_CPU_DEFAULT_core2,\n   TARGET_CPU_DEFAULT_corei7,\n   TARGET_CPU_DEFAULT_corei7_avx,\n-  TARGET_CPU_DEFAULT_haswell,\n+  TARGET_CPU_DEFAULT_core_avx2,\n   TARGET_CPU_DEFAULT_atom,\n   TARGET_CPU_DEFAULT_slm,\n+  TARGET_CPU_DEFAULT_nehalem,\n+  TARGET_CPU_DEFAULT_westmere,\n+  TARGET_CPU_DEFAULT_sandybridge,\n+  TARGET_CPU_DEFAULT_ivybridge,\n+  TARGET_CPU_DEFAULT_haswell,\n+  TARGET_CPU_DEFAULT_broadwell,\n+  TARGET_CPU_DEFAULT_bonnell,\n+  TARGET_CPU_DEFAULT_silvermont,\n   TARGET_CPU_DEFAULT_intel,\n \n   TARGET_CPU_DEFAULT_geode,\n@@ -2220,9 +2228,11 @@ enum processor_type\n   PROCESSOR_K8,\n   PROCESSOR_NOCONA,\n   PROCESSOR_CORE2,\n-  PROCESSOR_COREI7,\n-  PROCESSOR_COREI7_AVX,\n+  PROCESSOR_NEHALEM,\n+  PROCESSOR_SANDYBRIDGE,\n   PROCESSOR_HASWELL,\n+  PROCESSOR_BONNELL,\n+  PROCESSOR_SILVERMONT,\n   PROCESSOR_GENERIC,\n   PROCESSOR_AMDFAM10,\n   PROCESSOR_BDVER1,\n@@ -2231,8 +2241,6 @@ enum processor_type\n   PROCESSOR_BDVER4,\n   PROCESSOR_BTVER1,\n   PROCESSOR_BTVER2,\n-  PROCESSOR_ATOM,\n-  PROCESSOR_SLM,\n   PROCESSOR_max\n };\n "}, {"sha": "7a16c8ec1dff10b94fdb7d139e703ca3cefe32b5", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -354,7 +354,7 @@\n \n \f\n ;; Processor type.\n-(define_attr \"cpu\" \"none,pentium,pentiumpro,geode,k6,athlon,k8,core2,corei7,\n+(define_attr \"cpu\" \"none,pentium,pentiumpro,geode,k6,athlon,k8,core2,nehalem,\n \t\t    atom,slm,generic,amdfam10,bdver1,bdver2,bdver3,bdver4,\n \t\t    btver1,btver2\"\n   (const (symbol_ref \"ix86_schedule\")))"}, {"sha": "88e0402462bc19fbb10733a6ea1e8f96587192ff", "filename": "gcc/config/i386/x86-tune.def", "status": "modified", "additions": 42, "deletions": 42, "changes": 84, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fx86-tune.def?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -40,15 +40,15 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n \n /* X86_TUNE_SCHEDULE: Enable scheduling.  */\n DEF_TUNE (X86_TUNE_SCHEDULE, \"schedule\",\n-          m_PENT | m_PPRO | m_CORE_ALL | m_ATOM | m_SLM | m_K6_GEODE \n+          m_PENT | m_PPRO | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_K6_GEODE\n           | m_AMD_MULTIPLE | m_GENERIC)\n \n /* X86_TUNE_PARTIAL_REG_DEPENDENCY: Enable more register renaming\n    on modern chips.  Preffer stores affecting whole integer register\n    over partial stores.  For example preffer MOVZBL or MOVQ to load 8bit\n    value over movb.  */\n DEF_TUNE (X86_TUNE_PARTIAL_REG_DEPENDENCY, \"partial_reg_dependency\",\n-          m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_AMD_MULTIPLE \n+          m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_AMD_MULTIPLE\n           | m_GENERIC)\n \n /* X86_TUNE_SSE_PARTIAL_REG_DEPENDENCY: This knob promotes all store\n@@ -58,7 +58,7 @@ DEF_TUNE (X86_TUNE_PARTIAL_REG_DEPENDENCY, \"partial_reg_dependency\",\n    SPECfp regression, while enabling it on K8 brings roughly 2.4% regression\n    that can be partly masked by careful scheduling of moves.  */\n DEF_TUNE (X86_TUNE_SSE_PARTIAL_REG_DEPENDENCY, \"sse_partial_reg_dependency\",\n-          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_AMDFAM10 \n+          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_AMDFAM10\n           | m_BDVER | m_GENERIC)\n \n /* X86_TUNE_SSE_SPLIT_REGS: Set for machines where the type and dependencies\n@@ -84,13 +84,13 @@ DEF_TUNE (X86_TUNE_PARTIAL_FLAG_REG_STALL, \"partial_flag_reg_stall\",\n /* X86_TUNE_MOVX: Enable to zero extend integer registers to avoid\n    partial dependencies.  */\n DEF_TUNE (X86_TUNE_MOVX, \"movx\",\n-          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_GEODE \n+          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_GEODE\n           | m_AMD_MULTIPLE  | m_GENERIC)\n \n /* X86_TUNE_MEMORY_MISMATCH_STALL: Avoid partial stores that are followed by\n    full sized loads.  */\n DEF_TUNE (X86_TUNE_MEMORY_MISMATCH_STALL, \"memory_mismatch_stall\",\n-          m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_AMD_MULTIPLE | m_GENERIC)\n+          m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_AMD_MULTIPLE | m_GENERIC)\n \n /* X86_TUNE_FUSE_CMP_AND_BRANCH_32: Fuse compare with a subsequent\n    conditional jump instruction for 32 bit TARGET.\n@@ -102,29 +102,29 @@ DEF_TUNE (X86_TUNE_FUSE_CMP_AND_BRANCH_32, \"fuse_cmp_and_branch_32\",\n    conditional jump instruction for TARGET_64BIT.\n    FIXME: revisit for generic.  */\n DEF_TUNE (X86_TUNE_FUSE_CMP_AND_BRANCH_64, \"fuse_cmp_and_branch_64\",\n-          m_COREI7 | m_COREI7_AVX | m_HASWELL | m_BDVER)\n+          m_NEHALEM | m_SANDYBRIDGE | m_HASWELL | m_BDVER)\n \n /* X86_TUNE_FUSE_CMP_AND_BRANCH_SOFLAGS: Fuse compare with a\n    subsequent conditional jump instruction when the condition jump\n    check sign flag (SF) or overflow flag (OF).  */\n DEF_TUNE (X86_TUNE_FUSE_CMP_AND_BRANCH_SOFLAGS, \"fuse_cmp_and_branch_soflags\",\n-          m_COREI7 | m_COREI7_AVX | m_HASWELL | m_BDVER)\n+          m_NEHALEM | m_SANDYBRIDGE | m_HASWELL | m_BDVER)\n \n /* X86_TUNE_FUSE_ALU_AND_BRANCH: Fuse alu with a subsequent conditional\n    jump instruction when the alu instruction produces the CCFLAG consumed by\n    the conditional jump instruction. */\n DEF_TUNE (X86_TUNE_FUSE_ALU_AND_BRANCH, \"fuse_alu_and_branch\",\n-          m_COREI7_AVX | m_HASWELL)\n+          m_SANDYBRIDGE | m_HASWELL)\n \n /* X86_TUNE_REASSOC_INT_TO_PARALLEL: Try to produce parallel computations\n    during reassociation of integer computation.  */\n DEF_TUNE (X86_TUNE_REASSOC_INT_TO_PARALLEL, \"reassoc_int_to_parallel\",\n-          m_ATOM)\n+          m_BONNELL)\n \n /* X86_TUNE_REASSOC_FP_TO_PARALLEL: Try to produce parallel computations\n    during reassociation of fp computation.  */\n DEF_TUNE (X86_TUNE_REASSOC_FP_TO_PARALLEL, \"reassoc_fp_to_parallel\",\n-          m_ATOM | m_SLM | m_HASWELL | m_BDVER1 | m_BDVER2 | m_GENERIC)\n+          m_BONNELL | m_SILVERMONT | m_HASWELL | m_BDVER1 | m_BDVER2 | m_GENERIC)\n \n /*****************************************************************************/\n /* Function prologue, epilogue and function calling sequences.               */\n@@ -142,33 +142,33 @@ DEF_TUNE (X86_TUNE_REASSOC_FP_TO_PARALLEL, \"reassoc_fp_to_parallel\",\n    Bobcat and Generic.  This is because disabling it causes large\n    regression on mgrid due to IRA limitation leading to unecessary\n    use of the frame pointer in 32bit mode.  */\n-DEF_TUNE (X86_TUNE_ACCUMULATE_OUTGOING_ARGS, \"accumulate_outgoing_args\", \n-\t  m_PPRO | m_P4_NOCONA | m_ATOM | m_SLM | m_AMD_MULTIPLE | m_GENERIC)\n+DEF_TUNE (X86_TUNE_ACCUMULATE_OUTGOING_ARGS, \"accumulate_outgoing_args\",\n+\t  m_PPRO | m_P4_NOCONA | m_BONNELL | m_SILVERMONT | m_AMD_MULTIPLE | m_GENERIC)\n \n /* X86_TUNE_PROLOGUE_USING_MOVE: Do not use push/pop in prologues that are\n    considered on critical path.  */\n-DEF_TUNE (X86_TUNE_PROLOGUE_USING_MOVE, \"prologue_using_move\", \n+DEF_TUNE (X86_TUNE_PROLOGUE_USING_MOVE, \"prologue_using_move\",\n           m_PPRO | m_ATHLON_K8)\n \n /* X86_TUNE_PROLOGUE_USING_MOVE: Do not use push/pop in epilogues that are\n    considered on critical path.  */\n DEF_TUNE (X86_TUNE_EPILOGUE_USING_MOVE, \"epilogue_using_move\",\n-          m_PPRO | m_ATHLON_K8)\t\n+          m_PPRO | m_ATHLON_K8)\n \n /* X86_TUNE_USE_LEAVE: Use \"leave\" instruction in epilogues where it fits.  */\n-DEF_TUNE (X86_TUNE_USE_LEAVE, \"use_leave\", \n+DEF_TUNE (X86_TUNE_USE_LEAVE, \"use_leave\",\n \t  m_386 | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE | m_GENERIC)\n \n /* X86_TUNE_PUSH_MEMORY: Enable generation of \"push mem\" instructions.\n    Some chips, like 486 and Pentium works faster with separate load\n    and push instructions.  */\n-DEF_TUNE (X86_TUNE_PUSH_MEMORY, \"push_memory\", \n-          m_386 | m_P4_NOCONA | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE \n+DEF_TUNE (X86_TUNE_PUSH_MEMORY, \"push_memory\",\n+          m_386 | m_P4_NOCONA | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE\n           | m_GENERIC)\n \n /* X86_TUNE_SINGLE_PUSH: Enable if single push insn is preferred\n    over esp subtraction.  */\n-DEF_TUNE (X86_TUNE_SINGLE_PUSH, \"single_push\", m_386 | m_486 | m_PENT \n+DEF_TUNE (X86_TUNE_SINGLE_PUSH, \"single_push\", m_386 | m_486 | m_PENT\n           | m_K6_GEODE)\n \n /* X86_TUNE_DOUBLE_PUSH. Enable if double push insn is preferred\n@@ -189,7 +189,7 @@ DEF_TUNE (X86_TUNE_DOUBLE_POP, \"double_pop\", m_PENT)\n \n /* X86_TUNE_PAD_SHORT_FUNCTION: Make every function to be at least 4\n    instructions long.  */\n-DEF_TUNE (X86_TUNE_PAD_SHORT_FUNCTION, \"pad_short_function\", m_ATOM)\n+DEF_TUNE (X86_TUNE_PAD_SHORT_FUNCTION, \"pad_short_function\", m_BONNELL)\n \n /* X86_TUNE_PAD_RETURNS: Place NOP before every RET that is a destination\n    of conditional jump or directly preceded by other jump instruction.\n@@ -202,7 +202,7 @@ DEF_TUNE (X86_TUNE_PAD_RETURNS, \"pad_returns\",\n /* X86_TUNE_FOUR_JUMP_LIMIT: Some CPU cores are not able to predict more\n    than 4 branch instructions in the 16 byte window.  */\n DEF_TUNE (X86_TUNE_FOUR_JUMP_LIMIT, \"four_jump_limit\",\n-          m_PPRO | m_P4_NOCONA | m_ATOM | m_SLM | m_ATHLON_K8 | m_AMDFAM10)\n+          m_PPRO | m_P4_NOCONA | m_BONNELL | m_SILVERMONT | m_ATHLON_K8 | m_AMDFAM10)\n \n /*****************************************************************************/\n /* Integer instruction selection tuning                                      */\n@@ -224,34 +224,34 @@ DEF_TUNE (X86_TUNE_READ_MODIFY, \"read_modify\", ~(m_PENT | m_PPRO))\n \n /* X86_TUNE_USE_INCDEC: Enable use of inc/dec instructions.   */\n DEF_TUNE (X86_TUNE_USE_INCDEC, \"use_incdec\",\n-          ~(m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_GENERIC))\n+          ~(m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_GENERIC))\n \n /* X86_TUNE_INTEGER_DFMODE_MOVES: Enable if integer moves are preferred\n    for DFmode copies */\n DEF_TUNE (X86_TUNE_INTEGER_DFMODE_MOVES, \"integer_dfmode_moves\",\n-          ~(m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM \n+          ~(m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT\n           | m_GEODE | m_AMD_MULTIPLE | m_GENERIC))\n \n /* X86_TUNE_OPT_AGU: Optimize for Address Generation Unit. This flag\n    will impact LEA instruction selection. */\n-DEF_TUNE (X86_TUNE_OPT_AGU, \"opt_agu\", m_ATOM | m_SLM)\n+DEF_TUNE (X86_TUNE_OPT_AGU, \"opt_agu\", m_BONNELL | m_SILVERMONT)\n \n /* X86_TUNE_SLOW_IMUL_IMM32_MEM: Imul of 32-bit constant and memory is\n-   vector path on AMD machines. \n+   vector path on AMD machines.\n    FIXME: Do we need to enable this for core? */\n DEF_TUNE (X86_TUNE_SLOW_IMUL_IMM32_MEM, \"slow_imul_imm32_mem\",\n           m_K8 | m_AMDFAM10)\n \n /* X86_TUNE_SLOW_IMUL_IMM8: Imul of 8-bit constant is vector path on AMD\n-   machines. \n+   machines.\n    FIXME: Do we need to enable this for core? */\n DEF_TUNE (X86_TUNE_SLOW_IMUL_IMM8, \"slow_imul_imm8\",\n           m_K8 | m_AMDFAM10)\n \n /* X86_TUNE_AVOID_MEM_OPND_FOR_CMOVE: Try to avoid memory operands for\n    a conditional move.  */\n DEF_TUNE (X86_TUNE_AVOID_MEM_OPND_FOR_CMOVE, \"avoid_mem_opnd_for_cmove\",\n-\t  m_ATOM | m_SLM)\n+\t  m_BONNELL | m_SILVERMONT)\n \n /* X86_TUNE_SINGLE_STRINGOP: Enable use of single string operations, such\n    as MOVS and STOS (without a REP prefix) to move/set sequences of bytes.  */\n@@ -268,15 +268,15 @@ DEF_TUNE (X86_TUNE_MISALIGNED_MOVE_STRING_PRO_EPILOGUES,\n \n /* X86_TUNE_USE_SAHF: Controls use of SAHF.  */\n DEF_TUNE (X86_TUNE_USE_SAHF, \"use_sahf\",\n-          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_K6_GEODE\n+          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_K6_GEODE\n           | m_K8 | m_AMDFAM10 | m_BDVER | m_BTVER | m_GENERIC)\n \n /* X86_TUNE_USE_CLTD: Controls use of CLTD and CTQO instructions.  */\n-DEF_TUNE (X86_TUNE_USE_CLTD, \"use_cltd\", ~(m_PENT | m_ATOM | m_SLM | m_K6))\n+DEF_TUNE (X86_TUNE_USE_CLTD, \"use_cltd\", ~(m_PENT | m_BONNELL | m_SILVERMONT | m_K6))\n \n /* X86_TUNE_USE_BT: Enable use of BT (bit test) instructions.  */\n DEF_TUNE (X86_TUNE_USE_BT, \"use_bt\",\n-          m_CORE_ALL | m_ATOM | m_SLM | m_AMD_MULTIPLE | m_GENERIC)\n+          m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_AMD_MULTIPLE | m_GENERIC)\n \n /*****************************************************************************/\n /* 387 instruction selection tuning                                          */\n@@ -285,21 +285,21 @@ DEF_TUNE (X86_TUNE_USE_BT, \"use_bt\",\n /* X86_TUNE_USE_HIMODE_FIOP: Enables use of x87 instructions with 16bit\n    integer operand.\n    FIXME: Why this is disabled for modern chips?  */\n-DEF_TUNE (X86_TUNE_USE_HIMODE_FIOP, \"use_himode_fiop\", \n+DEF_TUNE (X86_TUNE_USE_HIMODE_FIOP, \"use_himode_fiop\",\n           m_386 | m_486 | m_K6_GEODE)\n \n /* X86_TUNE_USE_SIMODE_FIOP: Enables use of x87 instructions with 32bit\n    integer operand.  */\n DEF_TUNE (X86_TUNE_USE_SIMODE_FIOP, \"use_simode_fiop\",\n-          ~(m_PENT | m_PPRO | m_CORE_ALL | m_ATOM \n-            | m_SLM | m_AMD_MULTIPLE | m_GENERIC))\n+          ~(m_PENT | m_PPRO | m_CORE_ALL | m_BONNELL\n+            | m_SILVERMONT | m_AMD_MULTIPLE | m_GENERIC))\n \n /* X86_TUNE_USE_FFREEP: Use freep instruction instead of fstp.  */\n DEF_TUNE (X86_TUNE_USE_FFREEP, \"use_ffreep\", m_AMD_MULTIPLE)\n \n /* X86_TUNE_EXT_80387_CONSTANTS: Use fancy 80387 constants, such as PI.  */\n DEF_TUNE (X86_TUNE_EXT_80387_CONSTANTS, \"ext_80387_constants\",\n-          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_K6_GEODE\n+          m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_BONNELL | m_SILVERMONT | m_K6_GEODE\n           | m_ATHLON_K8 | m_GENERIC)\n \n /*****************************************************************************/\n@@ -308,7 +308,7 @@ DEF_TUNE (X86_TUNE_EXT_80387_CONSTANTS, \"ext_80387_constants\",\n \n /* X86_TUNE_VECTORIZE_DOUBLE: Enable double precision vector\n    instructions.  */\n-DEF_TUNE (X86_TUNE_VECTORIZE_DOUBLE, \"vectorize_double\", ~m_ATOM)\n+DEF_TUNE (X86_TUNE_VECTORIZE_DOUBLE, \"vectorize_double\", ~m_BONNELL)\n \n /* X86_TUNE_GENERAL_REGS_SSE_SPILL: Try to spill general regs to SSE\n    regs instead of memory.  */\n@@ -318,12 +318,12 @@ DEF_TUNE (X86_TUNE_GENERAL_REGS_SSE_SPILL, \"general_regs_sse_spill\",\n /* X86_TUNE_SSE_UNALIGNED_LOAD_OPTIMAL: Use movups for misaligned loads instead\n    of a sequence loading registers by parts.  */\n DEF_TUNE (X86_TUNE_SSE_UNALIGNED_LOAD_OPTIMAL, \"sse_unaligned_load_optimal\",\n-          m_COREI7 | m_COREI7_AVX | m_HASWELL | m_AMDFAM10 | m_BDVER | m_BTVER | m_SLM | m_GENERIC)\n+          m_NEHALEM | m_SANDYBRIDGE | m_HASWELL | m_AMDFAM10 | m_BDVER | m_BTVER | m_SILVERMONT | m_GENERIC)\n \n /* X86_TUNE_SSE_UNALIGNED_STORE_OPTIMAL: Use movups for misaligned stores instead\n    of a sequence loading registers by parts.  */\n DEF_TUNE (X86_TUNE_SSE_UNALIGNED_STORE_OPTIMAL, \"sse_unaligned_store_optimal\",\n-          m_COREI7 | m_COREI7_AVX | m_HASWELL | m_BDVER | m_SLM | m_GENERIC)\n+          m_NEHALEM | m_SANDYBRIDGE | m_HASWELL | m_BDVER | m_SILVERMONT | m_GENERIC)\n \n /* Use packed single precision instructions where posisble.  I.e. movups instead\n    of movupd.  */\n@@ -360,7 +360,7 @@ DEF_TUNE (X86_TUNE_INTER_UNIT_CONVERSIONS, \"inter_unit_conversions\",\n /* X86_TUNE_SPLIT_MEM_OPND_FOR_FP_CONVERTS: Try to split memory operand for\n    fp converts to destination register.  */\n DEF_TUNE (X86_TUNE_SPLIT_MEM_OPND_FOR_FP_CONVERTS, \"split_mem_opnd_for_fp_converts\",\n-          m_SLM)\n+          m_SILVERMONT)\n \n /* X86_TUNE_USE_VECTOR_FP_CONVERTS: Prefer vector packed SSE conversion\n    from FP to FP.  This form of instructions avoids partial write to the\n@@ -378,13 +378,13 @@ DEF_TUNE (X86_TUNE_USE_VECTOR_CONVERTS, \"use_vector_converts\", m_AMDFAM10)\n \n /* X86_TUNE_AVX256_UNALIGNED_LOAD_OPTIMAL: if false, unaligned loads are\n    split.  */\n-DEF_TUNE (X86_TUNE_AVX256_UNALIGNED_LOAD_OPTIMAL, \"256_unaligned_load_optimal\", \n-          ~(m_COREI7 | m_COREI7_AVX | m_GENERIC))\n+DEF_TUNE (X86_TUNE_AVX256_UNALIGNED_LOAD_OPTIMAL, \"256_unaligned_load_optimal\",\n+          ~(m_NEHALEM | m_SANDYBRIDGE | m_GENERIC))\n \n /* X86_TUNE_AVX256_UNALIGNED_STORE_OPTIMAL: if false, unaligned stores are\n    split.  */\n-DEF_TUNE (X86_TUNE_AVX256_UNALIGNED_STORE_OPTIMAL, \"256_unaligned_store_optimal\", \n-          ~(m_COREI7 | m_COREI7_AVX | m_BDVER | m_GENERIC))\n+DEF_TUNE (X86_TUNE_AVX256_UNALIGNED_STORE_OPTIMAL, \"256_unaligned_store_optimal\",\n+          ~(m_NEHALEM | m_SANDYBRIDGE | m_BDVER | m_GENERIC))\n \n /* X86_TUNE_AVX128_OPTIMAL: Enable 128-bit AVX instruction generation for\n    the auto-vectorizer.  */\n@@ -401,7 +401,7 @@ DEF_TUNE (X86_TUNE_DOUBLE_WITH_ADD, \"double_with_add\", ~m_386)\n /* X86_TUNE_ALWAYS_FANCY_MATH_387: controls use of fancy 387 operations,\n    such as fsqrt, fprem, fsin, fcos, fsincos etc.\n    Should be enabled for all targets that always has coprocesor.  */\n-DEF_TUNE (X86_TUNE_ALWAYS_FANCY_MATH_387, \"always_fancy_math_387\", \n+DEF_TUNE (X86_TUNE_ALWAYS_FANCY_MATH_387, \"always_fancy_math_387\",\n           ~(m_386 | m_486))\n \n /* X86_TUNE_UNROLL_STRLEN: Produce (quite lame) unrolled sequence for"}, {"sha": "a10b6f567452188447c5b6966fdc465637431b98", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 16, "deletions": 12, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -14648,34 +14648,38 @@ SSE2 and SSE3 instruction set support.\n Intel Core 2 CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3 and SSSE3\n instruction set support.\n \n-@item corei7\n-Intel Core i7 CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3,\n+@item nehalem\n+Intel Nehalem CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3,\n SSE4.1, SSE4.2 and POPCNT instruction set support.\n \n-@item corei7-avx\n-Intel Core i7 CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3,\n+@item westmere\n+Intel Westmere CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3,\n+SSE4.1, SSE4.2, POPCNT, AES and PCLMUL instruction set support.\n+\n+@item sandybridge\n+Intel Sandy Bridge CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3,\n SSE4.1, SSE4.2, POPCNT, AVX, AES and PCLMUL instruction set support.\n \n-@item core-avx-i\n-Intel Core CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3,\n+@item ivybridge\n+Intel Ivy Bridge CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3,\n SSE4.1, SSE4.2, POPCNT, AVX, AES, PCLMUL, FSGSBASE, RDRND and F16C\n instruction set support.\n \n-@item core-avx2\n-Intel Core CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3,\n+@item haswell\n+Intel Haswell CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3,\n SSE4.1, SSE4.2, POPCNT, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA,\n BMI, BMI2 and F16C instruction set support.\n \n @item broadwell\n Intel Broadwell CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3,\n SSE4.1, SSE4.2, POPCNT, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA,\n-BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW instruction set support.\n+BMI, BMI2, F16C, RDSEED, ADCX and PREFETCHW instruction set support.\n \n-@item atom\n-Intel Atom CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3 and SSSE3\n+@item bonnell\n+Intel Bonnell CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3 and SSSE3\n instruction set support.\n \n-@item slm\n+@item silvermont\n Intel Silvermont CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3,\n SSE4.1, SSE4.2, POPCNT, AES, PCLMUL and RDRND instruction set support.\n "}, {"sha": "139841fcf0bcbc0fb7b4a09a8250366356e6e519", "filename": "libgcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/libgcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/libgcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2FChangeLog?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -1,3 +1,9 @@\n+2013-12-23   H.J. Lu  <hongjiu.lu@intel.com>\n+\n+\t* config/i386/cpuinfo.c (processor_subtypes): Replace INTEL_ATOM,\n+\tINTEL_SLM with INTEL_BONNELL, INTEL_SILVERMONT.\n+\t(get_intel_cpu): Updated.\n+\n 2013-12-12  Zhenqiang Chen  <zhenqiang.chen@arm.com>\n \n \t* config.host (arm*-*-uclinux*): Move t-arm before t-bpabi."}, {"sha": "4b0c189bb644a885690631a9a90bd9c1ced3f0a6", "filename": "libgcc/config/i386/cpuinfo.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3c11974032e21121a051d423a1d71097edf752f/libgcc%2Fconfig%2Fi386%2Fcpuinfo.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3c11974032e21121a051d423a1d71097edf752f/libgcc%2Fconfig%2Fi386%2Fcpuinfo.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Fi386%2Fcpuinfo.c?ref=d3c11974032e21121a051d423a1d71097edf752f", "patch": "@@ -56,12 +56,12 @@ enum processor_vendor\n \n enum processor_types\n {\n-  INTEL_ATOM = 1,\n+  INTEL_BONNELL = 1,\n   INTEL_CORE2,\n   INTEL_COREI7,\n   AMDFAM10H,\n   AMDFAM15H,\n-  INTEL_SLM,\n+  INTEL_SILVERMONT,\n   CPU_TYPE_MAX\n };\n \n@@ -167,13 +167,13 @@ get_intel_cpu (unsigned int family, unsigned int model, unsigned int brand_id)\n \t    {\n \t    case 0x1c:\n \t    case 0x26:\n-\t      /* Atom.  */\n-\t      __cpu_model.__cpu_type = INTEL_ATOM;\n+\t      /* Bonnell.  */\n+\t      __cpu_model.__cpu_type = INTEL_BONNELL;\n \t      break;\n \t    case 0x37:\n \t    case 0x4d:\n \t      /* Silvermont.  */\n-\t      __cpu_model.__cpu_type = INTEL_SLM;\n+\t      __cpu_model.__cpu_type = INTEL_SILVERMONT;\n \t      break;\n \t    case 0x1a:\n \t    case 0x1e:"}]}