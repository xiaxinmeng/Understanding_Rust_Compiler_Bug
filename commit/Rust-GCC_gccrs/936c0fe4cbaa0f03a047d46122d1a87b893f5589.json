{"sha": "936c0fe4cbaa0f03a047d46122d1a87b893f5589", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTM2YzBmZTRjYmFhMGYwM2EwNDdkNDYxMjJkMWE4N2I4OTNmNTU4OQ==", "commit": {"author": {"name": "Alexander Ivchenko", "email": "alexander.ivchenko@intel.com", "date": "2014-10-28T14:11:00Z"}, "committer": {"name": "Kirill Yukhin", "email": "kyukhin@gcc.gnu.org", "date": "2014-10-28T14:11:00Z"}, "message": "AVX-512. 85/n. Add intrinsics headers.\n\ngcc/\n\t* config/i386/avx512bwintrin.h: New.\n\t* config/i386/avx512dqintrin.h: Ditto.\n\t* config/i386/avx512vlbwintrin.h: Ditto.\n\t* config/i386/avx512vldqintrin.h: Ditto.\n\t* config/i386/avx512vlintrin.h: Ditto.\n\t* config/i386/immintrin.h: Include avx512vlintrin.h, avx512bwintrin.h,\n\tavx512dqintrin.h, avx512vlbwintrin.h, avx512vldqintrin.h.\n\nCo-Authored-By: Andrey Turetskiy <andrey.turetskiy@intel.com>\nCo-Authored-By: Anna Tikhonova <anna.tikhonova@intel.com>\nCo-Authored-By: Ilya Tocar <ilya.tocar@intel.com>\nCo-Authored-By: Ilya Verbin <ilya.verbin@intel.com>\nCo-Authored-By: Kirill Yukhin <kirill.yukhin@intel.com>\nCo-Authored-By: Maxim Kuznetsov <maxim.kuznetsov@intel.com>\nCo-Authored-By: Michael Zolotukhin <michael.v.zolotukhin@intel.com>\n\nFrom-SVN: r216798", "tree": {"sha": "ec0a41fe5f9713534ff38c018ae34df5b4277522", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ec0a41fe5f9713534ff38c018ae34df5b4277522"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/936c0fe4cbaa0f03a047d46122d1a87b893f5589", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/936c0fe4cbaa0f03a047d46122d1a87b893f5589", "html_url": "https://github.com/Rust-GCC/gccrs/commit/936c0fe4cbaa0f03a047d46122d1a87b893f5589", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/936c0fe4cbaa0f03a047d46122d1a87b893f5589/comments", "author": null, "committer": null, "parents": [{"sha": "a40be84c87e346b41c6086a11fc8ccf74e011687", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a40be84c87e346b41c6086a11fc8ccf74e011687", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a40be84c87e346b41c6086a11fc8ccf74e011687"}], "stats": {"total": 24452, "additions": 24450, "deletions": 2}, "files": [{"sha": "64ed03b87b27cad243637db4f22bbe61fc0fc2b6", "filename": "gcc/ChangeLog", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589", "patch": "@@ -1,3 +1,20 @@\n+2014-10-28  Alexander Ivchenko  <alexander.ivchenko@intel.com>\n+\t    Maxim Kuznetsov  <maxim.kuznetsov@intel.com>\n+\t    Anna Tikhonova  <anna.tikhonova@intel.com>\n+\t    Ilya Tocar  <ilya.tocar@intel.com>\n+\t    Andrey Turetskiy  <andrey.turetskiy@intel.com>\n+\t    Ilya Verbin  <ilya.verbin@intel.com>\n+\t    Kirill Yukhin  <kirill.yukhin@intel.com>\n+\t    Michael Zolotukhin  <michael.v.zolotukhin@intel.com>\n+\n+\t* config/i386/avx512bwintrin.h: New.\n+\t* config/i386/avx512dqintrin.h: Ditto.\n+\t* config/i386/avx512vlbwintrin.h: Ditto.\n+\t* config/i386/avx512vldqintrin.h: Ditto.\n+\t* config/i386/avx512vlintrin.h: Ditto.\n+\t* config/i386/immintrin.h: Include avx512vlintrin.h, avx512bwintrin.h,\n+\tavx512dqintrin.h, avx512vlbwintrin.h, avx512vldqintrin.h.\n+\n 2014-10-28  Alexander Ivchenko  <alexander.ivchenko@intel.com>\n \t    Maxim Kuznetsov  <maxim.kuznetsov@intel.com>\n \t    Anna Tikhonova  <anna.tikhonova@intel.com>"}, {"sha": "137373ff552b1f04a087738a89e75b8606c60f79", "filename": "gcc/config.gcc", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589", "patch": "@@ -364,7 +364,8 @@ i[34567]86-*-*)\n \t\t       adxintrin.h fxsrintrin.h xsaveintrin.h xsaveoptintrin.h\n \t\t       avx512cdintrin.h avx512erintrin.h avx512pfintrin.h\n \t\t       shaintrin.h clflushoptintrin.h xsavecintrin.h\n-\t\t       xsavesintrin.h\"\n+\t\t       xsavesintrin.h avx512dqintrin.h avx512bwintrin.h\n+\t\t       avx512vlintrin.h avx512vlbwintrin.h avx512vldqintrin.h\"\n \t;;\n x86_64-*-*)\n \tcpu_type=i386\n@@ -382,7 +383,8 @@ x86_64-*-*)\n \t\t       adxintrin.h fxsrintrin.h xsaveintrin.h xsaveoptintrin.h\n \t\t       avx512cdintrin.h avx512erintrin.h avx512pfintrin.h\n \t\t       shaintrin.h clflushoptintrin.h xsavecintrin.h\n-\t\t       xsavesintrin.h\"\n+\t\t       xsavesintrin.h avx512dqintrin.h avx512bwintrin.h\n+\t\t       avx512vlintrin.h avx512vlbwintrin.h avx512vldqintrin.h\"\n \t;;\n ia64-*-*)\n \textra_headers=ia64intrin.h"}, {"sha": "47b3f50749f3d7657d2df8a63bbab3e526b210bc", "filename": "gcc/config/i386/avx512bwintrin.h", "status": "added", "additions": 2656, "deletions": 0, "changes": 2656, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512bwintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512bwintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512bwintrin.h?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589", "patch": "@@ -0,0 +1,2656 @@\n+/* Copyright (C) 2014\n+   Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify\n+   it under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   Under Section 7 of GPL version 3, you are granted additional\n+   permissions described in the GCC Runtime Library Exception, version\n+   3.1, as published by the Free Software Foundation.\n+\n+   You should have received a copy of the GNU General Public License and\n+   a copy of the GCC Runtime Library Exception along with this program;\n+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#ifndef _IMMINTRIN_H_INCLUDED\n+#error \"Never use <avx512bwintrin.h> directly; include <immintrin.h> instead.\"\n+#endif\n+\n+#ifndef _AVX512BWINTRIN_H_INCLUDED\n+#define _AVX512BWINTRIN_H_INCLUDED\n+\n+#ifndef __AVX512BW__\n+#pragma GCC push_options\n+#pragma GCC target(\"avx512bw\")\n+#define __DISABLE_AVX512BW__\n+#endif /* __AVX512BW__ */\n+\n+/* Internal data types for implementing the intrinsics.  */\n+typedef short __v32hi __attribute__ ((__vector_size__ (64)));\n+typedef char __v64qi __attribute__ ((__vector_size__ (64)));\n+\n+typedef unsigned long long __mmask64;\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_setzero_qi (void)\n+{\n+  return __extension__ (__m512i)(__v64qi){ 0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0 };\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_setzero_hi (void)\n+{\n+  return __extension__ (__m512i)(__v32hi){ 0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t\t   0, 0, 0, 0, 0, 0, 0, 0 };\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_mov_epi16 (__m512i __W, __mmask32 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_movdquhi512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_mov_epi16 (__mmask32 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_movdquhi512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_loadu_epi16 (__m512i __W, __mmask32 __U, void const *__P)\n+{\n+  return (__m512i) __builtin_ia32_loaddquhi512_mask ((__v32hi *) __P,\n+\t\t\t\t\t\t     (__v32hi) __W,\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_loadu_epi16 (__mmask32 __U, void const *__P)\n+{\n+  return (__m512i) __builtin_ia32_loaddquhi512_mask ((__v32hi *) __P,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi (),\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline void\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_storeu_epi16 (void *__P, __mmask32 __U, __m512i __A)\n+{\n+  __builtin_ia32_storedquhi512_mask ((__v32hi *) __P,\n+\t\t\t\t     (__v32hi) __A,\n+\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_mov_epi8 (__m512i __W, __mmask64 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_movdquqi512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t    (__v64qi) __W,\n+\t\t\t\t\t\t    (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_mov_epi8 (__mmask64 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_movdquqi512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t    (__v64qi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask64) __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_kunpackw (__mmask32 __A, __mmask32 __B)\n+{\n+  return (__mmask32) __builtin_ia32_kunpcksi ((__mmask32) __A,\n+\t\t\t\t\t      (__mmask32) __B);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_kunpackd (__mmask64 __A, __mmask64 __B)\n+{\n+  return (__mmask64) __builtin_ia32_kunpckdi ((__mmask64) __A,\n+\t\t\t\t\t      (__mmask64) __B);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_loadu_epi8 (__m512i __W, __mmask64 __U, void const *__P)\n+{\n+  return (__m512i) __builtin_ia32_loaddquqi512_mask ((__v64qi *) __P,\n+\t\t\t\t\t\t     (__v64qi) __W,\n+\t\t\t\t\t\t     (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_loadu_epi8 (__mmask64 __U, void const *__P)\n+{\n+  return (__m512i) __builtin_ia32_loaddquqi512_mask ((__v64qi *) __P,\n+\t\t\t\t\t\t     (__v64qi)\n+\t\t\t\t\t\t     _mm512_setzero_hi (),\n+\t\t\t\t\t\t     (__mmask64) __U);\n+}\n+\n+extern __inline void\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_storeu_epi8 (void *__P, __mmask64 __U, __m512i __A)\n+{\n+  __builtin_ia32_storedquqi512_mask ((__v64qi *) __P,\n+\t\t\t\t     (__v64qi) __A,\n+\t\t\t\t     (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_sad_epu8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psadbw512 ((__v64qi) __A,\n+\t\t\t\t\t     (__v64qi) __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtepi16_epi8 (__m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32qi) _mm256_undefined_si256(),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32qi) __O, __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtepi16_epi8 (__mmask32 __M, __m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32qi)\n+\t\t\t\t\t\t  _mm256_setzero_si256 (),\n+\t\t\t\t\t\t  __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtsepi16_epi8 (__m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32qi)_mm256_undefined_si256(),\n+\t\t\t\t\t\t   (__mmask32) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtsepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32qi)__O,\n+\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtsepi16_epi8 (__mmask32 __M, __m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32qi)\n+\t\t\t\t\t\t   _mm256_setzero_si256 (),\n+\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtusepi16_epi8 (__m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32qi)_mm256_undefined_si256(),\n+\t\t\t\t\t\t    (__mmask32) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtusepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32qi) __O,\n+\t\t\t\t\t\t    __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtusepi16_epi8 (__mmask32 __M, __m512i __A)\n+{\n+  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32qi)\n+\t\t\t\t\t\t    _mm256_setzero_si256 (),\n+\t\t\t\t\t\t    __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcastb_epi8 (__m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,\n+\t\t\t\t\t\t       (__v64qi)_mm512_undefined_si512(),\n+\t\t\t\t\t\t       (__mmask64) -\n+\t\t\t\t\t\t       1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcastb_epi8 (__m512i __O, __mmask64 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,\n+\t\t\t\t\t\t       (__v64qi) __O,\n+\t\t\t\t\t\t       __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcastb_epi8 (__mmask64 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,\n+\t\t\t\t\t\t       (__v64qi)\n+\t\t\t\t\t\t       _mm512_setzero_qi(),\n+\t\t\t\t\t\t       __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_set1_epi8 (__m512i __O, __mmask64 __M, char __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastb512_gpr_mask (__A,\n+\t\t\t\t\t\t\t   (__v64qi) __O,\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_set1_epi8 (__mmask64 __M, char __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastb512_gpr_mask (__A,\n+\t\t\t\t\t\t\t   (__v64qi)\n+\t\t\t\t\t\t\t   _mm512_setzero_qi(),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcastw_epi16 (__m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,\n+\t\t\t\t\t\t       (__v32hi)_mm512_undefined_si512(),\n+\t\t\t\t\t\t       (__mmask32)-1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcastw_epi16 (__m512i __O, __mmask32 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,\n+\t\t\t\t\t\t       (__v32hi) __O,\n+\t\t\t\t\t\t       __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcastw_epi16 (__mmask32 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,\n+\t\t\t\t\t\t       (__v32hi)\n+\t\t\t\t\t\t       _mm512_setzero_hi(),\n+\t\t\t\t\t\t       __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_set1_epi16 (__m512i __O, __mmask32 __M, short __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastw512_gpr_mask (__A,\n+\t\t\t\t\t\t\t   (__v32hi) __O,\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_set1_epi16 (__mmask32 __M, short __A)\n+{\n+  return (__m512i) __builtin_ia32_pbroadcastw512_gpr_mask (__A,\n+\t\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t\t   _mm512_setzero_hi(),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mulhrs_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_mulhrs_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t  __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_mulhrs_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mulhi_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_mulhi_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_mulhi_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mulhi_epu16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_mulhi_epu16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi) __W,\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_mulhi_epu16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mullo_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmullw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_mullo_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmullw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_mullo_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmullw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtepi8_epi16 (__m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtepi8_epi16 (__m512i __W, __mmask32 __U, __m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtepi8_epi16 (__mmask32 __U, __m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi(),\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtepu8_epi16 (__m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtepu8_epi16 (__m512i __W, __mmask32 __U, __m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtepu8_epi16 (__mmask32 __U, __m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi(),\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_permutexvar_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi (),\n+\t\t\t\t\t\t     (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_permutexvar_epi16 (__mmask32 __M, __m512i __A,\n+\t\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi(),\n+\t\t\t\t\t\t     (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_permutexvar_epi16 (__m512i __W, __mmask32 __M, __m512i __A,\n+\t\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __W,\n+\t\t\t\t\t\t     (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_permutex2var_epi16 (__m512i __A, __m512i __I, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_vpermt2varhi512_mask ((__v32hi) __I\n+\t\t\t\t\t\t\t/* idx */ ,\n+\t\t\t\t\t\t\t(__v32hi) __A,\n+\t\t\t\t\t\t\t(__v32hi) __B,\n+\t\t\t\t\t\t\t(__mmask32) -\n+\t\t\t\t\t\t\t1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_permutex2var_epi16 (__m512i __A, __mmask32 __U,\n+\t\t\t\t__m512i __I, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_vpermt2varhi512_mask ((__v32hi) __I\n+\t\t\t\t\t\t\t/* idx */ ,\n+\t\t\t\t\t\t\t(__v32hi) __A,\n+\t\t\t\t\t\t\t(__v32hi) __B,\n+\t\t\t\t\t\t\t(__mmask32)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask2_permutex2var_epi16 (__m512i __A, __m512i __I,\n+\t\t\t\t __mmask32 __U, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_vpermi2varhi512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t\t(__v32hi) __I\n+\t\t\t\t\t\t\t/* idx */ ,\n+\t\t\t\t\t\t\t(__v32hi) __B,\n+\t\t\t\t\t\t\t(__mmask32)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_permutex2var_epi16 (__mmask32 __U, __m512i __A,\n+\t\t\t\t __m512i __I, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_vpermt2varhi512_maskz ((__v32hi) __I\n+\t\t\t\t\t\t\t /* idx */ ,\n+\t\t\t\t\t\t\t (__v32hi) __A,\n+\t\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t\t (__mmask32)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_avg_epu8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi (),\n+\t\t\t\t\t\t (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_avg_epu8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t      __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi) __W,\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_avg_epu8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi(),\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_add_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi (),\n+\t\t\t\t\t\t (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_add_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t      __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi) __W,\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_add_epi8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi (),\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_sub_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi (),\n+\t\t\t\t\t\t (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_sub_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t      __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi) __W,\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_sub_epi8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi (),\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_avg_epu16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_avg_epu16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi) __W,\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_avg_epu16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi(),\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_subs_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_subs_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi) __W,\n+\t\t\t\t\t\t  (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_subs_epi8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_subs_epu8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t   (__v64qi) __B,\n+\t\t\t\t\t\t   (__v64qi)\n+\t\t\t\t\t\t   _mm512_setzero_qi (),\n+\t\t\t\t\t\t   (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_subs_epu8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t   (__v64qi) __B,\n+\t\t\t\t\t\t   (__v64qi) __W,\n+\t\t\t\t\t\t   (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_subs_epu8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t   (__v64qi) __B,\n+\t\t\t\t\t\t   (__v64qi)\n+\t\t\t\t\t\t   _mm512_setzero_qi (),\n+\t\t\t\t\t\t   (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_adds_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_adds_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi) __W,\n+\t\t\t\t\t\t  (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_adds_epi8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_adds_epu8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t   (__v64qi) __B,\n+\t\t\t\t\t\t   (__v64qi)\n+\t\t\t\t\t\t   _mm512_setzero_qi (),\n+\t\t\t\t\t\t   (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_adds_epu8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t   (__v64qi) __B,\n+\t\t\t\t\t\t   (__v64qi) __W,\n+\t\t\t\t\t\t   (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_adds_epu8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t   (__v64qi) __B,\n+\t\t\t\t\t\t   (__v64qi)\n+\t\t\t\t\t\t   _mm512_setzero_qi (),\n+\t\t\t\t\t\t   (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_sub_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_sub_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi) __W,\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_sub_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_subs_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_subs_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_subs_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_subs_epu16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_subs_epu16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi) __W,\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_subs_epu16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_add_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_add_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi) __W,\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_add_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_adds_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_adds_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_adds_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_adds_epu16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_adds_epu16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi) __W,\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_adds_epu16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_srl_epi16 (__m512i __A, __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_srl_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t       __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi) __W,\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_srl_epi16 (__mmask32 __U, __m512i __A, __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_packs_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v64qi)\n+\t\t\t\t\t\t    _mm512_setzero_qi (),\n+\t\t\t\t\t\t    (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_sll_epi16 (__m512i __A, __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_sll_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t       __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi) __W,\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_sll_epi16 (__mmask32 __U, __m512i __A, __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maddubs_epi16 (__m512i __X, __m512i __Y)\n+{\n+  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,\n+\t\t\t\t\t\t     (__v64qi) __Y,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi (),\n+\t\t\t\t\t\t     (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_maddubs_epi16 (__m512i __W, __mmask32 __U, __m512i __X,\n+\t\t\t   __m512i __Y)\n+{\n+  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,\n+\t\t\t\t\t\t     (__v64qi) __Y,\n+\t\t\t\t\t\t     (__v32hi) __W,\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_maddubs_epi16 (__mmask32 __U, __m512i __X, __m512i __Y)\n+{\n+  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,\n+\t\t\t\t\t\t     (__v64qi) __Y,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi (),\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_madd_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v16si)\n+\t\t\t\t\t\t   _mm512_setzero_si512 (),\n+\t\t\t\t\t\t   (__mmask16) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_madd_epi16 (__m512i __W, __mmask16 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v16si) __W,\n+\t\t\t\t\t\t   (__mmask16) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_madd_epi16 (__mmask16 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   (__v32hi) __B,\n+\t\t\t\t\t\t   (__v16si)\n+\t\t\t\t\t\t   _mm512_setzero_si512 (),\n+\t\t\t\t\t\t   (__mmask16) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_unpackhi_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__v64qi)\n+\t\t\t\t\t\t     _mm512_setzero_qi (),\n+\t\t\t\t\t\t     (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_unpackhi_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t\t   __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__v64qi) __W,\n+\t\t\t\t\t\t     (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_unpackhi_epi8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__v64qi)\n+\t\t\t\t\t\t     _mm512_setzero_qi(),\n+\t\t\t\t\t\t     (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_unpackhi_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi (),\n+\t\t\t\t\t\t     (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_unpackhi_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t    __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi) __W,\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_unpackhi_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi(),\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_unpacklo_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__v64qi)\n+\t\t\t\t\t\t     _mm512_setzero_qi (),\n+\t\t\t\t\t\t     (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_unpacklo_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t\t   __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__v64qi) __W,\n+\t\t\t\t\t\t     (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_unpacklo_epi8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__v64qi)\n+\t\t\t\t\t\t     _mm512_setzero_qi(),\n+\t\t\t\t\t\t     (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_unpacklo_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi (),\n+\t\t\t\t\t\t     (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_unpacklo_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t    __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi) __W,\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_unpacklo_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__v32hi)\n+\t\t\t\t\t\t     _mm512_setzero_hi(),\n+\t\t\t\t\t\t     (__mmask32) __U);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmpeq_epi8_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_pcmpeqb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__mmask64) -1);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmpeq_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_pcmpeqb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmpeq_epi16_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_pcmpeqw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__mmask32) -1);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmpeq_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_pcmpeqw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     __U);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmpgt_epi8_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_pcmpgtb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     (__mmask64) -1);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmpgt_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_pcmpgtb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t     (__v64qi) __B,\n+\t\t\t\t\t\t     __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmpgt_epi16_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_pcmpgtw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     (__mmask32) -1);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmpgt_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_pcmpgtw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t     (__v32hi) __B,\n+\t\t\t\t\t\t     __U);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movepi8_mask (__m512i __A)\n+{\n+  return (__mmask64) __builtin_ia32_cvtb2mask512 ((__v64qi) __A);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movepi16_mask (__m512i __A)\n+{\n+  return (__mmask32) __builtin_ia32_cvtw2mask512 ((__v32hi) __A);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movm_epi8 (__mmask64 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtmask2b512 (__A);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movm_epi16 (__mmask32 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtmask2w512 (__A);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_test_epi8_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_ptestmb512 ((__v64qi) __A,\n+\t\t\t\t\t\t(__v64qi) __B,\n+\t\t\t\t\t\t(__mmask64) -1);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_test_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_ptestmb512 ((__v64qi) __A,\n+\t\t\t\t\t\t(__v64qi) __B, __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_test_epi16_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_ptestmw512 ((__v32hi) __A,\n+\t\t\t\t\t\t(__v32hi) __B,\n+\t\t\t\t\t\t(__mmask32) -1);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_test_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_ptestmw512 ((__v32hi) __A,\n+\t\t\t\t\t\t(__v32hi) __B, __U);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_testn_epi8_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_ptestnmb512 ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B,\n+\t\t\t\t\t\t (__mmask64) -1);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_testn_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask64) __builtin_ia32_ptestnmb512 ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __B, __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_testn_epi16_mask (__m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_ptestnmw512 ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B,\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_testn_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__mmask32) __builtin_ia32_ptestnmw512 ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __B, __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_shuffle_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_shuffle_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t\t  __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi) __W,\n+\t\t\t\t\t\t  (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_shuffle_epi8 (__mmask64 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_min_epu16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_min_epu16 (__mmask32 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi(),\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_min_epu16 (__m512i __W, __mmask32 __M, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_min_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_min_epi16 (__mmask32 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi(),\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_min_epi16 (__m512i __W, __mmask32 __M, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_max_epu8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_max_epu8 (__mmask64 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi(),\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_max_epu8 (__m512i __W, __mmask64 __M, __m512i __A,\n+\t\t      __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi) __W,\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_max_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_max_epi8 (__mmask64 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi(),\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_max_epi8 (__m512i __W, __mmask64 __M, __m512i __A,\n+\t\t      __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi) __W,\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_min_epu8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_min_epu8 (__mmask64 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi(),\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_min_epu8 (__m512i __W, __mmask64 __M, __m512i __A,\n+\t\t      __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi) __W,\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_min_epi8 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi (),\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_min_epi8 (__mmask64 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi)\n+\t\t\t\t\t\t  _mm512_setzero_qi(),\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_min_epi8 (__m512i __W, __mmask64 __M, __m512i __A,\n+\t\t      __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t  (__v64qi) __B,\n+\t\t\t\t\t\t  (__v64qi) __W,\n+\t\t\t\t\t\t  (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_max_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_max_epi16 (__mmask32 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi(),\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_max_epi16 (__m512i __W, __mmask32 __M, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_max_epu16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_max_epu16 (__mmask32 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi(),\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_max_epu16 (__m512i __W, __mmask32 __M, __m512i __A,\n+\t\t       __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_sra_epi16 (__m512i __A, __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_sra_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t       __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi) __W,\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_sra_epi16 (__mmask32 __U, __m512i __A, __m128i __B)\n+{\n+  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v8hi) __B,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_srav_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_srav_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_srav_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_srlv_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_srlv_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_srlv_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_sllv_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_sllv_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_sllv_epi16 (__mmask32 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,\n+\t\t\t\t\t\t  (__v32hi) __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_packs_epi16 (__m512i __W, __mmask64 __M, __m512i __A,\n+\t\t\t __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v64qi) __W,\n+\t\t\t\t\t\t    (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_packs_epi16 (__mmask64 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v64qi)\n+\t\t\t\t\t\t    _mm512_setzero_qi(),\n+\t\t\t\t\t\t    __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_packus_epi16 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v64qi)\n+\t\t\t\t\t\t    _mm512_setzero_qi (),\n+\t\t\t\t\t\t    (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_packus_epi16 (__m512i __W, __mmask64 __M, __m512i __A,\n+\t\t\t  __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v64qi) __W,\n+\t\t\t\t\t\t    (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_packus_epi16 (__mmask64 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __B,\n+\t\t\t\t\t\t    (__v64qi)\n+\t\t\t\t\t\t    _mm512_setzero_qi(),\n+\t\t\t\t\t\t    (__mmask64) __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_abs_epi8 (__m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi (),\n+\t\t\t\t\t\t (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_abs_epi8 (__m512i __W, __mmask64 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi) __W,\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_abs_epi8 (__mmask64 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t (__v64qi)\n+\t\t\t\t\t\t _mm512_setzero_qi (),\n+\t\t\t\t\t\t (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_abs_epi16 (__m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_abs_epi16 (__m512i __W, __mmask32 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi) __W,\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_abs_epi16 (__mmask32 __U, __m512i __A)\n+{\n+  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t (__v32hi)\n+\t\t\t\t\t\t _mm512_setzero_hi (),\n+\t\t\t\t\t\t (__mmask32) __U);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_alignr_epi8 (__m512i __A, __m512i __B, const int __N)\n+{\n+  return (__m512i) __builtin_ia32_palignr512 ((__v8di) __A,\n+\t\t\t\t\t      (__v8di) __B, __N * 8);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_alignr_epi8 (__m512i __W, __mmask64 __U, __m512i __A,\n+\t\t\t __m512i __B, const int __N)\n+{\n+  return (__m512i) __builtin_ia32_palignr512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8di) __B,\n+\t\t\t\t\t\t   __N * 8,\n+\t\t\t\t\t\t   (__v8di) __W,\n+\t\t\t\t\t\t   (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_alignr_epi8 (__mmask64 __U, __m512i __A, __m512i __B,\n+\t\t\t  const int __N)\n+{\n+  return (__m512i) __builtin_ia32_palignr512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8di) __B,\n+\t\t\t\t\t\t   __N * 8,\n+\t\t\t\t\t\t   (__v8di)\n+\t\t\t\t\t\t   _mm512_setzero_si512 (),\n+\t\t\t\t\t\t   (__mmask64) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_dbsad_epu8 (__m512i __A, __m512i __B, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_dbpsadbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t    (__v64qi) __B,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_dbsad_epu8 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t__m512i __B, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_dbpsadbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t    (__v64qi) __B,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_dbsad_epu8 (__mmask32 __U, __m512i __A, __m512i __B,\n+\t\t\t const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_dbpsadbw512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t    (__v64qi) __B,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi(),\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_srli_epi16 (__m512i __A, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_psrlwi512_mask ((__v32hi) __A, __imm,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_srli_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\tconst int __imm)\n+{\n+  return (__m512i) __builtin_ia32_psrlwi512_mask ((__v32hi) __A, __imm,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_srli_epi16 (__mmask32 __U, __m512i __A, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_psrlwi512_mask ((__v32hi) __A, __imm,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_slli_epi16 (__m512i __A, const int __B)\n+{\n+  return (__m512i) __builtin_ia32_psllwi512_mask ((__v32hi) __A, __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_slli_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\tconst int __B)\n+{\n+  return (__m512i) __builtin_ia32_psllwi512_mask ((__v32hi) __A, __B,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_slli_epi16 (__mmask32 __U, __m512i __A, const int __B)\n+{\n+  return (__m512i) __builtin_ia32_psllwi512_mask ((__v32hi) __A, __B,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_shufflehi_epi16 (__m512i __A, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_pshufhw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_shufflehi_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_pshufhw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v32hi) __W,\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_shufflehi_epi16 (__mmask32 __U, __m512i __A,\n+\t\t\t      const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_pshufhw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_shufflelo_epi16 (__m512i __A, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_pshuflw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_shufflelo_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_pshuflw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v32hi) __W,\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_shufflelo_epi16 (__mmask32 __U, __m512i __A,\n+\t\t\t      const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_pshuflw512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v32hi)\n+\t\t\t\t\t\t   _mm512_setzero_hi (),\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_srai_epi16 (__m512i __A, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_psrawi512_mask ((__v32hi) __A, __imm,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_srai_epi16 (__m512i __W, __mmask32 __U, __m512i __A,\n+\t\t\tconst int __imm)\n+{\n+  return (__m512i) __builtin_ia32_psrawi512_mask ((__v32hi) __A, __imm,\n+\t\t\t\t\t\t  (__v32hi) __W,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_srai_epi16 (__mmask32 __U, __m512i __A, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_psrawi512_mask ((__v32hi) __A, __imm,\n+\t\t\t\t\t\t  (__v32hi)\n+\t\t\t\t\t\t  _mm512_setzero_hi (),\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_blend_epi16 (__mmask32 __U, __m512i __A, __m512i __W)\n+{\n+  return (__m512i) __builtin_ia32_blendmw_512_mask ((__v32hi) __A,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    (__mmask32) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_blend_epi8 (__mmask64 __U, __m512i __A, __m512i __W)\n+{\n+  return (__m512i) __builtin_ia32_blendmb_512_mask ((__v64qi) __A,\n+\t\t\t\t\t\t    (__v64qi) __W,\n+\t\t\t\t\t\t    (__mmask64) __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmp_epi16_mask (__mmask32 __U, __m512i __X, __m512i __Y,\n+\t\t\t    const int __P)\n+{\n+  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,\n+\t\t\t\t\t\t  (__v32hi) __Y, __P,\n+\t\t\t\t\t\t  (__mmask32) __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmp_epi16_mask (__m512i __X, __m512i __Y, const int __P)\n+{\n+  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,\n+\t\t\t\t\t\t  (__v32hi) __Y, __P,\n+\t\t\t\t\t\t  (__mmask32) -1);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmp_epi8_mask (__mmask32 __U, __m512i __X, __m512i __Y,\n+\t\t\t   const int __P)\n+{\n+  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,\n+\t\t\t\t\t\t  (__v64qi) __Y, __P,\n+\t\t\t\t\t\t  (__mmask64) __U);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmp_epi8_mask (__m512i __X, __m512i __Y, const int __P)\n+{\n+  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,\n+\t\t\t\t\t\t  (__v64qi) __Y, __P,\n+\t\t\t\t\t\t  (__mmask64) -1);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmp_epu16_mask (__mmask32 __U, __m512i __X, __m512i __Y,\n+\t\t\t    const int __P)\n+{\n+  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,\n+\t\t\t\t\t\t   (__v32hi) __Y, __P,\n+\t\t\t\t\t\t   (__mmask32) __U);\n+}\n+\n+extern __inline __mmask32\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmp_epu16_mask (__m512i __X, __m512i __Y, const int __P)\n+{\n+  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,\n+\t\t\t\t\t\t   (__v32hi) __Y, __P,\n+\t\t\t\t\t\t   (__mmask32) -1);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cmp_epu8_mask (__mmask32 __U, __m512i __X, __m512i __Y,\n+\t\t\t   const int __P)\n+{\n+  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,\n+\t\t\t\t\t\t   (__v64qi) __Y, __P,\n+\t\t\t\t\t\t   (__mmask64) __U);\n+}\n+\n+extern __inline __mmask64\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cmp_epu8_mask (__m512i __X, __m512i __Y, const int __P)\n+{\n+  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,\n+\t\t\t\t\t\t   (__v64qi) __Y, __P,\n+\t\t\t\t\t\t   (__mmask64) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_packs_epi32 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packssdw512_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v16si) __B,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_packs_epi32 (__mmask32 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packssdw512_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v16si) __B,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi(),\n+\t\t\t\t\t\t    __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_packs_epi32 (__m512i __W, __mmask32 __M, __m512i __A,\n+\t\t\t __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packssdw512_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v16si) __B,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_packus_epi32 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packusdw512_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v16si) __B,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi (),\n+\t\t\t\t\t\t    (__mmask32) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_packus_epi32 (__mmask32 __M, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packusdw512_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v16si) __B,\n+\t\t\t\t\t\t    (__v32hi)\n+\t\t\t\t\t\t    _mm512_setzero_hi(),\n+\t\t\t\t\t\t    __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_packus_epi32 (__m512i __W, __mmask32 __M, __m512i __A,\n+\t\t\t  __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_packusdw512_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v16si) __B,\n+\t\t\t\t\t\t    (__v32hi) __W,\n+\t\t\t\t\t\t    __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_bslli_epi128 (__m512i __A, const int __N)\n+{\n+  return (__m512i) __builtin_ia32_pslldq512 (__A, __N * 8);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_bsrli_epi128 (__m512i __A, const int __N)\n+{\n+  return (__m512i) __builtin_ia32_psrldq512 (__A, __N * 8);\n+}\n+\n+#else\n+#define _mm512_alignr_epi8(X, Y, N)\t\t\t\t\t\t    \\\n+  ((__m512i) __builtin_ia32_palignr512 ((__v8di)(__m512i)(X),\t\t\t    \\\n+\t\t\t\t\t(__v8di)(__m512i)(Y),\t\t\t    \\\n+\t\t\t\t\t(int)(N * 8)))\n+\n+#define _mm512_mask_alignr_epi8(W, U, X, Y, N)\t\t\t\t\t    \\\n+  ((__m512i) __builtin_ia32_palignr512_mask ((__v8di)(__m512i)(X),\t\t    \\\n+\t\t\t\t\t    (__v8di)(__m512i)(Y), (int)(N * 8),\t    \\\n+\t\t\t\t\t    (__v8di)(__m512i)(W), (__mmask64)(U)))\n+\n+#define _mm512_maskz_alignr_epi8(U, X, Y, N)\t\t\t\t\t    \\\n+  ((__m512i) __builtin_ia32_palignr512_mask ((__v8di)(__m512i)(X),\t\t    \\\n+\t\t\t\t\t    (__v8di)(__m512i)(Y), (int)(N * 8),\t    \\\n+\t\t\t\t\t    (__v8di)(__m512i)_mm512_setzero_si512 (),   \\\n+\t\t\t\t\t    (__mmask64)(U)))\n+\n+#define _mm512_dbsad_epu8(X, Y, C)                                                  \\\n+  ((__m512i) __builtin_ia32_dbpsadbw512_mask ((__v64qi)(__m512i) (X),               \\\n+                                              (__v64qi)(__m512i) (Y), (int) (C),    \\\n+                                              (__v32hi)(__m512i)_mm512_setzero_si512 (),\\\n+                                              (__mmask32)-1))\n+\n+#define _mm512_mask_dbsad_epu8(W, U, X, Y, C)                                       \\\n+  ((__m512i) __builtin_ia32_dbpsadbw512_mask ((__v64qi)(__m512i) (X),               \\\n+                                              (__v64qi)(__m512i) (Y), (int) (C),    \\\n+                                              (__v32hi)(__m512i)(W),                \\\n+                                              (__mmask32)(U)))\n+\n+#define _mm512_maskz_dbsad_epu8(U, X, Y, C)                                         \\\n+  ((__m512i) __builtin_ia32_dbpsadbw512_mask ((__v64qi)(__m512i) (X),               \\\n+                                              (__v64qi)(__m512i) (Y), (int) (C),    \\\n+                                              (__v32hi)(__m512i)_mm512_setzero_si512 (),\\\n+                                              (__mmask32)(U)))\n+\n+#define _mm512_srli_epi16(A, B)                                         \\\n+  ((__m512i) __builtin_ia32_psrlwi512_mask ((__v32hi)(__m512i)(A),      \\\n+    (int)(B), (__v32hi)_mm512_setzero_hi(), (__mmask32)-1))\n+\n+#define _mm512_mask_srli_epi16(W, U, A, B)                              \\\n+  ((__m512i) __builtin_ia32_psrlwi512_mask ((__v32hi)(__m512i)(A),      \\\n+    (int)(B), (__v32hi)(__m512i)(W), (__mmask32)(U)))\n+\n+#define _mm512_maskz_srli_epi16(U, A, B)                                \\\n+  ((__m512i) __builtin_ia32_psrlwi512_mask ((__v32hi)(__m512i)(A),      \\\n+    (int)(B), (__v32hi)_mm512_setzero_hi(), (__mmask32)(U)))\n+\n+#define _mm512_slli_epi16(X, C)\t\t\t\t\t\t   \\\n+  ((__m512i)__builtin_ia32_psllwi512_mask ((__v32hi)(__m512i)(X), (int)(C),\\\n+    (__v32hi)(__m512i)_mm512_setzero_hi(),\\\n+    (__mmask32)-1))\n+\n+#define _mm512_mask_slli_epi16(W, U, X, C)                                 \\\n+  ((__m512i)__builtin_ia32_psllwi512_mask ((__v32hi)(__m512i)(X), (int)(C),\\\n+    (__v32hi)(__m512i)(W),\\\n+    (__mmask32)(U)))\n+\n+#define _mm512_maskz_slli_epi16(U, X, C)                                   \\\n+  ((__m512i)__builtin_ia32_psllwi512_mask ((__v32hi)(__m512i)(X), (int)(C),\\\n+    (__v32hi)(__m512i)_mm512_setzero_hi(),\\\n+    (__mmask32)(U)))\n+\n+#define _mm512_shufflehi_epi16(A, B)                                                \\\n+  ((__m512i) __builtin_ia32_pshufhw512_mask ((__v32hi)(__m512i)(A), (int)(B),       \\\n+                                             (__v32hi)(__m512i)_mm512_setzero_hi(), \\\n+                                             (__mmask32)-1))\n+\n+#define _mm512_mask_shufflehi_epi16(W, U, A, B)                                     \\\n+  ((__m512i) __builtin_ia32_pshufhw512_mask ((__v32hi)(__m512i)(A), (int)(B),       \\\n+                                             (__v32hi)(__m512i)(W),                 \\\n+                                             (__mmask32)(U)))\n+\n+#define _mm512_maskz_shufflehi_epi16(U, A, B)                                       \\\n+  ((__m512i) __builtin_ia32_pshufhw512_mask ((__v32hi)(__m512i)(A), (int)(B),       \\\n+                                             (__v32hi)(__m512i)_mm512_setzero_hi(), \\\n+                                             (__mmask32)(U)))\n+\n+#define _mm512_shufflelo_epi16(A, B)                                                \\\n+  ((__m512i) __builtin_ia32_pshuflw512_mask ((__v32hi)(__m512i)(A), (int)(B),       \\\n+                                             (__v32hi)(__m512i)_mm512_setzero_hi(), \\\n+                                             (__mmask32)-1))\n+\n+#define _mm512_mask_shufflelo_epi16(W, U, A, B)                                     \\\n+  ((__m512i) __builtin_ia32_pshuflw512_mask ((__v32hi)(__m512i)(A), (int)(B),       \\\n+                                             (__v32hi)(__m512i)(W),                 \\\n+                                             (__mmask32)(U)))\n+\n+#define _mm512_maskz_shufflelo_epi16(U, A, B)                                       \\\n+  ((__m512i) __builtin_ia32_pshuflw512_mask ((__v32hi)(__m512i)(A), (int)(B),       \\\n+                                             (__v32hi)(__m512i)_mm512_setzero_hi(), \\\n+                                             (__mmask32)(U)))\n+\n+#define _mm512_srai_epi16(A, B)                                         \\\n+  ((__m512i) __builtin_ia32_psrawi512_mask ((__v32hi)(__m512i)(A),      \\\n+    (int)(B), (__v32hi)_mm512_setzero_hi(), (__mmask32)-1))\n+\n+#define _mm512_mask_srai_epi16(W, U, A, B)                              \\\n+  ((__m512i) __builtin_ia32_psrawi512_mask ((__v32hi)(__m512i)(A),      \\\n+    (int)(B), (__v32hi)(__m512i)(W), (__mmask32)(U)))\n+\n+#define _mm512_maskz_srai_epi16(U, A, B)                                \\\n+  ((__m512i) __builtin_ia32_psrawi512_mask ((__v32hi)(__m512i)(A),      \\\n+    (int)(B), (__v32hi)_mm512_setzero_hi(), (__mmask32)(U)))\n+\n+#define _mm512_mask_blend_epi16(__U, __A, __W)\t\t\t      \\\n+  ((__m512i) __builtin_ia32_blendmw_512_mask ((__v32hi) (__A),\t      \\\n+\t\t\t\t\t\t    (__v32hi) (__W),  \\\n+\t\t\t\t\t\t    (__mmask32) (__U)))\n+\n+#define _mm512_mask_blend_epi8(__U, __A, __W)\t\t\t      \\\n+  ((__m512i) __builtin_ia32_blendmb_512_mask ((__v64qi) (__A),\t      \\\n+\t\t\t\t\t\t    (__v64qi) (__W),  \\\n+\t\t\t\t\t\t    (__mmask64) (__U)))\n+\n+#define _mm512_cmp_epi16_mask(X, Y, P)\t\t\t\t\\\n+  ((__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v32hi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask32)(-1)))\n+\n+#define _mm512_cmp_epi8_mask(X, Y, P)\t\t\t\t\\\n+  ((__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v64qi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask64)(-1)))\n+\n+#define _mm512_cmp_epu16_mask(X, Y, P)\t\t\t\t\\\n+  ((__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v32hi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask32)(-1)))\n+\n+#define _mm512_cmp_epu8_mask(X, Y, P)\t\t\t\t\\\n+  ((__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v64qi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask64)(-1)))\n+\n+#define _mm512_mask_cmp_epi16_mask(M, X, Y, P)\t\t\t\t\\\n+  ((__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v32hi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask32)(M)))\n+\n+#define _mm512_mask_cmp_epi8_mask(M, X, Y, P)\t\t\t\t\\\n+  ((__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v64qi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask64)(M)))\n+\n+#define _mm512_mask_cmp_epu16_mask(M, X, Y, P)\t\t\t\t\\\n+  ((__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v32hi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask32)(M)))\n+\n+#define _mm512_mask_cmp_epu8_mask(M, X, Y, P)\t\t\t\t\\\n+  ((__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi)(__m512i)(X),\t\\\n+\t\t\t\t\t    (__v64qi)(__m512i)(Y), (int)(P),\\\n+\t\t\t\t\t    (__mmask64)(M)))\n+\n+#define _mm512_bslli_epi128(A, N)                                         \\\n+  ((__m512i)__builtin_ia32_pslldq512 ((__m512i)(A), (int)(N) * 8))\n+\n+#define _mm512_bsrli_epi128(A, N)                                         \\\n+  ((__m512i)__builtin_ia32_psrldq512 ((__m512i)(A), (int)(N) * 8))\n+\n+#endif\n+\n+#ifdef __DISABLE_AVX512BW__\n+#undef __DISABLE_AVX512BW__\n+#pragma GCC pop_options\n+#endif /* __DISABLE_AVX512BW__ */\n+\n+#endif /* _AVX512BWINTRIN_H_INCLUDED */"}, {"sha": "6014a1ce9846a4f6311b846fffedea9e83953bab", "filename": "gcc/config/i386/avx512dqintrin.h", "status": "added", "additions": 2306, "deletions": 0, "changes": 2306, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512dqintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512dqintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512dqintrin.h?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589", "patch": "@@ -0,0 +1,2306 @@\n+/* Copyright (C) 2014\n+   Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify\n+   it under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   Under Section 7 of GPL version 3, you are granted additional\n+   permissions described in the GCC Runtime Library Exception, version\n+   3.1, as published by the Free Software Foundation.\n+\n+   You should have received a copy of the GNU General Public License and\n+   a copy of the GCC Runtime Library Exception along with this program;\n+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#ifndef _IMMINTRIN_H_INCLUDED\n+#error \"Never use <avx512dqintrin.h> directly; include <immintrin.h> instead.\"\n+#endif\n+\n+#ifndef _AVX512DQINTRIN_H_INCLUDED\n+#define _AVX512DQINTRIN_H_INCLUDED\n+\n+#ifndef __AVX512DQ__\n+#pragma GCC push_options\n+#pragma GCC target(\"avx512dq\")\n+#define __DISABLE_AVX512DQ__\n+#endif /* __AVX512DQ__ */\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcast_f64x2 (__m128d __A)\n+{\n+  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   _mm512_undefined_pd(),\n+\t\t\t\t\t\t\t   (__mmask8) -\n+\t\t\t\t\t\t\t   1);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcast_f64x2 (__m512d __O, __mmask8 __M, __m128d __A)\n+{\n+  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v8df)\n+\t\t\t\t\t\t\t   __O, __M);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcast_f64x2 (__mmask8 __M, __m128d __A)\n+{\n+  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v8df)\n+\t\t\t\t\t\t\t   _mm512_setzero_ps (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcast_i64x2 (__m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   _mm512_undefined_si512(),\n+\t\t\t\t\t\t\t   (__mmask8) -\n+\t\t\t\t\t\t\t   1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcast_i64x2 (__m512i __O, __mmask8 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v8di)\n+\t\t\t\t\t\t\t   __O, __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcast_i64x2 (__mmask8 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v8di)\n+\t\t\t\t\t\t\t   _mm512_setzero_si512 (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcast_f32x2 (__m128 __A)\n+{\n+  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,\n+\t\t\t\t\t\t\t  (__v16sf)_mm512_undefined_ps(),\n+\t\t\t\t\t\t\t  (__mmask16) -\n+\t\t\t\t\t\t\t  1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcast_f32x2 (__m512 __O, __mmask16 __M, __m128 __A)\n+{\n+  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,\n+\t\t\t\t\t\t\t  (__v16sf)\n+\t\t\t\t\t\t\t  __O, __M);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcast_f32x2 (__mmask16 __M, __m128 __A)\n+{\n+  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,\n+\t\t\t\t\t\t\t  (__v16sf)\n+\t\t\t\t\t\t\t  _mm512_setzero_ps (),\n+\t\t\t\t\t\t\t  __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcast_i32x2 (__m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v16si)_mm512_undefined_si512(),\n+\t\t\t\t\t\t\t   (__mmask16)\n+\t\t\t\t\t\t\t   -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcast_i32x2 (__m512i __O, __mmask16 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v16si)\n+\t\t\t\t\t\t\t   __O, __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcast_i32x2 (__mmask16 __M, __m128i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v16si)\n+\t\t\t\t\t\t\t   _mm512_setzero_si512 (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcast_f32x8 (__m256 __A)\n+{\n+  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t\t  _mm512_undefined_ps(),\n+\t\t\t\t\t\t\t  (__mmask16) -\n+\t\t\t\t\t\t\t  1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcast_f32x8 (__m512 __O, __mmask16 __M, __m256 __A)\n+{\n+  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t\t  (__v16sf)__O,\n+\t\t\t\t\t\t\t  __M);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcast_f32x8 (__mmask16 __M, __m256 __A)\n+{\n+  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t\t  (__v16sf)\n+\t\t\t\t\t\t\t  _mm512_setzero_ps (),\n+\t\t\t\t\t\t\t  __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_broadcast_i32x8 (__m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v16si)_mm512_undefined_si512(),\n+\t\t\t\t\t\t\t   (__mmask16)\n+\t\t\t\t\t\t\t   -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_broadcast_i32x8 (__m512i __O, __mmask16 __M, __m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v16si)__O,\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_broadcast_i32x8 (__mmask16 __M, __m256i __A)\n+{\n+  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v16si)\n+\t\t\t\t\t\t\t   _mm512_setzero_si512 (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mullo_epi64 (__m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmullq512_mask ((__v8di) __A,\n+\t\t\t\t\t\t  (__v8di) __B,\n+\t\t\t\t\t\t  (__v8di)\n+\t\t\t\t\t\t  _mm512_setzero_si512 (),\n+\t\t\t\t\t\t  (__mmask8) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_mullo_epi64 (__m512i __W, __mmask8 __U, __m512i __A,\n+\t\t\t __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmullq512_mask ((__v8di) __A,\n+\t\t\t\t\t\t  (__v8di) __B,\n+\t\t\t\t\t\t  (__v8di) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_mullo_epi64 (__mmask8 __U, __m512i __A, __m512i __B)\n+{\n+  return (__m512i) __builtin_ia32_pmullq512_mask ((__v8di) __A,\n+\t\t\t\t\t\t  (__v8di) __B,\n+\t\t\t\t\t\t  (__v8di)\n+\t\t\t\t\t\t  _mm512_setzero_si512 (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_xor_pd (__m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t (__v8df) __B,\n+\t\t\t\t\t\t (__v8df)\n+\t\t\t\t\t\t _mm512_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) -1);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_xor_pd (__m512d __W, __mmask8 __U, __m512d __A,\n+\t\t    __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t (__v8df) __B,\n+\t\t\t\t\t\t (__v8df) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_xor_pd (__mmask8 __U, __m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t (__v8df) __B,\n+\t\t\t\t\t\t (__v8df)\n+\t\t\t\t\t\t _mm512_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_xor_ps (__m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t(__v16sf) __B,\n+\t\t\t\t\t\t(__v16sf)\n+\t\t\t\t\t\t_mm512_setzero_ps (),\n+\t\t\t\t\t\t(__mmask16) -1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_xor_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t(__v16sf) __B,\n+\t\t\t\t\t\t(__v16sf) __W,\n+\t\t\t\t\t\t(__mmask16) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_xor_ps (__mmask16 __U, __m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t(__v16sf) __B,\n+\t\t\t\t\t\t(__v16sf)\n+\t\t\t\t\t\t_mm512_setzero_ps (),\n+\t\t\t\t\t\t(__mmask16) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_or_pd (__m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t(__v8df) __B,\n+\t\t\t\t\t\t(__v8df)\n+\t\t\t\t\t\t_mm512_setzero_pd (),\n+\t\t\t\t\t\t(__mmask8) -1);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_or_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t(__v8df) __B,\n+\t\t\t\t\t\t(__v8df) __W,\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_or_pd (__mmask8 __U, __m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t(__v8df) __B,\n+\t\t\t\t\t\t(__v8df)\n+\t\t\t\t\t\t_mm512_setzero_pd (),\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_or_ps (__m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,\n+\t\t\t\t\t       (__v16sf) __B,\n+\t\t\t\t\t       (__v16sf)\n+\t\t\t\t\t       _mm512_setzero_ps (),\n+\t\t\t\t\t       (__mmask16) -1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_or_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,\n+\t\t\t\t\t       (__v16sf) __B,\n+\t\t\t\t\t       (__v16sf) __W,\n+\t\t\t\t\t       (__mmask16) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_or_ps (__mmask16 __U, __m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,\n+\t\t\t\t\t       (__v16sf) __B,\n+\t\t\t\t\t       (__v16sf)\n+\t\t\t\t\t       _mm512_setzero_ps (),\n+\t\t\t\t\t       (__mmask16) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_and_pd (__m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t (__v8df) __B,\n+\t\t\t\t\t\t (__v8df)\n+\t\t\t\t\t\t _mm512_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) -1);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_and_pd (__m512d __W, __mmask8 __U, __m512d __A,\n+\t\t    __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t (__v8df) __B,\n+\t\t\t\t\t\t (__v8df) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_and_pd (__mmask8 __U, __m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t (__v8df) __B,\n+\t\t\t\t\t\t (__v8df)\n+\t\t\t\t\t\t _mm512_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_and_ps (__m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t(__v16sf) __B,\n+\t\t\t\t\t\t(__v16sf)\n+\t\t\t\t\t\t_mm512_setzero_ps (),\n+\t\t\t\t\t\t(__mmask16) -1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_and_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t(__v16sf) __B,\n+\t\t\t\t\t\t(__v16sf) __W,\n+\t\t\t\t\t\t(__mmask16) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_and_ps (__mmask16 __U, __m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t(__v16sf) __B,\n+\t\t\t\t\t\t(__v16sf)\n+\t\t\t\t\t\t_mm512_setzero_ps (),\n+\t\t\t\t\t\t(__mmask16) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_andnot_pd (__m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t  (__v8df) __B,\n+\t\t\t\t\t\t  (__v8df)\n+\t\t\t\t\t\t  _mm512_setzero_pd (),\n+\t\t\t\t\t\t  (__mmask8) -1);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_andnot_pd (__m512d __W, __mmask8 __U, __m512d __A,\n+\t\t       __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t  (__v8df) __B,\n+\t\t\t\t\t\t  (__v8df) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_andnot_pd (__mmask8 __U, __m512d __A, __m512d __B)\n+{\n+  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t  (__v8df) __B,\n+\t\t\t\t\t\t  (__v8df)\n+\t\t\t\t\t\t  _mm512_setzero_pd (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_andnot_ps (__m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t (__v16sf) __B,\n+\t\t\t\t\t\t (__v16sf)\n+\t\t\t\t\t\t _mm512_setzero_ps (),\n+\t\t\t\t\t\t (__mmask16) -1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_andnot_ps (__m512 __W, __mmask16 __U, __m512 __A,\n+\t\t       __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t (__v16sf) __B,\n+\t\t\t\t\t\t (__v16sf) __W,\n+\t\t\t\t\t\t (__mmask16) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_andnot_ps (__mmask16 __U, __m512 __A, __m512 __B)\n+{\n+  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t (__v16sf) __B,\n+\t\t\t\t\t\t (__v16sf)\n+\t\t\t\t\t\t _mm512_setzero_ps (),\n+\t\t\t\t\t\t (__mmask16) __U);\n+}\n+\n+extern __inline __mmask16\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movepi32_mask (__m512i __A)\n+{\n+  return (__mmask16) __builtin_ia32_cvtd2mask512 ((__v16si) __A);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movepi64_mask (__m512i __A)\n+{\n+  return (__mmask8) __builtin_ia32_cvtq2mask512 ((__v8di) __A);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movm_epi32 (__mmask16 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtmask2d512 (__A);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_movm_epi64 (__mmask8 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtmask2q512 (__A);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvttpd_epi64 (__m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvttpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvttpd_epi64 (__mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvttpd_epu64 (__m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) -1,\n+\t\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvttpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      (__v8di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvttpd_epu64 (__mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvttps_epi64 (__m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvttps_epi64 (__m512i __W, __mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvttps_epi64 (__mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvttps_epu64 (__m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) -1,\n+\t\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvttps_epu64 (__m512i __W, __mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      (__v8di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvttps_epu64 (__mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtpd_epi64 (__m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t    (__v8di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtpd_epi64 (__mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtpd_epu64 (__m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtpd_epu64 (__mmask8 __U, __m512d __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtps_epi64 (__m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtps_epi64 (__m512i __W, __mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t    (__v8di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtps_epi64 (__mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtps_epu64 (__m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtps_epu64 (__m512i __W, __mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtps_epu64 (__mmask8 __U, __m256 __A)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtepi64_ps (__m512i __A)\n+{\n+  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8sf)\n+\t\t\t\t\t\t   _mm256_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) -1,\n+\t\t\t\t\t\t   _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtepi64_ps (__m256 __W, __mmask8 __U, __m512i __A)\n+{\n+  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8sf) __W,\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtepi64_ps (__mmask8 __U, __m512i __A)\n+{\n+  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8sf)\n+\t\t\t\t\t\t   _mm256_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtepu64_ps (__m512i __A)\n+{\n+  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8sf)\n+\t\t\t\t\t\t    _mm256_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtepu64_ps (__m256 __W, __mmask8 __U, __m512i __A)\n+{\n+  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8sf) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtepu64_ps (__mmask8 __U, __m512i __A)\n+{\n+  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8sf)\n+\t\t\t\t\t\t    _mm256_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtepi64_pd (__m512i __A)\n+{\n+  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8df)\n+\t\t\t\t\t\t    _mm512_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtepi64_pd (__m512d __W, __mmask8 __U, __m512i __A)\n+{\n+  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8df) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtepi64_pd (__mmask8 __U, __m512i __A)\n+{\n+  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8df)\n+\t\t\t\t\t\t    _mm512_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtepu64_pd (__m512i __A)\n+{\n+  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t     (__v8df)\n+\t\t\t\t\t\t     _mm512_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtepu64_pd (__m512d __W, __mmask8 __U, __m512i __A)\n+{\n+  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t     (__v8df) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtepu64_pd (__mmask8 __U, __m512i __A)\n+{\n+  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t     (__v8df)\n+\t\t\t\t\t\t     _mm512_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_range_pd (__m512d __A, __m512d __B, int __C)\n+{\n+  return (__m512d) __builtin_ia32_rangepd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t   (__v8df) __B, __C,\n+\t\t\t\t\t\t   (__v8df)\n+\t\t\t\t\t\t   _mm512_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) -1,\n+\t\t\t\t\t\t   _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_range_pd (__m512d __W, __mmask8 __U,\n+\t\t      __m512d __A, __m512d __B, int __C)\n+{\n+  return (__m512d) __builtin_ia32_rangepd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t   (__v8df) __B, __C,\n+\t\t\t\t\t\t   (__v8df) __W,\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_range_pd (__mmask8 __U, __m512d __A, __m512d __B, int __C)\n+{\n+  return (__m512d) __builtin_ia32_rangepd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t   (__v8df) __B, __C,\n+\t\t\t\t\t\t   (__v8df)\n+\t\t\t\t\t\t   _mm512_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_range_ps (__m512 __A, __m512 __B, int __C)\n+{\n+  return (__m512) __builtin_ia32_rangeps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t  (__v16sf) __B, __C,\n+\t\t\t\t\t\t  (__v16sf)\n+\t\t\t\t\t\t  _mm512_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask16) -1,\n+\t\t\t\t\t\t  _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_range_ps (__m512 __W, __mmask16 __U,\n+\t\t      __m512 __A, __m512 __B, int __C)\n+{\n+  return (__m512) __builtin_ia32_rangeps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t  (__v16sf) __B, __C,\n+\t\t\t\t\t\t  (__v16sf) __W,\n+\t\t\t\t\t\t  (__mmask16) __U,\n+\t\t\t\t\t\t  _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_range_ps (__mmask16 __U, __m512 __A, __m512 __B, int __C)\n+{\n+  return (__m512) __builtin_ia32_rangeps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t  (__v16sf) __B, __C,\n+\t\t\t\t\t\t  (__v16sf)\n+\t\t\t\t\t\t  _mm512_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask16) __U,\n+\t\t\t\t\t\t  _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_reduce_sd (__m128d __A, __m128d __B, int __C)\n+{\n+  return (__m128d) __builtin_ia32_reducesd ((__v2df) __A,\n+\t\t\t\t\t\t (__v2df) __B, __C);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_reduce_ss (__m128 __A, __m128 __B, int __C)\n+{\n+  return (__m128) __builtin_ia32_reducess ((__v4sf) __A,\n+\t\t\t\t\t\t(__v4sf) __B, __C);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_range_sd (__m128d __A, __m128d __B, int __C)\n+{\n+  return (__m128d) __builtin_ia32_rangesd128_round ((__v2df) __A,\n+\t\t\t\t\t\t   (__v2df) __B, __C,\n+\t\t\t\t\t\t   _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_range_ss (__m128 __A, __m128 __B, int __C)\n+{\n+  return (__m128) __builtin_ia32_rangess128_round ((__v4sf) __A,\n+\t\t\t\t\t\t  (__v4sf) __B, __C,\n+\t\t\t\t\t\t  _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_range_round_sd (__m128d __A, __m128d __B, int __C, const int __R)\n+{\n+  return (__m128d) __builtin_ia32_rangesd128_round ((__v2df) __A,\n+\t\t\t\t\t\t   (__v2df) __B, __C,\n+\t\t\t\t\t\t   __R);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_range_round_ss (__m128 __A, __m128 __B, int __C, const int __R)\n+{\n+  return (__m128) __builtin_ia32_rangess128_round ((__v4sf) __A,\n+\t\t\t\t\t\t  (__v4sf) __B, __C,\n+\t\t\t\t\t\t  __R);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fpclass_ss_mask (__m128 __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclassss ((__v4sf) __A, __imm);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fpclass_sd_mask (__m128d __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclasssd ((__v2df) __A, __imm);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtt_roundpd_epi64 (__m512d __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtt_roundpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtt_roundpd_epi64 (__mmask8 __U, __m512d __A,\n+\t\t\t\t const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtt_roundpd_epu64 (__m512d __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) -1,\n+\t\t\t\t\t\t      __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtt_roundpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      (__v8di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtt_roundpd_epu64 (__mmask8 __U, __m512d __A,\n+\t\t\t\t const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtt_roundps_epi64 (__m256 __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtt_roundps_epi64 (__m512i __W, __mmask8 __U, __m256 __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtt_roundps_epi64 (__mmask8 __U, __m256 __A,\n+\t\t\t\t const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtt_roundps_epu64 (__m256 __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) -1,\n+\t\t\t\t\t\t      __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtt_roundps_epu64 (__m512i __W, __mmask8 __U, __m256 __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      (__v8di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtt_roundps_epu64 (__mmask8 __U, __m256 __A,\n+\t\t\t\t const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      (__v8di)\n+\t\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t\t      (__mmask8) __U,\n+\t\t\t\t\t\t      __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundpd_epi64 (__m512d __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t    (__v8di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundpd_epi64 (__mmask8 __U, __m512d __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundpd_epu64 (__m512d __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundpd_epu64 (__mmask8 __U, __m512d __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundps_epi64 (__m256 __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundps_epi64 (__m512i __W, __mmask8 __U, __m256 __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t    (__v8di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundps_epi64 (__mmask8 __U, __m256 __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t    (__v8di)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundps_epu64 (__m256 __A, const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundps_epu64 (__m512i __W, __mmask8 __U, __m256 __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundps_epu64 (__mmask8 __U, __m256 __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,\n+\t\t\t\t\t\t     (__v8di)\n+\t\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundepi64_ps (__m512i __A, const int __R)\n+{\n+  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8sf)\n+\t\t\t\t\t\t   _mm256_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) -1,\n+\t\t\t\t\t\t   __R);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundepi64_ps (__m256 __W, __mmask8 __U, __m512i __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8sf) __W,\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   __R);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundepi64_ps (__mmask8 __U, __m512i __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t   (__v8sf)\n+\t\t\t\t\t\t   _mm256_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   __R);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundepu64_ps (__m512i __A, const int __R)\n+{\n+  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8sf)\n+\t\t\t\t\t\t    _mm256_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundepu64_ps (__m256 __W, __mmask8 __U, __m512i __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8sf) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundepu64_ps (__mmask8 __U, __m512i __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8sf)\n+\t\t\t\t\t\t    _mm256_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundepi64_pd (__m512i __A, const int __R)\n+{\n+  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8df)\n+\t\t\t\t\t\t    _mm512_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) -1,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundepi64_pd (__m512d __W, __mmask8 __U, __m512i __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8df) __W,\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundepi64_pd (__mmask8 __U, __m512i __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t    (__v8df)\n+\t\t\t\t\t\t    _mm512_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) __U,\n+\t\t\t\t\t\t    __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundepu64_pd (__m512i __A, const int __R)\n+{\n+  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t     (__v8df)\n+\t\t\t\t\t\t     _mm512_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) -1,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundepu64_pd (__m512d __W, __mmask8 __U, __m512i __A,\n+\t\t\t       const int __R)\n+{\n+  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t     (__v8df) __W,\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundepu64_pd (__mmask8 __U, __m512i __A,\n+\t\t\t\tconst int __R)\n+{\n+  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,\n+\t\t\t\t\t\t     (__v8df)\n+\t\t\t\t\t\t     _mm512_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) __U,\n+\t\t\t\t\t\t     __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_reduce_pd (__m512d __A, int __B)\n+{\n+  return (__m512d) __builtin_ia32_reducepd512_mask ((__v8df) __A, __B,\n+\t\t\t\t\t\t    (__v8df)\n+\t\t\t\t\t\t    _mm512_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_reduce_pd (__m512d __W, __mmask8 __U, __m512d __A, int __B)\n+{\n+  return (__m512d) __builtin_ia32_reducepd512_mask ((__v8df) __A, __B,\n+\t\t\t\t\t\t    (__v8df) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_reduce_pd (__mmask8 __U, __m512d __A, int __B)\n+{\n+  return (__m512d) __builtin_ia32_reducepd512_mask ((__v8df) __A, __B,\n+\t\t\t\t\t\t    (__v8df)\n+\t\t\t\t\t\t    _mm512_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_reduce_ps (__m512 __A, int __B)\n+{\n+  return (__m512) __builtin_ia32_reduceps512_mask ((__v16sf) __A, __B,\n+\t\t\t\t\t\t   (__v16sf)\n+\t\t\t\t\t\t   _mm512_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask16) -1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_reduce_ps (__m512 __W, __mmask16 __U, __m512 __A, int __B)\n+{\n+  return (__m512) __builtin_ia32_reduceps512_mask ((__v16sf) __A, __B,\n+\t\t\t\t\t\t   (__v16sf) __W,\n+\t\t\t\t\t\t   (__mmask16) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_reduce_ps (__mmask16 __U, __m512 __A, int __B)\n+{\n+  return (__m512) __builtin_ia32_reduceps512_mask ((__v16sf) __A, __B,\n+\t\t\t\t\t\t   (__v16sf)\n+\t\t\t\t\t\t   _mm512_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask16) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_extractf32x8_ps (__m512 __A, const int __imm)\n+{\n+  return (__m256) __builtin_ia32_extractf32x8_mask ((__v16sf) __A,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v8sf)\n+\t\t\t\t\t\t    _mm256_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_extractf32x8_ps (__m256 __W, __mmask8 __U, __m512 __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__m256) __builtin_ia32_extractf32x8_mask ((__v16sf) __A,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v8sf) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_extractf32x8_ps (__mmask8 __U, __m512 __A,\n+\t\t\t      const int __imm)\n+{\n+  return (__m256) __builtin_ia32_extractf32x8_mask ((__v16sf) __A,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v8sf)\n+\t\t\t\t\t\t    _mm256_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_extractf64x2_pd (__m512d __A, const int __imm)\n+{\n+  return (__m128d) __builtin_ia32_extractf64x2_512_mask ((__v8df) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t\t _mm_setzero_pd (),\n+\t\t\t\t\t\t\t (__mmask8) -\n+\t\t\t\t\t\t\t 1);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_extractf64x2_pd (__m128d __W, __mmask8 __U, __m512d __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__m128d) __builtin_ia32_extractf64x2_512_mask ((__v8df) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2df) __W,\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_extractf64x2_pd (__mmask8 __U, __m512d __A,\n+\t\t\t      const int __imm)\n+{\n+  return (__m128d) __builtin_ia32_extractf64x2_512_mask ((__v8df) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t\t _mm_setzero_pd (),\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_extracti32x8_epi32 (__m512i __A, const int __imm)\n+{\n+  return (__m256i) __builtin_ia32_extracti32x8_mask ((__v16si) __A,\n+\t\t\t\t\t\t     __imm,\n+\t\t\t\t\t\t     (__v8si)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_extracti32x8_epi32 (__m256i __W, __mmask8 __U, __m512i __A,\n+\t\t\t\tconst int __imm)\n+{\n+  return (__m256i) __builtin_ia32_extracti32x8_mask ((__v16si) __A,\n+\t\t\t\t\t\t     __imm,\n+\t\t\t\t\t\t     (__v8si) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_extracti32x8_epi32 (__mmask8 __U, __m512i __A,\n+\t\t\t\t const int __imm)\n+{\n+  return (__m256i) __builtin_ia32_extracti32x8_mask ((__v16si) __A,\n+\t\t\t\t\t\t     __imm,\n+\t\t\t\t\t\t     (__v8si)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_extracti64x2_epi64 (__m512i __A, const int __imm)\n+{\n+  return (__m128i) __builtin_ia32_extracti64x2_512_mask ((__v8di) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2di)\n+\t\t\t\t\t\t\t _mm_setzero_di (),\n+\t\t\t\t\t\t\t (__mmask8) -\n+\t\t\t\t\t\t\t 1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_extracti64x2_epi64 (__m128i __W, __mmask8 __U, __m512i __A,\n+\t\t\t\tconst int __imm)\n+{\n+  return (__m128i) __builtin_ia32_extracti64x2_512_mask ((__v8di) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2di) __W,\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_extracti64x2_epi64 (__mmask8 __U, __m512i __A,\n+\t\t\t\t const int __imm)\n+{\n+  return (__m128i) __builtin_ia32_extracti64x2_512_mask ((__v8di) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2di)\n+\t\t\t\t\t\t\t _mm_setzero_di (),\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_range_round_pd (__m512d __A, __m512d __B, int __C,\n+\t\t       const int __R)\n+{\n+  return (__m512d) __builtin_ia32_rangepd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t   (__v8df) __B, __C,\n+\t\t\t\t\t\t   (__v8df)\n+\t\t\t\t\t\t   _mm512_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) -1,\n+\t\t\t\t\t\t   __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_range_round_pd (__m512d __W, __mmask8 __U,\n+\t\t\t    __m512d __A, __m512d __B, int __C,\n+\t\t\t    const int __R)\n+{\n+  return (__m512d) __builtin_ia32_rangepd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t   (__v8df) __B, __C,\n+\t\t\t\t\t\t   (__v8df) __W,\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   __R);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_range_round_pd (__mmask8 __U, __m512d __A, __m512d __B,\n+\t\t\t     int __C, const int __R)\n+{\n+  return (__m512d) __builtin_ia32_rangepd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t   (__v8df) __B, __C,\n+\t\t\t\t\t\t   (__v8df)\n+\t\t\t\t\t\t   _mm512_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) __U,\n+\t\t\t\t\t\t   __R);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_range_round_ps (__m512 __A, __m512 __B, int __C, const int __R)\n+{\n+  return (__m512) __builtin_ia32_rangeps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t  (__v16sf) __B, __C,\n+\t\t\t\t\t\t  (__v16sf)\n+\t\t\t\t\t\t  _mm512_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask16) -1,\n+\t\t\t\t\t\t  __R);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_range_round_ps (__m512 __W, __mmask16 __U,\n+\t\t\t    __m512 __A, __m512 __B, int __C,\n+\t\t\t    const int __R)\n+{\n+  return (__m512) __builtin_ia32_rangeps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t  (__v16sf) __B, __C,\n+\t\t\t\t\t\t  (__v16sf) __W,\n+\t\t\t\t\t\t  (__mmask16) __U,\n+\t\t\t\t\t\t  __R);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_range_round_ps (__mmask16 __U, __m512 __A, __m512 __B,\n+\t\t\t     int __C, const int __R)\n+{\n+  return (__m512) __builtin_ia32_rangeps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t  (__v16sf) __B, __C,\n+\t\t\t\t\t\t  (__v16sf)\n+\t\t\t\t\t\t  _mm512_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask16) __U,\n+\t\t\t\t\t\t  __R);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_inserti32x8 (__m512i __A, __m256i __B, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_inserti32x8_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v8si) __B,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v16si)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask16) -1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_inserti32x8 (__m512i __W, __mmask16 __U, __m512i __A,\n+\t\t\t __m256i __B, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_inserti32x8_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v8si) __B,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v16si) __W,\n+\t\t\t\t\t\t    (__mmask16) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_inserti32x8 (__mmask16 __U, __m512i __A, __m256i __B,\n+\t\t\t  const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_inserti32x8_mask ((__v16si) __A,\n+\t\t\t\t\t\t    (__v8si) __B,\n+\t\t\t\t\t\t    __imm,\n+\t\t\t\t\t\t    (__v16si)\n+\t\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t\t    (__mmask16) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_insertf32x8 (__m512 __A, __m256 __B, const int __imm)\n+{\n+  return (__m512) __builtin_ia32_insertf32x8_mask ((__v16sf) __A,\n+\t\t\t\t\t\t   (__v8sf) __B,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v16sf)\n+\t\t\t\t\t\t   _mm512_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask16) -1);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_insertf32x8 (__m512 __W, __mmask16 __U, __m512 __A,\n+\t\t\t __m256 __B, const int __imm)\n+{\n+  return (__m512) __builtin_ia32_insertf32x8_mask ((__v16sf) __A,\n+\t\t\t\t\t\t   (__v8sf) __B,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v16sf) __W,\n+\t\t\t\t\t\t   (__mmask16) __U);\n+}\n+\n+extern __inline __m512\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_insertf32x8 (__mmask16 __U, __m512 __A, __m256 __B,\n+\t\t\t  const int __imm)\n+{\n+  return (__m512) __builtin_ia32_insertf32x8_mask ((__v16sf) __A,\n+\t\t\t\t\t\t   (__v8sf) __B,\n+\t\t\t\t\t\t   __imm,\n+\t\t\t\t\t\t   (__v16sf)\n+\t\t\t\t\t\t   _mm512_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask16) __U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_inserti64x2 (__m512i __A, __m128i __B, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_inserti64x2_512_mask ((__v8di) __A,\n+\t\t\t\t\t\t\t(__v2di) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v8di)\n+\t\t\t\t\t\t\t_mm512_setzero_si512 (),\n+\t\t\t\t\t\t\t(__mmask8) -\n+\t\t\t\t\t\t\t1);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_inserti64x2 (__m512i __W, __mmask8 __U, __m512i __A,\n+\t\t\t __m128i __B, const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_inserti64x2_512_mask ((__v8di) __A,\n+\t\t\t\t\t\t\t(__v2di) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v8di) __W,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_inserti64x2 (__mmask8 __U, __m512i __A, __m128i __B,\n+\t\t\t  const int __imm)\n+{\n+  return (__m512i) __builtin_ia32_inserti64x2_512_mask ((__v8di) __A,\n+\t\t\t\t\t\t\t(__v2di) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v8di)\n+\t\t\t\t\t\t\t_mm512_setzero_si512 (),\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_insertf64x2 (__m512d __A, __m128d __B, const int __imm)\n+{\n+  return (__m512d) __builtin_ia32_insertf64x2_512_mask ((__v8df) __A,\n+\t\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v8df)\n+\t\t\t\t\t\t\t_mm512_setzero_pd (),\n+\t\t\t\t\t\t\t(__mmask8) -\n+\t\t\t\t\t\t\t1);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_insertf64x2 (__m512d __W, __mmask8 __U, __m512d __A,\n+\t\t\t __m128d __B, const int __imm)\n+{\n+  return (__m512d) __builtin_ia32_insertf64x2_512_mask ((__v8df) __A,\n+\t\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v8df) __W,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m512d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_insertf64x2 (__mmask8 __U, __m512d __A, __m128d __B,\n+\t\t\t  const int __imm)\n+{\n+  return (__m512d) __builtin_ia32_insertf64x2_512_mask ((__v8df) __A,\n+\t\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v8df)\n+\t\t\t\t\t\t\t_mm512_setzero_pd (),\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fpclass_pd_mask (__mmask8 __U, __m512d __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclasspd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      __imm, __U);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fpclass_pd_mask (__m512d __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclasspd512_mask ((__v8df) __A,\n+\t\t\t\t\t\t      __imm,\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __mmask16\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fpclass_ps_mask (__mmask16 __U, __m512 __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__mmask16) __builtin_ia32_fpclassps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t       __imm, __U);\n+}\n+\n+extern __inline __mmask16\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fpclass_ps_mask (__m512 __A, const int __imm)\n+{\n+  return (__mmask16) __builtin_ia32_fpclassps512_mask ((__v16sf) __A,\n+\t\t\t\t\t\t       __imm,\n+\t\t\t\t\t\t       (__mmask16) -\n+\t\t\t\t\t\t       1);\n+}\n+\n+#else\n+#define _mm_range_sd(A, B, C)\t\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_rangesd128_round ((__v2df)(__m128d)(A),\t\\\n+    (__v2df)(__m128d)(B), (int)(C),\t\t\t\t\t\\\n+    _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm_range_ss(A, B, C)\t\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_rangess128_round ((__v4sf)(__m128)(A),\t\\\n+    (__v4sf)(__m128)(B), (int)(C),\t\t\t\t\t\\\n+    _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm_range_round_sd(A, B, C, R)\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_rangesd128_round ((__v2df)(__m128d)(A),\t\\\n+    (__v2df)(__m128d)(B), (int)(C), (R)))\n+\n+#define _mm_range_round_ss(A, B, C, R)\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_rangess128_round ((__v4sf)(__m128)(A),\t\\\n+    (__v4sf)(__m128)(B), (int)(C), (R)))\n+\n+#define _mm512_cvtt_roundpd_epi64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvttpd2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvtt_roundpd_epi64(W, U, A, B)  \\\n+    ((__m512i)__builtin_ia32_cvttpd2qq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvtt_roundpd_epi64(U, A, B)    \\\n+    ((__m512i)__builtin_ia32_cvttpd2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvtt_roundpd_epu64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvttpd2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvtt_roundpd_epu64(W, U, A, B)  \\\n+    ((__m512i)__builtin_ia32_cvttpd2uqq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvtt_roundpd_epu64(U, A, B)    \\\n+    ((__m512i)__builtin_ia32_cvttpd2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvtt_roundps_epi64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvttps2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvtt_roundps_epi64(W, U, A, B)  \\\n+    ((__m512i)__builtin_ia32_cvttps2qq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvtt_roundps_epi64(U, A, B)    \\\n+    ((__m512i)__builtin_ia32_cvttps2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvtt_roundps_epu64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvttps2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvtt_roundps_epu64(W, U, A, B)  \\\n+    ((__m512i)__builtin_ia32_cvttps2uqq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvtt_roundps_epu64(U, A, B)    \\\n+    ((__m512i)__builtin_ia32_cvttps2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvt_roundpd_epi64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvtpd2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundpd_epi64(W, U, A, B)   \\\n+    ((__m512i)__builtin_ia32_cvtpd2qq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundpd_epi64(U, A, B)     \\\n+    ((__m512i)__builtin_ia32_cvtpd2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvt_roundpd_epu64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvtpd2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundpd_epu64(W, U, A, B)   \\\n+    ((__m512i)__builtin_ia32_cvtpd2uqq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundpd_epu64(U, A, B)     \\\n+    ((__m512i)__builtin_ia32_cvtpd2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvt_roundps_epi64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvtps2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundps_epi64(W, U, A, B)   \\\n+    ((__m512i)__builtin_ia32_cvtps2qq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundps_epi64(U, A, B)     \\\n+    ((__m512i)__builtin_ia32_cvtps2qq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvt_roundps_epu64(A, B)\t\t    \\\n+    ((__m512i)__builtin_ia32_cvtps2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundps_epu64(W, U, A, B)   \\\n+    ((__m512i)__builtin_ia32_cvtps2uqq512_mask((A), (__v8di)(W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundps_epu64(U, A, B)     \\\n+    ((__m512i)__builtin_ia32_cvtps2uqq512_mask((A), (__v8di)_mm512_setzero_si512 (), (U), (B)))\n+\n+#define _mm512_cvt_roundepi64_ps(A, B)\t\t    \\\n+    ((__m256)__builtin_ia32_cvtqq2ps512_mask((__v8di)(A), (__v8sf)_mm256_setzero_ps(), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundepi64_ps(W, U, A, B)   \\\n+    ((__m256)__builtin_ia32_cvtqq2ps512_mask((__v8di)(A), (W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundepi64_ps(U, A, B)     \\\n+    ((__m256)__builtin_ia32_cvtqq2ps512_mask((__v8di)(A), (__v8sf)_mm256_setzero_ps(), (U), (B)))\n+\n+#define _mm512_cvt_roundepu64_ps(A, B)\t\t    \\\n+    ((__m256)__builtin_ia32_cvtuqq2ps512_mask((__v8di)(A), (__v8sf)_mm256_setzero_ps(), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundepu64_ps(W, U, A, B)   \\\n+    ((__m256)__builtin_ia32_cvtuqq2ps512_mask((__v8di)(A), (W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundepu64_ps(U, A, B)     \\\n+    ((__m256)__builtin_ia32_cvtuqq2ps512_mask((__v8di)(A), (__v8sf)_mm256_setzero_ps(), (U), (B)))\n+\n+#define _mm512_cvt_roundepi64_pd(A, B)\t\t    \\\n+    ((__m512d)__builtin_ia32_cvtqq2pd512_mask((__v8di)(A), (__v8df)_mm512_setzero_pd(), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundepi64_pd(W, U, A, B)   \\\n+    ((__m512d)__builtin_ia32_cvtqq2pd512_mask((__v8di)(A), (W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundepi64_pd(U, A, B)     \\\n+    ((__m512d)__builtin_ia32_cvtqq2pd512_mask((__v8di)(A), (__v8df)_mm512_setzero_pd(), (U), (B)))\n+\n+#define _mm512_cvt_roundepu64_pd(A, B)\t\t    \\\n+    ((__m512d)__builtin_ia32_cvtuqq2pd512_mask((__v8di)(A), (__v8df)_mm512_setzero_pd(), -1, (B)))\n+\n+#define _mm512_mask_cvt_roundepu64_pd(W, U, A, B)   \\\n+    ((__m512d)__builtin_ia32_cvtuqq2pd512_mask((__v8di)(A), (W), (U), (B)))\n+\n+#define _mm512_maskz_cvt_roundepu64_pd(U, A, B)     \\\n+    ((__m512d)__builtin_ia32_cvtuqq2pd512_mask((__v8di)(A), (__v8df)_mm512_setzero_pd(), (U), (B)))\n+\n+#define _mm512_reduce_pd(A, B)\t\t\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_reducepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (int)(B), (__v8df)_mm512_setzero_pd(), (__mmask8)-1))\n+\n+#define _mm512_mask_reduce_pd(W, U, A, B)\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_reducepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (int)(B), (__v8df)(__m512d)(W), (__mmask8)(U)))\n+\n+#define _mm512_maskz_reduce_pd(U, A, B)\t\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_reducepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (int)(B), (__v8df)_mm512_setzero_pd(), (__mmask8)(U)))\n+\n+#define _mm512_reduce_ps(A, B)\t\t\t\t\t\t\\\n+  ((__m512) __builtin_ia32_reduceps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (int)(B), (__v16sf)_mm512_setzero_ps(), (__mmask16)-1))\n+\n+#define _mm512_mask_reduce_ps(W, U, A, B)\t\t\t\t\\\n+  ((__m512) __builtin_ia32_reduceps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (int)(B), (__v16sf)(__m512)(W), (__mmask16)(U)))\n+\n+#define _mm512_maskz_reduce_ps(U, A, B)\t\t\t\t\t\\\n+  ((__m512) __builtin_ia32_reduceps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (int)(B), (__v16sf)_mm512_setzero_ps(), (__mmask16)(U)))\n+\n+#define _mm512_extractf32x8_ps(X, C)                                    \\\n+  ((__m256) __builtin_ia32_extractf32x8_mask ((__v16sf)(__m512) (X),    \\\n+    (int) (C), (__v8sf)(__m256) _mm256_setzero_ps(), (__mmask8)-1))\n+\n+#define _mm512_mask_extractf32x8_ps(W, U, X, C)                         \\\n+  ((__m256) __builtin_ia32_extractf32x8_mask ((__v16sf)(__m512) (X),    \\\n+    (int) (C), (__v8sf)(__m256) (W), (__mmask8) (U)))\n+\n+#define _mm512_maskz_extractf32x8_ps(U, X, C)                           \\\n+  ((__m256) __builtin_ia32_extractf32x8_mask ((__v16sf)(__m512) (X),    \\\n+    (int) (C), (__v8sf)(__m256) _mm256_setzero_ps(), (__mmask8) (U)))\n+\n+#define _mm512_extractf64x2_pd(X, C)                                    \\\n+  ((__m128d) __builtin_ia32_extractf64x2_512_mask ((__v8df)(__m512d) (X),\\\n+    (int) (C), (__v2df)(__m128d) _mm_setzero_pd(), (__mmask8)-1))\n+\n+#define _mm512_mask_extractf64x2_pd(W, U, X, C)                         \\\n+  ((__m128d) __builtin_ia32_extractf64x2_512_mask ((__v8df)(__m512d) (X),\\\n+    (int) (C), (__v2df)(__m128d) (W), (__mmask8) (U)))\n+\n+#define _mm512_maskz_extractf64x2_pd(U, X, C)                           \\\n+  ((__m128d) __builtin_ia32_extractf64x2_512_mask ((__v8df)(__m512d) (X),\\\n+    (int) (C), (__v2df)(__m128d) _mm_setzero_pd(), (__mmask8) (U)))\n+\n+#define _mm512_extracti32x8_epi32(X, C)                                 \\\n+  ((__m256i) __builtin_ia32_extracti32x8_mask ((__v16si)(__m512i) (X),  \\\n+    (int) (C), (__v8si)(__m256i) _mm256_setzero_si256(), (__mmask8)-1))\n+\n+#define _mm512_mask_extracti32x8_epi32(W, U, X, C)                      \\\n+  ((__m256i) __builtin_ia32_extracti32x8_mask ((__v16si)(__m512i) (X),  \\\n+    (int) (C), (__v8si)(__m256i) (W), (__mmask8) (U)))\n+\n+#define _mm512_maskz_extracti32x8_epi32(U, X, C)                        \\\n+  ((__m256i) __builtin_ia32_extracti32x8_mask ((__v16si)(__m512i) (X),  \\\n+    (int) (C), (__v8si)(__m256i) _mm256_setzero_si256(), (__mmask8) (U)))\n+\n+#define _mm512_extracti64x2_epi64(X, C)                                 \\\n+  ((__m128i) __builtin_ia32_extracti64x2_512_mask ((__v8di)(__m512i) (X),\\\n+    (int) (C), (__v2di)(__m128i) _mm_setzero_di(), (__mmask8)-1))\n+\n+#define _mm512_mask_extracti64x2_epi64(W, U, X, C)                      \\\n+  ((__m128i) __builtin_ia32_extracti64x2_512_mask ((__v8di)(__m512i) (X),\\\n+    (int) (C), (__v2di)(__m128i) (W), (__mmask8) (U)))\n+\n+#define _mm512_maskz_extracti64x2_epi64(U, X, C)                        \\\n+  ((__m128i) __builtin_ia32_extracti64x2_512_mask ((__v8di)(__m512i) (X),\\\n+    (int) (C), (__v2di)(__m128i) _mm_setzero_di(), (__mmask8) (U)))\n+\n+#define _mm512_range_pd(A, B, C)\t\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_rangepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (__v8df)(__m512d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8df)_mm512_setzero_pd(), (__mmask8)-1, _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm512_mask_range_pd(W, U, A, B, C)\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_rangepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (__v8df)(__m512d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8df)(__m512d)(W), (__mmask8)(U), _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm512_maskz_range_pd(U, A, B, C)\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_rangepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (__v8df)(__m512d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8df)_mm512_setzero_pd(), (__mmask8)(U), _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm512_range_ps(A, B, C)\t\t\t\t\t\\\n+  ((__m512) __builtin_ia32_rangeps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (__v16sf)(__m512)(B), (int)(C),\t\t\t\t\t\\\n+    (__v16sf)_mm512_setzero_ps(), (__mmask16)-1, _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm512_mask_range_ps(W, U, A, B, C)\t\t\t\t\\\n+  ((__m512) __builtin_ia32_rangeps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (__v16sf)(__m512)(B), (int)(C),\t\t\t\t\t\\\n+    (__v16sf)(__m512)(W), (__mmask16)(U), _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm512_maskz_range_ps(U, A, B, C)\t\t\t\t\\\n+  ((__m512) __builtin_ia32_rangeps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (__v16sf)(__m512)(B), (int)(C),\t\t\t\t\t\\\n+    (__v16sf)_mm512_setzero_ps(), (__mmask16)(U), _MM_FROUND_CUR_DIRECTION))\n+\n+#define _mm512_range_round_pd(A, B, C, R)\t\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_rangepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (__v8df)(__m512d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8df)_mm512_setzero_pd(), (__mmask8)-1, (R)))\n+\n+#define _mm512_mask_range_round_pd(W, U, A, B, C, R)\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_rangepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (__v8df)(__m512d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8df)(__m512d)(W), (__mmask8)(U), (R)))\n+\n+#define _mm512_maskz_range_round_pd(U, A, B, C, R)\t\t\t\t\\\n+  ((__m512d) __builtin_ia32_rangepd512_mask ((__v8df)(__m512d)(A),\t\\\n+    (__v8df)(__m512d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8df)_mm512_setzero_pd(), (__mmask8)(U), (R)))\n+\n+#define _mm512_range_round_ps(A, B, C, R)\t\t\t\t\t\\\n+  ((__m512) __builtin_ia32_rangeps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (__v16sf)(__m512)(B), (int)(C),\t\t\t\t\t\\\n+    (__v16sf)_mm512_setzero_ps(), (__mmask16)-1, (R)))\n+\n+#define _mm512_mask_range_round_ps(W, U, A, B, C, R)\t\t\t\t\\\n+  ((__m512) __builtin_ia32_rangeps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (__v16sf)(__m512)(B), (int)(C),\t\t\t\t\t\\\n+    (__v16sf)(__m512)(W), (__mmask16)(U), (R)))\n+\n+#define _mm512_maskz_range_round_ps(U, A, B, C, R)\t\t\t\t\\\n+  ((__m512) __builtin_ia32_rangeps512_mask ((__v16sf)(__m512)(A),\t\\\n+    (__v16sf)(__m512)(B), (int)(C),\t\t\t\t\t\\\n+    (__v16sf)_mm512_setzero_ps(), (__mmask16)(U), (R)))\n+\n+#define _mm512_insertf64x2(X, Y, C)                                     \\\n+  ((__m512d) __builtin_ia32_insertf64x2_512_mask ((__v8df)(__m512d) (X),\\\n+    (__v2df)(__m128d) (Y), (int) (C), (__v8df)(__m512d) (X),            \\\n+    (__mmask8)-1))\n+\n+#define _mm512_mask_insertf64x2(W, U, X, Y, C)                          \\\n+  ((__m512d) __builtin_ia32_insertf64x2_512_mask ((__v8df)(__m512d) (X),\\\n+    (__v2df)(__m128d) (Y), (int) (C), (__v8df)(__m512d) (W),            \\\n+    (__mmask8) (U)))\n+\n+#define _mm512_maskz_insertf64x2(U, X, Y, C)                            \\\n+  ((__m512d) __builtin_ia32_insertf64x2_512_mask ((__v8df)(__m512d) (X),\\\n+    (__v2df)(__m128d) (Y), (int) (C),                                   \\\n+    (__v8df)(__m512d) _mm512_setzero_pd(), (__mmask8) (U)))\n+\n+#define _mm512_inserti64x2(X, Y, C)                                     \\\n+  ((__m512i) __builtin_ia32_inserti64x2_512_mask ((__v8di)(__m512i) (X),\\\n+    (__v2di)(__m128i) (Y), (int) (C), (__v8di)(__m512i) (X), (__mmask8)-1))\n+\n+#define _mm512_mask_inserti64x2(W, U, X, Y, C)                          \\\n+  ((__m512i) __builtin_ia32_inserti64x2_512_mask ((__v8di)(__m512i) (X),\\\n+    (__v2di)(__m128i) (Y), (int) (C), (__v8di)(__m512i) (W),            \\\n+    (__mmask8) (U)))\n+\n+#define _mm512_maskz_inserti64x2(U, X, Y, C)                            \\\n+  ((__m512i) __builtin_ia32_inserti64x2_512_mask ((__v8di)(__m512i) (X),\\\n+    (__v2di)(__m128i) (Y), (int) (C),                                   \\\n+    (__v8di)(__m512i) _mm512_setzero_si512 (), (__mmask8) (U)))\n+\n+#define _mm512_insertf32x8(X, Y, C)                                     \\\n+  ((__m512) __builtin_ia32_insertf32x8_mask ((__v16sf)(__m512) (X),     \\\n+    (__v8sf)(__m256) (Y), (int) (C),\\\n+    (__v16sf)(__m512)_mm512_setzero_ps(),\\\n+    (__mmask16)-1))\n+\n+#define _mm512_mask_insertf32x8(W, U, X, Y, C)                          \\\n+  ((__m512) __builtin_ia32_insertf32x8_mask ((__v16sf)(__m512) (X),     \\\n+    (__v8sf)(__m256) (Y), (int) (C),\\\n+    (__v16sf)(__m512)(W),\\\n+    (__mmask16)(U)))\n+\n+#define _mm512_maskz_insertf32x8(U, X, Y, C)                            \\\n+  ((__m512) __builtin_ia32_insertf32x8_mask ((__v16sf)(__m512) (X),     \\\n+    (__v8sf)(__m256) (Y), (int) (C),\\\n+    (__v16sf)(__m512)_mm512_setzero_ps(),\\\n+    (__mmask16)(U)))\n+\n+#define _mm512_inserti32x8(X, Y, C)                                     \\\n+  ((__m512i) __builtin_ia32_inserti32x8_mask ((__v16si)(__m512i) (X),   \\\n+    (__v8si)(__m256i) (Y), (int) (C),\\\n+    (__v16si)(__m512i)_mm512_setzero_si512 (),\\\n+    (__mmask16)-1))\n+\n+#define _mm512_mask_inserti32x8(W, U, X, Y, C)                          \\\n+  ((__m512i) __builtin_ia32_inserti32x8_mask ((__v16si)(__m512i) (X),   \\\n+    (__v8si)(__m256i) (Y), (int) (C),\\\n+    (__v16si)(__m512i)(W),\\\n+    (__mmask16)(U)))\n+\n+#define _mm512_maskz_inserti32x8(U, X, Y, C)                            \\\n+  ((__m512i) __builtin_ia32_inserti32x8_mask ((__v16si)(__m512i) (X),   \\\n+    (__v8si)(__m256i) (Y), (int) (C),\\\n+    (__v16si)(__m512i)_mm512_setzero_si512 (),\\\n+    (__mmask16)(U)))\n+\n+#define _mm_fpclass_ss_mask(X, C)\t\t\t\t\t\t\\\n+  ((__mmask8) __builtin_ia32_fpclassss ((__v4sf) (__m128) (X), (int) (C)))  \\\n+\n+#define _mm_fpclass_sd_mask(X, C)\t\t\t\t\t\t\\\n+  ((__mmask8) __builtin_ia32_fpclasssd ((__v2df) (__m128d) (X), (int) (C))) \\\n+\n+#define _mm512_mask_fpclass_pd_mask(u, X, C)                            \\\n+  ((__mmask8) __builtin_ia32_fpclasspd512_mask ((__v8df) (__m512d) (X), \\\n+\t\t\t\t\t\t(int) (C), (__mmask8)(u)))\n+\n+#define _mm512_mask_fpclass_ps_mask(u, x, c)\t\t\t\t\\\n+  ((__mmask16) __builtin_ia32_fpclassps512_mask ((__v16sf) (__m512) (x),\\\n+\t\t\t\t\t\t (int) (c),(__mmask8)(u)))\n+\n+#define _mm512_fpclass_pd_mask(X, C)                                    \\\n+  ((__mmask8) __builtin_ia32_fpclasspd512_mask ((__v8df) (__m512d) (X), \\\n+\t\t\t\t\t\t(int) (C), (__mmask8)-1))\n+\n+#define _mm512_fpclass_ps_mask(x, c)                                    \\\n+  ((__mmask16) __builtin_ia32_fpclassps512_mask ((__v16sf) (__m512) (x),\\\n+\t\t\t\t\t\t (int) (c),(__mmask8)-1))\n+\n+#define _mm_reduce_sd(A, B, C)\t\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_reducesd ((__v2df)(__m128d)(A),\t\\\n+    (__v2df)(__m128d)(B), (int)(C)))\t\t\t\t\t\\\n+\n+#define _mm_reduce_ss(A, B, C)\t\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_reducess ((__v4sf)(__m128)(A),\t\t\\\n+    (__v4sf)(__m128)(A), (int)(C)))\t\t\t\t\t\\\n+\n+#endif\n+\n+#ifdef __DISABLE_AVX512DQ__\n+#undef __DISABLE_AVX512DQ__\n+#pragma GCC pop_options\n+#endif /* __DISABLE_AVX512DQ__ */\n+\n+#endif /* _AVX512DQINTRIN_H_INCLUDED */"}, {"sha": "1a4fe2ca2c6274c2bde735df321099f15aa8944b", "filename": "gcc/config/i386/avx512vlbwintrin.h", "status": "added", "additions": 4224, "deletions": 0, "changes": 4224, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512vlbwintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512vlbwintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512vlbwintrin.h?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589"}, {"sha": "43a7388a633e60860ce6e846e7c6e50ed47020f9", "filename": "gcc/config/i386/avx512vldqintrin.h", "status": "added", "additions": 2034, "deletions": 0, "changes": 2034, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512vldqintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512vldqintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512vldqintrin.h?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589", "patch": "@@ -0,0 +1,2034 @@\n+/* Copyright (C) 2014\n+   Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify\n+   it under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   Under Section 7 of GPL version 3, you are granted additional\n+   permissions described in the GCC Runtime Library Exception, version\n+   3.1, as published by the Free Software Foundation.\n+\n+   You should have received a copy of the GNU General Public License and\n+   a copy of the GCC Runtime Library Exception along with this program;\n+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#ifndef _IMMINTRIN_H_INCLUDED\n+#error \"Never use <avx512vldqintrin.h> directly; include <immintrin.h> instead.\"\n+#endif\n+\n+#ifndef _AVX512VLDQINTRIN_H_INCLUDED\n+#define _AVX512VLDQINTRIN_H_INCLUDED\n+\n+#if !defined(__AVX512VL__) || !defined(__AVX512DQ__)\n+#pragma GCC push_options\n+#pragma GCC target(\"avx512vl,avx512dq\")\n+#define __DISABLE_AVX512VLDQ__\n+#endif /* __AVX512VLDQ__ */\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvttpd_epi64 (__m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvttpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t     (__v4di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvttpd_epi64 (__mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvttpd_epi64 (__m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_di (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvttpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t     (__v2di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvttpd_epi64 (__mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_si128 (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvttpd_epu64 (__m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t      (__v4di)\n+\t\t\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvttpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t      (__v4di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvttpd_epu64 (__mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t      (__v4di)\n+\t\t\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvttpd_epu64 (__m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t      (__v2di)\n+\t\t\t\t\t\t      _mm_setzero_di (),\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvttpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t      (__v2di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvttpd_epu64 (__mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t      (__v2di)\n+\t\t\t\t\t\t      _mm_setzero_si128 (),\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtpd_epi64 (__m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t    (__v4di)\n+\t\t\t\t\t\t    _mm256_setzero_si256 (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t    (__v4di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtpd_epi64 (__mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t    (__v4di)\n+\t\t\t\t\t\t    _mm256_setzero_si256 (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtpd_epi64 (__m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t    (__v2di)\n+\t\t\t\t\t\t    _mm_setzero_di (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t    (__v2di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtpd_epi64 (__mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t    (__v2di)\n+\t\t\t\t\t\t    _mm_setzero_si128 (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtpd_epu64 (__m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t     (__v4di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtpd_epu64 (__mmask8 __U, __m256d __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtpd_epu64 (__m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_di (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t     (__v2di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtpd_epu64 (__mmask8 __U, __m128d __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_si128 (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvttps_epi64 (__m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvttps_epi64 (__m256i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v4di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvttps_epi64 (__m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_di (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvttps_epi64 (__m128i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v2di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_di (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvttps_epu64 (__m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      (__v4di)\n+\t\t\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvttps_epu64 (__m256i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      (__v4di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      (__v4di)\n+\t\t\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvttps_epu64 (__m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      (__v2di)\n+\t\t\t\t\t\t      _mm_setzero_di (),\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvttps_epu64 (__m128i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      (__v2di) __W,\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      (__v2di)\n+\t\t\t\t\t\t      _mm_setzero_di (),\n+\t\t\t\t\t\t      (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcast_f64x2 (__m128d __A)\n+{\n+  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t           (__v4df)_mm256_undefined_pd(),\n+\t\t\t\t\t\t\t   (__mmask8) -\n+\t\t\t\t\t\t\t   1);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_broadcast_f64x2 (__m256d __O, __mmask8 __M, __m128d __A)\n+{\n+  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v4df)\n+\t\t\t\t\t\t\t   __O, __M);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_broadcast_f64x2 (__mmask8 __M, __m128d __A)\n+{\n+  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v4df)\n+\t\t\t\t\t\t\t   _mm256_setzero_ps (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcast_i64x2 (__m128i __A)\n+{\n+  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t           (__v4di)_mm256_undefined_si256(),\n+\t\t\t\t\t\t\t   (__mmask8) -\n+\t\t\t\t\t\t\t   1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_broadcast_i64x2 (__m256i __O, __mmask8 __M, __m128i __A)\n+{\n+  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v4di)\n+\t\t\t\t\t\t\t   __O, __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_broadcast_i64x2 (__mmask8 __M, __m128i __A)\n+{\n+  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v4di)\n+\t\t\t\t\t\t\t   _mm256_setzero_si256 (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcast_f32x2 (__m128 __A)\n+{\n+  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t          (__v8sf)_mm256_undefined_ps(),\n+\t\t\t\t\t\t\t  (__mmask16) -\n+\t\t\t\t\t\t\t  1);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_broadcast_f32x2 (__m256 __O, __mmask8 __M, __m128 __A)\n+{\n+  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t\t  (__v8sf) __O,\n+\t\t\t\t\t\t\t  __M);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_broadcast_f32x2 (__mmask8 __M, __m128 __A)\n+{\n+  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t\t  (__v8sf)\n+\t\t\t\t\t\t\t  _mm256_setzero_ps (),\n+\t\t\t\t\t\t\t  __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcast_i32x2 (__m128i __A)\n+{\n+  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t          (__v8si)_mm256_undefined_si256(),\n+\t\t\t\t\t\t\t   (__mmask8) -\n+\t\t\t\t\t\t\t   1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_broadcast_i32x2 (__m256i __O, __mmask8 __M, __m128i __A)\n+{\n+  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v8si)\n+\t\t\t\t\t\t\t   __O, __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)\n+{\n+  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v8si)\n+\t\t\t\t\t\t\t   _mm256_setzero_si256 (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_broadcast_i32x2 (__m128i __A)\n+{\n+  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t          (__v4si)_mm_undefined_si128(),\n+\t\t\t\t\t\t\t   (__mmask8) -\n+\t\t\t\t\t\t\t   1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_broadcast_i32x2 (__m128i __O, __mmask8 __M, __m128i __A)\n+{\n+  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v4si)\n+\t\t\t\t\t\t\t   __O, __M);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)\n+{\n+  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)\n+\t\t\t\t\t\t\t   __A,\n+\t\t\t\t\t\t\t   (__v4si)\n+\t\t\t\t\t\t\t   _mm_setzero_si128 (),\n+\t\t\t\t\t\t\t   __M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mullo_epi64 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,\n+\t\t\t\t\t\t  (__v4di) __B,\n+\t\t\t\t\t\t  (__v4di)\n+\t\t\t\t\t\t  _mm256_setzero_si256 (),\n+\t\t\t\t\t\t  (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_mullo_epi64 (__m256i __W, __mmask8 __U, __m256i __A,\n+\t\t\t __m256i __B)\n+{\n+  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,\n+\t\t\t\t\t\t  (__v4di) __B,\n+\t\t\t\t\t\t  (__v4di) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_mullo_epi64 (__mmask8 __U, __m256i __A, __m256i __B)\n+{\n+  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,\n+\t\t\t\t\t\t  (__v4di) __B,\n+\t\t\t\t\t\t  (__v4di)\n+\t\t\t\t\t\t  _mm256_setzero_si256 (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mullo_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,\n+\t\t\t\t\t\t  (__v2di) __B,\n+\t\t\t\t\t\t  (__v2di)\n+\t\t\t\t\t\t  _mm_setzero_di (),\n+\t\t\t\t\t\t  (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_mullo_epi64 (__m128i __W, __mmask8 __U, __m128i __A,\n+\t\t      __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,\n+\t\t\t\t\t\t  (__v2di) __B,\n+\t\t\t\t\t\t  (__v2di) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_mullo_epi64 (__mmask8 __U, __m128i __A, __m128i __B)\n+{\n+  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,\n+\t\t\t\t\t\t  (__v2di) __B,\n+\t\t\t\t\t\t  (__v2di)\n+\t\t\t\t\t\t  _mm_setzero_di (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_andnot_pd (__m256d __W, __mmask8 __U, __m256d __A,\n+\t\t       __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t  (__v4df) __B,\n+\t\t\t\t\t\t  (__v4df) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_andnot_pd (__mmask8 __U, __m256d __A, __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t  (__v4df) __B,\n+\t\t\t\t\t\t  (__v4df)\n+\t\t\t\t\t\t  _mm256_setzero_pd (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_andnot_pd (__m128d __W, __mmask8 __U, __m128d __A,\n+\t\t    __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t  (__v2df) __B,\n+\t\t\t\t\t\t  (__v2df) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_andnot_pd (__mmask8 __U, __m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t  (__v2df) __B,\n+\t\t\t\t\t\t  (__v2df)\n+\t\t\t\t\t\t  _mm_setzero_pd (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_andnot_ps (__m256 __W, __mmask8 __U, __m256 __A,\n+\t\t       __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t (__v8sf) __B,\n+\t\t\t\t\t\t (__v8sf) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_andnot_ps (__mmask8 __U, __m256 __A, __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t (__v8sf) __B,\n+\t\t\t\t\t\t (__v8sf)\n+\t\t\t\t\t\t _mm256_setzero_ps (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_andnot_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t (__v4sf) __B,\n+\t\t\t\t\t\t (__v4sf) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_andnot_ps (__mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t (__v4sf) __B,\n+\t\t\t\t\t\t (__v4sf)\n+\t\t\t\t\t\t _mm_setzero_ps (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtps_epi64 (__m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t    (__v4di)\n+\t\t\t\t\t\t    _mm256_setzero_si256 (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtps_epi64 (__m256i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t    (__v4di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t    (__v4di)\n+\t\t\t\t\t\t    _mm256_setzero_si256 (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtps_epi64 (__m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t    (__v2di)\n+\t\t\t\t\t\t    _mm_setzero_di (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtps_epi64 (__m128i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t    (__v2di) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t    (__v2di)\n+\t\t\t\t\t\t    _mm_setzero_di (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtps_epu64 (__m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtps_epu64 (__m256i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v4di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v4di)\n+\t\t\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtps_epu64 (__m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_di (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtps_epu64 (__m128i __W, __mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v2di) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t     (__v2di)\n+\t\t\t\t\t\t     _mm_setzero_di (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi64_ps (__m256i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,\n+\t\t\t\t\t\t   (__v4sf)\n+\t\t\t\t\t\t   _mm_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) -1);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m256i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,\n+\t\t\t\t\t\t   (__v4sf) __W,\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtepi64_ps (__mmask8 __U, __m256i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,\n+\t\t\t\t\t\t   (__v4sf)\n+\t\t\t\t\t\t   _mm_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtepi64_ps (__m128i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,\n+\t\t\t\t\t\t   (__v4sf)\n+\t\t\t\t\t\t   _mm_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) -1);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m128i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,\n+\t\t\t\t\t\t   (__v4sf) __W,\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtepi64_ps (__mmask8 __U, __m128i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,\n+\t\t\t\t\t\t   (__v4sf)\n+\t\t\t\t\t\t   _mm_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu64_ps (__m256i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,\n+\t\t\t\t\t\t    (__v4sf)\n+\t\t\t\t\t\t    _mm_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m256i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,\n+\t\t\t\t\t\t    (__v4sf) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtepu64_ps (__mmask8 __U, __m256i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,\n+\t\t\t\t\t\t    (__v4sf)\n+\t\t\t\t\t\t    _mm_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtepu64_ps (__m128i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,\n+\t\t\t\t\t\t    (__v4sf)\n+\t\t\t\t\t\t    _mm_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m128i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,\n+\t\t\t\t\t\t    (__v4sf) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtepu64_ps (__mmask8 __U, __m128i __A)\n+{\n+  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,\n+\t\t\t\t\t\t    (__v4sf)\n+\t\t\t\t\t\t    _mm_setzero_ps (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi64_pd (__m256i __A)\n+{\n+  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,\n+\t\t\t\t\t\t    (__v4df)\n+\t\t\t\t\t\t    _mm256_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtepi64_pd (__m256d __W, __mmask8 __U, __m256i __A)\n+{\n+  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,\n+\t\t\t\t\t\t    (__v4df) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtepi64_pd (__mmask8 __U, __m256i __A)\n+{\n+  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,\n+\t\t\t\t\t\t    (__v4df)\n+\t\t\t\t\t\t    _mm256_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtepi64_pd (__m128i __A)\n+{\n+  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,\n+\t\t\t\t\t\t    (__v2df)\n+\t\t\t\t\t\t    _mm_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtepi64_pd (__m128d __W, __mmask8 __U, __m128i __A)\n+{\n+  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,\n+\t\t\t\t\t\t    (__v2df) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtepi64_pd (__mmask8 __U, __m128i __A)\n+{\n+  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,\n+\t\t\t\t\t\t    (__v2df)\n+\t\t\t\t\t\t    _mm_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu64_pd (__m256i __A)\n+{\n+  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,\n+\t\t\t\t\t\t     (__v4df)\n+\t\t\t\t\t\t     _mm256_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtepu64_pd (__m256d __W, __mmask8 __U, __m256i __A)\n+{\n+  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,\n+\t\t\t\t\t\t     (__v4df) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtepu64_pd (__mmask8 __U, __m256i __A)\n+{\n+  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,\n+\t\t\t\t\t\t     (__v4df)\n+\t\t\t\t\t\t     _mm256_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_and_pd (__m256d __W, __mmask8 __U, __m256d __A,\n+\t\t    __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t (__v4df) __B,\n+\t\t\t\t\t\t (__v4df) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_and_pd (__mmask8 __U, __m256d __A, __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t (__v4df) __B,\n+\t\t\t\t\t\t (__v4df)\n+\t\t\t\t\t\t _mm256_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_and_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t (__v2df) __B,\n+\t\t\t\t\t\t (__v2df) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_and_pd (__mmask8 __U, __m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t (__v2df) __B,\n+\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t _mm_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_and_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t(__v8sf) __B,\n+\t\t\t\t\t\t(__v8sf) __W,\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_and_ps (__mmask8 __U, __m256 __A, __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t(__v8sf) __B,\n+\t\t\t\t\t\t(__v8sf)\n+\t\t\t\t\t\t_mm256_setzero_ps (),\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_and_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t(__v4sf) __B,\n+\t\t\t\t\t\t(__v4sf) __W,\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_and_ps (__mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t(__v4sf) __B,\n+\t\t\t\t\t\t(__v4sf)\n+\t\t\t\t\t\t_mm_setzero_ps (),\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtepu64_pd (__m128i __A)\n+{\n+  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,\n+\t\t\t\t\t\t     (__v2df)\n+\t\t\t\t\t\t     _mm_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtepu64_pd (__m128d __W, __mmask8 __U, __m128i __A)\n+{\n+  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,\n+\t\t\t\t\t\t     (__v2df) __W,\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtepu64_pd (__mmask8 __U, __m128i __A)\n+{\n+  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,\n+\t\t\t\t\t\t     (__v2df)\n+\t\t\t\t\t\t     _mm_setzero_pd (),\n+\t\t\t\t\t\t     (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_xor_pd (__m256d __W, __mmask8 __U, __m256d __A,\n+\t\t    __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t (__v4df) __B,\n+\t\t\t\t\t\t (__v4df) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_xor_pd (__mmask8 __U, __m256d __A, __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t (__v4df) __B,\n+\t\t\t\t\t\t (__v4df)\n+\t\t\t\t\t\t _mm256_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_xor_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t (__v2df) __B,\n+\t\t\t\t\t\t (__v2df) __W,\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_xor_pd (__mmask8 __U, __m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t (__v2df) __B,\n+\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t _mm_setzero_pd (),\n+\t\t\t\t\t\t (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_xor_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t(__v8sf) __B,\n+\t\t\t\t\t\t(__v8sf) __W,\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_xor_ps (__mmask8 __U, __m256 __A, __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t(__v8sf) __B,\n+\t\t\t\t\t\t(__v8sf)\n+\t\t\t\t\t\t_mm256_setzero_ps (),\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_xor_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t(__v4sf) __B,\n+\t\t\t\t\t\t(__v4sf) __W,\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_xor_ps (__mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t(__v4sf) __B,\n+\t\t\t\t\t\t(__v4sf)\n+\t\t\t\t\t\t_mm_setzero_ps (),\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_or_pd (__m256d __W, __mmask8 __U, __m256d __A, __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t(__v4df) __B,\n+\t\t\t\t\t\t(__v4df) __W,\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_or_pd (__mmask8 __U, __m256d __A, __m256d __B)\n+{\n+  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t(__v4df) __B,\n+\t\t\t\t\t\t(__v4df)\n+\t\t\t\t\t\t_mm256_setzero_pd (),\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_or_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t(__v2df) __W,\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_or_pd (__mmask8 __U, __m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t(__v2df)\n+\t\t\t\t\t\t_mm_setzero_pd (),\n+\t\t\t\t\t\t(__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_or_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,\n+\t\t\t\t\t       (__v8sf) __B,\n+\t\t\t\t\t       (__v8sf) __W,\n+\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_or_ps (__mmask8 __U, __m256 __A, __m256 __B)\n+{\n+  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,\n+\t\t\t\t\t       (__v8sf) __B,\n+\t\t\t\t\t       (__v8sf)\n+\t\t\t\t\t       _mm256_setzero_ps (),\n+\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_or_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,\n+\t\t\t\t\t       (__v4sf) __B,\n+\t\t\t\t\t       (__v4sf) __W,\n+\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_or_ps (__mmask8 __U, __m128 __A, __m128 __B)\n+{\n+  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,\n+\t\t\t\t\t       (__v4sf) __B,\n+\t\t\t\t\t       (__v4sf)\n+\t\t\t\t\t       _mm_setzero_ps (),\n+\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_movm_epi32 (__mmask8 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtmask2d128 (__A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_movm_epi32 (__mmask8 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtmask2d256 (__A);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_movm_epi64 (__mmask8 __A)\n+{\n+  return (__m128i) __builtin_ia32_cvtmask2q128 (__A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_movm_epi64 (__mmask8 __A)\n+{\n+  return (__m256i) __builtin_ia32_cvtmask2q256 (__A);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_movepi32_mask (__m128i __A)\n+{\n+  return (__mmask8) __builtin_ia32_cvtd2mask128 ((__v4si) __A);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_movepi32_mask (__m256i __A)\n+{\n+  return (__mmask8) __builtin_ia32_cvtd2mask256 ((__v8si) __A);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_movepi64_mask (__m128i __A)\n+{\n+  return (__mmask8) __builtin_ia32_cvtq2mask128 ((__v2di) __A);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_movepi64_mask (__m256i __A)\n+{\n+  return (__mmask8) __builtin_ia32_cvtq2mask256 ((__v4di) __A);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_extractf64x2_pd (__m256d __A, const int __imm)\n+{\n+  return (__m128d) __builtin_ia32_extractf64x2_256_mask ((__v4df) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t\t _mm_setzero_pd (),\n+\t\t\t\t\t\t\t (__mmask8) -\n+\t\t\t\t\t\t\t 1);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_extractf64x2_pd (__m128d __W, __mmask8 __U, __m256d __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__m128d) __builtin_ia32_extractf64x2_256_mask ((__v4df) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2df) __W,\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_extractf64x2_pd (__mmask8 __U, __m256d __A,\n+\t\t\t      const int __imm)\n+{\n+  return (__m128d) __builtin_ia32_extractf64x2_256_mask ((__v4df) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t\t _mm_setzero_pd (),\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_extracti64x2_epi64 (__m256i __A, const int __imm)\n+{\n+  return (__m128i) __builtin_ia32_extracti64x2_256_mask ((__v4di) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2di)\n+\t\t\t\t\t\t\t _mm_setzero_di (),\n+\t\t\t\t\t\t\t (__mmask8) -\n+\t\t\t\t\t\t\t 1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_extracti64x2_epi64 (__m128i __W, __mmask8 __U, __m256i __A,\n+\t\t\t\tconst int __imm)\n+{\n+  return (__m128i) __builtin_ia32_extracti64x2_256_mask ((__v4di) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2di) __W,\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_extracti64x2_epi64 (__mmask8 __U, __m256i __A,\n+\t\t\t\t const int __imm)\n+{\n+  return (__m128i) __builtin_ia32_extracti64x2_256_mask ((__v4di) __A,\n+\t\t\t\t\t\t\t __imm,\n+\t\t\t\t\t\t\t (__v2di)\n+\t\t\t\t\t\t\t _mm_setzero_di (),\n+\t\t\t\t\t\t\t (__mmask8)\n+\t\t\t\t\t\t\t __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_reduce_pd (__m256d __A, int __B)\n+{\n+  return (__m256d) __builtin_ia32_reducepd256_mask ((__v4df) __A, __B,\n+\t\t\t\t\t\t    (__v4df)\n+\t\t\t\t\t\t    _mm256_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_reduce_pd (__m256d __W, __mmask8 __U, __m256d __A, int __B)\n+{\n+  return (__m256d) __builtin_ia32_reducepd256_mask ((__v4df) __A, __B,\n+\t\t\t\t\t\t    (__v4df) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_reduce_pd (__mmask8 __U, __m256d __A, int __B)\n+{\n+  return (__m256d) __builtin_ia32_reducepd256_mask ((__v4df) __A, __B,\n+\t\t\t\t\t\t    (__v4df)\n+\t\t\t\t\t\t    _mm256_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_reduce_pd (__m128d __A, int __B)\n+{\n+  return (__m128d) __builtin_ia32_reducepd128_mask ((__v2df) __A, __B,\n+\t\t\t\t\t\t    (__v2df)\n+\t\t\t\t\t\t    _mm_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_reduce_pd (__m128d __W, __mmask8 __U, __m128d __A, int __B)\n+{\n+  return (__m128d) __builtin_ia32_reducepd128_mask ((__v2df) __A, __B,\n+\t\t\t\t\t\t    (__v2df) __W,\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_reduce_pd (__mmask8 __U, __m128d __A, int __B)\n+{\n+  return (__m128d) __builtin_ia32_reducepd128_mask ((__v2df) __A, __B,\n+\t\t\t\t\t\t    (__v2df)\n+\t\t\t\t\t\t    _mm_setzero_pd (),\n+\t\t\t\t\t\t    (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_reduce_ps (__m256 __A, int __B)\n+{\n+  return (__m256) __builtin_ia32_reduceps256_mask ((__v8sf) __A, __B,\n+\t\t\t\t\t\t   (__v8sf)\n+\t\t\t\t\t\t   _mm256_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) -1);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_reduce_ps (__m256 __W, __mmask8 __U, __m256 __A, int __B)\n+{\n+  return (__m256) __builtin_ia32_reduceps256_mask ((__v8sf) __A, __B,\n+\t\t\t\t\t\t   (__v8sf) __W,\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_reduce_ps (__mmask8 __U, __m256 __A, int __B)\n+{\n+  return (__m256) __builtin_ia32_reduceps256_mask ((__v8sf) __A, __B,\n+\t\t\t\t\t\t   (__v8sf)\n+\t\t\t\t\t\t   _mm256_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_reduce_ps (__m128 __A, int __B)\n+{\n+  return (__m128) __builtin_ia32_reduceps128_mask ((__v4sf) __A, __B,\n+\t\t\t\t\t\t   (__v4sf)\n+\t\t\t\t\t\t   _mm_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) -1);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_reduce_ps (__m128 __W, __mmask8 __U, __m128 __A, int __B)\n+{\n+  return (__m128) __builtin_ia32_reduceps128_mask ((__v4sf) __A, __B,\n+\t\t\t\t\t\t   (__v4sf) __W,\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_reduce_ps (__mmask8 __U, __m128 __A, int __B)\n+{\n+  return (__m128) __builtin_ia32_reduceps128_mask ((__v4sf) __A, __B,\n+\t\t\t\t\t\t   (__v4sf)\n+\t\t\t\t\t\t   _mm_setzero_ps (),\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_range_pd (__m256d __A, __m256d __B, int __C)\n+{\n+  return (__m256d) __builtin_ia32_rangepd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t   (__v4df) __B, __C,\n+\t\t\t\t\t\t   (__v4df)\n+\t\t\t\t\t\t   _mm256_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) -1);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_range_pd (__m256d __W, __mmask8 __U,\n+\t\t      __m256d __A, __m256d __B, int __C)\n+{\n+  return (__m256d) __builtin_ia32_rangepd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t   (__v4df) __B, __C,\n+\t\t\t\t\t\t   (__v4df) __W,\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_range_pd (__mmask8 __U, __m256d __A, __m256d __B, int __C)\n+{\n+  return (__m256d) __builtin_ia32_rangepd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t   (__v4df) __B, __C,\n+\t\t\t\t\t\t   (__v4df)\n+\t\t\t\t\t\t   _mm256_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_range_pd (__m128d __A, __m128d __B, int __C)\n+{\n+  return (__m128d) __builtin_ia32_rangepd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t   (__v2df) __B, __C,\n+\t\t\t\t\t\t   (__v2df)\n+\t\t\t\t\t\t   _mm_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) -1);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_range_pd (__m128d __W, __mmask8 __U,\n+\t\t   __m128d __A, __m128d __B, int __C)\n+{\n+  return (__m128d) __builtin_ia32_rangepd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t   (__v2df) __B, __C,\n+\t\t\t\t\t\t   (__v2df) __W,\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_range_pd (__mmask8 __U, __m128d __A, __m128d __B, int __C)\n+{\n+  return (__m128d) __builtin_ia32_rangepd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t   (__v2df) __B, __C,\n+\t\t\t\t\t\t   (__v2df)\n+\t\t\t\t\t\t   _mm_setzero_pd (),\n+\t\t\t\t\t\t   (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_range_ps (__m256 __A, __m256 __B, int __C)\n+{\n+  return (__m256) __builtin_ia32_rangeps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t  (__v8sf) __B, __C,\n+\t\t\t\t\t\t  (__v8sf)\n+\t\t\t\t\t\t  _mm256_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask8) -1);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_range_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B,\n+\t\t      int __C)\n+{\n+  return (__m256) __builtin_ia32_rangeps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t  (__v8sf) __B, __C,\n+\t\t\t\t\t\t  (__v8sf) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_range_ps (__mmask8 __U, __m256 __A, __m256 __B, int __C)\n+{\n+  return (__m256) __builtin_ia32_rangeps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t  (__v8sf) __B, __C,\n+\t\t\t\t\t\t  (__v8sf)\n+\t\t\t\t\t\t  _mm256_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_range_ps (__m128 __A, __m128 __B, int __C)\n+{\n+  return (__m128) __builtin_ia32_rangeps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t  (__v4sf) __B, __C,\n+\t\t\t\t\t\t  (__v4sf)\n+\t\t\t\t\t\t  _mm_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask8) -1);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_range_ps (__m128 __W, __mmask8 __U,\n+\t\t   __m128 __A, __m128 __B, int __C)\n+{\n+  return (__m128) __builtin_ia32_rangeps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t  (__v4sf) __B, __C,\n+\t\t\t\t\t\t  (__v4sf) __W,\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_range_ps (__mmask8 __U, __m128 __A, __m128 __B, int __C)\n+{\n+  return (__m128) __builtin_ia32_rangeps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t  (__v4sf) __B, __C,\n+\t\t\t\t\t\t  (__v4sf)\n+\t\t\t\t\t\t  _mm_setzero_ps (),\n+\t\t\t\t\t\t  (__mmask8) __U);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_fpclass_pd_mask (__mmask8 __U, __m256d __A,\n+\t\t\t     const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclasspd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t      __imm, __U);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_fpclass_pd_mask (__m256d __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclasspd256_mask ((__v4df) __A,\n+\t\t\t\t\t\t      __imm,\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_fpclass_ps_mask (__mmask8 __U, __m256 __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclassps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      __imm, __U);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_fpclass_ps_mask (__m256 __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclassps256_mask ((__v8sf) __A,\n+\t\t\t\t\t\t      __imm,\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_fpclass_pd_mask (__mmask8 __U, __m128d __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclasspd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t      __imm, __U);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fpclass_pd_mask (__m128d __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclasspd128_mask ((__v2df) __A,\n+\t\t\t\t\t\t      __imm,\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_fpclass_ps_mask (__mmask8 __U, __m128 __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclassps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      __imm, __U);\n+}\n+\n+extern __inline __mmask8\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fpclass_ps_mask (__m128 __A, const int __imm)\n+{\n+  return (__mmask8) __builtin_ia32_fpclassps128_mask ((__v4sf) __A,\n+\t\t\t\t\t\t      __imm,\n+\t\t\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_inserti64x2 (__m256i __A, __m128i __B, const int __imm)\n+{\n+  return (__m256i) __builtin_ia32_inserti64x2_256_mask ((__v4di) __A,\n+\t\t\t\t\t\t\t(__v2di) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v4di)\n+\t\t\t\t\t\t\t_mm256_setzero_si256 (),\n+\t\t\t\t\t\t\t(__mmask8) -\n+\t\t\t\t\t\t\t1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_inserti64x2 (__m256i __W, __mmask8 __U, __m256i __A,\n+\t\t\t __m128i __B, const int __imm)\n+{\n+  return (__m256i) __builtin_ia32_inserti64x2_256_mask ((__v4di) __A,\n+\t\t\t\t\t\t\t(__v2di) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v4di) __W,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_inserti64x2 (__mmask8 __U, __m256i __A, __m128i __B,\n+\t\t\t  const int __imm)\n+{\n+  return (__m256i) __builtin_ia32_inserti64x2_256_mask ((__v4di) __A,\n+\t\t\t\t\t\t\t(__v2di) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v4di)\n+\t\t\t\t\t\t\t_mm256_setzero_si256 (),\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_insertf64x2 (__m256d __A, __m128d __B, const int __imm)\n+{\n+  return (__m256d) __builtin_ia32_insertf64x2_256_mask ((__v4df) __A,\n+\t\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v4df)\n+\t\t\t\t\t\t\t_mm256_setzero_pd (),\n+\t\t\t\t\t\t\t(__mmask8) -\n+\t\t\t\t\t\t\t1);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_insertf64x2 (__m256d __W, __mmask8 __U, __m256d __A,\n+\t\t\t __m128d __B, const int __imm)\n+{\n+  return (__m256d) __builtin_ia32_insertf64x2_256_mask ((__v4df) __A,\n+\t\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v4df) __W,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_insertf64x2 (__mmask8 __U, __m256d __A, __m128d __B,\n+\t\t\t  const int __imm)\n+{\n+  return (__m256d) __builtin_ia32_insertf64x2_256_mask ((__v4df) __A,\n+\t\t\t\t\t\t\t(__v2df) __B,\n+\t\t\t\t\t\t\t__imm,\n+\t\t\t\t\t\t\t(__v4df)\n+\t\t\t\t\t\t\t_mm256_setzero_pd (),\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+#else\n+#define _mm256_insertf64x2(X, Y, C)                                     \\\n+  ((__m256d) __builtin_ia32_insertf64x2_256_mask ((__v4df)(__m256d) (X),\\\n+    (__v2df)(__m128d) (Y), (int) (C),\t\t\t\t\t\\\n+    (__v4df)(__m256d)_mm256_setzero_pd(),\t\t\t\t\\\n+    (__mmask8)-1))\n+\n+#define _mm256_mask_insertf64x2(W, U, X, Y, C)                          \\\n+  ((__m256d) __builtin_ia32_insertf64x2_256_mask ((__v4df)(__m256d) (X),\\\n+    (__v2df)(__m128d) (Y), (int) (C),\t\t\t\t\t\\\n+    (__v4df)(__m256d)(W),\t\t\t\t\t\t\\\n+    (__mmask8)(U)))\n+\n+#define _mm256_maskz_insertf64x2(U, X, Y, C)\t\t\t\t\\\n+  ((__m256d) __builtin_ia32_insertf64x2_256_mask ((__v4df)(__m256d) (X),\\\n+    (__v2df)(__m128d) (Y), (int) (C),\t\t\t\t\t\\\n+    (__v4df)(__m256d)_mm256_setzero_pd(),\t\t\t\t\\\n+    (__mmask8)(U)))\n+\n+#define _mm256_inserti64x2(X, Y, C)                                     \\\n+  ((__m256i) __builtin_ia32_inserti64x2_256_mask ((__v4di)(__m256i) (X),\\\n+    (__v2di)(__m128i) (Y), (int) (C),\t\t\t\t\t\\\n+    (__v4di)(__m256i)_mm256_setzero_si256 (),\t\t\t\t\\\n+    (__mmask8)-1))\n+\n+#define _mm256_mask_inserti64x2(W, U, X, Y, C)                          \\\n+  ((__m256i) __builtin_ia32_inserti64x2_256_mask ((__v4di)(__m256i) (X),\\\n+    (__v2di)(__m128i) (Y), (int) (C),\t\t\t\t\t\\\n+    (__v4di)(__m256i)(W),\t\t\t\t\t\t\\\n+    (__mmask8)(U)))\n+\n+#define _mm256_maskz_inserti64x2(U, X, Y, C)                            \\\n+  ((__m256i) __builtin_ia32_inserti64x2_256_mask ((__v4di)(__m256i) (X),\\\n+    (__v2di)(__m128i) (Y), (int) (C),\t\t\t\t\t\\\n+    (__v4di)(__m256i)_mm256_setzero_si256 (),\t\t\t\t\\\n+    (__mmask8)(U)))\n+\n+#define _mm256_extractf64x2_pd(X, C)                                    \\\n+  ((__m128d) __builtin_ia32_extractf64x2_256_mask ((__v4df)(__m256d) (X),\\\n+    (int) (C), (__v2df)(__m128d) _mm_setzero_pd(), (__mmask8)-1))\n+\n+#define _mm256_mask_extractf64x2_pd(W, U, X, C)                         \\\n+  ((__m128d) __builtin_ia32_extractf64x2_256_mask ((__v4df)(__m256d) (X),\\\n+    (int) (C), (__v2df)(__m128d) (W), (__mmask8) (U)))\n+\n+#define _mm256_maskz_extractf64x2_pd(U, X, C)                           \\\n+  ((__m128d) __builtin_ia32_extractf64x2_256_mask ((__v4df)(__m256d) (X),\\\n+    (int) (C), (__v2df)(__m128d) _mm_setzero_pd(), (__mmask8) (U)))\n+\n+#define _mm256_extracti64x2_epi64(X, C)                                 \\\n+  ((__m128i) __builtin_ia32_extracti64x2_256_mask ((__v4di)(__m256i) (X),\\\n+    (int) (C), (__v2di)(__m128i) _mm_setzero_di(), (__mmask8)-1))\n+\n+#define _mm256_mask_extracti64x2_epi64(W, U, X, C)                     \\\n+  ((__m128i) __builtin_ia32_extracti64x2_256_mask ((__v4di)(__m256i) (X),\\\n+    (int) (C), (__v2di)(__m128i) (W), (__mmask8) (U)))\n+\n+#define _mm256_maskz_extracti64x2_epi64(U, X, C)                        \\\n+  ((__m128i) __builtin_ia32_extracti64x2_256_mask ((__v4di)(__m256i) (X),\\\n+    (int) (C), (__v2di)(__m128i) _mm_setzero_di(), (__mmask8) (U)))\n+\n+#define _mm256_reduce_pd(A, B)\t\t\t\t\t\t\\\n+  ((__m256d) __builtin_ia32_reducepd256_mask ((__v4df)(__m256d)(A),\t\\\n+    (int)(B), (__v4df)_mm256_setzero_pd(), (__mmask8)-1))\n+\n+#define _mm256_mask_reduce_pd(W, U, A, B)\t\t\t\t\\\n+  ((__m256d) __builtin_ia32_reducepd256_mask ((__v4df)(__m256d)(A),\t\\\n+    (int)(B), (__v4df)(__m256d)(W), (__mmask8)(U)))\n+\n+#define _mm256_maskz_reduce_pd(U, A, B)\t\t\t\t\t\\\n+  ((__m256d) __builtin_ia32_reducepd256_mask ((__v4df)(__m256d)(A),\t\\\n+    (int)(B), (__v4df)_mm256_setzero_pd(), (__mmask8)(U)))\n+\n+#define _mm_reduce_pd(A, B)\t\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_reducepd128_mask ((__v2df)(__m128d)(A),\t\\\n+    (int)(B), (__v2df)_mm_setzero_pd(), (__mmask8)-1))\n+\n+#define _mm_mask_reduce_pd(W, U, A, B)\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_reducepd128_mask ((__v2df)(__m128d)(A),\t\\\n+    (int)(B), (__v2df)(__m128d)(W), (__mmask8)(U)))\n+\n+#define _mm_maskz_reduce_pd(U, A, B)\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_reducepd128_mask ((__v2df)(__m128d)(A),\t\\\n+    (int)(B), (__v2df)_mm_setzero_pd(), (__mmask8)(U)))\n+\n+#define _mm256_reduce_ps(A, B)\t\t\t\t\t\t\\\n+  ((__m256) __builtin_ia32_reduceps256_mask ((__v8sf)(__m256)(A),\t\\\n+    (int)(B), (__v8sf)_mm256_setzero_ps(), (__mmask8)-1))\n+\n+#define _mm256_mask_reduce_ps(W, U, A, B)\t\t\t\t\\\n+  ((__m256) __builtin_ia32_reduceps256_mask ((__v8sf)(__m256)(A),\t\\\n+    (int)(B), (__v8sf)(__m256)(W), (__mmask8)(U)))\n+\n+#define _mm256_maskz_reduce_ps(U, A, B)\t\t\t\t\t\\\n+  ((__m256) __builtin_ia32_reduceps256_mask ((__v8sf)(__m256)(A),\t\\\n+    (int)(B), (__v8sf)_mm256_setzero_ps(), (__mmask8)(U)))\n+\n+#define _mm_reduce_ps(A, B)\t\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_reduceps128_mask ((__v4sf)(__m128)(A),\t\\\n+    (int)(B), (__v4sf)_mm_setzero_ps(), (__mmask8)-1))\n+\n+#define _mm_mask_reduce_ps(W, U, A, B)\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_reduceps128_mask ((__v4sf)(__m128)(A),\t\\\n+    (int)(B), (__v4sf)(__m128)(W), (__mmask8)(U)))\n+\n+#define _mm_maskz_reduce_ps(U, A, B)\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_reduceps128_mask ((__v4sf)(__m128)(A),\t\\\n+    (int)(B), (__v4sf)_mm_setzero_ps(), (__mmask8)(U)))\n+\n+#define _mm256_range_pd(A, B, C)\t\t\t\t\t\\\n+  ((__m256d) __builtin_ia32_rangepd256_mask ((__v4df)(__m256d)(A),\t\\\n+    (__v4df)(__m256d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v4df)_mm256_setzero_pd(), (__mmask8)-1))\n+\n+#define _mm256_maskz_range_pd(U, A, B, C)\t\t\t\t\\\n+  ((__m256d) __builtin_ia32_rangepd256_mask ((__v4df)(__m256d)(A),\t\\\n+    (__v4df)(__m256d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v4df)_mm256_setzero_pd(), (__mmask8)(U)))\n+\n+#define _mm_range_pd(A, B, C)\t\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_rangepd128_mask ((__v2df)(__m128d)(A),\t\\\n+    (__v2df)(__m128d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v2df)_mm_setzero_pd(), (__mmask8)-1))\n+\n+#define _mm256_range_ps(A, B, C)\t\t\t\t\t\\\n+  ((__m256) __builtin_ia32_rangeps256_mask ((__v8sf)(__m256)(A),\t\\\n+    (__v8sf)(__m256)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8sf)_mm256_setzero_ps(), (__mmask8)-1))\n+\n+#define _mm256_mask_range_ps(W, U, A, B, C)\t\t\t\t\\\n+  ((__m256) __builtin_ia32_rangeps256_mask ((__v8sf)(__m256)(A),\t\\\n+    (__v8sf)(__m256)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8sf)(__m256)(W), (__mmask8)(U)))\n+\n+#define _mm256_maskz_range_ps(U, A, B, C)\t\t\t\t\\\n+  ((__m256) __builtin_ia32_rangeps256_mask ((__v8sf)(__m256)(A),\t\\\n+    (__v8sf)(__m256)(B), (int)(C),\t\t\t\t\t\\\n+    (__v8sf)_mm256_setzero_ps(), (__mmask8)(U)))\n+\n+#define _mm_range_ps(A, B, C)\t\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_rangeps128_mask ((__v4sf)(__m128)(A),\t\\\n+    (__v4sf)(__m128)(B), (int)(C),\t\t\t\t\t\\\n+    (__v4sf)_mm_setzero_ps(), (__mmask8)-1))\n+\n+#define _mm_mask_range_ps(W, U, A, B, C)\t\t\t\t\\\n+  ((__m128) __builtin_ia32_rangeps128_mask ((__v4sf)(__m128)(A),\t\\\n+    (__v4sf)(__m128)(B), (int)(C),\t\t\t\t\t\\\n+    (__v4sf)(__m128)(W), (__mmask8)(U)))\n+\n+#define _mm_maskz_range_ps(U, A, B, C)\t\t\t\t\t\\\n+  ((__m128) __builtin_ia32_rangeps128_mask ((__v4sf)(__m128)(A),\t\\\n+    (__v4sf)(__m128)(B), (int)(C),\t\t\t\t\t\\\n+    (__v4sf)_mm_setzero_ps(), (__mmask8)(U)))\n+\n+#define _mm256_mask_range_pd(W, U, A, B, C)\t\t\t\t\\\n+  ((__m256d) __builtin_ia32_rangepd256_mask ((__v4df)(__m256d)(A),\t\\\n+    (__v4df)(__m256d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v4df)(__m256d)(W), (__mmask8)(U)))\n+\n+#define _mm_mask_range_pd(W, U, A, B, C)\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_rangepd128_mask ((__v2df)(__m128d)(A),\t\\\n+    (__v2df)(__m128d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v2df)(__m128d)(W), (__mmask8)(U)))\n+\n+#define _mm_maskz_range_pd(U, A, B, C)\t\t\t\t\t\\\n+  ((__m128d) __builtin_ia32_rangepd128_mask ((__v2df)(__m128d)(A),\t\\\n+    (__v2df)(__m128d)(B), (int)(C),\t\t\t\t\t\\\n+    (__v2df)_mm_setzero_pd(), (__mmask8)(U)))\n+\n+#define _mm256_mask_fpclass_pd_mask(u, X, C)                            \\\n+  ((__mmask8) __builtin_ia32_fpclasspd256_mask ((__v4df) (__m256d) (X), \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)(u)))\n+\n+#define _mm256_mask_fpclass_ps_mask(u, X, C)\t\t\t\t\\\n+  ((__mmask8) __builtin_ia32_fpclassps256_mask ((__v8sf) (__m256) (X),  \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)(u)))\n+\n+#define _mm_mask_fpclass_pd_mask(u, X, C)                               \\\n+  ((__mmask8) __builtin_ia32_fpclasspd128_mask ((__v2df) (__m128d) (X), \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)(u)))\n+\n+#define _mm_mask_fpclass_ps_mask(u, X, C)                               \\\n+  ((__mmask8) __builtin_ia32_fpclassps128_mask ((__v4sf) (__m128) (X),  \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)(u)))\n+\n+#define _mm256_fpclass_pd_mask(X, C)                                    \\\n+  ((__mmask8) __builtin_ia32_fpclasspd256_mask ((__v4df) (__m256d) (X), \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)-1))\n+\n+#define _mm256_fpclass_ps_mask(X, C)                                    \\\n+  ((__mmask8) __builtin_ia32_fpclassps256_mask ((__v8sf) (__m256) (X),  \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)-1))\n+\n+#define _mm_fpclass_pd_mask(X, C)                                       \\\n+  ((__mmask8) __builtin_ia32_fpclasspd128_mask ((__v2df) (__m128d) (X), \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)-1))\n+\n+#define _mm_fpclass_ps_mask(X, C)                                       \\\n+  ((__mmask8) __builtin_ia32_fpclassps128_mask ((__v4sf) (__m128) (X),  \\\n+\t\t\t\t\t\t(int) (C),(__mmask8)-1))\n+\n+#endif\n+\n+#ifdef __DISABLE_AVX512VLDQ__\n+#undef __DISABLE_AVX512VLDQ__\n+#pragma GCC pop_options\n+#endif /* __DISABLE_AVX512VLDQ__ */\n+\n+#endif /* _AVX512VLDQINTRIN_H_INCLUDED */"}, {"sha": "2f5e048f3a844de58b4e5951ea17385adf01b325", "filename": "gcc/config/i386/avx512vlintrin.h", "status": "added", "additions": 13199, "deletions": 0, "changes": 13199, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512vlintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Favx512vlintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512vlintrin.h?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589"}, {"sha": "5d921822248a180607843435f78a388eddfd1519", "filename": "gcc/config/i386/immintrin.h", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Fimmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/936c0fe4cbaa0f03a047d46122d1a87b893f5589/gcc%2Fconfig%2Fi386%2Fimmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fimmintrin.h?ref=936c0fe4cbaa0f03a047d46122d1a87b893f5589", "patch": "@@ -50,6 +50,16 @@\n \n #include <avx512cdintrin.h>\n \n+#include <avx512vlintrin.h>\n+\n+#include <avx512bwintrin.h>\n+\n+#include <avx512dqintrin.h>\n+\n+#include <avx512vlbwintrin.h>\n+\n+#include <avx512vldqintrin.h>\n+\n #include <shaintrin.h>\n \n #include <lzcntintrin.h>"}]}