{"sha": "ea900239f40b40cb0b5174fb15818c862b6bb333", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZWE5MDAyMzlmNDBiNDBjYjBiNTE3NGZiMTU4MThjODYyYjZiYjMzMw==", "commit": {"author": {"name": "Daniel Berlin", "email": "dberlin@dberlin.org", "date": "2005-07-16T18:56:53Z"}, "committer": {"name": "Kenneth Zadeck", "email": "zadeck@gcc.gnu.org", "date": "2005-07-16T18:56:53Z"}, "message": "Makefile.in: Added rules for ipa-pure-const.c...\n\n2005-07-16  Danny Berlin <dberlin@dberlin.org>\n\t    Kenneth Zadeck <zadeck@naturalbridge.com>\n\n\t* Makefile.in: Added rules for ipa-pure-const.c, ipa-reference.c,\n\tipa-reference.h, ipa-utils.c, ipa-utils.h, ipa-type-escape.c,\n\tipa-type-escape.h, tree-promote-statics.c\n\t* ipa-pure-const.c, ipa-reference.c, ipa-reference.h, ipa-utils.c,\n\tipa-utils.h, ipa-type-escape.c, ipa-type-escape.h,\n\ttree-promote-statics.c: new files.\n\t* alias.c: (nonlocal_mentioned_p_1, nonlocal_mentioned_p,\n\tnonlocal_referenced_p_1, nonlocal_referenced_p, nonlocal_set_p_1,\n\tint nonlocal_set_p, mark_constant_function): Deleted.\n\t(rest_of_handle_cfg): Removed call to mark_constant_function.\n        (nonoverlapping_component_refs_p): Added calls to support\n\ttype based aliasing.\n        * tree-ssa-alias.c (may_alias_p,\n\tcompute_flow_insensitive_aliasing): Ditto.\n\t* calls.c (flags_from_decl_or_type): Removed reference to\n\tcgraph_rtl_info.\n\t(flags_from_decl_or_type): Support ECF_POINTER_NO_CAPTURE attribute.\n\t* c-common.c (handle_pointer_no_capture_attribute): New function\n\tand added pointer_no_capture attribute.\n      \t* c-typeck.c (convert_arguments): Make builtins tolerant of having\n\ttoo many arguments.  This is necessary for Spec 2000.\n\t* cgraph.h (const_function, pure_function): Removed.\n\t* common.opt: Added \"fipa-pure-const\", \"fipa-reference\",\n\t\"fipa-type-escape\", and \"ftree-promote-static\".\n\t* opts.c: Ditto.\n\t* passes.c: Added ipa and tree-promote-statics passes.\n\t* timevar.def: Added TV_IPA_PURE_CONST, TV_IPA_REFERENCE,\n\tTV_IPA_TYPE_ESCAPE, and TV_PROMOTE_STATICS.\n\t* tree.h: Support ECF_POINTER_NO_CAPTURE attribute.\n\t* tree-dfa.c (referenced_var_lookup_if_exists): New function.\n\t* tree-flow.h: Added exposed sra calls and addition of\n\treference_vars_info field for FUNCTION_DECLS.\n\t* tree-pass.h: Added passes.\n\t* tree-sra.c: (sra_init_cache): New function.\n\t(sra_insert_before, sra_insert_after) Made public.\n\t(type_can_be_decomposed_p): Renamed from type_can_be_decomposed_p\n\tand made public.\n\t* tree-ssa-alias.c (dump_alias_stats): Added stats for type based\n\taliasing. (may_alias_p): Added code to use type escape analysis to\n\timprove alias sets.\n\t* tree-ssa-operands.c (add_call_clobber_ops): Added parameter and\n\tcode to prune clobbers of static variables based on information\n\tproduced in ipa-reference pass.  Changed call clobbering so that\n\tstatics are not marked as clobbered if the call does not clobber\n\tthem.\n\n\n2005-07-16  Danny Berlin <dberlin@dberlin.org>\n\t    Kenneth Zadeck <zadeck@naturalbridge.com>\n\n\t* gcc.dg/tree-ssa/ssa-dce-2.c: Changed dg-options to run at -O2\n\tsince pure const detection cannot run at -O1 in c compiler.\n\t* gcc.dg/tree-ssa/20030714-1.c Changed scanning patterns because we\n\tcan now optimize this case properly.\n\t* gcc.dg/tree-ssa/sra-2.c: Changed to -O3 and removed xfail\n\tbecause we now pass.\n\t* gcc.dg/vect/vect-92.c: Removed out of bounds array access.\n\nCo-Authored-By: Kenneth Zadeck <zadeck@naturalbridge.com>\n\nFrom-SVN: r102098", "tree": {"sha": "4d5596f0a90a8d86cb901a22b6fc51007ed87f90", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4d5596f0a90a8d86cb901a22b6fc51007ed87f90"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ea900239f40b40cb0b5174fb15818c862b6bb333", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ea900239f40b40cb0b5174fb15818c862b6bb333", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ea900239f40b40cb0b5174fb15818c862b6bb333", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ea900239f40b40cb0b5174fb15818c862b6bb333/comments", "author": {"login": "dberlin", "id": 324715, "node_id": "MDQ6VXNlcjMyNDcxNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/324715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dberlin", "html_url": "https://github.com/dberlin", "followers_url": "https://api.github.com/users/dberlin/followers", "following_url": "https://api.github.com/users/dberlin/following{/other_user}", "gists_url": "https://api.github.com/users/dberlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/dberlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dberlin/subscriptions", "organizations_url": "https://api.github.com/users/dberlin/orgs", "repos_url": "https://api.github.com/users/dberlin/repos", "events_url": "https://api.github.com/users/dberlin/events{/privacy}", "received_events_url": "https://api.github.com/users/dberlin/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "8f59c51bb13229c9de2f774b0ce63aedcb6cb6e7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8f59c51bb13229c9de2f774b0ce63aedcb6cb6e7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8f59c51bb13229c9de2f774b0ce63aedcb6cb6e7"}], "stats": {"total": 5745, "additions": 5284, "deletions": 461}, "files": [{"sha": "c7eed293724e3372aa0d5bc9ec6f38afe3083d1f", "filename": "ChangeLog", "status": "modified", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/ChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/ChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/ChangeLog?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -1,3 +1,53 @@\n+2005-07-16 Danny Berlin <dberlin@dberlin.org>\n+\t   Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+\t* Makefile.in: Added rules for ipa-pure-const.c, ipa-reference.c,\n+\tipa-reference.h, ipa-utils.c, ipa-utils.h, ipa-type-escape.c,\n+\tipa-type-escape.h, tree-promote-statics.c\n+\t* ipa-pure-const.c, ipa-reference.c, ipa-reference.h, ipa-utils.c,\n+\tipa-utils.h, ipa-type-escape.c, ipa-type-escape.h, \n+\ttree-promote-statics.c: new files.\n+\t* alias.c: (nonlocal_mentioned_p_1, nonlocal_mentioned_p,\n+\tnonlocal_referenced_p_1, nonlocal_referenced_p, nonlocal_set_p_1,\n+\tint nonlocal_set_p, mark_constant_function): Deleted.\n+\t(rest_of_handle_cfg): Removed call to mark_constant_function. \n+        (nonoverlapping_component_refs_p): Added calls to support\n+\ttype based aliasing.    \n+        * tree-ssa-alias.c (may_alias_p,\n+\tcompute_flow_insensitive_aliasing): Ditto.\n+\t* calls.c (flags_from_decl_or_type): Removed reference to\n+\tcgraph_rtl_info. \n+\t(flags_from_decl_or_type): Support ECF_POINTER_NO_CAPTURE attribute.\n+\t* c-common.c (handle_pointer_no_capture_attribute): New function\n+\tand added pointer_no_capture attribute.\n+      \t* c-typeck.c (convert_arguments): Make builtins tolerant of having\n+\ttoo many arguments.  This is necessary for Spec 2000.\n+\t* cgraph.h (const_function, pure_function): Removed.\n+\t* common.opt: Added \"fipa-pure-const\", \"fipa-reference\",  \n+\t\"fipa-type-escape\", and \"ftree-promote-static\".\n+\t* opts.c: Ditto.\n+\t* passes.c: Added ipa and tree-promote-statics passes. \n+\t* timevar.def: Added TV_IPA_PURE_CONST, TV_IPA_REFERENCE,\n+\tTV_IPA_TYPE_ESCAPE, and TV_PROMOTE_STATICS.\n+\t* tree.h: Support ECF_POINTER_NO_CAPTURE attribute.\n+\t* tree-dfa.c (referenced_var_lookup_if_exists): New function.\n+\t* tree-flow.h: Added exposed sra calls and addition of \n+\treference_vars_info field for FUNCTION_DECLS.\n+\t* tree-pass.h: Added passes.\n+\t* tree-sra.c: (sra_init_cache): New function.\n+\t(sra_insert_before, sra_insert_after) Made public.\n+\t(type_can_be_decomposed_p): Renamed from type_can_be_decomposed_p\n+\tand made public.\n+\t* tree-ssa-alias.c (dump_alias_stats): Added stats for type based\n+\taliasing. (may_alias_p): Added code to use type escape analysis to\n+\timprove alias sets.\n+\t* tree-ssa-operands.c (add_call_clobber_ops): Added parameter and\n+\tcode to prune clobbers of static variables based on information\n+\tproduced in ipa-reference pass.  Changed call clobbering so that\n+\tstatics are not marked as clobbered if the call does not clobber\n+\tthem.\n+\n+\n 2005-07-16  Kelley Cook  <kcook@gcc.gnu.org>\n \n \t* all files: Update FSF address."}, {"sha": "910cdc8b89f12cb64a87f4a10d9c7ff8eeb3795f", "filename": "gcc/Makefile.in", "status": "modified", "additions": 35, "deletions": 8, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -729,6 +729,9 @@ SCHED_INT_H = sched-int.h $(INSN_ATTR_H) $(BASIC_BLOCK_H) $(RTL_H)\n INTEGRATE_H = integrate.h varray.h\n CFGLAYOUT_H = cfglayout.h $(BASIC_BLOCK_H)\n CFGLOOP_H = cfgloop.h $(BASIC_BLOCK_H) $(RTL_H)\n+IPA_UTILS_H = ipa-utils.h $(TREE_H) $(CGRAPH_H) \n+IPA_REFERENCE_H = ipa-reference.h bitmap.h $(TREE_H)  \n+IPA_TYPE_ESCAPE_H = ipa-type-escape.h $(TREE_H)  \n CGRAPH_H = cgraph.h tree.h \n DF_H = df.h bitmap.h sbitmap.h $(BASIC_BLOCK_H)\n DDG_H = ddg.h sbitmap.h $(DF_H)\n@@ -750,7 +753,7 @@ TREE_DUMP_H = tree-dump.h $(SPLAY_TREE_H)\n TREE_GIMPLE_H = tree-gimple.h tree-iterator.h\n TREE_FLOW_H = tree-flow.h tree-flow-inline.h tree-ssa-operands.h \\\n \t\tbitmap.h $(BASIC_BLOCK_H) hard-reg-set.h $(TREE_GIMPLE_H) \\\n-\t\t$(HASHTAB_H) $(CGRAPH_H)\n+\t\t$(HASHTAB_H) $(CGRAPH_H) $(IPA_REFERENCE_H)\n TREE_SSA_LIVE_H = tree-ssa-live.h $(PARTITION_H)\n PRETTY_PRINT_H = pretty-print.h input.h $(OBSTACK_H)\n DIAGNOSTIC_H = diagnostic.h diagnostic.def $(PRETTY_PRINT_H)\n@@ -945,7 +948,7 @@ OBJS-common = \\\n  integrate.o intl.o jump.o  langhooks.o lcm.o lists.o local-alloc.o  \t   \\\n  loop.o mode-switching.o modulo-sched.o optabs.o options.o opts.o\t   \\\n  params.o postreload.o postreload-gcse.o predict.o\t\t\t   \\\n- insn-preds.o pointer-set.o\t\t\t\t\t\t   \\\n+ insn-preds.o pointer-set.o tree-promote-statics.o\t\t   \t   \\\n  print-rtl.o print-tree.o profile.o value-prof.o var-tracking.o\t\t   \\\n  real.o recog.o reg-stack.o regclass.o regmove.o regrename.o\t\t   \\\n  reload.o reload1.o reorg.o resource.o rtl.o rtlanal.o rtl-error.o\t   \\\n@@ -962,7 +965,8 @@ OBJS-common = \\\n \n OBJS-md = $(out_object_file)\n OBJS-archive = $(EXTRA_OBJS) $(host_hook_obj) tree-inline.o\t\t   \\\n-  cgraph.o cgraphunit.o tree-nomudflap.o ipa.o ipa-inline.o\n+  cgraph.o cgraphunit.o tree-nomudflap.o ipa.o ipa-inline.o                \\\n+  ipa-utils.o ipa-reference.o ipa-pure-const.o ipa-type-escape.o\n \n OBJS = $(OBJS-common) $(out_object_file) $(OBJS-archive)\n \n@@ -1837,11 +1841,12 @@ tree-dfa.o : tree-dfa.c $(TREE_FLOW_H) $(CONFIG_H) $(SYSTEM_H) \\\n    tree-inline.h $(HASHTAB_H) pointer-set.h $(FLAGS_H) function.h \\\n    $(TIMEVAR_H) convert.h $(TM_H) coretypes.h langhooks.h $(TREE_DUMP_H) \\\n    tree-pass.h $(PARAMS_H) $(CGRAPH_H) $(BASIC_BLOCK_H) hard-reg-set.h \\\n-   $(TREE_GIMPLE_H)\n+   $(TREE_GIMPLE_H) \n tree-ssa-operands.o : tree-ssa-operands.c $(TREE_FLOW_H) $(CONFIG_H) \\\n-   $(SYSTEM_H) $(TREE_H) $(GGC_H) $(DIAGNOSTIC_H) tree-inline.h \\\n+   $(SYSTEM_H) $(TREE_H) $(GGC_H) $(DIAGNOSTIC_H) errors.h tree-inline.h \\\n    $(FLAGS_H) function.h $(TM_H) $(TIMEVAR_H) tree-pass.h toplev.h \\\n-   gt-tree-ssa-operands.h coretypes.h langhooks.h tree-ssa-opfinalize.h\n+   gt-tree-ssa-operands.h coretypes.h langhooks.h tree-ssa-opfinalize.h \\\n+   $(IPA_REFERENCE_H)\n tree-eh.o : tree-eh.c $(TREE_FLOW_H) $(CONFIG_H) $(SYSTEM_H) \\\n    $(RTL_H) $(TREE_H) $(TM_H) $(FLAGS_H) function.h except.h langhooks.h \\\n    $(GGC_H) tree-pass.h coretypes.h $(TIMEVAR_H) $(TM_P_H) \\\n@@ -1895,7 +1900,8 @@ tree-ssa-alias.o : tree-ssa-alias.c $(TREE_FLOW_H) $(CONFIG_H) $(SYSTEM_H) \\\n    $(RTL_H) $(TREE_H) $(TM_P_H) $(EXPR_H) $(GGC_H) tree-inline.h $(FLAGS_H) \\\n    function.h $(TIMEVAR_H) convert.h $(TM_H) coretypes.h langhooks.h \\\n    $(TREE_DUMP_H) tree-pass.h $(PARAMS_H) $(BASIC_BLOCK_H) $(DIAGNOSTIC_H) \\\n-   hard-reg-set.h $(TREE_GIMPLE_H) vec.h tree-ssa-structalias.h\n+   hard-reg-set.h $(TREE_GIMPLE_H) vec.h tree-ssa-structalias.h \\\n+   $(IPA_TYPE_ESCAPE_H)\n tree-ssa-reassoc.o : tree-ssa-reassoc.c $(TREE_FLOW_H) $(CONFIG_H) \\\n    $(SYSTEM_H) $(TREE_H) $(GGC_H) $(DIAGNOSTIC_H) errors.h $(TIMEVAR_H) \\\n    $(TM_H) coretypes.h $(TREE_DUMP_H) tree-pass.h $(FLAGS_H) tree-iterator.h\\\n@@ -2142,6 +2148,22 @@ ipa-inline.o : ipa-inline.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n    $(TREE_H) langhooks.h tree-inline.h $(FLAGS_H) $(CGRAPH_H) intl.h \\\n    $(DIAGNOSTIC_H) $(FIBHEAP_H) $(PARAMS_H) $(TIMEVAR_H) tree-pass.h \\\n    $(COVERAGE_H) $(HASHTAB_H)\n+ipa-utils.o : ipa-utils.c $(IPA_UTILS_H) $(CONFIG_H) $(SYSTEM_H) \\\n+   coretypes.h $(TM_H) $(TREE_H) $(TREE_FLOW_H) tree-inline.h langhooks.h \\\n+   pointer-set.h $(GGC_H) $(C_COMMON_H) $(TREE_GIMPLE_H) \\\n+   $(CGRAPH_H) output.h $(FLAGS_H) tree-pass.h $(DIAGNOSTIC_H) \n+ipa-reference.o : ipa-reference.c $(CONFIG_H) $(SYSTEM_H) \\\n+   coretypes.h $(TM_H) $(TREE_H) $(TREE_FLOW_H) tree-inline.h langhooks.h \\\n+   pointer-set.h $(GGC_H) $(IPA_REFERENCE_H) $(IPA_UTILS_H) $(C_COMMON_H) \\\n+   $(TREE_GIMPLE_H) $(CGRAPH_H) output.h $(FLAGS_H) tree-pass.h $(DIAGNOSTIC_H)  \n+ipa-pure-const.o : ipa-pure-const.c $(CONFIG_H) $(SYSTEM_H) \\\n+   coretypes.h $(TM_H) $(TREE_H) $(TREE_FLOW_H) tree-inline.h langhooks.h \\\n+   pointer-set.h $(GGC_H) $(IPA_UTILS_H) $(C_COMMON_H) \\\n+   $(TREE_GIMPLE_H) $(CGRAPH_H) output.h $(FLAGS_H) tree-pass.h $(DIAGNOSTIC_H)  \n+ipa-type-escape.o : ipa-type-escape.c $(CONFIG_H) $(SYSTEM_H) \\\n+   coretypes.h $(TM_H) $(TREE_H) $(TREE_FLOW_H) tree-inline.h langhooks.h \\\n+   pointer-set.h $(GGC_H) $(IPA_TYPE_ESCAPE_H) $(IPA_UTILS_H) $(C_COMMON_H) \\\n+   $(TREE_GIMPLE_H) $(CGRAPH_H) output.h $(FLAGS_H) tree-pass.h $(DIAGNOSTIC_H)  \n coverage.o : coverage.c $(GCOV_IO_H) $(CONFIG_H) $(SYSTEM_H) coretypes.h \\\n    $(TM_H) $(RTL_H) $(TREE_H) $(FLAGS_H) output.h $(REGS_H) $(EXPR_H) \\\n    function.h toplev.h $(GGC_H) langhooks.h $(COVERAGE_H) gt-coverage.h \\\n@@ -2196,6 +2218,9 @@ tree-vect-generic.o : tree-vect-generic.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) \\\n     $(FLAGS_H) $(OPTABS_H) $(RTL_H) $(MACHMODE_H) $(EXPR_H) \\\n     langhooks.h $(FLAGS_H) $(DIAGNOSTIC_H) gt-tree-vect-generic.h $(GGC_H) \\\n     coretypes.h insn-codes.h\n+tree-promote-statics.o : tree-promote-statics.c $(CONFIG_H) system.h \\\n+   $(TREE_H) $(TM_H) $(BASIC_BLOCK_H) $(TREE_FLOW_H) $(IPA_UTILS_H) \\\n+   $(IPA_REFERENCE_H) bitmap.h tree-pass.h $(FLAGS_H) $(TIMEVAR_H) \n df.o : df.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n    insn-config.h $(RECOG_H) function.h $(REGS_H) alloc-pool.h hard-reg-set.h \\\n    $(BASIC_BLOCK_H) $(DF_H) bitmap.h sbitmap.h $(TM_P_H)\n@@ -2345,7 +2370,7 @@ alias.o : alias.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n    $(FLAGS_H) hard-reg-set.h $(BASIC_BLOCK_H) $(REGS_H) toplev.h output.h \\\n    $(ALIAS_H) $(EMIT_RTL_H) $(GGC_H) function.h cselib.h $(TREE_H) $(TM_P_H) \\\n    langhooks.h $(TARGET_H) gt-alias.h $(TIMEVAR_H) $(CGRAPH_H) \\\n-   $(SPLAY_TREE_H) $(VARRAY_H) tree-pass.h\n+   $(SPLAY_TREE_H) $(VARRAY_H) $(IPA_TYPE_ESCAPE_H) tree-pass.h\n regmove.o : regmove.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n    insn-config.h timevar.h tree-pass.h \\\n    $(RECOG_H) output.h $(REGS_H) hard-reg-set.h $(FLAGS_H) function.h \\\n@@ -2682,6 +2707,7 @@ GTFILES = $(srcdir)/input.h $(srcdir)/coretypes.h \\\n   $(srcdir)/coverage.c $(srcdir)/function.h $(srcdir)/rtl.h \\\n   $(srcdir)/optabs.h $(srcdir)/tree.h $(srcdir)/libfuncs.h $(SYMTAB_H) \\\n   $(srcdir)/real.h $(srcdir)/varray.h $(srcdir)/insn-addr.h $(srcdir)/hwint.h \\\n+  $(srcdir)/ipa-reference.h \\\n   $(srcdir)/cselib.h $(srcdir)/basic-block.h  $(srcdir)/cgraph.h \\\n   $(srcdir)/c-common.h $(srcdir)/c-tree.h $(srcdir)/reload.h \\\n   $(srcdir)/alias.c $(srcdir)/bitmap.c $(srcdir)/cselib.c $(srcdir)/cgraph.c \\\n@@ -2703,6 +2729,7 @@ GTFILES = $(srcdir)/input.h $(srcdir)/coretypes.h \\\n   $(srcdir)/tree-chrec.h $(srcdir)/tree-vect-generic.c \\\n   $(srcdir)/tree-ssa-operands.h $(srcdir)/tree-ssa-operands.c \\\n   $(srcdir)/tree-profile.c $(srcdir)/rtl-profile.c $(srcdir)/tree-nested.c \\\n+  $(srcdir)/ipa-reference.c \\\n   $(srcdir)/targhooks.c $(out_file) \\\n   @all_gtfiles@\n "}, {"sha": "cdbb94dfceb1b3a01b2390f207cf0bf7d2f7bacc", "filename": "gcc/alias.c", "status": "modified", "additions": 87, "deletions": 388, "changes": 475, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Falias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Falias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Falias.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -45,6 +45,58 @@ Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n #include \"cgraph.h\"\n #include \"varray.h\"\n #include \"tree-pass.h\"\n+#include \"ipa-type-escape.h\"\n+\n+/* The aliasing API provided here solves related but different problems:\n+\n+   Say there exists (in c) \n+\n+   struct X {\n+     struct Y y1;\n+     struct Z z2;\n+   } x1, *px1,  *px2;\n+\n+   struct Y y2, *py;\n+   struct Z z2, *pz;\n+\n+\n+   py = &px1.y1;\n+   px2 = &x1;\n+\n+   Consider the four questions:\n+\n+   Can a store to x1 interfere with px2->y1?\n+   Can a store to x1 interfere with px2->z2?\n+   (*px2).z2\n+   Can a store to x1 change the value pointed to by with py?\n+   Can a store to x1 change the value pointed to by with pz?\n+\n+   The answer to these questions can be yes, yes, yes, and maybe.\n+\n+   The first two questions can be answered with a simple examination\n+   of the type system.  If structure X contains a field of type Y then\n+   a store thru a pointer to an X can overwrite any field that is\n+   contained (recursively) in an X (unless we know that px1 != px2).\n+\n+   The last two of the questions can be solved in the same way as the\n+   first two questions but this is too conservative.  The observation\n+   is that in some cases analysis we can know if which (if any) fields\n+   are addressed and if those addresses are used in bad ways.  This\n+   analysis may be language specific.  In C, arbitrary operations may\n+   be applied to pointers.  However, there is some indication that\n+   this may be too conservative for some C++ types.\n+\n+   The pass ipa-type-escape does this analysis for the types whose\n+   instances do not escape across the compilation boundary.  \n+\n+   Historically in GCC, these two problems were combined and a single\n+   data structure was used to represent the solution to these\n+   problems.  We now have two similar but different data structures,\n+   The data structure to solve the last two question is similar to the\n+   first, but does not contain have the fields in it whose address are\n+   never taken.  For types that do escape the compilation unit, the\n+   data structures will have identical information.\n+*/\n \n /* The alias sets assigned to MEMs assist the back-end in determining\n    which MEMs can alias which other MEMs.  In general, two MEMs in\n@@ -116,12 +168,6 @@ static rtx adjust_offset_for_component_ref (tree, rtx);\n static int nonoverlapping_memrefs_p (rtx, rtx);\n static int write_dependence_p (rtx, rtx, int);\n \n-static int nonlocal_mentioned_p_1 (rtx *, void *);\n-static int nonlocal_mentioned_p (rtx);\n-static int nonlocal_referenced_p_1 (rtx *, void *);\n-static int nonlocal_referenced_p (rtx);\n-static int nonlocal_set_p_1 (rtx *, void *);\n-static int nonlocal_set_p (rtx);\n static void memory_modified_1 (rtx, rtx, void *);\n static void record_alias_subset (HOST_WIDE_INT, HOST_WIDE_INT);\n \n@@ -1924,9 +1970,8 @@ nonoverlapping_component_refs_p (tree x, tree y)\n \t  x = TREE_OPERAND (x, 0);\n \t}\n       while (x && TREE_CODE (x) == COMPONENT_REF);\n-\n       /* Never found a common type.  */\n-      return false;\n+      return true;\n \n     found:\n       /* If we're left with accessing different fields of a structure,\n@@ -2006,22 +2051,34 @@ nonoverlapping_memrefs_p (rtx x, rtx y)\n   /* Unless both have exprs, we can't tell anything.  */\n   if (exprx == 0 || expry == 0)\n     return 0;\n-\n+  \n   /* If both are field references, we may be able to determine something.  */\n   if (TREE_CODE (exprx) == COMPONENT_REF\n       && TREE_CODE (expry) == COMPONENT_REF\n       && nonoverlapping_component_refs_p (exprx, expry))\n     return 1;\n \n+  \n   /* If the field reference test failed, look at the DECLs involved.  */\n   moffsetx = MEM_OFFSET (x);\n   if (TREE_CODE (exprx) == COMPONENT_REF)\n     {\n-      tree t = decl_for_component_ref (exprx);\n-      if (! t)\n-\treturn 0;\n-      moffsetx = adjust_offset_for_component_ref (exprx, moffsetx);\n-      exprx = t;\n+      if (TREE_CODE (expry) == VAR_DECL\n+\t  && POINTER_TYPE_P (TREE_TYPE (expry)))\n+\t{\n+\t tree field = TREE_OPERAND (exprx, 1);\n+\t tree fieldcontext = DECL_FIELD_CONTEXT (field);\n+\t if (ipa_type_escape_field_does_not_clobber_p (fieldcontext,\n+\t\t\t\t\t\t       TREE_TYPE (field)))\n+\t   return 1;\t \n+\t}\n+      {\n+\ttree t = decl_for_component_ref (exprx);\n+\tif (! t)\n+\t  return 0;\n+\tmoffsetx = adjust_offset_for_component_ref (exprx, moffsetx);\n+\texprx = t;\n+      }\n     }\n   else if (INDIRECT_REF_P (exprx))\n     {\n@@ -2034,11 +2091,22 @@ nonoverlapping_memrefs_p (rtx x, rtx y)\n   moffsety = MEM_OFFSET (y);\n   if (TREE_CODE (expry) == COMPONENT_REF)\n     {\n-      tree t = decl_for_component_ref (expry);\n-      if (! t)\n-\treturn 0;\n-      moffsety = adjust_offset_for_component_ref (expry, moffsety);\n-      expry = t;\n+      if (TREE_CODE (exprx) == VAR_DECL\n+\t  && POINTER_TYPE_P (TREE_TYPE (exprx)))\n+\t{\n+\t tree field = TREE_OPERAND (expry, 1);\n+\t tree fieldcontext = DECL_FIELD_CONTEXT (field);\n+\t if (ipa_type_escape_field_does_not_clobber_p (fieldcontext,\n+\t\t\t\t\t\t       TREE_TYPE (field)))\n+\t   return 1;\t \n+\t}\n+      {\n+\ttree t = decl_for_component_ref (expry);\n+\tif (! t)\n+\t  return 0;\n+\tmoffsety = adjust_offset_for_component_ref (expry, moffsety);\n+\texpry = t;\n+      }\n     }\n   else if (INDIRECT_REF_P (expry))\n     {\n@@ -2326,353 +2394,6 @@ output_dependence (rtx mem, rtx x)\n   return write_dependence_p (mem, x, /*writep=*/1);\n }\n \f\n-/* A subroutine of nonlocal_mentioned_p, returns 1 if *LOC mentions\n-   something which is not local to the function and is not constant.  */\n-\n-static int\n-nonlocal_mentioned_p_1 (rtx *loc, void *data ATTRIBUTE_UNUSED)\n-{\n-  rtx x = *loc;\n-  rtx base;\n-  int regno;\n-\n-  if (! x)\n-    return 0;\n-\n-  switch (GET_CODE (x))\n-    {\n-    case SUBREG:\n-      if (REG_P (SUBREG_REG (x)))\n-\t{\n-\t  /* Global registers are not local.  */\n-\t  if (REGNO (SUBREG_REG (x)) < FIRST_PSEUDO_REGISTER\n-\t      && global_regs[subreg_regno (x)])\n-\t    return 1;\n-\t  return 0;\n-\t}\n-      break;\n-\n-    case REG:\n-      regno = REGNO (x);\n-      /* Global registers are not local.  */\n-      if (regno < FIRST_PSEUDO_REGISTER && global_regs[regno])\n-\treturn 1;\n-      return 0;\n-\n-    case SCRATCH:\n-    case PC:\n-    case CC0:\n-    case CONST_INT:\n-    case CONST_DOUBLE:\n-    case CONST_VECTOR:\n-    case CONST:\n-    case LABEL_REF:\n-      return 0;\n-\n-    case SYMBOL_REF:\n-      /* Constants in the function's constants pool are constant.  */\n-      if (CONSTANT_POOL_ADDRESS_P (x))\n-\treturn 0;\n-      return 1;\n-\n-    case CALL:\n-      /* Non-constant calls and recursion are not local.  */\n-      return 1;\n-\n-    case MEM:\n-      /* Be overly conservative and consider any volatile memory\n-\t reference as not local.  */\n-      if (MEM_VOLATILE_P (x))\n-\treturn 1;\n-      base = find_base_term (XEXP (x, 0));\n-      if (base)\n-\t{\n-\t  /* A Pmode ADDRESS could be a reference via the structure value\n-\t     address or static chain.  Such memory references are nonlocal.\n-\n-\t     Thus, we have to examine the contents of the ADDRESS to find\n-\t     out if this is a local reference or not.  */\n-\t  if (GET_CODE (base) == ADDRESS\n-\t      && GET_MODE (base) == Pmode\n-\t      && (XEXP (base, 0) == stack_pointer_rtx\n-\t\t  || XEXP (base, 0) == arg_pointer_rtx\n-#if HARD_FRAME_POINTER_REGNUM != FRAME_POINTER_REGNUM\n-\t\t  || XEXP (base, 0) == hard_frame_pointer_rtx\n-#endif\n-\t\t  || XEXP (base, 0) == frame_pointer_rtx))\n-\t    return 0;\n-\t  /* Constants in the function's constant pool are constant.  */\n-\t  if (GET_CODE (base) == SYMBOL_REF && CONSTANT_POOL_ADDRESS_P (base))\n-\t    return 0;\n-\t}\n-      return 1;\n-\n-    case UNSPEC_VOLATILE:\n-    case ASM_INPUT:\n-      return 1;\n-\n-    case ASM_OPERANDS:\n-      if (MEM_VOLATILE_P (x))\n-\treturn 1;\n-\n-    /* Fall through.  */\n-\n-    default:\n-      break;\n-    }\n-\n-  return 0;\n-}\n-\n-/* Returns nonzero if X might mention something which is not\n-   local to the function and is not constant.  */\n-\n-static int\n-nonlocal_mentioned_p (rtx x)\n-{\n-  if (INSN_P (x))\n-    {\n-      if (CALL_P (x))\n-\t{\n-\t  if (! CONST_OR_PURE_CALL_P (x))\n-\t    return 1;\n-\t  x = CALL_INSN_FUNCTION_USAGE (x);\n-\t  if (x == 0)\n-\t    return 0;\n-\t}\n-      else\n-\tx = PATTERN (x);\n-    }\n-\n-  return for_each_rtx (&x, nonlocal_mentioned_p_1, NULL);\n-}\n-\n-/* A subroutine of nonlocal_referenced_p, returns 1 if *LOC references\n-   something which is not local to the function and is not constant.  */\n-\n-static int\n-nonlocal_referenced_p_1 (rtx *loc, void *data ATTRIBUTE_UNUSED)\n-{\n-  rtx x = *loc;\n-\n-  if (! x)\n-    return 0;\n-\n-  switch (GET_CODE (x))\n-    {\n-    case MEM:\n-    case REG:\n-    case SYMBOL_REF:\n-    case SUBREG:\n-      return nonlocal_mentioned_p (x);\n-\n-    case CALL:\n-      /* Non-constant calls and recursion are not local.  */\n-      return 1;\n-\n-    case SET:\n-      if (nonlocal_mentioned_p (SET_SRC (x)))\n-\treturn 1;\n-\n-      if (MEM_P (SET_DEST (x)))\n-\treturn nonlocal_mentioned_p (XEXP (SET_DEST (x), 0));\n-\n-      /* If the destination is anything other than a CC0, PC,\n-\t MEM, REG, or a SUBREG of a REG that occupies all of\n-\t the REG, then X references nonlocal memory if it is\n-\t mentioned in the destination.  */\n-      if (GET_CODE (SET_DEST (x)) != CC0\n-\t  && GET_CODE (SET_DEST (x)) != PC\n-\t  && !REG_P (SET_DEST (x))\n-\t  && ! (GET_CODE (SET_DEST (x)) == SUBREG\n-\t\t&& REG_P (SUBREG_REG (SET_DEST (x)))\n-\t\t&& (((GET_MODE_SIZE (GET_MODE (SUBREG_REG (SET_DEST (x))))\n-\t\t      + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD)\n-\t\t    == ((GET_MODE_SIZE (GET_MODE (SET_DEST (x)))\n-\t\t\t + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD))))\n-\treturn nonlocal_mentioned_p (SET_DEST (x));\n-      return 0;\n-\n-    case CLOBBER:\n-      if (MEM_P (XEXP (x, 0)))\n-\treturn nonlocal_mentioned_p (XEXP (XEXP (x, 0), 0));\n-      return 0;\n-\n-    case USE:\n-      return nonlocal_mentioned_p (XEXP (x, 0));\n-\n-    case ASM_INPUT:\n-    case UNSPEC_VOLATILE:\n-      return 1;\n-\n-    case ASM_OPERANDS:\n-      if (MEM_VOLATILE_P (x))\n-\treturn 1;\n-\n-    /* Fall through.  */\n-\n-    default:\n-      break;\n-    }\n-\n-  return 0;\n-}\n-\n-/* Returns nonzero if X might reference something which is not\n-   local to the function and is not constant.  */\n-\n-static int\n-nonlocal_referenced_p (rtx x)\n-{\n-  if (INSN_P (x))\n-    {\n-      if (CALL_P (x))\n-\t{\n-\t  if (! CONST_OR_PURE_CALL_P (x))\n-\t    return 1;\n-\t  x = CALL_INSN_FUNCTION_USAGE (x);\n-\t  if (x == 0)\n-\t    return 0;\n-\t}\n-      else\n-\tx = PATTERN (x);\n-    }\n-\n-  return for_each_rtx (&x, nonlocal_referenced_p_1, NULL);\n-}\n-\n-/* A subroutine of nonlocal_set_p, returns 1 if *LOC sets\n-   something which is not local to the function and is not constant.  */\n-\n-static int\n-nonlocal_set_p_1 (rtx *loc, void *data ATTRIBUTE_UNUSED)\n-{\n-  rtx x = *loc;\n-\n-  if (! x)\n-    return 0;\n-\n-  switch (GET_CODE (x))\n-    {\n-    case CALL:\n-      /* Non-constant calls and recursion are not local.  */\n-      return 1;\n-\n-    case PRE_INC:\n-    case PRE_DEC:\n-    case POST_INC:\n-    case POST_DEC:\n-    case PRE_MODIFY:\n-    case POST_MODIFY:\n-      return nonlocal_mentioned_p (XEXP (x, 0));\n-\n-    case SET:\n-      if (nonlocal_mentioned_p (SET_DEST (x)))\n-\treturn 1;\n-      return nonlocal_set_p (SET_SRC (x));\n-\n-    case CLOBBER:\n-      return nonlocal_mentioned_p (XEXP (x, 0));\n-\n-    case USE:\n-      return 0;\n-\n-    case ASM_INPUT:\n-    case UNSPEC_VOLATILE:\n-      return 1;\n-\n-    case ASM_OPERANDS:\n-      if (MEM_VOLATILE_P (x))\n-\treturn 1;\n-\n-    /* Fall through.  */\n-\n-    default:\n-      break;\n-    }\n-\n-  return 0;\n-}\n-\n-/* Returns nonzero if X might set something which is not\n-   local to the function and is not constant.  */\n-\n-static int\n-nonlocal_set_p (rtx x)\n-{\n-  if (INSN_P (x))\n-    {\n-      if (CALL_P (x))\n-\t{\n-\t  if (! CONST_OR_PURE_CALL_P (x))\n-\t    return 1;\n-\t  x = CALL_INSN_FUNCTION_USAGE (x);\n-\t  if (x == 0)\n-\t    return 0;\n-\t}\n-      else\n-\tx = PATTERN (x);\n-    }\n-\n-  return for_each_rtx (&x, nonlocal_set_p_1, NULL);\n-}\n-\n-/* Mark the function if it is pure or constant.  */\n-\n-void\n-mark_constant_function (void)\n-{\n-  rtx insn;\n-  int nonlocal_memory_referenced;\n-\n-  if (TREE_READONLY (current_function_decl)\n-      || DECL_IS_PURE (current_function_decl)\n-      || TREE_THIS_VOLATILE (current_function_decl)\n-      || current_function_has_nonlocal_goto\n-      || !targetm.binds_local_p (current_function_decl))\n-    return;\n-\n-  /* A loop might not return which counts as a side effect.  */\n-  if (mark_dfs_back_edges ())\n-    return;\n-\n-  nonlocal_memory_referenced = 0;\n-\n-  init_alias_analysis ();\n-\n-  /* Determine if this is a constant or pure function.  */\n-\n-  for (insn = get_insns (); insn; insn = NEXT_INSN (insn))\n-    {\n-      if (! INSN_P (insn))\n-\tcontinue;\n-\n-      if (nonlocal_set_p (insn) || global_reg_mentioned_p (insn)\n-\t  || volatile_refs_p (PATTERN (insn)))\n-\tbreak;\n-\n-      if (! nonlocal_memory_referenced)\n-\tnonlocal_memory_referenced = nonlocal_referenced_p (insn);\n-    }\n-\n-  end_alias_analysis ();\n-\n-  /* Mark the function.  */\n-\n-  if (insn)\n-    ;\n-  else if (nonlocal_memory_referenced)\n-    {\n-      cgraph_rtl_info (current_function_decl)->pure_function = 1;\n-      DECL_IS_PURE (current_function_decl) = 1;\n-    }\n-  else\n-    {\n-      cgraph_rtl_info (current_function_decl)->const_function = 1;\n-      TREE_READONLY (current_function_decl) = 1;\n-    }\n-}\n-\f\n \n void\n init_alias_once (void)\n@@ -2979,28 +2700,6 @@ rest_of_handle_cfg (void)\n   if (optimize)\n     cleanup_cfg (CLEANUP_EXPENSIVE\n                  | (flag_thread_jumps ? CLEANUP_THREADING : 0));\n-\n-  /* It may make more sense to mark constant functions after dead code is\n-     eliminated by life_analysis, but we need to do it early, as -fprofile-arcs\n-     may insert code making function non-constant, but we still must consider\n-     it as constant, otherwise -fbranch-probabilities will not read data back.\n-\n-     life_analysis rarely eliminates modification of external memory.\n-\n-     FIXME: now with tree based profiling we are in the trap described above\n-     again.  It seems to be easiest to disable the optimization for time\n-     being before the problem is either solved by moving the transformation\n-     to the IPA level (we need the CFG for this) or the very early optimization\n-     passes are made to ignore the const/pure flags so code does not change.  */\n-  if (optimize\n-      && (!flag_tree_based_profiling\n-          || (!profile_arc_flag && !flag_branch_probabilities)))\n-    {\n-      /* Alias analysis depends on this information and mark_constant_function\n-       depends on alias analysis.  */\n-      reg_scan (get_insns (), max_reg_num ());\n-      mark_constant_function ();\n-    }\n }\n \n struct tree_opt_pass pass_cfg ="}, {"sha": "f21426fa995d1ee4655d072d45016f4a3ed0af74", "filename": "gcc/calls.c", "status": "modified", "additions": 0, "deletions": 9, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -570,17 +570,8 @@ flags_from_decl_or_type (tree exp)\n \n   if (DECL_P (exp))\n     {\n-      struct cgraph_rtl_info *i = cgraph_rtl_info (exp);\n       type = TREE_TYPE (exp);\n \n-      if (i)\n-\t{\n-\t  if (i->pure_function)\n-\t    flags |= ECF_PURE | ECF_LIBCALL_BLOCK;\n-\t  if (i->const_function)\n-\t    flags |= ECF_CONST | ECF_LIBCALL_BLOCK;\n-\t}\n-\n       /* The function exp may have the `malloc' attribute.  */\n       if (DECL_IS_MALLOC (exp))\n \tflags |= ECF_MALLOC;"}, {"sha": "d063d41906dd4bead477d291ad8dadbca73bd720", "filename": "gcc/cgraph.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fcgraph.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fcgraph.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraph.h?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -107,8 +107,6 @@ struct cgraph_global_info GTY(())\n struct cgraph_rtl_info GTY(())\n {\n    int preferred_incoming_stack_boundary;\n-   bool const_function;\n-   bool pure_function;\n };\n \n /* The cgraph data structure."}, {"sha": "9d2b6712c479a035e55c13204ca3ff37439c9b4b", "filename": "gcc/common.opt", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fcommon.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fcommon.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcommon.opt?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -491,6 +491,18 @@ finstrument-functions\n Common Report Var(flag_instrument_function_entry_exit)\n Instrument function entry and exit with profiling calls\n \n+fipa-pure-const\n+Common Report Var(flag_ipa_pure_const) Init(0)\n+Discover pure and const functions\n+\n+fipa-reference\n+Common Report Var(flag_ipa_reference) Init(0)\n+Discover readonly and non addressable static variables\n+\n+fipa-type-escape\n+Common Report Var(flag_ipa_type_escape) Init(0)\n+Type based escape and alias analysis\n+\n fivopts\n Common Report Var(flag_ivopts) Init(1)\n Optimize induction variables on trees\n@@ -915,6 +927,10 @@ ftree-pre\n Common Report Var(flag_tree_pre)\n Enable SSA-PRE optimization on trees\n \n+ftree-promote-statics\n+Common Report Var(flag_tree_promote_statics) Init(0)\n+Enable promotion of static variables\n+\n ftree-salias\n Common Report Var(flag_tree_salias)\n Perform structural alias analysis"}, {"sha": "1402607aa8b0945efa1c3a79f600aa2c2070242e", "filename": "gcc/ipa-pure-const.c", "status": "added", "additions": 729, "deletions": 0, "changes": 729, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-pure-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-pure-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-pure-const.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,729 @@\n+/* Callgraph based analysis of static variables.\n+   Copyright (C) 2004, 2005 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+/* This file mark functions as being either const (TREE_READONLY) or\n+   pure (DECL_IS_PURE).\n+\n+   This must be run after inlining decisions have been made since\n+   otherwise, the local sets will not contain information that is\n+   consistent with post inlined state.  The global sets are not prone\n+   to this problem since they are by definition transitive.  */\n+\n+/* The code in this module is called by the ipa pass manager. It\n+   should be one of the later passes since it's information is used by\n+   the rest of the compilation. */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"tree.h\"\n+#include \"tree-flow.h\"\n+#include \"tree-inline.h\"\n+#include \"tree-pass.h\"\n+#include \"langhooks.h\"\n+#include \"pointer-set.h\"\n+#include \"ggc.h\"\n+#include \"ipa-utils.h\"\n+#include \"c-common.h\"\n+#include \"tree-gimple.h\"\n+#include \"cgraph.h\"\n+#include \"output.h\"\n+#include \"flags.h\"\n+#include \"timevar.h\"\n+#include \"diagnostic.h\"\n+#include \"langhooks.h\"\n+\n+static struct pointer_set_t *visited_nodes;\n+\n+/* Lattice values for const and pure functions.  Everything starts out\n+   being const, then may drop to pure and then neither depending on\n+   what is found.  */\n+enum pure_const_state_e\n+{\n+  IPA_CONST,\n+  IPA_PURE,\n+  IPA_NEITHER\n+};\n+\n+/* Holder inserted into the ipa_dfs_info aux field to hold the\n+   const_state.  */\n+struct funct_state_d \n+{\n+  enum pure_const_state_e pure_const_state;\n+  bool state_set_in_source;\n+};\n+\n+typedef struct funct_state_d * funct_state;\n+\n+/* Return the function state from NODE.  */ \n+\n+static inline funct_state\n+get_function_state (struct cgraph_node *node)\n+{\n+  struct ipa_dfs_info * info = node->aux;\n+  return info->aux;\n+}\n+\n+/* Check to see if the use (or definition when CHECHING_WRITE is true) \n+   variable T is legal in a function that is either pure or const.  */\n+\n+static inline void \n+check_decl (funct_state local, \n+\t    tree t, bool checking_write)\n+{\n+  /* If the variable has the \"used\" attribute, treat it as if it had a\n+     been touched by the devil.  */\n+  if (lookup_attribute (\"used\", DECL_ATTRIBUTES (t)))\n+    {\n+      local->pure_const_state = IPA_NEITHER;\n+      return;\n+    }\n+\n+  /* Do not want to do anything with volatile except mark any\n+     function that uses one to be not const or pure.  */\n+  if (TREE_THIS_VOLATILE (t)) \n+    { \n+      local->pure_const_state = IPA_NEITHER;\n+      return;\n+    }\n+\n+  /* Do not care about a local automatic that is not static.  */\n+  if (!TREE_STATIC (t) && !DECL_EXTERNAL (t))\n+    return;\n+\n+  /* Since we have dealt with the locals and params cases above, if we\n+     are CHECKING_WRITE, this cannot be a pure or constant\n+     function.  */\n+  if (checking_write) \n+    local->pure_const_state = IPA_NEITHER;\n+\n+  if (DECL_EXTERNAL (t) || TREE_PUBLIC (t))\n+    {\n+      /* If the front end set the variable to be READONLY and\n+\t constant, we can allow this variable in pure or const\n+\t functions but the scope is too large for our analysis to set\n+\t these bits ourselves.  */\n+      \n+      if (TREE_READONLY (t)\n+\t  && DECL_INITIAL (t)\n+\t  && is_gimple_min_invariant (DECL_INITIAL (t)))\n+\t; /* Read of a constant, do not change the function state.  */\n+      else \n+\t{\n+\t  /* Just a regular read.  */\n+\t  if (local->pure_const_state == IPA_CONST)\n+\t    local->pure_const_state = IPA_PURE;\n+\t}\n+    }\n+  \n+  /* Compilation level statics can be read if they are readonly\n+     variables.  */\n+  if (TREE_READONLY (t))\n+    return;\n+\n+  /* Just a regular read.  */\n+  if (local->pure_const_state == IPA_CONST)\n+    local->pure_const_state = IPA_PURE;\n+}\n+\n+/* If T is a VAR_DECL check to see if it is an allowed reference.  */\n+\n+static void\n+check_operand (funct_state local, \n+\t       tree t, bool checking_write)\n+{\n+  if (!t) return;\n+\n+  if (TREE_CODE (t) == VAR_DECL)\n+    check_decl (local, t, checking_write); \n+}\n+\n+/* Examine tree T for references.  */\n+\n+static void\n+check_tree (funct_state local, tree t, bool checking_write)\n+{\n+  if ((TREE_CODE (t) == EXC_PTR_EXPR) || (TREE_CODE (t) == FILTER_EXPR))\n+    return;\n+\n+  while (TREE_CODE (t) == REALPART_EXPR \n+\t || TREE_CODE (t) == IMAGPART_EXPR\n+\t || handled_component_p (t))\n+    {\n+      if (TREE_CODE (t) == ARRAY_REF)\n+\tcheck_operand (local, TREE_OPERAND (t, 1), false);\n+      t = TREE_OPERAND (t, 0);\n+    }\n+\n+  /* The bottom of an indirect reference can only be read, not\n+     written.  */\n+  if (INDIRECT_REF_P (t))\n+    {\n+      check_tree (local, TREE_OPERAND (t, 0), false);\n+      \n+      /* Any indirect reference that occurs on the lhs\n+\t disqualifies the function from being pure or const. Any\n+\t indirect reference that occurs on the rhs disqualifies\n+\t the function from being const.  */\n+      if (checking_write) \n+\tlocal->pure_const_state = IPA_NEITHER;\n+      else \n+\tif (local->pure_const_state == IPA_CONST)\n+\t  local->pure_const_state = IPA_PURE;\n+    }\n+\n+  if (SSA_VAR_P (t))\n+    check_operand (local, t, checking_write);\n+}\n+\n+/* Scan tree T to see if there are any addresses taken in within T.  */\n+\n+static void \n+look_for_address_of (funct_state local, tree t)\n+{\n+  if (TREE_CODE (t) == ADDR_EXPR)\n+    {\n+      tree x = get_base_var (t);\n+      if (TREE_CODE (x) == VAR_DECL) \n+\t{\n+\t  check_decl (local, x, false);\n+\t  \n+\t  /* Taking the address of something appears to be reasonable\n+\t     in PURE code.  Not allowed in const.  */\n+\t  if (local->pure_const_state == IPA_CONST)\n+\t    local->pure_const_state = IPA_PURE;\n+\t}\n+    }\n+}\n+\n+/* Check to see if T is a read or address of operation on a var we are\n+   interested in analyzing.  LOCAL is passed in to get access to its\n+   bit vectors.  */\n+\n+static void\n+check_rhs_var (funct_state local, tree t)\n+{\n+  look_for_address_of (local, t);\n+\n+  /* Memcmp and strlen can both trap and they are declared pure.  */\n+  if (tree_could_trap_p (t)\n+      && local->pure_const_state == IPA_CONST)\n+    local->pure_const_state = IPA_PURE;\n+\n+  check_tree(local, t, false);\n+}\n+\n+/* Check to see if T is an assignment to a var we are interested in\n+   analyzing.  LOCAL is passed in to get access to its bit vectors. */\n+\n+static void\n+check_lhs_var (funct_state local, tree t)\n+{\n+  /* Memcmp and strlen can both trap and they are declared pure.\n+     Which seems to imply that we can apply the same rule here.  */\n+  if (tree_could_trap_p (t)\n+      && local->pure_const_state == IPA_CONST)\n+    local->pure_const_state = IPA_PURE;\n+    \n+  check_tree(local, t, true);\n+}\n+\n+/* This is a scaled down version of get_asm_expr_operands from\n+   tree_ssa_operands.c.  The version there runs much later and assumes\n+   that aliasing information is already available. Here we are just\n+   trying to find if the set of inputs and outputs contain references\n+   or address of operations to local static variables.  STMT is the\n+   actual asm statement.  */\n+\n+static void\n+get_asm_expr_operands (funct_state local, tree stmt)\n+{\n+  int noutputs = list_length (ASM_OUTPUTS (stmt));\n+  const char **oconstraints\n+    = (const char **) alloca ((noutputs) * sizeof (const char *));\n+  int i;\n+  tree link;\n+  const char *constraint;\n+  bool allows_mem, allows_reg, is_inout;\n+  \n+  for (i=0, link = ASM_OUTPUTS (stmt); link; ++i, link = TREE_CHAIN (link))\n+    {\n+      oconstraints[i] = constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_output_constraint (&constraint, i, 0, 0,\n+\t\t\t       &allows_mem, &allows_reg, &is_inout);\n+      \n+      check_lhs_var (local, TREE_VALUE (link));\n+    }\n+\n+  for (link = ASM_INPUTS (stmt); link; link = TREE_CHAIN (link))\n+    {\n+      constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_input_constraint (&constraint, 0, 0, noutputs, 0,\n+\t\t\t      oconstraints, &allows_mem, &allows_reg);\n+      \n+      check_rhs_var (local, TREE_VALUE (link));\n+    }\n+  \n+  for (link = ASM_CLOBBERS (stmt); link; link = TREE_CHAIN (link))\n+    if (simple_cst_equal(TREE_VALUE (link), memory_identifier_string) == 1) \n+      /* Abandon all hope, ye who enter here. */\n+      local->pure_const_state = IPA_NEITHER;\n+\n+  if (ASM_VOLATILE_P (stmt))\n+    local->pure_const_state = IPA_NEITHER;\n+}\n+\n+/* Check the parameters of a function call to CALL_EXPR to see if\n+   there are any references in the parameters that are not allowed for\n+   pure or const functions.  Also check to see if this is either an\n+   indirect call, a call outside the compilation unit, or has special\n+   attributes that may also effect the purity.  The CALL_EXPR node for\n+   the entire call expression.  */\n+\n+static void\n+check_call (funct_state local, tree call_expr) \n+{\n+  int flags = call_expr_flags(call_expr);\n+  tree operand_list = TREE_OPERAND (call_expr, 1);\n+  tree operand;\n+  tree callee_t = get_callee_fndecl (call_expr);\n+  struct cgraph_node* callee;\n+  enum availability avail = AVAIL_NOT_AVAILABLE;\n+\n+  for (operand = operand_list;\n+       operand != NULL_TREE;\n+       operand = TREE_CHAIN (operand))\n+    {\n+      tree argument = TREE_VALUE (operand);\n+      check_rhs_var (local, argument);\n+    }\n+  \n+  /* The const and pure flags are set by a variety of places in the\n+     compiler (including here).  If someone has already set the flags\n+     for the callee, (such as for some of the builtins) we will use\n+     them, otherwise we will compute our own information. \n+  \n+     Const and pure functions have less clobber effects than other\n+     functions so we process these first.  Otherwise if it is a call\n+     outside the compilation unit or an indirect call we punt.  This\n+     leaves local calls which will be processed by following the call\n+     graph.  */  \n+  if (callee_t)\n+    {\n+      callee = cgraph_node(callee_t);\n+      avail = cgraph_function_body_availability (callee);\n+\n+      /* When bad things happen to bad functions, they cannot be const\n+\t or pure.  */\n+      if (setjmp_call_p (callee_t))\n+\tlocal->pure_const_state = IPA_NEITHER;\n+\n+      if (DECL_BUILT_IN_CLASS (callee_t) == BUILT_IN_NORMAL)\n+\tswitch (DECL_FUNCTION_CODE (callee_t))\n+\t  {\n+\t  case BUILT_IN_LONGJMP:\n+\t  case BUILT_IN_NONLOCAL_GOTO:\n+\t    local->pure_const_state = IPA_NEITHER;\n+\t    break;\n+\t  default:\n+\t    break;\n+\t  }\n+    }\n+\n+  /* The callee is either unknown (indirect call) or there is just no\n+     scannable code for it (external call) .  We look to see if there\n+     are any bits available for the callee (such as by declaration or\n+     because it is builtin) and process solely on the basis of those\n+     bits. */\n+  if (avail == AVAIL_NOT_AVAILABLE || avail == AVAIL_OVERWRITABLE)\n+    {\n+      if (flags & ECF_PURE) \n+\t{\n+\t  if (local->pure_const_state == IPA_CONST)\n+\t    local->pure_const_state = IPA_PURE;\n+\t}\n+      else \n+\tlocal->pure_const_state = IPA_NEITHER;\n+    }\n+  else\n+    {\n+      /* We have the code and we will scan it for the effects. */\n+      if (flags & ECF_PURE) \n+\t{\n+\t  if (local->pure_const_state == IPA_CONST)\n+\t    local->pure_const_state = IPA_PURE;\n+\t}\n+    }\n+}\n+\n+/* TP is the part of the tree currently under the microscope.\n+   WALK_SUBTREES is part of the walk_tree api but is unused here.\n+   DATA is cgraph_node of the function being walked.  */\n+\n+/* FIXME: When this is converted to run over SSA form, this code\n+   should be converted to use the operand scanner.  */\n+\n+static tree\n+scan_function (tree *tp, \n+\t\t      int *walk_subtrees, \n+\t\t      void *data)\n+{\n+  struct cgraph_node *fn = data;\n+  tree t = *tp;\n+  funct_state local = get_function_state (fn);\n+\n+  switch (TREE_CODE (t))  \n+    {\n+    case VAR_DECL:\n+      if (DECL_INITIAL (t))\n+\twalk_tree (&DECL_INITIAL (t), scan_function, fn, visited_nodes);\n+      *walk_subtrees = 0;\n+      break;\n+\n+    case MODIFY_EXPR:\n+      {\n+\t/* First look on the lhs and see what variable is stored to */\n+\ttree lhs = TREE_OPERAND (t, 0);\n+\ttree rhs = TREE_OPERAND (t, 1);\n+\tcheck_lhs_var (local, lhs);\n+\n+\t/* For the purposes of figuring out what the cast affects */\n+\n+\t/* Next check the operands on the rhs to see if they are ok. */\n+\tswitch (TREE_CODE_CLASS (TREE_CODE (rhs))) \n+\t  {\n+\t  case tcc_binary:\t    \n+ \t    {\n+ \t      tree op0 = TREE_OPERAND (rhs, 0);\n+ \t      tree op1 = TREE_OPERAND (rhs, 1);\n+ \t      check_rhs_var (local, op0);\n+ \t      check_rhs_var (local, op1);\n+\t    }\n+\t    break;\n+\t  case tcc_unary:\n+ \t    {\n+ \t      tree op0 = TREE_OPERAND (rhs, 0);\n+ \t      check_rhs_var (local, op0);\n+ \t    }\n+\n+\t    break;\n+\t  case tcc_reference:\n+\t    check_rhs_var (local, rhs);\n+\t    break;\n+\t  case tcc_declaration:\n+\t    check_rhs_var (local, rhs);\n+\t    break;\n+\t  case tcc_expression:\n+\t    switch (TREE_CODE (rhs)) \n+\t      {\n+\t      case ADDR_EXPR:\n+\t\tcheck_rhs_var (local, rhs);\n+\t\tbreak;\n+\t      case CALL_EXPR: \n+\t\tcheck_call (local, rhs);\n+\t\tbreak;\n+\t      default:\n+\t\tbreak;\n+\t      }\n+\t    break;\n+\t  default:\n+\t    break;\n+\t  }\n+\t*walk_subtrees = 0;\n+      }\n+      break;\n+\n+    case ADDR_EXPR:\n+      /* This case is here to find addresses on rhs of constructors in\n+\t decl_initial of static variables. */\n+      check_rhs_var (local, t);\n+      *walk_subtrees = 0;\n+      break;\n+\n+    case LABEL_EXPR:\n+      if (DECL_NONLOCAL (TREE_OPERAND (t, 0)))\n+\t/* Target of long jump. */\n+\tlocal->pure_const_state = IPA_NEITHER;\n+      break;\n+\n+    case CALL_EXPR: \n+      check_call (local, t);\n+      *walk_subtrees = 0;\n+      break;\n+      \n+    case ASM_EXPR:\n+      get_asm_expr_operands (local, t);\n+      *walk_subtrees = 0;\n+      break;\n+      \n+    default:\n+      break;\n+    }\n+  return NULL;\n+}\n+\n+/* This is the main routine for finding the reference patterns for\n+   global variables within a function FN.  */\n+\n+static void\n+analyze_function (struct cgraph_node *fn)\n+{\n+  funct_state l = xcalloc (1, sizeof (struct funct_state_d));\n+  tree decl = fn->decl;\n+  struct ipa_dfs_info * w_info = fn->aux;\n+\n+  w_info->aux = l;\n+\n+  l->pure_const_state = IPA_CONST;\n+  l->state_set_in_source = false;\n+\n+  /* If this is a volatile function, do not touch this unless it has\n+     been marked as const or pure by the front end.  */\n+  if (TREE_THIS_VOLATILE (decl))\n+    {\n+      l->pure_const_state = IPA_NEITHER;\n+      return;\n+    }\n+\n+  if (TREE_READONLY (decl))\n+    {\n+      l->pure_const_state = IPA_CONST;\n+      l->state_set_in_source = true;\n+    }\n+  if (DECL_IS_PURE (decl))\n+    {\n+      l->pure_const_state = IPA_PURE;\n+      l->state_set_in_source = true;\n+    }\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"\\n local analysis of %s with initial value = %d\\n \", \n+\t       cgraph_node_name (fn),\n+\t       l->pure_const_state);\n+    }\n+  \n+  if (!l->state_set_in_source)\n+    {\n+      struct function *this_cfun = DECL_STRUCT_FUNCTION (decl);\n+      basic_block this_block;\n+      \n+      FOR_EACH_BB_FN (this_block, this_cfun)\n+\t{\n+\t  block_stmt_iterator bsi;\n+\t  for (bsi = bsi_start (this_block); !bsi_end_p (bsi); bsi_next (&bsi))\n+\t    {\n+\t      walk_tree (bsi_stmt_ptr (bsi), scan_function, \n+\t\t\t fn, visited_nodes);\n+\t      if (l->pure_const_state == IPA_NEITHER) \n+\t\treturn;\n+\t    }\n+\t}\n+\n+      if (l->pure_const_state != IPA_NEITHER)\n+\t{\n+\t  tree old_decl = current_function_decl;\n+\t  /* Const functions cannot have back edges (an\n+\t     indication of possible infinite loop side\n+\t     effect.  */\n+\t    \n+\t  current_function_decl = fn->decl;\n+\n+\t  /* The C++ front end, has a tendency to some times jerk away\n+\t     a function after it has created it.  This should have\n+\t     been fixed.  */\n+\t  gcc_assert (DECL_STRUCT_FUNCTION (fn->decl));\n+\t  \n+\t  push_cfun (DECL_STRUCT_FUNCTION (fn->decl));\n+\t  \n+\t  if (mark_dfs_back_edges ())\n+\t    l->pure_const_state = IPA_NEITHER;\n+\t  \n+\t  current_function_decl = old_decl;\n+\t  pop_cfun ();\n+\t}\n+    }\n+}\n+\n+\f\n+/* Produce the global information by preforming a transitive closure\n+   on the local information that was produced by ipa_analyze_function\n+   and ipa_analyze_variable.  */\n+\n+static void\n+static_execute (void)\n+{\n+  struct cgraph_node *node;\n+  struct cgraph_node *w;\n+  struct cgraph_node **order =\n+    xcalloc (cgraph_n_nodes, sizeof (struct cgraph_node *));\n+  int order_pos = order_pos = ipa_utils_reduced_inorder (order, true, false);\n+  int i;\n+  struct ipa_dfs_info * w_info;\n+\n+  if (!memory_identifier_string)\n+    memory_identifier_string = build_string(7, \"memory\");\n+\n+  /* There are some shared nodes, in particular the initializers on\n+     static declarations.  We do not need to scan them more than once\n+     since all we would be interested in are the addressof\n+     operations.  */\n+  visited_nodes = pointer_set_create ();\n+\n+  /* Process all of the functions. \n+\n+     We do not want to process any of the clones so we check that this\n+     is a master clone.  However, we do NOT process any\n+     AVAIL_OVERWRITABLE functions (these are never clones) we cannot\n+     guarantee that what we learn about the one we see will be true\n+     for the one that overriders it.\n+  */\n+  for (node = cgraph_nodes; node; node = node->next)\n+    if (node->analyzed && cgraph_is_master_clone (node))\n+      analyze_function (node);\n+\n+  pointer_set_destroy (visited_nodes);\n+  visited_nodes = NULL;\n+  if (dump_file)\n+    {\n+      dump_cgraph (dump_file);\n+      ipa_utils_print_order(dump_file, \"reduced\", order, order_pos);\n+    }\n+\n+  /* Propagate the local information thru the call graph to produce\n+     the global information.  All the nodes within a cycle will have\n+     the same info so we collapse cycles first.  Then we can do the\n+     propagation in one pass from the leaves to the roots.  */\n+  for (i = 0; i < order_pos; i++ )\n+    {\n+      enum pure_const_state_e pure_const_state = IPA_CONST;\n+      node = order[i];\n+\n+      /* Find the worst state for any node in the cycle.  */\n+      w = node;\n+      while (w)\n+\t{\n+\t  funct_state w_l = get_function_state (w);\n+\t  if (pure_const_state < w_l->pure_const_state)\n+\t    pure_const_state = w_l->pure_const_state;\n+\n+\t  if (pure_const_state == IPA_NEITHER) \n+\t    break;\n+\n+\t  if (!w_l->state_set_in_source)\n+\t    {\n+\t      struct cgraph_edge *e;\n+\t      for (e = w->callees; e; e = e->next_callee) \n+\t\t{\n+\t\t  struct cgraph_node *y = e->callee;\n+\t\t  /* Only look at the master nodes and skip external nodes.  */\n+\t\t  y = cgraph_master_clone (y);\n+\t\t  if (y)\n+\t\t    {\n+\t\t      funct_state y_l = get_function_state (y);\n+\t\t      if (pure_const_state < y_l->pure_const_state)\n+\t\t\tpure_const_state = y_l->pure_const_state;\n+\t\t      if (pure_const_state == IPA_NEITHER) \n+\t\t\tbreak;\n+\t\t    }\n+\t\t}\n+\t    }\n+\t  w_info = w->aux;\n+\t  w = w_info->next_cycle;\n+\t}\n+\n+      /* Copy back the region's pure_const_state which is shared by\n+\t all nodes in the region.  */\n+      w = node;\n+      while (w)\n+\t{\n+\t  funct_state w_l = get_function_state (w);\n+\n+\t  /* All nodes within a cycle share the same info.  */\n+\t  if (!w_l->state_set_in_source)\n+\t    {\n+\t      w_l->pure_const_state = pure_const_state;\n+\t      switch (pure_const_state)\n+\t\t{\n+\t\tcase IPA_CONST:\n+\t\t  TREE_READONLY (w->decl) = 1;\n+\t\t  if (dump_file)\n+\t\t    fprintf (dump_file, \"Function found to be const: %s\\n\",  \n+\t\t\t     lang_hooks.decl_printable_name(w->decl, 2)); \n+\t\t  break;\n+\t\t  \n+\t\tcase IPA_PURE:\n+\t\t  DECL_IS_PURE (w->decl) = 1;\n+\t\t  if (dump_file)\n+\t\t    fprintf (dump_file, \"Function found to be pure: %s\\n\",  \n+\t\t\t     lang_hooks.decl_printable_name(w->decl, 2)); \n+\t\t  break;\n+\t\t  \n+\t\tdefault:\n+\t\t  break;\n+\t\t}\n+\t    }\n+\t  w_info = w->aux;\n+\t  w = w_info->next_cycle;\n+\t}\n+    }\n+\n+  /* Cleanup. */\n+  for (node = cgraph_nodes; node; node = node->next)\n+    /* Get rid of the aux information.  */\n+    if (node->aux)\n+      {\n+\tfree (node->aux);\n+\tnode->aux = NULL;\n+      }\n+\n+  free (order);\n+}\n+\n+static bool\n+gate_pure_const (void)\n+{\n+  return (flag_unit_at_a_time != 0 && flag_ipa_pure_const \n+\t  /* Don't bother doing anything if the program has errors.  */\n+\t  && !(errorcount || sorrycount));\n+}\n+\n+struct tree_opt_pass pass_ipa_pure_const =\n+{\n+  \"ipa-pure-const\",\t\t        /* name */\n+  gate_pure_const,\t\t\t/* gate */\n+  static_execute,\t\t\t/* execute */\n+  NULL,\t\t\t\t\t/* sub */\n+  NULL,\t\t\t\t\t/* next */\n+  0,\t\t\t\t\t/* static_pass_number */\n+  TV_IPA_PURE_CONST,\t\t        /* tv_id */\n+  0,\t                                /* properties_required */\n+  0,\t\t\t\t\t/* properties_provided */\n+  0,\t\t\t\t\t/* properties_destroyed */\n+  0,\t\t\t\t\t/* todo_flags_start */\n+  0,                                    /* todo_flags_finish */\n+  0\t\t\t\t\t/* letter */\n+};\n+\n+"}, {"sha": "223a56ac6805e105fa38f90596e1569891869307", "filename": "gcc/ipa-reference.c", "status": "added", "additions": 1317, "deletions": 0, "changes": 1317, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-reference.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-reference.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-reference.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,1317 @@\n+/* Callgraph based analysis of static variables.\n+   Copyright (C) 2004, 2005 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  \n+*/\n+\n+/* This file gathers information about how variables whose scope is\n+   confined to the compilation unit are used.  \n+\n+   There are two categories of information produced by this pass:\n+\n+   1) The addressable (TREE_ADDRESSABLE) bit and readonly\n+   (TREE_READONLY) bit associated with these variables is properly set\n+   based on scanning all of the code withing the compilation unit.\n+\n+   2) The transitive call site specific clobber effects are computed\n+   for the variables whose scope is contained within this compilation\n+   unit.\n+\n+   First each function and static variable initialization is analyzed\n+   to determine which local static variables are either read, written,\n+   or have their address taken.  Any local static that has its address\n+   taken is removed from consideration.  Once the local read and\n+   writes are determined, a transitive closure of this information is\n+   performed over the call graph to determine the worst case set of\n+   side effects of each call.  In later parts of the compiler, these\n+   local and global sets are examined to make the call clobbering less\n+   traumatic, promote some statics to registers, and improve aliasing\n+   information.\n+   \n+   Currently must be run after inlining decisions have been made since\n+   otherwise, the local sets will not contain information that is\n+   consistent with post inlined state.  The global sets are not prone\n+   to this problem since they are by definition transitive.  \n+*/\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"tree.h\"\n+#include \"tree-flow.h\"\n+#include \"tree-inline.h\"\n+#include \"tree-pass.h\"\n+#include \"langhooks.h\"\n+#include \"pointer-set.h\"\n+#include \"ggc.h\"\n+#include \"ipa-utils.h\"\n+#include \"ipa-reference.h\"\n+#include \"c-common.h\"\n+#include \"tree-gimple.h\"\n+#include \"cgraph.h\"\n+#include \"output.h\"\n+#include \"flags.h\"\n+#include \"timevar.h\"\n+#include \"diagnostic.h\"\n+#include \"langhooks.h\"\n+\n+/* This splay tree contains all of the static variables that are\n+   being considered by the compilation level alias analysis.  For\n+   module_at_a_time compilation, this is the set of static but not\n+   public variables.  Any variables that either have their address\n+   taken or participate in otherwise unsavory operations are deleted\n+   from this list.  */\n+static GTY((param1_is(int), param2_is(tree)))\n+     splay_tree reference_vars_to_consider;\n+\n+/* This bitmap is used to knock out the module static variables whose\n+   addresses have been taken and passed around.  */\n+static bitmap module_statics_escape;\n+\n+/* This bitmap is used to knock out the module static variables that\n+   are not readonly.  */\n+static bitmap module_statics_written;\n+\n+/* A bit is set for every module static we are considering.  This is\n+   ored into the local info when asm code is found that clobbers all\n+   memory. */\n+static bitmap all_module_statics;\n+\n+static struct pointer_set_t *visited_nodes;\n+\n+static bitmap_obstack ipa_obstack;\n+\n+enum initialization_status_t\n+{\n+  UNINITIALIZED,\n+  RUNNING,\n+  FINISHED\n+};\n+\n+tree memory_identifier_string;\n+\n+/* Return the ipa_reference_vars structure starting from the cgraph NODE.  */\n+static inline ipa_reference_vars_info_t\n+get_reference_vars_info_from_cgraph (struct cgraph_node * node)\n+{\n+  return get_var_ann (node->decl)->reference_vars_info;\n+}\n+\n+/* Get a bitmap that contains all of the locally referenced static\n+   variables for function FN.  */\n+static ipa_reference_local_vars_info_t\n+get_local_reference_vars_info (tree fn) \n+{\n+  ipa_reference_vars_info_t info = get_var_ann (fn)->reference_vars_info;\n+\n+  if (info)\n+    return info->local;\n+  else\n+    /* This phase was not run.  */ \n+    return NULL;\n+}\n+\n+/* Get a bitmap that contains all of the globally referenced static\n+   variables for function FN.  */\n+ \n+static ipa_reference_global_vars_info_t\n+get_global_reference_vars_info (tree fn) \n+{\n+  ipa_reference_vars_info_t info = get_var_ann (fn)->reference_vars_info;\n+\n+  if (info)\n+    return info->global;\n+  else\n+    /* This phase was not run.  */ \n+    return NULL;\n+}\n+\n+/* Return a bitmap indexed by VAR_DECL uid for the static variables\n+   that may be read locally by the execution of the function fn.\n+   Returns NULL if no data is available.  */\n+\n+bitmap \n+ipa_reference_get_read_local (tree fn)\n+{\n+  ipa_reference_local_vars_info_t l = get_local_reference_vars_info (fn);\n+  if (l) \n+    return l->statics_read;\n+  else\n+    return NULL;\n+}\n+\n+/* Return a bitmap indexed by VAR_DECL uid for the static variables\n+   that may be written locally by the execution of the function fn.\n+   Returns NULL if no data is available.  */\n+\n+bitmap \n+ipa_reference_get_written_local (tree fn)\n+{\n+  ipa_reference_local_vars_info_t l = get_local_reference_vars_info (fn);\n+  if (l) \n+    return l->statics_written;\n+  else\n+    return NULL;\n+}\n+\n+/* Return a bitmap indexed by VAR_DECL uid for the static variables\n+   that are read during the execution of the function FN.  Returns\n+   NULL if no data is available.  */\n+\n+bitmap \n+ipa_reference_get_read_global (tree fn) \n+{\n+  ipa_reference_global_vars_info_t g = get_global_reference_vars_info (fn);\n+  if (g) \n+    return g->statics_read;\n+  else\n+    return NULL;\n+}\n+\n+/* Return a bitmap indexed by VAR_DECL uid for the static variables\n+   that are written during the execution of the function FN.  Note\n+   that variables written may or may not be read during the function\n+   call.  Returns NULL if no data is available.  */\n+\n+bitmap \n+ipa_reference_get_written_global (tree fn) \n+{\n+  ipa_reference_global_vars_info_t g = get_global_reference_vars_info (fn);\n+  if (g) \n+    return g->statics_written;\n+  else\n+    return NULL;\n+}\n+\n+/* Return a bitmap indexed by_DECL_UID uid for the static variables\n+   that are not read during the execution of the function FN.  Returns\n+   NULL if no data is available.  */\n+\n+bitmap \n+ipa_reference_get_not_read_global (tree fn) \n+{\n+  ipa_reference_global_vars_info_t g = get_global_reference_vars_info (fn);\n+  if (g) \n+    return g->statics_not_read;\n+  else\n+    return NULL;\n+}\n+\n+/* Return a bitmap indexed by DECL_UID uid for the static variables\n+   that are not written during the execution of the function FN.  Note\n+   that variables written may or may not be read during the function\n+   call.  Returns NULL if no data is available.  */\n+\n+bitmap \n+ipa_reference_get_not_written_global (tree fn) \n+{\n+  ipa_reference_global_vars_info_t g = get_global_reference_vars_info (fn);\n+  if (g) \n+    return g->statics_not_written;\n+  else\n+    return NULL;\n+}\n+\n+\f\n+\n+/* Add VAR to all_module_statics and the two\n+   reference_vars_to_consider* sets.  */\n+\n+static inline void \n+add_static_var (tree var) \n+{\n+  int uid = DECL_UID (var);\n+  if (!bitmap_bit_p (all_module_statics, uid))\n+    {\n+      splay_tree_insert (reference_vars_to_consider,\n+\t\t\t uid, (splay_tree_value)var);\n+      bitmap_set_bit (all_module_statics, uid);\n+    }\n+}\n+\n+/* Return true if the variable T is the right kind of static variable to\n+   perform compilation unit scope escape analysis.  */\n+\n+static inline bool \n+has_proper_scope_for_analysis (tree t)\n+{\n+  /* If the variable has the \"used\" attribute, treat it as if it had a\n+     been touched by the devil.  */\n+  if (lookup_attribute (\"used\", DECL_ATTRIBUTES (t)))\n+    return false;\n+\n+  /* Do not want to do anything with volatile except mark any\n+     function that uses one to be not const or pure.  */\n+  if (TREE_THIS_VOLATILE (t)) \n+    return false;\n+\n+  /* Do not care about a local automatic that is not static.  */\n+  if (!TREE_STATIC (t) && !DECL_EXTERNAL (t))\n+    return false;\n+\n+  if (DECL_EXTERNAL (t) || TREE_PUBLIC (t))\n+    return false;\n+\n+  /* This is a variable we care about.  Check if we have seen it\n+     before, and if not add it the set of variables we care about.  */\n+  if (!bitmap_bit_p (all_module_statics, DECL_UID (t)))\n+    add_static_var (t);\n+\n+  return true;\n+}\n+\n+/* If T is a VAR_DECL for a static that we are interested in, add the\n+   uid to the bitmap.  */\n+\n+static void\n+check_operand (ipa_reference_local_vars_info_t local, \n+\t       tree t, bool checking_write)\n+{\n+  if (!t) return;\n+\n+  if ((TREE_CODE (t) == VAR_DECL)\n+      && (has_proper_scope_for_analysis (t))) \n+    {\n+      if (checking_write)\n+\t{\n+\t  if (local)\n+\t    bitmap_set_bit (local->statics_written, DECL_UID (t));\n+\t  /* Mark the write so we can tell which statics are\n+\t     readonly.  */\n+\t  bitmap_set_bit (module_statics_written, DECL_UID (t));\n+\t}\n+      else if (local)\n+\tbitmap_set_bit (local->statics_read, DECL_UID (t));\n+    }\n+}\n+\n+/* Examine tree T for references to static variables. All internal\n+   references like array references or indirect references are added\n+   to the READ_BM. Direct references are added to either READ_BM or\n+   WRITE_BM depending on the value of CHECKING_WRITE.   */\n+\n+static void\n+check_tree (ipa_reference_local_vars_info_t local, tree t, bool checking_write)\n+{\n+  if ((TREE_CODE (t) == EXC_PTR_EXPR) || (TREE_CODE (t) == FILTER_EXPR))\n+    return;\n+\n+  while (TREE_CODE (t) == REALPART_EXPR \n+\t || TREE_CODE (t) == IMAGPART_EXPR\n+\t || handled_component_p (t))\n+    {\n+      if (TREE_CODE (t) == ARRAY_REF)\n+\tcheck_operand (local, TREE_OPERAND (t, 1), false);\n+      t = TREE_OPERAND (t, 0);\n+    }\n+\n+  /* The bottom of an indirect reference can only be read, not\n+     written.  So just recurse and whatever we find, check it against\n+     the read bitmaps.  */\n+\n+  /*  if (INDIRECT_REF_P (t) || TREE_CODE (t) == MEM_REF) */\n+  /* FIXME when we have array_ref's of pointers.  */\n+  if (INDIRECT_REF_P (t))\n+    check_tree (local, TREE_OPERAND (t, 0), false);\n+\n+  if (SSA_VAR_P (t))\n+    check_operand (local, t, checking_write);\n+}\n+\n+/* Scan tree T to see if there are any addresses taken in within T.  */\n+\n+static void \n+look_for_address_of (tree t)\n+{\n+  if (TREE_CODE (t) == ADDR_EXPR)\n+    {\n+      tree x = get_base_var (t);\n+      if (TREE_CODE (x) == VAR_DECL) \n+\tif (has_proper_scope_for_analysis (x))\n+\t  bitmap_set_bit (module_statics_escape, DECL_UID (x));\n+    }\n+}\n+\n+/* Check to see if T is a read or address of operation on a static var\n+   we are interested in analyzing.  LOCAL is passed in to get access\n+   to its bit vectors.  Local is NULL if this is called from a static\n+   initializer.  */\n+\n+static void\n+check_rhs_var (ipa_reference_local_vars_info_t local, tree t)\n+{\n+  look_for_address_of (t);\n+\n+  if (local == NULL) \n+    return;\n+\n+  check_tree(local, t, false);\n+}\n+\n+/* Check to see if T is an assignment to a static var we are\n+   interested in analyzing.  LOCAL is passed in to get access to its bit\n+   vectors.  */\n+\n+static void\n+check_lhs_var (ipa_reference_local_vars_info_t local, tree t)\n+{\n+  if (local == NULL) \n+    return;\n+   \n+  check_tree(local, t, true);\n+}\n+\n+/* This is a scaled down version of get_asm_expr_operands from\n+   tree_ssa_operands.c.  The version there runs much later and assumes\n+   that aliasing information is already available. Here we are just\n+   trying to find if the set of inputs and outputs contain references\n+   or address of operations to local static variables.  FN is the\n+   function being analyzed and STMT is the actual asm statement.  */\n+\n+static void\n+get_asm_expr_operands (ipa_reference_local_vars_info_t local, tree stmt)\n+{\n+  int noutputs = list_length (ASM_OUTPUTS (stmt));\n+  const char **oconstraints\n+    = (const char **) alloca ((noutputs) * sizeof (const char *));\n+  int i;\n+  tree link;\n+  const char *constraint;\n+  bool allows_mem, allows_reg, is_inout;\n+  \n+  for (i=0, link = ASM_OUTPUTS (stmt); link; ++i, link = TREE_CHAIN (link))\n+    {\n+      oconstraints[i] = constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_output_constraint (&constraint, i, 0, 0,\n+\t\t\t       &allows_mem, &allows_reg, &is_inout);\n+      \n+      check_lhs_var (local, TREE_VALUE (link));\n+    }\n+\n+  for (link = ASM_INPUTS (stmt); link; link = TREE_CHAIN (link))\n+    {\n+      constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_input_constraint (&constraint, 0, 0, noutputs, 0,\n+\t\t\t      oconstraints, &allows_mem, &allows_reg);\n+      \n+      check_rhs_var (local, TREE_VALUE (link));\n+    }\n+  \n+  for (link = ASM_CLOBBERS (stmt); link; link = TREE_CHAIN (link))\n+    if (simple_cst_equal(TREE_VALUE (link), memory_identifier_string) == 1) \n+      {\n+\t/* Abandon all hope, ye who enter here. */\n+\tlocal->calls_read_all = true;\n+\tlocal->calls_write_all = true;\n+      }      \n+}\n+\n+/* Check the parameters of a function call from CALLER to CALL_EXPR to\n+   see if any of them are static vars.  Also check to see if this is\n+   either an indirect call, a call outside the compilation unit, or\n+   has special attributes that effect the clobbers.  The caller\n+   parameter is the tree node for the caller and the second operand is\n+   the tree node for the entire call expression.  */\n+\n+static void\n+check_call (ipa_reference_local_vars_info_t local, tree call_expr) \n+{\n+  int flags = call_expr_flags (call_expr);\n+  tree operand_list = TREE_OPERAND (call_expr, 1);\n+  tree operand;\n+  tree callee_t = get_callee_fndecl (call_expr);\n+  enum availability avail = AVAIL_NOT_AVAILABLE;\n+\n+  for (operand = operand_list;\n+       operand != NULL_TREE;\n+       operand = TREE_CHAIN (operand))\n+    {\n+      tree argument = TREE_VALUE (operand);\n+      check_rhs_var (local, argument);\n+    }\n+\n+  if (callee_t)\n+    {\n+      struct cgraph_node* callee = cgraph_node(callee_t);\n+      avail = cgraph_function_body_availability (callee);\n+    }\n+\n+  if (avail == AVAIL_NOT_AVAILABLE || avail == AVAIL_OVERWRITABLE)\n+    if (local) \n+      {\n+\tif (flags & ECF_PURE) \n+\t  local->calls_read_all = true;\n+\telse \n+\t  {\n+\t    local->calls_read_all = true;\n+\t    local->calls_write_all = true;\n+\t  }\n+      }\n+}\n+\n+/* TP is the part of the tree currently under the microscope.\n+   WALK_SUBTREES is part of the walk_tree api but is unused here.\n+   DATA is cgraph_node of the function being walked.  */\n+\n+/* FIXME: When this is converted to run over SSA form, this code\n+   should be converted to use the operand scanner.  */\n+\n+static tree\n+scan_for_static_refs (tree *tp, \n+\t\t      int *walk_subtrees, \n+\t\t      void *data)\n+{\n+  struct cgraph_node *fn = data;\n+  tree t = *tp;\n+  ipa_reference_local_vars_info_t local = NULL;\n+  if (fn)\n+    local = get_reference_vars_info_from_cgraph (fn)->local;\n+\n+  switch (TREE_CODE (t))  \n+    {\n+    case VAR_DECL:\n+      if (DECL_INITIAL (t))\n+\twalk_tree (&DECL_INITIAL (t), scan_for_static_refs, fn, visited_nodes);\n+      *walk_subtrees = 0;\n+      break;\n+\n+    case MODIFY_EXPR:\n+      {\n+\t/* First look on the lhs and see what variable is stored to */\n+\ttree lhs = TREE_OPERAND (t, 0);\n+\ttree rhs = TREE_OPERAND (t, 1);\n+\tcheck_lhs_var (local, lhs);\n+\n+\t/* For the purposes of figuring out what the cast affects */\n+\n+\t/* Next check the operands on the rhs to see if they are ok. */\n+\tswitch (TREE_CODE_CLASS (TREE_CODE (rhs))) \n+\t  {\n+\t  case tcc_binary:\t    \n+ \t    {\n+ \t      tree op0 = TREE_OPERAND (rhs, 0);\n+ \t      tree op1 = TREE_OPERAND (rhs, 1);\n+ \t      check_rhs_var (local, op0);\n+ \t      check_rhs_var (local, op1);\n+\t    }\n+\t    break;\n+\t  case tcc_unary:\n+ \t    {\n+ \t      tree op0 = TREE_OPERAND (rhs, 0);\n+ \t      check_rhs_var (local, op0);\n+ \t    }\n+\n+\t    break;\n+\t  case tcc_reference:\n+\t    check_rhs_var (local, rhs);\n+\t    break;\n+\t  case tcc_declaration:\n+\t    check_rhs_var (local, rhs);\n+\t    break;\n+\t  case tcc_expression:\n+\t    switch (TREE_CODE (rhs)) \n+\t      {\n+\t      case ADDR_EXPR:\n+\t\tcheck_rhs_var (local, rhs);\n+\t\tbreak;\n+\t      case CALL_EXPR: \n+\t\tcheck_call (local, rhs);\n+\t\tbreak;\n+\t      default:\n+\t\tbreak;\n+\t      }\n+\t    break;\n+\t  default:\n+\t    break;\n+\t  }\n+\t*walk_subtrees = 0;\n+      }\n+      break;\n+\n+    case ADDR_EXPR:\n+      /* This case is here to find addresses on rhs of constructors in\n+\t decl_initial of static variables. */\n+      check_rhs_var (local, t);\n+      *walk_subtrees = 0;\n+      break;\n+\n+    case LABEL_EXPR:\n+      if (DECL_NONLOCAL (TREE_OPERAND (t, 0)))\n+\t{\n+\t  /* Target of long jump. */\n+\t  local->calls_read_all = true;\n+\t  local->calls_write_all = true;\n+\t}\n+      break;\n+\n+    case CALL_EXPR: \n+      check_call (local, t);\n+      *walk_subtrees = 0;\n+      break;\n+      \n+    case ASM_EXPR:\n+      get_asm_expr_operands (local, t);\n+      *walk_subtrees = 0;\n+      break;\n+      \n+    default:\n+      break;\n+    }\n+  return NULL;\n+}\n+\n+\n+/* Lookup the tree node for the static variable that has UID.  */\n+static tree\n+get_static_decl (int index)\n+{\n+  splay_tree_node stn = \n+    splay_tree_lookup (reference_vars_to_consider, index);\n+  if (stn)\n+    return (tree)stn->value;\n+  return NULL;\n+}\n+\n+/* Lookup the tree node for the static variable that has UID and\n+   conver the name to a string for debugging.  */\n+\n+static const char *\n+get_static_name (int index)\n+{\n+  splay_tree_node stn = \n+    splay_tree_lookup (reference_vars_to_consider, index);\n+  if (stn)\n+    return lang_hooks.decl_printable_name ((tree)(stn->value), 2);\n+  return NULL;\n+}\n+\n+/* Or in all of the bits from every callee into X, the caller's, bit\n+   vector.  There are several cases to check to avoid the sparse\n+   bitmap oring.  */\n+\n+static void\n+propagate_bits (struct cgraph_node *x)\n+{\n+  ipa_reference_vars_info_t x_info = get_reference_vars_info_from_cgraph (x);\n+  ipa_reference_global_vars_info_t x_global = x_info->global;\n+\n+  struct cgraph_edge *e;\n+  for (e = x->callees; e; e = e->next_callee) \n+    {\n+      struct cgraph_node *y = e->callee;\n+\n+      /* Only look at the master nodes and skip external nodes.  */\n+      y = cgraph_master_clone (y);\n+      if (y)\n+\t{\n+\t  if (get_reference_vars_info_from_cgraph (y))\n+\t    {\n+\t      ipa_reference_vars_info_t y_info = get_reference_vars_info_from_cgraph (y);\n+\t      ipa_reference_global_vars_info_t y_global = y_info->global;\n+\t      \n+\t      if (x_global->statics_read\n+\t\t  != all_module_statics)\n+\t\t{\n+\t\t  if (y_global->statics_read \n+\t\t      == all_module_statics)\n+\t\t    {\n+\t\t      BITMAP_FREE (x_global->statics_read);\n+\t\t      x_global->statics_read \n+\t\t\t= all_module_statics;\n+\t\t    }\n+\t\t  /* Skip bitmaps that are pointer equal to node's bitmap\n+\t\t     (no reason to spin within the cycle).  */\n+\t\t  else if (x_global->statics_read \n+\t\t\t   != y_global->statics_read)\n+\t\t    bitmap_ior_into (x_global->statics_read,\n+\t\t\t\t     y_global->statics_read);\n+\t\t}\n+\t      \n+\t      if (x_global->statics_written \n+\t\t  != all_module_statics)\n+\t\t{\n+\t\t  if (y_global->statics_written \n+\t\t      == all_module_statics)\n+\t\t    {\n+\t\t      BITMAP_FREE (x_global->statics_written);\n+\t\t      x_global->statics_written \n+\t\t\t= all_module_statics;\n+\t\t    }\n+\t\t  /* Skip bitmaps that are pointer equal to node's bitmap\n+\t\t     (no reason to spin within the cycle).  */\n+\t\t  else if (x_global->statics_written \n+\t\t\t   != y_global->statics_written)\n+\t\t    bitmap_ior_into (x_global->statics_written,\n+\t\t\t\t     y_global->statics_written);\n+\t\t}\n+\t    }\n+\t  else \n+\t    {\n+\t      gcc_unreachable ();\n+\t    }\n+\t}\n+    }\n+}\n+\n+/* Look at all of the callees of X to see which ones represent inlined\n+   calls.  For each of these callees, merge their local info into\n+   TARGET and check their children recursively.  \n+\n+   This function goes away when Jan changes the inliner and IPA\n+   analysis so that this is not run between the time when inlining\n+   decisions are made and when the inlining actually occurs.  */\n+\n+static void \n+merge_callee_local_info (struct cgraph_node *target, \n+\t\t\t struct cgraph_node *x)\n+{\n+  struct cgraph_edge *e;\n+  ipa_reference_local_vars_info_t x_l = \n+    get_reference_vars_info_from_cgraph (target)->local;\n+\n+  /* Make the world safe for tail recursion.  */\n+  struct ipa_dfs_info *node_info = x->aux;\n+  \n+  if (node_info->aux) \n+    return;\n+\n+  node_info->aux = x;\n+\n+  for (e = x->callees; e; e = e->next_callee) \n+    {\n+      struct cgraph_node *y = e->callee;\n+      if (y->global.inlined_to) \n+\t{\n+\t  ipa_reference_vars_info_t y_info;\n+\t  ipa_reference_local_vars_info_t y_l;\n+\t  struct cgraph_node* orig_y = y;\n+\t \n+\t  y = cgraph_master_clone (y);\n+\t  if (y)\n+\t    {\n+\t      y_info = get_reference_vars_info_from_cgraph (y);\n+\t      y_l = y_info->local;\n+\t      if (x_l != y_l)\n+\t\t{\n+\t\t  bitmap_ior_into (x_l->statics_read,\n+\t\t\t\t   y_l->statics_read);\n+\t\t  bitmap_ior_into (x_l->statics_written,\n+\t\t\t\t   y_l->statics_written);\n+\t\t}\n+\t      x_l->calls_read_all |= y_l->calls_read_all;\n+\t      x_l->calls_write_all |= y_l->calls_write_all;\n+\t      merge_callee_local_info (target, y);\n+\t    }\n+\t  else \n+\t    {\n+\t      fprintf(stderr, \"suspect inlining of \");\n+\t      dump_cgraph_node (stderr, orig_y);\n+\t      fprintf(stderr, \"\\ninto \");\n+\t      dump_cgraph_node (stderr, target);\n+\t      dump_cgraph (stderr);\n+\t      gcc_assert(false);\n+\t    }\n+\t}\n+    }\n+\n+  node_info->aux = NULL;\n+}\n+\n+/* The init routine for analyzing global static variable usage.  See\n+   comments at top for description.  */\n+static void \n+ipa_init (void) \n+{\n+  memory_identifier_string = build_string(7, \"memory\");\n+\n+  reference_vars_to_consider =\n+    splay_tree_new_ggc (splay_tree_compare_ints);\n+\n+  bitmap_obstack_initialize (&ipa_obstack);\n+  module_statics_escape = BITMAP_ALLOC (&ipa_obstack);\n+  module_statics_written = BITMAP_ALLOC (&ipa_obstack);\n+  all_module_statics = BITMAP_ALLOC (&ipa_obstack);\n+\n+  /* There are some shared nodes, in particular the initializers on\n+     static declarations.  We do not need to scan them more than once\n+     since all we would be interested in are the addressof\n+     operations.  */\n+  visited_nodes = pointer_set_create ();\n+}\n+\n+/* Check out the rhs of a static or global initialization VNODE to see\n+   if any of them contain addressof operations.  Note that some of\n+   these variables may  not even be referenced in the code in this\n+   compilation unit but their right hand sides may contain references\n+   to variables defined within this unit.  */\n+\n+static void \n+analyze_variable (struct cgraph_varpool_node *vnode)\n+{\n+  tree global = vnode->decl;\n+  if (TREE_CODE (global) == VAR_DECL)\n+    {\n+      if (DECL_INITIAL (global)) \n+\twalk_tree (&DECL_INITIAL (global), scan_for_static_refs, \n+\t\t   NULL, visited_nodes);\n+    } \n+  else gcc_unreachable ();\n+}\n+\n+/* This is the main routine for finding the reference patterns for\n+   global variables within a function FN.  */\n+\n+static void\n+analyze_function (struct cgraph_node *fn)\n+{\n+  ipa_reference_vars_info_t info \n+    = xcalloc (1, sizeof (struct ipa_reference_vars_info_d));\n+  ipa_reference_local_vars_info_t l\n+    = xcalloc (1, sizeof (struct ipa_reference_local_vars_info_d));\n+  tree decl = fn->decl;\n+\n+  /* Add the info to the tree's annotation.  */\n+  get_var_ann (fn->decl)->reference_vars_info = info;\n+\n+  info->local = l;\n+  l->statics_read = BITMAP_ALLOC (&ipa_obstack);\n+  l->statics_written = BITMAP_ALLOC (&ipa_obstack);\n+\n+  if (dump_file)\n+    fprintf (dump_file, \"\\n local analysis of %s\\n\", cgraph_node_name (fn));\n+  \n+  {\n+    struct function *this_cfun = DECL_STRUCT_FUNCTION (decl);\n+    basic_block this_block;\n+\n+    FOR_EACH_BB_FN (this_block, this_cfun)\n+      {\n+\tblock_stmt_iterator bsi;\n+\tfor (bsi = bsi_start (this_block); !bsi_end_p (bsi); bsi_next (&bsi))\n+\t  walk_tree (bsi_stmt_ptr (bsi), scan_for_static_refs, \n+\t\t     fn, visited_nodes);\n+      }\n+  }\n+\n+  /* There may be const decls with interesting right hand sides.  */\n+  if (DECL_STRUCT_FUNCTION (decl))\n+    {\n+      tree step;\n+      for (step = DECL_STRUCT_FUNCTION (decl)->unexpanded_var_list;\n+\t   step;\n+\t   step = TREE_CHAIN (step))\n+\t{\n+\t  tree var = TREE_VALUE (step);\n+\t  if (TREE_CODE (var) == VAR_DECL \n+\t      && DECL_INITIAL (var)\n+\t      && !TREE_STATIC (var))\n+\t    walk_tree (&DECL_INITIAL (var), scan_for_static_refs, \n+\t\t       fn, visited_nodes);\n+\t}\n+    }\n+}\n+\n+/* If FN is avail == AVAIL_OVERWRITABLE, replace the effects bit\n+   vectors with worst case bit vectors.  We had to analyze it above to\n+   find out if it took the address of any statics. However, now that\n+   we know that, we can get rid of all of the other side effects.  */\n+\n+static void\n+clean_function (struct cgraph_node *fn)\n+{\n+  ipa_reference_vars_info_t info = get_reference_vars_info_from_cgraph (fn);\n+  ipa_reference_local_vars_info_t l = info->local;\n+  ipa_reference_global_vars_info_t g = info->global;\n+  \n+  if (l)\n+    {\n+      if (l->statics_read\n+\t  && l->statics_read != all_module_statics)\n+\tBITMAP_FREE (l->statics_read);\n+      if (l->statics_written\n+\t  &&l->statics_written != all_module_statics)\n+\tBITMAP_FREE (l->statics_written);\n+      free (l);\n+    }\n+  \n+  if (g)\n+    {\n+      if (g->statics_read\n+\t  && g->statics_read != all_module_statics)\n+\tBITMAP_FREE (g->statics_read);\n+      \n+      if (g->statics_written\n+\t  && g->statics_written != all_module_statics)\n+\tBITMAP_FREE (g->statics_written);\n+      \n+      if (g->statics_not_read\n+\t  && g->statics_not_read != all_module_statics)\n+\tBITMAP_FREE (g->statics_not_read);\n+      \n+      if (g->statics_not_written\n+\t  && g->statics_not_written != all_module_statics)\n+\tBITMAP_FREE (g->statics_not_written);\n+      free (g);\n+    }\n+\n+  \n+  free (get_var_ann (fn->decl)->reference_vars_info);\n+  get_var_ann (fn->decl)->reference_vars_info = NULL;\n+}\n+\n+\f\n+/* Produce the global information by preforming a transitive closure\n+   on the local information that was produced by ipa_analyze_function\n+   and ipa_analyze_variable.  */\n+\n+static void\n+static_execute (void)\n+{\n+  struct cgraph_node *node;\n+  struct cgraph_varpool_node *vnode;\n+  struct cgraph_node *w;\n+  struct cgraph_node **order =\n+    xcalloc (cgraph_n_nodes, sizeof (struct cgraph_node *));\n+  int order_pos = order_pos = ipa_utils_reduced_inorder (order, false, true);\n+  int i;\n+\n+  ipa_init ();\n+\n+  /* Process all of the variables first.  */\n+  for (vnode = cgraph_varpool_nodes_queue; vnode; vnode = vnode->next_needed)\n+    analyze_variable (vnode);\n+\n+  /* Process all of the functions next. \n+\n+     We do not want to process any of the clones so we check that this\n+     is a master clone.  However, we do need to process any\n+     AVAIL_OVERWRITABLE functions (these are never clones) because\n+     they may cause a static variable to escape.  The code that can\n+     overwrite such a function cannot access the statics because it\n+     would not be in the same compilation unit.  When the analysis is\n+     finished, the computed information of these AVAIL_OVERWRITABLE is\n+     replaced with worst case info.  \n+  */\n+  for (node = cgraph_nodes; node; node = node->next)\n+    if (node->analyzed \n+\t&& (cgraph_is_master_clone (node)\n+\t    || (cgraph_function_body_availability (node) \n+\t\t== AVAIL_OVERWRITABLE)))\n+      analyze_function (node);\n+\n+  pointer_set_destroy (visited_nodes);\n+  visited_nodes = NULL;\n+  if (dump_file) \n+    dump_cgraph (dump_file);\n+\n+  /* Prune out the variables that were found to behave badly\n+     (i.e. have their address taken).  */\n+  {\n+    unsigned int index;\n+    bitmap_iterator bi;\n+    bitmap module_statics_readonly = BITMAP_ALLOC (&ipa_obstack);\n+    bitmap module_statics_const = BITMAP_ALLOC (&ipa_obstack);\n+    bitmap bm_temp = BITMAP_ALLOC (&ipa_obstack);\n+\n+    EXECUTE_IF_SET_IN_BITMAP (module_statics_escape, 0, index, bi)\n+      {\n+\tsplay_tree_remove (reference_vars_to_consider, index);\n+      }\n+\n+    bitmap_and_compl_into (all_module_statics, \n+\t\t\t   module_statics_escape);\n+\n+    bitmap_and_compl (module_statics_readonly, all_module_statics,\n+\t\t      module_statics_written);\n+\n+    /* If the address is not taken, we can unset the addressable bit\n+       on this variable.  */\n+    EXECUTE_IF_SET_IN_BITMAP (all_module_statics, 0, index, bi)\n+      {\n+\ttree var = get_static_decl (index);\n+ \tTREE_ADDRESSABLE (var) = 0;\n+\tif (dump_file) \n+\t  fprintf (dump_file, \"Not TREE_ADDRESSABLE var %s\\n\",\n+\t\t   get_static_name (index));\n+      }\n+\n+    /* If the variable is never written, we can set the TREE_READONLY\n+       flag.  Additionally if it has a DECL_INITIAL that is made up of\n+       constants we can treat the entire global as a constant.  */\n+\n+    bitmap_and_compl (module_statics_readonly, all_module_statics,\n+\t\t      module_statics_written);\n+    EXECUTE_IF_SET_IN_BITMAP (module_statics_readonly, 0, index, bi)\n+      {\n+\ttree var = get_static_decl (index);\n+\tTREE_READONLY (var) = 1;\n+\tif (dump_file)\n+\t  fprintf (dump_file, \"read-only var %s\\n\", \n+\t\t   get_static_name (index)); \n+\tif (DECL_INITIAL (var)\n+\t    && is_gimple_min_invariant (DECL_INITIAL (var)))\n+\t  {\n+ \t    bitmap_set_bit (module_statics_const, index);\n+\t    if (dump_file)\n+\t      fprintf (dump_file, \"read-only constant %s\\n\",\n+\t\t       get_static_name (index));\n+\t  }\n+      }\n+\n+    BITMAP_FREE(module_statics_escape);\n+    BITMAP_FREE(module_statics_written);\n+\n+    if (dump_file)\n+      EXECUTE_IF_SET_IN_BITMAP (all_module_statics, 0, index, bi)\n+\t{\n+\t  fprintf (dump_file, \"\\nPromotable global:%s\",\n+\t\t   get_static_name (index));\n+\t}\n+\n+    for (i = 0; i < order_pos; i++ )\n+      {\n+\tipa_reference_local_vars_info_t l;\n+\tnode = order[i];\n+\tl = get_reference_vars_info_from_cgraph (node)->local;\n+\n+\t/* Any variables that are not in all_module_statics are\n+\t   removed from the local maps.  This will include all of the\n+\t   variables that were found to escape in the function\n+\t   scanning.  */\n+\tbitmap_and_into (l->statics_read, \n+\t\t         all_module_statics);\n+\tbitmap_and_into (l->statics_written, \n+\t\t         all_module_statics);\n+      }\n+\n+    BITMAP_FREE(module_statics_readonly);\n+    BITMAP_FREE(module_statics_const);\n+    BITMAP_FREE(bm_temp);\n+  }\n+\n+  if (dump_file)\n+    {\n+      for (i = 0; i < order_pos; i++ )\n+\t{\n+\t  unsigned int index;\n+\t  ipa_reference_local_vars_info_t l;\n+\t  bitmap_iterator bi;\n+\n+\t  node = order[i];\n+\t  l = get_reference_vars_info_from_cgraph (node)->local;\n+\t  fprintf (dump_file, \n+\t\t   \"\\nFunction name:%s/%i:\", \n+\t\t   cgraph_node_name (node), node->uid);\n+\t  fprintf (dump_file, \"\\n  locals read: \");\n+\t  EXECUTE_IF_SET_IN_BITMAP (l->statics_read,\n+\t\t\t\t    0, index, bi)\n+\t    {\n+\t      fprintf (dump_file, \"%s \",\n+\t\t       get_static_name (index));\n+\t    }\n+\t  fprintf (dump_file, \"\\n  locals written: \");\n+\t  EXECUTE_IF_SET_IN_BITMAP (l->statics_written,\n+\t\t\t\t    0, index, bi)\n+\t    {\n+\t      fprintf(dump_file, \"%s \",\n+\t\t      get_static_name (index));\n+\t    }\n+\t}\n+    }\n+\n+  /* Propagate the local information thru the call graph to produce\n+     the global information.  All the nodes within a cycle will have\n+     the same info so we collapse cycles first.  Then we can do the\n+     propagation in one pass from the leaves to the roots.  */\n+  order_pos = ipa_utils_reduced_inorder (order, true, true);\n+  if (dump_file)\n+    ipa_utils_print_order(dump_file, \"reduced\", order, order_pos);\n+\n+  for (i = 0; i < order_pos; i++ )\n+    {\n+      ipa_reference_vars_info_t node_info;\n+      ipa_reference_global_vars_info_t node_g = \n+\txcalloc (1, sizeof (struct ipa_reference_global_vars_info_d));\n+      ipa_reference_local_vars_info_t node_l;\n+      \n+      bool read_all;\n+      bool write_all;\n+      struct ipa_dfs_info * w_info;\n+\n+      node = order[i];\n+      node_info = get_reference_vars_info_from_cgraph (node);\n+      if (!node_info) \n+\t{\n+\t  dump_cgraph_node (stderr, node);\n+\t  dump_cgraph (stderr);\n+\t  gcc_unreachable ();\n+\t}\n+\n+      node_info->global = node_g;\n+      node_l = node_info->local;\n+\n+      read_all = node_l->calls_read_all;\n+      write_all = node_l->calls_write_all;\n+\n+      /* If any node in a cycle is calls_read_all or calls_write_all\n+\t they all are. */\n+      w_info = node->aux;\n+      w = w_info->next_cycle;\n+      while (w)\n+\t{\n+\t  ipa_reference_local_vars_info_t w_l = \n+\t    get_reference_vars_info_from_cgraph (w)->local;\n+\t  read_all |= w_l->calls_read_all;\n+\t  write_all |= w_l->calls_write_all;\n+\n+\t  w_info = w->aux;\n+\t  w = w_info->next_cycle;\n+\t}\n+\n+      /* Initialized the bitmaps for the reduced nodes */\n+      if (read_all) \n+\tnode_g->statics_read = all_module_statics;\n+      else \n+\t{\n+\t  node_g->statics_read = BITMAP_ALLOC (&ipa_obstack);\n+\t  bitmap_copy (node_g->statics_read, \n+\t\t       node_l->statics_read);\n+\t}\n+\n+      if (write_all) \n+\tnode_g->statics_written = all_module_statics;\n+      else\n+\t{\n+\t  node_g->statics_written = BITMAP_ALLOC (&ipa_obstack);\n+\t  bitmap_copy (node_g->statics_written, \n+\t\t       node_l->statics_written);\n+\t}\n+\n+      w_info = node->aux;\n+      w = w_info->next_cycle;\n+      while (w)\n+\t{\n+\t  ipa_reference_vars_info_t w_ri = \n+\t    get_reference_vars_info_from_cgraph (w);\n+\t  ipa_reference_local_vars_info_t w_l = w_ri->local;\n+\n+\t  /* All nodes within a cycle share the same global info bitmaps.  */\n+\t  w_ri->global = node_g;\n+\t  \n+\t  /* These global bitmaps are initialized from the local info\n+\t     of all of the nodes in the region.  However there is no\n+\t     need to do any work if the bitmaps were set to\n+\t     all_module_statics.  */\n+\t  if (!read_all)\n+\t    bitmap_ior_into (node_g->statics_read,\n+\t\t\t     w_l->statics_read);\n+\t  if (!write_all)\n+\t    bitmap_ior_into (node_g->statics_written,\n+\t\t\t     w_l->statics_written);\n+\t  w_info = w->aux;\n+\t  w = w_info->next_cycle;\n+\t}\n+\n+      w = node;\n+      while (w)\n+\t{\n+\t  propagate_bits (w);\n+\t  w_info = w->aux;\n+\t  w = w_info->next_cycle;\n+\t}\n+    }\n+\n+  /* Need to fix up the local information sets.  The information that\n+     has been gathered so far is preinlining.  However, the\n+     compilation will progress post inlining so the local sets for the\n+     inlined calls need to be merged into the callers.  Note that the\n+     local sets are not shared between all of the nodes in a cycle so\n+     those nodes in the cycle must be processed explicitly.  */\n+  for (i = 0; i < order_pos; i++ )\n+    {\n+      struct ipa_dfs_info * w_info;\n+      node = order[i];\n+      merge_callee_local_info (node, node);\n+      \n+      w_info = node->aux;\n+      w = w_info->next_cycle;\n+      while (w)\n+\t{\n+\t  merge_callee_local_info (w, w);\n+\t  w_info = w->aux;\n+\t  w = w_info->next_cycle;\n+\t}\n+    }\n+\n+  if (dump_file)\n+    {\n+      for (i = 0; i < order_pos; i++ )\n+\t{\n+\t  ipa_reference_vars_info_t node_info;\n+\t  ipa_reference_global_vars_info_t node_g;\n+\t  ipa_reference_local_vars_info_t node_l;\n+\t  unsigned int index;\n+\t  bitmap_iterator bi;\n+\t  struct ipa_dfs_info * w_info;\n+\n+\t  node = order[i];\n+\t  node_info = get_reference_vars_info_from_cgraph (node);\n+\t  node_g = node_info->global;\n+\t  node_l = node_info->local;\n+\t  fprintf (dump_file, \n+\t\t   \"\\nFunction name:%s/%i:\", \n+\t\t   cgraph_node_name (node), node->uid);\n+\t  fprintf (dump_file, \"\\n  locals read: \");\n+\t  EXECUTE_IF_SET_IN_BITMAP (node_l->statics_read,\n+\t\t\t\t    0, index, bi)\n+\t    {\n+\t      fprintf (dump_file, \"%s \",\n+\t\t       get_static_name (index));\n+\t    }\n+\t  fprintf (dump_file, \"\\n  locals written: \");\n+\t  EXECUTE_IF_SET_IN_BITMAP (node_l->statics_written,\n+\t\t\t\t    0, index, bi)\n+\t    {\n+\t      fprintf(dump_file, \"%s \",\n+\t\t      get_static_name (index));\n+\t    }\n+\n+\t  w_info = node->aux;\n+\t  w = w_info->next_cycle;\n+\t  while (w) \n+\t    {\n+\t      ipa_reference_vars_info_t w_ri = \n+\t\tget_reference_vars_info_from_cgraph (w);\n+\t      ipa_reference_local_vars_info_t w_l = w_ri->local;\n+\t      fprintf (dump_file, \"\\n  next cycle: %s/%i \",\n+\t\t       cgraph_node_name (w), w->uid);\n+ \t      fprintf (dump_file, \"\\n    locals read: \");\n+\t      EXECUTE_IF_SET_IN_BITMAP (w_l->statics_read,\n+\t\t\t\t\t0, index, bi)\n+\t\t{\n+\t\t  fprintf (dump_file, \"%s \",\n+\t\t\t   get_static_name (index));\n+\t\t}\n+\n+\t      fprintf (dump_file, \"\\n    locals written: \");\n+\t      EXECUTE_IF_SET_IN_BITMAP (w_l->statics_written,\n+\t\t\t\t\t0, index, bi)\n+\t\t{\n+\t\t  fprintf(dump_file, \"%s \",\n+\t\t\t  get_static_name (index));\n+\t\t}\n+\t      \n+\n+\t      w_info = w->aux;\n+\t      w = w_info->next_cycle;\n+\t    }\n+\t  fprintf (dump_file, \"\\n  globals read: \");\n+\t  EXECUTE_IF_SET_IN_BITMAP (node_g->statics_read,\n+\t\t\t\t    0, index, bi)\n+\t    {\n+\t      fprintf (dump_file, \"%s \",\n+\t\t       get_static_name (index));\n+\t    }\n+\t  fprintf (dump_file, \"\\n  globals written: \");\n+\t  EXECUTE_IF_SET_IN_BITMAP (node_g->statics_written,\n+\t\t\t\t    0, index, bi)\n+\t    {\n+\t      fprintf (dump_file, \"%s \",\n+\t\t       get_static_name (index));\n+\t    }\n+\t}\n+    }\n+\n+  /* Cleanup. */\n+  for (i = 0; i < order_pos; i++ )\n+    {\n+      ipa_reference_vars_info_t node_info;\n+      ipa_reference_global_vars_info_t node_g;\n+      node = order[i];\n+      node_info = get_reference_vars_info_from_cgraph (node);\n+      node_g = node_info->global;\n+      \n+      /* Create the complimentary sets.  These are more useful for\n+\t certain apis.  */\n+      node_g->statics_not_read = BITMAP_ALLOC (&ipa_obstack);\n+      node_g->statics_not_written = BITMAP_ALLOC (&ipa_obstack);\n+\n+      if (node_g->statics_read != all_module_statics) \n+\t{\n+\t  bitmap_and_compl (node_g->statics_not_read, \n+\t\t\t    all_module_statics,\n+\t\t\t    node_g->statics_read);\n+\t}\n+\n+      if (node_g->statics_written \n+\t  != all_module_statics) \n+\tbitmap_and_compl (node_g->statics_not_written, \n+\t\t\t  all_module_statics,\n+\t\t\t  node_g->statics_written);\n+   }\n+\n+  free (order);\n+\n+  for (node = cgraph_nodes; node; node = node->next)\n+    {\n+      /* Get rid of the aux information.  */\n+      \n+      if (node->aux)\n+\t{\n+\t  free (node->aux);\n+\t  node->aux = NULL;\n+\t}\n+      \n+      if (node->analyzed \n+\t  && (cgraph_function_body_availability (node) == AVAIL_OVERWRITABLE))\n+\tclean_function (node);\n+    }\n+}\n+\n+\n+static bool\n+gate_reference (void)\n+{\n+  return (flag_unit_at_a_time != 0  && flag_ipa_reference\n+\t  /* Don't bother doing anything if the program has errors.  */\n+\t  && !(errorcount || sorrycount));\n+}\n+\n+struct tree_opt_pass pass_ipa_reference =\n+{\n+  \"static-var\",\t\t\t\t/* name */\n+  gate_reference,\t\t\t/* gate */\n+  static_execute,\t\t\t/* execute */\n+  NULL,\t\t\t\t\t/* sub */\n+  NULL,\t\t\t\t\t/* next */\n+  0,\t\t\t\t\t/* static_pass_number */\n+  TV_IPA_REFERENCE,\t\t        /* tv_id */\n+  0,\t                                /* properties_required */\n+  0,\t\t\t\t\t/* properties_provided */\n+  0,\t\t\t\t\t/* properties_destroyed */\n+  0,\t\t\t\t\t/* todo_flags_start */\n+  0,                                    /* todo_flags_finish */\n+  0\t\t\t\t\t/* letter */\n+};\n+\n+#include \"gt-ipa-reference.h\"\n+"}, {"sha": "26dce15afc46083a727465fa55da5334befb3f80", "filename": "gcc/ipa-reference.h", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-reference.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-reference.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-reference.h?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,83 @@\n+/* IPA handling of references.\n+   Copyright (C) 2004-2005 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#ifndef GCC_IPA_REFERENCE_H\n+#define GCC_IPA_REFERENCE_H\n+#include \"bitmap.h\"\n+#include \"tree.h\"\n+\n+/* The static variables defined within the compilation unit that are\n+   loaded or stored directly by function that owns this structure.  */ \n+\n+struct ipa_reference_local_vars_info_d \n+{\n+  bitmap statics_read;\n+  bitmap statics_written;\n+\n+  /* Set when this function calls another function external to the\n+     compilation unit or if the function has a asm clobber of memory.\n+     In general, such calls are modeled as reading and writing all\n+     variables (both bits on) but sometime there are attributes on the\n+     called function so we can do better.  */\n+  bool calls_read_all;\n+  bool calls_write_all;\n+};\n+\n+struct ipa_reference_global_vars_info_d\n+{\n+  bitmap statics_read;\n+  bitmap statics_written;\n+  bitmap statics_not_read;\n+  bitmap statics_not_written;\n+};\n+\n+/* Statics that are read and written by some set of functions. The\n+   local ones are based on the loads and stores local to the function.\n+   The global ones are based on the local info as well as the\n+   transitive closure of the functions that are called.  The\n+   structures are separated to allow the global structures to be\n+   shared between several functions since every function within a\n+   strongly connected component will have the same information.  This\n+   sharing saves both time and space in the computation of the vectors\n+   as well as their translation from decl_uid form to ann_uid\n+   form.  */ \n+\n+typedef struct ipa_reference_local_vars_info_d *ipa_reference_local_vars_info_t;\n+typedef struct ipa_reference_global_vars_info_d *ipa_reference_global_vars_info_t;\n+\n+struct ipa_reference_vars_info_d \n+{\n+  ipa_reference_local_vars_info_t local;\n+  ipa_reference_global_vars_info_t global;\n+};\n+\n+typedef struct ipa_reference_vars_info_d *ipa_reference_vars_info_t;\n+\n+/* In ipa-reference.c  */\n+bitmap ipa_reference_get_read_local (tree fn);\n+bitmap ipa_reference_get_written_local (tree fn);\n+bitmap ipa_reference_get_read_global (tree fn);\n+bitmap ipa_reference_get_written_global (tree fn);\n+bitmap ipa_reference_get_not_read_global (tree fn);\n+bitmap ipa_reference_get_not_written_global (tree fn);\n+\n+#endif  /* GCC_IPA_REFERENCE_H  */\n+"}, {"sha": "289598d4bb8f9f11e2181bf7d5cde4af2c2236fa", "filename": "gcc/ipa-type-escape.c", "status": "added", "additions": 1854, "deletions": 0, "changes": 1854, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-type-escape.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-type-escape.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-type-escape.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,1854 @@\n+/* Type based alias analysis.\n+   Copyright (C) 2004, 2005 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+/* This pass determines which types in the program contain only\n+   instances that are completely encapsulated by the compilation unit.\n+   Those types that are encapsulated must also pass the further\n+   requirement that there be no bad operations on any instances of\n+   those types.\n+\n+   A great deal of freedom in compilation is allowed for the instances\n+   of those types that pass these conditions.\n+*/\n+\n+/* The code in this module is called by the ipa pass manager. It\n+   should be one of the later passes since its information is used by\n+   the rest of the compilation. */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"tree.h\"\n+#include \"tree-flow.h\"\n+#include \"tree-inline.h\"\n+#include \"tree-pass.h\"\n+#include \"langhooks.h\"\n+#include \"pointer-set.h\"\n+#include \"ggc.h\"\n+#include \"ipa-utils.h\"\n+#include \"ipa-type-escape.h\"\n+#include \"c-common.h\"\n+#include \"tree-gimple.h\"\n+#include \"cgraph.h\"\n+#include \"output.h\"\n+#include \"flags.h\"\n+#include \"timevar.h\"\n+#include \"diagnostic.h\"\n+#include \"langhooks.h\"\n+\n+/* Some of the aliasing is called very early, before this phase is\n+   called.  To assure that this is not a problem, we keep track of if\n+   this phase has been run.  */\n+static bool initialized = false;\n+\n+/* This bitmap contains the set of local vars that are the lhs of\n+   calls to mallocs.  These variables, when seen on the rhs as part of\n+   a cast, the cast are not marked as doing bad things to the type\n+   even though they are generally of the form \n+   \"foo = (type_of_foo)void_temp\". */\n+static bitmap results_of_malloc;\n+\n+/* Scratch bitmap for avoiding work. */\n+static bitmap been_there_done_that;\n+static bitmap bitmap_tmp;\n+\n+/* There are two levels of escape that types can undergo.\n+\n+   EXPOSED_PARAMETER - some instance of the variable is\n+   passed by value into an externally visible function or some\n+   instance of the variable is passed out of an externally visible\n+   function as a return value.  In this case any of the fields of the\n+   variable that are pointer types end up having their types marked as\n+   FULL_ESCAPE.\n+\n+   FULL_ESCAPE - when bad things happen to good types. One of the\n+   following things happens to the type: (a) either an instance of the\n+   variable has its address passed to an externally visible function,\n+   (b) the address is taken and some bad cast happens to the address\n+   or (c) explicit arithmetic is done to the address.\n+*/\n+\n+enum escape_t\n+{\n+  EXPOSED_PARAMETER,\n+  FULL_ESCAPE\n+};\n+\n+/* The following two bit vectors global_types_* correspond to\n+   previous cases above.  During the analysis phase, a bit is set in\n+   one of these vectors if an operation of the offending class is\n+   discovered to happen on the associated type.  */\n+ \n+static bitmap global_types_exposed_parameter;\n+static bitmap global_types_full_escape;\n+\n+/* All of the types seen in this compilation unit. */\n+static bitmap global_types_seen;\n+/* Reverse map to take a canon uid and map it to a canon type.  Uid's\n+   are never manipulated unless they are associated with a canon\n+   type.  */\n+static splay_tree uid_to_canon_type;\n+\n+/* Internal structure of type mapping code.  This maps a canon type\n+   name to its canon type.  */\n+static splay_tree all_canon_types;\n+\n+/* Map from type clones to the single canon type.  */\n+static splay_tree type_to_canon_type;\n+\n+/* A splay tree of bitmaps.  An element X in the splay tree has a bit\n+   set in its bitmap at TYPE_UID (TYPE_MAIN_VARIANT (Y)) if there was\n+   an operation in the program of the form \"&X.Y\".  */\n+static splay_tree uid_to_addressof_down_map;\n+\n+/* A splay tree of bitmaps.  An element Y in the splay tree has a bit\n+   set in its bitmap at TYPE_UID (TYPE_MAIN_VARIANT (X)) if there was\n+   an operation in the program of the form \"&X.Y\".  */\n+static splay_tree uid_to_addressof_up_map;\n+\n+/* Tree to hold the subtype maps used to mark subtypes of escaped\n+   types.  */\n+static splay_tree uid_to_subtype_map;\n+\n+/* Records tree nodes seen in cgraph_create_edges.  Simply using\n+   walk_tree_without_duplicates doesn't guarantee each node is visited\n+   once because it gets a new htab upon each recursive call from\n+   scan_for_refs.  */\n+static struct pointer_set_t *visited_nodes;\n+\n+static bitmap_obstack ipa_obstack;\n+\n+/* Get the name of TYPE or return the string \"<UNNAMED>\".  */\n+static char*\n+get_name_of_type (tree type)\n+{\n+  tree name = TYPE_NAME (type);\n+  \n+  if (!name)\n+    /* Unnamed type, do what you like here.  */\n+    return (char*)\"<UNNAMED>\";\n+  \n+  /* It will be a TYPE_DECL in the case of a typedef, otherwise, an\n+     identifier_node */\n+  if (TREE_CODE (name) == TYPE_DECL)\n+    {\n+      /*  Each DECL has a DECL_NAME field which contains an\n+\t  IDENTIFIER_NODE.  (Some decls, most often labels, may have\n+\t  zero as the DECL_NAME).  */\n+      if (DECL_NAME (name))\n+\treturn (char*)IDENTIFIER_POINTER (DECL_NAME (name));\n+      else\n+\t/* Unnamed type, do what you like here.  */\n+\treturn (char*)\"<UNNAMED>\";\n+    }\n+  else if (TREE_CODE (name) == IDENTIFIER_NODE)\n+    return (char*)IDENTIFIER_POINTER (name);\n+  else \n+    return (char*)\"<UNNAMED>\";\n+}\n+\n+struct type_brand_s \n+{\n+  char* name;\n+  int seq;\n+};\n+\n+/* Splay tree comparison function on type_brand_s structures.  */\n+\n+static int \n+compare_type_brand (splay_tree_key sk1, splay_tree_key sk2)\n+{\n+  struct type_brand_s * k1 = (struct type_brand_s *) sk1;\n+  struct type_brand_s * k2 = (struct type_brand_s *) sk2;\n+\n+  int value = strcmp(k1->name, k2->name);\n+  if (value == 0)\n+    return k2->seq - k1->seq;\n+  else \n+    return value;\n+}\n+\n+/* All of the \"unique_type\" code is a hack to get around the sleazy\n+   implementation used to compile more than file.  Currently gcc does\n+   not get rid of multiple instances of the same type that have been\n+   collected from different compilation units.  */\n+/* This is a trivial algorithm for removing duplicate types.  This\n+   would not work for any language that used structural equivalence as\n+   the basis of its type system.  */\n+/* Return either TYPE if this is first time TYPE has been seen an\n+   compatible TYPE that has already been processed.  */ \n+\n+static tree\n+discover_unique_type (tree type)\n+{\n+  struct type_brand_s * brand = xmalloc(sizeof(struct type_brand_s));\n+  int i = 0;\n+  splay_tree_node result;\n+  \n+  while (1)\n+  {\n+    brand->name = get_name_of_type (type);\n+    brand->seq = i;\n+    result = splay_tree_lookup (all_canon_types, (splay_tree_key) brand);\n+    if (result)\n+      {\n+\t/* Create an alias since this is just the same as\n+\t   other_type.  */\n+\ttree other_type = (tree) result->value;\n+\tif (lang_hooks.types_compatible_p (type, other_type) == 1)\n+\t  {\n+\t    free (brand);\n+\t    /* Insert this new type as an alias for other_type.  */\n+\t    splay_tree_insert (type_to_canon_type, \n+\t\t\t       (splay_tree_key) type,\n+\t\t\t       (splay_tree_value) other_type);\n+\t    return other_type;\n+\t  }\n+\t/* Not compatible, look for next instance with same name.  */\n+      }\n+    else \n+      {\n+\t/* No more instances, create new one since this is the first\n+\t   time we saw this type.  */\n+\tbrand->seq = i++;\n+\t/* Insert the new brand.  */\n+\tsplay_tree_insert (all_canon_types, \n+\t\t\t   (splay_tree_key) brand,\n+\t\t\t   (splay_tree_value) type);\t  \n+\t\n+\t/* Insert this new type as an alias for itself.  */\n+\tsplay_tree_insert (type_to_canon_type, \n+\t\t\t   (splay_tree_key) type,\n+\t\t\t   (splay_tree_value) type);\n+\n+\t/* Insert the uid for reverse lookup; */\n+\tsplay_tree_insert (uid_to_canon_type, \n+\t\t\t   (splay_tree_key) TYPE_UID (type),\n+\t\t\t   (splay_tree_value) type);\t  \n+\n+\tbitmap_set_bit (global_types_seen, TYPE_UID (type));\n+\treturn type;\n+      }\n+    i++;\n+  } \n+}\n+\n+/* Return true if TYPE is one of the type classes that we are willing\n+   to analyze.  This skips the goofy types like arrays of pointers to\n+   methods. */\n+static bool\n+type_to_consider (tree type)\n+{\n+  /* Strip the *'s off.  */\n+  type = TYPE_MAIN_VARIANT (type);\n+  while (POINTER_TYPE_P (type) || TREE_CODE (type) == ARRAY_TYPE)\n+    type = TYPE_MAIN_VARIANT (TREE_TYPE (type));\n+\n+  switch (TREE_CODE (type))\n+    {\n+    case BOOLEAN_TYPE:\n+    case CHAR_TYPE:\n+    case COMPLEX_TYPE:\n+    case ENUMERAL_TYPE:\n+    case INTEGER_TYPE:\n+    case QUAL_UNION_TYPE:\n+    case REAL_TYPE:\n+    case RECORD_TYPE:\n+    case UNION_TYPE:\n+    case VECTOR_TYPE:\n+    case VOID_TYPE:\n+      return true;\n+  \n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Get the canon type of TYPE.  If SEE_THRU_PTRS is true, remove all\n+   the POINTER_TOs and if SEE_THRU_ARRAYS is true, remove all of the\n+   ARRAY_OFs and POINTER_TOs.  */\n+\n+static tree \n+get_canon_type (tree type, bool see_thru_ptrs, bool see_thru_arrays)\n+{\n+  splay_tree_node result;\n+  /* Strip the *'s off.  */\n+  if (!type || !type_to_consider (type))\n+    return NULL;\n+\n+  type = TYPE_MAIN_VARIANT (type);\n+  if (see_thru_arrays) \n+    while (POINTER_TYPE_P (type) || TREE_CODE (type) == ARRAY_TYPE)\n+      type = TYPE_MAIN_VARIANT (TREE_TYPE (type));\n+\n+  else if (see_thru_ptrs) \n+    while (POINTER_TYPE_P (type))\n+\ttype = TYPE_MAIN_VARIANT (TREE_TYPE (type));\n+\n+  result = splay_tree_lookup(type_to_canon_type, (splay_tree_key) type);\n+  \n+  if (result == NULL)\n+    return discover_unique_type (type);\n+  else return (tree) result->value;\n+}\n+\n+/* Same as GET_CANON_TYPE, except return the TYPE_ID rather than the\n+   TYPE.  */\n+\n+static int\n+get_canon_type_uid (tree type, bool see_thru_ptrs, bool see_thru_arrays)\n+{\n+  type = get_canon_type (type, see_thru_ptrs, see_thru_arrays);\n+  if (type)\n+    return TYPE_UID(type);\n+  else return 0;\n+}\n+\n+/* Return 0 if TYPE is a record or union type.  Return a positive\n+   number if TYPE is a pointer to a record or union.  The number is\n+   the number of pointer types stripped to get to the record or union\n+   type.  Return -1 if TYPE is none of the above.  */\n+ \n+int\n+ipa_type_escape_star_count_of_interesting_type (tree type) \n+{\n+  int count = 0;\n+  /* Strip the *'s off.  */\n+  if (!type)\n+    return -1;\n+  type = TYPE_MAIN_VARIANT (type);\n+  while (POINTER_TYPE_P (type))\n+    {\n+      type = TYPE_MAIN_VARIANT (TREE_TYPE (type));\n+      count++;\n+    }\n+\n+  /* We are interested in records, and unions only.  */\n+  if (TREE_CODE (type) == RECORD_TYPE \n+      || TREE_CODE (type) == QUAL_UNION_TYPE \n+      || TREE_CODE (type) == UNION_TYPE)\n+    return count;\n+  else \n+    return -1;\n+} \n+\n+\n+/* Return 0 if TYPE is a record or union type.  Return a positive\n+   number if TYPE is a pointer to a record or union.  The number is\n+   the number of pointer types stripped to get to the record or union\n+   type.  Return -1 if TYPE is none of the above.  */\n+ \n+int\n+ipa_type_escape_star_count_of_interesting_or_array_type (tree type) \n+{\n+  int count = 0;\n+  /* Strip the *'s off.  */\n+  if (!type)\n+    return -1;\n+  type = TYPE_MAIN_VARIANT (type);\n+  while (POINTER_TYPE_P (type) || TREE_CODE (type) == ARRAY_TYPE)\n+    {\n+      type = TYPE_MAIN_VARIANT (TREE_TYPE (type));\n+      count++;\n+    }\n+\n+  /* We are interested in records, and unions only.  */\n+  if (TREE_CODE (type) == RECORD_TYPE \n+      || TREE_CODE (type) == QUAL_UNION_TYPE \n+      || TREE_CODE (type) == UNION_TYPE)\n+    return count;\n+  else \n+    return -1;\n+} \n+ \n+ \n+/* Return true if the record, or union TYPE passed in escapes this\n+   compilation unit. Note that all of the pointer-to's are removed\n+   before testing since these may not be correct.  */\n+\n+bool\n+ipa_type_escape_type_contained_p (tree type)\n+{\n+  if (!initialized)\n+    return false;\n+  return !bitmap_bit_p (global_types_full_escape, \n+\t\t\tget_canon_type_uid (type, true, false));\n+}\n+\n+/* Return true a modification to a field of type FIELD_TYPE cannot\n+   clobber a record of RECORD_TYPE.  */\n+\n+bool \n+ipa_type_escape_field_does_not_clobber_p (tree record_type, tree field_type)\n+{ \n+  splay_tree_node result;\n+  int uid;\n+  \n+  if (!initialized)\n+    return false;\n+\n+  /* Strip off all of the pointer tos on the record type.  Strip the\n+     same number of pointer tos from the field type.  If the field\n+     type has fewer, it could not have been aliased. */\n+  record_type = TYPE_MAIN_VARIANT (record_type);\n+  field_type = TYPE_MAIN_VARIANT (field_type);\n+  while (POINTER_TYPE_P (record_type))\n+    {\n+      record_type = TYPE_MAIN_VARIANT (TREE_TYPE (record_type));\n+      if (POINTER_TYPE_P (field_type)) \n+\tfield_type = TYPE_MAIN_VARIANT (TREE_TYPE (field_type));\n+      else \n+\t/* However, if field_type is a union, this quick test is not\n+\t   correct since one of the variants of the union may be a\n+\t   pointer to type and we cannot see across that here.  So we\n+\t   just strip the remaining pointer tos off the record type\n+\t   and fall thru to the more precise code.  */\n+\tif (TREE_CODE (field_type) == QUAL_UNION_TYPE \n+\t    || TREE_CODE (field_type) == UNION_TYPE)\n+\t  {\n+\t    while (POINTER_TYPE_P (record_type))\n+\t      record_type = TYPE_MAIN_VARIANT (TREE_TYPE (record_type));\n+\t    break;\n+\t  } \n+\telse \n+\t  return true;\n+    }\n+  \n+  record_type = get_canon_type (record_type, true, true);\n+  /* The record type must be contained.  The field type may\n+     escape.  */\n+  if (!ipa_type_escape_type_contained_p (record_type))\n+    return false;\n+\n+  uid = TYPE_UID (record_type);\n+  result = splay_tree_lookup (uid_to_addressof_down_map, (splay_tree_key) uid);\n+  \n+  if (result) \n+    {\n+      bitmap field_type_map = (bitmap) result->value;\n+      uid = get_canon_type_uid (field_type, true, true);\n+      /* If the bit is there, the address was taken. If not, it\n+\t wasn't.  */\n+      return !bitmap_bit_p (field_type_map, uid);\n+    }\n+  else\n+    /* No bitmap means no addresses were taken.  */\n+    return true;\n+}\n+\n+\n+/* Add TYPE to the suspect type set. Return true if the bit needed to\n+   be marked.  */\n+\n+static tree\n+mark_type (tree type, enum escape_t escape_status)\n+{\n+  bitmap map = NULL;\n+  int uid;\n+\n+  type = get_canon_type (type, true, true);\n+  if (!type) \n+    return NULL;\n+\n+  switch (escape_status) \n+    {\n+    case EXPOSED_PARAMETER:\n+      map = global_types_exposed_parameter;\n+      break;\n+    case FULL_ESCAPE:\n+      map = global_types_full_escape;\n+      break;\n+    }\n+\n+  uid = TYPE_UID (type);\n+  if (bitmap_bit_p (map, uid))\n+    return type;\n+  else\n+    {\n+      bitmap_set_bit (map, uid);\n+      if (escape_status == FULL_ESCAPE)\n+\t{\n+\t  /* Effeciency hack. When things are bad, do not mess around\n+\t     with this type anymore.  */\n+\t  bitmap_set_bit (global_types_exposed_parameter, uid);\n+\t}      \n+    }\n+  return type;\n+}\n+\n+/* Add interesting TYPE to the suspect type set. If the set is\n+   EXPOSED_PARAMETER and the TYPE is a pointer type, the set is\n+   changed to FULL_ESCAPE.  */\n+\n+static void \n+mark_interesting_type (tree type, enum escape_t escape_status)\n+{\n+  if (!type) return;\n+  if (ipa_type_escape_star_count_of_interesting_type (type) >= 0)\n+    {\n+      if ((escape_status == EXPOSED_PARAMETER)\n+\t  && POINTER_TYPE_P (type))\n+\t/* EXPOSED_PARAMETERs are only structs or unions are passed by\n+\t   value.  Anything passed by reference to an external\n+\t   function fully exposes the type.  */\n+\tmark_type (type, FULL_ESCAPE);\n+      else\n+\tmark_type (type, escape_status);\n+    }\n+}\n+\n+/* Return true if PARENT is supertype of CHILD.  Both types must be\n+   known to be structures or unions. */\n+ \n+static bool\n+parent_type_p (tree parent, tree child)\n+{\n+  int i;\n+  tree binfo, base_binfo;\n+  if (TYPE_BINFO (parent)) \n+    for (binfo = TYPE_BINFO (parent), i = 0;\n+\t BINFO_BASE_ITERATE (binfo, i, base_binfo); i++)\n+      {\n+\ttree binfotype = BINFO_TYPE (base_binfo);\n+\tif (binfotype == child) \n+\t  return true;\n+\telse if (parent_type_p (binfotype, child))\n+\t  return true;\n+      }\n+  if (TREE_CODE (parent) == UNION_TYPE\n+      || TREE_CODE (parent) == QUAL_UNION_TYPE) \n+    {\n+      tree field;\n+      /* Search all of the variants in the union to see if one of them\n+\t is the child.  */\n+      for (field = TYPE_FIELDS (parent);\n+\t   field;\n+\t   field = TREE_CHAIN (field))\n+\t{\n+\t  tree field_type;\n+\t  if (TREE_CODE (field) != FIELD_DECL)\n+\t    continue;\n+\t  \n+\t  field_type = TREE_TYPE (field);\n+\t  if (field_type == child) \n+\t    return true;\n+\t}\n+\n+      /* If we did not find it, recursively ask the variants if one of\n+\t their children is the child type.  */\n+      for (field = TYPE_FIELDS (parent);\n+\t   field;\n+\t   field = TREE_CHAIN (field))\n+\t{\n+\t  tree field_type;\n+\t  if (TREE_CODE (field) != FIELD_DECL)\n+\t    continue;\n+\t  \n+\t  field_type = TREE_TYPE (field);\n+\t  if (TREE_CODE (field_type) == RECORD_TYPE \n+\t      || TREE_CODE (field_type) == QUAL_UNION_TYPE \n+\t      || TREE_CODE (field_type) == UNION_TYPE)\n+\t    if (parent_type_p (field_type, child)) \n+\t      return true;\n+\t}\n+    }\n+  \n+  if (TREE_CODE (parent) == RECORD_TYPE)\n+    {\n+      tree field;\n+      for (field = TYPE_FIELDS (parent);\n+\t   field;\n+\t   field = TREE_CHAIN (field))\n+\t{\n+\t  tree field_type;\n+\t  if (TREE_CODE (field) != FIELD_DECL)\n+\t    continue;\n+\t  \n+\t  field_type = TREE_TYPE (field);\n+\t  if (field_type == child) \n+\t    return true;\n+\t  /* You can only cast to the first field so if it does not\n+\t     match, quit.  */\n+\t  if (TREE_CODE (field_type) == RECORD_TYPE \n+\t      || TREE_CODE (field_type) == QUAL_UNION_TYPE \n+\t      || TREE_CODE (field_type) == UNION_TYPE)\n+\t    {\n+\t      if (parent_type_p (field_type, child)) \n+\t\treturn true;\n+\t      else \n+\t\tbreak;\n+\t    }\n+\t}\n+    }\n+  return false;\n+}\n+\n+/* Return the number of pointer tos for TYPE and return TYPE with all\n+   of these stripped off.  */\n+\n+static int \n+count_stars (tree* type_ptr)\n+{\n+  tree type = *type_ptr;\n+  int i = 0;\n+  type = TYPE_MAIN_VARIANT (type);\n+  while (POINTER_TYPE_P (type))\n+    {\n+      type = TYPE_MAIN_VARIANT (TREE_TYPE (type));\n+      i++;\n+    }\n+\n+  *type_ptr = type;\n+  return i;\n+}\n+\n+enum cast_type {\n+  CT_UP,\n+  CT_DOWN,\n+  CT_SIDEWAYS,\n+  CT_USELESS\n+};\n+\n+/* Check the cast FROM_TYPE to TO_TYPE.  This function requires that\n+   the two types have already passed the\n+   ipa_type_escape_star_count_of_interesting_type test.  */\n+\n+static enum cast_type\n+check_cast_type (tree to_type, tree from_type)\n+{\n+  int to_stars = count_stars (&to_type);\n+  int from_stars = count_stars (&from_type);\n+  if (to_stars != from_stars) \n+    return CT_SIDEWAYS;\n+\n+  if (to_type == from_type)\n+    return CT_USELESS;\n+\n+  if (parent_type_p (to_type, from_type)) return CT_UP;\n+  if (parent_type_p (from_type, to_type)) return CT_DOWN;\n+  return CT_SIDEWAYS;\n+}     \n+\n+/* Check a cast FROM this variable, TO_TYPE.  Mark the escaping types\n+   if appropriate.  */ \n+static void\n+check_cast (tree to_type, tree from) \n+{\n+  tree from_type = get_canon_type (TREE_TYPE (from), false, false);\n+  bool to_interesting_type, from_interesting_type;\n+\n+  to_type = get_canon_type (to_type, false, false);\n+  if (!from_type || !to_type || from_type == to_type)\n+    return;\n+\n+  to_interesting_type = \n+    ipa_type_escape_star_count_of_interesting_type (to_type) >= 0;\n+  from_interesting_type = \n+    ipa_type_escape_star_count_of_interesting_type (from_type) >= 0;\n+\n+  if (to_interesting_type) \n+    if (from_interesting_type)\n+      {\n+\t/* Both types are interesting. This can be one of four types\n+\t   of cast: useless, up, down, or sideways.  We do not care\n+\t   about up or useless.  Sideways casts are always bad and\n+\t   both sides get marked as escaping.  Downcasts are not\n+\t   interesting here because if type is marked as escaping, all\n+\t   of its subtypes escape.  */\n+\tswitch (check_cast_type (to_type, from_type)) \n+\t  {\n+\t  case CT_UP:\n+\t  case CT_USELESS:\n+\t  case CT_DOWN:\n+\t    break;\n+\n+\t  case CT_SIDEWAYS:\n+\t    mark_type (to_type, FULL_ESCAPE);\n+\t    mark_type (from_type, FULL_ESCAPE);\n+\t    break;\n+\t  }\n+      }\n+    else\n+      {\n+\t/* If this is a cast from the local that is a result from a\n+\t   call to malloc, do not mark the cast as bad.  */\n+\tif (DECL_P (from) && !bitmap_bit_p (results_of_malloc, DECL_UID (from)))\n+\t  mark_type (to_type, FULL_ESCAPE);\n+      }\n+  else if (from_interesting_type)\n+    mark_type (from_type, FULL_ESCAPE);\n+}\n+\n+/* Register the parameter and return types of function FN.  The type\n+   ESCAPES if the function is visible outside of the compilation\n+   unit.  */\n+static void \n+check_function_parameter_and_return_types (tree fn, bool escapes) \n+{\n+  tree arg;\n+  \n+  if (TYPE_ARG_TYPES (TREE_TYPE (fn)))\n+    {\n+      for (arg = TYPE_ARG_TYPES (TREE_TYPE (fn));\n+\t   arg && TREE_VALUE (arg) != void_type_node;\n+\t   arg = TREE_CHAIN (arg))\n+\t{\n+\t  tree type = get_canon_type (TREE_VALUE (arg), false, false);\n+\t  if (escapes)\n+\t    mark_interesting_type (type, EXPOSED_PARAMETER);\n+\t}\n+    }\n+  else\n+    {\n+      /* FIXME - According to Geoff Keating, we should never have to\n+\t do this; the front ends should always process the arg list\n+\t from the TYPE_ARG_LIST. However, Geoff is wrong, this code\n+\t does seem to be live.  */\n+\n+      for (arg = DECL_ARGUMENTS (fn); arg; arg = TREE_CHAIN (arg))\n+\t{\n+\t  tree type = get_canon_type (TREE_TYPE (arg), false, false);\n+\t  if (escapes)\n+\t    mark_interesting_type (type, EXPOSED_PARAMETER);\n+\t}\n+    }\n+  if (escapes)\n+    {\n+      tree type = get_canon_type (TREE_TYPE (TREE_TYPE (fn)), false, false);\n+      mark_interesting_type (type, EXPOSED_PARAMETER); \n+    }\n+}\n+\n+/* Return true if the variable T is the right kind of static variable to\n+   perform compilation unit scope escape analysis.  */\n+\n+static inline void\n+has_proper_scope_for_analysis (tree t)\n+{\n+  /* If the variable has the \"used\" attribute, treat it as if it had a\n+     been touched by the devil.  */\n+  tree type = get_canon_type (TREE_TYPE (t), false, false);\n+  if (!type) return;\n+\n+  if (lookup_attribute (\"used\", DECL_ATTRIBUTES (t)))\n+    {\n+      mark_interesting_type (type, FULL_ESCAPE);\n+      return;\n+    }\n+\n+  /* Do not want to do anything with volatile except mark any\n+     function that uses one to be not const or pure.  */\n+  if (TREE_THIS_VOLATILE (t)) \n+    return;\n+\n+  /* Do not care about a local automatic that is not static.  */\n+  if (!TREE_STATIC (t) && !DECL_EXTERNAL (t))\n+    return;\n+\n+  if (DECL_EXTERNAL (t) || TREE_PUBLIC (t))\n+    {\n+      /* If the front end set the variable to be READONLY and\n+\t constant, we can allow this variable in pure or const\n+\t functions but the scope is too large for our analysis to set\n+\t these bits ourselves.  */\n+      \n+      if (TREE_READONLY (t)\n+\t  && DECL_INITIAL (t)\n+\t  && is_gimple_min_invariant (DECL_INITIAL (t)))\n+\t; /* Read of a constant, do not change the function state.  */\n+      else \n+\t{\n+\t  /* The type escapes for all public and externs. */\n+\t  mark_interesting_type (type, FULL_ESCAPE);\n+\t}\n+    }\n+}\n+\n+/* If T is a VAR_DECL for a static that we are interested in, add the\n+   uid to the bitmap.  */\n+\n+static void\n+check_operand (tree t)\n+{\n+  if (!t) return;\n+\n+  /* This is an assignment from a function, register the types as\n+     escaping.  */\n+  if (TREE_CODE (t) == FUNCTION_DECL)\n+    check_function_parameter_and_return_types (t, true);\n+\n+  else if (TREE_CODE (t) == VAR_DECL)\n+    has_proper_scope_for_analysis (t); \n+}\n+\n+/* Examine tree T for references.   */\n+\n+static void\n+check_tree (tree t)\n+{\n+  if ((TREE_CODE (t) == EXC_PTR_EXPR) || (TREE_CODE (t) == FILTER_EXPR))\n+    return;\n+\n+  while (TREE_CODE (t) == REALPART_EXPR \n+\t || TREE_CODE (t) == IMAGPART_EXPR\n+\t || handled_component_p (t))\n+    {\n+      if (TREE_CODE (t) == ARRAY_REF)\n+\tcheck_operand (TREE_OPERAND (t, 1));\n+      t = TREE_OPERAND (t, 0);\n+    }\n+\n+  if (INDIRECT_REF_P (t))\n+/*  || TREE_CODE (t) == MEM_REF) */\n+    check_tree (TREE_OPERAND (t, 0));\n+\n+  if (SSA_VAR_P (t) || (TREE_CODE (t) == FUNCTION_DECL))\n+    check_operand (t);\n+}\n+\n+/* Create an address_of edge FROM_TYPE.TO_TYPE.  */\n+static void\n+mark_interesting_addressof (tree to_type, tree from_type)\n+{\n+  int from_uid;\n+  int to_uid;\n+  bitmap type_map;\n+  splay_tree_node result; \n+\n+  from_type = get_canon_type (from_type, false, false);\n+  to_type = get_canon_type (to_type, false, false);\n+  \n+  if (!from_type || !to_type)\n+    return;\n+\n+  from_uid = TYPE_UID (from_type);\n+  to_uid = TYPE_UID (to_type);\n+\n+  gcc_assert (ipa_type_escape_star_count_of_interesting_type (from_type) == 0);\n+  \n+  /* Process the Y into X map pointer.  */\n+  result = splay_tree_lookup (uid_to_addressof_down_map, \n+\t\t\t      (splay_tree_key) from_uid);\n+  \n+  if (result) \n+    type_map = (bitmap) result->value;  \n+  else \n+    {\n+      type_map = BITMAP_ALLOC (&ipa_obstack);\n+      splay_tree_insert (uid_to_addressof_down_map,\n+\t\t\t from_uid, \n+\t\t\t (splay_tree_value)type_map);\n+    }\n+  bitmap_set_bit (type_map, TYPE_UID (to_type));\n+  \n+  /* Process the X into Y reverse map pointer.  */\n+  result = \n+    splay_tree_lookup (uid_to_addressof_up_map, (splay_tree_key) to_uid);\n+  \n+  if (result) \n+    type_map = (bitmap) result->value;  \n+  else \n+    {\n+      type_map = BITMAP_ALLOC (&ipa_obstack);\n+      splay_tree_insert (uid_to_addressof_up_map,\n+\t\t\t to_uid, \n+\t\t\t (splay_tree_value)type_map);\n+    }\n+  bitmap_set_bit (type_map, TYPE_UID (to_type));\n+}\n+\n+/* Scan tree T to see if there are any addresses taken in within T.  */\n+\n+static void \n+look_for_address_of (tree t)\n+{\n+  if (TREE_CODE (t) == ADDR_EXPR)\n+    {\n+      tree x = get_base_var (t);\n+      tree cref = TREE_OPERAND (t, 0);\n+\n+      /* If we have an expression of the form \"&a.b.c.d\", mark a.b,\n+\t b.c and c.d. as having its address taken.  */ \n+      tree fielddecl = NULL_TREE;\n+      while (cref!= x)\n+\t{\n+\t  if (TREE_CODE (cref) == COMPONENT_REF)\n+\t    {\n+\t      fielddecl =  TREE_OPERAND (cref, 1);\n+\t      mark_interesting_addressof (TREE_TYPE (fielddecl), \n+\t\t\t\t\t  DECL_FIELD_CONTEXT (fielddecl));\n+\t    }\n+\t  else if (TREE_CODE (cref) == ARRAY_REF)\n+\t    get_canon_type (TREE_TYPE (cref), false, false);\n+\n+\t  cref = TREE_OPERAND (cref, 0);\n+\t}\n+\n+      if (TREE_CODE (x) == VAR_DECL) \n+\thas_proper_scope_for_analysis (x);\n+    }\n+}\n+\n+\n+/* Scan tree T to see if there are any casts within it.\n+   LHS Is the LHS of the expression involving the cast.  */\n+\n+static void \n+look_for_casts (tree lhs __attribute__((unused)), tree t)\n+{\n+  if (is_gimple_cast (t) || TREE_CODE (t) == VIEW_CONVERT_EXPR)\n+    {\n+      tree castfromvar = TREE_OPERAND (t, 0);\n+      check_cast (TREE_TYPE (t), castfromvar);\n+    }\n+  else if (TREE_CODE (t) == COMPONENT_REF\n+\t   || TREE_CODE (t) == INDIRECT_REF\n+\t   || TREE_CODE (t) == BIT_FIELD_REF)\n+    {\n+      tree base = get_base_address (t);\n+      while (t != base)\n+\t{\n+\t  t = TREE_OPERAND (t, 0);\n+\t  if (TREE_CODE (t) == VIEW_CONVERT_EXPR)\n+\t    {\n+\t      /* This may be some part of a component ref.\n+\t\t IE it may be a.b.VIEW_CONVERT_EXPR<weird_type>(c).d, AFAIK.\n+\t\t castfromref will give you a.b.c, not a. */\n+\t      tree castfromref = TREE_OPERAND (t, 0);\n+\t      check_cast (TREE_TYPE (t), castfromref);\n+\t    }\n+\t  else if (TREE_CODE (t) == COMPONENT_REF)\n+\t    get_canon_type (TREE_TYPE (TREE_OPERAND (t, 1)), false, false);\n+\t}\n+    } \n+} \n+\n+/* Check to see if T is a read or address of operation on a static var\n+   we are interested in analyzing.  */\n+\n+static void\n+check_rhs_var (tree t)\n+{\n+  look_for_address_of (t);\n+  check_tree(t);\n+}\n+\n+/* Check to see if T is an assignment to a static var we are\n+   interested in analyzing.  */\n+\n+static void\n+check_lhs_var (tree t)\n+{\n+  check_tree(t);\n+}\n+\n+/* This is a scaled down version of get_asm_expr_operands from\n+   tree_ssa_operands.c.  The version there runs much later and assumes\n+   that aliasing information is already available. Here we are just\n+   trying to find if the set of inputs and outputs contain references\n+   or address of operations to local.  FN is the function being\n+   analyzed and STMT is the actual asm statement.  */\n+\n+static void\n+get_asm_expr_operands (tree stmt)\n+{\n+  int noutputs = list_length (ASM_OUTPUTS (stmt));\n+  const char **oconstraints\n+    = (const char **) alloca ((noutputs) * sizeof (const char *));\n+  int i;\n+  tree link;\n+  const char *constraint;\n+  bool allows_mem, allows_reg, is_inout;\n+  \n+  for (i=0, link = ASM_OUTPUTS (stmt); link; ++i, link = TREE_CHAIN (link))\n+    {\n+      oconstraints[i] = constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_output_constraint (&constraint, i, 0, 0,\n+\t\t\t       &allows_mem, &allows_reg, &is_inout);\n+      \n+      check_lhs_var (TREE_VALUE (link));\n+    }\n+\n+  for (link = ASM_INPUTS (stmt); link; link = TREE_CHAIN (link))\n+    {\n+      constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_input_constraint (&constraint, 0, 0, noutputs, 0,\n+\t\t\t      oconstraints, &allows_mem, &allows_reg);\n+      \n+      check_rhs_var (TREE_VALUE (link));\n+    }\n+  \n+  /* There is no code here to check for asm memory clobbers.  The\n+     casual maintainer might think that such code would be necessary,\n+     but that appears to be wrong.  In other parts of the compiler,\n+     the asm memory clobbers are assumed to only clobber variables\n+     that are addressable.  All types with addressable instances are\n+     assumed to already escape.  So, we are protected here.  */\n+}\n+\n+/* Check the parameters of a function call to CALL_EXPR to mark the\n+   types that pass across the function boundary.  Also check to see if\n+   this is either an indirect call, a call outside the compilation\n+   unit.  */\n+\n+static bool\n+check_call (tree call_expr) \n+{\n+  int flags = call_expr_flags(call_expr);\n+  tree operand_list = TREE_OPERAND (call_expr, 1);\n+  tree operand;\n+  tree callee_t = get_callee_fndecl (call_expr);\n+  tree argument;\n+  struct cgraph_node* callee;\n+  enum availability avail = AVAIL_NOT_AVAILABLE;\n+\n+  for (operand = operand_list;\n+       operand != NULL_TREE;\n+       operand = TREE_CHAIN (operand))\n+    {\n+      tree argument = TREE_VALUE (operand);\n+      check_rhs_var (argument);\n+    }\n+  \n+  if (callee_t)\n+    {\n+      tree arg_type;\n+      tree last_arg_type = NULL;\n+      callee = cgraph_node(callee_t);\n+      avail = cgraph_function_body_availability (callee);\n+      \n+      /* Check that there are no implicit casts in the passing of\n+\t parameters.  */\n+      if (TYPE_ARG_TYPES (TREE_TYPE (callee_t)))\n+\t{\n+\t  operand = operand_list;\n+\t  for (arg_type = TYPE_ARG_TYPES (TREE_TYPE (callee_t));\n+\t       arg_type && TREE_VALUE (arg_type) != void_type_node;\n+\t       arg_type = TREE_CHAIN (arg_type))\n+\t    {\n+\t      if (operand)\n+\t\t{\n+\t\t  argument = TREE_VALUE (operand);\n+\t\t  last_arg_type = TREE_VALUE(arg_type);\n+\t\t  check_cast (last_arg_type, argument);\n+\t\t  operand = TREE_CHAIN (operand);\n+\t\t}\n+\t      else \n+\t\t/* The code reaches here for some unfortunate\n+\t\t   builtin functions that do not have a list of\n+\t\t   argument types.  */\n+\t\tbreak; \n+\t    }\n+\t} \n+      else  \n+\t{ \n+\t  /* FIXME - According to Geoff Keating, we should never\n+\t     have to do this; the front ends should always process\n+\t     the arg list from the TYPE_ARG_LIST. */\n+\t  operand = operand_list;\n+\t  for (arg_type = DECL_ARGUMENTS (callee_t); \n+\t       arg_type;\n+\t       arg_type = TREE_CHAIN (arg_type))\n+\t    {\n+\t      if (operand)\n+\t\t{\n+\t\t  argument = TREE_VALUE (operand);\n+\t\t  last_arg_type = TREE_TYPE(arg_type);\n+\t\t  check_cast (last_arg_type, argument);\n+\t\t  operand = TREE_CHAIN (operand);\n+\t\t} \n+\t      else \n+\t\t/* The code reaches here for some unfortunate\n+\t\t   builtin functions that do not have a list of\n+\t\t   argument types.  */\n+\t\tbreak; \n+\t    }\n+\t}\n+      \n+      /* In the case where we have a var_args function, we need to\n+\t check the remaining parameters against the last argument.  */\n+      arg_type = last_arg_type;\n+      for (;\n+\t   operand != NULL_TREE;\n+\t   operand = TREE_CHAIN (operand))\n+\t{\n+\t  argument = TREE_VALUE (operand);\n+\t  if (arg_type)\n+\t    check_cast (arg_type, argument);\n+\t  else \n+\t    {\n+\t      /* The code reaches here for some unfortunate\n+\t\t builtin functions that do not have a list of\n+\t\t argument types.  Most of these functions have\n+\t\t been marked as having their parameters not\n+\t\t escape, but for the rest, the type is doomed.  */\n+\t      tree type = get_canon_type (TREE_TYPE (argument), false, false);\n+\t      mark_interesting_type (type, FULL_ESCAPE);\n+\t    }\n+\t}\n+    }\n+\n+  /* The callee is either unknown (indirect call) or there is just no\n+     scannable code for it (external call) .  We look to see if there\n+     are any bits available for the callee (such as by declaration or\n+     because it is builtin) and process solely on the basis of those\n+     bits. */\n+\n+  if (avail == AVAIL_NOT_AVAILABLE || avail == AVAIL_OVERWRITABLE)\n+    {\n+      /* If this is a direct call to an external function, mark all of\n+\t the parameter and return types.  */\n+      for (operand = operand_list;\n+\t   operand != NULL_TREE;\n+\t   operand = TREE_CHAIN (operand))\n+\t{\n+\t  tree type = \n+\t    get_canon_type (TREE_TYPE (TREE_VALUE (operand)), false, false);\n+\t  mark_interesting_type (type, EXPOSED_PARAMETER);\n+    }\n+\t  \n+      if (callee_t) \n+\t{\n+\t  tree type = \n+\t    get_canon_type (TREE_TYPE (TREE_TYPE (callee_t)), false, false);\n+\t  mark_interesting_type (type, EXPOSED_PARAMETER);\n+\t}\n+    }\n+  return (flags & ECF_MALLOC);\n+}\n+\n+/* CODE is the operation on OP0 and OP1.  OP0 is the operand that we\n+   *know* is a pointer type.  OP1 may be a pointer type.  */\n+static bool \n+okay_pointer_operation (enum tree_code code, tree op0, tree op1)\n+{\n+  tree op0type = TYPE_MAIN_VARIANT (TREE_TYPE (op0));\n+  tree op1type = TYPE_MAIN_VARIANT (TREE_TYPE (op1));\n+  if (POINTER_TYPE_P (op1type))\n+    return false;\n+  switch (code)\n+    {\n+    case MULT_EXPR:\n+    case PLUS_EXPR:\n+    case MINUS_EXPR:\n+      /* TODO: Handle multiples of op0 size as well */\n+      if (operand_equal_p (size_in_bytes (op0type), op1, 0))\n+\treturn true;\n+      /* fallthrough */\n+\n+    default:\n+      return false;\n+    }\n+  return false;\n+}\n+\n+/* TP is the part of the tree currently under the microscope.\n+   WALK_SUBTREES is part of the walk_tree api but is unused here.\n+   DATA is cgraph_node of the function being walked.  */\n+\n+/* FIXME: When this is converted to run over SSA form, this code\n+   should be converted to use the operand scanner.  */\n+\n+static tree\n+scan_for_refs (tree *tp, int *walk_subtrees, void *data)\n+{\n+  struct cgraph_node *fn = data;\n+  tree t = *tp;\n+\n+  switch (TREE_CODE (t))  \n+    {\n+    case VAR_DECL:\n+      if (DECL_INITIAL (t))\n+\twalk_tree (&DECL_INITIAL (t), scan_for_refs, fn, visited_nodes);\n+      *walk_subtrees = 0;\n+      break;\n+\n+    case MODIFY_EXPR:\n+      {\n+\t/* First look on the lhs and see what variable is stored to */\n+\ttree lhs = TREE_OPERAND (t, 0);\n+\ttree rhs = TREE_OPERAND (t, 1);\n+\n+\tcheck_lhs_var (lhs);\n+ \tcheck_cast (TREE_TYPE (lhs), rhs);\n+\n+\t/* For the purposes of figuring out what the cast affects */\n+\n+\t/* Next check the operands on the rhs to see if they are ok. */\n+\tswitch (TREE_CODE_CLASS (TREE_CODE (rhs))) \n+\t  {\n+\t  case tcc_binary:\t    \n+ \t    {\n+ \t      tree op0 = TREE_OPERAND (rhs, 0);\n+\t      tree type0 = get_canon_type (TREE_TYPE (op0), false, false);\n+ \t      tree op1 = TREE_OPERAND (rhs, 1);\n+\t      tree type1 = get_canon_type (TREE_TYPE (op1), false, false);\n+ \n+ \t      /* If this is pointer arithmetic of any bad sort, then\n+ \t\t we need to mark the types as bad.  For binary\n+ \t\t operations, no binary operator we currently support\n+ \t\t is always \"safe\" in regard to what it would do to\n+ \t\t pointers for purposes of determining which types\n+ \t\t escape, except operations of the size of the type.\n+ \t\t It is possible that min and max under the right set\n+ \t\t of circumstances and if the moon is in the correct\n+ \t\t place could be safe, but it is hard to see how this\n+ \t\t is worth the effort.  */\n+ \n+ \t      if (type0 && POINTER_TYPE_P (type0)\n+\t\t  && !okay_pointer_operation (TREE_CODE (rhs), op0, op1))\n+ \t\tmark_interesting_type (type0, FULL_ESCAPE);\n+ \t      if (type1 && POINTER_TYPE_P (type1)\n+\t\t  && !okay_pointer_operation (TREE_CODE (rhs), op1, op0))\n+ \t\tmark_interesting_type (type1, FULL_ESCAPE);\n+ \t      \n+\t      look_for_casts (lhs, op0);\n+\t      look_for_casts (lhs, op1);\n+ \t      check_rhs_var (op0);\n+ \t      check_rhs_var (op1);\n+\t    }\n+\t    break;\n+\t  case tcc_unary:\n+ \t    {\n+ \t      tree op0 = TREE_OPERAND (rhs, 0);\n+\t      tree type0 = get_canon_type (TREE_TYPE (op0), false, false);\n+\t      /* For unary operations, if the operation is NEGATE or\n+\t\t ABS on a pointer, this is also considered pointer\n+\t\t arithmetic and thus, bad for business.  */\n+ \t      if (type0 && (TREE_CODE (op0) == NEGATE_EXPR\n+ \t\t   || TREE_CODE (op0) == ABS_EXPR)\n+ \t\t  && POINTER_TYPE_P (type0))\n+ \t\t{\n+ \t\t  mark_interesting_type (type0, FULL_ESCAPE);\n+ \t\t}\n+ \t      check_rhs_var (op0);\n+\t      look_for_casts (lhs, op0);\n+\t      look_for_casts (lhs, rhs);\n+ \t    }\n+\n+\t    break;\n+\t  case tcc_reference:\n+\t    look_for_casts (lhs, rhs);\n+\t    check_rhs_var (rhs);\n+\t    break;\n+\t  case tcc_declaration:\n+\t    check_rhs_var (rhs);\n+\t    break;\n+\t  case tcc_expression:\n+\t    switch (TREE_CODE (rhs)) \n+\t      {\n+\t      case ADDR_EXPR:\n+\t\tlook_for_casts (lhs, TREE_OPERAND (rhs, 0));\n+\t\tcheck_rhs_var (rhs);\n+\t\tbreak;\n+\t      case CALL_EXPR: \n+\t\t/* If this is a call to malloc, squirrel away the\n+\t\t   result so we do mark the resulting cast as being\n+\t\t   bad.  */\n+\t\tif (check_call (rhs))\n+\t\t  bitmap_set_bit (results_of_malloc, DECL_UID (lhs));\n+\t\tbreak;\n+\t      default:\n+\t\tbreak;\n+\t      }\n+\t    break;\n+\t  default:\n+\t    break;\n+\t  }\n+\t*walk_subtrees = 0;\n+      }\n+      break;\n+\n+    case ADDR_EXPR:\n+      /* This case is here to find addresses on rhs of constructors in\n+\t decl_initial of static variables. */\n+      check_rhs_var (t);\n+      *walk_subtrees = 0;\n+      break;\n+\n+    case CALL_EXPR: \n+      check_call (t);\n+      *walk_subtrees = 0;\n+      break;\n+      \n+    case ASM_EXPR:\n+      get_asm_expr_operands (t);\n+      *walk_subtrees = 0;\n+      break;\n+      \n+    default:\n+      break;\n+    }\n+  return NULL;\n+}\n+\n+\n+/* The init routine for analyzing global static variable usage.  See\n+   comments at top for description.  */\n+static void \n+ipa_init (void) \n+{\n+  bitmap_obstack_initialize (&ipa_obstack);\n+  global_types_exposed_parameter = BITMAP_ALLOC (&ipa_obstack);\n+  global_types_full_escape = BITMAP_ALLOC (&ipa_obstack);\n+  global_types_seen = BITMAP_ALLOC (&ipa_obstack);\n+  results_of_malloc = BITMAP_ALLOC (&ipa_obstack);\n+\n+  uid_to_canon_type = splay_tree_new (splay_tree_compare_ints, 0, 0);\n+  all_canon_types = splay_tree_new (compare_type_brand, 0, 0);\n+  type_to_canon_type = splay_tree_new (splay_tree_compare_pointers, 0, 0);\n+  uid_to_subtype_map = splay_tree_new (splay_tree_compare_ints, 0, 0);\n+  uid_to_addressof_down_map = splay_tree_new (splay_tree_compare_ints, 0, 0);\n+  uid_to_addressof_up_map = splay_tree_new (splay_tree_compare_ints, 0, 0);\n+\n+  /* There are some shared nodes, in particular the initializers on\n+     static declarations.  We do not need to scan them more than once\n+     since all we would be interested in are the addressof\n+     operations.  */\n+  visited_nodes = pointer_set_create ();\n+  initialized = true;\n+}\n+\n+/* Check out the rhs of a static or global initialization VNODE to see\n+   if any of them contain addressof operations.  Note that some of\n+   these variables may  not even be referenced in the code in this\n+   compilation unit but their right hand sides may contain references\n+   to variables defined within this unit.  */\n+\n+static void \n+analyze_variable (struct cgraph_varpool_node *vnode)\n+{\n+  tree global = vnode->decl;\n+  tree type = get_canon_type (TREE_TYPE (global), false, false);\n+\n+  /* If this variable has exposure beyond the compilation unit, add\n+     its type to the global types.  */\n+\n+  if (vnode->externally_visible)\n+    mark_interesting_type (type, FULL_ESCAPE);\n+\n+  if (TREE_CODE (global) == VAR_DECL)\n+    {\n+      if (DECL_INITIAL (global)) \n+\twalk_tree (&DECL_INITIAL (global), scan_for_refs, \n+\t\t   NULL, visited_nodes);\n+    } \n+  else abort();\n+}\n+\n+/* This is the main routine for finding the reference patterns for\n+   global variables within a function FN.  */\n+\n+static void\n+analyze_function (struct cgraph_node *fn)\n+{\n+  tree decl = fn->decl;\n+  check_function_parameter_and_return_types (decl, \n+\t\t\t\t\t     fn->local.externally_visible);\n+  if (dump_file)\n+    fprintf (dump_file, \"\\n local analysis of %s\", cgraph_node_name (fn));\n+  \n+  {\n+    struct function *this_cfun = DECL_STRUCT_FUNCTION (decl);\n+    basic_block this_block;\n+\n+    FOR_EACH_BB_FN (this_block, this_cfun)\n+      {\n+\tblock_stmt_iterator bsi;\n+\tfor (bsi = bsi_start (this_block); !bsi_end_p (bsi); bsi_next (&bsi))\n+\t  walk_tree (bsi_stmt_ptr (bsi), scan_for_refs, \n+\t\t     fn, visited_nodes);\n+      }\n+  }\n+\n+  /* There may be const decls with interesting right hand sides.  */\n+  if (DECL_STRUCT_FUNCTION (decl))\n+    {\n+      tree step;\n+      for (step = DECL_STRUCT_FUNCTION (decl)->unexpanded_var_list;\n+\t   step;\n+\t   step = TREE_CHAIN (step))\n+\t{\n+\t  tree var = TREE_VALUE (step);\n+\t  if (TREE_CODE (var) == VAR_DECL \n+\t      && DECL_INITIAL (var)\n+\t      && !TREE_STATIC (var))\n+\t    walk_tree (&DECL_INITIAL (var), scan_for_refs, \n+\t\t       fn, visited_nodes);\n+\t  get_canon_type (TREE_TYPE (var), false, false);\n+\t}\n+    }\n+}\n+\n+\f\n+\n+/* Convert a type_UID into a type.  */\n+static tree\n+type_for_uid (int uid)\n+{\n+  splay_tree_node result = \n+    splay_tree_lookup (uid_to_canon_type, (splay_tree_key) uid);\n+  \n+  if (result)\n+    return (tree) result->value;  \n+  else return NULL;\n+}\n+\n+/* Return the a bitmap with the subtypes of the type for UID.  If it\n+   does not exist, return either NULL or a new bitmap depending on the\n+   value of CREATE.  */ \n+\n+static bitmap\n+subtype_map_for_uid (int uid, bool create)\n+{\n+  splay_tree_node result = splay_tree_lookup (uid_to_subtype_map, \n+\t\t\t      (splay_tree_key) uid);\n+  \n+  if (result) \n+    return (bitmap) result->value;  \n+  else if (create)\n+    {\n+      bitmap subtype_map = BITMAP_ALLOC (&ipa_obstack);\n+      splay_tree_insert (uid_to_subtype_map,\n+\t\t\t uid, \n+\t\t\t (splay_tree_value)subtype_map);\n+      return subtype_map;\n+    }\n+  else return NULL;\n+}\n+\n+/* Mark all of the supertypes and field types of TYPE as being seen.\n+   Also accumulate the subtypes for each type so that\n+   close_types_full_escape can mark a subtype as escaping if the\n+   supertype escapes.  */\n+\n+static void\n+close_type_seen (tree type)\n+{\n+  tree field;\n+  int i, uid;\n+  tree binfo, base_binfo;\n+\n+  /* See thru all pointer tos and array ofs. */\n+  type = get_canon_type (type, true, true);\n+  if (!type)\n+    return;\n+\n+  uid = TYPE_UID (type);\n+\n+  if (bitmap_bit_p (been_there_done_that, uid))\n+    return;\n+  bitmap_set_bit (been_there_done_that, uid);\n+\n+  /* If we are doing a language with a type heirarchy, mark all of\n+     the superclasses.  */\n+  if (TYPE_BINFO (type)) \n+    for (binfo = TYPE_BINFO (type), i = 0;\n+\t BINFO_BASE_ITERATE (binfo, i, base_binfo); i++)\n+      {\n+\ttree binfo_type = BINFO_TYPE (base_binfo);\n+\tbitmap subtype_map = subtype_map_for_uid \n+\t  (TYPE_UID (TYPE_MAIN_VARIANT (binfo_type)), true);\n+\tbitmap_set_bit (subtype_map, uid);\n+\tclose_type_seen (get_canon_type (binfo_type, true, true));\n+      }\n+      \n+  /* If the field is a struct or union type, mark all of the\n+     subfields.  */\n+  for (field = TYPE_FIELDS (type);\n+       field;\n+       field = TREE_CHAIN (field))\n+    {\n+      tree field_type;\n+      if (TREE_CODE (field) != FIELD_DECL)\n+\tcontinue;\n+\n+      field_type = TREE_TYPE (field);\n+      if (ipa_type_escape_star_count_of_interesting_or_array_type (field_type) >= 0)\n+\tclose_type_seen (get_canon_type (field_type, true, true));\n+    }\n+}\n+\n+/* Take a TYPE that has been passed by value to an external function\n+   and mark all of the fields that have pointer types as escaping. For\n+   any of the non pointer types that are structures or unions,\n+   recurse.  TYPE is never a pointer type.  */ \n+\n+static void\n+close_type_exposed_parameter (tree type)\n+{\n+  tree field;\n+  int uid;\n+\n+  type = get_canon_type (type, false, false);\n+  if (!type)\n+    return;\n+  uid = TYPE_UID (type);\n+  gcc_assert (!POINTER_TYPE_P (type));\n+\n+  if (bitmap_bit_p (been_there_done_that, uid))\n+    return;\n+  bitmap_set_bit (been_there_done_that, uid);\n+\n+  /* If the field is a struct or union type, mark all of the\n+     subfields.  */\n+  for (field = TYPE_FIELDS (type);\n+       field;\n+       field = TREE_CHAIN (field))\n+    {\n+      tree field_type;\n+\n+      if (TREE_CODE (field) != FIELD_DECL)\n+\tcontinue;\n+\n+      field_type = get_canon_type (TREE_TYPE (field), false, false);\n+      mark_interesting_type (field_type, EXPOSED_PARAMETER);\n+\n+      /* Only recurse for non pointer types of structures and unions.  */\n+      if (ipa_type_escape_star_count_of_interesting_type (field_type) == 0) \n+\tclose_type_exposed_parameter (field_type);\n+    }\n+}\n+\n+/* The next function handles the case where a type fully escapes.\n+   This means that not only does the type itself escape, \n+\n+   a) the type of every field recursively escapes\n+   b) the type of every subtype escapes as well as the super as well\n+   as all of the pointer to types for each field.\n+\n+   Note that pointer to types are not marked as escaping.  If the\n+   pointed to type escapes, the pointer to type also escapes.\n+\n+   Take a TYPE that has had the address taken for an instance of it\n+   and mark all of the types for its fields as having their addresses\n+   taken. */ \n+\n+static void\n+close_type_full_escape (tree type)\n+{\n+  tree field;\n+  unsigned int i;\n+  int uid;\n+  tree binfo, base_binfo;\n+  bitmap_iterator bi;\n+  bitmap subtype_map;\n+  splay_tree_node address_result; \n+\n+  /* Strip off any pointer or array types.  */\n+  type = get_canon_type (type, true, true);\n+  if (!type)\n+    return;\n+  uid = TYPE_UID (type);\n+\n+  if (bitmap_bit_p (been_there_done_that, uid))\n+    return;\n+  bitmap_set_bit (been_there_done_that, uid);\n+\n+  subtype_map = subtype_map_for_uid (uid, false);\n+\n+  /* If we are doing a language with a type heirarchy, mark all of\n+     the superclasses.  */\n+  if (TYPE_BINFO (type)) \n+    for (binfo = TYPE_BINFO (type), i = 0;\n+\t BINFO_BASE_ITERATE (binfo, i, base_binfo); i++)\n+      {\n+\ttree binfotype = BINFO_TYPE (base_binfo);\n+\tbinfotype = mark_type (binfotype, FULL_ESCAPE);\n+\tclose_type_full_escape (binfotype);\n+      }\n+      \n+  /* Mark as escaped any types that have been down casted to\n+     this type. */\n+  if (subtype_map)\n+    EXECUTE_IF_SET_IN_BITMAP (subtype_map, 0, i, bi)\n+      {\n+\ttree subtype = type_for_uid (i); \n+\tsubtype = mark_type (subtype, FULL_ESCAPE);\n+\tclose_type_full_escape (subtype);\n+      }\n+\n+  /* If the field is a struct or union type, mark all of the\n+     subfields.  */\n+  for (field = TYPE_FIELDS (type);\n+       field;\n+       field = TREE_CHAIN (field))\n+    {\n+      tree field_type;\n+      if (TREE_CODE (field) != FIELD_DECL)\n+\tcontinue;\n+\n+      field_type = TREE_TYPE (field);\n+      if (ipa_type_escape_star_count_of_interesting_or_array_type (field_type) >= 0)\n+\t{\n+\t  field_type = mark_type (field_type, FULL_ESCAPE);\n+\t  close_type_full_escape (field_type);\n+\t}\n+    }\n+\n+  /* For all of the types A that contain this type B and were part of\n+     an expression like \"&...A.B...\", mark the A's as escaping.  */\n+  address_result = splay_tree_lookup (uid_to_addressof_up_map, \n+\t\t\t\t      (splay_tree_key) uid);\n+  if (address_result)\n+    {\n+      bitmap containing_classes = (bitmap) address_result->value;\n+      EXECUTE_IF_SET_IN_BITMAP (containing_classes, 0, i, bi)\n+\t{\n+\t  close_type_full_escape (type_for_uid (i));\n+\t}\n+    }\n+}\n+\n+/* Transitively close the addressof bitmap for the type with UID.\n+   This means that if we had a.b and b.c, a would have both b an c in\n+   its maps.  */ \n+\n+static bitmap\n+close_addressof_down (int uid) \n+{\n+  bitmap_iterator bi;\n+  splay_tree_node result = \n+    splay_tree_lookup (uid_to_addressof_down_map, (splay_tree_key) uid);\n+  bitmap map = NULL;\n+  bitmap new_map;\n+  unsigned int i;\n+  \n+  if (result) \n+    map = (bitmap) result->value;\n+  else \n+    return NULL;\n+\n+  if (bitmap_bit_p (been_there_done_that, uid))\n+    return map;\n+  bitmap_set_bit (been_there_done_that, uid);\n+\n+  /* If the type escapes, get rid of the addressof map, it will not be\n+     needed.  */\n+  if (bitmap_bit_p (global_types_full_escape, uid))\n+    {\n+      BITMAP_FREE (map);\n+      splay_tree_remove (uid_to_addressof_down_map, (splay_tree_key) uid);\n+      return NULL;\n+    }\n+\n+  /* The new_map will have all of the bits for the enclosed fields and\n+     will have the unique id version of the old map.  */\n+  new_map = BITMAP_ALLOC (&ipa_obstack);\n+\n+  EXECUTE_IF_SET_IN_BITMAP (map, 0, i, bi)\n+    {\n+      bitmap submap = close_addressof_down (i);\n+      bitmap_set_bit (new_map, i);\n+      if (submap) \n+\tbitmap_ior_into (new_map, submap);\n+    }      \n+  result->value = (splay_tree_value) new_map;\n+\n+  BITMAP_FREE (map);\n+  return new_map;\n+}\n+\n+\f\n+/* The main entry point for type escape analysis.  */\n+\n+static void\n+type_escape_execute (void)\n+{\n+  struct cgraph_node *node;\n+  struct cgraph_varpool_node *vnode;\n+  unsigned int i;\n+  bitmap_iterator bi;\n+  splay_tree_node result;\n+\n+  ipa_init ();\n+\n+  /* Process all of the variables first.  */\n+  for (vnode = cgraph_varpool_nodes_queue; vnode; vnode = vnode->next_needed)\n+    analyze_variable (vnode);\n+\n+  /* Process all of the functions. next\n+\n+     We do not want to process any of the clones so we check that this\n+     is a master clone.  However, we do need to process any\n+     AVAIL_OVERWRITABLE functions (these are never clones) because\n+     they may cause a type variable to escape.  \n+  */\n+  for (node = cgraph_nodes; node; node = node->next)\n+    if (node->analyzed \n+\t&& (cgraph_is_master_clone (node)\n+\t    || (cgraph_function_body_availability (node) == AVAIL_OVERWRITABLE)))\n+      analyze_function (node);\n+\n+\n+  pointer_set_destroy (visited_nodes);\n+  visited_nodes = NULL;\n+\n+  /* Do all of the closures to discover which types escape the\n+     compilation unit.  */\n+\n+  been_there_done_that = BITMAP_ALLOC (&ipa_obstack);\n+  bitmap_tmp = BITMAP_ALLOC (&ipa_obstack);\n+\n+  /* Examine the types that we have directly seen in scanning the code\n+     and add to that any contained types or superclasses.  */\n+\n+  bitmap_copy (bitmap_tmp, global_types_seen);\n+  EXECUTE_IF_SET_IN_BITMAP (bitmap_tmp, 0, i, bi)\n+    {\n+      tree type = type_for_uid (i);\n+      /* Only look at records and unions and pointer tos.  */\n+      if (ipa_type_escape_star_count_of_interesting_or_array_type (type) >= 0)\n+\tclose_type_seen (type);\n+    }\n+  bitmap_clear (been_there_done_that);\n+\n+  /* Examine all of the types passed by value and mark any enclosed\n+     pointer types as escaping.  */\n+  bitmap_copy (bitmap_tmp, global_types_exposed_parameter);\n+  EXECUTE_IF_SET_IN_BITMAP (bitmap_tmp, 0, i, bi)\n+    {\n+      close_type_exposed_parameter (type_for_uid (i));\n+    }\n+  bitmap_clear (been_there_done_that);\n+\n+  /* Close the types for escape.  If something escapes, then any\n+     enclosed types escape as well as any subtypes.  */\n+  bitmap_copy (bitmap_tmp, global_types_full_escape);\n+  EXECUTE_IF_SET_IN_BITMAP (bitmap_tmp, 0, i, bi)\n+    {\n+      close_type_full_escape (type_for_uid (i));\n+    }\n+  bitmap_clear (been_there_done_that);\n+\n+  /* Before this pass, the uid_to_addressof_down_map for type X\n+     contained an entry for Y if there had been an operation of the\n+     form &X.Y.  This step adds all of the fields contained within Y\n+     (recursively) to X's map.  */\n+  \n+  result = splay_tree_min (uid_to_addressof_down_map);\n+  while (result)\n+    {\n+      int uid = result->key;\n+      /* Close the addressof map, i.e. copy all of the transitive\n+\t substructures up to this level.  */\n+      close_addressof_down (uid);\n+      result = splay_tree_successor (uid_to_addressof_down_map, uid);\n+    }\n+\n+  /* Do not need the array types and pointer types in the persistent\n+     data structures.  */\n+  result = splay_tree_min (all_canon_types);\n+  while (result)\n+    {\n+      tree type = (tree) result->value;\n+      tree key = (tree) result->key;\n+      if (POINTER_TYPE_P (type) \n+\t  || TREE_CODE (type) == ARRAY_TYPE)\n+\t{\n+\t  splay_tree_remove (all_canon_types, (splay_tree_key) result->key);\n+\t  splay_tree_remove (type_to_canon_type, (splay_tree_key) type);\n+\t  splay_tree_remove (uid_to_canon_type, (splay_tree_key) TYPE_UID (type));\n+\t  bitmap_clear_bit (global_types_seen, TYPE_UID (type));\n+\t}\n+      result = splay_tree_successor (all_canon_types, (splay_tree_key) key);\n+    }\n+\n+/*   { */\n+/*     FILE * tmp = dump_file; */\n+/*     dump_file = stderr; */\n+  if (dump_file)\n+    { \n+      EXECUTE_IF_SET_IN_BITMAP (global_types_seen, 0, i, bi)\n+\t{\n+\t  /* The pointer types are in the global_types_full_escape\n+\t     bitmap but not in the backwards map.  They also contain\n+\t     no useful information since they are not marked.  */\n+\t  tree type = type_for_uid (i);\n+\t  fprintf(dump_file, \"type %d \", i);\n+\t  print_generic_expr (dump_file, type, 0);\n+\t  if (bitmap_bit_p (global_types_full_escape, i))\n+\t    fprintf(dump_file, \" escaped\\n\");\n+\t  else \n+\t    fprintf(dump_file, \" contained\\n\");\n+\t}\n+    }\n+/*   dump_file = tmp; */\n+/*   } */\n+\n+  /* Get rid of uid_to_addressof_up_map and its bitmaps.  */\n+  result = splay_tree_min (uid_to_addressof_up_map);\n+  while (result)\n+    {\n+      int uid = (int)result->key;\n+      bitmap bm = (bitmap)result->value;\n+\n+      BITMAP_FREE (bm);\n+      splay_tree_remove (uid_to_addressof_up_map, (splay_tree_key) uid);\n+      result = splay_tree_successor (uid_to_addressof_up_map, uid);\n+    }\n+\n+  /* Get rid of the subtype map.  */\n+  result = splay_tree_min (uid_to_subtype_map);\n+  while (result)\n+    {\n+      bitmap b = (bitmap)result->value;\n+      BITMAP_FREE(b);\n+      splay_tree_remove (uid_to_subtype_map, result->key);\n+      result = splay_tree_min (uid_to_subtype_map);\n+    }\n+  splay_tree_delete (uid_to_subtype_map);\n+  uid_to_subtype_map = NULL;\n+\n+  BITMAP_FREE (global_types_exposed_parameter);\n+  BITMAP_FREE (been_there_done_that);\n+  BITMAP_FREE (bitmap_tmp);\n+  BITMAP_FREE (results_of_malloc);\n+}\n+\n+static bool\n+gate_type_escape_vars (void)\n+{\n+  return (flag_unit_at_a_time != 0 && flag_ipa_type_escape\n+\t  /* Don't bother doing anything if the program has errors.  */\n+\t  && !(errorcount || sorrycount));\n+}\n+\n+struct tree_opt_pass pass_ipa_type_escape =\n+{\n+  \"type-escape-var\",\t\t\t/* name */\n+  gate_type_escape_vars,\t\t/* gate */\n+  type_escape_execute,\t\t\t/* execute */\n+  NULL,\t\t\t\t\t/* sub */\n+  NULL,\t\t\t\t\t/* next */\n+  0,\t\t\t\t\t/* static_pass_number */\n+  TV_IPA_TYPE_ESCAPE,\t        \t/* tv_id */\n+  0,\t                                /* properties_required */\n+  0,\t\t\t\t\t/* properties_provided */\n+  0,\t\t\t\t\t/* properties_destroyed */\n+  0,\t\t\t\t\t/* todo_flags_start */\n+  0,                                    /* todo_flags_finish */\n+  0\t\t\t\t\t/* letter */\n+};\n+"}, {"sha": "76a7b7b485bafa83812145a12f44b6c69fe02913", "filename": "gcc/ipa-type-escape.h", "status": "added", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-type-escape.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-type-escape.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-type-escape.h?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,33 @@\n+/* Type based alias analysis.\n+   Copyright (C) 2004 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#ifndef GCC_IPA_TYPE_ESCAPE_H\n+#define GCC_IPA_TYPE_ESCAPE_H\n+#include \"tree.h\"\n+\n+bool   ipa_type_escape_type_contained_p (tree type);\n+bool   ipa_type_escape_field_does_not_clobber_p (tree record_type, tree field_type);\n+int    ipa_type_escape_star_count_of_interesting_type (tree type); \n+int    ipa_type_escape_star_count_of_interesting_or_array_type (tree type);\n+\n+\n+#endif  /* GCC_IPA_TYPE_ESCAPE_H  */\n+"}, {"sha": "b758031adbe60818f89954d4b1d7e57c65c18cb3", "filename": "gcc/ipa-utils.c", "status": "added", "additions": 228, "deletions": 0, "changes": 228, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-utils.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-utils.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-utils.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,228 @@\n+/* Utilities for ipa analysis.\n+   Copyright (C) 2005 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  \n+*/\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"tree.h\"\n+#include \"tree-flow.h\"\n+#include \"tree-inline.h\"\n+#include \"tree-pass.h\"\n+#include \"langhooks.h\"\n+#include \"pointer-set.h\"\n+#include \"ggc.h\"\n+#include \"ipa-utils.h\"\n+#include \"ipa-reference.h\"\n+#include \"c-common.h\"\n+#include \"tree-gimple.h\"\n+#include \"cgraph.h\"\n+#include \"output.h\"\n+#include \"flags.h\"\n+#include \"timevar.h\"\n+#include \"diagnostic.h\"\n+#include \"langhooks.h\"\n+\n+/* Debugging function for postorder and inorder code. NOTE is a string\n+   that is printed before the nodes are printed.  ORDER is an array of\n+   cgraph_nodes that has COUNT useful nodes in it.  */\n+\n+void \n+ipa_utils_print_order (FILE* out, \n+\t\t       const char * note, \n+\t\t       struct cgraph_node** order, \n+\t\t       int count) \n+{\n+  int i;\n+  fprintf (out, \"\\n\\n ordered call graph: %s\\n\", note);\n+  \n+  for (i = count - 1; i >= 0; i--)\n+    dump_cgraph_node(dump_file, order[i]);\n+  fprintf (out, \"\\n\");\n+  fflush(out);\n+}\n+\n+\f\n+struct searchc_env {\n+  struct cgraph_node **stack;\n+  int stack_size;\n+  struct cgraph_node **result;\n+  int order_pos;\n+  splay_tree nodes_marked_new;\n+  bool reduce;\n+  int count;\n+};\n+\n+/* This is an implementation of Tarjan's strongly connected region\n+   finder as reprinted in Aho Hopcraft and Ullman's The Design and\n+   Analysis of Computer Programs (1975) pages 192-193.  This version\n+   has been customized for cgraph_nodes.  The env parameter is because\n+   it is recursive and there are no nested functions here.  This\n+   function should only be called from itself or\n+   cgraph_reduced_inorder.  ENV is a stack env and would be\n+   unnecessary if C had nested functions.  V is the node to start\n+   searching from.  */\n+\n+static void\n+searchc (struct searchc_env* env, struct cgraph_node *v) \n+{\n+  struct cgraph_edge *edge;\n+  struct ipa_dfs_info *v_info = v->aux;\n+  \n+  /* mark node as old */\n+  v_info->new = false;\n+  splay_tree_remove (env->nodes_marked_new, v->uid);\n+  \n+  v_info->dfn_number = env->count;\n+  v_info->low_link = env->count;\n+  env->count++;\n+  env->stack[(env->stack_size)++] = v;\n+  v_info->on_stack = true;\n+  \n+  for (edge = v->callees; edge; edge = edge->next_callee)\n+    {\n+      struct ipa_dfs_info * w_info;\n+      struct cgraph_node *w = edge->callee;\n+      /* Bypass the clones and only look at the master node.  Skip\n+\t external and other bogus nodes.  */\n+      w = cgraph_master_clone (w);\n+      if (w && w->aux) \n+\t{\n+\t  w_info = w->aux;\n+\t  if (w_info->new) \n+\t    {\n+\t      searchc (env, w);\n+\t      v_info->low_link =\n+\t\t(v_info->low_link < w_info->low_link) ?\n+\t\tv_info->low_link : w_info->low_link;\n+\t    } \n+\t  else \n+\t    if ((w_info->dfn_number < v_info->dfn_number) \n+\t\t&& (w_info->on_stack)) \n+\t      v_info->low_link =\n+\t\t(w_info->dfn_number < v_info->low_link) ?\n+\t\tw_info->dfn_number : v_info->low_link;\n+\t}\n+    }\n+\n+\n+  if (v_info->low_link == v_info->dfn_number) \n+    {\n+      struct cgraph_node *last = NULL;\n+      struct cgraph_node *x;\n+      struct ipa_dfs_info *x_info;\n+      do {\n+\tx = env->stack[--(env->stack_size)];\n+\tx_info = x->aux;\n+\tx_info->on_stack = false;\n+\t\n+\tif (env->reduce) \n+\t  {\n+\t    x_info->next_cycle = last;\n+\t    last = x;\n+\t  } \n+\telse \n+\t  env->result[env->order_pos++] = x;\n+      } \n+      while (v != x);\n+      if (env->reduce) \n+\tenv->result[env->order_pos++] = v;\n+    }\n+}\n+\n+/* Topsort the call graph by caller relation.  Put the result in ORDER.\n+\n+   The REDUCE flag is true if you want the cycles reduced to single\n+   nodes.  Only consider nodes that have the output bit set. */\n+\n+int\n+ipa_utils_reduced_inorder (struct cgraph_node **order, \n+\t\t\t   bool reduce, bool allow_overwritable)\n+{\n+  struct cgraph_node *node;\n+  struct searchc_env env;\n+  splay_tree_node result;\n+  env.stack = xcalloc (cgraph_n_nodes, sizeof (struct cgraph_node *));\n+  env.stack_size = 0;\n+  env.result = order;\n+  env.order_pos = 0;\n+  env.nodes_marked_new = splay_tree_new (splay_tree_compare_ints, 0, 0);\n+  env.count = 1;\n+  env.reduce = reduce;\n+  \n+  for (node = cgraph_nodes; node; node = node->next) \n+    if ((node->analyzed)\n+\t&& (cgraph_is_master_clone (node) \n+\t || (allow_overwritable \n+\t     && (cgraph_function_body_availability (node) == \n+\t\t AVAIL_OVERWRITABLE))))\n+      {\n+\t/* Reuse the info if it is already there.  */\n+\tstruct ipa_dfs_info *info = node->aux;\n+\tif (!info)\n+\t  info = xcalloc (1, sizeof (struct ipa_dfs_info));\n+\tinfo->new = true;\n+\tinfo->on_stack = false;\n+\tinfo->next_cycle = NULL;\n+\tnode->aux = info;\n+\t\n+\tsplay_tree_insert (env.nodes_marked_new,\n+\t\t\t   (splay_tree_key)node->uid, \n+\t\t\t   (splay_tree_value)node);\n+      } \n+    else \n+      node->aux = NULL;\n+  result = splay_tree_min (env.nodes_marked_new);\n+  while (result)\n+    {\n+      node = (struct cgraph_node *)result->value;\n+      searchc (&env, node);\n+      result = splay_tree_min (env.nodes_marked_new);\n+    }\n+  splay_tree_delete (env.nodes_marked_new);\n+  free (env.stack);\n+\n+  return env.order_pos;\n+}\n+\n+\n+/* Given a memory reference T, will return the variable at the bottom\n+   of the access.  Unlike get_base_address, this will recurse thru\n+   INDIRECT_REFS.  */\n+\n+tree\n+get_base_var (tree t)\n+{\n+  if ((TREE_CODE (t) == EXC_PTR_EXPR) || (TREE_CODE (t) == FILTER_EXPR))\n+    return t;\n+\n+  while (!SSA_VAR_P (t) \n+\t && (!CONSTANT_CLASS_P (t))\n+\t && TREE_CODE (t) != LABEL_DECL\n+\t && TREE_CODE (t) != FUNCTION_DECL\n+\t && TREE_CODE (t) != CONST_DECL)\n+    {\n+      t = TREE_OPERAND (t, 0);\n+    }\n+  return t;\n+} \n+"}, {"sha": "e3b31fb6101fe5978e633eb66042648259d8bf26", "filename": "gcc/ipa-utils.h", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-utils.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fipa-utils.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-utils.h?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,49 @@\n+/* Utilities for ipa analysis.\n+   Copyright (C) 2004-2005 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#ifndef GCC_IPA_UTILS_H\n+#define GCC_IPA_UTILS_H\n+#include \"tree.h\"\n+#include \"cgraph.h\"\n+\n+/* Used for parsing attributes of asm code.  */\n+extern tree memory_identifier_string;\n+\n+struct ipa_dfs_info {\n+  int dfn_number;\n+  int low_link;\n+  bool new;\n+  bool on_stack;\n+  struct cgraph_node* next_cycle;\n+  PTR aux;\n+};\n+\n+\n+\n+/* In ipa-utils.c  */\n+void ipa_utils_print_order (FILE*, const char *, struct cgraph_node**, int);\n+int ipa_utils_reduced_inorder (struct cgraph_node **, bool, bool);\n+tree get_base_var (tree);\n+\n+ \n+#endif  /* GCC_IPA_UTILS_H  */\n+\n+"}, {"sha": "b7948f63e923a6073476e46afa237f7aa62383d3", "filename": "gcc/opts.c", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fopts.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -523,6 +523,8 @@ decode_options (unsigned int argc, const char **argv)\n       flag_loop_optimize = 1;\n       flag_if_conversion = 1;\n       flag_if_conversion2 = 1;\n+      flag_ipa_pure_const = 1;\n+      flag_ipa_reference = 1;\n       flag_tree_ccp = 1;\n       flag_tree_dce = 1;\n       flag_tree_dom = 1;\n@@ -556,6 +558,7 @@ decode_options (unsigned int argc, const char **argv)\n       flag_cse_skip_blocks = 1;\n       flag_gcse = 1;\n       flag_expensive_optimizations = 1;\n+      flag_ipa_type_escape = 1;\n       flag_strength_reduce = 1;\n       flag_rerun_cse_after_loop = 1;\n       flag_rerun_loop_opt = 1;\n@@ -583,6 +586,7 @@ decode_options (unsigned int argc, const char **argv)\n \n   if (optimize >= 3)\n     {\n+      flag_tree_promote_statics = 1;\n       flag_inline_functions = 1;\n       flag_unswitch_loops = 1;\n       flag_gcse_after_reload = 1;"}, {"sha": "41617232fbb9a75c939239de0ac9b6f9aa27428e", "filename": "gcc/passes.c", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fpasses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Fpasses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -431,6 +431,9 @@ init_optimization_passes (void)\n   NEXT_PASS (pass_early_ipa_inline);\n   NEXT_PASS (pass_early_local_passes);\n   NEXT_PASS (pass_ipa_inline);\n+  NEXT_PASS (pass_ipa_reference);\n+  NEXT_PASS (pass_ipa_pure_const); \n+  NEXT_PASS (pass_ipa_type_escape);\n   *p = NULL;\n \n   /* All passes needed to lower the function into shape optimizers can operate\n@@ -469,6 +472,7 @@ init_optimization_passes (void)\n \n   p = &pass_all_optimizations.sub;\n   NEXT_PASS (pass_referenced_vars);\n+  NEXT_PASS (pass_promote_statics); \n   NEXT_PASS (pass_create_structure_vars);\n   NEXT_PASS (pass_build_ssa);\n   NEXT_PASS (pass_may_alias);"}, {"sha": "34fb26697d3d0a9039effa73e16cb50ab9742577", "filename": "gcc/testsuite/gcc.dg/tree-ssa/20030714-1.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20030714-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20030714-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2F20030714-1.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -34,13 +34,13 @@ find_base_value (src)\n }\n \n \n-/* There should be six IF conditionals.  */\n-/* { dg-final { scan-tree-dump-times \"if \" 6 \"dom3\"} } */\n+/* There should be four IF conditionals.  */\n+/* { dg-final { scan-tree-dump-times \"if \" 4 \"dom3\"} } */\n \n /* There should be no casts to short unsigned int.  */\n /* { dg-final { scan-tree-dump-times \"\\\\(short unsigned int\\\\)\" 0 \"dom3\"} } */\n \n-/* There should be three loads of ->code.  */\n-/* { dg-final { scan-tree-dump-times \"->code\" 3 \"dom3\"} } */\n+/* There should be two loads of ->code.  */\n+/* { dg-final { scan-tree-dump-times \"->code\" 2 \"dom3\"} } */\n \n /* { dg-final { cleanup-tree-dump \"dom3\" } } */"}, {"sha": "82f03c264dd591070b22fdebe60eb1e22f125c79", "filename": "gcc/testsuite/gcc.dg/tree-ssa/sra-2.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fsra-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fsra-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fsra-2.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */ \n-/* { dg-options \"-O1 -fdump-tree-optimized\" } */\n+/* { dg-options \"-O3 -fdump-tree-optimized\" } */\n \n /* Test for SRA. */\n \n@@ -22,5 +22,5 @@ copystruct11 (teststruct *param)\n \n \n /* There should be no reference to link_error. */\n-/* { dg-final { scan-tree-dump-times \"link_error\" 0 \"optimized\" { xfail *-*-* } } } */\n+/* { dg-final { scan-tree-dump-times \"link_error\" 0 \"optimized\" } } */\n /* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "81a11a97bdacb5817e2408d08febb15696d36503", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-dce-2.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-dce-2.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O1 -fdump-tree-dce3\" } */\n+/* { dg-options \"-O2 -fdump-tree-dce3\" } */\n \n /* We should notice constantness of this function. */\n int t(int a) "}, {"sha": "a2c57407ed1fb798df353b16dbfc35cebc521ccf", "filename": "gcc/testsuite/gcc.dg/vect/vect-92.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-92.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-92.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-92.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -80,7 +80,7 @@ int main (void)\n \n   main1 (a,b,c);\n   main2 (a,b,c);\n-  main3 (a,b,c,N);\n+  main3 (a,b,c,N-1);\n \n   return 0;\n }"}, {"sha": "66574f5b6abbf81f9ef2852a1accac033c7a3515", "filename": "gcc/timevar.def", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftimevar.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftimevar.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftimevar.def?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -42,6 +42,9 @@ DEFTIMEVAR (TV_DUMP                  , \"dump files\")\n \n DEFTIMEVAR (TV_CGRAPH                , \"callgraph construction\")\n DEFTIMEVAR (TV_CGRAPHOPT             , \"callgraph optimization\")\n+DEFTIMEVAR (TV_IPA_REFERENCE         , \"ipa reference\")\n+DEFTIMEVAR (TV_IPA_PURE_CONST        , \"ipa pure const\")\n+DEFTIMEVAR (TV_IPA_TYPE_ESCAPE       , \"ipa type escape\")\n /* Time spent by constructing CFG.  */\n DEFTIMEVAR (TV_CFG                   , \"cfg construction\")\n /* Time spent by cleaning up CFG.  */\n@@ -66,6 +69,7 @@ DEFTIMEVAR (TV_TREE_GIMPLIFY\t     , \"tree gimplify\")\n DEFTIMEVAR (TV_TREE_EH\t\t     , \"tree eh\")\n DEFTIMEVAR (TV_TREE_CFG\t\t     , \"tree CFG construction\")\n DEFTIMEVAR (TV_TREE_CLEANUP_CFG\t     , \"tree CFG cleanup\")\n+DEFTIMEVAR (TV_TREE_PROMOTE_STATICS  , \"tree promote statics\")\n DEFTIMEVAR (TV_TREE_VRP              , \"tree VRP\")\n DEFTIMEVAR (TV_TREE_COPY_PROP        , \"tree copy propagation\")\n DEFTIMEVAR (TV_TREE_STORE_COPY_PROP  , \"tree store copy prop\")"}, {"sha": "b9fecfbb8904e054790a07eee005f43140119c30", "filename": "gcc/tree-dfa.c", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-dfa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-dfa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dfa.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -565,6 +565,20 @@ find_vars_r (tree *tp, int *walk_subtrees, void *data)\n }\n \n \n+/* Lookup UID in the referenced_vars hashtable and return the associated\n+   variable or NULL if it is not there.  */\n+\n+tree \n+referenced_var_lookup_if_exists (unsigned int uid)\n+{\n+  struct int_tree_map *h, in;\n+  in.uid = uid;\n+  h = htab_find_with_hash (referenced_vars, &in, uid);\n+  if (h)\n+    return h->to;\n+  return NULL_TREE;\n+}\n+\n /* Lookup UID in the referenced_vars hashtable and return the associated\n    variable.  */\n "}, {"sha": "2bf40df5fa31675380255fac2e544ffee89e7af1", "filename": "gcc/tree-flow.h", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-flow.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-flow.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow.h?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -29,6 +29,7 @@ Boston, MA 02110-1301, USA.  */\n #include \"tree-gimple.h\"\n #include \"tree-ssa-operands.h\"\n #include \"cgraph.h\"\n+#include \"ipa-reference.h\"\n \n /* Forward declare structures for the garbage collector GTY markers.  */\n #ifndef GCC_BASIC_BLOCK_H\n@@ -239,6 +240,11 @@ struct var_ann_d GTY(())\n      current version of this variable (an SSA_NAME).  */\n   tree current_def;\n   \n+  /* Pointer to the structure that contains the sets of global\n+     variables modified by function calls.  This field is only used\n+     for FUNCTION_DECLs.  */\n+  ipa_reference_vars_info_t GTY ((skip)) reference_vars_info;\n+\n   /* If this variable is a structure, this fields holds a list of\n      symbols representing each of the fields of the structure.  */\n   subvar_t subvars;\n@@ -392,6 +398,7 @@ typedef struct\n extern GTY((param_is (struct int_tree_map))) htab_t referenced_vars;\n \n extern tree referenced_var_lookup (unsigned int);\n+extern tree referenced_var_lookup_if_exists (unsigned int);\n #define num_referenced_vars htab_elements (referenced_vars)\n #define referenced_var(i) referenced_var_lookup (i)\n \n@@ -772,6 +779,10 @@ bool is_hidden_global_store (tree);\n \n /* In tree-sra.c  */\n void insert_edge_copies (tree, basic_block);\n+void sra_insert_before (block_stmt_iterator *, tree);\n+void sra_insert_after (block_stmt_iterator *, tree);\n+void sra_init_cache (void);\n+bool sra_type_can_be_decomposed_p (tree);\n \n /* In tree-loop-linear.c  */\n extern void linear_transform_loops (struct loops *);"}, {"sha": "db9a8a5af88af0cb5ce4aa724db9d49772ae1881", "filename": "gcc/tree-pass.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-pass.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-pass.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pass.h?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -278,13 +278,17 @@ extern struct tree_opt_pass pass_store_copy_prop;\n extern struct tree_opt_pass pass_vrp;\n extern struct tree_opt_pass pass_create_structure_vars;\n extern struct tree_opt_pass pass_uncprop;\n+extern struct tree_opt_pass pass_promote_statics;\n extern struct tree_opt_pass pass_return_slot;\n extern struct tree_opt_pass pass_reassoc;\n extern struct tree_opt_pass pass_rebuild_cgraph_edges;\n \n /* IPA Passes */\n extern struct tree_opt_pass pass_ipa_inline;\n extern struct tree_opt_pass pass_early_ipa_inline;\n+extern struct tree_opt_pass pass_ipa_reference;\n+extern struct tree_opt_pass pass_ipa_pure_const;\n+extern struct tree_opt_pass pass_ipa_type_escape;\n extern struct tree_opt_pass pass_early_local_passes;\n \n extern struct tree_opt_pass pass_all_optimizations;"}, {"sha": "521bdf52689707eb8e1964e8e7a3aa93f662bbe3", "filename": "gcc/tree-promote-statics.c", "status": "added", "additions": 597, "deletions": 0, "changes": 597, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-promote-statics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-promote-statics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-promote-statics.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -0,0 +1,597 @@\n+/* Promotion of static variables to ssa registers\n+   Copyright (C) 2004-2005 Free Software Foundation, Inc.\n+   Contributed by Kenneth Zadeck <zadeck@naturalbridge.com>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"tree.h\"\n+#include \"basic-block.h\"\n+#include \"tree-flow.h\"\n+#include \"ipa-utils.h\"\n+#include \"ipa-reference.h\"\n+#include \"bitmap.h\"\n+#include \"tree-pass.h\"\n+#include \"flags.h\"\n+#include \"timevar.h\"\n+#include \"langhooks.h\"\n+\n+/*\n+The main idea is to promote some static variables from memory to SSA\n+registers.  This transformation is only applied to those static\n+variables for which the effects of subroutine calls can be understood.\n+Such infomation is provided by functions in cgraphunit.c.\n+\n+The following table shows the actions that are taken to promote\n+variables.  The analysis in cgraphunit constructs information about\n+both local usage and the effect of any particular call.  Variables are\n+broken into 4 categories: only-read, only-write, read-write, and no\n+information.  (No information variables are never promoted.)  \n+\n+All information is of the \"may\" variety: if a function is marked read,\n+it means the call may read the variable, but it also may not read the\n+variable.\n+\n+There are two possible ways to perform the promotion: assume that the\n+static is live everywhere or compute the minimal live range for the\n+static variable.\n+\n+The minimal live range path has a lot of problems:\n+\n+1) live variables and upwards exposed uses must be first comuputed.\n+2) new machiney must be invented to prevent code motion algorithms\n+from floating a use of the surrogate register across a register\n+function call that clobbers the variable, but was not in any minimal\n+live range at the time of this analysis.\n+\n+While the first problem is simply a lot of code, the second problem\n+requires a new mechanism for pinning code and teaching all passes that\n+can move code to obey this new fenceposts.  \n+\n+The maximum live range path has the problem that this technique can\n+create many false live ranges where the register is loaded after on\n+call only to be stored back right before the next call.  This will eat\n+a certain amount of space and requires special smarts to get rid of them.\n+\n+There are really 7 situations to cover in the following table.  \n+\n+action             read                    write                   read-write\n+\n+             -+---------------------------------------------------------------\n+\n+entry         |  load                    load                    load\n+              |\n+load          |  getfromreg              xxxxx                   getfromreg\n+              |\n+store         |  xxxx                    puttoreg                puttoreg\n+              |\n+call-read     |  noaction                store before            store before\n+              |\n+call-write    |  load after              store before            store before\n+              |                          load after              load after  \n+call-readwrite|  load after              store before            store before\n+              |                          load after              load after  \n+              |\n+return        |  no action               store                   store         \n+\n+\n+l-r\tl-w\tc-r\tc-w\tstore-b\tload-a\n+\n+0\t0\t0\t0   |\t0\t0\n+0\t0\t0\t1   |\t0\t0\n+0\t0       1      \t0   |\t0\t0\n+0\t0\t1\t1   |\t0\t0\n+0\t1\t0\t0   |\t0\t0\n+0\t1\t0\t1   |\t1\t1\t \n+0\t1       1      \t0   |\t1\t0\n+0\t1\t1\t1   |\t1\t1\n+1\t0\t0\t0   |\t0\t0\n+1\t0\t0\t1   |   0       1\n+1\t0       1      \t0   |\t0\t0\t\n+1\t0\t1\t1   |\t0\t1\n+1\t1\t0\t0   |\t0\t0\n+1\t1\t0\t1   |\t1\t1\n+1\t1       1      \t0   |\t1\t0\n+1\t1\t1\t1   |\t1\t1\n+\n+store_before = local_written & (callee_read | callee_written)\n+load_after = (local_read | local_written) & callee_written\n+*/\n+\n+static bitmap_obstack promote_obstack;\n+\n+/* All of the static variables under consideration by this pass that\n+   do reads or writes withing this function.   */\n+static bitmap local_read;\n+static bitmap local_written;\n+static bitmap local_all;\n+\n+/* Return true if the asm STMT clobbers memory.  */\n+\n+static bool\n+asm_clobbers_mem (tree stmt)\n+{\n+  tree link;\n+  for (link = ASM_CLOBBERS (stmt); link; link = TREE_CHAIN (link))\n+    if (simple_cst_equal(TREE_VALUE (link), memory_identifier_string) == 1) \n+      return true;\n+\n+  return false;\n+}\n+\n+/* Return a INPUT_BITMAP for the asm inputs and OUTPUT_BITMAP for the\n+   asm outputs of variables written by the asm STMT.  */\n+\n+static void\n+get_asm_read_and_write (bitmap input_bitmap, bitmap output_bitmap, tree stmt) \n+{\n+  int noutputs = list_length (ASM_OUTPUTS (stmt));\n+  const char **oconstraints\n+    = (const char **) alloca ((noutputs) * sizeof (const char *));\n+  int i;\n+  tree link;\n+  const char *constraint;\n+  bool allows_mem, allows_reg, is_inout;\n+\n+  for (i=0, link = ASM_OUTPUTS (stmt); link; ++i, link = TREE_CHAIN (link))\n+    {\n+      oconstraints[i] = constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_output_constraint (&constraint, i, 0, 0,\n+\t  &allows_mem, &allows_reg, &is_inout);\n+\n+      /* The variable is only added to the bitmap if there is an aux\n+\t field, ie.this is a variable we care about.  */\n+      if (!allows_reg && allows_mem)\n+\t{\n+\t  tree var = TREE_VALUE (link);\n+\t  var = get_base_address (var);\n+\t  if (TREE_CODE (var) == VAR_DECL)\n+\t    {\n+\t      var_ann_t va = var_ann (var);\n+\t      if (va && va->common.aux) \n+\t\tbitmap_set_bit(output_bitmap, DECL_UID (var));\n+\t    }\n+\t}\n+    }\n+\n+  for (link = ASM_INPUTS (stmt); link; link = TREE_CHAIN (link))\n+    {\n+      constraint\n+\t= TREE_STRING_POINTER (TREE_VALUE (TREE_PURPOSE (link)));\n+      parse_input_constraint (&constraint, 0, 0, noutputs, 0,\n+\t\t\t      oconstraints, &allows_mem, &allows_reg);\n+      \n+      /* The variable is only added to the bitmap if there is an aux\n+\t field, ie.this is a variable we care about.  */\n+      if (!allows_reg && allows_mem)\n+\t{\n+\t  tree var = TREE_VALUE (link);\n+\t  var = get_base_address (var);\n+\t  if (TREE_CODE (var) == VAR_DECL)\n+\t    {\n+\t      var_ann_t va = var_ann (var);\n+\t      if (va && va->common.aux) \n+\t\tbitmap_set_bit(input_bitmap, DECL_UID (var));\n+\t    }\n+\t}\n+    }\n+}\n+\n+/* Generate a series of loads from the static variables pointed to by\n+   B1 && B2 or just B1 (if B2 is NULL) and insert them after\n+   BSI).  */\n+\n+static void\n+gen_loads (bitmap b1, bitmap b2, block_stmt_iterator *bsi) \n+{\n+  bitmap result;\n+  bitmap_iterator bi;\n+  unsigned int index;\n+  tree list = NULL;\n+\n+  if (b2) \n+    {\n+      result = BITMAP_ALLOC (&promote_obstack);\n+      bitmap_and (result, b1, b2);\n+    }\n+  else \n+    result = b1;\n+\n+  EXECUTE_IF_SET_IN_BITMAP(result, 0, index, bi) \n+      {\n+\ttree src = referenced_var (index);\n+\ttree dest = (tree) (var_ann (src)->common.aux);\n+\ttree stmt = build (MODIFY_EXPR, TREE_TYPE (src), dest, src);\n+\tappend_to_statement_list (stmt, &list);\n+      }\n+\n+  if (list)\n+    sra_insert_after (bsi, list);\n+\t\t\t   \n+  if (b2)\n+    BITMAP_FREE (result);\n+}\n+\n+/* Generate a series of stores to the static variables pointed to by\n+   B1 && B2 or just B1 (if B2 is NULL) and insert them before\n+   BSI).  */\n+\n+static void\n+gen_stores (bitmap b1, bitmap b2, block_stmt_iterator *bsi) \n+{\n+  bitmap result;\n+  bitmap_iterator bi;\n+  unsigned int index;\n+  tree list = NULL;\n+\n+  if (b2) \n+    {\n+      result = BITMAP_ALLOC (&promote_obstack);\n+      bitmap_and (result, b1, b2);\n+    }\n+  else \n+    result = b1;\n+\n+  EXECUTE_IF_SET_IN_BITMAP(result, 0, index, bi) \n+      {\n+\ttree dest = referenced_var (index);\n+\ttree src = (tree) (var_ann (dest)->common.aux);\n+\ttree stmt = build (MODIFY_EXPR, TREE_TYPE (src), dest, src);\n+\tappend_to_statement_list (stmt, &list);\n+      }\n+\n+  if (list)\n+    sra_insert_before (bsi, list);\n+\t\t\t   \n+  if (b2)\n+    BITMAP_FREE (result);\n+}\n+\n+/* Replace the static references if it exists in the TPTR.  */\n+\n+static void \n+try_replace_operand(tree * tptr)\n+{\n+  tree t = *tptr;\n+  if (TREE_CODE (t) == VAR_DECL)\n+    {\n+      var_ann_t va = var_ann (t);\n+      tree replacement = (tree) (va->common.aux);\n+      if (replacement)\n+\t*tptr = replacement;\n+    }\n+}\n+\n+/* Walk an expression TPTR replacing all of the static references.  */\n+\n+static void\n+try_replace (tree *tptr) \n+{\n+  tree t = *tptr;\n+  if ((TREE_CODE (t) == EXC_PTR_EXPR) || (TREE_CODE (t) == FILTER_EXPR))\n+    return;\n+\n+  /* The INTEGER_CST is because some people use cute things like &0->a\n+     for offsetof.  */\n+  while (t && !SSA_VAR_P (t) \n+\t && (!CONSTANT_CLASS_P (t)) \n+\t && TREE_CODE (t) != LABEL_DECL\n+\t && TREE_CODE (t) != CONST_DECL\n+\t && TREE_CODE (t) != FUNCTION_DECL\n+         && TREE_CODE (t) != EXC_PTR_EXPR)\n+    {\n+      if (TREE_CODE (t) == ARRAY_REF)\n+\ttry_replace_operand (&TREE_OPERAND (t, 1));\n+\n+      tptr = &TREE_OPERAND (t, 0);\n+      t = *tptr;\n+    }\n+  if (t)\n+    try_replace_operand (tptr);\n+}\n+\n+/* Repalce the static references that exist in a constructor.  */\n+\n+static void\n+try_replace_constructor (tree ctor)\n+{\n+  tree t;\n+  for (t = TREE_OPERAND (ctor, 0); t; t = TREE_CHAIN (t))\n+    {\n+      try_replace (&TREE_VALUE (t));\n+    }\n+}\n+\n+/* Replace all the static references in the operand list of\n+   CALL_EXPR.  */\n+\n+static void\n+try_replace_call_operands (tree call_expr) \n+{\n+  tree operandList = TREE_OPERAND (call_expr, 1);\n+  tree operand;\n+\n+  for (operand = operandList;\n+       operand != NULL_TREE;\n+       operand = TREE_CHAIN (operand))\n+ \n+    if (TREE_CODE(TREE_VALUE (operand)) != FUNCTION_DECL)\n+      try_replace (&TREE_VALUE (operand));\n+}\n+\n+/* Generate loads and stores and replace all the static references in\n+   function FN using statement iterator SI. This form is used when\n+   there is not info available about the caller.  */\n+\n+static void \n+gen_dumb_call (tree fn, block_stmt_iterator si) \n+{\n+  gen_stores (local_written, NULL, &si);\n+  try_replace (&TREE_OPERAND (fn, 0));\n+  try_replace_call_operands (fn);\n+  gen_loads (local_all, NULL, &si);\n+}\n+\n+\n+/* Generate loads and stores and replace all the static references in\n+   function FN using statement iterator SI.  */\n+\n+static void \n+try_replace_call (tree fn, block_stmt_iterator si)\n+{\n+  /* Store intersection of call_read and local_written\n+     registers back to memory before calling.  */\n+  /* int call_flags = call_expr_flags (fn); */\n+  tree callee = get_callee_fndecl (fn);\n+  if (callee) \n+    {\n+      bitmap callee_all = BITMAP_ALLOC (&promote_obstack);\n+      bitmap callee_written = ipa_reference_get_written_global (callee);\n+      if (callee_written) \n+\t{\n+\t  bitmap_ior (callee_all, \n+\t\t      ipa_reference_get_read_global (callee), \n+\t\t      callee_written);\n+\t  \n+\t  gen_stores (local_written, callee_all, &si);\n+\t  \n+\t  if (TREE_CODE (callee) != FUNCTION_DECL)\n+\t    try_replace (&TREE_OPERAND (fn, 0));\n+\t  try_replace_call_operands (fn);\n+\t  \n+\t  /* This is a hack required because the call_flags are set on a\n+\t     function by function basis during compilation.  Thus these\n+\t     flags are only set if the callee has already been compiled.  */\n+\t  /* if (!(call_flags & (ECF_PURE | ECF_CONST | ECF_NORETURN))) */\n+\t  gen_loads (local_all, callee_written, &si);\n+\t  BITMAP_FREE (callee_all);\n+\t}\n+      else \n+\tgen_dumb_call (fn, si);\n+    }\n+  else\n+    gen_dumb_call (fn, si);\n+}\n+\n+\n+/* Walk the entire function looking uses or stores to global variables\n+   and changing them to use ssa shadow registers.  */ \n+\n+static void\n+walk_function (void)\n+{\n+  basic_block bb;\n+  block_stmt_iterator si, ni;\n+\n+  FOR_EACH_BB (bb)\n+    for (si = bsi_start (bb); !bsi_end_p (si); si = ni)\n+      {\n+\ttree stmt = bsi_stmt (si);\n+\n+\tni = si;\n+\tbsi_next (&ni);\n+\n+\tswitch (TREE_CODE (stmt))\n+\t  {\n+\t  case RETURN_EXPR:\n+\t    /* Store all of the local_written registers back to memory\n+\t       before returning. */\n+\t    gen_stores (local_written, NULL, &si);\n+\t    break;\n+\n+\t  case MODIFY_EXPR:\n+\t    /* Change load of static to use of reg.  Change store of\n+\t       static to store of reg.  */\n+\t    {\n+\t      tree rhs = TREE_OPERAND (stmt, 1);\n+\t      tree *rhsp = &TREE_OPERAND (stmt, 1);\n+\t      tree *lhsp = &TREE_OPERAND (stmt, 0);\n+\n+\t      /* If we have a call on the rhs, try to replace the arguments.\n+\t\t Otherwise, try to replace the operand on the LHS and the operand on\n+\t\t the RHS.  */\n+\t      if (TREE_CODE (rhs) == CALL_EXPR)\n+\t\ttry_replace_call (rhs, si);\n+\t      else if (TREE_CODE (rhs) == CONSTRUCTOR)\n+\t\ttry_replace_constructor (rhs);\n+\t      else\n+\t\ttry_replace (rhsp);\n+\t      try_replace (lhsp);\n+\t    }\n+\t    break;\n+\t  case CALL_EXPR:\n+\t    try_replace_call (stmt, si);\n+   \n+\t    break;\n+\t  case ASM_EXPR:\n+\t    /* If the asm clobbers memory, just store everything and\n+\t       load it back.  */\n+\t    if (asm_clobbers_mem (stmt)) \n+\t      { \n+\t\tgen_stores (local_written, NULL, &si);\n+\t\tgen_loads (local_all, NULL, &si);\n+\t      }\n+\t    else \n+\t      {\n+\t\tbitmap store_bitmap = BITMAP_ALLOC (&promote_obstack);\n+\t\tbitmap load_bitmap = BITMAP_ALLOC (&promote_obstack);\n+\t\tbitmap all_bitmap = BITMAP_ALLOC (&promote_obstack);\n+\t\t/* The asm read generates a stores before, and the asm\n+\t\t   write generates loads after.  */\n+\t\tget_asm_read_and_write (store_bitmap, load_bitmap, stmt);\n+\t\tbitmap_ior (all_bitmap, store_bitmap, load_bitmap);\n+\t\t\n+\t\tgen_stores (local_written, all_bitmap , &si);\n+\t\tgen_loads (local_all, load_bitmap, &si);\n+\t\t\n+\t\tBITMAP_FREE (store_bitmap);\n+\t\tBITMAP_FREE (load_bitmap);\n+\t\tBITMAP_FREE (all_bitmap);\n+\t      } \n+\t    break;\n+\t    \n+\t  default:\n+\t    break;\n+\t  }\n+      }\n+}\n+\n+/* Main entry point for the promotion of statics to ssa regsisters. */\n+\n+static void\n+execute_promote_statics (void)\n+{\n+  unsigned int index;\n+  bitmap_iterator bi;\n+  bitmap tb = ipa_reference_get_read_local (current_function_decl);\n+\n+\n+  /* There are some options that cause this pass to run even if file\n+     at a time is not set.  */\n+  if (!tb)\n+    return;\n+\n+  bitmap_obstack_initialize (&promote_obstack);\n+  sra_init_cache ();\n+\n+  local_read = BITMAP_ALLOC (&promote_obstack);\n+  bitmap_copy (local_read, tb);\n+  tb = ipa_reference_get_written_local (current_function_decl);\n+  local_written = BITMAP_ALLOC (&promote_obstack);\n+  bitmap_copy (local_written, tb);\n+\n+  local_all = BITMAP_ALLOC (&promote_obstack);\n+  tb = BITMAP_ALLOC (&promote_obstack);\n+  bitmap_ior (local_all, local_read, local_written);\n+\n+  if (dump_file)\n+    fprintf (dump_file, \"promoting in %s\\n\", \n+\t     lang_hooks.decl_printable_name (current_function_decl, 2)); \n+\n+  EXECUTE_IF_SET_IN_BITMAP (local_all, 0, index, bi) \n+    {\n+      tree svar = referenced_var_lookup_if_exists (index);\n+      if (svar)\n+\t{\n+\t  tree type = TREE_TYPE (svar);\n+\t  /* We only promote variables that are either scalars or if\n+\t     they are aggregrates, they must be a type that sra is\n+\t     willing to scalarize.  Otherwise there is no reason to\n+\t     promote it a register.  \n+\t     \n+\t     We also do not promote anything that is marked READONLY\n+\t     since there is little gain.  The optimizations should\n+\t     generally be able to look thru the operations and find the\n+\t     constants.  */\n+\t  if ((!TREE_READONLY(svar)) \n+\t      && (TREE_CODE (type) != ARRAY_TYPE)\n+\t      && ((!AGGREGATE_TYPE_P (type))\n+\t\t  || (sra_type_can_be_decomposed_p (type))))\n+\t    {\n+\t      tree tmp = create_tmp_var (type, get_name (svar));\n+\t      add_referenced_tmp_var (tmp);\n+\t      var_ann (svar)->common.aux = tmp;\n+\t      \n+\t      /* Insert loads from all read statics in the entry\n+\t\t block.  */\n+\t      insert_edge_copies (build (MODIFY_EXPR, TREE_TYPE (svar), \n+\t\t\t\t\t tmp, svar), \n+\t\t\t\t  ENTRY_BLOCK_PTR);\n+\t      if (dump_file) \n+\t\tfprintf (dump_file, \"  var=%s, read=%d,write=%d\\n\", \n+\t\t\t get_name (svar), \n+\t\t\t bitmap_bit_p (local_read, index),  \n+\t\t\t bitmap_bit_p (local_written, index)); \n+\t    }\n+\t  else \n+\t    /* There is nothing to be done with this variable.  */ \n+\t    bitmap_set_bit (tb, index);\n+\t}\n+      else\n+\t/* There is nothing to be done with this variable because the\n+\t   reference was optimized out before we got here.  */ \n+\tbitmap_set_bit (tb, index);\n+    }\n+\n+  /* Clear the to be ignored variables from the local maps.  */\n+  bitmap_and_compl_into (local_read, tb);\n+  bitmap_and_compl_into (local_written, tb);\n+  bitmap_and_compl_into (local_all, tb);\n+\n+  walk_function ();\n+  bsi_commit_edge_inserts ();\n+\n+  EXECUTE_IF_SET_IN_BITMAP (local_all, 0, index, bi) \n+    {\n+      tree svar = referenced_var (index);\n+      var_ann (svar)->common.aux = NULL;\n+    }\n+\n+  bitmap_obstack_release (&promote_obstack);\n+}\n+\n+static bool\n+gate_promote_statics (void)\n+{\n+  return flag_unit_at_a_time != 0 \n+    && flag_ipa_reference \n+    && flag_tree_promote_statics;\n+}\n+\n+struct tree_opt_pass pass_promote_statics = \n+{\n+  \"tree-promote-static\",\t\t/* name */\n+  gate_promote_statics,\t\t\t/* gate */\n+  execute_promote_statics,\t\t/* execute */\n+  NULL,\t\t\t\t\t/* sub */\n+  NULL,\t\t\t\t\t/* next */\n+  0,\t\t\t\t\t/* static_pass_number */\n+  TV_TREE_PROMOTE_STATICS,\t\t/* tv_id */\n+  PROP_cfg,                    \t\t/* properties_required */\n+  0,\t\t\t\t\t/* properties_provided */\n+  0,\t\t\t\t\t/* properties_destroyed */\n+  0,\t\t\t\t\t/* todo_flags_start */\n+  TODO_dump_func,\t\t\t/* todo_flags_finish */\n+  0                                     /* letter */\n+};\n+\n+"}, {"sha": "b3494af5c92afc1dc7c9540e00b80405fb70a35e", "filename": "gcc/tree-sra.c", "status": "modified", "additions": 17, "deletions": 8, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-sra.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-sra.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-sra.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -172,8 +172,8 @@ is_sra_scalar_type (tree type)\n    instantiated, just that if we decide to break up the type into\n    separate pieces that it can be done.  */\n \n-static bool\n-type_can_be_decomposed_p (tree type)\n+bool\n+sra_type_can_be_decomposed_p (tree type)\n {\n   unsigned int cache = TYPE_UID (TYPE_MAIN_VARIANT (type)) * 2;\n   tree t;\n@@ -275,7 +275,7 @@ decl_can_be_decomposed_p (tree var)\n     }\n \n   /* We must be able to decompose the variable's type.  */\n-  if (!type_can_be_decomposed_p (TREE_TYPE (var)))\n+  if (!sra_type_can_be_decomposed_p (TREE_TYPE (var)))\n     {\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \t{\n@@ -296,7 +296,7 @@ type_can_instantiate_all_elements (tree type)\n {\n   if (is_sra_scalar_type (type))\n     return true;\n-  if (!type_can_be_decomposed_p (type))\n+  if (!sra_type_can_be_decomposed_p (type))\n     return false;\n \n   switch (TREE_CODE (type))\n@@ -1769,7 +1769,7 @@ insert_edge_copies (tree stmt, basic_block bb)\n \n /* Helper function to insert LIST before BSI, and set up line number info.  */\n \n-static void\n+void\n sra_insert_before (block_stmt_iterator *bsi, tree list)\n {\n   tree stmt = bsi_stmt (*bsi);\n@@ -1781,7 +1781,7 @@ sra_insert_before (block_stmt_iterator *bsi, tree list)\n \n /* Similarly, but insert after BSI.  Handles insertion onto edges as well.  */\n \n-static void\n+void\n sra_insert_after (block_stmt_iterator *bsi, tree list)\n {\n   tree stmt = bsi_stmt (*bsi);\n@@ -2138,6 +2138,16 @@ debug_sra_elt_name (struct sra_elt *elt)\n   fputc ('\\n', stderr);\n }\n \n+void \n+sra_init_cache (void)\n+{\n+  if (sra_type_decomp_cache) \n+    return;\n+\n+  sra_type_decomp_cache = BITMAP_ALLOC (NULL);\n+  sra_type_inst_cache = BITMAP_ALLOC (NULL);\n+}\n+\n /* Main entry point.  */\n \n static void\n@@ -2147,8 +2157,7 @@ tree_sra (void)\n   gcc_obstack_init (&sra_obstack);\n   sra_candidates = BITMAP_ALLOC (NULL);\n   needs_copy_in = BITMAP_ALLOC (NULL);\n-  sra_type_decomp_cache = BITMAP_ALLOC (NULL);\n-  sra_type_inst_cache = BITMAP_ALLOC (NULL);\n+  sra_init_cache ();\n   sra_map = htab_create (101, sra_elt_hash, sra_elt_eq, NULL);\n \n   /* Scan.  If we find anything, instantiate and scalarize.  */"}, {"sha": "387a6961cd5cee176bf70fdb30942009897d5985", "filename": "gcc/tree-ssa-alias.c", "status": "modified", "additions": 73, "deletions": 6, "changes": 79, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-ssa-alias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-ssa-alias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-alias.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -43,6 +43,7 @@ Boston, MA 02110-1301, USA.  */\n #include \"tree-ssa-structalias.h\"\n #include \"convert.h\"\n #include \"params.h\"\n+#include \"ipa-type-escape.h\"\n #include \"vec.h\"\n #include \"bitmap.h\"\n \n@@ -86,6 +87,8 @@ struct alias_stats_d\n   unsigned int simple_resolved;\n   unsigned int tbaa_queries;\n   unsigned int tbaa_resolved;\n+  unsigned int structnoaddress_queries;\n+  unsigned int structnoaddress_resolved;\n };\n \n \n@@ -95,7 +98,7 @@ static struct alias_stats_d alias_stats;\n /* Local functions.  */\n static void compute_flow_insensitive_aliasing (struct alias_info *);\n static void dump_alias_stats (FILE *);\n-static bool may_alias_p (tree, HOST_WIDE_INT, tree, HOST_WIDE_INT);\n+static bool may_alias_p (tree, HOST_WIDE_INT, tree, HOST_WIDE_INT, bool);\n static tree create_memory_tag (tree type, bool is_type_tag);\n static tree get_tmt_for (tree, struct alias_info *);\n static tree get_nmt_for (tree);\n@@ -346,6 +349,7 @@ count_ptr_derefs (tree *tp, int *walk_subtrees ATTRIBUTE_UNUSED, void *data)\n   struct count_ptr_d *count_p = (struct count_ptr_d *) data;\n \n   if (INDIRECT_REF_P (*tp) && TREE_OPERAND (*tp, 0) == count_p->ptr)\n+/*       || (TREE_CODE (*tp) == MEM_REF && MEM_REF_SYMBOL (*tp) == count_p->ptr)) */\n     count_p->count++;\n \n   return NULL_TREE;\n@@ -433,7 +437,6 @@ count_uses_and_derefs (tree ptr, tree stmt, unsigned *num_uses_p,\n   gcc_assert (*num_uses_p >= *num_derefs_p);\n }\n \n-\n /* Initialize the data structures used for alias analysis.  */\n \n static struct alias_info *\n@@ -780,8 +783,8 @@ compute_flow_insensitive_aliasing (struct alias_info *ai)\n \t                 || bitmap_bit_p (ai->written_vars, DECL_UID (var));\n \t  if (!tag_stored_p && !var_stored_p)\n \t    continue;\n-\n-\t  if (may_alias_p (p_map->var, p_map->set, var, v_map->set))\n+\t     \n+\t  if (may_alias_p (p_map->var, p_map->set, var, v_map->set, false))\n \t    {\n \t      subvar_t svars;\n \t      size_t num_tag_refs, num_var_refs;\n@@ -862,7 +865,7 @@ compute_flow_insensitive_aliasing (struct alias_info *ai)\n \t  bitmap may_aliases2 = p_map2->may_aliases;\n \n \t  /* If the pointers may not point to each other, do nothing.  */\n-\t  if (!may_alias_p (p_map1->var, p_map1->set, tag2, p_map2->set))\n+\t  if (!may_alias_p (p_map1->var, p_map1->set, tag2, p_map2->set, true))\n \t    continue;\n \n \t  /* The two pointers may alias each other.  If they already have\n@@ -1453,7 +1456,8 @@ maybe_create_global_var (struct alias_info *ai)\n \n static bool\n may_alias_p (tree ptr, HOST_WIDE_INT mem_alias_set,\n-\t     tree var, HOST_WIDE_INT var_alias_set)\n+\t     tree var, HOST_WIDE_INT var_alias_set,\n+\t     bool alias_set_only)\n {\n   tree mem;\n   var_ann_t m_ann;\n@@ -1520,6 +1524,65 @@ may_alias_p (tree ptr, HOST_WIDE_INT mem_alias_set,\n       alias_stats.tbaa_resolved++;\n       return false;\n     }\n+\n+  /* If var is a record or union type, ptr cannot point into var\n+     unless there is some operation explicit address operation in the\n+     program that can reference a field of the ptr's dereferenced\n+     type.  This also assumes that the types of both var and ptr are\n+     contained within the compilation unit, and that there is no fancy\n+     addressing arithmetic associated with any of the types\n+     involved.  */\n+\n+  if ((mem_alias_set != 0) && (var_alias_set != 0))\n+    {\n+      tree ptr_type = TREE_TYPE (ptr);\n+      tree var_type = TREE_TYPE (var);\n+      \n+      /* The star count is -1 if the type at the end of the pointer_to \n+\t chain is not a record or union type. */ \n+      if ((!alias_set_only) && \n+\t  ipa_type_escape_star_count_of_interesting_type (var_type) >= 0)\n+\t{\n+\t  int ptr_star_count = 0;\n+\t  \n+\t  /* Ipa_type_escape_star_count_of_interesting_type is a little to\n+\t     restrictive for the pointer type, need to allow pointers to\n+\t     primitive types as long as those types cannot be pointers\n+\t     to everything.  */\n+\t  while (POINTER_TYPE_P (ptr_type))\n+\t    /* Strip the *'s off.  */ \n+\t    {\n+\t      ptr_type = TREE_TYPE (ptr_type);\n+\t      ptr_star_count++;\n+\t    }\n+\t  \n+\t  /* There does not appear to be a better test to see if the \n+\t     pointer type was one of the pointer to everything \n+\t     types.  */\n+\t  \n+\t  if (ptr_star_count > 0)\n+\t    {\n+\t      alias_stats.structnoaddress_queries++;\n+\t      if (ipa_type_escape_field_does_not_clobber_p (var_type, \n+\t\t\t\t\t\t\t    TREE_TYPE (ptr))) \n+\t\t{\n+\t\t  alias_stats.structnoaddress_resolved++;\n+\t\t  alias_stats.alias_noalias++;\n+\t\t  return false;\n+\t\t}\n+\t    }\n+\t  else if (ptr_star_count == 0)\n+\t    {\n+\t      /* If ptr_type was not really a pointer to type, it cannot \n+\t\t alias.  */ \n+\t      alias_stats.structnoaddress_queries++;\n+\t      alias_stats.structnoaddress_resolved++;\n+\t      alias_stats.alias_noalias++;\n+\t      return false;\n+\t    }\n+\t}\n+    }\n+\n   alias_stats.alias_mayalias++;\n   return true;\n }\n@@ -1851,6 +1914,10 @@ dump_alias_stats (FILE *file)\n \t   alias_stats.tbaa_queries);\n   fprintf (file, \"Total TBAA resolved:\\t%u\\n\",\n \t   alias_stats.tbaa_resolved);\n+  fprintf (file, \"Total non-addressable structure type queries:\\t%u\\n\",\n+\t   alias_stats.structnoaddress_queries);\n+  fprintf (file, \"Total non-addressable structure type resolved:\\t%u\\n\",\n+\t   alias_stats.structnoaddress_resolved);\n }\n   \n "}, {"sha": "609fa0f947c44796df2135b5b80d13f62014b0de", "filename": "gcc/tree-ssa-operands.c", "status": "modified", "additions": 67, "deletions": 32, "changes": 99, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-ssa-operands.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ea900239f40b40cb0b5174fb15818c862b6bb333/gcc%2Ftree-ssa-operands.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-operands.c?ref=ea900239f40b40cb0b5174fb15818c862b6bb333", "patch": "@@ -33,6 +33,7 @@ Boston, MA 02110-1301, USA.  */\n #include \"timevar.h\"\n #include \"toplev.h\"\n #include \"langhooks.h\"\n+#include \"ipa-reference.h\"\n \n /* This file contains the code required to manage the operands cache of the \n    SSA optimizer.  For every stmt, we maintain an operand cache in the stmt \n@@ -156,7 +157,7 @@ static inline void append_def (tree *);\n static inline void append_use (tree *);\n static void append_v_may_def (tree);\n static void append_v_must_def (tree);\n-static void add_call_clobber_ops (tree);\n+static void add_call_clobber_ops (tree, tree);\n static void add_call_read_ops (tree);\n static void add_stmt_operand (tree *, stmt_ann_t, int);\n static void build_ssa_operands (tree stmt);\n@@ -1727,7 +1728,7 @@ get_call_expr_operands (tree stmt, tree expr)\n \t there is no point in recording that.  */ \n       if (TREE_SIDE_EFFECTS (expr)\n \t  && !(call_flags & (ECF_PURE | ECF_CONST | ECF_NORETURN)))\n-\tadd_call_clobber_ops (stmt);\n+\tadd_call_clobber_ops (stmt, get_callee_fndecl (expr));\n       else if (!(call_flags & ECF_CONST))\n \tadd_call_read_ops (stmt);\n     }\n@@ -1944,14 +1945,15 @@ add_to_addressable_set (tree ref, bitmap *addresses_taken)\n    clobbered variables in the function.  */\n \n static void\n-add_call_clobber_ops (tree stmt)\n+add_call_clobber_ops (tree stmt, tree callee)\n {\n   int i;\n   unsigned u;\n   tree t;\n   bitmap_iterator bi;\n   stmt_ann_t s_ann = stmt_ann (stmt);\n   struct stmt_ann_d empty_ann;\n+  bitmap not_read_b, not_written_b;\n \n   /* Functions that are not const, pure or never return may clobber\n      call-clobbered variables.  */\n@@ -1966,8 +1968,22 @@ add_call_clobber_ops (tree stmt)\n       return;\n     }\n \n+  /* FIXME - if we have better information from the static vars\n+     analysis, we need to make the cache call site specific.  This way\n+     we can have the performance benefits even if we are doing good\n+     optimization.  */\n+\n+  /* Get info for local and module level statics.  There is a bit\n+     set for each static if the call being processed does not read\n+     or write that variable.  */\n+\n+  not_read_b = callee ? ipa_reference_get_not_read_global (callee) : NULL; \n+  not_written_b = callee ? ipa_reference_get_not_written_global (callee) : NULL; \n+\n   /* If cache is valid, copy the elements into the build vectors.  */\n-  if (ssa_call_clobbered_cache_valid)\n+  if (ssa_call_clobbered_cache_valid\n+      && (!not_read_b || bitmap_empty_p (not_read_b))\n+      && (!not_written_b || bitmap_empty_p (not_written_b)))\n     {\n       /* Process the caches in reverse order so we are always inserting at\n          the head of the list.  */\n@@ -2002,43 +2018,62 @@ add_call_clobber_ops (tree stmt)\n       if (unmodifiable_var_p (var))\n \tadd_stmt_operand (&var, &empty_ann, opf_none);\n       else\n-\tadd_stmt_operand (&var, &empty_ann, opf_is_def | opf_non_specific);\n+\t{\n+\t  bool not_read\n+\t    = not_read_b ? bitmap_bit_p (not_read_b, u) : false;\n+\t  bool not_written\n+\t    = not_written_b ? bitmap_bit_p (not_written_b, u) : false;\n+\n+\t  if ((TREE_READONLY (var)\n+\t       && (TREE_STATIC (var) || DECL_EXTERNAL (var)))\n+\t      || not_written)\n+\t    {\n+\t      if (!not_read)\n+\t\tadd_stmt_operand (&var, &empty_ann, opf_none);\n+\t    }\n+\t  else\n+\t    add_stmt_operand (&var, &empty_ann, opf_is_def);\n+\t}\n     }\n \n-  clobbered_aliased_loads = empty_ann.makes_aliased_loads;\n-  clobbered_aliased_stores = empty_ann.makes_aliased_stores;\n-\n-  /* Set the flags for a stmt's annotation.  */\n-  if (s_ann)\n+  if ((!not_read_b || bitmap_empty_p (not_read_b))\n+      && (!not_written_b || bitmap_empty_p (not_written_b)))\n     {\n-      s_ann->makes_aliased_loads = empty_ann.makes_aliased_loads;\n-      s_ann->makes_aliased_stores = empty_ann.makes_aliased_stores;\n-    }\n+      clobbered_aliased_loads = empty_ann.makes_aliased_loads;\n+      clobbered_aliased_stores = empty_ann.makes_aliased_stores;\n \n-  /* Prepare empty cache vectors.  */\n-  VEC_truncate (tree, clobbered_vuses, 0);\n-  VEC_truncate (tree, clobbered_v_may_defs, 0);\n+      /* Set the flags for a stmt's annotation.  */\n+      if (s_ann)\n+\t{\n+\t  s_ann->makes_aliased_loads = empty_ann.makes_aliased_loads;\n+\t  s_ann->makes_aliased_stores = empty_ann.makes_aliased_stores;\n+\t}\n \n-  /* Now fill the clobbered cache with the values that have been found.  */\n-  for (i = opbuild_first (&build_vuses);\n-       i != OPBUILD_LAST;\n-       i = opbuild_next (&build_vuses, i))\n-    VEC_safe_push (tree, heap, clobbered_vuses,\n-\t\t   opbuild_elem_virtual (&build_vuses, i));\n+      /* Prepare empty cache vectors.  */\n+      VEC_truncate (tree, clobbered_vuses, 0);\n+      VEC_truncate (tree, clobbered_v_may_defs, 0);\n \n-  gcc_assert (opbuild_num_elems (&build_vuses) \n-\t      == VEC_length (tree, clobbered_vuses));\n+      /* Now fill the clobbered cache with the values that have been found.  */\n+      for (i = opbuild_first (&build_vuses);\n+\t   i != OPBUILD_LAST;\n+\t   i = opbuild_next (&build_vuses, i))\n+\tVEC_safe_push (tree, heap, clobbered_vuses,\n+\t\t       opbuild_elem_virtual (&build_vuses, i));\n \n-  for (i = opbuild_first (&build_v_may_defs);\n-       i != OPBUILD_LAST;\n-       i = opbuild_next (&build_v_may_defs, i))\n-    VEC_safe_push (tree, heap, clobbered_v_may_defs, \n-\t\t   opbuild_elem_virtual (&build_v_may_defs, i));\n+      gcc_assert (opbuild_num_elems (&build_vuses) \n+\t\t  == VEC_length (tree, clobbered_vuses));\n+\n+      for (i = opbuild_first (&build_v_may_defs);\n+\t   i != OPBUILD_LAST;\n+\t   i = opbuild_next (&build_v_may_defs, i))\n+\tVEC_safe_push (tree, heap, clobbered_v_may_defs, \n+\t\t       opbuild_elem_virtual (&build_v_may_defs, i));\n \n-  gcc_assert (opbuild_num_elems (&build_v_may_defs) \n-\t      == VEC_length (tree, clobbered_v_may_defs));\n+      gcc_assert (opbuild_num_elems (&build_v_may_defs) \n+\t\t  == VEC_length (tree, clobbered_v_may_defs));\n \n-  ssa_call_clobbered_cache_valid = true;\n+      ssa_call_clobbered_cache_valid = true;\n+    }\n }\n \n "}]}