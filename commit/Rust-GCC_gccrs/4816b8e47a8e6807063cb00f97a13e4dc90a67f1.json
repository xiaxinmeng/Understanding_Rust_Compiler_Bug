{"sha": "4816b8e47a8e6807063cb00f97a13e4dc90a67f1", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDgxNmI4ZTQ3YThlNjgwNzA2M2NiMDBmOTdhMTNlNGRjOTBhNjdmMQ==", "commit": {"author": {"name": "Nick Clifton", "email": "nickc@redhat.com", "date": "2000-11-12T18:40:22Z"}, "committer": {"name": "Nick Clifton", "email": "nickc@gcc.gnu.org", "date": "2000-11-12T18:40:22Z"}, "message": "Fix comment formating, and adjust sequence of #include headers.\n\nFrom-SVN: r37407", "tree": {"sha": "de0d34fbdeef1a795ab1ccce699f0f263c2c9912", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/de0d34fbdeef1a795ab1ccce699f0f263c2c9912"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4816b8e47a8e6807063cb00f97a13e4dc90a67f1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4816b8e47a8e6807063cb00f97a13e4dc90a67f1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4816b8e47a8e6807063cb00f97a13e4dc90a67f1", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4816b8e47a8e6807063cb00f97a13e4dc90a67f1/comments", "author": {"login": "nickclifton", "id": 31441682, "node_id": "MDQ6VXNlcjMxNDQxNjgy", "avatar_url": "https://avatars.githubusercontent.com/u/31441682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nickclifton", "html_url": "https://github.com/nickclifton", "followers_url": "https://api.github.com/users/nickclifton/followers", "following_url": "https://api.github.com/users/nickclifton/following{/other_user}", "gists_url": "https://api.github.com/users/nickclifton/gists{/gist_id}", "starred_url": "https://api.github.com/users/nickclifton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nickclifton/subscriptions", "organizations_url": "https://api.github.com/users/nickclifton/orgs", "repos_url": "https://api.github.com/users/nickclifton/repos", "events_url": "https://api.github.com/users/nickclifton/events{/privacy}", "received_events_url": "https://api.github.com/users/nickclifton/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "ee7692d2fd4df71a8dde3617c2e1b0497ed82638", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ee7692d2fd4df71a8dde3617c2e1b0497ed82638", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ee7692d2fd4df71a8dde3617c2e1b0497ed82638"}], "stats": {"total": 291, "additions": 171, "deletions": 120}, "files": [{"sha": "9b466b2d8429ac2cc8eadbd53046c97213725eed", "filename": "gcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4816b8e47a8e6807063cb00f97a13e4dc90a67f1/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4816b8e47a8e6807063cb00f97a13e4dc90a67f1/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4816b8e47a8e6807063cb00f97a13e4dc90a67f1", "patch": "@@ -1,4 +1,10 @@\n+2000-11-12  Nick Clifton  <nickc@redhat.com>\n+\n+\t* config/mcore/mcore.c: Fix comment formating, and adjust sequence\n+\tof #include headers.\n+\n 2000-11-12  Marc Espie <espie@openbsd.org>\n+\t\n \t* configure.in: Fix filds test.\n \t* configure: Regen.\n "}, {"sha": "a94bd3d0023cb2723f13723a04769e66381b4c8f", "filename": "gcc/config/mcore/mcore.c", "status": "modified", "additions": 165, "deletions": 120, "changes": 285, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4816b8e47a8e6807063cb00f97a13e4dc90a67f1/gcc%2Fconfig%2Fmcore%2Fmcore.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4816b8e47a8e6807063cb00f97a13e4dc90a67f1/gcc%2Fconfig%2Fmcore%2Fmcore.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fmcore%2Fmcore.c?ref=4816b8e47a8e6807063cb00f97a13e4dc90a67f1", "patch": "@@ -19,19 +19,18 @@ the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.  */\n \n #include \"config.h\"\n #include \"system.h\"\n+#include \"rtl.h\"\n+#include \"tree.h\"\n+#include \"tm_p.h\"\n #include \"assert.h\"\n #include \"gansidecl.h\"\n-\n-#include \"rtl.h\"\n #include \"mcore.h\"\n-\n #include \"regs.h\"\n #include \"hard-reg-set.h\"\n #include \"real.h\"\n #include \"insn-config.h\"\n #include \"conditions.h\"\n #include \"insn-flags.h\"\n-#include \"tree.h\"\n #include \"output.h\"\n #include \"insn-attr.h\"\n #include \"flags.h\"\n@@ -42,7 +41,6 @@ the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.  */\n #include \"function.h\"\n #include \"ggc.h\"\n #include \"toplev.h\"\n-#include \"mcore-protos.h\"\n \n /* Maximum size we are allowed to grow the stack in a single operation.\n    If we want more, we must do it in increments of at most this size.\n@@ -139,7 +137,7 @@ output_stack_adjust (direction, size)\n      int direction;\n      int size;\n {\n-  /* If extending stack a lot, we do it incrementally. */\n+  /* If extending stack a lot, we do it incrementally.  */\n   if (direction < 0 && size > mcore_stack_increment && mcore_stack_increment > 0)\n     {\n       rtx tmp = gen_rtx (REG, SImode, 1);\n@@ -155,8 +153,8 @@ output_stack_adjust (direction, size)\n \t}\n       while (size > mcore_stack_increment);\n \n-      /* 'size' is now the residual for the last adjustment, which doesn't\n-       * require a probe. */\n+      /* SIZE is now the residual for the last adjustment,\n+\t which doesn't require a probe.  */\n     }\n \n   if (size)\n@@ -180,8 +178,9 @@ output_stack_adjust (direction, size)\n     }\n }\n \n-/* Work out the registers which need to be saved, both as a mask and a\n-   count.  */\n+/* Work out the registers which need to be saved,\n+   both as a mask and a count.  */\n+\n static int\n calc_live_regs (count)\n      int * count;\n@@ -204,6 +203,7 @@ calc_live_regs (count)\n }\n \n /* Print the operand address in x to the stream.  */\n+\n void\n mcore_print_operand_address (stream, x)\n      FILE * stream;\n@@ -260,7 +260,8 @@ mcore_print_operand_address (stream, x)\n    'P'  print log2 of a power of two\n    'Q'  print log2 of an inverse of a power of two\n    'U'  print register for ldm/stm instruction\n-   'X'  print byte number for xtrbN instruction  */\n+   'X'  print byte number for xtrbN instruction.  */\n+\n void\n mcore_print_operand (stream, x, code)\n      FILE * stream;\n@@ -331,6 +332,7 @@ mcore_print_operand (stream, x, code)\n }\n \n /* What does a constant cost ?  */\n+\n int\n mcore_const_costs (exp, code)\n      rtx exp;\n@@ -360,7 +362,8 @@ mcore_const_costs (exp, code)\n \n /* What does an and instruction cost - we do this b/c immediates may \n    have been relaxed.   We want to ensure that cse will cse relaxed immeds\n-   out.  Otherwise we'll get bad code (multiple reloads of the same const) */\n+   out.  Otherwise we'll get bad code (multiple reloads of the same const).  */\n+\n int\n mcore_and_cost (x)\n      rtx x;\n@@ -372,7 +375,7 @@ mcore_and_cost (x)\n \n   val = INTVAL (XEXP (x, 1));\n    \n-  /* Do it directly. */\n+  /* Do it directly.  */\n   if (CONST_OK_FOR_K (val) || CONST_OK_FOR_M (~val))\n     return 2;\n   /* Takes one instruction to load.  */\n@@ -382,11 +385,12 @@ mcore_and_cost (x)\n   else if (TARGET_HARDLIT && mcore_const_ok_for_inline (val))\n     return 4;\n \n-  /* takes a lrw to load */\n+  /* Takes a lrw to load.  */\n   return 5;\n }\n \n-/* What does an or cost - see and_cost(). */\n+/* What does an or cost - see and_cost().  */\n+\n int\n mcore_ior_cost (x)\n      rtx x;\n@@ -398,23 +402,24 @@ mcore_ior_cost (x)\n \n   val = INTVAL (XEXP (x, 1));\n \n-  /* Do it directly with bclri. */\n+  /* Do it directly with bclri.  */\n   if (CONST_OK_FOR_M (val))\n     return 2;\n-  /* Takes one instruction to load. */\n+  /* Takes one instruction to load.  */\n   else if (const_ok_for_mcore (val))\n     return 3;\n-  /* Takes two instructions to load. */\n+  /* Takes two instructions to load.  */\n   else if (TARGET_HARDLIT && mcore_const_ok_for_inline (val))\n     return 4;\n   \n-  /* Takes a lrw to load. */\n+  /* Takes a lrw to load.  */\n   return 5;\n }\n \n /* Check to see if a comparison against a constant can be made more efficient\n    by incrementing/decrementing the constant to get one that is more efficient\n    to load.  */\n+\n int\n mcore_modify_comparison (code)\n      enum rtx_code code;\n@@ -444,6 +449,7 @@ mcore_modify_comparison (code)\n }\n \n /* Prepare the operands for a comparison.  */\n+\n rtx\n mcore_gen_compare_reg (code)\n      enum rtx_code code;\n@@ -456,37 +462,40 @@ mcore_gen_compare_reg (code)\n     op1 = force_reg (SImode, op1);\n \n   /* cmpnei: 0-31 (K immediate)\n-     cmplti: 1-32 (J immediate, 0 using btsti x,31) */\n+     cmplti: 1-32 (J immediate, 0 using btsti x,31).  */\n   switch (code)\n     {\n-    case EQ:\t/* use inverted condition, cmpne */\n+    case EQ:\t/* Use inverted condition, cmpne.  */\n       code = NE;\n       /* drop through */\n-    case NE:\t/* use normal condition, cmpne */\n+      \n+    case NE:\t/* Use normal condition, cmpne.  */\n       if (GET_CODE (op1) == CONST_INT && ! CONST_OK_FOR_K (INTVAL (op1)))\n \top1 = force_reg (SImode, op1);\n       break;\n \n-    case LE:\t/* use inverted condition, reversed cmplt */\n+    case LE:\t/* Use inverted condition, reversed cmplt.  */\n       code = GT;\n       /* drop through */\n-    case GT:\t/* use normal condition, reversed cmplt */\n+      \n+    case GT:\t/* Use normal condition, reversed cmplt.  */\n       if (GET_CODE (op1) == CONST_INT)\n \top1 = force_reg (SImode, op1);\n       break;\n \n-    case GE:\t/* use inverted condition, cmplt */\n+    case GE:\t/* Use inverted condition, cmplt.  */\n       code = LT;\n       /* drop through */\n-    case LT:\t/* use normal condition, cmplt */\n+      \n+    case LT:\t/* Use normal condition, cmplt.  */\n       if (GET_CODE (op1) == CONST_INT && \n \t  /* covered by btsti x,31 */\n \t  INTVAL (op1) != 0 &&\n \t  ! CONST_OK_FOR_J (INTVAL (op1)))\n \top1 = force_reg (SImode, op1);\n       break;\n \n-    case GTU:\t/* use inverted condition, cmple */\n+    case GTU:\t/* Use inverted condition, cmple.  */\n       if (GET_CODE (op1) == CONST_INT && INTVAL (op1) == 0)\n \t{\n \t  /* Unsigned > 0 is the same as != 0, but we need\n@@ -501,15 +510,17 @@ mcore_gen_compare_reg (code)\n \t}\n       code = LEU;\n       /* drop through */\n-    case LEU:\t/* use normal condition, reversed cmphs */\n+      \n+    case LEU:\t/* Use normal condition, reversed cmphs. */\n       if (GET_CODE (op1) == CONST_INT && INTVAL (op1) != 0)\n \top1 = force_reg (SImode, op1);\n       break;\n \n-    case LTU:\t/* use inverted condition, cmphs */\n+    case LTU:\t/* Use inverted condition, cmphs.  */\n       code = GEU;\n       /* drop through */\n-    case GEU:\t/* use normal condition, cmphs */\n+      \n+    case GEU:\t/* Use normal condition, cmphs.  */\n       if (GET_CODE (op1) == CONST_INT && INTVAL (op1) != 0)\n \top1 = force_reg (SImode, op1);\n       break;\n@@ -594,6 +605,7 @@ mcore_output_call (operands, index)\n }\n \n /* Can we load a constant with a single instruction ?  */\n+\n static int\n const_ok_for_mcore (value)\n      int value;\n@@ -613,6 +625,7 @@ const_ok_for_mcore (value)\n }\n \n /* Can we load a constant inline with up to 2 instructions ?  */\n+\n int\n mcore_const_ok_for_inline (value)\n      long value;\n@@ -623,6 +636,7 @@ mcore_const_ok_for_inline (value)\n }\n \n /* Are we loading the constant using a not ?  */\n+\n int\n mcore_const_trick_uses_not (value)\n      long value;\n@@ -634,20 +648,19 @@ mcore_const_trick_uses_not (value)\n \n /* Try tricks to load a constant inline and return the trick number if\n    success (0 is non-inlinable).\n- *\n- * 0: not inlinable\n- * 1: single instruction (do the usual thing)\n- * 2: single insn followed by a 'not'\n- * 3: single insn followed by a subi\n- * 4: single insn followed by an addi\n- * 5: single insn followed by rsubi\n- * 6: single insn followed by bseti\n- * 7: single insn followed by bclri\n- * 8: single insn followed by rotli\n- * 9: single insn followed by lsli\n- * 10: single insn followed by ixh\n- * 11: single insn followed by ixw\n- */\n+  \n+   0: not inlinable\n+   1: single instruction (do the usual thing)\n+   2: single insn followed by a 'not'\n+   3: single insn followed by a subi\n+   4: single insn followed by an addi\n+   5: single insn followed by rsubi\n+   6: single insn followed by bseti\n+   7: single insn followed by bclri\n+   8: single insn followed by rotli\n+   9: single insn followed by lsli\n+   10: single insn followed by ixh\n+   11: single insn followed by ixw.  */\n \n static int\n try_constant_tricks (value, x, y)\n@@ -659,7 +672,7 @@ try_constant_tricks (value, x, y)\n   unsigned bit, shf, rot;\n \n   if (const_ok_for_mcore (value))\n-    return 1;\t/* do the usual thing */\n+    return 1;\t/* Do the usual thing.  */\n   \n   if (TARGET_HARDLIT) \n     {\n@@ -741,7 +754,7 @@ try_constant_tricks (value, x, y)\n \t    }\n \t  \n \t  if (shf & 1)\n-\t    shf = 0;\t/* Can't use logical shift, low order bit is one. */\n+\t    shf = 0;\t/* Can't use logical shift, low order bit is one.  */\n \t  \n \t  shf >>= 1;\n \t  \n@@ -777,7 +790,8 @@ try_constant_tricks (value, x, y)\n    for either the next use (i.e., reg is live), a death note, or a set of\n    reg.  Don't just use dead_or_set_p() since reload does not always mark \n    deaths (especially if PRESERVE_DEATH_NOTES_REGNO_P is not defined). We\n-   can ignore subregs by extracting the actual register.  BRC */\n+   can ignore subregs by extracting the actual register.  BRC  */\n+\n int\n mcore_is_dead (first, reg)\n      rtx first;\n@@ -825,11 +839,12 @@ mcore_is_dead (first, reg)\n \n \n /* Count the number of ones in mask.  */\n+\n int\n mcore_num_ones (mask)\n      int mask;\n {\n-  /* A trick to count set bits recently posted on comp.compilers */\n+  /* A trick to count set bits recently posted on comp.compilers.  */\n   mask =  (mask >> 1  & 0x55555555) + (mask & 0x55555555);\n   mask = ((mask >> 2) & 0x33333333) + (mask & 0x33333333);\n   mask = ((mask >> 4) + mask) & 0x0f0f0f0f;\n@@ -838,7 +853,8 @@ mcore_num_ones (mask)\n   return (mask + (mask >> 16)) & 0xff;\n }\n \n-/* Count the number of zeros in mask. */\n+/* Count the number of zeros in mask.  */\n+\n int\n mcore_num_zeros (mask)\n      int mask;\n@@ -847,6 +863,7 @@ mcore_num_zeros (mask)\n }\n \n /* Determine byte being masked.  */\n+\n int\n mcore_byte_offset (mask)\n      unsigned int mask;\n@@ -864,6 +881,7 @@ mcore_byte_offset (mask)\n }\n \n /* Determine halfword being masked.  */\n+\n int\n mcore_halfword_offset (mask)\n      unsigned int mask;\n@@ -877,6 +895,7 @@ mcore_halfword_offset (mask)\n }\n \n /* Output a series of bseti's corresponding to mask.  */\n+\n const char *\n mcore_output_bseti (dst, mask)\n      rtx dst;\n@@ -902,6 +921,7 @@ mcore_output_bseti (dst, mask)\n }\n \n /* Output a series of bclri's corresponding to mask.  */\n+\n const char *\n mcore_output_bclri (dst, mask)\n      rtx dst;\n@@ -930,6 +950,7 @@ mcore_output_bclri (dst, mask)\n /* Output a conditional move of two constants that are +/- 1 within each\n    other.  See the \"movtK\" patterns in mcore.md.   I'm not sure this is\n    really worth the effort.  */\n+\n const char *\n mcore_output_cmov (operands, cmp_t, test)\n      rtx operands[];\n@@ -942,8 +963,7 @@ mcore_output_cmov (operands, cmp_t, test)\n \n   out_operands[0] = operands[0];\n \n-  /* check to see which constant is loadable */\n-\n+  /* Check to see which constant is loadable.  */\n   if (const_ok_for_mcore (INTVAL (operands[1])))\n     {\n       out_operands[1] = operands[1];\n@@ -954,31 +974,29 @@ mcore_output_cmov (operands, cmp_t, test)\n       out_operands[1] = operands[2];\n       out_operands[2] = operands[1];\n \n-      /* complement test since constants are swapped */\n+      /* Complement test since constants are swapped.  */\n       cmp_t = (cmp_t == 0);\n     }\n   load_value   = INTVAL (out_operands[1]);\n   adjust_value = INTVAL (out_operands[2]);\n \n-  /* first output the test if folded into the pattern */\n+  /* First output the test if folded into the pattern.  */\n \n   if (test) \n     output_asm_insn (test, operands);\n \n-  /* load the constant - for now, only support constants that can be\n+  /* Load the constant - for now, only support constants that can be\n      generated with a single instruction.  maybe add general inlinable\n      constants later (this will increase the # of patterns since the\n-     instruction sequence has a different length attribute). */\n-\n+     instruction sequence has a different length attribute).  */\n   if (load_value >= 0 && load_value <= 127)\n     output_asm_insn (\"movi\\t%0,%1\", out_operands);\n   else if ((load_value & (load_value - 1)) == 0)\n     output_asm_insn (\"bgeni\\t%0,%P1\", out_operands);\n   else if ((load_value & (load_value + 1)) == 0)\n     output_asm_insn (\"bmaski\\t%0,%N1\", out_operands);\n    \n-  /* output the constant adjustment */\n-\n+  /* Output the constant adjustment.  */\n   if (load_value > adjust_value)\n     {\n       if (cmp_t)\n@@ -998,7 +1016,8 @@ mcore_output_cmov (operands, cmp_t, test)\n }\n \n /* Outputs the peephole for moving a constant that gets not'ed followed \n-   by an and (i.e. combine the not and the and into andn) BRC */\n+   by an and (i.e. combine the not and the and into andn). BRC  */\n+\n const char *\n mcore_output_andn (insn, operands)\n      rtx insn ATTRIBUTE_UNUSED;\n@@ -1018,12 +1037,15 @@ mcore_output_andn (insn, operands)\n \n   if (x >= 0 && x <= 127)\n     load_op = \"movi\\t%0,%1\";\n-  /* try exact power of two */\n+  \n+  /* Try exact power of two.  */\n   else if ((x & (x - 1)) == 0)\n     load_op = \"bgeni\\t%0,%P1\";\n-  /* try exact power of two - 1 */\n+  \n+  /* Try exact power of two - 1.  */\n   else if ((x & (x + 1)) == 0)\n     load_op = \"bmaski\\t%0,%N1\";\n+  \n   else \n     load_op = \"BADMOVI\\t%0,%1\";\n \n@@ -1034,6 +1056,7 @@ mcore_output_andn (insn, operands)\n }\n \n /* Output an inline constant.  */\n+\n static const char *\n output_inline_const (mode, operands)\n      enum machine_mode mode;\n@@ -1060,29 +1083,30 @@ output_inline_const (mode, operands)\n   if (trick_no == 1)\n     x = value;\n \n-  /* operands: 0 = dst, 1 = load immed., 2 = immed. adjustment */\n-\n+  /* operands: 0 = dst, 1 = load immed., 2 = immed. adjustment.  */\n   out_operands[0] = operands[0];\n   out_operands[1] = GEN_INT (x);\n   \n   if (trick_no > 2)\n     out_operands[2] = GEN_INT (y);\n \n-  /* Select dst format based on mode */\n-\n+  /* Select dst format based on mode.  */\n   if (mode == DImode && (! TARGET_LITTLE_END))\n     dst_fmt = \"%R0\";\n   else\n     dst_fmt = \"%0\";\n \n   if (x >= 0 && x <= 127)\n     sprintf (load_op, \"movi\\t%s,%%1\", dst_fmt);\n+  \n   /* Try exact power of two.  */\n   else if ((x & (x - 1)) == 0)\n     sprintf (load_op, \"bgeni\\t%s,%%P1\", dst_fmt);\n-  /* try exact power of two - 1.  */\n+  \n+  /* Try exact power of two - 1.  */\n   else if ((x & (x + 1)) == 0)\n     sprintf (load_op, \"bmaski\\t%s,%%N1\", dst_fmt);\n+  \n   else \n     sprintf (load_op, \"BADMOVI\\t%s,%%1\", dst_fmt);\n \n@@ -1101,7 +1125,7 @@ output_inline_const (mode, operands)\n       sprintf (buf, \"%s\\n\\tsubi\\t%s,%%2\\t// %d 0x%x\", load_op, dst_fmt, value, value);\n       break;\n     case 5:   /* rsub */\n-      /* never happens unless -mrsubi, see try_constant_tricks() */\n+      /* Never happens unless -mrsubi, see try_constant_tricks().  */\n       sprintf (buf, \"%s\\n\\trsubi\\t%s,%%2\\t// %d 0x%x\", load_op, dst_fmt, value, value);\n       break;\n     case 6:   /* bset */\n@@ -1132,6 +1156,7 @@ output_inline_const (mode, operands)\n }\n \n /* Output a move of a word or less value.  */\n+\n const char *\n mcore_output_move (insn, operands, mode)\n      rtx insn ATTRIBUTE_UNUSED;\n@@ -1170,10 +1195,10 @@ mcore_output_move (insn, operands, mode)\n \t  else if (try_constant_tricks (INTVAL (src), &x, &y))     /* R-P */\n             return output_inline_const (SImode, operands);  /* 1-2 insns */\n \t  else \n-            return \"lrw\\t%0,%x1\\t// %1\";\t/* get it from literal pool */\n+            return \"lrw\\t%0,%x1\\t// %1\";\t/* Get it from literal pool.  */\n \t}\n       else\n-\treturn \"lrw\\t%0, %1\";                /* into the literal pool */\n+\treturn \"lrw\\t%0, %1\";                /* Into the literal pool.  */\n     }\n   else if (GET_CODE (dst) == MEM)               /* m-r */\n     return \"stw\\t%1,%0\";\n@@ -1185,6 +1210,7 @@ mcore_output_move (insn, operands, mode)\n    Useful for things where we've gotten into trouble and think we'd\n    be doing an lrw into r15 (forbidden). This lets us get out of\n    that pickle even after register allocation.  */\n+\n const char *\n mcore_output_inline_const_forced (insn, operands, mode)\n      rtx insn ATTRIBUTE_UNUSED;\n@@ -1235,7 +1261,7 @@ mcore_output_inline_const_forced (insn, operands, mode)\n   if (value == 0 || ! mcore_const_ok_for_inline (value))\n     abort ();\n \n-  /* Now, work our way backwards emitting the constant. */\n+  /* Now, work our way backwards emitting the constant.  */\n \n   /* Emit the value that remains -- it will be non-zero.  */\n   operands[1] = GEN_INT (value);\n@@ -1265,13 +1291,14 @@ mcore_output_inline_const_forced (insn, operands, mode)\n   if (value != ovalue)          /* sanity */\n     abort ();\n  \n-  /* We've output all the instructions.   */\n+  /* We've output all the instructions.  */\n   return \"\";\n }\n \n /* Return a sequence of instructions to perform DI or DF move.\n    Since the MCORE cannot move a DI or DF in one instruction, we have\n    to take care when we see overlapping source and dest registers.  */\n+\n const char *\n mcore_output_movedouble (operands, mode)\n      rtx operands[];\n@@ -1286,6 +1313,7 @@ mcore_output_movedouble (operands, mode)\n \t{\n \t  int dstreg = REGNO (dst);\n \t  int srcreg = REGNO (src);\n+\t  \n \t  /* Ensure the second source not overwritten.  */\n \t  if (srcreg + 1 == dstreg)\n \t    return \"mov\t%R0,%R1\\n\\tmov\t%0,%1\";\n@@ -1314,13 +1342,14 @@ mcore_output_movedouble (operands, mode)\n \t  else\n \t    abort ();\n \n-          /* ??? length attribute is wrong here */\n+          /* ??? length attribute is wrong here.  */\n \t  if (dstreg == basereg)\n \t    {\n-\t      /* just load them in reverse order */\n+\t      /* Just load them in reverse order.  */\n \t      return \"ldw\\t%R0,%R1\\n\\tldw\\t%0,%1\";\n+\t      \n \t      /* XXX: alternative: move basereg to basereg+1\n-\t       * and then fall through */\n+\t         and then fall through.  */\n \t    }\n \t  else\n \t    return \"ldw\\t%0,%1\\n\\tldw\\t%R0,%R1\";\n@@ -1376,6 +1405,7 @@ mcore_output_movedouble (operands, mode)\n /* Predicates used by the templates.  */\n \n /* Non zero if OP can be source of a simple move operation.  */\n+\n int\n mcore_general_movsrc_operand (op, mode)\n      rtx op;\n@@ -1389,6 +1419,7 @@ mcore_general_movsrc_operand (op, mode)\n }\n \n /* Non zero if OP can be destination of a simple move operation. */\n+\n int\n mcore_general_movdst_operand (op, mode)\n      rtx op;\n@@ -1401,6 +1432,7 @@ mcore_general_movdst_operand (op, mode)\n }\n \n /* Nonzero if OP is a normal arithmetic register.  */\n+\n int\n mcore_arith_reg_operand (op, mode)\n      rtx op;\n@@ -1420,6 +1452,7 @@ mcore_arith_reg_operand (op, mode)\n \n /* Non zero if OP should be recognized during reload for an ixh/ixw\n    operand.  See the ixh/ixw patterns.  */\n+\n int\n mcore_reload_operand (op, mode)\n      rtx op;\n@@ -1435,6 +1468,7 @@ mcore_reload_operand (op, mode)\n }\n \n /* Nonzero if OP is a valid source operand for an arithmetic insn.  */\n+\n int\n mcore_arith_J_operand (op, mode)\n      rtx op;\n@@ -1450,6 +1484,7 @@ mcore_arith_J_operand (op, mode)\n }\n \n /* Nonzero if OP is a valid source operand for an arithmetic insn.  */\n+\n int\n mcore_arith_K_operand (op, mode)\n      rtx op;\n@@ -1465,6 +1500,7 @@ mcore_arith_K_operand (op, mode)\n }\n \n /* Nonzero if OP is a valid source operand for a shift or rotate insn.  */\n+\n int\n mcore_arith_K_operand_not_0 (op, mode)\n      rtx op;\n@@ -1522,7 +1558,8 @@ mcore_arith_M_operand (op, mode)\n   return 0;\n }\n \n-/* Nonzero if OP is a valid source operand for loading  */\n+/* Nonzero if OP is a valid source operand for loading.  */\n+\n int\n mcore_arith_imm_operand (op, mode)\n      rtx op;\n@@ -1551,7 +1588,8 @@ mcore_arith_any_imm_operand (op, mode)\n   return 0;\n }\n \n-/* Nonzero if OP is a valid source operand for a cmov with two consts +/- 1 */\n+/* Nonzero if OP is a valid source operand for a cmov with two consts +/- 1.  */\n+\n int\n mcore_arith_O_operand (op, mode)\n      rtx op;\n@@ -1567,6 +1605,7 @@ mcore_arith_O_operand (op, mode)\n }\n \n /* Nonzero if OP is a valid source operand for a btsti.  */\n+\n int\n mcore_literal_K_operand (op, mode)\n      rtx op;\n@@ -1579,6 +1618,7 @@ mcore_literal_K_operand (op, mode)\n }\n \n /* Nonzero if OP is a valid source operand for an add/sub insn.  */\n+\n int\n mcore_addsub_operand (op, mode)\n      rtx op;\n@@ -1596,7 +1636,7 @@ mcore_addsub_operand (op, mode)\n \t constants may not directly be used in an add/sub, they may if first loaded\n \t into a register.  Thus, this predicate should indicate that they are valid,\n \t and the constraint in mcore.md should control whether an additional load to\n-\t register is needed. (see mcore.md, addsi) -- DAC 4/2/1998 */\n+\t register is needed. (see mcore.md, addsi). -- DAC 4/2/1998  */\n       /*\n \tif (CONST_OK_FOR_J(INTVAL(op)) || CONST_OK_FOR_L(INTVAL(op)))\n           return 1;\n@@ -1607,6 +1647,7 @@ mcore_addsub_operand (op, mode)\n }\n \n /* Nonzero if OP is a valid source operand for a compare operation.  */\n+\n int\n mcore_compare_operand (op, mode)\n      rtx op;\n@@ -1621,7 +1662,8 @@ mcore_compare_operand (op, mode)\n   return 0;\n }\n \n-/* Expand insert bit field.  BRC */\n+/* Expand insert bit field.  BRC  */\n+\n int\n mcore_expand_insv (operands)\n      rtx operands[];\n@@ -1633,12 +1675,11 @@ mcore_expand_insv (operands)\n \n   /* To get width 1 insv, the test in store_bit_field() (expmed.c, line 191)\n      for width==1 must be removed.  Look around line 368.  This is something\n-     we really want the md part to do. */\n-\n+     we really want the md part to do.  */\n   if (width == 1 && GET_CODE (operands[3]) == CONST_INT)\n     {\n-      /* Do directly with bseti or bclri */\n-      /* RBE: 2/97 consider only low bit of constant */\n+      /* Do directly with bseti or bclri.  */\n+      /* RBE: 2/97 consider only low bit of constant.  */\n       if ((INTVAL(operands[3])&1) == 0)\n \t{\n \t  mask = ~(1 << posn);\n@@ -1656,7 +1697,7 @@ mcore_expand_insv (operands)\n     }\n \n   /* Look at some bitfield placements that we aren't interested\n-   * in handling ourselves, unless specifically directed to do so */\n+     in handling ourselves, unless specifically directed to do so.  */\n   if (! TARGET_W_FIELD)\n     return 0;\t\t/* Generally, give up about now.  */\n \n@@ -1671,7 +1712,7 @@ mcore_expand_insv (operands)\n   /* The general case - we can do this a little bit better than what the\n      machine independent part tries.  This will get rid of all the subregs\n      that mess up constant folding in combine when working with relaxed\n-     immediates. */\n+     immediates.  */\n \n   /* If setting the entire field, do it directly.  */\n   if (GET_CODE (operands[3]) == CONST_INT && \n@@ -1703,15 +1744,15 @@ mcore_expand_insv (operands)\n      always have to do this since we widen everything to SImode.\n      We don't have to mask if we're shifting this up against the\n      MSB of the register (e.g., the shift will push out any hi-order\n-     bits. */\n+     bits.  */\n   if (width + posn != (int) GET_MODE_SIZE (SImode))\n     {\n       ereg = force_reg (SImode, GEN_INT ((1 << width) - 1));      \n       emit_insn (gen_rtx (SET, SImode, sreg,\n                           gen_rtx (AND, SImode, sreg, ereg)));\n     }\n \n-  /* Insert source value in dest. */\n+  /* Insert source value in dest.  */\n   if (posn != 0)\n     emit_insn (gen_rtx (SET, SImode, sreg,\n \t\t        gen_rtx (ASHIFT, SImode, sreg, GEN_INT (posn))));\n@@ -1765,6 +1806,7 @@ mcore_load_multiple_operation (op, mode)\n }\n \n /* Similar, but tests for store multiple.  */\n+\n int\n mcore_store_multiple_operation (op, mode)\n      rtx op;\n@@ -1936,7 +1978,7 @@ mcore_expand_block_move (dst_mem, src_mem, operands)\n \talign = 4;\n       \n       /* RBE: bumped 1 and 2 byte align from 1 and 2 to 4 and 8 bytes before\n-         we give up and go to memcpy.. */\n+         we give up and go to memcpy.  */\n       if ((align == 4 && (bytes <= 4*4\n \t\t\t  || ((bytes & 01) == 0 && bytes <= 8*4)\n \t\t\t  || ((bytes & 03) == 0 && bytes <= 16*4)))\n@@ -1958,13 +2000,14 @@ mcore_expand_block_move (dst_mem, src_mem, operands)\n \n /* Code to generate prologue and epilogue sequences.  */\n static int number_of_regs_before_varargs;\n+\n /* Set by SETUP_INCOMING_VARARGS to indicate to prolog that this is\n    for a varargs function.  */\n static int current_function_anonymous_args;\n \n #define\tSTACK_BYTES (STACK_BOUNDARY/BITS_PER_UNIT)\n #define\tSTORE_REACH (64)\t/* Maximum displace of word store + 4.  */\n-#define\tADDI_REACH (32)\t\t/* Maximum addi operand. */\n+#define\tADDI_REACH (32)\t\t/* Maximum addi operand.  */\n \n static void\n layout_mcore_frame (infp)\n@@ -1981,7 +2024,7 @@ layout_mcore_frame (infp)\n   int step;\n \n   /* Might have to spill bytes to re-assemble a big argument that\n-     was passed partially in registers and partially on the stack. */\n+     was passed partially in registers and partially on the stack.  */\n   nbytes = current_function_pretend_args_size;\n   \n   /* Determine how much space for spilled anonymous args (e.g., stdarg).  */\n@@ -2050,7 +2093,7 @@ layout_mcore_frame (infp)\n       infp->reg_growth = growths;\n       infp->local_growth = growths;\n       \n-      /* If we haven't already folded it in... */\n+      /* If we haven't already folded it in.  */\n       if (outbounds)\n \tinfp->growth[growths++] = outbounds;\n       \n@@ -2083,22 +2126,22 @@ layout_mcore_frame (infp)\n       infp->reg_offset = step - infp->pad_reg - infp->reg_size;\n       all -= step;\n \n-      /* Can we fold in any space required for outbounds? */\n+      /* Can we fold in any space required for outbounds?  */\n       if (outbounds + all <= ADDI_REACH && !frame_pointer_needed)\n \t{\n \t  all += outbounds;\n \t  outbounds = 0;\n \t}\n \n-      /* Get the rest of the locals in place. */\n+      /* Get the rest of the locals in place.  */\n       step = all;\n       infp->growth[growths++] = step;\n       infp->local_growth = growths;\n       all -= step;\n \n       assert (all == 0);\n \n-      /* Finish off if we need to do so... */\n+      /* Finish off if we need to do so.  */\n       if (outbounds)\n \tinfp->growth[growths++] = outbounds;\n       \n@@ -2129,25 +2172,22 @@ layout_mcore_frame (infp)\n       infp->growth[growths++] = step;\n       infp->local_growth = growths;\n \n-      /* If there's any left to be done... */\n+      /* If there's any left to be done.  */\n       if (outbounds)\n \tinfp->growth[growths++] = outbounds;\n       \n       goto finish;\n     }\n \n   /* XXX: optimizations that we'll want to play with....\n-   * -- regarg is not aligned, but it's a small number of registers;\n-   *\tuse some of localsize so that regarg is aligned and then \n-   *\tsave the registers.\n-   * \n-   */\n+     -- regarg is not aligned, but it's a small number of registers;\n+    \tuse some of localsize so that regarg is aligned and then \n+    \tsave the registers.  */\n \n   /* Simple encoding; plods down the stack buying the pieces as it goes.\n-   * -- does not optimize space consumption.\n-   * -- does not attempt to optimize instruction counts.\n-   * -- but it is safe for all alignments.\n-   */\n+     -- does not optimize space consumption.\n+     -- does not attempt to optimize instruction counts.\n+     -- but it is safe for all alignments.  */\n   if (regarg % STACK_BYTES != 0)\n     infp->pad_reg = STACK_BYTES - (regarg % STACK_BYTES);\n   \n@@ -2193,6 +2233,7 @@ layout_mcore_frame (infp)\n \n /* Define the offset between two registers, one to be eliminated, and\n    the other its replacement, at the start of a routine.  */\n+\n int\n mcore_initial_elimination_offset (from, to)\n      int from;\n@@ -2223,7 +2264,8 @@ mcore_initial_elimination_offset (from, to)\n   return 0;\n }\n \n-/* Keep track of some information about varargs for the prolog. */\n+/* Keep track of some information about varargs for the prolog.  */\n+\n void\n mcore_setup_incoming_varargs (args_so_far, mode, type, ptr_pretend_size)\n      CUMULATIVE_ARGS args_so_far;\n@@ -2327,7 +2369,7 @@ mcore_expand_prolog ()\n         }\n     }\n \n-  /* Do we need another stack adjustment before we do the register saves? */\n+  /* Do we need another stack adjustment before we do the register saves?  */\n   if (growth < fi.reg_growth)\n     output_stack_adjust (-1, fi.growth[growth++]);\t\t/* grows it */\n \n@@ -2373,7 +2415,7 @@ mcore_expand_prolog ()\n       \n       emit_insn (gen_movsi (frame_pointer_rtx, stack_pointer_rtx));\n \n-      /* ... and then go any remaining distance for outbounds, etc. */\n+      /* ... and then go any remaining distance for outbounds, etc.  */\n       if (fi.growth[growth])\n         output_stack_adjust (-1, fi.growth[growth++]);\n     }\n@@ -2420,8 +2462,7 @@ mcore_expand_epilog ()\n \n   /* Make sure we've shrunk stack back to the point where the registers\n      were laid down. This is typically 0/1 iterations.  Then pull the\n-     register save information back off the stack. */\n-\n+     register save information back off the stack.  */\n   while (growth >= fi.reg_growth)\n     output_stack_adjust ( 1, fi.growth[growth--]);\n   \n@@ -2459,7 +2500,7 @@ mcore_expand_epilog ()\n     }\n \n   /* Give back anything else.  */\n-  /* XXX: Should accumuate total and then give it back... */\n+  /* XXX: Should accumuate total and then give it back.  */\n   while (growth >= 0)\n     output_stack_adjust ( 1, fi.growth[growth--]);\n }\n@@ -2534,6 +2575,7 @@ static int pool_size;\n \n /* Dump out any constants accumulated in the final pass.  These\n    will only be labels.  */\n+\n const char *\n mcore_output_jump_label_table ()\n {\n@@ -2563,7 +2605,7 @@ mcore_output_jump_label_table ()\n /* We need these below.  They use information stored in tables to figure out\n    what values are in what registers, etc.  This is okay, since these tables\n    are valid at the time mcore_dependent_simplify_rtx() is invoked.  Don't\n-   use them anywhere else.   BRC */\n+   use them anywhere else.  BRC  */\n \n extern unsigned HOST_WIDE_INT nonzero_bits PARAMS ((rtx, enum machine_mode));\n extern int num_sign_bit_copies PARAMS ((Rtx, enum machine_mode));\n@@ -2573,7 +2615,7 @@ extern int num_sign_bit_copies PARAMS ((Rtx, enum machine_mode));\n    simplifications should be tried after machine dependent ones.  Thus,\n    we can filter out certain simplifications and keep the simplify_rtx()\n    from changing things that we just simplified in a machine dependent\n-   fashion.  This is experimental.  BRC */\n+   fashion.  This is experimental.  BRC  */\n rtx\n mcore_dependent_simplify_rtx (x, int_op0_mode, last, in_dest, general_simplify)\n      rtx x;\n@@ -2585,8 +2627,7 @@ mcore_dependent_simplify_rtx (x, int_op0_mode, last, in_dest, general_simplify)\n   enum machine_mode mode = GET_MODE (x);\n   enum rtx_code code = GET_CODE (x);\n \n-  /* always simplify unless explicitly asked not to */\n-\n+  /* Always simplify unless explicitly asked not to.  */\n   * general_simplify = 1;\n \n   if (code == IF_THEN_ELSE)\n@@ -2604,7 +2645,7 @@ mcore_dependent_simplify_rtx (x, int_op0_mode, last, in_dest, general_simplify)\n          if it would be turned into a shift by simplify_if_then_else().\n          instead, leave it alone so that it will collapse into a conditional\n          move.  besides, at least for the mcore, doing this simplification does\n-         not typically help.  see combine.c, line 4217.  BRC */\n+         not typically help.  see combine.c, line 4217.  BRC  */\n \n       if (true_code == NE && XEXP (cond, 1) == const0_rtx\n \t  && false == const0_rtx && GET_CODE (true) == CONST_INT\n@@ -2624,14 +2665,15 @@ mcore_dependent_simplify_rtx (x, int_op0_mode, last, in_dest, general_simplify)\n #endif\n \n /* Check whether insn is a candidate for a conditional.  */\n+\n static cond_type\n is_cond_candidate (insn)\n      rtx insn;\n {\n   /* The only things we conditionalize are those that can be directly\n      changed into a conditional.  Only bother with SImode items.  If \n      we wanted to be a little more aggressive, we could also do other\n-     modes such as DImode with reg-reg move or load 0. */\n+     modes such as DImode with reg-reg move or load 0.  */\n   if (GET_CODE (insn) == INSN)\n     {\n       rtx pat = PATTERN (insn);\n@@ -2693,6 +2735,7 @@ is_cond_candidate (insn)\n \n /* Emit a conditional version of insn and replace the old insn with the\n    new one.  Return the new insn if emitted.  */\n+\n static rtx\n emit_new_cond_insn (insn, cond)\n      rtx insn;\n@@ -2808,7 +2851,7 @@ emit_new_cond_insn (insn, cond)\n \n    we can delete the L2 label if NUSES==1 and re-apply the optimization\n    starting at the last instruction of block 2.  This may allow an entire\n-   if-then-else statement to be conditionalized.  BRC  */ \n+   if-then-else statement to be conditionalized.  BRC  */\n static rtx\n conditionalize_block (first)\n      rtx first;\n@@ -2938,7 +2981,7 @@ conditionalize_block (first)\n   if (! start_blk_3_lab)\n     return end_blk_2_insn;\n   \n-  /* Return the insn right after the label at the start of block 3. */\n+  /* Return the insn right after the label at the start of block 3.  */\n   return NEXT_INSN (start_blk_3_lab);\n }\n \n@@ -2949,7 +2992,8 @@ conditionalize_block (first)\n    say before cse 2, it may expose more optimization opportunities.  \n    but, the pay back probably isn't really worth the effort (we'd have \n    to update all reg/flow/notes/links/etc to make it work - and stick it\n-   in before cse 2). */\n+   in before cse 2).  */\n+\n static void\n conditionalize_optimization (first)\n      rtx first;\n@@ -2963,15 +3007,16 @@ conditionalize_optimization (first)\n static int saved_warn_return_type = -1;\n static int saved_warn_return_type_count = 0;\n \n-/* This function is called from toplev.c before reorg. */\n+/* This function is called from toplev.c before reorg.  */\n+\n void\n mcore_dependent_reorg (first)\n      rtx first;\n {\n   /* Reset this variable.  */\n   current_function_anonymous_args = 0;\n   \n-  /* Restore the warn_return_type if it has been altered */\n+  /* Restore the warn_return_type if it has been altered.  */\n   if (saved_warn_return_type != -1)\n     {\n       /* Only restore the value if we have reached another function."}]}