{"sha": "5b0264cb4d7a017784253061843a52f7776a3942", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NWIwMjY0Y2I0ZDdhMDE3Nzg0MjUzMDYxODQzYTUyZjc3NzZhMzk0Mg==", "commit": {"author": {"name": "Nathan Sidwell", "email": "nathan@gcc.gnu.org", "date": "2004-09-08T08:05:14Z"}, "committer": {"name": "Nathan Sidwell", "email": "nathan@gcc.gnu.org", "date": "2004-09-08T08:05:14Z"}, "message": "emit-rtl.c (immed_double_const): Use gcc_assert and gcc_unreachable.\n\n\t* emit-rtl.c (immed_double_const): Use gcc_assert and gcc_unreachable.\n\t(gen_rtx_SUBREG, gen_reg_rtx, mark_user_reg, subreg_hard_regno,\n\tgen_lowpart_common, gen_highpart, gen_highpart_mode,\n\tsubreg_highpart_offset, operand_subword, operand_subword_force,\n\tmem_expr_equal_p, set_mem_attributes_minus_bitpos,\n\tset_mem_alias_set, change_address_1, verify_rtx_sharing,\n\tcopy_most_rtx, set_first_insn, set_last_insn, prev_cc0_setter,\n\ttry_split, add_insn_after, add_insn_before, remove_insn,\n\tremove_unnecessary_notes, emit_insn_before, emit_jump_insn_before,\n\temit_call_insn_before, emit_insn_after, emit_jump_insn_after,\n\temit_call_insn_after, emit_insn, emit_jump_insn, emit_call_insn,\n\tset_unique_reg_note, emit, push_to_full_sequence, copy_insn_1,\n\tgen_const_vector_0, emit_copy_of_insn_after): Likewise.\n\t* et-forest.c (set_prev, set_next, et_check_occ_sanity,\n\trecord_path_before_1, check_path_after_1, check_path_after): Likewise.\n\t* except.c (gen_eh_region, resolve_one_fixup_region,\n\tremove_unreachable_regions, convert_from_eh_region_ranges_1,\n\tadd_ehl_entry, duplicate_eh_region_1, build_post_landing_pads,\n\tconnect_post_landing_pads, sjlj_emit_function_exit,\n\tremove_exception_handler_label, remove_eh_handler,\n\treachable_next_level, collect_one_action_chain,\n\toutput_function_exception_table): Likewise.\n\t* explow.c (trunc_int_for_mode, copy_to_mode_reg,\n\toptimize_save_area_alloca, allocate_dynamic_stack_space,\n\tprobe_stack_range, hard_function_value): Likewise.\n\t* expmed.c (mode_for_extraction, store_bit_field,\n\tstore_fixed_bit_field, extract_bit_field, expand_shift,\n\texpand_mult_const, expand_mult, choose_multiplier,\n\texpand_mult_highpart, expand_divmod, emit_store_flag,\n\tdo_cmp_and_jump): Likewise.\n\t* expr.c (convert_move, convert_modes, move_by_pieces,\n\tmove_by_pieces_ninsns, move_by_pieces_1, emit_block_move,\n\tmove_block_from_reg, gen_group_rtx, emit_group_load,\n\temit_group_move, emit_group_store, use_reg, use_regs,\n\tcan_store_by_pieces, store_by_pieces, store_by_pieces_1,\n\temit_move_insn, emit_move_insn_1, emit_push_insn,\n\texpand_assignment, store_expr, count_type_elements,\n\tstore_constructor, store_field, safe_from_p, expand_var,\n\texpand_expr_addr_expr, expand_expr_real_1, do_store_flag): Likewise.\n\nFrom-SVN: r87178", "tree": {"sha": "33b0784e8edadfbdb707175909731132a211267f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/33b0784e8edadfbdb707175909731132a211267f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5b0264cb4d7a017784253061843a52f7776a3942", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5b0264cb4d7a017784253061843a52f7776a3942", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5b0264cb4d7a017784253061843a52f7776a3942", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5b0264cb4d7a017784253061843a52f7776a3942/comments", "author": null, "committer": null, "parents": [{"sha": "ced3f397be6d68ba9a838ee7e3f27c456238501a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ced3f397be6d68ba9a838ee7e3f27c456238501a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ced3f397be6d68ba9a838ee7e3f27c456238501a"}], "stats": {"total": 2320, "additions": 1101, "deletions": 1219}, "files": [{"sha": "88432812e4c016aa0178ab73ea0e4270e074ada4", "filename": "gcc/ChangeLog", "status": "modified", "additions": 43, "deletions": 1, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=5b0264cb4d7a017784253061843a52f7776a3942", "patch": "@@ -1,3 +1,45 @@\n+2004-09-08  Nathan Sidwell  <nathan@codesourcery.com>\n+\n+\t* emit-rtl.c (immed_double_const): Use gcc_assert and gcc_unreachable.\n+\t(gen_rtx_SUBREG, gen_reg_rtx, mark_user_reg, subreg_hard_regno,\n+\tgen_lowpart_common, gen_highpart, gen_highpart_mode,\n+\tsubreg_highpart_offset, operand_subword, operand_subword_force,\n+\tmem_expr_equal_p, set_mem_attributes_minus_bitpos,\n+\tset_mem_alias_set, change_address_1, verify_rtx_sharing,\n+\tcopy_most_rtx, set_first_insn, set_last_insn, prev_cc0_setter,\n+\ttry_split, add_insn_after, add_insn_before, remove_insn,\n+\tremove_unnecessary_notes, emit_insn_before, emit_jump_insn_before,\n+\temit_call_insn_before, emit_insn_after, emit_jump_insn_after,\n+\temit_call_insn_after, emit_insn, emit_jump_insn, emit_call_insn,\n+\tset_unique_reg_note, emit, push_to_full_sequence, copy_insn_1,\n+\tgen_const_vector_0, emit_copy_of_insn_after): Likewise.\n+\t* et-forest.c (set_prev, set_next, et_check_occ_sanity,\n+\trecord_path_before_1, check_path_after_1, check_path_after): Likewise.\n+\t* except.c (gen_eh_region, resolve_one_fixup_region,\n+\tremove_unreachable_regions, convert_from_eh_region_ranges_1,\n+\tadd_ehl_entry, duplicate_eh_region_1, build_post_landing_pads,\n+\tconnect_post_landing_pads, sjlj_emit_function_exit,\n+\tremove_exception_handler_label, remove_eh_handler,\n+\treachable_next_level, collect_one_action_chain,\n+\toutput_function_exception_table): Likewise.\n+\t* explow.c (trunc_int_for_mode, copy_to_mode_reg,\n+\toptimize_save_area_alloca, allocate_dynamic_stack_space,\n+\tprobe_stack_range, hard_function_value): Likewise.\n+\t* expmed.c (mode_for_extraction, store_bit_field,\n+\tstore_fixed_bit_field, extract_bit_field, expand_shift,\n+\texpand_mult_const, expand_mult, choose_multiplier,\n+\texpand_mult_highpart, expand_divmod, emit_store_flag,\n+\tdo_cmp_and_jump): Likewise.\n+\t* expr.c (convert_move, convert_modes, move_by_pieces,\n+\tmove_by_pieces_ninsns, move_by_pieces_1, emit_block_move,\n+\tmove_block_from_reg, gen_group_rtx, emit_group_load,\n+\temit_group_move, emit_group_store, use_reg, use_regs,\n+\tcan_store_by_pieces, store_by_pieces, store_by_pieces_1,\n+\temit_move_insn, emit_move_insn_1, emit_push_insn,\n+\texpand_assignment, store_expr, count_type_elements,\n+\tstore_constructor, store_field, safe_from_p, expand_var,\n+\texpand_expr_addr_expr, expand_expr_real_1, do_store_flag): Likewise.\n+\n 2004-09-08  Nathan Sidwell  <nathan@codesourcery.com>\n \n \t* dbxout.c (dbxout_type, dbxout_type_name, dbxout_symbol): Use\n@@ -6066,7 +6108,7 @@\n \t* config/i386/xmmintrin.h: Include <mm_malloc.h>.\n \n 2004-08-03  H.J. Lu  <hongjiu.lu@intel.com>\n-\t    Tanguy Fautr\u00c3  <tfautre@pandora.be>\n+\t    Tanguy Fautr\ufffd  <tfautre@pandora.be>\n \n \t* config/i386/pmm_malloc.h: New file.\n "}, {"sha": "9f9289bfad5560ce63c9102672a2b557a7fe8643", "filename": "gcc/emit-rtl.c", "status": "modified", "additions": 111, "deletions": 166, "changes": 277, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Femit-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Femit-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Femit-rtl.c?ref=5b0264cb4d7a017784253061843a52f7776a3942", "patch": "@@ -456,12 +456,12 @@ immed_double_const (HOST_WIDE_INT i0, HOST_WIDE_INT i1, enum machine_mode mode)\n   if (mode != VOIDmode)\n     {\n       int width;\n-      if (GET_MODE_CLASS (mode) != MODE_INT\n-\t  && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT\n-\t  /* We can get a 0 for an error mark.  */\n-\t  && GET_MODE_CLASS (mode) != MODE_VECTOR_INT\n-\t  && GET_MODE_CLASS (mode) != MODE_VECTOR_FLOAT)\n-\tabort ();\n+      \n+      gcc_assert (GET_MODE_CLASS (mode) == MODE_INT\n+\t\t  || GET_MODE_CLASS (mode) == MODE_PARTIAL_INT\n+\t\t  /* We can get a 0 for an error mark.  */\n+\t\t  || GET_MODE_CLASS (mode) == MODE_VECTOR_INT\n+\t\t  || GET_MODE_CLASS (mode) == MODE_VECTOR_FLOAT);\n \n       /* We clear out all bits that don't belong in MODE, unless they and\n \t our sign bit are all one.  So we get either a reasonable negative\n@@ -474,9 +474,9 @@ immed_double_const (HOST_WIDE_INT i0, HOST_WIDE_INT i1, enum machine_mode mode)\n       else if (width == HOST_BITS_PER_WIDE_INT\n \t       && ! (i1 == ~0 && i0 < 0))\n \ti1 = 0;\n-      else if (width > 2 * HOST_BITS_PER_WIDE_INT)\n-\t/* We cannot represent this value as a constant.  */\n-\tabort ();\n+      else\n+\t/* We should be able to represent this value as a constant.  */\n+\tgcc_assert (width <= 2 * HOST_BITS_PER_WIDE_INT);\n \n       /* If this would be an entire word for the target, but is not for\n \t the host, then sign-extend on the host so that the number will\n@@ -623,16 +623,14 @@ gen_rtx_SUBREG (enum machine_mode mode, rtx reg, int offset)\n {\n   /* This is the most common failure type.\n      Catch it early so we can see who does it.  */\n-  if ((offset % GET_MODE_SIZE (mode)) != 0)\n-    abort ();\n+  gcc_assert (!(offset % GET_MODE_SIZE (mode)));\n \n   /* This check isn't usable right now because combine will\n      throw arbitrary crap like a CALL into a SUBREG in\n      gen_lowpart_for_combine so we must just eat it.  */\n #if 0\n   /* Check for this too.  */\n-  if (offset >= GET_MODE_SIZE (GET_MODE (reg)))\n-    abort ();\n+  gcc_assert (offset < GET_MODE_SIZE (GET_MODE (reg)));\n #endif\n   return gen_rtx_raw_SUBREG (mode, reg, offset);\n }\n@@ -711,8 +709,7 @@ gen_reg_rtx (enum machine_mode mode)\n \n   /* Don't let anything called after initial flow analysis create new\n      registers.  */\n-  if (no_new_pseudos)\n-    abort ();\n+  gcc_assert (!no_new_pseudos);\n \n   if (generating_concat_p\n       && (GET_MODE_CLASS (mode) == MODE_COMPLEX_FLOAT\n@@ -972,10 +969,11 @@ mark_user_reg (rtx reg)\n       REG_USERVAR_P (XEXP (reg, 0)) = 1;\n       REG_USERVAR_P (XEXP (reg, 1)) = 1;\n     }\n-  else if (REG_P (reg))\n-    REG_USERVAR_P (reg) = 1;\n   else\n-    abort ();\n+    {\n+      gcc_assert (REG_P (reg));\n+      REG_USERVAR_P (reg) = 1;\n+    }\n }\n \n /* Identify REG as a probable pointer register and show its alignment\n@@ -1044,23 +1042,17 @@ subreg_hard_regno (rtx x, int check_mode)\n \n   /* This is where we attempt to catch illegal subregs\n      created by the compiler.  */\n-  if (GET_CODE (x) != SUBREG\n-      || !REG_P (reg))\n-    abort ();\n+  gcc_assert (GET_CODE (x) == SUBREG && REG_P (reg));\n   base_regno = REGNO (reg);\n-  if (base_regno >= FIRST_PSEUDO_REGISTER)\n-    abort ();\n-  if (check_mode && ! HARD_REGNO_MODE_OK (base_regno, GET_MODE (reg)))\n-    abort ();\n+  gcc_assert (base_regno < FIRST_PSEUDO_REGISTER);\n+  gcc_assert (!check_mode || HARD_REGNO_MODE_OK (base_regno, GET_MODE (reg)));\n #ifdef ENABLE_CHECKING\n-  if (!subreg_offset_representable_p (REGNO (reg), GET_MODE (reg),\n-\t\t\t\t      SUBREG_BYTE (x), mode))\n-    abort ();\n+  gcc_assert (subreg_offset_representable_p (REGNO (reg), GET_MODE (reg),\n+\t\t\t\t\t     SUBREG_BYTE (x), mode));\n #endif\n   /* Catch non-congruent offsets too.  */\n   byte_offset = SUBREG_BYTE (x);\n-  if ((byte_offset % GET_MODE_SIZE (mode)) != 0)\n-    abort ();\n+  gcc_assert (!(byte_offset % GET_MODE_SIZE (mode)));\n \n   final_regno = subreg_regno (x);\n \n@@ -1096,8 +1088,7 @@ gen_lowpart_common (enum machine_mode mode, rtx x)\n   \n   xsize = GET_MODE_SIZE (innermode);\n \n-  if (innermode == VOIDmode || innermode == BLKmode)\n-    abort ();\n+  gcc_assert (innermode != VOIDmode && innermode != BLKmode);\n \n   if (innermode == mode)\n     return x;\n@@ -1224,21 +1215,22 @@ gen_highpart (enum machine_mode mode, rtx x)\n \n   /* This case loses if X is a subreg.  To catch bugs early,\n      complain if an invalid MODE is used even in other cases.  */\n-  if (msize > UNITS_PER_WORD\n-      && msize != (unsigned int) GET_MODE_UNIT_SIZE (GET_MODE (x)))\n-    abort ();\n+  gcc_assert (msize <= UNITS_PER_WORD\n+\t      || msize == (unsigned int) GET_MODE_UNIT_SIZE (GET_MODE (x)));\n \n   result = simplify_gen_subreg (mode, x, GET_MODE (x),\n \t\t\t\tsubreg_highpart_offset (mode, GET_MODE (x)));\n-\n+  gcc_assert (result);\n+  \n   /* simplify_gen_subreg is not guaranteed to return a valid operand for\n      the target if we have a MEM.  gen_highpart must return a valid operand,\n      emitting code if necessary to do so.  */\n-  if (result != NULL_RTX && MEM_P (result))\n-    result = validize_mem (result);\n-\n-  if (!result)\n-    abort ();\n+  if (MEM_P (result))\n+    {\n+      result = validize_mem (result);\n+      gcc_assert (result);\n+    }\n+  \n   return result;\n }\n \n@@ -1249,8 +1241,7 @@ gen_highpart_mode (enum machine_mode outermode, enum machine_mode innermode, rtx\n {\n   if (GET_MODE (exp) != VOIDmode)\n     {\n-      if (GET_MODE (exp) != innermode)\n-\tabort ();\n+      gcc_assert (GET_MODE (exp) == innermode);\n       return gen_highpart (outermode, exp);\n     }\n   return simplify_gen_subreg (outermode, exp, innermode,\n@@ -1285,8 +1276,7 @@ subreg_highpart_offset (enum machine_mode outermode, enum machine_mode innermode\n   unsigned int offset = 0;\n   int difference = (GET_MODE_SIZE (innermode) - GET_MODE_SIZE (outermode));\n \n-  if (GET_MODE_SIZE (innermode) < GET_MODE_SIZE (outermode))\n-    abort ();\n+  gcc_assert (GET_MODE_SIZE (innermode) >= GET_MODE_SIZE (outermode));\n \n   if (difference > 0)\n     {\n@@ -1346,8 +1336,7 @@ operand_subword (rtx op, unsigned int offset, int validate_address, enum machine\n   if (mode == VOIDmode)\n     mode = GET_MODE (op);\n \n-  if (mode == VOIDmode)\n-    abort ();\n+  gcc_assert (mode != VOIDmode);\n \n   /* If OP is narrower than a word, fail.  */\n   if (mode != BLKmode\n@@ -1405,8 +1394,7 @@ operand_subword_force (rtx op, unsigned int offset, enum machine_mode mode)\n     }\n \n   result = operand_subword (op, offset, 1, mode);\n-  if (result == 0)\n-    abort ();\n+  gcc_assert (result);\n \n   return result;\n }\n@@ -1500,13 +1488,13 @@ mem_expr_equal_p (tree expr1, tree expr2)\n   if (TREE_CODE (expr1) == INDIRECT_REF)\n     return mem_expr_equal_p (TREE_OPERAND (expr1, 0),\n \t\t\t     TREE_OPERAND (expr2, 0));\n-  \n-  /* Decls with different pointers can't be equal.  */\n-  if (DECL_P (expr1))\n-    return 0;\n \n-  abort(); /* ARRAY_REFs, ARRAY_RANGE_REFs and BIT_FIELD_REFs should already\n+  /* ARRAY_REFs, ARRAY_RANGE_REFs and BIT_FIELD_REFs should already\n \t      have been resolved here.  */\n+  gcc_assert (DECL_P (expr1));\n+  \n+  /* Decls with different pointers can't be equal.  */\n+  return 0;\n }\n \n /* Given REF, a MEM, and T, either the type of X or the expression\n@@ -1540,8 +1528,7 @@ set_mem_attributes_minus_bitpos (rtx ref, tree t, int objectp,\n      wrong answer, as it assumes that DECL_RTL already has the right alias\n      info.  Callers should not set DECL_RTL until after the call to\n      set_mem_attributes.  */\n-  if (DECL_P (t) && ref == DECL_RTL_IF_SET (t))\n-    abort ();\n+  gcc_assert (!DECL_P (t) || ref != DECL_RTL_IF_SET (t));\n \n   /* Get the alias set from the expression or type (perhaps using a\n      front-end routine) and use it.  */\n@@ -1754,8 +1741,7 @@ set_mem_alias_set (rtx mem, HOST_WIDE_INT set)\n {\n #ifdef ENABLE_CHECKING\n   /* If the new and old alias sets don't conflict, something is wrong.  */\n-  if (!alias_sets_conflict_p (set, MEM_ALIAS_SET (mem)))\n-    abort ();\n+  gcc_assert (alias_sets_conflict_p (set, MEM_ALIAS_SET (mem)));\n #endif\n \n   MEM_ATTRS (mem) = get_mem_attrs (set, MEM_EXPR (mem), MEM_OFFSET (mem),\n@@ -1814,8 +1800,7 @@ change_address_1 (rtx memref, enum machine_mode mode, rtx addr, int validate)\n {\n   rtx new;\n \n-  if (!MEM_P (memref))\n-    abort ();\n+  gcc_assert (MEM_P (memref));\n   if (mode == VOIDmode)\n     mode = GET_MODE (memref);\n   if (addr == 0)\n@@ -1827,10 +1812,7 @@ change_address_1 (rtx memref, enum machine_mode mode, rtx addr, int validate)\n   if (validate)\n     {\n       if (reload_in_progress || reload_completed)\n-\t{\n-\t  if (! memory_address_p (mode, addr))\n-\t    abort ();\n-\t}\n+\tgcc_assert (memory_address_p (mode, addr));\n       else\n \taddr = memory_address (mode, addr);\n     }\n@@ -2285,7 +2267,7 @@ verify_rtx_sharing (rtx orig, rtx insn)\n       debug_rtx (insn);\n       error (\"Shared rtx\");\n       debug_rtx (x);\n-      abort ();\n+      fatal_error (\"Internal consistency failure\");\n     }\n   RTX_FLAG (x, used) = 1;\n \n@@ -2490,7 +2472,7 @@ copy_most_rtx (rtx orig, rtx may_share)\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n     }\n   return copy;\n@@ -2822,8 +2804,7 @@ get_insns (void)\n void\n set_first_insn (rtx insn)\n {\n-  if (PREV_INSN (insn) != 0)\n-    abort ();\n+  gcc_assert (!PREV_INSN (insn));\n   first_insn = insn;\n }\n \n@@ -2840,8 +2821,7 @@ get_last_insn (void)\n void\n set_last_insn (rtx insn)\n {\n-  if (NEXT_INSN (insn) != 0)\n-    abort ();\n+  gcc_assert (!NEXT_INSN (insn));\n   last_insn = insn;\n }\n \n@@ -3191,8 +3171,7 @@ prev_cc0_setter (rtx insn)\n     return XEXP (note, 0);\n \n   insn = prev_nonnote_insn (insn);\n-  if (! sets_cc0_p (PATTERN (insn)))\n-    abort ();\n+  gcc_assert (sets_cc0_p (PATTERN (insn)));\n \n   return insn;\n }\n@@ -3292,8 +3271,7 @@ try_split (rtx pat, rtx trial, int last)\n \t\t one jump is created, otherwise the machine description\n \t\t is responsible for this step using\n \t\t split_branch_probability variable.  */\n-\t      if (njumps != 1)\n-\t\tabort ();\n+\t      gcc_assert (njumps == 1);\n \t      REG_NOTES (insn)\n \t\t= gen_rtx_EXPR_LIST (REG_BR_PROB,\n \t\t\t\t     GEN_INT (probability),\n@@ -3510,8 +3488,7 @@ add_insn_after (rtx insn, rtx after)\n   rtx next = NEXT_INSN (after);\n   basic_block bb;\n \n-  if (optimize && INSN_DELETED_P (after))\n-    abort ();\n+  gcc_assert (!optimize || !INSN_DELETED_P (after));\n \n   NEXT_INSN (insn) = next;\n   PREV_INSN (insn) = after;\n@@ -3535,8 +3512,7 @@ add_insn_after (rtx insn, rtx after)\n \t    break;\n \t  }\n \n-      if (stack == 0)\n-\tabort ();\n+      gcc_assert (stack);\n     }\n \n   if (!BARRIER_P (after)\n@@ -3575,8 +3551,7 @@ add_insn_before (rtx insn, rtx before)\n   rtx prev = PREV_INSN (before);\n   basic_block bb;\n \n-  if (optimize && INSN_DELETED_P (before))\n-    abort ();\n+  gcc_assert (!optimize || !INSN_DELETED_P (before));\n \n   PREV_INSN (insn) = prev;\n   NEXT_INSN (insn) = before;\n@@ -3603,8 +3578,7 @@ add_insn_before (rtx insn, rtx before)\n \t    break;\n \t  }\n \n-      if (stack == 0)\n-\tabort ();\n+      gcc_assert (stack);\n     }\n \n   if (!BARRIER_P (before)\n@@ -3614,14 +3588,13 @@ add_insn_before (rtx insn, rtx before)\n       set_block_for_insn (insn, bb);\n       if (INSN_P (insn))\n \tbb->flags |= BB_DIRTY;\n-      /* Should not happen as first in the BB is always\n-\t either NOTE or LABEl.  */\n-      if (BB_HEAD (bb) == insn\n-\t  /* Avoid clobbering of structure when creating new BB.  */\n-\t  && !BARRIER_P (insn)\n-\t  && (!NOTE_P (insn)\n-\t      || NOTE_LINE_NUMBER (insn) != NOTE_INSN_BASIC_BLOCK))\n-\tabort ();\n+      /* Should not happen as first in the BB is always either NOTE or\n+\t LABEl.  */\n+      gcc_assert (BB_HEAD (bb) != insn\n+\t\t  /* Avoid clobbering of structure when creating new BB.  */\n+\t\t  || BARRIER_P (insn)\n+\t\t  || (NOTE_P (insn)\n+\t\t      && NOTE_LINE_NUMBER (insn) == NOTE_INSN_BASIC_BLOCK));\n     }\n \n   PREV_INSN (before) = insn;\n@@ -3660,8 +3633,7 @@ remove_insn (rtx insn)\n \t    break;\n \t  }\n \n-      if (stack == 0)\n-\tabort ();\n+      gcc_assert (stack);\n     }\n \n   if (next)\n@@ -3683,8 +3655,7 @@ remove_insn (rtx insn)\n \t    break;\n \t  }\n \n-      if (stack == 0)\n-\tabort ();\n+      gcc_assert (stack);\n     }\n   if (!BARRIER_P (insn)\n       && (bb = BLOCK_FOR_INSN (insn)))\n@@ -3695,8 +3666,7 @@ remove_insn (rtx insn)\n \t{\n \t  /* Never ever delete the basic block note without deleting whole\n \t     basic block.  */\n-\t  if (NOTE_P (insn))\n-\t    abort ();\n+\t  gcc_assert (!NOTE_P (insn));\n \t  BB_HEAD (bb) = next;\n \t}\n       if (BB_END (bb) == insn)\n@@ -3709,8 +3679,7 @@ remove_insn (rtx insn)\n void\n add_function_usage_to (rtx call_insn, rtx call_fusage)\n {\n-  if (! call_insn || !CALL_P (call_insn))\n-    abort ();\n+  gcc_assert (call_insn && CALL_P (call_insn));\n \n   /* Put the register usage information on the CALL.  If there is already\n      some usage information, put ours at the end.  */\n@@ -3857,11 +3826,10 @@ remove_unnecessary_notes (void)\n \n \tcase NOTE_INSN_EH_REGION_END:\n \t  /* Too many end notes.  */\n-\t  if (eh_stack == NULL_RTX)\n-\t    abort ();\n+\t  gcc_assert (eh_stack);\n \t  /* Mismatched nesting.  */\n-\t  if (NOTE_EH_HANDLER (XEXP (eh_stack, 0)) != NOTE_EH_HANDLER (insn))\n-\t    abort ();\n+\t  gcc_assert (NOTE_EH_HANDLER (XEXP (eh_stack, 0))\n+\t\t      == NOTE_EH_HANDLER (insn));\n \t  tmp = eh_stack;\n \t  eh_stack = XEXP (eh_stack, 1);\n \t  free_INSN_LIST_node (tmp);\n@@ -3870,18 +3838,15 @@ remove_unnecessary_notes (void)\n \tcase NOTE_INSN_BLOCK_BEG:\n \t  /* By now, all notes indicating lexical blocks should have\n \t     NOTE_BLOCK filled in.  */\n-\t  if (NOTE_BLOCK (insn) == NULL_TREE)\n-\t    abort ();\n+\t  gcc_assert (NOTE_BLOCK (insn));\n \t  block_stack = alloc_INSN_LIST (insn, block_stack);\n \t  break;\n \n \tcase NOTE_INSN_BLOCK_END:\n \t  /* Too many end notes.  */\n-\t  if (block_stack == NULL_RTX)\n-\t    abort ();\n+\t  gcc_assert (block_stack);\n \t  /* Mismatched nesting.  */\n-\t  if (NOTE_BLOCK (XEXP (block_stack, 0)) != NOTE_BLOCK (insn))\n-\t    abort ();\n+\t  gcc_assert (NOTE_BLOCK (XEXP (block_stack, 0)) == NOTE_BLOCK (insn));\n \t  tmp = block_stack;\n \t  block_stack = XEXP (block_stack, 1);\n \t  free_INSN_LIST_node (tmp);\n@@ -3930,8 +3895,7 @@ remove_unnecessary_notes (void)\n     }\n \n   /* Too many begin notes.  */\n-  if (block_stack || eh_stack)\n-    abort ();\n+  gcc_assert (!block_stack && !eh_stack);\n }\n \n \f\n@@ -3968,10 +3932,7 @@ emit_insn_before (rtx x, rtx before)\n   rtx last = before;\n   rtx insn;\n \n-#ifdef ENABLE_RTL_CHECKING\n-  if (before == NULL_RTX)\n-    abort ();\n-#endif\n+  gcc_assert (before);\n \n   if (x == NULL_RTX)\n     return last;\n@@ -3996,7 +3957,7 @@ emit_insn_before (rtx x, rtx before)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4017,10 +3978,7 @@ emit_jump_insn_before (rtx x, rtx before)\n {\n   rtx insn, last = NULL_RTX;\n \n-#ifdef ENABLE_RTL_CHECKING\n-  if (before == NULL_RTX)\n-    abort ();\n-#endif\n+  gcc_assert (before);\n \n   switch (GET_CODE (x))\n     {\n@@ -4042,7 +4000,7 @@ emit_jump_insn_before (rtx x, rtx before)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4063,10 +4021,7 @@ emit_call_insn_before (rtx x, rtx before)\n {\n   rtx last = NULL_RTX, insn;\n \n-#ifdef ENABLE_RTL_CHECKING\n-  if (before == NULL_RTX)\n-    abort ();\n-#endif\n+  gcc_assert (before);\n \n   switch (GET_CODE (x))\n     {\n@@ -4088,7 +4043,7 @@ emit_call_insn_before (rtx x, rtx before)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4196,10 +4151,7 @@ emit_insn_after (rtx x, rtx after)\n {\n   rtx last = after;\n \n-#ifdef ENABLE_RTL_CHECKING\n-  if (after == NULL_RTX)\n-    abort ();\n-#endif\n+  gcc_assert (after);\n \n   if (x == NULL_RTX)\n     return last;\n@@ -4217,7 +4169,7 @@ emit_insn_after (rtx x, rtx after)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4255,10 +4207,7 @@ emit_jump_insn_after (rtx x, rtx after)\n {\n   rtx last;\n \n-#ifdef ENABLE_RTL_CHECKING\n-  if (after == NULL_RTX)\n-    abort ();\n-#endif\n+  gcc_assert (after);\n \n   switch (GET_CODE (x))\n     {\n@@ -4273,7 +4222,7 @@ emit_jump_insn_after (rtx x, rtx after)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4294,10 +4243,7 @@ emit_call_insn_after (rtx x, rtx after)\n {\n   rtx last;\n \n-#ifdef ENABLE_RTL_CHECKING\n-  if (after == NULL_RTX)\n-    abort ();\n-#endif\n+  gcc_assert (after);\n \n   switch (GET_CODE (x))\n     {\n@@ -4312,7 +4258,7 @@ emit_call_insn_after (rtx x, rtx after)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4513,7 +4459,7 @@ emit_insn (rtx x)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4554,7 +4500,7 @@ emit_jump_insn (rtx x)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4588,7 +4534,7 @@ emit_call_insn (rtx x)\n \n #ifdef ENABLE_RTL_CHECKING\n     case SEQUENCE:\n-      abort ();\n+      gcc_unreachable ();\n       break;\n #endif\n \n@@ -4737,8 +4683,7 @@ set_unique_reg_note (rtx insn, enum reg_note kind, rtx datum)\n \t means the insn only has one * useful * set).  */\n       if (GET_CODE (PATTERN (insn)) == PARALLEL && multiple_sets (insn))\n \t{\n-\t  if (note)\n-\t    abort ();\n+\t  gcc_assert (!note);\n \t  return NULL_RTX;\n \t}\n \n@@ -4807,21 +4752,24 @@ emit (rtx x)\n {\n   enum rtx_code code = classify_insn (x);\n \n-  if (code == CODE_LABEL)\n-    return emit_label (x);\n-  else if (code == INSN)\n-    return emit_insn (x);\n-  else if (code == JUMP_INSN)\n+  switch (code)\n     {\n-      rtx insn = emit_jump_insn (x);\n-      if (any_uncondjump_p (insn) || GET_CODE (x) == RETURN)\n-\treturn emit_barrier ();\n-      return insn;\n+    case CODE_LABEL:\n+      return emit_label (x);\n+    case INSN:\n+      return emit_insn (x);\n+    case  JUMP_INSN:\n+      {\n+\trtx insn = emit_jump_insn (x);\n+\tif (any_uncondjump_p (insn) || GET_CODE (x) == RETURN)\n+\t  return emit_barrier ();\n+\treturn insn;\n+      }\n+    case CALL_INSN:\n+      return emit_call_insn (x);\n+    default:\n+      gcc_unreachable ();\n     }\n-  else if (code == CALL_INSN)\n-    return emit_call_insn (x);\n-  else\n-    abort ();\n }\n \f\n /* Space for free sequence stack entries.  */\n@@ -4883,8 +4831,7 @@ push_to_full_sequence (rtx first, rtx last)\n   first_insn = first;\n   last_insn = last;\n   /* We really should have the end of the insn chain here.  */\n-  if (last && NEXT_INSN (last))\n-    abort ();\n+  gcc_assert (!last || !NEXT_INSN (last));\n }\n \n /* Set up the outer-level insn chain\n@@ -5104,15 +5051,14 @@ copy_insn_1 (rtx orig)\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n     }\n \n   if (code == SCRATCH)\n     {\n       i = copy_insn_n_scratches++;\n-      if (i >= MAX_RECOG_OPERANDS)\n-\tabort ();\n+      gcc_assert (i < MAX_RECOG_OPERANDS);\n       copy_insn_scratch_in[i] = orig;\n       copy_insn_scratch_out[i] = copy;\n     }\n@@ -5227,8 +5173,7 @@ gen_const_vector_0 (enum machine_mode mode)\n   v = rtvec_alloc (units);\n \n   /* We need to call this function after we to set CONST0_RTX first.  */\n-  if (!CONST0_RTX (inner))\n-    abort ();\n+  gcc_assert (CONST0_RTX (inner));\n \n   for (i = 0; i < units; ++i)\n     RTVEC_ELT (v, i) = CONST0_RTX (inner);\n@@ -5477,7 +5422,7 @@ emit_copy_of_insn_after (rtx insn, rtx after)\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   /* Update LABEL_NUSES.  */"}, {"sha": "7fbbb77312c6cf44c9318378046cebd615971ae0", "filename": "gcc/et-forest.c", "status": "modified", "additions": 18, "deletions": 40, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fet-forest.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fet-forest.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fet-forest.c?ref=5b0264cb4d7a017784253061843a52f7776a3942", "patch": "@@ -88,8 +88,7 @@ static inline void\n set_prev (struct et_occ *occ, struct et_occ *t)\n {\n #ifdef DEBUG_ET\n-  if (occ == t)\n-    abort ();\n+  gcc_assert (occ != t);\n #endif\n \n   occ->prev = t;\n@@ -103,8 +102,7 @@ static inline void\n set_next (struct et_occ *occ, struct et_occ *t)\n {\n #ifdef DEBUG_ET\n-  if (occ == t)\n-    abort ();\n+  gcc_assert (occ != t);\n #endif\n \n   occ->next = t;\n@@ -145,40 +143,26 @@ et_check_occ_sanity (struct et_occ *occ)\n   if (!occ)\n     return;\n \n-  if (occ->parent == occ)\n-    abort ();\n-\n-  if (occ->prev == occ)\n-    abort ();\n-\n-  if (occ->next == occ)\n-    abort ();\n-\n-  if (occ->next && occ->next == occ->prev)\n-    abort ();\n+  gcc_assert (occ->parent != occ);\n+  gcc_assert (occ->prev != occ);\n+  gcc_assert (occ->next != occ);\n+  gcc_assert (!occ->next || occ->next != occ->prev);\n \n   if (occ->next)\n     {\n-      if (occ->next == occ->parent)\n-\tabort ();\n-\n-      if (occ->next->parent != occ)\n-\tabort ();\n+      gcc_assert (occ->next != occ->parent);\n+      gcc_assert (occ->next->parent == occ);\n     }\n \n   if (occ->prev)\n     {\n-      if (occ->prev == occ->parent)\n-\tabort ();\n-\n-      if (occ->prev->parent != occ)\n-\tabort ();\n+      gcc_assert (occ->prev != occ->parent);\n+      gcc_assert (occ->prev->parent == occ);\n     }\n \n-  if (occ->parent\n-      && occ->parent->prev != occ\n-      && occ->parent->next != occ)\n-    abort ();\n+  gcc_assert (!occ->parent\n+\t      || occ->parent->prev == occ\n+\t      || occ->parent->next == occ);\n }\n \n /* Checks whether tree rooted at OCC is sane.  */\n@@ -233,8 +217,7 @@ record_path_before_1 (struct et_occ *occ, int depth)\n \n   fprintf (stderr, \"%d (%d); \", ((basic_block) occ->of->data)->index, depth);\n \n-  if (len >= MAX_NODES)\n-    abort ();\n+  gcc_assert (len < MAX_NODES);\n \n   depths[len] = depth;\n   datas[len] = occ->of;\n@@ -247,8 +230,7 @@ record_path_before_1 (struct et_occ *occ, int depth)\n \tmn = m;\n     }\n \n-  if (mn != occ->min + depth - occ->depth)\n-    abort ();\n+  gcc_assert (mn == occ->min + depth - occ->depth);\n \n   return mn;\n }\n@@ -285,9 +267,7 @@ check_path_after_1 (struct et_occ *occ, int depth)\n     }\n \n   len--;\n-  if (depths[len] != depth\n-      || datas[len] != occ->of)\n-    abort ();\n+  gcc_assert (depths[len] == depth && datas[len] == occ->of);\n \n   if (occ->prev)\n     {\n@@ -296,8 +276,7 @@ check_path_after_1 (struct et_occ *occ, int depth)\n \tmn =  m;\n     }\n \n-  if (mn != occ->min + depth - occ->depth)\n-    abort ();\n+  gcc_assert (mn == occ->min + depth - occ->depth);\n \n   return mn;\n }\n@@ -312,8 +291,7 @@ check_path_after (struct et_occ *occ)\n     occ = occ->parent;\n \n   check_path_after_1 (occ, 0);\n-  if (len != 0)\n-    abort ();\n+  gcc_assert (!len);\n }\n \n #endif"}, {"sha": "b09ff8338a7888ab81d9bcfe36edcf5fdc52e036", "filename": "gcc/except.c", "status": "modified", "additions": 19, "deletions": 29, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexcept.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexcept.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexcept.c?ref=5b0264cb4d7a017784253061843a52f7776a3942", "patch": "@@ -460,8 +460,7 @@ gen_eh_region (enum eh_region_type type, struct eh_region *outer)\n   struct eh_region *new;\n \n #ifdef ENABLE_CHECKING\n-  if (! doing_eh (0))\n-    abort ();\n+  gcc_assert (doing_eh (0));\n #endif\n \n   /* Insert a new blank region as a leaf in the tree.  */\n@@ -688,8 +687,7 @@ resolve_one_fixup_region (struct eh_region *fixup)\n \t  && cleanup->u.cleanup.exp == fixup->u.fixup.cleanup_exp)\n \tbreak;\n     }\n-  if (j > n)\n-    abort ();\n+  gcc_assert (j <= n);\n \n   real = cleanup->outer;\n   if (real && real->type == ERT_FIXUP)\n@@ -811,14 +809,12 @@ remove_unreachable_regions (rtx insns)\n \n       if (r->resume)\n \t{\n-\t  if (uid_region_num[INSN_UID (r->resume)])\n-\t    abort ();\n+\t  gcc_assert (!uid_region_num[INSN_UID (r->resume)]);\n \t  uid_region_num[INSN_UID (r->resume)] = i;\n \t}\n       if (r->label)\n \t{\n-\t  if (uid_region_num[INSN_UID (r->label)])\n-\t    abort ();\n+\t  gcc_assert (!uid_region_num[INSN_UID (r->label)]);\n \t  uid_region_num[INSN_UID (r->label)] = i;\n \t}\n     }\n@@ -942,8 +938,7 @@ convert_from_eh_region_ranges_1 (rtx *pinsns, int *orig_sp, int cur)\n \t}\n     }\n \n-  if (sp != orig_sp)\n-    abort ();\n+  gcc_assert (sp == orig_sp);\n }\n \n static void\n@@ -1006,8 +1001,7 @@ add_ehl_entry (rtx label, struct eh_region *region)\n      label.  After landing pad creation, the exception handlers may\n      share landing pads.  This is ok, since maybe_remove_eh_handler\n      only requires the 1-1 mapping before landing pad creation.  */\n-  if (*slot && !cfun->eh->built_landing_pads)\n-    abort ();\n+  gcc_assert (!*slot || cfun->eh->built_landing_pads);\n \n   *slot = entry;\n }\n@@ -1104,16 +1098,15 @@ duplicate_eh_region_1 (struct eh_region *o, struct inline_remap *map)\n       n->u.throw.type = o->u.throw.type;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   if (o->label)\n     n->label = get_label_from_map (map, CODE_LABEL_NUMBER (o->label));\n   if (o->resume)\n     {\n       n->resume = map->insn_map[INSN_UID (o->resume)];\n-      if (n->resume == NULL)\n-\tabort ();\n+      gcc_assert (n->resume);\n     }\n \n   return n;\n@@ -1586,7 +1579,7 @@ build_post_landing_pads (void)\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n     }\n }\n@@ -1657,8 +1650,7 @@ connect_post_landing_pads (void)\n       end_sequence ();\n       barrier = emit_insn_before (seq, region->resume);\n       /* Avoid duplicate barrier.  */\n-      if (!BARRIER_P (barrier))\n-\tabort ();\n+      gcc_assert (BARRIER_P (barrier));\n       delete_insn (barrier);\n       delete_insn (region->resume);\n \n@@ -2049,8 +2041,7 @@ sjlj_emit_function_exit (void)\n       /* Figure out whether the place we are supposed to insert libcall\n          is inside the last basic block or after it.  In the other case\n          we need to emit to edge.  */\n-      if (e->src->next_bb != EXIT_BLOCK_PTR)\n-\tabort ();\n+      gcc_assert (e->src->next_bb == EXIT_BLOCK_PTR);\n       for (insn = NEXT_INSN (BB_END (e->src)); insn; insn = NEXT_INSN (insn))\n \tif (insn == cfun->eh->sjlj_exit_after)\n \t  break;\n@@ -2258,8 +2249,7 @@ remove_exception_handler_label (rtx label)\n   tmp.label = label;\n   slot = (struct ehl_map_entry **)\n     htab_find_slot (cfun->eh->exception_handler_label_map, &tmp, NO_INSERT);\n-  if (! slot)\n-    abort ();\n+  gcc_assert (slot);\n \n   htab_clear_slot (cfun->eh->exception_handler_label_map, (void **) slot);\n }\n@@ -2330,8 +2320,7 @@ remove_eh_handler (struct eh_region *region)\n \t   try->type == ERT_CATCH;\n \t   try = try->next_peer)\n \tcontinue;\n-      if (try->type != ERT_TRY)\n-\tabort ();\n+      gcc_assert (try->type == ERT_TRY);\n \n       next = region->u.catch.next_catch;\n       prev = region->u.catch.prev_catch;\n@@ -2642,10 +2631,11 @@ reachable_next_level (struct eh_region *region, tree type_thrown,\n     case ERT_FIXUP:\n     case ERT_UNKNOWN:\n       /* Shouldn't see these here.  */\n+      gcc_unreachable ();\n       break;\n+    default:\n+      gcc_unreachable ();\n     }\n-\n-  abort ();\n }\n \n /* Invoke CALLBACK on each region reachable from REGION_NUMBER.  */\n@@ -3259,7 +3249,7 @@ collect_one_action_chain (htab_t ar_hash, struct eh_region *region)\n       return collect_one_action_chain (ar_hash, region->outer);\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n }\n \n@@ -3763,8 +3753,8 @@ output_function_exception_table (void)\n \t\t    cgraph_varpool_mark_needed_node (node);\n \t\t}\n \t    }\n-\t  else if (TREE_CODE (type) != INTEGER_CST)\n-\t    abort ();\n+\t  else\n+\t    gcc_assert (TREE_CODE (type) == INTEGER_CST);\n \t}\n \n       if (tt_format == DW_EH_PE_absptr || tt_format == DW_EH_PE_aligned)"}, {"sha": "62ca87c3ca0b8ac6b0b0750327e65fa7ddf3b223", "filename": "gcc/explow.c", "status": "modified", "additions": 12, "deletions": 19, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexplow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexplow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexplow.c?ref=5b0264cb4d7a017784253061843a52f7776a3942", "patch": "@@ -50,8 +50,7 @@ trunc_int_for_mode (HOST_WIDE_INT c, enum machine_mode mode)\n   int width = GET_MODE_BITSIZE (mode);\n \n   /* You want to truncate to a _what_?  */\n-  if (! SCALAR_INT_MODE_P (mode))\n-    abort ();\n+  gcc_assert (SCALAR_INT_MODE_P (mode));\n \n   /* Canonicalize BImode to 0 and STORE_FLAG_VALUE.  */\n   if (mode == BImode)\n@@ -633,8 +632,7 @@ copy_to_mode_reg (enum machine_mode mode, rtx x)\n   if (! general_operand (x, VOIDmode))\n     x = force_operand (x, temp);\n \n-  if (GET_MODE (x) != mode && GET_MODE (x) != VOIDmode)\n-    abort ();\n+  gcc_assert (GET_MODE (x) == mode || GET_MODE (x) == VOIDmode);\n   if (x != temp)\n     emit_move_insn (temp, x);\n   return temp;\n@@ -1106,11 +1104,10 @@ optimize_save_area_alloca (void)\n \n \t\t Right now only supported port with stack that grow upward\n \t\t is the HPPA and it does not define SETJMP_VIA_SAVE_AREA.  */\n-\t      if (GET_CODE (pat) != SET\n-\t\t  || SET_DEST (pat) != stack_pointer_rtx\n-\t\t  || GET_CODE (SET_SRC (pat)) != MINUS\n-\t\t  || XEXP (SET_SRC (pat), 0) != stack_pointer_rtx)\n-\t\tabort ();\n+\t      gcc_assert (GET_CODE (pat) == SET\n+\t\t\t  && SET_DEST (pat) == stack_pointer_rtx\n+\t\t\t  && GET_CODE (SET_SRC (pat)) == MINUS\n+\t\t\t  && XEXP (SET_SRC (pat), 0) == stack_pointer_rtx);\n \n \t      /* This will now be transformed into a (set REG REG)\n \t\t so we can just blow away all the other notes.  */\n@@ -1134,8 +1131,7 @@ optimize_save_area_alloca (void)\n \t\t    if (XEXP (srch, 1) == note)\n \t\t      break;\n \n-\t\t  if (srch == NULL_RTX)\n-\t\t    abort ();\n+\t\t  gcc_assert (srch);\n \n \t\t  XEXP (srch, 1) = XEXP (note, 1);\n \t\t}\n@@ -1229,8 +1225,7 @@ allocate_dynamic_stack_space (rtx size, rtx target, int known_align)\n \n \t/* ??? Code below assumes that the save area needs maximal\n \t   alignment.  This constraint may be too strong.  */\n-\tif (PREFERRED_STACK_BOUNDARY != BIGGEST_ALIGNMENT)\n-\t  abort ();\n+\tgcc_assert (PREFERRED_STACK_BOUNDARY == BIGGEST_ALIGNMENT);\n \n \tif (GET_CODE (size) == CONST_INT)\n \t  {\n@@ -1287,8 +1282,8 @@ allocate_dynamic_stack_space (rtx size, rtx target, int known_align)\n \n  /* We ought to be called always on the toplevel and stack ought to be aligned\n     properly.  */\n-  if (stack_pointer_delta % (PREFERRED_STACK_BOUNDARY / BITS_PER_UNIT))\n-    abort ();\n+  gcc_assert (!(stack_pointer_delta\n+\t\t% (PREFERRED_STACK_BOUNDARY / BITS_PER_UNIT)));\n \n   /* If needed, check that we have the required amount of stack.  Take into\n      account what has already been checked.  */\n@@ -1539,8 +1534,7 @@ probe_stack_range (HOST_WIDE_INT first, rtx size)\n \t\t\t   1, OPTAB_WIDEN);\n #endif\n \n-      if (temp != test_addr)\n-\tabort ();\n+      gcc_assert (temp == test_addr);\n \n       emit_label (test_lab);\n       emit_cmp_and_jump_insns (test_addr, last_addr, CMP_OPCODE,\n@@ -1594,8 +1588,7 @@ hard_function_value (tree valtype, tree func ATTRIBUTE_UNUSED,\n \t}\n \n       /* No suitable mode found.  */\n-      if (tmpmode == VOIDmode)\n-\tabort ();\n+      gcc_assert (tmpmode != VOIDmode);\n \n       PUT_MODE (val, tmpmode);\n     }"}, {"sha": "fe9aeb5c4c9b4fa541c4f4c07ce0877b4156da6e", "filename": "gcc/expmed.c", "status": "modified", "additions": 74, "deletions": 93, "changes": 167, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=5b0264cb4d7a017784253061843a52f7776a3942", "patch": "@@ -298,7 +298,7 @@ mode_for_extraction (enum extraction_pattern pattern, int opno)\n       return MAX_MACHINE_MODE;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   if (opno == -1)\n@@ -386,10 +386,9 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n       /* We could handle this, but we should always be called with a pseudo\n \t for our targets and all insns should take them as outputs.  */\n-      if (! (*insn_data[icode].operand[0].predicate) (dest, mode0)\n-\t  || ! (*insn_data[icode].operand[1].predicate) (src, mode1)\n-\t  || ! (*insn_data[icode].operand[2].predicate) (rtxpos, mode2))\n-\tabort ();\n+      gcc_assert ((*insn_data[icode].operand[0].predicate) (dest, mode0)\n+\t\t  && (*insn_data[icode].operand[1].predicate) (src, mode1)\n+\t\t  && (*insn_data[icode].operand[2].predicate) (rtxpos, mode2));\n       pat = GEN_FCN (icode) (dest, src, rtxpos);\n       seq = get_insns ();\n       end_sequence ();\n@@ -433,15 +432,14 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t{\n \t  if (GET_CODE (op0) == SUBREG)\n \t    {\n-\t      if (GET_MODE (SUBREG_REG (op0)) == fieldmode\n-\t\t  || GET_MODE_CLASS (fieldmode) == MODE_INT\n-\t\t  || GET_MODE_CLASS (fieldmode) == MODE_PARTIAL_INT)\n-\t\top0 = SUBREG_REG (op0);\n-\t      else\n-\t\t/* Else we've got some float mode source being extracted into\n-\t\t   a different float mode destination -- this combination of\n-\t\t   subregs results in Severe Tire Damage.  */\n-\t\tabort ();\n+\t      /* Else we've got some float mode source being extracted\n+\t\t into a different float mode destination -- this\n+\t\t combination of subregs results in Severe Tire\n+\t\t Damage.  */\n+\t      gcc_assert (GET_MODE (SUBREG_REG (op0)) == fieldmode\n+\t\t\t  || GET_MODE_CLASS (fieldmode) == MODE_INT\n+\t\t\t  || GET_MODE_CLASS (fieldmode) == MODE_PARTIAL_INT);\n+\t      op0 = SUBREG_REG (op0);\n \t    }\n \t  if (REG_P (op0))\n \t    op0 = gen_rtx_SUBREG (fieldmode, op0, byte_offset);\n@@ -462,10 +460,11 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n       {\n \tif (MEM_P (op0))\n \t  op0 = adjust_address (op0, imode, 0);\n-\telse if (imode != BLKmode)\n-\t  op0 = gen_lowpart (imode, op0);\n \telse\n-\t  abort ();\n+\t  {\n+\t    gcc_assert (imode != BLKmode);\n+\t    op0 = gen_lowpart (imode, op0);\n+\t  }\n       }\n   }\n \n@@ -510,15 +509,13 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n       if (GET_CODE (op0) == SUBREG)\n \t{\n-\t  if (GET_MODE (SUBREG_REG (op0)) == fieldmode\n-\t      || GET_MODE_CLASS (fieldmode) == MODE_INT\n-\t      || GET_MODE_CLASS (fieldmode) == MODE_PARTIAL_INT)\n-\t    op0 = SUBREG_REG (op0);\n-\t  else\n-\t    /* Else we've got some float mode source being extracted into\n-\t       a different float mode destination -- this combination of\n-\t       subregs results in Severe Tire Damage.  */\n-\t    abort ();\n+\t  /* Else we've got some float mode source being extracted into\n+\t     a different float mode destination -- this combination of\n+\t     subregs results in Severe Tire Damage.  */\n+\t  gcc_assert (GET_MODE (SUBREG_REG (op0)) == fieldmode\n+\t\t      || GET_MODE_CLASS (fieldmode) == MODE_INT\n+\t\t      || GET_MODE_CLASS (fieldmode) == MODE_PARTIAL_INT);\n+\t  op0 = SUBREG_REG (op0);\n \t}\n \n       emit_insn (GEN_FCN (icode)\n@@ -589,12 +586,10 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t\t pseudo.  We can trivially remove a SUBREG that does not\n \t\t change the size of the operand.  Such a SUBREG may have been\n \t\t added above.  Otherwise, abort.  */\n-\t      if (GET_CODE (op0) == SUBREG\n-\t\t  && (GET_MODE_SIZE (GET_MODE (op0))\n-\t\t      == GET_MODE_SIZE (GET_MODE (SUBREG_REG (op0)))))\n-\t\top0 = SUBREG_REG (op0);\n-\t      else\n-\t\tabort ();\n+\t      gcc_assert (GET_CODE (op0) == SUBREG\n+\t\t\t  && (GET_MODE_SIZE (GET_MODE (op0))\n+\t\t\t      == GET_MODE_SIZE (GET_MODE (SUBREG_REG (op0)))));\n+\t      op0 = SUBREG_REG (op0);\n \t    }\n \t  op0 = gen_rtx_SUBREG (mode_for_size (BITS_PER_WORD, MODE_INT, 0),\n \t\t                op0, (offset * UNITS_PER_WORD));\n@@ -731,12 +726,12 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t    }\n \t  else if (GET_CODE (value) == CONST_INT)\n \t    value1 = gen_int_mode (INTVAL (value), maxmode);\n-\t  else if (!CONSTANT_P (value))\n+\t  else\n \t    /* Parse phase is supposed to make VALUE's data type\n \t       match that of the component reference, which is a type\n \t       at least as wide as the field; so VALUE should have\n \t       a mode that corresponds to that type.  */\n-\t    abort ();\n+\t    gcc_assert (CONSTANT_P (value));\n \t}\n \n       /* If this machine's insv insists on a register,\n@@ -790,8 +785,7 @@ store_fixed_bit_field (rtx op0, unsigned HOST_WIDE_INT offset,\n \n   if (REG_P (op0) || GET_CODE (op0) == SUBREG)\n     {\n-      if (offset != 0)\n-\tabort ();\n+      gcc_assert (!offset);\n       /* Special treatment for a bit field split across two registers.  */\n       if (bitsize + bitpos > BITS_PER_WORD)\n \t{\n@@ -1146,10 +1140,9 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n       /* We could handle this, but we should always be called with a pseudo\n \t for our targets and all insns should take them as outputs.  */\n-      if (! (*insn_data[icode].operand[0].predicate) (dest, mode0)\n-\t  || ! (*insn_data[icode].operand[1].predicate) (src, mode1)\n-\t  || ! (*insn_data[icode].operand[2].predicate) (rtxpos, mode2))\n-\tabort ();\n+      gcc_assert ((*insn_data[icode].operand[0].predicate) (dest, mode0)\n+\t\t  && (*insn_data[icode].operand[1].predicate) (src, mode1)\n+\t\t  && (*insn_data[icode].operand[2].predicate) (rtxpos, mode2));\n \n       pat = GEN_FCN (icode) (dest, src, rtxpos);\n       seq = get_insns ();\n@@ -1170,10 +1163,11 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n       {\n \tif (MEM_P (op0))\n \t  op0 = adjust_address (op0, imode, 0);\n-\telse if (imode != BLKmode)\n-\t  op0 = gen_lowpart (imode, op0);\n \telse\n-\t  abort ();\n+\t  {\n+\t    gcc_assert (imode != BLKmode);\n+\t    op0 = gen_lowpart (imode, op0);\n+\t  }\n       }\n   }\n \n@@ -1299,8 +1293,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t\t\t\t bitnum + bit_offset, 1, target_part, mode,\n \t\t\t\t word_mode);\n \n-\t  if (target_part == 0)\n-\t    abort ();\n+\t  gcc_assert (target_part);\n \n \t  if (result_part != target_part)\n \t    emit_move_insn (target_part, result_part);\n@@ -1346,13 +1339,11 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n   int_mode = int_mode_for_mode (tmode);\n   if (int_mode == BLKmode)\n     int_mode = int_mode_for_mode (mode);\n-  if (int_mode == BLKmode)\n-    abort ();    /* Should probably push op0 out to memory and then\n-\t\t    do a load.  */\n+  /* Should probably push op0 out to memory and then do a load.  */\n+  gcc_assert (int_mode != BLKmode);\n \n   /* OFFSET is the number of words or bytes (UNIT says which)\n      from STR_RTX to the first word or byte containing part of the field.  */\n-\n   if (!MEM_P (op0))\n     {\n       if (offset != 0\n@@ -2145,8 +2136,7 @@ expand_shift (enum tree_code code, enum machine_mode mode, rtx shifted,\n \t define_expand for lshrsi3 was added to vax.md.  */\n     }\n \n-  if (temp == 0)\n-    abort ();\n+  gcc_assert (temp);\n   return temp;\n }\n \f\n@@ -2649,7 +2639,7 @@ expand_mult_const (enum machine_mode mode, rtx op0, HOST_WIDE_INT val,\n       val_so_far = 1;\n     }\n   else\n-    abort ();\n+    gcc_unreachable ();\n \n   for (opno = 1; opno < alg->ops; opno++)\n     {\n@@ -2727,7 +2717,7 @@ expand_mult_const (enum machine_mode mode, rtx op0, HOST_WIDE_INT val,\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n \n       /* Write a REG_EQUAL note on the last insn so that we can cse\n@@ -2762,8 +2752,7 @@ expand_mult_const (enum machine_mode mode, rtx op0, HOST_WIDE_INT val,\n      in the result mode, to avoid sign-/zero-extension confusion.  */\n   val &= GET_MODE_MASK (mode);\n   val_so_far &= GET_MODE_MASK (mode);\n-  if (val != val_so_far)\n-    abort ();\n+  gcc_assert (val == val_so_far);\n \n   return accum;\n }\n@@ -2848,8 +2837,7 @@ expand_mult (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n \t\t      && flag_trapv && (GET_MODE_CLASS(mode) == MODE_INT)\n \t\t      ? smulv_optab : smul_optab,\n \t\t      op0, op1, target, unsignedp, OPTAB_LIB_WIDEN);\n-  if (op0 == 0)\n-    abort ();\n+  gcc_assert (op0);\n   return op0;\n }\n \f\n@@ -2893,18 +2881,15 @@ choose_multiplier (unsigned HOST_WIDE_INT d, int n, int precision,\n   /* lgup = ceil(log2(divisor)); */\n   lgup = ceil_log2 (d);\n \n-  if (lgup > n)\n-    abort ();\n+  gcc_assert (lgup <= n);\n \n   pow = n + lgup;\n   pow2 = n + lgup - precision;\n \n-  if (pow == 2 * HOST_BITS_PER_WIDE_INT)\n-    {\n-      /* We could handle this with some effort, but this case is much better\n-\t handled directly with a scc insn, so rely on caller using that.  */\n-      abort ();\n-    }\n+  /* We could handle this with some effort, but this case is much\n+     better handled directly with a scc insn, so rely on caller using\n+     that.  */\n+  gcc_assert (pow != 2 * HOST_BITS_PER_WIDE_INT);\n \n   /* mlow = 2^(N + lgup)/d */\n  if (pow >= HOST_BITS_PER_WIDE_INT)\n@@ -2928,13 +2913,11 @@ choose_multiplier (unsigned HOST_WIDE_INT d, int n, int precision,\n   div_and_round_double (TRUNC_DIV_EXPR, 1, nl, nh, d, (HOST_WIDE_INT) 0,\n \t\t\t&mhigh_lo, &mhigh_hi, &dummy1, &dummy2);\n \n-  if (mhigh_hi && nh - d >= d)\n-    abort ();\n-  if (mhigh_hi > 1 || mlow_hi > 1)\n-    abort ();\n+  gcc_assert (!mhigh_hi || nh - d < d);\n+  gcc_assert (mhigh_hi <= 1 && mlow_hi <= 1);\n   /* Assert that mlow < mhigh.  */\n-  if (! (mlow_hi < mhigh_hi || (mlow_hi == mhigh_hi && mlow_lo < mhigh_lo)))\n-    abort ();\n+  gcc_assert (mlow_hi < mhigh_hi\n+\t      || (mlow_hi == mhigh_hi && mlow_lo < mhigh_lo));\n \n   /* If precision == N, then mlow, mhigh exceed 2^N\n      (but they do not exceed 2^(N+1)).  */\n@@ -3156,8 +3139,7 @@ expand_mult_highpart (enum machine_mode mode, rtx op0,\n   rtx op1, tem;\n \n   /* We can't support modes wider than HOST_BITS_PER_INT.  */\n-  if (GET_MODE_BITSIZE (mode) > HOST_BITS_PER_WIDE_INT)\n-    abort ();\n+  gcc_assert (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT);\n \n   op1 = gen_int_mode (cnst1, wider_mode);\n   cnst1 &= GET_MODE_MASK (mode);\n@@ -3662,8 +3644,7 @@ expand_divmod (int rem_flag, enum tree_code code, enum machine_mode mode,\n \t\t\t    mh = choose_multiplier (d >> pre_shift, size,\n \t\t\t\t\t\t    size - pre_shift,\n \t\t\t\t\t\t    &ml, &post_shift, &dummy);\n-\t\t\t    if (mh)\n-\t\t\t      abort ();\n+\t\t\t    gcc_assert (!mh);\n \t\t\t  }\n \t\t\telse\n \t\t\t  pre_shift = 0;\n@@ -3939,8 +3920,7 @@ expand_divmod (int rem_flag, enum tree_code code, enum machine_mode mode,\n \n \t\t    mh = choose_multiplier (d, size, size - 1,\n \t\t\t\t\t    &ml, &post_shift, &lgup);\n-\t\t    if (mh)\n-\t\t      abort ();\n+\t\t    gcc_assert (!mh);\n \n \t\t    if (post_shift < BITS_PER_WORD\n \t\t\t&& size - 1 < BITS_PER_WORD)\n@@ -4398,7 +4378,7 @@ expand_divmod (int rem_flag, enum tree_code code, enum machine_mode mode,\n \treturn gen_lowpart (mode, rem_flag ? remainder : quotient);\n \n       default:\n-\tabort ();\n+\tgcc_unreachable ();\n       }\n \n   if (quotient == 0)\n@@ -4899,20 +4879,23 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n \t= compare_from_rtx (op0, op1, code, unsignedp, mode, NULL_RTX);\n       if (CONSTANT_P (comparison))\n \t{\n-\t  if (GET_CODE (comparison) == CONST_INT)\n+\t  switch (GET_CODE (comparison))\n \t    {\n+\t    case CONST_INT:\n \t      if (comparison == const0_rtx)\n \t\treturn const0_rtx;\n-\t    }\n+\t      break;\n+\t      \n #ifdef FLOAT_STORE_FLAG_VALUE\n-\t  else if (GET_CODE (comparison) == CONST_DOUBLE)\n-\t    {\n+\t    case CONST_DOUBLE:\n \t      if (comparison == CONST0_RTX (GET_MODE (comparison)))\n \t\treturn const0_rtx;\n-\t    }\n+\t      break;\n #endif\n-\t  else\n-\t    abort ();\n+\t    default:\n+\t      gcc_unreachable ();\n+\t    }\n+\t  \n \t  if (normalizep == 1)\n \t    return const1_rtx;\n \t  if (normalizep == -1)\n@@ -4987,14 +4970,14 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n \t    op0 = expand_shift (RSHIFT_EXPR, compare_mode, op0,\n \t\t\t\tsize_int (GET_MODE_BITSIZE (compare_mode) - 1),\n \t\t\t\tsubtarget, normalizep == 1);\n-\t  else if (STORE_FLAG_VALUE & 1)\n+\t  else\n \t    {\n+\t      gcc_assert (STORE_FLAG_VALUE & 1);\n+\t      \n \t      op0 = expand_and (compare_mode, op0, const1_rtx, subtarget);\n \t      if (normalizep == -1)\n \t\top0 = expand_unop (compare_mode, neg_optab, op0, op0, 0);\n \t    }\n-\t  else\n-\t    abort ();\n \n \t  /* If we were converting to a smaller mode, do the\n \t     conversion now.  */\n@@ -5262,19 +5245,17 @@ do_cmp_and_jump (rtx arg1, rtx arg2, enum rtx_code op, enum machine_mode mode,\n \t  /* do_jump_by_parts_equality_rtx compares with zero.  Luckily\n \t     that's the only equality operations we do */\n \tcase EQ:\n-\t  if (arg2 != const0_rtx || mode != GET_MODE(arg1))\n-\t    abort ();\n+\t  gcc_assert (arg2 == const0_rtx && mode == GET_MODE(arg1));\n \t  do_jump_by_parts_equality_rtx (arg1, label2, label);\n \t  break;\n \n \tcase NE:\n-\t  if (arg2 != const0_rtx || mode != GET_MODE(arg1))\n-\t    abort ();\n+\t  gcc_assert (arg2 == const0_rtx && mode == GET_MODE(arg1));\n \t  do_jump_by_parts_equality_rtx (arg1, label, label2);\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n \n       emit_label (label2);"}, {"sha": "40beef3413eaa9d3cf63e034cfecd8bcce66e1b8", "filename": "gcc/expr.c", "status": "modified", "additions": 824, "deletions": 871, "changes": 1695, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b0264cb4d7a017784253061843a52f7776a3942/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=5b0264cb4d7a017784253061843a52f7776a3942", "patch": "@@ -335,8 +335,7 @@ convert_move (rtx to, rtx from, int unsignedp)\n \t\t\t      : (unsignedp ? ZERO_EXTEND : SIGN_EXTEND));\n \n \n-  if (to_real != from_real)\n-    abort ();\n+  gcc_assert (to_real == from_real);\n \n   /* If the source and destination are already the same, then there's\n      nothing to do.  */\n@@ -353,8 +352,7 @@ convert_move (rtx to, rtx from, int unsignedp)\n       && SUBREG_PROMOTED_UNSIGNED_P (from) == unsignedp)\n     from = gen_lowpart (to_mode, from), from_mode = to_mode;\n \n-  if (GET_CODE (to) == SUBREG && SUBREG_PROMOTED_VAR_P (to))\n-    abort ();\n+  gcc_assert (GET_CODE (to) != SUBREG || !SUBREG_PROMOTED_VAR_P (to));\n \n   if (to_mode == from_mode\n       || (from_mode == VOIDmode && CONSTANT_P (from)))\n@@ -365,8 +363,7 @@ convert_move (rtx to, rtx from, int unsignedp)\n \n   if (VECTOR_MODE_P (to_mode) || VECTOR_MODE_P (from_mode))\n     {\n-      if (GET_MODE_BITSIZE (from_mode) != GET_MODE_BITSIZE (to_mode))\n-\tabort ();\n+      gcc_assert (GET_MODE_BITSIZE (from_mode) == GET_MODE_BITSIZE (to_mode));\n \n       if (VECTOR_MODE_P (to_mode))\n \tfrom = simplify_gen_subreg (to_mode, from, GET_MODE (from), 0);\n@@ -389,12 +386,13 @@ convert_move (rtx to, rtx from, int unsignedp)\n       rtx value, insns;\n       convert_optab tab;\n \n+      gcc_assert (GET_MODE_PRECISION (from_mode)\n+\t\t  != GET_MODE_PRECISION (to_mode));\n+      \n       if (GET_MODE_PRECISION (from_mode) < GET_MODE_PRECISION (to_mode))\n \ttab = sext_optab;\n-      else if (GET_MODE_PRECISION (from_mode) > GET_MODE_PRECISION (to_mode))\n-\ttab = trunc_optab;\n       else\n-\tabort ();\n+\ttab = trunc_optab;\n \n       /* Try converting directly if the insn is supported.  */\n \n@@ -409,9 +407,8 @@ convert_move (rtx to, rtx from, int unsignedp)\n       /* Otherwise use a libcall.  */\n       libcall = tab->handlers[to_mode][from_mode].libfunc;\n \n-      if (!libcall)\n-\t/* This conversion is not implemented yet.  */\n-\tabort ();\n+      /* Is this conversion implemented yet?  */\n+      gcc_assert (libcall);\n \n       start_sequence ();\n       value = emit_library_call_value (libcall, NULL_RTX, LCT_CONST, to_mode,\n@@ -433,9 +430,8 @@ convert_move (rtx to, rtx from, int unsignedp)\n       enum machine_mode full_mode\n \t= smallest_mode_for_size (GET_MODE_BITSIZE (to_mode), MODE_INT);\n \n-      if (trunc_optab->handlers[to_mode][full_mode].insn_code\n-\t  == CODE_FOR_nothing)\n-\tabort ();\n+      gcc_assert (trunc_optab->handlers[to_mode][full_mode].insn_code\n+\t\t  != CODE_FOR_nothing);\n \n       if (full_mode != from_mode)\n \tfrom = convert_to_mode (full_mode, from, unsignedp);\n@@ -448,9 +444,8 @@ convert_move (rtx to, rtx from, int unsignedp)\n       enum machine_mode full_mode\n \t= smallest_mode_for_size (GET_MODE_BITSIZE (from_mode), MODE_INT);\n \n-      if (sext_optab->handlers[full_mode][from_mode].insn_code\n-\t  == CODE_FOR_nothing)\n-\tabort ();\n+      gcc_assert (sext_optab->handlers[full_mode][from_mode].insn_code\n+\t\t  != CODE_FOR_nothing);\n \n       emit_unop_insn (sext_optab->handlers[full_mode][from_mode].insn_code,\n \t\t      to, from, UNKNOWN);\n@@ -557,8 +552,7 @@ convert_move (rtx to, rtx from, int unsignedp)\n \t  int index = (WORDS_BIG_ENDIAN ? nwords - i - 1 : i);\n \t  rtx subword = operand_subword (to, index, 1, to_mode);\n \n-\t  if (subword == 0)\n-\t    abort ();\n+\t  gcc_assert (subword);\n \n \t  if (fill_value != subword)\n \t    emit_move_insn (subword, fill_value);\n@@ -683,7 +677,7 @@ convert_move (rtx to, rtx from, int unsignedp)\n     }\n \n   /* Mode combination is not recognized.  */\n-  abort ();\n+  gcc_unreachable ();\n }\n \n /* Return an rtx for a value that would result\n@@ -797,8 +791,7 @@ convert_modes (enum machine_mode mode, enum machine_mode oldmode, rtx x, int uns\n      subreg operation.  */\n   if (VECTOR_MODE_P (mode) && GET_MODE (x) == VOIDmode)\n     {\n-      if (GET_MODE_BITSIZE (mode) != GET_MODE_BITSIZE (oldmode))\n-\tabort ();\n+      gcc_assert (GET_MODE_BITSIZE (mode) == GET_MODE_BITSIZE (oldmode));\n       return simplify_gen_subreg (mode, x, oldmode, 0);\n     }\n \n@@ -964,15 +957,13 @@ move_by_pieces (rtx to, rtx from, unsigned HOST_WIDE_INT len,\n     }\n \n   /* The code above should have handled everything.  */\n-  if (data.len > 0)\n-    abort ();\n+  gcc_assert (!data.len);\n \n   if (endp)\n     {\n       rtx to1;\n \n-      if (data.reverse)\n-\tabort ();\n+      gcc_assert (!data.reverse);\n       if (data.autinc_to)\n \t{\n \t  if (endp == 2)\n@@ -1045,8 +1036,7 @@ move_by_pieces_ninsns (unsigned HOST_WIDE_INT l, unsigned int align,\n       max_size = GET_MODE_SIZE (mode);\n     }\n \n-  if (l)\n-    abort ();\n+  gcc_assert (!l);\n   return n_insns;\n }\n \n@@ -1095,7 +1085,7 @@ move_by_pieces_1 (rtx (*genfun) (rtx, ...), enum machine_mode mode,\n #ifdef PUSH_ROUNDING\n \t  emit_single_push_insn (mode, from1, NULL);\n #else\n-\t  abort ();\n+\t  gcc_unreachable ();\n #endif\n \t}\n \n@@ -1149,17 +1139,14 @@ emit_block_move (rtx x, rtx y, rtx size, enum block_op_methods method)\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   align = MIN (MEM_ALIGN (x), MEM_ALIGN (y));\n \n-  if (!MEM_P (x))\n-    abort ();\n-  if (!MEM_P (y))\n-    abort ();\n-  if (size == 0)\n-    abort ();\n+  gcc_assert (MEM_P (x));\n+  gcc_assert (MEM_P (y));\n+  gcc_assert (size);\n \n   /* Make sure we've got BLKmode addresses; store_one_arg can decide that\n      block copy is more efficient for other large modes, e.g. DCmode.  */\n@@ -1530,8 +1517,7 @@ move_block_from_reg (int regno, rtx x, int nregs)\n     {\n       rtx tem = operand_subword (x, i, 1, BLKmode);\n \n-      if (tem == 0)\n-\tabort ();\n+      gcc_assert (tem);\n \n       emit_move_insn (tem, gen_rtx_REG (word_mode, regno + i));\n     }\n@@ -1549,8 +1535,7 @@ gen_group_rtx (rtx orig)\n   int i, length;\n   rtx *tmps;\n \n-  if (GET_CODE (orig) != PARALLEL)\n-    abort ();\n+  gcc_assert (GET_CODE (orig) == PARALLEL);\n \n   length = XVECLEN (orig, 0);\n   tmps = alloca (sizeof (rtx) * length);\n@@ -1583,8 +1568,7 @@ emit_group_load (rtx dst, rtx orig_src, tree type ATTRIBUTE_UNUSED, int ssize)\n   rtx *tmps, src;\n   int start, i;\n \n-  if (GET_CODE (dst) != PARALLEL)\n-    abort ();\n+  gcc_assert (GET_CODE (dst) == PARALLEL);\n \n   /* Check for a NULL entry, used to indicate that the parameter goes\n      both on the stack and in registers.  */\n@@ -1618,8 +1602,7 @@ emit_group_load (rtx dst, rtx orig_src, tree type ATTRIBUTE_UNUSED, int ssize)\n \t      )\n \t    shift = (bytelen - (ssize - bytepos)) * BITS_PER_UNIT;\n \t  bytelen = ssize - bytepos;\n-\t  if (bytelen <= 0)\n-\t    abort ();\n+\t  gcc_assert (bytelen > 0);\n \t}\n \n       /* If we won't be loading directly from memory, protect the real source\n@@ -1668,14 +1651,15 @@ emit_group_load (rtx dst, rtx orig_src, tree type ATTRIBUTE_UNUSED, int ssize)\n \t\t\t\t\t     (bytepos % slen0) * BITS_PER_UNIT,\n \t\t\t\t\t     1, NULL_RTX, mode, mode);\n \t    }\n-\t  else if (bytepos == 0)\n+\t  else\n \t    {\n-\t      rtx mem = assign_stack_temp (GET_MODE (src), slen, 0);\n+\t      rtx mem;\n+\t      \n+\t      gcc_assert (!bytepos);\n+\t      mem = assign_stack_temp (GET_MODE (src), slen, 0);\n \t      emit_move_insn (mem, src);\n \t      tmps[i] = adjust_address (mem, mode, 0);\n \t    }\n-\t  else\n-\t    abort ();\n \t}\n       /* FIXME: A SIMD parallel will eventually lead to a subreg of a\n \t SIMD register, which is currently broken.  While we get GCC\n@@ -1719,10 +1703,9 @@ emit_group_move (rtx dst, rtx src)\n {\n   int i;\n \n-  if (GET_CODE (src) != PARALLEL\n-      || GET_CODE (dst) != PARALLEL\n-      || XVECLEN (src, 0) != XVECLEN (dst, 0))\n-    abort ();\n+  gcc_assert (GET_CODE (src) == PARALLEL\n+\t      && GET_CODE (dst) == PARALLEL\n+\t      && XVECLEN (src, 0) == XVECLEN (dst, 0));\n \n   /* Skip first entry if NULL.  */\n   for (i = XEXP (XVECEXP (src, 0, 0), 0) ? 0 : 1; i < XVECLEN (src, 0); i++)\n@@ -1741,8 +1724,7 @@ emit_group_store (rtx orig_dst, rtx src, tree type ATTRIBUTE_UNUSED, int ssize)\n   rtx *tmps, dst;\n   int start, i;\n \n-  if (GET_CODE (src) != PARALLEL)\n-    abort ();\n+  gcc_assert (GET_CODE (src) == PARALLEL);\n \n   /* Check for a NULL entry, used to indicate that the parameter goes\n      both on the stack and in registers.  */\n@@ -1829,17 +1811,16 @@ emit_group_store (rtx orig_dst, rtx src, tree type ATTRIBUTE_UNUSED, int ssize)\n \t      bytepos -= GET_MODE_SIZE (GET_MODE (XEXP (dst, 0)));\n \t      dest = XEXP (dst, 1);\n \t    }\n-\t  else if (bytepos == 0 && XVECLEN (src, 0))\n+\t  else\n \t    {\n+\t      gcc_assert (bytepos == 0 && XVECLEN (src, 0));\n \t      dest = assign_stack_temp (GET_MODE (dest),\n \t\t\t\t        GET_MODE_SIZE (GET_MODE (dest)), 0);\n \t      emit_move_insn (adjust_address (dest, GET_MODE (tmps[i]), bytepos),\n \t\t\t      tmps[i]);\n \t      dst = dest;\n \t      break;\n \t    }\n-\t  else\n-\t    abort ();\n \t}\n \n       /* Optimize the access just a bit.  */\n@@ -1947,10 +1928,8 @@ copy_blkmode_from_reg (rtx tgtblk, rtx srcreg, tree type)\n void\n use_reg (rtx *call_fusage, rtx reg)\n {\n-  if (!REG_P (reg)\n-      || REGNO (reg) >= FIRST_PSEUDO_REGISTER)\n-    abort ();\n-\n+  gcc_assert (REG_P (reg) && REGNO (reg) < FIRST_PSEUDO_REGISTER);\n+  \n   *call_fusage\n     = gen_rtx_EXPR_LIST (VOIDmode,\n \t\t\t gen_rtx_USE (VOIDmode, reg), *call_fusage);\n@@ -1964,8 +1943,7 @@ use_regs (rtx *call_fusage, int regno, int nregs)\n {\n   int i;\n \n-  if (regno + nregs > FIRST_PSEUDO_REGISTER)\n-    abort ();\n+  gcc_assert (regno + nregs <= FIRST_PSEUDO_REGISTER);\n \n   for (i = 0; i < nregs; i++)\n     use_reg (call_fusage, regno_reg_rtx[regno + i]);\n@@ -2081,8 +2059,7 @@ can_store_by_pieces (unsigned HOST_WIDE_INT len,\n \t}\n \n       /* The code above should have handled everything.  */\n-      if (l != 0)\n-\tabort ();\n+      gcc_assert (!l);\n     }\n \n   return 1;\n@@ -2105,13 +2082,11 @@ store_by_pieces (rtx to, unsigned HOST_WIDE_INT len,\n \n   if (len == 0)\n     {\n-      if (endp == 2)\n-\tabort ();\n+      gcc_assert (endp != 2);\n       return to;\n     }\n \n-  if (! STORE_BY_PIECES_P (len, align))\n-    abort ();\n+  gcc_assert (STORE_BY_PIECES_P (len, align));\n   data.constfun = constfun;\n   data.constfundata = constfundata;\n   data.len = len;\n@@ -2121,8 +2096,7 @@ store_by_pieces (rtx to, unsigned HOST_WIDE_INT len,\n     {\n       rtx to1;\n \n-      if (data.reverse)\n-\tabort ();\n+      gcc_assert (!data.reverse);\n       if (data.autinc_to)\n \t{\n \t  if (endp == 2)\n@@ -2271,8 +2245,7 @@ store_by_pieces_1 (struct store_by_pieces *data ATTRIBUTE_UNUSED,\n     }\n \n   /* The code above should have handled everything.  */\n-  if (data->len != 0)\n-    abort ();\n+  gcc_assert (!data->len);\n }\n \n /* Subroutine of store_by_pieces_1.  Store as many bytes as appropriate\n@@ -2508,8 +2481,8 @@ emit_move_insn (rtx x, rtx y)\n   rtx y_cst = NULL_RTX;\n   rtx last_insn, set;\n \n-  if (mode == BLKmode || (GET_MODE (y) != mode && GET_MODE (y) != VOIDmode))\n-    abort ();\n+  gcc_assert (mode != BLKmode\n+\t      && (GET_MODE (y) == mode || GET_MODE (y) == VOIDmode));\n \n   if (CONSTANT_P (y))\n     {\n@@ -2547,8 +2520,7 @@ emit_move_insn (rtx x, rtx y)\n \t      && CONSTANT_ADDRESS_P (XEXP (y, 0)))))\n     y = validize_mem (y);\n \n-  if (mode == BLKmode)\n-    abort ();\n+  gcc_assert (mode != BLKmode);\n \n   last_insn = emit_move_insn_1 (x, y);\n \n@@ -2572,8 +2544,7 @@ emit_move_insn_1 (rtx x, rtx y)\n   enum machine_mode submode;\n   enum mode_class class = GET_MODE_CLASS (mode);\n \n-  if ((unsigned int) mode >= (unsigned int) MAX_MACHINE_MODE)\n-    abort ();\n+  gcc_assert ((unsigned int) mode < (unsigned int) MAX_MACHINE_MODE);\n \n   if (mov_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)\n     return\n@@ -2753,8 +2724,7 @@ emit_move_insn_1 (rtx x, rtx y)\n \t  if (GET_MODE_SIZE (tmode) == GET_MODE_SIZE (mode))\n \t    break;\n \n-      if (tmode == VOIDmode)\n-\tabort ();\n+      gcc_assert (tmode != VOIDmode);\n \n       /* Get X and Y in TMODE.  We can't use gen_lowpart here because it\n \t may call change_address which is not appropriate if we were\n@@ -2803,13 +2773,15 @@ emit_move_insn_1 (rtx x, rtx y)\n   /* This will handle any multi-word or full-word mode that lacks a move_insn\n      pattern.  However, you will get better code if you define such patterns,\n      even if they must turn into multiple assembler instructions.  */\n-  else if (GET_MODE_SIZE (mode) >= UNITS_PER_WORD)\n+  else\n     {\n       rtx last_insn = 0;\n       rtx seq, inner;\n       int need_clobber;\n       int i;\n-\n+      \n+      gcc_assert (GET_MODE_SIZE (mode) >= UNITS_PER_WORD);\n+      \n #ifdef PUSH_ROUNDING\n \n       /* If X is a push on the stack, do the push now and replace\n@@ -2883,8 +2855,7 @@ emit_move_insn_1 (rtx x, rtx y)\n \t  else if (ypart == 0)\n \t    ypart = operand_subword_force (y, i, mode);\n \n-\t  if (xpart == 0 || ypart == 0)\n-\t    abort ();\n+\t  gcc_assert (xpart && ypart);\n \n \t  need_clobber |= (GET_CODE (xpart) == SUBREG);\n \n@@ -2907,8 +2878,6 @@ emit_move_insn_1 (rtx x, rtx y)\n \n       return last_insn;\n     }\n-  else\n-    abort ();\n }\n \n /* If Y is representable exactly in a narrower mode, and the target can\n@@ -3192,8 +3161,7 @@ emit_push_insn (rtx x, enum machine_mode mode, tree type, rtx size,\n       else\n \toffset = used % (PARM_BOUNDARY / BITS_PER_UNIT);\n \n-      if (size == 0)\n-\tabort ();\n+      gcc_assert (size);\n \n       used -= offset;\n \n@@ -3490,8 +3458,7 @@ expand_assignment (tree to, tree from, int want_value)\n \t{\n \t  rtx offset_rtx = expand_expr (offset, NULL_RTX, VOIDmode, EXPAND_SUM);\n \n-\t  if (!MEM_P (to_rtx))\n-\t    abort ();\n+\t  gcc_assert (MEM_P (to_rtx));\n \n #ifdef POINTERS_EXTEND_UNSIGNED\n \t  if (GET_MODE (offset_rtx) != Pmode)\n@@ -3821,8 +3788,7 @@ store_expr (tree exp, rtx target, int want_value)\n       /* C++ can generate ?: expressions with a throw expression in one\n \t branch and an rvalue in the other. Here, we resolve attempts to\n \t store the throw expression's nonexistent result.  */\n-      if (want_value)\n-\tabort ();\n+      gcc_assert (!want_value);\n       expand_expr (exp, const0_rtx, VOIDmode, 0);\n       return NULL_RTX;\n     }\n@@ -4304,7 +4270,7 @@ count_type_elements (tree type)\n     case FUNCTION_TYPE:\n     case LANG_TYPE:\n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n }\n \n@@ -4397,721 +4363,731 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n   HOST_WIDE_INT exp_size = int_size_in_bytes (type);\n #endif\n \n-  if (TREE_CODE (type) == RECORD_TYPE || TREE_CODE (type) == UNION_TYPE\n-      || TREE_CODE (type) == QUAL_UNION_TYPE)\n+  switch (TREE_CODE (type))\n     {\n-      tree elt;\n-\n-      /* If size is zero or the target is already cleared, do nothing.  */\n-      if (size == 0 || cleared)\n-\tcleared = 1;\n-      /* We either clear the aggregate or indicate the value is dead.  */\n-      else if ((TREE_CODE (type) == UNION_TYPE\n-\t\t|| TREE_CODE (type) == QUAL_UNION_TYPE)\n-\t       && ! CONSTRUCTOR_ELTS (exp))\n-\t/* If the constructor is empty, clear the union.  */\n-\t{\n-\t  clear_storage (target, expr_size (exp));\n-\t  cleared = 1;\n-\t}\n-\n-      /* If we are building a static constructor into a register,\n-\t set the initial value as zero so we can fold the value into\n-\t a constant.  But if more than one register is involved,\n-\t this probably loses.  */\n-      else if (REG_P (target) && TREE_STATIC (exp)\n-\t       && GET_MODE_SIZE (GET_MODE (target)) <= UNITS_PER_WORD)\n-\t{\n-\t  emit_move_insn (target, CONST0_RTX (GET_MODE (target)));\n-\t  cleared = 1;\n-\t}\n+    case RECORD_TYPE:\n+    case UNION_TYPE:\n+    case QUAL_UNION_TYPE:\n+      {\n+\ttree elt;\n \n-      /* If the constructor has fewer fields than the structure\n-\t or if we are initializing the structure to mostly zeros,\n-\t clear the whole structure first.  Don't do this if TARGET is a\n-\t register whose mode size isn't equal to SIZE since clear_storage\n-\t can't handle this case.  */\n-      else if (size > 0\n-\t       && ((list_length (CONSTRUCTOR_ELTS (exp)) != fields_length (type))\n-\t\t   || mostly_zeros_p (exp))\n-\t       && (!REG_P (target)\n-\t\t   || ((HOST_WIDE_INT) GET_MODE_SIZE (GET_MODE (target))\n-\t\t       == size)))\n-\t{\n-\t  clear_storage (target, GEN_INT (size));\n+\t/* If size is zero or the target is already cleared, do nothing.  */\n+\tif (size == 0 || cleared)\n \t  cleared = 1;\n-\t}\n-\n-      if (! cleared)\n-\temit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n-\n-      /* Store each element of the constructor into\n-\t the corresponding field of TARGET.  */\n-\n-      for (elt = CONSTRUCTOR_ELTS (exp); elt; elt = TREE_CHAIN (elt))\n-\t{\n-\t  tree field = TREE_PURPOSE (elt);\n-\t  tree value = TREE_VALUE (elt);\n-\t  enum machine_mode mode;\n-\t  HOST_WIDE_INT bitsize;\n-\t  HOST_WIDE_INT bitpos = 0;\n-\t  tree offset;\n-\t  rtx to_rtx = target;\n-\n-\t  /* Just ignore missing fields.\n-\t     We cleared the whole structure, above,\n-\t     if any fields are missing.  */\n-\t  if (field == 0)\n-\t    continue;\n-\n-\t  if (cleared && initializer_zerop (value))\n-\t    continue;\n-\n-\t  if (host_integerp (DECL_SIZE (field), 1))\n-\t    bitsize = tree_low_cst (DECL_SIZE (field), 1);\n-\t  else\n-\t    bitsize = -1;\n-\n-\t  mode = DECL_MODE (field);\n-\t  if (DECL_BIT_FIELD (field))\n-\t    mode = VOIDmode;\n+\t/* We either clear the aggregate or indicate the value is dead.  */\n+\telse if ((TREE_CODE (type) == UNION_TYPE\n+\t\t  || TREE_CODE (type) == QUAL_UNION_TYPE)\n+\t\t && ! CONSTRUCTOR_ELTS (exp))\n+\t  /* If the constructor is empty, clear the union.  */\n+\t  {\n+\t    clear_storage (target, expr_size (exp));\n+\t    cleared = 1;\n+\t  }\n \n-\t  offset = DECL_FIELD_OFFSET (field);\n-\t  if (host_integerp (offset, 0)\n-\t      && host_integerp (bit_position (field), 0))\n-\t    {\n-\t      bitpos = int_bit_position (field);\n-\t      offset = 0;\n-\t    }\n-\t  else\n-\t    bitpos = tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 0);\n+\t/* If we are building a static constructor into a register,\n+\t   set the initial value as zero so we can fold the value into\n+\t   a constant.  But if more than one register is involved,\n+\t   this probably loses.  */\n+\telse if (REG_P (target) && TREE_STATIC (exp)\n+\t\t && GET_MODE_SIZE (GET_MODE (target)) <= UNITS_PER_WORD)\n+\t  {\n+\t    emit_move_insn (target, CONST0_RTX (GET_MODE (target)));\n+\t    cleared = 1;\n+\t  }\n \n-\t  if (offset)\n-\t    {\n-\t      rtx offset_rtx;\n+        /* If the constructor has fewer fields than the structure or\n+\t   if we are initializing the structure to mostly zeros, clear\n+\t   the whole structure first.  Don't do this if TARGET is a\n+\t   register whose mode size isn't equal to SIZE since\n+\t   clear_storage can't handle this case.  */\n+\telse if (size > 0\n+\t\t && ((list_length (CONSTRUCTOR_ELTS (exp))\n+\t\t      != fields_length (type))\n+\t\t     || mostly_zeros_p (exp))\n+\t\t && (!REG_P (target)\n+\t\t     || ((HOST_WIDE_INT) GET_MODE_SIZE (GET_MODE (target))\n+\t\t\t == size)))\n+\t  {\n+\t    clear_storage (target, GEN_INT (size));\n+\t    cleared = 1;\n+\t  }\n \n-\t      offset\n-\t\t= SUBSTITUTE_PLACEHOLDER_IN_EXPR (offset,\n-\t\t\t\t\t\t  make_tree (TREE_TYPE (exp),\n-\t\t\t\t\t\t\t     target));\n+\tif (! cleared)\n+\t  emit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n \n-\t      offset_rtx = expand_expr (offset, NULL_RTX, VOIDmode, 0);\n-\t      if (!MEM_P (to_rtx))\n-\t\tabort ();\n+\t/* Store each element of the constructor into the\n+\t   corresponding field of TARGET.  */\n \n+\tfor (elt = CONSTRUCTOR_ELTS (exp); elt; elt = TREE_CHAIN (elt))\n+\t  {\n+\t    tree field = TREE_PURPOSE (elt);\n+\t    tree value = TREE_VALUE (elt);\n+\t    enum machine_mode mode;\n+\t    HOST_WIDE_INT bitsize;\n+\t    HOST_WIDE_INT bitpos = 0;\n+\t    tree offset;\n+\t    rtx to_rtx = target;\n+\t    \n+\t    /* Just ignore missing fields.  We cleared the whole\n+\t       structure, above, if any fields are missing.  */\n+\t    if (field == 0)\n+\t      continue;\n+\t    \n+\t    if (cleared && initializer_zerop (value))\n+\t      continue;\n+\t    \n+\t    if (host_integerp (DECL_SIZE (field), 1))\n+\t      bitsize = tree_low_cst (DECL_SIZE (field), 1);\n+\t    else\n+\t      bitsize = -1;\n+\t    \n+\t    mode = DECL_MODE (field);\n+\t    if (DECL_BIT_FIELD (field))\n+\t      mode = VOIDmode;\n+\t    \n+\t    offset = DECL_FIELD_OFFSET (field);\n+\t    if (host_integerp (offset, 0)\n+\t\t&& host_integerp (bit_position (field), 0))\n+\t      {\n+\t\tbitpos = int_bit_position (field);\n+\t\toffset = 0;\n+\t      }\n+\t    else\n+\t      bitpos = tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 0);\n+\t    \n+\t    if (offset)\n+\t      {\n+\t\trtx offset_rtx;\n+\t\t\n+\t\toffset\n+\t\t  = SUBSTITUTE_PLACEHOLDER_IN_EXPR (offset,\n+\t\t\t\t\t\t    make_tree (TREE_TYPE (exp),\n+\t\t\t\t\t\t\t       target));\n+\n+\t\toffset_rtx = expand_expr (offset, NULL_RTX, VOIDmode, 0);\n+\t\tgcc_assert (MEM_P (to_rtx));\n+\t\t\n #ifdef POINTERS_EXTEND_UNSIGNED\n-\t      if (GET_MODE (offset_rtx) != Pmode)\n-\t\toffset_rtx = convert_to_mode (Pmode, offset_rtx, 0);\n+\t\tif (GET_MODE (offset_rtx) != Pmode)\n+\t\t  offset_rtx = convert_to_mode (Pmode, offset_rtx, 0);\n #else\n-\t      if (GET_MODE (offset_rtx) != ptr_mode)\n-\t\toffset_rtx = convert_to_mode (ptr_mode, offset_rtx, 0);\n+\t\tif (GET_MODE (offset_rtx) != ptr_mode)\n+\t\t  offset_rtx = convert_to_mode (ptr_mode, offset_rtx, 0);\n #endif\n \n-\t      to_rtx = offset_address (to_rtx, offset_rtx,\n-\t\t\t\t       highest_pow2_factor (offset));\n-\t    }\n+\t\tto_rtx = offset_address (to_rtx, offset_rtx,\n+\t\t\t\t\t highest_pow2_factor (offset));\n+\t      }\n \n #ifdef WORD_REGISTER_OPERATIONS\n-\t  /* If this initializes a field that is smaller than a word, at the\n-\t     start of a word, try to widen it to a full word.\n-\t     This special case allows us to output C++ member function\n-\t     initializations in a form that the optimizers can understand.  */\n-\t  if (REG_P (target)\n-\t      && bitsize < BITS_PER_WORD\n-\t      && bitpos % BITS_PER_WORD == 0\n-\t      && GET_MODE_CLASS (mode) == MODE_INT\n-\t      && TREE_CODE (value) == INTEGER_CST\n-\t      && exp_size >= 0\n-\t      && bitpos + BITS_PER_WORD <= exp_size * BITS_PER_UNIT)\n-\t    {\n-\t      tree type = TREE_TYPE (value);\n-\n-\t      if (TYPE_PRECISION (type) < BITS_PER_WORD)\n-\t\t{\n-\t\t  type = lang_hooks.types.type_for_size\n-\t\t    (BITS_PER_WORD, TYPE_UNSIGNED (type));\n-\t\t  value = convert (type, value);\n-\t\t}\n-\n-\t      if (BYTES_BIG_ENDIAN)\n-\t\tvalue\n-\t\t  = fold (build2 (LSHIFT_EXPR, type, value,\n-\t\t\t\t  build_int_cst (NULL_TREE,\n-\t\t\t\t\t\t BITS_PER_WORD - bitsize)));\n-\t      bitsize = BITS_PER_WORD;\n-\t      mode = word_mode;\n-\t    }\n+\t    /* If this initializes a field that is smaller than a\n+\t       word, at the start of a word, try to widen it to a full\n+\t       word.  This special case allows us to output C++ member\n+\t       function initializations in a form that the optimizers\n+\t       can understand.  */\n+\t    if (REG_P (target)\n+\t\t&& bitsize < BITS_PER_WORD\n+\t\t&& bitpos % BITS_PER_WORD == 0\n+\t\t&& GET_MODE_CLASS (mode) == MODE_INT\n+\t\t&& TREE_CODE (value) == INTEGER_CST\n+\t\t&& exp_size >= 0\n+\t\t&& bitpos + BITS_PER_WORD <= exp_size * BITS_PER_UNIT)\n+\t      {\n+\t\ttree type = TREE_TYPE (value);\n+\t\t\n+\t\tif (TYPE_PRECISION (type) < BITS_PER_WORD)\n+\t\t  {\n+\t\t    type = lang_hooks.types.type_for_size\n+\t\t      (BITS_PER_WORD, TYPE_UNSIGNED (type));\n+\t\t    value = convert (type, value);\n+\t\t  }\n+\t\t\n+\t\tif (BYTES_BIG_ENDIAN)\n+\t\t  value\n+\t\t    = fold (build2 (LSHIFT_EXPR, type, value,\n+\t\t\t\t    build_int_cst (NULL_TREE,\n+\t\t\t\t\t\t   BITS_PER_WORD - bitsize)));\n+\t\tbitsize = BITS_PER_WORD;\n+\t\tmode = word_mode;\n+\t      }\n #endif\n \n-\t  if (MEM_P (to_rtx) && !MEM_KEEP_ALIAS_SET_P (to_rtx)\n-\t      && DECL_NONADDRESSABLE_P (field))\n-\t    {\n-\t      to_rtx = copy_rtx (to_rtx);\n-\t      MEM_KEEP_ALIAS_SET_P (to_rtx) = 1;\n-\t    }\n-\n-\t  store_constructor_field (to_rtx, bitsize, bitpos, mode,\n-\t\t\t\t   value, type, cleared,\n-\t\t\t\t   get_alias_set (TREE_TYPE (field)));\n-\t}\n-    }\n-\n-  else if (TREE_CODE (type) == ARRAY_TYPE)\n-    {\n-      tree elt;\n-      int i;\n-      int need_to_clear;\n-      tree domain;\n-      tree elttype = TREE_TYPE (type);\n-      int const_bounds_p;\n-      HOST_WIDE_INT minelt = 0;\n-      HOST_WIDE_INT maxelt = 0;\n-\n-      domain = TYPE_DOMAIN (type);\n-      const_bounds_p = (TYPE_MIN_VALUE (domain)\n-\t\t\t&& TYPE_MAX_VALUE (domain)\n-\t\t\t&& host_integerp (TYPE_MIN_VALUE (domain), 0)\n-\t\t\t&& host_integerp (TYPE_MAX_VALUE (domain), 0));\n-\n-      /* If we have constant bounds for the range of the type, get them.  */\n-      if (const_bounds_p)\n-\t{\n-\t  minelt = tree_low_cst (TYPE_MIN_VALUE (domain), 0);\n-\t  maxelt = tree_low_cst (TYPE_MAX_VALUE (domain), 0);\n-\t}\n-\n-      /* If the constructor has fewer elements than the array,\n-         clear the whole array first.  Similarly if this is\n-         static constructor of a non-BLKmode object.  */\n-      if (cleared)\n-\tneed_to_clear = 0;\n-      else if (REG_P (target) && TREE_STATIC (exp))\n-\tneed_to_clear = 1;\n-      else\n-\t{\n-\t  HOST_WIDE_INT count = 0, zero_count = 0;\n-\t  need_to_clear = ! const_bounds_p;\n-\n-\t  /* This loop is a more accurate version of the loop in\n-\t     mostly_zeros_p (it handles RANGE_EXPR in an index).\n-\t     It is also needed to check for missing elements.  */\n-\t  for (elt = CONSTRUCTOR_ELTS (exp);\n-\t       elt != NULL_TREE && ! need_to_clear;\n-\t       elt = TREE_CHAIN (elt))\n-\t    {\n-\t      tree index = TREE_PURPOSE (elt);\n-\t      HOST_WIDE_INT this_node_count;\n-\n-\t      if (index != NULL_TREE && TREE_CODE (index) == RANGE_EXPR)\n-\t\t{\n-\t\t  tree lo_index = TREE_OPERAND (index, 0);\n-\t\t  tree hi_index = TREE_OPERAND (index, 1);\n-\n-\t\t  if (! host_integerp (lo_index, 1)\n-\t\t      || ! host_integerp (hi_index, 1))\n-\t\t    {\n-\t\t      need_to_clear = 1;\n-\t\t      break;\n-\t\t    }\n-\n-\t\t  this_node_count = (tree_low_cst (hi_index, 1)\n-\t\t\t\t     - tree_low_cst (lo_index, 1) + 1);\n-\t\t}\n-\t      else\n-\t\tthis_node_count = 1;\n-\n-\t      count += this_node_count;\n-\t      if (mostly_zeros_p (TREE_VALUE (elt)))\n-\t\tzero_count += this_node_count;\n-\t    }\n-\n-\t  /* Clear the entire array first if there are any missing elements,\n-\t     or if the incidence of zero elements is >= 75%.  */\n-\t  if (! need_to_clear\n-\t      && (count < maxelt - minelt + 1 || 4 * zero_count >= 3 * count))\n-\t    need_to_clear = 1;\n-\t}\n-\n-      if (need_to_clear && size > 0)\n-\t{\n-\t  if (REG_P (target))\n-\t    emit_move_insn (target,  CONST0_RTX (GET_MODE (target)));\n-\t  else\n-\t    clear_storage (target, GEN_INT (size));\n-\t  cleared = 1;\n-\t}\n-\n-      if (!cleared && REG_P (target))\n-\t/* Inform later passes that the old value is dead.  */\n-\temit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n-\n-      /* Store each element of the constructor into\n-\t the corresponding element of TARGET, determined\n-\t by counting the elements.  */\n-      for (elt = CONSTRUCTOR_ELTS (exp), i = 0;\n-\t   elt;\n-\t   elt = TREE_CHAIN (elt), i++)\n-\t{\n-\t  enum machine_mode mode;\n-\t  HOST_WIDE_INT bitsize;\n-\t  HOST_WIDE_INT bitpos;\n-\t  int unsignedp;\n-\t  tree value = TREE_VALUE (elt);\n-\t  tree index = TREE_PURPOSE (elt);\n-\t  rtx xtarget = target;\n-\n-\t  if (cleared && initializer_zerop (value))\n-\t    continue;\n-\n-\t  unsignedp = TYPE_UNSIGNED (elttype);\n-\t  mode = TYPE_MODE (elttype);\n-\t  if (mode == BLKmode)\n-\t    bitsize = (host_integerp (TYPE_SIZE (elttype), 1)\n-\t\t       ? tree_low_cst (TYPE_SIZE (elttype), 1)\n-\t\t       : -1);\n-\t  else\n-\t    bitsize = GET_MODE_BITSIZE (mode);\n-\n-\t  if (index != NULL_TREE && TREE_CODE (index) == RANGE_EXPR)\n-\t    {\n-\t      tree lo_index = TREE_OPERAND (index, 0);\n-\t      tree hi_index = TREE_OPERAND (index, 1);\n-\t      rtx index_r, pos_rtx;\n-\t      HOST_WIDE_INT lo, hi, count;\n-\t      tree position;\n-\n-\t      /* If the range is constant and \"small\", unroll the loop.  */\n-\t      if (const_bounds_p\n-\t\t  && host_integerp (lo_index, 0)\n-\t\t  && host_integerp (hi_index, 0)\n-\t\t  && (lo = tree_low_cst (lo_index, 0),\n-\t\t      hi = tree_low_cst (hi_index, 0),\n-\t\t      count = hi - lo + 1,\n-\t\t      (!MEM_P (target)\n-\t\t       || count <= 2\n-\t\t       || (host_integerp (TYPE_SIZE (elttype), 1)\n-\t\t\t   && (tree_low_cst (TYPE_SIZE (elttype), 1) * count\n-\t\t\t       <= 40 * 8)))))\n-\t\t{\n-\t\t  lo -= minelt;  hi -= minelt;\n-\t\t  for (; lo <= hi; lo++)\n-\t\t    {\n-\t\t      bitpos = lo * tree_low_cst (TYPE_SIZE (elttype), 0);\n-\n-\t\t      if (MEM_P (target)\n-\t\t\t  && !MEM_KEEP_ALIAS_SET_P (target)\n-\t\t\t  && TREE_CODE (type) == ARRAY_TYPE\n-\t\t\t  && TYPE_NONALIASED_COMPONENT (type))\n-\t\t\t{\n-\t\t\t  target = copy_rtx (target);\n-\t\t\t  MEM_KEEP_ALIAS_SET_P (target) = 1;\n-\t\t\t}\n-\n-\t\t      store_constructor_field\n-\t\t\t(target, bitsize, bitpos, mode, value, type, cleared,\n-\t\t\t get_alias_set (elttype));\n-\t\t    }\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  rtx loop_start = gen_label_rtx ();\n-\t\t  rtx loop_end = gen_label_rtx ();\n-\t\t  tree exit_cond;\n-\n-\t\t  expand_expr (hi_index, NULL_RTX, VOIDmode, 0);\n-\t\t  unsignedp = TYPE_UNSIGNED (domain);\n-\n-\t\t  index = build_decl (VAR_DECL, NULL_TREE, domain);\n-\n-\t\t  index_r\n-\t\t    = gen_reg_rtx (promote_mode (domain, DECL_MODE (index),\n-\t\t\t\t\t\t &unsignedp, 0));\n-\t\t  SET_DECL_RTL (index, index_r);\n-\t\t  store_expr (lo_index, index_r, 0);\n-\n-\t\t  /* Build the head of the loop.  */\n-\t\t  do_pending_stack_adjust ();\n-\t\t  emit_label (loop_start);\n-\n-\t\t  /* Assign value to element index.  */\n-\t\t  position\n-\t\t    = convert (ssizetype,\n-\t\t\t       fold (build2 (MINUS_EXPR, TREE_TYPE (index),\n-\t\t\t\t\t     index, TYPE_MIN_VALUE (domain))));\n-\t\t  position = size_binop (MULT_EXPR, position,\n-\t\t\t\t\t convert (ssizetype,\n-\t\t\t\t\t\t  TYPE_SIZE_UNIT (elttype)));\n-\n-\t\t  pos_rtx = expand_expr (position, 0, VOIDmode, 0);\n-\t\t  xtarget = offset_address (target, pos_rtx,\n-\t\t\t\t\t    highest_pow2_factor (position));\n-\t\t  xtarget = adjust_address (xtarget, mode, 0);\n-\t\t  if (TREE_CODE (value) == CONSTRUCTOR)\n-\t\t    store_constructor (value, xtarget, cleared,\n-\t\t\t\t       bitsize / BITS_PER_UNIT);\n-\t\t  else\n-\t\t    store_expr (value, xtarget, 0);\n-\n-\t\t  /* Generate a conditional jump to exit the loop.  */\n-\t\t  exit_cond = build2 (LT_EXPR, integer_type_node,\n-\t\t\t\t      index, hi_index);\n-\t\t  jumpif (exit_cond, loop_end);\n-\n-\t\t  /* Update the loop counter, and jump to the head of\n-\t\t     the loop.  */\n-\t\t  expand_assignment (index,\n-\t\t\t             build2 (PLUS_EXPR, TREE_TYPE (index),\n-\t\t\t\t\t     index, integer_one_node), 0);\n-\n-\t\t  emit_jump (loop_start);\n-\n-\t\t  /* Build the end of the loop.  */\n-\t\t  emit_label (loop_end);\n-\t\t}\n-\t    }\n-\t  else if ((index != 0 && ! host_integerp (index, 0))\n-\t\t   || ! host_integerp (TYPE_SIZE (elttype), 1))\n-\t    {\n-\t      tree position;\n-\n-\t      if (index == 0)\n-\t\tindex = ssize_int (1);\n-\n-\t      if (minelt)\n-\t\tindex = fold_convert (ssizetype,\n-\t\t\t\t      fold (build2 (MINUS_EXPR,\n-\t\t\t\t\t\t    TREE_TYPE (index),\n-\t\t\t\t\t\t    index,\n-\t\t\t\t\t\t    TYPE_MIN_VALUE (domain))));\n-\n-\t      position = size_binop (MULT_EXPR, index,\n-\t\t\t\t     convert (ssizetype,\n-\t\t\t\t\t      TYPE_SIZE_UNIT (elttype)));\n-\t      xtarget = offset_address (target,\n-\t\t\t\t\texpand_expr (position, 0, VOIDmode, 0),\n-\t\t\t\t\thighest_pow2_factor (position));\n-\t      xtarget = adjust_address (xtarget, mode, 0);\n-\t      store_expr (value, xtarget, 0);\n-\t    }\n-\t  else\n-\t    {\n-\t      if (index != 0)\n-\t\tbitpos = ((tree_low_cst (index, 0) - minelt)\n-\t\t\t  * tree_low_cst (TYPE_SIZE (elttype), 1));\n-\t      else\n-\t\tbitpos = (i * tree_low_cst (TYPE_SIZE (elttype), 1));\n-\n-\t      if (MEM_P (target) && !MEM_KEEP_ALIAS_SET_P (target)\n-\t\t  && TREE_CODE (type) == ARRAY_TYPE\n-\t\t  && TYPE_NONALIASED_COMPONENT (type))\n-\t\t{\n-\t\t  target = copy_rtx (target);\n-\t\t  MEM_KEEP_ALIAS_SET_P (target) = 1;\n-\t\t}\n-\t      store_constructor_field (target, bitsize, bitpos, mode, value,\n-\t\t\t\t       type, cleared, get_alias_set (elttype));\n-\t    }\n-\t}\n-    }\n-\n-  else if (TREE_CODE (type) == VECTOR_TYPE)\n-    {\n-      tree elt;\n-      int i;\n-      int need_to_clear;\n-      int icode = 0;\n-      tree elttype = TREE_TYPE (type);\n-      int elt_size = tree_low_cst (TYPE_SIZE (elttype), 1);\n-      enum machine_mode eltmode = TYPE_MODE (elttype);\n-      HOST_WIDE_INT bitsize;\n-      HOST_WIDE_INT bitpos;\n-      rtx *vector = NULL;\n-      unsigned n_elts;\n-\n-      if (eltmode == BLKmode)\n-\tabort ();\n-\n-      n_elts = TYPE_VECTOR_SUBPARTS (type);\n-      if (REG_P (target) && VECTOR_MODE_P (GET_MODE (target)))\n-\t{\n-\t  enum machine_mode mode = GET_MODE (target);\n-\n-\t  icode = (int) vec_init_optab->handlers[mode].insn_code;\n-\t  if (icode != CODE_FOR_nothing)\n-\t    {\n-\t      unsigned int i;\n-\n-\t      vector = alloca (n_elts);\n-\t      for (i = 0; i < n_elts; i++)\n-\t\tvector [i] = CONST0_RTX (GET_MODE_INNER (mode));\n-\t    }\n-\t}\n-\n-      /* If the constructor has fewer elements than the vector,\n-         clear the whole array first.  Similarly if this is\n-         static constructor of a non-BLKmode object.  */\n-      if (cleared)\n-\tneed_to_clear = 0;\n-      else if (REG_P (target) && TREE_STATIC (exp))\n-\tneed_to_clear = 1;\n-      else\n-\t{\n-\t  unsigned HOST_WIDE_INT count = 0, zero_count = 0;\n-\n-\t  for (elt = CONSTRUCTOR_ELTS (exp);\n-\t       elt != NULL_TREE;\n-\t       elt = TREE_CHAIN (elt))\n-\t    {\n-\t      int n_elts_here =\n-\t\ttree_low_cst (\n-\t\t  int_const_binop (TRUNC_DIV_EXPR,\n-\t\t\t\t   TYPE_SIZE (TREE_TYPE (TREE_VALUE (elt))),\n-\t\t\t\t   TYPE_SIZE (elttype), 0), 1);\n-\n-\t      count += n_elts_here;\n-\t      if (mostly_zeros_p (TREE_VALUE (elt)))\n-\t        zero_count += n_elts_here;\n-\t    }\n-\n-\t  /* Clear the entire vector first if there are any missing elements,\n-\t     or if the incidence of zero elements is >= 75%.  */\n-\t  need_to_clear = (count < n_elts || 4 * zero_count >= 3 * count);\n-\t}\n-\n-      if (need_to_clear && size > 0 && !vector)\n-\t{\n-\t  if (REG_P (target))\n-\t    emit_move_insn (target,  CONST0_RTX (GET_MODE (target)));\n-\t  else\n-\t    clear_storage (target, GEN_INT (size));\n-\t  cleared = 1;\n-\t}\n+\t    if (MEM_P (to_rtx) && !MEM_KEEP_ALIAS_SET_P (to_rtx)\n+\t\t&& DECL_NONADDRESSABLE_P (field))\n+\t      {\n+\t\tto_rtx = copy_rtx (to_rtx);\n+\t\tMEM_KEEP_ALIAS_SET_P (to_rtx) = 1;\n+\t      }\n+\t    \n+\t    store_constructor_field (to_rtx, bitsize, bitpos, mode,\n+\t\t\t\t     value, type, cleared,\n+\t\t\t\t     get_alias_set (TREE_TYPE (field)));\n+\t  }\n+\tbreak;\n+      }\n+    case ARRAY_TYPE:\n+      {\n+\ttree elt;\n+\tint i;\n+\tint need_to_clear;\n+\ttree domain;\n+\ttree elttype = TREE_TYPE (type);\n+\tint const_bounds_p;\n+\tHOST_WIDE_INT minelt = 0;\n+\tHOST_WIDE_INT maxelt = 0;\n+\n+\tdomain = TYPE_DOMAIN (type);\n+\tconst_bounds_p = (TYPE_MIN_VALUE (domain)\n+\t\t\t  && TYPE_MAX_VALUE (domain)\n+\t\t\t  && host_integerp (TYPE_MIN_VALUE (domain), 0)\n+\t\t\t  && host_integerp (TYPE_MAX_VALUE (domain), 0));\n+\n+\t/* If we have constant bounds for the range of the type, get them.  */\n+\tif (const_bounds_p)\n+\t  {\n+\t    minelt = tree_low_cst (TYPE_MIN_VALUE (domain), 0);\n+\t    maxelt = tree_low_cst (TYPE_MAX_VALUE (domain), 0);\n+\t  }\n \n-      if (!cleared && REG_P (target))\n-\t/* Inform later passes that the old value is dead.  */\n-\temit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n+\t/* If the constructor has fewer elements than the array, clear\n+           the whole array first.  Similarly if this is static\n+           constructor of a non-BLKmode object.  */\n+\tif (cleared)\n+\t  need_to_clear = 0;\n+\telse if (REG_P (target) && TREE_STATIC (exp))\n+\t  need_to_clear = 1;\n+\telse\n+\t  {\n+\t    HOST_WIDE_INT count = 0, zero_count = 0;\n+\t    need_to_clear = ! const_bounds_p;\n+\t    \n+\t    /* This loop is a more accurate version of the loop in\n+\t       mostly_zeros_p (it handles RANGE_EXPR in an index).  It\n+\t       is also needed to check for missing elements.  */\n+\t    for (elt = CONSTRUCTOR_ELTS (exp);\n+\t\t elt != NULL_TREE && ! need_to_clear;\n+\t\t elt = TREE_CHAIN (elt))\n+\t      {\n+\t\ttree index = TREE_PURPOSE (elt);\n+\t\tHOST_WIDE_INT this_node_count;\n+\t\t\n+\t\tif (index != NULL_TREE && TREE_CODE (index) == RANGE_EXPR)\n+\t\t  {\n+\t\t    tree lo_index = TREE_OPERAND (index, 0);\n+\t\t    tree hi_index = TREE_OPERAND (index, 1);\n+\t\t    \n+\t\t    if (! host_integerp (lo_index, 1)\n+\t\t\t|| ! host_integerp (hi_index, 1))\n+\t\t      {\n+\t\t\tneed_to_clear = 1;\n+\t\t\tbreak;\n+\t\t      }\n+\t\t    \n+\t\t    this_node_count = (tree_low_cst (hi_index, 1)\n+\t\t\t\t       - tree_low_cst (lo_index, 1) + 1);\n+\t\t  }\n+\t\telse\n+\t\t  this_node_count = 1;\n+\t\t\n+\t\tcount += this_node_count;\n+\t\tif (mostly_zeros_p (TREE_VALUE (elt)))\n+\t\t  zero_count += this_node_count;\n+\t      }\n+\t    \n+\t    /* Clear the entire array first if there are any missing\n+\t       elements, or if the incidence of zero elements is >=\n+\t       75%.  */\n+\t    if (! need_to_clear\n+\t\t&& (count < maxelt - minelt + 1\n+\t\t    || 4 * zero_count >= 3 * count))\n+\t      need_to_clear = 1;\n+\t  }\n+\t\n+\tif (need_to_clear && size > 0)\n+\t  {\n+\t    if (REG_P (target))\n+\t      emit_move_insn (target,  CONST0_RTX (GET_MODE (target)));\n+\t    else\n+\t      clear_storage (target, GEN_INT (size));\n+\t    cleared = 1;\n+\t  }\n \n-      /* Store each element of the constructor into the corresponding\n-\t element of TARGET, determined by counting the elements.  */\n-      for (elt = CONSTRUCTOR_ELTS (exp), i = 0;\n-\t   elt;\n-\t   elt = TREE_CHAIN (elt), i += bitsize / elt_size)\n-\t{\n-\t  tree value = TREE_VALUE (elt);\n-\t  tree index = TREE_PURPOSE (elt);\n-\t  HOST_WIDE_INT eltpos;\n+\tif (!cleared && REG_P (target))\n+\t  /* Inform later passes that the old value is dead.  */\n+\t  emit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n \n-\t  bitsize = tree_low_cst (TYPE_SIZE (TREE_TYPE (value)), 1);\n-\t  if (cleared && initializer_zerop (value))\n-\t    continue;\n+\t/* Store each element of the constructor into the\n+\t   corresponding element of TARGET, determined by counting the\n+\t   elements.  */\n+\tfor (elt = CONSTRUCTOR_ELTS (exp), i = 0;\n+\t     elt;\n+\t     elt = TREE_CHAIN (elt), i++)\n+\t  {\n+\t    enum machine_mode mode;\n+\t    HOST_WIDE_INT bitsize;\n+\t    HOST_WIDE_INT bitpos;\n+\t    int unsignedp;\n+\t    tree value = TREE_VALUE (elt);\n+\t    tree index = TREE_PURPOSE (elt);\n+\t    rtx xtarget = target;\n+\t    \n+\t    if (cleared && initializer_zerop (value))\n+\t      continue;\n+\t    \n+\t    unsignedp = TYPE_UNSIGNED (elttype);\n+\t    mode = TYPE_MODE (elttype);\n+\t    if (mode == BLKmode)\n+\t      bitsize = (host_integerp (TYPE_SIZE (elttype), 1)\n+\t\t\t ? tree_low_cst (TYPE_SIZE (elttype), 1)\n+\t\t\t : -1);\n+\t    else\n+\t      bitsize = GET_MODE_BITSIZE (mode);\n+\t    \n+\t    if (index != NULL_TREE && TREE_CODE (index) == RANGE_EXPR)\n+\t      {\n+\t\ttree lo_index = TREE_OPERAND (index, 0);\n+\t\ttree hi_index = TREE_OPERAND (index, 1);\n+\t\trtx index_r, pos_rtx;\n+\t\tHOST_WIDE_INT lo, hi, count;\n+\t\ttree position;\n+\t\t\n+\t\t/* If the range is constant and \"small\", unroll the loop.  */\n+\t\tif (const_bounds_p\n+\t\t    && host_integerp (lo_index, 0)\n+\t\t    && host_integerp (hi_index, 0)\n+\t\t    && (lo = tree_low_cst (lo_index, 0),\n+\t\t\thi = tree_low_cst (hi_index, 0),\n+\t\t\tcount = hi - lo + 1,\n+\t\t\t(!MEM_P (target)\n+\t\t\t || count <= 2\n+\t\t\t || (host_integerp (TYPE_SIZE (elttype), 1)\n+\t\t\t     && (tree_low_cst (TYPE_SIZE (elttype), 1) * count\n+\t\t\t\t <= 40 * 8)))))\n+\t\t  {\n+\t\t    lo -= minelt;  hi -= minelt;\n+\t\t    for (; lo <= hi; lo++)\n+\t\t      {\n+\t\t\tbitpos = lo * tree_low_cst (TYPE_SIZE (elttype), 0);\n+\t\t\t\n+\t\t\tif (MEM_P (target)\n+\t\t\t    && !MEM_KEEP_ALIAS_SET_P (target)\n+\t\t\t    && TREE_CODE (type) == ARRAY_TYPE\n+\t\t\t    && TYPE_NONALIASED_COMPONENT (type))\n+\t\t\t  {\n+\t\t\t    target = copy_rtx (target);\n+\t\t\t    MEM_KEEP_ALIAS_SET_P (target) = 1;\n+\t\t\t  }\n+\t\t\t\n+\t\t\tstore_constructor_field\n+\t\t\t  (target, bitsize, bitpos, mode, value, type, cleared,\n+\t\t\t   get_alias_set (elttype));\n+\t\t      }\n+\t\t  }\n+\t\telse\n+\t\t  {\n+\t\t    rtx loop_start = gen_label_rtx ();\n+\t\t    rtx loop_end = gen_label_rtx ();\n+\t\t    tree exit_cond;\n+\t\t    \n+\t\t    expand_expr (hi_index, NULL_RTX, VOIDmode, 0);\n+\t\t    unsignedp = TYPE_UNSIGNED (domain);\n+\t\t    \n+\t\t    index = build_decl (VAR_DECL, NULL_TREE, domain);\n+\t\t    \n+\t\t    index_r\n+\t\t      = gen_reg_rtx (promote_mode (domain, DECL_MODE (index),\n+\t\t\t\t\t\t   &unsignedp, 0));\n+\t\t    SET_DECL_RTL (index, index_r);\n+\t\t    store_expr (lo_index, index_r, 0);\n+\t\t    \n+\t\t    /* Build the head of the loop.  */\n+\t\t    do_pending_stack_adjust ();\n+\t\t    emit_label (loop_start);\n+\n+\t\t    /* Assign value to element index.  */\n+\t\t    position\n+\t\t      = convert (ssizetype,\n+\t\t\t\t fold (build2 (MINUS_EXPR, TREE_TYPE (index),\n+\t\t\t\t\t       index, TYPE_MIN_VALUE (domain))));\n+\t\t    position = size_binop (MULT_EXPR, position,\n+\t\t\t\t\t   convert (ssizetype,\n+\t\t\t\t\t\t    TYPE_SIZE_UNIT (elttype)));\n+\t\t    \n+\t\t    pos_rtx = expand_expr (position, 0, VOIDmode, 0);\n+\t\t    xtarget = offset_address (target, pos_rtx,\n+\t\t\t\t\t      highest_pow2_factor (position));\n+\t\t    xtarget = adjust_address (xtarget, mode, 0);\n+\t\t    if (TREE_CODE (value) == CONSTRUCTOR)\n+\t\t      store_constructor (value, xtarget, cleared,\n+\t\t\t\t\t bitsize / BITS_PER_UNIT);\n+\t\t    else\n+\t\t      store_expr (value, xtarget, 0);\n+\n+\t\t    /* Generate a conditional jump to exit the loop.  */\n+\t\t    exit_cond = build2 (LT_EXPR, integer_type_node,\n+\t\t\t\t\tindex, hi_index);\n+\t\t    jumpif (exit_cond, loop_end);\n+\t\t    \n+\t\t    /* Update the loop counter, and jump to the head of\n+\t\t       the loop.  */\n+\t\t    expand_assignment (index,\n+\t\t\t\t       build2 (PLUS_EXPR, TREE_TYPE (index),\n+\t\t\t\t\t       index, integer_one_node), 0);\n+\t\t    \n+\t\t    emit_jump (loop_start);\n+\t\t    \n+\t\t    /* Build the end of the loop.  */\n+\t\t    emit_label (loop_end);\n+\t\t  }\n+\t      }\n+\t    else if ((index != 0 && ! host_integerp (index, 0))\n+\t\t     || ! host_integerp (TYPE_SIZE (elttype), 1))\n+\t      {\n+\t\ttree position;\n+\t\t\n+\t\tif (index == 0)\n+\t\t  index = ssize_int (1);\n+\t\t\n+\t\tif (minelt)\n+\t\t  index = fold_convert (ssizetype,\n+\t\t\t\t\tfold (build2 (MINUS_EXPR,\n+\t\t\t\t\t\t      TREE_TYPE (index),\n+\t\t\t\t\t\t      index,\n+\t\t\t\t\t\t      TYPE_MIN_VALUE (domain))));\n+\t\t\n+\t\tposition = size_binop (MULT_EXPR, index,\n+\t\t\t\t       convert (ssizetype,\n+\t\t\t\t\t\tTYPE_SIZE_UNIT (elttype)));\n+\t\txtarget = offset_address (target,\n+\t\t\t\t\t  expand_expr (position, 0, VOIDmode, 0),\n+\t\t\t\t\t  highest_pow2_factor (position));\n+\t\txtarget = adjust_address (xtarget, mode, 0);\n+\t\tstore_expr (value, xtarget, 0);\n+\t      }\n+\t    else\n+\t      {\n+\t\tif (index != 0)\n+\t\t  bitpos = ((tree_low_cst (index, 0) - minelt)\n+\t\t\t    * tree_low_cst (TYPE_SIZE (elttype), 1));\n+\t\telse\n+\t\t  bitpos = (i * tree_low_cst (TYPE_SIZE (elttype), 1));\n+\t\t\n+\t\tif (MEM_P (target) && !MEM_KEEP_ALIAS_SET_P (target)\n+\t\t    && TREE_CODE (type) == ARRAY_TYPE\n+\t\t    && TYPE_NONALIASED_COMPONENT (type))\n+\t\t  {\n+\t\t    target = copy_rtx (target);\n+\t\t    MEM_KEEP_ALIAS_SET_P (target) = 1;\n+\t\t  }\n+\t\tstore_constructor_field (target, bitsize, bitpos, mode, value,\n+\t\t\t\t\t type, cleared, get_alias_set (elttype));\n+\t      }\n+\t  }\n+\tbreak;\n+      }\n \n-\t  if (index != 0)\n-\t    eltpos = tree_low_cst (index, 1);\n-\t  else\n-\t    eltpos = i;\n+    case VECTOR_TYPE:\n+      {\n+\ttree elt;\n+\tint i;\n+\tint need_to_clear;\n+\tint icode = 0;\n+\ttree elttype = TREE_TYPE (type);\n+\tint elt_size = tree_low_cst (TYPE_SIZE (elttype), 1);\n+\tenum machine_mode eltmode = TYPE_MODE (elttype);\n+\tHOST_WIDE_INT bitsize;\n+\tHOST_WIDE_INT bitpos;\n+\trtx *vector = NULL;\n+\tunsigned n_elts;\n+\t\n+\tgcc_assert (eltmode != BLKmode);\n+\t\n+\tn_elts = TYPE_VECTOR_SUBPARTS (type);\n+\tif (REG_P (target) && VECTOR_MODE_P (GET_MODE (target)))\n+\t  {\n+\t    enum machine_mode mode = GET_MODE (target);\n+\t    \n+\t    icode = (int) vec_init_optab->handlers[mode].insn_code;\n+\t    if (icode != CODE_FOR_nothing)\n+\t      {\n+\t\tunsigned int i;\n+\t\t\n+\t\tvector = alloca (n_elts);\n+\t\tfor (i = 0; i < n_elts; i++)\n+\t\t  vector [i] = CONST0_RTX (GET_MODE_INNER (mode));\n+\t      }\n+\t  }\n+\t\n+\t/* If the constructor has fewer elements than the vector,\n+\t   clear the whole array first.  Similarly if this is static\n+\t   constructor of a non-BLKmode object.  */\n+\tif (cleared)\n+\t  need_to_clear = 0;\n+\telse if (REG_P (target) && TREE_STATIC (exp))\n+\t  need_to_clear = 1;\n+\telse\n+\t  {\n+\t    unsigned HOST_WIDE_INT count = 0, zero_count = 0;\n+\t    \n+\t    for (elt = CONSTRUCTOR_ELTS (exp);\n+\t\t elt != NULL_TREE;\n+\t\t elt = TREE_CHAIN (elt))\n+\t      {\n+\t\tint n_elts_here = tree_low_cst\n+\t\t  (int_const_binop (TRUNC_DIV_EXPR,\n+\t\t\t\t    TYPE_SIZE (TREE_TYPE (TREE_VALUE (elt))),\n+\t\t\t\t    TYPE_SIZE (elttype), 0), 1);\n+\t\t\n+\t\tcount += n_elts_here;\n+\t\tif (mostly_zeros_p (TREE_VALUE (elt)))\n+\t\t  zero_count += n_elts_here;\n+\t      }\n \n-\t  if (vector)\n-\t    {\n-\t      /* Vector CONSTRUCTORs should only be built from smaller\n-\t\t vectors in the case of BLKmode vectors.  */\n-\t      if (TREE_CODE (TREE_TYPE (value)) == VECTOR_TYPE)\n-\t\tabort ();\n-\t      vector[eltpos] = expand_expr (value, NULL_RTX, VOIDmode, 0);\n-\t    }\n-\t  else\n-\t    {\n-\t      enum machine_mode value_mode =\n-\t\tTREE_CODE (TREE_TYPE (value)) == VECTOR_TYPE\n+\t    /* Clear the entire vector first if there are any missing elements,\n+\t       or if the incidence of zero elements is >= 75%.  */\n+\t    need_to_clear = (count < n_elts || 4 * zero_count >= 3 * count);\n+\t  }\n+\t\n+\tif (need_to_clear && size > 0 && !vector)\n+\t  {\n+\t    if (REG_P (target))\n+\t      emit_move_insn (target,  CONST0_RTX (GET_MODE (target)));\n+\t    else\n+\t      clear_storage (target, GEN_INT (size));\n+\t    cleared = 1;\n+\t  }\n+\t\n+\tif (!cleared && REG_P (target))\n+\t  /* Inform later passes that the old value is dead.  */\n+\t  emit_insn (gen_rtx_CLOBBER (VOIDmode, target));\n+\n+        /* Store each element of the constructor into the corresponding\n+\t   element of TARGET, determined by counting the elements.  */\n+\tfor (elt = CONSTRUCTOR_ELTS (exp), i = 0;\n+\t     elt;\n+\t     elt = TREE_CHAIN (elt), i += bitsize / elt_size)\n+\t  {\n+\t    tree value = TREE_VALUE (elt);\n+\t    tree index = TREE_PURPOSE (elt);\n+\t    HOST_WIDE_INT eltpos;\n+\t    \n+\t    bitsize = tree_low_cst (TYPE_SIZE (TREE_TYPE (value)), 1);\n+\t    if (cleared && initializer_zerop (value))\n+\t      continue;\n+\t    \n+\t    if (index != 0)\n+\t      eltpos = tree_low_cst (index, 1);\n+\t    else\n+\t      eltpos = i;\n+\t    \n+\t    if (vector)\n+\t      {\n+\t        /* Vector CONSTRUCTORs should only be built from smaller\n+\t\t   vectors in the case of BLKmode vectors.  */\n+\t\tgcc_assert (TREE_CODE (TREE_TYPE (value)) != VECTOR_TYPE);\n+\t\tvector[eltpos] = expand_expr (value, NULL_RTX, VOIDmode, 0);\n+\t      }\n+\t    else\n+\t      {\n+\t\tenum machine_mode value_mode =\n+\t\t  TREE_CODE (TREE_TYPE (value)) == VECTOR_TYPE\n \t\t  ? TYPE_MODE (TREE_TYPE (value))\n \t\t  : eltmode;\n-\t      bitpos = eltpos * elt_size;\n-\t      store_constructor_field (target, bitsize, bitpos, value_mode, value,\n-\t\t\t\t       type, cleared, get_alias_set (elttype));\n-\t    }\n-\t}\n-\n-      if (vector)\n-\temit_insn (GEN_FCN (icode) (target,\n-\t\t\t\t    gen_rtx_PARALLEL (GET_MODE (target),\n-\t\t\t\t\t\t      gen_rtvec_v (n_elts, vector))));\n-    }\n-\n-  /* Set constructor assignments.  */\n-  else if (TREE_CODE (type) == SET_TYPE)\n-    {\n-      tree elt = CONSTRUCTOR_ELTS (exp);\n-      unsigned HOST_WIDE_INT nbytes = int_size_in_bytes (type), nbits;\n-      tree domain = TYPE_DOMAIN (type);\n-      tree domain_min, domain_max, bitlength;\n-\n-      /* The default implementation strategy is to extract the constant\n-\t parts of the constructor, use that to initialize the target,\n-\t and then \"or\" in whatever non-constant ranges we need in addition.\n-\n-\t If a large set is all zero or all ones, it is\n-\t probably better to set it using memset.\n-\t Also, if a large set has just a single range, it may also be\n-\t better to first clear all the first clear the set (using\n-\t memset), and set the bits we want.  */\n-\n-      /* Check for all zeros.  */\n-      if (elt == NULL_TREE && size > 0)\n-\t{\n-\t  if (!cleared)\n-\t    clear_storage (target, GEN_INT (size));\n-\t  return;\n-\t}\n-\n-      domain_min = convert (sizetype, TYPE_MIN_VALUE (domain));\n-      domain_max = convert (sizetype, TYPE_MAX_VALUE (domain));\n-      bitlength = size_binop (PLUS_EXPR,\n-\t\t\t      size_diffop (domain_max, domain_min),\n-\t\t\t      ssize_int (1));\n-\n-      nbits = tree_low_cst (bitlength, 1);\n-\n-      /* For \"small\" sets, or \"medium-sized\" (up to 32 bytes) sets that\n-\t are \"complicated\" (more than one range), initialize (the\n-\t constant parts) by copying from a constant.  */\n-      if (GET_MODE (target) != BLKmode || nbits <= 2 * BITS_PER_WORD\n-\t  || (nbytes <= 32 && TREE_CHAIN (elt) != NULL_TREE))\n-\t{\n-\t  unsigned int set_word_size = TYPE_ALIGN (TREE_TYPE (exp));\n-\t  enum machine_mode mode = mode_for_size (set_word_size, MODE_INT, 1);\n-\t  char *bit_buffer = alloca (nbits);\n-\t  HOST_WIDE_INT word = 0;\n-\t  unsigned int bit_pos = 0;\n-\t  unsigned int ibit = 0;\n-\t  unsigned int offset = 0;  /* In bytes from beginning of set.  */\n-\n-\t  elt = get_set_constructor_bits (exp, bit_buffer, nbits);\n-\t  for (;;)\n-\t    {\n-\t      if (bit_buffer[ibit])\n-\t\t{\n-\t\t  if (BYTES_BIG_ENDIAN)\n-\t\t    word |= (1 << (set_word_size - 1 - bit_pos));\n-\t\t  else\n-\t\t    word |= 1 << bit_pos;\n-\t\t}\n-\n-\t      bit_pos++;  ibit++;\n-\t      if (bit_pos >= set_word_size || ibit == nbits)\n-\t\t{\n-\t\t  if (word != 0 || ! cleared)\n-\t\t    {\n-\t\t      rtx datum = gen_int_mode (word, mode);\n-\t\t      rtx to_rtx;\n-\n-\t\t      /* The assumption here is that it is safe to use\n-\t\t\t XEXP if the set is multi-word, but not if\n-\t\t\t it's single-word.  */\n-\t\t      if (MEM_P (target))\n-\t\t\tto_rtx = adjust_address (target, mode, offset);\n-\t\t      else if (offset == 0)\n-\t\t\tto_rtx = target;\n-\t\t      else\n-\t\t\tabort ();\n-\t\t      emit_move_insn (to_rtx, datum);\n-\t\t    }\n-\n-\t\t  if (ibit == nbits)\n-\t\t    break;\n-\t\t  word = 0;\n-\t\t  bit_pos = 0;\n-\t\t  offset += set_word_size / BITS_PER_UNIT;\n-\t\t}\n-\t    }\n-\t}\n-      else if (!cleared)\n-\t/* Don't bother clearing storage if the set is all ones.  */\n-\tif (TREE_CHAIN (elt) != NULL_TREE\n-\t    || (TREE_PURPOSE (elt) == NULL_TREE\n-\t\t? nbits != 1\n-\t\t: ( ! host_integerp (TREE_VALUE (elt), 0)\n-\t\t   || ! host_integerp (TREE_PURPOSE (elt), 0)\n-\t\t   || (tree_low_cst (TREE_VALUE (elt), 0)\n-\t\t       - tree_low_cst (TREE_PURPOSE (elt), 0) + 1\n-\t\t       != (HOST_WIDE_INT) nbits))))\n-\t  clear_storage (target, expr_size (exp));\n-\n-      for (; elt != NULL_TREE; elt = TREE_CHAIN (elt))\n-\t{\n-\t  /* Start of range of element or NULL.  */\n-\t  tree startbit = TREE_PURPOSE (elt);\n-\t  /* End of range of element, or element value.  */\n-\t  tree endbit   = TREE_VALUE (elt);\n-\t  HOST_WIDE_INT startb, endb;\n-\t  rtx bitlength_rtx, startbit_rtx, endbit_rtx, targetx;\n-\n-\t  bitlength_rtx = expand_expr (bitlength,\n-\t\t\t\t       NULL_RTX, MEM, EXPAND_CONST_ADDRESS);\n-\n-\t  /* Handle non-range tuple element like [ expr ].  */\n-\t  if (startbit == NULL_TREE)\n-\t    {\n-\t      startbit = save_expr (endbit);\n-\t      endbit = startbit;\n-\t    }\n+\t\tbitpos = eltpos * elt_size;\n+\t\tstore_constructor_field (target, bitsize, bitpos,\n+\t\t\t\t\t value_mode, value, type,\n+\t\t\t\t\t cleared, get_alias_set (elttype));\n+\t      }\n+\t  }\n+\t\n+\tif (vector)\n+\t  emit_insn (GEN_FCN (icode)\n+\t\t     (target,\n+\t\t      gen_rtx_PARALLEL (GET_MODE (target),\n+\t\t\t\t\tgen_rtvec_v (n_elts, vector))));\n+\tbreak;\n+      }\n \n-\t  startbit = convert (sizetype, startbit);\n-\t  endbit = convert (sizetype, endbit);\n-\t  if (! integer_zerop (domain_min))\n-\t    {\n-\t      startbit = size_binop (MINUS_EXPR, startbit, domain_min);\n-\t      endbit = size_binop (MINUS_EXPR, endbit, domain_min);\n-\t    }\n-\t  startbit_rtx = expand_expr (startbit, NULL_RTX, MEM,\n+      /* Set constructor assignments.  */\n+    case SET_TYPE:\n+      {\n+\ttree elt = CONSTRUCTOR_ELTS (exp);\n+\tunsigned HOST_WIDE_INT nbytes = int_size_in_bytes (type), nbits;\n+\ttree domain = TYPE_DOMAIN (type);\n+\ttree domain_min, domain_max, bitlength;\n+\t\n+\t/* The default implementation strategy is to extract the\n+\t   constant parts of the constructor, use that to initialize\n+\t   the target, and then \"or\" in whatever non-constant ranges\n+\t   we need in addition.\n+\n+\t   If a large set is all zero or all ones, it is probably\n+\t   better to set it using memset.  Also, if a large set has\n+\t   just a single range, it may also be better to first clear\n+\t   all the first clear the set (using memset), and set the\n+\t   bits we want.  */\n+\n+\t/* Check for all zeros.  */\n+\tif (elt == NULL_TREE && size > 0)\n+\t  {\n+\t    if (!cleared)\n+\t      clear_storage (target, GEN_INT (size));\n+\t    return;\n+\t  }\n+\t\n+\tdomain_min = convert (sizetype, TYPE_MIN_VALUE (domain));\n+\tdomain_max = convert (sizetype, TYPE_MAX_VALUE (domain));\n+\tbitlength = size_binop (PLUS_EXPR,\n+\t\t\t\tsize_diffop (domain_max, domain_min),\n+\t\t\t\tssize_int (1));\n+\t\n+\tnbits = tree_low_cst (bitlength, 1);\n+\n+        /* For \"small\" sets, or \"medium-sized\" (up to 32 bytes) sets\n+\t   that are \"complicated\" (more than one range), initialize\n+\t   (the constant parts) by copying from a constant.  */\n+\tif (GET_MODE (target) != BLKmode || nbits <= 2 * BITS_PER_WORD\n+\t    || (nbytes <= 32 && TREE_CHAIN (elt) != NULL_TREE))\n+\t  {\n+\t    unsigned int set_word_size = TYPE_ALIGN (TREE_TYPE (exp));\n+\t    enum machine_mode mode = mode_for_size (set_word_size, MODE_INT, 1);\n+\t    char *bit_buffer = alloca (nbits);\n+\t    HOST_WIDE_INT word = 0;\n+\t    unsigned int bit_pos = 0;\n+\t    unsigned int ibit = 0;\n+\t    unsigned int offset = 0;  /* In bytes from beginning of set.  */\n+\t    \n+\t    elt = get_set_constructor_bits (exp, bit_buffer, nbits);\n+\t    for (;;)\n+\t      {\n+\t\tif (bit_buffer[ibit])\n+\t\t  {\n+\t\t    if (BYTES_BIG_ENDIAN)\n+\t\t      word |= (1 << (set_word_size - 1 - bit_pos));\n+\t\t    else\n+\t\t      word |= 1 << bit_pos;\n+\t\t  }\n+\t\t\n+\t\tbit_pos++;  ibit++;\n+\t\tif (bit_pos >= set_word_size || ibit == nbits)\n+\t\t  {\n+\t\t    if (word != 0 || ! cleared)\n+\t\t      {\n+\t\t\trtx datum = gen_int_mode (word, mode);\n+\t\t\trtx to_rtx;\n+\t\t\t\n+\t\t\t/* The assumption here is that it is safe to\n+\t\t\t   use XEXP if the set is multi-word, but not\n+\t\t\t   if it's single-word.  */\n+\t\t\tif (MEM_P (target))\n+\t\t\t  to_rtx = adjust_address (target, mode, offset);\n+\t\t\telse\n+\t\t\t  {\n+\t\t\t    gcc_assert (!offset);\n+\t\t\t    to_rtx = target;\n+\t\t\t  }\n+\t\t\temit_move_insn (to_rtx, datum);\n+\t\t      }\n+\t\t    \n+\t\t    if (ibit == nbits)\n+\t\t      break;\n+\t\t    word = 0;\n+\t\t    bit_pos = 0;\n+\t\t    offset += set_word_size / BITS_PER_UNIT;\n+\t\t  }\n+\t      }\n+\t  }\n+\telse if (!cleared)\n+\t  /* Don't bother clearing storage if the set is all ones.  */\n+\t  if (TREE_CHAIN (elt) != NULL_TREE\n+\t      || (TREE_PURPOSE (elt) == NULL_TREE\n+\t\t  ? nbits != 1\n+\t\t  : ( ! host_integerp (TREE_VALUE (elt), 0)\n+\t\t      || ! host_integerp (TREE_PURPOSE (elt), 0)\n+\t\t      || (tree_low_cst (TREE_VALUE (elt), 0)\n+\t\t\t  - tree_low_cst (TREE_PURPOSE (elt), 0) + 1\n+\t\t\t  != (HOST_WIDE_INT) nbits))))\n+\t    clear_storage (target, expr_size (exp));\n+\t\n+\tfor (; elt != NULL_TREE; elt = TREE_CHAIN (elt))\n+\t  {\n+\t    /* Start of range of element or NULL.  */\n+\t    tree startbit = TREE_PURPOSE (elt);\n+ \t    /* End of range of element, or element value.  */\n+\t    tree endbit   = TREE_VALUE (elt);\n+\t    HOST_WIDE_INT startb, endb;\n+\t    rtx bitlength_rtx, startbit_rtx, endbit_rtx, targetx;\n+\t    \n+\t    bitlength_rtx = expand_expr (bitlength,\n+\t\t\t\t\t NULL_RTX, MEM, EXPAND_CONST_ADDRESS);\n+\t    \n+\t    /* Handle non-range tuple element like [ expr ].  */\n+\t    if (startbit == NULL_TREE)\n+\t      {\n+\t\tstartbit = save_expr (endbit);\n+\t\tendbit = startbit;\n+\t      }\n+\t    \n+\t    startbit = convert (sizetype, startbit);\n+\t    endbit = convert (sizetype, endbit);\n+\t    if (! integer_zerop (domain_min))\n+\t      {\n+\t\tstartbit = size_binop (MINUS_EXPR, startbit, domain_min);\n+\t\tendbit = size_binop (MINUS_EXPR, endbit, domain_min);\n+\t      }\n+\t    startbit_rtx = expand_expr (startbit, NULL_RTX, MEM,\n+\t\t\t\t\tEXPAND_CONST_ADDRESS);\n+\t    endbit_rtx = expand_expr (endbit, NULL_RTX, MEM,\n \t\t\t\t      EXPAND_CONST_ADDRESS);\n-\t  endbit_rtx = expand_expr (endbit, NULL_RTX, MEM,\n-\t\t\t\t    EXPAND_CONST_ADDRESS);\n-\n-\t  if (REG_P (target))\n-\t    {\n-\t      targetx\n-\t\t= assign_temp\n+\t    \n+\t    if (REG_P (target))\n+\t      {\n+\t\ttargetx\n+\t\t  = assign_temp\n \t\t  ((build_qualified_type (lang_hooks.types.type_for_mode\n \t\t\t\t\t  (GET_MODE (target), 0),\n \t\t\t\t\t  TYPE_QUAL_CONST)),\n \t\t   0, 1, 1);\n-\t      emit_move_insn (targetx, target);\n-\t    }\n+\t\temit_move_insn (targetx, target);\n+\t      }\n+\t    \n+\t    else\n+\t      {\n+\t\tgcc_assert (MEM_P (target));\n+\t\ttargetx = target;\n+\t      }\n \n-\t  else if (MEM_P (target))\n-\t    targetx = target;\n-\t  else\n-\t    abort ();\n-\n-\t  /* Optimization:  If startbit and endbit are constants divisible\n-\t     by BITS_PER_UNIT, call memset instead.  */\n-\t  if (TREE_CODE (startbit) == INTEGER_CST\n-\t      && TREE_CODE (endbit) == INTEGER_CST\n-\t      && (startb = TREE_INT_CST_LOW (startbit)) % BITS_PER_UNIT == 0\n-\t      && (endb = TREE_INT_CST_LOW (endbit) + 1) % BITS_PER_UNIT == 0)\n-\t    {\n-\t      emit_library_call (memset_libfunc, LCT_NORMAL,\n-\t\t\t\t VOIDmode, 3,\n-\t\t\t\t plus_constant (XEXP (targetx, 0),\n-\t\t\t\t\t\tstartb / BITS_PER_UNIT),\n-\t\t\t\t Pmode,\n-\t\t\t\t constm1_rtx, TYPE_MODE (integer_type_node),\n-\t\t\t\t GEN_INT ((endb - startb) / BITS_PER_UNIT),\n-\t\t\t\t TYPE_MODE (sizetype));\n-\t    }\n-\t  else\n-\t    emit_library_call (setbits_libfunc, LCT_NORMAL,\n-\t\t\t       VOIDmode, 4, XEXP (targetx, 0),\n-\t\t\t       Pmode, bitlength_rtx, TYPE_MODE (sizetype),\n-\t\t\t       startbit_rtx, TYPE_MODE (sizetype),\n-\t\t\t       endbit_rtx, TYPE_MODE (sizetype));\n-\n-\t  if (REG_P (target))\n-\t    emit_move_insn (target, targetx);\n-\t}\n+\t    /* Optimization:  If startbit and endbit are constants divisible\n+\t       by BITS_PER_UNIT, call memset instead.  */\n+\t    if (TREE_CODE (startbit) == INTEGER_CST\n+\t\t&& TREE_CODE (endbit) == INTEGER_CST\n+\t\t&& (startb = TREE_INT_CST_LOW (startbit)) % BITS_PER_UNIT == 0\n+\t\t&& (endb = TREE_INT_CST_LOW (endbit) + 1) % BITS_PER_UNIT == 0)\n+\t      {\n+\t\temit_library_call (memset_libfunc, LCT_NORMAL,\n+\t\t\t\t   VOIDmode, 3,\n+\t\t\t\t   plus_constant (XEXP (targetx, 0),\n+\t\t\t\t\t\t  startb / BITS_PER_UNIT),\n+\t\t\t\t   Pmode,\n+\t\t\t\t   constm1_rtx, TYPE_MODE (integer_type_node),\n+\t\t\t\t   GEN_INT ((endb - startb) / BITS_PER_UNIT),\n+\t\t\t\t   TYPE_MODE (sizetype));\n+\t      }\n+\t    else\n+\t      emit_library_call (setbits_libfunc, LCT_NORMAL,\n+\t\t\t\t VOIDmode, 4, XEXP (targetx, 0),\n+\t\t\t\t Pmode, bitlength_rtx, TYPE_MODE (sizetype),\n+\t\t\t\t startbit_rtx, TYPE_MODE (sizetype),\n+\t\t\t\t endbit_rtx, TYPE_MODE (sizetype));\n+\t    \n+\t    if (REG_P (target))\n+\t      emit_move_insn (target, targetx);\n+\t  }\n+\tbreak;\n+      }\n+    default:\n+      gcc_unreachable ();\n     }\n-\n-  else\n-    abort ();\n }\n \n /* Store the value of EXP (an expression tree)\n@@ -5183,8 +5159,7 @@ store_field (rtx target, HOST_WIDE_INT bitsize, HOST_WIDE_INT bitpos,\n     {\n       /* We're storing into a struct containing a single __complex.  */\n \n-      if (bitpos != 0)\n-\tabort ();\n+      gcc_assert (!bitpos);\n       return store_expr (exp, target, value_mode != VOIDmode);\n     }\n \n@@ -5237,9 +5212,8 @@ store_field (rtx target, HOST_WIDE_INT bitsize, HOST_WIDE_INT bitpos,\n \t boundary.  If so, we simply do a block copy.  */\n       if (GET_MODE (target) == BLKmode && GET_MODE (temp) == BLKmode)\n \t{\n-\t  if (!MEM_P (target) || !MEM_P (temp)\n-\t      || bitpos % BITS_PER_UNIT != 0)\n-\t    abort ();\n+\t  gcc_assert (MEM_P (target) && MEM_P (temp)\n+\t\t      && !(bitpos % BITS_PER_UNIT));\n \n \t  target = adjust_address (target, VOIDmode, bitpos / BITS_PER_UNIT);\n \t  emit_block_move (target, temp,\n@@ -5873,7 +5847,7 @@ safe_from_p (rtx x, tree exp, int top_p)\n \tcase WITH_CLEANUP_EXPR:\n \tcase CLEANUP_POINT_EXPR:\n \t  /* Lowered by gimplify.c.  */\n-\t  abort ();\n+\t  gcc_unreachable ();\n \n \tcase SAVE_EXPR:\n \t  return safe_from_p (x, TREE_OPERAND (exp, 0), 0);\n@@ -6037,13 +6011,12 @@ expand_var (tree var)\n \texpand_decl (var);\n       else if (TREE_CODE (var) == VAR_DECL && TREE_STATIC (var))\n \trest_of_decl_compilation (var, 0, 0);\n-      else if (TREE_CODE (var) == TYPE_DECL\n-\t       || TREE_CODE (var) == CONST_DECL\n-\t       || TREE_CODE (var) == FUNCTION_DECL\n-\t       || TREE_CODE (var) == LABEL_DECL)\n-\t/* No expansion needed.  */;\n       else\n-\tabort ();\n+\t/* No expansion needed.  */\n+\tgcc_assert (TREE_CODE (var) == TYPE_DECL\n+\t\t    || TREE_CODE (var) == CONST_DECL\n+\t\t    || TREE_CODE (var) == FUNCTION_DECL\n+\t\t    || TREE_CODE (var) == LABEL_DECL);\n     }\n }\n \n@@ -6142,8 +6115,7 @@ expand_expr_addr_expr (tree exp, rtx target, enum machine_mode tmode,\n \t  /* If the DECL isn't in memory, then the DECL wasn't properly\n \t     marked TREE_ADDRESSABLE, which will be either a front-end\n \t     or a tree optimizer bug.  */\n-\t  if (GET_CODE (result) != MEM)\n-\t    abort ();\n+\t  gcc_assert (GET_CODE (result) == MEM);\n \t  result = XEXP (result, 0);\n \n \t  /* ??? Is this needed anymore?  */\n@@ -6165,8 +6137,7 @@ expand_expr_addr_expr (tree exp, rtx target, enum machine_mode tmode,\n     }\n \n   /* We must have made progress.  */\n-  if (inner == exp)\n-    abort ();\n+  gcc_assert (inner != exp);\n \n   subtarget = offset || bitpos ? NULL_RTX : target;\n   result = expand_expr_addr_expr (inner, subtarget, tmode, modifier);\n@@ -6200,8 +6171,7 @@ expand_expr_addr_expr (tree exp, rtx target, enum machine_mode tmode,\n     {\n       /* Someone beforehand should have rejected taking the address\n \t of such an object.  */\n-      if (bitpos % BITS_PER_UNIT != 0)\n-\tabort ();\n+      gcc_assert (!(bitpos % BITS_PER_UNIT));\n \n       result = plus_constant (result, bitpos / BITS_PER_UNIT);\n       if (modifier < EXPAND_SUM)\n@@ -6479,8 +6449,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n     case FUNCTION_DECL:\n     case RESULT_DECL:\n-      if (DECL_RTL (exp) == 0)\n-\tabort ();\n+      gcc_assert (DECL_RTL (exp));\n \n       /* Ensure variable marked as used even if it doesn't go through\n \t a parser.  If it hasn't be used yet, write out an external\n@@ -6497,18 +6466,17 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       /* Variables inherited from containing functions should have\n \t been lowered by this point.  */\n       context = decl_function_context (exp);\n-      if (context != 0\n-\t  && context != current_function_decl\n-\t  && !TREE_STATIC (exp)\n-\t  /* ??? C++ creates functions that are not TREE_STATIC.  */\n-\t  && TREE_CODE (exp) != FUNCTION_DECL)\n-\tabort ();\n+      gcc_assert (!context\n+\t\t  || context == current_function_decl\n+\t\t  || TREE_STATIC (exp)\n+\t\t  /* ??? C++ creates functions that are not TREE_STATIC.  */\n+\t\t  || TREE_CODE (exp) == FUNCTION_DECL);\n \n       /* This is the case of an array whose size is to be determined\n \t from its initializer, while the initializer is still being parsed.\n \t See expand_decl.  */\n \n-      else if (MEM_P (DECL_RTL (exp))\n+      if (MEM_P (DECL_RTL (exp))\n \t       && REG_P (XEXP (DECL_RTL (exp), 0)))\n \ttemp = validize_mem (DECL_RTL (exp));\n \n@@ -6548,12 +6516,13 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       if (REG_P (DECL_RTL (exp))\n \t  && GET_MODE (DECL_RTL (exp)) != DECL_MODE (exp))\n \t{\n+\t  enum machine_mode pmode;\n+\t  \n \t  /* Get the signedness used for this variable.  Ensure we get the\n \t     same mode we got when the variable was declared.  */\n-\t  if (GET_MODE (DECL_RTL (exp))\n-\t      != promote_mode (type, DECL_MODE (exp), &unsignedp,\n-\t\t\t       (TREE_CODE (exp) == RESULT_DECL ? 1 : 0)))\n-\t    abort ();\n+\t  pmode = promote_mode (type, DECL_MODE (exp), &unsignedp,\n+\t\t\t\t(TREE_CODE (exp) == RESULT_DECL ? 1 : 0));\n+\t  gcc_assert (GET_MODE (DECL_RTL (exp)) == pmode);\n \n \t  temp = gen_lowpart_SUBREG (mode, DECL_RTL (exp));\n \t  SUBREG_PROMOTED_VAR_P (temp) = 1;\n@@ -6654,8 +6623,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t       expanders calling save_expr immediately before expanding\n \t       something.  Assume this means that we only have to deal\n \t       with non-BLKmode values.  */\n-\t    if (GET_MODE (ret) == BLKmode)\n-\t      abort ();\n+\t    gcc_assert (GET_MODE (ret) != BLKmode);\n \n \t    val = build_decl (VAR_DECL, NULL, TREE_TYPE (exp));\n \t    DECL_ARTIFICIAL (val) = 1;\n@@ -6772,17 +6740,14 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n     case ARRAY_REF:\n \n-#ifdef ENABLE_CHECKING\n-      if (TREE_CODE (TREE_TYPE (TREE_OPERAND (exp, 0))) != ARRAY_TYPE)\n-\tabort ();\n-#endif\n-\n       {\n \ttree array = TREE_OPERAND (exp, 0);\n \ttree low_bound = array_ref_low_bound (exp);\n \ttree index = convert (sizetype, TREE_OPERAND (exp, 1));\n \tHOST_WIDE_INT i;\n \n+\tgcc_assert (TREE_CODE (TREE_TYPE (array)) == ARRAY_TYPE);\n+\n \t/* Optimize the special-case of a zero lower bound.\n \n \t   We convert the low_bound to sizetype to avoid some problems\n@@ -6952,8 +6917,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t/* If we got back the original object, something is wrong.  Perhaps\n \t   we are evaluating an expression too early.  In any event, don't\n \t   infinitely recurse.  */\n-\tif (tem == exp)\n-\t  abort ();\n+\tgcc_assert (tem != exp);\n \n \t/* If TEM's type is a union of variable size, pass TARGET to the inner\n \t   computation, since it will need a temporary and TARGET is known\n@@ -7007,8 +6971,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t    rtx offset_rtx = expand_expr (offset, NULL_RTX, VOIDmode,\n \t\t\t\t\t  EXPAND_SUM);\n \n-\t    if (!MEM_P (op0))\n-\t      abort ();\n+\t    gcc_assert (MEM_P (op0));\n \n #ifdef POINTERS_EXTEND_UNSIGNED\n \t    if (GET_MODE (offset_rtx) != Pmode)\n@@ -7055,8 +7018,8 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t   one element arrays having the same mode as its element.  */\n \tif (GET_CODE (op0) == CONCAT)\n \t  {\n-\t    if (bitpos != 0 || bitsize != GET_MODE_BITSIZE (GET_MODE (op0)))\n-\t      abort ();\n+\t    gcc_assert (bitpos == 0\n+\t\t\t&& bitsize == GET_MODE_BITSIZE (GET_MODE (op0)));\n \t    return op0;\n \t  }\n \n@@ -7113,10 +7076,9 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n \t\t/* In this case, BITPOS must start at a byte boundary and\n \t\t   TARGET, if specified, must be a MEM.  */\n-\t\tif (!MEM_P (op0)\n-\t\t    || (target != 0 && !MEM_P (target))\n-\t\t    || bitpos % BITS_PER_UNIT != 0)\n-\t\t  abort ();\n+\t\tgcc_assert (MEM_P (op0)\n+\t\t\t    && (!target || MEM_P (target))\n+\t\t\t    && !(bitpos % BITS_PER_UNIT));\n \n \t\temit_block_move (target,\n \t\t\t\t adjust_address (op0, VOIDmode,\n@@ -7261,17 +7223,19 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t\t\tadjust_address (target, TYPE_MODE (valtype), 0),\n \t\t\tmodifier == EXPAND_STACK_PARM ? 2 : 0);\n \n-\t  else if (REG_P (target))\n-\t    /* Store this field into a union of the proper type.  */\n-\t    store_field (target,\n-\t\t\t MIN ((int_size_in_bytes (TREE_TYPE\n-\t\t\t\t\t\t  (TREE_OPERAND (exp, 0)))\n-\t\t\t       * BITS_PER_UNIT),\n-\t\t\t      (HOST_WIDE_INT) GET_MODE_BITSIZE (mode)),\n-\t\t\t 0, TYPE_MODE (valtype), TREE_OPERAND (exp, 0),\n-\t\t\t VOIDmode, 0, type, 0);\n \t  else\n-\t    abort ();\n+\t    {\n+\t      gcc_assert (REG_P (target));\n+\t      \n+\t      /* Store this field into a union of the proper type.  */\n+\t      store_field (target,\n+\t\t\t   MIN ((int_size_in_bytes (TREE_TYPE\n+\t\t\t\t\t\t    (TREE_OPERAND (exp, 0)))\n+\t\t\t\t * BITS_PER_UNIT),\n+\t\t\t\t(HOST_WIDE_INT) GET_MODE_BITSIZE (mode)),\n+\t\t\t   0, TYPE_MODE (valtype), TREE_OPERAND (exp, 0),\n+\t\t\t   VOIDmode, 0, type, 0);\n+\t    }\n \n \t  /* Return the entire union.  */\n \t  return target;\n@@ -7347,8 +7311,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t     constants to change mode.  */\n \t  tree inner_type = TREE_TYPE (TREE_OPERAND (exp, 0));\n \n-\t  if (TREE_ADDRESSABLE (exp))\n-\t    abort ();\n+\t  gcc_assert (!TREE_ADDRESSABLE (exp));\n \n \t  if (target == 0 || GET_MODE (target) != TYPE_MODE (inner_type))\n \t    target\n@@ -7381,8 +7344,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t\t\t\t\t\t    temp_size, 0, type);\n \t      rtx new_with_op0_mode = adjust_address (new, GET_MODE (op0), 0);\n \n-\t      if (TREE_ADDRESSABLE (exp))\n-\t\tabort ();\n+\t      gcc_assert (!TREE_ADDRESSABLE (exp));\n \n \t      if (GET_MODE (op0) == BLKmode)\n \t\temit_block_move (new_with_op0_mode, op0,\n@@ -7712,7 +7674,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n     case FIX_ROUND_EXPR:\n     case FIX_FLOOR_EXPR:\n     case FIX_CEIL_EXPR:\n-      abort ();\t\t\t/* Not used for C.  */\n+      gcc_unreachable ();\t\t\t/* Not used for C.  */\n \n     case FIX_TRUNC_EXPR:\n       op0 = expand_expr (TREE_OPERAND (exp, 0), NULL_RTX, VOIDmode, 0);\n@@ -7741,8 +7703,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       temp = expand_unop (mode,\n       \t\t\t  optab_for_tree_code (NEGATE_EXPR, type),\n \t\t\t  op0, target, 0);\n-      if (temp == 0)\n-\tabort ();\n+      gcc_assert (temp);\n       return REDUCE_BIT_FIELD (temp);\n \n     case ABS_EXPR:\n@@ -7751,9 +7712,8 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \ttarget = 0;\n \n       /* ABS_EXPR is not valid for complex arguments.  */\n-      if (GET_MODE_CLASS (mode) == MODE_COMPLEX_INT\n-\t  || GET_MODE_CLASS (mode) == MODE_COMPLEX_FLOAT)\n-\tabort ();\n+      gcc_assert (GET_MODE_CLASS (mode) != MODE_COMPLEX_INT\n+\t\t  && GET_MODE_CLASS (mode) != MODE_COMPLEX_FLOAT);\n \n       /* Unsigned abs is simply the operand.  Testing here means we don't\n \t risk generating incorrect code below.  */\n@@ -7830,8 +7790,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       if (modifier == EXPAND_STACK_PARM)\n \ttarget = 0;\n       temp = expand_unop (mode, one_cmpl_optab, op0, target, 1);\n-      if (temp == 0)\n-\tabort ();\n+      gcc_assert (temp);\n       return temp;\n \n       /* ??? Can optimize bitwise operations with one arg constant.\n@@ -7968,16 +7927,14 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t only with operands that are always zero or one.  */\n       temp = expand_binop (mode, xor_optab, op0, const1_rtx,\n \t\t\t   target, 1, OPTAB_LIB_WIDEN);\n-      if (temp == 0)\n-\tabort ();\n+      gcc_assert (temp);\n       return temp;\n \n     case STATEMENT_LIST:\n       {\n \ttree_stmt_iterator iter;\n \n-\tif (!ignore)\n-\t  abort ();\n+\tgcc_assert (ignore);\n \n \tfor (iter = tsi_start (exp); !tsi_end_p (iter); tsi_next (&iter))\n \t  expand_expr (tsi_stmt (iter), const0_rtx, VOIDmode, modifier);\n@@ -7992,11 +7949,10 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n   \t  tree then_ = TREE_OPERAND (exp, 1);\n   \t  tree else_ = TREE_OPERAND (exp, 2);\n \n-\t  if (TREE_CODE (then_) != GOTO_EXPR\n-\t      || TREE_CODE (GOTO_DESTINATION (then_)) != LABEL_DECL\n-\t      || TREE_CODE (else_) != GOTO_EXPR\n-\t      || TREE_CODE (GOTO_DESTINATION (else_)) != LABEL_DECL)\n-\t    abort ();\n+\t  gcc_assert (TREE_CODE (then_) == GOTO_EXPR\n+\t\t      && TREE_CODE (GOTO_DESTINATION (then_)) == LABEL_DECL\n+\t\t      && TREE_CODE (else_) == GOTO_EXPR\n+\t\t      && TREE_CODE (GOTO_DESTINATION (else_)) == LABEL_DECL);\n \n \t  jumpif (pred, label_rtx (GOTO_DESTINATION (then_)));\n \t  return expand_expr (else_, const0_rtx, VOIDmode, 0);\n@@ -8007,11 +7963,10 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n   \t a temporary variable, so that we can evaluate them here\n   \t for side effect only.  If type is void, we must do likewise.  */\n \n-        if (TREE_ADDRESSABLE (type)\n- \t  || ignore\n- \t  || TREE_TYPE (TREE_OPERAND (exp, 1)) == void_type_node\n- \t  || TREE_TYPE (TREE_OPERAND (exp, 2)) == void_type_node)\n- \tabort ();\n+        gcc_assert (!TREE_ADDRESSABLE (type)\n+\t\t    && !ignore\n+\t\t    && TREE_TYPE (TREE_OPERAND (exp, 1)) != void_type_node\n+\t\t    && TREE_TYPE (TREE_OPERAND (exp, 2)) != void_type_node);\n \n        /* If we are not to produce a result, we have no target.  Otherwise,\n  \t if a target was specified use it; it will not be used as an\n@@ -8163,7 +8118,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n     case EH_FILTER_EXPR:\n     case TRY_FINALLY_EXPR:\n       /* Lowered by tree-eh.c.  */\n-      abort ();\n+      gcc_unreachable ();\n \n     case WITH_CLEANUP_EXPR:\n     case CLEANUP_POINT_EXPR:\n@@ -8185,7 +8140,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n     case TRUTH_ANDIF_EXPR:\n     case TRUTH_ORIF_EXPR:\n       /* Lowered by gimplify.c.  */\n-      abort ();\n+      gcc_unreachable ();\n \n     case EXC_PTR_EXPR:\n       return get_exception_pointer (cfun);\n@@ -8196,7 +8151,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n     case FDESC_EXPR:\n       /* Function descriptors are not valid except for as\n \t initialization constants, and should not be expanded.  */\n-      abort ();\n+      gcc_unreachable ();\n \n     case SWITCH_EXPR:\n       expand_case (exp);\n@@ -8232,8 +8187,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n     target = 0;\n   temp = expand_binop (mode, this_optab, op0, op1, target,\n \t\t       unsignedp, OPTAB_LIB_WIDEN);\n-  if (temp == 0)\n-    abort ();\n+  gcc_assert (temp);\n   return REDUCE_BIT_FIELD (temp);\n }\n #undef REDUCE_BIT_FIELD\n@@ -8499,7 +8453,7 @@ do_store_flag (tree exp, rtx target, enum machine_mode mode, int only_cheap)\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   /* Put a constant second.  */\n@@ -8595,8 +8549,7 @@ do_store_flag (tree exp, rtx target, enum machine_mode mode, int only_cheap)\n   code = GET_CODE (result);\n \n   label = gen_label_rtx ();\n-  if (bcc_gen_fctn[(int) code] == 0)\n-    abort ();\n+  gcc_assert (bcc_gen_fctn[(int) code]);\n \n   emit_jump_insn ((*bcc_gen_fctn[(int) code]) (label));\n   emit_move_insn (target, invert ? const1_rtx : const0_rtx);"}]}