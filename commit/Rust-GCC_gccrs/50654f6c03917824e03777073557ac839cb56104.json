{"sha": "50654f6c03917824e03777073557ac839cb56104", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTA2NTRmNmMwMzkxNzgyNGUwMzc3NzA3MzU1N2FjODM5Y2I1NjEwNA==", "commit": {"author": {"name": "Zdenek Dvorak", "email": "rakdver@atrey.karlin.mff.cuni.cz", "date": "2004-02-17T16:41:44Z"}, "committer": {"name": "Zdenek Dvorak", "email": "rakdver@gcc.gnu.org", "date": "2004-02-17T16:41:44Z"}, "message": "loop-iv.c: New file.\n\n\t* loop-iv.c: New file.\n\t* Makefile.in (loop-iv.o): New.\n\t* basic_block.h (FOR_BB_INSNS, FOR_BB_INSNS_REVERSE): New macros.\n\t* cfgloop.c (fill_sons_in_loop, get_loop_body_in_dom_order,\n\tnum_loop_branches): New functions.\n\t* cfgloop.h (get_loop_body_in_dom_order, num_loop_branches,\n\tiv_analysis_loop_init, iv_get_reaching_def, iv_analyse, get_iv_value,\n\tfind_simple_exit, iv_number_of_iterations, iv_analysis_done,\n\tget_simple_loop_desc, free_simple_loop_desc): Declare.\n\t(simple_loop_desc): New inline function.\n\t(struct rtx_iv, struct niter_desc): New.\n\t* cfgloopmanip.c (loopify): Specify semantics more precisely.\n\t* expr.c (force_operand): Handle subregs of expressions created by\n\tloop unroller.\n\t* loop-init.c (loop_optimizer_init, loop_optimizer_finalize): Move\n\tparts of the initialization to toplev.c\n\t* loop-unroll.c (loop_exit_at_end_p): New.\n\t(unroll_and_peel_loops): Call iv_analysis_done.\n\t(decide_peel_once_rolling, decide_peel_completely,\n\tdecide_unroll_stupid, decide_unroll_constant_iterations,\n\tdecide_unroll_runtime_iterations, decide_peel_simple,\n\tpeel_loop_simple, unroll_loop_stupid, unroll_loop_constant_iterations,\n\tunroll_loop_runtime_iterations): Use new simple loop analysis.\n\t* loop-unswitch.c (compare_and_jump_seq): New.\n\t(may_unswitch_on_p): Renamed to ...\n\t(may_unswitch_on): Use new iv analysis.\n\t(reversed_condition): Export.\n\t(unswitch_single_loop, unswitch_loop): Use new iv analysis.\n\t* predict.c (estimate_probability): Use new simple loop analysis.\n\t* rtl.h (get_mode_bounds, reversed_condition,compare_and_jump_seq,\n\tcanon_condition, simplify_using_condition): Declare.\n\t* stor-layout.c (get_mode_bounds): New.\n\t* toplev.c (rest_of_handle_loop2): Some parts of\n\tinitialization/finalization moved here from loop-init.c.\n\nFrom-SVN: r77951", "tree": {"sha": "871928dcce64f79c8e877a86be241c2ed02c9cf3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/871928dcce64f79c8e877a86be241c2ed02c9cf3"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/50654f6c03917824e03777073557ac839cb56104", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/50654f6c03917824e03777073557ac839cb56104", "html_url": "https://github.com/Rust-GCC/gccrs/commit/50654f6c03917824e03777073557ac839cb56104", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/50654f6c03917824e03777073557ac839cb56104/comments", "author": null, "committer": null, "parents": [{"sha": "cc7ce44e4c87839efaaddd07d1f03cc50a78d047", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cc7ce44e4c87839efaaddd07d1f03cc50a78d047", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cc7ce44e4c87839efaaddd07d1f03cc50a78d047"}], "stats": {"total": 3398, "additions": 3174, "deletions": 224}, "files": [{"sha": "de24deb627d19881958208e0081db00b98a8ec60", "filename": "gcc/ChangeLog", "status": "modified", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -1,3 +1,40 @@\n+2004-02-17  Zdenek Dvorak  <rakdver@atrey.karlin.mff.cuni.cz>\n+\n+\t* loop-iv.c: New file.\n+\t* Makefile.in (loop-iv.o): New.\n+\t* basic_block.h (FOR_BB_INSNS, FOR_BB_INSNS_REVERSE): New macros.\n+\t* cfgloop.c (fill_sons_in_loop, get_loop_body_in_dom_order,\n+\tnum_loop_branches): New functions.\n+\t* cfgloop.h (get_loop_body_in_dom_order, num_loop_branches,\n+\tiv_analysis_loop_init, iv_get_reaching_def, iv_analyse, get_iv_value,\n+\tfind_simple_exit, iv_number_of_iterations, iv_analysis_done,\n+\tget_simple_loop_desc, free_simple_loop_desc): Declare.\n+\t(simple_loop_desc): New inline function.\n+\t(struct rtx_iv, struct niter_desc): New.\n+\t* cfgloopmanip.c (loopify): Specify semantics more precisely.\n+\t* expr.c (force_operand): Handle subregs of expressions created by\n+\tloop unroller.\n+\t* loop-init.c (loop_optimizer_init, loop_optimizer_finalize): Move\n+\tparts of the initialization to toplev.c\n+\t* loop-unroll.c (loop_exit_at_end_p): New.\n+\t(unroll_and_peel_loops): Call iv_analysis_done.\n+\t(decide_peel_once_rolling, decide_peel_completely,\n+\tdecide_unroll_stupid, decide_unroll_constant_iterations,\n+\tdecide_unroll_runtime_iterations, decide_peel_simple,\n+\tpeel_loop_simple, unroll_loop_stupid, unroll_loop_constant_iterations,\n+\tunroll_loop_runtime_iterations): Use new simple loop analysis.\n+\t* loop-unswitch.c (compare_and_jump_seq): New.\n+\t(may_unswitch_on_p): Renamed to ...\n+\t(may_unswitch_on): Use new iv analysis.\n+\t(reversed_condition): Export.\n+\t(unswitch_single_loop, unswitch_loop): Use new iv analysis.\n+\t* predict.c (estimate_probability): Use new simple loop analysis.\n+\t* rtl.h (get_mode_bounds, reversed_condition,compare_and_jump_seq,\n+\tcanon_condition, simplify_using_condition): Declare.\n+\t* stor-layout.c (get_mode_bounds): New.\n+\t* toplev.c (rest_of_handle_loop2): Some parts of\n+\tinitialization/finalization moved here from loop-init.c.\n+\n 2004-02-17  Kazu Hirata  <kazu@cs.umass.edu>\n \n \t* config/h8300/h8300.h (FIXED_REGISTERS): Add the soft frame"}, {"sha": "06a70f28841e6a8a6d159d921d2cf97fd9084272", "filename": "gcc/Makefile.in", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -848,7 +848,7 @@ OBJS-common = \\\n  cfgloopanal.o cfgloopmanip.o loop-init.o loop-unswitch.o loop-unroll.o\t   \\\n  cfgrtl.o combine.o conflict.o convert.o coverage.o cse.o cselib.o \t   \\\n  dbxout.o debug.o df.o diagnostic.o dojump.o doloop.o dominance.o\t   \\\n- dwarf2asm.o dwarf2out.o emit-rtl.o except.o explow.o\t                   \\\n+ dwarf2asm.o dwarf2out.o emit-rtl.o except.o explow.o loop-iv.o\t\t   \\\n  expmed.o expr.o final.o flow.o fold-const.o function.o gcse.o\t\t   \\\n  genrtl.o ggc-common.o global.o graph.o gtype-desc.o\t\t\t   \\\n  haifa-sched.o hooks.o ifcvt.o insn-attrtab.o insn-emit.o insn-modes.o\t   \\\n@@ -1719,6 +1719,8 @@ cfgloop.o : cfgloop.c $(CONFIG_H) $(SYSTEM_H) $(RTL_H) coretypes.h $(TM_H) \\\n    $(BASIC_BLOCK_H) hard-reg-set.h cfgloop.h flags.h\n cfgloopanal.o : cfgloopanal.c $(CONFIG_H) $(SYSTEM_H) $(RTL_H) \\\n    $(BASIC_BLOCK_H) hard-reg-set.h cfgloop.h $(EXPR_H) coretypes.h $(TM_H)\n+loop-iv.o : loop-iv.c $(CONFIG_H) $(SYSTEM_H) $(RTL_H) $(GGC_H) \\\n+   $(BASIC_BLOCK_H) hard-reg-set.h cfgloop.h $(EXPR_H) coretypes.h $(TM_H)\n cfgloopmanip.o : cfgloopmanip.c $(CONFIG_H) $(SYSTEM_H) $(RTL_H) \\\n    $(BASIC_BLOCK_H) hard-reg-set.h cfgloop.h cfglayout.h output.h coretypes.h $(TM_H)\n loop-init.o : loop-init.c $(CONFIG_H) $(SYSTEM_H) $(RTL_H) \\"}, {"sha": "3f1775d8c3650ec87e929cba6cd6f43fe19ec57c", "filename": "gcc/basic-block.h", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Fbasic-block.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Fbasic-block.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbasic-block.h?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -288,6 +288,17 @@ extern varray_type basic_block_info;\n #define FOR_EACH_BB_REVERSE(BB) \\\n   FOR_BB_BETWEEN (BB, EXIT_BLOCK_PTR->prev_bb, ENTRY_BLOCK_PTR, prev_bb)\n \n+/* For iterating over insns in basic block.  */\n+#define FOR_BB_INSNS(BB, INSN)\t\t\t\\\n+  for ((INSN) = BB_HEAD (BB);\t\t\t\\\n+       (INSN) != NEXT_INSN (BB_END (BB));\t\\\n+       (INSN) = NEXT_INSN (INSN))\n+\n+#define FOR_BB_INSNS_REVERSE(BB, INSN)\t\t\\\n+  for ((INSN) = BB_END (BB);\t\t\t\\\n+       (INSN) != PREV_INSN (BB_HEAD (BB));\t\\\n+       (INSN) = PREV_INSN (INSN))\n+\n /* Cycles through _all_ basic blocks, even the fake ones (entry and\n    exit block).  */\n "}, {"sha": "2be4b7cc0b768d57d5a6ee04b5f4686aa5875b28", "filename": "gcc/cfgloop.c", "status": "modified", "additions": 77, "deletions": 0, "changes": 77, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Fcfgloop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Fcfgloop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgloop.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -959,6 +959,62 @@ get_loop_body (const struct loop *loop)\n   return tovisit;\n }\n \n+/* Fills dominance descendants inside LOOP of the basic block BB into\n+   array TOVISIT from index *TV.  */\n+\n+static void\n+fill_sons_in_loop (const struct loop *loop, basic_block bb,\n+\t\t   basic_block *tovisit, int *tv)\n+{\n+  basic_block son, postpone = NULL;\n+\n+  tovisit[(*tv)++] = bb;\n+  for (son = first_dom_son (CDI_DOMINATORS, bb);\n+       son;\n+       son = next_dom_son (CDI_DOMINATORS, son))\n+    {\n+      if (!flow_bb_inside_loop_p (loop, son))\n+\tcontinue;\n+\n+      if (dominated_by_p (CDI_DOMINATORS, loop->latch, son))\n+\t{\n+\t  postpone = son;\n+\t  continue;\n+\t}\n+      fill_sons_in_loop (loop, son, tovisit, tv);\n+    }\n+\n+  if (postpone)\n+    fill_sons_in_loop (loop, postpone, tovisit, tv);\n+}\n+\n+/* Gets body of a LOOP (that must be different from the outermost loop)\n+   sorted by dominance relation.  Additionally, if a basic block s dominates\n+   the latch, then only blocks dominated by s are be after it.  */\n+\n+basic_block *\n+get_loop_body_in_dom_order (const struct loop *loop)\n+{\n+  basic_block *tovisit;\n+  int tv;\n+\n+  if (!loop->num_nodes)\n+    abort ();\n+\n+  tovisit = xcalloc (loop->num_nodes, sizeof (basic_block));\n+\n+  if (loop->latch == EXIT_BLOCK_PTR)\n+    abort ();\n+\n+  tv = 0;\n+  fill_sons_in_loop (loop, loop->header, tovisit, &tv);\n+\n+  if (tv != (int) loop->num_nodes)\n+    abort ();\n+\n+  return tovisit;\n+}\n+\n /* Gets exit edges of a LOOP, returning their number in N_EDGES.  */\n edge *\n get_loop_exit_edges (const struct loop *loop, unsigned int *n_edges)\n@@ -988,6 +1044,27 @@ get_loop_exit_edges (const struct loop *loop, unsigned int *n_edges)\n   return edges;\n }\n \n+/* Counts the number of conditional branches inside LOOP.  */\n+\n+unsigned\n+num_loop_branches (const struct loop *loop)\n+{\n+  unsigned i, n;\n+  basic_block * body;\n+\n+  if (loop->latch == EXIT_BLOCK_PTR)\n+    abort ();\n+\n+  body = get_loop_body (loop);\n+  n = 0;\n+  for (i = 0; i < loop->num_nodes; i++)\n+    if (body[i]->succ && body[i]->succ->succ_next)\n+      n++;\n+  free (body);\n+\n+  return n;\n+}\n+\n /* Adds basic block BB to LOOP.  */\n void\n add_bb_to_loop (basic_block bb, struct loop *loop)"}, {"sha": "58184b5e29b9850a2652e9b143a4436e898d5c16", "filename": "gcc/cfgloop.h", "status": "modified", "additions": 110, "deletions": 0, "changes": 110, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Fcfgloop.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Fcfgloop.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgloop.h?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -278,7 +278,9 @@ extern int average_num_loop_insns (struct loop *);\n \n /* Loops & cfg manipulation.  */\n extern basic_block *get_loop_body (const struct loop *);\n+extern basic_block *get_loop_body_in_dom_order (const struct loop *);\n extern edge *get_loop_exit_edges (const struct loop *, unsigned *);\n+extern unsigned num_loop_branches (const struct loop *);\n \n extern edge loop_preheader_edge (const struct loop *);\n extern edge loop_latch_edge (const struct loop *);\n@@ -322,6 +324,114 @@ extern void unloop (struct loops *, struct loop *);\n extern bool remove_path (struct loops *, edge);\n extern edge split_loop_bb (basic_block, rtx);\n \n+/* Induction variable analysis.  */\n+\n+/* The description of induction variable.  The things are a bit complicated\n+   due to need to handle subregs and extends.  The value of the object described\n+   by it can be obtained as follows (all computations are done in extend_mode):\n+\n+   Value in i-th iteration is\n+     delta + mult * extend_{extend_mode} (subreg_{mode} (base + i * step)).\n+\n+   If first_special is true, the value in the first iteration is\n+     delta + mult * base\n+     \n+   If extend = NIL, first_special must be false, delta 0, mult 1 and value is\n+     subreg_{mode} (base + i * step)\n+\n+   The get_iv_value function can be used to obtain these expressions.\n+\n+   ??? Add a third mode field that would specify the mode in that inner\n+   computation is done, which would enable it to be different from the\n+   outer one?  */\n+\n+struct rtx_iv\n+{\n+  /* Its base and step (mode of base and step is supposed to be extend_mode,\n+     see the description above).  */\n+  rtx base, step;\n+\n+  /* The type of extend applied to it (SIGN_EXTEND, ZERO_EXTEND or NIL).  */\n+  enum rtx_code extend;\n+\n+  /* Operations applied in the extended mode.  */\n+  rtx delta, mult;\n+\n+  /* The mode it is extended to.  */\n+  enum machine_mode extend_mode;\n+\n+  /* The mode the variable iterates in.  */\n+  enum machine_mode mode;\n+\n+  /* Whether we have already filled the remaining fields.  */\n+  unsigned analysed : 1;\n+\n+  /* Whether the first iteration needs to be handled specially.  */\n+  unsigned first_special : 1;\n+};\n+\n+/* This should replace struct loop_desc.  We keep this just so that we are\n+   able to compare the results.  */\n+\n+struct niter_desc\n+{\n+  /* The edge out of the loop.  */\n+  edge out_edge;\n+\n+  /* The other edge leading from the condition.  */\n+  edge in_edge;\n+\n+  /* True if we are able to say anything about number of iterations of the\n+     loop.  */\n+  bool simple_p;\n+\n+  /* True if the loop iterates the constant number of times.  */\n+  bool const_iter;\n+\n+  /* Number of iterations if constant.  */\n+  unsigned HOST_WIDEST_INT niter;\n+\n+  /* Upper bound on the number of iterations.  */\n+  unsigned HOST_WIDEST_INT niter_max;\n+\n+  /* Assumptions under that the rest of the information is valid.  */\n+  rtx assumptions;\n+\n+  /* Assumptions under that the loop ends before reaching the latch,\n+     even if value of niter_expr says otherwise.  */\n+  rtx noloop_assumptions;\n+\n+  /* Condition under that the loop is infinite.  */\n+  rtx infinite;\n+\n+  /* Whether the comparison is signed.  */\n+  bool signed_p;\n+\n+  /* The mode in that niter_expr should be computed.  */\n+  enum machine_mode mode;\n+\n+  /* The number of iterations of the loop.  */\n+  rtx niter_expr;\n+};\n+\n+extern void iv_analysis_loop_init (struct loop *);\n+extern rtx iv_get_reaching_def (rtx, rtx);\n+extern bool iv_analyse (rtx, rtx, struct rtx_iv *);\n+extern rtx get_iv_value (struct rtx_iv *, rtx);\n+extern void find_simple_exit (struct loop *, struct niter_desc *);\n+extern void iv_number_of_iterations (struct loop *, rtx, rtx,\n+\t\t\t\t     struct niter_desc *);\n+extern void iv_analysis_done (void);\n+\n+extern struct niter_desc *get_simple_loop_desc (struct loop *loop);\n+extern void free_simple_loop_desc (struct loop *loop);\n+\n+static inline struct niter_desc *\n+simple_loop_desc (struct loop *loop)\n+{\n+  return loop->aux;\n+}\n+\n /* Loop optimizer initialization.  */\n extern struct loops *loop_optimizer_init (FILE *);\n extern void loop_optimizer_finalize (struct loops *, FILE *);"}, {"sha": "35444eea1c96aeda5e2d69a528953b0b3d466b18", "filename": "gcc/cfgloopmanip.c", "status": "modified", "additions": 9, "deletions": 5, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Fcfgloopmanip.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Fcfgloopmanip.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgloopmanip.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -480,11 +480,13 @@ scale_loop_frequencies (struct loop *loop, int num, int den)\n    accordingly. Everything between them plus LATCH_EDGE destination must\n    be dominated by HEADER_EDGE destination, and back-reachable from\n    LATCH_EDGE source.  HEADER_EDGE is redirected to basic block SWITCH_BB,\n-   SWITCH_BB->succ to original destination of LATCH_EDGE and\n-   SWITCH_BB->succ->succ_next to original destination of HEADER_EDGE.\n+   FALLTHRU_EDGE (SWITCH_BB) to original destination of HEADER_EDGE and\n+   BRANCH_EDGE (SWITCH_BB) to original destination of LATCH_EDGE.\n    Returns newly created loop.  */\n+\n struct loop *\n-loopify (struct loops *loops, edge latch_edge, edge header_edge, basic_block switch_bb)\n+loopify (struct loops *loops, edge latch_edge, edge header_edge, \n+\t basic_block switch_bb)\n {\n   basic_block succ_bb = latch_edge->dest;\n   basic_block pred_bb = header_edge->src;\n@@ -509,13 +511,15 @@ loopify (struct loops *loops, edge latch_edge, edge header_edge, basic_block swi\n \n   /* Redirect edges.  */\n   loop_redirect_edge (latch_edge, loop->header);\n+  loop_redirect_edge (BRANCH_EDGE (switch_bb), succ_bb);\n+\n   loop_redirect_edge (header_edge, switch_bb);\n-  loop_redirect_edge (switch_bb->succ->succ_next, loop->header);\n-  loop_redirect_edge (switch_bb->succ, succ_bb);\n+  loop_redirect_edge (FALLTHRU_EDGE (switch_bb), loop->header); \n \n   /* Update dominators.  */\n   set_immediate_dominator (CDI_DOMINATORS, switch_bb, pred_bb);\n   set_immediate_dominator (CDI_DOMINATORS, loop->header, switch_bb);\n+\n   set_immediate_dominator (CDI_DOMINATORS, succ_bb, switch_bb);\n \n   /* Compute new loop.  */"}, {"sha": "223a36b0136f152b33208ed9f767abc3ad41f40b", "filename": "gcc/expr.c", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -5588,6 +5588,20 @@ force_operand (rtx value, rtx target)\n   rtx subtarget = get_subtarget (target);\n   enum rtx_code code = GET_CODE (value);\n \n+  /* Check for subreg applied to an expression produced by loop optimizer.  */\n+  if (code == SUBREG\n+      && GET_CODE (SUBREG_REG (value)) != REG\n+      && GET_CODE (SUBREG_REG (value)) != MEM)\n+    {\n+      value = simplify_gen_subreg (GET_MODE (value),\n+\t\t\t\t   force_reg (GET_MODE (SUBREG_REG (value)),\n+\t\t\t\t\t      force_operand (SUBREG_REG (value),\n+\t\t\t\t\t\t\t     NULL_RTX)),\n+\t\t\t\t   GET_MODE (SUBREG_REG (value)),\n+\t\t\t\t   SUBREG_BYTE (value));\n+      code = GET_CODE (value);\n+    }\n+\n   /* Check for a PIC address load.  */\n   if ((code == PLUS || code == MINUS)\n       && XEXP (value, 0) == pic_offset_table_rtx"}, {"sha": "19d53e112bd799712dbd1cbff08ad72a248be58b", "filename": "gcc/loop-init.c", "status": "modified", "additions": 7, "deletions": 19, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-init.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-init.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-init.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -36,9 +36,6 @@ loop_optimizer_init (FILE *dumpfile)\n   struct loops *loops = xcalloc (1, sizeof (struct loops));\n   edge e;\n \n-  /* Initialize structures for layout changes.  */\n-  cfg_layout_initialize ();\n-\n   /* Avoid annoying special cases of edges going to exit\n      block.  */\n   for (e = EXIT_BLOCK_PTR->pred; e; e = e->pred_next)\n@@ -49,18 +46,11 @@ loop_optimizer_init (FILE *dumpfile)\n \n   if (flow_loops_find (loops, LOOP_TREE) <= 1)\n     {\n-      basic_block bb;\n-\n       /* No loops.  */\n       flow_loops_free (loops);\n       free_dominance_info (CDI_DOMINATORS);\n       free (loops);\n \n-      /* Make chain.  */\n-      FOR_EACH_BB (bb)\n-\tif (bb->next_bb != EXIT_BLOCK_PTR)\n-\t  bb->rbi->next = bb->next_bb;\n-\t  cfg_layout_finalize ();\n       return NULL;\n     }\n \n@@ -94,13 +84,14 @@ loop_optimizer_init (FILE *dumpfile)\n void\n loop_optimizer_finalize (struct loops *loops, FILE *dumpfile)\n {\n-  basic_block bb;\n+  unsigned i;\n \n-  /* Finalize layout changes.  */\n-  /* Make chain.  */\n-  FOR_EACH_BB (bb)\n-    if (bb->next_bb != EXIT_BLOCK_PTR)\n-      bb->rbi->next = bb->next_bb;\n+  if (!loops)\n+    return;\n+\n+  for (i = 1; i < loops->num; i++)\n+    if (loops->parray[i])\n+      free_simple_loop_desc (loops->parray[i]);\n \n   /* Another dump.  */\n   flow_loops_dump (loops, dumpfile, NULL, 1);\n@@ -110,9 +101,6 @@ loop_optimizer_finalize (struct loops *loops, FILE *dumpfile)\n   free_dominance_info (CDI_DOMINATORS);\n   free (loops);\n \n-  /* Finalize changes.  */\n-  cfg_layout_finalize ();\n-\n   /* Checking.  */\n #ifdef ENABLE_CHECKING\n   verify_flow_info ();"}, {"sha": "efdcc7395985ceb295560d82b6dca4185b8f4468", "filename": "gcc/loop-iv.c", "status": "added", "additions": 2465, "deletions": 0, "changes": 2465, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-iv.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-iv.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-iv.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -0,0 +1,2465 @@\n+/* Rtl-level induction variable analysis.\n+   Copyright (C) 2004 Free Software Foundation, Inc.\n+   \n+This file is part of GCC.\n+   \n+GCC is free software; you can redistribute it and/or modify it\n+under the terms of the GNU General Public License as published by the\n+Free Software Foundation; either version 2, or (at your option) any\n+later version.\n+   \n+GCC is distributed in the hope that it will be useful, but WITHOUT\n+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+   \n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+/* This is just a very simplistic analysis of induction variables of the loop.\n+   The major use is for determining the number of iterations of a loop for\n+   loop unrolling, doloop optimization and branch prediction.  For this we\n+   are only interested in bivs and a fairly limited set of givs that are\n+   needed in the exit condition.  We also only compute the iv information on\n+   demand.\n+\n+   The interesting registers are determined.  A register is interesting if\n+\n+   -- it is set only in the blocks that dominate the latch of the current loop\n+   -- all its sets are simple -- i.e. in the form we understand\n+\n+   We also number the insns sequentially in each basic block.  For a use of the\n+   interesting reg, it is now easy to find a reaching definition (there may be\n+   only one).\n+\n+   Induction variable is then simply analysed by walking the use-def\n+   chains.\n+   \n+   Usage:\n+\n+   iv_analysis_loop_init (loop);\n+   insn = iv_get_reaching_def (where, reg);\n+   if (iv_analyse (insn, reg, &iv))\n+     {\n+       ...\n+     }\n+   iv_analysis_done (); */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"rtl.h\"\n+#include \"hard-reg-set.h\"\n+#include \"basic-block.h\"\n+#include \"cfgloop.h\"\n+#include \"expr.h\"\n+#include \"output.h\"\n+\n+/* The insn information.  */\n+\n+struct insn_info\n+{\n+  /* Id of the insn.  */\n+  unsigned luid;\n+\n+  /* The previous definition of the register defined by the single\n+     set in the insn.  */\n+  rtx prev_def;\n+\n+  /* The description of the iv.  */\n+  struct rtx_iv iv;\n+};\n+\n+static struct insn_info *insn_info;\n+\n+/* The last definition of register.  */\n+\n+static rtx *last_def;\n+\n+/* The bivs.  */\n+\n+static struct rtx_iv *bivs;\n+\n+/* Maximal insn number for that there is place in insn_info array.  */\n+\n+static unsigned max_insn_no;\n+\n+/* Maximal register number for that there is place in bivs and last_def\n+   arrays.  */\n+\n+static unsigned max_reg_no;\n+\n+/* Dumps information about IV to FILE.  */\n+\n+extern void dump_iv_info (FILE *, struct rtx_iv *);\n+void\n+dump_iv_info (FILE *file, struct rtx_iv *iv)\n+{\n+  if (!iv->base)\n+    {\n+      fprintf (file, \"not simple\");\n+      return;\n+    }\n+\n+  if (iv->step == const0_rtx)\n+    {\n+      fprintf (file, \"invariant \");\n+      print_rtl (file, iv->base);\n+      return;\n+    }\n+\n+  print_rtl (file, iv->base);\n+  fprintf (file, \" + \");\n+  print_rtl (file, iv->step);\n+  fprintf (file, \" * iteration\");\n+  fprintf (file, \" (in %s)\", GET_MODE_NAME (iv->mode));\n+\n+  if (iv->mode != iv->extend_mode)\n+    fprintf (file, \" %s to %s\",\n+\t     rtx_name[iv->extend],\n+\t     GET_MODE_NAME (iv->extend_mode));\n+\n+  if (iv->mult != const1_rtx)\n+    {\n+      fprintf (file, \" * \");\n+      print_rtl (file, iv->mult);\n+    }\n+  if (iv->delta != const0_rtx)\n+    {\n+      fprintf (file, \" + \");\n+      print_rtl (file, iv->delta);\n+    }\n+  if (iv->first_special)\n+    fprintf (file, \" (first special)\");\n+}\n+\n+/* Assigns luids to insns in basic block BB.  */\n+\n+static void\n+assign_luids (basic_block bb)\n+{\n+  unsigned i = 0, uid;\n+  rtx insn;\n+\n+  FOR_BB_INSNS (bb, insn)\n+    {\n+      uid = INSN_UID (insn);\n+      insn_info[uid].luid = i++;\n+      insn_info[uid].prev_def = NULL_RTX;\n+      insn_info[uid].iv.analysed = false;\n+    }\n+}\n+\n+/* Generates a subreg to get the least significant part of EXPR (in mode\n+   INNER_MODE) to OUTER_MODE.  */\n+\n+static rtx\n+lowpart_subreg (enum machine_mode outer_mode, rtx expr,\n+\t\tenum machine_mode inner_mode)\n+{\n+  return simplify_gen_subreg (outer_mode, expr, inner_mode,\n+\t\t\t      subreg_lowpart_offset (outer_mode, inner_mode));\n+}\n+\n+/* Checks whether REG is a well-behaved register.  */\n+\n+static bool\n+simple_reg_p (rtx reg)\n+{\n+  unsigned r;\n+\n+  if (GET_CODE (reg) == SUBREG)\n+    {\n+      if (!subreg_lowpart_p (reg))\n+\treturn false;\n+      reg = SUBREG_REG (reg);\n+    }\n+\n+  if (!REG_P (reg))\n+    return false;\n+\n+  r = REGNO (reg);\n+  if (HARD_REGISTER_NUM_P (r))\n+    return false;\n+\n+  if (GET_MODE_CLASS (GET_MODE (reg)) != MODE_INT)\n+    return false;\n+\n+  if (last_def[r] == const0_rtx)\n+    return false;\n+\n+  return true;\n+}\n+\n+/* Checks whether assignment LHS = RHS is simple enough for us to process.  */\n+\n+static bool\n+simple_set_p (rtx lhs, rtx rhs)\n+{\n+  rtx op0, op1;\n+\n+  if (!REG_P (lhs)\n+      || !simple_reg_p (lhs))\n+    return false;\n+\n+  if (CONSTANT_P (rhs))\n+    return true;\n+\n+  switch (GET_CODE (rhs))\n+    {\n+    case SUBREG:\n+    case REG:\n+      return simple_reg_p (rhs);\n+\n+    case SIGN_EXTEND:\n+    case ZERO_EXTEND:\n+    case NEG:\n+      return simple_reg_p (XEXP (rhs, 0));\n+\n+    case PLUS:\n+    case MINUS:\n+    case MULT:\n+      op0 = XEXP (rhs, 0);\n+      op1 = XEXP (rhs, 1);\n+\n+      if (!simple_reg_p (op0)\n+\t  && !CONSTANT_P (op0))\n+\treturn false;\n+\n+      if (!simple_reg_p (op1)\n+\t  && !CONSTANT_P (op1))\n+\treturn false;\n+\n+      if (GET_CODE (rhs) == MULT\n+\t  && !CONSTANT_P (op0)\n+\t  && !CONSTANT_P (op1))\n+\treturn false;\n+\n+      return true;\n+\n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Mark single SET in INSN.  */\n+\n+static rtx\n+mark_single_set (rtx insn, rtx set)\n+{\n+  rtx def = SET_DEST (set), src;\n+  unsigned regno, uid;\n+\n+  src = find_reg_equal_equiv_note (insn);\n+  if (!src)\n+    src = SET_SRC (set);\n+\n+  if (!simple_set_p (SET_DEST (set), src))\n+    return NULL_RTX;\n+\n+  regno = REGNO (def);\n+  uid = INSN_UID (insn);\n+\n+  bivs[regno].analysed = false;\n+  insn_info[uid].prev_def = last_def[regno];\n+  last_def[regno] = insn;\n+\n+  return def;\n+}\n+\n+/* Invalidate register REG unless it is equal to EXCEPT.  */\n+\n+static void\n+kill_sets (rtx reg, rtx by ATTRIBUTE_UNUSED, void *except)\n+{\n+  if (GET_CODE (reg) == SUBREG)\n+    reg = SUBREG_REG (reg);\n+  if (!REG_P (reg))\n+    return;\n+  if (reg == except)\n+    return;\n+\n+  last_def[REGNO (reg)] = const0_rtx;\n+}\n+\n+/* Marks sets in basic block BB.  If DOM is true, BB dominates the loop\n+   latch.  */\n+\n+static void\n+mark_sets (basic_block bb, bool dom)\n+{\n+  rtx insn, set, def;\n+\n+  FOR_BB_INSNS (bb, insn)\n+    {\n+      if (!INSN_P (insn))\n+\tcontinue;\n+\n+      if (dom\n+\t  && (set = single_set (insn)))\n+\tdef = mark_single_set (insn, set);\n+      else\n+\tdef = NULL_RTX;\n+\n+      note_stores (PATTERN (insn), kill_sets, def);\n+    }\n+}\n+\n+/* Prepare the data for an induction variable analysis of a LOOP.  */\n+\n+void\n+iv_analysis_loop_init (struct loop *loop)\n+{\n+  basic_block *body = get_loop_body_in_dom_order (loop);\n+  unsigned b;\n+\n+  if ((unsigned) get_max_uid () >= max_insn_no)\n+    {\n+      /* Add some reserve for insns and registers produced in optimizations.  */\n+      max_insn_no = get_max_uid () + 100;\n+      if (insn_info)\n+\tfree (insn_info);\n+      insn_info = xmalloc (max_insn_no * sizeof (struct insn_info));\n+    }\n+\n+  if ((unsigned) max_reg_num () >= max_reg_no)\n+    {\n+      max_reg_no = max_reg_num () + 100;\n+      if (last_def)\n+\tfree (last_def);\n+      last_def = xmalloc (max_reg_no * sizeof (rtx));\n+      if (bivs)\n+\tfree (bivs);\n+      bivs = xmalloc (max_reg_no * sizeof (struct rtx_iv));\n+    }\n+\n+  memset (last_def, 0, max_reg_num () * sizeof (rtx));\n+\n+  for (b = 0; b < loop->num_nodes; b++)\n+    {\n+      assign_luids (body[b]);\n+      mark_sets (body[b], just_once_each_iteration_p (loop, body[b]));\n+    }\n+\n+  free (body);\n+}\n+\n+/* Gets definition of REG reaching the INSN.  If REG is not simple, const0_rtx\n+   is returned.  If INSN is before the first def in the loop, NULL_RTX is\n+   returned.  */\n+\n+rtx\n+iv_get_reaching_def (rtx insn, rtx reg)\n+{\n+  unsigned regno, luid, auid;\n+  rtx ainsn;\n+  basic_block bb, abb;\n+\n+  if (GET_CODE (reg) == SUBREG)\n+    {\n+      if (!subreg_lowpart_p (reg))\n+\treturn const0_rtx;\n+      reg = SUBREG_REG (reg);\n+    }\n+  if (!REG_P (reg))\n+    return NULL_RTX;\n+\n+  regno = REGNO (reg);\n+  if (!last_def[regno]\n+      || last_def[regno] == const0_rtx)\n+    return last_def[regno];\n+\n+  bb = BLOCK_FOR_INSN (insn);\n+  luid = insn_info[INSN_UID (insn)].luid;\n+\n+  ainsn = last_def[regno];\n+  while (1)\n+    {\n+      abb = BLOCK_FOR_INSN (ainsn);\n+\n+      if (dominated_by_p (CDI_DOMINATORS, bb, abb))\n+\tbreak;\n+\n+      auid = INSN_UID (ainsn);\n+      ainsn = insn_info[auid].prev_def;\n+\n+      if (!ainsn)\n+\treturn NULL_RTX;\n+    }\n+\n+  while (1)\n+    {\n+      abb = BLOCK_FOR_INSN (ainsn);\n+      if (abb != bb)\n+\treturn ainsn;\n+\n+      auid = INSN_UID (ainsn);\n+      if (luid > insn_info[auid].luid)\n+\treturn ainsn;\n+\n+      ainsn = insn_info[auid].prev_def;\n+      if (!ainsn)\n+\treturn NULL_RTX;\n+    }\n+}\n+\n+/* Sets IV to invariant CST in MODE.  Always returns true (just for\n+   consistency with other iv manipulation functions that may fail).  */\n+\n+static bool\n+iv_constant (struct rtx_iv *iv, rtx cst, enum machine_mode mode)\n+{\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (cst);\n+\n+  iv->analysed = true;\n+  iv->mode = mode;\n+  iv->base = cst;\n+  iv->step = const0_rtx;\n+  iv->first_special = false;\n+  iv->extend = NIL;\n+  iv->extend_mode = iv->mode;\n+  iv->delta = const0_rtx;\n+  iv->mult = const1_rtx;\n+\n+  return true;\n+}\n+\n+/* Evaluates application of subreg to MODE on IV.  */\n+\n+static bool\n+iv_subreg (struct rtx_iv *iv, enum machine_mode mode)\n+{\n+  if (iv->extend_mode == mode)\n+    return true;\n+\n+  if (GET_MODE_BITSIZE (mode) > GET_MODE_BITSIZE (iv->mode))\n+    return false;\n+\n+  iv->extend = NIL;\n+  iv->mode = mode;\n+\n+  iv->base = simplify_gen_binary (PLUS, iv->extend_mode, iv->delta,\n+\t\t\t\t  simplify_gen_binary (MULT, iv->extend_mode,\n+\t\t\t\t\t\t       iv->base, iv->mult));\n+  iv->step = simplify_gen_binary (MULT, iv->extend_mode, iv->step, iv->mult);\n+  iv->mult = const1_rtx;\n+  iv->delta = const0_rtx;\n+  iv->first_special = false;\n+\n+  return true;\n+}\n+\n+/* Evaluates application of EXTEND to MODE on IV.  */\n+\n+static bool\n+iv_extend (struct rtx_iv *iv, enum rtx_code extend, enum machine_mode mode)\n+{\n+  if (mode != iv->extend_mode)\n+    return false;\n+\n+  if (iv->extend != NIL\n+      && iv->extend != extend)\n+    return false;\n+\n+  iv->extend = extend;\n+\n+  return true;\n+}\n+\n+/* Evaluates negation of IV.  */\n+\n+static bool\n+iv_neg (struct rtx_iv *iv)\n+{\n+  if (iv->extend == NIL)\n+    {\n+      iv->base = simplify_gen_unary (NEG, iv->extend_mode,\n+\t\t\t\t     iv->base, iv->extend_mode);\n+      iv->step = simplify_gen_unary (NEG, iv->extend_mode,\n+\t\t\t\t     iv->step, iv->extend_mode);\n+    }\n+  else\n+    {\n+      iv->delta = simplify_gen_unary (NEG, iv->extend_mode,\n+\t\t\t\t      iv->delta, iv->extend_mode);\n+      iv->mult = simplify_gen_unary (NEG, iv->extend_mode,\n+\t\t\t\t     iv->mult, iv->extend_mode);\n+    }\n+\n+  return true;\n+}\n+\n+/* Evaluates addition or subtraction (according to OP) of IV1 to IV0.  */\n+\n+static bool\n+iv_add (struct rtx_iv *iv0, struct rtx_iv *iv1, enum rtx_code op)\n+{\n+  enum machine_mode mode;\n+  rtx arg;\n+\n+  /* Extend the constant to extend_mode of the other operand if neccesary.  */\n+  if (iv0->extend == NIL\n+      && iv0->mode == iv0->extend_mode\n+      && iv0->step == const0_rtx\n+      && GET_MODE_SIZE (iv0->extend_mode) < GET_MODE_SIZE (iv1->extend_mode))\n+    {\n+      iv0->extend_mode = iv1->extend_mode;\n+      iv0->base = simplify_gen_unary (ZERO_EXTEND, iv0->extend_mode,\n+\t\t\t\t      iv0->base, iv0->mode);\n+    }\n+  if (iv1->extend == NIL\n+      && iv1->mode == iv1->extend_mode\n+      && iv1->step == const0_rtx\n+      && GET_MODE_SIZE (iv1->extend_mode) < GET_MODE_SIZE (iv0->extend_mode))\n+    {\n+      iv1->extend_mode = iv0->extend_mode;\n+      iv1->base = simplify_gen_unary (ZERO_EXTEND, iv1->extend_mode,\n+\t\t\t\t      iv1->base, iv1->mode);\n+    }\n+\n+  mode = iv0->extend_mode;\n+  if (mode != iv1->extend_mode)\n+    return false;\n+\n+  if (iv0->extend == NIL && iv1->extend == NIL)\n+    {\n+      if (iv0->mode != iv1->mode)\n+\treturn false;\n+\n+      iv0->base = simplify_gen_binary (op, mode, iv0->base, iv1->base);\n+      iv0->step = simplify_gen_binary (op, mode, iv0->step, iv1->step);\n+\n+      return true;\n+    }\n+\n+  /* Handle addition of constant.  */\n+  if (iv1->extend == NIL\n+      && iv1->mode == mode\n+      && iv1->step == const0_rtx)\n+    {\n+      iv0->delta = simplify_gen_binary (op, mode, iv0->delta, iv1->base);\n+      return true;\n+    }\n+\n+  if (iv0->extend == NIL\n+      && iv0->mode == mode\n+      && iv0->step == const0_rtx)\n+    {\n+      arg = iv0->base;\n+      *iv0 = *iv1;\n+      if (op == MINUS\n+\t  && !iv_neg (iv0))\n+\treturn false;\n+\n+      iv0->delta = simplify_gen_binary (PLUS, mode, iv0->delta, arg);\n+      return true;\n+    }\n+\n+  return false;\n+}\n+\n+/* Evaluates multiplication of IV by constant CST.  */\n+\n+static bool\n+iv_mult (struct rtx_iv *iv, rtx mby)\n+{\n+  enum machine_mode mode = iv->extend_mode;\n+\n+  if (GET_MODE (mby) != VOIDmode\n+      && GET_MODE (mby) != mode)\n+    return false;\n+\n+  if (iv->extend == NIL)\n+    {\n+      iv->base = simplify_gen_binary (MULT, mode, iv->base, mby);\n+      iv->step = simplify_gen_binary (MULT, mode, iv->step, mby);\n+    }\n+  else\n+    {\n+      iv->delta = simplify_gen_binary (MULT, mode, iv->delta, mby);\n+      iv->mult = simplify_gen_binary (MULT, mode, iv->mult, mby);\n+    }\n+\n+  return true;\n+}\n+\n+/* The recursive part of get_biv_step.  Gets the value of the single value\n+   defined in INSN wrto initial value of REG inside loop, in shape described\n+   at get_biv_step.  */\n+\n+static bool\n+get_biv_step_1 (rtx insn, rtx reg,\n+\t\trtx *inner_step, enum machine_mode *inner_mode,\n+\t\tenum rtx_code *extend, enum machine_mode outer_mode,\n+\t\trtx *outer_step)\n+{\n+  rtx set, lhs, rhs, op0 = NULL_RTX, op1 = NULL_RTX;\n+  rtx next, nextr, def_insn, tmp;\n+  enum rtx_code code;\n+\n+  set = single_set (insn);\n+  rhs = find_reg_equal_equiv_note (insn);\n+  if (!rhs)\n+    rhs = SET_SRC (set);\n+  lhs = SET_DEST (set);\n+\n+  code = GET_CODE (rhs);\n+  switch (code)\n+    {\n+    case SUBREG:\n+    case REG:\n+      next = rhs;\n+      break;\n+\n+    case PLUS:\n+    case MINUS:\n+      op0 = XEXP (rhs, 0);\n+      op1 = XEXP (rhs, 1);\n+\n+      if (code == PLUS && CONSTANT_P (op0))\n+\t{\n+\t  tmp = op0; op0 = op1; op1 = tmp;\n+\t}\n+\n+      if (!simple_reg_p (op0)\n+\t  || !CONSTANT_P (op1))\n+\treturn false;\n+\n+      if (GET_MODE (rhs) != outer_mode)\n+\t{\n+\t  /* ppc64 uses expressions like\n+\n+\t     (set x:SI (plus:SI (subreg:SI y:DI) 1)).\n+\n+\t     this is equivalent to\n+\n+\t     (set x':DI (plus:DI y:DI 1))\n+\t     (set x:SI (subreg:SI (x':DI)).  */\n+\t  if (GET_CODE (op0) != SUBREG)\n+\t    return false;\n+\t  if (GET_MODE (SUBREG_REG (op0)) != outer_mode)\n+\t    return false;\n+\t}\n+\n+      next = op0;\n+      break;\n+\n+    case SIGN_EXTEND:\n+    case ZERO_EXTEND:\n+      if (GET_MODE (rhs) != outer_mode)\n+\treturn false;\n+\n+      op0 = XEXP (rhs, 0);\n+      if (!simple_reg_p (op0))\n+\treturn false;\n+\n+      next = op0;\n+      break;\n+\n+    default:\n+      return false;\n+    }\n+\n+  if (GET_CODE (next) == SUBREG)\n+    {\n+      if (!subreg_lowpart_p (next))\n+\treturn false;\n+\n+      nextr = SUBREG_REG (next);\n+      if (GET_MODE (nextr) != outer_mode)\n+\treturn false;\n+    }\n+  else\n+    nextr = next;\n+\n+  def_insn = iv_get_reaching_def (insn, nextr);\n+  if (def_insn == const0_rtx)\n+    return false;\n+\n+  if (!def_insn)\n+    {\n+      if (!rtx_equal_p (nextr, reg))\n+\treturn false;\n+\n+      *inner_step = const0_rtx;\n+      *extend = NIL;\n+      *inner_mode = outer_mode;\n+      *outer_step = const0_rtx;\n+    }\n+  else if (!get_biv_step_1 (def_insn, reg,\n+\t\t\t    inner_step, inner_mode, extend, outer_mode,\n+\t\t\t    outer_step))\n+    return false;\n+\n+  if (GET_CODE (next) == SUBREG)\n+    {\n+      enum machine_mode amode = GET_MODE (next);\n+\n+      if (GET_MODE_SIZE (amode) > GET_MODE_SIZE (*inner_mode))\n+\treturn false;\n+\n+      *inner_mode = amode;\n+      *inner_step = simplify_gen_binary (PLUS, outer_mode,\n+\t\t\t\t\t *inner_step, *outer_step);\n+      *outer_step = const0_rtx;\n+      *extend = NIL;\n+    }\n+\n+  switch (code)\n+    {\n+    case REG:\n+    case SUBREG:\n+      break;\n+\n+    case PLUS:\n+    case MINUS:\n+      if (*inner_mode == outer_mode\n+\t  /* See comment in previous switch.  */\n+\t  || GET_MODE (rhs) != outer_mode)\n+\t*inner_step = simplify_gen_binary (code, outer_mode,\n+\t\t\t\t\t   *inner_step, op1);\n+      else\n+\t*outer_step = simplify_gen_binary (code, outer_mode,\n+\t\t\t\t\t   *outer_step, op1);\n+      break;\n+\n+    case SIGN_EXTEND:\n+    case ZERO_EXTEND:\n+      if (GET_MODE (op0) != *inner_mode\n+\t  || *extend != NIL\n+\t  || *outer_step != const0_rtx)\n+\tabort ();\n+\n+      *extend = code;\n+      break;\n+\n+    default:\n+      abort ();\n+    }\n+\n+  return true;\n+}\n+\n+/* Gets the operation on register REG inside loop, in shape\n+\n+   OUTER_STEP + EXTEND_{OUTER_MODE} (SUBREG_{INNER_MODE} (REG + INNER_STEP))\n+\n+   If the operation cannot be described in this shape, return false.  */\n+\n+static bool\n+get_biv_step (rtx reg, rtx *inner_step, enum machine_mode *inner_mode,\n+\t      enum rtx_code *extend, enum machine_mode *outer_mode,\n+\t      rtx *outer_step)\n+{\n+  *outer_mode = GET_MODE (reg);\n+\n+  if (!get_biv_step_1 (last_def[REGNO (reg)], reg,\n+\t\t       inner_step, inner_mode, extend, *outer_mode,\n+\t\t       outer_step))\n+    return false;\n+\n+  if (*inner_mode != *outer_mode\n+      && *extend == NIL)\n+    abort ();\n+\n+  if (*inner_mode == *outer_mode\n+      && *extend != NIL)\n+    abort ();\n+\n+  if (*inner_mode == *outer_mode\n+      && *outer_step != const0_rtx)\n+    abort ();\n+\n+  return true;\n+}\n+\n+/* Determines whether DEF is a biv and if so, stores its description\n+   to *IV.  */\n+\n+static bool\n+iv_analyse_biv (rtx def, struct rtx_iv *iv)\n+{\n+  unsigned regno;\n+  rtx inner_step, outer_step;\n+  enum machine_mode inner_mode, outer_mode;\n+  enum rtx_code extend;\n+\n+  if (rtl_dump_file)\n+    {\n+      fprintf (rtl_dump_file, \"Analysing \");\n+      print_rtl (rtl_dump_file, def);\n+      fprintf (rtl_dump_file, \" for bivness.\\n\");\n+    }\n+    \n+  if (!REG_P (def))\n+    {\n+      if (!CONSTANT_P (def))\n+\treturn false;\n+\n+      return iv_constant (iv, def, VOIDmode);\n+    }\n+\n+  regno = REGNO (def);\n+  if (last_def[regno] == const0_rtx)\n+    {\n+      if (rtl_dump_file)\n+\tfprintf (rtl_dump_file, \"  not simple.\\n\");\n+      return false;\n+    }\n+\n+  if (last_def[regno] && bivs[regno].analysed)\n+    {\n+      if (rtl_dump_file)\n+\tfprintf (rtl_dump_file, \"  already analysed.\\n\");\n+\n+      *iv = bivs[regno];\n+      return iv->base != NULL_RTX;\n+    }\n+\n+  if (!last_def[regno])\n+    {\n+      iv_constant (iv, def, VOIDmode);\n+      goto end;\n+    }\n+\n+  iv->analysed = true;\n+  if (!get_biv_step (def, &inner_step, &inner_mode, &extend,\n+\t\t     &outer_mode, &outer_step))\n+    {\n+      iv->base = NULL_RTX;\n+      goto end;\n+    }\n+\n+  /* Loop transforms base to es (base + inner_step) + outer_step,\n+     where es means extend of subreg between inner_mode and outer_mode.\n+     The corresponding induction variable is\n+\n+     es ((base - outer_step) + i * (inner_step + outer_step)) + outer_step  */\n+\n+  iv->base = simplify_gen_binary (MINUS, outer_mode, def, outer_step);\n+  iv->step = simplify_gen_binary (PLUS, outer_mode, inner_step, outer_step);\n+  iv->mode = inner_mode;\n+  iv->extend_mode = outer_mode;\n+  iv->extend = extend;\n+  iv->mult = const1_rtx;\n+  iv->delta = outer_step;\n+  iv->first_special = inner_mode != outer_mode;\n+\n+end:\n+  if (rtl_dump_file)\n+    {\n+      fprintf (rtl_dump_file, \"  \");\n+      dump_iv_info (rtl_dump_file, iv);\n+      fprintf (rtl_dump_file, \"\\n\");\n+    }\n+\n+  bivs[regno] = *iv;\n+\n+  return iv->base != NULL_RTX;\n+}\n+\n+/* Analyses operand OP of INSN and stores the result to *IV.  */\n+\n+static bool\n+iv_analyse_op (rtx insn, rtx op, struct rtx_iv *iv)\n+{\n+  rtx def_insn;\n+  unsigned regno;\n+  bool inv = CONSTANT_P (op);\n+\n+  if (rtl_dump_file)\n+    {\n+      fprintf (rtl_dump_file, \"Analysing operand \");\n+      print_rtl (rtl_dump_file, op);\n+      fprintf (rtl_dump_file, \" of insn \");\n+      print_rtl_single (rtl_dump_file, insn);\n+    }\n+\n+  if (GET_CODE (op) == SUBREG)\n+    {\n+      if (!subreg_lowpart_p (op))\n+\treturn false;\n+\n+      if (!iv_analyse_op (insn, SUBREG_REG (op), iv))\n+\treturn false;\n+\n+      return iv_subreg (iv, GET_MODE (op));\n+    }\n+\n+  if (!inv)\n+    {\n+      regno = REGNO (op);\n+      if (!last_def[regno])\n+\tinv = true;\n+      else if (last_def[regno] == const0_rtx)\n+\t{\n+\t  if (rtl_dump_file)\n+\t    fprintf (rtl_dump_file, \"  not simple.\\n\");\n+\t  return false;\n+\t}\n+    }\n+\n+  if (inv)\n+    {\n+      iv_constant (iv, op, VOIDmode);\n+\n+      if (rtl_dump_file)\n+\t{\n+\t  fprintf (rtl_dump_file, \"  \");\n+\t  dump_iv_info (rtl_dump_file, iv);\n+\t  fprintf (rtl_dump_file, \"\\n\");\n+\t}\n+      return true;\n+    }\n+\n+  def_insn = iv_get_reaching_def (insn, op);\n+  if (def_insn == const0_rtx)\n+    {\n+      if (rtl_dump_file)\n+\tfprintf (rtl_dump_file, \"  not simple.\\n\");\n+      return false;\n+    }\n+\n+  return iv_analyse (def_insn, op, iv);\n+}\n+\n+/* Analyses iv DEF defined in INSN and stores the result to *IV.  */\n+\n+bool\n+iv_analyse (rtx insn, rtx def, struct rtx_iv *iv)\n+{\n+  unsigned uid;\n+  rtx set, rhs, mby = NULL_RTX, tmp;\n+  rtx op0 = NULL_RTX, op1 = NULL_RTX;\n+  struct rtx_iv iv0, iv1;\n+  enum machine_mode amode;\n+  enum rtx_code code;\n+\n+  if (insn == const0_rtx)\n+    return false;\n+\n+  if (GET_CODE (def) == SUBREG)\n+    {\n+      if (!subreg_lowpart_p (def))\n+\treturn false;\n+\n+      if (!iv_analyse (insn, SUBREG_REG (def), iv))\n+\treturn false;\n+\n+      return iv_subreg (iv, GET_MODE (def));\n+    }\n+\n+  if (!insn)\n+    return iv_analyse_biv (def, iv);\n+\n+  if (rtl_dump_file)\n+    {\n+      fprintf (rtl_dump_file, \"Analysing def of \");\n+      print_rtl (rtl_dump_file, def);\n+      fprintf (rtl_dump_file, \" in insn \");\n+      print_rtl_single (rtl_dump_file, insn);\n+    }\n+\n+  uid = INSN_UID (insn);\n+  if (insn_info[uid].iv.analysed)\n+    {\n+      if (rtl_dump_file)\n+\tfprintf (rtl_dump_file, \"  already analysed.\\n\");\n+      *iv = insn_info[uid].iv;\n+      return iv->base != NULL_RTX;\n+    }\n+\n+  iv->mode = VOIDmode;\n+  iv->base = NULL_RTX;\n+  iv->step = NULL_RTX;\n+\n+  set = single_set (insn);\n+  rhs = find_reg_equal_equiv_note (insn);\n+  if (!rhs)\n+    rhs = SET_SRC (set);\n+  code = GET_CODE (rhs);\n+\n+  if (CONSTANT_P (rhs))\n+    {\n+      op0 = rhs;\n+      amode = GET_MODE (def);\n+    }\n+  else\n+    {\n+      switch (code)\n+\t{\n+\tcase SUBREG:\n+\t  if (!subreg_lowpart_p (rhs))\n+\t    goto end;\n+\t  op0 = rhs;\n+\t  break;\n+\t  \n+\tcase REG:\n+\t  op0 = rhs;\n+\t  break;\n+\n+\tcase SIGN_EXTEND:\n+\tcase ZERO_EXTEND:\n+\tcase NEG:\n+\t  op0 = XEXP (rhs, 0);\n+\t  break;\n+\n+\tcase PLUS:\n+\tcase MINUS:\n+\t  op0 = XEXP (rhs, 0);\n+\t  op1 = XEXP (rhs, 1);\n+\t  break;\n+\n+\tcase MULT:\n+\t  op0 = XEXP (rhs, 0);\n+\t  mby = XEXP (rhs, 1);\n+\t  if (!CONSTANT_P (mby))\n+\t    {\n+\t      if (!CONSTANT_P (op0))\n+\t\tabort ();\n+\t      tmp = op0;\n+\t      op0 = mby;\n+\t      mby = tmp;\n+\t    }\n+\t  break;\n+\t    \n+\tdefault:\n+\t  abort ();\n+\t}\n+\n+      amode = GET_MODE (rhs);\n+    }\n+\n+  if (op0)\n+    {\n+      if (!iv_analyse_op (insn, op0, &iv0))\n+\tgoto end;\n+\t\n+      if (iv0.mode == VOIDmode)\n+\t{\n+\t  iv0.mode = amode;\n+\t  iv0.extend_mode = amode;\n+\t}\n+    }\n+\n+  if (op1)\n+    {\n+      if (!iv_analyse_op (insn, op1, &iv1))\n+\tgoto end;\n+\n+      if (iv1.mode == VOIDmode)\n+\t{\n+\t  iv1.mode = amode;\n+\t  iv1.extend_mode = amode;\n+\t}\n+    }\n+\n+  switch (code)\n+    {\n+    case SIGN_EXTEND:\n+    case ZERO_EXTEND:\n+      if (!iv_extend (&iv0, code, amode))\n+\tgoto end;\n+      break;\n+\n+    case NEG:\n+      if (!iv_neg (&iv0))\n+\tgoto end;\n+      break;\n+\n+    case PLUS:\n+    case MINUS:\n+      if (!iv_add (&iv0, &iv1, code))\n+\tgoto end;\n+      break;\n+\n+    case MULT:\n+      if (!iv_mult (&iv0, mby))\n+\tgoto end;\n+      break;\n+\n+    default:\n+      break;\n+    }\n+\n+  *iv = iv0;\n+\n+end:\n+  iv->analysed = true;\n+  insn_info[uid].iv = *iv;\n+\n+  if (rtl_dump_file)\n+    {\n+      print_rtl (rtl_dump_file, def);\n+      fprintf (rtl_dump_file, \" in insn \");\n+      print_rtl_single (rtl_dump_file, insn);\n+      fprintf (rtl_dump_file, \"  is \");\n+      dump_iv_info (rtl_dump_file, iv);\n+      fprintf (rtl_dump_file, \"\\n\");\n+    }\n+\n+  return iv->base != NULL_RTX;\n+}\n+\n+/* Calculates value of IV at ITERATION-th iteration.  */\n+\n+rtx\n+get_iv_value (struct rtx_iv *iv, rtx iteration)\n+{\n+  rtx val;\n+\n+  /* We would need to generate some if_then_else patterns, and so far\n+     it is not needed anywhere.  */\n+  if (iv->first_special)\n+    abort ();\n+\n+  if (iv->step != const0_rtx && iteration != const0_rtx)\n+    val = simplify_gen_binary (PLUS, iv->extend_mode, iv->base,\n+\t\t\t       simplify_gen_binary (MULT, iv->extend_mode,\n+\t\t\t\t\t\t    iv->step, iteration));\n+  else\n+    val = iv->base;\n+\n+  if (iv->extend_mode == iv->mode)\n+    return val;\n+\n+  val = lowpart_subreg (iv->mode, val, iv->extend_mode);\n+\n+  if (iv->extend == NIL)\n+    return val;\n+\n+  val = simplify_gen_unary (iv->extend, iv->extend_mode, val, iv->mode);\n+  val = simplify_gen_binary (PLUS, iv->extend_mode, iv->delta,\n+\t\t\t     simplify_gen_binary (MULT, iv->extend_mode,\n+\t\t\t\t\t\t  iv->mult, val));\n+\n+  return val;\n+}\n+\n+/* Free the data for an induction variable analysis.  */\n+\n+void\n+iv_analysis_done (void)\n+{\n+  max_insn_no = 0;\n+  max_reg_no = 0;\n+  if (insn_info)\n+    {\n+      free (insn_info);\n+      insn_info = NULL;\n+    }\n+  if (last_def)\n+    {\n+      free (last_def);\n+      last_def = NULL;\n+    }\n+  if (bivs)\n+    {\n+      free (bivs);\n+      bivs = NULL;\n+    }\n+}\n+\n+/* Computes inverse to X modulo (1 << MOD).  */\n+\n+static unsigned HOST_WIDEST_INT\n+inverse (unsigned HOST_WIDEST_INT x, int mod)\n+{\n+  unsigned HOST_WIDEST_INT mask =\n+\t  ((unsigned HOST_WIDEST_INT) 1 << (mod - 1) << 1) - 1;\n+  unsigned HOST_WIDEST_INT rslt = 1;\n+  int i;\n+\n+  for (i = 0; i < mod - 1; i++)\n+    {\n+      rslt = (rslt * x) & mask;\n+      x = (x * x) & mask;\n+    }\n+\n+  return rslt;\n+}\n+\n+/* Tries to estimate the maximum number of iterations.  */\n+\n+static unsigned HOST_WIDEST_INT\n+determine_max_iter (struct niter_desc *desc)\n+{\n+  rtx niter = desc->niter_expr;\n+  rtx mmin, mmax, left, right;\n+  unsigned HOST_WIDEST_INT nmax, inc;\n+\n+  if (GET_CODE (niter) == AND\n+      && GET_CODE (XEXP (niter, 0)) == CONST_INT)\n+    {\n+      nmax = INTVAL (XEXP (niter, 0));\n+      if (!(nmax & (nmax + 1)))\n+\t{\n+\t  desc->niter_max = nmax;\n+\t  return nmax;\n+\t}\n+    }\n+\n+  get_mode_bounds (desc->mode, desc->signed_p, &mmin, &mmax);\n+  nmax = INTVAL (mmax) - INTVAL (mmin);\n+\n+  if (GET_CODE (niter) == UDIV)\n+    {\n+      if (GET_CODE (XEXP (niter, 1)) != CONST_INT)\n+\t{\n+\t  desc->niter_max = nmax;\n+\t  return nmax;\n+\t}\n+      inc = INTVAL (XEXP (niter, 1));\n+      niter = XEXP (niter, 0);\n+    }\n+  else\n+    inc = 1;\n+\n+  if (GET_CODE (niter) == PLUS)\n+    {\n+      left = XEXP (niter, 0);\n+      right = XEXP (niter, 0);\n+\n+      if (GET_CODE (right) == CONST_INT)\n+\tright = GEN_INT (-INTVAL (right));\n+    }\n+  else if (GET_CODE (niter) == MINUS)\n+    {\n+      left = XEXP (niter, 0);\n+      right = XEXP (niter, 0);\n+    }\n+  else\n+    {\n+      left = niter;\n+      right = mmin;\n+    }\n+\n+  if (GET_CODE (left) == CONST_INT)\n+    mmax = left;\n+  if (GET_CODE (right) == CONST_INT)\n+    mmin = right;\n+  nmax = INTVAL (mmax) - INTVAL (mmin);\n+\n+  desc->niter_max = nmax / inc;\n+  return nmax / inc;\n+}\n+\n+/* Checks whether register *REG is in set ALT.  Callback for for_each_rtx.  */\n+\n+static int\n+altered_reg_used (rtx *reg, void *alt)\n+{\n+  if (!REG_P (*reg))\n+    return 0;\n+\n+  return REGNO_REG_SET_P (alt, REGNO (*reg));\n+}\n+\n+/* Marks registers altered by EXPR in set ALT.  */\n+\n+static void\n+mark_altered (rtx expr, rtx by ATTRIBUTE_UNUSED, void *alt)\n+{\n+  if (GET_CODE (expr) == SUBREG)\n+    expr = SUBREG_REG (expr);\n+  if (!REG_P (expr))\n+    return;\n+\n+  SET_REGNO_REG_SET (alt, REGNO (expr));\n+}\n+\n+/* Checks whether RHS is simple enough to process.  */\n+\n+static bool\n+simple_rhs_p (rtx rhs)\n+{\n+  rtx op0, op1;\n+\n+  if (CONSTANT_P (rhs)\n+      || REG_P (rhs))\n+    return true;\n+\n+  switch (GET_CODE (rhs))\n+    {\n+    case PLUS:\n+    case MINUS:\n+      op0 = XEXP (rhs, 0);\n+      op1 = XEXP (rhs, 1);\n+      /* Allow reg + const sets only.  */\n+      if (REG_P (op0) && CONSTANT_P (op1))\n+\treturn true;\n+      if (REG_P (op1) && CONSTANT_P (op0))\n+\treturn true;\n+\n+      return false;\n+\n+    default:\n+      return false;\n+    }\n+}\n+\n+/* Simplifies *EXPR using assignment in INSN.  ALTERED is the set of registers\n+   altered so far.  */\n+\n+static void\n+simplify_using_assignment (rtx insn, rtx *expr, regset altered)\n+{\n+  rtx set = single_set (insn);\n+  rtx lhs, rhs;\n+  bool ret = false;\n+\n+  if (set)\n+    {\n+      lhs = SET_DEST (set);\n+      if (GET_CODE (lhs) != REG\n+\t  || altered_reg_used (&lhs, altered))\n+\tret = true;\n+    }\n+  else\n+    ret = true;\n+\n+  note_stores (PATTERN (insn), mark_altered, altered);\n+  if (GET_CODE (insn) == CALL_INSN)\n+    {\n+      int i;\n+\n+      /* Kill all call clobbered registers.  */\n+      for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+\tif (TEST_HARD_REG_BIT (regs_invalidated_by_call, i))\n+\t  SET_REGNO_REG_SET (altered, i);\n+    }\n+\n+  if (ret)\n+    return;\n+\n+  rhs = find_reg_equal_equiv_note (insn);\n+  if (!rhs)\n+    rhs = SET_SRC (set);\n+\n+  if (!simple_rhs_p (rhs))\n+    return;\n+\n+  if (for_each_rtx (&rhs, altered_reg_used, altered))\n+    return;\n+\n+  *expr = simplify_replace_rtx (*expr, lhs, rhs);\n+}\n+\n+/* Checks whether A implies B.  */\n+\n+static bool\n+implies_p (rtx a, rtx b)\n+{\n+  rtx op0, op1, r;\n+\n+  if (GET_CODE (a) == EQ)\n+    {\n+      op0 = XEXP (a, 0);\n+      op1 = XEXP (a, 1);\n+\n+      if (REG_P (op0))\n+\t{\n+\t  r = simplify_replace_rtx (b, op0, op1);\n+\t  if (r == const_true_rtx)\n+\t    return true;\n+\t}\n+\n+      if (REG_P (op1))\n+\t{\n+\t  r = simplify_replace_rtx (b, op1, op0);\n+\t  if (r == const_true_rtx)\n+\t    return true;\n+\t}\n+    }\n+\n+  return false;\n+}\n+\n+/* Canonicalizes COND so that\n+\n+   (1) Ensure that operands are ordered according to\n+       swap_commutative_operands_p.\n+   (2) (LE x const) will be replaced with (LT x <const+1>) and similarly\n+       for GE, GEU, and LEU.  */\n+\n+rtx\n+canon_condition (rtx cond)\n+{\n+  rtx tem;\n+  rtx op0, op1;\n+  enum rtx_code code;\n+  enum machine_mode mode;\n+\n+  code = GET_CODE (cond);\n+  op0 = XEXP (cond, 0);\n+  op1 = XEXP (cond, 1);\n+\n+  if (swap_commutative_operands_p (op0, op1))\n+    {\n+      code = swap_condition (code);\n+      tem = op0;\n+      op0 = op1;\n+      op1 = tem;\n+    }\n+\n+  mode = GET_MODE (op0);\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (op1);\n+  if (mode == VOIDmode)\n+    abort ();\n+\n+  if (GET_CODE (op1) == CONST_INT\n+      && GET_MODE_CLASS (mode) != MODE_CC\n+      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+    {\n+      HOST_WIDE_INT const_val = INTVAL (op1);\n+      unsigned HOST_WIDE_INT uconst_val = const_val;\n+      unsigned HOST_WIDE_INT max_val\n+\t= (unsigned HOST_WIDE_INT) GET_MODE_MASK (mode);\n+\n+      switch (code)\n+\t{\n+\tcase LE:\n+\t  if ((unsigned HOST_WIDE_INT) const_val != max_val >> 1)\n+\t    code = LT, op1 = gen_int_mode (const_val + 1, GET_MODE (op0));\n+\t  break;\n+\n+\t/* When cross-compiling, const_val might be sign-extended from\n+\t   BITS_PER_WORD to HOST_BITS_PER_WIDE_INT */\n+\tcase GE:\n+\t  if ((HOST_WIDE_INT) (const_val & max_val)\n+\t      != (((HOST_WIDE_INT) 1\n+\t\t   << (GET_MODE_BITSIZE (GET_MODE (op0)) - 1))))\n+\t    code = GT, op1 = gen_int_mode (const_val - 1, mode);\n+\t  break;\n+\n+\tcase LEU:\n+\t  if (uconst_val < max_val)\n+\t    code = LTU, op1 = gen_int_mode (uconst_val + 1, mode);\n+\t  break;\n+\n+\tcase GEU:\n+\t  if (uconst_val != 0)\n+\t    code = GTU, op1 = gen_int_mode (uconst_val - 1, mode);\n+\t  break;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+    }\n+\n+  if (op0 != XEXP (cond, 0)\n+      || op1 != XEXP (cond, 1)\n+      || code != GET_CODE (cond)\n+      || GET_MODE (cond) != SImode)\n+    cond = gen_rtx_fmt_ee (code, SImode, op0, op1);\n+\n+  return cond;\n+}\n+\n+/* Tries to use the fact that COND holds to simplify EXPR.  ALTERED is the\n+   set of altered regs.  */\n+\n+void\n+simplify_using_condition (rtx cond, rtx *expr, regset altered)\n+{\n+  rtx rev, reve, exp = *expr;\n+\n+  if (GET_RTX_CLASS (GET_CODE (*expr)) != '<')\n+    return;\n+\n+  /* If some register gets altered later, we do not really speak about its\n+     value at the time of comparison.  */\n+  if (altered\n+      && for_each_rtx (&cond, altered_reg_used, altered))\n+    return;\n+\n+  rev = reversed_condition (cond);\n+  reve = reversed_condition (exp);\n+\n+  cond = canon_condition (cond);\n+  exp = canon_condition (exp);\n+  if (rev)\n+    rev = canon_condition (rev);\n+  if (reve)\n+    reve = canon_condition (reve);\n+\n+  if (rtx_equal_p (exp, cond))\n+    {\n+      *expr = const_true_rtx;\n+      return;\n+    }\n+\n+\n+  if (rev && rtx_equal_p (exp, rev))\n+    {\n+      *expr = const0_rtx;\n+      return;\n+    }\n+\n+  if (implies_p (cond, exp))\n+    {\n+      *expr = const_true_rtx;\n+      return;\n+    }\n+  \n+  if (reve && implies_p (cond, reve))\n+    {\n+      *expr = const0_rtx;\n+      return;\n+    }\n+\n+  /* A proof by contradiction.  If *EXPR implies (not cond), *EXPR must\n+     be false.  */\n+  if (rev && implies_p (exp, rev))\n+    {\n+      *expr = const0_rtx;\n+      return;\n+    }\n+\n+  /* Similarly, If (not *EXPR) implies (not cond), *EXPR must be true.  */\n+  if (rev && reve && implies_p (reve, rev))\n+    {\n+      *expr = const_true_rtx;\n+      return;\n+    }\n+\n+  /* We would like to have some other tests here.  TODO.  */\n+\n+  return;\n+}\n+\n+/* Use relationship between A and *B to eventually eliminate *B.\n+   OP is the operation we consider.  */\n+\n+static void\n+eliminate_implied_condition (enum rtx_code op, rtx a, rtx *b)\n+{\n+  if (op == AND)\n+    {\n+      /* If A implies *B, we may replace *B by true.  */\n+      if (implies_p (a, *b))\n+\t*b = const_true_rtx;\n+    }\n+  else if (op == IOR)\n+    {\n+      /* If *B implies A, we may replace *B by false.  */\n+      if (implies_p (*b, a))\n+\t*b = const0_rtx;\n+    }\n+  else\n+    abort ();\n+}\n+\n+/* Eliminates the conditions in TAIL that are implied by HEAD.  OP is the\n+   operation we consider.  */\n+\n+static void\n+eliminate_implied_conditions (enum rtx_code op, rtx *head, rtx tail)\n+{\n+  rtx elt;\n+\n+  for (elt = tail; elt; elt = XEXP (elt, 1))\n+    eliminate_implied_condition (op, *head, &XEXP (elt, 0));\n+  for (elt = tail; elt; elt = XEXP (elt, 1))\n+    eliminate_implied_condition (op, XEXP (elt, 0), head);\n+}\n+\n+/* Simplifies *EXPR using initial values at the start of the LOOP.  If *EXPR\n+   is a list, its elements are assumed to be combined using OP.  */\n+\n+static void\n+simplify_using_initial_values (struct loop *loop, enum rtx_code op, rtx *expr)\n+{\n+  rtx head, tail, insn;\n+  rtx neutral, aggr;\n+  regset altered;\n+  regset_head altered_head;\n+  edge e;\n+\n+  if (!*expr)\n+    return;\n+\n+  if (CONSTANT_P (*expr))\n+    return;\n+\n+  if (GET_CODE (*expr) == EXPR_LIST)\n+    {\n+      head = XEXP (*expr, 0);\n+      tail = XEXP (*expr, 1);\n+\n+      eliminate_implied_conditions (op, &head, tail);\n+\n+      if (op == AND)\n+\t{\n+\t  neutral = const_true_rtx;\n+\t  aggr = const0_rtx;\n+\t}\n+      else if (op == IOR)\n+\t{\n+\t  neutral = const0_rtx;\n+\t  aggr = const_true_rtx;\n+\t}\n+      else\n+\tabort ();\n+\n+      simplify_using_initial_values (loop, NIL, &head);\n+      if (head == aggr)\n+\t{\n+\t  XEXP (*expr, 0) = aggr;\n+\t  XEXP (*expr, 1) = NULL_RTX;\n+\t  return;\n+\t}\n+      else if (head == neutral)\n+\t{\n+\t  *expr = tail;\n+\t  simplify_using_initial_values (loop, op, expr);\n+\t  return;\n+\t}\n+      simplify_using_initial_values (loop, op, &tail);\n+\n+      if (tail && XEXP (tail, 0) == aggr)\n+\t{\n+\t  *expr = tail;\n+\t  return;\n+\t}\n+  \n+      XEXP (*expr, 0) = head;\n+      XEXP (*expr, 1) = tail;\n+      return;\n+    }\n+\n+  if (op != NIL)\n+    abort ();\n+\n+  e = loop_preheader_edge (loop);\n+  if (e->src == ENTRY_BLOCK_PTR)\n+    return;\n+\n+  altered = INITIALIZE_REG_SET (altered_head);\n+\n+  while (1)\n+    {\n+      insn = BB_END (e->src);\n+      if (any_condjump_p (insn))\n+\t{\n+\t  /* FIXME -- slightly wrong -- what if compared register\n+\t     gets altered between start of the condition and insn?  */\n+\t  rtx cond = get_condition (BB_END (e->src), NULL, false);\n+      \n+\t  if (cond && (e->flags & EDGE_FALLTHRU))\n+\t    cond = reversed_condition (cond);\n+\t  if (cond)\n+\t    {\n+\t      simplify_using_condition (cond, expr, altered);\n+\t      if (CONSTANT_P (*expr))\n+\t\t{\n+\t\t  FREE_REG_SET (altered);\n+\t\t  return;\n+\t\t}\n+\t    }\n+\t}\n+\n+      FOR_BB_INSNS_REVERSE (e->src, insn)\n+\t{\n+\t  if (!INSN_P (insn))\n+\t    continue;\n+\t    \n+\t  simplify_using_assignment (insn, expr, altered);\n+\t  if (CONSTANT_P (*expr))\n+\t    {\n+\t      FREE_REG_SET (altered);\n+\t      return;\n+\t    }\n+\t}\n+\n+      e = e->src->pred;\n+      if (e->pred_next\n+\t  || e->src == ENTRY_BLOCK_PTR)\n+\tbreak;\n+    }\n+\n+  FREE_REG_SET (altered);\n+}\n+\n+/* Transforms invariant IV into MODE.  Adds assumptions based on the fact\n+   that IV occurs as left operands of comparison COND and its signedness\n+   is SIGNED_P to DESC.  */\n+\n+static void\n+shorten_into_mode (struct rtx_iv *iv, enum machine_mode mode,\n+\t\t   enum rtx_code cond, bool signed_p, struct niter_desc *desc)\n+{\n+  rtx mmin, mmax, cond_over, cond_under;\n+\n+  get_mode_bounds (mode, signed_p, &mmin, &mmax);\n+  cond_under = simplify_gen_relational (LT, SImode, iv->extend_mode,\n+\t\t\t\t\tiv->base, mmin);\n+  cond_over = simplify_gen_relational (GT, SImode, iv->extend_mode,\n+\t\t\t\t       iv->base, mmax);\n+\n+  switch (cond)\n+    {\n+      case LE:\n+      case LT:\n+      case LEU:\n+      case LTU:\n+\tif (cond_under != const0_rtx)\n+\t  desc->infinite =\n+\t\t  alloc_EXPR_LIST (0, cond_under, desc->infinite);\n+\tif (cond_over != const0_rtx)\n+\t  desc->noloop_assumptions =\n+\t\t  alloc_EXPR_LIST (0, cond_over, desc->noloop_assumptions);\n+\tbreak;\n+\n+      case GE:\n+      case GT:\n+      case GEU:\n+      case GTU:\n+\tif (cond_over != const0_rtx)\n+\t  desc->infinite =\n+\t\t  alloc_EXPR_LIST (0, cond_over, desc->infinite);\n+\tif (cond_under != const0_rtx)\n+\t  desc->noloop_assumptions =\n+\t\t  alloc_EXPR_LIST (0, cond_under, desc->noloop_assumptions);\n+\tbreak;\n+\n+      case NE:\n+\tif (cond_over != const0_rtx)\n+\t  desc->infinite =\n+\t\t  alloc_EXPR_LIST (0, cond_over, desc->infinite);\n+\tif (cond_under != const0_rtx)\n+\t  desc->infinite =\n+\t\t  alloc_EXPR_LIST (0, cond_under, desc->infinite);\n+\tbreak;\n+\n+      default:\n+\tabort ();\n+    }\n+\n+  iv->mode = mode;\n+  iv->extend = signed_p ? SIGN_EXTEND : ZERO_EXTEND;\n+}\n+\n+/* Transforms IV0 and IV1 compared by COND so that they are both compared as\n+   subregs of the same mode if possible (sometimes it is neccesary to add\n+   some assumptions to DESC).  */\n+\n+static bool\n+canonicalize_iv_subregs (struct rtx_iv *iv0, struct rtx_iv *iv1,\n+\t\t\t enum rtx_code cond, struct niter_desc *desc)\n+{\n+  enum machine_mode comp_mode;\n+  bool signed_p;\n+\n+  /* If the ivs behave specially in the first iteration, or are\n+     added/multiplied after extending, we ignore them.  */\n+  if (iv0->first_special || iv0->mult != const1_rtx || iv0->delta != const0_rtx)\n+    return false;\n+  if (iv1->first_special || iv1->mult != const1_rtx || iv1->delta != const0_rtx)\n+    return false;\n+\n+  /* If there is some extend, it must match signedness of the comparison.  */\n+  switch (cond)\n+    {\n+      case LE:\n+      case LT:\n+\tif (iv0->extend == ZERO_EXTEND\n+\t    || iv1->extend == ZERO_EXTEND)\n+\t  return false;\n+\tsigned_p = true;\n+\tbreak;\n+\n+      case LEU:\n+      case LTU:\n+\tif (iv0->extend == SIGN_EXTEND\n+\t    || iv1->extend == SIGN_EXTEND)\n+\t  return false;\n+\tsigned_p = false;\n+\tbreak;\n+\n+      case NE:\n+\tif (iv0->extend != NIL\n+\t    && iv1->extend != NIL\n+\t    && iv0->extend != iv1->extend)\n+\t  return false;\n+\n+\tsigned_p = false;\n+\tif (iv0->extend != NIL)\n+\t  signed_p = iv0->extend == SIGN_EXTEND;\n+\tif (iv1->extend != NIL)\n+\t  signed_p = iv1->extend == SIGN_EXTEND;\n+\tbreak;\n+\n+      default:\n+\tabort ();\n+    }\n+\n+  /* Values of both variables should be computed in the same mode.  These\n+     might indeed be different, if we have comparison like\n+\n+     (compare (subreg:SI (iv0)) (subreg:SI (iv1)))\n+\n+     and iv0 and iv1 are both ivs iterating in SI mode, but calculated\n+     in different modes.  This does not seem impossible to handle, but\n+     it hardly ever occurs in practice.\n+     \n+     The only exception is the case when one of operands is invariant.\n+     For example pentium 3 generates comparisons like\n+     (lt (subreg:HI (reg:SI)) 100).  Here we assign HImode to 100, but we\n+     definitely do not want this prevent the optimization.  */\n+  comp_mode = iv0->extend_mode;\n+  if (GET_MODE_BITSIZE (comp_mode) < GET_MODE_BITSIZE (iv1->extend_mode))\n+    comp_mode = iv1->extend_mode;\n+\n+  if (iv0->extend_mode != comp_mode)\n+    {\n+      if (iv0->mode != iv0->extend_mode\n+\t  || iv0->step != const0_rtx)\n+\treturn false;\n+\n+      iv0->base = simplify_gen_unary (signed_p ? SIGN_EXTEND : ZERO_EXTEND,\n+\t\t\t\t      comp_mode, iv0->base, iv0->mode);\n+      iv0->extend_mode = comp_mode;\n+    }\n+\n+  if (iv1->extend_mode != comp_mode)\n+    {\n+      if (iv1->mode != iv1->extend_mode\n+\t  || iv1->step != const0_rtx)\n+\treturn false;\n+\n+      iv1->base = simplify_gen_unary (signed_p ? SIGN_EXTEND : ZERO_EXTEND,\n+\t\t\t\t      comp_mode, iv1->base, iv1->mode);\n+      iv1->extend_mode = comp_mode;\n+    }\n+\n+  /* Check that both ivs belong to a range of a single mode.  If one of the\n+     operands is an invariant, we may need to shorten it into the common\n+     mode.  */\n+  if (iv0->mode == iv0->extend_mode\n+      && iv0->step == const0_rtx\n+      && iv0->mode != iv1->mode)\n+    shorten_into_mode (iv0, iv1->mode, cond, signed_p, desc);\n+\n+  if (iv1->mode == iv1->extend_mode\n+      && iv1->step == const0_rtx\n+      && iv0->mode != iv1->mode)\n+    shorten_into_mode (iv1, iv0->mode, swap_condition (cond), signed_p, desc);\n+\n+  if (iv0->mode != iv1->mode)\n+    return false;\n+\n+  desc->mode = iv0->mode;\n+  desc->signed_p = signed_p;\n+\n+  return true;\n+}\n+\n+/* Computes number of iterations of the CONDITION in INSN in LOOP and stores\n+   the result into DESC.  Very similar to determine_number_of_iterations\n+   (basically its rtl version), complicated by things like subregs.  */\n+\n+void\n+iv_number_of_iterations (struct loop *loop, rtx insn, rtx condition,\n+\t\t\t struct niter_desc *desc)\n+{\n+  rtx op0, op1, delta, step, bound, may_xform, def_insn, tmp, tmp0, tmp1;\n+  struct rtx_iv iv0, iv1, tmp_iv;\n+  rtx assumption;\n+  enum rtx_code cond;\n+  enum machine_mode mode, comp_mode;\n+  rtx mmin, mmax;\n+  unsigned HOST_WIDEST_INT s, size, d;\n+  HOST_WIDEST_INT up, down, inc;\n+  int was_sharp = false;\n+\n+  /* The meaning of these assumptions is this:\n+     if !assumptions\n+       then the rest of information does not have to be valid\n+     if noloop_assumptions then the loop does not roll\n+     if infinite then this exit is never used */\n+\n+  desc->assumptions = NULL_RTX;\n+  desc->noloop_assumptions = NULL_RTX;\n+  desc->infinite = NULL_RTX;\n+  desc->simple_p = true;\n+\n+  desc->const_iter = false;\n+  desc->niter_expr = NULL_RTX;\n+  desc->niter_max = 0;\n+\n+  cond = GET_CODE (condition);\n+  if (GET_RTX_CLASS (cond) != '<')\n+    abort ();\n+\n+  mode = GET_MODE (XEXP (condition, 0));\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (XEXP (condition, 1));\n+  /* The constant comparisons should be folded.  */\n+  if (mode == VOIDmode)\n+    abort ();\n+\n+  /* We only handle integers or pointers.  */\n+  if (GET_MODE_CLASS (mode) != MODE_INT\n+      && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)\n+    goto fail;\n+\n+  op0 = XEXP (condition, 0);\n+  def_insn = iv_get_reaching_def (insn, op0);\n+  if (!iv_analyse (def_insn, op0, &iv0))\n+    goto fail;\n+  if (iv0.extend_mode == VOIDmode)\n+    iv0.mode = iv0.extend_mode = mode;\n+  \n+  op1 = XEXP (condition, 1);\n+  def_insn = iv_get_reaching_def (insn, op1);\n+  if (!iv_analyse (def_insn, op1, &iv1))\n+    goto fail;\n+  if (iv1.extend_mode == VOIDmode)\n+    iv1.mode = iv1.extend_mode = mode;\n+\n+  if (GET_MODE_BITSIZE (iv0.extend_mode) > HOST_BITS_PER_WIDE_INT\n+      || GET_MODE_BITSIZE (iv1.extend_mode) > HOST_BITS_PER_WIDE_INT)\n+    goto fail;\n+\n+  /* Check condition and normalize it.  */\n+\n+  switch (cond)\n+    {\n+      case GE:\n+      case GT:\n+      case GEU:\n+      case GTU:\n+\ttmp_iv = iv0; iv0 = iv1; iv1 = tmp_iv;\n+\tcond = swap_condition (cond);\n+\tbreak;\n+      case NE:\n+      case LE:\n+      case LEU:\n+      case LT:\n+      case LTU:\n+\tbreak;\n+      default:\n+\tgoto fail;\n+    }\n+\n+  /* Handle extends.  This is relatively nontrivial, so we only try in some\n+     easy cases, when we can canonicalize the ivs (possibly by adding some\n+     assumptions) to shape subreg (base + i * step).  This function also fills\n+     in desc->mode and desc->signed_p.  */\n+\n+  if (!canonicalize_iv_subregs (&iv0, &iv1, cond, desc))\n+    goto fail;\n+\n+  comp_mode = iv0.extend_mode;\n+  mode = iv0.mode;\n+  size = GET_MODE_BITSIZE (mode);\n+  get_mode_bounds (mode, (cond == LE || cond == LT), &mmin, &mmax);\n+\n+  if (GET_CODE (iv0.step) != CONST_INT || GET_CODE (iv1.step) != CONST_INT)\n+    goto fail;\n+\n+  /* We can take care of the case of two induction variables chasing each other\n+     if the test is NE. I have never seen a loop using it, but still it is\n+     cool.  */\n+  if (iv0.step != const0_rtx && iv1.step != const0_rtx)\n+    {\n+      if (cond != NE)\n+\tgoto fail;\n+\n+      iv0.step = simplify_gen_binary (MINUS, comp_mode, iv0.step, iv1.step);\n+      iv1.step = const0_rtx;\n+    }\n+\n+  /* This is either infinite loop or the one that ends immediately, depending\n+     on initial values.  Unswitching should remove this kind of conditions.  */\n+  if (iv0.step == const0_rtx && iv1.step == const0_rtx)\n+    goto fail;\n+\n+  /* Ignore loops of while (i-- < 10) type.  */\n+  if (cond != NE\n+      && (INTVAL (iv0.step) < 0 || INTVAL (iv1.step) > 0))\n+    goto fail;\n+\n+  /* Some more condition normalization.  We must record some assumptions\n+     due to overflows.  */\n+  switch (cond)\n+    {\n+      case LT:\n+      case LTU:\n+\t/* We want to take care only of non-sharp relationals; this is easy,\n+\t   as in cases the overflow would make the transformation unsafe\n+\t   the loop does not roll.  Seemingly it would make more sense to want\n+\t   to take care of sharp relationals instead, as NE is more similar to\n+\t   them, but the problem is that here the transformation would be more\n+\t   difficult due to possibly infinite loops.  */\n+\tif (iv0.step == const0_rtx)\n+\t  {\n+\t    tmp = lowpart_subreg (mode, iv0.base, comp_mode);\n+\t    assumption = simplify_gen_relational (EQ, SImode, mode, tmp, mmax);\n+\t    if (assumption == const_true_rtx)\n+\t      goto zero_iter;\n+\t    iv0.base = simplify_gen_binary (PLUS, comp_mode,\n+\t\t\t\t\t    iv0.base, const1_rtx);\n+\t  }\n+\telse\n+\t  {\n+\t    tmp = lowpart_subreg (mode, iv1.base, comp_mode);\n+\t    assumption = simplify_gen_relational (EQ, SImode, mode, tmp, mmin);\n+\t    if (assumption == const_true_rtx)\n+\t      goto zero_iter;\n+\t    iv1.base = simplify_gen_binary (PLUS, comp_mode,\n+\t\t\t\t\t    iv1.base, constm1_rtx);\n+\t  }\n+\n+\tif (assumption != const0_rtx)\n+\t  desc->noloop_assumptions =\n+\t\t  alloc_EXPR_LIST (0, assumption, desc->noloop_assumptions);\n+\tcond = (cond == LT) ? LE : LEU;\n+\n+\t/* It will be useful to be able to tell the difference once more in\n+\t   LE -> NE reduction.  */\n+\twas_sharp = true;\n+\tbreak;\n+      default: ;\n+    }\n+\n+  /* Take care of trivially infinite loops.  */\n+  if (cond != NE)\n+    {\n+      if (iv0.step == const0_rtx)\n+\t{\n+\t  tmp = lowpart_subreg (mode, iv0.base, comp_mode);\n+\t  if (rtx_equal_p (tmp, mmin))\n+\t    {\n+\t      desc->infinite =\n+\t\t      alloc_EXPR_LIST (0, const_true_rtx, NULL_RTX);\n+\t      return;\n+\t    }\n+\t}\n+      else\n+\t{\n+\t  tmp = lowpart_subreg (mode, iv1.base, comp_mode);\n+\t  if (rtx_equal_p (tmp, mmax))\n+\t    {\n+\t      desc->infinite =\n+\t\t      alloc_EXPR_LIST (0, const_true_rtx, NULL_RTX);\n+\t      return;\n+\t    }\n+\t}\n+    }\n+\n+  /* If we can we want to take care of NE conditions instead of size\n+     comparisons, as they are much more friendly (most importantly\n+     this takes care of special handling of loops with step 1).  We can\n+     do it if we first check that upper bound is greater or equal to\n+     lower bound, their difference is constant c modulo step and that\n+     there is not an overflow.  */\n+  if (cond != NE)\n+    {\n+      if (iv0.step == const0_rtx)\n+\tstep = simplify_gen_unary (NEG, comp_mode, iv1.step, comp_mode);\n+      else\n+\tstep = iv0.step;\n+      delta = simplify_gen_binary (MINUS, comp_mode, iv1.base, iv0.base);\n+      delta = lowpart_subreg (mode, delta, comp_mode);\n+      delta = simplify_gen_binary (UMOD, mode, delta, step);\n+      may_xform = const0_rtx;\n+\n+      if (GET_CODE (delta) == CONST_INT)\n+\t{\n+\t  if (was_sharp && INTVAL (delta) == INTVAL (step) - 1)\n+\t    {\n+\t      /* A special case.  We have transformed condition of type\n+\t\t for (i = 0; i < 4; i += 4)\n+\t\t into\n+\t\t for (i = 0; i <= 3; i += 4)\n+\t\t obviously if the test for overflow during that transformation\n+\t\t passed, we cannot overflow here.  Most importantly any\n+\t\t loop with sharp end condition and step 1 falls into this\n+\t\t cathegory, so handling this case specially is definitely\n+\t\t worth the troubles.  */\n+\t      may_xform = const_true_rtx;\n+\t    }\n+\t  else if (iv0.step == const0_rtx)\n+\t    {\n+\t      bound = simplify_gen_binary (PLUS, comp_mode, mmin, step);\n+\t      bound = simplify_gen_binary (MINUS, comp_mode, bound, delta);\n+\t      bound = lowpart_subreg (mode, bound, comp_mode);\n+\t      tmp = lowpart_subreg (mode, iv0.base, comp_mode);\n+\t      may_xform = simplify_gen_relational (cond, SImode, mode,\n+\t\t\t\t\t\t   bound, tmp);\n+\t    }\n+\t  else\n+\t    {\n+\t      bound = simplify_gen_binary (MINUS, comp_mode, mmax, step);\n+\t      bound = simplify_gen_binary (PLUS, comp_mode, bound, delta);\n+\t      bound = lowpart_subreg (mode, bound, comp_mode);\n+\t      tmp = lowpart_subreg (mode, iv1.base, comp_mode);\n+\t      may_xform = simplify_gen_relational (cond, SImode, mode,\n+\t\t\t\t\t\t   tmp, bound);\n+\t    }\n+\t}\n+\n+      if (may_xform != const0_rtx)\n+\t{\n+\t  /* We perform the transformation always provided that it is not\n+\t     completely senseless.  This is OK, as we would need this assumption\n+\t     to determine the number of iterations anyway.  */\n+\t  if (may_xform != const_true_rtx)\n+\t    desc->assumptions = alloc_EXPR_LIST (0, may_xform,\n+\t\t\t\t\t\t desc->assumptions);\n+\n+\t  /* We are going to lose some information about upper bound on\n+\t     number of iterations in this step, so record the information\n+\t     here.  */\n+\t  inc = INTVAL (iv0.step) - INTVAL (iv1.step);\n+\t  if (GET_CODE (iv1.base) == CONST_INT)\n+\t    up = INTVAL (iv1.base);\n+\t  else\n+\t    up = INTVAL (mmax) - inc;\n+\t  down = INTVAL (GET_CODE (iv0.base) == CONST_INT ? iv0.base : mmin);\n+\t  desc->niter_max = (up - down) / inc + 1;\n+\n+\t  if (iv0.step == const0_rtx)\n+\t    {\n+\t      iv0.base = simplify_gen_binary (PLUS, comp_mode, iv0.base, delta);\n+\t      iv0.base = simplify_gen_binary (MINUS, comp_mode, iv0.base, step);\n+\t    }\n+\t  else\n+\t    {\n+\t      iv1.base = simplify_gen_binary (MINUS, comp_mode, iv1.base, delta);\n+\t      iv1.base = simplify_gen_binary (PLUS, comp_mode, iv1.base, step);\n+\t    }\n+\n+\t  tmp0 = lowpart_subreg (mode, iv0.base, comp_mode);\n+\t  tmp1 = lowpart_subreg (mode, iv1.base, comp_mode);\n+\t  assumption = simplify_gen_relational (reverse_condition (cond),\n+\t\t\t\t\t\tSImode, mode, tmp0, tmp1);\n+\t  if (assumption == const_true_rtx)\n+\t    goto zero_iter;\n+\t  else if (assumption != const0_rtx)\n+\t    desc->noloop_assumptions =\n+\t\t    alloc_EXPR_LIST (0, assumption, desc->noloop_assumptions);\n+\t  cond = NE;\n+\t}\n+    }\n+\n+  /* Count the number of iterations.  */\n+  if (cond == NE)\n+    {\n+      /* Everything we do here is just arithmetics modulo size of mode.  This\n+\t makes us able to do more involved computations of number of iterations\n+\t than in other cases.  First transform the condition into shape\n+\t s * i <> c, with s positive.  */\n+      iv1.base = simplify_gen_binary (MINUS, comp_mode, iv1.base, iv0.base);\n+      iv0.base = const0_rtx;\n+      iv0.step = simplify_gen_binary (MINUS, comp_mode, iv0.step, iv1.step);\n+      iv1.step = const0_rtx;\n+      if (INTVAL (iv0.step) < 0)\n+\t{\n+\t  iv0.step = simplify_gen_unary (NEG, comp_mode, iv0.step, mode);\n+\t  iv1.base = simplify_gen_unary (NEG, comp_mode, iv1.base, mode);\n+\t}\n+      iv0.step = lowpart_subreg (mode, iv0.step, comp_mode);\n+\n+      /* Let nsd (s, size of mode) = d.  If d does not divide c, the loop\n+\t is infinite.  Otherwise, the number of iterations is\n+\t (inverse(s/d) * (c/d)) mod (size of mode/d).  */\n+      s = INTVAL (iv0.step); d = 1;\n+      while (s % 2 != 1)\n+\t{\n+\t  s /= 2;\n+\t  d *= 2;\n+\t  size--;\n+\t}\n+      bound = GEN_INT (((unsigned HOST_WIDEST_INT) 1 << (size - 1 ) << 1) - 1);\n+\n+      tmp1 = lowpart_subreg (mode, iv1.base, comp_mode);\n+      tmp = simplify_gen_binary (UMOD, mode, tmp1, GEN_INT (d));\n+      assumption = simplify_gen_relational (NE, SImode, mode, tmp, const0_rtx);\n+      desc->infinite = alloc_EXPR_LIST (0, assumption, desc->infinite);\n+\n+      tmp = simplify_gen_binary (UDIV, mode, tmp1, GEN_INT (d));\n+      tmp = simplify_gen_binary (MULT, mode,\n+\t\t\t\t tmp, GEN_INT (inverse (s, size)));\n+      desc->niter_expr = simplify_gen_binary (AND, mode, tmp, bound);\n+    }\n+  else\n+    {\n+      if (iv1.step == const0_rtx)\n+\t/* Condition in shape a + s * i <= b\n+\t   We must know that b + s does not overflow and a <= b + s and then we\n+\t   can compute number of iterations as (b + s - a) / s.  (It might\n+\t   seem that we in fact could be more clever about testing the b + s\n+\t   overflow condition using some information about b - a mod s,\n+\t   but it was already taken into account during LE -> NE transform).  */\n+\t{\n+\t  step = iv0.step;\n+\t  tmp0 = lowpart_subreg (mode, iv0.base, comp_mode);\n+\t  tmp1 = lowpart_subreg (mode, iv1.base, comp_mode);\n+\n+\t  bound = simplify_gen_binary (MINUS, mode, mmax, step);\n+\t  assumption = simplify_gen_relational (cond, SImode, mode,\n+\t\t\t\t\t\ttmp1, bound);\n+\t  desc->assumptions =\n+\t\t  alloc_EXPR_LIST (0, assumption, desc->assumptions);\n+\n+\t  tmp = simplify_gen_binary (PLUS, comp_mode, iv1.base, iv0.step);\n+\t  tmp = lowpart_subreg (mode, tmp, comp_mode);\n+\t  assumption = simplify_gen_relational (reverse_condition (cond),\n+\t\t\t\t\t\tSImode, mode, tmp0, tmp);\n+\n+\t  delta = simplify_gen_binary (PLUS, mode, tmp1, step);\n+\t  delta = simplify_gen_binary (MINUS, mode, delta, tmp0);\n+\t}\n+      else\n+\t{\n+\t  /* Condition in shape a <= b - s * i\n+\t     We must know that a - s does not overflow and a - s <= b and then\n+\t     we can again compute number of iterations as (b - (a - s)) / s.  */\n+\t  step = simplify_gen_unary (NEG, mode, iv1.step, mode);\n+\t  tmp0 = lowpart_subreg (mode, iv0.base, comp_mode);\n+\t  tmp1 = lowpart_subreg (mode, iv1.base, comp_mode);\n+\n+\t  bound = simplify_gen_binary (MINUS, mode, mmin, step);\n+\t  assumption = simplify_gen_relational (cond, SImode, mode,\n+\t\t\t\t\t\tbound, tmp0);\n+\t  desc->assumptions =\n+\t\t  alloc_EXPR_LIST (0, assumption, desc->assumptions);\n+\n+\t  tmp = simplify_gen_binary (PLUS, comp_mode, iv0.base, iv1.step);\n+\t  tmp = lowpart_subreg (mode, tmp, comp_mode);\n+\t  assumption = simplify_gen_relational (reverse_condition (cond),\n+\t\t\t\t\t\tSImode, mode,\n+\t\t\t\t\t\ttmp, tmp1);\n+\t  delta = simplify_gen_binary (MINUS, mode, tmp0, step);\n+\t  delta = simplify_gen_binary (MINUS, mode, tmp1, delta);\n+\t}\n+      if (assumption == const_true_rtx)\n+\tgoto zero_iter;\n+      else if (assumption != const0_rtx)\n+\tdesc->noloop_assumptions =\n+\t\talloc_EXPR_LIST (0, assumption, desc->noloop_assumptions);\n+      delta = simplify_gen_binary (UDIV, mode, delta, step);\n+      desc->niter_expr = delta;\n+    }\n+\n+  simplify_using_initial_values (loop, AND, &desc->assumptions);\n+  if (desc->assumptions\n+      && XEXP (desc->assumptions, 0) == const0_rtx)\n+    goto fail;\n+  simplify_using_initial_values (loop, IOR, &desc->noloop_assumptions);\n+  simplify_using_initial_values (loop, IOR, &desc->infinite);\n+  simplify_using_initial_values (loop, NIL, &desc->niter_expr);\n+\n+  /* Rerun the simplification.  Consider code (created by copying loop headers)\n+\n+     i = 0;\n+\n+     if (0 < n)\n+       {\n+         do\n+\t   {\n+\t     i++;\n+\t   } while (i < n);\n+       }\n+\n+    The first pass determines that i = 0, the second pass uses it to eliminate\n+    noloop assumption.  */\n+\n+  simplify_using_initial_values (loop, AND, &desc->assumptions);\n+  if (desc->assumptions\n+      && XEXP (desc->assumptions, 0) == const0_rtx)\n+    goto fail;\n+  simplify_using_initial_values (loop, IOR, &desc->noloop_assumptions);\n+  simplify_using_initial_values (loop, IOR, &desc->infinite);\n+  simplify_using_initial_values (loop, NIL, &desc->niter_expr);\n+\n+  if (GET_CODE (desc->niter_expr) == CONST_INT)\n+    {\n+      unsigned HOST_WIDEST_INT val = INTVAL (desc->niter_expr);\n+\n+      desc->const_iter = true;\n+      desc->niter_max = desc->niter = val & GET_MODE_MASK (desc->mode);\n+    }\n+  else if (!desc->niter_max)\n+    desc->niter_max = determine_max_iter (desc);\n+\n+  return;\n+\n+fail:\n+  desc->simple_p = false;\n+  return;\n+\n+zero_iter:\n+  desc->const_iter = true;\n+  desc->niter = 0;\n+  desc->niter_max = 0;\n+  desc->niter_expr = const0_rtx;\n+  return;\n+}\n+\n+/* Checks whether E is a simple exit from LOOP and stores its description\n+   into DESC.  TODO Should replace cfgloopanal.c:simple_loop_exit_p.  */\n+\n+static void\n+check_simple_exit (struct loop *loop, edge e, struct niter_desc *desc)\n+{\n+  basic_block exit_bb;\n+  rtx condition, at;\n+  edge ei;\n+\n+  exit_bb = e->src;\n+  desc->simple_p = false;\n+\n+  /* It must belong directly to the loop.  */\n+  if (exit_bb->loop_father != loop)\n+    return;\n+\n+  /* It must be tested (at least) once during any iteration.  */\n+  if (!dominated_by_p (CDI_DOMINATORS, loop->latch, exit_bb))\n+    return;\n+\n+  /* It must end in a simple conditional jump.  */\n+  if (!any_condjump_p (BB_END (exit_bb)))\n+    return;\n+\n+  ei = exit_bb->succ;\n+  if (ei == e)\n+    ei = ei->succ_next;\n+\n+  desc->out_edge = e;\n+  desc->in_edge = ei;\n+\n+  /* Test whether the condition is suitable.  */\n+  if (!(condition = get_condition (BB_END (ei->src), &at, false)))\n+    return;\n+\n+  if (ei->flags & EDGE_FALLTHRU)\n+    {\n+      condition = reversed_condition (condition);\n+      if (!condition)\n+\treturn;\n+    }\n+\n+  /* Check that we are able to determine number of iterations and fill\n+     in information about it.  */\n+  iv_number_of_iterations (loop, at, condition, desc);\n+}\n+\n+/* Finds a simple exit of LOOP and stores its description into DESC.\n+   TODO Should replace cfgloopanal.c:simple_loop_p.  */\n+\n+void\n+find_simple_exit (struct loop *loop, struct niter_desc *desc)\n+{\n+  unsigned i;\n+  basic_block *body;\n+  edge e;\n+  struct niter_desc act;\n+  bool any = false;\n+\n+  desc->simple_p = false;\n+  body = get_loop_body (loop);\n+\n+  for (i = 0; i < loop->num_nodes; i++)\n+    {\n+      for (e = body[i]->succ; e; e = e->succ_next)\n+\t{\n+\t  if (flow_bb_inside_loop_p (loop, e->dest))\n+\t    continue;\n+\t  \n+\t  check_simple_exit (loop, e, &act);\n+\t  if (!act.simple_p)\n+\t    continue;\n+\n+\t  /* Prefer constant iterations; the less the better.  */\n+\t  if (!any)\n+\t    any = true;\n+\t  else if (!act.const_iter\n+\t\t   || (desc->const_iter && act.niter >= desc->niter))\n+\t    continue;\n+\t  *desc = act;\n+\t}\n+    }\n+\n+  if (rtl_dump_file)\n+    {\n+      if (desc->simple_p)\n+\t{\n+\t  fprintf (rtl_dump_file, \"Loop %d is simple:\\n\", loop->num);\n+\t  fprintf (rtl_dump_file, \"  simple exit %d -> %d\\n\",\n+\t\t   desc->out_edge->src->index,\n+\t\t   desc->out_edge->dest->index);\n+\t  if (desc->assumptions)\n+\t    {\n+\t      fprintf (rtl_dump_file, \"  assumptions: \");\n+\t      print_rtl (rtl_dump_file, desc->assumptions);\n+\t      fprintf (rtl_dump_file, \"\\n\");\n+\t    }\n+\t  if (desc->noloop_assumptions)\n+\t    {\n+\t      fprintf (rtl_dump_file, \"  does not roll if: \");\n+\t      print_rtl (rtl_dump_file, desc->noloop_assumptions);\n+\t      fprintf (rtl_dump_file, \"\\n\");\n+\t    }\n+\t  if (desc->infinite)\n+\t    {\n+\t      fprintf (rtl_dump_file, \"  infinite if: \");\n+\t      print_rtl (rtl_dump_file, desc->infinite);\n+\t      fprintf (rtl_dump_file, \"\\n\");\n+\t    }\n+\n+\t  fprintf (rtl_dump_file, \"  number of iterations: \");\n+\t  print_rtl (rtl_dump_file, desc->niter_expr);\n+      \t  fprintf (rtl_dump_file, \"\\n\");\n+\n+\t  fprintf (rtl_dump_file, \"  upper bound: \");\n+\t  fprintf (rtl_dump_file, HOST_WIDEST_INT_PRINT_DEC, desc->niter_max);\n+      \t  fprintf (rtl_dump_file, \"\\n\");\n+\t}\n+      else\n+\tfprintf (rtl_dump_file, \"Loop %d is not simple.\\n\", loop->num);\n+    }\n+\n+  free (body);\n+}\n+\n+/* Creates a simple loop description of LOOP if it was not computed\n+   already.  */\n+\n+struct niter_desc *\n+get_simple_loop_desc (struct loop *loop)\n+{\n+  struct niter_desc *desc = simple_loop_desc (loop);\n+\n+  if (desc)\n+    return desc;\n+\n+  desc = xmalloc (sizeof (struct niter_desc));\n+  iv_analysis_loop_init (loop);\n+  find_simple_exit (loop, desc);\n+  loop->aux = desc;\n+\n+  return desc;\n+}\n+\n+/* Releases simple loop description for LOOP.  */\n+\n+void\n+free_simple_loop_desc (struct loop *loop)\n+{\n+  struct niter_desc *desc = simple_loop_desc (loop);\n+\n+  if (!desc)\n+    return;\n+\n+  free (desc);\n+  loop->aux = NULL;\n+}"}, {"sha": "b093a7de081a2644a86b926facef9511a2da4e3e", "filename": "gcc/loop-unroll.c", "status": "modified", "additions": 237, "deletions": 119, "changes": 356, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-unroll.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-unroll.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-unroll.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -85,7 +85,7 @@ void\n unroll_and_peel_loops (struct loops *loops, int flags)\n {\n   struct loop *loop, *next;\n-  int check;\n+  bool check;\n \n   /* First perform complete loop peeling (it is almost surely a win,\n      and affects parameters for further decision a lot).  */\n@@ -110,7 +110,7 @@ unroll_and_peel_loops (struct loops *loops, int flags)\n       else\n \tnext = loop->outer;\n \n-      check = 1;\n+      check = true;\n       /* And perform the appropriate transformations.  */\n       switch (loop->lpt_decision.decision)\n \t{\n@@ -130,7 +130,7 @@ unroll_and_peel_loops (struct loops *loops, int flags)\n \t  unroll_loop_stupid (loops, loop);\n \t  break;\n \tcase LPT_NONE:\n-\t  check = 0;\n+\t  check = false;\n \t  break;\n \tdefault:\n \t  abort ();\n@@ -144,6 +144,29 @@ unroll_and_peel_loops (struct loops *loops, int flags)\n \t}\n       loop = next;\n     }\n+\n+  iv_analysis_done ();\n+}\n+\n+/* Check whether exit of the LOOP is at the end of loop body.  */\n+\n+static bool\n+loop_exit_at_end_p (struct loop *loop)\n+{\n+  struct niter_desc *desc = get_simple_loop_desc (loop);\n+  rtx insn;\n+\n+  if (desc->in_edge->dest != loop->latch)\n+    return false;\n+\n+  /* Check that the latch is empty.  */\n+  FOR_BB_INSNS (loop->latch, insn)\n+    {\n+      if (INSN_P (insn))\n+\treturn false;\n+    }\n+\n+  return true;\n }\n \n /* Check whether to peel LOOPS (depending on FLAGS) completely and do so.  */\n@@ -168,10 +191,9 @@ peel_loops_completely (struct loops *loops, int flags)\n \tnext = loop->outer;\n \n       loop->lpt_decision.decision = LPT_NONE;\n-      loop->has_desc = 0;\n \n       if (rtl_dump_file)\n-\tfprintf (rtl_dump_file, \";; Considering loop %d for complete peeling\\n\",\n+\tfprintf (rtl_dump_file, \"\\n;; *** Considering loop %d for complete peeling ***\\n\",\n \t\t loop->num);\n \n       loop->ninsns = num_loop_insns (loop);\n@@ -216,7 +238,7 @@ decide_unrolling_and_peeling (struct loops *loops, int flags)\n       loop->lpt_decision.decision = LPT_NONE;\n \n       if (rtl_dump_file)\n-\tfprintf (rtl_dump_file, \";; Considering loop %d\\n\", loop->num);\n+\tfprintf (rtl_dump_file, \"\\n;; *** Considering loop %d ***\\n\", loop->num);\n \n       /* Do not peel cold areas.  */\n       if (!maybe_hot_bb_p (loop->header))\n@@ -269,8 +291,10 @@ decide_unrolling_and_peeling (struct loops *loops, int flags)\n static void\n decide_peel_once_rolling (struct loop *loop, int flags ATTRIBUTE_UNUSED)\n {\n+  struct niter_desc *desc;\n+\n   if (rtl_dump_file)\n-    fprintf (rtl_dump_file, \";; Considering peeling once rolling loop\\n\");\n+    fprintf (rtl_dump_file, \"\\n;; Considering peeling once rolling loop\\n\");\n \n   /* Is the loop small enough?  */\n   if ((unsigned) PARAM_VALUE (PARAM_MAX_ONCE_PEELED_INSNS) < loop->ninsns)\n@@ -281,11 +305,13 @@ decide_peel_once_rolling (struct loop *loop, int flags ATTRIBUTE_UNUSED)\n     }\n \n   /* Check for simple loops.  */\n-  loop->simple = simple_loop_p (loop, &loop->desc);\n-  loop->has_desc = 1;\n+  desc = get_simple_loop_desc (loop);\n \n   /* Check number of iterations.  */\n-  if (!loop->simple || !loop->desc.const_iter || loop->desc.niter != 0)\n+  if (!desc->simple_p\n+      || desc->assumptions\n+      || !desc->const_iter\n+      || desc->niter != 0)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Unable to prove that the loop rolls exactly once\\n\");\n@@ -303,9 +329,10 @@ static void\n decide_peel_completely (struct loop *loop, int flags ATTRIBUTE_UNUSED)\n {\n   unsigned npeel;\n+  struct niter_desc *desc;\n \n   if (rtl_dump_file)\n-    fprintf (rtl_dump_file, \";; Considering peeling completely\\n\");\n+    fprintf (rtl_dump_file, \"\\n;; Considering peeling completely\\n\");\n \n   /* Skip non-innermost loops.  */\n   if (loop->inner)\n@@ -346,26 +373,24 @@ decide_peel_completely (struct loop *loop, int flags ATTRIBUTE_UNUSED)\n     }\n \n   /* Check for simple loops.  */\n-  if (!loop->has_desc)\n-    {\n-      loop->simple = simple_loop_p (loop, &loop->desc);\n-      loop->has_desc = 1;\n-    }\n+  desc = get_simple_loop_desc (loop);\n \n   /* Check number of iterations.  */\n-  if (!loop->simple || !loop->desc.const_iter)\n+  if (!desc->simple_p\n+      || desc->assumptions\n+      || !desc->const_iter)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Unable to prove that the loop iterates constant times\\n\");\n       return;\n     }\n \n-  if (loop->desc.niter > npeel - 1)\n+  if (desc->niter > npeel - 1)\n     {\n       if (rtl_dump_file)\n \t{\n \t  fprintf (rtl_dump_file, \";; Not peeling loop completely, rolls too much (\");\n-\t  fprintf (rtl_dump_file, HOST_WIDEST_INT_PRINT_DEC,(HOST_WIDEST_INT) loop->desc.niter);\n+\t  fprintf (rtl_dump_file, HOST_WIDEST_INT_PRINT_DEC, desc->niter);\n \t  fprintf (rtl_dump_file, \" iterations > %d [maximum peelings])\\n\", npeel);\n \t}\n       return;\n@@ -397,8 +422,8 @@ peel_loop_completely (struct loops *loops, struct loop *loop)\n   sbitmap wont_exit;\n   unsigned HOST_WIDE_INT npeel;\n   unsigned n_remove_edges, i;\n-  edge *remove_edges;\n-  struct loop_desc *desc = &loop->desc;\n+  edge *remove_edges, ei;\n+  struct niter_desc *desc = get_simple_loop_desc (loop);\n \n   npeel = desc->niter;\n \n@@ -407,7 +432,7 @@ peel_loop_completely (struct loops *loops, struct loop *loop)\n       wont_exit = sbitmap_alloc (npeel + 1);\n       sbitmap_ones (wont_exit);\n       RESET_BIT (wont_exit, 0);\n-      if (desc->may_be_zero)\n+      if (desc->noloop_assumptions)\n \tRESET_BIT (wont_exit, 1);\n \n       remove_edges = xcalloc (npeel, sizeof (edge));\n@@ -427,19 +452,24 @@ peel_loop_completely (struct loops *loops, struct loop *loop)\n       free (remove_edges);\n     }\n \n+  ei = desc->in_edge;\n+  free_simple_loop_desc (loop);\n+\n   /* Now remove the unreachable part of the last iteration and cancel\n      the loop.  */\n-  remove_path (loops, desc->in_edge);\n+  remove_path (loops, ei);\n \n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \";; Peeled loop completely, %d times\\n\", (int) npeel);\n }\n \n /* Decide whether to unroll LOOP iterating constant number of times and how much.  */\n+\n static void\n decide_unroll_constant_iterations (struct loop *loop, int flags)\n {\n-  unsigned nunroll, nunroll_by_av, best_copies, best_unroll = -1, n_copies, i;\n+  unsigned nunroll, nunroll_by_av, best_copies, best_unroll = 0, n_copies, i;\n+  struct niter_desc *desc;\n \n   if (!(flags & UAP_UNROLL))\n     {\n@@ -448,7 +478,8 @@ decide_unroll_constant_iterations (struct loop *loop, int flags)\n     }\n \n   if (rtl_dump_file)\n-    fprintf (rtl_dump_file, \";; Considering unrolling loop with constant number of iterations\\n\");\n+    fprintf (rtl_dump_file,\n+\t     \"\\n;; Considering unrolling loop with constant number of iterations\\n\");\n \n   /* nunroll = total number of copies of the original loop body in\n      unrolled loop (i.e. if it is 2, we have to duplicate loop body once.  */\n@@ -468,22 +499,18 @@ decide_unroll_constant_iterations (struct loop *loop, int flags)\n     }\n \n   /* Check for simple loops.  */\n-  if (!loop->has_desc)\n-    {\n-      loop->simple = simple_loop_p (loop, &loop->desc);\n-      loop->has_desc = 1;\n-    }\n+  desc = get_simple_loop_desc (loop);\n \n   /* Check number of iterations.  */\n-  if (!loop->simple || !loop->desc.const_iter)\n+  if (!desc->simple_p || !desc->const_iter || desc->assumptions)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Unable to prove that the loop iterates constant times\\n\");\n       return;\n     }\n \n   /* Check whether the loop rolls enough to consider.  */\n-  if (loop->desc.niter < 2 * nunroll)\n+  if (desc->niter < 2 * nunroll)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Not unrolling loop, doesn't roll\\n\");\n@@ -497,16 +524,17 @@ decide_unroll_constant_iterations (struct loop *loop, int flags)\n   best_copies = 2 * nunroll + 10;\n \n   i = 2 * nunroll + 2;\n-  if ((unsigned) i - 1 >= loop->desc.niter)\n-    i = loop->desc.niter - 2;\n+  if (i - 1 >= desc->niter)\n+    i = desc->niter - 2;\n \n   for (; i >= nunroll - 1; i--)\n     {\n-      unsigned exit_mod = loop->desc.niter % (i + 1);\n+      unsigned exit_mod = desc->niter % (i + 1);\n \n-      if (loop->desc.postincr)\n+      if (!loop_exit_at_end_p (loop))\n \tn_copies = exit_mod + i + 1;\n-      else if (exit_mod != (unsigned) i || loop->desc.may_be_zero)\n+      else if (exit_mod != (unsigned) i\n+\t       || desc->noloop_assumptions != NULL_RTX)\n \tn_copies = exit_mod + i + 2;\n       else\n \tn_copies = i + 1;\n@@ -524,6 +552,11 @@ decide_unroll_constant_iterations (struct loop *loop, int flags)\n \n   loop->lpt_decision.decision = LPT_UNROLL_CONSTANT;\n   loop->lpt_decision.times = best_unroll;\n+  \n+  if (rtl_dump_file)\n+    fprintf (rtl_dump_file,\n+\t     \";; Decided to unroll the constant times rolling loop, %d times.\\n\",\n+\t     loop->lpt_decision.times);\n }\n \n /* Unroll LOOP with constant number of iterations LOOP->LPT_DECISION.TIMES + 1\n@@ -554,11 +587,12 @@ unroll_loop_constant_iterations (struct loops *loops, struct loop *loop)\n   unsigned n_remove_edges, i;\n   edge *remove_edges;\n   unsigned max_unroll = loop->lpt_decision.times;\n-  struct loop_desc *desc = &loop->desc;\n+  struct niter_desc *desc = get_simple_loop_desc (loop);\n+  bool exit_at_end = loop_exit_at_end_p (loop);\n \n   niter = desc->niter;\n \n-  if (niter <= (unsigned) max_unroll + 1)\n+  if (niter <= max_unroll + 1)\n     abort ();  /* Should not get here (such loop should be peeled instead).  */\n \n   exit_mod = niter % (max_unroll + 1);\n@@ -569,9 +603,9 @@ unroll_loop_constant_iterations (struct loops *loops, struct loop *loop)\n   remove_edges = xcalloc (max_unroll + exit_mod + 1, sizeof (edge));\n   n_remove_edges = 0;\n \n-  if (desc->postincr)\n+  if (!exit_at_end)\n     {\n-      /* Counter is incremented after the exit test; leave exit test\n+      /* The exit is not at the end of the loop; leave exit test\n \t in the first copy, so that the loops that start with test\n \t of exit condition have continuous body after unrolling.  */\n \n@@ -580,15 +614,22 @@ unroll_loop_constant_iterations (struct loops *loops, struct loop *loop)\n \n       /* Peel exit_mod iterations.  */\n       RESET_BIT (wont_exit, 0);\n-      if (desc->may_be_zero)\n+      if (desc->noloop_assumptions)\n \tRESET_BIT (wont_exit, 1);\n \n-      if (exit_mod\n-\t  && !duplicate_loop_to_header_edge (loop, loop_preheader_edge (loop),\n-\t\tloops, exit_mod,\n-\t\twont_exit, desc->out_edge, remove_edges, &n_remove_edges,\n-\t\tDLTHE_FLAG_UPDATE_FREQ))\n-\tabort ();\n+      if (exit_mod)\n+\t{\n+\t  if (!duplicate_loop_to_header_edge (loop, loop_preheader_edge (loop),\n+\t\t\t\t\t      loops, exit_mod,\n+\t\t\t\t\t      wont_exit, desc->out_edge,\n+\t\t\t\t\t      remove_edges, &n_remove_edges,\n+\t\t\t\t\t      DLTHE_FLAG_UPDATE_FREQ))\n+\t    abort ();\n+\n+\t  desc->noloop_assumptions = NULL_RTX;\n+\t  desc->niter -= exit_mod;\n+\t  desc->niter_max -= exit_mod;\n+\t}\n \n       SET_BIT (wont_exit, 1);\n     }\n@@ -602,12 +643,12 @@ unroll_loop_constant_iterations (struct loops *loops, struct loop *loop)\n \n       /* We know that niter >= max_unroll + 2; so we do not need to care of\n \t case when we would exit before reaching the loop.  So just peel\n-\t exit_mod + 1 iterations.\n-\t */\n-      if (exit_mod != (unsigned) max_unroll || desc->may_be_zero)\n+\t exit_mod + 1 iterations.  */\n+      if (exit_mod != max_unroll\n+\t  || desc->noloop_assumptions)\n \t{\n \t  RESET_BIT (wont_exit, 0);\n-\t  if (desc->may_be_zero)\n+\t  if (desc->noloop_assumptions)\n \t    RESET_BIT (wont_exit, 1);\n \n \t  if (!duplicate_loop_to_header_edge (loop, loop_preheader_edge (loop),\n@@ -616,6 +657,10 @@ unroll_loop_constant_iterations (struct loops *loops, struct loop *loop)\n \t\tDLTHE_FLAG_UPDATE_FREQ))\n \t    abort ();\n \n+\t  desc->niter -= exit_mod + 1;\n+\t  desc->niter_max -= exit_mod + 1;\n+\t  desc->noloop_assumptions = NULL_RTX;\n+\n \t  SET_BIT (wont_exit, 0);\n \t  SET_BIT (wont_exit, 1);\n \t}\n@@ -632,6 +677,27 @@ unroll_loop_constant_iterations (struct loops *loops, struct loop *loop)\n \n   free (wont_exit);\n \n+  if (exit_at_end)\n+    {\n+      basic_block exit_block = desc->in_edge->src->rbi->copy;\n+      /* Find a new in and out edge; they are in the last copy we have made.  */\n+      \n+      if (exit_block->succ->dest == desc->out_edge->dest)\n+\t{\n+\t  desc->out_edge = exit_block->succ;\n+\t  desc->in_edge = exit_block->succ->succ_next;\n+\t}\n+      else\n+\t{\n+\t  desc->out_edge = exit_block->succ->succ_next;\n+\t  desc->in_edge = exit_block->succ;\n+\t}\n+    }\n+\n+  desc->niter /= max_unroll + 1;\n+  desc->niter_max /= max_unroll + 1;\n+  desc->niter_expr = GEN_INT (desc->niter);\n+\n   /* Remove the edges.  */\n   for (i = 0; i < n_remove_edges; i++)\n     remove_path (loops, remove_edges[i]);\n@@ -647,6 +713,7 @@ static void\n decide_unroll_runtime_iterations (struct loop *loop, int flags)\n {\n   unsigned nunroll, nunroll_by_av, i;\n+  struct niter_desc *desc;\n \n   if (!(flags & UAP_UNROLL))\n     {\n@@ -655,7 +722,8 @@ decide_unroll_runtime_iterations (struct loop *loop, int flags)\n     }\n \n   if (rtl_dump_file)\n-    fprintf (rtl_dump_file, \";; Considering unrolling loop with runtime computable number of iterations\\n\");\n+    fprintf (rtl_dump_file,\n+\t     \"\\n;; Considering unrolling loop with runtime computable number of iterations\\n\");\n \n   /* nunroll = total number of copies of the original loop body in\n      unrolled loop (i.e. if it is 2, we have to duplicate loop body once.  */\n@@ -675,21 +743,18 @@ decide_unroll_runtime_iterations (struct loop *loop, int flags)\n     }\n \n   /* Check for simple loops.  */\n-  if (!loop->has_desc)\n-    {\n-      loop->simple = simple_loop_p (loop, &loop->desc);\n-      loop->has_desc = 1;\n-    }\n+  desc = get_simple_loop_desc (loop);\n \n   /* Check simpleness.  */\n-  if (!loop->simple)\n+  if (!desc->simple_p || desc->assumptions)\n     {\n       if (rtl_dump_file)\n-\tfprintf (rtl_dump_file, \";; Unable to prove that the number of iterations can be counted in runtime\\n\");\n+\tfprintf (rtl_dump_file,\n+\t\t \";; Unable to prove that the number of iterations can be counted in runtime\\n\");\n       return;\n     }\n \n-  if (loop->desc.const_iter)\n+  if (desc->const_iter)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Loop iterates constant times\\n\");\n@@ -706,10 +771,16 @@ decide_unroll_runtime_iterations (struct loop *loop, int flags)\n \n   /* Success; now force nunroll to be power of 2, as we are unable to\n      cope with overflows in computation of number of iterations.  */\n-  for (i = 1; 2 * i <= nunroll; i *= 2);\n+  for (i = 1; 2 * i <= nunroll; i *= 2)\n+    continue;\n \n   loop->lpt_decision.decision = LPT_UNROLL_RUNTIME;\n   loop->lpt_decision.times = i - 1;\n+  \n+  if (rtl_dump_file)\n+    fprintf (rtl_dump_file,\n+\t     \";; Decided to unroll the runtime computable times rolling loop, %d times.\\n\",\n+\t     loop->lpt_decision.times);\n }\n \n /* Unroll LOOP for that we are able to count number of iterations in runtime\n@@ -746,7 +817,7 @@ decide_unroll_runtime_iterations (struct loop *loop, int flags)\n static void\n unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n {\n-  rtx niter, init_code, branch_code, jump, label;\n+  rtx old_niter, niter, init_code, branch_code, tmp;\n   unsigned i, j, p;\n   basic_block preheader, *body, *dom_bbs, swtch, ezc_swtch;\n   unsigned n_dom_bbs;\n@@ -756,7 +827,8 @@ unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n   edge *remove_edges, e;\n   bool extra_zero_check, last_may_exit;\n   unsigned max_unroll = loop->lpt_decision.times;\n-  struct loop_desc *desc = &loop->desc;\n+  struct niter_desc *desc = get_simple_loop_desc (loop);\n+  bool exit_at_end = loop_exit_at_end_p (loop);\n \n   /* Remember blocks whose dominators will have to be updated.  */\n   dom_bbs = xcalloc (n_basic_blocks, sizeof (basic_block));\n@@ -777,7 +849,7 @@ unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n     }\n   free (body);\n \n-  if (desc->postincr)\n+  if (!exit_at_end)\n     {\n       /* Leave exit in first copy (for explanation why see comment in\n \t unroll_loop_constant_iterations).  */\n@@ -798,15 +870,15 @@ unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n \n   /* Get expression for number of iterations.  */\n   start_sequence ();\n-  niter = count_loop_iterations (desc, NULL, NULL);\n-  if (!niter)\n-    abort ();\n-  niter = force_operand (niter, NULL);\n+  old_niter = niter = gen_reg_rtx (desc->mode);\n+  tmp = force_operand (copy_rtx (desc->niter_expr), niter);\n+  if (tmp != niter)\n+    emit_move_insn (niter, tmp);\n \n   /* Count modulo by ANDing it with max_unroll; we use the fact that\n      the number of unrollings is a power of two, and thus this is correct\n      even if there is overflow in the computation.  */\n-  niter = expand_simple_binop (GET_MODE (desc->var), AND,\n+  niter = expand_simple_binop (desc->mode, AND,\n \t\t\t       niter,\n \t\t\t       GEN_INT (max_unroll),\n \t\t\t       NULL_RTX, 0, OPTAB_LIB_WIDEN);\n@@ -824,10 +896,11 @@ unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n \n   /* Peel the first copy of loop body (almost always we must leave exit test\n      here; the only exception is when we have extra zero check and the number\n-     of iterations is reliable (i.e. comes out of NE condition).  Also record\n-     the place of (possible) extra zero check.  */\n+     of iterations is reliable.  Also record the place of (possible) extra\n+     zero check.  */\n   sbitmap_zero (wont_exit);\n-  if (extra_zero_check && desc->cond == NE)\n+  if (extra_zero_check\n+      && !desc->noloop_assumptions)\n     SET_BIT (wont_exit, 1);\n   ezc_swtch = loop_preheader_edge (loop)->src;\n   if (!duplicate_loop_to_header_edge (loop, loop_preheader_edge (loop),\n@@ -857,20 +930,8 @@ unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n       p = REG_BR_PROB_BASE / (i + 2);\n \n       preheader = loop_split_edge_with (loop_preheader_edge (loop), NULL_RTX);\n-      label = block_label (preheader);\n-      start_sequence ();\n-      do_compare_rtx_and_jump (copy_rtx (niter), GEN_INT (j), EQ, 0,\n-\t\t\t       GET_MODE (desc->var), NULL_RTX, NULL_RTX,\n-\t\t\t       label);\n-      jump = get_last_insn ();\n-      JUMP_LABEL (jump) = label;\n-      REG_NOTES (jump)\n-\t      = gen_rtx_EXPR_LIST (REG_BR_PROB,\n-\t\t\t\t   GEN_INT (p), REG_NOTES (jump));\n-\n-      LABEL_NUSES (label)++;\n-      branch_code = get_insns ();\n-      end_sequence ();\n+      branch_code = compare_and_jump_seq (copy_rtx (niter), GEN_INT (j), EQ,\n+\t\t\t\t\t  block_label (preheader), p, NULL_RTX);\n \n       swtch = loop_split_edge_with (swtch->pred, branch_code);\n       set_immediate_dominator (CDI_DOMINATORS, preheader, swtch);\n@@ -886,20 +947,8 @@ unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n       p = REG_BR_PROB_BASE / (max_unroll + 1);\n       swtch = ezc_swtch;\n       preheader = loop_split_edge_with (loop_preheader_edge (loop), NULL_RTX);\n-      label = block_label (preheader);\n-      start_sequence ();\n-      do_compare_rtx_and_jump (copy_rtx (niter), const0_rtx, EQ, 0,\n-\t\t\t       GET_MODE (desc->var), NULL_RTX, NULL_RTX,\n-\t\t\t       label);\n-      jump = get_last_insn ();\n-      JUMP_LABEL (jump) = label;\n-      REG_NOTES (jump)\n-\t      = gen_rtx_EXPR_LIST (REG_BR_PROB,\n-\t\t\t\t   GEN_INT (p), REG_NOTES (jump));\n-\n-      LABEL_NUSES (label)++;\n-      branch_code = get_insns ();\n-      end_sequence ();\n+      branch_code = compare_and_jump_seq (copy_rtx (niter), const0_rtx, EQ,\n+\t\t\t\t\t  block_label (preheader), p, NULL_RTX);\n \n       swtch = loop_split_edge_with (swtch->succ, branch_code);\n       set_immediate_dominator (CDI_DOMINATORS, preheader, swtch);\n@@ -925,11 +974,45 @@ unroll_loop_runtime_iterations (struct loops *loops, struct loop *loop)\n \n   free (wont_exit);\n \n+  if (exit_at_end)\n+    {\n+      basic_block exit_block = desc->in_edge->src->rbi->copy;\n+      /* Find a new in and out edge; they are in the last copy we have made.  */\n+      \n+      if (exit_block->succ->dest == desc->out_edge->dest)\n+\t{\n+\t  desc->out_edge = exit_block->succ;\n+\t  desc->in_edge = exit_block->succ->succ_next;\n+\t}\n+      else\n+\t{\n+\t  desc->out_edge = exit_block->succ->succ_next;\n+\t  desc->in_edge = exit_block->succ;\n+\t}\n+    }\n+\n   /* Remove the edges.  */\n   for (i = 0; i < n_remove_edges; i++)\n     remove_path (loops, remove_edges[i]);\n   free (remove_edges);\n \n+  /* We must be careful when updating the number of iterations due to\n+     preconditioning and the fact that the value must be valid at entry\n+     of the loop.  After passing through the above code, we see that\n+     the correct new number of iterations is this:  */\n+  if (desc->const_iter)\n+    abort ();\n+  desc->niter_expr =\n+    simplify_gen_binary (UDIV, desc->mode, old_niter, GEN_INT (max_unroll + 1));\n+  desc->niter_max /= max_unroll + 1;\n+  if (exit_at_end)\n+    {\n+      desc->niter_expr =\n+\tsimplify_gen_binary (MINUS, desc->mode, desc->niter_expr, const1_rtx);\n+      desc->noloop_assumptions = NULL_RTX;\n+      desc->niter_max--;\n+    }\n+\n   if (rtl_dump_file)\n     fprintf (rtl_dump_file,\n \t     \";; Unrolled loop %d times, counting # of iterations in runtime, %i insns\\n\",\n@@ -941,6 +1024,7 @@ static void\n decide_peel_simple (struct loop *loop, int flags)\n {\n   unsigned npeel;\n+  struct niter_desc *desc;\n \n   if (!(flags & UAP_PEEL))\n     {\n@@ -949,7 +1033,7 @@ decide_peel_simple (struct loop *loop, int flags)\n     }\n \n   if (rtl_dump_file)\n-    fprintf (rtl_dump_file, \";; Considering simply peeling loop\\n\");\n+    fprintf (rtl_dump_file, \"\\n;; Considering simply peeling loop\\n\");\n \n   /* npeel = number of iterations to peel.  */\n   npeel = PARAM_VALUE (PARAM_MAX_PEELED_INSNS) / loop->ninsns;\n@@ -965,14 +1049,10 @@ decide_peel_simple (struct loop *loop, int flags)\n     }\n \n   /* Check for simple loops.  */\n-  if (!loop->has_desc)\n-    {\n-      loop->simple = simple_loop_p (loop, &loop->desc);\n-      loop->has_desc = 1;\n-    }\n+  desc = get_simple_loop_desc (loop);\n \n   /* Check number of iterations.  */\n-  if (loop->simple && loop->desc.const_iter)\n+  if (desc->simple_p && !desc->assumptions && desc->const_iter)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Loop iterates constant times\\n\");\n@@ -981,7 +1061,7 @@ decide_peel_simple (struct loop *loop, int flags)\n \n   /* Do not simply peel loops with branches inside -- it increases number\n      of mispredicts.  */\n-  if (loop->desc.n_branches > 1)\n+  if (num_loop_branches (loop) > 1)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Not peeling, contains branches\\n\");\n@@ -1016,6 +1096,10 @@ decide_peel_simple (struct loop *loop, int flags)\n   /* Success.  */\n   loop->lpt_decision.decision = LPT_PEEL_SIMPLE;\n   loop->lpt_decision.times = npeel;\n+      \n+  if (rtl_dump_file)\n+    fprintf (rtl_dump_file, \";; Decided to simply peel the loop, %d times.\\n\",\n+\t     loop->lpt_decision.times);\n }\n \n /* Peel a LOOP LOOP->LPT_DECISION.TIMES times.  The transformation:\n@@ -1037,6 +1121,7 @@ peel_loop_simple (struct loops *loops, struct loop *loop)\n {\n   sbitmap wont_exit;\n   unsigned npeel = loop->lpt_decision.times;\n+  struct niter_desc *desc = get_simple_loop_desc (loop);\n \n   wont_exit = sbitmap_alloc (npeel + 1);\n   sbitmap_zero (wont_exit);\n@@ -1048,6 +1133,23 @@ peel_loop_simple (struct loops *loops, struct loop *loop)\n \n   free (wont_exit);\n \n+  if (desc->simple_p)\n+    {\n+      if (desc->const_iter)\n+\t{\n+\t  desc->niter -= npeel;\n+\t  desc->niter_expr = GEN_INT (desc->niter);\n+\t  desc->noloop_assumptions = NULL_RTX;\n+\t}\n+      else\n+\t{\n+\t  /* We cannot just update niter_expr, as its value might be clobbered\n+\t     inside loop.  We could handle this by counting the number into\n+\t     temporary just like we do in runtime unrolling, but it does not\n+\t     seem worthwhile.  */\n+\t  free_simple_loop_desc (loop);\n+\t}\n+    }\n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \";; Peeling loop %d times\\n\", npeel);\n }\n@@ -1057,6 +1159,7 @@ static void\n decide_unroll_stupid (struct loop *loop, int flags)\n {\n   unsigned nunroll, nunroll_by_av, i;\n+  struct niter_desc *desc;\n \n   if (!(flags & UAP_UNROLL_ALL))\n     {\n@@ -1065,7 +1168,7 @@ decide_unroll_stupid (struct loop *loop, int flags)\n     }\n \n   if (rtl_dump_file)\n-    fprintf (rtl_dump_file, \";; Considering unrolling loop stupidly\\n\");\n+    fprintf (rtl_dump_file, \"\\n;; Considering unrolling loop stupidly\\n\");\n \n   /* nunroll = total number of copies of the original loop body in\n      unrolled loop (i.e. if it is 2, we have to duplicate loop body once.  */\n@@ -1085,14 +1188,10 @@ decide_unroll_stupid (struct loop *loop, int flags)\n     }\n \n   /* Check for simple loops.  */\n-  if (!loop->has_desc)\n-    {\n-      loop->simple = simple_loop_p (loop, &loop->desc);\n-      loop->has_desc = 1;\n-    }\n+  desc = get_simple_loop_desc (loop);\n \n   /* Check simpleness.  */\n-  if (loop->simple)\n+  if (desc->simple_p && !desc->assumptions)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; The loop is simple\\n\");\n@@ -1101,15 +1200,16 @@ decide_unroll_stupid (struct loop *loop, int flags)\n \n   /* Do not unroll loops with branches inside -- it increases number\n      of mispredicts.  */\n-  if (loop->desc.n_branches > 1)\n+  if (num_loop_branches (loop) > 1)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Not unrolling, contains branches\\n\");\n       return;\n     }\n \n   /* If we have profile feedback, check whether the loop rolls.  */\n-  if (loop->header->count && expected_loop_iterations (loop) < 2 * nunroll)\n+  if (loop->header->count\n+      && expected_loop_iterations (loop) < 2 * nunroll)\n     {\n       if (rtl_dump_file)\n \tfprintf (rtl_dump_file, \";; Not unrolling loop, doesn't roll\\n\");\n@@ -1119,10 +1219,16 @@ decide_unroll_stupid (struct loop *loop, int flags)\n   /* Success.  Now force nunroll to be power of 2, as it seems that this\n      improves results (partially because of better alignments, partially\n      because of some dark magic).  */\n-  for (i = 1; 2 * i <= nunroll; i *= 2);\n+  for (i = 1; 2 * i <= nunroll; i *= 2)\n+    continue;\n \n   loop->lpt_decision.decision = LPT_UNROLL_STUPID;\n   loop->lpt_decision.times = i - 1;\n+      \n+  if (rtl_dump_file)\n+    fprintf (rtl_dump_file,\n+\t     \";; Decided to unroll the loop stupidly, %d times.\\n\",\n+\t     loop->lpt_decision.times);\n }\n \n /* Unroll a LOOP LOOP->LPT_DECISION.TIMES times.  The transformation:\n@@ -1147,6 +1253,7 @@ unroll_loop_stupid (struct loops *loops, struct loop *loop)\n {\n   sbitmap wont_exit;\n   unsigned nunroll = loop->lpt_decision.times;\n+  struct niter_desc *desc = get_simple_loop_desc (loop);\n \n   wont_exit = sbitmap_alloc (nunroll + 1);\n   sbitmap_zero (wont_exit);\n@@ -1158,6 +1265,17 @@ unroll_loop_stupid (struct loops *loops, struct loop *loop)\n \n   free (wont_exit);\n \n+  if (desc->simple_p)\n+    {\n+      /* We indeed may get here provided that there are nontrivial assumptions\n+\t for a loop to be really simple.  We could update the counts, but the\n+\t problem is that we are unable to decide which exit will be taken\n+\t (not really true in case the number of iterations is constant,\n+\t but noone will do anything with this information, so we do not\n+\t worry about it).  */\n+      desc->simple_p = false;\n+    }\n+\n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \";; Unrolled loop %d times, %i insns\\n\",\n \t     nunroll, num_loop_insns (loop));"}, {"sha": "ebbabe82988eb7caf1172ea04c23dc4c0a6acfcb", "filename": "gcc/loop-unswitch.c", "status": "modified", "additions": 152, "deletions": 78, "changes": 230, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-unswitch.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Floop-unswitch.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-unswitch.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -79,11 +79,63 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n   with handling this case.  */\n \n static struct loop *unswitch_loop (struct loops *, struct loop *,\n-\t\t\t\t   basic_block);\n+\t\t\t\t   basic_block, rtx, rtx);\n static void unswitch_single_loop (struct loops *, struct loop *, rtx, int);\n-static bool may_unswitch_on_p (basic_block, struct loop *,\n-\t\t\t       basic_block *);\n-static rtx reversed_condition (rtx);\n+static rtx may_unswitch_on (basic_block, struct loop *, rtx *);\n+\n+/* Prepare a sequence comparing OP0 with OP1 using COMP and jumping to LABEL if\n+   true, with probability PROB.  If CINSN is not NULL, it is the insn to copy\n+   in order to create a jump.  */\n+\n+rtx\n+compare_and_jump_seq (rtx op0, rtx op1, enum rtx_code comp, rtx label, int prob,\n+\t\t      rtx cinsn)\n+{\n+  rtx seq, jump, cond;\n+  enum machine_mode mode;\n+\n+  mode = GET_MODE (op0);\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (op1);\n+\n+  start_sequence ();\n+  if (GET_MODE_CLASS (mode) == MODE_CC)\n+    {\n+      /* A hack -- there seems to be no easy generic way how to make a\n+\t conditional jump from a ccmode comparison.  */\n+      if (!cinsn)\n+\tabort ();\n+      cond = XEXP (SET_SRC (pc_set (cinsn)), 0);\n+      if (GET_CODE (cond) != comp\n+\t  || !rtx_equal_p (op0, XEXP (cond, 0))\n+\t  || !rtx_equal_p (op1, XEXP (cond, 1)))\n+\tabort ();\n+      emit_jump_insn (copy_insn (PATTERN (cinsn)));\n+      jump = get_last_insn ();\n+      JUMP_LABEL (jump) = JUMP_LABEL (cinsn);\n+      LABEL_NUSES (JUMP_LABEL (jump))++;\n+      redirect_jump (jump, label, 0);\n+    }\n+  else\n+    {\n+      if (cinsn)\n+\tabort ();\n+\n+      op0 = force_operand (op0, NULL_RTX);\n+      op1 = force_operand (op1, NULL_RTX);\n+      do_compare_rtx_and_jump (op0, op1, comp, 0,\n+\t\t\t       mode, NULL_RTX, NULL_RTX, label);\n+      jump = get_last_insn ();\n+      JUMP_LABEL (jump) = label;\n+      LABEL_NUSES (label)++;\n+    }\n+  REG_NOTES (jump) = gen_rtx_EXPR_LIST (REG_BR_PROB, GEN_INT (prob),\n+\t\t\t\t\tREG_NOTES (jump));\n+  seq = get_insns ();\n+  end_sequence ();\n+\n+  return seq;\n+}\n \n /* Main entry point.  Perform loop unswitching on all suitable LOOPS.  */\n void\n@@ -111,48 +163,82 @@ unswitch_loops (struct loops *loops)\n       verify_loop_structure (loops);\n #endif\n     }\n+\n+  iv_analysis_done ();\n }\n \n /* Checks whether we can unswitch LOOP on condition at end of BB -- one of its\n-   basic blocks (for what it means see comments below).  List of basic blocks\n-   inside LOOP is provided in BODY to save time.  */\n-static bool\n-may_unswitch_on_p (basic_block bb, struct loop *loop, basic_block *body)\n+   basic blocks (for what it means see comments below).  In case condition\n+   compares loop invariant cc mode register, return the jump in CINSN.  */\n+\n+static rtx\n+may_unswitch_on (basic_block bb, struct loop *loop, rtx *cinsn)\n {\n-  rtx test;\n+  rtx test, at, insn, op[2];\n+  struct rtx_iv iv;\n   unsigned i;\n+  enum machine_mode mode;\n \n   /* BB must end in a simple conditional jump.  */\n   if (!bb->succ || !bb->succ->succ_next || bb->succ->succ_next->succ_next)\n-    return false;\n+    return NULL_RTX;\n   if (!any_condjump_p (BB_END (bb)))\n-    return false;\n+    return NULL_RTX;\n \n   /* With branches inside loop.  */\n   if (!flow_bb_inside_loop_p (loop, bb->succ->dest)\n       || !flow_bb_inside_loop_p (loop, bb->succ->succ_next->dest))\n-    return false;\n+    return NULL_RTX;\n \n   /* It must be executed just once each iteration (because otherwise we\n      are unable to update dominator/irreducible loop information correctly).  */\n   if (!just_once_each_iteration_p (loop, bb))\n-    return false;\n+    return NULL_RTX;\n \n-  /* Condition must be invariant.  We use just a stupid test of invariantness\n-     of the condition: all used regs must not be modified inside loop body.  */\n-  test = get_condition (BB_END (bb), NULL, true);\n+  /* Condition must be invariant.  */\n+  test = get_condition (BB_END (bb), &at, true);\n   if (!test)\n-    return false;\n+    return NULL_RTX;\n+\n+  for (i = 0; i < 2; i++)\n+    {\n+      op[i] = XEXP (test, i);\n+\n+      if (CONSTANT_P (op[i]))\n+\tcontinue;\n+\n+      insn = iv_get_reaching_def (at, op[i]);\n+      if (!iv_analyse (insn, op[i], &iv))\n+\treturn NULL_RTX;\n+      if (iv.step != const0_rtx\n+\t  || iv.first_special)\n+\treturn NULL_RTX;\n+\n+      op[i] = get_iv_value (&iv, const0_rtx);\n+    }\n+\n+  mode = GET_MODE (op[0]);\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (op[1]);\n+  if (GET_MODE_CLASS (mode) == MODE_CC)\n+    {\n+      if (at != BB_END (bb))\n+\treturn NULL_RTX;\n \n-  for (i = 0; i < loop->num_nodes; i++)\n-    if (modified_between_p (test, BB_HEAD (body[i]), NEXT_INSN (BB_END (body[i]))))\n-      return false;\n+      *cinsn = BB_END (bb);\n+      if (!rtx_equal_p (op[0], XEXP (test, 0))\n+\t  || !rtx_equal_p (op[1], XEXP (test, 1)))\n+\treturn NULL_RTX;\n \n-  return true;\n+      return test;\n+    }\n+\n+  return canon_condition (gen_rtx_fmt_ee (GET_CODE (test), SImode,\n+\t\t\t\t\t  op[0], op[1]));\n }\n \n /* Reverses CONDition; returns NULL if we cannot.  */\n-static rtx\n+rtx\n reversed_condition (rtx cond)\n {\n   enum rtx_code reversed;\n@@ -173,13 +259,10 @@ static void\n unswitch_single_loop (struct loops *loops, struct loop *loop,\n \t\t      rtx cond_checked, int num)\n {\n-  basic_block *bbs, bb;\n+  basic_block *bbs;\n   struct loop *nloop;\n   unsigned i;\n-  int true_first;\n-  rtx cond, rcond, conds, rconds, acond, split_before;\n-  int always_true;\n-  int always_false;\n+  rtx cond, rcond, conds, rconds, acond, cinsn = NULL_RTX;\n   int repeat;\n   edge e;\n \n@@ -237,8 +320,9 @@ unswitch_single_loop (struct loops *loops, struct loop *loop,\n \n       /* Find a bb to unswitch on.  */\n       bbs = get_loop_body (loop);\n+      iv_analysis_loop_init (loop);\n       for (i = 0; i < loop->num_nodes; i++)\n-\tif (may_unswitch_on_p (bbs[i], loop, bbs))\n+\tif ((cond = may_unswitch_on (bbs[i], loop, &cinsn)))\n \t  break;\n \n       if (i == loop->num_nodes)\n@@ -247,39 +331,26 @@ unswitch_single_loop (struct loops *loops, struct loop *loop,\n \t  return;\n \t}\n \n-      if (!(cond = get_condition (BB_END (bbs[i]), &split_before, true)))\n-\tabort ();\n       rcond = reversed_condition (cond);\n+      if (rcond)\n+\trcond = canon_condition (rcond);\n \n       /* Check whether the result can be predicted.  */\n-      always_true = 0;\n-      always_false = 0;\n       for (acond = cond_checked; acond; acond = XEXP (acond, 1))\n-\t{\n-\t  if (rtx_equal_p (cond, XEXP (acond, 0)))\n-\t    {\n-\t      always_true = 1;\n-\t      break;\n-\t    }\n-\t  if (rtx_equal_p (rcond, XEXP (acond, 0)))\n-\t    {\n-\t      always_false = 1;\n-\t      break;\n-\t    }\n-\t}\n+\tsimplify_using_condition (XEXP (acond, 0), &cond, NULL);\n \n-      if (always_true)\n+      if (cond == const_true_rtx)\n \t{\n \t  /* Remove false path.  */\n-\t  for (e = bbs[i]->succ; !(e->flags & EDGE_FALLTHRU); e = e->succ_next);\n+\t  e = FALLTHRU_EDGE (bbs[i]);\n \t  remove_path (loops, e);\n \t  free (bbs);\n \t  repeat = 1;\n \t}\n-      else if (always_false)\n+      else if (cond == const0_rtx)\n \t{\n \t  /* Remove true path.  */\n-\t  for (e = bbs[i]->succ; e->flags & EDGE_FALLTHRU; e = e->succ_next);\n+\t  e = BRANCH_EDGE (bbs[i]);\n \t  remove_path (loops, e);\n \t  free (bbs);\n \t  repeat = 1;\n@@ -293,21 +364,17 @@ unswitch_single_loop (struct loops *loops, struct loop *loop,\n   else\n     rconds = cond_checked;\n \n-  /* Separate condition in a single basic block.  */\n-  bb = split_loop_bb (bbs[i], PREV_INSN (split_before))->dest;\n-  free (bbs);\n-  true_first = !(bb->succ->flags & EDGE_FALLTHRU);\n   if (rtl_dump_file)\n     fprintf (rtl_dump_file, \";; Unswitching loop\\n\");\n \n   /* Unswitch the loop on this condition.  */\n-  nloop = unswitch_loop (loops, loop, bb);\n+  nloop = unswitch_loop (loops, loop, bbs[i], cond, cinsn);\n   if (!nloop)\n   abort ();\n \n   /* Invoke itself on modified loops.  */\n-  unswitch_single_loop (loops, nloop, true_first ? conds : rconds, num + 1);\n-  unswitch_single_loop (loops, loop, true_first ? rconds : conds, num + 1);\n+  unswitch_single_loop (loops, nloop, rconds, num + 1);\n+  unswitch_single_loop (loops, loop, conds, num + 1);\n \n   free_EXPR_LIST_node (conds);\n   if (rcond)\n@@ -316,17 +383,21 @@ unswitch_single_loop (struct loops *loops, struct loop *loop,\n \n /* Unswitch a LOOP w.r. to given basic block UNSWITCH_ON.  We only support\n    unswitching of innermost loops.  UNSWITCH_ON must be executed in every\n-   iteration, i.e. it must dominate LOOP latch, and should only contain code\n-   for the condition we unswitch on.  Returns NULL if impossible, new\n-   loop otherwise.  */\n+   iteration, i.e. it must dominate LOOP latch.  COND is the condition\n+   determining which loop is entered.  Returns NULL if impossible, new loop\n+   otherwise.  The new loop is entered if COND is true.  If CINSN is not\n+   NULL, it is the insn in that COND is compared.  */\n+\n static struct loop *\n-unswitch_loop (struct loops *loops, struct loop *loop, basic_block unswitch_on)\n+unswitch_loop (struct loops *loops, struct loop *loop, basic_block unswitch_on,\n+\t       rtx cond, rtx cinsn)\n {\n-  edge entry, latch_edge;\n+  edge entry, latch_edge, true_edge, false_edge, e;\n   basic_block switch_bb, unswitch_on_alt, src;\n   struct loop *nloop;\n   sbitmap zero_bitmap;\n-  int irred_flag;\n+  int irred_flag, prob;\n+  rtx seq;\n \n   /* Some sanity checking.  */\n   if (!flow_bb_inside_loop_p (loop, unswitch_on))\n@@ -343,12 +414,6 @@ unswitch_loop (struct loops *loops, struct loop *loop, basic_block unswitch_on)\n   if (!flow_bb_inside_loop_p (loop, unswitch_on->succ->succ_next->dest))\n     abort ();\n \n-  /* Will we be able to perform redirection?  */\n-  if (!any_condjump_p (BB_END (unswitch_on)))\n-    return NULL;\n-  if (!cfg_layout_can_duplicate_bb_p (unswitch_on))\n-    return NULL;\n-\n   entry = loop_preheader_edge (loop);\n \n   /* Make a copy.  */\n@@ -365,10 +430,24 @@ unswitch_loop (struct loops *loops, struct loop *loop, basic_block unswitch_on)\n \n   /* Record the block with condition we unswitch on.  */\n   unswitch_on_alt = unswitch_on->rbi->copy;\n+  true_edge = BRANCH_EDGE (unswitch_on_alt);\n+  false_edge = FALLTHRU_EDGE (unswitch_on);\n+  latch_edge = loop->latch->rbi->copy->succ;\n+\n+  /* Create a block with the condition.  */\n+  prob = true_edge->probability;\n+  switch_bb = create_empty_bb (EXIT_BLOCK_PTR->prev_bb);\n+  seq = compare_and_jump_seq (XEXP (cond, 0), XEXP (cond, 1), GET_CODE (cond),\n+\t\t\t      block_label (true_edge->dest),\n+\t\t\t      prob, cinsn);\n+  emit_insn_after (seq, BB_END (switch_bb));\n+  e = make_edge (switch_bb, true_edge->dest, 0);\n+  e->probability = prob;\n+  e->count = latch_edge->count * prob / REG_BR_PROB_BASE;\n+  e = make_edge (switch_bb, FALLTHRU_EDGE (unswitch_on)->dest, EDGE_FALLTHRU);\n+  e->probability = false_edge->probability;\n+  e->count = latch_edge->count * (false_edge->probability) / REG_BR_PROB_BASE;\n \n-  /* Make a copy of the block containing the condition; we will use\n-     it as switch to decide which loop we want to use.  */\n-  switch_bb = cfg_layout_duplicate_bb (unswitch_on, NULL);\n   if (irred_flag)\n     {\n       switch_bb->flags |= BB_IRREDUCIBLE_LOOP;\n@@ -381,19 +460,14 @@ unswitch_loop (struct loops *loops, struct loop *loop, basic_block unswitch_on)\n       switch_bb->succ->flags &= ~EDGE_IRREDUCIBLE_LOOP;\n       switch_bb->succ->succ_next->flags &= ~EDGE_IRREDUCIBLE_LOOP;\n     }\n-  unswitch_on->rbi->copy = unswitch_on_alt;\n \n   /* Loopify from the copy of LOOP body, constructing the new loop.  */\n-  for (latch_edge = loop->latch->rbi->copy->succ;\n-       latch_edge->dest != loop->header;\n-       latch_edge = latch_edge->succ_next);\n   nloop = loopify (loops, latch_edge,\n \t\t   loop->header->rbi->copy->pred, switch_bb);\n \n-  /* Remove branches that are now unreachable in new loops.  We rely on the\n-     fact that cfg_layout_duplicate_bb reverses list of edges.  */\n-  remove_path (loops, unswitch_on->succ);\n-  remove_path (loops, unswitch_on_alt->succ);\n+  /* Remove branches that are now unreachable in new loops.  */\n+  remove_path (loops, true_edge);\n+  remove_path (loops, false_edge);\n \n   /* One of created loops do not have to be subloop of the outer loop now,\n      so fix its placement in loop data structure.  */"}, {"sha": "44ee10c9fe600498bb30d3004dbf8009acf77d39", "filename": "gcc/predict.c", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Fpredict.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Fpredict.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpredict.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -406,13 +406,16 @@ estimate_probability (struct loops *loops_info)\n       unsigned j;\n       int exits;\n       struct loop *loop = loops_info->parray[i];\n-      struct loop_desc desc;\n+      struct niter_desc desc;\n       unsigned HOST_WIDE_INT niter;\n \n       flow_loop_scan (loop, LOOP_EXIT_EDGES);\n       exits = loop->num_exits;\n \n-      if (simple_loop_p (loop, &desc) && desc.const_iter)\n+      iv_analysis_loop_init (loop);\n+      find_simple_exit (loop, &desc);\n+\n+      if (desc.simple_p && desc.const_iter)\n \t{\n \t  int prob;\n \t  niter = desc.niter + 1;\n@@ -472,6 +475,8 @@ estimate_probability (struct loops *loops_info)\n       free (bbs);\n     }\n \n+  iv_analysis_done ();\n+\n   /* Attempt to predict conditional jumps using a number of heuristics.  */\n   FOR_EACH_BB (bb)\n     {"}, {"sha": "c2c2a4bbc6ad6856698643349cd9a1ef913d2a95", "filename": "gcc/rtl.h", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -2361,4 +2361,15 @@ extern void tracer (void);\n /* In var-tracking.c */\n extern void variable_tracking_main (void);\n \n+/* In stor-layout.c.  */\n+extern void get_mode_bounds (enum machine_mode, int, rtx *, rtx *);\n+\n+/* In loop-unswitch.c  */\n+extern rtx reversed_condition (rtx);\n+extern rtx compare_and_jump_seq (rtx, rtx, enum rtx_code, rtx, int, rtx);\n+\n+/* In loop-iv.c  */\n+extern rtx canon_condition (rtx);\n+extern void simplify_using_condition (rtx, rtx *, struct bitmap_head_def *);\n+\n #endif /* ! GCC_RTL_H */"}, {"sha": "98420fb2dafcfbd0f72d89bf22c04bdc76530ec7", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -2118,4 +2118,27 @@ get_best_mode (int bitsize, int bitpos, unsigned int align,\n   return mode;\n }\n \n+/* Gets minimal and maximal values for MODE (signed or unsigned depending on\n+   SIGN).  */\n+\n+void\n+get_mode_bounds (enum machine_mode mode, int sign, rtx *mmin, rtx *mmax)\n+{\n+  int size = GET_MODE_BITSIZE (mode);\n+\n+  if (size > HOST_BITS_PER_WIDE_INT)\n+    abort ();\n+\n+  if (sign)\n+    {\n+      *mmin = GEN_INT (-((unsigned HOST_WIDE_INT) 1 << (size - 1)));\n+      *mmax = GEN_INT (((unsigned HOST_WIDE_INT) 1 << (size - 1)) - 1);\n+    }\n+  else\n+    {\n+      *mmin = const0_rtx;\n+      *mmax = GEN_INT (((unsigned HOST_WIDE_INT) 1 << (size - 1) << 1) - 1);\n+    }\n+}\n+\n #include \"gt-stor-layout.h\""}, {"sha": "c470cf0e3a4a1282954ac972f09b8f88a698cad7", "filename": "gcc/toplev.c", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50654f6c03917824e03777073557ac839cb56104/gcc%2Ftoplev.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50654f6c03917824e03777073557ac839cb56104/gcc%2Ftoplev.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftoplev.c?ref=50654f6c03917824e03777073557ac839cb56104", "patch": "@@ -3034,11 +3034,16 @@ static void\n rest_of_handle_loop2 (tree decl, rtx insns)\n {\n   struct loops *loops;\n+  basic_block bb;\n+\n   timevar_push (TV_LOOP);\n   open_dump_file (DFI_loop2, decl);\n   if (rtl_dump_file)\n     dump_flow_info (rtl_dump_file);\n \n+  /* Initialize structures for layout changes.  */\n+  cfg_layout_initialize ();\n+\n   loops = loop_optimizer_init (rtl_dump_file);\n \n   if (loops)\n@@ -3056,6 +3061,12 @@ rest_of_handle_loop2 (tree decl, rtx insns)\n       loop_optimizer_finalize (loops, rtl_dump_file);\n     }\n \n+  /* Finalize layout changes.  */\n+  FOR_EACH_BB (bb)\n+    if (bb->next_bb != EXIT_BLOCK_PTR)\n+      bb->rbi->next = bb->next_bb;\n+  cfg_layout_finalize ();\n+\n   cleanup_cfg (CLEANUP_EXPENSIVE);\n   delete_trivially_dead_insns (insns, max_reg_num ());\n   reg_scan (insns, max_reg_num (), 0);"}]}