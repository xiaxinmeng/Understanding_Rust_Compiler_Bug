{"sha": "2b835d68114d222704505707d0315902a4201250", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MmI4MzVkNjgxMTRkMjIyNzA0NTA1NzA3ZDAzMTU5MDJhNDIwMTI1MA==", "commit": {"author": {"name": "Richard Earnshaw", "email": "erich@gnu.org", "date": "1995-12-06T11:41:39Z"}, "committer": {"name": "Richard Earnshaw", "email": "erich@gnu.org", "date": "1995-12-06T11:41:39Z"}, "message": "(arm_gen_constant): New function.\n\n(arm_split_constant): Split most of the functionality into\narm_gen_constant.  Try to decide which way of handling the constant\nis optimal for the target processor.\n(arm_prgmode): New enum.\n(target_{cpu,fpe}_name, arm_fast_multiply, arm_arch4): New variables.\n(all_procs): New table describing processors and capabilities.\n(arm_override_options): New function.\n(arm_return_in_memory): New function.\n(arm_rtx_costs): Adjust the multiply costs to cope with processors\nwith fast multiplication instructions.\n(output_move_double): Use the ldm/stm variants more efficiently.\nDelete cases that can no-longer occur.\n(output_return_instruction, output_func_epilogue): Use TARGET_APCS_32,\nnot TARGET_6 for determining the type of return instruction to emit.\n(final_prescan_insn case CALL_INSN): Use TARGET_APCS_32, not TARGET_6\nto determine condition preservation.\n({symbol,label}_mentioned_p): New functions.\n(add_constant, dump_table, fixit, find_barrier, broken_move): New\nsupport functions for handling constant spilling.\n(arm_reorg): New constant spilling pass, for putting unhandlable\nconstants into the rtl where we can load them efficiently.\n(output_load_symbol): Delete.\n(strings_fpa): Use a form which is common to both GAS and ARMASM.\n(output_return_instruction, output_func_epilogue): Call\nassemble_external_libcall, before trying to generate an abort call\nin the assembler.\n\t(arm_asm_output_label): Call ARM_OUTPUT_LABEL, rather than assuming\nthat labels are followed by a colon.\n(aof_text_section, aof_add_import, aof_delete_import,\naof_dump_imports): New functions to support ARMASM assembler\ngeneration.\n\nFrom-SVN: r10680", "tree": {"sha": "e77783f05a0d139fd6e72215a8e806a53f4ed558", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e77783f05a0d139fd6e72215a8e806a53f4ed558"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2b835d68114d222704505707d0315902a4201250", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2b835d68114d222704505707d0315902a4201250", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2b835d68114d222704505707d0315902a4201250", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2b835d68114d222704505707d0315902a4201250/comments", "author": null, "committer": null, "parents": [{"sha": "9fb7806b3797b39b4931aa570e95ee056381dc0f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9fb7806b3797b39b4931aa570e95ee056381dc0f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9fb7806b3797b39b4931aa570e95ee056381dc0f"}], "stats": {"total": 1361, "additions": 1116, "deletions": 245}, "files": [{"sha": "079e4b647e945d6d0eebd1cd0e900f29abf155d8", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 1116, "deletions": 245, "changes": 1361, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2b835d68114d222704505707d0315902a4201250/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2b835d68114d222704505707d0315902a4201250/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=2b835d68114d222704505707d0315902a4201250", "patch": "@@ -50,6 +50,8 @@ extern void arm_increase_location ();\n \n HOST_WIDE_INT int_log2 PROTO ((HOST_WIDE_INT));\n static int get_prologue_size PROTO ((void));\n+static int arm_gen_constant PROTO ((enum rtx_code, enum machine_mode,\n+\t\t\t\t    HOST_WIDE_INT, rtx, rtx, int, int));\n \n /*  Define the information needed to generate branch insns.  This is\n    stored from the compare operation. */\n@@ -63,6 +65,18 @@ enum processor_type arm_cpu;\n /* What type of floating point are we compiling for? */\n enum floating_point_type arm_fpu;\n \n+/* What program mode is the cpu running in? 26-bit mode or 32-bit mode */\n+enum prog_mode_type arm_prgmode;\n+\n+char *target_cpu_name = ARM_CPU_NAME;\n+char *target_fpe_name = NULL;\n+\n+/* Nonzero if this is an \"M\" variant of the processor.  */\n+int arm_fast_multiply = 0;\n+\n+/* Nonzero if this chip support the ARM Architecture 4 extensions */\n+int arm_arch4 = 0;\n+\n /* In case of a PRE_INC, POST_INC, PRE_DEC, POST_DEC memory reference, we\n    must report the mode of the memory reference from PRINT_OPERAND to\n    PRINT_OPERAND_ADDRESS.  */\n@@ -96,6 +110,8 @@ static struct label_offset *offset_table[LABEL_HASH_SIZE];\n \n static int return_used_this_function;\n \n+static int arm_constant_limit = 3;\n+\n /* For an explanation of these variables, see final_prescan_insn below.  */\n int arm_ccfsm_state;\n int arm_current_cc;\n@@ -110,6 +126,168 @@ char *arm_condition_codes[] =\n };\n \n #define ARM_INVERSE_CONDITION_CODE(X)  ((X) ^ 1)\n+\n+\f\n+/* Initialization code */\n+\n+#define FL_CO_PROC    0x01            /* Has external co-processor bus */\n+#define FL_FAST_MULT  0x02            /* Fast multiply */\n+#define FL_MODE26     0x04            /* 26-bit mode support */\n+#define FL_MODE32     0x08            /* 32-bit mode support */\n+#define FL_ARCH4      0x10            /* Architecture rel 4 */\n+#define FL_THUMB      0x20            /* Thumb aware */\n+struct processors\n+{\n+  char *name;\n+  enum processor_type type;\n+  unsigned int flags;\n+};\n+\n+/* Not all of these give usefully different compilation alternatives,\n+   but there is no simple way of generalizing them.  */\n+static struct processors all_procs[] =\n+{\n+  {\"arm2\",\tPROCESSOR_ARM2, FL_CO_PROC | FL_MODE26},\n+  {\"arm250\",\tPROCESSOR_ARM2, FL_CO_PROC | FL_MODE26},\n+  {\"arm3\",\tPROCESSOR_ARM2, FL_CO_PROC | FL_MODE26},\n+  {\"arm6\",\tPROCESSOR_ARM6, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm60\",\tPROCESSOR_ARM6, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm600\",\tPROCESSOR_ARM6, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm610\",\tPROCESSOR_ARM6, FL_MODE32 | FL_MODE26},\n+  {\"arm620\",\tPROCESSOR_ARM6, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm7\",\tPROCESSOR_ARM7, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm70\",\tPROCESSOR_ARM7, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm7d\",\tPROCESSOR_ARM7, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm7di\",\tPROCESSOR_ARM7, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm7dm\",\tPROCESSOR_ARM7, (FL_CO_PROC | FL_FAST_MULT | FL_MODE32\n+\t\t\t\t | FL_MODE26)},\n+  {\"arm7dmi\",\tPROCESSOR_ARM7, (FL_CO_PROC | FL_FAST_MULT | FL_MODE32\n+\t\t\t\t | FL_MODE26)},\n+  {\"arm700\",\tPROCESSOR_ARM7, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm700i\",\tPROCESSOR_ARM7, FL_CO_PROC | FL_MODE32 | FL_MODE26},\n+  {\"arm710\",\tPROCESSOR_ARM7, FL_MODE32 | FL_MODE26},\n+  {\"arm710c\",\tPROCESSOR_ARM7, FL_MODE32 | FL_MODE26},\n+  {\"arm7500\",\tPROCESSOR_ARM7, FL_MODE32 | FL_MODE26},\n+  {\"arm7tdmi\",\tPROCESSOR_ARM7, (FL_CO_PROC | FL_FAST_MULT | FL_MODE32\n+\t\t\t\t | FL_ARCH4 | FL_THUMB)},\n+  {NULL, 0, 0}\n+};\n+\n+/* Fix up any incompatible options that the user has specified.\n+   This has now turned into a maze.  */\n+void\n+arm_override_options ()\n+{\n+  int arm_thumb_aware = 0;\n+\n+  if (write_symbols != NO_DEBUG && flag_omit_frame_pointer)\n+    warning (\"-g with -fomit-frame-pointer may not give sensible debugging\");\n+\n+  if (TARGET_POKE_FUNCTION_NAME)\n+    target_flags |= ARM_FLAG_APCS_FRAME;\n+\n+  if (TARGET_6)\n+    {\n+      warning (\"Option '-m6' deprecated.  Use: '-mapcs-32' or -mcpu-<proc>\");\n+      target_flags |= ARM_FLAG_APCS_32;\n+      arm_cpu = PROCESSOR_ARM6;\n+    }\n+\n+  if (TARGET_3)\n+    {\n+      warning (\"Option '-m3' deprecated.  Use: '-mapcs-26' or -mcpu-<proc>\");\n+      target_flags &= ~ARM_FLAG_APCS_32;\n+      arm_cpu = PROCESSOR_ARM2;\n+    }\n+\n+  if ((TARGET_3 || TARGET_6) && target_cpu_name != NULL)\n+    fatal (\"Incompatible mix of old and new options.  -m%d and -mcpu-%s\",\n+\t   TARGET_3 ? 3 : 6, target_cpu_name);\n+\n+  if (TARGET_APCS_REENT && flag_pic)\n+    fatal (\"-fpic and -mapcs-reent are incompatible\");\n+\n+  if (TARGET_APCS_REENT)\n+    warning (\"APCS reentrant code not supported.  Ignored\");\n+\n+  if (flag_pic)\n+    warning (\"Position independent code not supported.  Ignored\");\n+\n+  if (TARGET_APCS_FLOAT)\n+    warning (\"Passing floating point arguments in fp regs not yet supported\");\n+\n+  if (TARGET_APCS_STACK && ! TARGET_APCS)\n+    {\n+      warning (\"-mapcs-stack-check incompatible with -mno-apcs-frame\");\n+      target_flags |= ARM_FLAG_APCS_FRAME;\n+    }\n+\n+  arm_cpu = TARGET_6 ? PROCESSOR_ARM6: PROCESSOR_ARM2;\n+  arm_fpu = FP_HARD;\n+\n+  if (target_cpu_name != NULL)\n+    {\n+      char *c = target_cpu_name;\n+      struct processors *proc;\n+\n+      /* Match against the supported types.  */\n+      for (proc = all_procs; proc->name != NULL; proc++)\n+\t{\n+\t  if (strcmp (proc->name, c) == 0)\n+\t    break;\n+\t}\n+\n+      if (proc->name)\n+\t{\n+\t  arm_cpu = proc->type;\n+\n+\t  /* Default value for floating point code... if no co-processor\n+\t     bus, then schedule for emulated floating point.  Otherwise,\n+\t     assume the user has an FPA, unless overridden with -mfpe-...  */\n+\t  if (proc->flags & FL_CO_PROC == 0)\n+\t    arm_fpu = FP_SOFT3;\n+\t  else\n+\t    arm_fpu = FP_HARD;\n+\t  arm_fast_multiply = (proc->flags & FL_FAST_MULT) != 0;\n+\t  arm_arch4 = (proc->flags & FL_ARCH4) != 0;\n+\t  arm_thumb_aware = (proc->flags & FL_THUMB) != 0;\n+\t  /* Processors with a load delay slot can load constants faster,\n+\t     from the pool than it takes to construct them, so reduce the\n+\t     complexity of the constant that we will try to generate\n+\t     inline.  */\n+\t}\n+      else\n+\tfatal (\"Unrecognized cpu type: %s\", target_cpu_name);\n+    }\n+\n+  if (target_fpe_name)\n+    {\n+      if (strcmp (target_fpe_name, \"2\") == 0)\n+\tarm_fpu = FP_SOFT2;\n+      else if (strcmp (target_fpe_name, \"3\") == 0)\n+\tarm_fpu = FP_SOFT3;\n+      else\n+\tfatal (\"Invalid floating point emulation option: -mfpe-%s\",\n+\t       target_fpe_name);\n+    }\n+\n+  if (TARGET_THUMB_INTERWORK && ! arm_thumb_aware)\n+    {\n+      warning (\"This processor variant does not support Thumb interworking\");\n+      target_flags &= ~ARM_FLAG_THUMB;\n+    }\n+\n+  if (TARGET_FPE && arm_fpu != FP_HARD)\n+    arm_fpu = FP_SOFT2;\n+\n+  /* For arm2/3 there is no need to do any scheduling if there is only\n+     a floating point emulator, or we are doing software floating-point.  */\n+  if ((TARGET_SOFT_FLOAT || arm_fpu != FP_HARD) && arm_cpu == PROCESSOR_ARM2)\n+    flag_schedule_insns = flag_schedule_insns_after_reload = 0;\n+\n+  arm_prog_mode = TARGET_APCS_32 ? PROG_MODE_PROG32 : PROG_MODE_PROG26;\n+}\n+\n \f\n /* Return 1 if it is possible to return using a single instruction */\n \n@@ -191,7 +369,8 @@ const_ok_for_op (i, code, mode)\n    VAL is the integer to operate on;\n    SOURCE is the other operand (a register, or a null-pointer for SET);\n    SUBTARGETS means it is safe to create scratch registers if that will\n-   either produce a simpler sequence, or we will want to cse the values. */\n+   either produce a simpler sequence, or we will want to cse the values.\n+   Return value is the number of insns emitted.  */\n \n int\n arm_split_constant (code, mode, val, target, source, subtargets)\n@@ -201,6 +380,55 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n      rtx target;\n      rtx source;\n      int subtargets;\n+{\n+  if (subtargets || code == SET\n+      || (GET_CODE (target) == REG && GET_CODE (source) == REG\n+\t  && REGNO (target) != REGNO (source)))\n+    {\n+      rtx temp;\n+\n+      if (arm_gen_constant (code, mode, val, target, source, 1, 0)\n+\t  > arm_constant_limit + (code != SET))\n+\t{\n+\t  if (code == SET)\n+\t    {\n+\t      /* Currently SET is the only monadic value for CODE, all\n+\t\t the rest are diadic.  */\n+\t      emit_insn (gen_rtx (SET, VOIDmode, target, GEN_INT (val)));\n+\t      return 1;\n+\t    }\n+\t  else\n+\t    {\n+\t      rtx temp = subtargets ? gen_reg_rtx (mode) : target;\n+\n+\t      emit_insn (gen_rtx (SET, VOIDmode, temp, GEN_INT (val)));\n+\t      /* For MINUS, the value is subtracted from, since we never\n+\t\t have subtraction of a constant.  */\n+\t      if (code == MINUS)\n+\t\temit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\t    gen_rtx (code, mode, temp, source)));\n+\t      else\n+\t\temit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\t    gen_rtx (code, mode, source, temp)));\n+\t      return 2;\n+\t    }\n+\t}\n+    }\n+\n+  return arm_gen_constant (code, mode, val, target, source, subtargets, 1);\n+}\n+\n+/* As above, but extra parameter GENERATE which, if clear, suppresses\n+   RTL generation.  */\n+int\n+arm_gen_constant (code, mode, val, target, source, subtargets, generate)\n+     enum rtx_code code;\n+     enum machine_mode mode;\n+     HOST_WIDE_INT val;\n+     rtx target;\n+     rtx source;\n+     int subtargets;\n+     int generate;\n {\n   int can_add = 0;\n   int can_invert = 0;\n@@ -237,30 +465,34 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n     case IOR:\n       if (remainder == 0xffffffff)\n \t{\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t      GEN_INT (ARM_SIGN_EXTEND (val))));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\tGEN_INT (ARM_SIGN_EXTEND (val))));\n \t  return 1;\n \t}\n       if (remainder == 0)\n \t{\n \t  if (reload_completed && rtx_equal_p (target, source))\n \t    return 0;\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target, source));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target, source));\n \t  return 1;\n \t}\n       break;\n \n     case AND:\n       if (remainder == 0)\n \t{\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target, const0_rtx));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target, const0_rtx));\n \t  return 1;\n \t}\n       if (remainder == 0xffffffff)\n \t{\n \t  if (reload_completed && rtx_equal_p (target, source))\n \t    return 0;\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target, source));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target, source));\n \t  return 1;\n \t}\n       can_invert = 1;\n@@ -271,13 +503,15 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \t{\n \t  if (reload_completed && rtx_equal_p (target, source))\n \t    return 0;\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target, source));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target, source));\n \t  return 1;\n \t}\n       if (remainder == 0xffffffff)\n \t{\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t      gen_rtx (NOT, mode, source)));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\tgen_rtx (NOT, mode, source)));\n \t  return 1;\n \t}\n \n@@ -289,14 +523,16 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \t passed as (source + (-val)).  */\n       if (remainder == 0)\n \t{\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t      gen_rtx (NEG, mode, source)));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\tgen_rtx (NEG, mode, source)));\n \t  return 1;\n \t}\n       if (const_ok_for_arm (val))\n \t{\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target, \n-\t\t\t      gen_rtx (MINUS, mode, GEN_INT (val), source)));\n+\t  if (generate)\n+\t    emit_insn (gen_rtx (SET, VOIDmode, target, \n+\t\t\t\tgen_rtx (MINUS, mode, GEN_INT (val), source)));\n \t  return 1;\n \t}\n       can_negate = 1;\n@@ -312,9 +548,11 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n       || (can_negate_initial && const_ok_for_arm (-val))\n       || (can_invert && const_ok_for_arm (~val)))\n     {\n-      emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t  (source ? gen_rtx (code, mode, source,\n-\t\t\t\t\t     GEN_INT (val)) : GEN_INT (val))));\n+      if (generate)\n+\temit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t    (source ? gen_rtx (code, mode, source,\n+\t\t\t\t\t       GEN_INT (val))\n+\t\t\t     : GEN_INT (val))));\n       return 1;\n     }\n \n@@ -366,21 +604,29 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \t      (temp1 = ARM_SIGN_EXTEND (remainder \n \t\t\t\t\t<< (set_sign_bit_copies - 1))))\n \t    {\n-\t      new_src = subtargets ? gen_reg_rtx (mode) : target;\n-\t      emit_insn (gen_rtx (SET, VOIDmode, new_src, GEN_INT (temp1)));\n-\t      emit_insn (gen_ashrsi3 (target, new_src, \n-\t\t\t\t      GEN_INT (set_sign_bit_copies - 1)));\n+\t      if (generate)\n+\t\t{\n+\t\t  new_src = subtargets ? gen_reg_rtx (mode) : target;\n+\t\t  emit_insn (gen_rtx (SET, VOIDmode, new_src, \n+\t\t\t\t      GEN_INT (temp1)));\n+\t\t  emit_insn (gen_ashrsi3 (target, new_src, \n+\t\t\t\t\t  GEN_INT (set_sign_bit_copies - 1)));\n+\t\t}\n \t      return 2;\n \t    }\n \t  /* For an inverted constant, we will need to set the low bits,\n \t     these will be shifted out of harm's way.  */\n \t  temp1 |= (1 << (set_sign_bit_copies - 1)) - 1;\n \t  if (const_ok_for_arm (~temp1))\n \t    {\n-\t      new_src = subtargets ? gen_reg_rtx (mode) : target;\n-\t      emit_insn (gen_rtx (SET, VOIDmode, new_src, GEN_INT (temp1)));\n-\t      emit_insn (gen_ashrsi3 (target, new_src, \n-\t\t\t\t      GEN_INT (set_sign_bit_copies - 1)));\n+\t      if (generate)\n+\t\t{\n+\t\t  new_src = subtargets ? gen_reg_rtx (mode) : target;\n+\t\t  emit_insn (gen_rtx (SET, VOIDmode, new_src,\n+\t\t\t\t      GEN_INT (temp1)));\n+\t\t  emit_insn (gen_ashrsi3 (target, new_src, \n+\t\t\t\t\t  GEN_INT (set_sign_bit_copies - 1)));\n+\t\t}\n \t      return 2;\n \t    }\n \t}\n@@ -401,18 +647,18 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \t      if ((((temp2 | (temp2 << i)) & 0xffffffff) == remainder)\n \t\t  && ! const_ok_for_arm (temp2))\n \t\t{\n-\t\t  insns\n-\t\t    = arm_split_constant (code, mode, temp2,\n-\t\t\t\t\t  (new_src\n-\t\t\t\t\t   = subtargets ? gen_reg_rtx (mode)\n-\t\t\t\t\t   : target),\n-\t\t\t\t\t  source, subtargets);\n+\t\t  insns = arm_gen_constant (code, mode, temp2,\n+\t\t\t\t\t    new_src = (subtargets\n+\t\t\t\t\t\t       ? gen_reg_rtx (mode)\n+\t\t\t\t\t\t       : target),\n+\t\t\t\t\t    source, subtargets, generate);\n \t\t  source = new_src;\n-\t\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t\t      gen_rtx (IOR, mode,\n-\t\t\t\t\t       gen_rtx (ASHIFT, mode, source,\n-\t\t\t\t\t\t\tGEN_INT (i)),\n-\t\t\t\t\t       source)));\n+\t\t  if (generate)\n+\t\t    emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\t\tgen_rtx (IOR, mode,\n+\t\t\t\t\t\t gen_rtx (ASHIFT, mode, source,\n+\t\t\t\t\t\t\t  GEN_INT (i)),\n+\t\t\t\t\t\t source)));\n \t\t  return insns + 1;\n \t\t}\n \t    }\n@@ -423,18 +669,18 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \t      if (((temp1 | (temp1 >> i)) == remainder)\n \t\t  && ! const_ok_for_arm (temp1))\n \t\t{\n-\t\t  insns\n-\t\t    = arm_split_constant (code, mode, temp1,\n-\t\t\t\t\t  (new_src\n-\t\t\t\t\t   = subtargets ? gen_reg_rtx (mode)\n-\t\t\t\t\t   : target),\n-\t\t\t\t\t  source, subtargets);\n+\t\t  insns = arm_gen_constant (code, mode, temp1,\n+\t\t\t\t\t    new_src = (subtargets\n+\t\t\t\t\t\t       ? gen_reg_rtx (mode)\n+\t\t\t\t\t\t       : target),\n+\t\t\t\t\t    source, subtargets, generate);\n \t\t  source = new_src;\n-\t\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t\t      gen_rtx (IOR, mode,\n-\t\t\t\t\t       gen_rtx (LSHIFTRT, mode, source,\n-\t\t\t\t\t\t\tGEN_INT (i)),\n-\t\t\t\t\t       source)));\n+\t\t  if (generate)\n+\t\t    emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\t\tgen_rtx (IOR, mode,\n+\t\t\t\t\t\t gen_rtx (LSHIFTRT, mode,\n+\t\t\t\t\t\t\t  source, GEN_INT (i)),\n+\t\t\t\t\t\t source)));\n \t\t  return insns + 1;\n \t\t}\n \t    }\n@@ -451,12 +697,15 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \t{\n \t  if (const_ok_for_arm (ARM_SIGN_EXTEND (~ val)))\n \t    {\n-\t      rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n+\t      if (generate)\n+\t\t{\n+\t\t  rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n \n-\t      emit_insn (gen_rtx (SET, VOIDmode, sub,\n-\t\t\t\t  GEN_INT (ARM_SIGN_EXTEND (~ val))));\n-\t      emit_insn (gen_rtx (SET, VOIDmode, target, \n-\t\t\t\t  gen_rtx (code, mode, source, sub)));\n+\t\t  emit_insn (gen_rtx (SET, VOIDmode, sub,\n+\t\t\t\t      GEN_INT (ARM_SIGN_EXTEND (~ val))));\n+\t\t  emit_insn (gen_rtx (SET, VOIDmode, target, \n+\t\t\t\t      gen_rtx (code, mode, source, sub)));\n+\t\t}\n \t      return 2;\n \t    }\n \t}\n@@ -467,49 +716,59 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n       if (set_sign_bit_copies > 8\n \t  && (val & (-1 << (32 - set_sign_bit_copies))) == val)\n \t{\n-\t  rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n-\t  rtx shift = GEN_INT (set_sign_bit_copies);\n-\n-\t  emit_insn (gen_rtx (SET, VOIDmode, sub,\n-\t\t\t      gen_rtx (NOT, mode, \n-\t\t\t\t       gen_rtx (ASHIFT, mode, source, \n-\t\t\t\t\t\tshift))));\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t      gen_rtx (NOT, mode,\n-\t\t\t\t       gen_rtx (LSHIFTRT, mode, sub,\n-\t\t\t\t\t\tshift))));\n+\t  if (generate)\n+\t    {\n+\t      rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n+\t      rtx shift = GEN_INT (set_sign_bit_copies);\n+\n+\t      emit_insn (gen_rtx (SET, VOIDmode, sub,\n+\t\t\t\t  gen_rtx (NOT, mode, \n+\t\t\t\t\t   gen_rtx (ASHIFT, mode, source, \n+\t\t\t\t\t\t    shift))));\n+\t      emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\t  gen_rtx (NOT, mode,\n+\t\t\t\t\t   gen_rtx (LSHIFTRT, mode, sub,\n+\t\t\t\t\t\t    shift))));\n+\t    }\n \t  return 2;\n \t}\n \n       if (set_zero_bit_copies > 8\n \t  && (remainder & ((1 << set_zero_bit_copies) - 1)) == remainder)\n \t{\n-\t  rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n-\t  rtx shift = GEN_INT (set_zero_bit_copies);\n-\t  \n-\t  emit_insn (gen_rtx (SET, VOIDmode, sub,\n-\t\t\t      gen_rtx (NOT, mode,\n-\t\t\t\t       gen_rtx (LSHIFTRT, mode, source,\n-\t\t\t\t\t\tshift))));\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t      gen_rtx (NOT, mode,\n-\t\t\t\t       gen_rtx (ASHIFT, mode, sub,\n-\t\t\t\t\t\tshift))));\n+\t  if (generate)\n+\t    {\n+\t      rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n+\t      rtx shift = GEN_INT (set_zero_bit_copies);\n+\n+\t      emit_insn (gen_rtx (SET, VOIDmode, sub,\n+\t\t\t\t  gen_rtx (NOT, mode,\n+\t\t\t\t\t   gen_rtx (LSHIFTRT, mode, source,\n+\t\t\t\t\t\t    shift))));\n+\t      emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\t  gen_rtx (NOT, mode,\n+\t\t\t\t\t   gen_rtx (ASHIFT, mode, sub,\n+\t\t\t\t\t\t    shift))));\n+\t    }\n \t  return 2;\n \t}\n \n       if (const_ok_for_arm (temp1 = ARM_SIGN_EXTEND (~ val)))\n \t{\n-\t  rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n-\t  emit_insn (gen_rtx (SET, VOIDmode, sub,\n-\t\t\t      gen_rtx (NOT, mode, source)));\n-\t  source = sub;\n-\t  if (subtargets)\n-\t    sub = gen_reg_rtx (mode);\n-\t  emit_insn (gen_rtx (SET, VOIDmode, sub,\n-\t\t\t      gen_rtx (AND, mode, source, GEN_INT (temp1))));\n-\t  emit_insn (gen_rtx (SET, VOIDmode, target,\n-\t\t\t      gen_rtx (NOT, mode, sub)));\n+\t  if (generate)\n+\t    {\n+\t      rtx sub = subtargets ? gen_reg_rtx (mode) : target;\n+\t      emit_insn (gen_rtx (SET, VOIDmode, sub,\n+\t\t\t\t  gen_rtx (NOT, mode, source)));\n+\t      source = sub;\n+\t      if (subtargets)\n+\t\tsub = gen_reg_rtx (mode);\n+\t      emit_insn (gen_rtx (SET, VOIDmode, sub,\n+\t\t\t\t  gen_rtx (AND, mode, source, \n+\t\t\t\t\t   GEN_INT (temp1))));\n+\t      emit_insn (gen_rtx (SET, VOIDmode, target,\n+\t\t\t\t  gen_rtx (NOT, mode, sub)));\n+\t    }\n \t  return 3;\n \t}\n       break;\n@@ -522,39 +781,61 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \t\t\t\t       << (32 - clear_sign_bit_copies))\n \t\t\t\t      & 0xffffffff);\n \t  rtx new_source;\n-\t  rtx shift = GEN_INT (clear_sign_bit_copies);\n+\t  rtx shift;\n \n \t  if ((remainder | shift_mask) != 0xffffffff)\n \t    {\n+\t      if (generate)\n+\t\t{\n+\t\t  new_source = subtargets ? gen_reg_rtx (mode) : target;\n+\t\t  insns = arm_gen_constant (AND, mode, remainder | shift_mask,\n+\t\t\t\t\t    new_source, source, subtargets, 1);\n+\t\t  source = new_source;\n+\t\t}\n+\t      else\n+\t\tinsns = arm_gen_constant (AND, mode, remainder | shift_mask,\n+\t\t\t\t\t  new_source, source, subtargets, 0);\n+\t    }\n+\n+\t  if (generate)\n+\t    {\n+\t      shift = GEN_INT (clear_sign_bit_copies);\n \t      new_source = subtargets ? gen_reg_rtx (mode) : target;\n-\t      insns = arm_split_constant (AND, mode, remainder | shift_mask,\n-\t\t\t\t\t  new_source, source, subtargets);\n-\t      source = new_source;\n+\t      emit_insn (gen_ashlsi3 (new_source, source, shift));\n+\t      emit_insn (gen_lshrsi3 (target, new_source, shift));\n \t    }\n \n-\t  new_source = subtargets ? gen_reg_rtx (mode) : target;\n-\t  emit_insn (gen_ashlsi3 (new_source, source, shift));\n-\t  emit_insn (gen_lshrsi3 (target, new_source, shift));\n \t  return insns + 2;\n \t}\n \n       if (clear_zero_bit_copies >= 16 && clear_zero_bit_copies < 24)\n \t{\n \t  HOST_WIDE_INT shift_mask = (1 << clear_zero_bit_copies) - 1;\n \t  rtx new_source;\n-\t  rtx shift = GEN_INT (clear_zero_bit_copies);\n+\t  rtx shift;\n \t  \n \t  if ((remainder | shift_mask) != 0xffffffff)\n \t    {\n+\t      if (generate)\n+\t\t{\n+\t\t  new_source = subtargets ? gen_reg_rtx (mode) : target;\n+\t\t  insns = arm_gen_constant (AND, mode, remainder | shift_mask,\n+\t\t\t\t\t    new_source, source, subtargets, 1);\n+\t\t  source = new_source;\n+\t\t}\n+\t      else\n+\t\tinsns = arm_gen_constant (AND, mode, remainder | shift_mask,\n+\t\t\t\t\t  new_source, source, subtargets, 0);\n+\t    }\n+\n+\t  if (generate)\n+\t    {\n+\t      shift = GEN_INT (clear_zero_bit_copies);\n \t      new_source = subtargets ? gen_reg_rtx (mode) : target;\n-\t      insns = arm_split_constant (AND, mode, remainder | shift_mask,\n-\t\t\t\t\t  new_source, source, subtargets);\n-\t      source = new_source;\n+\t      emit_insn (gen_lshrsi3 (new_source, source, shift));\n+\t      emit_insn (gen_ashlsi3 (target, new_source, shift));\n \t    }\n \n-\t  new_source = subtargets ? gen_reg_rtx (mode) : target;\n-\t  emit_insn (gen_lshrsi3 (new_source, source, shift));\n-\t  emit_insn (gen_ashlsi3 (target, new_source, shift));\n \t  return insns + 2;\n \t}\n \n@@ -629,32 +910,40 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n \n \t    if (code == SET)\n \t      {\n-\t\temit_insn (gen_rtx (SET, VOIDmode,\n-\t\t\t\t    new_src = (subtargets ? gen_reg_rtx (mode)\n-\t\t\t\t\t       : target),\n-\t\t\t\t    GEN_INT (can_invert ? ~temp1 : temp1)));\n+\t\tif (generate)\n+\t\t  emit_insn (gen_rtx (SET, VOIDmode,\n+\t\t\t\t      new_src = (subtargets\n+\t\t\t\t\t\t ? gen_reg_rtx (mode)\n+\t\t\t\t\t\t : target),\n+\t\t\t\t      GEN_INT (can_invert ? ~temp1 : temp1)));\n \t\tcan_invert = 0;\n \t\tcode = PLUS;\n \t      }\n \t    else if (code == MINUS)\n \t      {\n-\t\temit_insn (gen_rtx (SET, VOIDmode,\n-\t\t\t\t    new_src = (subtargets ? gen_reg_rtx (mode)\n-\t\t\t\t\t       : target),\n-\t\t\t\t    gen_rtx (code, mode, GEN_INT (temp1),\n-\t\t\t\t\t     source)));\n+\t\tif (generate)\n+\t\t  emit_insn (gen_rtx (SET, VOIDmode,\n+\t\t\t\t      new_src = (subtargets\n+\t\t\t\t\t\t ? gen_reg_rtx (mode)\n+\t\t\t\t\t\t : target),\n+\t\t\t\t      gen_rtx (code, mode, GEN_INT (temp1),\n+\t\t\t\t\t       source)));\n \t\tcode = PLUS;\n \t      }\n \t    else\n \t      {\n-\t\temit_insn (gen_rtx (SET, VOIDmode,\n-\t\t\t\t    new_src = remainder ? (subtargets\n-\t\t\t\t\t\t\t   ? gen_reg_rtx (mode)\n-\t\t\t\t\t\t\t   : target) : target,\n-\t\t\t\t    gen_rtx (code, mode, source,\n-\t\t\t\t\t     GEN_INT (can_invert ? ~temp1\n-\t\t\t\t\t\t      : (can_negate\n-\t\t\t\t\t\t\t ? -temp1 : temp1)))));\n+\t\tif (generate)\n+\t\t  emit_insn (gen_rtx (SET, VOIDmode,\n+\t\t\t\t      new_src = (remainder\n+\t\t\t\t\t\t ? (subtargets\n+\t\t\t\t\t\t    ? gen_reg_rtx (mode)\n+\t\t\t\t\t\t    : target)\n+\t\t\t\t\t\t : target),\n+\t\t\t\t      gen_rtx (code, mode, source,\n+\t\t\t\t\t       GEN_INT (can_invert ? ~temp1\n+\t\t\t\t\t\t\t: (can_negate\n+\t\t\t\t\t\t\t   ? -temp1\n+\t\t\t\t\t\t\t   : temp1)))));\n \t      }\n \n \t    insns++;\n@@ -667,6 +956,46 @@ arm_split_constant (code, mode, val, target, source, subtargets)\n   return insns;\n }\n \n+/* Handle aggregates that are not laid out in a BLKmode element.\n+   This is a sub-element of RETURN_IN_MEMORY.  */\n+int\n+arm_return_in_memory (type)\n+     tree type;\n+{\n+  if (TREE_CODE (type) == RECORD_TYPE)\n+    {\n+      tree field;\n+\n+      /* For a struct, we can return in a register if every element was a\n+\t bit-field.  */\n+      for (field = TYPE_FIELDS (type); field;  field = TREE_CHAIN (field))\n+\tif (TREE_CODE (field) != FIELD_DECL\n+\t    || ! DECL_BIT_FIELD_TYPE (field))\n+\t  return 1;\n+\n+      return 0;\n+    }\n+  else if (TREE_CODE (type) == UNION_TYPE)\n+    {\n+      tree field;\n+\n+      /* Unions can be returned in registers if every element is\n+\t integral, or can be returned in an integer register.  */\n+      for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n+\t{\n+\t  if (TREE_CODE (field) != FIELD_DECL\n+\t      || (AGGREGATE_TYPE_P (TREE_TYPE (field))\n+\t\t  && RETURN_IN_MEMORY (TREE_TYPE (field)))\n+\t      || FLOAT_TYPE_P (TREE_TYPE (field)))\n+\t    return 1;\n+\t}\n+      return 0;\n+    }\n+  /* XXX Not sure what should be done for other aggregates, so put them in\n+     memory. */\n+  return 1;\n+}\n+\n #define REG_OR_SUBREG_REG(X)\t\t\t\t\t\t\\\n   (GET_CODE (X) == REG\t\t\t\t\t\t\t\\\n    || (GET_CODE (X) == SUBREG && GET_CODE (SUBREG_REG (X)) == REG))\n@@ -814,27 +1143,35 @@ arm_rtx_costs (x, code, outer_code)\n       return 8;\n \n     case MULT:\n+      if (arm_fast_multiply && mode == DImode\n+\t  && (GET_CODE (XEXP (x, 0)) == GET_CODE (XEXP (x, 1)))\n+\t  && (GET_CODE (XEXP (x, 0)) == ZERO_EXTEND\n+\t      || GET_CODE (XEXP (x, 0)) == SIGN_EXTEND))\n+\treturn 8;\n+\n       if (GET_MODE_CLASS (mode) == MODE_FLOAT\n \t  || mode == DImode)\n \treturn 30;\n \n       if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n \t{\n-\t  HOST_WIDE_INT i = INTVAL (XEXP (x, 1)) & 0xffffffff;\n+\t  unsigned HOST_WIDE_INT i = (INTVAL (XEXP (x, 1))\n+\t\t\t\t      & (unsigned HOST_WIDE_INT) 0xffffffff);\n \t  int add_cost = const_ok_for_arm (i) ? 4 : 8;\n \t  int j;\n-\t  \n-\t  /* This will need adjusting for ARM's with fast multiplies */\n-\t  for (j = 0; i && j < 32; j += 2)\n+\t  int booth_unit_size = (arm_fast_multiply ? 8 : 2);\n+\n+\t  for (j = 0; i && j < 32; j += booth_unit_size)\n \t    {\n-\t      i &= ~(3 << j);\n+\t      i >>= booth_unit_size;\n \t      add_cost += 2;\n \t    }\n \n \t  return add_cost;\n \t}\n \n-      return (30 + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 4)\n+      return ((arm_fast_multiply ? 8 : 30)\n+\t      + (REG_OR_SUBREG_REG (XEXP (x, 0)) ? 0 : 4)\n \t      + (REG_OR_SUBREG_REG (XEXP (x, 1)) ? 0 : 4));\n \n     case NEG:\n@@ -889,15 +1226,9 @@ arm_rtx_costs (x, code, outer_code)\n static int fpa_consts_inited = 0;\n \n char *strings_fpa[8] = {\n-  \"0.0\",\n-  \"1.0\",\n-  \"2.0\",\n-  \"3.0\",\n-  \"4.0\",\n-  \"5.0\",\n-  \"0.5\",\n-  \"10.0\"\n-  };\n+  \"0\",   \"1\",   \"2\",   \"3\",\n+  \"4\",   \"5\",   \"0.5\", \"10\"\n+};\n \n static REAL_VALUE_TYPE values_fpa[8];\n \n@@ -1306,6 +1637,64 @@ reversible_cc_register (x, mode)\n   return FALSE;\n }\n \n+/* Return TRUE if X references a SYMBOL_REF.  */\n+int\n+symbol_mentioned_p (x)\n+     rtx x;\n+{\n+  register char *fmt;\n+  register int i;\n+\n+  if (GET_CODE (x) == SYMBOL_REF)\n+    return 1;\n+\n+  fmt = GET_RTX_FORMAT (GET_CODE (x));\n+  for (i = GET_RTX_LENGTH (GET_CODE (x)) - 1; i >= 0; i--)\n+    {\n+      if (fmt[i] == 'E')\n+\t{\n+\t  register int j;\n+\n+\t  for (j = XVECLEN (x, i) - 1; j >= 0; j--)\n+\t    if (symbol_mentioned_p (XVECEXP (x, i, j)))\n+\t      return 1;\n+\t}\n+      else if (fmt[i] == 'e' && symbol_mentioned_p (XEXP (x, i)))\n+\treturn 1;\n+    }\n+\n+  return 0;\n+}\n+\n+/* Return TRUE if X references a LABEL_REF.  */\n+int\n+label_mentioned_p (x)\n+     rtx x;\n+{\n+  register char *fmt;\n+  register int i;\n+\n+  if (GET_CODE (x) == LABEL_REF)\n+    return 1;\n+\n+  fmt = GET_RTX_FORMAT (GET_CODE (x));\n+  for (i = GET_RTX_LENGTH (GET_CODE (x)) - 1; i >= 0; i--)\n+    {\n+      if (fmt[i] == 'E')\n+\t{\n+\t  register int j;\n+\n+\t  for (j = XVECLEN (x, i) - 1; j >= 0; j--)\n+\t    if (label_mentioned_p (XVECEXP (x, i, j)))\n+\t      return 1;\n+\t}\n+      else if (fmt[i] == 'e' && label_mentioned_p (XEXP (x, i)))\n+\treturn 1;\n+    }\n+\n+  return 0;\n+}\n+\n enum rtx_code\n minmax_code (x)\n      rtx x;\n@@ -1826,6 +2215,391 @@ arm_insn_not_targeted (insn)\n   return insn != arm_target_insn;\n }\n \n+\f\n+/* Routines for manipulation of the constant pool.  */\n+/* This is unashamedly hacked from the version in sh.c, since the problem is\n+   extremely similar.  */\n+\n+/* Arm instructions cannot load a large constant into a register,\n+   constants have to come from a pc relative load.  The reference of a pc\n+   relative load instruction must be less than 1k infront of the instruction.\n+   This means that we often have to dump a constant inside a function, and\n+   generate code to branch around it.\n+\n+   It is important to minimize this, since the branches will slow things\n+   down and make things bigger.\n+\n+   Worst case code looks like:\n+\n+\tldr\trn, L1\n+\tb\tL2\n+\talign\n+\tL1:\t.long value\n+\tL2:\n+\t..\n+\n+\tldr\trn, L3\n+\tb\tL4\n+\talign\n+\tL3:\t.long value\n+\tL4:\n+\t..\n+\n+   We fix this by performing a scan before scheduling, which notices which\n+   instructions need to have their operands fetched from the constant table\n+   and builds the table.\n+\n+\n+   The algorithm is:\n+\n+   scan, find an instruction which needs a pcrel move.  Look forward, find th\n+   last barrier which is within MAX_COUNT bytes of the requirement.\n+   If there isn't one, make one.  Process all the instructions between\n+   the find and the barrier.\n+\n+   In the above example, we can tell that L3 is within 1k of L1, so\n+   the first move can be shrunk from the 2 insn+constant sequence into\n+   just 1 insn, and the constant moved to L3 to make:\n+\n+\tldr\trn, L1\n+\t..\n+\tldr\trn, L3\n+\tb\tL4\n+\talign\n+\tL1:\t.long value\n+\tL3:\t.long value\n+\tL4:\n+\n+   Then the second move becomes the target for the shortening process.\n+\n+ */\n+\n+typedef struct\n+{\n+  rtx value;                    /* Value in table */\n+  HOST_WIDE_INT next_offset;\n+  enum machine_mode mode;       /* Mode of value */\n+} pool_node;\n+\n+/* The maximum number of constants that can fit into one pool, since\n+   the pc relative range is 0...1020 bytes and constants are at least 4\n+   bytes long */\n+\n+#define MAX_POOL_SIZE (1020/4)\n+static pool_node pool_vector[MAX_POOL_SIZE];\n+static int pool_size;\n+static rtx pool_vector_label;\n+\n+/* Add a constant to the pool and return its label.  */\n+static HOST_WIDE_INT\n+add_constant (x, mode)\n+     rtx x;\n+     enum machine_mode mode;\n+{\n+  int i;\n+  rtx lab;\n+  HOST_WIDE_INT offset;\n+\n+  if (mode == SImode && GET_CODE (x) == MEM && CONSTANT_P (XEXP (x, 0))\n+      && CONSTANT_POOL_ADDRESS_P (XEXP (x, 0)))\n+    x = get_pool_constant (XEXP (x, 0));\n+#ifndef AOF_ASSEMBLER\n+  else if (GET_CODE (x) == UNSPEC && XINT (x, 1) == 3)\n+    x = XVECEXP (x, 0, 0);\n+#endif\n+\n+  /* First see if we've already got it */\n+  for (i = 0; i < pool_size; i++)\n+    {\n+      if (GET_CODE (x) == pool_vector[i].value->code\n+\t  && mode == pool_vector[i].mode)\n+\t{\n+\t  if (GET_CODE (x) == CODE_LABEL)\n+\t    {\n+\t      if (XINT (x, 3) != XINT (pool_vector[i].value, 3))\n+\t\tcontinue;\n+\t    }\n+\t  if (rtx_equal_p (x, pool_vector[i].value))\n+\t    return pool_vector[i].next_offset - GET_MODE_SIZE (mode);\n+\t}\n+    }\n+\n+  /* Need a new one */\n+  pool_vector[pool_size].next_offset = GET_MODE_SIZE (mode);\n+  offset = 0;\n+  if (pool_size == 0)\n+    pool_vector_label = gen_label_rtx ();\n+  else\n+    pool_vector[pool_size].next_offset\n+      += (offset = pool_vector[pool_size - 1].next_offset);\n+\n+  pool_vector[pool_size].value = x;\n+  pool_vector[pool_size].mode = mode;\n+  pool_size++;\n+  return offset;\n+}\n+\n+/* Output the literal table */\n+static void\n+dump_table (scan)\n+     rtx scan;\n+{\n+  int i;\n+\n+  scan = emit_label_after (gen_label_rtx (), scan);\n+  scan = emit_insn_after (gen_align_4 (), scan);\n+  scan = emit_label_after (pool_vector_label, scan);\n+\n+  for (i = 0; i < pool_size; i++)\n+    {\n+      pool_node *p = pool_vector + i;\n+\n+      switch (GET_MODE_SIZE (p->mode))\n+\t{\n+\tcase 4:\n+\t  scan = emit_insn_after (gen_consttable_4 (p->value), scan);\n+\t  break;\n+\n+\tcase 8:\n+\t  scan = emit_insn_after (gen_consttable_8 (p->value), scan);\n+\t  break;\n+\n+\tdefault:\n+\t  abort ();\n+\t  break;\n+\t}\n+    }\n+\n+  scan = emit_insn_after (gen_consttable_end (), scan);\n+  scan = emit_barrier_after (scan);\n+  pool_size = 0;\n+}\n+\n+/* Non zero if the src operand needs to be fixed up */\n+static int\n+fixit (src, mode, destreg)\n+     rtx src;\n+     enum machine_mode mode;\n+     int destreg;\n+{\n+  if (CONSTANT_P (src))\n+    {\n+      if (GET_CODE (src) == CONST_INT)\n+\treturn (! const_ok_for_arm (INTVAL (src))\n+\t\t&& ! const_ok_for_arm (~INTVAL (src)));\n+      if (GET_CODE (src) == CONST_DOUBLE)\n+\treturn (GET_MODE (src) == VOIDmode\n+\t\t|| destreg < 16\n+\t\t|| (! const_double_rtx_ok_for_fpu (src)\n+\t\t    && ! neg_const_double_rtx_ok_for_fpu (src)));\n+      return symbol_mentioned_p (src);\n+    }\n+#ifndef AOF_ASSEMBLER\n+  else if (GET_CODE (src) == UNSPEC && XINT (src, 1) == 3)\n+    return 1;\n+#endif\n+  else\n+    return (mode == SImode && GET_CODE (src) == MEM\n+\t    && GET_CODE (XEXP (src, 0)) == SYMBOL_REF\n+\t    && CONSTANT_POOL_ADDRESS_P (XEXP (src, 0)));\n+}\n+\n+/* Find the last barrier less than MAX_COUNT bytes from FROM, or create one. */\n+static rtx\n+find_barrier (from, max_count)\n+     rtx from;\n+     int max_count;\n+{\n+  int count = 0;\n+  rtx found_barrier = 0;\n+\n+  while (from && count < max_count)\n+    {\n+      if (GET_CODE (from) == BARRIER)\n+\tfound_barrier = from;\n+\n+      /* Count the length of this insn */\n+      if (GET_CODE (from) == INSN\n+\t  && GET_CODE (PATTERN (from)) == SET\n+\t  && CONSTANT_P (SET_SRC (PATTERN (from)))\n+\t  && CONSTANT_POOL_ADDRESS_P (SET_SRC (PATTERN (from))))\n+\t{\n+\t  rtx src = SET_SRC (PATTERN (from));\n+\t  count += 2;\n+\t}\n+      else\n+\tcount += get_attr_length (from);\n+\n+      from = NEXT_INSN (from);\n+    }\n+\n+  if (!found_barrier)\n+    {\n+      /* We didn't find a barrier in time to\n+\t dump our stuff, so we'll make one */\n+      rtx label = gen_label_rtx ();\n+\n+      if (from)\n+\tfrom = PREV_INSN (from);\n+      else\n+\tfrom = get_last_insn ();\n+\n+      /* Walk back to be just before any jump */\n+      while (GET_CODE (from) == JUMP_INSN\n+             || GET_CODE (from) == NOTE\n+\t     || GET_CODE (from) == CODE_LABEL)\n+\tfrom = PREV_INSN (from);\n+\n+      from = emit_jump_insn_after (gen_jump (label), from);\n+      JUMP_LABEL (from) = label;\n+      found_barrier = emit_barrier_after (from);\n+      emit_label_after (label, found_barrier);\n+      return found_barrier;\n+    }\n+\n+  return found_barrier;\n+}\n+\n+/* Non zero if the insn is a move instruction which needs to be fixed. */\n+static int\n+broken_move (insn)\n+     rtx insn;\n+{\n+  if (!INSN_DELETED_P (insn)\n+      && GET_CODE (insn) == INSN\n+      && GET_CODE (PATTERN (insn)) == SET)\n+    {\n+      rtx pat = PATTERN (insn);\n+      rtx src = SET_SRC (pat);\n+      rtx dst = SET_DEST (pat);\n+      int destreg;\n+      enum machine_mode mode = GET_MODE (dst);\n+      if (dst == pc_rtx)\n+\treturn 0;\n+\n+      if (GET_CODE (dst) == REG)\n+\tdestreg = REGNO (dst);\n+      else if (GET_CODE (dst) == SUBREG && GET_CODE (SUBREG_REG (dst)) == REG)\n+\tdestreg = REGNO (SUBREG_REG (dst));\n+\n+      return fixit (src, mode, destreg);\n+    }\n+  return 0;\n+}\n+\n+void\n+arm_reorg (first)\n+     rtx first;\n+{\n+  rtx insn;\n+  int count_size;\n+  int regno;\n+\n+#if 0\n+  /* The ldr instruction can work with up to a 4k offset, and most constants\n+     will be loaded with one of these instructions; however, the adr \n+     instruction and the ldf instructions only work with a 1k offset.  This\n+     code needs to be rewritten to use the 4k offset when possible, and to\n+     adjust when a 1k offset is needed.  For now we just use a 1k offset\n+     from the start.  */\n+  count_size = 4000;\n+\n+  /* Floating point operands can't work further than 1024 bytes from the\n+     PC, so to make things simple we restrict all loads for such functions.\n+     */\n+  if (TARGET_HARD_FLOAT)\n+    for (regno = 16; regno < 24; regno++)\n+      if (regs_ever_live[regno])\n+\t{\n+\t  count_size = 1000;\n+\t  break;\n+\t}\n+#else\n+  count_size = 1000;\n+#endif /* 0 */\n+\n+  for (insn = first; insn; insn = NEXT_INSN (insn))\n+    {\n+      if (broken_move (insn))\n+\t{\n+\t  /* This is a broken move instruction, scan ahead looking for\n+\t     a barrier to stick the constant table behind */\n+\t  rtx scan;\n+\t  rtx barrier = find_barrier (insn, count_size);\n+\n+\t  /* Now find all the moves between the points and modify them */\n+\t  for (scan = insn; scan != barrier; scan = NEXT_INSN (scan))\n+\t    {\n+\t      if (broken_move (scan))\n+\t\t{\n+\t\t  /* This is a broken move instruction, add it to the pool */\n+\t\t  rtx pat = PATTERN (scan);\n+\t\t  rtx src = SET_SRC (pat);\n+\t\t  rtx dst = SET_DEST (pat);\n+\t\t  enum machine_mode mode = GET_MODE (dst);\n+\t\t  HOST_WIDE_INT offset;\n+\t\t  rtx newinsn = scan;\n+\t\t  rtx newsrc;\n+\t\t  rtx addr;\n+\t\t  int scratch;\n+\n+\t\t  /* If this is an HImode constant load, convert it into\n+\t\t     an SImode constant load.  Since the register is always\n+\t\t     32 bits this is safe.  We have to do this, since the\n+\t\t     load pc-relative instruction only does a 32-bit load. */\n+\t\t  if (mode == HImode)\n+\t\t    {\n+\t\t      mode = SImode;\n+\t\t      if (GET_CODE (dst) != REG)\n+\t\t\tabort ();\n+\t\t      PUT_MODE (dst, SImode);\n+\t\t    }\n+\n+\t\t  offset = add_constant (src, mode);\n+\t\t  addr = plus_constant (gen_rtx (LABEL_REF, VOIDmode,\n+\t\t\t\t\t\t pool_vector_label),\n+\t\t\t\t\toffset);\n+\n+\t\t  /* For wide moves to integer regs we need to split the\n+\t\t     address calculation off into a separate insn, so that\n+\t\t     the load can then be done with a load-multiple.  This is\n+\t\t     safe, since we have already noted the length of such\n+\t\t     insns to be 8, and we are immediately over-writing the\n+\t\t     scratch we have grabbed with the final result.  */\n+\t\t  if (GET_MODE_SIZE (mode) > 4\n+\t\t      && (scratch = REGNO (dst)) < 16)\n+\t\t    {\n+\t\t      rtx reg = gen_rtx (REG, SImode, scratch);\n+\t\t      newinsn = emit_insn_after (gen_movaddr (reg, addr),\n+\t\t\t\t\t\t newinsn);\n+\t\t      addr = reg;\n+\t\t    }\n+\n+\t\t  newsrc = gen_rtx (MEM, mode, addr);\n+\n+\t\t  /* Build a jump insn wrapper around the move instead\n+\t\t     of an ordinary insn, because we want to have room for\n+\t\t     the target label rtx in fld[7], which an ordinary\n+\t\t     insn doesn't have. */\n+\t\t  newinsn = emit_jump_insn_after (gen_rtx (SET, VOIDmode,\n+\t\t\t\t\t\t\t   dst, newsrc),\n+\t\t\t\t\t\t  newinsn);\n+\t\t  JUMP_LABEL (newinsn) = pool_vector_label;\n+\n+\t\t  /* But it's still an ordinary insn */\n+\t\t  PUT_CODE (newinsn, INSN);\n+\n+\t\t  /* Kill old insn */\n+\t\t  delete_insn (scan);\n+\t\t  scan = newinsn;\n+\t\t}\n+\t    }\n+\t  dump_table (barrier);\n+\t  insn = scan;\n+\t}\n+    }\n+}\n+\n \f\n /* Routines to output assembly language.  */\n \n@@ -2150,74 +2924,141 @@ output_move_double (operands)\n \t  switch (GET_CODE (XEXP (operands[1], 0)))\n \t    {\n \t    case REG:\n-\t      /* Handle the simple case where address is [r, #0] more\n-\t\t efficient.  */\n \t      output_asm_insn (\"ldm%?ia\\t%m1, %M0\", operands);\n \t      break;\n+\n   \t    case PRE_INC:\n-\t      output_asm_insn (\"add%?\\t%m1, %m1, #8\", operands);\n-\t      output_asm_insn (\"ldm%?ia\\t%m1, %M0\", operands);\n+\t      abort (); /* Should never happen now */\n \t      break;\n+\n \t    case PRE_DEC:\n-\t      output_asm_insn (\"sub%?\\t%m1, %m1, #8\", operands);\n-\t      output_asm_insn (\"ldm%?ia\\t%m1, %M0\", operands);\n+\t      output_asm_insn (\"ldm%?db\\t%m1!, %M0\", operands);\n \t      break;\n+\n \t    case POST_INC:\n \t      output_asm_insn (\"ldm%?ia\\t%m1!, %M0\", operands);\n \t      break;\n+\n \t    case POST_DEC:\n-\t      output_asm_insn (\"ldm%?ia\\t%m1, %M0\", operands);\n-\t      output_asm_insn (\"sub%?\\t%m1, %m1, #8\", operands);\n+\t      abort (); /* Should never happen now */\n \t      break;\n+\n+\t    case LABEL_REF:\n+\t    case CONST:\n+\t      output_asm_insn (\"adr%?\\t%0, %1\", operands);\n+\t      output_asm_insn (\"ldm%?ia\\t%0, %M0\", operands);\n+\t      break;\n+\n \t    default:\n-\t      otherops[1] = adj_offsettable_operand (operands[1], 4);\n-\t      /* Take care of overlapping base/data reg.  */\n-\t      if (reg_mentioned_p (operands[0], operands[1]))\n-\t\t{\n-\t\t  output_asm_insn (\"ldr%?\\t%0, %1\", otherops);\n-\t\t  output_asm_insn (\"ldr%?\\t%0, %1\", operands);\n-\t\t}\n-\t      else\n+\t      if (arm_add_operand (XEXP (XEXP (operands[1], 0), 1)))\n \t\t{\n-\t\t  output_asm_insn (\"ldr%?\\t%0, %1\", operands);\n-\t\t  output_asm_insn (\"ldr%?\\t%0, %1\", otherops);\n+\t\t  otherops[0] = operands[0];\n+\t\t  otherops[1] = XEXP (XEXP (operands[1], 0), 0);\n+\t\t  otherops[2] = XEXP (XEXP (operands[1], 0), 1);\n+\t\t  if (GET_CODE (XEXP (operands[1], 0)) == PLUS)\n+\t\t    {\n+\t\t      if (GET_CODE (otherops[2]) == CONST_INT)\n+\t\t\t{\n+\t\t\t  switch (INTVAL (otherops[2]))\n+\t\t\t    {\n+\t\t\t    case -8:\n+\t\t\t      output_asm_insn (\"ldm%?db\\t%1, %M0\", otherops);\n+\t\t\t      return \"\";\n+\t\t\t    case -4:\n+\t\t\t      output_asm_insn (\"ldm%?da\\t%1, %M0\", otherops);\n+\t\t\t      return \"\";\n+\t\t\t    case 4:\n+\t\t\t      output_asm_insn (\"ldm%?ib\\t%1, %M0\", otherops);\n+\t\t\t      return \"\";\n+\t\t\t    }\n+\t\t\t  if (!(const_ok_for_arm (INTVAL (otherops[2]))))\n+\t\t\t    output_asm_insn (\"sub%?\\t%0, %1, #%n2\", otherops);\n+\t\t\t  else\n+\t\t\t    output_asm_insn (\"add%?\\t%0, %1, %2\", otherops);\n+\t\t\t}\n+\t\t      else\n+\t\t\toutput_asm_insn (\"add%?\\t%0, %1, %2\", otherops);\n+\t\t    }\n+\t\t  else\n+\t\t    output_asm_insn (\"sub%?\\t%0, %1, %2\", otherops);\n+\t\t  return \"ldm%?ia\\t%0, %M0\";\n+                }\n+              else\n+                {\n+\t\t  otherops[1] = adj_offsettable_operand (operands[1], 4);\n+\t\t  /* Take care of overlapping base/data reg.  */\n+\t\t  if (reg_mentioned_p (operands[0], operands[1]))\n+\t\t    {\n+\t\t      output_asm_insn (\"ldr%?\\t%0, %1\", otherops);\n+\t\t      output_asm_insn (\"ldr%?\\t%0, %1\", operands);\n+\t\t    }\n+\t\t  else\n+\t\t    {\n+\t\t      output_asm_insn (\"ldr%?\\t%0, %1\", operands);\n+\t\t      output_asm_insn (\"ldr%?\\t%0, %1\", otherops);\n+\t\t    }\n \t\t}\n \t    }\n \t}\n-      else abort();  /* Constraints should prevent this */\n+      else\n+\tabort();  /* Constraints should prevent this */\n     }\n   else if (code0 == MEM && code1 == REG)\n     {\n       if (REGNO (operands[1]) == 12)\n \tabort();\n+\n       switch (GET_CODE (XEXP (operands[0], 0)))\n         {\n \tcase REG:\n \t  output_asm_insn (\"stm%?ia\\t%m0, %M1\", operands);\n \t  break;\n+\n         case PRE_INC:\n-\t  output_asm_insn (\"add%?\\t%m0, %m0, #8\", operands);\n-\t  output_asm_insn (\"stm%?ia\\t%m0, %M1\", operands);\n+\t  abort (); /* Should never happen now */\n \t  break;\n+\n         case PRE_DEC:\n-\t  output_asm_insn (\"sub%?\\t%m0, %m0, #8\", operands);\n-\t  output_asm_insn (\"stm%?ia\\t%m0, %M1\", operands);\n+\t  output_asm_insn (\"stm%?db\\t%m0!, %M1\", operands);\n \t  break;\n+\n         case POST_INC:\n \t  output_asm_insn (\"stm%?ia\\t%m0!, %M1\", operands);\n \t  break;\n+\n         case POST_DEC:\n-\t  output_asm_insn (\"stm%?ia\\t%m0, %M1\", operands);\n-\t  output_asm_insn (\"sub%?\\t%m0, %m0, #8\", operands);\n+\t  abort (); /* Should never happen now */\n \t  break;\n+\n+\tcase PLUS:\n+\t  if (GET_CODE (XEXP (XEXP (operands[0], 0), 1)) == CONST_INT)\n+\t    {\n+\t      switch (INTVAL (XEXP (XEXP (operands[0], 0), 1)))\n+\t\t{\n+\t\tcase -8:\n+\t\t  output_asm_insn (\"stm%?db\\t%m0, %M1\", operands);\n+\t\t  return \"\";\n+\n+\t\tcase -4:\n+\t\t  output_asm_insn (\"stm%?da\\t%m0, %M1\", operands);\n+\t\t  return \"\";\n+\n+\t\tcase 4:\n+\t\t  output_asm_insn (\"stm%?ib\\t%m0, %M1\", operands);\n+\t\t  return \"\";\n+\t\t}\n+\t    }\n+\t  /* Fall through */\n+\n         default:\n \t  otherops[0] = adj_offsettable_operand (operands[0], 4);\n \t  otherops[1] = gen_rtx (REG, SImode, 1 + REGNO (operands[1]));\n \t  output_asm_insn (\"str%?\\t%1, %0\", operands);\n \t  output_asm_insn (\"str%?\\t%1, %0\", otherops);\n \t}\n     }\n-  else abort();  /* Constraints should prevent this */\n+  else\n+    abort();  /* Constraints should prevent this */\n \n   return \"\";\n }\n@@ -2454,7 +3295,7 @@ int_log2 (power)\n {\n   HOST_WIDE_INT shift = 0;\n \n-  while (((1 << shift) & power) == 0)\n+  while (((((HOST_WIDE_INT) 1) << shift) & power) == 0)\n     {\n       if (shift > 31)\n \tabort ();\n@@ -2680,6 +3521,7 @@ output_return_instruction (operand, really_return)\n       /* Otherwise, trap an attempted return by aborting. */\n       ops[0] = operand;\n       ops[1] = gen_rtx (SYMBOL_REF, Pmode, \"abort\");\n+      assemble_external_libcall (ops[1]);\n       output_asm_insn (\"bl%d0\\t%a1\", ops);\n       return \"\";\n     }\n@@ -2732,13 +3574,13 @@ output_return_instruction (operand, really_return)\n \t  strcat (instr, \"%|\");\n \t  strcat (instr, really_return ? reg_names[15] : reg_names[14]);\n \t}\n-      strcat (instr, (TARGET_6 || !really_return) ? \"}\" : \"}^\");\n+      strcat (instr, (TARGET_APCS_32 || !really_return) ? \"}\" : \"}^\");\n       output_asm_insn (instr, &operand);\n     }\n   else if (really_return)\n     {\n-      strcpy (instr,\n-\t      TARGET_6 ? \"mov%?%d0\\t%|pc, lr\" : \"mov%?%d0s\\t%|pc, %|lr\");\n+      strcpy (instr, (TARGET_APCS_32\n+\t\t      ? \"mov%?%d0\\t%|pc, %|lr\" : \"mov%?%d0s\\t%|pc, %|lr\"));\n       output_asm_insn (instr, &operand);\n     }\n \n@@ -2866,6 +3708,7 @@ output_func_epilogue (f, frame_size)\n   if (volatile_func)\n     {\n       rtx op = gen_rtx (SYMBOL_REF, Pmode, \"abort\");\n+      assemble_external_libcall (op);\n       output_asm_insn (\"bl\\t%a0\", &op);\n       code_size = 4;\n       goto epilogue_done;\n@@ -2891,7 +3734,7 @@ output_func_epilogue (f, frame_size)\n \n       live_regs_mask |= 0xA800;\n       print_multi_reg (f, \"ldmea\\t%sfp\", live_regs_mask,\n-\t\t       TARGET_6 ? FALSE : TRUE);\n+\t\t       TARGET_APCS_32 ? FALSE : TRUE);\n       code_size += 4;\n     }\n   else\n@@ -2914,7 +3757,7 @@ output_func_epilogue (f, frame_size)\n       if (current_function_pretend_args_size == 0 && regs_ever_live[14])\n \t{\n \t  print_multi_reg (f, \"ldmfd\\t%ssp!\", live_regs_mask | 0x8000,\n-\t\t\t   TARGET_6 ? FALSE : TRUE);\n+\t\t\t   TARGET_APCS_32 ? FALSE : TRUE);\n \t  code_size += 4;\n \t}\n       else\n@@ -2932,8 +3775,8 @@ output_func_epilogue (f, frame_size)\n \t\t\t\t     current_function_pretend_args_size);\n \t      output_add_immediate (operands);\n \t    }\n-\t  fprintf (f,\n-\t\t   TARGET_6 ? \"\\tmov\\t%spc, %slr\\n\" : \"\\tmovs\\t%spc, %slr\\n\",\n+\t  fprintf (f, (TARGET_APCS_32 ? \"\\tmov\\t%spc, %slr\\n\"\n+\t\t       : \"\\tmovs\\t%spc, %slr\\n\"),\n \t\t   REGISTER_PREFIX, REGISTER_PREFIX, f);\n \t  code_size += 4;\n \t}\n@@ -3256,8 +4099,7 @@ arm_asm_output_label (stream, name)\n   struct label_offset *cur;\n   int hash = 0;\n \n-  assemble_name (stream, name);\n-  fputs (\":\\n\", stream);\n+  ARM_OUTPUT_LABEL (stream, name);\n   if (! in_text_section ())\n     return;\n \n@@ -3283,82 +4125,6 @@ arm_asm_output_label (stream, name)\n   offset_table[hash] = cur;\n }\n \n-/* Load a symbol that is known to be in the text segment into a register.\n-   This should never be called when not optimizing.  */\n-\n-char *\n-output_load_symbol (insn, operands)\n-     rtx insn;\n-     rtx *operands;\n-{\n-  char *s;\n-  char *name = XSTR (operands[1], 0);\n-  struct label_offset *he;\n-  int hash = 0;\n-  int offset;\n-  unsigned int mask, never_mask = 0xffffffff;\n-  int shift, inst;\n-  char buffer[100];\n-\n-  if (optimize == 0 || *name != '*')\n-    abort ();\n-\n-  for (s = &name[1]; *s; s++)\n-    hash += *s;\n-\n-  hash = hash % LABEL_HASH_SIZE;\n-  he = offset_table[hash];\n-  while (he && strcmp (he->name, &name[1]))\n-    he = he->cdr;\n-  \n-  if (!he)\n-    abort ();\n-  \n-  offset = (arm_text_location + insn_addresses[INSN_UID (insn)]\n-\t    + get_prologue_size () + 8 - he->offset);\n-  if (offset < 0)\n-    abort ();\n-\n-  /* When generating the instructions, we never mask out the bits that we\n-     think will be always zero, then if a mistake has occurred somewhere, the\n-     assembler will spot it and generate an error.  */\n-\n-  /* If the symbol is word aligned then we might be able to reduce the\n-     number of loads.  */\n-  shift = ((offset & 3) == 0) ? 2 : 0;\n-\n-  /* Clear the bits from NEVER_MASK that will be orred in with the individual\n-     instructions.  */\n-  for (; shift < 32; shift += 8)\n-    {\n-      mask = 0xff << shift;\n-      if ((offset & mask) || ((unsigned) offset) > mask)\n-\tnever_mask &= ~mask;\n-    }\n-\n-  inst = 8;\n-  mask = 0xff << (shift - 32);\n-\n-  while (mask && (never_mask & mask) == 0)\n-    {\n-      if (inst == 8)\n-\t{\n-\t  strcpy (buffer, \"sub%?\\t%0, %|pc, #(8 + . -%a1)\");\n-\t  if ((never_mask | mask) != 0xffffffff)\n-\t    sprintf (buffer + strlen (buffer), \" & 0x%x\", mask | never_mask);\n-\t}\n-      else\n-\tsprintf (buffer, \"sub%%?\\t%%0, %%0, #(%d + . -%%a1) & 0x%x\",\n-\t\t inst, mask | never_mask);\n-\n-      output_asm_insn (buffer, operands);\n-      mask <<= 8;\n-      inst -= 4;\n-    }\n-\n-  return \"\";\n-}\n-\n /* Output code resembling an .lcomm directive.  /bin/as doesn't have this\n    directive hence this hack, which works by reserving some `.space' in the\n    bss segment directly.\n@@ -3634,11 +4400,12 @@ final_prescan_insn (insn, opvec, noperands)\n \t      break;\n \n \t    case CALL_INSN:\n-\t      /* The arm 6xx uses full 32 bit addresses so the cc is not \n-\t\t preserved over calls */\n-\t      if (TARGET_6)\n+\t      /* If using 32-bit addresses the cc is not preserved over\n+\t\t calls */\n+\t      if (TARGET_APCS_32)\n \t\tfail = TRUE;\n \t      break;\n+\n \t    case JUMP_INSN:\n       \t      /* If this is an unconditional branch to the same label, succeed.\n \t\t If it is to another label, do nothing.  If it is conditional,\n@@ -3746,4 +4513,108 @@ final_prescan_insn (insn, opvec, noperands)\n     }\n }\n \n-/* EOF */\n+#ifdef AOF_ASSEMBLER\n+/* Special functions only needed when producing AOF syntax assembler. */\n+\n+int arm_text_section_count = 1;\n+\n+char *\n+aof_text_section (in_readonly)\n+     int in_readonly;\n+{\n+  static char buf[100];\n+  if (in_readonly)\n+    return \"\";\n+  sprintf (buf, \"\\tAREA |C$$code%d|, CODE, READONLY\",\n+\t   arm_text_section_count++);\n+  if (flag_pic)\n+    strcat (buf, \", PIC, REENTRANT\");\n+  return buf;\n+}\n+\n+static int arm_data_section_count = 1;\n+\n+char *\n+aof_data_section ()\n+{\n+  static char buf[100];\n+  sprintf (buf, \"\\tAREA |C$$data%d|, DATA\", arm_data_section_count++);\n+  return buf;\n+}\n+\n+/* The AOF assembler is religiously strict about declarations of\n+   imported and exported symbols, so that it is impossible to declare\n+   a function as imported near the begining of the file, and then to\n+   export it later on.  It is, however, possible to delay the decision\n+   until all the functions in the file have been compiled.  To get\n+   around this, we maintain a list of the imports and exports, and\n+   delete from it any that are subsequently defined.  At the end of\n+   compilation we spit the remainder of the list out before the END\n+   directive.  */\n+\n+struct import\n+{\n+  struct import *next;\n+  char *name;\n+};\n+\n+static struct import *imports_list = NULL;\n+\n+void\n+aof_add_import (name)\n+     char *name;\n+{\n+  struct import *new;\n+\n+  for (new = imports_list; new; new = new->next)\n+    if (new->name == name)\n+      return;\n+\n+  new = (struct import *) xmalloc (sizeof (struct import));\n+  new->next = imports_list;\n+  imports_list = new;\n+  new->name = name;\n+}\n+\n+void\n+aof_delete_import (name)\n+     char *name;\n+{\n+  struct import **old;\n+\n+  for (old = &imports_list; *old; old = & (*old)->next)\n+    {\n+      if ((*old)->name == name)\n+\t{\n+\t  *old = (*old)->next;\n+\t  return;\n+\t}\n+    }\n+}\n+\n+int arm_main_function = 0;\n+\n+void\n+aof_dump_imports (f)\n+     FILE *f;\n+{\n+  /* The AOF assembler needs this to cause the startup code to be extracted\n+     from the library.  Brining in __main causes the whole thing to work\n+     automagically.  */\n+  if (arm_main_function)\n+    {\n+      text_section ();\n+      fputs (\"\\tIMPORT __main\\n\", f);\n+      fputs (\"\\tDCD __main\\n\", f);\n+    }\n+\n+  /* Now dump the remaining imports.  */\n+  while (imports_list)\n+    {\n+      fprintf (f, \"\\tIMPORT\\t\");\n+      assemble_name (f, imports_list->name);\n+      fputc ('\\n', f);\n+      imports_list = imports_list->next;\n+    }\n+}\n+#endif /* AOF_ASSEMBLER */"}]}