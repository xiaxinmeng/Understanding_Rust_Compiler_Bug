{"sha": "1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWVlM2QxZWYxMDVjNTE4MWZiZjI5OGI4ZGRiNjM4ZjhlM2NiYWFjYQ==", "commit": {"author": {"name": "Martin Liska", "email": "mliska@suse.cz", "date": "2020-11-13T16:06:48Z"}, "committer": {"name": "Matthew Malcomson", "email": "matthew.malcomson@arm.com", "date": "2020-11-25T16:35:30Z"}, "message": "libsanitizer: add hwasan.\n\nIntroduce the libhwasan library from LLVM sources.", "tree": {"sha": "388861983e62f323e196589cbf51973e40a7f928", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/388861983e62f323e196589cbf51973e40a7f928"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/comments", "author": {"login": "marxin", "id": 2658545, "node_id": "MDQ6VXNlcjI2NTg1NDU=", "avatar_url": "https://avatars.githubusercontent.com/u/2658545?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marxin", "html_url": "https://github.com/marxin", "followers_url": "https://api.github.com/users/marxin/followers", "following_url": "https://api.github.com/users/marxin/following{/other_user}", "gists_url": "https://api.github.com/users/marxin/gists{/gist_id}", "starred_url": "https://api.github.com/users/marxin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marxin/subscriptions", "organizations_url": "https://api.github.com/users/marxin/orgs", "repos_url": "https://api.github.com/users/marxin/repos", "events_url": "https://api.github.com/users/marxin/events{/privacy}", "received_events_url": "https://api.github.com/users/marxin/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mmalcomson", "id": 57484298, "node_id": "MDQ6VXNlcjU3NDg0Mjk4", "avatar_url": "https://avatars.githubusercontent.com/u/57484298?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmalcomson", "html_url": "https://github.com/mmalcomson", "followers_url": "https://api.github.com/users/mmalcomson/followers", "following_url": "https://api.github.com/users/mmalcomson/following{/other_user}", "gists_url": "https://api.github.com/users/mmalcomson/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmalcomson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmalcomson/subscriptions", "organizations_url": "https://api.github.com/users/mmalcomson/orgs", "repos_url": "https://api.github.com/users/mmalcomson/repos", "events_url": "https://api.github.com/users/mmalcomson/events{/privacy}", "received_events_url": "https://api.github.com/users/mmalcomson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b13dacdfb315675803982ad5a3098f7b55e6357a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b13dacdfb315675803982ad5a3098f7b55e6357a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b13dacdfb315675803982ad5a3098f7b55e6357a"}], "stats": {"total": 4576, "additions": 4575, "deletions": 1}, "files": [{"sha": "0fb64a9567c1dc2e67ac3541b0add83bf5b77b55", "filename": "libsanitizer/MERGE", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2FMERGE", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2FMERGE", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2FMERGE?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -1,4 +1,4 @@\n-a28a466210199559d38251c11f30515cc83eadd6\n+6e7dd1e3e1170080b76b5dcc5716bdd974343233\n \n The first line of this file holds the git revision number of the\n last merge done from the master library sources."}, {"sha": "07defc5b6d8700803e402f0e2ea70d7854c2d769", "filename": "libsanitizer/README.gcc", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2FREADME.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2FREADME.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2FREADME.gcc?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -11,6 +11,7 @@ https://github.com/llvm/llvm-project in the following directories:\n   compiler-rt/lib/tsan\n   compiler-rt/lib/lsan\n   compiler-rt/lib/ubsan\n+  compiler-rt/lib/hwasan\n \n Trivial and urgent fixes (portability, build fixes, etc.) may go directly to the\n GCC tree.  All non-trivial changes, functionality improvements, etc. should go"}, {"sha": "c5322110cb662a55092d94d85b66767bf932f538", "filename": "libsanitizer/hwasan/hwasan.cpp", "status": "added", "additions": 522, "deletions": 0, "changes": 522, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,522 @@\n+//===-- hwasan.cpp --------------------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// HWAddressSanitizer runtime.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"hwasan.h\"\n+\n+#include \"hwasan_checks.h\"\n+#include \"hwasan_dynamic_shadow.h\"\n+#include \"hwasan_globals.h\"\n+#include \"hwasan_poisoning.h\"\n+#include \"hwasan_report.h\"\n+#include \"hwasan_thread.h\"\n+#include \"hwasan_thread_list.h\"\n+#include \"sanitizer_common/sanitizer_atomic.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_flag_parser.h\"\n+#include \"sanitizer_common/sanitizer_flags.h\"\n+#include \"sanitizer_common/sanitizer_libc.h\"\n+#include \"sanitizer_common/sanitizer_procmaps.h\"\n+#include \"sanitizer_common/sanitizer_stackdepot.h\"\n+#include \"sanitizer_common/sanitizer_stacktrace.h\"\n+#include \"sanitizer_common/sanitizer_symbolizer.h\"\n+#include \"ubsan/ubsan_flags.h\"\n+#include \"ubsan/ubsan_init.h\"\n+\n+// ACHTUNG! No system header includes in this file.\n+\n+using namespace __sanitizer;\n+\n+namespace __hwasan {\n+\n+static Flags hwasan_flags;\n+\n+Flags *flags() {\n+  return &hwasan_flags;\n+}\n+\n+int hwasan_inited = 0;\n+int hwasan_instrumentation_inited = 0;\n+bool hwasan_init_is_running;\n+\n+int hwasan_report_count = 0;\n+\n+void Flags::SetDefaults() {\n+#define HWASAN_FLAG(Type, Name, DefaultValue, Description) Name = DefaultValue;\n+#include \"hwasan_flags.inc\"\n+#undef HWASAN_FLAG\n+}\n+\n+static void RegisterHwasanFlags(FlagParser *parser, Flags *f) {\n+#define HWASAN_FLAG(Type, Name, DefaultValue, Description) \\\n+  RegisterFlag(parser, #Name, Description, &f->Name);\n+#include \"hwasan_flags.inc\"\n+#undef HWASAN_FLAG\n+}\n+\n+static void InitializeFlags() {\n+  SetCommonFlagsDefaults();\n+  {\n+    CommonFlags cf;\n+    cf.CopyFrom(*common_flags());\n+    cf.external_symbolizer_path = GetEnv(\"HWASAN_SYMBOLIZER_PATH\");\n+    cf.malloc_context_size = 20;\n+    cf.handle_ioctl = true;\n+    // FIXME: test and enable.\n+    cf.check_printf = false;\n+    cf.intercept_tls_get_addr = true;\n+    cf.exitcode = 99;\n+    // 8 shadow pages ~512kB, small enough to cover common stack sizes.\n+    cf.clear_shadow_mmap_threshold = 4096 * (SANITIZER_ANDROID ? 2 : 8);\n+    // Sigtrap is used in error reporting.\n+    cf.handle_sigtrap = kHandleSignalExclusive;\n+\n+#if SANITIZER_ANDROID\n+    // Let platform handle other signals. It is better at reporting them then we\n+    // are.\n+    cf.handle_segv = kHandleSignalNo;\n+    cf.handle_sigbus = kHandleSignalNo;\n+    cf.handle_abort = kHandleSignalNo;\n+    cf.handle_sigill = kHandleSignalNo;\n+    cf.handle_sigfpe = kHandleSignalNo;\n+#endif\n+    OverrideCommonFlags(cf);\n+  }\n+\n+  Flags *f = flags();\n+  f->SetDefaults();\n+\n+  FlagParser parser;\n+  RegisterHwasanFlags(&parser, f);\n+  RegisterCommonFlags(&parser);\n+\n+#if HWASAN_CONTAINS_UBSAN\n+  __ubsan::Flags *uf = __ubsan::flags();\n+  uf->SetDefaults();\n+\n+  FlagParser ubsan_parser;\n+  __ubsan::RegisterUbsanFlags(&ubsan_parser, uf);\n+  RegisterCommonFlags(&ubsan_parser);\n+#endif\n+\n+  // Override from user-specified string.\n+  if (__hwasan_default_options)\n+    parser.ParseString(__hwasan_default_options());\n+#if HWASAN_CONTAINS_UBSAN\n+  const char *ubsan_default_options = __ubsan_default_options();\n+  ubsan_parser.ParseString(ubsan_default_options);\n+#endif\n+\n+  parser.ParseStringFromEnv(\"HWASAN_OPTIONS\");\n+#if HWASAN_CONTAINS_UBSAN\n+  ubsan_parser.ParseStringFromEnv(\"UBSAN_OPTIONS\");\n+#endif\n+\n+  InitializeCommonFlags();\n+\n+  if (Verbosity()) ReportUnrecognizedFlags();\n+\n+  if (common_flags()->help) parser.PrintFlagDescriptions();\n+}\n+\n+static void HWAsanCheckFailed(const char *file, int line, const char *cond,\n+                              u64 v1, u64 v2) {\n+  Report(\"HWAddressSanitizer CHECK failed: %s:%d \\\"%s\\\" (0x%zx, 0x%zx)\\n\", file,\n+         line, cond, (uptr)v1, (uptr)v2);\n+  PRINT_CURRENT_STACK_CHECK();\n+  Die();\n+}\n+\n+static constexpr uptr kMemoryUsageBufferSize = 4096;\n+\n+static void HwasanFormatMemoryUsage(InternalScopedString &s) {\n+  HwasanThreadList &thread_list = hwasanThreadList();\n+  auto thread_stats = thread_list.GetThreadStats();\n+  auto *sds = StackDepotGetStats();\n+  AllocatorStatCounters asc;\n+  GetAllocatorStats(asc);\n+  s.append(\n+      \"HWASAN pid: %d rss: %zd threads: %zd stacks: %zd\"\n+      \" thr_aux: %zd stack_depot: %zd uniq_stacks: %zd\"\n+      \" heap: %zd\",\n+      internal_getpid(), GetRSS(), thread_stats.n_live_threads,\n+      thread_stats.total_stack_size,\n+      thread_stats.n_live_threads * thread_list.MemoryUsedPerThread(),\n+      sds->allocated, sds->n_uniq_ids, asc[AllocatorStatMapped]);\n+}\n+\n+#if SANITIZER_ANDROID\n+static char *memory_usage_buffer = nullptr;\n+\n+static void InitMemoryUsage() {\n+  memory_usage_buffer =\n+      (char *)MmapOrDie(kMemoryUsageBufferSize, \"memory usage string\");\n+  CHECK(memory_usage_buffer);\n+  memory_usage_buffer[0] = '\\0';\n+  DecorateMapping((uptr)memory_usage_buffer, kMemoryUsageBufferSize,\n+                  memory_usage_buffer);\n+}\n+\n+void UpdateMemoryUsage() {\n+  if (!flags()->export_memory_stats)\n+    return;\n+  if (!memory_usage_buffer)\n+    InitMemoryUsage();\n+  InternalScopedString s(kMemoryUsageBufferSize);\n+  HwasanFormatMemoryUsage(s);\n+  internal_strncpy(memory_usage_buffer, s.data(), kMemoryUsageBufferSize - 1);\n+  memory_usage_buffer[kMemoryUsageBufferSize - 1] = '\\0';\n+}\n+#else\n+void UpdateMemoryUsage() {}\n+#endif\n+\n+} // namespace __hwasan\n+\n+using namespace __hwasan;\n+\n+void __sanitizer::BufferedStackTrace::UnwindImpl(\n+    uptr pc, uptr bp, void *context, bool request_fast, u32 max_depth) {\n+  Thread *t = GetCurrentThread();\n+  if (!t) {\n+    // The thread is still being created, or has already been destroyed.\n+    size = 0;\n+    return;\n+  }\n+  Unwind(max_depth, pc, bp, context, t->stack_top(), t->stack_bottom(),\n+         request_fast);\n+}\n+\n+static bool InitializeSingleGlobal(const hwasan_global &global) {\n+  uptr full_granule_size = RoundDownTo(global.size(), 16);\n+  TagMemoryAligned(global.addr(), full_granule_size, global.tag());\n+  if (global.size() % 16)\n+    TagMemoryAligned(global.addr() + full_granule_size, 16, global.size() % 16);\n+  return false;\n+}\n+\n+static void InitLoadedGlobals() {\n+  dl_iterate_phdr(\n+      [](dl_phdr_info *info, size_t /* size */, void * /* data */) -> int {\n+        for (const hwasan_global &global : HwasanGlobalsFor(\n+                 info->dlpi_addr, info->dlpi_phdr, info->dlpi_phnum))\n+          InitializeSingleGlobal(global);\n+        return 0;\n+      },\n+      nullptr);\n+}\n+\n+// Prepare to run instrumented code on the main thread.\n+static void InitInstrumentation() {\n+  if (hwasan_instrumentation_inited) return;\n+\n+  InitPrctl();\n+\n+  if (!InitShadow()) {\n+    Printf(\"FATAL: HWAddressSanitizer cannot mmap the shadow memory.\\n\");\n+    DumpProcessMap();\n+    Die();\n+  }\n+\n+  InitThreads();\n+  hwasanThreadList().CreateCurrentThread();\n+\n+  hwasan_instrumentation_inited = 1;\n+}\n+\n+// Interface.\n+\n+uptr __hwasan_shadow_memory_dynamic_address;  // Global interface symbol.\n+\n+// This function was used by the old frame descriptor mechanism. We keep it\n+// around to avoid breaking ABI.\n+void __hwasan_init_frames(uptr beg, uptr end) {}\n+\n+void __hwasan_init_static() {\n+  InitShadowGOT();\n+  InitInstrumentation();\n+\n+  // In the non-static code path we call dl_iterate_phdr here. But at this point\n+  // libc might not have been initialized enough for dl_iterate_phdr to work.\n+  // Fortunately, since this is a statically linked executable we can use the\n+  // linker-defined symbol __ehdr_start to find the only relevant set of phdrs.\n+  extern ElfW(Ehdr) __ehdr_start;\n+  for (const hwasan_global &global : HwasanGlobalsFor(\n+           /* base */ 0,\n+           reinterpret_cast<const ElfW(Phdr) *>(\n+               reinterpret_cast<const char *>(&__ehdr_start) +\n+               __ehdr_start.e_phoff),\n+           __ehdr_start.e_phnum))\n+    InitializeSingleGlobal(global);\n+}\n+\n+void __hwasan_init() {\n+  CHECK(!hwasan_init_is_running);\n+  if (hwasan_inited) return;\n+  hwasan_init_is_running = 1;\n+  SanitizerToolName = \"HWAddressSanitizer\";\n+\n+  InitTlsSize();\n+\n+  CacheBinaryName();\n+  InitializeFlags();\n+\n+  // Install tool-specific callbacks in sanitizer_common.\n+  SetCheckFailedCallback(HWAsanCheckFailed);\n+\n+  __sanitizer_set_report_path(common_flags()->log_path);\n+\n+  AndroidTestTlsSlot();\n+\n+  DisableCoreDumperIfNecessary();\n+\n+  InitInstrumentation();\n+  InitLoadedGlobals();\n+\n+  // Needs to be called here because flags()->random_tags might not have been\n+  // initialized when InitInstrumentation() was called.\n+  GetCurrentThread()->InitRandomState();\n+\n+  SetPrintfAndReportCallback(AppendToErrorMessageBuffer);\n+  // This may call libc -> needs initialized shadow.\n+  AndroidLogInit();\n+\n+  InitializeInterceptors();\n+  InstallDeadlySignalHandlers(HwasanOnDeadlySignal);\n+  InstallAtExitHandler(); // Needs __cxa_atexit interceptor.\n+\n+  InitializeCoverage(common_flags()->coverage, common_flags()->coverage_dir);\n+\n+  HwasanTSDInit();\n+  HwasanTSDThreadInit();\n+\n+  HwasanAllocatorInit();\n+\n+#if HWASAN_CONTAINS_UBSAN\n+  __ubsan::InitAsPlugin();\n+#endif\n+\n+  VPrintf(1, \"HWAddressSanitizer init done\\n\");\n+\n+  hwasan_init_is_running = 0;\n+  hwasan_inited = 1;\n+}\n+\n+void __hwasan_library_loaded(ElfW(Addr) base, const ElfW(Phdr) * phdr,\n+                             ElfW(Half) phnum) {\n+  for (const hwasan_global &global : HwasanGlobalsFor(base, phdr, phnum))\n+    InitializeSingleGlobal(global);\n+}\n+\n+void __hwasan_library_unloaded(ElfW(Addr) base, const ElfW(Phdr) * phdr,\n+                               ElfW(Half) phnum) {\n+  for (; phnum != 0; ++phdr, --phnum)\n+    if (phdr->p_type == PT_LOAD)\n+      TagMemory(base + phdr->p_vaddr, phdr->p_memsz, 0);\n+}\n+\n+void __hwasan_print_shadow(const void *p, uptr sz) {\n+  uptr ptr_raw = UntagAddr(reinterpret_cast<uptr>(p));\n+  uptr shadow_first = MemToShadow(ptr_raw);\n+  uptr shadow_last = MemToShadow(ptr_raw + sz - 1);\n+  Printf(\"HWASan shadow map for %zx .. %zx (pointer tag %x)\\n\", ptr_raw,\n+         ptr_raw + sz, GetTagFromPointer((uptr)p));\n+  for (uptr s = shadow_first; s <= shadow_last; ++s)\n+    Printf(\"  %zx: %x\\n\", ShadowToMem(s), *(tag_t *)s);\n+}\n+\n+sptr __hwasan_test_shadow(const void *p, uptr sz) {\n+  if (sz == 0)\n+    return -1;\n+  tag_t ptr_tag = GetTagFromPointer((uptr)p);\n+  uptr ptr_raw = UntagAddr(reinterpret_cast<uptr>(p));\n+  uptr shadow_first = MemToShadow(ptr_raw);\n+  uptr shadow_last = MemToShadow(ptr_raw + sz - 1);\n+  for (uptr s = shadow_first; s <= shadow_last; ++s)\n+    if (*(tag_t *)s != ptr_tag) {\n+      sptr offset = ShadowToMem(s) - ptr_raw;\n+      return offset < 0 ? 0 : offset;\n+    }\n+  return -1;\n+}\n+\n+u16 __sanitizer_unaligned_load16(const uu16 *p) {\n+  return *p;\n+}\n+u32 __sanitizer_unaligned_load32(const uu32 *p) {\n+  return *p;\n+}\n+u64 __sanitizer_unaligned_load64(const uu64 *p) {\n+  return *p;\n+}\n+void __sanitizer_unaligned_store16(uu16 *p, u16 x) {\n+  *p = x;\n+}\n+void __sanitizer_unaligned_store32(uu32 *p, u32 x) {\n+  *p = x;\n+}\n+void __sanitizer_unaligned_store64(uu64 *p, u64 x) {\n+  *p = x;\n+}\n+\n+void __hwasan_loadN(uptr p, uptr sz) {\n+  CheckAddressSized<ErrorAction::Abort, AccessType::Load>(p, sz);\n+}\n+void __hwasan_load1(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Load, 0>(p);\n+}\n+void __hwasan_load2(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Load, 1>(p);\n+}\n+void __hwasan_load4(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Load, 2>(p);\n+}\n+void __hwasan_load8(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Load, 3>(p);\n+}\n+void __hwasan_load16(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Load, 4>(p);\n+}\n+\n+void __hwasan_loadN_noabort(uptr p, uptr sz) {\n+  CheckAddressSized<ErrorAction::Recover, AccessType::Load>(p, sz);\n+}\n+void __hwasan_load1_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Load, 0>(p);\n+}\n+void __hwasan_load2_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Load, 1>(p);\n+}\n+void __hwasan_load4_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Load, 2>(p);\n+}\n+void __hwasan_load8_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Load, 3>(p);\n+}\n+void __hwasan_load16_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Load, 4>(p);\n+}\n+\n+void __hwasan_storeN(uptr p, uptr sz) {\n+  CheckAddressSized<ErrorAction::Abort, AccessType::Store>(p, sz);\n+}\n+void __hwasan_store1(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Store, 0>(p);\n+}\n+void __hwasan_store2(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Store, 1>(p);\n+}\n+void __hwasan_store4(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Store, 2>(p);\n+}\n+void __hwasan_store8(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Store, 3>(p);\n+}\n+void __hwasan_store16(uptr p) {\n+  CheckAddress<ErrorAction::Abort, AccessType::Store, 4>(p);\n+}\n+\n+void __hwasan_storeN_noabort(uptr p, uptr sz) {\n+  CheckAddressSized<ErrorAction::Recover, AccessType::Store>(p, sz);\n+}\n+void __hwasan_store1_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Store, 0>(p);\n+}\n+void __hwasan_store2_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Store, 1>(p);\n+}\n+void __hwasan_store4_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Store, 2>(p);\n+}\n+void __hwasan_store8_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Store, 3>(p);\n+}\n+void __hwasan_store16_noabort(uptr p) {\n+  CheckAddress<ErrorAction::Recover, AccessType::Store, 4>(p);\n+}\n+\n+void __hwasan_tag_memory(uptr p, u8 tag, uptr sz) {\n+  TagMemoryAligned(p, sz, tag);\n+}\n+\n+uptr __hwasan_tag_pointer(uptr p, u8 tag) {\n+  return AddTagToPointer(p, tag);\n+}\n+\n+void __hwasan_handle_longjmp(const void *sp_dst) {\n+  uptr dst = (uptr)sp_dst;\n+  // HWASan does not support tagged SP.\n+  CHECK(GetTagFromPointer(dst) == 0);\n+\n+  uptr sp = (uptr)__builtin_frame_address(0);\n+  static const uptr kMaxExpectedCleanupSize = 64 << 20;  // 64M\n+  if (dst < sp || dst - sp > kMaxExpectedCleanupSize) {\n+    Report(\n+        \"WARNING: HWASan is ignoring requested __hwasan_handle_longjmp: \"\n+        \"stack top: %p; target %p; distance: %p (%zd)\\n\"\n+        \"False positive error reports may follow\\n\",\n+        (void *)sp, (void *)dst, dst - sp);\n+    return;\n+  }\n+  TagMemory(sp, dst - sp, 0);\n+}\n+\n+void __hwasan_handle_vfork(const void *sp_dst) {\n+  uptr sp = (uptr)sp_dst;\n+  Thread *t = GetCurrentThread();\n+  CHECK(t);\n+  uptr top = t->stack_top();\n+  uptr bottom = t->stack_bottom();\n+  if (top == 0 || bottom == 0 || sp < bottom || sp >= top) {\n+    Report(\n+        \"WARNING: HWASan is ignoring requested __hwasan_handle_vfork: \"\n+        \"stack top: %zx; current %zx; bottom: %zx \\n\"\n+        \"False positive error reports may follow\\n\",\n+        top, sp, bottom);\n+    return;\n+  }\n+  TagMemory(bottom, sp - bottom, 0);\n+}\n+\n+extern \"C\" void *__hwasan_extra_spill_area() {\n+  Thread *t = GetCurrentThread();\n+  return &t->vfork_spill();\n+}\n+\n+void __hwasan_print_memory_usage() {\n+  InternalScopedString s(kMemoryUsageBufferSize);\n+  HwasanFormatMemoryUsage(s);\n+  Printf(\"%s\\n\", s.data());\n+}\n+\n+static const u8 kFallbackTag = 0xBB;\n+\n+u8 __hwasan_generate_tag() {\n+  Thread *t = GetCurrentThread();\n+  if (!t) return kFallbackTag;\n+  return t->GenerateRandomTag();\n+}\n+\n+#if !SANITIZER_SUPPORTS_WEAK_HOOKS\n+extern \"C\" {\n+SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+const char* __hwasan_default_options() { return \"\"; }\n+}  // extern \"C\"\n+#endif\n+\n+extern \"C\" {\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_print_stack_trace() {\n+  GET_FATAL_STACK_TRACE_PC_BP(StackTrace::GetCurrentPc(), GET_CURRENT_FRAME());\n+  stack.Print();\n+}\n+} // extern \"C\""}, {"sha": "d4521efd089a7b2b4731334fe3849424d5642f31", "filename": "libsanitizer/hwasan/hwasan.h", "status": "added", "additions": 165, "deletions": 0, "changes": 165, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,165 @@\n+//===-- hwasan.h ------------------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// Private Hwasan header.\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_H\n+#define HWASAN_H\n+\n+#include \"sanitizer_common/sanitizer_flags.h\"\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+#include \"sanitizer_common/sanitizer_stacktrace.h\"\n+#include \"hwasan_interface_internal.h\"\n+#include \"hwasan_flags.h\"\n+#include \"ubsan/ubsan_platform.h\"\n+\n+#ifndef HWASAN_CONTAINS_UBSAN\n+# define HWASAN_CONTAINS_UBSAN CAN_SANITIZE_UB\n+#endif\n+\n+#ifndef HWASAN_WITH_INTERCEPTORS\n+#define HWASAN_WITH_INTERCEPTORS 0\n+#endif\n+\n+#ifndef HWASAN_REPLACE_OPERATORS_NEW_AND_DELETE\n+#define HWASAN_REPLACE_OPERATORS_NEW_AND_DELETE HWASAN_WITH_INTERCEPTORS\n+#endif\n+\n+typedef u8 tag_t;\n+\n+// TBI (Top Byte Ignore) feature of AArch64: bits [63:56] are ignored in address\n+// translation and can be used to store a tag.\n+const unsigned kAddressTagShift = 56;\n+const uptr kAddressTagMask = 0xFFUL << kAddressTagShift;\n+\n+// Minimal alignment of the shadow base address. Determines the space available\n+// for threads and stack histories. This is an ABI constant.\n+const unsigned kShadowBaseAlignment = 32;\n+\n+const unsigned kRecordAddrBaseTagShift = 3;\n+const unsigned kRecordFPShift = 48;\n+const unsigned kRecordFPLShift = 4;\n+const unsigned kRecordFPModulus = 1 << (64 - kRecordFPShift + kRecordFPLShift);\n+\n+static inline tag_t GetTagFromPointer(uptr p) {\n+  return p >> kAddressTagShift;\n+}\n+\n+static inline uptr UntagAddr(uptr tagged_addr) {\n+  return tagged_addr & ~kAddressTagMask;\n+}\n+\n+static inline void *UntagPtr(const void *tagged_ptr) {\n+  return reinterpret_cast<void *>(\n+      UntagAddr(reinterpret_cast<uptr>(tagged_ptr)));\n+}\n+\n+static inline uptr AddTagToPointer(uptr p, tag_t tag) {\n+  return (p & ~kAddressTagMask) | ((uptr)tag << kAddressTagShift);\n+}\n+\n+namespace __hwasan {\n+\n+extern int hwasan_inited;\n+extern bool hwasan_init_is_running;\n+extern int hwasan_report_count;\n+\n+bool InitShadow();\n+void InitPrctl();\n+void InitThreads();\n+void InitializeInterceptors();\n+\n+void HwasanAllocatorInit();\n+\n+void *hwasan_malloc(uptr size, StackTrace *stack);\n+void *hwasan_calloc(uptr nmemb, uptr size, StackTrace *stack);\n+void *hwasan_realloc(void *ptr, uptr size, StackTrace *stack);\n+void *hwasan_reallocarray(void *ptr, uptr nmemb, uptr size, StackTrace *stack);\n+void *hwasan_valloc(uptr size, StackTrace *stack);\n+void *hwasan_pvalloc(uptr size, StackTrace *stack);\n+void *hwasan_aligned_alloc(uptr alignment, uptr size, StackTrace *stack);\n+void *hwasan_memalign(uptr alignment, uptr size, StackTrace *stack);\n+int hwasan_posix_memalign(void **memptr, uptr alignment, uptr size,\n+                        StackTrace *stack);\n+void hwasan_free(void *ptr, StackTrace *stack);\n+\n+void InstallAtExitHandler();\n+\n+#define GET_MALLOC_STACK_TRACE                                            \\\n+  BufferedStackTrace stack;                                               \\\n+  if (hwasan_inited)                                                      \\\n+    stack.Unwind(StackTrace::GetCurrentPc(), GET_CURRENT_FRAME(),         \\\n+                 nullptr, common_flags()->fast_unwind_on_malloc,          \\\n+                 common_flags()->malloc_context_size)\n+\n+#define GET_FATAL_STACK_TRACE_PC_BP(pc, bp)              \\\n+  BufferedStackTrace stack;                              \\\n+  if (hwasan_inited)                                     \\\n+    stack.Unwind(pc, bp, nullptr, common_flags()->fast_unwind_on_fatal)\n+\n+#define GET_FATAL_STACK_TRACE_HERE \\\n+  GET_FATAL_STACK_TRACE_PC_BP(StackTrace::GetCurrentPc(), GET_CURRENT_FRAME())\n+\n+#define PRINT_CURRENT_STACK_CHECK() \\\n+  {                                 \\\n+    GET_FATAL_STACK_TRACE_HERE;     \\\n+    stack.Print();                  \\\n+  }\n+\n+void HwasanTSDInit();\n+void HwasanTSDThreadInit();\n+\n+void HwasanOnDeadlySignal(int signo, void *info, void *context);\n+\n+void UpdateMemoryUsage();\n+\n+void AppendToErrorMessageBuffer(const char *buffer);\n+\n+void AndroidTestTlsSlot();\n+\n+}  // namespace __hwasan\n+\n+#define HWASAN_MALLOC_HOOK(ptr, size)       \\\n+  do {                                    \\\n+    if (&__sanitizer_malloc_hook) {       \\\n+      __sanitizer_malloc_hook(ptr, size); \\\n+    }                                     \\\n+    RunMallocHooks(ptr, size);            \\\n+  } while (false)\n+#define HWASAN_FREE_HOOK(ptr)       \\\n+  do {                            \\\n+    if (&__sanitizer_free_hook) { \\\n+      __sanitizer_free_hook(ptr); \\\n+    }                             \\\n+    RunFreeHooks(ptr);            \\\n+  } while (false)\n+\n+#if HWASAN_WITH_INTERCEPTORS && defined(__aarch64__)\n+// For both bionic and glibc __sigset_t is an unsigned long.\n+typedef unsigned long __hw_sigset_t;\n+// Setjmp and longjmp implementations are platform specific, and hence the\n+// interception code is platform specific too.  As yet we've only implemented\n+// the interception for AArch64.\n+typedef unsigned long long __hw_register_buf[22];\n+struct __hw_jmp_buf_struct {\n+  // NOTE: The machine-dependent definition of `__sigsetjmp'\n+  // assume that a `__hw_jmp_buf' begins with a `__hw_register_buf' and that\n+  // `__mask_was_saved' follows it.  Do not move these members or add others\n+  // before it.\n+  __hw_register_buf __jmpbuf; // Calling environment.\n+  int __mask_was_saved;       // Saved the signal mask?\n+  __hw_sigset_t __saved_mask; // Saved signal mask.\n+};\n+typedef struct __hw_jmp_buf_struct __hw_jmp_buf[1];\n+typedef struct __hw_jmp_buf_struct __hw_sigjmp_buf[1];\n+#endif // HWASAN_WITH_INTERCEPTORS && __aarch64__\n+\n+#endif  // HWASAN_H"}, {"sha": "0b6b7347892ed3807c8c9087071bc818e6c956d8", "filename": "libsanitizer/hwasan/hwasan_allocator.cpp", "status": "added", "additions": 408, "deletions": 0, "changes": 408, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_allocator.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_allocator.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_allocator.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,408 @@\n+//===-- hwasan_allocator.cpp ------------------------ ---------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// HWAddressSanitizer allocator.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"sanitizer_common/sanitizer_atomic.h\"\n+#include \"sanitizer_common/sanitizer_errno.h\"\n+#include \"sanitizer_common/sanitizer_stackdepot.h\"\n+#include \"hwasan.h\"\n+#include \"hwasan_allocator.h\"\n+#include \"hwasan_checks.h\"\n+#include \"hwasan_mapping.h\"\n+#include \"hwasan_malloc_bisect.h\"\n+#include \"hwasan_thread.h\"\n+#include \"hwasan_report.h\"\n+\n+namespace __hwasan {\n+\n+static Allocator allocator;\n+static AllocatorCache fallback_allocator_cache;\n+static SpinMutex fallback_mutex;\n+static atomic_uint8_t hwasan_allocator_tagging_enabled;\n+\n+static const tag_t kFallbackAllocTag = 0xBB;\n+static const tag_t kFallbackFreeTag = 0xBC;\n+\n+enum RightAlignMode {\n+  kRightAlignNever,\n+  kRightAlignSometimes,\n+  kRightAlignAlways\n+};\n+\n+// Initialized in HwasanAllocatorInit, an never changed.\n+static ALIGNED(16) u8 tail_magic[kShadowAlignment - 1];\n+\n+bool HwasanChunkView::IsAllocated() const {\n+  return metadata_ && metadata_->alloc_context_id &&\n+         metadata_->get_requested_size();\n+}\n+\n+// Aligns the 'addr' right to the granule boundary.\n+static uptr AlignRight(uptr addr, uptr requested_size) {\n+  uptr tail_size = requested_size % kShadowAlignment;\n+  if (!tail_size) return addr;\n+  return addr + kShadowAlignment - tail_size;\n+}\n+\n+uptr HwasanChunkView::Beg() const {\n+  if (metadata_ && metadata_->right_aligned)\n+    return AlignRight(block_, metadata_->get_requested_size());\n+  return block_;\n+}\n+uptr HwasanChunkView::End() const {\n+  return Beg() + UsedSize();\n+}\n+uptr HwasanChunkView::UsedSize() const {\n+  return metadata_->get_requested_size();\n+}\n+u32 HwasanChunkView::GetAllocStackId() const {\n+  return metadata_->alloc_context_id;\n+}\n+\n+uptr HwasanChunkView::ActualSize() const {\n+  return allocator.GetActuallyAllocatedSize(reinterpret_cast<void *>(block_));\n+}\n+\n+bool HwasanChunkView::FromSmallHeap() const {\n+  return allocator.FromPrimary(reinterpret_cast<void *>(block_));\n+}\n+\n+void GetAllocatorStats(AllocatorStatCounters s) {\n+  allocator.GetStats(s);\n+}\n+\n+void HwasanAllocatorInit() {\n+  atomic_store_relaxed(&hwasan_allocator_tagging_enabled,\n+                       !flags()->disable_allocator_tagging);\n+  SetAllocatorMayReturnNull(common_flags()->allocator_may_return_null);\n+  allocator.Init(common_flags()->allocator_release_to_os_interval_ms);\n+  for (uptr i = 0; i < sizeof(tail_magic); i++)\n+    tail_magic[i] = GetCurrentThread()->GenerateRandomTag();\n+}\n+\n+void AllocatorSwallowThreadLocalCache(AllocatorCache *cache) {\n+  allocator.SwallowCache(cache);\n+}\n+\n+static uptr TaggedSize(uptr size) {\n+  if (!size) size = 1;\n+  uptr new_size = RoundUpTo(size, kShadowAlignment);\n+  CHECK_GE(new_size, size);\n+  return new_size;\n+}\n+\n+static void *HwasanAllocate(StackTrace *stack, uptr orig_size, uptr alignment,\n+                            bool zeroise) {\n+  if (orig_size > kMaxAllowedMallocSize) {\n+    if (AllocatorMayReturnNull()) {\n+      Report(\"WARNING: HWAddressSanitizer failed to allocate 0x%zx bytes\\n\",\n+             orig_size);\n+      return nullptr;\n+    }\n+    ReportAllocationSizeTooBig(orig_size, kMaxAllowedMallocSize, stack);\n+  }\n+\n+  alignment = Max(alignment, kShadowAlignment);\n+  uptr size = TaggedSize(orig_size);\n+  Thread *t = GetCurrentThread();\n+  void *allocated;\n+  if (t) {\n+    allocated = allocator.Allocate(t->allocator_cache(), size, alignment);\n+  } else {\n+    SpinMutexLock l(&fallback_mutex);\n+    AllocatorCache *cache = &fallback_allocator_cache;\n+    allocated = allocator.Allocate(cache, size, alignment);\n+  }\n+  if (UNLIKELY(!allocated)) {\n+    SetAllocatorOutOfMemory();\n+    if (AllocatorMayReturnNull())\n+      return nullptr;\n+    ReportOutOfMemory(size, stack);\n+  }\n+  Metadata *meta =\n+      reinterpret_cast<Metadata *>(allocator.GetMetaData(allocated));\n+  meta->set_requested_size(orig_size);\n+  meta->alloc_context_id = StackDepotPut(*stack);\n+  meta->right_aligned = false;\n+  if (zeroise) {\n+    internal_memset(allocated, 0, size);\n+  } else if (flags()->max_malloc_fill_size > 0) {\n+    uptr fill_size = Min(size, (uptr)flags()->max_malloc_fill_size);\n+    internal_memset(allocated, flags()->malloc_fill_byte, fill_size);\n+  }\n+  if (size != orig_size) {\n+    internal_memcpy(reinterpret_cast<u8 *>(allocated) + orig_size, tail_magic,\n+                    size - orig_size - 1);\n+  }\n+\n+  void *user_ptr = allocated;\n+  // Tagging can only be skipped when both tag_in_malloc and tag_in_free are\n+  // false. When tag_in_malloc = false and tag_in_free = true malloc needs to\n+  // retag to 0.\n+  if ((flags()->tag_in_malloc || flags()->tag_in_free) &&\n+      atomic_load_relaxed(&hwasan_allocator_tagging_enabled)) {\n+    if (flags()->tag_in_malloc && malloc_bisect(stack, orig_size)) {\n+      tag_t tag = t ? t->GenerateRandomTag() : kFallbackAllocTag;\n+      uptr tag_size = orig_size ? orig_size : 1;\n+      uptr full_granule_size = RoundDownTo(tag_size, kShadowAlignment);\n+      user_ptr =\n+          (void *)TagMemoryAligned((uptr)user_ptr, full_granule_size, tag);\n+      if (full_granule_size != tag_size) {\n+        u8 *short_granule =\n+            reinterpret_cast<u8 *>(allocated) + full_granule_size;\n+        TagMemoryAligned((uptr)short_granule, kShadowAlignment,\n+                         tag_size % kShadowAlignment);\n+        short_granule[kShadowAlignment - 1] = tag;\n+      }\n+    } else {\n+      user_ptr = (void *)TagMemoryAligned((uptr)user_ptr, size, 0);\n+    }\n+  }\n+\n+  HWASAN_MALLOC_HOOK(user_ptr, size);\n+  return user_ptr;\n+}\n+\n+static bool PointerAndMemoryTagsMatch(void *tagged_ptr) {\n+  CHECK(tagged_ptr);\n+  uptr tagged_uptr = reinterpret_cast<uptr>(tagged_ptr);\n+  tag_t mem_tag = *reinterpret_cast<tag_t *>(\n+      MemToShadow(reinterpret_cast<uptr>(UntagPtr(tagged_ptr))));\n+  return PossiblyShortTagMatches(mem_tag, tagged_uptr, 1);\n+}\n+\n+static void HwasanDeallocate(StackTrace *stack, void *tagged_ptr) {\n+  CHECK(tagged_ptr);\n+  HWASAN_FREE_HOOK(tagged_ptr);\n+\n+  if (!PointerAndMemoryTagsMatch(tagged_ptr))\n+    ReportInvalidFree(stack, reinterpret_cast<uptr>(tagged_ptr));\n+\n+  void *untagged_ptr = UntagPtr(tagged_ptr);\n+  void *aligned_ptr = reinterpret_cast<void *>(\n+      RoundDownTo(reinterpret_cast<uptr>(untagged_ptr), kShadowAlignment));\n+  Metadata *meta =\n+      reinterpret_cast<Metadata *>(allocator.GetMetaData(aligned_ptr));\n+  uptr orig_size = meta->get_requested_size();\n+  u32 free_context_id = StackDepotPut(*stack);\n+  u32 alloc_context_id = meta->alloc_context_id;\n+\n+  // Check tail magic.\n+  uptr tagged_size = TaggedSize(orig_size);\n+  if (flags()->free_checks_tail_magic && orig_size &&\n+      tagged_size != orig_size) {\n+    uptr tail_size = tagged_size - orig_size - 1;\n+    CHECK_LT(tail_size, kShadowAlignment);\n+    void *tail_beg = reinterpret_cast<void *>(\n+        reinterpret_cast<uptr>(aligned_ptr) + orig_size);\n+    if (tail_size && internal_memcmp(tail_beg, tail_magic, tail_size))\n+      ReportTailOverwritten(stack, reinterpret_cast<uptr>(tagged_ptr),\n+                            orig_size, tail_magic);\n+  }\n+\n+  meta->set_requested_size(0);\n+  meta->alloc_context_id = 0;\n+  // This memory will not be reused by anyone else, so we are free to keep it\n+  // poisoned.\n+  Thread *t = GetCurrentThread();\n+  if (flags()->max_free_fill_size > 0) {\n+    uptr fill_size =\n+        Min(TaggedSize(orig_size), (uptr)flags()->max_free_fill_size);\n+    internal_memset(aligned_ptr, flags()->free_fill_byte, fill_size);\n+  }\n+  if (flags()->tag_in_free && malloc_bisect(stack, 0) &&\n+      atomic_load_relaxed(&hwasan_allocator_tagging_enabled))\n+    TagMemoryAligned(reinterpret_cast<uptr>(aligned_ptr), TaggedSize(orig_size),\n+                     t ? t->GenerateRandomTag() : kFallbackFreeTag);\n+  if (t) {\n+    allocator.Deallocate(t->allocator_cache(), aligned_ptr);\n+    if (auto *ha = t->heap_allocations())\n+      ha->push({reinterpret_cast<uptr>(tagged_ptr), alloc_context_id,\n+                free_context_id, static_cast<u32>(orig_size)});\n+  } else {\n+    SpinMutexLock l(&fallback_mutex);\n+    AllocatorCache *cache = &fallback_allocator_cache;\n+    allocator.Deallocate(cache, aligned_ptr);\n+  }\n+}\n+\n+static void *HwasanReallocate(StackTrace *stack, void *tagged_ptr_old,\n+                              uptr new_size, uptr alignment) {\n+  if (!PointerAndMemoryTagsMatch(tagged_ptr_old))\n+    ReportInvalidFree(stack, reinterpret_cast<uptr>(tagged_ptr_old));\n+\n+  void *tagged_ptr_new =\n+      HwasanAllocate(stack, new_size, alignment, false /*zeroise*/);\n+  if (tagged_ptr_old && tagged_ptr_new) {\n+    void *untagged_ptr_old =  UntagPtr(tagged_ptr_old);\n+    Metadata *meta =\n+        reinterpret_cast<Metadata *>(allocator.GetMetaData(untagged_ptr_old));\n+    internal_memcpy(\n+        UntagPtr(tagged_ptr_new), untagged_ptr_old,\n+        Min(new_size, static_cast<uptr>(meta->get_requested_size())));\n+    HwasanDeallocate(stack, tagged_ptr_old);\n+  }\n+  return tagged_ptr_new;\n+}\n+\n+static void *HwasanCalloc(StackTrace *stack, uptr nmemb, uptr size) {\n+  if (UNLIKELY(CheckForCallocOverflow(size, nmemb))) {\n+    if (AllocatorMayReturnNull())\n+      return nullptr;\n+    ReportCallocOverflow(nmemb, size, stack);\n+  }\n+  return HwasanAllocate(stack, nmemb * size, sizeof(u64), true);\n+}\n+\n+HwasanChunkView FindHeapChunkByAddress(uptr address) {\n+  void *block = allocator.GetBlockBegin(reinterpret_cast<void*>(address));\n+  if (!block)\n+    return HwasanChunkView();\n+  Metadata *metadata =\n+      reinterpret_cast<Metadata*>(allocator.GetMetaData(block));\n+  return HwasanChunkView(reinterpret_cast<uptr>(block), metadata);\n+}\n+\n+static uptr AllocationSize(const void *tagged_ptr) {\n+  const void *untagged_ptr = UntagPtr(tagged_ptr);\n+  if (!untagged_ptr) return 0;\n+  const void *beg = allocator.GetBlockBegin(untagged_ptr);\n+  Metadata *b = (Metadata *)allocator.GetMetaData(untagged_ptr);\n+  if (b->right_aligned) {\n+    if (beg != reinterpret_cast<void *>(RoundDownTo(\n+                   reinterpret_cast<uptr>(untagged_ptr), kShadowAlignment)))\n+      return 0;\n+  } else {\n+    if (beg != untagged_ptr) return 0;\n+  }\n+  return b->get_requested_size();\n+}\n+\n+void *hwasan_malloc(uptr size, StackTrace *stack) {\n+  return SetErrnoOnNull(HwasanAllocate(stack, size, sizeof(u64), false));\n+}\n+\n+void *hwasan_calloc(uptr nmemb, uptr size, StackTrace *stack) {\n+  return SetErrnoOnNull(HwasanCalloc(stack, nmemb, size));\n+}\n+\n+void *hwasan_realloc(void *ptr, uptr size, StackTrace *stack) {\n+  if (!ptr)\n+    return SetErrnoOnNull(HwasanAllocate(stack, size, sizeof(u64), false));\n+  if (size == 0) {\n+    HwasanDeallocate(stack, ptr);\n+    return nullptr;\n+  }\n+  return SetErrnoOnNull(HwasanReallocate(stack, ptr, size, sizeof(u64)));\n+}\n+\n+void *hwasan_reallocarray(void *ptr, uptr nmemb, uptr size, StackTrace *stack) {\n+  if (UNLIKELY(CheckForCallocOverflow(size, nmemb))) {\n+    errno = errno_ENOMEM;\n+    if (AllocatorMayReturnNull())\n+      return nullptr;\n+    ReportReallocArrayOverflow(nmemb, size, stack);\n+  }\n+  return hwasan_realloc(ptr, nmemb * size, stack);\n+}\n+\n+void *hwasan_valloc(uptr size, StackTrace *stack) {\n+  return SetErrnoOnNull(\n+      HwasanAllocate(stack, size, GetPageSizeCached(), false));\n+}\n+\n+void *hwasan_pvalloc(uptr size, StackTrace *stack) {\n+  uptr PageSize = GetPageSizeCached();\n+  if (UNLIKELY(CheckForPvallocOverflow(size, PageSize))) {\n+    errno = errno_ENOMEM;\n+    if (AllocatorMayReturnNull())\n+      return nullptr;\n+    ReportPvallocOverflow(size, stack);\n+  }\n+  // pvalloc(0) should allocate one page.\n+  size = size ? RoundUpTo(size, PageSize) : PageSize;\n+  return SetErrnoOnNull(HwasanAllocate(stack, size, PageSize, false));\n+}\n+\n+void *hwasan_aligned_alloc(uptr alignment, uptr size, StackTrace *stack) {\n+  if (UNLIKELY(!CheckAlignedAllocAlignmentAndSize(alignment, size))) {\n+    errno = errno_EINVAL;\n+    if (AllocatorMayReturnNull())\n+      return nullptr;\n+    ReportInvalidAlignedAllocAlignment(size, alignment, stack);\n+  }\n+  return SetErrnoOnNull(HwasanAllocate(stack, size, alignment, false));\n+}\n+\n+void *hwasan_memalign(uptr alignment, uptr size, StackTrace *stack) {\n+  if (UNLIKELY(!IsPowerOfTwo(alignment))) {\n+    errno = errno_EINVAL;\n+    if (AllocatorMayReturnNull())\n+      return nullptr;\n+    ReportInvalidAllocationAlignment(alignment, stack);\n+  }\n+  return SetErrnoOnNull(HwasanAllocate(stack, size, alignment, false));\n+}\n+\n+int hwasan_posix_memalign(void **memptr, uptr alignment, uptr size,\n+                        StackTrace *stack) {\n+  if (UNLIKELY(!CheckPosixMemalignAlignment(alignment))) {\n+    if (AllocatorMayReturnNull())\n+      return errno_EINVAL;\n+    ReportInvalidPosixMemalignAlignment(alignment, stack);\n+  }\n+  void *ptr = HwasanAllocate(stack, size, alignment, false);\n+  if (UNLIKELY(!ptr))\n+    // OOM error is already taken care of by HwasanAllocate.\n+    return errno_ENOMEM;\n+  CHECK(IsAligned((uptr)ptr, alignment));\n+  *(void **)UntagPtr(memptr) = ptr;\n+  return 0;\n+}\n+\n+void hwasan_free(void *ptr, StackTrace *stack) {\n+  return HwasanDeallocate(stack, ptr);\n+}\n+\n+}  // namespace __hwasan\n+\n+using namespace __hwasan;\n+\n+void __hwasan_enable_allocator_tagging() {\n+  atomic_store_relaxed(&hwasan_allocator_tagging_enabled, 1);\n+}\n+\n+void __hwasan_disable_allocator_tagging() {\n+  atomic_store_relaxed(&hwasan_allocator_tagging_enabled, 0);\n+}\n+\n+uptr __sanitizer_get_current_allocated_bytes() {\n+  uptr stats[AllocatorStatCount];\n+  allocator.GetStats(stats);\n+  return stats[AllocatorStatAllocated];\n+}\n+\n+uptr __sanitizer_get_heap_size() {\n+  uptr stats[AllocatorStatCount];\n+  allocator.GetStats(stats);\n+  return stats[AllocatorStatMapped];\n+}\n+\n+uptr __sanitizer_get_free_bytes() { return 1; }\n+\n+uptr __sanitizer_get_unmapped_bytes() { return 1; }\n+\n+uptr __sanitizer_get_estimated_allocated_size(uptr size) { return size; }\n+\n+int __sanitizer_get_ownership(const void *p) { return AllocationSize(p) != 0; }\n+\n+uptr __sanitizer_get_allocated_size(const void *p) { return AllocationSize(p); }"}, {"sha": "43670a6a3fb7eb5eefec3367f1df00f353e0ad3e", "filename": "libsanitizer/hwasan/hwasan_allocator.h", "status": "added", "additions": 107, "deletions": 0, "changes": 107, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_allocator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_allocator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_allocator.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,107 @@\n+//===-- hwasan_allocator.h --------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_ALLOCATOR_H\n+#define HWASAN_ALLOCATOR_H\n+\n+#include \"sanitizer_common/sanitizer_allocator.h\"\n+#include \"sanitizer_common/sanitizer_allocator_checks.h\"\n+#include \"sanitizer_common/sanitizer_allocator_interface.h\"\n+#include \"sanitizer_common/sanitizer_allocator_report.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_ring_buffer.h\"\n+#include \"hwasan_poisoning.h\"\n+\n+#if !defined(__aarch64__) && !defined(__x86_64__)\n+#error Unsupported platform\n+#endif\n+\n+namespace __hwasan {\n+\n+struct Metadata {\n+  u32 requested_size_low;\n+  u32 requested_size_high : 31;\n+  u32 right_aligned : 1;\n+  u32 alloc_context_id;\n+  u64 get_requested_size() {\n+    return (static_cast<u64>(requested_size_high) << 32) + requested_size_low;\n+  }\n+  void set_requested_size(u64 size) {\n+    requested_size_low = size & ((1ul << 32) - 1);\n+    requested_size_high = size >> 32;\n+  }\n+};\n+\n+struct HwasanMapUnmapCallback {\n+  void OnMap(uptr p, uptr size) const { UpdateMemoryUsage(); }\n+  void OnUnmap(uptr p, uptr size) const {\n+    // We are about to unmap a chunk of user memory.\n+    // It can return as user-requested mmap() or another thread stack.\n+    // Make it accessible with zero-tagged pointer.\n+    TagMemory(p, size, 0);\n+  }\n+};\n+\n+static const uptr kMaxAllowedMallocSize = 1UL << 40;  // 1T\n+\n+struct AP64 {\n+  static const uptr kSpaceBeg = ~0ULL;\n+  static const uptr kSpaceSize = 0x2000000000ULL;\n+  static const uptr kMetadataSize = sizeof(Metadata);\n+  typedef __sanitizer::VeryDenseSizeClassMap SizeClassMap;\n+  using AddressSpaceView = LocalAddressSpaceView;\n+  typedef HwasanMapUnmapCallback MapUnmapCallback;\n+  static const uptr kFlags = 0;\n+};\n+typedef SizeClassAllocator64<AP64> PrimaryAllocator;\n+typedef CombinedAllocator<PrimaryAllocator> Allocator;\n+typedef Allocator::AllocatorCache AllocatorCache;\n+\n+void AllocatorSwallowThreadLocalCache(AllocatorCache *cache);\n+\n+class HwasanChunkView {\n+ public:\n+  HwasanChunkView() : block_(0), metadata_(nullptr) {}\n+  HwasanChunkView(uptr block, Metadata *metadata)\n+      : block_(block), metadata_(metadata) {}\n+  bool IsAllocated() const;    // Checks if the memory is currently allocated\n+  uptr Beg() const;            // First byte of user memory\n+  uptr End() const;            // Last byte of user memory\n+  uptr UsedSize() const;       // Size requested by the user\n+  uptr ActualSize() const;     // Size allocated by the allocator.\n+  u32 GetAllocStackId() const;\n+  bool FromSmallHeap() const;\n+ private:\n+  uptr block_;\n+  Metadata *const metadata_;\n+};\n+\n+HwasanChunkView FindHeapChunkByAddress(uptr address);\n+\n+// Information about one (de)allocation that happened in the past.\n+// These are recorded in a thread-local ring buffer.\n+// TODO: this is currently 24 bytes (20 bytes + alignment).\n+// Compress it to 16 bytes or extend it to be more useful.\n+struct HeapAllocationRecord {\n+  uptr tagged_addr;\n+  u32  alloc_context_id;\n+  u32  free_context_id;\n+  u32  requested_size;\n+};\n+\n+typedef RingBuffer<HeapAllocationRecord> HeapAllocationsRingBuffer;\n+\n+void GetAllocatorStats(AllocatorStatCounters s);\n+\n+} // namespace __hwasan\n+\n+#endif // HWASAN_ALLOCATOR_H"}, {"sha": "a8de0fef20f0bd8522e02e05c9d2f11c38f3b2f5", "filename": "libsanitizer/hwasan/hwasan_checks.h", "status": "added", "additions": 124, "deletions": 0, "changes": 124, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_checks.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_checks.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_checks.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,124 @@\n+//===-- hwasan_checks.h -----------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_CHECKS_H\n+#define HWASAN_CHECKS_H\n+\n+#include \"hwasan_mapping.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+\n+namespace __hwasan {\n+template <unsigned X>\n+__attribute__((always_inline)) static void SigTrap(uptr p) {\n+#if defined(__aarch64__)\n+  (void)p;\n+  // 0x900 is added to do not interfere with the kernel use of lower values of\n+  // brk immediate.\n+  register uptr x0 asm(\"x0\") = p;\n+  asm(\"brk %1\\n\\t\" ::\"r\"(x0), \"n\"(0x900 + X));\n+#elif defined(__x86_64__)\n+  // INT3 + NOP DWORD ptr [EAX + X] to pass X to our signal handler, 5 bytes\n+  // total. The pointer is passed via rdi.\n+  // 0x40 is added as a safeguard, to help distinguish our trap from others and\n+  // to avoid 0 offsets in the command (otherwise it'll be reduced to a\n+  // different nop command, the three bytes one).\n+  asm volatile(\n+      \"int3\\n\"\n+      \"nopl %c0(%%rax)\\n\" ::\"n\"(0x40 + X),\n+      \"D\"(p));\n+#else\n+  // FIXME: not always sigill.\n+  __builtin_trap();\n+#endif\n+  // __builtin_unreachable();\n+}\n+\n+// Version with access size which is not power of 2\n+template <unsigned X>\n+__attribute__((always_inline)) static void SigTrap(uptr p, uptr size) {\n+#if defined(__aarch64__)\n+  register uptr x0 asm(\"x0\") = p;\n+  register uptr x1 asm(\"x1\") = size;\n+  asm(\"brk %2\\n\\t\" ::\"r\"(x0), \"r\"(x1), \"n\"(0x900 + X));\n+#elif defined(__x86_64__)\n+  // Size is stored in rsi.\n+  asm volatile(\n+      \"int3\\n\"\n+      \"nopl %c0(%%rax)\\n\" ::\"n\"(0x40 + X),\n+      \"D\"(p), \"S\"(size));\n+#else\n+  __builtin_trap();\n+#endif\n+  // __builtin_unreachable();\n+}\n+\n+__attribute__((always_inline, nodebug)) static bool PossiblyShortTagMatches(\n+    tag_t mem_tag, uptr ptr, uptr sz) {\n+  tag_t ptr_tag = GetTagFromPointer(ptr);\n+  if (ptr_tag == mem_tag)\n+    return true;\n+  if (mem_tag >= kShadowAlignment)\n+    return false;\n+  if ((ptr & (kShadowAlignment - 1)) + sz > mem_tag)\n+    return false;\n+#ifndef __aarch64__\n+  ptr = UntagAddr(ptr);\n+#endif\n+  return *(u8 *)(ptr | (kShadowAlignment - 1)) == ptr_tag;\n+}\n+\n+enum class ErrorAction { Abort, Recover };\n+enum class AccessType { Load, Store };\n+\n+template <ErrorAction EA, AccessType AT, unsigned LogSize>\n+__attribute__((always_inline, nodebug)) static void CheckAddress(uptr p) {\n+  uptr ptr_raw = p & ~kAddressTagMask;\n+  tag_t mem_tag = *(tag_t *)MemToShadow(ptr_raw);\n+  if (UNLIKELY(!PossiblyShortTagMatches(mem_tag, p, 1 << LogSize))) {\n+    SigTrap<0x20 * (EA == ErrorAction::Recover) +\n+            0x10 * (AT == AccessType::Store) + LogSize>(p);\n+    if (EA == ErrorAction::Abort)\n+      __builtin_unreachable();\n+  }\n+}\n+\n+template <ErrorAction EA, AccessType AT>\n+__attribute__((always_inline, nodebug)) static void CheckAddressSized(uptr p,\n+                                                                      uptr sz) {\n+  if (sz == 0)\n+    return;\n+  tag_t ptr_tag = GetTagFromPointer(p);\n+  uptr ptr_raw = p & ~kAddressTagMask;\n+  tag_t *shadow_first = (tag_t *)MemToShadow(ptr_raw);\n+  tag_t *shadow_last = (tag_t *)MemToShadow(ptr_raw + sz);\n+  for (tag_t *t = shadow_first; t < shadow_last; ++t)\n+    if (UNLIKELY(ptr_tag != *t)) {\n+      SigTrap<0x20 * (EA == ErrorAction::Recover) +\n+              0x10 * (AT == AccessType::Store) + 0xf>(p, sz);\n+      if (EA == ErrorAction::Abort)\n+        __builtin_unreachable();\n+    }\n+  uptr end = p + sz;\n+  uptr tail_sz = end & 0xf;\n+  if (UNLIKELY(tail_sz != 0 &&\n+               !PossiblyShortTagMatches(\n+                   *shadow_last, end & ~(kShadowAlignment - 1), tail_sz))) {\n+    SigTrap<0x20 * (EA == ErrorAction::Recover) +\n+            0x10 * (AT == AccessType::Store) + 0xf>(p, sz);\n+    if (EA == ErrorAction::Abort)\n+      __builtin_unreachable();\n+  }\n+}\n+\n+}  // end namespace __hwasan\n+\n+#endif  // HWASAN_CHECKS_H"}, {"sha": "12730b29bae3675a22b08749c2664ca0e59e1da3", "filename": "libsanitizer/hwasan/hwasan_dynamic_shadow.cpp", "status": "added", "additions": 126, "deletions": 0, "changes": 126, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,126 @@\n+//===-- hwasan_dynamic_shadow.cpp -------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+///\n+/// \\file\n+/// This file is a part of HWAddressSanitizer. It reserves dynamic shadow memory\n+/// region and handles ifunc resolver case, when necessary.\n+///\n+//===----------------------------------------------------------------------===//\n+\n+#include \"hwasan.h\"\n+#include \"hwasan_dynamic_shadow.h\"\n+#include \"hwasan_mapping.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_posix.h\"\n+\n+#include <elf.h>\n+#include <link.h>\n+\n+// The code in this file needs to run in an unrelocated binary. It should not\n+// access any external symbol, including its own non-hidden globals.\n+\n+#if SANITIZER_ANDROID\n+extern \"C\" {\n+\n+INTERFACE_ATTRIBUTE void __hwasan_shadow();\n+decltype(__hwasan_shadow)* __hwasan_premap_shadow();\n+\n+}  // extern \"C\"\n+\n+namespace __hwasan {\n+\n+// Conservative upper limit.\n+static uptr PremapShadowSize() {\n+  return RoundUpTo(GetMaxVirtualAddress() >> kShadowScale,\n+                   GetMmapGranularity());\n+}\n+\n+static uptr PremapShadow() {\n+  return MapDynamicShadow(PremapShadowSize(), kShadowScale,\n+                          kShadowBaseAlignment, kHighMemEnd);\n+}\n+\n+static bool IsPremapShadowAvailable() {\n+  const uptr shadow = reinterpret_cast<uptr>(&__hwasan_shadow);\n+  const uptr resolver = reinterpret_cast<uptr>(&__hwasan_premap_shadow);\n+  // shadow == resolver is how Android KitKat and older handles ifunc.\n+  // shadow == 0 just in case.\n+  return shadow != 0 && shadow != resolver;\n+}\n+\n+static uptr FindPremappedShadowStart(uptr shadow_size_bytes) {\n+  const uptr granularity = GetMmapGranularity();\n+  const uptr shadow_start = reinterpret_cast<uptr>(&__hwasan_shadow);\n+  const uptr premap_shadow_size = PremapShadowSize();\n+  const uptr shadow_size = RoundUpTo(shadow_size_bytes, granularity);\n+\n+  // We may have mapped too much. Release extra memory.\n+  UnmapFromTo(shadow_start + shadow_size, shadow_start + premap_shadow_size);\n+  return shadow_start;\n+}\n+\n+}  // namespace __hwasan\n+\n+extern \"C\" {\n+\n+decltype(__hwasan_shadow)* __hwasan_premap_shadow() {\n+  // The resolver might be called multiple times. Map the shadow just once.\n+  static __sanitizer::uptr shadow = 0;\n+  if (!shadow)\n+    shadow = __hwasan::PremapShadow();\n+  return reinterpret_cast<decltype(__hwasan_shadow)*>(shadow);\n+}\n+\n+// __hwasan_shadow is a \"function\" that has the same address as the first byte\n+// of the shadow mapping.\n+INTERFACE_ATTRIBUTE __attribute__((ifunc(\"__hwasan_premap_shadow\")))\n+void __hwasan_shadow();\n+\n+extern __attribute((weak, visibility(\"hidden\"))) ElfW(Rela) __rela_iplt_start[],\n+    __rela_iplt_end[];\n+\n+}  // extern \"C\"\n+\n+namespace __hwasan {\n+\n+void InitShadowGOT() {\n+  // Call the ifunc resolver for __hwasan_shadow and fill in its GOT entry. This\n+  // needs to be done before other ifunc resolvers (which are handled by libc)\n+  // because a resolver might read __hwasan_shadow.\n+  typedef ElfW(Addr) (*ifunc_resolver_t)(void);\n+  for (ElfW(Rela) *r = __rela_iplt_start; r != __rela_iplt_end; ++r) {\n+    ElfW(Addr)* offset = reinterpret_cast<ElfW(Addr)*>(r->r_offset);\n+    ElfW(Addr) resolver = r->r_addend;\n+    if (resolver == reinterpret_cast<ElfW(Addr)>(&__hwasan_premap_shadow)) {\n+      *offset = reinterpret_cast<ifunc_resolver_t>(resolver)();\n+      break;\n+    }\n+  }\n+}\n+\n+uptr FindDynamicShadowStart(uptr shadow_size_bytes) {\n+  if (IsPremapShadowAvailable())\n+    return FindPremappedShadowStart(shadow_size_bytes);\n+  return MapDynamicShadow(shadow_size_bytes, kShadowScale, kShadowBaseAlignment,\n+                          kHighMemEnd);\n+}\n+\n+}  // namespace __hwasan\n+#else\n+namespace __hwasan {\n+\n+void InitShadowGOT() {}\n+\n+uptr FindDynamicShadowStart(uptr shadow_size_bytes) {\n+  return MapDynamicShadow(shadow_size_bytes, kShadowScale, kShadowBaseAlignment,\n+                          kHighMemEnd);\n+}\n+\n+}  // namespace __hwasan\n+\n+#endif  // SANITIZER_ANDROID"}, {"sha": "3c2e7c716a3465e117255e93841f734e07198e5a", "filename": "libsanitizer/hwasan/hwasan_dynamic_shadow.h", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,27 @@\n+//===-- hwasan_dynamic_shadow.h ---------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+///\n+/// \\file\n+/// This file is a part of HWAddressSanitizer. It reserves dynamic shadow memory\n+/// region.\n+///\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_PREMAP_SHADOW_H\n+#define HWASAN_PREMAP_SHADOW_H\n+\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+\n+namespace __hwasan {\n+\n+uptr FindDynamicShadowStart(uptr shadow_size_bytes);\n+void InitShadowGOT();\n+\n+}  // namespace __hwasan\n+\n+#endif  // HWASAN_PREMAP_SHADOW_H"}, {"sha": "169e7876cb58a9dafb70973ed9fb1dfd815a7ceb", "filename": "libsanitizer/hwasan/hwasan_exceptions.cpp", "status": "added", "additions": 67, "deletions": 0, "changes": 67, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_exceptions.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_exceptions.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_exceptions.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,67 @@\n+//===-- hwasan_exceptions.cpp ---------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// HWAddressSanitizer runtime.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"hwasan_poisoning.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+\n+#include <unwind.h>\n+\n+using namespace __hwasan;\n+using namespace __sanitizer;\n+\n+typedef _Unwind_Reason_Code PersonalityFn(int version, _Unwind_Action actions,\n+                                          uint64_t exception_class,\n+                                          _Unwind_Exception* unwind_exception,\n+                                          _Unwind_Context* context);\n+\n+// Pointers to the _Unwind_GetGR and _Unwind_GetCFA functions are passed in\n+// instead of being called directly. This is to handle cases where the unwinder\n+// is statically linked and the sanitizer runtime and the program are linked\n+// against different unwinders. The _Unwind_Context data structure is opaque so\n+// it may be incompatible between unwinders.\n+typedef _Unwind_Word GetGRFn(_Unwind_Context* context, int index);\n+typedef _Unwind_Word GetCFAFn(_Unwind_Context* context);\n+\n+extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE _Unwind_Reason_Code\n+__hwasan_personality_wrapper(int version, _Unwind_Action actions,\n+                             uint64_t exception_class,\n+                             _Unwind_Exception* unwind_exception,\n+                             _Unwind_Context* context,\n+                             PersonalityFn* real_personality, GetGRFn* get_gr,\n+                             GetCFAFn* get_cfa) {\n+  _Unwind_Reason_Code rc;\n+  if (real_personality)\n+    rc = real_personality(version, actions, exception_class, unwind_exception,\n+                          context);\n+  else\n+    rc = _URC_CONTINUE_UNWIND;\n+\n+  // We only untag frames without a landing pad because landing pads are\n+  // responsible for untagging the stack themselves if they resume.\n+  //\n+  // Here we assume that the frame record appears after any locals. This is not\n+  // required by AAPCS but is a requirement for HWASAN instrumented functions.\n+  if ((actions & _UA_CLEANUP_PHASE) && rc == _URC_CONTINUE_UNWIND) {\n+#if defined(__x86_64__)\n+    uptr fp = get_gr(context, 6); // rbp\n+#elif defined(__aarch64__)\n+    uptr fp = get_gr(context, 29); // x29\n+#else\n+#error Unsupported architecture\n+#endif\n+    uptr sp = get_cfa(context);\n+    TagMemory(sp, fp - sp, 0);\n+  }\n+\n+  return rc;\n+}"}, {"sha": "0a6998f675d69b0c75b6b5cab207f59d1c41ab32", "filename": "libsanitizer/hwasan/hwasan_flags.h", "status": "added", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_flags.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_flags.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_flags.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,29 @@\n+//===-- hwasan_flags.h ------------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+#ifndef HWASAN_FLAGS_H\n+#define HWASAN_FLAGS_H\n+\n+namespace __hwasan {\n+\n+struct Flags {\n+#define HWASAN_FLAG(Type, Name, DefaultValue, Description) Type Name;\n+#include \"hwasan_flags.inc\"\n+#undef HWASAN_FLAG\n+\n+  void SetDefaults();\n+};\n+\n+Flags *flags();\n+\n+}  // namespace __hwasan\n+\n+#endif  // HWASAN_FLAGS_H"}, {"sha": "8e431d9c4ff94f9551f471bf50c09c73df0082e1", "filename": "libsanitizer/hwasan/hwasan_flags.inc", "status": "added", "additions": 74, "deletions": 0, "changes": 74, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_flags.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_flags.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_flags.inc?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,74 @@\n+//===-- hwasan_flags.inc ----------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// Hwasan runtime flags.\n+//\n+//===----------------------------------------------------------------------===//\n+#ifndef HWASAN_FLAG\n+# error \"Define HWASAN_FLAG prior to including this file!\"\n+#endif\n+\n+// HWASAN_FLAG(Type, Name, DefaultValue, Description)\n+// See COMMON_FLAG in sanitizer_flags.inc for more details.\n+\n+HWASAN_FLAG(bool, verbose_threads, false,\n+            \"inform on thread creation/destruction\")\n+HWASAN_FLAG(bool, tag_in_malloc, true, \"\")\n+HWASAN_FLAG(bool, tag_in_free, true, \"\")\n+HWASAN_FLAG(bool, print_stats, false, \"\")\n+HWASAN_FLAG(bool, halt_on_error, true, \"\")\n+HWASAN_FLAG(bool, atexit, false, \"\")\n+\n+// Test only flag to disable malloc/realloc/free memory tagging on startup.\n+// Tagging can be reenabled with __hwasan_enable_allocator_tagging().\n+HWASAN_FLAG(bool, disable_allocator_tagging, false, \"\")\n+\n+// If false, use simple increment of a thread local counter to generate new\n+// tags.\n+HWASAN_FLAG(bool, random_tags, true, \"\")\n+\n+HWASAN_FLAG(\n+    int, max_malloc_fill_size, 0,\n+    \"HWASan allocator flag. max_malloc_fill_size is the maximal amount of \"\n+    \"bytes that will be filled with malloc_fill_byte on malloc.\")\n+\n+HWASAN_FLAG(bool, free_checks_tail_magic, 1,\n+    \"If set, free() will check the magic values \"\n+    \"to the right of the allocated object \"\n+    \"if the allocation size is not a divident of the granule size\")\n+HWASAN_FLAG(\n+    int, max_free_fill_size, 0,\n+    \"HWASan allocator flag. max_free_fill_size is the maximal amount of \"\n+    \"bytes that will be filled with free_fill_byte during free.\")\n+HWASAN_FLAG(int, malloc_fill_byte, 0xbe,\n+          \"Value used to fill the newly allocated memory.\")\n+HWASAN_FLAG(int, free_fill_byte, 0x55,\n+          \"Value used to fill deallocated memory.\")\n+HWASAN_FLAG(int, heap_history_size, 1023,\n+          \"The number of heap (de)allocations remembered per thread. \"\n+          \"Affects the quality of heap-related reports, but not the ability \"\n+          \"to find bugs.\")\n+HWASAN_FLAG(bool, export_memory_stats, true,\n+            \"Export up-to-date memory stats through /proc\")\n+HWASAN_FLAG(int, stack_history_size, 1024,\n+            \"The number of stack frames remembered per thread. \"\n+            \"Affects the quality of stack-related reports, but not the ability \"\n+            \"to find bugs.\")\n+\n+// Malloc / free bisection. Only tag malloc and free calls when a hash of\n+// allocation size and stack trace is between malloc_bisect_left and\n+// malloc_bisect_right (both inclusive). [0, 0] range is special and disables\n+// bisection (i.e. everything is tagged). Once the range is narrowed down\n+// enough, use malloc_bisect_dump to see interesting allocations.\n+HWASAN_FLAG(uptr, malloc_bisect_left, 0,\n+            \"Left bound of malloc bisection, inclusive.\")\n+HWASAN_FLAG(uptr, malloc_bisect_right, 0,\n+            \"Right bound of malloc bisection, inclusive.\")\n+HWASAN_FLAG(bool, malloc_bisect_dump, false,\n+            \"Print all allocations within [malloc_bisect_left, \"\n+            \"malloc_bisect_right] range \")"}, {"sha": "d71bcd792e1f9a9b03cffb55a45c4bad32bf9c99", "filename": "libsanitizer/hwasan/hwasan_globals.cpp", "status": "added", "additions": 91, "deletions": 0, "changes": 91, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_globals.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_globals.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_globals.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,91 @@\n+//===-- hwasan_globals.cpp ------------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// HWAddressSanitizer globals-specific runtime.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"hwasan_globals.h\"\n+\n+namespace __hwasan {\n+\n+enum { NT_LLVM_HWASAN_GLOBALS = 3 };\n+struct hwasan_global_note {\n+  s32 begin_relptr;\n+  s32 end_relptr;\n+};\n+\n+// Check that the given library meets the code model requirements for tagged\n+// globals. These properties are not checked at link time so they need to be\n+// checked at runtime.\n+static void CheckCodeModel(ElfW(Addr) base, const ElfW(Phdr) * phdr,\n+                           ElfW(Half) phnum) {\n+  ElfW(Addr) min_addr = -1ull, max_addr = 0;\n+  for (unsigned i = 0; i != phnum; ++i) {\n+    if (phdr[i].p_type != PT_LOAD)\n+      continue;\n+    ElfW(Addr) lo = base + phdr[i].p_vaddr, hi = lo + phdr[i].p_memsz;\n+    if (min_addr > lo)\n+      min_addr = lo;\n+    if (max_addr < hi)\n+      max_addr = hi;\n+  }\n+\n+  if (max_addr - min_addr > 1ull << 32) {\n+    Report(\"FATAL: HWAddressSanitizer: library size exceeds 2^32\\n\");\n+    Die();\n+  }\n+  if (max_addr > 1ull << 48) {\n+    Report(\"FATAL: HWAddressSanitizer: library loaded above address 2^48\\n\");\n+    Die();\n+  }\n+}\n+\n+ArrayRef<const hwasan_global> HwasanGlobalsFor(ElfW(Addr) base,\n+                                               const ElfW(Phdr) * phdr,\n+                                               ElfW(Half) phnum) {\n+  // Read the phdrs from this DSO.\n+  for (unsigned i = 0; i != phnum; ++i) {\n+    if (phdr[i].p_type != PT_NOTE)\n+      continue;\n+\n+    const char *note = reinterpret_cast<const char *>(base + phdr[i].p_vaddr);\n+    const char *nend = note + phdr[i].p_memsz;\n+\n+    // Traverse all the notes until we find a HWASan note.\n+    while (note < nend) {\n+      auto *nhdr = reinterpret_cast<const ElfW(Nhdr) *>(note);\n+      const char *name = note + sizeof(ElfW(Nhdr));\n+      const char *desc = name + RoundUpTo(nhdr->n_namesz, 4);\n+\n+      // Discard non-HWASan-Globals notes.\n+      if (nhdr->n_type != NT_LLVM_HWASAN_GLOBALS ||\n+          internal_strcmp(name, \"LLVM\") != 0) {\n+        note = desc + RoundUpTo(nhdr->n_descsz, 4);\n+        continue;\n+      }\n+\n+      // Only libraries with instrumented globals need to be checked against the\n+      // code model since they use relocations that aren't checked at link time.\n+      CheckCodeModel(base, phdr, phnum);\n+\n+      auto *global_note = reinterpret_cast<const hwasan_global_note *>(desc);\n+      auto *globals_begin = reinterpret_cast<const hwasan_global *>(\n+          note + global_note->begin_relptr);\n+      auto *globals_end = reinterpret_cast<const hwasan_global *>(\n+          note + global_note->end_relptr);\n+\n+      return {globals_begin, globals_end};\n+    }\n+  }\n+\n+  return {};\n+}\n+\n+}  // namespace __hwasan"}, {"sha": "fd7adf7a05880278c500d0532344f58a76c9a6b5", "filename": "libsanitizer/hwasan/hwasan_globals.h", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_globals.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_globals.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_globals.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,49 @@\n+//===-- hwasan_globals.h ----------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// Private Hwasan header.\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_GLOBALS_H\n+#define HWASAN_GLOBALS_H\n+\n+#include <link.h>\n+\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+\n+namespace __hwasan {\n+// This object should only ever be casted over the global (i.e. not constructed)\n+// in the ELF PT_NOTE in order for `addr()` to work correctly.\n+struct hwasan_global {\n+  // The size of this global variable. Note that the size in the descriptor is\n+  // max 1 << 24. Larger globals have multiple descriptors.\n+  uptr size() const { return info & 0xffffff; }\n+  // The fully-relocated address of this global.\n+  uptr addr() const { return reinterpret_cast<uintptr_t>(this) + gv_relptr; }\n+  // The static tag of this global.\n+  u8 tag() const { return info >> 24; };\n+\n+  // The relative address between the start of the descriptor for the HWASan\n+  // global (in the PT_NOTE), and the fully relocated address of the global.\n+  s32 gv_relptr;\n+  u32 info;\n+};\n+\n+// Walk through the specific DSO (as specified by the base, phdr, and phnum),\n+// and return the range of the [beginning, end) of the HWASan globals descriptor\n+// array.\n+ArrayRef<const hwasan_global> HwasanGlobalsFor(ElfW(Addr) base,\n+                                               const ElfW(Phdr) * phdr,\n+                                               ElfW(Half) phnum);\n+\n+}  // namespace __hwasan\n+\n+#endif  // HWASAN_GLOBALS_H"}, {"sha": "44e569ee6d721a99a3333a21ebf1a51fb33b6e7a", "filename": "libsanitizer/hwasan/hwasan_interceptors.cpp", "status": "added", "additions": 349, "deletions": 0, "changes": 349, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_interceptors.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_interceptors.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_interceptors.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,349 @@\n+//===-- hwasan_interceptors.cpp -------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// Interceptors for standard library functions.\n+//\n+// FIXME: move as many interceptors as possible into\n+// sanitizer_common/sanitizer_common_interceptors.h\n+//===----------------------------------------------------------------------===//\n+\n+#include \"interception/interception.h\"\n+#include \"hwasan.h\"\n+#include \"hwasan_allocator.h\"\n+#include \"hwasan_mapping.h\"\n+#include \"hwasan_thread.h\"\n+#include \"hwasan_poisoning.h\"\n+#include \"hwasan_report.h\"\n+#include \"sanitizer_common/sanitizer_platform_limits_posix.h\"\n+#include \"sanitizer_common/sanitizer_allocator.h\"\n+#include \"sanitizer_common/sanitizer_allocator_interface.h\"\n+#include \"sanitizer_common/sanitizer_allocator_internal.h\"\n+#include \"sanitizer_common/sanitizer_atomic.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_errno.h\"\n+#include \"sanitizer_common/sanitizer_stackdepot.h\"\n+#include \"sanitizer_common/sanitizer_libc.h\"\n+#include \"sanitizer_common/sanitizer_linux.h\"\n+#include \"sanitizer_common/sanitizer_tls_get_addr.h\"\n+\n+#include <stdarg.h>\n+// ACHTUNG! No other system header includes in this file.\n+// Ideally, we should get rid of stdarg.h as well.\n+\n+using namespace __hwasan;\n+\n+using __sanitizer::memory_order;\n+using __sanitizer::atomic_load;\n+using __sanitizer::atomic_store;\n+using __sanitizer::atomic_uintptr_t;\n+\n+static uptr allocated_for_dlsym;\n+static const uptr kDlsymAllocPoolSize = 1024;\n+static uptr alloc_memory_for_dlsym[kDlsymAllocPoolSize];\n+\n+static bool IsInDlsymAllocPool(const void *ptr) {\n+  uptr off = (uptr)ptr - (uptr)alloc_memory_for_dlsym;\n+  return off < sizeof(alloc_memory_for_dlsym);\n+}\n+\n+static void *AllocateFromLocalPool(uptr size_in_bytes) {\n+  uptr size_in_words = RoundUpTo(size_in_bytes, kWordSize) / kWordSize;\n+  void *mem = (void *)&alloc_memory_for_dlsym[allocated_for_dlsym];\n+  allocated_for_dlsym += size_in_words;\n+  CHECK_LT(allocated_for_dlsym, kDlsymAllocPoolSize);\n+  return mem;\n+}\n+\n+#define ENSURE_HWASAN_INITED() do { \\\n+  CHECK(!hwasan_init_is_running); \\\n+  if (!hwasan_inited) { \\\n+    __hwasan_init(); \\\n+  } \\\n+} while (0)\n+\n+\n+int __sanitizer_posix_memalign(void **memptr, uptr alignment, uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  CHECK_NE(memptr, 0);\n+  int res = hwasan_posix_memalign(memptr, alignment, size, &stack);\n+  return res;\n+}\n+\n+void * __sanitizer_memalign(uptr alignment, uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  return hwasan_memalign(alignment, size, &stack);\n+}\n+\n+void * __sanitizer_aligned_alloc(uptr alignment, uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  return hwasan_aligned_alloc(alignment, size, &stack);\n+}\n+\n+void * __sanitizer___libc_memalign(uptr alignment, uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  void *ptr = hwasan_memalign(alignment, size, &stack);\n+  if (ptr)\n+    DTLS_on_libc_memalign(ptr, size);\n+  return ptr;\n+}\n+\n+void * __sanitizer_valloc(uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  return hwasan_valloc(size, &stack);\n+}\n+\n+void * __sanitizer_pvalloc(uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  return hwasan_pvalloc(size, &stack);\n+}\n+\n+void __sanitizer_free(void *ptr) {\n+  GET_MALLOC_STACK_TRACE;\n+  if (!ptr || UNLIKELY(IsInDlsymAllocPool(ptr))) return;\n+  hwasan_free(ptr, &stack);\n+}\n+\n+void __sanitizer_cfree(void *ptr) {\n+  GET_MALLOC_STACK_TRACE;\n+  if (!ptr || UNLIKELY(IsInDlsymAllocPool(ptr))) return;\n+  hwasan_free(ptr, &stack);\n+}\n+\n+uptr __sanitizer_malloc_usable_size(const void *ptr) {\n+  return __sanitizer_get_allocated_size(ptr);\n+}\n+\n+struct __sanitizer_struct_mallinfo __sanitizer_mallinfo() {\n+  __sanitizer_struct_mallinfo sret;\n+  internal_memset(&sret, 0, sizeof(sret));\n+  return sret;\n+}\n+\n+int __sanitizer_mallopt(int cmd, int value) {\n+  return 0;\n+}\n+\n+void __sanitizer_malloc_stats(void) {\n+  // FIXME: implement, but don't call REAL(malloc_stats)!\n+}\n+\n+void * __sanitizer_calloc(uptr nmemb, uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  if (UNLIKELY(!hwasan_inited))\n+    // Hack: dlsym calls calloc before REAL(calloc) is retrieved from dlsym.\n+    return AllocateFromLocalPool(nmemb * size);\n+  return hwasan_calloc(nmemb, size, &stack);\n+}\n+\n+void * __sanitizer_realloc(void *ptr, uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  if (UNLIKELY(IsInDlsymAllocPool(ptr))) {\n+    uptr offset = (uptr)ptr - (uptr)alloc_memory_for_dlsym;\n+    uptr copy_size = Min(size, kDlsymAllocPoolSize - offset);\n+    void *new_ptr;\n+    if (UNLIKELY(!hwasan_inited)) {\n+      new_ptr = AllocateFromLocalPool(copy_size);\n+    } else {\n+      copy_size = size;\n+      new_ptr = hwasan_malloc(copy_size, &stack);\n+    }\n+    internal_memcpy(new_ptr, ptr, copy_size);\n+    return new_ptr;\n+  }\n+  return hwasan_realloc(ptr, size, &stack);\n+}\n+\n+void * __sanitizer_reallocarray(void *ptr, uptr nmemb, uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  return hwasan_reallocarray(ptr, nmemb, size, &stack);\n+}\n+\n+void * __sanitizer_malloc(uptr size) {\n+  GET_MALLOC_STACK_TRACE;\n+  if (UNLIKELY(!hwasan_init_is_running))\n+    ENSURE_HWASAN_INITED();\n+  if (UNLIKELY(!hwasan_inited))\n+    // Hack: dlsym calls malloc before REAL(malloc) is retrieved from dlsym.\n+    return AllocateFromLocalPool(size);\n+  return hwasan_malloc(size, &stack);\n+}\n+\n+#if HWASAN_WITH_INTERCEPTORS\n+#define INTERCEPTOR_ALIAS(RET, FN, ARGS...)                                  \\\n+  extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE RET WRAP(FN)(ARGS)                \\\n+      ALIAS(\"__sanitizer_\" #FN);                                             \\\n+  extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE RET FN(  \\\n+      ARGS) ALIAS(\"__sanitizer_\" #FN)\n+\n+INTERCEPTOR_ALIAS(int, posix_memalign, void **memptr, SIZE_T alignment,\n+                  SIZE_T size);\n+INTERCEPTOR_ALIAS(void *, aligned_alloc, SIZE_T alignment, SIZE_T size);\n+INTERCEPTOR_ALIAS(void *, __libc_memalign, SIZE_T alignment, SIZE_T size);\n+INTERCEPTOR_ALIAS(void *, valloc, SIZE_T size);\n+INTERCEPTOR_ALIAS(void, free, void *ptr);\n+INTERCEPTOR_ALIAS(uptr, malloc_usable_size, const void *ptr);\n+INTERCEPTOR_ALIAS(void *, calloc, SIZE_T nmemb, SIZE_T size);\n+INTERCEPTOR_ALIAS(void *, realloc, void *ptr, SIZE_T size);\n+INTERCEPTOR_ALIAS(void *, reallocarray, void *ptr, SIZE_T nmemb, SIZE_T size);\n+INTERCEPTOR_ALIAS(void *, malloc, SIZE_T size);\n+\n+#if !SANITIZER_FREEBSD && !SANITIZER_NETBSD\n+INTERCEPTOR_ALIAS(void *, memalign, SIZE_T alignment, SIZE_T size);\n+INTERCEPTOR_ALIAS(void *, pvalloc, SIZE_T size);\n+INTERCEPTOR_ALIAS(void, cfree, void *ptr);\n+INTERCEPTOR_ALIAS(__sanitizer_struct_mallinfo, mallinfo);\n+INTERCEPTOR_ALIAS(int, mallopt, int cmd, int value);\n+INTERCEPTOR_ALIAS(void, malloc_stats, void);\n+#endif\n+\n+struct ThreadStartArg {\n+  thread_callback_t callback;\n+  void *param;\n+};\n+\n+static void *HwasanThreadStartFunc(void *arg) {\n+  __hwasan_thread_enter();\n+  ThreadStartArg A = *reinterpret_cast<ThreadStartArg*>(arg);\n+  UnmapOrDie(arg, GetPageSizeCached());\n+  return A.callback(A.param);\n+}\n+\n+INTERCEPTOR(int, pthread_create, void *th, void *attr, void *(*callback)(void*),\n+            void * param) {\n+  ScopedTaggingDisabler disabler;\n+  ThreadStartArg *A = reinterpret_cast<ThreadStartArg *> (MmapOrDie(\n+      GetPageSizeCached(), \"pthread_create\"));\n+  *A = {callback, param};\n+  int res = REAL(pthread_create)(UntagPtr(th), UntagPtr(attr),\n+                                 &HwasanThreadStartFunc, A);\n+  return res;\n+}\n+\n+DEFINE_REAL(int, vfork)\n+DECLARE_EXTERN_INTERCEPTOR_AND_WRAPPER(int, vfork)\n+#endif // HWASAN_WITH_INTERCEPTORS\n+\n+#if HWASAN_WITH_INTERCEPTORS && defined(__aarch64__)\n+// Get and/or change the set of blocked signals.\n+extern \"C\" int sigprocmask(int __how, const __hw_sigset_t *__restrict __set,\n+                           __hw_sigset_t *__restrict __oset);\n+#define SIG_BLOCK 0\n+#define SIG_SETMASK 2\n+extern \"C\" int __sigjmp_save(__hw_sigjmp_buf env, int savemask) {\n+  env[0].__mask_was_saved =\n+      (savemask && sigprocmask(SIG_BLOCK, (__hw_sigset_t *)0,\n+                               &env[0].__saved_mask) == 0);\n+  return 0;\n+}\n+\n+static void __attribute__((always_inline))\n+InternalLongjmp(__hw_register_buf env, int retval) {\n+  // Clear all memory tags on the stack between here and where we're going.\n+  unsigned long long stack_pointer = env[13];\n+  // The stack pointer should never be tagged, so we don't need to clear the\n+  // tag for this function call.\n+  __hwasan_handle_longjmp((void *)stack_pointer);\n+\n+  // Run code for handling a longjmp.\n+  // Need to use a register that isn't going to be loaded from the environment\n+  // buffer -- hence why we need to specify the register to use.\n+  // Must implement this ourselves, since we don't know the order of registers\n+  // in different libc implementations and many implementations mangle the\n+  // stack pointer so we can't use it without knowing the demangling scheme.\n+  register long int retval_tmp asm(\"x1\") = retval;\n+  register void *env_address asm(\"x0\") = &env[0];\n+  asm volatile(\"ldp\tx19, x20, [%0, #0<<3];\"\n+               \"ldp\tx21, x22, [%0, #2<<3];\"\n+               \"ldp\tx23, x24, [%0, #4<<3];\"\n+               \"ldp\tx25, x26, [%0, #6<<3];\"\n+               \"ldp\tx27, x28, [%0, #8<<3];\"\n+               \"ldp\tx29, x30, [%0, #10<<3];\"\n+               \"ldp\t d8,  d9, [%0, #14<<3];\"\n+               \"ldp\td10, d11, [%0, #16<<3];\"\n+               \"ldp\td12, d13, [%0, #18<<3];\"\n+               \"ldp\td14, d15, [%0, #20<<3];\"\n+               \"ldr\tx5, [%0, #13<<3];\"\n+               \"mov\tsp, x5;\"\n+               // Return the value requested to return through arguments.\n+               // This should be in x1 given what we requested above.\n+               \"cmp\t%1, #0;\"\n+               \"mov\tx0, #1;\"\n+               \"csel\tx0, %1, x0, ne;\"\n+               \"br\tx30;\"\n+               : \"+r\"(env_address)\n+               : \"r\"(retval_tmp));\n+}\n+\n+INTERCEPTOR(void, siglongjmp, __hw_sigjmp_buf env, int val) {\n+  if (env[0].__mask_was_saved)\n+    // Restore the saved signal mask.\n+    (void)sigprocmask(SIG_SETMASK, &env[0].__saved_mask,\n+                      (__hw_sigset_t *)0);\n+  InternalLongjmp(env[0].__jmpbuf, val);\n+}\n+\n+// Required since glibc libpthread calls __libc_longjmp on pthread_exit, and\n+// _setjmp on start_thread.  Hence we have to intercept the longjmp on\n+// pthread_exit so the __hw_jmp_buf order matches.\n+INTERCEPTOR(void, __libc_longjmp, __hw_jmp_buf env, int val) {\n+  InternalLongjmp(env[0].__jmpbuf, val);\n+}\n+\n+INTERCEPTOR(void, longjmp, __hw_jmp_buf env, int val) {\n+  InternalLongjmp(env[0].__jmpbuf, val);\n+}\n+#undef SIG_BLOCK\n+#undef SIG_SETMASK\n+\n+#endif // HWASAN_WITH_INTERCEPTORS && __aarch64__\n+\n+static void BeforeFork() {\n+  StackDepotLockAll();\n+}\n+\n+static void AfterFork() {\n+  StackDepotUnlockAll();\n+}\n+\n+INTERCEPTOR(int, fork, void) {\n+  ENSURE_HWASAN_INITED();\n+  BeforeFork();\n+  int pid = REAL(fork)();\n+  AfterFork();\n+  return pid;\n+}\n+\n+namespace __hwasan {\n+\n+int OnExit() {\n+  // FIXME: ask frontend whether we need to return failure.\n+  return 0;\n+}\n+\n+} // namespace __hwasan\n+\n+namespace __hwasan {\n+\n+void InitializeInterceptors() {\n+  static int inited = 0;\n+  CHECK_EQ(inited, 0);\n+\n+  INTERCEPT_FUNCTION(fork);\n+\n+#if HWASAN_WITH_INTERCEPTORS\n+#if defined(__linux__)\n+  INTERCEPT_FUNCTION(vfork);\n+#endif  // __linux__\n+  INTERCEPT_FUNCTION(pthread_create);\n+#endif\n+\n+  inited = 1;\n+}\n+} // namespace __hwasan"}, {"sha": "23d565936d8799cb6938f2236be8516a8e7636e5", "filename": "libsanitizer/hwasan/hwasan_interceptors_vfork.S", "status": "added", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_interceptors_vfork.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_interceptors_vfork.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_interceptors_vfork.S?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,11 @@\n+#include \"sanitizer_common/sanitizer_asm.h\"\n+\n+#if defined(__linux__) && HWASAN_WITH_INTERCEPTORS\n+#define COMMON_INTERCEPTOR_SPILL_AREA __hwasan_extra_spill_area\n+#define COMMON_INTERCEPTOR_HANDLE_VFORK __hwasan_handle_vfork\n+#include \"sanitizer_common/sanitizer_common_interceptors_vfork_aarch64.inc.S\"\n+#include \"sanitizer_common/sanitizer_common_interceptors_vfork_riscv64.inc.S\"\n+#include \"sanitizer_common/sanitizer_common_interceptors_vfork_x86_64.inc.S\"\n+#endif\n+\n+NO_EXEC_STACK_DIRECTIVE"}, {"sha": "aedda317497b61349050511a3d244f480fae5ba2", "filename": "libsanitizer/hwasan/hwasan_interface_internal.h", "status": "added", "additions": 227, "deletions": 0, "changes": 227, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_interface_internal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_interface_internal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_interface_internal.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,227 @@\n+//===-- hwasan_interface_internal.h -----------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// Private Hwasan interface header.\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_INTERFACE_INTERNAL_H\n+#define HWASAN_INTERFACE_INTERNAL_H\n+\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+#include \"sanitizer_common/sanitizer_platform_limits_posix.h\"\n+#include <link.h>\n+\n+extern \"C\" {\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_init_static();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_init();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_library_loaded(ElfW(Addr) base, const ElfW(Phdr) * phdr,\n+                             ElfW(Half) phnum);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_library_unloaded(ElfW(Addr) base, const ElfW(Phdr) * phdr,\n+                               ElfW(Half) phnum);\n+\n+using __sanitizer::uptr;\n+using __sanitizer::sptr;\n+using __sanitizer::uu64;\n+using __sanitizer::uu32;\n+using __sanitizer::uu16;\n+using __sanitizer::u64;\n+using __sanitizer::u32;\n+using __sanitizer::u16;\n+using __sanitizer::u8;\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_init_frames(uptr, uptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+extern uptr __hwasan_shadow_memory_dynamic_address;\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_loadN(uptr, uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load1(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load2(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load4(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load8(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load16(uptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_loadN_noabort(uptr, uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load1_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load2_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load4_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load8_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_load16_noabort(uptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_storeN(uptr, uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store1(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store2(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store4(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store8(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store16(uptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_storeN_noabort(uptr, uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store1_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store2_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store4_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store8_noabort(uptr);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_store16_noabort(uptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_tag_memory(uptr p, u8 tag, uptr sz);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+uptr __hwasan_tag_pointer(uptr p, u8 tag);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_tag_mismatch(uptr addr, u8 ts);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_tag_mismatch4(uptr addr, uptr access_info, uptr *registers_frame,\n+                            size_t outsize);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+u8 __hwasan_generate_tag();\n+\n+// Returns the offset of the first tag mismatch or -1 if the whole range is\n+// good.\n+SANITIZER_INTERFACE_ATTRIBUTE\n+sptr __hwasan_test_shadow(const void *x, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+/* OPTIONAL */ const char* __hwasan_default_options();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_print_shadow(const void *x, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_handle_longjmp(const void *sp_dst);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_handle_vfork(const void *sp_dst);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+u16 __sanitizer_unaligned_load16(const uu16 *p);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+u32 __sanitizer_unaligned_load32(const uu32 *p);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+u64 __sanitizer_unaligned_load64(const uu64 *p);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_unaligned_store16(uu16 *p, u16 x);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_unaligned_store32(uu32 *p, u32 x);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_unaligned_store64(uu64 *p, u64 x);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_enable_allocator_tagging();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_disable_allocator_tagging();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_thread_enter();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_thread_exit();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __hwasan_print_memory_usage();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+int __sanitizer_posix_memalign(void **memptr, uptr alignment, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_memalign(uptr alignment, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_aligned_alloc(uptr alignment, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer___libc_memalign(uptr alignment, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_valloc(uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_pvalloc(uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_free(void *ptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_cfree(void *ptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+uptr __sanitizer_malloc_usable_size(const void *ptr);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+__hwasan::__sanitizer_struct_mallinfo __sanitizer_mallinfo();\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+int __sanitizer_mallopt(int cmd, int value);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_malloc_stats(void);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_calloc(uptr nmemb, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_realloc(void *ptr, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_reallocarray(void *ptr, uptr nmemb, uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void * __sanitizer_malloc(uptr size);\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void *__hwasan_memcpy(void *dst, const void *src, uptr size);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void *__hwasan_memset(void *s, int c, uptr n);\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void *__hwasan_memmove(void *dest, const void *src, uptr n);\n+}  // extern \"C\"\n+\n+#endif  // HWASAN_INTERFACE_INTERNAL_H"}, {"sha": "e99926d355cfa186d287923acddc200858e0a1a4", "filename": "libsanitizer/hwasan/hwasan_linux.cpp", "status": "added", "additions": 455, "deletions": 0, "changes": 455, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_linux.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_linux.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_linux.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,455 @@\n+//===-- hwasan_linux.cpp ----------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+///\n+/// \\file\n+/// This file is a part of HWAddressSanitizer and contains Linux-, NetBSD- and\n+/// FreeBSD-specific code.\n+///\n+//===----------------------------------------------------------------------===//\n+\n+#include \"sanitizer_common/sanitizer_platform.h\"\n+#if SANITIZER_FREEBSD || SANITIZER_LINUX || SANITIZER_NETBSD\n+\n+#include \"hwasan.h\"\n+#include \"hwasan_dynamic_shadow.h\"\n+#include \"hwasan_interface_internal.h\"\n+#include \"hwasan_mapping.h\"\n+#include \"hwasan_report.h\"\n+#include \"hwasan_thread.h\"\n+#include \"hwasan_thread_list.h\"\n+\n+#include <dlfcn.h>\n+#include <elf.h>\n+#include <link.h>\n+#include <pthread.h>\n+#include <signal.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <sys/resource.h>\n+#include <sys/time.h>\n+#include <unistd.h>\n+#include <unwind.h>\n+#include <sys/prctl.h>\n+#include <errno.h>\n+\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_procmaps.h\"\n+\n+// Configurations of HWASAN_WITH_INTERCEPTORS and SANITIZER_ANDROID.\n+//\n+// HWASAN_WITH_INTERCEPTORS=OFF, SANITIZER_ANDROID=OFF\n+//   Not currently tested.\n+// HWASAN_WITH_INTERCEPTORS=OFF, SANITIZER_ANDROID=ON\n+//   Integration tests downstream exist.\n+// HWASAN_WITH_INTERCEPTORS=ON, SANITIZER_ANDROID=OFF\n+//    Tested with check-hwasan on x86_64-linux.\n+// HWASAN_WITH_INTERCEPTORS=ON, SANITIZER_ANDROID=ON\n+//    Tested with check-hwasan on aarch64-linux-android.\n+#if !SANITIZER_ANDROID\n+SANITIZER_INTERFACE_ATTRIBUTE\n+THREADLOCAL uptr __hwasan_tls;\n+#endif\n+\n+namespace __hwasan {\n+\n+// With the zero shadow base we can not actually map pages starting from 0.\n+// This constant is somewhat arbitrary.\n+constexpr uptr kZeroBaseShadowStart = 0;\n+constexpr uptr kZeroBaseMaxShadowStart = 1 << 18;\n+\n+static void ProtectGap(uptr addr, uptr size) {\n+  __sanitizer::ProtectGap(addr, size, kZeroBaseShadowStart,\n+                          kZeroBaseMaxShadowStart);\n+}\n+\n+uptr kLowMemStart;\n+uptr kLowMemEnd;\n+uptr kLowShadowEnd;\n+uptr kLowShadowStart;\n+uptr kHighShadowStart;\n+uptr kHighShadowEnd;\n+uptr kHighMemStart;\n+uptr kHighMemEnd;\n+\n+static void PrintRange(uptr start, uptr end, const char *name) {\n+  Printf(\"|| [%p, %p] || %.*s ||\\n\", (void *)start, (void *)end, 10, name);\n+}\n+\n+static void PrintAddressSpaceLayout() {\n+  PrintRange(kHighMemStart, kHighMemEnd, \"HighMem\");\n+  if (kHighShadowEnd + 1 < kHighMemStart)\n+    PrintRange(kHighShadowEnd + 1, kHighMemStart - 1, \"ShadowGap\");\n+  else\n+    CHECK_EQ(kHighShadowEnd + 1, kHighMemStart);\n+  PrintRange(kHighShadowStart, kHighShadowEnd, \"HighShadow\");\n+  if (kLowShadowEnd + 1 < kHighShadowStart)\n+    PrintRange(kLowShadowEnd + 1, kHighShadowStart - 1, \"ShadowGap\");\n+  else\n+    CHECK_EQ(kLowMemEnd + 1, kHighShadowStart);\n+  PrintRange(kLowShadowStart, kLowShadowEnd, \"LowShadow\");\n+  if (kLowMemEnd + 1 < kLowShadowStart)\n+    PrintRange(kLowMemEnd + 1, kLowShadowStart - 1, \"ShadowGap\");\n+  else\n+    CHECK_EQ(kLowMemEnd + 1, kLowShadowStart);\n+  PrintRange(kLowMemStart, kLowMemEnd, \"LowMem\");\n+  CHECK_EQ(0, kLowMemStart);\n+}\n+\n+static uptr GetHighMemEnd() {\n+  // HighMem covers the upper part of the address space.\n+  uptr max_address = GetMaxUserVirtualAddress();\n+  // Adjust max address to make sure that kHighMemEnd and kHighMemStart are\n+  // properly aligned:\n+  max_address |= (GetMmapGranularity() << kShadowScale) - 1;\n+  return max_address;\n+}\n+\n+static void InitializeShadowBaseAddress(uptr shadow_size_bytes) {\n+  __hwasan_shadow_memory_dynamic_address =\n+      FindDynamicShadowStart(shadow_size_bytes);\n+}\n+\n+void InitPrctl() {\n+#define PR_SET_TAGGED_ADDR_CTRL 55\n+#define PR_GET_TAGGED_ADDR_CTRL 56\n+#define PR_TAGGED_ADDR_ENABLE (1UL << 0)\n+  // Check we're running on a kernel that can use the tagged address ABI.\n+  if (internal_prctl(PR_GET_TAGGED_ADDR_CTRL, 0, 0, 0, 0) == (uptr)-1 &&\n+      errno == EINVAL) {\n+#if SANITIZER_ANDROID\n+    // Some older Android kernels have the tagged pointer ABI on\n+    // unconditionally, and hence don't have the tagged-addr prctl while still\n+    // allow the ABI.\n+    // If targeting Android and the prctl is not around we assume this is the\n+    // case.\n+    return;\n+#else\n+    Printf(\n+        \"FATAL: \"\n+        \"HWAddressSanitizer requires a kernel with tagged address ABI.\\n\");\n+    Die();\n+#endif\n+  }\n+\n+  // Turn on the tagged address ABI.\n+  if (internal_prctl(PR_SET_TAGGED_ADDR_CTRL, PR_TAGGED_ADDR_ENABLE, 0, 0, 0) ==\n+          (uptr)-1 ||\n+      !internal_prctl(PR_GET_TAGGED_ADDR_CTRL, 0, 0, 0, 0)) {\n+    Printf(\n+        \"FATAL: HWAddressSanitizer failed to enable tagged address syscall \"\n+        \"ABI.\\nSuggest check `sysctl abi.tagged_addr_disabled` \"\n+        \"configuration.\\n\");\n+    Die();\n+  }\n+#undef PR_SET_TAGGED_ADDR_CTRL\n+#undef PR_GET_TAGGED_ADDR_CTRL\n+#undef PR_TAGGED_ADDR_ENABLE\n+}\n+\n+bool InitShadow() {\n+  // Define the entire memory range.\n+  kHighMemEnd = GetHighMemEnd();\n+\n+  // Determine shadow memory base offset.\n+  InitializeShadowBaseAddress(MemToShadowSize(kHighMemEnd));\n+\n+  // Place the low memory first.\n+  kLowMemEnd = __hwasan_shadow_memory_dynamic_address - 1;\n+  kLowMemStart = 0;\n+\n+  // Define the low shadow based on the already placed low memory.\n+  kLowShadowEnd = MemToShadow(kLowMemEnd);\n+  kLowShadowStart = __hwasan_shadow_memory_dynamic_address;\n+\n+  // High shadow takes whatever memory is left up there (making sure it is not\n+  // interfering with low memory in the fixed case).\n+  kHighShadowEnd = MemToShadow(kHighMemEnd);\n+  kHighShadowStart = Max(kLowMemEnd, MemToShadow(kHighShadowEnd)) + 1;\n+\n+  // High memory starts where allocated shadow allows.\n+  kHighMemStart = ShadowToMem(kHighShadowStart);\n+\n+  // Check the sanity of the defined memory ranges (there might be gaps).\n+  CHECK_EQ(kHighMemStart % GetMmapGranularity(), 0);\n+  CHECK_GT(kHighMemStart, kHighShadowEnd);\n+  CHECK_GT(kHighShadowEnd, kHighShadowStart);\n+  CHECK_GT(kHighShadowStart, kLowMemEnd);\n+  CHECK_GT(kLowMemEnd, kLowMemStart);\n+  CHECK_GT(kLowShadowEnd, kLowShadowStart);\n+  CHECK_GT(kLowShadowStart, kLowMemEnd);\n+\n+  if (Verbosity())\n+    PrintAddressSpaceLayout();\n+\n+  // Reserve shadow memory.\n+  ReserveShadowMemoryRange(kLowShadowStart, kLowShadowEnd, \"low shadow\");\n+  ReserveShadowMemoryRange(kHighShadowStart, kHighShadowEnd, \"high shadow\");\n+\n+  // Protect all the gaps.\n+  ProtectGap(0, Min(kLowMemStart, kLowShadowStart));\n+  if (kLowMemEnd + 1 < kLowShadowStart)\n+    ProtectGap(kLowMemEnd + 1, kLowShadowStart - kLowMemEnd - 1);\n+  if (kLowShadowEnd + 1 < kHighShadowStart)\n+    ProtectGap(kLowShadowEnd + 1, kHighShadowStart - kLowShadowEnd - 1);\n+  if (kHighShadowEnd + 1 < kHighMemStart)\n+    ProtectGap(kHighShadowEnd + 1, kHighMemStart - kHighShadowEnd - 1);\n+\n+  return true;\n+}\n+\n+void InitThreads() {\n+  CHECK(__hwasan_shadow_memory_dynamic_address);\n+  uptr guard_page_size = GetMmapGranularity();\n+  uptr thread_space_start =\n+      __hwasan_shadow_memory_dynamic_address - (1ULL << kShadowBaseAlignment);\n+  uptr thread_space_end =\n+      __hwasan_shadow_memory_dynamic_address - guard_page_size;\n+  ReserveShadowMemoryRange(thread_space_start, thread_space_end - 1,\n+                           \"hwasan threads\", /*madvise_shadow*/ false);\n+  ProtectGap(thread_space_end,\n+             __hwasan_shadow_memory_dynamic_address - thread_space_end);\n+  InitThreadList(thread_space_start, thread_space_end - thread_space_start);\n+}\n+\n+bool MemIsApp(uptr p) {\n+  CHECK(GetTagFromPointer(p) == 0);\n+  return p >= kHighMemStart || (p >= kLowMemStart && p <= kLowMemEnd);\n+}\n+\n+static void HwasanAtExit(void) {\n+  if (common_flags()->print_module_map)\n+    DumpProcessMap();\n+  if (flags()->print_stats && (flags()->atexit || hwasan_report_count > 0))\n+    ReportStats();\n+  if (hwasan_report_count > 0) {\n+    // ReportAtExitStatistics();\n+    if (common_flags()->exitcode)\n+      internal__exit(common_flags()->exitcode);\n+  }\n+}\n+\n+void InstallAtExitHandler() {\n+  atexit(HwasanAtExit);\n+}\n+\n+// ---------------------- TSD ---------------- {{{1\n+\n+extern \"C\" void __hwasan_thread_enter() {\n+  hwasanThreadList().CreateCurrentThread()->InitRandomState();\n+}\n+\n+extern \"C\" void __hwasan_thread_exit() {\n+  Thread *t = GetCurrentThread();\n+  // Make sure that signal handler can not see a stale current thread pointer.\n+  atomic_signal_fence(memory_order_seq_cst);\n+  if (t)\n+    hwasanThreadList().ReleaseThread(t);\n+}\n+\n+#if HWASAN_WITH_INTERCEPTORS\n+static pthread_key_t tsd_key;\n+static bool tsd_key_inited = false;\n+\n+void HwasanTSDThreadInit() {\n+  if (tsd_key_inited)\n+    CHECK_EQ(0, pthread_setspecific(tsd_key,\n+                                    (void *)GetPthreadDestructorIterations()));\n+}\n+\n+void HwasanTSDDtor(void *tsd) {\n+  uptr iterations = (uptr)tsd;\n+  if (iterations > 1) {\n+    CHECK_EQ(0, pthread_setspecific(tsd_key, (void *)(iterations - 1)));\n+    return;\n+  }\n+  __hwasan_thread_exit();\n+}\n+\n+void HwasanTSDInit() {\n+  CHECK(!tsd_key_inited);\n+  tsd_key_inited = true;\n+  CHECK_EQ(0, pthread_key_create(&tsd_key, HwasanTSDDtor));\n+}\n+#else\n+void HwasanTSDInit() {}\n+void HwasanTSDThreadInit() {}\n+#endif\n+\n+#if SANITIZER_ANDROID\n+uptr *GetCurrentThreadLongPtr() {\n+  return (uptr *)get_android_tls_ptr();\n+}\n+#else\n+uptr *GetCurrentThreadLongPtr() {\n+  return &__hwasan_tls;\n+}\n+#endif\n+\n+#if SANITIZER_ANDROID\n+void AndroidTestTlsSlot() {\n+  uptr kMagicValue = 0x010203040A0B0C0D;\n+  uptr *tls_ptr = GetCurrentThreadLongPtr();\n+  uptr old_value = *tls_ptr;\n+  *tls_ptr = kMagicValue;\n+  dlerror();\n+  if (*(uptr *)get_android_tls_ptr() != kMagicValue) {\n+    Printf(\n+        \"ERROR: Incompatible version of Android: TLS_SLOT_SANITIZER(6) is used \"\n+        \"for dlerror().\\n\");\n+    Die();\n+  }\n+  *tls_ptr = old_value;\n+}\n+#else\n+void AndroidTestTlsSlot() {}\n+#endif\n+\n+Thread *GetCurrentThread() {\n+  uptr *ThreadLongPtr = GetCurrentThreadLongPtr();\n+  if (UNLIKELY(*ThreadLongPtr == 0))\n+    return nullptr;\n+  auto *R = (StackAllocationsRingBuffer *)ThreadLongPtr;\n+  return hwasanThreadList().GetThreadByBufferAddress((uptr)R->Next());\n+}\n+\n+struct AccessInfo {\n+  uptr addr;\n+  uptr size;\n+  bool is_store;\n+  bool is_load;\n+  bool recover;\n+};\n+\n+static AccessInfo GetAccessInfo(siginfo_t *info, ucontext_t *uc) {\n+  // Access type is passed in a platform dependent way (see below) and encoded\n+  // as 0xXY, where X&1 is 1 for store, 0 for load, and X&2 is 1 if the error is\n+  // recoverable. Valid values of Y are 0 to 4, which are interpreted as\n+  // log2(access_size), and 0xF, which means that access size is passed via\n+  // platform dependent register (see below).\n+#if defined(__aarch64__)\n+  // Access type is encoded in BRK immediate as 0x900 + 0xXY. For Y == 0xF,\n+  // access size is stored in X1 register. Access address is always in X0\n+  // register.\n+  uptr pc = (uptr)info->si_addr;\n+  const unsigned code = ((*(u32 *)pc) >> 5) & 0xffff;\n+  if ((code & 0xff00) != 0x900)\n+    return AccessInfo{}; // Not ours.\n+\n+  const bool is_store = code & 0x10;\n+  const bool recover = code & 0x20;\n+  const uptr addr = uc->uc_mcontext.regs[0];\n+  const unsigned size_log = code & 0xf;\n+  if (size_log > 4 && size_log != 0xf)\n+    return AccessInfo{}; // Not ours.\n+  const uptr size = size_log == 0xf ? uc->uc_mcontext.regs[1] : 1U << size_log;\n+\n+#elif defined(__x86_64__)\n+  // Access type is encoded in the instruction following INT3 as\n+  // NOP DWORD ptr [EAX + 0x40 + 0xXY]. For Y == 0xF, access size is stored in\n+  // RSI register. Access address is always in RDI register.\n+  uptr pc = (uptr)uc->uc_mcontext.gregs[REG_RIP];\n+  uint8_t *nop = (uint8_t*)pc;\n+  if (*nop != 0x0f || *(nop + 1) != 0x1f || *(nop + 2) != 0x40  ||\n+      *(nop + 3) < 0x40)\n+    return AccessInfo{}; // Not ours.\n+  const unsigned code = *(nop + 3);\n+\n+  const bool is_store = code & 0x10;\n+  const bool recover = code & 0x20;\n+  const uptr addr = uc->uc_mcontext.gregs[REG_RDI];\n+  const unsigned size_log = code & 0xf;\n+  if (size_log > 4 && size_log != 0xf)\n+    return AccessInfo{}; // Not ours.\n+  const uptr size =\n+      size_log == 0xf ? uc->uc_mcontext.gregs[REG_RSI] : 1U << size_log;\n+\n+#else\n+# error Unsupported architecture\n+#endif\n+\n+  return AccessInfo{addr, size, is_store, !is_store, recover};\n+}\n+\n+static void HandleTagMismatch(AccessInfo ai, uptr pc, uptr frame,\n+                              ucontext_t *uc, uptr *registers_frame = nullptr) {\n+  InternalMmapVector<BufferedStackTrace> stack_buffer(1);\n+  BufferedStackTrace *stack = stack_buffer.data();\n+  stack->Reset();\n+  stack->Unwind(pc, frame, uc, common_flags()->fast_unwind_on_fatal);\n+\n+  // The second stack frame contains the failure __hwasan_check function, as\n+  // we have a stack frame for the registers saved in __hwasan_tag_mismatch that\n+  // we wish to ignore. This (currently) only occurs on AArch64, as x64\n+  // implementations use SIGTRAP to implement the failure, and thus do not go\n+  // through the stack saver.\n+  if (registers_frame && stack->trace && stack->size > 0) {\n+    stack->trace++;\n+    stack->size--;\n+  }\n+\n+  bool fatal = flags()->halt_on_error || !ai.recover;\n+  ReportTagMismatch(stack, ai.addr, ai.size, ai.is_store, fatal,\n+                    registers_frame);\n+}\n+\n+static bool HwasanOnSIGTRAP(int signo, siginfo_t *info, ucontext_t *uc) {\n+  AccessInfo ai = GetAccessInfo(info, uc);\n+  if (!ai.is_store && !ai.is_load)\n+    return false;\n+\n+  SignalContext sig{info, uc};\n+  HandleTagMismatch(ai, StackTrace::GetNextInstructionPc(sig.pc), sig.bp, uc);\n+\n+#if defined(__aarch64__)\n+  uc->uc_mcontext.pc += 4;\n+#elif defined(__x86_64__)\n+#else\n+# error Unsupported architecture\n+#endif\n+  return true;\n+}\n+\n+static void OnStackUnwind(const SignalContext &sig, const void *,\n+                          BufferedStackTrace *stack) {\n+  stack->Unwind(StackTrace::GetNextInstructionPc(sig.pc), sig.bp, sig.context,\n+                common_flags()->fast_unwind_on_fatal);\n+}\n+\n+void HwasanOnDeadlySignal(int signo, void *info, void *context) {\n+  // Probably a tag mismatch.\n+  if (signo == SIGTRAP)\n+    if (HwasanOnSIGTRAP(signo, (siginfo_t *)info, (ucontext_t*)context))\n+      return;\n+\n+  HandleDeadlySignal(info, context, GetTid(), &OnStackUnwind, nullptr);\n+}\n+\n+\n+} // namespace __hwasan\n+\n+// Entry point for interoperability between __hwasan_tag_mismatch (ASM) and the\n+// rest of the mismatch handling code (C++).\n+void __hwasan_tag_mismatch4(uptr addr, uptr access_info, uptr *registers_frame,\n+                            size_t outsize) {\n+  __hwasan::AccessInfo ai;\n+  ai.is_store = access_info & 0x10;\n+  ai.is_load = !ai.is_store;\n+  ai.recover = access_info & 0x20;\n+  ai.addr = addr;\n+  if ((access_info & 0xf) == 0xf)\n+    ai.size = outsize;\n+  else\n+    ai.size = 1 << (access_info & 0xf);\n+\n+  __hwasan::HandleTagMismatch(ai, (uptr)__builtin_return_address(0),\n+                              (uptr)__builtin_frame_address(0), nullptr,\n+                              registers_frame);\n+  __builtin_unreachable();\n+}\n+\n+#endif // SANITIZER_FREEBSD || SANITIZER_LINUX || SANITIZER_NETBSD"}, {"sha": "7d134e8c4b7fa833a67929006e5df5d0288ae677", "filename": "libsanitizer/hwasan/hwasan_malloc_bisect.h", "status": "added", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_malloc_bisect.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_malloc_bisect.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_malloc_bisect.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,50 @@\n+//===-- hwasan_malloc_bisect.h ----------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"sanitizer_common/sanitizer_hash.h\"\n+#include \"hwasan.h\"\n+\n+namespace __hwasan {\n+\n+static u32 malloc_hash(StackTrace *stack, uptr orig_size) {\n+  uptr len = Min(stack->size, (unsigned)7);\n+  MurMur2HashBuilder H(len);\n+  H.add(orig_size);\n+  // Start with frame #1 to skip __sanitizer_malloc frame, which is\n+  // (a) almost always the same (well, could be operator new or new[])\n+  // (b) can change hashes when compiler-rt is rebuilt, invalidating previous\n+  // bisection results.\n+  // Because of ASLR, use only offset inside the page.\n+  for (uptr i = 1; i < len; ++i) H.add(((u32)stack->trace[i]) & 0xFFF);\n+  return H.get();\n+}\n+\n+static inline bool malloc_bisect(StackTrace *stack, uptr orig_size) {\n+  uptr left = flags()->malloc_bisect_left;\n+  uptr right = flags()->malloc_bisect_right;\n+  if (LIKELY(left == 0 && right == 0))\n+    return true;\n+  if (!stack)\n+    return true;\n+  // Allow malloc_bisect_right > (u32)(-1) to avoid spelling the latter in\n+  // decimal.\n+  uptr h = (uptr)malloc_hash(stack, orig_size);\n+  if (h < left || h > right)\n+    return false;\n+  if (flags()->malloc_bisect_dump) {\n+    Printf(\"[alloc] %u %zu\\n\", h, orig_size);\n+    stack->Print();\n+  }\n+  return true;\n+}\n+\n+}  // namespace __hwasan"}, {"sha": "c149687bdfa60e409ad6b2c8d3cdc6687c1afc1c", "filename": "libsanitizer/hwasan/hwasan_mapping.h", "status": "added", "additions": 66, "deletions": 0, "changes": 66, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_mapping.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_mapping.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_mapping.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,66 @@\n+//===-- hwasan_mapping.h ----------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+///\n+/// \\file\n+/// This file is a part of HWAddressSanitizer and defines memory mapping.\n+///\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_MAPPING_H\n+#define HWASAN_MAPPING_H\n+\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+#include \"hwasan_interface_internal.h\"\n+\n+// Typical mapping on Linux/x86_64:\n+// with dynamic shadow mapped at [0x770d59f40000, 0x7f0d59f40000]:\n+// || [0x7f0d59f40000, 0x7fffffffffff] || HighMem    ||\n+// || [0x7efe2f934000, 0x7f0d59f3ffff] || HighShadow ||\n+// || [0x7e7e2f934000, 0x7efe2f933fff] || ShadowGap  ||\n+// || [0x770d59f40000, 0x7e7e2f933fff] || LowShadow  ||\n+// || [0x000000000000, 0x770d59f3ffff] || LowMem     ||\n+\n+// Typical mapping on Android/AArch64\n+// with dynamic shadow mapped: [0x007477480000, 0x007c77480000]:\n+// || [0x007c77480000, 0x007fffffffff] || HighMem    ||\n+// || [0x007c3ebc8000, 0x007c7747ffff] || HighShadow ||\n+// || [0x007bbebc8000, 0x007c3ebc7fff] || ShadowGap  ||\n+// || [0x007477480000, 0x007bbebc7fff] || LowShadow  ||\n+// || [0x000000000000, 0x00747747ffff] || LowMem     ||\n+\n+// Reasonable values are 4 (for 1/16th shadow) and 6 (for 1/64th).\n+constexpr uptr kShadowScale = 4;\n+constexpr uptr kShadowAlignment = 1ULL << kShadowScale;\n+\n+namespace __hwasan {\n+\n+extern uptr kLowMemStart;\n+extern uptr kLowMemEnd;\n+extern uptr kLowShadowEnd;\n+extern uptr kLowShadowStart;\n+extern uptr kHighShadowStart;\n+extern uptr kHighShadowEnd;\n+extern uptr kHighMemStart;\n+extern uptr kHighMemEnd;\n+\n+inline uptr MemToShadow(uptr untagged_addr) {\n+  return (untagged_addr >> kShadowScale) +\n+         __hwasan_shadow_memory_dynamic_address;\n+}\n+inline uptr ShadowToMem(uptr shadow_addr) {\n+  return (shadow_addr - __hwasan_shadow_memory_dynamic_address) << kShadowScale;\n+}\n+inline uptr MemToShadowSize(uptr size) {\n+  return size >> kShadowScale;\n+}\n+\n+bool MemIsApp(uptr p);\n+\n+}  // namespace __hwasan\n+\n+#endif  // HWASAN_MAPPING_H"}, {"sha": "e82d77a1bc16f7c7303c8fd5a533509becdf5cdf", "filename": "libsanitizer/hwasan/hwasan_memintrinsics.cpp", "status": "added", "additions": 44, "deletions": 0, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_memintrinsics.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_memintrinsics.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_memintrinsics.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,44 @@\n+//===-- hwasan_memintrinsics.cpp --------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+///\n+/// \\file\n+/// This file is a part of HWAddressSanitizer and contains HWASAN versions of\n+/// memset, memcpy and memmove\n+///\n+//===----------------------------------------------------------------------===//\n+\n+#include <string.h>\n+#include \"hwasan.h\"\n+#include \"hwasan_checks.h\"\n+#include \"hwasan_flags.h\"\n+#include \"hwasan_interface_internal.h\"\n+#include \"sanitizer_common/sanitizer_libc.h\"\n+\n+using namespace __hwasan;\n+\n+void *__hwasan_memset(void *block, int c, uptr size) {\n+  CheckAddressSized<ErrorAction::Recover, AccessType::Store>(\n+      reinterpret_cast<uptr>(block), size);\n+  return memset(UntagPtr(block), c, size);\n+}\n+\n+void *__hwasan_memcpy(void *to, const void *from, uptr size) {\n+  CheckAddressSized<ErrorAction::Recover, AccessType::Store>(\n+      reinterpret_cast<uptr>(to), size);\n+  CheckAddressSized<ErrorAction::Recover, AccessType::Load>(\n+      reinterpret_cast<uptr>(from), size);\n+  return memcpy(UntagPtr(to), UntagPtr(from), size);\n+}\n+\n+void *__hwasan_memmove(void *to, const void *from, uptr size) {\n+  CheckAddressSized<ErrorAction::Recover, AccessType::Store>(\n+      reinterpret_cast<uptr>(to), size);\n+  CheckAddressSized<ErrorAction::Recover, AccessType::Load>(\n+      reinterpret_cast<uptr>(from), size);\n+  return memmove(UntagPtr(to), UntagPtr(from), size);\n+}"}, {"sha": "8d01d3944f2b7deaac230aefb6caad4e687c5cdc", "filename": "libsanitizer/hwasan/hwasan_new_delete.cpp", "status": "added", "additions": 81, "deletions": 0, "changes": 81, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_new_delete.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_new_delete.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_new_delete.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,81 @@\n+//===-- hwasan_new_delete.cpp ---------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// Interceptors for operators new and delete.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"hwasan.h\"\n+#include \"interception/interception.h\"\n+#include \"sanitizer_common/sanitizer_allocator.h\"\n+#include \"sanitizer_common/sanitizer_allocator_report.h\"\n+\n+#include <stddef.h>\n+#include <stdlib.h>\n+\n+#if HWASAN_REPLACE_OPERATORS_NEW_AND_DELETE\n+\n+// TODO(alekseys): throw std::bad_alloc instead of dying on OOM.\n+#define OPERATOR_NEW_BODY(nothrow) \\\n+  GET_MALLOC_STACK_TRACE; \\\n+  void *res = hwasan_malloc(size, &stack);\\\n+  if (!nothrow && UNLIKELY(!res)) ReportOutOfMemory(size, &stack);\\\n+  return res\n+\n+#define OPERATOR_DELETE_BODY \\\n+  GET_MALLOC_STACK_TRACE; \\\n+  if (ptr) hwasan_free(ptr, &stack)\n+\n+#elif defined(__ANDROID__)\n+\n+// We don't actually want to intercept operator new and delete on Android, but\n+// since we previously released a runtime that intercepted these functions,\n+// removing the interceptors would break ABI. Therefore we simply forward to\n+// malloc and free.\n+#define OPERATOR_NEW_BODY(nothrow) return malloc(size)\n+#define OPERATOR_DELETE_BODY free(ptr)\n+\n+#endif\n+\n+#ifdef OPERATOR_NEW_BODY\n+\n+using namespace __hwasan;\n+\n+// Fake std::nothrow_t to avoid including <new>.\n+namespace std {\n+  struct nothrow_t {};\n+}  // namespace std\n+\n+\n+\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void *operator new(size_t size) { OPERATOR_NEW_BODY(false /*nothrow*/); }\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void *operator new[](size_t size) { OPERATOR_NEW_BODY(false /*nothrow*/); }\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void *operator new(size_t size, std::nothrow_t const&) {\n+  OPERATOR_NEW_BODY(true /*nothrow*/);\n+}\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void *operator new[](size_t size, std::nothrow_t const&) {\n+  OPERATOR_NEW_BODY(true /*nothrow*/);\n+}\n+\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void operator delete(void *ptr) NOEXCEPT { OPERATOR_DELETE_BODY; }\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void operator delete[](void *ptr) NOEXCEPT { OPERATOR_DELETE_BODY; }\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void operator delete(void *ptr, std::nothrow_t const&) { OPERATOR_DELETE_BODY; }\n+INTERCEPTOR_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n+void operator delete[](void *ptr, std::nothrow_t const&) {\n+  OPERATOR_DELETE_BODY;\n+}\n+\n+#endif // OPERATOR_NEW_BODY"}, {"sha": "2a0816428e75ba6c2fd6a613e89c7ab7de7a7f16", "filename": "libsanitizer/hwasan/hwasan_poisoning.cpp", "status": "added", "additions": 52, "deletions": 0, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_poisoning.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_poisoning.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_poisoning.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,52 @@\n+//===-- hwasan_poisoning.cpp ------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"hwasan_poisoning.h\"\n+\n+#include \"hwasan_mapping.h\"\n+#include \"interception/interception.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_linux.h\"\n+\n+namespace __hwasan {\n+\n+uptr TagMemoryAligned(uptr p, uptr size, tag_t tag) {\n+  CHECK(IsAligned(p, kShadowAlignment));\n+  CHECK(IsAligned(size, kShadowAlignment));\n+  uptr shadow_start = MemToShadow(p);\n+  uptr shadow_size = MemToShadowSize(size);\n+\n+  uptr page_size = GetPageSizeCached();\n+  uptr page_start = RoundUpTo(shadow_start, page_size);\n+  uptr page_end = RoundDownTo(shadow_start + shadow_size, page_size);\n+  uptr threshold = common_flags()->clear_shadow_mmap_threshold;\n+  if (SANITIZER_LINUX &&\n+      UNLIKELY(page_end >= page_start + threshold && tag == 0)) {\n+    internal_memset((void *)shadow_start, tag, page_start - shadow_start);\n+    internal_memset((void *)page_end, tag,\n+                    shadow_start + shadow_size - page_end);\n+    // For an anonymous private mapping MADV_DONTNEED will return a zero page on\n+    // Linux.\n+    ReleaseMemoryPagesToOSAndZeroFill(page_start, page_end);\n+  } else {\n+    internal_memset((void *)shadow_start, tag, shadow_size);\n+  }\n+  return AddTagToPointer(p, tag);\n+}\n+\n+uptr TagMemory(uptr p, uptr size, tag_t tag) {\n+  uptr start = RoundDownTo(p, kShadowAlignment);\n+  uptr end = RoundUpTo(p + size, kShadowAlignment);\n+  return TagMemoryAligned(start, end - start, tag);\n+}\n+\n+}  // namespace __hwasan"}, {"sha": "61751f7d252e9028dba2c86c024f1544aca7b631", "filename": "libsanitizer/hwasan/hwasan_poisoning.h", "status": "added", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_poisoning.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_poisoning.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_poisoning.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,24 @@\n+//===-- hwasan_poisoning.h --------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_POISONING_H\n+#define HWASAN_POISONING_H\n+\n+#include \"hwasan.h\"\n+\n+namespace __hwasan {\n+uptr TagMemory(uptr p, uptr size, tag_t tag);\n+uptr TagMemoryAligned(uptr p, uptr size, tag_t tag);\n+\n+}  // namespace __hwasan\n+\n+#endif  // HWASAN_POISONING_H"}, {"sha": "0be7deeaee1a0bd523d9e0fe1dc3b1311b3920e2", "filename": "libsanitizer/hwasan/hwasan_report.cpp", "status": "added", "additions": 651, "deletions": 0, "changes": 651, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_report.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_report.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_report.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,651 @@\n+//===-- hwasan_report.cpp -------------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// Error reporting.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"hwasan_report.h\"\n+\n+#include <dlfcn.h>\n+\n+#include \"hwasan.h\"\n+#include \"hwasan_allocator.h\"\n+#include \"hwasan_globals.h\"\n+#include \"hwasan_mapping.h\"\n+#include \"hwasan_thread.h\"\n+#include \"hwasan_thread_list.h\"\n+#include \"sanitizer_common/sanitizer_allocator_internal.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_flags.h\"\n+#include \"sanitizer_common/sanitizer_mutex.h\"\n+#include \"sanitizer_common/sanitizer_report_decorator.h\"\n+#include \"sanitizer_common/sanitizer_stackdepot.h\"\n+#include \"sanitizer_common/sanitizer_stacktrace_printer.h\"\n+#include \"sanitizer_common/sanitizer_symbolizer.h\"\n+\n+using namespace __sanitizer;\n+\n+namespace __hwasan {\n+\n+class ScopedReport {\n+ public:\n+  ScopedReport(bool fatal = false) : error_message_(1), fatal(fatal) {\n+    BlockingMutexLock lock(&error_message_lock_);\n+    error_message_ptr_ = fatal ? &error_message_ : nullptr;\n+    ++hwasan_report_count;\n+  }\n+\n+  ~ScopedReport() {\n+    {\n+      BlockingMutexLock lock(&error_message_lock_);\n+      if (fatal)\n+        SetAbortMessage(error_message_.data());\n+      error_message_ptr_ = nullptr;\n+    }\n+    if (common_flags()->print_module_map >= 2 ||\n+        (fatal && common_flags()->print_module_map))\n+      DumpProcessMap();\n+    if (fatal)\n+      Die();\n+  }\n+\n+  static void MaybeAppendToErrorMessage(const char *msg) {\n+    BlockingMutexLock lock(&error_message_lock_);\n+    if (!error_message_ptr_)\n+      return;\n+    uptr len = internal_strlen(msg);\n+    uptr old_size = error_message_ptr_->size();\n+    error_message_ptr_->resize(old_size + len);\n+    // overwrite old trailing '\\0', keep new trailing '\\0' untouched.\n+    internal_memcpy(&(*error_message_ptr_)[old_size - 1], msg, len);\n+  }\n+ private:\n+  ScopedErrorReportLock error_report_lock_;\n+  InternalMmapVector<char> error_message_;\n+  bool fatal;\n+\n+  static InternalMmapVector<char> *error_message_ptr_;\n+  static BlockingMutex error_message_lock_;\n+};\n+\n+InternalMmapVector<char> *ScopedReport::error_message_ptr_;\n+BlockingMutex ScopedReport::error_message_lock_;\n+\n+// If there is an active ScopedReport, append to its error message.\n+void AppendToErrorMessageBuffer(const char *buffer) {\n+  ScopedReport::MaybeAppendToErrorMessage(buffer);\n+}\n+\n+static StackTrace GetStackTraceFromId(u32 id) {\n+  CHECK(id);\n+  StackTrace res = StackDepotGet(id);\n+  CHECK(res.trace);\n+  return res;\n+}\n+\n+// A RAII object that holds a copy of the current thread stack ring buffer.\n+// The actual stack buffer may change while we are iterating over it (for\n+// example, Printf may call syslog() which can itself be built with hwasan).\n+class SavedStackAllocations {\n+ public:\n+  SavedStackAllocations(StackAllocationsRingBuffer *rb) {\n+    uptr size = rb->size() * sizeof(uptr);\n+    void *storage =\n+        MmapAlignedOrDieOnFatalError(size, size * 2, \"saved stack allocations\");\n+    new (&rb_) StackAllocationsRingBuffer(*rb, storage);\n+  }\n+\n+  ~SavedStackAllocations() {\n+    StackAllocationsRingBuffer *rb = get();\n+    UnmapOrDie(rb->StartOfStorage(), rb->size() * sizeof(uptr));\n+  }\n+\n+  StackAllocationsRingBuffer *get() {\n+    return (StackAllocationsRingBuffer *)&rb_;\n+  }\n+\n+ private:\n+  uptr rb_;\n+};\n+\n+class Decorator: public __sanitizer::SanitizerCommonDecorator {\n+ public:\n+  Decorator() : SanitizerCommonDecorator() { }\n+  const char *Access() { return Blue(); }\n+  const char *Allocation() const { return Magenta(); }\n+  const char *Origin() const { return Magenta(); }\n+  const char *Name() const { return Green(); }\n+  const char *Location() { return Green(); }\n+  const char *Thread() { return Green(); }\n+};\n+\n+static bool FindHeapAllocation(HeapAllocationsRingBuffer *rb, uptr tagged_addr,\n+                               HeapAllocationRecord *har, uptr *ring_index,\n+                               uptr *num_matching_addrs,\n+                               uptr *num_matching_addrs_4b) {\n+  if (!rb) return false;\n+\n+  *num_matching_addrs = 0;\n+  *num_matching_addrs_4b = 0;\n+  for (uptr i = 0, size = rb->size(); i < size; i++) {\n+    auto h = (*rb)[i];\n+    if (h.tagged_addr <= tagged_addr &&\n+        h.tagged_addr + h.requested_size > tagged_addr) {\n+      *har = h;\n+      *ring_index = i;\n+      return true;\n+    }\n+\n+    // Measure the number of heap ring buffer entries that would have matched\n+    // if we had only one entry per address (e.g. if the ring buffer data was\n+    // stored at the address itself). This will help us tune the allocator\n+    // implementation for MTE.\n+    if (UntagAddr(h.tagged_addr) <= UntagAddr(tagged_addr) &&\n+        UntagAddr(h.tagged_addr) + h.requested_size > UntagAddr(tagged_addr)) {\n+      ++*num_matching_addrs;\n+    }\n+\n+    // Measure the number of heap ring buffer entries that would have matched\n+    // if we only had 4 tag bits, which is the case for MTE.\n+    auto untag_4b = [](uptr p) {\n+      return p & ((1ULL << 60) - 1);\n+    };\n+    if (untag_4b(h.tagged_addr) <= untag_4b(tagged_addr) &&\n+        untag_4b(h.tagged_addr) + h.requested_size > untag_4b(tagged_addr)) {\n+      ++*num_matching_addrs_4b;\n+    }\n+  }\n+  return false;\n+}\n+\n+static void PrintStackAllocations(StackAllocationsRingBuffer *sa,\n+                                  tag_t addr_tag, uptr untagged_addr) {\n+  uptr frames = Min((uptr)flags()->stack_history_size, sa->size());\n+  bool found_local = false;\n+  for (uptr i = 0; i < frames; i++) {\n+    const uptr *record_addr = &(*sa)[i];\n+    uptr record = *record_addr;\n+    if (!record)\n+      break;\n+    tag_t base_tag =\n+        reinterpret_cast<uptr>(record_addr) >> kRecordAddrBaseTagShift;\n+    uptr fp = (record >> kRecordFPShift) << kRecordFPLShift;\n+    uptr pc_mask = (1ULL << kRecordFPShift) - 1;\n+    uptr pc = record & pc_mask;\n+    FrameInfo frame;\n+    if (Symbolizer::GetOrInit()->SymbolizeFrame(pc, &frame)) {\n+      for (LocalInfo &local : frame.locals) {\n+        if (!local.has_frame_offset || !local.has_size || !local.has_tag_offset)\n+          continue;\n+        tag_t obj_tag = base_tag ^ local.tag_offset;\n+        if (obj_tag != addr_tag)\n+          continue;\n+        // Calculate the offset from the object address to the faulting\n+        // address. Because we only store bits 4-19 of FP (bits 0-3 are\n+        // guaranteed to be zero), the calculation is performed mod 2^20 and may\n+        // harmlessly underflow if the address mod 2^20 is below the object\n+        // address.\n+        uptr obj_offset =\n+            (untagged_addr - fp - local.frame_offset) & (kRecordFPModulus - 1);\n+        if (obj_offset >= local.size)\n+          continue;\n+        if (!found_local) {\n+          Printf(\"Potentially referenced stack objects:\\n\");\n+          found_local = true;\n+        }\n+        Printf(\"  %s in %s %s:%d\\n\", local.name, local.function_name,\n+               local.decl_file, local.decl_line);\n+      }\n+      frame.Clear();\n+    }\n+  }\n+\n+  if (found_local)\n+    return;\n+\n+  // We didn't find any locals. Most likely we don't have symbols, so dump\n+  // the information that we have for offline analysis.\n+  InternalScopedString frame_desc(GetPageSizeCached() * 2);\n+  Printf(\"Previously allocated frames:\\n\");\n+  for (uptr i = 0; i < frames; i++) {\n+    const uptr *record_addr = &(*sa)[i];\n+    uptr record = *record_addr;\n+    if (!record)\n+      break;\n+    uptr pc_mask = (1ULL << 48) - 1;\n+    uptr pc = record & pc_mask;\n+    frame_desc.append(\"  record_addr:0x%zx record:0x%zx\",\n+                      reinterpret_cast<uptr>(record_addr), record);\n+    if (SymbolizedStack *frame = Symbolizer::GetOrInit()->SymbolizePC(pc)) {\n+      RenderFrame(&frame_desc, \" %F %L\\n\", 0, frame->info.address, &frame->info,\n+                  common_flags()->symbolize_vs_style,\n+                  common_flags()->strip_path_prefix);\n+      frame->ClearAll();\n+    }\n+    Printf(\"%s\", frame_desc.data());\n+    frame_desc.clear();\n+  }\n+}\n+\n+// Returns true if tag == *tag_ptr, reading tags from short granules if\n+// necessary. This may return a false positive if tags 1-15 are used as a\n+// regular tag rather than a short granule marker.\n+static bool TagsEqual(tag_t tag, tag_t *tag_ptr) {\n+  if (tag == *tag_ptr)\n+    return true;\n+  if (*tag_ptr == 0 || *tag_ptr > kShadowAlignment - 1)\n+    return false;\n+  uptr mem = ShadowToMem(reinterpret_cast<uptr>(tag_ptr));\n+  tag_t inline_tag = *reinterpret_cast<tag_t *>(mem + kShadowAlignment - 1);\n+  return tag == inline_tag;\n+}\n+\n+// HWASan globals store the size of the global in the descriptor. In cases where\n+// we don't have a binary with symbols, we can't grab the size of the global\n+// from the debug info - but we might be able to retrieve it from the\n+// descriptor. Returns zero if the lookup failed.\n+static uptr GetGlobalSizeFromDescriptor(uptr ptr) {\n+  // Find the ELF object that this global resides in.\n+  Dl_info info;\n+  dladdr(reinterpret_cast<void *>(ptr), &info);\n+  auto *ehdr = reinterpret_cast<const ElfW(Ehdr) *>(info.dli_fbase);\n+  auto *phdr_begin = reinterpret_cast<const ElfW(Phdr) *>(\n+      reinterpret_cast<const u8 *>(ehdr) + ehdr->e_phoff);\n+\n+  // Get the load bias. This is normally the same as the dli_fbase address on\n+  // position-independent code, but can be different on non-PIE executables,\n+  // binaries using LLD's partitioning feature, or binaries compiled with a\n+  // linker script.\n+  ElfW(Addr) load_bias = 0;\n+  for (const auto &phdr :\n+       ArrayRef<const ElfW(Phdr)>(phdr_begin, phdr_begin + ehdr->e_phnum)) {\n+    if (phdr.p_type != PT_LOAD || phdr.p_offset != 0)\n+      continue;\n+    load_bias = reinterpret_cast<ElfW(Addr)>(ehdr) - phdr.p_vaddr;\n+    break;\n+  }\n+\n+  // Walk all globals in this ELF object, looking for the one we're interested\n+  // in. Once we find it, we can stop iterating and return the size of the\n+  // global we're interested in.\n+  for (const hwasan_global &global :\n+       HwasanGlobalsFor(load_bias, phdr_begin, ehdr->e_phnum))\n+    if (global.addr() <= ptr && ptr < global.addr() + global.size())\n+      return global.size();\n+\n+  return 0;\n+}\n+\n+void PrintAddressDescription(\n+    uptr tagged_addr, uptr access_size,\n+    StackAllocationsRingBuffer *current_stack_allocations) {\n+  Decorator d;\n+  int num_descriptions_printed = 0;\n+  uptr untagged_addr = UntagAddr(tagged_addr);\n+\n+  // Print some very basic information about the address, if it's a heap.\n+  HwasanChunkView chunk = FindHeapChunkByAddress(untagged_addr);\n+  if (uptr beg = chunk.Beg()) {\n+    uptr size = chunk.ActualSize();\n+    Printf(\"%s[%p,%p) is a %s %s heap chunk; \"\n+           \"size: %zd offset: %zd\\n%s\",\n+           d.Location(),\n+           beg, beg + size,\n+           chunk.FromSmallHeap() ? \"small\" : \"large\",\n+           chunk.IsAllocated() ? \"allocated\" : \"unallocated\",\n+           size, untagged_addr - beg,\n+           d.Default());\n+  }\n+\n+  // Check if this looks like a heap buffer overflow by scanning\n+  // the shadow left and right and looking for the first adjacent\n+  // object with a different memory tag. If that tag matches addr_tag,\n+  // check the allocator if it has a live chunk there.\n+  tag_t addr_tag = GetTagFromPointer(tagged_addr);\n+  tag_t *tag_ptr = reinterpret_cast<tag_t*>(MemToShadow(untagged_addr));\n+  tag_t *candidate = nullptr, *left = tag_ptr, *right = tag_ptr;\n+  for (int i = 0; i < 1000; i++) {\n+    if (TagsEqual(addr_tag, left)) {\n+      candidate = left;\n+      break;\n+    }\n+    --left;\n+    if (TagsEqual(addr_tag, right)) {\n+      candidate = right;\n+      break;\n+    }\n+    ++right;\n+  }\n+\n+  if (candidate) {\n+    uptr mem = ShadowToMem(reinterpret_cast<uptr>(candidate));\n+    HwasanChunkView chunk = FindHeapChunkByAddress(mem);\n+    if (chunk.IsAllocated()) {\n+      Printf(\"%s\", d.Location());\n+      Printf(\"%p is located %zd bytes to the %s of %zd-byte region [%p,%p)\\n\",\n+             untagged_addr,\n+             candidate == left ? untagged_addr - chunk.End()\n+                               : chunk.Beg() - untagged_addr,\n+             candidate == left ? \"right\" : \"left\", chunk.UsedSize(),\n+             chunk.Beg(), chunk.End());\n+      Printf(\"%s\", d.Allocation());\n+      Printf(\"allocated here:\\n\");\n+      Printf(\"%s\", d.Default());\n+      GetStackTraceFromId(chunk.GetAllocStackId()).Print();\n+      num_descriptions_printed++;\n+    } else {\n+      // Check whether the address points into a loaded library. If so, this is\n+      // most likely a global variable.\n+      const char *module_name;\n+      uptr module_address;\n+      Symbolizer *sym = Symbolizer::GetOrInit();\n+      if (sym->GetModuleNameAndOffsetForPC(mem, &module_name,\n+                                           &module_address)) {\n+        DataInfo info;\n+        if (sym->SymbolizeData(mem, &info) && info.start) {\n+          Printf(\n+              \"%p is located %zd bytes to the %s of %zd-byte global variable \"\n+              \"%s [%p,%p) in %s\\n\",\n+              untagged_addr,\n+              candidate == left ? untagged_addr - (info.start + info.size)\n+                                : info.start - untagged_addr,\n+              candidate == left ? \"right\" : \"left\", info.size, info.name,\n+              info.start, info.start + info.size, module_name);\n+        } else {\n+          uptr size = GetGlobalSizeFromDescriptor(mem);\n+          if (size == 0)\n+            // We couldn't find the size of the global from the descriptors.\n+            Printf(\n+                \"%p is located to the %s of a global variable in (%s+0x%x)\\n\",\n+                untagged_addr, candidate == left ? \"right\" : \"left\",\n+                module_name, module_address);\n+          else\n+            Printf(\n+                \"%p is located to the %s of a %zd-byte global variable in \"\n+                \"(%s+0x%x)\\n\",\n+                untagged_addr, candidate == left ? \"right\" : \"left\", size,\n+                module_name, module_address);\n+        }\n+        num_descriptions_printed++;\n+      }\n+    }\n+  }\n+\n+  hwasanThreadList().VisitAllLiveThreads([&](Thread *t) {\n+    // Scan all threads' ring buffers to find if it's a heap-use-after-free.\n+    HeapAllocationRecord har;\n+    uptr ring_index, num_matching_addrs, num_matching_addrs_4b;\n+    if (FindHeapAllocation(t->heap_allocations(), tagged_addr, &har,\n+                           &ring_index, &num_matching_addrs,\n+                           &num_matching_addrs_4b)) {\n+      Printf(\"%s\", d.Location());\n+      Printf(\"%p is located %zd bytes inside of %zd-byte region [%p,%p)\\n\",\n+             untagged_addr, untagged_addr - UntagAddr(har.tagged_addr),\n+             har.requested_size, UntagAddr(har.tagged_addr),\n+             UntagAddr(har.tagged_addr) + har.requested_size);\n+      Printf(\"%s\", d.Allocation());\n+      Printf(\"freed by thread T%zd here:\\n\", t->unique_id());\n+      Printf(\"%s\", d.Default());\n+      GetStackTraceFromId(har.free_context_id).Print();\n+\n+      Printf(\"%s\", d.Allocation());\n+      Printf(\"previously allocated here:\\n\", t);\n+      Printf(\"%s\", d.Default());\n+      GetStackTraceFromId(har.alloc_context_id).Print();\n+\n+      // Print a developer note: the index of this heap object\n+      // in the thread's deallocation ring buffer.\n+      Printf(\"hwasan_dev_note_heap_rb_distance: %zd %zd\\n\", ring_index + 1,\n+             flags()->heap_history_size);\n+      Printf(\"hwasan_dev_note_num_matching_addrs: %zd\\n\", num_matching_addrs);\n+      Printf(\"hwasan_dev_note_num_matching_addrs_4b: %zd\\n\",\n+             num_matching_addrs_4b);\n+\n+      t->Announce();\n+      num_descriptions_printed++;\n+    }\n+\n+    // Very basic check for stack memory.\n+    if (t->AddrIsInStack(untagged_addr)) {\n+      Printf(\"%s\", d.Location());\n+      Printf(\"Address %p is located in stack of thread T%zd\\n\", untagged_addr,\n+             t->unique_id());\n+      Printf(\"%s\", d.Default());\n+      t->Announce();\n+\n+      auto *sa = (t == GetCurrentThread() && current_stack_allocations)\n+                     ? current_stack_allocations\n+                     : t->stack_allocations();\n+      PrintStackAllocations(sa, addr_tag, untagged_addr);\n+      num_descriptions_printed++;\n+    }\n+  });\n+\n+  // Print the remaining threads, as an extra information, 1 line per thread.\n+  hwasanThreadList().VisitAllLiveThreads([&](Thread *t) { t->Announce(); });\n+\n+  if (!num_descriptions_printed)\n+    // We exhausted our possibilities. Bail out.\n+    Printf(\"HWAddressSanitizer can not describe address in more detail.\\n\");\n+}\n+\n+void ReportStats() {}\n+\n+static void PrintTagInfoAroundAddr(tag_t *tag_ptr, uptr num_rows,\n+                                   void (*print_tag)(InternalScopedString &s,\n+                                                     tag_t *tag)) {\n+  const uptr row_len = 16;  // better be power of two.\n+  tag_t *center_row_beg = reinterpret_cast<tag_t *>(\n+      RoundDownTo(reinterpret_cast<uptr>(tag_ptr), row_len));\n+  tag_t *beg_row = center_row_beg - row_len * (num_rows / 2);\n+  tag_t *end_row = center_row_beg + row_len * ((num_rows + 1) / 2);\n+  InternalScopedString s(GetPageSizeCached() * 8);\n+  for (tag_t *row = beg_row; row < end_row; row += row_len) {\n+    s.append(\"%s\", row == center_row_beg ? \"=>\" : \"  \");\n+    s.append(\"%p:\", row);\n+    for (uptr i = 0; i < row_len; i++) {\n+      s.append(\"%s\", row + i == tag_ptr ? \"[\" : \" \");\n+      print_tag(s, &row[i]);\n+      s.append(\"%s\", row + i == tag_ptr ? \"]\" : \" \");\n+    }\n+    s.append(\"\\n\");\n+  }\n+  Printf(\"%s\", s.data());\n+}\n+\n+static void PrintTagsAroundAddr(tag_t *tag_ptr) {\n+  Printf(\n+      \"Memory tags around the buggy address (one tag corresponds to %zd \"\n+      \"bytes):\\n\", kShadowAlignment);\n+  PrintTagInfoAroundAddr(tag_ptr, 17, [](InternalScopedString &s, tag_t *tag) {\n+    s.append(\"%02x\", *tag);\n+  });\n+\n+  Printf(\n+      \"Tags for short granules around the buggy address (one tag corresponds \"\n+      \"to %zd bytes):\\n\",\n+      kShadowAlignment);\n+  PrintTagInfoAroundAddr(tag_ptr, 3, [](InternalScopedString &s, tag_t *tag) {\n+    if (*tag >= 1 && *tag <= kShadowAlignment) {\n+      uptr granule_addr = ShadowToMem(reinterpret_cast<uptr>(tag));\n+      s.append(\"%02x\",\n+               *reinterpret_cast<u8 *>(granule_addr + kShadowAlignment - 1));\n+    } else {\n+      s.append(\"..\");\n+    }\n+  });\n+  Printf(\n+      \"See \"\n+      \"https://clang.llvm.org/docs/\"\n+      \"HardwareAssistedAddressSanitizerDesign.html#short-granules for a \"\n+      \"description of short granule tags\\n\");\n+}\n+\n+void ReportInvalidFree(StackTrace *stack, uptr tagged_addr) {\n+  ScopedReport R(flags()->halt_on_error);\n+\n+  uptr untagged_addr = UntagAddr(tagged_addr);\n+  tag_t ptr_tag = GetTagFromPointer(tagged_addr);\n+  tag_t *tag_ptr = reinterpret_cast<tag_t*>(MemToShadow(untagged_addr));\n+  tag_t mem_tag = *tag_ptr;\n+  Decorator d;\n+  Printf(\"%s\", d.Error());\n+  uptr pc = stack->size ? stack->trace[0] : 0;\n+  const char *bug_type = \"invalid-free\";\n+  Report(\"ERROR: %s: %s on address %p at pc %p\\n\", SanitizerToolName, bug_type,\n+         untagged_addr, pc);\n+  Printf(\"%s\", d.Access());\n+  Printf(\"tags: %02x/%02x (ptr/mem)\\n\", ptr_tag, mem_tag);\n+  Printf(\"%s\", d.Default());\n+\n+  stack->Print();\n+\n+  PrintAddressDescription(tagged_addr, 0, nullptr);\n+\n+  PrintTagsAroundAddr(tag_ptr);\n+\n+  ReportErrorSummary(bug_type, stack);\n+}\n+\n+void ReportTailOverwritten(StackTrace *stack, uptr tagged_addr, uptr orig_size,\n+                           const u8 *expected) {\n+  uptr tail_size = kShadowAlignment - (orig_size % kShadowAlignment);\n+  ScopedReport R(flags()->halt_on_error);\n+  Decorator d;\n+  uptr untagged_addr = UntagAddr(tagged_addr);\n+  Printf(\"%s\", d.Error());\n+  const char *bug_type = \"allocation-tail-overwritten\";\n+  Report(\"ERROR: %s: %s; heap object [%p,%p) of size %zd\\n\", SanitizerToolName,\n+         bug_type, untagged_addr, untagged_addr + orig_size, orig_size);\n+  Printf(\"\\n%s\", d.Default());\n+  stack->Print();\n+  HwasanChunkView chunk = FindHeapChunkByAddress(untagged_addr);\n+  if (chunk.Beg()) {\n+    Printf(\"%s\", d.Allocation());\n+    Printf(\"allocated here:\\n\");\n+    Printf(\"%s\", d.Default());\n+    GetStackTraceFromId(chunk.GetAllocStackId()).Print();\n+  }\n+\n+  InternalScopedString s(GetPageSizeCached() * 8);\n+  CHECK_GT(tail_size, 0U);\n+  CHECK_LT(tail_size, kShadowAlignment);\n+  u8 *tail = reinterpret_cast<u8*>(untagged_addr + orig_size);\n+  s.append(\"Tail contains: \");\n+  for (uptr i = 0; i < kShadowAlignment - tail_size; i++)\n+    s.append(\".. \");\n+  for (uptr i = 0; i < tail_size; i++)\n+    s.append(\"%02x \", tail[i]);\n+  s.append(\"\\n\");\n+  s.append(\"Expected:      \");\n+  for (uptr i = 0; i < kShadowAlignment - tail_size; i++)\n+    s.append(\".. \");\n+  for (uptr i = 0; i < tail_size; i++)\n+    s.append(\"%02x \", expected[i]);\n+  s.append(\"\\n\");\n+  s.append(\"               \");\n+  for (uptr i = 0; i < kShadowAlignment - tail_size; i++)\n+    s.append(\"   \");\n+  for (uptr i = 0; i < tail_size; i++)\n+    s.append(\"%s \", expected[i] != tail[i] ? \"^^\" : \"  \");\n+\n+  s.append(\"\\nThis error occurs when a buffer overflow overwrites memory\\n\"\n+    \"to the right of a heap object, but within the %zd-byte granule, e.g.\\n\"\n+    \"   char *x = new char[20];\\n\"\n+    \"   x[25] = 42;\\n\"\n+    \"%s does not detect such bugs in uninstrumented code at the time of write,\"\n+    \"\\nbut can detect them at the time of free/delete.\\n\"\n+    \"To disable this feature set HWASAN_OPTIONS=free_checks_tail_magic=0\\n\",\n+    kShadowAlignment, SanitizerToolName);\n+  Printf(\"%s\", s.data());\n+  GetCurrentThread()->Announce();\n+\n+  tag_t *tag_ptr = reinterpret_cast<tag_t*>(MemToShadow(untagged_addr));\n+  PrintTagsAroundAddr(tag_ptr);\n+\n+  ReportErrorSummary(bug_type, stack);\n+}\n+\n+void ReportTagMismatch(StackTrace *stack, uptr tagged_addr, uptr access_size,\n+                       bool is_store, bool fatal, uptr *registers_frame) {\n+  ScopedReport R(fatal);\n+  SavedStackAllocations current_stack_allocations(\n+      GetCurrentThread()->stack_allocations());\n+\n+  Decorator d;\n+  Printf(\"%s\", d.Error());\n+  uptr untagged_addr = UntagAddr(tagged_addr);\n+  // TODO: when possible, try to print heap-use-after-free, etc.\n+  const char *bug_type = \"tag-mismatch\";\n+  uptr pc = stack->size ? stack->trace[0] : 0;\n+  Report(\"ERROR: %s: %s on address %p at pc %p\\n\", SanitizerToolName, bug_type,\n+         untagged_addr, pc);\n+\n+  Thread *t = GetCurrentThread();\n+\n+  sptr offset =\n+      __hwasan_test_shadow(reinterpret_cast<void *>(tagged_addr), access_size);\n+  CHECK(offset >= 0 && offset < static_cast<sptr>(access_size));\n+  tag_t ptr_tag = GetTagFromPointer(tagged_addr);\n+  tag_t *tag_ptr =\n+      reinterpret_cast<tag_t *>(MemToShadow(untagged_addr + offset));\n+  tag_t mem_tag = *tag_ptr;\n+\n+  Printf(\"%s\", d.Access());\n+  Printf(\"%s of size %zu at %p tags: %02x/%02x (ptr/mem) in thread T%zd\\n\",\n+         is_store ? \"WRITE\" : \"READ\", access_size, untagged_addr, ptr_tag,\n+         mem_tag, t->unique_id());\n+  if (offset != 0)\n+    Printf(\"Invalid access starting at offset [%zu, %zu)\\n\", offset,\n+           Min(access_size, static_cast<uptr>(offset) + (1 << kShadowScale)));\n+  Printf(\"%s\", d.Default());\n+\n+  stack->Print();\n+\n+  PrintAddressDescription(tagged_addr, access_size,\n+                          current_stack_allocations.get());\n+  t->Announce();\n+\n+  PrintTagsAroundAddr(tag_ptr);\n+\n+  if (registers_frame)\n+    ReportRegisters(registers_frame, pc);\n+\n+  ReportErrorSummary(bug_type, stack);\n+}\n+\n+// See the frame breakdown defined in __hwasan_tag_mismatch (from\n+// hwasan_tag_mismatch_aarch64.S).\n+void ReportRegisters(uptr *frame, uptr pc) {\n+  Printf(\"Registers where the failure occurred (pc %p):\\n\", pc);\n+\n+  // We explicitly print a single line (4 registers/line) each iteration to\n+  // reduce the amount of logcat error messages printed. Each Printf() will\n+  // result in a new logcat line, irrespective of whether a newline is present,\n+  // and so we wish to reduce the number of Printf() calls we have to make.\n+  Printf(\"    x0  %016llx  x1  %016llx  x2  %016llx  x3  %016llx\\n\",\n+       frame[0], frame[1], frame[2], frame[3]);\n+  Printf(\"    x4  %016llx  x5  %016llx  x6  %016llx  x7  %016llx\\n\",\n+       frame[4], frame[5], frame[6], frame[7]);\n+  Printf(\"    x8  %016llx  x9  %016llx  x10 %016llx  x11 %016llx\\n\",\n+       frame[8], frame[9], frame[10], frame[11]);\n+  Printf(\"    x12 %016llx  x13 %016llx  x14 %016llx  x15 %016llx\\n\",\n+       frame[12], frame[13], frame[14], frame[15]);\n+  Printf(\"    x16 %016llx  x17 %016llx  x18 %016llx  x19 %016llx\\n\",\n+       frame[16], frame[17], frame[18], frame[19]);\n+  Printf(\"    x20 %016llx  x21 %016llx  x22 %016llx  x23 %016llx\\n\",\n+       frame[20], frame[21], frame[22], frame[23]);\n+  Printf(\"    x24 %016llx  x25 %016llx  x26 %016llx  x27 %016llx\\n\",\n+       frame[24], frame[25], frame[26], frame[27]);\n+  Printf(\"    x28 %016llx  x29 %016llx  x30 %016llx\\n\",\n+       frame[28], frame[29], frame[30]);\n+}\n+\n+}  // namespace __hwasan"}, {"sha": "de86c38fc01f2d88bebcacb2b823f8b22894d4e3", "filename": "libsanitizer/hwasan/hwasan_report.h", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_report.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_report.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_report.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,35 @@\n+//===-- hwasan_report.h -----------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+///\n+/// \\file\n+/// This file is a part of HWAddressSanitizer. HWASan-private header for error\n+/// reporting functions.\n+///\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_REPORT_H\n+#define HWASAN_REPORT_H\n+\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+#include \"sanitizer_common/sanitizer_stacktrace.h\"\n+\n+namespace __hwasan {\n+\n+void ReportStats();\n+void ReportTagMismatch(StackTrace *stack, uptr addr, uptr access_size,\n+                       bool is_store, bool fatal, uptr *registers_frame);\n+void ReportInvalidFree(StackTrace *stack, uptr addr);\n+void ReportTailOverwritten(StackTrace *stack, uptr addr, uptr orig_size,\n+                           const u8 *expected);\n+void ReportRegisters(uptr *registers_frame, uptr pc);\n+void ReportAtExitStatistics();\n+\n+\n+}  // namespace __hwasan\n+\n+#endif  // HWASAN_REPORT_H"}, {"sha": "0c1354331940e23acad1ca4becba87199a211653", "filename": "libsanitizer/hwasan/hwasan_setjmp.S", "status": "added", "additions": 100, "deletions": 0, "changes": 100, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_setjmp.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_setjmp.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_setjmp.S?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,100 @@\n+//===-- hwasan_setjmp.S --------------------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// HWAddressSanitizer runtime.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"sanitizer_common/sanitizer_asm.h\"\n+\n+#if HWASAN_WITH_INTERCEPTORS && defined(__aarch64__)\n+#include \"sanitizer_common/sanitizer_platform.h\"\n+\n+// We want to save the context of the calling function.\n+// That requires\n+// 1) No modification of the link register by this function.\n+// 2) No modification of the stack pointer by this function.\n+// 3) (no modification of any other saved register, but that's not really going\n+// to occur, and hence isn't as much of a worry).\n+//\n+// There's essentially no way to ensure that the compiler will not modify the\n+// stack pointer when compiling a C function.\n+// Hence we have to write this function in assembly.\n+\n+.section .text\n+.file \"hwasan_setjmp.S\"\n+\n+.global __interceptor_setjmp\n+ASM_TYPE_FUNCTION(__interceptor_setjmp)\n+__interceptor_setjmp:\n+  CFI_STARTPROC\n+  mov\tx1, #0\n+  b\t__interceptor_sigsetjmp\n+  CFI_ENDPROC\n+ASM_SIZE(__interceptor_setjmp)\n+\n+#if SANITIZER_ANDROID\n+// Bionic also defines a function `setjmp` that calls `sigsetjmp` saving the\n+// current signal.\n+.global __interceptor_setjmp_bionic\n+ASM_TYPE_FUNCTION(__interceptor_setjmp_bionic)\n+__interceptor_setjmp_bionic:\n+  CFI_STARTPROC\n+  mov\tx1, #1\n+  b\t__interceptor_sigsetjmp\n+  CFI_ENDPROC\n+ASM_SIZE(__interceptor_setjmp_bionic)\n+#endif\n+\n+.global __interceptor_sigsetjmp\n+ASM_TYPE_FUNCTION(__interceptor_sigsetjmp)\n+__interceptor_sigsetjmp:\n+  CFI_STARTPROC\n+  stp\tx19, x20, [x0, #0<<3]\n+  stp\tx21, x22, [x0, #2<<3]\n+  stp\tx23, x24, [x0, #4<<3]\n+  stp\tx25, x26, [x0, #6<<3]\n+  stp\tx27, x28, [x0, #8<<3]\n+  stp\tx29, x30, [x0, #10<<3]\n+  stp\t d8,  d9, [x0, #14<<3]\n+  stp\td10, d11, [x0, #16<<3]\n+  stp\td12, d13, [x0, #18<<3]\n+  stp\td14, d15, [x0, #20<<3]\n+  mov\tx2,  sp\n+  str\tx2,  [x0, #13<<3]\n+  // We always have the second argument to __sigjmp_save (savemask) set, since\n+  // the _setjmp function above has set it for us as `false`.\n+  // This function is defined in hwasan_interceptors.cc\n+  b\t__sigjmp_save\n+  CFI_ENDPROC\n+ASM_SIZE(__interceptor_sigsetjmp)\n+\n+\n+.macro ALIAS first second\n+  .globl \\second\n+  .equ \\second\\(), \\first\n+.endm\n+\n+#if SANITIZER_ANDROID\n+ALIAS __interceptor_sigsetjmp, sigsetjmp\n+.weak sigsetjmp\n+\n+ALIAS __interceptor_setjmp_bionic, setjmp\n+.weak setjmp\n+#else\n+ALIAS __interceptor_sigsetjmp, __sigsetjmp\n+.weak __sigsetjmp\n+#endif\n+\n+ALIAS __interceptor_setjmp, _setjmp\n+.weak _setjmp\n+#endif\n+\n+// We do not need executable stack.\n+NO_EXEC_STACK_DIRECTIVE"}, {"sha": "08df12736bb4cf1d510c5d0b9262cd6f6e244cda", "filename": "libsanitizer/hwasan/hwasan_tag_mismatch_aarch64.S", "status": "added", "additions": 152, "deletions": 0, "changes": 152, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_tag_mismatch_aarch64.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_tag_mismatch_aarch64.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_tag_mismatch_aarch64.S?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,152 @@\n+#include \"sanitizer_common/sanitizer_asm.h\"\n+\n+// The content of this file is AArch64-only:\n+#if defined(__aarch64__)\n+\n+// The responsibility of the HWASan entry point in compiler-rt is to primarily\n+// readjust the stack from the callee and save the current register values to\n+// the stack.\n+// This entry point function should be called from a __hwasan_check_* symbol.\n+// These are generated during a lowering pass in the backend, and are found in\n+// AArch64AsmPrinter::EmitHwasanMemaccessSymbols(). Please look there for\n+// further information.\n+// The __hwasan_check_* caller of this function should have expanded the stack\n+// and saved the previous values of x0, x1, x29, and x30. This function will\n+// \"consume\" these saved values and treats it as part of its own stack frame.\n+// In this sense, the __hwasan_check_* callee and this function \"share\" a stack\n+// frame. This allows us to omit having unwinding information (.cfi_*) present\n+// in every __hwasan_check_* function, therefore reducing binary size. This is\n+// particularly important as hwasan_check_* instances are duplicated in every\n+// translation unit where HWASan is enabled.\n+// This function calls HwasanTagMismatch to step back into the C++ code that\n+// completes the stack unwinding and error printing. This function is is not\n+// permitted to return.\n+\n+\n+// Frame from __hwasan_check_:\n+// |              ...                |\n+// |              ...                |\n+// | Previous stack frames...        |\n+// +=================================+\n+// | Unused 8-bytes for maintaining  |\n+// | 16-byte SP alignment.           |\n+// +---------------------------------+\n+// | Return address (x30) for caller |\n+// | of __hwasan_check_*.            |\n+// +---------------------------------+\n+// | Frame address (x29) for caller  |\n+// | of __hwasan_check_*             |\n+// +---------------------------------+ <-- [SP + 232]\n+// |              ...                |\n+// |                                 |\n+// | Stack frame space for x2 - x28. |\n+// |                                 |\n+// |              ...                |\n+// +---------------------------------+ <-- [SP + 16]\n+// |                                 |\n+// | Saved x1, as __hwasan_check_*   |\n+// | clobbers it.                    |\n+// +---------------------------------+\n+// | Saved x0, likewise above.       |\n+// +---------------------------------+ <-- [x30 / SP]\n+\n+// This function takes two arguments:\n+//   * x0: The data address.\n+//   * x1: The encoded access info for the failing access.\n+\n+// This function has two entry points. The first, __hwasan_tag_mismatch, is used\n+// by clients that were compiled without short tag checks (i.e. binaries built\n+// by older compilers and binaries targeting older runtimes). In this case the\n+// outlined tag check will be missing the code handling short tags (which won't\n+// be used in the binary's own stack variables but may be used on the heap\n+// or stack variables in other binaries), so the check needs to be done here.\n+//\n+// The second, __hwasan_tag_mismatch_v2, is used by binaries targeting newer\n+// runtimes. This entry point bypasses the short tag check since it will have\n+// already been done as part of the outlined tag check. Since tag mismatches are\n+// uncommon, there isn't a significant performance benefit to being able to\n+// bypass the check; the main benefits are that we can sometimes avoid\n+// clobbering the x17 register in error reports, and that the program will have\n+// a runtime dependency on the __hwasan_tag_mismatch_v2 symbol therefore it will\n+// fail to start up given an older (i.e. incompatible) runtime.\n+.section .text\n+.file \"hwasan_tag_mismatch_aarch64.S\"\n+.global __hwasan_tag_mismatch\n+.type __hwasan_tag_mismatch, %function\n+__hwasan_tag_mismatch:\n+  // Compute the granule position one past the end of the access.\n+  mov x16, #1\n+  and x17, x1, #0xf\n+  lsl x16, x16, x17\n+  and x17, x0, #0xf\n+  add x17, x16, x17\n+\n+  // Load the shadow byte again and check whether it is a short tag within the\n+  // range of the granule position computed above.\n+  ubfx x16, x0, #4, #52\n+  ldrb w16, [x9, x16]\n+  cmp w16, #0xf\n+  b.hi __hwasan_tag_mismatch_v2\n+  cmp w16, w17\n+  b.lo __hwasan_tag_mismatch_v2\n+\n+  // Load the real tag from the last byte of the granule and compare against\n+  // the pointer tag.\n+  orr x16, x0, #0xf\n+  ldrb w16, [x16]\n+  cmp x16, x0, lsr #56\n+  b.ne __hwasan_tag_mismatch_v2\n+\n+  // Restore x0, x1 and sp to their values from before the __hwasan_tag_mismatch\n+  // call and resume execution.\n+  ldp x0, x1, [sp], #256\n+  ret\n+\n+.global __hwasan_tag_mismatch_v2\n+.type __hwasan_tag_mismatch_v2, %function\n+__hwasan_tag_mismatch_v2:\n+  CFI_STARTPROC\n+\n+  // Set the CFA to be the return address for caller of __hwasan_check_*. Note\n+  // that we do not emit CFI predicates to describe the contents of this stack\n+  // frame, as this proxy entry point should never be debugged. The contents\n+  // are static and are handled by the unwinder after calling\n+  // __hwasan_tag_mismatch. The frame pointer is already correctly setup\n+  // by __hwasan_check_*.\n+  add x29, sp, #232\n+  CFI_DEF_CFA(w29, 24)\n+  CFI_OFFSET(w30, -16)\n+  CFI_OFFSET(w29, -24)\n+\n+  // Save the rest of the registers into the preallocated space left by\n+  // __hwasan_check.\n+  str     x28,      [sp, #224]\n+  stp     x26, x27, [sp, #208]\n+  stp     x24, x25, [sp, #192]\n+  stp     x22, x23, [sp, #176]\n+  stp     x20, x21, [sp, #160]\n+  stp     x18, x19, [sp, #144]\n+  stp     x16, x17, [sp, #128]\n+  stp     x14, x15, [sp, #112]\n+  stp     x12, x13, [sp, #96]\n+  stp     x10, x11, [sp, #80]\n+  stp     x8,  x9,  [sp, #64]\n+  stp     x6,  x7,  [sp, #48]\n+  stp     x4,  x5,  [sp, #32]\n+  stp     x2,  x3,  [sp, #16]\n+\n+  // Pass the address of the frame to __hwasan_tag_mismatch4, so that it can\n+  // extract the saved registers from this frame without having to worry about\n+  // finding this frame.\n+  mov x2, sp\n+\n+  bl __hwasan_tag_mismatch4\n+  CFI_ENDPROC\n+\n+.Lfunc_end0:\n+  .size __hwasan_tag_mismatch, .Lfunc_end0-__hwasan_tag_mismatch\n+\n+#endif  // defined(__aarch64__)\n+\n+// We do not need executable stack.\n+NO_EXEC_STACK_DIRECTIVE"}, {"sha": "b81a6350c05c0d854c744ed986ed8b587bcc4ed9", "filename": "libsanitizer/hwasan/hwasan_thread.cpp", "status": "added", "additions": 133, "deletions": 0, "changes": 133, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_thread.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,133 @@\n+\n+#include \"hwasan.h\"\n+#include \"hwasan_mapping.h\"\n+#include \"hwasan_thread.h\"\n+#include \"hwasan_poisoning.h\"\n+#include \"hwasan_interface_internal.h\"\n+\n+#include \"sanitizer_common/sanitizer_file.h\"\n+#include \"sanitizer_common/sanitizer_placement_new.h\"\n+#include \"sanitizer_common/sanitizer_tls_get_addr.h\"\n+\n+\n+namespace __hwasan {\n+\n+static u32 RandomSeed() {\n+  u32 seed;\n+  do {\n+    if (UNLIKELY(!GetRandom(reinterpret_cast<void *>(&seed), sizeof(seed),\n+                            /*blocking=*/false))) {\n+      seed = static_cast<u32>(\n+          (NanoTime() >> 12) ^\n+          (reinterpret_cast<uptr>(__builtin_frame_address(0)) >> 4));\n+    }\n+  } while (!seed);\n+  return seed;\n+}\n+\n+void Thread::InitRandomState() {\n+  random_state_ = flags()->random_tags ? RandomSeed() : unique_id_;\n+\n+  // Push a random number of zeros onto the ring buffer so that the first stack\n+  // tag base will be random.\n+  for (tag_t i = 0, e = GenerateRandomTag(); i != e; ++i)\n+    stack_allocations_->push(0);\n+}\n+\n+void Thread::Init(uptr stack_buffer_start, uptr stack_buffer_size) {\n+  static u64 unique_id;\n+  unique_id_ = unique_id++;\n+  if (auto sz = flags()->heap_history_size)\n+    heap_allocations_ = HeapAllocationsRingBuffer::New(sz);\n+\n+  HwasanTSDThreadInit();  // Only needed with interceptors.\n+  uptr *ThreadLong = GetCurrentThreadLongPtr();\n+  // The following implicitly sets (this) as the current thread.\n+  stack_allocations_ = new (ThreadLong)\n+      StackAllocationsRingBuffer((void *)stack_buffer_start, stack_buffer_size);\n+  // Check that it worked.\n+  CHECK_EQ(GetCurrentThread(), this);\n+\n+  // ScopedTaggingDisable needs GetCurrentThread to be set up.\n+  ScopedTaggingDisabler disabler;\n+\n+  uptr tls_size;\n+  uptr stack_size;\n+  GetThreadStackAndTls(IsMainThread(), &stack_bottom_, &stack_size, &tls_begin_,\n+                       &tls_size);\n+  stack_top_ = stack_bottom_ + stack_size;\n+  tls_end_ = tls_begin_ + tls_size;\n+\n+  if (stack_bottom_) {\n+    int local;\n+    CHECK(AddrIsInStack((uptr)&local));\n+    CHECK(MemIsApp(stack_bottom_));\n+    CHECK(MemIsApp(stack_top_ - 1));\n+  }\n+\n+  if (flags()->verbose_threads) {\n+    if (IsMainThread()) {\n+      Printf(\"sizeof(Thread): %zd sizeof(HeapRB): %zd sizeof(StackRB): %zd\\n\",\n+             sizeof(Thread), heap_allocations_->SizeInBytes(),\n+             stack_allocations_->size() * sizeof(uptr));\n+    }\n+    Print(\"Creating  : \");\n+  }\n+}\n+\n+void Thread::ClearShadowForThreadStackAndTLS() {\n+  if (stack_top_ != stack_bottom_)\n+    TagMemory(stack_bottom_, stack_top_ - stack_bottom_, 0);\n+  if (tls_begin_ != tls_end_)\n+    TagMemory(tls_begin_, tls_end_ - tls_begin_, 0);\n+}\n+\n+void Thread::Destroy() {\n+  if (flags()->verbose_threads)\n+    Print(\"Destroying: \");\n+  AllocatorSwallowThreadLocalCache(allocator_cache());\n+  ClearShadowForThreadStackAndTLS();\n+  if (heap_allocations_)\n+    heap_allocations_->Delete();\n+  DTLS_Destroy();\n+  // Unregister this as the current thread.\n+  // Instrumented code can not run on this thread from this point onwards, but\n+  // malloc/free can still be served. Glibc may call free() very late, after all\n+  // TSD destructors are done.\n+  CHECK_EQ(GetCurrentThread(), this);\n+  *GetCurrentThreadLongPtr() = 0;\n+}\n+\n+void Thread::Print(const char *Prefix) {\n+  Printf(\"%sT%zd %p stack: [%p,%p) sz: %zd tls: [%p,%p)\\n\", Prefix,\n+         unique_id_, this, stack_bottom(), stack_top(),\n+         stack_top() - stack_bottom(),\n+         tls_begin(), tls_end());\n+}\n+\n+static u32 xorshift(u32 state) {\n+  state ^= state << 13;\n+  state ^= state >> 17;\n+  state ^= state << 5;\n+  return state;\n+}\n+\n+// Generate a (pseudo-)random non-zero tag.\n+tag_t Thread::GenerateRandomTag() {\n+  if (tagging_disabled_) return 0;\n+  tag_t tag;\n+  do {\n+    if (flags()->random_tags) {\n+      if (!random_buffer_)\n+        random_buffer_ = random_state_ = xorshift(random_state_);\n+      CHECK(random_buffer_);\n+      tag = random_buffer_ & 0xFF;\n+      random_buffer_ >>= 8;\n+    } else {\n+      tag = random_state_ = (random_state_ + 1) & 0xFF;\n+    }\n+  } while (!tag);\n+  return tag;\n+}\n+\n+} // namespace __hwasan"}, {"sha": "ebcdb791fb36733aa6f23cc5d4a0fce3a0516667", "filename": "libsanitizer/hwasan/hwasan_thread.h", "status": "added", "additions": 98, "deletions": 0, "changes": 98, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_thread.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,98 @@\n+//===-- hwasan_thread.h -----------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef HWASAN_THREAD_H\n+#define HWASAN_THREAD_H\n+\n+#include \"hwasan_allocator.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_ring_buffer.h\"\n+\n+namespace __hwasan {\n+\n+typedef __sanitizer::CompactRingBuffer<uptr> StackAllocationsRingBuffer;\n+\n+class Thread {\n+ public:\n+  void Init(uptr stack_buffer_start, uptr stack_buffer_size);  // Must be called from the thread itself.\n+  void InitRandomState();\n+  void Destroy();\n+\n+  uptr stack_top() { return stack_top_; }\n+  uptr stack_bottom() { return stack_bottom_; }\n+  uptr stack_size() { return stack_top() - stack_bottom(); }\n+  uptr tls_begin() { return tls_begin_; }\n+  uptr tls_end() { return tls_end_; }\n+  bool IsMainThread() { return unique_id_ == 0; }\n+\n+  bool AddrIsInStack(uptr addr) {\n+    return addr >= stack_bottom_ && addr < stack_top_;\n+  }\n+\n+  AllocatorCache *allocator_cache() { return &allocator_cache_; }\n+  HeapAllocationsRingBuffer *heap_allocations() { return heap_allocations_; }\n+  StackAllocationsRingBuffer *stack_allocations() { return stack_allocations_; }\n+\n+  tag_t GenerateRandomTag();\n+\n+  void DisableTagging() { tagging_disabled_++; }\n+  void EnableTagging() { tagging_disabled_--; }\n+\n+  u64 unique_id() const { return unique_id_; }\n+  void Announce() {\n+    if (announced_) return;\n+    announced_ = true;\n+    Print(\"Thread: \");\n+  }\n+\n+  uptr &vfork_spill() { return vfork_spill_; }\n+\n+ private:\n+  // NOTE: There is no Thread constructor. It is allocated\n+  // via mmap() and *must* be valid in zero-initialized state.\n+  void ClearShadowForThreadStackAndTLS();\n+  void Print(const char *prefix);\n+  uptr vfork_spill_;\n+  uptr stack_top_;\n+  uptr stack_bottom_;\n+  uptr tls_begin_;\n+  uptr tls_end_;\n+\n+  u32 random_state_;\n+  u32 random_buffer_;\n+\n+  AllocatorCache allocator_cache_;\n+  HeapAllocationsRingBuffer *heap_allocations_;\n+  StackAllocationsRingBuffer *stack_allocations_;\n+\n+  Thread *next_;  // All live threads form a linked list.\n+\n+  u64 unique_id_;  // counting from zero.\n+\n+  u32 tagging_disabled_;  // if non-zero, malloc uses zero tag in this thread.\n+\n+  bool announced_;\n+\n+  friend struct ThreadListHead;\n+};\n+\n+Thread *GetCurrentThread();\n+uptr *GetCurrentThreadLongPtr();\n+\n+struct ScopedTaggingDisabler {\n+  ScopedTaggingDisabler() { GetCurrentThread()->DisableTagging(); }\n+  ~ScopedTaggingDisabler() { GetCurrentThread()->EnableTagging(); }\n+};\n+\n+} // namespace __hwasan\n+\n+#endif // HWASAN_THREAD_H"}, {"sha": "a31eee84ed9375d12d55f1d374b2703464a04801", "filename": "libsanitizer/hwasan/hwasan_thread_list.cpp", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread_list.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread_list.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_thread_list.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,15 @@\n+#include \"hwasan_thread_list.h\"\n+\n+namespace __hwasan {\n+static ALIGNED(16) char thread_list_placeholder[sizeof(HwasanThreadList)];\n+static HwasanThreadList *hwasan_thread_list;\n+\n+HwasanThreadList &hwasanThreadList() { return *hwasan_thread_list; }\n+\n+void InitThreadList(uptr storage, uptr size) {\n+  CHECK(hwasan_thread_list == nullptr);\n+  hwasan_thread_list =\n+      new (thread_list_placeholder) HwasanThreadList(storage, size);\n+}\n+\n+} // namespace"}, {"sha": "914b632d9776a1620ffd9240ccbd7de315b91968", "filename": "libsanitizer/hwasan/hwasan_thread_list.h", "status": "added", "additions": 215, "deletions": 0, "changes": 215, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread_list.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_thread_list.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_thread_list.h?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,215 @@\n+//===-- hwasan_thread_list.h ------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+// HwasanThreadList is a registry for live threads, as well as an allocator for\n+// HwasanThread objects and their stack history ring buffers. There are\n+// constraints on memory layout of the shadow region and CompactRingBuffer that\n+// are part of the ABI contract between compiler-rt and llvm.\n+//\n+// * Start of the shadow memory region is aligned to 2**kShadowBaseAlignment.\n+// * All stack ring buffers are located within (2**kShadowBaseAlignment)\n+// sized region below and adjacent to the shadow region.\n+// * Each ring buffer has a size of (2**N)*4096 where N is in [0, 8), and is\n+// aligned to twice its size. The value of N can be different for each buffer.\n+//\n+// These constrains guarantee that, given an address A of any element of the\n+// ring buffer,\n+//     A_next = (A + sizeof(uptr)) & ~((1 << (N + 13)) - 1)\n+//   is the address of the next element of that ring buffer (with wrap-around).\n+// And, with K = kShadowBaseAlignment,\n+//     S = (A | ((1 << K) - 1)) + 1\n+//   (align up to kShadowBaseAlignment) is the start of the shadow region.\n+//\n+// These calculations are used in compiler instrumentation to update the ring\n+// buffer and obtain the base address of shadow using only two inputs: address\n+// of the current element of the ring buffer, and N (i.e. size of the ring\n+// buffer). Since the value of N is very limited, we pack both inputs into a\n+// single thread-local word as\n+//   (1 << (N + 56)) | A\n+// See the implementation of class CompactRingBuffer, which is what is stored in\n+// said thread-local word.\n+//\n+// Note the unusual way of aligning up the address of the shadow:\n+//   (A | ((1 << K) - 1)) + 1\n+// It is only correct if A is not already equal to the shadow base address, but\n+// it saves 2 instructions on AArch64.\n+\n+#include \"hwasan.h\"\n+#include \"hwasan_allocator.h\"\n+#include \"hwasan_flags.h\"\n+#include \"hwasan_thread.h\"\n+\n+#include \"sanitizer_common/sanitizer_placement_new.h\"\n+\n+namespace __hwasan {\n+\n+static uptr RingBufferSize() {\n+  uptr desired_bytes = flags()->stack_history_size * sizeof(uptr);\n+  // FIXME: increase the limit to 8 once this bug is fixed:\n+  // https://bugs.llvm.org/show_bug.cgi?id=39030\n+  for (int shift = 1; shift < 7; ++shift) {\n+    uptr size = 4096 * (1ULL << shift);\n+    if (size >= desired_bytes)\n+      return size;\n+  }\n+  Printf(\"stack history size too large: %d\\n\", flags()->stack_history_size);\n+  CHECK(0);\n+  return 0;\n+}\n+\n+struct ThreadListHead {\n+  Thread *list_;\n+\n+  ThreadListHead() : list_(nullptr) {}\n+\n+  void Push(Thread *t) {\n+    t->next_ = list_;\n+    list_ = t;\n+  }\n+\n+  Thread *Pop() {\n+    Thread *t = list_;\n+    if (t)\n+      list_ = t->next_;\n+    return t;\n+  }\n+\n+  void Remove(Thread *t) {\n+    Thread **cur = &list_;\n+    while (*cur != t) cur = &(*cur)->next_;\n+    CHECK(*cur && \"thread not found\");\n+    *cur = (*cur)->next_;\n+  }\n+\n+  template <class CB>\n+  void ForEach(CB cb) {\n+    Thread *t = list_;\n+    while (t) {\n+      cb(t);\n+      t = t->next_;\n+    }\n+  }\n+};\n+\n+struct ThreadStats {\n+  uptr n_live_threads;\n+  uptr total_stack_size;\n+};\n+\n+class HwasanThreadList {\n+ public:\n+  HwasanThreadList(uptr storage, uptr size)\n+      : free_space_(storage), free_space_end_(storage + size) {\n+    // [storage, storage + size) is used as a vector of\n+    // thread_alloc_size_-sized, ring_buffer_size_*2-aligned elements.\n+    // Each element contains\n+    // * a ring buffer at offset 0,\n+    // * a Thread object at offset ring_buffer_size_.\n+    ring_buffer_size_ = RingBufferSize();\n+    thread_alloc_size_ =\n+        RoundUpTo(ring_buffer_size_ + sizeof(Thread), ring_buffer_size_ * 2);\n+  }\n+\n+  Thread *CreateCurrentThread() {\n+    Thread *t;\n+    {\n+      SpinMutexLock l(&list_mutex_);\n+      t = free_list_.Pop();\n+      if (t) {\n+        uptr start = (uptr)t - ring_buffer_size_;\n+        internal_memset((void *)start, 0, ring_buffer_size_ + sizeof(Thread));\n+      } else {\n+        t = AllocThread();\n+      }\n+      live_list_.Push(t);\n+    }\n+    t->Init((uptr)t - ring_buffer_size_, ring_buffer_size_);\n+    AddThreadStats(t);\n+    return t;\n+  }\n+\n+  void DontNeedThread(Thread *t) {\n+    uptr start = (uptr)t - ring_buffer_size_;\n+    ReleaseMemoryPagesToOS(start, start + thread_alloc_size_);\n+  }\n+\n+  void ReleaseThread(Thread *t) {\n+    RemoveThreadStats(t);\n+    t->Destroy();\n+    SpinMutexLock l(&list_mutex_);\n+    live_list_.Remove(t);\n+    free_list_.Push(t);\n+    DontNeedThread(t);\n+  }\n+\n+  Thread *GetThreadByBufferAddress(uptr p) {\n+    return (Thread *)(RoundDownTo(p, ring_buffer_size_ * 2) +\n+                      ring_buffer_size_);\n+  }\n+\n+  uptr MemoryUsedPerThread() {\n+    uptr res = sizeof(Thread) + ring_buffer_size_;\n+    if (auto sz = flags()->heap_history_size)\n+      res += HeapAllocationsRingBuffer::SizeInBytes(sz);\n+    return res;\n+  }\n+\n+  template <class CB>\n+  void VisitAllLiveThreads(CB cb) {\n+    SpinMutexLock l(&list_mutex_);\n+    live_list_.ForEach(cb);\n+  }\n+\n+  void AddThreadStats(Thread *t) {\n+    SpinMutexLock l(&stats_mutex_);\n+    stats_.n_live_threads++;\n+    stats_.total_stack_size += t->stack_size();\n+  }\n+\n+  void RemoveThreadStats(Thread *t) {\n+    SpinMutexLock l(&stats_mutex_);\n+    stats_.n_live_threads--;\n+    stats_.total_stack_size -= t->stack_size();\n+  }\n+\n+  ThreadStats GetThreadStats() {\n+    SpinMutexLock l(&stats_mutex_);\n+    return stats_;\n+  }\n+\n+ private:\n+  Thread *AllocThread() {\n+    uptr align = ring_buffer_size_ * 2;\n+    CHECK(IsAligned(free_space_, align));\n+    Thread *t = (Thread *)(free_space_ + ring_buffer_size_);\n+    free_space_ += thread_alloc_size_;\n+    CHECK(free_space_ <= free_space_end_ && \"out of thread memory\");\n+    return t;\n+  }\n+\n+  uptr free_space_;\n+  uptr free_space_end_;\n+  uptr ring_buffer_size_;\n+  uptr thread_alloc_size_;\n+\n+  ThreadListHead free_list_;\n+  ThreadListHead live_list_;\n+  SpinMutex list_mutex_;\n+\n+  ThreadStats stats_;\n+  SpinMutex stats_mutex_;\n+};\n+\n+void InitThreadList(uptr storage, uptr size);\n+HwasanThreadList &hwasanThreadList();\n+\n+} // namespace"}, {"sha": "8cff495bae153eb728a9dc7d12e80be3bc976a85", "filename": "libsanitizer/hwasan/hwasan_type_test.cpp", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_type_test.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fhwasan%2Fhwasan_type_test.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_type_test.cpp?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -0,0 +1,25 @@\n+//===-- hwasan_type_test.cpp ------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of HWAddressSanitizer.\n+//\n+// Compile-time tests of the internal type definitions.\n+//===----------------------------------------------------------------------===//\n+\n+#include \"interception/interception.h\"\n+#include \"sanitizer_common/sanitizer_platform_limits_posix.h\"\n+#include \"hwasan.h\"\n+#include <setjmp.h>\n+\n+#define CHECK_TYPE_SIZE_FITS(TYPE) \\\n+  COMPILER_CHECK(sizeof(__hw_##TYPE) <= sizeof(TYPE))\n+\n+#if HWASAN_WITH_INTERCEPTORS && defined(__aarch64__)\n+CHECK_TYPE_SIZE_FITS(jmp_buf);\n+CHECK_TYPE_SIZE_FITS(sigjmp_buf);\n+#endif"}, {"sha": "95ded4f96344ba0c4617f3a72212057bb9b7d68e", "filename": "libsanitizer/merge.sh", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fmerge.sh", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca/libsanitizer%2Fmerge.sh", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fmerge.sh?ref=1ee3d1ef105c5181fbf298b8ddb638f8e3cbaaca", "patch": "@@ -71,6 +71,7 @@ merge lib/tsan/rtl tsan\n merge lib/sanitizer_common sanitizer_common\n merge lib/interception interception\n merge lib/ubsan ubsan\n+merge lib/hwasan hwasan\n \n # Need to merge lib/builtins/assembly.h file:\n mkdir -p builtins"}]}