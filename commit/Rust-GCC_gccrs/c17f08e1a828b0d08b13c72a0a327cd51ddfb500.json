{"sha": "c17f08e1a828b0d08b13c72a0a327cd51ddfb500", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzE3ZjA4ZTFhODI4YjBkMDhiMTNjNzJhMGEzMjdjZDUxZGRmYjUwMA==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2000-12-29T11:51:01Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2000-12-29T11:51:01Z"}, "message": "alpha.c (alpha_expand_block_move): Initialize src_align and dst_align in bits.\n\n        * config/alpha/alpha.c (alpha_expand_block_move): Initialize\n        src_align and dst_align in bits.  Do unaligned quadword loads\n        if possible for BWX too.\n        (alpha_expand_block_clear): Initialize align in bits.  Track\n        small leading offsets into a larger alignment.  Play games with\n        stq_u for large 4-byte aligned blocks.  Use load/mask/store\n        for appropreately aligned heads and tails.\n\nFrom-SVN: r38532", "tree": {"sha": "4eacbe524708e265e27dbabe7b1f851d7d7ee0c2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4eacbe524708e265e27dbabe7b1f851d7d7ee0c2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c17f08e1a828b0d08b13c72a0a327cd51ddfb500", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c17f08e1a828b0d08b13c72a0a327cd51ddfb500", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c17f08e1a828b0d08b13c72a0a327cd51ddfb500", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c17f08e1a828b0d08b13c72a0a327cd51ddfb500/comments", "author": null, "committer": null, "parents": [{"sha": "12db0efc8e84be42c46bb216fa743d847a2124f8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/12db0efc8e84be42c46bb216fa743d847a2124f8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/12db0efc8e84be42c46bb216fa743d847a2124f8"}], "stats": {"total": 243, "additions": 203, "deletions": 40}, "files": [{"sha": "476801bbe459824008149f72a488a1672b77a70a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c17f08e1a828b0d08b13c72a0a327cd51ddfb500/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c17f08e1a828b0d08b13c72a0a327cd51ddfb500/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c17f08e1a828b0d08b13c72a0a327cd51ddfb500", "patch": "@@ -1,3 +1,13 @@\n+2000-12-29  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/alpha/alpha.c (alpha_expand_block_move): Initialize\n+\tsrc_align and dst_align in bits.  Do unaligned quadword loads\n+\tif possible for BWX too.\n+\t(alpha_expand_block_clear): Initialize align in bits.  Track\n+\tsmall leading offsets into a larger alignment.  Play games with\n+\tstq_u for large 4-byte aligned blocks.  Use load/mask/store\n+\tfor appropreately aligned heads and tails.\n+\n 2000-12-29  Alexandre Oliva  <aoliva@redhat.com>\n \n \t* function.c (assign_parms): Convert arguments passed by"}, {"sha": "cfebe6a9f09fcbef55783c7c5fa9b0b7859fd4d7", "filename": "gcc/config/alpha/alpha.c", "status": "modified", "additions": 193, "deletions": 40, "changes": 233, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c17f08e1a828b0d08b13c72a0a327cd51ddfb500/gcc%2Fconfig%2Falpha%2Falpha.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c17f08e1a828b0d08b13c72a0a327cd51ddfb500/gcc%2Fconfig%2Falpha%2Falpha.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Falpha%2Falpha.c?ref=c17f08e1a828b0d08b13c72a0a327cd51ddfb500", "patch": "@@ -2833,18 +2833,18 @@ alpha_expand_block_move (operands)\n   rtx bytes_rtx\t= operands[2];\n   rtx align_rtx = operands[3];\n   HOST_WIDE_INT orig_bytes = INTVAL (bytes_rtx);\n-  unsigned HOST_WIDE_INT bytes = orig_bytes;\n-  unsigned HOST_WIDE_INT src_align = INTVAL (align_rtx) * BITS_PER_UNIT;\n-  unsigned HOST_WIDE_INT dst_align = src_align;\n+  HOST_WIDE_INT bytes = orig_bytes;\n+  HOST_WIDE_INT src_align = INTVAL (align_rtx) * BITS_PER_UNIT;\n+  HOST_WIDE_INT dst_align = src_align;\n   rtx orig_src = operands[1];\n   rtx orig_dst = operands[0];\n   rtx data_regs[2 * MAX_MOVE_WORDS + 16];\n   rtx tmp;\n-  unsigned int i, words, ofs, nregs = 0;\n+  int i, words, ofs, nregs = 0;\n   \n   if (orig_bytes <= 0)\n     return 1;\n-  else if (bytes > MAX_MOVE_WORDS * BITS_PER_UNIT)\n+  else if (orig_bytes > MAX_MOVE_WORDS * UNITS_PER_WORD)\n     return 0;\n \n   /* Look for additional alignment information from recorded register info.  */\n@@ -2920,6 +2920,7 @@ alpha_expand_block_move (operands)\n       /* No appropriate mode; fall back on memory.  */\n       orig_src = change_address (orig_src, GET_MODE (orig_src),\n \t\t\t\t copy_addr_to_reg (XEXP (orig_src, 0)));\n+      src_align = GET_MODE_BITSIZE (GET_MODE (XEXP (tmp, 0)));\n     }\n \n   ofs = 0;\n@@ -2959,7 +2960,7 @@ alpha_expand_block_move (operands)\n       ofs += words * 4;\n     }\n \n-  if (bytes >= 16)\n+  if (bytes >= 8)\n     {\n       words = bytes / 8;\n \n@@ -2974,14 +2975,6 @@ alpha_expand_block_move (operands)\n       ofs += words * 8;\n     }\n \n-  if (! TARGET_BWX && bytes >= 8)\n-    {\n-      data_regs[nregs++] = tmp = gen_reg_rtx (DImode);\n-      alpha_expand_unaligned_load (tmp, orig_src, 8, ofs, 0);\n-      bytes -= 8;\n-      ofs += 8;\n-    }\n-\n   if (! TARGET_BWX && bytes >= 4)\n     {\n       data_regs[nregs++] = tmp = gen_reg_rtx (SImode);\n@@ -3004,7 +2997,6 @@ alpha_expand_block_move (operands)\n \t    ofs += 2;\n \t  } while (bytes >= 2);\n \t}\n-\n       else if (! TARGET_BWX)\n \t{\n \t  data_regs[nregs++] = tmp = gen_reg_rtx (HImode);\n@@ -3082,7 +3074,7 @@ alpha_expand_block_move (operands)\n \t up by recognizing extra alignment information.  */\n       orig_dst = change_address (orig_dst, GET_MODE (orig_dst),\n \t\t\t\t copy_addr_to_reg (XEXP (orig_dst, 0)));\n-      dst_align = GET_MODE_SIZE (GET_MODE (tmp));\n+      dst_align = GET_MODE_BITSIZE (GET_MODE (XEXP (tmp, 0)));\n     }\n \n   /* Write out the data in whatever chunks reading the source allowed.  */\n@@ -3202,15 +3194,16 @@ alpha_expand_block_clear (operands)\n   rtx bytes_rtx\t= operands[1];\n   rtx align_rtx = operands[2];\n   HOST_WIDE_INT orig_bytes = INTVAL (bytes_rtx);\n-  unsigned HOST_WIDE_INT bytes = orig_bytes;\n-  unsigned HOST_WIDE_INT align = INTVAL (align_rtx);\n+  HOST_WIDE_INT bytes = orig_bytes;\n+  HOST_WIDE_INT align = INTVAL (align_rtx) * BITS_PER_UNIT;\n+  HOST_WIDE_INT alignofs = 0;\n   rtx orig_dst = operands[0];\n   rtx tmp;\n-  unsigned HOST_WIDE_INT i, words, ofs = 0;\n+  int i, words, ofs = 0;\n   \n   if (orig_bytes <= 0)\n     return 1;\n-  if (bytes > MAX_MOVE_WORDS*8)\n+  if (orig_bytes > MAX_MOVE_WORDS * UNITS_PER_WORD)\n     return 0;\n \n   /* Look for stricter alignment.  */\n@@ -3221,20 +3214,19 @@ alpha_expand_block_clear (operands)\n \t   && GET_CODE (XEXP (tmp, 0)) == REG\n \t   && GET_CODE (XEXP (tmp, 1)) == CONST_INT)\n     {\n-      unsigned HOST_WIDE_INT c = INTVAL (XEXP (tmp, 1));\n-      unsigned int a = REGNO_POINTER_ALIGN (REGNO (XEXP (tmp, 0)));\n+      HOST_WIDE_INT c = INTVAL (XEXP (tmp, 1));\n+      int a = REGNO_POINTER_ALIGN (REGNO (XEXP (tmp, 0)));\n \n       if (a > align)\n \t{\n-          if (a >= 64 && c % 8 == 0)\n-\t    align = 64;\n-          else if (a >= 32 && c % 4 == 0)\n-\t    align = 32;\n-          else if (a >= 16 && c % 2 == 0)\n-\t    align = 16;\n+          if (a >= 64)\n+\t    align = a, alignofs = 8 - c % 8;\n+          else if (a >= 32)\n+\t    align = a, alignofs = 4 - c % 4;\n+          else if (a >= 16)\n+\t    align = a, alignofs = 2 - c % 2;\n \t}\n     }\n-\n   else if (GET_CODE (tmp) == ADDRESSOF)\n     {\n       enum machine_mode mode;\n@@ -3249,10 +3241,93 @@ alpha_expand_block_clear (operands)\n       /* No appropriate mode; fall back on memory.  */\n       orig_dst = change_address (orig_dst, GET_MODE (orig_dst),\n \t\t\t\t copy_addr_to_reg (tmp));\n-      align = GET_MODE_SIZE (GET_MODE (XEXP (tmp, 0)));\n+      align = GET_MODE_BITSIZE (GET_MODE (XEXP (tmp, 0)));\n     }\n \n-  /* Handle a block of contiguous words first.  */\n+  /* Handle an unaligned prefix first.  */\n+\n+  if (alignofs > 0)\n+    {\n+#if HOST_BITS_PER_WIDE_INT >= 64\n+      /* Given that alignofs is bounded by align, the only time BWX could\n+\t generate three stores is for a 7 byte fill.  Prefer two individual\n+\t stores over a load/mask/store sequence.  */\n+      if ((!TARGET_BWX || alignofs == 7)\n+\t       && align >= 32\n+\t       && !(alignofs == 4 && bytes >= 4))\n+\t{\n+\t  enum machine_mode mode = (align >= 64 ? DImode : SImode);\n+\t  int inv_alignofs = (align >= 64 ? 8 : 4) - alignofs;\n+\t  rtx mem, tmp;\n+\t  HOST_WIDE_INT mask;\n+\n+\t  mem = change_address (orig_dst, mode,\n+\t\t\t\tplus_constant (XEXP (orig_dst, 0),\n+\t\t\t\t\t       ofs - inv_alignofs));\n+\t  MEM_ALIAS_SET (mem) = 0;\n+\n+\t  mask = ~(~(HOST_WIDE_INT)0 << (inv_alignofs * 8));\n+\t  if (bytes < alignofs)\n+\t    {\n+\t      mask |= ~(HOST_WIDE_INT)0 << ((inv_alignofs + bytes) * 8);\n+\t      ofs += bytes;\n+\t      bytes = 0;\n+\t    }\n+\t  else\n+\t    {\n+\t      bytes -= alignofs;\n+\t      ofs += alignofs;\n+\t    }\n+\t  alignofs = 0;\n+\n+\t  tmp = expand_binop (mode, and_optab, mem, GEN_INT (mask),\n+\t\t\t      NULL_RTX, 1, OPTAB_WIDEN);\n+\n+\t  emit_move_insn (mem, tmp);\n+\t}\n+#endif\n+\n+      if (TARGET_BWX && (alignofs & 1) && bytes >= 1)\n+\t{\n+\t  emit_move_insn (change_address (orig_dst, QImode,\n+\t\t\t\t\t  plus_constant (XEXP (orig_dst, 0),\n+\t\t\t\t\t\t         ofs)),\n+\t\t\t  const0_rtx);\n+\t  bytes -= 1;\n+\t  ofs += 1;\n+\t  alignofs -= 1;\n+\t}\n+      if (TARGET_BWX && align >= 16 && (alignofs & 3) == 2 && bytes >= 2)\n+\t{\n+\t  emit_move_insn (change_address (orig_dst, HImode,\n+\t\t\t\t\t  plus_constant (XEXP (orig_dst, 0),\n+\t\t\t\t\t\t         ofs)),\n+\t\t\t  const0_rtx);\n+\t  bytes -= 2;\n+\t  ofs += 2;\n+\t  alignofs -= 2;\n+\t}\n+      if (alignofs == 4 && bytes >= 4)\n+\t{\n+\t  emit_move_insn (change_address (orig_dst, SImode,\n+\t\t\t\t\t  plus_constant (XEXP (orig_dst, 0),\n+\t\t\t\t\t\t         ofs)),\n+\t\t\t  const0_rtx);\n+\t  bytes -= 4;\n+\t  ofs += 4;\n+\t  alignofs = 0;\n+\t}\n+\n+      /* If we've not used the extra lead alignment information by now,\n+\t we won't be able to.  Downgrade align to match what's left over.  */\n+      if (alignofs > 0)\n+\t{\n+\t  alignofs = alignofs & -alignofs;\n+\t  align = MIN (align, alignofs * BITS_PER_UNIT);\n+\t}\n+    }\n+\n+  /* Handle a block of contiguous long-words.  */\n \n   if (align >= 64 && bytes >= 8)\n     {\n@@ -3268,7 +3343,42 @@ alpha_expand_block_clear (operands)\n       ofs += words * 8;\n     }\n \n-  if (align >= 16 && bytes >= 4)\n+  /* If the block is large and appropriately aligned, emit a single\n+     store followed by a sequence of stq_u insns.  */\n+\n+  if (align >= 32 && bytes > 16)\n+    {\n+      emit_move_insn (change_address (orig_dst, SImode,\n+\t\t\t\t      plus_constant (XEXP (orig_dst, 0), ofs)),\n+\t\t      const0_rtx);\n+      bytes -= 4;\n+      ofs += 4;\n+\n+      words = bytes / 8;\n+      for (i = 0; i < words; ++i)\n+\t{\n+\t  rtx mem;\n+\t  mem = change_address (orig_dst, DImode,\n+\t\t\t\tgen_rtx_AND (DImode,\n+\t\t\t\t\t     plus_constant (XEXP (orig_dst, 0),\n+\t\t\t\t\t\t\t    ofs + i*8),\n+\t\t\t\t\t     GEN_INT (-8)));\n+\t  MEM_ALIAS_SET (mem) = 0;\n+\t  emit_move_insn (mem, const0_rtx);\n+\t}\n+\n+      /* Depending on the alignment, the first stq_u may have overlapped\n+\t with the initial stl, which means that the last stq_u didn't\n+\t write as much as it would appear.  Leave those questionable bytes\n+\t unaccounted for.  */\n+      bytes -= words * 8 - 4;\n+      ofs += words * 8 - 4;\n+    }\n+\n+  /* Handle a smaller block of aligned words.  */\n+\n+  if ((align >= 64 && bytes == 4)\n+      || (align == 32 && bytes >= 4))\n     {\n       words = bytes / 4;\n \n@@ -3282,7 +3392,9 @@ alpha_expand_block_clear (operands)\n       ofs += words * 4;\n     }\n \n-  if (bytes >= 16)\n+  /* An unaligned block uses stq_u stores for as many as possible.  */\n+\n+  if (bytes >= 8)\n     {\n       words = bytes / 8;\n \n@@ -3292,15 +3404,56 @@ alpha_expand_block_clear (operands)\n       ofs += words * 8;\n     }\n \n-  /* Next clean up any trailing pieces.  We know from the contiguous\n-     block move that there are no aligned SImode or DImode hunks left.  */\n+  /* Next clean up any trailing pieces.  */\n \n-  if (! TARGET_BWX && bytes >= 8)\n-    {\n-      alpha_expand_unaligned_store (orig_dst, const0_rtx, 8, ofs);\n-      bytes -= 8;\n-      ofs += 8;\n+#if HOST_BITS_PER_WIDE_INT >= 64\n+  /* Count the number of bits in BYTES for which aligned stores could\n+     be emitted.  */\n+  words = 0;\n+  for (i = (TARGET_BWX ? 1 : 4); i * BITS_PER_UNIT <= align ; i <<= 1)\n+    if (bytes & i)\n+      words += 1;\n+\n+  /* If we have appropriate alignment (and it wouldn't take too many\n+     instructions otherwise), mask out the bytes we need.  */\n+  if (TARGET_BWX ? words > 2 : bytes > 0)\n+    {\n+      if (align >= 64)\n+\t{\n+\t  rtx mem, tmp;\n+\t  HOST_WIDE_INT mask;\n+\n+\t  mem = change_address (orig_dst, DImode,\n+\t\t\t\tplus_constant (XEXP (orig_dst, 0), ofs));\n+\t  MEM_ALIAS_SET (mem) = 0;\n+\n+\t  mask = ~(HOST_WIDE_INT)0 << (bytes * 8);\n+\n+\t  tmp = expand_binop (DImode, and_optab, mem, GEN_INT (mask),\n+\t\t\t      NULL_RTX, 1, OPTAB_WIDEN);\n+\n+\t  emit_move_insn (mem, tmp);\n+\t  return 1;\n+\t}\n+      else if (align >= 32 && bytes < 4)\n+\t{\n+\t  rtx mem, tmp;\n+\t  HOST_WIDE_INT mask;\n+\n+\t  mem = change_address (orig_dst, SImode,\n+\t\t\t\tplus_constant (XEXP (orig_dst, 0), ofs));\n+\t  MEM_ALIAS_SET (mem) = 0;\n+\n+\t  mask = ~(HOST_WIDE_INT)0 << (bytes * 8);\n+\n+\t  tmp = expand_binop (SImode, and_optab, mem, GEN_INT (mask),\n+\t\t\t      NULL_RTX, 1, OPTAB_WIDEN);\n+\n+\t  emit_move_insn (mem, tmp);\n+\t  return 1;\n+\t}\n     }\n+#endif\n \n   if (!TARGET_BWX && bytes >= 4)\n     {"}]}