{"sha": "9a810e57c4e6af54d29c325a013f451ade2b85e8", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OWE4MTBlNTdjNGU2YWY1NGQyOWMzMjVhMDEzZjQ1MWFkZTJiODVlOA==", "commit": {"author": {"name": "Srinath Parvathaneni", "email": "srinath.parvathaneni@arm.com", "date": "2020-06-04T14:41:29Z"}, "committer": {"name": "Srinath Parvathaneni", "email": "srinath.parvathaneni@arm.com", "date": "2020-06-04T14:55:31Z"}, "message": "[ARM]: Correct the grouping of operands in MVE vector scatter store intrinsics (PR94735).\n\nThe operands in RTL patterns of MVE vector scatter store intrinsics are wrongly grouped,\nbecause of which few vector loads and stores instructions are wrongly getting optimized\nout with -O2.\n\nA new predicate \"mve_scatter_memory\" is defined in this patch, this predicate returns TRUE on\nmatching: (mem(reg)) for MVE scatter store intrinsics.\nThis patch fixes the issue by adding define_expand pattern with \"mve_scatter_memory\" predicate\nand calls the corresponding define_insn by passing register_operand as first argument.\nThis register_operand is extracted from the operand with \"mve_scatter_memory\" predicate in\ndefine_expand pattern.\n\ngcc/ChangeLog:\n\n2020-06-01  Srinath Parvathaneni  <srinath.parvathaneni@arm.com>\n\n\tPR target/94735\n\t* config/arm/predicates.md (mve_scatter_memory): Define to\n\tmatch (mem (reg)) for scatter store memory.\n\t* config/arm/mve.md (mve_vstrbq_scatter_offset_<supf><mode>): Modify\n\tdefine_insn to define_expand.\n\t(mve_vstrbq_scatter_offset_p_<supf><mode>): Likewise.\n\t(mve_vstrhq_scatter_offset_<supf><mode>): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_p_<supf><mode>): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_<supf><mode>): Likewise.\n\t(mve_vstrdq_scatter_offset_p_<supf>v2di): Likewise.\n\t(mve_vstrdq_scatter_offset_<supf>v2di): Likewise.\n\t(mve_vstrdq_scatter_shifted_offset_p_<supf>v2di): Likewise.\n\t(mve_vstrdq_scatter_shifted_offset_<supf>v2di): Likewise.\n\t(mve_vstrhq_scatter_offset_fv8hf): Likewise.\n\t(mve_vstrhq_scatter_offset_p_fv8hf): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_fv8hf): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_p_fv8hf): Likewise.\n\t(mve_vstrwq_scatter_offset_fv4sf): Likewise.\n\t(mve_vstrwq_scatter_offset_p_fv4sf): Likewise.\n\t(mve_vstrwq_scatter_offset_p_<supf>v4si): Likewise.\n\t(mve_vstrwq_scatter_offset_<supf>v4si): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_fv4sf): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_p_fv4sf): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_p_<supf>v4si): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_<supf>v4si): Likewise.\n\t(mve_vstrbq_scatter_offset_<supf><mode>_insn): Define insn for scatter\n\tstores.\n\t(mve_vstrbq_scatter_offset_p_<supf><mode>_insn): Likewise.\n\t(mve_vstrhq_scatter_offset_<supf><mode>_insn): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_p_<supf><mode>_insn): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_<supf><mode>_insn): Likewise.\n\t(mve_vstrdq_scatter_offset_p_<supf>v2di_insn): Likewise.\n\t(mve_vstrdq_scatter_offset_<supf>v2di_insn): Likewise.\n\t(mve_vstrdq_scatter_shifted_offset_p_<supf>v2di_insn): Likewise.\n\t(mve_vstrdq_scatter_shifted_offset_<supf>v2di_insn): Likewise.\n\t(mve_vstrhq_scatter_offset_fv8hf_insn): Likewise.\n\t(mve_vstrhq_scatter_offset_p_fv8hf_insn): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_fv8hf_insn): Likewise.\n\t(mve_vstrhq_scatter_shifted_offset_p_fv8hf_insn): Likewise.\n\t(mve_vstrwq_scatter_offset_fv4sf_insn): Likewise.\n\t(mve_vstrwq_scatter_offset_p_fv4sf_insn): Likewise.\n\t(mve_vstrwq_scatter_offset_p_<supf>v4si_insn): Likewise.\n\t(mve_vstrwq_scatter_offset_<supf>v4si_insn): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_fv4sf_insn): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_p_fv4sf_insn): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_p_<supf>v4si_insn): Likewise.\n\t(mve_vstrwq_scatter_shifted_offset_<supf>v4si_insn): Likewise.\n\ngcc/testsuite/ChangeLog:\n\n2020-06-01  Srinath Parvathaneni  <srinath.parvathaneni@arm.com>\n\n\tPR target/94735\n\t* gcc.target/arm/mve/intrinsics/mve_vstore_scatter_base.c: New test.\n\t* gcc.target/arm/mve/intrinsics/mve_vstore_scatter_base_p.c: Likewise.\n\t* gcc.target/arm/mve/intrinsics/mve_vstore_scatter_offset.c: Likewise.\n\t* gcc.target/arm/mve/intrinsics/mve_vstore_scatter_offset_p.c: Likewise.\n\t* gcc.target/arm/mve/intrinsics/mve_vstore_scatter_shifted_offset.c:\n\tLikewise.\n\t* gcc.target/arm/mve/intrinsics/mve_vstore_scatter_shifted_offset_p.c:\n\tLikewise.", "tree": {"sha": "0e8b8a988b085a69d81f97f8137125af5ef904b5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0e8b8a988b085a69d81f97f8137125af5ef904b5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/9a810e57c4e6af54d29c325a013f451ade2b85e8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9a810e57c4e6af54d29c325a013f451ade2b85e8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9a810e57c4e6af54d29c325a013f451ade2b85e8", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9a810e57c4e6af54d29c325a013f451ade2b85e8/comments", "author": {"login": "sripar01", "id": 115715849, "node_id": "U_kgDOBuWvCQ", "avatar_url": "https://avatars.githubusercontent.com/u/115715849?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sripar01", "html_url": "https://github.com/sripar01", "followers_url": "https://api.github.com/users/sripar01/followers", "following_url": "https://api.github.com/users/sripar01/following{/other_user}", "gists_url": "https://api.github.com/users/sripar01/gists{/gist_id}", "starred_url": "https://api.github.com/users/sripar01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sripar01/subscriptions", "organizations_url": "https://api.github.com/users/sripar01/orgs", "repos_url": "https://api.github.com/users/sripar01/repos", "events_url": "https://api.github.com/users/sripar01/events{/privacy}", "received_events_url": "https://api.github.com/users/sripar01/received_events", "type": "User", "site_admin": false}, "committer": {"login": "sripar01", "id": 115715849, "node_id": "U_kgDOBuWvCQ", "avatar_url": "https://avatars.githubusercontent.com/u/115715849?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sripar01", "html_url": "https://github.com/sripar01", "followers_url": "https://api.github.com/users/sripar01/followers", "following_url": "https://api.github.com/users/sripar01/following{/other_user}", "gists_url": "https://api.github.com/users/sripar01/gists{/gist_id}", "starred_url": "https://api.github.com/users/sripar01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sripar01/subscriptions", "organizations_url": "https://api.github.com/users/sripar01/orgs", "repos_url": "https://api.github.com/users/sripar01/repos", "events_url": "https://api.github.com/users/sripar01/events{/privacy}", "received_events_url": "https://api.github.com/users/sripar01/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d34f510e2bf976cff3b9fbf7a8c5a41c233db2e4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d34f510e2bf976cff3b9fbf7a8c5a41c233db2e4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d34f510e2bf976cff3b9fbf7a8c5a41c233db2e4"}], "stats": {"total": 1684, "additions": 1363, "deletions": 321}, "files": [{"sha": "3a57901bd5bcd770832d59dc77cd92b6d9b5ecb4", "filename": "gcc/config/arm/mve.md", "status": "modified", "additions": 507, "deletions": 321, "changes": 828, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Fconfig%2Farm%2Fmve.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Fconfig%2Farm%2Fmve.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fmve.md?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -8102,22 +8102,29 @@\n ;;\n ;; [vstrbq_scatter_offset_s vstrbq_scatter_offset_u]\n ;;\n-(define_insn \"mve_vstrbq_scatter_offset_<supf><mode>\"\n-  [(set (match_operand:<MVE_B_ELEM> 0 \"memory_operand\" \"=Us\")\n-\t(unspec:<MVE_B_ELEM>\n-\t\t[(match_operand:MVE_2 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:MVE_2 2 \"s_register_operand\" \"w\")]\n-\t VSTRBSOQ))\n-  ]\n+(define_expand \"mve_vstrbq_scatter_offset_<supf><mode>\"\n+  [(match_operand:<MVE_B_ELEM> 0 \"mve_scatter_memory\")\n+   (match_operand:MVE_2 1 \"s_register_operand\")\n+   (match_operand:MVE_2 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRBSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn(\"vstrb.<V_sz_elem>\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrbq_scatter_offset_<supf><mode>_insn (ind, operands[1],\n+\t\t\t\t\t\t\t      operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrbq_scatter_offset_<supf><mode>_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:MVE_2 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:MVE_2 2 \"s_register_operand\" \"w\")]\n+\t  VSTRBSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vstrb.<V_sz_elem>\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n@@ -8210,23 +8217,33 @@\n ;;\n ;; [vstrbq_scatter_offset_p_s vstrbq_scatter_offset_p_u]\n ;;\n-(define_insn \"mve_vstrbq_scatter_offset_p_<supf><mode>\"\n-  [(set (match_operand:<MVE_B_ELEM> 0 \"memory_operand\" \"=Us\")\n-\t(unspec:<MVE_B_ELEM>\n-\t\t[(match_operand:MVE_2 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:MVE_2 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRBSOQ))\n-  ]\n+(define_expand \"mve_vstrbq_scatter_offset_p_<supf><mode>\"\n+  [(match_operand:<MVE_B_ELEM>  0 \"mve_scatter_memory\")\n+   (match_operand:MVE_2 1 \"s_register_operand\")\n+   (match_operand:MVE_2 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")\n+   (unspec:V4SI [(const_int 0)] VSTRBSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\n\\tvstrbt.<V_sz_elem>\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrbq_scatter_offset_p_<supf><mode>_insn (ind, operands[1],\n+\t\t\t\t\t\t       operands[2],\n+\t\t\t\t\t\t       operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrbq_scatter_offset_p_<supf><mode>_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:MVE_2 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:MVE_2 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRBSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vpst\\;vstrbt.<V_sz_elem>\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n@@ -9097,87 +9114,122 @@\n ;;\n ;; [vstrhq_scatter_offset_p_s vstrhq_scatter_offset_p_u]\n ;;\n-(define_insn \"mve_vstrhq_scatter_offset_p_<supf><mode>\"\n-  [(set (match_operand:<MVE_H_ELEM> 0 \"memory_operand\" \"=Us\")\n-\t(unspec:<MVE_H_ELEM>\n-\t\t[(match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:MVE_6 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRHSOQ))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_offset_p_<supf><mode>\"\n+  [(match_operand:<MVE_H_ELEM> 0 \"mve_scatter_memory\")\n+   (match_operand:MVE_6 1 \"s_register_operand\")\n+   (match_operand:MVE_6 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRHSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\n\\tvstrht.<V_sz_elem>\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrhq_scatter_offset_p_<supf><mode>_insn (ind, operands[1],\n+\t\t\t\t\t\t       operands[2],\n+\t\t\t\t\t\t       operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_offset_p_<supf><mode>_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:MVE_6 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRHSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vpst\\;vstrht.<V_sz_elem>\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrhq_scatter_offset_s vstrhq_scatter_offset_u]\n ;;\n-(define_insn \"mve_vstrhq_scatter_offset_<supf><mode>\"\n-  [(set (match_operand:<MVE_H_ELEM> 0 \"memory_operand\" \"=Us\")\n-\t(unspec:<MVE_H_ELEM>\n-\t\t[(match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:MVE_6 2 \"s_register_operand\" \"w\")]\n-\t VSTRHSOQ))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_offset_<supf><mode>\"\n+  [(match_operand:<MVE_H_ELEM> 0 \"mve_scatter_memory\")\n+   (match_operand:MVE_6 1 \"s_register_operand\")\n+   (match_operand:MVE_6 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRHSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrh.<V_sz_elem>\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrhq_scatter_offset_<supf><mode>_insn (ind, operands[1],\n+\t\t\t\t\t\t\t      operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_offset_<supf><mode>_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:MVE_6 2 \"s_register_operand\" \"w\")]\n+\t  VSTRHSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vstrh.<V_sz_elem>\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n ;; [vstrhq_scatter_shifted_offset_p_s vstrhq_scatter_shifted_offset_p_u]\n ;;\n-(define_insn \"mve_vstrhq_scatter_shifted_offset_p_<supf><mode>\"\n-  [(set (match_operand:<MVE_H_ELEM> 0 \"memory_operand\" \"=Ux\")\n-\t(unspec:<MVE_H_ELEM>\n-\t\t[(match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:MVE_6 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRHSSOQ))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_shifted_offset_p_<supf><mode>\"\n+  [(match_operand:<MVE_H_ELEM> 0 \"mve_scatter_memory\")\n+   (match_operand:MVE_6 1 \"s_register_operand\")\n+   (match_operand:MVE_6 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRHSSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\n\\tvstrht.<V_sz_elem>\\t%q2, [%m0, %q1, uxtw #1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrhq_scatter_shifted_offset_p_<supf><mode>_insn (ind, operands[1],\n+\t\t\t\t\t\t\t       operands[2],\n+\t\t\t\t\t\t\t       operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_shifted_offset_p_<supf><mode>_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:MVE_6 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRHSSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vpst\\;vstrht.<V_sz_elem>\\t%q2, [%0, %q1, uxtw #1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrhq_scatter_shifted_offset_s vstrhq_scatter_shifted_offset_u]\n ;;\n-(define_insn \"mve_vstrhq_scatter_shifted_offset_<supf><mode>\"\n-  [(set (match_operand:<MVE_H_ELEM> 0 \"memory_operand\" \"=Us\")\n-\t(unspec:<MVE_H_ELEM>\n-\t\t[(match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:MVE_6 2 \"s_register_operand\" \"w\")]\n-\t VSTRHSSOQ))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_shifted_offset_<supf><mode>\"\n+  [(match_operand:<MVE_H_ELEM> 0 \"mve_scatter_memory\")\n+   (match_operand:MVE_6 1 \"s_register_operand\")\n+   (match_operand:MVE_6 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRHSSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrh.<V_sz_elem>\\t%q2, [%m0, %q1, uxtw #1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrhq_scatter_shifted_offset_<supf><mode>_insn (ind, operands[1],\n+\t\t\t\t\t\t\t     operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_shifted_offset_<supf><mode>_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:MVE_6 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:MVE_6 2 \"s_register_operand\" \"w\")]\n+\t  VSTRHSSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vstrh.<V_sz_elem>\\t%q2, [%0, %q1, uxtw #1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n@@ -9345,173 +9397,240 @@\n ;;\n ;; [vstrdq_scatter_offset_p_s vstrdq_scatter_offset_p_u]\n ;;\n-(define_insn \"mve_vstrdq_scatter_offset_p_<supf>v2di\"\n-  [(set (match_operand:V2DI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V2DI\n-\t\t[(match_operand:V2DI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V2DI 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRDSOQ))\n-  ]\n+(define_expand \"mve_vstrdq_scatter_offset_p_<supf>v2di\"\n+  [(match_operand:V2DI 0 \"mve_scatter_memory\")\n+   (match_operand:V2DI 1 \"s_register_operand\")\n+   (match_operand:V2DI 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRDSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\;\\tvstrdt.64\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrdq_scatter_offset_p_<supf>v2di_insn (ind, operands[1],\n+\t\t\t\t\t\t\t      operands[2],\n+\t\t\t\t\t\t\t      operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrdq_scatter_offset_p_<supf>v2di_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V2DI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V2DI 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRDSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vpst\\;vstrdt.64\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrdq_scatter_offset_s vstrdq_scatter_offset_u]\n ;;\n-(define_insn \"mve_vstrdq_scatter_offset_<supf>v2di\"\n-  [(set (match_operand:V2DI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V2DI\n-\t\t[(match_operand:V2DI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V2DI 2 \"s_register_operand\" \"w\")]\n-\t VSTRDSOQ))\n-  ]\n+(define_expand \"mve_vstrdq_scatter_offset_<supf>v2di\"\n+  [(match_operand:V2DI 0 \"mve_scatter_memory\")\n+   (match_operand:V2DI 1 \"s_register_operand\")\n+   (match_operand:V2DI 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRDSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrd.64\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrdq_scatter_offset_<supf>v2di_insn (ind, operands[1],\n+\t\t\t\t\t\t\t    operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrdq_scatter_offset_<supf>v2di_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V2DI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V2DI 2 \"s_register_operand\" \"w\")]\n+\t  VSTRDSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vstrd.64\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n ;; [vstrdq_scatter_shifted_offset_p_s vstrdq_scatter_shifted_offset_p_u]\n ;;\n-(define_insn \"mve_vstrdq_scatter_shifted_offset_p_<supf>v2di\"\n-  [(set (match_operand:V2DI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V2DI\n-\t\t[(match_operand:V2DI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V2DI 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRDSSOQ))\n-  ]\n+(define_expand \"mve_vstrdq_scatter_shifted_offset_p_<supf>v2di\"\n+  [(match_operand:V2DI 0 \"mve_scatter_memory\")\n+   (match_operand:V2DI 1 \"s_register_operand\")\n+   (match_operand:V2DI 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRDSSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\;\\tvstrdt.64\\t%q2, [%m0, %q1, UXTW #3]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrdq_scatter_shifted_offset_p_<supf>v2di_insn (ind, operands[1],\n+\t\t\t\t\t\t\t     operands[2],\n+\t\t\t\t\t\t\t     operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrdq_scatter_shifted_offset_p_<supf>v2di_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V2DI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V2DI 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRDSSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vpst\\;vstrdt.64\\t%q2, [%0, %q1, UXTW #3]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrdq_scatter_shifted_offset_s vstrdq_scatter_shifted_offset_u]\n ;;\n-(define_insn \"mve_vstrdq_scatter_shifted_offset_<supf>v2di\"\n-  [(set (match_operand:V2DI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V2DI\n-\t\t[(match_operand:V2DI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V2DI 2 \"s_register_operand\" \"w\")]\n-\t VSTRDSSOQ))\n-  ]\n+(define_expand \"mve_vstrdq_scatter_shifted_offset_<supf>v2di\"\n+  [(match_operand:V2DI 0 \"mve_scatter_memory\")\n+   (match_operand:V2DI 1 \"s_register_operand\")\n+   (match_operand:V2DI 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRDSSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrd.64\\t%q2, [%m0, %q1, UXTW #3]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrdq_scatter_shifted_offset_<supf>v2di_insn (ind, operands[1],\n+\t\t\t\t\t\t\t   operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrdq_scatter_shifted_offset_<supf>v2di_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V2DI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V2DI 2 \"s_register_operand\" \"w\")]\n+\t  VSTRDSSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vstrd.64\\t%q2, [%0, %q1, UXTW #3]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n ;; [vstrhq_scatter_offset_f]\n ;;\n-(define_insn \"mve_vstrhq_scatter_offset_fv8hf\"\n-  [(set (match_operand:V8HI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V8HI\n-\t\t[(match_operand:V8HI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V8HF 2 \"s_register_operand\" \"w\")]\n-\t VSTRHQSO_F))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_offset_fv8hf\"\n+  [(match_operand:V8HI 0 \"mve_scatter_memory\")\n+   (match_operand:V8HI 1 \"s_register_operand\")\n+   (match_operand:V8HF 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRHQSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrh.16\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrhq_scatter_offset_fv8hf_insn (ind, operands[1],\n+\t\t\t\t\t\t       operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_offset_fv8hf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V8HI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V8HF 2 \"s_register_operand\" \"w\")]\n+\t  VSTRHQSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vstrh.16\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n ;; [vstrhq_scatter_offset_p_f]\n ;;\n-(define_insn \"mve_vstrhq_scatter_offset_p_fv8hf\"\n-  [(set (match_operand:V8HI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V8HI\n-\t\t[(match_operand:V8HI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V8HF 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRHQSO_F))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_offset_p_fv8hf\"\n+  [(match_operand:V8HI 0 \"mve_scatter_memory\")\n+   (match_operand:V8HI 1 \"s_register_operand\")\n+   (match_operand:V8HF 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRHQSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\n\\tvstrht.16\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrhq_scatter_offset_p_fv8hf_insn (ind, operands[1],\n+\t\t\t\t\t\t\t operands[2],\n+\t\t\t\t\t\t\t operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_offset_p_fv8hf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V8HI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V8HF 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRHQSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vpst\\;vstrht.16\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrhq_scatter_shifted_offset_f]\n ;;\n-(define_insn \"mve_vstrhq_scatter_shifted_offset_fv8hf\"\n-  [(set (match_operand:V8HI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V8HI\n-\t\t[(match_operand:V8HI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V8HF 2 \"s_register_operand\" \"w\")]\n-\t VSTRHQSSO_F))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_shifted_offset_fv8hf\"\n+  [(match_operand:V8HI 0 \"memory_operand\" \"=Us\")\n+   (match_operand:V8HI 1 \"s_register_operand\" \"w\")\n+   (match_operand:V8HF 2 \"s_register_operand\" \"w\")\n+   (unspec:V4SI [(const_int 0)] VSTRHQSSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrh.16\\t%q2, [%m0, %q1, uxtw #1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrhq_scatter_shifted_offset_fv8hf_insn (ind, operands[1],\n+\t\t\t\t\t\t\t       operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_shifted_offset_fv8hf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V8HI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V8HF 2 \"s_register_operand\" \"w\")]\n+\t  VSTRHQSSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vstrh.16\\t%q2, [%0, %q1, uxtw #1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n ;; [vstrhq_scatter_shifted_offset_p_f]\n ;;\n-(define_insn \"mve_vstrhq_scatter_shifted_offset_p_fv8hf\"\n-  [(set (match_operand:V8HI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V8HI\n-\t\t[(match_operand:V8HI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V8HF 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRHQSSO_F))\n-  ]\n+(define_expand \"mve_vstrhq_scatter_shifted_offset_p_fv8hf\"\n+  [(match_operand:V8HI 0 \"memory_operand\" \"=Us\")\n+   (match_operand:V8HI 1 \"s_register_operand\" \"w\")\n+   (match_operand:V8HF 2 \"s_register_operand\" \"w\")\n+   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")\n+   (unspec:V4SI [(const_int 0)] VSTRHQSSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\n\\tvstrht.16\\t%q2, [%m0, %q1, uxtw #1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrhq_scatter_shifted_offset_p_fv8hf_insn (ind, operands[1],\n+\t\t\t\t\t\t\toperands[2],\n+\t\t\t\t\t\t\toperands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrhq_scatter_shifted_offset_p_fv8hf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V8HI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V8HF 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRHQSSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vpst\\;vstrht.16\\t%q2, [%0, %q1, uxtw #1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n@@ -9562,173 +9681,240 @@\n ;;\n ;; [vstrwq_scatter_offset_f]\n ;;\n-(define_insn \"mve_vstrwq_scatter_offset_fv4sf\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SF 2 \"s_register_operand\" \"w\")]\n-\t VSTRWQSO_F))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_offset_fv4sf\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SF 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWQSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrw.32\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrwq_scatter_offset_fv4sf_insn (ind, operands[1],\n+\t\t\t\t\t\t       operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_offset_fv4sf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SF 2 \"s_register_operand\" \"w\")]\n+\t  VSTRWQSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vstrw.32\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n ;; [vstrwq_scatter_offset_p_f]\n ;;\n-(define_insn \"mve_vstrwq_scatter_offset_p_fv4sf\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SF 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRWQSO_F))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_offset_p_fv4sf\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SF 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWQSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\n\\tvstrwt.32\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrwq_scatter_offset_p_fv4sf_insn (ind, operands[1],\n+\t\t\t\t\t\t\t operands[2],\n+\t\t\t\t\t\t\t operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_offset_p_fv4sf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SF 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRWQSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vpst\\;vstrwt.32\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n-;; [vstrwq_scatter_offset_p_s vstrwq_scatter_offset_p_u]\n+;; [vstrwq_scatter_offset_s vstrwq_scatter_offset_u]\n ;;\n-(define_insn \"mve_vstrwq_scatter_offset_p_<supf>v4si\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SI 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRWSOQ))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_offset_p_<supf>v4si\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SI 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\n\\tvstrwt.32\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrwq_scatter_offset_p_<supf>v4si_insn (ind, operands[1],\n+\t\t\t\t\t\t\t      operands[2],\n+\t\t\t\t\t\t\t      operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_offset_p_<supf>v4si_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SI 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRWSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vpst\\;vstrwt.32\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrwq_scatter_offset_s vstrwq_scatter_offset_u]\n ;;\n-(define_insn \"mve_vstrwq_scatter_offset_<supf>v4si\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SI 2 \"s_register_operand\" \"w\")]\n-\t VSTRWSOQ))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_offset_<supf>v4si\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SI 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrw.32\\t%q2, [%m0, %q1]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrwq_scatter_offset_<supf>v4si_insn (ind, operands[1],\n+\t\t\t\t\t\t\t    operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_offset_<supf>v4si_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SI 2 \"s_register_operand\" \"w\")]\n+\t  VSTRWSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vstrw.32\\t%q2, [%0, %q1]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;\n ;; [vstrwq_scatter_shifted_offset_f]\n ;;\n-(define_insn \"mve_vstrwq_scatter_shifted_offset_fv4sf\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SF 2 \"s_register_operand\" \"w\")]\n-\t VSTRWQSSO_F))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_shifted_offset_fv4sf\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SF 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWQSSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrw.32\\t%q2, [%m0, %q1, uxtw #2]\",ops);\n-   return \"\";\n-}\n-  [(set_attr \"length\" \"4\")])\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (gen_mve_vstrwq_scatter_shifted_offset_fv4sf_insn (ind, operands[1],\n+\t\t\t\t\t\t\t       operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_shifted_offset_fv4sf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SF 2 \"s_register_operand\" \"w\")]\n+\t VSTRWQSSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vstrw.32\\t%q2, [%0, %q1, uxtw #2]\"\n+  [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrwq_scatter_shifted_offset_p_f]\n ;;\n-(define_insn \"mve_vstrwq_scatter_shifted_offset_p_fv4sf\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SF 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRWQSSO_F))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_shifted_offset_p_fv4sf\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SF 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWQSSO_F)]\n   \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\;\\tvstrwt.32\\t%q2, [%m0, %q1, uxtw #2]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrwq_scatter_shifted_offset_p_fv4sf_insn (ind, operands[1],\n+\t\t\t\t\t\t\toperands[2],\n+\t\t\t\t\t\t\toperands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_shifted_offset_p_fv4sf_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SF 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRWQSSO_F))]\n+  \"TARGET_HAVE_MVE && TARGET_HAVE_MVE_FLOAT\"\n+  \"vpst\\;vstrwt.32\\t%q2, [%0, %q1, uxtw #2]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrwq_scatter_shifted_offset_p_s vstrwq_scatter_shifted_offset_p_u]\n ;;\n-(define_insn \"mve_vstrwq_scatter_shifted_offset_p_<supf>v4si\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SI 2 \"s_register_operand\" \"w\")\n-\t\t (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n-\t VSTRWSSOQ))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_shifted_offset_p_<supf>v4si\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SI 2 \"s_register_operand\")\n+   (match_operand:HI 3 \"vpr_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWSSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vpst\\;\\tvstrwt.32\\t%q2, [%m0, %q1, uxtw #2]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrwq_scatter_shifted_offset_p_<supf>v4si_insn (ind, operands[1],\n+\t\t\t\t\t\t\t     operands[2],\n+\t\t\t\t\t\t\t     operands[3]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_shifted_offset_p_<supf>v4si_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SI 2 \"s_register_operand\" \"w\")\n+\t   (match_operand:HI 3 \"vpr_register_operand\" \"Up\")]\n+\t  VSTRWSSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vpst\\;vstrwt.32\\t%q2, [%0, %q1, uxtw #2]\"\n   [(set_attr \"length\" \"8\")])\n \n ;;\n ;; [vstrwq_scatter_shifted_offset_s vstrwq_scatter_shifted_offset_u]\n ;;\n-(define_insn \"mve_vstrwq_scatter_shifted_offset_<supf>v4si\"\n-  [(set (match_operand:V4SI 0 \"memory_operand\" \"=Us\")\n-\t(unspec:V4SI\n-\t\t[(match_operand:V4SI 1 \"s_register_operand\" \"w\")\n-\t\t (match_operand:V4SI 2 \"s_register_operand\" \"w\")]\n-\t VSTRWSSOQ))\n-  ]\n+(define_expand \"mve_vstrwq_scatter_shifted_offset_<supf>v4si\"\n+  [(match_operand:V4SI 0 \"mve_scatter_memory\")\n+   (match_operand:V4SI 1 \"s_register_operand\")\n+   (match_operand:V4SI 2 \"s_register_operand\")\n+   (unspec:V4SI [(const_int 0)] VSTRWSSOQ)]\n   \"TARGET_HAVE_MVE\"\n {\n-   rtx ops[3];\n-   ops[0] = operands[0];\n-   ops[1] = operands[1];\n-   ops[2] = operands[2];\n-   output_asm_insn (\"vstrw.32\\t%q2, [%m0, %q1, uxtw #2]\",ops);\n-   return \"\";\n-}\n+  rtx ind = XEXP (operands[0], 0);\n+  gcc_assert (REG_P (ind));\n+  emit_insn (\n+    gen_mve_vstrwq_scatter_shifted_offset_<supf>v4si_insn (ind, operands[1],\n+\t\t\t\t\t\t\t   operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"mve_vstrwq_scatter_shifted_offset_<supf>v4si_insn\"\n+  [(set (mem:BLK (scratch))\n+\t(unspec:BLK\n+\t  [(match_operand:SI 0 \"register_operand\" \"r\")\n+\t   (match_operand:V4SI 1 \"s_register_operand\" \"w\")\n+\t   (match_operand:V4SI 2 \"s_register_operand\" \"w\")]\n+\t  VSTRWSSOQ))]\n+  \"TARGET_HAVE_MVE\"\n+  \"vstrw.32\\t%q2, [%0, %q1, uxtw #2]\"\n   [(set_attr \"length\" \"4\")])\n \n ;;"}, {"sha": "9e9bca4d87fdc31e045b2b5bb03b996f082079bd", "filename": "gcc/config/arm/predicates.md", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Fconfig%2Farm%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Fconfig%2Farm%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fpredicates.md?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -37,6 +37,12 @@\n \t\t    && mve_vector_mem_operand (GET_MODE (op), XEXP (op, 0),\n \t\t\t\t\t       false)\")))\n \n+(define_predicate \"mve_scatter_memory\"\n+  (and (match_code \"mem\")\n+       (match_test \"TARGET_HAVE_MVE && REG_P (XEXP (op, 0))\n+\t\t    && mve_vector_mem_operand (GET_MODE (op), XEXP (op, 0),\n+\t\t\t\t\t       false)\")))\n+\n ;; True for immediates in the range of 1 to 16 for MVE.\n (define_predicate \"mve_imm_16\"\n   (match_test \"satisfies_constraint_Rd (op)\"))"}, {"sha": "21b9e12d57e064688e6d52493deffc1c2c39761d", "filename": "gcc/testsuite/gcc.target/arm/mve/intrinsics/mve_vstore_scatter_base.c", "status": "added", "additions": 67, "deletions": 0, "changes": 67, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_base.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_base.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_base.c?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -0,0 +1,67 @@\n+/* { dg-require-effective-target arm_v8_1m_mve_fp_ok } */\n+/* { dg-add-options arm_v8_1m_mve_fp } */\n+/* { dg-additional-options \"-O2\" } */\n+\n+#include \"arm_mve.h\"\n+\n+int\n+foows32(uint32x4_t pDataDest, int32x4_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrwq_scatter_base_s32 (pDataDest, 4, value);\n+    vstrwq_scatter_base_s32 (pDataDest, 132, value);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs1, (int32x4_t) pDataDest);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs2, (int32x4_t) pDataDest);\n+    return 0;\n+}\n+\n+int\n+foowu32(uint32x4_t pDataDest, uint32x4_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrwq_scatter_base_u32 (pDataDest, 4, value);\n+    vstrwq_scatter_base_u32 (pDataDest, 132, value);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs1, (int32x4_t) pDataDest);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs2, (int32x4_t) pDataDest);\n+    return 0;\n+}\n+\n+int\n+foowf32(uint32x4_t pDataDest, float32x4_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrwq_scatter_base_f32 (pDataDest, 4, value);\n+    vstrwq_scatter_base_f32 (pDataDest, 132, value);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs1, (int32x4_t) pDataDest);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs2, (int32x4_t) pDataDest);\n+    return 0;\n+}\n+\n+int\n+foods64(uint64x2_t pDataDest, int64x2_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrdq_scatter_base_s64 (pDataDest, 256, value);\n+    vstrdq_scatter_base_s64 (pDataDest, 512, value);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs1, (int32x4_t) pDataDest);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs2, (int32x4_t) pDataDest);\n+    return 0;\n+}\n+\n+int\n+foodu64(uint64x2_t pDataDest, uint64x2_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrdq_scatter_base_u64 (pDataDest, 256, value);\n+    vstrdq_scatter_base_u64 (pDataDest, 512, value);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs1, (int32x4_t) pDataDest);\n+    vstrwq_scatter_offset_s32 (ret, vecOffs2, (int32x4_t) pDataDest);\n+    return 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"vstr\\[a-z\\]\" 20 } } */"}, {"sha": "15c6496732a31259ebcceebeb8ac65e071a04b20", "filename": "gcc/testsuite/gcc.target/arm/mve/intrinsics/mve_vstore_scatter_base_p.c", "status": "added", "additions": 69, "deletions": 0, "changes": 69, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_base_p.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_base_p.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_base_p.c?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -0,0 +1,69 @@\n+/* { dg-require-effective-target arm_v8_1m_mve_fp_ok } */\n+/* { dg-add-options arm_v8_1m_mve_fp } */\n+/* { dg-additional-options \"-O2\" } */\n+\n+#include \"arm_mve.h\"\n+\n+mve_pred16_t __p;\n+\n+int\n+foows32(uint32x4_t pDataDest, int32x4_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrwq_scatter_base_p_s32 (pDataDest, 4, value, __p);\n+    vstrwq_scatter_base_p_s32 (pDataDest, 132, value, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs1, (int32x4_t) pDataDest, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs2, (int32x4_t) pDataDest, __p);\n+    return 0;\n+}\n+\n+int\n+foowu32(uint32x4_t pDataDest, uint32x4_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrwq_scatter_base_p_u32 (pDataDest, 4, value, __p);\n+    vstrwq_scatter_base_p_u32 (pDataDest, 132, value, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs1, (int32x4_t) pDataDest, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs2, (int32x4_t) pDataDest, __p);\n+    return 0;\n+}\n+\n+int\n+foowf32(uint32x4_t pDataDest, float32x4_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrwq_scatter_base_p_f32 (pDataDest, 4, value, __p);\n+    vstrwq_scatter_base_p_f32 (pDataDest, 132, value, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs1, (int32x4_t) pDataDest, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs2, (int32x4_t) pDataDest, __p);\n+    return 0;\n+}\n+\n+int\n+foods64(uint64x2_t pDataDest, int64x2_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrdq_scatter_base_p_s64 (pDataDest, 256, value, __p);\n+    vstrdq_scatter_base_p_s64 (pDataDest, 512, value, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs1, (int32x4_t) pDataDest, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs2, (int32x4_t) pDataDest, __p);\n+    return 0;\n+}\n+\n+int\n+foodu64(uint64x2_t pDataDest, uint64x2_t value, int32_t * ret)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    vstrdq_scatter_base_p_u64 (pDataDest, 256, value, __p);\n+    vstrdq_scatter_base_p_u64 (pDataDest, 512, value, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs1, (int32x4_t) pDataDest, __p);\n+    vstrwq_scatter_offset_p_s32 (ret, vecOffs2, (int32x4_t) pDataDest, __p);\n+    return 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"vstr\\[a-z\\]t\" 20 } } */"}, {"sha": "6d123669c13f168e651b7aa3344c4324fd4afe50", "filename": "gcc/testsuite/gcc.target/arm/mve/intrinsics/mve_vstore_scatter_offset.c", "status": "added", "additions": 215, "deletions": 0, "changes": 215, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_offset.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_offset.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_offset.c?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -0,0 +1,215 @@\n+/* { dg-require-effective-target arm_v8_1m_mve_fp_ok } */\n+/* { dg-add-options arm_v8_1m_mve_fp } */\n+/* { dg-additional-options \"-O2\" } */\n+\n+#include \"arm_mve.h\"\n+\n+int\n+foobu8( uint8_t * pDataSrc, uint8_t * pDataDest)\n+{\n+    const uint8x16_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5, 9, 11, 13, 10, 12, 15, 8, 14};\n+    const uint8x16_t vecOffs2 = { 31, 29, 27, 25, 23, 28, 21, 26, 19, 24, 17, 22, 16, 20, 18, 30};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[16]);\n+    vstrbq_scatter_offset_u8 (pDataDest, vecOffs1, (uint8x16_t) vecIn1);\n+    vstrbq_scatter_offset_u8 (pDataDest, vecOffs2, (uint8x16_t) vecIn2);\n+    pDataDest[32] = pDataSrc[32];\n+    return 0;\n+}\n+\n+int\n+foobu16( uint8_t * pDataSrc, uint8_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrbq_scatter_offset_u16 (pDataDest, vecOffs1, (uint16x8_t) vecIn1);\n+    vstrbq_scatter_offset_u16 (pDataDest, vecOffs2, (uint16x8_t) vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foobu32( uint8_t * pDataSrc, uint8_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrbq_scatter_offset_u32 (pDataDest, vecOffs1, (uint32x4_t) vecIn1);\n+    vstrbq_scatter_offset_u32 (pDataDest, vecOffs2, (uint32x4_t) vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foobs8( int8_t * pDataSrc, int8_t * pDataDest)\n+{\n+    const uint8x16_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5, 9, 11, 13, 10, 12, 15, 8, 14};\n+    const uint8x16_t vecOffs2 = { 31, 29, 27, 25, 23, 28, 21, 26, 19, 24, 17, 22, 16, 20, 18, 30};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[16]);\n+    vstrbq_scatter_offset_s8 (pDataDest, vecOffs1, (int8x16_t) vecIn1);\n+    vstrbq_scatter_offset_s8 (pDataDest, vecOffs2, (int8x16_t) vecIn2);\n+    pDataDest[32] = pDataSrc[32];\n+    return 0;\n+}\n+\n+int\n+foobs16( int8_t * pDataSrc, int8_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[8]);\n+    vstrbq_scatter_offset_s16 (pDataDest, vecOffs1, (int16x8_t) vecIn1);\n+    vstrbq_scatter_offset_s16 (pDataDest, vecOffs2, (int16x8_t) vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foobs32( uint8_t * pDataSrc, int8_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[4]);\n+    vstrbq_scatter_offset_s32 (pDataDest, vecOffs1, (int32x4_t) vecIn1);\n+    vstrbq_scatter_offset_s32 (pDataDest, vecOffs2, (int32x4_t) vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohu16( uint16_t * pDataSrc, uint16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_offset_u16 (pDataDest, vecOffs1, (uint16x8_t) vecIn1);\n+    vstrhq_scatter_offset_u16 (pDataDest, vecOffs2, (uint16x8_t) vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohu32( uint16_t * pDataSrc, uint16_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrhq_scatter_offset_u32 (pDataDest, vecOffs1, (uint32x4_t) vecIn1);\n+    vstrhq_scatter_offset_u32 (pDataDest, vecOffs2, (uint32x4_t) vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohs16( int16_t * pDataSrc, int16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_offset_s16 (pDataDest, vecOffs1, (int16x8_t) vecIn1);\n+    vstrhq_scatter_offset_s16 (pDataDest, vecOffs2, (int16x8_t) vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohs32( uint16_t * pDataSrc, int16_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[4]);\n+    vstrhq_scatter_offset_s32 (pDataDest, vecOffs1, (int32x4_t) vecIn1);\n+    vstrhq_scatter_offset_s32 (pDataDest, vecOffs2, (int32x4_t) vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohf16( float16_t * pDataSrc, float16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_offset_f16 (pDataDest, vecOffs1, (float16x8_t) vecIn1);\n+    vstrhq_scatter_offset_f16 (pDataDest, vecOffs2, (float16x8_t) vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foowu32( uint32_t * pDataSrc, uint32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrwq_scatter_offset_u32 (pDataDest, vecOffs1, (uint32x4_t) vecIn1);\n+    vstrwq_scatter_offset_u32 (pDataDest, vecOffs2, (uint32x4_t) vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foows32( int32_t * pDataSrc, int32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrwq_scatter_offset_s32 (pDataDest, vecOffs1, (int32x4_t) vecIn1);\n+    vstrwq_scatter_offset_s32 (pDataDest, vecOffs2, (int32x4_t) vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foowf32( float32_t * pDataSrc, float32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrwq_scatter_offset_f32 (pDataDest, vecOffs1, (float32x4_t) vecIn1);\n+    vstrwq_scatter_offset_f32 (pDataDest, vecOffs2, (float32x4_t) vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foowu64( uint64_t * pDataSrc, uint64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 3};\n+    const uint64x2_t vecOffs2 = { 1, 2};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[2]);\n+    vstrdq_scatter_offset_u64 (pDataDest, vecOffs1, (uint64x2_t) vecIn1);\n+    vstrdq_scatter_offset_u64 (pDataDest, vecOffs2, (uint64x2_t) vecIn2);\n+    pDataDest[4] = pDataSrc[4];\n+    return 0;\n+}\n+\n+int\n+foows64( int64_t * pDataSrc, int64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 3};\n+    const uint64x2_t vecOffs2 = { 1, 2};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[2]);\n+    vstrdq_scatter_offset_s64 (pDataDest, vecOffs1, (int64x2_t) vecIn1);\n+    vstrdq_scatter_offset_s64 (pDataDest, vecOffs2, (int64x2_t) vecIn2);\n+    pDataDest[4] = pDataSrc[4];\n+    return 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"vstr\\[a-z\\]\" 32 } } */"}, {"sha": "cd2e1ee80f9dfe35955468a822bd202679039831", "filename": "gcc/testsuite/gcc.target/arm/mve/intrinsics/mve_vstore_scatter_offset_p.c", "status": "added", "additions": 216, "deletions": 0, "changes": 216, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_offset_p.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_offset_p.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_offset_p.c?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -0,0 +1,216 @@\n+/* { dg-require-effective-target arm_v8_1m_mve_fp_ok } */\n+/* { dg-add-options arm_v8_1m_mve_fp } */\n+/* { dg-additional-options \"-O2\" } */\n+\n+#include \"arm_mve.h\"\n+\n+mve_pred16_t __p;\n+int\n+foobu8( uint8_t * pDataSrc, uint8_t * pDataDest)\n+{\n+    const uint8x16_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5, 9, 11, 13, 10, 12, 15, 8, 14};\n+    const uint8x16_t vecOffs2 = { 31, 29, 27, 25, 23, 28, 21, 26, 19, 24, 17, 22, 16, 20, 18, 30};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[16]);\n+    vstrbq_scatter_offset_p_u8(pDataDest, vecOffs1, (uint8x16_t) vecIn1, __p);\n+    vstrbq_scatter_offset_p_u8(pDataDest, vecOffs2, (uint8x16_t) vecIn2, __p);\n+    pDataDest[32] = pDataSrc[32];\n+    return 0;\n+}\n+\n+int\n+foobu16( uint8_t * pDataSrc, uint8_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrbq_scatter_offset_p_u16 (pDataDest, vecOffs1, (uint16x8_t) vecIn1, __p);\n+    vstrbq_scatter_offset_p_u16 (pDataDest, vecOffs2, (uint16x8_t) vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foobu32( uint8_t * pDataSrc, uint8_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrbq_scatter_offset_p_u32 (pDataDest, vecOffs1, (uint32x4_t) vecIn1, __p);\n+    vstrbq_scatter_offset_p_u32 (pDataDest, vecOffs2, (uint32x4_t) vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foobs8( int8_t * pDataSrc, int8_t * pDataDest)\n+{\n+    const uint8x16_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5, 9, 11, 13, 10, 12, 15, 8, 14};\n+    const uint8x16_t vecOffs2 = { 31, 29, 27, 25, 23, 28, 21, 26, 19, 24, 17, 22, 16, 20, 18, 30};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[16]);\n+    vstrbq_scatter_offset_p_s8 (pDataDest, vecOffs1, (int8x16_t) vecIn1, __p);\n+    vstrbq_scatter_offset_p_s8 (pDataDest, vecOffs2, (int8x16_t) vecIn2, __p);\n+    pDataDest[32] = pDataSrc[32];\n+    return 0;\n+}\n+\n+int\n+foobs16( int8_t * pDataSrc, int8_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[8]);\n+    vstrbq_scatter_offset_p_s16 (pDataDest, vecOffs1, (int16x8_t) vecIn1, __p);\n+    vstrbq_scatter_offset_p_s16 (pDataDest, vecOffs2, (int16x8_t) vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foobs32( uint8_t * pDataSrc, int8_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[4]);\n+    vstrbq_scatter_offset_p_s32 (pDataDest, vecOffs1, (int32x4_t) vecIn1, __p);\n+    vstrbq_scatter_offset_p_s32 (pDataDest, vecOffs2, (int32x4_t) vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohu16( uint16_t * pDataSrc, uint16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_offset_p_u16 (pDataDest, vecOffs1, (uint16x8_t) vecIn1, __p);\n+    vstrhq_scatter_offset_p_u16 (pDataDest, vecOffs2, (uint16x8_t) vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohu32( uint16_t * pDataSrc, uint16_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrhq_scatter_offset_p_u32 (pDataDest, vecOffs1, (uint32x4_t) vecIn1, __p);\n+    vstrhq_scatter_offset_p_u32 (pDataDest, vecOffs2, (uint32x4_t) vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohs16( int16_t * pDataSrc, int16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_offset_p_s16 (pDataDest, vecOffs1, (int16x8_t) vecIn1, __p);\n+    vstrhq_scatter_offset_p_s16 (pDataDest, vecOffs2, (int16x8_t) vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohs32( uint16_t * pDataSrc, int16_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[4]);\n+    vstrhq_scatter_offset_p_s32 (pDataDest, vecOffs1, (int32x4_t) vecIn1, __p);\n+    vstrhq_scatter_offset_p_s32 (pDataDest, vecOffs2, (int32x4_t) vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohf16( float16_t * pDataSrc, float16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 11, 13, 10, 12, 15, 8, 14, 9};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_offset_p_f16 (pDataDest, vecOffs1, (float16x8_t) vecIn1, __p);\n+    vstrhq_scatter_offset_p_f16 (pDataDest, vecOffs2, (float16x8_t) vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foowu32( uint32_t * pDataSrc, uint32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrwq_scatter_offset_p_u32 (pDataDest, vecOffs1, (uint32x4_t) vecIn1, __p);\n+    vstrwq_scatter_offset_p_u32 (pDataDest, vecOffs2, (uint32x4_t) vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foows32( int32_t * pDataSrc, int32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrwq_scatter_offset_p_s32 (pDataDest, vecOffs1, (int32x4_t) vecIn1, __p);\n+    vstrwq_scatter_offset_p_s32 (pDataDest, vecOffs2, (int32x4_t) vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foowf32( float32_t * pDataSrc, float32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[8]);\n+    vstrwq_scatter_offset_p_f32 (pDataDest, vecOffs1, (float32x4_t) vecIn1, __p);\n+    vstrwq_scatter_offset_p_f32 (pDataDest, vecOffs2, (float32x4_t) vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foowu64( uint64_t * pDataSrc, uint64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 3};\n+    const uint64x2_t vecOffs2 = { 1, 2};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[2]);\n+    vstrdq_scatter_offset_p_u64 (pDataDest, vecOffs1, (uint64x2_t) vecIn1, __p);\n+    vstrdq_scatter_offset_p_u64 (pDataDest, vecOffs2, (uint64x2_t) vecIn2, __p);\n+    pDataDest[4] = pDataSrc[4];\n+    return 0;\n+}\n+\n+int\n+foows64( int64_t * pDataSrc, int64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 3};\n+    const uint64x2_t vecOffs2 = { 1, 2};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[2]);\n+    vstrdq_scatter_offset_p_s64 (pDataDest, vecOffs1, (int64x2_t) vecIn1, __p);\n+    vstrdq_scatter_offset_p_s64 (pDataDest, vecOffs2, (int64x2_t) vecIn2, __p);\n+    pDataDest[4] = pDataSrc[4];\n+    return 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"vstr\\[a-z\\]t\" 32 } } */"}, {"sha": "62dfb450a6d30312472f5c8bb2d41e98fe6b6a32", "filename": "gcc/testsuite/gcc.target/arm/mve/intrinsics/mve_vstore_scatter_shifted_offset.c", "status": "added", "additions": 141, "deletions": 0, "changes": 141, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_shifted_offset.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_shifted_offset.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_shifted_offset.c?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -0,0 +1,141 @@\n+/* { dg-require-effective-target arm_v8_1m_mve_fp_ok } */\n+/* { dg-add-options arm_v8_1m_mve_fp } */\n+/* { dg-additional-options \"-O2\" } */\n+\n+#include \"arm_mve.h\"\n+\n+int\n+foowu32( uint32_t * pDataSrc, uint32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[4]);\n+    vstrwq_scatter_shifted_offset_u32 (pDataDest, vecOffs1, vecIn1);\n+    vstrwq_scatter_shifted_offset_u32 (pDataDest, vecOffs2, vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foowf32( float32_t * pDataSrc, float32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    float32x4_t vecIn1 = vldrwq_f32 ((float32_t const *) pDataSrc);\n+    float32x4_t vecIn2 = vldrwq_f32 ((float32_t const *) &pDataSrc[4]);\n+    vstrwq_scatter_shifted_offset_f32 (pDataDest, vecOffs1, vecIn1);\n+    vstrwq_scatter_shifted_offset_f32 (pDataDest, vecOffs2, vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohu16( uint16_t * pDataSrc, uint16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 9, 11, 13, 10, 12, 15, 8, 14};\n+    uint16x8_t vecIn1 = vldrhq_u16 ((uint16_t const *) pDataSrc);\n+    uint16x8_t vecIn2 = vldrhq_u16 ((uint16_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_shifted_offset_u16 (pDataDest, vecOffs1, vecIn1);\n+    vstrhq_scatter_shifted_offset_u16 (pDataDest, vecOffs2, vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohu32( uint32_t * pDataSrc, uint32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrhq_u32 ((uint16_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrhq_u32 ((uint16_t const *) &pDataSrc[4]);\n+    vstrhq_scatter_shifted_offset_u32 ((uint16_t *)pDataDest, vecOffs1, vecIn1);\n+    vstrhq_scatter_shifted_offset_u32 ((uint16_t *)pDataDest, vecOffs2, vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohf16( float16_t * pDataSrc, float16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 9, 11, 13, 10, 12, 15, 8, 14};\n+    float16x8_t vecIn1 = vldrhq_f16 ((float16_t const *) pDataSrc);\n+    float16x8_t vecIn2 = vldrhq_f16 ((float16_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_shifted_offset_f16 (pDataDest, vecOffs1, vecIn1);\n+    vstrhq_scatter_shifted_offset_f16 (pDataDest, vecOffs2, vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foodu64( uint64_t * pDataSrc, uint64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 1};\n+    const uint64x2_t vecOffs2 = { 2, 3};\n+    uint32x4_t vecIn1 = vldrwq_u32 ((uint32_t const *) pDataSrc);\n+    uint32x4_t vecIn2 = vldrwq_u32 ((uint32_t const *) &pDataSrc[2]);\n+\n+    vstrdq_scatter_shifted_offset_u64 (pDataDest, vecOffs1, (uint64x2_t) vecIn1);\n+    vstrdq_scatter_shifted_offset_u64 (pDataDest, vecOffs2, (uint64x2_t) vecIn2);\n+\n+    pDataDest[2] = pDataSrc[2];\n+    return 0;\n+}\n+\n+int\n+foows32( int32_t * pDataSrc, int32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[4]);\n+    vstrwq_scatter_shifted_offset_s32 (pDataDest, vecOffs1, vecIn1);\n+    vstrwq_scatter_shifted_offset_s32 (pDataDest, vecOffs2, vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohs16( int16_t * pDataSrc, int16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 9, 11, 13, 10, 12, 15, 8, 14};\n+    int16x8_t vecIn1 = vldrhq_s16 ((int16_t const *) pDataSrc);\n+    int16x8_t vecIn2 = vldrhq_s16 ((int16_t const *) &pDataSrc[8]);\n+    vstrhq_scatter_shifted_offset_s16 (pDataDest, vecOffs1, vecIn1);\n+    vstrhq_scatter_shifted_offset_s16 (pDataDest, vecOffs2, vecIn2);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohs32( int32_t * pDataSrc, int32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrhq_s32 ((int16_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrhq_s32 ((int16_t const *) &pDataSrc[4]);\n+    vstrhq_scatter_shifted_offset_s32 ((int16_t *)pDataDest, vecOffs1, vecIn1);\n+    vstrhq_scatter_shifted_offset_s32 ((int16_t *)pDataDest, vecOffs2, vecIn2);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foods64( int64_t * pDataSrc, int64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 1};\n+    const uint64x2_t vecOffs2 = { 2, 3};\n+    int32x4_t vecIn1 = vldrwq_s32 ((int32_t const *) pDataSrc);\n+    int32x4_t vecIn2 = vldrwq_s32 ((int32_t const *) &pDataSrc[2]);\n+\n+    vstrdq_scatter_shifted_offset_s64 (pDataDest, vecOffs1, (int64x2_t) vecIn1);\n+    vstrdq_scatter_shifted_offset_s64 (pDataDest, vecOffs2, (int64x2_t) vecIn2);\n+\n+    pDataDest[2] = pDataSrc[2];\n+    return 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"vstr\\[a-z\\]\" 20 } } */"}, {"sha": "a51d3a211672e74e99f571ef362445d13f2e2368", "filename": "gcc/testsuite/gcc.target/arm/mve/intrinsics/mve_vstore_scatter_shifted_offset_p.c", "status": "added", "additions": 142, "deletions": 0, "changes": 142, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_shifted_offset_p.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9a810e57c4e6af54d29c325a013f451ade2b85e8/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_shifted_offset_p.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fmve%2Fintrinsics%2Fmve_vstore_scatter_shifted_offset_p.c?ref=9a810e57c4e6af54d29c325a013f451ade2b85e8", "patch": "@@ -0,0 +1,142 @@\n+/* { dg-require-effective-target arm_v8_1m_mve_fp_ok } */\n+/* { dg-add-options arm_v8_1m_mve_fp } */\n+/* { dg-additional-options \"-O2\" } */\n+\n+#include \"arm_mve.h\"\n+\n+mve_pred16_t __p;\n+int\n+foowu32( uint32_t * pDataSrc, uint32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrwq_z_u32 ((uint32_t const *) pDataSrc, __p);\n+    uint32x4_t vecIn2 = vldrwq_z_u32 ((uint32_t const *) &pDataSrc[4], __p);\n+    vstrwq_scatter_shifted_offset_p_u32 (pDataDest, vecOffs1, vecIn1, __p);\n+    vstrwq_scatter_shifted_offset_p_u32 (pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foowf32( float32_t * pDataSrc, float32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    float32x4_t vecIn1 = vldrwq_z_f32 ((float32_t const *) pDataSrc, __p);\n+    float32x4_t vecIn2 = vldrwq_z_f32 ((float32_t const *) &pDataSrc[4], __p);\n+    vstrwq_scatter_shifted_offset_p_f32 (pDataDest, vecOffs1, vecIn1, __p);\n+    vstrwq_scatter_shifted_offset_p_f32 (pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohu16( uint16_t * pDataSrc, uint16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 9, 11, 13, 10, 12, 15, 8, 14};\n+    uint16x8_t vecIn1 = vldrhq_z_u16 ((uint16_t const *) pDataSrc, __p);\n+    uint16x8_t vecIn2 = vldrhq_z_u16 ((uint16_t const *) &pDataSrc[8], __p);\n+    vstrhq_scatter_shifted_offset_p_u16 (pDataDest, vecOffs1, vecIn1, __p);\n+    vstrhq_scatter_shifted_offset_p_u16 (pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohu32( uint32_t * pDataSrc, uint32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    uint32x4_t vecIn1 = vldrhq_z_u32 ((uint16_t const *) pDataSrc, __p);\n+    uint32x4_t vecIn2 = vldrhq_z_u32 ((uint16_t const *) &pDataSrc[4], __p);\n+    vstrhq_scatter_shifted_offset_p_u32 ((uint16_t *)pDataDest, vecOffs1, vecIn1, __p);\n+    vstrhq_scatter_shifted_offset_p_u32 ((uint16_t *)pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohf16( float16_t * pDataSrc, float16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 9, 11, 13, 10, 12, 15, 8, 14};\n+    float16x8_t vecIn1 = vldrhq_z_f16 ((float16_t const *) pDataSrc, __p);\n+    float16x8_t vecIn2 = vldrhq_z_f16 ((float16_t const *) &pDataSrc[8], __p);\n+    vstrhq_scatter_shifted_offset_p_f16 (pDataDest, vecOffs1, vecIn1, __p);\n+    vstrhq_scatter_shifted_offset_p_f16 (pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foodu64( uint64_t * pDataSrc, uint64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 1};\n+    const uint64x2_t vecOffs2 = { 2, 3};\n+    uint32x4_t vecIn1 = vldrwq_z_u32 ((uint32_t const *) pDataSrc, __p);\n+    uint32x4_t vecIn2 = vldrwq_z_u32 ((uint32_t const *) &pDataSrc[2], __p);\n+\n+    vstrdq_scatter_shifted_offset_p_u64 (pDataDest, vecOffs1, (uint64x2_t) vecIn1, __p);\n+    vstrdq_scatter_shifted_offset_p_u64 (pDataDest, vecOffs2, (uint64x2_t) vecIn2, __p);\n+\n+    pDataDest[2] = pDataSrc[2];\n+    return 0;\n+}\n+\n+int\n+foows32( int32_t * pDataSrc, int32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrwq_z_s32 ((int32_t const *) pDataSrc, __p);\n+    int32x4_t vecIn2 = vldrwq_z_s32 ((int32_t const *) &pDataSrc[4], __p);\n+    vstrwq_scatter_shifted_offset_p_s32 (pDataDest, vecOffs1, vecIn1, __p);\n+    vstrwq_scatter_shifted_offset_p_s32 (pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foohs16( int16_t * pDataSrc, int16_t * pDataDest)\n+{\n+    const uint16x8_t vecOffs1 = { 0, 3, 6, 1, 4, 7, 2, 5};\n+    const uint16x8_t vecOffs2 = { 9, 11, 13, 10, 12, 15, 8, 14};\n+    int16x8_t vecIn1 = vldrhq_z_s16 ((int16_t const *) pDataSrc, __p);\n+    int16x8_t vecIn2 = vldrhq_z_s16 ((int16_t const *) &pDataSrc[8], __p);\n+    vstrhq_scatter_shifted_offset_p_s16 (pDataDest, vecOffs1, vecIn1, __p);\n+    vstrhq_scatter_shifted_offset_p_s16 (pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[16] = pDataSrc[16];\n+    return 0;\n+}\n+\n+int\n+foohs32( int32_t * pDataSrc, int32_t * pDataDest)\n+{\n+    const uint32x4_t vecOffs1 = { 0, 3, 6, 1};\n+    const uint32x4_t vecOffs2 = { 4, 7, 2, 5};\n+    int32x4_t vecIn1 = vldrhq_z_s32 ((int16_t const *) pDataSrc, __p);\n+    int32x4_t vecIn2 = vldrhq_z_s32 ((int16_t const *) &pDataSrc[4], __p);\n+    vstrhq_scatter_shifted_offset_p_s32 ((int16_t *)pDataDest, vecOffs1, vecIn1, __p);\n+    vstrhq_scatter_shifted_offset_p_s32 ((int16_t *)pDataDest, vecOffs2, vecIn2, __p);\n+    pDataDest[8] = pDataSrc[8];\n+    return 0;\n+}\n+\n+int\n+foods64( int64_t * pDataSrc, int64_t * pDataDest)\n+{\n+    const uint64x2_t vecOffs1 = { 0, 1};\n+    const uint64x2_t vecOffs2 = { 2, 3};\n+    int32x4_t vecIn1 = vldrwq_z_s32 ((int32_t const *) pDataSrc, __p);\n+    int32x4_t vecIn2 = vldrwq_z_s32 ((int32_t const *) &pDataSrc[2], __p);\n+\n+    vstrdq_scatter_shifted_offset_p_s64 (pDataDest, vecOffs1, (int64x2_t) vecIn1, __p);\n+    vstrdq_scatter_shifted_offset_p_s64 (pDataDest, vecOffs2, (int64x2_t) vecIn2, __p);\n+\n+    pDataDest[2] = pDataSrc[2];\n+    return 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"vstr\\[a-z\\]t\" 20 } } */"}]}