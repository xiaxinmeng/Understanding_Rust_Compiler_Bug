{"sha": "f9957958fe143fd987e0c3e339d2586dc7cc06cd", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Zjk5NTc5NThmZTE0M2ZkOTg3ZTBjM2UzMzlkMjU4NmRjN2NjMDZjZA==", "commit": {"author": {"name": "Mostafa Hagog", "email": "mustafa@il.ibm.com", "date": "2004-03-03T16:32:45Z"}, "committer": {"name": "David Edelsohn", "email": "dje@gcc.gnu.org", "date": "2004-03-03T16:32:45Z"}, "message": "common.opt: Add description of the new -fgcse-after-reload flag.\n\n2004-03-03  Mostafa Hagog  <mustafa@il.ibm.com>\n\n        * common.opt: Add description of the new -fgcse-after-reload flag.\n\n        * flags.h (flag_gcse_after_reload): Declaration of global variable.\n\n        * gcse.c (reg_used_on_edge ,reg_set_between_after_reload_p,\n        reg_used_between_after_reload_p, rtx get_avail_load_store_reg,\n        is_jump_table_basic_block, bb_has_well_behaved_predecessors,\n        get_bb_avail_insn, hash_scan_set_after_reload,\n        compute_hash_table_after_reload, eliminate_partially_redundant_loads,\n        gcse_after_reload, get_bb_avail_insn): New functions to implement\n        gcse-after-reload.\n        (gcse_after_reload_main): New function, the main entry point to\n        gcse-after-reload.\n\n        * rtl.h (gcse_after_reload_main): Declaration of the new function.\n\n        * opts.c (common_handle_option): Handle the -fgcse-after-reload flag.\n\n        * toplev.c (flag_gcse_after_reload): Initialization.\n\n        * passes.c (rest_of_handl_gcse2): Call gcse_after_reload_main.\n\n        * params.def (PARAM_GCSE_AFTER_RELOAD_PARTIAL_FRACTION,\n        PARAM_GCSE_AFTER_RELOAD_CRITICAL_FRACTION): New parameters for tuning\n        the gcse after reload optimization.\n\n        * params.h (GCSE_AFTER_RELOAD_PARTIAL_FRACTION,\n        GCSE_AFTER_RELOAD_CRITICAL_FRACTION): Two macros to access the tuning\n        parameters.\n\n        * doc/invoke.texi: Documentation for the new flag gcse-after-reload.\n\nFrom-SVN: r78842", "tree": {"sha": "a9a88dd3608db538ae3d670cde68145ab19f3038", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a9a88dd3608db538ae3d670cde68145ab19f3038"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/f9957958fe143fd987e0c3e339d2586dc7cc06cd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f9957958fe143fd987e0c3e339d2586dc7cc06cd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f9957958fe143fd987e0c3e339d2586dc7cc06cd", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f9957958fe143fd987e0c3e339d2586dc7cc06cd/comments", "author": null, "committer": null, "parents": [{"sha": "6f6dedf5bdc043a65453543e03a055d6251c17e7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6f6dedf5bdc043a65453543e03a055d6251c17e7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6f6dedf5bdc043a65453543e03a055d6251c17e7"}], "stats": {"total": 756, "additions": 750, "deletions": 6}, "files": [{"sha": "86c9d2e6f9347938449f985f445b60e8d8bd9845", "filename": "gcc/ChangeLog", "status": "modified", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -1,3 +1,37 @@\n+2004-03-03  Mostafa Hagog  <mustafa@il.ibm.com>\n+\n+\t* common.opt: Add description of the new -fgcse-after-reload flag.\n+\n+\t* flags.h (flag_gcse_after_reload): Declaration of global variable.\n+\n+\t* gcse.c (reg_used_on_edge ,reg_set_between_after_reload_p,\n+\treg_used_between_after_reload_p, rtx get_avail_load_store_reg,\n+\tis_jump_table_basic_block, bb_has_well_behaved_predecessors,\n+\tget_bb_avail_insn, hash_scan_set_after_reload,\n+\tcompute_hash_table_after_reload, eliminate_partially_redundant_loads,\n+\tgcse_after_reload, get_bb_avail_insn): New functions to implement\n+\tgcse-after-reload.\n+\t(gcse_after_reload_main): New function, the main entry point to\n+\tgcse-after-reload.\n+\n+\t* rtl.h (gcse_after_reload_main): Declaration of the new function.\n+\n+\t* opts.c (common_handle_option): Handle the -fgcse-after-reload flag.\n+\n+\t* toplev.c (flag_gcse_after_reload): Initialization.\n+\n+\t* passes.c (rest_of_handl_gcse2): Call gcse_after_reload_main.\n+\n+\t* params.def (PARAM_GCSE_AFTER_RELOAD_PARTIAL_FRACTION,\n+\tPARAM_GCSE_AFTER_RELOAD_CRITICAL_FRACTION): New parameters for tuning\n+\tthe gcse after reload optimization.\n+\n+\t* params.h (GCSE_AFTER_RELOAD_PARTIAL_FRACTION,\n+\tGCSE_AFTER_RELOAD_CRITICAL_FRACTION): Two macros to access the tuning\n+\tparameters.\n+\n+\t* doc/invoke.texi: Documentation for the new flag gcse-after-reload.\n+\n 2004-03-03  Nicolas Pitre <nico@cam.org>\n \n \t* config/arm/ieee754-df.S (muldf3, divdf3): Fix denormalization of"}, {"sha": "d9faa60a8f5203f4f2eb4a065792a39691147a5b", "filename": "gcc/common.opt", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fcommon.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fcommon.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcommon.opt?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -371,7 +371,13 @@ Perform store motion after global common subexpression elimination\n \n fgcse-las\n Common\n-Perform redundant load after store elimination in global common subexpression elimination\n+Perform redundant load after store elimination in global common subexpression\n+elimination\n+\n+fgcse-after-reload\n+Common\n+Perform global common subexpression elimination after register allocation\n+has finished.\n \n fguess-branch-probability\n Common"}, {"sha": "26b9a127bec85caa012d02f7ba0c3342c82efe7d", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 10, "deletions": 3, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -270,8 +270,8 @@ in the following sections.\n -fdelayed-branch  -fdelete-null-pointer-checks @gol\n -fexpensive-optimizations  -ffast-math  -ffloat-store @gol\n -fforce-addr  -fforce-mem  -ffunction-sections @gol\n--fgcse  -fgcse-lm  -fgcse-sm  -fgcse-las  -floop-optimize @gol\n--fcrossjumping  -fif-conversion  -fif-conversion2 @gol\n+-fgcse  -fgcse-lm  -fgcse-sm  -fgcse-las  -fgcse-after-reload @gol\n+-floop-optimize -fcrossjumping  -fif-conversion  -fif-conversion2 @gol\n -finline-functions  -finline-limit=@var{n}  -fkeep-inline-functions @gol\n -fkeep-static-consts  -fmerge-constants  -fmerge-all-constants @gol\n -fmove-all-movables  -fnew-ra  -fno-branch-count-reg @gol\n@@ -3646,7 +3646,8 @@ invoking @option{-O2} on programs that use computed gotos.\n @opindex O3\n Optimize yet more.  @option{-O3} turns on all optimizations specified by\n @option{-O2} and also turns on the @option{-finline-functions},\n-@option{-fweb} and @option{-frename-registers} options.\n+@option{-fweb}, @option{-frename-registers}\n+and @option{-fgcse-after-reload} options.\n \n @item -O0\n @opindex O0\n@@ -3957,6 +3958,12 @@ same memory location (both partial and full redundancies).\n \n Enabled by default when gcse is enabled.\n \n+@item -fgcse-after-reload\n+@opindex fgcse-after-reload\n+When @option{-fgcse-after-reload} is enabled, a redundant load elimination\n+pass is performed after reload. The purpose of this pass is to cleanup\n+redundant spilling.\n+\n @item -floop-optimize\n @opindex floop-optimize\n Perform loop optimizations: move constant expressions out of loops, simplify"}, {"sha": "b088f6cb3ba6d0ee2b761ae953eda3f2d279f135", "filename": "gcc/flags.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fflags.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fflags.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fflags.h?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -672,6 +672,11 @@ extern int flag_gcse_sm;\n \n extern int flag_gcse_las;\n \n+/* Nonzero if we want to perform global redundancy elimination after\n+   register allocation.  */\n+\n+extern int flag_gcse_after_reload;\n+\n /* Nonzero if value histograms should be used to optimize code.  */\n extern int flag_value_profile_transformations;\n "}, {"sha": "975fb1fbe2fe92402539f7afc0720022e986f1ff", "filename": "gcc/gcse.c", "status": "modified", "additions": 638, "deletions": 0, "changes": 638, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fgcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fgcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgcse.c?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -1980,6 +1980,7 @@ insert_expr_in_table (rtx x, enum machine_mode mode, rtx insn, int antic_p,\n \n \t  antic_occr->insn = insn;\n \t  antic_occr->next = NULL;\n+\t  antic_occr->deleted_p = 0;\n \t}\n     }\n \n@@ -2016,6 +2017,7 @@ insert_expr_in_table (rtx x, enum machine_mode mode, rtx insn, int antic_p,\n \n \t  avail_occr->insn = insn;\n \t  avail_occr->next = NULL;\n+\t  avail_occr->deleted_p = 0;\n \t}\n     }\n }\n@@ -2102,6 +2104,7 @@ insert_set_in_table (rtx x, rtx insn, struct hash_table *table)\n \n       cur_occr->insn = insn;\n       cur_occr->next = NULL;\n+      cur_occr->deleted_p = 0;\n     }\n }\n \n@@ -8091,4 +8094,639 @@ is_too_expensive (const char *pass)\n   return false;\n }\n \n+/* The following code implements gcse after reload, the purpose of this\n+   pass is to cleanup redundant loads generated by reload and other\n+   optimizations that come after gcse. It searches for simple inter-block\n+   redundancies and tries to eliminate them by adding moves and loads\n+   in cold places.  */\n+\n+/* The following structure holds the information about the occurrences of\n+   the redundant instructions.  */\n+struct unoccr\n+{\n+  struct unoccr *next;\n+  edge pred;\n+  rtx insn;\n+};\n+\n+static bool reg_used_on_edge (rtx, edge);\n+static rtx reg_set_between_after_reload_p (rtx, rtx, rtx);\n+static rtx reg_used_between_after_reload_p (rtx, rtx, rtx);\n+static rtx get_avail_load_store_reg (rtx);\n+static bool is_jump_table_basic_block (basic_block);\n+static bool bb_has_well_behaved_predecessors (basic_block);\n+static struct occr* get_bb_avail_insn (basic_block, struct occr *);\n+static void hash_scan_set_after_reload (rtx, rtx, struct hash_table *);\n+static void compute_hash_table_after_reload (struct hash_table *);\n+static void eliminate_partially_redundant_loads (basic_block,\n+\t\t\t\t\t\trtx,\n+\t\t\t\t\t\tstruct expr *);\n+static void gcse_after_reload (void);\n+static struct occr* get_bb_avail_insn (basic_block, struct occr *);\n+void gcse_after_reload_main (rtx, FILE *);\n+\n+\n+/* Check if register REG is used in any insn waiting to be inserted on E.\n+   Assumes no such insn can be a CALL_INSN; if so call reg_used_between_p\n+   with PREV(insn),NEXT(insn) instead of calling\n+   reg_overlap_mentioned_p.  */\n+\n+static bool\n+reg_used_on_edge (rtx reg, edge e)\n+{\n+  rtx insn;\n+\n+  for (insn = e->insns; insn; insn = NEXT_INSN (insn))\n+    if (INSN_P (insn) && reg_overlap_mentioned_p (reg, PATTERN (insn)))\n+      return true;\n+\n+  return false;\n+}\n+\n+/* Return the insn that sets register REG or clobbers it in between\n+   FROM_INSN and TO_INSN (exclusive of those two).\n+   Just like reg_set_between but for hard registers and not pseudos.  */\n+\n+static rtx\n+reg_set_between_after_reload_p (rtx reg, rtx from_insn, rtx to_insn)\n+{\n+  rtx insn;\n+  int regno;\n+\n+  if (GET_CODE (reg) != REG)\n+    abort ();\n+  regno = REGNO (reg);\n+\n+  /* We are called after register allocation.  */\n+  if (regno >= FIRST_PSEUDO_REGISTER)\n+    abort ();\n+\n+  if (from_insn == to_insn)\n+    return NULL_RTX;\n+\n+  for (insn = NEXT_INSN (from_insn);\n+       insn != to_insn;\n+       insn = NEXT_INSN (insn))\n+    {\n+      if (INSN_P (insn))\n+\t{\n+\t  if (FIND_REG_INC_NOTE (insn, reg)\n+\t      || (GET_CODE (insn) == CALL_INSN\n+\t\t  && call_used_regs[regno])\n+\t      || find_reg_fusage (insn, CLOBBER, reg))\n+\t    return insn;\n+\t}\n+      if (set_of (reg, insn) != NULL_RTX)\n+\treturn insn;\n+    }\n+  return NULL_RTX;\n+}\n+\n+/* Return the insn that uses register REG in between FROM_INSN and TO_INSN\n+   (exclusive of those two). Similar to reg_used_between but for hard\n+   registers and not pseudos.  */\n+\n+static rtx\n+reg_used_between_after_reload_p (rtx reg, rtx from_insn, rtx to_insn)\n+{\n+  rtx insn;\n+  int regno;\n+\n+  if (GET_CODE (reg) != REG)\n+    return to_insn;\n+  regno = REGNO (reg);\n+\n+  /* We are called after register allocation.  */\n+  if (regno >= FIRST_PSEUDO_REGISTER)\n+    abort ();\n+  if (from_insn == to_insn)\n+    return NULL_RTX;\n+\n+  for (insn = NEXT_INSN (from_insn);\n+       insn != to_insn;\n+       insn = NEXT_INSN (insn))\n+    if (INSN_P (insn)\n+\t&& (reg_overlap_mentioned_p (reg, PATTERN (insn))\n+\t    || (GET_CODE (insn) == CALL_INSN\n+\t\t&& call_used_regs[regno])\n+\t    || find_reg_fusage (insn, USE, reg)\n+\t    || find_reg_fusage (insn, CLOBBER, reg)))\n+      return insn;\n+  return NULL_RTX;\n+}\n+\n+/* Return the loaded/stored register of a load/store instruction.  */\n+\n+static rtx\n+get_avail_load_store_reg (rtx insn)\n+{\n+  if (GET_CODE (SET_DEST (PATTERN (insn))) == REG)  /* A load.  */\n+    return SET_DEST(PATTERN(insn));\n+  if (GET_CODE (SET_SRC (PATTERN (insn))) == REG)  /* A store.  */\n+    return SET_SRC (PATTERN (insn));\n+  abort ();\n+}\n+\n+/* Don't handle ABNORMAL edges or jump tables.  */\n+\n+static bool\n+is_jump_table_basic_block (basic_block bb)\n+{\n+  rtx insn = BB_END (bb);\n+\n+  if (GET_CODE (insn) == JUMP_INSN &&\n+      (GET_CODE (PATTERN (insn)) == ADDR_VEC\n+       || GET_CODE (PATTERN (insn)) == ADDR_DIFF_VEC))\n+    return true;\n+  return false;\n+}\n+\n+/* Return nonzero if the predecessors of BB are \"well behaved\".  */\n+\n+static bool\n+bb_has_well_behaved_predecessors (basic_block bb)\n+{\n+  edge pred;\n+\n+  if (! bb->pred)\n+    return false;\n+  for (pred = bb->pred; pred != NULL; pred = pred->pred_next)\n+    if (((pred->flags & EDGE_ABNORMAL) && EDGE_CRITICAL_P (pred))\n+\t|| is_jump_table_basic_block (pred->src))\n+      return false;\n+  return true;\n+}\n+\n+\n+/* Search for the occurrences of expression in BB.  */\n+\n+static struct occr*\n+get_bb_avail_insn (basic_block bb, struct occr *occr)\n+{\n+  for (; occr != NULL; occr = occr->next)\n+    if (BLOCK_FOR_INSN (occr->insn)->index == bb->index)\n+      return occr;\n+  return NULL;\n+}\n+\n+/* Perform partial GCSE pass after reload, try to eliminate redundant loads\n+   created by the reload pass. We try to look for a full or partial\n+   redundant loads fed by one or more loads/stores in predecessor BBs,\n+   and try adding loads to make them fully redundant. We also check if\n+   it's worth adding loads to be able to delete the redundant load.\n+\n+   Algorithm:\n+   1. Build available expressions hash table:\n+       For each load/store instruction, if the loaded/stored memory didn't\n+       change until the end of the basic block add this memory expression to\n+       the hash table.\n+   2. Perform Redundancy elimination:\n+      For each load instruction do the following:\n+\t perform partial redundancy elimination, check if it's worth adding\n+\t loads to make the load fully redundant. If so add loads and\n+\t register copies and delete the load.\n+\n+   Future enhancement:\n+     if loaded register is used/defined between load and some store,\n+     look for some other free register between load and all its stores,\n+     and replace load with a copy from this register to the loaded\n+     register.  */\n+\n+\n+/* This handles the case where several stores feed a partially redundant\n+   load. It checks if the redundancy elimination is possible and if it's\n+   worth it.  */\n+\n+static void\n+eliminate_partially_redundant_loads (basic_block bb, rtx insn,\n+\t\t\t\t     struct expr *expr)\n+{\n+  edge pred;\n+  rtx avail_insn = NULL_RTX;\n+  rtx avail_reg;\n+  rtx dest, pat;\n+  struct occr *a_occr;\n+  struct unoccr *occr, *avail_occrs = NULL;\n+  struct unoccr *unoccr, *unavail_occrs = NULL;\n+  int npred_ok = 0;\n+  gcov_type ok_count = 0; /* Redundant load execution count.  */\n+  gcov_type critical_count = 0; /* Execution count of critical edges.  */\n+\n+  /* The execution count of the loads to be added to make the\n+     load fully redundant.  */\n+  gcov_type not_ok_count = 0;\n+  basic_block pred_bb;\n+\n+  pat = PATTERN (insn);\n+  dest = SET_DEST (pat);\n+  /* Check if the loaded register is not used nor killed from the beginning\n+     of the block.  */\n+  if (reg_used_between_after_reload_p (dest,\n+\t\t\t\t       PREV_INSN (BB_HEAD (bb)), insn))\n+    return;\n+\n+  /* Check potential for replacing load with copy for predecessors.  */\n+  for (pred = bb->pred; pred; pred = pred->pred_next)\n+    {\n+      rtx next_pred_bb_end;\n+\n+      avail_insn = NULL_RTX;\n+      pred_bb = pred->src;\n+      next_pred_bb_end = NEXT_INSN (BB_END (pred_bb));\n+      for (a_occr = get_bb_avail_insn (pred_bb, expr->avail_occr); a_occr;\n+\t   a_occr = get_bb_avail_insn (pred_bb, a_occr->next))\n+\t{\n+\t  /* Check if the loaded register is not used.  */\n+\t  avail_insn = a_occr->insn;\n+\t  if (! (avail_reg = get_avail_load_store_reg (avail_insn)))\n+\t    abort ();\n+\t  /* Make sure we can generate a move from register avail_reg to\n+\t     dest.  */\n+\t  extract_insn (gen_move_insn (copy_rtx (dest),\n+\t\t\t\t       copy_rtx (avail_reg)));\n+\t  if (! constrain_operands (1)\n+\t      || reg_killed_on_edge (avail_reg, pred)\n+\t      || reg_used_on_edge (dest, pred))\n+\t    {\n+\t      avail_insn = NULL;\n+\t      continue;\n+\t    }\n+\t  if (! reg_set_between_after_reload_p (avail_reg, avail_insn,\n+\t\t\t\t\t\tnext_pred_bb_end))\n+\t    /* AVAIL_INSN remains non-null.  */\n+\t    break;\n+\t  else\n+\t    avail_insn = NULL;\n+\t}\n+      if (avail_insn != NULL_RTX)\n+\t{\n+\t  npred_ok++;\n+\t  ok_count += pred->count;\n+          if (EDGE_CRITICAL_P (pred))\n+            critical_count += pred->count;\n+\t  occr = (struct unoccr *) gmalloc (sizeof (struct unoccr));\n+\t  occr->insn = avail_insn;\n+\t  occr->pred = pred;\n+\t  occr->next = avail_occrs;\n+\t  avail_occrs = occr;\n+\t}\n+      else\n+\t{\n+\t  not_ok_count += pred->count;\n+          if (EDGE_CRITICAL_P (pred))\n+            critical_count += pred->count;\n+\t  unoccr = (struct unoccr *) gmalloc (sizeof (struct unoccr));\n+\t  unoccr->insn = NULL_RTX;\n+\t  unoccr->pred = pred;\n+\t  unoccr->next = unavail_occrs;\n+\t  unavail_occrs = unoccr;\n+\t}\n+    }\n+\n+  if (npred_ok == 0    /* No load can be replaced by copy.  */\n+      || (optimize_size && npred_ok > 1)) /* Prevent exploding the code.  */\n+    return;\n+\n+  /* Check if it's worth applying the partial redundancy elimination.  */\n+  if (ok_count < GCSE_AFTER_RELOAD_PARTIAL_FRACTION * not_ok_count)\n+    return;\n+\n+  if (ok_count < GCSE_AFTER_RELOAD_CRITICAL_FRACTION * critical_count)\n+    return;\n+\n+  /* Generate moves to the loaded register from where\n+     the memory is available.  */\n+  for (occr = avail_occrs; occr; occr = occr->next)\n+    {\n+      avail_insn = occr->insn;\n+      pred = occr->pred;\n+      /* Set avail_reg to be the register having the value of the\n+\t memory.  */\n+      avail_reg = get_avail_load_store_reg (avail_insn);\n+      if (! avail_reg)\n+\tabort ();\n+\n+      insert_insn_on_edge (gen_move_insn (copy_rtx (dest),\n+\t\t\t\t\t  copy_rtx (avail_reg)),\n+\t\t\t   pred);\n+\n+      if (gcse_file)\n+\tfprintf (gcse_file,\n+\t\t \"GCSE AFTER reload generating move from %d to %d on \\\n+\t\t edge from %d to %d\\n\",\n+\t\t REGNO (avail_reg),\n+\t\t REGNO (dest),\n+\t\t pred->src->index,\n+\t\t pred->dest->index);\n+    }\n+\n+  /* Regenerate loads where the memory is unavailable.  */\n+  for (unoccr = unavail_occrs; unoccr; unoccr = unoccr->next)\n+    {\n+      pred = unoccr->pred;\n+      insert_insn_on_edge (copy_insn (PATTERN (insn)), pred);\n+\n+      if (gcse_file)\n+\tfprintf (gcse_file,\n+\t\t \"GCSE AFTER reload: generating on edge from %d to %d\\\n+\t\t  a copy of load:\\n\",\n+\t\t pred->src->index,\n+\t\t pred->dest->index);\n+    }\n+\n+  /* Delete the insn if it is not available in this block and mark it\n+     for deletion if it is available. If insn is available it may help\n+     discover additional redundancies, so mark it for later deletion.*/\n+  for (a_occr = get_bb_avail_insn (bb, expr->avail_occr);\n+       a_occr && (a_occr->insn != insn);\n+       a_occr = get_bb_avail_insn (bb, a_occr->next));\n+\n+  if (!a_occr)\n+    delete_insn (insn);\n+  else\n+    a_occr->deleted_p = 1;\n+}\n+\n+/* Performing the redundancy elimination as described before.  */\n+\n+static void\n+gcse_after_reload (void)\n+{\n+  unsigned int i;\n+  rtx insn;\n+  basic_block bb;\n+  struct expr *expr;\n+  struct occr *occr;\n+\n+  /* Note we start at block 1.  */\n+\n+  if (ENTRY_BLOCK_PTR->next_bb == EXIT_BLOCK_PTR)\n+    return;\n+\n+  FOR_BB_BETWEEN (bb,\n+\t\t  ENTRY_BLOCK_PTR->next_bb->next_bb,\n+\t\t  EXIT_BLOCK_PTR,\n+\t\t  next_bb)\n+    {\n+      if (! bb_has_well_behaved_predecessors (bb))\n+\tcontinue;\n+\n+      /* Do not try this optimization on cold basic blocks.  */\n+      if (probably_cold_bb_p (bb))\n+\tcontinue;\n+\n+      reset_opr_set_tables ();\n+\n+      for (insn = BB_HEAD (bb);\n+\t   insn != NULL\n+\t   && insn != NEXT_INSN (BB_END (bb));\n+\t   insn = NEXT_INSN (insn))\n+\t{\n+\t  /* Is it a load - of the form (set (reg) (mem))?  */\n+\t  if (GET_CODE (insn) == INSN\n+              && GET_CODE (PATTERN (insn)) == SET\n+\t      && GET_CODE (SET_DEST (PATTERN (insn))) == REG\n+\t      && GET_CODE (SET_SRC (PATTERN (insn))) == MEM)\n+\t    {\n+\t      rtx pat = PATTERN (insn);\n+\t      rtx src = SET_SRC (pat);\n+\t      struct expr *expr;\n+\n+\t      if (general_operand (src, GET_MODE (src))\n+\t\t  /* Is the expression recorded?  */\n+\t\t  && (expr = lookup_expr (src, &expr_hash_table)) != NULL\n+\t\t  /* Are the operands unchanged since the start of the\n+\t\t     block?  */\n+\t\t  && oprs_not_set_p (src, insn)\n+\t\t  && ! MEM_VOLATILE_P (src)\n+\t\t  && GET_MODE (src) != BLKmode\n+\t\t  && !(flag_non_call_exceptions && may_trap_p (src))\n+\t\t  && !side_effects_p (src))\n+\t\t{\n+\t\t  /* We now have a load (insn) and an available memory at\n+\t\t     its BB start (expr). Try to remove the loads if it is\n+\t\t     redundant.  */\n+\t\t  eliminate_partially_redundant_loads (bb, insn, expr);\n+\t\t}\n+\t    }\n+\n+\t    /* Keep track of everything modified by this insn.  */\n+\t    if (INSN_P (insn))\n+\t      mark_oprs_set (insn);\n+\t}\n+    }\n+\n+  commit_edge_insertions ();\n+\n+  /* Go over the expression hash table and delete insns that were\n+     marked for later deletion.  */\n+  for (i = 0; i < expr_hash_table.size; i++)\n+    {\n+      for (expr = expr_hash_table.table[i];\n+\t   expr != NULL;\n+\t   expr = expr->next_same_hash)\n+\tfor (occr = expr->avail_occr; occr; occr = occr->next)\n+\t  if (occr->deleted_p)\n+\t    delete_insn (occr->insn);\n+    }\n+}\n+\n+/* Scan pattern PAT of INSN and add an entry to the hash TABLE.\n+   After reload we are interested in loads/stores only.  */\n+\n+static void\n+hash_scan_set_after_reload (rtx pat, rtx insn, struct hash_table *table)\n+{\n+  rtx src = SET_SRC (pat);\n+  rtx dest = SET_DEST (pat);\n+\n+  if (GET_CODE (src) != MEM && GET_CODE (dest) != MEM)\n+    return;\n+\n+  if (GET_CODE (dest) == REG)\n+    {\n+      if (/* Don't GCSE something if we can't do a reg/reg copy.  */\n+\t  can_copy_p (GET_MODE (dest))\n+\t  /* GCSE commonly inserts instruction after the insn.  We can't\n+\t     do that easily for EH_REGION notes so disable GCSE on these\n+\t     for now.  */\n+\t  && ! find_reg_note (insn, REG_EH_REGION, NULL_RTX)\n+\t  /* Is SET_SRC something we want to gcse?  */\n+\t  && general_operand (src, GET_MODE (src))\n+\t  /* Don't CSE a nop.  */\n+\t  && ! set_noop_p (pat)\n+\t  && ! JUMP_P (insn))\n+\t{\n+\t  /* An expression is not available if its operands are\n+\t     subsequently modified, including this insn.  */\n+\t  if (oprs_available_p (src, insn))\n+\t    insert_expr_in_table (src, GET_MODE (dest), insn, 0, 1, table);\n+\t}\n+    }\n+  else if ((GET_CODE (src) == REG))\n+    {\n+      /* Only record sets of pseudo-regs in the hash table.  */\n+      if (/* Don't GCSE something if we can't do a reg/reg copy.  */\n+\t  can_copy_p (GET_MODE (src))\n+\t  /* GCSE commonly inserts instruction after the insn.  We can't\n+\t     do that easily for EH_REGION notes so disable GCSE on these\n+\t     for now.  */\n+\t  && ! find_reg_note (insn, REG_EH_REGION, NULL_RTX)\n+\t  /* Is SET_DEST something we want to gcse?  */\n+\t  && general_operand (dest, GET_MODE (dest))\n+\t  /* Don't CSE a nop.  */\n+\t  && ! set_noop_p (pat)\n+\t  &&! JUMP_P (insn)\n+\t  && ! (flag_float_store && FLOAT_MODE_P (GET_MODE (dest)))\n+\t  /* Check if the memory expression is killed after insn.  */\n+\t  && ! load_killed_in_block_p (BLOCK_FOR_INSN (insn),\n+\t\t\t\t       INSN_CUID (insn) + 1,\n+\t\t\t\t       dest,\n+\t\t\t\t       1)\n+\t  && oprs_unchanged_p (XEXP (dest, 0), insn, 1))\n+\t{\n+\t  insert_expr_in_table (dest, GET_MODE (dest), insn, 0, 1, table);\n+\t}\n+    }\n+}\n+\n+\n+/* Create hash table of memory expressions available at end of basic\n+   blocks.  */\n+\n+static void\n+compute_hash_table_after_reload (struct hash_table *table)\n+{\n+  unsigned int i;\n+\n+  table->set_p = 0;\n+\n+  /* Initialize count of number of entries in hash table.  */\n+  table->n_elems = 0;\n+  memset ((char *) table->table, 0,\n+\t  table->size * sizeof (struct expr *));\n+\n+  /* While we compute the hash table we also compute a bit array of which\n+     registers are set in which blocks.  */\n+  sbitmap_vector_zero (reg_set_in_block, last_basic_block);\n+\n+  /* Re-cache any INSN_LIST nodes we have allocated.  */\n+  clear_modify_mem_tables ();\n+\n+  /* Some working arrays used to track first and last set in each block.  */\n+  reg_avail_info = (struct reg_avail_info*)\n+\t\t   gmalloc (max_gcse_regno * sizeof (struct reg_avail_info));\n+\n+  for (i = 0; i < max_gcse_regno; ++i)\n+    reg_avail_info[i].last_bb = NULL;\n+\n+  FOR_EACH_BB (current_bb)\n+    {\n+      rtx insn;\n+      unsigned int regno;\n+\n+      /* First pass over the instructions records information used to\n+\t determine when registers and memory are first and last set.  */\n+      for (insn = BB_HEAD (current_bb);\n+\t   insn && insn != NEXT_INSN (BB_END (current_bb));\n+\t   insn = NEXT_INSN (insn))\n+\t{\n+\t  if (! INSN_P (insn))\n+\t    continue;\n+\n+\t  if (GET_CODE (insn) == CALL_INSN)\n+\t    {\n+\t      bool clobbers_all = false;\n+\n+#ifdef NON_SAVING_SETJMP\n+\t      if (NON_SAVING_SETJMP\n+\t\t  && find_reg_note (insn, REG_SETJMP, NULL_RTX))\n+\t\tclobbers_all = true;\n+#endif\n+\n+\t      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n+\t\tif (clobbers_all\n+\t\t    || TEST_HARD_REG_BIT (regs_invalidated_by_call,\n+\t\t\t\t\t  regno))\n+\t\t  record_last_reg_set_info (insn, regno);\n+\n+\t      mark_call (insn);\n+\t    }\n+\n+\t    note_stores (PATTERN (insn), record_last_set_info, insn);\n+\n+\t    if (GET_CODE (PATTERN (insn)) == SET)\n+\t      {\n+\t\trtx src, dest;\n+\n+\t\tsrc = SET_SRC (PATTERN (insn));\n+\t\tdest = SET_DEST (PATTERN (insn));\n+\t\tif (GET_CODE (src) == MEM && auto_inc_p (XEXP (src, 0)))\n+\t\t  {\n+\t\t    regno = REGNO (XEXP (XEXP (src, 0), 0));\n+\t\t    record_last_reg_set_info (insn, regno);\n+\t\t  }\n+\t\tif (GET_CODE (dest) == MEM && auto_inc_p (XEXP (dest, 0)))\n+\t\t  {\n+\t\t    regno = REGNO (XEXP (XEXP (dest, 0), 0));\n+\t\t    record_last_reg_set_info (insn, regno);\n+\t\t  }\n+\t\t}\n+\t  }\n+\n+\t/* The next pass builds the hash table.  */\n+\tfor (insn = BB_HEAD (current_bb);\n+\t     insn && insn != NEXT_INSN (BB_END (current_bb));\n+\t     insn = NEXT_INSN (insn))\n+\t  if (INSN_P (insn) && GET_CODE (PATTERN (insn)) == SET)\n+\t    if (! find_reg_note (insn, REG_LIBCALL, NULL_RTX))\n+\t      hash_scan_set_after_reload (PATTERN (insn), insn, table);\n+    }\n+\n+  free (reg_avail_info);\n+  reg_avail_info = NULL;\n+}\n+\n+\n+/* Main entry point of the GCSE after reload - clean some redundant loads\n+   due to spilling.  */\n+\n+void\n+gcse_after_reload_main (rtx f, FILE* file)\n+{\n+  gcse_subst_count = 0;\n+  gcse_create_count = 0;\n+\n+  gcse_file = file;\n+\n+  gcc_obstack_init (&gcse_obstack);\n+  bytes_used = 0;\n+\n+  /* We need alias.  */\n+  init_alias_analysis ();\n+\n+  max_gcse_regno = max_reg_num ();\n+\n+  alloc_reg_set_mem (max_gcse_regno);\n+  alloc_gcse_mem (f);\n+  alloc_hash_table (max_cuid, &expr_hash_table, 0);\n+  compute_hash_table_after_reload (&expr_hash_table);\n+\n+  if (gcse_file)\n+    dump_hash_table (gcse_file, \"Expression\", &expr_hash_table);\n+\n+  if (expr_hash_table.n_elems > 0)\n+    gcse_after_reload ();\n+\n+  free_hash_table (&expr_hash_table);\n+\n+  free_gcse_mem ();\n+  free_reg_set_mem ();\n+\n+  /* We are finished with alias.  */\n+  end_alias_analysis ();\n+\n+  obstack_free (&gcse_obstack, NULL);\n+}\n+\n #include \"gt-gcse.h\""}, {"sha": "fa1971cd651c9faa3c2c48d22eb095c0c8ef4526", "filename": "gcc/opts.c", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fopts.c?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -574,6 +574,7 @@ decode_options (unsigned int argc, const char **argv)\n       flag_rename_registers = 1;\n       flag_unswitch_loops = 1;\n       flag_web = 1;\n+      flag_gcse_after_reload = 1;\n     }\n \n   if (optimize < 2 || optimize_size)\n@@ -1035,6 +1036,10 @@ common_handle_option (size_t scode, const char *arg,\n       flag_gcse_sm = value;\n       break;\n \n+    case OPT_fgcse_after_reload:\n+      flag_gcse_after_reload = value;\n+      break;\n+\n     case OPT_fgcse_las:\n       flag_gcse_las = value;\n       break;"}, {"sha": "7be8ddc132295078ff41c5a932e87d9aa8e3b4f0", "filename": "gcc/params.def", "status": "modified", "additions": 19, "deletions": 1, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fparams.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fparams.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.def?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -131,7 +131,25 @@ DEFPARAM(PARAM_MAX_GCSE_PASSES,\n \t\"max-gcse-passes\",\n \t\"The maximum number of passes to make when doing GCSE\",\n \t1)\n-\n+/* This is the threshold ratio when to perform partial redundancy\n+   elimination after reload. We perform partial redundancy elimination\n+   when the following holds:\n+   (Redundant load execution count)\n+   ------------------------------- >= GCSE_AFTER_RELOAD_PARTIAL_FRACTION\n+   (Added loads execution count)\t\t\t\t\t  */\n+DEFPARAM(PARAM_GCSE_AFTER_RELOAD_PARTIAL_FRACTION,\n+\t\"gcse-after-reload-partial-fraction\",\n+\t\"The threshold ratio for performing partial redundancy elimination \\\n+         after reload.\",\n+        3)\n+/* This is the threshold ratio of the critical edges execution count compared to\n+   the redundant loads execution count that permits performing the load\n+   redundancy elimination in gcse after reload.  */\n+DEFPARAM(PARAM_GCSE_AFTER_RELOAD_CRITICAL_FRACTION,\n+\t\"gcse-after-reload-critical-fraction\",\n+\t\"The threshold ratio of critical edges execution count that permit \\\n+         performing redundancy elimination after reload.\",\n+        10)\n /* This parameter limits the number of insns in a loop that will be unrolled,\n    and by how much the loop is unrolled.\n    "}, {"sha": "d030dbe645af3ffac8ae43321462fae0e0847c13", "filename": "gcc/params.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fparams.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fparams.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.h?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -104,6 +104,10 @@ typedef enum compiler_param\n   ((size_t) PARAM_VALUE (PARAM_MAX_GCSE_MEMORY))\n #define MAX_GCSE_PASSES \\\n   PARAM_VALUE (PARAM_MAX_GCSE_PASSES)\n+#define GCSE_AFTER_RELOAD_PARTIAL_FRACTION \\\n+  PARAM_VALUE (PARAM_GCSE_AFTER_RELOAD_PARTIAL_FRACTION)\n+#define GCSE_AFTER_RELOAD_CRITICAL_FRACTION \\\n+  PARAM_VALUE (PARAM_GCSE_AFTER_RELOAD_CRITICAL_FRACTION)\n #define MAX_UNROLLED_INSNS \\\n   PARAM_VALUE (PARAM_MAX_UNROLLED_INSNS)\n #endif /* ! GCC_PARAMS_H */"}, {"sha": "1bd554c61e1fd2b428e9dbdf3b5fdc41e286aefb", "filename": "gcc/passes.c", "status": "modified", "additions": 23, "deletions": 1, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fpasses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Fpasses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.c?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -158,6 +158,7 @@ enum dump_file_index\n   DFI_lreg,\n   DFI_greg,\n   DFI_postreload,\n+  DFI_gcse2,\n   DFI_flow2,\n   DFI_peephole2,\n   DFI_ce3,\n@@ -178,7 +179,7 @@ enum dump_file_index\n    Remaining -d letters:\n \n \t\"   e        m   q         \"\n-\t\"         JK   O Q     WXY \"\n+\t\"          K   O Q     WXY \"\n */\n \n static struct dump_file_info dump_file_tbl[DFI_MAX] =\n@@ -210,6 +211,7 @@ static struct dump_file_info dump_file_tbl[DFI_MAX] =\n   { \"lreg\",\t'l', 1, 0, 0 },\n   { \"greg\",\t'g', 1, 0, 0 },\n   { \"postreload\", 'o', 1, 0, 0 },\n+  { \"gcse2\",    'J', 0, 0, 0 },\n   { \"flow2\",\t'w', 1, 0, 0 },\n   { \"peephole2\", 'z', 1, 0, 0 },\n   { \"ce3\",\t'E', 1, 0, 0 },\n@@ -788,6 +790,23 @@ rest_of_handle_sched2 (tree decl, rtx insns)\n }\n #endif\n \n+static void\n+rest_of_handle_gcse2 (tree decl, rtx insns)\n+{\n+  open_dump_file (DFI_gcse2, decl);\n+\n+  gcse_after_reload_main (insns, dump_file);\n+  rebuild_jump_labels (insns);\n+  delete_trivially_dead_insns (insns, max_reg_num ());\n+  close_dump_file (DFI_gcse2, print_rtl_with_bb, insns);\n+\n+  ggc_collect ();\n+\n+#ifdef ENABLE_CHECKING\n+  verify_flow_info ();\n+#endif\n+}\n+\n /* Register allocation pre-pass, to reduce number of moves necessary\n    for two-address machines.  */\n static void\n@@ -1842,6 +1861,9 @@ rest_of_compilation (tree decl)\n \n   close_dump_file (DFI_postreload, print_rtl_with_bb, insns);\n \n+  if (optimize > 0 && flag_gcse_after_reload)\n+    rest_of_handle_gcse2 (decl, insns);\n+\n   /* Re-create the death notes which were deleted during reload.  */\n   timevar_push (TV_FLOW2);\n   open_dump_file (DFI_flow2, decl);"}, {"sha": "2e91136257826ac53a3629270b8e0c3b1e437bfe", "filename": "gcc/rtl.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -2289,6 +2289,7 @@ extern rtx fis_get_condition (rtx);\n #ifdef BUFSIZ\n extern int gcse_main (rtx, FILE *);\n extern int bypass_jumps (FILE *);\n+extern void gcse_after_reload_main (rtx, FILE *);\n #endif\n \n /* In global.c */"}, {"sha": "8192a1a8ea843cc9921273def070861012546826", "filename": "gcc/toplev.c", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Ftoplev.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f9957958fe143fd987e0c3e339d2586dc7cc06cd/gcc%2Ftoplev.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftoplev.c?ref=f9957958fe143fd987e0c3e339d2586dc7cc06cd", "patch": "@@ -526,6 +526,9 @@ int flag_gcse_sm = 1;\n \n int flag_gcse_las = 1;\n \n+/* Nonzero means perform global cse after register allocation.  */\n+int flag_gcse_after_reload = 0;\n+\n /* Perform target register optimization before prologue / epilogue\n    threading.  */\n \n@@ -915,6 +918,7 @@ static const lang_independent_options f_options[] =\n   {\"gcse-lm\", &flag_gcse_lm, 1 },\n   {\"gcse-sm\", &flag_gcse_sm, 1 },\n   {\"gcse-las\", &flag_gcse_las, 1 },\n+  {\"gcse-after-reload\", &flag_gcse_after_reload, 1},\n   {\"branch-target-load-optimize\", &flag_branch_target_load_optimize, 1 },\n   {\"branch-target-load-optimize2\", &flag_branch_target_load_optimize2, 1 },\n   {\"btr-bb-exclusive\", &flag_btr_bb_exclusive, 1 },"}]}