{"sha": "38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Mzg5ODhjYmY5ZWJhYTk2ZmIxZTg5MWE0NmFhMDYzZjBjMjk4YTJlMg==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2019-07-08T07:09:24Z"}, "committer": {"name": "Richard Biener", "email": "rguenth@gcc.gnu.org", "date": "2019-07-08T07:09:24Z"}, "message": "re PR tree-optimization/83518 (Missing optimization: useless instructions should be dropped)\n\n2019-07-08  Richard Biener  <rguenther@suse.de>\n\n\tPR tree-optimization/83518\n\t* tree-ssa-sccvn.c: Include splay-tree.h.\n\t(struct pd_range, struct pd_data): New.\n\t(struct vn_walk_cb_data): Add data to track partial definitions.\n\t(vn_walk_cb_data::~vn_walk_cb_data): New.\n\t(vn_walk_cb_data::push_partial_def): New.\n\t(pd_tree_alloc, pd_tree_dealloc, pd_range_compare): New.\n\t(vn_reference_lookup_2): When partial defs are registered give up.\n\t(vn_reference_lookup_3): Track partial defs for memset and\n\tconstructor zeroing and for defs from constants.\n\n\t* gcc.dg/tree-ssa/ssa-fre-73.c: New testcase.\n\t* gcc.dg/tree-ssa/ssa-fre-74.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-fre-75.c: Likewise.\n\t* gcc.dg/tree-ssa/ssa-fre-76.c: Likewise.\n\t* g++.dg/tree-ssa/pr83518.C: Likewise.\n\nFrom-SVN: r273194", "tree": {"sha": "0f54d5e9ceddc39613106ca89f748a865a10a7f9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0f54d5e9ceddc39613106ca89f748a865a10a7f9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "8849d5034c5ab5c2e6f3fc17209504576e7c6dd4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8849d5034c5ab5c2e6f3fc17209504576e7c6dd4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8849d5034c5ab5c2e6f3fc17209504576e7c6dd4"}], "stats": {"total": 518, "additions": 469, "deletions": 49}, "files": [{"sha": "74a98908b9052156471ea59ac797da784d49698e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -1,3 +1,16 @@\n+2019-07-08  Richard Biener  <rguenther@suse.de>\n+\n+\tPR tree-optimization/83518\n+\t* tree-ssa-sccvn.c: Include splay-tree.h.\n+\t(struct pd_range, struct pd_data): New.\n+\t(struct vn_walk_cb_data): Add data to track partial definitions.\n+\t(vn_walk_cb_data::~vn_walk_cb_data): New.\n+\t(vn_walk_cb_data::push_partial_def): New.\n+\t(pd_tree_alloc, pd_tree_dealloc, pd_range_compare): New.\n+\t(vn_reference_lookup_2): When partial defs are registered give up.\n+\t(vn_reference_lookup_3): Track partial defs for memset and\n+\tconstructor zeroing and for defs from constants.\n+\n 2019-07-08  Richard Sandiford  <richard.sandiford@arm.com>\n \n \t* doc/install.texi (bootstrap-Og): Document."}, {"sha": "db493b33cf54124fed3f14893b53ff9398f26819", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -1,3 +1,12 @@\n+2019-07-08  Richard Biener  <rguenther@suse.de>\n+\n+\tPR tree-optimization/83518\n+\t* gcc.dg/tree-ssa/ssa-fre-73.c: New testcase.\n+\t* gcc.dg/tree-ssa/ssa-fre-74.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-fre-75.c: Likewise.\n+\t* gcc.dg/tree-ssa/ssa-fre-76.c: Likewise.\n+\t* g++.dg/tree-ssa/pr83518.C: Likewise.\n+\n 2019-07-08  Richard Sandiford  <richard.sandiford@arm.com>\n \n \t* gcc.dg/guality/guality.h: Include <sys/prctl.h> on Linux targets."}, {"sha": "3e153c51369f304bd08e47e176107464f9afceca", "filename": "gcc/testsuite/g++.dg/tree-ssa/pr83518.C", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftree-ssa%2Fpr83518.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftree-ssa%2Fpr83518.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Ftree-ssa%2Fpr83518.C?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -0,0 +1,27 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O3 -fdump-tree-optimized\" } */\n+\n+unsigned test()\n+{\n+  int arr[] = {5,4,3,2,1};\n+  int sum = 0;\n+\n+  for(int i = 0;i < 5;++i)\n+    {\n+      for(int j = 0; j < 5; ++j)\n+\t{\n+\t  int t = arr[i];\n+\t  arr[i] = arr[j];\n+\t  arr[j] = t;\n+\t}\n+    }\n+\n+  for(int i = 0; i < 5; ++i)\n+    {\n+      sum += arr[i];\n+    }\n+\n+  return sum;\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 15;\" \"optimized\" } } */"}, {"sha": "f138203648754bb0b6624ac4ec9f37d8be276870", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-73.c", "status": "added", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-73.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-73.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-73.c?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -0,0 +1,14 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-fre1\" } */\n+\n+typedef int v2si __attribute__((vector_size(__SIZEOF_INT__ * 2)));\n+int foo (int *a)\n+{\n+  a[0] = 1;\n+  a[1] = 2;\n+  v2si x = *(v2si *)a;\n+  *(v2si *)&a[2] = x;\n+  return a[3];\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 2;\" \"fre1\" } } */"}, {"sha": "4439d838e8461fbcc09aa62316fa1492c69d7510", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-74.c", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-74.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-74.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-74.c?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -0,0 +1,16 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-fre1\" } */\n+\n+typedef int v4si __attribute__((vector_size(__SIZEOF_INT__ * 4)));\n+int foo (int *a)\n+{\n+  a[2] = 2;\n+  a[0] = 0;\n+  a[1] = 1;\n+  a[3] = 4;\n+  v4si x = *(v4si *)a;\n+  *(v4si *)&a[4] = x;\n+  return a[4] + a[7];\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 4;\" \"fre1\" } } */"}, {"sha": "54bfe731bdd230e3440736833ae09a83dea2f43f", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-75.c", "status": "added", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-75.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-75.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-75.c?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -0,0 +1,34 @@\n+/* { dg-do compile } */\n+/* { dg-require-effective-target int32plus } */\n+/* { dg-options \"-O -fgimple -fdump-tree-fre1\" } */\n+\n+typedef int v4si __attribute__((vector_size(__SIZEOF_INT__ * 4)));\n+#if __SIZEOF_INT__ == 4\n+__GIMPLE (ssa) int foo (int *a)\n+{\n+  v4si _2;\n+  int _3;\n+  int _4;\n+  int _5;\n+  int _6;\n+  int _7;\n+  int _8;\n+  int _9;\n+\n+__BB(2):\n+  __MEM <unsigned char[3 * __SIZEOF_INT__]> ((char *)a_1(D) + 4) = _Literal (unsigned char[3 * __SIZEOF_INT__]) {};\n+  __MEM <int> (a_1(D) + 8) = 2;\n+  __MEM <int> (a_1(D)) = 1;\n+  _2 = __MEM <v4si> (a_1(D));\n+  _3 = __BIT_FIELD_REF <int> (_2, 32, 0);\n+  _4 = __BIT_FIELD_REF <int> (_2, 32, 32);\n+  _5 = __BIT_FIELD_REF <int> (_2, 32, 64);\n+  _6 = __BIT_FIELD_REF <int> (_2, 32, 96);\n+  _7 = _3 + _4;\n+  _8 = _7 + _5;\n+  _9 = _8 + _6;\n+  return _9;\n+}\n+#endif\n+\n+/* { dg-final { scan-tree-dump \"return 3;\" \"fre1\" } } */"}, {"sha": "7a1eede8c0d61162b1489e916985034b7d89fa1d", "filename": "gcc/testsuite/gcc.dg/tree-ssa/ssa-fre-76.c", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-76.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-76.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fssa-fre-76.c?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -0,0 +1,16 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-fre1\" } */\n+\n+typedef int v4si __attribute__((vector_size(__SIZEOF_INT__ * 4)));\n+int foo (int *a)\n+{\n+  __builtin_memset (a, 0, 2 * __SIZEOF_INT__);\n+  a[2] = 2;\n+  a[0] = 1;\n+  a[3] = 3;\n+  v4si x = *(v4si *)a;\n+  *(v4si *)&a[4] = x;\n+  return a[4] + a[5] + a[7];\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 4;\" \"fre1\" } } */"}, {"sha": "3c45adcf3266a6f353f2cf42963a16f976491427", "filename": "gcc/tree-ssa-sccvn.c", "status": "modified", "additions": 340, "deletions": 49, "changes": 389, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftree-ssa-sccvn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/38988cbf9ebaa96fb1e891a46aa063f0c298a2e2/gcc%2Ftree-ssa-sccvn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sccvn.c?ref=38988cbf9ebaa96fb1e891a46aa063f0c298a2e2", "patch": "@@ -21,6 +21,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"config.h\"\n #include \"system.h\"\n #include \"coretypes.h\"\n+#include \"splay-tree.h\"\n #include \"backend.h\"\n #include \"rtl.h\"\n #include \"tree.h\"\n@@ -360,6 +361,8 @@ static void init_vn_nary_op_from_stmt (vn_nary_op_t, gimple *);\n static void init_vn_nary_op_from_pieces (vn_nary_op_t, unsigned int,\n \t\t\t\t\t enum tree_code, tree, tree *);\n static tree vn_lookup_simplify_result (gimple_match_op *);\n+static vn_reference_t vn_reference_lookup_or_insert_for_pieces\n+\t  (tree, alias_set_type, tree, vec<vn_reference_op_s, va_heap>, tree);\n \n /* Return whether there is value numbering information for a given SSA name.  */\n \n@@ -1646,20 +1649,245 @@ vn_reference_lookup_1 (vn_reference_t vr, vn_reference_t *vnresult)\n   return NULL_TREE;\n }\n \n+\n+/* Partial definition tracking support.  */\n+\n+struct pd_range\n+{\n+  HOST_WIDE_INT offset;\n+  HOST_WIDE_INT size;\n+};\n+\n+struct pd_data\n+{\n+  tree rhs;\n+  HOST_WIDE_INT offset;\n+  HOST_WIDE_INT size;\n+};\n+\n+/* Context for alias walking.  */\n+\n struct vn_walk_cb_data\n {\n   vn_walk_cb_data (vn_reference_t vr_, tree *last_vuse_ptr_,\n-                   vn_lookup_kind vn_walk_kind_, bool tbaa_p_)\n+\t\t   vn_lookup_kind vn_walk_kind_, bool tbaa_p_)\n     : vr (vr_), last_vuse_ptr (last_vuse_ptr_), vn_walk_kind (vn_walk_kind_),\n-      tbaa_p (tbaa_p_)\n-    {}\n+      tbaa_p (tbaa_p_), known_ranges (NULL)\n+   {}\n+  ~vn_walk_cb_data ();\n+  void *push_partial_def (const pd_data& pd, tree, HOST_WIDE_INT);\n \n   vn_reference_t vr;\n   tree *last_vuse_ptr;\n   vn_lookup_kind vn_walk_kind;\n   bool tbaa_p;\n+\n+  /* The VDEFs of partial defs we come along.  */\n+  auto_vec<pd_data, 2> partial_defs;\n+  /* The first defs range to avoid splay tree setup in most cases.  */\n+  pd_range first_range;\n+  tree first_vuse;\n+  splay_tree known_ranges;\n+  obstack ranges_obstack;\n };\n \n+vn_walk_cb_data::~vn_walk_cb_data ()\n+{\n+  if (known_ranges)\n+    {\n+      splay_tree_delete (known_ranges);\n+      obstack_free (&ranges_obstack, NULL);\n+    }\n+}\n+\n+/* pd_range splay-tree helpers.  */\n+\n+static int\n+pd_range_compare (splay_tree_key offset1p, splay_tree_key offset2p)\n+{\n+  HOST_WIDE_INT offset1 = *(HOST_WIDE_INT *)offset1p;\n+  HOST_WIDE_INT offset2 = *(HOST_WIDE_INT *)offset2p;\n+  if (offset1 < offset2)\n+    return -1;\n+  else if (offset1 > offset2)\n+    return 1;\n+  return 0;\n+}\n+\n+static void *\n+pd_tree_alloc (int size, void *data_)\n+{\n+  vn_walk_cb_data *data = (vn_walk_cb_data *)data_;\n+  return obstack_alloc (&data->ranges_obstack, size);\n+}\n+\n+static void\n+pd_tree_dealloc (void *, void *)\n+{\n+}\n+\n+/* Push PD to the vector of partial definitions returning a\n+   value when we are ready to combine things with VUSE and MAXSIZEI,\n+   NULL when we want to continue looking for partial defs or -1\n+   on failure.  */\n+\n+void *\n+vn_walk_cb_data::push_partial_def (const pd_data &pd, tree vuse,\n+\t\t\t\t   HOST_WIDE_INT maxsizei)\n+{\n+  if (partial_defs.is_empty ())\n+    {\n+      partial_defs.safe_push (pd);\n+      first_range.offset = pd.offset;\n+      first_range.size = pd.size;\n+      first_vuse = vuse;\n+      last_vuse_ptr = NULL;\n+    }\n+  else\n+    {\n+      if (!known_ranges)\n+\t{\n+\t  /* ???  Optimize the case where the second partial def\n+\t     completes things.  */\n+\t  gcc_obstack_init (&ranges_obstack);\n+\t  known_ranges\n+\t      = splay_tree_new_with_allocator (pd_range_compare, 0, 0,\n+\t\t\t\t\t       pd_tree_alloc,\n+\t\t\t\t\t       pd_tree_dealloc, this);\n+\t  splay_tree_insert (known_ranges,\n+\t\t\t     (splay_tree_key)&first_range.offset,\n+\t\t\t     (splay_tree_value)&first_range);\n+\t}\n+      if (known_ranges)\n+\t{\n+\t  pd_range newr = { pd.offset, pd.size };\n+\t  splay_tree_node n;\n+\t  pd_range *r;\n+\t  /* Lookup the predecessor of offset + 1 and see if\n+\t     we need to merge with it.  */\n+\t  HOST_WIDE_INT loffset = newr.offset + 1;\n+\t  if ((n = splay_tree_predecessor (known_ranges,\n+\t\t\t\t\t   (splay_tree_key)&loffset))\n+\t      && ((r = (pd_range *)n->value), true)\n+\t      && ranges_known_overlap_p (r->offset, r->size + 1,\n+\t\t\t\t\t newr.offset, newr.size))\n+\t    {\n+\t      /* Ignore partial defs already covered.  */\n+\t      if (known_subrange_p (newr.offset, newr.size,\n+\t\t\t\t    r->offset, r->size))\n+\t\treturn NULL;\n+\t      r->size = MAX (r->offset + r->size,\n+\t\t\t     newr.offset + newr.size) - r->offset;\n+\t    }\n+\t  else\n+\t    {\n+\t      /* newr.offset wasn't covered yet, insert the\n+\t\t range.  */\n+\t      r = XOBNEW (&ranges_obstack, pd_range);\n+\t      *r = newr;\n+\t      splay_tree_insert (known_ranges,\n+\t\t\t\t (splay_tree_key)&r->offset,\n+\t\t\t\t (splay_tree_value)r);\n+\t    }\n+\t  /* Merge r which now contains newr and is a member\n+\t     of the splay tree with adjacent overlapping ranges.  */\n+\t  pd_range *rafter;\n+\t  while ((n = splay_tree_successor (known_ranges,\n+\t\t\t\t\t    (splay_tree_key)&r->offset))\n+\t\t && ((rafter = (pd_range *)n->value), true)\n+\t\t && ranges_known_overlap_p (r->offset, r->size + 1,\n+\t\t\t\t\t    rafter->offset, rafter->size))\n+\t    {\n+\t      r->size = MAX (r->offset + r->size,\n+\t\t\t     rafter->offset + rafter->size) - r->offset;\n+\t      splay_tree_remove (known_ranges,\n+\t\t\t\t (splay_tree_key)&rafter->offset);\n+\t    }\n+\t  partial_defs.safe_push (pd);\n+\n+\t  /* Now we have merged newr into the range tree.\n+\t     When we have covered [offseti, sizei] then the\n+\t     tree will contain exactly one node which has\n+\t     the desired properties and it will be 'r'.  */\n+\t  if (known_subrange_p (0, maxsizei / BITS_PER_UNIT,\n+\t\t\t\tr->offset, r->size))\n+\t    {\n+\t      /* Now simply native encode all partial defs\n+\t\t in reverse order.  */\n+\t      unsigned ndefs = partial_defs.length ();\n+\t      /* We support up to 512-bit values (for V8DFmode).  */\n+\t      unsigned char buffer[64];\n+\t      int len;\n+\n+\t      while (!partial_defs.is_empty ())\n+\t\t{\n+\t\t  pd_data pd = partial_defs.pop ();\n+\t\t  if (TREE_CODE (pd.rhs) == CONSTRUCTOR)\n+\t\t    /* Empty CONSTRUCTOR.  */\n+\t\t    memset (buffer + MAX (0, pd.offset),\n+\t\t\t    0, MIN ((HOST_WIDE_INT)sizeof (buffer), pd.size));\n+\t\t  else\n+\t\t    {\n+\t\t      len = native_encode_expr (pd.rhs,\n+\t\t\t\t\t\tbuffer + MAX (0, pd.offset),\n+\t\t\t\t\t\tsizeof (buffer - MAX (0, pd.offset)),\n+\t\t\t\t\t\tMAX (0, -pd.offset));\n+\t\t      if (len <= 0\n+\t\t\t  || len < (pd.size - MAX (0, -pd.offset)))\n+\t\t\t{\n+\t\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t\t\t    fprintf (dump_file, \"Failed to encode %u \"\n+\t\t\t\t     \"partial definitions\\n\", ndefs);\n+\t\t\t  return (void *)-1;\n+\t\t\t}\n+\t\t    }\n+\t\t}\n+\n+\t      tree type = vr->type;\n+\t      /* Make sure to interpret in a type that has a range\n+\t\t covering the whole access size.  */\n+\t      if (INTEGRAL_TYPE_P (vr->type)\n+\t\t  && maxsizei != TYPE_PRECISION (vr->type))\n+\t\ttype = build_nonstandard_integer_type (maxsizei,\n+\t\t\t\t\t\t       TYPE_UNSIGNED (type));\n+\t      tree val = native_interpret_expr (type, buffer,\n+\t\t\t\t\t\tmaxsizei / BITS_PER_UNIT);\n+\t      /* If we chop off bits because the types precision doesn't\n+\t\t match the memory access size this is ok when optimizing\n+\t\t reads but not when called from the DSE code during\n+\t\t elimination.  */\n+\t      if (val\n+\t\t  && type != vr->type)\n+\t\t{\n+\t\t  if (! int_fits_type_p (val, vr->type))\n+\t\t    val = NULL_TREE;\n+\t\t  else\n+\t\t    val = fold_convert (vr->type, val);\n+\t\t}\n+\n+\t      if (val)\n+\t\t{\n+\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t\t    fprintf (dump_file, \"Successfully combined %u \"\n+\t\t\t     \"partial definitions\\n\", ndefs);\n+\t\t  return vn_reference_lookup_or_insert_for_pieces\n+\t\t      (first_vuse,\n+\t\t       vr->set, vr->type, vr->operands, val);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t\t    fprintf (dump_file, \"Failed to interpret %u \"\n+\t\t\t     \"encoded partial definitions\\n\", ndefs);\n+\t\t  return (void *)-1;\n+\t\t}\n+\t    }\n+\t}\n+    }\n+  /* Continue looking for partial defs.  */\n+  return NULL;\n+}\n+\n /* Callback for walk_non_aliased_vuses.  Adjusts the vn_reference_t VR_\n    with the current VUSE and performs the expression lookup.  */\n \n@@ -1671,6 +1899,11 @@ vn_reference_lookup_2 (ao_ref *op ATTRIBUTE_UNUSED, tree vuse, void *data_)\n   vn_reference_s **slot;\n   hashval_t hash;\n \n+  /* If we have partial definitions recorded we have to go through\n+     vn_reference_lookup_3.  */\n+  if (!data->partial_defs.is_empty ())\n+    return NULL;\n+\n   if (data->last_vuse_ptr)\n     *data->last_vuse_ptr = vuse;\n \n@@ -2179,8 +2412,10 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n       else\n \treturn (void *)-1;\n       tree len = gimple_call_arg (def_stmt, 2);\n-      if (known_subrange_p (offset, maxsize, offset2,\n-\t\t\t    wi::to_poly_offset (len) << LOG2_BITS_PER_UNIT))\n+      HOST_WIDE_INT leni, offset2i, offseti;\n+      if (data->partial_defs.is_empty ()\n+\t  && known_subrange_p (offset, maxsize, offset2,\n+\t\t\t       wi::to_poly_offset (len) << LOG2_BITS_PER_UNIT))\n \t{\n \t  tree val;\n \t  if (integer_zerop (gimple_call_arg (def_stmt, 1)))\n@@ -2209,6 +2444,19 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n \t  return vn_reference_lookup_or_insert_for_pieces\n \t           (vuse, vr->set, vr->type, vr->operands, val);\n \t}\n+      /* For now handle clearing memory with partial defs.  */\n+      else if (integer_zerop (gimple_call_arg (def_stmt, 1))\n+\t       && tree_to_poly_int64 (len).is_constant (&leni)\n+\t       && offset.is_constant (&offseti)\n+\t       && offset2.is_constant (&offset2i)\n+\t       && maxsize.is_constant (&maxsizei))\n+\t{\n+\t  pd_data pd;\n+\t  pd.rhs = build_constructor (NULL_TREE, NULL);\n+\t  pd.offset = offset2i - offseti;\n+\t  pd.size = leni;\n+\t  return data->push_partial_def (pd, vuse, maxsizei);\n+\t}\n     }\n \n   /* 2) Assignment from an empty CONSTRUCTOR.  */\n@@ -2219,18 +2467,37 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n     {\n       tree base2;\n       poly_int64 offset2, size2, maxsize2;\n+      HOST_WIDE_INT offset2i, size2i;\n       bool reverse;\n       base2 = get_ref_base_and_extent (gimple_assign_lhs (def_stmt),\n \t\t\t\t       &offset2, &size2, &maxsize2, &reverse);\n       if (known_size_p (maxsize2)\n \t  && known_eq (maxsize2, size2)\n \t  && adjust_offsets_for_equal_base_address (base, &offset,\n-\t\t\t\t\t\t    base2, &offset2)\n-\t  && known_subrange_p (offset, maxsize, offset2, size2))\n+\t\t\t\t\t\t    base2, &offset2))\n \t{\n-\t  tree val = build_zero_cst (vr->type);\n-\t  return vn_reference_lookup_or_insert_for_pieces\n-\t           (vuse, vr->set, vr->type, vr->operands, val);\n+\t  if (data->partial_defs.is_empty ()\n+\t      && known_subrange_p (offset, maxsize, offset2, size2))\n+\t    {\n+\t      tree val = build_zero_cst (vr->type);\n+\t      return vn_reference_lookup_or_insert_for_pieces\n+\t\t  (vuse, vr->set, vr->type, vr->operands, val);\n+\t    }\n+\t  else if (maxsize.is_constant (&maxsizei)\n+\t\t   && maxsizei % BITS_PER_UNIT == 0\n+\t\t   && offset.is_constant (&offseti)\n+\t\t   && offseti % BITS_PER_UNIT == 0\n+\t\t   && offset2.is_constant (&offset2i)\n+\t\t   && offset2i % BITS_PER_UNIT == 0\n+\t\t   && size2.is_constant (&size2i)\n+\t\t   && size2i % BITS_PER_UNIT == 0)\n+\t    {\n+\t      pd_data pd;\n+\t      pd.rhs = gimple_assign_rhs1 (def_stmt);\n+\t      pd.offset = (offset2i - offseti) / BITS_PER_UNIT;\n+\t      pd.size = size2i / BITS_PER_UNIT;\n+\t      return data->push_partial_def (pd, vuse, maxsizei);\n+\t    }\n \t}\n     }\n \n@@ -2253,7 +2520,7 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n     {\n       tree base2;\n       poly_int64 offset2, size2, maxsize2;\n-      HOST_WIDE_INT offset2i;\n+      HOST_WIDE_INT offset2i, size2i;\n       bool reverse;\n       base2 = get_ref_base_and_extent (gimple_assign_lhs (def_stmt),\n \t\t\t\t       &offset2, &size2, &maxsize2, &reverse);\n@@ -2266,45 +2533,60 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n \t\t\t\t\t\t    base2, &offset2)\n \t  && offset.is_constant (&offseti)\n \t  && offset2.is_constant (&offset2i)\n-\t  && known_subrange_p (offseti, maxsizei, offset2, size2))\n+\t  && size2.is_constant (&size2i))\n \t{\n-\t  /* We support up to 512-bit values (for V8DFmode).  */\n-\t  unsigned char buffer[64];\n-\t  int len;\n-\n-\t  tree rhs = gimple_assign_rhs1 (def_stmt);\n-\t  if (TREE_CODE (rhs) == SSA_NAME)\n-\t    rhs = SSA_VAL (rhs);\n-\t  len = native_encode_expr (rhs,\n-\t\t\t\t    buffer, sizeof (buffer),\n-\t\t\t\t    (offseti - offset2i) / BITS_PER_UNIT);\n-\t  if (len > 0 && len * BITS_PER_UNIT >= maxsizei)\n+\t  if (data->partial_defs.is_empty ()\n+\t      && known_subrange_p (offseti, maxsizei, offset2, size2))\n \t    {\n-\t      tree type = vr->type;\n-\t      /* Make sure to interpret in a type that has a range\n-\t\t covering the whole access size.  */\n-\t      if (INTEGRAL_TYPE_P (vr->type)\n-\t\t  && maxsizei != TYPE_PRECISION (vr->type))\n-\t\ttype = build_nonstandard_integer_type (maxsizei,\n-\t\t\t\t\t\t       TYPE_UNSIGNED (type));\n-\t      tree val = native_interpret_expr (type, buffer,\n-\t\t\t\t\t\tmaxsizei / BITS_PER_UNIT);\n-\t      /* If we chop off bits because the types precision doesn't\n-\t\t match the memory access size this is ok when optimizing\n-\t\t reads but not when called from the DSE code during\n-\t\t elimination.  */\n-\t      if (val\n-\t\t  && type != vr->type)\n+\t      /* We support up to 512-bit values (for V8DFmode).  */\n+\t      unsigned char buffer[64];\n+\t      int len;\n+\n+\t      tree rhs = gimple_assign_rhs1 (def_stmt);\n+\t      if (TREE_CODE (rhs) == SSA_NAME)\n+\t\trhs = SSA_VAL (rhs);\n+\t      len = native_encode_expr (rhs,\n+\t\t\t\t\tbuffer, sizeof (buffer),\n+\t\t\t\t\t(offseti - offset2i) / BITS_PER_UNIT);\n+\t      if (len > 0 && len * BITS_PER_UNIT >= maxsizei)\n \t\t{\n-\t\t  if (! int_fits_type_p (val, vr->type))\n-\t\t    val = NULL_TREE;\n-\t\t  else\n-\t\t    val = fold_convert (vr->type, val);\n-\t\t}\n+\t\t  tree type = vr->type;\n+\t\t  /* Make sure to interpret in a type that has a range\n+\t\t     covering the whole access size.  */\n+\t\t  if (INTEGRAL_TYPE_P (vr->type)\n+\t\t      && maxsizei != TYPE_PRECISION (vr->type))\n+\t\t    type = build_nonstandard_integer_type (maxsizei,\n+\t\t\t\t\t\t\t   TYPE_UNSIGNED (type));\n+\t\t  tree val = native_interpret_expr (type, buffer,\n+\t\t\t\t\t\t    maxsizei / BITS_PER_UNIT);\n+\t\t  /* If we chop off bits because the types precision doesn't\n+\t\t     match the memory access size this is ok when optimizing\n+\t\t     reads but not when called from the DSE code during\n+\t\t     elimination.  */\n+\t\t  if (val\n+\t\t      && type != vr->type)\n+\t\t    {\n+\t\t      if (! int_fits_type_p (val, vr->type))\n+\t\t\tval = NULL_TREE;\n+\t\t      else\n+\t\t\tval = fold_convert (vr->type, val);\n+\t\t    }\n \n-\t      if (val)\n-\t\treturn vn_reference_lookup_or_insert_for_pieces\n-\t\t\t (vuse, vr->set, vr->type, vr->operands, val);\n+\t\t  if (val)\n+\t\t    return vn_reference_lookup_or_insert_for_pieces\n+\t\t\t(vuse, vr->set, vr->type, vr->operands, val);\n+\t\t}\n+\t    }\n+\t  else if (ranges_known_overlap_p (offseti, maxsizei, offset2i, size2i))\n+\t    {\n+\t      pd_data pd;\n+\t      tree rhs = gimple_assign_rhs1 (def_stmt);\n+\t      if (TREE_CODE (rhs) == SSA_NAME)\n+\t\trhs = SSA_VAL (rhs);\n+\t      pd.rhs = rhs;\n+\t      pd.offset = (offset2i - offseti) / BITS_PER_UNIT;\n+\t      pd.size = size2i / BITS_PER_UNIT;\n+\t      return data->push_partial_def (pd, vuse, maxsizei);\n \t    }\n \t}\n     }\n@@ -2315,7 +2597,12 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n \t   && is_gimple_reg_type (vr->type)\n \t   && !contains_storage_order_barrier_p (vr->operands)\n \t   && gimple_assign_single_p (def_stmt)\n-\t   && TREE_CODE (gimple_assign_rhs1 (def_stmt)) == SSA_NAME)\n+\t   && TREE_CODE (gimple_assign_rhs1 (def_stmt)) == SSA_NAME\n+\t   /* A subset of partial defs from non-constants can be handled\n+\t      by for example inserting a CONSTRUCTOR, a COMPLEX_EXPR or\n+\t      even a (series of) BIT_INSERT_EXPR hoping for simplifications\n+\t      downstream, not so much for actually doing the insertion.  */\n+\t   && data->partial_defs.is_empty ())\n     {\n       tree base2;\n       poly_int64 offset2, size2, maxsize2;\n@@ -2363,7 +2650,9 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n \t   && gimple_assign_single_p (def_stmt)\n \t   && (DECL_P (gimple_assign_rhs1 (def_stmt))\n \t       || TREE_CODE (gimple_assign_rhs1 (def_stmt)) == MEM_REF\n-\t       || handled_component_p (gimple_assign_rhs1 (def_stmt))))\n+\t       || handled_component_p (gimple_assign_rhs1 (def_stmt)))\n+\t   /* Handling this is more complicated, give up for now.  */\n+\t   && data->partial_defs.is_empty ())\n     {\n       tree base2;\n       int i, j, k;\n@@ -2497,7 +2786,9 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,\n \t       || TREE_CODE (gimple_call_arg (def_stmt, 0)) == SSA_NAME)\n \t   && (TREE_CODE (gimple_call_arg (def_stmt, 1)) == ADDR_EXPR\n \t       || TREE_CODE (gimple_call_arg (def_stmt, 1)) == SSA_NAME)\n-\t   && poly_int_tree_p (gimple_call_arg (def_stmt, 2), &copy_size))\n+\t   && poly_int_tree_p (gimple_call_arg (def_stmt, 2), &copy_size)\n+\t   /* Handling this is more complicated, give up for now.  */\n+\t   && data->partial_defs.is_empty ())\n     {\n       tree lhs, rhs;\n       ao_ref r;"}]}