{"sha": "43a5d30b9a1c2a90daf7fe3b857be138aebb8e23", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDNhNWQzMGI5YTFjMmE5MGRhZjdmZTNiODU3YmUxMzhhZWJiOGUyMw==", "commit": {"author": {"name": "Anatoly Sokolov", "email": "aesok@post.ru", "date": "2010-06-24T19:11:19Z"}, "committer": {"name": "Anatoly Sokolov", "email": "aesok@gcc.gnu.org", "date": "2010-06-24T19:11:19Z"}, "message": "fold-const.c (const_binop): Remove 'notrunc' argement.\n\n\t* fold-const.c (const_binop): Remove 'notrunc' argement. Adjust\n\trecursive call and call to 'int_const_binop'.\n\t(build_range_check, fold_cond_expr_with_comparison, unextend,\n\tfold_truthop, extract_muldiv_1, fold_comparison, fold_binary_loc,\n\tmultiple_of_p): Adjust call to const_binop.\n\nFrom-SVN: r161336", "tree": {"sha": "ebcaeb7bc74794383a65bcfcf87a312d5800ef1b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ebcaeb7bc74794383a65bcfcf87a312d5800ef1b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23", "html_url": "https://github.com/Rust-GCC/gccrs/commit/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23/comments", "author": null, "committer": null, "parents": [{"sha": "9ab1f9c70e551be4152a328b838d8b4a65289336", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9ab1f9c70e551be4152a328b838d8b4a65289336", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9ab1f9c70e551be4152a328b838d8b4a65289336"}], "stats": {"total": 222, "additions": 107, "deletions": 115}, "files": [{"sha": "6e5c9d7cf548736dd6a9d8116d855525ea96e7b1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=43a5d30b9a1c2a90daf7fe3b857be138aebb8e23", "patch": "@@ -1,3 +1,11 @@\n+2010-06-24  Anatoly Sokolov  <aesok@post.ru>\n+\n+\t* fold-const.c (const_binop): Remove 'notrunc' argement. Adjust\n+\trecursive call and call to 'int_const_binop'.\n+\t(build_range_check, fold_cond_expr_with_comparison, unextend,\n+\tfold_truthop, extract_muldiv_1, fold_comparison, fold_binary_loc,\n+\tmultiple_of_p): Adjust call to const_binop.\n+\n 2010-06-24  Uros Bizjak  <ubizjak@gmail.com>\n \n \t* config/i386/i386.md (XFmode push splitter): Use GET_MODE_SIZE to"}, {"sha": "7e7c0a20251fcbbe5cea6566b0e15d4ad68e315f", "filename": "gcc/fold-const.c", "status": "modified", "additions": 99, "deletions": 115, "changes": 214, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/43a5d30b9a1c2a90daf7fe3b857be138aebb8e23/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=43a5d30b9a1c2a90daf7fe3b857be138aebb8e23", "patch": "@@ -97,7 +97,7 @@ static bool negate_expr_p (tree);\n static tree negate_expr (tree);\n static tree split_tree (tree, enum tree_code, tree *, tree *, tree *, int);\n static tree associate_trees (location_t, tree, tree, enum tree_code, tree);\n-static tree const_binop (enum tree_code, tree, tree, int);\n+static tree const_binop (enum tree_code, tree, tree);\n static enum comparison_code comparison_to_compcode (enum tree_code);\n static enum tree_code compcode_to_comparison (enum comparison_code);\n static int operand_equal_for_comparison_p (tree, tree, tree);\n@@ -1087,12 +1087,10 @@ int_const_binop (enum tree_code code, const_tree arg1, const_tree arg2, int notr\n /* Combine two constants ARG1 and ARG2 under operation CODE to produce a new\n    constant.  We assume ARG1 and ARG2 have the same data type, or at least\n    are the same kind of constant and the same machine mode.  Return zero if\n-   combining the constants is not allowed in the current operating mode.\n-\n-   If NOTRUNC is nonzero, do not truncate the result to fit the data type.  */\n+   combining the constants is not allowed in the current operating mode.  */\n \n static tree\n-const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n+const_binop (enum tree_code code, tree arg1, tree arg2)\n {\n   /* Sanity check for the recursive cases.  */\n   if (!arg1 || !arg2)\n@@ -1102,7 +1100,7 @@ const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n   STRIP_NOPS (arg2);\n \n   if (TREE_CODE (arg1) == INTEGER_CST)\n-    return int_const_binop (code, arg1, arg2, notrunc);\n+    return int_const_binop (code, arg1, arg2, 0);\n \n   if (TREE_CODE (arg1) == REAL_CST)\n     {\n@@ -1236,8 +1234,8 @@ const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n \t{\n \tcase PLUS_EXPR:\n \tcase MINUS_EXPR:\n-\t  real = const_binop (code, r1, r2, notrunc);\n-\t  imag = const_binop (code, i1, i2, notrunc);\n+\t  real = const_binop (code, r1, r2);\n+\t  imag = const_binop (code, i1, i2);\n \t  break;\n \n \tcase MULT_EXPR:\n@@ -1247,13 +1245,11 @@ const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n \t\t\t\tmpc_mul);\n \n \t  real = const_binop (MINUS_EXPR,\n-\t\t\t      const_binop (MULT_EXPR, r1, r2, notrunc),\n-\t\t\t      const_binop (MULT_EXPR, i1, i2, notrunc),\n-\t\t\t      notrunc);\n+\t\t\t      const_binop (MULT_EXPR, r1, r2),\n+\t\t\t      const_binop (MULT_EXPR, i1, i2));\n \t  imag = const_binop (PLUS_EXPR,\n-\t\t\t      const_binop (MULT_EXPR, r1, i2, notrunc),\n-\t\t\t      const_binop (MULT_EXPR, i1, r2, notrunc),\n-\t\t\t      notrunc);\n+\t\t\t      const_binop (MULT_EXPR, r1, i2),\n+\t\t\t      const_binop (MULT_EXPR, i1, r2));\n \t  break;\n \n \tcase RDIV_EXPR:\n@@ -1277,22 +1273,19 @@ const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n \t    */\n \t    tree magsquared\n \t      = const_binop (PLUS_EXPR,\n-\t\t\t     const_binop (MULT_EXPR, r2, r2, notrunc),\n-\t\t\t     const_binop (MULT_EXPR, i2, i2, notrunc),\n-\t\t\t     notrunc);\n+\t\t\t     const_binop (MULT_EXPR, r2, r2),\n+\t\t\t     const_binop (MULT_EXPR, i2, i2));\n \t    tree t1\n \t      = const_binop (PLUS_EXPR,\n-\t\t\t     const_binop (MULT_EXPR, r1, r2, notrunc),\n-\t\t\t     const_binop (MULT_EXPR, i1, i2, notrunc),\n-\t\t\t     notrunc);\n+\t\t\t     const_binop (MULT_EXPR, r1, r2),\n+\t\t\t     const_binop (MULT_EXPR, i1, i2));\n \t    tree t2\n \t      = const_binop (MINUS_EXPR,\n-\t\t\t     const_binop (MULT_EXPR, i1, r2, notrunc),\n-\t\t\t     const_binop (MULT_EXPR, r1, i2, notrunc),\n-\t\t\t     notrunc);\n+\t\t\t     const_binop (MULT_EXPR, i1, r2),\n+\t\t\t     const_binop (MULT_EXPR, r1, i2));\n \n-\t    real = const_binop (code, t1, magsquared, notrunc);\n-\t    imag = const_binop (code, t2, magsquared, notrunc);\n+\t    real = const_binop (code, t1, magsquared);\n+\t    imag = const_binop (code, t2, magsquared);\n \t  }\n \t  else\n \t  {\n@@ -1314,18 +1307,16 @@ const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n \t\t   ti = (ai * ratio) - ar;\n \t\t   tr = tr / div;\n \t\t   ti = ti / div;  */\n-\t\ttree ratio = const_binop (code, r2, i2, notrunc);\n+\t\ttree ratio = const_binop (code, r2, i2);\n \t\ttree div = const_binop (PLUS_EXPR, i2,\n-\t\t\t\t\tconst_binop (MULT_EXPR, r2, ratio,\n-\t\t\t\t\t\t     notrunc),\n-\t\t\t\t\tnotrunc);\n-\t\treal = const_binop (MULT_EXPR, r1, ratio, notrunc);\n-\t\treal = const_binop (PLUS_EXPR, real, i1, notrunc);\n-\t\treal = const_binop (code, real, div, notrunc);\n-\n-\t\timag = const_binop (MULT_EXPR, i1, ratio, notrunc);\n-\t\timag = const_binop (MINUS_EXPR, imag, r1, notrunc);\n-\t\timag = const_binop (code, imag, div, notrunc);\n+\t\t\t\t\tconst_binop (MULT_EXPR, r2, ratio));\n+\t\treal = const_binop (MULT_EXPR, r1, ratio);\n+\t\treal = const_binop (PLUS_EXPR, real, i1);\n+\t\treal = const_binop (code, real, div);\n+\n+\t\timag = const_binop (MULT_EXPR, i1, ratio);\n+\t\timag = const_binop (MINUS_EXPR, imag, r1);\n+\t\timag = const_binop (code, imag, div);\n \t      }\n \t    else\n \t      {\n@@ -1336,19 +1327,17 @@ const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n \t\t   ti = b - (a * ratio);\n \t\t   tr = tr / div;\n \t\t   ti = ti / div;  */\n-\t\ttree ratio = const_binop (code, i2, r2, notrunc);\n+\t\ttree ratio = const_binop (code, i2, r2);\n \t\ttree div = const_binop (PLUS_EXPR, r2,\n-                                        const_binop (MULT_EXPR, i2, ratio,\n-\t\t\t\t\t\t     notrunc),\n-\t\t\t\t\tnotrunc);\n+                                        const_binop (MULT_EXPR, i2, ratio));\n \n-\t\treal = const_binop (MULT_EXPR, i1, ratio, notrunc);\n-\t\treal = const_binop (PLUS_EXPR, real, r1, notrunc);\n-\t\treal = const_binop (code, real, div, notrunc);\n+\t\treal = const_binop (MULT_EXPR, i1, ratio);\n+\t\treal = const_binop (PLUS_EXPR, real, r1);\n+\t\treal = const_binop (code, real, div);\n \n-\t\timag = const_binop (MULT_EXPR, r1, ratio, notrunc);\n-\t\timag = const_binop (MINUS_EXPR, i1, imag, notrunc);\n-\t\timag = const_binop (code, imag, div, notrunc);\n+\t\timag = const_binop (MULT_EXPR, r1, ratio);\n+\t\timag = const_binop (MINUS_EXPR, i1, imag);\n+\t\timag = const_binop (code, imag, div);\n \t      }\n \t  }\n \t  break;\n@@ -1394,7 +1383,7 @@ const_binop (enum tree_code code, tree arg1, tree arg2, int notrunc)\n               elements2 = TREE_CHAIN (elements2);\n             }\n \n-          elem = const_binop (code, elem1, elem2, notrunc);\n+          elem = const_binop (code, elem1, elem2);\n \n           /* It is possible that const_binop cannot handle the given\n             code and return NULL_TREE */\n@@ -3490,9 +3479,9 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n \n   /* Make the mask to be used against the extracted field.  */\n   mask = build_int_cst_type (unsigned_type, -1);\n-  mask = const_binop (LSHIFT_EXPR, mask, size_int (nbitsize - lbitsize), 0);\n+  mask = const_binop (LSHIFT_EXPR, mask, size_int (nbitsize - lbitsize));\n   mask = const_binop (RSHIFT_EXPR, mask,\n-\t\t      size_int (nbitsize - lbitsize - lbitpos), 0);\n+\t\t      size_int (nbitsize - lbitsize - lbitpos));\n \n   if (! const_p)\n     /* If not comparing with constant, just rework the comparison\n@@ -3525,7 +3514,7 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n       if (! integer_zerop (const_binop (RSHIFT_EXPR,\n \t\t\t\t\tfold_convert_loc (loc,\n \t\t\t\t\t\t\t  unsigned_type, rhs),\n-\t\t\t\t\tsize_int (lbitsize), 0)))\n+\t\t\t\t\tsize_int (lbitsize))))\n \t{\n \t  warning (0, \"comparison is always %d due to width of bit-field\",\n \t\t   code == NE_EXPR);\n@@ -3536,7 +3525,7 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n     {\n       tree tem = const_binop (RSHIFT_EXPR,\n \t\t\t      fold_convert_loc (loc, signed_type, rhs),\n-\t\t\t      size_int (lbitsize - 1), 0);\n+\t\t\t      size_int (lbitsize - 1));\n       if (! integer_zerop (tem) && ! integer_all_onesp (tem))\n \t{\n \t  warning (0, \"comparison is always %d due to width of bit-field\",\n@@ -3565,8 +3554,8 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n   rhs = const_binop (BIT_AND_EXPR,\n \t\t     const_binop (LSHIFT_EXPR,\n \t\t\t\t  fold_convert_loc (loc, unsigned_type, rhs),\n-\t\t\t\t  size_int (lbitpos), 0),\n-\t\t     mask, 0);\n+\t\t\t\t  size_int (lbitpos)),\n+\t\t     mask);\n \n   lhs = build2 (code, compare_type,\n \t\tbuild2 (BIT_AND_EXPR, unsigned_type, lhs, mask),\n@@ -3652,8 +3641,8 @@ decode_field_reference (location_t loc, tree exp, HOST_WIDE_INT *pbitsize,\n \n   mask = build_int_cst_type (unsigned_type, -1);\n \n-  mask = const_binop (LSHIFT_EXPR, mask, size_int (precision - *pbitsize), 0);\n-  mask = const_binop (RSHIFT_EXPR, mask, size_int (precision - *pbitsize), 0);\n+  mask = const_binop (LSHIFT_EXPR, mask, size_int (precision - *pbitsize));\n+  mask = const_binop (RSHIFT_EXPR, mask, size_int (precision - *pbitsize));\n \n   /* Merge it with the mask we found in the BIT_AND_EXPR, if any.  */\n   if (and_mask != 0)\n@@ -3681,9 +3670,8 @@ all_ones_mask_p (const_tree mask, int size)\n     tree_int_cst_equal (mask,\n \t\t\tconst_binop (RSHIFT_EXPR,\n \t\t\t\t     const_binop (LSHIFT_EXPR, tmask,\n-\t\t\t\t\t\t  size_int (precision - size),\n-\t\t\t\t\t\t  0),\n-\t\t\t\t     size_int (precision - size), 0));\n+\t\t\t\t\t\t  size_int (precision - size)),\n+\t\t\t\t     size_int (precision - size)));\n }\n \n /* Subroutine for fold: determine if VAL is the INTEGER_CONST that\n@@ -4283,7 +4271,7 @@ build_range_check (location_t loc, tree type, tree exp, int in_p,\n   low = fold_convert_loc (loc, etype, low);\n   exp = fold_convert_loc (loc, etype, exp);\n \n-  value = const_binop (MINUS_EXPR, high, low, 0);\n+  value = const_binop (MINUS_EXPR, high, low);\n \n \n   if (POINTER_TYPE_P (etype))\n@@ -4786,7 +4774,7 @@ fold_cond_expr_with_comparison (location_t loc, tree type,\n \t\t\t       OEP_ONLY_CONST)\n \t    && operand_equal_p (arg01,\n \t\t\t\tconst_binop (PLUS_EXPR, arg2,\n-\t\t\t\t\t     build_int_cst (type, 1), 0),\n+\t\t\t\t\t     build_int_cst (type, 1)),\n \t\t\t\tOEP_ONLY_CONST))\n \t  {\n \t    tem = fold_build2_loc (loc, MIN_EXPR, TREE_TYPE (arg00), arg00,\n@@ -4804,7 +4792,7 @@ fold_cond_expr_with_comparison (location_t loc, tree type,\n \t\t\t       OEP_ONLY_CONST)\n \t    && operand_equal_p (arg01,\n \t\t\t\tconst_binop (MINUS_EXPR, arg2,\n-\t\t\t\t\t     build_int_cst (type, 1), 0),\n+\t\t\t\t\t     build_int_cst (type, 1)),\n \t\t\t\tOEP_ONLY_CONST))\n \t  {\n \t    tem = fold_build2_loc (loc, MIN_EXPR, TREE_TYPE (arg00), arg00,\n@@ -4822,7 +4810,7 @@ fold_cond_expr_with_comparison (location_t loc, tree type,\n \t\t\t       OEP_ONLY_CONST)\n \t    && operand_equal_p (arg01,\n \t\t\t\tconst_binop (MINUS_EXPR, arg2,\n-\t\t\t\t\t     build_int_cst (type, 1), 0),\n+\t\t\t\t\t     build_int_cst (type, 1)),\n \t\t\t\tOEP_ONLY_CONST))\n \t  {\n \t    tem = fold_build2_loc (loc, MAX_EXPR, TREE_TYPE (arg00), arg00,\n@@ -4838,7 +4826,7 @@ fold_cond_expr_with_comparison (location_t loc, tree type,\n \t\t\t       OEP_ONLY_CONST)\n \t    && operand_equal_p (arg01,\n \t\t\t\tconst_binop (PLUS_EXPR, arg2,\n-\t\t\t\t\t     build_int_cst (type, 1), 0),\n+\t\t\t\t\t     build_int_cst (type, 1)),\n \t\t\t\tOEP_ONLY_CONST))\n \t  {\n \t    tem = fold_build2_loc (loc, MAX_EXPR, TREE_TYPE (arg00), arg00,\n@@ -4970,8 +4958,8 @@ unextend (tree c, int p, int unsignedp, tree mask)\n   /* We work by getting just the sign bit into the low-order bit, then\n      into the high-order bit, then sign-extend.  We then XOR that value\n      with C.  */\n-  temp = const_binop (RSHIFT_EXPR, c, size_int (p - 1), 0);\n-  temp = const_binop (BIT_AND_EXPR, temp, size_int (1), 0);\n+  temp = const_binop (RSHIFT_EXPR, c, size_int (p - 1));\n+  temp = const_binop (BIT_AND_EXPR, temp, size_int (1));\n \n   /* We must use a signed type in order to get an arithmetic right shift.\n      However, we must also avoid introducing accidental overflows, so that\n@@ -4982,18 +4970,16 @@ unextend (tree c, int p, int unsignedp, tree mask)\n   if (TYPE_UNSIGNED (type))\n     temp = fold_convert (signed_type_for (type), temp);\n \n-  temp = const_binop (LSHIFT_EXPR, temp, size_int (modesize - 1), 0);\n-  temp = const_binop (RSHIFT_EXPR, temp, size_int (modesize - p - 1), 0);\n+  temp = const_binop (LSHIFT_EXPR, temp, size_int (modesize - 1));\n+  temp = const_binop (RSHIFT_EXPR, temp, size_int (modesize - p - 1));\n   if (mask != 0)\n     temp = const_binop (BIT_AND_EXPR, temp,\n-\t\t\tfold_convert (TREE_TYPE (c), mask),\n-\t\t\t0);\n+\t\t\tfold_convert (TREE_TYPE (c), mask));\n   /* If necessary, convert the type back to match the type of C.  */\n   if (TYPE_UNSIGNED (type))\n     temp = fold_convert (type, temp);\n \n-  return fold_convert (type,\n-\t\t       const_binop (BIT_XOR_EXPR, c, temp, 0));\n+  return fold_convert (type, const_binop (BIT_XOR_EXPR, c, temp));\n }\n \f\n /* For an expression that has the form\n@@ -5330,19 +5316,18 @@ fold_truthop (location_t loc, enum tree_code code, tree truth_type,\n     }\n \n   ll_mask = const_binop (LSHIFT_EXPR, fold_convert_loc (loc, lntype, ll_mask),\n-\t\t\t size_int (xll_bitpos), 0);\n+\t\t\t size_int (xll_bitpos));\n   rl_mask = const_binop (LSHIFT_EXPR, fold_convert_loc (loc, lntype, rl_mask),\n-\t\t\t size_int (xrl_bitpos), 0);\n+\t\t\t size_int (xrl_bitpos));\n \n   if (l_const)\n     {\n       l_const = fold_convert_loc (loc, lntype, l_const);\n       l_const = unextend (l_const, ll_bitsize, ll_unsignedp, ll_and_mask);\n-      l_const = const_binop (LSHIFT_EXPR, l_const, size_int (xll_bitpos), 0);\n+      l_const = const_binop (LSHIFT_EXPR, l_const, size_int (xll_bitpos));\n       if (! integer_zerop (const_binop (BIT_AND_EXPR, l_const,\n \t\t\t\t\tfold_build1_loc (loc, BIT_NOT_EXPR,\n-\t\t\t\t\t\t     lntype, ll_mask),\n-\t\t\t\t\t0)))\n+\t\t\t\t\t\t     lntype, ll_mask))))\n \t{\n \t  warning (0, \"comparison is always %d\", wanted_code == NE_EXPR);\n \n@@ -5353,11 +5338,10 @@ fold_truthop (location_t loc, enum tree_code code, tree truth_type,\n     {\n       r_const = fold_convert_loc (loc, lntype, r_const);\n       r_const = unextend (r_const, rl_bitsize, rl_unsignedp, rl_and_mask);\n-      r_const = const_binop (LSHIFT_EXPR, r_const, size_int (xrl_bitpos), 0);\n+      r_const = const_binop (LSHIFT_EXPR, r_const, size_int (xrl_bitpos));\n       if (! integer_zerop (const_binop (BIT_AND_EXPR, r_const,\n \t\t\t\t\tfold_build1_loc (loc, BIT_NOT_EXPR,\n-\t\t\t\t\t\t     lntype, rl_mask),\n-\t\t\t\t\t0)))\n+\t\t\t\t\t\t     lntype, rl_mask))))\n \t{\n \t  warning (0, \"comparison is always %d\", wanted_code == NE_EXPR);\n \n@@ -5398,18 +5382,18 @@ fold_truthop (location_t loc, enum tree_code code, tree truth_type,\n \n       lr_mask = const_binop (LSHIFT_EXPR, fold_convert_loc (loc,\n \t\t\t\t\t\t\t    rntype, lr_mask),\n-\t\t\t     size_int (xlr_bitpos), 0);\n+\t\t\t     size_int (xlr_bitpos));\n       rr_mask = const_binop (LSHIFT_EXPR, fold_convert_loc (loc,\n \t\t\t\t\t\t\t    rntype, rr_mask),\n-\t\t\t     size_int (xrr_bitpos), 0);\n+\t\t\t     size_int (xrr_bitpos));\n \n       /* Make a mask that corresponds to both fields being compared.\n \t Do this for both items being compared.  If the operands are the\n \t same size and the bits being compared are in the same position\n \t then we can do this by masking both and comparing the masked\n \t results.  */\n-      ll_mask = const_binop (BIT_IOR_EXPR, ll_mask, rl_mask, 0);\n-      lr_mask = const_binop (BIT_IOR_EXPR, lr_mask, rr_mask, 0);\n+      ll_mask = const_binop (BIT_IOR_EXPR, ll_mask, rl_mask);\n+      lr_mask = const_binop (BIT_IOR_EXPR, lr_mask, rr_mask);\n       if (lnbitsize == rnbitsize && xll_bitpos == xlr_bitpos)\n \t{\n \t  lhs = make_bit_field_ref (loc, ll_inner, lntype, lnbitsize, lnbitpos,\n@@ -5448,9 +5432,9 @@ fold_truthop (location_t loc, enum tree_code code, tree truth_type,\n \t\t\t\t    MIN (lr_bitpos, rr_bitpos), lr_unsignedp);\n \n \t  ll_mask = const_binop (RSHIFT_EXPR, ll_mask,\n-\t\t\t\t size_int (MIN (xll_bitpos, xrl_bitpos)), 0);\n+\t\t\t\t size_int (MIN (xll_bitpos, xrl_bitpos)));\n \t  lr_mask = const_binop (RSHIFT_EXPR, lr_mask,\n-\t\t\t\t size_int (MIN (xlr_bitpos, xrr_bitpos)), 0);\n+\t\t\t\t size_int (MIN (xlr_bitpos, xrr_bitpos)));\n \n \t  /* Convert to the smaller type before masking out unwanted bits.  */\n \t  type = lntype;\n@@ -5487,10 +5471,10 @@ fold_truthop (location_t loc, enum tree_code code, tree truth_type,\n      common between the masks, those bits of the constants must be the same.\n      If not, the condition is always false.  Test for this to avoid generating\n      incorrect code below.  */\n-  result = const_binop (BIT_AND_EXPR, ll_mask, rl_mask, 0);\n+  result = const_binop (BIT_AND_EXPR, ll_mask, rl_mask);\n   if (! integer_zerop (result)\n-      && simple_cst_equal (const_binop (BIT_AND_EXPR, result, l_const, 0),\n-\t\t\t   const_binop (BIT_AND_EXPR, result, r_const, 0)) != 1)\n+      && simple_cst_equal (const_binop (BIT_AND_EXPR, result, l_const),\n+\t\t\t   const_binop (BIT_AND_EXPR, result, r_const)) != 1)\n     {\n       if (wanted_code == NE_EXPR)\n \t{\n@@ -5511,15 +5495,15 @@ fold_truthop (location_t loc, enum tree_code code, tree truth_type,\n   result = make_bit_field_ref (loc, ll_inner, lntype, lnbitsize, lnbitpos,\n \t\t\t       ll_unsignedp || rl_unsignedp);\n \n-  ll_mask = const_binop (BIT_IOR_EXPR, ll_mask, rl_mask, 0);\n+  ll_mask = const_binop (BIT_IOR_EXPR, ll_mask, rl_mask);\n   if (! all_ones_mask_p (ll_mask, lnbitsize))\n     {\n       result = build2 (BIT_AND_EXPR, lntype, result, ll_mask);\n       SET_EXPR_LOCATION (result, loc);\n     }\n \n   result = build2 (wanted_code, truth_type, result,\n-\t\t   const_binop (BIT_IOR_EXPR, l_const, r_const, 0));\n+\t\t   const_binop (BIT_IOR_EXPR, l_const, r_const));\n \n  fold_truthop_exit:\n   SET_EXPR_LOCATION (result, loc);\n@@ -5702,9 +5686,9 @@ extract_muldiv_1 (tree t, tree c, enum tree_code code, tree wide_type,\n       /* For a constant, we can always simplify if we are a multiply\n \t or (for divide and modulus) if it is a multiple of our constant.  */\n       if (code == MULT_EXPR\n-\t  || integer_zerop (const_binop (TRUNC_MOD_EXPR, t, c, 0)))\n+\t  || integer_zerop (const_binop (TRUNC_MOD_EXPR, t, c)))\n \treturn const_binop (code, fold_convert (ctype, t),\n-\t\t\t    fold_convert (ctype, c), 0);\n+\t\t\t    fold_convert (ctype, c));\n       break;\n \n     CASE_CONVERT: case NON_LVALUE_EXPR:\n@@ -5812,7 +5796,7 @@ extract_muldiv_1 (tree t, tree c, enum tree_code code, tree wide_type,\n \t  && 0 != (t1 = fold_convert (ctype,\n \t\t\t\t      const_binop (LSHIFT_EXPR,\n \t\t\t\t\t\t   size_one_node,\n-\t\t\t\t\t\t   op1, 0)))\n+\t\t\t\t\t\t   op1)))\n \t  && !TREE_OVERFLOW (t1))\n \treturn extract_muldiv (build2 (tcode == LSHIFT_EXPR\n \t\t\t\t       ? MULT_EXPR : FLOOR_DIV_EXPR,\n@@ -5880,10 +5864,10 @@ extract_muldiv_1 (tree t, tree c, enum tree_code code, tree wide_type,\n       /* If it's a multiply or a division/modulus operation of a multiple\n          of our constant, do the operation and verify it doesn't overflow.  */\n       if (code == MULT_EXPR\n-\t  || integer_zerop (const_binop (TRUNC_MOD_EXPR, op1, c, 0)))\n+\t  || integer_zerop (const_binop (TRUNC_MOD_EXPR, op1, c)))\n \t{\n \t  op1 = const_binop (code, fold_convert (ctype, op1),\n-\t\t\t     fold_convert (ctype, c), 0);\n+\t\t\t     fold_convert (ctype, c));\n \t  /* We allow the constant to overflow with wrapping semantics.  */\n \t  if (op1 == 0\n \t      || (TREE_OVERFLOW (op1) && !TYPE_OVERFLOW_WRAPS (ctype)))\n@@ -5931,7 +5915,7 @@ extract_muldiv_1 (tree t, tree c, enum tree_code code, tree wide_type,\n \t      || (TREE_CODE (TREE_TYPE (t)) == INTEGER_TYPE\n \t\t  && TYPE_IS_SIZETYPE (TREE_TYPE (t))))\n \t  && TREE_CODE (TREE_OPERAND (t, 1)) == INTEGER_CST\n-\t  && integer_zerop (const_binop (TRUNC_MOD_EXPR, op1, c, 0)))\n+\t  && integer_zerop (const_binop (TRUNC_MOD_EXPR, op1, c)))\n \t{\n \t  *strict_overflow_p = true;\n \t  return omit_one_operand (type, integer_zero_node, op0);\n@@ -5987,23 +5971,23 @@ extract_muldiv_1 (tree t, tree c, enum tree_code code, tree wide_type,\n \t\t  && code != FLOOR_MOD_EXPR && code != ROUND_MOD_EXPR\n \t\t  && code != MULT_EXPR)))\n \t{\n-\t  if (integer_zerop (const_binop (TRUNC_MOD_EXPR, op1, c, 0)))\n+\t  if (integer_zerop (const_binop (TRUNC_MOD_EXPR, op1, c)))\n \t    {\n \t      if (TYPE_OVERFLOW_UNDEFINED (ctype))\n \t\t*strict_overflow_p = true;\n \t      return fold_build2 (tcode, ctype, fold_convert (ctype, op0),\n \t\t\t\t  fold_convert (ctype,\n \t\t\t\t\t\tconst_binop (TRUNC_DIV_EXPR,\n-\t\t\t\t\t\t\t     op1, c, 0)));\n+\t\t\t\t\t\t\t     op1, c)));\n \t    }\n-\t  else if (integer_zerop (const_binop (TRUNC_MOD_EXPR, c, op1, 0)))\n+\t  else if (integer_zerop (const_binop (TRUNC_MOD_EXPR, c, op1)))\n \t    {\n \t      if (TYPE_OVERFLOW_UNDEFINED (ctype))\n \t\t*strict_overflow_p = true;\n \t      return fold_build2 (code, ctype, fold_convert (ctype, op0),\n \t\t\t\t  fold_convert (ctype,\n \t\t\t\t\t\tconst_binop (TRUNC_DIV_EXPR,\n-\t\t\t\t\t\t\t     c, op1, 0)));\n+\t\t\t\t\t\t\t     c, op1)));\n \t    }\n \t}\n       break;\n@@ -9015,7 +8999,7 @@ fold_comparison (location_t loc, enum tree_code code, tree type,\n \t  && TREE_CODE (TREE_OPERAND (arg0, 1)) == REAL_CST\n \t  && 0 != (tem = const_binop (TREE_CODE (arg0) == PLUS_EXPR\n \t\t\t\t      ? MINUS_EXPR : PLUS_EXPR,\n-\t\t\t\t      arg1, TREE_OPERAND (arg0, 1), 0))\n+\t\t\t\t      arg1, TREE_OPERAND (arg0, 1)))\n \t  && !TREE_OVERFLOW (tem))\n \treturn fold_build2_loc (loc, code, type, TREE_OPERAND (arg0, 0), tem);\n \n@@ -9028,7 +9012,7 @@ fold_comparison (location_t loc, enum tree_code code, tree type,\n \t  && TREE_CODE (arg0) == MINUS_EXPR\n \t  && TREE_CODE (TREE_OPERAND (arg0, 0)) == REAL_CST\n \t  && 0 != (tem = const_binop (MINUS_EXPR, TREE_OPERAND (arg0, 0),\n-\t\t\t\t      arg1, 0))\n+\t\t\t\t      arg1))\n \t  && !TREE_OVERFLOW (tem))\n \treturn fold_build2_loc (loc, swap_tree_comparison (code), type,\n \t\t\t    TREE_OPERAND (arg0, 1), tem);\n@@ -9449,7 +9433,7 @@ fold_binary_loc (location_t loc,\n \t  /* Make sure type and arg0 have the same saturating flag.  */\n \t  gcc_assert (TYPE_SATURATING (type)\n \t\t      == TYPE_SATURATING (TREE_TYPE (arg0)));\n-\t  tem = const_binop (code, arg0, arg1, 0);\n+\t  tem = const_binop (code, arg0, arg1);\n \t}\n       else if (kind == tcc_comparison)\n \ttem = fold_relational_const (code, type, arg0, arg1);\n@@ -9708,7 +9692,7 @@ fold_binary_loc (location_t loc,\n \t      && TREE_CODE (TREE_OPERAND (arg1, 1)) == INTEGER_CST\n \t      && integer_zerop (const_binop (BIT_AND_EXPR,\n \t\t\t\t\t     TREE_OPERAND (arg0, 1),\n-\t\t\t\t\t     TREE_OPERAND (arg1, 1), 0)))\n+\t\t\t\t\t     TREE_OPERAND (arg1, 1))))\n \t    {\n \t      code = BIT_IOR_EXPR;\n \t      goto bit_ior;\n@@ -10430,7 +10414,7 @@ fold_binary_loc (location_t loc,\n \t      && TREE_CODE (TREE_OPERAND (arg0, 0)) == REAL_CST)\n \t    {\n \t      tree tem = const_binop (MULT_EXPR, TREE_OPERAND (arg0, 0),\n-\t\t\t\t      arg1, 0);\n+\t\t\t\t      arg1);\n \t      if (tem)\n \t\treturn fold_build2_loc (loc, RDIV_EXPR, type, tem,\n \t\t\t\t    TREE_OPERAND (arg0, 1));\n@@ -10799,7 +10783,7 @@ fold_binary_loc (location_t loc,\n \t  && TREE_CODE (TREE_OPERAND (arg1, 1)) == INTEGER_CST\n \t  && integer_zerop (const_binop (BIT_AND_EXPR,\n \t\t\t\t\t TREE_OPERAND (arg0, 1),\n-\t\t\t\t\t TREE_OPERAND (arg1, 1), 0)))\n+\t\t\t\t\t TREE_OPERAND (arg1, 1))))\n \t{\n \t  code = BIT_IOR_EXPR;\n \t  goto bit_ior;\n@@ -11255,7 +11239,7 @@ fold_binary_loc (location_t loc,\n \t{\n \t  if (flag_reciprocal_math\n \t      && 0 != (tem = const_binop (code, build_real (type, dconst1),\n-\t\t\t\t\t  arg1, 0)))\n+\t\t\t\t\t  arg1)))\n \t    return fold_build2_loc (loc, MULT_EXPR, type, arg0, tem);\n \t  /* Find the reciprocal if optimizing and the result is exact.  */\n \t  if (optimize)\n@@ -11292,7 +11276,7 @@ fold_binary_loc (location_t loc,\n \t  && TREE_CODE (TREE_OPERAND (arg1, 1)) == REAL_CST)\n \t{\n \t  tree tem = const_binop (RDIV_EXPR, arg0,\n-\t\t\t\t  TREE_OPERAND (arg1, 1), 0);\n+\t\t\t\t  TREE_OPERAND (arg1, 1));\n \t  if (tem)\n \t    return fold_build2_loc (loc, RDIV_EXPR, type, tem,\n \t\t\t\tTREE_OPERAND (arg1, 0));\n@@ -11727,7 +11711,7 @@ fold_binary_loc (location_t loc,\n \t{\n \t  tree tem = build_int_cst (TREE_TYPE (arg1),\n \t\t\t\t    TYPE_PRECISION (type));\n-\t  tem = const_binop (MINUS_EXPR, tem, arg1, 0);\n+\t  tem = const_binop (MINUS_EXPR, tem, arg1);\n \t  return fold_build2_loc (loc, RROTATE_EXPR, type, op0, tem);\n \t}\n \n@@ -12074,7 +12058,7 @@ fold_binary_loc (location_t loc,\n \t\t\t\t      ? MINUS_EXPR : PLUS_EXPR,\n \t\t\t\t      fold_convert_loc (loc, TREE_TYPE (arg0),\n \t\t\t\t\t\t\targ1),\n-\t\t\t\t      TREE_OPERAND (arg0, 1), 0))\n+\t\t\t\t      TREE_OPERAND (arg0, 1)))\n \t  && !TREE_OVERFLOW (tem))\n \treturn fold_build2_loc (loc, code, type, TREE_OPERAND (arg0, 0), tem);\n \n@@ -12810,14 +12794,14 @@ fold_binary_loc (location_t loc,\n \t\t{\n \t\tcase GT_EXPR:\n \t\t  arg1 = const_binop (PLUS_EXPR, arg1,\n-\t\t\t\t      build_int_cst (TREE_TYPE (arg1), 1), 0);\n+\t\t\t\t      build_int_cst (TREE_TYPE (arg1), 1));\n \t\t  return fold_build2_loc (loc, EQ_EXPR, type,\n \t\t\t\t      fold_convert_loc (loc,\n \t\t\t\t\t\t\tTREE_TYPE (arg1), arg0),\n \t\t\t\t      arg1);\n \t\tcase LE_EXPR:\n \t\t  arg1 = const_binop (PLUS_EXPR, arg1,\n-\t\t\t\t      build_int_cst (TREE_TYPE (arg1), 1), 0);\n+\t\t\t\t      build_int_cst (TREE_TYPE (arg1), 1));\n \t\t  return fold_build2_loc (loc, NE_EXPR, type,\n \t\t\t\t      fold_convert_loc (loc, TREE_TYPE (arg1),\n \t\t\t\t\t\t\targ0),\n@@ -12851,13 +12835,13 @@ fold_binary_loc (location_t loc,\n \t      switch (code)\n \t\t{\n \t\tcase GE_EXPR:\n-\t\t  arg1 = const_binop (MINUS_EXPR, arg1, integer_one_node, 0);\n+\t\t  arg1 = const_binop (MINUS_EXPR, arg1, integer_one_node);\n \t\t  return fold_build2_loc (loc, NE_EXPR, type,\n \t\t\t\t      fold_convert_loc (loc,\n \t\t\t\t\t\t\tTREE_TYPE (arg1), arg0),\n \t\t\t\t      arg1);\n \t\tcase LT_EXPR:\n-\t\t  arg1 = const_binop (MINUS_EXPR, arg1, integer_one_node, 0);\n+\t\t  arg1 = const_binop (MINUS_EXPR, arg1, integer_one_node);\n \t\t  return fold_build2_loc (loc, EQ_EXPR, type,\n \t\t\t\t      fold_convert_loc (loc, TREE_TYPE (arg1),\n \t\t\t\t\t\t\targ0),\n@@ -14176,7 +14160,7 @@ multiple_of_p (tree type, const_tree top, const_tree bottom)\n \t      && 0 != (t1 = fold_convert (type,\n \t\t\t\t\t  const_binop (LSHIFT_EXPR,\n \t\t\t\t\t\t       size_one_node,\n-\t\t\t\t\t\t       op1, 0)))\n+\t\t\t\t\t\t       op1)))\n \t      && !TREE_OVERFLOW (t1))\n \t    return multiple_of_p (type, t1, bottom);\n \t}"}]}