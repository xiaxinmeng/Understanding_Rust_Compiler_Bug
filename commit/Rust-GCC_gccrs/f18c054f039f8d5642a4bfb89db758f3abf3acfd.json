{"sha": "f18c054f039f8d5642a4bfb89db758f3abf3acfd", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZjE4YzA1NGYwMzlmOGQ1NjQyYTRiZmI4OWRiNzU4ZjNhYmYzYWNmZA==", "commit": {"author": {"name": "Daniel Berlin", "email": "dan@cgsoftware.com", "date": "2001-12-01T01:59:02Z"}, "committer": {"name": "Daniel Berlin", "email": "dberlin@gcc.gnu.org", "date": "2001-12-01T01:59:02Z"}, "message": "rs6000.c (altivec_expand_builtin): add ALTIVEC_BUILTIN_LD_INTERNAL_4sf and ALTIVEC_BUILTIN_ST_INTERNAL_4sf...\n\n2001-11-30  Daniel Berlin  <dan@cgsoftware.com>\n\n\t* config/rs6000/rs6000.c (altivec_expand_builtin): add\n\tALTIVEC_BUILTIN_LD_INTERNAL_4sf and ALTIVEC_BUILTIN_ST_INTERNAL_4sf,\n\t*_16qi,_8hi, rename existing V4SI ones to *_4si.\n\t(altivec_init_builtins): Ditto.\n\t(bdesc_2arg): Rename CODE_FOR_* to match changes in MD file.\n\n\t* config/rs6000/rs6000.md: Add attribute types vecsimple,\n\tveccomplex, vecfloat, and vecperm, for altivec instructions.\n\tModify altivec patterns to use approriate attribute type.\n\tModify altivec patterns to match RTL operations where approriate\n\t(IE no unspec where we can avoid it).\n\tAdd vector unit scheduling for ppc7450.\n\tRename patterns to what they are where approriate\n\t(altivec_vaddfp->addv4sf3, etc)\n\n\t* config/rs6000/rs6000.h (enum rs6000_builtins): Change VRS->VSR.\n\tPass -mppc, and define _ARCH_PPC, if -mcpu=7450 is used.\n\n\t* config/rs6000/sysv4.h: Add -mcpu=7450.\n\n\t* testsuite/gcc.dg/altivec-1.c: Update test to take into account renamed\n\t_builtin_altivec_ld_interal function.\n\nFrom-SVN: r47502", "tree": {"sha": "b1e97ced54c5df40ecdbb3fb976618106a610db3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b1e97ced54c5df40ecdbb3fb976618106a610db3"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/f18c054f039f8d5642a4bfb89db758f3abf3acfd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f18c054f039f8d5642a4bfb89db758f3abf3acfd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f18c054f039f8d5642a4bfb89db758f3abf3acfd", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f18c054f039f8d5642a4bfb89db758f3abf3acfd/comments", "author": null, "committer": null, "parents": [{"sha": "6af8c7409177219af485173a9c917d466efb5e10", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6af8c7409177219af485173a9c917d466efb5e10", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6af8c7409177219af485173a9c917d466efb5e10"}], "stats": {"total": 722, "additions": 487, "deletions": 235}, "files": [{"sha": "71bacf59bfe34b6d601fd06e4c1424a542f0f4dd", "filename": "gcc/ChangeLog", "status": "modified", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=f18c054f039f8d5642a4bfb89db758f3abf3acfd", "patch": "@@ -1,3 +1,28 @@\n+2001-11-30  Daniel Berlin  <dan@cgsoftware.com>\n+\n+\t* config/rs6000/rs6000.c (altivec_expand_builtin): add \n+\tALTIVEC_BUILTIN_LD_INTERNAL_4sf and ALTIVEC_BUILTIN_ST_INTERNAL_4sf, \n+\t*_16qi,_8hi, rename existing V4SI ones to *_4si.\n+\t(altivec_init_builtins): Ditto.\n+\t(bdesc_2arg): Rename CODE_FOR_* to match changes in MD file.\n+\t\n+\t* config/rs6000/rs6000.md: Add attribute types vecsimple,\n+\tveccomplex, vecfloat, and vecperm, for altivec instructions.  \n+\tModify altivec patterns to use approriate attribute type.\n+\tModify altivec patterns to match RTL operations where approriate\n+\t(IE no unspec where we can avoid it).\n+\tAdd vector unit scheduling for ppc7450.\n+\tRename patterns to what they are where approriate \n+\t(altivec_vaddfp->addv4sf3, etc)\n+\n+\t* config/rs6000/rs6000.h (enum rs6000_builtins): Change VRS->VSR.\n+\tPass -mppc, and define _ARCH_PPC, if -mcpu=7450 is used.\n+\n+\t* config/rs6000/sysv4.h: Add -mcpu=7450.\n+\n+\t* testsuite/gcc.dg/altivec-1.c: Update test to take into account renamed \n+\t_builtin_altivec_ld_interal function.\n+\n 2001-11-30  Kaveh R. Ghazi  <ghazi@caip.rutgers.edu>\n \n \t* configure.in (AC_CHECK_FUNCS): Delete strtoul, bsearch, popen,"}, {"sha": "2f1b0a162aebc8fd14cddb8ea7f6a327c955a5e4", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 189, "deletions": 33, "changes": 222, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=f18c054f039f8d5642a4bfb89db758f3abf3acfd", "patch": "@@ -2976,18 +2976,18 @@ struct builtin_description\n /* Simple binary operatiors: VECc = foo (VECa, VECb).  */\n static const struct builtin_description bdesc_2arg[] =\n {\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vaddubm, \"__builtin_altivec_vaddubm\", ALTIVEC_BUILTIN_VADDUBM },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vadduhm, \"__builtin_altivec_vadduhm\", ALTIVEC_BUILTIN_VADDUHM },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vadduwm, \"__builtin_altivec_vadduwm\", ALTIVEC_BUILTIN_VADDUWM },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vaddfp, \"__builtin_altivec_vaddfp\", ALTIVEC_BUILTIN_VADDFP },\n+  { MASK_ALTIVEC, CODE_FOR_addv16qi3, \"__builtin_altivec_vaddubm\", ALTIVEC_BUILTIN_VADDUBM },\n+  { MASK_ALTIVEC, CODE_FOR_addv8hi3, \"__builtin_altivec_vadduhm\", ALTIVEC_BUILTIN_VADDUHM },\n+  { MASK_ALTIVEC, CODE_FOR_addv4si3, \"__builtin_altivec_vadduwm\", ALTIVEC_BUILTIN_VADDUWM },\n+  { MASK_ALTIVEC, CODE_FOR_addv4sf3, \"__builtin_altivec_vaddfp\", ALTIVEC_BUILTIN_VADDFP },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vaddcuw, \"__builtin_altivec_vaddcuw\", ALTIVEC_BUILTIN_VADDCUW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vaddubs, \"__builtin_altivec_vaddubs\", ALTIVEC_BUILTIN_VADDUBS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vaddsbs, \"__builtin_altivec_vaddsbs\", ALTIVEC_BUILTIN_VADDSBS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vadduhs, \"__builtin_altivec_vadduhs\", ALTIVEC_BUILTIN_VADDUHS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vaddshs, \"__builtin_altivec_vaddshs\", ALTIVEC_BUILTIN_VADDSHS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vadduws, \"__builtin_altivec_vadduws\", ALTIVEC_BUILTIN_VADDUWS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vaddsws, \"__builtin_altivec_vaddsws\", ALTIVEC_BUILTIN_VADDSWS },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vand, \"__builtin_altivec_vand\", ALTIVEC_BUILTIN_VAND },\n+  { MASK_ALTIVEC, CODE_FOR_andv4si3, \"__builtin_altivec_vand\", ALTIVEC_BUILTIN_VAND },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vandc, \"__builtin_altivec_vandc\", ALTIVEC_BUILTIN_VANDC },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vavgub, \"__builtin_altivec_vavgub\", ALTIVEC_BUILTIN_VAVGUB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vavgsb, \"__builtin_altivec_vavgsb\", ALTIVEC_BUILTIN_VAVGSB },\n@@ -3008,26 +3008,26 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vcmpgtuw, \"__builtin_altivec_vcmpgtuw\", ALTIVEC_BUILTIN_VCMPGTUW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vcmpgtsw, \"__builtin_altivec_vcmpgtsw\", ALTIVEC_BUILTIN_VCMPGTSW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vcmpgtfp, \"__builtin_altivec_vcmpgtfp\", ALTIVEC_BUILTIN_VCMPGTFP },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vmaxub, \"__builtin_altivec_vmaxub\", ALTIVEC_BUILTIN_VMAXUB },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vmaxsb, \"__builtin_altivec_vmaxsb\", ALTIVEC_BUILTIN_VMAXSB },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vmaxuh, \"__builtin_altivec_vmaxuh\", ALTIVEC_BUILTIN_VMAXUH },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vmaxsh, \"__builtin_altivec_vmaxsh\", ALTIVEC_BUILTIN_VMAXSH },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vmaxuw, \"__builtin_altivec_vmaxuw\", ALTIVEC_BUILTIN_VMAXUW },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vmaxsw, \"__builtin_altivec_vmaxsw\", ALTIVEC_BUILTIN_VMAXSW },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vmaxfp, \"__builtin_altivec_vmaxfp\", ALTIVEC_BUILTIN_VMAXFP },\n+  { MASK_ALTIVEC, CODE_FOR_umaxv16qi3, \"__builtin_altivec_vmaxub\", ALTIVEC_BUILTIN_VMAXUB },\n+  { MASK_ALTIVEC, CODE_FOR_smaxv16qi3, \"__builtin_altivec_vmaxsb\", ALTIVEC_BUILTIN_VMAXSB },\n+  { MASK_ALTIVEC, CODE_FOR_uminv8hi3, \"__builtin_altivec_vmaxuh\", ALTIVEC_BUILTIN_VMAXUH },\n+  { MASK_ALTIVEC, CODE_FOR_sminv8hi3, \"__builtin_altivec_vmaxsh\", ALTIVEC_BUILTIN_VMAXSH },\n+  { MASK_ALTIVEC, CODE_FOR_uminv4si3, \"__builtin_altivec_vmaxuw\", ALTIVEC_BUILTIN_VMAXUW },\n+  { MASK_ALTIVEC, CODE_FOR_sminv4si3, \"__builtin_altivec_vmaxsw\", ALTIVEC_BUILTIN_VMAXSW },\n+  { MASK_ALTIVEC, CODE_FOR_sminv4sf3, \"__builtin_altivec_vmaxfp\", ALTIVEC_BUILTIN_VMAXFP },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmrghb, \"__builtin_altivec_vmrghb\", ALTIVEC_BUILTIN_VMRGHB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmrghh, \"__builtin_altivec_vmrghh\", ALTIVEC_BUILTIN_VMRGHH },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmrghw, \"__builtin_altivec_vmrghw\", ALTIVEC_BUILTIN_VMRGHW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmrglb, \"__builtin_altivec_vmrglb\", ALTIVEC_BUILTIN_VMRGLB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmrglh, \"__builtin_altivec_vmrglh\", ALTIVEC_BUILTIN_VMRGLH },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmrglw, \"__builtin_altivec_vmrglw\", ALTIVEC_BUILTIN_VMRGLW },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vminub, \"__builtin_altivec_vminub\", ALTIVEC_BUILTIN_VMINUB },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vminsb, \"__builtin_altivec_vminsb\", ALTIVEC_BUILTIN_VMINSB },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vminuh, \"__builtin_altivec_vminuh\", ALTIVEC_BUILTIN_VMINUH },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vminsh, \"__builtin_altivec_vminsh\", ALTIVEC_BUILTIN_VMINSH },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vminuw, \"__builtin_altivec_vminuw\", ALTIVEC_BUILTIN_VMINUW },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vminsw, \"__builtin_altivec_vminsw\", ALTIVEC_BUILTIN_VMINSW },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vminfp, \"__builtin_altivec_vminfp\", ALTIVEC_BUILTIN_VMINFP },\n+  { MASK_ALTIVEC, CODE_FOR_uminv16qi3, \"__builtin_altivec_vminub\", ALTIVEC_BUILTIN_VMINUB },\n+  { MASK_ALTIVEC, CODE_FOR_sminv16qi3, \"__builtin_altivec_vminsb\", ALTIVEC_BUILTIN_VMINSB },\n+  { MASK_ALTIVEC, CODE_FOR_uminv8hi3, \"__builtin_altivec_vminuh\", ALTIVEC_BUILTIN_VMINUH },\n+  { MASK_ALTIVEC, CODE_FOR_sminv8hi3, \"__builtin_altivec_vminsh\", ALTIVEC_BUILTIN_VMINSH },\n+  { MASK_ALTIVEC, CODE_FOR_uminv4si3, \"__builtin_altivec_vminuw\", ALTIVEC_BUILTIN_VMINUW },\n+  { MASK_ALTIVEC, CODE_FOR_sminv4si3, \"__builtin_altivec_vminsw\", ALTIVEC_BUILTIN_VMINSW },\n+  { MASK_ALTIVEC, CODE_FOR_sminv4sf3, \"__builtin_altivec_vminfp\", ALTIVEC_BUILTIN_VMINFP },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmuleub, \"__builtin_altivec_vmuleub\", ALTIVEC_BUILTIN_VMULEUB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmulesb, \"__builtin_altivec_vmulesb\", ALTIVEC_BUILTIN_VMULESB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmuleuh, \"__builtin_altivec_vmuleuh\", ALTIVEC_BUILTIN_VMULEUH },\n@@ -3037,7 +3037,7 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmulouh, \"__builtin_altivec_vmulouh\", ALTIVEC_BUILTIN_VMULOUH },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vmulosh, \"__builtin_altivec_vmulosh\", ALTIVEC_BUILTIN_VMULOSH },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vnor, \"__builtin_altivec_vnor\", ALTIVEC_BUILTIN_VNOR },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vor, \"__builtin_altivec_vor\", ALTIVEC_BUILTIN_VOR },\n+  { MASK_ALTIVEC, CODE_FOR_iorv4si3, \"__builtin_altivec_vor\", ALTIVEC_BUILTIN_VOR },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vpkuhum, \"__builtin_altivec_vpkuhum\", ALTIVEC_BUILTIN_VPKUHUM },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vpkuwum, \"__builtin_altivec_vpkuwum\", ALTIVEC_BUILTIN_VPKUWUM },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vpkpx, \"__builtin_altivec_vpkpx\", ALTIVEC_BUILTIN_VPKPX },\n@@ -3058,17 +3058,17 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsl, \"__builtin_altivec_vsl\", ALTIVEC_BUILTIN_VSL },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vslo, \"__builtin_altivec_vslo\", ALTIVEC_BUILTIN_VSLO },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsrb, \"__builtin_altivec_vsrb\", ALTIVEC_BUILTIN_VSRB },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vrsh, \"__builtin_altivec_vrsh\", ALTIVEC_BUILTIN_VRSH },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vrsw, \"__builtin_altivec_vrsw\", ALTIVEC_BUILTIN_VRSW },\n+  { MASK_ALTIVEC, CODE_FOR_altivec_vsrh, \"__builtin_altivec_vsrh\", ALTIVEC_BUILTIN_VSRH },\n+  { MASK_ALTIVEC, CODE_FOR_altivec_vsrw, \"__builtin_altivec_vsrw\", ALTIVEC_BUILTIN_VSRW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsrab, \"__builtin_altivec_vsrab\", ALTIVEC_BUILTIN_VSRAB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsrah, \"__builtin_altivec_vsrah\", ALTIVEC_BUILTIN_VSRAH },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsraw, \"__builtin_altivec_vsraw\", ALTIVEC_BUILTIN_VSRAW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsr, \"__builtin_altivec_vsr\", ALTIVEC_BUILTIN_VSR },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsro, \"__builtin_altivec_vsro\", ALTIVEC_BUILTIN_VSRO },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vsububm, \"__builtin_altivec_vsububm\", ALTIVEC_BUILTIN_VSUBUBM },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vsubuhm, \"__builtin_altivec_vsubuhm\", ALTIVEC_BUILTIN_VSUBUHM },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vsubuwm, \"__builtin_altivec_vsubuwm\", ALTIVEC_BUILTIN_VSUBUWM },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vsubfp, \"__builtin_altivec_vsubfp\", ALTIVEC_BUILTIN_VSUBFP },\n+  { MASK_ALTIVEC, CODE_FOR_subv16qi3, \"__builtin_altivec_vsububm\", ALTIVEC_BUILTIN_VSUBUBM },\n+  { MASK_ALTIVEC, CODE_FOR_subv8hi3, \"__builtin_altivec_vsubuhm\", ALTIVEC_BUILTIN_VSUBUHM },\n+  { MASK_ALTIVEC, CODE_FOR_subv4si3, \"__builtin_altivec_vsubuwm\", ALTIVEC_BUILTIN_VSUBUWM },\n+  { MASK_ALTIVEC, CODE_FOR_subv4sf3, \"__builtin_altivec_vsubfp\", ALTIVEC_BUILTIN_VSUBFP },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsubcuw, \"__builtin_altivec_vsubcuw\", ALTIVEC_BUILTIN_VSUBCUW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsububs, \"__builtin_altivec_vsububs\", ALTIVEC_BUILTIN_VSUBUBS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsubsbs, \"__builtin_altivec_vsubsbs\", ALTIVEC_BUILTIN_VSUBSBS },\n@@ -3081,7 +3081,7 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsum4shs, \"__builtin_altivec_vsum4shs\", ALTIVEC_BUILTIN_VSUM4SHS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsum2sws, \"__builtin_altivec_vsum2sws\", ALTIVEC_BUILTIN_VSUM2SWS },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsumsws, \"__builtin_altivec_vsumsws\", ALTIVEC_BUILTIN_VSUMSWS },\n-  { MASK_ALTIVEC, CODE_FOR_altivec_vxor, \"__builtin_altivec_vxor\", ALTIVEC_BUILTIN_VXOR },\n+  { MASK_ALTIVEC, CODE_FOR_xorv4si3, \"__builtin_altivec_vxor\", ALTIVEC_BUILTIN_VXOR },\n };\n \n static rtx\n@@ -3134,8 +3134,8 @@ altivec_expand_builtin (exp, target)\n   \n   switch (fcode)\n     {\n-    case ALTIVEC_BUILTIN_LD_INTERNAL:\n-      icode = CODE_FOR_altivec_lvx;\n+    case ALTIVEC_BUILTIN_LD_INTERNAL_16qi:\n+      icode = CODE_FOR_altivec_lvx_16qi;\n       arg0 = TREE_VALUE (arglist);\n       op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n       tmode = insn_data[icode].operand[0].mode;\n@@ -3154,9 +3154,126 @@ altivec_expand_builtin (exp, target)\n \treturn 0;\n       emit_insn (pat);\n       return target;\n+    case ALTIVEC_BUILTIN_LD_INTERNAL_8hi:\n+      icode = CODE_FOR_altivec_lvx_8hi;\n+      arg0 = TREE_VALUE (arglist);\n+      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n+      tmode = insn_data[icode].operand[0].mode;\n+      mode0 = insn_data[icode].operand[1].mode;\n \n-    case ALTIVEC_BUILTIN_ST_INTERNAL:\n-      icode = CODE_FOR_altivec_stvx;\n+      if (! target\n+\t  || GET_MODE (target) != tmode\n+\t  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n+\ttarget = gen_reg_rtx (tmode);\n+\n+      if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n+\top0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n+\n+      pat = GEN_FCN (icode) (target, op0);\n+      if (! pat)\n+\treturn 0;\n+      emit_insn (pat);\n+      return target;\n+    case ALTIVEC_BUILTIN_LD_INTERNAL_4si:\n+      icode = CODE_FOR_altivec_lvx_4si;\n+      arg0 = TREE_VALUE (arglist);\n+      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n+      tmode = insn_data[icode].operand[0].mode;\n+      mode0 = insn_data[icode].operand[1].mode;\n+\n+      if (! target\n+\t  || GET_MODE (target) != tmode\n+\t  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n+\ttarget = gen_reg_rtx (tmode);\n+\n+      if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n+\top0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n+\n+      pat = GEN_FCN (icode) (target, op0);\n+      if (! pat)\n+\treturn 0;\n+      emit_insn (pat);\n+      return target;\n+    case ALTIVEC_BUILTIN_LD_INTERNAL_4sf:\n+      icode = CODE_FOR_altivec_lvx_4sf;\n+      arg0 = TREE_VALUE (arglist);\n+      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n+      tmode = insn_data[icode].operand[0].mode;\n+      mode0 = insn_data[icode].operand[1].mode;\n+\n+      if (! target\n+\t  || GET_MODE (target) != tmode\n+\t  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n+\ttarget = gen_reg_rtx (tmode);\n+\n+      if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n+\top0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n+\n+      pat = GEN_FCN (icode) (target, op0);\n+      if (! pat)\n+\treturn 0;\n+      emit_insn (pat);\n+      return target;\n+\n+    case ALTIVEC_BUILTIN_ST_INTERNAL_16qi:\n+      icode = CODE_FOR_altivec_stvx_16qi;\n+      arg0 = TREE_VALUE (arglist);\n+      arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n+      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n+      op1 = expand_expr (arg1, NULL_RTX, VOIDmode, 0);\n+      mode0 = insn_data[icode].operand[0].mode;\n+      mode1 = insn_data[icode].operand[1].mode;\n+\n+      if (! (*insn_data[icode].operand[0].predicate) (op0, mode0))\n+\top0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n+      if (! (*insn_data[icode].operand[1].predicate) (op1, mode1))\n+\top1 = copy_to_mode_reg (mode1, op1);\n+\n+      pat = GEN_FCN (icode) (op0, op1);\n+      if (! pat)\n+\treturn 0;\n+      emit_insn (pat);\n+      return NULL_RTX;\n+    case ALTIVEC_BUILTIN_ST_INTERNAL_8hi:\n+      icode = CODE_FOR_altivec_stvx_8hi;\n+      arg0 = TREE_VALUE (arglist);\n+      arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n+      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n+      op1 = expand_expr (arg1, NULL_RTX, VOIDmode, 0);\n+      mode0 = insn_data[icode].operand[0].mode;\n+      mode1 = insn_data[icode].operand[1].mode;\n+\n+      if (! (*insn_data[icode].operand[0].predicate) (op0, mode0))\n+\top0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n+      if (! (*insn_data[icode].operand[1].predicate) (op1, mode1))\n+\top1 = copy_to_mode_reg (mode1, op1);\n+\n+      pat = GEN_FCN (icode) (op0, op1);\n+      if (! pat)\n+\treturn 0;\n+      emit_insn (pat);\n+      return NULL_RTX;\n+    case ALTIVEC_BUILTIN_ST_INTERNAL_4si:\n+      icode = CODE_FOR_altivec_stvx_4si;\n+      arg0 = TREE_VALUE (arglist);\n+      arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n+      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n+      op1 = expand_expr (arg1, NULL_RTX, VOIDmode, 0);\n+      mode0 = insn_data[icode].operand[0].mode;\n+      mode1 = insn_data[icode].operand[1].mode;\n+\n+      if (! (*insn_data[icode].operand[0].predicate) (op0, mode0))\n+\top0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n+      if (! (*insn_data[icode].operand[1].predicate) (op1, mode1))\n+\top1 = copy_to_mode_reg (mode1, op1);\n+\n+      pat = GEN_FCN (icode) (op0, op1);\n+      if (! pat)\n+\treturn 0;\n+      emit_insn (pat);\n+      return NULL_RTX;\n+    case ALTIVEC_BUILTIN_ST_INTERNAL_4sf:\n+      icode = CODE_FOR_altivec_stvx_4sf;\n       arg0 = TREE_VALUE (arglist);\n       arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n       op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n@@ -3223,18 +3340,51 @@ altivec_init_builtins (void)\n   tree endlink = void_list_node;\n \n   tree pint_type_node = build_pointer_type (integer_type_node);\n+  tree pshort_type_node = build_pointer_type (short_integer_type_node);\n+  tree pchar_type_node = build_pointer_type (char_type_node);\n+  tree pfloat_type_node = build_pointer_type (float_type_node);\n \n   /* V4SI foo (int *).  */\n   tree v4si_ftype_pint\n     = build_function_type (V4SI_type_node,\n \t\t\t   tree_cons (NULL_TREE, pint_type_node, endlink));\n+  /* V8HI foo (short *).  */\n+  tree v8hi_ftype_pshort\n+    = build_function_type (V8HI_type_node,\n+\t\t\t   tree_cons (NULL_TREE, pshort_type_node, endlink));\n+  /* V16QI foo (char *).  */\n+  tree v16qi_ftype_pchar\n+    = build_function_type (V16QI_type_node,\n+\t\t\t   tree_cons (NULL_TREE, pchar_type_node, endlink));\n+  /* V4SF foo (float *).  */\n+  tree v4sf_ftype_pfloat\n+    = build_function_type (V4SF_type_node,\n+\t\t\t   tree_cons (NULL_TREE, pfloat_type_node, endlink));\n \n   /* void foo (int *, V4SI).  */\n   tree void_ftype_pint_v4si\n     = build_function_type (void_type_node,\n \t\t\t   tree_cons (NULL_TREE, pint_type_node,\n \t\t\t\t      tree_cons (NULL_TREE, V4SI_type_node,\n \t\t\t\t\t\t endlink)));\n+  /* void foo (short *, V8HI).  */\n+  tree void_ftype_pshort_v8hi\n+    = build_function_type (void_type_node,\n+\t\t\t   tree_cons (NULL_TREE, pshort_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V8HI_type_node,\n+\t\t\t\t\t\t endlink)));\n+  /* void foo (char *, V16QI).  */\n+  tree void_ftype_pchar_v16qi\n+    = build_function_type (void_type_node,\n+\t\t\t   tree_cons (NULL_TREE, pchar_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V16QI_type_node,\n+\t\t\t\t\t\t endlink)));\n+  /* void foo (float *, V4SF).  */\n+  tree void_ftype_pfloat_v4sf\n+    = build_function_type (void_type_node,\n+\t\t\t   tree_cons (NULL_TREE, pfloat_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V4SF_type_node,\n+\t\t\t\t\t\t endlink)));\n \n   tree v4si_ftype_v4si_v4si\n     = build_function_type (V4SI_type_node,\n@@ -3326,8 +3476,14 @@ altivec_init_builtins (void)\n \t\t\t\t      tree_cons (NULL_TREE, V8HI_type_node,\n \t\t\t\t\t\t endlink)));\n \n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal\", v4si_ftype_pint, ALTIVEC_BUILTIN_LD_INTERNAL);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal\", void_ftype_pint_v4si, ALTIVEC_BUILTIN_ST_INTERNAL);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_4sf\", v4sf_ftype_pfloat, ALTIVEC_BUILTIN_LD_INTERNAL_4sf);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_4sf\", void_ftype_pfloat_v4sf, ALTIVEC_BUILTIN_ST_INTERNAL_4sf);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_4si\", v4si_ftype_pint, ALTIVEC_BUILTIN_LD_INTERNAL_4si);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_4si\", void_ftype_pint_v4si, ALTIVEC_BUILTIN_ST_INTERNAL_4si);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_8hi\", v8hi_ftype_pshort, ALTIVEC_BUILTIN_LD_INTERNAL_8hi);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_8hi\", void_ftype_pshort_v8hi, ALTIVEC_BUILTIN_ST_INTERNAL_8hi);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_16qi\", v16qi_ftype_pchar, ALTIVEC_BUILTIN_LD_INTERNAL_16qi);\n+  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_16qi\", void_ftype_pchar_v16qi, ALTIVEC_BUILTIN_ST_INTERNAL_16qi);\n \n   /* Add the simple binary operators.  */\n   d = (struct builtin_description *) bdesc_2arg;"}, {"sha": "e81069affb7d0d479017a3d750dc6b888cbde305", "filename": "gcc/config/rs6000/rs6000.h", "status": "modified", "additions": 14, "deletions": 6, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Frs6000.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Frs6000.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.h?ref=f18c054f039f8d5642a4bfb89db758f3abf3acfd", "patch": "@@ -76,6 +76,7 @@ Boston, MA 02111-1307, USA.  */\n %{mcpu=604e: -D_ARCH_PPC} \\\n %{mcpu=620: -D_ARCH_PPC} \\\n %{mcpu=740: -D_ARCH_PPC} \\\n+%{mcpu=7450: -D_ARCH_PPC} \\\n %{mcpu=750: -D_ARCH_PPC} \\\n %{mcpu=801: -D_ARCH_PPC} \\\n %{mcpu=821: -D_ARCH_PPC} \\\n@@ -113,6 +114,7 @@ Boston, MA 02111-1307, USA.  */\n %{mcpu=604e: -mppc} \\\n %{mcpu=620: -mppc} \\\n %{mcpu=740: -mppc} \\\n+%{mcpu=7450: -mppc} \\\n %{mcpu=750: -mppc} \\\n %{mcpu=801: -mppc} \\\n %{mcpu=821: -mppc} \\\n@@ -293,9 +295,9 @@ extern int target_flags;\n \t\t\tN_(\"Use PowerPC-64 instruction set\")},\t\t\\\n   {\"no-powerpc64\",\t- MASK_POWERPC64,\t\t\t\t\\\n \t\t\tN_(\"Don't use PowerPC-64 instruction set\")},\t\\\n-  {\"altivec\",\t\tMASK_ALTIVEC,\t\t\t\t\t\\\n+  {\"altivec\",\t\tMASK_ALTIVEC ,\t\t\t\t\t\\\n \t\t\tN_(\"Use AltiVec instructions.\")},\t\t\\\n-  {\"no-altivec\",\t- MASK_ALTIVEC,\t\t\t\t\t\\\n+  {\"no-altivec\",\t- MASK_ALTIVEC ,\t\t\t\t\t\\\n \t\t\tN_(\"Don't use AltiVec instructions.\")},\t\\\n   {\"new-mnemonics\",\tMASK_NEW_MNEMONICS,\t\t\t\t\\\n \t\t\tN_(\"Use new mnemonics for PowerPC architecture\")},\\\n@@ -2852,8 +2854,14 @@ extern int frame_pointer_needed;\n enum rs6000_builtins\n {\n   /* AltiVec builtins.  */\n-  ALTIVEC_BUILTIN_ST_INTERNAL,\n-  ALTIVEC_BUILTIN_LD_INTERNAL,\n+  ALTIVEC_BUILTIN_ST_INTERNAL_4si,\n+  ALTIVEC_BUILTIN_LD_INTERNAL_4si,\n+  ALTIVEC_BUILTIN_ST_INTERNAL_8hi,\n+  ALTIVEC_BUILTIN_LD_INTERNAL_8hi,\n+  ALTIVEC_BUILTIN_ST_INTERNAL_16qi,\n+  ALTIVEC_BUILTIN_LD_INTERNAL_16qi,\n+  ALTIVEC_BUILTIN_ST_INTERNAL_4sf,\n+  ALTIVEC_BUILTIN_LD_INTERNAL_4sf,\n   ALTIVEC_BUILTIN_VADDUBM,\n   ALTIVEC_BUILTIN_VADDUHM,\n   ALTIVEC_BUILTIN_VADDUWM,\n@@ -2936,8 +2944,8 @@ enum rs6000_builtins\n   ALTIVEC_BUILTIN_VSL,\n   ALTIVEC_BUILTIN_VSLO,\n   ALTIVEC_BUILTIN_VSRB,\n-  ALTIVEC_BUILTIN_VRSH,\n-  ALTIVEC_BUILTIN_VRSW,\n+  ALTIVEC_BUILTIN_VSRH,\n+  ALTIVEC_BUILTIN_VSRW,\n   ALTIVEC_BUILTIN_VSRAB,\n   ALTIVEC_BUILTIN_VSRAH,\n   ALTIVEC_BUILTIN_VSRAW,"}, {"sha": "a8a5a95a78f2135f988fd8b51b0ce0d21d75dc02", "filename": "gcc/config/rs6000/rs6000.md", "status": "modified", "additions": 256, "deletions": 194, "changes": 450, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Frs6000.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Frs6000.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.md?ref=f18c054f039f8d5642a4bfb89db758f3abf3acfd", "patch": "@@ -37,7 +37,7 @@\n \f\n ;; Define an insn type attribute.  This is used in function unit delay\n ;; computations.\n-(define_attr \"type\" \"integer,load,store,fpload,fpstore,imul,lmul,idiv,ldiv,branch,compare,cr_logical,delayed_compare,fpcompare,mtjmpr,fp,dmul,sdiv,ddiv,ssqrt,dsqrt,jmpreg,altivec\"\n+(define_attr \"type\" \"integer,load,store,fpload,fpstore,vecload,vecstore,imul,lmul,idiv,ldiv,branch,compare,cr_logical,delayed_compare,fpcompare,mtjmpr,fp,dmul,sdiv,ddiv,ssqrt,dsqrt,jmpreg,vecsimple,veccomplex,veccmp,vecperm,vecfloat,altivec\"\n   (const_string \"integer\"))\n \n ;; Length (in bytes).\n@@ -70,7 +70,7 @@\n   2 1)\n \n (define_function_unit \"lsu\" 1 0\n-  (and (eq_attr \"type\" \"load\")\n+  (and (eq_attr \"type\" \"load,vecload\")\n        (eq_attr \"cpu\" \"ppc7450\"))\n   3 1)\n \n@@ -85,7 +85,7 @@\n   2 1)\n \n (define_function_unit \"lsu\" 1 0\n-  (and (eq_attr \"type\" \"store\")\n+  (and (eq_attr \"type\" \"store,vecstore\")\n        (eq_attr \"cpu\" \"ppc7450\"))\n   3 1)\n \n@@ -317,6 +317,26 @@\n   (and (eq_attr \"type\" \"cr_logical\")\n        (eq_attr \"cpu\" \"ppc7450\"))\n   1 1)\n+(define_function_unit \"viu1\" 1 0\n+  (and (eq_attr \"type\" \"vecsimple\")\n+       (eq_attr \"cpu\" \"ppc7450\"))\n+  1 1)\n+(define_function_unit \"viu2\" 1 0\n+  (and (eq_attr \"type\" \"veccomplex\")\n+       (eq_attr \"cpu\" \"ppc7450\"))\n+  4 1)\n+(define_function_unit \"vfpu\" 1 0\n+  (and (eq_attr \"type\" \"veccmp\")\n+       (eq_attr \"cpu\" \"ppc7450\"))\n+  2 1)\n+(define_function_unit \"vfpu\" 1 0\n+  (and (eq_attr \"type\" \"vecfloat\")\n+       (eq_attr \"cpu\" \"ppc7450\"))\n+  4 1)\n+(define_function_unit \"vpu\" 1 0\n+  (and (eq_attr \"type\" \"vecperm\")\n+       (eq_attr \"cpu\" \"ppc7450\"))\n+  2 1)\n \n ; PPC750 has two integer units: a primary one which can perform all\n ; operations and a secondary one which is fed in lock step with the first\n@@ -13559,20 +13579,62 @@\n ;; AltiVec patterns\n \n ;; Generic LVX load instruction.\n-(define_insn \"altivec_lvx\"\n+(define_insn \"altivec_lvx_4si\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n \t(match_operand:V4SI 1 \"memory_operand\" \"m\"))]\n   \"TARGET_ALTIVEC\"\n   \"lvx %0,%y1\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecload\")])\n+\n+(define_insn \"altivec_lvx_8hi\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n+\t(match_operand:V8HI 1 \"memory_operand\" \"m\"))]\n+  \"TARGET_ALTIVEC\"\n+  \"lvx %0,%y1\"\n+  [(set_attr \"type\" \"vecload\")])\n+\n+(define_insn \"altivec_lvx_16qi\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n+\t(match_operand:V16QI 1 \"memory_operand\" \"m\"))]\n+  \"TARGET_ALTIVEC\"\n+  \"lvx %0,%y1\"\n+  [(set_attr \"type\" \"vecload\")])\n+\n+(define_insn \"altivec_lvx_4sf\"\n+  [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n+\t(match_operand:V4SF 1 \"memory_operand\" \"m\"))]\n+  \"TARGET_ALTIVEC\"\n+  \"lvx %0,%y1\"\n+  [(set_attr \"type\" \"vecload\")])\n \n ;; Generic STVX store instruction.\n-(define_insn \"altivec_stvx\"\n+(define_insn \"altivec_stvx_4si\"\n   [(set (match_operand:V4SI 0 \"memory_operand\" \"=m\")\n \t(match_operand:V4SI 1 \"register_operand\" \"v\"))]\n   \"TARGET_ALTIVEC\"\n   \"stvx %1,%y0\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecstore\")])\n+\n+(define_insn \"altivec_stvx_8hi\"\n+  [(set (match_operand:V8HI 0 \"memory_operand\" \"=m\")\n+\t(match_operand:V8HI 1 \"register_operand\" \"v\"))]\n+  \"TARGET_ALTIVEC\"\n+  \"stvx %1,%y0\"\n+  [(set_attr \"type\" \"vecstore\")])\n+\n+(define_insn \"altivec_stvx_16qi\"\n+  [(set (match_operand:V16QI 0 \"memory_operand\" \"=m\")\n+\t(match_operand:V16QI 1 \"register_operand\" \"v\"))]\n+  \"TARGET_ALTIVEC\"\n+  \"stvx %1,%y0\"\n+  [(set_attr \"type\" \"vecstore\")])\n+\n+(define_insn \"altivec_stvx_4sf\"\n+  [(set (match_operand:V4SF 0 \"memory_operand\" \"=m\")\n+\t(match_operand:V4SF 1 \"register_operand\" \"v\"))]\n+  \"TARGET_ALTIVEC\"\n+  \"stvx %1,%y0\"\n+  [(set_attr \"type\" \"vecstore\")])\n \n ;; Vector move instructions.\n (define_expand \"movv4si\"\n@@ -13666,850 +13728,850 @@\n \n ;; Simple binary operations.\n \n-(define_insn \"altivec_vaddubm\"\n+(define_insn \"addv16qi3\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 31))]\n+        (plus:V16QI (match_operand:V16QI 1 \"register_operand\" \"v\")\n+                    (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vaddubm %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vadduhm\"\n+(define_insn \"addv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] 32))]\n+        (plus:V8HI (match_operand:V8HI 1 \"register_operand\" \"v\")\n+                   (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vadduhm %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vadduwm\"\n+(define_insn \"addv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 33))]\n+        (plus:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                   (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vadduwm %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vaddfp\"\n+(define_insn \"addv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")] 34))]\n+        (plus:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n+\t \t   (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vaddfp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecfloat\")])\n \n (define_insn \"altivec_vaddcuw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 35))]\n   \"TARGET_ALTIVEC\"\n   \"vaddcuw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vaddubs\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 36))]\n   \"TARGET_ALTIVEC\"\n   \"vaddubs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vaddsbs\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 37))]\n   \"TARGET_ALTIVEC\"\n   \"vaddsbs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vadduhs\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 38))]\n   \"TARGET_ALTIVEC\"\n   \"vadduhs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vaddshs\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 39))]\n   \"TARGET_ALTIVEC\"\n   \"vaddshs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vadduws\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 40))]\n   \"TARGET_ALTIVEC\"\n   \"vadduws %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vaddsws\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 41))]\n   \"TARGET_ALTIVEC\"\n   \"vaddsws %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vand\"\n+(define_insn \"andv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 42))]\n+        (and:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                  (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vand %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vandc\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 43))]\n   \"TARGET_ALTIVEC\"\n   \"vandc %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vavgub\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 44))]\n   \"TARGET_ALTIVEC\"\n   \"vavgub %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vavgsb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 45))]\n   \"TARGET_ALTIVEC\"\n   \"vavgsb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vavguh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 46))]\n   \"TARGET_ALTIVEC\"\n   \"vavguh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vavgsh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 47))]\n   \"TARGET_ALTIVEC\"\n   \"vavgsh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vavguw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 48))]\n   \"TARGET_ALTIVEC\"\n   \"vavguw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vavgsw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 49))]\n   \"TARGET_ALTIVEC\"\n   \"vavgsw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpbfp\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"v\")\n                       (match_operand:V4SF 2 \"register_operand\" \"v\")] 50))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpbfp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccmp\")])\n \n (define_insn \"altivec_vcmpequb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 51))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpequb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpequh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 52))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpequh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpequw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 53))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpequw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpeqfp\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"v\")\n                       (match_operand:V4SF 2 \"register_operand\" \"v\")] 54))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpeqfp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccmp\")])\n \n (define_insn \"altivec_vcmpgefp\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"v\")\n                       (match_operand:V4SF 2 \"register_operand\" \"v\")] 55))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgefp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccmp\")])\n \n (define_insn \"altivec_vcmpgtub\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 56))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgtub %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpgtsb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 57))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgtsb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpgtuh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 58))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgtuh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpgtsh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 59))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgtsh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpgtuw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 60))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgtuw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpgtsw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 61))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgtsw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vcmpgtfp\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"v\")\n                       (match_operand:V4SF 2 \"register_operand\" \"v\")] 62))]\n   \"TARGET_ALTIVEC\"\n   \"vcmpgtfp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vmaxub\"\n+(define_insn \"umaxv16qi3\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 63))]\n+        (umax:V16QI (match_operand:V16QI 1 \"register_operand\" \"v\")\n+                    (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vmaxub %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vmaxsb\"\n+(define_insn \"smaxv16qi3\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 64))]\n+        (smax:V16QI (match_operand:V16QI 1 \"register_operand\" \"v\")\n+                    (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vmaxsb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vmaxuh\"\n+(define_insn \"umaxv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] 65))]\n+        (umax:V8HI (match_operand:V8HI 1 \"register_operand\" \"v\")\n+                   (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vmaxuh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vmaxsh\"\n+(define_insn \"smaxv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] 66))]\n+        (smax:V8HI (match_operand:V8HI 1 \"register_operand\" \"v\")\n+                   (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vmaxsh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vmaxuw\"\n+(define_insn \"umaxv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 67))]\n+        (umax:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                   (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vmaxuw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vmaxsw\"\n+(define_insn \"smaxv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 68))]\n+        (smax:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                   (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vmaxsw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vmaxfp\"\n+(define_insn \"smaxv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")] 69))]\n+        (smax:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n+                   (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vmaxfp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccmp\")])\n \n (define_insn \"altivec_vmrghb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 70))]\n   \"TARGET_ALTIVEC\"\n   \"vmrghb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vmrghh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 71))]\n   \"TARGET_ALTIVEC\"\n   \"vmrghh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vmrghw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 72))]\n   \"TARGET_ALTIVEC\"\n   \"vmrghw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vmrglb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 73))]\n   \"TARGET_ALTIVEC\"\n   \"vmrglb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vmrglh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 74))]\n   \"TARGET_ALTIVEC\"\n   \"vmrglh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vmrglw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 75))]\n   \"TARGET_ALTIVEC\"\n   \"vmrglw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"altivec_vminub\"\n+(define_insn \"uminv16qi3\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 76))]\n+        (umin:V16QI (match_operand:V16QI 1 \"register_operand\" \"v\")\n+                    (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vminub %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vminsb\"\n+(define_insn \"sminv16qi3\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 77))]\n+        (smin:V16QI (match_operand:V16QI 1 \"register_operand\" \"v\")\n+                    (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vminsb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vminuh\"\n+(define_insn \"uminv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] 78))]\n+        (umin:V8HI (match_operand:V8HI 1 \"register_operand\" \"v\")\n+                   (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vminuh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vminsh\"\n+(define_insn \"sminv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] 79))]\n+        (smin:V8HI (match_operand:V8HI 1 \"register_operand\" \"v\")\n+                   (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vminsh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vminuw\"\n+(define_insn \"uminv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 80))]\n+        (umin:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                   (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vminuw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vminsw\"\n+(define_insn \"sminv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 81))]\n+        (smin:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                   (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vminsw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vminfp\"\n+(define_insn \"sminv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")] 82))]\n+        (smin:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n+                   (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vminfp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccmp\")])\n \n (define_insn \"altivec_vmuleub\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 83))]\n   \"TARGET_ALTIVEC\"\n   \"vmuleub %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vmulesb\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 84))]\n   \"TARGET_ALTIVEC\"\n   \"vmulesb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vmuleuh\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 85))]\n   \"TARGET_ALTIVEC\"\n   \"vmuleuh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vmulesh\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 86))]\n   \"TARGET_ALTIVEC\"\n   \"vmulesh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vmuloub\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 87))]\n   \"TARGET_ALTIVEC\"\n   \"vmuloub %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vmulosb\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 88))]\n   \"TARGET_ALTIVEC\"\n   \"vmulosb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vmulouh\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 89))]\n   \"TARGET_ALTIVEC\"\n   \"vmulouh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vmulosh\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 90))]\n   \"TARGET_ALTIVEC\"\n   \"vmulosh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vnor\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 91))]\n+        (not:V4SI (ior:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                            (match_operand:V4SI 2 \"register_operand\" \"v\"))))]\n   \"TARGET_ALTIVEC\"\n   \"vnor %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vor\"\n+(define_insn \"iorv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 92))]\n+        (ior:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                  (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vor %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vpkuhum\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                        (match_operand:V8HI 2 \"register_operand\" \"v\")] 93))]\n   \"TARGET_ALTIVEC\"\n   \"vpkuhum %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkuwum\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 94))]\n   \"TARGET_ALTIVEC\"\n   \"vpkuwum %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkpx\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 95))]\n   \"TARGET_ALTIVEC\"\n   \"vpkpx %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkuhss\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                        (match_operand:V8HI 2 \"register_operand\" \"v\")] 96))]\n   \"TARGET_ALTIVEC\"\n   \"vpkuhss %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkshss\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                        (match_operand:V8HI 2 \"register_operand\" \"v\")] 97))]\n   \"TARGET_ALTIVEC\"\n   \"vpkshss %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkuwss\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 98))]\n   \"TARGET_ALTIVEC\"\n   \"vpkuwss %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkswss\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 99))]\n   \"TARGET_ALTIVEC\"\n   \"vpkswss %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkuhus\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                        (match_operand:V8HI 2 \"register_operand\" \"v\")] 100))]\n   \"TARGET_ALTIVEC\"\n   \"vpkuhus %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkshus\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                        (match_operand:V8HI 2 \"register_operand\" \"v\")] 101))]\n   \"TARGET_ALTIVEC\"\n   \"vpkshus %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkuwus\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 102))]\n   \"TARGET_ALTIVEC\"\n   \"vpkuwus %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vpkswus\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 103))]\n   \"TARGET_ALTIVEC\"\n   \"vpkswus %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vrlb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 104))]\n   \"TARGET_ALTIVEC\"\n   \"vrlb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vrlh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 105))]\n   \"TARGET_ALTIVEC\"\n   \"vrlh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vrlw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 106))]\n   \"TARGET_ALTIVEC\"\n   \"vrlw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vslb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 107))]\n   \"TARGET_ALTIVEC\"\n   \"vslb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vslh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 108))]\n   \"TARGET_ALTIVEC\"\n   \"vslh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vslw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 109))]\n   \"TARGET_ALTIVEC\"\n   \"vslw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsl\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 110))]\n   \"TARGET_ALTIVEC\"\n   \"vsl %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vslo\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 111))]\n   \"TARGET_ALTIVEC\"\n   \"vslo %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vsrb\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 112))]\n   \"TARGET_ALTIVEC\"\n   \"vsrb %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vrsh\"\n+(define_insn \"altivec_vsrh\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 113))]\n   \"TARGET_ALTIVEC\"\n-  \"vrsh %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  \"vsrh %0,%1,%2\"\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vrsw\"\n+(define_insn \"altivec_vsrw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 114))]\n   \"TARGET_ALTIVEC\"\n-  \"vrsw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  \"vsrw %0,%1,%2\"\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsrab\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 115))]\n   \"TARGET_ALTIVEC\"\n   \"vsrab %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsrah\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 116))]\n   \"TARGET_ALTIVEC\"\n   \"vsrah %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsraw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 117))]\n   \"TARGET_ALTIVEC\"\n   \"vsraw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsr\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 118))]\n   \"TARGET_ALTIVEC\"\n   \"vsr %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n (define_insn \"altivec_vsro\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 119))]\n   \"TARGET_ALTIVEC\"\n   \"vsro %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"altivec_vsububm\"\n+(define_insn \"subv16qi3\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] 120))]\n+        (minus:V16QI (match_operand:V16QI 1 \"register_operand\" \"v\")\n+                     (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vsububm %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vsubuhm\"\n+(define_insn \"subv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] 121))]\n+        (minus:V8HI (match_operand:V8HI 1 \"register_operand\" \"v\")\n+                    (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vsubuhm %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vsubuwm\"\n+(define_insn \"subv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 122))]\n+        (minus:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                    (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vsubuwm %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"altivec_vsubfp\"\n+(define_insn \"subv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")] 123))]\n+        (minus:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n+                    (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vsubfp %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecfloat\")])\n \n (define_insn \"altivec_vsubcuw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 124))]\n   \"TARGET_ALTIVEC\"\n   \"vsubcuw %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsububs\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 125))]\n   \"TARGET_ALTIVEC\"\n   \"vsububs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsubsbs\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n         (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                        (match_operand:V16QI 2 \"register_operand\" \"v\")] 126))]\n   \"TARGET_ALTIVEC\"\n   \"vsubsbs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsubuhs\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 127))]\n   \"TARGET_ALTIVEC\"\n   \"vsubuhs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsubshs\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n         (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V8HI 2 \"register_operand\" \"v\")] 128))]\n   \"TARGET_ALTIVEC\"\n   \"vsubshs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsubuws\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 129))]\n   \"TARGET_ALTIVEC\"\n   \"vsubuws %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsubsws\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 130))]\n   \"TARGET_ALTIVEC\"\n   \"vsubsws %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])\n \n (define_insn \"altivec_vsum4ubs\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 131))]\n   \"TARGET_ALTIVEC\"\n   \"vsum4ubs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vsum4sbs\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 132))]\n   \"TARGET_ALTIVEC\"\n   \"vsum4sbs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vsum4shs\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 133))]\n   \"TARGET_ALTIVEC\"\n   \"vsum4shs %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vsum2sws\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 134))]\n   \"TARGET_ALTIVEC\"\n   \"vsum2sws %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n (define_insn \"altivec_vsumsws\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n                       (match_operand:V4SI 2 \"register_operand\" \"v\")] 135))]\n   \"TARGET_ALTIVEC\"\n   \"vsumsws %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"veccomplex\")])\n \n-(define_insn \"altivec_vxor\"\n+(define_insn \"xorv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] 136))]\n+        (xor:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+                  (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vxor %0,%1,%2\"\n-  [(set_attr \"type\" \"altivec\")])\n+  [(set_attr \"type\" \"vecsimple\")])"}, {"sha": "91478c1faed0609e672659365506ed2084f0cc20", "filename": "gcc/config/rs6000/sysv4.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Fsysv4.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Fconfig%2Frs6000%2Fsysv4.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fsysv4.h?ref=f18c054f039f8d5642a4bfb89db758f3abf3acfd", "patch": "@@ -1316,6 +1316,7 @@ ncrtn.o%s\"\n %{mcpu=604e: -DCPU=PPC604} \\\n %{mcpu=620: -DCPU=PPC604} \\\n %{mcpu=740: -DCPU=PPC603} \\\n+%{mcpu=7450: -DCPU=PPC603} \\\n %{mcpu=750: -DCPU=PPC603} \\\n %{mcpu=801: -DCPU=PPC603} \\\n %{mcpu=821: -DCPU=PPC603} \\"}, {"sha": "8fd40869efd07fa50e4b7732c855d6cd18b3e041", "filename": "gcc/testsuite/gcc.dg/altivec-1.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Ftestsuite%2Fgcc.dg%2Faltivec-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f18c054f039f8d5642a4bfb89db758f3abf3acfd/gcc%2Ftestsuite%2Fgcc.dg%2Faltivec-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Faltivec-1.c?ref=f18c054f039f8d5642a4bfb89db758f3abf3acfd", "patch": "@@ -9,10 +9,10 @@\n    overloaded functions implemented in an <altivec.h>.  */\n \n #define vec_load(src) \\\n-  __builtin_altivec_ld_internal ((int *) src)\n+  __builtin_altivec_ld_internal_4si ((int *) src)\n \n #define vec_store(dst, src) \\\n-  __builtin_altivec_st_internal ((int *) dst, (int4) src)\n+  __builtin_altivec_st_internal_4si ((int *) dst, (int4) src)\n \n #define vec_add_int4(x, y) \\\n   __builtin_altivec_vaddsws (x, y)"}]}