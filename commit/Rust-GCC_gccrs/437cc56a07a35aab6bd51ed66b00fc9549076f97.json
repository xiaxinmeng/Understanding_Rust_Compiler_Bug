{"sha": "437cc56a07a35aab6bd51ed66b00fc9549076f97", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDM3Y2M1NmEwN2EzNWFhYjZiZDUxZWQ2NmIwMGZjOTU0OTA3NmY5Nw==", "commit": {"author": {"name": "Andrew Pinski", "email": "andrew_pinski@playstation.sony.com", "date": "2007-09-05T01:36:09Z"}, "committer": {"name": "Andrew Pinski", "email": "pinskia@gcc.gnu.org", "date": "2007-09-05T01:36:09Z"}, "message": "config.gcc (powerpc*-*-*): Install spu2vmx.h, vec_types.h, and si2vmx.h headers.\n\n2007-09-04  Andrew Pinski  <andrew_pinski@playstation.sony.com>\n\n        * config.gcc (powerpc*-*-*): Install\n        spu2vmx.h, vec_types.h, and si2vmx.h headers.\n        * config/rs6000/spu2vmx.h: New header.\n        * config/rs6000/si2vmx.h: New header.\n        * config/rs6000/vec_types.h: New header.\n2007-09-04  Andrew Pinski  <andrew_pinski@playstation.sony.com>\n\n        * g++.dg/other/spu2vmx-1.C: New test.\n\nFrom-SVN: r128118", "tree": {"sha": "f8004724c93c60a7e4e47d71053fef17976df904", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f8004724c93c60a7e4e47d71053fef17976df904"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/437cc56a07a35aab6bd51ed66b00fc9549076f97", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/437cc56a07a35aab6bd51ed66b00fc9549076f97", "html_url": "https://github.com/Rust-GCC/gccrs/commit/437cc56a07a35aab6bd51ed66b00fc9549076f97", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/437cc56a07a35aab6bd51ed66b00fc9549076f97/comments", "author": null, "committer": null, "parents": [{"sha": "ff539210fad1f87e5bd134b2b9a3b6b0dce93b5c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ff539210fad1f87e5bd134b2b9a3b6b0dce93b5c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ff539210fad1f87e5bd134b2b9a3b6b0dce93b5c"}], "stats": {"total": 4550, "additions": 4549, "deletions": 1}, "files": [{"sha": "c390cb5afd93a9daea2a4776ead9c8c7c1d6aa10", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=437cc56a07a35aab6bd51ed66b00fc9549076f97", "patch": "@@ -1,3 +1,11 @@\n+2007-09-04  Andrew Pinski  <andrew_pinski@playstation.sony.com>\n+\n+\t* config.gcc (powerpc*-*-*): Install\n+\tspu2vmx.h, vec_types.h, and si2vmx.h headers.\n+\t* config/rs6000/spu2vmx.h: New header.\n+\t* config/rs6000/si2vmx.h: New header.\n+\t* config/rs6000/vec_types.h: New header.\n+\n 2007-09-05  Ben Elliston  <bje@au.ibm.com>\n \n \t* varasm.c (initializer_constant_valid_p): Fix comment typo."}, {"sha": "75038951ddc84b9211622baed96ed034212d8806", "filename": "gcc/config.gcc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=437cc56a07a35aab6bd51ed66b00fc9549076f97", "patch": "@@ -312,7 +312,7 @@ mips*-*-*)\n \t;;\n powerpc*-*-*)\n \tcpu_type=rs6000\n-\textra_headers=\"ppc-asm.h altivec.h spe.h ppu_intrinsics.h paired.h\"\n+\textra_headers=\"ppc-asm.h altivec.h spe.h ppu_intrinsics.h paired.h spu2vmx.h vec_types.h si2vmx.h\"\n \tneed_64bit_hwint=yes\n \tcase x$with_cpu in\n \t    xpowerpc64|xdefault64|x6[23]0|x970|xG5|xpower[3456]|xpower6x|xrs64a)"}, {"sha": "2de3438707f4e97bb9fb92beb0486cbe6138cd6e", "filename": "gcc/config/rs6000/si2vmx.h", "status": "added", "additions": 2050, "deletions": 0, "changes": 2050, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig%2Frs6000%2Fsi2vmx.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig%2Frs6000%2Fsi2vmx.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fsi2vmx.h?ref=437cc56a07a35aab6bd51ed66b00fc9549076f97", "patch": "@@ -0,0 +1,2050 @@\n+/* Cell BEA specific SPU intrinsics to PPU/VMX intrinsics\n+   Copyright (C) 2007 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source files \n+   compiled by GCC, this header file does not by itself cause  the resulting \n+   executable to be covered by the GNU General Public License.  This exception \n+   does not however invalidate any other reasons why the executable file might be \n+   covered by the GNU General Public License.  */ \n+\n+#ifndef _SI2VMX_H_\n+#define _SI2VMX_H_\t1\n+\n+#ifndef __SPU__\n+\n+#include <stdlib.h>\n+#include <vec_types.h>\n+\n+\n+/* Specify a default halt action for spu_hcmpeq and spu_hcmpgt intrinsics.\n+ * Users can override the action by defining it prior to including this \n+ * header file.\n+ */\n+#ifndef SPU_HALT_ACTION\n+#define SPU_HALT_ACTION\t\tabort()\n+#endif\n+\n+/* Specify a default stop action for the spu_stop intrinsic.\n+ * Users can override the action by defining it prior to including this \n+ * header file.\n+ */\n+#ifndef SPU_STOP_ACTION\n+#define SPU_STOP_ACTION\t\tabort()\n+#endif\n+\n+\n+/* Specify a default action for unsupported intrinsic.\n+ * Users can override the action by defining it prior to including this \n+ * header file.\n+ */\n+#ifndef SPU_UNSUPPORTED_ACTION\n+#define SPU_UNSUPPORTED_ACTION\tabort()\n+#endif\n+\n+\n+/* Casting intrinsics - from scalar to quadword \n+ */\n+\n+static __inline qword si_from_uchar(unsigned char c) {\n+  union {\n+    qword q;\n+    unsigned char c[16];\n+  } x;\n+  x.c[3] = c;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_char(signed char c) {\n+  union {\n+    qword q;\n+    signed char c[16];\n+  } x;\n+  x.c[3] = c;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_ushort(unsigned short s) {\n+  union {\n+    qword q;\n+    unsigned short s[8];\n+  } x;\n+  x.s[1] = s;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_short(short s) {\n+  union {\n+    qword q;\n+    short s[8];\n+  } x;\n+  x.s[1] = s;\n+  return (x.q);\n+}\n+\n+\n+static __inline qword si_from_uint(unsigned int i) {\n+  union {\n+    qword q;\n+    unsigned int i[4];\n+  } x;\n+  x.i[0] = i;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_int(int i) {\n+  union {\n+    qword q;\n+    int i[4];\n+  } x;\n+  x.i[0] = i;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_ullong(unsigned long long l) {\n+  union {\n+    qword q;\n+    unsigned long long l[2];\n+  } x;\n+  x.l[0] = l;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_llong(long long l) {\n+  union {\n+    qword q;\n+    long long l[2];\n+  } x;\n+  x.l[0] = l;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_float(float f) {\n+  union {\n+    qword q;\n+    float f[4];\n+  } x;\n+  x.f[0] = f;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_double(double d) {\n+  union {\n+    qword q;\n+    double d[2];\n+  } x;\n+  x.d[0] = d;\n+  return (x.q);\n+}\n+\n+static __inline qword si_from_ptr(void *ptr) {\n+  union {\n+    qword q;\n+    void *p;\n+  } x;\n+  x.p = ptr;\n+  return (x.q);\n+}\n+\n+\n+/* Casting intrinsics - from quadword to scalar\n+ */\n+static __inline unsigned char si_to_uchar(qword q) {\n+  union {\n+    qword q;\n+    unsigned char c[16];\n+  } x;\n+  x.q = q;\n+  return (x.c[3]);\n+}\n+\n+static __inline signed char si_to_char(qword q) {\n+  union {\n+    qword q;\n+    signed char c[16];\n+  } x;\n+  x.q = q;\n+  return (x.c[3]);\n+}\n+\n+static __inline unsigned short si_to_ushort(qword q) {\n+  union {\n+    qword q;\n+    unsigned short s[8];\n+  } x;\n+  x.q = q;\n+  return (x.s[1]);\n+}\n+\n+static __inline short si_to_short(qword q) {\n+  union {\n+    qword q;\n+    short s[8];\n+  } x;\n+  x.q = q;\n+  return (x.s[1]);\n+}\n+\n+static __inline unsigned int si_to_uint(qword q) {\n+  union {\n+    qword q;\n+    unsigned int i[4];\n+  } x;\n+  x.q = q;\n+  return (x.i[0]);\n+}\n+\n+static __inline int si_to_int(qword q) {\n+  union {\n+    qword q;\n+    int i[4];\n+  } x;\n+  x.q = q;\n+  return (x.i[0]);\n+}\n+\n+static __inline unsigned long long si_to_ullong(qword q) {\n+  union {\n+    qword q;\n+    unsigned long long l[2];\n+  } x;\n+  x.q = q;\n+  return (x.l[0]);\n+}\n+\n+static __inline long long si_to_llong(qword q) {\n+  union {\n+    qword q;\n+    long long l[2];\n+  } x;\n+  x.q = q;\n+  return (x.l[0]);\n+}\n+\n+static __inline float si_to_float(qword q) {\n+  union {\n+    qword q;\n+    float f[4];\n+  } x;\n+  x.q = q;\n+  return (x.f[0]);\n+}\n+\n+static __inline double si_to_double(qword q) {\n+  union {\n+    qword q;\n+    double d[2];\n+  } x;\n+  x.q = q;\n+  return (x.d[0]);\n+}\n+\n+static __inline void * si_to_ptr(qword q) {\n+  union {\n+    qword q;\n+    void *p;\n+  } x;\n+  x.q = q;\n+  return (x.p);\n+}\n+\n+\n+/* Absolute difference\n+ */\n+static __inline qword si_absdb(qword a, qword b)\n+{\n+  vec_uchar16 ac, bc, dc;\n+\n+  ac = (vec_uchar16)(a);\n+  bc = (vec_uchar16)(b);\n+  dc = vec_sel(vec_sub(bc, ac), vec_sub(ac, bc), vec_cmpgt(ac, bc));\n+\n+  return ((qword)(dc));\n+}\n+\n+/* Add intrinsics \n+ */\n+#define si_a(_a, _b)\t\t((qword)(vec_add((vec_uint4)(_a), (vec_uint4)(_b))))\n+\n+#define si_ah(_a, _b)\t\t((qword)(vec_add((vec_ushort8)(_a), (vec_ushort8)(_b))))\n+\n+static __inline qword si_ai(qword a, int b)\n+{\n+  return ((qword)(vec_add((vec_int4)(a), \n+\t\t\t  vec_splat((vec_int4)(si_from_int(b)), 0))));\n+}\n+\n+\n+static __inline qword si_ahi(qword a, short b)\n+{\n+  return ((qword)(vec_add((vec_short8)(a), \n+\t\t\t  vec_splat((vec_short8)(si_from_short(b)), 1))));\n+}\n+\n+\n+#define si_fa(_a, _b)\t((qword)(vec_add((vec_float4)(_a), (vec_float4)(_b))))\n+\n+\n+static __inline qword si_dfa(qword a, qword b)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } ad, bd, dd;\n+\n+  ad.v = (vec_double2)(a);\n+  bd.v = (vec_double2)(b);\n+  dd.d[0] = ad.d[0] + bd.d[0];\n+  dd.d[1] = ad.d[1] + bd.d[1];\n+\n+  return ((qword)(dd.v));\n+}\n+\n+/* Add word extended\n+ */\n+#define si_addx(_a, _b, _c)\t((qword)(vec_add(vec_add((vec_uint4)(_a), (vec_uint4)(_b)), \t\\\n+\t\t\t\t\t\t vec_and((vec_uint4)(_c), vec_splat_u32(1)))))\n+\n+\n+/* Bit-wise AND\n+ */\n+#define si_and(_a, _b)\t\t((qword)(vec_and((vec_uint4)(_a), (vec_uint4)(_b))))\n+\n+\n+static __inline qword si_andbi(qword a, signed char b)\n+{\n+  return ((qword)(vec_and((vec_char16)(a), \n+\t\t\t  vec_splat((vec_char16)(si_from_char(b)), 3))));\n+}\n+\n+static __inline qword si_andhi(qword a, signed short b)\n+{\n+  return ((qword)(vec_and((vec_short8)(a), \n+\t\t\t  vec_splat((vec_short8)(si_from_short(b)), 1))));\n+}\n+\n+\n+static __inline qword si_andi(qword a, signed int b)\n+{\n+  return ((qword)(vec_and((vec_int4)(a),\n+\t\t\t  vec_splat((vec_int4)(si_from_int(b)), 0))));\n+}\n+\n+\n+/* Bit-wise AND with complement\n+ */\n+#define si_andc(_a, _b)\t\t((qword)(vec_andc((vec_uchar16)(_a), (vec_uchar16)(_b))))\n+\n+\n+/* Average byte vectors\n+ */\n+#define si_avgb(_a, _b)\t\t((qword)(vec_avg((vec_uchar16)(_a), (vec_uchar16)(_b))))\n+\n+\n+/* Branch indirect and set link on external data\n+ */\n+#define si_bisled(_func)\t/* not mappable */\n+#define si_bisledd(_func)\t/* not mappable */\n+#define si_bislede(_func)\t/* not mappable */\n+\n+\n+/* Borrow generate\n+ */\n+#define si_bg(_a, _b)\t\t((qword)(vec_subc((vec_uint4)(_b), (vec_uint4)(_a))))\n+\n+#define si_bgx(_a, _b, _c)\t((qword)(vec_and(vec_or(vec_cmpgt((vec_uint4)(_b), (vec_uint4)(_a)),\t\t\\\n+\t\t\t\t\t\t\tvec_and(vec_cmpeq((vec_uint4)(_b), (vec_uint4)(_a)), \t\\\n+\t\t\t\t\t\t\t\t(vec_uint4)(_c))), vec_splat_u32(1))))\n+\n+/* Compare absolute equal\n+ */\n+static __inline qword si_fcmeq(qword a, qword b)\n+{\n+  vec_float4 msb = (vec_float4)((vec_uint4){0x80000000, 0x80000000, 0x80000000, 0x80000000});\n+  \n+  return ((qword)(vec_cmpeq(vec_andc((vec_float4)(a), msb), \n+\t\t\t\t  vec_andc((vec_float4)(b), msb))));\n+}\n+\n+static __inline qword si_dfcmeq(qword a, qword b)\n+{\n+  vec_uint4 sign_mask= (vec_uint4) { 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF };\n+  vec_uint4 nan_mask = (vec_uint4) { 0x7FF00000, 0x00000000, 0x7FF00000, 0x00000000 };\n+  vec_uchar16 hihi_promote = (vec_uchar16) { 0,1,2,3,  16,17,18,19,  8,9,10,11, 24,25,26,27};\n+\n+  vec_uint4 biteq;\n+  vec_uint4 aabs;\n+  vec_uint4 babs;\n+  vec_uint4 a_gt;\n+  vec_uint4 ahi_inf;\n+  vec_uint4 anan;\n+  vec_uint4 result;\n+\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+\n+  /* Shift 4 bytes  */\n+  x.i[3] = 4 << 3;\n+\n+  /*  Mask out sign bits */\n+  aabs = vec_and((vec_uint4)a,sign_mask);\n+  babs = vec_and((vec_uint4)b,sign_mask);\n+\n+  /*  A)  Check for bit equality, store in high word */\n+  biteq = (vec_uint4) vec_cmpeq((vec_uint4)aabs,(vec_uint4)babs);\n+  biteq = vec_and(biteq,(vec_uint4)vec_slo((vec_uchar16)biteq,x.v));\n+\n+  /*  \n+      B)  Check if a is NaN, store in high word\n+        \n+      B1) If the high word is greater than max_exp (indicates a NaN)\n+      B2) If the low word is greater than 0 \n+  */\n+  a_gt = (vec_uint4)vec_cmpgt(aabs,nan_mask);\n+\n+  /*  B3) Check if the high word is equal to the inf exponent */\n+  ahi_inf = (vec_uint4)vec_cmpeq(aabs,nan_mask);\n+\n+  /*  anan = B1[hi] or (B2[lo] and B3[hi]) */\n+  anan = (vec_uint4)vec_or(a_gt,vec_and((vec_uint4)vec_slo((vec_uchar16)a_gt,x.v),ahi_inf));\n+\n+  /*  result = A and not B  */\n+  result = vec_andc(biteq, anan);\n+\n+  /*  Promote high words to 64 bits and return  */\n+  return ((qword)(vec_perm((vec_uchar16)result, (vec_uchar16)result, hihi_promote)));\n+}\n+\n+\n+/* Compare absolute greater than\n+ */\n+static __inline qword si_fcmgt(qword a, qword b)\n+{\n+  vec_float4 msb = (vec_float4)((vec_uint4){0x80000000, 0x80000000, 0x80000000, 0x80000000});\n+  \n+  return ((qword)(vec_cmpgt(vec_andc((vec_float4)(a), msb),\n+\t\t\t\t  vec_andc((vec_float4)(b), msb))));\n+}\n+\n+static __inline qword si_dfcmgt(qword a, qword b)\n+{\n+  vec_uchar16 splat_hi = (vec_uchar16) { 0,1,2,3, 0,1,2,3, 8,9,10,11, 8,9,10,11 };\n+  vec_uint4 nan_mask = (vec_uint4) { 0x7FF00000, 0x0, 0x7FF00000, 0x0 };\n+  vec_uint4 sign_mask = (vec_uint4) { 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF };\n+\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+\n+  /* Shift 4 bytes  */\n+  x.i[3] = 4 << 3;\n+\n+  // absolute value of a,b \n+  vec_uint4 aabs = vec_and((vec_uint4)a, sign_mask);\n+  vec_uint4 babs = vec_and((vec_uint4)b, sign_mask);\n+\n+  // check if a is nan\n+  vec_uint4 a_inf = (vec_uint4)vec_cmpeq(aabs, nan_mask);\n+  vec_uint4 a_nan = (vec_uint4)vec_cmpgt(aabs, nan_mask);\n+  a_nan = vec_or(a_nan, vec_and((vec_uint4)vec_slo((vec_uchar16)a_nan,x.v),a_inf));\n+  a_nan = (vec_uint4)vec_perm((vec_uchar16)a_nan, (vec_uchar16)a_nan, splat_hi);\n+\n+  // check if b is nan\n+  vec_uint4 b_inf = (vec_uint4)vec_cmpeq(babs, nan_mask);\n+  vec_uint4 b_nan = (vec_uint4)vec_cmpgt(babs, nan_mask);\n+  b_nan = vec_or(b_nan, vec_and((vec_uint4)vec_slo((vec_uchar16)b_nan,x.v),b_inf));\n+  b_nan = (vec_uint4)vec_perm((vec_uchar16)b_nan, (vec_uchar16)b_nan, splat_hi);\n+\n+  // A) Check if the exponents are different \n+  vec_uint4 gt_hi = (vec_uint4)vec_cmpgt(aabs,babs);\n+\n+  // B) Check if high word equal, and low word greater\n+  vec_uint4 gt_lo = (vec_uint4)vec_cmpgt((vec_uint4)aabs, (vec_uint4)babs);\n+  vec_uint4 eq = (vec_uint4)vec_cmpeq(aabs, babs);\n+  vec_uint4 eqgt = vec_and(eq,vec_slo(gt_lo,x.v));\n+\n+  //  If either A or B is true, return true (unless NaNs detected) \n+  vec_uint4 r = vec_or(gt_hi, eqgt);\n+\n+  // splat the high words of the comparison step\n+  r = (vec_uint4)vec_perm((vec_uchar16)r,(vec_uchar16)r,splat_hi);\n+\n+  // correct for NaNs in input\n+  return ((qword)vec_andc(r,vec_or(a_nan,b_nan)));\n+}\n+\n+\n+/* Compare equal\n+ */\n+static __inline qword si_ceqb(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpeq((vec_uchar16)(a), (vec_uchar16)(b))));\n+}\n+\n+static __inline qword si_ceqh(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpeq((vec_ushort8)(a), (vec_ushort8)(b))));\n+}\n+\n+static __inline qword si_ceq(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpeq((vec_uint4)(a), (vec_uint4)(b))));\n+}\n+\n+static __inline qword si_fceq(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpeq((vec_float4)(a), (vec_float4)(b))));\n+}\n+\n+static __inline qword si_ceqbi(qword a, signed char b)\n+{\n+  return ((qword)(vec_cmpeq((vec_char16)(a), \n+\t\t\t    vec_splat((vec_char16)(si_from_char(b)), 3))));\n+}\n+\n+static __inline qword si_ceqhi(qword a, signed short b)\n+{\n+  return ((qword)(vec_cmpeq((vec_short8)(a), \n+\t\t\t  vec_splat((vec_short8)(si_from_short(b)), 1))));\n+}\n+\n+static __inline qword si_ceqi(qword a, signed int b)\n+{\n+  return ((qword)(vec_cmpeq((vec_int4)(a), \n+\t\t\t  vec_splat((vec_int4)(si_from_int(b)), 0))));\n+}\n+\n+static __inline qword si_dfceq(qword a, qword b)\n+{\n+  vec_uint4 sign_mask= (vec_uint4) { 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF };\n+  vec_uint4 nan_mask = (vec_uint4) { 0x7FF00000, 0x00000000, 0x7FF00000, 0x00000000 };\n+  vec_uchar16 hihi_promote = (vec_uchar16) { 0,1,2,3,  16,17,18,19,  8,9,10,11, 24,25,26,27};\n+\n+  vec_uint4 biteq;\n+  vec_uint4 aabs;\n+  vec_uint4 babs;\n+  vec_uint4 a_gt;\n+  vec_uint4 ahi_inf;\n+  vec_uint4 anan;\n+  vec_uint4 iszero;\n+  vec_uint4 result;\n+\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+\n+  /* Shift 4 bytes  */\n+  x.i[3] = 4 << 3;\n+\n+  /*  A)  Check for bit equality, store in high word */\n+  biteq = (vec_uint4) vec_cmpeq((vec_uint4)a,(vec_uint4)b);\n+  biteq = vec_and(biteq,(vec_uint4)vec_slo((vec_uchar16)biteq,x.v));\n+\n+  /*  Mask out sign bits */\n+  aabs = vec_and((vec_uint4)a,sign_mask);\n+  babs = vec_and((vec_uint4)b,sign_mask);\n+\n+  /*  \n+      B)  Check if a is NaN, store in high word\n+        \n+      B1) If the high word is greater than max_exp (indicates a NaN)\n+      B2) If the low word is greater than 0 \n+  */\n+  a_gt = (vec_uint4)vec_cmpgt(aabs,nan_mask);\n+\n+  /*  B3) Check if the high word is equal to the inf exponent */\n+  ahi_inf = (vec_uint4)vec_cmpeq(aabs,nan_mask);\n+\n+  /*  anan = B1[hi] or (B2[lo] and B3[hi]) */\n+  anan = (vec_uint4)vec_or(a_gt,vec_and((vec_uint4)vec_slo((vec_uchar16)a_gt,x.v),ahi_inf));\n+\n+  /*  C)  Check for 0 = -0 special case */\n+  iszero =(vec_uint4)vec_cmpeq((vec_uint4)vec_or(aabs,babs),(vec_uint4)vec_splat_u32(0));\n+  iszero = vec_and(iszero,(vec_uint4)vec_slo((vec_uchar16)iszero,x.v));\n+\n+  /*  result = (A or C) and not B  */\n+  result = vec_or(biteq,iszero);\n+  result = vec_andc(result, anan);\n+\n+  /*  Promote high words to 64 bits and return  */\n+  return ((qword)(vec_perm((vec_uchar16)result, (vec_uchar16)result, hihi_promote))); \n+}\n+\n+\n+/* Compare greater than\n+ */\n+static __inline qword si_cgtb(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpgt((vec_char16)(a), (vec_char16)(b))));\n+}\n+\n+static __inline qword si_cgth(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpgt((vec_short8)(a), (vec_short8)(b))));\n+}\n+\n+static __inline qword si_cgt(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpgt((vec_int4)(a), (vec_int4)(b))));\n+}\n+\n+static __inline qword si_clgtb(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpgt((vec_uchar16)(a), (vec_uchar16)(b))));\n+}\n+\n+static __inline qword si_clgth(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpgt((vec_ushort8)(a), (vec_ushort8)(b))));\n+}\n+\n+static __inline qword si_clgt(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpgt((vec_uint4)(a), (vec_uint4)(b))));\n+}\n+\n+static __inline qword si_fcgt(qword a, qword b)\n+{\n+  return ((qword)(vec_cmpgt((vec_float4)(a), (vec_float4)(b))));\n+}\n+\n+static __inline qword si_dfcgt(qword a, qword b)\n+{\n+  vec_uchar16 splat_hi = (vec_uchar16) { 0,1,2,3, 0,1,2,3, 8,9,10,11, 8,9,10,11 };\n+  vec_uchar16 borrow_shuffle = (vec_uchar16) { 4,5,6,7, 192,192,192,192, 12,13,14,15, 192,192,192,192 };\n+  vec_uint4 nan_mask = (vec_uint4) { 0x7FF00000, 0x0, 0x7FF00000, 0x0 };\n+  vec_uint4 sign_mask = (vec_uint4) { 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF };\n+\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+\n+  /* Shift 4 bytes  */\n+  x.i[3] = 4 << 3;\n+\n+  // absolute value of a,b \n+  vec_uint4 aabs = vec_and((vec_uint4)a, sign_mask);\n+  vec_uint4 babs = vec_and((vec_uint4)b, sign_mask);\n+\n+  // check if a is nan\n+  vec_uint4 a_inf = (vec_uint4)vec_cmpeq(aabs, nan_mask);\n+  vec_uint4 a_nan = (vec_uint4)vec_cmpgt(aabs, nan_mask);\n+  a_nan = vec_or(a_nan, vec_and((vec_uint4)vec_slo((vec_uchar16)a_nan,x.v),a_inf));\n+  a_nan = (vec_uint4)vec_perm((vec_uchar16)a_nan, (vec_uchar16)a_nan, splat_hi);\n+\n+  // check if b is nan\n+  vec_uint4 b_inf = (vec_uint4)vec_cmpeq(babs, nan_mask);\n+  vec_uint4 b_nan = (vec_uint4)vec_cmpgt(babs, nan_mask);\n+  b_nan = vec_or(b_nan, vec_and((vec_uint4)vec_slo((vec_uchar16)b_nan,x.v),b_inf));\n+  b_nan = (vec_uint4)vec_perm((vec_uchar16)b_nan, (vec_uchar16)b_nan, splat_hi);\n+\n+  // sign of a\n+  vec_uint4 asel = (vec_uint4)vec_sra((vec_int4)(a), (vec_uint4)vec_splat(((vec_uint4)si_from_int(31)), 0));\n+  asel = (vec_uint4)vec_perm((vec_uchar16)asel,(vec_uchar16)asel,splat_hi);\n+\n+  // sign of b\n+  vec_uint4 bsel = (vec_uint4)vec_sra((vec_int4)(b), (vec_uint4)vec_splat(((vec_uint4)si_from_int(31)), 0));\n+  bsel = (vec_uint4)vec_perm((vec_uchar16)bsel,(vec_uchar16)bsel,splat_hi);\n+\n+  // negative a\n+  vec_uint4 abor = vec_subc((vec_uint4)vec_splat_u32(0), aabs);\n+  vec_uchar16 pat = vec_sel(((vec_uchar16){0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15}), vec_sr(borrow_shuffle, vec_splat_u8(3)), vec_sra(borrow_shuffle, vec_splat_u8(7)));\n+  abor = (vec_uint4)(vec_perm(vec_perm((vec_uchar16)abor, (vec_uchar16)abor, borrow_shuffle),((vec_uchar16){0, 0, 0, 0, 0, 0, 0, 0, 0xFF, 0xFF, 0xFF, 0xFF, 0x80, 0x80, 0x80, 0x80}),pat));\n+  vec_uint4 aneg = vec_add(vec_add(vec_splat_u32(0), vec_nor(aabs, aabs)), vec_and(abor, vec_splat_u32(1)));\n+\n+  // pick the one we want\n+  vec_int4 aval = (vec_int4)vec_sel((vec_uchar16)aabs, (vec_uchar16)aneg, (vec_uchar16)asel);\n+\n+  // negative b\n+  vec_uint4 bbor = vec_subc((vec_uint4)vec_splat_u32(0), babs);\n+  bbor = (vec_uint4)(vec_perm(vec_perm((vec_uchar16)bbor, (vec_uchar16)bbor, borrow_shuffle),((vec_uchar16){0, 0, 0, 0, 0, 0, 0, 0, 0xFF, 0xFF, 0xFF, 0xFF, 0x80, 0x80, 0x80, 0x80}),pat));\n+  vec_uint4 bneg = vec_add(vec_nor(babs, babs), vec_and(bbor, vec_splat_u32(1)));\n+\n+  // pick the one we want\n+  vec_int4 bval=(vec_int4)vec_sel((vec_uchar16)babs, (vec_uchar16)bneg, (vec_uchar16)bsel);\n+\n+  // A) Check if the exponents are different \n+  vec_uint4 gt_hi = (vec_uint4)vec_cmpgt(aval,bval);\n+\n+  // B) Check if high word equal, and low word greater\n+  vec_uint4 gt_lo = (vec_uint4)vec_cmpgt((vec_uint4)aval, (vec_uint4)bval);\n+  vec_uint4 eq = (vec_uint4)vec_cmpeq(aval, bval);\n+  vec_uint4 eqgt = vec_and(eq,vec_slo(gt_lo,x.v));\n+\n+  //  If either A or B is true, return true (unless NaNs detected) \n+  vec_uint4 r = vec_or(gt_hi, eqgt);\n+\n+  // splat the high words of the comparison step\n+  r = (vec_uint4)vec_perm((vec_uchar16)r,(vec_uchar16)r,splat_hi);\n+\n+  // correct for NaNs in input\n+  return ((qword)vec_andc(r,vec_or(a_nan,b_nan)));\n+}\n+\n+static __inline qword si_cgtbi(qword a, signed char b)\n+{\n+  return ((qword)(vec_cmpgt((vec_char16)(a), \n+\t\t\t    vec_splat((vec_char16)(si_from_char(b)), 3))));\n+}\n+\n+static __inline qword si_cgthi(qword a, signed short b)\n+{\n+  return ((qword)(vec_cmpgt((vec_short8)(a), \n+\t\t\t    vec_splat((vec_short8)(si_from_short(b)), 1))));\n+}\n+\n+static __inline qword si_cgti(qword a, signed int b)\n+{\n+  return ((qword)(vec_cmpgt((vec_int4)(a), \n+\t\t\t    vec_splat((vec_int4)(si_from_int(b)), 0))));\n+}\n+\n+static __inline qword si_clgtbi(qword a, unsigned char b)\n+{\n+  return ((qword)(vec_cmpgt((vec_uchar16)(a), \n+\t\t\t    vec_splat((vec_uchar16)(si_from_uchar(b)), 3))));\n+}\n+\n+static __inline qword si_clgthi(qword a, unsigned short b)\n+{\n+  return ((qword)(vec_cmpgt((vec_ushort8)(a),\n+\t\t\t    vec_splat((vec_ushort8)(si_from_ushort(b)), 1))));\n+}\n+\n+static __inline qword si_clgti(qword a, unsigned int b)\n+{\n+  return ((qword)(vec_cmpgt((vec_uint4)(a), \n+\t\t\t    vec_splat((vec_uint4)(si_from_uint(b)), 0))));\n+}\n+\n+static __inline qword si_dftsv(qword a, char b)\n+{\n+  vec_uchar16 splat_hi = (vec_uchar16) { 0,1,2,3, 0,1,2,3, 8,9,10,11, 8,9,10,11 };\n+  vec_uint4 sign_mask = (vec_uint4) { 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF };\n+  vec_uint4 result = (vec_uint4){0};\n+  vec_uint4 sign = (vec_uint4)vec_sra((vec_int4)(a), (vec_uint4)vec_splat(((vec_uint4)si_from_int(31)), 0));\n+  sign = (vec_uint4)vec_perm((vec_uchar16)sign,(vec_uchar16)sign,splat_hi);\n+  vec_uint4 aabs = vec_and((vec_uint4)a,sign_mask);\n+  \n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+\n+  /* Shift 4 bytes  */\n+  x.i[3] = 4 << 3;\n+  \n+  /* Nan or +inf or -inf  */\n+  if (b & 0x70)\n+  {\n+    vec_uint4 nan_mask = (vec_uint4) { 0x7FF00000, 0x0, 0x7FF00000, 0x0 };\n+    vec_uint4 a_inf = (vec_uint4)vec_cmpeq(aabs, nan_mask);\n+     /* NaN  */\n+     if (b & 0x40)\n+     {\n+       vec_uint4 a_nan = (vec_uint4)vec_cmpgt(aabs, nan_mask);\n+       a_nan = vec_or(a_nan, vec_and((vec_uint4)vec_slo((vec_uchar16)a_nan,x.v),a_inf));\n+       a_nan = (vec_uint4)vec_perm((vec_uchar16)a_nan, (vec_uchar16)a_nan, splat_hi); \n+       result = vec_or(result, a_nan);\n+     }\n+     /* inf  */ \n+     if (b & 0x30)\n+     {\n+       a_inf = vec_and((vec_uint4)vec_slo((vec_uchar16)a_inf,x.v), a_inf);\n+       a_inf = (vec_uint4)vec_perm((vec_uchar16)a_inf, (vec_uchar16)a_inf, splat_hi); \n+        /* +inf  */\n+        if (b & 0x20)\n+          result = vec_or(vec_andc(a_inf, sign), result);\n+        /* -inf  */\n+        if (b & 0x10)\n+          result = vec_or(vec_and(a_inf, sign), result);\n+     } \n+  }\n+  /* 0 or denorm  */\n+  if (b & 0xF)\n+  {\n+    vec_uint4 iszero =(vec_uint4)vec_cmpeq(aabs,(vec_uint4)vec_splat_u32(0));\n+    iszero = vec_and(iszero,(vec_uint4)vec_slo((vec_uchar16)iszero,x.v));\n+    /* denorm  */\n+    if (b & 0x3)\n+    {\n+      vec_uint4 denorm_mask = (vec_uint4){0xFFFFF, 0xFFFFF, 0xFFFFF, 0xFFFFF};\n+      vec_uint4 isdenorm = vec_nor((vec_uint4)vec_cmpgt(aabs, denorm_mask), iszero);\n+      isdenorm = (vec_uint4)vec_perm((vec_uchar16)isdenorm, (vec_uchar16)isdenorm, splat_hi);\n+      /* +denorm  */\n+     if (b & 0x2)\n+        result = vec_or(vec_andc(isdenorm, sign), result);\n+      /* -denorm  */\n+     if (b & 0x1)\n+        result = vec_or(vec_and(isdenorm, sign), result);\n+    }\n+    /* 0  */\n+    if (b & 0xC)\n+    {\n+      iszero = (vec_uint4)vec_perm((vec_uchar16)iszero, (vec_uchar16)iszero, splat_hi);\n+      /* +0  */\n+     if (b & 0x8)\n+        result = vec_or(vec_andc(iszero, sign), result);\n+      /* -0  */\n+     if (b & 0x4)\n+        result = vec_or(vec_and(iszero, sign), result);\n+    }\n+  }\n+  return ((qword)result);\n+}\n+\n+\n+/* Carry generate\n+ */\n+#define si_cg(_a, _b)\t\t((qword)(vec_addc((vec_uint4)(_a), (vec_uint4)(_b))))\n+\n+#define si_cgx(_a, _b, _c)\t((qword)(vec_or(vec_addc((vec_uint4)(_a), (vec_uint4)(_b)), \t\t\\\n+\t\t\t\t\t\tvec_addc(vec_add((vec_uint4)(_a), (vec_uint4)(_b)),\t\\\n+\t\t\t\t\t\t\t vec_and((vec_uint4)(_c), vec_splat_u32(1))))))\n+\n+\n+/* Count ones for bytes\n+ */\n+static __inline qword si_cntb(qword a)\n+{\n+  vec_uchar16 nib_cnt = (vec_uchar16){0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};\n+  vec_uchar16 four = { 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 };\n+  vec_uchar16 av;\n+\n+  av = (vec_uchar16)(a);\n+\n+  return ((qword)(vec_add(vec_perm(nib_cnt, nib_cnt, av),\n+\t\t\t  vec_perm(nib_cnt, nib_cnt, vec_sr (av, four)))));\n+}\n+\n+/* Count ones for bytes\n+ */\n+static __inline qword si_clz(qword a)\n+{\n+  vec_uchar16 av;\n+  vec_uchar16 cnt_hi, cnt_lo, cnt, tmp1, tmp2, tmp3;\n+  vec_uchar16 four    = vec_splat_u8(4);\n+  vec_uchar16 nib_cnt = (vec_uchar16){4, 3, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0};\n+  vec_uchar16 eight   = vec_splat_u8(8);\n+  vec_uchar16 sixteen = (vec_uchar16){16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16};\n+  vec_uchar16 twentyfour = (vec_uchar16){24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24};\n+\n+  av = (vec_uchar16)(a);\n+\n+  cnt_hi = vec_perm(nib_cnt, nib_cnt, vec_sr(av, four));\n+  cnt_lo = vec_perm(nib_cnt, nib_cnt, av);\n+\n+  cnt = vec_add(cnt_hi, vec_and(cnt_lo, vec_cmpeq(cnt_hi, four)));\n+\n+  tmp1 = (vec_uchar16)vec_sl((vec_uint4)(cnt), (vec_uint4)(eight));\n+  tmp2 = (vec_uchar16)vec_sl((vec_uint4)(cnt), (vec_uint4)(sixteen));\n+  tmp3 = (vec_uchar16)vec_sl((vec_uint4)(cnt), (vec_uint4)(twentyfour));\n+\n+  cnt = vec_add(cnt, vec_and(tmp1, vec_cmpeq(cnt, eight)));\n+  cnt = vec_add(cnt, vec_and(tmp2, vec_cmpeq(cnt, sixteen)));\n+  cnt = vec_add(cnt, vec_and(tmp3, vec_cmpeq(cnt, twentyfour)));\n+  \n+  return (qword)((vec_sr((vec_uint4)(cnt), (vec_uint4)(twentyfour))));\n+}\n+\n+/* Convert to float\n+ */\n+#define si_cuflt(_a, _b)\t((qword)(vec_ctf((vec_uint4)(_a), _b)))\n+#define si_csflt(_a, _b)\t((qword)(vec_ctf((vec_int4)(_a), _b)))\n+\n+/* Convert to signed int\n+ */\n+#define si_cflts(_a, _b)\t((qword)(vec_cts((vec_float4)(_a), _b)))\n+\n+/* Convert to unsigned int\n+ */\n+#define si_cfltu(_a, _b)\t((qword)(vec_ctu((vec_float4)(_a), _b)))\n+\n+/* Synchronize\n+ */\n+#define si_dsync()\t\t/* do nothing */\n+#define si_sync()\t\t/* do nothing */\n+#define si_syncc()\t\t/* do nothing */\n+\n+\n+/* Equivalence\n+ */\n+static __inline qword si_eqv(qword a, qword b)\n+{\n+  vec_uchar16 d;\n+\n+  d = vec_xor((vec_uchar16)(a), (vec_uchar16)(b));\n+  return ((qword)(vec_nor(d, d)));\n+}\n+\n+/* Extend\n+ */\n+static __inline qword si_xsbh(qword a)\n+{\n+  vec_char16 av;\n+\n+  av = (vec_char16)(a);\n+  return ((qword)(vec_unpackh(vec_perm(av, av, ((vec_uchar16){1, 3, 5, 7, 9,11,13,15, \n+\t\t\t\t\t\t              0, 0, 0, 0, 0, 0, 0, 0})))));\n+}\n+\n+static __inline qword si_xshw(qword a)\n+{\n+  vec_short8 av;\n+\n+  av = (vec_short8)(a);\n+  return ((qword)(vec_unpackh(vec_perm(av, av, ((vec_uchar16){2, 3, 6, 7, \n+\t\t\t\t\t                      10,11,14,15,\n+\t\t\t\t\t\t\t      0, 0, 0, 0, \n+\t\t\t\t\t\t              0, 0, 0, 0})))));\n+}\n+\n+static __inline qword si_xswd(qword a)\n+{\n+  vec_int4 av;\n+\n+  av = (vec_int4)(a);\n+  return ((qword)(vec_perm(av, vec_sra(av, ((vec_uint4){31,31,31,31})), \n+\t\t\t   ((vec_uchar16){20, 21, 22, 23,  \n+\t\t\t\t\t   4,  5,  6,  7, \n+\t\t\t\t          28, 29, 30, 31, \n+\t\t\t\t          12, 13, 14, 15}))));\n+}\n+\n+static __inline qword si_fesd(qword a)\n+{\n+  union {\n+    double d[2];\n+    vec_double2\tvd;\n+  } out;\n+  union {\n+    float f[4];\n+    vec_float4 vf;\n+  } in;\n+\n+  in.vf = (vec_float4)(a);\n+  out.d[0] = (double)(in.f[0]);\n+  out.d[1] = (double)(in.f[2]);\n+  return ((qword)(out.vd));\n+}\n+\n+/* Gather\n+ */\n+static __inline qword si_gbb(qword a)\n+{\n+  vec_uchar16 bits;\n+  vec_uint4   bytes;\n+\n+  bits  = vec_sl(vec_and((vec_uchar16)(a), vec_splat_u8(1)), ((vec_uchar16){7, 6, 5, 4, 3, 2, 1, 0,\n+\t\t\t\t\t\t\t\t            7, 6, 5, 4, 3, 2, 1, 0}));\n+  bytes = (vec_uint4)vec_sum2s((vec_int4)(vec_sum4s(bits, ((vec_uint4){0}))), ((vec_int4){0}));\n+\n+  return ((qword)(vec_perm(bytes, bytes, ((vec_uchar16){0, 0, 7,15, 0, 0, 0, 0,\n+\t\t\t\t\t                0, 0, 0, 0, 0, 0, 0, 0}))));\n+}\n+\n+\n+static __inline qword si_gbh(qword a)\n+{\n+  vec_ushort8 bits;\n+  vec_uint4   bytes;\n+\n+  bits  = vec_sl(vec_and((vec_ushort8)(a), vec_splat_u16(1)), ((vec_ushort8){7, 6, 5, 4, 3, 2, 1, 0}));\n+\n+  bytes = (vec_uint4)vec_sums((vec_int4)(vec_sum4s((vec_short8)(bits), (vec_int4){0})), (vec_int4){0});\n+\n+  return ((qword)(vec_sld(bytes, bytes, 12)));\n+}\n+\n+static __inline qword si_gb(qword a)\n+{\n+  vec_uint4 bits;\n+  vec_uint4 bytes;\n+\n+  bits  = vec_sl(vec_and((vec_uint4)(a), vec_splat_u32(1)), ((vec_uint4){3, 2, 1, 0}));\n+  bytes = (vec_uint4)vec_sums((vec_int4)(bits), ((vec_int4){0}));\n+  return ((qword)(vec_sld(bytes, bytes, 12)));\n+}\n+\n+\n+/* Compare and halt \n+ */\n+static __inline void si_heq(qword a, qword b)\n+{\n+  union {\n+    vector unsigned int v;\n+    unsigned int i[4];\n+  } aa, bb;\n+\n+  aa.v = (vector unsigned int)(a);\n+  bb.v = (vector unsigned int)(b);\n+\n+  if (aa.i[0] == bb.i[0]) { SPU_HALT_ACTION; };\n+}\n+\n+static __inline void si_heqi(qword a, unsigned int b)\n+{\n+  union {\n+    vector unsigned int v;\n+    unsigned int i[4];\n+  } aa;\n+\n+  aa.v = (vector unsigned int)(a);\n+\n+  if (aa.i[0] == b) { SPU_HALT_ACTION; };\n+}\n+\n+static __inline void si_hgt(qword a, qword b)\n+{\n+  union {\n+    vector signed int v;\n+    signed int i[4];\n+  } aa, bb;\n+\n+  aa.v = (vector signed int)(a);\n+  bb.v = (vector signed int)(b);\n+\n+  if (aa.i[0] > bb.i[0]) { SPU_HALT_ACTION; };\n+}\n+\n+static __inline void si_hgti(qword a, signed int b)\n+{\n+  union {\n+    vector signed int v;\n+    signed int i[4];\n+  } aa;\n+\n+  aa.v = (vector signed int)(a);\n+\n+  if (aa.i[0] > b) { SPU_HALT_ACTION; };\n+}\n+\n+static __inline void si_hlgt(qword a, qword b)\n+{\n+  union {\n+    vector unsigned int v;\n+    unsigned int i[4];\n+  } aa, bb;\n+\n+  aa.v = (vector unsigned int)(a);\n+  bb.v = (vector unsigned int)(b);\n+\n+  if (aa.i[0] > bb.i[0]) { SPU_HALT_ACTION; };\n+}\n+\n+static __inline void si_hlgti(qword a, unsigned int b)\n+{\n+  union {\n+    vector unsigned int v;\n+    unsigned int i[4];\n+  } aa;\n+\n+  aa.v = (vector unsigned int)(a);\n+\n+  if (aa.i[0] > b) { SPU_HALT_ACTION; };\n+}\n+\n+\n+/* Multiply and Add\n+ */\n+static __inline qword si_mpya(qword a, qword b, qword c)\n+{\n+  return ((qword)(vec_msum(vec_and((vec_short8)(a), \n+\t\t\t\t   ((vec_short8){0, -1, 0, -1, 0, -1, 0, -1})), \n+\t\t\t   (vec_short8)(b), (vec_int4)(c))));\n+}\n+\n+static __inline qword si_fma(qword a, qword b, qword c)\n+{\n+  return ((qword)(vec_madd((vec_float4)(a), (vec_float4)(b), (vec_float4)(c))));\n+}\n+\n+static __inline qword si_dfma(qword a, qword b, qword c)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } aa, bb, cc, dd;\n+\n+  aa.v = (vec_double2)(a);\n+  bb.v = (vec_double2)(b);\n+  cc.v = (vec_double2)(c);\n+  dd.d[0] = aa.d[0] * bb.d[0] + cc.d[0];\n+  dd.d[1] = aa.d[1] * bb.d[1] + cc.d[1];\n+  return ((qword)(dd.v));\n+}\n+\n+/* Form Mask\n+ */\n+#define si_fsmbi(_a)\tsi_fsmb(si_from_int(_a))\n+\n+static __inline qword si_fsmb(qword a)\n+{\n+  vec_char16 mask;\n+  vec_ushort8 in;\n+\n+  in = (vec_ushort8)(a);\n+  mask = (vec_char16)(vec_perm(in, in, ((vec_uchar16){2, 2, 2, 2, 2, 2, 2, 2,\n+\t\t\t\t\t              3, 3, 3, 3, 3, 3, 3, 3})));\n+  return ((qword)(vec_sra(vec_sl(mask, ((vec_uchar16){0, 1, 2, 3, 4, 5, 6, 7,\n+\t\t\t\t                      0, 1, 2, 3, 4, 5, 6, 7})),\n+\t\t\t  vec_splat_u8(7))));\n+}\n+\n+\n+static __inline qword si_fsmh(qword a)\n+{\n+  vec_uchar16 in;\n+  vec_short8 mask;\n+\n+  in = (vec_uchar16)(a);\n+  mask = (vec_short8)(vec_splat(in, 3));\n+  return ((qword)(vec_sra(vec_sl(mask, ((vec_ushort8){0, 1, 2, 3, 4, 5, 6, 7})), \n+\t\t\t  vec_splat_u16(15))));\n+}\n+\n+static __inline qword si_fsm(qword a)\n+{\n+  vec_uchar16 in;\n+  vec_int4 mask;\n+\n+  in = (vec_uchar16)(a);\n+  mask = (vec_int4)(vec_splat(in, 3));\n+  return ((qword)(vec_sra(vec_sl(mask, ((vec_uint4){28, 29, 30, 31})),\n+\t\t\t  ((vec_uint4){31,31,31,31}))));\n+}\n+\n+/* Move from/to registers\n+ */\n+#define si_fscrrd()\t\t((qword)((vec_uint4){0}))\n+#define si_fscrwr(_a)\n+\n+#define si_mfspr(_reg)\t\t((qword)((vec_uint4){0}))\n+#define si_mtspr(_reg, _a)\n+\n+/* Multiply High High Add\n+ */\n+static __inline qword si_mpyhha(qword a, qword b, qword c)\n+{\n+  return ((qword)(vec_add(vec_mule((vec_short8)(a), (vec_short8)(b)), (vec_int4)(c))));\n+}\n+\n+static __inline qword si_mpyhhau(qword a, qword b, qword c)\n+{\n+  return ((qword)(vec_add(vec_mule((vec_ushort8)(a), (vec_ushort8)(b)), (vec_uint4)(c))));\n+}\n+\n+/* Multiply Subtract\n+ */\n+static __inline qword si_fms(qword a, qword b, qword c)\n+{\n+  return ((qword)(vec_madd((vec_float4)(a), (vec_float4)(b), \n+\t\t\t   vec_sub(((vec_float4){0.0f}), (vec_float4)(c)))));\n+}\n+\n+static __inline qword si_dfms(qword a, qword b, qword c)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } aa, bb, cc, dd;\n+\n+  aa.v = (vec_double2)(a);\n+  bb.v = (vec_double2)(b);\n+  cc.v = (vec_double2)(c);\n+  dd.d[0] = aa.d[0] * bb.d[0] - cc.d[0];\n+  dd.d[1] = aa.d[1] * bb.d[1] - cc.d[1];\n+  return ((qword)(dd.v));\n+}\n+\n+/* Multiply\n+ */\n+static __inline qword si_fm(qword a, qword b)\n+{\n+  return ((qword)(vec_madd((vec_float4)(a), (vec_float4)(b), ((vec_float4){0.0f}))));\n+}\n+\n+static __inline qword si_dfm(qword a, qword b)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } aa, bb, dd;\n+\n+  aa.v = (vec_double2)(a);\n+  bb.v = (vec_double2)(b);\n+  dd.d[0] = aa.d[0] * bb.d[0];\n+  dd.d[1] = aa.d[1] * bb.d[1];\n+  return ((qword)(dd.v));\n+}\n+\n+/* Multiply High\n+ */\n+static __inline qword si_mpyh(qword a, qword b)\n+{\n+  vec_uint4 sixteen = (vec_uint4){16, 16, 16, 16};\n+\n+  return ((qword)(vec_sl(vec_mule((vec_short8)(a), (vec_short8)(vec_sl((vec_uint4)(b), sixteen))), sixteen)));\n+}\n+\n+\n+/* Multiply High High\n+ */\n+static __inline qword si_mpyhh(qword a, qword b)\n+{\n+  return ((qword)(vec_mule((vec_short8)(a), (vec_short8)(b))));\n+}\n+\n+static __inline qword si_mpyhhu(qword a, qword b)\n+{\n+  return ((qword)(vec_mule((vec_ushort8)(a), (vec_ushort8)(b))));\n+}\n+\n+/* Multiply Odd\n+ */\n+static __inline qword si_mpy(qword a, qword b)\n+{\n+  return ((qword)(vec_mulo((vec_short8)(a), (vec_short8)(b))));\n+}\n+\n+static __inline qword si_mpyu(qword a, qword b)\n+{\n+  return ((qword)(vec_mulo((vec_ushort8)(a), (vec_ushort8)(b))));\n+}\n+\n+static __inline qword si_mpyi(qword a, short b)\n+{\n+  return ((qword)(vec_mulo((vec_short8)(a), \n+\t\t\t   vec_splat((vec_short8)(si_from_short(b)), 1))));\n+}\n+\n+static __inline qword si_mpyui(qword a, unsigned short b)\n+{\n+  return ((qword)(vec_mulo((vec_ushort8)(a), \n+\t\t\t   vec_splat((vec_ushort8)(si_from_ushort(b)), 1))));\n+}\n+\n+/* Multiply and Shift Right\n+ */\n+static __inline qword si_mpys(qword a, qword b)\n+{\n+  return ((qword)(vec_sra(vec_mulo((vec_short8)(a), (vec_short8)(b)), ((vec_uint4){16,16,16,16}))));\n+}\n+\n+/* Nand\n+ */\n+static __inline qword si_nand(qword a, qword b)\n+{\n+  vec_uchar16 d;\n+\n+  d = vec_and((vec_uchar16)(a), (vec_uchar16)(b));\n+  return ((qword)(vec_nor(d, d)));\n+}\n+\n+/* Negative Multiply Add\n+ */\n+static __inline qword si_dfnma(qword a, qword b, qword c)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } aa, bb, cc, dd;\n+\n+  aa.v = (vec_double2)(a);\n+  bb.v = (vec_double2)(b);\n+  cc.v = (vec_double2)(c);\n+  dd.d[0] = -cc.d[0] - aa.d[0] * bb.d[0];\n+  dd.d[1] = -cc.d[1] - aa.d[1] * bb.d[1];\n+  return ((qword)(dd.v));\n+}\n+\n+/* Negative Multiply and Subtract\n+ */\n+static __inline qword si_fnms(qword a, qword b, qword c)\n+{\n+  return ((qword)(vec_nmsub((vec_float4)(a), (vec_float4)(b), (vec_float4)(c))));\n+}\n+\n+static __inline qword si_dfnms(qword a, qword b, qword c)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } aa, bb, cc, dd;\n+\n+  aa.v = (vec_double2)(a);\n+  bb.v = (vec_double2)(b);\n+  cc.v = (vec_double2)(c);\n+  dd.d[0] = cc.d[0] - aa.d[0] * bb.d[0];\n+  dd.d[1] = cc.d[1] - aa.d[1] * bb.d[1];\n+  return ((qword)(dd.v));\n+}\n+\n+/* Nor\n+ */\n+static __inline qword si_nor(qword a, qword b)\n+{\n+  return ((qword)(vec_nor((vec_uchar16)(a), (vec_uchar16)(b))));\n+}\n+\n+/* Or\n+ */\n+static __inline qword si_or(qword a, qword b)\n+{\n+  return ((qword)(vec_or((vec_uchar16)(a), (vec_uchar16)(b))));\n+}\n+\n+static __inline qword si_orbi(qword a, unsigned char b)\n+{\n+  return ((qword)(vec_or((vec_uchar16)(a), \n+\t\t\t vec_splat((vec_uchar16)(si_from_uchar(b)), 3))));\n+}\n+\n+static __inline qword si_orhi(qword a, unsigned short b)\n+{\n+  return ((qword)(vec_or((vec_ushort8)(a), \n+\t\t\t  vec_splat((vec_ushort8)(si_from_ushort(b)), 1))));\n+}\n+\n+static __inline qword si_ori(qword a, unsigned int b)\n+{\n+  return ((qword)(vec_or((vec_uint4)(a), \n+\t\t\t  vec_splat((vec_uint4)(si_from_uint(b)), 0))));\n+}\n+\n+/* Or Complement\n+ */\n+static __inline qword si_orc(qword a, qword b)\n+{\n+  return ((qword)(vec_or((vec_uchar16)(a), vec_nor((vec_uchar16)(b), (vec_uchar16)(b)))));\n+}\n+\n+\n+/* Or Across\n+ */\n+static __inline qword si_orx(qword a)\n+{\n+  vec_uchar16 tmp;\n+  tmp = (vec_uchar16)(a);\n+  tmp = vec_or(tmp, vec_sld(tmp, tmp, 8));\n+  tmp = vec_or(tmp, vec_sld(tmp, tmp, 4));\n+  return ((qword)(vec_and(tmp, ((vec_uchar16){0xFF,0xFF,0xFF,0xFF, 0x00,0x00,0x00,0x00,\n+\t\t\t\t              0x00,0x00,0x00,0x00, 0x00,0x00,0x00,0x00}))));\n+}\n+\n+\n+/* Estimates\n+ */\n+static __inline qword si_frest(qword a)\n+{\n+  return ((qword)(vec_re((vec_float4)(a))));\n+}\n+\n+static __inline qword si_frsqest(qword a)\n+{\n+  return ((qword)(vec_rsqrte((vec_float4)(a))));\n+}\n+\n+#define si_fi(_a, _d)\t\t(_d)\n+\n+/* Channel Read and Write\n+ */\n+#define si_rdch(_channel)\t\t((qword)(vec_splat_u8(0)))\t/* not mappable */\n+#define si_rchcnt(_channel)\t\t((qword)(vec_splat_u8(0)))\t/* not mappable */\n+#define si_wrch(_channel, _a)\t\t/* not mappable */\n+\n+/* Rotate Left\n+ */\n+static __inline qword si_roth(qword a, qword b)\n+{\n+  return ((qword)(vec_rl((vec_ushort8)(a), (vec_ushort8)(b))));\n+}\n+\n+static __inline qword si_rot(qword a, qword b)\n+{\n+  return ((qword)(vec_rl((vec_uint4)(a), (vec_uint4)(b))));\n+}\n+\n+static __inline qword si_rothi(qword a, int b)\n+{\n+  return ((qword)(vec_rl((vec_ushort8)(a), \n+\t\t\t vec_splat((vec_ushort8)(si_from_int(b)), 1))));\n+}\n+\n+static __inline qword si_roti(qword a, int b)\n+{\n+  return ((qword)(vec_rl((vec_uint4)(a), \n+\t\t\t vec_splat((vec_uint4)(si_from_int(b)), 0))));\n+}\n+\n+/* Rotate Left with Mask\n+ */\n+static __inline qword si_rothm(qword a, qword b)\n+{\n+  vec_ushort8 neg_b;\n+  vec_ushort8 mask;\n+\n+  neg_b = (vec_ushort8)vec_sub(vec_splat_s16(0), (vec_short8)(b));\n+  mask = vec_sra(vec_sl(neg_b, vec_splat_u16(11)), vec_splat_u16(15));\n+  return ((qword)(vec_andc(vec_sr((vec_ushort8)(a), neg_b), mask)));\n+}\n+\n+static __inline qword si_rotm(qword a, qword b)\n+{\n+  vec_uint4 neg_b;\n+  vec_uint4 mask;\n+\n+  neg_b = (vec_uint4)vec_sub(vec_splat_s32(0), (vec_int4)(b));\n+  mask = vec_sra(vec_sl(neg_b, ((vec_uint4){26,26,26,26})), ((vec_uint4){31,31,31,31}));\n+  return ((qword)(vec_andc(vec_sr((vec_uint4)(a), neg_b), mask)));\n+}\n+\n+static __inline qword si_rothmi(qword a, int b)\n+{\n+  vec_ushort8 neg_b;\n+  vec_ushort8 mask;\n+\n+  neg_b = vec_splat((vec_ushort8)(si_from_int(-b)), 1);\n+  mask = vec_sra(vec_sl(neg_b, vec_splat_u16(11)), vec_splat_u16(15));\n+  return ((qword)(vec_andc(vec_sr((vec_ushort8)(a), neg_b), mask)));\n+}\n+\n+static __inline qword si_rotmi(qword a, int b)\n+{\n+  vec_uint4 neg_b;\n+  vec_uint4 mask;\n+\n+  neg_b = vec_splat((vec_uint4)(si_from_int(-b)), 0);\n+  mask = vec_sra(vec_sl(neg_b, ((vec_uint4){26,26,26,26})), ((vec_uint4){31,31,31,31}));\n+  return ((qword)(vec_andc(vec_sr((vec_uint4)(a), neg_b), mask)));\n+}\n+\n+\n+/* Rotate Left Algebraic with Mask\n+ */\n+static __inline qword si_rotmah(qword a, qword b)\n+{\n+  vec_ushort8 neg_b;\n+  vec_ushort8 mask;\n+\n+  neg_b = (vec_ushort8)vec_sub(vec_splat_s16(0), (vec_short8)(b));\n+  mask = vec_sra(vec_sl(neg_b, vec_splat_u16(11)), vec_splat_u16(15));\n+  return ((qword)(vec_sra((vec_short8)(a), (vec_ushort8)vec_or(neg_b, mask))));\n+}\n+\n+static __inline qword si_rotma(qword a, qword b)\n+{\n+  vec_uint4 neg_b;\n+  vec_uint4 mask;\n+\n+  neg_b = (vec_uint4)vec_sub(vec_splat_s32(0), (vec_int4)(b));\n+  mask = vec_sra(vec_sl(neg_b, ((vec_uint4){26,26,26,26})), ((vec_uint4){31,31,31,31}));\n+  return ((qword)(vec_sra((vec_int4)(a), (vec_uint4)vec_or(neg_b, mask))));\n+}\n+\n+\n+static __inline qword si_rotmahi(qword a, int b)\n+{\n+  vec_ushort8 neg_b;\n+  vec_ushort8 mask;\n+\n+  neg_b = vec_splat((vec_ushort8)(si_from_int(-b)), 1);\n+  mask = vec_sra(vec_sl(neg_b, vec_splat_u16(11)), vec_splat_u16(15));\n+  return ((qword)(vec_sra((vec_short8)(a), (vec_ushort8)vec_or(neg_b, mask))));\n+}\n+\n+static __inline qword si_rotmai(qword a, int b)\n+{\n+  vec_uint4 neg_b;\n+  vec_uint4 mask;\n+\n+  neg_b = vec_splat((vec_uint4)(si_from_int(-b)), 0);\n+  mask = vec_sra(vec_sl(neg_b, ((vec_uint4){26,26,26,26})), ((vec_uint4){31,31,31,31}));\n+  return ((qword)(vec_sra((vec_int4)(a), (vec_uint4)vec_or(neg_b, mask))));\n+}\n+\n+\n+/* Rotate Left Quadword by Bytes with Mask\n+ */\n+static __inline qword si_rotqmbyi(qword a, int count)\n+{\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+  vec_uchar16 mask;\n+\n+  count = 0 - count;\n+  x.i[3] = count << 3;\n+  mask = (count & 0x10) ? vec_splat_u8(0) : vec_splat_u8(-1);\n+\n+  return ((qword)(vec_and(vec_sro((vec_uchar16)(a), x.v), mask)));\n+}\n+\n+\n+static __inline qword si_rotqmby(qword a, qword count)\n+{\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+  int cnt;\n+  vec_uchar16 mask;\n+\n+  x.v = (vec_uchar16)(count);\n+  x.i[0] = cnt = (0 - x.i[0]) << 3;\n+\n+  x.v = vec_splat(x.v, 3);\n+  mask = (cnt & 0x80) ? vec_splat_u8(0) : vec_splat_u8(-1);\n+\n+  return ((qword)(vec_and(vec_sro((vec_uchar16)(a), x.v), mask)));\n+}\n+\n+\n+/* Rotate Left Quadword by Bytes\n+ */\n+static __inline qword si_rotqbyi(qword a, int count)\n+{\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } left, right;\n+ \n+  count <<= 3;\n+  left.i[3] = count;\n+  right.i[3] = 0 - count;\n+  return ((qword)(vec_or(vec_slo((vec_uchar16)(a), left.v), vec_sro((vec_uchar16)(a), right.v))));\n+}\n+\n+static __inline qword si_rotqby(qword a, qword count)\n+{\n+  vec_uchar16 left, right;\n+ \n+  left = vec_sl(vec_splat((vec_uchar16)(count), 3), vec_splat_u8(3));\n+  right = vec_sub(vec_splat_u8(0), left);\n+  return ((qword)(vec_or(vec_slo((vec_uchar16)(a), left), vec_sro((vec_uchar16)(a), right))));\n+}\n+\n+/* Rotate Left Quadword by Bytes Bit Count\n+ */\n+static __inline qword si_rotqbybi(qword a, qword count)\n+{\n+  vec_uchar16 left, right;\n+\n+  left = vec_splat((vec_uchar16)(count), 3);\n+  right = vec_sub(vec_splat_u8(7), left);\n+  return ((qword)(vec_or(vec_slo((vec_uchar16)(a), left), vec_sro((vec_uchar16)(a), right))));\n+}\n+\n+\n+/* Rotate Left Quadword by Bytes Bit Count\n+ */\n+static __inline qword si_rotqbii(qword a, int count)\n+{\n+  vec_uchar16 x, y;\n+  vec_uchar16 result;\n+ \n+  x = vec_splat((vec_uchar16)(si_from_int(count & 7)), 3);\n+  y = (vec_uchar16)(vec_sr((vec_uint4)vec_sro((vec_uchar16)(a), ((vec_uchar16)((vec_uint4){0,0,0,120}))),\n+\t\t\t   (vec_uint4)vec_sub(vec_splat_u8(8), x)));\n+  result = vec_or(vec_sll((qword)(a), x), y);\n+  return ((qword)(result));\n+}\n+\n+static __inline qword si_rotqbi(qword a, qword count)\n+{\n+  vec_uchar16 x, y;\n+  vec_uchar16 result;\n+ \n+  x = vec_and(vec_splat((vec_uchar16)(count), 3), vec_splat_u8(7));\n+  y = (vec_uchar16)(vec_sr((vec_uint4)vec_sro((vec_uchar16)(a), ((vec_uchar16)((vec_uint4){0,0,0,120}))),\n+\t\t\t   (vec_uint4)vec_sub(vec_splat_u8(8), x)));\n+  \n+  result = vec_or(vec_sll((qword)(a), x), y);\n+  return ((qword)(result));\n+}\n+\n+\n+/* Rotate Left Quadword and Mask by Bits\n+ */\n+static __inline qword si_rotqmbii(qword a, int count)\n+{\n+  return ((qword)(vec_srl((vec_uchar16)(a), vec_splat((vec_uchar16)(si_from_int(0 - count)), 3))));\n+}\n+\n+static __inline qword si_rotqmbi(qword a, qword count)\n+{\n+  return ((qword)(vec_srl((vec_uchar16)(a), vec_sub(vec_splat_u8(0), vec_splat((vec_uchar16)(count), 3)))));\n+}\n+\n+\n+/* Rotate Left Quadword and Mask by Bytes with Bit Count\n+ */\n+static __inline qword si_rotqmbybi(qword a, qword count)\n+{\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+  int cnt;\n+  vec_uchar16 mask;\n+\n+  x.v = (vec_uchar16)(count);\n+  x.i[0] = cnt = 0 - (x.i[0] & ~7);\n+  x.v = vec_splat(x.v, 3);\n+  mask = (cnt & 0x80) ? vec_splat_u8(0) : vec_splat_u8(-1);\n+\n+  return ((qword)(vec_and(vec_sro((vec_uchar16)(a), x.v), mask)));\n+}\n+\n+\n+\n+\n+/* Round Double to Float\n+ */\n+static __inline qword si_frds(qword a)\n+{\n+  union {\n+    vec_float4 v;\n+    float f[4];\n+  } d;\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } in;\n+\n+  in.v = (vec_double2)(a);\n+  d.v = (vec_float4){0.0f};\n+  d.f[0] = (float)in.d[0];\n+  d.f[2] = (float)in.d[1];\n+\n+  return ((qword)(d.v));\n+}\n+\n+/* Select Bits\n+ */\n+static __inline qword si_selb(qword a, qword b, qword c)\n+{\n+  return ((qword)(vec_sel((vec_uchar16)(a), (vec_uchar16)(b), (vec_uchar16)(c))));\n+}\n+\n+\n+/* Shuffle Bytes\n+ */\n+static __inline qword si_shufb(qword a, qword b, qword pattern)\n+{\n+  vec_uchar16 pat;\n+\n+  pat = vec_sel(((vec_uchar16){0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15}), \n+\t\tvec_sr((vec_uchar16)(pattern), vec_splat_u8(3)),\n+\t\tvec_sra((vec_uchar16)(pattern), vec_splat_u8(7)));\n+  return ((qword)(vec_perm(vec_perm(a, b, pattern), \n+\t\t\t   ((vec_uchar16){0, 0, 0, 0, 0, 0, 0, 0,\n+\t\t\t\t          0xFF, 0xFF, 0xFF, 0xFF, 0x80, 0x80, 0x80, 0x80}),\n+\t\t\t   pat)));\n+}\n+\n+\n+/* Shift Left\n+ */\n+static __inline qword si_shlh(qword a, qword b)\n+{\n+  vec_ushort8 mask;\n+\n+  mask = (vec_ushort8)vec_sra(vec_sl((vec_ushort8)(b), vec_splat_u16(11)), vec_splat_u16(15));\n+  return ((qword)(vec_andc(vec_sl((vec_ushort8)(a), (vec_ushort8)(b)), mask)));\n+}\n+\n+static __inline qword si_shl(qword a, qword b)\n+{\n+  vec_uint4 mask;\n+\n+  mask = (vec_uint4)vec_sra(vec_sl((vec_uint4)(b), ((vec_uint4){26,26,26,26})), ((vec_uint4){31,31,31,31}));\n+  return ((qword)(vec_andc(vec_sl((vec_uint4)(a), (vec_uint4)(b)), mask)));\n+}\n+\n+\n+static __inline qword si_shlhi(qword a, unsigned int b)\n+{\n+  vec_ushort8 mask;\n+  vec_ushort8 bv;\n+\n+  bv = vec_splat((vec_ushort8)(si_from_int(b)), 1);\n+  mask = (vec_ushort8)vec_sra(vec_sl(bv, vec_splat_u16(11)), vec_splat_u16(15));\n+  return ((qword)(vec_andc(vec_sl((vec_ushort8)(a), bv), mask)));\n+}\n+\n+static __inline qword si_shli(qword a, unsigned int b)\n+{\n+  vec_uint4 bv;\n+  vec_uint4 mask;\n+\n+  bv = vec_splat((vec_uint4)(si_from_uint(b)), 0);\n+  mask = (vec_uint4)vec_sra(vec_sl(bv, ((vec_uint4){26,26,26,26})), ((vec_uint4){31,31,31,31}));\n+  return ((qword)(vec_andc(vec_sl((vec_uint4)(a), bv), mask)));\n+}\n+\n+\n+/* Shift Left Quadword\n+ */\n+static __inline qword si_shlqbii(qword a, unsigned int count)\n+{\n+  vec_uchar16 x;\n+\n+  x = vec_splat((vec_uchar16)(si_from_uint(count)), 3);\n+  return ((qword)(vec_sll((vec_uchar16)(a), x)));\n+}\n+\n+static __inline qword si_shlqbi(qword a, qword count)\n+{\n+  vec_uchar16 x;\n+\n+  x = vec_splat((vec_uchar16)(count), 3);\n+  return ((qword)(vec_sll((vec_uchar16)(a), x)));\n+}\n+\n+\n+/* Shift Left Quadword by Bytes\n+ */\n+static __inline qword si_shlqbyi(qword a, unsigned int count)\n+{\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+  vec_uchar16 mask;\n+\n+  x.i[3] = count << 3;\n+  mask = (count & 0x10) ? vec_splat_u8(0) : vec_splat_u8(-1);\n+  return ((qword)(vec_and(vec_slo((vec_uchar16)(a), x.v), mask)));\n+}\n+\n+static __inline qword si_shlqby(qword a, qword count)\n+{\n+  union {\n+    vec_uchar16 v;\n+    unsigned int i[4];\n+  } x;\n+  unsigned int cnt;\n+  vec_uchar16 mask;\n+\n+  x.v = vec_sl(vec_splat((vec_uchar16)(count), 3), vec_splat_u8(3));\n+  cnt = x.i[0];\n+  mask = (cnt & 0x80) ? vec_splat_u8(0) : vec_splat_u8(-1);\n+  return ((qword)(vec_and(vec_slo((vec_uchar16)(a), x.v), mask)));\n+}\n+\n+/* Shift Left Quadword by Bytes with Bit Count\n+ */\n+static __inline qword si_shlqbybi(qword a, qword count)\n+{\n+  union {\n+    vec_uchar16 v;\n+    int i[4];\n+  } x;\n+  unsigned int cnt;\n+  vec_uchar16 mask;\n+\n+  x.v = vec_splat((vec_uchar16)(count), 3);\n+  cnt = x.i[0];\n+  mask = (cnt & 0x80) ? vec_splat_u8(0) : vec_splat_u8(-1);\n+  return ((qword)(vec_and(vec_slo((vec_uchar16)(a), x.v), mask)));\n+}\n+\n+\n+/* Stop and Signal\n+ */\n+#define si_stop(_type)\t\tSPU_STOP_ACTION\n+#define si_stopd(a, b, c)\tSPU_STOP_ACTION\n+\n+\n+/* Subtract\n+ */\n+static __inline qword si_sfh(qword a, qword b)\n+{\n+  return ((qword)(vec_sub((vec_ushort8)(b), (vec_ushort8)(a))));\n+}\n+\n+static __inline qword si_sf(qword a, qword b)\n+{\n+  return ((qword)(vec_sub((vec_uint4)(b), (vec_uint4)(a))));\n+}\n+\n+static __inline qword si_fs(qword a, qword b)\n+{\n+  return ((qword)(vec_sub((vec_float4)(a), (vec_float4)(b))));\n+}\n+\n+static __inline qword si_dfs(qword a, qword b)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } aa, bb, dd;\n+\n+  aa.v = (vec_double2)(a);\n+  bb.v = (vec_double2)(b);\n+  dd.d[0] = aa.d[0] - bb.d[0];\n+  dd.d[1] = aa.d[1] - bb.d[1];\n+  return ((qword)(dd.v));\n+}\n+\n+static __inline qword si_sfhi(qword a, short b)\n+{\n+  return ((qword)(vec_sub(vec_splat((vec_short8)(si_from_short(b)), 1),\n+\t\t\t  (vec_short8)(a))));\n+}\n+\n+static __inline qword si_sfi(qword a, int b)\n+{\n+  return ((qword)(vec_sub(vec_splat((vec_int4)(si_from_int(b)), 0),\n+\t\t\t  (vec_int4)(a))));\n+}\n+\n+/* Subtract word extended\n+ */\n+#define si_sfx(_a, _b, _c)\t((qword)(vec_add(vec_add((vec_uint4)(_b), \t\t\t\t\\\n+\t\t\t\t\t\t\t vec_nor((vec_uint4)(_a), (vec_uint4)(_a))), \t\\\n+\t\t\t\t\t\t vec_and((vec_uint4)(_c), vec_splat_u32(1)))))\n+\n+\n+/* Sum Bytes into Shorts\n+ */\n+static __inline qword si_sumb(qword a, qword b)\n+{\n+  vec_uint4 zero = (vec_uint4){0};\n+  vec_ushort8 sum_a, sum_b;\n+  \n+  sum_a = (vec_ushort8)vec_sum4s((vec_uchar16)(a), zero);\n+  sum_b = (vec_ushort8)vec_sum4s((vec_uchar16)(b), zero);\n+\n+  return ((qword)(vec_perm(sum_a, sum_b, ((vec_uchar16){18, 19,  2,  3, 22, 23,  6,  7,\n+\t\t\t\t\t                26, 27, 10, 11, 30, 31, 14, 15}))));\n+}\n+\n+/* Exclusive OR\n+ */\n+static __inline qword si_xor(qword a, qword b)\n+{\n+  return ((qword)(vec_xor((vec_uchar16)(a), (vec_uchar16)(b))));\n+}\n+\n+static __inline qword si_xorbi(qword a, unsigned char b)\n+{\n+  return ((qword)(vec_xor((vec_uchar16)(a), \n+\t\t\t  vec_splat((vec_uchar16)(si_from_uchar(b)), 3))));\n+}\n+\n+static __inline qword si_xorhi(qword a, unsigned short b)\n+{\n+  return ((qword)(vec_xor((vec_ushort8)(a), \n+\t\t\t  vec_splat((vec_ushort8)(si_from_ushort(b)), 1))));\n+}\n+\n+static __inline qword si_xori(qword a, unsigned int b)\n+{\n+  return ((qword)(vec_xor((vec_uint4)(a), \n+\t\t\t  vec_splat((vec_uint4)(si_from_uint(b)), 0))));\n+}\n+\n+\n+/* Generate Controls for Sub-Quadword Insertion\n+ */\n+static __inline qword si_cbd(qword a, int imm)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned char c[16];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.c[(si_to_uint(a) + (unsigned int)(imm)) & 0xF] = 0x03;\n+  return ((qword)(shmask.v));\n+}\n+\n+static __inline qword si_cdd(qword a, int imm)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned long long ll[2];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.ll[((si_to_uint(a) + (unsigned int)(imm)) >> 3) & 0x1] = 0x0001020304050607ULL;\n+  return ((qword)(shmask.v));\n+}\n+\n+static __inline qword si_chd(qword a, int imm)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned short s[8];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.s[((si_to_uint(a) + (unsigned int)(imm)) >> 1) & 0x7] = 0x0203;\n+  return ((qword)(shmask.v));\n+}\n+\n+static __inline qword si_cwd(qword a, int imm)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned int i[4];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.i[((si_to_uint(a) + (unsigned int)(imm)) >> 2) & 0x3] = 0x00010203;\n+  return ((qword)(shmask.v));\n+}\n+\n+static __inline qword si_cbx(qword a, qword b)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned char c[16];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.c[si_to_uint((qword)(vec_add((vec_uint4)(a), (vec_uint4)(b)))) & 0xF] = 0x03;\n+  return ((qword)(shmask.v));\n+}\n+\n+\n+static __inline qword si_cdx(qword a, qword b)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned long long ll[2];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.ll[(si_to_uint((qword)(vec_add((vec_uint4)(a), (vec_uint4)(b)))) >> 3) & 0x1] = 0x0001020304050607ULL;\n+  return ((qword)(shmask.v));\n+}\n+\n+static __inline qword si_chx(qword a, qword b)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned short s[8];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.s[(si_to_uint((qword)(vec_add((vec_uint4)(a), (vec_uint4)(b)))) >> 1) & 0x7] = 0x0203;\n+  return ((qword)(shmask.v));\n+}\n+\n+static __inline qword si_cwx(qword a, qword b)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned int i[4];\n+  } shmask;\n+\n+  shmask.v = ((vec_uint4){0x10111213, 0x14151617, 0x18191A1B, 0x1C1D1E1F});\n+  shmask.i[(si_to_uint((qword)(vec_add((vec_uint4)(a), (vec_uint4)(b)))) >> 2) & 0x3] = 0x00010203;\n+  return ((qword)(shmask.v));\n+}\n+\n+\n+/* Constant Formation\n+ */\n+static __inline qword si_il(signed short imm)\n+{\n+  return ((qword)(vec_splat((vec_int4)(si_from_int((signed int)(imm))), 0)));\n+}\n+\n+\n+static __inline qword si_ila(unsigned int imm)\n+{\n+  return ((qword)(vec_splat((vec_uint4)(si_from_uint(imm)), 0)));\n+}\n+\n+static __inline qword si_ilh(signed short imm)\n+{\n+  return ((qword)(vec_splat((vec_short8)(si_from_short(imm)), 1)));\n+}\n+\n+static __inline qword si_ilhu(signed short imm)\n+{\n+  return ((qword)(vec_splat((vec_uint4)(si_from_uint((unsigned int)(imm) << 16)), 0)));\n+}\n+\n+static __inline qword si_iohl(qword a, unsigned short imm)\n+{\n+  return ((qword)(vec_or((vec_uint4)(a), vec_splat((vec_uint4)(si_from_uint((unsigned int)(imm))), 0))));\n+}\n+\n+/* No Operation\n+ */\n+#define si_lnop()\t\t/* do nothing */\n+#define si_nop()\t\t/* do nothing */\n+\n+\n+/* Memory Load and Store\n+ */\n+static __inline qword si_lqa(unsigned int imm)\n+{\n+  return ((qword)(vec_ld(0, (vector unsigned char *)(imm))));\n+}\n+\n+static __inline qword si_lqd(qword a, unsigned int imm)\n+{\n+  return ((qword)(vec_ld(si_to_uint(a) & ~0xF, (vector unsigned char *)(imm))));\n+}\n+\n+static __inline qword si_lqr(unsigned int imm)\n+{\n+  return ((qword)(vec_ld(0, (vector unsigned char *)(imm))));\n+}\n+\n+static __inline qword si_lqx(qword a, qword b)\n+{\n+  return ((qword)(vec_ld(si_to_uint((qword)(vec_add((vec_uint4)(a), (vec_uint4)(b)))), (vector unsigned char *)(0))));\n+}\n+\n+static __inline void si_stqa(qword a, unsigned int imm)\n+{\n+  vec_st((vec_uchar16)(a), 0, (vector unsigned char *)(imm));\n+}\n+\n+static __inline void si_stqd(qword a, qword b, unsigned int imm)\n+{\n+  vec_st((vec_uchar16)(a), si_to_uint(b) & ~0xF, (vector unsigned char *)(imm));\n+}\n+\n+static __inline void si_stqr(qword a, unsigned int imm)\n+{\n+  vec_st((vec_uchar16)(a), 0, (vector unsigned char *)(imm));\n+}\n+\n+static __inline void si_stqx(qword a, qword b, qword c)\n+{\n+  vec_st((vec_uchar16)(a), \n+\t si_to_uint((qword)(vec_add((vec_uint4)(b), (vec_uint4)(c)))),\n+\t (vector unsigned char *)(0));\n+}\n+\n+#endif /* !__SPU__ */\n+#endif /* !_SI2VMX_H_ */\n+"}, {"sha": "b4a48102ae8b17a721bfb19ae46924c71d8bbeec", "filename": "gcc/config/rs6000/spu2vmx.h", "status": "added", "additions": 2417, "deletions": 0, "changes": 2417, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig%2Frs6000%2Fspu2vmx.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig%2Frs6000%2Fspu2vmx.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fspu2vmx.h?ref=437cc56a07a35aab6bd51ed66b00fc9549076f97", "patch": "@@ -0,0 +1,2417 @@\n+/* Cell SPU 2 VMX intrinsics header\n+   Copyright (C) 2007 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source files \n+   compiled by GCC, this header file does not by itself cause  the resulting \n+   executable to be covered by the GNU General Public License.  This exception \n+   does not however invalidate any other reasons why the executable file might be \n+   covered by the GNU General Public License.  */ \n+\n+#ifndef _SPU2VMX_H_\n+#define _SPU2VMX_H_\t1\n+\n+#ifdef __cplusplus\n+\n+#ifndef __SPU__\n+\n+#include <si2vmx.h>\n+\n+/* spu_absd (absolute difference)\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_absd(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_absdb((qword)(a), (qword)(b))));\n+\n+}\n+\n+\n+/* spu_add\n+ * =======\n+ */\n+static __inline vec_uint4 spu_add(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_a((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_add(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_a((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_add(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_ah((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_add(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_ah((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_add(vec_uint4 a, unsigned int b)\n+{\n+  return ((vec_uint4)(si_ai((qword)(a), (int)(b))));\n+}\n+\n+static __inline vec_int4 spu_add(vec_int4 a, int b)\n+{\n+  return ((vec_int4)(si_ai((qword)(a), b)));\n+}\n+\n+static __inline vec_ushort8 spu_add(vec_ushort8 a, unsigned short b)\n+{\n+  return ((vec_ushort8)(si_ahi((qword)(a), (short)(b))));\n+}\n+\n+static __inline vec_short8 spu_add(vec_short8 a, short b)\n+{\n+  return ((vec_short8)(si_ahi((qword)(a), b)));\n+}\n+\n+static __inline vec_float4 spu_add(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_fa((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_double2 spu_add(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_dfa((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_addx\n+ * ========\n+ */\n+static __inline vec_uint4 spu_addx(vec_uint4 a, vec_uint4 b, vec_uint4 c)\n+{\n+  return ((vec_uint4)(si_addx((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+static __inline vec_int4 spu_addx(vec_int4 a, vec_int4 b, vec_int4 c)\n+{\n+  return ((vec_int4)(si_addx((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+/* spu_and\n+ * =======\n+ */\n+static __inline vec_uchar16 spu_and(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_char16 spu_and(vec_char16 a, vec_char16 b)\n+{\n+  return ((vec_char16)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_and(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_and(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_and(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_and(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_float4 spu_and(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ullong2 spu_and(vec_ullong2 a, vec_ullong2 b)\n+{\n+  return ((vec_ullong2)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_llong2 spu_and(vec_llong2 a, vec_llong2 b)\n+{\n+  return ((vec_llong2)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_double2 spu_and(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_and((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uchar16 spu_and(vec_uchar16 a, unsigned char b)\n+{\n+  return ((vec_uchar16)(si_andbi((qword)(a), (signed char)(b))));\n+}\n+\n+\n+static __inline vec_char16 spu_and(vec_char16 a, signed char b)\n+{\n+  return ((vec_char16)(si_andbi((qword)(a), b)));\n+}\n+\n+static __inline vec_ushort8 spu_and(vec_ushort8 a, unsigned short b)\n+{\n+  return ((vec_ushort8)(si_andhi((qword)(a), (signed short)(b))));\n+}\n+\n+static __inline vec_short8 spu_and(vec_short8 a, signed short b)\n+{\n+  return ((vec_short8)(si_andhi((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_and(vec_uint4 a, unsigned int b)\n+{\n+  return ((vec_uint4)(si_andi((qword)(a), (signed int)(b))));\n+}\n+\n+static __inline vec_int4 spu_and(vec_int4 a, signed int b)\n+{\n+  return ((vec_int4)(si_andi((qword)(a), b)));\n+}\n+\n+\n+/* spu_andc\n+ * ========\n+ */\n+#define spu_andc(_a, _b)\tvec_andc(_a, _b)\n+\n+\n+/* spu_avg\n+ * =======\n+ */\n+#define spu_avg(_a, _b)\t\tvec_avg(_a, _b)\n+  \n+\n+/* spu_bisled\n+ * spu_bisled_d\n+ * spu_bisled_e\n+ * ============\n+ */\n+#define spu_bisled(_func)\t/* not mappable */\n+#define spu_bisled_d(_func)\t/* not mappable */\n+#define spu_bisled_e(_func)\t/* not mappable */\n+\n+/* spu_cmpabseq\n+ * ============\n+ */\n+static __inline vec_uint4 spu_cmpabseq(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_uint4)(si_fcmeq((qword)(a), (qword)(b))));\n+\n+}\n+\n+static __inline vec_ullong2 spu_cmpabseq(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_ullong2)(si_dfcmeq((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_cmpabsgt\n+ * ============\n+ */\n+static __inline vec_uint4 spu_cmpabsgt(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_uint4)(si_fcmgt((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ullong2 spu_cmpabsgt(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_ullong2)(si_dfcmgt((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_cmpeq\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_cmpeq(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_ceqb((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uchar16 spu_cmpeq(vec_char16 a, vec_char16 b)\n+{\n+  return ((vec_uchar16)(si_ceqb((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_cmpeq(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_ceqh((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_cmpeq(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_ushort8)(si_ceqh((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_cmpeq(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_ceq((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_cmpeq(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_uint4)(si_ceq((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_cmpeq(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_uint4)(si_fceq((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uchar16 spu_cmpeq(vec_uchar16 a, unsigned char b)\n+{\n+  return ((vec_uchar16)(si_ceqbi((qword)(a), (signed char)(b))));\n+}\n+\n+static __inline vec_uchar16 spu_cmpeq(vec_char16 a, signed char b)\n+{\n+  return ((vec_uchar16)(si_ceqbi((qword)(a), b)));\n+}\n+\n+static __inline vec_ushort8 spu_cmpeq(vec_ushort8 a, unsigned short b)\n+{\n+  return ((vec_ushort8)(si_ceqhi((qword)(a), (signed short)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_cmpeq(vec_short8 a, signed short b)\n+{\n+  return ((vec_ushort8)(si_ceqhi((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_cmpeq(vec_uint4 a, unsigned int b)\n+{\n+  return ((vec_uint4)(si_ceqi((qword)(a), (signed int)(b))));\n+}\n+\n+static __inline vec_uint4 spu_cmpeq(vec_int4 a, signed int b)\n+{\n+  return ((vec_uint4)(si_ceqi((qword)(a), b)));\n+}\n+\n+static __inline vec_ullong2 spu_cmpeq(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_ullong2)(si_dfceq((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_cmpgt\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_cmpgt(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_clgtb((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uchar16 spu_cmpgt(vec_char16 a, vec_char16 b)\n+{\n+  return ((vec_uchar16)(si_cgtb((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_cmpgt(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_clgth((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_cmpgt(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_ushort8)(si_cgth((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_cmpgt(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_clgt((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_cmpgt(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_uint4)(si_cgt((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_cmpgt(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_uint4)(si_fcgt((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uchar16 spu_cmpgt(vec_uchar16 a, unsigned char b)\n+{\n+  return ((vec_uchar16)(si_clgtbi((qword)(a), b)));\n+}\n+\n+static __inline vec_uchar16 spu_cmpgt(vec_char16 a, signed char b)\n+{\n+  return ((vec_uchar16)(si_cgtbi((qword)(a), b)));\n+}\n+\n+static __inline vec_ushort8 spu_cmpgt(vec_ushort8 a, unsigned short b)\n+{\n+  return ((vec_ushort8)(si_clgthi((qword)(a), b)));\n+}\n+\n+static __inline vec_ushort8 spu_cmpgt(vec_short8 a, signed short b)\n+{\n+  return ((vec_ushort8)(si_cgthi((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_cmpgt(vec_uint4 a, unsigned int b)\n+{\n+  return ((vec_uint4)(si_clgti((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_cmpgt(vec_int4 a, signed int b)\n+{\n+  return ((vec_uint4)(si_cgti((qword)(a), b)));\n+}\n+\n+static __inline vec_ullong2 spu_cmpgt(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_ullong2)(si_dfcgt((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_cntb\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_cntb(vec_uchar16 a)\n+{\n+  return ((vec_uchar16)(si_cntb((qword)(a))));\n+}\n+\n+\n+static __inline vec_uchar16 spu_cntb(vec_char16 a)\n+{\n+  return ((vec_uchar16)(si_cntb((qword)(a))));\n+}\n+\n+/* spu_cntlz\n+ * =========\n+ */\n+static __inline vec_uint4 spu_cntlz(vec_uint4 a)\n+{\n+  return ((vec_uint4)(si_clz((qword)(a))));\n+}\n+\n+static __inline vec_uint4 spu_cntlz(vec_int4 a)\n+{\n+  return ((vec_uint4)(si_clz((qword)(a))));\n+}\n+\n+static __inline vec_uint4 spu_cntlz(vec_float4 a)\n+{\n+  return ((vec_uint4)(si_clz((qword)(a))));\n+}\n+\n+/* spu_testsv\n+ * ==========\n+ */\n+static __inline vec_ullong2 spu_testsv(vec_double2 a, char b)\n+{\n+  return ((vec_ullong2)(si_dftsv((qword)(a), b)));\n+}\n+\n+/* spu_convtf\n+ * ==========\n+ */\n+#define spu_convtf(_a, _b)\t(vec_ctf(_a, _b))\n+\n+/* spu_convts\n+ * ==========\n+ */\n+#define spu_convts(_a, _b)\t(vec_cts(_a, _b))\n+\n+/* spu_convtu\n+ * ==========\n+ */\n+#define spu_convtu(_a, _b)\t(vec_ctu(_a, _b))\n+\n+\n+/* spu_dsync\n+ * ========\n+ */\n+#define spu_dsync()\n+\n+/* spu_eqv\n+ * =======\n+ */\n+static __inline vec_uchar16 spu_eqv(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_char16 spu_eqv(vec_char16 a, vec_char16 b)\n+{\n+  return ((vec_char16)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_eqv(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_eqv(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_eqv(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_eqv(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_float4 spu_eqv(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ullong2 spu_eqv(vec_ullong2 a, vec_ullong2 b)\n+{\n+  return ((vec_ullong2)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_llong2 spu_eqv(vec_llong2 a, vec_llong2 b)\n+{\n+  return ((vec_llong2)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_double2 spu_eqv(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_eqv((qword)(a), (qword)(b))));\n+}\n+\n+/* spu_extend\n+ * ========\n+ */\n+static __inline vec_short8 spu_extend(vec_char16 a)\n+{\n+  return ((vec_short8)(si_xsbh((qword)(a))));\n+}\n+\n+\n+static __inline vec_int4 spu_extend(vec_short8 a)\n+{\n+  return ((vec_int4)(si_xshw((qword)(a))));\n+}\n+\n+static __inline vec_llong2 spu_extend(vec_int4 a)\n+{\n+  return ((vec_llong2)(si_xswd((qword)(a))));\n+}\n+\n+\n+static __inline vec_double2 spu_extend(vec_float4 a)\n+{\n+  return ((vec_double2)(si_fesd((qword)(a))));\n+}\n+\n+\n+/* spu_extract\n+ * ========\n+ */\n+static __inline unsigned char spu_extract(vec_uchar16 a, int element)\n+{\n+  union {\n+    vec_uchar16 v;\n+    unsigned char c[16];\n+  } in;\n+\n+  in.v = a;\n+  return (in.c[element & 15]);\n+}\n+\n+static __inline signed char spu_extract(vec_char16 a, int element)\n+{\n+  union {\n+    vec_char16 v;\n+    signed char c[16];\n+  } in;\n+\n+  in.v = a;\n+  return (in.c[element & 15]);\n+}\n+\n+static __inline unsigned short spu_extract(vec_ushort8 a, int element)\n+{\n+  union {\n+    vec_ushort8 v;\n+    unsigned short s[8];\n+  } in;\n+\n+  in.v = a;\n+  return (in.s[element & 7]);\n+}\n+\n+static __inline signed short spu_extract(vec_short8 a, int element)\n+{\n+  union {\n+    vec_short8 v;\n+    signed short s[8];\n+  } in;\n+\n+  in.v = a;\n+  return (in.s[element & 7]);\n+}\n+\n+static __inline unsigned int spu_extract(vec_uint4 a, int element)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned int i[4];\n+  } in;\n+\n+  in.v = a;\n+  return (in.i[element & 3]);\n+}\n+\n+static __inline signed int spu_extract(vec_int4 a, int element)\n+{\n+  union {\n+    vec_int4 v;\n+    signed int i[4];\n+  } in;\n+\n+  in.v = a;\n+  return (in.i[element & 3]);\n+}\n+\n+static __inline float spu_extract(vec_float4 a, int element)\n+{\n+  union {\n+    vec_float4 v;\n+    float f[4];\n+  } in;\n+\n+  in.v = a;\n+  return (in.f[element & 3]);\n+}\n+\n+static __inline unsigned long long  spu_extract(vec_ullong2 a, int element)\n+{\n+  union {\n+    vec_ullong2 v;\n+    unsigned long long l[2];\n+  } in;\n+\n+  in.v = a;\n+  return (in.l[element & 1]);\n+}\n+\n+static __inline signed long long  spu_extract(vec_llong2 a, int element)\n+{\n+  union {\n+    vec_llong2 v;\n+    signed long long l[2];\n+  } in;\n+\n+  in.v = a;\n+  return (in.l[element & 1]);\n+}\n+\n+static __inline double spu_extract(vec_double2 a, int element)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } in;\n+\n+  in.v = a;\n+  return (in.d[element & 1]);\n+}\n+\n+/* spu_gather\n+ * ========\n+ */\n+static __inline vec_uint4 spu_gather(vec_uchar16 a)\n+{\n+  return ((vec_uint4)(si_gbb((qword)(a))));\n+}\n+\n+\n+static __inline vec_uint4 spu_gather(vec_char16 a)\n+{\n+  return ((vec_uint4)(si_gbb((qword)(a))));\n+}\n+\n+static __inline vec_uint4 spu_gather(vec_ushort8 a)\n+{\n+  return ((vec_uint4)(si_gbh((qword)(a))));\n+}\n+\n+static __inline vec_uint4 spu_gather(vec_short8 a)\n+{\n+  return ((vec_uint4)(si_gbh((qword)(a))));\n+}\n+\n+\n+static __inline vec_uint4 spu_gather(vec_uint4 a)\n+{\n+  return ((vec_uint4)(si_gb((qword)(a))));\n+}\n+\n+static __inline vec_uint4 spu_gather(vec_int4 a)\n+{\n+  return ((vec_uint4)(si_gb((qword)(a))));\n+}\n+\n+static __inline vec_uint4 spu_gather(vec_float4 a)\n+{\n+  return ((vec_uint4)(si_gb((qword)(a))));\n+}\n+\n+/* spu_genb\n+ * ========\n+ */\n+static __inline vec_uint4 spu_genb(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_bg((qword)(b), (qword)(a))));\n+}\n+\n+static __inline vec_int4 spu_genb(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_bg((qword)(b), (qword)(a))));\n+}\n+\n+/* spu_genbx\n+ * =========\n+ */\n+static __inline vec_uint4 spu_genbx(vec_uint4 a, vec_uint4 b, vec_uint4 c)\n+{\n+  return ((vec_uint4)(si_bgx((qword)(b), (qword)(a), (qword)(c))));\n+}\n+\n+static __inline vec_int4 spu_genbx(vec_int4 a, vec_int4 b, vec_int4 c)\n+{\n+  return ((vec_int4)(si_bgx((qword)(b), (qword)(a), (qword)(c))));\n+}\n+\n+\n+/* spu_genc\n+ * ========\n+ */\n+static __inline vec_uint4 spu_genc(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_cg((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_genc(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_cg((qword)(a), (qword)(b))));\n+}\n+\n+/* spu_gencx\n+ * =========\n+ */\n+static __inline vec_uint4 spu_gencx(vec_uint4 a, vec_uint4 b, vec_uint4 c)\n+{\n+  return ((vec_uint4)(si_cgx((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+static __inline vec_int4 spu_gencx(vec_int4 a, vec_int4 b, vec_int4 c)\n+{\n+  return ((vec_int4)(si_cgx((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+/* spu_hcmpeq\n+ * ========\n+ */\n+#define spu_hcmpeq(_a, _b)\tif (_a == _b) { SPU_HALT_ACTION; };\n+\n+\n+/* spu_hcmpgt\n+ * ========\n+ */\n+#define spu_hcmpgt(_a, _b)\tif (_a > _b) { SPU_HALT_ACTION; };\n+\n+\n+/* spu_idisable\n+ * ============\n+ */\n+#define spu_idisable()\t\tSPU_UNSUPPORTED_ACTION\n+\n+\n+/* spu_ienable\n+ * ===========\n+ */\n+#define spu_ienable()\t\tSPU_UNSUPPORTED_ACTION\n+\n+\n+/* spu_insert\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_insert(unsigned char a, vec_uchar16 b, int element)\n+{\n+  union {\n+    vec_uchar16 v;\n+    unsigned char c[16];\n+  } in;\n+\n+  in.v = b;\n+  in.c[element & 15] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_char16 spu_insert(signed char a, vec_char16 b, int element)\n+{\n+  return ((vec_char16)spu_insert((unsigned char)(a), (vec_uchar16)(b), element));\n+}\n+\n+static __inline vec_ushort8 spu_insert(unsigned short a, vec_ushort8 b, int element)\n+{\n+  union {\n+    vec_ushort8 v;\n+    unsigned short s[8];\n+  } in;\n+\n+  in.v = b;\n+  in.s[element & 7] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_short8 spu_insert(signed short a, vec_short8 b, int element)\n+{\n+  return ((vec_short8)spu_insert((unsigned short)(a), (vec_ushort8)(b), element));\n+}\n+\n+static __inline vec_uint4 spu_insert(unsigned int a, vec_uint4 b, int element)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned int i[4];\n+  } in;\n+\n+  in.v = b;\n+  in.i[element & 3] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_int4 spu_insert(signed int a, vec_int4 b, int element)\n+{\n+  return ((vec_int4)spu_insert((unsigned int)(a), (vec_uint4)(b), element));\n+}\n+\n+static __inline vec_float4 spu_insert(float a, vec_float4 b, int element)\n+{\n+  union {\n+    vec_float4 v;\n+    float f[4];\n+  } in;\n+\n+  in.v = b;\n+  in.f[element & 3] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_ullong2 spu_insert(unsigned long long a, vec_ullong2 b, int element)\n+{\n+  union {\n+    vec_ullong2 v;\n+    unsigned long long l[2];\n+  } in;\n+\n+  in.v = b;\n+  in.l[element & 1] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_llong2 spu_insert(signed long long a, vec_llong2 b, int element)\n+{\n+  return ((vec_llong2)spu_insert((unsigned long long)(a), (vec_ullong2)(b), element));\n+}\n+\n+static __inline vec_double2 spu_insert(double a, vec_double2 b, int element)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } in;\n+\n+  in.v = b;\n+  in.d[element & 1] = a;\n+  return (in.v);\n+}\n+\n+\n+/* spu_madd\n+ * ========\n+ */\n+static __inline vec_int4 spu_madd(vec_short8 a, vec_short8 b, vec_int4 c)\n+{\n+  return ((vec_int4)(si_mpya((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+static __inline vec_float4 spu_madd(vec_float4 a, vec_float4 b, vec_float4 c)\n+{\n+  return ((vec_float4)(si_fma((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+static __inline vec_double2 spu_madd(vec_double2 a, vec_double2 b, vec_double2 c)\n+{\n+  return ((vec_double2)(si_dfma((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+/* spu_maskb\n+ * ========\n+ */\n+#define spu_maskb(_a)\t(vec_uchar16)(si_fsmb(si_from_int((int)(_a))))\n+\n+/* spu_maskh\n+ * ========\n+ */\n+#define spu_maskh(_a)\t(vec_ushort8)(si_fsmh(si_from_int((int)(_a))))\n+\n+\n+/* spu_maskw\n+ * ========\n+ */\n+#define spu_maskw(_a)\t(vec_uint4)(si_fsm(si_from_int((int)(_a))))\n+\n+\n+/* spu_mfcdma32\n+ * ========\n+ */\n+#define spu_mfcdma32(_ls, _ea, _size, _tagid, _cmd)\n+\n+\n+/* spu_mfcdma64\n+ * ========\n+ */\n+#define spu_mfcdma64(_ls, _eahi, _ealow,  _size, _tagid, _cmd)\n+\n+/* spu_mfcstat\n+ * ========\n+ */\n+#define spu_mfcstat(_type)\t0xFFFFFFFF\n+\n+\n+\n+/* spu_mffpscr\n+ * ===========\n+ */\n+#define spu_mffpscr()\t\t(vec_uint4)(si_fscrrd())\n+\n+\n+/* spu_mfspr\n+ * ========\n+ */\n+\n+#define spu_mfspr(_reg)\t\tsi_to_uint(si_mfspr(_reg))\n+\n+\n+\n+/* spu_mhhadd\n+ * ==========\n+ */\n+static __inline vec_int4 spu_mhhadd(vec_short8 a, vec_short8 b, vec_int4 c)\n+{\n+  return ((vec_int4)(si_mpyhha((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+static __inline vec_uint4 spu_mhhadd(vec_ushort8 a, vec_ushort8 b, vec_uint4 c)\n+{\n+  return ((vec_uint4)(si_mpyhhau((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+/* spu_msub\n+ * ========\n+ */\n+static __inline vec_float4 spu_msub(vec_float4 a, vec_float4 b, vec_float4 c)\n+{\n+  return ((vec_float4)(si_fms((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+static __inline vec_double2 spu_msub(vec_double2 a, vec_double2 b, vec_double2 c)\n+{\n+  return ((vec_double2)(si_dfms((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+/* spu_mtfpscr\n+ * ===========\n+ */\n+#define spu_mtfpscr(_a)\n+\n+\n+/* spu_mtspr\n+ * ========\n+ */\n+#define spu_mtspr(_reg, _a)\n+\n+\n+/* spu_mul\n+ * ========\n+ */\n+static __inline vec_float4 spu_mul(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_fm((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_double2 spu_mul(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_dfm((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_mulh\n+ * ========\n+ */\n+static __inline vec_int4 spu_mulh(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_int4)(si_mpyh((qword)(a), (qword)(b))));\n+}\n+\n+/* spu_mule\n+ * =========\n+ */\n+#define spu_mule(_a, _b)\tvec_mule(_a, _b)\n+\n+\n+\n+/* spu_mulo\n+ * ========\n+ */\n+static __inline vec_int4 spu_mulo(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_int4)(si_mpy((qword)(a), (qword)(b))));\n+}\n+\n+\n+static __inline vec_uint4 spu_mulo(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_uint4)(si_mpyu((qword)(a), (qword)(b))));\n+}\n+\n+\n+static __inline vec_int4 spu_mulo(vec_short8 a, short b)\n+{\n+  return ((vec_int4)(si_mpyi((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_mulo(vec_ushort8 a, unsigned short b)\n+{\n+  return ((vec_uint4)(si_mpyui((qword)(a), b)));\n+}\n+\n+\n+/* spu_mulsr\n+ * =========\n+ */\n+static __inline vec_int4 spu_mulsr(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_int4)(si_mpys((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_nand\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_nand(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_char16 spu_nand(vec_char16 a, vec_char16 b)\n+{\n+  return ((vec_char16)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_nand(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_nand(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_nand(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_nand(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_float4 spu_nand(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ullong2 spu_nand(vec_ullong2 a, vec_ullong2 b)\n+{\n+  return ((vec_ullong2)(si_nand((qword)(a), (qword)(b)))); \n+}\n+\n+static __inline vec_llong2 spu_nand(vec_llong2 a, vec_llong2 b)\n+{\n+  return ((vec_llong2)(si_nand((qword)(a), (qword)(b)))); \n+}\n+\n+static __inline vec_double2 spu_nand(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_nand((qword)(a), (qword)(b))));\n+}\n+\n+\n+/* spu_nmadd\n+ * =========\n+ */\n+static __inline vec_double2 spu_nmadd(vec_double2 a, vec_double2 b, vec_double2 c)\n+{\n+  return ((vec_double2)(si_dfnma((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+/* spu_nmsub\n+ * =========\n+ */\n+static __inline vec_float4 spu_nmsub(vec_float4 a, vec_float4 b, vec_float4 c)\n+{\n+  return ((vec_float4)(si_fnms((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+static __inline vec_double2 spu_nmsub(vec_double2 a, vec_double2 b, vec_double2 c)\n+{\n+  return ((vec_double2)(si_dfnms((qword)(a), (qword)(b), (qword)(c))));\n+}\n+\n+\n+/* spu_nor\n+ * =======\n+ */\n+#define spu_nor(_a, _b)\t\tvec_nor(_a, _b)\n+\n+\n+/* spu_or\n+ * ======\n+ */\n+static __inline vec_uchar16 spu_or(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_char16 spu_or(vec_char16 a, vec_char16 b)\n+{\n+  return ((vec_char16)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_or(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_or(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_or(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_or(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_float4 spu_or(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ullong2 spu_or(vec_ullong2 a, vec_ullong2 b)\n+{\n+  return ((vec_ullong2)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_llong2 spu_or(vec_llong2 a, vec_llong2 b)\n+{\n+  return ((vec_llong2)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_double2 spu_or(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_or((qword)(a), (qword)(b))));\n+}\n+\n+\n+static __inline vec_uchar16 spu_or(vec_uchar16 a, unsigned char b)\n+{\n+  return ((vec_uchar16)(si_orbi((qword)(a), b)));\n+}\n+\n+static __inline vec_char16 spu_or(vec_char16 a, signed char b)\n+{\n+  return ((vec_char16)(si_orbi((qword)(a), (unsigned char)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_or(vec_ushort8 a, unsigned short b)\n+{\n+  return ((vec_ushort8)(si_orhi((qword)(a), b)));\n+}\n+\n+static __inline vec_short8 spu_or(vec_short8 a, signed short b)\n+{\n+  return ((vec_short8)(si_orhi((qword)(a), (unsigned short)(b))));\n+}\n+\n+static __inline vec_uint4 spu_or(vec_uint4 a, unsigned int b)\n+{\n+  return ((vec_uint4)(si_ori((qword)(a), b)));\n+}\n+\n+static __inline vec_int4 spu_or(vec_int4 a, signed int b)\n+{\n+  return ((vec_int4)(si_ori((qword)(a), (unsigned int)(b))));\n+}\n+\n+\n+/* spu_orc\n+ * =======\n+ */\n+#define spu_orc(_a, _b)\t\tvec_or(_a, vec_nor(_b, _b))\n+\n+\n+/* spu_orx\n+ * =======\n+ */\n+static __inline vec_uint4 spu_orx(vec_uint4 a)\n+{\n+  return ((vec_uint4)(si_orx((qword)(a))));\n+}\n+\n+static __inline vec_int4 spu_orx(vec_int4 a)\n+{\n+  return ((vec_int4)(si_orx((qword)(a))));\n+}\n+\n+\n+/* spu_promote\n+ * ===========\n+ */\n+static __inline vec_uchar16 spu_promote(unsigned char a, int element)\n+{\n+  union {\n+    vec_uchar16 v;\n+    unsigned char c[16];\n+  } in;\n+\n+  in.c[element & 15] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_char16 spu_promote(signed char a, int element)\n+{\n+  union {\n+    vec_char16 v;\n+    signed char c[16];\n+  } in;\n+\n+  in.c[element & 15] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_ushort8 spu_promote(unsigned short a, int element)\n+{\n+  union {\n+    vec_ushort8 v;\n+    unsigned short s[8];\n+  } in;\n+\n+  in.s[element & 7] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_short8 spu_promote(signed short a, int element)\n+{\n+  union {\n+    vec_short8 v;\n+    signed short s[8];\n+  } in;\n+\n+  in.s[element & 7] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_uint4 spu_promote(unsigned int a, int element)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned int i[4];\n+  } in;\n+\n+  in.i[element & 3] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_int4 spu_promote(signed int a, int element)\n+{\n+  union {\n+    vec_int4 v;\n+    signed int i[4];\n+  } in;\n+\n+  in.i[element & 3] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_float4 spu_promote(float a, int element)\n+{\n+  union {\n+    vec_float4 v;\n+    float f[4];\n+  } in;\n+\n+  in.f[element & 3] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_ullong2 spu_promote(unsigned long long a, int element)\n+{\n+  union {\n+    vec_ullong2 v;\n+    unsigned long long l[2];\n+  } in;\n+\n+  in.l[element & 1] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_llong2 spu_promote(signed long long a, int element)\n+{\n+  union {\n+    vec_llong2 v;\n+    signed long long l[2];\n+  } in;\n+\n+  in.l[element & 1] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_double2 spu_promote(double a, int element)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } in;\n+\n+  in.d[element & 1] = a;\n+  return (in.v);\n+}\n+\n+/* spu_re\n+ * ======\n+ */\n+#define spu_re(_a)\t\tvec_re(_a)\n+\n+\n+/* spu_readch\n+ * ==========\n+ */\n+#define spu_readch(_channel)\t\t0\t/* not mappable */\n+\n+\n+/* spu_readchcnt\n+ * =============\n+ */\n+#define spu_readchcnt(_channel)\t\t0\t/* not mappable */\n+\n+\n+/* spu_readchqw\n+ * ============\n+ */\n+#define spu_readchqw(_channel) __extension__ ({ vec_uint4 result = { 0, 0, 0, 0 }; result; })\n+\n+/* spu_rl\n+ * ======\n+ */\n+static __inline vec_ushort8 spu_rl(vec_ushort8 a, vec_short8 b)\n+{\n+  return ((vec_ushort8)(si_roth((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_rl(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_roth((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_rl(vec_uint4 a, vec_int4 b)\n+{\n+  return ((vec_uint4)(si_rot((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_rl(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_rot((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_rl(vec_ushort8 a, int b)\n+{\n+  return ((vec_ushort8)(si_rothi((qword)(a), b)));\n+}\n+\n+static __inline vec_short8 spu_rl(vec_short8 a, int b)\n+{\n+  return ((vec_short8)(si_rothi((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_rl(vec_uint4 a, int b)\n+{\n+  return ((vec_uint4)(si_roti((qword)(a), b)));\n+}\n+\n+static __inline vec_int4 spu_rl(vec_int4 a, int b)\n+{\n+  return ((vec_int4)(si_roti((qword)(a), b)));\n+}\n+\n+\n+/* spu_rlmask\n+ * ==========\n+ */\n+static __inline vec_ushort8 spu_rlmask(vec_ushort8 a, vec_short8 b)\n+{\n+  return ((vec_ushort8)(si_rothm((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_rlmask(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_rothm((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_rlmask(vec_uint4 a, vec_int4 b)\n+{\n+  return ((vec_uint4)(si_rotm((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_rlmask(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_rotm((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_rlmask(vec_ushort8 a, int b)\n+{\n+  return ((vec_ushort8)(si_rothmi((qword)(a), b)));\n+}\n+\n+static __inline vec_short8 spu_rlmask(vec_short8 a, int b)\n+{\n+  return ((vec_short8)(si_rothmi((qword)(a), b)));\n+}\n+\n+\n+static __inline vec_uint4 spu_rlmask(vec_uint4 a, int b)\n+{\n+  return ((vec_uint4)(si_rotmi((qword)(a), b)));\n+}\n+\n+static __inline vec_int4 spu_rlmask(vec_int4 a, int b)\n+{\n+  return ((vec_int4)(si_rotmi((qword)(a), b)));\n+}\n+\n+/* spu_rlmaska\n+ * ===========\n+ */\n+static __inline vec_short8 spu_rlmaska(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_rotmah((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_rlmaska(vec_ushort8 a, vec_short8 b)\n+{\n+  return ((vec_ushort8)(si_rotmah((qword)(a), (qword)(b))));\n+}\n+\n+\n+static __inline vec_int4 spu_rlmaska(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_rotma((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_rlmaska(vec_uint4 a, vec_int4 b)\n+{\n+  return ((vec_uint4)(si_rotma((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_rlmaska(vec_ushort8 a, int b)\n+{\n+  return ((vec_ushort8)(si_rotmahi((qword)(a), b)));\n+}\n+\n+static __inline vec_short8 spu_rlmaska(vec_short8 a, int b)\n+{\n+  return ((vec_short8)(si_rotmahi((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_rlmaska(vec_uint4 a, int b)\n+{\n+  return ((vec_uint4)(si_rotmai((qword)(a), b)));\n+}\n+\n+static __inline vec_int4 spu_rlmaska(vec_int4 a, int b)\n+{\n+  return ((vec_int4)(si_rotmai((qword)(a), b)));\n+}\n+\n+\n+/* spu_rlmaskqw\n+ * ============\n+ */\n+static __inline vec_uchar16 spu_rlmaskqw(vec_uchar16 a, int count)\n+{\n+  return ((vec_uchar16)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_char16 spu_rlmaskqw(vec_char16 a, int count)\n+{\n+  return ((vec_char16)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ushort8 spu_rlmaskqw(vec_ushort8 a, int count)\n+{\n+  return ((vec_ushort8)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_short8 spu_rlmaskqw(vec_short8 a, int count)\n+{\n+  return ((vec_short8)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_uint4 spu_rlmaskqw(vec_uint4 a, int count)\n+{\n+  return ((vec_uint4)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_int4 spu_rlmaskqw(vec_int4 a, int count)\n+{\n+  return ((vec_int4)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_float4 spu_rlmaskqw(vec_float4 a, int count)\n+{\n+  return ((vec_float4)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ullong2 spu_rlmaskqw(vec_ullong2 a, int count)\n+{\n+  return ((vec_ullong2)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_llong2 spu_rlmaskqw(vec_llong2 a, int count)\n+{\n+  return ((vec_llong2)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_double2 spu_rlmaskqw(vec_double2 a, int count)\n+{\n+  return ((vec_double2)(si_rotqmbi((qword)(a), si_from_int(count))));\n+}\n+\n+/* spu_rlmaskqwbyte\n+ * ================\n+ */\n+static __inline vec_uchar16 spu_rlmaskqwbyte(vec_uchar16 a, int count)\n+{\n+  return ((vec_uchar16)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_char16 spu_rlmaskqwbyte(vec_char16 a, int count)\n+{\n+  return ((vec_char16)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ushort8 spu_rlmaskqwbyte(vec_ushort8 a, int count)\n+{\n+  return ((vec_ushort8)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_short8 spu_rlmaskqwbyte(vec_short8 a, int count)\n+{\n+  return ((vec_short8)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_uint4 spu_rlmaskqwbyte(vec_uint4 a, int count)\n+{\n+  return ((vec_uint4)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_int4 spu_rlmaskqwbyte(vec_int4 a, int count)\n+{\n+  return ((vec_int4)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_float4 spu_rlmaskqwbyte(vec_float4 a, int count)\n+{\n+  return ((vec_float4)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ullong2 spu_rlmaskqwbyte(vec_ullong2 a, int count)\n+{\n+  return ((vec_ullong2)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_llong2 spu_rlmaskqwbyte(vec_llong2 a, int count)\n+{\n+  return ((vec_llong2)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_double2 spu_rlmaskqwbyte(vec_double2 a, int count)\n+{\n+  return ((vec_double2)(si_rotqmby((qword)(a), si_from_int(count))));\n+}\n+\n+/* spu_rlmaskqwbytebc\n+ * ==================\n+ */\n+static __inline vec_uchar16 spu_rlmaskqwbytebc(vec_uchar16 a, int count)\n+{\n+  return ((vec_uchar16)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_char16 spu_rlmaskqwbytebc(vec_char16 a, int count)\n+{\n+  return ((vec_char16)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ushort8 spu_rlmaskqwbytebc(vec_ushort8 a, int count)\n+{\n+  return ((vec_ushort8)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_short8 spu_rlmaskqwbytebc(vec_short8 a, int count)\n+{\n+  return ((vec_short8)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_uint4 spu_rlmaskqwbytebc(vec_uint4 a, int count)\n+{\n+  return ((vec_uint4)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_int4 spu_rlmaskqwbytebc(vec_int4 a, int count)\n+{\n+  return ((vec_int4)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_float4 spu_rlmaskqwbytebc(vec_float4 a, int count)\n+{\n+  return ((vec_float4)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ullong2 spu_rlmaskqwbytebc(vec_ullong2 a, int count)\n+{\n+  return ((vec_ullong2)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_llong2 spu_rlmaskqwbytebc(vec_llong2 a, int count)\n+{\n+  return ((vec_llong2)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_double2 spu_rlmaskqwbytebc(vec_double2 a, int count)\n+{\n+  return ((vec_double2)(si_rotqmbybi((qword)(a), si_from_int(count))));\n+}\n+\n+\n+/* spu_rlqwbyte\n+ * ============\n+ */\n+static __inline vec_uchar16 spu_rlqwbyte(vec_uchar16 a, int count)\n+{\n+  return ((vec_uchar16)(si_rotqby((qword)(a), si_from_int(count))));\n+}  \n+\n+static __inline vec_char16 spu_rlqwbyte(vec_char16 a, int count)\n+{\n+  return ((vec_char16)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ushort8 spu_rlqwbyte(vec_ushort8 a, int count)\n+{\n+  return ((vec_ushort8)(si_rotqby((qword)(a), si_from_int(count))));\n+}  \n+\n+static __inline vec_short8 spu_rlqwbyte(vec_short8 a, int count)\n+{\n+  return ((vec_short8)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_uint4 spu_rlqwbyte(vec_uint4 a, int count)\n+{\n+  return ((vec_uint4)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_int4 spu_rlqwbyte(vec_int4 a, int count)\n+{\n+  return ((vec_int4)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_float4 spu_rlqwbyte(vec_float4 a, int count)\n+{\n+  return ((vec_float4)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ullong2 spu_rlqwbyte(vec_ullong2 a, int count)\n+{\n+  return ((vec_ullong2)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_llong2 spu_rlqwbyte(vec_llong2 a, int count)\n+{\n+  return ((vec_llong2)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_double2 spu_rlqwbyte(vec_double2 a, int count)\n+{\n+  return ((vec_double2)(si_rotqby((qword)(a), si_from_int(count))));\n+}\n+\n+\n+/* spu_rlqwbytebc\n+ * ==============\n+ */\n+static __inline vec_uchar16 spu_rlqwbytebc(vec_uchar16 a, int count)\n+{\n+  return ((vec_uchar16)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_char16 spu_rlqwbytebc(vec_char16 a, int count)\n+{\n+  return ((vec_char16)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ushort8 spu_rlqwbytebc(vec_ushort8 a, int count)\n+{\n+  return ((vec_ushort8)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_short8 spu_rlqwbytebc(vec_short8 a, int count)\n+{\n+  return ((vec_short8)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_uint4 spu_rlqwbytebc(vec_uint4 a, int count)\n+{\n+  return ((vec_uint4)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_int4 spu_rlqwbytebc(vec_int4 a, int count)\n+{\n+  return ((vec_int4)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_float4 spu_rlqwbytebc(vec_float4 a, int count)\n+{\n+  return ((vec_float4)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ullong2 spu_rlqwbytebc(vec_ullong2 a, int count)\n+{\n+  return ((vec_ullong2)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_llong2 spu_rlqwbytebc(vec_llong2 a, int count)\n+{\n+  return ((vec_llong2)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_double2 spu_rlqwbytebc(vec_double2 a, int count)\n+{\n+  return ((vec_double2)(si_rotqbybi((qword)(a), si_from_int(count))));\n+}\n+\n+/* spu_rlqw\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_rlqw(vec_uchar16 a, int count)\n+{\n+  return ((vec_uchar16)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_char16 spu_rlqw(vec_char16 a, int count)\n+{\n+  return ((vec_char16)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ushort8 spu_rlqw(vec_ushort8 a, int count)\n+{\n+  return ((vec_ushort8)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_short8 spu_rlqw(vec_short8 a, int count)\n+{\n+  return ((vec_short8)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_uint4 spu_rlqw(vec_uint4 a, int count)\n+{\n+  return ((vec_uint4)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_int4 spu_rlqw(vec_int4 a, int count)\n+{\n+  return ((vec_int4)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_float4 spu_rlqw(vec_float4 a, int count)\n+{\n+  return ((vec_float4)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_ullong2 spu_rlqw(vec_ullong2 a, int count)\n+{\n+  return ((vec_ullong2)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_llong2 spu_rlqw(vec_llong2 a, int count)\n+{\n+  return ((vec_llong2)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+static __inline vec_double2 spu_rlqw(vec_double2 a, int count)\n+{\n+  return ((vec_double2)(si_rotqbi((qword)(a), si_from_int(count))));\n+}\n+\n+/* spu_roundtf\n+ * ===========\n+ */\n+static __inline vec_float4 spu_roundtf(vec_double2 a)\n+{\n+  return ((vec_float4)(si_frds((qword)(a))));\n+}\n+\n+\n+/* spu_rsqrte\n+ * ==========\n+ */\n+#define spu_rsqrte(_a)\t\tvec_rsqrte(_a)\n+\n+\n+/* spu_sel\n+ * =======\n+ */\n+static __inline vec_uchar16 spu_sel(vec_uchar16 a, vec_uchar16 b, vec_uchar16 pattern)\n+{\n+  return ((vec_uchar16)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_char16 spu_sel(vec_char16 a, vec_char16 b, vec_uchar16 pattern)\n+{\n+  return ((vec_char16)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_ushort8 spu_sel(vec_ushort8 a, vec_ushort8 b, vec_ushort8 pattern)\n+{\n+  return ((vec_ushort8)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_short8 spu_sel(vec_short8 a, vec_short8 b, vec_ushort8 pattern)\n+{\n+  return ((vec_short8)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_uint4 spu_sel(vec_uint4 a, vec_uint4 b, vec_uint4 pattern)\n+{\n+  return ((vec_uint4)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_int4 spu_sel(vec_int4 a, vec_int4 b, vec_uint4 pattern)\n+{\n+  return ((vec_int4)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_float4 spu_sel(vec_float4 a, vec_float4 b, vec_uint4 pattern)\n+{\n+  return ((vec_float4)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_ullong2 spu_sel(vec_ullong2 a, vec_ullong2 b, vec_ullong2 pattern)\n+{\n+  return ((vec_ullong2)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_llong2 spu_sel(vec_llong2 a, vec_llong2 b, vec_ullong2 pattern)\n+{\n+  return ((vec_llong2)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_double2 spu_sel(vec_double2 a, vec_double2 b, vec_ullong2 pattern)\n+{\n+  return ((vec_double2)(si_selb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+\n+\n+/* spu_shuffle\n+ * ===========\n+ */\n+static __inline vec_uchar16 spu_shuffle(vec_uchar16 a, vec_uchar16 b, vec_uchar16 pattern)\n+{\n+  return ((vec_uchar16)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_char16 spu_shuffle(vec_char16 a, vec_char16 b, vec_uchar16 pattern)\n+{\n+  return ((vec_char16)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_ushort8 spu_shuffle(vec_ushort8 a, vec_ushort8 b, vec_uchar16 pattern)\n+{\n+  return ((vec_ushort8)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_short8 spu_shuffle(vec_short8 a, vec_short8 b, vec_uchar16 pattern)\n+{\n+  return ((vec_short8)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_uint4 spu_shuffle(vec_uint4 a, vec_uint4 b, vec_uchar16 pattern)\n+{\n+  return ((vec_uint4)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_int4 spu_shuffle(vec_int4 a, vec_int4 b, vec_uchar16 pattern)\n+{\n+  return ((vec_int4)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_float4 spu_shuffle(vec_float4 a, vec_float4 b, vec_uchar16 pattern)\n+{\n+  return ((vec_float4)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_ullong2 spu_shuffle(vec_ullong2 a, vec_ullong2 b, vec_uchar16 pattern)\n+{\n+  return ((vec_ullong2)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_llong2 spu_shuffle(vec_llong2 a, vec_llong2 b, vec_uchar16 pattern)\n+{\n+  return ((vec_llong2)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+static __inline vec_double2 spu_shuffle(vec_double2 a, vec_double2 b, vec_uchar16 pattern)\n+{\n+  return ((vec_double2)(si_shufb((qword)(a), (qword)(b), (qword)(pattern))));\n+}\n+\n+\n+/* spu_sl\n+ * ======\n+ */\n+static __inline vec_ushort8 spu_sl(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_shlh((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_sl(vec_short8 a, vec_ushort8 b)\n+{\n+  return ((vec_short8)(si_shlh((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_sl(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_shl((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_sl(vec_int4 a, vec_uint4 b)\n+{\n+  return ((vec_int4)(si_shl((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_sl(vec_ushort8 a, unsigned int b)\n+{\n+  return ((vec_ushort8)(si_shlhi((qword)(a), b)));\n+}\n+\n+static __inline vec_short8 spu_sl(vec_short8 a, unsigned int b)\n+{\n+  return ((vec_short8)(si_shlhi((qword)(a), b)));\n+}\n+\n+static __inline vec_uint4 spu_sl(vec_uint4 a, unsigned int b)\n+{\n+  return ((vec_uint4)(si_shli((qword)(a), b)));\n+}\n+\n+static __inline vec_int4 spu_sl(vec_int4 a, unsigned int b)\n+{\n+  return ((vec_int4)(si_shli((qword)(a), b)));\n+}\n+\n+\n+/* spu_slqw\n+ * ========\n+ */\n+static __inline vec_uchar16 spu_slqw(vec_uchar16 a, unsigned int count)\n+{\n+  return ((vec_uchar16)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_char16 spu_slqw(vec_char16 a, unsigned int count)\n+{\n+  return ((vec_char16)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_ushort8 spu_slqw(vec_ushort8 a, unsigned int count)\n+{\n+  return ((vec_ushort8)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_short8 spu_slqw(vec_short8 a, unsigned int count)\n+{\n+  return ((vec_short8)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_uint4 spu_slqw(vec_uint4 a, unsigned int count)\n+{\n+  return ((vec_uint4)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_int4 spu_slqw(vec_int4 a, unsigned int count)\n+{\n+  return ((vec_int4)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_float4 spu_slqw(vec_float4 a, unsigned int count)\n+{\n+  return ((vec_float4)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_ullong2 spu_slqw(vec_ullong2 a, unsigned int count)\n+{\n+  return ((vec_ullong2)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_llong2 spu_slqw(vec_llong2 a, unsigned int count)\n+{\n+  return ((vec_llong2)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_double2 spu_slqw(vec_double2 a, unsigned int count)\n+{\n+  return ((vec_double2)(si_shlqbi((qword)(a), si_from_uint(count))));\n+}\n+\n+/* spu_slqwbyte\n+ * ============\n+ */\n+static __inline vec_uchar16 spu_slqwbyte(vec_uchar16 a, unsigned int count)\n+{\n+  return ((vec_uchar16)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_char16 spu_slqwbyte(vec_char16 a, unsigned int count)\n+{\n+  return ((vec_char16)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_ushort8 spu_slqwbyte(vec_ushort8 a, unsigned int count)\n+{\n+  return ((vec_ushort8)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_short8 spu_slqwbyte(vec_short8 a, unsigned int count)\n+{\n+  return ((vec_short8)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_uint4 spu_slqwbyte(vec_uint4 a, unsigned int count)\n+{\n+  return ((vec_uint4)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_int4 spu_slqwbyte(vec_int4 a, unsigned int count)\n+{\n+  return ((vec_int4)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_float4 spu_slqwbyte(vec_float4 a, unsigned int count)\n+{\n+  return ((vec_float4)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_ullong2 spu_slqwbyte(vec_ullong2 a, unsigned int count)\n+{\n+  return ((vec_ullong2)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_llong2 spu_slqwbyte(vec_llong2 a, unsigned int count)\n+{\n+  return ((vec_llong2)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_double2 spu_slqwbyte(vec_double2 a, unsigned int count)\n+{\n+  return ((vec_double2)(si_shlqby((qword)(a), si_from_uint(count))));\n+}\n+\n+/* spu_slqwbytebc\n+ * ==============\n+ */\n+static __inline vec_uchar16 spu_slqwbytebc(vec_uchar16 a, unsigned int count)\n+{\n+  return ((vec_uchar16)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_char16 spu_slqwbytebc(vec_char16 a, unsigned int count)\n+{\n+  return ((vec_char16)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_ushort8 spu_slqwbytebc(vec_ushort8 a, unsigned int count)\n+{\n+  return ((vec_ushort8)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_short8 spu_slqwbytebc(vec_short8 a, unsigned int count)\n+{\n+  return ((vec_short8)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_uint4 spu_slqwbytebc(vec_uint4 a, unsigned int count)\n+{\n+  return ((vec_uint4)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_int4 spu_slqwbytebc(vec_int4 a, unsigned int count)\n+{\n+  return ((vec_int4)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_float4 spu_slqwbytebc(vec_float4 a, unsigned int count)\n+{\n+  return ((vec_float4)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_ullong2 spu_slqwbytebc(vec_ullong2 a, unsigned int count)\n+{\n+  return ((vec_ullong2)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_llong2 spu_slqwbytebc(vec_llong2 a, unsigned int count)\n+{\n+  return ((vec_llong2)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+static __inline vec_double2 spu_slqwbytebc(vec_double2 a, unsigned int count)\n+{\n+  return ((vec_double2)(si_shlqbybi((qword)(a), si_from_uint(count))));\n+}\n+\n+/* spu_splats\n+ * ==========\n+ */\n+static __inline vec_uchar16 spu_splats(unsigned char a)\n+{\n+  union {\n+    vec_uchar16 v;\n+    unsigned char c[16];\n+  } in;\n+\n+  in.c[0] = a;\n+  return (vec_splat(in.v, 0));\n+}\n+\n+static __inline vec_char16 spu_splats(signed char a)\n+{\n+  return ((vec_char16)spu_splats((unsigned char)(a)));\n+}\n+\n+static __inline vec_ushort8 spu_splats(unsigned short a)\n+{\n+  union {\n+    vec_ushort8 v;\n+    unsigned short s[8];\n+  } in;\n+\n+  in.s[0] = a;\n+  return (vec_splat(in.v, 0));\n+}\n+\n+static __inline vec_short8 spu_splats(signed short a)\n+{\n+  return ((vec_short8)spu_splats((unsigned short)(a)));\n+}\n+\n+static __inline vec_uint4 spu_splats(unsigned int a)\n+{\n+  union {\n+    vec_uint4 v;\n+    unsigned int i[4];\n+  } in;\n+\n+  in.i[0] = a;\n+  return (vec_splat(in.v, 0));\n+}\n+\n+static __inline vec_int4 spu_splats(signed int a)\n+{\n+  return ((vec_int4)spu_splats((unsigned int)(a)));\n+}\n+\n+static __inline vec_float4 spu_splats(float a)\n+{\n+  union {\n+    vec_float4 v;\n+    float f[4];\n+  } in;\n+\n+  in.f[0] = a;\n+  return (vec_splat(in.v, 0));\n+}\n+\n+static __inline vec_ullong2 spu_splats(unsigned long long a)\n+{\n+  union {\n+    vec_ullong2 v;\n+    unsigned long long l[2];\n+  } in;\n+\n+  in.l[0] = a;\n+  in.l[1] = a;\n+  return (in.v);\n+}\n+\n+static __inline vec_llong2 spu_splats(signed long long a)\n+{\n+  return ((vec_llong2)spu_splats((unsigned long long)(a)));\n+}\n+\n+static __inline vec_double2 spu_splats(double a)\n+{\n+  union {\n+    vec_double2 v;\n+    double d[2];\n+  } in;\n+\n+  in.d[0] = a;\n+  in.d[1] = a;\n+  return (in.v);\n+}\n+\n+\n+/* spu_stop\n+ * ========\n+ */\n+#define spu_stop(_type)\tsi_stop(_type)\n+\n+\n+/* spu_sub\n+ * =======\n+ */\n+static __inline vec_ushort8 spu_sub(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_sfh((qword)(b), (qword)(a))));\n+}\n+\n+static __inline vec_short8 spu_sub(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_sfh((qword)(b), (qword)(a))));\n+}\n+\n+static __inline vec_uint4 spu_sub(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_sf((qword)(b), (qword)(a))));\n+}\n+\n+static __inline vec_int4 spu_sub(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_sf((qword)(b), (qword)(a))));\n+}\n+\n+static __inline vec_float4 spu_sub(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_fs((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_double2 spu_sub(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_dfs((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_sub(unsigned int a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_sfi((qword)b, (int)a)));\n+}\n+\n+static __inline vec_int4 spu_sub(signed int a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_sfi((qword)b, (int)a)));\n+}\n+\n+static __inline vec_ushort8 spu_sub(unsigned short a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_sfhi((qword)b, (short)a)));\n+}\n+\n+static __inline vec_short8 spu_sub(signed short a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_sfhi((qword)b, (short)a)));\n+}\n+\n+/* spu_subx\n+ * ========\n+ */\n+static __inline vec_uint4 spu_subx(vec_uint4 a, vec_uint4 b, vec_uint4 c)\n+{\n+  return ((vec_uint4)(si_sfx((qword)(b), (qword)(a), (qword)(c))));\n+}\n+\n+static __inline vec_int4 spu_subx(vec_int4 a, vec_int4 b, vec_int4 c)\n+{\n+  return ((vec_int4)(si_sfx((qword)(b), (qword)(a), (qword)(c))));\n+}\n+\n+/* spu_sumb\n+ * ========\n+ */\n+static __inline vec_ushort8 spu_sumb(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_ushort8)(si_sumb((qword)(a), (qword)(b))));\n+}  \n+\n+\n+/* spu_sync\n+ * spu_sync_c\n+ * ========\n+ */\n+#define spu_sync()\t/* do nothing */\n+\n+#define spu_sync_c()\t/* do nothing */\n+\n+\n+/* spu_writech\n+ * ===========\n+ */\n+#define spu_writech(_channel, _a)\t/* not mappable */\n+\n+/* spu_writechqw\n+ * =============\n+ */\n+#define spu_writechqw(_channel, _a)\t/* not mappable */\n+\n+\n+/* spu_xor\n+ * =======\n+ */\n+static __inline vec_uchar16 spu_xor(vec_uchar16 a, vec_uchar16 b)\n+{\n+  return ((vec_uchar16)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_char16 spu_xor(vec_char16 a, vec_char16 b)\n+{\n+  return ((vec_char16)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_xor(vec_ushort8 a, vec_ushort8 b)\n+{\n+  return ((vec_ushort8)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_short8 spu_xor(vec_short8 a, vec_short8 b)\n+{\n+  return ((vec_short8)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uint4 spu_xor(vec_uint4 a, vec_uint4 b)\n+{\n+  return ((vec_uint4)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_int4 spu_xor(vec_int4 a, vec_int4 b)\n+{\n+  return ((vec_int4)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_float4 spu_xor(vec_float4 a, vec_float4 b)\n+{\n+  return ((vec_float4)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_ullong2 spu_xor(vec_ullong2 a, vec_ullong2 b)\n+{\n+  return ((vec_ullong2)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_llong2 spu_xor(vec_llong2 a, vec_llong2 b)\n+{\n+  return ((vec_llong2)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_double2 spu_xor(vec_double2 a, vec_double2 b)\n+{\n+  return ((vec_double2)(si_xor((qword)(a), (qword)(b))));\n+}\n+\n+static __inline vec_uchar16 spu_xor(vec_uchar16 a, unsigned char b)\n+{\n+  return ((vec_uchar16)(si_xorbi((qword)(a), b)));\n+}\n+\n+static __inline vec_char16 spu_xor(vec_char16 a, signed char b)\n+{\n+  return ((vec_char16)(si_xorbi((qword)(a), (unsigned char)(b))));\n+}\n+\n+static __inline vec_ushort8 spu_xor(vec_ushort8 a, unsigned short b)\n+{\n+  return ((vec_ushort8)(si_xorhi((qword)(a), b)));\n+}\n+\n+static __inline vec_short8 spu_xor(vec_short8 a, signed short b)\n+{\n+  return ((vec_short8)(si_xorhi((qword)(a), (unsigned short)(b))));\n+}\n+\n+static __inline vec_uint4 spu_xor(vec_uint4 a, unsigned int b)\n+{\n+  return ((vec_uint4)(si_xori((qword)(a), b)));\n+}\n+\n+static __inline vec_int4 spu_xor(vec_int4 a, signed int b)\n+{\n+  return ((vec_int4)(si_xori((qword)(a), (unsigned int)(b))));\n+}\n+\n+#endif /* !__SPU__ */\n+#endif /* __cplusplus */\n+#endif /* !_SPU2VMX_H_ */"}, {"sha": "eabe78b6996f5fc0965102b82250c28cb6413553", "filename": "gcc/config/rs6000/vec_types.h", "status": "added", "additions": 54, "deletions": 0, "changes": 54, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig%2Frs6000%2Fvec_types.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Fconfig%2Frs6000%2Fvec_types.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fvec_types.h?ref=437cc56a07a35aab6bd51ed66b00fc9549076f97", "patch": "@@ -0,0 +1,54 @@\n+/* Cell single token vector types\n+   Copyright (C) 2007 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source files \n+   compiled by GCC, this header file does not by itself cause  the resulting \n+   executable to be covered by the GNU General Public License.  This exception \n+   does not however invalidate any other reasons why the executable file might be \n+   covered by the GNU General Public License.  */ \n+\n+/* Single token vector data types for the PowerPC SIMD/Vector Multi-media \n+   eXtension */\n+\n+#ifndef _VEC_TYPES_H_\n+#define _VEC_TYPES_H_\t1\n+\n+#define qword\t\t__vector unsigned char\n+\n+#define vec_uchar16\t__vector unsigned char\n+#define vec_char16\t__vector signed char\n+#define vec_bchar16\t__vector bool char\n+\n+#define vec_ushort8\t__vector unsigned short\n+#define vec_short8\t__vector signed short\n+#define vec_bshort8\t__vector bool short\n+\n+#define vec_pixel8\t__vector pixel\n+\n+#define vec_uint4\t__vector unsigned int\n+#define vec_int4\t__vector signed int\n+#define vec_bint4\t__vector bool int\n+\n+#define vec_float4\t__vector float\n+\n+#define vec_ullong2\t__vector bool char\n+#define vec_llong2\t__vector bool short\n+\n+#define vec_double2\t__vector bool int\n+\n+#endif /* _VEC_TYPES_H_ */"}, {"sha": "3ae76e319e0b5ace404ef19b8f8615f9fcac7729", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=437cc56a07a35aab6bd51ed66b00fc9549076f97", "patch": "@@ -1,3 +1,7 @@\n+2007-09-04  Andrew Pinski  <andrew_pinski@playstation.sony.com>\n+\n+\t* g++.dg/other/spu2vmx-1.C: New test.\n+\n 2007-09-05  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR tree-optimization/33017"}, {"sha": "becd1dcabeb4bfb7dafdb3bbb30a85d16939705b", "filename": "gcc/testsuite/g++.dg/other/spu2vmx-1.C", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fother%2Fspu2vmx-1.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/437cc56a07a35aab6bd51ed66b00fc9549076f97/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fother%2Fspu2vmx-1.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fother%2Fspu2vmx-1.C?ref=437cc56a07a35aab6bd51ed66b00fc9549076f97", "patch": "@@ -0,0 +1,15 @@\n+/* { dg-do compile { target powerpc*-*-* } } */\n+/* { dg-require-effective-target powerpc_altivec_ok } */\n+/* { dg-options \"-maltivec\" } */\n+\n+#include <altivec.h>\n+#include <spu2vmx.h>\n+\n+vec_uint4 f(vec_uint4 a, vec_uint4 b)\n+{\n+  return spu_add(a, b);\n+}\n+vec_float4 f(vec_float4 a, vec_float4 b)\n+{\n+  return spu_add(a, b);\n+}"}]}