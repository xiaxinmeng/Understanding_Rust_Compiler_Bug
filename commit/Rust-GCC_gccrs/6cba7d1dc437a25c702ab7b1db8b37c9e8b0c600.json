{"sha": "6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NmNiYTdkMWRjNDM3YTI1YzcwMmFiN2IxZGI4YjM3YzllOGIwYzYwMA==", "commit": {"author": {"name": "Bill Schmidt", "email": "wschmidt@linux.ibm.com", "date": "2021-09-17T15:32:59Z"}, "committer": {"name": "Bill Schmidt", "email": "wschmidt@linux.ibm.com", "date": "2021-09-17T15:53:53Z"}, "message": "rs6000: Handle some recent MMA builtin changes\n\nPeter Bergner recently added two new builtins __builtin_vsx_lxvp and\n__builtin_vsx_stxvp.  These happened to break a pattern in MMA builtins that\nI had been using to automate gimple folding of MMA builtins.  Previously,\nevery MMA function that could be folded had an associated internal function\nthat it was folded into.  The LXVP/STXVP builtins are just folded directly\ninto memory operations.\n\nInstead of relying on this pattern, this patch adds a new attribute to\nbuiltins called \"mmaint,\" which is set for all MMA builtins that have an\nassociated internal builtin.  The naming convention that adds _INTERNAL to\nthe builtin index name remains.\n\nThe rest of the patch is just duplicating Peter's patch, using the new\nbuiltin infrastructure.\n\n2021-09-17  Bill Schmidt  <wschmidt@linux.ibm.com>\n\ngcc/\n\t* config/rs6000/rs6000-builtin-new.def (ASSEMBLE_ACC): Add mmaint flag.\n\t(ASSEMBLE_PAIR): Likewise.\n\t(BUILD_ACC): Likewise.\n\t(DISASSEMBLE_ACC): Likewise.\n\t(DISASSEMBLE_PAIR): Likewise.\n\t(PMXVBF16GER2): Likewise.\n\t(PMXVBF16GER2NN): Likewise.\n\t(PMXVBF16GER2NP): Likewise.\n\t(PMXVBF16GER2PN): Likewise.\n\t(PMXVBF16GER2PP): Likewise.\n\t(PMXVF16GER2): Likewise.\n\t(PMXVF16GER2NN): Likewise.\n\t(PMXVF16GER2NP): Likewise.\n\t(PMXVF16GER2PN): Likewise.\n\t(PMXVF16GER2PP): Likewise.\n\t(PMXVF32GER): Likewise.\n\t(PMXVF32GERNN): Likewise.\n\t(PMXVF32GERNP): Likewise.\n\t(PMXVF32GERPN): Likewise.\n\t(PMXVF32GERPP): Likewise.\n\t(PMXVF64GER): Likewise.\n\t(PMXVF64GERNN): Likewise.\n\t(PMXVF64GERNP): Likewise.\n\t(PMXVF64GERPN): Likewise.\n\t(PMXVF64GERPP): Likewise.\n\t(PMXVI16GER2): Likewise.\n\t(PMXVI16GER2PP): Likewise.\n\t(PMXVI16GER2S): Likewise.\n\t(PMXVI16GER2SPP): Likewise.\n\t(PMXVI4GER8): Likewise.\n\t(PMXVI4GER8PP): Likewise.\n\t(PMXVI8GER4): Likewise.\n\t(PMXVI8GER4PP): Likewise.\n\t(PMXVI8GER4SPP): Likewise.\n\t(XVBF16GER2): Likewise.\n\t(XVBF16GER2NN): Likewise.\n\t(XVBF16GER2NP): Likewise.\n\t(XVBF16GER2PN): Likewise.\n\t(XVBF16GER2PP): Likewise.\n\t(XVF16GER2): Likewise.\n\t(XVF16GER2NN): Likewise.\n\t(XVF16GER2NP): Likewise.\n\t(XVF16GER2PN): Likewise.\n\t(XVF16GER2PP): Likewise.\n\t(XVF32GER): Likewise.\n\t(XVF32GERNN): Likewise.\n\t(XVF32GERNP): Likewise.\n\t(XVF32GERPN): Likewise.\n\t(XVF32GERPP): Likewise.\n\t(XVF64GER): Likewise.\n\t(XVF64GERNN): Likewise.\n\t(XVF64GERNP): Likewise.\n\t(XVF64GERPN): Likewise.\n\t(XVF64GERPP): Likewise.\n\t(XVI16GER2): Likewise.\n\t(XVI16GER2PP): Likewise.\n\t(XVI16GER2S): Likewise.\n\t(XVI16GER2SPP): Likewise.\n\t(XVI4GER8): Likewise.\n\t(XVI4GER8PP): Likewise.\n\t(XVI8GER4): Likewise.\n\t(XVI8GER4PP): Likewise.\n\t(XVI8GER4SPP): Likewise.\n\t(XXMFACC): Likewise.\n\t(XXMTACC): Likewise.\n\t(XXSETACCZ): Likewise.\n\t(ASSEMBLE_PAIR_V): Likewise.\n\t(BUILD_PAIR): Likewise.\n\t(DISASSEMBLE_PAIR_V): Likewise.\n\t(LXVP): New.\n\t(STXVP): New.\n\t* config/rs6000/rs6000-call.c (rs6000_gimple_fold_new_mma_builtin):\n\tHandle RS6000_BIF_LXVP and RS6000_BIF_STXVP.\n\t* config/rs6000/rs6000-gen-builtins.c (attrinfo): Add ismmaint.\n\t(parse_bif_attrs): Handle ismmaint.\n\t(write_decls): Add bif_mmaint_bit and bif_is_mmaint.\n\t(write_bif_static_init): Handle ismmaint.", "tree": {"sha": "e5bc21b4f5d1d634424001cb010bf312bebe398e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e5bc21b4f5d1d634424001cb010bf312bebe398e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600/comments", "author": null, "committer": null, "parents": [{"sha": "41a34e22f899765652988c53f708143089510461", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/41a34e22f899765652988c53f708143089510461", "html_url": "https://github.com/Rust-GCC/gccrs/commit/41a34e22f899765652988c53f708143089510461"}], "stats": {"total": 224, "additions": 138, "deletions": 86}, "files": [{"sha": "1966516551e6f8b5ab945e9542261a3da72fca1c", "filename": "gcc/config/rs6000/rs6000-builtin-new.def", "status": "modified", "additions": 76, "deletions": 69, "changes": 145, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600/gcc%2Fconfig%2Frs6000%2Frs6000-builtin-new.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600/gcc%2Fconfig%2Frs6000%2Frs6000-builtin-new.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-builtin-new.def?ref=6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600", "patch": "@@ -129,6 +129,7 @@\n ;   mma      Needs special handling for MMA\n ;   quad     MMA instruction using a register quad as an input operand\n ;   pair     MMA instruction using a register pair as an input operand\n+;   mmaint   MMA instruction expanding to internal call at GIMPLE time\n ;   no32bit  Not valid for TARGET_32BIT\n ;   32bit    Requires different handling for TARGET_32BIT\n ;   cpu      This is a \"cpu_is\" or \"cpu_supports\" builtin\n@@ -3584,415 +3585,421 @@\n \n [mma]\n   void __builtin_mma_assemble_acc (v512 *, vuc, vuc, vuc, vuc);\n-    ASSEMBLE_ACC nothing {mma}\n+    ASSEMBLE_ACC nothing {mma,mmaint}\n \n   v512 __builtin_mma_assemble_acc_internal (vuc, vuc, vuc, vuc);\n     ASSEMBLE_ACC_INTERNAL mma_assemble_acc {mma}\n \n   void __builtin_mma_assemble_pair (v256 *, vuc, vuc);\n-    ASSEMBLE_PAIR nothing {mma}\n+    ASSEMBLE_PAIR nothing {mma,mmaint}\n \n   v256 __builtin_mma_assemble_pair_internal (vuc, vuc);\n     ASSEMBLE_PAIR_INTERNAL vsx_assemble_pair {mma}\n \n   void __builtin_mma_build_acc (v512 *, vuc, vuc, vuc, vuc);\n-    BUILD_ACC nothing {mma}\n+    BUILD_ACC nothing {mma,mmaint}\n \n   v512 __builtin_mma_build_acc_internal (vuc, vuc, vuc, vuc);\n     BUILD_ACC_INTERNAL mma_assemble_acc {mma}\n \n   void __builtin_mma_disassemble_acc (void *, v512 *);\n-    DISASSEMBLE_ACC nothing {mma,quad}\n+    DISASSEMBLE_ACC nothing {mma,quad,mmaint}\n \n   vuc __builtin_mma_disassemble_acc_internal (v512, const int<2>);\n     DISASSEMBLE_ACC_INTERNAL mma_disassemble_acc {mma}\n \n   void __builtin_mma_disassemble_pair (void *, v256 *);\n-    DISASSEMBLE_PAIR nothing {mma,pair}\n+    DISASSEMBLE_PAIR nothing {mma,pair,mmaint}\n \n   vuc __builtin_mma_disassemble_pair_internal (v256, const int<2>);\n     DISASSEMBLE_PAIR_INTERNAL vsx_disassemble_pair {mma}\n \n   void __builtin_mma_pmxvbf16ger2 (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVBF16GER2 nothing {mma}\n+    PMXVBF16GER2 nothing {mma,mmaint}\n \n   v512 __builtin_mma_pmxvbf16ger2_internal (vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVBF16GER2_INTERNAL mma_pmxvbf16ger2 {mma}\n \n   void __builtin_mma_pmxvbf16ger2nn (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVBF16GER2NN nothing {mma,quad}\n+    PMXVBF16GER2NN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvbf16ger2nn_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVBF16GER2NN_INTERNAL mma_pmxvbf16ger2nn {mma,quad}\n \n   void __builtin_mma_pmxvbf16ger2np (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVBF16GER2NP nothing {mma,quad}\n+    PMXVBF16GER2NP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvbf16ger2np_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVBF16GER2NP_INTERNAL mma_pmxvbf16ger2np {mma,quad}\n \n   void __builtin_mma_pmxvbf16ger2pn (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVBF16GER2PN nothing {mma,quad}\n+    PMXVBF16GER2PN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvbf16ger2pn_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVBF16GER2PN_INTERNAL mma_pmxvbf16ger2pn {mma,quad}\n \n   void __builtin_mma_pmxvbf16ger2pp (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVBF16GER2PP nothing {mma,quad}\n+    PMXVBF16GER2PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvbf16ger2pp_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVBF16GER2PP_INTERNAL mma_pmxvbf16ger2pp {mma,quad}\n \n   void __builtin_mma_pmxvf16ger2 (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVF16GER2 nothing {mma}\n+    PMXVF16GER2 nothing {mma,mmaint}\n \n   v512 __builtin_mma_pmxvf16ger2_internal (vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVF16GER2_INTERNAL mma_pmxvf16ger2 {mma}\n \n   void __builtin_mma_pmxvf16ger2nn (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVF16GER2NN nothing {mma,quad}\n+    PMXVF16GER2NN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf16ger2nn_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVF16GER2NN_INTERNAL mma_pmxvf16ger2nn {mma,quad}\n \n   void __builtin_mma_pmxvf16ger2np (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVF16GER2NP nothing {mma,quad}\n+    PMXVF16GER2NP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf16ger2np_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVF16GER2NP_INTERNAL mma_pmxvf16ger2np {mma,quad}\n \n   void __builtin_mma_pmxvf16ger2pn (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVF16GER2PN nothing {mma,quad}\n+    PMXVF16GER2PN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf16ger2pn_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVF16GER2PN_INTERNAL mma_pmxvf16ger2pn {mma,quad}\n \n   void __builtin_mma_pmxvf16ger2pp (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVF16GER2PP nothing {mma,quad}\n+    PMXVF16GER2PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf16ger2pp_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVF16GER2PP_INTERNAL mma_pmxvf16ger2pp {mma,quad}\n \n   void __builtin_mma_pmxvf32ger (v512 *, vuc, vuc, const int<4>, const int<4>);\n-    PMXVF32GER nothing {mma}\n+    PMXVF32GER nothing {mma,mmaint}\n \n   v512 __builtin_mma_pmxvf32ger_internal (vuc, vuc, const int<4>, const int<4>);\n     PMXVF32GER_INTERNAL mma_pmxvf32ger {mma}\n \n   void __builtin_mma_pmxvf32gernn (v512 *, vuc, vuc, const int<4>, const int<4>);\n-    PMXVF32GERNN nothing {mma,quad}\n+    PMXVF32GERNN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf32gernn_internal (v512, vuc, vuc, const int<4>, const int<4>);\n     PMXVF32GERNN_INTERNAL mma_pmxvf32gernn {mma,quad}\n \n   void __builtin_mma_pmxvf32gernp (v512 *, vuc, vuc, const int<4>, const int<4>);\n-    PMXVF32GERNP nothing {mma,quad}\n+    PMXVF32GERNP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf32gernp_internal (v512, vuc, vuc, const int<4>, const int<4>);\n     PMXVF32GERNP_INTERNAL mma_pmxvf32gernp {mma,quad}\n \n   void __builtin_mma_pmxvf32gerpn (v512 *, vuc, vuc, const int<4>, const int<4>);\n-    PMXVF32GERPN nothing {mma,quad}\n+    PMXVF32GERPN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf32gerpn_internal (v512, vuc, vuc, const int<4>, const int<4>);\n     PMXVF32GERPN_INTERNAL mma_pmxvf32gerpn {mma,quad}\n \n   void __builtin_mma_pmxvf32gerpp (v512 *, vuc, vuc, const int<4>, const int<4>);\n-    PMXVF32GERPP nothing {mma,quad}\n+    PMXVF32GERPP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf32gerpp_internal (v512, vuc, vuc, const int<4>, const int<4>);\n     PMXVF32GERPP_INTERNAL mma_pmxvf32gerpp {mma,quad}\n \n   void __builtin_mma_pmxvf64ger (v512 *, v256, vuc, const int<4>, const int<2>);\n-    PMXVF64GER nothing {mma,pair}\n+    PMXVF64GER nothing {mma,pair,mmaint}\n \n   v512 __builtin_mma_pmxvf64ger_internal (v256, vuc, const int<4>, const int<2>);\n     PMXVF64GER_INTERNAL mma_pmxvf64ger {mma,pair}\n \n   void __builtin_mma_pmxvf64gernn (v512 *, v256, vuc, const int<4>, const int<2>);\n-    PMXVF64GERNN nothing {mma,pair,quad}\n+    PMXVF64GERNN nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf64gernn_internal (v512, v256, vuc, const int<4>, const int<2>);\n     PMXVF64GERNN_INTERNAL mma_pmxvf64gernn {mma,pair,quad}\n \n   void __builtin_mma_pmxvf64gernp (v512 *, v256, vuc, const int<4>, const int<2>);\n-    PMXVF64GERNP nothing {mma,pair,quad}\n+    PMXVF64GERNP nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf64gernp_internal (v512, v256, vuc, const int<4>, const int<2>);\n     PMXVF64GERNP_INTERNAL mma_pmxvf64gernp {mma,pair,quad}\n \n   void __builtin_mma_pmxvf64gerpn (v512 *, v256, vuc, const int<4>, const int<2>);\n-    PMXVF64GERPN nothing {mma,pair,quad}\n+    PMXVF64GERPN nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf64gerpn_internal (v512, v256, vuc, const int<4>, const int<2>);\n     PMXVF64GERPN_INTERNAL mma_pmxvf64gerpn {mma,pair,quad}\n \n   void __builtin_mma_pmxvf64gerpp (v512 *, v256, vuc, const int<4>, const int<2>);\n-    PMXVF64GERPP nothing {mma,pair,quad}\n+    PMXVF64GERPP nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_pmxvf64gerpp_internal (v512, v256, vuc, const int<4>, const int<2>);\n     PMXVF64GERPP_INTERNAL mma_pmxvf64gerpp {mma,pair,quad}\n \n   void __builtin_mma_pmxvi16ger2 (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVI16GER2 nothing {mma}\n+    PMXVI16GER2 nothing {mma,mmaint}\n \n   v512 __builtin_mma_pmxvi16ger2_internal (vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVI16GER2_INTERNAL mma_pmxvi16ger2 {mma}\n \n   void __builtin_mma_pmxvi16ger2pp (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVI16GER2PP nothing {mma,quad}\n+    PMXVI16GER2PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvi16ger2pp_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVI16GER2PP_INTERNAL mma_pmxvi16ger2pp {mma,quad}\n \n   void __builtin_mma_pmxvi16ger2s (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVI16GER2S nothing {mma}\n+    PMXVI16GER2S nothing {mma,mmaint}\n \n   v512 __builtin_mma_pmxvi16ger2s_internal (vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVI16GER2S_INTERNAL mma_pmxvi16ger2s {mma}\n \n   void __builtin_mma_pmxvi16ger2spp (v512 *, vuc, vuc, const int<4>, const int<4>, const int<2>);\n-    PMXVI16GER2SPP nothing {mma,quad}\n+    PMXVI16GER2SPP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvi16ger2spp_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<2>);\n     PMXVI16GER2SPP_INTERNAL mma_pmxvi16ger2spp {mma,quad}\n \n   void __builtin_mma_pmxvi4ger8 (v512 *, vuc, vuc, const int<4>, const int<4>, const int<8>);\n-    PMXVI4GER8 nothing {mma}\n+    PMXVI4GER8 nothing {mma,mmaint}\n \n   v512 __builtin_mma_pmxvi4ger8_internal (vuc, vuc, const int<4>, const int<4>, const int<8>);\n     PMXVI4GER8_INTERNAL mma_pmxvi4ger8 {mma}\n \n   void __builtin_mma_pmxvi4ger8pp (v512 *, vuc, vuc, const int<4>, const int<4>, const int<4>);\n-    PMXVI4GER8PP nothing {mma,quad}\n+    PMXVI4GER8PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvi4ger8pp_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<4>);\n     PMXVI4GER8PP_INTERNAL mma_pmxvi4ger8pp {mma,quad}\n \n   void __builtin_mma_pmxvi8ger4 (v512 *, vuc, vuc, const int<4>, const int<4>, const int<4>);\n-    PMXVI8GER4 nothing {mma}\n+    PMXVI8GER4 nothing {mma,mmaint}\n \n   v512 __builtin_mma_pmxvi8ger4_internal (vuc, vuc, const int<4>, const int<4>, const int<4>);\n     PMXVI8GER4_INTERNAL mma_pmxvi8ger4 {mma}\n \n   void __builtin_mma_pmxvi8ger4pp (v512 *, vuc, vuc, const int<4>, const int<4>, const int<4>);\n-    PMXVI8GER4PP nothing {mma,quad}\n+    PMXVI8GER4PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvi8ger4pp_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<4>);\n     PMXVI8GER4PP_INTERNAL mma_pmxvi8ger4pp {mma,quad}\n \n   void __builtin_mma_pmxvi8ger4spp (v512 *, vuc, vuc, const int<4>, const int<4>, const int<4>);\n-    PMXVI8GER4SPP nothing {mma,quad}\n+    PMXVI8GER4SPP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_pmxvi8ger4spp_internal (v512, vuc, vuc, const int<4>, const int<4>, const int<4>);\n     PMXVI8GER4SPP_INTERNAL mma_pmxvi8ger4spp {mma,quad}\n \n   void __builtin_mma_xvbf16ger2 (v512 *, vuc, vuc);\n-    XVBF16GER2 nothing {mma}\n+    XVBF16GER2 nothing {mma,mmaint}\n \n   v512 __builtin_mma_xvbf16ger2_internal (vuc, vuc);\n     XVBF16GER2_INTERNAL mma_xvbf16ger2 {mma}\n \n   void __builtin_mma_xvbf16ger2nn (v512 *, vuc, vuc);\n-    XVBF16GER2NN nothing {mma,quad}\n+    XVBF16GER2NN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvbf16ger2nn_internal (v512, vuc, vuc);\n     XVBF16GER2NN_INTERNAL mma_xvbf16ger2nn {mma,quad}\n \n   void __builtin_mma_xvbf16ger2np (v512 *, vuc, vuc);\n-    XVBF16GER2NP nothing {mma,quad}\n+    XVBF16GER2NP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvbf16ger2np_internal (v512, vuc, vuc);\n     XVBF16GER2NP_INTERNAL mma_xvbf16ger2np {mma,quad}\n \n   void __builtin_mma_xvbf16ger2pn (v512 *, vuc, vuc);\n-    XVBF16GER2PN nothing {mma,quad}\n+    XVBF16GER2PN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvbf16ger2pn_internal (v512, vuc, vuc);\n     XVBF16GER2PN_INTERNAL mma_xvbf16ger2pn {mma,quad}\n \n   void __builtin_mma_xvbf16ger2pp (v512 *, vuc, vuc);\n-    XVBF16GER2PP nothing {mma,quad}\n+    XVBF16GER2PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvbf16ger2pp_internal (v512, vuc, vuc);\n     XVBF16GER2PP_INTERNAL mma_xvbf16ger2pp {mma,quad}\n \n   void __builtin_mma_xvf16ger2 (v512 *, vuc, vuc);\n-    XVF16GER2 nothing {mma}\n+    XVF16GER2 nothing {mma,mmaint}\n \n   v512 __builtin_mma_xvf16ger2_internal (vuc, vuc);\n     XVF16GER2_INTERNAL mma_xvf16ger2 {mma}\n \n   void __builtin_mma_xvf16ger2nn (v512 *, vuc, vuc);\n-    XVF16GER2NN nothing {mma,quad}\n+    XVF16GER2NN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf16ger2nn_internal (v512, vuc, vuc);\n     XVF16GER2NN_INTERNAL mma_xvf16ger2nn {mma,quad}\n \n   void __builtin_mma_xvf16ger2np (v512 *, vuc, vuc);\n-    XVF16GER2NP nothing {mma,quad}\n+    XVF16GER2NP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf16ger2np_internal (v512, vuc, vuc);\n     XVF16GER2NP_INTERNAL mma_xvf16ger2np {mma,quad}\n \n   void __builtin_mma_xvf16ger2pn (v512 *, vuc, vuc);\n-    XVF16GER2PN nothing {mma,quad}\n+    XVF16GER2PN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf16ger2pn_internal (v512, vuc, vuc);\n     XVF16GER2PN_INTERNAL mma_xvf16ger2pn {mma,quad}\n \n   void __builtin_mma_xvf16ger2pp (v512 *, vuc, vuc);\n-    XVF16GER2PP nothing {mma,quad}\n+    XVF16GER2PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf16ger2pp_internal (v512, vuc, vuc);\n     XVF16GER2PP_INTERNAL mma_xvf16ger2pp {mma,quad}\n \n   void __builtin_mma_xvf32ger (v512 *, vuc, vuc);\n-    XVF32GER nothing {mma}\n+    XVF32GER nothing {mma,mmaint}\n \n   v512 __builtin_mma_xvf32ger_internal (vuc, vuc);\n     XVF32GER_INTERNAL mma_xvf32ger {mma}\n \n   void __builtin_mma_xvf32gernn (v512 *, vuc, vuc);\n-    XVF32GERNN nothing {mma,quad}\n+    XVF32GERNN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf32gernn_internal (v512, vuc, vuc);\n     XVF32GERNN_INTERNAL mma_xvf32gernn {mma,quad}\n \n   void __builtin_mma_xvf32gernp (v512 *, vuc, vuc);\n-    XVF32GERNP nothing {mma,quad}\n+    XVF32GERNP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf32gernp_internal (v512, vuc, vuc);\n     XVF32GERNP_INTERNAL mma_xvf32gernp {mma,quad}\n \n   void __builtin_mma_xvf32gerpn (v512 *, vuc, vuc);\n-    XVF32GERPN nothing {mma,quad}\n+    XVF32GERPN nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf32gerpn_internal (v512, vuc, vuc);\n     XVF32GERPN_INTERNAL mma_xvf32gerpn {mma,quad}\n \n   void __builtin_mma_xvf32gerpp (v512 *, vuc, vuc);\n-    XVF32GERPP nothing {mma,quad}\n+    XVF32GERPP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvf32gerpp_internal (v512, vuc, vuc);\n     XVF32GERPP_INTERNAL mma_xvf32gerpp {mma,quad}\n \n   void __builtin_mma_xvf64ger (v512 *, v256, vuc);\n-    XVF64GER nothing {mma,pair}\n+    XVF64GER nothing {mma,pair,mmaint}\n \n   v512 __builtin_mma_xvf64ger_internal (v256, vuc);\n     XVF64GER_INTERNAL mma_xvf64ger {mma,pair}\n \n   void __builtin_mma_xvf64gernn (v512 *, v256, vuc);\n-    XVF64GERNN nothing {mma,pair,quad}\n+    XVF64GERNN nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_xvf64gernn_internal (v512, v256, vuc);\n     XVF64GERNN_INTERNAL mma_xvf64gernn {mma,pair,quad}\n \n   void __builtin_mma_xvf64gernp (v512 *, v256, vuc);\n-    XVF64GERNP nothing {mma,pair,quad}\n+    XVF64GERNP nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_xvf64gernp_internal (v512, v256, vuc);\n     XVF64GERNP_INTERNAL mma_xvf64gernp {mma,pair,quad}\n \n   void __builtin_mma_xvf64gerpn (v512 *, v256, vuc);\n-    XVF64GERPN nothing {mma,pair,quad}\n+    XVF64GERPN nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_xvf64gerpn_internal (v512, v256, vuc);\n     XVF64GERPN_INTERNAL mma_xvf64gerpn {mma,pair,quad}\n \n   void __builtin_mma_xvf64gerpp (v512 *, v256, vuc);\n-    XVF64GERPP nothing {mma,pair,quad}\n+    XVF64GERPP nothing {mma,pair,quad,mmaint}\n \n   v512 __builtin_mma_xvf64gerpp_internal (v512, v256, vuc);\n     XVF64GERPP_INTERNAL mma_xvf64gerpp {mma,pair,quad}\n \n   void __builtin_mma_xvi16ger2 (v512 *, vuc, vuc);\n-    XVI16GER2 nothing {mma}\n+    XVI16GER2 nothing {mma,mmaint}\n \n   v512 __builtin_mma_xvi16ger2_internal (vuc, vuc);\n     XVI16GER2_INTERNAL mma_xvi16ger2 {mma}\n \n   void __builtin_mma_xvi16ger2pp (v512 *, vuc, vuc);\n-    XVI16GER2PP nothing {mma,quad}\n+    XVI16GER2PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvi16ger2pp_internal (v512, vuc, vuc);\n     XVI16GER2PP_INTERNAL mma_xvi16ger2pp {mma,quad}\n \n   void __builtin_mma_xvi16ger2s (v512 *, vuc, vuc);\n-    XVI16GER2S nothing {mma}\n+    XVI16GER2S nothing {mma,mmaint}\n \n   v512 __builtin_mma_xvi16ger2s_internal (vuc, vuc);\n     XVI16GER2S_INTERNAL mma_xvi16ger2s {mma}\n \n   void __builtin_mma_xvi16ger2spp (v512 *, vuc, vuc);\n-    XVI16GER2SPP nothing {mma,quad}\n+    XVI16GER2SPP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvi16ger2spp_internal (v512, vuc, vuc);\n     XVI16GER2SPP_INTERNAL mma_xvi16ger2spp {mma,quad}\n \n   void __builtin_mma_xvi4ger8 (v512 *, vuc, vuc);\n-    XVI4GER8 nothing {mma}\n+    XVI4GER8 nothing {mma,mmaint}\n \n   v512 __builtin_mma_xvi4ger8_internal (vuc, vuc);\n     XVI4GER8_INTERNAL mma_xvi4ger8 {mma}\n \n   void __builtin_mma_xvi4ger8pp (v512 *, vuc, vuc);\n-    XVI4GER8PP nothing {mma,quad}\n+    XVI4GER8PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvi4ger8pp_internal (v512, vuc, vuc);\n     XVI4GER8PP_INTERNAL mma_xvi4ger8pp {mma,quad}\n \n   void __builtin_mma_xvi8ger4 (v512 *, vuc, vuc);\n-    XVI8GER4 nothing {mma}\n+    XVI8GER4 nothing {mma,mmaint}\n \n   v512 __builtin_mma_xvi8ger4_internal (vuc, vuc);\n     XVI8GER4_INTERNAL mma_xvi8ger4 {mma}\n \n   void __builtin_mma_xvi8ger4pp (v512 *, vuc, vuc);\n-    XVI8GER4PP nothing {mma,quad}\n+    XVI8GER4PP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvi8ger4pp_internal (v512, vuc, vuc);\n     XVI8GER4PP_INTERNAL mma_xvi8ger4pp {mma,quad}\n \n   void __builtin_mma_xvi8ger4spp (v512 *, vuc, vuc);\n-    XVI8GER4SPP nothing {mma,quad}\n+    XVI8GER4SPP nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xvi8ger4spp_internal (v512, vuc, vuc);\n     XVI8GER4SPP_INTERNAL mma_xvi8ger4spp {mma,quad}\n \n   void __builtin_mma_xxmfacc (v512 *);\n-    XXMFACC nothing {mma,quad}\n+    XXMFACC nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xxmfacc_internal (v512);\n     XXMFACC_INTERNAL mma_xxmfacc {mma,quad}\n \n   void __builtin_mma_xxmtacc (v512 *);\n-    XXMTACC nothing {mma,quad}\n+    XXMTACC nothing {mma,quad,mmaint}\n \n   v512 __builtin_mma_xxmtacc_internal (v512);\n     XXMTACC_INTERNAL mma_xxmtacc {mma,quad}\n \n   void __builtin_mma_xxsetaccz (v512 *);\n-    XXSETACCZ nothing {mma}\n+    XXSETACCZ nothing {mma,mmaint}\n \n   v512 __builtin_mma_xxsetaccz_internal ();\n     XXSETACCZ_INTERNAL mma_xxsetaccz {mma}\n \n   void __builtin_vsx_assemble_pair (v256 *, vuc, vuc);\n-    ASSEMBLE_PAIR_V nothing {mma}\n+    ASSEMBLE_PAIR_V nothing {mma,mmaint}\n \n   v256 __builtin_vsx_assemble_pair_internal (vuc, vuc);\n     ASSEMBLE_PAIR_V_INTERNAL vsx_assemble_pair {mma}\n \n   void __builtin_vsx_build_pair (v256 *, vuc, vuc);\n-    BUILD_PAIR nothing {mma}\n+    BUILD_PAIR nothing {mma,mmaint}\n \n   v256 __builtin_vsx_build_pair_internal (vuc, vuc);\n     BUILD_PAIR_INTERNAL vsx_assemble_pair {mma}\n \n   void __builtin_vsx_disassemble_pair (void *, v256 *);\n-    DISASSEMBLE_PAIR_V nothing {mma,pair}\n+    DISASSEMBLE_PAIR_V nothing {mma,pair,mmaint}\n \n   vuc __builtin_vsx_disassemble_pair_internal (v256, const int<2>);\n     DISASSEMBLE_PAIR_V_INTERNAL vsx_disassemble_pair {mma}\n+\n+  v256 __builtin_vsx_lxvp (unsigned long, const v256 *);\n+    LXVP nothing {mma}\n+\n+  void __builtin_vsx_stxvp (v256, unsigned long, const v256 *);\n+    STXVP nothing {mma,pair}"}, {"sha": "7d4854802251eaa4225da92b9453250ed03374ba", "filename": "gcc/config/rs6000/rs6000-call.c", "status": "modified", "additions": 39, "deletions": 2, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600/gcc%2Fconfig%2Frs6000%2Frs6000-call.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600/gcc%2Fconfig%2Frs6000%2Frs6000-call.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-call.c?ref=6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600", "patch": "@@ -13072,8 +13072,10 @@ rs6000_gimple_fold_new_mma_builtin (gimple_stmt_iterator *gsi,\n \n   /* Each call that can be gimple-expanded has an associated built-in\n      function that it will expand into.  If this one doesn't, we have\n-     already expanded it!  */\n-  if (rs6000_builtin_info_x[fncode].assoc_bif == RS6000_BIF_NONE)\n+     already expanded it!  Exceptions: lxvp and stxvp.  */\n+  if (rs6000_builtin_info_x[fncode].assoc_bif == RS6000_BIF_NONE\n+      && fncode != RS6000_BIF_LXVP\n+      && fncode != RS6000_BIF_STXVP)\n     return false;\n \n   bifdata *bd = &rs6000_builtin_info_x[fncode];\n@@ -13151,6 +13153,41 @@ rs6000_gimple_fold_new_mma_builtin (gimple_stmt_iterator *gsi,\n       return true;\n     }\n \n+  /* TODO: Do some factoring on these two chunks.  */\n+  if (fncode == RS6000_BIF_LXVP)\n+    {\n+      push_gimplify_context (true);\n+      tree offset = gimple_call_arg (stmt, 0);\n+      tree ptr = gimple_call_arg (stmt, 1);\n+      tree lhs = gimple_call_lhs (stmt);\n+      if (TREE_TYPE (TREE_TYPE (ptr)) != vector_pair_type_node)\n+\tptr = build1 (VIEW_CONVERT_EXPR,\n+\t\t      build_pointer_type (vector_pair_type_node), ptr);\n+      tree mem = build_simple_mem_ref (build2 (POINTER_PLUS_EXPR,\n+\t\t\t\t\t       TREE_TYPE (ptr), ptr, offset));\n+      gimplify_assign (lhs, mem, &new_seq);\n+      pop_gimplify_context (NULL);\n+      gsi_replace_with_seq (gsi, new_seq, true);\n+      return true;\n+    }\n+\n+  if (fncode == RS6000_BIF_STXVP)\n+    {\n+      push_gimplify_context (true);\n+      tree src = gimple_call_arg (stmt, 0);\n+      tree offset = gimple_call_arg (stmt, 1);\n+      tree ptr = gimple_call_arg (stmt, 2);\n+      if (TREE_TYPE (TREE_TYPE (ptr)) != vector_pair_type_node)\n+\tptr = build1 (VIEW_CONVERT_EXPR,\n+\t\t      build_pointer_type (vector_pair_type_node), ptr);\n+      tree mem = build_simple_mem_ref (build2 (POINTER_PLUS_EXPR,\n+\t\t\t\t\t       TREE_TYPE (ptr), ptr, offset));\n+      gimplify_assign (mem, src, &new_seq);\n+      pop_gimplify_context (NULL);\n+      gsi_replace_with_seq (gsi, new_seq, true);\n+      return true;\n+    }\n+\n   /* Convert this built-in into an internal version that uses pass-by-value\n      arguments.  The internal built-in is found in the assoc_bif field.  */\n   new_decl = rs6000_builtin_decls_x[rs6000_builtin_info_x[fncode].assoc_bif];"}, {"sha": "7f711210aff2827abf54de5a9ea46eb5d76511ef", "filename": "gcc/config/rs6000/rs6000-gen-builtins.c", "status": "modified", "additions": 23, "deletions": 15, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600/gcc%2Fconfig%2Frs6000%2Frs6000-gen-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600/gcc%2Fconfig%2Frs6000%2Frs6000-gen-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-gen-builtins.c?ref=6cba7d1dc437a25c702ab7b1db8b37c9e8b0c600", "patch": "@@ -84,6 +84,7 @@ along with GCC; see the file COPYING3.  If not see\n      mma      Needs special handling for MMA instructions\n      quad     MMA instruction using a register quad as an input operand\n      pair     MMA instruction using a register pair as an input operand\n+     mmaint   MMA instruction expanding to internal call at GIMPLE time\n      no32bit  Not valid for TARGET_32BIT\n      32bit    Requires different handling for TARGET_32BIT\n      cpu      This is a \"cpu_is\" or \"cpu_supports\" builtin\n@@ -369,6 +370,7 @@ struct attrinfo\n   bool ismma;\n   bool isquad;\n   bool ispair;\n+  bool ismmaint;\n   bool isno32bit;\n   bool is32bit;\n   bool iscpu;\n@@ -1363,6 +1365,8 @@ parse_bif_attrs (attrinfo *attrptr)\n \t  attrptr->isquad = 1;\n \telse if (!strcmp (attrname, \"pair\"))\n \t  attrptr->ispair = 1;\n+\telse if (!strcmp (attrname, \"mmaint\"))\n+\t  attrptr->ismmaint = 1;\n \telse if (!strcmp (attrname, \"no32bit\"))\n \t  attrptr->isno32bit = 1;\n \telse if (!strcmp (attrname, \"32bit\"))\n@@ -1409,15 +1413,15 @@ parse_bif_attrs (attrinfo *attrptr)\n   (*diag) (\"attribute set: init = %d, set = %d, extract = %d, nosoft = %d, \"\n \t   \"ldvec = %d, stvec = %d, reve = %d, pred = %d, htm = %d, \"\n \t   \"htmspr = %d, htmcr = %d, mma = %d, quad = %d, pair = %d, \"\n-\t   \"no32bit = %d, 32bit = %d, cpu = %d, ldstmask = %d, lxvrse = %d, \"\n-\t   \"lxvrze = %d, endian = %d.\\n\",\n+\t   \"mmaint = %d, no32bit = %d, 32bit = %d, cpu = %d, ldstmask = %d, \"\n+\t   \"lxvrse = %d, lxvrze = %d, endian = %d.\\n\",\n \t   attrptr->isinit, attrptr->isset, attrptr->isextract,\n \t   attrptr->isnosoft, attrptr->isldvec, attrptr->isstvec,\n \t   attrptr->isreve, attrptr->ispred, attrptr->ishtm, attrptr->ishtmspr,\n \t   attrptr->ishtmcr, attrptr->ismma, attrptr->isquad, attrptr->ispair,\n-\t   attrptr->isno32bit, attrptr->is32bit, attrptr->iscpu,\n-\t   attrptr->isldstmask, attrptr->islxvrse, attrptr->islxvrze,\n-\t   attrptr->isendian);\n+\t   attrptr->ismmaint, attrptr->isno32bit, attrptr->is32bit,\n+\t   attrptr->iscpu, attrptr->isldstmask, attrptr->islxvrse,\n+\t   attrptr->islxvrze, attrptr->isendian);\n #endif\n \n   return PC_OK;\n@@ -2223,13 +2227,14 @@ write_decls (void)\n   fprintf (header_file, \"#define bif_mma_bit\\t\\t(0x00000800)\\n\");\n   fprintf (header_file, \"#define bif_quad_bit\\t\\t(0x00001000)\\n\");\n   fprintf (header_file, \"#define bif_pair_bit\\t\\t(0x00002000)\\n\");\n-  fprintf (header_file, \"#define bif_no32bit_bit\\t\\t(0x00004000)\\n\");\n-  fprintf (header_file, \"#define bif_32bit_bit\\t\\t(0x00008000)\\n\");\n-  fprintf (header_file, \"#define bif_cpu_bit\\t\\t(0x00010000)\\n\");\n-  fprintf (header_file, \"#define bif_ldstmask_bit\\t(0x00020000)\\n\");\n-  fprintf (header_file, \"#define bif_lxvrse_bit\\t\\t(0x00040000)\\n\");\n-  fprintf (header_file, \"#define bif_lxvrze_bit\\t\\t(0x00080000)\\n\");\n-  fprintf (header_file, \"#define bif_endian_bit\\t\\t(0x00100000)\\n\");\n+  fprintf (header_file, \"#define bif_mmaint_bit\\t\\t(0x00004000)\\n\");\n+  fprintf (header_file, \"#define bif_no32bit_bit\\t\\t(0x00008000)\\n\");\n+  fprintf (header_file, \"#define bif_32bit_bit\\t\\t(0x00010000)\\n\");\n+  fprintf (header_file, \"#define bif_cpu_bit\\t\\t(0x00020000)\\n\");\n+  fprintf (header_file, \"#define bif_ldstmask_bit\\t(0x00040000)\\n\");\n+  fprintf (header_file, \"#define bif_lxvrse_bit\\t\\t(0x00080000)\\n\");\n+  fprintf (header_file, \"#define bif_lxvrze_bit\\t\\t(0x00100000)\\n\");\n+  fprintf (header_file, \"#define bif_endian_bit\\t\\t(0x00200000)\\n\");\n   fprintf (header_file, \"\\n\");\n   fprintf (header_file,\n \t   \"#define bif_is_init(x)\\t\\t((x).bifattrs & bif_init_bit)\\n\");\n@@ -2259,6 +2264,8 @@ write_decls (void)\n \t   \"#define bif_is_quad(x)\\t\\t((x).bifattrs & bif_quad_bit)\\n\");\n   fprintf (header_file,\n \t   \"#define bif_is_pair(x)\\t\\t((x).bifattrs & bif_pair_bit)\\n\");\n+  fprintf (header_file,\n+\t   \"#define bif_is_mmaint(x)\\t\\t((x).bifattrs & bif_mmaint_bit)\\n\");\n   fprintf (header_file,\n \t   \"#define bif_is_no32bit(x)\\t((x).bifattrs & bif_no32bit_bit)\\n\");\n   fprintf (header_file,\n@@ -2491,6 +2498,8 @@ write_bif_static_init (void)\n \tfprintf (init_file, \" | bif_quad_bit\");\n       if (bifp->attrs.ispair)\n \tfprintf (init_file, \" | bif_pair_bit\");\n+      if (bifp->attrs.ismmaint)\n+\tfprintf (init_file, \" | bif_mmaint_bit\");\n       if (bifp->attrs.isno32bit)\n \tfprintf (init_file, \" | bif_no32bit_bit\");\n       if (bifp->attrs.is32bit)\n@@ -2537,10 +2546,9 @@ write_bif_static_init (void)\n \t\t: (bifp->kind == FNK_PURE ? \"= pure\"\n \t\t   : (bifp->kind == FNK_FPMATH ? \"= fp, const\"\n \t\t      : \"\"))));\n-      bool no_icode = !strcmp (bifp->patname, \"nothing\");\n       fprintf (init_file, \"      /* assoc_bif */\\tRS6000_BIF_%s%s\\n\",\n-\t       bifp->attrs.ismma && no_icode ? bifp->idname : \"NONE\",\n-\t       bifp->attrs.ismma && no_icode ? \"_INTERNAL\" : \"\");\n+\t       bifp->attrs.ismmaint ? bifp->idname : \"NONE\",\n+\t       bifp->attrs.ismmaint ? \"_INTERNAL\" : \"\");\n       fprintf (init_file, \"    },\\n\");\n     }\n   fprintf (init_file, \"  };\\n\\n\");"}]}