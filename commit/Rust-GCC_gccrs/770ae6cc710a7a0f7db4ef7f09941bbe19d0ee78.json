{"sha": "770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzcwYWU2Y2M3MTBhN2EwZjdkYjRlZjdmMDk5NDFiYmUxOWQwZWU3OA==", "commit": {"author": {"name": "Richard Kenner", "email": "kenner@vlsi1.ultra.nyu.edu", "date": "2000-03-25T18:34:13Z"}, "committer": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "2000-03-25T18:34:13Z"}, "message": "* Rework fields used to describe positions of bitfields and\n\tmodify sizes to be unsigned and use HOST_WIDE_INT.\n\t* alias.c (reg_known_value_size): Now unsigned.\n\t* c-typeck.c (build_unary_op, case ADDR_EXPR): Use byte_position.\n\t(really_start_incremental_init): Use bitsize_zero_node.\n\t(push_init_level, pop_init_level, output_init_element): Likewise.\n\tUse bitsize_unit_node and bitsize_one_node.\n\t(output_pending_init_elements, process_init_element): Likewise.\n\t* combine.c (combine_max_regno, reg_sign_bit_copies): Now unsigned.\n\t(make_extraction): Position and length HOST_WIDE_INT and unsigned\n\tHOST_WIDE_INT, respectively.\n\t(get_pos_from_mask): Passed in value is unsigned HOST_WIDE_INT.\n\t(num_sign_bit_copies): Returns unsigned.\n\tBITWIDTH now unsigned; rework arithmetic.\n\tRemove recursive call from arg to MAX.\n\t(combine_instructions, init_reg_last_arrays): NREGS now unsigned.\n\t(setup_incoming_promotions, can_combine_p, try_combine, simplify_set):\n\tREGNO now unsigned.\n\t(set_nonzero_bit_and_sign_copies): NUM now unsigned.\n\t(find_split_point, expand_compound_operation, make_extraction): LEN\n\tnow unsigned HOST_WIDE_INT, POS now HOST_WIDE_INT.\n\t(make_field_assignment): Likewise.\n\t(combine_simplify_rtx): Add cast.\n\t(expand_compound_operation): MODEWIDTH now unsigned; rework arithmetic.\n\t(force_to_mode): WIDTH now unsigned; add cast.\n\t(if_then_else_cond): SIZE now unsigned.\n\t(nonzero_bits): MODE_WIDTH, RESULT_WIDTH, and WIDTH now unsigned.\n\t(extended_count): Now returns unsigned.\n\t(simplify_shift_const): COUNT unsigned; arg is now INPUT_COUNT.\n\tAdd SIGNED_COUNT variable; MODE_WORDS and FIRST_COUNT now unsigned.\n\t(simplify_comparison): MODE_WIDTH now unsigned.\n\t(update_table_tick): REGNO and ENDREGNO now unsigned; new var R.\n\t(mark_used_regs_combine): Likewise; rework arithmetic.\n\t(record_value_for_reg): REGNO, ENDREGNO, and I now unsigned.\n\t(record_dead_and_set_regs, reg_dead_at_p, distribute_notes): Likewise.\n\t(record_promoted_value): REGNO now unsigned.\n\t(get_last_value_validate): REGNO, ENDREGNO, and J now unsigned.\n\t(get_last_value): REGNO now unsigned.\n\t(use_crosses_set_p): REGNO and ENDREGNO now unsigned.\n\t(reg_dead_regno, reg_dead_endregno): Now unsigned.\n\t(remove_death): Arg REGNO now unsigned.\n\t(move_deaths):  REGNO, DEADREGNO, DEADEND, OUREND, and I now unsigned.\n\t(reg_bitfield_target_p): REGNO, REGNO, ENDREGNO, and ENDTREGNO\n\tnow unsigned.\n\t* convert.c (convert_to_integer): INPREC and OUTPREC now unsigned.\n\t* cse.c (struct qty_table_elem): FIRST_REG and LAST_REG now unsigned.\n\t(struct cse_reg_info): REGNO now unsigned.\n\t(cached_regno): Now unsigned.\n\t(REGNO_QTY_VALID_P): Add cast.\n\t(make_new_qty, make_regs_eqv, delete_reg_eqiv): Regno args unsigned.\n\t(remove_invalid_regs): Likewise.\n\t(remove_invalid_subreg_refs): Likewise; arg WORD also unsigned\n\tas are variables END and I.\n\t(get_cse_reg_info, insert): Likewise.\n\t(mention_regs, invalidate_for_call): REGNO, ENDREGNO, and I unsigned.\n\t(canon_hash): Likewise.\n\t(insert_regs, lookup_for_remove): REGNO now unsigned.\n\t(invalidate): REGNO, ENDREGNO, TREGNO, and TENDREGNO now unsigned.\n\tNew variable RN.\n\t* dbxout.c (dbxout_parms, dbxout_reg_parms): Don't check for REGNO < 0.\n\t* dwarf2out.c (dwarf2ou_frame_debug_expr): Remove cast.\n\t* emit-rtl.c (subreg_realpart_p): Add cast.\n\t(operand_subword): Arg I is now unsigned as is var PARTWORDS.\n\t(operand_subword_force): Arg I is now unsigned.\n\t* except.c (eh_regs): Variable I is now unsigned.\n\t* explow.c (hard_function_value): BYTES is unsigned HOST_WIDE_INT.\n\t* expmed.c (store_fixed_bit_field): Position is HOST_WIDE_INT;\n\tlength is unsigned HOST_WIDE_INT; likewise for internal variables.\n\t(store_split_bit_field, extract_fixed_bit_field): Likewise.\n\t(extract_split_bit_field, store_bit_field, extract_bit_field):\n\tLikewise.\n\t* expr.c (store_constructor_fields, store_constructor, store_field):\n\tPositions are HOST_WIDE_INT and lengths are unsigned HOST_WIDE_INT.\n\t(expand_assignment, expand_expr, expand_expr_unaligned): Likewise.\n\t(do_jump): Likewise.\n\t(move_by_pieces, move_by_pieces_ninsns, clear_by_pieces):\n\tMAX_SIZE is now unsigned.\n\t(emit_group_load): BYTEPOS is HOST_WIDE_INT; BYTELEN is unsigned.\n\t(emit_group_store): Likewise.\n\t(emit_move_insn): I now unsigned.\n\t(store_constructor): Use host_integerp, tree_low_cst, and\n\tbitsize_unit_node.\n\t(get_inner_reference): Return bitpos and bitsize as HOST_WIDE_INT.\n\tRework all calculations to use trees and new fields.\n\t* expr.h (promoted_input_arg): Regno now unsigned.\n\t(store_bit_field, extract_bit_field): Adjust types of pos and size.\n\t(mark_seen_cases): Arg is HOST_WIDE_INT.\n\t* flow.c (verify_wide_reg_1): REGNO now unsigned.\n\t* fold-const.c (decode_field_reference): Size and pos HOST_WIDE_INT;\n\tprecisions and alignments are unsigned.\n\t(optimize_bit_field_compare, fold_truthop): Likewise.\n\t(int_const_binop): Adjust threshold for size_int_type_wide call.\n\t(fold_convert): Likewise.\n\t(size_int_type_wide): Make table larger and fix thinko that only\n\thad half of table used.\n\t(all_ones_mask_p, fold): Precisions are unsigned.\n\t* function.c (put_reg_info_stack): REGNO is unsigned.\n\t(instantiate_decl): Size is HOST_WIDE_INT.\n\t(instantiate_virtual_regs): I is unsigned.\n\t(assign_parms): REGNO, REGNOI, and REGNOR are unsigned.\n\t(promoted_input_arg): REGNO is unsigned.\n\t* function.h (struct function): x_max_parm_reg is now unsigned.\n\t* gcse.c (max_gcse_regno): Now unsigned.\n\t(struct null_pointer_info): min_reg and max_reg now unsigned.\n\t(lookup_set, next_set): REGNO arg now unsigned.\n\t(compute_hash_table): REGNO and I now unsigned.\n\t(handle_avail_expr): regnum_for_replacing now unsigned.\n\t(cprop_insn): REGNO now unsigned.\n\t(delete_null_pointer_checks_1): BLOCK_REG now pointer to unsigned.\n\t* ggc-common.c (ggc_mark_tree_children, case FIELD_DECL): New case.\n\t* global.c (set_preference): SRC_REGNO, DEST_REGNO, and I now unsigned.\n\t* hard-reg-set.h (reg_class_size): Now unsigned.\n\t* integrate.c (mark_stores): LAST_REG and I now unsigned; new UREGNO.\n\t* jump.c (mark_modified_reg): I now unsigned; add cast.\n\t(rtx_equal_for_thread_p): Add cast.\n\t* loop.c (max_reg_before_loop): Now unsigned.\n\t(struct_movable): REGNO now unsigned.\n\t(try_copy_prop): REGNO arg unsigned.\n\t(regs_match_p): XN and YN now unsigned.\n\t(consec_sets_invariant_p, maybe_eliminate_biv): REGNO now unsigned.\n\t(strength_reduce): Likewise; NREGS also unsigned.\n\t(first_increment_giv, last_increment_giv unsigned): Now unsigned.\n\t* loop.h (struct iv_class): REGNO now unsigned.\n\t(max_reg_before_loop, first_increment_giv, last_increment_giv):\n\tNow unsigned.\n\t* machmode.h (mode_size, mode_unit_size): Now unsigned.\n\t(mode_for_size, smallest_mode_for_size): Pass size as unsigned.\n\t* optabs.c (expand_binop): I and NWORDS now unsigned.\n\t(expand_unop): I now unsigned.\n\t* print-tree.c (print_node): Don't print DECL_FIELD_BITPOS, but do\n\tprint DECL_FIELD_OFFSET and DECL_FIELD_BIT_OFFSET.\n\t* real.c (significand_size): Now returns unsigned.\n\t* real.h (significand_size): Likewise.\n\t* regclass.c (reg_class_size): Now unsigned.\n\t(choose_hard_reg_mode): Both operands now unsigned.\n\t(record_reg_classes): REGNO and NR now unsigned.\n\t(reg_scan): NREGS now unsigned.\n\t(reg_scan_update): old_max_regno now unsigned.\n\t(reg_scan_mark_refs): Arg MIN_REGNO and var REGNO now unsigned.\n\t* reload.c (find_valid_class): BEST_SIZE now unsigned.\n\t(find_dummy_reload): REGNO, NWORDS, and\tI now unsigned.\n\t(hard_reg_set_here_p): Args BEG_REGNO and END_REGNO now unsigned.\n\tLikewise for variable R.\n\t(refers_to_regno_for_reload_p): Args REGNO and END_REGNO now unsigned,\n\tas are variables INNER_REGNO and INNER_ENDREGNO; add new variable R.\n\t(find_equiv_reg): Add casts.\n\t(regno_clobbered_p): Arg REGNO now unsigned.\n\t* reload.h (struct reload): NREGS now unsigned.\n\t(refers_to_regno_for_reload_p): Regno args are unsigned.\n\t(regno_clobbered_p): Likewise.\n\t* reload1.c (reg_max_ref_width, spill_stack_slot_width): Now unsigned.\n\t(compute_use_by_pseudos): REGNO now unsigned.\n\t(find_reg): I and J now unsigned, new variable K, and change loop\n\tvariables accordingly; THIS_NREGS now unsigned.\n\t(alter_reg): INHERENT_SIZE and TOTAL_SIZE now unsigned.\n\t(spill_hard_reg): REGNO arg now unsigned; add casts.\n\t(forget_old_reloads_1): REGNO, NR, and I now unsigned.\n\t(mark_reload_reg_in_use): Arg REGNO and vars NREGS and I now unsigned.\n\t(clear_reload_reg_in_use): Arg REGNO and vars NREGS, START_REGNO,\n\tEND_REGNO, CONFLICT_START, and CONFLICT_END now unsigned.\n\t(reload_reg_free_p, reload_reg_reaches_end_p): Arg REGNO now unsigned.\n\t(choose_reload_regs): MAX_GROUP_SIZE now unsigned.\n\t(emit_reload_insns): REGNO now unsigned.\n\t(reload_cse_move2add): Add cast.\n\t(move2add_note_store): REGNO and I now unsigned; new variable ENDREGNO\n\tand rework loop.\n\t* resource.c (mark_referenced_resources, mark_set_resources): New\n\tvariable R; REGNO and LAST_REGNO now unsigned.\n\t(mark_target_live_regs): J and REGNO now unsigned.\n\t* rtl.c (mode_size, mode_unit_size): Now unsigned.\n\t* rtl.h (union rtunion_def): New field rtuint.\n\t(XCUINT): New macro.\n\t(ADDRESSOF_REGNO, REGNO, SUBREG_WORD): New XCUINT.\n\t(operand_subword, operand_subword_force): Word number is unsigned.\n\t(choose_hard_reg_mode): Operands are unsigned.\n\t(refers_to-regno_p, dead_or_set_regno_p): Regno arg is unsigned.\n\t(find_regno_note, find_regno_fusage, replace_regs): Likewise.\n\t(regno_use_in, combine_instructions, remove_death): Likewise.\n\t(reg_scan, reg_scan_update): Likewise.\n\t(extended_count): Return is unsigned.\n\t* rtlanal.c (refers_to_regno_p): Args REGNO and ENDREGNO and vars I,\n\tINNER_REGNO, and INNER_ENDREGNO now unsigned; new variable X_REGNO.\n\t(reg_overlap_mentioned_p): REGNO and ENDREGNO now unsigned.\n\t(reg_set_last_first_regno, reg_set_last_last_regno): Now unsigned.\n\t(reg_reg_last_1): FIRS and LAST now unsigned.\n\t(dead_or_set_p): REGNO, LAST_REGNO, and I now unsigned.\n\t(dead_or_set_regno_p): Arg TEST_REGNO and vars REGNO and ENDREGNO\n\tnow unsigned.\n\t(find_regno_note, regno_use_in): Arg REGNO now unsigned.\n\t(find_regno_fusage): Likewise; also var REGNOTE now unsigned.\n\t(find_reg_fusage): Variables REGNO, END_REGNO, and I now unsigned.\n\t(replace_regs): Arg NREGS now unsigned.\n\t* sdbout.c (sdbout_parms, sdbout_reg_parms): Don't check REGNO < 0.\n\t* simplify-rtx.c (simplify_unary_operation): WIDTH now unsigned.\n\t(simplify_binary_operation): Likewise.\n\t(cselib_invalidate_regno): Arg REGNO and variables ENDREGNO, I, and\n\tTHIS_LAST now unsigned.\n\t(cselib_record_set): Add cast.\n\t* ssa.c (ssa_max_reg_num): Now unsigned.\n\t(rename_block): REGNO now unsigned.\n\t* stmt.c (expand_return): Bit positions unsigned HOST_WIDE_INT;\n\tsizes now unsigned.\n\t(all_cases_count): Just return -1 not -2.\n\tCOUNT, MINVAL, and LASTVAL now HOST_WIDE_INT.\n\tRework tests to use trees whenever possible.\n\tUse host_integerp and tree_low_cst.\n\t(mark_seen_cases): COUNT arg now HOST_WIDE_INT;\n\tLikewise variable NEXT_NODE_OFFSET; XLO now unsigned.\n\t(check_for_full_enumeration_handing): BYTES_NEEDED, I to HOST_WIDE_INT.\n\t* stor-layout.c (mode_for_size): SIZE arg now unsigned.\n\t(smallest_mode_for_size): Likewise.\n\t(layout_decl): Simplify handing of a specified DECL_SIZE_UNIT.\n\tKNOWN_ALIGN is now an alignment, so simplify code.\n\tDon't turn off DECL_BIT_FIELD if field is BLKmode, but not type.\n\t(start_record_layout): Renamed from new_record_layout_info.\n\tUpdate to new fields.\n\t(debug_rli, normalize_rli, rli_size_unit_so_far, rli_size_so_far):\n\tNew functions.\n\t(place_union_field): Renamed from layout_union_field.\n\tUpdate to use new fields in rli.\n\t(place_field): Renamed from layout_field.\n\tMajor rewrite to use new fields in rli; pass alignment to layout_decl.\n\t(finalize_record_size): Rework to use new fields in rli and handle\n\tunion.\n\t(compute_record_mode): Rework to simplify and to use new DECL fields.\n\t(finalize_type_size): Make rounding more consistent.\n\t(finish_union_layout): Deleted.\n\t(layout_type, case VOID_TYPE): Don't set TYPE_SIZE_UNIT either.\n\t(layout_type, case RECORD_TYPE): Call new function names.\n\t(initialize_sizetypes): Set TYPE_IS_SIZETYPE.\n\t(set_sizetype): Set TYPE_IS_SIZETYPE earlier.\n\t(get_best_mode): UNIT is now unsigned; remove casts.\n\t* tree.c (bit_position): Compute from new fields.\n\t(byte_position, int_byte_position): New functions.\n\t(print_type_hash_statistics): Cast to remove warning.\n\t(build_range_type): Use host_integerp and tree_low_cst to try to hash.\n\t(build_index_type): Likewise; make subtype of sizetype.\n\t(build_index_2_type): Pass sizetype to build_range_type.\n\t(build_common_tree_nodes): Use size_int and bitsize_int to\n\tinitialize nodes; add bitsize_{zero,one,unit}_node.\n\t* tree.h (DECL_FIELD_CONTEXT): Use FIELD_DECL_CHECK.\n\t(DECL_BIT_FIELD_TYPE, DECL_QUALIFIER, DECL_FCONTEXT): Likewise.\n\t(DECL_PACKED, DECL_BIT_FIELD): Likewise.\n\t(DECL_FIELD_BITPOS): Deleted.\n\t(DECL_FIELD_OFFSET, DECL_FIELD_BIT_OFFSET): New fields.\n\t(DECL_RESULT, DECL_SAVED_INSNS): Use FUNCTION_DECL_CHECK.\n\t(DECL_FRAME_SIZE, DECL_FUNCTION_CODE, DECL_NO_STATIC_CHAIN): Likewise.\n\t(DECL_INLINE, DECL_BUILT_IN_NONANSI, DECL_IS_MALLOC): Likewise.\n\t(DECL_BUILT_IN_CLASS, DECL_STATIC_CONSTRUCTOR): Likewise.\n\t(DECL_STATIC_DESTRUCTOR, DECL_NO_CHECK_MEMORY_USAGE): Likewise.\n\t(DECL_NO_INSTRUMENT_FUNCTION_ENTRY_EXIT, DECL_NO_LIMIT_STACK) Likewise.\n\t(DECL_ORIGINAL_TYPE, TYPE_DECL_SUPPRESS_DEBUG): Use TYPE_DECL_CHECK.\n\t(DECL_ARG_TYPE_AS_WRITEN, DECL_ARG_TYPE): Use PARM_DECL_CHECK.\n\t(DECL_INCOMING_RTL, DECL_TRANSPARENT_UNION): Likewise.\n\t(DECL_ALIGN): Adjust to new field in union.\n\t(DECL_OFFSET_ALIGN): New field.\n\t(DECL_ERROR_ISSUED, DECL_TOO_LATE): Use LABEL_DECL_CHECK.\n\t(DECL_IN_TEXT_SECTION): Use VAR_DECL_CHECK.\n\t(union tree_decl): Add struct for both aligns.\n\t(enum tree_index): Add TI_BITSIZE_{ZERO,ONE,UNIT}.\n\t(bitsize_zero_node, bitsize_one_node, bitsize_unit_node): Added.\n\t(struct record_layout_info): Rework fields to have offset\n\talignment and byte and bit position.\n\t(start_record_layout, place_field): Renamed from old names.\n\t(rli_size_so_far, rli_size_unit_so_far, normalize_rli): New decls.\n\t(byte_position, int_byte_position): Likewise.\n\t(get_inner_reference): Change types of position and length.\n\t* unroll.c (unroll_loop): New variable R; use for some loops.\n\tMAX_LOCAL_REGNUM and MAXREGNUM now unsigned.\n\t(calculate_giv_inc): Arg REGNO now unsigned.\n\t(copy_loop_body): REGNO and SRC_REGNO now unsigned.\n\t* varasm.c (assemble_variable): Clean up handling of size using\n\thost_integerp and tree_low_cst.\n\t(decode_addr_const): Use byte, not bit, position.\n\t(output_constructor): bitpos and offsets are HOST_WIDE_INT;\n\tuse tree_low_cst and int_bit_position.\n\t* objc/objc-act.c (build_ivar_list_initializer): Use byte_position.\n\t* ch/actions.c (check_missing_cases): BYTES_NEEDED is HOST_WIDE_INT.\n\t* ch/typeck.c (expand_constant_to_buffer): Use int_byte_position.\n\t(extract_constant_from_buffer): Likewise.\n\t* cp/class.c (build_vbase_pointer_fields): layout_field now\n\tplace_field.\n\t(get_vfield_offset): Use byte_position.\n\t(set_rtti_entry): Set OFFSET to ssizetype zero.\n\t(get_binfo_offset_as_int): Deleted.\n\t(dfs_record_base_offsets): Use tree_low_cst.\n\t(dfs_search_base_offsets): Likewise.\n\t(layout_nonempty_base_or_field): Reflect changes in RLI format\n\tand call byte_position.\n\t(layout_empty_base): Convert offset to ssizetype.\n\t(build_base_field): use rli_size_unit_so_far.\n\t(dfs_propagate_binfo_offsets): Do computation in proper type.\n\t(layout_virtual_bases): Pass ssizetype to propagate_binfo_offsets.\n\t(layout_class_type): Reflect changes in RLI names and fields.\n\t(finish_struct_1): Set DECL_FIELD_OFFSET.\n\t* cp/dump.c (dequeue_and_dump): Call bit_position.\n\t* cp/expr.c (cplus_expand_constant): Use byte_position.\n\t* cp/rtti.c (expand_class_desc): Use bitsize_one_node.\n\t* cp/typeck.c (build_component_addr): Use byte_position and don't\n\tspecial case for zero offset.\n\t* f/com.c (ffecom_tree_canonize_ptr_): Use bitsize_zero_node.\n\t(ffecom_tree_canonize_ref_): Likewise.\n\t* java/class.c (make_field_value): Use byte_position.\n\t* java/expr.c (JAVA_ARRAY_LENGTH_OFFSET): Use byte_position.\n\t(java_array_data_offset): Likewise.\n\t* java/java-tree.h (MAYBE_CREATE_TYPE_TYPE_LANG_SPECIFIC): Add case to\n\tbzero call.\n\nFrom-SVN: r32742", "tree": {"sha": "2aa8734829bb9352ea3ee4958179c54a164bfc53", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2aa8734829bb9352ea3ee4958179c54a164bfc53"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "html_url": "https://github.com/Rust-GCC/gccrs/commit/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/comments", "author": null, "committer": null, "parents": [{"sha": "370af2d55a9765c7e5796f80dfa97b04283b2ab9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/370af2d55a9765c7e5796f80dfa97b04283b2ab9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/370af2d55a9765c7e5796f80dfa97b04283b2ab9"}], "stats": {"total": 3563, "additions": 1990, "deletions": 1573}, "files": [{"sha": "d4d8a0b439d479609d58ac9a16e719d0a36d77cc", "filename": "gcc/ChangeLog", "status": "modified", "additions": 280, "deletions": 0, "changes": 280, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,3 +1,283 @@\n+Sat Mar 25 09:12:10 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n+\n+\t* Rework fields used to describe positions of bitfields and\n+\tmodify sizes to be unsigned and use HOST_WIDE_INT.\n+\t* alias.c (reg_known_value_size): Now unsigned.\n+\t* c-typeck.c (build_unary_op, case ADDR_EXPR): Use byte_position.\n+\t(really_start_incremental_init): Use bitsize_zero_node.\n+\t(push_init_level, pop_init_level, output_init_element): Likewise.\n+\tUse bitsize_unit_node and bitsize_one_node.\n+\t(output_pending_init_elements, process_init_element): Likewise.\n+\t* combine.c (combine_max_regno, reg_sign_bit_copies): Now unsigned.\n+\t(make_extraction): Position and length HOST_WIDE_INT and unsigned\n+\tHOST_WIDE_INT, respectively.\n+\t(get_pos_from_mask): Passed in value is unsigned HOST_WIDE_INT.\n+\t(num_sign_bit_copies): Returns unsigned.\n+\tBITWIDTH now unsigned; rework arithmetic.\n+\tRemove recursive call from arg to MAX.\n+\t(combine_instructions, init_reg_last_arrays): NREGS now unsigned.\n+\t(setup_incoming_promotions, can_combine_p, try_combine, simplify_set):\n+\tREGNO now unsigned.\n+\t(set_nonzero_bit_and_sign_copies): NUM now unsigned.\n+\t(find_split_point, expand_compound_operation, make_extraction): LEN\n+\tnow unsigned HOST_WIDE_INT, POS now HOST_WIDE_INT.\n+\t(make_field_assignment): Likewise.\n+\t(combine_simplify_rtx): Add cast.\n+\t(expand_compound_operation): MODEWIDTH now unsigned; rework arithmetic.\n+\t(force_to_mode): WIDTH now unsigned; add cast.\n+\t(if_then_else_cond): SIZE now unsigned.\n+\t(nonzero_bits): MODE_WIDTH, RESULT_WIDTH, and WIDTH now unsigned.\n+\t(extended_count): Now returns unsigned.\n+\t(simplify_shift_const): COUNT unsigned; arg is now INPUT_COUNT.\n+\tAdd SIGNED_COUNT variable; MODE_WORDS and FIRST_COUNT now unsigned.\n+\t(simplify_comparison): MODE_WIDTH now unsigned.\n+\t(update_table_tick): REGNO and ENDREGNO now unsigned; new var R.\n+\t(mark_used_regs_combine): Likewise; rework arithmetic.\n+\t(record_value_for_reg): REGNO, ENDREGNO, and I now unsigned.\n+\t(record_dead_and_set_regs, reg_dead_at_p, distribute_notes): Likewise.\n+\t(record_promoted_value): REGNO now unsigned.\n+\t(get_last_value_validate): REGNO, ENDREGNO, and J now unsigned.\n+\t(get_last_value): REGNO now unsigned.\n+\t(use_crosses_set_p): REGNO and ENDREGNO now unsigned.\n+\t(reg_dead_regno, reg_dead_endregno): Now unsigned.\n+\t(remove_death): Arg REGNO now unsigned.\n+\t(move_deaths):  REGNO, DEADREGNO, DEADEND, OUREND, and I now unsigned.\n+\t(reg_bitfield_target_p): REGNO, REGNO, ENDREGNO, and ENDTREGNO\n+\tnow unsigned.\n+\t* convert.c (convert_to_integer): INPREC and OUTPREC now unsigned.\n+\t* cse.c (struct qty_table_elem): FIRST_REG and LAST_REG now unsigned.\n+\t(struct cse_reg_info): REGNO now unsigned.\n+\t(cached_regno): Now unsigned.\n+\t(REGNO_QTY_VALID_P): Add cast.\n+\t(make_new_qty, make_regs_eqv, delete_reg_eqiv): Regno args unsigned.\n+\t(remove_invalid_regs): Likewise.\n+\t(remove_invalid_subreg_refs): Likewise; arg WORD also unsigned\n+\tas are variables END and I.\n+\t(get_cse_reg_info, insert): Likewise.\n+\t(mention_regs, invalidate_for_call): REGNO, ENDREGNO, and I unsigned.\n+\t(canon_hash): Likewise.\n+\t(insert_regs, lookup_for_remove): REGNO now unsigned.\n+\t(invalidate): REGNO, ENDREGNO, TREGNO, and TENDREGNO now unsigned.\n+\tNew variable RN.\n+\t* dbxout.c (dbxout_parms, dbxout_reg_parms): Don't check for REGNO < 0.\n+\t* dwarf2out.c (dwarf2ou_frame_debug_expr): Remove cast.\n+\t* emit-rtl.c (subreg_realpart_p): Add cast.\n+\t(operand_subword): Arg I is now unsigned as is var PARTWORDS.\n+\t(operand_subword_force): Arg I is now unsigned.\n+\t* except.c (eh_regs): Variable I is now unsigned.\n+\t* explow.c (hard_function_value): BYTES is unsigned HOST_WIDE_INT.\n+\t* expmed.c (store_fixed_bit_field): Position is HOST_WIDE_INT;\n+\tlength is unsigned HOST_WIDE_INT; likewise for internal variables.\n+\t(store_split_bit_field, extract_fixed_bit_field): Likewise.\n+\t(extract_split_bit_field, store_bit_field, extract_bit_field):\n+\tLikewise.\n+\t* expr.c (store_constructor_fields, store_constructor, store_field):\n+\tPositions are HOST_WIDE_INT and lengths are unsigned HOST_WIDE_INT.\n+\t(expand_assignment, expand_expr, expand_expr_unaligned): Likewise.\n+\t(do_jump): Likewise.\n+\t(move_by_pieces, move_by_pieces_ninsns, clear_by_pieces):\n+\tMAX_SIZE is now unsigned.\n+\t(emit_group_load): BYTEPOS is HOST_WIDE_INT; BYTELEN is unsigned.\n+\t(emit_group_store): Likewise.\n+\t(emit_move_insn): I now unsigned.\n+\t(store_constructor): Use host_integerp, tree_low_cst, and\n+\tbitsize_unit_node.\n+\t(get_inner_reference): Return bitpos and bitsize as HOST_WIDE_INT.\n+\tRework all calculations to use trees and new fields.\n+\t* expr.h (promoted_input_arg): Regno now unsigned.\n+\t(store_bit_field, extract_bit_field): Adjust types of pos and size.\n+\t(mark_seen_cases): Arg is HOST_WIDE_INT.\n+\t* flow.c (verify_wide_reg_1): REGNO now unsigned.\n+\t* fold-const.c (decode_field_reference): Size and pos HOST_WIDE_INT;\n+\tprecisions and alignments are unsigned.\n+\t(optimize_bit_field_compare, fold_truthop): Likewise.\n+\t(int_const_binop): Adjust threshold for size_int_type_wide call.\n+\t(fold_convert): Likewise.\n+\t(size_int_type_wide): Make table larger and fix thinko that only\n+\thad half of table used.\n+\t(all_ones_mask_p, fold): Precisions are unsigned.\n+\t* function.c (put_reg_info_stack): REGNO is unsigned.\n+\t(instantiate_decl): Size is HOST_WIDE_INT.\n+\t(instantiate_virtual_regs): I is unsigned.\n+\t(assign_parms): REGNO, REGNOI, and REGNOR are unsigned.\n+\t(promoted_input_arg): REGNO is unsigned.\n+\t* function.h (struct function): x_max_parm_reg is now unsigned.\n+\t* gcse.c (max_gcse_regno): Now unsigned.\n+\t(struct null_pointer_info): min_reg and max_reg now unsigned.\n+\t(lookup_set, next_set): REGNO arg now unsigned.\n+\t(compute_hash_table): REGNO and I now unsigned.\n+\t(handle_avail_expr): regnum_for_replacing now unsigned.\n+\t(cprop_insn): REGNO now unsigned.\n+\t(delete_null_pointer_checks_1): BLOCK_REG now pointer to unsigned.\n+\t* ggc-common.c (ggc_mark_tree_children, case FIELD_DECL): New case.\n+\t* global.c (set_preference): SRC_REGNO, DEST_REGNO, and I now unsigned.\n+\t* hard-reg-set.h (reg_class_size): Now unsigned.\n+\t* integrate.c (mark_stores): LAST_REG and I now unsigned; new UREGNO.\n+\t* jump.c (mark_modified_reg): I now unsigned; add cast.\n+\t(rtx_equal_for_thread_p): Add cast.\n+\t* loop.c (max_reg_before_loop): Now unsigned.\n+\t(struct_movable): REGNO now unsigned.\n+\t(try_copy_prop): REGNO arg unsigned.\n+\t(regs_match_p): XN and YN now unsigned.\n+\t(consec_sets_invariant_p, maybe_eliminate_biv): REGNO now unsigned.\n+\t(strength_reduce): Likewise; NREGS also unsigned.\n+\t(first_increment_giv, last_increment_giv unsigned): Now unsigned.\n+\t* loop.h (struct iv_class): REGNO now unsigned.\n+\t(max_reg_before_loop, first_increment_giv, last_increment_giv):\n+\tNow unsigned.\n+\t* machmode.h (mode_size, mode_unit_size): Now unsigned.\n+\t(mode_for_size, smallest_mode_for_size): Pass size as unsigned.\n+\t* optabs.c (expand_binop): I and NWORDS now unsigned.\n+\t(expand_unop): I now unsigned.\n+\t* print-tree.c (print_node): Don't print DECL_FIELD_BITPOS, but do\n+\tprint DECL_FIELD_OFFSET and DECL_FIELD_BIT_OFFSET.\n+\t* real.c (significand_size): Now returns unsigned.\n+\t* real.h (significand_size): Likewise.\n+\t* regclass.c (reg_class_size): Now unsigned.\n+\t(choose_hard_reg_mode): Both operands now unsigned.\n+\t(record_reg_classes): REGNO and NR now unsigned.\n+\t(reg_scan): NREGS now unsigned.\n+\t(reg_scan_update): old_max_regno now unsigned.\n+\t(reg_scan_mark_refs): Arg MIN_REGNO and var REGNO now unsigned.\n+\t* reload.c (find_valid_class): BEST_SIZE now unsigned.\n+\t(find_dummy_reload): REGNO, NWORDS, and\tI now unsigned.\n+\t(hard_reg_set_here_p): Args BEG_REGNO and END_REGNO now unsigned.\n+\tLikewise for variable R.\n+\t(refers_to_regno_for_reload_p): Args REGNO and END_REGNO now unsigned,\n+\tas are variables INNER_REGNO and INNER_ENDREGNO; add new variable R.\n+\t(find_equiv_reg): Add casts.\n+\t(regno_clobbered_p): Arg REGNO now unsigned.\n+\t* reload.h (struct reload): NREGS now unsigned.\n+\t(refers_to_regno_for_reload_p): Regno args are unsigned.\n+\t(regno_clobbered_p): Likewise.\n+\t* reload1.c (reg_max_ref_width, spill_stack_slot_width): Now unsigned.\n+\t(compute_use_by_pseudos): REGNO now unsigned.\n+\t(find_reg): I and J now unsigned, new variable K, and change loop\n+\tvariables accordingly; THIS_NREGS now unsigned.\n+\t(alter_reg): INHERENT_SIZE and TOTAL_SIZE now unsigned.\n+\t(spill_hard_reg): REGNO arg now unsigned; add casts.\n+\t(forget_old_reloads_1): REGNO, NR, and I now unsigned.\n+\t(mark_reload_reg_in_use): Arg REGNO and vars NREGS and I now unsigned.\n+\t(clear_reload_reg_in_use): Arg REGNO and vars NREGS, START_REGNO,\n+\tEND_REGNO, CONFLICT_START, and CONFLICT_END now unsigned.\n+\t(reload_reg_free_p, reload_reg_reaches_end_p): Arg REGNO now unsigned.\n+\t(choose_reload_regs): MAX_GROUP_SIZE now unsigned.\n+\t(emit_reload_insns): REGNO now unsigned.\n+\t(reload_cse_move2add): Add cast.\n+\t(move2add_note_store): REGNO and I now unsigned; new variable ENDREGNO\n+\tand rework loop.\n+\t* resource.c (mark_referenced_resources, mark_set_resources): New\n+\tvariable R; REGNO and LAST_REGNO now unsigned.\n+\t(mark_target_live_regs): J and REGNO now unsigned.\n+\t* rtl.c (mode_size, mode_unit_size): Now unsigned.\n+\t* rtl.h (union rtunion_def): New field rtuint.\n+\t(XCUINT): New macro.\n+\t(ADDRESSOF_REGNO, REGNO, SUBREG_WORD): New XCUINT.\n+\t(operand_subword, operand_subword_force): Word number is unsigned.\n+\t(choose_hard_reg_mode): Operands are unsigned.\n+\t(refers_to-regno_p, dead_or_set_regno_p): Regno arg is unsigned.\n+\t(find_regno_note, find_regno_fusage, replace_regs): Likewise.\n+\t(regno_use_in, combine_instructions, remove_death): Likewise.\n+\t(reg_scan, reg_scan_update): Likewise.\n+\t(extended_count): Return is unsigned.\n+\t* rtlanal.c (refers_to_regno_p): Args REGNO and ENDREGNO and vars I,\n+\tINNER_REGNO, and INNER_ENDREGNO now unsigned; new variable X_REGNO.\n+\t(reg_overlap_mentioned_p): REGNO and ENDREGNO now unsigned.\n+\t(reg_set_last_first_regno, reg_set_last_last_regno): Now unsigned.\n+\t(reg_reg_last_1): FIRS and LAST now unsigned.\n+\t(dead_or_set_p): REGNO, LAST_REGNO, and I now unsigned.\n+\t(dead_or_set_regno_p): Arg TEST_REGNO and vars REGNO and ENDREGNO\n+\tnow unsigned.\n+\t(find_regno_note, regno_use_in): Arg REGNO now unsigned.\n+\t(find_regno_fusage): Likewise; also var REGNOTE now unsigned.\n+\t(find_reg_fusage): Variables REGNO, END_REGNO, and I now unsigned.\n+\t(replace_regs): Arg NREGS now unsigned.\n+\t* sdbout.c (sdbout_parms, sdbout_reg_parms): Don't check REGNO < 0.\n+\t* simplify-rtx.c (simplify_unary_operation): WIDTH now unsigned.\n+\t(simplify_binary_operation): Likewise.\n+\t(cselib_invalidate_regno): Arg REGNO and variables ENDREGNO, I, and\n+\tTHIS_LAST now unsigned.\n+\t(cselib_record_set): Add cast.\n+\t* ssa.c (ssa_max_reg_num): Now unsigned.\n+\t(rename_block): REGNO now unsigned.\n+\t* stmt.c (expand_return): Bit positions unsigned HOST_WIDE_INT;\n+\tsizes now unsigned.\n+\t(all_cases_count): Just return -1 not -2.\n+\tCOUNT, MINVAL, and LASTVAL now HOST_WIDE_INT.\n+\tRework tests to use trees whenever possible.\n+\tUse host_integerp and tree_low_cst.\n+\t(mark_seen_cases): COUNT arg now HOST_WIDE_INT;\n+\tLikewise variable NEXT_NODE_OFFSET; XLO now unsigned.\n+\t(check_for_full_enumeration_handing): BYTES_NEEDED, I to HOST_WIDE_INT.\n+\t* stor-layout.c (mode_for_size): SIZE arg now unsigned.\n+\t(smallest_mode_for_size): Likewise.\n+\t(layout_decl): Simplify handing of a specified DECL_SIZE_UNIT.\n+\tKNOWN_ALIGN is now an alignment, so simplify code.\n+\tDon't turn off DECL_BIT_FIELD if field is BLKmode, but not type.\n+\t(start_record_layout): Renamed from new_record_layout_info.\n+\tUpdate to new fields.\n+\t(debug_rli, normalize_rli, rli_size_unit_so_far, rli_size_so_far):\n+\tNew functions.\n+\t(place_union_field): Renamed from layout_union_field.\n+\tUpdate to use new fields in rli.\n+\t(place_field): Renamed from layout_field.\n+\tMajor rewrite to use new fields in rli; pass alignment to layout_decl.\n+\t(finalize_record_size): Rework to use new fields in rli and handle\n+\tunion.\n+\t(compute_record_mode): Rework to simplify and to use new DECL fields.\n+\t(finalize_type_size): Make rounding more consistent.\n+\t(finish_union_layout): Deleted.\n+\t(layout_type, case VOID_TYPE): Don't set TYPE_SIZE_UNIT either.\n+\t(layout_type, case RECORD_TYPE): Call new function names.\n+\t(initialize_sizetypes): Set TYPE_IS_SIZETYPE.\n+\t(set_sizetype): Set TYPE_IS_SIZETYPE earlier.\n+\t(get_best_mode): UNIT is now unsigned; remove casts.\n+\t* tree.c (bit_position): Compute from new fields.\n+\t(byte_position, int_byte_position): New functions.\n+\t(print_type_hash_statistics): Cast to remove warning.\n+\t(build_range_type): Use host_integerp and tree_low_cst to try to hash.\n+\t(build_index_type): Likewise; make subtype of sizetype.\n+\t(build_index_2_type): Pass sizetype to build_range_type.\n+\t(build_common_tree_nodes): Use size_int and bitsize_int to\n+\tinitialize nodes; add bitsize_{zero,one,unit}_node.\n+\t* tree.h (DECL_FIELD_CONTEXT): Use FIELD_DECL_CHECK.\n+\t(DECL_BIT_FIELD_TYPE, DECL_QUALIFIER, DECL_FCONTEXT): Likewise.\n+\t(DECL_PACKED, DECL_BIT_FIELD): Likewise.\n+\t(DECL_FIELD_BITPOS): Deleted.\n+\t(DECL_FIELD_OFFSET, DECL_FIELD_BIT_OFFSET): New fields.\n+\t(DECL_RESULT, DECL_SAVED_INSNS): Use FUNCTION_DECL_CHECK.\n+\t(DECL_FRAME_SIZE, DECL_FUNCTION_CODE, DECL_NO_STATIC_CHAIN): Likewise.\n+\t(DECL_INLINE, DECL_BUILT_IN_NONANSI, DECL_IS_MALLOC): Likewise.\n+\t(DECL_BUILT_IN_CLASS, DECL_STATIC_CONSTRUCTOR): Likewise.\n+\t(DECL_STATIC_DESTRUCTOR, DECL_NO_CHECK_MEMORY_USAGE): Likewise.\n+\t(DECL_NO_INSTRUMENT_FUNCTION_ENTRY_EXIT, DECL_NO_LIMIT_STACK) Likewise.\n+\t(DECL_ORIGINAL_TYPE, TYPE_DECL_SUPPRESS_DEBUG): Use TYPE_DECL_CHECK.\n+\t(DECL_ARG_TYPE_AS_WRITEN, DECL_ARG_TYPE): Use PARM_DECL_CHECK.\n+\t(DECL_INCOMING_RTL, DECL_TRANSPARENT_UNION): Likewise.\n+\t(DECL_ALIGN): Adjust to new field in union.\n+\t(DECL_OFFSET_ALIGN): New field.\n+\t(DECL_ERROR_ISSUED, DECL_TOO_LATE): Use LABEL_DECL_CHECK.\n+\t(DECL_IN_TEXT_SECTION): Use VAR_DECL_CHECK.\n+\t(union tree_decl): Add struct for both aligns.\n+\t(enum tree_index): Add TI_BITSIZE_{ZERO,ONE,UNIT}.\n+\t(bitsize_zero_node, bitsize_one_node, bitsize_unit_node): Added.\n+\t(struct record_layout_info): Rework fields to have offset\n+\talignment and byte and bit position.\n+\t(start_record_layout, place_field): Renamed from old names.\n+\t(rli_size_so_far, rli_size_unit_so_far, normalize_rli): New decls.\n+\t(byte_position, int_byte_position): Likewise.\n+\t(get_inner_reference): Change types of position and length.\n+\t* unroll.c (unroll_loop): New variable R; use for some loops.\n+\tMAX_LOCAL_REGNUM and MAXREGNUM now unsigned.\n+\t(calculate_giv_inc): Arg REGNO now unsigned.\n+\t(copy_loop_body): REGNO and SRC_REGNO now unsigned.\n+\t* varasm.c (assemble_variable): Clean up handling of size using\n+\thost_integerp and tree_low_cst.\n+\t(decode_addr_const): Use byte, not bit, position.\n+\t(output_constructor): bitpos and offsets are HOST_WIDE_INT;\n+\tuse tree_low_cst and int_bit_position.\n+\t* objc/objc-act.c (build_ivar_list_initializer): Use byte_position.\n+\t\n Fri Mar 24 20:13:49 2000  Jason Eckhardt  <jle@cygnus.com>\n \n \t* bb-reorder.c (REORDER_MOVED_BLOCK_END): Removed."}, {"sha": "8d1633024978f742b60f95e5bf8317a403bc38dd", "filename": "gcc/alias.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Falias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Falias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Falias.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -158,7 +158,7 @@ static rtx *alias_invariant;\n rtx *reg_known_value;\n \n /* Indicates number of valid entries in reg_known_value.  */\n-static int reg_known_value_size;\n+static unsigned int reg_known_value_size;\n \n /* Vector recording for each reg_known_value whether it is due to a\n    REG_EQUIV note.  Future passes (viz., reload) may replace the"}, {"sha": "21a9557d24aad46af651d2f908589662b72c46f1", "filename": "gcc/c-typeck.c", "status": "modified", "additions": 25, "deletions": 41, "changes": 66, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fc-typeck.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fc-typeck.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-typeck.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -2982,17 +2982,16 @@ build_unary_op (code, xarg, noconvert)\n \n       /* Ordinary case; arg is a COMPONENT_REF or a decl.  */\n       argtype = TREE_TYPE (arg);\n+\n       /* If the lvalue is const or volatile, merge that into the type\n          to which the address will point.  Note that you can't get a\n \t restricted pointer by taking the address of something, so we\n \t only have to deal with `const' and `volatile' here.  */\n-      if (DECL_P (arg) || TREE_CODE_CLASS (TREE_CODE (arg)) == 'r')\n-\t{\n-\t  if (TREE_READONLY (arg) || TREE_THIS_VOLATILE (arg))\n-\t    argtype = c_build_type_variant (argtype,\n-\t\t\t\t\t    TREE_READONLY (arg),\n-\t\t\t\t\t    TREE_THIS_VOLATILE (arg));\n-\t}\n+      if ((DECL_P (arg) || TREE_CODE_CLASS (TREE_CODE (arg)) == 'r')\n+\t  && (TREE_READONLY (arg) || TREE_THIS_VOLATILE (arg)))\n+\t  argtype = c_build_type_variant (argtype,\n+\t\t\t\t\t  TREE_READONLY (arg),\n+\t\t\t\t\t  TREE_THIS_VOLATILE (arg));\n \n       argtype = build_pointer_type (argtype);\n \n@@ -3015,19 +3014,9 @@ build_unary_op (code, xarg, noconvert)\n \t\treturn error_mark_node;\n \t      }\n \n-\t    addr = convert (argtype, addr);\n-\n-\t    if (! integer_zerop (bit_position (field)))\n-\t      {\n-\t\ttree offset\n-\t\t  = size_binop (EASY_DIV_EXPR, bit_position (field),\n-\t\t\t\tbitsize_int (BITS_PER_UNIT));\n-\t\tint flag = TREE_CONSTANT (addr);\n-\n-\t\taddr = fold (build (PLUS_EXPR, argtype,\n-\t\t\t\t    addr, convert (argtype, offset)));\n-\t\tTREE_CONSTANT (addr) = flag;\n-\t      }\n+\t    addr = fold (build (PLUS_EXPR, argtype,\n+\t\t\t\tconvert (argtype, addr),\n+\t\t\t\tconvert (argtype, byte_position (field))));\n \t  }\n \telse\n \t  addr = build1 (code, argtype, arg);\n@@ -5026,7 +5015,7 @@ really_start_incremental_init (type)\n \tconstructor_fields = TREE_CHAIN (constructor_fields);\n \n       constructor_unfilled_fields = constructor_fields;\n-      constructor_bit_index = bitsize_int (0);\n+      constructor_bit_index = bitsize_zero_node;\n     }\n   else if (TREE_CODE (constructor_type) == ARRAY_TYPE)\n     {\n@@ -5040,7 +5029,7 @@ really_start_incremental_init (type)\n \t\t       TYPE_MIN_VALUE (TYPE_DOMAIN (constructor_type)));\n \t}\n       else\n-\tconstructor_index = bitsize_int (0);\n+\tconstructor_index = bitsize_zero_node;\n \n       constructor_unfilled_index = constructor_index;\n     }\n@@ -5104,7 +5093,7 @@ push_init_level (implicit)\n \t\t\tsize_binop (MINUS_EXPR,\n \t\t\t\t    bit_position (constructor_fields),\n \t\t\t\t    constructor_bit_index),\n-\t\t\tbitsize_int (BITS_PER_UNIT)),\n+\t\t\tbitsize_unit_node),\n \t    1));\n \n       /* Indicate that we have now filled the structure up to the current\n@@ -5196,7 +5185,7 @@ push_init_level (implicit)\n \tconstructor_fields = TREE_CHAIN (constructor_fields);\n \n       constructor_unfilled_fields = constructor_fields;\n-      constructor_bit_index = bitsize_int (0);\n+      constructor_bit_index = bitsize_zero_node;\n     }\n   else if (TREE_CODE (constructor_type) == ARRAY_TYPE)\n     {\n@@ -5211,7 +5200,7 @@ push_init_level (implicit)\n \t\t\t\t  (TYPE_DOMAIN (constructor_type)));\n \t}\n       else\n-\tconstructor_index = bitsize_int (0);\n+\tconstructor_index = bitsize_zero_node;\n \n       constructor_unfilled_index = constructor_index;\n     }\n@@ -5393,9 +5382,8 @@ pop_init_level (implicit)\n       if (TREE_CODE (constructor_type) == RECORD_TYPE\n \t  || TREE_CODE (constructor_type) == UNION_TYPE)\n \t/* Find the offset of the end of that field.  */\n-\tfilled = size_binop (CEIL_DIV_EXPR,\n-\t\t\t     constructor_bit_index,\n-\t\t\t     bitsize_int (BITS_PER_UNIT));\n+\tfilled = size_binop (CEIL_DIV_EXPR, constructor_bit_index,\n+\t\t\t     bitsize_unit_node);\n \n       else if (TREE_CODE (constructor_type) == ARRAY_TYPE)\n \t{\n@@ -5406,7 +5394,7 @@ pop_init_level (implicit)\n \t    {\n \t      tree maxindex\n \t\t= copy_node (size_diffop (constructor_unfilled_index,\n-\t\t\t\t\t  bitsize_int (1)));\n+\t\t\t\t\t  bitsize_one_node));\n \n \t      TYPE_DOMAIN (constructor_type) = build_index_type (maxindex);\n \t      TREE_TYPE (maxindex) = TYPE_DOMAIN (constructor_type);\n@@ -5914,7 +5902,7 @@ output_init_element (value, type, field, pending)\n \t\t   (size_binop (TRUNC_DIV_EXPR,\n \t\t\t\tsize_binop (MINUS_EXPR, bit_position (field),\n \t\t\t\t\t    constructor_bit_index),\n-\t\t\t\tbitsize_int (BITS_PER_UNIT)),\n+\t\t\t\tbitsize_unit_node),\n \t\t    0));\n \n \t      output_constant (digest_init (type, value,\n@@ -5936,7 +5924,7 @@ output_init_element (value, type, field, pending)\n       if (TREE_CODE (constructor_type) == ARRAY_TYPE)\n \tconstructor_unfilled_index\n \t  = size_binop (PLUS_EXPR, constructor_unfilled_index,\n-\t\t\tbitsize_int (1));\n+\t\t\tbitsize_one_node);\n       else if (TREE_CODE (constructor_type) == RECORD_TYPE)\n \t{\n \t  constructor_unfilled_fields\n@@ -6089,7 +6077,7 @@ output_pending_init_elements (all)\n   if (constructor_incremental)\n     {\n       tree filled;\n-      tree nextpos_tree = bitsize_int (0);\n+      tree nextpos_tree = bitsize_zero_node;\n \n       if (TREE_CODE (constructor_type) == RECORD_TYPE\n \t  || TREE_CODE (constructor_type) == UNION_TYPE)\n@@ -6105,17 +6093,13 @@ output_pending_init_elements (all)\n \t  if (tail)\n \t    /* Find the offset of the end of that field.  */\n \t    filled = size_binop (CEIL_DIV_EXPR,\n-\t\t\t\t size_binop (PLUS_EXPR,\n-\t\t\t\t\t     bit_position (tail),\n+\t\t\t\t size_binop (PLUS_EXPR, bit_position (tail),\n \t\t\t\t\t     DECL_SIZE (tail)),\n-\t\t\t\t bitsize_int (BITS_PER_UNIT));\n+\t\t\t\t bitsize_unit_node);\n \t  else\n-\t    filled = bitsize_int (0);\n-\n-\t  nextpos_tree = size_binop (CEIL_DIV_EXPR,\n-\t\t\t\t     bit_position (next),\n-\t\t\t\t     bitsize_int (BITS_PER_UNIT));\n+\t    filled = bitsize_zero_node;\n \n+\t  nextpos_tree = convert (bitsizetype, byte_position (next));\n \t  constructor_bit_index = bit_position (next);\n \t  constructor_unfilled_fields = next;\n \t}\n@@ -6395,7 +6379,7 @@ process_init_element (value)\n \t\t}\n \n \t      constructor_index\n-\t\t= size_binop (PLUS_EXPR, constructor_index, bitsize_int (1));\n+\t\t= size_binop (PLUS_EXPR, constructor_index, bitsize_one_node);\n \n \t      if (! value)\n \t\t/* If we are doing the bookkeeping for an element that was"}, {"sha": "cc3197791193f17adb98e578d24117e500bf6fe5", "filename": "gcc/ch/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fch%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fch%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fch%2FChangeLog?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,3 +1,9 @@\n+Sat Mar 25 09:12:10 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n+\n+\t* actions.c (check_missing_cases): BYTES_NEEDED is HOST_WIDE_INT.\n+\t* typeck.c (expand_constant_to_buffer): Use int_byte_position.\n+\t(extract_constant_from_buffer): Likewise.\n+\n Fri Mar 17 08:09:14 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n \n \t* typeck.c (min_precision): New function."}, {"sha": "32bb18152add5621a829c3ece5ee3a6f560e5b85", "filename": "gcc/ch/actions.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fch%2Factions.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fch%2Factions.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fch%2Factions.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1453,7 +1453,8 @@ check_missing_cases (type)\n   unsigned char *cases_seen;\n   /* The number of possible selector values. */\n   HOST_WIDE_INT size = all_cases_count (type, &is_sparse);\n-  long bytes_needed = (size+HOST_BITS_PER_CHAR)/HOST_BITS_PER_CHAR;\n+  HOST_WIDE_INT bytes_needed\n+    = (size + HOST_BITS_PER_CHAR) / HOST_BITS_PER_CHAR;\n \n   if (size == -1)\n     warning (\"CASE selector with variable range\");"}, {"sha": "17539602e308771ed520eb9b39c3732b87ec6cb1", "filename": "gcc/ch/typeck.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fch%2Ftypeck.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fch%2Ftypeck.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fch%2Ftypeck.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -830,7 +830,7 @@ expand_constant_to_buffer (value, buffer, buf_size)\n \t      if (DECL_BIT_FIELD (field))\n \t\treturn 0;\n \n-\t      offset = int_bit_position (field) / BITS_PER_UNIT;\n+\t      offset = int_byte_position (field);\n \t      if (!expand_constant_to_buffer (TREE_VALUE (list),\n \t\t\t\t\t      buffer + offset,\n \t\t\t\t\t      buf_size - offset))\n@@ -946,7 +946,7 @@ extract_constant_from_buffer (type, buffer, buf_size)\n \ttree field = TYPE_FIELDS (type);\n \tfor (; field != NULL_TREE; field = TREE_CHAIN (field))\n \t  {\n-\t    HOST_WIDE_INT offset = int_bit_position (field) / BITS_PER_UNIT;\n+\t    HOST_WIDE_INT offset = int_byte_position (field);\n \n \t    if (DECL_BIT_FIELD (field))\n \t      return 0;"}, {"sha": "614a95dbfeca60a3fbbaa148387f8c5277136af9", "filename": "gcc/combine.c", "status": "modified", "additions": 178, "deletions": 141, "changes": 319, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -142,7 +142,7 @@ static int max_uid_cuid;\n \n /* Maximum register number, which is the size of the tables below.  */\n \n-static int combine_max_regno;\n+static unsigned int combine_max_regno;\n \n /* Record last point of death of (hard or pseudo) register n.  */\n \n@@ -291,7 +291,7 @@ static enum machine_mode nonzero_bits_mode;\n /* Nonzero if we know that a register has some leading bits that are always\n    equal to the sign bit.  */\n \n-static char *reg_sign_bit_copies;\n+static unsigned char *reg_sign_bit_copies;\n \n /* Nonzero when reg_nonzero_bits and reg_sign_bit_copies can be safely used.\n    It is zero while computing them and after combine has completed.  This\n@@ -371,11 +371,13 @@ static rtx simplify_set\t\tPARAMS ((rtx));\n static rtx simplify_logical\tPARAMS ((rtx, int));\n static rtx expand_compound_operation  PARAMS ((rtx));\n static rtx expand_field_assignment  PARAMS ((rtx));\n-static rtx make_extraction\tPARAMS ((enum machine_mode, rtx, int, rtx, int,\n-\t\t\t\t\t int, int, int));\n+static rtx make_extraction\tPARAMS ((enum machine_mode, rtx, HOST_WIDE_INT,\n+\t\t\t\t\t rtx, unsigned HOST_WIDE_INT, int,\n+\t\t\t\t\t int, int));\n static rtx extract_left_shift\tPARAMS ((rtx, int));\n static rtx make_compound_operation  PARAMS ((rtx, enum rtx_code));\n-static int get_pos_from_mask\tPARAMS ((unsigned HOST_WIDE_INT, int *));\n+static int get_pos_from_mask\tPARAMS ((unsigned HOST_WIDE_INT,\n+\t\t\t\t\t unsigned HOST_WIDE_INT *));\n static rtx force_to_mode\tPARAMS ((rtx, enum machine_mode,\n \t\t\t\t\t unsigned HOST_WIDE_INT, rtx, int));\n static rtx if_then_else_cond\tPARAMS ((rtx, rtx *, rtx *));\n@@ -386,7 +388,7 @@ static rtx apply_distributive_law  PARAMS ((rtx));\n static rtx simplify_and_const_int  PARAMS ((rtx, enum machine_mode, rtx,\n \t\t\t\t\t    unsigned HOST_WIDE_INT));\n static unsigned HOST_WIDE_INT nonzero_bits  PARAMS ((rtx, enum machine_mode));\n-static int num_sign_bit_copies  PARAMS ((rtx, enum machine_mode));\n+static unsigned int num_sign_bit_copies  PARAMS ((rtx, enum machine_mode));\n static int merge_outer_ops\tPARAMS ((enum rtx_code *, HOST_WIDE_INT *,\n \t\t\t\t\t enum rtx_code, HOST_WIDE_INT,\n \t\t\t\t\t enum machine_mode, int *));\n@@ -488,7 +490,7 @@ do_SUBST_INT(into, newval)\n int\n combine_instructions (f, nregs)\n      rtx f;\n-     int nregs;\n+     unsigned int nregs;\n {\n   register rtx insn, next;\n #ifdef HAVE_cc0\n@@ -508,7 +510,8 @@ combine_instructions (f, nregs)\n \n   reg_nonzero_bits = ((unsigned HOST_WIDE_INT *) \n \t\t      xcalloc (nregs, sizeof (unsigned HOST_WIDE_INT)));\n-  reg_sign_bit_copies = (char *) xcalloc (nregs, sizeof (char));\n+  reg_sign_bit_copies\n+    = (unsigned char *) xcalloc (nregs, sizeof (unsigned char));\n \n   reg_last_death = (rtx *) xmalloc (nregs * sizeof (rtx));\n   reg_last_set = (rtx *) xmalloc (nregs * sizeof (rtx));\n@@ -764,7 +767,7 @@ combine_instructions (f, nregs)\n static void\n init_reg_last_arrays ()\n {\n-  int nregs = combine_max_regno;\n+  unsigned int nregs = combine_max_regno;\n \n   bzero ((char *) reg_last_death, nregs * sizeof (rtx));\n   bzero ((char *) reg_last_set, nregs * sizeof (rtx));\n@@ -783,7 +786,7 @@ static void\n setup_incoming_promotions ()\n {\n #ifdef PROMOTE_FUNCTION_ARGS\n-  int regno;\n+  unsigned int regno;\n   rtx reg;\n   enum machine_mode mode;\n   int unsignedp;\n@@ -825,7 +828,7 @@ set_nonzero_bits_and_sign_copies (x, set, data)\n      rtx set;\n      void *data ATTRIBUTE_UNUSED;\n {\n-  int num;\n+  unsigned int num;\n \n   if (GET_CODE (x) == REG\n       && REGNO (x) >= FIRST_PSEUDO_REGISTER\n@@ -967,10 +970,12 @@ can_combine_p (insn, i3, pred, succ, pdest, psrc)\n \t\t{\n \t\t  rtx i3pat = PATTERN (i3);\n \t\t  int i = XVECLEN (i3pat, 0) - 1;\n-\t\t  int regno = REGNO (XEXP (elt, 0));\n+\t\t  unsigned int regno = REGNO (XEXP (elt, 0));\n+\n \t\t  do\n \t\t    {\n \t\t      rtx i3elt = XVECEXP (i3pat, 0, i);\n+\n \t\t      if (GET_CODE (i3elt) == USE\n \t\t\t  && GET_CODE (XEXP (i3elt, 0)) == REG\n \t\t\t  && (REGNO (XEXP (i3elt, 0)) == regno\n@@ -1866,7 +1871,7 @@ try_combine (i3, i2, i1, new_direct_jump_p)\n \t\t\t\t\t      i2src, const0_rtx))\n \t      != GET_MODE (SET_DEST (newpat))))\n \t{\n-\t  int regno = REGNO (SET_DEST (newpat));\n+\t  unsigned int regno = REGNO (SET_DEST (newpat));\n \t  rtx new_dest = gen_rtx_REG (compare_mode, regno);\n \n \t  if (regno < FIRST_PSEUDO_REGISTER\n@@ -2431,7 +2436,7 @@ try_combine (i3, i2, i1, new_direct_jump_p)\n     rtx i3notes, i2notes, i1notes = 0;\n     rtx i3links, i2links, i1links = 0;\n     rtx midnotes = 0;\n-    register int regno;\n+    unsigned int regno;\n     /* Compute which registers we expect to eliminate.  newi2pat may be setting\n        either i3dest or i2dest, so we must check it.  Also, i1dest may be the\n        same as i3dest, in which case newi2pat may be setting i1dest.  */\n@@ -2691,9 +2696,7 @@ try_combine (i3, i2, i1, new_direct_jump_p)\n \n \tregno = REGNO (i1dest);\n \tif (! added_sets_1 && ! i1dest_in_i1src)\n-\t  {\n-\t    REG_N_SETS (regno)--;\n-\t  }\n+\t  REG_N_SETS (regno)--;\n       }\n \n     /* Update reg_nonzero_bits et al for any changes that may have been made\n@@ -2795,7 +2798,9 @@ find_split_point (loc, insn)\n   rtx x = *loc;\n   enum rtx_code code = GET_CODE (x);\n   rtx *split;\n-  int len = 0, pos = 0, unsignedp = 0;\n+  unsigned HOST_WIDE_INT len = 0;\n+  HOST_WIDE_INT pos = 0;\n+  int unsignedp = 0;\n   rtx inner = NULL_RTX;\n \n   /* First special-case some codes.  */\n@@ -2930,17 +2935,17 @@ find_split_point (loc, insn)\n \t      <= GET_MODE_BITSIZE (GET_MODE (XEXP (SET_DEST (x), 0))))\n \t  && ! side_effects_p (XEXP (SET_DEST (x), 0)))\n \t{\n-\t  int pos = INTVAL (XEXP (SET_DEST (x), 2));\n-\t  int len = INTVAL (XEXP (SET_DEST (x), 1));\n-\t  int src = INTVAL (SET_SRC (x));\n+\t  HOST_WIDE_INT pos = INTVAL (XEXP (SET_DEST (x), 2));\n+\t  unsigned HOST_WIDE_INT len = INTVAL (XEXP (SET_DEST (x), 1));\n+\t  unsigned HOST_WIDE_INT src = INTVAL (SET_SRC (x));\n \t  rtx dest = XEXP (SET_DEST (x), 0);\n \t  enum machine_mode mode = GET_MODE (dest);\n \t  unsigned HOST_WIDE_INT mask = ((HOST_WIDE_INT) 1 << len) - 1;\n \n \t  if (BITS_BIG_ENDIAN)\n \t    pos = GET_MODE_BITSIZE (mode) - len - pos;\n \n-\t  if ((unsigned HOST_WIDE_INT) src == mask)\n+\t  if (src == mask)\n \t    SUBST (SET_SRC (x),\n \t\t   gen_binary (IOR, mode, dest, GEN_INT (src << pos)));\n \t  else\n@@ -4143,7 +4148,7 @@ combine_simplify_rtx (x, op0_mode, last, in_dest)\n \t\t   == ((HOST_WIDE_INT) 1 << (i + 1)) - 1))\n \t      || (GET_CODE (XEXP (XEXP (x, 0), 0)) == ZERO_EXTEND\n \t\t  && (GET_MODE_BITSIZE (GET_MODE (XEXP (XEXP (XEXP (x, 0), 0), 0)))\n-\t\t      == i + 1))))\n+\t\t      == (unsigned int) i + 1))))\n \treturn simplify_shift_const\n \t  (NULL_RTX, ASHIFTRT, mode,\n \t   simplify_shift_const (NULL_RTX, ASHIFT, mode,\n@@ -4866,7 +4871,7 @@ simplify_set (x)\n \t which case we can safely change its mode.  */\n       if (compare_mode != GET_MODE (dest))\n \t{\n-\t  int regno = REGNO (dest);\n+\t  unsigned int regno = REGNO (dest);\n \t  rtx new_dest = gen_rtx_REG (compare_mode, regno);\n \n \t  if (regno < FIRST_PSEUDO_REGISTER\n@@ -5458,9 +5463,9 @@ static rtx\n expand_compound_operation (x)\n      rtx x;\n {\n-  int pos = 0, len;\n+  unsigned HOST_WIDE_INT pos = 0, len;\n   int unsignedp = 0;\n-  int modewidth;\n+  unsigned int modewidth;\n   rtx tem;\n \n   switch (GET_CODE (x))\n@@ -5608,7 +5613,7 @@ expand_compound_operation (x)\n      a such a position.  */\n \n   modewidth = GET_MODE_BITSIZE (GET_MODE (x));\n-  if (modewidth >= pos - len)\n+  if (modewidth + len >= pos)\n     tem = simplify_shift_const (NULL_RTX, unsignedp ? LSHIFTRT : ASHIFTRT,\n \t\t\t\tGET_MODE (x),\n \t\t\t\tsimplify_shift_const (NULL_RTX, ASHIFT,\n@@ -5800,9 +5805,9 @@ make_extraction (mode, inner, pos, pos_rtx, len,\n \t\t unsignedp, in_dest, in_compare)\n      enum machine_mode mode;\n      rtx inner;\n-     int pos;\n+     HOST_WIDE_INT pos;\n      rtx pos_rtx;\n-     int len;\n+     unsigned HOST_WIDE_INT len;\n      int unsignedp;\n      int in_dest, in_compare;\n {\n@@ -5819,7 +5824,7 @@ make_extraction (mode, inner, pos, pos_rtx, len,\n   int spans_byte = 0;\n   rtx new = 0;\n   rtx orig_pos_rtx = pos_rtx;\n-  int orig_pos;\n+  HOST_WIDE_INT orig_pos;\n \n   /* Get some information about INNER and get the innermost object.  */\n   if (GET_CODE (inner) == USE)\n@@ -6528,7 +6533,7 @@ make_compound_operation (x, in_code)\n static int\n get_pos_from_mask (m, plen)\n      unsigned HOST_WIDE_INT m;\n-     int *plen;\n+     unsigned HOST_WIDE_INT *plen;\n {\n   /* Get the bit number of the first 1 bit from the right, -1 if none.  */\n   int pos = exact_log2 (m & - m);\n@@ -6748,7 +6753,7 @@ force_to_mode (x, mode, mask, reg, just_select)\n \t This may eliminate that PLUS and, later, the AND.  */\n \n       {\n-\tint width = GET_MODE_BITSIZE (mode);\n+\tunsigned int width = GET_MODE_BITSIZE (mode);\n \tunsigned HOST_WIDE_INT smask = mask;\n \n \t/* If MODE is narrower than HOST_WIDE_INT and mask is a negative\n@@ -6920,7 +6925,7 @@ force_to_mode (x, mode, mask, reg, just_select)\n \t       + num_sign_bit_copies (XEXP (x, 0), GET_MODE (XEXP (x, 0))))\n \t      >= GET_MODE_BITSIZE (GET_MODE (x)))\n \t  && exact_log2 (mask + 1) >= 0\n-\t  && (num_sign_bit_copies (XEXP (x, 0), GET_MODE (XEXP (x, 0)))\n+\t  && ((int) num_sign_bit_copies (XEXP (x, 0), GET_MODE (XEXP (x, 0)))\n \t      >= exact_log2 (mask + 1)))\n \tx = gen_binary (LSHIFTRT, GET_MODE (x), XEXP (x, 0),\n \t\t\tGEN_INT (GET_MODE_BITSIZE (GET_MODE (x))\n@@ -7119,7 +7124,7 @@ if_then_else_cond (x, ptrue, pfalse)\n {\n   enum machine_mode mode = GET_MODE (x);\n   enum rtx_code code = GET_CODE (x);\n-  int size = GET_MODE_BITSIZE (mode);\n+  unsigned int size = GET_MODE_BITSIZE (mode);\n   rtx cond0, cond1, true0, true1, false0, false1;\n   unsigned HOST_WIDE_INT nz;\n \n@@ -7455,7 +7460,8 @@ make_field_assignment (x)\n   rtx assign;\n   rtx rhs, lhs;\n   HOST_WIDE_INT c1;\n-  int pos, len;\n+  HOST_WIDE_INT pos;\n+  unsigned HOST_WIDE_INT len;\n   rtx other;\n   enum machine_mode mode;\n \n@@ -7802,7 +7808,7 @@ nonzero_bits (x, mode)\n   unsigned HOST_WIDE_INT nonzero = GET_MODE_MASK (mode);\n   unsigned HOST_WIDE_INT inner_nz;\n   enum rtx_code code;\n-  int mode_width = GET_MODE_BITSIZE (mode);\n+  unsigned int mode_width = GET_MODE_BITSIZE (mode);\n   rtx tem;\n \n   /* For floating-point values, assume all bits are needed.  */\n@@ -8050,7 +8056,7 @@ nonzero_bits (x, mode)\n \t  = (nz0 & ((HOST_WIDE_INT) 1 << (mode_width - 1)));\n \tHOST_WIDE_INT op1_maybe_minusp\n \t  = (nz1 & ((HOST_WIDE_INT) 1 << (mode_width - 1)));\n-\tint result_width = mode_width;\n+\tunsigned int result_width = mode_width;\n \tint result_low = 0;\n \n \tswitch (code)\n@@ -8171,7 +8177,7 @@ nonzero_bits (x, mode)\n \t  && INTVAL (XEXP (x, 1)) < HOST_BITS_PER_WIDE_INT)\n \t{\n \t  enum machine_mode inner_mode = GET_MODE (x);\n-\t  int width = GET_MODE_BITSIZE (inner_mode);\n+\t  unsigned int width = GET_MODE_BITSIZE (inner_mode);\n \t  int count = INTVAL (XEXP (x, 1));\n \t  unsigned HOST_WIDE_INT mode_mask = GET_MODE_MASK (inner_mode);\n \t  unsigned HOST_WIDE_INT op_nonzero = nonzero_bits (XEXP (x, 0), mode);\n@@ -8228,13 +8234,13 @@ nonzero_bits (x, mode)\n    VOIDmode, X will be used in its own mode.  The returned value  will always\n    be between 1 and the number of bits in MODE.  */\n \n-static int\n+static unsigned int\n num_sign_bit_copies (x, mode)\n      rtx x;\n      enum machine_mode mode;\n {\n   enum rtx_code code = GET_CODE (x);\n-  int bitwidth;\n+  unsigned int bitwidth;\n   int num0, num1, result;\n   unsigned HOST_WIDE_INT nonzero;\n   rtx tem;\n@@ -8253,8 +8259,11 @@ num_sign_bit_copies (x, mode)\n \n   /* For a smaller object, just ignore the high bits.  */\n   if (bitwidth < GET_MODE_BITSIZE (GET_MODE (x)))\n-    return MAX (1, (num_sign_bit_copies (x, GET_MODE (x))\n-\t\t    - (GET_MODE_BITSIZE (GET_MODE (x)) - bitwidth)));\n+    {\n+      num0 = num_sign_bit_copies (x, GET_MODE (x));\n+      return MAX (1,\n+\t\t  num0 - (int) (GET_MODE_BITSIZE (GET_MODE (x)) - bitwidth));\n+    }\n      \n   if (GET_MODE (x) != VOIDmode && bitwidth > GET_MODE_BITSIZE (GET_MODE (x)))\n     {\n@@ -8310,7 +8319,8 @@ num_sign_bit_copies (x, mode)\n #ifdef LOAD_EXTEND_OP\n       /* Some RISC machines sign-extend all loads of smaller than a word.  */\n       if (LOAD_EXTEND_OP (GET_MODE (x)) == SIGN_EXTEND)\n-\treturn MAX (1, bitwidth - GET_MODE_BITSIZE (GET_MODE (x)) + 1);\n+\treturn MAX (1, ((int) bitwidth\n+\t\t\t- (int) GET_MODE_BITSIZE (GET_MODE (x)) + 1));\n #endif\n       break;\n \n@@ -8330,16 +8340,20 @@ num_sign_bit_copies (x, mode)\n \t high-order bits are known to be sign bit copies.  */\n \n       if (SUBREG_PROMOTED_VAR_P (x) && ! SUBREG_PROMOTED_UNSIGNED_P (x))\n-\treturn MAX (bitwidth - GET_MODE_BITSIZE (GET_MODE (x)) + 1,\n-\t\t    num_sign_bit_copies (SUBREG_REG (x), mode));\n-\n+\t{\n+\t  num0 = num_sign_bit_copies (SUBREG_REG (x), mode);\n+\t  return MAX ((int) bitwidth\n+\t\t      - (int) GET_MODE_BITSIZE (GET_MODE (x)) + 1,\n+\t\t      num0);\n+\t}\n+\t\t \n       /* For a smaller object, just ignore the high bits.  */\n       if (bitwidth <= GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))))\n \t{\n \t  num0 = num_sign_bit_copies (SUBREG_REG (x), VOIDmode);\n \t  return MAX (1, (num0\n-\t\t\t  - (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x)))\n-\t\t\t     - bitwidth)));\n+\t\t\t  - (int) (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x)))\n+\t\t\t\t   - bitwidth)));\n \t}\n \n #ifdef WORD_REGISTER_OPERATIONS\n@@ -8364,7 +8378,7 @@ num_sign_bit_copies (x, mode)\n \n     case SIGN_EXTRACT:\n       if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n-\treturn MAX (1, bitwidth - INTVAL (XEXP (x, 1)));\n+\treturn MAX (1, (int) bitwidth - INTVAL (XEXP (x, 1)));\n       break;\n \n     case SIGN_EXTEND: \n@@ -8374,8 +8388,8 @@ num_sign_bit_copies (x, mode)\n     case TRUNCATE:\n       /* For a smaller object, just ignore the high bits.  */\n       num0 = num_sign_bit_copies (XEXP (x, 0), VOIDmode);\n-      return MAX (1, (num0 - (GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0)))\n-\t\t\t      - bitwidth)));\n+      return MAX (1, (num0 - (int) (GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0)))\n+\t\t\t\t    - bitwidth)));\n \n     case NOT:\n       return num_sign_bit_copies (XEXP (x, 0), mode);\n@@ -8389,7 +8403,7 @@ num_sign_bit_copies (x, mode)\n \t{\n \t  num0 = num_sign_bit_copies (XEXP (x, 0), mode);\n \t  return MAX (1, num0 - (code == ROTATE ? INTVAL (XEXP (x, 1))\n-\t\t\t\t : bitwidth - INTVAL (XEXP (x, 1))));\n+\t\t\t\t : (int) bitwidth - INTVAL (XEXP (x, 1))));\n \t}\n       break;\n \n@@ -8557,7 +8571,7 @@ num_sign_bit_copies (x, mode)\n    This function will always return 0 unless called during combine, which\n    implies that it must be called from a define_split.  */\n \n-int\n+unsigned int\n extended_count (x, mode, unsignedp)\n      rtx x;\n      enum machine_mode mode;\n@@ -8568,8 +8582,9 @@ extended_count (x, mode, unsignedp)\n \n   return (unsignedp\n \t  ? (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n-\t     && (GET_MODE_BITSIZE (mode) - 1\n-\t\t - floor_log2 (nonzero_bits (x, mode))))\n+\t     ? (GET_MODE_BITSIZE (mode) - 1\n+\t\t- floor_log2 (nonzero_bits (x, mode)))\n+\t     : 0)\n \t  : num_sign_bit_copies (x, mode) - 1);\n }\n \f\n@@ -8719,18 +8734,20 @@ merge_outer_ops (pop0, pconst0, op1, const1, mode, pcomp_p)\n    are ASHIFTRT and ROTATE, which are always done in their original mode,  */\n \n static rtx\n-simplify_shift_const (x, code, result_mode, varop, count)\n+simplify_shift_const (x, code, result_mode, varop, input_count)\n      rtx x;\n      enum rtx_code code;\n      enum machine_mode result_mode;\n      rtx varop;\n-     int count;\n+     int input_count;\n {\n   enum rtx_code orig_code = code;\n-  int orig_count = count;\n+  int orig_count = input_count;\n+  unsigned int count;\n+  int signed_count;\n   enum machine_mode mode = result_mode;\n   enum machine_mode shift_mode, tmode;\n-  int mode_words\n+  unsigned int mode_words\n     = (GET_MODE_SIZE (mode) + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD;\n   /* We form (outer_op (code varop count) (outer_const)).  */\n   enum rtx_code outer_op = NIL;\n@@ -8742,14 +8759,16 @@ simplify_shift_const (x, code, result_mode, varop, count)\n   /* If we were given an invalid count, don't do anything except exactly\n      what was requested.  */\n \n-  if (count < 0 || count > GET_MODE_BITSIZE (mode))\n+  if (input_count < 0 || input_count > (int) GET_MODE_BITSIZE (mode))\n     {\n       if (x)\n \treturn x;\n \n-      return gen_rtx_fmt_ee (code, mode, varop, GEN_INT (count));\n+      return gen_rtx_fmt_ee (code, mode, varop, GEN_INT (input_count));\n     }\n \n+  count = input_count;\n+\n   /* Unless one of the branches of the `if' in this loop does a `continue',\n      we will `break' the loop after the `if'.  */\n \n@@ -8803,12 +8822,6 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t    }\n \t}\n \n-      /* Negative counts are invalid and should not have been made (a\n-\t programmer-specified negative count should have been handled\n-\t above).  */\n-      else if (count < 0)\n-\tabort ();\n-\n       /* An arithmetic right shift of a quantity known to be -1 or 0\n \t is a no-op.  */\n       if (code == ASHIFTRT\n@@ -8931,8 +8944,9 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t  if (GET_CODE (XEXP (varop, 1)) == CONST_INT\n \t      && exact_log2 (INTVAL (XEXP (varop, 1))) >= 0)\n \t    {\n-\t      varop = gen_binary (ASHIFT, GET_MODE (varop), XEXP (varop, 0),\n-\t\t\t\t  GEN_INT (exact_log2 (INTVAL (XEXP (varop, 1)))));\n+\t      varop\n+\t\t= gen_binary (ASHIFT, GET_MODE (varop), XEXP (varop, 0),\n+\t\t\t      GEN_INT (exact_log2 (INTVAL (XEXP (varop, 1)))));\n \t      continue;\n \t    }\n \t  break;\n@@ -8942,8 +8956,9 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t  if (GET_CODE (XEXP (varop, 1)) == CONST_INT\n \t      && exact_log2 (INTVAL (XEXP (varop, 1))) >= 0)\n \t    {\n-\t      varop = gen_binary (LSHIFTRT, GET_MODE (varop), XEXP (varop, 0),\n-\t\t\t\t  GEN_INT (exact_log2 (INTVAL (XEXP (varop, 1)))));\n+\t      varop\n+\t\t= gen_binary (LSHIFTRT, GET_MODE (varop), XEXP (varop, 0),\n+\t\t\t      GEN_INT (exact_log2 (INTVAL (XEXP (varop, 1)))));\n \t      continue;\n \t    }\n \t  break;\n@@ -8971,7 +8986,7 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n \t    {\n \t      enum rtx_code first_code = GET_CODE (varop);\n-\t      int first_count = INTVAL (XEXP (varop, 1));\n+\t      unsigned int first_count = INTVAL (XEXP (varop, 1));\n \t      unsigned HOST_WIDE_INT mask;\n \t      rtx mask_rtx;\n \n@@ -9012,10 +9027,14 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t\t  && (num_sign_bit_copies (XEXP (varop, 0), shift_mode)\n \t\t      > first_count))\n \t\t{\n-\t\t  count -= first_count;\n-\t\t  if (count < 0)\n-\t\t    count = - count, code = ASHIFT;\n \t\t  varop = XEXP (varop, 0);\n+\n+\t\t  signed_count = count - first_count;\n+\t\t  if (signed_count < 0)\n+\t\t    count = - signed_count, code = ASHIFT;\n+\t\t  else\n+\t\t    count = signed_count;\n+\n \t\t  continue;\n \t\t}\n \n@@ -9075,22 +9094,25 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \n \t      /* If the shifts are in the same direction, we add the\n \t\t counts.  Otherwise, we subtract them.  */\n+\t      signed_count = count;\n \t      if ((code == ASHIFTRT || code == LSHIFTRT)\n \t\t  == (first_code == ASHIFTRT || first_code == LSHIFTRT))\n-\t\tcount += first_count;\n+\t\tsigned_count += first_count;\n \t      else\n-\t\tcount -= first_count;\n+\t\tsigned_count -= first_count;\n \n \t      /* If COUNT is positive, the new shift is usually CODE, \n \t\t except for the two exceptions below, in which case it is\n \t\t FIRST_CODE.  If the count is negative, FIRST_CODE should\n \t\t always be used  */\n-\t      if (count > 0\n+\t      if (signed_count > 0\n \t\t  && ((first_code == ROTATE && code == ASHIFT)\n \t\t      || (first_code == ASHIFTRT && code == LSHIFTRT)))\n-\t\tcode = first_code;\n-\t      else if (count < 0)\n-\t\tcode = first_code, count = - count;\n+\t\tcode = first_code, count = signed_count;\n+\t      else if (signed_count < 0)\n+\t\tcode = first_code, count = - signed_count;\n+\t      else\n+\t\tcount = signed_count;\n \n \t      varop = XEXP (varop, 0);\n \t      continue;\n@@ -9191,7 +9213,8 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t      && count == GET_MODE_BITSIZE (result_mode) - 1\n \t      && GET_MODE_BITSIZE (result_mode) <= HOST_BITS_PER_WIDE_INT\n \t      && ((STORE_FLAG_VALUE\n-\t\t   & ((HOST_WIDE_INT) 1 << (GET_MODE_BITSIZE (result_mode) - 1))))\n+\t\t   & ((HOST_WIDE_INT) 1 \n+\t\t      < (GET_MODE_BITSIZE (result_mode) - 1))))\n \t      && nonzero_bits (XEXP (varop, 0), result_mode) == 1\n \t      && merge_outer_ops (&outer_op, &outer_const, XOR,\n \t\t\t\t  (HOST_WIDE_INT) 1, result_mode,\n@@ -9276,7 +9299,7 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t      && (new = simplify_binary_operation (ASHIFT, result_mode,\n \t\t\t\t\t\t   XEXP (varop, 1),\n \t\t\t\t\t\t   GEN_INT (count))) != 0\n-\t      && GET_CODE(new) == CONST_INT\n+\t      && GET_CODE (new) == CONST_INT\n \t      && merge_outer_ops (&outer_op, &outer_const, PLUS,\n \t\t\t\t  INTVAL (new), result_mode, &complement_p))\n \t    {\n@@ -9324,10 +9347,11 @@ simplify_shift_const (x, code, result_mode, varop, count)\n \t    {\n \t      rtx varop_inner = XEXP (varop, 0);\n \n-\t      varop_inner = gen_rtx_combine (LSHIFTRT,\n-\t\t\t\t\t     GET_MODE (varop_inner),\n-\t\t\t\t\t     XEXP (varop_inner, 0),\n-\t\t\t\t\t     GEN_INT (count + INTVAL (XEXP (varop_inner, 1))));\n+\t      varop_inner\n+\t\t= gen_rtx_combine (LSHIFTRT, GET_MODE (varop_inner),\n+\t\t\t\t   XEXP (varop_inner, 0),\n+\t\t\t\t   GEN_INT (count\n+\t\t\t\t\t    + INTVAL (XEXP (varop_inner, 1))));\n \t      varop = gen_rtx_combine (TRUNCATE, GET_MODE (varop),\n \t\t\t\t       varop_inner);\n \t      count = 0;\n@@ -9968,7 +9992,7 @@ simplify_comparison (code, pop0, pop1)\n   while (GET_CODE (op1) == CONST_INT)\n     {\n       enum machine_mode mode = GET_MODE (op0);\n-      int mode_width = GET_MODE_BITSIZE (mode);\n+      unsigned int mode_width = GET_MODE_BITSIZE (mode);\n       unsigned HOST_WIDE_INT mask = GET_MODE_MASK (mode);\n       int equality_comparison_p;\n       int sign_bit_comparison_p;\n@@ -10943,12 +10967,14 @@ update_table_tick (x)\n \n   if (code == REG)\n     {\n-      int regno = REGNO (x);\n-      int endregno = regno + (regno < FIRST_PSEUDO_REGISTER\n-\t\t\t      ? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n+      unsigned int regno = REGNO (x);\n+      unsigned int endregno\n+\t= regno + (regno < FIRST_PSEUDO_REGISTER\n+\t\t   ? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n+      unsigned int r;\n \n-      for (i = regno; i < endregno; i++)\n-\treg_last_set_table_tick[i] = label_tick;\n+      for (r = regno; r < endregno; r++)\n+\treg_last_set_table_tick[r] = label_tick;\n \n       return;\n     }\n@@ -10971,10 +10997,11 @@ record_value_for_reg (reg, insn, value)\n      rtx insn;\n      rtx value;\n {\n-  int regno = REGNO (reg);\n-  int endregno = regno + (regno < FIRST_PSEUDO_REGISTER\n-\t\t\t  ? HARD_REGNO_NREGS (regno, GET_MODE (reg)) : 1);\n-  int i;\n+  unsigned int regno = REGNO (reg);\n+  unsigned int endregno\n+    = regno + (regno < FIRST_PSEUDO_REGISTER\n+\t       ? HARD_REGNO_NREGS (regno, GET_MODE (reg)) : 1);\n+  unsigned int i;\n \n   /* If VALUE contains REG and we have a previous value for REG, substitute\n      the previous value.  */\n@@ -11007,10 +11034,11 @@ record_value_for_reg (reg, insn, value)\n      we don't know about its bitwise content, that its value has been\n      updated, and that we don't know the location of the death of the\n      register.  */\n-  for (i = regno; i < endregno; i ++)\n+  for (i = regno; i < endregno; i++)\n     {\n       if (insn)\n \treg_last_set[i] = insn;\n+\n       reg_last_set_value[i] = 0;\n       reg_last_set_mode[i] = 0;\n       reg_last_set_nonzero_bits[i] = 0;\n@@ -11118,15 +11146,15 @@ record_dead_and_set_regs (insn)\n      rtx insn;\n {\n   register rtx link;\n-  int i;\n+  unsigned int i;\n \n   for (link = REG_NOTES (insn); link; link = XEXP (link, 1))\n     {\n       if (REG_NOTE_KIND (link) == REG_DEAD\n \t  && GET_CODE (XEXP (link, 0)) == REG)\n \t{\n-\t  int regno = REGNO (XEXP (link, 0));\n-\t  int endregno\n+\t  unsigned int regno = REGNO (XEXP (link, 0));\n+\t  unsigned int endregno\n \t    = regno + (regno < FIRST_PSEUDO_REGISTER\n \t\t       ? HARD_REGNO_NREGS (regno, GET_MODE (XEXP (link, 0)))\n \t\t       : 1);\n@@ -11171,7 +11199,7 @@ record_promoted_value (insn, subreg)\n     rtx subreg;\n {\n   rtx links, set;\n-  int regno = REGNO (SUBREG_REG (subreg));\n+  unsigned int regno = REGNO (SUBREG_REG (subreg));\n   enum machine_mode mode = GET_MODE (subreg);\n \n   if (GET_MODE_BITSIZE (mode) >= HOST_BITS_PER_WIDE_INT)\n@@ -11262,18 +11290,20 @@ get_last_value_validate (loc, insn, tick, replace)\n \n   if (GET_CODE (x) == REG)\n     {\n-      int regno = REGNO (x);\n-      int endregno = regno + (regno < FIRST_PSEUDO_REGISTER\n-\t\t\t      ? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n-      int j;\n+      unsigned int regno = REGNO (x);\n+      unsigned int endregno\n+\t= regno + (regno < FIRST_PSEUDO_REGISTER\n+\t\t   ? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n+      unsigned int j;\n \n       for (j = regno; j < endregno; j++)\n \tif (reg_last_set_invalid[j]\n \t    /* If this is a pseudo-register that was only set once and not\n \t       live at the beginning of the function, it is always valid.  */\n \t    || (! (regno >= FIRST_PSEUDO_REGISTER \n \t\t   && REG_N_SETS (regno) == 1\n-\t\t   && ! REGNO_REG_SET_P (BASIC_BLOCK (0)->global_live_at_start, regno))\n+\t\t   && (! REGNO_REG_SET_P\n+\t\t       (BASIC_BLOCK (0)->global_live_at_start, regno)))\n \t\t&& reg_last_set_label[j] > tick))\n \t  {\n \t    if (replace)\n@@ -11313,7 +11343,7 @@ static rtx\n get_last_value (x)\n      rtx x;\n {\n-  int regno;\n+  unsigned int regno;\n   rtx value;\n \n   /* If this is a non-paradoxical SUBREG, get the value of its operand and\n@@ -11346,7 +11376,8 @@ get_last_value (x)\n       || (reg_last_set_label[regno] != label_tick\n \t  && (regno < FIRST_PSEUDO_REGISTER\n \t      || REG_N_SETS (regno) != 1\n-\t      || REGNO_REG_SET_P (BASIC_BLOCK (0)->global_live_at_start, regno))))\n+\t      || (REGNO_REG_SET_P\n+\t\t  (BASIC_BLOCK (0)->global_live_at_start, regno)))))\n     return 0;\n \n   /* If the value was set in a later insn than the ones we are processing,\n@@ -11384,8 +11415,8 @@ use_crosses_set_p (x, from_cuid)\n \n   if (code == REG)\n     {\n-      register int regno = REGNO (x);\n-      int endreg = regno + (regno < FIRST_PSEUDO_REGISTER\n+      unsigned int regno = REGNO (x);\n+      unsigned endreg = regno + (regno < FIRST_PSEUDO_REGISTER\n \t\t\t    ? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n       \n #ifdef PUSH_ROUNDING\n@@ -11394,7 +11425,7 @@ use_crosses_set_p (x, from_cuid)\n       if (regno == STACK_POINTER_REGNUM)\n \treturn 1;\n #endif\n-      for (;regno < endreg; regno++)\n+      for (; regno < endreg; regno++)\n \tif (reg_last_set[regno]\n \t    && INSN_CUID (reg_last_set[regno]) > from_cuid)\n \t  return 1;\n@@ -11425,7 +11456,7 @@ use_crosses_set_p (x, from_cuid)\n /* Define three variables used for communication between the following\n    routines.  */\n \n-static int reg_dead_regno, reg_dead_endregno;\n+static unsigned int reg_dead_regno, reg_dead_endregno;\n static int reg_dead_flag;\n \n /* Function called via note_stores from reg_dead_at_p.\n@@ -11439,7 +11470,7 @@ reg_dead_at_p_1 (dest, x, data)\n      rtx x;\n      void *data ATTRIBUTE_UNUSED;\n {\n-  int regno, endregno;\n+  unsigned int regno, endregno;\n \n   if (GET_CODE (dest) != REG)\n     return;\n@@ -11465,7 +11496,8 @@ reg_dead_at_p (reg, insn)\n      rtx reg;\n      rtx insn;\n {\n-  int block, i;\n+  int block;\n+  unsigned int i;\n \n   /* Set variables for reg_dead_at_p_1.  */\n   reg_dead_regno = REGNO (reg);\n@@ -11524,8 +11556,8 @@ static void\n mark_used_regs_combine (x)\n      rtx x;\n {\n-  register RTX_CODE code = GET_CODE (x);\n-  register int regno;\n+  RTX_CODE code = GET_CODE (x);\n+  unsigned int regno;\n   int i;\n \n   switch (code)\n@@ -11559,6 +11591,8 @@ mark_used_regs_combine (x)\n \t If so, mark all of them just like the first.  */\n       if (regno < FIRST_PSEUDO_REGISTER)\n \t{\n+\t  unsigned int endregno, r;\n+\n \t  /* None of this applies to the stack, frame or arg pointers */\n \t  if (regno == STACK_POINTER_REGNUM\n #if FRAME_POINTER_REGNUM != HARD_FRAME_POINTER_REGNUM\n@@ -11570,9 +11604,9 @@ mark_used_regs_combine (x)\n \t      || regno == FRAME_POINTER_REGNUM)\n \t    return;\n \n-\t  i = HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t  while (i-- > 0)\n-\t    SET_HARD_REG_BIT (newpat_used_regs, regno + i);\n+\t  endregno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\t  for (r = regno; r < endregno; r++)\n+\t    SET_HARD_REG_BIT (newpat_used_regs, r);\n \t}\n       return;\n \n@@ -11626,7 +11660,7 @@ mark_used_regs_combine (x)\n \n rtx\n remove_death (regno, insn)\n-     int regno;\n+     unsigned int regno;\n      rtx insn;\n {\n   register rtx note = find_regno_note (insn, REG_DEAD, regno);\n@@ -11664,20 +11698,21 @@ move_deaths (x, maybe_kill_insn, from_cuid, to_insn, pnotes)\n \n   if (code == REG)\n     {\n-      register int regno = REGNO (x);\n+      unsigned int regno = REGNO (x);\n       register rtx where_dead = reg_last_death[regno];\n       register rtx before_dead, after_dead;\n \n       /* Don't move the register if it gets killed in between from and to */\n       if (maybe_kill_insn && reg_set_p (x, maybe_kill_insn)\n-\t  && !reg_referenced_p (x, maybe_kill_insn))\n+\t  && ! reg_referenced_p (x, maybe_kill_insn))\n \treturn;\n \n       /* WHERE_DEAD could be a USE insn made by combine, so first we\n \t make sure that we have insns with valid INSN_CUID values.  */\n       before_dead = where_dead;\n       while (before_dead && INSN_UID (before_dead) > max_uid_cuid)\n \tbefore_dead = PREV_INSN (before_dead);\n+\n       after_dead = where_dead;\n       while (after_dead && INSN_UID (after_dead) > max_uid_cuid)\n \tafter_dead = NEXT_INSN (after_dead);\n@@ -11703,12 +11738,13 @@ move_deaths (x, maybe_kill_insn, from_cuid, to_insn, pnotes)\n \t      && (GET_MODE_SIZE (GET_MODE (XEXP (note, 0)))\n \t\t  > GET_MODE_SIZE (GET_MODE (x))))\n \t    {\n-\t      int deadregno = REGNO (XEXP (note, 0));\n-\t      int deadend\n+\t      unsigned int deadregno = REGNO (XEXP (note, 0));\n+\t      unsigned int deadend\n \t\t= (deadregno + HARD_REGNO_NREGS (deadregno,\n \t\t\t\t\t\t GET_MODE (XEXP (note, 0))));\n-\t      int ourend = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t      int i;\n+\t      unsigned int ourend\n+\t\t= regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\t      unsigned int i;\n \n \t      for (i = deadregno; i < deadend; i++)\n \t\tif (i < regno || i >= ourend)\n@@ -11717,6 +11753,7 @@ move_deaths (x, maybe_kill_insn, from_cuid, to_insn, pnotes)\n \t\t\t\t\t gen_rtx_REG (reg_raw_mode[i], i),\n \t\t\t\t\t REG_NOTES (where_dead));\n \t    }\n+\n \t  /* If we didn't find any note, or if we found a REG_DEAD note that\n \t     covers only part of the given reg, and we have a multi-reg hard\n \t     register, then to be safe we must check for REG_DEAD notes\n@@ -11729,8 +11766,9 @@ move_deaths (x, maybe_kill_insn, from_cuid, to_insn, pnotes)\n \t\t   && regno < FIRST_PSEUDO_REGISTER\n \t\t   && HARD_REGNO_NREGS (regno, GET_MODE (x)) > 1)\n \t    {\n-\t      int ourend = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t      int i, offset;\n+\t      unsigned int ourend\n+\t\t= regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\t      unsigned int i, offset;\n \t      rtx oldnotes = 0;\n \n \t      if (note)\n@@ -11829,7 +11867,7 @@ reg_bitfield_target_p (x, body)\n     {\n       rtx dest = SET_DEST (body);\n       rtx target;\n-      int regno, tregno, endregno, endtregno;\n+      unsigned int regno, tregno, endregno, endtregno;\n \n       if (GET_CODE (dest) == ZERO_EXTRACT)\n \ttarget = XEXP (dest, 0);\n@@ -11949,7 +11987,8 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \t     is one already.  */\n \t  else if (reg_referenced_p (XEXP (note, 0), PATTERN (i3))\n \t\t   && ! (GET_CODE (XEXP (note, 0)) == REG\n-\t\t\t ? find_regno_note (i3, REG_DEAD, REGNO (XEXP (note, 0)))\n+\t\t\t ? find_regno_note (i3, REG_DEAD,\n+\t\t\t\t\t    REGNO (XEXP (note, 0)))\n \t\t\t : find_reg_note (i3, REG_DEAD, XEXP (note, 0))))\n \t    {\n \t      PUT_REG_NOTE_KIND (note, REG_DEAD);\n@@ -12219,14 +12258,12 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \t\t of the block.  If the existing life info says the reg\n \t\t was dead, there's nothing left to do.  Otherwise, we'll\n \t\t need to do a global life update after combine.  */\n-\t      if (REG_NOTE_KIND (note) == REG_DEAD && place == 0)\n+\t      if (REG_NOTE_KIND (note) == REG_DEAD && place == 0\n+\t\t  && REGNO_REG_SET_P (bb->global_live_at_start,\n+\t\t\t\t      REGNO (XEXP (note, 0))))\n \t\t{\n-\t\t  int regno = REGNO (XEXP (note, 0));\n-\t\t  if (REGNO_REG_SET_P (bb->global_live_at_start, regno))\n-\t\t    {\n-\t\t      SET_BIT (refresh_blocks, this_basic_block);\n-\t\t      need_refresh = 1;\n-\t\t    }\n+\t\t  SET_BIT (refresh_blocks, this_basic_block);\n+\t\t  need_refresh = 1;\n \t\t}\n \t    }\n \n@@ -12238,7 +12275,7 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \n \t  if (place && REG_NOTE_KIND (note) == REG_DEAD)\n \t    {\n-\t      int regno = REGNO (XEXP (note, 0));\n+\t      unsigned int regno = REGNO (XEXP (note, 0));\n \n \t      if (dead_or_set_p (place, XEXP (note, 0))\n \t\t  || reg_bitfield_target_p (XEXP (note, 0), PATTERN (place)))\n@@ -12267,11 +12304,11 @@ distribute_notes (notes, from_insn, i3, i2, elim_i2, elim_i1)\n \t      if (place && regno < FIRST_PSEUDO_REGISTER\n \t\t  && HARD_REGNO_NREGS (regno, GET_MODE (XEXP (note, 0))) > 1)\n \t\t{\n-\t\t  int endregno\n+\t\t  unsigned int endregno\n \t\t    = regno + HARD_REGNO_NREGS (regno,\n \t\t\t\t\t\tGET_MODE (XEXP (note, 0)));\n \t\t  int all_used = 1;\n-\t\t  int i;\n+\t\t  unsigned int i;\n \n \t\t  for (i = regno; i < endregno; i++)\n \t\t    if (! refers_to_regno_p (i, i + 1, PATTERN (place), 0)"}, {"sha": "56a9e829e709143472371fc5aae1161f580cb5ab", "filename": "gcc/convert.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fconvert.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fconvert.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconvert.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -120,8 +120,8 @@ convert_to_integer (type, expr)\n {\n   enum tree_code ex_form = TREE_CODE (expr);\n   tree intype = TREE_TYPE (expr);\n-  int inprec = TYPE_PRECISION (intype);\n-  int outprec = TYPE_PRECISION (type);\n+  unsigned int inprec = TYPE_PRECISION (intype);\n+  unsigned int outprec = TYPE_PRECISION (type);\n \n   /* An INTEGER_TYPE cannot be incomplete, but an ENUMERAL_TYPE can\n      be.  Consider `enum E = { a, b = (enum E) 3 };'.  */"}, {"sha": "63add6d3a7a2592ce21beb9adf036341b9167f79", "filename": "gcc/cp/ChangeLog", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2FChangeLog?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,3 +1,25 @@\n+Sat Mar 25 09:12:10 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n+\n+\t* class.c (build_vbase_pointer_fields): layout_field now place_field.\n+\t(get_vfield_offset): Use byte_position.\n+\t(set_rtti_entry): Set OFFSET to ssizetype zero.\n+\t(get_binfo_offset_as_int): Deleted.\n+\t(dfs_record_base_offsets): Use tree_low_cst.\n+\t(dfs_search_base_offsets): Likewise.\n+\t(layout_nonempty_base_or_field): Reflect changes in RLI format\n+\tand call byte_position.\n+\t(layout_empty_base): Convert offset to ssizetype.\n+\t(build_base_field): use rli_size_unit_so_far.\n+\t(dfs_propagate_binfo_offsets): Do computation in proper type.\n+\t(layout_virtual_bases): Pass ssizetype to propagate_binfo_offsets.\n+\t(layout_class_type): Reflect changes in RLI names and fields.\n+\t(finish_struct_1): Set DECL_FIELD_OFFSET.\n+\t* dump.c (dequeue_and_dump): Call bit_position.\n+\t* expr.c (cplus_expand_constant): Use byte_position.\n+\t* rtti.c (expand_class_desc): Use bitsize_one_node.\n+\t* typeck.c (build_component_addr): Use byte_position and don't\n+\tspecial case for zero offset.\n+\t\n 2000-03-24  Nathan Sidwell  <nathan@codesourcery.com>\n \n \t* decl.c (vtype_decl_p): Use TYPE_POLYMORPHIC_P."}, {"sha": "789ce454df0e99d3bb4fca9fd30f9a13ed8daa1a", "filename": "gcc/cp/class.c", "status": "modified", "additions": 55, "deletions": 79, "changes": 134, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fclass.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fclass.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fclass.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -243,7 +243,7 @@ build_vbase_pointer_fields (rli, empty_p)\n \t\t\t\t\t    empty_p);\n \t  BINFO_VPTR_FIELD (base_binfo) = decl;\n \t  TREE_CHAIN (decl) = vbase_decls;\n-\t  layout_field (rli, decl);\n+\t  place_field (rli, decl);\n \t  vbase_decls = decl;\n \t  *empty_p = 0;\n \n@@ -912,13 +912,9 @@ tree\n get_vfield_offset (binfo)\n      tree binfo;\n {\n-  tree tmp\n-    = size_binop (FLOOR_DIV_EXPR,\n-\t\t  bit_position (TYPE_VFIELD (BINFO_TYPE (binfo))),\n-\t\t  bitsize_int (BITS_PER_UNIT));\n-\n-  return size_binop (PLUS_EXPR, convert (sizetype, tmp),\n-\t\t     BINFO_OFFSET (binfo));\n+  return\n+    size_binop (PLUS_EXPR, byte_position (TYPE_VFIELD (BINFO_TYPE (binfo))),\n+\t\tBINFO_OFFSET (binfo));\n }\n \n /* Get the offset to the start of the original binfo that we derived\n@@ -981,7 +977,7 @@ set_rtti_entry (virtuals, offset, type)\n \n       /* The next node holds the decl.  */\n       virtuals = TREE_CHAIN (virtuals);\n-      offset = integer_zero_node;\n+      offset = ssize_int (0);\n     }\n \n   /* This slot holds the function to call.  */\n@@ -2794,7 +2790,6 @@ dfs_accumulate_vtbl_inits (binfo, data)\n       && CLASSTYPE_VFIELDS (BINFO_TYPE (binfo))\n       && BINFO_NEW_VTABLE_MARKED (binfo, t))\n     {\n-\n       /* If this is a secondary vtable, record its location.  */\n       if (binfo != TYPE_BINFO (t))\n \t{\n@@ -4122,22 +4117,6 @@ build_vtbl_or_vbase_field (name, assembler_name, type, class_type, fcontext,\n   return field;\n }\n \n-/* Return the BINFO_OFFSET for BINFO as a native integer, not an\n-   INTEGER_CST.  */\n-\n-static unsigned HOST_WIDE_INT\n-get_binfo_offset_as_int (binfo)\n-     tree binfo;\n-{\n-  tree offset;\n-\n-  offset = BINFO_OFFSET (binfo);\n-  my_friendly_assert (TREE_CODE (offset) == INTEGER_CST, 20000313);\n-  my_friendly_assert (TREE_INT_CST_HIGH (offset) == 0, 20000313);\n-\n-  return (unsigned HOST_WIDE_INT) TREE_INT_CST_LOW (offset);\n-}\n-\n /* Record the type of BINFO in the slot in DATA (which is really a\n    `varray_type *') corresponding to the BINFO_OFFSET.  */\n \n@@ -4147,7 +4126,7 @@ dfs_record_base_offsets (binfo, data)\n      void *data;\n {\n   varray_type *v;\n-  unsigned HOST_WIDE_INT offset = get_binfo_offset_as_int (binfo);\n+  unsigned HOST_WIDE_INT offset = tree_low_cst (BINFO_OFFSET (binfo), 1);\n \n   v = (varray_type *) data;\n   while (VARRAY_SIZE (*v) <= offset)\n@@ -4184,11 +4163,10 @@ dfs_search_base_offsets (binfo, data)\n   if (is_empty_class (BINFO_TYPE (binfo)))\n     {\n       varray_type v = (varray_type) data;\n-      unsigned HOST_WIDE_INT offset;\n+      /* Find the offset for this BINFO.  */\n+      unsigned HOST_WIDE_INT offset = tree_low_cst (BINFO_OFFSET (binfo), 1);\n       tree t;\n \n-      /* Find the offset for this BINFO.  */\n-      offset = get_binfo_offset_as_int (binfo);\n       /* If we haven't yet encountered any objects at offsets that\n \t big, then there's no conflict.  */\n       if (VARRAY_SIZE (v) <= offset)\n@@ -4238,14 +4216,14 @@ layout_nonempty_base_or_field (rli, decl, binfo, v)\n   while (1)\n     {\n       tree offset;\n+      struct record_layout_info old_rli = *rli;\n \n-      /* Layout this field.  */\n-      layout_field (rli, decl);\n+      /* Place this field.  */\n+      place_field (rli, decl);\n       \n       /* Now that we know where it wil be placed, update its\n \t BINFO_OFFSET.  */\n-      offset = size_int (CEIL (TREE_INT_CST_LOW (DECL_FIELD_BITPOS (decl)),\n-\t\t\t       BITS_PER_UNIT));\n+      offset = convert (ssizetype, byte_position (decl));\n       if (binfo)\n \tpropagate_binfo_offsets (binfo, offset);\n  \n@@ -4267,17 +4245,20 @@ layout_nonempty_base_or_field (rli, decl, binfo, v)\n       if (binfo && flag_new_abi && layout_conflict_p (binfo, v))\n \t{\n \t  /* Undo the propogate_binfo_offsets call.  */\n-\t  offset = convert (sizetype,\n-\t\t\t    size_diffop (size_zero_node, offset));\n+\t  offset = size_diffop (size_zero_node, offset);\n \t  propagate_binfo_offsets (binfo, offset);\n-\n+\t \n \t  /* Strip off the size allocated to this field.  That puts us\n \t     at the first place we could have put the field with\n \t     proper alignment.  */\n-\t  rli->const_size -= TREE_INT_CST_LOW (DECL_SIZE (decl));\n-\t  /* Bump up by th alignment required for the type, without\n+\t  *rli = old_rli;\n+\n+\t  /* Bump up by the alignment required for the type, without\n \t     virtual base classes.  */\n-\t  rli->const_size += CLASSTYPE_ALIGN (BINFO_TYPE (binfo));\n+\t  rli->bitpos\n+\t    = size_binop (PLUS_EXPR, rli->bitpos,\n+\t\t\t  bitsize_int (CLASSTYPE_ALIGN (BINFO_TYPE (binfo))));\n+\t  normalize_rli (rli);\n \t}\n       else\n \t/* There was no conflict.  We're done laying out this field.  */\n@@ -4312,15 +4293,15 @@ layout_empty_base (binfo, eoc, binfo_offsets)\n     {\n       /* That didn't work.  Now, we move forward from the next\n \t available spot in the class.  */\n-      propagate_binfo_offsets (binfo, eoc);\n+      propagate_binfo_offsets (binfo, convert (ssizetype, eoc));\n       while (1) \n \t{\n \t  if (!layout_conflict_p (binfo, binfo_offsets))\n \t    /* We finally found a spot where there's no overlap.  */\n \t    break;\n \n \t  /* There's overlap here, too.  Bump along to the next spot.  */\n-\t  propagate_binfo_offsets (binfo, size_one_node);\n+\t  propagate_binfo_offsets (binfo, ssize_int (1));\n \t}\n     }\n }\n@@ -4379,9 +4360,7 @@ build_base_field (rli, binfo, empty_p, base_align, v)\n       layout_nonempty_base_or_field (rli, decl, binfo, *v);\n     }\n   else\n-    layout_empty_base (binfo,\n-\t\t       size_int (CEIL (rli->const_size, BITS_PER_UNIT)),\n-\t\t       *v);\n+    layout_empty_base (binfo, rli_size_unit_so_far (rli), *v);\n \n   /* Check for inaccessible base classes.  If the same base class\n      appears more than once in the hierarchy, but isn't virtual, then\n@@ -4749,12 +4728,12 @@ dfs_propagate_binfo_offsets (binfo, data)\n {\n   tree offset = (tree) data;\n \n-  /* Update the BINFO_OFFSET for this base.  */\n-  BINFO_OFFSET (binfo) = fold (build (PLUS_EXPR,\n-\t\t\t\t      sizetype,\n-\t\t\t\t      BINFO_OFFSET (binfo), \n-\t\t\t\t      offset));\n-\n+  /* Update the BINFO_OFFSET for this base.  Allow for the case where it\n+     might be negative.  */\n+  BINFO_OFFSET (binfo)\n+    = convert (sizetype, size_binop (PLUS_EXPR,\n+\t\t\t\t     convert (ssizetype, BINFO_OFFSET (binfo)),\n+\t\t\t\t\t      offset));\n   SET_BINFO_MARKED (binfo);\n \n   return NULL_TREE;\n@@ -4890,7 +4869,7 @@ layout_virtual_bases (t, base_offsets)\n \t    dsize = CEIL (dsize, desired_align) * desired_align;\n \t    /* And compute the offset of the virtual base.  */\n \t    propagate_binfo_offsets (vbase, \n-\t\t\t\t     size_int (CEIL (dsize, BITS_PER_UNIT)));\n+\t\t\t\t     ssize_int (CEIL (dsize, BITS_PER_UNIT)));\n \t    /* Every virtual baseclass takes a least a UNIT, so that\n \t       we can take it's address and get something different\n \t       for each base.  */\n@@ -4934,8 +4913,8 @@ layout_virtual_bases (t, base_offsets)\n   dsize = CEIL (dsize, TYPE_ALIGN (t)) * TYPE_ALIGN (t);\n   TYPE_SIZE (t) = bitsize_int (dsize);\n   TYPE_SIZE_UNIT (t) = convert (sizetype,\n-\t\t\t\tsize_binop (FLOOR_DIV_EXPR, TYPE_SIZE (t),\n-\t\t\t\t\t    bitsize_int (BITS_PER_UNIT)));\n+\t\t\t\tsize_binop (CEIL_DIV_EXPR, TYPE_SIZE (t),\n+\t\t\t\t\t    bitsize_unit_node));\n \n   /* Check for ambiguous virtual bases.  */\n   if (extra_warnings)\n@@ -5009,8 +4988,8 @@ layout_class_type (t, empty_p, has_virtual_p,\n   /* Keep track of the first non-static data member.  */\n   non_static_data_members = TYPE_FIELDS (t);\n \n-  /* Initialize the layout information.  */\n-  rli = new_record_layout_info (t);\n+  /* Start laying out the record.  */\n+  rli = start_record_layout (t);\n \n   /* If possible, we reuse the virtual function table pointer from one\n      of our base classes.  */\n@@ -5025,7 +5004,7 @@ layout_class_type (t, empty_p, has_virtual_p,\n   if (flag_new_abi && vptr)\n     {\n       TYPE_FIELDS (t) = chainon (vptr, TYPE_FIELDS (t));\n-      layout_field (rli, vptr);\n+      place_field (rli, vptr);\n     }\n \n   /* Add pointers to all of our virtual base-classes.  */\n@@ -5040,9 +5019,7 @@ layout_class_type (t, empty_p, has_virtual_p,\n   fixup_inline_methods (t);\n \n   /* Layout the non-static data members.  */\n-  for (field = non_static_data_members; \n-       field; \n-       field = TREE_CHAIN (field))\n+  for (field = non_static_data_members; field; field = TREE_CHAIN (field))\n     {\n       tree binfo;\n       tree type;\n@@ -5052,7 +5029,7 @@ layout_class_type (t, empty_p, has_virtual_p,\n \t the back-end, in case it wants to do something with them.  */\n       if (TREE_CODE (field) != FIELD_DECL)\n \t{\n-\t  layout_field (rli, field);\n+\t  place_field (rli, field);\n \t  continue;\n \t}\n \n@@ -5067,9 +5044,9 @@ layout_class_type (t, empty_p, has_virtual_p,\n \t  && ((flag_new_abi \n \t       && INT_CST_LT (TYPE_SIZE (type), DECL_SIZE (field)))\n \t      || (!flag_new_abi\n-\t\t  && compare_tree_int (DECL_SIZE (field),\n-\t\t\t\t       TYPE_PRECISION\n-\t\t\t\t       (long_long_unsigned_type_node)) > 0)))\n+\t\t  && 0 < compare_tree_int (DECL_SIZE (field),\n+\t\t\t\t\t   TYPE_PRECISION\n+\t\t\t\t\t   (long_long_unsigned_type_node)))))\n \t{\n \t  integer_type_kind itk;\n \t  tree integer_type;\n@@ -5087,8 +5064,8 @@ layout_class_type (t, empty_p, has_virtual_p,\n \t     field.  We have to back up by one to find the largest\n \t     type that fits.  */\n \t  integer_type = integer_types[itk - 1];\n-\t  padding = size_diffop (DECL_SIZE (field), \n-\t\t\t\t TYPE_SIZE (integer_type));\n+\t  padding = size_binop (MINUS_EXPR, DECL_SIZE (field), \n+\t\t\t\tTYPE_SIZE (integer_type));\n \t  DECL_SIZE (field) = TYPE_SIZE (integer_type);\n \t  DECL_ALIGN (field) = TYPE_ALIGN (integer_type);\n \t}\n@@ -5122,13 +5099,15 @@ layout_class_type (t, empty_p, has_virtual_p,\n      offset.  However, now we need to make sure that RLI is big enough\n      to reflect the entire class.  */\n   eoc = end_of_class (t, /*include_virtuals_p=*/0);\n-  if (eoc * BITS_PER_UNIT > rli->const_size)\n+  if (TREE_CODE (rli_size_unit_so_far (rli)) == INTEGER_CST\n+      && compare_tree_int (rli_size_unit_so_far (rli), eoc) < 0)\n     {\n       /* We don't handle zero-sized base classes specially under the\n \t old ABI, so if we get here, we had better be operating under\n \t the new ABI rules.  */\n       my_friendly_assert (flag_new_abi, 20000321);\n-      rli->const_size = (eoc + 1) * BITS_PER_UNIT;\n+      rli->offset = size_binop (MAX_EXPR, rli->offset, size_int (eoc + 1));\n+      rli->bitpos = bitsize_zero_node;\n     }\n \n   /* We make all structures have at least one element, so that they\n@@ -5141,7 +5120,7 @@ layout_class_type (t, empty_p, has_virtual_p,\n       tree padding;\n \n       padding = build_lang_decl (FIELD_DECL, NULL_TREE, char_type_node);\n-      layout_field (rli, padding);\n+      place_field (rli, padding);\n       TYPE_NONCOPIED_PARTS (t) \n \t= tree_cons (NULL_TREE, padding, TYPE_NONCOPIED_PARTS (t));\n       TREE_STATIC (TYPE_NONCOPIED_PARTS (t)) = 1;\n@@ -5151,7 +5130,7 @@ layout_class_type (t, empty_p, has_virtual_p,\n      class.   */\n   if (!flag_new_abi && vptr)\n     {\n-      layout_field (rli, vptr);\n+      place_field (rli, vptr);\n       TYPE_FIELDS (t) = chainon (TYPE_FIELDS (t), vptr);\n     }\n   \n@@ -5170,7 +5149,7 @@ layout_class_type (t, empty_p, has_virtual_p,\n      the virtual bases.  */\n   if (*empty_p && flag_new_abi)\n     {\n-      CLASSTYPE_SIZE (t) = bitsize_int (0);\n+      CLASSTYPE_SIZE (t) = bitsize_zero_node;\n       CLASSTYPE_SIZE_UNIT (t) = size_zero_node;\n     }\n   else if (flag_new_abi && TYPE_HAS_COMPLEX_INIT_REF (t)\n@@ -5283,18 +5262,15 @@ finish_struct_1 (t)\n   if (vfield != NULL_TREE\n       && DECL_FIELD_CONTEXT (vfield) != t)\n     {\n-      tree binfo = get_binfo (DECL_FIELD_CONTEXT (vfield), t, 0);\n-      tree offset = convert (bitsizetype, BINFO_OFFSET (binfo));\n-\n       vfield = copy_node (vfield);\n       copy_lang_decl (vfield);\n \n-      if (! integer_zerop (offset))\n-\toffset = size_binop (MULT_EXPR, offset, bitsize_int (BITS_PER_UNIT));\n-\n       DECL_FIELD_CONTEXT (vfield) = t;\n-      DECL_FIELD_BITPOS (vfield)\n-\t= size_binop (PLUS_EXPR, offset, bit_position (vfield));\n+      DECL_FIELD_OFFSET (vfield)\n+\t= size_binop (PLUS_EXPR,\n+\t\t      BINFO_OFFSET (get_binfo (DECL_FIELD_CONTEXT (vfield),\n+\t\t\t\t\t       t, 0)),\n+\t\t      DECL_FIELD_OFFSET (vfield));\n       TYPE_VFIELD (t) = vfield;\n     }\n "}, {"sha": "d66f21770e980a831c9531fa084bc9bf929cd423", "filename": "gcc/cp/dump.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fdump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fdump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fdump.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -550,7 +550,7 @@ dequeue_and_dump (di)\n \t{\n \t  if (DECL_C_BIT_FIELD (t))\n \t    dump_string (di, \"bitfield\");\n-\t  dump_child (\"bpos\", DECL_FIELD_BITPOS (t));\n+\t  dump_child (\"bpos\", bit_position (t));\n \t}\n       break;\n "}, {"sha": "ebf7c94f946acada35e09962a0b83b73a7fd828c", "filename": "gcc/cp/expr.c", "status": "modified", "additions": 3, "deletions": 12, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fexpr.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -52,18 +52,14 @@ cplus_expand_constant (cst)\n       {\n \ttree type = TREE_TYPE (cst);\n \ttree member;\n-\ttree offset;\n       \n \t/* Find the member.  */\n \tmember = PTRMEM_CST_MEMBER (cst);\n \n \tif (TREE_CODE (member) == FIELD_DECL) \n \t  {\n \t    /* Find the offset for the field.  */\n-\t    offset = convert (sizetype,\n-\t\t\t      size_binop (EASY_DIV_EXPR,\n-\t\t\t\t\t  bit_position (member),\n-\t\t\t\t\t  bitsize_int (BITS_PER_UNIT)));\n+\t    tree offset = byte_position (member);\n \n \t    if (flag_new_abi)\n \t      /* Under the new ABI, we use -1 to represent the NULL\n@@ -80,15 +76,10 @@ cplus_expand_constant (cst)\n \t  }\n \telse\n \t  {\n-\t    tree delta;\n-\t    tree idx;\n-\t    tree pfn;\n-\t    tree delta2;\n+\t    tree delta, idx, pfn, delta2;\n \n \t    expand_ptrmemfunc_cst (cst, &delta, &idx, &pfn, &delta2);\n-\n-\t    cst = build_ptrmemfunc1 (type, delta, idx,\n-\t\t\t\t     pfn, delta2);\n+\t    cst = build_ptrmemfunc1 (type, delta, idx, pfn, delta2);\n \t  }\n       }\n       break;"}, {"sha": "e35acc9889df7421a63f1cba02ebe5a889068fb8", "filename": "gcc/cp/method.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fmethod.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Fmethod.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fmethod.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1228,7 +1228,7 @@ build_mangled_name (parmtypes, begin, end)\n \n   if (end) \n     OB_FINISH ();\n-  return (char *)obstack_base (&scratch_obstack);\n+  return (char *) obstack_base (&scratch_obstack);\n }\n \n /* Emit modifiers such as constant, read-only, and volatile.  */"}, {"sha": "30a972c1fa5d6da93aa8304f8000b8310ac17a29", "filename": "gcc/cp/rtti.c", "status": "modified", "additions": 13, "deletions": 20, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Frtti.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Frtti.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Frtti.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -513,30 +513,23 @@ get_base_offset (binfo, parent)\n      tree binfo;\n      tree parent;\n {\n-  tree offset;\n-  \n-  if (!TREE_VIA_VIRTUAL (binfo))\n-    offset = BINFO_OFFSET (binfo);\n-  else if (!vbase_offsets_in_vtable_p ())\n+  if (! TREE_VIA_VIRTUAL (binfo))\n+    return BINFO_OFFSET (binfo);\n+  else if (! vbase_offsets_in_vtable_p ())\n     {\n-      tree t = BINFO_TYPE (binfo);\n       const char *name;\n-      tree field;\n     \n-      FORMAT_VBASE_NAME (name, t);\n-      field = lookup_field (parent, get_identifier (name), 0, 0);\n-      offset = size_binop (FLOOR_DIV_EXPR, bit_position (field), \n-    \t\t           bitsize_int (BITS_PER_UNIT));\n-      offset = convert (sizetype, offset);\n+      FORMAT_VBASE_NAME (name, BINFO_TYPE (binfo));\n+      return byte_position (lookup_field (parent, get_identifier (name),\n+\t\t\t\t\t  0, 0));\n     }\n   else\n-    {\n-      /* Under the new ABI, we store the vtable offset at which\n-         the virtual base offset can be found.  */\n-      tree vbase = BINFO_FOR_VBASE (BINFO_TYPE (binfo), parent);\n-      offset = convert (sizetype, BINFO_VPTR_FIELD (vbase));\n-    }\n-  return offset;\n+    /* Under the new ABI, we store the vtable offset at which\n+       the virtual base offset can be found.  */\n+    return convert (sizetype,\n+\t\t    BINFO_VPTR_FIELD (BINFO_FOR_VBASE (BINFO_TYPE (binfo),\n+\t\t\t\t\t\t       parent)));\n+\n }\n \n /* Execute a dynamic cast, as described in section 5.2.6 of the 9/93 working\n@@ -941,7 +934,7 @@ expand_class_desc (tdecl, type)\n \n       fields [2] = build_lang_decl (FIELD_DECL, NULL_TREE, boolean_type_node);\n       DECL_BIT_FIELD (fields[2]) = 1;\n-      DECL_SIZE (fields[2]) = bitsize_int (1);\n+      DECL_SIZE (fields[2]) = bitsize_one_node;\n \n       /* Actually enum access */\n       fields [3] = build_lang_decl (FIELD_DECL, NULL_TREE, integer_type_node);"}, {"sha": "c6c92b8f1ec66979f8b12a38c716710b621c7eb6", "filename": "gcc/cp/typeck.c", "status": "modified", "additions": 2, "deletions": 12, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Ftypeck.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcp%2Ftypeck.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Ftypeck.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -4279,18 +4279,8 @@ build_component_addr (arg, argtype)\n     /* This conversion is harmless.  */\n     rval = convert_force (argtype, rval, 0);\n \n-  if (! integer_zerop (bit_position (field)))\n-    {\n-      tree offset = size_binop (EASY_DIV_EXPR, bit_position (field),\n-\t\t\t\tbitsize_int (BITS_PER_UNIT));\n-      int flag = TREE_CONSTANT (rval);\n-\n-      offset = convert (sizetype, offset);\n-      rval = fold (build (PLUS_EXPR, argtype,\n-\t\t\t  rval, cp_convert (argtype, offset)));\n-      TREE_CONSTANT (rval) = flag;\n-    }\n-  return rval;\n+  return fold (build (PLUS_EXPR, argtype, rval,\n+\t\t      cp_convert (argtype, byte_position (field))));\n }\n    \n /* Construct and perhaps optimize a tree representation"}, {"sha": "03772b0196b4707d9ada5a2e6429fd7c06a8feaa", "filename": "gcc/cse.c", "status": "modified", "additions": 76, "deletions": 70, "changes": 146, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -246,7 +246,7 @@ struct qty_table_elem\n   rtx const_insn;\n   rtx comparison_const;\n   int comparison_qty;\n-  int first_reg, last_reg;\n+  unsigned int first_reg, last_reg;\n   enum machine_mode mode;\n   enum rtx_code comparison_code;\n };\n@@ -302,7 +302,7 @@ struct cse_reg_info\n   struct cse_reg_info *next;\n \n   /* Search key */\n-  int regno;\n+  unsigned int regno;\n \n   /* The quantity number of the register's current contents.  */\n   int reg_qty;\n@@ -336,7 +336,7 @@ static struct cse_reg_info *reg_hash[REGHASH_SIZE];\n \n /* The last lookup we did into the cse_reg_info_tree.  This allows us\n    to cache repeated lookups.  */\n-static int cached_regno;\n+static unsigned int cached_regno;\n static struct cse_reg_info *cached_cse_reg_info;\n \n /* A HARD_REG_SET containing all the hard registers for which there is \n@@ -531,7 +531,7 @@ struct table_elt\n /* Determine if the quantity number for register X represents a valid index\n    into the qty_table.  */\n \n-#define REGNO_QTY_VALID_P(N) (REG_QTY (N) != (N))\n+#define REGNO_QTY_VALID_P(N) (REG_QTY (N) != (int) (N))\n \n #ifdef ADDRESS_COST\n /* The ADDRESS_COST macro does not deal with ADDRESSOF nodes.  But,\n@@ -653,9 +653,9 @@ struct cse_basic_block_data\n \n static int notreg_cost\t\tPARAMS ((rtx));\n static void new_basic_block\tPARAMS ((void));\n-static void make_new_qty\tPARAMS ((int, enum machine_mode));\n-static void make_regs_eqv\tPARAMS ((int, int));\n-static void delete_reg_equiv\tPARAMS ((int));\n+static void make_new_qty\tPARAMS ((unsigned int, enum machine_mode));\n+static void make_regs_eqv\tPARAMS ((unsigned int, unsigned int));\n+static void delete_reg_equiv\tPARAMS ((unsigned int));\n static int mention_regs\t\tPARAMS ((rtx));\n static int insert_regs\t\tPARAMS ((rtx, struct table_elt *, int));\n static void remove_from_table\tPARAMS ((struct table_elt *, unsigned));\n@@ -668,8 +668,9 @@ static void merge_equiv_classes PARAMS ((struct table_elt *,\n \t\t\t\t\t struct table_elt *));\n static void invalidate\t\tPARAMS ((rtx, enum machine_mode));\n static int cse_rtx_varies_p\tPARAMS ((rtx));\n-static void remove_invalid_refs\tPARAMS ((int));\n-static void remove_invalid_subreg_refs\tPARAMS ((int, int, enum machine_mode));\n+static void remove_invalid_refs\tPARAMS ((unsigned int));\n+static void remove_invalid_subreg_refs\tPARAMS ((unsigned int, unsigned int,\n+\t\t\t\t\t\t enum machine_mode));\n static void rehash_using_reg\tPARAMS ((rtx));\n static void invalidate_memory\tPARAMS ((void));\n static void invalidate_for_call\tPARAMS ((void));\n@@ -699,7 +700,7 @@ static void cse_set_around_loop\tPARAMS ((rtx, rtx, rtx));\n static rtx cse_basic_block\tPARAMS ((rtx, rtx, struct branch_path *, int));\n static void count_reg_usage\tPARAMS ((rtx, int *, rtx, int));\n extern void dump_class          PARAMS ((struct table_elt*));\n-static struct cse_reg_info* get_cse_reg_info PARAMS ((int));\n+static struct cse_reg_info * get_cse_reg_info PARAMS ((unsigned int));\n \n static void flush_hash_table\tPARAMS ((void));\n \f\n@@ -845,7 +846,7 @@ rtx_cost (x, outer_code)\n \f\n static struct cse_reg_info *\n get_cse_reg_info (regno)\n-     int regno;\n+     unsigned int regno;\n {\n   struct cse_reg_info **hash_head = &reg_hash[REGHASH_FN (regno)];\n   struct cse_reg_info *p;\n@@ -949,8 +950,8 @@ new_basic_block ()\n \n static void\n make_new_qty (reg, mode)\n-     register int reg;\n-     register enum machine_mode mode;\n+     unsigned int reg;\n+     enum machine_mode mode;\n {\n   register int q;\n   register struct qty_table_elem *ent;\n@@ -976,11 +977,11 @@ make_new_qty (reg, mode)\n \n static void\n make_regs_eqv (new, old)\n-     register int new, old;\n+     unsigned int new, old;\n {\n-  register int lastr, firstr;\n-  register int q = REG_QTY (old);\n-  register struct qty_table_elem *ent;\n+  unsigned int lastr, firstr;\n+  int q = REG_QTY (old);\n+  struct qty_table_elem *ent;\n \n   ent = &qty_table[q];\n \n@@ -1040,14 +1041,14 @@ make_regs_eqv (new, old)\n \n static void\n delete_reg_equiv (reg)\n-     register int reg;\n+     unsigned int reg;\n {\n   register struct qty_table_elem *ent;\n   register int q = REG_QTY (reg);\n   register int p, n;\n \n   /* If invalid, do nothing.  */\n-  if (q == reg)\n+  if (q == (int) reg)\n     return;\n \n   ent = &qty_table[q];\n@@ -1094,11 +1095,11 @@ mention_regs (x)\n   code = GET_CODE (x);\n   if (code == REG)\n     {\n-      register int regno = REGNO (x);\n-      register int endregno\n+      unsigned int regno = REGNO (x);\n+      unsigned int endregno\n \t= regno + (regno >= FIRST_PSEUDO_REGISTER ? 1\n \t\t   : HARD_REGNO_NREGS (regno, GET_MODE (x)));\n-      int i;\n+      unsigned int i;\n \n       for (i = regno; i < endregno; i++)\n \t{\n@@ -1117,7 +1118,7 @@ mention_regs (x)\n   if (code == SUBREG && GET_CODE (SUBREG_REG (x)) == REG\n       && REGNO (SUBREG_REG (x)) >= FIRST_PSEUDO_REGISTER)\n     {\n-      int i = REGNO (SUBREG_REG (x));\n+      unsigned int i = REGNO (SUBREG_REG (x));\n \n       if (REG_IN_TABLE (i) >= 0 && REG_IN_TABLE (i) != REG_TICK (i))\n \t{\n@@ -1193,8 +1194,8 @@ insert_regs (x, classp, modified)\n {\n   if (GET_CODE (x) == REG)\n     {\n-      register int regno = REGNO (x);\n-      register int qty_valid;\n+      unsigned int regno = REGNO (x);\n+      int qty_valid;\n \n       /* If REGNO is in the equivalence table already but is of the\n \t wrong mode for that equivalence, don't do anything here.  */\n@@ -1237,7 +1238,7 @@ insert_regs (x, classp, modified)\n   else if (GET_CODE (x) == SUBREG && GET_CODE (SUBREG_REG (x)) == REG\n \t   && ! REGNO_QTY_VALID_P (REGNO (SUBREG_REG (x))))\n     {\n-      int regno = REGNO (SUBREG_REG (x));\n+      unsigned int regno = REGNO (SUBREG_REG (x));\n \n       insert_regs (SUBREG_REG (x), NULL_PTR, 0);\n       /* Mention_regs checks if REG_TICK is exactly one larger than\n@@ -1324,6 +1325,7 @@ remove_from_table (elt, hash)\n   if (elt->related_value != 0 && elt->related_value != elt)\n     {\n       register struct table_elt *p = elt->related_value;\n+\n       while (p->related_value != elt)\n \tp = p->related_value;\n       p->related_value = elt->related_value;\n@@ -1374,7 +1376,8 @@ lookup_for_remove (x, hash, mode)\n \n   if (GET_CODE (x) == REG)\n     {\n-      int regno = REGNO (x);\n+      unsigned int regno = REGNO (x);\n+\n       /* Don't check the machine mode when comparing registers;\n \t invalidating (REG:SI 0) also invalidates (REG:DF 0).  */\n       for (p = table[hash]; p; p = p->next_same_hash)\n@@ -1400,8 +1403,9 @@ lookup_as_function (x, code)\n      rtx x;\n      enum rtx_code code;\n {\n-  register struct table_elt *p = lookup (x, safe_hash (x, VOIDmode) & HASH_MASK,\n-\t\t\t\t\t GET_MODE (x));\n+  register struct table_elt *p\n+    = lookup (x, safe_hash (x, VOIDmode) & HASH_MASK, GET_MODE (x));\n+\n   /* If we are looking for a CONST_INT, the mode doesn't really matter, as\n      long as we are narrowing.  So if we looked in vain for a mode narrower\n      than word_mode before, look for word_mode now.  */\n@@ -1417,12 +1421,10 @@ lookup_as_function (x, code)\n     return 0;\n \n   for (p = p->first_same_value; p; p = p->next_same_value)\n-    {\n-      if (GET_CODE (p->exp) == code\n-\t  /* Make sure this is a valid entry in the table.  */\n-\t  && exp_equiv_p (p->exp, p->exp, 1, 0))\n-\treturn p->exp;\n-    }\n+    if (GET_CODE (p->exp) == code\n+\t/* Make sure this is a valid entry in the table.  */\n+\t&& exp_equiv_p (p->exp, p->exp, 1, 0))\n+      return p->exp;\n   \n   return 0;\n }\n@@ -1470,12 +1472,12 @@ insert (x, classp, hash, mode)\n   /* If X is a hard register, show it is being put in the table.  */\n   if (GET_CODE (x) == REG && REGNO (x) < FIRST_PSEUDO_REGISTER)\n     {\n-      int regno = REGNO (x);\n-      int endregno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-      int i;\n+      unsigned int regno = REGNO (x);\n+      unsigned int endregno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+      unsigned int i;\n \n       for (i = regno; i < endregno; i++)\n-\t    SET_HARD_REG_BIT (hard_regs_in_table, i);\n+\tSET_HARD_REG_BIT (hard_regs_in_table, i);\n     }\n \n   /* If X is a label, show we recorded it.  */\n@@ -1488,9 +1490,7 @@ insert (x, classp, hash, mode)\n \n   elt = free_element_chain;\n   if (elt)\n-    {\n-      free_element_chain = elt->next_same_hash;\n-    }\n+    free_element_chain = elt->next_same_hash;\n   else\n     {\n       n_elements_made++;\n@@ -1538,12 +1538,15 @@ insert (x, classp, hash, mode)\n \t  /* Insert not at head of the class.  */\n \t  /* Put it after the last element cheaper than X.  */\n \t  register struct table_elt *p, *next;\n+\n \t  for (p = classp; (next = p->next_same_value) && CHEAPER (next, elt);\n \t       p = next);\n+\n \t  /* Put it after P and before NEXT.  */\n \t  elt->next_same_value = next;\n \t  if (next)\n \t    next->prev_same_value = elt;\n+\n \t  elt->prev_same_value = p;\n \t  p->next_same_value = elt;\n \t  elt->first_same_value = classp;\n@@ -1591,7 +1594,8 @@ insert (x, classp, hash, mode)\n \t      int x_q = REG_QTY (REGNO (x));\n \t      struct qty_table_elem *x_ent = &qty_table[x_q];\n \n-\t      x_ent->const_rtx = gen_lowpart_if_possible (GET_MODE (x), p->exp);\n+\t      x_ent->const_rtx\n+\t\t= gen_lowpart_if_possible (GET_MODE (x), p->exp);\n \t      x_ent->const_insn = this_insn;\n \t      break;\n \t    }\n@@ -1661,7 +1665,7 @@ merge_equiv_classes (class1, class2)\n \n   for (elt = class2; elt; elt = next)\n     {\n-      unsigned hash;\n+      unsigned int hash;\n       rtx exp = elt->exp;\n       enum machine_mode mode = elt->mode;\n \n@@ -1740,8 +1744,8 @@ invalidate (x, full_mode)\n \t   through the qty number mechanism.  Just change the qty number of\n \t   the register, mark it as invalid for expressions that refer to it,\n \t   and remove it itself.  */\n-\tregister int regno = REGNO (x);\n-\tregister unsigned hash = HASH (x, GET_MODE (x));\n+\tunsigned int regno = REGNO (x);\n+\tunsigned int hash = HASH (x, GET_MODE (x));\n \n \t/* Remove REGNO from any quantity list it might be on and indicate\n \t   that its value might have changed.  If it is a pseudo, remove its\n@@ -1768,18 +1772,19 @@ invalidate (x, full_mode)\n \t  {\n \t    HOST_WIDE_INT in_table\n \t      = TEST_HARD_REG_BIT (hard_regs_in_table, regno);\n-\t    int endregno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t    int tregno, tendregno;\n+\t    unsigned int endregno\n+\t      = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\t    unsigned int tregno, tendregno, rn;\n \t    register struct table_elt *p, *next;\n \n \t    CLEAR_HARD_REG_BIT (hard_regs_in_table, regno);\n \n-\t    for (i = regno + 1; i < endregno; i++)\n+\t    for (rn = regno + 1; rn < endregno; rn++)\n \t      {\n-\t\tin_table |= TEST_HARD_REG_BIT (hard_regs_in_table, i);\n-\t\tCLEAR_HARD_REG_BIT (hard_regs_in_table, i);\n-\t\tdelete_reg_equiv (i);\n-\t\tREG_TICK (i)++;\n+\t\tin_table |= TEST_HARD_REG_BIT (hard_regs_in_table, rn);\n+\t\tCLEAR_HARD_REG_BIT (hard_regs_in_table, rn);\n+\t\tdelete_reg_equiv (rn);\n+\t\tREG_TICK (rn)++;\n \t      }\n \n \t    if (in_table)\n@@ -1851,10 +1856,10 @@ invalidate (x, full_mode)\n \n static void\n remove_invalid_refs (regno)\n-     int regno;\n+     unsigned int regno;\n {\n-  register int i;\n-  register struct table_elt *p, *next;\n+  unsigned int i;\n+  struct table_elt *p, *next;\n \n   for (i = 0; i < HASH_SIZE; i++)\n     for (p = table[i]; p; p = next)\n@@ -1869,13 +1874,13 @@ remove_invalid_refs (regno)\n /* Likewise for a subreg with subreg_reg WORD and mode MODE.  */\n static void\n remove_invalid_subreg_refs (regno, word, mode)\n-     int regno;\n-     int word;\n+     unsigned int regno;\n+     unsigned int word;\n      enum machine_mode mode;\n {\n-  register int i;\n-  register struct table_elt *p, *next;\n-  int end = word + (GET_MODE_SIZE (mode) - 1) / UNITS_PER_WORD;\n+  unsigned int i;\n+  struct table_elt *p, *next;\n+  unsigned int end = word + (GET_MODE_SIZE (mode) - 1) / UNITS_PER_WORD;\n \n   for (i = 0; i < HASH_SIZE; i++)\n     for (p = table[i]; p; p = next)\n@@ -1956,8 +1961,8 @@ rehash_using_reg (x)\n static void\n invalidate_for_call ()\n {\n-  int regno, endregno;\n-  int i;\n+  unsigned int regno, endregno;\n+  unsigned int i;\n   unsigned hash;\n   struct table_elt *p, *next;\n   int in_table = 0;\n@@ -2111,7 +2116,7 @@ canon_hash (x, mode)\n     {\n     case REG:\n       {\n-\tregister int regno = REGNO (x);\n+\tunsigned int regno = REGNO (x);\n \n \t/* On some machines, we can't record any non-fixed hard register,\n \t   because extending its life will cause reload problems.  We\n@@ -2136,6 +2141,7 @@ canon_hash (x, mode)\n \t    do_not_record = 1;\n \t    return 0;\n \t  }\n+\n \thash += ((unsigned) REG << 7) + (unsigned) REG_QTY (regno);\n \treturn hash;\n       }\n@@ -2374,11 +2380,11 @@ exp_equiv_p (x, y, validate, equal_values)\n \n     case REG:\n       {\n-\tint regno = REGNO (y);\n-\tint endregno\n+\tunsigned int regno = REGNO (y);\n+\tunsigned int endregno\n \t  = regno + (regno >= FIRST_PSEUDO_REGISTER ? 1\n \t\t     : HARD_REGNO_NREGS (regno, GET_MODE (y)));\n-\tint i;\n+\tunsigned int i;\n \n \t/* If the quantities are not the same, the expressions are not\n \t   equivalent.  If there are and we are not to validate, they\n@@ -5703,11 +5709,11 @@ cse_insn (insn, libcall_insn)\n \t\t This code is similar to the REG case in mention_regs,\n \t\t but it knows that reg_tick has been incremented, and\n \t\t it leaves reg_in_table as -1 .  */\n-\t      register int regno = REGNO (x);\n-\t      register int endregno\n+\t      unsigned int regno = REGNO (x);\n+\t      unsigned int endregno\n \t\t= regno + (regno >= FIRST_PSEUDO_REGISTER ? 1\n \t\t\t   : HARD_REGNO_NREGS (regno, GET_MODE (x)));\n-\t      int i;\n+\t      unsigned int i;\n \n \t      for (i = regno; i < endregno; i++)\n \t\t{"}, {"sha": "59264424694b32d7348317d86a0a76e9d3a02a63", "filename": "gcc/dbxout.c", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fdbxout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fdbxout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdbxout.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -2370,8 +2370,7 @@ dbxout_parms (parms)\n \n \t       If we use DECL_RTL, then we must use the declared type of\n \t       the variable, not the type that it arrived in.  */\n-\t    if (REGNO (DECL_RTL (parms)) >= 0\n-\t\t&& REGNO (DECL_RTL (parms)) < FIRST_PSEUDO_REGISTER)\n+\t    if (REGNO (DECL_RTL (parms)) < FIRST_PSEUDO_REGISTER)\n \t      {\n \t\tbest_rtl = DECL_RTL (parms);\n \t\tparm_type = TREE_TYPE (parms);\n@@ -2430,8 +2429,7 @@ dbxout_parms (parms)\n \t    /* DECL_RTL looks like (MEM (REG...).  Get the register number.\n \t       If it is an unallocated pseudo-reg, then use the register where\n \t       it was passed instead.  */\n-\t    if (REGNO (XEXP (DECL_RTL (parms), 0)) >= 0\n-\t\t&& REGNO (XEXP (DECL_RTL (parms), 0)) < FIRST_PSEUDO_REGISTER)\n+\t    if (REGNO (XEXP (DECL_RTL (parms), 0)) < FIRST_PSEUDO_REGISTER)\n \t      current_sym_value = REGNO (XEXP (DECL_RTL (parms), 0));\n \t    else\n \t      current_sym_value = REGNO (DECL_INCOMING_RTL (parms));\n@@ -2558,7 +2556,6 @@ dbxout_reg_parms (parms)\n \t/* Report parms that live in registers during the function\n \t   but were passed in memory.  */\n \tif (GET_CODE (DECL_RTL (parms)) == REG\n-\t    && REGNO (DECL_RTL (parms)) >= 0\n \t    && REGNO (DECL_RTL (parms)) < FIRST_PSEUDO_REGISTER)\n \t  dbxout_symbol_location (parms, TREE_TYPE (parms),\n \t\t\t\t  0, DECL_RTL (parms));"}, {"sha": "eb9630c962864f648dd426b3a1db26b50c6a7fff", "filename": "gcc/dwarf2out.c", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fdwarf2out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fdwarf2out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdwarf2out.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -218,7 +218,7 @@ static void reg_save\t\t\tPARAMS ((char *, unsigned, unsigned,\n static void initial_return_save\t\tPARAMS ((rtx));\n static void output_cfi\t\t\tPARAMS ((dw_cfi_ref, dw_fde_ref));\n static void output_call_frame_info\tPARAMS ((int));\n-static unsigned reg_number\t\tPARAMS ((rtx));\n+static unsigned int reg_number\t\tPARAMS ((rtx));\n static void dwarf2out_stack_adjust\tPARAMS ((rtx));\n static void dwarf2out_frame_debug_expr\tPARAMS ((rtx, char *));\n \n@@ -553,7 +553,7 @@ stripattributes (s)\n \n /* Return the register number described by a given RTL node.  */\n \n-static unsigned\n+static unsigned int\n reg_number (rtl)\n      register rtx rtl;\n {\n@@ -1314,7 +1314,7 @@ dwarf2out_frame_debug_expr (expr, label)\n \n \t  /* Without an offset.  */\n \tcase REG:\n-\t  if (cfa_store_reg != (unsigned) REGNO (XEXP (dest, 0)))\n+\t  if (cfa_store_reg != REGNO (XEXP (dest, 0)))\n \t    abort();\n \t  offset = -cfa_store_offset;\n \t  break;\n@@ -2670,9 +2670,9 @@ static inline int\n is_pseudo_reg (rtl)\n      register rtx rtl;\n {\n-  return (((GET_CODE (rtl) == REG) && (REGNO (rtl) >= FIRST_PSEUDO_REGISTER))\n-\t  || ((GET_CODE (rtl) == SUBREG)\n-\t      && (REGNO (XEXP (rtl, 0)) >= FIRST_PSEUDO_REGISTER)));\n+  return ((GET_CODE (rtl) == REG && REGNO (rtl) >= FIRST_PSEUDO_REGISTER)\n+\t  || (GET_CODE (rtl) == SUBREG\n+\t      && REGNO (XEXP (rtl, 0)) >= FIRST_PSEUDO_REGISTER));\n }\n \n /* Return a reference to a type, with its const and volatile qualifiers"}, {"sha": "70db81c672fa84cf59551d107de3ac10dd7ba065", "filename": "gcc/emit-rtl.c", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Femit-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Femit-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Femit-rtl.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -924,7 +924,8 @@ subreg_realpart_p (x)\n   if (GET_CODE (x) != SUBREG)\n     abort ();\n \n-  return SUBREG_WORD (x) * UNITS_PER_WORD < GET_MODE_UNIT_SIZE (GET_MODE (SUBREG_REG (x)));\n+  return ((unsigned int) SUBREG_WORD (x) * UNITS_PER_WORD\n+\t  < GET_MODE_UNIT_SIZE (GET_MODE (SUBREG_REG (x))));\n }\n \f\n /* Assuming that X is an rtx (e.g., MEM, REG or SUBREG) for a value,\n@@ -1104,7 +1105,7 @@ subreg_lowpart_p (x)\n rtx\n operand_subword (op, i, validate_address, mode)\n      rtx op;\n-     int i;\n+     unsigned int i;\n      int validate_address;\n      enum machine_mode mode;\n {\n@@ -1181,7 +1182,9 @@ operand_subword (op, i, validate_address, mode)\n     return gen_rtx_SUBREG (word_mode, SUBREG_REG (op), i + SUBREG_WORD (op));\n   else if (GET_CODE (op) == CONCAT)\n     {\n-      int partwords = GET_MODE_UNIT_SIZE (GET_MODE (op)) / UNITS_PER_WORD;\n+      unsigned int partwords\n+\t= GET_MODE_UNIT_SIZE (GET_MODE (op)) / UNITS_PER_WORD;\n+\n       if (i < partwords)\n \treturn operand_subword (XEXP (op, 0), i, validate_address, mode);\n       return operand_subword (XEXP (op, 1), i - partwords,\n@@ -1428,7 +1431,7 @@ operand_subword (op, i, validate_address, mode)\n rtx\n operand_subword_force (op, i, mode)\n      rtx op;\n-     int i;\n+     unsigned int i;\n      enum machine_mode mode;\n {\n   rtx result = operand_subword (op, i, 1, mode);"}, {"sha": "2d7114ae11b2c7e896747a97f71ef23ada24d14a", "filename": "gcc/except.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexcept.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexcept.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexcept.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -2924,7 +2924,7 @@ eh_regs (pcontext, psp, pra, outgoing)\n      int outgoing ATTRIBUTE_UNUSED;\n {\n   rtx rcontext, rsp, rra;\n-  int i;\n+  unsigned int i;\n \n #ifdef FUNCTION_OUTGOING_VALUE\n   if (outgoing)"}, {"sha": "99d7d98bc046f6fa211fe95594c4c56e0cff9b74", "filename": "gcc/explow.c", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexplow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexplow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexplow.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1584,17 +1584,20 @@ hard_function_value (valtype, func, outgoing)\n      int outgoing ATTRIBUTE_UNUSED;\n {\n   rtx val;\n+\n #ifdef FUNCTION_OUTGOING_VALUE\n   if (outgoing)\n     val = FUNCTION_OUTGOING_VALUE (valtype, func);\n   else\n #endif\n     val = FUNCTION_VALUE (valtype, func);\n+\n   if (GET_CODE (val) == REG\n       && GET_MODE (val) == BLKmode)\n     {\n-      int bytes = int_size_in_bytes (valtype);\n+      unsigned HOST_WIDE_INT bytes = int_size_in_bytes (valtype);\n       enum machine_mode tmpmode;\n+\n       for (tmpmode = GET_CLASS_NARROWEST_MODE (MODE_INT);\n            tmpmode != VOIDmode;\n            tmpmode = GET_MODE_WIDER_MODE (tmpmode))"}, {"sha": "0f29b3b8402ee72f3af3a9caa0bdab5e2c31d3fe", "filename": "gcc/expmed.c", "status": "modified", "additions": 71, "deletions": 58, "changes": 129, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -35,18 +35,24 @@ Boston, MA 02111-1307, USA.  */\n #include \"real.h\"\n #include \"recog.h\"\n \n-static void store_fixed_bit_field\tPARAMS ((rtx, int, int, int, rtx,\n-\t\t\t\t\t\t unsigned int));\n-static void store_split_bit_field\tPARAMS ((rtx, int, int, rtx,\n+static void store_fixed_bit_field\tPARAMS ((rtx, unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT, rtx,\n \t\t\t\t\t\t unsigned int));\n-static rtx extract_fixed_bit_field\tPARAMS ((enum machine_mode, rtx, int,\n-\t\t\t\t\t\t int, int, rtx, int,\n+static void store_split_bit_field\tPARAMS ((rtx, unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT, rtx,\n \t\t\t\t\t\t unsigned int));\n+static rtx extract_fixed_bit_field\tPARAMS ((enum machine_mode, rtx,\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\t rtx, int, unsigned int));\n static rtx mask_rtx\t\t\tPARAMS ((enum machine_mode, int,\n \t\t\t\t\t\t int, int));\n static rtx lshift_value\t\t\tPARAMS ((enum machine_mode, rtx,\n \t\t\t\t\t\t int, int));\n-static rtx extract_split_bit_field\tPARAMS ((rtx, int, int, int,\n+static rtx extract_split_bit_field\tPARAMS ((rtx, unsigned HOST_WIDE_INT,\n+\t\t\t\t\t\t unsigned HOST_WIDE_INT, int,\n \t\t\t\t\t\t unsigned int));\n static void do_cmp_and_jump\t\tPARAMS ((rtx, rtx, enum rtx_code,\n \t\t\t\t\t\t enum machine_mode, rtx));\n@@ -225,19 +231,20 @@ negate_rtx (mode, x)\n rtx\n store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n      rtx str_rtx;\n-     register int bitsize;\n-     int bitnum;\n+     unsigned HOST_WIDE_INT bitsize;\n+     unsigned HOST_WIDE_INT bitnum;\n      enum machine_mode fieldmode;\n      rtx value;\n      unsigned int align;\n-     int total_size;\n+     HOST_WIDE_INT total_size;\n {\n-  int unit = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n-  register int offset = bitnum / unit;\n-  register int bitpos = bitnum % unit;\n+  unsigned int unit\n+    = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n+  unsigned HOST_WIDE_INT offset = bitnum / unit;\n+  unsigned HOST_WIDE_INT bitpos = bitnum % unit;\n   register rtx op0 = str_rtx;\n #ifdef HAVE_insv\n-  int insv_bitsize;\n+  unsigned HOST_WIDE_INT insv_bitsize;\n   enum machine_mode op_mode;\n \n   op_mode = insn_data[(int) CODE_FOR_insv].operand[3].mode;\n@@ -384,10 +391,9 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \t be less than full.\n \t However, only do that if the value is not BLKmode.  */\n \n-      int backwards = WORDS_BIG_ENDIAN && fieldmode != BLKmode;\n-\n-      int nwords = (bitsize + (BITS_PER_WORD - 1)) / BITS_PER_WORD;\n-      int i;\n+      unsigned int backwards = WORDS_BIG_ENDIAN && fieldmode != BLKmode;\n+      unsigned int nwords = (bitsize + (BITS_PER_WORD - 1)) / BITS_PER_WORD;\n+      unsigned int i;\n \n       /* This is the mode we must force value to, so that there will be enough\n \t subwords to extract.  Note that fieldmode will often (always?) be\n@@ -400,10 +406,13 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \t{\n \t  /* If I is 0, use the low-order word in both field and target;\n \t     if I is 1, use the next to lowest word; and so on.  */\n-\t  int wordnum = (backwards ? nwords - i - 1 : i);\n-\t  int bit_offset = (backwards\n-\t\t\t    ? MAX (bitsize - (i + 1) * BITS_PER_WORD, 0)\n-\t\t\t    : i * BITS_PER_WORD);\n+\t  unsigned int wordnum = (backwards ? nwords - i - 1 : i);\n+\t  unsigned int bit_offset = (backwards\n+\t\t\t    ? MAX ((int) bitsize - ((int) i + 1)\n+\t\t\t\t   * BITS_PER_WORD,\n+\t\t\t\t   0)\n+\t\t\t    : (int) i * BITS_PER_WORD);\n+\n \t  store_bit_field (op0, MIN (BITS_PER_WORD,\n \t\t\t\t     bitsize - i * BITS_PER_WORD),\n \t\t\t   bitnum + bit_offset, word_mode,\n@@ -513,7 +522,7 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n \n \t  if (bestmode == VOIDmode\n \t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t  && GET_MODE_SIZE (bestmode) > (int) align))\n+\t\t  && GET_MODE_SIZE (bestmode) > align))\n \t    goto insv_loses;\n \n \t  /* Adjust address to point to the containing unit of that mode.  */\n@@ -626,12 +635,12 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n static void\n store_fixed_bit_field (op0, offset, bitsize, bitpos, value, struct_align)\n      register rtx op0;\n-     register int offset, bitsize, bitpos;\n+     unsigned HOST_WIDE_INT offset, bitsize, bitpos;\n      register rtx value;\n      unsigned int struct_align;\n {\n   register enum machine_mode mode;\n-  int total_bits = BITS_PER_WORD;\n+  unsigned int total_bits = BITS_PER_WORD;\n   rtx subtarget, temp;\n   int all_zero = 0;\n   int all_one = 0;\n@@ -797,12 +806,12 @@ store_fixed_bit_field (op0, offset, bitsize, bitpos, value, struct_align)\n static void\n store_split_bit_field (op0, bitsize, bitpos, value, align)\n      rtx op0;\n-     int bitsize, bitpos;\n+     unsigned HOST_WIDE_INT bitsize, bitpos;\n      rtx value;\n      unsigned int align;\n {\n-  int unit;\n-  int bitsdone = 0;\n+  unsigned int unit;\n+  unsigned int bitsdone = 0;\n \n   /* Make sure UNIT isn't larger than BITS_PER_WORD, we can only handle that\n      much at a time.  */\n@@ -831,10 +840,10 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n \n   while (bitsdone < bitsize)\n     {\n-      int thissize;\n+      unsigned HOST_WIDE_INT thissize;\n       rtx part, word;\n-      int thispos;\n-      int offset;\n+      unsigned HOST_WIDE_INT thispos;\n+      unsigned HOST_WIDE_INT offset;\n \n       offset = (bitpos + bitsdone) / unit;\n       thispos = (bitpos + bitsdone) % unit;\n@@ -951,27 +960,28 @@ rtx\n extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t\t   target, mode, tmode, align, total_size)\n      rtx str_rtx;\n-     register int bitsize;\n-     int bitnum;\n+     unsigned HOST_WIDE_INT bitsize;\n+     unsigned HOST_WIDE_INT bitnum;\n      int unsignedp;\n      rtx target;\n      enum machine_mode mode, tmode;\n      unsigned int align;\n-     int total_size;\n+     HOST_WIDE_INT total_size;\n {\n-  int unit = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n-  register int offset = bitnum / unit;\n-  register int bitpos = bitnum % unit;\n+  unsigned int unit\n+    = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n+  unsigned HOST_WIDE_INT offset = bitnum / unit;\n+  unsigned HOST_WIDE_INT bitpos = bitnum % unit;\n   register rtx op0 = str_rtx;\n   rtx spec_target = target;\n   rtx spec_target_subreg = 0;\n   enum machine_mode int_mode;\n #ifdef HAVE_extv\n-  int extv_bitsize;\n+  unsigned HOST_WIDE_INT extv_bitsize;\n   enum machine_mode extv_mode;\n #endif\n #ifdef HAVE_extzv\n-  int extzv_bitsize;\n+  unsigned HOST_WIDE_INT extzv_bitsize;\n   enum machine_mode extzv_mode;\n #endif\n \n@@ -1107,8 +1117,8 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t This is because the most significant word is the one which may\n \t be less than full.  */\n \n-      int nwords = (bitsize + (BITS_PER_WORD - 1)) / BITS_PER_WORD;\n-      int i;\n+      unsigned int nwords = (bitsize + (BITS_PER_WORD - 1)) / BITS_PER_WORD;\n+      unsigned int i;\n \n       if (target == 0 || GET_CODE (target) != REG)\n \ttarget = gen_reg_rtx (mode);\n@@ -1121,13 +1131,15 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t  /* If I is 0, use the low-order word in both field and target;\n \t     if I is 1, use the next to lowest word; and so on.  */\n \t  /* Word number in TARGET to use.  */\n-\t  int wordnum = (WORDS_BIG_ENDIAN\n-\t\t\t ? GET_MODE_SIZE (GET_MODE (target)) / UNITS_PER_WORD - i - 1\n-\t\t\t : i);\n+\t  unsigned int wordnum\n+\t    = (WORDS_BIG_ENDIAN\n+\t       ? GET_MODE_SIZE (GET_MODE (target)) / UNITS_PER_WORD - i - 1\n+\t       : i);\n \t  /* Offset from start of field in OP0.  */\n-\t  int bit_offset = (WORDS_BIG_ENDIAN\n-\t\t\t    ? MAX (0, bitsize - (i + 1) * BITS_PER_WORD)\n-\t\t\t    : i * BITS_PER_WORD);\n+\t  unsigned int bit_offset = (WORDS_BIG_ENDIAN\n+\t\t\t\t     ? MAX (0, ((int) bitsize - ((int) i + 1)\n+\t\t\t\t\t\t* BITS_PER_WORD))\n+\t\t\t\t     : (int) i * BITS_PER_WORD);\n \t  rtx target_part = operand_subword (target, wordnum, 1, VOIDmode);\n \t  rtx result_part\n \t    = extract_bit_field (op0, MIN (BITS_PER_WORD,\n@@ -1149,7 +1161,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t     need to be zero'd out.  */\n \t  if (GET_MODE_SIZE (GET_MODE (target)) > nwords * UNITS_PER_WORD)\n \t    {\n-\t      int i,total_words;\n+\t      unsigned int i, total_words;\n \n \t      total_words = GET_MODE_SIZE (GET_MODE (target)) / UNITS_PER_WORD;\n \t      for (i = nwords; i < total_words; i++)\n@@ -1215,7 +1227,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t  && ! ((GET_CODE (op0) == REG || GET_CODE (op0) == SUBREG)\n \t\t&& (bitsize + bitpos > extzv_bitsize)))\n \t{\n-\t  int xbitpos = bitpos, xoffset = offset;\n+\t  unsigned HOST_WIDE_INT xbitpos = bitpos, xoffset = offset;\n \t  rtx bitsize_rtx, bitpos_rtx;\n \t  rtx last = get_last_insn ();\n \t  rtx xop0 = op0;\n@@ -1258,7 +1270,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \n \t\t  if (bestmode == VOIDmode\n \t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t\t  && GET_MODE_SIZE (bestmode) > (int) align))\n+\t\t\t  && GET_MODE_SIZE (bestmode) > align))\n \t\t    goto extzv_loses;\n \n \t\t  /* Compute offset as multiple of this unit,\n@@ -1396,7 +1408,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \n \t\t  if (bestmode == VOIDmode\n \t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t\t  && GET_MODE_SIZE (bestmode) > (int) align))\n+\t\t\t  && GET_MODE_SIZE (bestmode) > align))\n \t\t    goto extv_loses;\n \n \t\t  /* Compute offset as multiple of this unit,\n@@ -1533,11 +1545,11 @@ extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n \t\t\t target, unsignedp, align)\n      enum machine_mode tmode;\n      register rtx op0, target;\n-     register int offset, bitsize, bitpos;\n+     unsigned HOST_WIDE_INT offset, bitsize, bitpos;\n      int unsignedp;\n      unsigned int align;\n {\n-  int total_bits = BITS_PER_WORD;\n+  unsigned int total_bits = BITS_PER_WORD;\n   enum machine_mode mode;\n \n   if (GET_CODE (op0) == SUBREG || GET_CODE (op0) == REG)\n@@ -1753,11 +1765,12 @@ lshift_value (mode, value, bitpos, bitsize)\n static rtx\n extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n      rtx op0;\n-     int bitsize, bitpos, unsignedp;\n+     unsigned HOST_WIDE_INT bitsize, bitpos;\n+     int unsignedp;\n      unsigned int align;\n {\n-  int unit;\n-  int bitsdone = 0;\n+  unsigned int unit;\n+  unsigned int bitsdone = 0;\n   rtx result = NULL_RTX;\n   int first = 1;\n \n@@ -1770,10 +1783,10 @@ extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n \n   while (bitsdone < bitsize)\n     {\n-      int thissize;\n+      unsigned HOST_WIDE_INT thissize;\n       rtx part, word;\n-      int thispos;\n-      int offset;\n+      unsigned HOST_WIDE_INT thispos;\n+      unsigned HOST_WIDE_INT offset;\n \n       offset = (bitpos + bitsdone) / unit;\n       thispos = (bitpos + bitsdone) % unit;"}, {"sha": "4d7007e4766c9d0ba6990e3f1d32b03bc09fc2d8", "filename": "gcc/expr.c", "status": "modified", "additions": 99, "deletions": 141, "changes": 240, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -143,12 +143,15 @@ static void clear_by_pieces_1\tPARAMS ((rtx (*) (rtx, ...),\n \t\t\t\t\t struct clear_by_pieces *));\n static int is_zeros_p\t\tPARAMS ((tree));\n static int mostly_zeros_p\tPARAMS ((tree));\n-static void store_constructor_field PARAMS ((rtx, int, int, enum machine_mode,\n+static void store_constructor_field PARAMS ((rtx, unsigned HOST_WIDE_INT,\n+\t\t\t\t\t     HOST_WIDE_INT, enum machine_mode,\n \t\t\t\t\t     tree, tree, unsigned int, int));\n-static void store_constructor\tPARAMS ((tree, rtx, unsigned int, int, int));\n-static rtx store_field\t\tPARAMS ((rtx, int, int, enum machine_mode,\n+static void store_constructor\tPARAMS ((tree, rtx, unsigned int, int,\n+\t\t\t\t\t unsigned HOST_WIDE_INT));\n+static rtx store_field\t\tPARAMS ((rtx, HOST_WIDE_INT,\n+\t\t\t\t\t HOST_WIDE_INT, enum machine_mode,\n \t\t\t\t\t tree, enum machine_mode, int,\n-\t\t\t\t\t unsigned int, int, int));\n+\t\t\t\t\t unsigned int, HOST_WIDE_INT, int));\n static enum memory_use_mode\n   get_memory_usage_from_modifier PARAMS ((enum expand_modifier));\n static tree save_noncopied_parts PARAMS ((tree, tree));\n@@ -162,7 +165,8 @@ static rtx expand_increment\tPARAMS ((tree, int, int));\n static void preexpand_calls\tPARAMS ((tree));\n static void do_jump_by_parts_greater PARAMS ((tree, int, rtx, rtx));\n static void do_jump_by_parts_equality PARAMS ((tree, rtx, rtx));\n-static void do_compare_and_jump\tPARAMS ((tree, enum rtx_code, enum rtx_code, rtx, rtx));\n+static void do_compare_and_jump\tPARAMS ((tree, enum rtx_code, enum rtx_code,\n+\t\t\t\t\t rtx, rtx));\n static rtx do_store_flag\tPARAMS ((tree, rtx, enum machine_mode, int));\n \n /* Record for each mode whether we can move a register directly to or\n@@ -1368,7 +1372,7 @@ move_by_pieces (to, from, len, align)\n {\n   struct move_by_pieces data;\n   rtx to_addr = XEXP (to, 0), from_addr = XEXP (from, 0);\n-  int max_size = MOVE_MAX_PIECES + 1;\n+  unsigned int max_size = MOVE_MAX_PIECES + 1;\n   enum machine_mode mode = VOIDmode, tmode;\n   enum insn_code icode;\n \n@@ -1479,7 +1483,7 @@ move_by_pieces_ninsns (l, align)\n      unsigned int align;\n {\n   register int n_insns = 0;\n-  int max_size = MOVE_MAX + 1;\n+  unsigned int max_size = MOVE_MAX + 1;\n \n   if (! SLOW_UNALIGNED_ACCESS (word_mode, align)\n       || align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n@@ -1920,8 +1924,8 @@ emit_group_load (dst, orig_src, ssize, align)\n   for (i = start; i < XVECLEN (dst, 0); i++)\n     {\n       enum machine_mode mode = GET_MODE (XEXP (XVECEXP (dst, 0, i), 0));\n-      int bytepos = INTVAL (XEXP (XVECEXP (dst, 0, i), 1));\n-      int bytelen = GET_MODE_SIZE (mode);\n+      HOST_WIDE_INT bytepos = INTVAL (XEXP (XVECEXP (dst, 0, i), 1));\n+      unsigned int bytelen = GET_MODE_SIZE (mode);\n       int shift = 0;\n \n       /* Handle trailing fragments that run over the size of the struct.  */\n@@ -2050,9 +2054,9 @@ emit_group_store (orig_dst, src, ssize, align)\n   /* Process the pieces.  */\n   for (i = start; i < XVECLEN (src, 0); i++)\n     {\n-      int bytepos = INTVAL (XEXP (XVECEXP (src, 0, i), 1));\n+      HOST_WIDE_INT bytepos = INTVAL (XEXP (XVECEXP (src, 0, i), 1));\n       enum machine_mode mode = GET_MODE (tmps[i]);\n-      int bytelen = GET_MODE_SIZE (mode);\n+      unsigned int bytelen = GET_MODE_SIZE (mode);\n \n       /* Handle trailing fragments that run over the size of the struct.  */\n       if (ssize >= 0 && bytepos + bytelen > ssize)\n@@ -2238,7 +2242,7 @@ clear_by_pieces (to, len, align)\n {\n   struct clear_by_pieces data;\n   rtx to_addr = XEXP (to, 0);\n-  int max_size = MOVE_MAX_PIECES + 1;\n+  unsigned int max_size = MOVE_MAX_PIECES + 1;\n   enum machine_mode mode = VOIDmode, tmode;\n   enum insn_code icode;\n \n@@ -2587,7 +2591,7 @@ emit_move_insn_1 (x, y)\n   enum machine_mode mode = GET_MODE (x);\n   enum machine_mode submode;\n   enum mode_class class = GET_MODE_CLASS (mode);\n-  int i;\n+  unsigned int i;\n \n   if (mode >= MAX_MACHINE_MODE)\n       abort ();\n@@ -3323,8 +3327,7 @@ expand_assignment (to, from, want_value, suggest_reg)\n       || TREE_CODE (to) == ARRAY_REF)\n     {\n       enum machine_mode mode1;\n-      int bitsize;\n-      int bitpos;\n+      HOST_WIDE_INT bitsize, bitpos;\n       tree offset;\n       int unsignedp;\n       int volatilep = 0;\n@@ -4051,7 +4054,8 @@ static void\n store_constructor_field (target, bitsize, bitpos,\n \t\t\t mode, exp, type, align, cleared)\n      rtx target;\n-     int bitsize, bitpos;\n+     unsigned HOST_WIDE_INT bitsize;\n+     HOST_WIDE_INT bitpos;\n      enum machine_mode mode;\n      tree exp, type;\n      unsigned int align;\n@@ -4095,7 +4099,7 @@ store_constructor (exp, target, align, cleared, size)\n      rtx target;\n      unsigned int align;\n      int cleared;\n-     int size;\n+     unsigned HOST_WIDE_INT size;\n {\n   tree type = TREE_TYPE (exp);\n #ifdef WORD_REGISTER_OPERATIONS\n@@ -4175,10 +4179,10 @@ store_constructor (exp, target, align, cleared, size)\n \t  tree value = TREE_VALUE (elt);\n #endif\n \t  register enum machine_mode mode;\n-\t  int bitsize;\n-\t  int bitpos = 0;\n+\t  HOST_WIDE_INT bitsize;\n+\t  HOST_WIDE_INT bitpos = 0;\n \t  int unsignedp;\n-\t  tree pos, constant = 0, offset = 0;\n+\t  tree offset;\n \t  rtx to_rtx = target;\n \n \t  /* Just ignore missing fields.\n@@ -4190,8 +4194,8 @@ store_constructor (exp, target, align, cleared, size)\n \t  if (cleared && is_zeros_p (TREE_VALUE (elt)))\n \t    continue;\n \n-\t  if (TREE_CODE (DECL_SIZE (field)) == INTEGER_CST)\n-\t    bitsize = TREE_INT_CST_LOW (DECL_SIZE (field));\n+\t  if (host_integerp (DECL_SIZE (field), 1))\n+\t    bitsize = tree_low_cst (DECL_SIZE (field), 1);\n \t  else\n \t    bitsize = -1;\n \n@@ -4200,18 +4204,16 @@ store_constructor (exp, target, align, cleared, size)\n \t  if (DECL_BIT_FIELD (field))\n \t    mode = VOIDmode;\n \n-\t  pos = DECL_FIELD_BITPOS (field);\n-\t  if (TREE_CODE (pos) == INTEGER_CST)\n-\t    constant = pos;\n-\t  else if (TREE_CODE (pos) == PLUS_EXPR\n-\t\t   && TREE_CODE (TREE_OPERAND (pos, 1)) == INTEGER_CST)\n-\t    constant = TREE_OPERAND (pos, 1), offset = TREE_OPERAND (pos, 0);\n+\t  offset = DECL_FIELD_OFFSET (field);\n+\t  if (host_integerp (offset, 0)\n+\t      && host_integerp (bit_position (field), 0))\n+\t    {\n+\t      bitpos = int_bit_position (field);\n+\t      offset = 0;\n+\t    }\n \t  else\n-\t    offset = pos;\n-\n-\t  if (constant)\n-\t    bitpos = TREE_INT_CST_LOW (constant);\n-\n+\t    bitpos = tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 0);\n+\t\t\t      \n \t  if (offset)\n \t    {\n \t      rtx offset_rtx;\n@@ -4220,8 +4222,7 @@ store_constructor (exp, target, align, cleared, size)\n \t\toffset = build (WITH_RECORD_EXPR, bitsizetype,\n \t\t\t\toffset, make_tree (TREE_TYPE (exp), target));\n \n-\t      offset = size_binop (EXACT_DIV_EXPR, offset,\n-\t\t\t\t   bitsize_int (BITS_PER_UNIT));\n+\t      offset = size_binop (EXACT_DIV_EXPR, offset, bitsize_unit_node);\n \t      offset = convert (sizetype, offset);\n \n \t      offset_rtx = expand_expr (offset, NULL_RTX, VOIDmode, 0);\n@@ -4257,8 +4258,7 @@ store_constructor (exp, target, align, cleared, size)\n \t     start of a word, try to widen it to a full word.\n \t     This special case allows us to output C++ member function\n \t     initializations in a form that the optimizers can understand.  */\n-\t  if (constant\n-\t      && GET_CODE (target) == REG\n+\t  if (GET_CODE (target) == REG\n \t      && bitsize < BITS_PER_WORD\n \t      && bitpos % BITS_PER_WORD == 0\n \t      && GET_MODE_CLASS (mode) == MODE_INT\n@@ -4707,13 +4707,14 @@ static rtx\n store_field (target, bitsize, bitpos, mode, exp, value_mode,\n \t     unsignedp, align, total_size, alias_set)\n      rtx target;\n-     int bitsize, bitpos;\n+     HOST_WIDE_INT bitsize;\n+     HOST_WIDE_INT bitpos;\n      enum machine_mode mode;\n      tree exp;\n      enum machine_mode value_mode;\n      int unsignedp;\n      unsigned int align;\n-     int total_size;\n+     HOST_WIDE_INT total_size;\n      int alias_set;\n {\n   HOST_WIDE_INT width_mask = 0;\n@@ -4929,25 +4930,29 @@ tree\n get_inner_reference (exp, pbitsize, pbitpos, poffset, pmode,\n \t\t     punsignedp, pvolatilep, palignment)\n      tree exp;\n-     int *pbitsize;\n-     int *pbitpos;\n+     HOST_WIDE_INT *pbitsize;\n+     HOST_WIDE_INT *pbitpos;\n      tree *poffset;\n      enum machine_mode *pmode;\n      int *punsignedp;\n      int *pvolatilep;\n      unsigned int *palignment;\n {\n-  tree orig_exp = exp;\n   tree size_tree = 0;\n   enum machine_mode mode = VOIDmode;\n   tree offset = size_zero_node;\n+  tree bit_offset = bitsize_zero_node;\n   unsigned int alignment = BIGGEST_ALIGNMENT;\n+  tree tem;\n \n+  /* First get the mode, signedness, and size.  We do this from just the\n+     outermost expression.  */\n   if (TREE_CODE (exp) == COMPONENT_REF)\n     {\n       size_tree = DECL_SIZE (TREE_OPERAND (exp, 1));\n       if (! DECL_BIT_FIELD (TREE_OPERAND (exp, 1)))\n \tmode = DECL_MODE (TREE_OPERAND (exp, 1));\n+\n       *punsignedp = TREE_UNSIGNED (TREE_OPERAND (exp, 1));\n     }\n   else if (TREE_CODE (exp) == BIT_FIELD_REF)\n@@ -4958,122 +4963,71 @@ get_inner_reference (exp, pbitsize, pbitpos, poffset, pmode,\n   else\n     {\n       mode = TYPE_MODE (TREE_TYPE (exp));\n+      *punsignedp = TREE_UNSIGNED (TREE_TYPE (exp));\n+\n       if (mode == BLKmode)\n \tsize_tree = TYPE_SIZE (TREE_TYPE (exp));\n-\n-      *pbitsize = GET_MODE_BITSIZE (mode);\n-      *punsignedp = TREE_UNSIGNED (TREE_TYPE (exp));\n+      else\n+\t*pbitsize = GET_MODE_BITSIZE (mode);\n     }\n       \n-  if (size_tree)\n+  if (size_tree != 0)\n     {\n-      if (TREE_CODE (size_tree) != INTEGER_CST)\n+      if (! host_integerp (size_tree, 1))\n \tmode = BLKmode, *pbitsize = -1;\n       else\n-\t*pbitsize = TREE_INT_CST_LOW (size_tree);\n+\t*pbitsize = tree_low_cst (size_tree, 1);\n     }\n \n   /* Compute cumulative bit-offset for nested component-refs and array-refs,\n      and find the ultimate containing object.  */\n-\n-  *pbitpos = 0;\n-\n   while (1)\n     {\n-      if (TREE_CODE (exp) == COMPONENT_REF || TREE_CODE (exp) == BIT_FIELD_REF)\n+      if (TREE_CODE (exp) == BIT_FIELD_REF)\n+\tbit_offset = size_binop (PLUS_EXPR, bit_offset, TREE_OPERAND (exp, 2));\n+      else if (TREE_CODE (exp) == COMPONENT_REF)\n \t{\n-\t  tree pos = (TREE_CODE (exp) == COMPONENT_REF\n-\t\t      ? DECL_FIELD_BITPOS (TREE_OPERAND (exp, 1))\n-\t\t      : TREE_OPERAND (exp, 2));\n-\t  tree constant = bitsize_int (0), var = pos;\n+\t  tree field = TREE_OPERAND (exp, 1);\n+\t  tree this_offset = DECL_FIELD_OFFSET (field);\n \n \t  /* If this field hasn't been filled in yet, don't go\n \t     past it.  This should only happen when folding expressions\n \t     made during type construction.  */\n-\t  if (pos == 0)\n+\t  if (this_offset == 0)\n \t    break;\n+\t  else if (! TREE_CONSTANT (this_offset)\n+\t\t   && contains_placeholder_p (this_offset))\n+\t    this_offset = build (WITH_RECORD_EXPR, sizetype, this_offset, exp);\n \n-\t  /* Assume here that the offset is a multiple of a unit.\n-\t     If not, there should be an explicitly added constant.  */\n-\t  if (TREE_CODE (pos) == PLUS_EXPR\n-\t      && TREE_CODE (TREE_OPERAND (pos, 1)) == INTEGER_CST)\n-\t    constant = TREE_OPERAND (pos, 1), var = TREE_OPERAND (pos, 0);\n-\t  else if (TREE_CODE (pos) == INTEGER_CST)\n-\t    constant = pos, var = bitsize_int (0);\n+\t  offset = size_binop (PLUS_EXPR, offset, DECL_FIELD_OFFSET (field));\n+\t  bit_offset = size_binop (PLUS_EXPR, bit_offset,\n+\t\t\t\t   DECL_FIELD_BIT_OFFSET (field));\n \n-\t  *pbitpos += TREE_INT_CST_LOW (constant);\n-\t  offset\n-\t    = size_binop (PLUS_EXPR, offset,\n-\t\t\t  convert (sizetype,\n-\t\t\t\t   size_binop (EXACT_DIV_EXPR, var,\n-\t\t\t\t\t       bitsize_int (BITS_PER_UNIT))));\n+\t  if (! host_integerp (offset, 0))\n+\t    alignment = MIN (alignment, DECL_OFFSET_ALIGN (field));\n \t}\n-\n       else if (TREE_CODE (exp) == ARRAY_REF)\n \t{\n-\t  /* This code is based on the code in case ARRAY_REF in expand_expr\n-\t     below.  We assume here that the size of an array element is\n-\t     always an integral multiple of BITS_PER_UNIT.  */\n-\n \t  tree index = TREE_OPERAND (exp, 1);\n \t  tree domain = TYPE_DOMAIN (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-\t  tree low_bound\n-\t    = domain ? TYPE_MIN_VALUE (domain) : integer_zero_node;\n-\t  tree index_type = TREE_TYPE (index);\n-\t  tree xindex;\n-\n-\t  if (TYPE_PRECISION (index_type) != TYPE_PRECISION (sizetype))\n-\t    {\n-\t      index = convert (type_for_size (TYPE_PRECISION (sizetype), 0),\n-\t\t\t       index);\n-\t      index_type = TREE_TYPE (index);\n-\t    }\n+\t  tree low_bound = (domain ? TYPE_MIN_VALUE (domain) : 0);\n \n-\t  /* Optimize the special-case of a zero lower bound.\n-\t     \n-\t     We convert the low_bound to sizetype to avoid some problems\n-\t     with constant folding.  (E.g. suppose the lower bound is 1,\n-\t     and its mode is QI.  Without the conversion,  (ARRAY\n-\t     +(INDEX-(unsigned char)1)) becomes ((ARRAY+(-(unsigned char)1))\n-\t     +INDEX), which becomes (ARRAY+255+INDEX).  Oops!)\n-\t     \n-\t     But sizetype isn't quite right either (especially if\n-\t     the lowbound is negative).  FIXME */\n-\n-\t  if (! integer_zerop (low_bound))\n-\t    index = fold (build (MINUS_EXPR, index_type, index,\n-\t\t\t\t convert (sizetype, low_bound)));\n-\n-\t  if (TREE_CODE (index) == INTEGER_CST)\n-\t    {\n-\t      index = convert (sbitsizetype, index);\n-\t      index_type = TREE_TYPE (index);\n-\t    }\n+\t  /* We assume all arrays have sizes that are a multiple of a byte.\n+\t     First subtract the lower bound, if any, in the type of the\n+\t     index, then convert to sizetype and multiply by the size of the\n+\t     array element.  */\n+\t  if (low_bound != 0 && ! integer_zerop (low_bound))\n+\t    index = fold (build (MINUS_EXPR, TREE_TYPE (index),\n+\t\t\t\t index, low_bound));\n \n-\t  xindex = fold (build (MULT_EXPR, sbitsizetype, index,\n-\t\t\t        convert (sbitsizetype,\n-\t\t\t\t\t TYPE_SIZE (TREE_TYPE (exp)))));\n+\t  if (! TREE_CONSTANT (index)\n+\t      && contains_placeholder_p (index))\n+\t    index = build (WITH_RECORD_EXPR, TREE_TYPE (index), index, exp);\n \n-\t  if (TREE_CODE (xindex) == INTEGER_CST\n-\t      && TREE_INT_CST_HIGH (xindex) == 0)\n-\t    *pbitpos += TREE_INT_CST_LOW (xindex);\n-\t  else\n-\t    {\n-\t      /* Either the bit offset calculated above is not constant, or\n-\t\t it overflowed.  In either case, redo the multiplication\n-\t\t against the size in units.  This is especially important\n-\t\t in the non-constant case to avoid a division at runtime.  */\n-\t      xindex\n-\t\t= fold (build (MULT_EXPR, ssizetype, index,\n-\t\t\t       convert (ssizetype,\n-\t\t\t\t\tTYPE_SIZE_UNIT (TREE_TYPE (exp)))));\n-\n-\t      if (contains_placeholder_p (xindex))\n-\t\txindex = build (WITH_RECORD_EXPR, ssizetype, xindex, exp);\n-\n-\t      offset\n-\t\t= size_binop (PLUS_EXPR, offset, convert (sizetype, xindex));\n-\t    }\n+\t  offset = size_binop (PLUS_EXPR, offset,\n+\t\t\t       size_binop (MULT_EXPR,\n+\t\t\t\t\t   convert (sizetype, index),\n+\t\t\t\t\t   TYPE_SIZE_UNIT (TREE_TYPE (exp))));\n \t}\n       else if (TREE_CODE (exp) != NON_LVALUE_EXPR\n \t       && ! ((TREE_CODE (exp) == NOP_EXPR\n@@ -5088,7 +5042,7 @@ get_inner_reference (exp, pbitsize, pbitpos, poffset, pmode,\n \n       /* If the offset is non-constant already, then we can't assume any\n \t alignment more than the alignment here.  */\n-      if (! integer_zerop (offset))\n+      if (! TREE_CONSTANT (offset))\n \talignment = MIN (alignment, TYPE_ALIGN (TREE_TYPE (exp)));\n \n       exp = TREE_OPERAND (exp, 0);\n@@ -5099,19 +5053,24 @@ get_inner_reference (exp, pbitsize, pbitpos, poffset, pmode,\n   else if (TREE_TYPE (exp) != 0)\n     alignment = MIN (alignment, TYPE_ALIGN (TREE_TYPE (exp)));\n \n-  if (integer_zerop (offset))\n-    offset = 0;\n-\n-  if (offset != 0 && contains_placeholder_p (offset))\n-    offset = build (WITH_RECORD_EXPR, sizetype, offset, orig_exp);\n+  /* If OFFSET is constant, see if we can return the whole thing as a\n+     constant bit position.  Otherwise, split it up.  */\n+  if (host_integerp (offset, 0)\n+      && 0 != (tem = size_binop (MULT_EXPR, convert (bitsizetype, offset),\n+\t\t\t\t bitsize_unit_node))\n+      && 0 != (tem = size_binop (PLUS_EXPR, tem, bit_offset))\n+      && host_integerp (tem, 0))\n+    *pbitpos = tree_low_cst (tem, 0), *poffset = 0;\n+  else\n+    *pbitpos = tree_low_cst (bit_offset, 0), *poffset = offset;\n \n   *pmode = mode;\n-  *poffset = offset;\n   *palignment = alignment / BITS_PER_UNIT;\n   return exp;\n }\n \n /* Subroutine of expand_exp: compute memory_usage from modifier.  */\n+\n static enum memory_use_mode\n get_memory_usage_from_modifier (modifier)\n      enum expand_modifier modifier;\n@@ -6615,8 +6574,7 @@ expand_expr (exp, target, tmode, modifier)\n \n       {\n \tenum machine_mode mode1;\n-\tint bitsize;\n-\tint bitpos;\n+\tHOST_WIDE_INT bitsize, bitpos;\n \ttree offset;\n \tint volatilep = 0;\n \tunsigned int alignment;\n@@ -8616,8 +8574,7 @@ expand_expr_unaligned (exp, palign)\n \n       {\n \tenum machine_mode mode1;\n-\tint bitsize;\n-\tint bitpos;\n+\tHOST_WIDE_INT bitsize, bitpos;\n \ttree offset;\n \tint volatilep = 0;\n \tunsigned int alignment;\n@@ -9350,7 +9307,8 @@ do_jump (exp, if_false_label, if_true_label)\n     case BIT_FIELD_REF:\n     case ARRAY_REF:\n       {\n-\tint bitsize, bitpos, unsignedp;\n+\tHOST_WIDE_INT bitsize, bitpos;\n+\tint unsignedp;\n \tenum machine_mode mode;\n \ttree type;\n \ttree offset;"}, {"sha": "a6cb091287555a37f5f27522c66c240abdbbfb28", "filename": "gcc/expr.h", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1108,7 +1108,8 @@ extern rtx label_rtx PARAMS ((tree));\n #endif\n \n /* Indicate how an input argument register was promoted.  */\n-extern rtx promoted_input_arg PARAMS ((int, enum machine_mode *, int *));\n+extern rtx promoted_input_arg PARAMS ((unsigned int, enum machine_mode *,\n+\t\t\t\t       int *));\n \n /* Return an rtx like arg but sans any constant terms.\n    Returns the original rtx if it has no constant terms.\n@@ -1206,11 +1207,14 @@ extern rtx hard_libcall_value PARAMS ((enum machine_mode));\n    of STACK_BOUNDARY / BITS_PER_UNIT.  */\n extern rtx round_push PARAMS ((rtx));\n \n-extern rtx store_bit_field PARAMS ((rtx, int, int, enum machine_mode, rtx,\n-\t\t\t\t    unsigned int, int));\n-extern rtx extract_bit_field PARAMS ((rtx, int, int, int, rtx,\n+extern rtx store_bit_field PARAMS ((rtx, unsigned HOST_WIDE_INT,\n+\t\t\t\t    unsigned HOST_WIDE_INT,\n+\t\t\t\t    enum machine_mode, rtx,\n+\t\t\t\t    unsigned int, HOST_WIDE_INT));\n+extern rtx extract_bit_field PARAMS ((rtx, unsigned HOST_WIDE_INT,\n+\t\t\t\t      unsigned HOST_WIDE_INT, int, rtx,\n \t\t\t\t      enum machine_mode, enum machine_mode,\n-\t\t\t\t      unsigned int, int));\n+\t\t\t\t      unsigned int, HOST_WIDE_INT));\n extern rtx expand_mult PARAMS ((enum machine_mode, rtx, rtx, rtx, int));\n extern rtx expand_mult_add PARAMS ((rtx, rtx, rtx, rtx,enum machine_mode, int));\n extern rtx expand_mult_highpart_adjust PARAMS ((enum machine_mode, rtx, rtx, rtx, rtx, int));\n@@ -1240,5 +1244,5 @@ extern void do_jump_by_parts_greater_rtx\tPARAMS ((enum machine_mode,\n \n #ifdef TREE_CODE   /* Don't lose if tree.h not included.  */\n extern void mark_seen_cases\t\t\tPARAMS ((tree, unsigned char *,\n-\t\t\t\t\t\t\t long, int));\n+\t\t\t\t\t\t\t HOST_WIDE_INT, int));\n #endif"}, {"sha": "42b1085b060de2ddc299fbaa9dc70f6e957d35c1", "filename": "gcc/f/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ff%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ff%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ff%2FChangeLog?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,3 +1,8 @@\n+Sat Mar 25 09:12:10 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n+\n+\t* com.c (ffecom_tree_canonize_ptr_): Use bitsize_zero_node.\n+\t(ffecom_tree_canonize_ref_): Likewise.\n+\n Mon Mar 20 15:49:40 2000  Jim Wilson  <wilson@cygnus.com>\n \n \t* f/target.h (FFETARGET_32bit_longs): New.  Define for alpha, sparc64,"}, {"sha": "5ab3d15f218c5bfc1d6d829b0461ac25d416a3e8", "filename": "gcc/f/com.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ff%2Fcom.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ff%2Fcom.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ff%2Fcom.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -9097,15 +9097,15 @@ ffecom_tree_canonize_ptr_ (tree *decl, tree *offset,\n \n     case PARM_DECL:\n       *decl = t;\n-      *offset = bitsize_int (0);\n+      *offset = bitsize_zero_node;\n       break;\n \n     case ADDR_EXPR:\n       if (TREE_CODE (TREE_OPERAND (t, 0)) == VAR_DECL)\n \t{\n \t  /* A reference to COMMON.  */\n \t  *decl = TREE_OPERAND (t, 0);\n-\t  *offset = bitsize_int (0);\n+\t  *offset = bitsize_zero_node;\n \t  break;\n \t}\n       /* Fall through.  */\n@@ -9226,7 +9226,7 @@ ffecom_tree_canonize_ref_ (tree *decl, tree *offset,\n     case VAR_DECL:\n     case PARM_DECL:\n       *decl = t;\n-      *offset = bitsize_int (0);\n+      *offset = bitsize_zero_node;\n       *size = TYPE_SIZE (TREE_TYPE (t));\n       return;\n "}, {"sha": "b7dc3be5c850a31e0401e730e2360aaf1a76d42e", "filename": "gcc/flow.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fflow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fflow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fflow.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -2579,7 +2579,7 @@ verify_wide_reg_1 (px, pregno)\n      void *pregno;\n {\n   rtx x = *px;\n-  int regno = *(int *) pregno;\n+  unsigned int regno = *(int *) pregno;\n \n   if (GET_CODE (x) == REG && REGNO (x) == regno)\n     {"}, {"sha": "b32f65a594838f93415da9df0600e77d7554c580", "filename": "gcc/fold-const.c", "status": "modified", "additions": 31, "deletions": 30, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -80,7 +80,8 @@ static tree distribute_bit_expr PARAMS ((enum tree_code, tree, tree, tree));\n static tree make_bit_field_ref\tPARAMS ((tree, tree, int, int, int));\n static tree optimize_bit_field_compare PARAMS ((enum tree_code, tree,\n \t\t\t\t\t\ttree, tree));\n-static tree decode_field_reference PARAMS ((tree, int *, int *,\n+static tree decode_field_reference PARAMS ((tree, HOST_WIDE_INT *,\n+\t\t\t\t\t    HOST_WIDE_INT *,\n \t\t\t\t\t    enum machine_mode *, int *,\n \t\t\t\t\t    int *, tree *, tree *));\n static int all_ones_mask_p\tPARAMS ((tree, int));\n@@ -1491,18 +1492,15 @@ int_const_binop (code, arg1, arg2, notrunc, forsize)\n       /* It's unclear from the C standard whether shifts can overflow.\n \t The following code ignores overflow; perhaps a C standard\n \t interpretation ruling is needed.  */\n-      lshift_double (int1l, int1h, int2l,\n-\t\t     TYPE_PRECISION (TREE_TYPE (arg1)),\n-\t\t     &low, &hi,\n-\t\t     !uns);\n+      lshift_double (int1l, int1h, int2l, TYPE_PRECISION (TREE_TYPE (arg1)),\n+\t\t     &low, &hi, !uns);\n       no_overflow = 1;\n       break;\n \n     case RROTATE_EXPR:\n       int2l = - int2l;\n     case LROTATE_EXPR:\n-      lrotate_double (int1l, int1h, int2l,\n-\t\t      TYPE_PRECISION (TREE_TYPE (arg1)),\n+      lrotate_double (int1l, int1h, int2l, TYPE_PRECISION (TREE_TYPE (arg1)),\n \t\t      &low, &hi);\n       break;\n \n@@ -1599,7 +1597,7 @@ int_const_binop (code, arg1, arg2, notrunc, forsize)\n       abort ();\n     }\n \n-  if (forsize && hi == 0 && low < 1000)\n+  if (forsize && hi == 0 && low < 10000)\n     return size_int_type_wide (low, TREE_TYPE (arg1));\n   else\n     {\n@@ -1850,7 +1848,7 @@ size_int_type_wide (number, type)\n      tree type;\n {\n   /* Type-size nodes already made for small sizes.  */\n-  static tree size_table[2 * HOST_BITS_PER_WIDE_INT + 1];\n+  static tree size_table[2048 + 1];\n   static int init_p = 0;\n   tree t;\n   \n@@ -1864,8 +1862,7 @@ size_int_type_wide (number, type)\n   /* If this is a positive number that fits in the table we use to hold\n      cached entries, see if it is already in the table and put it there\n      if not.  */\n-  if (number >= 0\n-      && number < (int) (sizeof size_table / sizeof size_table[0]) / 2)\n+  if (number >= 0 && number < (int) (sizeof size_table / sizeof size_table[0]))\n     {\n       if (size_table[number] != 0)\n \tfor (t = size_table[number]; t != 0; t = TREE_CHAIN (t))\n@@ -2021,7 +2018,7 @@ fold_convert (t, arg1)\n \t  /* If we are trying to make a sizetype for a small integer, use\n \t     size_int to pick up cached types to reduce duplicate nodes.  */\n \t  if (TREE_CODE (type) == INTEGER_CST && TYPE_IS_SIZETYPE (type)\n-\t      && compare_tree_int (arg1, 1000) < 0)\n+\t      && compare_tree_int (arg1, 10000) < 0)\n \t    return size_int_type_wide (TREE_INT_CST_LOW (arg1), type);\n \n \t  /* Given an integer constant, make new constant with new type,\n@@ -2432,7 +2429,7 @@ operand_equal_for_comparison_p (arg0, arg1, other)\n {\n   int unsignedp1, unsignedpo;\n   tree primarg0, primarg1, primother;\n-  unsigned correct_width;\n+  unsigned int correct_width;\n \n   if (operand_equal_p (arg0, arg1, 0))\n     return 1;\n@@ -2909,14 +2906,14 @@ optimize_bit_field_compare (code, compare_type, lhs, rhs)\n      tree compare_type;\n      tree lhs, rhs;\n {\n-  int lbitpos, lbitsize, rbitpos, rbitsize, nbitpos, nbitsize;\n+  HOST_WIDE_INT lbitpos, lbitsize, rbitpos, rbitsize, nbitpos, nbitsize;\n   tree type = TREE_TYPE (lhs);\n   tree signed_type, unsigned_type;\n   int const_p = TREE_CODE (rhs) == INTEGER_CST;\n   enum machine_mode lmode, rmode, nmode;\n   int lunsignedp, runsignedp;\n   int lvolatilep = 0, rvolatilep = 0;\n-  int alignment;\n+  unsigned int alignment;\n   tree linner, rinner = NULL_TREE;\n   tree mask;\n   tree offset;\n@@ -3085,7 +3082,7 @@ static tree\n decode_field_reference (exp, pbitsize, pbitpos, pmode, punsignedp,\n \t\t\tpvolatilep, pmask, pand_mask)\n      tree exp;\n-     int *pbitsize, *pbitpos;\n+     HOST_WIDE_INT *pbitsize, *pbitpos;\n      enum machine_mode *pmode;\n      int *punsignedp, *pvolatilep;\n      tree *pmask;\n@@ -3094,8 +3091,8 @@ decode_field_reference (exp, pbitsize, pbitpos, pmode, punsignedp,\n   tree and_mask = 0;\n   tree mask, inner, offset;\n   tree unsigned_type;\n-  int precision;\n-  int alignment;\n+  unsigned int precision;\n+  unsigned int alignment;\n \n   /* All the optimizations using this function assume integer fields.  \n      There are problems with FP fields since the type_for_size call\n@@ -3151,7 +3148,7 @@ all_ones_mask_p (mask, size)\n      int size;\n {\n   tree type = TREE_TYPE (mask);\n-  int precision = TYPE_PRECISION (type);\n+  unsigned int precision = TYPE_PRECISION (type);\n   tree tmask;\n \n   tmask = build_int_2 (~0, ~0);\n@@ -3893,10 +3890,10 @@ fold_truthop (code, truth_type, lhs, rhs)\n   enum tree_code lcode, rcode;\n   tree ll_arg, lr_arg, rl_arg, rr_arg;\n   tree ll_inner, lr_inner, rl_inner, rr_inner;\n-  int ll_bitsize, ll_bitpos, lr_bitsize, lr_bitpos;\n-  int rl_bitsize, rl_bitpos, rr_bitsize, rr_bitpos;\n-  int xll_bitpos, xlr_bitpos, xrl_bitpos, xrr_bitpos;\n-  int lnbitsize, lnbitpos, rnbitsize, rnbitpos;\n+  HOST_WIDE_INT ll_bitsize, ll_bitpos, lr_bitsize, lr_bitpos;\n+  HOST_WIDE_INT rl_bitsize, rl_bitpos, rr_bitsize, rr_bitpos;\n+  HOST_WIDE_INT xll_bitpos, xlr_bitpos, xrl_bitpos, xrr_bitpos;\n+  HOST_WIDE_INT lnbitsize, lnbitpos, rnbitsize, rnbitpos;\n   int ll_unsignedp, lr_unsignedp, rl_unsignedp, rr_unsignedp;\n   enum machine_mode ll_mode, lr_mode, rl_mode, rr_mode;\n   enum machine_mode lnmode, rnmode;\n@@ -5042,17 +5039,17 @@ fold (expr)\n \t  int inside_int = INTEGRAL_TYPE_P (inside_type);\n \t  int inside_ptr = POINTER_TYPE_P (inside_type);\n \t  int inside_float = FLOAT_TYPE_P (inside_type);\n-\t  int inside_prec = TYPE_PRECISION (inside_type);\n+\t  unsigned int inside_prec = TYPE_PRECISION (inside_type);\n \t  int inside_unsignedp = TREE_UNSIGNED (inside_type);\n \t  int inter_int = INTEGRAL_TYPE_P (inter_type);\n \t  int inter_ptr = POINTER_TYPE_P (inter_type);\n \t  int inter_float = FLOAT_TYPE_P (inter_type);\n-\t  int inter_prec = TYPE_PRECISION (inter_type);\n+\t  unsigned int inter_prec = TYPE_PRECISION (inter_type);\n \t  int inter_unsignedp = TREE_UNSIGNED (inter_type);\n \t  int final_int = INTEGRAL_TYPE_P (final_type);\n \t  int final_ptr = POINTER_TYPE_P (final_type);\n \t  int final_float = FLOAT_TYPE_P (final_type);\n-\t  int final_prec = TYPE_PRECISION (final_type);\n+\t  unsigned int final_prec = TYPE_PRECISION (final_type);\n \t  int final_unsignedp = TREE_UNSIGNED (final_type);\n \n \t  /* In addition to the cases of two conversions in a row \n@@ -5690,7 +5687,9 @@ fold (expr)\n       if (TREE_CODE (arg0) == INTEGER_CST && TREE_CODE (arg1) == NOP_EXPR\n \t  && TREE_UNSIGNED (TREE_TYPE (TREE_OPERAND (arg1, 0))))\n \t{\n-\t  int prec = TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (arg1, 0)));\n+\t  unsigned int prec\n+\t    = TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (arg1, 0)));\n+\n \t  if (prec < BITS_PER_WORD && prec < HOST_BITS_PER_WIDE_INT\n \t      && (~TREE_INT_CST_LOW (arg0)\n \t\t  & (((HOST_WIDE_INT) 1 << prec) - 1)) == 0)\n@@ -5699,7 +5698,9 @@ fold (expr)\n       if (TREE_CODE (arg1) == INTEGER_CST && TREE_CODE (arg0) == NOP_EXPR\n \t  && TREE_UNSIGNED (TREE_TYPE (TREE_OPERAND (arg0, 0))))\n \t{\n-\t  int prec = TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (arg0, 0)));\n+\t  unsigned int prec\n+\t    = TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (arg0, 0)));\n+\n \t  if (prec < BITS_PER_WORD && prec < HOST_BITS_PER_WIDE_INT\n \t      && (~TREE_INT_CST_LOW (arg1)\n \t\t  & (((HOST_WIDE_INT) 1 << prec) - 1)) == 0)\n@@ -6108,7 +6109,7 @@ fold (expr)\n \t\t\t\t\t  (TREE_OPERAND\n \t\t\t\t\t   (TREE_OPERAND (varop, 0), 1)));\n \t\t    tree mask, unsigned_type;\n-\t\t    int precision;\n+\t\t    unsigned int precision;\n \t\t    tree folded_compare;\n \n \t\t    /* First check whether the comparison would come out\n@@ -6165,7 +6166,7 @@ fold (expr)\n \t\t\t\t\t  (TREE_OPERAND\n \t\t\t\t\t   (TREE_OPERAND (varop, 0), 1)));\n \t\t    tree mask, unsigned_type;\n-\t\t    int precision;\n+\t\t    unsigned int precision;\n \t\t    tree folded_compare;\n \n \t\t    if (constopnum == 0)"}, {"sha": "5bebaa9a0317df6cca568ac138428a9bae724a2c", "filename": "gcc/function.c", "status": "modified", "additions": 15, "deletions": 11, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -247,7 +247,8 @@ static rtx assign_stack_temp_for_type PARAMS ((enum machine_mode,\n static struct temp_slot *find_temp_slot_from_address  PARAMS ((rtx));\n static void put_reg_into_stack\tPARAMS ((struct function *, rtx, tree,\n \t\t\t\t\t enum machine_mode, enum machine_mode,\n-\t\t\t\t\t int, int, int, struct hash_table *));\n+\t\t\t\t\t int, unsigned int, int,\n+\t\t\t\t\t struct hash_table *));\n static void fixup_var_refs\tPARAMS ((rtx, enum machine_mode, int, \n \t\t\t\t\t struct hash_table *));\n static struct fixup_replacement\n@@ -262,7 +263,7 @@ static rtx fixup_stack_1\tPARAMS ((rtx, rtx));\n static void optimize_bit_field\tPARAMS ((rtx, rtx, rtx *));\n static void instantiate_decls\tPARAMS ((tree, int));\n static void instantiate_decls_1\tPARAMS ((tree, int));\n-static void instantiate_decl\tPARAMS ((rtx, int, int));\n+static void instantiate_decl\tPARAMS ((rtx, HOST_WIDE_INT, int));\n static int instantiate_virtual_regs_1 PARAMS ((rtx *, rtx, int));\n static void delete_handlers\tPARAMS ((void));\n static void pad_to_arg_alignment PARAMS ((struct args_size *, int,\n@@ -1451,19 +1452,20 @@ put_reg_into_stack (function, reg, type, promoted_mode, decl_mode, volatile_p,\n      tree type;\n      enum machine_mode promoted_mode, decl_mode;\n      int volatile_p;\n-     int original_regno;\n+     unsigned int original_regno;\n      int used_p;\n      struct hash_table *ht;\n {\n   struct function *func = function ? function : cfun;\n   rtx new = 0;\n-  int regno = original_regno;\n+  unsigned int regno = original_regno;\n \n   if (regno == 0)\n     regno = REGNO (reg);\n \n   if (regno < func->x_max_parm_reg)\n     new = func->x_parm_reg_stack_loc[regno];\n+\n   if (new == 0)\n     new = assign_stack_local_1 (decl_mode, GET_MODE_SIZE (decl_mode), 0, func);\n \n@@ -3328,7 +3330,7 @@ instantiate_virtual_regs (fndecl, insns)\n      rtx insns;\n {\n   rtx insn;\n-  int i;\n+  unsigned int i;\n \n   /* Compute the offsets to use for this function.  */\n   in_arg_offset = FIRST_PARM_OFFSET (fndecl);\n@@ -3446,7 +3448,7 @@ instantiate_decls_1 (let, valid_only)\n static void\n instantiate_decl (x, size, valid_only)\n      rtx x;\n-     int size;\n+     HOST_WIDE_INT size;\n      int valid_only;\n {\n   enum machine_mode mode;\n@@ -3476,21 +3478,23 @@ instantiate_decl (x, size, valid_only)\n \n   instantiate_virtual_regs_1 (&addr, NULL_RTX, 0);\n \n-  if (valid_only)\n+  if (valid_only && size >= 0)\n     {\n+      unsigned HOST_WIDE_INT decl_size = size;\n+\n       /* Now verify that the resulting address is valid for every integer or\n \t floating-point mode up to and including SIZE bytes long.  We do this\n \t since the object might be accessed in any mode and frame addresses\n \t are shared.  */\n \n       for (mode = GET_CLASS_NARROWEST_MODE (MODE_INT);\n-\t   mode != VOIDmode && GET_MODE_SIZE (mode) <= size;\n+\t   mode != VOIDmode && GET_MODE_SIZE (mode) <= decl_size;\n \t   mode = GET_MODE_WIDER_MODE (mode))\n \tif (! memory_address_p (mode, addr))\n \t  return;\n \n       for (mode = GET_CLASS_NARROWEST_MODE (MODE_FLOAT);\n-\t   mode != VOIDmode && GET_MODE_SIZE (mode) <= size;\n+\t   mode != VOIDmode && GET_MODE_SIZE (mode) <= decl_size;\n \t   mode = GET_MODE_WIDER_MODE (mode))\n \tif (! memory_address_p (mode, addr))\n \t  return;\n@@ -4523,7 +4527,7 @@ assign_parms (fndecl)\n \t     may need to do it in a wider mode.  */\n \n \t  register rtx parmreg;\n-\t  int regno, regnoi = 0, regnor = 0;\n+\t  unsigned int regno, regnoi = 0, regnor = 0;\n \n \t  unsignedp = TREE_UNSIGNED (TREE_TYPE (parm));\n \n@@ -4917,7 +4921,7 @@ assign_parms (fndecl)\n \n rtx\n promoted_input_arg (regno, pmode, punsignedp)\n-     int regno;\n+     unsigned int regno;\n      enum machine_mode *pmode;\n      int *punsignedp;\n {"}, {"sha": "e43dd11da57e19b742ab46280eb1551db46d322a", "filename": "gcc/function.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ffunction.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ffunction.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -399,7 +399,7 @@ struct function\n \n   /* 1 + last pseudo register number possibly used for loading a copy\n      of a parameter of this function. */\n-  int x_max_parm_reg;\n+  unsigned int x_max_parm_reg;\n \n   /* Vector indexed by REGNO, containing location on stack in which\n      to put the parm which is nominally in pseudo register REGNO,"}, {"sha": "7a646f1c5e7b96e19bc760e05e1b7c29cc5dffd3", "filename": "gcc/gcse.c", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fgcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fgcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgcse.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -399,7 +399,7 @@ static rtx *cuid_insn;\n /* Maximum register number in function prior to doing gcse + 1.\n    Registers created during this pass have regno >= max_gcse_regno.\n    This is named with \"gcse\" to not collide with global of same name.  */\n-static int max_gcse_regno;\n+static unsigned int max_gcse_regno;\n \n /* Maximum number of cse-able expressions found.  */\n static int n_exprs;\n@@ -519,9 +519,9 @@ struct null_pointer_info\n   /* The basic block being processed.  */\n   int current_block;\n   /* The first register to be handled in this pass.  */\n-  int min_reg;\n+  unsigned int min_reg;\n   /* One greater than the last register to be handled in this pass.  */\n-  int max_reg;\n+  unsigned int max_reg;\n   sbitmap *nonnull_local;\n   sbitmap *nonnull_killed;\n };\n@@ -566,8 +566,8 @@ static void compute_expr_hash_table PARAMS ((void));\n static void dump_hash_table\tPARAMS ((FILE *, const char *, struct expr **,\n \t\t\t\t\t int, int));\n static struct expr *lookup_expr\tPARAMS ((rtx));\n-static struct expr *lookup_set\tPARAMS ((int, rtx));\n-static struct expr *next_set\tPARAMS ((int, struct expr *));\n+static struct expr *lookup_set\tPARAMS ((unsigned int, rtx));\n+static struct expr *next_set\tPARAMS ((unsigned int, struct expr *));\n static void reset_opr_set_tables PARAMS ((void));\n static int oprs_not_set_p\tPARAMS ((rtx, rtx));\n static void mark_call\t\tPARAMS ((rtx));\n@@ -628,7 +628,8 @@ static int handle_avail_expr\tPARAMS ((rtx, struct expr *));\n static int classic_gcse\t\tPARAMS ((void));\n static int one_classic_gcse_pass PARAMS ((int));\n static void invalidate_nonnull_info PARAMS ((rtx, rtx, void *));\n-static void delete_null_pointer_checks_1 PARAMS ((int *, sbitmap *, sbitmap *,\n+static void delete_null_pointer_checks_1 PARAMS ((unsigned int *, sbitmap *,\n+\t\t\t\t\t\t  sbitmap *,\n \t\t\t\t\t\t  struct null_pointer_info *));\n static rtx process_insert_insn\tPARAMS ((struct expr *));\n static int pre_edge_insert\tPARAMS ((struct edge_list *, struct expr **));\n@@ -2124,9 +2125,9 @@ compute_hash_table (set_p)\n   for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n       rtx insn;\n-      int regno;\n+      unsigned int regno;\n       int in_libcall_block;\n-      int i;\n+      unsigned int i;\n \n       /* First pass over the instructions records information used to\n \t determine when registers and memory are first and last set.\n@@ -2135,6 +2136,7 @@ compute_hash_table (set_p)\n \n       for (i = 0; i < max_gcse_regno; i++)\n \treg_first_set[i] = reg_last_set[i] = NEVER_SET;\n+\n       mem_first_set = NEVER_SET;\n       mem_last_set = NEVER_SET;\n \n@@ -2321,7 +2323,7 @@ lookup_expr (pat)\n \n static struct expr *\n lookup_set (regno, pat)\n-     int regno;\n+     unsigned int regno;\n      rtx pat;\n {\n   unsigned int hash = hash_set (regno, set_hash_table_size);\n@@ -2347,7 +2349,7 @@ lookup_set (regno, pat)\n \n static struct expr *\n next_set (regno, expr)\n-     int regno;\n+     unsigned int regno;\n      struct expr *expr;\n {\n   do\n@@ -3074,7 +3076,7 @@ handle_avail_expr (insn, expr)\n     {\n       /* This is the case when the available expression that reaches\n \t here has already been handled as an available expression.  */\n-      int regnum_for_replacing\n+      unsigned int regnum_for_replacing\n \t= REGNO (SET_SRC (PATTERN (insn_computes_expr)));\n \n       /* If the register was created by GCSE we can't use `reg_set_table',\n@@ -3093,7 +3095,7 @@ handle_avail_expr (insn, expr)\n \n   if (!found_setting)\n     {\n-      int regnum_for_replacing\n+      unsigned int regnum_for_replacing\n \t= REGNO (SET_DEST (PATTERN (insn_computes_expr)));\n \n       /* This shouldn't happen.  */\n@@ -3836,7 +3838,7 @@ cprop_insn (insn, alter_jumps)\n   for (reg_used = &reg_use_table[0]; reg_use_count > 0;\n        reg_used++, reg_use_count--)\n     {\n-      int regno = REGNO (reg_used->reg_rtx);\n+      unsigned int regno = REGNO (reg_used->reg_rtx);\n       rtx pat, src;\n       struct expr *set;\n \n@@ -4868,10 +4870,8 @@ invalidate_nonnull_info (x, setter, data)\n      rtx setter ATTRIBUTE_UNUSED;\n      void *data;\n {\n-  int offset, regno;\n-  struct null_pointer_info* npi = (struct null_pointer_info *) data;\n-\n-  offset = 0;\n+  unsigned int regno;\n+  struct null_pointer_info *npi = (struct null_pointer_info *) data;\n \n   while (GET_CODE (x) == SUBREG)\n     x = SUBREG_REG (x);\n@@ -4894,7 +4894,7 @@ invalidate_nonnull_info (x, setter, data)\n \n static void\n delete_null_pointer_checks_1 (block_reg, nonnull_avin, nonnull_avout, npi)\n-     int *block_reg;\n+     unsigned int *block_reg;\n      sbitmap *nonnull_avin;\n      sbitmap *nonnull_avout;\n      struct null_pointer_info *npi;\n@@ -5063,7 +5063,7 @@ delete_null_pointer_checks (f)\n      rtx f;\n {\n   sbitmap *nonnull_avin, *nonnull_avout;\n-  int *block_reg;\n+  unsigned int *block_reg;\n   int bb;\n   int reg;\n   int regs_per_pass;"}, {"sha": "46da58773a529fccf0ef499888b0ddaf644f7ba1", "filename": "gcc/genattrtab.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fgenattrtab.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fgenattrtab.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgenattrtab.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -622,7 +622,7 @@ attr_rtx VPARAMS ((enum rtx_code code, ...))\n   else if (GET_RTX_LENGTH (code) == 1\n \t   && GET_RTX_FORMAT (code)[0] == 's')\n     {\n-      char * arg0 = va_arg (p, char *);\n+      char *arg0 = va_arg (p, char *);\n \n       if (code == SYMBOL_REF)\n \targ0 = attr_string (arg0, strlen (arg0));"}, {"sha": "2fe33c9d14e60cf6eb3ab1084923fbc0b827497a", "filename": "gcc/ggc-common.c", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fggc-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fggc-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc-common.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -363,6 +363,10 @@ ggc_mark_tree_children (t)\n       ggc_mark_rtx (DECL_INCOMING_RTL (t));\n       break;\n \n+    case FIELD_DECL:\n+      ggc_mark_tree (DECL_FIELD_BIT_OFFSET (t));\n+      break;\n+\n     case IDENTIFIER_NODE:\n       ggc_mark_string (IDENTIFIER_POINTER (t));\n       lang_mark_tree (t);"}, {"sha": "1ad8d1a24bb10ed63a677749e038d7b395259d01", "filename": "gcc/ggc.h", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fggc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fggc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,22 +1,22 @@\n /* Garbage collection for the GNU compiler.\n    Copyright (C) 1998, 1999, 2000 Free Software Foundation, Inc.\n \n-   This file is part of GNU CC.\n-\n-   GNU CC is free software; you can redistribute it and/or modify\n-   it under the terms of the GNU General Public License as published by\n-   the Free Software Foundation; either version 2, or (at your option)\n-   any later version.\n-\n-   GNU CC is distributed in the hope that it will be useful,\n-   but WITHOUT ANY WARRANTY; without even the implied warranty of\n-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-   GNU General Public License for more details.\n-\n-   You should have received a copy of the GNU General Public License\n-   along with GNU CC; see the file COPYING.  If not, write to\n-   the Free Software Foundation, 59 Temple Place - Suite 330,\n-   Boston, MA 02111-1307, USA.  */\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify it\n+under the terms of the GNU General Public License as published by the\n+Free Software Foundation; either version 2, or (at your option) any\n+later version.\n+\n+GNU CC is distributed in the hope that it will be useful, but WITHOUT\n+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n \n #include \"gansidecl.h\"\n "}, {"sha": "3c615538643f5900f5eab85587fb5dff0c5e4ba6", "filename": "gcc/global.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fglobal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fglobal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fglobal.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1585,11 +1585,11 @@ static void\n set_preference (dest, src)\n      rtx dest, src;\n {\n-  int src_regno, dest_regno;\n+  unsigned int src_regno, dest_regno;\n   /* Amount to add to the hard regno for SRC, or subtract from that for DEST,\n      to compensate for subregs in SRC or DEST.  */\n   int offset = 0;\n-  int i;\n+  unsigned int i;\n   int copy = 1;\n \n   if (GET_RTX_FORMAT (GET_CODE (src))[0] == 'e')\n@@ -1633,7 +1633,7 @@ set_preference (dest, src)\n       && reg_allocno[src_regno] >= 0)\n     {\n       dest_regno -= offset;\n-      if (dest_regno >= 0 && dest_regno < FIRST_PSEUDO_REGISTER)\n+      if (dest_regno < FIRST_PSEUDO_REGISTER)\n \t{\n \t  if (copy)\n \t    SET_REGBIT (hard_reg_copy_preferences,\n@@ -1652,7 +1652,7 @@ set_preference (dest, src)\n       && reg_allocno[dest_regno] >= 0)\n     {\n       src_regno += offset;\n-      if (src_regno >= 0 && src_regno < FIRST_PSEUDO_REGISTER)\n+      if (src_regno < FIRST_PSEUDO_REGISTER)\n \t{\n \t  if (copy)\n \t    SET_REGBIT (hard_reg_copy_preferences,"}, {"sha": "8037edaacd5cc1447d8e76f5feed86554f8c5559", "filename": "gcc/hard-reg-set.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fhard-reg-set.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fhard-reg-set.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhard-reg-set.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,5 +1,5 @@\n /* Sets (bit vectors) of hard registers, and operations on them.\n-   Copyright (C) 1987, 1992, 1994 Free Software Foundation, Inc.\n+   Copyright (C) 1987, 1992, 1994, 2000 Free Software Foundation, Inc.\n \n This file is part of GNU CC\n \n@@ -445,7 +445,7 @@ extern HARD_REG_SET reg_class_contents[];\n \n /* For each reg class, number of regs it contains.  */\n \n-extern int reg_class_size[N_REG_CLASSES];\n+extern unsigned int reg_class_size[N_REG_CLASSES];\n \n /* For each reg class, table listing all the containing classes.  */\n "}, {"sha": "5b8c8dc7b25c02272b91823c3f4768783cc78675", "filename": "gcc/integrate.c", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fintegrate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fintegrate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fintegrate.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -2572,15 +2572,16 @@ mark_stores (dest, x, data)\n \n   if (regno >= 0)\n     {\n-      int last_reg = (regno >= FIRST_PSEUDO_REGISTER ? regno\n-\t\t      : regno + HARD_REGNO_NREGS (regno, mode) - 1);\n-      int i;\n+      unsigned int uregno = regno;\n+      unsigned int last_reg = (uregno >= FIRST_PSEUDO_REGISTER ? uregno\n+\t\t\t      : uregno + HARD_REGNO_NREGS (uregno, mode) - 1);\n+      unsigned int i;\n \n       /* Ignore virtual stack var or virtual arg register since those\n \t are handled separately.  */\n-      if (regno != VIRTUAL_INCOMING_ARGS_REGNUM\n-\t  && regno != VIRTUAL_STACK_VARS_REGNUM)\n-\tfor (i = regno; i <= last_reg; i++)\n+      if (uregno != VIRTUAL_INCOMING_ARGS_REGNUM\n+\t  && uregno != VIRTUAL_STACK_VARS_REGNUM)\n+\tfor (i = uregno; i <= last_reg; i++)\n \t  if ((size_t) i < VARRAY_SIZE (global_const_equiv_varray))\n \t    VARRAY_CONST_EQUIV (global_const_equiv_varray, i).rtx = 0;\n     }"}, {"sha": "1584a80894a6a7db42c539abcd17c3e3080eccf4", "filename": "gcc/java/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjava%2FChangeLog?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,3 +1,11 @@\n+Sat Mar 25 09:12:10 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n+\n+\t* class.c (make_field_value): Use byte_position.\n+\t* expr.c (JAVA_ARRAY_LENGTH_OFFSET): Use byte_position.\n+\t(java_array_data_offset): Likewise.\n+\t* java-tree.h (MAYBE_CREATE_TYPE_TYPE_LANG_SPECIFIC): Add case to\n+\tbzero call.\n+\n 2000-03-22  Alexandre Petit-Bianco  <apbianco@cygnus.com>\n \n \t* parse.y (check_abstract_method_definitions): New local"}, {"sha": "e9d41e37e0dd128c0c00308ef6023b019b8e46f8", "filename": "gcc/java/class.c", "status": "modified", "additions": 15, "deletions": 18, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2Fclass.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2Fclass.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjava%2Fclass.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1071,7 +1071,7 @@ static tree\n make_field_value (fdecl)\n   tree fdecl;\n {\n-  tree finit, info;\n+  tree finit;\n   int flags;\n   tree type = TREE_TYPE (fdecl);\n   int resolved = is_compiled_class (type);\n@@ -1083,33 +1083,30 @@ make_field_value (fdecl)\n   else\n     {\n       tree signature = build_java_signature (type);\n+\n       type = build_utf8_ref (unmangle_classname \n-\t\t\t     (IDENTIFIER_POINTER(signature),\n-\t\t\t      IDENTIFIER_LENGTH(signature)));\n+\t\t\t     (IDENTIFIER_POINTER (signature),\n+\t\t\t      IDENTIFIER_LENGTH (signature)));\n     }\n   PUSH_FIELD_VALUE (finit, \"type\", type);\n+\n   flags = get_access_flags_from_decl (fdecl);\n   if (! resolved)\n     flags |= 0x8000 /* FIELD_UNRESOLVED_FLAG */;\n \n   PUSH_FIELD_VALUE (finit, \"accflags\", build_int_2 (flags, 0));\n   PUSH_FIELD_VALUE (finit, \"bsize\", TYPE_SIZE_UNIT (TREE_TYPE (fdecl)));\n-  if (FIELD_STATIC (fdecl))\n-    {\n-      tree cfield = TREE_CHAIN (TYPE_FIELDS (field_info_union_node));\n-      tree faddr = build_address_of (build_static_field_ref (fdecl));\n-\n-      info = build (CONSTRUCTOR, field_info_union_node, NULL_TREE,\n-\t\t    build_tree_list (cfield, faddr));\n-    }\n-  else\n-    info = build (CONSTRUCTOR, field_info_union_node, NULL_TREE,\n-\t\t  build_tree_list (TYPE_FIELDS (field_info_union_node),\n-\t\t\t\t   build_int_2 ((int_bit_position (fdecl)\n-\t\t\t\t\t\t / BITS_PER_UNIT),\n-\t\t\t\t\t\t0)));\n \n-  PUSH_FIELD_VALUE (finit, \"info\", info);\n+  PUSH_FIELD_VALUE\n+    (finit, \"info\",\n+     build (CONSTRUCTOR, field_info_union_node, NULL_TREE,\n+\t    build_tree_list\n+\t    ((FIELD_STATIC (fdecl)\n+\t      ? TREE_CHAIN (TYPE_FIELDS (field_info_union_node))\n+\t      : TYPE_FIELDS (field_info_union_node)),\n+\t     (FIELD_STATIC (fdecl)\n+\t      ? build_address_of (build_static_field_ref (fdecl))\n+\t      : byte_position (fdecl)))));\n \n   FINISH_RECORD_CONSTRUCTOR (finit);\n   return finit;"}, {"sha": "776c6f3db73a243263b04a8c4597949aa582ba83", "filename": "gcc/java/expr.c", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjava%2Fexpr.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -575,11 +575,8 @@ build_java_ret (location)\n \n /* Array core info access macros */\n \n-#define JAVA_ARRAY_LENGTH_OFFSET(A)\t\t\t\t\t   \\\n-  size_binop (CEIL_DIV_EXPR, \t\t\t\t\t\t   \\\n-\t      (DECL_FIELD_BITPOS\t\t\t\t\t   \\\n-\t\t  (TREE_CHAIN (TYPE_FIELDS (TREE_TYPE (TREE_TYPE (A)))))), \\\n-              bitsize_int (BITS_PER_UNIT))\n+#define JAVA_ARRAY_LENGTH_OFFSET(A) \\\n+  byte_position (TREE_CHAIN (TYPE_FIELDS (TREE_TYPE (TREE_TYPE (A)))))\n \n tree\n decode_newarray_type (atype)\n@@ -690,10 +687,11 @@ java_array_data_offset (array)\n {\n   tree array_type = TREE_TYPE (TREE_TYPE (array));\n   tree data_fld = TREE_CHAIN (TREE_CHAIN (TYPE_FIELDS (array_type)));\n+\n   if (data_fld == NULL_TREE)\n     return size_in_bytes (array_type);\n   else\n-    return build_int_2 (int_bit_position (data_fld) / BITS_PER_UNIT, 0);\n+    return byte_position (data_fld);\n }\n \n /* Implement array indexing (either as l-value or r-value)."}, {"sha": "f56991c7fabf6704401ff5d575934d786bbb9ff7", "filename": "gcc/java/java-tree.h", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2Fjava-tree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjava%2Fjava-tree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjava%2Fjava-tree.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -541,9 +541,12 @@ struct lang_decl_var\n   if (TYPE_LANG_SPECIFIC ((T)) == NULL)\t\t\t\t\t\\\n     {\t\t\t\t\t\t\t\t\t\\\n       TYPE_LANG_SPECIFIC ((T)) = \t\t\t\t\t\\\n-\t(struct lang_type *)xmalloc (sizeof (struct lang_type));\t\\\n-      bzero (TYPE_LANG_SPECIFIC ((T)), sizeof (struct lang_type));\t\\\n+\t(struct lang_type *) xmalloc (sizeof (struct lang_type));\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+      bzero ((char *) TYPE_LANG_SPECIFIC ((T)),\t\t\t\t\\\n+\t     sizeof (struct lang_type));\t\t\t\t\\\n     }\n+\n #define TYPE_FINIT_STMT_LIST(T)  (TYPE_LANG_SPECIFIC(T)->finit_stmt_list)\n #define TYPE_CLINIT_STMT_LIST(T) (TYPE_LANG_SPECIFIC(T)->clinit_stmt_list)\n #define TYPE_II_STMT_LIST(T)     (TYPE_LANG_SPECIFIC(T)->ii_block)"}, {"sha": "1aba12c286ac72ff6901d12753f8547c475cc50a", "filename": "gcc/jump.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fjump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjump.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -4998,7 +4998,8 @@ mark_modified_reg (dest, x, data)\n      rtx x ATTRIBUTE_UNUSED;\n      void *data ATTRIBUTE_UNUSED;\n {\n-  int regno, i;\n+  int regno;\n+  unsigned int i;\n \n   if (GET_CODE (dest) == SUBREG)\n     dest = SUBREG_REG (dest);\n@@ -5286,7 +5287,7 @@ rtx_equal_for_thread_p (x, y, yinsn)\n \t  return 1;\n \t}\n       else\n-\treturn (same_regs[REGNO (x)] == REGNO (y));\n+\treturn (same_regs[REGNO (x)] == (int) REGNO (y));\n \n       break;\n \n@@ -5310,7 +5311,7 @@ rtx_equal_for_thread_p (x, y, yinsn)\n       if (GET_CODE (SET_DEST (x)) == REG\n           && GET_CODE (SET_DEST (y)) == REG)\n \t{\n-          if (same_regs[REGNO (SET_DEST (x))] == REGNO (SET_DEST (y)))\n+          if (same_regs[REGNO (SET_DEST (x))] == (int) REGNO (SET_DEST (y)))\n \t    {\n \t      same_regs[REGNO (SET_DEST (x))] = -1;\n \t      num_same_regs--;"}, {"sha": "e277f803425a7d550903935d13d2a2590e1d0cd0", "filename": "gcc/local-alloc.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Flocal-alloc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Flocal-alloc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flocal-alloc.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1252,9 +1252,10 @@ block_alloc (b)\n \t  for (link = REG_NOTES (insn); link; link = XEXP (link, 1))\n \t    if (REG_NOTE_KIND (link) == REG_DEAD\n \t\t&& GET_CODE (XEXP (link, 0)) == REG\n-\t\t&& combined_regno != REGNO (XEXP (link, 0))\n-\t\t&& (no_conflict_combined_regno != REGNO (XEXP (link, 0))\n-\t\t    || ! find_reg_note (insn, REG_NO_CONFLICT, XEXP (link, 0))))\n+\t\t&& combined_regno != (int) REGNO (XEXP (link, 0))\n+\t\t&& (no_conflict_combined_regno != (int) REGNO (XEXP (link, 0))\n+\t\t    || ! find_reg_note (insn, REG_NO_CONFLICT,\n+\t\t\t\t\tXEXP (link, 0))))\n \t      wipe_dead_reg (XEXP (link, 0), 0);\n \n \t  /* Allocate qty numbers for all registers local to this block"}, {"sha": "cbb1731deae6a9a50464c2d6a48ec73c95490931", "filename": "gcc/loop.c", "status": "modified", "additions": 13, "deletions": 12, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Floop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Floop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -162,7 +162,7 @@ static int num_mem_sets;\n \n /* Bound on pseudo register number before loop optimization.\n    A pseudo has valid regscan info if its number is < max_reg_before_loop.  */\n-int max_reg_before_loop;\n+unsigned int max_reg_before_loop;\n \n /* The value to pass to the next call of reg_scan_update.  */\n static int loop_max_reg;\n@@ -194,7 +194,7 @@ struct movable\n \t\t\t\t   of any registers used within the LIBCALL.  */\n   int consec;\t\t\t/* Number of consecutive following insns \n \t\t\t\t   that must be moved with this one.  */\n-  int regno;\t\t\t/* The register it sets */\n+  unsigned int regno;\t\t/* The register it sets */\n   short lifetime;\t\t/* lifetime of that register;\n \t\t\t\t   may be adjusted when matching movables\n \t\t\t\t   that load the same value are found.  */\n@@ -306,7 +306,7 @@ static int insert_loop_mem PARAMS ((rtx *, void *));\n static int replace_loop_mem PARAMS ((rtx *, void *));\n static int replace_loop_reg PARAMS ((rtx *, void *));\n static void note_reg_stored PARAMS ((rtx, rtx, void *));\n-static void try_copy_prop PARAMS ((const struct loop *, rtx, int));\n+static void try_copy_prop PARAMS ((const struct loop *, rtx, unsigned int));\n static int replace_label PARAMS ((rtx *, void *));\n \n typedef struct rtx_and_int {\n@@ -1536,8 +1536,8 @@ regs_match_p (x, y, movables)\n      rtx x, y;\n      struct movable *movables;\n {\n-  int xn = REGNO (x);\n-  int yn = REGNO (y);\n+  unsigned int xn = REGNO (x);\n+  unsigned int yn = REGNO (y);\n   struct movable *mx, *my;\n \n   for (mx = movables; mx; mx = mx->next)\n@@ -3348,8 +3348,8 @@ consec_sets_invariant_p (loop, reg, n_sets, insn)\n      int n_sets;\n      rtx reg, insn;\n {\n-  register rtx p = insn;\n-  register int regno = REGNO (reg);\n+  rtx p = insn;\n+  unsigned int regno = REGNO (reg);\n   rtx temp;\n   /* Number of sets we have to insist on finding after INSN.  */\n   int count = n_sets - 1;\n@@ -3657,7 +3657,7 @@ struct iv_class *loop_iv_list;\n /* Givs made from biv increments are always splittable for loop unrolling.\n    Since there is no regscan info for them, we have to keep track of them\n    separately.  */\n-int first_increment_giv, last_increment_giv;\n+unsigned int first_increment_giv, last_increment_giv;\n \n /* Communication with routines called via `note_stores'.  */\n \n@@ -4089,7 +4089,7 @@ strength_reduce (loop, insn_count, unroll_p, bct_p)\n \t      && CONSTANT_P (XEXP (src, 1))\n \t      && ((increment = biv_total_increment (bl)) != NULL_RTX))\n \t    {\n-\t      int regno = REGNO (XEXP (src, 0));\n+\t      unsigned int regno = REGNO (XEXP (src, 0));\n \n \t      for (bl2 = loop_iv_list; bl2; bl2 = bl2->next)\n \t\tif (bl2->regno == regno)\n@@ -4215,7 +4215,7 @@ strength_reduce (loop, insn_count, unroll_p, bct_p)\n      markers.  */\n   if (n_extra_increment  && ! loop_info->has_volatile)\n     {\n-      int nregs = first_increment_giv + n_extra_increment;\n+      unsigned int nregs = first_increment_giv + n_extra_increment;\n \n       /* Reallocate reg_iv_type and reg_iv_info.  */\n       VARRAY_GROW (reg_iv_type, nregs);\n@@ -8458,7 +8458,7 @@ maybe_eliminate_biv (loop, bl, eliminate_p, threshold, insn_count)\n \n \t      if (set && GET_CODE (SET_DEST (set)) == REG)\n \t\t{\n-\t\t  int regno = REGNO (SET_DEST (set));\n+\t\t  unsigned int regno = REGNO (SET_DEST (set));\n \n \t\t  if (regno < max_reg_before_loop\n \t\t      && REG_IV_TYPE (regno) == GENERAL_INDUCT\n@@ -10064,11 +10064,12 @@ note_reg_stored (x, setter, arg)\n    There must be exactly one insn that sets this pseudo; it will be\n    deleted if all replacements succeed and we can prove that the register\n    is not used after the loop.  */\n+\n static void\n try_copy_prop (loop, replacement, regno)\n      const struct loop *loop;\n      rtx replacement;\n-     int regno;\n+     unsigned int regno;\n {\n   /* This is the reg that we are copying from.  */\n   rtx reg_rtx = regno_reg_rtx[regno];"}, {"sha": "703073372b6492ff51f52d077c694ed2c5de9ab6", "filename": "gcc/loop.h", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Floop.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Floop.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -137,7 +137,7 @@ struct induction\n /* A `struct iv_class' is created for each biv.  */\n \n struct iv_class {\n-  int regno;\t\t\t/* Pseudo reg which is the biv.  */\n+  unsigned int regno;\t\t/* Pseudo reg which is the biv.  */\n   int biv_count;\t\t/* Number of insns setting this reg.  */\n   struct induction *biv;\t/* List of all insns that set this reg.  */\n   int giv_count;\t\t/* Number of DEST_REG givs computed from this\n@@ -211,7 +211,7 @@ enum iv_mode { UNKNOWN_INDUCT, BASIC_INDUCT, NOT_BASIC_INDUCT,\n \n extern int *uid_luid;\n extern int max_uid_for_loop;\n-extern int max_reg_before_loop;\n+extern unsigned int max_reg_before_loop;\n extern struct loop **uid_loop;\n extern FILE *loop_dump_stream;\n \n@@ -226,7 +226,7 @@ extern varray_type reg_iv_info;\n extern struct iv_class **reg_biv_class;\n extern struct iv_class *loop_iv_list;\n \n-extern int first_increment_giv, last_increment_giv;\n+extern unsigned int first_increment_giv, last_increment_giv;\n \n /* Forward declarations for non-static functions declared in loop.c and\n    unroll.c.  */"}, {"sha": "ee2d7249eb6067ac2ecbb673e09c62698bdff3f2", "filename": "gcc/machmode.h", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fmachmode.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fmachmode.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmachmode.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -68,12 +68,12 @@ extern const enum mode_class mode_class[];\n \n /* Get the size in bytes of an object of mode MODE.  */\n \n-extern const int mode_size[];\n+extern const unsigned int mode_size[];\n #define GET_MODE_SIZE(MODE)\t\t(mode_size[(int) (MODE)])\n \n /* Get the size in bytes of the basic parts of an object of mode MODE.  */\n \n-extern const int mode_unit_size[];\n+extern const unsigned int mode_unit_size[];\n #define GET_MODE_UNIT_SIZE(MODE)\t(mode_unit_size[(int) (MODE)])\n \n /* Get the number of units in the object.  */\n@@ -106,12 +106,13 @@ extern const unsigned char mode_wider_mode[];\n    If LIMIT is nonzero, then don't use modes bigger than MAX_FIXED_MODE_SIZE.\n    The value is BLKmode if no other mode is found.  */\n \n-extern enum machine_mode mode_for_size PARAMS ((int, enum mode_class, int));\n+extern enum machine_mode mode_for_size PARAMS ((unsigned int,\n+\t\t\t\t\t\tenum mode_class, int));\n \n /* Similar, but find the smallest mode for a given width.  */\n \n extern enum machine_mode smallest_mode_for_size \n-\t\t\t\tPARAMS ((int, enum mode_class));\n+\t\t\t\tPARAMS ((unsigned int, enum mode_class));\n \n \n /* Return an integer mode of the exact same size as the input mode,"}, {"sha": "842944d43d35169be8f0faee963056d2191b26e8", "filename": "gcc/objc/objc-act.c", "status": "modified", "additions": 2, "deletions": 7, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fobjc%2Fobjc-act.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fobjc%2Fobjc-act.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fobjc%2Fobjc-act.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -3817,13 +3817,8 @@ build_ivar_list_initializer (type, field_decl)\n \t   ivar);\n       obstack_free (&util_obstack, util_firstobj);\n \n-      /* set offset */\n-      ivar\n-\t= tree_cons\n-\t  (NULL_TREE,\n-\t   build_int_2 ((int_bit_position (field_decl) / BITS_PER_UNIT), 0),\n-\t   ivar);\n-\n+      /* Set offset. */\n+      ivar = tree_cons (NULL_TREE, byte_position (field_decl), ivar);\n       initlist = tree_cons (NULL_TREE, \n \t\t\t    build_constructor (type, nreverse (ivar)),\n \t\t\t    initlist);"}, {"sha": "b92f1e1858dde49bde967602063a1b7f866ee6b5", "filename": "gcc/optabs.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -829,7 +829,7 @@ expand_binop (mode, binoptab, op0, op1, target, unsignedp, methods)\n       && GET_MODE_SIZE (mode) > UNITS_PER_WORD\n       && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)\n     {\n-      int i;\n+      unsigned int i;\n       rtx insns;\n       rtx equiv_value;\n \n@@ -1120,10 +1120,10 @@ expand_binop (mode, binoptab, op0, op1, target, unsignedp, methods)\n       && GET_MODE_SIZE (mode) >= 2 * UNITS_PER_WORD\n       && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)\n     {\n-      int i;\n+      unsigned int i;\n       rtx carry_tmp = gen_reg_rtx (word_mode);\n       optab otheroptab = binoptab == add_optab ? sub_optab : add_optab;\n-      int nwords = GET_MODE_BITSIZE (mode) / BITS_PER_WORD;\n+      unsigned int nwords = GET_MODE_BITSIZE (mode) / BITS_PER_WORD;\n       rtx carry_in = NULL_RTX, carry_out = NULL_RTX;\n       rtx xop0, xop1;\n \n@@ -2090,7 +2090,7 @@ expand_unop (mode, unoptab, op0, target, unsignedp)\n       && GET_MODE_SIZE (mode) > UNITS_PER_WORD\n       && unoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)\n     {\n-      int i;\n+      unsigned int i;\n       rtx insns;\n \n       if (target == 0 || target == op0)"}, {"sha": "f9a9709bd34b2ecdd1860dbec8e8cc6dafff77ea", "filename": "gcc/print-tree.c", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fprint-tree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fprint-tree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fprint-tree.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -421,7 +421,11 @@ print_node (file, prefix, node, indent)\n \tfprintf (file, \" alias set %d\", DECL_POINTER_ALIAS_SET (node));\n \n       if (TREE_CODE (node) == FIELD_DECL)\n-\tprint_node (file, \"bitpos\", DECL_FIELD_BITPOS (node), indent + 4);\n+\t{\n+\t  print_node (file, \"offset\", DECL_FIELD_OFFSET (node), indent + 4);\n+\t  print_node (file, \"bit offset\", DECL_FIELD_BIT_OFFSET (node),\n+\t\t      indent + 4);\n+\t}\n \n       print_node_brief (file, \"context\", DECL_CONTEXT (node), indent + 4);\n       print_node_brief (file, \"machine_attributes\","}, {"sha": "f26635b89de552298e45a1cbd7bb2b215909f4ee", "filename": "gcc/real.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freal.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -6843,7 +6843,7 @@ esqrt (x, y)\n    floating point mode.  The mode can hold an integer value\n    that many bits wide, without losing any bits.  */\n \n-int\n+unsigned int\n significand_size (mode)\n      enum machine_mode mode;\n {"}, {"sha": "3aba2e245d4048f53d5a24fd0c962f33c8b66dd1", "filename": "gcc/real.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freal.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -119,7 +119,7 @@ typedef struct {\n #endif /* no TFmode support */\n #endif /* no XFmode support */\n \n-extern int significand_size\tPARAMS ((enum machine_mode));\n+extern unsigned int significand_size\tPARAMS ((enum machine_mode));\n \n /* If emulation has been enabled by defining REAL_ARITHMETIC or by\n    setting LONG_DOUBLE_TYPE_SIZE to 96 or 128, then define macros so that"}, {"sha": "3d7ba5f20da6fa019bbef331d9e34a627d267f2e", "filename": "gcc/regclass.c", "status": "modified", "additions": 15, "deletions": 14, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fregclass.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fregclass.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fregclass.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -140,7 +140,7 @@ static unsigned int_reg_class_contents[N_REG_CLASSES][N_REG_INTS]\n \n /* For each reg class, number of regs it contains.  */\n \n-int reg_class_size[N_REG_CLASSES];\n+unsigned int reg_class_size[N_REG_CLASSES];\n \n /* For each reg class, table listing all the containing classes.  */\n \n@@ -554,8 +554,8 @@ memory_move_secondary_cost (mode, class, in)\n \n enum machine_mode\n choose_hard_reg_mode (regno, nregs)\n-     int regno ATTRIBUTE_UNUSED;\n-     int nregs;\n+     unsigned int regno ATTRIBUTE_UNUSED;\n+     unsigned int nregs;\n {\n   enum machine_mode found_mode = VOIDmode, mode;\n \n@@ -730,7 +730,7 @@ static void record_address_regs\tPARAMS ((rtx, enum reg_class, int));\n #ifdef FORBIDDEN_INC_DEC_CLASSES\n static int auto_inc_dec_reg_p\tPARAMS ((rtx, enum machine_mode));\n #endif\n-static void reg_scan_mark_refs\tPARAMS ((rtx, rtx, int, int));\n+static void reg_scan_mark_refs\tPARAMS ((rtx, rtx, int, unsigned int));\n \n /* Return the reg_class in which pseudo reg number REGNO is best allocated.\n    This function is sometimes called before the info has been computed.\n@@ -1681,10 +1681,10 @@ record_reg_classes (n_alts, n_ops, ops, modes, subreg_changes_size,\n     for (i = 0; i <= 1; i++)\n       if (REGNO (ops[i]) >= FIRST_PSEUDO_REGISTER)\n \t{\n-\t  int regno = REGNO (ops[!i]);\n+\t  unsigned int regno = REGNO (ops[!i]);\n \t  enum machine_mode mode = GET_MODE (ops[!i]);\n \t  int class;\n-\t  int nr;\n+\t  unsigned int nr;\n \n \t  if (regno >= FIRST_PSEUDO_REGISTER && reg_pref != 0)\n \t    {\n@@ -1704,13 +1704,14 @@ record_reg_classes (n_alts, n_ops, ops, modes, subreg_changes_size,\n \t\t    op_costs[i].cost[class] = -1;\n \t\t  else\n \t\t    {\n-\t\t      for (nr = 0; nr < HARD_REGNO_NREGS(regno, mode); nr++)\n+\t\t      for (nr = 0; nr < HARD_REGNO_NREGS (regno, mode); nr++)\n \t\t\t{\n-\t\t\t  if (!TEST_HARD_REG_BIT (reg_class_contents[class], regno + nr))\n+\t\t\t  if (! TEST_HARD_REG_BIT (reg_class_contents[class],\n+\t\t\t\t\t\t   regno + nr))\n \t\t\t    break;\n \t\t\t}\n \n-\t\t      if (nr == HARD_REGNO_NREGS(regno,mode))\n+\t\t      if (nr == HARD_REGNO_NREGS (regno,mode))\n \t\t\top_costs[i].cost[class] = -1;\n \t\t    }\n \t\t}\n@@ -2142,7 +2143,7 @@ int max_parallel;\n void\n reg_scan (f, nregs, repeat)\n      rtx f;\n-     int nregs;\n+     unsigned int nregs;\n      int repeat ATTRIBUTE_UNUSED;\n {\n   register rtx insn;\n@@ -2171,10 +2172,10 @@ reg_scan (f, nregs, repeat)\n    such a REG.  We only update information for those.  */\n \n void\n-reg_scan_update(first, last, old_max_regno)\n+reg_scan_update (first, last, old_max_regno)\n      rtx first;\n      rtx last;\n-     int old_max_regno;\n+     unsigned int old_max_regno;\n {\n   register rtx insn;\n \n@@ -2205,7 +2206,7 @@ reg_scan_mark_refs (x, insn, note_flag, min_regno)\n      rtx x;\n      rtx insn;\n      int note_flag;\n-     int min_regno;\n+     unsigned int min_regno;\n {\n   register enum rtx_code code;\n   register rtx dest;\n@@ -2227,7 +2228,7 @@ reg_scan_mark_refs (x, insn, note_flag, min_regno)\n \n     case REG:\n       {\n-\tregister int regno = REGNO (x);\n+\tunsigned int regno = REGNO (x);\n \n \tif (regno >= min_regno)\n \t  {"}, {"sha": "3e5d2775e7358e152ac166212d973b8b1c5fc865", "filename": "gcc/reload.c", "status": "modified", "additions": 45, "deletions": 35, "changes": 80, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -253,11 +253,12 @@ static int find_reusable_reload\tPARAMS ((rtx *, rtx, enum reg_class,\n static rtx find_dummy_reload\tPARAMS ((rtx, rtx, rtx *, rtx *,\n \t\t\t\t       enum machine_mode, enum machine_mode,\n \t\t\t\t       enum reg_class, int, int));\n-static int hard_reg_set_here_p\tPARAMS ((int, int, rtx));\n+static int hard_reg_set_here_p\tPARAMS ((unsigned int, unsigned int, rtx));\n static struct decomposition decompose PARAMS ((rtx));\n static int immune_p\t\tPARAMS ((rtx, rtx, struct decomposition));\n static int alternative_allows_memconst PARAMS ((const char *, int));\n-static rtx find_reloads_toplev\tPARAMS ((rtx, int, enum reload_type, int, int, rtx));\n+static rtx find_reloads_toplev\tPARAMS ((rtx, int, enum reload_type, int,\n+\t\t\t\t\t int, rtx));\n static rtx make_memloc\t\tPARAMS ((rtx, int));\n static int find_reloads_address\tPARAMS ((enum machine_mode, rtx *, rtx, rtx *,\n \t\t\t\t       int, enum reload_type, int, rtx));\n@@ -659,7 +660,7 @@ find_valid_class (m1, n)\n   int class;\n   int regno;\n   enum reg_class best_class = NO_REGS;\n-  int best_size = 0;\n+  unsigned int best_size = 0;\n \n   for (class = 1; class < N_REG_CLASSES; class++)\n     {\n@@ -1823,8 +1824,8 @@ find_dummy_reload (real_in, real_out, inloc, outloc,\n   if (GET_CODE (out) == REG\n       && REGNO (out) < FIRST_PSEUDO_REGISTER)\n     {\n-      register int regno = REGNO (out) + out_offset;\n-      int nwords = HARD_REGNO_NREGS (regno, outmode);\n+      unsigned int regno = REGNO (out) + out_offset;\n+      unsigned int nwords = HARD_REGNO_NREGS (regno, outmode);\n       rtx saved_rtx;\n \n       /* When we consider whether the insn uses OUT,\n@@ -1843,7 +1844,8 @@ find_dummy_reload (real_in, real_out, inloc, outloc,\n \t  && ! refers_to_regno_for_reload_p (regno, regno + nwords,\n \t\t\t\t\t     PATTERN (this_insn), outloc))\n \t{\n-\t  int i;\n+\t  unsigned int i;\n+\n \t  for (i = 0; i < nwords; i++)\n \t    if (! TEST_HARD_REG_BIT (reg_class_contents[(int) class],\n \t\t\t\t     regno + i))\n@@ -1882,8 +1884,8 @@ find_dummy_reload (real_in, real_out, inloc, outloc,\n \t\t\t     (GET_MODE (out) != VOIDmode\n \t\t\t      ? GET_MODE (out) : outmode)))\n     {\n-      register int regno = REGNO (in) + in_offset;\n-      int nwords = HARD_REGNO_NREGS (regno, inmode);\n+      unsigned int regno = REGNO (in) + in_offset;\n+      unsigned int nwords = HARD_REGNO_NREGS (regno, inmode);\n \n       if (! refers_to_regno_for_reload_p (regno, regno + nwords, out, NULL_PTR)\n \t  && ! hard_reg_set_here_p (regno, regno + nwords,\n@@ -1892,7 +1894,8 @@ find_dummy_reload (real_in, real_out, inloc, outloc,\n \t      || ! refers_to_regno_for_reload_p (regno, regno + nwords,\n \t\t\t\t\t\t PATTERN (this_insn), inloc)))\n \t{\n-\t  int i;\n+\t  unsigned int i;\n+\n \t  for (i = 0; i < nwords; i++)\n \t    if (! TEST_HARD_REG_BIT (reg_class_contents[(int) class],\n \t\t\t\t     regno + i))\n@@ -1942,17 +1945,19 @@ earlyclobber_operand_p (x)\n \n static int\n hard_reg_set_here_p (beg_regno, end_regno, x)\n-     register int beg_regno, end_regno;\n+     unsigned int beg_regno, end_regno;\n      rtx x;\n {\n   if (GET_CODE (x) == SET || GET_CODE (x) == CLOBBER)\n     {\n       register rtx op0 = SET_DEST (x);\n+\n       while (GET_CODE (op0) == SUBREG)\n \top0 = SUBREG_REG (op0);\n       if (GET_CODE (op0) == REG)\n \t{\n-\t  register int r = REGNO (op0);\n+\t  unsigned int r = REGNO (op0);\n+\n \t  /* See if this reg overlaps range under consideration.  */\n \t  if (r < end_regno\n \t      && r + HARD_REGNO_NREGS (r, GET_MODE (op0)) > beg_regno)\n@@ -1962,6 +1967,7 @@ hard_reg_set_here_p (beg_regno, end_regno, x)\n   else if (GET_CODE (x) == PARALLEL)\n     {\n       register int i = XVECLEN (x, 0) - 1;\n+\n       for (; i >= 0; i--)\n \tif (hard_reg_set_here_p (beg_regno, end_regno, XVECEXP (x, 0, i)))\n \t  return 1;\n@@ -5689,13 +5695,14 @@ find_replacement (loc)\n \n int\n refers_to_regno_for_reload_p (regno, endregno, x, loc)\n-     int regno, endregno;\n+     unsigned int regno, endregno;\n      rtx x;\n      rtx *loc;\n {\n-  register int i;\n-  register RTX_CODE code;\n-  register const char *fmt;\n+  int i;\n+  unsigned int r;\n+  RTX_CODE code;\n+  const char *fmt;\n \n   if (x == 0)\n     return 0;\n@@ -5706,26 +5713,26 @@ refers_to_regno_for_reload_p (regno, endregno, x, loc)\n   switch (code)\n     {\n     case REG:\n-      i = REGNO (x);\n+      r = REGNO (x);\n \n       /* If this is a pseudo, a hard register must not have been allocated.\n \t X must therefore either be a constant or be in memory.  */\n-      if (i >= FIRST_PSEUDO_REGISTER)\n+      if (r >= FIRST_PSEUDO_REGISTER)\n \t{\n-\t  if (reg_equiv_memory_loc[i])\n+\t  if (reg_equiv_memory_loc[r])\n \t    return refers_to_regno_for_reload_p (regno, endregno,\n-\t\t\t\t\t\t reg_equiv_memory_loc[i],\n+\t\t\t\t\t\t reg_equiv_memory_loc[r],\n \t\t\t\t\t\t NULL_PTR);\n \n-\t  if (reg_equiv_constant[i])\n+\t  if (reg_equiv_constant[r])\n \t    return 0;\n \n \t  abort ();\n \t}\n \n-      return (endregno > i\n-\t      && regno < i + (i < FIRST_PSEUDO_REGISTER\n-\t\t\t      ? HARD_REGNO_NREGS (i, GET_MODE (x))\n+      return (endregno > r\n+\t      && regno < r + (r < FIRST_PSEUDO_REGISTER\n+\t\t\t      ? HARD_REGNO_NREGS (r, GET_MODE (x))\n \t\t\t      : 1));\n \n     case SUBREG:\n@@ -5734,8 +5741,8 @@ refers_to_regno_for_reload_p (regno, endregno, x, loc)\n       if (GET_CODE (SUBREG_REG (x)) == REG\n \t  && REGNO (SUBREG_REG (x)) < FIRST_PSEUDO_REGISTER)\n \t{\n-\t  int inner_regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n-\t  int inner_endregno\n+\t  unsigned int inner_regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n+\t  unsigned int inner_endregno\n \t    = inner_regno + (inner_regno < FIRST_PSEUDO_REGISTER\n \t\t\t     ? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n \n@@ -5983,21 +5990,24 @@ find_equiv_reg (goal, insn, class, other, reload_reg_p, goalreg, mode)\n       p = PREV_INSN (p);\n       if (p == 0 || GET_CODE (p) == CODE_LABEL)\n \treturn 0;\n+\n       if (GET_CODE (p) == INSN\n \t  /* If we don't want spill regs ...  */\n \t  && (! (reload_reg_p != 0\n \t\t && reload_reg_p != (short *) (HOST_WIDE_INT) 1)\n-\t      /* ... then ignore insns introduced by reload; they aren't useful\n-\t\t and can cause results in reload_as_needed to be different\n-\t\t from what they were when calculating the need for spills.\n-\t\t If we notice an input-reload insn here, we will reject it below,\n-\t\t but it might hide a usable equivalent.  That makes bad code.\n-\t\t It may even abort: perhaps no reg was spilled for this insn\n-\t\t because it was assumed we would find that equivalent.  */\n+\t      /* ... then ignore insns introduced by reload; they aren't\n+\t\t useful and can cause results in reload_as_needed to be\n+\t\t different from what they were when calculating the need for\n+\t\t spills.  If we notice an input-reload insn here, we will\n+\t\t reject it below, but it might hide a usable equivalent.\n+\t\t That makes bad code.  It may even abort: perhaps no reg was\n+\t\t spilled for this insn because it was assumed we would find\n+\t\t that equivalent.  */\n \t      || INSN_UID (p) < reload_first_uid))\n \t{\n \t  rtx tem;\n \t  pat = single_set (p);\n+\n \t  /* First check for something that sets some reg equal to GOAL.  */\n \t  if (pat != 0\n \t      && ((regno >= 0\n@@ -6098,8 +6108,8 @@ find_equiv_reg (goal, insn, class, other, reload_reg_p, goalreg, mode)\n   /* Reject registers that overlap GOAL.  */\n \n   if (!goal_mem && !goal_const\n-      && regno + HARD_REGNO_NREGS (regno, mode) > valueno\n-      && regno < valueno + HARD_REGNO_NREGS (valueno, mode))\n+      && regno + (int) HARD_REGNO_NREGS (regno, mode) > valueno\n+      && regno < valueno + (int) HARD_REGNO_NREGS (valueno, mode))\n     return 0;\n \n   /* Reject VALUE if it is one of the regs reserved for reloads.\n@@ -6388,7 +6398,7 @@ find_inc_amount (x, inced)\n \n int\n regno_clobbered_p (regno, insn)\n-     int regno;\n+     unsigned int regno;\n      rtx insn;\n {\n   if (GET_CODE (PATTERN (insn)) == CLOBBER"}, {"sha": "34b93cf2b207dedd27e2008c313afe3f3b9f0a45", "filename": "gcc/reload.h", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freload.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freload.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -104,7 +104,7 @@ struct reload\n   enum machine_mode mode;\n \n   /* the largest number of registers this reload will require.  */\n-  int nregs;\n+  unsigned int nregs;\n \n   /* Positive amount to increment or decrement by if\n      reload_in is a PRE_DEC, PRE_INC, POST_DEC, POST_INC.\n@@ -319,7 +319,8 @@ extern rtx find_replacement PARAMS ((rtx *));\n /* Return nonzero if register in range [REGNO, ENDREGNO)\n    appears either explicitly or implicitly in X\n    other than being stored into.  */\n-extern int refers_to_regno_for_reload_p PARAMS ((int, int, rtx, rtx *));\n+extern int refers_to_regno_for_reload_p PARAMS ((unsigned int, unsigned int,\n+\t\t\t\t\t\t rtx, rtx *));\n \n /* Nonzero if modifying X will affect IN.  */\n extern int reg_overlap_mentioned_for_reload_p PARAMS ((rtx, rtx));\n@@ -334,7 +335,7 @@ extern rtx find_equiv_reg PARAMS ((rtx, rtx, enum reg_class, int, short *,\n \t\t\t\t int, enum machine_mode));\n \n /* Return 1 if register REGNO is the subject of a clobber in insn INSN.  */\n-extern int regno_clobbered_p PARAMS ((int, rtx));\n+extern int regno_clobbered_p PARAMS ((unsigned int, rtx));\n \n /* Return 1 if X is an operand of an insn that is being earlyclobbered.  */\n int earlyclobber_operand_p PARAMS ((rtx));"}, {"sha": "996336c2620ea4ba5f3256fe952d2509520a15b7", "filename": "gcc/reload1.c", "status": "modified", "additions": 96, "deletions": 63, "changes": 159, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freload1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Freload1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload1.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -120,7 +120,7 @@ rtx *reg_equiv_address;\n rtx *reg_equiv_mem;\n \n /* Widest width in which each pseudo reg is referred to (via subreg).  */\n-static int *reg_max_ref_width;\n+static unsigned int *reg_max_ref_width;\n \n /* Element N is the list of insns that initialized reg N from its equivalent\n    constant or memory slot.  */\n@@ -237,7 +237,7 @@ char double_reg_address_ok;\n static rtx spill_stack_slot[FIRST_PSEUDO_REGISTER];\n \n /* Width allocated so far for that stack slot.  */\n-static int spill_stack_slot_width[FIRST_PSEUDO_REGISTER];\n+static unsigned int spill_stack_slot_width[FIRST_PSEUDO_REGISTER];\n \n /* Record which pseudos needed to be spilled.  */\n static regset_head spilled_pseudos;\n@@ -393,7 +393,7 @@ static void set_initial_label_offsets\tPARAMS ((void));\n static void set_offsets_for_label\tPARAMS ((rtx));\n static void init_elim_table\t\tPARAMS ((void));\n static void update_eliminables\t\tPARAMS ((HARD_REG_SET *));\n-static void spill_hard_reg\t\tPARAMS ((int, FILE *, int));\n+static void spill_hard_reg\t\tPARAMS ((unsigned int, FILE *, int));\n static int finish_spills\t\tPARAMS ((int, FILE *));\n static void ior_hard_reg_set\t\tPARAMS ((HARD_REG_SET *, HARD_REG_SET *));\n static void scan_paradoxical_subregs\tPARAMS ((rtx));\n@@ -402,28 +402,33 @@ static void order_regs_for_reload\tPARAMS ((struct insn_chain *));\n static void reload_as_needed\t\tPARAMS ((int));\n static void forget_old_reloads_1\tPARAMS ((rtx, rtx, void *));\n static int reload_reg_class_lower\tPARAMS ((const PTR, const PTR));\n-static void mark_reload_reg_in_use\tPARAMS ((int, int, enum reload_type,\n-\t\t\t\t\t       enum machine_mode));\n-static void clear_reload_reg_in_use\tPARAMS ((int, int, enum reload_type,\n-\t\t\t\t\t       enum machine_mode));\n-static int reload_reg_free_p\t\tPARAMS ((int, int, enum reload_type));\n+static void mark_reload_reg_in_use\tPARAMS ((unsigned int, int,\n+\t\t\t\t\t\t enum reload_type,\n+\t\t\t\t\t\t enum machine_mode));\n+static void clear_reload_reg_in_use\tPARAMS ((unsigned int, int,\n+\t\t\t\t\t\t enum reload_type,\n+\t\t\t\t\t\t enum machine_mode));\n+static int reload_reg_free_p\t\tPARAMS ((unsigned int, int,\n+\t\t\t\t\t\t enum reload_type));\n static int reload_reg_free_for_value_p\tPARAMS ((int, int, enum reload_type,\n-\t\t\t\t\t       rtx, rtx, int, int));\n-static int reload_reg_reaches_end_p\tPARAMS ((int, int, enum reload_type));\n-static int allocate_reload_reg\t\tPARAMS ((struct insn_chain *, int, int));\n+\t\t\t\t\t\t rtx, rtx, int, int));\n+static int reload_reg_reaches_end_p\tPARAMS ((unsigned int, int,\n+\t\t\t\t\t\t enum reload_type));\n+static int allocate_reload_reg\t\tPARAMS ((struct insn_chain *, int,\n+\t\t\t\t\t\t int));\n static void failed_reload\t\tPARAMS ((rtx, int));\n static int set_reload_reg\t\tPARAMS ((int, int));\n static void choose_reload_regs_init\tPARAMS ((struct insn_chain *, rtx *));\n static void choose_reload_regs\t\tPARAMS ((struct insn_chain *));\n static void merge_assigned_reloads\tPARAMS ((rtx));\n static void emit_input_reload_insns\tPARAMS ((struct insn_chain *,\n-\t\t\t\t\t       struct reload *, rtx, int));\n+\t\t\t\t\t\t struct reload *, rtx, int));\n static void emit_output_reload_insns\tPARAMS ((struct insn_chain *,\n-\t\t\t\t\t       struct reload *, int));\n+\t\t\t\t\t\t struct reload *, int));\n static void do_input_reload\t\tPARAMS ((struct insn_chain *,\n-\t\t\t\t\t       struct reload *, int));\n+\t\t\t\t\t\t struct reload *, int));\n static void do_output_reload\t\tPARAMS ((struct insn_chain *,\n-\t\t\t\t\t       struct reload *, int));\n+\t\t\t\t\t\t struct reload *, int));\n static void emit_reload_insns\t\tPARAMS ((struct insn_chain *));\n static void delete_output_reload\tPARAMS ((rtx, int, int));\n static void delete_address_reloads\tPARAMS ((rtx, rtx));\n@@ -434,16 +439,16 @@ static void reload_cse_regs_1\t\tPARAMS ((rtx));\n static int reload_cse_noop_set_p\tPARAMS ((rtx));\n static int reload_cse_simplify_set\tPARAMS ((rtx, rtx));\n static int reload_cse_simplify_operands\tPARAMS ((rtx));\n-static void reload_combine PARAMS ((void));\n-static void reload_combine_note_use PARAMS ((rtx *, rtx));\n-static void reload_combine_note_store PARAMS ((rtx, rtx, void *));\n-static void reload_cse_move2add PARAMS ((rtx));\n-static void move2add_note_store PARAMS ((rtx, rtx, void *));\n+static void reload_combine\t\tPARAMS ((void));\n+static void reload_combine_note_use\tPARAMS ((rtx *, rtx));\n+static void reload_combine_note_store\tPARAMS ((rtx, rtx, void *));\n+static void reload_cse_move2add\t\tPARAMS ((rtx));\n+static void move2add_note_store\t\tPARAMS ((rtx, rtx, void *));\n #ifdef AUTO_INC_DEC\n-static void add_auto_inc_notes PARAMS ((rtx, rtx));\n+static void add_auto_inc_notes\t\tPARAMS ((rtx, rtx));\n #endif\n static rtx gen_mode_int\t\t\tPARAMS ((enum machine_mode,\n-\t\t\t\t\t       HOST_WIDE_INT));\n+\t\t\t\t\t\t HOST_WIDE_INT));\n static void failed_reload\t\tPARAMS ((rtx, int));\n static int set_reload_reg\t\tPARAMS ((int, int));\n extern void dump_needs\t\t\tPARAMS ((struct insn_chain *, FILE *));\n@@ -534,17 +539,20 @@ new_insn_chain ()\n \n /* Small utility function to set all regs in hard reg set TO which are\n    allocated to pseudos in regset FROM.  */\n+\n void\n compute_use_by_pseudos (to, from)\n      HARD_REG_SET *to;\n      regset from;\n {\n-  int regno;\n+  unsigned int regno;\n+\n   EXECUTE_IF_SET_IN_REG_SET\n     (from, FIRST_PSEUDO_REGISTER, regno,\n      {\n        int r = reg_renumber[regno];\n        int nregs;\n+\n        if (r < 0)\n \t {\n \t   /* reload_combine uses the information from\n@@ -1475,6 +1483,7 @@ static int spill_cost[FIRST_PSEUDO_REGISTER];\n static int spill_add_cost[FIRST_PSEUDO_REGISTER];\n \n /* Update the spill cost arrays, considering that pseudo REG is live.  */\n+\n static void\n count_pseudo (reg)\n      int reg;\n@@ -1552,6 +1561,7 @@ static HARD_REG_SET used_spill_regs_local;\n    SPILLED_NREGS.  Determine how pseudo REG, which is live during the insn,\n    is affected.  We will add it to SPILLED_PSEUDOS if necessary, and we will\n    update SPILL_COST/SPILL_ADD_COST.  */\n+\n static void\n count_spilled_pseudo (spilled, spilled_nregs, reg)\n      int spilled, spilled_nregs, reg;\n@@ -1582,7 +1592,8 @@ find_reg (chain, order, dumpfile)\n   struct reload *rl = rld + rnum;\n   int best_cost = INT_MAX;\n   int best_reg = -1;\n-  int i, j;\n+  unsigned int i, j;\n+  int k;\n   HARD_REG_SET not_usable;\n   HARD_REG_SET used_by_other_reload;\n \n@@ -1591,24 +1602,26 @@ find_reg (chain, order, dumpfile)\n   IOR_COMPL_HARD_REG_SET (not_usable, reg_class_contents[rl->class]);\n \n   CLEAR_HARD_REG_SET (used_by_other_reload);\n-  for (i = 0; i < order; i++)\n+  for (k = 0; k < order; k++)\n     {\n-      int other = reload_order[i];\n+      int other = reload_order[k];\n+\n       if (rld[other].regno >= 0 && reloads_conflict (other, rnum))\n \tfor (j = 0; j < rld[other].nregs; j++)\n \t  SET_HARD_REG_BIT (used_by_other_reload, rld[other].regno + j);\n     }\n \n   for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n     {\n-      int regno = i;\n+      unsigned int regno = i;\n+\n       if (! TEST_HARD_REG_BIT (not_usable, regno)\n \t  && ! TEST_HARD_REG_BIT (used_by_other_reload, regno)\n \t  && HARD_REGNO_MODE_OK (regno, rl->mode))\n \t{\n \t  int this_cost = spill_cost[regno];\n \t  int ok = 1;\n-\t  int this_nregs = HARD_REGNO_NREGS (regno, rl->mode);\n+\t  unsigned int this_nregs = HARD_REGNO_NREGS (regno, rl->mode);\n \n \t  for (j = 1; j < this_nregs; j++)\n \t    {\n@@ -1643,8 +1656,10 @@ find_reg (chain, order, dumpfile)\n     }\n   if (best_reg == -1)\n     return 0;\n+\n   if (dumpfile)\n     fprintf (dumpfile, \"Using reg %d for reload %d\\n\", best_reg, rnum);\n+\n   rl->nregs = HARD_REGNO_NREGS (best_reg, rl->mode);\n   rl->regno = best_reg;\n \n@@ -1653,6 +1668,7 @@ find_reg (chain, order, dumpfile)\n      {\n        count_spilled_pseudo (best_reg, rl->nregs, j);\n      });\n+\n   EXECUTE_IF_SET_IN_REG_SET\n     (&chain->dead_or_set, FIRST_PSEUDO_REGISTER, j,\n      {\n@@ -1693,7 +1709,8 @@ find_reload_regs (chain, dumpfile)\n \t{\n \t  int regno = REGNO (chain->rld[i].reg_rtx);\n \t  chain->rld[i].regno = regno;\n-\t  chain->rld[i].nregs = HARD_REGNO_NREGS (regno, GET_MODE (chain->rld[i].reg_rtx));\n+\t  chain->rld[i].nregs\n+\t    = HARD_REGNO_NREGS (regno, GET_MODE (chain->rld[i].reg_rtx));\n \t}\n       else\n \tchain->rld[i].regno = -1;\n@@ -1868,8 +1885,8 @@ alter_reg (i, from_reg)\n       && reg_equiv_memory_loc[i] == 0)\n     {\n       register rtx x;\n-      int inherent_size = PSEUDO_REGNO_BYTES (i);\n-      int total_size = MAX (inherent_size, reg_max_ref_width[i]);\n+      unsigned int inherent_size = PSEUDO_REGNO_BYTES (i);\n+      unsigned int total_size = MAX (inherent_size, reg_max_ref_width[i]);\n       int adjust = 0;\n \n       /* Each pseudo reg has an inherent size which comes from its own mode,\n@@ -1970,6 +1987,7 @@ mark_home_live (regno)\n      int regno;\n {\n   register int i, lim;\n+\n   i = reg_renumber[regno];\n   if (i < 0)\n     return;\n@@ -3419,7 +3437,7 @@ init_elim_table ()\n \n static void\n spill_hard_reg (regno, dumpfile, cant_eliminate)\n-     register int regno;\n+     unsigned int regno;\n      FILE *dumpfile ATTRIBUTE_UNUSED;\n      int cant_eliminate;\n {\n@@ -3436,16 +3454,17 @@ spill_hard_reg (regno, dumpfile, cant_eliminate)\n \n   for (i = FIRST_PSEUDO_REGISTER; i < max_regno; i++)\n     if (reg_renumber[i] >= 0\n-\t&& reg_renumber[i] <= regno\n-\t&& (reg_renumber[i]\n-\t    + HARD_REGNO_NREGS (reg_renumber[i],\n+\t&& (unsigned int) reg_renumber[i] <= regno\n+\t&& ((unsigned int) reg_renumber[i]\n+\t    + HARD_REGNO_NREGS ((unsigned int) reg_renumber[i],\n \t\t\t\tPSEUDO_REGNO_MODE (i))\n \t    > regno))\n       SET_REGNO_REG_SET (&spilled_pseudos, i);\n }\n \n /* I'm getting weird preprocessor errors if I use IOR_HARD_REG_SET\n    from within EXECUTE_IF_SET_IN_REG_SET.  Hence this awkwardness.  */\n+\n static void\n ior_hard_reg_set (set1, set2)\n      HARD_REG_SET *set1, *set2;\n@@ -3956,8 +3975,8 @@ forget_old_reloads_1 (x, ignored, data)\n      rtx ignored ATTRIBUTE_UNUSED;\n      void *data ATTRIBUTE_UNUSED;\n {\n-  register int regno;\n-  int nr;\n+  unsigned int regno;\n+  unsigned int nr;\n   int offset = 0;\n \n   /* note_stores does give us subregs of hard regs.  */\n@@ -3976,7 +3995,8 @@ forget_old_reloads_1 (x, ignored, data)\n     nr = 1;\n   else\n     {\n-      int i;\n+      unsigned int i;\n+\n       nr = HARD_REGNO_NREGS (regno, GET_MODE (x));\n       /* Storing into a spilled-reg invalidates its contents.\n \t This can happen if a block-local pseudo is allocated to that reg\n@@ -4045,13 +4065,13 @@ static HARD_REG_SET reg_used_in_insn;\n \n static void\n mark_reload_reg_in_use (regno, opnum, type, mode)\n-     int regno;\n+     unsigned int regno;\n      int opnum;\n      enum reload_type type;\n      enum machine_mode mode;\n {\n-  int nregs = HARD_REGNO_NREGS (regno, mode);\n-  int i;\n+  unsigned int nregs = HARD_REGNO_NREGS (regno, mode);\n+  unsigned int i;\n \n   for (i = regno; i < nregs + regno; i++)\n     {\n@@ -4110,13 +4130,13 @@ mark_reload_reg_in_use (regno, opnum, type, mode)\n \n static void\n clear_reload_reg_in_use (regno, opnum, type, mode)\n-     int regno;\n+     unsigned int regno;\n      int opnum;\n      enum reload_type type;\n      enum machine_mode mode;\n {\n-  int nregs = HARD_REGNO_NREGS (regno, mode);\n-  int start_regno, end_regno;\n+  unsigned int nregs = HARD_REGNO_NREGS (regno, mode);\n+  unsigned int start_regno, end_regno, r;\n   int i;\n   /* A complication is that for some reload types, inheritance might\n      allow multiple reloads of the same types to share a reload register.\n@@ -4196,8 +4216,8 @@ clear_reload_reg_in_use (regno, opnum, type, mode)\n \t      && (check_any || rld[i].opnum == opnum)\n \t      && rld[i].reg_rtx)\n \t    {\n-\t      int conflict_start = true_regnum (rld[i].reg_rtx);\n-\t      int conflict_end\n+\t      unsigned int conflict_start = true_regnum (rld[i].reg_rtx);\n+\t      unsigned int conflict_end\n \t\t= (conflict_start\n \t\t   + HARD_REGNO_NREGS (conflict_start, rld[i].mode));\n \n@@ -4212,16 +4232,17 @@ clear_reload_reg_in_use (regno, opnum, type, mode)\n \t    }\n \t}\n     }\n-  for (i = start_regno; i < end_regno; i++)\n-    CLEAR_HARD_REG_BIT (*used_in_set, i);\n+\n+  for (r = start_regno; r < end_regno; r++)\n+    CLEAR_HARD_REG_BIT (*used_in_set, r);\n }\n \n /* 1 if reg REGNO is free as a reload reg for a reload of the sort\n    specified by OPNUM and TYPE.  */\n \n static int\n reload_reg_free_p (regno, opnum, type)\n-     int regno;\n+     unsigned int regno;\n      int opnum;\n      enum reload_type type;\n {\n@@ -4381,7 +4402,7 @@ reload_reg_free_p (regno, opnum, type)\n \n static int\n reload_reg_reaches_end_p (regno, opnum, type)\n-     int regno;\n+     unsigned int regno;\n      int opnum;\n      enum reload_type type;\n {\n@@ -5101,7 +5122,7 @@ choose_reload_regs (chain)\n {\n   rtx insn = chain->insn;\n   register int i, j;\n-  int max_group_size = 1;\n+  unsigned int max_group_size = 1;\n   enum reg_class group_class = NO_REGS;\n   int pass, win, inheritance;\n \n@@ -5124,7 +5145,8 @@ choose_reload_regs (chain)\n       if (rld[j].nregs > 1)\n \t{\n \t  max_group_size = MAX (rld[j].nregs, max_group_size);\n-\t  group_class = reg_class_superunion[(int)rld[j].class][(int)group_class];\n+\t  group_class\n+\t    = reg_class_superunion[(int)rld[j].class][(int)group_class];\n \t}\n \n       save_reload_reg_rtx[j] = rld[j].reg_rtx;\n@@ -5146,11 +5168,11 @@ choose_reload_regs (chain)\n       /* Process the reloads in order of preference just found.\n \t Beyond this point, subregs can be found in reload_reg_rtx.\n \n-\t This used to look for an existing reloaded home for all\n-\t of the reloads, and only then perform any new reloads.\n-\t But that could lose if the reloads were done out of reg-class order\n-\t because a later reload with a looser constraint might have an old\n-\t home in a register needed by an earlier reload with a tighter constraint.\n+\t This used to look for an existing reloaded home for all of the\n+\t reloads, and only then perform any new reloads.  But that could lose\n+\t if the reloads were done out of reg-class order because a later\n+\t reload with a looser constraint might have an old home in a register\n+\t needed by an earlier reload with a tighter constraint.\n \n \t To solve this, we make two passes over the reloads, in the order\n \t described above.  In the first pass we try to inherit a reload\n@@ -5873,6 +5895,7 @@ static HARD_REG_SET reg_reloaded_died;\n \n /* Generate insns to perform reload RL, which is for the insn in CHAIN and\n    has the number J.  OLD contains the value to be used as input.  */\n+\n static void\n emit_input_reload_insns (chain, rl, old, j)\n      struct insn_chain *chain;\n@@ -5957,7 +5980,7 @@ emit_input_reload_insns (chain, rl, old, j)\n \n   if (oldequiv)\n     {\n-      int regno = true_regnum (oldequiv);\n+      unsigned int regno = true_regnum (oldequiv);\n \n       /* Don't use OLDEQUIV if any other reload changes it at an\n \t earlier stage of this insn or at this stage.  */\n@@ -8784,6 +8807,7 @@ reload_combine_note_use (xp, insn)\n    reg_offset[n] / reg_base_reg[n] / reg_mode[n] are only valid if\n    reg_set_luid[n] is larger than last_label_luid[n] .  */\n static int reg_set_luid[FIRST_PSEUDO_REGISTER];\n+\n /* reg_offset[n] has to be CONST_INT for it and reg_base_reg[n] /\n    reg_mode[n] to be valid.\n    If reg_offset[n] is a CONST_INT and reg_base_reg[n] is negative, register n\n@@ -8794,12 +8818,14 @@ static int reg_set_luid[FIRST_PSEUDO_REGISTER];\n static rtx reg_offset[FIRST_PSEUDO_REGISTER];\n static int reg_base_reg[FIRST_PSEUDO_REGISTER];\n static enum machine_mode reg_mode[FIRST_PSEUDO_REGISTER];\n+\n /* move2add_luid is linearily increased while scanning the instructions\n    from first to last.  It is used to set reg_set_luid in\n    reload_cse_move2add and move2add_note_store.  */\n static int move2add_luid;\n \n /* Generate a CONST_INT and force it in the range of MODE.  */\n+\n static rtx\n gen_mode_int (mode, value)\n      enum machine_mode mode;\n@@ -8900,7 +8926,7 @@ reload_cse_move2add (first)\n \t\t\t\t  ...\n \t\t\t\t  (set (REGX) (plus (REGX) (CONST_INT B-A)))  */\n \t      else if (GET_CODE (src) == REG\n-\t\t       && reg_base_reg[regno] == REGNO (src)\n+\t\t       && reg_base_reg[regno] == (int) REGNO (src)\n \t\t       && reg_set_luid[regno] > reg_set_luid[REGNO (src)])\n \t\t{\n \t\t  rtx next = next_nonnote_insn (insn);\n@@ -8985,20 +9011,22 @@ reload_cse_move2add (first)\n /* SET is a SET or CLOBBER that sets DST.\n    Update reg_set_luid, reg_offset and reg_base_reg accordingly.\n    Called from reload_cse_move2add via note_stores.  */\n+\n static void\n move2add_note_store (dst, set, data)\n      rtx dst, set;\n      void *data ATTRIBUTE_UNUSED;\n {\n-  int regno = 0;\n-  int i;\n-\n+  unsigned int regno = 0;\n+  unsigned int i;\n   enum machine_mode mode = GET_MODE (dst);\n+\n   if (GET_CODE (dst) == SUBREG)\n     {\n       regno = SUBREG_WORD (dst);\n       dst = SUBREG_REG (dst);\n     }\n+\n   if (GET_CODE (dst) != REG)\n     return;\n \n@@ -9017,6 +9045,7 @@ move2add_note_store (dst, set, data)\n \tcase PLUS:\n \t  {\n \t    rtx src0 = XEXP (src, 0);\n+\n \t    if (GET_CODE (src0) == REG)\n \t      {\n \t\tif (REGNO (src0) != regno\n@@ -9025,9 +9054,11 @@ move2add_note_store (dst, set, data)\n \t\t    reg_base_reg[regno] = REGNO (src0);\n \t\t    reg_set_luid[regno] = move2add_luid;\n \t\t  }\n+\n \t\treg_offset[regno] = XEXP (src, 1);\n \t\tbreak;\n \t      }\n+\n \t    reg_set_luid[regno] = move2add_luid;\n \t    reg_offset[regno] = set;\t/* Invalidate contents.  */\n \t    break;\n@@ -9048,7 +9079,9 @@ move2add_note_store (dst, set, data)\n     }\n   else\n     {\n-      for (i = regno + HARD_REGNO_NREGS (regno, mode) - 1; i >= regno; i--)\n+      unsigned int endregno = regno + HARD_REGNO_NREGS (regno, mode);\n+\n+      for (i = regno; i < endregno; i++)\n \t{\n \t  /* Indicate that this register has been recently written to,\n \t     but the exact contents are not available.  */"}, {"sha": "e2c3010f03a753e10a080f32bcd6d35c2787bd1e", "filename": "gcc/resource.c", "status": "modified", "additions": 37, "deletions": 28, "changes": 65, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fresource.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fresource.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fresource.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -185,8 +185,9 @@ mark_referenced_resources (x, res, include_delayed_effects)\n      register struct resources *res;\n      register int include_delayed_effects;\n {\n-  register enum rtx_code code = GET_CODE (x);\n-  register int i, j;\n+  enum rtx_code code = GET_CODE (x);\n+  int i, j;\n+  unsigned int r;\n   register const char *format_ptr;\n \n   /* Handle leaf items for which we set resource flags.  Also, special-case\n@@ -206,16 +207,18 @@ mark_referenced_resources (x, res, include_delayed_effects)\n \tmark_referenced_resources (SUBREG_REG (x), res, 0);\n       else\n \t{\n-\t  int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n-\t  int last_regno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t  for (i = regno; i < last_regno; i++)\n-\t    SET_HARD_REG_BIT (res->regs, i);\n+\t  unsigned int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n+\t  unsigned int last_regno\n+\t    = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\n+\t  for (r = regno; r < last_regno; r++)\n+\t    SET_HARD_REG_BIT (res->regs, r);\n \t}\n       return;\n \n     case REG:\n-      for (i = 0; i < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); i++)\n-\tSET_HARD_REG_BIT (res->regs, REGNO (x) + i);\n+      for (r = 0; r < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); r++)\n+\tSET_HARD_REG_BIT (res->regs, REGNO (x) + r);\n       return;\n \n     case MEM:\n@@ -594,9 +597,10 @@ mark_set_resources (x, res, in_dest, include_delayed_effects)\n      int in_dest;\n      int include_delayed_effects;\n {\n-  register enum rtx_code code;\n-  register int i, j;\n-  register const char *format_ptr;\n+  enum rtx_code code;\n+  int i, j;\n+  unsigned int r;\n+  const char *format_ptr;\n \n  restart:\n \n@@ -634,9 +638,9 @@ mark_set_resources (x, res, in_dest, include_delayed_effects)\n \t  rtx link;\n \n \t  res->cc = res->memory = 1;\n-\t  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-\t    if (call_used_regs[i] || global_regs[i])\n-\t      SET_HARD_REG_BIT (res->regs, i);\n+\t  for (r = 0; r < FIRST_PSEUDO_REGISTER; r++)\n+\t    if (call_used_regs[r] || global_regs[r])\n+\t      SET_HARD_REG_BIT (res->regs, r);\n \n \t  /* If X is part of a delay slot sequence, then NEXT should be\n \t     the first insn after the sequence.  */\n@@ -731,18 +735,20 @@ mark_set_resources (x, res, in_dest, include_delayed_effects)\n \t\t\t\tin_dest, include_delayed_effects);\n \t  else\n \t    {\n-\t      int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n-\t      int last_regno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t      for (i = regno; i < last_regno; i++)\n-\t\tSET_HARD_REG_BIT (res->regs, i);\n+\t      unsigned int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n+\t      unsigned int last_regno\n+\t\t= regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\n+\t      for (r = regno; r < last_regno; r++)\n+\t\tSET_HARD_REG_BIT (res->regs, r);\n \t    }\n \t}\n       return;\n \n     case REG:\n       if (in_dest)\n-        for (i = 0; i < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); i++)\n-\t  SET_HARD_REG_BIT (res->regs, REGNO (x) + i);\n+        for (r = 0; r < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); r++)\n+\t  SET_HARD_REG_BIT (res->regs, REGNO (x) + r);\n       return;\n \n     case UNSPEC_VOLATILE:\n@@ -905,8 +911,8 @@ mark_target_live_regs (insns, target, res)\n   if (b != -1)\n     {\n       regset regs_live = BASIC_BLOCK (b)->global_live_at_start;\n-      int j;\n-      int regno;\n+      unsigned int j;\n+      unsigned int regno;\n       rtx start_insn, stop_insn;\n \n       /* Compute hard regs live at start of block -- this is the real hard regs\n@@ -918,12 +924,15 @@ mark_target_live_regs (insns, target, res)\n       EXECUTE_IF_SET_IN_REG_SET\n \t(regs_live, FIRST_PSEUDO_REGISTER, i,\n \t {\n-\t   if ((regno = reg_renumber[i]) >= 0)\n-\t     for (j = regno;\n-\t\t  j < regno + HARD_REGNO_NREGS (regno,\n-\t\t\t\t\t\tPSEUDO_REGNO_MODE (i));\n-\t\t  j++)\n-\t       SET_HARD_REG_BIT (current_live_regs, j);\n+\t   if (reg_renumber[i] >= 0)\n+\t     {\n+\t       regno = reg_renumber[i];\n+\t       for (j = regno;\n+\t\t    j < regno + HARD_REGNO_NREGS (regno,\n+\t\t\t\t\t\t  PSEUDO_REGNO_MODE (i));\n+\t\t    j++)\n+\t\t SET_HARD_REG_BIT (current_live_regs, j);\n+\t     }\n \t });\n \n       /* Get starting and ending insn, handling the case where each might"}, {"sha": "b25d43ba445a876686cdf049f96ee8ce99212945", "filename": "gcc/rtl.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Frtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Frtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -136,7 +136,7 @@ const enum mode_class mode_class[(int) MAX_MACHINE_MODE] = {\n \n #define DEF_MACHMODE(SYM, NAME, CLASS, SIZE, UNIT, WIDER)  SIZE,\n \n-const int mode_size[(int) MAX_MACHINE_MODE] = {\n+const unsigned int mode_size[(int) MAX_MACHINE_MODE] = {\n #include \"machmode.def\"\n };\n \n@@ -147,7 +147,7 @@ const int mode_size[(int) MAX_MACHINE_MODE] = {\n \n #define DEF_MACHMODE(SYM, NAME, CLASS, SIZE, UNIT, WIDER)  UNIT,\n \n-const int mode_unit_size[(int) MAX_MACHINE_MODE] = {\n+const unsigned int mode_unit_size[(int) MAX_MACHINE_MODE] = {\n #include \"machmode.def\"\t\t/* machine modes are documented here */\n };\n "}, {"sha": "cadc5060447c09801065899cf699eb40e2aea7c3", "filename": "gcc/rtl.h", "status": "modified", "additions": 31, "deletions": 19, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -87,6 +87,7 @@ typedef union rtunion_def\n {\n   HOST_WIDE_INT rtwint;\n   int rtint;\n+  unsigned int rtuint;\n   const char *rtstr;\n   struct rtx_def *rtx;\n   struct rtvec_def *rtvec;\n@@ -338,6 +339,7 @@ extern void rtvec_check_failed_bounds PARAMS ((rtvec, int,\n \n #define XCWINT(RTX, N, C)     (RTL_CHECKC1(RTX, N, C).rtwint)\n #define XCINT(RTX, N, C)      (RTL_CHECKC1(RTX, N, C).rtint)\n+#define XCUINT(RTX, N, C)     (RTL_CHECKC1(RTX, N, C).rtuint)\n #define XCSTR(RTX, N, C)      (RTL_CHECKC1(RTX, N, C).rtstr)\n #define XCEXP(RTX, N, C)      (RTL_CHECKC1(RTX, N, C).rtx)\n #define XCVEC(RTX, N, C)      (RTL_CHECKC1(RTX, N, C).rtvec)\n@@ -613,7 +615,7 @@ extern const char * const note_insn_name[];\n #define LABEL_ALTERNATE_NAME(RTX) XCSTR(RTX, 7, CODE_LABEL)\n \n /* The original regno this ADDRESSOF was built for.  */\n-#define ADDRESSOF_REGNO(RTX) XCINT(RTX, 1, ADDRESSOF)\n+#define ADDRESSOF_REGNO(RTX) XCUINT(RTX, 1, ADDRESSOF)\n \n /* The variable in the register we took the address of.  */\n #define ADDRESSOF_DECL(RTX) XCTREE(RTX, 2, ADDRESSOF)\n@@ -642,7 +644,7 @@ extern const char * const note_insn_name[];\n \n /* For a REG rtx, REGNO extracts the register number.  */\n \n-#define REGNO(RTX) XCINT(RTX, 0, REG)\n+#define REGNO(RTX) XCUINT(RTX, 0, REG)\n \n /* For a REG rtx, REG_FUNCTION_VALUE_P is nonzero if the reg\n    is the current function's return value.  */\n@@ -660,7 +662,7 @@ extern const char * const note_insn_name[];\n    SUBREG_WORD extracts the word-number.  */\n \n #define SUBREG_REG(RTX) XCEXP(RTX, 0, SUBREG)\n-#define SUBREG_WORD(RTX) XCINT(RTX, 1, SUBREG)\n+#define SUBREG_WORD(RTX) XCUINT(RTX, 1, SUBREG)\n \n /* 1 if the REG contained in SUBREG_REG is already known to be\n    sign- or zero-extended from the mode of the SUBREG to the mode of\n@@ -999,8 +1001,10 @@ extern rtx gen_lowpart_if_possible\tPARAMS ((enum machine_mode, rtx));\n extern rtx gen_highpart\t\t\tPARAMS ((enum machine_mode, rtx));\n extern rtx gen_realpart\t\t\tPARAMS ((enum machine_mode, rtx));\n extern rtx gen_imagpart\t\t\tPARAMS ((enum machine_mode, rtx));\n-extern rtx operand_subword\t\tPARAMS ((rtx, int, int, enum machine_mode));\n-extern rtx operand_subword_force\tPARAMS ((rtx, int, enum machine_mode));\n+extern rtx operand_subword\t\tPARAMS ((rtx, unsigned int, int,\n+\t\t\t\t\t\t enum machine_mode));\n+extern rtx operand_subword_force\tPARAMS ((rtx, unsigned int,\n+\t\t\t\t\t\t enum machine_mode));\n extern int subreg_lowpart_p\t\tPARAMS ((rtx));\n extern rtx make_safe_from\t\tPARAMS ((rtx, rtx));\n extern rtx convert_memory_address\tPARAMS ((enum machine_mode, rtx));\n@@ -1101,8 +1105,10 @@ extern rtx gen_bge\t\t\tPARAMS ((rtx));\n extern rtx gen_ble\t\t\tPARAMS ((rtx));\n extern rtx gen_mem_addressof\t\tPARAMS ((rtx, union tree_node *));\n extern rtx eliminate_constant_term\tPARAMS ((rtx, rtx *));\n-extern rtx expand_complex_abs\t\tPARAMS ((enum machine_mode, rtx, rtx, int));\n-extern enum machine_mode choose_hard_reg_mode PARAMS ((int, int));\n+extern rtx expand_complex_abs\t\tPARAMS ((enum machine_mode, rtx, rtx,\n+\t\t\t\t\t\t int));\n+extern enum machine_mode choose_hard_reg_mode PARAMS ((unsigned int,\n+\t\t\t\t\t\t       unsigned int));\n extern void set_unique_reg_note         PARAMS ((rtx, enum reg_note, rtx));\n \n /* Functions in rtlanal.c */\n@@ -1126,28 +1132,34 @@ extern int reg_set_p\t\t\tPARAMS ((rtx, rtx));\n extern rtx single_set\t\t\tPARAMS ((rtx));\n extern int multiple_sets\t\tPARAMS ((rtx));\n extern rtx find_last_value\t\tPARAMS ((rtx, rtx *, rtx, int));\n-extern int refers_to_regno_p\t\tPARAMS ((int, int, rtx, rtx *));\n+extern int refers_to_regno_p\t\tPARAMS ((unsigned int, unsigned int,\n+\t\t\t\t\t\t rtx, rtx *));\n extern int reg_overlap_mentioned_p\tPARAMS ((rtx, rtx));\n-extern void note_stores\t\t\tPARAMS ((rtx, void (*)(rtx, rtx, void *), void *));\n+extern void note_stores\t\t\tPARAMS ((rtx,\n+\t\t\t\t\t\t void (*) (rtx, rtx, void *),\n+\t\t\t\t\t\t void *));\n extern rtx reg_set_last\t\t\tPARAMS ((rtx, rtx));\n extern int dead_or_set_p\t\tPARAMS ((rtx, rtx));\n-extern int dead_or_set_regno_p\t\tPARAMS ((rtx, int));\n+extern int dead_or_set_regno_p\t\tPARAMS ((rtx, unsigned int));\n extern rtx find_reg_note\t\tPARAMS ((rtx, enum reg_note, rtx));\n-extern rtx find_regno_note\t\tPARAMS ((rtx, enum reg_note, int));\n+extern rtx find_regno_note\t\tPARAMS ((rtx, enum reg_note,\n+\t\t\t\t\t\t unsigned int));\n extern int find_reg_fusage\t\tPARAMS ((rtx, enum rtx_code, rtx));\n-extern int find_regno_fusage\t\tPARAMS ((rtx, enum rtx_code, int));\n+extern int find_regno_fusage\t\tPARAMS ((rtx, enum rtx_code,\n+\t\t\t\t\t\t unsigned int));\n extern void remove_note\t\t\tPARAMS ((rtx, rtx));\n extern int side_effects_p\t\tPARAMS ((rtx));\n extern int volatile_refs_p\t\tPARAMS ((rtx));\n extern int volatile_insn_p\t\tPARAMS ((rtx));\n extern int may_trap_p\t\t\tPARAMS ((rtx));\n extern int inequality_comparisons_p\tPARAMS ((rtx));\n extern rtx replace_rtx\t\t\tPARAMS ((rtx, rtx, rtx));\n-extern rtx replace_regs\t\t\tPARAMS ((rtx, rtx *, int, int));\n+extern rtx replace_regs\t\t\tPARAMS ((rtx, rtx *, unsigned int,\n+\t\t\t\t\t\t int));\n extern int computed_jump_p\t\tPARAMS ((rtx));\n typedef int (*rtx_function)             PARAMS ((rtx *, void *));\n extern int for_each_rtx                 PARAMS ((rtx *, rtx_function, void *));\n-extern rtx regno_use_in\t\t\tPARAMS ((int, rtx));\n+extern rtx regno_use_in\t\t\tPARAMS ((unsigned int, rtx));\n extern int auto_inc_p\t\t\tPARAMS ((rtx));\n extern void remove_node_from_expr_list\tPARAMS ((rtx, rtx *));\n extern int insns_safe_to_move_p         PARAMS ((rtx, rtx, rtx *));\n@@ -1486,9 +1498,9 @@ extern void remove_unncessary_notes             PARAMS ((void));\n extern void add_clobbers\t\tPARAMS ((rtx, int));\n \n /* In combine.c */\n-extern int combine_instructions\tPARAMS ((rtx, int));\n-extern int extended_count\t\tPARAMS ((rtx, enum machine_mode, int));\n-extern rtx remove_death\t\t\tPARAMS ((int, rtx));\n+extern int combine_instructions\t\tPARAMS ((rtx, unsigned int));\n+extern unsigned int extended_count\tPARAMS ((rtx, enum machine_mode, int));\n+extern rtx remove_death\t\t\tPARAMS ((unsigned int, rtx));\n #ifdef BUFSIZ\n extern void dump_combine_stats\t\tPARAMS ((FILE *));\n extern void dump_combine_total_stats\tPARAMS ((FILE *));\n@@ -1585,8 +1597,8 @@ extern void init_reg_sets\t\tPARAMS ((void));\n extern void regset_release_memory\tPARAMS ((void));\n extern void regclass_init\t\tPARAMS ((void));\n extern void regclass\t\t\tPARAMS ((rtx, int, FILE *));\n-extern void reg_scan\t\t\tPARAMS ((rtx, int, int));\n-extern void reg_scan_update\t\tPARAMS ((rtx, rtx, int));\n+extern void reg_scan\t\t\tPARAMS ((rtx, unsigned int, int));\n+extern void reg_scan_update\t\tPARAMS ((rtx, rtx, unsigned int));\n extern void fix_register\t\tPARAMS ((const char *, int, int));\n \n extern void delete_null_pointer_checks\tPARAMS ((rtx));"}, {"sha": "b44b9921d6acfcacd0d08b1a8515f5d977000d2a", "filename": "gcc/rtlanal.c", "status": "modified", "additions": 32, "deletions": 29, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Frtlanal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Frtlanal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlanal.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -824,13 +824,14 @@ find_last_value (x, pinsn, valid_to, allow_hwreg)\n \n int\n refers_to_regno_p (regno, endregno, x, loc)\n-     int regno, endregno;\n+     unsigned int regno, endregno;\n      rtx x;\n      rtx *loc;\n {\n-  register int i;\n-  register RTX_CODE code;\n-  register const char *fmt;\n+  int i;\n+  unsigned int x_regno;\n+  RTX_CODE code;\n+  const char *fmt;\n \n  repeat:\n   /* The contents of a REG_NONNEG note is always zero, so we must come here\n@@ -843,22 +844,22 @@ refers_to_regno_p (regno, endregno, x, loc)\n   switch (code)\n     {\n     case REG:\n-      i = REGNO (x);\n+      x_regno = REGNO (x);\n \n       /* If we modifying the stack, frame, or argument pointer, it will\n \t clobber a virtual register.  In fact, we could be more precise,\n \t but it isn't worth it.  */\n-      if ((i == STACK_POINTER_REGNUM\n+      if ((x_regno == STACK_POINTER_REGNUM\n #if FRAME_POINTER_REGNUM != ARG_POINTER_REGNUM\n-\t   || i == ARG_POINTER_REGNUM\n+\t   || x_regno == ARG_POINTER_REGNUM\n #endif\n-\t   || i == FRAME_POINTER_REGNUM)\n+\t   || x_regno == FRAME_POINTER_REGNUM)\n \t  && regno >= FIRST_VIRTUAL_REGISTER && regno <= LAST_VIRTUAL_REGISTER)\n \treturn 1;\n \n-      return (endregno > i\n-\t      && regno < i + (i < FIRST_PSEUDO_REGISTER \n-\t\t\t      ? HARD_REGNO_NREGS (i, GET_MODE (x))\n+      return (endregno > x_regno\n+\t      && regno < x_regno + (x_regno < FIRST_PSEUDO_REGISTER \n+\t\t\t\t    ? HARD_REGNO_NREGS (x_regno, GET_MODE (x))\n \t\t\t      : 1));\n \n     case SUBREG:\n@@ -867,8 +868,8 @@ refers_to_regno_p (regno, endregno, x, loc)\n       if (GET_CODE (SUBREG_REG (x)) == REG\n \t  && REGNO (SUBREG_REG (x)) < FIRST_PSEUDO_REGISTER)\n \t{\n-\t  int inner_regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n-\t  int inner_endregno\n+\t  unsigned int inner_regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n+\t  unsigned int inner_endregno\n \t    = inner_regno + (inner_regno < FIRST_PSEUDO_REGISTER\n \t\t\t     ? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n \n@@ -939,7 +940,7 @@ int\n reg_overlap_mentioned_p (x, in)\n      rtx x, in;\n {\n-  int regno, endregno;\n+  unsigned int regno, endregno;\n \n   /* Overly conservative.  */\n   if (GET_CODE (x) == STRICT_LOW_PART)\n@@ -1000,7 +1001,7 @@ reg_overlap_mentioned_p (x, in)\n \n static int reg_set_last_unknown;\n static rtx reg_set_last_value;\n-static int reg_set_last_first_regno, reg_set_last_last_regno;\n+static unsigned int reg_set_last_first_regno, reg_set_last_last_regno;\n \n /* Called via note_stores from reg_set_last.  */\n \n@@ -1010,7 +1011,7 @@ reg_set_last_1 (x, pat, data)\n      rtx pat;\n      void *data ATTRIBUTE_UNUSED;\n {\n-  int first, last;\n+  unsigned int first, last;\n \n   /* If X is not a register, or is not one in the range we care\n      about, ignore.  */\n@@ -1149,6 +1150,7 @@ note_stores (x, fun, data)\n \t\t  && GET_MODE (dest) == BLKmode)\n \t\t{\n \t\t  register int i;\n+\n \t\t  for (i = XVECLEN (dest, 0) - 1; i >= 0; i--)\n \t\t    (*fun) (SET_DEST (XVECEXP (dest, 0, i)), y, data);\n \t\t}\n@@ -1181,8 +1183,8 @@ dead_or_set_p (insn, x)\n      rtx insn;\n      rtx x;\n {\n-  register int regno, last_regno;\n-  register int i;\n+  unsigned int regno, last_regno;\n+  unsigned int i;\n \n   /* Can't use cc0_rtx below since this file is used by genattrtab.c.  */\n   if (GET_CODE (x) == CC0)\n@@ -1208,9 +1210,9 @@ dead_or_set_p (insn, x)\n int\n dead_or_set_regno_p (insn, test_regno)\n      rtx insn;\n-     int test_regno;\n+     unsigned int test_regno;\n {\n-  int regno, endregno;\n+  unsigned int regno, endregno;\n   rtx link;\n \n   /* See if there is a death note for something that includes\n@@ -1323,7 +1325,7 @@ rtx\n find_regno_note (insn, kind, regno)\n      rtx insn;\n      enum reg_note kind;\n-     int regno;\n+     unsigned int regno;\n {\n   register rtx link;\n \n@@ -1376,15 +1378,16 @@ find_reg_fusage (insn, code, datum)\n     }\n   else\n     {\n-      register int regno = REGNO (datum);\n+      unsigned int regno = REGNO (datum);\n \n       /* CALL_INSN_FUNCTION_USAGE information cannot contain references\n \t to pseudo registers, so don't bother checking.  */\n \n       if (regno < FIRST_PSEUDO_REGISTER)\n         {\n-\t  int end_regno = regno + HARD_REGNO_NREGS (regno, GET_MODE (datum));\n-\t  int i;\n+\t  unsigned int end_regno\n+\t    = regno + HARD_REGNO_NREGS (regno, GET_MODE (datum));\n+\t  unsigned int i;\n \n \t  for (i = regno; i < end_regno; i++)\n \t    if (find_regno_fusage (insn, code, i))\n@@ -1402,7 +1405,7 @@ int\n find_regno_fusage (insn, code, regno)\n      rtx insn;\n      enum rtx_code code;\n-     int regno;\n+     unsigned int regno;\n {\n   register rtx link;\n \n@@ -1415,8 +1418,8 @@ find_regno_fusage (insn, code, regno)\n \n   for (link = CALL_INSN_FUNCTION_USAGE (insn); link; link = XEXP (link, 1))\n     {\n-      register int regnote;\n-      register rtx op, reg;\n+      unsigned int regnote;\n+      rtx op, reg;\n \n       if (GET_CODE (op = XEXP (link, 0)) == code\n \t  && GET_CODE (reg = XEXP (op, 0)) == REG\n@@ -1889,7 +1892,7 @@ rtx\n replace_regs (x, reg_map, nregs, replace_dest)\n      rtx x;\n      rtx *reg_map;\n-     int nregs;\n+     unsigned int nregs;\n      int replace_dest;\n {\n   register enum rtx_code code;\n@@ -2165,7 +2168,7 @@ for_each_rtx (x, f, data)\n \n rtx\n regno_use_in (regno, x)\n-     int regno;\n+     unsigned int regno;\n      rtx x;\n {\n   register const char *fmt;"}, {"sha": "6433c67a2a15c6d0149f3d6a2794e04d37e095d5", "filename": "gcc/sdbout.c", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fsdbout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fsdbout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsdbout.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1358,7 +1358,6 @@ sdbout_parms (parms)\n \t      current_sym_value = 0;\n \n \t    if (GET_CODE (DECL_RTL (parms)) == REG\n-\t\t&& REGNO (DECL_RTL (parms)) >= 0\n \t\t&& REGNO (DECL_RTL (parms)) < FIRST_PSEUDO_REGISTER)\n \t      type = DECL_ARG_TYPE (parms);\n \t    else\n@@ -1406,8 +1405,7 @@ sdbout_parms (parms)\n \t       pretend the parm was passed there.  It would be more consistent\n \t       to describe the register where the parm was passed,\n \t       but in practice that register usually holds something else.  */\n-\t    if (REGNO (DECL_RTL (parms)) >= 0\n-\t\t&& REGNO (DECL_RTL (parms)) < FIRST_PSEUDO_REGISTER)\n+\t    if (REGNO (DECL_RTL (parms)) < FIRST_PSEUDO_REGISTER)\n \t      best_rtl = DECL_RTL (parms);\n \t    /* If the parm lives nowhere,\n \t       use the register where it was passed.  */\n@@ -1469,7 +1467,6 @@ sdbout_reg_parms (parms)\n \t/* Report parms that live in registers during the function\n \t   but were passed in memory.  */\n \tif (GET_CODE (DECL_RTL (parms)) == REG\n-\t    && REGNO (DECL_RTL (parms)) >= 0\n \t    && REGNO (DECL_RTL (parms)) < FIRST_PSEUDO_REGISTER\n \t    && PARM_PASSED_IN_MEMORY (parms))\n \t  {"}, {"sha": "22549b4fe69bf93f40d875c8bee8e163da8db581", "filename": "gcc/simplify-rtx.c", "status": "modified", "additions": 20, "deletions": 11, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -149,7 +149,7 @@ simplify_unary_operation (code, mode, op, op_mode)\n      rtx op;\n      enum machine_mode op_mode;\n {\n-  register int width = GET_MODE_BITSIZE (mode);\n+  unsigned int width = GET_MODE_BITSIZE (mode);\n \n   /* The order of these tests is critical so that, for example, we don't\n      check the wrong mode (input vs. output) for a conversion operation,\n@@ -550,7 +550,7 @@ simplify_binary_operation (code, mode, op0, op1)\n {\n   register HOST_WIDE_INT arg0, arg1, arg0s, arg1s;\n   HOST_WIDE_INT val;\n-  int width = GET_MODE_BITSIZE (mode);\n+  unsigned int width = GET_MODE_BITSIZE (mode);\n   rtx tem;\n \n   /* Relational operations don't work here.  We must know the mode\n@@ -1975,16 +1975,20 @@ static int discard_useless_locs\t\tPARAMS ((void **, void *));\n static int discard_useless_values\tPARAMS ((void **, void *));\n static void remove_useless_values\tPARAMS ((void));\n static unsigned int hash_rtx\t\tPARAMS ((rtx, enum machine_mode, int));\n-static cselib_val *new_cselib_val\tPARAMS ((unsigned int, enum machine_mode));\n-static void add_mem_for_addr\t\tPARAMS ((cselib_val *, cselib_val *, rtx));\n+static cselib_val *new_cselib_val\tPARAMS ((unsigned int,\n+\t\t\t\t\t\t enum machine_mode));\n+static void add_mem_for_addr\t\tPARAMS ((cselib_val *, cselib_val *,\n+\t\t\t\t\t\t rtx));\n static cselib_val *cselib_lookup_mem\tPARAMS ((rtx, int));\n static rtx cselib_subst_to_values\tPARAMS ((rtx));\n-static void cselib_invalidate_regno\tPARAMS ((int, enum machine_mode));\n+static void cselib_invalidate_regno\tPARAMS ((unsigned int,\n+\t\t\t\t\t\t enum machine_mode));\n static int cselib_mem_conflict_p\tPARAMS ((rtx, rtx));\n static int cselib_invalidate_mem_1\tPARAMS ((void **, void *));\n static void cselib_invalidate_mem\tPARAMS ((rtx));\n static void cselib_invalidate_rtx\tPARAMS ((rtx, rtx, void *));\n-static void cselib_record_set\t\tPARAMS ((rtx, cselib_val *, cselib_val *));\n+static void cselib_record_set\t\tPARAMS ((rtx, cselib_val *,\n+\t\t\t\t\t\t cselib_val *));\n static void cselib_record_sets\t\tPARAMS ((rtx));\n \n /* There are three ways in which cselib can look up an rtx:\n@@ -2779,13 +2783,14 @@ cselib_lookup (x, mode, create)\n    is used to determine how many hard registers are being changed.  If MODE\n    is VOIDmode, then only REGNO is being changed; this is used when\n    invalidating call clobbered registers across a call.  */\n+\n static void\n cselib_invalidate_regno (regno, mode)\n-     int regno;\n+     unsigned int regno;\n      enum machine_mode mode;\n {\n-  int endregno;\n-  int i;\n+  unsigned int endregno;\n+  unsigned int i;\n \n   /* If we see pseudos after reload, something is _wrong_.  */\n   if (reload_completed && regno >= FIRST_PSEUDO_REGISTER\n@@ -2810,15 +2815,17 @@ cselib_invalidate_regno (regno, mode)\n \t{\n \t  cselib_val *v = (*l)->elt;\n \t  struct elt_loc_list **p;\n-\t  int this_last = i;\n+\t  unsigned int this_last = i;\n \n \t  if (i < FIRST_PSEUDO_REGISTER)\n \t    this_last += HARD_REGNO_NREGS (i, GET_MODE (v->u.val_rtx)) - 1;\n+\n \t  if (this_last < regno)\n \t    {\n \t      l = &(*l)->next;\n \t      continue;\n \t    }\n+\n \t  /* We have an overlap.  */\n \t  unchain_one_elt_list (l);\n \n@@ -2827,6 +2834,7 @@ cselib_invalidate_regno (regno, mode)\n \t  for (p = &v->locs; ; p = &(*p)->next)\n \t    {\n \t      rtx x = (*p)->loc;\n+\n \t      if (GET_CODE (x) == REG && REGNO (x) == i)\n \t\t{\n \t\t  unchain_one_elt_loc_list (p);\n@@ -2986,12 +2994,13 @@ cselib_invalidate_rtx (dest, ignore, data)\n /* Record the result of a SET instruction.  DEST is being set; the source\n    contains the value described by SRC_ELT.  If DEST is a MEM, DEST_ADDR_ELT\n    describes its address.  */\n+\n static void\n cselib_record_set (dest, src_elt, dest_addr_elt)\n      rtx dest;\n      cselib_val *src_elt, *dest_addr_elt;\n {\n-  int dreg = GET_CODE (dest) == REG ? REGNO (dest) : -1;\n+  int dreg = GET_CODE (dest) == REG ? (int) REGNO (dest) : -1;\n \n   if (src_elt == 0 || side_effects_p (dest))\n     return;"}, {"sha": "26ed50ea8fb3a81e07f28039057944741673a8c3", "filename": "gcc/ssa.c", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fssa.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1,22 +1,22 @@\n /* Static Single Assignment conversion routines for the GNU compiler.\n    Copyright (C) 2000 Free Software Foundation, Inc.\n \n-   This file is part of GNU CC.\n+This file is part of GNU CC.\n \n-   GNU CC is free software; you can redistribute it and/or modify\n-   it under the terms of the GNU General Public License as published by\n-   the Free Software Foundation; either version 2, or (at your option)\n-   any later version.\n+GNU CC is free software; you can redistribute it and/or modify it\n+under the terms of the GNU General Public License as published by the\n+Free Software Foundation; either version 2, or (at your option) any\n+later version.\n \n-   GNU CC is distributed in the hope that it will be useful,\n-   but WITHOUT ANY WARRANTY; without even the implied warranty of\n-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n-   GNU General Public License for more details.\n+GNU CC is distributed in the hope that it will be useful, but WITHOUT\n+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n \n-   You should have received a copy of the GNU General Public License\n-   along with GNU CC; see the file COPYING.  If not, write to\n-   the Free Software Foundation, 59 Temple Place - Suite 330,\n-   Boston, MA 02111-1307, USA.  */\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n \n /* References:\n \n@@ -73,7 +73,7 @@ varray_type ssa_rename_from;\n static rtx *ssa_rename_to;\n \n /* The number of registers that were live on entry to the SSA routines.  */\n-static int ssa_max_reg_num;\n+static unsigned int ssa_max_reg_num;\n \n /* Local function prototypes.  */\n \n@@ -689,7 +689,7 @@ rename_block (bb, idom)\n       while (PHI_NODE_P (insn))\n \t{\n \t  rtx phi = PATTERN (insn);\n-\t  int regno;\n+\t  unsigned int regno;\n \t  rtx reg;\n \n \t  /* Find out which of our outgoing registers this node is"}, {"sha": "0bcae698bcf0436c882ed7779f1d8485c1bd1277", "filename": "gcc/stmt.c", "status": "modified", "additions": 54, "deletions": 62, "changes": 116, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fstmt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fstmt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstmt.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -2952,12 +2952,14 @@ expand_return (retval)\n       && TYPE_MODE (TREE_TYPE (retval_rhs)) == BLKmode\n       && GET_CODE (result_rtl) == REG)\n     {\n-      int i, bitpos, xbitpos;\n-      int big_endian_correction = 0;\n-      int bytes = int_size_in_bytes (TREE_TYPE (retval_rhs));\n+      int i;\n+      unsigned HOST_WIDE_INT bitpos, xbitpos;\n+      unsigned HOST_WIDE_INT big_endian_correction = 0;\n+      unsigned HOST_WIDE_INT bytes\n+\t= int_size_in_bytes (TREE_TYPE (retval_rhs));\n       int n_regs = (bytes + UNITS_PER_WORD - 1) / UNITS_PER_WORD;\n-      int bitsize = MIN (TYPE_ALIGN (TREE_TYPE (retval_rhs)),\n-\t\t\t (unsigned int)BITS_PER_WORD);\n+      unsigned int bitsize\n+\t= MIN (TYPE_ALIGN (TREE_TYPE (retval_rhs)), BITS_PER_WORD);\n       rtx *result_pseudos = (rtx *) alloca (sizeof (rtx) * n_regs);\n       rtx result_reg, src = NULL_RTX, dst = NULL_RTX;\n       rtx result_val = expand_expr (retval_rhs, NULL_RTX, VOIDmode, 0);\n@@ -4905,8 +4907,8 @@ add_case_node (low, high, label, duplicate)\n \n \f\n /* Returns the number of possible values of TYPE.\n-   Returns -1 if the number is unknown or variable.\n-   Returns -2 if the number does not fit in a HOST_WIDE_INT.\n+   Returns -1 if the number is unknown, variable, or if the number does not\n+   fit in a HOST_WIDE_INT.\n    Sets *SPARENESS to 2 if TYPE is an ENUMERAL_TYPE whose values\n    do not increase monotonically (there may be duplicates);\n    to 1 if the values increase monotonically, but not always by 1;\n@@ -4917,73 +4919,60 @@ all_cases_count (type, spareness)\n      tree type;\n      int *spareness;\n {\n-  HOST_WIDE_INT count;\n+  tree t;\n+  HOST_WIDE_INT count, minval, lastval;\n+\n   *spareness = 0;\n \n   switch (TREE_CODE (type))\n     {\n-      tree t;\n     case BOOLEAN_TYPE:\n       count = 2;\n       break;\n+\n     case CHAR_TYPE:\n       count = 1 << BITS_PER_UNIT;\n       break;\n+\n     default:\n     case INTEGER_TYPE:\n-      if (TREE_CODE (TYPE_MIN_VALUE (type)) != INTEGER_CST\n-\t  || TYPE_MAX_VALUE (type) == NULL\n-\t  || TREE_CODE (TYPE_MAX_VALUE (type)) != INTEGER_CST)\n-\treturn -1;\n+      if (TYPE_MAX_VALUE (type) != 0\n+\t  && 0 != (t = fold (build (MINUS_EXPR, type, TYPE_MAX_VALUE (type),\n+\t\t\t\t    TYPE_MIN_VALUE (type))))\n+\t  && 0 != (t = fold (build (PLUS_EXPR, type, t,\n+\t\t\t\t    convert (type, integer_zero_node))))\n+\t  && host_integerp (t, 1))\n+\tcount = tree_low_cst (t, 1);\n       else\n-\t{\n-\t  /* count\n-\t     = TREE_INT_CST_LOW (TYPE_MAX_VALUE (type))\n-\t     - TREE_INT_CST_LOW (TYPE_MIN_VALUE (type)) + 1\n-\t     but with overflow checking.  */\n-\t  tree mint = TYPE_MIN_VALUE (type);\n-\t  tree maxt = TYPE_MAX_VALUE (type);\n-\t  HOST_WIDE_INT lo, hi;\n-\t  neg_double(TREE_INT_CST_LOW (mint), TREE_INT_CST_HIGH (mint),\n-\t\t     &lo, &hi);\n-\t  add_double(TREE_INT_CST_LOW (maxt), TREE_INT_CST_HIGH (maxt),\n-\t\t     lo, hi, &lo, &hi);\n-\t  add_double (lo, hi, 1, 0, &lo, &hi);\n-\t  if (hi != 0 || lo < 0)\n-\t    return -2;\n-\t  count = lo;\n-\t}\n+\treturn -1;\n       break;\n+\n     case ENUMERAL_TYPE:\n+      /* Don't waste time with enumeral types with huge values.  */\n+      if (! host_integerp (TYPE_MIN_VALUE (type), 0)\n+\t  || TYPE_MAX_VALUE (type) == 0\n+\t  || ! host_integerp (TYPE_MAX_VALUE (type), 0))\n+\treturn -1;\n+\n+      lastval = minval = tree_low_cst (TYPE_MIN_VALUE (type), 0);\n       count = 0;\n+\n       for (t = TYPE_VALUES (type); t != NULL_TREE; t = TREE_CHAIN (t))\n \t{\n-\t  if (TREE_CODE (TYPE_MIN_VALUE (type)) != INTEGER_CST\n-\t      || TREE_CODE (TREE_VALUE (t)) != INTEGER_CST\n-\t      || (TREE_INT_CST_LOW (TYPE_MIN_VALUE (type)) + count\n-\t\t  != TREE_INT_CST_LOW (TREE_VALUE (t))))\n+\t  HOST_WIDE_INT thisval = tree_low_cst (TREE_VALUE (t), 0);\n+\n+\t  if (*spareness == 2 || thisval < lastval)\n+\t    *spareness = 2;\n+\t  else if (thisval != minval + count)\n \t    *spareness = 1;\n+\n \t  count++;\n \t}\n-      if (*spareness == 1)\n-\t{\n-\t  tree prev = TREE_VALUE (TYPE_VALUES (type));\n-\t  for (t = TYPE_VALUES (type); t = TREE_CHAIN (t), t != NULL_TREE; )\n-\t    {\n-\t      if (! tree_int_cst_lt (prev, TREE_VALUE (t)))\n-\t\t{\n-\t\t  *spareness = 2;\n-\t\t  break;\n-\t\t}\n-\t      prev = TREE_VALUE (t);\n-\t    }\n-\t  \n-\t}\n     }\n+\n   return count;\n }\n \n-\n #define BITARRAY_TEST(ARRAY, INDEX) \\\n   ((ARRAY)[(unsigned) (INDEX) / HOST_BITS_PER_CHAR]\\\n \t\t\t  & (1 << ((unsigned) (INDEX) % HOST_BITS_PER_CHAR)))\n@@ -5003,21 +4992,22 @@ void\n mark_seen_cases (type, cases_seen, count, sparseness)\n      tree type;\n      unsigned char *cases_seen;\n-     long count;\n+     HOST_WIDE_INT count;\n      int sparseness;\n {\n   tree next_node_to_try = NULL_TREE;\n-  long next_node_offset = 0;\n+  HOST_WIDE_INT next_node_offset = 0;\n \n   register struct case_node *n, *root = case_stack->data.case_stmt.case_list;\n   tree val = make_node (INTEGER_CST);\n+\n   TREE_TYPE (val) = type;\n   if (! root)\n     ; /* Do nothing */\n   else if (sparseness == 2)\n     {\n       tree t;\n-      HOST_WIDE_INT xlo;\n+      unsigned HOST_WIDE_INT xlo;\n \n       /* This less efficient loop is only needed to handle\n \t duplicate case values (multiple enum constants\n@@ -5053,6 +5043,7 @@ mark_seen_cases (type, cases_seen, count, sparseness)\n     {\n       if (root->left)\n \tcase_stack->data.case_stmt.case_list = root = case_tree2list (root, 0);\n+\n       for (n = root; n; n = n->right)\n \t{\n \t  TREE_INT_CST_LOW (val) = TREE_INT_CST_LOW (n->low);\n@@ -5063,8 +5054,10 @@ mark_seen_cases (type, cases_seen, count, sparseness)\n \t\t The element with lowest value has offset 0, the next smallest\n \t\t element has offset 1, etc.  */\n \n-\t      HOST_WIDE_INT xlo, xhi;\n+\t      unsigned HOST_WIDE_INT xlo;\n+\t      HOST_WIDE_INT xhi;\n \t      tree t;\n+\n \t      if (sparseness && TYPE_VALUES (type) != NULL_TREE)\n \t\t{\n \t\t  /* The TYPE_VALUES will be in increasing order, so\n@@ -5107,8 +5100,9 @@ mark_seen_cases (type, cases_seen, count, sparseness)\n \t\t\t      &xlo, &xhi);\n \t\t}\n \t      \n-\t      if (xhi == 0 && xlo >= 0 && xlo < count)\n+\t      if (xhi == 0 && xlo < (unsigned HOST_WIDE_INT) count)\n \t\tBITARRAY_SET (cases_seen, xlo);\n+\n \t      add_double (TREE_INT_CST_LOW (val), TREE_INT_CST_HIGH (val),\n \t\t\t  1, 0,\n \t\t\t  &TREE_INT_CST_LOW (val), &TREE_INT_CST_HIGH (val));\n@@ -5150,7 +5144,7 @@ check_for_full_enumeration_handling (type)\n   unsigned char *cases_seen;\n \n   /* The allocated size of cases_seen, in chars.  */\n-  long bytes_needed;\n+  HOST_WIDE_INT bytes_needed;\n \n   if (! warn_switch)\n     return;\n@@ -5164,7 +5158,7 @@ check_for_full_enumeration_handling (type)\n \t aborting, as xmalloc would do.  */\n       && (cases_seen = (unsigned char *) calloc (bytes_needed, 1)) != NULL)\n     {\n-      long i;\n+      HOST_WIDE_INT i;\n       tree v = TYPE_VALUES (type);\n \n       /* The time complexity of this code is normally O(N), where\n@@ -5174,12 +5168,10 @@ check_for_full_enumeration_handling (type)\n \n       mark_seen_cases (type, cases_seen, size, sparseness);\n \n-      for (i = 0;  v != NULL_TREE && i < size; i++, v = TREE_CHAIN (v))\n-\t{\n-\t  if (BITARRAY_TEST(cases_seen, i) == 0)\n-\t    warning (\"enumeration value `%s' not handled in switch\",\n-\t\t     IDENTIFIER_POINTER (TREE_PURPOSE (v)));\n-\t}\n+      for (i = 0; v != NULL_TREE && i < size; i++, v = TREE_CHAIN (v))\n+\tif (BITARRAY_TEST(cases_seen, i) == 0)\n+\t  warning (\"enumeration value `%s' not handled in switch\",\n+\t\t   IDENTIFIER_POINTER (TREE_PURPOSE (v)));\n \n       free (cases_seen);\n     }"}, {"sha": "ada43a0ca847cde94ea079a8c9d4134f3b1991c1", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 388, "deletions": 353, "changes": 741, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -50,11 +50,10 @@ unsigned int maximum_field_alignment;\n    May be overridden by front-ends.  */\n unsigned int set_alignment = 0;\n \n-static void finalize_record_size PARAMS ((record_layout_info));\n-static void compute_record_mode PARAMS ((tree));\n-static void finalize_type_size PARAMS ((tree));\n-static void layout_union_field PARAMS ((record_layout_info, tree));\n-static void finish_union_layout PARAMS ((record_layout_info));\n+static void finalize_record_size\tPARAMS ((record_layout_info));\n+static void compute_record_mode\t\tPARAMS ((tree));\n+static void finalize_type_size\t\tPARAMS ((tree));\n+static void place_union_field\t\tPARAMS ((record_layout_info, tree));\n \f\n /* SAVE_EXPRs for sizes of types and decls, waiting to be expanded.  */\n \n@@ -65,6 +64,8 @@ static tree pending_sizes;\n \n int immediate_size_expand;\n \n+/* Get a list of all the objects put on the pending sizes list.  */\n+\n tree\n get_pending_sizes ()\n {\n@@ -79,6 +80,9 @@ get_pending_sizes ()\n   return chain;\n }\n \n+/* Put a chain of objects into the pending sizes list, which must be\n+   empty.  */\n+\n void\n put_pending_sizes (chain)\n      tree chain;\n@@ -131,8 +135,7 @@ variable_size (size)\n        Also, we would like to pass const0_rtx here, but don't have it.  */\n     expand_expr (size, expand_expr (integer_zero_node, NULL_PTR, VOIDmode, 0),\n \t\t VOIDmode, 0);\n-  else if (cfun != 0\n-\t   && cfun->x_dont_save_pending_sizes_p)\n+  else if (cfun != 0 && cfun->x_dont_save_pending_sizes_p)\n     /* The front-end doesn't want us to keep a list of the expressions\n        that determine sizes for variable size objects.  */\n     ;\n@@ -153,7 +156,7 @@ variable_size (size)\n \n enum machine_mode\n mode_for_size (size, class, limit)\n-     int size;\n+     unsigned int size;\n      enum mode_class class;\n      int limit;\n {\n@@ -194,7 +197,7 @@ mode_for_size_tree (size, class, limit)\n \n enum machine_mode\n smallest_mode_for_size (size, class)\n-     int size;\n+     unsigned int size;\n      enum mode_class class;\n {\n   register enum machine_mode mode;\n@@ -296,37 +299,37 @@ layout_decl (decl, known_align)\n   if (type == error_mark_node)\n     type = void_type_node;\n \n-  /* Usually the size and mode come from the data type without change.  */\n+  /* Usually the size and mode come from the data type without change,\n+     however, the front-end may set the explicit width of the field, so its\n+     size may not be the same as the size of its type.  This happens with\n+     bitfields, of course (an `int' bitfield may be only 2 bits, say), but it\n+     also happens with other fields.  For example, the C++ front-end creates\n+     zero-sized fields corresponding to empty base classes, and depends on\n+     layout_type setting DECL_FIELD_BITPOS correctly for the field.  Set the\n+     size in bytes from the size in bits.  */\n+\n   DECL_MODE (decl) = TYPE_MODE (type);\n   TREE_UNSIGNED (decl) = TREE_UNSIGNED (type);\n+\n   if (DECL_SIZE (decl) == 0)\n     {\n       DECL_SIZE (decl) = TYPE_SIZE (type);\n       DECL_SIZE_UNIT (decl) = TYPE_SIZE_UNIT (type);\n     }\n-  else if (code == FIELD_DECL)\n-    {\n-      HOST_WIDE_INT spec_size;\n-\n-      /* Size is specified in number of bits.  */\n-      spec_size = TREE_INT_CST_LOW (DECL_SIZE (decl));\n-      if (spec_size % BITS_PER_UNIT == 0)\n-\tDECL_SIZE_UNIT (decl) = size_int (spec_size / BITS_PER_UNIT);\n-      else\n-\tDECL_SIZE_UNIT (decl) = 0;\n-    }\n+  else\n+    DECL_SIZE_UNIT (decl)\n+      = convert (sizetype, size_binop (CEIL_DIV_EXPR, DECL_SIZE (decl),\n+\t\t\t\t       bitsize_unit_node));\n \n   /* Force alignment required for the data type.\n      But if the decl itself wants greater alignment, don't override that.\n      Likewise, if the decl is packed, don't override it.  */\n   if (!(code == FIELD_DECL && DECL_BIT_FIELD (decl))\n       && (DECL_ALIGN (decl) == 0\n-\t  || (! DECL_PACKED (decl) &&  TYPE_ALIGN (type) > DECL_ALIGN (decl))))\n+\t  || (! DECL_PACKED (decl) && TYPE_ALIGN (type) > DECL_ALIGN (decl))))\n     DECL_ALIGN (decl) = TYPE_ALIGN (type);\n \n-  /* See if we can use an ordinary integer mode for a bit-field. \n-     Conditions are: a fixed size that is correct for another mode\n-     and occupying a complete byte or bytes on proper boundary.  */\n+  /* For fields, set the bit field type and update the alignment.  */\n   if (code == FIELD_DECL)\n     {\n       DECL_BIT_FIELD_TYPE (decl) = DECL_BIT_FIELD (decl) ? type : 0;\n@@ -336,6 +339,9 @@ layout_decl (decl, known_align)\n \tDECL_ALIGN (decl) = MIN (DECL_ALIGN (decl), BITS_PER_UNIT);\n     }\n \n+  /* See if we can use an ordinary integer mode for a bit-field. \n+     Conditions are: a fixed size that is correct for another mode\n+     and occupying a complete byte or bytes on proper boundary.  */\n   if (DECL_BIT_FIELD (decl)\n       && TYPE_SIZE (type) != 0\n       && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST\n@@ -344,24 +350,21 @@ layout_decl (decl, known_align)\n       register enum machine_mode xmode\n \t= mode_for_size_tree (DECL_SIZE (decl), MODE_INT, 1);\n \n-      if (xmode != BLKmode\n-\t  && known_align % GET_MODE_ALIGNMENT (xmode) == 0)\n+      if (xmode != BLKmode && known_align > GET_MODE_ALIGNMENT (xmode))\n \t{\n \t  DECL_ALIGN (decl) = MAX (GET_MODE_ALIGNMENT (xmode),\n \t\t\t\t   DECL_ALIGN (decl));\n \t  DECL_MODE (decl) = xmode;\n-\t  DECL_SIZE (decl) = bitsize_int (GET_MODE_BITSIZE (xmode));\n-\t  DECL_SIZE_UNIT (decl) = size_int (GET_MODE_SIZE (xmode));\n-\t  /* This no longer needs to be accessed as a bit field.  */\n \t  DECL_BIT_FIELD (decl) = 0;\n \t}\n     }\n \n   /* Turn off DECL_BIT_FIELD if we won't need it set.  */\n-  if (DECL_BIT_FIELD (decl) && TYPE_MODE (type) == BLKmode\n-      && known_align % TYPE_ALIGN (type) == 0\n-      && DECL_SIZE_UNIT (decl) != 0\n-      && DECL_ALIGN (decl) >= TYPE_ALIGN (type))\n+  if (DECL_BIT_FIELD (decl)\n+      && TYPE_MODE (type) == BLKmode && DECL_MODE (decl) == BLKmode\n+      && known_align > TYPE_ALIGN (type)\n+      && DECL_ALIGN (decl) >= TYPE_ALIGN (type)\n+      && DECL_SIZE_UNIT (decl) != 0)\n     DECL_BIT_FIELD (decl) = 0;\n \n   /* Evaluate nonconstant size only once, either now or as soon as safe.  */\n@@ -392,54 +395,125 @@ layout_decl (decl, known_align)\n     }\n }\n \f\n-/* Create a new record_layout_info for T, which may be a RECORD_TYPE,\n-   UNION_TYPE, or QUAL_UNION_TYPE.  It is the responsibility of the\n-   caller to call `free' for the storage the returned.  */\n+/* Begin laying out type T, which may be a RECORD_TYPE, UNION_TYPE, or\n+   QUAL_UNION_TYPE.  Return a pointer to a struct record_layout_info which\n+   is to be passed to all other layout functions for this record.  It is the\n+   responsibility of the caller to call `free' for the storage returned. \n+   Note that garbage collection is not permitted until we finish laying\n+   out the record.  */\n \n record_layout_info\n-new_record_layout_info (t)\n+start_record_layout (t)\n      tree t;\n {\n   record_layout_info rli \n-    = (record_layout_info) xcalloc (1, sizeof (struct record_layout_info_s));\n+    = (record_layout_info) xmalloc (sizeof (struct record_layout_info));\n \n   rli->t = t;\n+\n   /* If the type has a minimum specified alignment (via an attribute\n      declaration, for example) use it -- otherwise, start with a\n      one-byte alignment.  */\n   rli->record_align = MAX (BITS_PER_UNIT, TYPE_ALIGN (t));\n   rli->unpacked_align = rli->record_align;\n+  rli->offset_align = MAX (rli->record_align, BIGGEST_ALIGNMENT);\n \n #ifdef STRUCTURE_SIZE_BOUNDARY\n   /* Packed structures don't need to have minimum size.  */\n   if (! TYPE_PACKED (t))\n     rli->record_align = MAX (rli->record_align, STRUCTURE_SIZE_BOUNDARY);\n #endif\n \n+  rli->offset = size_zero_node;\n+  rli->bitpos = bitsize_zero_node;\n+  rli->pending_statics = 0;\n+  rli->packed_maybe_necessary = 0;\n+\n   return rli;\n }\n \n-/* Like layout_field, but for unions.  */\n+/* Print debugging information about the information in RLI.  */\n \n-static void\n-layout_union_field (rli, field)\n+void\n+debug_rli (rli)\n      record_layout_info rli;\n-     tree field;\n {\n-  tree dsize;\n-      \n-  /* This function should only be used for unions; use layout_field\n-     for RECORD_TYPEs.  */\n-  if (TREE_CODE (rli->t) != UNION_TYPE\n-      && TREE_CODE (rli->t) != QUAL_UNION_TYPE)\n-    abort ();\n+  print_node_brief (stderr, \"type\", rli->t, 0);\n+  print_node_brief (stderr, \"\\noffset\", rli->offset, 0);\n+  print_node_brief (stderr, \" bitpos\", rli->bitpos, 0);\n \n-  /* By now, we should only be seeing FIELD_DECLs.  */\n-  if (TREE_CODE (field) != FIELD_DECL)\n-    abort ();\n+  fprintf (stderr, \"\\nrec_align = %u, unpack_align = %u, off_align = %u\\n\",\n+\t   rli->record_align, rli->unpacked_align, rli->offset_align);\n+  if (rli->packed_maybe_necessary)\n+    fprintf (stderr, \"packed may be necessary\\n\");\n+\n+  if (rli->pending_statics)\n+    {\n+      fprintf (stderr, \"pending statics:\\n\");\n+      debug_tree (rli->pending_statics);\n+    }\n+}\n+\n+/* Given an RLI with a possibly-incremented BITPOS, adjust OFFSET and\n+   BITPOS if necessary to keep BITPOS below OFFSET_ALIGN.  */\n+\n+void\n+normalize_rli (rli)\n+     record_layout_info rli;\n+{\n+  /* If the bit position is now larger than it should be, adjust it\n+     downwards.  */\n+  if (compare_tree_int (rli->bitpos, rli->offset_align) >= 0)\n+    {\n+      tree extra_aligns = size_binop (FLOOR_DIV_EXPR, rli->bitpos,\n+\t\t\t\t      bitsize_int (rli->offset_align));\n+\n+      rli->offset\n+\t= size_binop (PLUS_EXPR, rli->offset,\n+\t\t      size_binop (MULT_EXPR, convert (sizetype, extra_aligns),\n+\t\t\t\t  size_int (rli->offset_align\n+\t\t\t\t\t    / BITS_PER_UNIT)));\n+\t\t\t\t\n+      rli->bitpos = size_binop (FLOOR_MOD_EXPR, rli->bitpos,\n+\t\t\t\tbitsize_int (rli->offset_align));\n+    }\n+}\n \n+/* Returns the size in bytes allocated so far.  */\n+\n+tree\n+rli_size_unit_so_far (rli)\n+     record_layout_info rli;\n+{\n+  return size_binop (PLUS_EXPR, rli->offset,\n+\t\t     convert (sizetype,\n+\t\t\t      size_binop (CEIL_DIV_EXPR, rli->bitpos,\n+\t\t\t\t\t  bitsize_unit_node)));\n+}\n+\n+/* Returns the size in bits allocated so far.  */\n+\n+tree\n+rli_size_so_far (rli)\n+     record_layout_info rli;\n+{\n+  return size_binop (PLUS_EXPR, rli->bitpos,\n+\t\t     size_binop (MULT_EXPR, convert (bitsizetype, rli->offset),\n+\t\t\t\t bitsize_unit_node));\n+}\n+\n+/* Called from place_field to handle unions.  */\n+\n+static void\n+place_union_field (rli, field)\n+     record_layout_info rli;\n+     tree field;\n+{\n   layout_decl (field, 0);\n-  DECL_FIELD_BITPOS (field) = bitsize_int (0);\n+  \n+  DECL_FIELD_OFFSET (field) = size_zero_node;\n+  DECL_FIELD_BIT_OFFSET (field) = bitsize_zero_node;\n+  DECL_OFFSET_ALIGN (field) = BIGGEST_ALIGNMENT;\n \n   /* Union must be at least as aligned as any field requires.  */\n   rli->record_align = MAX (rli->record_align, DECL_ALIGN (field));\n@@ -452,30 +526,14 @@ layout_union_field (rli, field)\n \t\t\t     TYPE_ALIGN (TREE_TYPE (field)));\n #endif\n \n-  dsize = DECL_SIZE (field);\n+  /* We assume the union's size will be a multiple of a byte so we don't\n+     bother with BITPOS.  */\n   if (TREE_CODE (rli->t) == UNION_TYPE)\n-    {\n-      /* Set union_size to max (decl_size, union_size).  There are\n-\t more and less general ways to do this.  Use only CONST_SIZE\n-\t unless forced to use VAR_SIZE.  */\n-\n-      if (TREE_CODE (dsize) == INTEGER_CST\n-\t  && ! TREE_CONSTANT_OVERFLOW (dsize)\n-\t  && TREE_INT_CST_HIGH (dsize) == 0)\n-\trli->const_size\n-\t  = MAX (rli->const_size, TREE_INT_CST_LOW (dsize));\n-      else if (rli->var_size == 0)\n-\trli->var_size = dsize;\n-      else\n-\trli->var_size = size_binop (MAX_EXPR, rli->var_size, dsize);\n-    }\n+    rli->offset = size_binop (MAX_EXPR, rli->offset, DECL_SIZE_UNIT (field));\n   else if (TREE_CODE (rli->t) == QUAL_UNION_TYPE)\n-    rli->var_size = fold (build (COND_EXPR, bitsizetype, \n-\t\t\t\t DECL_QUALIFIER (field),\n-\t\t\t\t DECL_SIZE (field),\n-\t\t\t\t (rli->var_size\n-\t\t\t\t  ? rli->var_size \n-\t\t\t\t  : bitsize_int (0))));\n+    rli->offset = fold (build (COND_EXPR, sizetype, \n+\t\t\t       DECL_QUALIFIER (field),\n+\t\t\t       DECL_SIZE_UNIT (field), rli->offset));\n }\n \n /* RLI contains information about the layout of a RECORD_TYPE.  FIELD\n@@ -484,7 +542,7 @@ layout_union_field (rli, field)\n    callers that desire that behavior must manually perform that step.)  */\n \n void\n-layout_field (rli, field)\n+place_field (rli, field)\n      record_layout_info rli;\n      tree field;\n {\n@@ -493,11 +551,10 @@ layout_field (rli, field)\n   /* The alignment FIELD would have if we just dropped it into the\n      record as it presently stands.  */\n   unsigned int known_align;\n+  unsigned int actual_align;\n   /* The type of this field.  */\n   tree type = TREE_TYPE (field);\n-  /* The size of this field, in bits.  */\n-  tree dsize;\n-\n+ \n   /* If FIELD is static, then treat it like a separate variable, not\n      really like a structure field.  If it is a FUNCTION_DECL, it's a\n      method.  In both cases, all we do is lay out the decl, and we do\n@@ -508,29 +565,40 @@ layout_field (rli, field)\n \t\t\t\t\trli->pending_statics);\n       return;\n     }\n+\n   /* Enumerators and enum types which are local to this class need not\n      be laid out.  Likewise for initialized constant fields.  */\n   else if (TREE_CODE (field) != FIELD_DECL)\n     return;\n-  /* This function should only be used for records; use\n-     layout_union_field for unions.  */\n+\n+  /* Unions are laid out very differently than records, so split\n+     that code off to another function.  */\n   else if (TREE_CODE (rli->t) != RECORD_TYPE)\n     {\n-      layout_union_field (rli, field);\n+      place_union_field (rli, field);\n       return;\n     }\n \n-  /* Work out the known alignment so far.  */\n-  known_align = rli->var_size ? rli->var_align : rli->const_size;\n+  /* Work out the known alignment so far.  Note that A & (-A) is the\n+     value of the least-significant bit in A that is one.  */\n+  if (! integer_zerop (rli->bitpos) && TREE_CONSTANT (rli->offset))\n+    known_align = (tree_low_cst (rli->bitpos, 1)\n+\t\t   & - tree_low_cst (rli->bitpos, 1));\n+  else if (host_integerp (rli->offset, 1))\n+    known_align = (BITS_PER_UNIT\n+\t\t   * (tree_low_cst (rli->offset, 1)\n+\t\t      & - tree_low_cst (rli->offset, 1)));\n+  else\n+    known_align = rli->offset_align;\n \n   /* Lay out the field so we know what alignment it needs.  For a\n      packed field, use the alignment as specified, disregarding what\n      the type would want.  */\n-  if (DECL_PACKED (field))\n-    desired_align = DECL_ALIGN (field);\n+  desired_align = DECL_ALIGN (field);\n   layout_decl (field, known_align);\n   if (! DECL_PACKED (field))\n     desired_align = DECL_ALIGN (field);\n+\n   /* Some targets (i.e. VMS) limit struct field alignment\n      to a lower boundary than alignment of variables.  */\n #ifdef BIGGEST_FIELD_ALIGNMENT\n@@ -556,6 +624,7 @@ layout_field (rli, field)\n \trli->record_align = MAX (rli->record_align, desired_align);\n       else if (! DECL_PACKED (field))\n \tdesired_align = TYPE_ALIGN (type);\n+\n       /* A named bit field of declared type `int'\n \t forces the entire structure to have `int' alignment.  */\n       if (DECL_NAME (field) != 0)\n@@ -577,15 +646,12 @@ layout_field (rli, field)\n #endif\n     {\n       rli->record_align = MAX (rli->record_align, desired_align);\n-      if (warn_packed)\n-\trli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));\n+      rli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));\n     }\n \n   if (warn_packed && DECL_PACKED (field))\n     {\n-      if (rli->const_size % TYPE_ALIGN (type) == 0\n-\t  || (rli->var_align % TYPE_ALIGN (type) == 0 \n-\t      && rli->var_size != NULL_TREE))\n+      if (known_align > TYPE_ALIGN (type))\n \t{\n \t  if (TYPE_ALIGN (type) > desired_align)\n \t    {\n@@ -601,65 +667,80 @@ layout_field (rli, field)\n \n   /* Does this field automatically have alignment it needs by virtue\n      of the fields that precede it and the record's own alignment?  */\n-  if (rli->const_size % desired_align != 0\n-      || (rli->var_align % desired_align != 0 \n-\t  && rli->var_size != NULL_TREE))\n+  if (known_align < desired_align)\n     {\n       /* No, we need to skip space before this field.\n \t Bump the cumulative size to multiple of field alignment.  */\n \n       if (warn_padded)\n \twarning_with_decl (field, \"padding struct to align `%s'\");\n \n-      if (rli->var_size == NULL_TREE || rli->var_align % desired_align == 0)\n-\trli->const_size\n-\t  = CEIL (rli->const_size, desired_align) * desired_align;\n+      /* If the alignment is still within offset_align, just align\n+\t the bit position.  */\n+      if (desired_align < rli->offset_align)\n+\trli->bitpos = round_up (rli->bitpos, desired_align);\n       else\n \t{\n-\t  if (rli->const_size > 0)\n-\t    rli->var_size = size_binop (PLUS_EXPR, rli->var_size,\n-\t\t\t\t\tbitsize_int (rli->const_size));\n-\t  rli->const_size = 0;\n-\t  rli->var_size = round_up (rli->var_size, desired_align);\n-\t  rli->var_align = MIN (rli->var_align, desired_align);\n+\t  /* First adjust OFFSET by the partial bits, then align.  */\n+\t  rli->offset\n+\t    = size_binop (PLUS_EXPR, rli->offset,\n+\t\t\t  convert (sizetype,\n+\t\t\t\t   size_binop (CEIL_DIV_EXPR, rli->bitpos,\n+\t\t\t\t\t       bitsize_unit_node)));\n+\t  rli->bitpos = bitsize_zero_node;\n+\n+\t  rli->offset = round_up (rli->offset, desired_align / BITS_PER_UNIT);\n \t}\n+\n     }\n \n+  /* Handle compatibility with PCC.  Note that if the record has any\n+     variable-sized fields, we need not worry about compatibility.  */\n #ifdef PCC_BITFIELD_TYPE_MATTERS\n   if (PCC_BITFIELD_TYPE_MATTERS\n       && TREE_CODE (field) == FIELD_DECL\n       && type != error_mark_node\n-      && DECL_BIT_FIELD_TYPE (field)\n-      && !DECL_PACKED (field)\n+      && DECL_BIT_FIELD (field)\n+      && ! DECL_PACKED (field)\n       && maximum_field_alignment == 0\n-      && !integer_zerop (DECL_SIZE (field)))\n+      && ! integer_zerop (DECL_SIZE (field))\n+      && host_integerp (DECL_SIZE (field), 1)\n+      && host_integerp (rli->offset, 1)\n+      && host_integerp (TYPE_SIZE (type), 1))\n     {\n       unsigned int type_align = TYPE_ALIGN (type);\n-      register tree dsize = DECL_SIZE (field);\n-      unsigned int field_size = TREE_INT_CST_LOW (dsize);\n+      tree dsize = DECL_SIZE (field);\n+      HOST_WIDE_INT field_size = tree_low_cst (dsize, 1);\n+      HOST_WIDE_INT offset = tree_low_cst (rli->offset, 0);\n+      HOST_WIDE_INT bit_offset = tree_low_cst (rli->bitpos, 0);\n \n       /* A bit field may not span more units of alignment of its type\n \t than its type itself.  Advance to next boundary if necessary.  */\n-      if (((rli->const_size + field_size + type_align - 1) / type_align\n-\t   - rli->const_size / type_align)\n-\t  > TREE_INT_CST_LOW (TYPE_SIZE (TREE_TYPE (field))) / type_align)\n-\trli->const_size = CEIL (rli->const_size, type_align) * type_align;\n+      if ((((offset * BITS_PER_UNIT + bit_offset + field_size +\n+\t     type_align - 1)\n+\t    / type_align)\n+\t   - (offset * BITS_PER_UNIT + bit_offset) / type_align)\n+\t  > tree_low_cst (TYPE_SIZE (type), 1) / type_align)\n+\trli->bitpos = round_up (rli->bitpos, type_align);\n     }\n #endif\n \n-  /* No existing machine description uses this parameter.  So I have\n-     made it in this aspect identical to PCC_BITFIELD_TYPE_MATTERS.  */\n #ifdef BITFIELD_NBYTES_LIMITED\n   if (BITFIELD_NBYTES_LIMITED\n       && TREE_CODE (field) == FIELD_DECL\n       && type != error_mark_node\n       && DECL_BIT_FIELD_TYPE (field)\n-      && !DECL_PACKED (field)\n-      && !integer_zerop (DECL_SIZE (field)))\n+      && ! DECL_PACKED (field)\n+      && ! integer_zerop (DECL_SIZE (field))\n+      && host_integerp (DECL_SIZE (field), 1)\n+      && host_integerp (rli->size, 1)\n+      && host_integerp (TYPE_SIZE (type), 1))\n     {\n       unsigned int type_align = TYPE_ALIGN (type);\n-      register tree dsize = DECL_SIZE (field);\n-      int field_size = TREE_INT_CST_LOW (dsize);\n+      tree dsize = DECL_SIZE (field);\n+      HOST_WIDE_INT field_size = tree_low_cst (dsize, 1);\n+      HOST_WIDE_INT offset = tree_low_cst (rli->offset, 0);\n+      HOST_WIDE_INT bit_offset = tree_low_cst (rli->bitpos, 0);\n \n       if (maximum_field_alignment != 0)\n \ttype_align = MIN (type_align, maximum_field_alignment);\n@@ -672,51 +753,63 @@ layout_field (rli, field)\n \t Advance to next boundary if necessary.  */\n       /* ??? This code should match the code above for the\n \t PCC_BITFIELD_TYPE_MATTERS case.  */\n-      if (rli->const_size / type_align\n-\t  != (rli->const_size + field_size - 1) / type_align)\n-\trli->const_size = CEIL (rli->const_size, type_align) * type_align;\n+      if ((offset * BITS_PER_UNIT + bit_offset) / type_align\n+\t  != ((offset * BITS_PER_UNIT + bit_offset + field_size - 1)\n+\t      / type_align))\n+\trli->bitpos = round_up (rli->bitpos, type_align);\n     }\n #endif\n \n-  /* Size so far becomes the position of this field.  */\n-\n-  if (rli->var_size && rli->const_size)\n-    DECL_FIELD_BITPOS (field)\n-      = size_binop (PLUS_EXPR, rli->var_size, bitsize_int (rli->const_size));\n-  else if (rli->var_size)\n-    DECL_FIELD_BITPOS (field) = rli->var_size;\n+  if (! TREE_CONSTANT (rli->offset))\n+    rli->offset_align = DECL_ALIGN (field);\n+\n+  /* Offset so far becomes the position of this field after normalizing.  */\n+  normalize_rli (rli);\n+  DECL_FIELD_OFFSET (field) = rli->offset;\n+  DECL_FIELD_BIT_OFFSET (field) = rli->bitpos;\n+  DECL_OFFSET_ALIGN (field) = rli->offset_align;\n+\n+  /* If this field ended up more aligned than we thought it would be (we\n+     approximate this by seeing if its position changed), lay out the field\n+     again; perhaps we can use an integral mode for it now.  */\n+  if (! integer_zerop (DECL_FIELD_BIT_OFFSET (field))\n+      && TREE_CONSTANT (DECL_FIELD_OFFSET (field)))\n+    actual_align = (tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1)\n+\t\t    & - tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1));\n+  else if (host_integerp (DECL_FIELD_OFFSET (field), 1))\n+    actual_align = (BITS_PER_UNIT\n+\t\t   * (tree_low_cst (DECL_FIELD_OFFSET (field), 1)\n+\t\t      & - tree_low_cst (DECL_FIELD_OFFSET (field), 1)));\n   else\n+    actual_align = DECL_OFFSET_ALIGN (field);\n+\n+  if (known_align != actual_align)\n+    layout_decl (field, actual_align);\n+\n+  /* Now add size of this field to the size of the record.  If the size is\n+     not constant, treat the field as being a multiple of bytes and just\n+     adjust the offset, resetting the bit position.  Otherwise, apportion the\n+     size amongst the bit position and offset.  First handle the case of an\n+     unspecified size, which can happen when we have an invalid nested struct\n+     definition, such as struct j { struct j { int i; } }.  The error message\n+     is printed in finish_struct.  */\n+  if (DECL_SIZE (field) == 0)\n+    /* Do nothing.  */;\n+  else if (! TREE_CONSTANT (DECL_SIZE_UNIT (field)))\n     {\n-      DECL_FIELD_BITPOS (field) = bitsize_int (rli->const_size);\n-\n-      /* If this field ended up more aligned than we thought it\n-\t would be (we approximate this by seeing if its position\n-\t changed), lay out the field again; perhaps we can use an\n-\t integral mode for it now.  */\n-      if (known_align != rli->const_size)\n-\tlayout_decl (field, rli->const_size);\n+      rli->offset\n+\t= size_binop (PLUS_EXPR, rli->offset,\n+\t\t      convert (sizetype,\n+\t\t\t       size_binop (CEIL_DIV_EXPR, rli->bitpos,\n+\t\t\t\t\t   bitsize_unit_node)));\n+      rli->offset\n+\t= size_binop (PLUS_EXPR, rli->offset, DECL_SIZE_UNIT (field));\n+      rli->bitpos = bitsize_zero_node;\n     }\n-\n-  /* Now add size of this field to the size of the record.  */\n-  dsize = DECL_SIZE (field);\n-\n-  /* This can happen when we have an invalid nested struct definition,\n-     such as struct j { struct j { int i; } }.  The error message is\n-     printed in finish_struct.  */\n-  if (dsize == 0)\n-    /* Do nothing.  */;\n-  else if (TREE_CODE (dsize) == INTEGER_CST\n-\t   && ! TREE_CONSTANT_OVERFLOW (dsize)\n-\t   && TREE_INT_CST_HIGH (dsize) == 0\n-\t   && TREE_INT_CST_LOW (dsize) + rli->const_size >= rli->const_size)\n-    /* Use const_size if there's no overflow.  */\n-    rli->const_size += TREE_INT_CST_LOW (dsize);\n   else\n     {\n-      if (rli->var_size == NULL_TREE)\n-\trli->var_size = dsize;\n-      else\n-\trli->var_size = size_binop (PLUS_EXPR, rli->var_size, dsize);\n+      rli->bitpos = size_binop (PLUS_EXPR, rli->bitpos, DECL_SIZE (field));\n+      normalize_rli (rli);\n     }\n }\n \n@@ -728,18 +821,15 @@ static void\n finalize_record_size (rli)\n      record_layout_info rli;\n {\n-  /* Work out the total size and alignment of the record as one\n-     expression and store in the record type.  Round it up to a\n-     multiple of the record's alignment.  */\n-  if (rli->var_size == NULL_TREE)\n-    TYPE_SIZE (rli->t) = bitsize_int (rli->const_size);\n-  else\n-    {\n-      if (rli->const_size)\n-\trli->var_size = size_binop (PLUS_EXPR, rli->var_size,\n-\t\t\t\t    bitsize_int (rli->const_size));\n-      TYPE_SIZE (rli->t) = rli->var_size;\n-    }\n+  tree unpadded_size, unpadded_size_unit;\n+\n+  /* Next move any full bytes of bits into the byte size.  */\n+  rli->offset\n+    = size_binop (PLUS_EXPR, rli->offset,\n+\t\t  convert (sizetype,\n+\t\t\t   size_binop (TRUNC_DIV_EXPR, rli->bitpos,\n+\t\t\t\t       bitsize_unit_node)));\n+  rli->bitpos = size_binop (TRUNC_MOD_EXPR, rli->bitpos, bitsize_unit_node);\n \n   /* Determine the desired alignment.  */\n #ifdef ROUND_TYPE_ALIGN\n@@ -749,45 +839,55 @@ finalize_record_size (rli)\n   TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);\n #endif\n \n+  unpadded_size\n+    = size_binop (PLUS_EXPR, rli->bitpos,\n+\t\t  size_binop (MULT_EXPR, convert (bitsizetype, rli->offset),\n+\t\t\t      bitsize_unit_node));\n+\n+  unpadded_size_unit\n+    = size_binop (PLUS_EXPR, rli->offset,\n+\t\t  convert (sizetype, \n+\t\t\t   size_binop (CEIL_DIV_EXPR, rli->bitpos,\n+\t\t\t\t       bitsize_unit_node)));\n+\n   /* Record the un-rounded size in the binfo node.  But first we check\n      the size of TYPE_BINFO to make sure that BINFO_SIZE is available.  */\n   if (TYPE_BINFO (rli->t) && TREE_VEC_LENGTH (TYPE_BINFO (rli->t)) > 6)\n     {\n-      TYPE_BINFO_SIZE (rli->t) = TYPE_SIZE (rli->t);\n-      TYPE_BINFO_SIZE_UNIT (rli->t)\n-\t= convert (sizetype,\n-\t\t   size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (rli->t),\n-\t\t\t       bitsize_int (BITS_PER_UNIT)));\n+      TYPE_BINFO_SIZE (rli->t) = unpadded_size;\n+      TYPE_BINFO_SIZE_UNIT (rli->t) = unpadded_size_unit;\n     }\n-  \n-  {\n-    tree unpadded_size = TYPE_SIZE (rli->t);\n \n+    /* Round the size up to be a multiple of the required alignment */\n #ifdef ROUND_TYPE_SIZE\n-    TYPE_SIZE (rli->t) = ROUND_TYPE_SIZE (rli->t, TYPE_SIZE (rli->t),\n-\t\t\t\t\t  TYPE_ALIGN (rli->t));\n+  TYPE_SIZE (rli->t) = ROUND_TYPE_SIZE (rli->t, unpadded_size,\n+\t\t\t\t\tTYPE_ALIGN (rli->t));\n+  TYPE_SIZE_UNIT (rli->t)\n+    = ROUND_TYPE_SIZE_UNIT (rli->t, unpaded_size_unit,\n+\t\t\t    TYPE_ALIGN (rli->t) / BITS_PER_UNIT);\n #else\n-    /* Round the size up to be a multiple of the required alignment */\n-    TYPE_SIZE (rli->t) = round_up (TYPE_SIZE (rli->t), TYPE_ALIGN (rli->t));\n+  TYPE_SIZE (rli->t) = round_up (unpadded_size, TYPE_ALIGN (rli->t));\n+  TYPE_SIZE_UNIT (rli->t) = round_up (unpadded_size_unit,\n+\t\t\t\t      TYPE_ALIGN (rli->t) / BITS_PER_UNIT);\n #endif\n \n-    if (warn_padded && rli->var_size == NULL_TREE\n-\t&& simple_cst_equal (unpadded_size, TYPE_SIZE (rli->t)) == 0)\n-      warning (\"padding struct size to alignment boundary\");\n-  }\n+  if (warn_padded && TREE_CONSTANT (unpadded_size)\n+      && simple_cst_equal (unpadded_size, TYPE_SIZE (rli->t)) == 0)\n+    warning (\"padding struct size to alignment boundary\");\n   \n-  if (warn_packed && TYPE_PACKED (rli->t) && !rli->packed_maybe_necessary\n-      && rli->var_size == NULL_TREE)\n+  if (warn_packed && TREE_CODE (rli->t) == RECORD_TYPE\n+      && TYPE_PACKED (rli->t) && ! rli->packed_maybe_necessary\n+      && TREE_CONSTANT (unpadded_size))\n     {\n       tree unpacked_size;\n \n-      TYPE_PACKED (rli->t) = 0;\n #ifdef ROUND_TYPE_ALIGN\n       rli->unpacked_align\n \t= ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t), rli->unpacked_align);\n #else\n       rli->unpacked_align = MAX (TYPE_ALIGN (rli->t), rli->unpacked_align);\n #endif\n+\n #ifdef ROUND_TYPE_SIZE\n       unpacked_size = ROUND_TYPE_SIZE (rli->t, TYPE_SIZE (rli->t),\n \t\t\t\t       rli->unpacked_align);\n@@ -797,6 +897,8 @@ finalize_record_size (rli)\n \n       if (simple_cst_equal (unpacked_size, TYPE_SIZE (rli->t)))\n \t{\n+\t  TYPE_PACKED (rli->t) = 0;\n+\n \t  if (TYPE_NAME (rli->t))\n \t    {\n \t      char *name;\n@@ -805,6 +907,7 @@ finalize_record_size (rli)\n \t\tname = IDENTIFIER_POINTER (TYPE_NAME (rli->t));\n \t      else\n \t\tname = IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (rli->t)));\n+\n \t      if (STRICT_ALIGNMENT)\n \t\twarning (\"packed attribute causes inefficient alignment for `%s'\", name);\n \t      else\n@@ -818,7 +921,6 @@ finalize_record_size (rli)\n \t\twarning (\"packed attribute is unnecessary\");\n \t    }\n \t}\n-      TYPE_PACKED (rli->t) = 1;\n     }\n }\n \n@@ -828,79 +930,77 @@ static void\n compute_record_mode (type)\n      tree type;\n {\n+  tree field;\n+  enum machine_mode mode = VOIDmode;\n+\n   /* Most RECORD_TYPEs have BLKmode, so we start off assuming that.\n      However, if possible, we use a mode that fits in a register\n      instead, in order to allow for better optimization down the\n      line.  */\n   TYPE_MODE (type) = BLKmode;\n-  if (TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST)\n-    {\n-      tree field;\n-      enum machine_mode mode = VOIDmode;\n-\n-      /* A record which has any BLKmode members must itself be\n-\t BLKmode; it can't go in a register.  Unless the member is\n-\t BLKmode only because it isn't aligned.  */\n-      for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n-\t{\n-\t  unsigned HOST_WIDE_INT bitpos;\n-\n-\t  if (TREE_CODE (field) != FIELD_DECL\n-\t      || TREE_CODE (TREE_TYPE (field)) == ERROR_MARK)\n-\t    continue;\n \n-\t  if (TYPE_MODE (TREE_TYPE (field)) == BLKmode\n-\t      && ! TYPE_NO_FORCE_BLK (TREE_TYPE (field)))\n-\t    return;\n-\n-\t  if (TREE_CODE (DECL_FIELD_BITPOS (field)) != INTEGER_CST)\n-\t    return;\n+  if (! host_integerp (TYPE_SIZE (type), 1))\n+    return;\n \n-\t  bitpos = TREE_INT_CST_LOW (DECL_FIELD_BITPOS (field));\n+  /* A record which has any BLKmode members must itself be\n+     BLKmode; it can't go in a register.  Unless the member is\n+     BLKmode only because it isn't aligned.  */\n+  for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n+    {\n+      unsigned HOST_WIDE_INT bitpos;\n \n-\t  /* Must be BLKmode if any field crosses a word boundary,\n-\t     since extract_bit_field can't handle that in registers.  */\n-\t  if (bitpos / BITS_PER_WORD\n-\t      != ((TREE_INT_CST_LOW (DECL_SIZE (field)) + bitpos - 1)\n-\t\t  / BITS_PER_WORD)\n-\t      /* But there is no problem if the field is entire words.  */\n-\t      && TREE_INT_CST_LOW (DECL_SIZE (field)) % BITS_PER_WORD != 0)\n-\t    return;\n+      if (TREE_CODE (field) != FIELD_DECL)\n+\tcontinue;\n \n-\t  /* If this field is the whole struct, remember its mode so\n-\t     that, say, we can put a double in a class into a DF\n-\t     register instead of forcing it to live in the stack.  */\n-\t  if (simple_cst_equal (TYPE_SIZE (type), DECL_SIZE (field)))\n-\t    mode = DECL_MODE (field);\n+      if (TREE_CODE (TREE_TYPE (field)) == ERROR_MARK\n+\t  || (TYPE_MODE (TREE_TYPE (field)) == BLKmode\n+\t      && ! TYPE_NO_FORCE_BLK (TREE_TYPE (field)))\n+\t  || ! host_integerp (bit_position (field), 1)\n+\t  || ! host_integerp (DECL_SIZE (field), 1))\n+\treturn;\n+\n+      bitpos = int_bit_position (field);\n+\t  \n+      /* Must be BLKmode if any field crosses a word boundary,\n+\t since extract_bit_field can't handle that in registers.  */\n+      if (bitpos / BITS_PER_WORD\n+\t  != ((TREE_INT_CST_LOW (DECL_SIZE (field)) + bitpos - 1)\n+\t      / BITS_PER_WORD)\n+\t  /* But there is no problem if the field is entire words.  */\n+\t  && tree_low_cst (DECL_SIZE (field), 1) % BITS_PER_WORD != 0)\n+\treturn;\n+\n+      /* If this field is the whole struct, remember its mode so\n+\t that, say, we can put a double in a class into a DF\n+\t register instead of forcing it to live in the stack.  */\n+      if (field == TYPE_FIELDS (type) && TREE_CHAIN (field) == 0)\n+\tmode = DECL_MODE (field);\n \n #ifdef STRUCT_FORCE_BLK\n-\t  /* With some targets, eg. c4x, it is sub-optimal\n-\t     to access an aligned BLKmode structure as a scalar.  */\n-\t  if (mode == VOIDmode && STRUCT_FORCE_BLK (field))\n-\t    return;\n+      /* With some targets, eg. c4x, it is sub-optimal\n+\t to access an aligned BLKmode structure as a scalar.  */\n+      if (mode == VOIDmode && STRUCT_FORCE_BLK (field))\n+\treturn;\n #endif /* STRUCT_FORCE_BLK  */\n-\t}\n+    }\n \n-      if (mode != VOIDmode)\n-\t/* We only have one real field; use its mode.  */\n-\tTYPE_MODE (type) = mode;\n-      else\n-\tTYPE_MODE (type)\n-\t  = mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);\n-\n-      /* If structure's known alignment is less than what the scalar\n-\t mode would need, and it matters, then stick with BLKmode.  */\n-      if (TYPE_MODE (type) != BLKmode\n-\t  && STRICT_ALIGNMENT\n-\t  && ! (TYPE_ALIGN (type) >= BIGGEST_ALIGNMENT\n-\t\t|| (TYPE_ALIGN (type) >=\n-\t\t    GET_MODE_ALIGNMENT (TYPE_MODE (type)))))\n-\t{\n-\t  /* If this is the only reason this type is BLKmode, then\n-\t     don't force containing types to be BLKmode.  */\n-\t  TYPE_NO_FORCE_BLK (type) = 1;\n-\t  TYPE_MODE (type) = BLKmode;\n-\t}\n+  if (mode != VOIDmode)\n+    /* We only have one real field; use its mode.  */\n+    TYPE_MODE (type) = mode;\n+  else\n+    TYPE_MODE (type) = mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);\n+\n+  /* If structure's known alignment is less than what the scalar\n+     mode would need, and it matters, then stick with BLKmode.  */\n+  if (TYPE_MODE (type) != BLKmode\n+      && STRICT_ALIGNMENT\n+      && ! (TYPE_ALIGN (type) >= BIGGEST_ALIGNMENT\n+\t    || TYPE_ALIGN (type) >= GET_MODE_ALIGNMENT (TYPE_MODE (type))))\n+    {\n+      /* If this is the only reason this type is BLKmode, then\n+\t don't force containing types to be BLKmode.  */\n+      TYPE_NO_FORCE_BLK (type) = 1;\n+      TYPE_MODE (type) = BLKmode;\n     }\n }\n \n@@ -929,28 +1029,35 @@ finalize_type_size (type)\n     = ROUND_TYPE_ALIGN (type, TYPE_ALIGN (type), BITS_PER_UNIT);\n #endif\n \n-#ifdef ROUND_TYPE_SIZE\n-  if (TYPE_SIZE (type) != 0)\n-    TYPE_SIZE (type)\n-      = ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));\n-#endif\n-\n-  /* Evaluate nonconstant size only once, either now or as soon as safe.  */\n-  if (TYPE_SIZE (type) != 0 && TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n-    TYPE_SIZE (type) = variable_size (TYPE_SIZE (type));\n-\n   /* If we failed to find a simple way to calculate the unit size\n-     of the type above, find it by division.  */\n+     of the type, find it by division.  */\n   if (TYPE_SIZE_UNIT (type) == 0 && TYPE_SIZE (type) != 0)\n     /* TYPE_SIZE (type) is computed in bitsizetype.  After the division, the\n        result will fit in sizetype.  We will get more efficient code using\n        sizetype, so we force a conversion.  */\n     TYPE_SIZE_UNIT (type)\n       = convert (sizetype,\n \t\t size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (type),\n-\t\t\t     bitsize_int (BITS_PER_UNIT)));\n+\t\t\t     bitsize_unit_node));\n \n-  /* Once again evaluate only once, either now or as soon as safe.  */\n+  if (TYPE_SIZE (type) != 0)\n+    {\n+#ifdef ROUND_TYPE_SIZE\n+      TYPE_SIZE (type)\n+\t= ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));\n+      TYPE_SIZE_UNIT (type)\n+\t= ROUND_TYPE_SIZE_UNIT (type, TYPE_SIZE_UNIT (type),\n+\t\t\t\tTYPE_ALIGN (type) / BITS_PER_UNIT);\n+#else\n+      TYPE_SIZE (type) = round_up (TYPE_SIZE (type), TYPE_ALIGN (type));\n+      TYPE_SIZE_UNIT (type)\n+\t= round_up (TYPE_SIZE_UNIT (type), TYPE_ALIGN (type) / BITS_PER_UNIT);\n+#endif\n+    }\n+\n+  /* Evaluate nonconstant sizes only once, either now or as soon as safe.  */\n+  if (TYPE_SIZE (type) != 0 && TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n+    TYPE_SIZE (type) = variable_size (TYPE_SIZE (type));\n   if (TYPE_SIZE_UNIT (type) != 0\n       && TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST)\n     TYPE_SIZE_UNIT (type) = variable_size (TYPE_SIZE_UNIT (type));\n@@ -987,16 +1094,11 @@ void\n finish_record_layout (rli)\n      record_layout_info rli;\n {\n-  /* Use finish_union_layout for unions.  */\n-  if (TREE_CODE (rli->t) != RECORD_TYPE)\n-    finish_union_layout (rli);\n-  else\n-    {\n-      /* Compute the final size.  */\n-      finalize_record_size (rli);\n-      /* Compute the TYPE_MODE for the record.  */\n-      compute_record_mode (rli->t);\n-    }\n+  /* Compute the final size.  */\n+  finalize_record_size (rli);\n+\n+  /* Compute the TYPE_MODE for the record.  */\n+  compute_record_mode (rli->t);\n \n   /* Lay out any static members.  This is done now because their type\n      may use the record's type.  */\n@@ -1008,83 +1110,10 @@ finish_record_layout (rli)\n \n   /* Perform any last tweaks to the TYPE_SIZE, etc.  */\n   finalize_type_size (rli->t);\n+\n   /* Clean up.  */\n   free (rli);\n }\n-\n-/* Like finish_record_layout, but for unions.  */\n-\n-static void\n-finish_union_layout (rli)\n-     record_layout_info rli;\n-{\n-  /* This function should only be used for unions; use\n-     finish_record_layout for RECORD_TYPEs.  */\n-  if (TREE_CODE (rli->t) != UNION_TYPE\n-      && TREE_CODE (rli->t) != QUAL_UNION_TYPE)\n-    abort ();\n-\n-  /* Determine the ultimate size of the union (in bytes).  */\n-  if (NULL == rli->var_size)\n-    TYPE_SIZE (rli->t)\n-      = bitsize_int (CEIL (rli->const_size, BITS_PER_UNIT) * BITS_PER_UNIT);\n-\n-  else if (rli->const_size == 0)\n-    TYPE_SIZE (rli->t) = rli->var_size;\n-  else\n-    TYPE_SIZE (rli->t) = size_binop (MAX_EXPR, rli->var_size,\n-\t\t\t\t     round_up (bitsize_int (rli->const_size),\n-\t\t\t\t\t       BITS_PER_UNIT));\n-\n-  /* Determine the desired alignment.  */\n-#ifdef ROUND_TYPE_ALIGN\n-  TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t), \n-\t\t\t\t\t  rli->record_align);\n-#else\n-  TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);\n-#endif\n-\n-#ifdef ROUND_TYPE_SIZE\n-  TYPE_SIZE (rli->t) = ROUND_TYPE_SIZE (rli->t, TYPE_SIZE (rli->t), \n-\t\t\t\t\tTYPE_ALIGN (rli->t));\n-#else\n-  /* Round the size up to be a multiple of the required alignment */\n-  TYPE_SIZE (rli->t) = round_up (TYPE_SIZE (rli->t), \n-\t\t\t\t TYPE_ALIGN (rli->t));\n-#endif\n-\n-  TYPE_MODE (rli->t) = BLKmode;\n-  if (TREE_CODE (TYPE_SIZE (rli->t)) == INTEGER_CST\n-      /* If structure's known alignment is less than\n-\t what the scalar mode would need, and it matters,\n-\t then stick with BLKmode.  */\n-      && (! STRICT_ALIGNMENT\n-\t  || TYPE_ALIGN (rli->t) >= BIGGEST_ALIGNMENT\n-\t  || compare_tree_int (TYPE_SIZE (rli->t), \n-\t\t\t       TYPE_ALIGN (rli->t)) <= 0))\n-    {\n-      tree field;\n-\n-      /* A union which has any BLKmode members must itself be BLKmode;\n-\t it can't go in a register.\n-\t Unless the member is BLKmode only because it isn't aligned.  */\n-      for (field = TYPE_FIELDS (rli->t); \n-\t   field; \n-\t   field = TREE_CHAIN (field))\n-\t{\n-\t  if (TREE_CODE (field) != FIELD_DECL)\n-\t    continue;\n-\n-\t  if (TYPE_MODE (TREE_TYPE (field)) == BLKmode\n-\t      && ! TYPE_NO_FORCE_BLK (TREE_TYPE (field)))\n-\t    return;\n-\t}\n-\n-      TYPE_MODE (rli->t) \n-\t= mode_for_size_tree (TYPE_SIZE (rli->t), MODE_INT, 1);\n-    }\n-}\n-\n \f\n /* Calculate the mode, size, and alignment for TYPE.\n    For an array type, calculate the element separation as well.\n@@ -1163,8 +1192,7 @@ layout_type (type)\n       break;\n \n     case VOID_TYPE:\n-      /* VOID_TYPE is an incompletable type, it has no size */\n-      TYPE_SIZE_UNIT (type) = size_zero_node;\n+      /* This is an incomplete type and so doesn't have a size.  */\n       TYPE_ALIGN (type) = 1;\n       TYPE_MODE (type) = VOIDmode;\n       break;\n@@ -1325,17 +1353,21 @@ layout_type (type)\n \trecord_layout_info rli;\n \n \t/* Initialize the layout information.  */\n-\trli = new_record_layout_info (type);\n+\trli = start_record_layout (type);\n+\n \t/* If this is a QUAL_UNION_TYPE, we want to process the fields\n \t   in the reverse order in building the COND_EXPR that denotes\n \t   its size.  We reverse them again later.  */\n \tif (TREE_CODE (type) == QUAL_UNION_TYPE)\n \t  TYPE_FIELDS (type) = nreverse (TYPE_FIELDS (type));\n-\t/* Layout all the fields.  */\n+\n+\t/* Place all the fields.  */\n \tfor (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n-\t  layout_field (rli, field);\n+\t  place_field (rli, field);\n+\n \tif (TREE_CODE (type) == QUAL_UNION_TYPE)\n \t  TYPE_FIELDS (type) = nreverse (TYPE_FIELDS (type));\n+\n \t/* Finish laying out the record.  */\n \tfinish_record_layout (rli);\n       }\n@@ -1448,6 +1480,7 @@ initialize_sizetypes ()\n   TREE_UNSIGNED (t) = 1;\n   TYPE_PRECISION (t) = GET_MODE_BITSIZE (SImode);\n   TYPE_MIN_VALUE (t) = build_int_2 (0, 0);\n+  TYPE_IS_SIZETYPE (t) = 1;\n \n   /* 1000 avoids problems with possible overflow and is certainly\n      larger than any size value we'd want to be storing.  */\n@@ -1483,9 +1516,11 @@ set_sizetype (type)\n   /* Make copies of nodes since we'll be setting TYPE_IS_SIZETYPE.  */\n   sizetype = copy_node (type);\n   TYPE_DOMAIN (sizetype) = type;\n+  TYPE_IS_SIZETYPE (sizetype) = 1;\n   bitsizetype = make_node (INTEGER_TYPE);\n   TYPE_NAME (bitsizetype) = TYPE_NAME (type);\n   TYPE_PRECISION (bitsizetype) = precision;\n+  TYPE_IS_SIZETYPE (bitsizetype) = 1;\n \n   if (TREE_UNSIGNED (type))\n     fixup_unsigned_type (bitsizetype);\n@@ -1624,7 +1659,7 @@ get_best_mode (bitsize, bitpos, align, largest_mode, volatilep)\n      int volatilep;\n {\n   enum machine_mode mode;\n-  int unit = 0;\n+  unsigned int unit = 0;\n \n   /* Find the narrowest integer mode that contains the bit field.  */\n   for (mode = GET_CLASS_NARROWEST_MODE (MODE_INT); mode != VOIDmode;\n@@ -1643,7 +1678,7 @@ get_best_mode (bitsize, bitpos, align, largest_mode, volatilep)\n \t if the extra 4th byte is past the end of memory.\n \t (Though at least one Unix compiler ignores this problem:\n \t that on the Sequent 386 machine.  */\n-      || MIN (unit, BIGGEST_ALIGNMENT) > (int) align\n+      || MIN (unit, BIGGEST_ALIGNMENT) > align\n       || (largest_mode != VOIDmode && unit > GET_MODE_BITSIZE (largest_mode)))\n     return VOIDmode;\n \n@@ -1657,7 +1692,7 @@ get_best_mode (bitsize, bitpos, align, largest_mode, volatilep)\n \t  unit = GET_MODE_BITSIZE (tmode);\n \t  if (bitpos / unit == (bitpos + bitsize - 1) / unit\n \t      && unit <= BITS_PER_WORD\n-\t      && unit <= (int) MIN (align, BIGGEST_ALIGNMENT)\n+\t      && unit <= MIN (align, BIGGEST_ALIGNMENT)\n \t      && (largest_mode == VOIDmode\n \t\t  || unit <= GET_MODE_BITSIZE (largest_mode)))\n \t    wide_mode = tmode;"}, {"sha": "1e212251f22dae3ec31bf640ab1fd08b96a03c9e", "filename": "gcc/tree.c", "status": "modified", "additions": 51, "deletions": 37, "changes": 88, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -2321,7 +2321,11 @@ tree\n bit_position (field)\n      tree field;\n {\n-  return DECL_FIELD_BITPOS (field);\n+  return size_binop (PLUS_EXPR, DECL_FIELD_BIT_OFFSET (field),\n+\t\t     size_binop (MULT_EXPR,\n+\t\t\t\t convert (bitsizetype,\n+\t\t\t\t\t  DECL_FIELD_OFFSET (field)),\n+\t\t\t\t bitsize_unit_node));\n }\n \n /* Likewise, but return as an integer.  Abort if it cannot be represented\n@@ -2335,6 +2339,31 @@ int_bit_position (field)\n   return tree_low_cst (bit_position (field), 0);\n }\n \f\n+/* Return the byte position of FIELD, in bytes from the start of the record.\n+   This is a tree of type sizetype.  */\n+\n+tree\n+byte_position (field)\n+     tree field;\n+{\n+  return size_binop (PLUS_EXPR, DECL_FIELD_OFFSET (field),\n+\t\t     convert (sizetype,\n+\t\t\t      size_binop (FLOOR_DIV_EXPR,\n+\t\t\t\t\t  DECL_FIELD_BIT_OFFSET (field),\n+\t\t\t\t\t  bitsize_unit_node)));\n+}\n+\n+/* Likewise, but return as an integer.  Abort if it cannot be represented\n+   in that way (since it could be a signed value, we don't have the option\n+   of returning -1 like int_size_in_byte can.  */\n+\n+HOST_WIDE_INT\n+int_byte_position (field)\n+     tree field;\n+{\n+  return tree_low_cst (byte_position (field), 0);\n+}\n+\f\n /* Return the strictest alignment, in bits, that T is known to have.  */\n \n unsigned int\n@@ -4091,8 +4120,8 @@ type_hash_canon (hashcode, type)\n \tobstack_free (TYPE_OBSTACK (type), type);\n \n #ifdef GATHER_STATISTICS\n-      tree_node_counts[(int)t_kind]--;\n-      tree_node_sizes[(int)t_kind] -= sizeof (struct tree_type);\n+      tree_node_counts[(int) t_kind]--;\n+      tree_node_sizes[(int) t_kind] -= sizeof (struct tree_type);\n #endif\n       return t1;\n     }\n@@ -4112,7 +4141,9 @@ mark_hash_entry (entry, param)\n      void *param ATTRIBUTE_UNUSED;\n {\n   struct type_hash *p = *(struct type_hash **)entry;\n+\n   ggc_mark_tree (p->type);\n+\n   /* Continue scan.  */\n   return 1;\n }\n@@ -4124,14 +4155,16 @@ mark_type_hash (arg)\n      void *arg;\n {\n   htab_t t = *(htab_t *) arg;\n+\n   htab_traverse (t, mark_hash_entry, 0);\n }\n \n static void\n print_type_hash_statistics ()\n {\n-  fprintf (stderr, \"Type hash: size %d, %d elements, %f collisions\\n\",\n-\t   htab_size (type_hash_table), htab_elements (type_hash_table),\n+  fprintf (stderr, \"Type hash: size %ld, %ld elements, %f collisions\\n\",\n+\t   (long) htab_size (type_hash_table),\n+\t   (long) htab_elements (type_hash_table),\n \t   htab_collisions (type_hash_table));\n }\n \n@@ -4594,6 +4627,7 @@ build_index_type (maxval)\n {\n   register tree itype = make_node (INTEGER_TYPE);\n \n+  TREE_TYPE (itype) = sizetype;\n   TYPE_PRECISION (itype) = TYPE_PRECISION (sizetype);\n   TYPE_MIN_VALUE (itype) = size_zero_node;\n \n@@ -4605,20 +4639,9 @@ build_index_type (maxval)\n   TYPE_SIZE (itype) = TYPE_SIZE (sizetype);\n   TYPE_SIZE_UNIT (itype) = TYPE_SIZE_UNIT (sizetype);\n   TYPE_ALIGN (itype) = TYPE_ALIGN (sizetype);\n-  if (TREE_CODE (maxval) == INTEGER_CST)\n-    {\n-      int maxint = TREE_INT_CST_LOW (maxval);\n-\n-      /* If the domain should be empty, make sure the maxval\n-\t remains -1 and is not spoiled by truncation.  */\n-      if (tree_int_cst_sgn (maxval) < 0)\n-\t{\n-\t  TYPE_MAX_VALUE (itype) = build_int_2 (-1, -1);\n-\t  TREE_TYPE (TYPE_MAX_VALUE (itype)) = sizetype;\n-\t}\n \n-      return type_hash_canon (maxint < 0 ? ~maxint : maxint, itype);\n-    }\n+  if (host_integerp (maxval, 1))\n+    return type_hash_canon (tree_low_cst (maxval, 1), itype);\n   else\n     return itype;\n }\n@@ -4648,21 +4671,11 @@ build_range_type (type, lowval, highval)\n   TYPE_SIZE (itype) = TYPE_SIZE (type);\n   TYPE_SIZE_UNIT (itype) = TYPE_SIZE_UNIT (type);\n   TYPE_ALIGN (itype) = TYPE_ALIGN (type);\n-  if (TREE_CODE (lowval) == INTEGER_CST)\n-    {\n-      HOST_WIDE_INT lowint, highint;\n-      int maxint;\n \n-      lowint = TREE_INT_CST_LOW (lowval);\n-      if (highval && TREE_CODE (highval) == INTEGER_CST)\n-\thighint = TREE_INT_CST_LOW (highval);\n-      else\n-\thighint = (~(unsigned HOST_WIDE_INT) 0) >> 1;\n-\n-      maxint = (int) (highint - lowint);\n-\n-      return type_hash_canon (maxint < 0 ? ~maxint : maxint, itype);\n-    }\n+  if (host_integerp (lowval, 0) && highval != 0 && host_integerp (highval, 0))\n+    return type_hash_canon (tree_low_cst (highval, 0)\n+\t\t\t    - tree_low_cst (lowval, 0),\n+\t\t\t    itype);\n   else\n     return itype;\n }\n@@ -4674,7 +4687,7 @@ tree\n build_index_2_type (lowval,highval)\n      tree lowval, highval;\n {\n-  return build_range_type (NULL_TREE, lowval, highval);\n+  return build_range_type (sizetype, lowval, highval);\n }\n \n /* Return nonzero iff ITYPE1 and ITYPE2 are equal (in the LISP sense).\n@@ -5700,10 +5713,11 @@ build_common_tree_nodes_2 (short_double)\n   integer_one_node = build_int_2 (1, 0);\n   TREE_TYPE (integer_one_node) = integer_type_node;\n \n-  size_zero_node = build_int_2 (0, 0);\n-  TREE_TYPE (size_zero_node) = sizetype;\n-  size_one_node = build_int_2 (1, 0);\n-  TREE_TYPE (size_one_node) = sizetype;\n+  size_zero_node = size_int (0);\n+  size_one_node = size_int (1);\n+  bitsize_zero_node = bitsize_int (0);\n+  bitsize_one_node = bitsize_int (1);\n+  bitsize_unit_node = bitsize_int (BITS_PER_UNIT);\n \n   void_type_node = make_node (VOID_TYPE);\n   layout_type (void_type_node);"}, {"sha": "029d836248f308869302fb188ae2cb255094d3a5", "filename": "gcc/tree.h", "status": "modified", "additions": 86, "deletions": 59, "changes": 145, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1063,27 +1063,30 @@ struct tree_type\n     containing function, the RECORD_TYPE or UNION_TYPE for the containing\n     type, or NULL_TREE if the given decl has \"file scope\".  */\n #define DECL_CONTEXT(NODE) (DECL_CHECK (NODE)->decl.context)\n-#define DECL_FIELD_CONTEXT(NODE) (DECL_CHECK (NODE)->decl.context)\n+#define DECL_FIELD_CONTEXT(NODE) (FIELD_DECL_CHECK (NODE)->decl.context)\n /* In a DECL this is the field where configuration dependent machine\n    attributes are store */\n #define DECL_MACHINE_ATTRIBUTES(NODE) (DECL_CHECK (NODE)->decl.machine_attributes)\n-/* In a FIELD_DECL, this is the field position, counting in bits,\n-   of the bit closest to the beginning of the structure.  */\n-#define DECL_FIELD_BITPOS(NODE) (DECL_CHECK (NODE)->decl.arguments)\n+/* In a FIELD_DECL, this is the field position, counting in bytes, of the\n+   byte containing the bit closest to the beginning of the structure.  */\n+#define DECL_FIELD_OFFSET(NODE) (FIELD_DECL_CHECK (NODE)->decl.arguments)\n+/* In a FIELD_DECL, this is the offset, in bits, of the first bit of the\n+   field from DECL_FIELD_OFFSET.  */\n+#define DECL_FIELD_BIT_OFFSET(NODE) (FIELD_DECL_CHECK (NODE)->decl.u2.t)\n /* In a FIELD_DECL, this indicates whether the field was a bit-field and\n    if so, the type that was originally specified for it.\n    TREE_TYPE may have been modified (in finish_struct).  */\n-#define DECL_BIT_FIELD_TYPE(NODE) (DECL_CHECK (NODE)->decl.result)\n+#define DECL_BIT_FIELD_TYPE(NODE) (FIELD_DECL_CHECK (NODE)->decl.result)\n /* In FUNCTION_DECL, a chain of ..._DECL nodes.  */\n /* VAR_DECL and PARM_DECL reserve the arguments slot\n    for language-specific uses.  */\n #define DECL_ARGUMENTS(NODE) (DECL_CHECK (NODE)->decl.arguments)\n /* In FUNCTION_DECL, holds the decl for the return value.  */\n-#define DECL_RESULT(NODE) (DECL_CHECK (NODE)->decl.result)\n+#define DECL_RESULT(NODE) (FUNCTION_DECL_CHECK (NODE)->decl.result)\n /* For a TYPE_DECL, holds the \"original\" type.  (TREE_TYPE has the copy.) */\n-#define DECL_ORIGINAL_TYPE(NODE) (DECL_CHECK (NODE)->decl.result)\n+#define DECL_ORIGINAL_TYPE(NODE) (TYPE_DECL_CHECK (NODE)->decl.result)\n /* In PARM_DECL, holds the type as written (perhaps a function or array).  */\n-#define DECL_ARG_TYPE_AS_WRITTEN(NODE) (DECL_CHECK (NODE)->decl.result)\n+#define DECL_ARG_TYPE_AS_WRITTEN(NODE) (PARM_DECL_CHECK (NODE)->decl.result)\n /* For a FUNCTION_DECL, holds the tree of BINDINGs.\n    For a VAR_DECL, holds the initial value.\n    For a PARM_DECL, not used--default\n@@ -1092,10 +1095,10 @@ struct tree_type\n #define DECL_INITIAL(NODE) (DECL_CHECK (NODE)->decl.initial)\n /* For a PARM_DECL, records the data type used to pass the argument,\n    which may be different from the type seen in the program.  */\n-#define DECL_ARG_TYPE(NODE) (DECL_CHECK (NODE)->decl.initial)\n+#define DECL_ARG_TYPE(NODE) (PARM_DECL_CHECK (NODE)->decl.initial)\n /* For a FIELD_DECL in a QUAL_UNION_TYPE, records the expression, which\n    if nonzero, indicates that the field occupies the type.  */\n-#define DECL_QUALIFIER(NODE) (DECL_CHECK (NODE)->decl.initial)\n+#define DECL_QUALIFIER(NODE) (FIELD_DECL_CHECK (NODE)->decl.initial)\n /* These two fields describe where in the source code the declaration was.  */\n #define DECL_SOURCE_FILE(NODE) (DECL_CHECK (NODE)->decl.filename)\n #define DECL_SOURCE_LINE(NODE) (DECL_CHECK (NODE)->decl.linenum)\n@@ -1105,7 +1108,9 @@ struct tree_type\n /* Likewise for the size in bytes.  */\n #define DECL_SIZE_UNIT(NODE) (DECL_CHECK (NODE)->decl.size_unit)\n /* Holds the alignment required for the datum.  */\n-#define DECL_ALIGN(NODE) (DECL_CHECK (NODE)->decl.u1.u)\n+#define DECL_ALIGN(NODE) (DECL_CHECK (NODE)->decl.u1.a.align)\n+/* For FIELD_DECLs, holds the alignment that DECL_FEILD_OFFSET has.  */\n+#define DECL_OFFSET_ALIGN(NODE) (FIELD_DECL_CHECK (NODE)->decl.u1.a.off_align)\n /* Holds the machine mode corresponding to the declaration of a variable or\n    field.  Always equal to TYPE_MODE (TREE_TYPE (decl)) except for a\n    FIELD_DECL.  */\n@@ -1121,15 +1126,15 @@ struct tree_type\n #define DECL_LIVE_RANGE_RTL(NODE) (DECL_CHECK (NODE)->decl.live_range_rtl)\n /* For PARM_DECL, holds an RTL for the stack slot or register\n    where the data was actually passed.  */\n-#define DECL_INCOMING_RTL(NODE) (DECL_CHECK (NODE)->decl.u2.r)\n+#define DECL_INCOMING_RTL(NODE) (PARM_DECL_CHECK (NODE)->decl.u2.r)\n /* For FUNCTION_DECL, if it is inline, holds the saved insn chain.  */\n-#define DECL_SAVED_INSNS(NODE) (DECL_CHECK (NODE)->decl.u2.f)\n+#define DECL_SAVED_INSNS(NODE) (FUNCTION_DECL_CHECK (NODE)->decl.u2.f)\n /* For FUNCTION_DECL, if it is inline,\n    holds the size of the stack frame, as an integer.  */\n-#define DECL_FRAME_SIZE(NODE) (DECL_CHECK (NODE)->decl.u1.i)\n+#define DECL_FRAME_SIZE(NODE) (FUNCTION_DECL_CHECK (NODE)->decl.u1.i)\n /* For FUNCTION_DECL, if it is built-in,\n    this identifies which built-in operation it is.  */\n-#define DECL_FUNCTION_CODE(NODE) (DECL_CHECK (NODE)->decl.u1.f)\n+#define DECL_FUNCTION_CODE(NODE) (FUNCTION_DECL_CHECK (NODE)->decl.u1.f)\n \n /* The DECL_VINDEX is used for FUNCTION_DECLS in two different ways.\n    Before the struct containing the FUNCTION_DECL is laid out,\n@@ -1142,7 +1147,7 @@ struct tree_type\n /* For FIELD_DECLS, DECL_FCONTEXT is the *first* baseclass in\n    which this FIELD_DECL is defined.  This information is needed when\n    writing debugging information about vfield and vbase decls for C++.  */\n-#define DECL_FCONTEXT(NODE) (DECL_CHECK (NODE)->decl.vindex)\n+#define DECL_FCONTEXT(NODE) (FIELD_DECL_CHECK (NODE)->decl.vindex)\n \n /* Every ..._DECL node gets a unique number.  */\n #define DECL_UID(NODE) (DECL_CHECK (NODE)->decl.uid)\n@@ -1206,19 +1211,20 @@ struct tree_type\n    nonzero means the detail info about this type is not dumped into stabs.\n    Instead it will generate cross reference ('x') of names. \n    This uses the same flag as DECL_EXTERNAL. */\n-#define TYPE_DECL_SUPPRESS_DEBUG(NODE) (DECL_CHECK (NODE)->decl.external_flag)\n-   \n+#define TYPE_DECL_SUPPRESS_DEBUG(NODE) \\\n+(TYPE_DECL_CHECK (NODE)->decl.external_flag)\n \n /* In VAR_DECL and PARM_DECL nodes, nonzero means declared `register'.  */\n #define DECL_REGISTER(NODE) (DECL_CHECK (NODE)->decl.regdecl_flag)\n /* In LABEL_DECL nodes, nonzero means that an error message about\n    jumping into such a binding contour has been printed for this label.  */\n-#define DECL_ERROR_ISSUED(NODE) (DECL_CHECK (NODE)->decl.regdecl_flag)\n+#define DECL_ERROR_ISSUED(NODE) (LABEL_DECL_CHECK (NODE)->decl.regdecl_flag)\n /* In a FIELD_DECL, indicates this field should be bit-packed.  */\n-#define DECL_PACKED(NODE) (DECL_CHECK (NODE)->decl.regdecl_flag)\n+#define DECL_PACKED(NODE) (FIELD_DECL_CHECK (NODE)->decl.regdecl_flag)\n /* In a FUNCTION_DECL with a non-zero DECL_CONTEXT, indicates that a\n    static chain is not needed.  */\n-#define DECL_NO_STATIC_CHAIN(NODE) (DECL_CHECK (NODE)->decl.regdecl_flag)\n+#define DECL_NO_STATIC_CHAIN(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->decl.regdecl_flag)\n \n /* Nonzero in a ..._DECL means this variable is ref'd from a nested function.\n    For VAR_DECL nodes, PARM_DECL nodes, and FUNCTION_DECL nodes.\n@@ -1231,35 +1237,37 @@ struct tree_type\n \n /* Nonzero in a FUNCTION_DECL means this function can be substituted\n    where it is called.  */\n-#define DECL_INLINE(NODE) (DECL_CHECK (NODE)->decl.inline_flag)\n+#define DECL_INLINE(NODE) (FUNCTION_DECL_CHECK (NODE)->decl.inline_flag)\n \n /* Nonzero in a FUNCTION_DECL means this is a built-in function\n    that is not specified by ansi C and that users are supposed to be allowed\n    to redefine for any purpose whatever.  */\n-#define DECL_BUILT_IN_NONANSI(NODE) ((NODE)->common.unsigned_flag)\n+#define DECL_BUILT_IN_NONANSI(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->common.unsigned_flag)\n \n /* Nonzero in a FUNCTION_DECL means this function should be treated\n    as if it were a malloc, meaning it returns a pointer that is\n    not an alias.  */\n-#define DECL_IS_MALLOC(NODE) (DECL_CHECK (NODE)->decl.malloc_flag)\n+#define DECL_IS_MALLOC(NODE) (FUNCTION_DECL_CHECK (NODE)->decl.malloc_flag)\n \n /* Nonzero in a FIELD_DECL means it is a bit field, and must be accessed\n    specially.  */\n-#define DECL_BIT_FIELD(NODE) (DECL_CHECK (NODE)->decl.bit_field_flag)\n+#define DECL_BIT_FIELD(NODE) (FIELD_DECL_CHECK (NODE)->decl.bit_field_flag)\n /* In a LABEL_DECL, nonzero means label was defined inside a binding\n    contour that restored a stack level and which is now exited.  */\n-#define DECL_TOO_LATE(NODE) (DECL_CHECK (NODE)->decl.bit_field_flag)\n+#define DECL_TOO_LATE(NODE) (LABEL_DECL_CHECK (NODE)->decl.bit_field_flag)\n \n /* Unused in FUNCTION_DECL.  */\n \n /* In a VAR_DECL that's static,\n    nonzero if the space is in the text section.  */\n-#define DECL_IN_TEXT_SECTION(NODE) (DECL_CHECK (NODE)->decl.bit_field_flag)\n+#define DECL_IN_TEXT_SECTION(NODE) (VAR_DECL_CHECK (NODE)->decl.bit_field_flag)\n \n /* In a FUNCTION_DECL, nonzero means a built in function.  */\n #define DECL_BUILT_IN(NODE) (DECL_BUILT_IN_CLASS (NODE) != NOT_BUILT_IN)\n /* For a builtin function, identify which part of the compiler defined it.  */\n-#define DECL_BUILT_IN_CLASS(NODE) (DECL_CHECK (NODE)->decl.built_in_class)\n+#define DECL_BUILT_IN_CLASS(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->decl.built_in_class)\n \n /* Used in VAR_DECLs to indicate that the variable is a vtable.\n    Used in FIELD_DECLs for vtable pointers.\n@@ -1273,12 +1281,16 @@ struct tree_type\n /* Used in PARM_DECLs whose type are unions to indicate that the\n    argument should be passed in the same way that the first union\n    alternative would be passed.  */\n-#define DECL_TRANSPARENT_UNION(NODE) (DECL_CHECK (NODE)->decl.transparent_union)\n+#define DECL_TRANSPARENT_UNION(NODE) \\\n+(PARM_DECL_CHECK (NODE)->decl.transparent_union)\n \n /* Used in FUNCTION_DECLs to indicate that they should be run automatically\n    at the beginning or end of execution.  */\n-#define DECL_STATIC_CONSTRUCTOR(NODE) (DECL_CHECK (NODE)->decl.static_ctor_flag)\n-#define DECL_STATIC_DESTRUCTOR(NODE) (DECL_CHECK (NODE)->decl.static_dtor_flag)\n+#define DECL_STATIC_CONSTRUCTOR(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->decl.static_ctor_flag)\n+\n+#define DECL_STATIC_DESTRUCTOR(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->decl.static_dtor_flag)\n \n /* Used to indicate that this DECL represents a compiler-generated entity.  */\n #define DECL_ARTIFICIAL(NODE) (DECL_CHECK (NODE)->decl.artificial_flag)\n@@ -1303,15 +1315,18 @@ struct tree_type\n \n /* Used in FUNCTION_DECLs to indicate that function entry and exit should\n    be instrumented with calls to support routines.  */\n-#define DECL_NO_INSTRUMENT_FUNCTION_ENTRY_EXIT(NODE) ((NODE)->decl.no_instrument_function_entry_exit)\n+#define DECL_NO_INSTRUMENT_FUNCTION_ENTRY_EXIT(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->decl.no_instrument_function_entry_exit)\n \n /* Used in FUNCTION_DECLs to indicate that check-memory-usage should be\n    disabled in this function.  */\n-#define DECL_NO_CHECK_MEMORY_USAGE(NODE) ((NODE)->decl.no_check_memory_usage)\n+#define DECL_NO_CHECK_MEMORY_USAGE(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->decl.no_check_memory_usage)\n \n /* Used in FUNCTION_DECLs to indicate that limit-stack-* should be\n    disabled in this function.  */\n-#define DECL_NO_LIMIT_STACK(NODE) ((NODE)->decl.no_limit_stack)\n+#define DECL_NO_LIMIT_STACK(NODE) \\\n+(FUNCTION_DECL_CHECK (NODE)->decl.no_limit_stack)\n \n /* Additional flags for language-specific uses.  */\n #define DECL_LANG_FLAG_0(NODE) (DECL_CHECK (NODE)->decl.lang_flag_0)\n@@ -1391,17 +1406,17 @@ struct tree_decl\n \n   /* For a FUNCTION_DECL, if inline, this is the size of frame needed.\n      If built-in, this is the code for which built-in function.\n-     For other kinds of decls, this is DECL_ALIGN.  */\n+     For other kinds of decls, this is DECL_ALIGN and DECL_OFFSET_ALIGN.  */\n   union {\n     HOST_WIDE_INT i;\n-    unsigned int u;\n     enum built_in_function f;\n+    struct {unsigned int align : 24; unsigned int off_align : 8;} a;\n   } u1;\n \n   union tree_node *size_unit;\n   union tree_node *name;\n   union tree_node *context;\n-  union tree_node *arguments;\t/* Also used for DECL_FIELD_BITPOS */\n+  union tree_node *arguments;\t/* Also used for DECL_FIELD_OFFSET */\n   union tree_node *result;\t/* Also used for DECL_BIT_FIELD_TYPE */\n   union tree_node *initial;\t/* Also used for DECL_QUALIFIER */\n   union tree_node *abstract_origin;\n@@ -1412,6 +1427,7 @@ struct tree_decl\n   struct rtx_def *live_range_rtl;\n \n   /* In FUNCTION_DECL, if it is inline, holds the saved insn chain.\n+     In FIELD_DECL, is DECL_FIELD_BIT_OFFSET.\n      In PARM_DECL, holds an RTL for the stack slot\n      of register where the data was actually passed.\n      Used by Chill and Java in LABEL_DECL and by C++ and Java in VAR_DECL.  */\n@@ -1471,7 +1487,11 @@ enum tree_index\n \n   TI_SIZE_ZERO,\n   TI_SIZE_ONE,\n-    \n+\n+  TI_BITSIZE_ZERO,\n+  TI_BITSIZE_ONE,\n+  TI_BITSIZE_UNIT,\n+\n   TI_COMPLEX_INTEGER_TYPE,\n   TI_COMPLEX_FLOAT_TYPE,\n   TI_COMPLEX_DOUBLE_TYPE,\n@@ -1510,6 +1530,10 @@ extern tree global_trees[TI_MAX];\n #define integer_one_node\t\tglobal_trees[TI_INTEGER_ONE]\n #define size_zero_node\t\t\tglobal_trees[TI_SIZE_ZERO]\n #define size_one_node\t\t\tglobal_trees[TI_SIZE_ONE]\n+#define bitsize_zero_node\t\tglobal_trees[TI_BITSIZE_ZERO]\n+#define bitsize_one_node\t\tglobal_trees[TI_BITSIZE_ONE]\n+#define bitsize_unit_node\t\tglobal_trees[TI_BITSIZE_UNIT]\n+\n #define null_pointer_node\t\tglobal_trees[TI_NULL_POINTER]\n \n #define float_type_node\t\t\tglobal_trees[TI_FLOAT_TYPE]\n@@ -1749,37 +1773,37 @@ extern void layout_type\t\t\tPARAMS ((tree));\n /* These functions allow a front-end to perform a manual layout of a\n    RECORD_TYPE.  (For instance, if the placement of subsequent fields\n    depends on the placement of fields so far.)  Begin by calling\n-   new_record_layout_info.  Then, call layout_field for each of the\n+   start_record_layout.  Then, call place_field for each of the\n    fields.  Then, call finish_record_layout.  See layout_type for the\n    default way in which these functions are used.  */\n \n-struct record_layout_info_s\n+typedef struct record_layout_info\n {\n   /* The RECORD_TYPE that we are laying out.  */\n   tree t;\n-  /* The size of the record so far, in bits.  */\n-  unsigned HOST_WIDE_INT const_size;\n+  /* The offset into the record so far, in bytes, not including bits in\n+     BITPOS.  */\n+  tree offset;\n+  /* The last known alignment of SIZE.  */\n+  unsigned int offset_align;\n+  /* The bit position within the last OFFSET_ALIGN bits, in bits.  */\n+  tree bitpos;\n   /* The alignment of the record so far, in bits.  */\n   unsigned int record_align;\n-  /* If the record can have a variable size, then this will be\n-     non-NULL, and the total size will be CONST_SIZE + VAR_SIZE.  */\n-  tree var_size;\n-  /* If the record can have a variable size, then this will be the\n-     maximum alignment that we know VAR_SIZE has.  */\n-  unsigned int var_align;\n+  /* The alignment of the record so far, not including padding, in bits.  */\n+  unsigned int unpacked_align;\n   /* The static variables (i.e., class variables, as opposed to\n      instance variables) encountered in T.  */\n   tree pending_statics;\n-  unsigned int unpacked_align;\n   int packed_maybe_necessary;\n-};\n-\n-typedef struct record_layout_info_s *record_layout_info;\n+} *record_layout_info;\n \n-extern record_layout_info new_record_layout_info \n-                                        PARAMS ((tree));\n-extern void layout_field                PARAMS ((record_layout_info, tree));\n-extern void finish_record_layout        PARAMS ((record_layout_info));\n+extern record_layout_info start_record_layout PARAMS ((tree));\n+extern tree rli_size_unit_so_far\tPARAMS ((record_layout_info));\n+extern tree rli_size_so_far\t\tPARAMS ((record_layout_info));\n+extern void normalize_rli\t\tPARAMS ((record_layout_info));\n+extern void place_field\t\t\tPARAMS ((record_layout_info, tree));\n+extern void finish_record_layout\tPARAMS ((record_layout_info));\n \n /* Given a hashcode and a ..._TYPE node (for which the hashcode was made),\n    return a canonicalized ..._TYPE node, so that duplicates are not made.\n@@ -1817,6 +1841,8 @@ extern tree size_in_bytes\t\tPARAMS ((tree));\n extern HOST_WIDE_INT int_size_in_bytes\tPARAMS ((tree));\n extern tree bit_position\t\tPARAMS ((tree));\n extern HOST_WIDE_INT int_bit_position\tPARAMS ((tree));\n+extern tree byte_position\t\tPARAMS ((tree));\n+extern HOST_WIDE_INT int_byte_position\tPARAMS ((tree));\n \n /* Define data structures, macros, and functions for handling sizes\n    and the various types used to represent sizes.  */\n@@ -2060,9 +2086,10 @@ extern tree maybe_build_cleanup\t\tPARAMS ((tree));\n    look for nested component-refs or array-refs at constant positions\n    and find the ultimate containing object, which is returned.  */\n \n-extern tree get_inner_reference\t\tPARAMS ((tree, int *, int *, tree *,\n-\t\t\t\t\t       enum machine_mode *, int *,\n-\t\t\t\t\t       int *, unsigned int *));\n+extern tree get_inner_reference\t\tPARAMS ((tree, HOST_WIDE_INT *,\n+\t\t\t\t\t\t HOST_WIDE_INT *, tree *,\n+\t\t\t\t\t\t enum machine_mode *, int *,\n+\t\t\t\t\t\t int *, unsigned int *));\n \n /* Given a DECL or TYPE, return the scope in which it was declared, or\n    NUL_TREE if there is no containing scope.  */"}, {"sha": "aa8f3eeeaf0f5639584b10efebf6e78cca85d014", "filename": "gcc/unroll.c", "status": "modified", "additions": 32, "deletions": 30, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Funroll.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Funroll.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Funroll.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -196,7 +196,7 @@ static int *splittable_regs_updates;\n /* Forward declarations.  */\n \n static void init_reg_map PARAMS ((struct inline_remap *, int));\n-static rtx calculate_giv_inc PARAMS ((rtx, rtx, int));\n+static rtx calculate_giv_inc PARAMS ((rtx, rtx, unsigned int));\n static rtx initial_reg_note_copy PARAMS ((rtx, struct inline_remap *));\n static void final_reg_note_copy PARAMS ((rtx, struct inline_remap *));\n static void copy_loop_body PARAMS ((rtx, rtx, struct inline_remap *, rtx, int,\n@@ -234,6 +234,7 @@ unroll_loop (loop, insn_count, end_insert_before, strength_reduce_p)\n      int strength_reduce_p;\n {\n   int i, j;\n+  unsigned int r;\n   unsigned HOST_WIDE_INT temp;\n   int unroll_number = 1;\n   rtx copy_start, copy_end;\n@@ -243,8 +244,8 @@ unroll_loop (loop, insn_count, end_insert_before, strength_reduce_p)\n   struct inline_remap *map;\n   char *local_label = NULL;\n   char *local_regno;\n-  int max_local_regnum;\n-  int maxregnum;\n+  unsigned int max_local_regnum;\n+  unsigned int maxregnum;\n   rtx exit_label = 0;\n   rtx start_label;\n   struct iv_class *bl;\n@@ -829,11 +830,11 @@ unroll_loop (loop, insn_count, end_insert_before, strength_reduce_p)\n \t results in better code.  */\n       /* We must limit the generic test to max_reg_before_loop, because only\n \t these pseudo registers have valid regno_first_uid info.  */\n-      for (j = FIRST_PSEUDO_REGISTER; j < max_reg_before_loop; ++j)\n-\tif (REGNO_FIRST_UID (j) > 0 && REGNO_FIRST_UID (j) <= max_uid_for_loop\n-\t    && uid_luid[REGNO_FIRST_UID (j)] >= copy_start_luid\n-\t    && REGNO_LAST_UID (j) > 0 && REGNO_LAST_UID (j) <= max_uid_for_loop\n-\t    && uid_luid[REGNO_LAST_UID (j)] <= copy_end_luid)\n+      for (r = FIRST_PSEUDO_REGISTER; r < max_reg_before_loop; ++r)\n+\tif (REGNO_FIRST_UID (r) > 0 && REGNO_FIRST_UID (r) <= max_uid_for_loop\n+\t    && uid_luid[REGNO_FIRST_UID (r)] >= copy_start_luid\n+\t    && REGNO_LAST_UID (r) > 0 && REGNO_LAST_UID (r) <= max_uid_for_loop\n+\t    && uid_luid[REGNO_LAST_UID (r)] <= copy_end_luid)\n \t  {\n \t    /* However, we must also check for loop-carried dependencies.\n \t       If the value the pseudo has at the end of iteration X is\n@@ -844,26 +845,26 @@ unroll_loop (loop, insn_count, end_insert_before, strength_reduce_p)\n \t       regno_last_uid.  */\n \t    /* ??? This check is simplistic.  We would get better code if\n \t       this check was more sophisticated.  */\n-\t    if (set_dominates_use (j, REGNO_FIRST_UID (j), REGNO_LAST_UID (j),\n+\t    if (set_dominates_use (r, REGNO_FIRST_UID (r), REGNO_LAST_UID (r),\n \t\t\t\t   copy_start, copy_end))\n-\t      local_regno[j] = 1;\n+\t      local_regno[r] = 1;\n \n \t    if (loop_dump_stream)\n \t      {\n-\t\tif (local_regno[j])\n-\t\t  fprintf (loop_dump_stream, \"Marked reg %d as local\\n\", j);\n+\t\tif (local_regno[r])\n+\t\t  fprintf (loop_dump_stream, \"Marked reg %d as local\\n\", r);\n \t\telse\n \t\t  fprintf (loop_dump_stream, \"Did not mark reg %d as local\\n\",\n-\t\t\t   j);\n+\t\t\t   r);\n \t      }\n \t  }\n       /* Givs that have been created from multiple biv increments always have\n \t local registers.  */\n-      for (j = first_increment_giv; j <= last_increment_giv; j++)\n+      for (r = first_increment_giv; r <= last_increment_giv; r++)\n \t{\n-\t  local_regno[j] = 1;\n+\t  local_regno[r] = 1;\n \t  if (loop_dump_stream)\n-\t    fprintf (loop_dump_stream, \"Marked reg %d as local\\n\", j);\n+\t    fprintf (loop_dump_stream, \"Marked reg %d as local\\n\", r);\n \t}\n     }\n \n@@ -1080,12 +1081,13 @@ unroll_loop (loop, insn_count, end_insert_before, strength_reduce_p)\n \t\tif (local_label[j])\n \t\t  set_label_in_map (map, j, gen_label_rtx ());\n \n-\t      for (j = FIRST_PSEUDO_REGISTER; j < max_local_regnum; j++)\n-\t\tif (local_regno[j])\n+\t      for (r = FIRST_PSEUDO_REGISTER; r < max_local_regnum; r++)\n+\t\tif (local_regno[r])\n \t\t  {\n-\t\t    map->reg_map[j] = gen_reg_rtx (GET_MODE (regno_reg_rtx[j]));\n-\t\t    record_base_value (REGNO (map->reg_map[j]),\n-\t\t\t\t       regno_reg_rtx[j], 0);\n+\t\t    map->reg_map[r]\n+\t\t      = gen_reg_rtx (GET_MODE (regno_reg_rtx[r]));\n+\t\t    record_base_value (REGNO (map->reg_map[r]),\n+\t\t\t\t       regno_reg_rtx[r], 0);\n \t\t  }\n \t      /* The last copy needs the compare/branch insns at the end,\n \t\t so reset copy_end here if the loop ends with a conditional\n@@ -1223,12 +1225,12 @@ unroll_loop (loop, insn_count, end_insert_before, strength_reduce_p)\n \tif (local_label[j])\n \t  set_label_in_map (map, j, gen_label_rtx ());\n \n-      for (j = FIRST_PSEUDO_REGISTER; j < max_local_regnum; j++)\n-\tif (local_regno[j])\n+      for (r = FIRST_PSEUDO_REGISTER; r < max_local_regnum; r++)\n+\tif (local_regno[r])\n \t  {\n-\t    map->reg_map[j] = gen_reg_rtx (GET_MODE (regno_reg_rtx[j]));\n-\t    record_base_value (REGNO (map->reg_map[j]),\n-\t\t\t       regno_reg_rtx[j], 0);\n+\t    map->reg_map[r] = gen_reg_rtx (GET_MODE (regno_reg_rtx[r]));\n+\t    record_base_value (REGNO (map->reg_map[r]),\n+\t\t\t       regno_reg_rtx[r], 0);\n \t  }\n \n       /* If loop starts with a branch to the test, then fix it so that\n@@ -1532,7 +1534,7 @@ init_reg_map (map, maxregnum)\n static rtx\n calculate_giv_inc (pattern, src_insn, regno)\n      rtx pattern, src_insn;\n-     int regno;\n+     unsigned int regno;\n {\n   rtx increment;\n   rtx increment_total = 0;\n@@ -1763,7 +1765,7 @@ copy_loop_body (copy_start, copy_end, map, exit_label, last_iteration,\n \t    {\n \t      struct iv_class *bl;\n \t      struct induction *v, *tv;\n-\t      int regno = REGNO (SET_DEST (set));\n+\t      unsigned int regno = REGNO (SET_DEST (set));\n \n \t      v = addr_combined_regs[REGNO (SET_DEST (set))];\n \t      bl = reg_biv_class[REGNO (v->src_reg)];\n@@ -1856,8 +1858,8 @@ copy_loop_body (copy_start, copy_end, map, exit_label, last_iteration,\n \t      && GET_CODE (SET_DEST (set)) == REG\n \t      && splittable_regs[REGNO (SET_DEST (set))])\n \t    {\n-\t      int regno = REGNO (SET_DEST (set));\n-\t      int src_regno;\n+\t      unsigned int regno = REGNO (SET_DEST (set));\n+\t      unsigned int src_regno;\n \n \t      dest_reg_was_split = 1;\n "}, {"sha": "442fca2589216b8452d184379a6642364a05975c", "filename": "gcc/varasm.c", "status": "modified", "additions": 29, "deletions": 45, "changes": 74, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fvarasm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78/gcc%2Fvarasm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvarasm.c?ref=770ae6cc710a7a0f7db4ef7f09941bbe19d0ee78", "patch": "@@ -1331,7 +1331,6 @@ assemble_variable (decl, top_level, at_end, dont_output_data)\n {\n   register const char *name;\n   unsigned int align;\n-  tree size_tree = NULL_TREE;\n   int reloc = 0;\n   enum in_section saved_in_section;\n \n@@ -1423,21 +1422,11 @@ assemble_variable (decl, top_level, at_end, dont_output_data)\n \n   app_disable ();\n \n-  if (! dont_output_data)\n+  if (! dont_output_data\n+      && ! host_integerp (DECL_SIZE_UNIT (decl), 1))\n     {\n-      unsigned int size;\n-\n-      if (TREE_CODE (DECL_SIZE_UNIT (decl)) != INTEGER_CST)\n-\tgoto finish;\n-\n-      size_tree = DECL_SIZE_UNIT (decl);\n-      size = TREE_INT_CST_LOW (size_tree);\n-\n-      if (compare_tree_int (size_tree, size) != 0)\n-\t{\n-\t  error_with_decl (decl, \"size of variable `%s' is too large\");\n-\t  goto finish;\n-\t}\n+      error_with_decl (decl, \"size of variable `%s' is too large\");\n+      goto finish;\n     }\n \n   name = XSTR (XEXP (DECL_RTL (decl), 0), 0);\n@@ -1503,20 +1492,22 @@ assemble_variable (decl, top_level, at_end, dont_output_data)\n       && DECL_SECTION_NAME (decl) == NULL_TREE\n       && ! dont_output_data)\n     {\n-      int size = TREE_INT_CST_LOW (size_tree);\n-      int rounded = size;\n+      unsigned HOST_WIDE_INT size = tree_low_cst (DECL_SIZE_UNIT (decl), 1);\n+      unsigned HOST_WIDE_INT rounded = size;\n \n       /* Don't allocate zero bytes of common,\n \t since that means \"undefined external\" in the linker.  */\n-      if (size == 0) rounded = 1;\n+      if (size == 0)\n+\trounded = 1;\n+\n       /* Round size up to multiple of BIGGEST_ALIGNMENT bits\n \t so that each uninitialized object starts on such a boundary.  */\n       rounded += (BIGGEST_ALIGNMENT / BITS_PER_UNIT) - 1;\n       rounded = (rounded / (BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n \t\t * (BIGGEST_ALIGNMENT / BITS_PER_UNIT));\n       \n #if !defined(ASM_OUTPUT_ALIGNED_COMMON) && !defined(ASM_OUTPUT_ALIGNED_BSS)\n-      if ((DECL_ALIGN (decl) / BITS_PER_UNIT) > (unsigned int) rounded)\n+      if (DECL_ALIGN (decl) / BITS_PER_UNIT > rounded)\n          warning_with_decl \n            (decl, \"requested alignment for %s is greater than implemented alignment of %d.\",rounded);\n #endif\n@@ -1650,10 +1641,11 @@ assemble_variable (decl, top_level, at_end, dont_output_data)\n     {\n       if (DECL_INITIAL (decl))\n \t/* Output the actual data.  */\n-\toutput_constant (DECL_INITIAL (decl), TREE_INT_CST_LOW (size_tree));\n+\toutput_constant (DECL_INITIAL (decl),\n+\t\t\t tree_low_cst (DECL_SIZE_UNIT (decl), 1));\n       else\n \t/* Leave space for it.  */\n-\tassemble_zeros (TREE_INT_CST_LOW (size_tree));\n+\tassemble_zeros (tree_low_cst (DECL_SIZE_UNIT (decl), 1));\n     }\n \n  finish:\n@@ -2279,22 +2271,16 @@ decode_addr_const (exp, value)\n   while (1)\n     {\n       if (TREE_CODE (target) == COMPONENT_REF\n-\t  && host_integerp (bit_position (TREE_OPERAND (target, 1)), 0))\n+\t  && host_integerp (byte_position (TREE_OPERAND (target, 1)), 0))\n \n \t{\n-\t  offset\n-\t    += int_bit_position (TREE_OPERAND (target, 1)) / BITS_PER_UNIT;\n-\n+\t  offset += int_byte_position (TREE_OPERAND (target, 1));\n \t  target = TREE_OPERAND (target, 0);\n \t}\n       else if (TREE_CODE (target) == ARRAY_REF)\n \t{\n-\t  if (TREE_CODE (TREE_OPERAND (target, 1)) != INTEGER_CST\n-\t      || TREE_CODE (TYPE_SIZE (TREE_TYPE (target))) != INTEGER_CST)\n-\t    abort ();\n-\t  offset += ((TREE_INT_CST_LOW (TYPE_SIZE (TREE_TYPE (target)))\n-\t\t      * TREE_INT_CST_LOW (TREE_OPERAND (target, 1)))\n-\t\t     / BITS_PER_UNIT);\n+\t  offset += (tree_low_cst (TYPE_SIZE_UNIT (TREE_TYPE (target)), 1)\n+\t\t     * tree_low_cst (TREE_OPERAND (target, 1), 0));\n \t  target = TREE_OPERAND (target, 0);\n \t}\n       else\n@@ -4420,13 +4406,12 @@ output_constructor (exp, size)\n \t  register int fieldsize;\n \t  /* Since this structure is static,\n \t     we know the positions are constant.  */\n-\t  int bitpos = (field ? (TREE_INT_CST_LOW (DECL_FIELD_BITPOS (field))\n-\t\t\t\t / BITS_PER_UNIT)\n-\t\t\t: 0);\n+\t  HOST_WIDE_INT bitpos = field ? int_byte_position (field) : 0;\n+\n \t  if (index != 0)\n-\t    bitpos = (TREE_INT_CST_LOW (TYPE_SIZE (TREE_TYPE (val)))\n-\t\t      / BITS_PER_UNIT\n-\t\t      * (TREE_INT_CST_LOW (index) - min_index));\n+\t    bitpos\n+\t      = (tree_low_cst (TYPE_SIZE_UNIT (TREE_TYPE (val)), 1)\n+\t\t* (tree_low_cst (index, 0) - min_index));\n \n \t  /* Output any buffered-up bit-fields preceding this element.  */\n \t  if (byte_buffer_in_use)\n@@ -4472,9 +4457,9 @@ output_constructor (exp, size)\n \t{\n \t  /* Element that is a bit-field.  */\n \n-\t  int next_offset = TREE_INT_CST_LOW (DECL_FIELD_BITPOS (field));\n-\t  int end_offset\n-\t    = (next_offset + TREE_INT_CST_LOW (DECL_SIZE (field)));\n+\t  HOST_WIDE_INT next_offset = int_bit_position (field);\n+\t  HOST_WIDE_INT end_offset\n+\t    = (next_offset + tree_low_cst (DECL_SIZE (field), 1));\n \n \t  if (val == 0)\n \t    val = integer_zero_node;\n@@ -4572,17 +4557,15 @@ output_constructor (exp, size)\n \t\t     take first the least significant bits of the value\n \t\t     and pack them starting at the least significant\n \t\t     bits of the bytes.  */\n-\t\t  shift = (next_offset\n-\t\t\t   - TREE_INT_CST_LOW (DECL_FIELD_BITPOS (field)));\n+\t\t  shift = next_offset - int_bit_position (field);\n+\n \t\t  /* Don't try to take a bunch of bits that cross\n \t\t     the word boundary in the INTEGER_CST. We can\n \t\t     only select bits from the LOW or HIGH part\n \t\t     not from both.  */\n \t\t  if (shift < HOST_BITS_PER_WIDE_INT\n \t\t      && shift + this_time > HOST_BITS_PER_WIDE_INT)\n-\t\t    {\n-\t\t      this_time = (HOST_BITS_PER_WIDE_INT - shift);\n-\t\t    }\n+\t\t    this_time = (HOST_BITS_PER_WIDE_INT - shift);\n \n \t\t  /* Now get the bits from the appropriate constant word.  */\n \t\t  if (shift < HOST_BITS_PER_WIDE_INT)\n@@ -4594,6 +4577,7 @@ output_constructor (exp, size)\n \t\t    }\n \t\t  else\n \t\t    abort ();\n+\n \t\t  /* Get the result. This works only when:\n \t\t     1 <= this_time <= HOST_BITS_PER_WIDE_INT.  */\n \t\t  byte |= (((value >> shift)"}]}