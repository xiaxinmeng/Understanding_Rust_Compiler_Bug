{"sha": "d8099dd8599b3fb226b451a1d421046ace4c6307", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDgwOTlkZDg1OTliM2ZiMjI2YjQ1MWExZDQyMTA0NmFjZTRjNjMwNw==", "commit": {"author": {"name": "Julian Brown", "email": "julian@codesourcery.com", "date": "2010-08-25T15:35:24Z"}, "committer": {"name": "Mark Mitchell", "email": "mmitchel@gcc.gnu.org", "date": "2010-08-25T15:35:24Z"}, "message": "arm.c (arm_issue_rate): Return 2 for Cortex-A5.\n\n\t* config/arm/arm.c (arm_issue_rate): Return 2 for Cortex-A5.\n\t* config/arm/arm.md (generic_sched): No for Cortex-A5.\n\t(generic_vfp): Likewise.\n\t(cortex-a5.md): Include.\n\t* config/arm/cortex-a5.md: New.\n\nFrom-SVN: r163550", "tree": {"sha": "af08893860f81e89e39d9a7000468d63ea9e801b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/af08893860f81e89e39d9a7000468d63ea9e801b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d8099dd8599b3fb226b451a1d421046ace4c6307", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d8099dd8599b3fb226b451a1d421046ace4c6307", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d8099dd8599b3fb226b451a1d421046ace4c6307", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d8099dd8599b3fb226b451a1d421046ace4c6307/comments", "author": {"login": "jtb20", "id": 6094880, "node_id": "MDQ6VXNlcjYwOTQ4ODA=", "avatar_url": "https://avatars.githubusercontent.com/u/6094880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jtb20", "html_url": "https://github.com/jtb20", "followers_url": "https://api.github.com/users/jtb20/followers", "following_url": "https://api.github.com/users/jtb20/following{/other_user}", "gists_url": "https://api.github.com/users/jtb20/gists{/gist_id}", "starred_url": "https://api.github.com/users/jtb20/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jtb20/subscriptions", "organizations_url": "https://api.github.com/users/jtb20/orgs", "repos_url": "https://api.github.com/users/jtb20/repos", "events_url": "https://api.github.com/users/jtb20/events{/privacy}", "received_events_url": "https://api.github.com/users/jtb20/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "0ceb0201344a65bab37d6933601df77a512c334e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0ceb0201344a65bab37d6933601df77a512c334e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0ceb0201344a65bab37d6933601df77a512c334e"}], "stats": {"total": 311, "additions": 309, "deletions": 2}, "files": [{"sha": "bb6ebd99bdc9e7f57cdb78262f2ed3af49a52d0a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d8099dd8599b3fb226b451a1d421046ace4c6307", "patch": "@@ -1,3 +1,11 @@\n+2010-08-25  Julian Brown  <julian@codesourcery.com>\n+\n+\t* config/arm/arm.c (arm_issue_rate): Return 2 for Cortex-A5.\n+\t* config/arm/arm.md (generic_sched): No for Cortex-A5.\n+\t(generic_vfp): Likewise.\n+\t(cortex-a5.md): Include.\n+\t* config/arm/cortex-a5.md: New.\n+\n 2010-08-25  Richard Guenther  <rguenther@suse.de>\n \n \t* alias.c (get_alias_set): Assign a single alias-set to"}, {"sha": "c5c0b0340f18d1c1e230cbb2f1851152064a83a0", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=d8099dd8599b3fb226b451a1d421046ace4c6307", "patch": "@@ -22446,6 +22446,7 @@ arm_issue_rate (void)\n     {\n     case cortexr4:\n     case cortexr4f:\n+    case cortexa5:\n     case cortexa8:\n     case cortexa9:\n       return 2;"}, {"sha": "70273d58c3815cb7358040dadb2f089b6a45e9e2", "filename": "gcc/config/arm/arm.md", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2Fconfig%2Farm%2Farm.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2Fconfig%2Farm%2Farm.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.md?ref=d8099dd8599b3fb226b451a1d421046ace4c6307", "patch": "@@ -495,15 +495,15 @@\n \n (define_attr \"generic_sched\" \"yes,no\"\n   (const (if_then_else \n-          (ior (eq_attr \"tune\" \"arm926ejs,arm1020e,arm1026ejs,arm1136js,arm1136jfs,cortexa8,cortexa9\")\n+          (ior (eq_attr \"tune\" \"arm926ejs,arm1020e,arm1026ejs,arm1136js,arm1136jfs,cortexa5,cortexa8,cortexa9\")\n \t      (eq_attr \"tune_cortexr4\" \"yes\"))\n           (const_string \"no\")\n           (const_string \"yes\"))))\n \n (define_attr \"generic_vfp\" \"yes,no\"\n   (const (if_then_else\n \t  (and (eq_attr \"fpu\" \"vfp\")\n-\t       (eq_attr \"tune\" \"!arm1020e,arm1022e,cortexa8,cortexa9\")\n+\t       (eq_attr \"tune\" \"!arm1020e,arm1022e,cortexa5,cortexa8,cortexa9\")\n \t       (eq_attr \"tune_cortexr4\" \"no\"))\n \t  (const_string \"yes\")\n \t  (const_string \"no\"))))\n@@ -513,6 +513,7 @@\n (include \"arm1020e.md\")\n (include \"arm1026ejs.md\")\n (include \"arm1136jfs.md\")\n+(include \"cortex-a5.md\")\n (include \"cortex-a8.md\")\n (include \"cortex-a9.md\")\n (include \"cortex-r4.md\")"}, {"sha": "471f588022e09ccc4f4e861ef06ce627c0d3ce4f", "filename": "gcc/config/arm/cortex-a5.md", "status": "added", "additions": 297, "deletions": 0, "changes": 297, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2Fconfig%2Farm%2Fcortex-a5.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8099dd8599b3fb226b451a1d421046ace4c6307/gcc%2Fconfig%2Farm%2Fcortex-a5.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcortex-a5.md?ref=d8099dd8599b3fb226b451a1d421046ace4c6307", "patch": "@@ -0,0 +1,297 @@\n+;; ARM Cortex-A5 pipeline description\n+;; Copyright (C) 2010 Free Software Foundation, Inc.\n+;; Contributed by CodeSourcery.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify it\n+;; under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful, but\n+;; WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+;; General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_automaton \"cortex_a5\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Functional units.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; The integer (ALU) pipeline.  There are five DPU pipeline\n+;; stages. However the decode/issue stages operate the same for all\n+;; instructions, so do not model them.  We only need to model the\n+;; first execute stage because instructions always advance one stage\n+;; per cycle in order.  Only branch instructions may dual-issue, so a\n+;; single unit covers all of the LS, ALU, MAC and FPU pipelines.\n+\n+(define_cpu_unit \"cortex_a5_ex1\" \"cortex_a5\")\n+\n+;; The branch pipeline.  Branches can dual-issue with other instructions\n+;; (except when those instructions take multiple cycles to issue).\n+\n+(define_cpu_unit \"cortex_a5_branch\" \"cortex_a5\")\n+\n+;; Pseudo-unit for blocking the multiply pipeline when a double-precision\n+;; multiply is in progress.\n+\n+(define_cpu_unit \"cortex_a5_fpmul_pipe\" \"cortex_a5\")\n+\n+;; The floating-point add pipeline (ex1/f1 stage), used to model the usage\n+;; of the add pipeline by fmac instructions, etc.\n+\n+(define_cpu_unit \"cortex_a5_fpadd_pipe\" \"cortex_a5\")\n+\n+;; Floating-point div/sqrt (long latency, out-of-order completion).\n+\n+(define_cpu_unit \"cortex_a5_fp_div_sqrt\" \"cortex_a5\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; ALU instructions.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+(define_insn_reservation \"cortex_a5_alu\" 2\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"alu\"))\n+  \"cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_alu_shift\" 2\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"alu_shift,alu_shift_reg\"))\n+  \"cortex_a5_ex1\")\n+\n+;; Forwarding path for unshifted operands.\n+\n+(define_bypass 1 \"cortex_a5_alu,cortex_a5_alu_shift\"\n+  \"cortex_a5_alu\")\n+\n+(define_bypass 1 \"cortex_a5_alu,cortex_a5_alu_shift\"\n+  \"cortex_a5_alu_shift\"\n+  \"arm_no_early_alu_shift_dep\")\n+\n+;; The multiplier pipeline can forward results from wr stage only so \n+;; there's no need to specify bypasses).\n+\n+(define_insn_reservation \"cortex_a5_mul\" 2\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"mult\"))\n+  \"cortex_a5_ex1\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Load/store instructions.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; Address-generation happens in the issue stage, which is one stage behind\n+;; the ex1 stage (the first stage we care about for scheduling purposes). The\n+;; dc1 stage is parallel with ex1, dc2 with ex2 and rot with wr.\n+\n+(define_insn_reservation \"cortex_a5_load1\" 2\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"load_byte,load1\"))\n+  \"cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_store1\" 0\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"store1\"))\n+  \"cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_load2\" 3\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"load2\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_store2\" 0\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"store2\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_load3\" 4\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"load3\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1+cortex_a5_branch,\\\n+   cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_store3\" 0\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"store3\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1+cortex_a5_branch,\\\n+   cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_load4\" 5\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"load3\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1+cortex_a5_branch,\\\n+   cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_store4\" 0\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"store3\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1+cortex_a5_branch,\\\n+   cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Branches.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; Direct branches are the only instructions we can dual-issue (also IT and\n+;; nop, but those aren't very interesting for scheduling).  (The latency here\n+;; is meant to represent when the branch actually takes place, but may not be\n+;; entirely correct.)\n+\n+(define_insn_reservation \"cortex_a5_branch\" 3\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"branch,call\"))\n+  \"cortex_a5_branch\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Floating-point arithmetic.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+(define_insn_reservation \"cortex_a5_fpalu\" 4\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"ffariths, fadds, ffarithd, faddd, fcpys, fmuls, f_cvt,\\\n+\t\t\tfcmps, fcmpd\"))\n+  \"cortex_a5_ex1+cortex_a5_fpadd_pipe\")\n+\n+;; For fconsts and fconstd, 8-bit immediate data is passed directly from\n+;; f1 to f3 (which I think reduces the latency by one cycle).\n+\n+(define_insn_reservation \"cortex_a5_fconst\" 3\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"fconsts,fconstd\"))\n+  \"cortex_a5_ex1+cortex_a5_fpadd_pipe\")\n+\n+;; We should try not to attempt to issue a single-precision multiplication in\n+;; the middle of a double-precision multiplication operation (the usage of\n+;; cortex_a5_fpmul_pipe).\n+\n+(define_insn_reservation \"cortex_a5_fpmuls\" 4\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"fmuls\"))\n+  \"cortex_a5_ex1+cortex_a5_fpmul_pipe\")\n+\n+;; For single-precision multiply-accumulate, the add (accumulate) is issued\n+;; whilst the multiply is in F4.  The multiply result can then be forwarded\n+;; from F5 to F1.  The issue unit is only used once (when we first start\n+;; processing the instruction), but the usage of the FP add pipeline could\n+;; block other instructions attempting to use it simultaneously.  We try to\n+;; avoid that using cortex_a5_fpadd_pipe.\n+\n+(define_insn_reservation \"cortex_a5_fpmacs\" 8\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"fmacs\"))\n+  \"cortex_a5_ex1+cortex_a5_fpmul_pipe, nothing*3, cortex_a5_fpadd_pipe\")\n+\n+;; Non-multiply instructions can issue in the middle two instructions of a\n+;; double-precision multiply.  Note that it isn't entirely clear when a branch\n+;; can dual-issue when a multi-cycle multiplication is in progress; we ignore\n+;; that for now though.\n+\n+(define_insn_reservation \"cortex_a5_fpmuld\" 7\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"fmuld\"))\n+  \"cortex_a5_ex1+cortex_a5_fpmul_pipe, cortex_a5_fpmul_pipe*2,\\\n+   cortex_a5_ex1+cortex_a5_fpmul_pipe\")\n+\n+(define_insn_reservation \"cortex_a5_fpmacd\" 11\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"fmacd\"))\n+  \"cortex_a5_ex1+cortex_a5_fpmul_pipe, cortex_a5_fpmul_pipe*2,\\\n+   cortex_a5_ex1+cortex_a5_fpmul_pipe, nothing*3, cortex_a5_fpadd_pipe\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Floating-point divide/square root instructions.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; ??? Not sure if the 14 cycles taken for single-precision divide to complete\n+;; includes the time taken for the special instruction used to collect the\n+;; result to travel down the multiply pipeline, or not.  Assuming so.  (If\n+;; that's wrong, the latency should be increased by a few cycles.)\n+\n+;; fsqrt takes one cycle less, but that is not modelled, nor is the use of the\n+;; multiply pipeline to collect the divide/square-root result.\n+\n+(define_insn_reservation \"cortex_a5_fdivs\" 14\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"fdivs\"))\n+  \"cortex_a5_ex1, cortex_a5_fp_div_sqrt * 13\")\n+\n+;; ??? Similarly for fdivd.\n+\n+(define_insn_reservation \"cortex_a5_fdivd\" 29\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"fdivd\"))\n+  \"cortex_a5_ex1, cortex_a5_fp_div_sqrt * 28\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; VFP to/from core transfers.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; FP loads take data from wr/rot/f3.\n+\n+;; Core-to-VFP transfers use the multiply pipeline.\n+\n+(define_insn_reservation \"cortex_a5_r2f\" 4\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"r_2_f\"))\n+  \"cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_f2r\" 2\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"f_2_r\"))\n+  \"cortex_a5_ex1\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; VFP flag transfer.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; ??? The flag forwarding from fmstat to the ex2 stage of the second\n+;; instruction is not modeled at present.\n+\n+(define_insn_reservation \"cortex_a5_f_flags\" 4\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"f_flag\"))\n+  \"cortex_a5_ex1\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; VFP load/store.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+(define_insn_reservation \"cortex_a5_f_loads\" 4\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"f_loads\"))\n+  \"cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_f_loadd\" 5\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"f_load,f_loadd\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_f_stores\" 0\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"f_stores\"))\n+  \"cortex_a5_ex1\")\n+\n+(define_insn_reservation \"cortex_a5_f_stored\" 0\n+  (and (eq_attr \"tune\" \"cortexa5\")\n+       (eq_attr \"type\" \"f_store,f_stored\"))\n+  \"cortex_a5_ex1+cortex_a5_branch, cortex_a5_ex1\")\n+\n+;; Load-to-use for floating-point values has a penalty of one cycle,\n+;; i.e. a latency of two.\n+\n+(define_bypass 2 \"cortex_a5_f_loads\"\n+                 \"cortex_a5_fpalu, cortex_a5_fpmacs, cortex_a5_fpmuld,\\\n+\t\t  cortex_a5_fpmacd, cortex_a5_fdivs, cortex_a5_fdivd,\\\n+\t\t  cortex_a5_f2r\")\n+\n+(define_bypass 3 \"cortex_a5_f_loadd\"\n+                 \"cortex_a5_fpalu, cortex_a5_fpmacs, cortex_a5_fpmuld,\\\n+\t\t  cortex_a5_fpmacd, cortex_a5_fdivs, cortex_a5_fdivd,\\\n+\t\t  cortex_a5_f2r\")"}]}