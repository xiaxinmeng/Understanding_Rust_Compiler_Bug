{"sha": "b8a64b7f5d699776983eab2c07125523e96bc6ea", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjhhNjRiN2Y1ZDY5OTc3Njk4M2VhYjJjMDcxMjU1MjNlOTZiYzZlYQ==", "commit": {"author": {"name": "Claudiu Zissulescu", "email": "claziss@synopsys.com", "date": "2015-12-10T13:32:21Z"}, "committer": {"name": "Claudiu Zissulescu", "email": "claziss@gcc.gnu.org", "date": "2015-12-10T13:32:21Z"}, "message": "[ARC] Add support for atomic memory built-in.\n\ngcc/\n\n2015-12-10  Claudiu Zissulescu  <claziss@synopsys.com>\n\n\t* config/arc/arc-protos.h (arc_expand_atomic_op): Prototype.\n\t(arc_split_compare_and_swap): Likewise.\n\t(arc_expand_compare_and_swap): Likewise.\n\t* config/arc/arc.c (arc_init): Check usage atomic option.\n\t(arc_pre_atomic_barrier): New function.\n\t(arc_post_atomic_barrier): Likewise.\n\t(emit_unlikely_jump): Likewise.\n\t(arc_expand_compare_and_swap_qh): Likewise.\n\t(arc_expand_compare_and_swap): Likewise.\n\t(arc_split_compare_and_swap): Likewise.\n\t(arc_expand_atomic_op): Likewise.\n\t* config/arc/arc.h (TARGET_CPU_CPP_BUILTINS): New C macro.\n\t(ASM_SPEC): Enable mlock option when matomic is used.\n\t* config/arc/arc.md (UNSPEC_ARC_MEMBAR): Define.\n\t(VUNSPEC_ARC_CAS): Likewise.\n\t(VUNSPEC_ARC_LL): Likewise.\n\t(VUNSPEC_ARC_SC): Likewise.\n\t(VUNSPEC_ARC_EX): Likewise.\n\t* config/arc/arc.opt (matomic): New option.\n\t* config/arc/constraints.md (ATO): New constraint.\n\t* config/arc/predicates.md (mem_noofs_operand): New predicate.\n\t* doc/invoke.texi: Document -matomic.\n\t* config/arc/atomic.md: New file.\n\ngcc/testsuite\n\n2015-12-10  Claudiu Zissulescu  <claziss@synopsys.com>\n\n\t* lib/target-supports.exp (check_effective_target_arc_atomic): New\n\tfunction.\n\t(check_effective_target_sync_int_long): Add checks for ARC atomic\n\tfeature.\n\t(check_effective_target_sync_char_short): Likewise.\n\nFrom-SVN: r231509", "tree": {"sha": "a9808e70899f6acf23ab79a385b0f2232a3e4e98", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a9808e70899f6acf23ab79a385b0f2232a3e4e98"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b8a64b7f5d699776983eab2c07125523e96bc6ea", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b8a64b7f5d699776983eab2c07125523e96bc6ea", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b8a64b7f5d699776983eab2c07125523e96bc6ea", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b8a64b7f5d699776983eab2c07125523e96bc6ea/comments", "author": {"login": "claziss", "id": 2761368, "node_id": "MDQ6VXNlcjI3NjEzNjg=", "avatar_url": "https://avatars.githubusercontent.com/u/2761368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/claziss", "html_url": "https://github.com/claziss", "followers_url": "https://api.github.com/users/claziss/followers", "following_url": "https://api.github.com/users/claziss/following{/other_user}", "gists_url": "https://api.github.com/users/claziss/gists{/gist_id}", "starred_url": "https://api.github.com/users/claziss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/claziss/subscriptions", "organizations_url": "https://api.github.com/users/claziss/orgs", "repos_url": "https://api.github.com/users/claziss/repos", "events_url": "https://api.github.com/users/claziss/events{/privacy}", "received_events_url": "https://api.github.com/users/claziss/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "41eefe133f91ffeead07774a8f68040135e5fe1c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/41eefe133f91ffeead07774a8f68040135e5fe1c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/41eefe133f91ffeead07774a8f68040135e5fe1c"}], "stats": {"total": 442, "additions": 440, "deletions": 2}, "files": [{"sha": "568381119c16d48f498616b2f203631938f1df1a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -1,3 +1,29 @@\n+2015-12-10  Claudiu Zissulescu  <claziss@synopsys.com>\n+\n+\t* config/arc/arc-protos.h (arc_expand_atomic_op): Prototype.\n+\t(arc_split_compare_and_swap): Likewise.\n+\t(arc_expand_compare_and_swap): Likewise.\n+\t* config/arc/arc.c (arc_init): Check usage atomic option.\n+\t(arc_pre_atomic_barrier): New function.\n+\t(arc_post_atomic_barrier): Likewise.\n+\t(emit_unlikely_jump): Likewise.\n+\t(arc_expand_compare_and_swap_qh): Likewise.\n+\t(arc_expand_compare_and_swap): Likewise.\n+\t(arc_split_compare_and_swap): Likewise.\n+\t(arc_expand_atomic_op): Likewise.\n+\t* config/arc/arc.h (TARGET_CPU_CPP_BUILTINS): New C macro.\n+\t(ASM_SPEC): Enable mlock option when matomic is used.\n+\t* config/arc/arc.md (UNSPEC_ARC_MEMBAR): Define.\n+\t(VUNSPEC_ARC_CAS): Likewise.\n+\t(VUNSPEC_ARC_LL): Likewise.\n+\t(VUNSPEC_ARC_SC): Likewise.\n+\t(VUNSPEC_ARC_EX): Likewise.\n+\t* config/arc/arc.opt (matomic): New option.\n+\t* config/arc/constraints.md (ATO): New constraint.\n+\t* config/arc/predicates.md (mem_noofs_operand): New predicate.\n+\t* doc/invoke.texi: Document -matomic.\n+\t* config/arc/atomic.md: New file.\n+\n 2015-12-10  Richard Biener  <rguenther@suse.de>\n \n \tPR tree-optimization/68817"}, {"sha": "3581bb0ed27b4a86ff8cc0902acb6f7c7f4f4e4d", "filename": "gcc/config/arc/arc-protos.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc-protos.h?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -41,6 +41,10 @@ extern int arc_output_commutative_cond_exec (rtx *operands, bool);\n extern bool arc_expand_movmem (rtx *operands);\n extern bool prepare_move_operands (rtx *operands, machine_mode mode);\n extern void emit_shift (enum rtx_code, rtx, rtx, rtx);\n+extern void arc_expand_atomic_op (enum rtx_code, rtx, rtx, rtx, rtx, rtx);\n+extern void arc_split_compare_and_swap (rtx *);\n+extern void arc_expand_compare_and_swap (rtx *);\n+\n #endif /* RTX_CODE */\n \n #ifdef TREE_CODE"}, {"sha": "5bc2bcebb2ad0b72757d4f9b3b57c015548c1a17", "filename": "gcc/config/arc/arc.c", "status": "modified", "additions": 357, "deletions": 0, "changes": 357, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.c?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -61,6 +61,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"context.h\"\n #include \"builtins.h\"\n #include \"rtl-iter.h\"\n+#include \"alias.h\"\n \n /* Which cpu we're compiling for (ARC600, ARC601, ARC700).  */\n static const char *arc_cpu_string = \"\";\n@@ -884,6 +885,9 @@ arc_init (void)\n       flag_pic = 0;\n     }\n \n+  if (TARGET_ATOMIC && !(TARGET_ARC700 || TARGET_HS))\n+    error (\"-matomic is only supported for ARC700 or ARC HS cores\");\n+\n   arc_init_reg_tables ();\n \n   /* Initialize array for PRINT_OPERAND_PUNCT_VALID_P.  */\n@@ -9650,6 +9654,359 @@ arc_use_by_pieces_infrastructure_p (unsigned HOST_WIDE_INT size,\n   return default_use_by_pieces_infrastructure_p (size, align, op, speed_p);\n }\n \n+/* Emit a (pre) memory barrier around an atomic sequence according to\n+   MODEL.  */\n+\n+static void\n+arc_pre_atomic_barrier (enum memmodel model)\n+{\n+  if (need_atomic_barrier_p (model, true))\n+    emit_insn (gen_memory_barrier ());\n+}\n+\n+/* Emit a (post) memory barrier around an atomic sequence according to\n+   MODEL.  */\n+\n+static void\n+arc_post_atomic_barrier (enum memmodel model)\n+{\n+  if (need_atomic_barrier_p (model, false))\n+    emit_insn (gen_memory_barrier ());\n+}\n+\n+/* Expand a compare and swap pattern.  */\n+\n+static void\n+emit_unlikely_jump (rtx insn)\n+{\n+  int very_unlikely = REG_BR_PROB_BASE / 100 - 1;\n+\n+  insn = emit_jump_insn (insn);\n+  add_int_reg_note (insn, REG_BR_PROB, very_unlikely);\n+}\n+\n+/* Expand code to perform a 8 or 16-bit compare and swap by doing\n+   32-bit compare and swap on the word containing the byte or\n+   half-word.  The difference between a weak and a strong CAS is that\n+   the weak version may simply fail.  The strong version relies on two\n+   loops, one checks if the SCOND op is succsfully or not, the other\n+   checks if the 32 bit accessed location which contains the 8 or 16\n+   bit datum is not changed by other thread.  The first loop is\n+   implemented by the atomic_compare_and_swapsi_1 pattern.  The second\n+   loops is implemented by this routine.  */\n+\n+static void\n+arc_expand_compare_and_swap_qh (rtx bool_result, rtx result, rtx mem,\n+\t\t\t\trtx oldval, rtx newval, rtx weak,\n+\t\t\t\trtx mod_s, rtx mod_f)\n+{\n+  rtx addr1 = force_reg (Pmode, XEXP (mem, 0));\n+  rtx addr = gen_reg_rtx (Pmode);\n+  rtx off = gen_reg_rtx (SImode);\n+  rtx oldv = gen_reg_rtx (SImode);\n+  rtx newv = gen_reg_rtx (SImode);\n+  rtx oldvalue = gen_reg_rtx (SImode);\n+  rtx newvalue = gen_reg_rtx (SImode);\n+  rtx res = gen_reg_rtx (SImode);\n+  rtx resv = gen_reg_rtx (SImode);\n+  rtx memsi, val, mask, end_label, loop_label, cc, x;\n+  machine_mode mode;\n+  bool is_weak = (weak != const0_rtx);\n+\n+  /* Truncate the address.  */\n+  emit_insn (gen_rtx_SET (addr,\n+\t\t\t  gen_rtx_AND (Pmode, addr1, GEN_INT (-4))));\n+\n+  /* Compute the datum offset.  */\n+  emit_insn (gen_rtx_SET (off,\n+\t\t\t  gen_rtx_AND (SImode, addr1, GEN_INT (3))));\n+  if (TARGET_BIG_ENDIAN)\n+    emit_insn (gen_rtx_SET (off,\n+\t\t\t    gen_rtx_MINUS (SImode,\n+\t\t\t\t\t   (GET_MODE (mem) == QImode) ?\n+\t\t\t\t\t   GEN_INT (3) : GEN_INT (2), off)));\n+\n+  /* Normal read from truncated address.  */\n+  memsi = gen_rtx_MEM (SImode, addr);\n+  set_mem_alias_set (memsi, ALIAS_SET_MEMORY_BARRIER);\n+  MEM_VOLATILE_P (memsi) = MEM_VOLATILE_P (mem);\n+\n+  val = copy_to_reg (memsi);\n+\n+  /* Convert the offset in bits.  */\n+  emit_insn (gen_rtx_SET (off,\n+\t\t\t  gen_rtx_ASHIFT (SImode, off, GEN_INT (3))));\n+\n+  /* Get the proper mask.  */\n+  if (GET_MODE (mem) == QImode)\n+    mask = force_reg (SImode, GEN_INT (0xff));\n+  else\n+    mask = force_reg (SImode, GEN_INT (0xffff));\n+\n+  emit_insn (gen_rtx_SET (mask,\n+\t\t\t  gen_rtx_ASHIFT (SImode, mask, off)));\n+\n+  /* Prepare the old and new values.  */\n+  emit_insn (gen_rtx_SET (val,\n+\t\t\t  gen_rtx_AND (SImode, gen_rtx_NOT (SImode, mask),\n+\t\t\t\t       val)));\n+\n+  oldval = gen_lowpart (SImode, oldval);\n+  emit_insn (gen_rtx_SET (oldv,\n+\t\t\t  gen_rtx_ASHIFT (SImode, oldval, off)));\n+\n+  newval = gen_lowpart_common (SImode, newval);\n+  emit_insn (gen_rtx_SET (newv,\n+\t\t\t  gen_rtx_ASHIFT (SImode, newval, off)));\n+\n+  emit_insn (gen_rtx_SET (oldv,\n+\t\t\t  gen_rtx_AND (SImode, oldv, mask)));\n+\n+  emit_insn (gen_rtx_SET (newv,\n+\t\t\t  gen_rtx_AND (SImode, newv, mask)));\n+\n+  if (!is_weak)\n+    {\n+      end_label = gen_label_rtx ();\n+      loop_label = gen_label_rtx ();\n+      emit_label (loop_label);\n+    }\n+\n+  /* Make the old and new values.  */\n+  emit_insn (gen_rtx_SET (oldvalue,\n+\t\t\t  gen_rtx_IOR (SImode, oldv, val)));\n+\n+  emit_insn (gen_rtx_SET (newvalue,\n+\t\t\t  gen_rtx_IOR (SImode, newv, val)));\n+\n+  /* Try an 32bit atomic compare and swap.  It clobbers the CC\n+     register.  */\n+  emit_insn (gen_atomic_compare_and_swapsi_1 (res, memsi, oldvalue, newvalue,\n+\t\t\t\t\t      weak, mod_s, mod_f));\n+\n+  /* Regardless of the weakness of the operation, a proper boolean\n+     result needs to be provided.  */\n+  x = gen_rtx_REG (CC_Zmode, CC_REG);\n+  x = gen_rtx_EQ (SImode, x, const0_rtx);\n+  emit_insn (gen_rtx_SET (bool_result, x));\n+\n+  if (!is_weak)\n+    {\n+      /* Check the results: if the atomic op is successfully the goto\n+\t to end label.  */\n+      x = gen_rtx_REG (CC_Zmode, CC_REG);\n+      x = gen_rtx_EQ (VOIDmode, x, const0_rtx);\n+      x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t\tgen_rtx_LABEL_REF (Pmode, end_label), pc_rtx);\n+      emit_jump_insn (gen_rtx_SET (pc_rtx, x));\n+\n+      /* Wait for the right moment when the accessed 32-bit location\n+\t is stable.  */\n+      emit_insn (gen_rtx_SET (resv,\n+\t\t\t      gen_rtx_AND (SImode, gen_rtx_NOT (SImode, mask),\n+\t\t\t\t\t   res)));\n+      mode = SELECT_CC_MODE (NE, resv, val);\n+      cc = gen_rtx_REG (mode, CC_REG);\n+      emit_insn (gen_rtx_SET (cc, gen_rtx_COMPARE (mode, resv, val)));\n+\n+      /* Set the new value of the 32 bit location, proper masked.  */\n+      emit_insn (gen_rtx_SET (val, resv));\n+\n+      /* Try again if location is unstable.  Fall through if only\n+\t scond op failed.  */\n+      x = gen_rtx_NE (VOIDmode, cc, const0_rtx);\n+      x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t\tgen_rtx_LABEL_REF (Pmode, loop_label), pc_rtx);\n+      emit_unlikely_jump (gen_rtx_SET (pc_rtx, x));\n+\n+      emit_label (end_label);\n+    }\n+\n+  /* End: proper return the result for the given mode.  */\n+  emit_insn (gen_rtx_SET (res,\n+\t\t\t  gen_rtx_AND (SImode, res, mask)));\n+\n+  emit_insn (gen_rtx_SET (res,\n+\t\t\t  gen_rtx_LSHIFTRT (SImode, res, off)));\n+\n+  emit_move_insn (result, gen_lowpart (GET_MODE (result), res));\n+}\n+\n+/* Helper function used by \"atomic_compare_and_swap\" expand\n+   pattern.  */\n+\n+void\n+arc_expand_compare_and_swap (rtx operands[])\n+{\n+  rtx bval, rval, mem, oldval, newval, is_weak, mod_s, mod_f, x;\n+  machine_mode mode;\n+\n+  bval = operands[0];\n+  rval = operands[1];\n+  mem = operands[2];\n+  oldval = operands[3];\n+  newval = operands[4];\n+  is_weak = operands[5];\n+  mod_s = operands[6];\n+  mod_f = operands[7];\n+  mode = GET_MODE (mem);\n+\n+  if (reg_overlap_mentioned_p (rval, oldval))\n+    oldval = copy_to_reg (oldval);\n+\n+  if (mode == SImode)\n+    {\n+      emit_insn (gen_atomic_compare_and_swapsi_1 (rval, mem, oldval, newval,\n+\t\t\t\t\t\t  is_weak, mod_s, mod_f));\n+      x = gen_rtx_REG (CC_Zmode, CC_REG);\n+      x = gen_rtx_EQ (SImode, x, const0_rtx);\n+      emit_insn (gen_rtx_SET (bval, x));\n+    }\n+  else\n+    {\n+      arc_expand_compare_and_swap_qh (bval, rval, mem, oldval, newval,\n+\t\t\t\t      is_weak, mod_s, mod_f);\n+    }\n+}\n+\n+/* Helper function used by the \"atomic_compare_and_swapsi_1\"\n+   pattern.  */\n+\n+void\n+arc_split_compare_and_swap (rtx operands[])\n+{\n+  rtx rval, mem, oldval, newval;\n+  machine_mode mode;\n+  enum memmodel mod_s, mod_f;\n+  bool is_weak;\n+  rtx label1, label2, x, cond;\n+\n+  rval = operands[0];\n+  mem = operands[1];\n+  oldval = operands[2];\n+  newval = operands[3];\n+  is_weak = (operands[4] != const0_rtx);\n+  mod_s = (enum memmodel) INTVAL (operands[5]);\n+  mod_f = (enum memmodel) INTVAL (operands[6]);\n+  mode = GET_MODE (mem);\n+\n+  /* ARC atomic ops work only with 32-bit aligned memories.  */\n+  gcc_assert (mode == SImode);\n+\n+  arc_pre_atomic_barrier (mod_s);\n+\n+  label1 = NULL_RTX;\n+  if (!is_weak)\n+    {\n+      label1 = gen_label_rtx ();\n+      emit_label (label1);\n+    }\n+  label2 = gen_label_rtx ();\n+\n+  /* Load exclusive.  */\n+  emit_insn (gen_arc_load_exclusivesi (rval, mem));\n+\n+  /* Check if it is oldval.  */\n+  mode = SELECT_CC_MODE (NE, rval, oldval);\n+  cond = gen_rtx_REG (mode, CC_REG);\n+  emit_insn (gen_rtx_SET (cond, gen_rtx_COMPARE (mode, rval, oldval)));\n+\n+  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+  x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t    gen_rtx_LABEL_REF (Pmode, label2), pc_rtx);\n+  emit_unlikely_jump (gen_rtx_SET (pc_rtx, x));\n+\n+  /* Exclusively store new item.  Store clobbers CC reg.  */\n+  emit_insn (gen_arc_store_exclusivesi (mem, newval));\n+\n+  if (!is_weak)\n+    {\n+      /* Check the result of the store.  */\n+      cond = gen_rtx_REG (CC_Zmode, CC_REG);\n+      x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+      x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t\tgen_rtx_LABEL_REF (Pmode, label1), pc_rtx);\n+      emit_unlikely_jump (gen_rtx_SET (pc_rtx, x));\n+    }\n+\n+  if (mod_f != MEMMODEL_RELAXED)\n+    emit_label (label2);\n+\n+  arc_post_atomic_barrier (mod_s);\n+\n+  if (mod_f == MEMMODEL_RELAXED)\n+    emit_label (label2);\n+}\n+\n+/* Expand an atomic fetch-and-operate pattern.  CODE is the binary operation\n+   to perform.  MEM is the memory on which to operate.  VAL is the second\n+   operand of the binary operator.  BEFORE and AFTER are optional locations to\n+   return the value of MEM either before of after the operation.  MODEL_RTX\n+   is a CONST_INT containing the memory model to use.  */\n+\n+void\n+arc_expand_atomic_op (enum rtx_code code, rtx mem, rtx val,\n+\t\t\t rtx orig_before, rtx orig_after, rtx model_rtx)\n+{\n+  enum memmodel model = (enum memmodel) INTVAL (model_rtx);\n+  machine_mode mode = GET_MODE (mem);\n+  rtx label, x, cond;\n+  rtx before = orig_before, after = orig_after;\n+\n+  /* ARC atomic ops work only with 32-bit aligned memories.  */\n+  gcc_assert (mode == SImode);\n+\n+  arc_pre_atomic_barrier (model);\n+\n+  label = gen_label_rtx ();\n+  emit_label (label);\n+  label = gen_rtx_LABEL_REF (VOIDmode, label);\n+\n+  if (before == NULL_RTX)\n+    before = gen_reg_rtx (mode);\n+\n+  if (after == NULL_RTX)\n+    after = gen_reg_rtx (mode);\n+\n+  /* Load exclusive.  */\n+  emit_insn (gen_arc_load_exclusivesi (before, mem));\n+\n+  switch (code)\n+    {\n+    case NOT:\n+      x = gen_rtx_AND (mode, before, val);\n+      emit_insn (gen_rtx_SET (after, x));\n+      x = gen_rtx_NOT (mode, after);\n+      emit_insn (gen_rtx_SET (after, x));\n+      break;\n+\n+    case MINUS:\n+      if (CONST_INT_P (val))\n+\t{\n+\t  val = GEN_INT (-INTVAL (val));\n+\t  code = PLUS;\n+\t}\n+\n+      /* FALLTHRU.  */\n+    default:\n+      x = gen_rtx_fmt_ee (code, mode, before, val);\n+      emit_insn (gen_rtx_SET (after, x));\n+      break;\n+   }\n+\n+  /* Exclusively store new item.  Store clobbers CC reg.  */\n+  emit_insn (gen_arc_store_exclusivesi (mem, after));\n+\n+  /* Check the result of the store.  */\n+  cond = gen_rtx_REG (CC_Zmode, CC_REG);\n+  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+  x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t    label, pc_rtx);\n+  emit_unlikely_jump (gen_rtx_SET (pc_rtx, x));\n+\n+  arc_post_atomic_barrier (model);\n+}\n+\n struct gcc_target targetm = TARGET_INITIALIZER;\n \n #include \"gt-arc.h\""}, {"sha": "c895725e62313f8f8cf5b5305276c720552203f1", "filename": "gcc/config/arc/arc.h", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.h?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -88,6 +88,10 @@ along with GCC; see the file COPYING3.  If not see\n       {\t\t\t\t\t\\\n \tbuiltin_define (\"__HS__\");\t\\\n       }\t\t\t\t\t\\\n+    if (TARGET_ATOMIC)\t\t\t\\\n+      {\t\t\t\t\t\\\n+\tbuiltin_define (\"__ARC_ATOMIC__\");\t\\\n+      }\t\t\t\t\t\\\n     if (TARGET_NORM)\t\t\t\\\n       {\t\t\t\t\t\\\n \tbuiltin_define (\"__ARC_NORM__\");\\\n@@ -153,7 +157,7 @@ along with GCC; see the file COPYING3.  If not see\n %{mcpu=ARC700|!mcpu=*:%{mrtsc}} \\\n %{mcpu=ARCHS:-mHS} \\\n %{mcpu=ARCEM:-mEM} \\\n-\"\n+%{matomic:-mlock}\"\n \n #if DEFAULT_LIBC == LIBC_UCLIBC\n /* Note that the default is to link against dynamic libraries, if they are"}, {"sha": "ac181a98895cbb27dfae3ad094351dbd94302e1b", "filename": "gcc/config/arc/arc.md", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.md?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -128,6 +128,12 @@\n    (VUNSPEC_UNIMP_S 28) ; blockage insn for unimp_s generation\n    (VUNSPEC_NOP 29) ; volatile NOP\n \n+   (UNSPEC_ARC_MEMBAR 30)\n+   (VUNSPEC_ARC_CAS 31)\n+   (VUNSPEC_ARC_LL 32)\n+   (VUNSPEC_ARC_SC 33)\n+   (VUNSPEC_ARC_EX 34)\n+\n    (R0_REG 0)\n    (R1_REG 1)\n    (R2_REG 2)\n@@ -5531,3 +5537,6 @@\n (include \"fpx.md\")\n \n (include \"simdext.md\")\n+\n+;; include atomic extensions\n+(include \"atomic.md\")"}, {"sha": "c4d7306ee9894ffde5b0d37475f50ed73824251d", "filename": "gcc/config/arc/arc.opt", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Farc.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.opt?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -414,3 +414,6 @@ Target Joined\n mmac_\n Target Joined\n \n+matomic\n+Target Report Mask(ATOMIC)\n+Enable atomic instructions."}, {"sha": "18309cc807341e8f6baac3e944006c2feed2c4db", "filename": "gcc/config/arc/constraints.md", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Fconstraints.md?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -421,3 +421,9 @@\n    An unsigned 6-bit integer constant, up to 62.\"\n   (and (match_code \"const_int\")\n        (match_test \"UNSIGNED_INT6 (ival - 1)\")))\n+\n+;; Memory constraint used for atomic ops.\n+(define_memory_constraint \"ATO\"\n+  \"A memory with only a base register\"\n+  (match_operand 0 \"mem_noofs_operand\"))\n+"}, {"sha": "de0735a407175e91c186232ff02185a3805a6778", "filename": "gcc/config/arc/predicates.md", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fconfig%2Farc%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Fpredicates.md?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -813,3 +813,7 @@\n (define_predicate \"short_const_int_operand\"\n   (and (match_operand 0 \"const_int_operand\")\n        (match_test \"satisfies_constraint_C16 (op)\")))\n+\n+(define_predicate \"mem_noofs_operand\"\n+  (and (match_code \"mem\")\n+       (match_code \"reg\" \"0\")))"}, {"sha": "3cddf5c4de53d0b0fd451ea5cf1ef9f8f27101f2", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -538,7 +538,7 @@ Objective-C and Objective-C++ Dialects}.\n @gccoptlist{-mbarrel-shifter @gol\n -mcpu=@var{cpu} -mA6 -mARC600 -mA7 -mARC700 @gol\n -mdpfp -mdpfp-compact -mdpfp-fast -mno-dpfp-lrsr @gol\n--mea -mno-mpy -mmul32x16 -mmul64 @gol\n+-mea -mno-mpy -mmul32x16 -mmul64 -matomic @gol\n -mnorm -mspfp -mspfp-compact -mspfp-fast -msimd -msoft-float -mswap @gol\n -mcrc -mdsp-packa -mdvbf -mlock -mmac-d16 -mmac-24 -mrtsc -mswape @gol\n -mtelephony -mxy -misize -mannotate-align -marclinux -marclinux_prof @gol\n@@ -12970,6 +12970,12 @@ can overridden by FPX options; @samp{mspfp}, @samp{mspfp-compact}, or\n @opindex mswap\n Generate swap instructions.\n \n+@item -matomic\n+@opindex matomic\n+This enables Locked Load/Store Conditional extension to implement\n+atomic memopry built-in functions.  Not available for ARC 6xx or ARC\n+EM cores.\n+\n @item -mdiv-rem\n @opindex mdiv-rem\n Enable DIV/REM instructions for ARCv2 cores."}, {"sha": "bb785c689cdf27f6d35c78acd9bc838ebc15ca63", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -1,3 +1,11 @@\n+2015-12-10  Claudiu Zissulescu  <claziss@synopsys.com>\n+\n+\t* lib/target-supports.exp (check_effective_target_arc_atomic): New\n+\tfunction.\n+\t(check_effective_target_sync_int_long): Add checks for ARC atomic\n+\tfeature.\n+\t(check_effective_target_sync_char_short): Likewise.\n+\n 2015-12-10  Richard Biener  <rguenther@suse.de>\n \n \tPR tree-optimization/68817"}, {"sha": "8d28b235c27ee30c3248f93cb6df02da3d956128", "filename": "gcc/testsuite/lib/target-supports.exp", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b8a64b7f5d699776983eab2c07125523e96bc6ea/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp?ref=b8a64b7f5d699776983eab2c07125523e96bc6ea", "patch": "@@ -2608,6 +2608,15 @@ proc check_effective_target_aarch64_little_endian { } {\n     }]\n }\n \n+# Return 1 if this is a compiler supporting ARC atomic operations\n+proc check_effective_target_arc_atomic { } {\n+    return [check_no_compiler_messages arc_atomic assembly {\n+\t#if !defined(__ARC_ATOMIC__)\n+\t#error FOO\n+\t#endif\n+    }]\n+}\n+\n # Return 1 if this is an arm target using 32-bit instructions\n proc check_effective_target_arm32 { } {\n     if { ![istarget arm*-*-*] } {\n@@ -5581,6 +5590,7 @@ proc check_effective_target_sync_int_long { } {\n \t     || [istarget crisv32-*-*] || [istarget cris-*-*]\n \t     || ([istarget sparc*-*-*] && [check_effective_target_sparc_v9])\n \t     || [istarget spu-*-*]\n+\t     || ([istarget arc*-*-*] && [check_effective_target_arc_atomic])\n \t     || [check_effective_target_mips_llsc] } {\n            set et_sync_int_long_saved 1\n         }\n@@ -5612,6 +5622,7 @@ proc check_effective_target_sync_char_short { } {\n \t     || [istarget crisv32-*-*] || [istarget cris-*-*]\n \t     || ([istarget sparc*-*-*] && [check_effective_target_sparc_v9])\n \t     || [istarget spu-*-*]\n+\t     || ([istarget arc*-*-*] && [check_effective_target_arc_atomic])\n \t     || [check_effective_target_mips_llsc] } {\n            set et_sync_char_short_saved 1\n         }"}]}