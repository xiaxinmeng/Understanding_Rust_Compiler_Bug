{"sha": "33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzNkNzJiNjM4NjNkZTJkZWRmYTdhNjk3ZDdkMGIwZThiODBlMTQxNg==", "commit": {"author": {"name": "Jiong Wang", "email": "jiong.wang@arm.com", "date": "2016-07-25T14:30:52Z"}, "committer": {"name": "Jiong Wang", "email": "jiwang@gcc.gnu.org", "date": "2016-07-25T14:30:52Z"}, "message": "[AArch64][3/10] ARMv8.2-A FP16 two operands vector intrinsics\n\ngcc/\n\t* config/aarch64/aarch64-simd-builtins.def: Register new builtins.\n\t* config/aarch64/aarch64-simd.md\n\t(aarch64_rsqrts<mode>): Extend to HF modes.\n\t(fabd<mode>3): Likewise.\n\t(<FCVT_F2FIXED:fcvt_fixed_insn><VHSDF_SDF:mode>3): Likewise.\n\t(<FCVT_FIXED2F:fcvt_fixed_insn><VHSDI_SDI:mode>3): Likewise.\n\t(aarch64_<maxmin_uns>p<mode>): Likewise.\n\t(<su><maxmin><mode>3): Likewise.\n\t(<maxmin_uns><mode>3): Likewise.\n\t(<fmaxmin><mode>3): Likewise.\n\t(aarch64_faddp<mode>): Likewise.\n\t(aarch64_fmulx<mode>): Likewise.\n\t(aarch64_frecps<mode>): Likewise.\n\t(*aarch64_fac<optab><mode>): Rename to aarch64_fac<optab><mode>.\n\t(add<mode>3): Extend to HF modes.\n\t(sub<mode>3): Likewise.\n\t(mul<mode>3): Likewise.\n\t(div<mode>3): Likewise.\n\t(*div<mode>3): Likewise.\n\t* config/aarch64/aarch64.c (aarch64_emit_approx_div): Return false for\n\tHF, V4HF and V8HF.\n\t* config/aarch64/iterators.md (VDQ_HSDI, VSDQ_HSDI): New mode iterator.\n\t* config/aarch64/arm_neon.h (vadd_f16): New.\n\t(vaddq_f16, vabd_f16, vabdq_f16, vcage_f16, vcageq_f16, vcagt_f16,\n\tvcagtq_f16, vcale_f16, vcaleq_f16, vcalt_f16, vcaltq_f16, vceq_f16,\n\tvceqq_f16, vcge_f16, vcgeq_f16, vcgt_f16, vcgtq_f16, vcle_f16,\n\tvcleq_f16, vclt_f16, vcltq_f16, vcvt_n_f16_s16, vcvtq_n_f16_s16,\n\tvcvt_n_f16_u16, vcvtq_n_f16_u16, vcvt_n_s16_f16, vcvtq_n_s16_f16,\n\tvcvt_n_u16_f16, vcvtq_n_u16_f16, vdiv_f16, vdivq_f16, vdup_lane_f16,\n\tvdup_laneq_f16, vdupq_lane_f16, vdupq_laneq_f16, vdups_lane_f16,\n\tvdups_laneq_f16, vmax_f16, vmaxq_f16, vmaxnm_f16, vmaxnmq_f16, vmin_f16,\n\tvminq_f16, vminnm_f16, vminnmq_f16, vmul_f16, vmulq_f16, vmulx_f16,\n\tvmulxq_f16, vpadd_f16, vpaddq_f16, vpmax_f16, vpmaxq_f16, vpmaxnm_f16,\n\tvpmaxnmq_f16, vpmin_f16, vpminq_f16, vpminnm_f16, vpminnmq_f16,\n\tvrecps_f16, vrecpsq_f16, vrsqrts_f16, vrsqrtsq_f16, vsub_f16,\n\tvsubq_f16): Likewise.\n\nFrom-SVN: r238717", "tree": {"sha": "2963f6ac69831eda6927f20fc8fb57d64f3aff8f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2963f6ac69831eda6927f20fc8fb57d64f3aff8f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "html_url": "https://github.com/Rust-GCC/gccrs/commit/33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/comments", "author": null, "committer": null, "parents": [{"sha": "daef0a8c7e99cbc574291227f2ed98220a5be4d4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/daef0a8c7e99cbc574291227f2ed98220a5be4d4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/daef0a8c7e99cbc574291227f2ed98220a5be4d4"}], "stats": {"total": 619, "additions": 523, "deletions": 96}, "files": [{"sha": "14967415b48df262c2f56853bbb4bd22d1125de2", "filename": "gcc/ChangeLog", "status": "modified", "additions": 41, "deletions": 2, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "patch": "@@ -1,3 +1,42 @@\n+2016-07-25  Jiong Wang  <jiong.wang@arm.com>\n+\n+\t* config/aarch64/aarch64-simd-builtins.def: Register new builtins.\n+\t* config/aarch64/aarch64-simd.md\n+\t(aarch64_rsqrts<mode>): Extend to HF modes.\n+\t(fabd<mode>3): Likewise.\n+\t(<FCVT_F2FIXED:fcvt_fixed_insn><VHSDF_SDF:mode>3): Likewise.\n+\t(<FCVT_FIXED2F:fcvt_fixed_insn><VHSDI_SDI:mode>3): Likewise.\n+\t(aarch64_<maxmin_uns>p<mode>): Likewise.\n+\t(<su><maxmin><mode>3): Likewise.\n+\t(<maxmin_uns><mode>3): Likewise.\n+\t(<fmaxmin><mode>3): Likewise.\n+\t(aarch64_faddp<mode>): Likewise.\n+\t(aarch64_fmulx<mode>): Likewise.\n+\t(aarch64_frecps<mode>): Likewise.\n+\t(*aarch64_fac<optab><mode>): Rename to aarch64_fac<optab><mode>.\n+\t(add<mode>3): Extend to HF modes.\n+\t(sub<mode>3): Likewise.\n+\t(mul<mode>3): Likewise.\n+\t(div<mode>3): Likewise.\n+\t(*div<mode>3): Likewise.\n+\t* config/aarch64/aarch64.c (aarch64_emit_approx_div): Return false for\n+\tHF, V4HF and V8HF.\n+\t* config/aarch64/iterators.md (VDQ_HSDI, VSDQ_HSDI): New mode iterator.\n+\t* config/aarch64/arm_neon.h (vadd_f16): New.\n+\t(vaddq_f16, vabd_f16, vabdq_f16, vcage_f16, vcageq_f16, vcagt_f16,\n+\tvcagtq_f16, vcale_f16, vcaleq_f16, vcalt_f16, vcaltq_f16, vceq_f16,\n+\tvceqq_f16, vcge_f16, vcgeq_f16, vcgt_f16, vcgtq_f16, vcle_f16,\n+\tvcleq_f16, vclt_f16, vcltq_f16, vcvt_n_f16_s16, vcvtq_n_f16_s16,\n+\tvcvt_n_f16_u16, vcvtq_n_f16_u16, vcvt_n_s16_f16, vcvtq_n_s16_f16,\n+\tvcvt_n_u16_f16, vcvtq_n_u16_f16, vdiv_f16, vdivq_f16, vdup_lane_f16,\n+\tvdup_laneq_f16, vdupq_lane_f16, vdupq_laneq_f16, vdups_lane_f16,\n+\tvdups_laneq_f16, vmax_f16, vmaxq_f16, vmaxnm_f16, vmaxnmq_f16, vmin_f16,\n+\tvminq_f16, vminnm_f16, vminnmq_f16, vmul_f16, vmulq_f16, vmulx_f16,\n+\tvmulxq_f16, vpadd_f16, vpaddq_f16, vpmax_f16, vpmaxq_f16, vpmaxnm_f16,\n+\tvpmaxnmq_f16, vpmin_f16, vpminq_f16, vpminnm_f16, vpminnmq_f16,\n+\tvrecps_f16, vrecpsq_f16, vrsqrts_f16, vrsqrtsq_f16, vsub_f16,\n+\tvsubq_f16): Likewise.\n+\n 2016-07-25  Jiong Wang  <jiong.wang@arm.com>\n \n \t* config/aarch64/aarch64-builtins.c (TYPES_BINOP_USS): New.\n@@ -15,8 +54,8 @@\n \t(*sqrt<mode>2): Likewise.\n \t(aarch64_frecpe<mode>): Likewise.\n \t(aarch64_cm<optab><mode>): Likewise.\n-\t* config/aarch64/aarch64.c (aarch64_emit_approx_sqrt): Return\n-\tfalse for V4HF and V8HF.\n+\t* config/aarch64/aarch64.c (aarch64_emit_approx_sqrt): Return false for\n+\tHF, V4HF and V8HF.\n \t* config/aarch64/iterators.md (VHSDF, VHSDF_DF, VHSDF_SDF): New.\n \t(VDQF_COND, fcvt_target, FCVT_TARGET, hcon): Extend mode attribute to HF modes.\n \t(stype): New."}, {"sha": "007dad60b6999158a1c9c1cf2a501a9f0712af54", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 23, "deletions": 17, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "patch": "@@ -41,7 +41,7 @@\n \n   BUILTIN_VDC (COMBINE, combine, 0)\n   BUILTIN_VB (BINOP, pmul, 0)\n-  BUILTIN_VALLF (BINOP, fmulx, 0)\n+  BUILTIN_VHSDF_SDF (BINOP, fmulx, 0)\n   BUILTIN_VHSDF_DF (UNOP, sqrt, 2)\n   BUILTIN_VD_BHSI (BINOP, addp, 0)\n   VAR1 (UNOP, addp, 0, di)\n@@ -248,22 +248,22 @@\n   BUILTIN_VDQ_BHSI (BINOP, smin, 3)\n   BUILTIN_VDQ_BHSI (BINOP, umax, 3)\n   BUILTIN_VDQ_BHSI (BINOP, umin, 3)\n-  BUILTIN_VDQF (BINOP, smax_nan, 3)\n-  BUILTIN_VDQF (BINOP, smin_nan, 3)\n+  BUILTIN_VHSDF (BINOP, smax_nan, 3)\n+  BUILTIN_VHSDF (BINOP, smin_nan, 3)\n \n   /* Implemented by <fmaxmin><mode>3.  */\n-  BUILTIN_VDQF (BINOP, fmax, 3)\n-  BUILTIN_VDQF (BINOP, fmin, 3)\n+  BUILTIN_VHSDF (BINOP, fmax, 3)\n+  BUILTIN_VHSDF (BINOP, fmin, 3)\n \n   /* Implemented by aarch64_<maxmin_uns>p<mode>.  */\n   BUILTIN_VDQ_BHSI (BINOP, smaxp, 0)\n   BUILTIN_VDQ_BHSI (BINOP, sminp, 0)\n   BUILTIN_VDQ_BHSI (BINOP, umaxp, 0)\n   BUILTIN_VDQ_BHSI (BINOP, uminp, 0)\n-  BUILTIN_VDQF (BINOP, smaxp, 0)\n-  BUILTIN_VDQF (BINOP, sminp, 0)\n-  BUILTIN_VDQF (BINOP, smax_nanp, 0)\n-  BUILTIN_VDQF (BINOP, smin_nanp, 0)\n+  BUILTIN_VHSDF (BINOP, smaxp, 0)\n+  BUILTIN_VHSDF (BINOP, sminp, 0)\n+  BUILTIN_VHSDF (BINOP, smax_nanp, 0)\n+  BUILTIN_VHSDF (BINOP, smin_nanp, 0)\n \n   /* Implemented by <frint_pattern><mode>2.  */\n   BUILTIN_VHSDF (UNOP, btrunc, 2)\n@@ -383,7 +383,7 @@\n   BUILTIN_VDQ_SI (UNOP, urecpe, 0)\n \n   BUILTIN_VHSDF (UNOP, frecpe, 0)\n-  BUILTIN_VDQF (BINOP, frecps, 0)\n+  BUILTIN_VHSDF (BINOP, frecps, 0)\n \n   /* Implemented by a mixture of abs2 patterns.  Note the DImode builtin is\n      only ever used for the int64x1_t intrinsic, there is no scalar version.  */\n@@ -475,22 +475,22 @@\n   BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlsh_laneq, 0)\n \n   /* Implemented by <FCVT_F2FIXED/FIXED2F:fcvt_fixed_insn><*><*>3.  */\n-  BUILTIN_VSDQ_SDI (SHIFTIMM, scvtf, 3)\n-  BUILTIN_VSDQ_SDI (FCVTIMM_SUS, ucvtf, 3)\n-  BUILTIN_VALLF (SHIFTIMM, fcvtzs, 3)\n-  BUILTIN_VALLF (SHIFTIMM_USS, fcvtzu, 3)\n+  BUILTIN_VSDQ_HSDI (SHIFTIMM, scvtf, 3)\n+  BUILTIN_VSDQ_HSDI (FCVTIMM_SUS, ucvtf, 3)\n+  BUILTIN_VHSDF_SDF (SHIFTIMM, fcvtzs, 3)\n+  BUILTIN_VHSDF_SDF (SHIFTIMM_USS, fcvtzu, 3)\n \n   /* Implemented by aarch64_rsqrte<mode>.  */\n   BUILTIN_VHSDF_SDF (UNOP, rsqrte, 0)\n \n   /* Implemented by aarch64_rsqrts<mode>.  */\n-  BUILTIN_VALLF (BINOP, rsqrts, 0)\n+  BUILTIN_VHSDF_SDF (BINOP, rsqrts, 0)\n \n   /* Implemented by fabd<mode>3.  */\n-  BUILTIN_VALLF (BINOP, fabd, 3)\n+  BUILTIN_VHSDF_SDF (BINOP, fabd, 3)\n \n   /* Implemented by aarch64_faddp<mode>.  */\n-  BUILTIN_VDQF (BINOP, faddp, 0)\n+  BUILTIN_VHSDF (BINOP, faddp, 0)\n \n   /* Implemented by aarch64_cm<optab><mode>.  */\n   BUILTIN_VHSDF_SDF (BINOP_USS, cmeq, 0)\n@@ -501,3 +501,9 @@\n \n   /* Implemented by neg<mode>2.  */\n   BUILTIN_VHSDF (UNOP, neg, 2)\n+\n+  /* Implemented by aarch64_fac<optab><mode>.  */\n+  BUILTIN_VHSDF_SDF (BINOP_USS, faclt, 0)\n+  BUILTIN_VHSDF_SDF (BINOP_USS, facle, 0)\n+  BUILTIN_VHSDF_SDF (BINOP_USS, facgt, 0)\n+  BUILTIN_VHSDF_SDF (BINOP_USS, facge, 0)"}, {"sha": "2aae7a6eb9cda59f649bc04a466b52b2745af914", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 83, "deletions": 77, "changes": 160, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "patch": "@@ -391,13 +391,13 @@\n   [(set_attr \"type\" \"neon_fp_rsqrte_<stype><q>\")])\n \n (define_insn \"aarch64_rsqrts<mode>\"\n-  [(set (match_operand:VALLF 0 \"register_operand\" \"=w\")\n-\t(unspec:VALLF [(match_operand:VALLF 1 \"register_operand\" \"w\")\n-\t       (match_operand:VALLF 2 \"register_operand\" \"w\")]\n-\t\t     UNSPEC_RSQRTS))]\n+  [(set (match_operand:VHSDF_SDF 0 \"register_operand\" \"=w\")\n+\t(unspec:VHSDF_SDF [(match_operand:VHSDF_SDF 1 \"register_operand\" \"w\")\n+\t\t\t   (match_operand:VHSDF_SDF 2 \"register_operand\" \"w\")]\n+\t UNSPEC_RSQRTS))]\n   \"TARGET_SIMD\"\n   \"frsqrts\\\\t%<v>0<Vmtype>, %<v>1<Vmtype>, %<v>2<Vmtype>\"\n-  [(set_attr \"type\" \"neon_fp_rsqrts_<Vetype><q>\")])\n+  [(set_attr \"type\" \"neon_fp_rsqrts_<stype><q>\")])\n \n (define_expand \"rsqrt<mode>2\"\n   [(set (match_operand:VALLF 0 \"register_operand\" \"=w\")\n@@ -475,14 +475,14 @@\n )\n \n (define_insn \"fabd<mode>3\"\n-  [(set (match_operand:VALLF 0 \"register_operand\" \"=w\")\n-\t(abs:VALLF\n-\t  (minus:VALLF\n-\t    (match_operand:VALLF 1 \"register_operand\" \"w\")\n-\t    (match_operand:VALLF 2 \"register_operand\" \"w\"))))]\n+  [(set (match_operand:VHSDF_SDF 0 \"register_operand\" \"=w\")\n+\t(abs:VHSDF_SDF\n+\t  (minus:VHSDF_SDF\n+\t    (match_operand:VHSDF_SDF 1 \"register_operand\" \"w\")\n+\t    (match_operand:VHSDF_SDF 2 \"register_operand\" \"w\"))))]\n   \"TARGET_SIMD\"\n   \"fabd\\t%<v>0<Vmtype>, %<v>1<Vmtype>, %<v>2<Vmtype>\"\n-  [(set_attr \"type\" \"neon_fp_abd_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_abd_<stype><q>\")]\n )\n \n (define_insn \"and<mode>3\"\n@@ -1105,10 +1105,10 @@\n \n ;; Pairwise FP Max/Min operations.\n (define_insn \"aarch64_<maxmin_uns>p<mode>\"\n- [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-       (unspec:VDQF [(match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t     (match_operand:VDQF 2 \"register_operand\" \"w\")]\n-\t\t    FMAXMINV))]\n+ [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (unspec:VHSDF [(match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t      (match_operand:VHSDF 2 \"register_operand\" \"w\")]\n+\t\t      FMAXMINV))]\n  \"TARGET_SIMD\"\n  \"<maxmin_uns_op>p\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n   [(set_attr \"type\" \"neon_minmax<q>\")]\n@@ -1517,36 +1517,36 @@\n ;; FP arithmetic operations.\n \n (define_insn \"add<mode>3\"\n- [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-       (plus:VDQF (match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t  (match_operand:VDQF 2 \"register_operand\" \"w\")))]\n+ [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (plus:VHSDF (match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t   (match_operand:VHSDF 2 \"register_operand\" \"w\")))]\n  \"TARGET_SIMD\"\n  \"fadd\\\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_addsub_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_addsub_<stype><q>\")]\n )\n \n (define_insn \"sub<mode>3\"\n- [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-       (minus:VDQF (match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t   (match_operand:VDQF 2 \"register_operand\" \"w\")))]\n+ [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (minus:VHSDF (match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t    (match_operand:VHSDF 2 \"register_operand\" \"w\")))]\n  \"TARGET_SIMD\"\n  \"fsub\\\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_addsub_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_addsub_<stype><q>\")]\n )\n \n (define_insn \"mul<mode>3\"\n- [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-       (mult:VDQF (match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t  (match_operand:VDQF 2 \"register_operand\" \"w\")))]\n+ [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (mult:VHSDF (match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t   (match_operand:VHSDF 2 \"register_operand\" \"w\")))]\n  \"TARGET_SIMD\"\n  \"fmul\\\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_mul_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_mul_<stype><q>\")]\n )\n \n (define_expand \"div<mode>3\"\n- [(set (match_operand:VDQF 0 \"register_operand\")\n-       (div:VDQF (match_operand:VDQF 1 \"general_operand\")\n-\t\t (match_operand:VDQF 2 \"register_operand\")))]\n+ [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (div:VHSDF (match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t  (match_operand:VHSDF 2 \"register_operand\" \"w\")))]\n  \"TARGET_SIMD\"\n {\n   if (aarch64_emit_approx_div (operands[0], operands[1], operands[2]))\n@@ -1556,12 +1556,12 @@\n })\n \n (define_insn \"*div<mode>3\"\n- [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-       (div:VDQF (match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t (match_operand:VDQF 2 \"register_operand\" \"w\")))]\n+ [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (div:VHSDF (match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t (match_operand:VHSDF 2 \"register_operand\" \"w\")))]\n  \"TARGET_SIMD\"\n  \"fdiv\\\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_div_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_div_<stype><q>\")]\n )\n \n (define_insn \"neg<mode>2\"\n@@ -1826,24 +1826,26 @@\n \n ;; Convert between fixed-point and floating-point (vector modes)\n \n-(define_insn \"<FCVT_F2FIXED:fcvt_fixed_insn><VDQF:mode>3\"\n-  [(set (match_operand:<VDQF:FCVT_TARGET> 0 \"register_operand\" \"=w\")\n-\t(unspec:<VDQF:FCVT_TARGET> [(match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t\t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n+(define_insn \"<FCVT_F2FIXED:fcvt_fixed_insn><VHSDF:mode>3\"\n+  [(set (match_operand:<VHSDF:FCVT_TARGET> 0 \"register_operand\" \"=w\")\n+\t(unspec:<VHSDF:FCVT_TARGET>\n+\t  [(match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t   (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t FCVT_F2FIXED))]\n   \"TARGET_SIMD\"\n   \"<FCVT_F2FIXED:fcvt_fixed_insn>\\t%<v>0<Vmtype>, %<v>1<Vmtype>, #%2\"\n-  [(set_attr \"type\" \"neon_fp_to_int_<VDQF:Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_to_int_<VHSDF:stype><q>\")]\n )\n \n-(define_insn \"<FCVT_FIXED2F:fcvt_fixed_insn><VDQ_SDI:mode>3\"\n-  [(set (match_operand:<VDQ_SDI:FCVT_TARGET> 0 \"register_operand\" \"=w\")\n-\t(unspec:<VDQ_SDI:FCVT_TARGET> [(match_operand:VDQ_SDI 1 \"register_operand\" \"w\")\n-\t\t\t\t       (match_operand:SI 2 \"immediate_operand\" \"i\")]\n+(define_insn \"<FCVT_FIXED2F:fcvt_fixed_insn><VDQ_HSDI:mode>3\"\n+  [(set (match_operand:<VDQ_HSDI:FCVT_TARGET> 0 \"register_operand\" \"=w\")\n+\t(unspec:<VDQ_HSDI:FCVT_TARGET>\n+\t  [(match_operand:VDQ_HSDI 1 \"register_operand\" \"w\")\n+\t   (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t FCVT_FIXED2F))]\n   \"TARGET_SIMD\"\n   \"<FCVT_FIXED2F:fcvt_fixed_insn>\\t%<v>0<Vmtype>, %<v>1<Vmtype>, #%2\"\n-  [(set_attr \"type\" \"neon_int_to_fp_<VDQ_SDI:Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_int_to_fp_<VDQ_HSDI:stype><q>\")]\n )\n \n ;; ??? Note that the vectorizer usage of the vec_unpacks_[lo/hi] patterns\n@@ -2002,33 +2004,33 @@\n ;; NaNs.\n \n (define_insn \"<su><maxmin><mode>3\"\n-  [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-        (FMAXMIN:VDQF (match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t   (match_operand:VDQF 2 \"register_operand\" \"w\")))]\n+  [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+\t(FMAXMIN:VHSDF (match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t       (match_operand:VHSDF 2 \"register_operand\" \"w\")))]\n   \"TARGET_SIMD\"\n   \"f<maxmin>nm\\\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_minmax_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_minmax_<stype><q>\")]\n )\n \n (define_insn \"<maxmin_uns><mode>3\"\n-  [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-       (unspec:VDQF [(match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t     (match_operand:VDQF 2 \"register_operand\" \"w\")]\n-\t\t    FMAXMIN_UNS))]\n+  [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (unspec:VHSDF [(match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t      (match_operand:VHSDF 2 \"register_operand\" \"w\")]\n+\t\t      FMAXMIN_UNS))]\n   \"TARGET_SIMD\"\n   \"<maxmin_uns_op>\\\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_minmax_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_minmax_<stype><q>\")]\n )\n \n ;; Auto-vectorized forms for the IEEE-754 fmax()/fmin() functions\n (define_insn \"<fmaxmin><mode>3\"\n-  [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-\t(unspec:VDQF [(match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t      (match_operand:VDQF 2 \"register_operand\" \"w\")]\n-\t\t      FMAXMIN))]\n+  [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+\t(unspec:VHSDF [(match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t       (match_operand:VHSDF 2 \"register_operand\" \"w\")]\n+\t\t       FMAXMIN))]\n   \"TARGET_SIMD\"\n   \"<fmaxmin_op>\\\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_minmax_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_minmax_<stype><q>\")]\n )\n \n ;; 'across lanes' add.\n@@ -2048,13 +2050,13 @@\n )\n \n (define_insn \"aarch64_faddp<mode>\"\n- [(set (match_operand:VDQF 0 \"register_operand\" \"=w\")\n-       (unspec:VDQF [(match_operand:VDQF 1 \"register_operand\" \"w\")\n-\t\t     (match_operand:VDQF 2 \"register_operand\" \"w\")]\n-\t\t     UNSPEC_FADDV))]\n+ [(set (match_operand:VHSDF 0 \"register_operand\" \"=w\")\n+       (unspec:VHSDF [(match_operand:VHSDF 1 \"register_operand\" \"w\")\n+\t\t      (match_operand:VHSDF 2 \"register_operand\" \"w\")]\n+\tUNSPEC_FADDV))]\n  \"TARGET_SIMD\"\n  \"faddp\\t%0.<Vtype>, %1.<Vtype>, %2.<Vtype>\"\n-  [(set_attr \"type\" \"neon_fp_reduc_add_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_reduc_add_<stype><q>\")]\n )\n \n (define_insn \"aarch64_reduc_plus_internal<mode>\"\n@@ -3050,13 +3052,14 @@\n ;; fmulx.\n \n (define_insn \"aarch64_fmulx<mode>\"\n-  [(set (match_operand:VALLF 0 \"register_operand\" \"=w\")\n-\t(unspec:VALLF [(match_operand:VALLF 1 \"register_operand\" \"w\")\n-\t\t       (match_operand:VALLF 2 \"register_operand\" \"w\")]\n-\t\t      UNSPEC_FMULX))]\n+  [(set (match_operand:VHSDF_SDF 0 \"register_operand\" \"=w\")\n+\t(unspec:VHSDF_SDF\n+\t  [(match_operand:VHSDF_SDF 1 \"register_operand\" \"w\")\n+\t   (match_operand:VHSDF_SDF 2 \"register_operand\" \"w\")]\n+\t   UNSPEC_FMULX))]\n  \"TARGET_SIMD\"\n  \"fmulx\\t%<v>0<Vmtype>, %<v>1<Vmtype>, %<v>2<Vmtype>\"\n- [(set_attr \"type\" \"neon_fp_mul_<Vetype>\")]\n+ [(set_attr \"type\" \"neon_fp_mul_<stype>\")]\n )\n \n ;; vmulxq_lane_f32, and vmulx_laneq_f32\n@@ -4310,16 +4313,18 @@\n ;; Note we can also handle what would be fac(le|lt) by\n ;; generating fac(ge|gt).\n \n-(define_insn \"*aarch64_fac<optab><mode>\"\n+(define_insn \"aarch64_fac<optab><mode>\"\n   [(set (match_operand:<V_cmp_result> 0 \"register_operand\" \"=w\")\n \t(neg:<V_cmp_result>\n \t  (FAC_COMPARISONS:<V_cmp_result>\n-\t    (abs:VALLF (match_operand:VALLF 1 \"register_operand\" \"w\"))\n-\t    (abs:VALLF (match_operand:VALLF 2 \"register_operand\" \"w\"))\n+\t    (abs:VHSDF_SDF\n+\t      (match_operand:VHSDF_SDF 1 \"register_operand\" \"w\"))\n+\t    (abs:VHSDF_SDF\n+\t      (match_operand:VHSDF_SDF 2 \"register_operand\" \"w\"))\n   )))]\n   \"TARGET_SIMD\"\n   \"fac<n_optab>\\t%<v>0<Vmtype>, %<v><cmp_1><Vmtype>, %<v><cmp_2><Vmtype>\"\n-  [(set_attr \"type\" \"neon_fp_compare_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_compare_<stype><q>\")]\n )\n \n ;; addp\n@@ -5431,13 +5436,14 @@\n )\n \n (define_insn \"aarch64_frecps<mode>\"\n-  [(set (match_operand:VALLF 0 \"register_operand\" \"=w\")\n-\t(unspec:VALLF [(match_operand:VALLF 1 \"register_operand\" \"w\")\n-\t\t     (match_operand:VALLF 2 \"register_operand\" \"w\")]\n-\t\t    UNSPEC_FRECPS))]\n+  [(set (match_operand:VHSDF_SDF 0 \"register_operand\" \"=w\")\n+\t(unspec:VHSDF_SDF\n+\t  [(match_operand:VHSDF_SDF 1 \"register_operand\" \"w\")\n+\t  (match_operand:VHSDF_SDF 2 \"register_operand\" \"w\")]\n+\t  UNSPEC_FRECPS))]\n   \"TARGET_SIMD\"\n   \"frecps\\\\t%<v>0<Vmtype>, %<v>1<Vmtype>, %<v>2<Vmtype>\"\n-  [(set_attr \"type\" \"neon_fp_recps_<Vetype><q>\")]\n+  [(set_attr \"type\" \"neon_fp_recps_<stype><q>\")]\n )\n \n (define_insn \"aarch64_urecpe<mode>\""}, {"sha": "fe2683e2032b17e789080648bc829027313f9e8a", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "patch": "@@ -7604,6 +7604,10 @@ bool\n aarch64_emit_approx_div (rtx quo, rtx num, rtx den)\n {\n   machine_mode mode = GET_MODE (quo);\n+\n+  if (GET_MODE_INNER (mode) == HFmode)\n+    return false;\n+\n   bool use_approx_division_p = (flag_mlow_precision_div\n \t\t\t        || (aarch64_tune_params.approx_modes->division\n \t\t\t\t    & AARCH64_APPROX_MODE (mode)));"}, {"sha": "baae27619a6a1c34c0ad338f2afec4932b51cbeb", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 362, "deletions": 0, "changes": 362, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "patch": "@@ -26385,6 +26385,368 @@ vsqrtq_f16 (float16x8_t a)\n   return __builtin_aarch64_sqrtv8hf (a);\n }\n \n+/* ARMv8.2-A FP16 two operands vector intrinsics.  */\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vadd_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __a + __b;\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vaddq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __a + __b;\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vabd_f16 (float16x4_t a, float16x4_t b)\n+{\n+  return __builtin_aarch64_fabdv4hf (a, b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vabdq_f16 (float16x8_t a, float16x8_t b)\n+{\n+  return __builtin_aarch64_fabdv8hf (a, b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcage_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_facgev4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcageq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_facgev8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcagt_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_facgtv4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcagtq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_facgtv8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcale_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_faclev4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcaleq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_faclev8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcalt_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_facltv4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcaltq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_facltv8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vceq_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_cmeqv4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vceqq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_cmeqv8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcge_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_cmgev4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcgeq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_cmgev8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcgt_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_cmgtv4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcgtq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_cmgtv8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcle_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_cmlev4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcleq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_cmlev8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vclt_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_cmltv4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcltq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_cmltv8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vcvt_n_f16_s16 (int16x4_t __a, const int __b)\n+{\n+  return __builtin_aarch64_scvtfv4hi (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vcvtq_n_f16_s16 (int16x8_t __a, const int __b)\n+{\n+  return __builtin_aarch64_scvtfv8hi (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vcvt_n_f16_u16 (uint16x4_t __a, const int __b)\n+{\n+  return __builtin_aarch64_ucvtfv4hi_sus (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vcvtq_n_f16_u16 (uint16x8_t __a, const int __b)\n+{\n+  return __builtin_aarch64_ucvtfv8hi_sus (__a, __b);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vcvt_n_s16_f16 (float16x4_t __a, const int __b)\n+{\n+  return __builtin_aarch64_fcvtzsv4hf (__a, __b);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vcvtq_n_s16_f16 (float16x8_t __a, const int __b)\n+{\n+  return __builtin_aarch64_fcvtzsv8hf (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcvt_n_u16_f16 (float16x4_t __a, const int __b)\n+{\n+  return __builtin_aarch64_fcvtzuv4hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcvtq_n_u16_f16 (float16x8_t __a, const int __b)\n+{\n+  return __builtin_aarch64_fcvtzuv8hf_uss (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vdiv_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __a / __b;\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vdivq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __a / __b;\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vmax_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_smax_nanv4hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vmaxq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_smax_nanv8hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vmaxnm_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_fmaxv4hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vmaxnmq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_fmaxv8hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vmin_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_smin_nanv4hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vminq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_smin_nanv8hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vminnm_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_fminv4hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vminnmq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_fminv8hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vmul_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __a * __b;\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vmulq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __a * __b;\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vmulx_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_fmulxv4hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vmulxq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_fmulxv8hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vpadd_f16 (float16x4_t a, float16x4_t b)\n+{\n+  return __builtin_aarch64_faddpv4hf (a, b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vpaddq_f16 (float16x8_t a, float16x8_t b)\n+{\n+  return __builtin_aarch64_faddpv8hf (a, b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vpmax_f16 (float16x4_t a, float16x4_t b)\n+{\n+  return __builtin_aarch64_smax_nanpv4hf (a, b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vpmaxq_f16 (float16x8_t a, float16x8_t b)\n+{\n+  return __builtin_aarch64_smax_nanpv8hf (a, b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vpmaxnm_f16 (float16x4_t a, float16x4_t b)\n+{\n+  return __builtin_aarch64_smaxpv4hf (a, b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vpmaxnmq_f16 (float16x8_t a, float16x8_t b)\n+{\n+  return __builtin_aarch64_smaxpv8hf (a, b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vpmin_f16 (float16x4_t a, float16x4_t b)\n+{\n+  return __builtin_aarch64_smin_nanpv4hf (a, b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vpminq_f16 (float16x8_t a, float16x8_t b)\n+{\n+  return __builtin_aarch64_smin_nanpv8hf (a, b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vpminnm_f16 (float16x4_t a, float16x4_t b)\n+{\n+  return __builtin_aarch64_sminpv4hf (a, b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vpminnmq_f16 (float16x8_t a, float16x8_t b)\n+{\n+  return __builtin_aarch64_sminpv8hf (a, b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vrecps_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __builtin_aarch64_frecpsv4hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vrecpsq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __builtin_aarch64_frecpsv8hf (__a, __b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vrsqrts_f16 (float16x4_t a, float16x4_t b)\n+{\n+  return __builtin_aarch64_rsqrtsv4hf (a, b);\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vrsqrtsq_f16 (float16x8_t a, float16x8_t b)\n+{\n+  return __builtin_aarch64_rsqrtsv8hf (a, b);\n+}\n+\n+__extension__ static __inline float16x4_t __attribute__ ((__always_inline__))\n+vsub_f16 (float16x4_t __a, float16x4_t __b)\n+{\n+  return __a - __b;\n+}\n+\n+__extension__ static __inline float16x8_t __attribute__ ((__always_inline__))\n+vsubq_f16 (float16x8_t __a, float16x8_t __b)\n+{\n+  return __a - __b;\n+}\n+\n #pragma GCC pop_options\n \n #undef __aarch64_vget_lane_any"}, {"sha": "35190b4343bd6dfb3a77a58bd1697426962cedc7", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/33d72b63863de2dedfa7a697d7d0b0e8b80e1416/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=33d72b63863de2dedfa7a697d7d0b0e8b80e1416", "patch": "@@ -166,9 +166,19 @@\n ;; Vector modes for S and D\n (define_mode_iterator VDQ_SDI [V2SI V4SI V2DI])\n \n+;; Vector modes for H, S and D\n+(define_mode_iterator VDQ_HSDI [(V4HI \"TARGET_SIMD_F16INST\")\n+\t\t\t\t(V8HI \"TARGET_SIMD_F16INST\")\n+\t\t\t\tV2SI V4SI V2DI])\n+\n ;; Scalar and Vector modes for S and D\n (define_mode_iterator VSDQ_SDI [V2SI V4SI V2DI SI DI])\n \n+;; Scalar and Vector modes for S and D, Vector modes for H.\n+(define_mode_iterator VSDQ_HSDI [(V4HI \"TARGET_SIMD_F16INST\")\n+\t\t\t\t (V8HI \"TARGET_SIMD_F16INST\")\n+\t\t\t\t V2SI V4SI V2DI SI DI])\n+\n ;; Vector modes for Q and H types.\n (define_mode_iterator VDQQH [V8QI V16QI V4HI V8HI])\n "}]}