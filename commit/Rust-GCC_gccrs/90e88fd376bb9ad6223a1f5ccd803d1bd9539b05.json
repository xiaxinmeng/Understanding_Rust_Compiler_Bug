{"sha": "90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTBlODhmZDM3NmJiOWFkNjIyM2ExZjVjY2Q4MDNkMWJkOTUzOWIwNQ==", "commit": {"author": {"name": "Andrew MacLeod", "email": "amacleod@redhat.com", "date": "2020-10-06T16:12:53Z"}, "committer": {"name": "Andrew MacLeod", "email": "amacleod@redhat.com", "date": "2020-10-06T16:47:59Z"}, "message": "Ranger classes.\n\nAdd the 8 ranger files and the Makefile changes to build it.\n\n2020-10-06  Andrew MacLeod  <amacleod@redhat.com>\n\n\t* Makefile.in (OBJS): Add gimple-range*.o.\n\t* gimple-range.h: New file.\n\t* gimple-range.cc: New file.\n\t* gimple-range-cache.h: New file.\n\t* gimple-range-cache.cc: New file.\n\t* gimple-range-edge.h: New file.\n\t* gimple-range-edge.cc: New file.\n\t* gimple-range-gori.h: New file.\n\t* gimple-range-gori.cc: New file.", "tree": {"sha": "7272e9d5642fd7ae4c15cefc98dea5b5a1b71db0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7272e9d5642fd7ae4c15cefc98dea5b5a1b71db0"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "html_url": "https://github.com/Rust-GCC/gccrs/commit/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/comments", "author": null, "committer": null, "parents": [{"sha": "1644d7f4c1c4f99231d7de5e35fa7ce2d2e2c4c6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1644d7f4c1c4f99231d7de5e35fa7ce2d2e2c4c6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1644d7f4c1c4f99231d7de5e35fa7ce2d2e2c4c6"}], "stats": {"total": 4166, "additions": 4166, "deletions": 0}, "files": [{"sha": "5a8fb0d7612f36607327429413b5ed1c47c0f632", "filename": "gcc/Makefile.in", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -1369,6 +1369,10 @@ OBJS = \\\n \tgimple-loop-versioning.o \\\n \tgimple-low.o \\\n \tgimple-pretty-print.o \\\n+\tgimple-range.o \\\n+\tgimple-range-cache.o \\\n+\tgimple-range-edge.o \\\n+\tgimple-range-gori.o \\\n \tgimple-ssa-backprop.o \\\n \tgimple-ssa-evrp.o \\\n \tgimple-ssa-evrp-analyze.o \\"}, {"sha": "13b9933cc019813add3297cdbab8c9c2ab362f49", "filename": "gcc/gimple-range-cache.cc", "status": "added", "additions": 877, "deletions": 0, "changes": 877, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-cache.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-cache.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range-cache.cc?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,877 @@\n+/* Gimple ranger SSA cache implementation.\n+   Copyright (C) 2017-2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"insn-codes.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"ssa.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"gimple-range.h\"\n+\n+// During contructor, allocate the vector of ssa_names.\n+\n+non_null_ref::non_null_ref ()\n+{\n+  m_nn.create (0);\n+  m_nn.safe_grow_cleared (num_ssa_names);\n+  bitmap_obstack_initialize (&m_bitmaps);\n+}\n+\n+// Free any bitmaps which were allocated,a swell as the vector itself.\n+\n+non_null_ref::~non_null_ref ()\n+{\n+  bitmap_obstack_release (&m_bitmaps);\n+  m_nn.release ();\n+}\n+\n+// Return true if NAME has a non-null dereference in block bb.  If this is the\n+// first query for NAME, calculate the summary first.\n+\n+bool\n+non_null_ref::non_null_deref_p (tree name, basic_block bb)\n+{\n+  if (!POINTER_TYPE_P (TREE_TYPE (name)))\n+    return false;\n+\n+  unsigned v = SSA_NAME_VERSION (name);\n+  if (!m_nn[v])\n+    process_name (name);\n+\n+  return bitmap_bit_p (m_nn[v], bb->index);\n+}\n+\n+// Allocate an populate the bitmap for NAME.  An ON bit for a block\n+// index indicates there is a non-null reference in that block.  In\n+// order to populate the bitmap, a quick run of all the immediate uses\n+// are made and the statement checked to see if a non-null dereference\n+// is made on that statement.\n+\n+void\n+non_null_ref::process_name (tree name)\n+{\n+  unsigned v = SSA_NAME_VERSION (name);\n+  use_operand_p use_p;\n+  imm_use_iterator iter;\n+  bitmap b;\n+\n+  // Only tracked for pointers.\n+  if (!POINTER_TYPE_P (TREE_TYPE (name)))\n+    return;\n+\n+  // Already processed if a bitmap has been allocated.\n+  if (m_nn[v])\n+    return;\n+\n+  b = BITMAP_ALLOC (&m_bitmaps);\n+\n+  // Loop over each immediate use and see if it implies a non-null value.\n+  FOR_EACH_IMM_USE_FAST (use_p, iter, name)\n+    {\n+      gimple *s = USE_STMT (use_p);\n+      unsigned index = gimple_bb (s)->index;\n+      tree value;\n+      enum tree_code comp_code;\n+\n+      // If bit is already set for this block, dont bother looking again.\n+      if (bitmap_bit_p (b, index))\n+\tcontinue;\n+\n+      // If we can infer a != 0 range, then set the bit for this BB\n+      if (infer_value_range (s, name, &comp_code, &value))\n+\t{\n+\t  if (comp_code == NE_EXPR && integer_zerop (value))\n+\t    bitmap_set_bit (b, index);\n+\t}\n+    }\n+\n+  m_nn[v] = b;\n+}\n+\n+// -------------------------------------------------------------------------\n+\n+// This class implements a cache of ranges indexed by basic block.  It\n+// represents all that is known about an SSA_NAME on entry to each\n+// block.  It caches a range-for-type varying range so it doesn't need\n+// to be reformed all the time.  If a range is ever always associated\n+// with a type, we can use that instead.  Whenever varying is being\n+// set for a block, the cache simply points to this cached one rather\n+// than create a new one each time.\n+\n+class ssa_block_ranges\n+{\n+public:\n+  ssa_block_ranges (tree t, irange_allocator *allocator);\n+  ~ssa_block_ranges ();\n+\n+  void set_bb_range (const basic_block bb, const irange &r);\n+  void set_bb_varying (const basic_block bb);\n+  bool get_bb_range (irange &r, const basic_block bb);\n+  bool bb_range_p (const basic_block bb);\n+\n+  void dump(FILE *f);\n+private:\n+  vec<irange *> m_tab;\n+  irange *m_type_range;\n+  tree m_type;\n+  irange_allocator *m_irange_allocator;\n+};\n+\n+\n+// Initialize a block cache for an ssa_name of type T.\n+\n+ssa_block_ranges::ssa_block_ranges (tree t, irange_allocator *allocator)\n+{\n+  gcc_checking_assert (TYPE_P (t));\n+  m_type = t;\n+  m_irange_allocator = allocator;\n+\n+  m_tab.create (0);\n+  m_tab.safe_grow_cleared (last_basic_block_for_fn (cfun));\n+\n+  // Create the cached type range.\n+  m_type_range = m_irange_allocator->allocate (2);\n+  m_type_range->set_varying (t);\n+\n+  m_tab[ENTRY_BLOCK_PTR_FOR_FN (cfun)->index] = m_type_range;\n+}\n+\n+// Destruct block range.\n+\n+ssa_block_ranges::~ssa_block_ranges ()\n+{\n+  m_tab.release ();\n+}\n+\n+// Set the range for block BB to be R.\n+\n+void\n+ssa_block_ranges::set_bb_range (const basic_block bb, const irange &r)\n+{\n+  irange *m = m_irange_allocator->allocate (r);\n+  m_tab[bb->index] = m;\n+}\n+\n+// Set the range for block BB to the range for the type.\n+\n+void\n+ssa_block_ranges::set_bb_varying (const basic_block bb)\n+{\n+  m_tab[bb->index] = m_type_range;\n+}\n+\n+// Return the range associated with block BB in R.  Return false if\n+// there is no range.\n+\n+bool\n+ssa_block_ranges::get_bb_range (irange &r, const basic_block bb)\n+{\n+  irange *m = m_tab[bb->index];\n+  if (m)\n+    {\n+      r = *m;\n+      return true;\n+    }\n+  return false;\n+}\n+\n+// Return true if a range is present.\n+\n+bool\n+ssa_block_ranges::bb_range_p (const basic_block bb)\n+{\n+  return m_tab[bb->index] != NULL;\n+}\n+\n+\n+// Print the list of known ranges for file F in a nice format.\n+\n+void\n+ssa_block_ranges::dump (FILE *f)\n+{\n+  basic_block bb;\n+  int_range_max r;\n+\n+  FOR_EACH_BB_FN (bb, cfun)\n+    if (get_bb_range (r, bb))\n+      {\n+\tfprintf (f, \"BB%d  -> \", bb->index);\n+\tr.dump (f);\n+\tfprintf (f, \"\\n\");\n+      }\n+}\n+\n+// -------------------------------------------------------------------------\n+\n+// Initialize the block cache.\n+\n+block_range_cache::block_range_cache ()\n+{\n+  m_ssa_ranges.create (0);\n+  m_ssa_ranges.safe_grow_cleared (num_ssa_names);\n+  m_irange_allocator = new irange_allocator;\n+}\n+\n+// Remove any m_block_caches which have been created.\n+\n+block_range_cache::~block_range_cache ()\n+{\n+  unsigned x;\n+  for (x = 0; x < m_ssa_ranges.length (); ++x)\n+    {\n+      if (m_ssa_ranges[x])\n+\tdelete m_ssa_ranges[x];\n+    }\n+  delete m_irange_allocator;\n+  // Release the vector itself.\n+  m_ssa_ranges.release ();\n+}\n+\n+// Return a reference to the m_block_cache for NAME.  If it has not been\n+// accessed yet, allocate it.\n+\n+ssa_block_ranges &\n+block_range_cache::get_block_ranges (tree name)\n+{\n+  unsigned v = SSA_NAME_VERSION (name);\n+  if (v >= m_ssa_ranges.length ())\n+    m_ssa_ranges.safe_grow_cleared (num_ssa_names + 1);\n+\n+  if (!m_ssa_ranges[v])\n+    m_ssa_ranges[v] = new ssa_block_ranges (TREE_TYPE (name), m_irange_allocator);\n+\n+  return *(m_ssa_ranges[v]);\n+}\n+\n+// Set the range for NAME on entry to block BB to R.\n+\n+void\n+block_range_cache::set_bb_range (tree name, const basic_block bb,\n+\t\t\t\t const irange &r)\n+{\n+  return get_block_ranges (name).set_bb_range (bb, r);\n+}\n+\n+// Set the range for NAME on entry to block BB to varying.\n+\n+void\n+block_range_cache::set_bb_varying (tree name, const basic_block bb)\n+{\n+  return get_block_ranges (name).set_bb_varying (bb);\n+}\n+\n+// Return the range for NAME on entry to BB in R.  Return true if there\n+// is one.\n+\n+bool\n+block_range_cache::get_bb_range (irange &r, tree name, const basic_block bb)\n+{\n+  return get_block_ranges (name).get_bb_range (r, bb);\n+}\n+\n+// Return true if NAME has a range set in block BB.\n+\n+bool\n+block_range_cache::bb_range_p (tree name, const basic_block bb)\n+{\n+  return get_block_ranges (name).bb_range_p (bb);\n+}\n+\n+// Print all known block caches to file F.\n+\n+void\n+block_range_cache::dump (FILE *f)\n+{\n+  unsigned x;\n+  for (x = 0; x < m_ssa_ranges.length (); ++x)\n+    {\n+      if (m_ssa_ranges[x])\n+\t{\n+\t  fprintf (f, \" Ranges for \");\n+\t  print_generic_expr (f, ssa_name (x), TDF_NONE);\n+\t  fprintf (f, \":\\n\");\n+\t  m_ssa_ranges[x]->dump (f);\n+\t  fprintf (f, \"\\n\");\n+\t}\n+    }\n+}\n+\n+// Print all known ranges on entry to blobk BB to file F.\n+\n+void\n+block_range_cache::dump (FILE *f, basic_block bb, bool print_varying)\n+{\n+  unsigned x;\n+  int_range_max r;\n+  bool summarize_varying = false;\n+  for (x = 1; x < m_ssa_ranges.length (); ++x)\n+    {\n+      if (!gimple_range_ssa_p (ssa_name (x)))\n+\tcontinue;\n+      if (m_ssa_ranges[x] && m_ssa_ranges[x]->get_bb_range (r, bb))\n+\t{\n+\t  if (!print_varying && r.varying_p ())\n+\t    {\n+\t      summarize_varying = true;\n+\t      continue;\n+\t    }\n+\t  print_generic_expr (f, ssa_name (x), TDF_NONE);\n+\t  fprintf (f, \"\\t\");\n+\t  r.dump(f);\n+\t  fprintf (f, \"\\n\");\n+\t}\n+    }\n+  // If there were any varying entries, lump them all together.\n+  if (summarize_varying)\n+    {\n+      fprintf (f, \"VARYING_P on entry : \");\n+      for (x = 1; x < num_ssa_names; ++x)\n+\t{\n+\t  if (!gimple_range_ssa_p (ssa_name (x)))\n+\t    continue;\n+\t  if (m_ssa_ranges[x] && m_ssa_ranges[x]->get_bb_range (r, bb))\n+\t    {\n+\t      if (r.varying_p ())\n+\t\t{\n+\t\t  print_generic_expr (f, ssa_name (x), TDF_NONE);\n+\t\t  fprintf (f, \"  \");\n+\t\t}\n+\t    }\n+\t}\n+      fprintf (f, \"\\n\");\n+    }\n+}\n+\n+// -------------------------------------------------------------------------\n+\n+// Initialize a global cache.\n+\n+ssa_global_cache::ssa_global_cache ()\n+{\n+  m_tab.create (0);\n+  m_tab.safe_grow_cleared (num_ssa_names);\n+  m_irange_allocator = new irange_allocator;\n+}\n+\n+// Deconstruct a global cache.\n+\n+ssa_global_cache::~ssa_global_cache ()\n+{\n+  m_tab.release ();\n+  delete m_irange_allocator;\n+}\n+\n+// Retrieve the global range of NAME from cache memory if it exists. \n+// Return the value in R.\n+\n+bool\n+ssa_global_cache::get_global_range (irange &r, tree name) const\n+{\n+  unsigned v = SSA_NAME_VERSION (name);\n+  if (v >= m_tab.length ())\n+    return false;\n+\n+  irange *stow = m_tab[v];\n+  if (!stow)\n+    return false;\n+  r = *stow;\n+  return true;\n+}\n+\n+// Set the range for NAME to R in the global cache.\n+\n+void\n+ssa_global_cache::set_global_range (tree name, const irange &r)\n+{\n+  unsigned v = SSA_NAME_VERSION (name);\n+  if (v >= m_tab.length ())\n+    m_tab.safe_grow_cleared (num_ssa_names + 1);\n+\n+  irange *m = m_tab[v];\n+  if (m && m->fits_p (r))\n+    *m = r;\n+  else\n+    m_tab[v] = m_irange_allocator->allocate (r);\n+}\n+\n+// Set the range for NAME to R in the glonbal cache.\n+\n+void\n+ssa_global_cache::clear_global_range (tree name)\n+{\n+  unsigned v = SSA_NAME_VERSION (name);\n+  if (v >= m_tab.length ())\n+    m_tab.safe_grow_cleared (num_ssa_names + 1);\n+  m_tab[v] = NULL;\n+}\n+\n+// Clear the global cache.\n+\n+void\n+ssa_global_cache::clear ()\n+{\n+  memset (m_tab.address(), 0, m_tab.length () * sizeof (irange *));\n+}\n+\n+// Dump the contents of the global cache to F.\n+\n+void\n+ssa_global_cache::dump (FILE *f)\n+{\n+  unsigned x;\n+  int_range_max r;\n+  fprintf (f, \"Non-varying global ranges:\\n\");\n+  fprintf (f, \"=========================:\\n\");\n+  for ( x = 1; x < num_ssa_names; x++)\n+    if (gimple_range_ssa_p (ssa_name (x)) &&\n+\tget_global_range (r, ssa_name (x))  && !r.varying_p ())\n+      {\n+\tprint_generic_expr (f, ssa_name (x), TDF_NONE);\n+\tfprintf (f, \"  : \");\n+\tr.dump (f);\n+\tfprintf (f, \"\\n\");\n+      }\n+  fputc ('\\n', f);\n+}\n+\n+// --------------------------------------------------------------------------\n+\n+ranger_cache::ranger_cache (range_query &q) : query (q)\n+{\n+  m_workback.create (0);\n+  m_workback.safe_grow_cleared (last_basic_block_for_fn (cfun));\n+  m_update_list.create (0);\n+  m_update_list.safe_grow_cleared (last_basic_block_for_fn (cfun));\n+  m_update_list.truncate (0);\n+  m_poor_value_list.create (0);\n+  m_poor_value_list.safe_grow_cleared (20);\n+  m_poor_value_list.truncate (0);\n+}\n+\n+ranger_cache::~ranger_cache ()\n+{\n+  m_poor_value_list.release ();\n+  m_workback.release ();\n+  m_update_list.release ();\n+}\n+\n+// Push a request for a new lookup in block BB of name.  Return true if\n+// the request is actually made (ie, isn't a duplicate).\n+\n+bool\n+ranger_cache::push_poor_value (basic_block bb, tree name)\n+{\n+  if (m_poor_value_list.length ())\n+    {\n+      // Don't push anything else to the same block.  If there are multiple \n+      // things required, another request will come during a later evaluation\n+      // and this prevents oscillation building uneccessary depth.\n+      if ((m_poor_value_list.last ()).bb == bb)\n+\treturn false;\n+    }\n+\n+  struct update_record rec;\n+  rec.bb = bb;\n+  rec.calc = name;\n+  m_poor_value_list.safe_push (rec);\n+  return true;\n+}\n+\n+//  Provide lookup for the gori-computes class to access the best known range\n+//  of an ssa_name in any given basic block.  Note, this does no additonal\n+//  lookups, just accesses the data that is already known.\n+\n+void\n+ranger_cache::ssa_range_in_bb (irange &r, tree name, basic_block bb)\n+{\n+  gimple *s = SSA_NAME_DEF_STMT (name);\n+  basic_block def_bb = ((s && gimple_bb (s)) ? gimple_bb (s) :\n+\t\t\t\t\t       ENTRY_BLOCK_PTR_FOR_FN (cfun));\n+  if (bb == def_bb)\n+    {\n+      // NAME is defined in this block, so request its current value\n+      if (!m_globals.get_global_range (r, name))\n+\t{\n+\t  // If it doesn't have a value calculated, it means it's a\n+\t  // \"poor\" value being used in some calculation.  Queue it up\n+\t  // as a poor value to be improved later.\n+\t  r = gimple_range_global (name);\n+\t  if (push_poor_value (bb, name))\n+\t    {\n+\t      if (DEBUG_RANGE_CACHE)\n+\t\t{\n+\t\t  fprintf (dump_file,\n+\t\t\t   \"*CACHE* no global def in bb %d for \", bb->index);\n+\t\t  print_generic_expr (dump_file, name, TDF_SLIM);\n+\t\t  fprintf (dump_file, \" depth : %d\\n\",\n+\t\t\t   m_poor_value_list.length ());\n+\t\t}\n+\t    }\n+\t }\n+    }\n+  // Look for the on-entry value of name in BB from the cache.\n+  else if (!m_on_entry.get_bb_range (r, name, bb))\n+    {\n+      // If it has no entry then mark this as a poor value.\n+      if (push_poor_value (bb, name))\n+\t{\n+\t  if (DEBUG_RANGE_CACHE)\n+\t    {\n+\t      fprintf (dump_file,\n+\t\t       \"*CACHE* no on entry range in bb %d for \", bb->index);\n+\t      print_generic_expr (dump_file, name, TDF_SLIM);\n+\t      fprintf (dump_file, \" depth : %d\\n\", m_poor_value_list.length ());\n+\t    }\n+\t}\n+      // Try to pick up any known global value as a best guess for now.\n+      if (!m_globals.get_global_range (r, name))\n+\tr = gimple_range_global (name);\n+    }\n+\n+  // Check if pointers have any non-null dereferences.  Non-call\n+  // exceptions mean we could throw in the middle of the block, so just\n+  // punt for now on those.\n+  if (r.varying_p () && m_non_null.non_null_deref_p (name, bb) &&\n+      !cfun->can_throw_non_call_exceptions)\n+    r = range_nonzero (TREE_TYPE (name));\n+}\n+\n+// Return a static range for NAME on entry to basic block BB in R.  If\n+// calc is true, fill any cache entries required between BB and the\n+// def block for NAME.  Otherwise, return false if the cache is empty.\n+\n+bool\n+ranger_cache::block_range (irange &r, basic_block bb, tree name, bool calc)\n+{\n+  gcc_checking_assert (gimple_range_ssa_p (name));\n+\n+  if (calc)\n+    {\n+      gimple *def_stmt = SSA_NAME_DEF_STMT (name);\n+      basic_block def_bb = NULL;\n+      if (def_stmt)\n+\tdef_bb = gimple_bb (def_stmt);;\n+      if (!def_bb)\n+\t{\n+\t  // If we get to the entry block, this better be a default def\n+\t  // or range_on_entry was called for a block not dominated by\n+\t  // the def.  \n+\t  gcc_checking_assert (SSA_NAME_IS_DEFAULT_DEF (name));\n+\t  def_bb = ENTRY_BLOCK_PTR_FOR_FN (cfun);\n+\t}\n+\n+      // There is no range on entry for the definition block.\n+      if (def_bb == bb)\n+\treturn false;\n+\n+      // Otherwise, go figure out what is known in predecessor blocks.\n+      fill_block_cache (name, bb, def_bb);\n+      gcc_checking_assert (m_on_entry.bb_range_p (name, bb));\n+    }\n+  return m_on_entry.get_bb_range (r, name, bb);\n+}\n+\n+// Add BB to the list of blocks to update, unless it's already in the list.\n+\n+void\n+ranger_cache::add_to_update (basic_block bb)\n+{\n+  if (!m_update_list.contains (bb))\n+    m_update_list.quick_push (bb);\n+}\n+\n+// If there is anything in the iterative update_list, continue\n+// processing NAME until the list of blocks is empty.\n+\n+void\n+ranger_cache::iterative_cache_update (tree name)\n+{\n+  basic_block bb;\n+  edge_iterator ei;\n+  edge e;\n+  int_range_max new_range;\n+  int_range_max current_range;\n+  int_range_max e_range;\n+\n+  // Process each block by seeing if its calculated range on entry is\n+  // the same as its cached value. If there is a difference, update\n+  // the cache to reflect the new value, and check to see if any\n+  // successors have cache entries which may need to be checked for\n+  // updates.\n+\n+  while (m_update_list.length () > 0)\n+    {\n+      bb = m_update_list.pop ();\n+      gcc_checking_assert (m_on_entry.bb_range_p (name, bb));\n+      m_on_entry.get_bb_range (current_range, name, bb);\n+\n+      // Calculate the \"new\" range on entry by unioning the pred edges.\n+      new_range.set_undefined ();\n+      FOR_EACH_EDGE (e, ei, bb->preds)\n+\t{\n+\t  if (DEBUG_RANGE_CACHE)\n+\t    fprintf (dump_file, \"   edge %d->%d :\", e->src->index, bb->index);\n+\t  // Get whatever range we can for this edge.\n+\t  if (!outgoing_edge_range_p (e_range, e, name))\n+\t    {\n+\t      ssa_range_in_bb (e_range, name, e->src);\n+\t      if (DEBUG_RANGE_CACHE)\n+\t\t{\n+\t\t  fprintf (dump_file, \"No outgoing edge range, picked up \");\n+\t\t  e_range.dump(dump_file);\n+\t\t  fprintf (dump_file, \"\\n\");\n+\t\t}\n+\t    }\n+\t  else\n+\t    {\n+\t      if (DEBUG_RANGE_CACHE)\n+\t\t{\n+\t\t  fprintf (dump_file, \"outgoing range :\");\n+\t\t  e_range.dump(dump_file);\n+\t\t  fprintf (dump_file, \"\\n\");\n+\t\t}\n+\t    }\n+\t  new_range.union_ (e_range);\n+\t  if (new_range.varying_p ())\n+\t    break;\n+\t}\n+\n+      if (DEBUG_RANGE_CACHE)\n+\t{\n+\t  fprintf (dump_file, \"FWD visiting block %d for \", bb->index);\n+\t  print_generic_expr (dump_file, name, TDF_SLIM);\n+\t  fprintf (dump_file, \"  starting range : \");\n+\t  current_range.dump (dump_file);\n+\t  fprintf (dump_file, \"\\n\");\n+\t}\n+\n+      // If the range on entry has changed, update it.\n+      if (new_range != current_range)\n+\t{\n+\t  if (DEBUG_RANGE_CACHE) \n+\t    {\n+\t      fprintf (dump_file, \"      Updating range to \");\n+\t      new_range.dump (dump_file);\n+\t      fprintf (dump_file, \"\\n      Updating blocks :\");\n+\t    }\n+\t  m_on_entry.set_bb_range (name, bb, new_range);\n+\t  // Mark each successor that has a range to re-check its range\n+\t  FOR_EACH_EDGE (e, ei, bb->succs)\n+\t    if (m_on_entry.bb_range_p (name, e->dest))\n+\t      {\n+\t\tif (DEBUG_RANGE_CACHE) \n+\t\t  fprintf (dump_file, \" bb%d\",e->dest->index);\n+\t\tadd_to_update (e->dest);\n+\t      }\n+\t  if (DEBUG_RANGE_CACHE) \n+\t    fprintf (dump_file, \"\\n\");\n+\t}\n+    }\n+    if (DEBUG_RANGE_CACHE)\n+      {\n+\tfprintf (dump_file, \"DONE visiting blocks for \");\n+\tprint_generic_expr (dump_file, name, TDF_SLIM);\n+\tfprintf (dump_file, \"\\n\");\n+      }\n+}\n+\n+// Make sure that the range-on-entry cache for NAME is set for block BB.\n+// Work back through the CFG to DEF_BB ensuring the range is calculated\n+// on the block/edges leading back to that point.\n+\n+void\n+ranger_cache::fill_block_cache (tree name, basic_block bb, basic_block def_bb)\n+{\n+  edge_iterator ei;\n+  edge e;\n+  int_range_max block_result;\n+  int_range_max undefined;\n+  unsigned poor_list_start = m_poor_value_list.length ();  \n+\n+  // At this point we shouldn't be looking at the def, entry or exit block.\n+  gcc_checking_assert (bb != def_bb && bb != ENTRY_BLOCK_PTR_FOR_FN (cfun) &&\n+\t\t       bb != EXIT_BLOCK_PTR_FOR_FN (cfun));\n+\n+  // If the block cache is set, then we've already visited this block.\n+  if (m_on_entry.bb_range_p (name, bb))\n+    return;\n+\n+  // Visit each block back to the DEF.  Initialize each one to UNDEFINED.\n+  // m_visited at the end will contain all the blocks that we needed to set\n+  // the range_on_entry cache for.\n+  m_workback.truncate (0);\n+  m_workback.quick_push (bb);\n+  undefined.set_undefined ();\n+  m_on_entry.set_bb_range (name, bb, undefined);\n+  gcc_checking_assert (m_update_list.length () == 0);\n+\n+  if (DEBUG_RANGE_CACHE)\n+    {\n+      fprintf (dump_file, \"\\n\");\n+      print_generic_expr (dump_file, name, TDF_SLIM);\n+      fprintf (dump_file, \" : \");\n+    }\n+\n+  while (m_workback.length () > 0)\n+    {\n+      basic_block node = m_workback.pop ();\n+      if (DEBUG_RANGE_CACHE)\n+\t{\n+\t  fprintf (dump_file, \"BACK visiting block %d for \", node->index);\n+\t  print_generic_expr (dump_file, name, TDF_SLIM);\n+\t  fprintf (dump_file, \"\\n\");\n+\t}\n+\n+      FOR_EACH_EDGE (e, ei, node->preds)\n+\t{\n+\t  basic_block pred = e->src;\n+\t  int_range_max r;\n+\n+\t  if (DEBUG_RANGE_CACHE)\n+\t    fprintf (dump_file, \"  %d->%d \",e->src->index, e->dest->index);\n+\n+\t  // If the pred block is the def block add this BB to update list.\n+\t  if (pred == def_bb)\n+\t    {\n+\t      add_to_update (node);\n+\t      continue;\n+\t    }\n+\n+\t  // If the pred is entry but NOT def, then it is used before\n+\t  // defined, it'll get set to [] and no need to update it.\n+\t  if (pred == ENTRY_BLOCK_PTR_FOR_FN (cfun))\n+\t    {\n+\t      if (DEBUG_RANGE_CACHE)\n+\t\tfprintf (dump_file, \"entry: bail.\");\n+\t      continue;\n+\t    }\n+\n+\t  // Regardless of whether we have visited pred or not, if the\n+\t  // pred has a non-null reference, revisit this block.\n+\t  if (m_non_null.non_null_deref_p (name, pred))\n+\t    {\n+\t      if (DEBUG_RANGE_CACHE)\n+\t\tfprintf (dump_file, \"nonnull: update \");\n+\t      add_to_update (node);\n+\t    }\n+\n+\t  // If the pred block already has a range, or if it can contribute\n+\t  // something new. Ie, the edge generates a range of some sort.\n+\t  if (m_on_entry.get_bb_range (r, name, pred))\n+\t    {\n+\t      if (DEBUG_RANGE_CACHE)\n+\t\tfprintf (dump_file, \"has cache, \");\n+\t      if (!r.undefined_p () || has_edge_range_p (e, name))\n+\t\t{\n+\t\t  add_to_update (node);\n+\t\t  if (DEBUG_RANGE_CACHE)\n+\t\t    fprintf (dump_file, \"update. \");\n+\t\t}\n+\t      continue;\n+\t    }\n+\n+\t  if (DEBUG_RANGE_CACHE)\n+\t    fprintf (dump_file, \"pushing undefined pred block. \");\n+\t  // If the pred hasn't been visited (has no range), add it to\n+\t  // the list.\n+\t  gcc_checking_assert (!m_on_entry.bb_range_p (name, pred));\n+\t  m_on_entry.set_bb_range (name, pred, undefined);\n+\t  m_workback.quick_push (pred);\n+\t}\n+    }\n+\n+  if (DEBUG_RANGE_CACHE)\n+    fprintf (dump_file, \"\\n\");\n+\n+  // Now fill in the marked blocks with values.\n+  iterative_cache_update (name);\n+  if (DEBUG_RANGE_CACHE)\n+    fprintf (dump_file, \"  iterative update done.\\n\");\n+\n+  // Now that the cache has been updated, check to see if there were any \n+  // SSA_NAMES used in filling the cache which were \"poor values\".\n+  // We can evaluate them, and inject any new values into the iteration \n+  // list, and see if it improves any on-entry values.\n+  if (poor_list_start !=  m_poor_value_list.length ())\n+    {\n+      gcc_checking_assert (poor_list_start < m_poor_value_list.length ());\n+      while (poor_list_start < m_poor_value_list.length ())\n+\t{\n+\t  // Find a range for this unresolved value.   \n+\t  // Note, this may spawn new cache filling cycles, but by the time it\n+\t  // is finished, the work vectors will all be back to the same state\n+\t  // as before the call.  The update record vector will always be\n+\t  // returned to the current state upon return.\n+\t  struct update_record rec = m_poor_value_list.pop ();\n+\t  basic_block calc_bb = rec.bb;\n+\t  int_range_max tmp;\n+\n+\t  // The update work list should be empty at this point.\n+\t  gcc_checking_assert (m_update_list.length () == 0);\n+\n+\t  if (DEBUG_RANGE_CACHE)\n+\t    {\n+\t      fprintf (dump_file, \"(%d:%d)Calculating \",\n+\t\t       m_poor_value_list.length () + 1, poor_list_start);\n+\t      print_generic_expr (dump_file, name, TDF_SLIM);\n+\t      fprintf (dump_file, \" used poor value for \");\n+\t      print_generic_expr (dump_file, rec.calc, TDF_SLIM);\n+\t      fprintf (dump_file, \" in bb%d, trying to improve:\\n\",\n+\t\t       calc_bb->index);\n+\t    }\n+\n+\t  // It must have at least one edge, pick edge 0.  we just want to\n+\t  // calculate a range at the exit from the block so the caches feeding\n+\t  // this block will be filled up. \n+\t  gcc_checking_assert (EDGE_SUCC (calc_bb, 0));\n+\t  query.range_on_edge (tmp, EDGE_SUCC (calc_bb, 0), rec.calc);\n+\t  \n+\t  if (DEBUG_RANGE_CACHE)\n+\t    fprintf (dump_file, \"    Checking successors of bb%d :\",\n+\t\t     calc_bb->index);\n+\n+\t  // Try recalculating any successor blocks with the new value.\n+\t  // Note that even if this value is refined from the initial value,\n+\t  // it may not affect the calculation, but the iterative update\n+\t  // will resolve that efficently.\n+\t  FOR_EACH_EDGE (e, ei, calc_bb->succs)\n+\t    {\n+\t      if (DEBUG_RANGE_CACHE)\n+\t\tfprintf (dump_file, \"bb%d: \", e->dest->index);\n+\t      // Only update active cache entries.\n+\t      if (m_on_entry.bb_range_p (name, e->dest))\n+\t\t{\n+\t\t  if (DEBUG_RANGE_CACHE)\n+\t\t    fprintf (dump_file, \"update \");\n+\t\t  add_to_update (e->dest);\n+\t\t}\n+\t    }\n+\t  if (DEBUG_RANGE_CACHE)\n+\t    fprintf (dump_file, \"\\n\");\n+\t  // Now see if there is a new value.\n+\t  iterative_cache_update (name);\n+\t}\n+    }\n+ \n+}"}, {"sha": "29ab01e2a984d560b6198beeed89eaeac5202e2b", "filename": "gcc/gimple-range-cache.h", "status": "added", "additions": 120, "deletions": 0, "changes": 120, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-cache.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-cache.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range-cache.h?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,120 @@\n+/* Header file for gimple ranger SSA cache.\n+   Copyright (C) 2017-2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_SSA_RANGE_CACHE_H\n+#define GCC_SSA_RANGE_CACHE_H\n+\n+#include \"gimple-range-gori.h\" \n+\n+// Class used to track non-null references of an SSA name.  A vector\n+// of bitmaps indexed by SSA name is maintained.  When indexed by\n+// basic block, an on-bit indicates there is a non-null dereference\n+// for that SSA in that block.\n+\n+class non_null_ref\n+{\n+public:\n+  non_null_ref ();\n+  ~non_null_ref ();\n+  bool non_null_deref_p (tree name, basic_block bb);\n+private:\n+  vec <bitmap> m_nn;\n+  void process_name (tree name);\n+  bitmap_obstack m_bitmaps;\n+};\n+\n+// This class manages a vector of pointers to ssa_block ranges.  It\n+// provides the basis for the \"range on entry\" cache for all\n+// SSA names.\n+\n+class block_range_cache\n+{\n+public:\n+  block_range_cache ();\n+  ~block_range_cache ();\n+\n+  void set_bb_range (tree name, const basic_block bb, const irange &r);\n+  void set_bb_varying (tree name, const basic_block bb);\n+  bool get_bb_range (irange &r, tree name, const basic_block bb);\n+  bool bb_range_p (tree name, const basic_block bb);\n+\n+  void dump (FILE *f);\n+  void dump (FILE *f, basic_block bb, bool print_varying = true);\n+private:\n+  vec<class ssa_block_ranges *> m_ssa_ranges;\n+  ssa_block_ranges &get_block_ranges (tree name);\n+  irange_allocator *m_irange_allocator;\n+};\n+\n+// This global cache is used with the range engine as markers for what\n+// has been visited during this incarnation.  Once the ranger evaluates\n+// a name, it is typically not re-evaluated again.\n+\n+class ssa_global_cache\n+{\n+public:\n+  ssa_global_cache ();\n+  ~ssa_global_cache ();\n+  bool get_global_range (irange &r, tree name) const;\n+  void set_global_range (tree name, const irange &r);\n+  void clear_global_range (tree name);\n+  void clear ();\n+  void dump (FILE *f = stderr);\n+private:\n+  vec<irange *> m_tab;\n+  class irange_allocator *m_irange_allocator;\n+};\n+\n+// This class provides all the caches a global ranger may need, and makes \n+// them available for gori-computes to query so outgoing edges can be\n+// properly calculated.\n+\n+class ranger_cache : public gori_compute_cache\n+{\n+public:\n+  ranger_cache (class range_query &q);\n+  ~ranger_cache ();\n+\n+  virtual void ssa_range_in_bb (irange &r, tree name, basic_block bb);\n+  bool block_range (irange &r, basic_block bb, tree name, bool calc = true);\n+\n+  ssa_global_cache m_globals;\n+  block_range_cache m_on_entry;\n+  non_null_ref m_non_null;\n+private:\n+  void add_to_update (basic_block bb);\n+  void fill_block_cache (tree name, basic_block bb, basic_block def_bb);\n+  void iterative_cache_update (tree name);\n+\n+  vec<basic_block> m_workback;\n+  vec<basic_block> m_update_list;\n+\n+  // Iterative \"poor value\" calculations.\n+  struct update_record\n+  {\n+    basic_block bb;\t// Block which value needs to be calculated in.\n+    tree calc;\t\t// SSA_NAME which needs its value calculated.\n+  };\n+  bool push_poor_value (basic_block bb, tree name);\n+  vec<update_record> m_poor_value_list;\n+  class range_query &query;\n+};\n+\n+#endif // GCC_SSA_RANGE_CACHE_H"}, {"sha": "c5ee54fec51a2b293a180f700f1a2cc6d41e6ca8", "filename": "gcc/gimple-range-edge.cc", "status": "added", "additions": 197, "deletions": 0, "changes": 197, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-edge.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-edge.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range-edge.cc?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,197 @@\n+/* Gimple range edge functionaluity.\n+   Copyright (C) 2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>\n+   and Aldy Hernandez <aldyh@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"ssa.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"gimple-iterator.h\"\n+#include \"tree-cfg.h\"\n+#include \"gimple-range.h\"\n+\n+// If there is a range control statment at the end of block BB, return it.\n+// Otherwise return NULL.\n+\n+gimple *\n+gimple_outgoing_range_stmt_p (basic_block bb)\n+{\n+  gimple_stmt_iterator gsi = gsi_last_nondebug_bb (bb);\n+  if (!gsi_end_p (gsi))\n+    {\n+      gimple *s = gsi_stmt (gsi);\n+      if (is_a<gcond *> (s) && gimple_range_handler (s))\n+\treturn gsi_stmt (gsi);\n+      gswitch *sw = dyn_cast<gswitch *> (s);\n+      if (sw && irange::supports_type_p (TREE_TYPE (gimple_switch_index (sw))))\n+\treturn gsi_stmt (gsi);\n+    }\n+  return NULL;\n+}\n+\n+\n+outgoing_range::outgoing_range ()\n+{\n+  m_edge_table = NULL;\n+}\n+\n+outgoing_range::~outgoing_range ()\n+{\n+  if (m_edge_table)\n+    delete m_edge_table;\n+}\n+\n+\n+// Get a range for a switch edge E from statement S and return it in R.\n+// Use a cached value if it exists, or calculate it if not.\n+\n+bool\n+outgoing_range::get_edge_range (irange &r, gimple *s, edge e)\n+{\n+  gcc_checking_assert (is_a<gswitch *> (s));\n+  gswitch *sw = as_a<gswitch *> (s);\n+\n+  // ADA currently has cases where the index is 64 bits and the case\n+  // arguments are 32 bit, causing a trap when we create a case_range.\n+  // Until this is resolved (https://gcc.gnu.org/bugzilla/show_bug.cgi?id=87798)\n+  // punt on switches where the labels dont match the argument.\n+  if (gimple_switch_num_labels (sw) > 1 && \n+      TYPE_PRECISION (TREE_TYPE (CASE_LOW (gimple_switch_label (sw, 1)))) !=\n+      TYPE_PRECISION (TREE_TYPE (gimple_switch_index (sw))))\n+    return false;\n+\n+   if (!m_edge_table)\n+     m_edge_table = new hash_map<edge, irange *> (n_edges_for_fn (cfun));\n+\n+   irange **val = m_edge_table->get (e);\n+   if (!val)\n+     {\n+       calc_switch_ranges (sw);\n+       val = m_edge_table->get (e);\n+       gcc_checking_assert (val);\n+     }\n+    r = **val;\n+  return true;\n+}\n+\n+\n+// Calculate all switch edges from SW and cache them in the hash table.\n+\n+void\n+outgoing_range::calc_switch_ranges (gswitch *sw)\n+{\n+  bool existed;\n+  unsigned x, lim;\n+  lim = gimple_switch_num_labels (sw);\n+  tree type = TREE_TYPE (gimple_switch_index (sw));\n+  \n+  edge default_edge = gimple_switch_default_edge (cfun, sw);\n+  irange *&default_slot = m_edge_table->get_or_insert (default_edge, &existed);\n+\n+  // This should be the first call into this switch.  For the default\n+  // range case, start with varying and intersect each other case from\n+  // it.\n+\n+  gcc_checking_assert (!existed);\n+\n+  // Allocate an int_range_max for default case.\n+  default_slot = m_range_allocator.allocate (255);\n+  default_slot->set_varying (type);\n+\n+  for (x = 1; x < lim; x++)\n+    {\n+      edge e = gimple_switch_edge (cfun, sw, x);\n+\n+      // If this edge is the same as the default edge, do nothing else.\n+      if (e == default_edge)\n+\tcontinue;\n+\n+      tree low = CASE_LOW (gimple_switch_label (sw, x));\n+      tree high = CASE_HIGH (gimple_switch_label (sw, x));\n+      if (!high)\n+\thigh = low;\n+\n+      // Remove the case range from the default case.\n+      int_range_max def_range (low, high);\n+      range_cast (def_range, type);\n+      def_range.invert ();\n+      default_slot->intersect (def_range);\n+\n+      // Create/union this case with anything on else on the edge.\n+      int_range_max case_range (low, high);\n+      range_cast (case_range, type);\n+      irange *&slot = m_edge_table->get_or_insert (e, &existed);\n+      if (existed)\n+\t{\n+\t  case_range.union_ (*slot);\n+\t  if (slot->fits_p (case_range))\n+\t    {\n+\t      *slot = case_range;\n+\t      continue;\n+\t    }\n+\t}\n+      // If there was an existing range and it doesn't fit, we lose the memory.\n+      // It'll get reclaimed when the obstack is freed.  This seems less\n+      // intrusive than allocating max ranges for each case.\n+      slot = m_range_allocator.allocate (case_range);\n+    }\n+}\n+\n+\n+// Calculate the range forced on on edge E by control flow, return it\n+// in R.  Return the statment which defines the range, otherwise\n+// return NULL\n+\n+gimple *\n+outgoing_range::edge_range_p (irange &r, edge e)\n+{\n+  // Determine if there is an outgoing edge.\n+  gimple *s = gimple_outgoing_range_stmt_p (e->src);\n+  if (!s)\n+    return NULL;\n+\n+  if (is_a<gcond *> (s))\n+    {\n+      if (e->flags & EDGE_TRUE_VALUE)\n+\tr = int_range<2> (boolean_true_node, boolean_true_node);\n+      else if (e->flags & EDGE_FALSE_VALUE)\n+\tr = int_range<2> (boolean_false_node, boolean_false_node);\n+      else\n+\tgcc_unreachable ();\n+      return s;\n+    }\n+\n+  gcc_checking_assert (is_a<gswitch *> (s));\n+  gswitch *sw = as_a<gswitch *> (s);\n+  tree type = TREE_TYPE (gimple_switch_index (sw));\n+\n+  if (!irange::supports_type_p (type))\n+    return NULL;\n+\n+  if (get_edge_range (r, sw, e))\n+    return s;\n+\n+  return NULL;\n+}"}, {"sha": "400c814ac7edc56491623466819fdba26e9beab1", "filename": "gcc/gimple-range-edge.h", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-edge.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-edge.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range-edge.h?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,55 @@\n+/* Gimple range edge header file.\n+   Copyright (C) 2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>\n+   and Aldy Hernandez <aldyh@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GIMPLE_RANGE_EDGE_H\n+#define GIMPLE_RANGE_EDGE_H\n+\n+// This class is used to query ranges on constant edges in GIMPLE.\n+//\n+// For a COND_EXPR, the TRUE edge will return [1,1] and the false edge a [0,0].\n+//\n+// For SWITCH_EXPR, it is awkward to calculate ranges.  When a request\n+// is made, the entire switch is evalauted and the results cached. \n+// Any future requests to that switch will use the cached value, providing\n+// dramatic decrease in computation time.\n+//\n+// The API is simple, just ask for the range on the edge.\n+// The return value is NULL for no range, or the branch statement which the\n+// edge gets the range from, along with the range.\n+\n+class outgoing_range\n+{\n+public:\n+  outgoing_range ();\n+  ~outgoing_range ();\n+  gimple *edge_range_p (irange &r, edge e);\n+private:\n+  void calc_switch_ranges (gswitch *sw);\n+  bool get_edge_range (irange &r, gimple *s, edge e);\n+\n+  hash_map<edge, irange *> *m_edge_table;\n+  irange_allocator m_range_allocator;\n+}; \n+\n+// If there is a range control statment at the end of block BB, return it.\n+gimple *gimple_outgoing_range_stmt_p (basic_block bb);\n+\n+#endif  // GIMPLE_RANGE_EDGE_H"}, {"sha": "eaf1a445c2532b85c321ebef9343c8f312e69601", "filename": "gcc/gimple-range-gori.cc", "status": "added", "additions": 1321, "deletions": 0, "changes": 1321, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-gori.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-gori.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range-gori.cc?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,1321 @@\n+/* Gimple range GORI functions.\n+   Copyright (C) 2017-2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>\n+   and Aldy Hernandez <aldyh@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"ssa.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"gimple-range.h\"\n+\n+\n+/* RANGE_DEF_CHAIN is used to determine what SSA names in a block can\n+   have range information calculated for them, and what the\n+   dependencies on each other are.\n+\n+   Information for a basic block is calculated once and stored.  It is\n+   only calculated the first time a query is made, so if no queries\n+   are made, there is little overhead.\n+\n+   The def_chain bitmap is indexed by SSA_NAME_VERSION.  Bits are set\n+   within this bitmap to indicate SSA names that are defined in the\n+   SAME block and used to calculate this SSA name.\n+\n+\n+    <bb 2> :\n+      _1 = x_4(D) + -2;\n+      _2 = _1 * 4;\n+      j_7 = foo ();\n+      q_5 = _2 + 3;\n+      if (q_5 <= 13)\n+\n+    _1  : x_4(D)\n+    _2  : 1  x_4(D)\n+    q_5  : _1  _2  x_4(D)\n+\n+    This dump indicates the bits set in the def_chain vector.\n+    as well as demonstrates the def_chain bits for the related ssa_names.\n+\n+    Checking the chain for _2 indicates that _1 and x_4 are used in\n+    its evaluation.\n+\n+    Def chains also only include statements which are valid gimple\n+    so a def chain will only span statements for which the range\n+    engine implements operations for.  */\n+\n+\n+class range_def_chain\n+{\n+public:\n+  range_def_chain ();\n+  ~range_def_chain ();\n+  bool has_def_chain (tree name);\n+  bitmap get_def_chain (tree name);\n+  bool in_chain_p (tree name, tree def);\n+private:\n+  vec<bitmap> m_def_chain;\t// SSA_NAME : def chain components.\n+  void build_def_chain (tree name, bitmap result, basic_block bb);\n+};\n+\n+\n+// Construct a range_def_chain.\n+\n+range_def_chain::range_def_chain ()\n+{\n+  m_def_chain.create (0);\n+  m_def_chain.safe_grow_cleared (num_ssa_names);\n+}\n+\n+// Destruct a range_def_chain.\n+\n+range_def_chain::~range_def_chain ()\n+{\n+  unsigned x;\n+  for (x = 0; x < m_def_chain.length (); ++x)\n+    if (m_def_chain[x])\n+      BITMAP_FREE (m_def_chain[x]);\n+  m_def_chain.release ();\n+}\n+\n+// Return true if NAME is in the def chain of DEF.  If BB is provided,\n+// only return true if the defining statement of DEF is in BB.\n+\n+bool\n+range_def_chain::in_chain_p (tree name, tree def)\n+{\n+  gcc_checking_assert (gimple_range_ssa_p (def));\n+  gcc_checking_assert (gimple_range_ssa_p (name));\n+\n+  // Get the defintion chain for DEF.\n+  bitmap chain = get_def_chain (def);\n+\n+  if (chain == NULL)\n+    return false;\n+  return bitmap_bit_p (chain, SSA_NAME_VERSION (name));\n+}\n+\n+// Build def_chains for NAME if it is in BB.  Copy the def chain into RESULT.\n+\n+void\n+range_def_chain::build_def_chain (tree name, bitmap result, basic_block bb)\n+{\n+  bitmap b;\n+  gimple *def_stmt = SSA_NAME_DEF_STMT (name);\n+  // Add this operand into the result.\n+  bitmap_set_bit (result, SSA_NAME_VERSION (name));\n+\n+  if (gimple_bb (def_stmt) == bb && !is_a<gphi *>(def_stmt))\n+    {\n+      // Get the def chain for the operand.\n+      b = get_def_chain (name);\n+      // If there was one, copy it into result.\n+      if (b)\n+\tbitmap_ior_into (result, b);\n+    }\n+}\n+\n+// Return TRUE if NAME has been processed for a def_chain.\n+\n+inline bool\n+range_def_chain::has_def_chain (tree name)\n+{\n+  // Ensure there is an entry in the internal vector.\n+  unsigned v = SSA_NAME_VERSION (name);\n+  if (v >= m_def_chain.length ())\n+    m_def_chain.safe_grow_cleared (num_ssa_names + 1);\n+  return (m_def_chain[v] != NULL);\n+}\n+\n+// Calculate the def chain for NAME and all of its dependent\n+// operands. Only using names in the same BB.  Return the bitmap of\n+// all names in the m_def_chain.  This only works for supported range\n+// statements.\n+\n+bitmap\n+range_def_chain::get_def_chain (tree name)\n+{\n+  tree ssa1, ssa2, ssa3;\n+  unsigned v = SSA_NAME_VERSION (name);\n+\n+  // If it has already been processed, just return the cached value.\n+  if (has_def_chain (name))\n+    return m_def_chain[v];\n+\n+  // No definition chain for default defs.\n+  if (SSA_NAME_IS_DEFAULT_DEF (name))\n+    return NULL;\n+\n+  gimple *stmt = SSA_NAME_DEF_STMT (name);\n+  if (gimple_range_handler (stmt))\n+    {\n+      ssa1 = gimple_range_ssa_p (gimple_range_operand1 (stmt));\n+      ssa2 = gimple_range_ssa_p (gimple_range_operand2 (stmt));\n+      ssa3 = NULL_TREE;\n+    }\n+  else if (is_a<gassign *> (stmt)\n+\t   && gimple_assign_rhs_code (stmt) == COND_EXPR)\n+    {\n+      gassign *st = as_a<gassign *> (stmt);\n+      ssa1 = gimple_range_ssa_p (gimple_assign_rhs1 (st));\n+      ssa2 = gimple_range_ssa_p (gimple_assign_rhs2 (st));\n+      ssa3 = gimple_range_ssa_p (gimple_assign_rhs3 (st));\n+    }\n+  else\n+    return NULL;\n+\n+  basic_block bb = gimple_bb (stmt);\n+\n+  m_def_chain[v] = BITMAP_ALLOC (NULL);\n+\n+  if (ssa1)\n+    build_def_chain (ssa1, m_def_chain[v], bb);\n+  if (ssa2)\n+    build_def_chain (ssa2, m_def_chain[v], bb);\n+  if (ssa3)\n+    build_def_chain (ssa3, m_def_chain[v], bb);\n+\n+  // If we run into pathological cases where the defintion chains are\n+  // huge (ie  huge basic block fully unrolled) we might be able to limit\n+  // this by deciding here that if some criteria is satisfied, we change the\n+  // def_chain back to be just the ssa-names.  That will help prevent chains\n+  // of a_2 = b_6 + a_8 from creating a pathological case.\n+  return m_def_chain[v];\n+}\n+\n+// -------------------------------------------------------------------\n+\n+/* GORI_MAP is used to accumulate what SSA names in a block can\n+   generate range information, and provides tools for the block ranger\n+   to enable it to efficiently calculate these ranges.\n+\n+   GORI stands for \"Generates Outgoing Range Information.\"\n+\n+   It utilizes the range_def_chain class to contruct def_chains.\n+   Information for a basic block is calculated once and stored.  It is\n+   only calculated the first time a query is made.  If no queries are\n+   made, there is little overhead.\n+\n+   one bitmap is maintained for each basic block:\n+   m_outgoing  : a set bit indicates a range can be generated for a name.\n+\n+   Generally speaking, the m_outgoing vector is the union of the\n+   entire def_chain of all SSA names used in the last statement of the\n+   block which generate ranges.  */\n+\n+class gori_map : public range_def_chain\n+{\n+public:\n+  gori_map ();\n+  ~gori_map ();\n+\n+  bool is_export_p (tree name, basic_block bb);\n+  bool def_chain_in_export_p (tree name, basic_block bb);\n+\n+  void dump (FILE *f);\n+  void dump (FILE *f, basic_block bb);\n+private:\n+  bitmap_obstack m_bitmaps;\n+  vec<bitmap> m_outgoing;\t// BB: Outgoing ranges calculatable on edges\n+  void maybe_add_gori (tree name, basic_block bb);\n+  void calculate_gori (basic_block bb);\n+  bitmap exports (basic_block bb);\n+};\n+\n+\n+// Initialize a gori-map structure.\n+\n+gori_map::gori_map ()\n+{\n+  m_outgoing.create (0);\n+  m_outgoing.safe_grow_cleared (last_basic_block_for_fn (cfun));\n+  bitmap_obstack_initialize (&m_bitmaps);\n+}\n+\n+// Free any memory the GORI map allocated.\n+\n+gori_map::~gori_map ()\n+{\n+  bitmap_obstack_release (&m_bitmaps);\n+  m_outgoing.release ();\n+}\n+\n+// Return the bitmap vector of all export from BB.  Calculate if necessary.\n+\n+bitmap\n+gori_map::exports (basic_block bb)\n+{\n+  if (!m_outgoing[bb->index])\n+    calculate_gori (bb);\n+  return m_outgoing[bb->index];\n+}\n+\n+// Return true if NAME is can have ranges generated for it from basic\n+// block BB.\n+\n+bool\n+gori_map::is_export_p (tree name, basic_block bb)\n+{\n+  return bitmap_bit_p (exports (bb), SSA_NAME_VERSION (name));\n+}\n+\n+// Return true if any element in the def chain of NAME is in the\n+// export list for BB.\n+\n+bool\n+gori_map::def_chain_in_export_p (tree name, basic_block bb)\n+{\n+  bitmap a = exports (bb);\n+  bitmap b = get_def_chain (name);\n+  if (a && b)\n+    return bitmap_intersect_p (a, b);\n+  return false;\n+}\n+\n+// If NAME is non-NULL and defined in block BB, calculate the def\n+// chain and add it to m_outgoing.\n+\n+void\n+gori_map::maybe_add_gori (tree name, basic_block bb)\n+{\n+  if (name)\n+    {\n+      gimple *s = SSA_NAME_DEF_STMT (name);\n+      bitmap r = get_def_chain (name);\n+      // Check if there is a def chain, and it is in this block.\n+      if (r && gimple_bb (s) == bb)\n+\tbitmap_copy (m_outgoing[bb->index], r);\n+      // Def chain doesn't include itself, and even if there isn't a\n+      // def chain, this name should be added to exports.\n+      bitmap_set_bit (m_outgoing[bb->index], SSA_NAME_VERSION (name));\n+    }\n+}\n+\n+// Calculate all the required information for BB.\n+\n+void\n+gori_map::calculate_gori (basic_block bb)\n+{\n+  tree name;\n+  if (bb->index >= (signed int)m_outgoing.length ())\n+    m_outgoing.safe_grow_cleared (last_basic_block_for_fn (cfun));\n+  gcc_checking_assert (m_outgoing[bb->index] == NULL);\n+  m_outgoing[bb->index] = BITMAP_ALLOC (&m_bitmaps);\n+\n+  // If this block's last statement may generate range informaiton, go\n+  // calculate it.\n+  gimple *stmt = gimple_outgoing_range_stmt_p (bb);\n+  if (!stmt)\n+    return;\n+  if (is_a<gcond *> (stmt))\n+    {\n+      gcond *gc = as_a<gcond *>(stmt);\n+      name = gimple_range_ssa_p (gimple_cond_lhs (gc));\n+      maybe_add_gori (name, gimple_bb (stmt));\n+\n+      name = gimple_range_ssa_p (gimple_cond_rhs (gc));\n+      maybe_add_gori (name, gimple_bb (stmt));\n+    }\n+  else\n+    {\n+      gswitch *gs = as_a<gswitch *>(stmt);\n+      name = gimple_range_ssa_p (gimple_switch_index (gs));\n+      maybe_add_gori (name, gimple_bb (stmt));\n+    }\n+}\n+\n+// Dump the table information for BB to file F.\n+\n+void\n+gori_map::dump (FILE *f, basic_block bb)\n+{\n+  bool header = false;\n+  const char *header_string = \"bb%-4d \";\n+  const char *header2 = \"       \";\n+  bool printed_something = false;;\n+  unsigned x, y;\n+  bitmap_iterator bi;\n+\n+  // BB was not processed.\n+  if (!m_outgoing[bb->index])\n+    return;\n+\n+  // Dump the def chain for each SSA_NAME defined in BB.\n+  for (x = 1; x < num_ssa_names; x++)\n+    {\n+      tree name = ssa_name (x);\n+      if (!name)\n+\tcontinue;\n+      gimple *stmt = SSA_NAME_DEF_STMT (name);\n+      bitmap chain = (has_def_chain (name) ? get_def_chain (name) : NULL);\n+      if (stmt && gimple_bb (stmt) == bb && chain && !bitmap_empty_p (chain))\n+        {\n+\t  fprintf (f, header_string, bb->index);\n+\t  header_string = header2;\n+\t  header = true;\n+\t  print_generic_expr (f, name, TDF_SLIM);\n+\t  fprintf (f, \" : \");\n+\t  EXECUTE_IF_SET_IN_BITMAP (chain, 0, y, bi)\n+\t    {\n+\t      print_generic_expr (f, ssa_name (y), TDF_SLIM);\n+\t      fprintf (f, \"  \");\n+\t    }\n+\t  fprintf (f, \"\\n\");\n+\t}\n+    }\n+\n+  printed_something |= header;\n+\n+  // Now dump the export vector.\n+  header = false;\n+  EXECUTE_IF_SET_IN_BITMAP (m_outgoing[bb->index], 0, y, bi)\n+    {\n+      if (!header)\n+        {\n+\t  fprintf (f, header_string, bb->index);\n+\t  fprintf (f, \"exports: \");\n+\t  header_string = header2;\n+\t  header = true;\n+\t}\n+      print_generic_expr (f, ssa_name (y), TDF_SLIM);\n+      fprintf (f, \"  \");\n+    }\n+  if (header)\n+    fputc ('\\n', f);\n+\n+  printed_something |= header;\n+  if (printed_something)\n+    fprintf (f, \"\\n\");\n+}\n+\n+// Dump the entire GORI map structure to file F.\n+\n+void\n+gori_map::dump (FILE *f)\n+{\n+  basic_block bb;\n+  FOR_EACH_BB_FN (bb, cfun)\n+    {\n+      dump (f, bb);\n+      if (m_outgoing[bb->index])\n+\tfprintf (f, \"\\n\");\n+    }\n+}\n+\n+DEBUG_FUNCTION void\n+debug (gori_map &g)\n+{\n+  g.dump (stderr);\n+}\n+\n+// -------------------------------------------------------------------\n+\n+// Construct a gori_compute object.\n+\n+gori_compute::gori_compute ()\n+{\n+  // Create a boolean_type true and false range.\n+  m_bool_zero = int_range<2> (boolean_false_node, boolean_false_node);\n+  m_bool_one = int_range<2> (boolean_true_node, boolean_true_node);\n+  m_gori_map = new gori_map;\n+}\n+\n+// Destruct a gori_compute_object.\n+\n+gori_compute::~gori_compute ()\n+{\n+  delete m_gori_map;\n+}\n+\n+// Provide a default of VARYING for all incoming SSA names.\n+\n+void\n+gori_compute::ssa_range_in_bb (irange &r, tree name, basic_block)\n+{\n+  r.set_varying (TREE_TYPE (name));\n+}\n+\n+void\n+gori_compute::expr_range_in_bb (irange &r, tree expr, basic_block bb)\n+{\n+  if (gimple_range_ssa_p (expr))\n+    ssa_range_in_bb (r, expr, bb);\n+  else\n+    get_tree_range (r, expr);\n+}\n+\n+// Calculate the range for NAME if the lhs of statement S has the\n+// range LHS.  Return the result in R.  Return false if no range can be\n+// calculated.\n+\n+bool\n+gori_compute::compute_name_range_op (irange &r, gimple *stmt,\n+\t\t\t\t     const irange &lhs, tree name)\n+{\n+  int_range_max op1_range, op2_range;\n+\n+  tree op1 = gimple_range_operand1 (stmt);\n+  tree op2 = gimple_range_operand2 (stmt);\n+\n+  // Operand 1 is the name being looked for, evaluate it.\n+  if (op1 == name)\n+    {\n+      expr_range_in_bb (op1_range, op1, gimple_bb (stmt));\n+      if (!op2)\n+\t{\n+\t  // The second parameter to a unary operation is the range\n+\t  // for the type of operand1, but if it can be reduced\n+\t  // further, the results will be better.  Start with what we\n+\t  // know of the range of OP1 instead of the full type.\n+\t  return gimple_range_calc_op1 (r, stmt, lhs, op1_range);\n+\t}\n+      // If we need the second operand, get a value and evaluate.\n+      expr_range_in_bb (op2_range, op2, gimple_bb (stmt));\n+      if (gimple_range_calc_op1 (r, stmt, lhs, op2_range))\n+\tr.intersect (op1_range);\n+      else\n+        r = op1_range;\n+      return true;\n+    }\n+\n+  if (op2 == name)\n+    {\n+      expr_range_in_bb (op1_range, op1, gimple_bb (stmt));\n+      expr_range_in_bb (r, op2, gimple_bb (stmt));\n+      if (gimple_range_calc_op2 (op2_range, stmt, lhs, op1_range))\n+        r.intersect (op2_range);\n+      return true;\n+    }\n+  return false;\n+}\n+\n+// Given the switch S, return an evaluation in R for NAME when the lhs\n+// evaluates to LHS.  Returning false means the name being looked for\n+// was not resolvable.\n+\n+bool\n+gori_compute::compute_operand_range_switch (irange &r, gswitch *s,\n+\t\t\t\t\t    const irange &lhs,\n+\t\t\t\t\t    tree name)\n+{\n+  tree op1 = gimple_switch_index (s);\n+\n+  // If name matches, the range is simply the range from the edge.\n+  // Empty ranges are viral as they are on a path which isn't\n+  // executable.\n+  if (op1 == name || lhs.undefined_p ())\n+    {\n+      r = lhs;\n+      return true;\n+    }\n+\n+  // If op1 is in the defintion chain, pass lhs back.\n+  if (gimple_range_ssa_p (op1) && m_gori_map->in_chain_p (name, op1))\n+    return compute_operand_range (r, SSA_NAME_DEF_STMT (op1), lhs, name);\n+\n+  return false;\n+}\n+\n+// Return TRUE if GS is a logical && or || expression.\n+\n+static inline bool\n+is_gimple_logical_p (const gimple *gs)\n+{\n+  // Look for boolean and/or condition.\n+  if (gimple_code (gs) == GIMPLE_ASSIGN)\n+    switch (gimple_expr_code (gs))\n+      {\n+\tcase TRUTH_AND_EXPR:\n+\tcase TRUTH_OR_EXPR:\n+\t  return true;\n+\n+\tcase BIT_AND_EXPR:\n+\tcase BIT_IOR_EXPR:\n+\t  // Bitwise operations on single bits are logical too.\n+\t  if (types_compatible_p (TREE_TYPE (gimple_assign_rhs1 (gs)),\n+\t\t\t\t  boolean_type_node))\n+\t    return true;\n+\t  break;\n+\n+\tdefault:\n+\t  break;\n+      }\n+  return false;\n+}\n+\n+// Return an evaluation for NAME as it would appear in STMT when the\n+// statement's lhs evaluates to LHS.  If successful, return TRUE and\n+// store the evaluation in R, otherwise return FALSE.\n+\n+bool\n+gori_compute::compute_operand_range (irange &r, gimple *stmt,\n+\t\t\t\t     const irange &lhs, tree name)\n+{\n+  // Empty ranges are viral as they are on an unexecutable path.\n+  if (lhs.undefined_p ())\n+    {\n+      r.set_undefined ();\n+      return true;\n+    }\n+  if (is_a<gswitch *> (stmt))\n+    return compute_operand_range_switch (r, as_a<gswitch *> (stmt), lhs, name);\n+  if (!gimple_range_handler (stmt))\n+    return false;\n+\n+  tree op1 = gimple_range_ssa_p (gimple_range_operand1 (stmt));\n+  tree op2 = gimple_range_ssa_p (gimple_range_operand2 (stmt));\n+\n+  // The base ranger handles NAME on this statement.\n+  if (op1 == name || op2 == name)\n+    return compute_name_range_op (r, stmt, lhs, name);\n+\n+  if (is_gimple_logical_p (stmt))\n+    return compute_logical_operands (r, stmt, lhs, name);\n+\n+  // NAME is not in this stmt, but one of the names in it ought to be\n+  // derived from it.\n+  bool op1_in_chain = op1 && m_gori_map->in_chain_p (name, op1);\n+  bool op2_in_chain = op2 && m_gori_map->in_chain_p (name, op2);\n+  if (op1_in_chain && op2_in_chain)\n+    return compute_operand1_and_operand2_range (r, stmt, lhs, name);\n+  if (op1_in_chain)\n+    return compute_operand1_range (r, stmt, lhs, name);\n+  if (op2_in_chain)\n+    return compute_operand2_range (r, stmt, lhs, name);\n+\n+  // If neither operand is derived, this statement tells us nothing.\n+  return false;\n+}\n+\n+// Return TRUE if range R is either a true or false compatible range.\n+\n+static bool\n+range_is_either_true_or_false (const irange &r)\n+{\n+  if (r.undefined_p ())\n+    return false;\n+\n+  // This is complicated by the fact that Ada has multi-bit booleans,\n+  // so true can be ~[0, 0] (i.e. [1,MAX]).\n+  tree type = r.type ();\n+  gcc_checking_assert (types_compatible_p (type, boolean_type_node));\n+  return (r.singleton_p () || !r.contains_p (build_zero_cst (type)));\n+}\n+\n+// A pair of ranges for true/false paths.\n+\n+struct tf_range\n+{\n+  tf_range () { }\n+  tf_range (const irange &t_range, const irange &f_range)\n+  {\n+    true_range = t_range;\n+    false_range = f_range;\n+  }\n+  int_range_max true_range, false_range;\n+};\n+\n+// Evaluate a binary logical expression by combining the true and\n+// false ranges for each of the operands based on the result value in\n+// the LHS.\n+\n+bool\n+gori_compute::logical_combine (irange &r, enum tree_code code,\n+\t\t\t       const irange &lhs,\n+\t\t\t       const tf_range &op1, const tf_range &op2)\n+{\n+  if (op1.true_range.varying_p ()\n+      && op1.false_range.varying_p ()\n+      && op2.true_range.varying_p ()\n+      && op2.false_range.varying_p ())\n+    return false;\n+\n+  // This is not a simple fold of a logical expression, rather it\n+  // determines ranges which flow through the logical expression.\n+  //\n+  // Assuming x_8 is an unsigned char, and relational statements:\n+  //\t      b_1 = x_8 < 20\n+  //\t      b_2 = x_8 > 5\n+  // consider the logical expression and branch:\n+  //          c_2 = b_1 && b_2\n+  //          if (c_2)\n+  //\n+  // To determine the range of x_8 on either edge of the branch, one\n+  // must first determine what the range of x_8 is when the boolean\n+  // values of b_1 and b_2 are both true and false.\n+  //    b_1 TRUE      x_8 = [0, 19]\n+  //    b_1 FALSE     x_8 = [20, 255]\n+  //    b_2 TRUE      x_8 = [6, 255]\n+  //    b_2 FALSE     x_8 = [0,5].\n+  //\n+  // These ranges are then combined based on the expected outcome of\n+  // the branch.  The range on the TRUE side of the branch must satisfy\n+  //     b_1 == true && b_2 == true\n+  //\n+  // In terms of x_8, that means both x_8 == [0, 19] and x_8 = [6, 255]\n+  // must be true.  The range of x_8 on the true side must be the\n+  // intersection of both ranges since both must be true.  Thus the\n+  // range of x_8 on the true side is [6, 19].\n+  //\n+  // To determine the ranges on the FALSE side, all 3 combinations of\n+  // failing ranges must be considered, and combined as any of them\n+  // can cause the false result.\n+  //\n+  // If the LHS can be TRUE or FALSE, then evaluate both a TRUE and\n+  // FALSE results and combine them.  If we fell back to VARYING any\n+  // range restrictions that have been discovered up to this point\n+  // would be lost.\n+  if (!range_is_either_true_or_false (lhs))\n+    {\n+      int_range_max r1;\n+      if (logical_combine (r1, code, m_bool_zero, op1, op2)\n+\t  && logical_combine (r, code, m_bool_one, op1, op2))\n+\t{\n+\t  r.union_ (r1);\n+\t  return true;\n+\t}\n+      return false;\n+    }\n+\n+  switch (code)\n+    {\n+      //  A logical AND combines ranges from 2 boolean conditions.\n+      //       c_2 = b_1 && b_2\n+      case TRUTH_AND_EXPR:\n+      case BIT_AND_EXPR:\n+        if (!lhs.zero_p ())\n+\t  {\n+\t    // The TRUE side is the intersection of the the 2 true ranges.\n+\t    r = op1.true_range;\n+\t    r.intersect (op2.true_range);\n+\t  }\n+\telse\n+\t  {\n+\t    // The FALSE side is the union of the other 3 cases.\n+\t    int_range_max ff (op1.false_range);\n+\t    ff.intersect (op2.false_range);\n+\t    int_range_max tf (op1.true_range);\n+\t    tf.intersect (op2.false_range);\n+\t    int_range_max ft (op1.false_range);\n+\t    ft.intersect (op2.true_range);\n+\t    r = ff;\n+\t    r.union_ (tf);\n+\t    r.union_ (ft);\n+\t  }\n+        break;\n+      //  A logical OR combines ranges from 2 boolean conditons.\n+      // \tc_2 = b_1 || b_2\n+      case TRUTH_OR_EXPR:\n+      case BIT_IOR_EXPR:\n+        if (lhs.zero_p ())\n+\t  {\n+\t    // An OR operation will only take the FALSE path if both\n+\t    // operands are false, so [20, 255] intersect [0, 5] is the\n+\t    // union: [0,5][20,255].\n+\t    r = op1.false_range;\n+\t    r.intersect (op2.false_range);\n+\t  }\n+\telse\n+\t  {\n+\t    // The TRUE side of an OR operation will be the union of\n+\t    // the other three combinations.\n+\t    int_range_max tt (op1.true_range);\n+\t    tt.intersect (op2.true_range);\n+\t    int_range_max tf (op1.true_range);\n+\t    tf.intersect (op2.false_range);\n+\t    int_range_max ft (op1.false_range);\n+\t    ft.intersect (op2.true_range);\n+\t    r = tt;\n+\t    r.union_ (tf);\n+\t    r.union_ (ft);\n+\t  }\n+\tbreak;\n+      default:\n+        gcc_unreachable ();\n+    }\n+\n+  return true;\n+}\n+\n+// Helper function for compute_logical_operands_in_chain that computes\n+// the range of logical statements that can be computed without\n+// chasing down operands.  These are things like [0 = x | y] where we\n+// know neither operand can be non-zero, or [1 = x & y] where we know\n+// neither operand can be zero.\n+\n+bool\n+gori_compute::optimize_logical_operands (tf_range &range,\n+\t\t\t\t\t gimple *stmt,\n+\t\t\t\t\t const irange &lhs,\n+\t\t\t\t\t tree name,\n+\t\t\t\t\t tree op)\n+{\n+  enum tree_code code = gimple_expr_code (stmt);\n+\n+  // Optimize [0 = x | y], since neither operand can ever be non-zero.\n+  if ((code == BIT_IOR_EXPR || code == TRUTH_OR_EXPR) && lhs.zero_p ())\n+    {\n+      if (!compute_operand_range (range.false_range, SSA_NAME_DEF_STMT (op),\n+\t\t\t\t  m_bool_zero, name))\n+\texpr_range_in_bb (range.false_range, name, gimple_bb (stmt));\n+      range.true_range = range.false_range;\n+      return true;\n+    }\n+  // Optimize [1 = x & y], since neither operand can ever be zero.\n+  if ((code == BIT_AND_EXPR || code == TRUTH_AND_EXPR) && lhs == m_bool_one)\n+    {\n+      if (!compute_operand_range (range.true_range, SSA_NAME_DEF_STMT (op),\n+\t\t\t\t  m_bool_one, name))\n+\texpr_range_in_bb (range.true_range, name, gimple_bb (stmt));\n+      range.false_range = range.true_range;\n+      return true;\n+    }\n+  return false;\n+}\n+\n+// Given a logical STMT, calculate true and false ranges for each\n+// potential path of NAME, assuming NAME came through the OP chain if\n+// OP_IN_CHAIN is true.\n+\n+void\n+gori_compute::compute_logical_operands_in_chain (tf_range &range,\n+\t\t\t\t\t\t gimple *stmt,\n+\t\t\t\t\t\t const irange &lhs,\n+\t\t\t\t\t\t tree name,\n+\t\t\t\t\t\t tree op, bool op_in_chain)\n+{\n+  if (!op_in_chain)\n+    {\n+      // If op is not in chain, use its known value.\n+      expr_range_in_bb (range.true_range, name, gimple_bb (stmt));\n+      range.false_range = range.true_range;\n+      return;\n+    }\n+  if (optimize_logical_operands (range, stmt, lhs, name, op))\n+    return;\n+\n+  // Calulate ranges for true and false on both sides, since the false\n+  // path is not always a simple inversion of the true side.\n+  if (!compute_operand_range (range.true_range, SSA_NAME_DEF_STMT (op),\n+\t\t\t      m_bool_one, name))\n+    expr_range_in_bb (range.true_range, name, gimple_bb (stmt));\n+  if (!compute_operand_range (range.false_range, SSA_NAME_DEF_STMT (op),\n+\t\t\t      m_bool_zero, name))\n+    expr_range_in_bb (range.false_range, name, gimple_bb (stmt));\n+}\n+\n+// Given a logical STMT, calculate true and false for each potential\n+// path using NAME, and resolve the outcome based on the logical\n+// operator.\n+\n+bool\n+gori_compute::compute_logical_operands (irange &r, gimple *stmt,\n+\t\t\t\t\tconst irange &lhs,\n+\t\t\t\t\ttree name)\n+{\n+  // Reaching this point means NAME is not in this stmt, but one of\n+  // the names in it ought to be derived from it.\n+  tree op1 = gimple_range_operand1 (stmt);\n+  tree op2 = gimple_range_operand2 (stmt);\n+  gcc_checking_assert (op1 != name && op2 != name);\n+\n+  bool op1_in_chain = (gimple_range_ssa_p (op1)\n+\t\t       && m_gori_map->in_chain_p (name, op1));\n+  bool op2_in_chain = (gimple_range_ssa_p (op2)\n+\t\t       && m_gori_map->in_chain_p (name, op2));\n+\n+  // If neither operand is derived, then this stmt tells us nothing.\n+  if (!op1_in_chain && !op2_in_chain)\n+    return false;\n+\n+  tf_range op1_range, op2_range;\n+  compute_logical_operands_in_chain (op1_range, stmt, lhs,\n+\t\t\t\t     name, op1, op1_in_chain);\n+  compute_logical_operands_in_chain (op2_range, stmt, lhs,\n+\t\t\t\t     name, op2, op2_in_chain);\n+  return logical_combine (r, gimple_expr_code (stmt), lhs,\n+\t\t\t  op1_range, op2_range);\n+}\n+\n+// Calculate a range for NAME from the operand 1 position of STMT\n+// assuming the result of the statement is LHS.  Return the range in\n+// R, or false if no range could be calculated.\n+\n+bool\n+gori_compute::compute_operand1_range (irange &r, gimple *stmt,\n+\t\t\t\t      const irange &lhs, tree name)\n+{\n+  int_range_max op1_range, op2_range;\n+  tree op1 = gimple_range_operand1 (stmt);\n+  tree op2 = gimple_range_operand2 (stmt);\n+\n+  expr_range_in_bb (op1_range, op1, gimple_bb (stmt));\n+\n+  // Now calcuated the operand and put that result in r.\n+  if (op2)\n+    {\n+      expr_range_in_bb (op2_range, op2, gimple_bb (stmt));\n+      if (!gimple_range_calc_op1 (r, stmt, lhs, op2_range))\n+\treturn false;\n+    }\n+  else\n+    {\n+      // We pass op1_range to the unary operation.  Nomally it's a\n+      // hidden range_for_type parameter, but sometimes having the\n+      // actual range can result in better information.\n+      if (!gimple_range_calc_op1 (r, stmt, lhs, op1_range))\n+\treturn false;\n+    }\n+\n+  // Intersect the calculated result with the known result.\n+  op1_range.intersect (r);\n+\n+  gimple *src_stmt = SSA_NAME_DEF_STMT (op1);\n+  // If def stmt is outside of this BB, then name must be an import.\n+  if (!src_stmt || (gimple_bb (src_stmt) != gimple_bb (stmt)))\n+    {\n+      // If this isn't the right import statement, then abort calculation.\n+      if (!src_stmt || gimple_get_lhs (src_stmt) != name)\n+        return false;\n+      return compute_name_range_op (r, src_stmt, op1_range, name);\n+    }\n+  // Then feed this range back as the LHS of the defining statement.\n+  return compute_operand_range (r, src_stmt, op1_range, name);\n+}\n+\n+\n+// Calculate a range for NAME from the operand 2 position of S\n+// assuming the result of the statement is LHS.  Return the range in\n+// R, or false if no range could be calculated.\n+\n+bool\n+gori_compute::compute_operand2_range (irange &r, gimple *stmt,\n+\t\t\t\t      const irange &lhs, tree name)\n+{\n+  int_range_max op1_range, op2_range;\n+  tree op1 = gimple_range_operand1 (stmt);\n+  tree op2 = gimple_range_operand2 (stmt);\n+\n+  expr_range_in_bb (op1_range, op1, gimple_bb (stmt));\n+  expr_range_in_bb (op2_range, op2, gimple_bb (stmt));\n+\n+  // Intersect with range for op2 based on lhs and op1.\n+  if (gimple_range_calc_op2 (r, stmt, lhs, op1_range))\n+    op2_range.intersect (r);\n+\n+  gimple *src_stmt = SSA_NAME_DEF_STMT (op2);\n+  // If def stmt is outside of this BB, then name must be an import.\n+  if (!src_stmt || (gimple_bb (src_stmt) != gimple_bb (stmt)))\n+    {\n+      // If  this isn't the right src statement, then abort calculation.\n+      if (!src_stmt || gimple_get_lhs (src_stmt) != name)\n+        return false;\n+      return compute_name_range_op (r, src_stmt, op2_range, name);\n+    }\n+  // Then feed this range back as the LHS of the defining statement.\n+  return compute_operand_range (r, src_stmt, op2_range, name);\n+}\n+\n+// Calculate a range for NAME from both operand positions of S\n+// assuming the result of the statement is LHS.  Return the range in\n+// R, or false if no range could be calculated.\n+\n+bool\n+gori_compute::compute_operand1_and_operand2_range\n+\t\t\t\t\t(irange &r,\n+\t\t\t\t\t gimple *stmt,\n+\t\t\t\t\t const irange &lhs,\n+\t\t\t\t\t tree name)\n+{\n+  int_range_max op_range;\n+\n+  // Calculate a good a range for op2.  Since op1 == op2, this will\n+  // have already included whatever the actual range of name is.\n+  if (!compute_operand2_range (op_range, stmt, lhs, name))\n+    return false;\n+\n+  // Now get the range thru op1.\n+  if (!compute_operand1_range (r, stmt, lhs, name))\n+    return false;\n+\n+  // Whichever range is the most permissive is the one we need to\n+  // use. (?)  OR is that true?  Maybe this should be intersection?\n+  r.union_ (op_range);\n+  return true;\n+}\n+\n+// Return TRUE if a range can be calcalated for NAME on edge E.\n+\n+bool\n+gori_compute::has_edge_range_p (edge e, tree name)\n+{\n+  return (m_gori_map->is_export_p (name, e->src)\n+\t  || m_gori_map->def_chain_in_export_p (name, e->src));\n+}\n+\n+// Dump what is known to GORI computes to listing file F.\n+\n+void\n+gori_compute::dump (FILE *f)\n+{\n+  m_gori_map->dump (f);\n+}\n+\n+// Calculate a range on edge E and return it in R.  Try to evaluate a\n+// range for NAME on this edge.  Return FALSE if this is either not a\n+// control edge or NAME is not defined by this edge.\n+\n+bool\n+gori_compute::outgoing_edge_range_p (irange &r, edge e, tree name)\n+{\n+  int_range_max lhs;\n+\n+  gcc_checking_assert (gimple_range_ssa_p (name));\n+  // Determine if there is an outgoing edge.\n+  gimple *stmt = outgoing.edge_range_p (lhs, e);\n+  if (!stmt)\n+    return false;\n+\n+  // If NAME can be calculated on the edge, use that.\n+  if (m_gori_map->is_export_p (name, e->src))\n+    return compute_operand_range (r, stmt, lhs, name);\n+\n+  // Otherwise see if NAME is derived from something that can be\n+  // calculated.  This performs no dynamic lookups whatsover, so it is\n+  // low cost.\n+  return false;\n+}\n+\n+// --------------------------------------------------------------------------\n+\n+// Cache for SSAs that appear on the RHS of a boolean assignment.\n+//\n+// Boolean assignments of logical expressions (i.e. LHS = j_5 > 999)\n+// have SSA operands whose range depend on the LHS of the assigment.\n+// That is, the range of j_5 when LHS is true is different than when\n+// LHS is false.\n+//\n+// This class caches the TRUE/FALSE ranges of such SSAs to avoid\n+// recomputing.\n+\n+class logical_stmt_cache\n+{\n+public:\n+  logical_stmt_cache ();\n+  ~logical_stmt_cache ();\n+  void set_range (tree lhs, tree name, const tf_range &);\n+  bool get_range (tf_range &r, tree lhs, tree name) const;\n+  bool cacheable_p (gimple *, const irange *lhs_range = NULL) const;\n+  void dump (FILE *, gimple *stmt) const;\n+  tree same_cached_name (tree lhs1, tree lh2) const;\n+private:\n+  tree cached_name (tree lhs) const;\n+  void slot_diagnostics (tree lhs, const tf_range &range) const;\n+  struct cache_entry\n+  {\n+    cache_entry (tree name, const irange &t_range, const irange &f_range);\n+    void dump (FILE *out) const;\n+    tree name;\n+    tf_range range;\n+  };\n+  vec<cache_entry *> m_ssa_cache;\n+};\n+\n+logical_stmt_cache::cache_entry::cache_entry (tree name,\n+\t\t\t\t\t      const irange &t_range,\n+\t\t\t\t\t      const irange &f_range)\n+  : name (name), range (t_range, f_range)\n+{\n+}\n+\n+logical_stmt_cache::logical_stmt_cache ()\n+{\n+  m_ssa_cache.create (num_ssa_names + num_ssa_names / 10);\n+  m_ssa_cache.safe_grow_cleared (num_ssa_names);\n+}\n+\n+logical_stmt_cache::~logical_stmt_cache ()\n+{\n+  for (unsigned i = 0; i < m_ssa_cache.length (); ++i)\n+    if (m_ssa_cache[i])\n+      delete m_ssa_cache[i];\n+  m_ssa_cache.release ();\n+}\n+\n+// Dump cache_entry to OUT.\n+\n+void\n+logical_stmt_cache::cache_entry::dump (FILE *out) const\n+{\n+  fprintf (out, \"name=\");\n+  print_generic_expr (out, name, TDF_SLIM);\n+  fprintf (out, \" \");\n+  range.true_range.dump (out);\n+  fprintf (out, \", \");\n+  range.false_range.dump (out);\n+  fprintf (out, \"\\n\");\n+}\n+\n+// Update range for cache entry of NAME as it appears in the defining\n+// statement of LHS.\n+\n+void\n+logical_stmt_cache::set_range (tree lhs, tree name, const tf_range &range)\n+{\n+  unsigned version = SSA_NAME_VERSION (lhs);\n+  if (version >= m_ssa_cache.length ())\n+    m_ssa_cache.safe_grow_cleared (num_ssa_names + num_ssa_names / 10);\n+\n+  cache_entry *slot = m_ssa_cache[version];\n+  slot_diagnostics (lhs, range);\n+  if (slot)\n+    {\n+      // The IL must have changed.  Update the carried SSA name for\n+      // consistency.  Testcase is libgomp.fortran/doacross1.f90.\n+      if (slot->name != name)\n+\tslot->name = name;\n+      return;\n+    }\n+  m_ssa_cache[version]\n+    = new cache_entry (name, range.true_range, range.false_range);\n+}\n+\n+// If there is a cached entry of NAME, set it in R and return TRUE,\n+// otherwise return FALSE.  LHS is the defining statement where NAME\n+// appeared.\n+\n+bool\n+logical_stmt_cache::get_range (tf_range &r, tree lhs, tree name) const\n+{\n+  gcc_checking_assert (cacheable_p (SSA_NAME_DEF_STMT (lhs)));\n+  if (cached_name (lhs) == name)\n+    {\n+      unsigned version = SSA_NAME_VERSION (lhs);\n+      if (m_ssa_cache[version])\n+\t{\n+\t  r = m_ssa_cache[version]->range;\n+\t  return true;\n+\t}\n+    }\n+  return false;\n+}\n+\n+// If the defining statement of LHS is in the cache, return the SSA\n+// operand being cached.  That is, return SSA for LHS = SSA .RELOP. OP2.\n+\n+tree\n+logical_stmt_cache::cached_name (tree lhs) const\n+{\n+  unsigned version = SSA_NAME_VERSION (lhs);\n+\n+  if (version >= m_ssa_cache.length ())\n+    return NULL;\n+\n+  if (m_ssa_cache[version])\n+    return m_ssa_cache[version]->name;\n+  return NULL;\n+}\n+\n+// Return TRUE if the cached name for LHS1 is the same as the\n+// cached name for LHS2.\n+\n+tree\n+logical_stmt_cache::same_cached_name (tree lhs1, tree lhs2) const\n+{\n+  tree name = cached_name (lhs1);\n+  if (name && name == cached_name (lhs2))\n+    return name;\n+  return NULL;\n+}\n+\n+// Return TRUE if STMT is a statement we are interested in caching.\n+// LHS_RANGE is any known range for the LHS of STMT.\n+\n+bool\n+logical_stmt_cache::cacheable_p (gimple *stmt, const irange *lhs_range) const\n+{\n+  if (gimple_code (stmt) == GIMPLE_ASSIGN\n+      && types_compatible_p (TREE_TYPE (gimple_assign_lhs (stmt)),\n+\t\t\t     boolean_type_node)\n+      && TREE_CODE (gimple_assign_rhs1 (stmt)) == SSA_NAME)\n+    {\n+      switch (gimple_expr_code (stmt))\n+\t{\n+\tcase LT_EXPR:\n+\tcase LE_EXPR:\n+\tcase GT_EXPR:\n+\tcase GE_EXPR:\n+\tcase EQ_EXPR:\n+\tcase NE_EXPR:\n+\tcase TRUTH_AND_EXPR:\n+\tcase BIT_AND_EXPR:\n+\tcase TRUTH_OR_EXPR:\n+\tcase BIT_IOR_EXPR:\n+\t  return !lhs_range || range_is_either_true_or_false (*lhs_range);\n+\tdefault:\n+\t  return false;\n+\t}\n+    }\n+  return false;\n+}\n+\n+// Output debugging diagnostics for the cache entry for LHS.  RANGE is\n+// the new range that is being cached.\n+\n+void\n+logical_stmt_cache::slot_diagnostics (tree lhs, const tf_range &range) const\n+{\n+  gimple *stmt = SSA_NAME_DEF_STMT (lhs);\n+  unsigned version = SSA_NAME_VERSION (lhs);\n+  cache_entry *slot = m_ssa_cache[version];\n+\n+  if (!slot)\n+    {\n+      if (DEBUG_RANGE_CACHE)\n+\t{\n+\t  fprintf (dump_file ? dump_file : stderr, \"registering range for: \");\n+\t  dump (dump_file ? dump_file : stderr, stmt);\n+\t}\n+      return;\n+    }\n+  if (DEBUG_RANGE_CACHE)\n+    fprintf (dump_file ? dump_file : stderr,\n+\t     \"reusing range for SSA #%d\\n\", version);\n+  if (CHECKING_P && (slot->range.true_range != range.true_range\n+\t\t     || slot->range.false_range != range.false_range))\n+    {\n+      fprintf (stderr, \"FATAL: range altered for cached: \");\n+      dump (stderr, stmt);\n+      fprintf (stderr, \"Attempt to change to:\\n\");\n+      fprintf (stderr, \"TRUE=\");\n+      range.true_range.dump (stderr);\n+      fprintf (stderr, \", FALSE=\");\n+      range.false_range.dump (stderr);\n+      fprintf (stderr, \"\\n\");\n+      gcc_unreachable ();\n+    }\n+}\n+\n+// Dump the cache information for STMT.\n+\n+void\n+logical_stmt_cache::dump (FILE *out, gimple *stmt) const\n+{\n+  tree lhs = gimple_assign_lhs (stmt);\n+  cache_entry *entry = m_ssa_cache[SSA_NAME_VERSION (lhs)];\n+\n+  print_gimple_stmt (out, stmt, 0, TDF_SLIM);\n+  if (entry)\n+    {\n+      fprintf (out, \"\\tname = \");\n+      print_generic_expr (out, entry->name);\n+      fprintf (out, \" lhs(%d)= \", SSA_NAME_VERSION (lhs));\n+      print_generic_expr (out, lhs);\n+      fprintf (out, \"\\n\\tTRUE=\");\n+      entry->range.true_range.dump (out);\n+      fprintf (out, \", FALSE=\");\n+      entry->range.false_range.dump (out);\n+      fprintf (out, \"\\n\");\n+    }\n+  else\n+    fprintf (out, \"[EMPTY]\\n\");\n+}\n+\n+gori_compute_cache::gori_compute_cache ()\n+{\n+  m_cache = new logical_stmt_cache;\n+}\n+\n+gori_compute_cache::~gori_compute_cache ()\n+{\n+  delete m_cache;\n+}\n+\n+// Caching version of compute_operand_range.  If NAME, as it appears\n+// in STMT, has already been cached return it from the cache,\n+// otherwise compute the operand range as normal and cache it.\n+\n+bool\n+gori_compute_cache::compute_operand_range (irange &r, gimple *stmt,\n+\t\t\t\t\t   const irange &lhs_range, tree name)\n+{\n+  bool cacheable = m_cache->cacheable_p (stmt, &lhs_range);\n+  if (cacheable)\n+    {\n+      tree lhs = gimple_assign_lhs (stmt);\n+      tf_range range;\n+      if (m_cache->get_range (range, lhs, name))\n+\t{\n+\t  if (lhs_range.zero_p ())\n+\t    r = range.false_range;\n+\t  else\n+\t    r = range.true_range;\n+\t  return true;\n+\t}\n+    }\n+  if (super::compute_operand_range (r, stmt, lhs_range, name))\n+    {\n+      if (cacheable)\n+\tcache_stmt (stmt);\n+      return true;\n+    }\n+  return false;\n+}\n+\n+// Cache STMT if possible.\n+\n+void\n+gori_compute_cache::cache_stmt (gimple *stmt)\n+{\n+  gcc_checking_assert (m_cache->cacheable_p (stmt));\n+  enum tree_code code = gimple_expr_code (stmt);\n+  tree lhs = gimple_assign_lhs (stmt);\n+  tree op1 = gimple_range_operand1 (stmt);\n+  tree op2 = gimple_range_operand2 (stmt);\n+  int_range_max r_true_side, r_false_side;\n+\n+  // LHS = s_5 > 999.\n+  if (TREE_CODE (op2) == INTEGER_CST)\n+    {\n+      range_operator *handler = range_op_handler (code, TREE_TYPE (lhs));\n+      int_range_max op2_range;\n+      expr_range_in_bb (op2_range, op2, gimple_bb (stmt));\n+      tree type = TREE_TYPE (op1);\n+      handler->op1_range (r_true_side, type, m_bool_one, op2_range);\n+      handler->op1_range (r_false_side, type, m_bool_zero, op2_range);\n+      m_cache->set_range (lhs, op1, tf_range (r_true_side, r_false_side));\n+    }\n+  // LHS = s_5 > b_8.\n+  else if (tree cached_name = m_cache->same_cached_name (op1, op2))\n+    {\n+      tf_range op1_range, op2_range;\n+      gcc_assert (m_cache->get_range (op1_range, op1, cached_name));\n+      gcc_assert (m_cache->get_range (op2_range, op2, cached_name));\n+      gcc_assert (logical_combine (r_true_side, code, m_bool_one,\n+\t\t\t\t   op1_range, op2_range));\n+      gcc_assert (logical_combine (r_false_side, code, m_bool_zero,\n+\t\t\t\t   op1_range, op2_range));\n+      m_cache->set_range (lhs, cached_name,\n+\t\t\t  tf_range (r_true_side, r_false_side));\n+    }\n+}"}, {"sha": "8ef452bf433a2a79b391b28d9631865a5163a69a", "filename": "gcc/gimple-range-gori.h", "status": "added", "additions": 138, "deletions": 0, "changes": 138, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-gori.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range-gori.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range-gori.h?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,138 @@\n+/* Header file for gimple range GORI structures.\n+   Copyright (C) 2017-2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>\n+   and Aldy Hernandez <aldyh@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_GIMPLE_RANGE_GORI_H\n+#define GCC_GIMPLE_RANGE_GORI_H\n+\n+\n+// This class is used to determine which SSA_NAMES can have ranges\n+// calculated for them on outgoing edges from basic blocks.  This represents\n+// ONLY the effect of the basic block edge->src on a range.\n+//\n+// There are 2 primary entry points:\n+//\n+// has_edge_range_p (edge e, tree name)  \n+//   returns true if the outgoing edge *may* be able to produce range\n+//   information for ssa_name NAME on edge E.\n+//   FALSE is returned if this edge does not affect the range of NAME.\n+//\n+// outgoing_edge_range_p (irange &range, edge e, tree name)\n+//   Actually does the calculation of RANGE for name on E\n+//   This represents application of whatever static range effect edge E\n+//   may have on NAME, not any cumulative effect.\n+\n+// There are also some internal APIs\n+//\n+// ssa_range_in_bb ()  is an internal routine which is used to start any\n+// calculation chain using SSA_NAMES which come from outside the block. ie\n+//      a_2 = b_4 - 8\n+//      if (a_2 < 30)\n+// on the true edge, a_2 is known to be [0, 29]\n+// b_4 can be calculated as [8, 37]\n+// during this calculation, b_4 is considered an \"import\" and ssa_range_in_bb\n+// is queried for a starting range which is used in the calculation.\n+// A default value of VARYING provides the raw static info for the edge.\n+//\n+// If there is any known range for b_4 coming into this block, it can refine\n+// the results.  This allows for cascading results to be propogated.\n+// if b_4 is [100, 200] on entry to the block, feeds into the calculation\n+// of a_2 = [92, 192], and finally on the true edge the range would be \n+// an empty range [] because it is not possible for the true edge to be taken.\n+//\n+// expr_range_in_bb is simply a wrapper which calls ssa_range_in_bb for \n+// SSA_NAMES and otherwise simply calculates the range of the expression.\n+//\n+// The remaining routines are internal use only.\n+\n+class gori_compute \n+{\n+public:\n+  gori_compute ();\n+  ~gori_compute ();\n+  bool outgoing_edge_range_p (irange &r, edge e, tree name);\n+  bool has_edge_range_p (edge e, tree name);\n+  void dump (FILE *f);\n+protected:\n+  virtual void ssa_range_in_bb (irange &r, tree name, basic_block bb);\n+  virtual bool compute_operand_range (irange &r, gimple *stmt,\n+\t\t\t\t      const irange &lhs, tree name);\n+\n+  void expr_range_in_bb (irange &r, tree expr, basic_block bb);\n+  bool compute_logical_operands (irange &r, gimple *stmt,\n+\t\t\t\t const irange &lhs,\n+\t\t\t\t tree name);\n+  void compute_logical_operands_in_chain (class tf_range &range,\n+\t\t\t\t\t  gimple *stmt, const irange &lhs,\n+\t\t\t\t\t  tree name, tree op,\n+\t\t\t\t\t  bool op_in_chain);\n+  bool optimize_logical_operands (tf_range &range, gimple *stmt,\n+\t\t\t\t  const irange &lhs, tree name, tree op);\n+  bool logical_combine (irange &r, enum tree_code code, const irange &lhs,\n+\t\t\tconst class tf_range &op1_range,\n+\t\t\tconst class tf_range &op2_range);\n+  int_range<2> m_bool_zero;           // Boolean false cached.\n+  int_range<2> m_bool_one;            // Boolean true cached.\n+\n+private:\n+  bool compute_operand_range_switch (irange &r, gswitch *stmt,\n+\t\t\t\t     const irange &lhs, tree name);\n+  bool compute_name_range_op (irange &r, gimple *stmt, const irange &lhs,\n+\t\t\t      tree name);\n+  bool compute_operand1_range (irange &r, gimple *stmt, const irange &lhs,\n+\t\t\t       tree name);\n+  bool compute_operand2_range (irange &r, gimple *stmt, const irange &lhs,\n+\t\t\t       tree name);\n+  bool compute_operand1_and_operand2_range (irange &r, gimple *stmt,\n+\t\t\t\t\t    const irange &lhs, tree name);\n+\n+  class gori_map *m_gori_map;\n+  outgoing_range outgoing;\t// Edge values for COND_EXPR & SWITCH_EXPR.\n+};\n+\n+\n+// This class adds a cache to gori_computes for logical expressions.\n+//       bool result = x && y\n+// requires calcuation of both X and Y for both true and false results.\n+// There are 4 combinations [0,0][0,0] [0,0][1,1] [1,1][0,0] and [1,1][1,1].\n+// Note that each pair of possible results for X and Y are used twice, and\n+// the calcuation of those results are the same each time.\n+//\n+// The cache simply checks if a stmt is cachable, and if so, saves both the\n+// true and false results for the next time the query is made.\n+//\n+// This is used to speed up long chains of logical operations which\n+// quickly become exponential.\n+\n+class gori_compute_cache : public gori_compute\n+{\n+public:\n+  gori_compute_cache ();\n+  ~gori_compute_cache ();\n+protected:\n+  virtual bool compute_operand_range (irange &r, gimple *stmt,\n+\t\t\t\t      const irange &lhs, tree name);\n+private:\n+  void cache_stmt (gimple *);\n+  typedef gori_compute super;\n+  class logical_stmt_cache *m_cache;\n+};\n+\n+#endif // GCC_GIMPLE_RANGE_GORI_H"}, {"sha": "75c03d6610b7f28f9b0913f7aa73bd25bd6f4759", "filename": "gcc/gimple-range.cc", "status": "added", "additions": 1284, "deletions": 0, "changes": 1284, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range.cc?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,1284 @@\n+/* Code for GIMPLE range related routines.\n+   Copyright (C) 2019-2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>\n+   and Aldy Hernandez <aldyh@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"insn-codes.h\"\n+#include \"rtl.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"ssa.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"gimple-iterator.h\"\n+#include \"optabs-tree.h\"\n+#include \"gimple-fold.h\"\n+#include \"tree-cfg.h\"\n+#include \"fold-const.h\"\n+#include \"tree-cfg.h\"\n+#include \"wide-int.h\"\n+#include \"fold-const.h\"\n+#include \"case-cfn-macros.h\"\n+#include \"omp-general.h\"\n+#include \"cfgloop.h\"\n+#include \"tree-ssa-loop.h\"\n+#include \"tree-scalar-evolution.h\"\n+#include \"dbgcnt.h\"\n+#include \"alloc-pool.h\"\n+#include \"vr-values.h\"\n+#include \"gimple-range.h\"\n+\n+\n+// Adjust the range for a pointer difference where the operands came\n+// from a memchr.\n+//\n+// This notices the following sequence:\n+//\n+//\tdef = __builtin_memchr (arg, 0, sz)\n+//\tn = def - arg\n+//\n+// The range for N can be narrowed to [0, PTRDIFF_MAX - 1].\n+\n+static void\n+adjust_pointer_diff_expr (irange &res, const gimple *diff_stmt)\n+{\n+  tree op0 = gimple_assign_rhs1 (diff_stmt);\n+  tree op1 = gimple_assign_rhs2 (diff_stmt);\n+  tree op0_ptype = TREE_TYPE (TREE_TYPE (op0));\n+  tree op1_ptype = TREE_TYPE (TREE_TYPE (op1));\n+  gimple *call;\n+\n+  if (TREE_CODE (op0) == SSA_NAME\n+      && TREE_CODE (op1) == SSA_NAME\n+      && (call = SSA_NAME_DEF_STMT (op0))\n+      && is_gimple_call (call)\n+      && gimple_call_builtin_p (call, BUILT_IN_MEMCHR)\n+      && TYPE_MODE (op0_ptype) == TYPE_MODE (char_type_node)\n+      && TYPE_PRECISION (op0_ptype) == TYPE_PRECISION (char_type_node)\n+      && TYPE_MODE (op1_ptype) == TYPE_MODE (char_type_node)\n+      && TYPE_PRECISION (op1_ptype) == TYPE_PRECISION (char_type_node)\n+      && gimple_call_builtin_p (call, BUILT_IN_MEMCHR)\n+      && vrp_operand_equal_p (op1, gimple_call_arg (call, 0))\n+      && integer_zerop (gimple_call_arg (call, 1)))\n+    {\n+      tree max = vrp_val_max (ptrdiff_type_node);\n+      wide_int wmax = wi::to_wide (max, TYPE_PRECISION (TREE_TYPE (max)));\n+      tree expr_type = gimple_expr_type (diff_stmt);\n+      tree range_min = build_zero_cst (expr_type);\n+      tree range_max = wide_int_to_tree (expr_type, wmax - 1);\n+      int_range<2> r (range_min, range_max);\n+      res.intersect (r);\n+    }\n+}\n+\n+// This function looks for situations when walking the use/def chains\n+// may provide additonal contextual range information not exposed on\n+// this statement.  Like knowing the IMAGPART return value from a\n+// builtin function is a boolean result.\n+\n+// We should rework how we're called, as we have an op_unknown entry\n+// for IMAGPART_EXPR and POINTER_DIFF_EXPR in range-ops just so this\n+// function gets called.\n+\n+static void\n+gimple_range_adjustment (irange &res, const gimple *stmt)\n+{\n+  switch (gimple_expr_code (stmt))\n+    {\n+    case POINTER_DIFF_EXPR:\n+      adjust_pointer_diff_expr (res, stmt);\n+      return;\n+\n+    case IMAGPART_EXPR:\n+      {\n+\ttree name = TREE_OPERAND (gimple_assign_rhs1 (stmt), 0);\n+\tif (TREE_CODE (name) == SSA_NAME)\n+\t  {\n+\t    gimple *def_stmt = SSA_NAME_DEF_STMT (name);\n+\t    if (def_stmt && is_gimple_call (def_stmt)\n+\t\t&& gimple_call_internal_p (def_stmt))\n+\t      {\n+\t\tswitch (gimple_call_internal_fn (def_stmt))\n+\t\t  {\n+\t\t  case IFN_ADD_OVERFLOW:\n+\t\t  case IFN_SUB_OVERFLOW:\n+\t\t  case IFN_MUL_OVERFLOW:\n+\t\t  case IFN_ATOMIC_COMPARE_EXCHANGE:\n+\t\t    {\n+\t\t      int_range<2> r;\n+\t\t      r.set_varying (boolean_type_node);\n+\t\t      tree type = TREE_TYPE (gimple_assign_lhs (stmt));\n+\t\t      range_cast (r, type);\n+\t\t      res.intersect (r);\n+\t\t    }\n+\t\t  default:\n+\t\t    break;\n+\t\t  }\n+\t      }\n+\t  }\n+\tbreak;\n+      }\n+\n+    default:\n+      break;\n+    }\n+}\n+\n+// Return a range in R for the tree EXPR.  Return true if a range is\n+// representable.\n+\n+bool\n+get_tree_range (irange &r, tree expr)\n+{\n+  tree type;\n+  if (TYPE_P (expr))\n+    type = expr;\n+  else\n+    type = TREE_TYPE (expr);\n+\n+  // Return false if the type isn't suported.\n+  if (!irange::supports_type_p (type))\n+    return false;\n+\n+  switch (TREE_CODE (expr))\n+    {\n+      case INTEGER_CST:\n+\tr.set (expr, expr);\n+\treturn true;\n+\n+      case SSA_NAME:\n+\tr = gimple_range_global (expr);\n+\treturn true;\n+\n+      case ADDR_EXPR:\n+        {\n+\t  // Handle &var which can show up in phi arguments.\n+\t  bool ov;\n+\t  if (tree_single_nonzero_warnv_p (expr, &ov))\n+\t    {\n+\t      r = range_nonzero (type);\n+\t      return true;\n+\t    }\n+\t  break;\n+\t}\n+\n+      default:\n+        break;\n+    }\n+  r.set_varying (type);\n+  return true;\n+}\n+\n+// Fold this unary statement using R1 as operand1's range, returning\n+// the result in RES.  Return false if the operation fails.\n+\n+bool\n+gimple_range_fold (irange &res, const gimple *stmt, const irange &r1)\n+{\n+  gcc_checking_assert (gimple_range_handler (stmt));\n+\n+  tree type = gimple_expr_type (stmt);\n+  // Unary SSA operations require the LHS type as the second range.\n+  int_range<2> r2 (type);\n+\n+  return gimple_range_fold (res, stmt, r1, r2);\n+}\n+\n+// Fold this binary statement using R1 and R2 as the operands ranges,\n+// returning the result in RES.  Return false if the operation fails.\n+\n+bool\n+gimple_range_fold (irange &res, const gimple *stmt,\n+\t\t   const irange &r1, const irange &r2)\n+{\n+  gcc_checking_assert (gimple_range_handler (stmt));\n+\n+  gimple_range_handler (stmt)->fold_range (res, gimple_expr_type (stmt),\n+\t\t\t\t\t   r1, r2);\n+\n+  // If there are any gimple lookups, do those now.\n+  gimple_range_adjustment (res, stmt);\n+  return true;\n+}\n+\n+// Return the base of the RHS of an assignment.\n+\n+tree\n+gimple_range_base_of_assignment (const gimple *stmt)\n+{\n+  gcc_checking_assert (gimple_code (stmt) == GIMPLE_ASSIGN);\n+  tree op1 = gimple_assign_rhs1 (stmt);\n+  if (gimple_assign_rhs_code (stmt) == ADDR_EXPR)\n+    return get_base_address (TREE_OPERAND (op1, 0));\n+  return op1;\n+}\n+\n+// Return the first operand of this statement if it is a valid operand\n+// supported by ranges, otherwise return NULL_TREE.  Special case is\n+// &(SSA_NAME expr), return the SSA_NAME instead of the ADDR expr.\n+\n+tree\n+gimple_range_operand1 (const gimple *stmt)\n+{\n+  gcc_checking_assert (gimple_range_handler (stmt));\n+\n+  switch (gimple_code (stmt))\n+    {\n+      case GIMPLE_COND:\n+\treturn gimple_cond_lhs (stmt);\n+      case GIMPLE_ASSIGN:\n+\t{\n+\t  tree base = gimple_range_base_of_assignment (stmt);\n+\t  if (base && TREE_CODE (base) == MEM_REF)\n+\t    {\n+\t      // If the base address is an SSA_NAME, we return it\n+\t      // here.  This allows processing of the range of that\n+\t      // name, while the rest of the expression is simply\n+\t      // ignored.  The code in range_ops will see the\n+\t      // ADDR_EXPR and do the right thing.\n+\t      tree ssa = TREE_OPERAND (base, 0);\n+\t      if (TREE_CODE (ssa) == SSA_NAME)\n+\t\treturn ssa;\n+\t    }\n+\t  return base;\n+\t}\n+      default:\n+\tbreak;\n+    }\n+  return NULL;\n+}\n+\n+// Return the second operand of statement STMT, otherwise return NULL_TREE.\n+\n+tree\n+gimple_range_operand2 (const gimple *stmt)\n+{\n+  gcc_checking_assert (gimple_range_handler (stmt));\n+\n+  switch (gimple_code (stmt))\n+    {\n+    case GIMPLE_COND:\n+      return gimple_cond_rhs (stmt);\n+    case GIMPLE_ASSIGN:\n+      if (gimple_num_ops (stmt) >= 3)\n+\treturn gimple_assign_rhs2 (stmt);\n+    default:\n+      break;\n+    }\n+  return NULL_TREE;\n+}\n+\n+// Calculate what we can determine of the range of this unary\n+// statement's operand if the lhs of the expression has the range\n+// LHS_RANGE.  Return false if nothing can be determined.\n+\n+bool\n+gimple_range_calc_op1 (irange &r, const gimple *stmt, const irange &lhs_range)\n+{\n+  gcc_checking_assert (gimple_num_ops (stmt) < 3);\n+\n+  // An empty range is viral.\n+  tree type = TREE_TYPE (gimple_range_operand1 (stmt));\n+  if (lhs_range.undefined_p ())\n+    {\n+      r.set_undefined ();\n+      return true;\n+    }\n+  // Unary operations require the type of the first operand in the\n+  // second range position.\n+  int_range<2> type_range (type);\n+  return gimple_range_handler (stmt)->op1_range (r, type, lhs_range,\n+\t\t\t\t\t\t type_range);\n+}\n+\n+// Calculate what we can determine of the range of this statement's\n+// first operand if the lhs of the expression has the range LHS_RANGE\n+// and the second operand has the range OP2_RANGE.  Return false if\n+// nothing can be determined.\n+\n+bool\n+gimple_range_calc_op1 (irange &r, const gimple *stmt,\n+\t\t       const irange &lhs_range, const irange &op2_range)\n+{\n+  // Unary operation are allowed to pass a range in for second operand\n+  // as there are often additional restrictions beyond the type which\n+  // can be imposed.  See operator_cast::op1_range().\n+  tree type = TREE_TYPE (gimple_range_operand1 (stmt));\n+  // An empty range is viral.\n+  if (op2_range.undefined_p () || lhs_range.undefined_p ())\n+    {\n+      r.set_undefined ();\n+      return true;\n+    }\n+  return gimple_range_handler (stmt)->op1_range (r, type, lhs_range,\n+\t\t\t\t\t\t op2_range);\n+}\n+\n+// Calculate what we can determine of the range of this statement's\n+// second operand if the lhs of the expression has the range LHS_RANGE\n+// and the first operand has the range OP1_RANGE.  Return false if\n+// nothing can be determined.\n+\n+bool\n+gimple_range_calc_op2 (irange &r, const gimple *stmt,\n+\t\t       const irange &lhs_range, const irange &op1_range)\n+{\n+  tree type = TREE_TYPE (gimple_range_operand2 (stmt));\n+  // An empty range is viral.\n+  if (op1_range.undefined_p () || lhs_range.undefined_p ())\n+    {\n+      r.set_undefined ();\n+      return true;\n+    }\n+  return gimple_range_handler (stmt)->op2_range (r, type, lhs_range,\n+\t\t\t\t\t\t op1_range);\n+}\n+\n+// Calculate a range for statement S and return it in R. If NAME is provided it\n+// represents the SSA_NAME on the LHS of the statement. It is only required\n+// if there is more than one lhs/output.  If a range cannot\n+// be calculated, return false.\n+\n+bool\n+gimple_ranger::calc_stmt (irange &r, gimple *s, tree name)\n+{\n+  bool res = false;\n+  // If name is specified, make sure it is an LHS of S.\n+  gcc_checking_assert (name ? SSA_NAME_DEF_STMT (name) == s : true);\n+\n+  if (gimple_range_handler (s))\n+    res = range_of_range_op (r, s);\n+  else if (is_a<gphi *>(s))\n+    res = range_of_phi (r, as_a<gphi *> (s));\n+  else if (is_a<gcall *>(s))\n+    res = range_of_call (r, as_a<gcall *> (s));\n+  else if (is_a<gassign *> (s) && gimple_assign_rhs_code (s) == COND_EXPR)\n+    res = range_of_cond_expr (r, as_a<gassign *> (s));\n+  else\n+    {\n+      // If no name is specified, try the expression kind.\n+      if (!name)\n+\t{\n+\t  tree t = gimple_expr_type (s);\n+\t  if (!irange::supports_type_p (t))\n+\t    return false;\n+\t  r.set_varying (t);\n+\t  return true;\n+\t}\n+      // We don't understand the stmt, so return the global range.\n+      r = gimple_range_global (name);\n+      return true;\n+    }\n+  if (res)\n+    {\n+      if (r.undefined_p ())\n+\treturn true;\n+      if (name && TREE_TYPE (name) != r.type ())\n+\trange_cast (r, TREE_TYPE (name));\n+      return true;\n+    }\n+  return false;\n+}\n+\n+// Calculate a range for range_op statement S and return it in R.  If any\n+// If a range cannot be calculated, return false.\n+\n+bool\n+gimple_ranger::range_of_range_op (irange &r, gimple *s)\n+{\n+  int_range_max range1, range2;\n+  tree type = gimple_expr_type (s);\n+  gcc_checking_assert (irange::supports_type_p (type));\n+\n+  tree op1 = gimple_range_operand1 (s);\n+  tree op2 = gimple_range_operand2 (s);\n+\n+  if (range_of_non_trivial_assignment (r, s))\n+    return true;\n+\n+  if (range_of_expr (range1, op1, s))\n+    {\n+      if (!op2)\n+\treturn gimple_range_fold (r, s, range1);\n+\n+      if (range_of_expr (range2, op2, s))\n+\treturn gimple_range_fold (r, s, range1, range2);\n+    }\n+  r.set_varying (type);\n+  return true;\n+}\n+\n+// Calculate the range of a non-trivial assignment.  That is, is one\n+// inolving arithmetic on an SSA name (for example, an ADDR_EXPR).\n+// Return the range in R.\n+//\n+// If a range cannot be calculated, return false.\n+\n+bool\n+gimple_ranger::range_of_non_trivial_assignment (irange &r, gimple *stmt)\n+{\n+  if (gimple_code (stmt) != GIMPLE_ASSIGN)\n+    return false;\n+\n+  tree base = gimple_range_base_of_assignment (stmt);\n+  if (base && TREE_CODE (base) == MEM_REF\n+      && TREE_CODE (TREE_OPERAND (base, 0)) == SSA_NAME)\n+    {\n+      int_range_max range1;\n+      tree ssa = TREE_OPERAND (base, 0);\n+      if (range_of_expr (range1, ssa, stmt))\n+\t{\n+\t  tree type = TREE_TYPE (ssa);\n+\t  range_operator *op = range_op_handler (POINTER_PLUS_EXPR, type);\n+\t  int_range<2> offset (TREE_OPERAND (base, 1), TREE_OPERAND (base, 1));\n+\t  op->fold_range (r, type, range1, offset);\n+\t  return true;\n+\t}\n+    }\n+  return false;\n+}\n+\n+// Calculate a range for phi statement S and return it in R.\n+// If a range cannot be calculated, return false.\n+\n+bool\n+gimple_ranger::range_of_phi (irange &r, gphi *phi)\n+{\n+  tree phi_def = gimple_phi_result (phi);\n+  tree type = TREE_TYPE (phi_def);\n+  int_range_max arg_range;\n+  unsigned x;\n+\n+  if (!irange::supports_type_p (type))\n+    return false;\n+\n+  // Start with an empty range, unioning in each argument's range.\n+  r.set_undefined ();\n+  for (x = 0; x < gimple_phi_num_args (phi); x++)\n+    {\n+      tree arg = gimple_phi_arg_def (phi, x);\n+      edge e = gimple_phi_arg_edge (phi, x);\n+\n+      range_on_edge (arg_range, e, arg);\n+      r.union_ (arg_range);\n+      // Once the value reaches varying, stop looking.\n+      if (r.varying_p ())\n+\tbreak;\n+    }\n+\n+  // If SCEV is available, query if this PHI has any knonwn values.\n+  if (scev_initialized_p () && !POINTER_TYPE_P (TREE_TYPE (phi_def)))\n+    {\n+      value_range loop_range;\n+      class loop *l = loop_containing_stmt (phi);\n+      if (l)\n+        {\n+\t  range_of_ssa_name_with_loop_info (loop_range, phi_def, l, phi);\n+\t  if (!loop_range.varying_p ())\n+\t    {\n+\t      if (dump_file && (dump_flags & TDF_DETAILS))\n+\t\t{\n+\t\t  fprintf (dump_file, \"   Loops range found for \");\n+\t\t  print_generic_expr (dump_file, phi_def, TDF_SLIM);\n+\t\t  fprintf (dump_file, \": \");\n+\t\t  loop_range.dump (dump_file);\n+\t\t  fprintf (dump_file, \" and calculated range :\");\n+\t\t  r.dump (dump_file);\n+\t\t  fprintf (dump_file, \"\\n\");\n+\t\t}\n+\t      r.intersect (loop_range);\n+\t    }\n+\t}\n+    }\n+\n+  return true;\n+}\n+\n+// Calculate a range for call statement S and return it in R.\n+// If a range cannot be calculated, return false.\n+\n+bool\n+gimple_ranger::range_of_call (irange &r, gcall *call)\n+{\n+  tree type = gimple_call_return_type (call);\n+  tree lhs = gimple_call_lhs (call);\n+  bool strict_overflow_p;\n+\n+  if (!irange::supports_type_p (type))\n+    return false;\n+\n+  if (range_of_builtin_call (r, call))\n+    ;\n+  else if (gimple_stmt_nonnegative_warnv_p (call, &strict_overflow_p))\n+    r.set (build_int_cst (type, 0), TYPE_MAX_VALUE (type));\n+  else if (gimple_call_nonnull_result_p (call)\n+\t   || gimple_call_nonnull_arg (call))\n+    r = range_nonzero (type);\n+  else\n+    r.set_varying (type);\n+\n+  // If there is an LHS, intersect that with what is known.\n+  if (lhs)\n+    {\n+      value_range def;\n+      def = gimple_range_global (lhs);\n+      r.intersect (def);\n+    }\n+  return true;\n+}\n+\n+\n+void\n+gimple_ranger::range_of_builtin_ubsan_call (irange &r, gcall *call,\n+\t\t\t\t\t    tree_code code)\n+{\n+  gcc_checking_assert (code == PLUS_EXPR || code == MINUS_EXPR\n+\t\t       || code == MULT_EXPR);\n+  tree type = gimple_call_return_type (call);\n+  range_operator *op = range_op_handler (code, type);\n+  gcc_checking_assert (op);\n+  int_range_max ir0, ir1;\n+  tree arg0 = gimple_call_arg (call, 0);\n+  tree arg1 = gimple_call_arg (call, 1);\n+  gcc_assert (range_of_expr (ir0, arg0, call));\n+  gcc_assert (range_of_expr (ir1, arg1, call));\n+\n+  bool saved_flag_wrapv = flag_wrapv;\n+  // Pretend the arithmetic is wrapping.  If there is any overflow,\n+  // we'll complain, but will actually do wrapping operation.\n+  flag_wrapv = 1;\n+  op->fold_range (r, type, ir0, ir1);\n+  flag_wrapv = saved_flag_wrapv;\n+\n+  // If for both arguments vrp_valueize returned non-NULL, this should\n+  // have been already folded and if not, it wasn't folded because of\n+  // overflow.  Avoid removing the UBSAN_CHECK_* calls in that case.\n+  if (r.singleton_p ())\n+    r.set_varying (type);\n+}\n+\n+\n+bool\n+gimple_ranger::range_of_builtin_call (irange &r, gcall *call)\n+{\n+  combined_fn func = gimple_call_combined_fn (call);\n+  if (func == CFN_LAST)\n+    return false;\n+\n+  tree type = gimple_call_return_type (call);\n+  tree arg;\n+  int mini, maxi, zerov, prec;\n+  scalar_int_mode mode;\n+\n+  switch (func)\n+    {\n+    case CFN_BUILT_IN_CONSTANT_P:\n+      if (cfun->after_inlining)\n+\t{\n+\t  r.set_zero (type);\n+\t  // r.equiv_clear ();\n+\t  return true;\n+\t}\n+      arg = gimple_call_arg (call, 0);\n+      if (range_of_expr (r, arg, call) && r.singleton_p ())\n+\t{\n+\t  r.set (build_one_cst (type), build_one_cst (type));\n+\t  return true;\n+\t}\n+      break;\n+\n+    CASE_CFN_FFS:\n+    CASE_CFN_POPCOUNT:\n+      // __builtin_ffs* and __builtin_popcount* return [0, prec].\n+      arg = gimple_call_arg (call, 0);\n+      prec = TYPE_PRECISION (TREE_TYPE (arg));\n+      mini = 0;\n+      maxi = prec;\n+      gcc_assert (range_of_expr (r, arg, call));\n+      // If arg is non-zero, then ffs or popcount are non-zero.\n+      if (!range_includes_zero_p (&r))\n+\tmini = 1;\n+      // If some high bits are known to be zero, decrease the maximum.\n+      if (!r.undefined_p ())\n+\t{\n+\t  wide_int max = r.upper_bound ();\n+\t  maxi = wi::floor_log2 (max) + 1;\n+\t}\n+      r.set (build_int_cst (type, mini), build_int_cst (type, maxi));\n+      return true;\n+\n+    CASE_CFN_PARITY:\n+      r.set (build_zero_cst (type), build_one_cst (type));\n+      return true;\n+\n+    CASE_CFN_CLZ:\n+      // __builtin_c[lt]z* return [0, prec-1], except when the\n+      // argument is 0, but that is undefined behavior.\n+      //\n+      // On many targets where the CLZ RTL or optab value is defined\n+      // for 0, the value is prec, so include that in the range by\n+      // default.\n+      arg = gimple_call_arg (call, 0);\n+      prec = TYPE_PRECISION (TREE_TYPE (arg));\n+      mini = 0;\n+      maxi = prec;\n+      mode = SCALAR_INT_TYPE_MODE (TREE_TYPE (arg));\n+      if (optab_handler (clz_optab, mode) != CODE_FOR_nothing\n+\t  && CLZ_DEFINED_VALUE_AT_ZERO (mode, zerov)\n+\t  // Only handle the single common value.\n+\t  && zerov != prec)\n+\t// Magic value to give up, unless we can prove arg is non-zero.\n+\tmini = -2;\n+\n+      gcc_assert (range_of_expr (r, arg, call));\n+      // From clz of minimum we can compute result maximum.\n+      if (r.constant_p ())\n+\t{\n+\t  maxi = prec - 1 - wi::floor_log2 (r.lower_bound ());\n+\t  if (maxi != prec)\n+\t    mini = 0;\n+\t}\n+      else if (!range_includes_zero_p (&r))\n+\t{\n+\t  maxi = prec - 1;\n+\t  mini = 0;\n+\t}\n+      if (mini == -2)\n+\tbreak;\n+      // From clz of maximum we can compute result minimum.\n+      if (r.constant_p ())\n+\t{\n+\t  mini = prec - 1 - wi::floor_log2 (r.upper_bound ());\n+\t  if (mini == prec)\n+\t    break;\n+\t}\n+      if (mini == -2)\n+\tbreak;\n+      r.set (build_int_cst (type, mini), build_int_cst (type, maxi));\n+      return true;\n+\n+    CASE_CFN_CTZ:\n+      // __builtin_ctz* return [0, prec-1], except for when the\n+      // argument is 0, but that is undefined behavior.\n+      //\n+      // If there is a ctz optab for this mode and\n+      // CTZ_DEFINED_VALUE_AT_ZERO, include that in the range,\n+      // otherwise just assume 0 won't be seen.\n+      arg = gimple_call_arg (call, 0);\n+      prec = TYPE_PRECISION (TREE_TYPE (arg));\n+      mini = 0;\n+      maxi = prec - 1;\n+      mode = SCALAR_INT_TYPE_MODE (TREE_TYPE (arg));\n+      if (optab_handler (ctz_optab, mode) != CODE_FOR_nothing\n+\t  && CTZ_DEFINED_VALUE_AT_ZERO (mode, zerov))\n+\t{\n+\t  // Handle only the two common values.\n+\t  if (zerov == -1)\n+\t    mini = -1;\n+\t  else if (zerov == prec)\n+\t    maxi = prec;\n+\t  else\n+\t    // Magic value to give up, unless we can prove arg is non-zero.\n+\t    mini = -2;\n+\t}\n+      gcc_assert (range_of_expr (r, arg, call));\n+      if (!r.undefined_p ())\n+\t{\n+\t  if (r.lower_bound () != 0)\n+\t    {\n+\t      mini = 0;\n+\t      maxi = prec - 1;\n+\t    }\n+\t  // If some high bits are known to be zero, we can decrease\n+\t  // the maximum.\n+\t  wide_int max = r.upper_bound ();\n+\t  if (max == 0)\n+\t    break;\n+\t  maxi = wi::floor_log2 (max);\n+\t}\n+      if (mini == -2)\n+\tbreak;\n+      r.set (build_int_cst (type, mini), build_int_cst (type, maxi));\n+      return true;\n+\n+    CASE_CFN_CLRSB:\n+      arg = gimple_call_arg (call, 0);\n+      prec = TYPE_PRECISION (TREE_TYPE (arg));\n+      r.set (build_int_cst (type, 0), build_int_cst (type, prec - 1));\n+      return true;\n+    case CFN_UBSAN_CHECK_ADD:\n+      range_of_builtin_ubsan_call (r, call, PLUS_EXPR);\n+      return true;\n+    case CFN_UBSAN_CHECK_SUB:\n+      range_of_builtin_ubsan_call (r, call, MINUS_EXPR);\n+      return true;\n+    case CFN_UBSAN_CHECK_MUL:\n+      range_of_builtin_ubsan_call (r, call, MULT_EXPR);\n+      return true;\n+\n+    case CFN_GOACC_DIM_SIZE:\n+    case CFN_GOACC_DIM_POS:\n+      // Optimizing these two internal functions helps the loop\n+      // optimizer eliminate outer comparisons.  Size is [1,N]\n+      // and pos is [0,N-1].\n+      {\n+\tbool is_pos = func == CFN_GOACC_DIM_POS;\n+\tint axis = oacc_get_ifn_dim_arg (call);\n+\tint size = oacc_get_fn_dim_size (current_function_decl, axis);\n+\tif (!size)\n+\t  // If it's dynamic, the backend might know a hardware limitation.\n+\t  size = targetm.goacc.dim_limit (axis);\n+\n+\tr.set (build_int_cst (type, is_pos ? 0 : 1),\n+\t       size\n+\t       ? build_int_cst (type, size - is_pos) : vrp_val_max (type));\n+\treturn true;\n+      }\n+\n+    case CFN_BUILT_IN_STRLEN:\n+      if (tree lhs = gimple_call_lhs (call))\n+\tif (ptrdiff_type_node\n+\t    && (TYPE_PRECISION (ptrdiff_type_node)\n+\t\t== TYPE_PRECISION (TREE_TYPE (lhs))))\n+\t  {\n+\t    tree type = TREE_TYPE (lhs);\n+\t    tree max = vrp_val_max (ptrdiff_type_node);\n+\t    wide_int wmax\n+\t      = wi::to_wide (max, TYPE_PRECISION (TREE_TYPE (max)));\n+\t    tree range_min = build_zero_cst (type);\n+\t    // To account for the terminating NULL, the maximum length\n+\t    // is one less than the maximum array size, which in turn\n+\t    // is one less than PTRDIFF_MAX (or SIZE_MAX where it's\n+\t    // smaller than the former type).\n+\t    // FIXME: Use max_object_size() - 1 here.\n+\t    tree range_max = wide_int_to_tree (type, wmax - 2);\n+\t    r.set (range_min, range_max);\n+\t    return true;\n+\t  }\n+      break;\n+    default:\n+      break;\n+    }\n+  return false;\n+}\n+\n+\n+\n+// Calculate a range for COND_EXPR statement S and return it in R.\n+// If a range cannot be calculated, return false.\n+\n+bool\n+gimple_ranger::range_of_cond_expr  (irange &r, gassign *s)\n+{\n+  int_range_max cond_range, range1, range2;\n+  tree cond = gimple_assign_rhs1 (s);\n+  tree op1 = gimple_assign_rhs2 (s);\n+  tree op2 = gimple_assign_rhs3 (s);\n+\n+  gcc_checking_assert (gimple_assign_rhs_code (s) == COND_EXPR);\n+  gcc_checking_assert (useless_type_conversion_p  (TREE_TYPE (op1),\n+\t\t\t\t\t\t   TREE_TYPE (op2)));\n+  if (!irange::supports_type_p (TREE_TYPE (op1)))\n+    return false;\n+\n+  gcc_assert (range_of_expr (cond_range, cond, s));\n+  gcc_assert (range_of_expr (range1, op1, s));\n+  gcc_assert (range_of_expr (range2, op2, s));\n+\n+  // If the condition is known, choose the appropriate expression.\n+  if (cond_range.singleton_p ())\n+    {\n+      // False, pick second operand.\n+      if (cond_range.zero_p ())\n+\tr = range2;\n+      else\n+\tr = range1;\n+    }\n+  else\n+    {\n+      r = range1;\n+      r.union_ (range2);\n+    }\n+  return true;\n+}\n+\n+bool\n+gimple_ranger::range_of_expr (irange &r, tree expr, gimple *stmt)\n+{\n+  if (!gimple_range_ssa_p (expr))\n+    return get_tree_range (r, expr);\n+\n+  // If there is no statement, just get the global value.\n+  if (!stmt)\n+    {\n+      if (!m_cache.m_globals.get_global_range (r, expr))\n+        r = gimple_range_global (expr);\n+      return true;\n+    }\n+\n+  basic_block bb = gimple_bb (stmt);\n+  gimple *def_stmt = SSA_NAME_DEF_STMT (expr);\n+\n+  // If name is defined in this block, try to get an range from S.\n+  if (def_stmt && gimple_bb (def_stmt) == bb)\n+    gcc_assert (range_of_stmt (r, def_stmt, expr));\n+  else\n+    // Otherwise OP comes from outside this block, use range on entry.\n+    range_on_entry (r, bb, expr);\n+\n+  // No range yet, see if there is a dereference in the block.\n+  // We don't care if it's between the def and a use within a block\n+  // because the entire block must be executed anyway.\n+  // FIXME:?? For non-call exceptions we could have a statement throw\n+  // which causes an early block exit.\n+  // in which case we may need to walk from S back to the def/top of block\n+  // to make sure the deref happens between S and there before claiming\n+  // there is a deref.   Punt for now.\n+  if (!cfun->can_throw_non_call_exceptions && r.varying_p () &&\n+      m_cache.m_non_null.non_null_deref_p (expr, bb))\n+    r = range_nonzero (TREE_TYPE (expr));\n+\n+  return true;\n+}\n+\n+// Return the range of NAME on entry to block BB in R.\n+\n+void\n+gimple_ranger::range_on_entry (irange &r, basic_block bb, tree name)\n+{\n+  int_range_max entry_range;\n+  gcc_checking_assert (gimple_range_ssa_p (name));\n+\n+  // Start with any known range\n+  gcc_assert (range_of_stmt (r, SSA_NAME_DEF_STMT (name), name));\n+\n+  // Now see if there is any on_entry value which may refine it.\n+  if (m_cache.block_range (entry_range, bb, name))\n+    r.intersect (entry_range);\n+}\n+\n+// Calculate the range for NAME at the end of block BB and return it in R.\n+// Return false if no range can be calculated.\n+\n+void\n+gimple_ranger::range_on_exit (irange &r, basic_block bb, tree name)\n+{\n+  // on-exit from the exit block?\n+  gcc_checking_assert (bb != EXIT_BLOCK_PTR_FOR_FN (cfun));\n+\n+  gimple *s = last_stmt (bb);\n+  // If there is no statement in the block and this isn't the entry\n+  // block, go get the range_on_entry for this block.  For the entry\n+  // block, a NULL stmt will return the global value for NAME.\n+  if (!s && bb != ENTRY_BLOCK_PTR_FOR_FN (cfun))\n+    range_on_entry (r, bb, name);\n+  else\n+    gcc_assert (range_of_expr (r, name, s));\n+  gcc_checking_assert (r.undefined_p ()\n+\t\t       || types_compatible_p (r.type(), TREE_TYPE (name)));\n+}\n+\n+// Calculate a range for NAME on edge E and return it in R.\n+\n+bool\n+gimple_ranger::range_on_edge (irange &r, edge e, tree name)\n+{\n+  int_range_max edge_range;\n+  gcc_checking_assert (irange::supports_type_p (TREE_TYPE (name)));\n+\n+  // PHI arguments can be constants, catch these here.\n+  if (!gimple_range_ssa_p (name))\n+    {\n+      gcc_assert (range_of_expr (r, name));\n+      return true;\n+    }\n+\n+  range_on_exit (r, e->src, name);\n+  gcc_checking_assert  (r.undefined_p ()\n+\t\t\t|| types_compatible_p (r.type(), TREE_TYPE (name)));\n+\n+  // Check to see if NAME is defined on edge e.\n+  if (m_cache.outgoing_edge_range_p (edge_range, e, name))\n+    r.intersect (edge_range);\n+\n+  return true;\n+}\n+\n+// Calculate a range for statement S and return it in R.  If NAME is\n+// provided it represents the SSA_NAME on the LHS of the statement.\n+// It is only required if there is more than one lhs/output.  Check\n+// the global cache for NAME first to see if the evaluation can be\n+// avoided.  If a range cannot be calculated, return false.\n+\n+bool\n+gimple_ranger::range_of_stmt (irange &r, gimple *s, tree name)\n+{\n+  // If no name, simply call the base routine.\n+  if (!name)\n+    name = gimple_get_lhs (s);\n+\n+  if (!name)\n+    return calc_stmt (r, s, NULL_TREE);\n+\n+  gcc_checking_assert (TREE_CODE (name) == SSA_NAME &&\n+\t\t       irange::supports_type_p (TREE_TYPE (name)));\n+\n+  // If this STMT has already been processed, return that value.\n+  if (m_cache.m_globals.get_global_range (r, name))\n+    return true;\n+  // Avoid infinite recursion by initializing global cache\n+  int_range_max tmp = gimple_range_global (name);\n+  m_cache.m_globals.set_global_range (name, tmp);\n+\n+  gcc_assert (calc_stmt (r, s, name));\n+\n+  if (is_a<gphi *> (s))\n+    r.intersect (tmp);\n+  m_cache.m_globals.set_global_range (name, r);\n+  return true;\n+}\n+\n+// This routine will export whatever global ranges are known to GCC\n+// SSA_RANGE_NAME_INFO fields.\n+\n+void\n+gimple_ranger::export_global_ranges ()\n+{\n+  unsigned x;\n+  int_range_max r;\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"Exported global range table\\n\");\n+      fprintf (dump_file, \"===========================\\n\");\n+    }\n+\n+  for ( x = 1; x < num_ssa_names; x++)\n+    {\n+      tree name = ssa_name (x);\n+      if (name && !SSA_NAME_IN_FREE_LIST (name)\n+\t  && gimple_range_ssa_p (name)\n+\t  && m_cache.m_globals.get_global_range (r, name)\n+\t  && !r.varying_p())\n+\t{\n+\t  // Make sure the new range is a subset of the old range.\n+\t  int_range_max old_range;\n+\t  old_range = gimple_range_global (name);\n+\t  old_range.intersect (r);\n+\t  /* Disable this while we fix tree-ssa/pr61743-2.c.  */\n+\t  //gcc_checking_assert (old_range == r);\n+\n+\t  // WTF? Can't write non-null pointer ranges?? stupid set_range_info!\n+\t  if (!POINTER_TYPE_P (TREE_TYPE (name)) && !r.undefined_p ())\n+\t    {\n+\t      value_range vr = r;\n+\t      set_range_info (name, vr);\n+\t      if (dump_file)\n+\t\t{\n+\t\t  print_generic_expr (dump_file, name , TDF_SLIM);\n+\t\t  fprintf (dump_file, \" --> \");\n+\t\t  vr.dump (dump_file);\n+\t\t  fprintf (dump_file, \"\\n\");\n+\t\t  fprintf (dump_file, \"         irange : \");\n+\t\t  r.dump (dump_file);\n+\t\t  fprintf (dump_file, \"\\n\");\n+\t\t}\n+\t    }\n+\t}\n+    }\n+}\n+\n+// Print the known table values to file F.\n+\n+void\n+gimple_ranger::dump (FILE *f)\n+{\n+  basic_block bb;\n+\n+  FOR_EACH_BB_FN (bb, cfun)\n+    {\n+      unsigned x;\n+      edge_iterator ei;\n+      edge e;\n+      int_range_max range;\n+      fprintf (f, \"\\n=========== BB %d ============\\n\", bb->index);\n+      m_cache.m_on_entry.dump (f, bb);\n+\n+      dump_bb (f, bb, 4, TDF_NONE);\n+\n+      // Now find any globals defined in this block.\n+      for (x = 1; x < num_ssa_names; x++)\n+\t{\n+\t  tree name = ssa_name (x);\n+\t  if (gimple_range_ssa_p (name) && SSA_NAME_DEF_STMT (name) &&\n+\t      gimple_bb (SSA_NAME_DEF_STMT (name)) == bb &&\n+\t      m_cache.m_globals.get_global_range (range, name))\n+\t    {\n+\t      if (!range.varying_p ())\n+\t       {\n+\t\t print_generic_expr (f, name, TDF_SLIM);\n+\t\t fprintf (f, \" : \");\n+\t\t range.dump (f);\n+\t\t fprintf (f, \"\\n\");\n+\t       }\n+\n+\t    }\n+\t}\n+\n+      // And now outgoing edges, if they define anything.\n+      FOR_EACH_EDGE (e, ei, bb->succs)\n+\t{\n+\t  for (x = 1; x < num_ssa_names; x++)\n+\t    {\n+\t      tree name = gimple_range_ssa_p (ssa_name (x));\n+\t      if (name && m_cache.outgoing_edge_range_p (range, e, name))\n+\t\t{\n+\t\t  gimple *s = SSA_NAME_DEF_STMT (name);\n+\t\t  // Only print the range if this is the def block, or\n+\t\t  // the on entry cache for either end of the edge is\n+\t\t  // set.\n+\t\t  if ((s && bb == gimple_bb (s)) ||\n+\t\t      m_cache.block_range (range, bb, name, false) ||\n+\t\t      m_cache.block_range (range, e->dest, name, false))\n+\t\t    {\n+\t\t      range_on_edge (range, e, name);\n+\t\t      if (!range.varying_p ())\n+\t\t\t{\n+\t\t\t  fprintf (f, \"%d->%d \", e->src->index,\n+\t\t\t\t   e->dest->index);\n+\t\t\t  char c = ' ';\n+\t\t\t  if (e->flags & EDGE_TRUE_VALUE)\n+\t\t\t    fprintf (f, \" (T)%c\", c);\n+\t\t\t  else if (e->flags & EDGE_FALSE_VALUE)\n+\t\t\t    fprintf (f, \" (F)%c\", c);\n+\t\t\t  else\n+\t\t\t    fprintf (f, \"     \");\n+\t\t\t  print_generic_expr (f, name, TDF_SLIM);\n+\t\t\t  fprintf(f, \" : \\t\");\n+\t\t\t  range.dump(f);\n+\t\t\t  fprintf (f, \"\\n\");\n+\t\t\t}\n+\t\t    }\n+\t\t}\n+\t    }\n+\t}\n+    }\n+\n+  m_cache.m_globals.dump (dump_file);\n+  fprintf (f, \"\\n\");\n+\n+  if (dump_flags & TDF_DETAILS)\n+    {\n+      fprintf (f, \"\\nDUMPING GORI MAP\\n\");\n+      m_cache.dump (f);\n+      fprintf (f, \"\\n\");\n+    }\n+}\n+\n+// If SCEV has any information about phi node NAME, return it as a range in R.\n+\n+void\n+gimple_ranger::range_of_ssa_name_with_loop_info (irange &r, tree name,\n+\t\t\t\t\t\t class loop *l, gphi *phi)\n+{\n+  gcc_checking_assert (TREE_CODE (name) == SSA_NAME);\n+  tree min, max, type = TREE_TYPE (name);\n+  if (bounds_of_var_in_loop (&min, &max, this, l, phi, name))\n+    {\n+      // ?? We could do better here.  Since MIN/MAX can only be an\n+      // SSA, SSA +- INTEGER_CST, or INTEGER_CST, we could easily call\n+      // the ranger and solve anything not an integer.\n+      if (TREE_CODE (min) != INTEGER_CST)\n+\tmin = vrp_val_min (type);\n+      if (TREE_CODE (max) != INTEGER_CST)\n+\tmax = vrp_val_max (type);\n+      r.set (min, max);\n+    }\n+  else\n+    r.set_varying (type);\n+}\n+\n+// --------------------------------------------------------------------------\n+// trace_ranger implementation.\n+\n+\n+trace_ranger::trace_ranger ()\n+{\n+  indent = 0;\n+  trace_count = 0;\n+}\n+\n+// If dumping, return true and print the prefix for the next output line.\n+\n+bool\n+trace_ranger::dumping (unsigned counter, bool trailing)\n+{\n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    {\n+      // Print counter index as well as INDENT spaces.\n+      if (!trailing)\n+\tfprintf (dump_file, \" %-7u \", counter);\n+      else\n+\tfprintf (dump_file, \"         \");\n+      unsigned x;\n+      for (x = 0; x< indent; x++)\n+\tfputc (' ', dump_file);\n+      return true;\n+    }\n+  return false;\n+}\n+\n+// After calling a routine, if dumping, print the CALLER, NAME, and RESULT,\n+// returning RESULT.\n+\n+bool\n+trace_ranger::trailer (unsigned counter, const char *caller, bool result,\n+\t\t       tree name, const irange &r)\n+{\n+  if (dumping (counter, true))\n+    {\n+      indent -= bump;\n+      fputs(result ? \"TRUE : \" : \"FALSE : \", dump_file);\n+      fprintf (dump_file, \"(%u) \", counter);\n+      fputs (caller, dump_file);\n+      fputs (\" (\",dump_file);\n+      if (name)\n+\tprint_generic_expr (dump_file, name, TDF_SLIM);\n+      fputs (\") \",dump_file);\n+      if (result)\n+\t{\n+\t  r.dump (dump_file);\n+\t  fputc('\\n', dump_file);\n+\t}\n+      else\n+\tfputc('\\n', dump_file);\n+      // Marks the end of a request.\n+      if (indent == 0)\n+\tfputc('\\n', dump_file);\n+    }\n+  return result;\n+}\n+\n+// Tracing version of range_on_edge.  Call it with printing wrappers.\n+\n+bool\n+trace_ranger::range_on_edge (irange &r, edge e, tree name)\n+{\n+  unsigned idx = ++trace_count;\n+  if (dumping (idx))\n+    {\n+      fprintf (dump_file, \"range_on_edge (\");\n+      print_generic_expr (dump_file, name, TDF_SLIM);\n+      fprintf (dump_file, \") on edge %d->%d\\n\", e->src->index, e->dest->index);\n+      indent += bump;\n+    }\n+\n+  bool res = gimple_ranger::range_on_edge (r, e, name);\n+  trailer (idx, \"range_on_edge\", true, name, r);\n+  return res;\n+}\n+\n+// Tracing version of range_on_entry.  Call it with printing wrappers.\n+\n+void\n+trace_ranger::range_on_entry (irange &r, basic_block bb, tree name)\n+{\n+  unsigned idx = ++trace_count;\n+  if (dumping (idx))\n+    {\n+      fprintf (dump_file, \"range_on_entry (\");\n+      print_generic_expr (dump_file, name, TDF_SLIM);\n+      fprintf (dump_file, \") to BB %d\\n\", bb->index);\n+      indent += bump;\n+    }\n+\n+  gimple_ranger::range_on_entry (r, bb, name);\n+\n+  trailer (idx, \"range_on_entry\", true, name, r);\n+}\n+\n+// Tracing version of range_on_exit.  Call it with printing wrappers.\n+\n+void\n+trace_ranger::range_on_exit (irange &r, basic_block bb, tree name)\n+{\n+  unsigned idx = ++trace_count;\n+  if (dumping (idx))\n+    {\n+      fprintf (dump_file, \"range_on_exit (\");\n+      print_generic_expr (dump_file, name, TDF_SLIM);\n+      fprintf (dump_file, \") from BB %d\\n\", bb->index);\n+      indent += bump;\n+    }\n+\n+  gimple_ranger::range_on_exit (r, bb, name);\n+\n+  trailer (idx, \"range_on_exit\", true, name, r);\n+}\n+\n+// Tracing version of range_of_stmt.  Call it with printing wrappers.\n+\n+bool\n+trace_ranger::range_of_stmt (irange &r, gimple *s, tree name)\n+{\n+  bool res;\n+  unsigned idx = ++trace_count;\n+  if (dumping (idx))\n+    {\n+      fprintf (dump_file, \"range_of_stmt (\");\n+      if (name)\n+\tprint_generic_expr (dump_file, name, TDF_SLIM);\n+      fputs (\") at stmt \", dump_file);\n+      print_gimple_stmt (dump_file, s, 0, TDF_SLIM);\n+      indent += bump;\n+    }\n+\n+  res = gimple_ranger::range_of_stmt (r, s, name);\n+\n+  return trailer (idx, \"range_of_stmt\", res, name, r);\n+}\n+\n+// Tracing version of range_of_expr.  Call it with printing wrappers.\n+\n+bool\n+trace_ranger::range_of_expr (irange &r, tree name, gimple *s)\n+{\n+  bool res;\n+  unsigned idx = ++trace_count;\n+  if (dumping (idx))\n+    {\n+      fprintf (dump_file, \"range_of_expr(\");\n+      print_generic_expr (dump_file, name, TDF_SLIM);\n+      fputs (\")\", dump_file);\n+      if (s)\n+\t{\n+\t  fputs (\" at stmt \", dump_file);\n+\t  print_gimple_stmt (dump_file, s, 0, TDF_SLIM);\n+\t}\n+      else\n+\tfputs (\"\\n\", dump_file);\n+      indent += bump;\n+    }\n+\n+  res = gimple_ranger::range_of_expr (r, name, s);\n+\n+  return trailer (idx, \"range_of_expr\", res, name, r);\n+}"}, {"sha": "4d35e72795fda8c2db67032fa1cd6a804b00a7fa", "filename": "gcc/gimple-range.h", "status": "added", "additions": 170, "deletions": 0, "changes": 170, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/90e88fd376bb9ad6223a1f5ccd803d1bd9539b05/gcc%2Fgimple-range.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-range.h?ref=90e88fd376bb9ad6223a1f5ccd803d1bd9539b05", "patch": "@@ -0,0 +1,170 @@\n+/* Header file for the GIMPLE range interface.\n+   Copyright (C) 2019-2020 Free Software Foundation, Inc.\n+   Contributed by Andrew MacLeod <amacleod@redhat.com>\n+   and Aldy Hernandez <aldyh@redhat.com>.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_GIMPLE_RANGE_STMT_H\n+#define GCC_GIMPLE_RANGE_STMT_H\n+\n+\n+#include \"range.h\"\n+#include \"range-op.h\"\n+#include \"gimple-range-edge.h\"\n+#include \"gimple-range-gori.h\"\n+#include \"gimple-range-cache.h\"\n+#include \"value-query.h\"\n+\n+// This is the basic range generator interface.\n+//\n+// This base class provides all the API entry points, but only provides\n+// functionality at the statement level.  Ie, it can calculate ranges on\n+// statements, but does no additonal lookup.\n+//\n+// All the range_of_* methods will return a range if the types is\n+// supported by the range engine.  It may be the full range for the\n+// type, AKA varying_p or it may be a refined range.  If the range\n+// type is not supported, then false is returned.  Non-statement\n+// related methods return whatever the current global value is.\n+\n+\n+class gimple_ranger : public range_query\n+{\n+public:\n+  gimple_ranger () : m_cache (*this) { }\n+  virtual bool range_of_stmt (irange &r, gimple *, tree name = NULL) OVERRIDE;\n+  virtual bool range_of_expr (irange &r, tree name, gimple * = NULL) OVERRIDE;\n+  virtual bool range_on_edge (irange &r, edge e, tree name) OVERRIDE;\n+  virtual void range_on_entry (irange &r, basic_block bb, tree name);\n+  virtual void range_on_exit (irange &r, basic_block bb, tree name);\n+  void export_global_ranges ();\n+  void dump (FILE *f);\n+protected:\n+  bool calc_stmt (irange &r, gimple *s, tree name = NULL_TREE);\n+  bool range_of_range_op (irange &r, gimple *s);\n+  bool range_of_call (irange &r, gcall *call);\n+  bool range_of_cond_expr (irange &r, gassign* cond);\n+  ranger_cache m_cache;\n+private:\n+  bool range_of_phi (irange &r, gphi *phi);\n+  bool range_of_non_trivial_assignment (irange &r, gimple *s);\n+  bool range_of_builtin_call (irange &r, gcall *call);\n+  void range_of_builtin_ubsan_call (irange &r, gcall *call, tree_code code);\n+  bool range_with_loop_info (irange &r, tree name);\n+  void range_of_ssa_name_with_loop_info (irange &, tree, class loop *,\n+\t\t\t\t\t gphi *);\n+};\n+\n+// Calculate a basic range for a tree expression.\n+extern bool get_tree_range (irange &r, tree expr);\n+\n+// These routines provide a GIMPLE interface to the range-ops code.\n+extern tree gimple_range_operand1 (const gimple *s);\n+extern tree gimple_range_operand2 (const gimple *s);\n+extern tree gimple_range_base_of_assignment (const gimple *s);\n+extern bool gimple_range_fold (irange &res, const gimple *s,\n+\t\t\t       const irange &r1);\n+extern bool gimple_range_fold (irange &res, const gimple *s,\n+\t\t\t       const irange &r1,\n+\t\t\t       const irange &r2);\n+extern bool gimple_range_calc_op1 (irange &r, const gimple *s,\n+\t\t\t\t   const irange &lhs_range);\n+extern bool gimple_range_calc_op1 (irange &r, const gimple *s,\n+\t\t\t\t   const irange &lhs_range,\n+\t\t\t\t   const irange &op2_range);\n+extern bool gimple_range_calc_op2 (irange &r, const gimple *s,\n+\t\t\t\t   const irange &lhs_range,\n+\t\t\t\t   const irange &op1_range);\n+\n+\n+// Return the range_operator pointer for this statement.  This routine\n+// can also be used to gate whether a routine is range-ops enabled.\n+\n+static inline range_operator *\n+gimple_range_handler (const gimple *s)\n+{\n+  if ((gimple_code (s) == GIMPLE_ASSIGN) || (gimple_code (s) == GIMPLE_COND))\n+    return range_op_handler (gimple_expr_code (s), gimple_expr_type (s));\n+  return NULL;\n+}\n+\n+// Return EXP if it is an SSA_NAME with a type supported by gimple ranges.\n+\n+static inline tree\n+gimple_range_ssa_p (tree exp)\n+{\n+  if (exp && TREE_CODE (exp) == SSA_NAME &&\n+      !SSA_NAME_IS_VIRTUAL_OPERAND (exp) &&\n+      irange::supports_type_p (TREE_TYPE (exp)))\n+    return exp;\n+  return NULL_TREE;\n+}\n+\n+// Return the legacy GCC global range for NAME if it has one, otherwise\n+// return VARYING.\n+\n+static inline value_range\n+gimple_range_global (tree name)\n+{\n+  gcc_checking_assert (gimple_range_ssa_p (name));\n+  tree type = TREE_TYPE (name);\n+#if 0\n+  // Reenable picking up global ranges when we are OK failing tests that look\n+  // for builtin_unreachable in the code, like\n+  // RUNTESTFLAGS=dg.exp=pr61034.C check-g++\n+  // pre-optimizations (inlining) set a global range which causes the ranger\n+  // to remove the condition which leads to builtin_unreachable.\n+  if (!POINTER_TYPE_P (type) && SSA_NAME_RANGE_INFO (name))\n+    {\n+      // Return a range from an SSA_NAME's available range.\n+      wide_int min, max;\n+      enum value_range_kind kind = get_range_info (name, &min, &max);\n+      return value_range (type, min, max, kind);\n+    }\n+#endif\n+ // Otherwise return range for the type.\n+ return value_range (type);\n+}\n+\n+\n+// This class overloads the ranger routines to provide tracing facilties\n+// Entry and exit values to each of the APIs is placed in the dumpfile.\n+\n+class trace_ranger : public gimple_ranger\n+{\n+public:\n+  trace_ranger ();\n+  virtual bool range_of_stmt (irange &r, gimple *s, tree name = NULL_TREE);\n+  virtual bool range_of_expr (irange &r, tree name, gimple *s = NULL);\n+  virtual bool range_on_edge (irange &r, edge e, tree name);\n+  virtual void range_on_entry (irange &r, basic_block bb, tree name);\n+  virtual void range_on_exit (irange &r, basic_block bb, tree name);\n+private:\n+  static const unsigned bump = 2;\n+  unsigned indent;\n+  unsigned trace_count;\t\t// Current trace index count.\n+\n+  bool dumping (unsigned counter, bool trailing = false);\n+  bool trailer (unsigned counter, const char *caller, bool result, tree name,\n+\t\tconst irange &r);\n+};\n+\n+// Flag to enable debugging the various internal Caches.\n+#define DEBUG_RANGE_CACHE (dump_file && (flag_evrp_mode & EVRP_MODE_DEBUG))\n+\n+#endif // GCC_GIMPLE_RANGE_STMT_H"}]}