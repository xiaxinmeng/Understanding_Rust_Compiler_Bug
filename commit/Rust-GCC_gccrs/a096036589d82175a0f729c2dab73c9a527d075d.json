{"sha": "a096036589d82175a0f729c2dab73c9a527d075d", "node_id": "C_kwDOANBUbNoAKGEwOTYwMzY1ODlkODIxNzVhMGY3MjljMmRhYjczYzlhNTI3ZDA3NWQ", "commit": {"author": {"name": "Wilco Dijkstra", "email": "wdijkstr@arm.com", "date": "2022-10-24T14:14:14Z"}, "committer": {"name": "Wilco Dijkstra", "email": "wdijkstr@arm.com", "date": "2022-10-24T14:36:28Z"}, "message": "[AArch64] Improve immediate expansion [PR106583]\n\nImprove immediate expansion of immediates which can be created from a\nbitmask immediate and 2 MOVKs.  Simplify, refactor and improve efficiency\nof bitmask checks.  Move various immediate handling functions together\nto avoid forward declarations.\n\nThis reduces the number of 4-instruction immediates in SPECINT/FP by 10-15%.\n\ngcc/\n\n\tPR target/106583\n\t* config/aarch64/aarch64.cc (aarch64_internal_mov_immediate)\n\tAdd support for a bitmask immediate with 2 MOVKs.\n\t(aarch64_check_bitmask): New function after refactorization.\n\t(aarch64_bitmask_imm): Simplify replication of small modes.\n\tSplit function into 64-bit only version for efficiency.\n\t(aarch64_move_imm): Move near other immediate functions.\n\t(aarch64_uimm12_shift): Likewise.\n\t(aarch64_clamp_to_uimm12_shift): Likewise.\n\t(aarch64_movk_shift): Likewise.\n\t(aarch64_replicate_bitmask_imm): Likewise.\n\t(aarch64_and_split_imm1): Likewise.\n\t(aarch64_and_split_imm2): Likewise.\n\t(aarch64_and_bitmask_imm): Likewise.\n\t(aarch64_movw_imm): Likewise.\n\ngcc/testsuite/\n\tPR target/106583\n\t* gcc.target/aarch64/pr106583.c: Add new test.", "tree": {"sha": "416db1dabf6e889a31f3c784d9239e47f312fdcc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/416db1dabf6e889a31f3c784d9239e47f312fdcc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a096036589d82175a0f729c2dab73c9a527d075d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a096036589d82175a0f729c2dab73c9a527d075d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a096036589d82175a0f729c2dab73c9a527d075d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a096036589d82175a0f729c2dab73c9a527d075d/comments", "author": null, "committer": null, "parents": [{"sha": "da8c362c4c18cff2f2dfd5c4706bdda7576899a4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/da8c362c4c18cff2f2dfd5c4706bdda7576899a4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/da8c362c4c18cff2f2dfd5c4706bdda7576899a4"}], "stats": {"total": 526, "additions": 301, "deletions": 225}, "files": [{"sha": "5d1ab5aa42b2cda0a655d2bc69c4df19da457ab3", "filename": "gcc/config/aarch64/aarch64.cc", "status": "modified", "additions": 260, "deletions": 225, "changes": 485, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a096036589d82175a0f729c2dab73c9a527d075d/gcc%2Fconfig%2Faarch64%2Faarch64.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a096036589d82175a0f729c2dab73c9a527d075d/gcc%2Fconfig%2Faarch64%2Faarch64.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.cc?ref=a096036589d82175a0f729c2dab73c9a527d075d", "patch": "@@ -305,7 +305,6 @@ static bool aarch64_builtin_support_vector_misalignment (machine_mode mode,\n static machine_mode aarch64_simd_container_mode (scalar_mode, poly_int64);\n static bool aarch64_print_address_internal (FILE*, machine_mode, rtx,\n \t\t\t\t\t    aarch64_addr_query_type);\n-static HOST_WIDE_INT aarch64_clamp_to_uimm12_shift (HOST_WIDE_INT val);\n \n /* The processor for which instructions should be scheduled.  */\n enum aarch64_processor aarch64_tune = cortexa53;\n@@ -5502,6 +5501,143 @@ aarch64_output_sve_vector_inc_dec (const char *operands, rtx x)\n \t\t\t\t\t     factor, nelts_per_vq);\n }\n \n+/* Multipliers for repeating bitmasks of width 32, 16, 8, 4, and 2.  */\n+\n+static const unsigned HOST_WIDE_INT bitmask_imm_mul[] =\n+  {\n+    0x0000000100000001ull,\n+    0x0001000100010001ull,\n+    0x0101010101010101ull,\n+    0x1111111111111111ull,\n+    0x5555555555555555ull,\n+  };\n+\n+\n+\n+/* Return true if 64-bit VAL is a valid bitmask immediate.  */\n+static bool\n+aarch64_bitmask_imm (unsigned HOST_WIDE_INT val)\n+{\n+  unsigned HOST_WIDE_INT tmp, mask, first_one, next_one;\n+  int bits;\n+\n+  /* Check for a single sequence of one bits and return quickly if so.\n+     The special cases of all ones and all zeroes returns false.  */\n+  tmp = val + (val & -val);\n+\n+  if (tmp == (tmp & -tmp))\n+    return (val + 1) > 1;\n+\n+  /* Invert if the immediate doesn't start with a zero bit - this means we\n+     only need to search for sequences of one bits.  */\n+  if (val & 1)\n+    val = ~val;\n+\n+  /* Find the first set bit and set tmp to val with the first sequence of one\n+     bits removed.  Return success if there is a single sequence of ones.  */\n+  first_one = val & -val;\n+  tmp = val & (val + first_one);\n+\n+  if (tmp == 0)\n+    return true;\n+\n+  /* Find the next set bit and compute the difference in bit position.  */\n+  next_one = tmp & -tmp;\n+  bits = clz_hwi (first_one) - clz_hwi (next_one);\n+  mask = val ^ tmp;\n+\n+  /* Check the bit position difference is a power of 2, and that the first\n+     sequence of one bits fits within 'bits' bits.  */\n+  if ((mask >> bits) != 0 || bits != (bits & -bits))\n+    return false;\n+\n+  /* Check the sequence of one bits is repeated 64/bits times.  */\n+  return val == mask * bitmask_imm_mul[__builtin_clz (bits) - 26];\n+}\n+\n+\n+/* Return true if VAL is a valid bitmask immediate for MODE.  */\n+bool\n+aarch64_bitmask_imm (HOST_WIDE_INT val_in, machine_mode mode)\n+{\n+  if (mode == DImode)\n+    return aarch64_bitmask_imm (val_in);\n+\n+  unsigned HOST_WIDE_INT val = val_in;\n+\n+  if (mode == SImode)\n+    return aarch64_bitmask_imm ((val & 0xffffffff) | (val << 32));\n+\n+  /* Replicate small immediates to fit 64 bits.  */\n+  int size = GET_MODE_UNIT_PRECISION (mode);\n+  val &= (HOST_WIDE_INT_1U << size) - 1;\n+  val *= bitmask_imm_mul[__builtin_clz (size) - 26];\n+\n+  return aarch64_bitmask_imm (val);\n+}\n+\n+\n+/* Return true if the immediate VAL can be a bitfield immediate\n+   by changing the given MASK bits in VAL to zeroes, ones or bits\n+   from the other half of VAL.  Return the new immediate in VAL2.  */\n+static inline bool\n+aarch64_check_bitmask (unsigned HOST_WIDE_INT val,\n+\t\t       unsigned HOST_WIDE_INT &val2,\n+\t\t       unsigned HOST_WIDE_INT mask)\n+{\n+  val2 = val & ~mask;\n+  if (val2 != val && aarch64_bitmask_imm (val2))\n+    return true;\n+  val2 = val | mask;\n+  if (val2 != val && aarch64_bitmask_imm (val2))\n+    return true;\n+  val = val & ~mask;\n+  val2 = val | (((val >> 32) | (val << 32)) & mask);\n+  if (val2 != val && aarch64_bitmask_imm (val2))\n+    return true;\n+  val2 = val | (((val >> 16) | (val << 48)) & mask);\n+  if (val2 != val && aarch64_bitmask_imm (val2))\n+    return true;\n+  return false;\n+}\n+\n+\n+/* Return true if val is an immediate that can be loaded into a\n+   register by a MOVZ instruction.  */\n+static bool\n+aarch64_movw_imm (HOST_WIDE_INT val, scalar_int_mode mode)\n+{\n+  if (GET_MODE_SIZE (mode) > 4)\n+    {\n+      if ((val & (((HOST_WIDE_INT) 0xffff) << 32)) == val\n+\t   || (val & (((HOST_WIDE_INT) 0xffff) << 48)) == val)\n+\treturn 1;\n+    }\n+  else\n+    {\n+      /* Ignore sign extension.  */\n+      val &= (HOST_WIDE_INT) 0xffffffff;\n+    }\n+  return ((val & (((HOST_WIDE_INT) 0xffff) << 0)) == val\n+\t  || (val & (((HOST_WIDE_INT) 0xffff) << 16)) == val);\n+}\n+\n+\n+/* Return true if VAL is an immediate that can be loaded into a\n+   register in a single instruction.  */\n+bool\n+aarch64_move_imm (HOST_WIDE_INT val, machine_mode mode)\n+{\n+  scalar_int_mode int_mode;\n+  if (!is_a <scalar_int_mode> (mode, &int_mode))\n+    return false;\n+\n+  if (aarch64_movw_imm (val, int_mode) || aarch64_movw_imm (~val, int_mode))\n+    return 1;\n+  return aarch64_bitmask_imm (val, int_mode);\n+}\n+\n+\n static int\n aarch64_internal_mov_immediate (rtx dest, rtx imm, bool generate,\n \t\t\t\tscalar_int_mode mode)\n@@ -5532,7 +5668,7 @@ aarch64_internal_mov_immediate (rtx dest, rtx imm, bool generate,\n \temit_insn (gen_rtx_SET (dest, GEN_INT (val2)));\n \n       /* Check if we have to emit a second instruction by checking to see\n-         if any of the upper 32 bits of the original DI mode value is set.  */\n+\t if any of the upper 32 bits of the original DI mode value is set.  */\n       if (val == val2)\n \treturn 1;\n \n@@ -5568,36 +5704,43 @@ aarch64_internal_mov_immediate (rtx dest, rtx imm, bool generate,\n   one_match = ((~val & mask) == 0) + ((~val & (mask << 16)) == 0) +\n     ((~val & (mask << 32)) == 0) + ((~val & (mask << 48)) == 0);\n \n-  if (zero_match != 2 && one_match != 2)\n+  if (zero_match < 2 && one_match < 2)\n     {\n       /* Try emitting a bitmask immediate with a movk replacing 16 bits.\n \t For a 64-bit bitmask try whether changing 16 bits to all ones or\n \t zeroes creates a valid bitmask.  To check any repeated bitmask,\n \t try using 16 bits from the other 32-bit half of val.  */\n \n-      for (i = 0; i < 64; i += 16, mask <<= 16)\n-\t{\n-\t  val2 = val & ~mask;\n-\t  if (val2 != val && aarch64_bitmask_imm (val2, mode))\n-\t    break;\n-\t  val2 = val | mask;\n-\t  if (val2 != val && aarch64_bitmask_imm (val2, mode))\n-\t    break;\n-\t  val2 = val2 & ~mask;\n-\t  val2 = val2 | (((val2 >> 32) | (val2 << 32)) & mask);\n-\t  if (val2 != val && aarch64_bitmask_imm (val2, mode))\n-\t    break;\n-\t}\n-      if (i != 64)\n-\t{\n-\t  if (generate)\n+      for (i = 0; i < 64; i += 16)\n+\tif (aarch64_check_bitmask (val, val2, mask << i))\n+\t  {\n+\t    if (generate)\n+\t      {\n+\t\temit_insn (gen_rtx_SET (dest, GEN_INT (val2)));\n+\t\temit_insn (gen_insv_immdi (dest, GEN_INT (i),\n+\t\t\t\t\t   GEN_INT ((val >> i) & 0xffff)));\n+\t      }\n+\t    return 2;\n+\t  }\n+    }\n+\n+  /* Try a bitmask plus 2 movk to generate the immediate in 3 instructions.  */\n+  if (zero_match + one_match == 0)\n+    {\n+      for (i = 0; i < 48; i += 16)\n+\tfor (int j = i + 16; j < 64; j += 16)\n+\t  if (aarch64_check_bitmask (val, val2, (mask << i) | (mask << j)))\n \t    {\n-\t      emit_insn (gen_rtx_SET (dest, GEN_INT (val2)));\n-\t      emit_insn (gen_insv_immdi (dest, GEN_INT (i),\n-\t\t\t\t\t GEN_INT ((val >> i) & 0xffff)));\n+\t      if (generate)\n+\t\t{\n+\t\t  emit_insn (gen_rtx_SET (dest, GEN_INT (val2)));\n+\t\t  emit_insn (gen_insv_immdi (dest, GEN_INT (i),\n+\t\t\t\t\t     GEN_INT ((val >> i) & 0xffff)));\n+\t\t  emit_insn (gen_insv_immdi (dest, GEN_INT (j),\n+\t\t\t\t\t       GEN_INT ((val >> j) & 0xffff)));\n+\t\t}\n+\t      return 3;\n \t    }\n-\t  return 2;\n-\t}\n     }\n \n   /* Generate 2-4 instructions, skipping 16 bits of all zeroes or ones which\n@@ -5644,6 +5787,99 @@ aarch64_mov128_immediate (rtx imm)\n }\n \n \n+/* Return true if val can be encoded as a 12-bit unsigned immediate with\n+   a left shift of 0 or 12 bits.  */\n+bool\n+aarch64_uimm12_shift (HOST_WIDE_INT val)\n+{\n+  return ((val & (((HOST_WIDE_INT) 0xfff) << 0)) == val\n+\t  || (val & (((HOST_WIDE_INT) 0xfff) << 12)) == val\n+\t  );\n+}\n+\n+/* Returns the nearest value to VAL that will fit as a 12-bit unsigned immediate\n+   that can be created with a left shift of 0 or 12.  */\n+static HOST_WIDE_INT\n+aarch64_clamp_to_uimm12_shift (HOST_WIDE_INT val)\n+{\n+  /* Check to see if the value fits in 24 bits, as that is the maximum we can\n+     handle correctly.  */\n+  gcc_assert ((val & 0xffffff) == val);\n+\n+  if (((val & 0xfff) << 0) == val)\n+    return val;\n+\n+  return val & (0xfff << 12);\n+}\n+\n+\n+/* Test whether:\n+\n+     X = (X & AND_VAL) | IOR_VAL;\n+\n+   can be implemented using:\n+\n+     MOVK X, #(IOR_VAL >> shift), LSL #shift\n+\n+   Return the shift if so, otherwise return -1.  */\n+int\n+aarch64_movk_shift (const wide_int_ref &and_val,\n+\t\t    const wide_int_ref &ior_val)\n+{\n+  unsigned int precision = and_val.get_precision ();\n+  unsigned HOST_WIDE_INT mask = 0xffff;\n+  for (unsigned int shift = 0; shift < precision; shift += 16)\n+    {\n+      if (and_val == ~mask && (ior_val & mask) == ior_val)\n+\treturn shift;\n+      mask <<= 16;\n+    }\n+  return -1;\n+}\n+\n+/* Create mask of ones, covering the lowest to highest bits set in VAL_IN.\n+   Assumed precondition: VAL_IN Is not zero.  */\n+\n+unsigned HOST_WIDE_INT\n+aarch64_and_split_imm1 (HOST_WIDE_INT val_in)\n+{\n+  int lowest_bit_set = ctz_hwi (val_in);\n+  int highest_bit_set = floor_log2 (val_in);\n+  gcc_assert (val_in != 0);\n+\n+  return ((HOST_WIDE_INT_UC (2) << highest_bit_set) -\n+\t  (HOST_WIDE_INT_1U << lowest_bit_set));\n+}\n+\n+/* Create constant where bits outside of lowest bit set to highest bit set\n+   are set to 1.  */\n+\n+unsigned HOST_WIDE_INT\n+aarch64_and_split_imm2 (HOST_WIDE_INT val_in)\n+{\n+  return val_in | ~aarch64_and_split_imm1 (val_in);\n+}\n+\n+/* Return true if VAL_IN is a valid 'and' bitmask immediate.  */\n+\n+bool\n+aarch64_and_bitmask_imm (unsigned HOST_WIDE_INT val_in, machine_mode mode)\n+{\n+  scalar_int_mode int_mode;\n+  if (!is_a <scalar_int_mode> (mode, &int_mode))\n+    return false;\n+\n+  if (aarch64_bitmask_imm (val_in, int_mode))\n+    return false;\n+\n+  if (aarch64_move_imm (val_in, int_mode))\n+    return false;\n+\n+  unsigned HOST_WIDE_INT imm2 = aarch64_and_split_imm2 (val_in);\n+\n+  return aarch64_bitmask_imm (imm2, int_mode);\n+}\n+\n /* Return the number of temporary registers that aarch64_add_offset_1\n    would need to add OFFSET to a register.  */\n \n@@ -10099,207 +10335,6 @@ aarch64_tls_referenced_p (rtx x)\n }\n \n \n-/* Return true if val can be encoded as a 12-bit unsigned immediate with\n-   a left shift of 0 or 12 bits.  */\n-bool\n-aarch64_uimm12_shift (HOST_WIDE_INT val)\n-{\n-  return ((val & (((HOST_WIDE_INT) 0xfff) << 0)) == val\n-\t  || (val & (((HOST_WIDE_INT) 0xfff) << 12)) == val\n-\t  );\n-}\n-\n-/* Returns the nearest value to VAL that will fit as a 12-bit unsigned immediate\n-   that can be created with a left shift of 0 or 12.  */\n-static HOST_WIDE_INT\n-aarch64_clamp_to_uimm12_shift (HOST_WIDE_INT val)\n-{\n-  /* Check to see if the value fits in 24 bits, as that is the maximum we can\n-     handle correctly.  */\n-  gcc_assert ((val & 0xffffff) == val);\n-\n-  if (((val & 0xfff) << 0) == val)\n-    return val;\n-\n-  return val & (0xfff << 12);\n-}\n-\n-/* Return true if val is an immediate that can be loaded into a\n-   register by a MOVZ instruction.  */\n-static bool\n-aarch64_movw_imm (HOST_WIDE_INT val, scalar_int_mode mode)\n-{\n-  if (GET_MODE_SIZE (mode) > 4)\n-    {\n-      if ((val & (((HOST_WIDE_INT) 0xffff) << 32)) == val\n-\t  || (val & (((HOST_WIDE_INT) 0xffff) << 48)) == val)\n-\treturn 1;\n-    }\n-  else\n-    {\n-      /* Ignore sign extension.  */\n-      val &= (HOST_WIDE_INT) 0xffffffff;\n-    }\n-  return ((val & (((HOST_WIDE_INT) 0xffff) << 0)) == val\n-\t  || (val & (((HOST_WIDE_INT) 0xffff) << 16)) == val);\n-}\n-\n-/* Test whether:\n-\n-     X = (X & AND_VAL) | IOR_VAL;\n-\n-   can be implemented using:\n-\n-     MOVK X, #(IOR_VAL >> shift), LSL #shift\n-\n-   Return the shift if so, otherwise return -1.  */\n-int\n-aarch64_movk_shift (const wide_int_ref &and_val,\n-\t\t    const wide_int_ref &ior_val)\n-{\n-  unsigned int precision = and_val.get_precision ();\n-  unsigned HOST_WIDE_INT mask = 0xffff;\n-  for (unsigned int shift = 0; shift < precision; shift += 16)\n-    {\n-      if (and_val == ~mask && (ior_val & mask) == ior_val)\n-\treturn shift;\n-      mask <<= 16;\n-    }\n-  return -1;\n-}\n-\n-/* VAL is a value with the inner mode of MODE.  Replicate it to fill a\n-   64-bit (DImode) integer.  */\n-\n-static unsigned HOST_WIDE_INT\n-aarch64_replicate_bitmask_imm (unsigned HOST_WIDE_INT val, machine_mode mode)\n-{\n-  unsigned int size = GET_MODE_UNIT_PRECISION (mode);\n-  while (size < 64)\n-    {\n-      val &= (HOST_WIDE_INT_1U << size) - 1;\n-      val |= val << size;\n-      size *= 2;\n-    }\n-  return val;\n-}\n-\n-/* Multipliers for repeating bitmasks of width 32, 16, 8, 4, and 2.  */\n-\n-static const unsigned HOST_WIDE_INT bitmask_imm_mul[] =\n-  {\n-    0x0000000100000001ull,\n-    0x0001000100010001ull,\n-    0x0101010101010101ull,\n-    0x1111111111111111ull,\n-    0x5555555555555555ull,\n-  };\n-\n-\n-/* Return true if val is a valid bitmask immediate.  */\n-\n-bool\n-aarch64_bitmask_imm (HOST_WIDE_INT val_in, machine_mode mode)\n-{\n-  unsigned HOST_WIDE_INT val, tmp, mask, first_one, next_one;\n-  int bits;\n-\n-  /* Check for a single sequence of one bits and return quickly if so.\n-     The special cases of all ones and all zeroes returns false.  */\n-  val = aarch64_replicate_bitmask_imm (val_in, mode);\n-  tmp = val + (val & -val);\n-\n-  if (tmp == (tmp & -tmp))\n-    return (val + 1) > 1;\n-\n-  /* Replicate 32-bit immediates so we can treat them as 64-bit.  */\n-  if (mode == SImode)\n-    val = (val << 32) | (val & 0xffffffff);\n-\n-  /* Invert if the immediate doesn't start with a zero bit - this means we\n-     only need to search for sequences of one bits.  */\n-  if (val & 1)\n-    val = ~val;\n-\n-  /* Find the first set bit and set tmp to val with the first sequence of one\n-     bits removed.  Return success if there is a single sequence of ones.  */\n-  first_one = val & -val;\n-  tmp = val & (val + first_one);\n-\n-  if (tmp == 0)\n-    return true;\n-\n-  /* Find the next set bit and compute the difference in bit position.  */\n-  next_one = tmp & -tmp;\n-  bits = clz_hwi (first_one) - clz_hwi (next_one);\n-  mask = val ^ tmp;\n-\n-  /* Check the bit position difference is a power of 2, and that the first\n-     sequence of one bits fits within 'bits' bits.  */\n-  if ((mask >> bits) != 0 || bits != (bits & -bits))\n-    return false;\n-\n-  /* Check the sequence of one bits is repeated 64/bits times.  */\n-  return val == mask * bitmask_imm_mul[__builtin_clz (bits) - 26];\n-}\n-\n-/* Create mask of ones, covering the lowest to highest bits set in VAL_IN.  \n-   Assumed precondition: VAL_IN Is not zero.  */\n-\n-unsigned HOST_WIDE_INT\n-aarch64_and_split_imm1 (HOST_WIDE_INT val_in)\n-{\n-  int lowest_bit_set = ctz_hwi (val_in);\n-  int highest_bit_set = floor_log2 (val_in);\n-  gcc_assert (val_in != 0);\n-\n-  return ((HOST_WIDE_INT_UC (2) << highest_bit_set) -\n-\t  (HOST_WIDE_INT_1U << lowest_bit_set));\n-}\n-\n-/* Create constant where bits outside of lowest bit set to highest bit set\n-   are set to 1.  */\n-\n-unsigned HOST_WIDE_INT\n-aarch64_and_split_imm2 (HOST_WIDE_INT val_in)\n-{\n-  return val_in | ~aarch64_and_split_imm1 (val_in);\n-}\n-\n-/* Return true if VAL_IN is a valid 'and' bitmask immediate.  */\n-\n-bool\n-aarch64_and_bitmask_imm (unsigned HOST_WIDE_INT val_in, machine_mode mode)\n-{\n-  scalar_int_mode int_mode;\n-  if (!is_a <scalar_int_mode> (mode, &int_mode))\n-    return false;\n-\n-  if (aarch64_bitmask_imm (val_in, int_mode))\n-    return false;\n-\n-  if (aarch64_move_imm (val_in, int_mode))\n-    return false;\n-\n-  unsigned HOST_WIDE_INT imm2 = aarch64_and_split_imm2 (val_in);\n-\n-  return aarch64_bitmask_imm (imm2, int_mode);\n-}\n-\n-/* Return true if val is an immediate that can be loaded into a\n-   register in a single instruction.  */\n-bool\n-aarch64_move_imm (HOST_WIDE_INT val, machine_mode mode)\n-{\n-  scalar_int_mode int_mode;\n-  if (!is_a <scalar_int_mode> (mode, &int_mode))\n-    return false;\n-\n-  if (aarch64_movw_imm (val, int_mode) || aarch64_movw_imm (~val, int_mode))\n-    return 1;\n-  return aarch64_bitmask_imm (val, int_mode);\n-}\n-\n static bool\n aarch64_cannot_force_const_mem (machine_mode mode ATTRIBUTE_UNUSED, rtx x)\n {"}, {"sha": "0f931580817d78dc1cc58f03b251bd21bec71f59", "filename": "gcc/testsuite/gcc.target/aarch64/pr106583.c", "status": "added", "additions": 41, "deletions": 0, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a096036589d82175a0f729c2dab73c9a527d075d/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fpr106583.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a096036589d82175a0f729c2dab73c9a527d075d/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fpr106583.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fpr106583.c?ref=a096036589d82175a0f729c2dab73c9a527d075d", "patch": "@@ -0,0 +1,41 @@\n+/* { dg-do assemble } */\n+/* { dg-options \"-O2 --save-temps\" } */\n+\n+long f1 (void)\n+{\n+  return 0x7efefefefefefeff;\n+}\n+\n+long f2 (void)\n+{\n+  return 0x12345678aaaaaaaa;\n+}\n+\n+long f3 (void)\n+{\n+  return 0x1234cccccccc5678;\n+}\n+\n+long f4 (void)\n+{\n+  return 0x7777123456787777;\n+}\n+\n+long f5 (void)\n+{\n+  return 0x5555555512345678;\n+}\n+\n+long f6 (void)\n+{\n+  return 0x1234bbbb5678bbbb;\n+}\n+\n+long f7 (void)\n+{\n+  return 0x4444123444445678;\n+}\n+\n+\n+/* { dg-final { scan-assembler-times {\\tmovk\\t} 14 } } */\n+/* { dg-final { scan-assembler-times {\\tmov\\t} 7 } } */"}]}