{"sha": "d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDFkOWE2YmQ2NmQzZDliNmNiYWRlNTYwOTM5NWZjNjE4ZmE4OGYxMQ==", "commit": {"author": {"name": "Neil Booth", "email": "neilb@earthling.net", "date": "2000-05-27T23:19:56Z"}, "committer": {"name": "Neil Booth", "email": "neil@gcc.gnu.org", "date": "2000-05-27T23:19:56Z"}, "message": "cppexp.c (parse_assertion): Supply extra argument to _cpp_init_toklist.\n\n\t* cppexp.c (parse_assertion): Supply extra argument to\n\t_cpp_init_toklist.\n\t* cpplib.c (do_assert, do_unassert): Similarly.\n\t* cpphash.h (_cpp_init_toklist) Update.\n\t(_cpp_expand_token_space): New.\n\t(DUMMY_TOKEN, NO_DUMMY_TOKEN): New.\n\t* cpplex.c (_cpp_init_toklist): New argument.\n\t(parse_string2): New argument multiline_ok.\n\t(spell_token): Take a const cpp_token *.\n\t(INIT_NAME): Replace with INIT_TOKEN_NAME.  Update tokens_used.\n\t(SPELL_ macros): Replace with enum.\n\t(expand_token_space): Replace with _cpp_expand_token_space.\n\tTake COUNT argument.\n\t(IS_DIRECTIVE): Update.\n\t(_cpp_lex_line): Update token structure before parsing number.\n\tDon't assume start at beginning of token list.\n\t(save_comment): Use INIT_TOKEN_NAME.\n\nFrom-SVN: r34214", "tree": {"sha": "ff9a2b403a2c145b28540e1d32020de18ec3ff6c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ff9a2b403a2c145b28540e1d32020de18ec3ff6c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/comments", "author": null, "committer": null, "parents": [{"sha": "f45c9d956fb0a137a3ec8e48e38a617b0119db53", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f45c9d956fb0a137a3ec8e48e38a617b0119db53", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f45c9d956fb0a137a3ec8e48e38a617b0119db53"}], "stats": {"total": 207, "additions": 132, "deletions": 75}, "files": [{"sha": "b8c97b4581e3397b7f0143a474754eacc865dffa", "filename": "gcc/ChangeLog", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "patch": "@@ -1,3 +1,23 @@\n+2000-05-28  Neil Booth  <NeilB@earthling.net>\n+\n+\t* cppexp.c (parse_assertion): Supply extra argument to\n+\t_cpp_init_toklist.\n+\t* cpplib.c (do_assert, do_unassert): Similarly.\n+\t* cpphash.h (_cpp_init_toklist) Update.\n+\t(_cpp_expand_token_space): New.\n+\t(DUMMY_TOKEN, NO_DUMMY_TOKEN): New.\n+\t* cpplex.c (_cpp_init_toklist): New argument.\n+\t(parse_string2): New argument multiline_ok.\n+\t(spell_token): Take a const cpp_token *.\n+\t(INIT_NAME): Replace with INIT_TOKEN_NAME.  Update tokens_used.\n+\t(SPELL_ macros): Replace with enum.\n+\t(expand_token_space): Replace with _cpp_expand_token_space.\n+\tTake COUNT argument.\n+\t(IS_DIRECTIVE): Update.\n+\t(_cpp_lex_line): Update token structure before parsing number.\n+\tDon't assume start at beginning of token list.\n+\t(save_comment): Use INIT_TOKEN_NAME.\n+\n 2000-05-27  Zack Weinberg  <zack@wolery.cumb.org>\n \n \t* configure.in (stage1_warn_cflags): Add -Wstrict-prototypes"}, {"sha": "e823232cee7c121a733f8c3d5b8ddc107ddc47d1", "filename": "gcc/cppexp.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcppexp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcppexp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppexp.c?ref=d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "patch": "@@ -423,7 +423,7 @@ parse_assertion (pfile)\n       if (_cpp_get_directive_token (pfile) != CPP_OPEN_PAREN)\n \tCPP_ICE (\"impossible token, expecting ( in parse_assertion\");\n \n-      _cpp_init_toklist (&query);\n+      _cpp_init_toklist (&query, NO_DUMMY_TOKEN);\n       specific = 1;\n       if (_cpp_scan_until (pfile, &query, CPP_CLOSE_PAREN) != CPP_CLOSE_PAREN)\n \tSYNTAX_ERROR (\"missing close paren on assertion answer\");"}, {"sha": "afa5d92cdd1eeaac334775b2aaf6d675fc675b6b", "filename": "gcc/cpphash.h", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcpphash.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcpphash.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpphash.h?ref=d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "patch": "@@ -218,6 +218,10 @@ extern unsigned char _cpp_IStable[256];\n #define ADJACENT_TO_MARK(PFILE) \\\n  (CPP_BUFFER(PFILE)->cur - CPP_BUFFER(PFILE)->mark == 1)\n \n+/* Flags for _cpp_init_toklist.  */\n+#define DUMMY_TOKEN     0\n+#define NO_DUMMY_TOKEN\t1\n+\n /* In cpphash.c */\n extern unsigned int _cpp_calc_hash\tPARAMS ((const U_CHAR *, size_t));\n extern HASHNODE *_cpp_lookup\t\tPARAMS ((cpp_reader *,\n@@ -260,7 +264,7 @@ extern enum cpp_ttype _cpp_get_define_token\n \t\t\t\t\tPARAMS ((cpp_reader *));\n extern enum cpp_ttype _cpp_scan_until\tPARAMS ((cpp_reader *, cpp_toklist *,\n \t\t\t\t\t\t enum cpp_ttype));\n-extern void _cpp_init_toklist\t\tPARAMS ((cpp_toklist *));\n+extern void _cpp_init_toklist\t\tPARAMS ((cpp_toklist *, int));\n extern void _cpp_clear_toklist\t\tPARAMS ((cpp_toklist *));\n extern void _cpp_free_toklist\t\tPARAMS ((cpp_toklist *));\n extern void _cpp_slice_toklist\t\tPARAMS ((cpp_toklist *,\n@@ -271,7 +275,7 @@ extern int _cpp_equiv_tokens\t\tPARAMS ((const cpp_token *,\n \t\t\t\t\t\t const cpp_token *));\n extern int _cpp_equiv_toklists\t\tPARAMS ((const cpp_toklist *,\n \t\t\t\t\t\t const cpp_toklist *));\n-\n+extern void _cpp_expand_token_space\tPARAMS ((cpp_toklist *, unsigned int));\n \n /* In cpplib.c */\n extern int _cpp_handle_directive\tPARAMS ((cpp_reader *));"}, {"sha": "ddea616cad6be9772ea5d8262d4ff9783bd650e7", "filename": "gcc/cpplex.c", "status": "modified", "additions": 103, "deletions": 70, "changes": 173, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcpplex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcpplex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplex.c?ref=d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "patch": "@@ -54,7 +54,6 @@ static void output_line_command\tPARAMS ((cpp_reader *, cpp_printer *,\n static void bump_column\t\tPARAMS ((cpp_printer *, unsigned int,\n \t\t\t\t\t unsigned int));\n static void expand_name_space   PARAMS ((cpp_toklist *, unsigned int));\n-static void expand_token_space\tPARAMS ((cpp_toklist *));\n static void pedantic_whitespace\tPARAMS ((cpp_reader *, U_CHAR *,\n \t\t\t\t\t unsigned int));\n \n@@ -75,26 +74,26 @@ static void skip_whitespace PARAMS ((cpp_reader *, int));\n static void parse_name PARAMS ((cpp_reader *, cpp_toklist *, cpp_name *));\n static void parse_number PARAMS ((cpp_reader *, cpp_toklist *, cpp_name *));\n static void parse_string2 PARAMS ((cpp_reader *, cpp_toklist *, cpp_name *,\n-\t\t\t\t  unsigned int));\n+\t\t\t\t  unsigned int, int));\n static int trigraph_ok PARAMS ((cpp_reader *, const unsigned char *));\n static void save_comment PARAMS ((cpp_toklist *, const unsigned char *,\n \t\t\t\t  unsigned int, unsigned int, unsigned int));\n void _cpp_lex_line PARAMS ((cpp_reader *, cpp_toklist *));\n \n static void _cpp_output_list PARAMS ((cpp_reader *, cpp_toklist *));\n \n-static unsigned char * spell_token PARAMS ((cpp_reader *, cpp_token *,\n+static unsigned char * spell_token PARAMS ((cpp_reader *, const cpp_token *,\n \t\t\t\t\t    unsigned char *, int));\n \n typedef unsigned int (* speller) PARAMS ((unsigned char *, cpp_toklist *,\n \t\t\t\t\t  cpp_token *));\n \n /* Macros on a cpp_name.  */\n-#define INIT_NAME(list, name) \\\n-  do {(name).len = 0; \\\n-      (name).text = (list)->namebuf + (list)->name_used;} while (0)\n-\n-#define IS_DIRECTIVE(list) (TOK_TYPE (list, 0) == CPP_HASH)\n+#define INIT_TOKEN_NAME(list, token) \\\n+  do {(token)->val.name.len = 0; \\\n+      (token)->val.name.text = (list)->namebuf + (list)->name_used; \\\n+      (list)->tokens_used = token - (list)->tokens + 1; \\\n+  } while (0)\n \n /* Maybe put these in the ISTABLE eventually.  */\n #define IS_HSPACE(c) ((c) == ' ' || (c) == '\\t')\n@@ -128,11 +127,14 @@ typedef unsigned int (* speller) PARAMS ((unsigned char *, cpp_toklist *,\n \n /* Order here matters.  Those beyond SPELL_NONE store their spelling\n    in the token list, and it's length in the token->val.name.len.  */\n-#define SPELL_OPERATOR 0\n-#define SPELL_CHAR     2\t/* FIXME: revert order after transition. */\n-#define SPELL_NONE     1\n-#define SPELL_IDENT    3\n-#define SPELL_STRING   4\n+enum spell_type\n+{\n+  SPELL_OPERATOR = 0,\n+  SPELL_NONE,\n+  SPELL_CHAR,    /* FIXME: revert order of NONE and CHAR after transition. */\n+  SPELL_IDENT,\n+  SPELL_STRING\n+};\n \n #define T(e, s) {SPELL_OPERATOR, (const U_CHAR *) s},\n #define I(e, s) {SPELL_IDENT, s},\n@@ -142,7 +144,7 @@ typedef unsigned int (* speller) PARAMS ((unsigned char *, cpp_toklist *,\n \n static const struct token_spelling\n {\n-  U_CHAR type;\n+  ENUM_BITFIELD(spell_type) type : CHAR_BIT;\n   const U_CHAR *spelling;\n } token_spellings [N_TTYPES + 1] = {TTYPE_TABLE {0, 0} };\n \n@@ -518,7 +520,8 @@ cpp_file_buffer (pfile)\n \n /* Token-buffer helper functions.  */\n \n-/* Expand a token list's string space.  */\n+/* Expand a token list's string space. It is *vital* that\n+   list->tokens_used is correct, to get pointer fix-up right.  */\n static void\n expand_name_space (list, len)\n      cpp_toklist *list;\n@@ -542,43 +545,64 @@ expand_name_space (list, len)\n }\n \n /* Expand the number of tokens in a list.  */\n-static void\n-expand_token_space (list)\n+void\n+_cpp_expand_token_space (list, count)\n      cpp_toklist *list;\n+     unsigned int count;\n {\n-  list->tokens_cap *= 2;\n+  unsigned int n;\n+\n+  list->tokens_cap += count;\n+  n = list->tokens_cap;\n   if (list->flags & LIST_OFFSET)\n-    list->tokens--;\n+    list->tokens--, n++;\n   list->tokens = (cpp_token *)\n-    xrealloc (list->tokens, (list->tokens_cap + 1) * sizeof (cpp_token));\n+    xrealloc (list->tokens, n * sizeof (cpp_token));\n   if (list->flags & LIST_OFFSET)\n     list->tokens++;\t\t/* Skip the dummy.  */\n }\n \n-/* Initialize a token list.  We allocate an extra token in front of\n-   the token list, as this allows us to always peek at the previous\n-   token without worrying about underflowing the list.  */\n+/* Initialize a token list.  If flags is DUMMY_TOKEN, we allocate\n+   an extra token in front of the token list, as this allows the lexer\n+   to always peek at the previous token without worrying about\n+   underflowing the list, and some initial space.  Otherwise, no\n+   token- or name-space is allocated, and there is no dummy token.  */\n void\n-_cpp_init_toklist (list)\n+_cpp_init_toklist (list, flags)\n      cpp_toklist *list;\n+     int flags;\n {\n-  /* Initialize token space.  Put a dummy token before the start\n-     that will fail matches.  */\n-  list->tokens_cap = 256;\t/* 4K's worth.  */\n-  list->tokens = (cpp_token *)\n-    xmalloc ((list->tokens_cap + 1) * sizeof (cpp_token));\n-  list->tokens[0].type = CPP_EOF;\n-  list->tokens++;\n+  /* We malloc zero bytes because we may want to realloc later, and\n+     some old implementations don't like realloc-ing a null pointer.  */\n+  if (flags == NO_DUMMY_TOKEN)\n+    {\n+      list->tokens_cap = 0;\n+      list->tokens = (cpp_token *) malloc (0);\n+      list->name_cap = 0;\n+      list->flags = 0;\n+    }\n+  else\n+    {\n+      /* Initialize token space.  Put a dummy token before the start\n+\t that will fail matches.  */\n+      list->tokens_cap = 256;\t/* 4K's worth.  */\n+      list->tokens = (cpp_token *)\n+\txmalloc ((list->tokens_cap + 1) * sizeof (cpp_token));\n+      list->tokens[0].type = CPP_EOF;\n+      list->tokens++;\n+\n+      /* Initialize name space.  */\n+      list->name_cap = 1024;\n+      list->flags = LIST_OFFSET;\n+    }\n \n-  /* Initialize name space.  */\n-  list->name_cap = 1024;\n+  /* Allocate name space.  */\n   list->namebuf = (unsigned char *) xmalloc (list->name_cap);\n \n   /* Only create a comment space on demand.  */\n   list->comments_cap = 0;\n   list->comments = 0;\n \n-  list->flags = LIST_OFFSET;\n   _cpp_clear_toklist (list);\n }\n \n@@ -777,7 +801,7 @@ _cpp_scan_until (pfile, list, stop)\n \tcontinue;\n \n       if (list->tokens_used >= list->tokens_cap)\n-\texpand_token_space (list);\n+\t_cpp_expand_token_space (list, 256);\n       if (list->name_used + len >= list->name_cap)\n \texpand_name_space (list, list->name_used + len + 1 - list->name_cap);\n \n@@ -2194,7 +2218,7 @@ _cpp_init_input_buffer (pfile)\n   U_CHAR *tmp;\n \n   init_chartab ();\n-  _cpp_init_toklist (&pfile->directbuf);\n+  _cpp_init_toklist (&pfile->directbuf, NO_DUMMY_TOKEN);\n \n   /* Determine the appropriate size for the input buffer.  Normal C\n      source files are smaller than eight K.  */\n@@ -2702,11 +2726,12 @@ parse_number (pfile, list, name)\n    allowed, except for within directives.  */\n \n static void\n-parse_string2 (pfile, list, name, terminator)\n+parse_string2 (pfile, list, name, terminator, multiline_ok)\n      cpp_reader *pfile;\n      cpp_toklist *list;\n      cpp_name *name;\n      unsigned int terminator;\n+     int multiline_ok;\n {\n   cpp_buffer *buffer = pfile->buffer;\n   register const unsigned char *cur = buffer->cur;\n@@ -2766,7 +2791,7 @@ parse_string2 (pfile, list, name, terminator)\n \t\t extend over multiple lines.  In Standard C, neither\n \t\t may strings.  We accept multiline strings as an\n \t\t extension, but not in directives.  */\n-\t      if (terminator != '\"' || IS_DIRECTIVE (list))\n+\t      if (!multiline_ok)\n \t\tgoto unterminated;\n \t\t\n \t      cur++;  /* Move forwards again.  */\n@@ -2857,14 +2882,16 @@ save_comment (list, from, len, tok_no, type)\n   if (list->name_used + len > list->name_cap)\n     expand_name_space (list, len);\n \n-  buffer = list->namebuf + list->name_used;\n-\n   comment = &list->comments[list->comments_used++];\n+  INIT_TOKEN_NAME (list, comment);\n   comment->type = CPP_COMMENT;\n   comment->aux = tok_no;\n   comment->val.name.len = len;\n-  comment->val.name.text = buffer;\n \n+  buffer = list->namebuf + list->name_used;\n+  list->name_used += len;\n+\n+  /* Copy the comment.  */\n   if (type == '*')\n     {\n       *buffer++ = '/';\n@@ -2875,9 +2902,7 @@ save_comment (list, from, len, tok_no, type)\n       *buffer++ = type;\n       *buffer++ = type;\n     }\n-\n   memcpy (buffer, from, len - COMMENT_START_LEN);\n-  list->name_used += len;\n }\n \n /*\n@@ -2894,6 +2919,8 @@ save_comment (list, from, len, tok_no, type)\n  *  even when enabled.\n  */\n \n+#define IS_DIRECTIVE() (list->tokens[first_token].type == CPP_HASH)\n+\n void\n _cpp_lex_line (pfile, list)\n      cpp_reader *pfile;\n@@ -2903,6 +2930,7 @@ _cpp_lex_line (pfile, list)\n   cpp_buffer *buffer = pfile->buffer;\n   register const unsigned char *cur = buffer->cur;\n   unsigned char flags = 0;\n+  unsigned int first_token = list->tokens_used;\n \n   pfile->col_adjust = 0;\n  expanded:\n@@ -2920,7 +2948,7 @@ _cpp_lex_line (pfile, list)\n \t{\n \t  /* Step back to get the null warning and tab correction.  */\n \t  buffer->cur = cur - 1;\n-\t  skip_whitespace (pfile, IS_DIRECTIVE (list));\n+\t  skip_whitespace (pfile, IS_DIRECTIVE ());\n \t  cur = buffer->cur;\n \n \t  flags = PREV_WHITESPACE;\n@@ -2938,27 +2966,31 @@ _cpp_lex_line (pfile, list)\n \t{\n \tcase '0': case '1': case '2': case '3': case '4':\n \tcase '5': case '6': case '7': case '8': case '9':\n-\t  cur--;\t\t/* Backup character.  */\n-\t  if (PREV_TOKEN_TYPE == CPP_DOT && IMMED_TOKEN ())\n-\t    {\n-\t      /* Prepend an immediately previous CPP_DOT token.  */\n-\t      cur_token--;\n-\t      if (list->name_cap == list->name_used)\n-\t\tauto_expand_name_space (list);\n+\t  {\n+\t    int prev_dot;\n \n-\t      cur_token->val.name.len = 1;\n-\t      cur_token->val.name.text = list->namebuf + list->name_used;\n-\t      list->namebuf[list->name_used++] = '.';\n-\t    }\n-\t  else\n-\t    INIT_NAME (list, cur_token->val.name);\n+\t    cur--;\t\t/* Backup character.  */\n+\t    prev_dot = PREV_TOKEN_TYPE == CPP_DOT && IMMED_TOKEN ();\n+\t    if (prev_dot)\n+\t      cur_token--;\n+\t    INIT_TOKEN_NAME (list, cur_token);\n+\t    /* Prepend an immediately previous CPP_DOT token.  */\n+\t    if (prev_dot)\n+\t      {\n+\t\tif (list->name_cap == list->name_used)\n+\t\t  auto_expand_name_space (list);\n \n-\tcontinue_number:\n-\t  buffer->cur = cur;\n-\t  parse_number (pfile, list, &cur_token->val.name);\n-\t  cur = buffer->cur;\n+\t\tcur_token->val.name.len = 1;\n+\t\tlist->namebuf[list->name_used++] = '.';\n+\t      }\n \n-\t  PUSH_TOKEN (CPP_NUMBER); /* Number not yet interpreted.  */\n+\t  continue_number:\n+\t    cur_token->type = CPP_NUMBER; /* Before parse_number.  */\n+\t    buffer->cur = cur;\n+\t    parse_number (pfile, list, &cur_token->val.name);\n+\t    cur = buffer->cur;\n+\t    cur_token++;\n+\t  }\n \t  break;\n \n \tletter:\n@@ -2974,7 +3006,7 @@ _cpp_lex_line (pfile, list)\n \tcase 'S': case 'T': case 'U': case 'V': case 'W': case 'X':\n \tcase 'Y': case 'Z':\n \t  cur--;\t\t     /* Backup character.  */\n-\t  INIT_NAME (list, cur_token->val.name);\n+\t  INIT_TOKEN_NAME (list, cur_token);\n \t  cur_token->type = CPP_NAME; /* Identifier, macro etc.  */\n \n \tcontinue_name:\n@@ -2983,7 +3015,7 @@ _cpp_lex_line (pfile, list)\n \t  cur = buffer->cur;\n \n \t  /* Find handler for newly created / extended directive.  */\n-\t  if (IS_DIRECTIVE (list) && cur_token == &list->tokens[1])\n+\t  if (IS_DIRECTIVE () && cur_token == &list->tokens[first_token + 1])\n \t    _cpp_check_directive (list, cur_token);\n \t  cur_token++;\n \t  break;\n@@ -3005,9 +3037,10 @@ _cpp_lex_line (pfile, list)\n \n \tdo_parse_string:\n \t  /* Here c is one of ' \" or >.  */\n-\t  INIT_NAME (list, cur_token->val.name);\n+\t  INIT_TOKEN_NAME (list, cur_token);\n \t  buffer->cur = cur;\n-\t  parse_string2 (pfile, list, &cur_token->val.name, c);\n+\t  parse_string2 (pfile, list, &cur_token->val.name, c,\n+\t\t\t c == '\"' && !IS_DIRECTIVE());\n \t  cur = buffer->cur;\n \t  cur_token++;\n \t  break;\n@@ -3325,14 +3358,14 @@ _cpp_lex_line (pfile, list)\n   if (cur_token == token_limit)\n     {\n       list->tokens_used = cur_token - list->tokens;\n-      expand_token_space (list);\n+      _cpp_expand_token_space (list, 256);\n       goto expanded;\n     }\n \n   cur_token->type = CPP_EOF;\n   cur_token->flags = flags;\n \n-  if (cur_token != &list->tokens[0])\n+  if (cur_token != &list->tokens[first_token])\n     {\n       /* Next call back will get just a CPP_EOF.  */\n       buffer->cur = cur;\n@@ -3369,7 +3402,7 @@ _cpp_lex_line (pfile, list)\n static unsigned char *\n spell_token (pfile, token, buffer, whitespace)\n      cpp_reader *pfile;\t\t/* Would be nice to be rid of this...  */\n-     cpp_token *token;\n+     const cpp_token *token;\n      unsigned char *buffer;\n      int whitespace;\n {\n@@ -3438,7 +3471,7 @@ _cpp_lex_file (pfile)\n \n   init_trigraph_map ();\n   list = (cpp_toklist *) xmalloc (sizeof (cpp_toklist));\n-  _cpp_init_toklist (list);\n+  _cpp_init_toklist (list, DUMMY_TOKEN);\n \n   for (;;)\n     {"}, {"sha": "4a099398f09a5c2dc84f970a9c164a8ba912efca", "filename": "gcc/cpplib.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcpplib.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d1d9a6bd66d3d9b6cbade5609395fc618fa88f11/gcc%2Fcpplib.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.c?ref=d1d9a6bd66d3d9b6cbade5609395fc618fa88f11", "patch": "@@ -1550,7 +1550,7 @@ do_assert (pfile)\n     ERROR (\"missing token-sequence in #assert\");\n \n   pred = (struct predicate *) xmalloc (sizeof (struct predicate));\n-  _cpp_init_toklist (&pred->answer);\n+  _cpp_init_toklist (&pred->answer, NO_DUMMY_TOKEN);\n \n   if (_cpp_scan_until (pfile, &pred->answer, CPP_CLOSE_PAREN)\n       != CPP_CLOSE_PAREN)\n@@ -1626,7 +1626,7 @@ do_unassert (pfile)\n   if (type == CPP_OPEN_PAREN)\n     {\n       specific = 1;\n-      _cpp_init_toklist (&ans);\n+      _cpp_init_toklist (&ans, NO_DUMMY_TOKEN);\n \n       if (_cpp_scan_until (pfile, &ans, CPP_CLOSE_PAREN)\n \t  != CPP_CLOSE_PAREN)"}]}