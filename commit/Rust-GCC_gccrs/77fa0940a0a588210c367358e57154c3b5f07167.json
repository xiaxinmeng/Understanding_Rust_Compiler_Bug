{"sha": "77fa0940a0a588210c367358e57154c3b5f07167", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzdmYTA5NDBhMGE1ODgyMTBjMzY3MzU4ZTU3MTU0YzNiNWYwNzE2Nw==", "commit": {"author": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1992-06-20T10:51:46Z"}, "committer": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1992-06-20T10:51:46Z"}, "message": "*** empty log message ***\n\nFrom-SVN: r1223", "tree": {"sha": "76c843976b76720a8a8745346d8bf4f8568746e2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/76c843976b76720a8a8745346d8bf4f8568746e2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/77fa0940a0a588210c367358e57154c3b5f07167", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/77fa0940a0a588210c367358e57154c3b5f07167", "html_url": "https://github.com/Rust-GCC/gccrs/commit/77fa0940a0a588210c367358e57154c3b5f07167", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/77fa0940a0a588210c367358e57154c3b5f07167/comments", "author": null, "committer": null, "parents": [{"sha": "54d8c2432f1b93a4a439786a6d193a1ca0b90af6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/54d8c2432f1b93a4a439786a6d193a1ca0b90af6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/54d8c2432f1b93a4a439786a6d193a1ca0b90af6"}], "stats": {"total": 220, "additions": 147, "deletions": 73}, "files": [{"sha": "6026d4544df23b02c7a848331f82a15ea9eeb607", "filename": "gcc/combine.c", "status": "modified", "additions": 30, "deletions": 22, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=77fa0940a0a588210c367358e57154c3b5f07167", "patch": "@@ -356,6 +356,7 @@ static rtx expand_compound_operation ();\n static rtx expand_field_assignment ();\n static rtx make_extraction ();\n static int get_pos_from_mask ();\n+static rtx force_to_mode ();\n static rtx make_field_assignment ();\n static rtx make_compound_operation ();\n static rtx apply_distributive_law ();\n@@ -1295,7 +1296,8 @@ try_combine (i3, i2, i1)\n       if (undobuf.other_insn == 0\n \t  && (cc_use = find_single_use (SET_DEST (newpat), i3,\n \t\t\t\t\t&undobuf.other_insn))\n-\t  && ((compare_mode = SELECT_CC_MODE (GET_CODE (*cc_use), i2src))\n+\t  && ((compare_mode = SELECT_CC_MODE (GET_CODE (*cc_use),\n+\t\t\t\t\t      i2src, const0_rtx))\n \t      != GET_MODE (SET_DEST (newpat))))\n \t{\n \t  int regno = REGNO (SET_DEST (newpat));\n@@ -2428,6 +2430,11 @@ subst (x, from, to, in_dest, unique_copy)\n     case '<':\n       temp = simplify_relational_operation (code, op0_mode,\n \t\t\t\t\t    XEXP (x, 0), XEXP (x, 1));\n+#ifdef FLOAT_STORE_FLAG_VALUE\n+      if (temp != 0 && GET_MODE_CLASS (GET_MODE (x)) == MODE_FLOAT)\n+\ttemp = ((temp == const0_rtx) ? CONST0_RTX (GET_MODE (x))\n+\t\t: immed_real_const_1 (FLOAT_STORE_FLAG_VALUE, GET_MODE (x)));\n+#endif\n       break;\n     case 'c':\n     case '2':\n@@ -3194,7 +3201,7 @@ subst (x, from, to, in_dest, unique_copy)\n #if !defined (HAVE_cc0) && defined (EXTRA_CC_MODES)\n \t  /* If this machine has CC modes other than CCmode, check to see\n \t     if we need to use a different CC mode here.  */\n-\t  compare_mode = SELECT_CC_MODE (new_code, op0);\n+\t  compare_mode = SELECT_CC_MODE (new_code, op0, op1);\n \n \t  /* If the mode changed, we have to change SET_DEST, the mode\n \t     in the compare, and the mode in the place SET_DEST is used.\n@@ -3636,25 +3643,6 @@ subst (x, from, to, in_dest, unique_copy)\n     case ASHIFTRT:\n     case ROTATE:\n     case ROTATERT:\n-#ifdef SHIFT_COUNT_TRUNCATED\n-      /* (*shift <X> (sign_extend <Y>)) = (*shift <X> <Y>) (most machines).\n-\t True for all kinds of shifts and also for zero_extend.  */\n-      if ((GET_CODE (XEXP (x, 1)) == SIGN_EXTEND\n-\t   || GET_CODE (XEXP (x, 1)) == ZERO_EXTEND)\n-\t  && FAKE_EXTEND_SAFE_P (mode, XEXP (XEXP (x, 1), 0)))\n-\tSUBST (XEXP (x, 1),\n-\t       /* This is a perverse SUBREG, wider than its base.  */\n-\t       gen_lowpart_for_combine (mode, XEXP (XEXP (x, 1), 0)));\n-\n-      /* tege: Change (bitshifts ... (and ... mask), c)\n-\t to (bitshifts ... c) if mask just masks the bits the bitshift\n-\t insns do automatically on this machine.  */\n-      if (GET_CODE (XEXP (x, 1)) == AND\n-\t  && GET_CODE (XEXP (XEXP (x, 1), 1)) == CONST_INT\n-\t  && (~ INTVAL (XEXP (XEXP (x, 1), 1)) & GET_MODE_MASK (mode)) == 0)\n-\tSUBST (XEXP (x, 1), XEXP (XEXP (x, 1), 0));\n-#endif\n-\n       /* If this is a shift by a constant amount, simplify it.  */\n       if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n \t{\n@@ -3663,6 +3651,15 @@ subst (x, from, to, in_dest, unique_copy)\n \t  if (GET_CODE (x) != code)\n \t    goto restart;\n \t}\n+\n+#ifdef SHIFT_COUNT_TRUNCATED\n+      else if (GET_CODE (XEXP (x, 1)) != REG)\n+\tSUBST (XEXP (x, 1),\n+\t       force_to_mode (XEXP (x, 1), GET_MODE (x),\n+\t\t\t      exact_log2 (GET_MODE_BITSIZE (GET_MODE (x))),\n+\t\t\t      0));\n+#endif\n+\n       break;\n     }\n \n@@ -4011,6 +4008,15 @@ make_extraction (mode, inner, pos, pos_rtx, len,\n \t  MEM_VOLATILE_P (new) = MEM_VOLATILE_P (inner);\n \t  MEM_IN_STRUCT_P (new) = MEM_IN_STRUCT_P (inner);\n \t}\n+      else if (GET_MODE (inner) == REG)\n+\t/* We can't call gen_lowpart_for_combine here since we always want\n+\t   a SUBREG and it would sometimes return a new hard register.  */\n+\tnew = gen_rtx (SUBREG, tmode, inner,\n+\t\t       (WORDS_BIG_ENDIAN\n+\t\t\t&& GET_MODE_SIZE (is_mode) > UNITS_PER_WORD)\n+\t\t       ? ((GET_MODE_SIZE (is_mode) - GET_MODE_SIZE (tmode)\n+\t\t\t   / UNITS_PER_WORD))\n+\t\t       : 0);\n       else\n \tnew = gen_lowpart_for_combine (tmode, inner);\n \n@@ -4019,7 +4025,9 @@ make_extraction (mode, inner, pos, pos_rtx, len,\n \n       if (in_dest)\n \treturn (GET_CODE (new) == MEM ? new\n-\t\t: gen_rtx_combine (STRICT_LOW_PART, VOIDmode, new));\n+\t\t: (GET_CODE (new) != SUBREG\n+\t\t   ? gen_rtx (CLOBBER, tmode, const0_rtx)\n+\t\t   : gen_rtx_combine (STRICT_LOW_PART, VOIDmode, new)));\n \n       /* Otherwise, sign- or zero-extend unless we already are in the\n \t proper mode.  */"}, {"sha": "bf59f5a14aa0463912a3939cb1677a799105f4b6", "filename": "gcc/config/romp/romp.md", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fconfig%2Fromp%2Fromp.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fconfig%2Fromp%2Fromp.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fromp%2Fromp.md?ref=77fa0940a0a588210c367358e57154c3b5f07167", "patch": "@@ -1602,7 +1602,7 @@\n (define_insn \"ashrsi3\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r,r\")\n \t(ashiftrt:SI (match_operand:SI 1 \"register_operand\" \"0,0\")\n-\t\t     (match_operand:QI 2 \"reg_or_cint_operand\" \"r,n\")))]\n+\t\t     (match_operand:SI 2 \"reg_or_cint_operand\" \"r,n\")))]\n   \"\"\n   \"@\n    sar %0,%2\n@@ -1612,7 +1612,7 @@\n (define_insn \"lshrsi3\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r,r\")\n \t(lshiftrt:SI (match_operand:SI 1 \"register_operand\" \"0,0\")\n-\t\t     (match_operand:QI 2 \"reg_or_cint_operand\" \"r,n\")))]\n+\t\t     (match_operand:SI 2 \"reg_or_cint_operand\" \"r,n\")))]\n   \"\"\n   \"@\n    sr %0,%2\n@@ -1631,7 +1631,7 @@\n (define_insn \"ashlsi3\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r,r\")\n \t(ashift:SI (match_operand:SI 1 \"register_operand\" \"0,0\")\n-\t\t   (match_operand:QI 2 \"reg_or_cint_operand\" \"r,n\")))]\n+\t\t   (match_operand:SI 2 \"reg_or_cint_operand\" \"r,n\")))]\n   \"\"\n   \"@\n    sl %0,%2"}, {"sha": "abbdf5b17b093f375f5541dd7f73acc005b9949f", "filename": "gcc/config/rs6000/rs6000.md", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fconfig%2Frs6000%2Frs6000.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fconfig%2Frs6000%2Frs6000.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.md?ref=77fa0940a0a588210c367358e57154c3b5f07167", "patch": "@@ -2083,6 +2083,26 @@\n    mt%0 %1\"\n   [(set_attr \"type\" \"*,load,*,*,*,*,*,mtlr\")])\n \n+;; Split a load of a large constant into the appropriate two-insn\n+;; sequence.\n+\n+(define_split\n+  [(set (match_operand:SI 0 \"gpc_reg_operand\" \"\")\n+\t(match_operand:SI 1 \"const_int_operand\" \"\"))]\n+  \"(unsigned) (INTVAL (operands[1]) + 0x8000) >= 0x10000\n+   && (INTVAL (operands[1]) & 0xffff) != 0\"\n+  [(set (match_dup 0)\n+\t(match_dup 2))\n+   (set (match_dup 0)\n+\t(ior:SI (match_dup 0)\n+\t\t(match_dup 3)))]\n+  \"\n+{\n+  operands[2] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t INTVAL (operands[1]) & 0xffff0000);\n+  operands[3] = gen_rtx (CONST_INT, VOIDmode, INTVAL (operands[1]) & 0xffff);\n+}\")\n+\n (define_insn \"\"\n   [(set (match_operand:CC 2 \"cc_reg_operand\" \"=x\")\n \t(compare:CC (match_operand:SI 1 \"gpc_reg_operand\" \"r\")"}, {"sha": "e945768f1fdf396ba1fccc031c1dd7c560c5c00d", "filename": "gcc/cse.c", "status": "modified", "additions": 37, "deletions": 30, "changes": 67, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=77fa0940a0a588210c367358e57154c3b5f07167", "patch": "@@ -2379,7 +2379,7 @@ canon_reg (x, insn)\n \t      && (((REGNO (new) < FIRST_PSEUDO_REGISTER)\n \t\t   != (REGNO (XEXP (x, i)) < FIRST_PSEUDO_REGISTER))\n \t\t  || (insn != 0 && insn_n_dups[recog_memoized (insn)] > 0)))\n-\t    validate_change (insn, &XEXP (x, i), new, 0);\n+\t    validate_change (insn, &XEXP (x, i), new, 1);\n \t  else\n \t    XEXP (x, i) = new;\n \t}\n@@ -5359,6 +5359,7 @@ cse_insn (insn, in_libcall_block)\n       else if (GET_CODE (SET_SRC (x)) == CALL)\n \t{\n \t  canon_reg (SET_SRC (x), insn);\n+\t  apply_change_group ();\n \t  fold_rtx (SET_SRC (x), insn);\n \t  invalidate (SET_DEST (x));\n \t}\n@@ -5400,6 +5401,7 @@ cse_insn (insn, in_libcall_block)\n \t      if (GET_CODE (SET_SRC (y)) == CALL)\n \t\t{\n \t\t  canon_reg (SET_SRC (y), insn);\n+\t\t  apply_change_group ();\n \t\t  fold_rtx (SET_SRC (y), insn);\n \t\t  invalidate (SET_DEST (y));\n \t\t}\n@@ -5428,6 +5430,7 @@ cse_insn (insn, in_libcall_block)\n \t  else if (GET_CODE (y) == CALL)\n \t    {\n \t      canon_reg (y, insn);\n+\t      apply_change_group ();\n \t      fold_rtx (y, insn);\n \t    }\n \t}\n@@ -5449,6 +5452,7 @@ cse_insn (insn, in_libcall_block)\n   else if (GET_CODE (x) == CALL)\n     {\n       canon_reg (x, insn);\n+      apply_change_group ();\n       fold_rtx (x, insn);\n     }\n \n@@ -5467,40 +5471,30 @@ cse_insn (insn, in_libcall_block)\n      we don't break the duplicate nature of the pattern.  So we will replace\n      both operands at the same time.  Otherwise, we would fail to find an\n      equivalent substitution in the loop calling validate_change below.\n-     (We also speed up that loop when a canonicalization was done since\n-     recog_memoized need not be called for just a canonicalization unless\n-     a pseudo register is being replaced by a hard reg of vice versa.)\n \n      We used to suppress canonicalization of DEST if it appears in SRC,\n-     but we don't do this any more.\n-\n-     ??? The way this code is written now, if we have a MATCH_DUP between\n-     two operands that are pseudos and we would want to canonicalize them\n-     to a hard register, we won't do that.  The only time this would happen\n-     is if the hard reg was a fixed register, and this should be rare.\n-\n-     ??? This won't work if there is a MATCH_DUP between an input and an\n-     output, but these never worked and must be declared invalid.  */\n+     but we don't do this any more.  */\n \n   for (i = 0; i < n_sets; i++)\n     {\n       rtx dest = SET_DEST (sets[i].rtl);\n       rtx src = SET_SRC (sets[i].rtl);\n       rtx new = canon_reg (src, insn);\n \n-      if (GET_CODE (new) == REG && GET_CODE (src) == REG\n-\t  && ((REGNO (new) < FIRST_PSEUDO_REGISTER)\n-\t      != (REGNO (src) < FIRST_PSEUDO_REGISTER)))\n-\tvalidate_change (insn, &SET_SRC (sets[i].rtl), new, 0);\n+      if ((GET_CODE (new) == REG && GET_CODE (src) == REG\n+\t   && ((REGNO (new) < FIRST_PSEUDO_REGISTER)\n+\t       != (REGNO (src) < FIRST_PSEUDO_REGISTER)))\n+\t  || insn_n_dups[recog_memoized (insn)] > 0)\n+\tvalidate_change (insn, &SET_SRC (sets[i].rtl), new, 1);\n       else\n \tSET_SRC (sets[i].rtl) = new;\n \n       if (GET_CODE (dest) == ZERO_EXTRACT || GET_CODE (dest) == SIGN_EXTRACT)\n \t{\n \t  validate_change (insn, &XEXP (dest, 1),\n-\t\t\t   canon_reg (XEXP (dest, 1), insn), 0);\n+\t\t\t   canon_reg (XEXP (dest, 1), insn), 1);\n \t  validate_change (insn, &XEXP (dest, 2),\n-\t\t\t   canon_reg (XEXP (dest, 2), insn), 0);\n+\t\t\t   canon_reg (XEXP (dest, 2), insn), 1);\n \t}\n \n       while (GET_CODE (dest) == SUBREG || GET_CODE (dest) == STRICT_LOW_PART\n@@ -5512,6 +5506,14 @@ cse_insn (insn, in_libcall_block)\n \tcanon_reg (dest, insn);\n     }\n \n+  /* Now that we have done all the replacements, we can apply the change\n+     group and see if they all work.  Note that this will cause some\n+     canonicalizations that would have worked individually not to be applied\n+     because some other canonicalization didn't work, but this should not\n+     occur often.  */\n+\n+  apply_change_group ();\n+\n   /* Set sets[i].src_elt to the class each source belongs to.\n      Detect assignments from or to volatile things\n      and set set[i] to zero so they will be ignored\n@@ -6294,11 +6296,16 @@ cse_insn (insn, in_libcall_block)\n       sets[i].src_elt = src_eqv_elt;\n \n   invalidate_from_clobbers (&writes_memory, x);\n-  /* Memory, and some registers, are invalidate by subroutine calls.  */\n+\n+  /* Some registers are invalidated by subroutine calls.  Memory is \n+     invalidated by non-constant calls.  */\n+\n   if (GET_CODE (insn) == CALL_INSN)\n     {\n       static struct write_data everything = {0, 1, 1, 1};\n-      invalidate_memory (&everything);\n+\n+      if (! CONST_CALL_P (insn))\n+\tinvalidate_memory (&everything);\n       invalidate_for_call ();\n     }\n \n@@ -7672,7 +7679,7 @@ delete_dead_from_cse (insns, nreg)\n      int nreg;\n {\n   int *counts = (int *) alloca (nreg * sizeof (int));\n-  rtx insn;\n+  rtx insn, prev;\n   rtx tem;\n   int i;\n   int in_libcall = 0;\n@@ -7685,14 +7692,16 @@ delete_dead_from_cse (insns, nreg)\n   /* Go from the last insn to the first and delete insns that only set unused\n      registers or copy a register to itself.  As we delete an insn, remove\n      usage counts for registers it uses.  */\n-  for (insn = prev_real_insn (get_last_insn ());\n-       insn; insn = prev_real_insn (insn))\n+  for (insn = prev_real_insn (get_last_insn ()); insn; insn = prev)\n     {\n       int live_insn = 0;\n \n+      prev = prev_real_insn (insn);\n+\n       /* Don't delete any insns that are part of a libcall block.\n-\t Flow or loop might get confused if we did that.  */\n-      if (find_reg_note (insn, REG_LIBCALL, 0))\n+\t Flow or loop might get confused if we did that.  Remember\n+\t that we are scanning backwards.  */\n+      if (find_reg_note (insn, REG_RETVAL, 0))\n \tin_libcall = 1;\n \n       if (in_libcall)\n@@ -7754,12 +7763,10 @@ delete_dead_from_cse (insns, nreg)\n       if (! live_insn)\n \t{\n \t  count_reg_usage (insn, counts, -1);\n-\t  PUT_CODE (insn, NOTE);\n-\t  NOTE_SOURCE_FILE (insn) = 0;\n-\t  NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;\n+\t  delete_insn (insn);\n \t}\n \n-      if (find_reg_note (insn, REG_RETVAL, 0))\n+      if (find_reg_note (insn, REG_LIBCALL, 0))\n \tin_libcall = 0;\n     }\n }"}, {"sha": "4cdbd76cd9bd8bc1a77c662dcc05625923fa2f44", "filename": "gcc/expr.c", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=77fa0940a0a588210c367358e57154c3b5f07167", "patch": "@@ -6318,9 +6318,11 @@ compare_from_rtx (op0, op1, code, unsignedp, mode, size, align)\n \n   /* If this is a signed equality comparison, we can do it as an\n      unsigned comparison since zero-extension is cheaper than sign\n-     extension and comparisons with zero are done as unsigned.  If we\n-     are comparing against a constant, we must convert it to what it\n-     would look like unsigned.  */\n+     extension and comparisons with zero are done as unsigned.  This is\n+     the case even on machines that can do fast sign extension, since\n+     zero-extension is easier to combinen with other operations than\n+     sign-extension is.  If we are comparing against a constant, we must\n+     convert it to what it would look like unsigned.  */\n   if ((code == EQ || code == NE) && ! unsignedp\n       && GET_MODE_BITSIZE (GET_MODE (op0)) <= HOST_BITS_PER_INT)\n     {"}, {"sha": "16d1dab63bd238351260b550757cf576a859f298", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 22, "deletions": 9, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=77fa0940a0a588210c367358e57154c3b5f07167", "patch": "@@ -952,9 +952,9 @@ fixup_unsigned_type (type)\n    VOLATILEP is true or SLOW_BYTE_ACCESS is false, we return the smallest\n    mode meeting these conditions.\n \n-   Otherwise (VOLATILEP is false and SLOW_BYTE_ACCESS is true), if a mode\n-   whose size is UNITS_PER_WORD meets all the conditions, it is returned\n-   instead.  */\n+   Otherwise (VOLATILEP is false and SLOW_BYTE_ACCESS is true), we return\n+   the largest mode (but a mode no wider than UNITS_PER_WORD) that meets\n+   all the conditions.  */\n \n enum machine_mode\n get_best_mode (bitsize, bitpos, align, largest_mode, volatilep)\n@@ -987,12 +987,25 @@ get_best_mode (bitsize, bitpos, align, largest_mode, volatilep)\n       || (largest_mode != VOIDmode && unit > GET_MODE_BITSIZE (largest_mode)))\n     return VOIDmode;\n \n-  if (SLOW_BYTE_ACCESS\n-      && ! volatilep\n-      && BITS_PER_WORD <= MIN (align, BIGGEST_ALIGNMENT)\n-      && (largest_mode == VOIDmode\n-\t  || BITS_PER_WORD <= GET_MODE_BITSIZE (largest_mode)))\n-    return word_mode;\n+  if (SLOW_BYTE_ACCESS && ! volatilep)\n+    {\n+      enum machine_mode wide_mode = VOIDmode, tmode;\n+\n+      for (tmode = GET_CLASS_NARROWEST_MODE (MODE_INT); tmode != VOIDmode;\n+\t   tmode = GET_MODE_WIDER_MODE (tmode))\n+\t{\n+\t  unit = GET_MODE_BITSIZE (tmode);\n+\t  if (bitpos / unit == (bitpos + bitsize - 1) / unit\n+\t      && unit <= BITS_PER_WORD\n+\t      && unit <= MIN (align, BIGGEST_ALIGNMENT)\n+\t      && (largest_mode == VOIDmode\n+\t\t  || unit <= GET_MODE_BITSIZE (largest_mode)))\n+\t    wide_mode = tmode;\n+\t}\n+\n+      if (wide_mode != VOIDmode)\n+\treturn wide_mode;\n+    }\n \n   return mode;\n }"}, {"sha": "5c3f7e18a3644bf9d77f39621db4705e184c2bac", "filename": "gcc/varasm.c", "status": "modified", "additions": 30, "deletions": 6, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fvarasm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/77fa0940a0a588210c367358e57154c3b5f07167/gcc%2Fvarasm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvarasm.c?ref=77fa0940a0a588210c367358e57154c3b5f07167", "patch": "@@ -1541,7 +1541,8 @@ const_hash (exp)\n \t       & ((1 << HASHBITS) - 1)) % MAX_HASH_TABLE;\n \n       for (link = CONSTRUCTOR_ELTS (exp); link; link = TREE_CHAIN (link))\n-\thi = (hi * 603 + const_hash (TREE_VALUE (link))) % MAX_HASH_TABLE;\n+\tif (TREE_VALUE (link))\n+\t  hi = (hi * 603 + const_hash (TREE_VALUE (link))) % MAX_HASH_TABLE;\n \n       return hi;\n     }\n@@ -1677,8 +1678,22 @@ compare_constant_1 (exp, p)\n \t}\n \n       for (link = CONSTRUCTOR_ELTS (exp); link; link = TREE_CHAIN (link))\n-\tif ((p = compare_constant_1 (TREE_VALUE (link), p)) == 0)\n-\t  return 0;\n+\t{\n+\t  if (TREE_VALUE (link))\n+\t    {\n+\t      if ((p = compare_constant_1 (TREE_VALUE (link), p)) == 0)\n+\t\treturn 0;\n+\t    }\n+\t  else\n+\t    {\n+\t      tree zero = 0;\n+\n+\t      if (bcmp (&zero, p, sizeof zero))\n+\t\treturn 0;\n+\t      p += sizeof zero;\n+\t    }\n+\t}\n+\n       return p;\n     }\n   else if (code == ADDR_EXPR)\n@@ -1798,7 +1813,17 @@ record_constant_1 (exp)\n \t}\n \n       for (link = CONSTRUCTOR_ELTS (exp); link; link = TREE_CHAIN (link))\n-\trecord_constant_1 (TREE_VALUE (link));\n+\t{\n+\t  if (TREE_VALUE (link))\n+\t    record_constant_1 (TREE_VALUE (link));\n+\t  else\n+\t    {\n+\t      tree zero = 0;\n+\n+\t      obstack_grow (&permanent_obstack, (char *) &zero, sizeof zero);\n+\t    }\n+\t}\n+\n       return;\n     }\n   else if (code == ADDR_EXPR)\n@@ -2520,8 +2545,7 @@ output_constant (exp, size)\n \n   /* Allow a constructor with no elements for any data type.\n      This means to fill the space with zeros.  */\n-  if (TREE_CODE (exp) == CONSTRUCTOR\n-      && TREE_OPERAND (exp, 1) == 0)\n+  if (TREE_CODE (exp) == CONSTRUCTOR && CONSTRUCTOR_ELTS (exp) == 0)\n     {\n       assemble_zeros (size);\n       return;"}]}