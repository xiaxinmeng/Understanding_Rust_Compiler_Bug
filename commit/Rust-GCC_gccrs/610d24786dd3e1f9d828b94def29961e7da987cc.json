{"sha": "610d24786dd3e1f9d828b94def29961e7da987cc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NjEwZDI0Nzg2ZGQzZTFmOWQ4MjhiOTRkZWYyOTk2MWU3ZGE5ODdjYw==", "commit": {"author": {"name": "Steven Bosscher", "email": "steven@gcc.gnu.org", "date": "2005-06-04T17:07:57Z"}, "committer": {"name": "Steven Bosscher", "email": "steven@gcc.gnu.org", "date": "2005-06-04T17:07:57Z"}, "message": "lcm.c: Move all mode-switching related functions from here...\n\n\t* lcm.c: Move all mode-switching related functions from here...\n\t* mode-switching.c: ...to this new file.\n\t* doc/passes.texi: Update accordingly.\n\n\t* basic-block.h (label_value_list): Remove extern decl.\n\t* cfgrtl.c (label_value_list): Remove.\n\t(can_delete_label_p): Don't look at it.\n\t* cfgcleanup.c (cleanup_cfg): Don't free it.\n\n\t* common.opt: Don't refer to non-existing flag_alias_check.\n\nFrom-SVN: r100591", "tree": {"sha": "60b6a1a40cafd587e8f0365563226295e3d92044", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/60b6a1a40cafd587e8f0365563226295e3d92044"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/610d24786dd3e1f9d828b94def29961e7da987cc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/610d24786dd3e1f9d828b94def29961e7da987cc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/610d24786dd3e1f9d828b94def29961e7da987cc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/610d24786dd3e1f9d828b94def29961e7da987cc/comments", "author": null, "committer": null, "parents": [{"sha": "4736115ed43eb30601d7860298a82251077c2cf3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4736115ed43eb30601d7860298a82251077c2cf3", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4736115ed43eb30601d7860298a82251077c2cf3"}], "stats": {"total": 1422, "additions": 732, "deletions": 690}, "files": [{"sha": "ad10c835cc3a8ecb6203b839ed8e2417db97cce5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 14, "deletions": 1, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -1,3 +1,16 @@\n+2005-06-04  Steven Bosscher  <stevenb@suse.de>\n+\n+\t* lcm.c: Move all mode-switching related functions from here...\n+\t* mode-switching.c: ...to this new file.\n+\t* doc/passes.texi: Update accordingly.\n+\n+\t* basic-block.h (label_value_list): Remove extern decl.\n+\t* cfgrtl.c (label_value_list): Remove.\n+\t(can_delete_label_p): Don't look at it.\n+\t* cfgcleanup.c (cleanup_cfg): Don't free it.\n+\n+\t* common.opt: Don't refer to non-existing flag_alias_check.\n+\n 2005-06-04  David Edelsohn  <edelsohn@gnu.org>\n \n \t* config/rs6000/aix52.h (ASM_CPU_SPEC): Add power5.\n@@ -62,7 +75,7 @@\n 2005-06-03  Eric Christopher  <echristo@redhat.com>\n \n \t* config/mips/mips.opt: Add RejectNegative to divide-breaks and\n-        divide-traps.\n+\tdivide-traps.\n \n 2005-06-03  Jan Hubicka  <jh@suse.cz>\n "}, {"sha": "9be640ebf26e3488710f9bdd6c39e319b4dca7a0", "filename": "gcc/Makefile.in", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -949,7 +949,7 @@ OBJS-common = \\\n  haifa-sched.o hooks.o ifcvt.o insn-attrtab.o insn-emit.o insn-modes.o\t   \\\n  insn-extract.o insn-opinit.o insn-output.o insn-peep.o insn-recog.o\t   \\\n  integrate.o intl.o jump.o  langhooks.o lcm.o lists.o local-alloc.o  \t   \\\n- loop.o modulo-sched.o optabs.o options.o opts.o\t\t\t   \\\n+ loop.o mode-switching.o modulo-sched.o optabs.o options.o opts.o\t   \\\n  params.o postreload.o postreload-gcse.o predict.o\t\t\t   \\\n  insn-preds.o pointer-set.o postreload.o\t\t\t\t   \\\n  print-rtl.o print-tree.o profile.o value-prof.o var-tracking.o\t\t   \\\n@@ -2099,6 +2099,9 @@ resource.o : resource.c $(CONFIG_H) $(RTL_H) hard-reg-set.h $(SYSTEM_H) \\\n lcm.o : lcm.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(REGS_H) \\\n    hard-reg-set.h $(FLAGS_H) real.h insn-config.h $(INSN_ATTR_H) $(RECOG_H) \\\n    $(BASIC_BLOCK_H) $(TM_P_H) function.h output.h\n+mode-switching.o : mode-switching.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n+   $(RTL_H) $(REGS_H) hard-reg-set.h $(FLAGS_H) real.h insn-config.h \\\n+   $(INSN_ATTR_H) $(RECOG_H) $(BASIC_BLOCK_H) $(TM_P_H) function.h output.h\n tree-ssa-dce.o : tree-ssa-dce.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) \\\n     $(RTL_H) $(TM_P_H) $(TREE_FLOW_H) $(DIAGNOSTIC_H) $(TIMEVAR_H) $(TM_H) \\\n     coretypes.h $(TREE_DUMP_H) tree-pass.h $(FLAGS_H) $(BASIC_BLOCK_H) \\"}, {"sha": "2979e01a3ea825b4f002fb4512f398530e8c8a2c", "filename": "gcc/basic-block.h", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fbasic-block.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fbasic-block.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbasic-block.h?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -446,10 +446,6 @@ extern bool rediscover_loops_after_threading;\n #define FOR_ALL_BB_FN(BB, FN) \\\n   for (BB = ENTRY_BLOCK_PTR_FOR_FUNCTION (FN); BB; BB = BB->next_bb)\n \n-/* Special labels found during CFG build.  */\n-\n-extern GTY(()) rtx label_value_list;\n-\n extern bitmap_obstack reg_obstack;\n \n /* Indexed by n, gives number of basic block that  (REG n) is used in."}, {"sha": "98c82452ca316926b913a90df4c1c78fb135d02a", "filename": "gcc/cfgcleanup.c", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fcfgcleanup.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fcfgcleanup.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgcleanup.c?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -2132,8 +2132,6 @@ cleanup_cfg (int mode)\n       delete_dead_jumptables ();\n     }\n \n-  /* Kill the data we won't maintain.  */\n-  free_EXPR_LIST_list (&label_value_list);\n   timevar_pop (TV_CLEANUP_CFG);\n \n   return changed;"}, {"sha": "2571d4d65dcf8a79b07ffbc0f38a2980e72b2505", "filename": "gcc/cfgrtl.c", "status": "modified", "additions": 1, "deletions": 7, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fcfgrtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fcfgrtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgrtl.c?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -59,11 +59,6 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"target.h\"\n #include \"cfgloop.h\"\n \n-/* The labels mentioned in non-jump rtl.  Valid during find_basic_blocks.  */\n-/* ??? Should probably be using LABEL_NUSES instead.  It would take a\n-   bit of surgery to be able to use or co-opt the routines in jump.  */\n-rtx label_value_list;\n-\n static int can_delete_note_p (rtx);\n static int can_delete_label_p (rtx);\n static void commit_one_edge_insertion (edge, int);\n@@ -103,8 +98,7 @@ can_delete_label_p (rtx label)\n   return (!LABEL_PRESERVE_P (label)\n \t  /* User declared labels must be preserved.  */\n \t  && LABEL_NAME (label) == 0\n-\t  && !in_expr_list_p (forced_labels, label)\n-\t  && !in_expr_list_p (label_value_list, label));\n+\t  && !in_expr_list_p (forced_labels, label));\n }\n \n /* Delete INSN by patching it out.  Return the next insn.  */"}, {"sha": "f54eabce8a14bb1bd02e884db865f845156cc741", "filename": "gcc/common.opt", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fcommon.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fcommon.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcommon.opt?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -234,7 +234,6 @@ Common RejectNegative Joined UInteger\n ;   global variables.\n ; 2 if pointer arguments may not alias each other and may not\n ;   alias global variables.  True in Fortran.\n-;   The value is ignored if flag_alias_check is 0.\n fargument-alias\n Common Report Var(flag_argument_noalias,0)\n Specify that arguments may alias each other and globals"}, {"sha": "e2fcc7a5d022bbef2ba7c3f09f14315b37d06e59", "filename": "gcc/doc/passes.texi", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fdoc%2Fpasses.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fdoc%2Fpasses.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fpasses.texi?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -639,7 +639,8 @@ The pass is located in @file{regmove.c}.\n This pass looks for instructions that require the processor to be in a\n specific ``mode'' and minimizes the number of mode changes required to\n satisfy all users.  What these modes are, and what they apply to are\n-completely target-specific.  The source is located in @file{lcm.c}.\n+completely target-specific.\n+The source is located in @file{mode-switching.c}.\n \n @cindex modulo scheduling\n @cindex sms, swing, software pipelining"}, {"sha": "330068e7d61663948ac111247864c6d605991165", "filename": "gcc/lcm.c", "status": "modified", "additions": 0, "deletions": 673, "changes": 673, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Flcm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Flcm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flcm.c?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -809,676 +809,3 @@ pre_edge_rev_lcm (FILE *file ATTRIBUTE_UNUSED, int n_exprs, sbitmap *transp,\n   return edge_list;\n }\n \n-/* Mode switching:\n-\n-   The algorithm for setting the modes consists of scanning the insn list\n-   and finding all the insns which require a specific mode.  Each insn gets\n-   a unique struct seginfo element.  These structures are inserted into a list\n-   for each basic block.  For each entity, there is an array of bb_info over\n-   the flow graph basic blocks (local var 'bb_info'), and contains a list\n-   of all insns within that basic block, in the order they are encountered.\n-\n-   For each entity, any basic block WITHOUT any insns requiring a specific\n-   mode are given a single entry, without a mode.  (Each basic block\n-   in the flow graph must have at least one entry in the segment table.)\n-\n-   The LCM algorithm is then run over the flow graph to determine where to\n-   place the sets to the highest-priority value in respect of first the first\n-   insn in any one block.  Any adjustments required to the transparency\n-   vectors are made, then the next iteration starts for the next-lower\n-   priority mode, till for each entity all modes are exhausted.\n-\n-   More details are located in the code for optimize_mode_switching().  */\n-\n-/* This structure contains the information for each insn which requires\n-   either single or double mode to be set.\n-   MODE is the mode this insn must be executed in.\n-   INSN_PTR is the insn to be executed (may be the note that marks the\n-   beginning of a basic block).\n-   BBNUM is the flow graph basic block this insn occurs in.\n-   NEXT is the next insn in the same basic block.  */\n-struct seginfo\n-{\n-  int mode;\n-  rtx insn_ptr;\n-  int bbnum;\n-  struct seginfo *next;\n-  HARD_REG_SET regs_live;\n-};\n-\n-struct bb_info\n-{\n-  struct seginfo *seginfo;\n-  int computing;\n-};\n-\n-/* These bitmaps are used for the LCM algorithm.  */\n-\n-#ifdef OPTIMIZE_MODE_SWITCHING\n-static sbitmap *antic;\n-static sbitmap *transp;\n-static sbitmap *comp;\n-\n-static struct seginfo * new_seginfo (int, rtx, int, HARD_REG_SET);\n-static void add_seginfo (struct bb_info *, struct seginfo *);\n-static void reg_dies (rtx, HARD_REG_SET);\n-static void reg_becomes_live (rtx, rtx, void *);\n-static void make_preds_opaque (basic_block, int);\n-#endif\n-\f\n-#ifdef OPTIMIZE_MODE_SWITCHING\n-\n-/* This function will allocate a new BBINFO structure, initialized\n-   with the MODE, INSN, and basic block BB parameters.  */\n-\n-static struct seginfo *\n-new_seginfo (int mode, rtx insn, int bb, HARD_REG_SET regs_live)\n-{\n-  struct seginfo *ptr;\n-  ptr = xmalloc (sizeof (struct seginfo));\n-  ptr->mode = mode;\n-  ptr->insn_ptr = insn;\n-  ptr->bbnum = bb;\n-  ptr->next = NULL;\n-  COPY_HARD_REG_SET (ptr->regs_live, regs_live);\n-  return ptr;\n-}\n-\n-/* Add a seginfo element to the end of a list.\n-   HEAD is a pointer to the list beginning.\n-   INFO is the structure to be linked in.  */\n-\n-static void\n-add_seginfo (struct bb_info *head, struct seginfo *info)\n-{\n-  struct seginfo *ptr;\n-\n-  if (head->seginfo == NULL)\n-    head->seginfo = info;\n-  else\n-    {\n-      ptr = head->seginfo;\n-      while (ptr->next != NULL)\n-\tptr = ptr->next;\n-      ptr->next = info;\n-    }\n-}\n-\n-/* Make all predecessors of basic block B opaque, recursively, till we hit\n-   some that are already non-transparent, or an edge where aux is set; that\n-   denotes that a mode set is to be done on that edge.\n-   J is the bit number in the bitmaps that corresponds to the entity that\n-   we are currently handling mode-switching for.  */\n-\n-static void\n-make_preds_opaque (basic_block b, int j)\n-{\n-  edge e;\n-  edge_iterator ei;\n-\n-  FOR_EACH_EDGE (e, ei, b->preds)\n-    {\n-      basic_block pb = e->src;\n-\n-      if (e->aux || ! TEST_BIT (transp[pb->index], j))\n-\tcontinue;\n-\n-      RESET_BIT (transp[pb->index], j);\n-      make_preds_opaque (pb, j);\n-    }\n-}\n-\n-/* Record in LIVE that register REG died.  */\n-\n-static void\n-reg_dies (rtx reg, HARD_REG_SET live)\n-{\n-  int regno, nregs;\n-\n-  if (!REG_P (reg))\n-    return;\n-\n-  regno = REGNO (reg);\n-  if (regno < FIRST_PSEUDO_REGISTER)\n-    for (nregs = hard_regno_nregs[regno][GET_MODE (reg)] - 1; nregs >= 0;\n-\t nregs--)\n-      CLEAR_HARD_REG_BIT (live, regno + nregs);\n-}\n-\n-/* Record in LIVE that register REG became live.\n-   This is called via note_stores.  */\n-\n-static void\n-reg_becomes_live (rtx reg, rtx setter ATTRIBUTE_UNUSED, void *live)\n-{\n-  int regno, nregs;\n-\n-  if (GET_CODE (reg) == SUBREG)\n-    reg = SUBREG_REG (reg);\n-\n-  if (!REG_P (reg))\n-    return;\n-\n-  regno = REGNO (reg);\n-  if (regno < FIRST_PSEUDO_REGISTER)\n-    for (nregs = hard_regno_nregs[regno][GET_MODE (reg)] - 1; nregs >= 0;\n-\t nregs--)\n-      SET_HARD_REG_BIT (* (HARD_REG_SET *) live, regno + nregs);\n-}\n-\n-/* Make sure if MODE_ENTRY is defined the MODE_EXIT is defined\n-   and vice versa.  */\n-#if defined (MODE_ENTRY) != defined (MODE_EXIT)\n- #error \"Both MODE_ENTRY and MODE_EXIT must be defined\"\n-#endif\n-\n-#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n-/* Split the fallthrough edge to the exit block, so that we can note\n-   that there NORMAL_MODE is required.  Return the new block if it's\n-   inserted before the exit block.  Otherwise return null.  */\n-\n-static basic_block\n-create_pre_exit (int n_entities, int *entity_map, const int *num_modes)\n-{\n-  edge eg;\n-  edge_iterator ei;\n-  basic_block pre_exit;\n-\n-  /* The only non-call predecessor at this stage is a block with a\n-     fallthrough edge; there can be at most one, but there could be\n-     none at all, e.g. when exit is called.  */\n-  pre_exit = 0;\n-  FOR_EACH_EDGE (eg, ei, EXIT_BLOCK_PTR->preds)\n-    if (eg->flags & EDGE_FALLTHRU)\n-      {\n-\tbasic_block src_bb = eg->src;\n-\tregset live_at_end = src_bb->global_live_at_end;\n-\trtx last_insn, ret_reg;\n-\n-\tgcc_assert (!pre_exit);\n-\t/* If this function returns a value at the end, we have to\n-\t   insert the final mode switch before the return value copy\n-\t   to its hard register.  */\n-\tif (EDGE_COUNT (EXIT_BLOCK_PTR->preds) == 1\n-\t    && NONJUMP_INSN_P ((last_insn = BB_END (src_bb)))\n-\t    && GET_CODE (PATTERN (last_insn)) == USE\n-\t    && GET_CODE ((ret_reg = XEXP (PATTERN (last_insn), 0))) == REG)\n-\t  {\n-\t    int ret_start = REGNO (ret_reg);\n-\t    int nregs = hard_regno_nregs[ret_start][GET_MODE (ret_reg)];\n-\t    int ret_end = ret_start + nregs;\n-\t    int short_block = 0;\n-\t    int maybe_builtin_apply = 0;\n-\t    int forced_late_switch = 0;\n-\t    rtx before_return_copy;\n-\n-\t    do\n-\t      {\n-\t\trtx return_copy = PREV_INSN (last_insn);\n-\t\trtx return_copy_pat, copy_reg;\n-\t\tint copy_start, copy_num;\n-\t\tint j;\n-\n-\t\tif (INSN_P (return_copy))\n-\t\t  {\n-\t\t    if (GET_CODE (PATTERN (return_copy)) == USE\n-\t\t\t&& GET_CODE (XEXP (PATTERN (return_copy), 0)) == REG\n-\t\t\t&& (FUNCTION_VALUE_REGNO_P\n-\t\t\t    (REGNO (XEXP (PATTERN (return_copy), 0)))))\n-\t\t      {\n-\t\t\tmaybe_builtin_apply = 1;\n-\t\t\tlast_insn = return_copy;\n-\t\t\tcontinue;\n-\t\t      }\n-\t\t    /* If the return register is not (in its entirety)\n-\t\t       likely spilled, the return copy might be\n-\t\t       partially or completely optimized away.  */\n-\t\t    return_copy_pat = single_set (return_copy);\n-\t\t    if (!return_copy_pat)\n-\t\t      {\n-\t\t\treturn_copy_pat = PATTERN (return_copy);\n-\t\t\tif (GET_CODE (return_copy_pat) != CLOBBER)\n-\t\t\t  break;\n-\t\t      }\n-\t\t    copy_reg = SET_DEST (return_copy_pat);\n-\t\t    if (GET_CODE (copy_reg) == REG)\n-\t\t      copy_start = REGNO (copy_reg);\n-\t\t    else if (GET_CODE (copy_reg) == SUBREG\n-\t\t\t     && GET_CODE (SUBREG_REG (copy_reg)) == REG)\n-\t\t      copy_start = REGNO (SUBREG_REG (copy_reg));\n-\t\t    else\n-\t\t      break;\n-\t\t    if (copy_start >= FIRST_PSEUDO_REGISTER)\n-\t\t      break;\n-\t\t    copy_num\n-\t\t      = hard_regno_nregs[copy_start][GET_MODE (copy_reg)];\n-\n-\t\t    /* If the return register is not likely spilled, - as is\n-\t\t       the case for floating point on SH4 - then it might\n-\t\t       be set by an arithmetic operation that needs a\n-\t\t       different mode than the exit block.  */\n-\t\t    for (j = n_entities - 1; j >= 0; j--)\n-\t\t      {\n-\t\t\tint e = entity_map[j];\n-\t\t\tint mode = MODE_NEEDED (e, return_copy);\n-\n-\t\t\tif (mode != num_modes[e] && mode != MODE_EXIT (e))\n-\t\t\t  break;\n-\t\t      }\n-\t\t    if (j >= 0)\n-\t\t      {\n-\t\t\t/* For the SH4, floating point loads depend on fpscr,\n-\t\t\t   thus we might need to put the final mode switch\n-\t\t\t   after the return value copy.  That is still OK,\n-\t\t\t   because a floating point return value does not\n-\t\t\t   conflict with address reloads.  */\n-\t\t\tif (copy_start >= ret_start\n-\t\t\t    && copy_start + copy_num <= ret_end\n-\t\t\t    && OBJECT_P (SET_SRC (return_copy_pat)))\n-\t\t\t  forced_late_switch = 1;\n-\t\t\tbreak;\n-\t\t      }\n-\n-\t\t    if (copy_start >= ret_start\n-\t\t\t&& copy_start + copy_num <= ret_end)\n-\t\t      nregs -= copy_num;\n-\t\t    else if (!maybe_builtin_apply\n-\t\t\t     || !FUNCTION_VALUE_REGNO_P (copy_start))\n-\t\t      break;\n-\t\t    last_insn = return_copy;\n-\t\t  }\n-\t\t/* ??? Exception handling can lead to the return value\n-\t\t   copy being already separated from the return value use,\n-\t\t   as in  unwind-dw2.c .\n-\t\t   Similarly, conditionally returning without a value,\n-\t\t   and conditionally using builtin_return can lead to an\n-\t\t   isolated use.  */\n-\t\tif (return_copy == BB_HEAD (src_bb))\n-\t\t  {\n-\t\t    short_block = 1;\n-\t\t    break;\n-\t\t  }\n-\t\tlast_insn = return_copy;\n-\t      }\n-\t    while (nregs);\n-\t    \n-\t    /* If we didn't see a full return value copy, verify that there\n-\t       is a plausible reason for this.  If some, but not all of the\n-\t       return register is likely spilled, we can expect that there\n-\t       is a copy for the likely spilled part.  */\n-\t    gcc_assert (!nregs\n-\t\t\t|| forced_late_switch\n-\t\t\t|| short_block\n-\t\t\t|| !(CLASS_LIKELY_SPILLED_P\n-\t\t\t     (REGNO_REG_CLASS (ret_start)))\n-\t\t\t|| (nregs\n-\t\t\t    != hard_regno_nregs[ret_start][GET_MODE (ret_reg)])\n-\t\t\t/* For multi-hard-register floating point\n-\t\t   \t   values, sometimes the likely-spilled part\n-\t\t   \t   is ordinarily copied first, then the other\n-\t\t   \t   part is set with an arithmetic operation.\n-\t\t   \t   This doesn't actually cause reload\n-\t\t   \t   failures, so let it pass.  */\n-\t\t\t|| (GET_MODE_CLASS (GET_MODE (ret_reg)) != MODE_INT\n-\t\t\t    && nregs != 1));\n-\t    \n-\t    if (INSN_P (last_insn))\n-\t      {\n-\t\tbefore_return_copy\n-\t\t  = emit_note_before (NOTE_INSN_DELETED, last_insn);\n-\t\t/* Instructions preceding LAST_INSN in the same block might\n-\t\t   require a different mode than MODE_EXIT, so if we might\n-\t\t   have such instructions, keep them in a separate block\n-\t\t   from pre_exit.  */\n-\t\tif (last_insn != BB_HEAD (src_bb))\n-\t\t  src_bb = split_block (src_bb,\n-\t\t\t\t\tPREV_INSN (before_return_copy))->dest;\n-\t      }\n-\t    else\n-\t      before_return_copy = last_insn;\n-\t    pre_exit = split_block (src_bb, before_return_copy)->src;\n-\t  }\n-\telse\n-\t  {\n-\t    pre_exit = split_edge (eg);\n-\t    COPY_REG_SET (pre_exit->global_live_at_start, live_at_end);\n-\t    COPY_REG_SET (pre_exit->global_live_at_end, live_at_end);\n-\t  }\n-      }\n-\n-  return pre_exit;\n-}\n-#endif\n-\n-/* Find all insns that need a particular mode setting, and insert the\n-   necessary mode switches.  Return true if we did work.  */\n-\n-int\n-optimize_mode_switching (FILE *file)\n-{\n-  rtx insn;\n-  int e;\n-  basic_block bb;\n-  int need_commit = 0;\n-  sbitmap *kill;\n-  struct edge_list *edge_list;\n-  static const int num_modes[] = NUM_MODES_FOR_MODE_SWITCHING;\n-#define N_ENTITIES ARRAY_SIZE (num_modes)\n-  int entity_map[N_ENTITIES];\n-  struct bb_info *bb_info[N_ENTITIES];\n-  int i, j;\n-  int n_entities;\n-  int max_num_modes = 0;\n-  bool emited = false;\n-  basic_block post_entry ATTRIBUTE_UNUSED, pre_exit ATTRIBUTE_UNUSED;\n-\n-  clear_bb_flags ();\n-\n-  for (e = N_ENTITIES - 1, n_entities = 0; e >= 0; e--)\n-    if (OPTIMIZE_MODE_SWITCHING (e))\n-      {\n-\tint entry_exit_extra = 0;\n-\n-\t/* Create the list of segments within each basic block.\n-\t   If NORMAL_MODE is defined, allow for two extra\n-\t   blocks split from the entry and exit block.  */\n-#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n-\tentry_exit_extra = 3;\n-#endif\n-\tbb_info[n_entities]\n-\t  = xcalloc (last_basic_block + entry_exit_extra, sizeof **bb_info);\n-\tentity_map[n_entities++] = e;\n-\tif (num_modes[e] > max_num_modes)\n-\t  max_num_modes = num_modes[e];\n-      }\n-\n-  if (! n_entities)\n-    return 0;\n-\n-#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n-  /* Split the edge from the entry block, so that we can note that\n-     there NORMAL_MODE is supplied.  */\n-  post_entry = split_edge (single_succ_edge (ENTRY_BLOCK_PTR));\n-  pre_exit = create_pre_exit (n_entities, entity_map, num_modes);\n-#endif\n-\n-  /* Create the bitmap vectors.  */\n-\n-  antic = sbitmap_vector_alloc (last_basic_block, n_entities);\n-  transp = sbitmap_vector_alloc (last_basic_block, n_entities);\n-  comp = sbitmap_vector_alloc (last_basic_block, n_entities);\n-\n-  sbitmap_vector_ones (transp, last_basic_block);\n-\n-  for (j = n_entities - 1; j >= 0; j--)\n-    {\n-      int e = entity_map[j];\n-      int no_mode = num_modes[e];\n-      struct bb_info *info = bb_info[j];\n-\n-      /* Determine what the first use (if any) need for a mode of entity E is.\n-\t This will be the mode that is anticipatable for this block.\n-\t Also compute the initial transparency settings.  */\n-      FOR_EACH_BB (bb)\n-\t{\n-\t  struct seginfo *ptr;\n-\t  int last_mode = no_mode;\n-\t  HARD_REG_SET live_now;\n-\n-\t  REG_SET_TO_HARD_REG_SET (live_now,\n-\t\t\t\t   bb->global_live_at_start);\n-\t  for (insn = BB_HEAD (bb);\n-\t       insn != NULL && insn != NEXT_INSN (BB_END (bb));\n-\t       insn = NEXT_INSN (insn))\n-\t    {\n-\t      if (INSN_P (insn))\n-\t\t{\n-\t\t  int mode = MODE_NEEDED (e, insn);\n-\t\t  rtx link;\n-\n-\t\t  if (mode != no_mode && mode != last_mode)\n-\t\t    {\n-\t\t      last_mode = mode;\n-\t\t      ptr = new_seginfo (mode, insn, bb->index, live_now);\n-\t\t      add_seginfo (info + bb->index, ptr);\n-\t\t      RESET_BIT (transp[bb->index], j);\n-\t\t    }\n-#ifdef MODE_AFTER\n-\t\t  last_mode = MODE_AFTER (last_mode, insn);\n-#endif\n-\t\t  /* Update LIVE_NOW.  */\n-\t\t  for (link = REG_NOTES (insn); link; link = XEXP (link, 1))\n-\t\t    if (REG_NOTE_KIND (link) == REG_DEAD)\n-\t\t      reg_dies (XEXP (link, 0), live_now);\n-\n-\t\t  note_stores (PATTERN (insn), reg_becomes_live, &live_now);\n-\t\t  for (link = REG_NOTES (insn); link; link = XEXP (link, 1))\n-\t\t    if (REG_NOTE_KIND (link) == REG_UNUSED)\n-\t\t      reg_dies (XEXP (link, 0), live_now);\n-\t\t}\n-\t    }\n-\n-\t  info[bb->index].computing = last_mode;\n-\t  /* Check for blocks without ANY mode requirements.  */\n-\t  if (last_mode == no_mode)\n-\t    {\n-\t      ptr = new_seginfo (no_mode, BB_END (bb), bb->index, live_now);\n-\t      add_seginfo (info + bb->index, ptr);\n-\t    }\n-\t}\n-#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n-      {\n-\tint mode = MODE_ENTRY (e);\n-\n-\tif (mode != no_mode)\n-\t  {\n-\t    bb = post_entry;\n-\n-\t    /* By always making this nontransparent, we save\n-\t       an extra check in make_preds_opaque.  We also\n-\t       need this to avoid confusing pre_edge_lcm when\n-\t       antic is cleared but transp and comp are set.  */\n-\t    RESET_BIT (transp[bb->index], j);\n-\n-\t    /* Insert a fake computing definition of MODE into entry\n-\t       blocks which compute no mode. This represents the mode on\n-\t       entry.  */\n-\t    info[bb->index].computing = mode;\n-\n-\t    if (pre_exit)\n-\t      info[pre_exit->index].seginfo->mode = MODE_EXIT (e);\n-\t  }\n-      }\n-#endif /* NORMAL_MODE */\n-    }\n-\n-  kill = sbitmap_vector_alloc (last_basic_block, n_entities);\n-  for (i = 0; i < max_num_modes; i++)\n-    {\n-      int current_mode[N_ENTITIES];\n-      sbitmap *delete;\n-      sbitmap *insert;\n-\n-      /* Set the anticipatable and computing arrays.  */\n-      sbitmap_vector_zero (antic, last_basic_block);\n-      sbitmap_vector_zero (comp, last_basic_block);\n-      for (j = n_entities - 1; j >= 0; j--)\n-\t{\n-\t  int m = current_mode[j] = MODE_PRIORITY_TO_MODE (entity_map[j], i);\n-\t  struct bb_info *info = bb_info[j];\n-\n-\t  FOR_EACH_BB (bb)\n-\t    {\n-\t      if (info[bb->index].seginfo->mode == m)\n-\t\tSET_BIT (antic[bb->index], j);\n-\n-\t      if (info[bb->index].computing == m)\n-\t\tSET_BIT (comp[bb->index], j);\n-\t    }\n-\t}\n-\n-      /* Calculate the optimal locations for the\n-\t placement mode switches to modes with priority I.  */\n-\n-      FOR_EACH_BB (bb)\n-\tsbitmap_not (kill[bb->index], transp[bb->index]);\n-      edge_list = pre_edge_lcm (file, 1, transp, comp, antic,\n-\t\t\t\tkill, &insert, &delete);\n-\n-      for (j = n_entities - 1; j >= 0; j--)\n-\t{\n-\t  /* Insert all mode sets that have been inserted by lcm.  */\n-\t  int no_mode = num_modes[entity_map[j]];\n-\n-\t  /* Wherever we have moved a mode setting upwards in the flow graph,\n-\t     the blocks between the new setting site and the now redundant\n-\t     computation ceases to be transparent for any lower-priority\n-\t     mode of the same entity.  First set the aux field of each\n-\t     insertion site edge non-transparent, then propagate the new\n-\t     non-transparency from the redundant computation upwards till\n-\t     we hit an insertion site or an already non-transparent block.  */\n-\t  for (e = NUM_EDGES (edge_list) - 1; e >= 0; e--)\n-\t    {\n-\t      edge eg = INDEX_EDGE (edge_list, e);\n-\t      int mode;\n-\t      basic_block src_bb;\n-\t      HARD_REG_SET live_at_edge;\n-\t      rtx mode_set;\n-\n-\t      eg->aux = 0;\n-\n-\t      if (! TEST_BIT (insert[e], j))\n-\t\tcontinue;\n-\n-\t      eg->aux = (void *)1;\n-\n-\t      mode = current_mode[j];\n-\t      src_bb = eg->src;\n-\n-\t      REG_SET_TO_HARD_REG_SET (live_at_edge,\n-\t\t\t\t       src_bb->global_live_at_end);\n-\n-\t      start_sequence ();\n-\t      EMIT_MODE_SET (entity_map[j], mode, live_at_edge);\n-\t      mode_set = get_insns ();\n-\t      end_sequence ();\n-\n-\t      /* Do not bother to insert empty sequence.  */\n-\t      if (mode_set == NULL_RTX)\n-\t\tcontinue;\n-\n-\t      /* If this is an abnormal edge, we'll insert at the end\n-\t\t of the previous block.  */\n-\t      if (eg->flags & EDGE_ABNORMAL)\n-\t\t{\n-\t\t  emited = true;\n-\t\t  if (JUMP_P (BB_END (src_bb)))\n-\t\t    emit_insn_before (mode_set, BB_END (src_bb));\n-\t\t  else\n-\t\t    {\n-\t\t      /* It doesn't make sense to switch to normal\n-\t\t         mode after a CALL_INSN.  The cases in which a\n-\t\t         CALL_INSN may have an abnormal edge are\n-\t\t         sibcalls and EH edges.  In the case of\n-\t\t         sibcalls, the dest basic-block is the\n-\t\t         EXIT_BLOCK, that runs in normal mode; it is\n-\t\t         assumed that a sibcall insn requires normal\n-\t\t         mode itself, so no mode switch would be\n-\t\t         required after the call (it wouldn't make\n-\t\t         sense, anyway).  In the case of EH edges, EH\n-\t\t         entry points also start in normal mode, so a\n-\t\t         similar reasoning applies.  */\n-\t\t      gcc_assert (NONJUMP_INSN_P (BB_END (src_bb)));\n-\t\t      emit_insn_after (mode_set, BB_END (src_bb));\n-\t\t    }\n-\t\t  bb_info[j][src_bb->index].computing = mode;\n-\t\t  RESET_BIT (transp[src_bb->index], j);\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  need_commit = 1;\n-\t\t  insert_insn_on_edge (mode_set, eg);\n-\t\t}\n-\t    }\n-\n-\t  FOR_EACH_BB_REVERSE (bb)\n-\t    if (TEST_BIT (delete[bb->index], j))\n-\t      {\n-\t\tmake_preds_opaque (bb, j);\n-\t\t/* Cancel the 'deleted' mode set.  */\n-\t\tbb_info[j][bb->index].seginfo->mode = no_mode;\n-\t      }\n-\t}\n-\n-      sbitmap_vector_free (delete);\n-      sbitmap_vector_free (insert);\n-      clear_aux_for_edges ();\n-      free_edge_list (edge_list);\n-    }\n-\n-  /* Now output the remaining mode sets in all the segments.  */\n-  for (j = n_entities - 1; j >= 0; j--)\n-    {\n-      int no_mode = num_modes[entity_map[j]];\n-\n-      FOR_EACH_BB_REVERSE (bb)\n-\t{\n-\t  struct seginfo *ptr, *next;\n-\t  for (ptr = bb_info[j][bb->index].seginfo; ptr; ptr = next)\n-\t    {\n-\t      next = ptr->next;\n-\t      if (ptr->mode != no_mode)\n-\t\t{\n-\t\t  rtx mode_set;\n-\n-\t\t  start_sequence ();\n-\t\t  EMIT_MODE_SET (entity_map[j], ptr->mode, ptr->regs_live);\n-\t\t  mode_set = get_insns ();\n-\t\t  end_sequence ();\n-\n-\t\t  /* Insert MODE_SET only if it is nonempty.  */\n-\t\t  if (mode_set != NULL_RTX)\n-\t\t    {\n-\t\t      emited = true;\n-\t\t      if (NOTE_P (ptr->insn_ptr)\n-\t\t\t  && (NOTE_LINE_NUMBER (ptr->insn_ptr)\n-\t\t\t      == NOTE_INSN_BASIC_BLOCK))\n-\t\t\temit_insn_after (mode_set, ptr->insn_ptr);\n-\t\t      else\n-\t\t\temit_insn_before (mode_set, ptr->insn_ptr);\n-\t\t    }\n-\t\t}\n-\n-\t      free (ptr);\n-\t    }\n-\t}\n-\n-      free (bb_info[j]);\n-    }\n-\n-  /* Finished. Free up all the things we've allocated.  */\n-\n-  sbitmap_vector_free (kill);\n-  sbitmap_vector_free (antic);\n-  sbitmap_vector_free (transp);\n-  sbitmap_vector_free (comp);\n-\n-  if (need_commit)\n-    commit_edge_insertions ();\n-\n-#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n-  cleanup_cfg (CLEANUP_NO_INSN_DEL);\n-#else\n-  if (!need_commit && !emited)\n-    return 0;\n-#endif\n-\n-  max_regno = max_reg_num ();\n-  allocate_reg_info (max_regno, FALSE, FALSE);\n-  update_life_info_in_dirty_blocks (UPDATE_LIFE_GLOBAL_RM_NOTES,\n-\t\t\t\t    (PROP_DEATH_NOTES | PROP_KILL_DEAD_CODE\n-\t\t\t\t     | PROP_SCAN_DEAD_CODE));\n-\n-  return 1;\n-}\n-#endif /* OPTIMIZE_MODE_SWITCHING */"}, {"sha": "57eb1d21dc1528d03e296f3a81920fa9498868ec", "filename": "gcc/mode-switching.c", "status": "added", "additions": 711, "deletions": 0, "changes": 711, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fmode-switching.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/610d24786dd3e1f9d828b94def29961e7da987cc/gcc%2Fmode-switching.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmode-switching.c?ref=610d24786dd3e1f9d828b94def29961e7da987cc", "patch": "@@ -0,0 +1,711 @@\n+/* CPU mode switching\n+   Copyright (C) 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005\n+   Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"rtl.h\"\n+#include \"regs.h\"\n+#include \"hard-reg-set.h\"\n+#include \"flags.h\"\n+#include \"real.h\"\n+#include \"insn-config.h\"\n+#include \"recog.h\"\n+#include \"basic-block.h\"\n+#include \"output.h\"\n+#include \"tm_p.h\"\n+#include \"function.h\"\n+\n+/* We want target macros for the mode switching code to be able to refer\n+   to instruction attribute values.  */\n+#include \"insn-attr.h\"\n+\n+#ifdef OPTIMIZE_MODE_SWITCHING\n+\n+/* The algorithm for setting the modes consists of scanning the insn list\n+   and finding all the insns which require a specific mode.  Each insn gets\n+   a unique struct seginfo element.  These structures are inserted into a list\n+   for each basic block.  For each entity, there is an array of bb_info over\n+   the flow graph basic blocks (local var 'bb_info'), and contains a list\n+   of all insns within that basic block, in the order they are encountered.\n+\n+   For each entity, any basic block WITHOUT any insns requiring a specific\n+   mode are given a single entry, without a mode.  (Each basic block\n+   in the flow graph must have at least one entry in the segment table.)\n+\n+   The LCM algorithm is then run over the flow graph to determine where to\n+   place the sets to the highest-priority value in respect of first the first\n+   insn in any one block.  Any adjustments required to the transparency\n+   vectors are made, then the next iteration starts for the next-lower\n+   priority mode, till for each entity all modes are exhausted.\n+\n+   More details are located in the code for optimize_mode_switching().  */\n+\f\n+/* This structure contains the information for each insn which requires\n+   either single or double mode to be set.\n+   MODE is the mode this insn must be executed in.\n+   INSN_PTR is the insn to be executed (may be the note that marks the\n+   beginning of a basic block).\n+   BBNUM is the flow graph basic block this insn occurs in.\n+   NEXT is the next insn in the same basic block.  */\n+struct seginfo\n+{\n+  int mode;\n+  rtx insn_ptr;\n+  int bbnum;\n+  struct seginfo *next;\n+  HARD_REG_SET regs_live;\n+};\n+\n+struct bb_info\n+{\n+  struct seginfo *seginfo;\n+  int computing;\n+};\n+\n+/* These bitmaps are used for the LCM algorithm.  */\n+\n+static sbitmap *antic;\n+static sbitmap *transp;\n+static sbitmap *comp;\n+\n+static struct seginfo * new_seginfo (int, rtx, int, HARD_REG_SET);\n+static void add_seginfo (struct bb_info *, struct seginfo *);\n+static void reg_dies (rtx, HARD_REG_SET);\n+static void reg_becomes_live (rtx, rtx, void *);\n+static void make_preds_opaque (basic_block, int);\n+\f\n+\n+/* This function will allocate a new BBINFO structure, initialized\n+   with the MODE, INSN, and basic block BB parameters.  */\n+\n+static struct seginfo *\n+new_seginfo (int mode, rtx insn, int bb, HARD_REG_SET regs_live)\n+{\n+  struct seginfo *ptr;\n+  ptr = xmalloc (sizeof (struct seginfo));\n+  ptr->mode = mode;\n+  ptr->insn_ptr = insn;\n+  ptr->bbnum = bb;\n+  ptr->next = NULL;\n+  COPY_HARD_REG_SET (ptr->regs_live, regs_live);\n+  return ptr;\n+}\n+\n+/* Add a seginfo element to the end of a list.\n+   HEAD is a pointer to the list beginning.\n+   INFO is the structure to be linked in.  */\n+\n+static void\n+add_seginfo (struct bb_info *head, struct seginfo *info)\n+{\n+  struct seginfo *ptr;\n+\n+  if (head->seginfo == NULL)\n+    head->seginfo = info;\n+  else\n+    {\n+      ptr = head->seginfo;\n+      while (ptr->next != NULL)\n+\tptr = ptr->next;\n+      ptr->next = info;\n+    }\n+}\n+\n+/* Make all predecessors of basic block B opaque, recursively, till we hit\n+   some that are already non-transparent, or an edge where aux is set; that\n+   denotes that a mode set is to be done on that edge.\n+   J is the bit number in the bitmaps that corresponds to the entity that\n+   we are currently handling mode-switching for.  */\n+\n+static void\n+make_preds_opaque (basic_block b, int j)\n+{\n+  edge e;\n+  edge_iterator ei;\n+\n+  FOR_EACH_EDGE (e, ei, b->preds)\n+    {\n+      basic_block pb = e->src;\n+\n+      if (e->aux || ! TEST_BIT (transp[pb->index], j))\n+\tcontinue;\n+\n+      RESET_BIT (transp[pb->index], j);\n+      make_preds_opaque (pb, j);\n+    }\n+}\n+\n+/* Record in LIVE that register REG died.  */\n+\n+static void\n+reg_dies (rtx reg, HARD_REG_SET live)\n+{\n+  int regno, nregs;\n+\n+  if (!REG_P (reg))\n+    return;\n+\n+  regno = REGNO (reg);\n+  if (regno < FIRST_PSEUDO_REGISTER)\n+    for (nregs = hard_regno_nregs[regno][GET_MODE (reg)] - 1; nregs >= 0;\n+\t nregs--)\n+      CLEAR_HARD_REG_BIT (live, regno + nregs);\n+}\n+\n+/* Record in LIVE that register REG became live.\n+   This is called via note_stores.  */\n+\n+static void\n+reg_becomes_live (rtx reg, rtx setter ATTRIBUTE_UNUSED, void *live)\n+{\n+  int regno, nregs;\n+\n+  if (GET_CODE (reg) == SUBREG)\n+    reg = SUBREG_REG (reg);\n+\n+  if (!REG_P (reg))\n+    return;\n+\n+  regno = REGNO (reg);\n+  if (regno < FIRST_PSEUDO_REGISTER)\n+    for (nregs = hard_regno_nregs[regno][GET_MODE (reg)] - 1; nregs >= 0;\n+\t nregs--)\n+      SET_HARD_REG_BIT (* (HARD_REG_SET *) live, regno + nregs);\n+}\n+\n+/* Make sure if MODE_ENTRY is defined the MODE_EXIT is defined\n+   and vice versa.  */\n+#if defined (MODE_ENTRY) != defined (MODE_EXIT)\n+ #error \"Both MODE_ENTRY and MODE_EXIT must be defined\"\n+#endif\n+\n+#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n+/* Split the fallthrough edge to the exit block, so that we can note\n+   that there NORMAL_MODE is required.  Return the new block if it's\n+   inserted before the exit block.  Otherwise return null.  */\n+\n+static basic_block\n+create_pre_exit (int n_entities, int *entity_map, const int *num_modes)\n+{\n+  edge eg;\n+  edge_iterator ei;\n+  basic_block pre_exit;\n+\n+  /* The only non-call predecessor at this stage is a block with a\n+     fallthrough edge; there can be at most one, but there could be\n+     none at all, e.g. when exit is called.  */\n+  pre_exit = 0;\n+  FOR_EACH_EDGE (eg, ei, EXIT_BLOCK_PTR->preds)\n+    if (eg->flags & EDGE_FALLTHRU)\n+      {\n+\tbasic_block src_bb = eg->src;\n+\tregset live_at_end = src_bb->global_live_at_end;\n+\trtx last_insn, ret_reg;\n+\n+\tgcc_assert (!pre_exit);\n+\t/* If this function returns a value at the end, we have to\n+\t   insert the final mode switch before the return value copy\n+\t   to its hard register.  */\n+\tif (EDGE_COUNT (EXIT_BLOCK_PTR->preds) == 1\n+\t    && NONJUMP_INSN_P ((last_insn = BB_END (src_bb)))\n+\t    && GET_CODE (PATTERN (last_insn)) == USE\n+\t    && GET_CODE ((ret_reg = XEXP (PATTERN (last_insn), 0))) == REG)\n+\t  {\n+\t    int ret_start = REGNO (ret_reg);\n+\t    int nregs = hard_regno_nregs[ret_start][GET_MODE (ret_reg)];\n+\t    int ret_end = ret_start + nregs;\n+\t    int short_block = 0;\n+\t    int maybe_builtin_apply = 0;\n+\t    int forced_late_switch = 0;\n+\t    rtx before_return_copy;\n+\n+\t    do\n+\t      {\n+\t\trtx return_copy = PREV_INSN (last_insn);\n+\t\trtx return_copy_pat, copy_reg;\n+\t\tint copy_start, copy_num;\n+\t\tint j;\n+\n+\t\tif (INSN_P (return_copy))\n+\t\t  {\n+\t\t    if (GET_CODE (PATTERN (return_copy)) == USE\n+\t\t\t&& GET_CODE (XEXP (PATTERN (return_copy), 0)) == REG\n+\t\t\t&& (FUNCTION_VALUE_REGNO_P\n+\t\t\t    (REGNO (XEXP (PATTERN (return_copy), 0)))))\n+\t\t      {\n+\t\t\tmaybe_builtin_apply = 1;\n+\t\t\tlast_insn = return_copy;\n+\t\t\tcontinue;\n+\t\t      }\n+\t\t    /* If the return register is not (in its entirety)\n+\t\t       likely spilled, the return copy might be\n+\t\t       partially or completely optimized away.  */\n+\t\t    return_copy_pat = single_set (return_copy);\n+\t\t    if (!return_copy_pat)\n+\t\t      {\n+\t\t\treturn_copy_pat = PATTERN (return_copy);\n+\t\t\tif (GET_CODE (return_copy_pat) != CLOBBER)\n+\t\t\t  break;\n+\t\t      }\n+\t\t    copy_reg = SET_DEST (return_copy_pat);\n+\t\t    if (GET_CODE (copy_reg) == REG)\n+\t\t      copy_start = REGNO (copy_reg);\n+\t\t    else if (GET_CODE (copy_reg) == SUBREG\n+\t\t\t     && GET_CODE (SUBREG_REG (copy_reg)) == REG)\n+\t\t      copy_start = REGNO (SUBREG_REG (copy_reg));\n+\t\t    else\n+\t\t      break;\n+\t\t    if (copy_start >= FIRST_PSEUDO_REGISTER)\n+\t\t      break;\n+\t\t    copy_num\n+\t\t      = hard_regno_nregs[copy_start][GET_MODE (copy_reg)];\n+\n+\t\t    /* If the return register is not likely spilled, - as is\n+\t\t       the case for floating point on SH4 - then it might\n+\t\t       be set by an arithmetic operation that needs a\n+\t\t       different mode than the exit block.  */\n+\t\t    for (j = n_entities - 1; j >= 0; j--)\n+\t\t      {\n+\t\t\tint e = entity_map[j];\n+\t\t\tint mode = MODE_NEEDED (e, return_copy);\n+\n+\t\t\tif (mode != num_modes[e] && mode != MODE_EXIT (e))\n+\t\t\t  break;\n+\t\t      }\n+\t\t    if (j >= 0)\n+\t\t      {\n+\t\t\t/* For the SH4, floating point loads depend on fpscr,\n+\t\t\t   thus we might need to put the final mode switch\n+\t\t\t   after the return value copy.  That is still OK,\n+\t\t\t   because a floating point return value does not\n+\t\t\t   conflict with address reloads.  */\n+\t\t\tif (copy_start >= ret_start\n+\t\t\t    && copy_start + copy_num <= ret_end\n+\t\t\t    && OBJECT_P (SET_SRC (return_copy_pat)))\n+\t\t\t  forced_late_switch = 1;\n+\t\t\tbreak;\n+\t\t      }\n+\n+\t\t    if (copy_start >= ret_start\n+\t\t\t&& copy_start + copy_num <= ret_end)\n+\t\t      nregs -= copy_num;\n+\t\t    else if (!maybe_builtin_apply\n+\t\t\t     || !FUNCTION_VALUE_REGNO_P (copy_start))\n+\t\t      break;\n+\t\t    last_insn = return_copy;\n+\t\t  }\n+\t\t/* ??? Exception handling can lead to the return value\n+\t\t   copy being already separated from the return value use,\n+\t\t   as in  unwind-dw2.c .\n+\t\t   Similarly, conditionally returning without a value,\n+\t\t   and conditionally using builtin_return can lead to an\n+\t\t   isolated use.  */\n+\t\tif (return_copy == BB_HEAD (src_bb))\n+\t\t  {\n+\t\t    short_block = 1;\n+\t\t    break;\n+\t\t  }\n+\t\tlast_insn = return_copy;\n+\t      }\n+\t    while (nregs);\n+\t    \n+\t    /* If we didn't see a full return value copy, verify that there\n+\t       is a plausible reason for this.  If some, but not all of the\n+\t       return register is likely spilled, we can expect that there\n+\t       is a copy for the likely spilled part.  */\n+\t    gcc_assert (!nregs\n+\t\t\t|| forced_late_switch\n+\t\t\t|| short_block\n+\t\t\t|| !(CLASS_LIKELY_SPILLED_P\n+\t\t\t     (REGNO_REG_CLASS (ret_start)))\n+\t\t\t|| (nregs\n+\t\t\t    != hard_regno_nregs[ret_start][GET_MODE (ret_reg)])\n+\t\t\t/* For multi-hard-register floating point\n+\t\t   \t   values, sometimes the likely-spilled part\n+\t\t   \t   is ordinarily copied first, then the other\n+\t\t   \t   part is set with an arithmetic operation.\n+\t\t   \t   This doesn't actually cause reload\n+\t\t   \t   failures, so let it pass.  */\n+\t\t\t|| (GET_MODE_CLASS (GET_MODE (ret_reg)) != MODE_INT\n+\t\t\t    && nregs != 1));\n+\t    \n+\t    if (INSN_P (last_insn))\n+\t      {\n+\t\tbefore_return_copy\n+\t\t  = emit_note_before (NOTE_INSN_DELETED, last_insn);\n+\t\t/* Instructions preceding LAST_INSN in the same block might\n+\t\t   require a different mode than MODE_EXIT, so if we might\n+\t\t   have such instructions, keep them in a separate block\n+\t\t   from pre_exit.  */\n+\t\tif (last_insn != BB_HEAD (src_bb))\n+\t\t  src_bb = split_block (src_bb,\n+\t\t\t\t\tPREV_INSN (before_return_copy))->dest;\n+\t      }\n+\t    else\n+\t      before_return_copy = last_insn;\n+\t    pre_exit = split_block (src_bb, before_return_copy)->src;\n+\t  }\n+\telse\n+\t  {\n+\t    pre_exit = split_edge (eg);\n+\t    COPY_REG_SET (pre_exit->global_live_at_start, live_at_end);\n+\t    COPY_REG_SET (pre_exit->global_live_at_end, live_at_end);\n+\t  }\n+      }\n+\n+  return pre_exit;\n+}\n+#endif\n+\n+/* Find all insns that need a particular mode setting, and insert the\n+   necessary mode switches.  Return true if we did work.  */\n+\n+int\n+optimize_mode_switching (FILE *file)\n+{\n+  rtx insn;\n+  int e;\n+  basic_block bb;\n+  int need_commit = 0;\n+  sbitmap *kill;\n+  struct edge_list *edge_list;\n+  static const int num_modes[] = NUM_MODES_FOR_MODE_SWITCHING;\n+#define N_ENTITIES ARRAY_SIZE (num_modes)\n+  int entity_map[N_ENTITIES];\n+  struct bb_info *bb_info[N_ENTITIES];\n+  int i, j;\n+  int n_entities;\n+  int max_num_modes = 0;\n+  bool emited = false;\n+  basic_block post_entry ATTRIBUTE_UNUSED, pre_exit ATTRIBUTE_UNUSED;\n+\n+  clear_bb_flags ();\n+\n+  for (e = N_ENTITIES - 1, n_entities = 0; e >= 0; e--)\n+    if (OPTIMIZE_MODE_SWITCHING (e))\n+      {\n+\tint entry_exit_extra = 0;\n+\n+\t/* Create the list of segments within each basic block.\n+\t   If NORMAL_MODE is defined, allow for two extra\n+\t   blocks split from the entry and exit block.  */\n+#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n+\tentry_exit_extra = 3;\n+#endif\n+\tbb_info[n_entities]\n+\t  = xcalloc (last_basic_block + entry_exit_extra, sizeof **bb_info);\n+\tentity_map[n_entities++] = e;\n+\tif (num_modes[e] > max_num_modes)\n+\t  max_num_modes = num_modes[e];\n+      }\n+\n+  if (! n_entities)\n+    return 0;\n+\n+#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n+  /* Split the edge from the entry block, so that we can note that\n+     there NORMAL_MODE is supplied.  */\n+  post_entry = split_edge (single_succ_edge (ENTRY_BLOCK_PTR));\n+  pre_exit = create_pre_exit (n_entities, entity_map, num_modes);\n+#endif\n+\n+  /* Create the bitmap vectors.  */\n+\n+  antic = sbitmap_vector_alloc (last_basic_block, n_entities);\n+  transp = sbitmap_vector_alloc (last_basic_block, n_entities);\n+  comp = sbitmap_vector_alloc (last_basic_block, n_entities);\n+\n+  sbitmap_vector_ones (transp, last_basic_block);\n+\n+  for (j = n_entities - 1; j >= 0; j--)\n+    {\n+      int e = entity_map[j];\n+      int no_mode = num_modes[e];\n+      struct bb_info *info = bb_info[j];\n+\n+      /* Determine what the first use (if any) need for a mode of entity E is.\n+\t This will be the mode that is anticipatable for this block.\n+\t Also compute the initial transparency settings.  */\n+      FOR_EACH_BB (bb)\n+\t{\n+\t  struct seginfo *ptr;\n+\t  int last_mode = no_mode;\n+\t  HARD_REG_SET live_now;\n+\n+\t  REG_SET_TO_HARD_REG_SET (live_now,\n+\t\t\t\t   bb->global_live_at_start);\n+\t  for (insn = BB_HEAD (bb);\n+\t       insn != NULL && insn != NEXT_INSN (BB_END (bb));\n+\t       insn = NEXT_INSN (insn))\n+\t    {\n+\t      if (INSN_P (insn))\n+\t\t{\n+\t\t  int mode = MODE_NEEDED (e, insn);\n+\t\t  rtx link;\n+\n+\t\t  if (mode != no_mode && mode != last_mode)\n+\t\t    {\n+\t\t      last_mode = mode;\n+\t\t      ptr = new_seginfo (mode, insn, bb->index, live_now);\n+\t\t      add_seginfo (info + bb->index, ptr);\n+\t\t      RESET_BIT (transp[bb->index], j);\n+\t\t    }\n+#ifdef MODE_AFTER\n+\t\t  last_mode = MODE_AFTER (last_mode, insn);\n+#endif\n+\t\t  /* Update LIVE_NOW.  */\n+\t\t  for (link = REG_NOTES (insn); link; link = XEXP (link, 1))\n+\t\t    if (REG_NOTE_KIND (link) == REG_DEAD)\n+\t\t      reg_dies (XEXP (link, 0), live_now);\n+\n+\t\t  note_stores (PATTERN (insn), reg_becomes_live, &live_now);\n+\t\t  for (link = REG_NOTES (insn); link; link = XEXP (link, 1))\n+\t\t    if (REG_NOTE_KIND (link) == REG_UNUSED)\n+\t\t      reg_dies (XEXP (link, 0), live_now);\n+\t\t}\n+\t    }\n+\n+\t  info[bb->index].computing = last_mode;\n+\t  /* Check for blocks without ANY mode requirements.  */\n+\t  if (last_mode == no_mode)\n+\t    {\n+\t      ptr = new_seginfo (no_mode, BB_END (bb), bb->index, live_now);\n+\t      add_seginfo (info + bb->index, ptr);\n+\t    }\n+\t}\n+#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n+      {\n+\tint mode = MODE_ENTRY (e);\n+\n+\tif (mode != no_mode)\n+\t  {\n+\t    bb = post_entry;\n+\n+\t    /* By always making this nontransparent, we save\n+\t       an extra check in make_preds_opaque.  We also\n+\t       need this to avoid confusing pre_edge_lcm when\n+\t       antic is cleared but transp and comp are set.  */\n+\t    RESET_BIT (transp[bb->index], j);\n+\n+\t    /* Insert a fake computing definition of MODE into entry\n+\t       blocks which compute no mode. This represents the mode on\n+\t       entry.  */\n+\t    info[bb->index].computing = mode;\n+\n+\t    if (pre_exit)\n+\t      info[pre_exit->index].seginfo->mode = MODE_EXIT (e);\n+\t  }\n+      }\n+#endif /* NORMAL_MODE */\n+    }\n+\n+  kill = sbitmap_vector_alloc (last_basic_block, n_entities);\n+  for (i = 0; i < max_num_modes; i++)\n+    {\n+      int current_mode[N_ENTITIES];\n+      sbitmap *delete;\n+      sbitmap *insert;\n+\n+      /* Set the anticipatable and computing arrays.  */\n+      sbitmap_vector_zero (antic, last_basic_block);\n+      sbitmap_vector_zero (comp, last_basic_block);\n+      for (j = n_entities - 1; j >= 0; j--)\n+\t{\n+\t  int m = current_mode[j] = MODE_PRIORITY_TO_MODE (entity_map[j], i);\n+\t  struct bb_info *info = bb_info[j];\n+\n+\t  FOR_EACH_BB (bb)\n+\t    {\n+\t      if (info[bb->index].seginfo->mode == m)\n+\t\tSET_BIT (antic[bb->index], j);\n+\n+\t      if (info[bb->index].computing == m)\n+\t\tSET_BIT (comp[bb->index], j);\n+\t    }\n+\t}\n+\n+      /* Calculate the optimal locations for the\n+\t placement mode switches to modes with priority I.  */\n+\n+      FOR_EACH_BB (bb)\n+\tsbitmap_not (kill[bb->index], transp[bb->index]);\n+      edge_list = pre_edge_lcm (file, 1, transp, comp, antic,\n+\t\t\t\tkill, &insert, &delete);\n+\n+      for (j = n_entities - 1; j >= 0; j--)\n+\t{\n+\t  /* Insert all mode sets that have been inserted by lcm.  */\n+\t  int no_mode = num_modes[entity_map[j]];\n+\n+\t  /* Wherever we have moved a mode setting upwards in the flow graph,\n+\t     the blocks between the new setting site and the now redundant\n+\t     computation ceases to be transparent for any lower-priority\n+\t     mode of the same entity.  First set the aux field of each\n+\t     insertion site edge non-transparent, then propagate the new\n+\t     non-transparency from the redundant computation upwards till\n+\t     we hit an insertion site or an already non-transparent block.  */\n+\t  for (e = NUM_EDGES (edge_list) - 1; e >= 0; e--)\n+\t    {\n+\t      edge eg = INDEX_EDGE (edge_list, e);\n+\t      int mode;\n+\t      basic_block src_bb;\n+\t      HARD_REG_SET live_at_edge;\n+\t      rtx mode_set;\n+\n+\t      eg->aux = 0;\n+\n+\t      if (! TEST_BIT (insert[e], j))\n+\t\tcontinue;\n+\n+\t      eg->aux = (void *)1;\n+\n+\t      mode = current_mode[j];\n+\t      src_bb = eg->src;\n+\n+\t      REG_SET_TO_HARD_REG_SET (live_at_edge,\n+\t\t\t\t       src_bb->global_live_at_end);\n+\n+\t      start_sequence ();\n+\t      EMIT_MODE_SET (entity_map[j], mode, live_at_edge);\n+\t      mode_set = get_insns ();\n+\t      end_sequence ();\n+\n+\t      /* Do not bother to insert empty sequence.  */\n+\t      if (mode_set == NULL_RTX)\n+\t\tcontinue;\n+\n+\t      /* If this is an abnormal edge, we'll insert at the end\n+\t\t of the previous block.  */\n+\t      if (eg->flags & EDGE_ABNORMAL)\n+\t\t{\n+\t\t  emited = true;\n+\t\t  if (JUMP_P (BB_END (src_bb)))\n+\t\t    emit_insn_before (mode_set, BB_END (src_bb));\n+\t\t  else\n+\t\t    {\n+\t\t      /* It doesn't make sense to switch to normal\n+\t\t         mode after a CALL_INSN.  The cases in which a\n+\t\t         CALL_INSN may have an abnormal edge are\n+\t\t         sibcalls and EH edges.  In the case of\n+\t\t         sibcalls, the dest basic-block is the\n+\t\t         EXIT_BLOCK, that runs in normal mode; it is\n+\t\t         assumed that a sibcall insn requires normal\n+\t\t         mode itself, so no mode switch would be\n+\t\t         required after the call (it wouldn't make\n+\t\t         sense, anyway).  In the case of EH edges, EH\n+\t\t         entry points also start in normal mode, so a\n+\t\t         similar reasoning applies.  */\n+\t\t      gcc_assert (NONJUMP_INSN_P (BB_END (src_bb)));\n+\t\t      emit_insn_after (mode_set, BB_END (src_bb));\n+\t\t    }\n+\t\t  bb_info[j][src_bb->index].computing = mode;\n+\t\t  RESET_BIT (transp[src_bb->index], j);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  need_commit = 1;\n+\t\t  insert_insn_on_edge (mode_set, eg);\n+\t\t}\n+\t    }\n+\n+\t  FOR_EACH_BB_REVERSE (bb)\n+\t    if (TEST_BIT (delete[bb->index], j))\n+\t      {\n+\t\tmake_preds_opaque (bb, j);\n+\t\t/* Cancel the 'deleted' mode set.  */\n+\t\tbb_info[j][bb->index].seginfo->mode = no_mode;\n+\t      }\n+\t}\n+\n+      sbitmap_vector_free (delete);\n+      sbitmap_vector_free (insert);\n+      clear_aux_for_edges ();\n+      free_edge_list (edge_list);\n+    }\n+\n+  /* Now output the remaining mode sets in all the segments.  */\n+  for (j = n_entities - 1; j >= 0; j--)\n+    {\n+      int no_mode = num_modes[entity_map[j]];\n+\n+      FOR_EACH_BB_REVERSE (bb)\n+\t{\n+\t  struct seginfo *ptr, *next;\n+\t  for (ptr = bb_info[j][bb->index].seginfo; ptr; ptr = next)\n+\t    {\n+\t      next = ptr->next;\n+\t      if (ptr->mode != no_mode)\n+\t\t{\n+\t\t  rtx mode_set;\n+\n+\t\t  start_sequence ();\n+\t\t  EMIT_MODE_SET (entity_map[j], ptr->mode, ptr->regs_live);\n+\t\t  mode_set = get_insns ();\n+\t\t  end_sequence ();\n+\n+\t\t  /* Insert MODE_SET only if it is nonempty.  */\n+\t\t  if (mode_set != NULL_RTX)\n+\t\t    {\n+\t\t      emited = true;\n+\t\t      if (NOTE_P (ptr->insn_ptr)\n+\t\t\t  && (NOTE_LINE_NUMBER (ptr->insn_ptr)\n+\t\t\t      == NOTE_INSN_BASIC_BLOCK))\n+\t\t\temit_insn_after (mode_set, ptr->insn_ptr);\n+\t\t      else\n+\t\t\temit_insn_before (mode_set, ptr->insn_ptr);\n+\t\t    }\n+\t\t}\n+\n+\t      free (ptr);\n+\t    }\n+\t}\n+\n+      free (bb_info[j]);\n+    }\n+\n+  /* Finished. Free up all the things we've allocated.  */\n+\n+  sbitmap_vector_free (kill);\n+  sbitmap_vector_free (antic);\n+  sbitmap_vector_free (transp);\n+  sbitmap_vector_free (comp);\n+\n+  if (need_commit)\n+    commit_edge_insertions ();\n+\n+#if defined (MODE_ENTRY) && defined (MODE_EXIT)\n+  cleanup_cfg (CLEANUP_NO_INSN_DEL);\n+#else\n+  if (!need_commit && !emited)\n+    return 0;\n+#endif\n+\n+  max_regno = max_reg_num ();\n+  allocate_reg_info (max_regno, FALSE, FALSE);\n+  update_life_info_in_dirty_blocks (UPDATE_LIFE_GLOBAL_RM_NOTES,\n+\t\t\t\t    (PROP_DEATH_NOTES | PROP_KILL_DEAD_CODE\n+\t\t\t\t     | PROP_SCAN_DEAD_CODE));\n+\n+  return 1;\n+}\n+#endif /* OPTIMIZE_MODE_SWITCHING */"}]}