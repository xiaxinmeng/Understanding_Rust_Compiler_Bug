{"sha": "2078550a005f3fde4c331ad4b8452c963c4cdb9d", "node_id": "C_kwDOANBUbNoAKDIwNzg1NTBhMDA1ZjNmZGU0YzMzMWFkNGI4NDUyYzk2M2M0Y2RiOWQ", "commit": {"author": {"name": "Richard Earnshaw", "email": "rearnsha@arm.com", "date": "2021-11-01T13:23:26Z"}, "committer": {"name": "Richard Earnshaw", "email": "rearnsha@arm.com", "date": "2022-01-20T11:15:22Z"}, "message": "arm: suppress aes erratum when forwarding from aes\n\nAES operations are commonly chained and since the result of one AES\noperation is never a 32-bit value, they do not need an additional\nmitigation instruction for the forwarded result.  We handle this\ncommon case by adding additional patterns that allow for this.\n\ngcc/ChangeLog:\n\n\t* config/arm/crypto.md (crypto_<CRYPTO_AESMC:crypto_pattern>_protected):\n\tNew pattern.\n\t(aarch32_crypto_aese_fused_protected): Likewise.\n\t(aarch32_crypto_aesd_fused_protected): Likewise.", "tree": {"sha": "4bbfc900fbfb7bf93d3bc8584e9231618fcab054", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4bbfc900fbfb7bf93d3bc8584e9231618fcab054"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2078550a005f3fde4c331ad4b8452c963c4cdb9d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2078550a005f3fde4c331ad4b8452c963c4cdb9d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2078550a005f3fde4c331ad4b8452c963c4cdb9d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2078550a005f3fde4c331ad4b8452c963c4cdb9d/comments", "author": null, "committer": null, "parents": [{"sha": "bc13384e1956a9bc38b084f82e250743451aae61", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bc13384e1956a9bc38b084f82e250743451aae61", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bc13384e1956a9bc38b084f82e250743451aae61"}], "stats": {"total": 50, "additions": 50, "deletions": 0}, "files": [{"sha": "df857352382bec328f93fbb9cbca198851f2de97", "filename": "gcc/config/arm/crypto.md", "status": "modified", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2078550a005f3fde4c331ad4b8452c963c4cdb9d/gcc%2Fconfig%2Farm%2Fcrypto.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2078550a005f3fde4c331ad4b8452c963c4cdb9d/gcc%2Fconfig%2Farm%2Fcrypto.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcrypto.md?ref=2078550a005f3fde4c331ad4b8452c963c4cdb9d", "patch": "@@ -75,6 +75,20 @@\n   [(set_attr \"type\" \"neon_move_q\")]\n )\n \n+;; An AESMC operation can feed directly into a subsequent AES\n+;; operation without needing mitigation.\n+(define_insn \"*crypto_<CRYPTO_AESMC:crypto_pattern>_protected\"\n+  [(set (match_operand:<crypto_mode> 0 \"register_operand\" \"=w\")\n+\t(unspec:<crypto_mode>\n+\t [(unspec:<crypto_mode>\n+\t   [(match_operand:<crypto_mode> 1 \"register_operand\" \"w\")]\n+\t   CRYPTO_AESMC)]\n+\t UNSPEC_AES_PROTECT))]\n+  \"TARGET_CRYPTO && fix_aes_erratum_1742098\"\n+  \"<crypto_pattern>.<crypto_size_sfx>\\\\t%q0, %q1\"\n+  [(set_attr \"type\" \"<crypto_type>\")]\n+)\n+\n ;; When AESE/AESMC fusion is enabled we really want to keep the two together\n ;; and enforce the register dependency without scheduling or register\n ;; allocation messing up the order or introducing moves inbetween.\n@@ -95,6 +109,25 @@\n    (set_attr \"length\" \"8\")]\n )\n \n+;; And similarly when mitigation is enabled, but not needed in this\n+;; case.\n+(define_insn \"*aarch32_crypto_aese_fused_protected\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=w\")\n+\t(unspec:V16QI\n+\t [(unspec:V16QI\n+\t   [(unspec:V16QI [(xor:V16QI\n+\t\t\t    (match_operand:V16QI 1 \"register_operand\" \"%0\")\n+\t\t\t    (match_operand:V16QI 2 \"register_operand\" \"w\"))]\n+\t     UNSPEC_AESE)]\n+\t   UNSPEC_AESMC)]\n+\t UNSPEC_AES_PROTECT))]\n+  \"TARGET_CRYPTO && fix_aes_erratum_1742098\n+   && arm_fusion_enabled_p (tune_params::FUSE_AES_AESMC)\"\n+  \"aese.8\\\\t%q0, %q2\\;aesmc.8\\\\t%q0, %q0\"\n+  [(set_attr \"type\" \"crypto_aese\")\n+   (set_attr \"length\" \"8\")]\n+)\n+\n ;; When AESD/AESIMC fusion is enabled we really want to keep the two together\n ;; and enforce the register dependency without scheduling or register\n ;; allocation messing up the order or introducing moves inbetween.\n@@ -115,6 +148,23 @@\n    (set_attr \"length\" \"8\")]\n )\n \n+(define_insn \"*aarch32_crypto_aesd_fused_protected\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=w\")\n+\t(unspec:V16QI\n+\t [(unspec:V16QI\n+\t   [(unspec:V16QI [(xor:V16QI\n+\t\t\t    (match_operand:V16QI 1 \"register_operand\" \"%0\")\n+\t\t\t    (match_operand:V16QI 2 \"register_operand\" \"w\"))]\n+\t     UNSPEC_AESD)]\n+\t   UNSPEC_AESIMC)]\n+\t UNSPEC_AES_PROTECT))]\n+  \"TARGET_CRYPTO && fix_aes_erratum_1742098\n+   && arm_fusion_enabled_p (tune_params::FUSE_AES_AESMC)\"\n+  \"aesd.8\\\\t%q0, %q2\\;aesimc.8\\\\t%q0, %q0\"\n+  [(set_attr \"type\" \"crypto_aese\")\n+   (set_attr \"length\" \"8\")]\n+)\n+\n (define_insn \"crypto_<CRYPTO_BINARY:crypto_pattern>\"\n   [(set (match_operand:<crypto_mode> 0 \"register_operand\" \"=w\")\n \t(unspec:<crypto_mode>"}]}