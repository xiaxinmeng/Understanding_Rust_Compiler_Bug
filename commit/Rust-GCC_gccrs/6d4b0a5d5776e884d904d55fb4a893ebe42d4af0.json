{"sha": "6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NmQ0YjBhNWQ1Nzc2ZTg4NGQ5MDRkNTVmYjRhODkzZWJlNDJkNGFmMA==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2004-01-26T22:57:19Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2004-01-26T22:57:19Z"}, "message": "c-parse.in (extension): Use itype.\n\n        * c-parse.in (extension): Use itype.\n        (SAVE_EXT_FLAGS): Don't allocate a tree.\n        (RESTORE_EXT_FLAGS): Don't read a tree.\n\nFrom-SVN: r76674", "tree": {"sha": "6ad2a5fec27d82b846c6968e407efd9ffcd30d66", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6ad2a5fec27d82b846c6968e407efd9ffcd30d66"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/comments", "author": null, "committer": null, "parents": [{"sha": "32e7d1e9bbcc2e125037c04f752f2a8ab33696be", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/32e7d1e9bbcc2e125037c04f752f2a8ab33696be", "html_url": "https://github.com/Rust-GCC/gccrs/commit/32e7d1e9bbcc2e125037c04f752f2a8ab33696be"}], "stats": {"total": 194, "additions": 164, "deletions": 30}, "files": [{"sha": "c05b347dce716ada57d5d974dec2e797389f1d90", "filename": "gcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "patch": "@@ -1,3 +1,9 @@\n+2004-01-26  Richard Henderson  <rth@redhat.com>\n+\n+\t* c-parse.in (extension): Use itype.\n+\t(SAVE_EXT_FLAGS): Don't allocate a tree.\n+\t(RESTORE_EXT_FLAGS): Don't read a tree.\n+\n 2004-01-26  Jan Hubicka  <jh@suse.cz>\n \n \t* cselib.c (discard_useless_values):  Clear out value pointer pointing"}, {"sha": "6ec7db7f2647a4b5fbe77f8bce64525c8a022152", "filename": "gcc/ggc-common.c", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2Fggc-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2Fggc-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc-common.c?ref=6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "patch": "@@ -147,6 +147,11 @@ ggc_realloc (void *x, size_t size)\n     return ggc_alloc (size);\n \n   old_size = ggc_get_size (x);\n+\n+#ifndef ENABLE_GC_ALWAYS_COLLECT\n+  /* In completely-anal-checking mode, never re-use memory.  This maximizes\n+     the chance of catching the user retaining a pointer to the old block.\n+     Otherwise, we get to consume the power-of-two overhead we had before.  */\n   if (size <= old_size)\n     {\n       /* Mark the unwanted memory as unaccessible.  We also need to make\n@@ -164,6 +169,7 @@ ggc_realloc (void *x, size_t size)\n       VALGRIND_DISCARD (VALGRIND_MAKE_READABLE (x, size));\n       return x;\n     }\n+#endif\n \n   r = ggc_alloc (size);\n \n@@ -176,7 +182,7 @@ ggc_realloc (void *x, size_t size)\n   memcpy (r, x, old_size);\n \n   /* The old object is not supposed to be used anymore.  */\n-  VALGRIND_DISCARD (VALGRIND_MAKE_NOACCESS (x, old_size));\n+  ggc_free (x);\n \n   return r;\n }"}, {"sha": "1c625e6f017e12fa2afc8eb77614624ac8c640b8", "filename": "gcc/ggc-page.c", "status": "modified", "additions": 149, "deletions": 29, "changes": 178, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2Fggc-page.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2Fggc-page.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc-page.c?ref=6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "patch": "@@ -401,6 +401,17 @@ static struct globals\n      zero otherwise.  We allocate them all together, to enable a\n      better runtime data access pattern.  */\n   unsigned long **save_in_use;\n+\n+#ifdef ENABLE_GC_ALWAYS_COLLECT\n+  /* List of free objects to be verified as actually free on the\n+     next collection.  */\n+  struct free_object\n+  {\n+    void *object;\n+    struct free_object *next;\n+  } *free_object_list;\n+#endif\n+\n #ifdef GATHER_STATISTICS\n   struct\n   {\n@@ -894,7 +905,7 @@ adjust_depth (void)\n \n /* For a page that is no longer needed, put it on the free page list.  */\n \n-static inline void\n+static void\n free_page (page_entry *entry)\n {\n   if (GGC_DEBUG_LEVEL >= 2)\n@@ -1049,16 +1060,19 @@ ggc_alloc_zone (size_t size, struct alloc_zone *zone ATTRIBUTE_UNUSED)\n void *\n ggc_alloc (size_t size)\n {\n-  unsigned order, word, bit, object_offset;\n+  size_t order, word, bit, object_offset, object_size;\n   struct page_entry *entry;\n   void *result;\n \n   if (size <= 256)\n-    order = size_lookup[size];\n+    {\n+      order = size_lookup[size];\n+      object_size = OBJECT_SIZE (order);\n+    }\n   else\n     {\n       order = 9;\n-      while (size > OBJECT_SIZE (order))\n+      while (size > (object_size = OBJECT_SIZE (order)))\n \torder++;\n     }\n \n@@ -1121,7 +1135,7 @@ ggc_alloc (size_t size)\n       /* Next time, try the next bit.  */\n       entry->next_bit_hint = hint + 1;\n \n-      object_offset = hint * OBJECT_SIZE (order);\n+      object_offset = hint * object_size;\n     }\n \n   /* Set the in-use bit.  */\n@@ -1149,16 +1163,16 @@ ggc_alloc (size_t size)\n      exact same semantics in presence of memory bugs, regardless of\n      ENABLE_VALGRIND_CHECKING.  We override this request below.  Drop the\n      handle to avoid handle leak.  */\n-  VALGRIND_DISCARD (VALGRIND_MAKE_WRITABLE (result, OBJECT_SIZE (order)));\n+  VALGRIND_DISCARD (VALGRIND_MAKE_WRITABLE (result, object_size));\n \n   /* `Poison' the entire allocated object, including any padding at\n      the end.  */\n-  memset (result, 0xaf, OBJECT_SIZE (order));\n+  memset (result, 0xaf, object_size);\n \n   /* Make the bytes after the end of the object unaccessible.  Discard the\n      handle to avoid handle leak.  */\n   VALGRIND_DISCARD (VALGRIND_MAKE_NOACCESS ((char *) result + size,\n-\t\t\t\t\t    OBJECT_SIZE (order) - size));\n+\t\t\t\t\t    object_size - size));\n #endif\n \n   /* Tell Valgrind that the memory is there, but its content isn't\n@@ -1168,37 +1182,39 @@ ggc_alloc (size_t size)\n \n   /* Keep track of how many bytes are being allocated.  This\n      information is used in deciding when to collect.  */\n-  G.allocated += OBJECT_SIZE (order);\n+  G.allocated += object_size;\n \n #ifdef GATHER_STATISTICS\n   {\n-    G.stats.total_overhead += OBJECT_SIZE (order) - size;\n-    G.stats.total_allocated += OBJECT_SIZE(order);\n-    G.stats.total_overhead_per_order[order] += OBJECT_SIZE (order) - size;\n-    G.stats.total_allocated_per_order[order] += OBJECT_SIZE (order);\n-\n-    if (size <= 32){\n-      G.stats.total_overhead_under32 += OBJECT_SIZE (order) - size;\n-      G.stats.total_allocated_under32 += OBJECT_SIZE(order);\n-    }\n+    size_t overhead = object_size - size;\n \n-    if (size <= 64){\n-      G.stats.total_overhead_under64 += OBJECT_SIZE (order) - size;\n-      G.stats.total_allocated_under64 += OBJECT_SIZE(order);\n-    }\n-  \n-    if (size <= 128){\n-      G.stats.total_overhead_under128 += OBJECT_SIZE (order) - size;\n-      G.stats.total_allocated_under128 += OBJECT_SIZE(order);\n-    }\n+    G.stats.total_overhead += overhead;\n+    G.stats.total_allocated += object_size;\n+    G.stats.total_overhead_per_order[order] += overhead;\n+    G.stats.total_allocated_per_order[order] += object_size;\n \n+    if (size <= 32)\n+      {\n+\tG.stats.total_overhead_under32 += overhead;\n+\tG.stats.total_allocated_under32 += object_size;\n+      }\n+    if (size <= 64)\n+      {\n+\tG.stats.total_overhead_under64 += overhead;\n+\tG.stats.total_allocated_under64 += object_size;\n+      }\n+    if (size <= 128)\n+      {\n+\tG.stats.total_overhead_under128 += overhead;\n+\tG.stats.total_allocated_under128 += object_size;\n+      }\n   }\n #endif\n-  \n+\n   if (GGC_DEBUG_LEVEL >= 3)\n     fprintf (G.debug_file,\n \t     \"Allocating object, requested size=%lu, actual=%lu at %p on %p\\n\",\n-\t     (unsigned long) size, (unsigned long) OBJECT_SIZE (order), result,\n+\t     (unsigned long) size, (unsigned long) object_size, result,\n \t     (void *) entry);\n \n   return result;\n@@ -1279,6 +1295,78 @@ ggc_get_size (const void *p)\n   page_entry *pe = lookup_page_table_entry (p);\n   return OBJECT_SIZE (pe->order);\n }\n+\n+/* Release the memory for object P.  */\n+\n+void\n+ggc_free (void *p)\n+{\n+  page_entry *pe = lookup_page_table_entry (p);\n+  size_t order = pe->order;\n+  size_t size = OBJECT_SIZE (order);\n+\n+  if (GGC_DEBUG_LEVEL >= 3)\n+    fprintf (G.debug_file,\n+\t     \"Freeing object, actual size=%lu, at %p on %p\\n\",\n+\t     (unsigned long) size, p, (void *) pe);\n+\n+#ifdef ENABLE_GC_CHECKING\n+  /* Poison the data, to indicate the data is garbage.  */\n+  VALGRIND_DISCARD (VALGRIND_MAKE_WRITABLE (p, size));\n+  memset (p, 0xa5, size);\n+#endif\n+  /* Let valgrind know the object is free.  */\n+  VALGRIND_DISCARD (VALGRIND_MAKE_NOACCESS (p, size));\n+\n+#ifdef ENABLE_GC_ALWAYS_COLLECT\n+  /* In the completely-anal-checking mode, we do *not* immediately free\n+     the data, but instead verify that the data is *actually* not \n+     reachable the next time we collect.  */\n+  {\n+    struct free_object *fo = xmalloc (sizeof (struct free_object));\n+    fo->object = p;\n+    fo->next = G.free_object_list;\n+    G.free_object_list = fo;\n+  }\n+#else\n+  {\n+    unsigned int bit_offset, word, bit;\n+\n+    G.allocated -= size;\n+\n+    /* Mark the object not-in-use.  */\n+    bit_offset = OFFSET_TO_BIT (((const char *) p) - pe->page, order);\n+    word = bit_offset / HOST_BITS_PER_LONG;\n+    bit = bit_offset % HOST_BITS_PER_LONG;\n+    pe->in_use_p[word] &= ~(1UL << bit);\n+\n+    if (pe->num_free_objects++ == 0)\n+      {\n+\t/* If the page is completely full, then it's supposed to\n+\t   be after all pages that aren't.  Since we've freed one\n+\t   object from a page that was full, we need to move the\n+\t   page to the head of the list.  */\n+\n+\tpage_entry *p, *q;\n+\tfor (q = NULL, p = G.pages[order]; ; q = p, p = p->next)\n+\t  if (p == pe)\n+\t    break;\n+\tif (q && q->num_free_objects == 0)\n+\t  {\n+\t    p = pe->next;\n+\t    q->next = p;\n+\t    if (!p)\n+\t      G.page_tails[order] = q;\n+\t    pe->next = G.pages[order];\n+\t    G.pages[order] = pe;\n+\t  }\n+\n+\t/* Reset the hint bit to point to the only free object.  */\n+\tpe->next_bit_hint = bit_offset;\n+      }\n+  }\n+#endif\n+}\n \f\n /* Subroutine of init_ggc which computes the pair of numbers used to\n    perform division by OBJECT_SIZE (order) and fills in inverse_table[].\n@@ -1788,6 +1876,8 @@ ggc_collect (void)\n   timevar_push (TV_GC);\n   if (!quiet_flag)\n     fprintf (stderr, \" {GC %luk -> \", (unsigned long) G.allocated / 1024);\n+  if (GGC_DEBUG_LEVEL >= 2)\n+    fprintf (G.debug_file, \"BEGIN COLLECTING\\n\");\n \n   /* Zero the total allocated bytes.  This will be recalculated in the\n      sweep phase.  */\n@@ -1809,12 +1899,42 @@ ggc_collect (void)\n \n   sweep_pages ();\n \n+#ifdef ENABLE_GC_ALWAYS_COLLECT\n+  /* Validate that the reportedly free objects actually are.  */\n+  {\n+    struct free_object *f, *n;\n+    for (f = G.free_object_list; f ; f = n)\n+      {\n+\tpage_entry *pe = lookup_page_table_entry (f->object);\n+\n+\t/* If the page entry is null, that means the entire page is free.\n+\t   Otherwise, we have to examine the in-use bit for the object.  */\n+\tif (pe != NULL)\n+\t  {\n+\t    size_t bit, word;\n+\t    bit = OFFSET_TO_BIT ((char *)f->object - pe->page, pe->order);\n+\t    word = bit / HOST_BITS_PER_LONG;\n+\t    bit = bit % HOST_BITS_PER_LONG;\n+\n+\t    if (pe->in_use_p[word] & (1UL << bit))\n+\t      abort ();\n+\t  }\n+\n+\tn = f->next;\n+\tfree (f);\n+      }\n+    G.free_object_list = NULL;\n+  }\n+#endif\n+\n   G.allocated_last_gc = G.allocated;\n \n   timevar_pop (TV_GC);\n \n   if (!quiet_flag)\n     fprintf (stderr, \"%luk}\", (unsigned long) G.allocated / 1024);\n+  if (GGC_DEBUG_LEVEL >= 2)\n+    fprintf (G.debug_file, \"END COLLECTING\\n\");\n }\n \n /* Print allocation statistics.  */"}, {"sha": "fbd1e3489e2a3bc35b190f16ea2c00db233bcb6c", "filename": "gcc/ggc.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2Fggc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6d4b0a5d5776e884d904d55fb4a893ebe42d4af0/gcc%2Fggc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc.h?ref=6d4b0a5d5776e884d904d55fb4a893ebe42d4af0", "patch": "@@ -223,6 +223,8 @@ extern void *ggc_alloc_cleared_zone (size_t, struct alloc_zone *);\n extern void *ggc_realloc (void *, size_t);\n /* Like ggc_alloc_cleared, but performs a multiplication.  */\n extern void *ggc_calloc (size_t, size_t);\n+/* Free a block.  To be used when known for certain it's not reachable.  */\n+extern void ggc_free (void *);\n \n #define ggc_alloc_rtx(CODE)                    \\\n   ((rtx) ggc_alloc_typed (gt_ggc_e_7rtx_def, RTX_SIZE (CODE)))"}]}