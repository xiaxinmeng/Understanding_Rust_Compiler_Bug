{"sha": "6c5d4d1a023fcf403eca657ac451c6c7e92019e1", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NmM1ZDRkMWEwMjNmY2Y0MDNlY2E2NTdhYzQ1MWM2YzdlOTIwMTllMQ==", "commit": {"author": {"name": "Steven Bosscher", "email": "steven@gcc.gnu.org", "date": "2009-05-01T20:22:56Z"}, "committer": {"name": "Steven Bosscher", "email": "steven@gcc.gnu.org", "date": "2009-05-01T20:22:56Z"}, "message": "store-motion.c: Many cleanups to make this pass a first-class citizen instead of an appendix to...\n\n\t* store-motion.c: Many cleanups to make this pass a first-class\n\tcitizen instead of an appendix to gcse load motion.  Add TODO list\n\tto make this pass faster/cleaner/better.\n\n\t(struct ls_expr): Post gcse.c-split cleanups.\n\tRename to st_expr.  Rename \"loads\" field to \"antic_stores\".  Rename\n\t\"stores\" field to \"avail_stores\".\n\t(pre_ldst_mems): Rename to store_motion_mems.\n\t(pre_ldst_table): Rename to store_motion_mems_table.\n\t(pre_ldst_expr_hash): Rename to pre_st_expr_hash, update users.\n\t(pre_ldst_expr_eq): Rename to pre_st_expr_eq, update users.\n\t(ldst_entry): Rename to st_expr_entry, update users.\n\t(free_ldst_entry): Rename to free_st_expr_entry, update users.\n\t(free_ldst_mems): Rename to free_store_motion_mems, update users.\n\t(enumerate_ldsts): Rename to enumerate_store_motion_mems, update caller.\n\t(first_ls_expr): Rename to first_st_expr, update users.\n\t(next_ls_expr): Rename to next_st_expr, update users.\n\t(print_ldst_list): Rename to print_store_motion_mems.  Print names of\n\tfields properly for store motion instead of names inherited from load\n\tmotion in gcse.c.\n\t(ANTIC_STORE_LIST, AVAIL_STORE_LIST): Remove.\n\t(LAST_AVAIL_CHECK_FAILURE): Explain what this is.  Undefine when we\n\tare done with it.\n\n\t(ae_kill): Rename to st_kill, update users.\n\t(ae_gen): Rename to st_avloc, update users.\n\t(transp): Rename to st_transp, update users.\n\t(pre_insert_map): Rename to st_insert_map, update users.\n\t(pre_delete_map): Rename to st_delete_map, update users.\n\t(insert_store, build_store_vectors, free_store_memory,\n\tone_store_motion_pass): Update for abovementioned changes.\n\n\t(gcse_subst_count, gcse_create_count): Remove.\n\t(one_store_motion_pass): New statistics counters \"n_stores_deleted\"\n\tand \"n_stores_created\", local variables.\n\n\t(extract_mentioned_regs, extract_mentioned_regs_1): Rewrite to\n\tuse for_each_rtx.\n\n\t(regvec, compute_store_table_current_insn): Remove.\n\t(reg_set_info, reg_clear_last_set): Remove.\n\t(compute_store_table): Use DF caches instead of local dataflow\n\tsolvers.\n\nFrom-SVN: r147034", "tree": {"sha": "d32ac06ec8236ef92384983844b497ac44e5264c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d32ac06ec8236ef92384983844b497ac44e5264c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/6c5d4d1a023fcf403eca657ac451c6c7e92019e1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6c5d4d1a023fcf403eca657ac451c6c7e92019e1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6c5d4d1a023fcf403eca657ac451c6c7e92019e1", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6c5d4d1a023fcf403eca657ac451c6c7e92019e1/comments", "author": null, "committer": null, "parents": [{"sha": "b02cec6ee663faf0f8b84d22a23d87a47d0d48c7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b02cec6ee663faf0f8b84d22a23d87a47d0d48c7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b02cec6ee663faf0f8b84d22a23d87a47d0d48c7"}], "stats": {"total": 650, "additions": 277, "deletions": 373}, "files": [{"sha": "877b8a12538194f7d050d9422bafc6cac724b83e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 46, "deletions": 0, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6c5d4d1a023fcf403eca657ac451c6c7e92019e1/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6c5d4d1a023fcf403eca657ac451c6c7e92019e1/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=6c5d4d1a023fcf403eca657ac451c6c7e92019e1", "patch": "@@ -1,3 +1,49 @@\n+2009-05-01  Steven Bosscher  <steven@gcc.gnu.org>\n+\n+\t* store-motion.c: Many cleanups to make this pass a first-class\n+\tcitizen instead of an appendix to gcse load motion.  Add TODO list\n+\tto make this pass faster/cleaner/better.\n+\n+\t(struct ls_expr): Post gcse.c-split cleanups.\n+\tRename to st_expr.  Rename \"loads\" field to \"antic_stores\".  Rename\n+\t\"stores\" field to \"avail_stores\".\n+\t(pre_ldst_mems): Rename to store_motion_mems.\n+\t(pre_ldst_table): Rename to store_motion_mems_table.\n+\t(pre_ldst_expr_hash): Rename to pre_st_expr_hash, update users.\n+\t(pre_ldst_expr_eq): Rename to pre_st_expr_eq, update users.\n+\t(ldst_entry): Rename to st_expr_entry, update users.\n+\t(free_ldst_entry): Rename to free_st_expr_entry, update users.\n+\t(free_ldst_mems): Rename to free_store_motion_mems, update users.\n+\t(enumerate_ldsts): Rename to enumerate_store_motion_mems, update caller.\n+\t(first_ls_expr): Rename to first_st_expr, update users.\n+\t(next_ls_expr): Rename to next_st_expr, update users.\n+\t(print_ldst_list): Rename to print_store_motion_mems.  Print names of\n+\tfields properly for store motion instead of names inherited from load\n+\tmotion in gcse.c.\n+\t(ANTIC_STORE_LIST, AVAIL_STORE_LIST): Remove.\n+\t(LAST_AVAIL_CHECK_FAILURE): Explain what this is.  Undefine when we\n+\tare done with it.\n+\n+\t(ae_kill): Rename to st_kill, update users.\n+\t(ae_gen): Rename to st_avloc, update users.\n+\t(transp): Rename to st_transp, update users.\n+\t(pre_insert_map): Rename to st_insert_map, update users.\n+\t(pre_delete_map): Rename to st_delete_map, update users.\n+\t(insert_store, build_store_vectors, free_store_memory,\n+\tone_store_motion_pass): Update for abovementioned changes.\n+\n+\t(gcse_subst_count, gcse_create_count): Remove.\n+\t(one_store_motion_pass): New statistics counters \"n_stores_deleted\"\n+\tand \"n_stores_created\", local variables.\n+\n+\t(extract_mentioned_regs, extract_mentioned_regs_1): Rewrite to\n+\tuse for_each_rtx.\n+\n+\t(regvec, compute_store_table_current_insn): Remove.\n+\t(reg_set_info, reg_clear_last_set): Remove.\n+\t(compute_store_table): Use DF caches instead of local dataflow\n+\tsolvers.\n+\n 2009-05-01  Joseph Myers  <joseph@codesourcery.com>\n \n \t* c-objc-common.c (c_tree_printer): Print identifiers with"}, {"sha": "7ff0ac69dc60043afc0ab7842f4145930ef3e841", "filename": "gcc/store-motion.c", "status": "modified", "additions": 231, "deletions": 373, "changes": 604, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6c5d4d1a023fcf403eca657ac451c6c7e92019e1/gcc%2Fstore-motion.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6c5d4d1a023fcf403eca657ac451c6c7e92019e1/gcc%2Fstore-motion.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstore-motion.c?ref=6c5d4d1a023fcf403eca657ac451c6c7e92019e1", "patch": "@@ -47,224 +47,208 @@ along with GCC; see the file COPYING3.  If not see\n #include \"df.h\"\n #include \"dbgcnt.h\"\n \n-\f\n-/* This is a list of expressions which are MEMs and will be used by load\n-   or store motion.\n-   Load motion tracks MEMs which aren't killed by\n-   anything except itself. (i.e., loads and stores to a single location).\n-   We can then allow movement of these MEM refs with a little special\n-   allowance. (all stores copy the same value to the reaching reg used\n-   for the loads).  This means all values used to store into memory must have\n-   no side effects so we can re-issue the setter value.\n-   Store Motion uses this structure as an expression table to track stores\n-   which look interesting, and might be moveable towards the exit block.  */\n-\n-struct ls_expr\n+/* This pass implements downward store motion.\n+   As of May 1, 2009, the pass is not enabled by default on any target,\n+   but bootstrap completes on ia64 and x86_64 with the pass enabled.  */\n+\n+/* TODO:\n+   - remove_reachable_equiv_notes is an incomprehensible pile of goo and\n+     a compile time hog that needs a rewrite (maybe cache st_exprs to\n+     invalidate REG_EQUAL/REG_EQUIV notes for?).\n+   - pattern_regs in st_expr should be a regset (on its own obstack).\n+   - antic_stores and avail_stores should be VECs instead of lists.\n+   - store_motion_mems should be a VEC instead of a list.\n+   - there should be an alloc pool for struct st_expr objects.\n+   - investigate whether it is helpful to make the address of an st_expr\n+     a cselib VALUE.\n+   - when GIMPLE alias information is exported, the effectiveness of this\n+     pass should be re-evaluated.\n+*/\n+\n+/* This is a list of store expressions (MEMs).  The structure is used\n+   as an expression table to track stores which look interesting, and\n+   might be moveable towards the exit block.  */\n+\n+struct st_expr\n {\n-  rtx pattern;\t\t\t/* Pattern of this mem.  */\n-  rtx pattern_regs;\t\t/* List of registers mentioned by the mem.  */\n-  rtx loads;\t\t\t/* INSN list of loads seen.  */\n-  rtx stores;\t\t\t/* INSN list of stores seen.  */\n-  struct ls_expr * next;\t/* Next in the list.  */\n-  int invalid;\t\t\t/* Invalid for some reason.  */\n-  int index;\t\t\t/* If it maps to a bitmap index.  */\n-  unsigned int hash_index;\t/* Index when in a hash table.  */\n-  rtx reaching_reg;\t\t/* Register to use when re-writing.  */\n+  /* Pattern of this mem.  */\n+  rtx pattern;\n+  /* List of registers mentioned by the mem.  */\n+  rtx pattern_regs;\n+  /* INSN list of stores that are locally anticipatable.  */\n+  rtx antic_stores;\n+  /* INSN list of stores that are locally available.  */\n+  rtx avail_stores;\n+  /* Next in the list.  */\n+  struct st_expr * next;\n+  /* Store ID in the dataflow bitmaps.  */\n+  int index;\n+  /* Hash value for the hash table.  */\n+  unsigned int hash_index;\n+  /* Register holding the stored expression when a store is moved.\n+     This field is also used as a cache in find_moveable_store, see\n+     LAST_AVAIL_CHECK_FAILURE below.  */\n+  rtx reaching_reg;\n };\n \n /* Head of the list of load/store memory refs.  */\n-static struct ls_expr * pre_ldst_mems = NULL;\n+static struct st_expr * store_motion_mems = NULL;\n \n /* Hashtable for the load/store memory refs.  */\n-static htab_t pre_ldst_table = NULL;\n-\n-/* Various variables for statistics gathering.  */\n+static htab_t store_motion_mems_table = NULL;\n \n-/* GCSE substitutions made.  */\n-static int gcse_subst_count;\n-/* Number of copy instructions created.  */\n-static int gcse_create_count;\n-/* For available exprs */\n-static sbitmap *ae_kill, *ae_gen;\n-\f\n-/* Nonzero for expressions that are transparent in the block.  */\n-static sbitmap *transp;\n+/* These bitmaps will hold the local dataflow properties per basic block.  */\n+static sbitmap *st_kill, *st_avloc, *st_antloc, *st_transp;\n \n /* Nonzero for expressions which should be inserted on a specific edge.  */\n-static sbitmap *pre_insert_map;\n+static sbitmap *st_insert_map;\n \n /* Nonzero for expressions which should be deleted in a specific block.  */\n-static sbitmap *pre_delete_map;\n+static sbitmap *st_delete_map;\n+\n+/* Global holding the number of store expressions we are dealing with.  */\n+static int num_stores;\n \n /* Contains the edge_list returned by pre_edge_lcm.  */\n static struct edge_list *edge_list;\n \n-/*  Here we provide the things required to do store motion towards\n-    the exit. In order for this to be effective, PRE load motion also needed\n-    to be taught how to move a load when it is kill only by a store to itself.\n-\n-\t    int i;\n-\t    float a[10];\n-\n-\t    void foo(float scale)\n-\t    {\n-\t      for (i=0; i<10; i++)\n-\t\ta[i] *= scale;\n-\t    }\n-\n-    'i' is both loaded and stored to in the loop. Normally, gcse cannot move\n-    the load out since its live around the loop, and stored at the bottom\n-    of the loop.\n-\n-      The 'Load Motion' referred to and implemented in this file is\n-    an enhancement to gcse which when using edge based lcm, recognizes\n-    this situation and allows gcse to move the load out of the loop.\n-\n-      Once gcse has hoisted the load, store motion can then push this\n-    load towards the exit, and we end up with no loads or stores of 'i'\n-    in the loop.  */\n-\n static hashval_t\n-pre_ldst_expr_hash (const void *p)\n+pre_st_expr_hash (const void *p)\n {\n   int do_not_record_p = 0;\n-  const struct ls_expr *const x = (const struct ls_expr *) p;\n+  const struct st_expr *const x = (const struct st_expr *) p;\n   return hash_rtx (x->pattern, GET_MODE (x->pattern), &do_not_record_p, NULL, false);\n }\n \n static int\n-pre_ldst_expr_eq (const void *p1, const void *p2)\n+pre_st_expr_eq (const void *p1, const void *p2)\n {\n-  const struct ls_expr *const ptr1 = (const struct ls_expr *) p1,\n-    *const ptr2 = (const struct ls_expr *) p2;\n+  const struct st_expr *const ptr1 = (const struct st_expr *) p1,\n+    *const ptr2 = (const struct st_expr *) p2;\n   return exp_equiv_p (ptr1->pattern, ptr2->pattern, 0, true);\n }\n \n-/* This will search the ldst list for a matching expression. If it\n+/* This will search the st_expr list for a matching expression. If it\n    doesn't find one, we create one and initialize it.  */\n \n-static struct ls_expr *\n-ldst_entry (rtx x)\n+static struct st_expr *\n+st_expr_entry (rtx x)\n {\n   int do_not_record_p = 0;\n-  struct ls_expr * ptr;\n+  struct st_expr * ptr;\n   unsigned int hash;\n   void **slot;\n-  struct ls_expr e;\n+  struct st_expr e;\n \n   hash = hash_rtx (x, GET_MODE (x), &do_not_record_p,\n \t\t   NULL,  /*have_reg_qty=*/false);\n \n   e.pattern = x;\n-  slot = htab_find_slot_with_hash (pre_ldst_table, &e, hash, INSERT);\n+  slot = htab_find_slot_with_hash (store_motion_mems_table, &e, hash, INSERT);\n   if (*slot)\n-    return (struct ls_expr *)*slot;\n+    return (struct st_expr *)*slot;\n \n-  ptr = XNEW (struct ls_expr);\n+  ptr = XNEW (struct st_expr);\n \n-  ptr->next         = pre_ldst_mems;\n+  ptr->next         = store_motion_mems;\n   ptr->pattern      = x;\n   ptr->pattern_regs = NULL_RTX;\n-  ptr->loads        = NULL_RTX;\n-  ptr->stores       = NULL_RTX;\n+  ptr->antic_stores = NULL_RTX;\n+  ptr->avail_stores = NULL_RTX;\n   ptr->reaching_reg = NULL_RTX;\n-  ptr->invalid      = 0;\n   ptr->index        = 0;\n   ptr->hash_index   = hash;\n-  pre_ldst_mems     = ptr;\n+  store_motion_mems = ptr;\n   *slot = ptr;\n \n   return ptr;\n }\n \n-/* Free up an individual ldst entry.  */\n+/* Free up an individual st_expr entry.  */\n \n static void\n-free_ldst_entry (struct ls_expr * ptr)\n+free_st_expr_entry (struct st_expr * ptr)\n {\n-  free_INSN_LIST_list (& ptr->loads);\n-  free_INSN_LIST_list (& ptr->stores);\n+  free_INSN_LIST_list (& ptr->antic_stores);\n+  free_INSN_LIST_list (& ptr->avail_stores);\n \n   free (ptr);\n }\n \n-/* Free up all memory associated with the ldst list.  */\n+/* Free up all memory associated with the st_expr list.  */\n \n static void\n-free_ldst_mems (void)\n+free_store_motion_mems (void)\n {\n-  if (pre_ldst_table)\n-    htab_delete (pre_ldst_table);\n-  pre_ldst_table = NULL;\n+  if (store_motion_mems_table)\n+    htab_delete (store_motion_mems_table);\n+  store_motion_mems_table = NULL;\n \n-  while (pre_ldst_mems)\n+  while (store_motion_mems)\n     {\n-      struct ls_expr * tmp = pre_ldst_mems;\n-\n-      pre_ldst_mems = pre_ldst_mems->next;\n-\n-      free_ldst_entry (tmp);\n+      struct st_expr * tmp = store_motion_mems;\n+      store_motion_mems = store_motion_mems->next;\n+      free_st_expr_entry (tmp);\n     }\n-\n-  pre_ldst_mems = NULL;\n+  store_motion_mems = NULL;\n }\n \n /* Assign each element of the list of mems a monotonically increasing value.  */\n \n static int\n-enumerate_ldsts (void)\n+enumerate_store_motion_mems (void)\n {\n-  struct ls_expr * ptr;\n+  struct st_expr * ptr;\n   int n = 0;\n \n-  for (ptr = pre_ldst_mems; ptr != NULL; ptr = ptr->next)\n+  for (ptr = store_motion_mems; ptr != NULL; ptr = ptr->next)\n     ptr->index = n++;\n \n   return n;\n }\n \n /* Return first item in the list.  */\n \n-static inline struct ls_expr *\n-first_ls_expr (void)\n+static inline struct st_expr *\n+first_st_expr (void)\n {\n-  return pre_ldst_mems;\n+  return store_motion_mems;\n }\n \n /* Return the next item in the list after the specified one.  */\n \n-static inline struct ls_expr *\n-next_ls_expr (struct ls_expr * ptr)\n+static inline struct st_expr *\n+next_st_expr (struct st_expr * ptr)\n {\n   return ptr->next;\n }\n \n-/* Dump debugging info about the ldst list.  */\n+/* Dump debugging info about the store_motion_mems list.  */\n \n static void\n-print_ldst_list (FILE * file)\n+print_store_motion_mems (FILE * file)\n {\n-  struct ls_expr * ptr;\n+  struct st_expr * ptr;\n \n-  fprintf (file, \"LDST list: \\n\");\n+  fprintf (dump_file, \"STORE_MOTION list of MEM exprs considered:\\n\");\n \n-  for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n+  for (ptr = first_st_expr (); ptr != NULL; ptr = next_st_expr (ptr))\n     {\n       fprintf (file, \"  Pattern (%3d): \", ptr->index);\n \n       print_rtl (file, ptr->pattern);\n \n-      fprintf (file, \"\\n\t Loads : \");\n+      fprintf (file, \"\\n\t ANTIC stores : \");\n \n-      if (ptr->loads)\n-\tprint_rtl (file, ptr->loads);\n+      if (ptr->antic_stores)\n+\tprint_rtl (file, ptr->antic_stores);\n       else\n \tfprintf (file, \"(nil)\");\n \n-      fprintf (file, \"\\n\tStores : \");\n+      fprintf (file, \"\\n\t AVAIL stores : \");\n \n-      if (ptr->stores)\n-\tprint_rtl (file, ptr->stores);\n+      if (ptr->avail_stores)\n+\tprint_rtl (file, ptr->avail_stores);\n       else\n \tfprintf (file, \"(nil)\");\n \n@@ -274,56 +258,6 @@ print_ldst_list (FILE * file)\n   fprintf (file, \"\\n\");\n }\n \f\n-/* Store motion code.  */\n-\n-#define ANTIC_STORE_LIST(x)\t\t((x)->loads)\n-#define AVAIL_STORE_LIST(x)\t\t((x)->stores)\n-#define LAST_AVAIL_CHECK_FAILURE(x)\t((x)->reaching_reg)\n-\n-/* This is used to communicate the target bitvector we want to use in the\n-   reg_set_info routine when called via the note_stores mechanism.  */\n-static int * regvec;\n-\n-/* And current insn, for the same routine.  */\n-static rtx compute_store_table_current_insn;\n-\n-/* Used in computing the reverse edge graph bit vectors.  */\n-static sbitmap * st_antloc;\n-\n-/* Global holding the number of store expressions we are dealing with.  */\n-static int num_stores;\n-\n-/* Checks to set if we need to mark a register set.  Called from\n-   note_stores.  */\n-\n-static void\n-reg_set_info (rtx dest, const_rtx setter ATTRIBUTE_UNUSED,\n-\t      void *data ATTRIBUTE_UNUSED)\n-{\n-  if (GET_CODE (dest) == SUBREG)\n-    dest = SUBREG_REG (dest);\n-\n-  if (REG_P (dest))\n-    regvec[REGNO (dest)] = INSN_UID (compute_store_table_current_insn);\n-}\n-\n-/* Clear any mark that says that this insn sets dest.  Called from\n-   note_stores.  */\n-\n-static void\n-reg_clear_last_set (rtx dest, const_rtx setter ATTRIBUTE_UNUSED,\n-\t      void *data)\n-{\n-  int *dead_vec = (int *) data;\n-\n-  if (GET_CODE (dest) == SUBREG)\n-    dest = SUBREG_REG (dest);\n-\n-  if (REG_P (dest) &&\n-      dead_vec[REGNO (dest)] == INSN_UID (compute_store_table_current_insn))\n-    dead_vec[REGNO (dest)] = 0;\n-}\n-\n /* Return zero if some of the registers in list X are killed\n    due to set of registers in bitmap REGS_SET.  */\n \n@@ -342,94 +276,28 @@ store_ops_ok (const_rtx x, int *regs_set)\n   return true;\n }\n \n-/* Helper for extract_mentioned_regs; ACCUM is used to accumulate used\n-   registers.  */\n-static rtx\n-extract_mentioned_regs_helper (rtx x, rtx accum)\n+/* Helper for extract_mentioned_regs.  */\n+ \n+static int\n+extract_mentioned_regs_1 (rtx *loc, void *data)\n {\n-  int i;\n-  enum rtx_code code;\n-  const char * fmt;\n-\n-  /* Repeat is used to turn tail-recursion into iteration.  */\n- repeat:\n-\n-  if (x == 0)\n-    return accum;\n-\n-  code = GET_CODE (x);\n-  switch (code)\n-    {\n-    case REG:\n-      return alloc_EXPR_LIST (0, x, accum);\n-\n-    case MEM:\n-      x = XEXP (x, 0);\n-      goto repeat;\n-\n-    case PRE_DEC:\n-    case PRE_INC:\n-    case PRE_MODIFY:\n-    case POST_DEC:\n-    case POST_INC:\n-    case POST_MODIFY:\n-      /* We do not run this function with arguments having side effects.  */\n-      gcc_unreachable ();\n-\n-    case PC:\n-    case CC0: /*FIXME*/\n-    case CONST:\n-    case CONST_INT:\n-    case CONST_DOUBLE:\n-    case CONST_FIXED:\n-    case CONST_VECTOR:\n-    case SYMBOL_REF:\n-    case LABEL_REF:\n-    case ADDR_VEC:\n-    case ADDR_DIFF_VEC:\n-      return accum;\n-\n-    default:\n-      break;\n-    }\n-\n-  i = GET_RTX_LENGTH (code) - 1;\n-  fmt = GET_RTX_FORMAT (code);\n-\n-  for (; i >= 0; i--)\n-    {\n-      if (fmt[i] == 'e')\n-\t{\n-\t  rtx tem = XEXP (x, i);\n-\n-\t  /* If we are about to do the last recursive call\n-\t     needed at this level, change it into iteration.  */\n-\t  if (i == 0)\n-\t    {\n-\t      x = tem;\n-\t      goto repeat;\n-\t    }\n+  rtx *mentioned_regs_p = (rtx *) data;\n \n-\t  accum = extract_mentioned_regs_helper (tem, accum);\n-\t}\n-      else if (fmt[i] == 'E')\n-\t{\n-\t  int j;\n+  if (REG_P (*loc))\n+    *mentioned_regs_p = alloc_EXPR_LIST (0, *loc, *mentioned_regs_p);\n \n-\t  for (j = 0; j < XVECLEN (x, i); j++)\n-\t    accum = extract_mentioned_regs_helper (XVECEXP (x, i, j), accum);\n-\t}\n-    }\n-\n-  return accum;\n+  return 0;\n }\n \n-/* Returns a list of registers mentioned in X.  */\n-/* ??? Reimplement with for_each_rtx?  */\n+/* Returns a list of registers mentioned in X.\n+   FIXME: A regset would be prettier and less expensive.  */\n+\n static rtx\n extract_mentioned_regs (rtx x)\n {\n-  return extract_mentioned_regs_helper (x, NULL_RTX);\n+  rtx mentioned_regs = NULL;\n+  for_each_rtx (&x, extract_mentioned_regs_1, &mentioned_regs);\n+  return mentioned_regs;\n }\n \n /* Check to see if the load X is aliased with STORE_PATTERN.\n@@ -446,7 +314,7 @@ load_kills_store (const_rtx x, const_rtx store_pattern, int after)\n \t\t\t    rtx_addr_varies_p);\n }\n \n-/* Go through the entire insn X, looking for any loads which might alias\n+/* Go through the entire rtx X, looking for any loads which might alias\n    STORE_PATTERN.  Return true if found.\n    AFTER is true if we are checking the case when STORE_PATTERN occurs\n    after the insn X.  */\n@@ -639,6 +507,17 @@ store_killed_before (const_rtx x, const_rtx x_regs, const_rtx insn, const_basic_\n   return false;\n }\n \n+/* The last insn in the basic block that compute_store_table is processing,\n+   where store_killed_after is true for X.\n+   Since we go through the basic block from BB_END to BB_HEAD, this is\n+   also the available store at the end of the basic block.  Therefore\n+   this is in effect a cache, to avoid calling store_killed_after for\n+   equivalent aliasing store expressions.\n+   This value is only meaningful during the computation of the store\n+   table.  We hi-jack the REACHING_REG field of struct st_expr to save\n+   a bit of memory.  */\n+#define LAST_AVAIL_CHECK_FAILURE(x)\t((x)->reaching_reg)\n+\n /* Determine whether INSN is MEM store pattern that we will consider moving.\n    REGS_SET_BEFORE is bitmap of registers set before (and including) the\n    current insn, REGS_SET_AFTER is bitmap of registers set after (and\n@@ -647,14 +526,14 @@ store_killed_before (const_rtx x, const_rtx x_regs, const_rtx insn, const_basic_\n \n    The results are stored this way:\n \n-   -- the first anticipatable expression is added into ANTIC_STORE_LIST\n+   -- the first anticipatable expression is added into ANTIC_STORES\n    -- if the processed expression is not anticipatable, NULL_RTX is added\n       there instead, so that we can use it as indicator that no further\n       expression of this type may be anticipatable\n-   -- if the expression is available, it is added as head of AVAIL_STORE_LIST;\n+   -- if the expression is available, it is added as head of AVAIL_STORES;\n       consequently, all of them but this head are dead and may be deleted.\n    -- if the expression is not available, the insn due to that it fails to be\n-      available is stored in reaching_reg.\n+      available is stored in REACHING_REG (via LAST_AVAIL_CHECK_FAILURE).\n \n    The things are complicated a bit by fact that there already may be stores\n    to the same MEM from other blocks; also caller must take care of the\n@@ -664,7 +543,7 @@ store_killed_before (const_rtx x, const_rtx x_regs, const_rtx insn, const_basic_\n static void\n find_moveable_store (rtx insn, int *regs_set_before, int *regs_set_after)\n {\n-  struct ls_expr * ptr;\n+  struct st_expr * ptr;\n   rtx dest, set, tmp;\n   int check_anticipatable, check_available;\n   basic_block bb = BLOCK_FOR_INSN (insn);\n@@ -701,18 +580,18 @@ find_moveable_store (rtx insn, int *regs_set_before, int *regs_set_after)\n   if (!can_assign_to_reg_without_clobbers_p (SET_SRC (set)))\n     return;\n \n-  ptr = ldst_entry (dest);\n+  ptr = st_expr_entry (dest);\n   if (!ptr->pattern_regs)\n     ptr->pattern_regs = extract_mentioned_regs (dest);\n \n   /* Do not check for anticipatability if we either found one anticipatable\n      store already, or tested for one and found out that it was killed.  */\n   check_anticipatable = 0;\n-  if (!ANTIC_STORE_LIST (ptr))\n+  if (!ptr->antic_stores)\n     check_anticipatable = 1;\n   else\n     {\n-      tmp = XEXP (ANTIC_STORE_LIST (ptr), 0);\n+      tmp = XEXP (ptr->antic_stores, 0);\n       if (tmp != NULL_RTX\n \t  && BLOCK_FOR_INSN (tmp) != bb)\n \tcheck_anticipatable = 1;\n@@ -723,19 +602,18 @@ find_moveable_store (rtx insn, int *regs_set_before, int *regs_set_after)\n \ttmp = NULL_RTX;\n       else\n \ttmp = insn;\n-      ANTIC_STORE_LIST (ptr) = alloc_INSN_LIST (tmp,\n-\t\t\t\t\t\tANTIC_STORE_LIST (ptr));\n+      ptr->antic_stores = alloc_INSN_LIST (tmp, ptr->antic_stores);\n     }\n \n   /* It is not necessary to check whether store is available if we did\n      it successfully before; if we failed before, do not bother to check\n      until we reach the insn that caused us to fail.  */\n   check_available = 0;\n-  if (!AVAIL_STORE_LIST (ptr))\n+  if (!ptr->avail_stores)\n     check_available = 1;\n   else\n     {\n-      tmp = XEXP (AVAIL_STORE_LIST (ptr), 0);\n+      tmp = XEXP (ptr->avail_stores, 0);\n       if (BLOCK_FOR_INSN (tmp) != bb)\n \tcheck_available = 1;\n     }\n@@ -758,7 +636,7 @@ find_moveable_store (rtx insn, int *regs_set_before, int *regs_set_after)\n \t\t\t\t\t      &LAST_AVAIL_CHECK_FAILURE (ptr));\n     }\n   if (!check_available)\n-    AVAIL_STORE_LIST (ptr) = alloc_INSN_LIST (insn, AVAIL_STORE_LIST (ptr));\n+    ptr->avail_stores = alloc_INSN_LIST (insn, ptr->avail_stores);\n }\n \n /* Find available and anticipatable stores.  */\n@@ -769,71 +647,49 @@ compute_store_table (void)\n   int ret;\n   basic_block bb;\n   unsigned regno;\n-  rtx insn, pat, tmp;\n+  rtx insn, tmp;\n+  df_ref *def_rec;\n   int *last_set_in, *already_set;\n-  struct ls_expr * ptr, **prev_next_ptr_ptr;\n+  struct st_expr * ptr, **prev_next_ptr_ptr;\n   unsigned int max_gcse_regno = max_reg_num ();\n \n-  pre_ldst_mems = 0;\n-  pre_ldst_table = htab_create (13, pre_ldst_expr_hash,\n-\t\t\t\tpre_ldst_expr_eq, NULL);\n+  store_motion_mems = NULL;\n+  store_motion_mems_table = htab_create (13, pre_st_expr_hash,\n+\t\t\t\t\t pre_st_expr_eq, NULL);\n   last_set_in = XCNEWVEC (int, max_gcse_regno);\n   already_set = XNEWVEC (int, max_gcse_regno);\n \n   /* Find all the stores we care about.  */\n   FOR_EACH_BB (bb)\n     {\n       /* First compute the registers set in this block.  */\n-      regvec = last_set_in;\n-\n       FOR_BB_INSNS (bb, insn)\n \t{\n+\n \t  if (! INSN_P (insn))\n \t    continue;\n \n-\t  if (CALL_P (insn))\n-\t    {\n-\t      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n-\t\tif (TEST_HARD_REG_BIT (regs_invalidated_by_call, regno))\n-\t\t  last_set_in[regno] = INSN_UID (insn);\n-\t    }\n-\n-\t  pat = PATTERN (insn);\n-\t  compute_store_table_current_insn = insn;\n-\t  note_stores (pat, reg_set_info, NULL);\n+\t  for (def_rec = DF_INSN_DEFS (insn); *def_rec; def_rec++)\n+\t    last_set_in[DF_REF_REGNO (*def_rec)] = INSN_UID (insn);\n \t}\n \n       /* Now find the stores.  */\n       memset (already_set, 0, sizeof (int) * max_gcse_regno);\n-      regvec = already_set;\n       FOR_BB_INSNS (bb, insn)\n \t{\n \t  if (! INSN_P (insn))\n \t    continue;\n \n-\t  if (CALL_P (insn))\n-\t    {\n-\t      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n-\t\tif (TEST_HARD_REG_BIT (regs_invalidated_by_call, regno))\n-\t\t  already_set[regno] = 1;\n-\t    }\n-\n-\t  pat = PATTERN (insn);\n-\t  note_stores (pat, reg_set_info, NULL);\n+\t  for (def_rec = DF_INSN_DEFS (insn); *def_rec; def_rec++)\n+\t    already_set[DF_REF_REGNO (*def_rec)] = INSN_UID (insn);\n \n \t  /* Now that we've marked regs, look for stores.  */\n \t  find_moveable_store (insn, already_set, last_set_in);\n \n \t  /* Unmark regs that are no longer set.  */\n-\t  compute_store_table_current_insn = insn;\n-\t  note_stores (pat, reg_clear_last_set, last_set_in);\n-\t  if (CALL_P (insn))\n-\t    {\n-\t      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n-\t\tif (TEST_HARD_REG_BIT (regs_invalidated_by_call, regno)\n-\t\t    && last_set_in[regno] == INSN_UID (insn))\n-\t\t  last_set_in[regno] = 0;\n-\t    }\n+\t  for (def_rec = DF_INSN_DEFS (insn); *def_rec; def_rec++)\n+\t    if (last_set_in[DF_REF_REGNO (*def_rec)] == INSN_UID (insn))\n+\t      last_set_in[DF_REF_REGNO (*def_rec)] = 0;\n \t}\n \n #ifdef ENABLE_CHECKING\n@@ -843,44 +699,47 @@ compute_store_table (void)\n #endif\n \n       /* Clear temporary marks.  */\n-      for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n+      for (ptr = first_st_expr (); ptr != NULL; ptr = next_st_expr (ptr))\n \t{\n-\t  LAST_AVAIL_CHECK_FAILURE(ptr) = NULL_RTX;\n-\t  if (ANTIC_STORE_LIST (ptr)\n-\t      && (tmp = XEXP (ANTIC_STORE_LIST (ptr), 0)) == NULL_RTX)\n-\t    ANTIC_STORE_LIST (ptr) = XEXP (ANTIC_STORE_LIST (ptr), 1);\n+\t  LAST_AVAIL_CHECK_FAILURE (ptr) = NULL_RTX;\n+\t  if (ptr->antic_stores\n+\t      && (tmp = XEXP (ptr->antic_stores, 0)) == NULL_RTX)\n+\t    ptr->antic_stores = XEXP (ptr->antic_stores, 1);\n \t}\n     }\n \n   /* Remove the stores that are not available anywhere, as there will\n      be no opportunity to optimize them.  */\n-  for (ptr = pre_ldst_mems, prev_next_ptr_ptr = &pre_ldst_mems;\n+  for (ptr = store_motion_mems, prev_next_ptr_ptr = &store_motion_mems;\n        ptr != NULL;\n        ptr = *prev_next_ptr_ptr)\n     {\n-      if (!AVAIL_STORE_LIST (ptr))\n+      if (! ptr->avail_stores)\n \t{\n \t  *prev_next_ptr_ptr = ptr->next;\n-\t  htab_remove_elt_with_hash (pre_ldst_table, ptr, ptr->hash_index);\n-\t  free_ldst_entry (ptr);\n+\t  htab_remove_elt_with_hash (store_motion_mems_table,\n+\t\t\t\t     ptr, ptr->hash_index);\n+\t  free_st_expr_entry (ptr);\n \t}\n       else\n \tprev_next_ptr_ptr = &ptr->next;\n     }\n \n-  ret = enumerate_ldsts ();\n+  ret = enumerate_store_motion_mems ();\n \n   if (dump_file)\n-    {\n-      fprintf (dump_file, \"ST_avail and ST_antic (shown under loads..)\\n\");\n-      print_ldst_list (dump_file);\n-    }\n+    print_store_motion_mems (dump_file);\n \n   free (last_set_in);\n   free (already_set);\n   return ret;\n }\n \n+/* In all code following after this, REACHING_REG has its original\n+   meaning again.  Avoid confusion, and undef the accessor macro for\n+   the temporary marks usage in compute_store_table.  */\n+#undef LAST_AVAIL_CHECK_FAILURE\n+\n /* Insert an instruction at the beginning of a basic block, and update\n    the BB_HEAD if needed.  */\n \n@@ -912,12 +771,12 @@ insert_insn_start_basic_block (rtx insn, basic_block bb)\n     }\n }\n \n-/* This routine will insert a store on an edge. EXPR is the ldst entry for\n+/* This routine will insert a store on an edge. EXPR is the st_expr entry for\n    the memory reference, and E is the edge to insert it on.  Returns nonzero\n    if an edge insertion was performed.  */\n \n static int\n-insert_store (struct ls_expr * expr, edge e)\n+insert_store (struct st_expr * expr, edge e)\n {\n   rtx reg, insn;\n   basic_block bb;\n@@ -945,7 +804,7 @@ insert_store (struct ls_expr * expr, edge e)\n \tint index = EDGE_INDEX (edge_list, tmp->src, tmp->dest);\n \t\n \tgcc_assert (index != EDGE_INDEX_NO_EDGE);\n-\tif (! TEST_BIT (pre_insert_map[index], expr->index))\n+\tif (! TEST_BIT (st_insert_map[index], expr->index))\n \t  break;\n       }\n \n@@ -956,7 +815,7 @@ insert_store (struct ls_expr * expr, edge e)\n       FOR_EACH_EDGE (tmp, ei, e->dest->preds)\n \t{\n \t  int index = EDGE_INDEX (edge_list, tmp->src, tmp->dest);\n-\t  RESET_BIT (pre_insert_map[index], expr->index);\n+\t  RESET_BIT (st_insert_map[index], expr->index);\n \t}\n       insert_insn_start_basic_block (insn, bb);\n       return 0;\n@@ -985,7 +844,7 @@ insert_store (struct ls_expr * expr, edge e)\n    This could be rather expensive.  */\n \n static void\n-remove_reachable_equiv_notes (basic_block bb, struct ls_expr *smexpr)\n+remove_reachable_equiv_notes (basic_block bb, struct st_expr *smexpr)\n {\n   edge_iterator *stack, ei;\n   int sp;\n@@ -1027,7 +886,7 @@ remove_reachable_equiv_notes (basic_block bb, struct ls_expr *smexpr)\n \n       if (TEST_BIT (st_antloc[bb->index], smexpr->index))\n \t{\n-\t  for (last = ANTIC_STORE_LIST (smexpr);\n+\t  for (last = smexpr->antic_stores;\n \t       BLOCK_FOR_INSN (XEXP (last, 0)) != bb;\n \t       last = XEXP (last, 1))\n \t    continue;\n@@ -1066,14 +925,14 @@ remove_reachable_equiv_notes (basic_block bb, struct ls_expr *smexpr)\n /* This routine will replace a store with a SET to a specified register.  */\n \n static void\n-replace_store_insn (rtx reg, rtx del, basic_block bb, struct ls_expr *smexpr)\n+replace_store_insn (rtx reg, rtx del, basic_block bb, struct st_expr *smexpr)\n {\n   rtx insn, mem, note, set, ptr;\n \n   mem = smexpr->pattern;\n   insn = gen_move_insn (reg, SET_SRC (single_set (del)));\n \n-  for (ptr = ANTIC_STORE_LIST (smexpr); ptr; ptr = XEXP (ptr, 1))\n+  for (ptr = smexpr->antic_stores; ptr; ptr = XEXP (ptr, 1))\n     if (XEXP (ptr, 0) == del)\n       {\n \tXEXP (ptr, 0) = insn;\n@@ -1127,7 +986,7 @@ replace_store_insn (rtx reg, rtx del, basic_block bb, struct ls_expr *smexpr)\n    the reaching_reg for later storing.  */\n \n static void\n-delete_store (struct ls_expr * expr, basic_block bb)\n+delete_store (struct st_expr * expr, basic_block bb)\n {\n   rtx reg, i, del;\n \n@@ -1136,7 +995,7 @@ delete_store (struct ls_expr * expr, basic_block bb)\n \n   reg = expr->reaching_reg;\n \n-  for (i = AVAIL_STORE_LIST (expr); i; i = XEXP (i, 1))\n+  for (i = expr->avail_stores; i; i = XEXP (i, 1))\n     {\n       del = XEXP (i, 0);\n       if (BLOCK_FOR_INSN (del) == bb)\n@@ -1157,20 +1016,20 @@ build_store_vectors (void)\n   basic_block bb;\n   int *regs_set_in_block;\n   rtx insn, st;\n-  struct ls_expr * ptr;\n+  struct st_expr * ptr;\n   unsigned int max_gcse_regno = max_reg_num ();\n \n   /* Build the gen_vector. This is any store in the table which is not killed\n      by aliasing later in its block.  */\n-  ae_gen = sbitmap_vector_alloc (last_basic_block, num_stores);\n-  sbitmap_vector_zero (ae_gen, last_basic_block);\n+  st_avloc = sbitmap_vector_alloc (last_basic_block, num_stores);\n+  sbitmap_vector_zero (st_avloc, last_basic_block);\n \n   st_antloc = sbitmap_vector_alloc (last_basic_block, num_stores);\n   sbitmap_vector_zero (st_antloc, last_basic_block);\n \n-  for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n+  for (ptr = first_st_expr (); ptr != NULL; ptr = next_st_expr (ptr))\n     {\n-      for (st = AVAIL_STORE_LIST (ptr); st != NULL; st = XEXP (st, 1))\n+      for (st = ptr->avail_stores; st != NULL; st = XEXP (st, 1))\n \t{\n \t  insn = XEXP (st, 0);\n \t  bb = BLOCK_FOR_INSN (insn);\n@@ -1179,30 +1038,30 @@ build_store_vectors (void)\n \t     we can delete this one (It occurs earlier in the block). We'll\n \t     copy the SRC expression to an unused register in case there\n \t     are any side effects.  */\n-\t  if (TEST_BIT (ae_gen[bb->index], ptr->index))\n+\t  if (TEST_BIT (st_avloc[bb->index], ptr->index))\n \t    {\n \t      rtx r = gen_reg_rtx_and_attrs (ptr->pattern);\n \t      if (dump_file)\n \t\tfprintf (dump_file, \"Removing redundant store:\\n\");\n \t      replace_store_insn (r, XEXP (st, 0), bb, ptr);\n \t      continue;\n \t    }\n-\t  SET_BIT (ae_gen[bb->index], ptr->index);\n+\t  SET_BIT (st_avloc[bb->index], ptr->index);\n \t}\n \n-      for (st = ANTIC_STORE_LIST (ptr); st != NULL; st = XEXP (st, 1))\n+      for (st = ptr->antic_stores; st != NULL; st = XEXP (st, 1))\n \t{\n \t  insn = XEXP (st, 0);\n \t  bb = BLOCK_FOR_INSN (insn);\n \t  SET_BIT (st_antloc[bb->index], ptr->index);\n \t}\n     }\n \n-  ae_kill = sbitmap_vector_alloc (last_basic_block, num_stores);\n-  sbitmap_vector_zero (ae_kill, last_basic_block);\n+  st_kill = sbitmap_vector_alloc (last_basic_block, num_stores);\n+  sbitmap_vector_zero (st_kill, last_basic_block);\n \n-  transp = sbitmap_vector_alloc (last_basic_block, num_stores);\n-  sbitmap_vector_zero (transp, last_basic_block);\n+  st_transp = sbitmap_vector_alloc (last_basic_block, num_stores);\n+  sbitmap_vector_zero (st_transp, last_basic_block);\n   regs_set_in_block = XNEWVEC (int, max_gcse_regno);\n \n   FOR_EACH_BB (bb)\n@@ -1219,19 +1078,19 @@ build_store_vectors (void)\n \t      }\n \t  }\n \n-      for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n+      for (ptr = first_st_expr (); ptr != NULL; ptr = next_st_expr (ptr))\n \t{\n \t  if (store_killed_after (ptr->pattern, ptr->pattern_regs, BB_HEAD (bb),\n \t\t\t\t  bb, regs_set_in_block, NULL))\n \t    {\n \t      /* It should not be necessary to consider the expression\n \t\t killed if it is both anticipatable and available.  */\n \t      if (!TEST_BIT (st_antloc[bb->index], ptr->index)\n-\t\t  || !TEST_BIT (ae_gen[bb->index], ptr->index))\n-\t\tSET_BIT (ae_kill[bb->index], ptr->index);\n+\t\t  || !TEST_BIT (st_avloc[bb->index], ptr->index))\n+\t\tSET_BIT (st_kill[bb->index], ptr->index);\n \t    }\n \t  else\n-\t    SET_BIT (transp[bb->index], ptr->index);\n+\t    SET_BIT (st_transp[bb->index], ptr->index);\n \t}\n     }\n \n@@ -1240,9 +1099,9 @@ build_store_vectors (void)\n   if (dump_file)\n     {\n       dump_sbitmap_vector (dump_file, \"st_antloc\", \"\", st_antloc, last_basic_block);\n-      dump_sbitmap_vector (dump_file, \"st_kill\", \"\", ae_kill, last_basic_block);\n-      dump_sbitmap_vector (dump_file, \"Transpt\", \"\", transp, last_basic_block);\n-      dump_sbitmap_vector (dump_file, \"st_avloc\", \"\", ae_gen, last_basic_block);\n+      dump_sbitmap_vector (dump_file, \"st_kill\", \"\", st_kill, last_basic_block);\n+      dump_sbitmap_vector (dump_file, \"st_transp\", \"\", st_transp, last_basic_block);\n+      dump_sbitmap_vector (dump_file, \"st_avloc\", \"\", st_avloc, last_basic_block);\n     }\n }\n \n@@ -1251,23 +1110,23 @@ build_store_vectors (void)\n static void\n free_store_memory (void)\n {\n-  free_ldst_mems ();\n-\n-  if (ae_gen)\n-    sbitmap_vector_free (ae_gen);\n-  if (ae_kill)\n-    sbitmap_vector_free (ae_kill);\n-  if (transp)\n-    sbitmap_vector_free (transp);\n+  free_store_motion_mems ();\n+\n+  if (st_avloc)\n+    sbitmap_vector_free (st_avloc);\n+  if (st_kill)\n+    sbitmap_vector_free (st_kill);\n+  if (st_transp)\n+    sbitmap_vector_free (st_transp);\n   if (st_antloc)\n     sbitmap_vector_free (st_antloc);\n-  if (pre_insert_map)\n-    sbitmap_vector_free (pre_insert_map);\n-  if (pre_delete_map)\n-    sbitmap_vector_free (pre_delete_map);\n+  if (st_insert_map)\n+    sbitmap_vector_free (st_insert_map);\n+  if (st_delete_map)\n+    sbitmap_vector_free (st_delete_map);\n \n-  ae_gen = ae_kill = transp = st_antloc = NULL;\n-  pre_insert_map = pre_delete_map = NULL;\n+  st_avloc = st_kill = st_transp = st_antloc = NULL;\n+  st_insert_map = st_delete_map = NULL;\n }\n \n /* Perform store motion. Much like gcse, except we move expressions the\n@@ -1279,20 +1138,19 @@ one_store_motion_pass (void)\n {\n   basic_block bb;\n   int x;\n-  struct ls_expr * ptr;\n-  int update_flow = 0;\n-\n-  gcse_subst_count = 0;\n-  gcse_create_count = 0;\n+  struct st_expr * ptr;\n+  int did_edge_inserts = 0;\n+  int n_stores_deleted = 0;\n+  int n_stores_created = 0;\n \n   init_alias_analysis ();\n \n   /* Find all the available and anticipatable stores.  */\n   num_stores = compute_store_table ();\n   if (num_stores == 0)\n     {\n-      htab_delete (pre_ldst_table);\n-      pre_ldst_table = NULL;\n+      htab_delete (store_motion_mems_table);\n+      store_motion_mems_table = NULL;\n       end_alias_analysis ();\n       return 0;\n     }\n@@ -1302,17 +1160,17 @@ one_store_motion_pass (void)\n   add_noreturn_fake_exit_edges ();\n   connect_infinite_loops_to_exit ();\n \n-  edge_list = pre_edge_rev_lcm (num_stores, transp, ae_gen,\n-\t\t\t\tst_antloc, ae_kill, &pre_insert_map,\n-\t\t\t\t&pre_delete_map);\n+  edge_list = pre_edge_rev_lcm (num_stores, st_transp, st_avloc,\n+\t\t\t\tst_antloc, st_kill, &st_insert_map,\n+\t\t\t\t&st_delete_map);\n \n   /* Now we want to insert the new stores which are going to be needed.  */\n-  for (ptr = first_ls_expr (); ptr != NULL; ptr = next_ls_expr (ptr))\n+  for (ptr = first_st_expr (); ptr != NULL; ptr = next_st_expr (ptr))\n     {\n       /* If any of the edges we have above are abnormal, we can't move this\n \t store.  */\n       for (x = NUM_EDGES (edge_list) - 1; x >= 0; x--)\n-\tif (TEST_BIT (pre_insert_map[x], ptr->index)\n+\tif (TEST_BIT (st_insert_map[x], ptr->index)\n \t    && (INDEX_EDGE (edge_list, x)->flags & EDGE_ABNORMAL))\n \t  break;\n \n@@ -1329,21 +1187,21 @@ one_store_motion_pass (void)\n       /* Now we want to insert the new stores which are going to be needed.  */\n \n       FOR_EACH_BB (bb)\n-\tif (TEST_BIT (pre_delete_map[bb->index], ptr->index))\n+\tif (TEST_BIT (st_delete_map[bb->index], ptr->index))\n \t  {\n \t    delete_store (ptr, bb);\n-\t    gcse_subst_count++;\n+\t    n_stores_deleted++;\n \t  }\n \n       for (x = 0; x < NUM_EDGES (edge_list); x++)\n-\tif (TEST_BIT (pre_insert_map[x], ptr->index))\n+\tif (TEST_BIT (st_insert_map[x], ptr->index))\n \t  {\n-\t    update_flow |= insert_store (ptr, INDEX_EDGE (edge_list, x));\n-\t    gcse_create_count++;\n+\t    did_edge_inserts |= insert_store (ptr, INDEX_EDGE (edge_list, x));\n+\t    n_stores_created++;\n \t  }\n     }\n \n-  if (update_flow)\n+  if (did_edge_inserts)\n     commit_edge_insertions ();\n \n   free_store_memory ();\n@@ -1355,11 +1213,11 @@ one_store_motion_pass (void)\n     {\n       fprintf (dump_file, \"STORE_MOTION of %s, %d basic blocks, \",\n \t       current_function_name (), n_basic_blocks);\n-      fprintf (dump_file, \"%d substs, %d insns created\\n\",\n-\t       gcse_subst_count, gcse_create_count);\n+      fprintf (dump_file, \"%d insns deleted, %d insns created\\n\",\n+\t       n_stores_deleted, n_stores_created);\n     }\n \n-  return (gcse_subst_count > 0 || gcse_create_count > 0);\n+  return (n_stores_deleted > 0 || n_stores_created > 0);\n }\n \n \f"}]}