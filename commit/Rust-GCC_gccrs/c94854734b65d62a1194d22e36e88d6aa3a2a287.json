{"sha": "c94854734b65d62a1194d22e36e88d6aa3a2a287", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Yzk0ODU0NzM0YjY1ZDYyYTExOTRkMjJlMzZlODhkNmFhM2EyYTI4Nw==", "commit": {"author": {"name": "Michael Meissner", "email": "meissner@linux.vnet.ibm.com", "date": "2011-02-03T05:42:19Z"}, "committer": {"name": "Michael Meissner", "email": "meissner@gcc.gnu.org", "date": "2011-02-03T05:42:19Z"}, "message": "Fix PR target/47272\n\nFrom-SVN: r169780", "tree": {"sha": "78603bad848ffa4b02b2b74ed975e05deb0510b4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/78603bad848ffa4b02b2b74ed975e05deb0510b4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c94854734b65d62a1194d22e36e88d6aa3a2a287", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c94854734b65d62a1194d22e36e88d6aa3a2a287", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c94854734b65d62a1194d22e36e88d6aa3a2a287", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c94854734b65d62a1194d22e36e88d6aa3a2a287/comments", "author": null, "committer": null, "parents": [{"sha": "b24d1acf7fcd5260c0fd7031805778e63adffcf4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b24d1acf7fcd5260c0fd7031805778e63adffcf4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b24d1acf7fcd5260c0fd7031805778e63adffcf4"}], "stats": {"total": 1263, "additions": 941, "deletions": 322}, "files": [{"sha": "1f16f47ea8dacb41b5047c1c5d5688ab50e82fd6", "filename": "gcc/ChangeLog", "status": "modified", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,3 +1,53 @@\n+2011-02-02  Michael Meissner  <meissner@linux.vnet.ibm.com>\n+\n+\tPR target/47272\n+\t* doc/extend.texi (PowerPC AltiVec/VSX Built-in Functions):\n+\tDocument using vector double with the load/store builtins, and\n+\tthat the load/store builtins always use Altivec instructions.\n+\n+\t* config/rs6000/vector.md (vector_altivec_load_<mode>): New insns\n+\tto use altivec memory instructions, even on VSX.\n+\t(vector_altivec_store_<mode>): Ditto.\n+\n+\t* config/rs6000/rs6000-protos.h (rs6000_address_for_altivec): New\n+\tfunction.\n+\n+\t* config/rs6000/rs6000-c.c (altivec_overloaded_builtins): Add\n+\tV2DF, V2DI support to load/store overloaded builtins.\n+\n+\t* config/rs6000/rs6000-builtin.def (ALTIVEC_BUILTIN_*): Add\n+\taltivec load/store builtins for V2DF/V2DI types.\n+\n+\t* config/rs6000/rs6000.c (rs6000_option_override_internal): Don't\n+\tset avoid indexed addresses on power6 if -maltivec.\n+\t(altivec_expand_ld_builtin): Add V2DF, V2DI support, use\n+\tvector_altivec_load/vector_altivec_store builtins.\n+\t(altivec_expand_st_builtin): Ditto.\n+\t(altivec_expand_builtin): Add VSX memory builtins.\n+\t(rs6000_init_builtins): Add V2DI types to internal types.\n+\t(altivec_init_builtins): Add support for V2DF/V2DI altivec\n+\tload/store builtins.\n+\t(rs6000_address_for_altivec): Insure memory address is appropriate\n+\tfor Altivec.\n+\n+\t* config/rs6000/vsx.md (vsx_load_<mode>): New expanders for\n+\tvec_vsx_ld and vec_vsx_st.\n+\t(vsx_store_<mode>): Ditto.\n+\n+\t* config/rs6000/rs6000.h (RS6000_BTI_long_long): New type\n+\tvariables to hold long long types for VSX vector memory builtins.\n+\t(RS6000_BTI_unsigned_long_long): Ditto.\n+\t(long_long_integer_type_internal_node): Ditti.\n+\t(long_long_unsigned_type_internal_node): Ditti.\n+\n+\t* config/rs6000/altivec.md (UNSPEC_LVX): New UNSPEC.\n+\t(altivec_lvx_<mode>): Make altivec_lvx use a mode iterator.\n+\t(altivec_stvx_<mode>): Make altivec_stvx use a mode iterator.\n+\n+\t* config/rs6000/altivec.h (vec_vsx_ld): Define VSX memory builtin\n+\tshort cuts.\n+\t(vec_vsx_st): Ditto.\n+\n 2011-02-02  Joseph Myers  <joseph@codesourcery.com>\n \n \t* config/pa/pa-hpux10.opt: New."}, {"sha": "583731b9668c4131221812e8c973d76f3347b30c", "filename": "gcc/config/rs6000/altivec.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Faltivec.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Faltivec.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Faltivec.h?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,5 +1,5 @@\n /* PowerPC AltiVec include file.\n-   Copyright (C) 2002, 2003, 2004, 2005, 2008, 2009, 2010\n+   Copyright (C) 2002, 2003, 2004, 2005, 2008, 2009, 2010, 2011\n    Free Software Foundation, Inc.\n    Contributed by Aldy Hernandez (aldyh@redhat.com).\n    Rewritten by Paolo Bonzini (bonzini@gnu.org).\n@@ -318,6 +318,8 @@\n #define vec_nearbyint __builtin_vec_nearbyint\n #define vec_rint __builtin_vec_rint\n #define vec_sqrt __builtin_vec_sqrt\n+#define vec_vsx_ld __builtin_vec_vsx_ld\n+#define vec_vsx_st __builtin_vec_vsx_st\n #endif\n \n /* Predicates."}, {"sha": "d7357ee32627caa1d1f01f2614bc6a0336679347", "filename": "gcc/config/rs6000/altivec.md", "status": "modified", "additions": 10, "deletions": 8, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Faltivec.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Faltivec.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Faltivec.md?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,5 +1,5 @@\n ;; AltiVec patterns.\n-;; Copyright (C) 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n+;; Copyright (C) 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n ;; Free Software Foundation, Inc.\n ;; Contributed by Aldy Hernandez (aldy@quesejoda.com)\n \n@@ -96,7 +96,7 @@\n    (UNSPEC_STVE         203)\n    (UNSPEC_SET_VSCR     213)\n    (UNSPEC_GET_VRSAVE   214)\n-   ;; 215 deleted\n+   (UNSPEC_LVX\t\t215)\n    (UNSPEC_REDUC_PLUS   217)\n    (UNSPEC_VECSH        219)\n    (UNSPEC_EXTEVEN_V4SI 220)\n@@ -1750,17 +1750,19 @@\n   \"lvxl %0,%y1\"\n   [(set_attr \"type\" \"vecload\")])\n \n-(define_insn \"altivec_lvx\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-\t(match_operand:V4SI 1 \"memory_operand\" \"Z\"))]\n+(define_insn \"altivec_lvx_<mode>\"\n+  [(parallel\n+    [(set (match_operand:VM2 0 \"register_operand\" \"=v\")\n+\t  (match_operand:VM2 1 \"memory_operand\" \"Z\"))\n+     (unspec [(const_int 0)] UNSPEC_LVX)])]\n   \"TARGET_ALTIVEC\"\n   \"lvx %0,%y1\"\n   [(set_attr \"type\" \"vecload\")])\n \n-(define_insn \"altivec_stvx\"\n+(define_insn \"altivec_stvx_<mode>\"\n   [(parallel\n-    [(set (match_operand:V4SI 0 \"memory_operand\" \"=Z\")\n-\t  (match_operand:V4SI 1 \"register_operand\" \"v\"))\n+    [(set (match_operand:VM2 0 \"memory_operand\" \"=Z\")\n+\t  (match_operand:VM2 1 \"register_operand\" \"v\"))\n      (unspec [(const_int 0)] UNSPEC_STVX)])]\n   \"TARGET_ALTIVEC\"\n   \"stvx %1,%y0\""}, {"sha": "fd6321dcf96ea5d0d76bb4be56b941f10fe29905", "filename": "gcc/config/rs6000/rs6000-builtin.def", "status": "modified", "additions": 20, "deletions": 6, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000-builtin.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000-builtin.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-builtin.def?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,5 +1,5 @@\n /* Builtin functions for rs6000/powerpc.\n-   Copyright (C) 2009, 2010\n+   Copyright (C) 2009, 2010, 2011\n    Free Software Foundation, Inc.\n    Contributed by Michael Meissner (meissner@linux.vnet.ibm.com)\n \n@@ -37,6 +37,10 @@ RS6000_BUILTIN(ALTIVEC_BUILTIN_ST_INTERNAL_16qi,\tRS6000_BTC_MEM)\n RS6000_BUILTIN(ALTIVEC_BUILTIN_LD_INTERNAL_16qi,\tRS6000_BTC_MEM)\n RS6000_BUILTIN(ALTIVEC_BUILTIN_ST_INTERNAL_4sf,\t\tRS6000_BTC_MEM)\n RS6000_BUILTIN(ALTIVEC_BUILTIN_LD_INTERNAL_4sf,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(ALTIVEC_BUILTIN_ST_INTERNAL_2df,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(ALTIVEC_BUILTIN_LD_INTERNAL_2df,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(ALTIVEC_BUILTIN_ST_INTERNAL_2di,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(ALTIVEC_BUILTIN_LD_INTERNAL_2di,\t\tRS6000_BTC_MEM)\n RS6000_BUILTIN(ALTIVEC_BUILTIN_VADDUBM,\t\t\tRS6000_BTC_CONST)\n RS6000_BUILTIN(ALTIVEC_BUILTIN_VADDUHM,\t\t\tRS6000_BTC_CONST)\n RS6000_BUILTIN(ALTIVEC_BUILTIN_VADDUWM,\t\t\tRS6000_BTC_CONST)\n@@ -778,12 +782,20 @@ RS6000_BUILTIN(PAIRED_BUILTIN_CMPU1,\t\t\tRS6000_BTC_MISC)\n \n   /* VSX builtins.  */\n RS6000_BUILTIN(VSX_BUILTIN_LXSDX,\t\t\tRS6000_BTC_MEM)\n-RS6000_BUILTIN(VSX_BUILTIN_LXVD2X,\t\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_LXVD2X_V2DF,\t\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_LXVD2X_V2DI,\t\t\tRS6000_BTC_MEM)\n RS6000_BUILTIN(VSX_BUILTIN_LXVDSX,\t\t\tRS6000_BTC_MEM)\n-RS6000_BUILTIN(VSX_BUILTIN_LXVW4X,\t\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_LXVW4X_V4SF,\t\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_LXVW4X_V4SI,\t\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_LXVW4X_V8HI,\t\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_LXVW4X_V16QI,\t\tRS6000_BTC_MEM)\n RS6000_BUILTIN(VSX_BUILTIN_STXSDX,\t\t\tRS6000_BTC_MEM)\n-RS6000_BUILTIN(VSX_BUILTIN_STXVD2X,\t\t\tRS6000_BTC_MEM)\n-RS6000_BUILTIN(VSX_BUILTIN_STXVW4X,\t\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_STXVD2X_V2DF,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_STXVD2X_V2DI,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_STXVW4X_V4SF,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_STXVW4X_V4SI,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_STXVW4X_V8HI,\t\tRS6000_BTC_MEM)\n+RS6000_BUILTIN(VSX_BUILTIN_STXVW4X_V16QI,\t\tRS6000_BTC_MEM)\n RS6000_BUILTIN(VSX_BUILTIN_XSABSDP,\t\t\tRS6000_BTC_CONST)\n RS6000_BUILTIN(VSX_BUILTIN_XSADDDP,\t\t\tRS6000_BTC_FP_PURE)\n RS6000_BUILTIN(VSX_BUILTIN_XSCMPODP,\t\t\tRS6000_BTC_FP_PURE)\n@@ -983,8 +995,10 @@ RS6000_BUILTIN(VSX_BUILTIN_VEC_XXPERMDI,\t\tRS6000_BTC_MISC)\n RS6000_BUILTIN(VSX_BUILTIN_VEC_XXSLDWI,\t\t\tRS6000_BTC_MISC)\n RS6000_BUILTIN(VSX_BUILTIN_VEC_XXSPLTD,\t\t\tRS6000_BTC_MISC)\n RS6000_BUILTIN(VSX_BUILTIN_VEC_XXSPLTW,\t\t\tRS6000_BTC_MISC)\n+RS6000_BUILTIN(VSX_BUILTIN_VEC_LD,\t\t\tRS6000_BTC_MISC)\n+RS6000_BUILTIN(VSX_BUILTIN_VEC_ST,\t\t\tRS6000_BTC_MISC)\n RS6000_BUILTIN_EQUATE(VSX_BUILTIN_OVERLOADED_LAST,\n-\t\t      VSX_BUILTIN_VEC_XXSPLTW)\n+\t\t      VSX_BUILTIN_VEC_ST)\n \n /* Combined VSX/Altivec builtins.  */\n RS6000_BUILTIN(VECTOR_BUILTIN_FLOAT_V4SI_V4SF,\t\tRS6000_BTC_FP_PURE)"}, {"sha": "3f4f90b236c106568d3a348fe0ffcca0d7e6e019", "filename": "gcc/config/rs6000/rs6000-c.c", "status": "modified", "additions": 193, "deletions": 1, "changes": 194, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-c.c?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -999,6 +999,15 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n   { VSX_BUILTIN_VEC_DIV, VSX_BUILTIN_XVDIVDP,\n     RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n+    RS6000_BTI_V2DF, RS6000_BTI_INTSI, ~RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n+    RS6000_BTI_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_V2DI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n+    RS6000_BTI_unsigned_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V2DI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_bool_V2DI, 0 },\n   { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n     RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_LD, ALTIVEC_BUILTIN_LVX,\n@@ -1112,9 +1121,19 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n   { ALTIVEC_BUILTIN_VEC_LDL, ALTIVEC_BUILTIN_LVXL,\n     RS6000_BTI_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_INTQI, 0 },\n   { ALTIVEC_BUILTIN_VEC_LDL, ALTIVEC_BUILTIN_LVXL,\n-    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_unsigned_V16QI, 0 },\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_LDL, ALTIVEC_BUILTIN_LVXL,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTQI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LDL, ALTIVEC_BUILTIN_LVXL,\n+    RS6000_BTI_V2DF, RS6000_BTI_INTSI, ~RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LDL, ALTIVEC_BUILTIN_LVXL,\n+    RS6000_BTI_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_V2DI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LDL, ALTIVEC_BUILTIN_LVXL,\n+    RS6000_BTI_unsigned_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V2DI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LDL, ALTIVEC_BUILTIN_LVXL,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_bool_V2DI, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTQI, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n@@ -1133,6 +1152,17 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_long, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_float, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_double, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTDI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_INTDI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_long_long, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSL, ALTIVEC_BUILTIN_LVSL,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_long_long, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTQI, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n@@ -1151,6 +1181,17 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_long, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_float, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_double, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTDI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_INTDI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_long_long, 0 },\n+  { ALTIVEC_BUILTIN_VEC_LVSR, ALTIVEC_BUILTIN_LVSR,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_long_long, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVLX, ALTIVEC_BUILTIN_LVLX,\n     RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_V4SF, 0 },\n   { ALTIVEC_BUILTIN_VEC_LVLX, ALTIVEC_BUILTIN_LVLX,\n@@ -2643,6 +2684,16 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_NOT_OPAQUE },\n   { ALTIVEC_BUILTIN_VEC_SLD, ALTIVEC_BUILTIN_VSLDOI_16QI,\n     RS6000_BTI_bool_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_NOT_OPAQUE },\n+  { ALTIVEC_BUILTIN_VEC_ST, ALTIVEC_BUILTIN_STVX,\n+    RS6000_BTI_void, RS6000_BTI_V2DF, RS6000_BTI_INTSI, ~RS6000_BTI_V2DF },\n+  { ALTIVEC_BUILTIN_VEC_ST, ALTIVEC_BUILTIN_STVX,\n+    RS6000_BTI_void, RS6000_BTI_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_ST, ALTIVEC_BUILTIN_STVX,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_ST, ALTIVEC_BUILTIN_STVX,\n+    RS6000_BTI_void, RS6000_BTI_bool_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_bool_V2DI },\n   { ALTIVEC_BUILTIN_VEC_ST, ALTIVEC_BUILTIN_STVX,\n     RS6000_BTI_void, RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_V4SF },\n   { ALTIVEC_BUILTIN_VEC_ST, ALTIVEC_BUILTIN_STVX,\n@@ -2809,6 +2860,18 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_void, RS6000_BTI_bool_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_INTQI },\n   { ALTIVEC_BUILTIN_VEC_STL, ALTIVEC_BUILTIN_STVXL,\n     RS6000_BTI_void, RS6000_BTI_pixel_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_pixel_V8HI },\n+  { ALTIVEC_BUILTIN_VEC_STL, ALTIVEC_BUILTIN_STVXL,\n+    RS6000_BTI_void, RS6000_BTI_V2DF, RS6000_BTI_INTSI, ~RS6000_BTI_V2DF },\n+  { ALTIVEC_BUILTIN_VEC_STL, ALTIVEC_BUILTIN_STVXL,\n+    RS6000_BTI_void, RS6000_BTI_V2DF, RS6000_BTI_INTSI, ~RS6000_BTI_double },\n+  { ALTIVEC_BUILTIN_VEC_STL, ALTIVEC_BUILTIN_STVXL,\n+    RS6000_BTI_void, RS6000_BTI_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_STL, ALTIVEC_BUILTIN_STVXL,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_STL, ALTIVEC_BUILTIN_STVXL,\n+    RS6000_BTI_void, RS6000_BTI_bool_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_bool_V2DI },\n   { ALTIVEC_BUILTIN_VEC_STVLX, ALTIVEC_BUILTIN_STVLX,\n     RS6000_BTI_void, RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_V4SF },\n   { ALTIVEC_BUILTIN_VEC_STVLX, ALTIVEC_BUILTIN_STVLX,\n@@ -3002,6 +3065,135 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI,\n     RS6000_BTI_NOT_OPAQUE },\n \n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVD2X_V2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_INTSI, ~RS6000_BTI_V2DF, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVD2X_V2DI,\n+    RS6000_BTI_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_V2DI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVD2X_V2DI,\n+    RS6000_BTI_unsigned_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V2DI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVD2X_V2DI,\n+    RS6000_BTI_bool_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_bool_V2DI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SF,\n+    RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_V4SF, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SF,\n+    RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_float, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SI,\n+    RS6000_BTI_bool_V4SI, RS6000_BTI_INTSI, ~RS6000_BTI_bool_V4SI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SI,\n+    RS6000_BTI_V4SI, RS6000_BTI_INTSI, ~RS6000_BTI_V4SI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SI,\n+    RS6000_BTI_V4SI, RS6000_BTI_INTSI, ~RS6000_BTI_INTSI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SI,\n+    RS6000_BTI_V4SI, RS6000_BTI_INTSI, ~RS6000_BTI_long, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SI,\n+    RS6000_BTI_unsigned_V4SI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V4SI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SI,\n+    RS6000_BTI_unsigned_V4SI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTSI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V4SI,\n+    RS6000_BTI_unsigned_V4SI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_long, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V8HI,\n+    RS6000_BTI_bool_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_bool_V8HI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V8HI,\n+    RS6000_BTI_pixel_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_pixel_V8HI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V8HI,\n+    RS6000_BTI_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_V8HI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V8HI,\n+    RS6000_BTI_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_INTHI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V8HI,\n+    RS6000_BTI_unsigned_V8HI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V8HI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V8HI,\n+    RS6000_BTI_unsigned_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTHI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V16QI,\n+    RS6000_BTI_bool_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_bool_V16QI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V16QI,\n+    RS6000_BTI_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_V16QI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V16QI,\n+    RS6000_BTI_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_INTQI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V16QI,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V16QI, 0 },\n+  { VSX_BUILTIN_VEC_LD, VSX_BUILTIN_LXVW4X_V16QI,\n+    RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_UINTQI, 0 },\n+\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVD2X_V2DF,\n+    RS6000_BTI_void, RS6000_BTI_V2DF, RS6000_BTI_INTSI, ~RS6000_BTI_V2DF },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVD2X_V2DI,\n+    RS6000_BTI_void, RS6000_BTI_V2DI, RS6000_BTI_INTSI, ~RS6000_BTI_V2DI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVD2X_V2DI,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V2DI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVD2X_V2DI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V2DI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_bool_V2DI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SF,\n+    RS6000_BTI_void, RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_V4SF },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SF,\n+    RS6000_BTI_void, RS6000_BTI_V4SF, RS6000_BTI_INTSI, ~RS6000_BTI_float },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SI,\n+    RS6000_BTI_void, RS6000_BTI_V4SI, RS6000_BTI_INTSI, ~RS6000_BTI_V4SI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SI,\n+    RS6000_BTI_void, RS6000_BTI_V4SI, RS6000_BTI_INTSI, ~RS6000_BTI_INTSI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SI,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V4SI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V4SI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SI,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V4SI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_UINTSI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V4SI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_bool_V4SI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V4SI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_UINTSI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V4SI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V4SI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_INTSI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V8HI,\n+    RS6000_BTI_void, RS6000_BTI_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_V8HI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V8HI,\n+    RS6000_BTI_void, RS6000_BTI_V8HI, RS6000_BTI_INTSI, ~RS6000_BTI_INTHI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V8HI,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V8HI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V8HI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V8HI,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V8HI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_UINTHI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V8HI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V8HI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_bool_V8HI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V8HI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V8HI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_UINTHI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V8HI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V8HI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_INTHI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_V16QI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_V16QI, RS6000_BTI_INTSI, ~RS6000_BTI_INTQI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_unsigned_V16QI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_unsigned_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_UINTQI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_bool_V16QI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_UINTQI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_bool_V16QI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_INTQI },\n+  { VSX_BUILTIN_VEC_ST, VSX_BUILTIN_STXVW4X_V16QI,\n+    RS6000_BTI_void, RS6000_BTI_pixel_V8HI, RS6000_BTI_INTSI,\n+    ~RS6000_BTI_pixel_V8HI },\n+\n   /* Predicates.  */\n   { ALTIVEC_BUILTIN_VCMPGT_P, ALTIVEC_BUILTIN_VCMPGTUB_P,\n     RS6000_BTI_INTSI, RS6000_BTI_INTSI, RS6000_BTI_bool_V16QI, RS6000_BTI_unsigned_V16QI },"}, {"sha": "d9b6bd70cad5d24baabd6311adecbea91d12cac1", "filename": "gcc/config/rs6000/rs6000-protos.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-protos.h?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,5 +1,6 @@\n /* Definitions of target machine for GNU compiler, for IBM RS/6000.\n-   Copyright (C) 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n+   Copyright (C) 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n+   2010, 2011\n    Free Software Foundation, Inc.\n    Contributed by Richard Kenner (kenner@vlsi1.ultra.nyu.edu)\n \n@@ -129,6 +130,7 @@ extern void rs6000_emit_parity (rtx, rtx);\n extern rtx rs6000_machopic_legitimize_pic_address (rtx, enum machine_mode,\n \t\t\t\t\t\t   rtx);\n extern rtx rs6000_address_for_fpconvert (rtx);\n+extern rtx rs6000_address_for_altivec (rtx);\n extern rtx rs6000_allocate_stack_temp (enum machine_mode, bool, bool);\n extern int rs6000_loop_align (rtx);\n #endif /* RTX_CODE */"}, {"sha": "df02bef54dfbcdc00e58f759bac7ad4c1e4ecaf1", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 152, "deletions": 65, "changes": 217, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -3316,9 +3316,12 @@ rs6000_option_override_internal (bool global_init_p)\n   /* If not explicitly specified via option, decide whether to generate indexed\n      load/store instructions.  */\n   if (TARGET_AVOID_XFORM == -1)\n-    /* Avoid indexed addressing when targeting Power6 in order to avoid\n-     the DERAT mispredict penalty.  */\n-    TARGET_AVOID_XFORM = (rs6000_cpu == PROCESSOR_POWER6 && TARGET_CMPB);\n+    /* Avoid indexed addressing when targeting Power6 in order to avoid the\n+     DERAT mispredict penalty.  However the LVE and STVE altivec instructions\n+     need indexed accesses and the type used is the scalar type of the element\n+     being loaded or stored.  */\n+    TARGET_AVOID_XFORM = (rs6000_cpu == PROCESSOR_POWER6 && TARGET_CMPB\n+\t\t\t  && !TARGET_ALTIVEC);\n \n   /* Set the -mrecip options.  */\n   if (rs6000_recip_name)\n@@ -11263,16 +11266,22 @@ altivec_expand_ld_builtin (tree exp, rtx target, bool *expandedp)\n   switch (fcode)\n     {\n     case ALTIVEC_BUILTIN_LD_INTERNAL_16qi:\n-      icode = CODE_FOR_vector_load_v16qi;\n+      icode = CODE_FOR_vector_altivec_load_v16qi;\n       break;\n     case ALTIVEC_BUILTIN_LD_INTERNAL_8hi:\n-      icode = CODE_FOR_vector_load_v8hi;\n+      icode = CODE_FOR_vector_altivec_load_v8hi;\n       break;\n     case ALTIVEC_BUILTIN_LD_INTERNAL_4si:\n-      icode = CODE_FOR_vector_load_v4si;\n+      icode = CODE_FOR_vector_altivec_load_v4si;\n       break;\n     case ALTIVEC_BUILTIN_LD_INTERNAL_4sf:\n-      icode = CODE_FOR_vector_load_v4sf;\n+      icode = CODE_FOR_vector_altivec_load_v4sf;\n+      break;\n+    case ALTIVEC_BUILTIN_LD_INTERNAL_2df:\n+      icode = CODE_FOR_vector_altivec_load_v2df;\n+      break;\n+    case ALTIVEC_BUILTIN_LD_INTERNAL_2di:\n+      icode = CODE_FOR_vector_altivec_load_v2di;\n       break;\n     default:\n       *expandedp = false;\n@@ -11316,16 +11325,22 @@ altivec_expand_st_builtin (tree exp, rtx target ATTRIBUTE_UNUSED,\n   switch (fcode)\n     {\n     case ALTIVEC_BUILTIN_ST_INTERNAL_16qi:\n-      icode = CODE_FOR_vector_store_v16qi;\n+      icode = CODE_FOR_vector_altivec_store_v16qi;\n       break;\n     case ALTIVEC_BUILTIN_ST_INTERNAL_8hi:\n-      icode = CODE_FOR_vector_store_v8hi;\n+      icode = CODE_FOR_vector_altivec_store_v8hi;\n       break;\n     case ALTIVEC_BUILTIN_ST_INTERNAL_4si:\n-      icode = CODE_FOR_vector_store_v4si;\n+      icode = CODE_FOR_vector_altivec_store_v4si;\n       break;\n     case ALTIVEC_BUILTIN_ST_INTERNAL_4sf:\n-      icode = CODE_FOR_vector_store_v4sf;\n+      icode = CODE_FOR_vector_altivec_store_v4sf;\n+      break;\n+    case ALTIVEC_BUILTIN_ST_INTERNAL_2df:\n+      icode = CODE_FOR_vector_altivec_store_v2df;\n+      break;\n+    case ALTIVEC_BUILTIN_ST_INTERNAL_2di:\n+      icode = CODE_FOR_vector_altivec_store_v2di;\n       break;\n     default:\n       *expandedp = false;\n@@ -11557,7 +11572,7 @@ altivec_expand_builtin (tree exp, rtx target, bool *expandedp)\n   switch (fcode)\n     {\n     case ALTIVEC_BUILTIN_STVX:\n-      return altivec_expand_stv_builtin (CODE_FOR_altivec_stvx, exp);\n+      return altivec_expand_stv_builtin (CODE_FOR_altivec_stvx_v4si, exp);\n     case ALTIVEC_BUILTIN_STVEBX:\n       return altivec_expand_stv_builtin (CODE_FOR_altivec_stvebx, exp);\n     case ALTIVEC_BUILTIN_STVEHX:\n@@ -11576,6 +11591,19 @@ altivec_expand_builtin (tree exp, rtx target, bool *expandedp)\n     case ALTIVEC_BUILTIN_STVRXL:\n       return altivec_expand_stv_builtin (CODE_FOR_altivec_stvrxl, exp);\n \n+    case VSX_BUILTIN_STXVD2X_V2DF:\n+      return altivec_expand_stv_builtin (CODE_FOR_vsx_store_v2df, exp);\n+    case VSX_BUILTIN_STXVD2X_V2DI:\n+      return altivec_expand_stv_builtin (CODE_FOR_vsx_store_v2di, exp);\n+    case VSX_BUILTIN_STXVW4X_V4SF:\n+      return altivec_expand_stv_builtin (CODE_FOR_vsx_store_v4sf, exp);\n+    case VSX_BUILTIN_STXVW4X_V4SI:\n+      return altivec_expand_stv_builtin (CODE_FOR_vsx_store_v4si, exp);\n+    case VSX_BUILTIN_STXVW4X_V8HI:\n+      return altivec_expand_stv_builtin (CODE_FOR_vsx_store_v8hi, exp);\n+    case VSX_BUILTIN_STXVW4X_V16QI:\n+      return altivec_expand_stv_builtin (CODE_FOR_vsx_store_v16qi, exp);\n+\n     case ALTIVEC_BUILTIN_MFVSCR:\n       icode = CODE_FOR_altivec_mfvscr;\n       tmode = insn_data[icode].operand[0].mode;\n@@ -11700,7 +11728,7 @@ altivec_expand_builtin (tree exp, rtx target, bool *expandedp)\n       return altivec_expand_lv_builtin (CODE_FOR_altivec_lvxl,\n \t\t\t\t\texp, target, false);\n     case ALTIVEC_BUILTIN_LVX:\n-      return altivec_expand_lv_builtin (CODE_FOR_altivec_lvx,\n+      return altivec_expand_lv_builtin (CODE_FOR_altivec_lvx_v4si,\n \t\t\t\t\texp, target, false);\n     case ALTIVEC_BUILTIN_LVLX:\n       return altivec_expand_lv_builtin (CODE_FOR_altivec_lvlx,\n@@ -11714,6 +11742,25 @@ altivec_expand_builtin (tree exp, rtx target, bool *expandedp)\n     case ALTIVEC_BUILTIN_LVRXL:\n       return altivec_expand_lv_builtin (CODE_FOR_altivec_lvrxl,\n \t\t\t\t\texp, target, true);\n+    case VSX_BUILTIN_LXVD2X_V2DF:\n+      return altivec_expand_lv_builtin (CODE_FOR_vsx_load_v2df,\n+\t\t\t\t\texp, target, false);\n+    case VSX_BUILTIN_LXVD2X_V2DI:\n+      return altivec_expand_lv_builtin (CODE_FOR_vsx_load_v2di,\n+\t\t\t\t\texp, target, false);\n+    case VSX_BUILTIN_LXVW4X_V4SF:\n+      return altivec_expand_lv_builtin (CODE_FOR_vsx_load_v4sf,\n+\t\t\t\t\texp, target, false);\n+    case VSX_BUILTIN_LXVW4X_V4SI:\n+      return altivec_expand_lv_builtin (CODE_FOR_vsx_load_v4si,\n+\t\t\t\t\texp, target, false);\n+    case VSX_BUILTIN_LXVW4X_V8HI:\n+      return altivec_expand_lv_builtin (CODE_FOR_vsx_load_v8hi,\n+\t\t\t\t\texp, target, false);\n+    case VSX_BUILTIN_LXVW4X_V16QI:\n+      return altivec_expand_lv_builtin (CODE_FOR_vsx_load_v16qi,\n+\t\t\t\t\texp, target, false);\n+      break;\n     default:\n       break;\n       /* Fall through.  */\n@@ -12331,6 +12378,8 @@ rs6000_init_builtins (void)\n \n   long_integer_type_internal_node = long_integer_type_node;\n   long_unsigned_type_internal_node = long_unsigned_type_node;\n+  long_long_integer_type_internal_node = long_long_integer_type_node;\n+  long_long_unsigned_type_internal_node = long_long_unsigned_type_node;\n   intQI_type_internal_node = intQI_type_node;\n   uintQI_type_internal_node = unsigned_intQI_type_node;\n   intHI_type_internal_node = intHI_type_node;\n@@ -12340,7 +12389,7 @@ rs6000_init_builtins (void)\n   intDI_type_internal_node = intDI_type_node;\n   uintDI_type_internal_node = unsigned_intDI_type_node;\n   float_type_internal_node = float_type_node;\n-  double_type_internal_node = float_type_node;\n+  double_type_internal_node = double_type_node;\n   void_type_internal_node = void_type_node;\n \n   /* Initialize the modes for builtin_function_type, mapping a machine mode to\n@@ -12872,19 +12921,11 @@ altivec_init_builtins (void)\n   size_t i;\n   tree ftype;\n \n-  tree pfloat_type_node = build_pointer_type (float_type_node);\n-  tree pint_type_node = build_pointer_type (integer_type_node);\n-  tree pshort_type_node = build_pointer_type (short_integer_type_node);\n-  tree pchar_type_node = build_pointer_type (char_type_node);\n-\n   tree pvoid_type_node = build_pointer_type (void_type_node);\n \n-  tree pcfloat_type_node = build_pointer_type (build_qualified_type (float_type_node, TYPE_QUAL_CONST));\n-  tree pcint_type_node = build_pointer_type (build_qualified_type (integer_type_node, TYPE_QUAL_CONST));\n-  tree pcshort_type_node = build_pointer_type (build_qualified_type (short_integer_type_node, TYPE_QUAL_CONST));\n-  tree pcchar_type_node = build_pointer_type (build_qualified_type (char_type_node, TYPE_QUAL_CONST));\n-\n-  tree pcvoid_type_node = build_pointer_type (build_qualified_type (void_type_node, TYPE_QUAL_CONST));\n+  tree pcvoid_type_node\n+    = build_pointer_type (build_qualified_type (void_type_node,\n+\t\t\t\t\t\tTYPE_QUAL_CONST));\n \n   tree int_ftype_opaque\n     = build_function_type_list (integer_type_node,\n@@ -12907,26 +12948,6 @@ altivec_init_builtins (void)\n     = build_function_type_list (integer_type_node,\n \t\t\t\tinteger_type_node, V4SI_type_node,\n \t\t\t\tV4SI_type_node, NULL_TREE);\n-  tree v4sf_ftype_pcfloat\n-    = build_function_type_list (V4SF_type_node, pcfloat_type_node, NULL_TREE);\n-  tree void_ftype_pfloat_v4sf\n-    = build_function_type_list (void_type_node,\n-\t\t\t\tpfloat_type_node, V4SF_type_node, NULL_TREE);\n-  tree v4si_ftype_pcint\n-    = build_function_type_list (V4SI_type_node, pcint_type_node, NULL_TREE);\n-  tree void_ftype_pint_v4si\n-    = build_function_type_list (void_type_node,\n-\t\t\t\tpint_type_node, V4SI_type_node, NULL_TREE);\n-  tree v8hi_ftype_pcshort\n-    = build_function_type_list (V8HI_type_node, pcshort_type_node, NULL_TREE);\n-  tree void_ftype_pshort_v8hi\n-    = build_function_type_list (void_type_node,\n-\t\t\t\tpshort_type_node, V8HI_type_node, NULL_TREE);\n-  tree v16qi_ftype_pcchar\n-    = build_function_type_list (V16QI_type_node, pcchar_type_node, NULL_TREE);\n-  tree void_ftype_pchar_v16qi\n-    = build_function_type_list (void_type_node,\n-\t\t\t\tpchar_type_node, V16QI_type_node, NULL_TREE);\n   tree void_ftype_v4si\n     = build_function_type_list (void_type_node, V4SI_type_node, NULL_TREE);\n   tree v8hi_ftype_void\n@@ -12938,16 +12959,32 @@ altivec_init_builtins (void)\n \n   tree opaque_ftype_long_pcvoid\n     = build_function_type_list (opaque_V4SI_type_node,\n-\t\t\t\tlong_integer_type_node, pcvoid_type_node, NULL_TREE);\n+\t\t\t\tlong_integer_type_node, pcvoid_type_node,\n+\t\t\t\tNULL_TREE);\n   tree v16qi_ftype_long_pcvoid\n     = build_function_type_list (V16QI_type_node,\n-\t\t\t\tlong_integer_type_node, pcvoid_type_node, NULL_TREE);\n+\t\t\t\tlong_integer_type_node, pcvoid_type_node,\n+\t\t\t\tNULL_TREE);\n   tree v8hi_ftype_long_pcvoid\n     = build_function_type_list (V8HI_type_node,\n-\t\t\t\tlong_integer_type_node, pcvoid_type_node, NULL_TREE);\n+\t\t\t\tlong_integer_type_node, pcvoid_type_node,\n+\t\t\t\tNULL_TREE);\n   tree v4si_ftype_long_pcvoid\n     = build_function_type_list (V4SI_type_node,\n-\t\t\t\tlong_integer_type_node, pcvoid_type_node, NULL_TREE);\n+\t\t\t\tlong_integer_type_node, pcvoid_type_node,\n+\t\t\t\tNULL_TREE);\n+  tree v4sf_ftype_long_pcvoid\n+    = build_function_type_list (V4SF_type_node,\n+\t\t\t\tlong_integer_type_node, pcvoid_type_node,\n+\t\t\t\tNULL_TREE);\n+  tree v2df_ftype_long_pcvoid\n+    = build_function_type_list (V2DF_type_node,\n+\t\t\t\tlong_integer_type_node, pcvoid_type_node,\n+\t\t\t\tNULL_TREE);\n+  tree v2di_ftype_long_pcvoid\n+    = build_function_type_list (V2DI_type_node,\n+\t\t\t\tlong_integer_type_node, pcvoid_type_node,\n+\t\t\t\tNULL_TREE);\n \n   tree void_ftype_opaque_long_pvoid\n     = build_function_type_list (void_type_node,\n@@ -12965,6 +13002,18 @@ altivec_init_builtins (void)\n     = build_function_type_list (void_type_node,\n \t\t\t\tV8HI_type_node, long_integer_type_node,\n \t\t\t\tpvoid_type_node, NULL_TREE);\n+  tree void_ftype_v4sf_long_pvoid\n+    = build_function_type_list (void_type_node,\n+\t\t\t\tV4SF_type_node, long_integer_type_node,\n+\t\t\t\tpvoid_type_node, NULL_TREE);\n+  tree void_ftype_v2df_long_pvoid\n+    = build_function_type_list (void_type_node,\n+\t\t\t\tV2DF_type_node, long_integer_type_node,\n+\t\t\t\tpvoid_type_node, NULL_TREE);\n+  tree void_ftype_v2di_long_pvoid\n+    = build_function_type_list (void_type_node,\n+\t\t\t\tV2DI_type_node, long_integer_type_node,\n+\t\t\t\tpvoid_type_node, NULL_TREE);\n   tree int_ftype_int_v8hi_v8hi\n     = build_function_type_list (integer_type_node,\n \t\t\t\tinteger_type_node, V8HI_type_node,\n@@ -12996,22 +13045,6 @@ altivec_init_builtins (void)\n \t\t\t\tpcvoid_type_node, integer_type_node,\n \t\t\t\tinteger_type_node, NULL_TREE);\n \n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_4sf\", v4sf_ftype_pcfloat,\n-\t       ALTIVEC_BUILTIN_LD_INTERNAL_4sf);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_4sf\", void_ftype_pfloat_v4sf,\n-\t       ALTIVEC_BUILTIN_ST_INTERNAL_4sf);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_4si\", v4si_ftype_pcint,\n-\t       ALTIVEC_BUILTIN_LD_INTERNAL_4si);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_4si\", void_ftype_pint_v4si,\n-\t       ALTIVEC_BUILTIN_ST_INTERNAL_4si);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_8hi\", v8hi_ftype_pcshort,\n-\t       ALTIVEC_BUILTIN_LD_INTERNAL_8hi);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_8hi\", void_ftype_pshort_v8hi,\n-\t       ALTIVEC_BUILTIN_ST_INTERNAL_8hi);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_ld_internal_16qi\", v16qi_ftype_pcchar,\n-\t       ALTIVEC_BUILTIN_LD_INTERNAL_16qi);\n-  def_builtin (MASK_ALTIVEC, \"__builtin_altivec_st_internal_16qi\", void_ftype_pchar_v16qi,\n-\t       ALTIVEC_BUILTIN_ST_INTERNAL_16qi);\n   def_builtin (MASK_ALTIVEC, \"__builtin_altivec_mtvscr\", void_ftype_v4si, ALTIVEC_BUILTIN_MTVSCR);\n   def_builtin (MASK_ALTIVEC, \"__builtin_altivec_mfvscr\", v8hi_ftype_void, ALTIVEC_BUILTIN_MFVSCR);\n   def_builtin (MASK_ALTIVEC, \"__builtin_altivec_dssall\", void_ftype_void, ALTIVEC_BUILTIN_DSSALL);\n@@ -13043,6 +13076,35 @@ altivec_init_builtins (void)\n   def_builtin (MASK_ALTIVEC, \"__builtin_vec_stvebx\", void_ftype_opaque_long_pvoid, ALTIVEC_BUILTIN_VEC_STVEBX);\n   def_builtin (MASK_ALTIVEC, \"__builtin_vec_stvehx\", void_ftype_opaque_long_pvoid, ALTIVEC_BUILTIN_VEC_STVEHX);\n \n+  def_builtin (MASK_VSX, \"__builtin_vsx_lxvd2x_v2df\", v2df_ftype_long_pcvoid,\n+\t       VSX_BUILTIN_LXVD2X_V2DF);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_lxvd2x_v2di\", v2di_ftype_long_pcvoid,\n+\t       VSX_BUILTIN_LXVD2X_V2DI);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_lxvw4x_v4sf\", v4sf_ftype_long_pcvoid,\n+\t       VSX_BUILTIN_LXVW4X_V4SF);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_lxvw4x_v4si\", v4si_ftype_long_pcvoid,\n+\t       VSX_BUILTIN_LXVW4X_V4SI);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_lxvw4x_v8hi\",\n+\t       v8hi_ftype_long_pcvoid, VSX_BUILTIN_LXVW4X_V8HI);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_lxvw4x_v16qi\",\n+\t       v16qi_ftype_long_pcvoid, VSX_BUILTIN_LXVW4X_V16QI);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_stxvd2x_v2df\",\n+\t       void_ftype_v2df_long_pvoid, VSX_BUILTIN_STXVD2X_V2DF);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_stxvd2x_v2di\",\n+\t       void_ftype_v2di_long_pvoid, VSX_BUILTIN_STXVD2X_V2DI);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_stxvw4x_v4sf\",\n+\t       void_ftype_v4sf_long_pvoid, VSX_BUILTIN_STXVW4X_V4SF);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_stxvw4x_v4si\",\n+\t       void_ftype_v4si_long_pvoid, VSX_BUILTIN_STXVW4X_V4SI);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_stxvw4x_v8hi\",\n+\t       void_ftype_v8hi_long_pvoid, VSX_BUILTIN_STXVW4X_V8HI);\n+  def_builtin (MASK_VSX, \"__builtin_vsx_stxvw4x_v16qi\",\n+\t       void_ftype_v16qi_long_pvoid, VSX_BUILTIN_STXVW4X_V16QI);\n+  def_builtin (MASK_VSX, \"__builtin_vec_vsx_ld\", opaque_ftype_long_pcvoid,\n+\t       VSX_BUILTIN_VEC_LD);\n+  def_builtin (MASK_VSX, \"__builtin_vec_vsx_st\", void_ftype_opaque_long_pvoid,\n+\t       VSX_BUILTIN_VEC_ST);\n+\n   if (rs6000_cpu == PROCESSOR_CELL)\n     {\n       def_builtin (MASK_ALTIVEC, \"__builtin_altivec_lvlx\",  v16qi_ftype_long_pcvoid, ALTIVEC_BUILTIN_LVLX);\n@@ -27925,4 +27987,29 @@ rs6000_address_for_fpconvert (rtx x)\n   return x;\n }\n \n+/* Given a memory reference, if it is not in the form for altivec memory\n+   reference instructions (i.e. reg or reg+reg addressing with AND of -16),\n+   convert to the altivec format.  */\n+\n+rtx\n+rs6000_address_for_altivec (rtx x)\n+{\n+  gcc_assert (MEM_P (x));\n+  if (!altivec_indexed_or_indirect_operand (x, GET_MODE (x)))\n+    {\n+      rtx addr = XEXP (x, 0);\n+      int strict_p = (reload_in_progress || reload_completed);\n+\n+      if (!legitimate_indexed_address_p (addr, strict_p)\n+\t  && !legitimate_indirect_address_p (addr, strict_p))\n+\taddr = copy_to_mode_reg (Pmode, addr);\n+\n+      addr = gen_rtx_AND (Pmode, addr, GEN_INT (-16));\n+      x = change_address (x, GET_MODE (x), addr);\n+    }\n+\n+  return x;\n+}\n+\n+\n #include \"gt-rs6000.h\""}, {"sha": "8c76d7ce101858a003485dc59c9ac2ecfbea3922", "filename": "gcc/config/rs6000/rs6000.h", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Frs6000.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.h?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,7 +1,7 @@\n /* Definitions of target machine for GNU compiler, for IBM RS/6000.\n    Copyright (C) 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n-   2010\n+   2010, 2011\n    Free Software Foundation, Inc.\n    Contributed by Richard Kenner (kenner@vlsi1.ultra.nyu.edu)\n \n@@ -2368,6 +2368,8 @@ enum rs6000_builtin_type_index\n   RS6000_BTI_pixel_V8HI,         /* __vector __pixel */\n   RS6000_BTI_long,\t         /* long_integer_type_node */\n   RS6000_BTI_unsigned_long,      /* long_unsigned_type_node */\n+  RS6000_BTI_long_long,\t         /* long_long_integer_type_node */\n+  RS6000_BTI_unsigned_long_long, /* long_long_unsigned_type_node */\n   RS6000_BTI_INTQI,\t         /* intQI_type_node */\n   RS6000_BTI_UINTQI,\t\t /* unsigned_intQI_type_node */\n   RS6000_BTI_INTHI,\t         /* intHI_type_node */\n@@ -2411,6 +2413,8 @@ enum rs6000_builtin_type_index\n #define bool_V2DI_type_node\t      (rs6000_builtin_types[RS6000_BTI_bool_V2DI])\n #define pixel_V8HI_type_node\t      (rs6000_builtin_types[RS6000_BTI_pixel_V8HI])\n \n+#define long_long_integer_type_internal_node  (rs6000_builtin_types[RS6000_BTI_long_long])\n+#define long_long_unsigned_type_internal_node (rs6000_builtin_types[RS6000_BTI_unsigned_long_long])\n #define long_integer_type_internal_node  (rs6000_builtin_types[RS6000_BTI_long])\n #define long_unsigned_type_internal_node (rs6000_builtin_types[RS6000_BTI_unsigned_long])\n #define intQI_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_INTQI])"}, {"sha": "5335d9d43016aa30fc7505277b651336c3b4572f", "filename": "gcc/config/rs6000/vector.md", "status": "modified", "additions": 38, "deletions": 1, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Fvector.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Fvector.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fvector.md?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -3,7 +3,7 @@\n ;; expander, and the actual vector instructions will be in altivec.md and\n ;; vsx.md\n \n-;; Copyright (C) 2009, 2010\n+;; Copyright (C) 2009, 2010, 2011\n ;; Free Software Foundation, Inc.\n ;; Contributed by Michael Meissner <meissner@linux.vnet.ibm.com>\n \n@@ -123,6 +123,43 @@\n   DONE;\n })\n \n+;; Vector floating point load/store instructions that uses the Altivec\n+;; instructions even if we are compiling for VSX, since the Altivec\n+;; instructions silently ignore the bottom 3 bits of the address, and VSX does\n+;; not.\n+(define_expand \"vector_altivec_load_<mode>\"\n+  [(set (match_operand:VEC_M 0 \"vfloat_operand\" \"\")\n+\t(match_operand:VEC_M 1 \"memory_operand\" \"\"))]\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n+  \"\n+{\n+  gcc_assert (VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode));\n+\n+  if (VECTOR_MEM_VSX_P (<MODE>mode))\n+    {\n+      operands[1] = rs6000_address_for_altivec (operands[1]);\n+      emit_insn (gen_altivec_lvx_<mode> (operands[0], operands[1]));\n+      DONE;\n+    }\n+}\")\n+\n+(define_expand \"vector_altivec_store_<mode>\"\n+  [(set (match_operand:VEC_M 0 \"memory_operand\" \"\")\n+\t(match_operand:VEC_M 1 \"vfloat_operand\" \"\"))]\n+  \"VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode)\"\n+  \"\n+{\n+  gcc_assert (VECTOR_MEM_ALTIVEC_OR_VSX_P (<MODE>mode));\n+\n+  if (VECTOR_MEM_VSX_P (<MODE>mode))\n+    {\n+      operands[0] = rs6000_address_for_altivec (operands[0]);\n+      emit_insn (gen_altivec_stvx_<mode> (operands[0], operands[1]));\n+      DONE;\n+    }\n+}\")\n+\n+\n \f\n ;; Reload patterns for vector operations.  We may need an addtional base\n ;; register to convert the reg+offset addressing to reg+reg for vector"}, {"sha": "3f6da4c0b4046b7139313ac07d67aa9f65f0c06c", "filename": "gcc/config/rs6000/vsx.md", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Fvsx.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fconfig%2Frs6000%2Fvsx.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fvsx.md?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -308,6 +308,19 @@\n }\n   [(set_attr \"type\" \"vecstore,vecload,vecsimple,*,*,*,vecsimple,*,vecstore,vecload\")])\n \n+;; Explicit  load/store expanders for the builtin functions\n+(define_expand \"vsx_load_<mode>\"\n+  [(set (match_operand:VSX_M 0 \"vsx_register_operand\" \"\")\n+\t(match_operand:VSX_M 1 \"memory_operand\" \"\"))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vsx_store_<mode>\"\n+  [(set (match_operand:VEC_M 0 \"memory_operand\" \"\")\n+\t(match_operand:VEC_M 1 \"vsx_register_operand\" \"\"))]\n+  \"VECTOR_MEM_VSX_P (<MODE>mode)\"\n+  \"\")\n+\n \f\n ;; VSX scalar and vector floating point arithmetic instructions\n (define_insn \"*vsx_add<mode>3\""}, {"sha": "67513608e3d21cb4ccc1b03c4ea9baa3510ca6e2", "filename": "gcc/doc/extend.texi", "status": "modified", "additions": 67, "deletions": 1, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fdoc%2Fextend.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Fdoc%2Fextend.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fextend.texi?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -12359,6 +12359,12 @@ vector bool long vec_cmplt (vector double, vector double);\n vector float vec_div (vector float, vector float);\n vector double vec_div (vector double, vector double);\n vector double vec_floor (vector double);\n+vector double vec_ld (int, const vector double *);\n+vector double vec_ld (int, const double *);\n+vector double vec_ldl (int, const vector double *);\n+vector double vec_ldl (int, const double *);\n+vector unsigned char vec_lvsl (int, const volatile double *);\n+vector unsigned char vec_lvsr (int, const volatile double *);\n vector double vec_madd (vector double, vector double, vector double);\n vector double vec_max (vector double, vector double);\n vector double vec_min (vector double, vector double);\n@@ -12387,6 +12393,8 @@ vector double vec_sel (vector double, vector double, vector unsigned long);\n vector double vec_sub (vector double, vector double);\n vector float vec_sqrt (vector float);\n vector double vec_sqrt (vector double);\n+void vec_st (vector double, int, vector double *);\n+void vec_st (vector double, int, double *);\n vector double vec_trunc (vector double);\n vector double vec_xor (vector double, vector double);\n vector double vec_xor (vector double, vector bool long);\n@@ -12415,7 +12423,65 @@ int vec_any_ngt (vector double, vector double);\n int vec_any_nle (vector double, vector double);\n int vec_any_nlt (vector double, vector double);\n int vec_any_numeric (vector double);\n-@end smallexample\n+\n+vector double vec_vsx_ld (int, const vector double *);\n+vector double vec_vsx_ld (int, const double *);\n+vector float vec_vsx_ld (int, const vector float *);\n+vector float vec_vsx_ld (int, const float *);\n+vector bool int vec_vsx_ld (int, const vector bool int *);\n+vector signed int vec_vsx_ld (int, const vector signed int *);\n+vector signed int vec_vsx_ld (int, const int *);\n+vector signed int vec_vsx_ld (int, const long *);\n+vector unsigned int vec_vsx_ld (int, const vector unsigned int *);\n+vector unsigned int vec_vsx_ld (int, const unsigned int *);\n+vector unsigned int vec_vsx_ld (int, const unsigned long *);\n+vector bool short vec_vsx_ld (int, const vector bool short *);\n+vector pixel vec_vsx_ld (int, const vector pixel *);\n+vector signed short vec_vsx_ld (int, const vector signed short *);\n+vector signed short vec_vsx_ld (int, const short *);\n+vector unsigned short vec_vsx_ld (int, const vector unsigned short *);\n+vector unsigned short vec_vsx_ld (int, const unsigned short *);\n+vector bool char vec_vsx_ld (int, const vector bool char *);\n+vector signed char vec_vsx_ld (int, const vector signed char *);\n+vector signed char vec_vsx_ld (int, const signed char *);\n+vector unsigned char vec_vsx_ld (int, const vector unsigned char *);\n+vector unsigned char vec_vsx_ld (int, const unsigned char *);\n+\n+void vec_vsx_st (vector double, int, vector double *);\n+void vec_vsx_st (vector double, int, double *);\n+void vec_vsx_st (vector float, int, vector float *);\n+void vec_vsx_st (vector float, int, float *);\n+void vec_vsx_st (vector signed int, int, vector signed int *);\n+void vec_vsx_st (vector signed int, int, int *);\n+void vec_vsx_st (vector unsigned int, int, vector unsigned int *);\n+void vec_vsx_st (vector unsigned int, int, unsigned int *);\n+void vec_vsx_st (vector bool int, int, vector bool int *);\n+void vec_vsx_st (vector bool int, int, unsigned int *);\n+void vec_vsx_st (vector bool int, int, int *);\n+void vec_vsx_st (vector signed short, int, vector signed short *);\n+void vec_vsx_st (vector signed short, int, short *);\n+void vec_vsx_st (vector unsigned short, int, vector unsigned short *);\n+void vec_vsx_st (vector unsigned short, int, unsigned short *);\n+void vec_vsx_st (vector bool short, int, vector bool short *);\n+void vec_vsx_st (vector bool short, int, unsigned short *);\n+void vec_vsx_st (vector pixel, int, vector pixel *);\n+void vec_vsx_st (vector pixel, int, unsigned short *);\n+void vec_vsx_st (vector pixel, int, short *);\n+void vec_vsx_st (vector bool short, int, short *);\n+void vec_vsx_st (vector signed char, int, vector signed char *);\n+void vec_vsx_st (vector signed char, int, signed char *);\n+void vec_vsx_st (vector unsigned char, int, vector unsigned char *);\n+void vec_vsx_st (vector unsigned char, int, unsigned char *);\n+void vec_vsx_st (vector bool char, int, vector bool char *);\n+void vec_vsx_st (vector bool char, int, unsigned char *);\n+void vec_vsx_st (vector bool char, int, signed char *);\n+@end smallexample\n+\n+Note that the @samp{vec_ld} and @samp{vec_st} builtins will always\n+generate the Altivec @samp{LVX} and @samp{STVX} instructions even\n+if the VSX instruction set is available.  The @samp{vec_vsx_ld} and\n+@samp{vec_vsx_st} builtins will always generate the VSX @samp{LXVD2X},\n+@samp{LXVW4X}, @samp{STXVD2X}, and @samp{STXVW4X} instructions.\n \n GCC provides a few other builtins on Powerpc to access certain instructions:\n @smallexample"}, {"sha": "de8cec7888832adccd33f859a6424d4b75c71c30", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,3 +1,19 @@\n+2011-02-02  Michael Meissner  <meissner@linux.vnet.ibm.com>\n+\n+\tPR target/47272\n+\t* gcc.target/powerpc/vsx-builtin-8.c: New file, test vec_vsx_ld\n+\tand vec_vsx_st.\n+\n+\t* gcc.target/powerpc/avoid-indexed-addresses.c: Disable altivec\n+\tand vsx so a default --with-cpu=power7 doesn't give an error\n+\twhen -mavoid-indexed-addresses is used.\n+\n+\t* gcc.target/powerpc/ppc32-abi-dfp-1.c: Rewrite to use an asm\n+\twrapper function to save the arguments and then jump to the real\n+\tfunction, rather than depending on the compiler not to move stuff\n+\tbefore an asm.\n+\t* gcc.target/powerpc/ppc64-abi-dfp-2.c: Ditto.\n+\n 2011-02-02  Janus Weil  <janus@gcc.gnu.org>\n \t    Paul Thomas  <pault@gcc.gnu.org>\n "}, {"sha": "e86aa8a5d2f0d891811c001dc5980596423c842c", "filename": "gcc/testsuite/gcc.target/powerpc/avoid-indexed-addresses.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Favoid-indexed-addresses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Favoid-indexed-addresses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Favoid-indexed-addresses.c?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile { target { powerpc*-*-* } } } */\n-/* { dg-options \"-O2 -mavoid-indexed-addresses\" } */\n+/* { dg-options \"-O2 -mavoid-indexed-addresses -mno-altivec -mno-vsx\" } */\n \n /* { dg-final { scan-assembler-not \"lbzx\" } }\n "}, {"sha": "14908dba690eaa95ac5e585241d07eb4710869f3", "filename": "gcc/testsuite/gcc.target/powerpc/ppc32-abi-dfp-1.c", "status": "modified", "additions": 104, "deletions": 80, "changes": 184, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fppc32-abi-dfp-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fppc32-abi-dfp-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fppc32-abi-dfp-1.c?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -30,147 +30,166 @@ typedef struct\n \n reg_parms_t gparms;\n \n-\n-/* Testcase could break on future gcc's, if parameter regs\n-   are changed before this asm.  */\n-\n-#define save_parms(lparms)\t\t\t\t\\\n-    asm volatile (\"lis 11,gparms@ha\\n\\t\"\t\t\\\n-                  \"la 11,gparms@l(11)\\n\\t\"\t\t\\\n-                  \"st 3,0(11)\\n\\t\"\t\t        \\\n-\t          \"st 4,4(11)\\n\\t\"\t\t\t\\\n-\t          \"st 5,8(11)\\n\\t\"\t\t\t\\\n-\t          \"st 6,12(11)\\n\\t\"\t\t\t\\\n-\t          \"st 7,16(11)\\n\\t\"\t\t\t\\\n-\t          \"st 8,20(11)\\n\\t\"\t\t\t\\\n-\t          \"st 9,24(11)\\n\\t\"\t\t\t\\\n-\t          \"st 10,28(11)\\n\\t\"\t\t\t\\\n-                  \"stfd 1,32(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 2,40(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 3,48(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 4,56(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 5,64(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 6,72(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 7,80(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 8,88(11)\\n\\t\":::\"11\", \"memory\");  \\\n-                  lparms = gparms;\n-\n typedef struct sf\n {\n   struct sf *backchain;\n   int a1;\n   unsigned int slot[200];\n } stack_frame_t;\n \n+/* Wrapper to save the GPRs and FPRs and then jump to the real function.  */\n+#define WRAPPER(NAME)\t\t\t\t\t\t\t\\\n+__asm__ (\"\\t.globl\\t\" #NAME \"_asm\\n\\t\"\t\t\t\t\t\\\n+\t \".text\\n\\t\"\t\t\t\t\t\t\t\\\n+\t \".type \" #NAME \"_asm, @function\\n\"\t\t\t\t\\\n+\t #NAME \"_asm:\\n\\t\"\t\t\t\t\t\t\\\n+\t \"lis 11,gparms@ha\\n\\t\"\t\t\t\t\t\t\\\n+\t \"la 11,gparms@l(11)\\n\\t\"\t\t\t\t\t\\\n+\t \"st 3,0(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"st 4,4(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"st 5,8(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"st 6,12(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"st 7,16(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"st 8,20(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"st 9,24(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"st 10,28(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 1,32(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 2,40(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 3,48(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 4,56(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 5,64(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 6,72(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 7,80(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 8,88(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"b \" #NAME \"\\n\\t\"\t\t\t\t\t\t\\\n+\t \".size \" #NAME \",.-\" #NAME \"\\n\")\n+\n /* Fill up floating point registers with double arguments, forcing\n    decimal float arguments into the parameter save area.  */\n+extern void func0_asm (double, double, double, double, double,\n+\t\t       double, double, double, _Decimal64, _Decimal128);\n+\n+WRAPPER(func0);\n+\n void __attribute__ ((noinline))\n func0 (double a1, double a2, double a3, double a4, double a5,\n        double a6, double a7, double a8, _Decimal64 a9, _Decimal128 a10)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != lparms.fprs[0]) FAILURE\n-  if (a2 != lparms.fprs[1]) FAILURE\n-  if (a3 != lparms.fprs[2]) FAILURE\n-  if (a4 != lparms.fprs[3]) FAILURE\n-  if (a5 != lparms.fprs[4]) FAILURE\n-  if (a6 != lparms.fprs[5]) FAILURE\n-  if (a7 != lparms.fprs[6]) FAILURE\n-  if (a8 != lparms.fprs[7]) FAILURE\n+  if (a1 != gparms.fprs[0]) FAILURE\n+  if (a2 != gparms.fprs[1]) FAILURE\n+  if (a3 != gparms.fprs[2]) FAILURE\n+  if (a4 != gparms.fprs[3]) FAILURE\n+  if (a5 != gparms.fprs[4]) FAILURE\n+  if (a6 != gparms.fprs[5]) FAILURE\n+  if (a7 != gparms.fprs[6]) FAILURE\n+  if (a8 != gparms.fprs[7]) FAILURE\n   if (a9 != *(_Decimal64 *)&sp->slot[0]) FAILURE\n   if (a10 != *(_Decimal128 *)&sp->slot[2]) FAILURE\n }\n \n /* Alternate 64-bit and 128-bit decimal float arguments, checking that\n    _Decimal128 is always passed in even/odd register pairs.  */\n+extern void func1_asm (_Decimal64, _Decimal128, _Decimal64, _Decimal128,\n+\t\t       _Decimal64, _Decimal128, _Decimal64, _Decimal128);\n+\n+WRAPPER(func1);\n+\n void __attribute__ ((noinline))\n func1 (_Decimal64 a1, _Decimal128 a2, _Decimal64 a3, _Decimal128 a4,\n        _Decimal64 a5, _Decimal128 a6, _Decimal64 a7, _Decimal128 a8)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != *(_Decimal64 *)&lparms.fprs[0]) FAILURE\t/* f1 */\n-  if (a2 != *(_Decimal128 *)&lparms.fprs[1]) FAILURE\t/* f2 & f3 */\n-  if (a3 != *(_Decimal64 *)&lparms.fprs[3]) FAILURE\t/* f4 */\n-  if (a4 != *(_Decimal128 *)&lparms.fprs[5]) FAILURE\t/* f6 & f7 */\n-  if (a5 != *(_Decimal64 *)&lparms.fprs[7]) FAILURE\t/* f8 */\n+  if (a1 != *(_Decimal64 *)&gparms.fprs[0]) FAILURE\t/* f1 */\n+  if (a2 != *(_Decimal128 *)&gparms.fprs[1]) FAILURE\t/* f2 & f3 */\n+  if (a3 != *(_Decimal64 *)&gparms.fprs[3]) FAILURE\t/* f4 */\n+  if (a4 != *(_Decimal128 *)&gparms.fprs[5]) FAILURE\t/* f6 & f7 */\n+  if (a5 != *(_Decimal64 *)&gparms.fprs[7]) FAILURE\t/* f8 */\n   if (a6 != *(_Decimal128 *)&sp->slot[0]) FAILURE\n   if (a7 != *(_Decimal64 *)&sp->slot[4]) FAILURE\n   if (a8 != *(_Decimal128 *)&sp->slot[6]) FAILURE\n }\n \n+extern void func2_asm (_Decimal128, _Decimal64, _Decimal128, _Decimal64,\n+\t\t       _Decimal128, _Decimal64, _Decimal128, _Decimal64);\n+\n+WRAPPER(func2);\n+\n void __attribute__ ((noinline))\n func2 (_Decimal128 a1, _Decimal64 a2, _Decimal128 a3, _Decimal64 a4,\n        _Decimal128 a5, _Decimal64 a6, _Decimal128 a7, _Decimal64 a8)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != *(_Decimal128 *)&lparms.fprs[1]) FAILURE\t/* f2 & f3 */\n-  if (a2 != *(_Decimal64 *)&lparms.fprs[3]) FAILURE\t/* f4 */\n-  if (a3 != *(_Decimal128 *)&lparms.fprs[5]) FAILURE\t/* f6 & f7 */\n-  if (a4 != *(_Decimal64 *)&lparms.fprs[7]) FAILURE\t/* f8 */\n+  if (a1 != *(_Decimal128 *)&gparms.fprs[1]) FAILURE\t/* f2 & f3 */\n+  if (a2 != *(_Decimal64 *)&gparms.fprs[3]) FAILURE\t/* f4 */\n+  if (a3 != *(_Decimal128 *)&gparms.fprs[5]) FAILURE\t/* f6 & f7 */\n+  if (a4 != *(_Decimal64 *)&gparms.fprs[7]) FAILURE\t/* f8 */\n   if (a5 != *(_Decimal128 *)&sp->slot[0]) FAILURE\n   if (a6 != *(_Decimal64 *)&sp->slot[4]) FAILURE\n   if (a7 != *(_Decimal128 *)&sp->slot[6]) FAILURE\n   if (a8 != *(_Decimal64 *)&sp->slot[10]) FAILURE\n }\n \n+extern void func3_asm (_Decimal64, _Decimal128, _Decimal64, _Decimal128,\n+\t\t       _Decimal64);\n+\n+WRAPPER(func3);\n+\n void __attribute__ ((noinline))\n func3 (_Decimal64 a1, _Decimal128 a2, _Decimal64 a3, _Decimal128 a4,\n        _Decimal64 a5)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != *(_Decimal64 *)&lparms.fprs[0]) FAILURE\t/* f1 */\n-  if (a2 != *(_Decimal128 *)&lparms.fprs[1]) FAILURE\t/* f2 & f3 */\n-  if (a3 != *(_Decimal64 *)&lparms.fprs[3]) FAILURE\t/* f4 */\n-  if (a4 != *(_Decimal128 *)&lparms.fprs[5]) FAILURE\t/* f6 & f7 */\n+  if (a1 != *(_Decimal64 *)&gparms.fprs[0]) FAILURE\t/* f1 */\n+  if (a2 != *(_Decimal128 *)&gparms.fprs[1]) FAILURE\t/* f2 & f3 */\n+  if (a3 != *(_Decimal64 *)&gparms.fprs[3]) FAILURE\t/* f4 */\n+  if (a4 != *(_Decimal128 *)&gparms.fprs[5]) FAILURE\t/* f6 & f7 */\n   if (a5 != *(_Decimal128 *)&sp->slot[0]) FAILURE\n }\n \n+extern void func4_asm (_Decimal32, _Decimal32, _Decimal32, _Decimal32,\n+\t\t       _Decimal32, _Decimal32, _Decimal32, _Decimal32,\n+\t\t       _Decimal32, _Decimal32, _Decimal32, _Decimal32,\n+\t\t       _Decimal32, _Decimal32, _Decimal32, _Decimal32);\n+\n+WRAPPER(func4);\n+\n void __attribute__ ((noinline))\n func4 (_Decimal32 a1, _Decimal32 a2, _Decimal32 a3, _Decimal32 a4,\n        _Decimal32 a5, _Decimal32 a6, _Decimal32 a7, _Decimal32 a8,\n        _Decimal32 a9, _Decimal32 a10, _Decimal32 a11, _Decimal32 a12,\n        _Decimal32 a13, _Decimal32 a14, _Decimal32 a15, _Decimal32 a16)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n   /* _Decimal32 is passed in the lower half of an FPR, or in parameter slot.  */\n-  if (a1 != ((d32parm_t *)&lparms.fprs[0])->d) FAILURE\t\t/* f1  */\n-  if (a2 != ((d32parm_t *)&lparms.fprs[1])->d) FAILURE\t\t/* f2  */\n-  if (a3 != ((d32parm_t *)&lparms.fprs[2])->d) FAILURE\t\t/* f3  */\n-  if (a4 != ((d32parm_t *)&lparms.fprs[3])->d) FAILURE\t\t/* f4  */\n-  if (a5 != ((d32parm_t *)&lparms.fprs[4])->d) FAILURE\t\t/* f5  */\n-  if (a6 != ((d32parm_t *)&lparms.fprs[5])->d) FAILURE\t\t/* f6  */\n-  if (a7 != ((d32parm_t *)&lparms.fprs[6])->d) FAILURE\t\t/* f7  */\n-  if (a8 != ((d32parm_t *)&lparms.fprs[7])->d) FAILURE\t\t/* f8  */\n+  if (a1 != ((d32parm_t *)&gparms.fprs[0])->d) FAILURE\t\t/* f1  */\n+  if (a2 != ((d32parm_t *)&gparms.fprs[1])->d) FAILURE\t\t/* f2  */\n+  if (a3 != ((d32parm_t *)&gparms.fprs[2])->d) FAILURE\t\t/* f3  */\n+  if (a4 != ((d32parm_t *)&gparms.fprs[3])->d) FAILURE\t\t/* f4  */\n+  if (a5 != ((d32parm_t *)&gparms.fprs[4])->d) FAILURE\t\t/* f5  */\n+  if (a6 != ((d32parm_t *)&gparms.fprs[5])->d) FAILURE\t\t/* f6  */\n+  if (a7 != ((d32parm_t *)&gparms.fprs[6])->d) FAILURE\t\t/* f7  */\n+  if (a8 != ((d32parm_t *)&gparms.fprs[7])->d) FAILURE\t\t/* f8  */\n   if (a9 != *(_Decimal32 *)&sp->slot[0]) FAILURE\n   if (a10 != *(_Decimal32 *)&sp->slot[1]) FAILURE\n   if (a11 != *(_Decimal32 *)&sp->slot[2]) FAILURE\n@@ -181,24 +200,29 @@ func4 (_Decimal32 a1, _Decimal32 a2, _Decimal32 a3, _Decimal32 a4,\n   if (a16 != *(_Decimal32 *)&sp->slot[7]) FAILURE\n }\n \n+extern void func5_asm (_Decimal32, _Decimal64, _Decimal128,\n+\t\t       _Decimal32, _Decimal64, _Decimal128,\n+\t\t       _Decimal32, _Decimal64, _Decimal128,\n+\t\t       _Decimal32, _Decimal64, _Decimal128);\n+\n+WRAPPER(func5);\n+\n void __attribute__ ((noinline))\n func5 (_Decimal32 a1, _Decimal64 a2, _Decimal128 a3,\n        _Decimal32 a4, _Decimal64 a5, _Decimal128 a6,\n        _Decimal32 a7, _Decimal64 a8, _Decimal128 a9,\n        _Decimal32 a10, _Decimal64 a11, _Decimal128 a12)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != ((d32parm_t *)&lparms.fprs[0])->d) FAILURE\t\t/* f1      */\n-  if (a2 != *(_Decimal64 *)&lparms.fprs[1]) FAILURE\t\t/* f2      */\n-  if (a3 != *(_Decimal128 *)&lparms.fprs[3]) FAILURE\t\t/* f4 & f5 */\n-  if (a4 != ((d32parm_t *)&lparms.fprs[5])->d) FAILURE\t\t/* f6      */\n-  if (a5 != *(_Decimal64 *)&lparms.fprs[6]) FAILURE\t\t/* f7      */\n+  if (a1 != ((d32parm_t *)&gparms.fprs[0])->d) FAILURE\t\t/* f1      */\n+  if (a2 != *(_Decimal64 *)&gparms.fprs[1]) FAILURE\t\t/* f2      */\n+  if (a3 != *(_Decimal128 *)&gparms.fprs[3]) FAILURE\t\t/* f4 & f5 */\n+  if (a4 != ((d32parm_t *)&gparms.fprs[5])->d) FAILURE\t\t/* f6      */\n+  if (a5 != *(_Decimal64 *)&gparms.fprs[6]) FAILURE\t\t/* f7      */\n \n   if (a6 != *(_Decimal128 *)&sp->slot[0]) FAILURE\n   if (a7 != *(_Decimal32 *)&sp->slot[4]) FAILURE\n@@ -212,15 +236,15 @@ func5 (_Decimal32 a1, _Decimal64 a2, _Decimal128 a3,\n int\n main ()\n {\n-  func0 (1., 2., 3., 4., 5., 6., 7., 8., 9.dd, 10.dl);\n-  func1 (1.dd, 2.dl, 3.dd, 4.dl, 5.dd, 6.dl, 7.dd, 8.dl);\n-  func2 (1.dl, 2.dd, 3.dl, 4.dd, 5.dl, 6.dd, 7.dl, 8.dd);\n-  func3 (1.dd, 2.dl, 3.dd, 4.dl, 5.dl);\n-  func4 (501.2df, 502.2df, 503.2df, 504.2df, 505.2df, 506.2df, 507.2df,\n-\t 508.2df, 509.2df, 510.2df, 511.2df, 512.2df, 513.2df, 514.2df,\n-\t 515.2df, 516.2df);\n-  func5 (601.2df, 602.2dd, 603.2dl, 604.2df, 605.2dd, 606.2dl,\n-\t 607.2df, 608.2dd, 609.2dl, 610.2df, 611.2dd, 612.2dl);\n+  func0_asm (1., 2., 3., 4., 5., 6., 7., 8., 9.dd, 10.dl);\n+  func1_asm (1.dd, 2.dl, 3.dd, 4.dl, 5.dd, 6.dl, 7.dd, 8.dl);\n+  func2_asm (1.dl, 2.dd, 3.dl, 4.dd, 5.dl, 6.dd, 7.dl, 8.dd);\n+  func3_asm (1.dd, 2.dl, 3.dd, 4.dl, 5.dl);\n+  func4_asm (501.2df, 502.2df, 503.2df, 504.2df, 505.2df, 506.2df, 507.2df,\n+\t     508.2df, 509.2df, 510.2df, 511.2df, 512.2df, 513.2df, 514.2df,\n+\t     515.2df, 516.2df);\n+  func5_asm (601.2df, 602.2dd, 603.2dl, 604.2df, 605.2dd, 606.2dl,\n+\t     607.2df, 608.2dd, 609.2dl, 610.2df, 611.2dd, 612.2dl);\n \n   if (failcnt != 0)\n     abort ();"}, {"sha": "eb54a653bf7c23487f6b16da5c95a1e88f559238", "filename": "gcc/testsuite/gcc.target/powerpc/ppc64-abi-dfp-1.c", "status": "modified", "additions": 169, "deletions": 156, "changes": 325, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fppc64-abi-dfp-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fppc64-abi-dfp-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fppc64-abi-dfp-1.c?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -1,4 +1,5 @@\n /* { dg-do run { target { powerpc64-*-* && { lp64 && dfprt } } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n /* { dg-options \"-std=gnu99 -O2 -fno-strict-aliasing\" } */\n \n /* Testcase to check for ABI compliance of parameter passing\n@@ -31,60 +32,42 @@ typedef struct\n reg_parms_t gparms;\n \n \n-/* Testcase could break on future gcc's, if parameter regs\n-   are changed before this asm.  */\n-\n-#ifndef __MACH__\n-#define save_parms(lparms)\t\t\t\t\\\n-    asm volatile (\"ld 11,gparms@got(2)\\n\\t\"                \\\n-                  \"std 3,0(11)\\n\\t\"\t\t        \\\n-\t          \"std 4,8(11)\\n\\t\"\t\t\t\\\n-\t          \"std 5,16(11)\\n\\t\"\t\t\t\\\n-\t          \"std 6,24(11)\\n\\t\"\t\t\t\\\n-\t          \"std 7,32(11)\\n\\t\"\t\t\t\\\n-\t          \"std 8,40(11)\\n\\t\"\t\t\t\\\n-\t          \"std 9,48(11)\\n\\t\"\t\t\t\\\n-\t          \"std 10,56(11)\\n\\t\"\t\t\t\\\n-                  \"stfd 1,64(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 2,72(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 3,80(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 4,88(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 5,96(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 6,104(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 7,112(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 8,120(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 9,128(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 10,136(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 11,144(11)\\n\\t\"\t\t\t\\\n-\t          \"stfd 12,152(11)\\n\\t\"                 \\\n-\t          \"stfd 13,160(11)\\n\\t\":::\"11\", \"memory\");  \\\n-                  lparms = gparms;\n-#else\n-#define save_parms(lparms)\t\t\t\t\\\n-    asm volatile (\"ld r11,gparms@got(r2)\\n\\t\"           \\\n-                  \"std r3,0(r11)\\n\\t\"\t\t        \\\n-\t          \"std r4,8(r11)\\n\\t\"\t\t\t\\\n-\t          \"std r5,16(r11)\\n\\t\"\t\t\t\\\n-\t          \"std r6,24(r11)\\n\\t\"\t\t\t\\\n-\t          \"std r7,32(r11)\\n\\t\"\t\t\t\\\n-\t          \"std r8,40(r11)\\n\\t\"\t\t\t\\\n-\t          \"std r9,48(r11)\\n\\t\"\t\t\t\\\n-\t          \"std r10,56(r11)\\n\\t\"                 \\\n-                  \"stfd f1,64(r11)\\n\\t\"\t\t        \\\n-\t          \"stfd f2,72(r11)\\n\\t\"\t\t\t\\\n-\t          \"stfd f3,80(r11)\\n\\t\"\t\t\t\\\n-\t          \"stfd f4,88(r11)\\n\\t\"\t\t\t\\\n-\t          \"stfd f5,96(r11)\\n\\t\"\t\t\t\\\n-\t          \"stfd f6,104(r11)\\n\\t\"\t\t\\\n-\t          \"stfd f7,112(r11)\\n\\t\"\t\t\\\n-\t          \"stfd f8,120(r11)\\n\\t\"\t\t\\\n-\t          \"stfd f9,128(r11)\\n\\t\"\t\t\\\n-\t          \"stfd f10,136(r11)\\n\\t\"\t\t\\\n-\t          \"stfd f11,144(r11)\\n\\t\"\t\t\\\n-\t          \"stfd f12,152(r11)\\n\\t\"               \\\n-\t          \"stfd f13,160(r11)\\n\\t\":::\"r11\", \"memory\");  \\\n-                  lparms = gparms;\n-#endif\n+/* Wrapper to save the GPRs and FPRs and then jump to the real function.  */\n+#define WRAPPER(NAME)\t\t\t\t\t\t\t\\\n+__asm__ (\"\\t.globl\\t\" #NAME \"_asm\\n\\t\"\t\t\t\t\t\\\n+\t \".section \\\".opd\\\",\\\"aw\\\"\\n\\t\"\t\t\t\t\t\\\n+\t \".align 3\\n\"\t\t\t\t\t\t\t\\\n+\t #NAME \"_asm:\\n\\t\"\t\t\t\t\t\t\\\n+\t \".quad .L.\" #NAME \"_asm,.TOC.@tocbase,0\\n\\t\"\t\t\t\\\n+\t \".text\\n\\t\"\t\t\t\t\t\t\t\\\n+\t \".type \" #NAME \"_asm, @function\\n\"\t\t\t\t\\\n+\t \".L.\" #NAME \"_asm:\\n\\t\"\t\t\t\t\t\\\n+\t \"ld 11,gparms@got(2)\\n\\t\"\t\t\t\t\t\\\n+\t \"std 3,0(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"std 4,8(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"std 5,16(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"std 6,24(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"std 7,32(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"std 8,40(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"std 9,48(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"std 10,56(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 1,64(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 2,72(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 3,80(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 4,88(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 5,96(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 6,104(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 7,112(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 8,120(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 9,128(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 10,136(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 11,144(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 12,152(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"stfd 13,160(11)\\n\\t\"\t\t\t\t\t\t\\\n+\t \"b \" #NAME \"\\n\\t\"\t\t\t\t\t\t\\\n+\t \".long 0\\n\\t\"\t\t\t\t\t\t\t\\\n+\t \".byte 0,0,0,0,0,0,0,0\\n\\t\"\t\t\t\t\t\\\n+\t \".size \" #NAME \",.-\" #NAME \"\\n\")\n \n typedef struct sf\n {\n@@ -97,6 +80,13 @@ typedef struct sf\n   unsigned long slot[100];\n } stack_frame_t;\n \n+extern void func0_asm (double, double, double, double, double, double,\n+\t\t       double, double, double, double, double, double,\n+\t\t       double, double, \n+\t\t       _Decimal64, _Decimal128, _Decimal64);\n+\n+WRAPPER(func0);\n+\n /* Fill up floating point registers with double arguments, forcing\n    decimal float arguments into the parameter save area.  */\n void __attribute__ ((noinline))\n@@ -105,210 +95,233 @@ func0 (double a1, double a2, double a3, double a4, double a5, double a6,\n        double a13, double a14, \n        _Decimal64 a15, _Decimal128 a16, _Decimal64 a17)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != lparms.fprs[0]) FAILURE\n-  if (a2 != lparms.fprs[1]) FAILURE\n-  if (a3 != lparms.fprs[2]) FAILURE\n-  if (a4 != lparms.fprs[3]) FAILURE\n-  if (a5 != lparms.fprs[4]) FAILURE\n-  if (a6 != lparms.fprs[5]) FAILURE\n-  if (a7 != lparms.fprs[6]) FAILURE\n-  if (a8 != lparms.fprs[7]) FAILURE\n-  if (a9 != lparms.fprs[8]) FAILURE\n-  if (a10 != lparms.fprs[9]) FAILURE\n-  if (a11 != lparms.fprs[10]) FAILURE\n-  if (a12 != lparms.fprs[11]) FAILURE\n-  if (a13 != lparms.fprs[12]) FAILURE\n+  if (a1 != gparms.fprs[0]) FAILURE\n+  if (a2 != gparms.fprs[1]) FAILURE\n+  if (a3 != gparms.fprs[2]) FAILURE\n+  if (a4 != gparms.fprs[3]) FAILURE\n+  if (a5 != gparms.fprs[4]) FAILURE\n+  if (a6 != gparms.fprs[5]) FAILURE\n+  if (a7 != gparms.fprs[6]) FAILURE\n+  if (a8 != gparms.fprs[7]) FAILURE\n+  if (a9 != gparms.fprs[8]) FAILURE\n+  if (a10 != gparms.fprs[9]) FAILURE\n+  if (a11 != gparms.fprs[10]) FAILURE\n+  if (a12 != gparms.fprs[11]) FAILURE\n+  if (a13 != gparms.fprs[12]) FAILURE\n   if (a14 != *(double *)&sp->slot[13]) FAILURE\n   if (a15 != *(_Decimal64 *)&sp->slot[14]) FAILURE\n   if (a16 != *(_Decimal128 *)&sp->slot[15]) FAILURE\n   if (a17 != *(_Decimal64 *)&sp->slot[17]) FAILURE\n }\n \n+extern void func1_asm (double, double, double, double, double, double,\n+\t\t       double, double, double, double, double, double,\n+\t\t       double, _Decimal128 );\n+\n+WRAPPER(func1);\n+\n void __attribute__ ((noinline))\n func1 (double a1, double a2, double a3, double a4, double a5, double a6,\n        double a7, double a8, double a9, double a10, double a11, double a12,\n        double a13, _Decimal128 a14)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != lparms.fprs[0]) FAILURE\n-  if (a2 != lparms.fprs[1]) FAILURE\n-  if (a3 != lparms.fprs[2]) FAILURE\n-  if (a4 != lparms.fprs[3]) FAILURE\n-  if (a5 != lparms.fprs[4]) FAILURE\n-  if (a6 != lparms.fprs[5]) FAILURE\n-  if (a7 != lparms.fprs[6]) FAILURE\n-  if (a8 != lparms.fprs[7]) FAILURE\n-  if (a9 != lparms.fprs[8]) FAILURE\n-  if (a10 != lparms.fprs[9]) FAILURE\n-  if (a11 != lparms.fprs[10]) FAILURE\n-  if (a12 != lparms.fprs[11]) FAILURE\n-  if (a13 != lparms.fprs[12]) FAILURE\n+  if (a1 != gparms.fprs[0]) FAILURE\n+  if (a2 != gparms.fprs[1]) FAILURE\n+  if (a3 != gparms.fprs[2]) FAILURE\n+  if (a4 != gparms.fprs[3]) FAILURE\n+  if (a5 != gparms.fprs[4]) FAILURE\n+  if (a6 != gparms.fprs[5]) FAILURE\n+  if (a7 != gparms.fprs[6]) FAILURE\n+  if (a8 != gparms.fprs[7]) FAILURE\n+  if (a9 != gparms.fprs[8]) FAILURE\n+  if (a10 != gparms.fprs[9]) FAILURE\n+  if (a11 != gparms.fprs[10]) FAILURE\n+  if (a12 != gparms.fprs[11]) FAILURE\n+  if (a13 != gparms.fprs[12]) FAILURE\n   if (a14 != *(_Decimal128 *)&sp->slot[13]) FAILURE\n }\n \n+extern void func2_asm (double, double, double, double, double, double,\n+\t\t       double, double, double, double, double, double,\n+\t\t       _Decimal128);\n+\n+WRAPPER(func2);\n+\n void __attribute__ ((noinline))\n func2 (double a1, double a2, double a3, double a4, double a5, double a6,\n        double a7, double a8, double a9, double a10, double a11, double a12,\n        _Decimal128 a13)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != lparms.fprs[0]) FAILURE\n-  if (a2 != lparms.fprs[1]) FAILURE\n-  if (a3 != lparms.fprs[2]) FAILURE\n-  if (a4 != lparms.fprs[3]) FAILURE\n-  if (a5 != lparms.fprs[4]) FAILURE\n-  if (a6 != lparms.fprs[5]) FAILURE\n-  if (a7 != lparms.fprs[6]) FAILURE\n-  if (a8 != lparms.fprs[7]) FAILURE\n-  if (a9 != lparms.fprs[8]) FAILURE\n-  if (a10 != lparms.fprs[9]) FAILURE\n-  if (a11 != lparms.fprs[10]) FAILURE\n-  if (a12 != lparms.fprs[11]) FAILURE\n+  if (a1 != gparms.fprs[0]) FAILURE\n+  if (a2 != gparms.fprs[1]) FAILURE\n+  if (a3 != gparms.fprs[2]) FAILURE\n+  if (a4 != gparms.fprs[3]) FAILURE\n+  if (a5 != gparms.fprs[4]) FAILURE\n+  if (a6 != gparms.fprs[5]) FAILURE\n+  if (a7 != gparms.fprs[6]) FAILURE\n+  if (a8 != gparms.fprs[7]) FAILURE\n+  if (a9 != gparms.fprs[8]) FAILURE\n+  if (a10 != gparms.fprs[9]) FAILURE\n+  if (a11 != gparms.fprs[10]) FAILURE\n+  if (a12 != gparms.fprs[11]) FAILURE\n   if (a13 != *(_Decimal128 *)&sp->slot[12]) FAILURE\n }\n \n+extern void func3_asm (_Decimal64, _Decimal128, _Decimal64, _Decimal128,\n+\t\t       _Decimal64, _Decimal128, _Decimal64, _Decimal128,\n+\t\t       _Decimal64, _Decimal128);\n+\n+WRAPPER(func3);\n+\n void __attribute__ ((noinline))\n func3 (_Decimal64 a1, _Decimal128 a2, _Decimal64 a3, _Decimal128 a4,\n        _Decimal64 a5, _Decimal128 a6, _Decimal64 a7, _Decimal128 a8,\n        _Decimal64 a9, _Decimal128 a10)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != *(_Decimal64 *)&lparms.fprs[0]) FAILURE\t/* f1        */\n-  if (a2 != *(_Decimal128 *)&lparms.fprs[1]) FAILURE\t/* f2 & f3   */\n-  if (a3 != *(_Decimal64 *)&lparms.fprs[3]) FAILURE\t/* f4        */\n-  if (a4 != *(_Decimal128 *)&lparms.fprs[5]) FAILURE\t/* f6 & f7   */\n-  if (a5 != *(_Decimal64 *)&lparms.fprs[7]) FAILURE\t/* f8        */\n-  if (a6 != *(_Decimal128 *)&lparms.fprs[9]) FAILURE\t/* f10 & f11 */\n-  if (a7 != *(_Decimal64 *)&lparms.fprs[11]) FAILURE\t/* f12       */\n+  if (a1 != *(_Decimal64 *)&gparms.fprs[0]) FAILURE\t/* f1        */\n+  if (a2 != *(_Decimal128 *)&gparms.fprs[1]) FAILURE\t/* f2 & f3   */\n+  if (a3 != *(_Decimal64 *)&gparms.fprs[3]) FAILURE\t/* f4        */\n+  if (a4 != *(_Decimal128 *)&gparms.fprs[5]) FAILURE\t/* f6 & f7   */\n+  if (a5 != *(_Decimal64 *)&gparms.fprs[7]) FAILURE\t/* f8        */\n+  if (a6 != *(_Decimal128 *)&gparms.fprs[9]) FAILURE\t/* f10 & f11 */\n+  if (a7 != *(_Decimal64 *)&gparms.fprs[11]) FAILURE\t/* f12       */\n   if (a8 != *(_Decimal128 *)&sp->slot[10]) FAILURE\n   if (a9 != *(_Decimal64 *)&sp->slot[12]) FAILURE\n   if (a10 != *(_Decimal128 *)&sp->slot[13]) FAILURE\n }\n \n+extern void func4_asm (_Decimal128, _Decimal64, _Decimal128, _Decimal64,\n+\t\t       _Decimal128, _Decimal64, _Decimal128, _Decimal64);\n+\n+WRAPPER(func4);\n+\n void __attribute__ ((noinline))\n func4 (_Decimal128 a1, _Decimal64 a2, _Decimal128 a3, _Decimal64 a4,\n        _Decimal128 a5, _Decimal64 a6, _Decimal128 a7, _Decimal64 a8)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != *(_Decimal128 *)&lparms.fprs[1]) FAILURE\t/* f2 & f3   */\n-  if (a2 != *(_Decimal64 *)&lparms.fprs[3]) FAILURE\t/* f4        */\n-  if (a3 != *(_Decimal128 *)&lparms.fprs[5]) FAILURE\t/* f6 & f7   */\n-  if (a4 != *(_Decimal64 *)&lparms.fprs[7]) FAILURE\t/* f8        */\n-  if (a5 != *(_Decimal128 *)&lparms.fprs[9]) FAILURE\t/* f10 & f11 */\n-  if (a6 != *(_Decimal64 *)&lparms.fprs[11]) FAILURE\t/* f12       */\n+  if (a1 != *(_Decimal128 *)&gparms.fprs[1]) FAILURE\t/* f2 & f3   */\n+  if (a2 != *(_Decimal64 *)&gparms.fprs[3]) FAILURE\t/* f4        */\n+  if (a3 != *(_Decimal128 *)&gparms.fprs[5]) FAILURE\t/* f6 & f7   */\n+  if (a4 != *(_Decimal64 *)&gparms.fprs[7]) FAILURE\t/* f8        */\n+  if (a5 != *(_Decimal128 *)&gparms.fprs[9]) FAILURE\t/* f10 & f11 */\n+  if (a6 != *(_Decimal64 *)&gparms.fprs[11]) FAILURE\t/* f12       */\n   if (a7 != *(_Decimal128 *)&sp->slot[9]) FAILURE\n   if (a8 != *(_Decimal64 *)&sp->slot[11]) FAILURE\n }\n \n+extern void func5_asm (_Decimal32, _Decimal32, _Decimal32, _Decimal32,\n+\t\t       _Decimal32, _Decimal32, _Decimal32, _Decimal32,\n+\t\t       _Decimal32, _Decimal32, _Decimal32, _Decimal32,\n+\t\t       _Decimal32, _Decimal32, _Decimal32, _Decimal32);\n+\n+WRAPPER(func5);\n+\n void __attribute__ ((noinline))\n func5 (_Decimal32 a1, _Decimal32 a2, _Decimal32 a3, _Decimal32 a4,\n        _Decimal32 a5, _Decimal32 a6, _Decimal32 a7, _Decimal32 a8,\n        _Decimal32 a9, _Decimal32 a10, _Decimal32 a11, _Decimal32 a12,\n        _Decimal32 a13, _Decimal32 a14, _Decimal32 a15, _Decimal32 a16)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n   /* _Decimal32 is passed in the lower half of an FPR or parameter slot.  */\n-  if (a1 != ((d32parm_t *)&lparms.fprs[0])->d) FAILURE\t\t/* f1  */\n-  if (a2 != ((d32parm_t *)&lparms.fprs[1])->d) FAILURE\t\t/* f2  */\n-  if (a3 != ((d32parm_t *)&lparms.fprs[2])->d) FAILURE\t\t/* f3  */\n-  if (a4 != ((d32parm_t *)&lparms.fprs[3])->d) FAILURE\t\t/* f4  */\n-  if (a5 != ((d32parm_t *)&lparms.fprs[4])->d) FAILURE\t\t/* f5  */\n-  if (a6 != ((d32parm_t *)&lparms.fprs[5])->d) FAILURE\t\t/* f6  */\n-  if (a7 != ((d32parm_t *)&lparms.fprs[6])->d) FAILURE\t\t/* f7  */\n-  if (a8 != ((d32parm_t *)&lparms.fprs[7])->d) FAILURE\t\t/* f8  */\n-  if (a9 != ((d32parm_t *)&lparms.fprs[8])->d) FAILURE\t\t/* f9  */\n-  if (a10 != ((d32parm_t *)&lparms.fprs[9])->d) FAILURE\t\t/* f10 */\n-  if (a11 != ((d32parm_t *)&lparms.fprs[10])->d) FAILURE\t/* f11 */\n-  if (a12 != ((d32parm_t *)&lparms.fprs[11])->d) FAILURE\t/* f12 */\n-  if (a13 != ((d32parm_t *)&lparms.fprs[12])->d) FAILURE\t/* f13 */\n+  if (a1 != ((d32parm_t *)&gparms.fprs[0])->d) FAILURE\t\t/* f1  */\n+  if (a2 != ((d32parm_t *)&gparms.fprs[1])->d) FAILURE\t\t/* f2  */\n+  if (a3 != ((d32parm_t *)&gparms.fprs[2])->d) FAILURE\t\t/* f3  */\n+  if (a4 != ((d32parm_t *)&gparms.fprs[3])->d) FAILURE\t\t/* f4  */\n+  if (a5 != ((d32parm_t *)&gparms.fprs[4])->d) FAILURE\t\t/* f5  */\n+  if (a6 != ((d32parm_t *)&gparms.fprs[5])->d) FAILURE\t\t/* f6  */\n+  if (a7 != ((d32parm_t *)&gparms.fprs[6])->d) FAILURE\t\t/* f7  */\n+  if (a8 != ((d32parm_t *)&gparms.fprs[7])->d) FAILURE\t\t/* f8  */\n+  if (a9 != ((d32parm_t *)&gparms.fprs[8])->d) FAILURE\t\t/* f9  */\n+  if (a10 != ((d32parm_t *)&gparms.fprs[9])->d) FAILURE\t\t/* f10 */\n+  if (a11 != ((d32parm_t *)&gparms.fprs[10])->d) FAILURE\t/* f11 */\n+  if (a12 != ((d32parm_t *)&gparms.fprs[11])->d) FAILURE\t/* f12 */\n+  if (a13 != ((d32parm_t *)&gparms.fprs[12])->d) FAILURE\t/* f13 */\n   if (a14 != ((d32parm_t *)&sp->slot[13])->d) FAILURE\n   if (a15 != ((d32parm_t *)&sp->slot[14])->d) FAILURE\n   if (a16 != ((d32parm_t *)&sp->slot[15])->d) FAILURE\n }\n \n+extern void func6_asm (_Decimal32, _Decimal64, _Decimal128,\n+\t\t       _Decimal32, _Decimal64, _Decimal128,\n+\t\t       _Decimal32, _Decimal64, _Decimal128,\n+\t\t       _Decimal32, _Decimal64, _Decimal128);\n+\n+WRAPPER(func6);\n+\n void __attribute__ ((noinline))\n func6 (_Decimal32 a1, _Decimal64 a2, _Decimal128 a3,\n        _Decimal32 a4, _Decimal64 a5, _Decimal128 a6,\n        _Decimal32 a7, _Decimal64 a8, _Decimal128 a9,\n        _Decimal32 a10, _Decimal64 a11, _Decimal128 a12)\n {\n-  reg_parms_t lparms;\n   stack_frame_t *sp;\n \n-  save_parms (lparms);\n   sp = __builtin_frame_address (0);\n   sp = sp->backchain;\n \n-  if (a1 != ((d32parm_t *)&lparms.fprs[0])->d) FAILURE\t\t/* f1        */\n-  if (a2 != *(_Decimal64 *)&lparms.fprs[1]) FAILURE\t\t/* f2        */\n-  if (a3 != *(_Decimal128 *)&lparms.fprs[3]) FAILURE\t\t/* f4 & f5   */\n-  if (a4 != ((d32parm_t *)&lparms.fprs[5])->d) FAILURE\t\t/* f6        */\n-  if (a5 != *(_Decimal64 *)&lparms.fprs[6]) FAILURE\t\t/* f7        */\n-  if (a6 != *(_Decimal128 *)&lparms.fprs[7]) FAILURE\t\t/* f8 & f9   */\n-  if (a7 != ((d32parm_t *)&lparms.fprs[9])->d) FAILURE\t\t/* f10       */\n-  if (a8 != *(_Decimal64 *)&lparms.fprs[10]) FAILURE\t\t/* f11       */\n-  if (a9 != *(_Decimal128 *)&lparms.fprs[11]) FAILURE\t\t/* f12 & f13 */\n+  if (a1 != ((d32parm_t *)&gparms.fprs[0])->d) FAILURE\t\t/* f1        */\n+  if (a2 != *(_Decimal64 *)&gparms.fprs[1]) FAILURE\t\t/* f2        */\n+  if (a3 != *(_Decimal128 *)&gparms.fprs[3]) FAILURE\t\t/* f4 & f5   */\n+  if (a4 != ((d32parm_t *)&gparms.fprs[5])->d) FAILURE\t\t/* f6        */\n+  if (a5 != *(_Decimal64 *)&gparms.fprs[6]) FAILURE\t\t/* f7        */\n+  if (a6 != *(_Decimal128 *)&gparms.fprs[7]) FAILURE\t\t/* f8 & f9   */\n+  if (a7 != ((d32parm_t *)&gparms.fprs[9])->d) FAILURE\t\t/* f10       */\n+  if (a8 != *(_Decimal64 *)&gparms.fprs[10]) FAILURE\t\t/* f11       */\n+  if (a9 != *(_Decimal128 *)&gparms.fprs[11]) FAILURE\t\t/* f12 & f13 */\n   if (a10 != ((d32parm_t *)&sp->slot[12])->d) FAILURE\n   if (a11 != *(_Decimal64 *)&sp->slot[13]) FAILURE\n }\n \n int\n main (void)\n {\n-  func0 (1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, 13.5,\n-\t 14.5, 15.2dd, 16.2dl, 17.2dd);\n-  func1 (101.5, 102.5, 103.5, 104.5, 105.5, 106.5, 107.5, 108.5, 109.5,\n-\t 110.5, 111.5, 112.5, 113.5, 114.2dd);\n-  func2 (201.5, 202.5, 203.5, 204.5, 205.5, 206.5, 207.5, 208.5, 209.5,\n-\t 210.5, 211.5, 212.5, 213.2dd);\n-  func3 (301.2dd, 302.2dl, 303.2dd, 304.2dl, 305.2dd, 306.2dl, 307.2dd,\n-\t 308.2dl, 309.2dd, 310.2dl);\n-  func4 (401.2dl, 402.2dd, 403.2dl, 404.2dd, 405.2dl, 406.2dd, 407.2dl,\n-\t 408.2dd);\n+  func0_asm (1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, 13.5,\n+\t     14.5, 15.2dd, 16.2dl, 17.2dd);\n+  func1_asm (101.5, 102.5, 103.5, 104.5, 105.5, 106.5, 107.5, 108.5, 109.5,\n+\t     110.5, 111.5, 112.5, 113.5, 114.2dd);\n+  func2_asm (201.5, 202.5, 203.5, 204.5, 205.5, 206.5, 207.5, 208.5, 209.5,\n+\t     210.5, 211.5, 212.5, 213.2dd);\n+  func3_asm (301.2dd, 302.2dl, 303.2dd, 304.2dl, 305.2dd, 306.2dl, 307.2dd,\n+\t     308.2dl, 309.2dd, 310.2dl);\n+  func4_asm (401.2dl, 402.2dd, 403.2dl, 404.2dd, 405.2dl, 406.2dd, 407.2dl,\n+\t     408.2dd);\n #if 0\n   /* _Decimal32 doesn't yet follow the ABI; enable this when it does.  */\n-  func5 (501.2df, 502.2df, 503.2df, 504.2df, 505.2df, 506.2df, 507.2df,\n-\t 508.2df, 509.2df, 510.2df, 511.2df, 512.2df, 513.2df, 514.2df,\n-\t 515.2df, 516.2df);\n-  func6 (601.2df, 602.2dd, 603.2dl, 604.2df, 605.2dd, 606.2dl,\n-\t 607.2df, 608.2dd, 609.2dl, 610.2df, 611.2dd, 612.2dl);\n+  func5_asm (501.2df, 502.2df, 503.2df, 504.2df, 505.2df, 506.2df, 507.2df,\n+\t     508.2df, 509.2df, 510.2df, 511.2df, 512.2df, 513.2df, 514.2df,\n+\t     515.2df, 516.2df);\n+  func6_asm (601.2df, 602.2dd, 603.2dl, 604.2df, 605.2dd, 606.2dl,\n+\t     607.2df, 608.2dd, 609.2dl, 610.2df, 611.2dd, 612.2dl);\n #endif\n \n   if (failcnt != 0)"}, {"sha": "836b3851cad843cda2ce4753e84663f5d05b67ec", "filename": "gcc/testsuite/gcc.target/powerpc/vsx-builtin-8.c", "status": "added", "additions": 97, "deletions": 0, "changes": 97, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-8.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c94854734b65d62a1194d22e36e88d6aa3a2a287/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-8.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fpowerpc%2Fvsx-builtin-8.c?ref=c94854734b65d62a1194d22e36e88d6aa3a2a287", "patch": "@@ -0,0 +1,97 @@\n+/* { dg-do compile { target { powerpc*-*-* } } } */\n+/* { dg-skip-if \"\" { powerpc*-*-darwin* } { \"*\" } { \"\" } } */\n+/* { dg-require-effective-target powerpc_vsx_ok } */\n+/* { dg-options \"-O3 -mcpu=power7\" } */\n+\n+/* Test the various load/store varients.  */\n+\n+#include <altivec.h>\n+\n+#define TEST_COPY(NAME, TYPE)\t\t\t\t\t\t\\\n+void NAME ## _copy_native (vector TYPE *a, vector TYPE *b)\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  *a = *b;\t\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+void NAME ## _copy_vec (vector TYPE *a, vector TYPE *b)\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  vector TYPE x = vec_ld (0, b);\t\t\t\t\t\\\n+  vec_st (x, 0, a);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+\n+#define TEST_COPYL(NAME, TYPE)\t\t\t\t\t\t\\\n+void NAME ## _lvxl (vector TYPE *a, vector TYPE *b)\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  vector TYPE x = vec_ldl (0, b);\t\t\t\t\t\\\n+  vec_stl (x, 0, a);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+\n+#define TEST_VSX_COPY(NAME, TYPE)\t\t\t\t\t\\\n+void NAME ## _copy_vsx (vector TYPE *a, vector TYPE *b)\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  vector TYPE x = vec_vsx_ld (0, b);\t\t\t\t\t\\\n+  vec_vsx_st (x, 0, a);\t\t\t\t\t\t\t\\\n+}\t\t\t\t\t\t\t\t\t\\\n+\n+#define TEST_ALIGN(NAME, TYPE)\t\t\t\t\t\t\\\n+void NAME ## _align (vector unsigned char *a, TYPE *b)\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  vector unsigned char x = vec_lvsl (0, b);\t\t\t\t\\\n+  vector unsigned char y = vec_lvsr (0, b);\t\t\t\t\\\n+  vec_st (x, 0, a);\t\t\t\t\t\t\t\\\n+  vec_st (y, 8, a);\t\t\t\t\t\t\t\\\n+}\n+\n+#ifndef NO_COPY\n+TEST_COPY(uchar,  unsigned char)\n+TEST_COPY(schar,  signed   char)\n+TEST_COPY(bchar,  bool     char)\n+TEST_COPY(ushort, unsigned short)\n+TEST_COPY(sshort, signed   short)\n+TEST_COPY(bshort, bool     short)\n+TEST_COPY(uint,   unsigned int)\n+TEST_COPY(sint,   signed   int)\n+TEST_COPY(bint,   bool     int)\n+TEST_COPY(float,  float)\n+TEST_COPY(double, double)\n+#endif\t/* NO_COPY */\n+\n+#ifndef NO_COPYL\n+TEST_COPYL(uchar,  unsigned char)\n+TEST_COPYL(schar,  signed   char)\n+TEST_COPYL(bchar,  bool     char)\n+TEST_COPYL(ushort, unsigned short)\n+TEST_COPYL(sshort, signed   short)\n+TEST_COPYL(bshort, bool     short)\n+TEST_COPYL(uint,   unsigned int)\n+TEST_COPYL(sint,   signed   int)\n+TEST_COPYL(bint,   bool     int)\n+TEST_COPYL(float,  float)\n+TEST_COPYL(double, double)\n+#endif\t/* NO_COPYL */\n+\n+#ifndef NO_ALIGN\n+TEST_ALIGN(uchar,  unsigned char)\n+TEST_ALIGN(schar,  signed   char)\n+TEST_ALIGN(ushort, unsigned short)\n+TEST_ALIGN(sshort, signed   short)\n+TEST_ALIGN(uint,   unsigned int)\n+TEST_ALIGN(sint,   signed   int)\n+TEST_ALIGN(float,  float)\n+TEST_ALIGN(double, double)\n+#endif\t/* NO_ALIGN */\n+\n+\n+#ifndef NO_VSX_COPY\n+TEST_VSX_COPY(uchar,  unsigned char)\n+TEST_VSX_COPY(schar,  signed   char)\n+TEST_VSX_COPY(bchar,  bool     char)\n+TEST_VSX_COPY(ushort, unsigned short)\n+TEST_VSX_COPY(sshort, signed   short)\n+TEST_VSX_COPY(bshort, bool     short)\n+TEST_VSX_COPY(uint,   unsigned int)\n+TEST_VSX_COPY(sint,   signed   int)\n+TEST_VSX_COPY(bint,   bool     int)\n+TEST_VSX_COPY(float,  float)\n+TEST_VSX_COPY(double, double)\n+#endif\t/* NO_VSX_COPY */"}]}