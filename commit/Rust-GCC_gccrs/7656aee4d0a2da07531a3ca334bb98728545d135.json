{"sha": "7656aee4d0a2da07531a3ca334bb98728545d135", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzY1NmFlZTRkMGEyZGEwNzUzMWEzY2EzMzRiYjk4NzI4NTQ1ZDEzNQ==", "commit": {"author": {"name": "Uros Bizjak", "email": "uros@gcc.gnu.org", "date": "2007-01-23T07:14:26Z"}, "committer": {"name": "Uros Bizjak", "email": "uros@gcc.gnu.org", "date": "2007-01-23T07:14:26Z"}, "message": "i386.md: Use REG_P...\n\n\t* config/i386/i386.md: Use REG_P, MEM_P, CONST_INT_P, LABEL_P,\n\tJUMP_P and CALL_P predicates where applicable.\n\t* config/i386/i386.c: Ditto.\n\t* config/i386/i386.md: Ditto.\n\t* config/i386/mmx.md: Ditto.\n\t* config/i386/predicates.md: Ditto.\n\nFrom-SVN: r121079", "tree": {"sha": "3c45285417cab5be4b197aa1e2a6272e6d14348f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3c45285417cab5be4b197aa1e2a6272e6d14348f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/7656aee4d0a2da07531a3ca334bb98728545d135", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7656aee4d0a2da07531a3ca334bb98728545d135", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7656aee4d0a2da07531a3ca334bb98728545d135", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7656aee4d0a2da07531a3ca334bb98728545d135/comments", "author": null, "committer": null, "parents": [{"sha": "c56b658bded715a47a8f53efef923c40328f797b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c56b658bded715a47a8f53efef923c40328f797b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c56b658bded715a47a8f53efef923c40328f797b"}], "stats": {"total": 601, "additions": 306, "deletions": 295}, "files": [{"sha": "a9d2cfbff4135ba766cf301af034f138f3c10e93", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 2, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=7656aee4d0a2da07531a3ca334bb98728545d135", "patch": "@@ -1,3 +1,12 @@\n+2007-01-23  Uros Bizjak  <ubizjak@gmail.com>\n+\n+\t* config/i386/i386.md: Use REG_P, MEM_P, CONST_INT_P, LABEL_P,\n+\tJUMP_P and CALL_P predicates where applicable.\n+\t* config/i386/i386.c: Ditto.\n+\t* config/i386/i386.md: Ditto.\n+\t* config/i386/mmx.md: Ditto.\n+\t* config/i386/predicates.md: Ditto.\n+\n 2007-01-22  Andreas Schwab  <schwab@suse.de>\n \n \t* config/m68k/m68k.h: Fix comment.\n@@ -42,8 +51,8 @@\n 2007-01-21  Jan Hubicka  <jh@suse.cz>\n \n \t* ipa-inline.c (inlining_mode): Comment, move up.\n-\t(cgraph_decide_inlining_incrementally): Do not perform inlining itself;\n-\tfix handling of flattening of self recursive functions.\n+\t(cgraph_decide_inlining_incrementally): Do not perform inlining\n+\titself; fix handling of flattening of self recursive functions.\n \t(cgraph_find_cycles): Remove.\n \t(cgraph_flatten_node): Remove.\n \t(cgraph_decide_inlining): Use incremental inliner to handle flattening."}, {"sha": "9191376dd43ac102c081d8f626dc3cd0f35235d3", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 138, "deletions": 138, "changes": 276, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=7656aee4d0a2da07531a3ca334bb98728545d135", "patch": "@@ -4708,7 +4708,7 @@ ix86_check_movabs (rtx insn, int opnum)\n   mem = XEXP (set, opnum);\n   while (GET_CODE (mem) == SUBREG)\n     mem = SUBREG_REG (mem);\n-  gcc_assert (GET_CODE (mem) == MEM);\n+  gcc_assert (MEM_P (mem));\n   return (volatile_ok || !MEM_VOLATILE_P (mem));\n }\n \f\n@@ -5959,7 +5959,7 @@ ix86_decompose_address (rtx addr, struct ix86_address *out)\n   int retval = 1;\n   enum ix86_address_seg seg = SEG_DEFAULT;\n \n-  if (GET_CODE (addr) == REG || GET_CODE (addr) == SUBREG)\n+  if (REG_P (addr) || GET_CODE (addr) == SUBREG)\n     base = addr;\n   else if (GET_CODE (addr) == PLUS)\n     {\n@@ -6036,7 +6036,7 @@ ix86_decompose_address (rtx addr, struct ix86_address *out)\n       /* We're called for lea too, which implements ashift on occasion.  */\n       index = XEXP (addr, 0);\n       tmp = XEXP (addr, 1);\n-      if (GET_CODE (tmp) != CONST_INT)\n+      if (!CONST_INT_P (tmp))\n \treturn 0;\n       scale = INTVAL (tmp);\n       if ((unsigned HOST_WIDE_INT) scale > 3)\n@@ -6050,7 +6050,7 @@ ix86_decompose_address (rtx addr, struct ix86_address *out)\n   /* Extract the integral value of scale.  */\n   if (scale_rtx)\n     {\n-      if (GET_CODE (scale_rtx) != CONST_INT)\n+      if (!CONST_INT_P (scale_rtx))\n \treturn 0;\n       scale = INTVAL (scale_rtx);\n     }\n@@ -6179,7 +6179,7 @@ ix86_find_base_term (rtx x)\n \treturn x;\n       term = XEXP (x, 0);\n       if (GET_CODE (term) == PLUS\n-\t  && (GET_CODE (XEXP (term, 1)) == CONST_INT\n+\t  && (CONST_INT_P (XEXP (term, 1))\n \t      || GET_CODE (XEXP (term, 1)) == CONST_DOUBLE))\n \tterm = XEXP (term, 0);\n       if (GET_CODE (term) != UNSPEC\n@@ -6239,7 +6239,7 @@ legitimate_constant_p (rtx x)\n \n       if (GET_CODE (x) == PLUS)\n \t{\n-\t  if (GET_CODE (XEXP (x, 1)) != CONST_INT)\n+\t  if (!CONST_INT_P (XEXP (x, 1)))\n \t    return false;\n \t  x = XEXP (x, 0);\n \t}\n@@ -6342,7 +6342,7 @@ legitimate_pic_operand_p (rtx x)\n     case CONST:\n       inner = XEXP (x, 0);\n       if (GET_CODE (inner) == PLUS\n-\t  && GET_CODE (XEXP (inner, 1)) == CONST_INT)\n+\t  && CONST_INT_P (XEXP (inner, 1)))\n \tinner = XEXP (inner, 0);\n \n       /* Only some unspecs are valid as \"constants\".  */\n@@ -6393,7 +6393,7 @@ legitimate_pic_address_disp_p (rtx disp)\n \t    break;\n \t  op0 = XEXP (XEXP (disp, 0), 0);\n \t  op1 = XEXP (XEXP (disp, 0), 1);\n-\t  if (GET_CODE (op1) != CONST_INT\n+\t  if (!CONST_INT_P (op1)\n \t      || INTVAL (op1) >= 16*1024*1024\n \t      || INTVAL (op1) < -16*1024*1024)\n             break;\n@@ -6437,7 +6437,7 @@ legitimate_pic_address_disp_p (rtx disp)\n   saw_plus = false;\n   if (GET_CODE (disp) == PLUS)\n     {\n-      if (GET_CODE (XEXP (disp, 1)) != CONST_INT)\n+      if (!CONST_INT_P (XEXP (disp, 1)))\n \treturn 0;\n       disp = XEXP (disp, 0);\n       saw_plus = true;\n@@ -6665,7 +6665,7 @@ legitimate_address_p (enum machine_mode mode, rtx addr, int strict)\n \t      if (GET_CODE (disp) != CONST\n \t\t  || GET_CODE (XEXP (disp, 0)) != PLUS\n \t\t  || GET_CODE (XEXP (XEXP (disp, 0), 0)) != UNSPEC\n-\t\t  || GET_CODE (XEXP (XEXP (disp, 0), 1)) != CONST_INT\n+\t\t  || !CONST_INT_P (XEXP (XEXP (disp, 0), 1))\n \t\t  || (XINT (XEXP (XEXP (disp, 0), 0), 1) != UNSPEC_DTPOFF\n \t\t      && XINT (XEXP (XEXP (disp, 0), 0), 1) != UNSPEC_NTPOFF))\n \t\t{\n@@ -6702,7 +6702,7 @@ legitimate_address_p (enum machine_mode mode, rtx addr, int strict)\n \t     correct fix for crash to disable this test.  */\n \t}\n       else if (GET_CODE (disp) != LABEL_REF\n-\t       && GET_CODE (disp) != CONST_INT\n+\t       && !CONST_INT_P (disp)\n \t       && (GET_CODE (disp) != CONST\n \t\t   || !legitimate_constant_p (disp))\n \t       && (GET_CODE (disp) != SYMBOL_REF\n@@ -6878,7 +6878,7 @@ legitimize_pic_address (rtx orig, rtx reg)\n     }\n   else\n     {\n-      if (GET_CODE (addr) == CONST_INT\n+      if (CONST_INT_P (addr)\n \t  && !x86_64_immediate_operand (addr, VOIDmode))\n \t{\n \t  if (reg)\n@@ -6909,7 +6909,7 @@ legitimize_pic_address (rtx orig, rtx reg)\n \t  /* Check first to see if this is a constant offset from a @GOTOFF\n \t     symbol reference.  */\n \t  if (local_symbolic_operand (op0, Pmode)\n-\t      && GET_CODE (op1) == CONST_INT)\n+\t      && CONST_INT_P (op1))\n \t    {\n \t      if (!TARGET_64BIT)\n \t\t{\n@@ -6944,7 +6944,7 @@ legitimize_pic_address (rtx orig, rtx reg)\n \t      new  = legitimize_pic_address (XEXP (addr, 1),\n \t\t\t\t\t     base == reg ? NULL_RTX : reg);\n \n-\t      if (GET_CODE (new) == CONST_INT)\n+\t      if (CONST_INT_P (new))\n \t\tnew = plus_constant (base, INTVAL (new));\n \t      else\n \t\t{\n@@ -7186,7 +7186,7 @@ legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED, enum machine_mode mode)\n \n   /* Canonicalize shifts by 0, 1, 2, 3 into multiply */\n   if (GET_CODE (x) == ASHIFT\n-      && GET_CODE (XEXP (x, 1)) == CONST_INT\n+      && CONST_INT_P (XEXP (x, 1))\n       && (unsigned HOST_WIDE_INT) INTVAL (XEXP (x, 1)) < 4)\n     {\n       changed = 1;\n@@ -7200,7 +7200,7 @@ legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED, enum machine_mode mode)\n       /* Canonicalize shifts by 0, 1, 2, 3 into multiply.  */\n \n       if (GET_CODE (XEXP (x, 0)) == ASHIFT\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT\n+\t  && CONST_INT_P (XEXP (XEXP (x, 0), 1))\n \t  && (unsigned HOST_WIDE_INT) INTVAL (XEXP (XEXP (x, 0), 1)) < 4)\n \t{\n \t  changed = 1;\n@@ -7211,7 +7211,7 @@ legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED, enum machine_mode mode)\n \t}\n \n       if (GET_CODE (XEXP (x, 1)) == ASHIFT\n-\t  && GET_CODE (XEXP (XEXP (x, 1), 1)) == CONST_INT\n+\t  && CONST_INT_P (XEXP (XEXP (x, 1), 1))\n \t  && (unsigned HOST_WIDE_INT) INTVAL (XEXP (XEXP (x, 1), 1)) < 4)\n \t{\n \t  changed = 1;\n@@ -7254,12 +7254,12 @@ legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED, enum machine_mode mode)\n \t  rtx constant;\n \t  rtx other = NULL_RTX;\n \n-\t  if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n+\t  if (CONST_INT_P (XEXP (x, 1)))\n \t    {\n \t      constant = XEXP (x, 1);\n \t      other = XEXP (XEXP (XEXP (x, 0), 1), 1);\n \t    }\n-\t  else if (GET_CODE (XEXP (XEXP (XEXP (x, 0), 1), 1)) == CONST_INT)\n+\t  else if (CONST_INT_P (XEXP (XEXP (XEXP (x, 0), 1), 1)))\n \t    {\n \t      constant = XEXP (XEXP (XEXP (x, 0), 1), 1);\n \t      other = XEXP (x, 1);\n@@ -7293,8 +7293,8 @@ legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED, enum machine_mode mode)\n \t}\n \n       if (changed\n-\t  && GET_CODE (XEXP (x, 1)) == REG\n-\t  && GET_CODE (XEXP (x, 0)) == REG)\n+\t  && REG_P (XEXP (x, 1))\n+\t  && REG_P (XEXP (x, 0)))\n \treturn x;\n \n       if (flag_pic && SYMBOLIC_CONST (XEXP (x, 1)))\n@@ -7306,7 +7306,7 @@ legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED, enum machine_mode mode)\n       if (changed && legitimate_address_p (mode, x, FALSE))\n \treturn x;\n \n-      if (GET_CODE (XEXP (x, 0)) == REG)\n+      if (REG_P (XEXP (x, 0)))\n \t{\n \t  rtx temp = gen_reg_rtx (Pmode);\n \t  rtx val  = force_operand (XEXP (x, 1), temp);\n@@ -7317,7 +7317,7 @@ legitimize_address (rtx x, rtx oldx ATTRIBUTE_UNUSED, enum machine_mode mode)\n \t  return x;\n \t}\n \n-      else if (GET_CODE (XEXP (x, 1)) == REG)\n+      else if (REG_P (XEXP (x, 1)))\n \t{\n \t  rtx temp = gen_reg_rtx (Pmode);\n \t  rtx val  = force_operand (XEXP (x, 0), temp);\n@@ -7392,15 +7392,15 @@ output_pic_addr_const (FILE *file, rtx x, int code)\n \n     case PLUS:\n       /* Some assemblers need integer constants to appear first.  */\n-      if (GET_CODE (XEXP (x, 0)) == CONST_INT)\n+      if (CONST_INT_P (XEXP (x, 0)))\n \t{\n \t  output_pic_addr_const (file, XEXP (x, 0), code);\n \t  putc ('+', file);\n \t  output_pic_addr_const (file, XEXP (x, 1), code);\n \t}\n       else\n \t{\n-\t  gcc_assert (GET_CODE (XEXP (x, 1)) == CONST_INT);\n+\t  gcc_assert (CONST_INT_P (XEXP (x, 1)));\n \t  output_pic_addr_const (file, XEXP (x, 1), code);\n \t  putc ('+', file);\n \t  output_pic_addr_const (file, XEXP (x, 0), code);\n@@ -7509,15 +7509,15 @@ ix86_delegitimize_address (rtx orig_x)\n   /* This is the result, or NULL.  */\n   rtx result = NULL_RTX;\n \n-  if (GET_CODE (x) == MEM)\n+  if (MEM_P (x))\n     x = XEXP (x, 0);\n \n   if (TARGET_64BIT)\n     {\n       if (GET_CODE (x) != CONST\n \t  || GET_CODE (XEXP (x, 0)) != UNSPEC\n \t  || XINT (XEXP (x, 0), 1) != UNSPEC_GOTPCREL\n-\t  || GET_CODE (orig_x) != MEM)\n+\t  || !MEM_P (orig_x))\n \treturn orig_x;\n       return XVECEXP (XEXP (x, 0), 0, 0);\n     }\n@@ -7526,23 +7526,23 @@ ix86_delegitimize_address (rtx orig_x)\n       || GET_CODE (XEXP (x, 1)) != CONST)\n     return orig_x;\n \n-  if (GET_CODE (XEXP (x, 0)) == REG\n+  if (REG_P (XEXP (x, 0))\n       && REGNO (XEXP (x, 0)) == PIC_OFFSET_TABLE_REGNUM)\n     /* %ebx + GOT/GOTOFF */\n     ;\n   else if (GET_CODE (XEXP (x, 0)) == PLUS)\n     {\n       /* %ebx + %reg * scale + GOT/GOTOFF */\n       reg_addend = XEXP (x, 0);\n-      if (GET_CODE (XEXP (reg_addend, 0)) == REG\n+      if (REG_P (XEXP (reg_addend, 0))\n \t  && REGNO (XEXP (reg_addend, 0)) == PIC_OFFSET_TABLE_REGNUM)\n \treg_addend = XEXP (reg_addend, 1);\n-      else if (GET_CODE (XEXP (reg_addend, 1)) == REG\n+      else if (REG_P (XEXP (reg_addend, 1))\n \t       && REGNO (XEXP (reg_addend, 1)) == PIC_OFFSET_TABLE_REGNUM)\n \treg_addend = XEXP (reg_addend, 0);\n       else\n \treturn orig_x;\n-      if (GET_CODE (reg_addend) != REG\n+      if (!REG_P (reg_addend)\n \t  && GET_CODE (reg_addend) != MULT\n \t  && GET_CODE (reg_addend) != ASHIFT)\n \treturn orig_x;\n@@ -7552,19 +7552,19 @@ ix86_delegitimize_address (rtx orig_x)\n \n   x = XEXP (XEXP (x, 1), 0);\n   if (GET_CODE (x) == PLUS\n-      && GET_CODE (XEXP (x, 1)) == CONST_INT)\n+      && CONST_INT_P (XEXP (x, 1)))\n     {\n       const_addend = XEXP (x, 1);\n       x = XEXP (x, 0);\n     }\n \n   if (GET_CODE (x) == UNSPEC\n-      && ((XINT (x, 1) == UNSPEC_GOT && GET_CODE (orig_x) == MEM)\n-\t  || (XINT (x, 1) == UNSPEC_GOTOFF && GET_CODE (orig_x) != MEM)))\n+      && ((XINT (x, 1) == UNSPEC_GOT && MEM_P (orig_x))\n+\t  || (XINT (x, 1) == UNSPEC_GOTOFF && !MEM_P (orig_x))))\n     result = XVECEXP (x, 0, 0);\n \n   if (TARGET_MACHO && darwin_local_data_pic (x)\n-      && GET_CODE (orig_x) != MEM)\n+      && !MEM_P (orig_x))\n     result = XEXP (x, 0);\n \n   if (! result)\n@@ -7862,7 +7862,7 @@ print_operand (FILE *file, rtx x, int code)\n \t    case ASM_INTEL:\n \t      /* Intel syntax. For absolute addresses, registers should not\n \t\t be surrounded by braces.  */\n-\t      if (GET_CODE (x) != REG)\n+\t      if (!REG_P (x))\n \t\t{\n \t\t  putc ('[', file);\n \t\t  PRINT_OPERAND (file, x, 0);\n@@ -7976,7 +7976,7 @@ print_operand (FILE *file, rtx x, int code)\n \t  break;\n \n \tcase 's':\n-\t  if (GET_CODE (x) == CONST_INT || ! SHIFT_DOUBLE_OMITS_COUNT)\n+\t  if (CONST_INT_P (x) || ! SHIFT_DOUBLE_OMITS_COUNT)\n \t    {\n \t      PRINT_OPERAND (file, x, 0);\n \t      putc (',', file);\n@@ -8114,10 +8114,10 @@ print_operand (FILE *file, rtx x, int code)\n \t}\n     }\n \n-  if (GET_CODE (x) == REG)\n+  if (REG_P (x))\n     print_reg (x, code, file);\n \n-  else if (GET_CODE (x) == MEM)\n+  else if (MEM_P (x))\n     {\n       /* No `byte ptr' prefix for call instructions.  */\n       if (ASSEMBLER_DIALECT == ASM_INTEL && code != 'X' && code != 'P')\n@@ -8150,7 +8150,7 @@ print_operand (FILE *file, rtx x, int code)\n       x = XEXP (x, 0);\n       /* Avoid (%rip) for call operands.  */\n       if (CONSTANT_ADDRESS_P (x) && code == 'P'\n-\t       && GET_CODE (x) != CONST_INT)\n+\t  && !CONST_INT_P (x))\n \toutput_addr_const (file, x);\n       else if (this_is_asm_operands && ! address_operand (x, VOIDmode))\n \toutput_operand_lossage (\"invalid constraints for operand\");\n@@ -8202,7 +8202,7 @@ print_operand (FILE *file, rtx x, int code)\n \n       if (code != 'P')\n \t{\n-\t  if (GET_CODE (x) == CONST_INT || GET_CODE (x) == CONST_DOUBLE)\n+\t  if (CONST_INT_P (x) || GET_CODE (x) == CONST_DOUBLE)\n \t    {\n \t      if (ASSEMBLER_DIALECT == ASM_ATT)\n \t\tputc ('$', file);\n@@ -8216,7 +8216,7 @@ print_operand (FILE *file, rtx x, int code)\n \t\tfputs (\"OFFSET FLAT:\", file);\n \t    }\n \t}\n-      if (GET_CODE (x) == CONST_INT)\n+      if (CONST_INT_P (x))\n \tfprintf (file, HOST_WIDE_INT_PRINT_DEC, INTVAL (x));\n       else if (flag_pic)\n \toutput_pic_addr_const (file, x, code);\n@@ -8260,7 +8260,7 @@ print_operand_address (FILE *file, rtx addr)\n     {\n       /* Displacement only requires special attention.  */\n \n-      if (GET_CODE (disp) == CONST_INT)\n+      if (CONST_INT_P (disp))\n \t{\n \t  if (ASSEMBLER_DIALECT == ASM_INTEL && parts.seg == SEG_DEFAULT)\n \t    {\n@@ -8280,7 +8280,7 @@ print_operand_address (FILE *file, rtx addr)\n \t{\n \t  if (GET_CODE (disp) == CONST\n \t      && GET_CODE (XEXP (disp, 0)) == PLUS\n-\t      && GET_CODE (XEXP (XEXP (disp, 0), 1)) == CONST_INT)\n+\t      && CONST_INT_P (XEXP (XEXP (disp, 0), 1)))\n \t    disp = XEXP (XEXP (disp, 0), 0);\n \t  if (GET_CODE (disp) == LABEL_REF\n \t      || (GET_CODE (disp) == SYMBOL_REF\n@@ -8323,7 +8323,7 @@ print_operand_address (FILE *file, rtx addr)\n \t      /* Pull out the offset of a symbol; print any symbol itself.  */\n \t      if (GET_CODE (disp) == CONST\n \t\t  && GET_CODE (XEXP (disp, 0)) == PLUS\n-\t\t  && GET_CODE (XEXP (XEXP (disp, 0), 1)) == CONST_INT)\n+\t\t  && CONST_INT_P (XEXP (XEXP (disp, 0), 1)))\n \t\t{\n \t\t  offset = XEXP (XEXP (disp, 0), 1);\n \t\t  disp = gen_rtx_CONST (VOIDmode,\n@@ -8334,7 +8334,7 @@ print_operand_address (FILE *file, rtx addr)\n \t\toutput_pic_addr_const (file, disp, 0);\n \t      else if (GET_CODE (disp) == LABEL_REF)\n \t\toutput_asm_label (disp);\n-\t      else if (GET_CODE (disp) == CONST_INT)\n+\t      else if (CONST_INT_P (disp))\n \t\toffset = disp;\n \t      else\n \t\toutput_addr_const (file, disp);\n@@ -8433,7 +8433,7 @@ split_di (rtx operands[], int num, rtx lo_half[], rtx hi_half[])\n \n       /* simplify_subreg refuse to split volatile memory addresses,\n          but we still have to handle it.  */\n-      if (GET_CODE (op) == MEM)\n+      if (MEM_P (op))\n \t{\n \t  lo_half[num] = adjust_address (op, SImode, 0);\n \t  hi_half[num] = adjust_address (op, SImode, 4);\n@@ -8464,7 +8464,7 @@ split_ti (rtx operands[], int num, rtx lo_half[], rtx hi_half[])\n \n       /* simplify_subreg refuse to split volatile memory addresses, but we\n          still have to handle it.  */\n-      if (GET_CODE (op) == MEM)\n+      if (MEM_P (op))\n \t{\n \t  lo_half[num] = adjust_address (op, DImode, 0);\n \t  hi_half[num] = adjust_address (op, DImode, 8);\n@@ -8508,10 +8508,10 @@ output_387_binary_op (rtx insn, rtx *operands)\n   if (STACK_REG_P (operands[0])\n       && ((REG_P (operands[1])\n \t   && REGNO (operands[0]) == REGNO (operands[1])\n-\t   && (STACK_REG_P (operands[2]) || GET_CODE (operands[2]) == MEM))\n+\t   && (STACK_REG_P (operands[2]) || MEM_P (operands[2])))\n \t  || (REG_P (operands[2])\n \t      && REGNO (operands[0]) == REGNO (operands[2])\n-\t      && (STACK_REG_P (operands[1]) || GET_CODE (operands[1]) == MEM)))\n+\t      && (STACK_REG_P (operands[1]) || MEM_P (operands[1]))))\n       && (STACK_TOP_P (operands[1]) || STACK_TOP_P (operands[2])))\n     ; /* ok */\n   else\n@@ -8584,7 +8584,7 @@ output_387_binary_op (rtx insn, rtx *operands)\n \n       /* know operands[0] == operands[1].  */\n \n-      if (GET_CODE (operands[2]) == MEM)\n+      if (MEM_P (operands[2]))\n \t{\n \t  p = \"%z2\\t%2\";\n \t  break;\n@@ -8614,13 +8614,13 @@ output_387_binary_op (rtx insn, rtx *operands)\n \n     case MINUS:\n     case DIV:\n-      if (GET_CODE (operands[1]) == MEM)\n+      if (MEM_P (operands[1]))\n \t{\n \t  p = \"r%z1\\t%1\";\n \t  break;\n \t}\n \n-      if (GET_CODE (operands[2]) == MEM)\n+      if (MEM_P (operands[2]))\n \t{\n \t  p = \"%z2\\t%2\";\n \t  break;\n@@ -8859,7 +8859,7 @@ output_fix_trunc (rtx insn, rtx *operands, int fisttp)\n     output_asm_insn (\"fld\\t%y1\", operands);\n \n   gcc_assert (STACK_TOP_P (operands[1]));\n-  gcc_assert (GET_CODE (operands[0]) == MEM);\n+  gcc_assert (MEM_P (operands[0]));\n \n   if (fisttp)\n       output_asm_insn (\"fisttp%z0\\t%0\", operands);\n@@ -9147,7 +9147,7 @@ ix86_expand_move (enum machine_mode mode, rtx operands[])\n \t  if (MACHOPIC_PURE)\n \t    {\n \t      rtx temp = ((reload_in_progress\n-\t\t\t   || ((op0 && GET_CODE (op0) == REG)\n+\t\t\t   || ((op0 && REG_P (op0))\n \t\t\t       && mode == Pmode))\n \t\t\t  ? op0 : gen_reg_rtx (Pmode));\n \t      op1 = machopic_indirect_data_reference (op1, temp);\n@@ -9162,18 +9162,18 @@ ix86_expand_move (enum machine_mode mode, rtx operands[])\n \t}\n       else\n \t{\n-\t  if (GET_CODE (op0) == MEM)\n+\t  if (MEM_P (op0))\n \t    op1 = force_reg (Pmode, op1);\n \t  else\n \t    op1 = legitimize_address (op1, op1, Pmode);\n \t}\n     }\n   else\n     {\n-      if (GET_CODE (op0) == MEM\n+      if (MEM_P (op0)\n \t  && (PUSH_ROUNDING (GET_MODE_SIZE (mode)) != GET_MODE_SIZE (mode)\n \t      || !push_operand (op0, mode))\n-\t  && GET_CODE (op1) == MEM)\n+\t  && MEM_P (op1))\n \top1 = force_reg (mode, op1);\n \n       if (push_operand (op0, mode)\n@@ -9408,7 +9408,7 @@ ix86_fixup_binary_operands (enum rtx_code code, enum machine_mode mode,\n   /* If the destination is memory, and we do not have matching source\n      operands, do things in registers.  */\n   matching_memory = 0;\n-  if (GET_CODE (dst) == MEM)\n+  if (MEM_P (dst))\n     {\n       if (rtx_equal_p (dst, src1))\n \tmatching_memory = 1;\n@@ -9420,7 +9420,7 @@ ix86_fixup_binary_operands (enum rtx_code code, enum machine_mode mode,\n     }\n \n   /* Both source operands cannot be in memory.  */\n-  if (GET_CODE (src1) == MEM && GET_CODE (src2) == MEM)\n+  if (MEM_P (src1) && MEM_P (src2))\n     {\n       if (matching_memory != 2)\n \tsrc2 = force_reg (mode, src2);\n@@ -9431,7 +9431,7 @@ ix86_fixup_binary_operands (enum rtx_code code, enum machine_mode mode,\n   /* If the operation is not commutable, source 1 cannot be a constant\n      or non-matching memory.  */\n   if ((CONSTANT_P (src1)\n-       || (!matching_memory && GET_CODE (src1) == MEM))\n+       || (!matching_memory && MEM_P (src1)))\n       && GET_RTX_CLASS (code) != RTX_COMM_ARITH)\n     src1 = force_reg (mode, src1);\n \n@@ -9495,20 +9495,20 @@ ix86_binary_operator_ok (enum rtx_code code,\n \t\t\t rtx operands[3])\n {\n   /* Both source operands cannot be in memory.  */\n-  if (GET_CODE (operands[1]) == MEM && GET_CODE (operands[2]) == MEM)\n+  if (MEM_P (operands[1]) && MEM_P (operands[2]))\n     return 0;\n   /* If the operation is not commutable, source 1 cannot be a constant.  */\n   if (CONSTANT_P (operands[1]) && GET_RTX_CLASS (code) != RTX_COMM_ARITH)\n     return 0;\n   /* If the destination is memory, we must have a matching source operand.  */\n-  if (GET_CODE (operands[0]) == MEM\n+  if (MEM_P (operands[0])\n       && ! (rtx_equal_p (operands[0], operands[1])\n \t    || (GET_RTX_CLASS (code) == RTX_COMM_ARITH\n \t\t&& rtx_equal_p (operands[0], operands[2]))))\n     return 0;\n   /* If the operation is not commutable and the source 1 is memory, we must\n      have a matching destination.  */\n-  if (GET_CODE (operands[1]) == MEM\n+  if (MEM_P (operands[1])\n       && GET_RTX_CLASS (code) != RTX_COMM_ARITH\n       && ! rtx_equal_p (operands[0], operands[1]))\n     return 0;\n@@ -9574,8 +9574,8 @@ ix86_unary_operator_ok (enum rtx_code code ATTRIBUTE_UNUSED,\n \t\t\trtx operands[2] ATTRIBUTE_UNUSED)\n {\n   /* If one of operands is memory, source and destination must match.  */\n-  if ((GET_CODE (operands[0]) == MEM\n-       || GET_CODE (operands[1]) == MEM)\n+  if ((MEM_P (operands[0])\n+       || MEM_P (operands[1]))\n       && ! rtx_equal_p (operands[0], operands[1]))\n     return FALSE;\n   return TRUE;\n@@ -10085,16 +10085,16 @@ ix86_prepare_fp_compare_args (enum rtx_code code, rtx *pop0, rtx *pop1)\n \t into a register.  */\n \n       if (standard_80387_constant_p (op0) == 0\n-\t  || (GET_CODE (op0) == MEM\n+\t  || (MEM_P (op0)\n \t      && ! (standard_80387_constant_p (op1) == 0\n-\t\t    || GET_CODE (op1) == MEM)))\n+\t\t    || MEM_P (op1))))\n \t{\n \t  rtx tmp;\n \t  tmp = op0, op0 = op1, op1 = tmp;\n \t  code = swap_condition (code);\n \t}\n \n-      if (GET_CODE (op0) != REG)\n+      if (!REG_P (op0))\n \top0 = force_reg (op_mode, op0);\n \n       if (CONSTANT_P (op1))\n@@ -10115,12 +10115,12 @@ ix86_prepare_fp_compare_args (enum rtx_code code, rtx *pop0, rtx *pop1)\n   /* Try to rearrange the comparison to make it cheaper.  */\n   if (ix86_fp_comparison_cost (code)\n       > ix86_fp_comparison_cost (swap_condition (code))\n-      && (GET_CODE (op1) == REG || !no_new_pseudos))\n+      && (REG_P (op1) || !no_new_pseudos))\n     {\n       rtx tmp;\n       tmp = op0, op0 = op1, op1 = tmp;\n       code = swap_condition (code);\n-      if (GET_CODE (op0) != REG)\n+      if (!REG_P (op0))\n \top0 = force_reg (op_mode, op0);\n     }\n \n@@ -10674,7 +10674,7 @@ ix86_expand_branch (enum rtx_code code, rtx label)\n \t   op1 is a constant and the low word is zero, then we can just\n \t   examine the high word.  */\n \n-\tif (GET_CODE (hi[1]) == CONST_INT && lo[1] == const0_rtx)\n+\tif (CONST_INT_P (hi[1]) && lo[1] == const0_rtx)\n \t  switch (code)\n \t    {\n \t    case LT: case LTU: case GE: case GEU:\n@@ -10948,7 +10948,7 @@ ix86_expand_carry_flag_compare (enum rtx_code code, rtx op0, rtx op1, rtx *pop)\n     /* Convert a>b into b<a or a>=b-1.  */\n     case GTU:\n     case LEU:\n-      if (GET_CODE (op1) == CONST_INT)\n+      if (CONST_INT_P (op1))\n \t{\n \t  op1 = gen_int_mode (INTVAL (op1) + 1, GET_MODE (op0));\n \t  /* Bail out on overflow.  We still can swap operands but that\n@@ -11025,8 +11025,8 @@ ix86_expand_int_movcc (rtx operands[])\n \n   if ((mode != HImode || TARGET_FAST_PREFIX)\n       && (mode != (TARGET_64BIT ? TImode : DImode))\n-      && GET_CODE (operands[2]) == CONST_INT\n-      && GET_CODE (operands[3]) == CONST_INT)\n+      && CONST_INT_P (operands[2])\n+      && CONST_INT_P (operands[3]))\n     {\n       rtx out = operands[0];\n       HOST_WIDE_INT ct = INTVAL (operands[2]);\n@@ -11201,7 +11201,7 @@ ix86_expand_int_movcc (rtx operands[])\n \n       compare_code = UNKNOWN;\n       if (GET_MODE_CLASS (GET_MODE (ix86_compare_op0)) == MODE_INT\n-\t  && GET_CODE (ix86_compare_op1) == CONST_INT)\n+\t  && CONST_INT_P (ix86_compare_op1))\n \t{\n \t  if (ix86_compare_op1 == const0_rtx\n \t      && (code == LT || code == GE))\n@@ -11413,7 +11413,7 @@ ix86_expand_int_movcc (rtx operands[])\n       /* If one of the two operands is an interesting constant, load a\n \t constant with the above and mask it in with a logical operation.  */\n \n-      if (GET_CODE (operands[2]) == CONST_INT)\n+      if (CONST_INT_P (operands[2]))\n \t{\n \t  var = operands[3];\n \t  if (INTVAL (operands[2]) == 0 && operands[3] != constm1_rtx)\n@@ -11423,7 +11423,7 @@ ix86_expand_int_movcc (rtx operands[])\n \t  else\n \t    return 0; /* FAIL */\n \t}\n-      else if (GET_CODE (operands[3]) == CONST_INT)\n+      else if (CONST_INT_P (operands[3]))\n \t{\n \t  var = operands[2];\n \t  if (INTVAL (operands[3]) == 0 && operands[2] != constm1_rtx)\n@@ -12055,19 +12055,19 @@ ix86_split_to_parts (rtx operand, rtx *parts, enum machine_mode mode)\n   else\n     size = (GET_MODE_SIZE (mode) + 4) / 8;\n \n-  gcc_assert (GET_CODE (operand) != REG || !MMX_REGNO_P (REGNO (operand)));\n+  gcc_assert (!REG_P (operand) || !MMX_REGNO_P (REGNO (operand)));\n   gcc_assert (size >= 2 && size <= 3);\n \n   /* Optimize constant pool reference to immediates.  This is used by fp\n      moves, that force all constants to memory to allow combining.  */\n-  if (GET_CODE (operand) == MEM && MEM_READONLY_P (operand))\n+  if (MEM_P (operand) && MEM_READONLY_P (operand))\n     {\n       rtx tmp = maybe_get_pool_constant (operand);\n       if (tmp)\n \toperand = tmp;\n     }\n \n-  if (GET_CODE (operand) == MEM && !offsettable_memref_p (operand))\n+  if (MEM_P (operand) && !offsettable_memref_p (operand))\n     {\n       /* The only non-offsetable memories we handle are pushes.  */\n       int ok = push_operand (operand, VOIDmode);\n@@ -12216,7 +12216,7 @@ ix86_split_long_move (rtx operands[])\n       /* Optimize constant pool reference to immediates.  This is used by\n \t fp moves, that force all constants to memory to allow combining.  */\n \n-      if (GET_CODE (operands[1]) == MEM\n+      if (MEM_P (operands[1])\n \t  && GET_CODE (XEXP (operands[1], 0)) == SYMBOL_REF\n \t  && CONSTANT_POOL_ADDRESS_P (XEXP (operands[1], 0)))\n \toperands[1] = get_pool_constant (XEXP (operands[1], 0));\n@@ -12236,14 +12236,14 @@ ix86_split_long_move (rtx operands[])\n   if (push_operand (operands[0], VOIDmode))\n     push = 1;\n   else\n-    gcc_assert (GET_CODE (operands[0]) != MEM\n+    gcc_assert (!MEM_P (operands[0])\n \t\t|| offsettable_memref_p (operands[0]));\n \n   nparts = ix86_split_to_parts (operands[1], part[1], GET_MODE (operands[0]));\n   ix86_split_to_parts (operands[0], part[0], GET_MODE (operands[0]));\n \n   /* When emitting push, take care for source operands on the stack.  */\n-  if (push && GET_CODE (operands[1]) == MEM\n+  if (push && MEM_P (operands[1])\n       && reg_overlap_mentioned_p (stack_pointer_rtx, operands[1]))\n     {\n       if (nparts == 3)\n@@ -12255,7 +12255,7 @@ ix86_split_long_move (rtx operands[])\n \n   /* We need to do copy in the right order in case an address register\n      of the source overlaps the destination.  */\n-  if (REG_P (part[0][0]) && GET_CODE (part[1][0]) == MEM)\n+  if (REG_P (part[0][0]) && MEM_P (part[1][0]))\n     {\n       if (reg_overlap_mentioned_p (part[0][0], XEXP (part[1][0], 0)))\n \tcollisions++;\n@@ -12390,25 +12390,25 @@ ix86_split_long_move (rtx operands[])\n   /* If optimizing for size, attempt to locally unCSE nonzero constants.  */\n   if (optimize_size)\n     {\n-      if (GET_CODE (operands[5]) == CONST_INT\n+      if (CONST_INT_P (operands[5])\n \t  && operands[5] != const0_rtx\n \t  && REG_P (operands[2]))\n \t{\n-\t  if (GET_CODE (operands[6]) == CONST_INT\n+\t  if (CONST_INT_P (operands[6])\n \t      && INTVAL (operands[6]) == INTVAL (operands[5]))\n \t    operands[6] = operands[2];\n \n \t  if (nparts == 3\n-\t      && GET_CODE (operands[7]) == CONST_INT\n+\t      && CONST_INT_P (operands[7])\n \t      && INTVAL (operands[7]) == INTVAL (operands[5]))\n \t    operands[7] = operands[2];\n \t}\n \n       if (nparts == 3\n-\t  && GET_CODE (operands[6]) == CONST_INT\n+\t  && CONST_INT_P (operands[6])\n \t  && operands[6] != const0_rtx\n \t  && REG_P (operands[3])\n-\t  && GET_CODE (operands[7]) == CONST_INT\n+\t  && CONST_INT_P (operands[7])\n \t  && INTVAL (operands[7]) == INTVAL (operands[6]))\n \toperands[7] = operands[3];\n     }\n@@ -12458,7 +12458,7 @@ ix86_split_ashl (rtx *operands, rtx scratch, enum machine_mode mode)\n   int count;\n   const int single_width = mode == DImode ? 32 : 64;\n \n-  if (GET_CODE (operands[2]) == CONST_INT)\n+  if (CONST_INT_P (operands[2]))\n     {\n       (mode == DImode ? split_di : split_ti) (operands, 2, low, high);\n       count = INTVAL (operands[2]) & (single_width * 2 - 1);\n@@ -12585,7 +12585,7 @@ ix86_split_ashr (rtx *operands, rtx scratch, enum machine_mode mode)\n   int count;\n   const int single_width = mode == DImode ? 32 : 64;\n \n-  if (GET_CODE (operands[2]) == CONST_INT)\n+  if (CONST_INT_P (operands[2]))\n     {\n       (mode == DImode ? split_di : split_ti) (operands, 2, low, high);\n       count = INTVAL (operands[2]) & (single_width * 2 - 1);\n@@ -12664,7 +12664,7 @@ ix86_split_lshr (rtx *operands, rtx scratch, enum machine_mode mode)\n   int count;\n   const int single_width = mode == DImode ? 32 : 64;\n \n-  if (GET_CODE (operands[2]) == CONST_INT)\n+  if (CONST_INT_P (operands[2]))\n     {\n       (mode == DImode ? split_di : split_ti) (operands, 2, low, high);\n       count = INTVAL (operands[2]) & (single_width * 2 - 1);\n@@ -12725,7 +12725,7 @@ static void\n predict_jump (int prob)\n {\n   rtx insn = get_last_insn ();\n-  gcc_assert (GET_CODE (insn) == JUMP_INSN);\n+  gcc_assert (JUMP_P (insn));\n   REG_NOTES (insn)\n     = gen_rtx_EXPR_LIST (REG_BR_PROB,\n \t\t\t GEN_INT (prob),\n@@ -12785,7 +12785,7 @@ scale_counter (rtx countreg, int scale)\n \n   if (scale == 1)\n     return countreg;\n-  if (GET_CODE (countreg) == CONST_INT)\n+  if (CONST_INT_P (countreg))\n     return GEN_INT (INTVAL (countreg) / scale);\n   gcc_assert (REG_P (countreg));\n \n@@ -12948,7 +12948,7 @@ expand_movmem_via_rep_mov (rtx destmem, rtx srcmem,\n   rtx countreg;\n \n   /* If the size is known, it is shorter to use rep movs.  */\n-  if (mode == QImode && GET_CODE (count) == CONST_INT\n+  if (mode == QImode && CONST_INT_P (count)\n       && !(INTVAL (count) & 3))\n     mode = SImode;\n \n@@ -13015,7 +13015,7 @@ expand_movmem_epilogue (rtx destmem, rtx srcmem,\n \t\t\trtx destptr, rtx srcptr, rtx count, int max_size)\n {\n   rtx src, dest;\n-  if (GET_CODE (count) == CONST_INT)\n+  if (CONST_INT_P (count))\n     {\n       HOST_WIDE_INT countval = INTVAL (count);\n       int offset = 0;\n@@ -13168,7 +13168,7 @@ expand_setmem_epilogue (rtx destmem, rtx destptr, rtx value, rtx count, int max_\n {\n   rtx dest;\n \n-  if (GET_CODE (count) == CONST_INT)\n+  if (CONST_INT_P (count))\n     {\n       HOST_WIDE_INT countval = INTVAL (count);\n       int offset = 0;\n@@ -13551,15 +13551,15 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n   enum stringop_alg alg;\n   int dynamic_check;\n \n-  if (GET_CODE (align_exp) == CONST_INT)\n+  if (CONST_INT_P (align_exp))\n     align = INTVAL (align_exp);\n   /* i386 can do misaligned access on reasonably increased cost.  */\n-  if (GET_CODE (expected_align_exp) == CONST_INT\n+  if (CONST_INT_P (expected_align_exp)\n       && INTVAL (expected_align_exp) > align)\n     align = INTVAL (expected_align_exp);\n-  if (GET_CODE (count_exp) == CONST_INT)\n+  if (CONST_INT_P (count_exp))\n     count = expected_size = INTVAL (count_exp);\n-  if (GET_CODE (expected_size_exp) == CONST_INT && count == 0)\n+  if (CONST_INT_P (expected_size_exp) && count == 0)\n     expected_size = INTVAL (expected_size_exp);\n \n   /* Step 0: Decide on preferred algorithm, desired alignment and\n@@ -13606,7 +13606,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n   /* Step 1: Prologue guard.  */\n \n   /* Alignment code needs count to be in register.  */\n-  if (GET_CODE (count_exp) == CONST_INT && desired_align > align)\n+  if (CONST_INT_P (count_exp) && desired_align > align)\n     {\n       enum machine_mode mode = SImode;\n       if (TARGET_64BIT && (count & ~0xffffffff))\n@@ -13704,7 +13704,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n       break;\n     }\n   /* Adjust properly the offset of src and dest memory for aliasing.  */\n-  if (GET_CODE (count_exp) == CONST_INT)\n+  if (CONST_INT_P (count_exp))\n     {\n       src = adjust_automodify_address_nv (src, BLKmode, srcreg,\n \t\t\t\t\t  (count / size_needed) * size_needed);\n@@ -13762,7 +13762,7 @@ promote_duplicated_reg (enum machine_mode mode, rtx val)\n   gcc_assert (mode == SImode || mode == DImode);\n   if (val == const0_rtx)\n     return copy_to_mode_reg (mode, const0_rtx);\n-  if (GET_CODE (val) == CONST_INT)\n+  if (CONST_INT_P (val))\n     {\n       HOST_WIDE_INT v = INTVAL (val) & 255;\n \n@@ -13861,15 +13861,15 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n   bool force_loopy_epilogue = false;\n   int dynamic_check;\n \n-  if (GET_CODE (align_exp) == CONST_INT)\n+  if (CONST_INT_P (align_exp))\n     align = INTVAL (align_exp);\n   /* i386 can do misaligned access on reasonably increased cost.  */\n-  if (GET_CODE (expected_align_exp) == CONST_INT\n+  if (CONST_INT_P (expected_align_exp)\n       && INTVAL (expected_align_exp) > align)\n     align = INTVAL (expected_align_exp);\n-  if (GET_CODE (count_exp) == CONST_INT)\n+  if (CONST_INT_P (count_exp))\n     count = expected_size = INTVAL (count_exp);\n-  if (GET_CODE (expected_size_exp) == CONST_INT && count == 0)\n+  if (CONST_INT_P (expected_size_exp) && count == 0)\n     expected_size = INTVAL (expected_size_exp);\n \n   /* Step 0: Decide on preferred algorithm, desired alignment and\n@@ -13914,7 +13914,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n   /* Step 1: Prologue guard.  */\n \n   /* Alignment code needs count to be in register.  */\n-  if (GET_CODE (count_exp) == CONST_INT && desired_align > align)\n+  if (CONST_INT_P (count_exp) && desired_align > align)\n     {\n       enum machine_mode mode = SImode;\n       if (TARGET_64BIT && (count & ~0xffffffff))\n@@ -13924,7 +13924,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n   /* Do the cheap promotion to allow better CSE across the \n      main loop and epilogue (ie one load of the big constant in the\n      front of all code.  */\n-  if (GET_CODE (val_exp) == CONST_INT)\n+  if (CONST_INT_P (val_exp))\n     promoted_val = promote_duplicated_reg_to_size (val_exp, size_needed,\n \t\t\t\t\t\t   desired_align, align);\n   /* Ensure that alignment prologue won't copy past end of block.  */\n@@ -14022,7 +14022,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n       break;\n     }\n   /* Adjust properly the offset of src and dest memory for aliasing.  */\n-  if (GET_CODE (count_exp) == CONST_INT)\n+  if (CONST_INT_P (count_exp))\n     dst = adjust_automodify_address_nv (dst, BLKmode, destreg,\n \t\t\t\t\t(count / size_needed) * size_needed);\n   else\n@@ -14076,7 +14076,7 @@ ix86_expand_strlen (rtx out, rtx src, rtx eoschar, rtx align)\n   if (TARGET_UNROLL_STRLEN && eoschar == const0_rtx && optimize > 1\n       && !TARGET_INLINE_ALL_STRINGOPS\n       && !optimize_size\n-      && (GET_CODE (align) != CONST_INT || INTVAL (align) < 4))\n+      && (!CONST_INT_P (align) || INTVAL (align) < 4))\n     return 0;\n \n   addr = force_reg (Pmode, XEXP (src, 0));\n@@ -14161,7 +14161,7 @@ ix86_expand_strlensi_unroll_1 (rtx out, rtx src, rtx align_rtx)\n   rtx cmp;\n \n   align = 0;\n-  if (GET_CODE (align_rtx) == CONST_INT)\n+  if (CONST_INT_P (align_rtx))\n     align = INTVAL (align_rtx);\n \n   /* Loop to check 1..3 bytes for null to get an aligned pointer.  */\n@@ -14606,7 +14606,7 @@ ix86_attr_length_address_default (rtx insn)\n \n   extract_insn_cached (insn);\n   for (i = recog_data.n_operands - 1; i >= 0; --i)\n-    if (GET_CODE (recog_data.operand[i]) == MEM)\n+    if (MEM_P (recog_data.operand[i]))\n       {\n \treturn memory_address_length (XEXP (recog_data.operand[i], 0));\n \tbreak;\n@@ -14673,7 +14673,7 @@ ix86_flags_dependent (rtx insn, rtx dep_insn, enum attr_type insn_type)\n   else\n     return 0;\n \n-  if (GET_CODE (set) != REG || REGNO (set) != FLAGS_REG)\n+  if (!REG_P (set) || REGNO (set) != FLAGS_REG)\n     return 0;\n \n   /* This test is true if the dependent insn reads the flags but\n@@ -14712,7 +14712,7 @@ ix86_agi_dependent (rtx insn, rtx dep_insn, enum attr_type insn_type)\n       int i;\n       extract_insn_cached (insn);\n       for (i = recog_data.n_operands - 1; i >= 0; --i)\n-\tif (GET_CODE (recog_data.operand[i]) == MEM)\n+\tif (MEM_P (recog_data.operand[i]))\n \t  {\n \t    addr = XEXP (recog_data.operand[i], 0);\n \t    goto found;\n@@ -14775,7 +14775,7 @@ ix86_adjust_cost (rtx insn, rtx link, rtx dep_insn, int cost)\n \t  && (set = single_set (dep_insn)) != NULL_RTX\n \t  && (set2 = single_set (insn)) != NULL_RTX\n \t  && rtx_equal_p (SET_DEST (set), SET_SRC (set2))\n-\t  && GET_CODE (SET_DEST (set2)) == MEM)\n+\t  && MEM_P (SET_DEST (set2)))\n \tcost += 1;\n \n       /* Show ability of reorder buffer to hide latency of load by executing\n@@ -18250,7 +18250,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n       return false;\n \n     case ASHIFT:\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+      if (CONST_INT_P (XEXP (x, 1))\n \t  && (GET_MODE (XEXP (x, 0)) != DImode || TARGET_64BIT))\n \t{\n \t  HOST_WIDE_INT value = INTVAL (XEXP (x, 1));\n@@ -18274,7 +18274,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n     case ROTATERT:\n       if (!TARGET_64BIT && GET_MODE (XEXP (x, 0)) == DImode)\n \t{\n-\t  if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n+\t  if (CONST_INT_P (XEXP (x, 1)))\n \t    {\n \t      if (INTVAL (XEXP (x, 1)) > 32)\n \t\t*total = ix86_cost->shift_const + COSTS_N_INSNS (2);\n@@ -18291,7 +18291,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t}\n       else\n \t{\n-\t  if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n+\t  if (CONST_INT_P (XEXP (x, 1)))\n \t    *total = ix86_cost->shift_const;\n \t  else\n \t    *total = ix86_cost->shift_var;\n@@ -18309,7 +18309,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  rtx op0 = XEXP (x, 0);\n \t  rtx op1 = XEXP (x, 1);\n \t  int nbits;\n-\t  if (GET_CODE (XEXP (x, 1)) == CONST_INT)\n+\t  if (CONST_INT_P (XEXP (x, 1)))\n \t    {\n \t      unsigned HOST_WIDE_INT value = INTVAL (XEXP (x, 1));\n \t      for (nbits = 0; value != 0; value &= value - 1)\n@@ -18329,7 +18329,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n \n \t      if (GET_CODE (op0) == GET_CODE (op1))\n \t\tis_mulwiden = 1, op1 = XEXP (op1, 0);\n-\t      else if (GET_CODE (op1) == CONST_INT)\n+\t      else if (CONST_INT_P (op1))\n \t\t{\n \t\t  if (GET_CODE (op0) == SIGN_EXTEND)\n \t\t    is_mulwiden = trunc_int_for_mode (INTVAL (op1), inner_mode)\n@@ -18367,7 +18367,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t{\n \t  if (GET_CODE (XEXP (x, 0)) == PLUS\n \t      && GET_CODE (XEXP (XEXP (x, 0), 0)) == MULT\n-\t      && GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 1)) == CONST_INT\n+\t      && CONST_INT_P (XEXP (XEXP (XEXP (x, 0), 0), 1))\n \t      && CONSTANT_P (XEXP (x, 1)))\n \t    {\n \t      HOST_WIDE_INT val = INTVAL (XEXP (XEXP (XEXP (x, 0), 0), 1));\n@@ -18382,7 +18382,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t\t}\n \t    }\n \t  else if (GET_CODE (XEXP (x, 0)) == MULT\n-\t\t   && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT)\n+\t\t   && CONST_INT_P (XEXP (XEXP (x, 0), 1)))\n \t    {\n \t      HOST_WIDE_INT val = INTVAL (XEXP (XEXP (x, 0), 1));\n \t      if (val == 2 || val == 4 || val == 8)\n@@ -18444,7 +18444,7 @@ ix86_rtx_costs (rtx x, int code, int outer_code, int *total)\n     case COMPARE:\n       if (GET_CODE (XEXP (x, 0)) == ZERO_EXTRACT\n \t  && XEXP (XEXP (x, 0), 1) == const1_rtx\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 2)) == CONST_INT\n+\t  && CONST_INT_P (XEXP (XEXP (x, 0), 2))\n \t  && XEXP (x, 1) == const0_rtx)\n \t{\n \t  /* This kind of construct is implemented using test[bwl].\n@@ -18938,14 +18938,14 @@ min_insn_size (rtx insn)\n   if (GET_CODE (PATTERN (insn)) == UNSPEC_VOLATILE\n       && XINT (PATTERN (insn), 1) == UNSPECV_ALIGN)\n     return 0;\n-  if (GET_CODE (insn) == JUMP_INSN\n+  if (JUMP_P (insn)\n       && (GET_CODE (PATTERN (insn)) == ADDR_VEC\n \t  || GET_CODE (PATTERN (insn)) == ADDR_DIFF_VEC))\n     return 0;\n \n   /* Important case - calls are always 5 bytes.\n      It is common to have many calls in the row.  */\n-  if (GET_CODE (insn) == CALL_INSN\n+  if (CALL_P (insn)\n       && symbolic_reference_mentioned_p (PATTERN (insn))\n       && !SIBLING_CALL_P (insn))\n     return 5;\n@@ -18955,7 +18955,7 @@ min_insn_size (rtx insn)\n   /* For normal instructions we may rely on the sizes of addresses\n      and the presence of symbol to require 4 bytes of encoding.\n      This is not the case for jumps where references are PC relative.  */\n-  if (GET_CODE (insn) != JUMP_INSN)\n+  if (!JUMP_P (insn))\n     {\n       l = get_attr_length_address (insn);\n       if (l < 4 && symbolic_reference_mentioned_p (PATTERN (insn)))\n@@ -18994,21 +18994,21 @@ ix86_avoid_jump_misspredicts (void)\n       if (dump_file)\n         fprintf(dump_file, \"Insn %i estimated to %i bytes\\n\",\n \t\tINSN_UID (insn), min_insn_size (insn));\n-      if ((GET_CODE (insn) == JUMP_INSN\n+      if ((JUMP_P (insn)\n \t   && GET_CODE (PATTERN (insn)) != ADDR_VEC\n \t   && GET_CODE (PATTERN (insn)) != ADDR_DIFF_VEC)\n-\t  || GET_CODE (insn) == CALL_INSN)\n+\t  || CALL_P (insn))\n \tnjumps++;\n       else\n \tcontinue;\n \n       while (njumps > 3)\n \t{\n \t  start = NEXT_INSN (start);\n-\t  if ((GET_CODE (start) == JUMP_INSN\n+\t  if ((JUMP_P (start)\n \t       && GET_CODE (PATTERN (start)) != ADDR_VEC\n \t       && GET_CODE (PATTERN (start)) != ADDR_DIFF_VEC)\n-\t      || GET_CODE (start) == CALL_INSN)\n+\t      || CALL_P (start))\n \t    njumps--, isjump = 1;\n \t  else\n \t    isjump = 0;\n@@ -19048,13 +19048,13 @@ ix86_pad_returns (void)\n       rtx prev;\n       bool replace = false;\n \n-      if (GET_CODE (ret) != JUMP_INSN || GET_CODE (PATTERN (ret)) != RETURN\n+      if (!JUMP_P (ret) || GET_CODE (PATTERN (ret)) != RETURN\n \t  || !maybe_hot_bb_p (bb))\n \tcontinue;\n       for (prev = PREV_INSN (ret); prev; prev = PREV_INSN (prev))\n-\tif (active_insn_p (prev) || GET_CODE (prev) == CODE_LABEL)\n+\tif (active_insn_p (prev) || LABEL_P (prev))\n \t  break;\n-      if (prev && GET_CODE (prev) == CODE_LABEL)\n+      if (prev && LABEL_P (prev))\n \t{\n \t  edge e;\n \t  edge_iterator ei;\n@@ -19068,8 +19068,8 @@ ix86_pad_returns (void)\n \t{\n \t  prev = prev_active_insn (ret);\n \t  if (prev\n-\t      && ((GET_CODE (prev) == JUMP_INSN && any_condjump_p (prev))\n-\t\t  || GET_CODE (prev) == CALL_INSN))\n+\t      && ((JUMP_P (prev) && any_condjump_p (prev))\n+\t\t  || CALL_P (prev)))\n \t    replace = true;\n \t  /* Empty functions get branch mispredict even when the jump destination\n \t     is not visible to us.  */"}, {"sha": "5ca723b4501aa7947e30643857479c81f5171824", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 144, "deletions": 142, "changes": 286, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=7656aee4d0a2da07531a3ca334bb98728545d135", "patch": "@@ -507,7 +507,7 @@\n \t\t    (match_operand:TI 1 \"x86_64_general_operand\" \"\")))]\n   \"TARGET_64BIT\"\n {\n-  if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)\n+  if (MEM_P (operands[0]) && MEM_P (operands[1]))\n     operands[0] = force_reg (TImode, operands[0]);\n   ix86_compare_op0 = operands[0];\n   ix86_compare_op1 = operands[1];\n@@ -520,7 +520,7 @@\n \t\t    (match_operand:DI 1 \"x86_64_general_operand\" \"\")))]\n   \"\"\n {\n-  if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)\n+  if (MEM_P (operands[0]) && MEM_P (operands[1]))\n     operands[0] = force_reg (DImode, operands[0]);\n   ix86_compare_op0 = operands[0];\n   ix86_compare_op1 = operands[1];\n@@ -533,7 +533,7 @@\n \t\t    (match_operand:SI 1 \"general_operand\" \"\")))]\n   \"\"\n {\n-  if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)\n+  if (MEM_P (operands[0]) && MEM_P (operands[1]))\n     operands[0] = force_reg (SImode, operands[0]);\n   ix86_compare_op0 = operands[0];\n   ix86_compare_op1 = operands[1];\n@@ -546,7 +546,7 @@\n \t\t    (match_operand:HI 1 \"general_operand\" \"\")))]\n   \"\"\n {\n-  if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)\n+  if (MEM_P (operands[0]) && MEM_P (operands[1]))\n     operands[0] = force_reg (HImode, operands[0]);\n   ix86_compare_op0 = operands[0];\n   ix86_compare_op1 = operands[1];\n@@ -559,7 +559,7 @@\n \t\t    (match_operand:QI 1 \"general_operand\" \"\")))]\n   \"TARGET_QIMODE_MATH\"\n {\n-  if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)\n+  if (MEM_P (operands[0]) && MEM_P (operands[1]))\n     operands[0] = force_reg (QImode, operands[0]);\n   ix86_compare_op0 = operands[0];\n   ix86_compare_op1 = operands[1];\n@@ -638,7 +638,7 @@\n   [(set (reg FLAGS_REG)\n \t(compare (match_operand:SI 0 \"nonimmediate_operand\" \"rm,r\")\n \t\t (match_operand:SI 1 \"general_operand\" \"ri,mr\")))]\n-  \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\n     && ix86_match_ccmode (insn, CCmode)\"\n   \"cmp{l}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"icmp\")\n@@ -670,7 +670,7 @@\n   [(set (reg FLAGS_REG)\n \t(compare (match_operand:HI 0 \"nonimmediate_operand\" \"rm,r\")\n \t\t (match_operand:HI 1 \"general_operand\" \"ri,mr\")))]\n-  \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && ix86_match_ccmode (insn, CCmode)\"\n   \"cmp{w}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"icmp\")\n@@ -692,7 +692,7 @@\n   [(set (reg FLAGS_REG)\n \t(compare (match_operand:QI 0 \"nonimmediate_operand\" \"qm,q\")\n \t\t (match_operand:QI 1 \"general_operand\" \"qi,mq\")))]\n-  \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\n     && ix86_match_ccmode (insn, CCmode)\"\n   \"cmp{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"icmp\")\n@@ -1310,7 +1310,7 @@\n (define_insn \"*movhi_1\"\n   [(set (match_operand:HI 0 \"nonimmediate_operand\" \"=r,r,r,m\")\n \t(match_operand:HI 1 \"general_operand\" \"r,rn,rm,rn\"))]\n-  \"GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM\"\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n {\n   switch (get_attr_type (insn))\n     {\n@@ -1419,15 +1419,15 @@\n   \"! TARGET_PARTIAL_REG_STALL || optimize_size\"\n {\n   /* Don't generate memory->memory moves, go through a register */\n-  if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)\n+  if (MEM_P (operands[0]) && MEM_P (operands[1]))\n     operands[1] = force_reg (HImode, operands[1]);\n })\n \n (define_insn \"*movstricthi_1\"\n   [(set (strict_low_part (match_operand:HI 0 \"nonimmediate_operand\" \"+rm,r\"))\n \t(match_operand:HI 1 \"general_operand\" \"rn,m\"))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"mov{w}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"imov\")\n    (set_attr \"mode\" \"HI\")])\n@@ -1483,12 +1483,12 @@\n (define_insn \"*movqi_1\"\n   [(set (match_operand:QI 0 \"nonimmediate_operand\" \"=q,q ,q ,r,r ,?r,m\")\n \t(match_operand:QI 1 \"general_operand\"      \" q,qn,qm,q,rn,qm,qn\"))]\n-  \"GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM\"\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n {\n   switch (get_attr_type (insn))\n     {\n     case TYPE_IMOVX:\n-      gcc_assert (ANY_QI_REG_P (operands[1]) || GET_CODE (operands[1]) == MEM);\n+      gcc_assert (ANY_QI_REG_P (operands[1]) || MEM_P (operands[1]));\n       return \"movz{bl|x}\\t{%1, %k0|%k0, %1}\";\n     default:\n       if (get_attr_mode (insn) == MODE_SI)\n@@ -1593,15 +1593,15 @@\n   \"! TARGET_PARTIAL_REG_STALL || optimize_size\"\n {\n   /* Don't generate memory->memory moves, go through a register.  */\n-  if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)\n+  if (MEM_P (operands[0]) && MEM_P (operands[1]))\n     operands[1] = force_reg (QImode, operands[1]);\n })\n \n (define_insn \"*movstrictqi_1\"\n   [(set (strict_low_part (match_operand:QI 0 \"nonimmediate_operand\" \"+qm,q\"))\n \t(match_operand:QI 1 \"general_operand\" \"*qn,m\"))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"mov{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"imov\")\n    (set_attr \"mode\" \"QI\")])\n@@ -2156,7 +2156,7 @@\n   [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:TI 1 \"vector_move_operand\" \"C,xm,x\"))]\n   \"TARGET_SSE && !TARGET_64BIT\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n {\n   switch (which_alternative)\n     {\n@@ -2190,7 +2190,7 @@\n   [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=r,o,x,x,xm\")\n \t(match_operand:TI 1 \"general_operand\" \"riFo,riF,C,xm,x\"))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n {\n   switch (which_alternative)\n     {\n@@ -2274,7 +2274,7 @@\n   [(set (match_operand:SF 0 \"push_operand\" \"\")\n \t(match_operand:SF 1 \"memory_operand\" \"\"))]\n   \"reload_completed\n-   && GET_CODE (operands[1]) == MEM\n+   && MEM_P (operands[1])\n    && constant_pool_reference_p (operands[1])\"\n   [(set (match_dup 0)\n \t(match_dup 1))]\n@@ -2470,7 +2470,7 @@\n \t\t\t\"=f,m,f,*r  ,o  ,Y*x,Y*x,Y*x ,m  \")\n \t(match_operand:DF 1 \"general_operand\"\n \t\t\t\"fm,f,G,*roF,F*r,C  ,Y*x,mY*x,Y*x\"))]\n-  \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && ((optimize_size || !TARGET_INTEGER_DFMODE_MOVES) && !TARGET_64BIT)\n    && (reload_in_progress || reload_completed\n        || (ix86_cmodel == CM_MEDIUM || ix86_cmodel == CM_LARGE)\n@@ -2592,7 +2592,7 @@\n \t\t\"=f,m,f,r  ,o ,Y*x,Y*x,Y*x,m  \")\n \t(match_operand:DF 1 \"general_operand\"\n \t\t\"fm,f,G,roF,Fr,C  ,Y*x,m  ,Y*x\"))]\n-  \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && ((!optimize_size && TARGET_INTEGER_DFMODE_MOVES) || TARGET_64BIT)\n    && (reload_in_progress || reload_completed\n        || (ix86_cmodel == CM_MEDIUM || ix86_cmodel == CM_LARGE)\n@@ -2714,7 +2714,7 @@\n   [(set (match_operand:DF 0 \"nonimmediate_operand\" \"\")\n \t(match_operand:DF 1 \"general_operand\" \"\"))]\n   \"reload_completed\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && ! (ANY_FP_REG_P (operands[0]) ||\n \t (GET_CODE (operands[0]) == SUBREG\n \t  && ANY_FP_REG_P (SUBREG_REG (operands[0]))))\n@@ -2807,7 +2807,7 @@\n   [(set (match_operand:XF 0 \"nonimmediate_operand\" \"=f,m,f,*r,o\")\n \t(match_operand:XF 1 \"general_operand\" \"fm,f,G,*roF,F*r\"))]\n   \"optimize_size\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && (reload_in_progress || reload_completed\n        || (optimize_size && standard_80387_constant_p (operands[1]))\n        || GET_CODE (operands[1]) != CONST_DOUBLE\n@@ -2842,7 +2842,7 @@\n   [(set (match_operand:XF 0 \"nonimmediate_operand\" \"=f,m,f,r,o\")\n \t(match_operand:XF 1 \"general_operand\" \"fm,f,G,roF,Fr\"))]\n   \"!optimize_size\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && (reload_in_progress || reload_completed\n        || (optimize_size && standard_80387_constant_p (operands[1]))\n        || GET_CODE (operands[1]) != CONST_DOUBLE\n@@ -2878,7 +2878,7 @@\n   [(set (match_operand 0 \"nonimmediate_operand\" \"\")\n \t(match_operand 1 \"general_operand\" \"\"))]\n   \"reload_completed\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && GET_MODE (operands[0]) == XFmode\n    && ! (ANY_FP_REG_P (operands[0]) ||\n \t (GET_CODE (operands[0]) == SUBREG\n@@ -2893,9 +2893,10 @@\n   [(set (match_operand 0 \"register_operand\" \"\")\n \t(match_operand 1 \"memory_operand\" \"\"))]\n   \"reload_completed\n-   && GET_CODE (operands[1]) == MEM\n+   && MEM_P (operands[1])\n    && (GET_MODE (operands[0]) == XFmode\n-       || GET_MODE (operands[0]) == SFmode || GET_MODE (operands[0]) == DFmode)\n+       || GET_MODE (operands[0]) == SFmode\n+       || GET_MODE (operands[0]) == DFmode)\n    && constant_pool_reference_p (operands[1])\"\n   [(set (match_dup 0) (match_dup 1))]\n {\n@@ -2925,9 +2926,10 @@\n   [(set (match_operand 0 \"register_operand\" \"\")\n \t(float_extend (match_operand 1 \"memory_operand\" \"\")))]\n   \"reload_completed\n-   && GET_CODE (operands[1]) == MEM\n+   && MEM_P (operands[1])\n    && (GET_MODE (operands[0]) == XFmode\n-       || GET_MODE (operands[0]) == SFmode || GET_MODE (operands[0]) == DFmode)\n+       || GET_MODE (operands[0]) == SFmode\n+       || GET_MODE (operands[0]) == DFmode)\n    && constant_pool_reference_p (operands[1])\"\n   [(set (match_dup 0) (match_dup 1))]\n {\n@@ -3001,7 +3003,7 @@\n   [(set (match_operand:TF 0 \"nonimmediate_operand\" \"=r,o,x,x,xm\")\n \t(match_operand:TF 1 \"general_operand\" \"riFo,riF,C,xm,x\"))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n {\n   switch (which_alternative)\n     {\n@@ -3214,7 +3216,7 @@\n    (clobber (reg:CC FLAGS_REG))]\n   \"reload_completed\n    && ANY_QI_REG_P (operands[0])\n-   && (ANY_QI_REG_P (operands[1]) || GET_CODE (operands[1]) == MEM)\n+   && (ANY_QI_REG_P (operands[1]) || MEM_P (operands[1]))\n    && (TARGET_ZERO_EXTEND_WITH_AND && !optimize_size)\n    && !reg_overlap_mentioned_p (operands[0], operands[1])\"\n   [(set (match_dup 0) (const_int 0))\n@@ -5191,7 +5193,7 @@\n \n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n \t  /* Avoid overflows.  */\n \t  && ((INTVAL (operands[2]) & ((((unsigned int) 1) << 31) - 1)))\n           && (INTVAL (operands[2]) == 128\n@@ -5262,7 +5264,7 @@\n \t - do we need new constraint?  */\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n \t  /* Avoid overflows.  */\n \t  && ((INTVAL (operands[2]) & ((((unsigned int) 1) << 31) - 1)))\n           && (INTVAL (operands[2]) == 128\n@@ -5288,7 +5290,7 @@\n    (clobber (match_scratch:DI 0 \"=r\"))]\n   \"TARGET_64BIT\n    && ix86_match_ccmode (insn, CCZmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\n    /* Current assemblers are broken and do not allow @GOTOFF in\n       ought but a memory context.  */\n    && ! pic_symbolic_operand (operands[2], VOIDmode)\"\n@@ -5311,7 +5313,7 @@\n \t - do we need new constraint?  */\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n \t  /* Avoid overflows.  */\n \t  && ((INTVAL (operands[2]) & ((((unsigned int) 1) << 31) - 1)))\n           && (INTVAL (operands[2]) == 128\n@@ -5386,7 +5388,7 @@\n    (clobber (match_scratch:DI 0 \"=r\"))]\n   \"TARGET_64BIT\n    && ix86_match_ccmode (insn, CCGOCmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\n    /* Current assemblers are broken and do not allow @GOTOFF in\n       ought but a memory context.  */\n    && ! pic_symbolic_operand (operands[2], VOIDmode)\"\n@@ -5407,7 +5409,7 @@\n       gcc_assert (rtx_equal_p (operands[0], operands[1]));\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n \t  /* Avoid overflows.  */\n \t  && ((INTVAL (operands[2]) & ((((unsigned int) 1) << 31) - 1)))\n           && (INTVAL (operands[2]) == 128\n@@ -5455,7 +5457,7 @@\n \n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5536,7 +5538,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5606,7 +5608,7 @@\n       gcc_assert (rtx_equal_p (operands[0], operands[1]));\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5652,7 +5654,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5675,7 +5677,7 @@\n \t\t (match_operand:SI 1 \"nonimmediate_operand\" \"%0\")))\n    (clobber (match_scratch:SI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCZmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\n    /* Current assemblers are broken and do not allow @GOTOFF in\n       ought but a memory context.  */\n    && ! pic_symbolic_operand (operands[2], VOIDmode)\"\n@@ -5696,7 +5698,7 @@\n       gcc_assert (rtx_equal_p (operands[0], operands[1]));\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5740,7 +5742,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5810,7 +5812,7 @@\n \t  (const_int 0)))\n    (clobber (match_scratch:SI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCGOCmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\n    /* Current assemblers are broken and do not allow @GOTOFF in\n       ought but a memory context.  */\n    && ! pic_symbolic_operand (operands[2], VOIDmode)\"\n@@ -5831,7 +5833,7 @@\n       gcc_assert (rtx_equal_p (operands[0], operands[1]));\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5884,7 +5886,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5925,7 +5927,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5967,7 +5969,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -5990,7 +5992,7 @@\n \t\t (match_operand:HI 1 \"nonimmediate_operand\" \"%0\")))\n    (clobber (match_scratch:HI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCZmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n {\n   switch (get_attr_type (insn))\n     {\n@@ -6006,7 +6008,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -6070,7 +6072,7 @@\n \t  (const_int 0)))\n    (clobber (match_scratch:HI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCGOCmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n {\n   switch (get_attr_type (insn))\n     {\n@@ -6086,7 +6088,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -6137,7 +6139,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -6185,7 +6187,7 @@\n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.\n \t Exceptions: -128 encodes smaller than 128, so swap sign and op.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t\t  && INTVAL (operands[2]) != -128)))\n@@ -6214,7 +6216,7 @@\n \t\t (match_operand:QI 1 \"general_operand\" \"qn,qnm\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n {\n   switch (get_attr_type (insn))\n     {\n@@ -6229,7 +6231,7 @@\n \n     default:\n       /* Make things pretty and `subl $4,%eax' rather than `addl $-4, %eax'.  */\n-      if (GET_CODE (operands[1]) == CONST_INT\n+      if (CONST_INT_P (operands[1])\n \t  && INTVAL (operands[1]) < 0)\n \t{\n \t  operands[1] = GEN_INT (-INTVAL (operands[1]));\n@@ -6267,14 +6269,14 @@\n       else\n         {\n \t  gcc_assert (operands[2] == constm1_rtx\n-\t\t      || (GET_CODE (operands[2]) == CONST_INT\n+\t\t      || (CONST_INT_P (operands[2])\n \t\t          && INTVAL (operands[2]) == 255));\n \t  return \"dec{b}\\t%0\";\n \t}\n \n     default:\n       /* Make things pretty and `subb $4,%al' rather than `addb $-4, %al'.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && INTVAL (operands[2]) < 0)\n \t{\n \t  operands[2] = GEN_INT (-INTVAL (operands[2]));\n@@ -6295,7 +6297,7 @@\n \t\t (match_operand:QI 1 \"nonimmediate_operand\" \"%0\")))\n    (clobber (match_scratch:QI 0 \"=q\"))]\n   \"ix86_match_ccmode (insn, CCZmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n {\n   switch (get_attr_type (insn))\n     {\n@@ -6305,14 +6307,14 @@\n       else\n         {\n \t  gcc_assert (operands[2] == constm1_rtx\n-\t\t      || (GET_CODE (operands[2]) == CONST_INT\n+\t\t      || (CONST_INT_P (operands[2])\n \t\t\t  && INTVAL (operands[2]) == 255));\n \t  return \"dec{b}\\t%0\";\n \t}\n \n     default:\n       /* Make things pretty and `subb $4,%al' rather than `addb $-4, %al'.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && INTVAL (operands[2]) < 0)\n \t{\n \t  operands[2] = GEN_INT (-INTVAL (operands[2]));\n@@ -6340,7 +6342,7 @@\n     {\n     case TYPE_INCDEC:\n       if (operands[2] == constm1_rtx\n-\t  || (GET_CODE (operands[2]) == CONST_INT\n+\t  || (CONST_INT_P (operands[2])\n \t      && INTVAL (operands[2]) == 255))\n         return \"inc{b}\\t%0\";\n       else\n@@ -6374,7 +6376,7 @@\n \t  (const_int 0)))\n    (clobber (match_scratch:QI 0 \"=q\"))]\n   \"ix86_match_ccmode (insn, CCGOCmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n {\n   switch (get_attr_type (insn))\n     {\n@@ -6384,14 +6386,14 @@\n       else\n         {\n \t  gcc_assert (operands[2] == constm1_rtx\n-\t\t      || (GET_CODE (operands[2]) == CONST_INT\n+\t\t      || (CONST_INT_P (operands[2])\n \t\t\t  && INTVAL (operands[2]) == 255));\n \t  return \"dec{b}\\t%0\";\n \t}\n \n     default:\n       /* Make things pretty and `subb $4,%al' rather than `addb $-4, %al'.  */\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && INTVAL (operands[2]) < 0)\n \t{\n \t  operands[2] = GEN_INT (-INTVAL (operands[2]));\n@@ -6428,7 +6430,7 @@\n       else\n         {\n \t  gcc_assert (operands[2] == constm1_rtx\n-\t\t      || (GET_CODE (operands[2]) == CONST_INT\n+\t\t      || (CONST_INT_P (operands[2])\n \t\t\t  && INTVAL (operands[2]) == 255));\n           return \"dec{b}\\t%h0\";\n \t}\n@@ -6464,7 +6466,7 @@\n       else\n         {\n \t  gcc_assert (operands[2] == constm1_rtx\n-\t\t      || (GET_CODE (operands[2]) == CONST_INT\n+\t\t      || (CONST_INT_P (operands[2])\n \t\t\t  && INTVAL (operands[2]) == 255));\n           return \"dec{b}\\t%h0\";\n         }\n@@ -6843,7 +6845,7 @@\n \t\t  (match_operand:QI 1 \"general_operand\" \"qn,qmn\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"sub{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"alu1\")\n    (set_attr \"mode\" \"QI\")])\n@@ -6913,7 +6915,7 @@\n \t\t (match_operand:DI 2 \"x86_64_general_operand\" \"K,e,mr\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"@\n    imul{q}\\t{%2, %1, %0|%0, %1, %2}\n    imul{q}\\t{%2, %1, %0|%0, %1, %2}\n@@ -6944,7 +6946,7 @@\n \t(mult:SI (match_operand:SI 1 \"nonimmediate_operand\" \"%rm,rm,0\")\n \t\t (match_operand:SI 2 \"general_operand\" \"K,i,mr\")))\n    (clobber (reg:CC FLAGS_REG))]\n-  \"GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM\"\n+  \"!(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"@\n    imul{l}\\t{%2, %1, %0|%0, %1, %2}\n    imul{l}\\t{%2, %1, %0|%0, %1, %2}\n@@ -6969,7 +6971,7 @@\n \t\t   (match_operand:SI 2 \"general_operand\" \"K,i,mr\"))))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"@\n    imul{l}\\t{%2, %1, %k0|%k0, %1, %2}\n    imul{l}\\t{%2, %1, %k0|%k0, %1, %2}\n@@ -7000,7 +7002,7 @@\n \t(mult:HI (match_operand:HI 1 \"nonimmediate_operand\" \"%rm,rm,0\")\n \t\t (match_operand:HI 2 \"general_operand\" \"K,i,mr\")))\n    (clobber (reg:CC FLAGS_REG))]\n-  \"GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM\"\n+  \"!(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"@\n    imul{w}\\t{%2, %1, %0|%0, %1, %2}\n    imul{w}\\t{%2, %1, %0|%0, %1, %2}\n@@ -7029,7 +7031,7 @@\n \t\t (match_operand:QI 2 \"nonimmediate_operand\" \"qm\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_QIMODE_MATH\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"mul{b}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7055,7 +7057,7 @@\n \t\t (zero_extend:HI (match_operand:QI 2 \"nonimmediate_operand\" \"qm\"))))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_QIMODE_MATH\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"mul{b}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7079,7 +7081,7 @@\n \t\t (sign_extend:HI (match_operand:QI 2 \"nonimmediate_operand\" \"qm\"))))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_QIMODE_MATH\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"imul{b}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7105,7 +7107,7 @@\n \t\t (zero_extend:TI (match_operand:DI 2 \"nonimmediate_operand\" \"rm\"))))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"mul{q}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7132,7 +7134,7 @@\n \t\t (zero_extend:DI (match_operand:SI 2 \"nonimmediate_operand\" \"rm\"))))\n    (clobber (reg:CC FLAGS_REG))]\n   \"!TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"mul{l}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7158,7 +7160,7 @@\n \t\t (sign_extend:TI (match_operand:DI 2 \"nonimmediate_operand\" \"rm\"))))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"imul{q}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7184,7 +7186,7 @@\n \t\t (sign_extend:DI (match_operand:SI 2 \"nonimmediate_operand\" \"rm\"))))\n    (clobber (reg:CC FLAGS_REG))]\n   \"!TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"imul{l}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7220,7 +7222,7 @@\n    (clobber (match_scratch:DI 3 \"=1\"))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"mul{q}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7255,7 +7257,7 @@\n \t    (const_int 32))))\n    (clobber (match_scratch:SI 3 \"=1\"))\n    (clobber (reg:CC FLAGS_REG))]\n-  \"GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM\"\n+  \"!(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"mul{l}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7277,7 +7279,7 @@\n    (clobber (match_scratch:SI 3 \"=1\"))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"mul{l}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set_attr \"length_immediate\" \"0\")\n@@ -7313,7 +7315,7 @@\n    (clobber (match_scratch:DI 3 \"=1\"))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"imul{q}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set (attr \"athlon_decode\")\n@@ -7347,7 +7349,7 @@\n \t    (const_int 32))))\n    (clobber (match_scratch:SI 3 \"=1\"))\n    (clobber (reg:CC FLAGS_REG))]\n-  \"GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM\"\n+  \"!(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"imul{l}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set (attr \"athlon_decode\")\n@@ -7368,7 +7370,7 @@\n    (clobber (match_scratch:SI 3 \"=1\"))\n    (clobber (reg:CC FLAGS_REG))]\n   \"TARGET_64BIT\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"imul{l}\\t%2\"\n   [(set_attr \"type\" \"imul\")\n    (set (attr \"athlon_decode\")\n@@ -7767,7 +7769,7 @@\n \t\t  (match_operand:DI 1 \"x86_64_szext_general_operand\" \"Z,Z,e,e,re\"))\n \t  (const_int 0)))]\n   \"TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n    test{l}\\t{%k1, %k0|%k0, %k1}\n    test{l}\\t{%k1, %k0|%k0, %k1}\n@@ -7786,7 +7788,7 @@\n \t\t  (match_operand:SI 1 \"general_operand\" \"in,in,rin\"))\n \t  (const_int 0)))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"test{l}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"test\")\n    (set_attr \"modrm\" \"0,1,1\")\n@@ -7808,7 +7810,7 @@\n \t\t\t (match_operand:HI 1 \"general_operand\" \"n,n,rn\"))\n \t\t (const_int 0)))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"test{w}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"test\")\n    (set_attr \"modrm\" \"0,1,1\")\n@@ -7830,14 +7832,14 @@\n \t    (match_operand:QI 0 \"nonimmediate_operand\" \"%!*a,q,qm,r\")\n \t    (match_operand:QI 1 \"general_operand\" \"n,n,qn,n\"))\n \t  (const_int 0)))]\n-   \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+   \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\n     && ix86_match_ccmode (insn,\n- \t\t\t GET_CODE (operands[1]) == CONST_INT\n+ \t\t\t CONST_INT_P (operands[1])\n  \t\t\t && INTVAL (operands[1]) >= 0 ? CCNOmode : CCZmode)\"\n {\n   if (which_alternative == 3)\n     {\n-      if (GET_CODE (operands[1]) == CONST_INT && INTVAL (operands[1]) < 0)\n+      if (CONST_INT_P (operands[1]) && INTVAL (operands[1]) < 0)\n \toperands[1] = GEN_INT (INTVAL (operands[1]) & 0xff);\n       return \"test{l}\\t{%1, %k0|%k0, %1}\";\n     }\n@@ -7855,7 +7857,7 @@\n \t    (match_operand:QI 0 \"nonimmediate_operand\" \"%!*a,q,qm\")\n \t    (match_operand:QI 1 \"general_operand\" \"n,n,qn\"))\n \t  (const_int 0)))]\n-  \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n+  \"!(MEM_P (operands[0]) && MEM_P (operands[1]))\n    && ix86_match_ccmode (insn, CCNOmode)\"\n   \"test{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"test\")\n@@ -7905,7 +7907,7 @@\n \t      (match_operand:QI 1 \"general_operand\" \"Qm\")))\n \t  (const_int 0)))]\n   \"!TARGET_64BIT && ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"test{b}\\t{%1, %h0|%h0, %1}\"\n   [(set_attr \"type\" \"test\")\n    (set_attr \"mode\" \"QI\")])\n@@ -8001,7 +8003,7 @@\n   enum machine_mode mode, submode;\n \n   mode = GET_MODE (val);\n-  if (GET_CODE (val) == MEM)\n+  if (MEM_P (val))\n     {\n       /* ??? Combine likes to put non-volatile mem extractions in QImode\n \t no matter the size of the test.  So find a mode that works.  */\n@@ -8107,7 +8109,7 @@\n       {\n \tenum machine_mode mode;\n \n-\tgcc_assert (GET_CODE (operands[2]) == CONST_INT);\n+\tgcc_assert (CONST_INT_P (operands[2]));\n         if (INTVAL (operands[2]) == 0xff)\n \t  mode = QImode;\n \telse\n@@ -8172,7 +8174,7 @@\n       {\n \tenum machine_mode mode;\n \n-\tgcc_assert (GET_CODE (operands[2]) == CONST_INT);\n+\tgcc_assert (CONST_INT_P (operands[2]));\n         if (INTVAL (operands[2]) == 0xff)\n \t  mode = QImode;\n \telse\n@@ -8291,7 +8293,7 @@\n   switch (get_attr_type (insn))\n     {\n     case TYPE_IMOVX:\n-      gcc_assert (GET_CODE (operands[2]) == CONST_INT);\n+      gcc_assert (CONST_INT_P (operands[2]));\n       gcc_assert (INTVAL (operands[2]) == 0xff);\n       return \"movz{bl|x}\\t{%b1, %k0|%k0, %b1}\";\n \n@@ -8346,7 +8348,7 @@\n \t\t(match_operand:QI 1 \"general_operand\" \"qi,qmi\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"and{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"alu1\")\n    (set_attr \"mode\" \"QI\")])\n@@ -8361,12 +8363,12 @@\n \t(and:QI (match_dup 1) (match_dup 2)))]\n   \"ix86_binary_operator_ok (AND, QImode, operands)\n    && ix86_match_ccmode (insn,\n-\t\t\t GET_CODE (operands[2]) == CONST_INT\n+\t\t\t CONST_INT_P (operands[2])\n \t\t\t && INTVAL (operands[2]) >= 0 ? CCNOmode : CCZmode)\"\n {\n   if (which_alternative == 2)\n     {\n-      if (GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) < 0)\n+      if (CONST_INT_P (operands[2]) && INTVAL (operands[2]) < 0)\n         operands[2] = GEN_INT (INTVAL (operands[2]) & 0xff);\n       return \"and{l}\\t{%2, %k0|%k0, %2}\";\n     }\n@@ -8399,7 +8401,7 @@\n \t(and:QI (match_dup 0) (match_dup 1)))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n    && ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"and{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"alu1\")\n    (set_attr \"mode\" \"QI\")])\n@@ -8694,7 +8696,7 @@\n \t\t (const_int 0)))\n    (clobber (match_scratch:SI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"or{l}\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")\n    (set_attr \"mode\" \"SI\")])\n@@ -8737,7 +8739,7 @@\n \t\t (const_int 0)))\n    (clobber (match_scratch:HI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"or{w}\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")\n    (set_attr \"mode\" \"HI\")])\n@@ -8770,7 +8772,7 @@\n \t\t(match_operand:QI 1 \"general_operand\" \"qmi,qi\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"or{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"alu1\")\n    (set_attr \"mode\" \"QI\")])\n@@ -8797,7 +8799,7 @@\n \t(ior:QI (match_dup 0) (match_dup 1)))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n    && ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"or{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"alu1\")\n    (set_attr \"mode\" \"QI\")])\n@@ -8809,7 +8811,7 @@\n \t\t (const_int 0)))\n    (clobber (match_scratch:QI 0 \"=q\"))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"or{b}\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")\n    (set_attr \"mode\" \"QI\")])\n@@ -9071,7 +9073,7 @@\n \t\t (const_int 0)))\n    (clobber (match_scratch:SI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"xor{l}\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")\n    (set_attr \"mode\" \"SI\")])\n@@ -9114,7 +9116,7 @@\n \t\t (const_int 0)))\n    (clobber (match_scratch:HI 0 \"=r\"))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"xor{w}\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")\n    (set_attr \"mode\" \"HI\")])\n@@ -9147,7 +9149,7 @@\n \t\t(match_operand:QI 1 \"general_operand\" \"qi,qmi\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"xor{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"alu1\")\n    (set_attr \"mode\" \"QI\")])\n@@ -9248,7 +9250,7 @@\n \t(xor:QI (match_dup 0) (match_dup 1)))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n    && ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"xor{b}\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"alu1\")\n    (set_attr \"mode\" \"QI\")])\n@@ -9261,7 +9263,7 @@\n \t  (const_int 0)))\n    (clobber (match_scratch:QI 0 \"=q\"))]\n   \"ix86_match_ccmode (insn, CCNOmode)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"xor{b}\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")\n    (set_attr \"mode\" \"QI\")])\n@@ -10396,7 +10398,7 @@\n       return \"add{q}\\t{%0, %0|%0, %0}\";\n \n     case TYPE_LEA:\n-      gcc_assert (GET_CODE (operands[2]) == CONST_INT);\n+      gcc_assert (CONST_INT_P (operands[2]));\n       gcc_assert ((unsigned HOST_WIDE_INT) INTVAL (operands[2]) <= 3);\n       operands[1] = gen_rtx_MULT (DImode, operands[1],\n \t\t\t\t  GEN_INT (1 << INTVAL (operands[2])));\n@@ -11877,7 +11879,7 @@\n \t\t     (match_operand:QI 1 \"nonmemory_operand\" \"I,c\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n    sar{b}\\t{%1, %0|%0, %1}\n    sar{b}\\t{%b1, %0|%0, %b1}\"\n@@ -12462,7 +12464,7 @@\n \t\t     (match_operand:QI 1 \"nonmemory_operand\" \"I,c\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n    shr{b}\\t{%1, %0|%0, %1}\n    shr{b}\\t{%b1, %0|%0, %b1}\"\n@@ -12745,7 +12747,7 @@\n \t\t   (match_operand:QI 1 \"nonmemory_operand\" \"I,c\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n    rol{b}\\t{%1, %0|%0, %1}\n    rol{b}\\t{%b1, %0|%0, %b1}\"\n@@ -12984,7 +12986,7 @@\n \t\t     (match_operand:QI 1 \"nonmemory_operand\" \"I,c\")))\n    (clobber (reg:CC FLAGS_REG))]\n   \"(! TARGET_PARTIAL_REG_STALL || optimize_size)\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n    ror{b}\\t{%1, %0|%0, %1}\n    ror{b}\\t{%b1, %0|%0, %b1}\"\n@@ -15044,7 +15046,7 @@\n \t\t\t (match_operand:SF 2 \"nonimmediate_operand\" \"fm,xm\")]))]\n   \"TARGET_MIX_SSE_I387\n    && COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n \t(if_then_else (eq_attr \"alternative\" \"1\")\n@@ -15063,7 +15065,7 @@\n \t\t\t (match_operand:SF 2 \"nonimmediate_operand\" \"xm\")]))]\n   \"TARGET_SSE_MATH\n    && COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n         (if_then_else (match_operand:SF 3 \"mult_operator\" \"\")\n@@ -15078,7 +15080,7 @@\n \t\t\t (match_operand:SF 2 \"nonimmediate_operand\" \"fm\")]))]\n   \"TARGET_80387\n    && COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n \t(if_then_else (match_operand:SF 3 \"mult_operator\" \"\")\n@@ -15093,7 +15095,7 @@\n \t\t\t (match_operand:SF 2 \"nonimmediate_operand\" \"fm,0,xm\")]))]\n   \"TARGET_MIX_SSE_I387\n    && !COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n         (cond [(and (eq_attr \"alternative\" \"2\")\n@@ -15137,7 +15139,7 @@\n \t\t\t (match_operand:SF 2 \"nonimmediate_operand\" \"fm,0\")]))]\n   \"TARGET_80387 && !TARGET_SSE_MATH\n    && !COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n         (cond [(match_operand:SF 3 \"mult_operator\" \"\")\n@@ -15190,7 +15192,7 @@\n \t\t\t (match_operand:DF 2 \"nonimmediate_operand\" \"fm,Ym\")]))]\n   \"TARGET_SSE2 && TARGET_MIX_SSE_I387\n    && COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n \t(if_then_else (eq_attr \"alternative\" \"1\")\n@@ -15209,7 +15211,7 @@\n \t\t\t (match_operand:DF 2 \"nonimmediate_operand\" \"Ym\")]))]\n   \"TARGET_SSE2 && TARGET_SSE_MATH\n    && COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n         (if_then_else (match_operand:DF 3 \"mult_operator\" \"\")\n@@ -15224,7 +15226,7 @@\n \t\t\t (match_operand:DF 2 \"nonimmediate_operand\" \"fm\")]))]\n   \"TARGET_80387\n    && COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n \t(if_then_else (match_operand:DF 3 \"mult_operator\" \"\")\n@@ -15239,7 +15241,7 @@\n \t\t\t (match_operand:DF 2 \"nonimmediate_operand\" \"fm,0,Ym\")]))]\n   \"TARGET_SSE2 && TARGET_SSE_MATH && TARGET_MIX_SSE_I387\n    && !COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n         (cond [(and (eq_attr \"alternative\" \"2\")\n@@ -15283,7 +15285,7 @@\n \t\t\t (match_operand:DF 2 \"nonimmediate_operand\" \"fm,0\")]))]\n   \"TARGET_80387 && !(TARGET_SSE2 && TARGET_SSE_MATH)\n    && !COMMUTATIVE_ARITH_P (operands[3])\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n         (cond [(match_operand:DF 3 \"mult_operator\" \"\")\n@@ -15337,7 +15339,7 @@\n \t   [(float_extend:DF (match_operand:SF 1 \"nonimmediate_operand\" \"fm,0\"))\n \t    (match_operand:DF 2 \"register_operand\" \"0,f\")]))]\n   \"TARGET_80387 && !(TARGET_SSE2 && TARGET_SSE_MATH)\n-   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+   && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n   \"* return output_387_binary_op (insn, operands);\"\n   [(set (attr \"type\")\n         (cond [(match_operand:DF 3 \"mult_operator\" \"\")\n@@ -18120,7 +18122,7 @@\n     FAIL;\n \n   out = operands[0];\n-  if (GET_CODE (out) != REG)\n+  if (!REG_P (out))\n     out = gen_reg_rtx (SImode);\n \n   addr1 = copy_to_mode_reg (Pmode, XEXP (operands[1], 0));\n@@ -18138,7 +18140,7 @@\n      once cc0 is dead.  */\n   align = operands[4];\n \n-  if (GET_CODE (count) == CONST_INT)\n+  if (CONST_INT_P (count))\n     {\n       if (INTVAL (count) == 0)\n \t{\n@@ -18457,7 +18459,7 @@\n \t\t      (match_operand:DI 2 \"nonimmediate_operand\" \"rm,0\")\n \t\t      (match_operand:DI 3 \"nonimmediate_operand\" \"0,rm\")))]\n   \"TARGET_64BIT && TARGET_CMOVE\n-   && (GET_CODE (operands[2]) != MEM || GET_CODE (operands[3]) != MEM)\"\n+   && !(MEM_P (operands[2]) && MEM_P (operands[3]))\"\n   \"@\n    cmov%O2%C1\\t{%2, %0|%0, %2}\n    cmov%O2%c1\\t{%3, %0|%0, %3}\"\n@@ -18500,7 +18502,7 @@\n \t\t      (match_operand:SI 2 \"nonimmediate_operand\" \"rm,0\")\n \t\t      (match_operand:SI 3 \"nonimmediate_operand\" \"0,rm\")))]\n   \"TARGET_CMOVE\n-   && (GET_CODE (operands[2]) != MEM || GET_CODE (operands[3]) != MEM)\"\n+   && !(MEM_P (operands[2]) && MEM_P (operands[3]))\"\n   \"@\n    cmov%O2%C1\\t{%2, %0|%0, %2}\n    cmov%O2%c1\\t{%3, %0|%0, %3}\"\n@@ -18522,7 +18524,7 @@\n \t\t      (match_operand:HI 2 \"nonimmediate_operand\" \"rm,0\")\n \t\t      (match_operand:HI 3 \"nonimmediate_operand\" \"0,rm\")))]\n   \"TARGET_CMOVE\n-   && (GET_CODE (operands[2]) != MEM || GET_CODE (operands[3]) != MEM)\"\n+   && !(MEM_P (operands[2]) && MEM_P (operands[3]))\"\n   \"@\n    cmov%O2%C1\\t{%2, %0|%0, %2}\n    cmov%O2%c1\\t{%3, %0|%0, %3}\"\n@@ -18572,7 +18574,7 @@\n \t\t      (match_operand:SF 2 \"nonimmediate_operand\" \"f,0,rm,0\")\n \t\t      (match_operand:SF 3 \"nonimmediate_operand\" \"0,f,0,rm\")))]\n   \"TARGET_80387 && TARGET_CMOVE\n-   && (GET_CODE (operands[2]) != MEM || GET_CODE (operands[3]) != MEM)\"\n+   && !(MEM_P (operands[2]) && MEM_P (operands[3]))\"\n   \"@\n    fcmov%F1\\t{%2, %0|%0, %2}\n    fcmov%f1\\t{%3, %0|%0, %3}\n@@ -18596,7 +18598,7 @@\n \t\t      (match_operand:DF 2 \"nonimmediate_operand\" \"f,0,rm,0\")\n \t\t      (match_operand:DF 3 \"nonimmediate_operand\" \"0,f,0,rm\")))]\n   \"!TARGET_64BIT && TARGET_80387 && TARGET_CMOVE\n-   && (GET_CODE (operands[2]) != MEM || GET_CODE (operands[3]) != MEM)\"\n+   && !(MEM_P (operands[2]) && MEM_P (operands[3]))\"\n   \"@\n    fcmov%F1\\t{%2, %0|%0, %2}\n    fcmov%f1\\t{%3, %0|%0, %3}\n@@ -18612,7 +18614,7 @@\n \t\t      (match_operand:DF 2 \"nonimmediate_operand\" \"f,0,rm,0\")\n \t\t      (match_operand:DF 3 \"nonimmediate_operand\" \"0,f,0,rm\")))]\n   \"TARGET_64BIT && TARGET_80387 && TARGET_CMOVE\n-   && (GET_CODE (operands[2]) != MEM || GET_CODE (operands[3]) != MEM)\"\n+   && !(MEM_P (operands[2]) && MEM_P (operands[3]))\"\n   \"@\n    fcmov%F1\\t{%2, %0|%0, %2}\n    fcmov%f1\\t{%3, %0|%0, %3}\n@@ -18834,7 +18836,7 @@\n       return \"mov{l}\\t{%1, %0|%0, %1}\";\n \n     case TYPE_ALU:\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n           && (INTVAL (operands[2]) == 128\n \t      || (INTVAL (operands[2]) < 0\n \t          && INTVAL (operands[2]) != -128)))\n@@ -18875,7 +18877,7 @@\n       return \"mov{q}\\t{%1, %0|%0, %1}\";\n \n     case TYPE_ALU:\n-      if (GET_CODE (operands[2]) == CONST_INT\n+      if (CONST_INT_P (operands[2])\n \t  /* Avoid overflows.  */\n \t  && ((INTVAL (operands[2]) & ((((unsigned int) 1) << 31) - 1)))\n           && (INTVAL (operands[2]) == 128\n@@ -19001,7 +19003,7 @@\n   \"TARGET_STACK_PROBE\"\n {\n #ifdef CHECK_STACK_LIMIT\n-  if (GET_CODE (operands[1]) == CONST_INT\n+  if (CONST_INT_P (operands[1])\n       && INTVAL (operands[1]) < CHECK_STACK_LIMIT)\n     emit_insn (gen_subsi3 (stack_pointer_rtx, stack_pointer_rtx,\n \t\t\t   operands[1]));\n@@ -19048,7 +19050,7 @@\n    && ((GET_MODE (operands[0]) == HImode\n \t&& ((!optimize_size && !TARGET_FAST_PREFIX)\n             /* ??? next two lines just !satisfies_constraint_K (...) */\n-\t    || GET_CODE (operands[2]) != CONST_INT\n+\t    || !CONST_INT_P (operands[2])\n \t    || satisfies_constraint_K (operands[2])))\n        || (GET_MODE (operands[0]) == QImode\n \t   && (TARGET_PROMOTE_QImode || optimize_size)))\"\n@@ -19320,7 +19322,7 @@\n   \"!optimize_size\n    && peep2_regno_dead_p (0, FLAGS_REG)\n    && ((TARGET_PENTIUM\n-        && (GET_CODE (operands[0]) != MEM\n+        && (!MEM_P (operands[0])\n             || !memory_displacement_operand (operands[0], SImode)))\n        || (TARGET_K6 && long_memory_operand (operands[0], SImode)))\"\n   [(parallel [(set (match_dup 0)\n@@ -19334,7 +19336,7 @@\n   \"!optimize_size\n    && peep2_regno_dead_p (0, FLAGS_REG)\n    && ((TARGET_PENTIUM\n-        && (GET_CODE (operands[0]) != MEM\n+        && (!MEM_P (operands[0])\n             || !memory_displacement_operand (operands[0], HImode)))\n        || (TARGET_K6 && long_memory_operand (operands[0], HImode)))\"\n   [(parallel [(set (match_dup 0)\n@@ -19348,7 +19350,7 @@\n   \"!optimize_size\n    && peep2_regno_dead_p (0, FLAGS_REG)\n    && ((TARGET_PENTIUM\n-        && (GET_CODE (operands[0]) != MEM\n+        && (!MEM_P (operands[0])\n             || !memory_displacement_operand (operands[0], QImode)))\n        || (TARGET_K6 && long_memory_operand (operands[0], QImode)))\"\n   [(parallel [(set (match_dup 0)"}, {"sha": "4c5ebbca4d1e3f9019322948f594634725784c22", "filename": "gcc/config/i386/mmx.md", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fmmx.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fmmx.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fmmx.md?ref=7656aee4d0a2da07531a3ca334bb98728545d135", "patch": "@@ -68,7 +68,7 @@\n \t(match_operand:MMXMODEI 1 \"vector_move_operand\"\n \t\t\t\t\"Cr ,m,C ,*ym,*y,Y ,*y,C,xm,x,x,r\"))]\n   \"TARGET_64BIT && TARGET_MMX\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n     movq\\t{%1, %0|%0, %1}\n     movq\\t{%1, %0|%0, %1}\n@@ -92,7 +92,7 @@\n \t(match_operand:MMXMODEI 1 \"vector_move_operand\"\n \t\t\t\"C  ,*ym,*y,*Y,*y,C ,*Ym,*Y,C ,*x,m ,*x,irm,r\"))]\n   \"TARGET_MMX\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n     pxor\\t%0, %0\n     movq\\t{%1, %0|%0, %1}\n@@ -127,7 +127,7 @@\n         (match_operand:V2SF 1 \"vector_move_operand\"\n \t\t\t\t\"Cr ,m ,C ,*ym,*y,Y ,*y,C,x,m,x,x,r\"))]\n   \"TARGET_64BIT && TARGET_MMX\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n     movq\\t{%1, %0|%0, %1}\n     movq\\t{%1, %0|%0, %1}\n@@ -152,7 +152,7 @@\n         (match_operand:V2SF 1 \"vector_move_operand\"\n \t\t\t\t\t\"C ,*ym,*y,*Y,*y,C ,*x,m ,*x,irm,r\"))]\n   \"TARGET_MMX\n-   && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n+   && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n   \"@\n     pxor\\t%0, %0\n     movq\\t{%1, %0|%0, %1}"}, {"sha": "3f48234bdafcf9e5555fe863f35ec0bc7c257ab0", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7656aee4d0a2da07531a3ca334bb98728545d135/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=7656aee4d0a2da07531a3ca334bb98728545d135", "patch": "@@ -146,7 +146,7 @@\n \n \t  if (ix86_cmodel == CM_LARGE)\n \t    return 0;\n-\t  if (GET_CODE (op2) != CONST_INT)\n+\t  if (!CONST_INT_P (op2))\n \t    return 0;\n \t  offset = trunc_int_for_mode (INTVAL (op2), DImode);\n \t  switch (GET_CODE (op1))\n@@ -266,7 +266,7 @@\n \t      if ((ix86_cmodel == CM_SMALL\n \t\t   || (ix86_cmodel == CM_MEDIUM\n \t\t       && !SYMBOL_REF_FAR_ADDR_P (op1)))\n-\t\t  && GET_CODE (op2) == CONST_INT\n+\t\t  && CONST_INT_P (op2)\n \t\t  && trunc_int_for_mode (INTVAL (op2), DImode) > -0x10000\n \t\t  && trunc_int_for_mode (INTVAL (op2), SImode) == INTVAL (op2))\n \t\treturn 1;\n@@ -280,7 +280,7 @@\n \t      /* These conditions are similar to SYMBOL_REF ones, just the\n \t\t constraints for code models differ.  */\n \t      if ((ix86_cmodel == CM_SMALL || ix86_cmodel == CM_MEDIUM)\n-\t\t  && GET_CODE (op2) == CONST_INT\n+\t\t  && CONST_INT_P (op2)\n \t\t  && trunc_int_for_mode (INTVAL (op2), DImode) > -0x10000\n \t\t  && trunc_int_for_mode (INTVAL (op2), SImode) == INTVAL (op2))\n \t\treturn 1;\n@@ -340,7 +340,7 @@\n   if (TARGET_64BIT && GET_CODE (op) == CONST)\n     {\n       op = XEXP (op, 0);\n-      if (GET_CODE (op) == PLUS && GET_CODE (XEXP (op, 1)) == CONST_INT)\n+      if (GET_CODE (op) == PLUS && CONST_INT_P (XEXP (op, 1)))\n \top = XEXP (op, 0);\n       if (GET_CODE (op) == UNSPEC\n \t  && (XINT (op, 1) == UNSPEC_GOTOFF\n@@ -380,7 +380,7 @@\n \t\t  || XINT (op, 1) == UNSPEC_GOTPCREL)))\n \treturn 1;\n       if (GET_CODE (op) != PLUS\n-\t  || GET_CODE (XEXP (op, 1)) != CONST_INT)\n+\t  || !CONST_INT_P (XEXP (op, 1)))\n \treturn 0;\n \n       op = XEXP (op, 0);\n@@ -423,7 +423,7 @@\n       if (GET_CODE (op) == UNSPEC)\n \treturn 1;\n       if (GET_CODE (op) != PLUS\n-\t  || GET_CODE (XEXP (op, 1)) != CONST_INT)\n+\t  || !CONST_INT_P (XEXP (op, 1)))\n \treturn 0;\n       op = XEXP (op, 0);\n       if (GET_CODE (op) == UNSPEC)\n@@ -438,7 +438,7 @@\n {\n   if (GET_CODE (op) == CONST\n       && GET_CODE (XEXP (op, 0)) == PLUS\n-      && GET_CODE (XEXP (XEXP (op, 0), 1)) == CONST_INT)\n+      && CONST_INT_P (XEXP (XEXP (op, 0), 1)))\n     op = XEXP (XEXP (op, 0), 0);\n \n   if (GET_CODE (op) == LABEL_REF)\n@@ -784,7 +784,7 @@\n     }\n   if (parts.disp)\n     {\n-      if (GET_CODE (parts.disp) != CONST_INT\n+      if (!CONST_INT_P (parts.disp)\n \t  || (INTVAL (parts.disp) & 3) != 0)\n \treturn 0;\n     }\n@@ -911,7 +911,7 @@\n   enum machine_mode inmode = GET_MODE (XEXP (op, 0));\n   enum rtx_code code = GET_CODE (op);\n \n-  if (GET_CODE (XEXP (op, 0)) != REG\n+  if (!REG_P (XEXP (op, 0))\n       || REGNO (XEXP (op, 0)) != FLAGS_REG\n       || XEXP (op, 1) != const0_rtx)\n     return 0;"}]}