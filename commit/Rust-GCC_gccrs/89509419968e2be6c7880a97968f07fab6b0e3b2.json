{"sha": "89509419968e2be6c7880a97968f07fab6b0e3b2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ODk1MDk0MTk5NjhlMmJlNmM3ODgwYTk3OTY4ZjA3ZmFiNmIwZTNiMg==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2010-10-19T02:12:00Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2010-10-19T02:12:00Z"}, "message": "Simplify FMA4 patterns with FMA rtx code.\n\nAlso fix incorrect rtl generation for scalar instructions.\n\nFrom-SVN: r165676", "tree": {"sha": "23aa0fcfd49c69dcded07a79443419e6decfd644", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/23aa0fcfd49c69dcded07a79443419e6decfd644"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/89509419968e2be6c7880a97968f07fab6b0e3b2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/89509419968e2be6c7880a97968f07fab6b0e3b2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/89509419968e2be6c7880a97968f07fab6b0e3b2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/89509419968e2be6c7880a97968f07fab6b0e3b2/comments", "author": null, "committer": null, "parents": [{"sha": "a11930ba8d19cc26848dc06d4a2571642af735b9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a11930ba8d19cc26848dc06d4a2571642af735b9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a11930ba8d19cc26848dc06d4a2571642af735b9"}], "stats": {"total": 982, "additions": 259, "deletions": 723}, "files": [{"sha": "8f1595d21fe7bc81a332059bbac51530d9cb6639", "filename": "gcc/ChangeLog", "status": "modified", "additions": 43, "deletions": 0, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=89509419968e2be6c7880a97968f07fab6b0e3b2", "patch": "@@ -1,3 +1,46 @@\n+2010-10-18  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/i386/i386.c (IX86_BUILTIN_VFMSUBSS, IX86_BUILTIN_VFMSUBSD,\n+\tIX86_BUILTIN_VFMSUBPS, IX86_BUILTIN_VFMSUBPD,\n+\tIX86_BUILTIN_VFMSUBADDPS, IX86_BUILTIN_VFMSUBADDPD,\n+\tIX86_BUILTIN_VFNMADDSS, IX86_BUILTIN_VFNMADDSD,\n+\tIX86_BUILTIN_VFNMADDPS, IX86_BUILTIN_VFNMADDPD,\n+\tIX86_BUILTIN_VFNMSUBSS, IX86_BUILTIN_VFNMSUBSD,\n+\tIX86_BUILTIN_VFNMSUBPS, IX86_BUILTIN_VFNMSUBPD,\n+\tIX86_BUILTIN_VFMSUBADDPS256, IX86_BUILTIN_VFMSUBADDPD256,\n+\tIX86_BUILTIN_VFNMADDPS256, IX86_BUILTIN_VFNMADDPD256,\n+\tIX86_BUILTIN_VFNMSUBPS256, IX86_BUILTIN_VFNMSUBPD256): Remove.\n+\t(bdesc_multi_arg): Remove the corresponding builtins.\n+\t* config/i386/i386.md (UNSPEC_FMA4_INTRINSIC): Remove.\n+\t(UNSPEC_FMA4_FMSUBADD): Remove.\n+\t(UNSPEC_FMADDSUB): Rename from UNSPEC_FMA4_FMADDSUB.\n+\t* config/i386/sse.md (FMA4MODEF4): Remove.\n+\t(FMAMODE): Add.\n+\t(fma<mode>4): New expander.\n+\t(*fma4i_fmadd_<mode>): Macroize from fma4i_fmadd<mode>4 patterns,\n+\tand use FMA rtx code instead of UNSPEC_FMA4_INTRINSIC.\n+\t(*fma4i_fmsub_<mode>): Similarly.\n+\t(*fma4i_fnmadd_<mode>): Similarly.\n+\t(*fma4i_fnmsub_<mode>): Similarly.\n+\t(fma4i_vmfmadd_<mode>): Scalar patterns zero-extend, not merge\n+\twith the first operand.\n+\t(fma4i_fmaddsub_<mode>): Represent with UNSPEC_FMADDSUB instead\n+\tof explicit arithmetic.  Macroize with AVXMODEF2P.\n+\t(*fma4i_fmsubadd_<mode>): Represent with UNSPEC_FMADDSUB + NEG.\n+\t(xop_frcz<mode>2): Macroize with FMAMODE.\n+\t(xop_vmfrcz<mode>2): Scalar patterns zero-extend, not merge with\n+\tthe first operand.\n+\t* config/i386/fma4intrin.h (_mm_msub_ps): Use vfmadd intrinsic with\n+\textra negations.\n+\t(_mm_msub_pd, _mm_msub_ss, _mm_msub_sd): Likewise.\n+\t(_mm_nmacc_ps, _mm_nmacc_pd, _mm_nmacc_ss, _mm_nmacc_sd): Likewise.\n+\t(_mm_nmsub_ps, _mm_nmsub_pd, _mm_nmsub_ss, _mm_nmsub_sd): Likewise.\n+\t(_mm256_msub_ps, _mm256_msub_pd): Likewise.\n+\t(_mm256_nmacc_ps, _mm256_nmacc_pd): Likewise.\n+\t(_mm256_nmsub_ps, _mm256_nmsub_pd): Likewise.\n+\t(_mm_msubadd_ps): Use vfmaddsub intrinsic with extra negation.\n+\t(_mm_msubadd_pd, _mm256_msubadd_ps, _mm256_msubadd_pd): Likewise.\n+\n 2010-10-18  Bernd Schmidt  <bernds@codesourcery.com>\n \n \tPR rtl-optimization/45966"}, {"sha": "b910cd150a08c321fcdf20bdb22a86afa1d505d6", "filename": "gcc/config/i386/fma4intrin.h", "status": "modified", "additions": 22, "deletions": 22, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Ffma4intrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Ffma4intrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Ffma4intrin.h?ref=89509419968e2be6c7880a97968f07fab6b0e3b2", "patch": "@@ -64,73 +64,73 @@ extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artif\n _mm_msub_ps (__m128 __A, __m128 __B, __m128 __C)\n \n {\n-  return (__m128) __builtin_ia32_vfmsubps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+  return (__m128) __builtin_ia32_vfmaddps ((__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);\n }\n \n extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_msub_pd (__m128d __A, __m128d __B, __m128d __C)\n {\n-  return (__m128d) __builtin_ia32_vfmsubpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+  return (__m128d) __builtin_ia32_vfmaddpd ((__v2df)__A, (__v2df)__B, -(__v2df)__C);\n }\n \n extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_msub_ss (__m128 __A, __m128 __B, __m128 __C)\n {\n-  return (__m128) __builtin_ia32_vfmsubss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+  return (__m128) __builtin_ia32_vfmaddss ((__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);\n }\n \n extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_msub_sd (__m128d __A, __m128d __B, __m128d __C)\n {\n-  return (__m128d) __builtin_ia32_vfmsubsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+  return (__m128d) __builtin_ia32_vfmaddsd ((__v2df)__A, (__v2df)__B, -(__v2df)__C);\n }\n \n extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmacc_ps (__m128 __A, __m128 __B, __m128 __C)\n {\n-  return (__m128) __builtin_ia32_vfnmaddps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+  return (__m128) __builtin_ia32_vfmaddps (-(__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n }\n \n extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmacc_pd (__m128d __A, __m128d __B, __m128d __C)\n {\n-  return (__m128d) __builtin_ia32_vfnmaddpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+  return (__m128d) __builtin_ia32_vfmaddpd (-(__v2df)__A, (__v2df)__B, (__v2df)__C);\n }\n \n extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmacc_ss (__m128 __A, __m128 __B, __m128 __C)\n {\n-  return (__m128) __builtin_ia32_vfnmaddss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+  return (__m128) __builtin_ia32_vfmaddss (-(__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n }\n \n extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmacc_sd (__m128d __A, __m128d __B, __m128d __C)\n {\n-  return (__m128d) __builtin_ia32_vfnmaddsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+  return (__m128d) __builtin_ia32_vfmaddsd (-(__v2df)__A, (__v2df)__B, (__v2df)__C);\n }\n \n extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmsub_ps (__m128 __A, __m128 __B, __m128 __C)\n {\n-  return (__m128) __builtin_ia32_vfnmsubps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+  return (__m128) __builtin_ia32_vfmaddps (-(__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);\n }\n \n extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmsub_pd (__m128d __A, __m128d __B, __m128d __C)\n {\n-  return (__m128d) __builtin_ia32_vfnmsubpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+  return (__m128d) __builtin_ia32_vfmaddpd (-(__v2df)__A, (__v2df)__B, -(__v2df)__C);\n }\n \n extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmsub_ss (__m128 __A, __m128 __B, __m128 __C)\n {\n-  return (__m128) __builtin_ia32_vfnmsubss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+  return (__m128) __builtin_ia32_vfmaddss (-(__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);\n }\n \n extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_nmsub_sd (__m128d __A, __m128d __B, __m128d __C)\n {\n-  return (__m128d) __builtin_ia32_vfnmsubsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+  return (__m128d) __builtin_ia32_vfmaddsd (-(__v2df)__A, (__v2df)__B, -(__v2df)__C);\n }\n \n extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n@@ -148,13 +148,13 @@ _mm_maddsub_pd (__m128d __A, __m128d __B, __m128d __C)\n extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_msubadd_ps (__m128 __A, __m128 __B, __m128 __C)\n {\n-  return (__m128) __builtin_ia32_vfmsubaddps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);\n+  return (__m128) __builtin_ia32_vfmaddsubps ((__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);\n }\n \n extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_msubadd_pd (__m128d __A, __m128d __B, __m128d __C)\n {\n-  return (__m128d) __builtin_ia32_vfmsubaddpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);\n+  return (__m128d) __builtin_ia32_vfmaddsubpd ((__v2df)__A, (__v2df)__B, -(__v2df)__C);\n }\n \n /* 256b Floating point multiply/add type instructions.  */\n@@ -174,37 +174,37 @@ extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artif\n _mm256_msub_ps (__m256 __A, __m256 __B, __m256 __C)\n \n {\n-  return (__m256) __builtin_ia32_vfmsubps256 ((__v8sf)__A, (__v8sf)__B, (__v8sf)__C);\n+  return (__m256) __builtin_ia32_vfmaddps256 ((__v8sf)__A, (__v8sf)__B, -(__v8sf)__C);\n }\n \n extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm256_msub_pd (__m256d __A, __m256d __B, __m256d __C)\n {\n-  return (__m256d) __builtin_ia32_vfmsubpd256 ((__v4df)__A, (__v4df)__B, (__v4df)__C);\n+  return (__m256d) __builtin_ia32_vfmaddpd256 ((__v4df)__A, (__v4df)__B, -(__v4df)__C);\n }\n \n extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm256_nmacc_ps (__m256 __A, __m256 __B, __m256 __C)\n {\n-  return (__m256) __builtin_ia32_vfnmaddps256 ((__v8sf)__A, (__v8sf)__B, (__v8sf)__C);\n+  return (__m256) __builtin_ia32_vfmaddps256 (-(__v8sf)__A, (__v8sf)__B, (__v8sf)__C);\n }\n \n extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm256_nmacc_pd (__m256d __A, __m256d __B, __m256d __C)\n {\n-  return (__m256d) __builtin_ia32_vfnmaddpd256 ((__v4df)__A, (__v4df)__B, (__v4df)__C);\n+  return (__m256d) __builtin_ia32_vfmaddpd256 (-(__v4df)__A, (__v4df)__B, (__v4df)__C);\n }\n \n extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm256_nmsub_ps (__m256 __A, __m256 __B, __m256 __C)\n {\n-  return (__m256) __builtin_ia32_vfnmsubps256 ((__v8sf)__A, (__v8sf)__B, (__v8sf)__C);\n+  return (__m256) __builtin_ia32_vfmaddps256 (-(__v8sf)__A, (__v8sf)__B, -(__v8sf)__C);\n }\n \n extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm256_nmsub_pd (__m256d __A, __m256d __B, __m256d __C)\n {\n-  return (__m256d) __builtin_ia32_vfnmsubpd256 ((__v4df)__A, (__v4df)__B, (__v4df)__C);\n+  return (__m256d) __builtin_ia32_vfmaddpd256 (-(__v4df)__A, (__v4df)__B, -(__v4df)__C);\n }\n \n extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n@@ -222,13 +222,13 @@ _mm256_maddsub_pd (__m256d __A, __m256d __B, __m256d __C)\n extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm256_msubadd_ps (__m256 __A, __m256 __B, __m256 __C)\n {\n-  return (__m256) __builtin_ia32_vfmsubaddps256 ((__v8sf)__A, (__v8sf)__B, (__v8sf)__C);\n+  return (__m256) __builtin_ia32_vfmaddsubps256 ((__v8sf)__A, (__v8sf)__B, -(__v8sf)__C);\n }\n \n extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm256_msubadd_pd (__m256d __A, __m256d __B, __m256d __C)\n {\n-  return (__m256d) __builtin_ia32_vfmsubaddpd256 ((__v4df)__A, (__v4df)__B, (__v4df)__C);\n+  return (__m256d) __builtin_ia32_vfmaddsubpd256 ((__v4df)__A, (__v4df)__B, -(__v4df)__C);\n }\n \n #endif"}, {"sha": "7da2cfb6841e9a5b05513f5e4992be7d7d456991", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 16, "deletions": 63, "changes": 79, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=89509419968e2be6c7880a97968f07fab6b0e3b2", "patch": "@@ -22769,34 +22769,12 @@ enum ix86_builtins\n   IX86_BUILTIN_VFMADDSD,\n   IX86_BUILTIN_VFMADDPS,\n   IX86_BUILTIN_VFMADDPD,\n-  IX86_BUILTIN_VFMSUBSS,\n-  IX86_BUILTIN_VFMSUBSD,\n-  IX86_BUILTIN_VFMSUBPS,\n-  IX86_BUILTIN_VFMSUBPD,\n-  IX86_BUILTIN_VFMADDSUBPS,\n-  IX86_BUILTIN_VFMADDSUBPD,\n-  IX86_BUILTIN_VFMSUBADDPS,\n-  IX86_BUILTIN_VFMSUBADDPD,\n-  IX86_BUILTIN_VFNMADDSS,\n-  IX86_BUILTIN_VFNMADDSD,\n-  IX86_BUILTIN_VFNMADDPS,\n-  IX86_BUILTIN_VFNMADDPD,\n-  IX86_BUILTIN_VFNMSUBSS,\n-  IX86_BUILTIN_VFNMSUBSD,\n-  IX86_BUILTIN_VFNMSUBPS,\n-  IX86_BUILTIN_VFNMSUBPD,\n   IX86_BUILTIN_VFMADDPS256,\n   IX86_BUILTIN_VFMADDPD256,\n-  IX86_BUILTIN_VFMSUBPS256,\n-  IX86_BUILTIN_VFMSUBPD256,\n+  IX86_BUILTIN_VFMADDSUBPS,\n+  IX86_BUILTIN_VFMADDSUBPD,\n   IX86_BUILTIN_VFMADDSUBPS256,\n   IX86_BUILTIN_VFMADDSUBPD256,\n-  IX86_BUILTIN_VFMSUBADDPS256,\n-  IX86_BUILTIN_VFMSUBADDPD256,\n-  IX86_BUILTIN_VFNMADDPS256,\n-  IX86_BUILTIN_VFNMADDPD256,\n-  IX86_BUILTIN_VFNMSUBPS256,\n-  IX86_BUILTIN_VFNMSUBPD256,\n \n   IX86_BUILTIN_VPCMOV,\n   IX86_BUILTIN_VPCMOV_V2DI,\n@@ -23953,43 +23931,18 @@ static const struct builtin_description bdesc_args[] =\n \n static const struct builtin_description bdesc_multi_arg[] =\n {\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfmaddv4sf4,     \"__builtin_ia32_vfmaddss\",    IX86_BUILTIN_VFMADDSS,    UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfmaddv2df4,     \"__builtin_ia32_vfmaddsd\",    IX86_BUILTIN_VFMADDSD,    UNKNOWN,      (int)MULTI_ARG_3_DF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddv4sf4,       \"__builtin_ia32_vfmaddps\",    IX86_BUILTIN_VFMADDPS,    UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddv2df4,       \"__builtin_ia32_vfmaddpd\",    IX86_BUILTIN_VFMADDPD,    UNKNOWN,      (int)MULTI_ARG_3_DF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfmsubv4sf4,     \"__builtin_ia32_vfmsubss\",    IX86_BUILTIN_VFMSUBSS,    UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfmsubv2df4,     \"__builtin_ia32_vfmsubsd\",    IX86_BUILTIN_VFMSUBSD,    UNKNOWN,      (int)MULTI_ARG_3_DF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubv4sf4,       \"__builtin_ia32_vfmsubps\",    IX86_BUILTIN_VFMSUBPS,    UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubv2df4,       \"__builtin_ia32_vfmsubpd\",    IX86_BUILTIN_VFMSUBPD,    UNKNOWN,      (int)MULTI_ARG_3_DF },\n-\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfnmaddv4sf4,    \"__builtin_ia32_vfnmaddss\",   IX86_BUILTIN_VFNMADDSS,   UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfnmaddv2df4,    \"__builtin_ia32_vfnmaddsd\",   IX86_BUILTIN_VFNMADDSD,   UNKNOWN,      (int)MULTI_ARG_3_DF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmaddv4sf4,      \"__builtin_ia32_vfnmaddps\",   IX86_BUILTIN_VFNMADDPS,   UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmaddv2df4,      \"__builtin_ia32_vfnmaddpd\",   IX86_BUILTIN_VFNMADDPD,   UNKNOWN,      (int)MULTI_ARG_3_DF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfnmsubv4sf4,    \"__builtin_ia32_vfnmsubss\",   IX86_BUILTIN_VFNMSUBSS,   UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfnmsubv2df4,    \"__builtin_ia32_vfnmsubsd\",   IX86_BUILTIN_VFNMSUBSD,   UNKNOWN,      (int)MULTI_ARG_3_DF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmsubv4sf4,      \"__builtin_ia32_vfnmsubps\",   IX86_BUILTIN_VFNMSUBPS,   UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmsubv2df4,      \"__builtin_ia32_vfnmsubpd\",   IX86_BUILTIN_VFNMSUBPD,   UNKNOWN,      (int)MULTI_ARG_3_DF },\n-\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsubv4sf4,\t   \"__builtin_ia32_vfmaddsubps\", IX86_BUILTIN_VFMADDSUBPS,    UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsubv2df4,\t   \"__builtin_ia32_vfmaddsubpd\", IX86_BUILTIN_VFMADDSUBPD,    UNKNOWN,      (int)MULTI_ARG_3_DF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubaddv4sf4,\t   \"__builtin_ia32_vfmsubaddps\", IX86_BUILTIN_VFMSUBADDPS,    UNKNOWN,      (int)MULTI_ARG_3_SF },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubaddv2df4,\t   \"__builtin_ia32_vfmsubaddpd\", IX86_BUILTIN_VFMSUBADDPD,    UNKNOWN,      (int)MULTI_ARG_3_DF },\n-\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddv8sf4256,       \"__builtin_ia32_vfmaddps256\",    IX86_BUILTIN_VFMADDPS256,    UNKNOWN,      (int)MULTI_ARG_3_SF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddv4df4256,       \"__builtin_ia32_vfmaddpd256\",    IX86_BUILTIN_VFMADDPD256,    UNKNOWN,      (int)MULTI_ARG_3_DF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubv8sf4256,       \"__builtin_ia32_vfmsubps256\",    IX86_BUILTIN_VFMSUBPS256,    UNKNOWN,      (int)MULTI_ARG_3_SF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubv4df4256,       \"__builtin_ia32_vfmsubpd256\",    IX86_BUILTIN_VFMSUBPD256,    UNKNOWN,      (int)MULTI_ARG_3_DF2 },\n-\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmaddv8sf4256,      \"__builtin_ia32_vfnmaddps256\",   IX86_BUILTIN_VFNMADDPS256,   UNKNOWN,      (int)MULTI_ARG_3_SF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmaddv4df4256,      \"__builtin_ia32_vfnmaddpd256\",   IX86_BUILTIN_VFNMADDPD256,   UNKNOWN,      (int)MULTI_ARG_3_DF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmsubv8sf4256,      \"__builtin_ia32_vfnmsubps256\",   IX86_BUILTIN_VFNMSUBPS256,   UNKNOWN,      (int)MULTI_ARG_3_SF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fnmsubv4df4256,      \"__builtin_ia32_vfnmsubpd256\",   IX86_BUILTIN_VFNMSUBPD256,   UNKNOWN,      (int)MULTI_ARG_3_DF2 },\n-\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsubv8sf4,\t   \"__builtin_ia32_vfmaddsubps256\", IX86_BUILTIN_VFMADDSUBPS256,    UNKNOWN,      (int)MULTI_ARG_3_SF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsubv4df4,\t   \"__builtin_ia32_vfmaddsubpd256\", IX86_BUILTIN_VFMADDSUBPD256,    UNKNOWN,      (int)MULTI_ARG_3_DF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubaddv8sf4,\t   \"__builtin_ia32_vfmsubaddps256\", IX86_BUILTIN_VFMSUBADDPS256,    UNKNOWN,      (int)MULTI_ARG_3_SF2 },\n-  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmsubaddv4df4,\t   \"__builtin_ia32_vfmsubaddpd256\", IX86_BUILTIN_VFMSUBADDPD256,    UNKNOWN,      (int)MULTI_ARG_3_DF2 },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfmadd_v4sf,     \"__builtin_ia32_vfmaddss\",    IX86_BUILTIN_VFMADDSS,    UNKNOWN,      (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_vmfmadd_v2df,     \"__builtin_ia32_vfmaddsd\",    IX86_BUILTIN_VFMADDSD,    UNKNOWN,      (int)MULTI_ARG_3_DF },\n+\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fmav4sf4,               \"__builtin_ia32_vfmaddps\",    IX86_BUILTIN_VFMADDPS,    UNKNOWN,   (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fmav2df4,               \"__builtin_ia32_vfmaddpd\",    IX86_BUILTIN_VFMADDPD,    UNKNOWN,   (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fmav8sf4,               \"__builtin_ia32_vfmaddps256\", IX86_BUILTIN_VFMADDPS256, UNKNOWN,   (int)MULTI_ARG_3_SF2 },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fmav4df4,               \"__builtin_ia32_vfmaddpd256\", IX86_BUILTIN_VFMADDPD256, UNKNOWN,   (int)MULTI_ARG_3_DF2 },\n+\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsub_v4sf,\t   \"__builtin_ia32_vfmaddsubps\", IX86_BUILTIN_VFMADDSUBPS,        UNKNOWN,  (int)MULTI_ARG_3_SF },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsub_v2df,\t   \"__builtin_ia32_vfmaddsubpd\", IX86_BUILTIN_VFMADDSUBPD,        UNKNOWN,  (int)MULTI_ARG_3_DF },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsub_v8sf,\t   \"__builtin_ia32_vfmaddsubps256\", IX86_BUILTIN_VFMADDSUBPS256,  UNKNOWN,  (int)MULTI_ARG_3_SF2 },\n+  { OPTION_MASK_ISA_FMA4, CODE_FOR_fma4i_fmaddsub_v4df,\t   \"__builtin_ia32_vfmaddsubpd256\", IX86_BUILTIN_VFMADDSUBPD256,  UNKNOWN,  (int)MULTI_ARG_3_DF2 },\n \n   { OPTION_MASK_ISA_XOP, CODE_FOR_xop_pcmov_v2di,        \"__builtin_ia32_vpcmov\",      IX86_BUILTIN_VPCMOV,\t UNKNOWN,      (int)MULTI_ARG_3_DI },\n   { OPTION_MASK_ISA_XOP, CODE_FOR_xop_pcmov_v2di,        \"__builtin_ia32_vpcmov_v2di\", IX86_BUILTIN_VPCMOV_V2DI, UNKNOWN,      (int)MULTI_ARG_3_DI },\n@@ -24043,8 +23996,8 @@ static const struct builtin_description bdesc_multi_arg[] =\n   { OPTION_MASK_ISA_XOP, CODE_FOR_xop_vmfrczv2df2,       \"__builtin_ia32_vfrczsd\",     IX86_BUILTIN_VFRCZSD,     UNKNOWN,      (int)MULTI_ARG_2_DF },\n   { OPTION_MASK_ISA_XOP, CODE_FOR_xop_frczv4sf2,         \"__builtin_ia32_vfrczps\",     IX86_BUILTIN_VFRCZPS,     UNKNOWN,      (int)MULTI_ARG_1_SF },\n   { OPTION_MASK_ISA_XOP, CODE_FOR_xop_frczv2df2,         \"__builtin_ia32_vfrczpd\",     IX86_BUILTIN_VFRCZPD,     UNKNOWN,      (int)MULTI_ARG_1_DF },\n-  { OPTION_MASK_ISA_XOP, CODE_FOR_xop_frczv8sf2256,         \"__builtin_ia32_vfrczps256\",  IX86_BUILTIN_VFRCZPS256,  UNKNOWN,      (int)MULTI_ARG_1_SF2 },\n-  { OPTION_MASK_ISA_XOP, CODE_FOR_xop_frczv4df2256,         \"__builtin_ia32_vfrczpd256\",  IX86_BUILTIN_VFRCZPD256,  UNKNOWN,      (int)MULTI_ARG_1_DF2 },\n+  { OPTION_MASK_ISA_XOP, CODE_FOR_xop_frczv8sf2,         \"__builtin_ia32_vfrczps256\",  IX86_BUILTIN_VFRCZPS256,  UNKNOWN,      (int)MULTI_ARG_1_SF2 },\n+  { OPTION_MASK_ISA_XOP, CODE_FOR_xop_frczv4df2,         \"__builtin_ia32_vfrczpd256\",  IX86_BUILTIN_VFRCZPD256,  UNKNOWN,      (int)MULTI_ARG_1_DF2 },\n \n   { OPTION_MASK_ISA_XOP, CODE_FOR_xop_phaddbw,           \"__builtin_ia32_vphaddbw\",    IX86_BUILTIN_VPHADDBW,    UNKNOWN,      (int)MULTI_ARG_1_QI_HI },\n   { OPTION_MASK_ISA_XOP, CODE_FOR_xop_phaddbd,           \"__builtin_ia32_vphaddbd\",    IX86_BUILTIN_VPHADDBD,    UNKNOWN,      (int)MULTI_ARG_1_QI_SI },"}, {"sha": "ae527466b5a90a169f168ef6a770ca4e0f318246", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=89509419968e2be6c7880a97968f07fab6b0e3b2", "patch": "@@ -199,9 +199,7 @@\n   UNSPEC_PCMPISTR\n \n   ;; For FMA4 support\n-  UNSPEC_FMA4_INTRINSIC\n-  UNSPEC_FMA4_FMADDSUB\n-  UNSPEC_FMA4_FMSUBADD\n+  UNSPEC_FMADDSUB\n   UNSPEC_XOP_UNSIGNED_CMP\n   UNSPEC_XOP_TRUEFALSE\n   UNSPEC_XOP_PERMUTE"}, {"sha": "d6e1f121d1dfe49c1a44490029a1e016d6180584", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 177, "deletions": 635, "changes": 812, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/89509419968e2be6c7880a97968f07fab6b0e3b2/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=89509419968e2be6c7880a97968f07fab6b0e3b2", "patch": "@@ -55,7 +55,6 @@\n (define_mode_iterator SSEMODE248 [V8HI V4SI V2DI])\n (define_mode_iterator SSEMODE1248 [V16QI V8HI V4SI V2DI])\n (define_mode_iterator SSEMODEF4 [SF DF V4SF V2DF])\n-(define_mode_iterator FMA4MODEF4 [V8SF V4DF])\n (define_mode_iterator SSEMODEF2P [V4SF V2DF])\n \n (define_mode_iterator AVX256MODEF2P [V8SF V4DF])\n@@ -70,6 +69,8 @@\n (define_mode_iterator AVXMODEDCVTDQ2PS [V4SF V8SF])\n (define_mode_iterator AVXMODEDCVTPS2DQ [V4SI V8SI])\n \n+(define_mode_iterator FMAMODE [SF DF V4SF V2DF V8SF V4DF])\n+\n ;; Int-float size matches\n (define_mode_iterator SSEMODE4S [V4SF V4SI])\n (define_mode_iterator SSEMODE2D [V2DF V2DI])\n@@ -1767,698 +1768,237 @@\n ;;\t(set (reg2) (mult (reg1) (mem (addr2))))\n ;;\t(set (reg3) (plus (reg2) (mem (addr3))))\n \n-(define_insn \"fma4_fmadd<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(plus:FMA4MODEF4\n-\t (mult:FMA4MODEF4\n-\t  (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t  (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\")))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n+;; Intrinsic FMA operations.\n+\n+(define_expand \"fma<mode>4\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\")\n+\t(fma:FMAMODE\n+\t  (match_operand:FMAMODE 1 \"nonimmediate_operand\")\n+\t  (match_operand:FMAMODE 2 \"nonimmediate_operand\")\n+\t  (match_operand:FMAMODE 3 \"nonimmediate_operand\")))]\n+  \"TARGET_FMA4\"\n+  \"\")\n+\n+(define_insn \"*fma4i_fmadd_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(fma:FMAMODE\n+\t  (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\")\n+\t  (match_operand:FMAMODE 2 \"nonimmediate_operand\" \" x,m\")\n+\t  (match_operand:FMAMODE 3 \"nonimmediate_operand\" \"xm,x\")))]\n+  \"TARGET_FMA4\"\n   \"vfmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-;; Floating multiply and subtract.\n-(define_insn \"fma4_fmsub<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(minus:FMA4MODEF4\n-\t (mult:FMA4MODEF4\n-\t  (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t  (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\")))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n+(define_insn \"*fma4i_fmsub_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(fma:FMAMODE\n+\t  (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\")\n+\t  (match_operand:FMAMODE 2 \"nonimmediate_operand\" \" x,m\")\n+\t  (neg:FMAMODE\n+\t    (match_operand:FMAMODE 3 \"nonimmediate_operand\" \"xm,x\"))))]\n+  \"TARGET_FMA4\"\n   \"vfmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-;; Floating point negative multiply and add.\n-;; Rewrite (- (a * b) + c) into the canonical form: c - (a * b).\n-(define_insn \"fma4_fnmadd<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(minus:FMA4MODEF4\n-\t (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\")\n-\t (mult:FMA4MODEF4\n-\t  (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t  (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\"))))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n+(define_insn \"*fma4i_fnmadd_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(fma:FMAMODE\n+\t  (neg:FMAMODE\n+\t    (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\"))\n+\t  (match_operand:FMAMODE   2 \"nonimmediate_operand\" \" x,m\")\n+\t  (match_operand:FMAMODE   3 \"nonimmediate_operand\" \"xm,x\")))]\n+  \"TARGET_FMA4\"\n   \"vfnmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-;; Floating point negative multiply and subtract.\n-(define_insn \"fma4_fnmsub<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(minus:FMA4MODEF4\n-\t (mult:FMA4MODEF4\n-\t  (neg:FMA4MODEF4\n-\t   (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\"))\n-\t  (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\")))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n+(define_insn \"*fma4i_fnmsub_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(fma:FMAMODE\n+\t  (neg:FMAMODE\n+\t    (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\"))\n+\t  (match_operand:FMAMODE   2 \"nonimmediate_operand\" \" x,m\")\n+\t  (neg:FMAMODE\n+\t    (match_operand:FMAMODE 3 \"nonimmediate_operand\" \"xm,x\"))))]\n+  \"TARGET_FMA4\"\n   \"vfnmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"fma4_fmadd<mode>4\"\n-  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x\")\n-\t(plus:SSEMODEF4\n-\t (mult:SSEMODEF4\n-\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x\")))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n+;; Scalar versions of the above.  Unlike ADDSS et al, these write the\n+;; entire destination register, with the high-order elements zeroed.\n+\n+(define_expand \"fma4i_vmfmadd_<mode>\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\")\n+\t(vec_merge:SSEMODEF2P\n+\t  (fma:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\")\n+\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\")\n+\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\"))\n+\t  (match_dup 4)\n+\t  (const_int 1)))]\n+  \"TARGET_FMA4\"\n+{\n+  operands[4] = CONST0_RTX (<MODE>mode);\n+})\n \n-;; For the scalar operations, use operand1 for the upper words that aren't\n-;; modified, so restrict the forms that are generated.\n-;; Scalar version of fmadd.\n-(define_insn \"fma4_vmfmadd<mode>4\"\n+(define_insn \"*fma4i_vmfmadd_<mode>\"\n   [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n \t(vec_merge:SSEMODEF2P\n-\t (plus:SSEMODEF2P\n-\t  (mult:SSEMODEF2P\n-\t   (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t (match_dup 0)\n-\t (const_int 1)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n+\t  (fma:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n+\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \" x,m\")\n+\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n+\t  (match_operand:SSEMODEF2P 4 \"const0_operand\" \"\")\n+\t  (const_int 1)))]\n+  \"TARGET_FMA4\"\n   \"vfmadd<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-;; Floating multiply and subtract.\n-;; Allow two memory operands the same as fmadd.\n-(define_insn \"fma4_fmsub<mode>4\"\n-  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x\")\n-\t(minus:SSEMODEF4\n-\t (mult:SSEMODEF4\n-\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x\")))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n-\n-;; For the scalar operations, use operand1 for the upper words that aren't\n-;; modified, so restrict the forms that are generated.\n-;; Scalar version of fmsub.\n-(define_insn \"fma4_vmfmsub<mode>4\"\n+(define_insn \"*fma4i_vmfmsub_<mode>\"\n   [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n \t(vec_merge:SSEMODEF2P\n-\t (minus:SSEMODEF2P\n-\t  (mult:SSEMODEF2P\n-\t   (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t (match_dup 0)\n-\t (const_int 1)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n+\t  (fma:SSEMODEF2P\n+\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n+\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \" x,m\")\n+\t    (neg:SSEMODEF2P\n+\t      (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\")))\n+\t  (match_operand:SSEMODEF2P 4 \"const0_operand\" \"\")\n+\t  (const_int 1)))]\n+  \"TARGET_FMA4\"\n   \"vfmsub<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-;; Floating point negative multiply and add.\n-;; Rewrite (- (a * b) + c) into the canonical form: c - (a * b).\n-(define_insn \"fma4_fnmadd<mode>4\"\n-  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x\")\n-\t(minus:SSEMODEF4\n-\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x\")\n-\t (mult:SSEMODEF4\n-\t  (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,m\"))))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfnmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n-\n-;; For the scalar operations, use operand1 for the upper words that aren't\n-;; modified, so restrict the forms that are generated.\n-;; Scalar version of fnmadd.\n-(define_insn \"fma4_vmfnmadd<mode>4\"\n+(define_insn \"*fma4i_vmfnmadd_<mode>\"\n   [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n \t(vec_merge:SSEMODEF2P\n-\t (minus:SSEMODEF2P\n-\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\")\n-\t  (mult:SSEMODEF2P\n-\t   (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\")))\n-\t (match_dup 0)\n-\t (const_int 1)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n+\t  (fma:SSEMODEF2P\n+\t    (neg:SSEMODEF2P\n+\t      (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\"))\n+\t    (match_operand:SSEMODEF2P   2 \"nonimmediate_operand\" \" x,m\")\n+\t    (match_operand:SSEMODEF2P   3 \"nonimmediate_operand\" \"xm,x\"))\n+\t  (match_operand:SSEMODEF2P 4 \"const0_operand\" \"\")\n+\t  (const_int 1)))]\n+  \"TARGET_FMA4\"\n   \"vfnmadd<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-;; Floating point negative multiply and subtract.\n-;; Rewrite (- (a * b) - c) into the canonical form: ((-a) * b) - c.\n-(define_insn \"fma4_fnmsub<mode>4\"\n-  [(set (match_operand:SSEMODEF4 0 \"register_operand\" \"=x,x\")\n-\t(minus:SSEMODEF4\n-\t (mult:SSEMODEF4\n-\t  (neg:SSEMODEF4\n-\t   (match_operand:SSEMODEF4 1 \"nonimmediate_operand\" \"%x,x\"))\n-\t  (match_operand:SSEMODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t (match_operand:SSEMODEF4 3 \"nonimmediate_operand\" \"xm,x\")))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfnmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n-\n-;; For the scalar operations, use operand1 for the upper words that aren't\n-;; modified, so restrict the forms that are generated.\n-;; Scalar version of fnmsub.\n-(define_insn \"fma4_vmfnmsub<mode>4\"\n+(define_insn \"*fma4i_vmfnmsub_<mode>\"\n   [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n \t(vec_merge:SSEMODEF2P\n-\t (minus:SSEMODEF2P\n-\t  (mult:SSEMODEF2P\n-\t   (neg:SSEMODEF2P\n-\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\"))\n-\t   (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t  (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t (match_dup 0)\n-\t (const_int 1)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfnmsub<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n-\n-(define_insn \"fma4i_fmadd<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(unspec:FMA4MODEF4\n-\t [(plus:FMA4MODEF4\n-\t   (mult:FMA4MODEF4\n-\t    (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t    (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t   (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\"))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n-\n-(define_insn \"fma4i_fmsub<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(unspec:FMA4MODEF4\n-\t [(minus:FMA4MODEF4\n-\t   (mult:FMA4MODEF4\n-\t    (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t    (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t   (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\"))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n-\n-(define_insn \"fma4i_fnmadd<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(unspec:FMA4MODEF4\n-\t [(minus:FMA4MODEF4\n-\t   (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\")\n-\t   (mult:FMA4MODEF4\n-\t    (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\")\n-\t    (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\")))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n+\t  (fma:SSEMODEF2P\n+\t    (neg:SSEMODEF2P\n+\t      (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\"))\n+\t    (match_operand:SSEMODEF2P   2 \"nonimmediate_operand\" \" x,m\")\n+\t    (neg:SSEMODEF2P\n+\t      (match_operand:SSEMODEF2P   3 \"nonimmediate_operand\" \"xm,x\")))\n+\t  (match_operand:SSEMODEF2P 4 \"const0_operand\" \"\")\n+\t  (const_int 1)))]\n   \"TARGET_FMA4\"\n-  \"vfnmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  \"vfnmsub<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"fma4i_fnmsub<mode>4256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x,x\")\n-\t(unspec:FMA4MODEF4\n-\t [(minus:FMA4MODEF4\n-\t   (mult:FMA4MODEF4\n-\t    (neg:FMA4MODEF4\n-\t     (match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"%x,x\"))\n-\t    (match_operand:FMA4MODEF4 2 \"nonimmediate_operand\" \"x,m\"))\n-\t   (match_operand:FMA4MODEF4 3 \"nonimmediate_operand\" \"xm,x\"))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfnmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<MODE>\")])\n+;; Non-intrinsic versions, matched when fused-multiply-add is allowed.\n \n-(define_insn \"fma4i_fmadd<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(plus:SSEMODEF2P\n-\t   (mult:SSEMODEF2P\n-\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n+(define_insn \"*fma4_fmadd_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(plus:FMAMODE\n+\t (mult:FMAMODE\n+\t  (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\")\n+\t  (match_operand:FMAMODE 2 \"nonimmediate_operand\" \" x,m\"))\n+\t (match_operand:FMAMODE 3 \"nonimmediate_operand\"  \"xm,x\")))]\n+  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n   \"vfmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"fma4i_fmsub<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(minus:SSEMODEF2P\n-\t   (mult:SSEMODEF2P\n-\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n+;; Floating multiply and subtract.\n+(define_insn \"*fma4_fmsub_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(minus:FMAMODE\n+\t (mult:FMAMODE\n+\t  (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\")\n+\t  (match_operand:FMAMODE 2 \"nonimmediate_operand\" \" x,m\"))\n+\t (match_operand:FMAMODE 3 \"nonimmediate_operand\"  \"xm,x\")))]\n+  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n   \"vfmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"fma4i_fnmadd<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(minus:SSEMODEF2P\n-\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\")\n-\t   (mult:SSEMODEF2P\n-\t    (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\")))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n+;; Floating point negative multiply and add.\n+;; Rewrite (- (a * b) + c) into the canonical form: c - (a * b).\n+(define_insn \"*fma4_fnmadd_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(minus:FMAMODE\n+\t (match_operand:FMAMODE 3 \"nonimmediate_operand\"  \"xm,x\")\n+\t (mult:FMAMODE\n+\t  (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\")\n+\t  (match_operand:FMAMODE 2 \"nonimmediate_operand\" \" x,m\"))))]\n+  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n   \"vfnmadd<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"fma4i_fnmsub<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(minus:SSEMODEF2P\n-\t   (mult:SSEMODEF2P\n-\t    (neg:SSEMODEF2P\n-\t     (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\"))\n-\t    (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t   (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n+;; Floating point negative multiply and subtract.\n+(define_insn \"*fma4_fnmsub_<mode>\"\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x,x\")\n+\t(minus:FMAMODE\n+\t (mult:FMAMODE\n+\t  (neg:FMAMODE\n+\t   (match_operand:FMAMODE 1 \"nonimmediate_operand\" \"%x,x\"))\n+\t  (match_operand:FMAMODE 2 \"nonimmediate_operand\"  \" x,m\"))\n+\t (match_operand:FMAMODE 3 \"nonimmediate_operand\"   \"xm,x\")))]\n+  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n   \"vfnmsub<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-;; For the scalar operations, use operand1 for the upper words that aren't\n-;; modified, so restrict the forms that are accepted.\n-(define_insn \"fma4i_vmfmadd<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(vec_merge:SSEMODEF2P\n-\t   (plus:SSEMODEF2P\n-\t    (mult:SSEMODEF2P\n-\t     (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (match_dup 0)\n-\t   (const_int 1))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmadd<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<ssescalarmode>\")])\n-\n-(define_insn \"fma4i_vmfmsub<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(vec_merge:SSEMODEF2P\n-\t   (minus:SSEMODEF2P\n-\t    (mult:SSEMODEF2P\n-\t     (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (match_dup 0)\n-\t   (const_int 1))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmsub<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<ssescalarmode>\")])\n-\n-(define_insn \"fma4i_vmfnmadd<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(vec_merge:SSEMODEF2P\n-\t   (minus:SSEMODEF2P\n-\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\")\n-\t    (mult:SSEMODEF2P\n-\t     (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n-\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\")))\n-\t   (match_dup 0)\n-\t   (const_int 1))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfnmadd<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<ssescalarmode>\")])\n-\n-(define_insn \"fma4i_vmfnmsub<mode>4\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODEF2P\n-\t [(vec_merge:SSEMODEF2P\n-\t   (minus:SSEMODEF2P\n-\t    (mult:SSEMODEF2P\n-\t     (neg:SSEMODEF2P\n-\t      (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"%x,x\"))\n-\t     (match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:SSEMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (match_dup 0)\n-\t   (const_int 1))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfnmsub<ssescalarmodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"<ssescalarmode>\")])\n-\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n ;; FMA4 Parallel floating point multiply addsub and subadd operations.\n ;;\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn \"fma4_fmaddsubv8sf4\"\n-  [(set (match_operand:V8SF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V8SF\n-\t  (plus:V8SF\n-\t    (mult:V8SF\n-\t      (match_operand:V8SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V8SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V8SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V8SF\n-\t    (mult:V8SF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 170)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmaddsubps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V8SF\")])\n-\n-(define_insn \"fma4_fmaddsubv4df4\"\n-  [(set (match_operand:V4DF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V4DF\n-\t  (plus:V4DF\n-\t    (mult:V4DF\n-\t      (match_operand:V4DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V4DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V4DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V4DF\n-\t    (mult:V4DF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 10)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmaddsubpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4DF\")])\n-\n-(define_insn \"fma4_fmaddsubv4sf4\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V4SF\n-\t  (plus:V4SF\n-\t    (mult:V4SF\n-\t      (match_operand:V4SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V4SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V4SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V4SF\n-\t    (mult:V4SF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 10)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmaddsubps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4SF\")])\n-\n-(define_insn \"fma4_fmaddsubv2df4\"\n-  [(set (match_operand:V2DF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V2DF\n-\t  (plus:V2DF\n-\t    (mult:V2DF\n-\t      (match_operand:V2DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V2DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V2DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V2DF\n-\t    (mult:V2DF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 2)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmaddsubpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V2DF\")])\n-\n-(define_insn \"fma4_fmsubaddv8sf4\"\n-  [(set (match_operand:V8SF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V8SF\n-\t  (plus:V8SF\n-\t    (mult:V8SF\n-\t      (match_operand:V8SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V8SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V8SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V8SF\n-\t    (mult:V8SF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 85)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmsubaddps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V8SF\")])\n-\n-(define_insn \"fma4_fmsubaddv4df4\"\n-  [(set (match_operand:V4DF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V4DF\n-\t  (plus:V4DF\n-\t    (mult:V4DF\n-\t      (match_operand:V4DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V4DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V4DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V4DF\n-\t    (mult:V4DF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 5)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmsubaddpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4DF\")])\n-\n-(define_insn \"fma4_fmsubaddv4sf4\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V4SF\n-\t  (plus:V4SF\n-\t    (mult:V4SF\n-\t      (match_operand:V4SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V4SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V4SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V4SF\n-\t    (mult:V4SF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 5)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmsubaddps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4SF\")])\n-\n-(define_insn \"fma4_fmsubaddv2df4\"\n-  [(set (match_operand:V2DF 0 \"register_operand\" \"=x,x\")\n-\t(vec_merge:V2DF\n-\t  (plus:V2DF\n-\t    (mult:V2DF\n-\t      (match_operand:V2DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t      (match_operand:V2DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t    (match_operand:V2DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t  (minus:V2DF\n-\t    (mult:V2DF\n-\t      (match_dup 1)\n-\t      (match_dup 2))\n-\t    (match_dup 3))\n-\t  (const_int 1)))]\n-  \"TARGET_FMA4 && TARGET_FUSED_MADD\"\n-  \"vfmsubaddpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V2DF\")])\n+;; It would be possible to represent these without the UNSPEC as\n+;;\n+;; (vec_merge\n+;;   (fma op1 op2 op3)\n+;;   (fma op1 op2 (neg op3))\n+;;   (merge-const))\n+;;\n+;; But this doesn't seem useful in practice.\n \n-(define_insn \"fma4i_fmaddsubv8sf4\"\n-  [(set (match_operand:V8SF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V8SF\n-\t [(vec_merge:V8SF\n-\t   (plus:V8SF\n-\t     (mult:V8SF\n-\t       (match_operand:V8SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V8SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V8SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V8SF\n-\t     (mult:V8SF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 170))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n+(define_insn \"fma4i_fmaddsub_<mode>\"\n+  [(set (match_operand:AVXMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(unspec:AVXMODEF2P\n+\t  [(match_operand:AVXMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n+\t   (match_operand:AVXMODEF2P 2 \"nonimmediate_operand\" \" x,m\")\n+\t   (match_operand:AVXMODEF2P 3 \"nonimmediate_operand\" \"xm,x\")]\n+\t  UNSPEC_FMADDSUB))]\n   \"TARGET_FMA4\"\n   \"vfmaddsubps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"V8SF\")])\n \n-(define_insn \"fma4i_fmaddsubv4df4\"\n-  [(set (match_operand:V4DF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V4DF\n-\t [(vec_merge:V4DF\n-\t   (plus:V4DF\n-\t     (mult:V4DF\n-\t       (match_operand:V4DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V4DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V4DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V4DF\n-\t     (mult:V4DF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 10))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmaddsubpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4DF\")])\n-\n-(define_insn \"fma4i_fmaddsubv4sf4\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V4SF\n-\t [(vec_merge:V4SF\n-\t   (plus:V4SF\n-\t     (mult:V4SF\n-\t       (match_operand:V4SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V4SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V4SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V4SF\n-\t     (mult:V4SF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 10))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmaddsubps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4SF\")])\n-\n-(define_insn \"fma4i_fmaddsubv2df4\"\n-  [(set (match_operand:V2DF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V2DF\n-\t [(vec_merge:V2DF\n-\t   (plus:V2DF\n-\t     (mult:V2DF\n-\t       (match_operand:V2DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V2DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V2DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V2DF\n-\t     (mult:V2DF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 2))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmaddsubpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V2DF\")])\n-\n-(define_insn \"fma4i_fmsubaddv8sf4\"\n-  [(set (match_operand:V8SF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V8SF\n-\t [(vec_merge:V8SF\n-\t   (plus:V8SF\n-\t     (mult:V8SF\n-\t       (match_operand:V8SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V8SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V8SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V8SF\n-\t     (mult:V8SF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 85))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n+(define_insn \"*fma4i_fmsubadd_<mode>\"\n+  [(set (match_operand:AVXMODEF2P 0 \"register_operand\" \"=x,x\")\n+\t(unspec:AVXMODEF2P\n+\t  [(match_operand:AVXMODEF2P 1 \"nonimmediate_operand\" \"%x,x\")\n+\t   (match_operand:AVXMODEF2P 2 \"nonimmediate_operand\" \" x,m\")\n+\t   (neg:AVXMODEF2P\n+\t     (match_operand:AVXMODEF2P 3 \"nonimmediate_operand\" \"xm,x\"))]\n+\t  UNSPEC_FMADDSUB))]\n   \"TARGET_FMA4\"\n   \"vfmsubaddps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"V8SF\")])\n \n-(define_insn \"fma4i_fmsubaddv4df4\"\n-  [(set (match_operand:V4DF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V4DF\n-\t [(vec_merge:V4DF\n-\t   (plus:V4DF\n-\t     (mult:V4DF\n-\t       (match_operand:V4DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V4DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V4DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V4DF\n-\t     (mult:V4DF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 5))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmsubaddpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4DF\")])\n-\n-(define_insn \"fma4i_fmsubaddv4sf4\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V4SF\n-\t [(vec_merge:V4SF\n-\t   (plus:V4SF\n-\t     (mult:V4SF\n-\t       (match_operand:V4SF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V4SF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V4SF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V4SF\n-\t     (mult:V4SF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 5))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmsubaddps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V4SF\")])\n-\n-(define_insn \"fma4i_fmsubaddv2df4\"\n-  [(set (match_operand:V2DF 0 \"register_operand\" \"=x,x\")\n-\t(unspec:V2DF\n-\t [(vec_merge:V2DF\n-\t   (plus:V2DF\n-\t     (mult:V2DF\n-\t       (match_operand:V2DF 1 \"nonimmediate_operand\" \"%x,x\")\n-\t       (match_operand:V2DF 2 \"nonimmediate_operand\" \"x,m\"))\n-\t     (match_operand:V2DF 3 \"nonimmediate_operand\" \"xm,x\"))\n-\t   (minus:V2DF\n-\t     (mult:V2DF\n-\t       (match_dup 1)\n-\t       (match_dup 2))\n-\t     (match_dup 3))\n-\t   (const_int 1))]\n-\t UNSPEC_FMA4_INTRINSIC))]\n-  \"TARGET_FMA4\"\n-  \"vfmsubaddpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n-  [(set_attr \"type\" \"ssemuladd\")\n-   (set_attr \"mode\" \"V2DF\")])\n-\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n ;; Parallel single-precision floating point conversion operations\n@@ -11405,38 +10945,40 @@\n })\n \n ;; XOP FRCZ support\n-;; parallel insns\n (define_insn \"xop_frcz<mode>2\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n-\t(unspec:SSEMODEF2P\n-\t [(match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"xm\")]\n+  [(set (match_operand:FMAMODE 0 \"register_operand\" \"=x\")\n+\t(unspec:FMAMODE\n+\t [(match_operand:FMAMODE 1 \"nonimmediate_operand\" \"xm\")]\n \t UNSPEC_FRCZ))]\n   \"TARGET_XOP\"\n   \"vfrcz<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"ssecvt1\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n ;; scalar insns\n-(define_insn \"xop_vmfrcz<mode>2\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n+(define_expand \"xop_vmfrcz<mode>2\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\")\n \t(vec_merge:SSEMODEF2P\n \t  (unspec:SSEMODEF2P\n-\t   [(match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"xm\")]\n+\t   [(match_operand:SSEMODEF2P 1 \"nonimmediate_operand\")]\n \t   UNSPEC_FRCZ)\n-\t  (match_operand:SSEMODEF2P 1 \"register_operand\" \"0\")\n+\t  (match_dup 3)\n \t  (const_int 1)))]\n   \"TARGET_XOP\"\n-  \"vfrcz<ssescalarmodesuffix>\\t{%2, %0|%0, %2}\"\n-  [(set_attr \"type\" \"ssecvt1\")\n-   (set_attr \"mode\" \"<MODE>\")])\n+{\n+  operands[3] = CONST0_RTX (<MODE>mode);\n+})\n \n-(define_insn \"xop_frcz<mode>2256\"\n-  [(set (match_operand:FMA4MODEF4 0 \"register_operand\" \"=x\")\n-\t(unspec:FMA4MODEF4\n-\t [(match_operand:FMA4MODEF4 1 \"nonimmediate_operand\" \"xm\")]\n-\t UNSPEC_FRCZ))]\n+(define_insn \"*xop_vmfrcz_<mode>\"\n+  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"=x\")\n+\t(vec_merge:SSEMODEF2P\n+\t  (unspec:SSEMODEF2P\n+\t   [(match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"xm\")]\n+\t   UNSPEC_FRCZ)\n+\t  (match_operand:SSEMODEF2P 2 \"const0_operand\")\n+\t  (const_int 1)))]\n   \"TARGET_XOP\"\n-  \"vfrcz<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vfrcz<ssescalarmodesuffix>\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"ssecvt1\")\n    (set_attr \"mode\" \"<MODE>\")])\n "}]}