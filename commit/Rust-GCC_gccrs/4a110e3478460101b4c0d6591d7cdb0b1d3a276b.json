{"sha": "4a110e3478460101b4c0d6591d7cdb0b1d3a276b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NGExMTBlMzQ3ODQ2MDEwMWI0YzBkNjU5MWQ3Y2RiMGIxZDNhMjc2Yg==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-11-01T15:44:18Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-11-01T15:44:18Z"}, "message": "Make tree-ssa-dse.c:normalize_ref return a bool\n\nThis patch moves the check for an overlapping byte to normalize_ref\nfrom its callers, so that it's easier to convert to poly_ints later.\nIt's not really worth it on its own.\n\n2017-11-01  Richard Sandiford  <richard.sandiford@linaro.org>\n\ngcc/\n\t* tree-ssa-dse.c (normalize_ref): Check whether the ranges overlap\n\tand return false if not.\n\t(clear_bytes_written_by, live_bytes_read): Update accordingly.\n\nFrom-SVN: r254313", "tree": {"sha": "52aae78cf938c3b3a9d91213fc749f00eafc3720", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/52aae78cf938c3b3a9d91213fc749f00eafc3720"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4a110e3478460101b4c0d6591d7cdb0b1d3a276b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4a110e3478460101b4c0d6591d7cdb0b1d3a276b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4a110e3478460101b4c0d6591d7cdb0b1d3a276b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4a110e3478460101b4c0d6591d7cdb0b1d3a276b/comments", "author": null, "committer": null, "parents": [{"sha": "7fc53ba4f8a0cecb7288ae04e32dfb38af016f57", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7fc53ba4f8a0cecb7288ae04e32dfb38af016f57", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7fc53ba4f8a0cecb7288ae04e32dfb38af016f57"}], "stats": {"total": 54, "additions": 31, "deletions": 23}, "files": [{"sha": "799cca8ff77336ef11965ab41f46c9d797c4a4b5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4a110e3478460101b4c0d6591d7cdb0b1d3a276b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4a110e3478460101b4c0d6591d7cdb0b1d3a276b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4a110e3478460101b4c0d6591d7cdb0b1d3a276b", "patch": "@@ -1,3 +1,9 @@\n+2017-11-01  Richard Sandiford  <richard.sandiford@linaro.org>\n+\n+\t* tree-ssa-dse.c (normalize_ref): Check whether the ranges overlap\n+\tand return false if not.\n+\t(clear_bytes_written_by, live_bytes_read): Update accordingly.\n+\n 2017-11-01  Richard Sandiford  <richard.sandiford@linaro.org>\n \n \t* tree-ssa-alias.h (ranges_overlap_p): Return false if either"}, {"sha": "4036f7d64b365ad4013b643c44ce27c6a5718558", "filename": "gcc/tree-ssa-dse.c", "status": "modified", "additions": 25, "deletions": 23, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4a110e3478460101b4c0d6591d7cdb0b1d3a276b/gcc%2Ftree-ssa-dse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4a110e3478460101b4c0d6591d7cdb0b1d3a276b/gcc%2Ftree-ssa-dse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dse.c?ref=4a110e3478460101b4c0d6591d7cdb0b1d3a276b", "patch": "@@ -137,27 +137,34 @@ valid_ao_ref_for_dse (ao_ref *ref)\n \t  && (ref->size != -1));\n }\n \n-/* Normalize COPY (an ao_ref) relative to REF.  Essentially when we are\n-   done COPY will only refer bytes found within REF.\n+/* Try to normalize COPY (an ao_ref) relative to REF.  Essentially when we are\n+   done COPY will only refer bytes found within REF.  Return true if COPY\n+   is known to intersect at least one byte of REF.  */\n \n-   We have already verified that COPY intersects at least one\n-   byte with REF.  */\n-\n-static void\n+static bool\n normalize_ref (ao_ref *copy, ao_ref *ref)\n {\n   /* If COPY starts before REF, then reset the beginning of\n      COPY to match REF and decrease the size of COPY by the\n      number of bytes removed from COPY.  */\n   if (copy->offset < ref->offset)\n     {\n-      copy->size -= (ref->offset - copy->offset);\n+      HOST_WIDE_INT diff = ref->offset - copy->offset;\n+      if (copy->size <= diff)\n+\treturn false;\n+      copy->size -= diff;\n       copy->offset = ref->offset;\n     }\n \n+  HOST_WIDE_INT diff = copy->offset - ref->offset;\n+  if (ref->size <= diff)\n+    return false;\n+\n   /* If COPY extends beyond REF, chop off its size appropriately.  */\n-  if (copy->offset + copy->size > ref->offset + ref->size)\n-    copy->size -= (copy->offset + copy->size - (ref->offset + ref->size));\n+  HOST_WIDE_INT limit = ref->size - diff;\n+  if (copy->size > limit)\n+    copy->size = limit;\n+  return true;\n }\n \n /* Clear any bytes written by STMT from the bitmap LIVE_BYTES.  The base\n@@ -179,14 +186,10 @@ clear_bytes_written_by (sbitmap live_bytes, gimple *stmt, ao_ref *ref)\n   if (valid_ao_ref_for_dse (&write)\n       && operand_equal_p (write.base, ref->base, OEP_ADDRESS_OF)\n       && write.size == write.max_size\n-      && ((write.offset < ref->offset\n-\t   && write.offset + write.size > ref->offset)\n-\t  || (write.offset >= ref->offset\n-\t      && write.offset < ref->offset + ref->size)))\n+      && normalize_ref (&write, ref))\n     {\n-      normalize_ref (&write, ref);\n-      bitmap_clear_range (live_bytes,\n-\t\t\t  (write.offset - ref->offset) / BITS_PER_UNIT,\n+      HOST_WIDE_INT start = write.offset - ref->offset;\n+      bitmap_clear_range (live_bytes, start / BITS_PER_UNIT,\n \t\t\t  write.size / BITS_PER_UNIT);\n     }\n }\n@@ -480,21 +483,20 @@ live_bytes_read (ao_ref use_ref, ao_ref *ref, sbitmap live)\n {\n   /* We have already verified that USE_REF and REF hit the same object.\n      Now verify that there's actually an overlap between USE_REF and REF.  */\n-  if (ranges_overlap_p (use_ref.offset, use_ref.size, ref->offset, ref->size))\n+  if (normalize_ref (&use_ref, ref))\n     {\n-      normalize_ref (&use_ref, ref);\n+      HOST_WIDE_INT start = use_ref.offset - ref->offset;\n+      HOST_WIDE_INT size = use_ref.size;\n \n       /* If USE_REF covers all of REF, then it will hit one or more\n \t live bytes.   This avoids useless iteration over the bitmap\n \t below.  */\n-      if (use_ref.offset <= ref->offset\n-\t  && use_ref.offset + use_ref.size >= ref->offset + ref->size)\n+      if (start == 0 && size == ref->size)\n \treturn true;\n \n       /* Now check if any of the remaining bits in use_ref are set in LIVE.  */\n-      unsigned int start = (use_ref.offset - ref->offset) / BITS_PER_UNIT;\n-      unsigned int end = start + (use_ref.size / BITS_PER_UNIT) - 1;\n-      return bitmap_bit_in_range_p (live, start, end);\n+      return bitmap_bit_in_range_p (live, start / BITS_PER_UNIT,\n+\t\t\t\t    (start + size - 1) / BITS_PER_UNIT);\n     }\n   return true;\n }"}]}