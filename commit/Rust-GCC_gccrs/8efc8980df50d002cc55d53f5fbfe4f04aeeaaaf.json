{"sha": "8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OGVmYzg5ODBkZjUwZDAwMmNjNTVkNTNmNWZiZmU0ZjA0YWVlYWFhZg==", "commit": {"author": {"name": "Richard Sandiford", "email": "rsandifo@redhat.com", "date": "2004-03-19T09:59:00Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2004-03-19T09:59:00Z"}, "message": "expmed.c (choose_mult_variant, [...]): New, split from...\n\n\t* expmed.c (choose_mult_variant, expand_mult_const): New, split from...\n\t(expand_mult): ...here.\n\t(extract_high_half): New, split out from expand_mult_highpart.\n\t(expand_highpart_optab): Likewise.  Don't clobber target prematurely.\n\t(expand_highpart): Evaluate the cost of a shift/add sequence,\n\tthen see if any of the specialized optabs are cheaper.\n\nFrom-SVN: r79673", "tree": {"sha": "ad576e9549b11010530d0d219800ac5cce072fb5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ad576e9549b11010530d0d219800ac5cce072fb5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf/comments", "author": null, "committer": null, "parents": [{"sha": "d36d56001a298d89b6d69750cb6dfee4653aa2b8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d36d56001a298d89b6d69750cb6dfee4653aa2b8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d36d56001a298d89b6d69750cb6dfee4653aa2b8"}], "stats": {"total": 568, "additions": 304, "deletions": 264}, "files": [{"sha": "c8d87b7df69995dbe5efa8bbf61a21e937ef96a5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf", "patch": "@@ -1,3 +1,12 @@\n+2004-03-19  Richard Sandiford  <rsandifo@redhat.com>\n+\n+\t* expmed.c (choose_mult_variant, expand_mult_const): New, split from...\n+\t(expand_mult): ...here.\n+\t(extract_high_half): New, split out from expand_mult_highpart.\n+\t(expand_highpart_optab): Likewise.  Don't clobber target prematurely.\n+\t(expand_highpart): Evaluate the cost of a shift/add sequence,\n+\tthen see if any of the specialized optabs are cheaper.\n+\n 2004-03-18  Ian Lance Taylor  <ian@wasabisystems.com>\n \n \t* mklibgcc.in: Remove obsolete MAYBE_USE_COLLECT2."}, {"sha": "da0a9fe7f0dffd96724c96a2f42f8d1316624991", "filename": "gcc/expmed.c", "status": "modified", "additions": 295, "deletions": 264, "changes": 559, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=8efc8980df50d002cc55d53f5fbfe4f04aeeaaaf", "patch": "@@ -2149,11 +2149,24 @@ struct algorithm\n   char log[MAX_BITS_PER_WORD];\n };\n \n+/* Indicates the type of fixup needed after a constant multiplication.\n+   BASIC_VARIANT means no fixup is needed, NEGATE_VARIANT means that\n+   the result should be negated, and ADD_VARIANT means that the\n+   multiplicand should be added to the result.  */\n+enum mult_variant {basic_variant, negate_variant, add_variant};\n+\n static void synth_mult (struct algorithm *, unsigned HOST_WIDE_INT, int);\n+static bool choose_mult_variant (enum machine_mode, HOST_WIDE_INT,\n+\t\t\t\t struct algorithm *, enum mult_variant *);\n+static rtx expand_mult_const (enum machine_mode, rtx, HOST_WIDE_INT, rtx,\n+\t\t\t      const struct algorithm *, enum mult_variant);\n static unsigned HOST_WIDE_INT choose_multiplier (unsigned HOST_WIDE_INT, int,\n \t\t\t\t\t\t int, unsigned HOST_WIDE_INT *,\n \t\t\t\t\t\t int *, int *);\n static unsigned HOST_WIDE_INT invert_mod2n (unsigned HOST_WIDE_INT, int);\n+static rtx extract_high_half (enum machine_mode, rtx);\n+static rtx expand_mult_highpart_optab (enum machine_mode, rtx, rtx, rtx,\n+\t\t\t\t       int, int);\n /* Compute and return the best algorithm for multiplying by T.\n    The algorithm must cost less than cost_limit\n    If retval.cost >= COST_LIMIT, no algorithm was found and all\n@@ -2396,6 +2409,198 @@ synth_mult (struct algorithm *alg_out, unsigned HOST_WIDE_INT t,\n \t  alg_out->ops * sizeof *alg_out->log);\n }\n \f\n+/* Find the cheapeast way of multiplying a value of mode MODE by VAL.\n+   Try three variations:\n+\n+       - a shift/add sequence based on VAL itself\n+       - a shift/add sequence based on -VAL, followed by a negation\n+       - a shift/add sequence based on VAL - 1, followed by an addition.\n+\n+   Return true if the cheapest of these is better than register\n+   multiplication, describing the algorithm in *ALG and final\n+   fixup in *VARIANT.  */\n+\n+static bool\n+choose_mult_variant (enum machine_mode mode, HOST_WIDE_INT val,\n+\t\t     struct algorithm *alg, enum mult_variant *variant)\n+{\n+  int mult_cost;\n+  struct algorithm alg2;\n+  rtx reg;\n+\n+  reg = gen_rtx_REG (mode, FIRST_PSEUDO_REGISTER);\n+  mult_cost = rtx_cost (gen_rtx_MULT (mode, reg, GEN_INT (val)), SET);\n+  mult_cost = MIN (12 * add_cost, mult_cost);\n+\n+  *variant = basic_variant;\n+  synth_mult (alg, val, mult_cost);\n+\n+  /* This works only if the inverted value actually fits in an\n+     `unsigned int' */\n+  if (HOST_BITS_PER_INT >= GET_MODE_BITSIZE (mode))\n+    {\n+      synth_mult (&alg2, -val, MIN (alg->cost, mult_cost) - negate_cost);\n+      alg2.cost += negate_cost;\n+      if (alg2.cost < alg->cost)\n+\t*alg = alg2, *variant = negate_variant;\n+    }\n+\n+  /* This proves very useful for division-by-constant.  */\n+  synth_mult (&alg2, val - 1, MIN (alg->cost, mult_cost) - add_cost);\n+  alg2.cost += add_cost;\n+  if (alg2.cost < alg->cost)\n+    *alg = alg2, *variant = add_variant;\n+\n+  return alg->cost < mult_cost;\n+}\n+\n+/* A subroutine of expand_mult, used for constant multiplications.\n+   Multiply OP0 by VAL in mode MODE, storing the result in TARGET if\n+   convenient.  Use the shift/add sequence described by ALG and apply\n+   the final fixup specified by VARIANT.  */\n+\n+static rtx\n+expand_mult_const (enum machine_mode mode, rtx op0, HOST_WIDE_INT val,\n+\t\t   rtx target, const struct algorithm *alg,\n+\t\t   enum mult_variant variant)\n+{\n+  HOST_WIDE_INT val_so_far;\n+  rtx insn, accum, tem;\n+  int opno;\n+  enum machine_mode nmode;\n+\n+  /* op0 must be register to make mult_cost match the precomputed\n+     shiftadd_cost array.  */\n+  op0 = protect_from_queue (op0, 0);\n+\n+  /* Avoid referencing memory over and over.\n+     For speed, but also for correctness when mem is volatile.  */\n+  if (GET_CODE (op0) == MEM)\n+    op0 = force_reg (mode, op0);\n+\n+  /* ACCUM starts out either as OP0 or as a zero, depending on\n+     the first operation.  */\n+\n+  if (alg->op[0] == alg_zero)\n+    {\n+      accum = copy_to_mode_reg (mode, const0_rtx);\n+      val_so_far = 0;\n+    }\n+  else if (alg->op[0] == alg_m)\n+    {\n+      accum = copy_to_mode_reg (mode, op0);\n+      val_so_far = 1;\n+    }\n+  else\n+    abort ();\n+\n+  for (opno = 1; opno < alg->ops; opno++)\n+    {\n+      int log = alg->log[opno];\n+      int preserve = preserve_subexpressions_p ();\n+      rtx shift_subtarget = preserve ? 0 : accum;\n+      rtx add_target\n+\t= (opno == alg->ops - 1 && target != 0 && variant != add_variant\n+\t   && ! preserve)\n+\t  ? target : 0;\n+      rtx accum_target = preserve ? 0 : accum;\n+\n+      switch (alg->op[opno])\n+\t{\n+\tcase alg_shift:\n+\t  accum = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t\tbuild_int_2 (log, 0), NULL_RTX, 0);\n+\t  val_so_far <<= log;\n+\t  break;\n+\n+\tcase alg_add_t_m2:\n+\t  tem = expand_shift (LSHIFT_EXPR, mode, op0,\n+\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n+\t  accum = force_operand (gen_rtx_PLUS (mode, accum, tem),\n+\t\t\t\t add_target ? add_target : accum_target);\n+\t  val_so_far += (HOST_WIDE_INT) 1 << log;\n+\t  break;\n+\n+\tcase alg_sub_t_m2:\n+\t  tem = expand_shift (LSHIFT_EXPR, mode, op0,\n+\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n+\t  accum = force_operand (gen_rtx_MINUS (mode, accum, tem),\n+\t\t\t\t add_target ? add_target : accum_target);\n+\t  val_so_far -= (HOST_WIDE_INT) 1 << log;\n+\t  break;\n+\n+\tcase alg_add_t2_m:\n+\t  accum = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t\tbuild_int_2 (log, 0), shift_subtarget,\n+\t\t\t\t0);\n+\t  accum = force_operand (gen_rtx_PLUS (mode, accum, op0),\n+\t\t\t\t add_target ? add_target : accum_target);\n+\t  val_so_far = (val_so_far << log) + 1;\n+\t  break;\n+\n+\tcase alg_sub_t2_m:\n+\t  accum = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t\tbuild_int_2 (log, 0), shift_subtarget, 0);\n+\t  accum = force_operand (gen_rtx_MINUS (mode, accum, op0),\n+\t\t\t\t add_target ? add_target : accum_target);\n+\t  val_so_far = (val_so_far << log) - 1;\n+\t  break;\n+\n+\tcase alg_add_factor:\n+\t  tem = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n+\t  accum = force_operand (gen_rtx_PLUS (mode, accum, tem),\n+\t\t\t\t add_target ? add_target : accum_target);\n+\t  val_so_far += val_so_far << log;\n+\t  break;\n+\n+\tcase alg_sub_factor:\n+\t  tem = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n+\t  accum = force_operand (gen_rtx_MINUS (mode, tem, accum),\n+\t\t\t\t (add_target ? add_target\n+\t\t\t\t  : preserve ? 0 : tem));\n+\t  val_so_far = (val_so_far << log) - val_so_far;\n+\t  break;\n+\n+\tdefault:\n+\t  abort ();\n+\t}\n+\n+      /* Write a REG_EQUAL note on the last insn so that we can cse\n+\t multiplication sequences.  Note that if ACCUM is a SUBREG,\n+\t we've set the inner register and must properly indicate\n+\t that.  */\n+\n+      tem = op0, nmode = mode;\n+      if (GET_CODE (accum) == SUBREG)\n+\t{\n+\t  nmode = GET_MODE (SUBREG_REG (accum));\n+\t  tem = gen_lowpart (nmode, op0);\n+\t}\n+\n+      insn = get_last_insn ();\n+      set_unique_reg_note (insn, REG_EQUAL,\n+\t\t\t   gen_rtx_MULT (nmode, tem, GEN_INT (val_so_far)));\n+    }\n+\n+  if (variant == negate_variant)\n+    {\n+      val_so_far = -val_so_far;\n+      accum = expand_unop (mode, neg_optab, accum, target, 0);\n+    }\n+  else if (variant == add_variant)\n+    {\n+      val_so_far = val_so_far + 1;\n+      accum = force_operand (gen_rtx_PLUS (mode, accum, op0), target);\n+    }\n+\n+  if (val != val_so_far)\n+    abort ();\n+\n+  return accum;\n+}\n+\n /* Perform a multiplication and return an rtx for the result.\n    MODE is mode of value; OP0 and OP1 are what to multiply (rtx's);\n    TARGET is a suggestion for where to store the result (an rtx).\n@@ -2409,6 +2614,8 @@ expand_mult (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n \t     int unsignedp)\n {\n   rtx const_op1 = op1;\n+  enum mult_variant variant;\n+  struct algorithm algorithm;\n \n   /* synth_mult does an `unsigned int' multiply.  As long as the mode is\n      less than or equal in size to `unsigned int' this doesn't matter.\n@@ -2435,190 +2642,10 @@ expand_mult (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n      that it seems better to use synth_mult always.  */\n \n   if (const_op1 && GET_CODE (const_op1) == CONST_INT\n-      && (unsignedp || ! flag_trapv))\n-    {\n-      struct algorithm alg;\n-      struct algorithm alg2;\n-      HOST_WIDE_INT val = INTVAL (op1);\n-      HOST_WIDE_INT val_so_far;\n-      rtx insn;\n-      int mult_cost;\n-      enum {basic_variant, negate_variant, add_variant} variant = basic_variant;\n-\n-      /* op0 must be register to make mult_cost match the precomputed\n-         shiftadd_cost array.  */\n-      op0 = force_reg (mode, op0);\n-\n-      /* Try to do the computation three ways: multiply by the negative of OP1\n-\t and then negate, do the multiplication directly, or do multiplication\n-\t by OP1 - 1.  */\n-\n-      mult_cost = rtx_cost (gen_rtx_MULT (mode, op0, op1), SET);\n-      mult_cost = MIN (12 * add_cost, mult_cost);\n-\n-      synth_mult (&alg, val, mult_cost);\n-\n-      /* This works only if the inverted value actually fits in an\n-\t `unsigned int' */\n-      if (HOST_BITS_PER_INT >= GET_MODE_BITSIZE (mode))\n-\t{\n-\t  synth_mult (&alg2, - val,\n-\t\t      (alg.cost < mult_cost ? alg.cost : mult_cost) - negate_cost);\n-\t  if (alg2.cost + negate_cost < alg.cost)\n-\t    alg = alg2, variant = negate_variant;\n-\t}\n-\n-      /* This proves very useful for division-by-constant.  */\n-      synth_mult (&alg2, val - 1,\n-\t\t  (alg.cost < mult_cost ? alg.cost : mult_cost) - add_cost);\n-      if (alg2.cost + add_cost < alg.cost)\n-\talg = alg2, variant = add_variant;\n-\n-      if (alg.cost < mult_cost)\n-\t{\n-\t  /* We found something cheaper than a multiply insn.  */\n-\t  int opno;\n-\t  rtx accum, tem;\n-\t  enum machine_mode nmode;\n-\n-\t  op0 = protect_from_queue (op0, 0);\n-\n-\t  /* Avoid referencing memory over and over.\n-\t     For speed, but also for correctness when mem is volatile.  */\n-\t  if (GET_CODE (op0) == MEM)\n-\t    op0 = force_reg (mode, op0);\n-\n-\t  /* ACCUM starts out either as OP0 or as a zero, depending on\n-\t     the first operation.  */\n-\n-\t  if (alg.op[0] == alg_zero)\n-\t    {\n-\t      accum = copy_to_mode_reg (mode, const0_rtx);\n-\t      val_so_far = 0;\n-\t    }\n-\t  else if (alg.op[0] == alg_m)\n-\t    {\n-\t      accum = copy_to_mode_reg (mode, op0);\n-\t      val_so_far = 1;\n-\t    }\n-\t  else\n-\t    abort ();\n-\n-\t  for (opno = 1; opno < alg.ops; opno++)\n-\t    {\n-\t      int log = alg.log[opno];\n-\t      int preserve = preserve_subexpressions_p ();\n-\t      rtx shift_subtarget = preserve ? 0 : accum;\n-\t      rtx add_target\n-\t\t= (opno == alg.ops - 1 && target != 0 && variant != add_variant\n-\t\t   && ! preserve)\n-\t\t  ? target : 0;\n-\t      rtx accum_target = preserve ? 0 : accum;\n-\n-\t      switch (alg.op[opno])\n-\t\t{\n-\t\tcase alg_shift:\n-\t\t  accum = expand_shift (LSHIFT_EXPR, mode, accum,\n-\t\t\t\t\tbuild_int_2 (log, 0), NULL_RTX, 0);\n-\t\t  val_so_far <<= log;\n-\t\t  break;\n-\n-\t\tcase alg_add_t_m2:\n-\t\t  tem = expand_shift (LSHIFT_EXPR, mode, op0,\n-\t\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n-\t\t  accum = force_operand (gen_rtx_PLUS (mode, accum, tem),\n-\t\t\t\t\t add_target\n-\t\t\t\t\t ? add_target : accum_target);\n-\t\t  val_so_far += (HOST_WIDE_INT) 1 << log;\n-\t\t  break;\n-\n-\t\tcase alg_sub_t_m2:\n-\t\t  tem = expand_shift (LSHIFT_EXPR, mode, op0,\n-\t\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n-\t\t  accum = force_operand (gen_rtx_MINUS (mode, accum, tem),\n-\t\t\t\t\t add_target\n-\t\t\t\t\t ? add_target : accum_target);\n-\t\t  val_so_far -= (HOST_WIDE_INT) 1 << log;\n-\t\t  break;\n-\n-\t\tcase alg_add_t2_m:\n-\t\t  accum = expand_shift (LSHIFT_EXPR, mode, accum,\n-\t\t\t\t\tbuild_int_2 (log, 0), shift_subtarget,\n-\t\t\t\t\t0);\n-\t\t  accum = force_operand (gen_rtx_PLUS (mode, accum, op0),\n-\t\t\t\t\t add_target\n-\t\t\t\t\t ? add_target : accum_target);\n-\t\t  val_so_far = (val_so_far << log) + 1;\n-\t\t  break;\n-\n-\t\tcase alg_sub_t2_m:\n-\t\t  accum = expand_shift (LSHIFT_EXPR, mode, accum,\n-\t\t\t\t\tbuild_int_2 (log, 0), shift_subtarget,\n-\t\t\t\t\t0);\n-\t\t  accum = force_operand (gen_rtx_MINUS (mode, accum, op0),\n-\t\t\t\t\t add_target\n-\t\t\t\t\t ? add_target : accum_target);\n-\t\t  val_so_far = (val_so_far << log) - 1;\n-\t\t  break;\n-\n-\t\tcase alg_add_factor:\n-\t\t  tem = expand_shift (LSHIFT_EXPR, mode, accum,\n-\t\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n-\t\t  accum = force_operand (gen_rtx_PLUS (mode, accum, tem),\n-\t\t\t\t\t add_target\n-\t\t\t\t\t ? add_target : accum_target);\n-\t\t  val_so_far += val_so_far << log;\n-\t\t  break;\n-\n-\t\tcase alg_sub_factor:\n-\t\t  tem = expand_shift (LSHIFT_EXPR, mode, accum,\n-\t\t\t\t      build_int_2 (log, 0), NULL_RTX, 0);\n-\t\t  accum = force_operand (gen_rtx_MINUS (mode, tem, accum),\n-\t\t\t\t\t (add_target ? add_target\n-\t\t\t\t\t  : preserve ? 0 : tem));\n-\t\t  val_so_far = (val_so_far << log) - val_so_far;\n-\t\t  break;\n-\n-\t\tdefault:\n-\t\t  abort ();\n-\t\t}\n-\n-\t      /* Write a REG_EQUAL note on the last insn so that we can cse\n-\t\t multiplication sequences.  Note that if ACCUM is a SUBREG,\n-\t\t we've set the inner register and must properly indicate\n-\t\t that.  */\n-\n-\t      tem = op0, nmode = mode;\n-\t      if (GET_CODE (accum) == SUBREG)\n-\t\t{\n-\t\t  nmode = GET_MODE (SUBREG_REG (accum));\n-\t\t  tem = gen_lowpart (nmode, op0);\n-\t\t}\n-\n-\t      insn = get_last_insn ();\n-\t      set_unique_reg_note (insn,\n-\t\t\t\t   REG_EQUAL,\n-\t\t\t\t   gen_rtx_MULT (nmode, tem,\n-\t\t\t\t\t         GEN_INT (val_so_far)));\n-\t    }\n-\n-\t  if (variant == negate_variant)\n-\t    {\n-\t      val_so_far = - val_so_far;\n-\t      accum = expand_unop (mode, neg_optab, accum, target, 0);\n-\t    }\n-\t  else if (variant == add_variant)\n-\t    {\n-\t      val_so_far = val_so_far + 1;\n-\t      accum = force_operand (gen_rtx_PLUS (mode, accum, op0), target);\n-\t    }\n-\n-\t  if (val != val_so_far)\n-\t    abort ();\n-\n-\t  return accum;\n-\t}\n-    }\n+      && (unsignedp || !flag_trapv)\n+      && choose_mult_variant (mode, INTVAL (const_op1), &algorithm, &variant))\n+    return expand_mult_const (mode, op0, INTVAL (const_op1), target,\n+\t\t\t      &algorithm, variant);\n \n   if (GET_CODE (op0) == CONST_DOUBLE)\n     {\n@@ -2832,70 +2859,46 @@ expand_mult_highpart_adjust (enum machine_mode mode, rtx adj_operand, rtx op0,\n   return target;\n }\n \n-/* Emit code to multiply OP0 and CNST1, putting the high half of the result\n-   in TARGET if that is convenient, and return where the result is.  If the\n-   operation can not be performed, 0 is returned.\n+/* Subroutine of expand_mult_highpart.  Return the MODE high part of OP.  */\n \n-   MODE is the mode of operation and result.\n+static rtx\n+extract_high_half (enum machine_mode mode, rtx op)\n+{\n+  enum machine_mode wider_mode;\n \n-   UNSIGNEDP nonzero means unsigned multiply.\n+  if (mode == word_mode)\n+    return gen_highpart (mode, op);\n \n-   MAX_COST is the total allowed cost for the expanded RTL.  */\n+  wider_mode = GET_MODE_WIDER_MODE (mode);\n+  op = expand_shift (RSHIFT_EXPR, wider_mode, op,\n+\t\t     build_int_2 (GET_MODE_BITSIZE (mode), 0), 0, 1);\n+  return convert_modes (mode, wider_mode, op, 0);\n+}\n \n-rtx\n-expand_mult_highpart (enum machine_mode mode, rtx op0,\n-\t\t      unsigned HOST_WIDE_INT cnst1, rtx target,\n-\t\t      int unsignedp, int max_cost)\n+/* Like expand_mult_highpart, but only consider using a multiplication\n+   optab.  OP1 is an rtx for the constant operand.  */\n+\n+static rtx\n+expand_mult_highpart_optab (enum machine_mode mode, rtx op0, rtx op1,\n+\t\t\t    rtx target, int unsignedp, int max_cost)\n {\n-  enum machine_mode wider_mode = GET_MODE_WIDER_MODE (mode);\n-  optab mul_highpart_optab;\n+  enum machine_mode wider_mode;\n   optab moptab;\n   rtx tem;\n-  int size = GET_MODE_BITSIZE (mode);\n-  rtx op1, wide_op1;\n-\n-  /* We can't support modes wider than HOST_BITS_PER_INT.  */\n-  if (size > HOST_BITS_PER_WIDE_INT)\n-    abort ();\n-\n-  op1 = gen_int_mode (cnst1, mode);\n-\n-  wide_op1\n-    = immed_double_const (cnst1,\n-\t\t\t  (unsignedp\n-\t\t\t   ? (HOST_WIDE_INT) 0\n-\t\t\t   : -(cnst1 >> (HOST_BITS_PER_WIDE_INT - 1))),\n-\t\t\t  wider_mode);\n-\n-  /* expand_mult handles constant multiplication of word_mode\n-     or narrower.  It does a poor job for large modes.  */\n-  if (size < BITS_PER_WORD\n-      && mul_cost[(int) wider_mode] + shift_cost[size-1] < max_cost)\n-    {\n-      /* We have to do this, since expand_binop doesn't do conversion for\n-\t multiply.  Maybe change expand_binop to handle widening multiply?  */\n-      op0 = convert_to_mode (wider_mode, op0, unsignedp);\n-\n-      /* We know that this can't have signed overflow, so pretend this is\n-         an unsigned multiply.  */\n-      tem = expand_mult (wider_mode, op0, wide_op1, NULL_RTX, 0);\n-      tem = expand_shift (RSHIFT_EXPR, wider_mode, tem,\n-\t\t\t  build_int_2 (size, 0), NULL_RTX, 1);\n-      return convert_modes (mode, wider_mode, tem, unsignedp);\n-    }\n+  int size;\n \n-  if (target == 0)\n-    target = gen_reg_rtx (mode);\n+  wider_mode = GET_MODE_WIDER_MODE (mode);\n+  size = GET_MODE_BITSIZE (mode);\n \n   /* Firstly, try using a multiplication insn that only generates the needed\n      high part of the product, and in the sign flavor of unsignedp.  */\n   if (mul_highpart_cost[(int) mode] < max_cost)\n     {\n-      mul_highpart_optab = unsignedp ? umul_highpart_optab : smul_highpart_optab;\n-      target = expand_binop (mode, mul_highpart_optab,\n-\t\t\t     op0, op1, target, unsignedp, OPTAB_DIRECT);\n-      if (target)\n-\treturn target;\n+      moptab = unsignedp ? umul_highpart_optab : smul_highpart_optab;\n+      tem = expand_binop (mode, moptab, op0, op1, target,\n+\t\t\t  unsignedp, OPTAB_DIRECT);\n+      if (tem)\n+\treturn tem;\n     }\n \n   /* Secondly, same as above, but use sign flavor opposite of unsignedp.\n@@ -2904,22 +2907,24 @@ expand_mult_highpart (enum machine_mode mode, rtx op0,\n       && (mul_highpart_cost[(int) mode] + 2 * shift_cost[size-1] + 4 * add_cost\n \t  < max_cost))\n     {\n-      mul_highpart_optab = unsignedp ? smul_highpart_optab : umul_highpart_optab;\n-      target = expand_binop (mode, mul_highpart_optab,\n-\t\t\t     op0, op1, target, unsignedp, OPTAB_DIRECT);\n-      if (target)\n+      moptab = unsignedp ? smul_highpart_optab : umul_highpart_optab;\n+      tem = expand_binop (mode, moptab, op0, op1, target,\n+\t\t\t  unsignedp, OPTAB_DIRECT);\n+      if (tem)\n \t/* We used the wrong signedness.  Adjust the result.  */\n-\treturn expand_mult_highpart_adjust (mode, target, op0,\n-\t\t\t\t\t    op1, target, unsignedp);\n+\treturn expand_mult_highpart_adjust (mode, tem, op0, op1,\n+\t\t\t\t\t    tem, unsignedp);\n     }\n \n   /* Try widening multiplication.  */\n   moptab = unsignedp ? umul_widen_optab : smul_widen_optab;\n   if (moptab->handlers[(int) wider_mode].insn_code != CODE_FOR_nothing\n       && mul_widen_cost[(int) wider_mode] < max_cost)\n     {\n-      op1 = force_reg (mode, op1);\n-      goto try;\n+      tem = expand_binop (wider_mode, moptab, op0, op1, 0,\n+\t\t\t  unsignedp, OPTAB_WIDEN);\n+      if (tem)\n+\treturn extract_high_half (mode, tem);\n     }\n \n   /* Try widening the mode and perform a non-widening multiplication.  */\n@@ -2928,8 +2933,10 @@ expand_mult_highpart (enum machine_mode mode, rtx op0,\n       && size - 1 < BITS_PER_WORD\n       && mul_cost[(int) wider_mode] + shift_cost[size-1] < max_cost)\n     {\n-      op1 = wide_op1;\n-      goto try;\n+      tem = expand_binop (wider_mode, moptab, op0, op1, 0,\n+\t\t\t  unsignedp, OPTAB_WIDEN);\n+      if (tem)\n+\treturn extract_high_half (mode, tem);\n     }\n \n   /* Try widening multiplication of opposite signedness, and adjust.  */\n@@ -2944,36 +2951,60 @@ expand_mult_highpart (enum machine_mode mode, rtx op0,\n \t\t\t  NULL_RTX, ! unsignedp, OPTAB_WIDEN);\n       if (tem != 0)\n \t{\n-\t  /* Extract the high half of the just generated product.  */\n-\t  tem = expand_shift (RSHIFT_EXPR, wider_mode, tem,\n-\t\t\t      build_int_2 (size, 0), NULL_RTX, 1);\n-\t  tem = convert_modes (mode, wider_mode, tem, unsignedp);\n+\t  tem = extract_high_half (mode, tem);\n \t  /* We used the wrong signedness.  Adjust the result.  */\n \t  return expand_mult_highpart_adjust (mode, tem, op0, op1,\n \t\t\t\t\t      target, unsignedp);\n \t}\n     }\n \n   return 0;\n+}\n \n- try:\n-  /* Pass NULL_RTX as target since TARGET has wrong mode.  */\n-  tem = expand_binop (wider_mode, moptab, op0, op1,\n-\t\t      NULL_RTX, unsignedp, OPTAB_WIDEN);\n-  if (tem == 0)\n-    return 0;\n+/* Emit code to multiply OP0 and CNST1, putting the high half of the result\n+   in TARGET if that is convenient, and return where the result is.  If the\n+   operation can not be performed, 0 is returned.\n \n-  /* Extract the high half of the just generated product.  */\n-  if (mode == word_mode)\n-    {\n-      return gen_highpart (mode, tem);\n-    }\n-  else\n+   MODE is the mode of operation and result.\n+\n+   UNSIGNEDP nonzero means unsigned multiply.\n+\n+   MAX_COST is the total allowed cost for the expanded RTL.  */\n+\n+rtx\n+expand_mult_highpart (enum machine_mode mode, rtx op0,\n+\t\t      unsigned HOST_WIDE_INT cnst1, rtx target,\n+\t\t      int unsignedp, int max_cost)\n+{\n+  enum machine_mode wider_mode;\n+  enum mult_variant variant;\n+  struct algorithm alg;\n+  rtx op1, tem;\n+\n+  /* We can't support modes wider than HOST_BITS_PER_INT.  */\n+  if (GET_MODE_BITSIZE (mode) > HOST_BITS_PER_WIDE_INT)\n+    abort ();\n+\n+  op1 = gen_int_mode (cnst1, mode);\n+\n+  /* See whether shift/add multiplication is cheap enough.  */\n+  if (choose_mult_variant (mode, cnst1, &alg, &variant)\n+      && (alg.cost += shift_cost[GET_MODE_BITSIZE (mode) - 1]) < max_cost)\n     {\n-      tem = expand_shift (RSHIFT_EXPR, wider_mode, tem,\n-\t\t\t  build_int_2 (size, 0), NULL_RTX, 1);\n-      return convert_modes (mode, wider_mode, tem, unsignedp);\n+      /* See whether the specialized multiplication optabs are\n+\t cheaper than the shift/add version.  */\n+      tem = expand_mult_highpart_optab (mode, op0, op1, target,\n+\t\t\t\t\tunsignedp, alg.cost);\n+      if (tem)\n+\treturn tem;\n+\n+      wider_mode = GET_MODE_WIDER_MODE (mode);\n+      op0 = convert_to_mode (wider_mode, op0, unsignedp);\n+      tem = expand_mult_const (wider_mode, op0, cnst1, 0, &alg, variant);\n+      return extract_high_half (mode, tem);\n     }\n+  return expand_mult_highpart_optab (mode, op0, op1, target,\n+\t\t\t\t     unsignedp, max_cost);\n }\n \f\n /* Emit the code to divide OP0 by OP1, putting the result in TARGET"}]}