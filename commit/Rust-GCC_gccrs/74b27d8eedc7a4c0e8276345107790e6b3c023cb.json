{"sha": "74b27d8eedc7a4c0e8276345107790e6b3c023cb", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzRiMjdkOGVlZGM3YTRjMGU4Mjc2MzQ1MTA3NzkwZTZiM2MwMjNjYg==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-09-23T18:25:04Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-09-23T18:25:04Z"}, "message": "aarch64: Prevent canary address being spilled to stack\n\nThis patch fixes the equivalent of arm bug PR85434/CVE-2018-12886\nfor aarch64: under high register pressure, the -fstack-protector\ncode might spill the address of the canary onto the stack and\nreload it at the test site, giving an attacker the opportunity\nto change the expected canary value.\n\nThis would happen in two cases:\n\n- when generating PIC for -mstack-protector-guard=global\n  (tested by stack-protector-6.c).  This is a direct analogue\n  of PR85434, which was also about PIC for the global case.\n\n- when using -mstack-protector-guard=sysreg.\n\nThe two problems were really separate bugs and caused by separate code,\nbut it was more convenient to fix them together.\n\nThe post-patch code still spills _GLOBAL_OFFSET_TABLE_ for\nstack-protector-6.c, which is a more general problem.  However,\nit no longer spills the canary address itself.\n\nThe patch also fixes an ICE when using -mstack-protector-guard=sysreg\nwith ILP32: even if the register read is SImode, the address\ncalculation itself should still be DImode.\n\ngcc/\n\t* config/aarch64/aarch64-protos.h (aarch64_salt_type): New enum.\n\t(aarch64_stack_protect_canary_mem): Declare.\n\t* config/aarch64/aarch64.md (UNSPEC_SALT_ADDR): New unspec.\n\t(stack_protect_set): Forward to stack_protect_combined_set.\n\t(stack_protect_combined_set): New pattern.  Use\n\taarch64_stack_protect_canary_mem.\n\t(reg_stack_protect_address_<mode>): Add a salt operand.\n\t(stack_protect_test): Forward to stack_protect_combined_test.\n\t(stack_protect_combined_test): New pattern.  Use\n\taarch64_stack_protect_canary_mem.\n\t* config/aarch64/aarch64.c (strip_salt): New function.\n\t(strip_offset_and_salt): Likewise.\n\t(tls_symbolic_operand_type): Use strip_offset_and_salt.\n\t(aarch64_stack_protect_canary_mem): New function.\n\t(aarch64_cannot_force_const_mem): Use strip_offset_and_salt.\n\t(aarch64_classify_address): Likewise.\n\t(aarch64_symbolic_address_p): Likewise.\n\t(aarch64_print_operand): Likewise.\n\t(aarch64_output_addr_const_extra): New function.\n\t(aarch64_tls_symbol_p): Use strip_salt.\n\t(aarch64_classify_symbol): Likewise.\n\t(aarch64_legitimate_pic_operand_p): Use strip_offset_and_salt.\n\t(aarch64_legitimate_constant_p): Likewise.\n\t(aarch64_mov_operand_p): Use strip_salt.\n\t(TARGET_ASM_OUTPUT_ADDR_CONST_EXTRA): Override.\n\ngcc/testsuite/\n\t* gcc.target/aarch64/stack-protector-5.c: New test.\n\t* gcc.target/aarch64/stack-protector-6.c: Likewise.\n\t* gcc.target/aarch64/stack-protector-7.c: Likewise.", "tree": {"sha": "9814ab980a925298f38feb3d81dd3528ad870f14", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9814ab980a925298f38feb3d81dd3528ad870f14"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/74b27d8eedc7a4c0e8276345107790e6b3c023cb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/74b27d8eedc7a4c0e8276345107790e6b3c023cb", "html_url": "https://github.com/Rust-GCC/gccrs/commit/74b27d8eedc7a4c0e8276345107790e6b3c023cb", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/74b27d8eedc7a4c0e8276345107790e6b3c023cb/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0f0b00033a71ff728d6fab6f9d674fb6b3ba4980", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0f0b00033a71ff728d6fab6f9d674fb6b3ba4980", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0f0b00033a71ff728d6fab6f9d674fb6b3ba4980"}], "stats": {"total": 325, "additions": 228, "deletions": 97}, "files": [{"sha": "302e09b202f9b3d854fe3b50e49da93daf8c8f90", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=74b27d8eedc7a4c0e8276345107790e6b3c023cb", "patch": "@@ -136,6 +136,25 @@ enum aarch64_addr_query_type {\n   ADDR_QUERY_ANY\n };\n \n+/* Enumerates values that can be arbitrarily mixed into a calculation\n+   in order to make the result of the calculation unique to its use case.\n+\n+   AARCH64_SALT_SSP_SET\n+   AARCH64_SALT_SSP_TEST\n+      Used when calculating the address of the stack protection canary value.\n+      There is a separate value for setting and testing the canary, meaning\n+      that these two operations produce unique addresses: they are different\n+      from each other, and from all other address calculations.\n+\n+      The main purpose of this is to prevent the SET address being spilled\n+      to the stack and reloaded for the TEST, since that would give an\n+      attacker the opportunity to change the address of the expected\n+      canary value.  */\n+enum aarch64_salt_type {\n+  AARCH64_SALT_SSP_SET,\n+  AARCH64_SALT_SSP_TEST\n+};\n+\n /* A set of tuning parameters contains references to size and time\n    cost models and vectors for address cost calculations, register\n    move costs and memory move costs.  */\n@@ -608,6 +627,7 @@ opt_machine_mode aarch64_ptrue_all_mode (rtx);\n rtx aarch64_convert_sve_data_to_pred (rtx, machine_mode, rtx);\n rtx aarch64_expand_sve_dupq (rtx, machine_mode, rtx);\n void aarch64_expand_mov_immediate (rtx, rtx);\n+rtx aarch64_stack_protect_canary_mem (machine_mode, rtx, aarch64_salt_type);\n rtx aarch64_ptrue_reg (machine_mode);\n rtx aarch64_pfalse_reg (machine_mode);\n bool aarch64_sve_pred_dominates_p (rtx *, rtx);"}, {"sha": "491fc582dab70eafa680defc7685c4ef7429fcad", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 116, "deletions": 48, "changes": 164, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=74b27d8eedc7a4c0e8276345107790e6b3c023cb", "patch": "@@ -1935,6 +1935,29 @@ aarch64_sve_abi (void)\n   return sve_abi;\n }\n \n+/* If X is an UNSPEC_SALT_ADDR expression, return the address that it\n+   wraps, otherwise return X itself.  */\n+\n+static rtx\n+strip_salt (rtx x)\n+{\n+  rtx search = x;\n+  if (GET_CODE (search) == CONST)\n+    search = XEXP (search, 0);\n+  if (GET_CODE (search) == UNSPEC && XINT (search, 1) == UNSPEC_SALT_ADDR)\n+    x = XVECEXP (search, 0, 0);\n+  return x;\n+}\n+\n+/* Like strip_offset, but also strip any UNSPEC_SALT_ADDR from the\n+   expression.  */\n+\n+static rtx\n+strip_offset_and_salt (rtx addr, poly_int64 *offset)\n+{\n+  return strip_salt (strip_offset (addr, offset));\n+}\n+\n /* Generate code to enable conditional branches in functions over 1 MiB.  */\n const char *\n aarch64_gen_far_branch (rtx * operands, int pos_label, const char * dest,\n@@ -2932,14 +2955,9 @@ static enum tls_model\n tls_symbolic_operand_type (rtx addr)\n {\n   enum tls_model tls_kind = TLS_MODEL_NONE;\n-  if (GET_CODE (addr) == CONST)\n-    {\n-      poly_int64 addend;\n-      rtx sym = strip_offset (addr, &addend);\n-      if (GET_CODE (sym) == SYMBOL_REF)\n-\ttls_kind = SYMBOL_REF_TLS_MODEL (sym);\n-    }\n-  else if (GET_CODE (addr) == SYMBOL_REF)\n+  poly_int64 offset;\n+  addr = strip_offset_and_salt (addr, &offset);\n+  if (GET_CODE (addr) == SYMBOL_REF)\n     tls_kind = SYMBOL_REF_TLS_MODEL (addr);\n \n   return tls_kind;\n@@ -5239,6 +5257,48 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n \t\t\t\t  as_a <scalar_int_mode> (mode));\n }\n \n+/* Return the MEM rtx that provides the canary value that should be used\n+   for stack-smashing protection.  MODE is the mode of the memory.\n+   For SSP_GLOBAL, DECL_RTL is the MEM rtx for the canary variable\n+   (__stack_chk_guard), otherwise it has no useful value.  SALT_TYPE\n+   indicates whether the caller is performing a SET or a TEST operation.  */\n+\n+rtx\n+aarch64_stack_protect_canary_mem (machine_mode mode, rtx decl_rtl,\n+\t\t\t\t  aarch64_salt_type salt_type)\n+{\n+  rtx addr;\n+  if (aarch64_stack_protector_guard == SSP_GLOBAL)\n+    {\n+      gcc_assert (MEM_P (decl_rtl));\n+      addr = XEXP (decl_rtl, 0);\n+      poly_int64 offset;\n+      rtx base = strip_offset_and_salt (addr, &offset);\n+      if (!SYMBOL_REF_P (base))\n+\treturn decl_rtl;\n+\n+      rtvec v = gen_rtvec (2, base, GEN_INT (salt_type));\n+      addr = gen_rtx_UNSPEC (Pmode, v, UNSPEC_SALT_ADDR);\n+      addr = gen_rtx_CONST (Pmode, addr);\n+      addr = plus_constant (Pmode, addr, offset);\n+    }\n+  else\n+    {\n+      /* Calculate the address from the system register.  */\n+      rtx salt = GEN_INT (salt_type);\n+      addr = gen_reg_rtx (mode);\n+      if (mode == DImode)\n+\temit_insn (gen_reg_stack_protect_address_di (addr, salt));\n+      else\n+\t{\n+\t  emit_insn (gen_reg_stack_protect_address_si (addr, salt));\n+\t  addr = convert_memory_address (Pmode, addr);\n+\t}\n+      addr = plus_constant (Pmode, addr, aarch64_stack_protector_guard_offset);\n+    }\n+  return gen_rtx_MEM (mode, force_reg (Pmode, addr));\n+}\n+\n /* Emit an SVE predicated move from SRC to DEST.  PRED is a predicate\n    that is known to contain PTRUE.  */\n \n@@ -8677,8 +8737,6 @@ aarch64_move_imm (HOST_WIDE_INT val, machine_mode mode)\n static bool\n aarch64_cannot_force_const_mem (machine_mode mode ATTRIBUTE_UNUSED, rtx x)\n {\n-  rtx base, offset;\n-\n   if (GET_CODE (x) == HIGH)\n     return true;\n \n@@ -8688,10 +8746,12 @@ aarch64_cannot_force_const_mem (machine_mode mode ATTRIBUTE_UNUSED, rtx x)\n     if (GET_CODE (*iter) == CONST_POLY_INT)\n       return true;\n \n-  split_const (x, &base, &offset);\n+  poly_int64 offset;\n+  rtx base = strip_offset_and_salt (x, &offset);\n   if (GET_CODE (base) == SYMBOL_REF || GET_CODE (base) == LABEL_REF)\n     {\n-      if (aarch64_classify_symbol (base, INTVAL (offset))\n+      /* We checked for POLY_INT_CST offsets above.  */\n+      if (aarch64_classify_symbol (base, offset.to_constant ())\n \t  != SYMBOL_FORCE_TO_MEM)\n \treturn true;\n       else\n@@ -9217,9 +9277,8 @@ aarch64_classify_address (struct aarch64_address_info *info,\n \t  && GET_MODE_SIZE (mode).is_constant (&const_size)\n \t  && const_size >= 4)\n \t{\n-\t  rtx sym, addend;\n-\n-\t  split_const (x, &sym, &addend);\n+\t  poly_int64 offset;\n+\t  rtx sym = strip_offset_and_salt (x, &offset);\n \t  return ((GET_CODE (sym) == LABEL_REF\n \t\t   || (GET_CODE (sym) == SYMBOL_REF\n \t\t       && CONSTANT_POOL_ADDRESS_P (sym)\n@@ -9234,10 +9293,12 @@ aarch64_classify_address (struct aarch64_address_info *info,\n       if (allow_reg_index_p\n \t  && aarch64_base_register_rtx_p (info->base, strict_p))\n \t{\n-\t  rtx sym, offs;\n-\t  split_const (info->offset, &sym, &offs);\n+\t  poly_int64 offset;\n+\t  HOST_WIDE_INT const_offset;\n+\t  rtx sym = strip_offset_and_salt (info->offset, &offset);\n \t  if (GET_CODE (sym) == SYMBOL_REF\n-\t      && (aarch64_classify_symbol (sym, INTVAL (offs))\n+\t      && offset.is_constant (&const_offset)\n+\t      && (aarch64_classify_symbol (sym, const_offset)\n \t\t  == SYMBOL_SMALL_ABSOLUTE))\n \t    {\n \t      /* The symbol and offset must be aligned to the access size.  */\n@@ -9263,7 +9324,7 @@ aarch64_classify_address (struct aarch64_address_info *info,\n \t      if (known_eq (ref_size, 0))\n \t\tref_size = GET_MODE_SIZE (DImode);\n \n-\t      return (multiple_p (INTVAL (offs), ref_size)\n+\t      return (multiple_p (const_offset, ref_size)\n \t\t      && multiple_p (align / BITS_PER_UNIT, ref_size));\n \t    }\n \t}\n@@ -9295,9 +9356,8 @@ aarch64_address_valid_for_prefetch_p (rtx x, bool strict_p)\n bool\n aarch64_symbolic_address_p (rtx x)\n {\n-  rtx offset;\n-\n-  split_const (x, &x, &offset);\n+  poly_int64 offset;\n+  x = strip_offset_and_salt (x, &offset);\n   return GET_CODE (x) == SYMBOL_REF || GET_CODE (x) == LABEL_REF;\n }\n \n@@ -10028,27 +10088,16 @@ aarch64_print_operand (FILE *f, rtx x, int code)\n   switch (code)\n     {\n     case 'c':\n-      switch (GET_CODE (x))\n+      if (CONST_INT_P (x))\n+\tfprintf (f, HOST_WIDE_INT_PRINT_DEC, INTVAL (x));\n+      else\n \t{\n-\tcase CONST_INT:\n-\t  fprintf (f, HOST_WIDE_INT_PRINT_DEC, INTVAL (x));\n-\t  break;\n-\n-\tcase SYMBOL_REF:\n-\t  output_addr_const (f, x);\n-\t  break;\n-\n-\tcase CONST:\n-\t  if (GET_CODE (XEXP (x, 0)) == PLUS\n-\t      && GET_CODE (XEXP (XEXP (x, 0), 0)) == SYMBOL_REF)\n-\t    {\n-\t      output_addr_const (f, x);\n-\t      break;\n-\t    }\n-\t  /* Fall through.  */\n-\n-\tdefault:\n-\t  output_operand_lossage (\"unsupported operand for code '%c'\", code);\n+\t  poly_int64 offset;\n+\t  rtx base = strip_offset_and_salt (x, &offset);\n+\t  if (SYMBOL_REF_P (base))\n+\t    output_addr_const (f, x);\n+\t  else\n+\t    output_operand_lossage (\"unsupported operand for code '%c'\", code);\n \t}\n       break;\n \n@@ -10623,6 +10672,19 @@ aarch64_print_operand_address (FILE *f, machine_mode mode, rtx x)\n     output_addr_const (f, x);\n }\n \n+/* Implement TARGET_ASM_OUTPUT_ADDR_CONST_EXTRA.  */\n+\n+static bool\n+aarch64_output_addr_const_extra (FILE *file, rtx x)\n+{\n+  if (GET_CODE (x) == UNSPEC && XINT (x, 1) == UNSPEC_SALT_ADDR)\n+    {\n+      output_addr_const (file, XVECEXP (x, 0, 0));\n+      return true;\n+   }\n+  return false;\n+}\n+\n bool\n aarch64_label_mentioned_p (rtx x)\n {\n@@ -15932,6 +15994,7 @@ aarch64_tls_symbol_p (rtx x)\n   if (! TARGET_HAVE_TLS)\n     return false;\n \n+  x = strip_salt (x);\n   if (GET_CODE (x) != SYMBOL_REF)\n     return false;\n \n@@ -15987,6 +16050,8 @@ aarch64_classify_tls_symbol (rtx x)\n enum aarch64_symbol_type\n aarch64_classify_symbol (rtx x, HOST_WIDE_INT offset)\n {\n+  x = strip_salt (x);\n+\n   if (GET_CODE (x) == LABEL_REF)\n     {\n       switch (aarch64_cmodel)\n@@ -16086,11 +16151,10 @@ aarch64_constant_address_p (rtx x)\n bool\n aarch64_legitimate_pic_operand_p (rtx x)\n {\n-  if (GET_CODE (x) == SYMBOL_REF\n-      || (GET_CODE (x) == CONST\n-\t  && GET_CODE (XEXP (x, 0)) == PLUS\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 0)) == SYMBOL_REF))\n-     return false;\n+  poly_int64 offset;\n+  x = strip_offset_and_salt (x, &offset);\n+  if (GET_CODE (x) == SYMBOL_REF)\n+    return false;\n \n   return true;\n }\n@@ -16136,7 +16200,7 @@ aarch64_legitimate_constant_p (machine_mode mode, rtx x)\n   /* If an offset is being added to something else, we need to allow the\n      base to be moved into the destination register, meaning that there\n      are no free temporaries for the offset.  */\n-  x = strip_offset (x, &offset);\n+  x = strip_offset_and_salt (x, &offset);\n   if (!offset.is_constant () && aarch64_offset_temporaries (true, offset) > 0)\n     return false;\n \n@@ -18035,6 +18099,7 @@ aarch64_mov_operand_p (rtx x, machine_mode mode)\n       return aarch64_simd_valid_immediate (x, NULL);\n     }\n \n+  x = strip_salt (x);\n   if (GET_CODE (x) == SYMBOL_REF && mode == DImode && CONSTANT_ADDRESS_P (x))\n     return true;\n \n@@ -23890,6 +23955,9 @@ aarch64_libgcc_floating_mode_supported_p\n #undef TARGET_PRINT_OPERAND_ADDRESS\n #define TARGET_PRINT_OPERAND_ADDRESS aarch64_print_operand_address\n \n+#undef TARGET_ASM_OUTPUT_ADDR_CONST_EXTRA\n+#define TARGET_ASM_OUTPUT_ADDR_CONST_EXTRA aarch64_output_addr_const_extra\n+\n #undef TARGET_OPTAB_SUPPORTED_P\n #define TARGET_OPTAB_SUPPORTED_P aarch64_optab_supported_p\n "}, {"sha": "19ec9e33f9f90e5e19710923c76712a5274debad", "filename": "gcc/config/aarch64/aarch64.md", "status": "modified", "additions": 36, "deletions": 49, "changes": 85, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Fconfig%2Faarch64%2Faarch64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Fconfig%2Faarch64%2Faarch64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.md?ref=74b27d8eedc7a4c0e8276345107790e6b3c023cb", "patch": "@@ -281,6 +281,7 @@\n     UNSPEC_GEN_TAG_RND\t\t; Generate a random 4-bit MTE tag.\n     UNSPEC_TAG_SPACE\t\t; Translate address to MTE tag address space.\n     UNSPEC_LD1RO\n+    UNSPEC_SALT_ADDR\n ])\n \n (define_c_enum \"unspecv\" [\n@@ -6881,43 +6882,37 @@\n   DONE;\n })\n \n-;; Named patterns for stack smashing protection.\n+;; Defined for -mstack-protector-guard=sysreg, which goes through this\n+;; pattern rather than stack_protect_combined_set.  Our implementation\n+;; of the latter can handle both.\n (define_expand \"stack_protect_set\"\n   [(match_operand 0 \"memory_operand\")\n-   (match_operand 1 \"memory_operand\")]\n+   (match_operand 1 \"\")]\n   \"\"\n {\n-  machine_mode mode = GET_MODE (operands[0]);\n-  if (aarch64_stack_protector_guard != SSP_GLOBAL)\n-  {\n-    /* Generate access through the system register.  */\n-    rtx tmp_reg = gen_reg_rtx (mode);\n-    if (mode == DImode)\n-    {\n-        emit_insn (gen_reg_stack_protect_address_di (tmp_reg));\n-        emit_insn (gen_adddi3 (tmp_reg, tmp_reg,\n-\t\t\t       GEN_INT (aarch64_stack_protector_guard_offset)));\n-    }\n-    else\n-    {\n-\temit_insn (gen_reg_stack_protect_address_si (tmp_reg));\n-\temit_insn (gen_addsi3 (tmp_reg, tmp_reg,\n-\t\t\t       GEN_INT (aarch64_stack_protector_guard_offset)));\n+  emit_insn (gen_stack_protect_combined_set (operands[0], operands[1]));\n+  DONE;\n+})\n \n-    }\n-    operands[1] = gen_rtx_MEM (mode, tmp_reg);\n-  }\n-  \n+(define_expand \"stack_protect_combined_set\"\n+  [(match_operand 0 \"memory_operand\")\n+   (match_operand 1 \"\")]\n+  \"\"\n+{\n+  machine_mode mode = GET_MODE (operands[0]);\n+  operands[1] = aarch64_stack_protect_canary_mem (mode, operands[1],\n+\t\t\t\t\t\t  AARCH64_SALT_SSP_SET);\n   emit_insn ((mode == DImode\n \t      ? gen_stack_protect_set_di\n \t      : gen_stack_protect_set_si) (operands[0], operands[1]));\n   DONE;\n })\n \n+;; Operand 1 is either AARCH64_SALT_SSP_SET or AARCH64_SALT_SSP_TEST.\n (define_insn \"reg_stack_protect_address_<mode>\"\n  [(set (match_operand:PTR 0 \"register_operand\" \"=r\")\n-       (unspec:PTR [(const_int 0)]\n-\tUNSPEC_SSP_SYSREG))]\n+       (unspec:PTR [(match_operand 1 \"const_int_operand\")]\n+\t\t   UNSPEC_SSP_SYSREG))]\n  \"aarch64_stack_protector_guard != SSP_GLOBAL\"\n  {\n    char buf[150];\n@@ -6940,37 +6935,29 @@\n   [(set_attr \"length\" \"12\")\n    (set_attr \"type\" \"multiple\")])\n \n+;; Defined for -mstack-protector-guard=sysreg, which goes through this\n+;; pattern rather than stack_protect_combined_test.  Our implementation\n+;; of the latter can handle both.\n (define_expand \"stack_protect_test\"\n   [(match_operand 0 \"memory_operand\")\n-   (match_operand 1 \"memory_operand\")\n+   (match_operand 1 \"\")\n    (match_operand 2)]\n   \"\"\n {\n-  machine_mode mode = GET_MODE (operands[0]);\n-\n-  if (aarch64_stack_protector_guard != SSP_GLOBAL)\n-  {\n-    /* Generate access through the system register. The\n-       sequence we want here is the access\n-       of the stack offset to come with\n-       mrs scratch_reg, <system_register>\n-       add scratch_reg, scratch_reg, :lo12:offset. */\n-    rtx tmp_reg = gen_reg_rtx (mode);\n-    if (mode == DImode)\n-    {\n-       emit_insn (gen_reg_stack_protect_address_di (tmp_reg));\n-       emit_insn (gen_adddi3 (tmp_reg, tmp_reg,\n-       \t\t              GEN_INT (aarch64_stack_protector_guard_offset)));\n-    }\n-    else\n-    {\n-\temit_insn (gen_reg_stack_protect_address_si (tmp_reg));\n-\temit_insn (gen_addsi3 (tmp_reg, tmp_reg,\n-\t\t\t       GEN_INT (aarch64_stack_protector_guard_offset)));\n+  emit_insn (gen_stack_protect_combined_test (operands[0], operands[1],\n+\t\t\t\t\t      operands[2]));\n+  DONE;\n+})\n \n-    }\n-    operands[1] = gen_rtx_MEM (mode, tmp_reg);\n-  }\n+(define_expand \"stack_protect_combined_test\"\n+  [(match_operand 0 \"memory_operand\")\n+   (match_operand 1 \"\")\n+   (match_operand 2)]\n+  \"\"\n+{\n+  machine_mode mode = GET_MODE (operands[0]);\n+  operands[1] = aarch64_stack_protect_canary_mem (mode, operands[1],\n+\t\t\t\t\t\t  AARCH64_SALT_SSP_TEST);\n   emit_insn ((mode == DImode\n \t     ? gen_stack_protect_test_di\n \t     : gen_stack_protect_test_si) (operands[0], operands[1]));"}, {"sha": "a9cd53b2eac83fff6485572b39dc884700e88002", "filename": "gcc/testsuite/gcc.target/aarch64/stack-protector-5.c", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-5.c?ref=74b27d8eedc7a4c0e8276345107790e6b3c023cb", "patch": "@@ -0,0 +1,23 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-fstack-protector-all -O2\" } */\n+\n+void __attribute__ ((noipa))\n+f (void)\n+{\n+  volatile int x;\n+  asm volatile (\"\" :::\n+\t\t\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\",\n+\t\t\"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\", \"x15\",\n+\t\t\"x16\", \"x17\", \"x18\", \"x19\", \"x20\", \"x21\", \"x22\", \"x23\",\n+\t\t\"x24\", \"x25\", \"x26\", \"x27\", \"x28\", \"x30\");\n+}\n+\n+/* The register clobbers above should not generate any single LDRs or STRs;\n+   all registers should be saved and restored in pairs.  The only STRs\n+   should be therefore be those associated with the stack protector\n+   tests themselves.\n+\n+   Make sure the address of the canary value is not spilled and reloaded,\n+   since that would give the attacker an opportunity to change the\n+   canary value.  */\n+/* { dg-final { scan-assembler-times {\\tstr\\t} 1 } } */"}, {"sha": "e2ac0885eba61ac6df3caf5299f73c7ff38ca548", "filename": "gcc/testsuite/gcc.target/aarch64/stack-protector-6.c", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-6.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-6.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-6.c?ref=74b27d8eedc7a4c0e8276345107790e6b3c023cb", "patch": "@@ -0,0 +1,8 @@\n+/* { dg-do compile } */\n+/* { dg-require-effective-target fpic } */\n+/* { dg-options \"-fstack-protector-all -O2 -fpic\" } */\n+\n+#include \"stack-protector-5.c\"\n+\n+/* See the comment in stack-protector-5.c.  */\n+/* { dg-final { scan-assembler-times {\\tldr\\t[^\\n]*__stack_chk_guard} 2 } } */"}, {"sha": "e644768fe5e4da457b29a0602498ab3edfa97379", "filename": "gcc/testsuite/gcc.target/aarch64/stack-protector-7.c", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-7.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/74b27d8eedc7a4c0e8276345107790e6b3c023cb/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-7.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fstack-protector-7.c?ref=74b27d8eedc7a4c0e8276345107790e6b3c023cb", "patch": "@@ -0,0 +1,25 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-fstack-protector-all -mstack-protector-guard=sysreg -mstack-protector-guard-offset=16 -mstack-protector-guard-reg=tpidr_el0 -O2\" } */\n+\n+void __attribute__ ((noipa))\n+f (void)\n+{\n+  volatile int x;\n+  asm volatile (\"\" :::\n+\t\t\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\",\n+\t\t\"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\", \"x15\",\n+\t\t\"x16\", \"x17\", \"x18\", \"x19\", \"x20\", \"x21\", \"x22\", \"x23\",\n+\t\t\"x24\", \"x25\", \"x26\", \"x27\", \"x28\", \"x30\");\n+}\n+\n+/* The register clobbers above should not generate any single LDRs or STRs;\n+   all registers should be saved and restored in pairs.  The only LDRs and\n+   STRs should be therefore be those associated with the stack protector\n+   tests themselves.\n+\n+   Make sure the address of the canary value (tpidr_el0 + 16) is not\n+   spilled and reloaded, since that would give the attacker an opportunity\n+   to change the canary value.  */\n+/* { dg-final { scan-assembler-times {\\tmrs\\t} 2 } } */\n+/* { dg-final { scan-assembler-times {\\tstr\\t} 1 } } */\n+/* { dg-final { scan-assembler-times {\\tldr\\t} 3 } } */"}]}