{"sha": "0257997968fc4b62547cdc2a5cf5e01777bd7ed7", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDI1Nzk5Nzk2OGZjNGI2MjU0N2NkYzJhNWNmNWUwMTc3N2JkN2VkNw==", "commit": {"author": {"name": "Nathan Sidwell", "email": "nathan@acm.org", "date": "2020-07-14T17:49:03Z"}, "committer": {"name": "Nathan Sidwell", "email": "nathan@acm.org", "date": "2020-07-14T17:58:36Z"}, "message": "c++: Parser entry cleanup\n\nThe handling of PCH is a little trick, because we have to deal with it before\nallocating memory.  I found the layering somewhat confusing.  This patch\nreorganizes that, so that the stopping of PCH is done in exactly one place,\nand the ordering of lexer creation relative to that is much clearer.\n\nI also changed the error message about multiple source files as with C++20,\n'modules' means something rather specific.\n\nOther than the error message changes, no functional changes.\n\n\tgcc/cp/\n\t* parser.c (cp_lexer_alloc): Do not deal with PCH here.\n\t(cp_lexer_new_main): Deal with PCH here.  Store the tokens directly\n\tinto the buffer.\n\t(cp_lexer_new_from_tokens): Assert last token isn't purged either.\n\t(cp_lexer_get_preprocessor_token): Change first arg to flags, adjust.\n\t(cp_parser_new): Pass the lexer in, don't create it here.\n\t(cp_parser_translation_unit): Initialize access checks here.\n\t(cp_parser_initial_pragma): First token is provided by caller,\n\tdon't deal with PCH stopping here.  Adjust error message.\n\t(c_parse_file): Adjust, change error message to avoid C++20 module\n\tconfusion.", "tree": {"sha": "5ff55f5854295e25b213772207d774d23db2e3d9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5ff55f5854295e25b213772207d774d23db2e3d9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0257997968fc4b62547cdc2a5cf5e01777bd7ed7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0257997968fc4b62547cdc2a5cf5e01777bd7ed7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0257997968fc4b62547cdc2a5cf5e01777bd7ed7", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0257997968fc4b62547cdc2a5cf5e01777bd7ed7/comments", "author": {"login": "urnathan", "id": 13103001, "node_id": "MDQ6VXNlcjEzMTAzMDAx", "avatar_url": "https://avatars.githubusercontent.com/u/13103001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/urnathan", "html_url": "https://github.com/urnathan", "followers_url": "https://api.github.com/users/urnathan/followers", "following_url": "https://api.github.com/users/urnathan/following{/other_user}", "gists_url": "https://api.github.com/users/urnathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/urnathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/urnathan/subscriptions", "organizations_url": "https://api.github.com/users/urnathan/orgs", "repos_url": "https://api.github.com/users/urnathan/repos", "events_url": "https://api.github.com/users/urnathan/events{/privacy}", "received_events_url": "https://api.github.com/users/urnathan/received_events", "type": "User", "site_admin": false}, "committer": {"login": "urnathan", "id": 13103001, "node_id": "MDQ6VXNlcjEzMTAzMDAx", "avatar_url": "https://avatars.githubusercontent.com/u/13103001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/urnathan", "html_url": "https://github.com/urnathan", "followers_url": "https://api.github.com/users/urnathan/followers", "following_url": "https://api.github.com/users/urnathan/following{/other_user}", "gists_url": "https://api.github.com/users/urnathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/urnathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/urnathan/subscriptions", "organizations_url": "https://api.github.com/users/urnathan/orgs", "repos_url": "https://api.github.com/users/urnathan/repos", "events_url": "https://api.github.com/users/urnathan/events{/privacy}", "received_events_url": "https://api.github.com/users/urnathan/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b52643ab9004ba8ecea06a399885fe1e04183eda", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b52643ab9004ba8ecea06a399885fe1e04183eda", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b52643ab9004ba8ecea06a399885fe1e04183eda"}], "stats": {"total": 95, "additions": 44, "deletions": 51}, "files": [{"sha": "08cfd23d8c40687c50e630f128b79e1873c7bd41", "filename": "gcc/cp/parser.c", "status": "modified", "additions": 44, "deletions": 51, "changes": 95, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0257997968fc4b62547cdc2a5cf5e01777bd7ed7/gcc%2Fcp%2Fparser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0257997968fc4b62547cdc2a5cf5e01777bd7ed7/gcc%2Fcp%2Fparser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fparser.c?ref=0257997968fc4b62547cdc2a5cf5e01777bd7ed7", "patch": "@@ -212,7 +212,7 @@ static int cp_lexer_saving_tokens\n static cp_token *cp_lexer_token_at\n   (cp_lexer *, cp_token_position);\n static void cp_lexer_get_preprocessor_token\n-  (cp_lexer *, cp_token *);\n+  (unsigned, cp_token *);\n static inline cp_token *cp_lexer_peek_token\n   (cp_lexer *);\n static cp_token *cp_lexer_peek_nth_token\n@@ -613,12 +613,8 @@ debug (cp_parser *ptr)\n static cp_lexer *\n cp_lexer_alloc (void)\n {\n-  cp_lexer *lexer;\n-\n-  c_common_no_more_pch ();\n-\n   /* Allocate the memory.  */\n-  lexer = ggc_cleared_alloc<cp_lexer> ();\n+  cp_lexer *lexer = ggc_cleared_alloc<cp_lexer> ();\n \n   /* Initially we are not debugging.  */\n   lexer->debugging_p = false;\n@@ -631,31 +627,30 @@ cp_lexer_alloc (void)\n   return lexer;\n }\n \n-\n /* Create a new main C++ lexer, the lexer that gets tokens from the\n    preprocessor.  */\n \n static cp_lexer *\n cp_lexer_new_main (void)\n {\n-  cp_lexer *lexer;\n   cp_token token;\n \n   /* It's possible that parsing the first pragma will load a PCH file,\n      which is a GC collection point.  So we have to do that before\n      allocating any memory.  */\n+  cp_lexer_get_preprocessor_token (0, &token);\n   cp_parser_initial_pragma (&token);\n+  c_common_no_more_pch ();\n \n-  lexer = cp_lexer_alloc ();\n-\n+  cp_lexer *lexer = cp_lexer_alloc ();\n   /* Put the first token in the buffer.  */\n-  lexer->buffer->quick_push (token);\n+  cp_token *tok = lexer->buffer->quick_push (token);\n \n   /* Get the remaining tokens from the preprocessor.  */\n-  while (token.type != CPP_EOF)\n+  while (tok->type != CPP_EOF)\n     {\n-      cp_lexer_get_preprocessor_token (lexer, &token);\n-      vec_safe_push (lexer->buffer, token);\n+      tok = vec_safe_push (lexer->buffer, cp_token ());\n+      cp_lexer_get_preprocessor_token (C_LEX_STRING_NO_JOIN, tok);\n     }\n \n   lexer->next_token = lexer->buffer->address ();\n@@ -698,7 +693,8 @@ cp_lexer_new_from_tokens (cp_token_cache *cache)\n   /* Initially we are not debugging.  */\n   lexer->debugging_p = false;\n \n-  gcc_assert (!lexer->next_token->purged_p);\n+  gcc_assert (!lexer->next_token->purged_p\n+\t      && !lexer->last_token->purged_p);\n   return lexer;\n }\n \n@@ -815,14 +811,14 @@ cp_lexer_saving_tokens (const cp_lexer* lexer)\n    processed strings.  */\n \n static void\n-cp_lexer_get_preprocessor_token (cp_lexer *lexer, cp_token *token)\n+cp_lexer_get_preprocessor_token (unsigned flags, cp_token *token)\n {\n   static int is_extern_c = 0;\n \n    /* Get a new token from the preprocessor.  */\n   token->type\n     = c_lex_with_flags (&token->u.value, &token->location, &token->flags,\n-\t\t\tlexer == NULL ? 0 : C_LEX_STRING_NO_JOIN);\n+\t\t\tflags);\n   token->keyword = RID_MAX;\n   token->purged_p = false;\n   token->error_reported = false;\n@@ -2029,7 +2025,7 @@ pop_unparsed_function_queues (cp_parser *parser)\n /* Constructors and destructors.  */\n \n static cp_parser *cp_parser_new\n-  (void);\n+  (cp_lexer *);\n \n /* Routines to parse various constructs.\n \n@@ -3997,22 +3993,14 @@ cp_parser_make_indirect_declarator (enum tree_code code, tree class_type,\n /* Create a new C++ parser.  */\n \n static cp_parser *\n-cp_parser_new (void)\n+cp_parser_new (cp_lexer *lexer)\n {\n-  cp_parser *parser;\n-  cp_lexer *lexer;\n-  unsigned i;\n-\n-  /* cp_lexer_new_main is called before doing GC allocation because\n-     cp_lexer_new_main might load a PCH file.  */\n-  lexer = cp_lexer_new_main ();\n-\n   /* Initialize the binops_by_token so that we can get the tree\n      directly from the token.  */\n-  for (i = 0; i < sizeof (binops) / sizeof (binops[0]); i++)\n+  for (unsigned i = 0; i < sizeof (binops) / sizeof (binops[0]); i++)\n     binops_by_token[binops[i].token_type] = binops[i];\n \n-  parser = ggc_cleared_alloc<cp_parser> ();\n+  cp_parser *parser = ggc_cleared_alloc<cp_parser> ();\n   parser->lexer = lexer;\n   parser->context = cp_parser_context_new (NULL);\n \n@@ -4728,14 +4716,19 @@ cp_parser_translation_unit (cp_parser* parser)\n   /* Remember where the base of the declarator obstack lies.  */\n   void *declarator_obstack_base = obstack_next_free (&declarator_obstack);\n \n+  push_deferring_access_checks (flag_access_control\n+\t\t\t\t? dk_no_deferred : dk_no_check);\n+\n   bool implicit_extern_c = false;\n \n+  /* Parse until EOF.  */\n   for (;;)\n     {\n       cp_token *token = cp_lexer_peek_token (parser->lexer);\n \n       /* If we're entering or exiting a region that's implicitly\n-\t extern \"C\", modify the lang context appropriately.  */\n+\t extern \"C\", modify the lang context appropriately.  This is\n+\t so horrible.  Please die.   */\n       if (implicit_extern_c\n \t  != cp_lexer_peek_token (parser->lexer)->implicit_extern_c)\n \t{\n@@ -43592,31 +43585,28 @@ static GTY (()) cp_parser *the_parser;\n static void\n cp_parser_initial_pragma (cp_token *first_token)\n {\n-  tree name = NULL;\n-\n-  cp_lexer_get_preprocessor_token (NULL, first_token);\n   if (cp_parser_pragma_kind (first_token) != PRAGMA_GCC_PCH_PREPROCESS)\n-    {\n-      c_common_no_more_pch ();\n-      return;\n-    }\n+    return;\n+\n+  cp_lexer_get_preprocessor_token (0, first_token);\n \n-  cp_lexer_get_preprocessor_token (NULL, first_token);\n+  tree name = NULL;\n   if (first_token->type == CPP_STRING)\n     {\n       name = first_token->u.value;\n \n-      cp_lexer_get_preprocessor_token (NULL, first_token);\n-      if (first_token->type != CPP_PRAGMA_EOL)\n-\terror_at (first_token->location,\n-\t\t  \"junk at end of %<#pragma GCC pch_preprocess%>\");\n+      cp_lexer_get_preprocessor_token (0, first_token);\n     }\n-  else\n-    error_at (first_token->location, \"expected string literal\");\n \n   /* Skip to the end of the pragma.  */\n-  while (first_token->type != CPP_PRAGMA_EOL && first_token->type != CPP_EOF)\n-    cp_lexer_get_preprocessor_token (NULL, first_token);\n+  if (first_token->type != CPP_PRAGMA_EOL)\n+    {\n+      error_at (first_token->location,\n+\t\t\"malformed %<#pragma GCC pch_preprocess%>\");\n+      do\n+\tcp_lexer_get_preprocessor_token (0, first_token);\n+      while (first_token->type != CPP_PRAGMA_EOL);\n+    }\n \n   /* Now actually load the PCH file.  */\n   if (name)\n@@ -43625,7 +43615,7 @@ cp_parser_initial_pragma (cp_token *first_token)\n   /* Read one more token to return to our caller.  We have to do this\n      after reading the PCH file in, since its pointers have to be\n      live.  */\n-  cp_lexer_get_preprocessor_token (NULL, first_token);\n+  cp_lexer_get_preprocessor_token (0, first_token);\n }\n \n /* Parse a pragma GCC ivdep.  */\n@@ -44050,12 +44040,15 @@ c_parse_file (void)\n \n   if (already_called)\n     fatal_error (input_location,\n-\t\t \"inter-module optimizations not implemented for C++\");\n+\t\t \"multi-source compilation not implemented for C++\");\n   already_called = true;\n \n-  the_parser = cp_parser_new ();\n-  push_deferring_access_checks (flag_access_control\n-\t\t\t\t? dk_no_deferred : dk_no_check);\n+  /* cp_lexer_new_main is called before doing any GC allocation\n+     because tokenization might load a PCH file.  */\n+  cp_lexer *lexer = cp_lexer_new_main ();\n+\n+  the_parser = cp_parser_new (lexer);\n+\n   cp_parser_translation_unit (the_parser);\n   class_decl_loc_t::diag_mismatched_tags ();\n "}]}