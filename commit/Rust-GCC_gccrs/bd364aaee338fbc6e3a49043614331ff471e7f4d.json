{"sha": "bd364aaee338fbc6e3a49043614331ff471e7f4d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmQzNjRhYWVlMzM4ZmJjNmUzYTQ5MDQzNjE0MzMxZmY0NzFlN2Y0ZA==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2021-03-17T21:37:11Z"}, "committer": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2021-03-17T21:37:11Z"}, "message": "Enable gather on zen3 hardware.\n\nFor TSVC it get used by 5 benchmarks with following runtime improvements:\n\ns4114: 1.424 -> 1.209  (84.9017%)\ns4115: 2.021 -> 1.065  (52.6967%)\ns4116: 1.549 -> 0.854  (55.1323%)\ns4117: 1.386 -> 1.193  (86.075%)\nvag: 2.741 -> 1.940  (70.7771%)\n\nthere is regression in\n\ns4112: 1.115 -> 1.184  (106.188%)\n\nThe internal loop is:\n\n        for (int i = 0; i < LEN_1D; i++) {\n            a[i] += b[ip[i]] * s;\n        }\n\n(so a standard accmulate and add with indirect addressing)\n\n  40a400:       c5 fe 6f 24 03          vmovdqu (%rbx,%rax,1),%ymm4\n  40a405:       c5 fc 28 da             vmovaps %ymm2,%ymm3\n  40a409:       48 83 c0 20             add    $0x20,%rax\n  40a40d:       c4 e2 65 92 04 a5 00    vgatherdps %ymm3,0x594100(,%ymm4,4),%ymm0\n  40a414:       41 59 00\n  40a417:       c4 e2 75 a8 80 e0 34    vfmadd213ps 0x5b34e0(%rax),%ymm1,%ymm0\n  40a41e:       5b 00\n  40a420:       c5 fc 29 80 e0 34 5b    vmovaps %ymm0,0x5b34e0(%rax)\n  40a427:       00\n  40a428:       48 3d 00 f4 01 00       cmp    $0x1f400,%rax\n  40a42e:       75 d0                   jne    40a400 <s4112+0x60>\n\ncompared to:\n\n  40a280:       49 63 14 04             movslq (%r12,%rax,1),%rdx\n  40a284:       48 83 c0 04             add    $0x4,%rax\n  40a288:       c5 fa 10 04 95 00 41    vmovss 0x594100(,%rdx,4),%xmm0\n  40a28f:       59 00\n  40a291:       c4 e2 71 a9 80 fc 34    vfmadd213ss 0x5b34fc(%rax),%xmm1,%xmm0\n  40a298:       5b 00\n  40a29a:       c5 fa 11 80 fc 34 5b    vmovss %xmm0,0x5b34fc(%rax)\n  40a2a1:       00\n  40a2a2:       48 3d 00 f4 01 00       cmp    $0x1f400,%rax\n  40a2a8:       75 d6                   jne    40a280 <s4112+0x40>\n\nLooking at instructions latencies\n\n - fmadd is 4 cycles\n - vgatherdps is 39\n\nSo vgather iself is 4.8 cycle per iteration and probably CPU is able to execute\nrest out of order getting clos to 4 cycles per iteration (it can do 2 loads in\nparallel, one store and rest fits easily to execution resources). That would\nexplain 20% slowdown.\n\ngimple internal loop is:\n  _2 = a[i_38];\n  _3 = (long unsigned int) i_38;\n  _4 = _3 * 4;\n  _5 = ip_18 + _4;\n  _6 = *_5;\n  _7 = b[_6];\n  _8 = _7 * s_19;\n  _9 = _2 + _8;\n  a[i_38] = _9;\n  i_28 = i_38 + 1;\n  ivtmp_52 = ivtmp_53 - 1;\n  if (ivtmp_52 != 0)\n    goto <bb 8>; [98.99%]\n  else\n    goto <bb 4>; [1.01%]\n\n0x25bac30 a[i_38] 1 times scalar_load costs 12 in body\n0x25bac30 *_5 1 times scalar_load costs 12 in body\n0x25bac30 b[_6] 1 times scalar_load costs 12 in body\n0x25bac30 _7 * s_19 1 times scalar_stmt costs 12 in body\n0x25bac30 _2 + _8 1 times scalar_stmt costs 12 in body\n0x25bac30 _9 1 times scalar_store costs 16 in body\n\nso 19 cycles estimate of scalar load\n\n0x2668630 a[i_38] 1 times vector_load costs 12 in body\n0x2668630 *_5 1 times unaligned_load (misalign -1) costs 12 in body\n0x2668630 b[_6] 8 times scalar_load costs 96 in body\n0x2668630 _7 * s_19 1 times scalar_to_vec costs 4 in prologue\n0x2668630 _7 * s_19 1 times vector_stmt costs 12 in body\n0x2668630 _2 + _8 1 times vector_stmt costs 12 in body\n0x2668630 _9 1 times vector_store costs 16 in body\n\nso 40 cycles per 8x vectorized body\n\ntsvc.c:3450:27: note:  operating only on full vectors.\ntsvc.c:3450:27: note:  Cost model analysis:\n  Vector inside of loop cost: 160\n  Vector prologue cost: 4\n  Vector epilogue cost: 0\n  Scalar iteration cost: 76\n  Scalar outside cost: 0\n  Vector outside cost: 4\n  prologue iterations: 0\n  epilogue iterations: 0\n  Calculated minimum iters for profitability: 1\n\nI think this generally suffers from GIGO principle.\nOne problem seems to be that we do not know about fmadd yet and compute it as\ntwo instructions (6 cycles instead of 4). More importnat problem is that we do\nnot account the parallelism at all.  I do not see how to disable the\nvecotrization here without bumping gather costs noticeably off reality and thus\nwe probably can try to experiment with this if more similar problems are found.\n\nIcc is also using gather in s1115 and s128.\nFor s1115 the vectorization does not seem to help and s128 gets slower.\n\nClang and aocc does not use gathers.\n\n\t* config/i386/x86-tune-costs.h (struct processor_costs): Update costs\n\tof gather to match reality.\n\t* config/i386/x86-tune.def (X86_TUNE_USE_GATHER): Enable for znver3.", "tree": {"sha": "b3737d19babe7a653c1e9f152c26e45e731f8472", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b3737d19babe7a653c1e9f152c26e45e731f8472"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/bd364aaee338fbc6e3a49043614331ff471e7f4d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bd364aaee338fbc6e3a49043614331ff471e7f4d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bd364aaee338fbc6e3a49043614331ff471e7f4d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bd364aaee338fbc6e3a49043614331ff471e7f4d/comments", "author": null, "committer": null, "parents": [{"sha": "f3e9c98a9f40fc24bb4ecef6aaa94ff799c8d587", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f3e9c98a9f40fc24bb4ecef6aaa94ff799c8d587", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f3e9c98a9f40fc24bb4ecef6aaa94ff799c8d587"}], "stats": {"total": 12, "additions": 6, "deletions": 6}, "files": [{"sha": "db03738313e741b16acfc8015e5af0cce29dc0b6", "filename": "gcc/config/i386/x86-tune-costs.h", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd364aaee338fbc6e3a49043614331ff471e7f4d/gcc%2Fconfig%2Fi386%2Fx86-tune-costs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd364aaee338fbc6e3a49043614331ff471e7f4d/gcc%2Fconfig%2Fi386%2Fx86-tune-costs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fx86-tune-costs.h?ref=bd364aaee338fbc6e3a49043614331ff471e7f4d", "patch": "@@ -1767,11 +1767,11 @@ struct processor_costs znver3_cost = {\n   2, 2, 3,\t\t\t\t/* cost of moving XMM,YMM,ZMM\n \t\t\t\t\t   register.  */\n   6,\t\t\t\t\t/* cost of moving SSE register to integer.  */\n-  /* VGATHERDPD is 23 uops and throughput is 9, VGATHERDPD is 35 uops,\n-     throughput 12.  Approx 9 uops do not depend on vector size and every load\n-     is 7 uops.  */\n-  18, 8,\t\t\t\t/* Gather load static, per_elt.  */\n-  18, 10,\t\t\t\t/* Gather store static, per_elt.  */\n+  /* VGATHERDPD is 15 uops and throughput is 4, VGATHERDPS is 23 uops,\n+     throughput 9.  Approx 7 uops do not depend on vector size and every load\n+     is 4 uops.  */\n+  14, 8,\t\t\t\t/* Gather load static, per_elt.  */\n+  14, 10,\t\t\t\t/* Gather store static, per_elt.  */\n   32,\t\t\t\t\t/* size of l1 cache.  */\n   512,\t\t\t\t\t/* size of l2 cache.  */\n   64,\t\t\t\t\t/* size of prefetch block.  */"}, {"sha": "caebf76736ee55f9cdabdfc1fbf215172f05ebb7", "filename": "gcc/config/i386/x86-tune.def", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd364aaee338fbc6e3a49043614331ff471e7f4d/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd364aaee338fbc6e3a49043614331ff471e7f4d/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fx86-tune.def?ref=bd364aaee338fbc6e3a49043614331ff471e7f4d", "patch": "@@ -436,7 +436,7 @@ DEF_TUNE (X86_TUNE_AVOID_4BYTE_PREFIXES, \"avoid_4byte_prefixes\",\n \n /* X86_TUNE_USE_GATHER: Use gather instructions.  */\n DEF_TUNE (X86_TUNE_USE_GATHER, \"use_gather\",\n-\t  ~(m_ZNVER | m_GENERIC))\n+\t  ~(m_ZNVER1 | m_ZNVER2 | m_GENERIC))\n \n /* X86_TUNE_AVOID_128FMA_CHAINS: Avoid creating loops with tight 128bit or\n    smaller FMA chain.  */"}]}