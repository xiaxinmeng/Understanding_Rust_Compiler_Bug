{"sha": "e0ae02888f7f11584f647434fabdbe0f0a3e121f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTBhZTAyODg4ZjdmMTE1ODRmNjQ3NDM0ZmFiZGJlMGYwYTNlMTIxZg==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2015-01-16T11:52:35Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2015-01-16T11:52:35Z"}, "message": "[AArch64] Add a new scheduling description for the ARM Cortex-A57 processor\n\ngcc/\n\n\t* config/arm/cortex-a57.md: New.\n\t* config/aarch64/aarch64.md: Include it.\n\t* config/aarch64/aarch64-cores.def (cortex-a57): Tune for it.\n\t* config/aarch64/aarch64-tune.md: Regenerate.\n\nFrom-SVN: r219724", "tree": {"sha": "9e504e354a55687ec94c65d8ffc6d1d20a5b1385", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9e504e354a55687ec94c65d8ffc6d1d20a5b1385"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e0ae02888f7f11584f647434fabdbe0f0a3e121f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e0ae02888f7f11584f647434fabdbe0f0a3e121f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e0ae02888f7f11584f647434fabdbe0f0a3e121f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e0ae02888f7f11584f647434fabdbe0f0a3e121f/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "5f3bc026061e59f2722ae17f2329d005e0f95559", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5f3bc026061e59f2722ae17f2329d005e0f95559", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5f3bc026061e59f2722ae17f2329d005e0f95559"}], "stats": {"total": 1607, "additions": 1604, "deletions": 3}, "files": [{"sha": "621223dec40845996194b7ed9e5f1a5db1f6970b", "filename": "gcc/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e0ae02888f7f11584f647434fabdbe0f0a3e121f", "patch": "@@ -1,3 +1,10 @@\n+2015-01-16  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/arm/cortex-a57.md: New.\n+\t* config/aarch64/aarch64.md: Include it.\n+\t* config/aarch64/aarch64-cores.def (cortex-a57): Tune for it.\n+\t* config/aarch64/aarch64-tune.md: Regenerate.\n+\n 2015-01-16  Zhenqiang Chen  <zhenqiang.chen@arm.com>\n \n \tPR target/64015"}, {"sha": "f978eb1d3866487a1a865743888ee03155dd4016", "filename": "gcc/config/aarch64/aarch64-cores.def", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Faarch64%2Faarch64-cores.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Faarch64%2Faarch64-cores.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-cores.def?ref=e0ae02888f7f11584f647434fabdbe0f0a3e121f", "patch": "@@ -35,7 +35,7 @@\n /* V8 Architecture Processors.  */\n \n AARCH64_CORE(\"cortex-a53\",  cortexa53, cortexa53, 8,  AARCH64_FL_FOR_ARCH8 | AARCH64_FL_CRC, cortexa53)\n-AARCH64_CORE(\"cortex-a57\",  cortexa15, cortexa15, 8,  AARCH64_FL_FOR_ARCH8 | AARCH64_FL_CRC, cortexa57)\n+AARCH64_CORE(\"cortex-a57\",  cortexa57, cortexa57, 8,  AARCH64_FL_FOR_ARCH8 | AARCH64_FL_CRC, cortexa57)\n AARCH64_CORE(\"thunderx\",    thunderx,  thunderx, 8,  AARCH64_FL_FOR_ARCH8 | AARCH64_FL_CRC | AARCH64_FL_CRYPTO, thunderx)\n AARCH64_CORE(\"xgene1\",      xgene1,    xgene1,    8,  AARCH64_FL_FOR_ARCH8, xgene1)\n "}, {"sha": "80f59c84ef91bb629a194fe5d7a9fb5aecdccfa3", "filename": "gcc/config/aarch64/aarch64-tune.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Faarch64%2Faarch64-tune.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Faarch64%2Faarch64-tune.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-tune.md?ref=e0ae02888f7f11584f647434fabdbe0f0a3e121f", "patch": "@@ -1,5 +1,5 @@\n ;; -*- buffer-read-only: t -*-\n ;; Generated automatically by gentune.sh from aarch64-cores.def\n (define_attr \"tune\"\n-\t\"cortexa53,cortexa15,thunderx,xgene1,cortexa57cortexa53\"\n+\t\"cortexa53,cortexa57,thunderx,xgene1,cortexa57cortexa53\"\n \t(const (symbol_ref \"((enum attr_tune) aarch64_tune)\")))"}, {"sha": "faf9cf34847002b353ad1b3c8a76db3e36d3ec23", "filename": "gcc/config/aarch64/aarch64.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Faarch64%2Faarch64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Faarch64%2Faarch64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.md?ref=e0ae02888f7f11584f647434fabdbe0f0a3e121f", "patch": "@@ -188,7 +188,7 @@\n \n ;; Scheduling\n (include \"../arm/cortex-a53.md\")\n-(include \"../arm/cortex-a15.md\")\n+(include \"../arm/cortex-a57.md\")\n (include \"thunderx.md\")\n (include \"../arm/xgene1.md\")\n "}, {"sha": "6750792f24d34c1cd40f49dd93bb5869ad4387e3", "filename": "gcc/config/arm/cortex-a57.md", "status": "added", "additions": 1594, "deletions": 0, "changes": 1594, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Farm%2Fcortex-a57.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e0ae02888f7f11584f647434fabdbe0f0a3e121f/gcc%2Fconfig%2Farm%2Fcortex-a57.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcortex-a57.md?ref=e0ae02888f7f11584f647434fabdbe0f0a3e121f", "patch": "@@ -0,0 +1,1594 @@\n+;; ARM Cortex-A57 pipeline description\n+;; Copyright (C) 2014-2015 Free Software Foundation, Inc.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify it\n+;; under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful, but\n+;; WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+;; General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_automaton \"cortex_a57\")\n+\n+(define_attr \"cortex_a57_neon_type\"\n+  \"neon_abd, neon_abd_q, neon_arith_acc, neon_arith_acc_q,\n+   neon_arith_basic, neon_arith_complex,\n+   neon_reduc_add_acc, neon_multiply, neon_multiply_q,\n+   neon_multiply_long, neon_mla, neon_mla_q, neon_mla_long,\n+   neon_sat_mla_long, neon_shift_acc, neon_shift_imm_basic,\n+   neon_shift_imm_complex,\n+   neon_shift_reg_basic, neon_shift_reg_basic_q, neon_shift_reg_complex,\n+   neon_shift_reg_complex_q, neon_fp_negabs, neon_fp_arith,\n+   neon_fp_arith_q, neon_fp_reductions_q, neon_fp_cvt_int,\n+   neon_fp_cvt_int_q, neon_fp_cvt16, neon_fp_minmax, neon_fp_mul,\n+   neon_fp_mul_q, neon_fp_mla, neon_fp_mla_q, neon_fp_recpe_rsqrte,\n+   neon_fp_recpe_rsqrte_q, neon_fp_recps_rsqrts, neon_fp_recps_rsqrts_q,\n+   neon_bitops, neon_bitops_q, neon_from_gp,\n+   neon_from_gp_q, neon_move, neon_tbl3_tbl4, neon_zip_q, neon_to_gp,\n+   neon_load_a, neon_load_b, neon_load_c, neon_load_d, neon_load_e,\n+   neon_load_f, neon_store_a, neon_store_b, neon_store_complex,\n+   unknown\"\n+  (cond [\n+\t  (eq_attr \"type\" \"neon_abd, neon_abd_long\")\n+\t    (const_string \"neon_abd\")\n+\t  (eq_attr \"type\" \"neon_abd_q\")\n+\t    (const_string \"neon_abd_q\")\n+\t  (eq_attr \"type\" \"neon_arith_acc, neon_reduc_add_acc,\\\n+\t\t\t   neon_reduc_add_acc_q\")\n+\t    (const_string \"neon_arith_acc\")\n+\t  (eq_attr \"type\" \"neon_arith_acc_q\")\n+\t    (const_string \"neon_arith_acc_q\")\n+\t  (eq_attr \"type\" \"neon_add, neon_add_q, neon_add_long,\\\n+\t\t\t   neon_add_widen, neon_neg, neon_neg_q,\\\n+\t\t\t   neon_reduc_add, neon_reduc_add_q,\\\n+\t\t\t   neon_reduc_add_long, neon_sub, neon_sub_q,\\\n+\t\t\t   neon_sub_long, neon_sub_widen, neon_logic,\\\n+\t\t\t   neon_logic_q, neon_tst, neon_tst_q\")\n+\t    (const_string \"neon_arith_basic\")\n+\t  (eq_attr \"type\" \"neon_abs, neon_abs_q, neon_add_halve_narrow_q,\\\n+\t\t\t   neon_add_halve, neon_add_halve_q,\\\n+\t\t\t   neon_sub_halve, neon_sub_halve_q, neon_qabs,\\\n+\t\t\t   neon_qabs_q, neon_qadd, neon_qadd_q, neon_qneg,\\\n+\t\t\t   neon_qneg_q, neon_qsub, neon_qsub_q,\\\n+\t\t\t   neon_sub_halve_narrow_q,\\\n+\t\t\t   neon_compare, neon_compare_q,\\\n+\t\t\t   neon_compare_zero, neon_compare_zero_q,\\\n+\t\t\t   neon_minmax, neon_minmax_q, neon_reduc_minmax,\\\n+\t\t\t   neon_reduc_minmax_q\")\n+\t    (const_string \"neon_arith_complex\")\n+\n+\t  (eq_attr \"type\" \"neon_mul_b, neon_mul_h, neon_mul_s,\\\n+\t\t\t   neon_mul_h_scalar, neon_mul_s_scalar,\\\n+\t\t\t   neon_sat_mul_b, neon_sat_mul_h,\\\n+\t\t\t   neon_sat_mul_s, neon_sat_mul_h_scalar,\\\n+\t\t\t   neon_sat_mul_s_scalar,\\\n+\t\t\t   neon_mul_b_long, neon_mul_h_long,\\\n+\t\t\t   neon_mul_s_long, neon_mul_d_long,\\\n+\t\t\t   neon_mul_h_scalar_long, neon_mul_s_scalar_long,\\\n+\t\t\t   neon_sat_mul_b_long, neon_sat_mul_h_long,\\\n+\t\t\t   neon_sat_mul_s_long, neon_sat_mul_h_scalar_long,\\\n+\t\t\t   neon_sat_mul_s_scalar_long\")\n+\t    (const_string \"neon_multiply\")\n+\t  (eq_attr \"type\" \"neon_mul_b_q, neon_mul_h_q, neon_mul_s_q,\\\n+\t\t\t   neon_mul_h_scalar_q, neon_mul_s_scalar_q,\\\n+\t\t\t   neon_sat_mul_b_q, neon_sat_mul_h_q,\\\n+\t\t\t   neon_sat_mul_s_q, neon_sat_mul_h_scalar_q,\\\n+\t\t\t   neon_sat_mul_s_scalar_q\")\n+\t    (const_string \"neon_multiply_q\")\n+\t  (eq_attr \"type\" \"neon_mla_b, neon_mla_h, neon_mla_s,\\\n+\t\t\t   neon_mla_h_scalar, neon_mla_s_scalar,\\\n+\t\t\t   neon_mla_b_long, neon_mla_h_long,\\\n+\t\t\t   neon_mla_s_long,\\\n+\t\t\t   neon_mla_h_scalar_long, neon_mla_s_scalar_long\")\n+\t    (const_string \"neon_mla\")\n+\t  (eq_attr \"type\" \"neon_mla_b_q, neon_mla_h_q, neon_mla_s_q,\\\n+\t\t\t   neon_mla_h_scalar_q, neon_mla_s_scalar_q\")\n+\t    (const_string \"neon_mla_q\")\n+\t  (eq_attr \"type\" \"neon_sat_mla_b_long, neon_sat_mla_h_long,\\\n+\t\t\t   neon_sat_mla_s_long, neon_sat_mla_h_scalar_long,\\\n+\t\t\t   neon_sat_mla_s_scalar_long\")\n+\t    (const_string \"neon_sat_mla_long\")\n+\n+\t  (eq_attr \"type\" \"neon_shift_acc, neon_shift_acc_q\")\n+\t    (const_string \"neon_shift_acc\")\n+\t  (eq_attr \"type\" \"neon_shift_imm, neon_shift_imm_q,\\\n+\t\t\t   neon_shift_imm_narrow_q, neon_shift_imm_long\")\n+\t    (const_string \"neon_shift_imm_basic\")\n+\t  (eq_attr \"type\" \"neon_sat_shift_imm, neon_sat_shift_imm_q,\\\n+\t\t\t   neon_sat_shift_imm_narrow_q\")\n+\t    (const_string \"neon_shift_imm_complex\")\n+\t  (eq_attr \"type\" \"neon_shift_reg\")\n+\t    (const_string \"neon_shift_reg_basic\")\n+\t  (eq_attr \"type\" \"neon_shift_reg_q\")\n+\t    (const_string \"neon_shift_reg_basic_q\")\n+\t  (eq_attr \"type\" \"neon_sat_shift_reg\")\n+\t    (const_string \"neon_shift_reg_complex\")\n+\t  (eq_attr \"type\" \"neon_sat_shift_reg_q\")\n+\t    (const_string \"neon_shift_reg_complex_q\")\n+\n+\t  (eq_attr \"type\" \"neon_fp_neg_s, neon_fp_neg_s_q,\\\n+\t\t\t   neon_fp_abs_s, neon_fp_abs_s_q,\\\n+\t\t\t   neon_fp_neg_d, neon_fp_neg_d_q,\\\n+\t\t\t   neon_fp_abs_d, neon_fp_abs_d_q\")\n+\t    (const_string \"neon_fp_negabs\")\n+\t  (eq_attr \"type\" \"neon_fp_addsub_s, neon_fp_abd_s,\\\n+\t\t\t   neon_fp_reduc_add_s, neon_fp_compare_s,\\\n+\t\t\t   neon_fp_minmax_s, neon_fp_round_s,\\\n+\t\t\t   neon_fp_addsub_d, neon_fp_abd_d,\\\n+\t\t\t   neon_fp_reduc_add_d, neon_fp_compare_d,\\\n+\t\t\t   neon_fp_minmax_d, neon_fp_round_d,\\\n+\t\t\t   neon_fp_reduc_minmax_s, neon_fp_reduc_minmax_d\")\n+\t    (const_string \"neon_fp_arith\")\n+\t  (eq_attr \"type\" \"neon_fp_addsub_s_q, neon_fp_abd_s_q,\\\n+\t\t\t   neon_fp_reduc_add_s_q, neon_fp_compare_s_q,\\\n+\t\t\t   neon_fp_minmax_s_q, neon_fp_round_s_q,\\\n+\t\t\t   neon_fp_addsub_d_q, neon_fp_abd_d_q,\\\n+\t\t\t   neon_fp_reduc_add_d_q, neon_fp_compare_d_q,\\\n+\t\t\t   neon_fp_minmax_d_q, neon_fp_round_d_q\")\n+\t    (const_string \"neon_fp_arith_q\")\n+\t  (eq_attr \"type\" \"neon_fp_reduc_minmax_s_q,\\\n+\t\t\t   neon_fp_reduc_minmax_d_q,\\\n+\t\t\t   neon_fp_reduc_add_s_q, neon_fp_reduc_add_d_q\")\n+\t    (const_string \"neon_fp_reductions_q\")\n+\t  (eq_attr \"type\" \"neon_fp_to_int_s, neon_int_to_fp_s,\\\n+\t\t\t   neon_fp_to_int_d, neon_int_to_fp_d\")\n+\t    (const_string \"neon_fp_cvt_int\")\n+\t  (eq_attr \"type\" \"neon_fp_to_int_s_q, neon_int_to_fp_s_q,\\\n+\t\t\t   neon_fp_to_int_d_q, neon_int_to_fp_d_q\")\n+\t    (const_string \"neon_fp_cvt_int_q\")\n+\t  (eq_attr \"type\" \"neon_fp_cvt_narrow_s_q, neon_fp_cvt_widen_h\")\n+\t    (const_string \"neon_fp_cvt16\")\n+\t  (eq_attr \"type\" \"neon_fp_mul_s, neon_fp_mul_s_scalar,\\\n+\t\t\t   neon_fp_mul_d\")\n+\t    (const_string \"neon_fp_mul\")\n+\t  (eq_attr \"type\" \"neon_fp_mul_s_q, neon_fp_mul_s_scalar_q,\\\n+\t\t\t   neon_fp_mul_d_q, neon_fp_mul_d_scalar_q\")\n+\t    (const_string \"neon_fp_mul_q\")\n+\t  (eq_attr \"type\" \"neon_fp_mla_s, neon_fp_mla_s_scalar,\\\n+\t\t\t   neon_fp_mla_d\")\n+\t    (const_string \"neon_fp_mla\")\n+\t  (eq_attr \"type\" \"neon_fp_mla_s_q, neon_fp_mla_s_scalar_q,\n+\t\t\t   neon_fp_mla_d_q, neon_fp_mla_d_scalar_q\")\n+\t    (const_string \"neon_fp_mla_q\")\n+\t  (eq_attr \"type\" \"neon_fp_recpe_s, neon_fp_rsqrte_s,\\\n+\t\t\t   neon_fp_recpx_s,\\\n+\t\t\t   neon_fp_recpe_d, neon_fp_rsqrte_d,\\\n+\t\t\t   neon_fp_recpx_d\")\n+\t    (const_string \"neon_fp_recpe_rsqrte\")\n+\t  (eq_attr \"type\" \"neon_fp_recpe_s_q, neon_fp_rsqrte_s_q,\\\n+\t\t\t   neon_fp_recpx_s_q,\\\n+\t\t\t   neon_fp_recpe_d_q, neon_fp_rsqrte_d_q,\\\n+\t\t\t   neon_fp_recpx_d_q\")\n+\t    (const_string \"neon_fp_recpe_rsqrte_q\")\n+\t  (eq_attr \"type\" \"neon_fp_recps_s, neon_fp_rsqrts_s,\\\n+\t\t\t   neon_fp_recps_d, neon_fp_rsqrts_d\")\n+\t    (const_string \"neon_fp_recps_rsqrts\")\n+\t  (eq_attr \"type\" \"neon_fp_recps_s_q, neon_fp_rsqrts_s_q,\\\n+\t\t\t   neon_fp_recps_d_q, neon_fp_rsqrts_d_q\")\n+\t    (const_string \"neon_fp_recps_rsqrts_q\")\n+\t  (eq_attr \"type\" \"neon_bsl, neon_cls, neon_cnt,\\\n+\t\t\t   neon_rev, neon_permute, neon_rbit,\\\n+\t\t\t   neon_tbl1, neon_tbl2, neon_zip,\\\n+\t\t\t   neon_dup, neon_dup_q, neon_ext, neon_ext_q,\\\n+\t\t\t   neon_move, neon_move_q, neon_move_narrow_q\")\n+\t    (const_string \"neon_bitops\")\n+\t  (eq_attr \"type\" \"neon_bsl_q, neon_cls_q, neon_cnt_q,\\\n+\t\t\t   neon_rev_q, neon_permute_q, neon_rbit_q\")\n+\t    (const_string \"neon_bitops_q\")\n+\t  (eq_attr \"type\" \"neon_from_gp,f_mcr,f_mcrr\")\n+\t    (const_string \"neon_from_gp\")\n+\t  (eq_attr \"type\" \"neon_from_gp_q\")\n+\t    (const_string \"neon_from_gp_q\")\n+\t  (eq_attr \"type\" \"neon_tbl3, neon_tbl4\")\n+\t    (const_string \"neon_tbl3_tbl4\")\n+\t  (eq_attr \"type\" \"neon_zip_q\")\n+\t    (const_string \"neon_zip_q\")\n+\t  (eq_attr \"type\" \"neon_to_gp, neon_to_gp_q,f_mrc,f_mrrc\")\n+\t    (const_string \"neon_to_gp\")\n+\n+\t  (eq_attr \"type\" \"f_loads, f_loadd,\\\n+\t\t\t   neon_load1_1reg, neon_load1_1reg_q,\\\n+\t\t\t   neon_load1_2reg, neon_load1_2reg_q\")\n+\t    (const_string \"neon_load_a\")\n+\t  (eq_attr \"type\" \"neon_load1_3reg, neon_load1_3reg_q,\\\n+\t\t\t   neon_load1_4reg, neon_load1_4reg_q\")\n+\t    (const_string \"neon_load_b\")\n+\t  (eq_attr \"type\" \"neon_load1_one_lane, neon_load1_one_lane_q,\\\n+\t\t\t   neon_load1_all_lanes, neon_load1_all_lanes_q,\\\n+\t\t\t   neon_load2_2reg, neon_load2_2reg_q,\\\n+\t\t\t   neon_load2_all_lanes, neon_load2_all_lanes_q\")\n+\t    (const_string \"neon_load_c\")\n+\t  (eq_attr \"type\" \"neon_load2_4reg, neon_load2_4reg_q,\\\n+\t\t\t   neon_load3_3reg, neon_load3_3reg_q,\\\n+\t\t\t   neon_load3_one_lane, neon_load3_one_lane_q,\\\n+\t\t\t   neon_load4_4reg, neon_load4_4reg_q\")\n+\t    (const_string \"neon_load_d\")\n+\t  (eq_attr \"type\" \"neon_load2_one_lane, neon_load2_one_lane_q,\\\n+\t\t\t   neon_load3_all_lanes, neon_load3_all_lanes_q,\\\n+\t\t\t   neon_load4_all_lanes, neon_load4_all_lanes_q\")\n+\t    (const_string \"neon_load_e\")\n+\t  (eq_attr \"type\" \"neon_load4_one_lane, neon_load4_one_lane_q\")\n+\t    (const_string \"neon_load_f\")\n+\n+\t  (eq_attr \"type\" \"f_stores, f_stored,\\\n+\t\t\t   neon_store1_1reg\")\n+\t    (const_string \"neon_store_a\")\n+\t  (eq_attr \"type\" \"neon_store1_2reg, neon_store1_1reg_q\")\n+\t    (const_string \"neon_store_b\")\n+\t  (eq_attr \"type\" \"neon_store1_3reg, neon_store1_3reg_q,\\\n+\t\t\t   neon_store3_3reg, neon_store3_3reg_q,\\\n+\t\t\t   neon_store2_4reg, neon_store2_4reg_q,\\\n+\t\t\t   neon_store4_4reg, neon_store4_4reg_q,\\\n+\t\t\t   neon_store2_2reg, neon_store2_2reg_q,\\\n+\t\t\t   neon_store3_one_lane, neon_store3_one_lane_q,\\\n+\t\t\t   neon_store4_one_lane, neon_store4_one_lane_q,\\\n+\t\t\t   neon_store1_4reg, neon_store1_4reg_q,\\\n+\t\t\t   neon_store1_one_lane, neon_store1_one_lane_q,\\\n+\t\t\t   neon_store2_one_lane, neon_store2_one_lane_q\")\n+\t    (const_string \"neon_store_complex\")]\n+\t  (const_string \"unknown\")))\n+\n+;; The Cortex-A57 core is modelled as a triple issue pipeline that has\n+;; the following functional units.\n+;; 1.  Two pipelines for integer operations: SX1, SX2\n+\n+(define_cpu_unit \"ca57_sx1_issue\" \"cortex_a57\")\n+(define_reservation \"ca57_sx1\" \"ca57_sx1_issue\")\n+\n+(define_cpu_unit \"ca57_sx2_issue\" \"cortex_a57\")\n+(define_reservation \"ca57_sx2\" \"ca57_sx2_issue\")\n+\n+;; 2.  One pipeline for complex integer operations: MX\n+\n+(define_cpu_unit \"ca57_mx_issue\"\n+\t\t \"cortex_a57\")\n+(define_reservation \"ca57_mx\" \"ca57_mx_issue\")\n+(define_reservation \"ca57_mx_block\" \"ca57_mx_issue\")\n+\n+;; 3.  Two asymmetric pipelines for Neon and FP operations: CX1, CX2\n+(define_automaton \"cortex_a57_cx\")\n+\n+(define_cpu_unit \"ca57_cx1_issue\"\n+\t\t \"cortex_a57_cx\")\n+(define_cpu_unit \"ca57_cx2_issue\"\n+\t\t \"cortex_a57_cx\")\n+\n+(define_reservation \"ca57_cx1\" \"ca57_cx1_issue\")\n+\n+(define_reservation \"ca57_cx2\" \"ca57_cx2_issue\")\n+(define_reservation \"ca57_cx2_block\" \"ca57_cx2_issue*2\")\n+\n+;; 4.  One pipeline for branch operations: BX\n+\n+(define_cpu_unit \"ca57_bx_issue\" \"cortex_a57\")\n+(define_reservation \"ca57_bx\" \"ca57_bx_issue\")\n+\n+;; 5.  Two pipelines for load and store operations: LS1, LS2.  The most\n+;;     valuable thing we can do is force a structural hazard to split\n+;;     up loads/stores.\n+\n+(define_cpu_unit \"ca57_ls_issue\" \"cortex_a57\")\n+(define_cpu_unit \"ca57_ldr, ca57_str\" \"cortex_a57\")\n+(define_reservation \"ca57_load_model\" \"ca57_ls_issue,ca57_ldr*2\")\n+(define_reservation \"ca57_store_model\" \"ca57_ls_issue,ca57_str\")\n+\n+;; Block all issue queues.\n+\n+(define_reservation \"ca57_block\" \"ca57_cx1_issue + ca57_cx2_issue\n+\t\t\t\t  + ca57_mx_issue + ca57_sx1_issue\n+\t\t\t\t  + ca57_sx2_issue + ca57_ls_issue\")\n+\n+;; Simple Execution Unit:\n+;;\n+;; Simple ALU without shift\n+(define_insn_reservation \"cortex_a57_alu\" 2\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"alu_imm,alus_imm,logic_imm,logics_imm,\\\n+\t\t\talu_sreg,alus_sreg,logic_reg,logics_reg,\\\n+\t\t\tadc_imm,adcs_imm,adc_reg,adcs_reg,\\\n+\t\t\tadr,bfm,clz,rbit,rev,alu_dsp_reg,\\\n+\t\t\tshift_imm,shift_reg,\\\n+\t\t\tmov_imm,mov_reg,\\\n+\t\t\tmvn_imm,mvn_reg,\\\n+\t\t\tmrs,multiple,no_insn\"))\n+  \"ca57_sx1|ca57_sx2\")\n+\n+;; ALU ops with immediate shift\n+(define_insn_reservation \"cortex_a57_alu_shift\" 3\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"extend,\\\n+\t\t\talu_shift_imm,alus_shift_imm,\\\n+\t\t\tcrc,logic_shift_imm,logics_shift_imm,\\\n+\t\t\tmov_shift,mvn_shift\"))\n+  \"ca57_mx\")\n+\n+;; Multi-Cycle Execution Unit:\n+;;\n+;; ALU ops with register controlled shift\n+(define_insn_reservation \"cortex_a57_alu_shift_reg\" 3\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"alu_shift_reg,alus_shift_reg,\\\n+\t\t\tlogic_shift_reg,logics_shift_reg,\\\n+\t\t\tmov_shift_reg,mvn_shift_reg\"))\n+   \"ca57_mx\")\n+\n+;; All multiplies\n+;; TODO: AArch32 and AArch64 have different behaviour\n+(define_insn_reservation \"cortex_a57_mult32\" 3\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (ior (eq_attr \"mul32\" \"yes\")\n+\t    (eq_attr \"mul64\" \"yes\")))\n+  \"ca57_mx\")\n+\n+;; Integer divide\n+(define_insn_reservation \"cortex_a57_div\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"udiv,sdiv\"))\n+  \"ca57_mx_issue,ca57_mx_block*3\")\n+\n+;; Block all issue pipes for a cycle\n+(define_insn_reservation \"cortex_a57_block\" 1\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"block\"))\n+  \"ca57_block\")\n+\n+;; Branch execution Unit\n+;;\n+;; Branches take one issue slot.\n+;; No latency as there is no result\n+(define_insn_reservation \"cortex_a57_branch\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"branch\"))\n+  \"ca57_bx\")\n+\n+;; Load-store execution Unit\n+;;\n+;; Loads of up to two words.\n+(define_insn_reservation \"cortex_a57_load1\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"load_byte,load1,load2\"))\n+  \"ca57_load_model\")\n+\n+;; Loads of three or four words.\n+(define_insn_reservation \"cortex_a57_load3\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"load3,load4\"))\n+  \"ca57_ls_issue*2,ca57_load_model\")\n+\n+;; Stores of up to two words.\n+(define_insn_reservation \"cortex_a57_store1\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"store1,store2\"))\n+  \"ca57_store_model\")\n+\n+;; Stores of three or four words.\n+(define_insn_reservation \"cortex_a57_store3\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"store3,store4\"))\n+  \"ca57_ls_issue*2,ca57_store_model\")\n+\n+;; Advanced SIMD Unit - Integer Arithmetic Instructions.\n+\n+(define_insn_reservation  \"cortex_a57_neon_abd\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_abd\"))\n+  \"ca57_cx1|ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_abd_q\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_abd_q\"))\n+  \"ca57_cx1+ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_aba\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_acc\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_aba_q\" 8\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_acc_q\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_arith_basic\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_basic\"))\n+  \"ca57_cx1|ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_arith_complex\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_complex\"))\n+  \"ca57_cx1|ca57_cx2\")\n+\n+;; Integer Multiply Instructions.\n+\n+(define_insn_reservation \"cortex_a57_neon_multiply\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_multiply\"))\n+  \"ca57_cx1\")\n+\n+(define_insn_reservation \"cortex_a57_neon_multiply_q\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_multiply_q\"))\n+  \"ca57_cx1+(ca57_cx1_issue,ca57_cx1)\")\n+\n+(define_insn_reservation \"cortex_a57_neon_mla\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_mla\"))\n+  \"ca57_cx1\")\n+\n+(define_insn_reservation \"cortex_a57_neon_mla_q\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_mla_q\"))\n+  \"ca57_cx1+(ca57_cx1_issue,ca57_cx1)\")\n+\n+(define_insn_reservation \"cortex_a57_neon_sat_mla_long\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_sat_mla_long\"))\n+  \"ca57_cx1\")\n+\n+;; Integer Shift Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_acc\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_acc\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_imm_basic\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_imm_basic\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_imm_complex\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_imm_complex\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_basic\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_basic\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_basic_q\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_basic_q\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_complex\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_complex\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_complex_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_complex_q\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+;; Floating Point Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_negabs\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_negabs\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_arith\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_arith\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_arith_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_arith_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_reductions_q\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_reductions_q\"))\n+  \"(ca57_cx1+ca57_cx2),(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_cvt_int\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_cvt_int\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_cvt_int_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_cvt_int_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_cvt16\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_cvt16\"))\n+  \"(ca57_cx1_issue+ca57_cx2_issue),(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mul\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mul\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mul_q\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mul_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mla\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mla\"))\n+  \"(ca57_cx1,ca57_cx1)|(ca57_cx2,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mla_q\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mla_q\"))\n+  \"(ca57_cx1+ca57_cx2),(ca57_cx1,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recpe_rsqrte\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recpe_rsqrte\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recpe_rsqrte_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recpe_rsqrte_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recps_rsqrts\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recps_rsqrts\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recps_rsqrts_q\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recps_rsqrts_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+;; Miscellaneous Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_bitops\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_bitops\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_bitops_q\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_bitops_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_from_gp\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_from_gp\"))\n+  \"(ca57_ls_issue+ca57_cx1_issue,ca57_cx1)\n+\t       |(ca57_ls_issue+ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_from_gp_q\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_from_gp_q\"))\n+  \"(ca57_ls_issue+ca57_cx1_issue,ca57_cx1)\n+\t       +(ca57_ls_issue+ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_tbl3_tbl4\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_tbl3_tbl4\"))\n+  \"(ca57_cx1_issue,ca57_cx1)\n+\t       +(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_zip_q\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_zip_q\"))\n+  \"(ca57_cx1_issue,ca57_cx1)\n+\t       +(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_to_gp\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_to_gp\"))\n+  \"((ca57_ls_issue+ca57_sx1_issue),ca57_sx1)\n+   |((ca57_ls_issue+ca57_sx2_issue),ca57_sx2)\")\n+\n+;; Load Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_a\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_a\"))\n+  \"ca57_load_model\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_b\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_b\"))\n+  \"ca57_ls_issue,ca57_ls_issue+ca57_ldr,ca57_ldr*2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_c\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_c\"))\n+  \"ca57_load_model+(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_d\" 11\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_d\"))\n+  \"ca57_cx1_issue+ca57_cx2_issue,\n+   ca57_ls_issue+ca57_ls_issue,ca57_ldr*2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_e\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_e\"))\n+  \"ca57_load_model+(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_f\" 11\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_f\"))\n+  \"ca57_cx1_issue+ca57_cx2_issue,\n+   ca57_ls_issue+ca57_ls_issue,ca57_ldr*2\")\n+\n+;; Store Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_store_a\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_store_a\"))\n+  \"ca57_store_model\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_store_b\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_store_b\"))\n+  \"ca57_store_model\")\n+\n+;; These block issue for a number of cycles proportional to the number\n+;; of 64-bit chunks they will store, we don't attempt to model that\n+;; precisely, treat them as blocking execution for two cycles when\n+;; issued.\n+(define_insn_reservation\n+  \"cortex_a57_neon_store_complex\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_store_complex\"))\n+  \"ca57_block*2\")\n+\n+;; Floating-Point Operations.\n+\n+(define_insn_reservation \"cortex_a57_fp_const\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fconsts,fconstd\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_add_sub\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fadds,faddd\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_mul\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fmuls,fmuld\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_mac\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fmacs,ffmas,fmacd,ffmad\"))\n+  \"(ca57_cx1,nothing,nothing,ca57_cx1) \\\n+   |(ca57_cx2,nothing,nothing,ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_cvt\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"f_cvt,f_cvtf2i,f_cvti2f\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_cmp\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fcmps,fcmpd\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation \"cortex_a57_fp_arith\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"ffariths,ffarithd\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_cpys\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fmov\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_divs\" 12\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fdivs, fsqrts,\\\n+\t\t\tneon_fp_div_s, neon_fp_sqrt_s\"))\n+  \"ca57_cx2_block*5\")\n+\n+(define_insn_reservation \"cortex_a57_fp_divd\" 16\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fdivd, fsqrtd, neon_fp_div_d, neon_fp_sqrt_d\"))\n+  \"ca57_cx2_block*3\")\n+\n+(define_insn_reservation \"cortex_a57_neon_fp_div_q\" 20\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fdivd, fsqrtd,\\\n+\t\t\t neon_fp_div_s_q, neon_fp_div_d_q,\\\n+\t\t\t neon_fp_sqrt_s_q, neon_fp_sqrt_d_q\"))\n+  \"ca57_cx2_block*3\")\n+\n+(define_insn_reservation \"cortex_a57_crypto_simple\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"crypto_aese,crypto_aesmc,crypto_sha1_fast\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation \"cortex_a57_crypto_complex\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"crypto_sha1_slow\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_crypto_xor\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"crypto_sha1_xor\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+;; We lie with calls.  They take up all issue slots, but are otherwise\n+;; not harmful.\n+(define_insn_reservation \"cortex_a57_call\" 1\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"call\"))\n+  \"ca57_sx1_issue+ca57_sx2_issue+ca57_cx1_issue+ca57_cx2_issue\\\n+    +ca57_mx_issue+ca57_bx_issue+ca57_ls_issue\"\n+)\n+\n+;; Simple execution unit bypasses\n+(define_bypass 1 \"cortex_a57_alu\"\n+\t         \"cortex_a57_alu,cortex_a57_alu_shift,cortex_a57_alu_shift_reg\")\n+(define_bypass 2 \"cortex_a57_alu_shift\"\n+\t         \"cortex_a57_alu,cortex_a57_alu_shift,cortex_a57_alu_shift_reg\")\n+(define_bypass 2 \"cortex_a57_alu_shift_reg\"\n+\t         \"cortex_a57_alu,cortex_a57_alu_shift,cortex_a57_alu_shift_reg\")\n+(define_bypass 1 \"cortex_a57_alu\" \"cortex_a57_load1,cortex_a57_load3\")\n+(define_bypass 2 \"cortex_a57_alu_shift\" \"cortex_a57_load1,cortex_a57_load3\")\n+(define_bypass 2 \"cortex_a57_alu_shift_reg\"\n+\t         \"cortex_a57_load1,cortex_a57_load3\")\n+\n+;; An MLA or a MUL can feed a dependent MLA.\n+(define_bypass 5 \"cortex_a57_neon_*mla*,cortex_a57_neon_*mul*\"\n+\t\t \"cortex_a57_neon_*mla*\")\n+\n+(define_bypass 5 \"cortex_a57_fp_mul,cortex_a57_fp_mac\"\n+\t\t \"cortex_a57_fp_mac\")\n+\n+;; We don't need to care about control hazards, either the branch is\n+;; predicted in which case we pay no penalty, or the branch is\n+;; mispredicted in which case instruction scheduling will be unlikely to\n+;; help.\n+(define_bypass 1 \"cortex_a57_*\"\n+\t\t \"cortex_a57_call,cortex_a57_branch\")\n+\n+;; ARM Cortex-A57 pipeline description\n+;; Copyright (C) 2014-2015 Free Software Foundation, Inc.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify it\n+;; under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful, but\n+;; WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+;; General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_automaton \"cortex_a57\")\n+\n+(define_attr \"cortex_a57_neon_type\"\n+  \"neon_abd, neon_abd_q, neon_arith_acc, neon_arith_acc_q,\n+   neon_arith_basic, neon_arith_complex,\n+   neon_reduc_add_acc, neon_multiply, neon_multiply_q,\n+   neon_multiply_long, neon_mla, neon_mla_q, neon_mla_long,\n+   neon_sat_mla_long, neon_shift_acc, neon_shift_imm_basic,\n+   neon_shift_imm_complex,\n+   neon_shift_reg_basic, neon_shift_reg_basic_q, neon_shift_reg_complex,\n+   neon_shift_reg_complex_q, neon_fp_negabs, neon_fp_arith,\n+   neon_fp_arith_q, neon_fp_reductions_q, neon_fp_cvt_int,\n+   neon_fp_cvt_int_q, neon_fp_cvt16, neon_fp_minmax, neon_fp_mul,\n+   neon_fp_mul_q, neon_fp_mla, neon_fp_mla_q, neon_fp_recpe_rsqrte,\n+   neon_fp_recpe_rsqrte_q, neon_fp_recps_rsqrts, neon_fp_recps_rsqrts_q,\n+   neon_bitops, neon_bitops_q, neon_from_gp,\n+   neon_from_gp_q, neon_move, neon_tbl3_tbl4, neon_zip_q, neon_to_gp,\n+   neon_load_a, neon_load_b, neon_load_c, neon_load_d, neon_load_e,\n+   neon_load_f, neon_store_a, neon_store_b, neon_store_complex,\n+   unknown\"\n+  (cond [\n+\t  (eq_attr \"type\" \"neon_abd, neon_abd_long\")\n+\t    (const_string \"neon_abd\")\n+\t  (eq_attr \"type\" \"neon_abd_q\")\n+\t    (const_string \"neon_abd_q\")\n+\t  (eq_attr \"type\" \"neon_arith_acc, neon_reduc_add_acc,\\\n+\t\t\t   neon_reduc_add_acc_q\")\n+\t    (const_string \"neon_arith_acc\")\n+\t  (eq_attr \"type\" \"neon_arith_acc_q\")\n+\t    (const_string \"neon_arith_acc_q\")\n+\t  (eq_attr \"type\" \"neon_add, neon_add_q, neon_add_long,\\\n+\t\t\t   neon_add_widen, neon_neg, neon_neg_q,\\\n+\t\t\t   neon_reduc_add, neon_reduc_add_q,\\\n+\t\t\t   neon_reduc_add_long, neon_sub, neon_sub_q,\\\n+\t\t\t   neon_sub_long, neon_sub_widen, neon_logic,\\\n+\t\t\t   neon_logic_q, neon_tst, neon_tst_q\")\n+\t    (const_string \"neon_arith_basic\")\n+\t  (eq_attr \"type\" \"neon_abs, neon_abs_q, neon_add_halve_narrow_q,\\\n+\t\t\t   neon_add_halve, neon_add_halve_q,\\\n+\t\t\t   neon_sub_halve, neon_sub_halve_q, neon_qabs,\\\n+\t\t\t   neon_qabs_q, neon_qadd, neon_qadd_q, neon_qneg,\\\n+\t\t\t   neon_qneg_q, neon_qsub, neon_qsub_q,\\\n+\t\t\t   neon_sub_halve_narrow_q,\\\n+\t\t\t   neon_compare, neon_compare_q,\\\n+\t\t\t   neon_compare_zero, neon_compare_zero_q,\\\n+\t\t\t   neon_minmax, neon_minmax_q, neon_reduc_minmax,\\\n+\t\t\t   neon_reduc_minmax_q\")\n+\t    (const_string \"neon_arith_complex\")\n+\n+\t  (eq_attr \"type\" \"neon_mul_b, neon_mul_h, neon_mul_s,\\\n+\t\t\t   neon_mul_h_scalar, neon_mul_s_scalar,\\\n+\t\t\t   neon_sat_mul_b, neon_sat_mul_h,\\\n+\t\t\t   neon_sat_mul_s, neon_sat_mul_h_scalar,\\\n+\t\t\t   neon_sat_mul_s_scalar,\\\n+\t\t\t   neon_mul_b_long, neon_mul_h_long,\\\n+\t\t\t   neon_mul_s_long, neon_mul_d_long,\\\n+\t\t\t   neon_mul_h_scalar_long, neon_mul_s_scalar_long,\\\n+\t\t\t   neon_sat_mul_b_long, neon_sat_mul_h_long,\\\n+\t\t\t   neon_sat_mul_s_long, neon_sat_mul_h_scalar_long,\\\n+\t\t\t   neon_sat_mul_s_scalar_long\")\n+\t    (const_string \"neon_multiply\")\n+\t  (eq_attr \"type\" \"neon_mul_b_q, neon_mul_h_q, neon_mul_s_q,\\\n+\t\t\t   neon_mul_h_scalar_q, neon_mul_s_scalar_q,\\\n+\t\t\t   neon_sat_mul_b_q, neon_sat_mul_h_q,\\\n+\t\t\t   neon_sat_mul_s_q, neon_sat_mul_h_scalar_q,\\\n+\t\t\t   neon_sat_mul_s_scalar_q\")\n+\t    (const_string \"neon_multiply_q\")\n+\t  (eq_attr \"type\" \"neon_mla_b, neon_mla_h, neon_mla_s,\\\n+\t\t\t   neon_mla_h_scalar, neon_mla_s_scalar,\\\n+\t\t\t   neon_mla_b_long, neon_mla_h_long,\\\n+\t\t\t   neon_mla_s_long,\\\n+\t\t\t   neon_mla_h_scalar_long, neon_mla_s_scalar_long\")\n+\t    (const_string \"neon_mla\")\n+\t  (eq_attr \"type\" \"neon_mla_b_q, neon_mla_h_q, neon_mla_s_q,\\\n+\t\t\t   neon_mla_h_scalar_q, neon_mla_s_scalar_q\")\n+\t    (const_string \"neon_mla_q\")\n+\t  (eq_attr \"type\" \"neon_sat_mla_b_long, neon_sat_mla_h_long,\\\n+\t\t\t   neon_sat_mla_s_long, neon_sat_mla_h_scalar_long,\\\n+\t\t\t   neon_sat_mla_s_scalar_long\")\n+\t    (const_string \"neon_sat_mla_long\")\n+\n+\t  (eq_attr \"type\" \"neon_shift_acc, neon_shift_acc_q\")\n+\t    (const_string \"neon_shift_acc\")\n+\t  (eq_attr \"type\" \"neon_shift_imm, neon_shift_imm_q,\\\n+\t\t\t   neon_shift_imm_narrow_q, neon_shift_imm_long\")\n+\t    (const_string \"neon_shift_imm_basic\")\n+\t  (eq_attr \"type\" \"neon_sat_shift_imm, neon_sat_shift_imm_q,\\\n+\t\t\t   neon_sat_shift_imm_narrow_q\")\n+\t    (const_string \"neon_shift_imm_complex\")\n+\t  (eq_attr \"type\" \"neon_shift_reg\")\n+\t    (const_string \"neon_shift_reg_basic\")\n+\t  (eq_attr \"type\" \"neon_shift_reg_q\")\n+\t    (const_string \"neon_shift_reg_basic_q\")\n+\t  (eq_attr \"type\" \"neon_sat_shift_reg\")\n+\t    (const_string \"neon_shift_reg_complex\")\n+\t  (eq_attr \"type\" \"neon_sat_shift_reg_q\")\n+\t    (const_string \"neon_shift_reg_complex_q\")\n+\n+\t  (eq_attr \"type\" \"neon_fp_neg_s, neon_fp_neg_s_q,\\\n+\t\t\t   neon_fp_abs_s, neon_fp_abs_s_q,\\\n+\t\t\t   neon_fp_neg_d, neon_fp_neg_d_q,\\\n+\t\t\t   neon_fp_abs_d, neon_fp_abs_d_q\")\n+\t    (const_string \"neon_fp_negabs\")\n+\t  (eq_attr \"type\" \"neon_fp_addsub_s, neon_fp_abd_s,\\\n+\t\t\t   neon_fp_reduc_add_s, neon_fp_compare_s,\\\n+\t\t\t   neon_fp_minmax_s, neon_fp_round_s,\\\n+\t\t\t   neon_fp_addsub_d, neon_fp_abd_d,\\\n+\t\t\t   neon_fp_reduc_add_d, neon_fp_compare_d,\\\n+\t\t\t   neon_fp_minmax_d, neon_fp_round_d,\\\n+\t\t\t   neon_fp_reduc_minmax_s, neon_fp_reduc_minmax_d\")\n+\t    (const_string \"neon_fp_arith\")\n+\t  (eq_attr \"type\" \"neon_fp_addsub_s_q, neon_fp_abd_s_q,\\\n+\t\t\t   neon_fp_reduc_add_s_q, neon_fp_compare_s_q,\\\n+\t\t\t   neon_fp_minmax_s_q, neon_fp_round_s_q,\\\n+\t\t\t   neon_fp_addsub_d_q, neon_fp_abd_d_q,\\\n+\t\t\t   neon_fp_reduc_add_d_q, neon_fp_compare_d_q,\\\n+\t\t\t   neon_fp_minmax_d_q, neon_fp_round_d_q\")\n+\t    (const_string \"neon_fp_arith_q\")\n+\t  (eq_attr \"type\" \"neon_fp_reduc_minmax_s_q,\\\n+\t\t\t   neon_fp_reduc_minmax_d_q,\\\n+\t\t\t   neon_fp_reduc_add_s_q, neon_fp_reduc_add_d_q\")\n+\t    (const_string \"neon_fp_reductions_q\")\n+\t  (eq_attr \"type\" \"neon_fp_to_int_s, neon_int_to_fp_s,\\\n+\t\t\t   neon_fp_to_int_d, neon_int_to_fp_d\")\n+\t    (const_string \"neon_fp_cvt_int\")\n+\t  (eq_attr \"type\" \"neon_fp_to_int_s_q, neon_int_to_fp_s_q,\\\n+\t\t\t   neon_fp_to_int_d_q, neon_int_to_fp_d_q\")\n+\t    (const_string \"neon_fp_cvt_int_q\")\n+\t  (eq_attr \"type\" \"neon_fp_cvt_narrow_s_q, neon_fp_cvt_widen_h\")\n+\t    (const_string \"neon_fp_cvt16\")\n+\t  (eq_attr \"type\" \"neon_fp_mul_s, neon_fp_mul_s_scalar,\\\n+\t\t\t   neon_fp_mul_d\")\n+\t    (const_string \"neon_fp_mul\")\n+\t  (eq_attr \"type\" \"neon_fp_mul_s_q, neon_fp_mul_s_scalar_q,\\\n+\t\t\t   neon_fp_mul_d_q, neon_fp_mul_d_scalar_q\")\n+\t    (const_string \"neon_fp_mul_q\")\n+\t  (eq_attr \"type\" \"neon_fp_mla_s, neon_fp_mla_s_scalar,\\\n+\t\t\t   neon_fp_mla_d\")\n+\t    (const_string \"neon_fp_mla\")\n+\t  (eq_attr \"type\" \"neon_fp_mla_s_q, neon_fp_mla_s_scalar_q,\n+\t\t\t   neon_fp_mla_d_q, neon_fp_mla_d_scalar_q\")\n+\t    (const_string \"neon_fp_mla_q\")\n+\t  (eq_attr \"type\" \"neon_fp_recpe_s, neon_fp_rsqrte_s,\\\n+\t\t\t   neon_fp_recpx_s,\\\n+\t\t\t   neon_fp_recpe_d, neon_fp_rsqrte_d,\\\n+\t\t\t   neon_fp_recpx_d\")\n+\t    (const_string \"neon_fp_recpe_rsqrte\")\n+\t  (eq_attr \"type\" \"neon_fp_recpe_s_q, neon_fp_rsqrte_s_q,\\\n+\t\t\t   neon_fp_recpx_s_q,\\\n+\t\t\t   neon_fp_recpe_d_q, neon_fp_rsqrte_d_q,\\\n+\t\t\t   neon_fp_recpx_d_q\")\n+\t    (const_string \"neon_fp_recpe_rsqrte_q\")\n+\t  (eq_attr \"type\" \"neon_fp_recps_s, neon_fp_rsqrts_s,\\\n+\t\t\t   neon_fp_recps_d, neon_fp_rsqrts_d\")\n+\t    (const_string \"neon_fp_recps_rsqrts\")\n+\t  (eq_attr \"type\" \"neon_fp_recps_s_q, neon_fp_rsqrts_s_q,\\\n+\t\t\t   neon_fp_recps_d_q, neon_fp_rsqrts_d_q\")\n+\t    (const_string \"neon_fp_recps_rsqrts_q\")\n+\t  (eq_attr \"type\" \"neon_bsl, neon_cls, neon_cnt,\\\n+\t\t\t   neon_rev, neon_permute, neon_rbit,\\\n+\t\t\t   neon_tbl1, neon_tbl2, neon_zip,\\\n+\t\t\t   neon_dup, neon_dup_q, neon_ext, neon_ext_q,\\\n+\t\t\t   neon_move, neon_move_q, neon_move_narrow_q\")\n+\t    (const_string \"neon_bitops\")\n+\t  (eq_attr \"type\" \"neon_bsl_q, neon_cls_q, neon_cnt_q,\\\n+\t\t\t   neon_rev_q, neon_permute_q, neon_rbit_q\")\n+\t    (const_string \"neon_bitops_q\")\n+\t  (eq_attr \"type\" \"neon_from_gp,f_mcr,f_mcrr\")\n+\t    (const_string \"neon_from_gp\")\n+\t  (eq_attr \"type\" \"neon_from_gp_q\")\n+\t    (const_string \"neon_from_gp_q\")\n+\t  (eq_attr \"type\" \"neon_tbl3, neon_tbl4\")\n+\t    (const_string \"neon_tbl3_tbl4\")\n+\t  (eq_attr \"type\" \"neon_zip_q\")\n+\t    (const_string \"neon_zip_q\")\n+\t  (eq_attr \"type\" \"neon_to_gp, neon_to_gp_q,f_mrc,f_mrrc\")\n+\t    (const_string \"neon_to_gp\")\n+\n+\t  (eq_attr \"type\" \"f_loads, f_loadd,\\\n+\t\t\t   neon_load1_1reg, neon_load1_1reg_q,\\\n+\t\t\t   neon_load1_2reg, neon_load1_2reg_q\")\n+\t    (const_string \"neon_load_a\")\n+\t  (eq_attr \"type\" \"neon_load1_3reg, neon_load1_3reg_q,\\\n+\t\t\t   neon_load1_4reg, neon_load1_4reg_q\")\n+\t    (const_string \"neon_load_b\")\n+\t  (eq_attr \"type\" \"neon_load1_one_lane, neon_load1_one_lane_q,\\\n+\t\t\t   neon_load1_all_lanes, neon_load1_all_lanes_q,\\\n+\t\t\t   neon_load2_2reg, neon_load2_2reg_q,\\\n+\t\t\t   neon_load2_all_lanes, neon_load2_all_lanes_q\")\n+\t    (const_string \"neon_load_c\")\n+\t  (eq_attr \"type\" \"neon_load2_4reg, neon_load2_4reg_q,\\\n+\t\t\t   neon_load3_3reg, neon_load3_3reg_q,\\\n+\t\t\t   neon_load3_one_lane, neon_load3_one_lane_q,\\\n+\t\t\t   neon_load4_4reg, neon_load4_4reg_q\")\n+\t    (const_string \"neon_load_d\")\n+\t  (eq_attr \"type\" \"neon_load2_one_lane, neon_load2_one_lane_q,\\\n+\t\t\t   neon_load3_all_lanes, neon_load3_all_lanes_q,\\\n+\t\t\t   neon_load4_all_lanes, neon_load4_all_lanes_q\")\n+\t    (const_string \"neon_load_e\")\n+\t  (eq_attr \"type\" \"neon_load4_one_lane, neon_load4_one_lane_q\")\n+\t    (const_string \"neon_load_f\")\n+\n+\t  (eq_attr \"type\" \"f_stores, f_stored,\\\n+\t\t\t   neon_store1_1reg\")\n+\t    (const_string \"neon_store_a\")\n+\t  (eq_attr \"type\" \"neon_store1_2reg, neon_store1_1reg_q\")\n+\t    (const_string \"neon_store_b\")\n+\t  (eq_attr \"type\" \"neon_store1_3reg, neon_store1_3reg_q,\\\n+\t\t\t   neon_store3_3reg, neon_store3_3reg_q,\\\n+\t\t\t   neon_store2_4reg, neon_store2_4reg_q,\\\n+\t\t\t   neon_store4_4reg, neon_store4_4reg_q,\\\n+\t\t\t   neon_store2_2reg, neon_store2_2reg_q,\\\n+\t\t\t   neon_store3_one_lane, neon_store3_one_lane_q,\\\n+\t\t\t   neon_store4_one_lane, neon_store4_one_lane_q,\\\n+\t\t\t   neon_store1_4reg, neon_store1_4reg_q,\\\n+\t\t\t   neon_store1_one_lane, neon_store1_one_lane_q,\\\n+\t\t\t   neon_store2_one_lane, neon_store2_one_lane_q\")\n+\t    (const_string \"neon_store_complex\")]\n+\t  (const_string \"unknown\")))\n+\n+;; The Cortex-A57 core is modelled as a triple issue pipeline that has\n+;; the following functional units.\n+;; 1.  Two pipelines for integer operations: SX1, SX2\n+\n+(define_cpu_unit \"ca57_sx1_issue\" \"cortex_a57\")\n+(define_reservation \"ca57_sx1\" \"ca57_sx1_issue\")\n+\n+(define_cpu_unit \"ca57_sx2_issue\" \"cortex_a57\")\n+(define_reservation \"ca57_sx2\" \"ca57_sx2_issue\")\n+\n+;; 2.  One pipeline for complex integer operations: MX\n+\n+(define_cpu_unit \"ca57_mx_issue\"\n+\t\t \"cortex_a57\")\n+(define_reservation \"ca57_mx\" \"ca57_mx_issue\")\n+(define_reservation \"ca57_mx_block\" \"ca57_mx_issue\")\n+\n+;; 3.  Two asymmetric pipelines for Neon and FP operations: CX1, CX2\n+(define_automaton \"cortex_a57_cx\")\n+\n+(define_cpu_unit \"ca57_cx1_issue\"\n+\t\t \"cortex_a57_cx\")\n+(define_cpu_unit \"ca57_cx2_issue\"\n+\t\t \"cortex_a57_cx\")\n+\n+(define_reservation \"ca57_cx1\" \"ca57_cx1_issue\")\n+\n+(define_reservation \"ca57_cx2\" \"ca57_cx2_issue\")\n+(define_reservation \"ca57_cx2_block\" \"ca57_cx2_issue*2\")\n+\n+;; 4.  One pipeline for branch operations: BX\n+\n+(define_cpu_unit \"ca57_bx_issue\" \"cortex_a57\")\n+(define_reservation \"ca57_bx\" \"ca57_bx_issue\")\n+\n+;; 5.  Two pipelines for load and store operations: LS1, LS2.  The most\n+;;     valuable thing we can do is force a structural hazard to split\n+;;     up loads/stores.\n+\n+(define_cpu_unit \"ca57_ls_issue\" \"cortex_a57\")\n+(define_cpu_unit \"ca57_ldr, ca57_str\" \"cortex_a57\")\n+(define_reservation \"ca57_load_model\" \"ca57_ls_issue,ca57_ldr*2\")\n+(define_reservation \"ca57_store_model\" \"ca57_ls_issue,ca57_str\")\n+\n+;; Block all issue queues.\n+\n+(define_reservation \"ca57_block\" \"ca57_cx1_issue + ca57_cx2_issue\n+\t\t\t\t  + ca57_mx_issue + ca57_sx1_issue\n+\t\t\t\t  + ca57_sx2_issue + ca57_ls_issue\")\n+\n+;; Simple Execution Unit:\n+;;\n+;; Simple ALU without shift\n+(define_insn_reservation \"cortex_a57_alu\" 2\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"alu_imm,alus_imm,logic_imm,logics_imm,\\\n+\t\t\talu_sreg,alus_sreg,logic_reg,logics_reg,\\\n+\t\t\tadc_imm,adcs_imm,adc_reg,adcs_reg,\\\n+\t\t\tadr,bfm,clz,rbit,rev,alu_dsp_reg,\\\n+\t\t\tshift_imm,shift_reg,\\\n+\t\t\tmov_imm,mov_reg,\\\n+\t\t\tmvn_imm,mvn_reg,\\\n+\t\t\tmrs,multiple,no_insn\"))\n+  \"ca57_sx1|ca57_sx2\")\n+\n+;; ALU ops with immediate shift\n+(define_insn_reservation \"cortex_a57_alu_shift\" 3\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"extend,\\\n+\t\t\talu_shift_imm,alus_shift_imm,\\\n+\t\t\tcrc,logic_shift_imm,logics_shift_imm,\\\n+\t\t\tmov_shift,mvn_shift\"))\n+  \"ca57_mx\")\n+\n+;; Multi-Cycle Execution Unit:\n+;;\n+;; ALU ops with register controlled shift\n+(define_insn_reservation \"cortex_a57_alu_shift_reg\" 3\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"alu_shift_reg,alus_shift_reg,\\\n+\t\t\tlogic_shift_reg,logics_shift_reg,\\\n+\t\t\tmov_shift_reg,mvn_shift_reg\"))\n+   \"ca57_mx\")\n+\n+;; All multiplies\n+;; TODO: AArch32 and AArch64 have different behaviour\n+(define_insn_reservation \"cortex_a57_mult32\" 3\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (ior (eq_attr \"mul32\" \"yes\")\n+\t    (eq_attr \"mul64\" \"yes\")))\n+  \"ca57_mx\")\n+\n+;; Integer divide\n+(define_insn_reservation \"cortex_a57_div\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"udiv,sdiv\"))\n+  \"ca57_mx_issue,ca57_mx_block*3\")\n+\n+;; Block all issue pipes for a cycle\n+(define_insn_reservation \"cortex_a57_block\" 1\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"block\"))\n+  \"ca57_block\")\n+\n+;; Branch execution Unit\n+;;\n+;; Branches take one issue slot.\n+;; No latency as there is no result\n+(define_insn_reservation \"cortex_a57_branch\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"branch\"))\n+  \"ca57_bx\")\n+\n+;; Load-store execution Unit\n+;;\n+;; Loads of up to two words.\n+(define_insn_reservation \"cortex_a57_load1\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"load_byte,load1,load2\"))\n+  \"ca57_load_model\")\n+\n+;; Loads of three or four words.\n+(define_insn_reservation \"cortex_a57_load3\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"load3,load4\"))\n+  \"ca57_ls_issue*2,ca57_load_model\")\n+\n+;; Stores of up to two words.\n+(define_insn_reservation \"cortex_a57_store1\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"store1,store2\"))\n+  \"ca57_store_model\")\n+\n+;; Stores of three or four words.\n+(define_insn_reservation \"cortex_a57_store3\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"store3,store4\"))\n+  \"ca57_ls_issue*2,ca57_store_model\")\n+\n+;; Advanced SIMD Unit - Integer Arithmetic Instructions.\n+\n+(define_insn_reservation  \"cortex_a57_neon_abd\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_abd\"))\n+  \"ca57_cx1|ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_abd_q\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_abd_q\"))\n+  \"ca57_cx1+ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_aba\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_acc\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_aba_q\" 8\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_acc_q\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_arith_basic\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_basic\"))\n+  \"ca57_cx1|ca57_cx2\")\n+\n+(define_insn_reservation  \"cortex_a57_neon_arith_complex\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_arith_complex\"))\n+  \"ca57_cx1|ca57_cx2\")\n+\n+;; Integer Multiply Instructions.\n+\n+(define_insn_reservation \"cortex_a57_neon_multiply\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_multiply\"))\n+  \"ca57_cx1\")\n+\n+(define_insn_reservation \"cortex_a57_neon_multiply_q\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_multiply_q\"))\n+  \"ca57_cx1+(ca57_cx1_issue,ca57_cx1)\")\n+\n+(define_insn_reservation \"cortex_a57_neon_mla\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_mla\"))\n+  \"ca57_cx1\")\n+\n+(define_insn_reservation \"cortex_a57_neon_mla_q\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_mla_q\"))\n+  \"ca57_cx1+(ca57_cx1_issue,ca57_cx1)\")\n+\n+(define_insn_reservation \"cortex_a57_neon_sat_mla_long\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_sat_mla_long\"))\n+  \"ca57_cx1\")\n+\n+;; Integer Shift Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_acc\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_acc\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_imm_basic\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_imm_basic\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_imm_complex\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_imm_complex\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_basic\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_basic\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_basic_q\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_basic_q\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_complex\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_complex\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_shift_reg_complex_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_shift_reg_complex_q\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+;; Floating Point Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_negabs\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_negabs\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_arith\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_arith\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_arith_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_arith_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_reductions_q\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_reductions_q\"))\n+  \"(ca57_cx1+ca57_cx2),(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_cvt_int\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_cvt_int\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_cvt_int_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_cvt_int_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_cvt16\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_cvt16\"))\n+  \"(ca57_cx1_issue+ca57_cx2_issue),(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mul\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mul\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mul_q\" 5\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mul_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mla\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mla\"))\n+  \"(ca57_cx1,ca57_cx1)|(ca57_cx2,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_mla_q\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_mla_q\"))\n+  \"(ca57_cx1+ca57_cx2),(ca57_cx1,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recpe_rsqrte\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recpe_rsqrte\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recpe_rsqrte_q\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recpe_rsqrte_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recps_rsqrts\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recps_rsqrts\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_fp_recps_rsqrts_q\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_fp_recps_rsqrts_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+;; Miscellaneous Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_bitops\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_bitops\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_bitops_q\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_bitops_q\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_from_gp\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_from_gp\"))\n+  \"(ca57_ls_issue+ca57_cx1_issue,ca57_cx1)\n+\t       |(ca57_ls_issue+ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_from_gp_q\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_from_gp_q\"))\n+  \"(ca57_ls_issue+ca57_cx1_issue,ca57_cx1)\n+\t       +(ca57_ls_issue+ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_tbl3_tbl4\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_tbl3_tbl4\"))\n+  \"(ca57_cx1_issue,ca57_cx1)\n+\t       +(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_zip_q\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_zip_q\"))\n+  \"(ca57_cx1_issue,ca57_cx1)\n+\t       +(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_to_gp\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_to_gp\"))\n+  \"((ca57_ls_issue+ca57_sx1_issue),ca57_sx1)\n+   |((ca57_ls_issue+ca57_sx2_issue),ca57_sx2)\")\n+\n+;; Load Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_a\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_a\"))\n+  \"ca57_load_model\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_b\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_b\"))\n+  \"ca57_ls_issue,ca57_ls_issue+ca57_ldr,ca57_ldr*2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_c\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_c\"))\n+  \"ca57_load_model+(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_d\" 11\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_d\"))\n+  \"ca57_cx1_issue+ca57_cx2_issue,\n+   ca57_ls_issue+ca57_ls_issue,ca57_ldr*2\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_e\" 9\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_e\"))\n+  \"ca57_load_model+(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_load_f\" 11\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_load_f\"))\n+  \"ca57_cx1_issue+ca57_cx2_issue,\n+   ca57_ls_issue+ca57_ls_issue,ca57_ldr*2\")\n+\n+;; Store Instructions.\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_store_a\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_store_a\"))\n+  \"ca57_store_model\")\n+\n+(define_insn_reservation\n+  \"cortex_a57_neon_store_b\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_store_b\"))\n+  \"ca57_store_model\")\n+\n+;; These block issue for a number of cycles proportional to the number\n+;; of 64-bit chunks they will store, we don't attempt to model that\n+;; precisely, treat them as blocking execution for two cycles when\n+;; issued.\n+(define_insn_reservation\n+  \"cortex_a57_neon_store_complex\" 0\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"cortex_a57_neon_type\" \"neon_store_complex\"))\n+  \"ca57_block*2\")\n+\n+;; Floating-Point Operations.\n+\n+(define_insn_reservation \"cortex_a57_fp_const\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fconsts,fconstd\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_add_sub\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fadds,faddd\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_mul\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fmuls,fmuld\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_mac\" 10\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fmacs,ffmas,fmacd,ffmad\"))\n+  \"(ca57_cx1,nothing,nothing,ca57_cx1) \\\n+   |(ca57_cx2,nothing,nothing,ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_cvt\" 6\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"f_cvt,f_cvtf2i,f_cvti2f\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_cmp\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fcmps,fcmpd\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation \"cortex_a57_fp_arith\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"ffariths,ffarithd\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_cpys\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fmov\"))\n+  \"(ca57_cx1|ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_fp_divs\" 12\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fdivs, fsqrts,\\\n+\t\t\tneon_fp_div_s, neon_fp_sqrt_s\"))\n+  \"ca57_cx2_block*5\")\n+\n+(define_insn_reservation \"cortex_a57_fp_divd\" 16\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fdivd, fsqrtd, neon_fp_div_d, neon_fp_sqrt_d\"))\n+  \"ca57_cx2_block*3\")\n+\n+(define_insn_reservation \"cortex_a57_neon_fp_div_q\" 20\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"fdivd, fsqrtd,\\\n+\t\t\t neon_fp_div_s_q, neon_fp_div_d_q,\\\n+\t\t\t neon_fp_sqrt_s_q, neon_fp_sqrt_d_q\"))\n+  \"ca57_cx2_block*3\")\n+\n+(define_insn_reservation \"cortex_a57_crypto_simple\" 4\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"crypto_aese,crypto_aesmc,crypto_sha1_fast\"))\n+  \"ca57_cx2\")\n+\n+(define_insn_reservation \"cortex_a57_crypto_complex\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"crypto_sha1_slow\"))\n+  \"ca57_cx2+(ca57_cx2_issue,ca57_cx2)\")\n+\n+(define_insn_reservation \"cortex_a57_crypto_xor\" 7\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"crypto_sha1_xor\"))\n+  \"(ca57_cx1+ca57_cx2)\")\n+\n+;; We lie with calls.  They take up all issue slots, but are otherwise\n+;; not harmful.\n+(define_insn_reservation \"cortex_a57_call\" 1\n+  (and (eq_attr \"tune\" \"cortexa57\")\n+       (eq_attr \"type\" \"call\"))\n+  \"ca57_sx1_issue+ca57_sx2_issue+ca57_cx1_issue+ca57_cx2_issue\\\n+    +ca57_mx_issue+ca57_bx_issue+ca57_ls_issue\"\n+)\n+\n+;; Simple execution unit bypasses\n+(define_bypass 1 \"cortex_a57_alu\"\n+\t         \"cortex_a57_alu,cortex_a57_alu_shift,cortex_a57_alu_shift_reg\")\n+(define_bypass 2 \"cortex_a57_alu_shift\"\n+\t         \"cortex_a57_alu,cortex_a57_alu_shift,cortex_a57_alu_shift_reg\")\n+(define_bypass 2 \"cortex_a57_alu_shift_reg\"\n+\t         \"cortex_a57_alu,cortex_a57_alu_shift,cortex_a57_alu_shift_reg\")\n+(define_bypass 1 \"cortex_a57_alu\" \"cortex_a57_load1,cortex_a57_load3\")\n+(define_bypass 2 \"cortex_a57_alu_shift\" \"cortex_a57_load1,cortex_a57_load3\")\n+(define_bypass 2 \"cortex_a57_alu_shift_reg\"\n+\t         \"cortex_a57_load1,cortex_a57_load3\")\n+\n+;; An MLA or a MUL can feed a dependent MLA.\n+(define_bypass 5 \"cortex_a57_neon_*mla*,cortex_a57_neon_*mul*\"\n+\t\t \"cortex_a57_neon_*mla*\")\n+\n+(define_bypass 5 \"cortex_a57_fp_mul,cortex_a57_fp_mac\"\n+\t\t \"cortex_a57_fp_mac\")\n+\n+;; We don't need to care about control hazards, either the branch is\n+;; predicted in which case we pay no penalty, or the branch is\n+;; mispredicted in which case instruction scheduling will be unlikely to\n+;; help.\n+(define_bypass 1 \"cortex_a57_*\"\n+\t\t \"cortex_a57_call,cortex_a57_branch\")\n+"}]}