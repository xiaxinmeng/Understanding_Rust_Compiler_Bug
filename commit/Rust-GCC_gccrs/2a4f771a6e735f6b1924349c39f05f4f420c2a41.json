{"sha": "2a4f771a6e735f6b1924349c39f05f4f420c2a41", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MmE0Zjc3MWE2ZTczNWY2YjE5MjQzNDljMzlmMDVmNGY0MjBjMmE0MQ==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2006-12-20T20:46:15Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2006-12-20T20:46:15Z"}, "message": "re PR rtl-optimization/30213 (Wrong code with optimized memset() (possible bug in RTL bbro optimizer))\n\n\tPR target/30213\n\t* i386.c (expand_setmem_epilogue): Fix formating.\n\t(dsmalest_pow2_greater_than): New function.\n\t(ix86_expand_movmem): Improve comments; avoid re-computing of\n\tepilogue size.\n\t(promote_duplicated_reg_to_size): Break out from ...\n\t(expand_setmem): ... this one; reorganize promotion code;\n\timprove comments; avoid recomputation of epilogue size.\n\nFrom-SVN: r120083", "tree": {"sha": "391ddf419840ba85f6d4c66c576620192d6584b6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/391ddf419840ba85f6d4c66c576620192d6584b6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2a4f771a6e735f6b1924349c39f05f4f420c2a41", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2a4f771a6e735f6b1924349c39f05f4f420c2a41", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2a4f771a6e735f6b1924349c39f05f4f420c2a41", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2a4f771a6e735f6b1924349c39f05f4f420c2a41/comments", "author": null, "committer": null, "parents": [{"sha": "75a4c3c194dda02369ca0b8ebcfe9f962f01dd02", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/75a4c3c194dda02369ca0b8ebcfe9f962f01dd02", "html_url": "https://github.com/Rust-GCC/gccrs/commit/75a4c3c194dda02369ca0b8ebcfe9f962f01dd02"}], "stats": {"total": 198, "additions": 148, "deletions": 50}, "files": [{"sha": "797cecf7a7f359577683702ab4c08e1d5f546ebb", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a4f771a6e735f6b1924349c39f05f4f420c2a41/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a4f771a6e735f6b1924349c39f05f4f420c2a41/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=2a4f771a6e735f6b1924349c39f05f4f420c2a41", "patch": "@@ -1,3 +1,14 @@\n+2006-12-20  Jan Hubicka  <jh@suse.cz>\n+\n+\tPR target/30213\n+\t* i386.c (expand_setmem_epilogue): Fix formating.\n+\t(dsmalest_pow2_greater_than): New function.\n+\t(ix86_expand_movmem): Improve comments; avoid re-computing of\n+\tepilogue size.\n+\t(promote_duplicated_reg_to_size): Break out from ...\n+\t(expand_setmem): ... this one; reorganize promotion code;\n+\timprove comments; avoid recomputation of epilogue size.\n+\n 2006-12-20  Andrew Pinski  <pinskia@gmail.com>\n \n \tPR middle-end/30143"}, {"sha": "ee0cdf4de52a89f529afffaf0678a83385442bd1", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 137, "deletions": 50, "changes": 187, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a4f771a6e735f6b1924349c39f05f4f420c2a41/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a4f771a6e735f6b1924349c39f05f4f420c2a41/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=2a4f771a6e735f6b1924349c39f05f4f420c2a41", "patch": "@@ -13159,6 +13159,7 @@ static void\n expand_setmem_epilogue (rtx destmem, rtx destptr, rtx value, rtx count, int max_size)\n {\n   rtx dest;\n+\n   if (GET_CODE (count) == CONST_INT)\n     {\n       HOST_WIDE_INT countval = INTVAL (count);\n@@ -13491,8 +13492,40 @@ decide_alignment (int align,\n   return desired_align;\n }\n \n+/* Return thre smallest power of 2 greater than VAL.  */\n+static int\n+smallest_pow2_greater_than (int val)\n+{\n+  int ret = 1;\n+  while (ret <= val)\n+    ret <<= 1;\n+  return ret;\n+}\n+\n /* Expand string move (memcpy) operation.  Use i386 string operations when\n-   profitable.  expand_clrmem contains similar code.  */\n+   profitable.  expand_clrmem contains similar code. The code depends upon\n+   architecture, block size and alignment, but always has the same\n+   overall structure:\n+\n+   1) Prologue guard: Conditional that jumps up to epilogues for small\n+      blocks that can be handled by epilogue alone.  This is faster but\n+      also needed for correctness, since prologue assume the block is larger\n+      than the desrired alignment.\n+\n+      Optional dynamic check for size and libcall for large\n+      blocks is emitted here too, with -minline-stringops-dynamically.\n+\n+   2) Prologue: copy first few bytes in order to get destination aligned\n+      to DESIRED_ALIGN.  It is emitted only when ALIGN is less than\n+      DESIRED_ALIGN and and up to DESIRED_ALIGN - ALIGN bytes can be copied.\n+      We emit either a jump tree on power of two sized blocks, or a byte loop.\n+\n+   3) Main body: the copying loop itself, copying in SIZE_NEEDED chunks\n+      with specified algorithm.\n+\n+   4) Epilogue: code copying tail of the block that is too small to be\n+      handled by main body (or up to size guarded by prologue guard).  */\n+   \n int\n ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n \t\t    rtx expected_align_exp, rtx expected_size_exp)\n@@ -13505,7 +13538,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n   HOST_WIDE_INT align = 1;\n   unsigned HOST_WIDE_INT count = 0;\n   HOST_WIDE_INT expected_size = -1;\n-  int size_needed = 0;\n+  int size_needed = 0, epilogue_size_needed;\n   int desired_align = 0;\n   enum stringop_alg alg;\n   int dynamic_check;\n@@ -13519,9 +13552,10 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n   if (GET_CODE (count_exp) == CONST_INT)\n     count = expected_size = INTVAL (count_exp);\n   if (GET_CODE (expected_size_exp) == CONST_INT && count == 0)\n-    {\n-      expected_size = INTVAL (expected_size_exp);\n-    }\n+    expected_size = INTVAL (expected_size_exp);\n+\n+  /* Step 0: Decide on preferred algorithm, desired alignment and\n+     size of chunks to be copied by main loop.  */\n \n   alg = decide_alg (count, expected_size, false, &dynamic_check);\n   desired_align = decide_alignment (align, alg, expected_size);\n@@ -13559,6 +13593,10 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n       break;\n     }\n \n+  epilogue_size_needed = size_needed;\n+\n+  /* Step 1: Prologue guard.  */\n+\n   /* Alignment code needs count to be in register.  */\n   if (GET_CODE (count_exp) == CONST_INT && desired_align > align)\n     {\n@@ -13568,17 +13606,22 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n       count_exp = force_reg (mode, count_exp);\n     }\n   gcc_assert (desired_align >= 1 && align >= 1);\n+\n   /* Ensure that alignment prologue won't copy past end of block.  */\n   if ((size_needed > 1 || (desired_align > 1 && desired_align > align))\n       && !count)\n     {\n-      int size = MAX (size_needed - 1, desired_align - align);\n+      epilogue_size_needed = MAX (size_needed - 1, desired_align - align);\n+\n+      /* Epilogue always copies COUNT_EXP & EPILOGUE_SIZE_NEEDED bytes.\n+\t Make sure it is power of 2.  */\n+      epilogue_size_needed = smallest_pow2_greater_than (epilogue_size_needed);\n \n       label = gen_label_rtx ();\n       emit_cmp_and_jump_insns (count_exp,\n-\t\t\t       GEN_INT (size),\n-\t\t\t       LEU, 0, GET_MODE (count_exp), 1, label);\n-      if (expected_size == -1 || expected_size < size)\n+\t\t\t       GEN_INT (epilogue_size_needed),\n+\t\t\t       LTU, 0, GET_MODE (count_exp), 1, label);\n+      if (expected_size == -1 || expected_size < epilogue_size_needed)\n \tpredict_jump (REG_BR_PROB_BASE * 60 / 100);\n       else\n \tpredict_jump (REG_BR_PROB_BASE * 20 / 100);\n@@ -13597,8 +13640,8 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n       emit_label (hot_label);\n     }\n \n+  /* Step 2: Alignment prologue.  */\n \n-  /* Alignment prologue.  */\n   if (desired_align > align)\n     {\n       /* Except for the first move in epilogue, we no longer know\n@@ -13617,7 +13660,8 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n       label = NULL;\n     }\n \n-  /* Main body.  */\n+  /* Step 3: Main loop.  */\n+\n   switch (alg)\n     {\n     case libcall:\n@@ -13665,25 +13709,31 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n       dst = change_address (dst, BLKmode, destreg);\n     }\n \n-  /* Epilogue to copy the remaining bytes.  */\n+  /* Step 4: Epilogue to copy the remaining bytes.  */\n+\n   if (label)\n     {\n-      if (size_needed < desired_align - align)\n+      /* When the main loop is done, COUNT_EXP might hold original count,\n+ \t while we want to copy only COUNT_EXP & SIZE_NEEDED bytes.\n+\t Epilogue code will actually copy COUNT_EXP & EPILOGUE_SIZE_NEEDED\n+\t bytes. Compensate if needed.  */\n+\t \n+      if (size_needed < epilogue_size_needed)\n \t{\n \t  tmp =\n \t    expand_simple_binop (GET_MODE (count_exp), AND, count_exp,\n \t\t\t\t GEN_INT (size_needed - 1), count_exp, 1,\n \t\t\t\t OPTAB_DIRECT);\n-\t  size_needed = desired_align - align + 1;\n \t  if (tmp != count_exp)\n \t    emit_move_insn (count_exp, tmp);\n \t}\n       emit_label (label);\n       LABEL_NUSES (label) = 1;\n     }\n-  if (count_exp != const0_rtx && size_needed > 1)\n+\n+  if (count_exp != const0_rtx && epilogue_size_needed > 1)\n     expand_movmem_epilogue (dst, src, destreg, srcreg, count_exp,\n-\t\t\t    size_needed);\n+\t\t\t    epilogue_size_needed);\n   if (jump_around_label)\n     emit_label (jump_around_label);\n   return 1;\n@@ -13761,8 +13811,30 @@ promote_duplicated_reg (enum machine_mode mode, rtx val)\n     }\n }\n \n+/* Duplicate value VAL using promote_duplicated_reg into maximal size that will\n+   be needed by main loop copying SIZE_NEEDED chunks and prologue getting\n+   alignment from ALIGN to DESIRED_ALIGN.  */\n+static rtx\n+promote_duplicated_reg_to_size (rtx val, int size_needed, int desired_align, int align)\n+{\n+  rtx promoted_val;\n+\n+  if (TARGET_64BIT\n+      && (size_needed > 4 || (desired_align > align && desired_align > 4)))\n+    promoted_val = promote_duplicated_reg (DImode, val);\n+  else if (size_needed > 2 || (desired_align > align && desired_align > 2))\n+    promoted_val = promote_duplicated_reg (SImode, val);\n+  else if (size_needed > 1 || (desired_align > align && desired_align > 1))\n+    promoted_val = promote_duplicated_reg (HImode, val);\n+  else\n+    promoted_val = val;\n+\n+  return promoted_val;\n+}\n+\n /* Expand string clear operation (bzero).  Use i386 string operations when\n-   profitable.  expand_movmem contains similar code.  */\n+   profitable.  See expand_movmem comment for explanation of individual\n+   steps performd.  */\n int\n ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n \t\t    rtx expected_align_exp, rtx expected_size_exp)\n@@ -13774,10 +13846,10 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n   HOST_WIDE_INT align = 1;\n   unsigned HOST_WIDE_INT count = 0;\n   HOST_WIDE_INT expected_size = -1;\n-  int size_needed = 0;\n+  int size_needed = 0, epilogue_size_needed;\n   int desired_align = 0;\n   enum stringop_alg alg;\n-  rtx promoted_val = val_exp;\n+  rtx promoted_val = NULL;\n   bool force_loopy_epilogue = false;\n   int dynamic_check;\n \n@@ -13792,6 +13864,9 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n   if (GET_CODE (expected_size_exp) == CONST_INT && count == 0)\n     expected_size = INTVAL (expected_size_exp);\n \n+  /* Step 0: Decide on preferred algorithm, desired alignment and\n+     size of chunks to be copied by main loop.  */\n+\n   alg = decide_alg (count, expected_size, true, &dynamic_check);\n   desired_align = decide_alignment (align, alg, expected_size);\n \n@@ -13826,6 +13901,10 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n       size_needed = 1;\n       break;\n     }\n+  epilogue_size_needed = size_needed;\n+\n+  /* Step 1: Prologue guard.  */\n+\n   /* Alignment code needs count to be in register.  */\n   if (GET_CODE (count_exp) == CONST_INT && desired_align > align)\n     {\n@@ -13834,20 +13913,33 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n \tmode = DImode;\n       count_exp = force_reg (mode, count_exp);\n     }\n+  /* Do the cheap promotion to allow better CSE across the \n+     main loop and epilogue (ie one load of the big constant in the\n+     front of all code.  */\n+  if (GET_CODE (val_exp) == CONST_INT)\n+    promoted_val = promote_duplicated_reg_to_size (val_exp, size_needed,\n+\t\t\t\t\t\t   desired_align, align);\n   /* Ensure that alignment prologue won't copy past end of block.  */\n   if ((size_needed > 1 || (desired_align > 1 && desired_align > align))\n       && !count)\n     {\n-      int size = MAX (size_needed - 1, desired_align - align);\n-      /* To improve performance of small blocks, we jump around the promoting\n-         code, so we need to use QImode accesses in epilogue.  */\n-      if (GET_CODE (val_exp) != CONST_INT && size_needed > 1)\n-\tforce_loopy_epilogue = true;\n+      epilogue_size_needed = MAX (size_needed - 1, desired_align - align);\n+\n+      /* Epilogue always copies COUNT_EXP & EPILOGUE_SIZE_NEEDED bytes.\n+\t Make sure it is power of 2.  */\n+      epilogue_size_needed = smallest_pow2_greater_than (epilogue_size_needed);\n+\n+      /* To improve performance of small blocks, we jump around the VAL\n+\t promoting mode.  This mean that if the promoted VAL is not constant,\n+\t we might not use it in the epilogue and have to use byte\n+\t loop variant.  */\n+      if (epilogue_size_needed > 2 && !promoted_val)\n+        force_loopy_epilogue = true;\n       label = gen_label_rtx ();\n       emit_cmp_and_jump_insns (count_exp,\n-\t\t\t       GEN_INT (size),\n-\t\t\t       LEU, 0, GET_MODE (count_exp), 1, label);\n-      if (expected_size == -1 || expected_size <= size)\n+\t\t\t       GEN_INT (epilogue_size_needed),\n+\t\t\t       LTU, 0, GET_MODE (count_exp), 1, label);\n+      if (expected_size == -1 || expected_size <= epilogue_size_needed)\n \tpredict_jump (REG_BR_PROB_BASE * 60 / 100);\n       else\n \tpredict_jump (REG_BR_PROB_BASE * 20 / 100);\n@@ -13863,30 +13955,15 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n       emit_jump (jump_around_label);\n       emit_label (hot_label);\n     }\n-  if (TARGET_64BIT\n-      && (size_needed > 4 || (desired_align > align && desired_align > 4)))\n-    promoted_val = promote_duplicated_reg (DImode, val_exp);\n-  else if (size_needed > 2 || (desired_align > align && desired_align > 2))\n-    promoted_val = promote_duplicated_reg (SImode, val_exp);\n-  else if (size_needed > 1 || (desired_align > align && desired_align > 1))\n-    promoted_val = promote_duplicated_reg (HImode, val_exp);\n-  else\n-    promoted_val = val_exp;\n+\n+  /* Step 2: Alignment prologue.  */\n+\n+  /* Do the expensive promotion once we branched off the small blocks.  */\n+  if (!promoted_val)\n+    promoted_val = promote_duplicated_reg_to_size (val_exp, size_needed,\n+\t\t\t\t\t\t   desired_align, align);\n   gcc_assert (desired_align >= 1 && align >= 1);\n-  if ((size_needed > 1 || (desired_align > 1 && desired_align > align))\n-      && !count && !label)\n-    {\n-      int size = MAX (size_needed - 1, desired_align - align);\n \n-      label = gen_label_rtx ();\n-      emit_cmp_and_jump_insns (count_exp,\n-\t\t\t       GEN_INT (size),\n-\t\t\t       LEU, 0, GET_MODE (count_exp), 1, label);\n-      if (expected_size == -1 || expected_size <= size)\n-\tpredict_jump (REG_BR_PROB_BASE * 60 / 100);\n-      else\n-\tpredict_jump (REG_BR_PROB_BASE * 20 / 100);\n-    }\n   if (desired_align > align)\n     {\n       /* Except for the first move in epilogue, we no longer know\n@@ -13903,6 +13980,9 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n       LABEL_NUSES (label) = 1;\n       label = NULL;\n     }\n+\n+  /* Step 3: Main loop.  */\n+\n   switch (alg)\n     {\n     case libcall:\n@@ -13940,8 +14020,15 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n   else\n     dst = change_address (dst, BLKmode, destreg);\n \n+  /* Step 4: Epilogue to copy the remaining bytes.  */\n+\n   if (label)\n     {\n+      /* When the main loop is done, COUNT_EXP might hold original count,\n+ \t while we want to copy only COUNT_EXP & SIZE_NEEDED bytes.\n+\t Epilogue code will actually copy COUNT_EXP & EPILOGUE_SIZE_NEEDED\n+\t bytes. Compensate if needed.  */\n+\n       if (size_needed < desired_align - align)\n \t{\n \t  tmp =\n@@ -13955,7 +14042,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n       emit_label (label);\n       LABEL_NUSES (label) = 1;\n     }\n-  if (count_exp != const0_rtx && size_needed > 1)\n+  if (count_exp != const0_rtx && epilogue_size_needed > 1)\n     {\n       if (force_loopy_epilogue)\n \texpand_setmem_epilogue_via_loop (dst, destreg, val_exp, count_exp,"}]}