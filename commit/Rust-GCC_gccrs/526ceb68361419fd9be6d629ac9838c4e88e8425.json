{"sha": "526ceb68361419fd9be6d629ac9838c4e88e8425", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTI2Y2ViNjgzNjE0MTlmZDliZTZkNjI5YWM5ODM4YzRlODhlODQyNQ==", "commit": {"author": {"name": "Trevor Saunders", "email": "tbsaunde+gcc@tbsaunde.org", "date": "2015-10-01T15:12:31Z"}, "committer": {"name": "Trevor Saunders", "email": "tbsaunde@gcc.gnu.org", "date": "2015-10-01T15:12:31Z"}, "message": "remove many typedefs\n\ngcc/ChangeLog:\n\n2015-10-01  Trevor Saunders  <tbsaunde+gcc@tbsaunde.org>\n\n\t* cfganal.c, compare-elim.c, coverage.c, cprop.c, df-scan.c,\n\tfunction.c, read-rtl.c, statistics.c, trans-mem.c, tree-if-conv.c,\n\ttree-into-ssa.c, tree-loop-distribution.c, tree-ssa-coalesce.c,\n\ttree-ssa-loop-ivopts.c, tree-ssa-reassoc.c, tree-ssa-strlen.c,\n\ttree-ssa-tail-merge.c, tree-vrp.c, var-tracking.c: Remove\nunneeded typedefs.\n\nFrom-SVN: r228344", "tree": {"sha": "642d211297defb60131bfbbe916e43ab1da041fc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/642d211297defb60131bfbbe916e43ab1da041fc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/526ceb68361419fd9be6d629ac9838c4e88e8425", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/526ceb68361419fd9be6d629ac9838c4e88e8425", "html_url": "https://github.com/Rust-GCC/gccrs/commit/526ceb68361419fd9be6d629ac9838c4e88e8425", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/526ceb68361419fd9be6d629ac9838c4e88e8425/comments", "author": null, "committer": null, "parents": [{"sha": "f6f69fb09c5f81dff3b9edcd03f5107d96e10a55", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f6f69fb09c5f81dff3b9edcd03f5107d96e10a55", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f6f69fb09c5f81dff3b9edcd03f5107d96e10a55"}], "stats": {"total": 1519, "additions": 742, "deletions": 777}, "files": [{"sha": "c0f2d0f8ec7f372ea7de9ee72f11e0bb6d9e19b5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -1,3 +1,11 @@\n+2015-10-01  Trevor Saunders  <tbsaunde+gcc@tbsaunde.org>\n+\n+\t* cfganal.c, compare-elim.c, coverage.c, cprop.c, df-scan.c,\n+\tfunction.c, read-rtl.c, statistics.c, trans-mem.c, tree-if-conv.c,\n+\ttree-into-ssa.c, tree-loop-distribution.c, tree-ssa-coalesce.c,\n+\ttree-ssa-loop-ivopts.c, tree-ssa-reassoc.c, tree-ssa-strlen.c,\n+\ttree-ssa-tail-merge.c, tree-vrp.c, var-tracking.c: Remove\n+\n 2015-10-01  Marek Polacek  <polacek@redhat.com>\n \n \tPR c/65345"}, {"sha": "279c3b549958dc3d57a7337de61967f9c70ffa5d", "filename": "gcc/cfganal.c", "status": "modified", "additions": 10, "deletions": 11, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcfganal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcfganal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfganal.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -29,7 +29,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"timevar.h\"\n \n /* Store the data structures necessary for depth-first search.  */\n-struct depth_first_search_dsS {\n+struct depth_first_search_ds {\n   /* stack for backtracking during the algorithm */\n   basic_block *stack;\n \n@@ -40,14 +40,13 @@ struct depth_first_search_dsS {\n   /* record of basic blocks already seen by depth-first search */\n   sbitmap visited_blocks;\n };\n-typedef struct depth_first_search_dsS *depth_first_search_ds;\n \n-static void flow_dfs_compute_reverse_init (depth_first_search_ds);\n-static void flow_dfs_compute_reverse_add_bb (depth_first_search_ds,\n+static void flow_dfs_compute_reverse_init (depth_first_search_ds *);\n+static void flow_dfs_compute_reverse_add_bb (depth_first_search_ds *,\n \t\t\t\t\t     basic_block);\n-static basic_block flow_dfs_compute_reverse_execute (depth_first_search_ds,\n+static basic_block flow_dfs_compute_reverse_execute (depth_first_search_ds *,\n \t\t\t\t\t\t     basic_block);\n-static void flow_dfs_compute_reverse_finish (depth_first_search_ds);\n+static void flow_dfs_compute_reverse_finish (depth_first_search_ds *);\n \f\n /* Mark the back edges in DFS traversal.\n    Return nonzero if a loop (natural or otherwise) is present.\n@@ -575,7 +574,7 @@ connect_infinite_loops_to_exit (void)\n {\n   basic_block unvisited_block = EXIT_BLOCK_PTR_FOR_FN (cfun);\n   basic_block deadend_block;\n-  struct depth_first_search_dsS dfs_ds;\n+  depth_first_search_ds dfs_ds;\n \n   /* Perform depth-first search in the reverse graph to find nodes\n      reachable from the exit block.  */\n@@ -1055,7 +1054,7 @@ pre_and_rev_post_order_compute (int *pre_order, int *rev_post_order,\n    element on the stack.  */\n \n static void\n-flow_dfs_compute_reverse_init (depth_first_search_ds data)\n+flow_dfs_compute_reverse_init (depth_first_search_ds *data)\n {\n   /* Allocate stack for back-tracking up CFG.  */\n   data->stack = XNEWVEC (basic_block, n_basic_blocks_for_fn (cfun));\n@@ -1075,7 +1074,7 @@ flow_dfs_compute_reverse_init (depth_first_search_ds data)\n    block.  */\n \n static void\n-flow_dfs_compute_reverse_add_bb (depth_first_search_ds data, basic_block bb)\n+flow_dfs_compute_reverse_add_bb (depth_first_search_ds *data, basic_block bb)\n {\n   data->stack[data->sp++] = bb;\n   bitmap_set_bit (data->visited_blocks, bb->index);\n@@ -1087,7 +1086,7 @@ flow_dfs_compute_reverse_add_bb (depth_first_search_ds data, basic_block bb)\n    available.  */\n \n static basic_block\n-flow_dfs_compute_reverse_execute (depth_first_search_ds data,\n+flow_dfs_compute_reverse_execute (depth_first_search_ds *data,\n \t\t\t\t  basic_block last_unvisited)\n {\n   basic_block bb;\n@@ -1116,7 +1115,7 @@ flow_dfs_compute_reverse_execute (depth_first_search_ds data,\n    reverse graph.  */\n \n static void\n-flow_dfs_compute_reverse_finish (depth_first_search_ds data)\n+flow_dfs_compute_reverse_finish (depth_first_search_ds *data)\n {\n   free (data->stack);\n   sbitmap_free (data->visited_blocks);"}, {"sha": "08e070cc7f17a7db9ea90c1ea729221bffedfbb0", "filename": "gcc/compare-elim.c", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcompare-elim.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcompare-elim.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcompare-elim.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -121,9 +121,7 @@ struct comparison\n   bool inputs_valid;\n };\n   \n-typedef struct comparison *comparison_struct_p;\n-\n-static vec<comparison_struct_p> all_compares;\n+static vec<comparison *> all_compares;\n \n /* Look for a \"conforming\" comparison, as defined above.  If valid, return\n    the rtx for the COMPARE itself.  */"}, {"sha": "4e08e5f685fcaed10b358aecbef049a29557d2ea", "filename": "gcc/coverage.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcoverage.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcoverage.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcoverage.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -77,7 +77,7 @@ struct GTY((chain_next (\"%h.next\"))) coverage_data\n };\n \n /* Counts information for a function.  */\n-typedef struct counts_entry : pointer_hash <counts_entry>\n+struct counts_entry : pointer_hash <counts_entry>\n {\n   /* We hash by  */\n   unsigned ident;\n@@ -93,7 +93,7 @@ typedef struct counts_entry : pointer_hash <counts_entry>\n   static inline hashval_t hash (const counts_entry *);\n   static int equal (const counts_entry *, const counts_entry *);\n   static void remove (counts_entry *);\n-} counts_entry_t;\n+};\n \n static GTY(()) struct coverage_data *functions_head = 0;\n static struct coverage_data **functions_tail = &functions_head;\n@@ -279,7 +279,7 @@ read_counts_file (void)\n \t}\n       else if (GCOV_TAG_IS_COUNTER (tag) && fn_ident)\n \t{\n-\t  counts_entry_t **slot, *entry, elt;\n+\t  counts_entry **slot, *entry, elt;\n \t  unsigned n_counts = GCOV_TAG_COUNTER_NUM (length);\n \t  unsigned ix;\n \n@@ -290,7 +290,7 @@ read_counts_file (void)\n \t  entry = *slot;\n \t  if (!entry)\n \t    {\n-\t      *slot = entry = XCNEW (counts_entry_t);\n+\t      *slot = entry = XCNEW (counts_entry);\n \t      entry->ident = fn_ident;\n \t      entry->ctr = elt.ctr;\n \t      entry->lineno_checksum = lineno_checksum;\n@@ -358,7 +358,7 @@ get_coverage_counts (unsigned counter, unsigned expected,\n                      unsigned cfg_checksum, unsigned lineno_checksum,\n \t\t     const struct gcov_ctr_summary **summary)\n {\n-  counts_entry_t *entry, elt;\n+  counts_entry *entry, elt;\n \n   /* No hash table, no counts.  */\n   if (!counts_hash)"}, {"sha": "28e9e54e93b0a777eba12d04ad5cf6ebb1868b20", "filename": "gcc/cprop.c", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcprop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fcprop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcprop.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -71,8 +71,6 @@ struct cprop_occr\n   rtx_insn *insn;\n };\n \n-typedef struct cprop_occr *occr_t;\n-\n /* Hash table entry for assignment expressions.  */\n \n struct cprop_expr"}, {"sha": "7a22b10371d432b8b5e859d39fa461447ab1b517", "filename": "gcc/df-scan.c", "status": "modified", "additions": 4, "deletions": 10, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fdf-scan.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fdf-scan.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdf-scan.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -40,9 +40,6 @@ along with GCC; see the file COPYING3.  If not see\n #include \"emit-rtl.h\"  /* FIXME: Can go away once crtl is moved to rtl.h.  */\n \n \n-typedef struct df_mw_hardreg *df_mw_hardreg_ptr;\n-\n-\n /* The set of hard registers in eliminables[i].from. */\n \n static HARD_REG_SET elim_reg_set;\n@@ -55,7 +52,7 @@ struct df_collection_rec\n   auto_vec<df_ref, 128> def_vec;\n   auto_vec<df_ref, 32> use_vec;\n   auto_vec<df_ref, 32> eq_use_vec;\n-  auto_vec<df_mw_hardreg_ptr, 32> mw_vec;\n+  auto_vec<df_mw_hardreg *, 32> mw_vec;\n };\n \n static void df_ref_record (enum df_ref_class, struct df_collection_rec *,\n@@ -147,9 +144,6 @@ struct df_scan_problem_data\n   bitmap_obstack insn_bitmaps;\n };\n \n-typedef struct df_scan_bb_info *df_scan_bb_info_t;\n-\n-\n /* Internal function to shut down the scanning problem.  */\n static void\n df_scan_free_internal (void)\n@@ -2241,7 +2235,7 @@ df_mw_ptr_compare (const void *m1, const void *m2)\n /* Sort and compress a set of refs.  */\n \n static void\n-df_sort_and_compress_mws (vec<df_mw_hardreg_ptr, va_heap> *mw_vec)\n+df_sort_and_compress_mws (vec<df_mw_hardreg *, va_heap> *mw_vec)\n {\n   unsigned int count;\n   struct df_scan_problem_data *problem_data\n@@ -2405,7 +2399,7 @@ df_install_refs (basic_block bb,\n    insn.  */\n \n static struct df_mw_hardreg *\n-df_install_mws (const vec<df_mw_hardreg_ptr, va_heap> *old_vec)\n+df_install_mws (const vec<df_mw_hardreg *, va_heap> *old_vec)\n {\n   unsigned int count = old_vec->length ();\n   if (count)\n@@ -4059,7 +4053,7 @@ df_refs_verify (const vec<df_ref, va_heap> *new_rec, df_ref old_rec,\n /* Verify that NEW_REC and OLD_REC have exactly the same members. */\n \n static bool\n-df_mws_verify (const vec<df_mw_hardreg_ptr, va_heap> *new_rec,\n+df_mws_verify (const vec<df_mw_hardreg *, va_heap> *new_rec,\n \t       struct df_mw_hardreg *old_rec,\n \t       bool abort_if_fail)\n {"}, {"sha": "e76ba2b31ce9d760175e5a4bc5084b788709f534", "filename": "gcc/function.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -156,9 +156,7 @@ static void do_use_return_reg (rtx, void *);\n /* Stack of nested functions.  */\n /* Keep track of the cfun stack.  */\n \n-typedef struct function *function_p;\n-\n-static vec<function_p> function_context_stack;\n+static vec<function *> function_context_stack;\n \n /* Save the current context for compilation of a nested function.\n    This is called from language-specific code.  */\n@@ -4745,7 +4743,7 @@ set_cfun (struct function *new_cfun)\n \n /* Initialized with NOGC, making this poisonous to the garbage collector.  */\n \n-static vec<function_p> cfun_stack;\n+static vec<function *> cfun_stack;\n \n /* Push the current cfun onto the stack, and set cfun to new_cfun.  Also set\n    current_function_decl accordingly.  */"}, {"sha": "36e42cd599a8c29f883dda1270b32a537fa43b57", "filename": "gcc/read-rtl.c", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fread-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fread-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fread-rtl.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -54,9 +54,6 @@ struct mapping {\n   struct map_value *current_value;\n };\n \n-/* Vector definitions for the above.  */\n-typedef struct mapping *mapping_ptr;\n-\n /* A structure for abstracting the common parts of iterators.  */\n struct iterator_group {\n   /* Tables of \"mapping\" structures, one for attributes and one for\n@@ -117,7 +114,7 @@ static rtx read_rtx_variadic (rtx);\n static struct iterator_group modes, codes, ints, substs;\n \n /* All iterators used in the current rtx.  */\n-static vec<mapping_ptr> current_iterators;\n+static vec<mapping *> current_iterators;\n \n /* The list of all iterator uses in the current rtx.  */\n static vec<iterator_use> iterator_uses;"}, {"sha": "8e3dc14562cedb4f1d2aaa0f1c3e43cc0dd94181", "filename": "gcc/statistics.c", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fstatistics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fstatistics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstatistics.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -36,45 +36,45 @@ static FILE *statistics_dump_file;\n /* Statistics entry.  A integer counter associated to a string ID\n    and value.  */\n \n-typedef struct statistics_counter_s {\n+struct statistics_counter {\n   const char *id;\n   int val;\n   bool histogram_p;\n   unsigned HOST_WIDE_INT count;\n   unsigned HOST_WIDE_INT prev_dumped_count;\n-} statistics_counter_t;\n+};\n \n /* Hashtable helpers.  */\n \n-struct stats_counter_hasher : pointer_hash <statistics_counter_t>\n+struct stats_counter_hasher : pointer_hash <statistics_counter>\n {\n-  static inline hashval_t hash (const statistics_counter_t *);\n-  static inline bool equal (const statistics_counter_t *,\n-\t\t\t    const statistics_counter_t *);\n-  static inline void remove (statistics_counter_t *);\n+  static inline hashval_t hash (const statistics_counter *);\n+  static inline bool equal (const statistics_counter *,\n+\t\t\t    const statistics_counter *);\n+  static inline void remove (statistics_counter *);\n };\n \n /* Hash a statistic counter by its string ID.  */\n \n inline hashval_t\n-stats_counter_hasher::hash (const statistics_counter_t *c)\n+stats_counter_hasher::hash (const statistics_counter *c)\n {\n   return htab_hash_string (c->id) + c->val;\n }\n \n /* Compare two statistic counters by their string IDs.  */\n \n inline bool\n-stats_counter_hasher::equal (const statistics_counter_t *c1,\n-\t\t\t     const statistics_counter_t *c2)\n+stats_counter_hasher::equal (const statistics_counter *c1,\n+\t\t\t     const statistics_counter *c2)\n {\n   return c1->val == c2->val && strcmp (c1->id, c2->id) == 0;\n }\n \n /* Free a statistics entry.  */\n \n inline void\n-stats_counter_hasher::remove (statistics_counter_t *v)\n+stats_counter_hasher::remove (statistics_counter *v)\n {\n   free (CONST_CAST (char *, v->id));\n   free (v);\n@@ -120,10 +120,10 @@ curr_statistics_hash (void)\n    since the last dump for the pass dump files.  */\n \n int\n-statistics_fini_pass_1 (statistics_counter_t **slot,\n+statistics_fini_pass_1 (statistics_counter **slot,\n \t\t\tvoid *data ATTRIBUTE_UNUSED)\n {\n-  statistics_counter_t *counter = *slot;\n+  statistics_counter *counter = *slot;\n   unsigned HOST_WIDE_INT count = counter->count - counter->prev_dumped_count;\n   if (count == 0)\n     return 1;\n@@ -141,10 +141,10 @@ statistics_fini_pass_1 (statistics_counter_t **slot,\n    since the last dump for the statistics dump.  */\n \n int\n-statistics_fini_pass_2 (statistics_counter_t **slot,\n+statistics_fini_pass_2 (statistics_counter **slot,\n \t\t\tvoid *data ATTRIBUTE_UNUSED)\n {\n-  statistics_counter_t *counter = *slot;\n+  statistics_counter *counter = *slot;\n   unsigned HOST_WIDE_INT count = counter->count - counter->prev_dumped_count;\n   if (count == 0)\n     return 1;\n@@ -172,10 +172,10 @@ statistics_fini_pass_2 (statistics_counter_t **slot,\n /* Helper for statistics_fini_pass, reset the counters.  */\n \n int\n-statistics_fini_pass_3 (statistics_counter_t **slot,\n+statistics_fini_pass_3 (statistics_counter **slot,\n \t\t\tvoid *data ATTRIBUTE_UNUSED)\n {\n-  statistics_counter_t *counter = *slot;\n+  statistics_counter *counter = *slot;\n   counter->prev_dumped_count = counter->count;\n   return 1;\n }\n@@ -210,9 +210,9 @@ statistics_fini_pass (void)\n /* Helper for printing summary information.  */\n \n int\n-statistics_fini_1 (statistics_counter_t **slot, opt_pass *pass)\n+statistics_fini_1 (statistics_counter **slot, opt_pass *pass)\n {\n-  statistics_counter_t *counter = *slot;\n+  statistics_counter *counter = *slot;\n   if (counter->count == 0)\n     return 1;\n   if (counter->histogram_p)\n@@ -280,18 +280,18 @@ statistics_init (void)\n /* Lookup or add a statistics counter in the hashtable HASH with ID, VAL\n    and HISTOGRAM_P.  */\n \n-static statistics_counter_t *\n+static statistics_counter *\n lookup_or_add_counter (stats_counter_table_type *hash, const char *id, int val,\n \t\t       bool histogram_p)\n {\n-  statistics_counter_t **counter;\n-  statistics_counter_t c;\n+  statistics_counter **counter;\n+  statistics_counter c;\n   c.id = id;\n   c.val = val;\n   counter = hash->find_slot (&c, INSERT);\n   if (!*counter)\n     {\n-      *counter = XNEW (struct statistics_counter_s);\n+      *counter = XNEW (statistics_counter);\n       (*counter)->id = xstrdup (id);\n       (*counter)->val = val;\n       (*counter)->histogram_p = histogram_p;\n@@ -308,7 +308,7 @@ lookup_or_add_counter (stats_counter_table_type *hash, const char *id, int val,\n void\n statistics_counter_event (struct function *fn, const char *id, int incr)\n {\n-  statistics_counter_t *counter;\n+  statistics_counter *counter;\n \n   if ((!(dump_flags & TDF_STATS)\n        && !statistics_dump_file)\n@@ -342,7 +342,7 @@ statistics_counter_event (struct function *fn, const char *id, int incr)\n void\n statistics_histogram_event (struct function *fn, const char *id, int val)\n {\n-  statistics_counter_t *counter;\n+  statistics_counter *counter;\n \n   if (!(dump_flags & TDF_STATS)\n       && !statistics_dump_file)"}, {"sha": "5b43d86f6da283adf5e362d768148be7debfbd6b", "filename": "gcc/trans-mem.c", "status": "modified", "additions": 21, "deletions": 23, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftrans-mem.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftrans-mem.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftrans-mem.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -927,7 +927,7 @@ make_pass_diagnose_tm_blocks (gcc::context *ctxt)\n /* One individual log entry.  We may have multiple statements for the\n    same location if neither dominate each other (on different\n    execution paths).  */\n-typedef struct tm_log_entry\n+struct tm_log_entry\n {\n   /* Address to save.  */\n   tree addr;\n@@ -940,7 +940,7 @@ typedef struct tm_log_entry\n      save/restore sequence.  Later, when generating the save sequence\n      we place the SSA temp generated here.  */\n   tree save_var;\n-} *tm_log_entry_t;\n+};\n \n \n /* Log entry hashtable helpers.  */\n@@ -1009,29 +1009,29 @@ enum thread_memory_type\n     mem_max\n   };\n \n-typedef struct tm_new_mem_map\n+struct tm_new_mem_map\n {\n   /* SSA_NAME being dereferenced.  */\n   tree val;\n   enum thread_memory_type local_new_memory;\n-} tm_new_mem_map_t;\n+};\n \n /* Hashtable helpers.  */\n \n-struct tm_mem_map_hasher : free_ptr_hash <tm_new_mem_map_t>\n+struct tm_mem_map_hasher : free_ptr_hash <tm_new_mem_map>\n {\n-  static inline hashval_t hash (const tm_new_mem_map_t *);\n-  static inline bool equal (const tm_new_mem_map_t *, const tm_new_mem_map_t *);\n+  static inline hashval_t hash (const tm_new_mem_map *);\n+  static inline bool equal (const tm_new_mem_map *, const tm_new_mem_map *);\n };\n \n inline hashval_t\n-tm_mem_map_hasher::hash (const tm_new_mem_map_t *v)\n+tm_mem_map_hasher::hash (const tm_new_mem_map *v)\n {\n   return (intptr_t)v->val >> 4;\n }\n \n inline bool\n-tm_mem_map_hasher::equal (const tm_new_mem_map_t *v, const tm_new_mem_map_t *c)\n+tm_mem_map_hasher::equal (const tm_new_mem_map *v, const tm_new_mem_map *c)\n {\n   return v->val == c->val;\n }\n@@ -1362,8 +1362,8 @@ thread_private_new_memory (basic_block entry_block, tree x)\n {\n   gimple *stmt = NULL;\n   enum tree_code code;\n-  tm_new_mem_map_t **slot;\n-  tm_new_mem_map_t elt, *elt_p;\n+  tm_new_mem_map **slot;\n+  tm_new_mem_map elt, *elt_p;\n   tree val = x;\n   enum thread_memory_type retval = mem_transaction_local;\n \n@@ -1383,7 +1383,7 @@ thread_private_new_memory (basic_block entry_block, tree x)\n \n   /* Optimistically assume the memory is transaction local during\n      processing.  This catches recursion into this variable.  */\n-  *slot = elt_p = XNEW (tm_new_mem_map_t);\n+  *slot = elt_p = XNEW (tm_new_mem_map);\n   elt_p->val = val;\n   elt_p->local_new_memory = mem_transaction_local;\n \n@@ -1864,8 +1864,6 @@ struct tm_region\n   bitmap irr_blocks;\n };\n \n-typedef struct tm_region *tm_region_p;\n-\n /* True if there are pending edge statements to be committed for the\n    current function being scanned in the tmmark pass.  */\n bool pending_edge_inserts_p;\n@@ -1970,7 +1968,7 @@ tm_region_init (struct tm_region *region)\n   auto_vec<basic_block> queue;\n   bitmap visited_blocks = BITMAP_ALLOC (NULL);\n   struct tm_region *old_region;\n-  auto_vec<tm_region_p> bb_regions;\n+  auto_vec<tm_region *> bb_regions;\n \n   all_tm_regions = region;\n   bb = single_succ (ENTRY_BLOCK_PTR_FOR_FN (cfun));\n@@ -2594,7 +2592,7 @@ get_tm_region_blocks (basic_block entry_block,\n // Callback data for collect_bb2reg.\n struct bb2reg_stuff\n {\n-  vec<tm_region_p> *bb2reg;\n+  vec<tm_region *> *bb2reg;\n   bool include_uninstrumented_p;\n };\n \n@@ -2603,7 +2601,7 @@ static void *\n collect_bb2reg (struct tm_region *region, void *data)\n {\n   struct bb2reg_stuff *stuff = (struct bb2reg_stuff *)data;\n-  vec<tm_region_p> *bb2reg = stuff->bb2reg;\n+  vec<tm_region *> *bb2reg = stuff->bb2reg;\n   vec<basic_block> queue;\n   unsigned int i;\n   basic_block bb;\n@@ -2647,13 +2645,13 @@ collect_bb2reg (struct tm_region *region, void *data)\n // ??? There is currently a hack inside tree-ssa-pre.c to work around the\n // only known instance of this block sharing.\n \n-static vec<tm_region_p>\n+static vec<tm_region *>\n get_bb_regions_instrumented (bool traverse_clones,\n \t\t\t     bool include_uninstrumented_p)\n {\n   unsigned n = last_basic_block_for_fn (cfun);\n   struct bb2reg_stuff stuff;\n-  vec<tm_region_p> ret;\n+  vec<tm_region *> ret;\n \n   ret.create (n);\n   ret.safe_grow_cleared (n);\n@@ -2986,7 +2984,7 @@ execute_tm_mark (void)\n \n   tm_log_init ();\n \n-  vec<tm_region_p> bb_regions\n+  vec<tm_region *> bb_regions\n     = get_bb_regions_instrumented (/*traverse_clones=*/true,\n \t\t\t\t   /*include_uninstrumented_p=*/false);\n   struct tm_region *r;\n@@ -3223,7 +3221,7 @@ class pass_tm_edges : public gimple_opt_pass\n unsigned int\n pass_tm_edges::execute (function *fun)\n {\n-  vec<tm_region_p> bb_regions\n+  vec<tm_region *> bb_regions\n     = get_bb_regions_instrumented (/*traverse_clones=*/false,\n \t\t\t\t   /*include_uninstrumented_p=*/true);\n   struct tm_region *r;\n@@ -3307,13 +3305,13 @@ expand_regions (struct tm_region *region,\n \n \f\n /* A unique TM memory operation.  */\n-typedef struct tm_memop\n+struct tm_memop\n {\n   /* Unique ID that all memory operations to the same location have.  */\n   unsigned int value_id;\n   /* Address of load/store.  */\n   tree addr;\n-} *tm_memop_t;\n+};\n \n /* TM memory operation hashtable helpers.  */\n "}, {"sha": "f201ab5fdb17b77e9b48d897b9348079a2e8659a", "filename": "gcc/tree-if-conv.c", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-if-conv.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-if-conv.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-if-conv.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -131,7 +131,7 @@ static bool aggressive_if_conv;\n \n /* Structure used to predicate basic blocks.  This is attached to the\n    ->aux field of the BBs in the loop to be if-converted.  */\n-typedef struct bb_predicate_s {\n+struct bb_predicate {\n \n   /* The condition under which this basic block is executed.  */\n   tree predicate;\n@@ -140,7 +140,7 @@ typedef struct bb_predicate_s {\n      recorded here, in order to avoid the duplication of computations\n      that occur in previous conditions.  See PR44483.  */\n   gimple_seq predicate_gimplified_stmts;\n-} *bb_predicate_p;\n+};\n \n /* Returns true when the basic block BB has a predicate.  */\n \n@@ -155,7 +155,7 @@ bb_has_predicate (basic_block bb)\n static inline tree\n bb_predicate (basic_block bb)\n {\n-  return ((bb_predicate_p) bb->aux)->predicate;\n+  return ((struct bb_predicate *) bb->aux)->predicate;\n }\n \n /* Sets the gimplified predicate COND for basic block BB.  */\n@@ -166,7 +166,7 @@ set_bb_predicate (basic_block bb, tree cond)\n   gcc_assert ((TREE_CODE (cond) == TRUTH_NOT_EXPR\n \t       && is_gimple_condexpr (TREE_OPERAND (cond, 0)))\n \t      || is_gimple_condexpr (cond));\n-  ((bb_predicate_p) bb->aux)->predicate = cond;\n+  ((struct bb_predicate *) bb->aux)->predicate = cond;\n }\n \n /* Returns the sequence of statements of the gimplification of the\n@@ -175,7 +175,7 @@ set_bb_predicate (basic_block bb, tree cond)\n static inline gimple_seq\n bb_predicate_gimplified_stmts (basic_block bb)\n {\n-  return ((bb_predicate_p) bb->aux)->predicate_gimplified_stmts;\n+  return ((struct bb_predicate *) bb->aux)->predicate_gimplified_stmts;\n }\n \n /* Sets the sequence of statements STMTS of the gimplification of the\n@@ -184,7 +184,7 @@ bb_predicate_gimplified_stmts (basic_block bb)\n static inline void\n set_bb_predicate_gimplified_stmts (basic_block bb, gimple_seq stmts)\n {\n-  ((bb_predicate_p) bb->aux)->predicate_gimplified_stmts = stmts;\n+  ((struct bb_predicate *) bb->aux)->predicate_gimplified_stmts = stmts;\n }\n \n /* Adds the sequence of statements STMTS to the sequence of statements\n@@ -194,15 +194,15 @@ static inline void\n add_bb_predicate_gimplified_stmts (basic_block bb, gimple_seq stmts)\n {\n   gimple_seq_add_seq\n-    (&(((bb_predicate_p) bb->aux)->predicate_gimplified_stmts), stmts);\n+    (&(((struct bb_predicate *) bb->aux)->predicate_gimplified_stmts), stmts);\n }\n \n /* Initializes to TRUE the predicate of basic block BB.  */\n \n static inline void\n init_bb_predicate (basic_block bb)\n {\n-  bb->aux = XNEW (struct bb_predicate_s);\n+  bb->aux = XNEW (struct bb_predicate);\n   set_bb_predicate_gimplified_stmts (bb, NULL);\n   set_bb_predicate (bb, boolean_true_node);\n }"}, {"sha": "9fd698dd63f02e63a23f80da81344b0e84a9cb92", "filename": "gcc/tree-into-ssa.c", "status": "modified", "additions": 38, "deletions": 50, "changes": 88, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-into-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-into-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-into-ssa.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -65,7 +65,7 @@ along with GCC; see the file COPYING3.  If not see\n \n /* Structure to map a variable VAR to the set of blocks that contain\n    definitions for VAR.  */\n-struct def_blocks_d\n+struct def_blocks\n {\n   /* Blocks that contain definitions of VAR.  Bit I will be set if the\n      Ith block contains a definition of VAR.  */\n@@ -79,9 +79,6 @@ struct def_blocks_d\n   bitmap livein_blocks;\n };\n \n-typedef struct def_blocks_d *def_blocks_p;\n-\n-\n /* Stack of trees used to restore the global currdefs to its original\n    state after completing rewriting of a block and its dominator\n    children.  Its elements have the following properties:\n@@ -169,7 +166,7 @@ enum need_phi_state {\n };\n \n /* Information stored for both SSA names and decls.  */\n-struct common_info_d\n+struct common_info\n {\n   /* This field indicates whether or not the variable may need PHI nodes.\n      See the enum's definition for more detailed information about the\n@@ -180,29 +177,23 @@ struct common_info_d\n   tree current_def;\n \n   /* Definitions for this var.  */\n-  struct def_blocks_d def_blocks;\n+  struct def_blocks def_blocks;\n };\n \n-/* The information associated with decls and SSA names.  */\n-typedef struct common_info_d *common_info_p;\n-\n /* Information stored for decls.  */\n-struct var_info_d\n+struct var_info\n {\n   /* The variable.  */\n   tree var;\n \n   /* Information stored for both SSA names and decls.  */\n-  struct common_info_d info;\n+  common_info info;\n };\n \n-/* The information associated with decls.  */\n-typedef struct var_info_d *var_info_p;\n-\n \n /* VAR_INFOS hashtable helpers.  */\n \n-struct var_info_hasher : free_ptr_hash <var_info_d>\n+struct var_info_hasher : free_ptr_hash <var_info>\n {\n   static inline hashval_t hash (const value_type &);\n   static inline bool equal (const value_type &, const compare_type &);\n@@ -238,13 +229,10 @@ struct ssa_name_info\n   bitmap repl_set;\n \n   /* Information stored for both SSA names and decls.  */\n-  struct common_info_d info;\n+  common_info info;\n };\n \n-/* The information associated with names.  */\n-typedef struct ssa_name_info *ssa_name_info_p;\n-\n-static vec<ssa_name_info_p> info_for_ssa_name;\n+static vec<ssa_name_info *> info_for_ssa_name;\n static unsigned current_info_for_ssa_name_age;\n \n static bitmap_obstack update_ssa_obstack;\n@@ -339,7 +327,7 @@ set_register_defs (gimple *stmt, bool register_defs_p)\n \n /* Get the information associated with NAME.  */\n \n-static inline ssa_name_info_p\n+static inline ssa_name_info *\n get_ssa_name_ann (tree name)\n {\n   unsigned ver = SSA_NAME_VERSION (name);\n@@ -376,16 +364,16 @@ get_ssa_name_ann (tree name)\n \n /* Return and allocate the auxiliar information for DECL.  */\n \n-static inline var_info_p\n+static inline var_info *\n get_var_info (tree decl)\n {\n-  struct var_info_d vi;\n-  var_info_d **slot;\n+  var_info vi;\n+  var_info **slot;\n   vi.var = decl;\n   slot = var_infos->find_slot_with_hash (&vi, DECL_UID (decl), INSERT);\n   if (*slot == NULL)\n     {\n-      var_info_p v = XCNEW (struct var_info_d);\n+      var_info *v = XCNEW (var_info);\n       v->var = decl;\n       *slot = v;\n       return v;\n@@ -409,7 +397,7 @@ clear_ssa_name_info (void)\n \n /* Get access to the auxiliar information stored per SSA name or decl.  */\n \n-static inline common_info_p\n+static inline common_info *\n get_common_info (tree var)\n {\n   if (TREE_CODE (var) == SSA_NAME)\n@@ -480,10 +468,10 @@ mark_block_for_update (basic_block bb)\n    where VAR is live on entry (livein).  If no entry is found in\n    DEF_BLOCKS, a new one is created and returned.  */\n \n-static inline struct def_blocks_d *\n-get_def_blocks_for (common_info_p info)\n+static inline def_blocks *\n+get_def_blocks_for (common_info *info)\n {\n-  struct def_blocks_d *db_p = &info->def_blocks;\n+  def_blocks *db_p = &info->def_blocks;\n   if (!db_p->def_blocks)\n     {\n       db_p->def_blocks = BITMAP_ALLOC (&update_ssa_obstack);\n@@ -501,8 +489,8 @@ get_def_blocks_for (common_info_p info)\n static void\n set_def_block (tree var, basic_block bb, bool phi_p)\n {\n-  struct def_blocks_d *db_p;\n-  common_info_p info;\n+  def_blocks *db_p;\n+  common_info *info;\n \n   info = get_common_info (var);\n   db_p = get_def_blocks_for (info);\n@@ -536,8 +524,8 @@ set_def_block (tree var, basic_block bb, bool phi_p)\n static void\n set_livein_block (tree var, basic_block bb)\n {\n-  common_info_p info;\n-  struct def_blocks_d *db_p;\n+  common_info *info;\n+  def_blocks *db_p;\n \n   info = get_common_info (var);\n   db_p = get_def_blocks_for (info);\n@@ -935,10 +923,10 @@ prune_unused_phi_nodes (bitmap phis, bitmap kills, bitmap uses)\n    where VAR is live on entry (livein).  Return NULL, if no entry is\n    found in DEF_BLOCKS.  */\n \n-static inline struct def_blocks_d *\n+static inline def_blocks *\n find_def_blocks_for (tree var)\n {\n-  def_blocks_p p = &get_common_info (var)->def_blocks;\n+  def_blocks *p = &get_common_info (var)->def_blocks;\n   if (!p->def_blocks)\n     return NULL;\n   return p;\n@@ -992,7 +980,7 @@ insert_phi_nodes_for (tree var, bitmap phi_insertion_points, bool update_p)\n   gphi *phi;\n   basic_block bb;\n   bitmap_iterator bi;\n-  struct def_blocks_d *def_map = find_def_blocks_for (var);\n+  def_blocks *def_map = find_def_blocks_for (var);\n \n   /* Remove the blocks where we already have PHI nodes for VAR.  */\n   bitmap_and_compl_into (phi_insertion_points, def_map->phi_blocks);\n@@ -1068,8 +1056,8 @@ insert_phi_nodes_for (tree var, bitmap phi_insertion_points, bool update_p)\n static int\n insert_phi_nodes_compare_var_infos (const void *a, const void *b)\n {\n-  const struct var_info_d *defa = *(struct var_info_d * const *)a;\n-  const struct var_info_d *defb = *(struct var_info_d * const *)b;\n+  const var_info *defa = *(var_info * const *)a;\n+  const var_info *defb = *(var_info * const *)b;\n   if (DECL_UID (defa->var) < DECL_UID (defb->var))\n     return -1;\n   else\n@@ -1085,11 +1073,11 @@ insert_phi_nodes (bitmap_head *dfs)\n {\n   hash_table<var_info_hasher>::iterator hi;\n   unsigned i;\n-  var_info_p info;\n+  var_info *info;\n \n   timevar_push (TV_TREE_INSERT_PHI_NODES);\n \n-  auto_vec<var_info_p> vars (var_infos->elements ());\n+  auto_vec<var_info *> vars (var_infos->elements ());\n   FOR_EACH_HASH_TABLE_ELEMENT (*var_infos, info, var_info_p, hi)\n     if (info->info.need_phi_state != NEED_PHI_STATE_NO)\n       vars.quick_push (info);\n@@ -1115,7 +1103,7 @@ insert_phi_nodes (bitmap_head *dfs)\n static void\n register_new_def (tree def, tree sym)\n {\n-  common_info_p info = get_common_info (sym);\n+  common_info *info = get_common_info (sym);\n   tree currdef;\n \n   /* If this variable is set in a single basic block and all uses are\n@@ -1183,7 +1171,7 @@ register_new_def (tree def, tree sym)\n static tree\n get_reaching_def (tree var)\n {\n-  common_info_p info = get_common_info (var);\n+  common_info *info = get_common_info (var);\n   tree currdef;\n \n   /* Lookup the current reaching definition for VAR.  */\n@@ -1215,7 +1203,7 @@ rewrite_debug_stmt_uses (gimple *stmt)\n   FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_USE)\n     {\n       tree var = USE_FROM_PTR (use_p), def;\n-      common_info_p info = get_common_info (var);\n+      common_info *info = get_common_info (var);\n       gcc_checking_assert (DECL_P (var));\n       def = info->current_def;\n       if (!def)\n@@ -1282,7 +1270,7 @@ rewrite_debug_stmt_uses (gimple *stmt)\n \t    ;\n \t  else\n \t    {\n-\t      struct def_blocks_d *db_p = get_def_blocks_for (info);\n+\t      def_blocks *db_p = get_def_blocks_for (info);\n \n \t      /* If there are some non-debug uses in the current bb,\n \t\t it is fine.  */\n@@ -1602,7 +1590,7 @@ dump_currdefs (FILE *file)\n   fprintf (file, \"\\n\\nCurrent reaching definitions\\n\\n\");\n   FOR_EACH_VEC_ELT (symbols_to_rename, i, var)\n     {\n-      common_info_p info = get_common_info (var);\n+      common_info *info = get_common_info (var);\n       fprintf (file, \"CURRDEF (\");\n       print_generic_expr (file, var, 0);\n       fprintf (file, \") = \");\n@@ -1689,9 +1677,9 @@ debug_tree_ssa_stats (void)\n /* Callback for htab_traverse to dump the VAR_INFOS hash table.  */\n \n int\n-debug_var_infos_r (var_info_d **slot, FILE *file)\n+debug_var_infos_r (var_info **slot, FILE *file)\n {\n-  struct var_info_d *info = *slot;\n+  var_info *info = *slot;\n \n   fprintf (file, \"VAR: \");\n   print_generic_expr (file, info->var, dump_flags);\n@@ -1731,7 +1719,7 @@ debug_var_infos (void)\n static inline void\n register_new_update_single (tree new_name, tree old_name)\n {\n-  common_info_p info = get_common_info (old_name);\n+  common_info *info = get_common_info (old_name);\n   tree currdef = info->current_def;\n \n   /* Push the current reaching definition into BLOCK_DEFS_STACK.\n@@ -2487,7 +2475,7 @@ mark_use_interesting (tree var, gimple *stmt, basic_block bb,\n      replace it).  */\n   if (insert_phi_p)\n     {\n-      struct def_blocks_d *db_p = get_def_blocks_for (get_common_info (var));\n+      def_blocks *db_p = get_def_blocks_for (get_common_info (var));\n       if (!bitmap_bit_p (db_p->def_blocks, bb->index))\n \tset_livein_block (var, bb);\n     }\n@@ -3006,7 +2994,7 @@ insert_updated_phi_nodes_for (tree var, bitmap_head *dfs, bitmap blocks,\n                               unsigned update_flags)\n {\n   basic_block entry;\n-  struct def_blocks_d *db;\n+  def_blocks *db;\n   bitmap idf, pruned_idf;\n   bitmap_iterator bi;\n   unsigned i;"}, {"sha": "6f86d53f54493f3d566da1b3e59b27e8887c9913", "filename": "gcc/tree-loop-distribution.c", "status": "modified", "additions": 36, "deletions": 36, "changes": 72, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-loop-distribution.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-loop-distribution.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-loop-distribution.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -73,7 +73,7 @@ along with GCC; see the file COPYING3.  If not see\n \n \n /* A Reduced Dependence Graph (RDG) vertex representing a statement.  */\n-typedef struct rdg_vertex\n+struct rdg_vertex\n {\n   /* The statement represented by this vertex.  */\n   gimple *stmt;\n@@ -86,7 +86,7 @@ typedef struct rdg_vertex\n \n   /* True when the statement contains a read from memory.  */\n   bool has_mem_reads;\n-} *rdg_vertex_p;\n+};\n \n #define RDGV_STMT(V)     ((struct rdg_vertex *) ((V)->data))->stmt\n #define RDGV_DATAREFS(V) ((struct rdg_vertex *) ((V)->data))->datarefs\n@@ -110,11 +110,11 @@ enum rdg_dep_type\n \n /* Dependence information attached to an edge of the RDG.  */\n \n-typedef struct rdg_edge\n+struct rdg_edge\n {\n   /* Type of the dependence.  */\n   enum rdg_dep_type type;\n-} *rdg_edge_p;\n+};\n \n #define RDGE_TYPE(E)        ((struct rdg_edge *) ((E)->data))->type\n \n@@ -474,7 +474,7 @@ enum partition_kind {\n     PKIND_NORMAL, PKIND_MEMSET, PKIND_MEMCPY\n };\n \n-typedef struct partition_s\n+struct partition\n {\n   bitmap stmts;\n   bitmap loops;\n@@ -485,15 +485,15 @@ typedef struct partition_s\n   data_reference_p secondary_dr;\n   tree niter;\n   bool plus_one;\n-} *partition_t;\n+};\n \n \n /* Allocate and initialize a partition from BITMAP.  */\n \n-static partition_t\n+static partition *\n partition_alloc (bitmap stmts, bitmap loops)\n {\n-  partition_t partition = XCNEW (struct partition_s);\n+  partition *partition = XCNEW (struct partition);\n   partition->stmts = stmts ? stmts : BITMAP_ALLOC (NULL);\n   partition->loops = loops ? loops : BITMAP_ALLOC (NULL);\n   partition->reduction_p = false;\n@@ -504,7 +504,7 @@ partition_alloc (bitmap stmts, bitmap loops)\n /* Free PARTITION.  */\n \n static void\n-partition_free (partition_t partition)\n+partition_free (partition *partition)\n {\n   BITMAP_FREE (partition->stmts);\n   BITMAP_FREE (partition->loops);\n@@ -514,23 +514,23 @@ partition_free (partition_t partition)\n /* Returns true if the partition can be generated as a builtin.  */\n \n static bool\n-partition_builtin_p (partition_t partition)\n+partition_builtin_p (partition *partition)\n {\n   return partition->kind != PKIND_NORMAL;\n }\n \n /* Returns true if the partition contains a reduction.  */\n \n static bool\n-partition_reduction_p (partition_t partition)\n+partition_reduction_p (partition *partition)\n {\n   return partition->reduction_p;\n }\n \n /* Merge PARTITION into the partition DEST.  */\n \n static void\n-partition_merge_into (partition_t dest, partition_t partition)\n+partition_merge_into (partition *dest, partition *partition)\n {\n   dest->kind = PKIND_NORMAL;\n   bitmap_ior_into (dest->stmts, partition->stmts);\n@@ -615,7 +615,7 @@ create_bb_after_loop (struct loop *loop)\n    basic blocks of a loop are taken in dom order.  */\n \n static void\n-generate_loops_for_partition (struct loop *loop, partition_t partition,\n+generate_loops_for_partition (struct loop *loop, partition *partition,\n \t\t\t      bool copy_p)\n {\n   unsigned i;\n@@ -776,7 +776,7 @@ const_with_all_bytes_same (tree val)\n /* Generate a call to memset for PARTITION in LOOP.  */\n \n static void\n-generate_memset_builtin (struct loop *loop, partition_t partition)\n+generate_memset_builtin (struct loop *loop, partition *partition)\n {\n   gimple_stmt_iterator gsi;\n   gimple *stmt, *fn_call;\n@@ -832,7 +832,7 @@ generate_memset_builtin (struct loop *loop, partition_t partition)\n /* Generate a call to memcpy for PARTITION in LOOP.  */\n \n static void\n-generate_memcpy_builtin (struct loop *loop, partition_t partition)\n+generate_memcpy_builtin (struct loop *loop, partition *partition)\n {\n   gimple_stmt_iterator gsi;\n   gimple *stmt, *fn_call;\n@@ -927,7 +927,7 @@ destroy_loop (struct loop *loop)\n \n static void\n generate_code_for_partition (struct loop *loop,\n-\t\t\t     partition_t partition, bool copy_p)\n+\t\t\t     partition *partition, bool copy_p)\n {\n   switch (partition->kind)\n     {\n@@ -960,10 +960,10 @@ generate_code_for_partition (struct loop *loop,\n /* Returns a partition with all the statements needed for computing\n    the vertex V of the RDG, also including the loop exit conditions.  */\n \n-static partition_t\n+static partition *\n build_rdg_partition_for_vertex (struct graph *rdg, int v)\n {\n-  partition_t partition = partition_alloc (NULL, NULL);\n+  partition *partition = partition_alloc (NULL, NULL);\n   auto_vec<int, 3> nodes;\n   unsigned i;\n   int x;\n@@ -984,7 +984,7 @@ build_rdg_partition_for_vertex (struct graph *rdg, int v)\n    For the moment we detect only the memset zero pattern.  */\n \n static void\n-classify_partition (loop_p loop, struct graph *rdg, partition_t partition)\n+classify_partition (loop_p loop, struct graph *rdg, partition *partition)\n {\n   bitmap_iterator bi;\n   unsigned i;\n@@ -1167,8 +1167,8 @@ ref_base_address (data_reference_p dr)\n    accesses in RDG.  */\n \n static bool\n-similar_memory_accesses (struct graph *rdg, partition_t partition1,\n-\t\t\t partition_t partition2)\n+similar_memory_accesses (struct graph *rdg, partition *partition1,\n+\t\t\t partition *partition2)\n {\n   unsigned i, j, k, l;\n   bitmap_iterator bi, bj;\n@@ -1210,7 +1210,7 @@ similar_memory_accesses (struct graph *rdg, partition_t partition1,\n static void\n rdg_build_partitions (struct graph *rdg,\n \t\t      vec<gimple *> starting_stmts,\n-\t\t      vec<partition_t> *partitions)\n+\t\t      vec<partition *> *partitions)\n {\n   bitmap processed = BITMAP_ALLOC (NULL);\n   int i;\n@@ -1229,7 +1229,7 @@ rdg_build_partitions (struct graph *rdg,\n       if (bitmap_bit_p (processed, v))\n \tcontinue;\n \n-      partition_t partition = build_rdg_partition_for_vertex (rdg, v);\n+      partition *partition = build_rdg_partition_for_vertex (rdg, v);\n       bitmap_ior_into (processed, partition->stmts);\n \n       if (dump_file && (dump_flags & TDF_DETAILS))\n@@ -1250,20 +1250,20 @@ rdg_build_partitions (struct graph *rdg,\n /* Dump to FILE the PARTITIONS.  */\n \n static void\n-dump_rdg_partitions (FILE *file, vec<partition_t> partitions)\n+dump_rdg_partitions (FILE *file, vec<partition *> partitions)\n {\n   int i;\n-  partition_t partition;\n+  partition *partition;\n \n   FOR_EACH_VEC_ELT (partitions, i, partition)\n     debug_bitmap_file (file, partition->stmts);\n }\n \n /* Debug PARTITIONS.  */\n-extern void debug_rdg_partitions (vec<partition_t> );\n+extern void debug_rdg_partitions (vec<partition *> );\n \n DEBUG_FUNCTION void\n-debug_rdg_partitions (vec<partition_t> partitions)\n+debug_rdg_partitions (vec<partition *> partitions)\n {\n   dump_rdg_partitions (stderr, partitions);\n }\n@@ -1291,7 +1291,7 @@ number_of_rw_in_rdg (struct graph *rdg)\n    the RDG.  */\n \n static int\n-number_of_rw_in_partition (struct graph *rdg, partition_t partition)\n+number_of_rw_in_partition (struct graph *rdg, partition *partition)\n {\n   int res = 0;\n   unsigned i;\n@@ -1314,10 +1314,10 @@ number_of_rw_in_partition (struct graph *rdg, partition_t partition)\n \n static bool\n partition_contains_all_rw (struct graph *rdg,\n-\t\t\t   vec<partition_t> partitions)\n+\t\t\t   vec<partition *> partitions)\n {\n   int i;\n-  partition_t partition;\n+  partition *partition;\n   int nrw = number_of_rw_in_rdg (rdg);\n \n   FOR_EACH_VEC_ELT (partitions, i, partition)\n@@ -1410,7 +1410,7 @@ distribute_loop (struct loop *loop, vec<gimple *> stmts,\n \t\t control_dependences *cd, int *nb_calls)\n {\n   struct graph *rdg;\n-  partition_t partition;\n+  partition *partition;\n   bool any_builtin;\n   int i, nbp;\n   graph *pg = NULL;\n@@ -1435,7 +1435,7 @@ distribute_loop (struct loop *loop, vec<gimple *> stmts,\n   if (dump_file && (dump_flags & TDF_DETAILS))\n     dump_rdg (dump_file, rdg);\n \n-  auto_vec<partition_t, 3> partitions;\n+  auto_vec<struct partition *, 3> partitions;\n   rdg_build_partitions (rdg, stmts, &partitions);\n \n   any_builtin = false;\n@@ -1458,7 +1458,7 @@ distribute_loop (struct loop *loop, vec<gimple *> stmts,\n      were not classified as builtins.  This also avoids chopping\n      a loop into pieces, separated by builtin calls.  That is, we\n      only want no or a single loop body remaining.  */\n-  partition_t into;\n+  struct partition *into;\n   if (!flag_tree_loop_distribution)\n     {\n       for (i = 0; partitions.iterate (i, &into); ++i)\n@@ -1535,7 +1535,7 @@ distribute_loop (struct loop *loop, vec<gimple *> stmts,\n     {\n       pg = new_graph (partitions.length ());\n       struct pgdata {\n-\t  partition_t partition;\n+\t  struct partition *partition;\n \t  vec<data_reference_p> writes;\n \t  vec<data_reference_p> reads;\n       };\n@@ -1559,7 +1559,7 @@ distribute_loop (struct loop *loop, vec<gimple *> stmts,\n \t      else\n \t\tdata->writes.safe_push (dr);\n \t}\n-      partition_t partition1, partition2;\n+      struct partition *partition1, *partition2;\n       for (i = 0; partitions.iterate (i, &partition1); ++i)\n \tfor (int j = i + 1; partitions.iterate (j, &partition2); ++j)\n \t  {\n@@ -1599,7 +1599,7 @@ distribute_loop (struct loop *loop, vec<gimple *> stmts,\n       num_sccs = graphds_scc (pg, NULL);\n       for (i = 0; i < num_sccs; ++i)\n \t{\n-\t  partition_t first;\n+\t  struct partition *first;\n \t  int j;\n \t  for (j = 0; partitions.iterate (j, &first); ++j)\n \t    if (pg->vertices[j].component == i)"}, {"sha": "fd716a6efe9cd28acfa69d6c2587247f4e4138b6", "filename": "gcc/tree-ssa-coalesce.c", "status": "modified", "additions": 70, "deletions": 71, "changes": 141, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-coalesce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-coalesce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-coalesce.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -51,13 +51,12 @@ along with GCC; see the file COPYING3.  If not see\n \n /* This structure defines a pair entry.  */\n \n-typedef struct coalesce_pair\n+struct coalesce_pair\n {\n   int first_element;\n   int second_element;\n   int cost;\n-} * coalesce_pair_p;\n-typedef const struct coalesce_pair *const_coalesce_pair_p;\n+};\n \n /* Coalesce pair hashtable helpers.  */\n \n@@ -92,22 +91,22 @@ typedef hash_table<coalesce_pair_hasher> coalesce_table_type;\n typedef coalesce_table_type::iterator coalesce_iterator_type;\n \n \n-typedef struct cost_one_pair_d\n+struct cost_one_pair\n {\n   int first_element;\n   int second_element;\n-  struct cost_one_pair_d *next;\n-} * cost_one_pair_p;\n+  cost_one_pair *next;\n+};\n \n /* This structure maintains the list of coalesce pairs.  */\n \n-typedef struct coalesce_list_d\n+struct coalesce_list\n {\n   coalesce_table_type *list;\t/* Hash table.  */\n-  coalesce_pair_p *sorted;\t/* List when sorted.  */\n+  coalesce_pair **sorted;\t/* List when sorted.  */\n   int num_sorted;\t\t/* Number in the sorted list.  */\n-  cost_one_pair_p cost_one_list;/* Single use coalesces with cost 1.  */\n-} *coalesce_list_p;\n+  cost_one_pair *cost_one_list;/* Single use coalesces with cost 1.  */\n+};\n \n #define NO_BEST_COALESCE\t-1\n #define MUST_COALESCE_COST\tINT_MAX\n@@ -185,9 +184,9 @@ coalesce_cost_edge (edge e)\n    NO_BEST_COALESCE is returned if there aren't any.  */\n \n static inline int\n-pop_cost_one_pair (coalesce_list_p cl, int *p1, int *p2)\n+pop_cost_one_pair (coalesce_list *cl, int *p1, int *p2)\n {\n-  cost_one_pair_p ptr;\n+  cost_one_pair *ptr;\n \n   ptr = cl->cost_one_list;\n   if (!ptr)\n@@ -207,9 +206,9 @@ pop_cost_one_pair (coalesce_list_p cl, int *p1, int *p2)\n    NO_BEST_COALESCE is returned if the coalesce list is empty.  */\n \n static inline int\n-pop_best_coalesce (coalesce_list_p cl, int *p1, int *p2)\n+pop_best_coalesce (coalesce_list *cl, int *p1, int *p2)\n {\n-  coalesce_pair_p node;\n+  coalesce_pair *node;\n   int ret;\n \n   if (cl->sorted == NULL)\n@@ -230,16 +229,16 @@ pop_best_coalesce (coalesce_list_p cl, int *p1, int *p2)\n \n /* Create a new empty coalesce list object and return it.  */\n \n-static inline coalesce_list_p\n+static inline coalesce_list *\n create_coalesce_list (void)\n {\n-  coalesce_list_p list;\n+  coalesce_list *list;\n   unsigned size = num_ssa_names * 3;\n \n   if (size < 40)\n     size = 40;\n \n-  list = (coalesce_list_p) xmalloc (sizeof (struct coalesce_list_d));\n+  list = (coalesce_list *) xmalloc (sizeof (struct coalesce_list));\n   list->list = new coalesce_table_type (size);\n   list->sorted = NULL;\n   list->num_sorted = 0;\n@@ -251,7 +250,7 @@ create_coalesce_list (void)\n /* Delete coalesce list CL.  */\n \n static inline void\n-delete_coalesce_list (coalesce_list_p cl)\n+delete_coalesce_list (coalesce_list *cl)\n {\n   gcc_assert (cl->cost_one_list == NULL);\n   delete cl->list;\n@@ -266,8 +265,8 @@ delete_coalesce_list (coalesce_list_p cl)\n    one isn't found, return NULL if CREATE is false, otherwise create a new\n    coalesce pair object and return it.  */\n \n-static coalesce_pair_p\n-find_coalesce_pair (coalesce_list_p cl, int p1, int p2, bool create)\n+static coalesce_pair *\n+find_coalesce_pair (coalesce_list *cl, int p1, int p2, bool create)\n {\n   struct coalesce_pair p;\n   coalesce_pair **slot;\n@@ -304,11 +303,11 @@ find_coalesce_pair (coalesce_list_p cl, int p1, int p2, bool create)\n }\n \n static inline void\n-add_cost_one_coalesce (coalesce_list_p cl, int p1, int p2)\n+add_cost_one_coalesce (coalesce_list *cl, int p1, int p2)\n {\n-  cost_one_pair_p pair;\n+  cost_one_pair *pair;\n \n-  pair = XNEW (struct cost_one_pair_d);\n+  pair = XNEW (cost_one_pair);\n   pair->first_element = p1;\n   pair->second_element = p2;\n   pair->next = cl->cost_one_list;\n@@ -319,9 +318,9 @@ add_cost_one_coalesce (coalesce_list_p cl, int p1, int p2)\n /* Add a coalesce between P1 and P2 in list CL with a cost of VALUE.  */\n \n static inline void\n-add_coalesce (coalesce_list_p cl, int p1, int p2, int value)\n+add_coalesce (coalesce_list *cl, int p1, int p2, int value)\n {\n-  coalesce_pair_p node;\n+  coalesce_pair *node;\n \n   gcc_assert (cl->sorted == NULL);\n   if (p1 == p2)\n@@ -345,8 +344,8 @@ add_coalesce (coalesce_list_p cl, int p1, int p2, int value)\n static int\n compare_pairs (const void *p1, const void *p2)\n {\n-  const_coalesce_pair_p const *const pp1 = (const_coalesce_pair_p const *) p1;\n-  const_coalesce_pair_p const *const pp2 = (const_coalesce_pair_p const *) p2;\n+  const coalesce_pair *const *const pp1 = (const coalesce_pair *const *) p1;\n+  const coalesce_pair *const *const pp2 = (const coalesce_pair *const *) p2;\n   int result;\n \n   result = (* pp1)->cost - (* pp2)->cost;\n@@ -367,7 +366,7 @@ compare_pairs (const void *p1, const void *p2)\n /* Return the number of unique coalesce pairs in CL.  */\n \n static inline int\n-num_coalesce_pairs (coalesce_list_p cl)\n+num_coalesce_pairs (coalesce_list *cl)\n {\n   return cl->list->elements ();\n }\n@@ -383,10 +382,10 @@ num_coalesce_pairs (coalesce_list_p cl)\n    in order from most important coalesce to least important.  */\n \n static void\n-sort_coalesce_list (coalesce_list_p cl)\n+sort_coalesce_list (coalesce_list *cl)\n {\n   unsigned x, num;\n-  coalesce_pair_p p;\n+  coalesce_pair *p;\n   coalesce_iterator_type ppi;\n \n   gcc_assert (cl->sorted == NULL);\n@@ -397,7 +396,7 @@ sort_coalesce_list (coalesce_list_p cl)\n     return;\n \n   /* Allocate a vector for the pair pointers.  */\n-  cl->sorted = XNEWVEC (coalesce_pair_p, num);\n+  cl->sorted = XNEWVEC (coalesce_pair *, num);\n \n   /* Populate the vector with pointers to the pairs.  */\n   x = 0;\n@@ -421,16 +420,16 @@ sort_coalesce_list (coalesce_list_p cl)\n      ??? Maybe std::sort will do better, provided that compare_pairs\n      can be inlined.  */\n   if (num > 2)\n-      qsort (cl->sorted, num, sizeof (coalesce_pair_p), compare_pairs);\n+      qsort (cl->sorted, num, sizeof (coalesce_pair *), compare_pairs);\n }\n \n \n /* Send debug info for coalesce list CL to file F.  */\n \n static void\n-dump_coalesce_list (FILE *f, coalesce_list_p cl)\n+dump_coalesce_list (FILE *f, coalesce_list *cl)\n {\n-  coalesce_pair_p node;\n+  coalesce_pair *node;\n   coalesce_iterator_type ppi;\n \n   int x;\n@@ -472,20 +471,20 @@ dump_coalesce_list (FILE *f, coalesce_list_p cl)\n    A full matrix is used for conflicts rather than just upper triangular form.\n    this make sit much simpler and faster to perform conflict merges.  */\n \n-typedef struct ssa_conflicts_d\n+struct ssa_conflicts\n {\n   bitmap_obstack obstack;\t/* A place to allocate our bitmaps.  */\n   vec<bitmap> conflicts;\n-} * ssa_conflicts_p;\n+};\n \n /* Return an empty new conflict graph for SIZE elements.  */\n \n-static inline ssa_conflicts_p\n+static inline ssa_conflicts *\n ssa_conflicts_new (unsigned size)\n {\n-  ssa_conflicts_p ptr;\n+  ssa_conflicts *ptr;\n \n-  ptr = XNEW (struct ssa_conflicts_d);\n+  ptr = XNEW (ssa_conflicts);\n   bitmap_obstack_initialize (&ptr->obstack);\n   ptr->conflicts.create (size);\n   ptr->conflicts.safe_grow_cleared (size);\n@@ -496,7 +495,7 @@ ssa_conflicts_new (unsigned size)\n /* Free storage for conflict graph PTR.  */\n \n static inline void\n-ssa_conflicts_delete (ssa_conflicts_p ptr)\n+ssa_conflicts_delete (ssa_conflicts *ptr)\n {\n   bitmap_obstack_release (&ptr->obstack);\n   ptr->conflicts.release ();\n@@ -507,7 +506,7 @@ ssa_conflicts_delete (ssa_conflicts_p ptr)\n /* Test if elements X and Y conflict in graph PTR.  */\n \n static inline bool\n-ssa_conflicts_test_p (ssa_conflicts_p ptr, unsigned x, unsigned y)\n+ssa_conflicts_test_p (ssa_conflicts *ptr, unsigned x, unsigned y)\n {\n   bitmap bx = ptr->conflicts[x];\n   bitmap by = ptr->conflicts[y];\n@@ -525,7 +524,7 @@ ssa_conflicts_test_p (ssa_conflicts_p ptr, unsigned x, unsigned y)\n /* Add a conflict with Y to the bitmap for X in graph PTR.  */\n \n static inline void\n-ssa_conflicts_add_one (ssa_conflicts_p ptr, unsigned x, unsigned y)\n+ssa_conflicts_add_one (ssa_conflicts *ptr, unsigned x, unsigned y)\n {\n   bitmap bx = ptr->conflicts[x];\n   /* If there are no conflicts yet, allocate the bitmap and set bit.  */\n@@ -538,7 +537,7 @@ ssa_conflicts_add_one (ssa_conflicts_p ptr, unsigned x, unsigned y)\n /* Add conflicts between X and Y in graph PTR.  */\n \n static inline void\n-ssa_conflicts_add (ssa_conflicts_p ptr, unsigned x, unsigned y)\n+ssa_conflicts_add (ssa_conflicts *ptr, unsigned x, unsigned y)\n {\n   gcc_checking_assert (x != y);\n   ssa_conflicts_add_one (ptr, x, y);\n@@ -549,7 +548,7 @@ ssa_conflicts_add (ssa_conflicts_p ptr, unsigned x, unsigned y)\n /* Merge all Y's conflict into X in graph PTR.  */\n \n static inline void\n-ssa_conflicts_merge (ssa_conflicts_p ptr, unsigned x, unsigned y)\n+ssa_conflicts_merge (ssa_conflicts *ptr, unsigned x, unsigned y)\n {\n   unsigned z;\n   bitmap_iterator bi;\n@@ -589,7 +588,7 @@ ssa_conflicts_merge (ssa_conflicts_p ptr, unsigned x, unsigned y)\n /* Dump a conflicts graph.  */\n \n static void\n-ssa_conflicts_dump (FILE *file, ssa_conflicts_p ptr)\n+ssa_conflicts_dump (FILE *file, ssa_conflicts *ptr)\n {\n   unsigned x;\n   bitmap b;\n@@ -617,28 +616,28 @@ ssa_conflicts_dump (FILE *file, ssa_conflicts_p ptr)\n    marked as being live.  This delays clearing of these bitmaps until\n    they are actually needed again.  */\n \n-typedef struct live_track_d\n+struct live_track\n {\n   bitmap_obstack obstack;\t/* A place to allocate our bitmaps.  */\n   bitmap live_base_var;\t\t/* Indicates if a basevar is live.  */\n   bitmap *live_base_partitions;\t/* Live partitions for each basevar.  */\n   var_map map;\t\t\t/* Var_map being used for partition mapping.  */\n-} * live_track_p;\n+};\n \n \n /* This routine will create a new live track structure based on the partitions\n    in MAP.  */\n \n-static live_track_p\n+static live_track *\n new_live_track (var_map map)\n {\n-  live_track_p ptr;\n+  live_track *ptr;\n   int lim, x;\n \n   /* Make sure there is a partition view in place.  */\n   gcc_assert (map->partition_to_base_index != NULL);\n \n-  ptr = (live_track_p) xmalloc (sizeof (struct live_track_d));\n+  ptr = (live_track *) xmalloc (sizeof (live_track));\n   ptr->map = map;\n   lim = num_basevars (map);\n   bitmap_obstack_initialize (&ptr->obstack);\n@@ -653,7 +652,7 @@ new_live_track (var_map map)\n /* This routine will free the memory associated with PTR.  */\n \n static void\n-delete_live_track (live_track_p ptr)\n+delete_live_track (live_track *ptr)\n {\n   bitmap_obstack_release (&ptr->obstack);\n   free (ptr->live_base_partitions);\n@@ -664,7 +663,7 @@ delete_live_track (live_track_p ptr)\n /* This function will remove PARTITION from the live list in PTR.  */\n \n static inline void\n-live_track_remove_partition (live_track_p ptr, int partition)\n+live_track_remove_partition (live_track *ptr, int partition)\n {\n   int root;\n \n@@ -679,7 +678,7 @@ live_track_remove_partition (live_track_p ptr, int partition)\n /* This function will adds PARTITION to the live list in PTR.  */\n \n static inline void\n-live_track_add_partition (live_track_p ptr, int partition)\n+live_track_add_partition (live_track *ptr, int partition)\n {\n   int root;\n \n@@ -696,7 +695,7 @@ live_track_add_partition (live_track_p ptr, int partition)\n /* Clear the live bit for VAR in PTR.  */\n \n static inline void\n-live_track_clear_var (live_track_p ptr, tree var)\n+live_track_clear_var (live_track *ptr, tree var)\n {\n   int p;\n \n@@ -709,7 +708,7 @@ live_track_clear_var (live_track_p ptr, tree var)\n /* Return TRUE if VAR is live in PTR.  */\n \n static inline bool\n-live_track_live_p (live_track_p ptr, tree var)\n+live_track_live_p (live_track *ptr, tree var)\n {\n   int p, root;\n \n@@ -728,7 +727,7 @@ live_track_live_p (live_track_p ptr, tree var)\n    ssa live map and the live bitmap for the root of USE.  */\n \n static inline void\n-live_track_process_use (live_track_p ptr, tree use)\n+live_track_process_use (live_track *ptr, tree use)\n {\n   int p;\n \n@@ -746,7 +745,7 @@ live_track_process_use (live_track_p ptr, tree use)\n    variable, conflicts will be added to GRAPH.  */\n \n static inline void\n-live_track_process_def (live_track_p ptr, tree def, ssa_conflicts_p graph)\n+live_track_process_def (live_track *ptr, tree def, ssa_conflicts *graph)\n {\n   int p, root;\n   bitmap b;\n@@ -774,7 +773,7 @@ live_track_process_def (live_track_p ptr, tree def, ssa_conflicts_p graph)\n /* Initialize PTR with the partitions set in INIT.  */\n \n static inline void\n-live_track_init (live_track_p ptr, bitmap init)\n+live_track_init (live_track *ptr, bitmap init)\n {\n   unsigned p;\n   bitmap_iterator bi;\n@@ -788,7 +787,7 @@ live_track_init (live_track_p ptr, bitmap init)\n /* This routine will clear all live partitions in PTR.   */\n \n static inline void\n-live_track_clear_base_vars (live_track_p ptr)\n+live_track_clear_base_vars (live_track *ptr)\n {\n   /* Simply clear the live base list.  Anything marked as live in the element\n      lists will be cleared later if/when the base variable ever comes alive\n@@ -802,14 +801,14 @@ live_track_clear_base_vars (live_track_p ptr)\n    conflict graph.  Only conflicts between ssa_name partitions with the same\n    base variable are added.  */\n \n-static ssa_conflicts_p\n+static ssa_conflicts *\n build_ssa_conflict_graph (tree_live_info_p liveinfo)\n {\n-  ssa_conflicts_p graph;\n+  ssa_conflicts *graph;\n   var_map map;\n   basic_block bb;\n   ssa_op_iter iter;\n-  live_track_p live;\n+  live_track *live;\n   basic_block entry;\n \n   /* If inter-variable coalescing is enabled, we may attempt to\n@@ -992,7 +991,7 @@ register_default_def (tree var, void *map_)\n    coalescing.  */\n \n static void\n-coalesce_with_default (tree var, coalesce_list_p cl, bitmap used_in_copy)\n+coalesce_with_default (tree var, coalesce_list *cl, bitmap used_in_copy)\n {\n   if (SSA_NAME_IS_DEFAULT_DEF (var)\n       || !SSA_NAME_VAR (var)\n@@ -1013,7 +1012,7 @@ coalesce_with_default (tree var, coalesce_list_p cl, bitmap used_in_copy)\n    a coalesce list for use later in the out of ssa process.  */\n \n static var_map\n-create_outofssa_var_map (coalesce_list_p cl, bitmap used_in_copy)\n+create_outofssa_var_map (coalesce_list *cl, bitmap used_in_copy)\n {\n   gimple_stmt_iterator gsi;\n   basic_block bb;\n@@ -1237,7 +1236,7 @@ create_outofssa_var_map (coalesce_list_p cl, bitmap used_in_copy)\n    DEBUG, if it is nun-NULL.  */\n \n static inline bool\n-attempt_coalesce (var_map map, ssa_conflicts_p graph, int x, int y,\n+attempt_coalesce (var_map map, ssa_conflicts *graph, int x, int y,\n \t\t  FILE *debug)\n {\n   int z;\n@@ -1303,7 +1302,7 @@ attempt_coalesce (var_map map, ssa_conflicts_p graph, int x, int y,\n    GRAPH.  Debug output is sent to DEBUG if it is non-NULL.  */\n \n static void\n-coalesce_partitions (var_map map, ssa_conflicts_p graph, coalesce_list_p cl,\n+coalesce_partitions (var_map map, ssa_conflicts *graph, coalesce_list *cl,\n \t\t     FILE *debug)\n {\n   int x = 0, y = 0;\n@@ -1523,7 +1522,7 @@ gimple_can_coalesce_p (tree name1, tree name2)\n \n static void\n compute_optimized_partition_bases (var_map map, bitmap used_in_copies,\n-\t\t\t\t   coalesce_list_p cl)\n+\t\t\t\t   coalesce_list *cl)\n {\n   int parts = num_var_partitions (map);\n   partition tentative = partition_new (parts);\n@@ -1532,7 +1531,7 @@ compute_optimized_partition_bases (var_map map, bitmap used_in_copies,\n      pair, both of its members are in the same partition in\n      TENTATIVE.  */\n   gcc_assert (!cl->sorted);\n-  coalesce_pair_p node;\n+  coalesce_pair *node;\n   coalesce_iterator_type ppi;\n   FOR_EACH_PARTITION_PAIR (node, ppi, cl)\n     {\n@@ -1548,7 +1547,7 @@ compute_optimized_partition_bases (var_map map, bitmap used_in_copies,\n     }\n \n   /* We have to deal with cost one pairs too.  */\n-  for (cost_one_pair_d *co = cl->cost_one_list; co; co = co->next)\n+  for (cost_one_pair *co = cl->cost_one_list; co; co = co->next)\n     {\n       tree v1 = ssa_name (co->first_element);\n       int p1 = partition_find (tentative, var_to_partition (map, v1));\n@@ -1726,8 +1725,8 @@ extern var_map\n coalesce_ssa_name (void)\n {\n   tree_live_info_p liveinfo;\n-  ssa_conflicts_p graph;\n-  coalesce_list_p cl;\n+  ssa_conflicts *graph;\n+  coalesce_list *cl;\n   bitmap used_in_copies = BITMAP_ALLOC (NULL);\n   var_map map;\n   unsigned int i;"}, {"sha": "945d34b4fa84d64424fcb95bc9324bdf271e5698", "filename": "gcc/tree-ssa-loop-ivopts.c", "status": "modified", "additions": 7, "deletions": 11, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-loop-ivopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-loop-ivopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-ivopts.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -267,10 +267,6 @@ struct iv_inv_expr_ent\n \n /* The data used by the induction variable optimizations.  */\n \n-typedef struct iv_use *iv_use_p;\n-\n-typedef struct iv_cand *iv_cand_p;\n-\n /* Hashtable helpers.  */\n \n struct iv_inv_expr_hasher : free_ptr_hash <iv_inv_expr_ent>\n@@ -326,10 +322,10 @@ struct ivopts_data\n   bitmap relevant;\n \n   /* The uses of induction variables.  */\n-  vec<iv_use_p> iv_uses;\n+  vec<iv_use *> iv_uses;\n \n   /* The candidates.  */\n-  vec<iv_cand_p> iv_candidates;\n+  vec<iv_cand *> iv_candidates;\n \n   /* A bitmap of important candidates.  */\n   bitmap important_candidates;\n@@ -3747,12 +3743,12 @@ enum ainc_type\n   AINC_NONE\t\t/* Also the number of auto increment types.  */\n };\n \n-typedef struct address_cost_data_s\n+struct address_cost_data\n {\n   HOST_WIDE_INT min_offset, max_offset;\n   unsigned costs[2][2][2][2];\n   unsigned ainc_costs[AINC_NONE];\n-} *address_cost_data;\n+};\n \n \n static comp_cost\n@@ -3763,9 +3759,9 @@ get_address_cost (bool symbol_present, bool var_present,\n \t\t  bool stmt_after_inc, bool *may_autoinc)\n {\n   machine_mode address_mode = targetm.addr_space.address_mode (as);\n-  static vec<address_cost_data> address_cost_data_list;\n+  static vec<address_cost_data *> address_cost_data_list;\n   unsigned int data_index = (int) as * MAX_MACHINE_MODE + (int) mem_mode;\n-  address_cost_data data;\n+  address_cost_data *data;\n   static bool has_preinc[MAX_MACHINE_MODE], has_postinc[MAX_MACHINE_MODE];\n   static bool has_predec[MAX_MACHINE_MODE], has_postdec[MAX_MACHINE_MODE];\n   unsigned cost, acost, complexity;\n@@ -3789,7 +3785,7 @@ get_address_cost (bool symbol_present, bool var_present,\n       rtx addr, base;\n       rtx reg0, reg1;\n \n-      data = (address_cost_data) xcalloc (1, sizeof (*data));\n+      data = (address_cost_data *) xcalloc (1, sizeof (*data));\n \n       reg1 = gen_raw_REG (address_mode, LAST_VIRTUAL_REGISTER + 1);\n "}, {"sha": "5efee2128582f61691e64ee9e7f6940304ba02fd", "filename": "gcc/tree-ssa-reassoc.c", "status": "modified", "additions": 72, "deletions": 75, "changes": 147, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-reassoc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-reassoc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-reassoc.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -70,7 +70,7 @@ along with GCC; see the file COPYING3.  If not see\n     2. Left linearization of the expression trees, so that (A+B)+(C+D)\n     becomes (((A+B)+C)+D), which is easier for us to rewrite later.\n     During linearization, we place the operands of the binary\n-    expressions into a vector of operand_entry_t\n+    expressions into a vector of operand_entry_*\n \n     3. Optimization of the operand lists, eliminating things like a +\n     -a, a & a, etc.\n@@ -192,13 +192,13 @@ static struct\n } reassociate_stats;\n \n /* Operator, rank pair.  */\n-typedef struct operand_entry\n+struct operand_entry\n {\n   unsigned int rank;\n   int id;\n   tree op;\n   unsigned int count;\n-} *operand_entry_t;\n+};\n \n static object_allocator<operand_entry> operand_entry_pool\n   (\"operand entry pool\");\n@@ -493,8 +493,8 @@ constant_type (tree t)\n static int\n sort_by_operand_rank (const void *pa, const void *pb)\n {\n-  const operand_entry_t oea = *(const operand_entry_t *)pa;\n-  const operand_entry_t oeb = *(const operand_entry_t *)pb;\n+  const operand_entry *oea = *(const operand_entry *const *)pa;\n+  const operand_entry *oeb = *(const operand_entry *const *)pb;\n \n   /* It's nicer for optimize_expression if constants that are likely\n      to fold when added/multiplied//whatever are put next to each\n@@ -556,9 +556,9 @@ sort_by_operand_rank (const void *pa, const void *pb)\n /* Add an operand entry to *OPS for the tree operand OP.  */\n \n static void\n-add_to_ops_vec (vec<operand_entry_t> *ops, tree op)\n+add_to_ops_vec (vec<operand_entry *> *ops, tree op)\n {\n-  operand_entry_t oe = operand_entry_pool.allocate ();\n+  operand_entry *oe = operand_entry_pool.allocate ();\n \n   oe->op = op;\n   oe->rank = get_rank (op);\n@@ -571,10 +571,10 @@ add_to_ops_vec (vec<operand_entry_t> *ops, tree op)\n    count REPEAT.  */\n \n static void\n-add_repeat_to_ops_vec (vec<operand_entry_t> *ops, tree op,\n+add_repeat_to_ops_vec (vec<operand_entry *> *ops, tree op,\n \t\t       HOST_WIDE_INT repeat)\n {\n-  operand_entry_t oe = operand_entry_pool.allocate ();\n+  operand_entry *oe = operand_entry_pool.allocate ();\n \n   oe->op = op;\n   oe->rank = get_rank (op);\n@@ -630,11 +630,11 @@ get_unary_op (tree name, enum tree_code opcode)\n \n static bool\n eliminate_duplicate_pair (enum tree_code opcode,\n-\t\t\t  vec<operand_entry_t> *ops,\n+\t\t\t  vec<operand_entry *> *ops,\n \t\t\t  bool *all_done,\n \t\t\t  unsigned int i,\n-\t\t\t  operand_entry_t curr,\n-\t\t\t  operand_entry_t last)\n+\t\t\t  operand_entry *curr,\n+\t\t\t  operand_entry *last)\n {\n \n   /* If we have two of the same op, and the opcode is & |, min, or max,\n@@ -708,14 +708,14 @@ static vec<tree> plus_negates;\n \n static bool\n eliminate_plus_minus_pair (enum tree_code opcode,\n-\t\t\t   vec<operand_entry_t> *ops,\n+\t\t\t   vec<operand_entry *> *ops,\n \t\t\t   unsigned int currindex,\n-\t\t\t   operand_entry_t curr)\n+\t\t\t   operand_entry *curr)\n {\n   tree negateop;\n   tree notop;\n   unsigned int i;\n-  operand_entry_t oe;\n+  operand_entry *oe;\n \n   if (opcode != PLUS_EXPR || TREE_CODE (curr->op) != SSA_NAME)\n     return false;\n@@ -791,13 +791,13 @@ eliminate_plus_minus_pair (enum tree_code opcode,\n \n static bool\n eliminate_not_pairs (enum tree_code opcode,\n-\t\t     vec<operand_entry_t> *ops,\n+\t\t     vec<operand_entry *> *ops,\n \t\t     unsigned int currindex,\n-\t\t     operand_entry_t curr)\n+\t\t     operand_entry *curr)\n {\n   tree notop;\n   unsigned int i;\n-  operand_entry_t oe;\n+  operand_entry *oe;\n \n   if ((opcode != BIT_IOR_EXPR && opcode != BIT_AND_EXPR)\n       || TREE_CODE (curr->op) != SSA_NAME)\n@@ -857,9 +857,9 @@ eliminate_not_pairs (enum tree_code opcode,\n \n static void\n eliminate_using_constants (enum tree_code opcode,\n-\t\t\t   vec<operand_entry_t> *ops)\n+\t\t\t   vec<operand_entry *> *ops)\n {\n-  operand_entry_t oelast = ops->last ();\n+  operand_entry *oelast = ops->last ();\n   tree type = TREE_TYPE (oelast->op);\n \n   if (oelast->rank == 0\n@@ -978,7 +978,7 @@ eliminate_using_constants (enum tree_code opcode,\n }\n \n \n-static void linearize_expr_tree (vec<operand_entry_t> *, gimple *,\n+static void linearize_expr_tree (vec<operand_entry *> *, gimple *,\n \t\t\t\t bool, bool);\n \n /* Structure for tracking and counting operands.  */\n@@ -1365,15 +1365,15 @@ build_and_add_sum (tree type, tree op1, tree op2, enum tree_code opcode)\n \n static bool\n undistribute_ops_list (enum tree_code opcode,\n-\t\t       vec<operand_entry_t> *ops, struct loop *loop)\n+\t\t       vec<operand_entry *> *ops, struct loop *loop)\n {\n   unsigned int length = ops->length ();\n-  operand_entry_t oe1;\n+  operand_entry *oe1;\n   unsigned i, j;\n   sbitmap candidates, candidates2;\n   unsigned nr_candidates, nr_candidates2;\n   sbitmap_iterator sbi0;\n-  vec<operand_entry_t> *subops;\n+  vec<operand_entry *> *subops;\n   bool changed = false;\n   int next_oecount_id = 0;\n \n@@ -1426,7 +1426,7 @@ undistribute_ops_list (enum tree_code opcode,\n \n   /* ??? Macro arguments cannot have multi-argument template types in\n      them.  This typedef is needed to workaround that limitation.  */\n-  typedef vec<operand_entry_t> vec_operand_entry_t_heap;\n+  typedef vec<operand_entry *> vec_operand_entry_t_heap;\n   subops = XCNEWVEC (vec_operand_entry_t_heap, ops->length ());\n   EXECUTE_IF_SET_IN_BITMAP (candidates, 0, i, sbi0)\n     {\n@@ -1522,7 +1522,7 @@ undistribute_ops_list (enum tree_code opcode,\n \n       if (nr_candidates2 >= 2)\n \t{\n-\t  operand_entry_t oe1, oe2;\n+\t  operand_entry *oe1, *oe2;\n \t  gimple *prod;\n \t  int first = bitmap_first_set_bit (candidates2);\n \n@@ -1590,15 +1590,15 @@ undistribute_ops_list (enum tree_code opcode,\n \n static bool\n eliminate_redundant_comparison (enum tree_code opcode,\n-\t\t\t\tvec<operand_entry_t> *ops,\n+\t\t\t\tvec<operand_entry *> *ops,\n \t\t\t\tunsigned int currindex,\n-\t\t\t\toperand_entry_t curr)\n+\t\t\t\toperand_entry *curr)\n {\n   tree op1, op2;\n   enum tree_code lcode, rcode;\n   gimple *def1, *def2;\n   int i;\n-  operand_entry_t oe;\n+  operand_entry *oe;\n \n   if (opcode != BIT_IOR_EXPR && opcode != BIT_AND_EXPR)\n     return false;\n@@ -1715,12 +1715,12 @@ eliminate_redundant_comparison (enum tree_code opcode,\n \n static void\n optimize_ops_list (enum tree_code opcode,\n-\t\t   vec<operand_entry_t> *ops)\n+\t\t   vec<operand_entry *> *ops)\n {\n   unsigned int length = ops->length ();\n   unsigned int i;\n-  operand_entry_t oe;\n-  operand_entry_t oelast = NULL;\n+  operand_entry *oe;\n+  operand_entry *oelast = NULL;\n   bool iterate = false;\n \n   if (length == 1)\n@@ -1732,7 +1732,7 @@ optimize_ops_list (enum tree_code opcode,\n      and try the next two.  */\n   if (oelast->rank == 0 && is_gimple_min_invariant (oelast->op))\n     {\n-      operand_entry_t oelm1 = (*ops)[length - 2];\n+      operand_entry *oelm1 = (*ops)[length - 2];\n \n       if (oelm1->rank == 0\n \t  && is_gimple_min_invariant (oelm1->op)\n@@ -2052,10 +2052,10 @@ static bool\n update_range_test (struct range_entry *range, struct range_entry *otherrange,\n \t\t   struct range_entry **otherrangep,\n \t\t   unsigned int count, enum tree_code opcode,\n-\t\t   vec<operand_entry_t> *ops, tree exp, gimple_seq seq,\n+\t\t   vec<operand_entry *> *ops, tree exp, gimple_seq seq,\n \t\t   bool in_p, tree low, tree high, bool strict_overflow_p)\n {\n-  operand_entry_t oe = (*ops)[range->idx];\n+  operand_entry *oe = (*ops)[range->idx];\n   tree op = oe->op;\n   gimple *stmt = op ? SSA_NAME_DEF_STMT (op) :\n     last_stmt (BASIC_BLOCK_FOR_FN (cfun, oe->id));\n@@ -2199,7 +2199,7 @@ update_range_test (struct range_entry *range, struct range_entry *otherrange,\n static bool\n optimize_range_tests_xor (enum tree_code opcode, tree type,\n \t\t\t  tree lowi, tree lowj, tree highi, tree highj,\n-\t\t\t  vec<operand_entry_t> *ops,\n+\t\t\t  vec<operand_entry *> *ops,\n \t\t\t  struct range_entry *rangei,\n \t\t\t  struct range_entry *rangej)\n {\n@@ -2240,7 +2240,7 @@ optimize_range_tests_xor (enum tree_code opcode, tree type,\n static bool\n optimize_range_tests_diff (enum tree_code opcode, tree type,\n \t\t\t    tree lowi, tree lowj, tree highi, tree highj,\n-\t\t\t    vec<operand_entry_t> *ops,\n+\t\t\t    vec<operand_entry *> *ops,\n \t\t\t    struct range_entry *rangei,\n \t\t\t    struct range_entry *rangej)\n {\n@@ -2283,7 +2283,7 @@ optimize_range_tests_diff (enum tree_code opcode, tree type,\n \n static bool\n optimize_range_tests_1 (enum tree_code opcode, int first, int length,\n-\t\t\tbool optimize_xor, vec<operand_entry_t> *ops,\n+\t\t\tbool optimize_xor, vec<operand_entry *> *ops,\n \t\t\tstruct range_entry *ranges)\n {\n   int i, j;\n@@ -2420,7 +2420,7 @@ extract_bit_test_mask (tree exp, int prec, tree totallow, tree low, tree high,\n \n static bool\n optimize_range_tests_to_bit_test (enum tree_code opcode, int first, int length,\n-\t\t\t\t  vec<operand_entry_t> *ops,\n+\t\t\t\t  vec<operand_entry *> *ops,\n \t\t\t\t  struct range_entry *ranges)\n {\n   int i, j;\n@@ -2497,7 +2497,7 @@ optimize_range_tests_to_bit_test (enum tree_code opcode, int first, int length,\n \t  tree high = wide_int_to_tree (TREE_TYPE (lowi),\n \t\t\t\t\twi::to_widest (lowi)\n \t\t\t\t\t+ prec - 1 - wi::clz (mask));\n-\t  operand_entry_t oe = (*ops)[ranges[i].idx];\n+\t  operand_entry *oe = (*ops)[ranges[i].idx];\n \t  tree op = oe->op;\n \t  gimple *stmt = op ? SSA_NAME_DEF_STMT (op)\n \t\t\t   : last_stmt (BASIC_BLOCK_FOR_FN (cfun, oe->id));\n@@ -2594,10 +2594,10 @@ optimize_range_tests_to_bit_test (enum tree_code opcode, int first, int length,\n \n static bool\n optimize_range_tests (enum tree_code opcode,\n-\t\t      vec<operand_entry_t> *ops)\n+\t\t      vec<operand_entry *> *ops)\n {\n   unsigned int length = ops->length (), i, j, first;\n-  operand_entry_t oe;\n+  operand_entry *oe;\n   struct range_entry *ranges;\n   bool any_changes = false;\n \n@@ -2904,7 +2904,7 @@ no_side_effect_bb (basic_block bb)\n    return true and fill in *OPS recursively.  */\n \n static bool\n-get_ops (tree var, enum tree_code code, vec<operand_entry_t> *ops,\n+get_ops (tree var, enum tree_code code, vec<operand_entry *> *ops,\n \t struct loop *loop)\n {\n   gimple *stmt = SSA_NAME_DEF_STMT (var);\n@@ -2922,7 +2922,7 @@ get_ops (tree var, enum tree_code code, vec<operand_entry_t> *ops,\n \t&& !get_ops (rhs[i], code, ops, loop)\n \t&& has_single_use (rhs[i]))\n       {\n-\toperand_entry_t oe = operand_entry_pool.allocate ();\n+\toperand_entry *oe = operand_entry_pool.allocate ();\n \n \toe->op = rhs[i];\n \toe->rank = code;\n@@ -2938,7 +2938,7 @@ get_ops (tree var, enum tree_code code, vec<operand_entry_t> *ops,\n    stmts.  */\n \n static tree\n-update_ops (tree var, enum tree_code code, vec<operand_entry_t> ops,\n+update_ops (tree var, enum tree_code code, vec<operand_entry *> ops,\n \t    unsigned int *pidx, struct loop *loop)\n {\n   gimple *stmt = SSA_NAME_DEF_STMT (var);\n@@ -2998,7 +2998,7 @@ maybe_optimize_range_tests (gimple *stmt)\n   basic_block bb;\n   edge_iterator ei;\n   edge e;\n-  auto_vec<operand_entry_t> ops;\n+  auto_vec<operand_entry *> ops;\n   auto_vec<inter_bb_range_test_entry> bbinfo;\n   bool any_changes = false;\n \n@@ -3155,7 +3155,7 @@ maybe_optimize_range_tests (gimple *stmt)\n \t      && has_single_use (rhs))\n \t    {\n \t      /* Otherwise, push the _234 range test itself.  */\n-\t      operand_entry_t oe = operand_entry_pool.allocate ();\n+\t      operand_entry *oe = operand_entry_pool.allocate ();\n \n \t      oe->op = rhs;\n \t      oe->rank = code;\n@@ -3187,7 +3187,7 @@ maybe_optimize_range_tests (gimple *stmt)\n \t\t\t   loop_containing_stmt (stmt))))\n \t{\n \t  /* Or push the GIMPLE_COND stmt itself.  */\n-\t  operand_entry_t oe = operand_entry_pool.allocate ();\n+\t  operand_entry *oe = operand_entry_pool.allocate ();\n \n \t  oe->op = NULL;\n \t  oe->rank = (e->flags & EDGE_TRUE_VALUE)\n@@ -3395,10 +3395,10 @@ remove_visited_stmt_chain (tree var)\n    cases, but it is unlikely to be worth it.  */\n \n static void\n-swap_ops_for_binary_stmt (vec<operand_entry_t> ops,\n+swap_ops_for_binary_stmt (vec<operand_entry *> ops,\n \t\t\t  unsigned int opindex, gimple *stmt)\n {\n-  operand_entry_t oe1, oe2, oe3;\n+  operand_entry *oe1, *oe2, *oe3;\n \n   oe1 = ops[opindex];\n   oe2 = ops[opindex + 1];\n@@ -3410,7 +3410,7 @@ swap_ops_for_binary_stmt (vec<operand_entry_t> ops,\n \t  && !is_phi_for_stmt (stmt, oe1->op)\n \t  && !is_phi_for_stmt (stmt, oe2->op)))\n     {\n-      struct operand_entry temp = *oe3;\n+      operand_entry temp = *oe3;\n       oe3->op = oe1->op;\n       oe3->rank = oe1->rank;\n       oe1->op = temp.op;\n@@ -3422,7 +3422,7 @@ swap_ops_for_binary_stmt (vec<operand_entry_t> ops,\n \t       && !is_phi_for_stmt (stmt, oe1->op)\n \t       && !is_phi_for_stmt (stmt, oe3->op)))\n     {\n-      struct operand_entry temp = *oe2;\n+      operand_entry temp = *oe2;\n       oe2->op = oe1->op;\n       oe2->rank = oe1->rank;\n       oe1->op = temp.op;\n@@ -3451,12 +3451,12 @@ find_insert_point (gimple *stmt, tree rhs1, tree rhs2)\n \n static tree\n rewrite_expr_tree (gimple *stmt, unsigned int opindex,\n-\t\t   vec<operand_entry_t> ops, bool changed)\n+\t\t   vec<operand_entry *> ops, bool changed)\n {\n   tree rhs1 = gimple_assign_rhs1 (stmt);\n   tree rhs2 = gimple_assign_rhs2 (stmt);\n   tree lhs = gimple_assign_lhs (stmt);\n-  operand_entry_t oe;\n+  operand_entry *oe;\n \n   /* The final recursion case for this function is that you have\n      exactly two operations left.\n@@ -3465,7 +3465,7 @@ rewrite_expr_tree (gimple *stmt, unsigned int opindex,\n      rewrites them one at a time.  */\n   if (opindex + 2 == ops.length ())\n     {\n-      operand_entry_t oe1, oe2;\n+      operand_entry *oe1, *oe2;\n \n       oe1 = ops[opindex];\n       oe2 = ops[opindex + 1];\n@@ -3661,7 +3661,7 @@ get_reassociation_width (int ops_num, enum tree_code opc,\n \n static void\n rewrite_expr_tree_parallel (gassign *stmt, int width,\n-\t\t\t    vec<operand_entry_t> ops)\n+\t\t\t    vec<operand_entry *> ops)\n {\n   enum tree_code opcode = gimple_assign_rhs_code (stmt);\n   int op_num = ops.length ();\n@@ -4010,7 +4010,7 @@ acceptable_pow_call (gimple *stmt, tree *base, HOST_WIDE_INT *exponent)\n    Place the operands of the expression tree in the vector named OPS.  */\n \n static void\n-linearize_expr_tree (vec<operand_entry_t> *ops, gimple *stmt,\n+linearize_expr_tree (vec<operand_entry *> *ops, gimple *stmt,\n \t\t     bool is_associative, bool set_visited)\n {\n   tree binlhs = gimple_assign_rhs1 (stmt);\n@@ -4287,7 +4287,7 @@ break_up_subtract_bb (basic_block bb)\n }\n \n /* Used for repeated factor analysis.  */\n-struct repeat_factor_d\n+struct repeat_factor\n {\n   /* An SSA name that occurs in a multiply chain.  */\n   tree factor;\n@@ -4303,9 +4303,6 @@ struct repeat_factor_d\n   tree repr;\n };\n \n-typedef struct repeat_factor_d repeat_factor, *repeat_factor_t;\n-typedef const struct repeat_factor_d *const_repeat_factor_t;\n-\n \n static vec<repeat_factor> repeat_factor_vec;\n \n@@ -4315,8 +4312,8 @@ static vec<repeat_factor> repeat_factor_vec;\n static int\n compare_repeat_factors (const void *x1, const void *x2)\n {\n-  const_repeat_factor_t rf1 = (const_repeat_factor_t) x1;\n-  const_repeat_factor_t rf2 = (const_repeat_factor_t) x2;\n+  const repeat_factor *rf1 = (const repeat_factor *) x1;\n+  const repeat_factor *rf2 = (const repeat_factor *) x2;\n \n   if (rf1->count != rf2->count)\n     return rf1->count - rf2->count;\n@@ -4330,12 +4327,12 @@ compare_repeat_factors (const void *x1, const void *x2)\n    SSA name representing the value of the replacement sequence.  */\n \n static tree\n-attempt_builtin_powi (gimple *stmt, vec<operand_entry_t> *ops)\n+attempt_builtin_powi (gimple *stmt, vec<operand_entry *> *ops)\n {\n   unsigned i, j, vec_len;\n   int ii;\n-  operand_entry_t oe;\n-  repeat_factor_t rf1, rf2;\n+  operand_entry *oe;\n+  repeat_factor *rf1, *rf2;\n   repeat_factor rfnew;\n   tree result = NULL_TREE;\n   tree target_ssa, iter_result;\n@@ -4441,7 +4438,7 @@ attempt_builtin_powi (gimple *stmt, vec<operand_entry_t> *ops)\n \t      if (dump_file && (dump_flags & TDF_DETAILS))\n \t\t{\n \t\t  unsigned elt;\n-\t\t  repeat_factor_t rf;\n+\t\t  repeat_factor *rf;\n \t\t  fputs (\"Multiplying by cached product \", dump_file);\n \t\t  for (elt = j; elt < vec_len; elt++)\n \t\t    {\n@@ -4466,7 +4463,7 @@ attempt_builtin_powi (gimple *stmt, vec<operand_entry_t> *ops)\n \t      if (dump_file && (dump_flags & TDF_DETAILS))\n \t\t{\n \t\t  unsigned elt;\n-\t\t  repeat_factor_t rf;\n+\t\t  repeat_factor *rf;\n \t\t  fputs (\"Building __builtin_pow call for cached product (\",\n \t\t\t dump_file);\n \t\t  for (elt = j; elt < vec_len; elt++)\n@@ -4501,7 +4498,7 @@ attempt_builtin_powi (gimple *stmt, vec<operand_entry_t> *ops)\n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n \t    {\n \t      unsigned elt;\n-\t      repeat_factor_t rf;\n+\t      repeat_factor *rf;\n \t      fputs (\"Building __builtin_pow call for (\", dump_file);\n \t      for (elt = j; elt < vec_len; elt++)\n \t\t{\n@@ -4745,7 +4742,7 @@ reassociate_bb (basic_block bb)\n \n \t  if (associative_tree_code (rhs_code))\n \t    {\n-\t      auto_vec<operand_entry_t> ops;\n+\t      auto_vec<operand_entry *> ops;\n \t      tree powi_result = NULL_TREE;\n \n \t      /* There may be no immediate uses left by the time we\n@@ -4918,15 +4915,15 @@ branch_fixup (void)\n   reassoc_branch_fixups.release ();\n }\n \n-void dump_ops_vector (FILE *file, vec<operand_entry_t> ops);\n-void debug_ops_vector (vec<operand_entry_t> ops);\n+void dump_ops_vector (FILE *file, vec<operand_entry *> ops);\n+void debug_ops_vector (vec<operand_entry *> ops);\n \n /* Dump the operand entry vector OPS to FILE.  */\n \n void\n-dump_ops_vector (FILE *file, vec<operand_entry_t> ops)\n+dump_ops_vector (FILE *file, vec<operand_entry *> ops)\n {\n-  operand_entry_t oe;\n+  operand_entry *oe;\n   unsigned int i;\n \n   FOR_EACH_VEC_ELT (ops, i, oe)\n@@ -4939,7 +4936,7 @@ dump_ops_vector (FILE *file, vec<operand_entry_t> ops)\n /* Dump the operand entry vector OPS to STDERR.  */\n \n DEBUG_FUNCTION void\n-debug_ops_vector (vec<operand_entry_t> ops)\n+debug_ops_vector (vec<operand_entry *> ops)\n {\n   dump_ops_vector (stderr, ops);\n }"}, {"sha": "9430fac3f30b3822ecc04151798eb99099ff302f", "filename": "gcc/tree-ssa-strlen.c", "status": "modified", "additions": 50, "deletions": 50, "changes": 100, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-strlen.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-strlen.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-strlen.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -66,7 +66,7 @@ static vec<int> ssa_ver_to_stridx;\n static int max_stridx;\n \n /* String information record.  */\n-typedef struct strinfo_struct\n+struct strinfo\n {\n   /* String length of this string.  */\n   tree length;\n@@ -110,18 +110,18 @@ typedef struct strinfo_struct\n   /* A flag for the next maybe_invalidate that this strinfo shouldn't\n      be invalidated.  Always cleared by maybe_invalidate.  */\n   bool dont_invalidate;\n-} *strinfo;\n+};\n \n /* Pool for allocating strinfo_struct entries.  */\n-static object_allocator<strinfo_struct> strinfo_pool (\"strinfo_struct pool\");\n+static object_allocator<strinfo> strinfo_pool (\"strinfo pool\");\n \n /* Vector mapping positive string indexes to strinfo, for the\n    current basic block.  The first pointer in the vector is special,\n    it is either NULL, meaning the vector isn't shared, or it is\n    a basic block pointer to the owner basic_block if shared.\n    If some other bb wants to modify the vector, the vector needs\n    to be unshared first, and only the owner bb is supposed to free it.  */\n-static vec<strinfo, va_heap, vl_embed> *stridx_to_strinfo;\n+static vec<strinfo *, va_heap, vl_embed> *stridx_to_strinfo;\n \n /* One OFFSET->IDX mapping.  */\n struct stridxlist\n@@ -155,11 +155,11 @@ struct laststmt_struct\n   int stridx;\n } laststmt;\n \n-static int get_stridx_plus_constant (strinfo, HOST_WIDE_INT, tree);\n+static int get_stridx_plus_constant (strinfo *, HOST_WIDE_INT, tree);\n \n /* Return strinfo vector entry IDX.  */\n \n-static inline strinfo\n+static inline strinfo *\n get_strinfo (int idx)\n {\n   if (vec_safe_length (stridx_to_strinfo) <= (unsigned int) idx)\n@@ -230,7 +230,7 @@ get_stridx (tree exp)\n \t    return 0;\n \t  if (ssa_ver_to_stridx[SSA_NAME_VERSION (rhs1)])\n \t    {\n-\t      strinfo si\n+\t      strinfo *si\n \t\t= get_strinfo (ssa_ver_to_stridx[SSA_NAME_VERSION (rhs1)]);\n \t      if (si\n \t\t  && si->length\n@@ -279,7 +279,7 @@ strinfo_shared (void)\n static void\n unshare_strinfo_vec (void)\n {\n-  strinfo si;\n+  strinfo *si;\n   unsigned int i = 0;\n \n   gcc_assert (strinfo_shared ());\n@@ -383,10 +383,10 @@ new_addr_stridx (tree exp)\n \n /* Create a new strinfo.  */\n \n-static strinfo\n+static strinfo *\n new_strinfo (tree ptr, int idx, tree length)\n {\n-  strinfo si = strinfo_pool.allocate ();\n+  strinfo *si = strinfo_pool.allocate ();\n   si->length = length;\n   si->ptr = ptr;\n   si->stmt = NULL;\n@@ -404,7 +404,7 @@ new_strinfo (tree ptr, int idx, tree length)\n /* Decrease strinfo refcount and free it if not referenced anymore.  */\n \n static inline void\n-free_strinfo (strinfo si)\n+free_strinfo (strinfo *si)\n {\n   if (si && --si->refcount == 0)\n     strinfo_pool.remove (si);\n@@ -413,7 +413,7 @@ free_strinfo (strinfo si)\n /* Set strinfo in the vector entry IDX to SI.  */\n \n static inline void\n-set_strinfo (int idx, strinfo si)\n+set_strinfo (int idx, strinfo *si)\n {\n   if (vec_safe_length (stridx_to_strinfo) && (*stridx_to_strinfo)[0])\n     unshare_strinfo_vec ();\n@@ -425,7 +425,7 @@ set_strinfo (int idx, strinfo si)\n /* Return string length, or NULL if it can't be computed.  */\n \n static tree\n-get_string_length (strinfo si)\n+get_string_length (strinfo *si)\n {\n   if (si->length)\n     return si->length;\n@@ -542,7 +542,7 @@ get_string_length (strinfo si)\n static bool\n maybe_invalidate (gimple *stmt)\n {\n-  strinfo si;\n+  strinfo *si;\n   unsigned int i;\n   bool nonempty = false;\n \n@@ -571,10 +571,10 @@ maybe_invalidate (gimple *stmt)\n    if stridx_to_strinfo vector is shared with some other\n    bbs.  */\n \n-static strinfo\n-unshare_strinfo (strinfo si)\n+static strinfo *\n+unshare_strinfo (strinfo *si)\n {\n-  strinfo nsi;\n+  strinfo *nsi;\n \n   if (si->refcount == 1 && !strinfo_shared ())\n     return si;\n@@ -595,10 +595,10 @@ unshare_strinfo (strinfo si)\n    if all strinfos in between belong to the chain, otherwise\n    NULL.  */\n \n-static strinfo\n-verify_related_strinfos (strinfo origsi)\n+static strinfo *\n+verify_related_strinfos (strinfo *origsi)\n {\n-  strinfo si = origsi, psi;\n+  strinfo *si = origsi, *psi;\n \n   if (origsi->first == 0)\n     return NULL;\n@@ -622,7 +622,7 @@ verify_related_strinfos (strinfo origsi)\n    been created.  */\n \n static int\n-get_stridx_plus_constant (strinfo basesi, HOST_WIDE_INT off, tree ptr)\n+get_stridx_plus_constant (strinfo *basesi, HOST_WIDE_INT off, tree ptr)\n {\n   gcc_checking_assert (TREE_CODE (ptr) == SSA_NAME);\n \n@@ -636,7 +636,7 @@ get_stridx_plus_constant (strinfo basesi, HOST_WIDE_INT off, tree ptr)\n     return 0;\n \n   HOST_WIDE_INT len = tree_to_shwi (basesi->length) - off;\n-  strinfo si = basesi, chainsi;\n+  strinfo *si = basesi, *chainsi;\n   if (si->first || si->prev || si->next)\n     si = verify_related_strinfos (basesi);\n   if (si == NULL\n@@ -676,7 +676,7 @@ get_stridx_plus_constant (strinfo basesi, HOST_WIDE_INT off, tree ptr)\n   set_strinfo (idx, si);\n   if (chainsi->next)\n     {\n-      strinfo nextsi = unshare_strinfo (get_strinfo (chainsi->next));\n+      strinfo *nextsi = unshare_strinfo (get_strinfo (chainsi->next));\n       si->next = nextsi->idx;\n       nextsi->prev = idx;\n     }\n@@ -697,10 +697,10 @@ get_stridx_plus_constant (strinfo basesi, HOST_WIDE_INT off, tree ptr)\n    to a zero-length string and if possible chain it to a related strinfo\n    chain whose part is or might be CHAINSI.  */\n \n-static strinfo\n-zero_length_string (tree ptr, strinfo chainsi)\n+static strinfo *\n+zero_length_string (tree ptr, strinfo *chainsi)\n {\n-  strinfo si;\n+  strinfo *si;\n   int idx;\n   if (ssa_ver_to_stridx.length () <= SSA_NAME_VERSION (ptr))\n     ssa_ver_to_stridx.safe_grow_cleared (num_ssa_names);\n@@ -779,16 +779,16 @@ zero_length_string (tree ptr, strinfo chainsi)\n    but don't adjust ORIGSI).  */\n \n static void\n-adjust_related_strinfos (location_t loc, strinfo origsi, tree adj)\n+adjust_related_strinfos (location_t loc, strinfo *origsi, tree adj)\n {\n-  strinfo si = verify_related_strinfos (origsi);\n+  strinfo *si = verify_related_strinfos (origsi);\n \n   if (si == NULL)\n     return;\n \n   while (1)\n     {\n-      strinfo nsi;\n+      strinfo *nsi;\n \n       if (si != origsi)\n \t{\n@@ -878,11 +878,11 @@ find_equal_ptrs (tree ptr, int idx)\n    strinfo.  */\n \n static void\n-adjust_last_stmt (strinfo si, gimple *stmt, bool is_strcat)\n+adjust_last_stmt (strinfo *si, gimple *stmt, bool is_strcat)\n {\n   tree vuse, callee, len;\n   struct laststmt_struct last = laststmt;\n-  strinfo lastsi, firstsi;\n+  strinfo *lastsi, *firstsi;\n   unsigned len_arg_no = 2;\n \n   laststmt.stmt = NULL;\n@@ -913,7 +913,7 @@ adjust_last_stmt (strinfo si, gimple *stmt, bool is_strcat)\n \treturn;\n       while (firstsi != lastsi)\n \t{\n-\t  strinfo nextsi;\n+\t  strinfo *nextsi;\n \t  if (firstsi->next == 0)\n \t    return;\n \t  nextsi = get_strinfo (firstsi->next);\n@@ -1010,7 +1010,7 @@ handle_builtin_strlen (gimple_stmt_iterator *gsi)\n   idx = get_stridx (src);\n   if (idx)\n     {\n-      strinfo si = NULL;\n+      strinfo *si = NULL;\n       tree rhs;\n \n       if (idx < 0)\n@@ -1061,7 +1061,7 @@ handle_builtin_strlen (gimple_stmt_iterator *gsi)\n     return;\n   if (idx)\n     {\n-      strinfo si = new_strinfo (src, idx, lhs);\n+      strinfo *si = new_strinfo (src, idx, lhs);\n       set_strinfo (idx, si);\n       find_equal_ptrs (src, idx);\n     }\n@@ -1090,7 +1090,7 @@ handle_builtin_strchr (gimple_stmt_iterator *gsi)\n   idx = get_stridx (src);\n   if (idx)\n     {\n-      strinfo si = NULL;\n+      strinfo *si = NULL;\n       tree rhs;\n \n       if (idx < 0)\n@@ -1165,7 +1165,7 @@ handle_builtin_strchr (gimple_stmt_iterator *gsi)\n \t  tree srcu = fold_convert_loc (loc, size_type_node, src);\n \t  tree length = fold_build2_loc (loc, MINUS_EXPR,\n \t\t\t\t\t size_type_node, lhsu, srcu);\n-\t  strinfo si = new_strinfo (src, idx, length);\n+\t  strinfo *si = new_strinfo (src, idx, length);\n \t  si->endptr = lhs;\n \t  set_strinfo (idx, si);\n \t  find_equal_ptrs (src, idx);\n@@ -1188,7 +1188,7 @@ handle_builtin_strcpy (enum built_in_function bcode, gimple_stmt_iterator *gsi)\n   tree src, dst, srclen, len, lhs, args, type, fn, oldlen;\n   bool success;\n   gimple *stmt = gsi_stmt (*gsi);\n-  strinfo si, dsi, olddsi, zsi;\n+  strinfo *si, *dsi, *olddsi, *zsi;\n   location_t loc;\n   bool with_bounds = gimple_call_with_bounds_p (stmt);\n \n@@ -1274,7 +1274,7 @@ handle_builtin_strcpy (enum built_in_function bcode, gimple_stmt_iterator *gsi)\n \n   if (dsi->length == NULL_TREE)\n     {\n-      strinfo chainsi;\n+      strinfo *chainsi;\n \n       /* If string length of src is unknown, use delayed length\n \t computation.  If string lenth of dst will be needed, it\n@@ -1439,7 +1439,7 @@ handle_builtin_memcpy (enum built_in_function bcode, gimple_stmt_iterator *gsi)\n   int idx, didx;\n   tree src, dst, len, lhs, oldlen, newlen;\n   gimple *stmt = gsi_stmt (*gsi);\n-  strinfo si, dsi, olddsi;\n+  strinfo *si, *dsi, *olddsi;\n   bool with_bounds = gimple_call_with_bounds_p (stmt);\n \n   len = gimple_call_arg (stmt, with_bounds ? 4 : 2);\n@@ -1582,7 +1582,7 @@ handle_builtin_strcat (enum built_in_function bcode, gimple_stmt_iterator *gsi)\n   tree src, dst, srclen, dstlen, len, lhs, args, type, fn, objsz, endptr;\n   bool success;\n   gimple *stmt = gsi_stmt (*gsi);\n-  strinfo si, dsi;\n+  strinfo *si, *dsi;\n   location_t loc;\n   bool with_bounds = gimple_call_with_bounds_p (stmt);\n \n@@ -1792,7 +1792,7 @@ handle_builtin_malloc (enum built_in_function bcode, gimple_stmt_iterator *gsi)\n   tree length = NULL_TREE;\n   if (bcode == BUILT_IN_CALLOC)\n     length = build_int_cst (size_type_node, 0);\n-  strinfo si = new_strinfo (lhs, idx, length);\n+  strinfo *si = new_strinfo (lhs, idx, length);\n   if (bcode == BUILT_IN_CALLOC)\n     si->endptr = lhs;\n   set_strinfo (idx, si);\n@@ -1815,7 +1815,7 @@ handle_builtin_memset (gimple_stmt_iterator *gsi)\n   int idx1 = get_stridx (ptr);\n   if (idx1 <= 0)\n     return true;\n-  strinfo si1 = get_strinfo (idx1);\n+  strinfo *si1 = get_strinfo (idx1);\n   if (!si1)\n     return true;\n   gimple *stmt1 = si1->stmt;\n@@ -1866,7 +1866,7 @@ handle_pointer_plus (gimple_stmt_iterator *gsi)\n   gimple *stmt = gsi_stmt (*gsi);\n   tree lhs = gimple_assign_lhs (stmt), off;\n   int idx = get_stridx (gimple_assign_rhs1 (stmt));\n-  strinfo si, zsi;\n+  strinfo *si, *zsi;\n \n   if (idx == 0)\n     return;\n@@ -1916,7 +1916,7 @@ static bool\n handle_char_store (gimple_stmt_iterator *gsi)\n {\n   int idx = -1;\n-  strinfo si = NULL;\n+  strinfo *si = NULL;\n   gimple *stmt = gsi_stmt (*gsi);\n   tree ssaname = NULL_TREE, lhs = gimple_assign_lhs (stmt);\n \n@@ -2224,7 +2224,7 @@ strlen_dom_walker::before_dom_children (basic_block bb)\n     stridx_to_strinfo = NULL;\n   else\n     {\n-      stridx_to_strinfo = ((vec<strinfo, va_heap, vl_embed> *) dombb->aux);\n+      stridx_to_strinfo = ((vec<strinfo *, va_heap, vl_embed> *) dombb->aux);\n       if (stridx_to_strinfo)\n \t{\n \t  for (gphi_iterator gsi = gsi_start_phis (bb); !gsi_end_p (gsi);\n@@ -2246,7 +2246,7 @@ strlen_dom_walker::before_dom_children (basic_block bb)\n \t\t      if (!strinfo_shared ())\n \t\t\t{\n \t\t\t  unsigned int i;\n-\t\t\t  strinfo si;\n+\t\t\t  strinfo *si;\n \n \t\t\t  for (i = 1;\n \t\t\t       vec_safe_iterate (stridx_to_strinfo, i, &si);\n@@ -2294,7 +2294,7 @@ strlen_dom_walker::before_dom_children (basic_block bb)\n \n   bb->aux = stridx_to_strinfo;\n   if (vec_safe_length (stridx_to_strinfo) && !strinfo_shared ())\n-    (*stridx_to_strinfo)[0] = (strinfo) bb;\n+    (*stridx_to_strinfo)[0] = (strinfo *) bb;\n }\n \n /* Callback for walk_dominator_tree.  Free strinfo vector if it is\n@@ -2305,12 +2305,12 @@ strlen_dom_walker::after_dom_children (basic_block bb)\n {\n   if (bb->aux)\n     {\n-      stridx_to_strinfo = ((vec<strinfo, va_heap, vl_embed> *) bb->aux);\n+      stridx_to_strinfo = ((vec<strinfo *, va_heap, vl_embed> *) bb->aux);\n       if (vec_safe_length (stridx_to_strinfo)\n-\t  && (*stridx_to_strinfo)[0] == (strinfo) bb)\n+\t  && (*stridx_to_strinfo)[0] == (strinfo *) bb)\n \t{\n \t  unsigned int i;\n-\t  strinfo si;\n+\t  strinfo *si;\n \n \t  for (i = 1; vec_safe_iterate (stridx_to_strinfo, i, &si); ++i)\n \t    free_strinfo (si);"}, {"sha": "579bcb23a4a003bb3a3da1b8372201b473da215c", "filename": "gcc/tree-ssa-tail-merge.c", "status": "modified", "additions": 48, "deletions": 52, "changes": 100, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-tail-merge.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-ssa-tail-merge.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-tail-merge.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -222,7 +222,7 @@ along with GCC; see the file COPYING3.  If not see\n    Additionally, the hash value for the struct is cached in hashval, and\n    in_worklist indicates whether it's currently part of worklist.  */\n \n-struct same_succ_def : pointer_hash <same_succ_def>\n+struct same_succ : pointer_hash <same_succ>\n {\n   /* The bbs that have the same successor bbs.  */\n   bitmap bbs;\n@@ -239,24 +239,22 @@ struct same_succ_def : pointer_hash <same_succ_def>\n   hashval_t hashval;\n \n   /* hash_table support.  */\n-  static inline hashval_t hash (const same_succ_def *);\n-  static int equal (const same_succ_def *, const same_succ_def *);\n-  static void remove (same_succ_def *);\n+  static inline hashval_t hash (const same_succ *);\n+  static int equal (const same_succ *, const same_succ *);\n+  static void remove (same_succ *);\n };\n-typedef struct same_succ_def *same_succ;\n-typedef const struct same_succ_def *const_same_succ;\n \n /* hash routine for hash_table support, returns hashval of E.  */\n \n inline hashval_t\n-same_succ_def::hash (const same_succ_def *e)\n+same_succ::hash (const same_succ *e)\n {\n   return e->hashval;\n }\n \n /* A group of bbs where 1 bb from bbs can replace the other bbs.  */\n \n-struct bb_cluster_def\n+struct bb_cluster\n {\n   /* The bbs in the cluster.  */\n   bitmap bbs;\n@@ -267,8 +265,6 @@ struct bb_cluster_def\n   /* The bb to replace the cluster with.  */\n   basic_block rep_bb;\n };\n-typedef struct bb_cluster_def *bb_cluster;\n-typedef const struct bb_cluster_def *const_bb_cluster;\n \n /* Per bb-info.  */\n \n@@ -277,9 +273,9 @@ struct aux_bb_info\n   /* The number of non-debug statements in the bb.  */\n   int size;\n   /* The same_succ that this bb is a member of.  */\n-  same_succ bb_same_succ;\n+  same_succ *bb_same_succ;\n   /* The cluster that this bb is a member of.  */\n-  bb_cluster cluster;\n+  bb_cluster *cluster;\n   /* The vop state at the exit of a bb.  This is shortlived data, used to\n      communicate data between update_block_by and update_vuses.  */\n   tree vop_at_exit;\n@@ -383,7 +379,7 @@ gvn_uses_equal (tree val1, tree val2)\n /* Prints E to FILE.  */\n \n static void\n-same_succ_print (FILE *file, const same_succ e)\n+same_succ_print (FILE *file, const same_succ *e)\n {\n   unsigned int i;\n   bitmap_print (file, e->bbs, \"bbs:\", \"\\n\");\n@@ -398,9 +394,9 @@ same_succ_print (FILE *file, const same_succ e)\n /* Prints same_succ VE to VFILE.  */\n \n inline int\n-ssa_same_succ_print_traverse (same_succ *pe, FILE *file)\n+ssa_same_succ_print_traverse (same_succ **pe, FILE *file)\n {\n-  const same_succ e = *pe;\n+  const same_succ *e = *pe;\n   same_succ_print (file, e);\n   return 1;\n }\n@@ -445,7 +441,7 @@ stmt_update_dep_bb (gimple *stmt)\n /* Calculates hash value for same_succ VE.  */\n \n static hashval_t\n-same_succ_hash (const_same_succ e)\n+same_succ_hash (const same_succ *e)\n {\n   inchash::hash hstate (bitmap_hash (e->succs));\n   int flags;\n@@ -523,7 +519,7 @@ same_succ_hash (const_same_succ e)\n    the other edge flags.  */\n \n static bool\n-inverse_flags (const_same_succ e1, const_same_succ e2)\n+inverse_flags (const same_succ *e1, const same_succ *e2)\n {\n   int f1a, f1b, f2a, f2b;\n   int mask = ~(EDGE_TRUE_VALUE | EDGE_FALSE_VALUE);\n@@ -545,7 +541,7 @@ inverse_flags (const_same_succ e1, const_same_succ e2)\n /* Compares SAME_SUCCs E1 and E2.  */\n \n int\n-same_succ_def::equal (const same_succ_def *e1, const same_succ_def *e2)\n+same_succ::equal (const same_succ *e1, const same_succ *e2)\n {\n   unsigned int i, first1, first2;\n   gimple_stmt_iterator gsi1, gsi2;\n@@ -600,10 +596,10 @@ same_succ_def::equal (const same_succ_def *e1, const same_succ_def *e2)\n \n /* Alloc and init a new SAME_SUCC.  */\n \n-static same_succ\n+static same_succ *\n same_succ_alloc (void)\n {\n-  same_succ same = XNEW (struct same_succ_def);\n+  same_succ *same = XNEW (struct same_succ);\n \n   same->bbs = BITMAP_ALLOC (NULL);\n   same->succs = BITMAP_ALLOC (NULL);\n@@ -617,7 +613,7 @@ same_succ_alloc (void)\n /* Delete same_succ E.  */\n \n void\n-same_succ_def::remove (same_succ e)\n+same_succ::remove (same_succ *e)\n {\n   BITMAP_FREE (e->bbs);\n   BITMAP_FREE (e->succs);\n@@ -630,15 +626,15 @@ same_succ_def::remove (same_succ e)\n /* Reset same_succ SAME.  */\n \n static void\n-same_succ_reset (same_succ same)\n+same_succ_reset (same_succ *same)\n {\n   bitmap_clear (same->bbs);\n   bitmap_clear (same->succs);\n   bitmap_clear (same->inverse);\n   same->succ_flags.truncate (0);\n }\n \n-static hash_table<same_succ_def> *same_succ_htab;\n+static hash_table<same_succ> *same_succ_htab;\n \n /* Array that is used to store the edge flags for a successor.  */\n \n@@ -665,7 +661,7 @@ debug_same_succ ( void)\n \n /* Vector of bbs to process.  */\n \n-static vec<same_succ> worklist;\n+static vec<same_succ *> worklist;\n \n /* Prints worklist to FILE.  */\n \n@@ -680,7 +676,7 @@ print_worklist (FILE *file)\n /* Adds SAME to worklist.  */\n \n static void\n-add_to_worklist (same_succ same)\n+add_to_worklist (same_succ *same)\n {\n   if (same->in_worklist)\n     return;\n@@ -695,12 +691,12 @@ add_to_worklist (same_succ same)\n /* Add BB to same_succ_htab.  */\n \n static void\n-find_same_succ_bb (basic_block bb, same_succ *same_p)\n+find_same_succ_bb (basic_block bb, same_succ **same_p)\n {\n   unsigned int j;\n   bitmap_iterator bj;\n-  same_succ same = *same_p;\n-  same_succ *slot;\n+  same_succ *same = *same_p;\n+  same_succ **slot;\n   edge_iterator ei;\n   edge e;\n \n@@ -750,7 +746,7 @@ find_same_succ_bb (basic_block bb, same_succ *same_p)\n static void\n find_same_succ (void)\n {\n-  same_succ same = same_succ_alloc ();\n+  same_succ *same = same_succ_alloc ();\n   basic_block bb;\n \n   FOR_EACH_BB_FN (bb, cfun)\n@@ -760,7 +756,7 @@ find_same_succ (void)\n \tsame = same_succ_alloc ();\n     }\n \n-  same_succ_def::remove (same);\n+  same_succ::remove (same);\n }\n \n /* Initializes worklist administration.  */\n@@ -769,7 +765,7 @@ static void\n init_worklist (void)\n {\n   alloc_aux_for_blocks (sizeof (struct aux_bb_info));\n-  same_succ_htab = new hash_table<same_succ_def> (n_basic_blocks_for_fn (cfun));\n+  same_succ_htab = new hash_table<same_succ> (n_basic_blocks_for_fn (cfun));\n   same_succ_edge_flags = XCNEWVEC (int, last_basic_block_for_fn (cfun));\n   deleted_bbs = BITMAP_ALLOC (NULL);\n   deleted_bb_preds = BITMAP_ALLOC (NULL);\n@@ -817,7 +813,7 @@ mark_basic_block_deleted (basic_block bb)\n static void\n same_succ_flush_bb (basic_block bb)\n {\n-  same_succ same = BB_SAME_SUCC (bb);\n+  same_succ *same = BB_SAME_SUCC (bb);\n   BB_SAME_SUCC (bb) = NULL;\n   if (bitmap_single_bit_set_p (same->bbs))\n     same_succ_htab->remove_elt_with_hash (same, same->hashval);\n@@ -875,7 +871,7 @@ update_worklist (void)\n   unsigned int i;\n   bitmap_iterator bi;\n   basic_block bb;\n-  same_succ same;\n+  same_succ *same;\n \n   bitmap_and_compl_into (deleted_bb_preds, deleted_bbs);\n   bitmap_clear (deleted_bbs);\n@@ -892,14 +888,14 @@ update_worklist (void)\n       if (same == NULL)\n \tsame = same_succ_alloc ();\n     }\n-  same_succ_def::remove (same);\n+  same_succ::remove (same);\n   bitmap_clear (deleted_bb_preds);\n }\n \n /* Prints cluster C to FILE.  */\n \n static void\n-print_cluster (FILE *file, bb_cluster c)\n+print_cluster (FILE *file, bb_cluster *c)\n {\n   if (c == NULL)\n     return;\n@@ -909,17 +905,17 @@ print_cluster (FILE *file, bb_cluster c)\n \n /* Prints cluster C to stderr.  */\n \n-extern void debug_cluster (bb_cluster);\n+extern void debug_cluster (bb_cluster *);\n DEBUG_FUNCTION void\n-debug_cluster (bb_cluster c)\n+debug_cluster (bb_cluster *c)\n {\n   print_cluster (stderr, c);\n }\n \n /* Update C->rep_bb, given that BB is added to the cluster.  */\n \n static void\n-update_rep_bb (bb_cluster c, basic_block bb)\n+update_rep_bb (bb_cluster *c, basic_block bb)\n {\n   /* Initial.  */\n   if (c->rep_bb == NULL)\n@@ -953,7 +949,7 @@ update_rep_bb (bb_cluster c, basic_block bb)\n /* Add BB to cluster C.  Sets BB in C->bbs, and preds of BB in C->preds.  */\n \n static void\n-add_bb_to_cluster (bb_cluster c, basic_block bb)\n+add_bb_to_cluster (bb_cluster *c, basic_block bb)\n {\n   edge e;\n   edge_iterator ei;\n@@ -968,11 +964,11 @@ add_bb_to_cluster (bb_cluster c, basic_block bb)\n \n /* Allocate and init new cluster.  */\n \n-static bb_cluster\n+static bb_cluster *\n new_cluster (void)\n {\n-  bb_cluster c;\n-  c = XCNEW (struct bb_cluster_def);\n+  bb_cluster *c;\n+  c = XCNEW (bb_cluster);\n   c->bbs = BITMAP_ALLOC (NULL);\n   c->preds = BITMAP_ALLOC (NULL);\n   c->rep_bb = NULL;\n@@ -982,7 +978,7 @@ new_cluster (void)\n /* Delete clusters.  */\n \n static void\n-delete_cluster (bb_cluster c)\n+delete_cluster (bb_cluster *c)\n {\n   if (c == NULL)\n     return;\n@@ -994,7 +990,7 @@ delete_cluster (bb_cluster c)\n \n /* Array that contains all clusters.  */\n \n-static vec<bb_cluster> all_clusters;\n+static vec<bb_cluster *> all_clusters;\n \n /* Allocate all cluster vectors.  */\n \n@@ -1032,7 +1028,7 @@ delete_cluster_vectors (void)\n /* Merge cluster C2 into C1.  */\n \n static void\n-merge_clusters (bb_cluster c1, bb_cluster c2)\n+merge_clusters (bb_cluster *c1, bb_cluster *c2)\n {\n   bitmap_ior_into (c1->bbs, c2->bbs);\n   bitmap_ior_into (c1->preds, c2->preds);\n@@ -1045,7 +1041,7 @@ static void\n set_cluster (basic_block bb1, basic_block bb2)\n {\n   basic_block merge_bb, other_bb;\n-  bb_cluster merge, old, c;\n+  bb_cluster *merge, *old, *c;\n \n   if (BB_CLUSTER (bb1) == NULL && BB_CLUSTER (bb2) == NULL)\n     {\n@@ -1105,7 +1101,7 @@ gimple_operand_equal_value_p (tree t1, tree t2)\n    gimple_bb (s2) are members of SAME_SUCC.  */\n \n static bool\n-gimple_equal_p (same_succ same_succ, gimple *s1, gimple *s2)\n+gimple_equal_p (same_succ *same_succ, gimple *s1, gimple *s2)\n {\n   unsigned int i;\n   tree lhs1, lhs2;\n@@ -1225,7 +1221,7 @@ gsi_advance_bw_nondebug_nonlocal (gimple_stmt_iterator *gsi, tree *vuse,\n    clusters them.  */\n \n static void\n-find_duplicate (same_succ same_succ, basic_block bb1, basic_block bb2)\n+find_duplicate (same_succ *same_succ, basic_block bb1, basic_block bb2)\n {\n   gimple_stmt_iterator gsi1 = gsi_last_nondebug_bb (bb1);\n   gimple_stmt_iterator gsi2 = gsi_last_nondebug_bb (bb2);\n@@ -1307,7 +1303,7 @@ same_phi_alternatives_1 (basic_block dest, edge e1, edge e2)\n    phi alternatives for BB1 and BB2 are equal.  */\n \n static bool\n-same_phi_alternatives (same_succ same_succ, basic_block bb1, basic_block bb2)\n+same_phi_alternatives (same_succ *same_succ, basic_block bb1, basic_block bb2)\n {\n   unsigned int s;\n   bitmap_iterator bs;\n@@ -1392,7 +1388,7 @@ deps_ok_for_redirect (basic_block bb1, basic_block bb2)\n /* Within SAME_SUCC->bbs, find clusters of bbs which can be merged.  */\n \n static void\n-find_clusters_1 (same_succ same_succ)\n+find_clusters_1 (same_succ *same_succ)\n {\n   basic_block bb1, bb2;\n   unsigned int i, j;\n@@ -1444,7 +1440,7 @@ find_clusters_1 (same_succ same_succ)\n static void\n find_clusters (void)\n {\n-  same_succ same;\n+  same_succ *same;\n \n   while (!worklist.is_empty ())\n     {\n@@ -1556,7 +1552,7 @@ static int\n apply_clusters (void)\n {\n   basic_block bb1, bb2;\n-  bb_cluster c;\n+  bb_cluster *c;\n   unsigned int i, j;\n   bitmap_iterator bj;\n   int nr_bbs_removed = 0;"}, {"sha": "3bc3b03e6a72368bbaf3b58620a460d977e625ba", "filename": "gcc/tree-vrp.c", "status": "modified", "additions": 126, "deletions": 128, "changes": 254, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-vrp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Ftree-vrp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vrp.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -63,7 +63,7 @@ along with GCC; see the file COPYING3.  If not see\n \n /* Range of values that can be associated with an SSA_NAME after VRP\n    has executed.  */\n-struct value_range_d\n+struct value_range\n {\n   /* Lattice value represented by this range.  */\n   enum value_range_type type;\n@@ -87,8 +87,6 @@ struct value_range_d\n   bitmap equiv;\n };\n \n-typedef struct value_range_d value_range_t;\n-\n #define VR_INITIALIZER { VR_UNDEFINED, NULL_TREE, NULL_TREE, NULL }\n \n /* Set of SSA names found live during the RPO traversal of the function\n@@ -107,8 +105,8 @@ live_on_edge (edge e, tree name)\n /* Local functions.  */\n static int compare_values (tree val1, tree val2);\n static int compare_values_warnv (tree val1, tree val2, bool *);\n-static void vrp_meet (value_range_t *, value_range_t *);\n-static void vrp_intersect_ranges (value_range_t *, value_range_t *);\n+static void vrp_meet (value_range *, value_range *);\n+static void vrp_intersect_ranges (value_range *, value_range *);\n static tree vrp_evaluate_conditional_warnv_with_ops (enum tree_code,\n \t\t\t\t\t\t     tree, tree, bool, bool *,\n \t\t\t\t\t\t     bool *);\n@@ -155,7 +153,7 @@ static assert_locus **asserts_for;\n /* Value range array.  After propagation, VR_VALUE[I] holds the range\n    of values that SSA name N_I may take.  */\n static unsigned num_vr_values;\n-static value_range_t **vr_value;\n+static value_range **vr_value;\n static bool values_propagated;\n \n /* For a PHI node which sets SSA name N_I, VR_COUNTS[I] holds the\n@@ -348,7 +346,7 @@ avoid_overflow_infinity (tree val)\n /* Set value range VR to VR_UNDEFINED.  */\n \n static inline void\n-set_value_range_to_undefined (value_range_t *vr)\n+set_value_range_to_undefined (value_range *vr)\n {\n   vr->type = VR_UNDEFINED;\n   vr->min = vr->max = NULL_TREE;\n@@ -360,7 +358,7 @@ set_value_range_to_undefined (value_range_t *vr)\n /* Set value range VR to VR_VARYING.  */\n \n static inline void\n-set_value_range_to_varying (value_range_t *vr)\n+set_value_range_to_varying (value_range *vr)\n {\n   vr->type = VR_VARYING;\n   vr->min = vr->max = NULL_TREE;\n@@ -372,7 +370,7 @@ set_value_range_to_varying (value_range_t *vr)\n /* Set value range VR to {T, MIN, MAX, EQUIV}.  */\n \n static void\n-set_value_range (value_range_t *vr, enum value_range_type t, tree min,\n+set_value_range (value_range *vr, enum value_range_type t, tree min,\n \t\t tree max, bitmap equiv)\n {\n #if defined ENABLE_CHECKING\n@@ -434,7 +432,7 @@ set_value_range (value_range_t *vr, enum value_range_type t, tree min,\n    extract ranges from var + CST op limit.  */\n \n static void\n-set_and_canonicalize_value_range (value_range_t *vr, enum value_range_type t,\n+set_and_canonicalize_value_range (value_range *vr, enum value_range_type t,\n \t\t\t\t  tree min, tree max, bitmap equiv)\n {\n   /* Use the canonical setters for VR_UNDEFINED and VR_VARYING.  */\n@@ -547,7 +545,7 @@ set_and_canonicalize_value_range (value_range_t *vr, enum value_range_type t,\n /* Copy value range FROM into value range TO.  */\n \n static inline void\n-copy_value_range (value_range_t *to, value_range_t *from)\n+copy_value_range (value_range *to, value_range *from)\n {\n   set_value_range (to, from->type, from->min, from->max, from->equiv);\n }\n@@ -558,7 +556,7 @@ copy_value_range (value_range_t *to, value_range_t *from)\n    infinity when we shouldn't.  */\n \n static inline void\n-set_value_range_to_value (value_range_t *vr, tree val, bitmap equiv)\n+set_value_range_to_value (value_range *vr, tree val, bitmap equiv)\n {\n   gcc_assert (is_gimple_min_invariant (val));\n   if (TREE_OVERFLOW_P (val))\n@@ -573,7 +571,7 @@ set_value_range_to_value (value_range_t *vr, tree val, bitmap equiv)\n    overflow does not occur.  */\n \n static inline void\n-set_value_range_to_nonnegative (value_range_t *vr, tree type,\n+set_value_range_to_nonnegative (value_range *vr, tree type,\n \t\t\t\tbool overflow_infinity)\n {\n   tree zero;\n@@ -595,7 +593,7 @@ set_value_range_to_nonnegative (value_range_t *vr, tree type,\n /* Set value range VR to a non-NULL range of type TYPE.  */\n \n static inline void\n-set_value_range_to_nonnull (value_range_t *vr, tree type)\n+set_value_range_to_nonnull (value_range *vr, tree type)\n {\n   tree zero = build_int_cst (type, 0);\n   set_value_range (vr, VR_ANTI_RANGE, zero, zero, vr->equiv);\n@@ -605,7 +603,7 @@ set_value_range_to_nonnull (value_range_t *vr, tree type)\n /* Set value range VR to a NULL range of type TYPE.  */\n \n static inline void\n-set_value_range_to_null (value_range_t *vr, tree type)\n+set_value_range_to_null (value_range *vr, tree type)\n {\n   set_value_range_to_value (vr, build_int_cst (type, 0), vr->equiv);\n }\n@@ -614,7 +612,7 @@ set_value_range_to_null (value_range_t *vr, tree type)\n /* Set value range VR to a range of a truthvalue of type TYPE.  */\n \n static inline void\n-set_value_range_to_truthvalue (value_range_t *vr, tree type)\n+set_value_range_to_truthvalue (value_range *vr, tree type)\n {\n   if (TYPE_PRECISION (type) == 1)\n     set_value_range_to_varying (vr);\n@@ -629,7 +627,7 @@ set_value_range_to_truthvalue (value_range_t *vr, tree type)\n    abs (min) >= abs (max), set VR to [-min, min].  */\n \n static void\n-abs_extent_range (value_range_t *vr, tree min, tree max)\n+abs_extent_range (value_range *vr, tree min, tree max)\n {\n   int cmp;\n \n@@ -666,12 +664,12 @@ abs_extent_range (value_range_t *vr, tree min, tree max)\n    If we have no values ranges recorded (ie, VRP is not running), then\n    return NULL.  Otherwise create an empty range if none existed for VAR.  */\n \n-static value_range_t *\n+static value_range *\n get_value_range (const_tree var)\n {\n-  static const struct value_range_d vr_const_varying\n+  static const value_range vr_const_varying\n     = { VR_VARYING, NULL_TREE, NULL_TREE, NULL };\n-  value_range_t *vr;\n+  value_range *vr;\n   tree sym;\n   unsigned ver = SSA_NAME_VERSION (var);\n \n@@ -683,18 +681,18 @@ get_value_range (const_tree var)\n      We should get here at most from the substitute-and-fold stage which\n      will never try to change values.  */\n   if (ver >= num_vr_values)\n-    return CONST_CAST (value_range_t *, &vr_const_varying);\n+    return CONST_CAST (value_range *, &vr_const_varying);\n \n   vr = vr_value[ver];\n   if (vr)\n     return vr;\n \n   /* After propagation finished do not allocate new value-ranges.  */\n   if (values_propagated)\n-    return CONST_CAST (value_range_t *, &vr_const_varying);\n+    return CONST_CAST (value_range *, &vr_const_varying);\n \n   /* Create a default value range.  */\n-  vr_value[ver] = vr = XCNEW (value_range_t);\n+  vr_value[ver] = vr = XCNEW (value_range);\n \n   /* Defer allocating the equivalence set.  */\n   vr->equiv = NULL;\n@@ -758,9 +756,9 @@ vrp_bitmap_equal_p (const_bitmap b1, const_bitmap b2)\n    is the range object associated with another SSA name.  */\n \n static inline bool\n-update_value_range (const_tree var, value_range_t *new_vr)\n+update_value_range (const_tree var, value_range *new_vr)\n {\n-  value_range_t *old_vr;\n+  value_range *old_vr;\n   bool is_new;\n \n   /* If there is a value-range on the SSA name from earlier analysis\n@@ -771,7 +769,7 @@ update_value_range (const_tree var, value_range_t *new_vr)\n       value_range_type rtype = get_range_info (var, &min, &max);\n       if (rtype == VR_RANGE || rtype == VR_ANTI_RANGE)\n \t{\n-\t  value_range_d nr;\n+\t  value_range nr;\n \t  nr.type = rtype;\n \t  nr.min = wide_int_to_tree (TREE_TYPE (var), min);\n \t  nr.max = wide_int_to_tree (TREE_TYPE (var), max);\n@@ -820,7 +818,7 @@ static void\n add_equivalence (bitmap *equiv, const_tree var)\n {\n   unsigned ver = SSA_NAME_VERSION (var);\n-  value_range_t *vr = vr_value[ver];\n+  value_range *vr = vr_value[ver];\n \n   if (*equiv == NULL)\n     *equiv = BITMAP_ALLOC (NULL);\n@@ -833,7 +831,7 @@ add_equivalence (bitmap *equiv, const_tree var)\n /* Return true if VR is ~[0, 0].  */\n \n static inline bool\n-range_is_nonnull (value_range_t *vr)\n+range_is_nonnull (value_range *vr)\n {\n   return vr->type == VR_ANTI_RANGE\n \t && integer_zerop (vr->min)\n@@ -844,7 +842,7 @@ range_is_nonnull (value_range_t *vr)\n /* Return true if VR is [0, 0].  */\n \n static inline bool\n-range_is_null (value_range_t *vr)\n+range_is_null (value_range *vr)\n {\n   return vr->type == VR_RANGE\n \t && integer_zerop (vr->min)\n@@ -855,7 +853,7 @@ range_is_null (value_range_t *vr)\n    a singleton.  */\n \n static inline bool\n-range_int_cst_p (value_range_t *vr)\n+range_int_cst_p (value_range *vr)\n {\n   return (vr->type == VR_RANGE\n \t  && TREE_CODE (vr->max) == INTEGER_CST\n@@ -865,7 +863,7 @@ range_int_cst_p (value_range_t *vr)\n /* Return true if VR is a INTEGER_CST singleton.  */\n \n static inline bool\n-range_int_cst_singleton_p (value_range_t *vr)\n+range_int_cst_singleton_p (value_range *vr)\n {\n   return (range_int_cst_p (vr)\n \t  && !is_overflow_infinity (vr->min)\n@@ -876,7 +874,7 @@ range_int_cst_singleton_p (value_range_t *vr)\n /* Return true if value range VR involves at least one symbol.  */\n \n static inline bool\n-symbolic_range_p (value_range_t *vr)\n+symbolic_range_p (value_range *vr)\n {\n   return (!is_gimple_min_invariant (vr->min)\n           || !is_gimple_min_invariant (vr->max));\n@@ -952,7 +950,7 @@ build_symbolic_expr (tree type, tree sym, bool neg, tree inv)\n /* Return true if value range VR involves exactly one symbol SYM.  */\n \n static bool\n-symbolic_range_based_on_p (value_range_t *vr, const_tree sym)\n+symbolic_range_based_on_p (value_range *vr, const_tree sym)\n {\n   bool neg, min_has_symbol, max_has_symbol;\n   tree inv;\n@@ -977,7 +975,7 @@ symbolic_range_based_on_p (value_range_t *vr, const_tree sym)\n /* Return true if value range VR uses an overflow infinity.  */\n \n static inline bool\n-overflow_infinity_range_p (value_range_t *vr)\n+overflow_infinity_range_p (value_range *vr)\n {\n   return (vr->type == VR_RANGE\n \t  && (is_overflow_infinity (vr->min)\n@@ -991,7 +989,7 @@ overflow_infinity_range_p (value_range_t *vr)\n    uses an overflow infinity.  */\n \n static bool\n-usable_range_p (value_range_t *vr, bool *strict_overflow_p)\n+usable_range_p (value_range *vr, bool *strict_overflow_p)\n {\n   gcc_assert (vr->type == VR_RANGE);\n   if (is_overflow_infinity (vr->min))\n@@ -1173,7 +1171,7 @@ vrp_stmt_computes_nonzero (gimple *stmt, bool *strict_overflow_p)\n \t  && TREE_CODE (base) == MEM_REF\n \t  && TREE_CODE (TREE_OPERAND (base, 0)) == SSA_NAME)\n \t{\n-\t  value_range_t *vr = get_value_range (TREE_OPERAND (base, 0));\n+\t  value_range *vr = get_value_range (TREE_OPERAND (base, 0));\n \t  if (range_is_nonnull (vr))\n \t    return true;\n \t}\n@@ -1497,7 +1495,7 @@ value_inside_range (tree val, tree min, tree max)\n    */\n \n static inline bool\n-value_ranges_intersect_p (value_range_t *vr0, value_range_t *vr1)\n+value_ranges_intersect_p (value_range *vr0, value_range *vr1)\n {\n   /* The value ranges do not intersect if the maximum of the first range is\n      less than the minimum of the second range or vice versa.\n@@ -1523,7 +1521,7 @@ range_includes_zero_p (tree min, tree max)\n /* Return true if *VR is know to only contain nonnegative values.  */\n \n static inline bool\n-value_range_nonnegative_p (value_range_t *vr)\n+value_range_nonnegative_p (value_range *vr)\n {\n   /* Testing for VR_ANTI_RANGE is not useful here as any anti-range\n      which would return a useful value should be encoded as a \n@@ -1541,7 +1539,7 @@ value_range_nonnegative_p (value_range_t *vr)\n    otherwise return NULL_TREE.  */\n \n static tree\n-value_range_constant_singleton (value_range_t *vr)\n+value_range_constant_singleton (value_range *vr)\n {\n   if (vr->type == VR_RANGE\n       && operand_equal_p (vr->min, vr->max, 0)\n@@ -1572,7 +1570,7 @@ op_with_constant_singleton_value_range (tree op)\n static bool\n op_with_boolean_value_range_p (tree op)\n {\n-  value_range_t *vr;\n+  value_range *vr;\n \n   if (TYPE_PRECISION (TREE_TYPE (op)) == 1)\n     return true;\n@@ -1594,10 +1592,10 @@ op_with_boolean_value_range_p (tree op)\n    it in *VR_P.  */\n \n static void\n-extract_range_from_assert (value_range_t *vr_p, tree expr)\n+extract_range_from_assert (value_range *vr_p, tree expr)\n {\n   tree var, cond, limit, min, max, type;\n-  value_range_t *limit_vr;\n+  value_range *limit_vr;\n   enum tree_code cond_code;\n \n   var = ASSERT_EXPR_VAR (expr);\n@@ -1877,9 +1875,9 @@ extract_range_from_assert (value_range_t *vr_p, tree expr)\n     always false.  */\n \n static void\n-extract_range_from_ssa_name (value_range_t *vr, tree var)\n+extract_range_from_ssa_name (value_range *vr, tree var)\n {\n-  value_range_t *var_vr = get_value_range (var);\n+  value_range *var_vr = get_value_range (var);\n \n   if (var_vr->type != VR_VARYING)\n     copy_value_range (vr, var_vr);\n@@ -2049,7 +2047,7 @@ vrp_int_const_binop (enum tree_code code, tree val1, tree val2)\n \n static bool\n zero_nonzero_bits_from_vr (const tree expr_type,\n-\t\t\t   value_range_t *vr,\n+\t\t\t   value_range *vr,\n \t\t\t   wide_int *may_be_nonzero,\n \t\t\t   wide_int *must_be_nonzero)\n {\n@@ -2089,8 +2087,8 @@ zero_nonzero_bits_from_vr (const tree expr_type,\n    *VR1 will be VR_UNDEFINED.  */\n \n static bool\n-ranges_from_anti_range (value_range_t *ar,\n-\t\t\tvalue_range_t *vr0, value_range_t *vr1)\n+ranges_from_anti_range (value_range *ar,\n+\t\t\tvalue_range *vr0, value_range *vr1)\n {\n   tree type = TREE_TYPE (ar->min);\n \n@@ -2129,9 +2127,9 @@ ranges_from_anti_range (value_range_t *ar,\n    *VR0 CODE *VR1.  */\n \n static void\n-extract_range_from_multiplicative_op_1 (value_range_t *vr,\n+extract_range_from_multiplicative_op_1 (value_range *vr,\n \t\t\t\t\tenum tree_code code,\n-\t\t\t\t\tvalue_range_t *vr0, value_range_t *vr1)\n+\t\t\t\t\tvalue_range *vr0, value_range *vr1)\n {\n   enum value_range_type type;\n   tree val[4];\n@@ -2284,12 +2282,12 @@ extract_range_from_multiplicative_op_1 (value_range_t *vr,\n    type EXPR_TYPE.  The resulting range is stored in *VR.  */\n \n static void\n-extract_range_from_binary_expr_1 (value_range_t *vr,\n+extract_range_from_binary_expr_1 (value_range *vr,\n \t\t\t\t  enum tree_code code, tree expr_type,\n-\t\t\t\t  value_range_t *vr0_, value_range_t *vr1_)\n+\t\t\t\t  value_range *vr0_, value_range *vr1_)\n {\n-  value_range_t vr0 = *vr0_, vr1 = *vr1_;\n-  value_range_t vrtem0 = VR_INITIALIZER, vrtem1 = VR_INITIALIZER;\n+  value_range vr0 = *vr0_, vr1 = *vr1_;\n+  value_range vrtem0 = VR_INITIALIZER, vrtem1 = VR_INITIALIZER;\n   enum value_range_type type;\n   tree min = NULL_TREE, max = NULL_TREE;\n   int cmp;\n@@ -2348,7 +2346,7 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n       extract_range_from_binary_expr_1 (vr, code, expr_type, &vrtem0, vr1_);\n       if (vrtem1.type != VR_UNDEFINED)\n \t{\n-\t  value_range_t vrres = VR_INITIALIZER;\n+\t  value_range vrres = VR_INITIALIZER;\n \t  extract_range_from_binary_expr_1 (&vrres, code, expr_type,\n \t\t\t\t\t    &vrtem1, vr1_);\n \t  vrp_meet (vr, &vrres);\n@@ -2362,7 +2360,7 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n       extract_range_from_binary_expr_1 (vr, code, expr_type, vr0_, &vrtem0);\n       if (vrtem1.type != VR_UNDEFINED)\n \t{\n-\t  value_range_t vrres = VR_INITIALIZER;\n+\t  value_range vrres = VR_INITIALIZER;\n \t  extract_range_from_binary_expr_1 (&vrres, code, expr_type,\n \t\t\t\t\t    vr0_, &vrtem1);\n \t  vrp_meet (vr, &vrres);\n@@ -2908,7 +2906,7 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n \t\t   && range_int_cst_singleton_p (&vr1))\n \t    {\n \t      bool saved_flag_wrapv;\n-\t      value_range_t vr1p = VR_INITIALIZER;\n+\t      value_range vr1p = VR_INITIALIZER;\n \t      vr1p.type = VR_RANGE;\n \t      vr1p.min = (wide_int_to_tree\n \t\t\t  (expr_type,\n@@ -3284,12 +3282,12 @@ extract_range_from_binary_expr_1 (value_range_t *vr,\n    The resulting range is stored in *VR.  */\n \n static void\n-extract_range_from_binary_expr (value_range_t *vr,\n+extract_range_from_binary_expr (value_range *vr,\n \t\t\t\tenum tree_code code,\n \t\t\t\ttree expr_type, tree op0, tree op1)\n {\n-  value_range_t vr0 = VR_INITIALIZER;\n-  value_range_t vr1 = VR_INITIALIZER;\n+  value_range vr0 = VR_INITIALIZER;\n+  value_range vr1 = VR_INITIALIZER;\n \n   /* Get value ranges for each operand.  For constant operands, create\n      a new value range with the operand to simplify processing.  */\n@@ -3321,7 +3319,7 @@ extract_range_from_binary_expr (value_range_t *vr,\n       && symbolic_range_based_on_p (&vr0, op1))\n     {\n       const bool minus_p = (code == MINUS_EXPR);\n-      value_range_t n_vr1 = VR_INITIALIZER;\n+      value_range n_vr1 = VR_INITIALIZER;\n \n       /* Try with VR0 and [-INF, OP1].  */\n       if (is_gimple_min_invariant (minus_p ? vr0.max : vr0.min))\n@@ -3345,7 +3343,7 @@ extract_range_from_binary_expr (value_range_t *vr,\n       && symbolic_range_based_on_p (&vr1, op0))\n     {\n       const bool minus_p = (code == MINUS_EXPR);\n-      value_range_t n_vr0 = VR_INITIALIZER;\n+      value_range n_vr0 = VR_INITIALIZER;\n \n       /* Try with [-INF, OP0] and VR1.  */\n       if (is_gimple_min_invariant (minus_p ? vr1.max : vr1.min))\n@@ -3368,11 +3366,11 @@ extract_range_from_binary_expr (value_range_t *vr,\n    The resulting range is stored in *VR.  */\n \n static void\n-extract_range_from_unary_expr_1 (value_range_t *vr,\n+extract_range_from_unary_expr_1 (value_range *vr,\n \t\t\t\t enum tree_code code, tree type,\n-\t\t\t\t value_range_t *vr0_, tree op0_type)\n+\t\t\t\t value_range *vr0_, tree op0_type)\n {\n-  value_range_t vr0 = *vr0_, vrtem0 = VR_INITIALIZER, vrtem1 = VR_INITIALIZER;\n+  value_range vr0 = *vr0_, vrtem0 = VR_INITIALIZER, vrtem1 = VR_INITIALIZER;\n \n   /* VRP only operates on integral and pointer types.  */\n   if (!(INTEGRAL_TYPE_P (op0_type)\n@@ -3402,7 +3400,7 @@ extract_range_from_unary_expr_1 (value_range_t *vr,\n     {\n       /* -X is simply 0 - X, so re-use existing code that also handles\n          anti-ranges fine.  */\n-      value_range_t zero = VR_INITIALIZER;\n+      value_range zero = VR_INITIALIZER;\n       set_value_range_to_value (&zero, build_int_cst (type, 0), NULL);\n       extract_range_from_binary_expr_1 (vr, MINUS_EXPR, type, &zero, &vr0);\n       return;\n@@ -3411,7 +3409,7 @@ extract_range_from_unary_expr_1 (value_range_t *vr,\n     {\n       /* ~X is simply -1 - X, so re-use existing code that also handles\n          anti-ranges fine.  */\n-      value_range_t minusone = VR_INITIALIZER;\n+      value_range minusone = VR_INITIALIZER;\n       set_value_range_to_value (&minusone, build_int_cst (type, -1), NULL);\n       extract_range_from_binary_expr_1 (vr, MINUS_EXPR,\n \t\t\t\t\ttype, &minusone, &vr0);\n@@ -3426,7 +3424,7 @@ extract_range_from_unary_expr_1 (value_range_t *vr,\n       extract_range_from_unary_expr_1 (vr, code, type, &vrtem0, op0_type);\n       if (vrtem1.type != VR_UNDEFINED)\n \t{\n-\t  value_range_t vrres = VR_INITIALIZER;\n+\t  value_range vrres = VR_INITIALIZER;\n \t  extract_range_from_unary_expr_1 (&vrres, code, type,\n \t\t\t\t\t   &vrtem1, op0_type);\n \t  vrp_meet (vr, &vrres);\n@@ -3669,10 +3667,10 @@ extract_range_from_unary_expr_1 (value_range_t *vr,\n    The resulting range is stored in *VR.  */\n \n static void\n-extract_range_from_unary_expr (value_range_t *vr, enum tree_code code,\n+extract_range_from_unary_expr (value_range *vr, enum tree_code code,\n \t\t\t       tree type, tree op0)\n {\n-  value_range_t vr0 = VR_INITIALIZER;\n+  value_range vr0 = VR_INITIALIZER;\n \n   /* Get value ranges for the operand.  For constant operands, create\n      a new value range with the operand to simplify processing.  */\n@@ -3691,11 +3689,11 @@ extract_range_from_unary_expr (value_range_t *vr, enum tree_code code,\n    the ranges of each of its operands and the expression code.  */\n \n static void\n-extract_range_from_cond_expr (value_range_t *vr, gassign *stmt)\n+extract_range_from_cond_expr (value_range *vr, gassign *stmt)\n {\n   tree op0, op1;\n-  value_range_t vr0 = VR_INITIALIZER;\n-  value_range_t vr1 = VR_INITIALIZER;\n+  value_range vr0 = VR_INITIALIZER;\n+  value_range vr1 = VR_INITIALIZER;\n \n   /* Get value ranges for each operand.  For constant operands, create\n      a new value range with the operand to simplify processing.  */\n@@ -3725,7 +3723,7 @@ extract_range_from_cond_expr (value_range_t *vr, gassign *stmt)\n    on the range of its operand and the expression code.  */\n \n static void\n-extract_range_from_comparison (value_range_t *vr, enum tree_code code,\n+extract_range_from_comparison (value_range *vr, enum tree_code code,\n \t\t\t       tree type, tree op0, tree op1)\n {\n   bool sop = false;\n@@ -3765,8 +3763,8 @@ static bool\n check_for_binary_op_overflow (enum tree_code subcode, tree type,\n \t\t\t      tree op0, tree op1, bool *ovf)\n {\n-  value_range_t vr0 = VR_INITIALIZER;\n-  value_range_t vr1 = VR_INITIALIZER;\n+  value_range vr0 = VR_INITIALIZER;\n+  value_range vr1 = VR_INITIALIZER;\n   if (TREE_CODE (op0) == SSA_NAME)\n     vr0 = *get_value_range (op0);\n   else if (TREE_CODE (op0) == INTEGER_CST)\n@@ -3867,7 +3865,7 @@ check_for_binary_op_overflow (enum tree_code subcode, tree type,\n    Store the result in *VR */\n \n static void\n-extract_range_basic (value_range_t *vr, gimple *stmt)\n+extract_range_basic (value_range *vr, gimple *stmt)\n {\n   bool sop = false;\n   tree type = gimple_expr_type (stmt);\n@@ -3903,7 +3901,7 @@ extract_range_basic (value_range_t *vr, gimple *stmt)\n \t  maxi = prec;\n \t  if (TREE_CODE (arg) == SSA_NAME)\n \t    {\n-\t      value_range_t *vr0 = get_value_range (arg);\n+\t      value_range *vr0 = get_value_range (arg);\n \t      /* If arg is non-zero, then ffs or popcount\n \t\t are non-zero.  */\n \t      if (((vr0->type == VR_RANGE\n@@ -3949,7 +3947,7 @@ extract_range_basic (value_range_t *vr, gimple *stmt)\n \t    mini = -2;\n \t  if (TREE_CODE (arg) == SSA_NAME)\n \t    {\n-\t      value_range_t *vr0 = get_value_range (arg);\n+\t      value_range *vr0 = get_value_range (arg);\n \t      /* From clz of VR_RANGE minimum we can compute\n \t\t result maximum.  */\n \t      if (vr0->type == VR_RANGE\n@@ -4010,7 +4008,7 @@ extract_range_basic (value_range_t *vr, gimple *stmt)\n \t    }\n \t  if (TREE_CODE (arg) == SSA_NAME)\n \t    {\n-\t      value_range_t *vr0 = get_value_range (arg);\n+\t      value_range *vr0 = get_value_range (arg);\n \t      /* If arg is non-zero, then use [0, prec - 1].  */\n \t      if (((vr0->type == VR_RANGE\n \t\t    && integer_nonzerop (vr0->min))\n@@ -4150,8 +4148,8 @@ extract_range_basic (value_range_t *vr, gimple *stmt)\n \t\t    }\n \t\t  else\n \t\t    {\n-\t\t      value_range_t vr0 = VR_INITIALIZER;\n-\t\t      value_range_t vr1 = VR_INITIALIZER;\n+\t\t      value_range vr0 = VR_INITIALIZER;\n+\t\t      value_range vr1 = VR_INITIALIZER;\n \t\t      bool saved_flag_wrapv = flag_wrapv;\n \t\t      /* Pretend the arithmetics is wrapping.  If there is\n \t\t\t any overflow, IMAGPART_EXPR will be set.  */\n@@ -4185,7 +4183,7 @@ extract_range_basic (value_range_t *vr, gimple *stmt)\n    in *VR.  */\n \n static void\n-extract_range_from_assignment (value_range_t *vr, gassign *stmt)\n+extract_range_from_assignment (value_range *vr, gassign *stmt)\n {\n   enum tree_code code = gimple_assign_rhs_code (stmt);\n \n@@ -4224,7 +4222,7 @@ extract_range_from_assignment (value_range_t *vr, gassign *stmt)\n    for VAR.  If so, update VR with the new limits.  */\n \n static void\n-adjust_range_with_scev (value_range_t *vr, struct loop *loop,\n+adjust_range_with_scev (value_range *vr, struct loop *loop,\n \t\t\tgimple *stmt, tree var)\n {\n   tree init, step, chrec, tmin, tmax, min, max, type, tem;\n@@ -4302,7 +4300,7 @@ adjust_range_with_scev (value_range_t *vr, struct loop *loop,\n \t the number of latch executions is the correct thing to use.  */\n       if (max_loop_iterations (loop, &nit))\n \t{\n-\t  value_range_t maxvr = VR_INITIALIZER;\n+\t  value_range maxvr = VR_INITIALIZER;\n \t  signop sgn = TYPE_SIGN (TREE_TYPE (step));\n \t  bool overflow;\n \n@@ -4407,7 +4405,7 @@ adjust_range_with_scev (value_range_t *vr, struct loop *loop,\n \n \n static tree\n-compare_ranges (enum tree_code comp, value_range_t *vr0, value_range_t *vr1,\n+compare_ranges (enum tree_code comp, value_range *vr0, value_range *vr1,\n \t\tbool *strict_overflow_p)\n {\n   /* VARYING or UNDEFINED ranges cannot be compared.  */\n@@ -4437,7 +4435,7 @@ compare_ranges (enum tree_code comp, value_range_t *vr0, value_range_t *vr1,\n       if (vr0->type == VR_RANGE)\n \t{\n \t  /* To simplify processing, make VR0 the anti-range.  */\n-\t  value_range_t *tmp = vr0;\n+\t  value_range *tmp = vr0;\n \t  vr0 = vr1;\n \t  vr1 = tmp;\n \t}\n@@ -4561,7 +4559,7 @@ compare_ranges (enum tree_code comp, value_range_t *vr0, value_range_t *vr1,\n    infinity was used in the test.  */\n \n static tree\n-compare_range_with_value (enum tree_code comp, value_range_t *vr, tree val,\n+compare_range_with_value (enum tree_code comp, value_range *vr, tree val,\n \t\t\t  bool *strict_overflow_p)\n {\n   if (vr->type == VR_VARYING || vr->type == VR_UNDEFINED)\n@@ -4683,8 +4681,8 @@ compare_range_with_value (enum tree_code comp, value_range_t *vr, tree val,\n \n /* Debugging dumps.  */\n \n-void dump_value_range (FILE *, value_range_t *);\n-void debug_value_range (value_range_t *);\n+void dump_value_range (FILE *, value_range *);\n+void debug_value_range (value_range *);\n void dump_all_value_ranges (FILE *);\n void debug_all_value_ranges (void);\n void dump_vr_equiv (FILE *, bitmap);\n@@ -4694,7 +4692,7 @@ void debug_vr_equiv (bitmap);\n /* Dump value range VR to FILE.  */\n \n void\n-dump_value_range (FILE *file, value_range_t *vr)\n+dump_value_range (FILE *file, value_range *vr)\n {\n   if (vr == NULL)\n     fprintf (file, \"[]\");\n@@ -4754,7 +4752,7 @@ dump_value_range (FILE *file, value_range_t *vr)\n /* Dump value range VR to stderr.  */\n \n DEBUG_FUNCTION void\n-debug_value_range (value_range_t *vr)\n+debug_value_range (value_range *vr)\n {\n   dump_value_range (stderr, vr);\n   fprintf (stderr, \"\\n\");\n@@ -6479,7 +6477,7 @@ insert_range_assertions (void)\n static void\n check_array_ref (location_t location, tree ref, bool ignore_off_by_one)\n {\n-  value_range_t* vr = NULL;\n+  value_range *vr = NULL;\n   tree low_sub, up_sub;\n   tree low_bound, up_bound, up_bound_p1;\n   tree base;\n@@ -6974,7 +6972,7 @@ vrp_initialize (void)\n \n   values_propagated = false;\n   num_vr_values = num_ssa_names;\n-  vr_value = XCNEWVEC (value_range_t *, num_vr_values);\n+  vr_value = XCNEWVEC (value_range *, num_vr_values);\n   vr_phi_edge_counts = XCNEWVEC (int, num_ssa_names);\n \n   FOR_EACH_BB_FN (bb, cfun)\n@@ -7024,7 +7022,7 @@ vrp_valueize (tree name)\n {\n   if (TREE_CODE (name) == SSA_NAME)\n     {\n-      value_range_t *vr = get_value_range (name);\n+      value_range *vr = get_value_range (name);\n       if (vr->type == VR_RANGE\n \t  && (vr->min == vr->max\n \t      || operand_equal_p (vr->min, vr->max, 0)))\n@@ -7048,7 +7046,7 @@ vrp_valueize_1 (tree name)\n       if (!gimple_nop_p (def_stmt)\n \t  && prop_simulate_again_p (def_stmt))\n \treturn NULL_TREE;\n-      value_range_t *vr = get_value_range (name);\n+      value_range *vr = get_value_range (name);\n       if (range_int_cst_singleton_p (vr))\n \treturn vr->min;\n     }\n@@ -7075,7 +7073,7 @@ vrp_visit_assignment_or_call (gimple *stmt, tree *output_p)\n \t   && TYPE_MAX_VALUE (TREE_TYPE (lhs)))\n \t  || POINTER_TYPE_P (TREE_TYPE (lhs))))\n     {\n-      value_range_t new_vr = VR_INITIALIZER;\n+      value_range new_vr = VR_INITIALIZER;\n \n       /* Try folding the statement to a constant first.  */\n       tree tem = gimple_fold_stmt_to_constant_1 (stmt, vrp_valueize,\n@@ -7153,9 +7151,9 @@ vrp_visit_assignment_or_call (gimple *stmt, tree *output_p)\n \t\t   SSA_PROP_NOT_INTERESTING.  If there are no\n \t\t   {REAL,IMAG}PART_EXPR uses at all,\n \t\t   return SSA_PROP_VARYING.  */\n-\t\tvalue_range_t new_vr = VR_INITIALIZER;\n+\t\tvalue_range new_vr = VR_INITIALIZER;\n \t\textract_range_basic (&new_vr, use_stmt);\n-\t\tvalue_range_t *old_vr = get_value_range (use_lhs);\n+\t\tvalue_range *old_vr = get_value_range (use_lhs);\n \t\tif (old_vr->type != new_vr.type\n \t\t    || !vrp_operand_equal_p (old_vr->min, new_vr.min)\n \t\t    || !vrp_operand_equal_p (old_vr->max, new_vr.max)\n@@ -7189,10 +7187,10 @@ vrp_visit_assignment_or_call (gimple *stmt, tree *output_p)\n    or a symbolic range containing the SSA_NAME only if the value range\n    is varying or undefined.  */\n \n-static inline value_range_t\n+static inline value_range\n get_vr_for_comparison (int i)\n {\n-  value_range_t vr = *get_value_range (ssa_name (i));\n+  value_range vr = *get_value_range (ssa_name (i));\n \n   /* If name N_i does not have a valid range, use N_i as its own\n      range.  This allows us to compare against names that may\n@@ -7222,7 +7220,7 @@ compare_name_with_value (enum tree_code comp, tree var, tree val,\n   tree retval, t;\n   int used_strict_overflow;\n   bool sop;\n-  value_range_t equiv_vr;\n+  value_range equiv_vr;\n \n   /* Get the set of equivalences for VAR.  */\n   e = get_value_range (var)->equiv;\n@@ -7345,14 +7343,14 @@ compare_names (enum tree_code comp, tree n1, tree n2,\n      of the loop just to check N1 and N2 ranges.  */\n   EXECUTE_IF_SET_IN_BITMAP (e1, 0, i1, bi1)\n     {\n-      value_range_t vr1 = get_vr_for_comparison (i1);\n+      value_range vr1 = get_vr_for_comparison (i1);\n \n       t = retval = NULL_TREE;\n       EXECUTE_IF_SET_IN_BITMAP (e2, 0, i2, bi2)\n \t{\n \t  bool sop = false;\n \n-\t  value_range_t vr2 = get_vr_for_comparison (i2);\n+\t  value_range vr2 = get_vr_for_comparison (i2);\n \n \t  t = compare_ranges (comp, &vr1, &vr2, &sop);\n \t  if (t)\n@@ -7402,7 +7400,7 @@ vrp_evaluate_conditional_warnv_with_ops_using_ranges (enum tree_code code,\n \t\t\t\t\t\t      tree op0, tree op1,\n \t\t\t\t\t\t      bool * strict_overflow_p)\n {\n-  value_range_t *vr0, *vr1;\n+  value_range *vr0, *vr1;\n \n   vr0 = (TREE_CODE (op0) == SSA_NAME) ? get_value_range (op0) : NULL;\n   vr1 = (TREE_CODE (op1) == SSA_NAME) ? get_value_range (op1) : NULL;\n@@ -7522,7 +7520,7 @@ vrp_evaluate_conditional (tree_code code, tree op0, tree op1, gimple *stmt)\n \t always fold regardless of the value of OP0.  If -Wtype-limits\n \t was specified, emit a warning.  */\n       tree type = TREE_TYPE (op0);\n-      value_range_t *vr0 = get_value_range (op0);\n+      value_range *vr0 = get_value_range (op0);\n \n       if (vr0->type == VR_RANGE\n \t  && INTEGRAL_TYPE_P (type)\n@@ -7777,7 +7775,7 @@ find_case_label_range (gswitch *stmt, tree min, tree max, size_t *min_idx,\n    Returns true if the default label is not needed.  */\n \n static bool\n-find_case_label_ranges (gswitch *stmt, value_range_t *vr, size_t *min_idx1,\n+find_case_label_ranges (gswitch *stmt, value_range *vr, size_t *min_idx1,\n \t\t\tsize_t *max_idx1, size_t *min_idx2,\n \t\t\tsize_t *max_idx2)\n {\n@@ -7858,7 +7856,7 @@ static enum ssa_prop_result\n vrp_visit_switch_stmt (gswitch *stmt, edge *taken_edge_p)\n {\n   tree op, val;\n-  value_range_t *vr;\n+  value_range *vr;\n   size_t i = 0, j = 0, k, l;\n   bool take_default;\n \n@@ -8531,9 +8529,9 @@ intersect_ranges (enum value_range_type *vr0type,\n    in *VR0.  This may not be the smallest possible such range.  */\n \n static void\n-vrp_intersect_ranges_1 (value_range_t *vr0, value_range_t *vr1)\n+vrp_intersect_ranges_1 (value_range *vr0, value_range *vr1)\n {\n-  value_range_t saved;\n+  value_range saved;\n \n   /* If either range is VR_VARYING the other one wins.  */\n   if (vr1->type == VR_VARYING)\n@@ -8583,7 +8581,7 @@ vrp_intersect_ranges_1 (value_range_t *vr0, value_range_t *vr1)\n }\n \n static void\n-vrp_intersect_ranges (value_range_t *vr0, value_range_t *vr1)\n+vrp_intersect_ranges (value_range *vr0, value_range *vr1)\n {\n   if (dump_file && (dump_flags & TDF_DETAILS))\n     {\n@@ -8607,9 +8605,9 @@ vrp_intersect_ranges (value_range_t *vr0, value_range_t *vr1)\n    may not be the smallest possible such range.  */\n \n static void\n-vrp_meet_1 (value_range_t *vr0, value_range_t *vr1)\n+vrp_meet_1 (value_range *vr0, value_range *vr1)\n {\n-  value_range_t saved;\n+  value_range saved;\n \n   if (vr0->type == VR_UNDEFINED)\n     {\n@@ -8680,7 +8678,7 @@ vrp_meet_1 (value_range_t *vr0, value_range_t *vr1)\n }\n \n static void\n-vrp_meet (value_range_t *vr0, value_range_t *vr1)\n+vrp_meet (value_range *vr0, value_range *vr1)\n {\n   if (dump_file && (dump_flags & TDF_DETAILS))\n     {\n@@ -8709,8 +8707,8 @@ vrp_visit_phi_node (gphi *phi)\n {\n   size_t i;\n   tree lhs = PHI_RESULT (phi);\n-  value_range_t *lhs_vr = get_value_range (lhs);\n-  value_range_t vr_result = VR_INITIALIZER;\n+  value_range *lhs_vr = get_value_range (lhs);\n+  value_range vr_result = VR_INITIALIZER;\n   bool first = true;\n   int edges, old_edges;\n   struct loop *l;\n@@ -8737,7 +8735,7 @@ vrp_visit_phi_node (gphi *phi)\n       if (e->flags & EDGE_EXECUTABLE)\n \t{\n \t  tree arg = PHI_ARG_DEF (phi, i);\n-\t  value_range_t vr_arg;\n+\t  value_range vr_arg;\n \n \t  ++edges;\n \n@@ -8993,7 +8991,7 @@ simplify_div_or_mod_using_ranges (gimple *stmt)\n   tree val = NULL;\n   tree op0 = gimple_assign_rhs1 (stmt);\n   tree op1 = gimple_assign_rhs2 (stmt);\n-  value_range_t *vr = get_value_range (op0);\n+  value_range *vr = get_value_range (op0);\n \n   if (rhs_code == TRUNC_MOD_EXPR\n       && TREE_CODE (op1) == INTEGER_CST\n@@ -9130,7 +9128,7 @@ static bool\n simplify_abs_using_ranges (gimple *stmt)\n {\n   tree op = gimple_assign_rhs1 (stmt);\n-  value_range_t *vr = get_value_range (op);\n+  value_range *vr = get_value_range (op);\n \n   if (vr)\n     {\n@@ -9187,8 +9185,8 @@ simplify_bit_ops_using_ranges (gimple_stmt_iterator *gsi, gimple *stmt)\n   tree op0 = gimple_assign_rhs1 (stmt);\n   tree op1 = gimple_assign_rhs2 (stmt);\n   tree op = NULL_TREE;\n-  value_range_t vr0 = VR_INITIALIZER;\n-  value_range_t vr1 = VR_INITIALIZER;\n+  value_range vr0 = VR_INITIALIZER;\n+  value_range vr1 = VR_INITIALIZER;\n   wide_int may_be_nonzero0, may_be_nonzero1;\n   wide_int must_be_nonzero0, must_be_nonzero1;\n   wide_int mask;\n@@ -9267,7 +9265,7 @@ simplify_bit_ops_using_ranges (gimple_stmt_iterator *gsi, gimple *stmt)\n \n static tree\n test_for_singularity (enum tree_code cond_code, tree op0,\n-\t\t      tree op1, value_range_t *vr,\n+\t\t      tree op1, value_range *vr,\n \t\t      bool *strict_overflow_p)\n {\n   tree min = NULL;\n@@ -9337,7 +9335,7 @@ test_for_singularity (enum tree_code cond_code, tree op0,\n    by PRECISION and UNSIGNED_P.  */\n \n static bool\n-range_fits_type_p (value_range_t *vr, unsigned dest_precision, signop dest_sgn)\n+range_fits_type_p (value_range *vr, unsigned dest_precision, signop dest_sgn)\n {\n   tree src_type;\n   unsigned src_precision;\n@@ -9402,7 +9400,7 @@ simplify_cond_using_ranges (gcond *stmt)\n       && INTEGRAL_TYPE_P (TREE_TYPE (op0))\n       && is_gimple_min_invariant (op1))\n     {\n-      value_range_t *vr = get_value_range (op0);\n+      value_range *vr = get_value_range (op0);\n \n       /* If we have range information for OP0, then we might be\n \t able to simplify this conditional. */\n@@ -9517,7 +9515,7 @@ simplify_cond_using_ranges (gcond *stmt)\n       if (TREE_CODE (innerop) == SSA_NAME\n \t  && !POINTER_TYPE_P (TREE_TYPE (innerop)))\n \t{\n-\t  value_range_t *vr = get_value_range (innerop);\n+\t  value_range *vr = get_value_range (innerop);\n \n \t  if (range_int_cst_p (vr)\n \t      && range_fits_type_p (vr,\n@@ -9568,7 +9566,7 @@ static bool\n simplify_switch_using_ranges (gswitch *stmt)\n {\n   tree op = gimple_switch_index (stmt);\n-  value_range_t *vr;\n+  value_range *vr;\n   bool take_default;\n   edge e;\n   edge_iterator ei;\n@@ -9667,7 +9665,7 @@ simplify_conversion_using_ranges (gimple *stmt)\n {\n   tree innerop, middleop, finaltype;\n   gimple *def_stmt;\n-  value_range_t *innervr;\n+  value_range *innervr;\n   signop inner_sgn, middle_sgn, final_sgn;\n   unsigned inner_prec, middle_prec, final_prec;\n   widest_int innermin, innermed, innermax, middlemin, middlemed, middlemax;\n@@ -9746,7 +9744,7 @@ simplify_float_conversion_using_ranges (gimple_stmt_iterator *gsi,\n \t\t\t\t\tgimple *stmt)\n {\n   tree rhs1 = gimple_assign_rhs1 (stmt);\n-  value_range_t *vr = get_value_range (rhs1);\n+  value_range *vr = get_value_range (rhs1);\n   machine_mode fltmode = TYPE_MODE (TREE_TYPE (gimple_assign_lhs (stmt)));\n   machine_mode mode;\n   tree tem;\n@@ -10078,7 +10076,7 @@ simplify_stmt_for_jump_threading (gimple *stmt, gimple *within_stmt,\n \n   if (gassign *assign_stmt = dyn_cast <gassign *> (stmt))\n     {\n-      value_range_t new_vr = VR_INITIALIZER;\n+      value_range new_vr = VR_INITIALIZER;\n       tree lhs = gimple_assign_lhs (assign_stmt);\n \n       if (TREE_CODE (lhs) == SSA_NAME"}, {"sha": "8010ce11bcf0df7a71291e51ec8cd50515f4cd40", "filename": "gcc/var-tracking.c", "status": "modified", "additions": 210, "deletions": 209, "changes": 419, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fvar-tracking.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526ceb68361419fd9be6d629ac9838c4e88e8425/gcc%2Fvar-tracking.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvar-tracking.c?ref=526ceb68361419fd9be6d629ac9838c4e88e8425", "patch": "@@ -248,10 +248,10 @@ dv_as_opaque (decl_or_value dv)\n    register is described by a chain of these structures.\n    The chains are pretty short (usually 1 or 2 elements) and thus\n    chain is the best data structure.  */\n-typedef struct attrs_def\n+struct attrs\n {\n   /* Pointer to next member of the list.  */\n-  struct attrs_def *next;\n+  attrs *next;\n \n   /* The rtx of register.  */\n   rtx loc;\n@@ -261,7 +261,7 @@ typedef struct attrs_def\n \n   /* Offset from start of DECL.  */\n   HOST_WIDE_INT offset;\n-} *attrs;\n+};\n \n /* Structure for chaining the locations.  */\n struct location_chain\n@@ -357,7 +357,7 @@ struct variable_part\n \n /* Enumeration type used to discriminate various types of one-part\n    variables.  */\n-typedef enum onepart_enum\n+enum onepart_enum\n {\n   /* Not a one-part variable.  */\n   NOT_ONEPART = 0,\n@@ -367,10 +367,10 @@ typedef enum onepart_enum\n   ONEPART_DEXPR = 2,\n   /* A VALUE.  */\n   ONEPART_VALUE = 3\n-} onepart_enum_t;\n+};\n \n /* Structure describing where the variable is located.  */\n-typedef struct variable_def\n+struct variable\n {\n   /* The declaration of the variable, or an RTL value being handled\n      like a declaration.  */\n@@ -391,11 +391,10 @@ typedef struct variable_def\n \n   /* The variable parts.  */\n   variable_part var_part[1];\n-} *variable;\n-typedef const struct variable_def *const_variable;\n+};\n \n /* Pointer to the BB's information specific to variable tracking pass.  */\n-#define VTI(BB) ((variable_tracking_info) (BB)->aux)\n+#define VTI(BB) ((variable_tracking_info *) (BB)->aux)\n \n /* Macro to access MEM_OFFSET as an HOST_WIDE_INT.  Evaluates MEM twice.  */\n #define INT_MEM_OFFSET(mem) (MEM_OFFSET_KNOWN_P (mem) ? MEM_OFFSET (mem) : 0)\n@@ -405,14 +404,14 @@ typedef const struct variable_def *const_variable;\n /* Access VAR's Ith part's offset, checking that it's not a one-part\n    variable.  */\n #define VAR_PART_OFFSET(var, i) __extension__\t\t\t\\\n-(*({  variable const __v = (var);\t\t\t\t\\\n+(*({  variable *const __v = (var);\t\t\t\t\\\n       gcc_checking_assert (!__v->onepart);\t\t\t\\\n       &__v->var_part[(i)].aux.offset; }))\n \n /* Access VAR's one-part auxiliary data, checking that it is a\n    one-part variable.  */\n #define VAR_LOC_1PAUX(var) __extension__\t\t\t\\\n-(*({  variable const __v = (var);\t\t\t\t\\\n+(*({  variable *const __v = (var);\t\t\t\t\\\n       gcc_checking_assert (__v->onepart);\t\t\t\\\n       &__v->var_part[0].aux.onepaux; }))\n \n@@ -471,27 +470,27 @@ static void variable_htab_free (void *);\n \n /* Variable hashtable helpers.  */\n \n-struct variable_hasher : pointer_hash <variable_def>\n+struct variable_hasher : pointer_hash <variable>\n {\n   typedef void *compare_type;\n-  static inline hashval_t hash (const variable_def *);\n-  static inline bool equal (const variable_def *, const void *);\n-  static inline void remove (variable_def *);\n+  static inline hashval_t hash (const variable *);\n+  static inline bool equal (const variable *, const void *);\n+  static inline void remove (variable *);\n };\n \n /* The hash function for variable_htab, computes the hash value\n    from the declaration of variable X.  */\n \n inline hashval_t\n-variable_hasher::hash (const variable_def *v)\n+variable_hasher::hash (const variable *v)\n {\n   return dv_htab_hash (v->dv);\n }\n \n /* Compare the declaration of variable X with declaration Y.  */\n \n inline bool\n-variable_hasher::equal (const variable_def *v, const void *y)\n+variable_hasher::equal (const variable *v, const void *y)\n {\n   decl_or_value dv = CONST_CAST2 (decl_or_value, const void *, y);\n \n@@ -501,7 +500,7 @@ variable_hasher::equal (const variable_def *v, const void *y)\n /* Free the element of VARIABLE_HTAB (its type is struct variable_def).  */\n \n inline void\n-variable_hasher::remove (variable_def *var)\n+variable_hasher::remove (variable *var)\n {\n   variable_htab_free (var);\n }\n@@ -541,7 +540,7 @@ struct dataflow_set\n   HOST_WIDE_INT stack_adjust;\n \n   /* Attributes for registers (lists of attrs).  */\n-  attrs regs[FIRST_PSEUDO_REGISTER];\n+  attrs *regs[FIRST_PSEUDO_REGISTER];\n \n   /* Variable locations.  */\n   shared_hash *vars;\n@@ -552,7 +551,7 @@ struct dataflow_set\n \n /* The structure (one for each basic block) containing the information\n    needed for variable tracking.  */\n-typedef struct variable_tracking_info_def\n+struct variable_tracking_info\n {\n   /* The vector of micro operations.  */\n   vec<micro_operation> mos;\n@@ -573,20 +572,20 @@ typedef struct variable_tracking_info_def\n   /* Has the block been flooded in VTA?  */\n   bool flooded;\n \n-} *variable_tracking_info;\n+};\n \n /* Alloc pool for struct attrs_def.  */\n-object_allocator<attrs_def> attrs_def_pool (\"attrs_def pool\");\n+object_allocator<attrs> attrs_pool (\"attrs pool\");\n \n /* Alloc pool for struct variable_def with MAX_VAR_PARTS entries.  */\n \n static pool_allocator var_pool\n-  (\"variable_def pool\", sizeof (variable_def) +\n-   (MAX_VAR_PARTS - 1) * sizeof (((variable)NULL)->var_part[0]));\n+  (\"variable_def pool\", sizeof (variable) +\n+   (MAX_VAR_PARTS - 1) * sizeof (((variable *)NULL)->var_part[0]));\n \n /* Alloc pool for struct variable_def with a single var_part entry.  */\n static pool_allocator valvar_pool\n-  (\"small variable_def pool\", sizeof (variable_def));\n+  (\"small variable_def pool\", sizeof (variable));\n \n /* Alloc pool for struct location_chain.  */\n static object_allocator<location_chain> location_chain_pool\n@@ -616,14 +615,14 @@ static shared_hash *empty_shared_hash;\n static bitmap scratch_regs = NULL;\n \n #ifdef HAVE_window_save\n-typedef struct GTY(()) parm_reg {\n+struct GTY(()) parm_reg {\n   rtx outgoing;\n   rtx incoming;\n-} parm_reg_t;\n+};\n \n \n /* Vector of windowed parameter registers, if any.  */\n-static vec<parm_reg_t, va_gc> *windowed_parm_regs = NULL;\n+static vec<parm_reg, va_gc> *windowed_parm_regs = NULL;\n #endif\n \n /* Variable used to tell whether cselib_process_insn called our hook.  */\n@@ -636,15 +635,15 @@ static void insn_stack_adjust_offset_pre_post (rtx_insn *, HOST_WIDE_INT *,\n \t\t\t\t\t       HOST_WIDE_INT *);\n static bool vt_stack_adjustments (void);\n \n-static void init_attrs_list_set (attrs *);\n-static void attrs_list_clear (attrs *);\n-static attrs attrs_list_member (attrs, decl_or_value, HOST_WIDE_INT);\n-static void attrs_list_insert (attrs *, decl_or_value, HOST_WIDE_INT, rtx);\n-static void attrs_list_copy (attrs *, attrs);\n-static void attrs_list_union (attrs *, attrs);\n+static void init_attrs_list_set (attrs **);\n+static void attrs_list_clear (attrs **);\n+static attrs *attrs_list_member (attrs *, decl_or_value, HOST_WIDE_INT);\n+static void attrs_list_insert (attrs **, decl_or_value, HOST_WIDE_INT, rtx);\n+static void attrs_list_copy (attrs **, attrs *);\n+static void attrs_list_union (attrs **, attrs *);\n \n-static variable_def **unshare_variable (dataflow_set *set, variable_def **slot,\n-\t\t\t\t\tvariable var, enum var_init_status);\n+static variable **unshare_variable (dataflow_set *set, variable **slot,\n+\t\t\t\t\tvariable *var, enum var_init_status);\n static void vars_copy (variable_table_type *, variable_table_type *);\n static tree var_debug_decl (tree);\n static void var_reg_set (dataflow_set *, rtx, enum var_init_status, rtx);\n@@ -662,12 +661,13 @@ static void dataflow_set_clear (dataflow_set *);\n static void dataflow_set_copy (dataflow_set *, dataflow_set *);\n static int variable_union_info_cmp_pos (const void *, const void *);\n static void dataflow_set_union (dataflow_set *, dataflow_set *);\n-static location_chain *find_loc_in_1pdv (rtx, variable, variable_table_type *);\n+static location_chain *find_loc_in_1pdv (rtx, variable *,\n+\t\t\t\t\t variable_table_type *);\n static bool canon_value_cmp (rtx, rtx);\n static int loc_cmp (rtx, rtx);\n static bool variable_part_different_p (variable_part *, variable_part *);\n-static bool onepart_variable_different_p (variable, variable);\n-static bool variable_different_p (variable, variable);\n+static bool onepart_variable_different_p (variable *, variable *);\n+static bool variable_different_p (variable *, variable *);\n static bool dataflow_set_different (dataflow_set *, dataflow_set *);\n static void dataflow_set_destroy (dataflow_set *);\n \n@@ -679,26 +679,26 @@ static void add_stores (rtx, const_rtx, void *);\n static bool compute_bb_dataflow (basic_block);\n static bool vt_find_locations (void);\n \n-static void dump_attrs_list (attrs);\n-static void dump_var (variable);\n+static void dump_attrs_list (attrs *);\n+static void dump_var (variable *);\n static void dump_vars (variable_table_type *);\n static void dump_dataflow_set (dataflow_set *);\n static void dump_dataflow_sets (void);\n \n static void set_dv_changed (decl_or_value, bool);\n-static void variable_was_changed (variable, dataflow_set *);\n-static variable_def **set_slot_part (dataflow_set *, rtx, variable_def **,\n-\t\t\t\t     decl_or_value, HOST_WIDE_INT,\n-\t\t\t\t     enum var_init_status, rtx);\n+static void variable_was_changed (variable *, dataflow_set *);\n+static variable **set_slot_part (dataflow_set *, rtx, variable **,\n+\t\t\t\t decl_or_value, HOST_WIDE_INT,\n+\t\t\t\t enum var_init_status, rtx);\n static void set_variable_part (dataflow_set *, rtx,\n \t\t\t       decl_or_value, HOST_WIDE_INT,\n \t\t\t       enum var_init_status, rtx, enum insert_option);\n-static variable_def **clobber_slot_part (dataflow_set *, rtx,\n-\t\t\t\t\t variable_def **, HOST_WIDE_INT, rtx);\n+static variable **clobber_slot_part (dataflow_set *, rtx,\n+\t\t\t\t     variable **, HOST_WIDE_INT, rtx);\n static void clobber_variable_part (dataflow_set *, rtx,\n \t\t\t\t   decl_or_value, HOST_WIDE_INT, rtx);\n-static variable_def **delete_slot_part (dataflow_set *, rtx, variable_def **,\n-\t\t\t\t\tHOST_WIDE_INT);\n+static variable **delete_slot_part (dataflow_set *, rtx, variable **,\n+\t\t\t\t    HOST_WIDE_INT);\n static void delete_variable_part (dataflow_set *, rtx,\n \t\t\t\t  decl_or_value, HOST_WIDE_INT);\n static void emit_notes_in_bb (basic_block, dataflow_set *);\n@@ -1203,7 +1203,7 @@ adjust_insn (basic_block bb, rtx_insn *insn)\n     {\n       unsigned int i, nregs = vec_safe_length (windowed_parm_regs);\n       rtx rtl = gen_rtx_PARALLEL (VOIDmode, rtvec_alloc (nregs * 2));\n-      parm_reg_t *p;\n+      parm_reg *p;\n \n       FOR_EACH_VEC_SAFE_ELT (windowed_parm_regs, i, p)\n \t{\n@@ -1334,7 +1334,7 @@ dv_as_rtx (decl_or_value dv)\n /* Return nonzero if a decl_or_value must not have more than one\n    variable part.  The returned value discriminates among various\n    kinds of one-part DVs ccording to enum onepart_enum.  */\n-static inline onepart_enum_t\n+static inline onepart_enum\n dv_onepart_p (decl_or_value dv)\n {\n   tree decl;\n@@ -1358,16 +1358,16 @@ dv_onepart_p (decl_or_value dv)\n \n /* Return the variable pool to be used for a dv of type ONEPART.  */\n static inline pool_allocator &\n-onepart_pool (onepart_enum_t onepart)\n+onepart_pool (onepart_enum onepart)\n {\n   return onepart ? valvar_pool : var_pool;\n }\n \n /* Allocate a variable_def from the corresponding variable pool.  */\n-static inline variable_def *\n-onepart_pool_allocate (onepart_enum_t onepart)\n+static inline variable *\n+onepart_pool_allocate (onepart_enum onepart)\n {\n-  return (variable_def*) onepart_pool (onepart).allocate ();\n+  return (variable*) onepart_pool (onepart).allocate ();\n }\n \n /* Build a decl_or_value out of a decl.  */\n@@ -1425,15 +1425,15 @@ debug_dv (decl_or_value dv)\n     debug_generic_stmt (dv_as_decl (dv));\n }\n \n-static void loc_exp_dep_clear (variable var);\n+static void loc_exp_dep_clear (variable *var);\n \n /* Free the element of VARIABLE_HTAB (its type is struct variable_def).  */\n \n static void\n variable_htab_free (void *elem)\n {\n   int i;\n-  variable var = (variable) elem;\n+  variable *var = (variable *) elem;\n   location_chain *node, *next;\n \n   gcc_checking_assert (var->refcount > 0);\n@@ -1468,7 +1468,7 @@ variable_htab_free (void *elem)\n /* Initialize the set (array) SET of attrs to empty lists.  */\n \n static void\n-init_attrs_list_set (attrs *set)\n+init_attrs_list_set (attrs **set)\n {\n   int i;\n \n@@ -1479,9 +1479,9 @@ init_attrs_list_set (attrs *set)\n /* Make the list *LISTP empty.  */\n \n static void\n-attrs_list_clear (attrs *listp)\n+attrs_list_clear (attrs **listp)\n {\n-  attrs list, next;\n+  attrs *list, *next;\n \n   for (list = *listp; list; list = next)\n     {\n@@ -1493,8 +1493,8 @@ attrs_list_clear (attrs *listp)\n \n /* Return true if the pair of DECL and OFFSET is the member of the LIST.  */\n \n-static attrs\n-attrs_list_member (attrs list, decl_or_value dv, HOST_WIDE_INT offset)\n+static attrs *\n+attrs_list_member (attrs *list, decl_or_value dv, HOST_WIDE_INT offset)\n {\n   for (; list; list = list->next)\n     if (dv_as_opaque (list->dv) == dv_as_opaque (dv) && list->offset == offset)\n@@ -1505,10 +1505,10 @@ attrs_list_member (attrs list, decl_or_value dv, HOST_WIDE_INT offset)\n /* Insert the triplet DECL, OFFSET, LOC to the list *LISTP.  */\n \n static void\n-attrs_list_insert (attrs *listp, decl_or_value dv,\n+attrs_list_insert (attrs **listp, decl_or_value dv,\n \t\t   HOST_WIDE_INT offset, rtx loc)\n {\n-  attrs list = new attrs_def;\n+  attrs *list = new attrs;\n   list->loc = loc;\n   list->dv = dv;\n   list->offset = offset;\n@@ -1519,12 +1519,12 @@ attrs_list_insert (attrs *listp, decl_or_value dv,\n /* Copy all nodes from SRC and create a list *DSTP of the copies.  */\n \n static void\n-attrs_list_copy (attrs *dstp, attrs src)\n+attrs_list_copy (attrs **dstp, attrs *src)\n {\n   attrs_list_clear (dstp);\n   for (; src; src = src->next)\n     {\n-      attrs n = new attrs_def;\n+      attrs *n = new attrs;\n       n->loc = src->loc;\n       n->dv = src->dv;\n       n->offset = src->offset;\n@@ -1536,7 +1536,7 @@ attrs_list_copy (attrs *dstp, attrs src)\n /* Add all nodes from SRC which are not in *DSTP to *DSTP.  */\n \n static void\n-attrs_list_union (attrs *dstp, attrs src)\n+attrs_list_union (attrs **dstp, attrs *src)\n {\n   for (; src; src = src->next)\n     {\n@@ -1549,7 +1549,7 @@ attrs_list_union (attrs *dstp, attrs src)\n    *DSTP.  */\n \n static void\n-attrs_list_mpdv_union (attrs *dstp, attrs src, attrs src2)\n+attrs_list_mpdv_union (attrs **dstp, attrs *src, attrs *src2)\n {\n   gcc_assert (!*dstp);\n   for (; src; src = src->next)\n@@ -1586,7 +1586,7 @@ shared_hash_htab (shared_hash *vars)\n /* Return true if VAR is shared, or maybe because VARS is shared.  */\n \n static inline bool\n-shared_var_p (variable var, shared_hash *vars)\n+shared_var_p (variable *var, shared_hash *vars)\n {\n   /* Don't count an entry in the changed_variables table as a duplicate.  */\n   return ((var->refcount > 1 + (int) var->in_changed_variables)\n@@ -1633,7 +1633,7 @@ shared_hash_destroy (shared_hash *vars)\n /* Unshare *PVARS if shared and return slot for DV.  If INS is\n    INSERT, insert it if not already present.  */\n \n-static inline variable_def **\n+static inline variable **\n shared_hash_find_slot_unshare_1 (shared_hash **pvars, decl_or_value dv,\n \t\t\t\t hashval_t dvhash, enum insert_option ins)\n {\n@@ -1642,7 +1642,7 @@ shared_hash_find_slot_unshare_1 (shared_hash **pvars, decl_or_value dv,\n   return shared_hash_htab (*pvars)->find_slot_with_hash (dv, dvhash, ins);\n }\n \n-static inline variable_def **\n+static inline variable **\n shared_hash_find_slot_unshare (shared_hash **pvars, decl_or_value dv,\n \t\t\t       enum insert_option ins)\n {\n@@ -1653,30 +1653,30 @@ shared_hash_find_slot_unshare (shared_hash **pvars, decl_or_value dv,\n    If it is not present, insert it only VARS is not shared, otherwise\n    return NULL.  */\n \n-static inline variable_def **\n+static inline variable **\n shared_hash_find_slot_1 (shared_hash *vars, decl_or_value dv, hashval_t dvhash)\n {\n   return shared_hash_htab (vars)->find_slot_with_hash (dv, dvhash,\n \t\t\t\t\t\t       shared_hash_shared (vars)\n \t\t\t\t\t\t       ? NO_INSERT : INSERT);\n }\n \n-static inline variable_def **\n+static inline variable **\n shared_hash_find_slot (shared_hash *vars, decl_or_value dv)\n {\n   return shared_hash_find_slot_1 (vars, dv, dv_htab_hash (dv));\n }\n \n /* Return slot for DV only if it is already present in the hash table.  */\n \n-static inline variable_def **\n+static inline variable **\n shared_hash_find_slot_noinsert_1 (shared_hash *vars, decl_or_value dv,\n \t\t\t\t  hashval_t dvhash)\n {\n   return shared_hash_htab (vars)->find_slot_with_hash (dv, dvhash, NO_INSERT);\n }\n \n-static inline variable_def **\n+static inline variable **\n shared_hash_find_slot_noinsert (shared_hash *vars, decl_or_value dv)\n {\n   return shared_hash_find_slot_noinsert_1 (vars, dv, dv_htab_hash (dv));\n@@ -1685,13 +1685,13 @@ shared_hash_find_slot_noinsert (shared_hash *vars, decl_or_value dv)\n /* Return variable for DV or NULL if not already present in the hash\n    table.  */\n \n-static inline variable\n+static inline variable *\n shared_hash_find_1 (shared_hash *vars, decl_or_value dv, hashval_t dvhash)\n {\n   return shared_hash_htab (vars)->find_with_hash (dv, dvhash);\n }\n \n-static inline variable\n+static inline variable *\n shared_hash_find (shared_hash *vars, decl_or_value dv)\n {\n   return shared_hash_find_1 (vars, dv, dv_htab_hash (dv));\n@@ -1717,11 +1717,11 @@ static bool dst_can_be_shared;\n \n /* Return a copy of a variable VAR and insert it to dataflow set SET.  */\n \n-static variable_def **\n-unshare_variable (dataflow_set *set, variable_def **slot, variable var,\n+static variable **\n+unshare_variable (dataflow_set *set, variable **slot, variable *var,\n \t\t  enum var_init_status initialized)\n {\n-  variable new_var;\n+  variable *new_var;\n   int i;\n \n   new_var = onepart_pool_allocate (var->onepart);\n@@ -1784,7 +1784,7 @@ unshare_variable (dataflow_set *set, variable_def **slot, variable var,\n   *slot = new_var;\n   if (var->in_changed_variables)\n     {\n-      variable_def **cslot\n+      variable **cslot\n \t= changed_variables->find_slot_with_hash (var->dv,\n \t\t\t\t\t\t  dv_htab_hash (var->dv),\n \t\t\t\t\t\t  NO_INSERT);\n@@ -1803,11 +1803,11 @@ static void\n vars_copy (variable_table_type *dst, variable_table_type *src)\n {\n   variable_iterator_type hi;\n-  variable var;\n+  variable *var;\n \n   FOR_EACH_HASH_TABLE_ELEMENT (*src, var, variable, hi)\n     {\n-      variable_def **dstp;\n+      variable **dstp;\n       var->refcount++;\n       dstp = dst->find_slot_with_hash (var->dv, dv_htab_hash (var->dv),\n \t\t\t\t       INSERT);\n@@ -1838,7 +1838,7 @@ var_reg_decl_set (dataflow_set *set, rtx loc, enum var_init_status initialized,\n \t\t  decl_or_value dv, HOST_WIDE_INT offset, rtx set_src,\n \t\t  enum insert_option iopt)\n {\n-  attrs node;\n+  attrs *node;\n   bool decl_p = dv_is_decl_p (dv);\n \n   if (decl_p)\n@@ -1869,7 +1869,7 @@ var_reg_set (dataflow_set *set, rtx loc, enum var_init_status initialized,\n static enum var_init_status\n get_init_value (dataflow_set *set, rtx loc, decl_or_value dv)\n {\n-  variable var;\n+  variable *var;\n   int i;\n   enum var_init_status ret_val = VAR_INIT_STATUS_UNKNOWN;\n \n@@ -1907,8 +1907,8 @@ var_reg_delete_and_set (dataflow_set *set, rtx loc, bool modify,\n {\n   tree decl = REG_EXPR (loc);\n   HOST_WIDE_INT offset = REG_OFFSET (loc);\n-  attrs node, next;\n-  attrs *nextp;\n+  attrs *node, *next;\n+  attrs **nextp;\n \n   decl = var_debug_decl (decl);\n \n@@ -1944,8 +1944,8 @@ var_reg_delete_and_set (dataflow_set *set, rtx loc, bool modify,\n static void\n var_reg_delete (dataflow_set *set, rtx loc, bool clobber)\n {\n-  attrs *nextp = &set->regs[REGNO (loc)];\n-  attrs node, next;\n+  attrs **nextp = &set->regs[REGNO (loc)];\n+  attrs *node, *next;\n \n   if (clobber)\n     {\n@@ -1976,8 +1976,8 @@ var_reg_delete (dataflow_set *set, rtx loc, bool clobber)\n static void\n var_regno_delete (dataflow_set *set, int regno)\n {\n-  attrs *reg = &set->regs[regno];\n-  attrs node, next;\n+  attrs **reg = &set->regs[regno];\n+  attrs *node, *next;\n \n   for (node = *reg; node; node = next)\n     {\n@@ -2067,7 +2067,7 @@ get_addr_from_local_cache (dataflow_set *set, rtx const loc)\n {\n   rtx x;\n   decl_or_value dv;\n-  variable var;\n+  variable *var;\n   location_chain *l;\n \n   gcc_checking_assert (GET_CODE (loc) == VALUE);\n@@ -2237,11 +2237,11 @@ struct overlapping_mems\n    canonicalized itself.  */\n \n int\n-drop_overlapping_mem_locs (variable_def **slot, overlapping_mems *coms)\n+drop_overlapping_mem_locs (variable **slot, overlapping_mems *coms)\n {\n   dataflow_set *set = coms->set;\n   rtx mloc = coms->loc, addr = coms->addr;\n-  variable var = *slot;\n+  variable *var = *slot;\n \n   if (var->onepart == ONEPART_VALUE)\n     {\n@@ -2512,7 +2512,7 @@ local_get_addr_clear_given_value (rtx const &, rtx *slot, rtx x)\n static void\n val_reset (dataflow_set *set, decl_or_value dv)\n {\n-  variable var = shared_hash_find (set->vars, dv) ;\n+  variable *var = shared_hash_find (set->vars, dv) ;\n   location_chain *node;\n   rtx cval;\n \n@@ -2618,7 +2618,7 @@ val_resolve (dataflow_set *set, rtx val, rtx loc, rtx_insn *insn)\n \n   if (REG_P (loc))\n     {\n-      attrs node, found = NULL;\n+      attrs *node, *found = NULL;\n \n       for (node = set->regs[REGNO (loc)]; node; node = node->next)\n \tif (dv_is_value_p (node->dv)\n@@ -2734,10 +2734,10 @@ variable_union_info_cmp_pos (const void *n1, const void *n2)\n    we keep the newest locations in the beginning.  */\n \n static int\n-variable_union (variable src, dataflow_set *set)\n+variable_union (variable *src, dataflow_set *set)\n {\n-  variable dst;\n-  variable_def **dstp;\n+  variable *dst;\n+  variable **dstp;\n   int i, j, k;\n \n   dstp = shared_hash_find_slot (set->vars, src->dv);\n@@ -2886,7 +2886,7 @@ variable_union (variable src, dataflow_set *set)\n \t\t{\n \t\t  dstp = unshare_variable (set, dstp, dst,\n \t\t\t\t\t   VAR_INIT_STATUS_UNKNOWN);\n-\t\t  dst = (variable)*dstp;\n+\t\t  dst = (variable *)*dstp;\n \t\t}\n \t    }\n \n@@ -3118,7 +3118,7 @@ dataflow_set_union (dataflow_set *dst, dataflow_set *src)\n   else\n     {\n       variable_iterator_type hi;\n-      variable var;\n+      variable *var;\n \n       FOR_EACH_HASH_TABLE_ELEMENT (*shared_hash_htab (src->vars),\n \t\t\t\t   var, variable, hi)\n@@ -3184,7 +3184,7 @@ dv_changed_p (decl_or_value dv)\n    be in star-canonical form.  */\n \n static location_chain *\n-find_loc_in_1pdv (rtx loc, variable var, variable_table_type *vars)\n+find_loc_in_1pdv (rtx loc, variable *var, variable_table_type *vars)\n {\n   location_chain *node;\n   enum rtx_code loc_code;\n@@ -3203,7 +3203,7 @@ find_loc_in_1pdv (rtx loc, variable var, variable_table_type *vars)\n   for (node = var->var_part[0].loc_chain; node; node = node->next)\n     {\n       decl_or_value dv;\n-      variable rvar;\n+      variable *rvar;\n \n       if (GET_CODE (node->loc) != loc_code)\n \t{\n@@ -3298,7 +3298,7 @@ insert_into_intersection (location_chain **nodep, rtx loc,\n \n static void\n intersect_loc_chains (rtx val, location_chain **dest, struct dfset_merge *dsm,\n-\t\t      location_chain *s1node, variable s2var)\n+\t\t      location_chain *s1node, variable *s2var)\n {\n   dataflow_set *s1set = dsm->cur;\n   dataflow_set *s2set = dsm->src;\n@@ -3343,7 +3343,7 @@ intersect_loc_chains (rtx val, location_chain **dest, struct dfset_merge *dsm,\n \t  && !VALUE_RECURSED_INTO (s1node->loc))\n \t{\n \t  decl_or_value dv = dv_from_value (s1node->loc);\n-\t  variable svar = shared_hash_find (s1set->vars, dv);\n+\t  variable *svar = shared_hash_find (s1set->vars, dv);\n \t  if (svar)\n \t    {\n \t      if (svar->n_var_parts == 1)\n@@ -3575,10 +3575,10 @@ loc_cmp (rtx x, rtx y)\n /* Check the order of entries in one-part variables.   */\n \n int\n-canonicalize_loc_order_check (variable_def **slot,\n+canonicalize_loc_order_check (variable **slot,\n \t\t\t      dataflow_set *data ATTRIBUTE_UNUSED)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n   location_chain *node, *next;\n \n #ifdef ENABLE_RTL_CHECKING\n@@ -3611,9 +3611,9 @@ canonicalize_loc_order_check (variable_def **slot,\n    the connections bidirectional.  */\n \n int\n-canonicalize_values_mark (variable_def **slot, dataflow_set *set)\n+canonicalize_values_mark (variable **slot, dataflow_set *set)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n   decl_or_value dv = var->dv;\n   rtx val;\n   location_chain *node;\n@@ -3633,7 +3633,7 @@ canonicalize_values_mark (variable_def **slot, dataflow_set *set)\n \telse\n \t  {\n \t    decl_or_value odv = dv_from_value (node->loc);\n-\t    variable_def **oslot;\n+\t    variable **oslot;\n \t    oslot = shared_hash_find_slot_noinsert (set->vars, odv);\n \n \t    set_slot_part (set, val, oslot, odv, 0,\n@@ -3650,14 +3650,14 @@ canonicalize_values_mark (variable_def **slot, dataflow_set *set)\n    variables, canonicalizing equivalence sets into star shapes.  */\n \n int\n-canonicalize_values_star (variable_def **slot, dataflow_set *set)\n+canonicalize_values_star (variable **slot, dataflow_set *set)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n   decl_or_value dv = var->dv;\n   location_chain *node;\n   decl_or_value cdv;\n   rtx val, cval;\n-  variable_def **cslot;\n+  variable **cslot;\n   bool has_value;\n   bool has_marks;\n \n@@ -3774,7 +3774,7 @@ canonicalize_values_star (variable_def **slot, dataflow_set *set)\n \t  }\n \telse if (GET_CODE (node->loc) == REG)\n \t  {\n-\t    attrs list = set->regs[REGNO (node->loc)], *listp;\n+\t    attrs *list = set->regs[REGNO (node->loc)], **listp;\n \n \t    /* Change an existing attribute referring to dv so that it\n \t       refers to cdv, removing any duplicate this might\n@@ -3871,15 +3871,15 @@ canonicalize_values_star (variable_def **slot, dataflow_set *set)\n    get to a variable that references another member of the set.  */\n \n int\n-canonicalize_vars_star (variable_def **slot, dataflow_set *set)\n+canonicalize_vars_star (variable **slot, dataflow_set *set)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n   decl_or_value dv = var->dv;\n   location_chain *node;\n   rtx cval;\n   decl_or_value cdv;\n-  variable_def **cslot;\n-  variable cvar;\n+  variable **cslot;\n+  variable *cvar;\n   location_chain *cnode;\n \n   if (!var->onepart || var->onepart == ONEPART_VALUE)\n@@ -3929,13 +3929,13 @@ canonicalize_vars_star (variable_def **slot, dataflow_set *set)\n    intersection.  */\n \n static int\n-variable_merge_over_cur (variable s1var, struct dfset_merge *dsm)\n+variable_merge_over_cur (variable *s1var, struct dfset_merge *dsm)\n {\n   dataflow_set *dst = dsm->dst;\n-  variable_def **dstslot;\n-  variable s2var, dvar = NULL;\n+  variable **dstslot;\n+  variable *s2var, *dvar = NULL;\n   decl_or_value dv = s1var->dv;\n-  onepart_enum_t onepart = s1var->onepart;\n+  onepart_enum onepart = s1var->onepart;\n   rtx val;\n   hashval_t dvhash;\n   location_chain *node, **nodep;\n@@ -4033,7 +4033,7 @@ variable_merge_over_cur (variable s1var, struct dfset_merge *dsm)\n \n       if (GET_CODE (node->loc) == REG)\n \t{\n-\t  attrs list;\n+\t  attrs *list;\n \n \t  for (list = dst->regs[REGNO (node->loc)]; list; list = list->next)\n \t    if (GET_MODE (node->loc) == GET_MODE (list->loc)\n@@ -4129,7 +4129,7 @@ variable_merge_over_cur (variable s1var, struct dfset_merge *dsm)\n \t      if (GET_CODE (node->loc) == VALUE)\n \t\t{\n \t\t  decl_or_value dv = dv_from_value (node->loc);\n-\t\t  variable_def **slot = NULL;\n+\t\t  variable **slot = NULL;\n \n \t\t  if (shared_hash_shared (dst->vars))\n \t\t    slot = shared_hash_find_slot_noinsert (dst->vars, dv);\n@@ -4138,7 +4138,7 @@ variable_merge_over_cur (variable s1var, struct dfset_merge *dsm)\n \t\t\t\t\t\t\t  INSERT);\n \t\t  if (!*slot)\n \t\t    {\n-\t\t      variable var = onepart_pool_allocate (ONEPART_VALUE);\n+\t\t      variable *var = onepart_pool_allocate (ONEPART_VALUE);\n \t\t      var->dv = dv;\n \t\t      var->refcount = 1;\n \t\t      var->n_var_parts = 1;\n@@ -4189,14 +4189,14 @@ variable_merge_over_cur (variable s1var, struct dfset_merge *dsm)\n    variable_merge_over_cur().  */\n \n static int\n-variable_merge_over_src (variable s2var, struct dfset_merge *dsm)\n+variable_merge_over_src (variable *s2var, struct dfset_merge *dsm)\n {\n   dataflow_set *dst = dsm->dst;\n   decl_or_value dv = s2var->dv;\n \n   if (!s2var->onepart)\n     {\n-      variable_def **dstp = shared_hash_find_slot (dst->vars, dv);\n+      variable **dstp = shared_hash_find_slot (dst->vars, dv);\n       *dstp = s2var;\n       s2var->refcount++;\n       return 1;\n@@ -4218,7 +4218,7 @@ dataflow_set_merge (dataflow_set *dst, dataflow_set *src2)\n   int i;\n   size_t src1_elems, src2_elems;\n   variable_iterator_type hi;\n-  variable var;\n+  variable *var;\n \n   src1_elems = shared_hash_htab (src1->vars)->elements ();\n   src2_elems = shared_hash_htab (src2->vars)->elements ();\n@@ -4256,7 +4256,7 @@ static void\n dataflow_set_equiv_regs (dataflow_set *set)\n {\n   int i;\n-  attrs list, *listp;\n+  attrs *list, **listp;\n \n   for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n     {\n@@ -4311,7 +4311,7 @@ dataflow_set_equiv_regs (dataflow_set *set)\n \tif (list->offset == 0 && dv_onepart_p (list->dv))\n \t  {\n \t    rtx cval = canon[(int)GET_MODE (list->loc)];\n-\t    variable_def **slot;\n+\t    variable **slot;\n \n \t    if (!cval)\n \t      continue;\n@@ -4335,7 +4335,7 @@ dataflow_set_equiv_regs (dataflow_set *set)\n    be unshared and 1-part.  */\n \n static void\n-remove_duplicate_values (variable var)\n+remove_duplicate_values (variable *var)\n {\n   location_chain *node, **nodep;\n \n@@ -4383,10 +4383,10 @@ struct dfset_post_merge\n    variables that don't have value numbers for them.  */\n \n int\n-variable_post_merge_new_vals (variable_def **slot, dfset_post_merge *dfpm)\n+variable_post_merge_new_vals (variable **slot, dfset_post_merge *dfpm)\n {\n   dataflow_set *set = dfpm->set;\n-  variable var = *slot;\n+  variable *var = *slot;\n   location_chain *node;\n \n   if (!var->onepart || !var->n_var_parts)\n@@ -4405,7 +4405,7 @@ variable_post_merge_new_vals (variable_def **slot, dfset_post_merge *dfpm)\n \t    gcc_assert (!VALUE_RECURSED_INTO (node->loc));\n \t  else if (GET_CODE (node->loc) == REG)\n \t    {\n-\t      attrs att, *attp, *curp = NULL;\n+\t      attrs *att, **attp, **curp = NULL;\n \n \t      if (var->refcount != 1)\n \t\t{\n@@ -4519,13 +4519,13 @@ variable_post_merge_new_vals (variable_def **slot, dfset_post_merge *dfpm)\n    chosen expression.  */\n \n int\n-variable_post_merge_perm_vals (variable_def **pslot, dfset_post_merge *dfpm)\n+variable_post_merge_perm_vals (variable **pslot, dfset_post_merge *dfpm)\n {\n   dataflow_set *set = dfpm->set;\n-  variable pvar = *pslot, var;\n+  variable *pvar = *pslot, *var;\n   location_chain *pnode;\n   decl_or_value dv;\n-  attrs att;\n+  attrs *att;\n \n   gcc_assert (dv_is_value_p (pvar->dv)\n \t      && pvar->n_var_parts == 1);\n@@ -4606,7 +4606,7 @@ find_mem_expr_in_1pdv (tree expr, rtx val, variable_table_type *vars)\n {\n   location_chain *node;\n   decl_or_value dv;\n-  variable var;\n+  variable *var;\n   location_chain *where = NULL;\n \n   if (!val)\n@@ -4674,9 +4674,9 @@ mem_dies_at_call (rtx mem)\n    the variable itself, directly or within a VALUE.  */\n \n int\n-dataflow_set_preserve_mem_locs (variable_def **slot, dataflow_set *set)\n+dataflow_set_preserve_mem_locs (variable **slot, dataflow_set *set)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n \n   if (var->onepart == ONEPART_VDECL || var->onepart == ONEPART_DEXPR)\n     {\n@@ -4783,9 +4783,9 @@ dataflow_set_preserve_mem_locs (variable_def **slot, dataflow_set *set)\n    value.  */\n \n int\n-dataflow_set_remove_mem_locs (variable_def **slot, dataflow_set *set)\n+dataflow_set_remove_mem_locs (variable **slot, dataflow_set *set)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n \n   if (var->onepart == ONEPART_VALUE)\n     {\n@@ -4906,7 +4906,7 @@ variable_part_different_p (variable_part *vp1, variable_part *vp2)\n    They must be in canonical order.  */\n \n static bool\n-onepart_variable_different_p (variable var1, variable var2)\n+onepart_variable_different_p (variable *var1, variable *var2)\n {\n   location_chain *lc1, *lc2;\n \n@@ -4935,7 +4935,7 @@ onepart_variable_different_p (variable var1, variable var2)\n /* Return true if variables VAR1 and VAR2 are different.  */\n \n static bool\n-variable_different_p (variable var1, variable var2)\n+variable_different_p (variable *var1, variable *var2)\n {\n   int i;\n \n@@ -4974,7 +4974,7 @@ static bool\n dataflow_set_different (dataflow_set *old_set, dataflow_set *new_set)\n {\n   variable_iterator_type hi;\n-  variable var1;\n+  variable *var1;\n \n   if (old_set->vars == new_set->vars)\n     return false;\n@@ -4987,7 +4987,7 @@ dataflow_set_different (dataflow_set *old_set, dataflow_set *new_set)\n \t\t\t       var1, variable, hi)\n     {\n       variable_table_type *htab = shared_hash_htab (new_set->vars);\n-      variable var2 = htab->find_with_hash (var1->dv, dv_htab_hash (var1->dv));\n+      variable *var2 = htab->find_with_hash (var1->dv, dv_htab_hash (var1->dv));\n       if (!var2)\n \t{\n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n@@ -6589,7 +6589,7 @@ find_src_set_src (dataflow_set *set, rtx src)\n {\n   tree decl = NULL_TREE;   /* The variable being copied around.          */\n   rtx set_src = NULL_RTX;  /* The value for \"decl\" stored in \"src\".      */\n-  variable var;\n+  variable *var;\n   location_chain *nextp;\n   int i;\n   bool found;\n@@ -7146,7 +7146,7 @@ vt_find_locations (void)\n /* Print the content of the LIST to dump file.  */\n \n static void\n-dump_attrs_list (attrs list)\n+dump_attrs_list (attrs *list)\n {\n   for (; list; list = list->next)\n     {\n@@ -7162,9 +7162,9 @@ dump_attrs_list (attrs list)\n /* Print the information about variable *SLOT to dump file.  */\n \n int\n-dump_var_tracking_slot (variable_def **slot, void *data ATTRIBUTE_UNUSED)\n+dump_var_tracking_slot (variable **slot, void *data ATTRIBUTE_UNUSED)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n \n   dump_var (var);\n \n@@ -7175,7 +7175,7 @@ dump_var_tracking_slot (variable_def **slot, void *data ATTRIBUTE_UNUSED)\n /* Print the information about variable VAR to dump file.  */\n \n static void\n-dump_var (variable var)\n+dump_var (variable *var)\n {\n   int i;\n   location_chain *node;\n@@ -7270,12 +7270,12 @@ dump_dataflow_sets (void)\n /* Return the variable for DV in dropped_values, inserting one if\n    requested with INSERT.  */\n \n-static inline variable\n+static inline variable *\n variable_from_dropped (decl_or_value dv, enum insert_option insert)\n {\n-  variable_def **slot;\n-  variable empty_var;\n-  onepart_enum_t onepart;\n+  variable **slot;\n+  variable *empty_var;\n+  onepart_enum onepart;\n \n   slot = dropped_values->find_slot_with_hash (dv, dv_htab_hash (dv), insert);\n \n@@ -7310,9 +7310,9 @@ variable_from_dropped (decl_or_value dv, enum insert_option insert)\n /* Recover the one-part aux from dropped_values.  */\n \n static struct onepart_aux *\n-recover_dropped_1paux (variable var)\n+recover_dropped_1paux (variable *var)\n {\n-  variable dvar;\n+  variable *dvar;\n \n   gcc_checking_assert (var->onepart);\n \n@@ -7337,13 +7337,13 @@ recover_dropped_1paux (variable var)\n    if it has no locations delete it from SET's hash table.  */\n \n static void\n-variable_was_changed (variable var, dataflow_set *set)\n+variable_was_changed (variable *var, dataflow_set *set)\n {\n   hashval_t hash = dv_htab_hash (var->dv);\n \n   if (emit_notes)\n     {\n-      variable_def **slot;\n+      variable **slot;\n \n       /* Remember this decl or VALUE has been added to changed_variables.  */\n       set_dv_changed (var->dv, true);\n@@ -7352,7 +7352,7 @@ variable_was_changed (variable var, dataflow_set *set)\n \n       if (*slot)\n \t{\n-\t  variable old_var = *slot;\n+\t  variable *old_var = *slot;\n \t  gcc_assert (old_var->in_changed_variables);\n \t  old_var->in_changed_variables = false;\n \t  if (var != old_var && var->onepart)\n@@ -7369,9 +7369,9 @@ variable_was_changed (variable var, dataflow_set *set)\n \n       if (set && var->n_var_parts == 0)\n \t{\n-\t  onepart_enum_t onepart = var->onepart;\n-\t  variable empty_var = NULL;\n-\t  variable_def **dslot = NULL;\n+\t  onepart_enum onepart = var->onepart;\n+\t  variable *empty_var = NULL;\n+\t  variable **dslot = NULL;\n \n \t  if (onepart == ONEPART_VALUE || onepart == ONEPART_DEXPR)\n \t    {\n@@ -7433,7 +7433,7 @@ variable_was_changed (variable var, dataflow_set *set)\n       gcc_assert (set);\n       if (var->n_var_parts == 0)\n \t{\n-\t  variable_def **slot;\n+\t  variable **slot;\n \n \tdrop_var:\n \t  slot = shared_hash_find_slot_noinsert (set->vars, var->dv);\n@@ -7454,7 +7454,7 @@ variable_was_changed (variable var, dataflow_set *set)\n    have, if it should be inserted.  */\n \n static inline int\n-find_variable_location_part (variable var, HOST_WIDE_INT offset,\n+find_variable_location_part (variable *var, HOST_WIDE_INT offset,\n \t\t\t     int *insertion_point)\n {\n   int pos, low, high;\n@@ -7492,16 +7492,16 @@ find_variable_location_part (variable var, HOST_WIDE_INT offset,\n   return -1;\n }\n \n-static variable_def **\n-set_slot_part (dataflow_set *set, rtx loc, variable_def **slot,\n+static variable **\n+set_slot_part (dataflow_set *set, rtx loc, variable **slot,\n \t       decl_or_value dv, HOST_WIDE_INT offset,\n \t       enum var_init_status initialized, rtx set_src)\n {\n   int pos;\n   location_chain *node, *next;\n   location_chain **nextp;\n-  variable var;\n-  onepart_enum_t onepart;\n+  variable *var;\n+  onepart_enum onepart;\n \n   var = *slot;\n \n@@ -7752,7 +7752,7 @@ set_variable_part (dataflow_set *set, rtx loc,\n \t\t   enum var_init_status initialized, rtx set_src,\n \t\t   enum insert_option iopt)\n {\n-  variable_def **slot;\n+  variable **slot;\n \n   if (iopt == NO_INSERT)\n     slot = shared_hash_find_slot_noinsert (set->vars, dv);\n@@ -7770,11 +7770,11 @@ set_variable_part (dataflow_set *set, rtx loc,\n    The variable part is specified by variable's declaration or value\n    DV and offset OFFSET.  */\n \n-static variable_def **\n-clobber_slot_part (dataflow_set *set, rtx loc, variable_def **slot,\n+static variable **\n+clobber_slot_part (dataflow_set *set, rtx loc, variable **slot,\n \t\t   HOST_WIDE_INT offset, rtx set_src)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n   int pos = find_variable_location_part (var, offset, NULL);\n \n   if (pos >= 0)\n@@ -7794,8 +7794,8 @@ clobber_slot_part (dataflow_set *set, rtx loc, variable_def **slot,\n \t    {\n \t      if (REG_P (node->loc))\n \t\t{\n-\t\t  attrs anode, anext;\n-\t\t  attrs *anextp;\n+\t\t  attrs *anode, *anext;\n+\t\t  attrs **anextp;\n \n \t\t  /* Remove the variable part from the register's\n \t\t     list, but preserve any other variable parts\n@@ -7833,7 +7833,7 @@ static void\n clobber_variable_part (dataflow_set *set, rtx loc, decl_or_value dv,\n \t\t       HOST_WIDE_INT offset, rtx set_src)\n {\n-  variable_def **slot;\n+  variable **slot;\n \n   if (!dv_as_opaque (dv)\n       || (!dv_is_value_p (dv) && ! DECL_P (dv_as_decl (dv))))\n@@ -7850,11 +7850,11 @@ clobber_variable_part (dataflow_set *set, rtx loc, decl_or_value dv,\n    variable part is specified by its SET->vars slot SLOT and offset\n    OFFSET and the part's location by LOC.  */\n \n-static variable_def **\n-delete_slot_part (dataflow_set *set, rtx loc, variable_def **slot,\n+static variable **\n+delete_slot_part (dataflow_set *set, rtx loc, variable **slot,\n \t\t  HOST_WIDE_INT offset)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n   int pos = find_variable_location_part (var, offset, NULL);\n \n   if (pos >= 0)\n@@ -7941,7 +7941,7 @@ static void\n delete_variable_part (dataflow_set *set, rtx loc, decl_or_value dv,\n \t\t      HOST_WIDE_INT offset)\n {\n-  variable_def **slot = shared_hash_find_slot_noinsert (set->vars, dv);\n+  variable **slot = shared_hash_find_slot_noinsert (set->vars, dv);\n   if (!slot)\n     return;\n \n@@ -7977,7 +7977,7 @@ struct expand_loc_callback_data\n    room for COUNT dependencies.  */\n \n static void\n-loc_exp_dep_alloc (variable var, int count)\n+loc_exp_dep_alloc (variable *var, int count)\n {\n   size_t allocsize;\n \n@@ -8025,7 +8025,7 @@ loc_exp_dep_alloc (variable var, int count)\n    removing them from the back-links lists too.  */\n \n static void\n-loc_exp_dep_clear (variable var)\n+loc_exp_dep_clear (variable *var)\n {\n   while (VAR_LOC_DEP_VEC (var) && !VAR_LOC_DEP_VEC (var)->is_empty ())\n     {\n@@ -8043,10 +8043,10 @@ loc_exp_dep_clear (variable var)\n    back-links in VARS.  */\n \n static void\n-loc_exp_insert_dep (variable var, rtx x, variable_table_type *vars)\n+loc_exp_insert_dep (variable *var, rtx x, variable_table_type *vars)\n {\n   decl_or_value dv;\n-  variable xvar;\n+  variable *xvar;\n   loc_exp_dep *led;\n \n   dv = dv_from_rtx (x);\n@@ -8093,7 +8093,7 @@ loc_exp_insert_dep (variable var, rtx x, variable_table_type *vars)\n    true if we found any pending-recursion results.  */\n \n static bool\n-loc_exp_dep_set (variable var, rtx result, rtx *value, int count,\n+loc_exp_dep_set (variable *var, rtx result, rtx *value, int count,\n \t\t variable_table_type *vars)\n {\n   bool pending_recursion = false;\n@@ -8123,14 +8123,14 @@ loc_exp_dep_set (variable var, rtx result, rtx *value, int count,\n    attempt to compute a current location.  */\n \n static void\n-notify_dependents_of_resolved_value (variable ivar, variable_table_type *vars)\n+notify_dependents_of_resolved_value (variable *ivar, variable_table_type *vars)\n {\n   loc_exp_dep *led, *next;\n \n   for (led = VAR_LOC_DEP_LST (ivar); led; led = next)\n     {\n       decl_or_value dv = led->dv;\n-      variable var;\n+      variable *var;\n \n       next = led->next;\n \n@@ -8215,7 +8215,8 @@ update_depth (expand_depth saved_depth, expand_depth best_depth)\n    it is pending recursion resolution.  */\n \n static inline rtx\n-vt_expand_var_loc_chain (variable var, bitmap regs, void *data, bool *pendrecp)\n+vt_expand_var_loc_chain (variable *var, bitmap regs, void *data,\n+\t\t\t bool *pendrecp)\n {\n   struct expand_loc_callback_data *elcd\n     = (struct expand_loc_callback_data *) data;\n@@ -8359,7 +8360,7 @@ vt_expand_loc_callback (rtx x, bitmap regs,\n   struct expand_loc_callback_data *elcd\n     = (struct expand_loc_callback_data *) data;\n   decl_or_value dv;\n-  variable var;\n+  variable *var;\n   rtx result, subreg;\n   bool pending_recursion = false;\n   bool from_empty = false;\n@@ -8534,7 +8535,7 @@ vt_expand_loc (rtx loc, variable_table_type *vars)\n    in VARS, updating their CUR_LOCs in the process.  */\n \n static rtx\n-vt_expand_1pvar (variable var, variable_table_type *vars)\n+vt_expand_1pvar (variable *var, variable_table_type *vars)\n {\n   struct expand_loc_callback_data data;\n   rtx loc;\n@@ -8560,9 +8561,9 @@ vt_expand_1pvar (variable var, variable_table_type *vars)\n    before or after instruction INSN.  */\n \n int\n-emit_note_insn_var_location (variable_def **varp, emit_note_data *data)\n+emit_note_insn_var_location (variable **varp, emit_note_data *data)\n {\n-  variable var = *varp;\n+  variable *var = *varp;\n   rtx_insn *insn = data->insn;\n   enum emit_note_where where = data->where;\n   variable_table_type *vars = data->vars;\n@@ -8791,10 +8792,10 @@ emit_note_insn_var_location (variable_def **varp, emit_note_data *data)\n    values) entries that aren't user variables.  */\n \n int\n-var_track_values_to_stack (variable_def **slot,\n+var_track_values_to_stack (variable **slot,\n \t\t\t   vec<rtx, va_heap> *changed_values_stack)\n {\n-  variable var = *slot;\n+  variable *var = *slot;\n \n   if (var->onepart == ONEPART_VALUE)\n     changed_values_stack->safe_push (dv_as_value (var->dv));\n@@ -8810,8 +8811,8 @@ static void\n remove_value_from_changed_variables (rtx val)\n {\n   decl_or_value dv = dv_from_rtx (val);\n-  variable_def **slot;\n-  variable var;\n+  variable **slot;\n+  variable *var;\n \n   slot = changed_variables->find_slot_with_hash (dv, dv_htab_hash (dv),\n \t\t\t\t\t\tNO_INSERT);\n@@ -8829,8 +8830,8 @@ static void\n notify_dependents_of_changed_value (rtx val, variable_table_type *htab,\n \t\t\t\t    vec<rtx, va_heap> *changed_values_stack)\n {\n-  variable_def **slot;\n-  variable var;\n+  variable **slot;\n+  variable *var;\n   loc_exp_dep *led;\n   decl_or_value dv = dv_from_rtx (val);\n \n@@ -8846,7 +8847,7 @@ notify_dependents_of_changed_value (rtx val, variable_table_type *htab,\n   while ((led = VAR_LOC_DEP_LST (var)))\n     {\n       decl_or_value ldv = led->dv;\n-      variable ivar;\n+      variable *ivar;\n \n       /* Deactivate and remove the backlink, as it was \u201cused up\u201d.  It\n \t makes no sense to attempt to notify the same entity again:\n@@ -8968,17 +8969,17 @@ emit_notes_for_changes (rtx_insn *insn, enum emit_note_where where,\n    same variable in hash table DATA or is not there at all.  */\n \n int\n-emit_notes_for_differences_1 (variable_def **slot, variable_table_type *new_vars)\n+emit_notes_for_differences_1 (variable **slot, variable_table_type *new_vars)\n {\n-  variable old_var, new_var;\n+  variable *old_var, *new_var;\n \n   old_var = *slot;\n   new_var = new_vars->find_with_hash (old_var->dv, dv_htab_hash (old_var->dv));\n \n   if (!new_var)\n     {\n       /* Variable has disappeared.  */\n-      variable empty_var = NULL;\n+      variable *empty_var = NULL;\n \n       if (old_var->onepart == ONEPART_VALUE\n \t  || old_var->onepart == ONEPART_DEXPR)\n@@ -9040,9 +9041,9 @@ emit_notes_for_differences_1 (variable_def **slot, variable_table_type *new_vars\n    table DATA.  */\n \n int\n-emit_notes_for_differences_2 (variable_def **slot, variable_table_type *old_vars)\n+emit_notes_for_differences_2 (variable **slot, variable_table_type *old_vars)\n {\n-  variable old_var, new_var;\n+  variable *old_var, *new_var;\n \n   new_var = *slot;\n   old_var = old_vars->find_with_hash (new_var->dv, dv_htab_hash (new_var->dv));\n@@ -9596,7 +9597,7 @@ vt_add_function_parameter (tree parm)\n \t  && HARD_REGISTER_P (incoming)\n \t  && OUTGOING_REGNO (REGNO (incoming)) != REGNO (incoming))\n \t{\n-\t  parm_reg_t p;\n+\t  parm_reg p;\n \t  p.incoming = incoming;\n \t  incoming\n \t    = gen_rtx_REG_offset (incoming, GET_MODE (incoming),\n@@ -9613,7 +9614,7 @@ vt_add_function_parameter (tree parm)\n \t  for (i = 0; i < XVECLEN (incoming, 0); i++)\n \t    {\n \t      rtx reg = XEXP (XVECEXP (incoming, 0, i), 0);\n-\t      parm_reg_t p;\n+\t      parm_reg p;\n \t      p.incoming = reg;\n \t      reg = gen_rtx_REG_offset (reg, GET_MODE (reg),\n \t\t\t\t\tOUTGOING_REGNO (REGNO (reg)), 0);\n@@ -9633,7 +9634,7 @@ vt_add_function_parameter (tree parm)\n \t  rtx reg = XEXP (incoming, 0);\n \t  if (OUTGOING_REGNO (REGNO (reg)) != REGNO (reg))\n \t    {\n-\t      parm_reg_t p;\n+\t      parm_reg p;\n \t      p.incoming = reg;\n \t      reg = gen_raw_REG (GET_MODE (reg), OUTGOING_REGNO (REGNO (reg)));\n \t      p.outgoing = reg;\n@@ -9856,7 +9857,7 @@ vt_initialize (void)\n   basic_block bb;\n   HOST_WIDE_INT fp_cfa_offset = -1;\n \n-  alloc_aux_for_blocks (sizeof (struct variable_tracking_info_def));\n+  alloc_aux_for_blocks (sizeof (variable_tracking_info));\n \n   empty_shared_hash = new shared_hash;\n   empty_shared_hash->refcount = 1;\n@@ -10216,7 +10217,7 @@ vt_finalize (void)\n   empty_shared_hash->htab = NULL;\n   delete changed_variables;\n   changed_variables = NULL;\n-  attrs_def_pool.release ();\n+  attrs_pool.release ();\n   var_pool.release ();\n   location_chain_pool.release ();\n   shared_hash_pool.release ();"}]}