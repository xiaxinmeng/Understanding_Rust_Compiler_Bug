{"sha": "0c5e486680d952780ebcf85a358200800c95cf01", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGM1ZTQ4NjY4MGQ5NTI3ODBlYmNmODVhMzU4MjAwODAwYzk1Y2YwMQ==", "commit": {"author": {"name": "Nathan Sidwell", "email": "nathan@codesourcery.com", "date": "2004-10-20T07:25:35Z"}, "committer": {"name": "Nathan Sidwell", "email": "nathan@gcc.gnu.org", "date": "2004-10-20T07:25:35Z"}, "message": "parser.c (cp_token_position): New typedef.\n\n\t* parser.c (cp_token_position): New typedef. Define VEC thereof.\n\t(struct cp_lexer): Allow buffer and buffer_end to be NULL. Make\n\tnext_token and last_token cp_token_position. Make saved_tokens a\n\tVEC(cp_token_position).\n\t(eof_token): New static variable.\n\t(CP_SAVED_TOKENS_SIZE): Rename to ...\n\t(CP_SAVED_TOKEN_STACK): ... here.\n\t(cp_lexer_new_main): Adjust main lexer creation and buffer\n\tfilling.\n\t(cp_lexer_new_from_tokens): Do not copy the tokens, merely point\n\tto the parent buffer.  Do not append eof token.\n\t(cp_lexer_destroy): Only free buffer if non-NULL. Free token\n\tstack.\n\t(cp_lexer_next_token, cp_lexer_prev_token): Remove.\n\t(cp_lexer_token_position, cp_lexer_token_at): New.\n\t(cp_lexer_saving_tokens): Adjust. Make inline.\n\t(cp_lexer_advance_token, cp_lexer_token_difference): Remove.\n\t(cp_lexer_peek_token_emit_debug_info): Fold into ...\n\t(cp_lexer_peek_token): ... here.\n\t(cp_lexer_peek_nth_token): Don't peek past EOF.\n\t(cp_lexer_consume_token): Set next_token to eof_token, if reaching\n\tEOF.\n\t(cp_lexer_purge_token): Adjust eof setting.\n\t(cp_lexer_purge_tokens_after): Likewise.\n\t(cp_lexer_save_tokens): Push next_token directly.\n\t(cp_lexer_commit_tokens): Adjust.\n\t(cp_lexer_rollback_tokens): Pop next_token directly.\n\t(cp_parser_check_for_invalid_template_id): Adjust token purging.\n\t(cp_parser_translation_unit): Do not consume the EOF.\n\t(cp_parser_nested_name_specifier_opt): Adjust token purging.\n\t(cp_parser_template_id, cp_parser_template_name): Likewise.\n\nFrom-SVN: r89320", "tree": {"sha": "3c8fe146f63cf777be9126401ba3671b1636bb73", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3c8fe146f63cf777be9126401ba3671b1636bb73"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0c5e486680d952780ebcf85a358200800c95cf01", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0c5e486680d952780ebcf85a358200800c95cf01", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0c5e486680d952780ebcf85a358200800c95cf01", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0c5e486680d952780ebcf85a358200800c95cf01/comments", "author": null, "committer": null, "parents": [{"sha": "242b11bd65a37e25c39d20bde6fd9807ecd3b9ea", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/242b11bd65a37e25c39d20bde6fd9807ecd3b9ea", "html_url": "https://github.com/Rust-GCC/gccrs/commit/242b11bd65a37e25c39d20bde6fd9807ecd3b9ea"}], "stats": {"total": 343, "additions": 149, "deletions": 194}, "files": [{"sha": "ba79b8b7e6268749610d77c8e9dd0704fcfed12d", "filename": "gcc/cp/ChangeLog", "status": "modified", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0c5e486680d952780ebcf85a358200800c95cf01/gcc%2Fcp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0c5e486680d952780ebcf85a358200800c95cf01/gcc%2Fcp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2FChangeLog?ref=0c5e486680d952780ebcf85a358200800c95cf01", "patch": "@@ -1,3 +1,37 @@\n+2004-10-20  Nathan Sidwell  <nathan@codesourcery.com>\n+\n+\t* parser.c (cp_token_position): New typedef. Define VEC thereof.\n+\t(struct cp_lexer): Allow buffer and buffer_end to be NULL. Make\n+\tnext_token and last_token cp_token_position. Make saved_tokens a\n+\tVEC(cp_token_position).\n+\t(eof_token): New static variable.\n+\t(CP_SAVED_TOKENS_SIZE): Rename to ...\n+\t(CP_SAVED_TOKEN_STACK): ... here.\n+\t(cp_lexer_new_main): Adjust main lexer creation and buffer\n+\tfilling.\n+\t(cp_lexer_new_from_tokens): Do not copy the tokens, merely point\n+\tto the parent buffer.  Do not append eof token.\n+\t(cp_lexer_destroy): Only free buffer if non-NULL. Free token\n+\tstack.\n+\t(cp_lexer_next_token, cp_lexer_prev_token): Remove.\n+\t(cp_lexer_token_position, cp_lexer_token_at): New.\n+\t(cp_lexer_saving_tokens): Adjust. Make inline.\n+\t(cp_lexer_advance_token, cp_lexer_token_difference): Remove.\n+\t(cp_lexer_peek_token_emit_debug_info): Fold into ...\n+\t(cp_lexer_peek_token): ... here.\n+\t(cp_lexer_peek_nth_token): Don't peek past EOF.\n+\t(cp_lexer_consume_token): Set next_token to eof_token, if reaching\n+\tEOF.\n+\t(cp_lexer_purge_token): Adjust eof setting.\n+\t(cp_lexer_purge_tokens_after): Likewise.\n+\t(cp_lexer_save_tokens): Push next_token directly.\n+\t(cp_lexer_commit_tokens): Adjust.\n+\t(cp_lexer_rollback_tokens): Pop next_token directly.\n+\t(cp_parser_check_for_invalid_template_id): Adjust token purging.\n+\t(cp_parser_translation_unit): Do not consume the EOF.\n+\t(cp_parser_nested_name_specifier_opt): Adjust token purging.\n+\t(cp_parser_template_id, cp_parser_template_name): Likewise.\n+\n 2004-10-19  Mark Mitchell  <mark@codesourcery.com>\n \n \tPR c++/14035"}, {"sha": "df3cb6526de5ee7ba043a85c2deb1bb73b603273", "filename": "gcc/cp/parser.c", "status": "modified", "additions": 115, "deletions": 194, "changes": 309, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0c5e486680d952780ebcf85a358200800c95cf01/gcc%2Fcp%2Fparser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0c5e486680d952780ebcf85a358200800c95cf01/gcc%2Fcp%2Fparser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fparser.c?ref=0c5e486680d952780ebcf85a358200800c95cf01", "patch": "@@ -63,31 +63,39 @@ typedef struct cp_token GTY (())\n   location_t location;\n } cp_token;\n \n+/* We use a stack of token pointer for saving token sets.  */\n+typedef struct cp_token *cp_token_position;\n+DEF_VEC_MALLOC_P (cp_token_position);\n+\n+static cp_token eof_token = {CPP_EOF, 0, 0, 0, 0, NULL_TREE, {0, 0}};\n+\n /* The cp_lexer structure represents the C++ lexer.  It is responsible\n    for managing the token stream from the preprocessor and supplying\n    it to the parser.  Tokens are never added to the cp_lexer after\n    it is created. */\n \n typedef struct cp_lexer GTY (())\n {\n-  /* The memory allocated for the buffer.  Never NULL.  */\n+  /* The memory allocated for the buffer.  NULL if this lexer does not\n+     own the token buffer.  */\n   cp_token * GTY ((length (\"(%h.buffer_end - %h.buffer)\"))) buffer;\n-  /* A pointer just past the end of the memory allocated for the buffer.  */\n+  /* If non-null, a pointer just past the end of the memory allocated\n+     for the buffer.  */\n   cp_token * GTY ((skip)) buffer_end;\n+  \n   /* A pointer just past the last available token.  The tokens\n      in this lexer are [buffer, last_token). */\n-  cp_token * GTY ((skip)) last_token;\n+  cp_token_position GTY ((skip)) last_token;\n \n-  /* The next available token.  If NEXT_TOKEN is NULL, then there are\n+  /* The next available token.  If NEXT_TOKEN is &eof_token, then there are\n      no more available tokens.  */\n-  cp_token * GTY ((skip)) next_token;\n+  cp_token_position GTY ((skip)) next_token;\n \n   /* A stack indicating positions at which cp_lexer_save_tokens was\n      called.  The top entry is the most recent position at which we\n-     began saving tokens.  The entries are differences in token\n-     position between BUFFER and the first saved token.\n-     If the stack is non-empty, we are saving tokens.  */\n-  varray_type saved_tokens;\n+     began saving tokens.  If the stack is non-empty, we are saving\n+     tokens.  */\n+  VEC (cp_token_position) *GTY ((skip)) saved_tokens;\n \n   /* True if we should output debugging information.  */\n   bool debugging_p;\n@@ -121,12 +129,10 @@ static void cp_lexer_destroy\n   (cp_lexer *);\n static int cp_lexer_saving_tokens\n   (const cp_lexer *);\n-static cp_token *cp_lexer_next_token\n-  (cp_lexer *, cp_token *);\n-static cp_token *cp_lexer_prev_token\n-  (cp_lexer *, cp_token *);\n-static ptrdiff_t cp_lexer_token_difference\n-  (cp_lexer *, cp_token *, cp_token *);\n+static cp_token_position cp_lexer_token_position\n+  (cp_lexer *, bool);\n+static cp_token *cp_lexer_token_at\n+  (cp_lexer *, cp_token_position);\n static void cp_lexer_grow_buffer\n   (cp_lexer *);\n static void cp_lexer_get_preprocessor_token\n@@ -146,7 +152,7 @@ static cp_token *cp_lexer_consume_token\n static void cp_lexer_purge_token\n   (cp_lexer *);\n static void cp_lexer_purge_tokens_after\n-  (cp_lexer *, cp_token *);\n+  (cp_lexer *, cp_token_position);\n static void cp_lexer_handle_pragma\n   (cp_lexer *);\n static void cp_lexer_save_tokens\n@@ -164,8 +170,6 @@ static void cp_lexer_start_debugging\n   (cp_lexer *) ATTRIBUTE_UNUSED;\n static void cp_lexer_stop_debugging\n   (cp_lexer *) ATTRIBUTE_UNUSED;\n-static void cp_lexer_peek_token_emit_debug_info\n-  (cp_lexer *, cp_token *);\n #else\n /* If we define cp_lexer_debug_stream to NULL it will provoke warnings\n    about passing NULL to functions that require non-NULL arguments\n@@ -174,16 +178,14 @@ static void cp_lexer_peek_token_emit_debug_info\n #define cp_lexer_debug_stream stdout\n #define cp_lexer_print_token(str, tok) (void) 0\n #define cp_lexer_debugging_p(lexer) 0\n-#define cp_lexer_peek_token_emit_debug_info(lexer, tok) (void) 0\n #endif /* ENABLE_CHECKING */\n \n static cp_token_cache *cp_token_cache_new\n   (cp_token *, cp_token *);\n \n /* Manifest constants.  */\n-\n #define CP_LEXER_BUFFER_SIZE 10000\n-#define CP_SAVED_TOKENS_SIZE 5\n+#define CP_SAVED_TOKEN_STACK 5\n \n /* A token type for keywords, as opposed to ordinary identifiers.  */\n #define CPP_KEYWORD ((enum cpp_ttype) (N_TTYPES + 1))\n@@ -245,24 +247,24 @@ cp_lexer_new_main (void)\n   lexer->buffer_end = lexer->buffer + CP_LEXER_BUFFER_SIZE;\n  \n   /* There is one token in the buffer.  */\n-  lexer->last_token = lexer->buffer + 1;\n+  lexer->last_token = lexer->buffer;\n   lexer->next_token = lexer->buffer;\n   *lexer->next_token = first_token;\n \n-  /* Create the SAVED_TOKENS stack.  */\n-  VARRAY_INT_INIT (lexer->saved_tokens, CP_SAVED_TOKENS_SIZE, \"saved_tokens\");\n+  lexer->saved_tokens = VEC_alloc (cp_token_position, CP_SAVED_TOKEN_STACK);\n \n #ifdef ENABLE_CHECKING  \n   /* Initially we are not debugging.  */\n   lexer->debugging_p = false;\n #endif /* ENABLE_CHECKING */\n \n   /* Get the rest of the tokens from the preprocessor. */\n-  while (lexer->last_token[-1].type != CPP_EOF)\n+  while (lexer->last_token->type != CPP_EOF)\n     {\n+      lexer->last_token++;\n       if (lexer->last_token == lexer->buffer_end)\n \tcp_lexer_grow_buffer (lexer);\n-      cp_lexer_get_preprocessor_token (lexer, lexer->last_token++);\n+      cp_lexer_get_preprocessor_token (lexer, lexer->last_token);\n     }\n \n   /* Pragma processing (via cpp_handle_deferred_pragma) may result in\n@@ -283,26 +285,13 @@ cp_lexer_new_from_tokens (cp_token_cache *cache)\n   cp_token *first = cache->first;\n   cp_token *last = cache->last;\n   cp_lexer *lexer = GGC_CNEW (cp_lexer);\n-  cp_token *eof;\n-\n-  /* Allocate a new buffer.  The reason we do this is to make sure\n-     there's a CPP_EOF token at the end.  An alternative would be to\n-     modify cp_lexer_peek_token so that it checks for end-of-buffer\n-     and returns a CPP_EOF when appropriate. */\n-\n-  lexer->buffer = GGC_NEWVEC (cp_token, (last - first) + 1);\n-  memcpy (lexer->buffer, first, sizeof (cp_token) * (last - first));\n-  lexer->next_token = lexer->buffer;\n-  lexer->buffer_end = lexer->last_token = lexer->buffer + (last - first);\n \n-  eof = lexer->buffer + (last - first);\n-  eof->type = CPP_EOF;\n-  eof->location = UNKNOWN_LOCATION;\n-  eof->value = NULL_TREE;\n-  eof->keyword = RID_MAX;\n-\n-  /* Create the SAVED_TOKENS stack.  */\n-  VARRAY_INT_INIT (lexer->saved_tokens, CP_SAVED_TOKENS_SIZE, \"saved_tokens\");\n+  /* We do not own the buffer.  */\n+  lexer->buffer = lexer->buffer_end = NULL;\n+  lexer->next_token = first == last ? &eof_token : first;\n+  lexer->last_token = last;\n+  \n+  lexer->saved_tokens = VEC_alloc (cp_token_position, CP_SAVED_TOKEN_STACK);\n \n #ifdef ENABLE_CHECKING\n   /* Initially we are not debugging.  */\n@@ -318,7 +307,9 @@ cp_lexer_new_from_tokens (cp_token_cache *cache)\n static void\n cp_lexer_destroy (cp_lexer *lexer)\n {\n-  ggc_free (lexer->buffer);\n+  if (lexer->buffer)\n+    ggc_free (lexer->buffer);\n+  VEC_free (cp_token_position, lexer->saved_tokens);\n   ggc_free (lexer);\n }\n \n@@ -334,51 +325,26 @@ cp_lexer_debugging_p (cp_lexer *lexer)\n \n #endif /* ENABLE_CHECKING */\n \n-/* TOKEN points into the circular token buffer.  Return a pointer to\n-   the next token in the buffer.  */\n-\n-static inline cp_token *\n-cp_lexer_next_token (cp_lexer* lexer ATTRIBUTE_UNUSED, cp_token* token)\n+static inline cp_token_position\n+cp_lexer_token_position (cp_lexer *lexer, bool previous_p)\n {\n-  token++;\n-  return token;\n+  gcc_assert (!previous_p || lexer->next_token != &eof_token);\n+  \n+  return lexer->next_token - previous_p;\n }\n \n-/* TOKEN points into the circular token buffer.  Return a pointer to\n-   the previous token in the buffer.  */\n-\n static inline cp_token *\n-cp_lexer_prev_token (cp_lexer* lexer ATTRIBUTE_UNUSED, cp_token* token)\n+cp_lexer_token_at (cp_lexer *lexer ATTRIBUTE_UNUSED, cp_token_position pos)\n {\n-  return token - 1;\n+  return pos;\n }\n \n /* nonzero if we are presently saving tokens.  */\n \n-static int\n+static inline int\n cp_lexer_saving_tokens (const cp_lexer* lexer)\n {\n-  return VARRAY_ACTIVE_SIZE (lexer->saved_tokens) != 0;\n-}\n-\n-/* Return a pointer to the token that is N tokens beyond TOKEN in the\n-   buffer.  */\n-\n-static inline cp_token *\n-cp_lexer_advance_token (cp_lexer *lexer ATTRIBUTE_UNUSED,\n-\t\t\tcp_token *token, ptrdiff_t n)\n-{\n-  return token + n;\n-}\n-\n-/* Returns the number of times that START would have to be incremented\n-   to reach FINISH.  If START and FINISH are the same, returns zero.  */\n-\n-static inline ptrdiff_t\n-cp_lexer_token_difference (cp_lexer* lexer ATTRIBUTE_UNUSED,\n-\t\t\t   cp_token* start, cp_token* finish)\n-{\n-  return finish - start;\n+  return VEC_length (cp_token_position, lexer->saved_tokens) != 0;\n }\n \n /* If the buffer is full, make it bigger.  */\n@@ -491,25 +457,14 @@ static inline cp_token *\n cp_lexer_peek_token (cp_lexer *lexer)\n {\n   if (cp_lexer_debugging_p (lexer))\n-    cp_lexer_peek_token_emit_debug_info (lexer, lexer->next_token);\n+    {\n+      fputs (\"cp_lexer: peeking at token: \", cp_lexer_debug_stream);\n+      cp_lexer_print_token (cp_lexer_debug_stream, lexer->next_token);\n+      putc ('\\n', cp_lexer_debug_stream);\n+    }\n   return lexer->next_token;\n }\n \n-#ifdef ENABLE_CHECKING\n-/* Emit debug output for cp_lexer_peek_token.  Split out into a\n-   separate function so that cp_lexer_peek_token can be small and\n-   inlinable. */\n-\n-static void\n-cp_lexer_peek_token_emit_debug_info (cp_lexer *lexer ATTRIBUTE_UNUSED,\n-\t\t\t\t     cp_token *token ATTRIBUTE_UNUSED)\n-{\n-  fputs (\"cp_lexer: peeking at token: \", cp_lexer_debug_stream);\n-  cp_lexer_print_token (cp_lexer_debug_stream, token);\n-  putc ('\\n', cp_lexer_debug_stream);\n-}\n-#endif\n-\n /* Return true if the next token has the indicated TYPE.  */\n \n static inline bool\n@@ -551,7 +506,7 @@ cp_lexer_peek_nth_token (cp_lexer* lexer, size_t n)\n   cp_token *token;\n \n   /* N is 1-based, not zero-based.  */\n-  gcc_assert (n > 0);\n+  gcc_assert (n > 0 && lexer->next_token != &eof_token);\n \n   if (cp_lexer_debugging_p (lexer))\n     fprintf (cp_lexer_debug_stream,\n@@ -562,6 +517,12 @@ cp_lexer_peek_nth_token (cp_lexer* lexer, size_t n)\n   while (n != 0)\n     {\n       ++token;\n+      if (token == lexer->last_token)\n+\t{\n+\t  token = &eof_token;\n+\t  break;\n+\t}\n+      \n       if (token->type != CPP_PURGED)\n \t--n;\n     }\n@@ -583,20 +544,30 @@ cp_lexer_consume_token (cp_lexer* lexer)\n {\n   cp_token *token = lexer->next_token;\n \n+  gcc_assert (token != &eof_token);\n+  \n   do\n-    ++lexer->next_token;\n+    {\n+      lexer->next_token++;\n+      if (lexer->next_token == lexer->last_token)\n+\t{\n+\t  lexer->next_token = &eof_token;\n+\t  break;\n+\t}\n+      \n+    }\n   while (lexer->next_token->type == CPP_PURGED);\n-\n+  \n   cp_lexer_set_source_position_from_token (token);\n-\n+  \n   /* Provide debugging output.  */\n   if (cp_lexer_debugging_p (lexer))\n     {\n       fputs (\"cp_lexer: consuming token: \", cp_lexer_debug_stream);\n       cp_lexer_print_token (cp_lexer_debug_stream, token);\n       putc ('\\n', cp_lexer_debug_stream);\n     }\n-\n+  \n   return token;\n }\n \n@@ -608,14 +579,24 @@ static void\n cp_lexer_purge_token (cp_lexer *lexer)\n {\n   cp_token *tok = lexer->next_token;\n+  \n+  gcc_assert (tok != &eof_token);\n   tok->type = CPP_PURGED;\n   tok->location = UNKNOWN_LOCATION;\n   tok->value = NULL_TREE;\n   tok->keyword = RID_MAX;\n \n   do\n-    ++lexer->next_token;\n-  while (lexer->next_token->type == CPP_PURGED);\n+    {\n+      tok++;\n+      if (tok == lexer->last_token)\n+\t{\n+\t  tok = &eof_token;\n+\t  break;\n+\t}\n+    }\n+  while (tok->type == CPP_PURGED);\n+  lexer->next_token = tok;\n }\n \n /* Permanently remove all tokens after TOK, up to, but not\n@@ -625,9 +606,11 @@ cp_lexer_purge_token (cp_lexer *lexer)\n static void\n cp_lexer_purge_tokens_after (cp_lexer *lexer, cp_token *tok)\n {\n-  cp_token *peek;\n+  cp_token *peek = lexer->next_token;\n \n-  peek = cp_lexer_peek_token (lexer);\n+  if (peek == &eof_token)\n+    peek = lexer->last_token;\n+  \n   gcc_assert (tok < peek);\n \n   for ( tok += 1; tok != peek; tok += 1)\n@@ -668,10 +651,7 @@ cp_lexer_save_tokens (cp_lexer* lexer)\n   if (cp_lexer_debugging_p (lexer))\n     fprintf (cp_lexer_debug_stream, \"cp_lexer: saving tokens\\n\");\n \n-  VARRAY_PUSH_INT (lexer->saved_tokens,\n-\t\t   cp_lexer_token_difference (lexer,\n-\t\t\t\t\t      lexer->buffer,\n-\t\t\t\t\t      lexer->next_token));\n+  VEC_safe_push (cp_token_position, lexer->saved_tokens, lexer->next_token);\n }\n \n /* Commit to the portion of the token stream most recently saved.  */\n@@ -683,7 +663,7 @@ cp_lexer_commit_tokens (cp_lexer* lexer)\n   if (cp_lexer_debugging_p (lexer))\n     fprintf (cp_lexer_debug_stream, \"cp_lexer: committing tokens\\n\");\n \n-  VARRAY_POP (lexer->saved_tokens);\n+  VEC_pop (cp_token_position, lexer->saved_tokens);\n }\n \n /* Return all tokens saved since the last call to cp_lexer_save_tokens\n@@ -692,20 +672,11 @@ cp_lexer_commit_tokens (cp_lexer* lexer)\n static void\n cp_lexer_rollback_tokens (cp_lexer* lexer)\n {\n-  size_t delta;\n-\n   /* Provide debugging output.  */\n   if (cp_lexer_debugging_p (lexer))\n     fprintf (cp_lexer_debug_stream, \"cp_lexer: restoring tokens\\n\");\n \n-  /* Find the token that was the NEXT_TOKEN when we started saving\n-     tokens.  */\n-  delta = VARRAY_TOP_INT(lexer->saved_tokens);\n-  /* Make it the next token again now.  */\n-  lexer->next_token = cp_lexer_advance_token (lexer, lexer->buffer, delta);\n-\n-  /* Stop saving tokens.  */\n-  VARRAY_POP (lexer->saved_tokens);\n+  lexer->next_token = VEC_pop (cp_token_position, lexer->saved_tokens);\n }\n \n /* Print a representation of the TOKEN on the STREAM.  */\n@@ -1956,8 +1927,7 @@ static void\n cp_parser_check_for_invalid_template_id (cp_parser* parser,\n \t\t\t\t\t tree type)\n {\n-  ptrdiff_t start;\n-  cp_token *token;\n+  cp_token_position start = 0;\n \n   if (cp_lexer_next_token_is (parser->lexer, CPP_LESS))\n     {\n@@ -1970,28 +1940,15 @@ cp_parser_check_for_invalid_template_id (cp_parser* parser,\n       /* Remember the location of the invalid \"<\".  */\n       if (cp_parser_parsing_tentatively (parser)\n \t  && !cp_parser_committed_to_tentative_parse (parser))\n-\t{\n-\t  token = cp_lexer_peek_token (parser->lexer);\n-\t  token = cp_lexer_prev_token (parser->lexer, token);\n-\t  start = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t     parser->lexer->buffer,\n-\t\t\t\t\t     token);\n-\t}\n-      else\n-\tstart = -1;\n+\tstart = cp_lexer_token_position (parser->lexer, true);\n       /* Consume the \"<\".  */\n       cp_lexer_consume_token (parser->lexer);\n       /* Parse the template arguments.  */\n       cp_parser_enclosed_template_argument_list (parser);\n       /* Permanently remove the invalid template arguments so that\n \t this error message is not issued again.  */\n-      if (start >= 0)\n-\t{\n-\t  token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t\t  parser->lexer->buffer,\n-\t\t\t\t\t  start);\n-\t  cp_lexer_purge_tokens_after (parser->lexer, token);\n-\t}\n+      if (start)\n+\tcp_lexer_purge_tokens_after (parser->lexer, start);\n     }\n }\n \n@@ -2634,9 +2591,6 @@ cp_parser_translation_unit (cp_parser* parser)\n       /* If there are no tokens left then all went well.  */\n       if (cp_lexer_next_token_is (parser->lexer, CPP_EOF))\n \t{\n-\t  /* Consume the EOF token.  */\n-\t  cp_parser_require (parser, CPP_EOF, \"end-of-file\");\n-\n \t  /* Get rid of the token array; we don't need it any more. */\n \t  cp_lexer_destroy (parser->lexer);\n \t  parser->lexer = NULL;\n@@ -3382,8 +3336,8 @@ cp_parser_nested_name_specifier_opt (cp_parser *parser,\n {\n   bool success = false;\n   tree access_check = NULL_TREE;\n-  ptrdiff_t start;\n-  cp_token* token;\n+  cp_token_position start = 0;\n+  cp_token *token;\n \n   /* If the next token corresponds to a nested name specifier, there\n      is no need to reparse it.  However, if CHECK_DEPENDENCY_P is\n@@ -3402,14 +3356,7 @@ cp_parser_nested_name_specifier_opt (cp_parser *parser,\n   /* Remember where the nested-name-specifier starts.  */\n   if (cp_parser_parsing_tentatively (parser)\n       && !cp_parser_committed_to_tentative_parse (parser))\n-    {\n-      token = cp_lexer_peek_token (parser->lexer);\n-      start = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t parser->lexer->buffer,\n-\t\t\t\t\t token);\n-    }\n-  else\n-    start = -1;\n+    start = cp_lexer_token_position (parser->lexer, false);\n \n   push_deferring_access_checks (dk_deferred);\n \n@@ -3570,21 +3517,18 @@ cp_parser_nested_name_specifier_opt (cp_parser *parser,\n      token.  That way, should we re-parse the token stream, we will\n      not have to repeat the effort required to do the parse, nor will\n      we issue duplicate error messages.  */\n-  if (success && start >= 0)\n+  if (success && start)\n     {\n-      /* Find the token that corresponds to the start of the\n-\t template-id.  */\n-      token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t      parser->lexer->buffer,\n-\t\t\t\t      start);\n-\n+      cp_token *token = cp_lexer_token_at (parser->lexer, start);\n+      \n       /* Reset the contents of the START token.  */\n       token->type = CPP_NESTED_NAME_SPECIFIER;\n       token->value = build_tree_list (access_check, parser->scope);\n       TREE_TYPE (token->value) = parser->qualifying_scope;\n       token->keyword = RID_MAX;\n+      \n       /* Purge all subsequent tokens.  */\n-      cp_lexer_purge_tokens_after (parser->lexer, token);\n+      cp_lexer_purge_tokens_after (parser->lexer, start);\n     }\n \n   pop_deferring_access_checks ();\n@@ -8358,7 +8302,7 @@ cp_parser_template_id (cp_parser *parser,\n   tree template;\n   tree arguments;\n   tree template_id;\n-  ptrdiff_t start_of_id;\n+  cp_token_position start_of_id = 0;\n   tree access_check = NULL_TREE;\n   cp_token *next_token, *next_token_2;\n   bool is_identifier;\n@@ -8395,14 +8339,7 @@ cp_parser_template_id (cp_parser *parser,\n   /* Remember where the template-id starts.  */\n   if (cp_parser_parsing_tentatively (parser)\n       && !cp_parser_committed_to_tentative_parse (parser))\n-    {\n-      next_token = cp_lexer_peek_token (parser->lexer);\n-      start_of_id = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t       parser->lexer->buffer,\n-\t\t\t\t\t       next_token);\n-    }\n-  else\n-    start_of_id = -1;\n+    start_of_id = cp_lexer_token_position (parser->lexer, false);\n \n   push_deferring_access_checks (dk_deferred);\n \n@@ -8503,22 +8440,17 @@ cp_parser_template_id (cp_parser *parser,\n      the effort required to do the parse, nor will we issue duplicate\n      error messages about problems during instantiation of the\n      template.  */\n-  if (start_of_id >= 0)\n+  if (start_of_id)\n     {\n-      cp_token *token;\n-\n-      /* Find the token that corresponds to the start of the\n-\t template-id.  */\n-      token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t      parser->lexer->buffer,\n-\t\t\t\t      start_of_id);\n-\n+      cp_token *token = cp_lexer_token_at (parser->lexer, start_of_id);\n+      \n       /* Reset the contents of the START_OF_ID token.  */\n       token->type = CPP_TEMPLATE_ID;\n       token->value = build_tree_list (access_check, template_id);\n       token->keyword = RID_MAX;\n+      \n       /* Purge all subsequent tokens.  */\n-      cp_lexer_purge_tokens_after (parser->lexer, token);\n+      cp_lexer_purge_tokens_after (parser->lexer, start_of_id);\n     }\n \n   pop_deferring_access_checks ();\n@@ -8628,8 +8560,8 @@ cp_parser_template_name (cp_parser* parser,\n \t     need the template keyword before their name.  */\n \t  && !constructor_name_p (identifier, parser->scope))\n \t{\n-\t  ptrdiff_t start;\n-\t  cp_token* token;\n+\t  cp_token_position start = 0;\n+\t  \n \t  /* Explain what went wrong.  */\n \t  error (\"non-template %qD used as template\", identifier);\n \t  inform (\"use %<%T::template %D%> to indicate that it is a template\",\n@@ -8640,14 +8572,8 @@ cp_parser_template_name (cp_parser* parser,\n \t      && !cp_parser_committed_to_tentative_parse (parser))\n \t    {\n \t      cp_parser_simulate_error (parser);\n-\t      token = cp_lexer_peek_token (parser->lexer);\n-\t      token = cp_lexer_prev_token (parser->lexer, token);\n-\t      start = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t\t parser->lexer->buffer,\n-\t\t\t\t\t\t token);\n+\t      start = cp_lexer_token_position (parser->lexer, true);\n \t    }\n-\t  else\n-\t    start = -1;\n \t  /* Parse the template arguments so that we can issue error\n \t     messages about them.  */\n \t  cp_lexer_consume_token (parser->lexer);\n@@ -8662,13 +8588,8 @@ cp_parser_template_name (cp_parser* parser,\n \t     template argument list.  That will prevent duplicate\n \t     error messages from being issued about the missing\n \t     \"template\" keyword.  */\n-\t  if (start >= 0)\n-\t    {\n-\t      token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t\t      parser->lexer->buffer,\n-\t\t\t\t\t      start);\n-\t      cp_lexer_purge_tokens_after (parser->lexer, token);\n-\t    }\n+\t  if (start)\n+\t    cp_lexer_purge_tokens_after (parser->lexer, start);\n \t  if (is_identifier)\n \t    *is_identifier = true;\n \t  return identifier;"}]}