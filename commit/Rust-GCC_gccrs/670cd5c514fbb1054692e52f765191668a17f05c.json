{"sha": "670cd5c514fbb1054692e52f765191668a17f05c", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NjcwY2Q1YzUxNGZiYjEwNTQ2OTJlNTJmNzY1MTkxNjY4YTE3ZjA1Yw==", "commit": {"author": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2005-05-25T12:34:01Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2005-05-25T12:34:01Z"}, "message": "Makefile.in (ipa-inline.o): Add COEVERAGE_H dependency.\n\n\n\t* Makefile.in (ipa-inline.o): Add COEVERAGE_H dependency.\n\t* cgraph.c (cgraph_create_node): Reset estimated_growth.\n\t* cgraph.h (cgraph_global_info): Add estimated_growth.\n\t* ipa-inline.c: Include coverage.h\n\t(max_insns, max_count): New static variables.\n\t(cgraph_estimate_size_after_inlining): Cache the result.\n\t(cgraph_estimate_growth):\n\t* passes.c (rest_of_clean_state): Kill coverage_end_function.\n\t* timevar.def (TV_INLINE_HEURISTICS): New timevar.\n\t* tree-optimize.c (init_tree_optimization_passes): Move profiling before\n\tinlining.\n\t(ipa_passes): Initialize bitmaps.\n\n\t* gcc.dg/tree-prof/inliner-1.c: New.\n\n2005-05-25  Janis Johnson  <janis187@us.ibm.com>\n\n\t* gcc.dg/tree-prof: New directory.\n\t* gcc.dg/tree-prof/tree-prof.exp: New.\n\nFrom-SVN: r100144", "tree": {"sha": "cbc0aabd04b30c845e5acd57b7e1bb0c6b3c0fb7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/cbc0aabd04b30c845e5acd57b7e1bb0c6b3c0fb7"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/670cd5c514fbb1054692e52f765191668a17f05c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/670cd5c514fbb1054692e52f765191668a17f05c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/670cd5c514fbb1054692e52f765191668a17f05c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/670cd5c514fbb1054692e52f765191668a17f05c/comments", "author": null, "committer": null, "parents": [{"sha": "a71a498df01ba32349bed4e72631433be1ff4a2a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a71a498df01ba32349bed4e72631433be1ff4a2a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a71a498df01ba32349bed4e72631433be1ff4a2a"}], "stats": {"total": 534, "additions": 425, "deletions": 109}, "files": [{"sha": "d7191b2ba432ece05acef229fd37f2ff7372602c", "filename": "gcc/ChangeLog", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -1,3 +1,18 @@\n+2005-05-25  Jan Hubicka  <jh@suse.cz>\n+\n+\t* Makefile.in (ipa-inline.o): Add COEVERAGE_H dependency.\n+\t* cgraph.c (cgraph_create_node): Reset estimated_growth.\n+\t* cgraph.h (cgraph_global_info): Add estimated_growth.\n+\t* ipa-inline.c: Include coverage.h\n+\t(max_insns, max_count): New static variables.\n+\t(cgraph_estimate_size_after_inlining): Cache the result.\n+\t(cgraph_estimate_growth):\n+\t* passes.c (rest_of_clean_state): Kill coverage_end_function.\n+\t* timevar.def (TV_INLINE_HEURISTICS): New timevar.\n+\t* tree-optimize.c (init_tree_optimization_passes): Move profiling before\n+\tinlining.\n+\t(ipa_passes): Initialize bitmaps.\n+\n 2005-05-25  Adrian Straetling  <straetling@de.ibm.com>\n \n \t* loop-doloop.c: Include \"target.h\". "}, {"sha": "9bafd593cd885d06349b4f508752f2e9ace2d99a", "filename": "gcc/Makefile.in", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -2064,7 +2064,8 @@ cgraphunit.o : cgraphunit.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n ipa.o : ipa.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(CGRAPH_H) \n ipa-inline.o : ipa-inline.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n    $(TREE_H) langhooks.h tree-inline.h $(FLAGS_H) $(CGRAPH_H) intl.h \\\n-   $(DIAGNOSTIC_H) $(FIBHEAP_H) $(PARAMS_H) $(TIMEVAR_H) tree-pass.h\n+   $(DIAGNOSTIC_H) $(FIBHEAP_H) $(PARAMS_H) $(TIMEVAR_H) tree-pass.h \\\n+   $(COVERAGE_H)\n coverage.o : coverage.c $(GCOV_IO_H) $(CONFIG_H) $(SYSTEM_H) coretypes.h \\\n    $(TM_H) $(RTL_H) $(TREE_H) $(FLAGS_H) output.h $(REGS_H) $(EXPR_H) \\\n    function.h toplev.h $(GGC_H) langhooks.h $(COVERAGE_H) gt-coverage.h \\"}, {"sha": "8d93c2a6eb4545c9b841aa1aa06302994b25a2b5", "filename": "gcc/cgraph.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fcgraph.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fcgraph.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraph.c?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -169,6 +169,7 @@ cgraph_create_node (void)\n   if (cgraph_nodes)\n     cgraph_nodes->previous = node;\n   node->previous = NULL;\n+  node->global.estimated_growth = INT_MIN;\n   cgraph_nodes = node;\n   cgraph_n_nodes++;\n   return node;"}, {"sha": "c1c0b98c841ed2f82f814e122348b07b62d56c31", "filename": "gcc/cgraph.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fcgraph.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fcgraph.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraph.h?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -69,6 +69,9 @@ struct cgraph_global_info GTY(())\n   /* Estimated size of the function after inlining.  */\n   int insns;\n \n+  /* Estimated growth after inlining.  INT_MIN if not computed.  */\n+  int estimated_growth;\n+\n   /* Set iff the function has been inlined at least once.  */\n   bool inlined;\n };"}, {"sha": "8addcfb31cb6dc1c2bb483d441cc4a72e8643e0e", "filename": "gcc/ipa-inline.c", "status": "modified", "additions": 299, "deletions": 105, "changes": 404, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fipa-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fipa-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-inline.c?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -78,25 +78,31 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"fibheap.h\"\n #include \"intl.h\"\n #include \"tree-pass.h\"\n+#include \"coverage.h\"\n \n /* Statistics we collect about inlining algorithm.  */\n static int ncalls_inlined;\n static int nfunctions_inlined;\n static int initial_insns;\n static int overall_insns;\n+static int max_insns;\n+static gcov_type max_count;\n \n /* Estimate size of the function after inlining WHAT into TO.  */\n \n static int\n cgraph_estimate_size_after_inlining (int times, struct cgraph_node *to,\n \t\t\t\t     struct cgraph_node *what)\n {\n-  tree fndecl = what->decl;\n-  tree arg;\n+  int size;\n+  tree fndecl = what->decl, arg;\n   int call_insns = PARAM_VALUE (PARAM_INLINE_CALL_COST);\n+\n   for (arg = DECL_ARGUMENTS (fndecl); arg; arg = TREE_CHAIN (arg))\n     call_insns += estimate_move_cost (TREE_TYPE (arg));\n-  return (what->global.insns - call_insns) * times + to->global.insns;\n+  size = (what->global.insns - call_insns) * times + to->global.insns;\n+  gcc_assert (size >= 0);\n+  return size;\n }\n \n /* E is expected to be an edge being inlined.  Clone destination node of\n@@ -209,6 +215,8 @@ cgraph_estimate_growth (struct cgraph_node *node)\n {\n   int growth = 0;\n   struct cgraph_edge *e;\n+  if (node->global.estimated_growth != INT_MIN)\n+    return node->global.estimated_growth;\n \n   for (e = node->callers; e; e = e->next_caller)\n     if (e->inline_failed)\n@@ -221,6 +229,7 @@ cgraph_estimate_growth (struct cgraph_node *node)\n   if (!node->needed && !DECL_EXTERNAL (node->decl))\n     growth -= node->global.insns;\n \n+  node->global.estimated_growth = growth;\n   return growth;\n }\n \n@@ -298,52 +307,145 @@ cgraph_recursive_inlining_p (struct cgraph_node *to,\n   return recursive;\n }\n \n-/* Recompute heap nodes for each of callees.  */\n+/* Return true if the call can be hot.  */\n+static bool\n+cgraph_maybe_hot_edge_p (struct cgraph_edge *edge)\n+{\n+  if (profile_info && flag_branch_probabilities\n+      && (edge->count\n+\t  <= profile_info->sum_max / PARAM_VALUE (HOT_BB_COUNT_FRACTION)))\n+    return false;\n+  return true;\n+}\n+\n+/* A cost model driving the inlining heuristics in a way so the edges with\n+   smallest badness are inlined first.  After each inlining is performed\n+   the costs of all caller edges of nodes affected are recompted so the\n+   metrics may accurately depend on values such as number of inlinable callers\n+   of the function or function body size.\n+\n+   For the moment we use estimated growth caused by inlining callee into all\n+   it's callers for driving the inlining but once we have loop depth or\n+   frequency information readilly available we should do better.\n+\n+   With profiling we use number of executions of each edge to drive the cost.\n+   We also should distinguish hot and cold calls where the cold calls are\n+   inlined into only when code size is overall improved.  \n+   \n+   Value INT_MAX can be returned to prevent function from being inlined.\n+   */\n+\n+static int\n+cgraph_edge_badness (struct cgraph_edge *edge)\n+{\n+  if (max_count)\n+    {\n+      int growth =\n+\tcgraph_estimate_size_after_inlining (1, edge->caller, edge->callee);\n+      growth -= edge->caller->global.insns;\n+\n+      /* Always preffer inlining saving code size.  */\n+      if (growth <= 0)\n+\treturn INT_MIN - growth;\n+      return ((int)((double)edge->count * INT_MIN / max_count)) / growth;\n+    }\n+  else\n+  {\n+    int nest = MIN (edge->loop_nest, 8);\n+    int badness = cgraph_estimate_growth (edge->callee) * 256;\n+\t\t    \n+    badness >>= nest;\n+\n+    /* Make recursive inlining happen always after other inlining is done.  */\n+    if (cgraph_recursive_inlining_p (edge->caller, edge->callee, NULL))\n+      return badness + 1;\n+    else\n+      return badness;\n+  }\n+}\n+\n+/* Recompute heap nodes for each of caller edge.  */\n+\n+static void\n+update_caller_keys (fibheap_t heap, struct cgraph_node *node,\n+\t\t    bitmap updated_nodes)\n+{\n+  struct cgraph_edge *edge;\n+\n+  if (!node->local.inlinable || node->local.disregard_inline_limits\n+      || node->global.inlined_to)\n+    return;\n+  if (bitmap_bit_p (updated_nodes, node->uid))\n+    return;\n+  bitmap_set_bit (updated_nodes, node->uid);\n+\n+  for (edge = node->callers; edge; edge = edge->next_caller)\n+    if (edge->inline_failed)\n+      {\n+\tint badness = cgraph_edge_badness (edge);\n+\tif (edge->aux)\n+\t  {\n+\t    fibnode_t n = edge->aux;\n+\t    gcc_assert (n->data == edge);\n+\t    if (n->key == badness)\n+\t      continue;\n+\n+\t    /* fibheap_replace_key only increase the keys.  */\n+\t    if (fibheap_replace_key (heap, n, badness))\n+\t      continue;\n+\t    fibheap_delete_node (heap, edge->aux);\n+\t  }\n+\tedge->aux = fibheap_insert (heap, badness, edge);\n+      }\n+}\n+\n+/* Recompute heap nodes for each of caller edges of each of callees.  */\n+\n static void\n-update_callee_keys (fibheap_t heap, struct fibnode **heap_node,\n-\t\t    struct cgraph_node *node)\n+update_callee_keys (fibheap_t heap, struct cgraph_node *node,\n+\t\t    bitmap updated_nodes)\n {\n   struct cgraph_edge *e;\n+  node->global.estimated_growth = INT_MIN;\n \n   for (e = node->callees; e; e = e->next_callee)\n-    if (e->inline_failed && heap_node[e->callee->uid])\n-      fibheap_replace_key (heap, heap_node[e->callee->uid],\n-\t\t\t   cgraph_estimate_growth (e->callee));\n+    if (e->inline_failed)\n+      update_caller_keys (heap, e->callee, updated_nodes);\n     else if (!e->inline_failed)\n-      update_callee_keys (heap, heap_node, e->callee);\n+      update_callee_keys (heap, e->callee, updated_nodes);\n }\n \n-/* Enqueue all recursive calls from NODE into queue linked via aux pointers\n-   in between FIRST and LAST.  WHERE is used for bookkeeping while looking\n-   int calls inlined within NODE.  */\n+/* Enqueue all recursive calls from NODE into priority queue depending on\n+   how likely we want to recursivly inline the call.  */\n+\n static void\n lookup_recursive_calls (struct cgraph_node *node, struct cgraph_node *where,\n-\t\t\tstruct cgraph_edge **first, struct cgraph_edge **last)\n+\t\t\tfibheap_t heap)\n {\n+  static int priority;\n   struct cgraph_edge *e;\n   for (e = where->callees; e; e = e->next_callee)\n     if (e->callee == node)\n       {\n-\tif (!*first)\n-\t  *first = e;\n-\telse\n-\t  (*last)->aux = e;\n-\t*last = e;\n+\t/* FIXME: Once counts and frequencies are available we should drive the\n+\t   order by these.  For now force the order to be simple queue since\n+\t   we get order dependent on recursion depth for free by this.  */\n+        fibheap_insert (heap, priority++, e);\n       }\n   for (e = where->callees; e; e = e->next_callee)\n     if (!e->inline_failed)\n-      lookup_recursive_calls (node, e->callee, first, last);\n+      lookup_recursive_calls (node, e->callee, heap);\n }\n \n /* Decide on recursive inlining: in the case function has recursive calls,\n    inline until body size reaches given argument.  */\n-static void\n+\n+static bool\n cgraph_decide_recursive_inlining (struct cgraph_node *node)\n {\n   int limit = PARAM_VALUE (PARAM_MAX_INLINE_INSNS_RECURSIVE_AUTO);\n   int max_depth = PARAM_VALUE (PARAM_MAX_INLINE_RECURSIVE_DEPTH_AUTO);\n-  struct cgraph_edge *first_call = NULL, *last_call = NULL;\n-  struct cgraph_edge *last_in_current_depth;\n+  fibheap_t heap;\n   struct cgraph_edge *e;\n   struct cgraph_node *master_clone;\n   int depth = 0;\n@@ -358,14 +460,18 @@ cgraph_decide_recursive_inlining (struct cgraph_node *node)\n   /* Make sure that function is small enough to be considered for inlining.  */\n   if (!max_depth\n       || cgraph_estimate_size_after_inlining (1, node, node)  >= limit)\n-    return;\n-  lookup_recursive_calls (node, node, &first_call, &last_call);\n-  if (!first_call)\n-    return;\n+    return false;\n+  heap = fibheap_new ();\n+  lookup_recursive_calls (node, node, heap);\n+  if (fibheap_empty (heap))\n+    {\n+      fibheap_delete (heap);\n+      return false;\n+    }\n \n   if (dump_file)\n     fprintf (dump_file, \n-\t     \"\\nPerforming recursive inlining on %s\\n\",\n+\t     \"  Performing recursive inlining on %s\\n\",\n \t     cgraph_node_name (node));\n \n   /* We need original clone to copy around.  */\n@@ -376,32 +482,30 @@ cgraph_decide_recursive_inlining (struct cgraph_node *node)\n       cgraph_clone_inlined_nodes (e, true);\n \n   /* Do the inlining and update list of recursive call during process.  */\n-  last_in_current_depth = last_call;\n-  while (first_call\n+  while (!fibheap_empty (heap)\n \t && cgraph_estimate_size_after_inlining (1, node, master_clone) <= limit)\n     {\n-      struct cgraph_edge *curr = first_call;\n-\n-      first_call = first_call->aux;\n-      curr->aux = NULL;\n+      struct cgraph_edge *curr = fibheap_extract_min (heap);\n+      struct cgraph_node *node;\n+\n+      depth = 0;\n+      for (node = curr->caller;\n+\t   node; node = node->global.inlined_to)\n+\tif (node->decl == curr->callee->decl)\n+\t  depth++;\n+      if (depth > max_depth)\n+\tcontinue;\n \n+      if (dump_file)\n+\tfprintf (dump_file, \n+\t\t \"   Inlining call of depth %i\\n\", depth);\n       cgraph_redirect_edge_callee (curr, master_clone);\n       cgraph_mark_inline_edge (curr);\n-      lookup_recursive_calls (node, curr->callee, &first_call, &last_call);\n-\n-      if (last_in_current_depth\n-\t  && ++depth >= max_depth)\n-\tbreak;\n+      lookup_recursive_calls (node, curr->callee, heap);\n       n++;\n     }\n \n-  /* Cleanup queue pointers.  */\n-  while (first_call)\n-    {\n-      struct cgraph_edge *next = first_call->aux;\n-      first_call->aux = NULL;\n-      first_call = next;\n-    }\n+  fibheap_delete (heap);\n   if (dump_file)\n     fprintf (dump_file, \n \t     \"\\n   Inlined %i times, body grown from %i to %i insns\\n\", n,\n@@ -415,6 +519,7 @@ cgraph_decide_recursive_inlining (struct cgraph_node *node)\n     if (node->global.inlined_to == master_clone)\n       cgraph_remove_node (node);\n   cgraph_remove_node (master_clone);\n+  return true;\n }\n \n /* Set inline_failed for all callers of given function to REASON.  */\n@@ -442,11 +547,12 @@ static void\n cgraph_decide_inlining_of_small_functions (void)\n {\n   struct cgraph_node *node;\n+  struct cgraph_edge *edge;\n   fibheap_t heap = fibheap_new ();\n-  struct fibnode **heap_node =\n-    xcalloc (cgraph_max_uid, sizeof (struct fibnode *));\n-  int max_insns = ((HOST_WIDEST_INT) initial_insns\n-\t\t   * (100 + PARAM_VALUE (PARAM_INLINE_UNIT_GROWTH)) / 100);\n+  bitmap updated_nodes = BITMAP_ALLOC (NULL);\n+\n+  if (dump_file)\n+    fprintf (dump_file, \"\\nDeciding on smaller functions:\\n\");\n \n   /* Put all inline candidates into the heap.  */\n \n@@ -455,87 +561,161 @@ cgraph_decide_inlining_of_small_functions (void)\n       if (!node->local.inlinable || !node->callers\n \t  || node->local.disregard_inline_limits)\n \tcontinue;\n+      if (dump_file)\n+\tfprintf (dump_file, \"Considering inline candidate %s.\\n\", cgraph_node_name (node));\n \n+      node->global.estimated_growth = INT_MIN;\n       if (!cgraph_default_inline_p (node))\n \t{\n \t  cgraph_set_inline_failed (node,\n \t    N_(\"--param max-inline-insns-single limit reached\"));\n \t  continue;\n \t}\n-      heap_node[node->uid] =\n-\tfibheap_insert (heap, cgraph_estimate_growth (node), node);\n-    }\n \n-  if (dump_file)\n-    fprintf (dump_file, \"\\nDeciding on smaller functions:\\n\");\n-  while (overall_insns <= max_insns && (node = fibheap_extract_min (heap)))\n+      for (edge = node->callers; edge; edge = edge->next_caller)\n+\tif (edge->inline_failed)\n+\t  {\n+\t    gcc_assert (!edge->aux);\n+\t    edge->aux = fibheap_insert (heap, cgraph_edge_badness (edge), edge);\n+\t  }\n+    }\n+  while (overall_insns <= max_insns && (edge = fibheap_extract_min (heap)))\n     {\n-      struct cgraph_edge *e, *next;\n       int old_insns = overall_insns;\n+      struct cgraph_node *where;\n+      int growth =\n+\tcgraph_estimate_size_after_inlining (1, edge->caller, edge->callee);\n+\n+      growth -= edge->caller->global.insns;\n \n-      heap_node[node->uid] = NULL;\n       if (dump_file)\n-\tfprintf (dump_file, \n-\t\t \"\\nConsidering %s with %i insns\\n\"\n-\t\t \" Estimated growth is %+i insns.\\n\",\n-\t\t cgraph_node_name (node), node->global.insns,\n-\t\t cgraph_estimate_growth (node));\n-      if (!cgraph_default_inline_p (node))\n \t{\n-\t  cgraph_set_inline_failed (node,\n-\t    N_(\"--param max-inline-insns-single limit reached after inlining into the callee\"));\n-\t  continue;\n+\t  fprintf (dump_file, \n+\t\t   \"\\nConsidering %s with %i insns to be inlined into %s\\n\"\n+\t\t   \" Estimated growth after inlined into all callees is %+i insns.\\n\"\n+\t\t   \" Estimated badness is %i.\\n\",\n+\t\t   cgraph_node_name (edge->callee),\n+\t\t   edge->callee->global.insns,\n+\t\t   cgraph_node_name (edge->caller),\n+\t\t   cgraph_estimate_growth (edge->callee),\n+\t\t   cgraph_edge_badness (edge));\n+\t  if (edge->count)\n+\t    fprintf (dump_file,\" Called \"HOST_WIDEST_INT_PRINT_DEC\"x\\n\", edge->count);\n \t}\n-      for (e = node->callers; e; e = next)\n-\t{\n-\t  next = e->next_caller;\n-\t  if (e->inline_failed)\n-\t    {\n-\t      struct cgraph_node *where;\n-\n-\t      if (cgraph_recursive_inlining_p (e->caller, e->callee,\n-\t\t\t\t      \t       &e->inline_failed)\n-\t\t  || !cgraph_check_inline_limits (e->caller, e->callee,\n-\t\t\t  \t\t\t  &e->inline_failed))\n-\t\t{\n-\t\t  if (dump_file)\n-\t\t    fprintf (dump_file, \" Not inlining into %s:%s.\\n\",\n-\t\t\t     cgraph_node_name (e->caller), e->inline_failed);\n-\t\t  continue;\n-\t\t}\n-\t      next = cgraph_mark_inline (e);\n-\t      where = e->caller;\n-\t      if (where->global.inlined_to)\n-\t\twhere = where->global.inlined_to;\n+      gcc_assert (edge->aux);\n+      edge->aux = NULL;\n+      if (!edge->inline_failed)\n+\tcontinue;\n \n-\t      if (heap_node[where->uid])\n-\t\tfibheap_replace_key (heap, heap_node[where->uid],\n-\t\t\t\t     cgraph_estimate_growth (where));\n+      /* When not having profile info ready we don't weight by any way the\n+         possition of call in procedure itself.  This means if call of\n+\t function A from function B seems profitable to inline, the recursive\n+\t call of function A in inline copy of A in B will look profitable too\n+\t and we end up inlining until reaching maximal function growth.  This\n+\t is not good idea so prohibit the recursive inlining.\n \n+\t ??? When the frequencies are taken into account we might not need this\n+\t restriction.   */\n+      if (!max_count)\n+\t{\n+\t  where = edge->caller;\n+\t  while (where->global.inlined_to)\n+\t    {\n+\t      if (where->decl == edge->callee->decl)\n+\t\tbreak;\n+\t      where = where->callers->caller;\n+\t    }\n+\t  if (where->global.inlined_to)\n+\t    {\n+\t      edge->inline_failed\n+\t\t= (edge->callee->local.disregard_inline_limits ? N_(\"recursive inlining\") : \"\");\n \t      if (dump_file)\n-\t\tfprintf (dump_file, \n-\t\t\t \" Inlined into %s which now has %i insns.\\n\",\n-\t\t\t cgraph_node_name (e->caller),\n-\t\t\t e->caller->global.insns);\n+\t\tfprintf (dump_file, \" inline_failed:Recursive inlining perfomed only for function itself.\\n\");\n+\t      continue;\n \t    }\n \t}\n \n-      cgraph_decide_recursive_inlining (node);\n-\n-      /* Similarly all functions called by the function we just inlined\n-         are now called more times; update keys.  */\n-      update_callee_keys (heap, heap_node, node);\n+      if (!cgraph_maybe_hot_edge_p (edge) && growth > 0)\n+\t{\n+          if (!cgraph_recursive_inlining_p (edge->caller, edge->callee,\n+\t\t\t\t            &edge->inline_failed))\n+\t    {\n+\t      edge->inline_failed = \n+\t\tN_(\"call is unlikely\");\n+\t      if (dump_file)\n+\t\tfprintf (dump_file, \" inline_failed:%s.\\n\", edge->inline_failed);\n+\t    }\n+\t  continue;\n+\t}\n+      if (!cgraph_default_inline_p (edge->callee))\n+\t{\n+          if (!cgraph_recursive_inlining_p (edge->caller, edge->callee,\n+\t\t\t\t            &edge->inline_failed))\n+\t    {\n+\t      edge->inline_failed = \n+\t\tN_(\"--param max-inline-insns-single limit reached after inlining into the callee\");\n+\t      if (dump_file)\n+\t\tfprintf (dump_file, \" inline_failed:%s.\\n\", edge->inline_failed);\n+\t    }\n+\t  continue;\n+\t}\n+      if (cgraph_recursive_inlining_p (edge->caller, edge->callee,\n+\t\t\t\t       &edge->inline_failed))\n+\t{\n+\t  where = edge->caller;\n+\t  if (where->global.inlined_to)\n+\t    where = where->global.inlined_to;\n+\t  if (!cgraph_decide_recursive_inlining (where))\n+\t    continue;\n+          update_callee_keys (heap, where, updated_nodes);\n+\t}\n+      else\n+\t{\n+\t  if (!cgraph_check_inline_limits (edge->caller, edge->callee,\n+\t\t\t\t\t   &edge->inline_failed))\n+\t    {\n+\t      if (dump_file)\n+\t\tfprintf (dump_file, \" Not inlining into %s:%s.\\n\",\n+\t\t\t cgraph_node_name (edge->caller), edge->inline_failed);\n+\t      continue;\n+\t    }\n+\t  cgraph_mark_inline_edge (edge);\n+         update_callee_keys (heap, edge->callee, updated_nodes);\n+\t}\n+      where = edge->caller;\n+      if (where->global.inlined_to)\n+\twhere = where->global.inlined_to;\n+\n+      /* Our profitability metric can depend on local properties\n+\t such as number of inlinable calls and size of the function body.\n+\t After inlining these properties might change for the function we\n+\t inlined into (since it's body size changed) and for the functions\n+\t called by function we inlined (since number of it inlinable callers\n+\t might change).  */\n+      update_caller_keys (heap, where, updated_nodes);\n+      bitmap_clear (updated_nodes);\n \n+      if (dump_file)\n+\tfprintf (dump_file, \n+\t\t \" Inlined into %s which now has %i insns.\\n\",\n+\t\t cgraph_node_name (edge->caller),\n+\t\t edge->caller->global.insns);\n       if (dump_file)\n \tfprintf (dump_file, \n \t\t \" Inlined for a net change of %+i insns.\\n\",\n \t\t overall_insns - old_insns);\n     }\n-  while ((node = fibheap_extract_min (heap)) != NULL)\n-    if (!node->local.disregard_inline_limits)\n-      cgraph_set_inline_failed (node, N_(\"--param inline-unit-growth limit reached\"));\n+  while ((edge = fibheap_extract_min (heap)) != NULL)\n+    {\n+      gcc_assert (edge->aux);\n+      edge->aux = NULL;\n+      if (!edge->callee->local.disregard_inline_limits && edge->inline_failed\n+          && !cgraph_recursive_inlining_p (edge->caller, edge->callee,\n+\t\t\t\t           &edge->inline_failed))\n+\tedge->inline_failed = N_(\"--param inline-unit-growth limit reached\");\n+    }\n   fibheap_delete (heap);\n-  free (heap_node);\n+  BITMAP_FREE (updated_nodes);\n }\n \n /* Decide on the inlining.  We do so in the topological order to avoid\n@@ -551,9 +731,21 @@ cgraph_decide_inlining (void)\n   int old_insns = 0;\n   int i;\n \n+  timevar_push (TV_INLINE_HEURISTICS);\n+  max_count = 0;\n   for (node = cgraph_nodes; node; node = node->next)\n-    initial_insns += node->local.self_insns;\n+    {\n+      struct cgraph_edge *e;\n+      initial_insns += node->local.self_insns;\n+      for (e = node->callees; e; e = e->next_callee)\n+\tif (max_count < e->count)\n+\t  max_count = e->count;\n+    }\n   overall_insns = initial_insns;\n+  gcc_assert (!max_count || (profile_info && flag_branch_probabilities));\n+\n+  max_insns = ((HOST_WIDEST_INT) overall_insns\n+\t       * (100 + PARAM_VALUE (PARAM_INLINE_UNIT_GROWTH)) / 100);\n \n   nnodes = cgraph_postorder (order);\n \n@@ -668,6 +860,7 @@ cgraph_decide_inlining (void)\n   /* We will never output extern functions we didn't inline. \n      ??? Perhaps we can prevent accounting of growth of external\n      inline functions.  */\n+\n   cgraph_remove_unreachable_nodes (false, dump_file);\n \n   if (dump_file)\n@@ -677,6 +870,7 @@ cgraph_decide_inlining (void)\n \t     ncalls_inlined, nfunctions_inlined, initial_insns,\n \t     overall_insns);\n   free (order);\n+  timevar_pop (TV_INLINE_HEURISTICS);\n }\n \n /* Decide on the inlining.  We do so in the topological order to avoid"}, {"sha": "369a2a53b2716f9fd6dccde87c68c1fc034e11ad", "filename": "gcc/passes.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fpasses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fpasses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.c?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -1427,7 +1427,6 @@ static void\n rest_of_clean_state (void)\n {\n   rtx insn, next;\n-  coverage_end_function ();\n \n   /* It is very important to decompose the RTL instruction chain here:\n      debug information keeps pointing into CODE_LABEL insns inside the function"}, {"sha": "b1514a523abd0bcf211ed6e5f6a52e96d94396a3", "filename": "gcc/profile.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fprofile.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Fprofile.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fprofile.c?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -1141,6 +1141,7 @@ branch_prob (void)\n   free_edge_list (el);\n   if (flag_branch_probabilities)\n     profile_status = PROFILE_READ;\n+  coverage_end_function ();\n }\n \f\n /* Union find algorithm implementation for the basic blocks using"}, {"sha": "7e4b7a2bd13e735455861f9a24b24eef03ecf94c", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -1,3 +1,12 @@\n+2005-05-25  Jan Hubicka  <jh@suse.cz>\n+\n+\t* gcc.dg/tree-prof/inliner-1.c: New.\n+\n+2005-05-25  Janis Johnson  <janis187@us.ibm.com>\n+\n+\t* gcc.dg/tree-prof: New directory.\n+\t* gcc.dg/tree-prof/tree-prof.exp: New.\n+\n 2005-05-25  DJ Delorie  <dj@redhat.com>\n \n \t* gcc.dg/Wattributes-1.c: New."}, {"sha": "9a1cd01f337e336a516e08d56564a15f7bb501e8", "filename": "gcc/testsuite/gcc.dg/tree-prof/inliner-1.c", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-prof%2Finliner-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-prof%2Finliner-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-prof%2Finliner-1.c?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -0,0 +1,37 @@\n+/* { dg-options \"-O2 -fdump-tree-optimized -fdump-tree-all\" } */\n+int a;\n+int b[100];\n+void abort (void);\n+\n+inline void\n+cold_function ()\n+{\n+  int i;\n+  for (i = 0; i < 99; i++)\n+    if (b[i] / (b[i+1] + 1))\n+      abort ();\n+}\n+\n+inline void\n+hot_function ()\n+{\n+  int i;\n+  for (i = 0; i < 99; i++)\n+    if (b[i] / (b[i+1] + 1))\n+      abort ();\n+}\n+\n+main ()\n+{\n+  if (a)\n+    cold_function ();\n+  else\n+    hot_function ();\n+  return 0;\n+}\n+\n+/* cold function should be inlined, while hot function should not.  \n+   Look for \"cold_function () [tail call];\" call statement not for the\n+   declaration or other apperances of the string in dump.  */\n+/* { dg-final-use { scan-tree-dump \"cold_function ..;\" \"optimized\"} } */\n+/* { dg-final-use { scan-tree-dump-not \"hot_function ..;\" \"optimized\"} } */"}, {"sha": "307cc2c52ae81c6bb5e0a608d810176cbfbaefa1", "filename": "gcc/testsuite/gcc.dg/tree-prof/tree-prof.exp", "status": "added", "additions": 53, "deletions": 0, "changes": 53, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-prof%2Ftree-prof.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-prof%2Ftree-prof.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-prof%2Ftree-prof.exp?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -0,0 +1,53 @@\n+#   Copyright (C) 2001, 2002, 2004, 2005 Free Software Foundation, Inc.\n+\n+# This program is free software; you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation; either version 2 of the License, or\n+# (at your option) any later version.\n+# \n+# This program is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+# \n+# You should have received a copy of the GNU General Public License\n+# along with this program; if not, write to the Free Software\n+# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  \n+\n+# Test the functionality of programs compiled with profile-directed block\n+# ordering using -fprofile-generate followed by -fprofile-use\n+\n+load_lib target-supports.exp\n+\n+# Some targets don't support tree profiling.\n+if { ![check_profiling_available \"-ftree-based-profiling\"] } {\n+    return\n+}\n+\n+# The procedures in profopt.exp need these parameters.\n+set tool gcc\n+set prof_ext \"gcda gcno\"\n+\n+# Override the list defined in profopt.exp.\n+set PROFOPT_OPTIONS [list {}]\n+\n+if $tracelevel then {\n+    strace $tracelevel\n+}\n+\n+# Load support procs.\n+load_lib profopt.exp\n+\n+# These are globals used by profopt-execute.  The first is options\n+# needed to generate profile data, the second is options to use the\n+# profile data.\n+set profile_option \"-ftree-based-profiling -fprofile-generate\"\n+set feedback_option \"-ftree-based-profiling -fprofile-use\"\n+\n+foreach src [lsort [glob -nocomplain $srcdir/$subdir/*.c]] {\n+    # If we're only testing specific files and this isn't one of them, skip it.\n+    if ![runtest_file_p $runtests $src] then {\n+        continue\n+    }\n+    profopt-execute $src\n+}"}, {"sha": "7f07aa3dc1dde5ee512e67aa579b55143430d429", "filename": "gcc/timevar.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftimevar.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftimevar.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftimevar.def?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -60,6 +60,7 @@ DEFTIMEVAR (TV_CPP\t\t     , \"preprocessing\")\n DEFTIMEVAR (TV_LEX\t\t     , \"lexical analysis\")\n DEFTIMEVAR (TV_PARSE                 , \"parser\")\n DEFTIMEVAR (TV_NAME_LOOKUP           , \"name lookup\")\n+DEFTIMEVAR (TV_INLINE_HEURISTICS     , \"inline heuristics\")\n DEFTIMEVAR (TV_INTEGRATION           , \"integration\")\n DEFTIMEVAR (TV_TREE_GIMPLIFY\t     , \"tree gimplify\")\n DEFTIMEVAR (TV_TREE_EH\t\t     , \"tree eh\")"}, {"sha": "825c2b194fcc56121ba72e0710a6502ef1bb6b09", "filename": "gcc/tree-optimize.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftree-optimize.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/670cd5c514fbb1054692e52f765191668a17f05c/gcc%2Ftree-optimize.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-optimize.c?ref=670cd5c514fbb1054692e52f765191668a17f05c", "patch": "@@ -377,11 +377,11 @@ init_tree_optimization_passes (void)\n   NEXT_PASS (pass_build_cfg); \n   NEXT_PASS (pass_pre_expand);\n   NEXT_PASS (pass_warn_function_return);\n+  NEXT_PASS (pass_tree_profile);\n   *p = NULL;\n \n   p = &all_passes;\n   NEXT_PASS (pass_fixup_cfg);\n-  NEXT_PASS (pass_tree_profile);\n   NEXT_PASS (pass_init_datastructures);\n   NEXT_PASS (pass_all_optimizations);\n   NEXT_PASS (pass_warn_function_noreturn);\n@@ -682,7 +682,9 @@ tree_lowering_passes (tree fn)\n void\n ipa_passes (void)\n {\n-   execute_pass_list (all_ipa_passes);\n+  bitmap_obstack_initialize (NULL);\n+  execute_pass_list (all_ipa_passes);\n+  bitmap_obstack_release (NULL);\n }\n \f\n "}]}