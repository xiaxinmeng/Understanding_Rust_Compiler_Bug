{"sha": "adedd5c173388ae505470df152b9cb3947339566", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWRlZGQ1YzE3MzM4OGFlNTA1NDcwZGYxNTJiOWNiMzk0NzMzOTU2Ng==", "commit": {"author": {"name": "Jakub Jelinek", "email": "jakub@redhat.com", "date": "2016-05-03T11:37:25Z"}, "committer": {"name": "Jakub Jelinek", "email": "jakub@gcc.gnu.org", "date": "2016-05-03T11:37:25Z"}, "message": "re PR target/49244 (__sync or __atomic builtins will not emit 'lock bts/btr/btc')\n\n\tPR target/49244\n\t* tree-ssa-ccp.c: Include stor-layout.h and optabs-query.h.\n\t(optimize_atomic_bit_test_and): New function.\n\t(pass_fold_builtins::execute): Use it.\n\t* optabs.def (atomic_bit_test_and_set_optab,\n\tatomic_bit_test_and_complement_optab,\n\tatomic_bit_test_and_reset_optab): New optabs.\n\t* internal-fn.def (ATOMIC_BIT_TEST_AND_SET,\n\tATOMIC_BIT_TEST_AND_COMPLEMENT, ATOMIC_BIT_TEST_AND_RESET): New ifns.\n\t* builtins.h (expand_ifn_atomic_bit_test_and): New prototype.\n\t* builtins.c (expand_ifn_atomic_bit_test_and): New function.\n\t* internal-fn.c (expand_ATOMIC_BIT_TEST_AND_SET,\n\texpand_ATOMIC_BIT_TEST_AND_COMPLEMENT,\n\texpand_ATOMIC_BIT_TEST_AND_RESET): New functions.\n\t* doc/md.texi (atomic_bit_test_and_set@var{mode},\n\tatomic_bit_test_and_complement@var{mode},\n\tatomic_bit_test_and_reset@var{mode}): Document.\n\t* config/i386/sync.md (atomic_bit_test_and_set<mode>,\n\tatomic_bit_test_and_complement<mode>,\n\tatomic_bit_test_and_reset<mode>): New expanders.\n\t(atomic_bit_test_and_set<mode>_1,\n\tatomic_bit_test_and_complement<mode>_1,\n\tatomic_bit_test_and_reset<mode>_1): New insns.\n\n\t* gcc.target/i386/pr49244-1.c: New test.\n\t* gcc.target/i386/pr49244-2.c: New test.\n\nFrom-SVN: r235813", "tree": {"sha": "858576e93abb78b087773e895b143546903f49f2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/858576e93abb78b087773e895b143546903f49f2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/adedd5c173388ae505470df152b9cb3947339566", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/adedd5c173388ae505470df152b9cb3947339566", "html_url": "https://github.com/Rust-GCC/gccrs/commit/adedd5c173388ae505470df152b9cb3947339566", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/adedd5c173388ae505470df152b9cb3947339566/comments", "author": {"login": "jakubjelinek", "id": 9370665, "node_id": "MDQ6VXNlcjkzNzA2NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/9370665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubjelinek", "html_url": "https://github.com/jakubjelinek", "followers_url": "https://api.github.com/users/jakubjelinek/followers", "following_url": "https://api.github.com/users/jakubjelinek/following{/other_user}", "gists_url": "https://api.github.com/users/jakubjelinek/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubjelinek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubjelinek/subscriptions", "organizations_url": "https://api.github.com/users/jakubjelinek/orgs", "repos_url": "https://api.github.com/users/jakubjelinek/repos", "events_url": "https://api.github.com/users/jakubjelinek/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubjelinek/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "50891606a95368edd688fa9dc73003b1dfd68983", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/50891606a95368edd688fa9dc73003b1dfd68983", "html_url": "https://github.com/Rust-GCC/gccrs/commit/50891606a95368edd688fa9dc73003b1dfd68983"}], "stats": {"total": 876, "additions": 876, "deletions": 0}, "files": [{"sha": "7122b6c2ba98bd28fd90f2d700a095302f461a98", "filename": "gcc/ChangeLog", "status": "modified", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -1,3 +1,29 @@\n+2016-05-03  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR target/49244\n+\t* tree-ssa-ccp.c: Include stor-layout.h and optabs-query.h.\n+\t(optimize_atomic_bit_test_and): New function.\n+\t(pass_fold_builtins::execute): Use it.\n+\t* optabs.def (atomic_bit_test_and_set_optab,\n+\tatomic_bit_test_and_complement_optab,\n+\tatomic_bit_test_and_reset_optab): New optabs.\n+\t* internal-fn.def (ATOMIC_BIT_TEST_AND_SET,\n+\tATOMIC_BIT_TEST_AND_COMPLEMENT, ATOMIC_BIT_TEST_AND_RESET): New ifns.\n+\t* builtins.h (expand_ifn_atomic_bit_test_and): New prototype.\n+\t* builtins.c (expand_ifn_atomic_bit_test_and): New function.\n+\t* internal-fn.c (expand_ATOMIC_BIT_TEST_AND_SET,\n+\texpand_ATOMIC_BIT_TEST_AND_COMPLEMENT,\n+\texpand_ATOMIC_BIT_TEST_AND_RESET): New functions.\n+\t* doc/md.texi (atomic_bit_test_and_set@var{mode},\n+\tatomic_bit_test_and_complement@var{mode},\n+\tatomic_bit_test_and_reset@var{mode}): Document.\n+\t* config/i386/sync.md (atomic_bit_test_and_set<mode>,\n+\tatomic_bit_test_and_complement<mode>,\n+\tatomic_bit_test_and_reset<mode>): New expanders.\n+\t(atomic_bit_test_and_set<mode>_1,\n+\tatomic_bit_test_and_complement<mode>_1,\n+\tatomic_bit_test_and_reset<mode>_1): New insns.\n+\n 2016-05-03  Richard Sandiford  <richard.sandiford@arm.com>\n \n \tPR rtl-optimization/70687"}, {"sha": "7d876199bcab8cca9f2e88dbd551b8fdb556c2e2", "filename": "gcc/builtins.c", "status": "modified", "additions": 84, "deletions": 0, "changes": 84, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -5310,6 +5310,90 @@ expand_builtin_atomic_fetch_op (machine_mode mode, tree exp, rtx target,\n   return ret;\n }\n \n+/* Expand IFN_ATOMIC_BIT_TEST_AND_* internal function.  */\n+\n+void\n+expand_ifn_atomic_bit_test_and (gcall *call)\n+{\n+  tree ptr = gimple_call_arg (call, 0);\n+  tree bit = gimple_call_arg (call, 1);\n+  tree flag = gimple_call_arg (call, 2);\n+  tree lhs = gimple_call_lhs (call);\n+  enum memmodel model = MEMMODEL_SYNC_SEQ_CST;\n+  machine_mode mode = TYPE_MODE (TREE_TYPE (flag));\n+  enum rtx_code code;\n+  optab optab;\n+  struct expand_operand ops[5];\n+\n+  gcc_assert (flag_inline_atomics);\n+\n+  if (gimple_call_num_args (call) == 4)\n+    model = get_memmodel (gimple_call_arg (call, 3));\n+\n+  rtx mem = get_builtin_sync_mem (ptr, mode);\n+  rtx val = expand_expr_force_mode (bit, mode);\n+\n+  switch (gimple_call_internal_fn (call))\n+    {\n+    case IFN_ATOMIC_BIT_TEST_AND_SET:\n+      code = IOR;\n+      optab = atomic_bit_test_and_set_optab;\n+      break;\n+    case IFN_ATOMIC_BIT_TEST_AND_COMPLEMENT:\n+      code = XOR;\n+      optab = atomic_bit_test_and_complement_optab;\n+      break;\n+    case IFN_ATOMIC_BIT_TEST_AND_RESET:\n+      code = AND;\n+      optab = atomic_bit_test_and_reset_optab;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  if (lhs == NULL_TREE)\n+    {\n+      val = expand_simple_binop (mode, ASHIFT, const1_rtx,\n+\t\t\t\t val, NULL_RTX, true, OPTAB_DIRECT);\n+      if (code == AND)\n+\tval = expand_simple_unop (mode, NOT, val, NULL_RTX, true);\n+      expand_atomic_fetch_op (const0_rtx, mem, val, code, model, false);\n+      return;\n+    }\n+\n+  rtx target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n+  enum insn_code icode = direct_optab_handler (optab, mode);\n+  gcc_assert (icode != CODE_FOR_nothing);\n+  create_output_operand (&ops[0], target, mode);\n+  create_fixed_operand (&ops[1], mem);\n+  create_convert_operand_to (&ops[2], val, mode, true);\n+  create_integer_operand (&ops[3], model);\n+  create_integer_operand (&ops[4], integer_onep (flag));\n+  if (maybe_expand_insn (icode, 5, ops))\n+    return;\n+\n+  rtx bitval = val;\n+  val = expand_simple_binop (mode, ASHIFT, const1_rtx,\n+\t\t\t     val, NULL_RTX, true, OPTAB_DIRECT);\n+  rtx maskval = val;\n+  if (code == AND)\n+    val = expand_simple_unop (mode, NOT, val, NULL_RTX, true);\n+  rtx result = expand_atomic_fetch_op (gen_reg_rtx (mode), mem, val,\n+\t\t\t\t       code, model, false);\n+  if (integer_onep (flag))\n+    {\n+      result = expand_simple_binop (mode, ASHIFTRT, result, bitval,\n+\t\t\t\t    NULL_RTX, true, OPTAB_DIRECT);\n+      result = expand_simple_binop (mode, AND, result, const1_rtx, target,\n+\t\t\t\t    true, OPTAB_DIRECT);\n+    }\n+  else\n+    result = expand_simple_binop (mode, AND, result, maskval, target, true,\n+\t\t\t\t  OPTAB_DIRECT);\n+  if (result != target)\n+    emit_move_insn (target, result);\n+}\n+\n /* Expand an atomic clear operation.\n \tvoid _atomic_clear (BOOL *obj, enum memmodel)\n    EXP is the call expression.  */"}, {"sha": "51e298cb76b666161e5c4532cf7357fcd048ca16", "filename": "gcc/builtins.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fbuiltins.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fbuiltins.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.h?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -71,6 +71,7 @@ extern tree std_fn_abi_va_list (tree);\n extern tree std_canonical_va_list_type (tree);\n extern void std_expand_builtin_va_start (tree, rtx);\n extern void expand_builtin_trap (void);\n+extern void expand_ifn_atomic_bit_test_and (gcall *);\n extern rtx expand_builtin (tree, rtx, rtx, machine_mode, int);\n extern rtx expand_builtin_with_bounds (tree, rtx, rtx, machine_mode, int);\n extern enum built_in_function builtin_mathfn_code (const_tree);"}, {"sha": "8322676a7b05e8856b621cb7e09ff9bf42c5332c", "filename": "gcc/config/i386/sync.md", "status": "modified", "additions": 111, "deletions": 0, "changes": 111, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fconfig%2Fi386%2Fsync.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fconfig%2Fi386%2Fsync.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsync.md?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -605,3 +605,114 @@\n    (clobber (reg:CC FLAGS_REG))]\n   \"\"\n   \"lock{%;} %K2<logic>{<imodesuffix>}\\t{%1, %0|%0, %1}\")\n+\n+(define_expand \"atomic_bit_test_and_set<mode>\"\n+  [(match_operand:SWI248 0 \"register_operand\")\n+   (match_operand:SWI248 1 \"memory_operand\")\n+   (match_operand:SWI248 2 \"nonmemory_operand\")\n+   (match_operand:SI 3 \"const_int_operand\") ;; model\n+   (match_operand:SI 4 \"const_int_operand\")]\n+  \"\"\n+{\n+  emit_insn (gen_atomic_bit_test_and_set<mode>_1 (operands[1], operands[2],\n+\t\t\t\t\t\t  operands[3]));\n+  rtx tem = gen_reg_rtx (QImode);\n+  ix86_expand_setcc (tem, EQ, gen_rtx_REG (CCCmode, FLAGS_REG), const0_rtx);\n+  rtx result = convert_modes (<MODE>mode, QImode, tem, 1);\n+  if (operands[4] == const0_rtx)\n+    result = expand_simple_binop (<MODE>mode, ASHIFT, result,\n+\t\t\t\t  operands[2], operands[0], 0, OPTAB_DIRECT);\n+  if (result != operands[0])\n+    emit_move_insn (operands[0], result);\n+  DONE;\n+})\n+\n+(define_insn \"atomic_bit_test_and_set<mode>_1\"\n+  [(set (reg:CCC FLAGS_REG)\n+\t(compare:CCC\n+\t  (unspec_volatile:SWI248\n+\t    [(match_operand:SWI248 0 \"memory_operand\" \"+m\")\n+\t     (match_operand:SI 2 \"const_int_operand\")]\t\t;; model\n+\t    UNSPECV_XCHG)\n+\t  (const_int 0)))\n+   (set (zero_extract:SWI248 (match_dup 0)\n+\t\t\t     (const_int 1)\n+\t\t\t     (match_operand:SWI248 1 \"nonmemory_operand\" \"rN\"))\n+\t(const_int 1))]\n+  \"\"\n+  \"lock{%;} %K2bts{<imodesuffix>}\\t{%1, %0|%0, %1}\")\n+\n+(define_expand \"atomic_bit_test_and_complement<mode>\"\n+  [(match_operand:SWI248 0 \"register_operand\")\n+   (match_operand:SWI248 1 \"memory_operand\")\n+   (match_operand:SWI248 2 \"nonmemory_operand\")\n+   (match_operand:SI 3 \"const_int_operand\") ;; model\n+   (match_operand:SI 4 \"const_int_operand\")]\n+  \"\"\n+{\n+  emit_insn (gen_atomic_bit_test_and_complement<mode>_1 (operands[1],\n+\t\t\t\t\t\t\t operands[2],\n+\t\t\t\t\t\t\t operands[3]));\n+  rtx tem = gen_reg_rtx (QImode);\n+  ix86_expand_setcc (tem, EQ, gen_rtx_REG (CCCmode, FLAGS_REG), const0_rtx);\n+  rtx result = convert_modes (<MODE>mode, QImode, tem, 1);\n+  if (operands[4] == const0_rtx)\n+    result = expand_simple_binop (<MODE>mode, ASHIFT, result,\n+\t\t\t\t  operands[2], operands[0], 0, OPTAB_DIRECT);\n+  if (result != operands[0])\n+    emit_move_insn (operands[0], result);\n+  DONE;\n+})\n+\n+(define_insn \"atomic_bit_test_and_complement<mode>_1\"\n+  [(set (reg:CCC FLAGS_REG)\n+\t(compare:CCC\n+\t  (unspec_volatile:SWI248\n+\t    [(match_operand:SWI248 0 \"memory_operand\" \"+m\")\n+\t     (match_operand:SI 2 \"const_int_operand\")]\t\t;; model\n+\t    UNSPECV_XCHG)\n+\t  (const_int 0)))\n+   (set (zero_extract:SWI248 (match_dup 0)\n+\t\t\t     (const_int 1)\n+\t\t\t     (match_operand:SWI248 1 \"nonmemory_operand\" \"rN\"))\n+\t(not:SWI248 (zero_extract:SWI248 (match_dup 0)\n+\t\t\t\t\t (const_int 1)\n+\t\t\t\t\t (match_dup 1))))]\n+  \"\"\n+  \"lock{%;} %K2btc{<imodesuffix>}\\t{%1, %0|%0, %1}\")\n+\n+(define_expand \"atomic_bit_test_and_reset<mode>\"\n+  [(match_operand:SWI248 0 \"register_operand\")\n+   (match_operand:SWI248 1 \"memory_operand\")\n+   (match_operand:SWI248 2 \"nonmemory_operand\")\n+   (match_operand:SI 3 \"const_int_operand\") ;; model\n+   (match_operand:SI 4 \"const_int_operand\")]\n+  \"\"\n+{\n+  emit_insn (gen_atomic_bit_test_and_reset<mode>_1 (operands[1], operands[2],\n+\t\t\t\t\t\t    operands[3]));\n+  rtx tem = gen_reg_rtx (QImode);\n+  ix86_expand_setcc (tem, EQ, gen_rtx_REG (CCCmode, FLAGS_REG), const0_rtx);\n+  rtx result = convert_modes (<MODE>mode, QImode, tem, 1);\n+  if (operands[4] == const0_rtx)\n+    result = expand_simple_binop (<MODE>mode, ASHIFT, result,\n+\t\t\t\t  operands[2], operands[0], 0, OPTAB_DIRECT);\n+  if (result != operands[0])\n+    emit_move_insn (operands[0], result);\n+  DONE;\n+})\n+\n+(define_insn \"atomic_bit_test_and_reset<mode>_1\"\n+  [(set (reg:CCC FLAGS_REG)\n+\t(compare:CCC\n+\t  (unspec_volatile:SWI248\n+\t    [(match_operand:SWI248 0 \"memory_operand\" \"+m\")\n+\t     (match_operand:SI 2 \"const_int_operand\")]\t\t;; model\n+\t    UNSPECV_XCHG)\n+\t  (const_int 0)))\n+   (set (zero_extract:SWI248 (match_dup 0)\n+\t\t\t     (const_int 1)\n+\t\t\t     (match_operand:SWI248 1 \"nonmemory_operand\" \"rN\"))\n+\t(const_int 0))]\n+  \"\"\n+  \"lock{%;} %K2btr{<imodesuffix>}\\t{%1, %0|%0, %1}\")"}, {"sha": "afaecef4e54f70d348175bda31c0797f6a21ada3", "filename": "gcc/doc/md.texi", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fdoc%2Fmd.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Fdoc%2Fmd.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fmd.texi?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -6909,6 +6909,33 @@ The specific value that defines \"set\" is implementation defined, and\n is normally based on what is performed by the native atomic test and set\n instruction.\n \n+@cindex @code{atomic_bit_test_and_set@var{mode}} instruction pattern\n+@cindex @code{atomic_bit_test_and_complement@var{mode}} instruction pattern\n+@cindex @code{atomic_bit_test_and_reset@var{mode}} instruction pattern\n+@item @samp{atomic_bit_test_and_set@var{mode}}\n+@itemx @samp{atomic_bit_test_and_complement@var{mode}}\n+@itemx @samp{atomic_bit_test_and_reset@var{mode}}\n+These patterns emit code for an atomic bitwise operation on memory with memory\n+model semantics, and return the original value of the specified bit.\n+Operand 0 is an output operand which contains the value of the specified bit\n+from the memory location before the operation was performed.  Operand 1 is the\n+memory on which the atomic operation is performed.  Operand 2 is the bit within\n+the operand, starting with least significant bit.  Operand 3 is the memory model\n+to be used by the operation.  Operand 4 is a flag - it is @code{const1_rtx}\n+if operand 0 should contain the original value of the specified bit in the\n+least significant bit of the operand, and @code{const0_rtx} if the bit should\n+be in its original position in the operand.\n+@code{atomic_bit_test_and_set@var{mode}} atomically sets the specified bit after\n+remembering its original value, @code{atomic_bit_test_and_complement@var{mode}}\n+inverts the specified bit and @code{atomic_bit_test_and_reset@var{mode}} clears\n+the specified bit.\n+\n+If these patterns are not defined, attempts will be made to use\n+@code{atomic_fetch_or@var{mode}}, @code{atomic_fetch_xor@var{mode}} or\n+@code{atomic_fetch_and@var{mode}} instruction patterns, or their @code{sync}\n+counterparts.  If none of these are available a compare-and-swap\n+loop will be used.\n+\n @cindex @code{mem_thread_fence@var{mode}} instruction pattern\n @item @samp{mem_thread_fence@var{mode}}\n This pattern emits code required to implement a thread fence with"}, {"sha": "c867ddc0ef7ddbe4841b00a1db1b49592db3f69b", "filename": "gcc/internal-fn.c", "status": "modified", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Finternal-fn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Finternal-fn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.c?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -39,6 +39,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"expr.h\"\n #include \"ubsan.h\"\n #include \"recog.h\"\n+#include \"builtins.h\"\n \n /* The names of each internal function, indexed by function number.  */\n const char *const internal_fn_name_array[] = {\n@@ -2118,6 +2119,30 @@ expand_SET_EDOM (internal_fn, gcall *)\n #endif\n }\n \n+/* Expand atomic bit test and set.  */\n+\n+static void\n+expand_ATOMIC_BIT_TEST_AND_SET (internal_fn, gcall *call)\n+{\n+  expand_ifn_atomic_bit_test_and (call);\n+}\n+\n+/* Expand atomic bit test and complement.  */\n+\n+static void\n+expand_ATOMIC_BIT_TEST_AND_COMPLEMENT (internal_fn, gcall *call)\n+{\n+  expand_ifn_atomic_bit_test_and (call);\n+}\n+\n+/* Expand atomic bit test and reset.  */\n+\n+static void\n+expand_ATOMIC_BIT_TEST_AND_RESET (internal_fn, gcall *call)\n+{\n+  expand_ifn_atomic_bit_test_and (call);\n+}\n+\n /* Expand a call to FN using the operands in STMT.  FN has a single\n    output operand and NARGS input operands.  */\n "}, {"sha": "e729d852a13f9cd58b27ab83e89840434289f6f9", "filename": "gcc/internal-fn.def", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Finternal-fn.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Finternal-fn.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.def?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -189,6 +189,11 @@ DEF_INTERNAL_FN (GOACC_REDUCTION, ECF_NOTHROW | ECF_LEAF, NULL)\n    current target.  */\n DEF_INTERNAL_FN (SET_EDOM, ECF_LEAF | ECF_NOTHROW, NULL)\n \n+/* Atomic functions.  */\n+DEF_INTERNAL_FN (ATOMIC_BIT_TEST_AND_SET, ECF_LEAF | ECF_NOTHROW, NULL)\n+DEF_INTERNAL_FN (ATOMIC_BIT_TEST_AND_COMPLEMENT, ECF_LEAF | ECF_NOTHROW, NULL)\n+DEF_INTERNAL_FN (ATOMIC_BIT_TEST_AND_RESET, ECF_LEAF | ECF_NOTHROW, NULL)\n+\n #undef DEF_INTERNAL_INT_FN\n #undef DEF_INTERNAL_FLT_FN\n #undef DEF_INTERNAL_OPTAB_FN"}, {"sha": "8875e30d4160c73c638575d6d5198b29a00ce6fd", "filename": "gcc/optabs.def", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Foptabs.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Foptabs.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.def?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -337,6 +337,9 @@ OPTAB_D (atomic_add_fetch_optab, \"atomic_add_fetch$I$a\")\n OPTAB_D (atomic_add_optab, \"atomic_add$I$a\")\n OPTAB_D (atomic_and_fetch_optab, \"atomic_and_fetch$I$a\")\n OPTAB_D (atomic_and_optab, \"atomic_and$I$a\")\n+OPTAB_D (atomic_bit_test_and_set_optab, \"atomic_bit_test_and_set$I$a\")\n+OPTAB_D (atomic_bit_test_and_complement_optab, \"atomic_bit_test_and_complement$I$a\")\n+OPTAB_D (atomic_bit_test_and_reset_optab, \"atomic_bit_test_and_reset$I$a\")\n OPTAB_D (atomic_compare_and_swap_optab, \"atomic_compare_and_swap$I$a\")\n OPTAB_D (atomic_exchange_optab,\t \"atomic_exchange$I$a\")\n OPTAB_D (atomic_fetch_add_optab, \"atomic_fetch_add$I$a\")"}, {"sha": "b29f76334fe6356c7d33599a5de02052f7933103", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -1,3 +1,9 @@\n+2016-05-03  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR target/49244\n+\t* gcc.target/i386/pr49244-1.c: New test.\n+\t* gcc.target/i386/pr49244-2.c: New test.\n+\n 2016-05-03  Bernd Schmidt  <bschmidt@redhat.com>\n \n \tPR rtl-optimization/44281"}, {"sha": "70ccf6e935a84e524de5bd0b3eabee5a3d6eb538", "filename": "gcc/testsuite/gcc.target/i386/pr49244-1.c", "status": "added", "additions": 188, "deletions": 0, "changes": 188, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr49244-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr49244-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr49244-1.c?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -0,0 +1,188 @@\n+/* PR target/49244 */\n+/* { dg-do compile } */\n+/* { dg-options \"-O2\" } */\n+\n+void bar (void);\n+\n+__attribute__((noinline, noclone)) int\n+f1 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  return (__sync_fetch_and_or (a, mask) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f2 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  unsigned int t1 = __atomic_fetch_or (a, mask, __ATOMIC_RELAXED);\n+  unsigned int t2 = t1 & mask;\n+  return t2 != 0;\n+}\n+\n+__attribute__((noinline, noclone)) long int\n+f3 (long int *a, int bit)\n+{\n+  unsigned long int mask = (1ul << bit);\n+  return (__atomic_fetch_or (a, mask, __ATOMIC_SEQ_CST) & mask) == 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f4 (int *a)\n+{\n+  unsigned int mask = (1u << 7);\n+  return (__sync_fetch_and_or (a, mask) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f5 (int *a)\n+{\n+  unsigned int mask = (1u << 13);\n+  return (__atomic_fetch_or (a, mask, __ATOMIC_RELAXED) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f6 (int *a)\n+{\n+  unsigned int mask = (1u << 0);\n+  return (__atomic_fetch_or (a, mask, __ATOMIC_SEQ_CST) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f7 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  if ((__sync_fetch_and_xor (a, mask) & mask) != 0)\n+    bar ();\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f8 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  if ((__atomic_fetch_xor (a, mask, __ATOMIC_RELAXED) & mask) == 0)\n+    bar ();\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f9 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  return (__atomic_fetch_xor (a, mask, __ATOMIC_SEQ_CST) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f10 (int *a)\n+{\n+  unsigned int mask = (1u << 7);\n+  return (__sync_fetch_and_xor (a, mask) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f11 (int *a)\n+{\n+  unsigned int mask = (1u << 13);\n+  return (__atomic_fetch_xor (a, mask, __ATOMIC_RELAXED) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f12 (int *a)\n+{\n+  unsigned int mask = (1u << 0);\n+  return (__atomic_fetch_xor (a, mask, __ATOMIC_SEQ_CST) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f13 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  return (__sync_fetch_and_and (a, ~mask) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f14 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  return (__atomic_fetch_and (a, ~mask, __ATOMIC_RELAXED) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f15 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  return (__atomic_fetch_and (a, ~mask, __ATOMIC_SEQ_CST) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f16 (int *a)\n+{\n+  unsigned int mask = (1u << 7);\n+  return (__sync_fetch_and_and (a, ~mask) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f17 (int *a)\n+{\n+  unsigned int mask = (1u << 13);\n+  return (__atomic_fetch_and (a, ~mask, __ATOMIC_RELAXED) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f18 (int *a)\n+{\n+  unsigned int mask = (1u << 0);\n+  return (__atomic_fetch_and (a, ~mask, __ATOMIC_SEQ_CST) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) unsigned long int\n+f19 (unsigned long int *a, int bit)\n+{\n+  unsigned long int mask = (1ul << bit);\n+  return (__atomic_xor_fetch (a, mask, __ATOMIC_SEQ_CST) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) unsigned long int\n+f20 (unsigned long int *a)\n+{\n+  unsigned long int mask = (1ul << 7);\n+  return (__atomic_xor_fetch (a, mask, __ATOMIC_SEQ_CST) & mask) == 0;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f21 (int *a, int bit)\n+{\n+  unsigned int mask = (1u << bit);\n+  return (__sync_fetch_and_or (a, mask) & mask);\n+}\n+\n+__attribute__((noinline, noclone)) unsigned long int\n+f22 (unsigned long int *a)\n+{\n+  unsigned long int mask = (1ul << 7);\n+  return (__atomic_xor_fetch (a, mask, __ATOMIC_SEQ_CST) & mask);\n+}\n+\n+__attribute__((noinline, noclone)) unsigned long int\n+f23 (unsigned long int *a)\n+{\n+  unsigned long int mask = (1ul << 7);\n+  return (__atomic_fetch_xor (a, mask, __ATOMIC_SEQ_CST) & mask);\n+}\n+\n+__attribute__((noinline, noclone)) unsigned short int\n+f24 (unsigned short int *a)\n+{\n+  unsigned short int mask = (1u << 7);\n+  return (__sync_fetch_and_or (a, mask) & mask) != 0;\n+}\n+\n+__attribute__((noinline, noclone)) unsigned short int\n+f25 (unsigned short int *a)\n+{\n+  unsigned short int mask = (1u << 7);\n+  return (__atomic_fetch_or (a, mask, __ATOMIC_SEQ_CST) & mask) != 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"lock;?\\[ \\t\\]*bts\" 9 } } */\n+/* { dg-final { scan-assembler-times \"lock;?\\[ \\t\\]*btc\" 10 } } */\n+/* { dg-final { scan-assembler-times \"lock;?\\[ \\t\\]*btr\" 6 } } */"}, {"sha": "847408e1a3f99638c1d9c43fbdf0e5c0d3cfe9e5", "filename": "gcc/testsuite/gcc.target/i386/pr49244-2.c", "status": "added", "additions": 108, "deletions": 0, "changes": 108, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr49244-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr49244-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fpr49244-2.c?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -0,0 +1,108 @@\n+/* PR target/49244 */\n+/* { dg-do run } */\n+/* { dg-options \"-O2 -g\" } */\n+\n+int cnt;\n+\n+__attribute__((noinline, noclone)) void\n+bar (void)\n+{\n+  cnt++;\n+}\n+\n+#include \"pr49244-1.c\"\n+\n+int a;\n+long int b;\n+unsigned long int c;\n+unsigned short int d;\n+\n+int\n+main ()\n+{\n+  __atomic_store_n (&a, 15, __ATOMIC_RELAXED);\n+  if (f1 (&a, 2) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 15\n+      || f1 (&a, 4) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 31)\n+    __builtin_abort ();\n+  if (f2 (&a, 1) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 31\n+      || f2 (&a, 5) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 63)\n+    __builtin_abort ();\n+  __atomic_store_n (&b, 24, __ATOMIC_RELAXED);\n+  if (f3 (&b, 2) != 1 || __atomic_load_n (&b, __ATOMIC_RELAXED) != 28\n+      || f3 (&b, 3) != 0 || __atomic_load_n (&b, __ATOMIC_RELAXED) != 28)\n+    __builtin_abort ();\n+  __atomic_store_n (&a, 0, __ATOMIC_RELAXED);\n+  if (f4 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 128\n+      || f4 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 128)\n+    __builtin_abort ();\n+  if (f5 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8320\n+      || f5 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8320)\n+    __builtin_abort ();\n+  if (f6 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321\n+      || f6 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321)\n+    __builtin_abort ();\n+  if (cnt != 0\n+      || (f7 (&a, 7), cnt) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8193\n+      || (f7 (&a, 7), cnt) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321)\n+    __builtin_abort ();\n+  if ((f8 (&a, 7), cnt) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8193\n+      || (f8 (&a, 7), cnt) != 2 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321)\n+    __builtin_abort ();\n+  if (f9 (&a, 13) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 129\n+      || f9 (&a, 13) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321)\n+    __builtin_abort ();\n+  if (f10 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8193\n+      || f10 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321)\n+    __builtin_abort ();\n+  if (f11 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 129\n+      || f11 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321)\n+    __builtin_abort ();\n+  if (f12 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8320\n+      || f12 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8321)\n+    __builtin_abort ();\n+  if (f13 (&a, 7) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8193\n+      || f13 (&a, 7) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8193)\n+    __builtin_abort ();\n+  if (f14 (&a, 13) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 1\n+      || f14 (&a, 13) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 1)\n+    __builtin_abort ();\n+  if (f15 (&a, 0) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 0\n+      || f15 (&a, 0) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 0)\n+    __builtin_abort ();\n+  __atomic_store_n (&a, 8321, __ATOMIC_RELAXED);\n+  if (f16 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8193\n+      || f16 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 8193)\n+    __builtin_abort ();\n+  if (f17 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 1\n+      || f17 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 1)\n+    __builtin_abort ();\n+  if (f18 (&a) != 1 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 0\n+      || f18 (&a) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 0)\n+    __builtin_abort ();\n+  if (f19 (&c, 7) != 1 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 128\n+      || f19 (&c, 7) != 0 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 0)\n+    __builtin_abort ();\n+  if (f20 (&c) != 0 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 128\n+      || f20 (&c) != 1 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 0)\n+    __builtin_abort ();\n+  __atomic_store_n (&a, 128, __ATOMIC_RELAXED);\n+  if (f21 (&a, 4) != 0 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 144\n+      || f21 (&a, 4) != 16 || __atomic_load_n (&a, __ATOMIC_RELAXED) != 144)\n+    __builtin_abort ();\n+  __atomic_store_n (&c, 1, __ATOMIC_RELAXED);\n+  if (f22 (&c) != 128 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 129\n+      || f22 (&c) != 0 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 1)\n+    __builtin_abort ();\n+  if (f23 (&c) != 0 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 129\n+      || f23 (&c) != 128 || __atomic_load_n (&c, __ATOMIC_RELAXED) != 1)\n+    __builtin_abort ();\n+  if (f24 (&d) != 0 || __atomic_load_n (&d, __ATOMIC_RELAXED) != 128\n+      || f24 (&d) != 1 || __atomic_load_n (&d, __ATOMIC_RELAXED) != 128)\n+    __builtin_abort ();\n+  __atomic_store_n (&d, 1, __ATOMIC_RELAXED);\n+  if (f25 (&d) != 0 || __atomic_load_n (&d, __ATOMIC_RELAXED) != 129\n+      || f25 (&d) != 1 || __atomic_load_n (&d, __ATOMIC_RELAXED) != 129\n+      || cnt != 2)\n+    __builtin_abort ();\n+  return 0;\n+}"}, {"sha": "c4e27f1cfe94bc86cd5e00461cdff10d4d8d9cda", "filename": "gcc/tree-ssa-ccp.c", "status": "modified", "additions": 292, "deletions": 0, "changes": 292, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftree-ssa-ccp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/adedd5c173388ae505470df152b9cb3947339566/gcc%2Ftree-ssa-ccp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ccp.c?ref=adedd5c173388ae505470df152b9cb3947339566", "patch": "@@ -140,6 +140,8 @@ along with GCC; see the file COPYING3.  If not see\n #include \"builtins.h\"\n #include \"tree-chkp.h\"\n #include \"cfgloop.h\"\n+#include \"stor-layout.h\"\n+#include \"optabs-query.h\"\n \n \n /* Possible lattice values.  */\n@@ -2697,6 +2699,224 @@ optimize_unreachable (gimple_stmt_iterator i)\n   return ret;\n }\n \n+/* Optimize\n+     mask_2 = 1 << cnt_1;\n+     _4 = __atomic_fetch_or_* (ptr_6, mask_2, _3);\n+     _5 = _4 & mask_2;\n+   to\n+     _4 = ATOMIC_BIT_TEST_AND_SET (ptr_6, cnt_1, 0, _3);\n+     _5 = _4;\n+   If _5 is only used in _5 != 0 or _5 == 0 comparisons, 1\n+   is passed instead of 0, and the builtin just returns a zero\n+   or 1 value instead of the actual bit.\n+   Similarly for __sync_fetch_and_or_* (without the \", _3\" part\n+   in there), and/or if mask_2 is a power of 2 constant.\n+   Similarly for xor instead of or, use ATOMIC_BIT_TEST_AND_COMPLEMENT\n+   in that case.  And similarly for and instead of or, except that\n+   the second argument to the builtin needs to be one's complement\n+   of the mask instead of mask.  */\n+\n+static void\n+optimize_atomic_bit_test_and (gimple_stmt_iterator *gsip,\n+\t\t\t      enum internal_fn fn, bool has_model_arg,\n+\t\t\t      bool after)\n+{\n+  gimple *call = gsi_stmt (*gsip);\n+  tree lhs = gimple_call_lhs (call);\n+  use_operand_p use_p;\n+  gimple *use_stmt;\n+  tree mask, bit;\n+  optab optab;\n+\n+  if (!flag_inline_atomics\n+      || optimize_debug\n+      || !gimple_call_builtin_p (call, BUILT_IN_NORMAL)\n+      || !lhs\n+      || SSA_NAME_OCCURS_IN_ABNORMAL_PHI (lhs)\n+      || !single_imm_use (lhs, &use_p, &use_stmt)\n+      || !is_gimple_assign (use_stmt)\n+      || gimple_assign_rhs_code (use_stmt) != BIT_AND_EXPR\n+      || !gimple_vdef (call))\n+    return;\n+\n+  switch (fn)\n+    {\n+    case IFN_ATOMIC_BIT_TEST_AND_SET:\n+      optab = atomic_bit_test_and_set_optab;\n+      break;\n+    case IFN_ATOMIC_BIT_TEST_AND_COMPLEMENT:\n+      optab = atomic_bit_test_and_complement_optab;\n+      break;\n+    case IFN_ATOMIC_BIT_TEST_AND_RESET:\n+      optab = atomic_bit_test_and_reset_optab;\n+      break;\n+    default:\n+      return;\n+    }\n+\n+  if (optab_handler (optab, TYPE_MODE (TREE_TYPE (lhs))) == CODE_FOR_nothing)\n+    return;\n+\n+  mask = gimple_call_arg (call, 1);\n+  tree use_lhs = gimple_assign_lhs (use_stmt);\n+  if (!use_lhs)\n+    return;\n+\n+  if (TREE_CODE (mask) == INTEGER_CST)\n+    {\n+      if (fn == IFN_ATOMIC_BIT_TEST_AND_RESET)\n+\tmask = const_unop (BIT_NOT_EXPR, TREE_TYPE (mask), mask);\n+      mask = fold_convert (TREE_TYPE (lhs), mask);\n+      int ibit = tree_log2 (mask);\n+      if (ibit < 0)\n+\treturn;\n+      bit = build_int_cst (TREE_TYPE (lhs), ibit);\n+    }\n+  else if (TREE_CODE (mask) == SSA_NAME)\n+    {\n+      gimple *g = SSA_NAME_DEF_STMT (mask);\n+      if (fn == IFN_ATOMIC_BIT_TEST_AND_RESET)\n+\t{\n+\t  if (!is_gimple_assign (g)\n+\t      || gimple_assign_rhs_code (g) != BIT_NOT_EXPR)\n+\t    return;\n+\t  mask = gimple_assign_rhs1 (g);\n+\t  if (TREE_CODE (mask) != SSA_NAME)\n+\t    return;\n+\t  g = SSA_NAME_DEF_STMT (mask);\n+\t}\n+      if (!is_gimple_assign (g)\n+\t  || gimple_assign_rhs_code (g) != LSHIFT_EXPR\n+\t  || !integer_onep (gimple_assign_rhs1 (g)))\n+\treturn;\n+      bit = gimple_assign_rhs2 (g);\n+    }\n+  else\n+    return;\n+\n+  if (gimple_assign_rhs1 (use_stmt) == lhs)\n+    {\n+      if (!operand_equal_p (gimple_assign_rhs2 (use_stmt), mask, 0))\n+\treturn;\n+    }\n+  else if (gimple_assign_rhs2 (use_stmt) != lhs\n+\t   || !operand_equal_p (gimple_assign_rhs1 (use_stmt), mask, 0))\n+    return;\n+\n+  bool use_bool = true;\n+  bool has_debug_uses = false;\n+  imm_use_iterator iter;\n+  gimple *g;\n+\n+  if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (use_lhs))\n+    use_bool = false;\n+  FOR_EACH_IMM_USE_STMT (g, iter, use_lhs)\n+    {\n+      enum tree_code code = ERROR_MARK;\n+      tree op0, op1;\n+      if (is_gimple_debug (g))\n+\t{\n+\t  has_debug_uses = true;\n+\t  continue;\n+\t}\n+      else if (is_gimple_assign (g))\n+\tswitch (gimple_assign_rhs_code (g))\n+\t  {\n+\t  case COND_EXPR:\n+\t    op1 = gimple_assign_rhs1 (g);\n+\t    code = TREE_CODE (op1);\n+\t    op0 = TREE_OPERAND (op1, 0);\n+\t    op1 = TREE_OPERAND (op1, 1);\n+\t    break;\n+\t  case EQ_EXPR:\n+\t  case NE_EXPR:\n+\t    code = gimple_assign_rhs_code (g);\n+\t    op0 = gimple_assign_rhs1 (g);\n+\t    op1 = gimple_assign_rhs2 (g);\n+\t    break;\n+\t  default:\n+\t    break;\n+\t  }\n+      else if (gimple_code (g) == GIMPLE_COND)\n+\t{\n+\t  code = gimple_cond_code (g);\n+\t  op0 = gimple_cond_lhs (g);\n+\t  op1 = gimple_cond_rhs (g);\n+\t}\n+\n+      if ((code == EQ_EXPR || code == NE_EXPR)\n+\t  && op0 == use_lhs\n+\t  && integer_zerop (op1))\n+\t{\n+\t  use_operand_p use_p;\n+\t  int n = 0;\n+\t  FOR_EACH_IMM_USE_ON_STMT (use_p, iter)\n+\t    n++;\n+\t  if (n == 1)\n+\t    continue;\n+\t}\n+\n+      use_bool = false;\n+      BREAK_FROM_IMM_USE_STMT (iter);\n+    }\n+\n+  tree new_lhs = make_ssa_name (TREE_TYPE (lhs));\n+  tree flag = build_int_cst (TREE_TYPE (lhs), use_bool);\n+  if (has_model_arg)\n+    g = gimple_build_call_internal (fn, 4, gimple_call_arg (call, 0),\n+\t\t\t\t    bit, flag, gimple_call_arg (call, 2));\n+  else\n+    g = gimple_build_call_internal (fn, 3, gimple_call_arg (call, 0),\n+\t\t\t\t    bit, flag);\n+  gimple_call_set_lhs (g, new_lhs);\n+  gimple_set_location (g, gimple_location (call));\n+  gimple_set_vuse (g, gimple_vuse (call));\n+  gimple_set_vdef (g, gimple_vdef (call));\n+  SSA_NAME_DEF_STMT (gimple_vdef (call)) = g;\n+  gimple_stmt_iterator gsi = *gsip;\n+  gsi_insert_after (&gsi, g, GSI_NEW_STMT);\n+  if (after)\n+    {\n+      /* The internal function returns the value of the specified bit\n+\t before the atomic operation.  If we are interested in the value\n+\t of the specified bit after the atomic operation (makes only sense\n+\t for xor, otherwise the bit content is compile time known),\n+\t we need to invert the bit.  */\n+      g = gimple_build_assign (make_ssa_name (TREE_TYPE (lhs)),\n+\t\t\t       BIT_XOR_EXPR, new_lhs,\n+\t\t\t       use_bool ? build_int_cst (TREE_TYPE (lhs), 1)\n+\t\t\t\t\t: mask);\n+      new_lhs = gimple_assign_lhs (g);\n+      gsi_insert_after (&gsi, g, GSI_NEW_STMT);\n+    }\n+  if (use_bool && has_debug_uses)\n+    {\n+      tree temp = make_node (DEBUG_EXPR_DECL);\n+      DECL_ARTIFICIAL (temp) = 1;\n+      TREE_TYPE (temp) = TREE_TYPE (lhs);\n+      DECL_MODE (temp) = TYPE_MODE (TREE_TYPE (lhs));\n+      tree t = build2 (LSHIFT_EXPR, TREE_TYPE (lhs), new_lhs, bit);\n+      g = gimple_build_debug_bind (temp, t, g);\n+      gsi_insert_after (&gsi, g, GSI_NEW_STMT);\n+      FOR_EACH_IMM_USE_STMT (g, iter, use_lhs)\n+\tif (is_gimple_debug (g))\n+\t  {\n+\t    use_operand_p use_p;\n+\t    FOR_EACH_IMM_USE_ON_STMT (use_p, iter)\n+\t      SET_USE (use_p, temp);\n+\t    update_stmt (g);\n+\t  }\n+    }\n+  SSA_NAME_OCCURS_IN_ABNORMAL_PHI (new_lhs)\n+    = SSA_NAME_OCCURS_IN_ABNORMAL_PHI (use_lhs);\n+  replace_uses_by (use_lhs, new_lhs);\n+  gsi = gsi_for_stmt (use_stmt);\n+  gsi_remove (&gsi, true);\n+  release_defs (use_stmt);\n+  gsi_remove (gsip, true);\n+  release_ssa_name (lhs);\n+}\n+\n /* A simple pass that attempts to fold all builtin functions.  This pass\n    is run after we've propagated as many constants as we can.  */\n \n@@ -2806,6 +3026,78 @@ pass_fold_builtins::execute (function *fun)\n \t\t    cfg_changed = true;\n \t\t  break;\n \n+\t\tcase BUILT_IN_ATOMIC_FETCH_OR_1:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_OR_2:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_OR_4:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_OR_8:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_OR_16:\n+\t\t  optimize_atomic_bit_test_and (&i,\n+\t\t\t\t\t\tIFN_ATOMIC_BIT_TEST_AND_SET,\n+\t\t\t\t\t\ttrue, false);\n+\t\t  break;\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_OR_1:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_OR_2:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_OR_4:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_OR_8:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_OR_16:\n+\t\t  optimize_atomic_bit_test_and (&i,\n+\t\t\t\t\t\tIFN_ATOMIC_BIT_TEST_AND_SET,\n+\t\t\t\t\t\tfalse, false);\n+\t\t  break;\n+\n+\t\tcase BUILT_IN_ATOMIC_FETCH_XOR_1:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_XOR_2:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_XOR_4:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_XOR_8:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_XOR_16:\n+\t\t  optimize_atomic_bit_test_and\n+\t\t\t(&i, IFN_ATOMIC_BIT_TEST_AND_COMPLEMENT, true, false);\n+\t\t  break;\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_XOR_1:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_XOR_2:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_XOR_4:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_XOR_8:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_XOR_16:\n+\t\t  optimize_atomic_bit_test_and\n+\t\t\t(&i, IFN_ATOMIC_BIT_TEST_AND_COMPLEMENT, false, false);\n+\t\t  break;\n+\n+\t\tcase BUILT_IN_ATOMIC_XOR_FETCH_1:\n+\t\tcase BUILT_IN_ATOMIC_XOR_FETCH_2:\n+\t\tcase BUILT_IN_ATOMIC_XOR_FETCH_4:\n+\t\tcase BUILT_IN_ATOMIC_XOR_FETCH_8:\n+\t\tcase BUILT_IN_ATOMIC_XOR_FETCH_16:\n+\t\t  optimize_atomic_bit_test_and\n+\t\t\t(&i, IFN_ATOMIC_BIT_TEST_AND_COMPLEMENT, true, true);\n+\t\t  break;\n+\t\tcase BUILT_IN_SYNC_XOR_AND_FETCH_1:\n+\t\tcase BUILT_IN_SYNC_XOR_AND_FETCH_2:\n+\t\tcase BUILT_IN_SYNC_XOR_AND_FETCH_4:\n+\t\tcase BUILT_IN_SYNC_XOR_AND_FETCH_8:\n+\t\tcase BUILT_IN_SYNC_XOR_AND_FETCH_16:\n+\t\t  optimize_atomic_bit_test_and\n+\t\t\t(&i, IFN_ATOMIC_BIT_TEST_AND_COMPLEMENT, false, true);\n+\t\t  break;\n+\n+\t\tcase BUILT_IN_ATOMIC_FETCH_AND_1:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_AND_2:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_AND_4:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_AND_8:\n+\t\tcase BUILT_IN_ATOMIC_FETCH_AND_16:\n+\t\t  optimize_atomic_bit_test_and (&i,\n+\t\t\t\t\t\tIFN_ATOMIC_BIT_TEST_AND_RESET,\n+\t\t\t\t\t\ttrue, false);\n+\t\t  break;\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_AND_1:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_AND_2:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_AND_4:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_AND_8:\n+\t\tcase BUILT_IN_SYNC_FETCH_AND_AND_16:\n+\t\t  optimize_atomic_bit_test_and (&i,\n+\t\t\t\t\t\tIFN_ATOMIC_BIT_TEST_AND_RESET,\n+\t\t\t\t\t\tfalse, false);\n+\t\t  break;\n+\n \t\tcase BUILT_IN_VA_START:\n \t\tcase BUILT_IN_VA_END:\n \t\tcase BUILT_IN_VA_COPY:"}]}