{"sha": "e87b4f3f4efbc1a4459a980e2c71f74e678e59c8", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTg3YjRmM2Y0ZWZiYzFhNDQ1OWE5ODBlMmM3MWY3NGU2NzhlNTljOA==", "commit": {"author": {"name": "Richard Stallman", "email": "rms@gnu.org", "date": "1992-03-16T22:53:41Z"}, "committer": {"name": "Richard Stallman", "email": "rms@gnu.org", "date": "1992-03-16T22:53:41Z"}, "message": "*** empty log message ***\n\nFrom-SVN: r507", "tree": {"sha": "85e80c4a97d8b56f8ca3edb23cccb0f97e1d739a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/85e80c4a97d8b56f8ca3edb23cccb0f97e1d739a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e87b4f3f4efbc1a4459a980e2c71f74e678e59c8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e87b4f3f4efbc1a4459a980e2c71f74e678e59c8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e87b4f3f4efbc1a4459a980e2c71f74e678e59c8", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e87b4f3f4efbc1a4459a980e2c71f74e678e59c8/comments", "author": null, "committer": null, "parents": [{"sha": "d519620311fffb146aed972b13c1859e218dc96f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d519620311fffb146aed972b13c1859e218dc96f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d519620311fffb146aed972b13c1859e218dc96f"}], "stats": {"total": 170, "additions": 124, "deletions": 46}, "files": [{"sha": "1e2ccfbbe3739abb793d474fa0568ed51358a877", "filename": "gcc/expr.c", "status": "modified", "additions": 124, "deletions": 46, "changes": 170, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e87b4f3f4efbc1a4459a980e2c71f74e678e59c8/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e87b4f3f4efbc1a4459a980e2c71f74e678e59c8/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=e87b4f3f4efbc1a4459a980e2c71f74e678e59c8", "patch": "@@ -114,6 +114,12 @@ static void do_jump_by_parts_greater ();\n #define MOVE_RATIO 15\n #endif\n #endif\n+\n+/* SLOW_UNALIGNED_ACCESS is non-zero if unaligned accesses are very slow. */\n+\n+#ifndef SLOW_UNALIGNED_ACCESS\n+#define SLOW_UNALIGNED_ACCESS 0\n+#endif\n \f\n /* This is run at the start of compiling a function.  */\n \n@@ -126,6 +132,7 @@ init_expr ()\n   inhibit_defer_pop = 0;\n   cleanups_this_call = 0;\n   saveregs_value = 0;\n+  forced_labels = 0;\n }\n \n /* Save all variables describing the current status into the structure *P.\n@@ -142,11 +149,13 @@ save_expr_status (p)\n   p->inhibit_defer_pop = inhibit_defer_pop;\n   p->cleanups_this_call = cleanups_this_call;\n   p->saveregs_value = saveregs_value;\n+  p->forced_labels = forced_labels;\n \n   pending_stack_adjust = 0;\n   inhibit_defer_pop = 0;\n   cleanups_this_call = 0;\n   saveregs_value = 0;\n+  forced_labels = 0;\n }\n \n /* Restore all variables describing the current status from the structure *P.\n@@ -160,6 +169,7 @@ restore_expr_status (p)\n   inhibit_defer_pop = p->inhibit_defer_pop;\n   cleanups_this_call = p->cleanups_this_call;\n   saveregs_value = p->saveregs_value;\n+  forced_labels = p->forced_labels;\n }\n \f\n /* Manage the queue of increment instructions to be output\n@@ -390,7 +400,7 @@ convert_move (to, from, unsignedp)\n \t   library calls.  */\n \tabort ();\n \n-      emit_library_call (libcall, 0, to_mode, 1, from, from_mode);\n+      emit_library_call (libcall, 1, to_mode, 1, from, from_mode);\n       emit_move_insn (to, hard_libcall_value (to_mode));\n       return;\n     }\n@@ -753,7 +763,7 @@ move_by_pieces (to, from, len, align)\n {\n   struct move_by_pieces data;\n   rtx to_addr = XEXP (to, 0), from_addr = XEXP (from, 0);\n-  int max_size = 10000;\n+  int max_size = MOVE_MAX + 1;\n \n   data.offset = 0;\n   data.to_addr = to_addr;\n@@ -819,12 +829,9 @@ move_by_pieces (to, from, len, align)\n \tdata.to_addr = copy_addr_to_reg (to_addr);\n     }\n \n-#if defined (STRICT_ALIGNMENT) || defined (SLOW_UNALIGNED_ACCESS)\n-  if (align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n+  if (! (STRICT_ALIGNMENT || SLOW_UNALIGNED_ACCESS)\n+      || align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n     align = MOVE_MAX;\n-#else\n-  align = MOVE_MAX;\n-#endif\n \n   /* First move what we can in the largest integer mode, then go to\n      successively smaller modes.  */\n@@ -866,14 +873,11 @@ move_by_pieces_ninsns (l, align)\n      int align;\n {\n   register int n_insns = 0;\n-  int max_size = 10000;\n+  int max_size = MOVE_MAX + 1;\n \n-#if defined (STRICT_ALIGNMENT) || defined (SLOW_UNALIGNED_ACCESS)\n-  if (align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n+  if (! (STRICT_ALIGNMENT || SLOW_UNALIGNED_ACCESS)\n+      || align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n     align = MOVE_MAX;\n-#else\n-  align = MOVE_MAX;\n-#endif\n \n   while (max_size > 1)\n     {\n@@ -930,11 +934,11 @@ move_by_pieces_1 (genfun, mode, data)\n \n #ifdef HAVE_PRE_DECREMENT\n       if (data->explicit_inc_to < 0)\n-\temit_insn (gen_sub2_insn (data->to_addr,\n-\t\t\t\t  gen_rtx (CONST_INT, VOIDmode, size)));\n+\temit_insn (gen_add2_insn (data->to_addr,\n+\t\t\t\t  gen_rtx (CONST_INT, VOIDmode, -size)));\n       if (data->explicit_inc_from < 0)\n-\temit_insn (gen_sub2_insn (data->from_addr,\n-\t\t\t\t  gen_rtx (CONST_INT, VOIDmode, size)));\n+\temit_insn (gen_add2_insn (data->from_addr,\n+\t\t\t\t  gen_rtx (CONST_INT, VOIDmode, -size)));\n #endif\n \n       emit_insn ((*genfun) (to1, from1));\n@@ -1050,12 +1054,12 @@ emit_block_move (x, y, size, align)\n #endif\n \n #ifdef TARGET_MEM_FUNCTIONS\n-      emit_library_call (memcpy_libfunc, 0,\n+      emit_library_call (memcpy_libfunc, 1,\n \t\t\t VOIDmode, 3, XEXP (x, 0), Pmode,\n \t\t\t XEXP (y, 0), Pmode,\n \t\t\t size, Pmode);\n #else\n-      emit_library_call (bcopy_libfunc, 0,\n+      emit_library_call (bcopy_libfunc, 1,\n \t\t\t VOIDmode, 3, XEXP (y, 0), Pmode,\n \t\t\t XEXP (x, 0), Pmode,\n \t\t\t size, Pmode);\n@@ -1159,12 +1163,12 @@ clear_storage (object, size)\n   if (GET_MODE (object) == BLKmode)\n     {\n #ifdef TARGET_MEM_FUNCTIONS\n-      emit_library_call (memset_libfunc, 0,\n+      emit_library_call (memset_libfunc, 1,\n \t\t\t VOIDmode, 3,\n \t\t\t XEXP (object, 0), Pmode, const0_rtx, Pmode,\n \t\t\t gen_rtx (CONST_INT, VOIDmode, size), Pmode);\n #else\n-      emit_library_call (bzero_libfunc, 0,\n+      emit_library_call (bzero_libfunc, 1,\n \t\t\t VOIDmode, 2,\n \t\t\t XEXP (object, 0), Pmode,\n \t\t\t gen_rtx (CONST_INT, VOIDmode, size), Pmode);\n@@ -1411,13 +1415,12 @@ emit_push_insn (x, mode, type, size, align, partial, reg, extra,\n \t  && skip == 0\n \t  && (move_by_pieces_ninsns ((unsigned) INTVAL (size) - used, align)\n \t      < MOVE_RATIO)\n-#if defined (STRICT_ALIGNMENT) || defined (SLOW_UNALIGNED_ACCESS)\n \t  /* Here we avoid the case of a structure whose weak alignment\n \t     forces many pushes of a small amount of data,\n \t     and such small pushes do rounding that causes trouble.  */\n-\t  && (align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT\n+\t  && ((! STRICT_ALIGNMENT && ! SLOW_UNALIGNED_ACCESS)\n+\t      || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT\n \t      || PUSH_ROUNDING (align) == align)\n-#endif\n \t  && PUSH_ROUNDING (INTVAL (size)) == INTVAL (size))\n \t{\n \t  /* Push padding now if padding above and stack grows down,\n@@ -1534,11 +1537,11 @@ emit_push_insn (x, mode, type, size, align, partial, reg, extra,\n \t     to force it to pop the bcopy-arguments right away.  */\n \t  NO_DEFER_POP;\n #ifdef TARGET_MEM_FUNCTIONS\n-\t  emit_library_call (memcpy_libfunc, 0,\n+\t  emit_library_call (memcpy_libfunc, 1,\n \t\t\t     VOIDmode, 3, temp, Pmode, XEXP (xinner, 0), Pmode,\n \t\t\t     size, Pmode);\n #else\n-\t  emit_library_call (bcopy_libfunc, 0,\n+\t  emit_library_call (bcopy_libfunc, 1,\n \t\t\t     VOIDmode, 3, XEXP (xinner, 0), Pmode, temp, Pmode,\n \t\t\t     size, Pmode);\n #endif\n@@ -1974,12 +1977,12 @@ expand_assignment (to, from, want_value, suggest_reg)\n       rtx size = expr_size (from);\n \n #ifdef TARGET_MEM_FUNCTIONS\n-      emit_library_call (memcpy_libfunc, 0,\n+      emit_library_call (memcpy_libfunc, 1,\n \t\t\t VOIDmode, 3, XEXP (to_rtx, 0), Pmode,\n \t\t\t XEXP (from_rtx, 0), Pmode,\n \t\t\t size, Pmode);\n #else\n-      emit_library_call (bcopy_libfunc, 0,\n+      emit_library_call (bcopy_libfunc, 1,\n \t\t\t VOIDmode, 3, XEXP (from_rtx, 0), Pmode,\n \t\t\t XEXP (to_rtx, 0), Pmode,\n \t\t\t size, Pmode);\n@@ -2120,22 +2123,68 @@ store_expr (exp, target, suggest_reg)\n \t     So copy just the string's actual length, and clear the rest.  */\n \t  rtx size;\n \n-\t  emit_block_move (target, temp,\n-\t\t\t   gen_rtx (CONST_INT, VOIDmode,\n-\t\t\t\t    TREE_STRING_LENGTH (exp)),\n-\t\t\t   TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n-\n-\t  temp = plus_constant (XEXP (target, 0), TREE_STRING_LENGTH (exp));\n-\t  size = plus_constant (expr_size (exp), - TREE_STRING_LENGTH (exp));\n-\t  if (size != const0_rtx)\n+\t  /* Get the size of the data type of the string,\n+\t     which is actually the size of the target.  */\n+\t  size = expr_size (exp);\n+\t  if (GET_CODE (size) == CONST_INT\n+\t      && INTVAL (size) < TREE_STRING_LENGTH (exp))\n+\t    emit_block_move (target, temp, size,\n+\t\t\t     TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n+\t  else\n \t    {\n+\t      /* Compute the size of the data to copy from the string.  */\n+\t      tree copy_size\n+\t\t= fold (build (MIN_EXPR, sizetype,\n+\t\t\t       size_binop (CEIL_DIV_EXPR,\n+\t\t\t\t\t   TYPE_SIZE (TREE_TYPE (exp)),\n+\t\t\t\t\t   size_int (BITS_PER_UNIT)),\n+\t\t\t       convert (sizetype,\n+\t\t\t\t\tbuild_int_2 (TREE_STRING_LENGTH (exp), 0))));\n+\t      rtx copy_size_rtx = expand_expr (copy_size, 0, VOIDmode, 0);\n+\t      rtx label = 0;\n+\n+\t      /* Copy that much.  */\n+\t      emit_block_move (target, temp, copy_size_rtx,\n+\t\t\t       TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n+\n+\t      /* Figure out how much is left in TARGET\n+\t\t that we have to clear.  */\n+\t      if (GET_CODE (copy_size_rtx) == CONST_INT)\n+\t\t{\n+\t\t  temp = plus_constant (XEXP (target, 0),\n+\t\t\t\t\tTREE_STRING_LENGTH (exp));\n+\t\t  size = plus_constant (size,\n+\t\t\t\t\t- TREE_STRING_LENGTH (exp));\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  enum machine_mode size_mode = Pmode;\n+\n+\t\t  temp = force_reg (Pmode, XEXP (target, 0));\n+\t\t  temp = expand_binop (size_mode, add_optab, temp,\n+\t\t\t\t       copy_size_rtx, 0, 0, OPTAB_LIB_WIDEN);\n+\n+\t\t  size = expand_binop (size_mode, sub_optab, size,\n+\t\t\t\t       copy_size_rtx, 0, 0, OPTAB_LIB_WIDEN);\n+\n+\t\t  emit_cmp_insn (size, const0_rtx, LT, 0,\n+\t\t\t\t GET_MODE (size), 0, 0);\n+\t\t  label = gen_label_rtx ();\n+\t\t  emit_jump_insn (gen_blt (label));\n+\t\t}\n+\n+\t      if (size != const0_rtx)\n+\t\t{\n #ifdef TARGET_MEM_FUNCTIONS\n-\t      emit_library_call (memset_libfunc, 0, VOIDmode, 3,\n-\t\t\t\t temp, Pmode, const0_rtx, Pmode, size, Pmode);\n+\t\t  emit_library_call (memset_libfunc, 1, VOIDmode, 3,\n+\t\t\t\t     temp, Pmode, const0_rtx, Pmode, size, Pmode);\n #else\n-\t      emit_library_call (bzero_libfunc, 0, VOIDmode, 2,\n-\t\t\t\t temp, Pmode, size, Pmode);\n+\t\t  emit_library_call (bzero_libfunc, 1, VOIDmode, 2,\n+\t\t\t\t     temp, Pmode, size, Pmode);\n #endif\n+\t\t}\n+\t      if (label)\n+\t\temit_label (label);\n \t    }\n \t}\n       else if (GET_MODE (temp) == BLKmode)\n@@ -4424,8 +4473,8 @@ expand_expr (exp, target, tmode, modifier)\n   return temp;\n }\n \f\n-/* Return the alignment of EXP, a pointer valued expression for the mem*\n-   builtin functions.  Alignments greater than MAX_ALIGN are not significant.\n+/* Return the alignment in bits of EXP, a pointer valued expression.\n+   But don't return more than MAX_ALIGN no matter what.\n    The alignment returned is, by default, the alignment of the thing that\n    EXP points to (if it is not a POINTER_TYPE, 0 is returned).\n \n@@ -4467,8 +4516,9 @@ get_pointer_alignment (exp, max_align)\n \t  if (TREE_CODE (TREE_OPERAND (exp, 1)) != INTEGER_CST)\n \t    return align;\n \n-\t  while ((TREE_INT_CST_LOW (TREE_OPERAND (exp, 1))\n-\t\t  & (max_align - 1)) != 0)\n+\t  while (((TREE_INT_CST_LOW (TREE_OPERAND (exp, 1)) * BITS_PER_UNIT)\n+\t\t  & (max_align - 1))\n+\t\t != 0)\n \t    max_align >>= 1;\n \n \t  exp = TREE_OPERAND (exp, 0);\n@@ -4625,6 +4675,27 @@ expand_builtin (exp, target, subtarget, mode, ignore)\n       /* build_function_call changes these into ABS_EXPR.  */\n       abort ();\n \n+    case BUILT_IN_FSQRT:\n+      /* If not optimizing, call the library function.  */\n+      if (!optimize)\n+\tbreak;\n+\n+      if (arglist == 0\n+\t  /* Arg could be non-integer if user redeclared this fcn wrong.  */\n+\t  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != REAL_TYPE)\n+\treturn const0_rtx;\n+\n+      /* Compute the argument.  */\n+      op0 = expand_expr (TREE_VALUE (arglist), subtarget, VOIDmode, 0);\n+      /* Compute sqrt, into TARGET if possible.\n+\t Set TARGET to wherever the result comes back.  */\n+      target = expand_unop (TYPE_MODE (TREE_TYPE (TREE_VALUE (arglist))),\n+\t\t\t    sqrt_optab, op0, target, 1);\n+      if (target == 0)\n+\tbreak;\n+      return target;\n+\n+\n     case BUILT_IN_SAVEREGS:\n       /* Don't do __builtin_saveregs more than once in a function.\n \t Save the result of the first call and reuse it.  */\n@@ -6161,19 +6232,26 @@ do_store_flag (exp, target, mode, only_cheap)\n \n /* INDEX is the value being switched on, with the lowest value\n    in the table already subtracted.\n+   MODE is its expected mode (needed if INDEX is ever constant).\n    RANGE is the length of the jump table.\n    TABLE_LABEL is a CODE_LABEL rtx for the table itself.\n \n    DEFAULT_LABEL is a CODE_LABEL rtx to jump to if the\n    index value is out of range.  */\n \n void\n-do_tablejump (index, range, table_label, default_label)\n+do_tablejump (index, mode, range, table_label, default_label)\n      rtx index, range, table_label, default_label;\n+     enum machine_mode mode;\n {\n   register rtx temp, vector;\n \n-  emit_cmp_insn (range, index, LTU, 0, GET_MODE (index), 0, 0);\n+  /* Code below assumes that MODE is Pmode,\n+     but I think that is a mistake.  Let's see if that is true.  */\n+  if (mode != Pmode)\n+    abort ();\n+\n+  emit_cmp_insn (range, index, LTU, 0, mode, 0, 0);\n   emit_jump_insn (gen_bltu (default_label));\n   /* If flag_force_addr were to affect this address\n      it could interfere with the tricky assumptions made"}]}