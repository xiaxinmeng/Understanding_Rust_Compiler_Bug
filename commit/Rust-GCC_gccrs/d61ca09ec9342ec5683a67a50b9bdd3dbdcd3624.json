{"sha": "d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDYxY2EwOWVjOTM0MmVjNTY4M2E2N2E1MGI5YmRkM2RiZGNkMzYyNA==", "commit": {"author": {"name": "Kyrylo Tkachov", "email": "kyrylo.tkachov@arm.com", "date": "2021-01-25T09:50:54Z"}, "committer": {"name": "Kyrylo Tkachov", "email": "kyrylo.tkachov@arm.com", "date": "2021-01-28T11:43:06Z"}, "message": "aarch64: Reimplement vshrn_high_n* intrinsics using builtins\n\nThis patch reimplements the vshrn_high_n* intrinsics that generate the\nSHRN2 instruction.\nIt is a vec_concat of the narrowing shift with the bottom part of the\ndestination register, so we need a little-endian and a big-endian version and an expander to\npick between them.\n\ngcc/ChangeLog:\n\n\t* config/aarch64/aarch64-simd-builtins.def (shrn2): Define\n\tbuiltin.\n\t* config/aarch64/aarch64-simd.md (aarch64_shrn2<mode>_insn_le):\n\tDefine.\n\t(aarch64_shrn2<mode>_insn_be): Likewise.\n\t(aarch64_shrn2<mode>): Likewise.\n\t* config/aarch64/arm_neon.h (vshrn_high_n_s16): Reimlplement\n\tusing builtins.\n\t(vshrn_high_n_s32): Likewise.\n\t(vshrn_high_n_s64): Likewise.\n\t(vshrn_high_n_u16): Likewise.\n\t(vshrn_high_n_u32): Likewise.\n\t(vshrn_high_n_u64): Likewise.", "tree": {"sha": "a66a52a9aa662b034dd0fab7246c372846b48502", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a66a52a9aa662b034dd0fab7246c372846b48502"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624/comments", "author": {"login": "ktkachov-arm", "id": 74917949, "node_id": "MDQ6VXNlcjc0OTE3OTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/74917949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktkachov-arm", "html_url": "https://github.com/ktkachov-arm", "followers_url": "https://api.github.com/users/ktkachov-arm/followers", "following_url": "https://api.github.com/users/ktkachov-arm/following{/other_user}", "gists_url": "https://api.github.com/users/ktkachov-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktkachov-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktkachov-arm/subscriptions", "organizations_url": "https://api.github.com/users/ktkachov-arm/orgs", "repos_url": "https://api.github.com/users/ktkachov-arm/repos", "events_url": "https://api.github.com/users/ktkachov-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/ktkachov-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ktkachov-arm", "id": 74917949, "node_id": "MDQ6VXNlcjc0OTE3OTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/74917949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktkachov-arm", "html_url": "https://github.com/ktkachov-arm", "followers_url": "https://api.github.com/users/ktkachov-arm/followers", "following_url": "https://api.github.com/users/ktkachov-arm/following{/other_user}", "gists_url": "https://api.github.com/users/ktkachov-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktkachov-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktkachov-arm/subscriptions", "organizations_url": "https://api.github.com/users/ktkachov-arm/orgs", "repos_url": "https://api.github.com/users/ktkachov-arm/repos", "events_url": "https://api.github.com/users/ktkachov-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/ktkachov-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fdb904a1822c38db5d69a50878b21041c476f045", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdb904a1822c38db5d69a50878b21041c476f045", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fdb904a1822c38db5d69a50878b21041c476f045"}], "stats": {"total": 169, "additions": 85, "deletions": 84}, "files": [{"sha": "66f1b231d213e0868b27938f3eb6723c777cd925", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624", "patch": "@@ -191,6 +191,9 @@\n   /* Implemented by aarch64_shrn<mode>\".  */\n   BUILTIN_VQN (SHIFTIMM, shrn, 0, NONE)\n \n+  /* Implemented by aarch64_shrn2<mode>.  */\n+  BUILTIN_VQN (SHIFTACC, shrn2, 0, NONE)\n+\n   /* Implemented by aarch64_<su>mlsl<mode>.  */\n   BUILTIN_VD_BHSI (TERNOP, smlsl, 0, NONE)\n   BUILTIN_VD_BHSI (TERNOPU, umlsl, 0, NONE)"}, {"sha": "86d2667601ba737fed925be04c336ea8ab17ef8f", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 43, "deletions": 0, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624", "patch": "@@ -1728,6 +1728,49 @@\n   }\n )\n \n+(define_insn \"aarch64_shrn2<mode>_insn_le\"\n+  [(set (match_operand:<VNARROWQ2> 0 \"register_operand\" \"=w\")\n+\t(vec_concat:<VNARROWQ2>\n+\t  (match_operand:<VNARROWQ> 1 \"register_operand\" \"0\")\n+\t  (truncate:<VNARROWQ>\n+\t    (lshiftrt:VQN (match_operand:VQN 2 \"register_operand\" \"w\")\n+\t\t(match_operand:VQN 3 \"aarch64_simd_rshift_imm\")))))]\n+  \"TARGET_SIMD && !BYTES_BIG_ENDIAN\"\n+  \"shrn2\\\\t%0.<V2ntype>, %2.<Vtype>, %3\"\n+  [(set_attr \"type\" \"neon_shift_imm_narrow_q\")]\n+)\n+\n+(define_insn \"aarch64_shrn2<mode>_insn_be\"\n+  [(set (match_operand:<VNARROWQ2> 0 \"register_operand\" \"=w\")\n+\t(vec_concat:<VNARROWQ2>\n+\t  (truncate:<VNARROWQ>\n+\t    (lshiftrt:VQN (match_operand:VQN 2 \"register_operand\" \"w\")\n+\t\t(match_operand:VQN 3 \"aarch64_simd_rshift_imm\")))\n+\t  (match_operand:<VNARROWQ> 1 \"register_operand\" \"0\")))]\n+  \"TARGET_SIMD && BYTES_BIG_ENDIAN\"\n+  \"shrn2\\\\t%0.<V2ntype>, %2.<Vtype>, %3\"\n+  [(set_attr \"type\" \"neon_shift_imm_narrow_q\")]\n+)\n+\n+(define_expand \"aarch64_shrn2<mode>\"\n+  [(match_operand:<VNARROWQ2> 0 \"register_operand\")\n+   (match_operand:<VNARROWQ> 1 \"register_operand\")\n+   (match_operand:VQN 2 \"register_operand\")\n+   (match_operand:SI 3 \"aarch64_simd_shift_imm_offset_<vn_mode>\")]\n+  \"TARGET_SIMD\"\n+  {\n+    operands[3] = aarch64_simd_gen_const_vector_dup (<MODE>mode,\n+\t\t\t\t\t\t INTVAL (operands[3]));\n+    if (BYTES_BIG_ENDIAN)\n+      emit_insn (gen_aarch64_shrn2<mode>_insn_be (operands[0], operands[1],\n+\t\t\t\t\t\t  operands[2], operands[3]));\n+    else\n+      emit_insn (gen_aarch64_shrn2<mode>_insn_le (operands[0], operands[1],\n+\t\t\t\t\t\t  operands[2], operands[3]));\n+    DONE;\n+  }\n+)\n+\n \n ;; For quads.\n "}, {"sha": "ac469ce3f5805558e14fecba0c915d0b9cdb9b91", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 39, "deletions": 84, "changes": 123, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=d61ca09ec9342ec5683a67a50b9bdd3dbdcd3624", "patch": "@@ -9809,95 +9809,50 @@ vrsqrteq_u32 (uint32x4_t __a)\n   return __result;\n }\n \n-#define vshrn_high_n_s16(a, b, c)                                       \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x8_t b_ = (b);                                              \\\n-       int8x8_t a_ = (a);                                               \\\n-       int8x16_t result = vcombine_s8                                   \\\n-                            (a_, vcreate_s8                             \\\n-                                   (__AARCH64_UINT64_C (0x0)));         \\\n-       __asm__ (\"shrn2 %0.16b,%1.8h,#%2\"                                \\\n-                : \"+w\"(result)                                          \\\n-                : \"w\"(b_), \"i\"(c)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n+__extension__ extern __inline int8x16_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_high_n_s16 (int8x8_t __a, int16x8_t __b, const int __c)\n+{\n+  return __builtin_aarch64_shrn2v8hi (__a, __b, __c);\n+}\n \n-#define vshrn_high_n_s32(a, b, c)                                       \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x4_t b_ = (b);                                              \\\n-       int16x4_t a_ = (a);                                              \\\n-       int16x8_t result = vcombine_s16                                  \\\n-                            (a_, vcreate_s16                            \\\n-                                   (__AARCH64_UINT64_C (0x0)));         \\\n-       __asm__ (\"shrn2 %0.8h,%1.4s,#%2\"                                 \\\n-                : \"+w\"(result)                                          \\\n-                : \"w\"(b_), \"i\"(c)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n+__extension__ extern __inline int16x8_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_high_n_s32 (int16x4_t __a, int32x4_t __b, const int __c)\n+{\n+  return __builtin_aarch64_shrn2v4si (__a, __b, __c);\n+}\n \n-#define vshrn_high_n_s64(a, b, c)                                       \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int64x2_t b_ = (b);                                              \\\n-       int32x2_t a_ = (a);                                              \\\n-       int32x4_t result = vcombine_s32                                  \\\n-                            (a_, vcreate_s32                            \\\n-                                   (__AARCH64_UINT64_C (0x0)));         \\\n-       __asm__ (\"shrn2 %0.4s,%1.2d,#%2\"                                 \\\n-                : \"+w\"(result)                                          \\\n-                : \"w\"(b_), \"i\"(c)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n+__extension__ extern __inline int32x4_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_high_n_s64 (int32x2_t __a, int64x2_t __b, const int __c)\n+{\n+  return __builtin_aarch64_shrn2v2di (__a, __b, __c);\n+}\n \n-#define vshrn_high_n_u16(a, b, c)                                       \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x8_t b_ = (b);                                             \\\n-       uint8x8_t a_ = (a);                                              \\\n-       uint8x16_t result = vcombine_u8                                  \\\n-                            (a_, vcreate_u8                             \\\n-                                   (__AARCH64_UINT64_C (0x0)));         \\\n-       __asm__ (\"shrn2 %0.16b,%1.8h,#%2\"                                \\\n-                : \"+w\"(result)                                          \\\n-                : \"w\"(b_), \"i\"(c)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n+__extension__ extern __inline uint8x16_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_high_n_u16 (uint8x8_t __a, uint16x8_t __b, const int __c)\n+{\n+  return (uint8x16_t)\n+    __builtin_aarch64_shrn2v8hi ((int8x8_t) __a, (int16x8_t) __b, __c);\n+}\n \n-#define vshrn_high_n_u32(a, b, c)                                       \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x4_t b_ = (b);                                             \\\n-       uint16x4_t a_ = (a);                                             \\\n-       uint16x8_t result = vcombine_u16                                 \\\n-                            (a_, vcreate_u16                            \\\n-                                   (__AARCH64_UINT64_C (0x0)));         \\\n-       __asm__ (\"shrn2 %0.8h,%1.4s,#%2\"                                 \\\n-                : \"+w\"(result)                                          \\\n-                : \"w\"(b_), \"i\"(c)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n+__extension__ extern __inline uint16x8_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_high_n_u32 (uint16x4_t __a, uint32x4_t __b, const int __c)\n+{\n+  return (uint16x8_t)\n+    __builtin_aarch64_shrn2v4si ((int16x4_t) __a, (int32x4_t) __b, __c);\n+}\n \n-#define vshrn_high_n_u64(a, b, c)                                       \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint64x2_t b_ = (b);                                             \\\n-       uint32x2_t a_ = (a);                                             \\\n-       uint32x4_t result = vcombine_u32                                 \\\n-                            (a_, vcreate_u32                            \\\n-                                   (__AARCH64_UINT64_C (0x0)));         \\\n-       __asm__ (\"shrn2 %0.4s,%1.2d,#%2\"                                 \\\n-                : \"+w\"(result)                                          \\\n-                : \"w\"(b_), \"i\"(c)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n+__extension__ extern __inline uint32x4_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_high_n_u64 (uint32x2_t __a, uint64x2_t __b, const int __c)\n+{\n+  return (uint32x4_t)\n+    __builtin_aarch64_shrn2v2di ((int32x2_t) __a, (int64x2_t) __b, __c);\n+}\n \n #define vsli_n_p8(a, b, c)                                              \\\n   __extension__                                                         \\"}]}