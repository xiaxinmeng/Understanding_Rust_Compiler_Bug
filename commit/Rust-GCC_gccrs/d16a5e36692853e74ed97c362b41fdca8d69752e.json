{"sha": "d16a5e36692853e74ed97c362b41fdca8d69752e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDE2YTVlMzY2OTI4NTNlNzRlZDk3YzM2MmI0MWZkY2E4ZDY5NzUyZQ==", "commit": {"author": {"name": "Daniel Berlin", "email": "dberlin@dberlin.org", "date": "2006-01-19T01:42:48Z"}, "committer": {"name": "Daniel Berlin", "email": "dberlin@gcc.gnu.org", "date": "2006-01-19T01:42:48Z"}, "message": "tree-ssa-operands.h (ssa_call_clobbered_cache_valid): Remove.\n\n2006-01-16  Daniel Berlin  <dberlin@dberlin.org>\n\n\t* tree-ssa-operands.h (ssa_call_clobbered_cache_valid): Remove.\n\t(ssa_ro_call_cache_valid): Ditto.\n\t* tree-ssa-alias.c (sort_tags_by_id): New function.\n\t(init_transitive_clobber_worklist): Ditto.\n\t(add_to_worklist): Ditto.\n\t(mark_aliases_call_clobbered): Ditto.\n\t(compute_tag_properties): Ditto.\n\t(set_initial_properties): Ditto.\n\t(compute_call_clobbered): Ditto.\n\t(compute_may_aliases):\tCall compute_call_clobbered and grouping.\n\t(compute_flow_sensitive_aliasing): Remove clobbering related code.\n\t(compute_flow_insensitive_aliasing): Grouping now happens in our\n\tcaller.\n\t(setup_pointers_and_addressables): Remove clobbering related code.\n\t(add_may_alias): Ditto.\n\t(replace_may_alias): Ditto.\n\t(get_nmt_for): Ditto.\n\t(create_global_var): \n\t(is_escape_site): Return an escape_type enumeration.\n\t* tree-flow-inline.h (is_call_clobbered):  Global var does not\n\timply call clobbered.\n\t(mark_call_clobbered): Take a reason for marking this. Remove\n\tmarking of globalness, and cache invalidation.\n\t(clear_call_clobbered): Remove cache invalidation code.\n\t* tree-dfa.c (dump_variable): If details is on, dump the reason\n\tfor escaping.\n\t* tree-outof-ssa.c (create_temp): Copy escape mask from original\n\tvariable. \n\t* tree-flow.h (struct ptr_info_def): Add escape mask member.\n\t(struct var_ann_d): Ditto.\n\t(enum escape_type): New.\n\t(mark_call_clobbered): Adjust prototype.\n\t* tree-ssa-structalias.c (update_alias_info): Unmodifiable vars\n\tare never call clobbered. \n\tRecord reasons for escaping.\n\t* tree-ssa-structalias.h (is_escape_site): Update prototype.\n\t* tree-ssa-operands.c (ssa_call_clobbered_cache_valid): Remove.\n\t(ssa_ro_call_cache_valid): Ditto.\n\t(clobbered_v_may_defs): Ditto.\n\t(clobbered_vuses): Ditto.\n\t(ro_call_vuses): Ditto.\n\t(clobber_stats): New.\n\t(init_ssa_operands): Zero out clobber stats.\n\t(fini_ssa_operands): Print out clobber stats.\n\t(get_call_expr_operands): Pass callee fndecl to\n\tadd_call_read_ops).\n\t(add_call_clobber_ops): Remove use of cache.\n\tAdd use of PURE_CONST information.\n\t(add_call_read_ops): Remove use of cache.\n\tAdd use of static not_read information.\n\nFrom-SVN: r109938", "tree": {"sha": "1bea89da9c401e1b8e235d514d1d027b81c0eece", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1bea89da9c401e1b8e235d514d1d027b81c0eece"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d16a5e36692853e74ed97c362b41fdca8d69752e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d16a5e36692853e74ed97c362b41fdca8d69752e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d16a5e36692853e74ed97c362b41fdca8d69752e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d16a5e36692853e74ed97c362b41fdca8d69752e/comments", "author": {"login": "dberlin", "id": 324715, "node_id": "MDQ6VXNlcjMyNDcxNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/324715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dberlin", "html_url": "https://github.com/dberlin", "followers_url": "https://api.github.com/users/dberlin/followers", "following_url": "https://api.github.com/users/dberlin/following{/other_user}", "gists_url": "https://api.github.com/users/dberlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/dberlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dberlin/subscriptions", "organizations_url": "https://api.github.com/users/dberlin/orgs", "repos_url": "https://api.github.com/users/dberlin/repos", "events_url": "https://api.github.com/users/dberlin/events{/privacy}", "received_events_url": "https://api.github.com/users/dberlin/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "c8db7d5c17414a130f023cf25b3fe12f6842599b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c8db7d5c17414a130f023cf25b3fe12f6842599b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c8db7d5c17414a130f023cf25b3fe12f6842599b"}], "stats": {"total": 794, "additions": 571, "deletions": 223}, "files": [{"sha": "d8586406628538ffaf3bae00f9c32f1bba155fb1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 53, "deletions": 0, "changes": 53, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -1,3 +1,56 @@\n+2006-01-16  Daniel Berlin  <dberlin@dberlin.org>\n+\n+\t* tree-ssa-operands.h (ssa_call_clobbered_cache_valid): Remove.\n+\t(ssa_ro_call_cache_valid): Ditto.\n+\t* tree-ssa-alias.c (sort_tags_by_id): New function.\n+\t(init_transitive_clobber_worklist): Ditto.\n+\t(add_to_worklist): Ditto.\n+\t(mark_aliases_call_clobbered): Ditto.\n+\t(compute_tag_properties): Ditto.\n+\t(set_initial_properties): Ditto.\n+\t(compute_call_clobbered): Ditto.\n+\t(compute_may_aliases):\tCall compute_call_clobbered and grouping.\n+\t(compute_flow_sensitive_aliasing): Remove clobbering related code.\n+\t(compute_flow_insensitive_aliasing): Grouping now happens in our\n+\tcaller.\n+\t(setup_pointers_and_addressables): Remove clobbering related code.\n+\t(add_may_alias): Ditto.\n+\t(replace_may_alias): Ditto.\n+\t(get_nmt_for): Ditto.\n+\t(create_global_var): \n+\t(is_escape_site): Return an escape_type enumeration.\n+\t* tree-flow-inline.h (is_call_clobbered):  Global var does not\n+\timply call clobbered.\n+\t(mark_call_clobbered): Take a reason for marking this. Remove\n+\tmarking of globalness, and cache invalidation.\n+\t(clear_call_clobbered): Remove cache invalidation code.\n+\t* tree-dfa.c (dump_variable): If details is on, dump the reason\n+\tfor escaping.\n+\t* tree-outof-ssa.c (create_temp): Copy escape mask from original\n+\tvariable. \n+\t* tree-flow.h (struct ptr_info_def): Add escape mask member.\n+\t(struct var_ann_d): Ditto.\n+\t(enum escape_type): New.\n+\t(mark_call_clobbered): Adjust prototype.\n+\t* tree-ssa-structalias.c (update_alias_info): Unmodifiable vars\n+\tare never call clobbered. \n+\tRecord reasons for escaping.\n+\t* tree-ssa-structalias.h (is_escape_site): Update prototype.\n+\t* tree-ssa-operands.c (ssa_call_clobbered_cache_valid): Remove.\n+\t(ssa_ro_call_cache_valid): Ditto.\n+\t(clobbered_v_may_defs): Ditto.\n+\t(clobbered_vuses): Ditto.\n+\t(ro_call_vuses): Ditto.\n+\t(clobber_stats): New.\n+\t(init_ssa_operands): Zero out clobber stats.\n+\t(fini_ssa_operands): Print out clobber stats.\n+\t(get_call_expr_operands): Pass callee fndecl to\n+\tadd_call_read_ops).\n+\t(add_call_clobber_ops): Remove use of cache.\n+\tAdd use of PURE_CONST information.\n+\t(add_call_read_ops): Remove use of cache.\n+\tAdd use of static not_read information.\n+\t\n 2006-01-18  Alexandre Oliva  <aoliva@redhat.com>\n \n \tIntroduce TLS descriptors for i386 and x86_64."}, {"sha": "d901d41476800d00f34ed5677d4b225151b5b903", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -1,3 +1,7 @@\n+2006-01-18  Daniel Berlin  <dberlin@dberlin.org>\n+\n+\t* gcc.dg/tree-ssa/pr24287.c: New test\n+\n 2006-01-18  Eric Christopher  <echristo@apple.com>\n \n \t* g++.dg/eh/table.C: New."}, {"sha": "8e7f18691dc75ff576d66c671764bdc037c0b259", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr24287.c", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr24287.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr24287.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr24287.c?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -0,0 +1,25 @@\n+/* { dg-do compile } */ \n+/* { dg-options \"-O2 -fdump-tree-optimized\" } */\n+int g1(int);\n+int h(int *a, int *b)__attribute__((pure));\n+void link_error();\n+\n+/* The calls to link_error should be eliminated, since nothing escapes to \n+   non-pure functions.  */\n+int g(void)\n+{\n+  int t = 0, t1 = 2;\n+  int t2 = h(&t, &t1);\n+  if (t != 0)\n+    link_error ();\n+  if (t1 != 2)\n+    link_error ();\n+  g1(t2);\n+  if (t != 0)\n+    link_error ();\n+  if (t1 != 2)\n+    link_error ();\n+  return t2 == 2;\n+}\n+/* { dg-final { scan-tree-dump-times \"link_error\" 0 \"optimized\"} } */\n+/* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "19453780d426968b07bd135ed16399db51b6d7a7", "filename": "gcc/tree-dfa.c", "status": "modified", "additions": 31, "deletions": 7, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-dfa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-dfa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dfa.c?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -363,7 +363,35 @@ dump_variable (FILE *file, tree var)\n     fprintf (file, \", is volatile\");\n \n   if (is_call_clobbered (var))\n-    fprintf (file, \", call clobbered\");\n+    {\n+      fprintf (file, \", call clobbered\");\n+      if (dump_flags & TDF_DETAILS)\n+\t{\n+\t  var_ann_t va = var_ann (var);\n+\t  unsigned int escape_mask = va->escape_mask;\n+\t  \n+\t  fprintf (file, \" (\");\n+\t  if (escape_mask & ESCAPE_STORED_IN_GLOBAL)\n+\t    fprintf (file, \", stored in global\");\n+\t  if (escape_mask & ESCAPE_TO_ASM)\n+\t    fprintf (file, \", goes through ASM\");\n+\t  if (escape_mask & ESCAPE_TO_CALL)\n+\t    fprintf (file, \", passed to call\");\n+\t  if (escape_mask & ESCAPE_BAD_CAST)\n+\t    fprintf (file, \", bad cast\");\n+\t  if (escape_mask & ESCAPE_TO_RETURN)\n+\t    fprintf (file, \", returned from func\");\n+\t  if (escape_mask & ESCAPE_TO_PURE_CONST)\n+\t    fprintf (file, \", passed to pure/const\");\n+\t  if (escape_mask & ESCAPE_IS_GLOBAL)\n+\t    fprintf (file, \", is global var\");\n+\t  if (escape_mask & ESCAPE_IS_PARM)\n+\t    fprintf (file, \", is incoming pointer\");\n+\t  if (escape_mask & ESCAPE_UNKNOWN)\n+\t    fprintf (file, \", unknown escape\");\n+\t  fprintf (file, \" )\");\n+\t}\n+    }\n \n   if (default_def (var))\n     {\n@@ -719,15 +747,11 @@ add_referenced_var (tree var, struct walk_state *walk_state)\n \t*slot = (void *) var;\n       \n       referenced_var_insert (DECL_UID (var), var);\n-\n-      /* Global variables are always call-clobbered.  */\n-      if (is_global_var (var))\n-\tmark_call_clobbered (var);\n-\n+      \n       /* Tag's don't have DECL_INITIAL.  */\n       if (MTAG_P (var))\n \treturn;\n-      \n+\n       /* Scan DECL_INITIAL for pointer variables as they may contain\n \t address arithmetic referencing the address of other\n \t variables.  */"}, {"sha": "69bef68f9ac2020895ea2a353106c9484a5dd569", "filename": "gcc/tree-flow-inline.h", "status": "modified", "additions": 5, "deletions": 15, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-flow-inline.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-flow-inline.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow-inline.h?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -843,34 +843,26 @@ loop_containing_stmt (tree stmt)\n static inline bool\n is_call_clobbered (tree var)\n {\n-  return is_global_var (var)\n-    || bitmap_bit_p (call_clobbered_vars, DECL_UID (var));\n+  return bitmap_bit_p (call_clobbered_vars, DECL_UID (var));\n }\n \n /* Mark variable VAR as being clobbered by function calls.  */\n static inline void\n-mark_call_clobbered (tree var)\n+mark_call_clobbered (tree var, unsigned int escape_type)\n {\n-  /* If VAR is a memory tag, then we need to consider it a global\n-     variable.  This is because the pointer that VAR represents has\n-     been found to point to either an arbitrary location or to a known\n-     location in global memory.  */\n-  if (MTAG_P (var) && TREE_CODE (var) != STRUCT_FIELD_TAG)\n-    MTAG_GLOBAL (var) = 1;\n+  var_ann (var)->escape_mask |= escape_type;\n   bitmap_set_bit (call_clobbered_vars, DECL_UID (var));\n-  ssa_call_clobbered_cache_valid = false;\n-  ssa_ro_call_cache_valid = false;\n }\n \n /* Clear the call-clobbered attribute from variable VAR.  */\n static inline void\n clear_call_clobbered (tree var)\n {\n+  var_ann_t ann = var_ann (var);\n+  ann->escape_mask = 0;\n   if (MTAG_P (var) && TREE_CODE (var) != STRUCT_FIELD_TAG)\n     MTAG_GLOBAL (var) = 0;\n   bitmap_clear_bit (call_clobbered_vars, DECL_UID (var));\n-  ssa_call_clobbered_cache_valid = false;\n-  ssa_ro_call_cache_valid = false;\n }\n \n /* Mark variable VAR as being non-addressable.  */\n@@ -879,8 +871,6 @@ mark_non_addressable (tree var)\n {\n   bitmap_clear_bit (call_clobbered_vars, DECL_UID (var));\n   TREE_ADDRESSABLE (var) = 0;\n-  ssa_call_clobbered_cache_valid = false;\n-  ssa_ro_call_cache_valid = false;\n }\n \n /* Return the common annotation for T.  Return NULL if the annotation"}, {"sha": "a766e391b171ac0085b49bd3c58fd86888bbcf3e", "filename": "gcc/tree-flow.h", "status": "modified", "additions": 26, "deletions": 1, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-flow.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-flow.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow.h?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -92,6 +92,9 @@ struct ptr_info_def GTY(())\n      pointer will be represented by this memory tag, instead of the type\n      tag computed by TBAA.  */\n   tree name_mem_tag;\n+\n+  /* Mask of reasons this pointer's value escapes the function  */\n+  unsigned int escape_mask;\n };\n \n \n@@ -213,6 +216,10 @@ struct var_ann_d GTY(())\n   /* If this variable is a structure, this fields holds a list of\n      symbols representing each of the fields of the structure.  */\n   subvar_t subvars;\n+\n+  /* Mask of values saying the reasons why this variable has escaped\n+     the function.  */\n+  unsigned int escape_mask;\n };\n \n struct function_ann_d GTY(())\n@@ -751,9 +758,27 @@ enum move_pos\n   };\n extern enum move_pos movement_possibility (tree);\n \n+/* The reasons a variable may escape a function.  */\n+enum escape_type \n+  {\n+    NO_ESCAPE = 0, /* Doesn't escape.  */\n+    ESCAPE_STORED_IN_GLOBAL = 1 << 1,\n+    ESCAPE_TO_ASM = 1 << 2,  /* Passed by address to an assembly\n+\t\t\t\tstatement.  */\n+    ESCAPE_TO_CALL = 1 << 3,  /* Escapes to a function call.  */\n+    ESCAPE_BAD_CAST = 1 << 4, /* Cast from pointer to integer */\n+    ESCAPE_TO_RETURN = 1 << 5, /* Returned from function.  */\n+    ESCAPE_TO_PURE_CONST = 1 << 6, /* Escapes to a pure or constant\n+\t\t\t\t      function call.  */\n+    ESCAPE_IS_GLOBAL = 1 << 7,  /* Is a global variable.  */\n+    ESCAPE_IS_PARM = 1 << 8, /* Is an incoming function parameter.  */\n+    ESCAPE_UNKNOWN = 1 << 9 /* We believe it escapes for some reason\n+\t\t\t       not enumerated above.  */\n+  };\n+\n /* In tree-flow-inline.h  */\n static inline bool is_call_clobbered (tree);\n-static inline void mark_call_clobbered (tree);\n+static inline void mark_call_clobbered (tree, unsigned int);\n static inline void set_is_used (tree);\n static inline bool unmodifiable_var_p (tree);\n "}, {"sha": "2f36cc6cc818319fe08abf62a73e787f3efecdd3", "filename": "gcc/tree-outof-ssa.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-outof-ssa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-outof-ssa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-outof-ssa.c?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -177,7 +177,7 @@ create_temp (tree t)\n      inherit from our original variable.  */\n   var_ann (tmp)->type_mem_tag = var_ann (t)->type_mem_tag;\n   if (is_call_clobbered (t))\n-    mark_call_clobbered (tmp);\n+    mark_call_clobbered (tmp, var_ann (t)->escape_mask);\n \n   return tmp;\n }"}, {"sha": "a890e11ce75d54fe217b0929aac4cd08bd528852", "filename": "gcc/tree-ssa-alias.c", "status": "modified", "additions": 307, "deletions": 69, "changes": 376, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-alias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-alias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-alias.c?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -135,6 +135,287 @@ bitmap addressable_vars;\n    having to keep track of too many V_MAY_DEF expressions at call sites.  */\n tree global_var;\n \n+DEF_VEC_I(int);\n+DEF_VEC_ALLOC_I(int,heap);\n+\n+/* qsort comparison function to sort type/name tags by DECL_UID.  */\n+\n+static int\n+sort_tags_by_id (const void *pa, const void *pb)\n+{\n+  tree a = *(tree *)pa;\n+  tree b = *(tree *)pb;\n+ \n+  return DECL_UID (a) - DECL_UID (b);\n+}\n+\n+/* Initialize WORKLIST to contain those memory tags that are marked call\n+   clobbered.  Initialized WORKLIST2 to contain the reasons these\n+   memory tags escaped.  */\n+\n+static void\n+init_transitive_clobber_worklist (VEC (tree, heap) **worklist,\n+\t\t\t\t  VEC (int, heap) **worklist2)\n+{\n+  referenced_var_iterator rvi;\n+  tree curr;\n+\n+  FOR_EACH_REFERENCED_VAR (curr, rvi)\n+    {\n+      if (MTAG_P (curr) && is_call_clobbered (curr))\n+\t{\n+\t  VEC_safe_push (tree, heap, *worklist, curr);\n+\t  VEC_safe_push (int, heap, *worklist2, var_ann (curr)->escape_mask);\n+\t}\n+    }\n+}\n+\n+/* Add ALIAS to WORKLIST (and the reason for escaping REASON to WORKLIST2) if\n+   ALIAS is not already marked call clobbered, and is a memory\n+   tag.  */\n+\n+static void\n+add_to_worklist (tree alias, VEC (tree, heap) **worklist,\n+\t\t VEC (int, heap) **worklist2,\n+\t\t int reason)\n+{\n+  if (MTAG_P (alias) && !is_call_clobbered (alias))\n+    {\n+      VEC_safe_push (tree, heap, *worklist, alias);\n+      VEC_safe_push (int, heap, *worklist2, reason);\n+    }\n+}\n+\n+/* Mark aliases of TAG as call clobbered, and place any tags on the\n+   alias list that were not already call clobbered on WORKLIST.  */\n+\n+static void\n+mark_aliases_call_clobbered (tree tag, VEC (tree, heap) **worklist,\n+\t\t\t     VEC (int, heap) **worklist2)\n+{\n+  unsigned int i;\n+  VEC (tree, gc) *ma;\n+  tree entry;\n+  var_ann_t ta = var_ann (tag);\n+\n+  if (!MTAG_P (tag))\n+    return;\n+  ma = may_aliases (tag);\n+  if (!ma)\n+    return;\n+\n+  for (i = 0; VEC_iterate (tree, ma, i, entry); i++)\n+    {\n+      if (!unmodifiable_var_p (entry))\n+\t{\n+\t  add_to_worklist (entry, worklist, worklist2, ta->escape_mask);\n+\t  mark_call_clobbered (entry, ta->escape_mask);\n+\t}\n+    }\n+}\n+\n+/* Tags containing global vars need to be marked as global.\n+   Tags containing call clobbered vars need to be marked as call\n+   clobbered. */\n+\n+static void\n+compute_tag_properties (void)\n+{\n+  referenced_var_iterator rvi;\n+  tree tag;\n+  bool changed = true;\n+  VEC (tree, heap) *taglist = NULL;\n+\n+  FOR_EACH_REFERENCED_VAR (tag, rvi)\n+    {\n+      if (!MTAG_P (tag) || TREE_CODE (tag) == STRUCT_FIELD_TAG)\n+\tcontinue;\n+      VEC_safe_push (tree, heap, taglist, tag);\n+    }\n+\n+  /* We sort the taglist by DECL_UID, for two reasons.\n+     1. To get a sequential ordering to make the bitmap accesses\n+     faster.\n+     2. Because of the way we compute aliases, it's more likely that\n+     an earlier tag is included in a later tag, and this will reduce\n+     the number of iterations.\n+\n+     If we had a real tag graph, we would just topo-order it and be\n+     done with it.  */\n+  qsort (VEC_address (tree, taglist),\n+\t VEC_length (tree, taglist),\n+\t sizeof (tree),\n+\t sort_tags_by_id);\n+\n+  /* Go through each tag not marked as global, and if it aliases\n+     global vars, mark it global. \n+     \n+     If the tag contains call clobbered vars, mark it call\n+     clobbered.  \n+\n+     This loop iterates because tags may appear in the may-aliases\n+     list of other tags when we group.  */\n+\n+  while (changed)\n+    {\n+      unsigned int k;\n+\n+      changed = false;      \n+      for (k = 0; VEC_iterate (tree, taglist, k, tag); k++)\n+\t{\n+\t  VEC (tree, gc) *ma;\n+\t  unsigned int i;\n+\t  tree entry;\n+\t  bool tagcc = is_call_clobbered (tag);\n+\t  bool tagglobal = MTAG_GLOBAL (tag);\n+\t  \n+\t  if (tagcc && tagglobal)\n+\t    continue;\n+\t  \n+\t  ma = may_aliases (tag);\n+\t  if (!ma)\n+\t    continue;\n+\n+\t  for (i = 0; VEC_iterate (tree, ma, i, entry); i++)\n+\t    {\n+\t      /* Call clobbered entries cause the tag to be marked\n+\t\t call clobbered.  */\n+\t      if (!tagcc && is_call_clobbered (entry))\n+\t\t{\n+\t\t  mark_call_clobbered (tag, var_ann (entry)->escape_mask);\n+\t\t  tagcc = true;\n+\t\t  changed = true;\n+\t\t}\n+\n+\t      /* Global vars cause the tag to be marked global.  */\n+\t      if (!tagglobal && is_global_var (entry))\n+\t\t{\n+\t\t  MTAG_GLOBAL (tag) = true;\n+\t\t  changed = true;\n+\t\t  tagglobal = true;\n+\t\t}\n+\n+\t      /* Early exit once both global and cc are set, since the\n+\t\t loop can't do any more than that.  */\n+\t      if (tagcc && tagglobal)\n+\t\tbreak;\n+\t    }\n+\t}\n+    }\n+  VEC_free (tree, heap, taglist);\n+}\n+\n+/* Set up the initial variable clobbers and globalness.\n+   When this function completes, only tags whose aliases need to be\n+   clobbered will be set clobbered.  Tags clobbered because they   \n+   contain call clobbered vars are handled in compute_tag_properties.  */\n+\n+static void\n+set_initial_properties (struct alias_info *ai)\n+{\n+  unsigned int i;\n+  referenced_var_iterator rvi;\n+  tree var;\n+\n+  FOR_EACH_REFERENCED_VAR (var, rvi)\n+    {\n+      if (is_global_var (var) \n+\t  && (!var_can_have_subvars (var)\n+\t      || get_subvars_for_var (var) == NULL))\n+\t{\n+\t  if (!unmodifiable_var_p (var))\n+\t    mark_call_clobbered (var, ESCAPE_IS_GLOBAL);\n+\t}\n+      else if (TREE_CODE (var) == PARM_DECL\n+\t       && default_def (var)\n+\t       && POINTER_TYPE_P (TREE_TYPE (var)))\n+\t{\n+\t  tree def = default_def (var);\n+\t  get_ptr_info (def)->value_escapes_p = 1;\n+\t  get_ptr_info (def)->escape_mask |= ESCAPE_IS_PARM;\t  \n+\t}\n+    }\n+\n+  for (i = 0; i < VARRAY_ACTIVE_SIZE (ai->processed_ptrs); i++)\n+    {\n+      tree ptr = VARRAY_TREE (ai->processed_ptrs, i);\n+      struct ptr_info_def *pi = SSA_NAME_PTR_INFO (ptr);\n+      var_ann_t v_ann = var_ann (SSA_NAME_VAR (ptr));\n+      \n+      if (pi->value_escapes_p)\n+\t{\n+\t  /* If PTR escapes then its associated memory tags and\n+\t     pointed-to variables are call-clobbered.  */\n+\t  if (pi->name_mem_tag)\n+\t    mark_call_clobbered (pi->name_mem_tag, pi->escape_mask);\n+\n+\t  if (v_ann->type_mem_tag)\n+\t    mark_call_clobbered (v_ann->type_mem_tag, pi->escape_mask);\n+\n+\t  if (pi->pt_vars)\n+\t    {\n+\t      bitmap_iterator bi;\n+\t      unsigned int j;\t      \n+\t      EXECUTE_IF_SET_IN_BITMAP (pi->pt_vars, 0, j, bi)\n+\t\tif (!unmodifiable_var_p (referenced_var (j)))\n+\t\t  mark_call_clobbered (referenced_var (j), pi->escape_mask);\n+\t    }\n+\t}\n+      /* If the name tag is call clobbered, so is the type tag\n+\t associated with the base VAR_DECL.  */\n+      if (pi->name_mem_tag\n+\t  && v_ann->type_mem_tag\n+\t  && is_call_clobbered (pi->name_mem_tag))\n+\tmark_call_clobbered (v_ann->type_mem_tag, pi->escape_mask);\n+\n+      /* Name tags and type tags that we don't know where they point\n+\t to, might point to global memory, and thus, are clobbered.\n+\n+         FIXME:  This is not quite right.  They should only be\n+         clobbered if value_escapes_p is true, regardless of whether\n+         they point to global memory or not.\n+         So removing this code and fixing all the bugs would be nice.\n+         It is the cause of a bunch of clobbering.  */\n+      if ((pi->pt_global_mem || pi->pt_anything) \n+\t  && pi->is_dereferenced && pi->name_mem_tag)\n+\t{\n+\t  mark_call_clobbered (pi->name_mem_tag, ESCAPE_IS_GLOBAL);\n+\t  MTAG_GLOBAL (pi->name_mem_tag) = true;\n+\t}\n+      \n+      if ((pi->pt_global_mem || pi->pt_anything) \n+\t  && pi->is_dereferenced && v_ann->type_mem_tag)\n+\t{\n+\t  mark_call_clobbered (v_ann->type_mem_tag, ESCAPE_IS_GLOBAL);\n+\t  MTAG_GLOBAL (v_ann->type_mem_tag) = true;\n+\t}\n+    }\n+}\n+\n+/* Compute which variables need to be marked call clobbered because\n+   their tag is call clobbered, and which tags need to be marked\n+   global because they contain global variables.  */\n+\n+static void\n+compute_call_clobbered (struct alias_info *ai)\n+{\n+  VEC (tree, heap) *worklist = NULL;\n+  VEC(int,heap) *worklist2 = NULL;\n+  \n+  set_initial_properties (ai);\n+  init_transitive_clobber_worklist (&worklist, &worklist2);\n+  while (VEC_length (tree, worklist) != 0)\n+    {\n+      tree curr = VEC_pop (tree, worklist);\n+      int reason = VEC_pop (int, worklist2);\n+      \n+      mark_call_clobbered (curr, reason);\n+      mark_aliases_call_clobbered (curr, &worklist, &worklist2);\n+    }\n+  VEC_free (tree, heap, worklist);\n+  VEC_free (int, heap, worklist2);\n+  compute_tag_properties ();\n+}\n \n /* Compute may-alias information for every variable referenced in function\n    FNDECL.\n@@ -277,6 +558,13 @@ compute_may_aliases (void)\n      memory tags.  */\n   compute_flow_insensitive_aliasing (ai);\n \n+  /* Determine if we need to enable alias grouping.  */\n+  if (ai->total_alias_vops >= MAX_ALIASED_VOPS)\n+    group_aliases (ai);\n+\n+  /* Compute call clobbering information.  */\n+  compute_call_clobbered (ai);\n+\n   /* If the program has too many call-clobbered variables and/or function\n      calls, create .GLOBAL_VAR and use it to model call-clobbering\n      semantics at call sites.  This reduces the number of virtual operands\n@@ -703,20 +991,6 @@ compute_flow_sensitive_aliasing (struct alias_info *ai)\n       var_ann_t v_ann = var_ann (SSA_NAME_VAR (ptr));\n       bitmap_iterator bi;\n \n-      if (pi->value_escapes_p || pi->pt_anything)\n-\t{\n-\t  /* If PTR escapes or may point to anything, then its associated\n-\t     memory tags and pointed-to variables are call-clobbered.  */\n-\t  if (pi->name_mem_tag)\n-\t    mark_call_clobbered (pi->name_mem_tag);\n-\n-\t  if (v_ann->type_mem_tag)\n-\t    mark_call_clobbered (v_ann->type_mem_tag);\n-\n-\t  if (pi->pt_vars)\n-\t    EXECUTE_IF_SET_IN_BITMAP (pi->pt_vars, 0, j, bi)\n-\t      mark_call_clobbered (referenced_var (j));\n-\t}\n \n       /* Set up aliasing information for PTR's name memory tag (if it has\n \t one).  Note that only pointers that have been dereferenced will\n@@ -727,13 +1001,6 @@ compute_flow_sensitive_aliasing (struct alias_info *ai)\n \t    add_may_alias (pi->name_mem_tag, referenced_var (j));\n \t    add_may_alias (v_ann->type_mem_tag, referenced_var (j));\n \t  }\n-\n-      /* If the name tag is call clobbered, so is the type tag\n-\t associated with the base VAR_DECL.  */\n-      if (pi->name_mem_tag\n-\t  && v_ann->type_mem_tag\n-\t  && is_call_clobbered (pi->name_mem_tag))\n-\tmark_call_clobbered (v_ann->type_mem_tag);\n     }\n }\n \n@@ -897,10 +1164,6 @@ compute_flow_insensitive_aliasing (struct alias_info *ai)\n     fprintf (dump_file, \"\\n%s: Total number of aliased vops: %ld\\n\",\n \t     get_name (current_function_decl),\n \t     ai->total_alias_vops);\n-\n-  /* Determine if we need to enable alias grouping.  */\n-  if (ai->total_alias_vops >= MAX_ALIASED_VOPS)\n-    group_aliases (ai);\n }\n \n \n@@ -1308,12 +1571,6 @@ setup_pointers_and_addressables (struct alias_info *ai)\n \t      if (bitmap_bit_p (ai->dereferenced_ptrs_store, DECL_UID (var)))\n \t\tbitmap_set_bit (ai->written_vars, DECL_UID (tag));\n \n-\t      /* If pointer VAR is a global variable or a PARM_DECL,\n-\t\t then its memory tag should be considered a global\n-\t\t variable.  */\n-\t      if (TREE_CODE (var) == PARM_DECL || is_global_var (var))\n-\t\tmark_call_clobbered (tag);\n-\n \t      /* All the dereferences of pointer VAR count as\n \t\t references of TAG.  Since TAG can be associated with\n \t\t several pointers, add the dereferences of VAR to the\n@@ -1598,16 +1855,6 @@ add_may_alias (tree var, tree alias)\n     if (alias == al)\n       return;\n \n-  /* If VAR is a call-clobbered variable, so is its new ALIAS.\n-     FIXME, call-clobbering should only depend on whether an address\n-     escapes.  It should be independent of aliasing.  */\n-  if (is_call_clobbered (var))\n-    mark_call_clobbered (alias);\n-\n-  /* Likewise.  If ALIAS is call-clobbered, so is VAR.  */\n-  else if (is_call_clobbered (alias))\n-    mark_call_clobbered (var);\n-\n   VEC_safe_push (tree, gc, v_ann->may_aliases, alias);\n   a_ann->is_alias_tag = 1;\n }\n@@ -1620,16 +1867,6 @@ replace_may_alias (tree var, size_t i, tree new_alias)\n {\n   var_ann_t v_ann = var_ann (var);\n   VEC_replace (tree, v_ann->may_aliases, i, new_alias);\n-\n-  /* If VAR is a call-clobbered variable, so is NEW_ALIAS.\n-     FIXME, call-clobbering should only depend on whether an address\n-     escapes.  It should be independent of aliasing.  */\n-  if (is_call_clobbered (var))\n-    mark_call_clobbered (new_alias);\n-\n-  /* Likewise.  If NEW_ALIAS is call-clobbered, so is VAR.  */\n-  else if (is_call_clobbered (new_alias))\n-    mark_call_clobbered (var);\n }\n \n \n@@ -1663,9 +1900,12 @@ set_pt_anything (tree ptr)\n \t3- STMT is an assignment to a non-local variable, or\n \t4- STMT is a return statement.\n \n-   AI points to the alias information collected so far.  */\n+   AI points to the alias information collected so far.  \n \n-bool\n+   Return the type of escape site found, if we found one, or NO_ESCAPE\n+   if none.  */\n+\n+enum escape_type\n is_escape_site (tree stmt, struct alias_info *ai)\n {\n   tree call = get_call_expr_in (stmt);\n@@ -1674,12 +1914,15 @@ is_escape_site (tree stmt, struct alias_info *ai)\n       ai->num_calls_found++;\n \n       if (!TREE_SIDE_EFFECTS (call))\n-\tai->num_pure_const_calls_found++;\n+\t{\n+\t  ai->num_pure_const_calls_found++;\n+\t  return ESCAPE_TO_PURE_CONST;\n+\t}\n \n-      return true;\n+      return ESCAPE_TO_CALL;\n     }\n   else if (TREE_CODE (stmt) == ASM_EXPR)\n-    return true;\n+    return ESCAPE_TO_ASM;\n   else if (TREE_CODE (stmt) == MODIFY_EXPR)\n     {\n       tree lhs = TREE_OPERAND (stmt, 0);\n@@ -1691,7 +1934,7 @@ is_escape_site (tree stmt, struct alias_info *ai)\n       /* If we couldn't recognize the LHS of the assignment, assume that it\n \t is a non-local store.  */\n       if (lhs == NULL_TREE)\n-\treturn true;\n+\treturn ESCAPE_UNKNOWN;\n \n       /* If the RHS is a conversion between a pointer and an integer, the\n \t pointer escapes since we can't track the integer.  */\n@@ -1701,12 +1944,12 @@ is_escape_site (tree stmt, struct alias_info *ai)\n \t  && POINTER_TYPE_P (TREE_TYPE (TREE_OPERAND\n \t\t\t\t\t(TREE_OPERAND (stmt, 1), 0)))\n \t  && !POINTER_TYPE_P (TREE_TYPE (TREE_OPERAND (stmt, 1))))\n-\treturn true;\n+\treturn ESCAPE_BAD_CAST;\n \n       /* If the LHS is an SSA name, it can't possibly represent a non-local\n \t memory store.  */\n       if (TREE_CODE (lhs) == SSA_NAME)\n-\treturn false;\n+\treturn NO_ESCAPE;\n \n       /* FIXME: LHS is not an SSA_NAME.  Even if it's an assignment to a\n \t local variables we cannot be sure if it will escape, because we\n@@ -1717,12 +1960,12 @@ is_escape_site (tree stmt, struct alias_info *ai)\n \t Midkiff, ``Escape analysis for java,'' in Proceedings of the\n \t Conference on Object-Oriented Programming Systems, Languages, and\n \t Applications (OOPSLA), pp. 1-19, 1999.  */\n-      return true;\n+      return ESCAPE_STORED_IN_GLOBAL;\n     }\n   else if (TREE_CODE (stmt) == RETURN_EXPR)\n-    return true;\n+    return ESCAPE_TO_RETURN;\n \n-  return false;\n+  return NO_ESCAPE;\n }\n \n /* Create a new memory tag of type TYPE.\n@@ -1793,13 +2036,6 @@ get_nmt_for (tree ptr)\n \n   if (tag == NULL_TREE)\n     tag = create_memory_tag (TREE_TYPE (TREE_TYPE (ptr)), false);\n-\n-  /* If PTR is a PARM_DECL, it points to a global variable or malloc,\n-     then its name tag should be considered a global variable.  */\n-  if (TREE_CODE (SSA_NAME_VAR (ptr)) == PARM_DECL\n-      || pi->pt_global_mem)\n-    mark_call_clobbered (tag);\n-\n   return tag;\n }\n \n@@ -1896,6 +2132,8 @@ create_global_var (void)\n   TREE_THIS_VOLATILE (global_var) = 0;\n   TREE_ADDRESSABLE (global_var) = 0;\n \n+  create_var_ann (global_var);\n+  mark_call_clobbered (global_var, ESCAPE_UNKNOWN);\n   add_referenced_tmp_var (global_var);\n   mark_sym_for_renaming (global_var);\n }"}, {"sha": "57cfedc020231cd4368e380b6d1c6ca1e25e37f9", "filename": "gcc/tree-ssa-operands.c", "status": "modified", "additions": 109, "deletions": 122, "changes": 231, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-operands.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-operands.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-operands.c?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -119,14 +119,8 @@ static VEC(tree,heap) *build_vuses;\n /* Array for building all the v_must_def operands.  */\n static VEC(tree,heap) *build_v_must_defs;\n \n-/* True if the operands for call clobbered vars are cached and valid.  */\n-bool ssa_call_clobbered_cache_valid;\n-bool ssa_ro_call_cache_valid;\n \n /* These arrays are the cached operand vectors for call clobbered calls.  */\n-static VEC(tree,heap) *clobbered_v_may_defs;\n-static VEC(tree,heap) *clobbered_vuses;\n-static VEC(tree,heap) *ro_call_vuses;\n static bool ops_active = false;\n \n static GTY (()) struct ssa_operand_memory_d *operand_memory = NULL;\n@@ -142,7 +136,7 @@ static inline void append_use (tree *);\n static void append_v_may_def (tree);\n static void append_v_must_def (tree);\n static void add_call_clobber_ops (tree, tree);\n-static void add_call_read_ops (tree);\n+static void add_call_read_ops (tree, tree);\n static void add_stmt_operand (tree *, stmt_ann_t, int);\n static void build_ssa_operands (tree stmt);\n                                                                                 \n@@ -220,7 +214,34 @@ ssa_operands_active (void)\n   return ops_active;\n }\n \n+/* Structure storing statistics on how many call clobbers we have, and\n+   how many where avoided.  */\n+static struct \n+{\n+  /* Number of call-clobbered ops we attempt to add to calls in\n+     add_call_clobber_ops.  */\n+  unsigned int clobbered_vars;\n+\n+  /* Number of write-clobbers (v_may_defs) avoided by using\n+     not_written information.  */\n+  unsigned int static_write_clobbers_avoided;\n+\n+  /* Number of reads (vuses) avoided by using not_read\n+     information.  */\n+  unsigned int static_read_clobbers_avoided;\n+  \n+  /* Number of write-clobbers avoided because the variable can't escape to\n+     this call.  */\n+  unsigned int unescapable_clobbers_avoided;\n \n+  /* Number of readonly uses we attempt to add to calls in\n+     add_call_read_ops.  */\n+  unsigned int readonly_clobbers;\n+\n+  /* Number of readonly uses we avoid using not_read information.  */\n+  unsigned int static_readonly_clobbers_avoided;\n+} clobber_stats;\n+  \n /* Initialize the operand cache routines.  */\n \n void\n@@ -235,6 +256,8 @@ init_ssa_operands (void)\n   gcc_assert (operand_memory == NULL);\n   operand_memory_index = SSA_OPERAND_MEMORY_SIZE;\n   ops_active = true;\n+  memset (&clobber_stats, 0, sizeof (clobber_stats));\n+  \n }\n \n \n@@ -260,10 +283,17 @@ fini_ssa_operands (void)\n       ggc_free (ptr);\n     }\n \n-  VEC_free (tree, heap, clobbered_v_may_defs);\n-  VEC_free (tree, heap, clobbered_vuses);\n-  VEC_free (tree, heap, ro_call_vuses);\n   ops_active = false;\n+  \n+  if (dump_file && (dump_flags & TDF_STATS))\n+    {\n+      fprintf (dump_file, \"Original clobbered vars:%d\\n\", clobber_stats.clobbered_vars);\n+      fprintf (dump_file, \"Static write clobbers avoided:%d\\n\", clobber_stats.static_write_clobbers_avoided);\n+      fprintf (dump_file, \"Static read clobbers avoided:%d\\n\", clobber_stats.static_read_clobbers_avoided);\n+      fprintf (dump_file, \"Unescapable clobbers avoided:%d\\n\", clobber_stats.unescapable_clobbers_avoided);\n+      fprintf (dump_file, \"Original readonly clobbers:%d\\n\", clobber_stats.readonly_clobbers);\n+      fprintf (dump_file, \"Static readonly clobbers avoided:%d\\n\", clobber_stats.static_readonly_clobbers_avoided);\n+    }\n }\n \n \n@@ -1528,7 +1558,7 @@ get_call_expr_operands (tree stmt, tree expr)\n \t  && !(call_flags & (ECF_PURE | ECF_CONST | ECF_NORETURN)))\n \tadd_call_clobber_ops (stmt, get_callee_fndecl (expr));\n       else if (!(call_flags & ECF_CONST))\n-\tadd_call_read_ops (stmt);\n+\tadd_call_read_ops (stmt, get_callee_fndecl (expr));\n     }\n \n   /* Find uses in the called function.  */\n@@ -1715,20 +1745,17 @@ add_to_addressable_set (tree ref, bitmap *addresses_taken)\n     }\n }\n \n-\n /* Add clobbering definitions for .GLOBAL_VAR or for each of the call\n    clobbered variables in the function.  */\n \n static void\n add_call_clobber_ops (tree stmt, tree callee)\n {\n   unsigned u;\n-  tree t;\n   bitmap_iterator bi;\n   stmt_ann_t s_ann = stmt_ann (stmt);\n-  struct stmt_ann_d empty_ann;\n   bitmap not_read_b, not_written_b;\n-\n+  \n   /* Functions that are not const, pure or never return may clobber\n      call-clobbered variables.  */\n   if (s_ann)\n@@ -1742,114 +1769,80 @@ add_call_clobber_ops (tree stmt, tree callee)\n       return;\n     }\n \n-  /* FIXME - if we have better information from the static vars\n-     analysis, we need to make the cache call site specific.  This way\n-     we can have the performance benefits even if we are doing good\n-     optimization.  */\n-\n   /* Get info for local and module level statics.  There is a bit\n      set for each static if the call being processed does not read\n      or write that variable.  */\n \n   not_read_b = callee ? ipa_reference_get_not_read_global (callee) : NULL; \n   not_written_b = callee ? ipa_reference_get_not_written_global (callee) : NULL; \n-\n-  /* If cache is valid, copy the elements into the build vectors.  */\n-  if (ssa_call_clobbered_cache_valid\n-      && (!not_read_b || bitmap_empty_p (not_read_b))\n-      && (!not_written_b || bitmap_empty_p (not_written_b)))\n-    {\n-      for (u = 0 ; u < VEC_length (tree, clobbered_vuses); u++)\n-\t{\n-\t  t = VEC_index (tree, clobbered_vuses, u);\n-\t  gcc_assert (TREE_CODE (t) != SSA_NAME);\n-\t  var_ann (t)->in_vuse_list = 1;\n-\t  VEC_safe_push (tree, heap, build_vuses, (tree)t);\n-\t}\n-      for (u = 0; u < VEC_length (tree, clobbered_v_may_defs); u++)\n-\t{\n-\t  t = VEC_index (tree, clobbered_v_may_defs, u);\n-\t  gcc_assert (TREE_CODE (t) != SSA_NAME);\n-\t  var_ann (t)->in_v_may_def_list = 1;\n-\t  VEC_safe_push (tree, heap, build_v_may_defs, (tree)t);\n-\t}\n-      return;\n-    }\n-\n-  memset (&empty_ann, 0, sizeof (struct stmt_ann_d));\n-\n   /* Add a V_MAY_DEF operand for every call clobbered variable.  */\n   EXECUTE_IF_SET_IN_BITMAP (call_clobbered_vars, 0, u, bi)\n     {\n-      tree var = referenced_var (u);\n-      unsigned int uid = u;\n+      tree var = referenced_var_lookup (u);\n+      unsigned int escape_mask = var_ann (var)->escape_mask;\n+      tree real_var = var;\n+      bool not_read;\n+      bool not_written;\n+      \n+      /* Not read and not written are computed on regular vars, not\n+\t subvars, so look at the parent var if this is an SFT. */\n \n-      if (unmodifiable_var_p (var))\n-\tadd_stmt_operand (&var, &empty_ann, opf_none);\n-      else\n+      if (TREE_CODE (var) == STRUCT_FIELD_TAG)\n+\treal_var = SFT_PARENT_VAR (var);\n+\n+      not_read = not_read_b ? bitmap_bit_p (not_read_b, \n+\t\t\t\t\t    DECL_UID (real_var)) : false;\n+      not_written = not_written_b ? bitmap_bit_p (not_written_b, \n+\t\t\t\t\t\t  DECL_UID (real_var)) : false;\n+      gcc_assert (!unmodifiable_var_p (var));\n+      \n+      clobber_stats.clobbered_vars++;\n+\n+      /* See if this variable is really clobbered by this function.  */\n+\n+      /* Trivial case: Things escaping only to pure/const are not\n+\t clobbered by non-pure-const, and only read by pure/const. */\n+      if ((escape_mask & ~(ESCAPE_TO_PURE_CONST)) == 0)\n \t{\n-\t  bool not_read;\n-\t  bool not_written;\n-\t  \n-\t  /* Not read and not written are computed on regular vars, not\n-\t     subvars, so look at the parent var if this is an SFT. */\n-\t  \n-\t  if (TREE_CODE (var) == STRUCT_FIELD_TAG)\n-\t    uid = DECL_UID (SFT_PARENT_VAR (var));\n-\n-\t  not_read = \n-\t    not_read_b ? bitmap_bit_p (not_read_b, uid) : false;\n-\t  not_written = \n-\t    not_written_b ? bitmap_bit_p (not_written_b, uid) : false;\n-\n-\t  if (not_written)\n+\t  tree call = get_call_expr_in (stmt);\n+\t  if (call_expr_flags (call) & (ECF_CONST | ECF_PURE))\n \t    {\n-\t      if (!not_read)\n-\t\tadd_stmt_operand (&var, &empty_ann, opf_none);\n+\t      add_stmt_operand (&var, s_ann, opf_none);\n+\t      clobber_stats.unescapable_clobbers_avoided++;\n+\t      continue;\n \t    }\n \t  else\n-\t    add_stmt_operand (&var, &empty_ann, opf_is_def);\n+\t    {\n+\t      clobber_stats.unescapable_clobbers_avoided++;\n+\t      continue;\n+\t    }\n \t}\n+            \n+      if (not_written)\n+\t{\n+\t  clobber_stats.static_write_clobbers_avoided++;\n+\t  if (!not_read)\n+\t    add_stmt_operand (&var, s_ann, opf_none);\n+\t  else\n+\t    clobber_stats.static_read_clobbers_avoided++;\n+\t}\n+      else\n+\tadd_stmt_operand (&var, s_ann, opf_is_def);\n     }\n-\n-  if ((!not_read_b || bitmap_empty_p (not_read_b))\n-      && (!not_written_b || bitmap_empty_p (not_written_b)))\n-    {\n-      /* Prepare empty cache vectors.  */\n-      VEC_truncate (tree, clobbered_vuses, 0);\n-      VEC_truncate (tree, clobbered_v_may_defs, 0);\n-\n-      /* Now fill the clobbered cache with the values that have been found.  */\n-      for (u = 0; u < VEC_length (tree, build_vuses); u++)\n-\tVEC_safe_push (tree, heap, clobbered_vuses,\n-\t\t       VEC_index (tree, build_vuses, u));\n-\n-      gcc_assert (VEC_length (tree, build_vuses) \n-\t\t  == VEC_length (tree, clobbered_vuses));\n-\n-      for (u = 0; u < VEC_length (tree, build_v_may_defs); u++)\n-\tVEC_safe_push (tree, heap, clobbered_v_may_defs, \n-\t\t       VEC_index (tree, build_v_may_defs, u));\n-\n-      gcc_assert (VEC_length (tree, build_v_may_defs) \n-\t\t  == VEC_length (tree, clobbered_v_may_defs));\n-\n-      ssa_call_clobbered_cache_valid = true;\n-    }\n+  \n }\n \n \n /* Add VUSE operands for .GLOBAL_VAR or all call clobbered variables in the\n    function.  */\n \n static void\n-add_call_read_ops (tree stmt)\n+add_call_read_ops (tree stmt, tree callee)\n {\n   unsigned u;\n-  tree t;\n   bitmap_iterator bi;\n   stmt_ann_t s_ann = stmt_ann (stmt);\n-  struct stmt_ann_d empty_ann;\n+  bitmap not_read_b;\n \n   /* if the function is not pure, it may reference memory.  Add\n      a VUSE for .GLOBAL_VAR if it has been created.  See add_referenced_var\n@@ -1860,40 +1853,34 @@ add_call_read_ops (tree stmt)\n       return;\n     }\n   \n-  /* If cache is valid, copy the elements into the build vector.  */\n-  if (ssa_ro_call_cache_valid)\n-    {\n-      for (u = 0; u < VEC_length (tree, ro_call_vuses); u++)\n-\t{\n-\t  t = VEC_index (tree, ro_call_vuses, u);\n-\t  gcc_assert (TREE_CODE (t) != SSA_NAME);\n-\t  var_ann (t)->in_vuse_list = 1;\n-\t  VEC_safe_push (tree, heap, build_vuses, (tree)t);\n-\t}\n-      return;\n-    }\n-\n-  memset (&empty_ann, 0, sizeof (struct stmt_ann_d));\n+  not_read_b = callee ? ipa_reference_get_not_read_global (callee) : NULL; \n \n   /* Add a VUSE for each call-clobbered variable.  */\n   EXECUTE_IF_SET_IN_BITMAP (call_clobbered_vars, 0, u, bi)\n     {\n       tree var = referenced_var (u);\n-      add_stmt_operand (&var, &empty_ann, opf_none | opf_non_specific);\n-    }\n-\n-  /* Prepare empty cache vectors.  */\n-  VEC_truncate (tree, ro_call_vuses, 0);\n+      tree real_var = var;\n+      bool not_read;\n+      \n+      clobber_stats.readonly_clobbers++;\n \n-  /* Now fill the clobbered cache with the values that have been found.  */\n-  for (u = 0; u <  VEC_length (tree, build_vuses); u++)\n-    VEC_safe_push (tree, heap, ro_call_vuses,\n-\t\t   VEC_index (tree, build_vuses, u));\n+      /* Not read and not written are computed on regular vars, not\n+\t subvars, so look at the parent var if this is an SFT. */\n \n-  gcc_assert (VEC_length (tree, build_vuses) \n-\t      == VEC_length (tree, ro_call_vuses));\n+      if (TREE_CODE (var) == STRUCT_FIELD_TAG)\n+\treal_var = SFT_PARENT_VAR (var);\n \n-  ssa_ro_call_cache_valid = true;\n+      not_read = not_read_b ? bitmap_bit_p (not_read_b, \n+\t\t\t\t\t    DECL_UID (real_var)) : false;\n+      \n+      if (not_read)\n+\t{\n+\t  clobber_stats.static_readonly_clobbers_avoided++;\n+\t  continue;\n+\t}\n+            \n+      add_stmt_operand (&var, s_ann, opf_none | opf_non_specific);\n+    }\n }\n \n "}, {"sha": "daf2dce05f7477e27e45013f3290f43f2f998307", "filename": "gcc/tree-ssa-operands.h", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-operands.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-operands.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-operands.h?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -165,9 +165,6 @@ extern void dump_immediate_uses_for (FILE *file, tree var);\n extern void debug_immediate_uses (void);\n extern void debug_immediate_uses_for (tree var);\n \n-extern bool ssa_call_clobbered_cache_valid;\n-extern bool ssa_ro_call_cache_valid;\n-\n extern bool ssa_operands_active (void);\n \n extern void add_to_addressable_set (tree, bitmap *);"}, {"sha": "923bdb77b3cfdd262f79a6bc06ae158523dcb370", "filename": "gcc/tree-ssa-structalias.c", "status": "modified", "additions": 9, "deletions": 4, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-structalias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-structalias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-structalias.c?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -2953,7 +2953,7 @@ update_alias_info (tree stmt, struct alias_info *ai)\n   bitmap addr_taken;\n   use_operand_p use_p;\n   ssa_op_iter iter;\n-  bool stmt_escapes_p = is_escape_site (stmt, ai);\n+  enum escape_type stmt_escape_type = is_escape_site (stmt, ai);\n   tree op;\n \n   /* Mark all the variables whose address are taken by the statement.  */\n@@ -2964,13 +2964,17 @@ update_alias_info (tree stmt, struct alias_info *ai)\n \n       /* If STMT is an escape point, all the addresses taken by it are\n \t call-clobbered.  */\n-      if (stmt_escapes_p)\n+      if (stmt_escape_type != NO_ESCAPE)\n \t{\n \t  bitmap_iterator bi;\n \t  unsigned i;\n \n \t  EXECUTE_IF_SET_IN_BITMAP (addr_taken, 0, i, bi)\n-\t    mark_call_clobbered (referenced_var (i));\n+\t    {\n+\t      tree rvar = referenced_var (i);\n+\t      if (!unmodifiable_var_p (rvar))\n+\t\tmark_call_clobbered (rvar, stmt_escape_type);\n+\t    }\n \t}\n     }\n \n@@ -3094,13 +3098,14 @@ update_alias_info (tree stmt, struct alias_info *ai)\n \t    bitmap_set_bit (ai->dereferenced_ptrs_load, DECL_UID (var));\n \t}\n \n-      if (stmt_escapes_p && num_derefs < num_uses)\n+      if (stmt_escape_type != NO_ESCAPE && num_derefs < num_uses)\n \t{\n \t  /* If STMT is an escape point and STMT contains at\n \t     least one direct use of OP, then the value of OP\n \t     escapes and so the pointed-to variables need to\n \t     be marked call-clobbered.  */\n \t  pi->value_escapes_p = 1;\n+\t  pi->escape_mask |= stmt_escape_type;\n \n \t  /* If the statement makes a function call, assume\n \t     that pointer OP will be dereferenced in a store"}, {"sha": "bc129dde13461386b15952e0bad27fabe2d9bfd7", "filename": "gcc/tree-ssa-structalias.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-structalias.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d16a5e36692853e74ed97c362b41fdca8d69752e/gcc%2Ftree-ssa-structalias.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-structalias.h?ref=d16a5e36692853e74ed97c362b41fdca8d69752e", "patch": "@@ -80,7 +80,7 @@ struct alias_info\n #define NUM_REFERENCES_SET(ANN, VAL) (ANN)->common.aux = (void*) ((void *)(VAL))\n \n /* In tree-ssa-alias.c.  */\n-bool is_escape_site (tree, struct alias_info *);\n+enum escape_type is_escape_site (tree, struct alias_info *);\n \n /* In tree-ssa-structalias.c.  */\n extern void compute_points_to_sets (struct alias_info *);"}]}