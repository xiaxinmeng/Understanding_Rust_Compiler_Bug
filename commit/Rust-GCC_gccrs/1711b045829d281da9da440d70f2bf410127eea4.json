{"sha": "1711b045829d281da9da440d70f2bf410127eea4", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTcxMWIwNDU4MjlkMjgxZGE5ZGE0NDBkNzBmMmJmNDEwMTI3ZWVhNA==", "commit": {"author": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-07-21T15:55:01Z"}, "committer": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-07-23T11:16:13Z"}, "message": "aarch64: Use memcpy to copy vector tables in vst1[q]_x4 intrinsics\n\nUse __builtin_memcpy to copy vector structures instead of using a\nunion in each of the vst1[q]_x4 Neon intrinsics in arm_neon.h.\n\nAdd new code generation tests to verify that superfluous move\ninstructions are not generated for the vst1q_x4 intrinsics.\n\ngcc/ChangeLog:\n\n2021-07-21  Jonathan Wright  <jonathan.wright@arm.com>\n\n\t* config/aarch64/arm_neon.h (vst1_s8_x4): Use\n\t__builtin_memcpy instead of using a union.\n\t(vst1q_s8_x4): Likewise.\n\t(vst1_s16_x4): Likewise.\n\t(vst1q_s16_x4): Likewise.\n\t(vst1_s32_x4): Likewise.\n\t(vst1q_s32_x4): Likewise.\n\t(vst1_u8_x4): Likewise.\n\t(vst1q_u8_x4): Likewise.\n\t(vst1_u16_x4): Likewise.\n\t(vst1q_u16_x4): Likewise.\n\t(vst1_u32_x4): Likewise.\n\t(vst1q_u32_x4): Likewise.\n\t(vst1_f16_x4): Likewise.\n\t(vst1q_f16_x4): Likewise.\n\t(vst1_f32_x4): Likewise.\n\t(vst1q_f32_x4): Likewise.\n\t(vst1_p8_x4): Likewise.\n\t(vst1q_p8_x4): Likewise.\n\t(vst1_p16_x4): Likewise.\n\t(vst1q_p16_x4): Likewise.\n\t(vst1_s64_x4): Likewise.\n\t(vst1_u64_x4): Likewise.\n\t(vst1_p64_x4): Likewise.\n\t(vst1q_s64_x4): Likewise.\n\t(vst1q_u64_x4): Likewise.\n\t(vst1q_p64_x4): Likewise.\n\t(vst1_f64_x4): Likewise.\n\t(vst1q_f64_x4): Likewise.\n\ngcc/testsuite/ChangeLog:\n\n\t* gcc.target/aarch64/vector_structure_intrinsics.c: Add new\n\ttests.", "tree": {"sha": "b77167365a983785dbd10dff437905db1c4b4936", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b77167365a983785dbd10dff437905db1c4b4936"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1711b045829d281da9da440d70f2bf410127eea4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1711b045829d281da9da440d70f2bf410127eea4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1711b045829d281da9da440d70f2bf410127eea4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1711b045829d281da9da440d70f2bf410127eea4/comments", "author": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "03148b8e508ea09ce62259ffb95844182c0b90c6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/03148b8e508ea09ce62259ffb95844182c0b90c6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/03148b8e508ea09ce62259ffb95844182c0b90c6"}], "stats": {"total": 288, "additions": 204, "deletions": 84}, "files": [{"sha": "9cf16a8efa6130c054f5dad5620e72a3deca0743", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 182, "deletions": 84, "changes": 266, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1711b045829d281da9da440d70f2bf410127eea4/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1711b045829d281da9da440d70f2bf410127eea4/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=1711b045829d281da9da440d70f2bf410127eea4", "patch": "@@ -26984,226 +26984,324 @@ vst1q_p64_x3 (poly64_t * __a, poly64x2x3_t __val)\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_s8_x4 (int8_t * __a, int8x8x4_t val)\n+vst1_s8_x4 (int8_t * __a, int8x8x4_t __val)\n {\n-  union { int8x8x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v8qi ((__builtin_aarch64_simd_qi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  int8x16x4_t __temp;\n+  __temp.val[0] = vcombine_s8 (__val.val[0], vcreate_s8 (__AARCH64_INT64_C (0)));\n+  __temp.val[1] = vcombine_s8 (__val.val[1], vcreate_s8 (__AARCH64_INT64_C (0)));\n+  __temp.val[2] = vcombine_s8 (__val.val[2], vcreate_s8 (__AARCH64_INT64_C (0)));\n+  __temp.val[3] = vcombine_s8 (__val.val[3], vcreate_s8 (__AARCH64_INT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v8qi ((__builtin_aarch64_simd_qi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_s8_x4 (int8_t * __a, int8x16x4_t val)\n+vst1q_s8_x4 (int8_t * __a, int8x16x4_t __val)\n {\n-  union { int8x16x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v16qi ((__builtin_aarch64_simd_qi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v16qi ((__builtin_aarch64_simd_qi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_s16_x4 (int16_t * __a, int16x4x4_t val)\n+vst1_s16_x4 (int16_t * __a, int16x4x4_t __val)\n {\n-  union { int16x4x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v4hi ((__builtin_aarch64_simd_hi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  int16x8x4_t __temp;\n+  __temp.val[0] = vcombine_s16 (__val.val[0], vcreate_s16 (__AARCH64_INT64_C (0)));\n+  __temp.val[1] = vcombine_s16 (__val.val[1], vcreate_s16 (__AARCH64_INT64_C (0)));\n+  __temp.val[2] = vcombine_s16 (__val.val[2], vcreate_s16 (__AARCH64_INT64_C (0)));\n+  __temp.val[3] = vcombine_s16 (__val.val[3], vcreate_s16 (__AARCH64_INT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v4hi ((__builtin_aarch64_simd_hi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_s16_x4 (int16_t * __a, int16x8x4_t val)\n+vst1q_s16_x4 (int16_t * __a, int16x8x4_t __val)\n {\n-  union { int16x8x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v8hi ((__builtin_aarch64_simd_hi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v8hi ((__builtin_aarch64_simd_hi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_s32_x4 (int32_t * __a, int32x2x4_t val)\n+vst1_s32_x4 (int32_t * __a, int32x2x4_t __val)\n {\n-  union { int32x2x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v2si ((__builtin_aarch64_simd_si *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  int32x4x4_t __temp;\n+  __temp.val[0] = vcombine_s32 (__val.val[0], vcreate_s32 (__AARCH64_INT64_C (0)));\n+  __temp.val[1] = vcombine_s32 (__val.val[1], vcreate_s32 (__AARCH64_INT64_C (0)));\n+  __temp.val[2] = vcombine_s32 (__val.val[2], vcreate_s32 (__AARCH64_INT64_C (0)));\n+  __temp.val[3] = vcombine_s32 (__val.val[3], vcreate_s32 (__AARCH64_INT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v2si ((__builtin_aarch64_simd_si *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_s32_x4 (int32_t * __a, int32x4x4_t val)\n+vst1q_s32_x4 (int32_t * __a, int32x4x4_t __val)\n {\n-  union { int32x4x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v4si ((__builtin_aarch64_simd_si *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v4si ((__builtin_aarch64_simd_si *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_u8_x4 (uint8_t * __a, uint8x8x4_t val)\n+vst1_u8_x4 (uint8_t * __a, uint8x8x4_t __val)\n {\n-  union { uint8x8x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v8qi ((__builtin_aarch64_simd_qi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  uint8x16x4_t __temp;\n+  __temp.val[0] = vcombine_u8 (__val.val[0], vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u8 (__val.val[1], vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u8 (__val.val[2], vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u8 (__val.val[3], vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v8qi ((__builtin_aarch64_simd_qi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_u8_x4 (uint8_t * __a, uint8x16x4_t val)\n+vst1q_u8_x4 (uint8_t * __a, uint8x16x4_t __val)\n {\n-  union { uint8x16x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v16qi ((__builtin_aarch64_simd_qi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v16qi ((__builtin_aarch64_simd_qi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_u16_x4 (uint16_t * __a, uint16x4x4_t val)\n+vst1_u16_x4 (uint16_t * __a, uint16x4x4_t __val)\n {\n-  union { uint16x4x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v4hi ((__builtin_aarch64_simd_hi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  uint16x8x4_t __temp;\n+  __temp.val[0] = vcombine_u16 (__val.val[0], vcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u16 (__val.val[1], vcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u16 (__val.val[2], vcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u16 (__val.val[3], vcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v4hi ((__builtin_aarch64_simd_hi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_u16_x4 (uint16_t * __a, uint16x8x4_t val)\n+vst1q_u16_x4 (uint16_t * __a, uint16x8x4_t __val)\n {\n-  union { uint16x8x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v8hi ((__builtin_aarch64_simd_hi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v8hi ((__builtin_aarch64_simd_hi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_u32_x4 (uint32_t * __a, uint32x2x4_t val)\n+vst1_u32_x4 (uint32_t * __a, uint32x2x4_t __val)\n {\n-  union { uint32x2x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v2si ((__builtin_aarch64_simd_si *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  uint32x4x4_t __temp;\n+  __temp.val[0] = vcombine_u32 (__val.val[0], vcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u32 (__val.val[1], vcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u32 (__val.val[2], vcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u32 (__val.val[3], vcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v2si ((__builtin_aarch64_simd_si *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_u32_x4 (uint32_t * __a, uint32x4x4_t val)\n+vst1q_u32_x4 (uint32_t * __a, uint32x4x4_t __val)\n {\n-  union { uint32x4x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v4si ((__builtin_aarch64_simd_si *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v4si ((__builtin_aarch64_simd_si *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_f16_x4 (float16_t * __a, float16x4x4_t val)\n+vst1_f16_x4 (float16_t * __a, float16x4x4_t __val)\n {\n-  union { float16x4x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v4hf ((__builtin_aarch64_simd_hf *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  float16x8x4_t __temp;\n+  __temp.val[0] = vcombine_f16 (__val.val[0], vcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_f16 (__val.val[1], vcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_f16 (__val.val[2], vcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_f16 (__val.val[3], vcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v4hf ((__builtin_aarch64_simd_hf *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_f16_x4 (float16_t * __a, float16x8x4_t val)\n+vst1q_f16_x4 (float16_t * __a, float16x8x4_t __val)\n {\n-  union { float16x8x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v8hf ((__builtin_aarch64_simd_hf *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v8hf ((__builtin_aarch64_simd_hf *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_f32_x4 (float32_t * __a, float32x2x4_t val)\n+vst1_f32_x4 (float32_t * __a, float32x2x4_t __val)\n {\n-  union { float32x2x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v2sf ((__builtin_aarch64_simd_sf *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  float32x4x4_t __temp;\n+  __temp.val[0] = vcombine_f32 (__val.val[0], vcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_f32 (__val.val[1], vcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_f32 (__val.val[2], vcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_f32 (__val.val[3], vcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v2sf ((__builtin_aarch64_simd_sf *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_f32_x4 (float32_t * __a, float32x4x4_t val)\n+vst1q_f32_x4 (float32_t * __a, float32x4x4_t __val)\n {\n-  union { float32x4x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v4sf ((__builtin_aarch64_simd_sf *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v4sf ((__builtin_aarch64_simd_sf *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_p8_x4 (poly8_t * __a, poly8x8x4_t val)\n+vst1_p8_x4 (poly8_t * __a, poly8x8x4_t __val)\n {\n-  union { poly8x8x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v8qi ((__builtin_aarch64_simd_qi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  poly8x16x4_t __temp;\n+  __temp.val[0] = vcombine_p8 (__val.val[0], vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_p8 (__val.val[1], vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_p8 (__val.val[2], vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_p8 (__val.val[3], vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v8qi ((__builtin_aarch64_simd_qi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_p8_x4 (poly8_t * __a, poly8x16x4_t val)\n+vst1q_p8_x4 (poly8_t * __a, poly8x16x4_t __val)\n {\n-  union { poly8x16x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v16qi ((__builtin_aarch64_simd_qi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v16qi ((__builtin_aarch64_simd_qi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_p16_x4 (poly16_t * __a, poly16x4x4_t val)\n+vst1_p16_x4 (poly16_t * __a, poly16x4x4_t __val)\n {\n-  union { poly16x4x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v4hi ((__builtin_aarch64_simd_hi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  poly16x8x4_t __temp;\n+  __temp.val[0] = vcombine_p16 (__val.val[0], vcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_p16 (__val.val[1], vcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_p16 (__val.val[2], vcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_p16 (__val.val[3], vcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4v4hi ((__builtin_aarch64_simd_hi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_p16_x4 (poly16_t * __a, poly16x8x4_t val)\n+vst1q_p16_x4 (poly16_t * __a, poly16x8x4_t __val)\n {\n-  union { poly16x8x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v8hi ((__builtin_aarch64_simd_hi *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v8hi ((__builtin_aarch64_simd_hi *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_s64_x4 (int64_t * __a, int64x1x4_t val)\n+vst1_s64_x4 (int64_t * __a, int64x1x4_t __val)\n {\n-  union { int64x1x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4di ((__builtin_aarch64_simd_di *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  int64x2x4_t __temp;\n+  __temp.val[0] = vcombine_s64 (__val.val[0], vcreate_s64 (__AARCH64_INT64_C (0)));\n+  __temp.val[1] = vcombine_s64 (__val.val[1], vcreate_s64 (__AARCH64_INT64_C (0)));\n+  __temp.val[2] = vcombine_s64 (__val.val[2], vcreate_s64 (__AARCH64_INT64_C (0)));\n+  __temp.val[3] = vcombine_s64 (__val.val[3], vcreate_s64 (__AARCH64_INT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4di ((__builtin_aarch64_simd_di *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_u64_x4 (uint64_t * __a, uint64x1x4_t val)\n+vst1_u64_x4 (uint64_t * __a, uint64x1x4_t __val)\n {\n-  union { uint64x1x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4di ((__builtin_aarch64_simd_di *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  uint64x2x4_t __temp;\n+  __temp.val[0] = vcombine_u64 (__val.val[0], vcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u64 (__val.val[1], vcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u64 (__val.val[2], vcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u64 (__val.val[3], vcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4di ((__builtin_aarch64_simd_di *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_p64_x4 (poly64_t * __a, poly64x1x4_t val)\n+vst1_p64_x4 (poly64_t * __a, poly64x1x4_t __val)\n {\n-  union { poly64x1x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4di ((__builtin_aarch64_simd_di *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  poly64x2x4_t __temp;\n+  __temp.val[0] = vcombine_p64 (__val.val[0], vcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_p64 (__val.val[1], vcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_p64 (__val.val[2], vcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_p64 (__val.val[3], vcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4di ((__builtin_aarch64_simd_di *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_s64_x4 (int64_t * __a, int64x2x4_t val)\n+vst1q_s64_x4 (int64_t * __a, int64x2x4_t __val)\n {\n-  union { int64x2x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v2di ((__builtin_aarch64_simd_di *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v2di ((__builtin_aarch64_simd_di *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_u64_x4 (uint64_t * __a, uint64x2x4_t val)\n+vst1q_u64_x4 (uint64_t * __a, uint64x2x4_t __val)\n {\n-  union { uint64x2x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v2di ((__builtin_aarch64_simd_di *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v2di ((__builtin_aarch64_simd_di *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_p64_x4 (poly64_t * __a, poly64x2x4_t val)\n+vst1q_p64_x4 (poly64_t * __a, poly64x2x4_t __val)\n {\n-  union { poly64x2x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v2di ((__builtin_aarch64_simd_di *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v2di ((__builtin_aarch64_simd_di *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1_f64_x4 (float64_t * __a, float64x1x4_t val)\n+vst1_f64_x4 (float64_t * __a, float64x1x4_t __val)\n {\n-  union { float64x1x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4df ((__builtin_aarch64_simd_df *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  float64x2x4_t __temp;\n+  __temp.val[0] = vcombine_f64 (__val.val[0], vcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_f64 (__val.val[1], vcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_f64 (__val.val[2], vcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_f64 (__val.val[3], vcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st1x4df ((__builtin_aarch64_simd_df *) __a, __o);\n }\n \n __extension__ extern __inline void\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n-vst1q_f64_x4 (float64_t * __a, float64x2x4_t val)\n+vst1q_f64_x4 (float64_t * __a, float64x2x4_t __val)\n {\n-  union { float64x2x4_t __i; __builtin_aarch64_simd_xi __o; } __u = { val };\n-  __builtin_aarch64_st1x4v2df ((__builtin_aarch64_simd_df *) __a, __u.__o);\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st1x4v2df ((__builtin_aarch64_simd_df *) __a, __o);\n }\n \n /* vstn */"}, {"sha": "6537f68178e73816e31d641fa933334a22d0fd9d", "filename": "gcc/testsuite/gcc.target/aarch64/vector_structure_intrinsics.c", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1711b045829d281da9da440d70f2bf410127eea4/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1711b045829d281da9da440d70f2bf410127eea4/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c?ref=1711b045829d281da9da440d70f2bf410127eea4", "patch": "@@ -139,10 +139,32 @@ TEST_ST3 (vst3q, uint64x2x3_t, uint64_t*, u64);\n TEST_ST3 (vst3q, float64x2x3_t, float64_t*, f64);\n TEST_ST3 (vst3q, poly64x2x3_t, poly64_t*, p64);\n \n+#define TEST_ST1xN(name, tbltype, ptrtype, ts, xn) \\\n+  void test_ ## name ## _ ## ts ## _ ## xn (ptrtype a, tbltype b) \\\n+\t{ \\\n+\t\tname ## _ ## ts ## _ ## xn (a, b); \\\n+\t}\n+\n+TEST_ST1xN (vst1q, int8x16x4_t, int8_t*, s8, x4);\n+TEST_ST1xN (vst1q, uint8x16x4_t, uint8_t*, u8, x4);\n+TEST_ST1xN (vst1q, poly8x16x4_t, poly8_t*, p8, x4);\n+TEST_ST1xN (vst1q, int16x8x4_t, int16_t*, s16, x4);\n+TEST_ST1xN (vst1q, uint16x8x4_t, uint16_t*, u16, x4);\n+TEST_ST1xN (vst1q, poly16x8x4_t, poly16_t*, p16, x4);\n+TEST_ST1xN (vst1q, float16x8x4_t, float16_t*, f16, x4);\n+TEST_ST1xN (vst1q, int32x4x4_t, int32_t*, s32, x4);\n+TEST_ST1xN (vst1q, uint32x4x4_t, uint32_t*, u32, x4);\n+TEST_ST1xN (vst1q, float32x4x4_t, float32_t*, f32, x4);\n+TEST_ST1xN (vst1q, int64x2x4_t, int64_t*, s64, x4);\n+TEST_ST1xN (vst1q, uint64x2x4_t, uint64_t*, u64, x4);\n+TEST_ST1xN (vst1q, poly64x2x4_t, poly64_t*, p64, x4);\n+TEST_ST1xN (vst1q, float64x2x4_t, float64_t*, f64, x4);\n+\n /* { dg-final { scan-assembler-not \"mov\\\\t\" } } */\n \n /* { dg-final { scan-assembler-times \"tbl\\\\t\" 18} }  */\n /* { dg-final { scan-assembler-times \"tbx\\\\t\" 18} }  */\n /* { dg-final { scan-assembler-times \"st4\\\\t\" 14} }  */\n /* { dg-final { scan-assembler-times \"st3\\\\t\" 14} }  */\n /* { dg-final { scan-assembler-times \"st2\\\\t\" 14} }  */\n+/* { dg-final { scan-assembler-times \"st1\\\\t\" 14} }  */"}]}