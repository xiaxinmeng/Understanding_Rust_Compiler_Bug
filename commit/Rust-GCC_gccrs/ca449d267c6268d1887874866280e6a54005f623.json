{"sha": "ca449d267c6268d1887874866280e6a54005f623", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2E0NDlkMjY3YzYyNjhkMTg4Nzg3NDg2NjI4MGU2YTU0MDA1ZjYyMw==", "commit": {"author": {"name": "Jiong Wang", "email": "jiong.wang@arm.com", "date": "2016-05-26T08:37:29Z"}, "committer": {"name": "Jiong Wang", "email": "jiwang@gcc.gnu.org", "date": "2016-05-26T08:37:29Z"}, "message": "[AArch64, testsuite] Fix vmul_elem_1.c on big-endian\n\ngcc/testsuite/\n        * gcc.target/aarch64/simd/vmul_elem_1.c: Force result variables to be\n        kept in memory.\n\nFrom-SVN: r236762", "tree": {"sha": "a18ca5521df493133f4a034f6b5fe22a8ea341aa", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a18ca5521df493133f4a034f6b5fe22a8ea341aa"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ca449d267c6268d1887874866280e6a54005f623", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca449d267c6268d1887874866280e6a54005f623", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ca449d267c6268d1887874866280e6a54005f623", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca449d267c6268d1887874866280e6a54005f623/comments", "author": null, "committer": null, "parents": [{"sha": "9de98f89feb0be9b7aba1e422ed9a2b3048ece0d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9de98f89feb0be9b7aba1e422ed9a2b3048ece0d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9de98f89feb0be9b7aba1e422ed9a2b3048ece0d"}], "stats": {"total": 115, "additions": 71, "deletions": 44}, "files": [{"sha": "8f1d5a78a1e12d5c55c79e1d0ac17beb18cd9592", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca449d267c6268d1887874866280e6a54005f623/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca449d267c6268d1887874866280e6a54005f623/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=ca449d267c6268d1887874866280e6a54005f623", "patch": "@@ -1,3 +1,8 @@\n+2016-05-26  Jiong Wang  <jiong.wang@arm.com>\n+\n+\t* gcc.target/aarch64/simd/vmul_elem_1.c: Force result variables to be\n+\tkept in memory. \n+\n 2016-05-25  Jeff Law  <law@redhat.com>\n \n \tPR tree-optimization/71272"}, {"sha": "a1faefd88bacabadf45bf5a22ca5481db13c41cb", "filename": "gcc/testsuite/gcc.target/aarch64/simd/vmul_elem_1.c", "status": "modified", "additions": 66, "deletions": 44, "changes": 110, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca449d267c6268d1887874866280e6a54005f623/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvmul_elem_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca449d267c6268d1887874866280e6a54005f623/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvmul_elem_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fvmul_elem_1.c?ref=ca449d267c6268d1887874866280e6a54005f623", "patch": "@@ -142,13 +142,15 @@ check_v2sf (float32_t elemA, float32_t elemB)\n   int32_t indx;\n   const float32_t vec32x2_buf[2] = {A, B};\n   float32x2_t vec32x2_src = vld1_f32 (vec32x2_buf);\n-  float32x2_t vec32x2_res = vmul_n_f32 (vec32x2_src, elemA);\n+  float32_t vec32x2_res[2];\n+\n+  vst1_f32 (vec32x2_res, vmul_n_f32 (vec32x2_src, elemA));\n \n   for (indx = 0; indx < 2; indx++)\n     if (* (uint32_t *) &vec32x2_res[indx] != * (uint32_t *) &expected2_1[indx])\n       abort ();\n \n-  vec32x2_res = vmul_n_f32 (vec32x2_src, elemB);\n+  vst1_f32 (vec32x2_res, vmul_n_f32 (vec32x2_src, elemB));\n \n   for (indx = 0; indx < 2; indx++)\n     if (* (uint32_t *) &vec32x2_res[indx] != * (uint32_t *) &expected2_2[indx])\n@@ -163,25 +165,27 @@ check_v4sf (float32_t elemA, float32_t elemB, float32_t elemC, float32_t elemD)\n   int32_t indx;\n   const float32_t vec32x4_buf[4] = {A, B, C, D};\n   float32x4_t vec32x4_src = vld1q_f32 (vec32x4_buf);\n-  float32x4_t vec32x4_res = vmulq_n_f32 (vec32x4_src, elemA);\n+  float32_t vec32x4_res[4];\n+\n+  vst1q_f32 (vec32x4_res, vmulq_n_f32 (vec32x4_src, elemA));\n \n   for (indx = 0; indx < 4; indx++)\n     if (* (uint32_t *) &vec32x4_res[indx] != * (uint32_t *) &expected4_1[indx])\n       abort ();\n \n-  vec32x4_res = vmulq_n_f32 (vec32x4_src, elemB);\n+  vst1q_f32 (vec32x4_res, vmulq_n_f32 (vec32x4_src, elemB));\n \n   for (indx = 0; indx < 4; indx++)\n     if (* (uint32_t *) &vec32x4_res[indx] != * (uint32_t *) &expected4_2[indx])\n       abort ();\n \n-  vec32x4_res = vmulq_n_f32 (vec32x4_src, elemC);\n+  vst1q_f32 (vec32x4_res, vmulq_n_f32 (vec32x4_src, elemC));\n \n   for (indx = 0; indx < 4; indx++)\n     if (* (uint32_t *) &vec32x4_res[indx] != * (uint32_t *) &expected4_3[indx])\n       abort ();\n \n-  vec32x4_res = vmulq_n_f32 (vec32x4_src, elemD);\n+  vst1q_f32 (vec32x4_res, vmulq_n_f32 (vec32x4_src, elemD));\n \n   for (indx = 0; indx < 4; indx++)\n     if (* (uint32_t *) &vec32x4_res[indx] != * (uint32_t *) &expected4_4[indx])\n@@ -196,13 +200,15 @@ check_v2df (float64_t elemdC, float64_t elemdD)\n   int32_t indx;\n   const float64_t vec64x2_buf[2] = {AD, BD};\n   float64x2_t vec64x2_src = vld1q_f64 (vec64x2_buf);\n-  float64x2_t vec64x2_res = vmulq_n_f64 (vec64x2_src, elemdC);\n+  float64_t vec64x2_res[2];\n+\n+  vst1q_f64 (vec64x2_res, vmulq_n_f64 (vec64x2_src, elemdC));\n \n   for (indx = 0; indx < 2; indx++)\n     if (* (uint64_t *) &vec64x2_res[indx] != * (uint64_t *) &expectedd2_1[indx])\n       abort ();\n \n-  vec64x2_res = vmulq_n_f64 (vec64x2_src, elemdD);\n+  vst1q_f64 (vec64x2_res, vmulq_n_f64 (vec64x2_src, elemdD));\n \n   for (indx = 0; indx < 2; indx++)\n     if (* (uint64_t *) &vec64x2_res[indx] != * (uint64_t *) &expectedd2_2[indx])\n@@ -217,13 +223,15 @@ check_v2si (int32_t elemsA, int32_t elemsB)\n   int32_t indx;\n   const int32_t vecs32x2_buf[2] = {AS, BS};\n   int32x2_t vecs32x2_src = vld1_s32 (vecs32x2_buf);\n-  int32x2_t vecs32x2_res = vmul_n_s32 (vecs32x2_src, elemsA);\n+  int32_t vecs32x2_res[2];\n+\n+  vst1_s32 (vecs32x2_res, vmul_n_s32 (vecs32x2_src, elemsA));\n \n   for (indx = 0; indx < 2; indx++)\n     if (vecs32x2_res[indx] != expecteds2_1[indx])\n       abort ();\n \n-  vecs32x2_res = vmul_n_s32 (vecs32x2_src, elemsB);\n+  vst1_s32 (vecs32x2_res, vmul_n_s32 (vecs32x2_src, elemsB));\n \n   for (indx = 0; indx < 2; indx++)\n     if (vecs32x2_res[indx] != expecteds2_2[indx])\n@@ -236,13 +244,15 @@ check_v2si_unsigned (uint32_t elemusA, uint32_t elemusB)\n   int indx;\n   const uint32_t vecus32x2_buf[2] = {AUS, BUS};\n   uint32x2_t vecus32x2_src = vld1_u32 (vecus32x2_buf);\n-  uint32x2_t vecus32x2_res = vmul_n_u32 (vecus32x2_src, elemusA);\n+  uint32_t vecus32x2_res[2];\n+\n+  vst1_u32 (vecus32x2_res, vmul_n_u32 (vecus32x2_src, elemusA));\n \n   for (indx = 0; indx < 2; indx++)\n     if (vecus32x2_res[indx] != expectedus2_1[indx])\n       abort ();\n \n-  vecus32x2_res = vmul_n_u32 (vecus32x2_src, elemusB);\n+  vst1_u32 (vecus32x2_res, vmul_n_u32 (vecus32x2_src, elemusB));\n \n   for (indx = 0; indx < 2; indx++)\n     if (vecus32x2_res[indx] != expectedus2_2[indx])\n@@ -257,25 +267,27 @@ check_v4si (int32_t elemsA, int32_t elemsB, int32_t elemsC, int32_t elemsD)\n   int32_t indx;\n   const int32_t vecs32x4_buf[4] = {AS, BS, CS, DS};\n   int32x4_t vecs32x4_src = vld1q_s32 (vecs32x4_buf);\n-  int32x4_t vecs32x4_res = vmulq_n_s32 (vecs32x4_src, elemsA);\n+  int32_t vecs32x4_res[4];\n+\n+  vst1q_s32 (vecs32x4_res, vmulq_n_s32 (vecs32x4_src, elemsA));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecs32x4_res[indx] != expecteds4_1[indx])\n       abort ();\n \n-  vecs32x4_res = vmulq_n_s32 (vecs32x4_src, elemsB);\n+  vst1q_s32 (vecs32x4_res, vmulq_n_s32 (vecs32x4_src, elemsB));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecs32x4_res[indx] != expecteds4_2[indx])\n       abort ();\n \n-  vecs32x4_res = vmulq_n_s32 (vecs32x4_src, elemsC);\n+  vst1q_s32 (vecs32x4_res, vmulq_n_s32 (vecs32x4_src, elemsC));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecs32x4_res[indx] != expecteds4_3[indx])\n       abort ();\n \n-  vecs32x4_res = vmulq_n_s32 (vecs32x4_src, elemsD);\n+  vst1q_s32 (vecs32x4_res, vmulq_n_s32 (vecs32x4_src, elemsD));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecs32x4_res[indx] != expecteds4_4[indx])\n@@ -289,25 +301,27 @@ check_v4si_unsigned (uint32_t elemusA, uint32_t elemusB, uint32_t elemusC,\n   int indx;\n   const uint32_t vecus32x4_buf[4] = {AUS, BUS, CUS, DUS};\n   uint32x4_t vecus32x4_src = vld1q_u32 (vecus32x4_buf);\n-  uint32x4_t vecus32x4_res = vmulq_n_u32 (vecus32x4_src, elemusA);\n+  uint32_t vecus32x4_res[4];\n+\n+  vst1q_u32 (vecus32x4_res, vmulq_n_u32 (vecus32x4_src, elemusA));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecus32x4_res[indx] != expectedus4_1[indx])\n       abort ();\n \n-  vecus32x4_res = vmulq_n_u32 (vecus32x4_src, elemusB);\n+  vst1q_u32 (vecus32x4_res, vmulq_n_u32 (vecus32x4_src, elemusB));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecus32x4_res[indx] != expectedus4_2[indx])\n       abort ();\n \n-  vecus32x4_res = vmulq_n_u32 (vecus32x4_src, elemusC);\n+  vst1q_u32 (vecus32x4_res, vmulq_n_u32 (vecus32x4_src, elemusC));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecus32x4_res[indx] != expectedus4_3[indx])\n       abort ();\n \n-  vecus32x4_res = vmulq_n_u32 (vecus32x4_src, elemusD);\n+  vst1q_u32 (vecus32x4_res, vmulq_n_u32 (vecus32x4_src, elemusD));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecus32x4_res[indx] != expectedus4_4[indx])\n@@ -323,25 +337,27 @@ check_v4hi (int16_t elemhA, int16_t elemhB, int16_t elemhC, int16_t elemhD)\n   int32_t indx;\n   const int16_t vech16x4_buf[4] = {AH, BH, CH, DH};\n   int16x4_t vech16x4_src = vld1_s16 (vech16x4_buf);\n-  int16x4_t vech16x4_res = vmul_n_s16 (vech16x4_src, elemhA);\n+  int16_t vech16x4_res[4];\n+\n+  vst1_s16 (vech16x4_res, vmul_n_s16 (vech16x4_src, elemhA));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vech16x4_res[indx] != expectedh4_1[indx])\n       abort ();\n \n-  vech16x4_res = vmul_n_s16 (vech16x4_src, elemhB);\n+  vst1_s16 (vech16x4_res, vmul_n_s16 (vech16x4_src, elemhB));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vech16x4_res[indx] != expectedh4_2[indx])\n       abort ();\n \n-  vech16x4_res = vmul_n_s16 (vech16x4_src, elemhC);\n+  vst1_s16 (vech16x4_res, vmul_n_s16 (vech16x4_src, elemhC));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vech16x4_res[indx] != expectedh4_3[indx])\n       abort ();\n \n-  vech16x4_res = vmul_n_s16 (vech16x4_src, elemhD);\n+  vst1_s16 (vech16x4_res, vmul_n_s16 (vech16x4_src, elemhD));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vech16x4_res[indx] != expectedh4_4[indx])\n@@ -355,25 +371,27 @@ check_v4hi_unsigned (uint16_t elemuhA, uint16_t elemuhB, uint16_t elemuhC,\n   int indx;\n   const uint16_t vecuh16x4_buf[4] = {AUH, BUH, CUH, DUH};\n   uint16x4_t vecuh16x4_src = vld1_u16 (vecuh16x4_buf);\n-  uint16x4_t vecuh16x4_res = vmul_n_u16 (vecuh16x4_src, elemuhA);\n+  uint16_t vecuh16x4_res[4];\n+\n+  vst1_u16 (vecuh16x4_res, vmul_n_u16 (vecuh16x4_src, elemuhA));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecuh16x4_res[indx] != expecteduh4_1[indx])\n       abort ();\n \n-  vecuh16x4_res = vmul_n_u16 (vecuh16x4_src, elemuhB);\n+  vst1_u16 (vecuh16x4_res, vmul_n_u16 (vecuh16x4_src, elemuhB));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecuh16x4_res[indx] != expecteduh4_2[indx])\n       abort ();\n \n-  vecuh16x4_res = vmul_n_u16 (vecuh16x4_src, elemuhC);\n+  vst1_u16 (vecuh16x4_res, vmul_n_u16 (vecuh16x4_src, elemuhC));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecuh16x4_res[indx] != expecteduh4_3[indx])\n       abort ();\n \n-  vecuh16x4_res = vmul_n_u16 (vecuh16x4_src, elemuhD);\n+  vst1_u16 (vecuh16x4_res, vmul_n_u16 (vecuh16x4_src, elemuhD));\n \n   for (indx = 0; indx < 4; indx++)\n     if (vecuh16x4_res[indx] != expecteduh4_4[indx])\n@@ -389,49 +407,51 @@ check_v8hi (int16_t elemhA, int16_t elemhB, int16_t elemhC, int16_t elemhD,\n   int32_t indx;\n   const int16_t vech16x8_buf[8] = {AH, BH, CH, DH, EH, FH, GH, HH};\n   int16x8_t vech16x8_src = vld1q_s16 (vech16x8_buf);\n-  int16x8_t vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhA);\n+  int16_t vech16x8_res[8];\n+\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhA));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_1[indx])\n       abort ();\n \n-  vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhB);\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhB));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_2[indx])\n       abort ();\n \n-  vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhC);\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhC));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_3[indx])\n       abort ();\n \n-  vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhD);\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhD));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_4[indx])\n       abort ();\n \n-  vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhE);\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhE));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_5[indx])\n       abort ();\n \n-  vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhF);\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhF));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_6[indx])\n       abort ();\n \n-  vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhG);\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhG));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_7[indx])\n       abort ();\n \n-  vech16x8_res = vmulq_n_s16 (vech16x8_src, elemhH);\n+  vst1q_s16 (vech16x8_res, vmulq_n_s16 (vech16x8_src, elemhH));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vech16x8_res[indx] != expectedh8_8[indx])\n@@ -446,49 +466,51 @@ check_v8hi_unsigned (uint16_t elemuhA, uint16_t elemuhB, uint16_t elemuhC,\n   int indx;\n   const uint16_t vecuh16x8_buf[8] = {AUH, BUH, CUH, DUH, EUH, FUH, GUH, HUH};\n   uint16x8_t vecuh16x8_src = vld1q_u16 (vecuh16x8_buf);\n-  uint16x8_t vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhA);\n+  uint16_t vecuh16x8_res[8];\n+\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhA));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_1[indx])\n       abort ();\n \n-  vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhB);\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhB));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_2[indx])\n       abort ();\n \n-  vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhC);\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhC));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_3[indx])\n       abort ();\n \n-  vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhD);\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhD));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_4[indx])\n       abort ();\n \n-  vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhE);\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhE));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_5[indx])\n       abort ();\n \n-  vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhF);\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhF));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_6[indx])\n       abort ();\n \n-  vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhG);\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhG));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_7[indx])\n       abort ();\n \n-  vecuh16x8_res = vmulq_n_u16 (vecuh16x8_src, elemuhH);\n+  vst1q_u16 (vecuh16x8_res, vmulq_n_u16 (vecuh16x8_src, elemuhH));\n \n   for (indx = 0; indx < 8; indx++)\n     if (vecuh16x8_res[indx] != expecteduh8_8[indx])"}]}