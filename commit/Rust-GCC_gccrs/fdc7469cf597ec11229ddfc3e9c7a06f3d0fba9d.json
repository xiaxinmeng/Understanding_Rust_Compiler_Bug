{"sha": "fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d", "node_id": "C_kwDOANBUbNoAKGZkYzc0NjljZjU5N2VjMTEyMjlkZGZjM2U5YzdhMDZmM2QwZmJhOWQ", "commit": {"author": {"name": "Chung-Lin Tang", "email": "cltang@codesourcery.com", "date": "2022-12-21T13:57:45Z"}, "committer": {"name": "Chung-Lin Tang", "email": "cltang@codesourcery.com", "date": "2022-12-21T13:58:49Z"}, "message": "nvptx: reimplement libgomp barriers [PR99555]\n\nInstead of trying to have the GPU do CPU-with-OS-like things, this new barriers\nimplementation for NVPTX uses simplistic bar.* synchronization instructions.\nTasks are processed after threads have joined, and only if team->task_count != 0\n\nIt is noted that: there might be a little bit of performance forfeited for\ncases where earlier arriving threads could've been used to process tasks ahead\nof other threads, but that has the requirement of implementing complex\nfutex-wait/wake like behavior, which is what we're try to avoid with this patch.\nIt is deemed that task processing is not what GPU target offloading is usually\nused for.\n\nImplementation highlight notes:\n1. gomp_team_barrier_wake() is now an empty function (threads never \"wake\" in\n   the usual manner)\n2. gomp_team_barrier_cancel() now uses the \"exit\" PTX instruction.\n3. gomp_barrier_wait_last() now is implemented using \"bar.arrive\"\n\n4. gomp_team_barrier_wait_end()/gomp_team_barrier_wait_cancel_end():\n   The main synchronization is done using a 'bar.red' instruction. This reduces\n   across all threads the condition (team->task_count != 0), to enable the task\n   processing down below if any thread created a task.\n   (this bar.red usage means that this patch is dependent on the prior NVPTX\n   bar.red GCC patch)\n\n\tPR target/99555\n\nlibgomp/ChangeLog:\n\n\t* config/nvptx/bar.c (generation_to_barrier): Remove.\n\t(futex_wait,futex_wake,do_spin,do_wait): Remove.\n\t(GOMP_WAIT_H): Remove.\n\t(#include \"../linux/bar.c\"): Remove.\n\t(gomp_barrier_wait_end): New function.\n\t(gomp_barrier_wait): Likewise.\n\t(gomp_barrier_wait_last): Likewise.\n\t(gomp_team_barrier_wait_end): Likewise.\n\t(gomp_team_barrier_wait): Likewise.\n\t(gomp_team_barrier_wait_final): Likewise.\n\t(gomp_team_barrier_wait_cancel_end): Likewise.\n\t(gomp_team_barrier_wait_cancel): Likewise.\n\t(gomp_team_barrier_cancel): Likewise.\n\t* config/nvptx/bar.h (gomp_barrier_t): Remove waiters, lock fields.\n\t(gomp_barrier_init): Remove init of waiters, lock fields.\n\t(gomp_team_barrier_wake): Remove prototype, add new static inline\n\tfunction.", "tree": {"sha": "bb39aafd56efe2de87b27e5c1b1026f66072f65a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/bb39aafd56efe2de87b27e5c1b1026f66072f65a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d/comments", "author": {"login": "cltang", "id": 4055966, "node_id": "MDQ6VXNlcjQwNTU5NjY=", "avatar_url": "https://avatars.githubusercontent.com/u/4055966?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cltang", "html_url": "https://github.com/cltang", "followers_url": "https://api.github.com/users/cltang/followers", "following_url": "https://api.github.com/users/cltang/following{/other_user}", "gists_url": "https://api.github.com/users/cltang/gists{/gist_id}", "starred_url": "https://api.github.com/users/cltang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cltang/subscriptions", "organizations_url": "https://api.github.com/users/cltang/orgs", "repos_url": "https://api.github.com/users/cltang/repos", "events_url": "https://api.github.com/users/cltang/events{/privacy}", "received_events_url": "https://api.github.com/users/cltang/received_events", "type": "User", "site_admin": false}, "committer": {"login": "cltang", "id": 4055966, "node_id": "MDQ6VXNlcjQwNTU5NjY=", "avatar_url": "https://avatars.githubusercontent.com/u/4055966?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cltang", "html_url": "https://github.com/cltang", "followers_url": "https://api.github.com/users/cltang/followers", "following_url": "https://api.github.com/users/cltang/following{/other_user}", "gists_url": "https://api.github.com/users/cltang/gists{/gist_id}", "starred_url": "https://api.github.com/users/cltang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cltang/subscriptions", "organizations_url": "https://api.github.com/users/cltang/orgs", "repos_url": "https://api.github.com/users/cltang/repos", "events_url": "https://api.github.com/users/cltang/events{/privacy}", "received_events_url": "https://api.github.com/users/cltang/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "623daaf8a229fcb58f84448d954f8c71191ca486", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/623daaf8a229fcb58f84448d954f8c71191ca486", "html_url": "https://github.com/Rust-GCC/gccrs/commit/623daaf8a229fcb58f84448d954f8c71191ca486"}], "stats": {"total": 227, "additions": 124, "deletions": 103}, "files": [{"sha": "2c9f96d8ddfa792dfb024e5bafeb085d161b717c", "filename": "libgomp/config/nvptx/bar.c", "status": "modified", "additions": 117, "deletions": 98, "changes": 215, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d/libgomp%2Fconfig%2Fnvptx%2Fbar.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d/libgomp%2Fconfig%2Fnvptx%2Fbar.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fconfig%2Fnvptx%2Fbar.c?ref=fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d", "patch": "@@ -30,137 +30,156 @@\n #include <limits.h>\n #include \"libgomp.h\"\n \n-/* For cpu_relax.  */\n-#include \"doacross.h\"\n-\n-/* Assuming ADDR is &bar->generation, return bar.  Copied from\n-   rtems/bar.c.  */\n+void\n+gomp_barrier_wait_end (gomp_barrier_t *bar, gomp_barrier_state_t state)\n+{\n+  if (__builtin_expect (state & BAR_WAS_LAST, 0))\n+    {\n+      /* Next time we'll be awaiting TOTAL threads again.  */\n+      bar->awaited = bar->total;\n+      __atomic_store_n (&bar->generation, bar->generation + BAR_INCR,\n+\t\t\tMEMMODEL_RELEASE);\n+    }\n+  if (bar->total > 1)\n+    asm (\"bar.sync 1, %0;\" : : \"r\" (32 * bar->total));\n+}\n \n-static gomp_barrier_t *\n-generation_to_barrier (int *addr)\n+void\n+gomp_barrier_wait (gomp_barrier_t *bar)\n {\n-  char *bar\n-    = (char *) addr - __builtin_offsetof (gomp_barrier_t, generation);\n-  return (gomp_barrier_t *)bar;\n+  gomp_barrier_wait_end (bar, gomp_barrier_wait_start (bar));\n }\n \n-/* Implement futex_wait-like behaviour to plug into the linux/bar.c\n-   implementation.  Assumes ADDR is &bar->generation.   */\n+/* Like gomp_barrier_wait, except that if the encountering thread\n+   is not the last one to hit the barrier, it returns immediately.\n+   The intended usage is that a thread which intends to gomp_barrier_destroy\n+   this barrier calls gomp_barrier_wait, while all other threads\n+   call gomp_barrier_wait_last.  When gomp_barrier_wait returns,\n+   the barrier can be safely destroyed.  */\n \n-static inline void\n-futex_wait (int *addr, int val)\n+void\n+gomp_barrier_wait_last (gomp_barrier_t *bar)\n {\n-  gomp_barrier_t *bar = generation_to_barrier (addr);\n+  /* The above described behavior matches 'bar.arrive' perfectly.  */\n+  if (bar->total > 1)\n+    asm (\"bar.arrive 1, %0;\" : : \"r\" (32 * bar->total));\n+}\n \n-  if (bar->total < 2)\n-    /* A barrier with less than two threads, nop.  */\n-    return;\n+/* Barriers are implemented mainly using 'bar.red.or', which combines a bar.sync\n+   operation with a OR-reduction of \"team->task_count != 0\" across all threads.\n+   Task processing is done only after synchronization and verifying that\n+   task_count was non-zero in at least one of the team threads.\n \n-  gomp_mutex_lock (&bar->lock);\n+   This use of simple-barriers, and queueing of tasks till the end, is deemed\n+   more efficient performance-wise for GPUs in the common offloading case, as\n+   opposed to implementing futex-wait/wake operations to simultaneously process\n+   tasks in a CPU-thread manner (which is not easy to implement efficiently\n+   on GPUs).  */\n \n-  /* Futex semantics: only go to sleep if *addr == val.  */\n-  if (__builtin_expect (__atomic_load_n (addr, MEMMODEL_ACQUIRE) != val, 0))\n-    {\n-      gomp_mutex_unlock (&bar->lock);\n-      return;\n-    }\n+void\n+gomp_team_barrier_wait_end (gomp_barrier_t *bar, gomp_barrier_state_t state)\n+{\n+  struct gomp_thread *thr = gomp_thread ();\n+  struct gomp_team *team = thr->ts.team;\n \n-  /* Register as waiter.  */\n-  unsigned int waiters\n-    = __atomic_add_fetch (&bar->waiters, 1, MEMMODEL_ACQ_REL);\n-  if (waiters == 0)\n-    __builtin_abort ();\n-  unsigned int waiter_id = waiters;\n+  bool run_tasks = (team->task_count != 0);\n+  if (bar->total > 1)\n+    run_tasks = __builtin_nvptx_bar_red_or (1, 32 * bar->total, true,\n+\t\t\t\t\t    (team->task_count != 0));\n \n-  if (waiters > 1)\n+  if (__builtin_expect (state & BAR_WAS_LAST, 0))\n     {\n-      /* Wake other threads in bar.sync.  */\n-      asm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * waiters));\n-\n-      /* Ensure that they have updated waiters.  */\n-      asm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * waiters));\n+      /* Next time we'll be awaiting TOTAL threads again.  */\n+      bar->awaited = bar->total;\n+      team->work_share_cancelled = 0;\n     }\n \n-  gomp_mutex_unlock (&bar->lock);\n-\n-  while (1)\n+  if (__builtin_expect (run_tasks == true, 0))\n     {\n-      /* Wait for next thread in barrier.  */\n-      asm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * (waiters + 1)));\n+      while (__atomic_load_n (&bar->generation, MEMMODEL_ACQUIRE)\n+\t     & BAR_TASK_PENDING)\n+\tgomp_barrier_handle_tasks (state);\n \n-      /* Get updated waiters.  */\n-      unsigned int updated_waiters\n-\t= __atomic_load_n (&bar->waiters, MEMMODEL_ACQUIRE);\n-\n-      /* Notify that we have updated waiters.  */\n-      asm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * (waiters + 1)));\n-\n-      waiters = updated_waiters;\n+      if (bar->total > 1)\n+\tasm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * bar->total));\n+    }\n+}\n \n-      if (waiter_id > waiters)\n-\t/* A wake happened, and we're in the group of woken threads.  */\n-\tbreak;\n+void\n+gomp_team_barrier_wait (gomp_barrier_t *bar)\n+{\n+  gomp_team_barrier_wait_end (bar, gomp_barrier_wait_start (bar));\n+}\n \n-      /* Continue waiting.  */\n-    }\n+void\n+gomp_team_barrier_wait_final (gomp_barrier_t *bar)\n+{\n+  gomp_barrier_state_t state = gomp_barrier_wait_final_start (bar);\n+  if (__builtin_expect (state & BAR_WAS_LAST, 0))\n+    bar->awaited_final = bar->total;\n+  gomp_team_barrier_wait_end (bar, state);\n }\n \n-/* Implement futex_wake-like behaviour to plug into the linux/bar.c\n-   implementation.  Assumes ADDR is &bar->generation.  */\n+/* See also comments for gomp_team_barrier_wait_end.  */\n \n-static inline void\n-futex_wake (int *addr, int count)\n+bool\n+gomp_team_barrier_wait_cancel_end (gomp_barrier_t *bar,\n+\t\t\t\t   gomp_barrier_state_t state)\n {\n-  gomp_barrier_t *bar = generation_to_barrier (addr);\n+  struct gomp_thread *thr = gomp_thread ();\n+  struct gomp_team *team = thr->ts.team;\n \n-  if (bar->total < 2)\n-    /* A barrier with less than two threads, nop.  */\n-    return;\n+  bool run_tasks = (team->task_count != 0);\n+  if (bar->total > 1)\n+    run_tasks = __builtin_nvptx_bar_red_or (1, 32 * bar->total, true,\n+\t\t\t\t\t    (team->task_count != 0));\n+  if (state & BAR_CANCELLED)\n+    return true;\n \n-  gomp_mutex_lock (&bar->lock);\n-  unsigned int waiters = __atomic_load_n (&bar->waiters, MEMMODEL_ACQUIRE);\n-  if (waiters == 0)\n+  if (__builtin_expect (state & BAR_WAS_LAST, 0))\n     {\n-      /* No threads to wake.  */\n-      gomp_mutex_unlock (&bar->lock);\n-      return;\n+      /* Note: BAR_CANCELLED should never be set in state here, because\n+\t cancellation means that at least one of the threads has been\n+\t cancelled, thus on a cancellable barrier we should never see\n+\t all threads to arrive.  */\n+\n+      /* Next time we'll be awaiting TOTAL threads again.  */\n+      bar->awaited = bar->total;\n+      team->work_share_cancelled = 0;\n     }\n \n-  if (count == INT_MAX)\n-    /* Release all threads.  */\n-    __atomic_store_n (&bar->waiters, 0, MEMMODEL_RELEASE);\n-  else if (count < bar->total)\n-    /* Release count threads.  */\n-    __atomic_add_fetch (&bar->waiters, -count, MEMMODEL_ACQ_REL);\n-  else\n-    /* Count has an illegal value.  */\n-    __builtin_abort ();\n-\n-  /* Wake other threads in bar.sync.  */\n-  asm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * (waiters + 1)));\n+  if (__builtin_expect (run_tasks == true, 0))\n+    {\n+      while (__atomic_load_n (&bar->generation, MEMMODEL_ACQUIRE)\n+\t     & BAR_TASK_PENDING)\n+\tgomp_barrier_handle_tasks (state);\n \n-  /* Let them get the updated waiters.  */\n-  asm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * (waiters + 1)));\n+      if (bar->total > 1)\n+\tasm volatile (\"bar.sync 1, %0;\" : : \"r\" (32 * bar->total));\n+    }\n \n-  gomp_mutex_unlock (&bar->lock);\n+  return false;\n }\n \n-/* Copied from linux/wait.h.  */\n-\n-static inline int do_spin (int *addr, int val)\n+bool\n+gomp_team_barrier_wait_cancel (gomp_barrier_t *bar)\n {\n-  /* The current implementation doesn't spin.  */\n-  return 1;\n+  return gomp_team_barrier_wait_cancel_end (bar, gomp_barrier_wait_start (bar));\n }\n \n-/* Copied from linux/wait.h.  */\n-\n-static inline void do_wait (int *addr, int val)\n+void\n+gomp_team_barrier_cancel (struct gomp_team *team)\n {\n-  if (do_spin (addr, val))\n-    futex_wait (addr, val);\n-}\n+  gomp_mutex_lock (&team->task_lock);\n+  if (team->barrier.generation & BAR_CANCELLED)\n+    {\n+      gomp_mutex_unlock (&team->task_lock);\n+      return;\n+    }\n+  team->barrier.generation |= BAR_CANCELLED;\n+  gomp_mutex_unlock (&team->task_lock);\n \n-/* Reuse the linux implementation.  */\n-#define GOMP_WAIT_H 1\n-#include \"../linux/bar.c\"\n+  /* The 'exit' instruction cancels this thread and also fullfills any other\n+     CTA threads waiting on barriers.  */\n+  asm volatile (\"exit;\");\n+}"}, {"sha": "61e9b55ceb113e9f9a42537d3cafc8450b81f450", "filename": "libgomp/config/nvptx/bar.h", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d/libgomp%2Fconfig%2Fnvptx%2Fbar.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d/libgomp%2Fconfig%2Fnvptx%2Fbar.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fconfig%2Fnvptx%2Fbar.h?ref=fdc7469cf597ec11229ddfc3e9c7a06f3d0fba9d", "patch": "@@ -38,8 +38,6 @@ typedef struct\n   unsigned generation;\n   unsigned awaited;\n   unsigned awaited_final;\n-  unsigned waiters;\n-  gomp_mutex_t lock;\n } gomp_barrier_t;\n \n typedef unsigned int gomp_barrier_state_t;\n@@ -59,8 +57,6 @@ static inline void gomp_barrier_init (gomp_barrier_t *bar, unsigned count)\n   bar->awaited = count;\n   bar->awaited_final = count;\n   bar->generation = 0;\n-  bar->waiters = 0;\n-  gomp_mutex_init (&bar->lock);\n }\n \n static inline void gomp_barrier_reinit (gomp_barrier_t *bar, unsigned count)\n@@ -83,10 +79,16 @@ extern void gomp_team_barrier_wait_end (gomp_barrier_t *,\n extern bool gomp_team_barrier_wait_cancel (gomp_barrier_t *);\n extern bool gomp_team_barrier_wait_cancel_end (gomp_barrier_t *,\n \t\t\t\t\t       gomp_barrier_state_t);\n-extern void gomp_team_barrier_wake (gomp_barrier_t *, int);\n struct gomp_team;\n extern void gomp_team_barrier_cancel (struct gomp_team *);\n \n+static inline void\n+gomp_team_barrier_wake (gomp_barrier_t *bar, int count)\n+{\n+  /* We never \"wake up\" threads on nvptx.  Threads wait at barrier\n+     instructions till barrier fullfilled.  Do nothing here.  */\n+}\n+\n static inline gomp_barrier_state_t\n gomp_barrier_wait_start (gomp_barrier_t *bar)\n {"}]}