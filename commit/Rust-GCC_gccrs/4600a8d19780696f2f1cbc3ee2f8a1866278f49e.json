{"sha": "4600a8d19780696f2f1cbc3ee2f8a1866278f49e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDYwMGE4ZDE5NzgwNjk2ZjJmMWNiYzNlZTJmOGExODY2Mjc4ZjQ5ZQ==", "commit": {"author": {"name": "Ramana Radhakrishnan", "email": "ramana.radhakrishnan@arm.com", "date": "2010-09-01T15:28:13Z"}, "committer": {"name": "Ramana Radhakrishnan", "email": "ramana@gcc.gnu.org", "date": "2010-09-01T15:28:13Z"}, "message": "neon-schedgen.ml (core): New type.\n\n\n2010-09-01  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>\n\n\t* config/arm/neon-schedgen.ml (core): New type.\n\t(allCores): List of supported cores.\n\t(availability_table): Add supported cores.\n\t(collate_bypasses): Accept core as a parameter.\n\t(worst_case_latencies_and_bypasses): Accept core as a\n\t parameter.\n\t(emit_insn_reservations): Accept core as a parameter.\n\tUse tuneStr and coreStr to get tune attribute and prefix\n\tfor functional units.\n\t(emit_bypasses): Accept core name and use it.\n\t(calculate_per_core_availability_table): New.\n\t(filter_core): New.\n\t(calculate_core_availability_table): New.\n\t(main): Use calculate_core_availablity_table.\n\t* config/arm/cortex-a8-neon.md: Update copyright year.\n\tRegenerated from ml file and merged in.\n\t(neon_mrrc, neon_mrc): Rename to cortex_a8_neon_mrrc and\n\tcortex_a8_neon_mrc.\n\nFrom-SVN: r163737", "tree": {"sha": "27018176e72573c6587019c28501169f8ec7c6ca", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/27018176e72573c6587019c28501169f8ec7c6ca"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4600a8d19780696f2f1cbc3ee2f8a1866278f49e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4600a8d19780696f2f1cbc3ee2f8a1866278f49e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4600a8d19780696f2f1cbc3ee2f8a1866278f49e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4600a8d19780696f2f1cbc3ee2f8a1866278f49e/comments", "author": null, "committer": null, "parents": [{"sha": "f6857310729acf4e5a8eac3b2076adad17356c8f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f6857310729acf4e5a8eac3b2076adad17356c8f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f6857310729acf4e5a8eac3b2076adad17356c8f"}], "stats": {"total": 1765, "additions": 913, "deletions": 852}, "files": [{"sha": "3017202840d3f07d95cea08730971f0ecde35eb8", "filename": "gcc/ChangeLog", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4600a8d19780696f2f1cbc3ee2f8a1866278f49e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4600a8d19780696f2f1cbc3ee2f8a1866278f49e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4600a8d19780696f2f1cbc3ee2f8a1866278f49e", "patch": "@@ -1,3 +1,24 @@\n+2010-09-01  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>\n+\n+\t* config/arm/neon-schedgen.ml (core): New type.\n+\t(allCores): List of supported cores.\n+\t(availability_table): Add supported cores.\n+\t(collate_bypasses): Accept core as a parameter.\n+\t(worst_case_latencies_and_bypasses): Accept core as a\n+\t parameter.\n+\t(emit_insn_reservations): Accept core as a parameter.\n+\tUse tuneStr and coreStr to get tune attribute and prefix\n+\tfor functional units.\n+\t(emit_bypasses): Accept core name and use it.\n+\t(calculate_per_core_availability_table): New.\n+\t(filter_core): New.\n+\t(calculate_core_availability_table): New.\n+\t(main): Use calculate_core_availablity_table.\n+\t* config/arm/cortex-a8-neon.md: Update copyright year.\n+\tRegenerated from ml file and merged in.\n+\t(neon_mrrc, neon_mrc): Rename to cortex_a8_neon_mrrc and\n+\tcortex_a8_neon_mrc.\n+\n 2010-09-01  Ian Bolton  <ian.bolton@arm.com>\n \n \t* Makefile.in (tree-switch-conversion.o): Update dependencies."}, {"sha": "5639b5836d5dc3ff96bf81afbed2cc13a6b273a4", "filename": "gcc/config/arm/cortex-a8-neon.md", "status": "modified", "additions": 773, "deletions": 773, "changes": 1546, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4600a8d19780696f2f1cbc3ee2f8a1866278f49e/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4600a8d19780696f2f1cbc3ee2f8a1866278f49e/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md?ref=4600a8d19780696f2f1cbc3ee2f8a1866278f49e", "patch": "@@ -182,12 +182,12 @@\n \n ;; NEON -> core transfers.\n \n-(define_insn_reservation \"neon_mrc\" 20\n+(define_insn_reservation \"cortex_a8_neon_mrc\" 20\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mrc\"))\n   \"cortex_a8_neon_ls\")\n \n-(define_insn_reservation \"neon_mrrc\" 21\n+(define_insn_reservation \"cortex_a8_neon_mrrc\" 21\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mrrc\"))\n   \"cortex_a8_neon_ls_2\")\n@@ -196,1117 +196,1117 @@\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N3.\n-(define_insn_reservation \"neon_int_1\" 3\n+(define_insn_reservation \"cortex_a8_neon_int_1\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_int_1\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)m operands at N1,\n ;; their (D|Q)n operands at N2, and produce a result at N3.\n-(define_insn_reservation \"neon_int_2\" 3\n+(define_insn_reservation \"cortex_a8_neon_int_2\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_int_2\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N3.\n-(define_insn_reservation \"neon_int_3\" 3\n+(define_insn_reservation \"cortex_a8_neon_int_3\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_int_3\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N4.\n-(define_insn_reservation \"neon_int_4\" 4\n+(define_insn_reservation \"cortex_a8_neon_int_4\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_int_4\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)m operands at N1,\n ;; their (D|Q)n operands at N2, and produce a result at N4.\n-(define_insn_reservation \"neon_int_5\" 4\n+(define_insn_reservation \"cortex_a8_neon_int_5\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_int_5\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N4.\n-(define_insn_reservation \"neon_vqneg_vqabs\" 4\n+(define_insn_reservation \"cortex_a8_neon_vqneg_vqabs\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vqneg_vqabs\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation produce a result at N3.\n-(define_insn_reservation \"neon_vmov\" 3\n+(define_insn_reservation \"cortex_a8_neon_vmov\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vmov\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6.\n-(define_insn_reservation \"neon_vaba\" 6\n+(define_insn_reservation \"cortex_a8_neon_vaba\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vaba\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 2.\n-(define_insn_reservation \"neon_vaba_qqq\" 7\n+(define_insn_reservation \"cortex_a8_neon_vaba_qqq\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vaba_qqq\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)m operands at N1,\n ;; their (D|Q)d operands at N3, and produce a result at N6.\n-(define_insn_reservation \"neon_vsma\" 6\n+(define_insn_reservation \"cortex_a8_neon_vsma\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vsma\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N6.\n-(define_insn_reservation \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n+(define_insn_reservation \"cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N6 on cycle 2.\n-(define_insn_reservation \"neon_mul_qqq_8_16_32_ddd_32\" 7\n+(define_insn_reservation \"cortex_a8_neon_mul_qqq_8_16_32_ddd_32\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mul_qqq_8_16_32_ddd_32\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N6 on cycle 2.\n-(define_insn_reservation \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\" 7\n+(define_insn_reservation \"cortex_a8_neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N6.\n-(define_insn_reservation \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n+(define_insn_reservation \"cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 2.\n-(define_insn_reservation \"neon_mla_qqq_8_16\" 7\n+(define_insn_reservation \"cortex_a8_neon_mla_qqq_8_16\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mla_qqq_8_16\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 2.\n-(define_insn_reservation \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\" 7\n+(define_insn_reservation \"cortex_a8_neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\" 7\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6 on cycle 4.\n-(define_insn_reservation \"neon_mla_qqq_32_qqd_32_scalar\" 9\n+(define_insn_reservation \"cortex_a8_neon_mla_qqq_32_qqd_32_scalar\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mla_qqq_32_qqd_32_scalar\"))\n   \"cortex_a8_neon_dp_4\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N6.\n-(define_insn_reservation \"neon_mul_ddd_16_scalar_32_16_long_scalar\" 6\n+(define_insn_reservation \"cortex_a8_neon_mul_ddd_16_scalar_32_16_long_scalar\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mul_ddd_16_scalar_32_16_long_scalar\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N6 on cycle 4.\n-(define_insn_reservation \"neon_mul_qqd_32_scalar\" 9\n+(define_insn_reservation \"cortex_a8_neon_mul_qqd_32_scalar\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mul_qqd_32_scalar\"))\n   \"cortex_a8_neon_dp_4\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N6.\n-(define_insn_reservation \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\" 6\n+(define_insn_reservation \"cortex_a8_neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N3.\n-(define_insn_reservation \"neon_shift_1\" 3\n+(define_insn_reservation \"cortex_a8_neon_shift_1\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_shift_1\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N4.\n-(define_insn_reservation \"neon_shift_2\" 4\n+(define_insn_reservation \"cortex_a8_neon_shift_2\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_shift_2\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N3 on cycle 2.\n-(define_insn_reservation \"neon_shift_3\" 4\n+(define_insn_reservation \"cortex_a8_neon_shift_3\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_shift_3\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N1.\n-(define_insn_reservation \"neon_vshl_ddd\" 1\n+(define_insn_reservation \"cortex_a8_neon_vshl_ddd\" 1\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vshl_ddd\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N4 on cycle 2.\n-(define_insn_reservation \"neon_vqshl_vrshl_vqrshl_qqq\" 5\n+(define_insn_reservation \"cortex_a8_neon_vqshl_vrshl_vqrshl_qqq\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vqshl_vrshl_vqrshl_qqq\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)m operands at N1,\n ;; their (D|Q)d operands at N3, and produce a result at N6.\n-(define_insn_reservation \"neon_vsra_vrsra\" 6\n+(define_insn_reservation \"cortex_a8_neon_vsra_vrsra\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vsra_vrsra\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N5.\n-(define_insn_reservation \"neon_fp_vadd_ddd_vabs_dd\" 5\n+(define_insn_reservation \"cortex_a8_neon_fp_vadd_ddd_vabs_dd\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vadd_ddd_vabs_dd\"))\n   \"cortex_a8_neon_fadd\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N5 on cycle 2.\n-(define_insn_reservation \"neon_fp_vadd_qqq_vabs_qq\" 6\n+(define_insn_reservation \"cortex_a8_neon_fp_vadd_qqq_vabs_qq\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vadd_qqq_vabs_qq\"))\n   \"cortex_a8_neon_fadd_2\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N5.\n-(define_insn_reservation \"neon_fp_vsum\" 5\n+(define_insn_reservation \"cortex_a8_neon_fp_vsum\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vsum\"))\n   \"cortex_a8_neon_fadd\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N5.\n-(define_insn_reservation \"neon_fp_vmul_ddd\" 5\n+(define_insn_reservation \"cortex_a8_neon_fp_vmul_ddd\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vmul_ddd\"))\n   \"cortex_a8_neon_dp\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, and produce a result at N5 on cycle 2.\n-(define_insn_reservation \"neon_fp_vmul_qqd\" 6\n+(define_insn_reservation \"cortex_a8_neon_fp_vmul_qqd\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vmul_qqd\"))\n   \"cortex_a8_neon_dp_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N9.\n-(define_insn_reservation \"neon_fp_vmla_ddd\" 9\n+(define_insn_reservation \"cortex_a8_neon_fp_vmla_ddd\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vmla_ddd\"))\n   \"cortex_a8_neon_fmul_then_fadd\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n ;; produce a result at N9 on cycle 2.\n-(define_insn_reservation \"neon_fp_vmla_qqq\" 10\n+(define_insn_reservation \"cortex_a8_neon_fp_vmla_qqq\" 10\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vmla_qqq\"))\n   \"cortex_a8_neon_fmul_then_fadd_2\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N9.\n-(define_insn_reservation \"neon_fp_vmla_ddd_scalar\" 9\n+(define_insn_reservation \"cortex_a8_neon_fp_vmla_ddd_scalar\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vmla_ddd_scalar\"))\n   \"cortex_a8_neon_fmul_then_fadd\")\n \n ;; Instructions using this reservation read their (D|Q)n operands at N2,\n ;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n ;; produce a result at N9 on cycle 2.\n-(define_insn_reservation \"neon_fp_vmla_qqq_scalar\" 10\n+(define_insn_reservation \"cortex_a8_neon_fp_vmla_qqq_scalar\" 10\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vmla_qqq_scalar\"))\n   \"cortex_a8_neon_fmul_then_fadd_2\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N9.\n-(define_insn_reservation \"neon_fp_vrecps_vrsqrts_ddd\" 9\n+(define_insn_reservation \"cortex_a8_neon_fp_vrecps_vrsqrts_ddd\" 9\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vrecps_vrsqrts_ddd\"))\n   \"cortex_a8_neon_fmul_then_fadd\")\n \n ;; Instructions using this reservation read their source operands at N2, and\n ;; produce a result at N9 on cycle 2.\n-(define_insn_reservation \"neon_fp_vrecps_vrsqrts_qqq\" 10\n+(define_insn_reservation \"cortex_a8_neon_fp_vrecps_vrsqrts_qqq\" 10\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_fp_vrecps_vrsqrts_qqq\"))\n   \"cortex_a8_neon_fmul_then_fadd_2\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2.\n-(define_insn_reservation \"neon_bp_simple\" 2\n+(define_insn_reservation \"cortex_a8_neon_bp_simple\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_bp_simple\"))\n   \"cortex_a8_neon_perm\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 2.\n-(define_insn_reservation \"neon_bp_2cycle\" 3\n+(define_insn_reservation \"cortex_a8_neon_bp_2cycle\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_bp_2cycle\"))\n   \"cortex_a8_neon_perm_2\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 3.\n-(define_insn_reservation \"neon_bp_3cycle\" 4\n+(define_insn_reservation \"cortex_a8_neon_bp_3cycle\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_bp_3cycle\"))\n   \"cortex_a8_neon_perm_3\")\n \n ;; Instructions using this reservation produce a result at N1.\n-(define_insn_reservation \"neon_ldr\" 1\n+(define_insn_reservation \"cortex_a8_neon_ldr\" 1\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_ldr\"))\n   \"cortex_a8_neon_ls\")\n \n ;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"neon_str\" 0\n+(define_insn_reservation \"cortex_a8_neon_str\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_str\"))\n   \"cortex_a8_neon_ls\")\n \n ;; Instructions using this reservation produce a result at N1 on cycle 2.\n-(define_insn_reservation \"neon_vld1_1_2_regs\" 2\n+(define_insn_reservation \"cortex_a8_neon_vld1_1_2_regs\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld1_1_2_regs\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation produce a result at N1 on cycle 3.\n-(define_insn_reservation \"neon_vld1_3_4_regs\" 3\n+(define_insn_reservation \"cortex_a8_neon_vld1_3_4_regs\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld1_3_4_regs\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation produce a result at N2 on cycle 2.\n-(define_insn_reservation \"neon_vld2_2_regs_vld1_vld2_all_lanes\" 3\n+(define_insn_reservation \"cortex_a8_neon_vld2_2_regs_vld1_vld2_all_lanes\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld2_2_regs_vld1_vld2_all_lanes\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation produce a result at N2 on cycle 3.\n-(define_insn_reservation \"neon_vld2_4_regs\" 4\n+(define_insn_reservation \"cortex_a8_neon_vld2_4_regs\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld2_4_regs\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation produce a result at N2 on cycle 4.\n-(define_insn_reservation \"neon_vld3_vld4\" 5\n+(define_insn_reservation \"cortex_a8_neon_vld3_vld4\" 5\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld3_vld4\"))\n   \"cortex_a8_neon_ls_4\")\n \n ;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"neon_vst1_1_2_regs_vst2_2_regs\" 0\n+(define_insn_reservation \"cortex_a8_neon_vst1_1_2_regs_vst2_2_regs\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vst1_1_2_regs_vst2_2_regs\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"neon_vst1_3_4_regs\" 0\n+(define_insn_reservation \"cortex_a8_neon_vst1_3_4_regs\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vst1_3_4_regs\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"neon_vst2_4_regs_vst3_vst4\" 0\n+(define_insn_reservation \"cortex_a8_neon_vst2_4_regs_vst3_vst4\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vst2_4_regs_vst3_vst4\"))\n   \"cortex_a8_neon_ls_4\")\n \n ;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"neon_vst3_vst4\" 0\n+(define_insn_reservation \"cortex_a8_neon_vst3_vst4\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vst3_vst4\"))\n   \"cortex_a8_neon_ls_4\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 3.\n-(define_insn_reservation \"neon_vld1_vld2_lane\" 4\n+(define_insn_reservation \"cortex_a8_neon_vld1_vld2_lane\" 4\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld1_vld2_lane\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation read their source operands at N1, and\n ;; produce a result at N2 on cycle 5.\n-(define_insn_reservation \"neon_vld3_vld4_lane\" 6\n+(define_insn_reservation \"cortex_a8_neon_vld3_vld4_lane\" 6\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld3_vld4_lane\"))\n   \"cortex_a8_neon_ls_5\")\n \n ;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"neon_vst1_vst2_lane\" 0\n+(define_insn_reservation \"cortex_a8_neon_vst1_vst2_lane\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vst1_vst2_lane\"))\n   \"cortex_a8_neon_ls_2\")\n \n ;; Instructions using this reservation read their source operands at N1.\n-(define_insn_reservation \"neon_vst3_vst4_lane\" 0\n+(define_insn_reservation \"cortex_a8_neon_vst3_vst4_lane\" 0\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vst3_vst4_lane\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation produce a result at N2 on cycle 2.\n-(define_insn_reservation \"neon_vld3_vld4_all_lanes\" 3\n+(define_insn_reservation \"cortex_a8_neon_vld3_vld4_all_lanes\" 3\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_vld3_vld4_all_lanes\"))\n   \"cortex_a8_neon_ls_3\")\n \n ;; Instructions using this reservation produce a result at N2.\n-(define_insn_reservation \"neon_mcr\" 2\n+(define_insn_reservation \"cortex_a8_neon_mcr\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mcr\"))\n   \"cortex_a8_neon_perm\")\n \n ;; Instructions using this reservation produce a result at N2.\n-(define_insn_reservation \"neon_mcr_2_mcrr\" 2\n+(define_insn_reservation \"cortex_a8_neon_mcr_2_mcrr\" 2\n   (and (eq_attr \"tune\" \"cortexa8\")\n        (eq_attr \"neon_type\" \"neon_mcr_2_mcrr\"))\n   \"cortex_a8_neon_perm_2\")\n \n ;; Exceptions to the default latencies.\n \n-(define_bypass 1 \"neon_mcr_2_mcrr\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 1 \"neon_mcr\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_vld3_vld4_all_lanes\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_vld3_vld4_lane\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_vld1_vld2_lane\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 4 \"neon_vld3_vld4\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_vld2_4_regs\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_vld2_2_regs_vld1_vld2_all_lanes\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_vld1_3_4_regs\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 1 \"neon_vld1_1_2_regs\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 0 \"neon_ldr\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_bp_3cycle\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_bp_2cycle\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 1 \"neon_bp_simple\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 9 \"neon_fp_vrecps_vrsqrts_qqq\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 8 \"neon_fp_vrecps_vrsqrts_ddd\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 9 \"neon_fp_vmla_qqq_scalar\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 8 \"neon_fp_vmla_ddd_scalar\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 9 \"neon_fp_vmla_qqq\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 8 \"neon_fp_vmla_ddd\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_fp_vmul_qqd\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 4 \"neon_fp_vmul_ddd\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 4 \"neon_fp_vsum\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_fp_vadd_qqq_vabs_qq\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 4 \"neon_fp_vadd_ddd_vabs_dd\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_vsra_vrsra\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 4 \"neon_vqshl_vrshl_vqrshl_qqq\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 0 \"neon_vshl_ddd\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_shift_3\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_shift_2\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_shift_1\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 8 \"neon_mul_qqd_32_scalar\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_mul_ddd_16_scalar_32_16_long_scalar\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 8 \"neon_mla_qqq_32_qqd_32_scalar\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 6 \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 6 \"neon_mla_qqq_8_16\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 6 \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 6 \"neon_mul_qqq_8_16_32_ddd_32\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_vsma\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 6 \"neon_vaba_qqq\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 5 \"neon_vaba\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_vmov\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_vqneg_vqabs\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_int_5\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 3 \"neon_int_4\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_int_3\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_int_2\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n-\n-(define_bypass 2 \"neon_int_1\"\n-               \"neon_int_1,\\\n-               neon_int_4,\\\n-               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mul_qqq_8_16_32_ddd_32,\\\n-               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n-               neon_mla_qqq_8_16,\\\n-               neon_fp_vadd_ddd_vabs_dd,\\\n-               neon_fp_vadd_qqq_vabs_qq,\\\n-               neon_fp_vmla_ddd,\\\n-               neon_fp_vmla_qqq,\\\n-               neon_fp_vrecps_vrsqrts_ddd,\\\n-               neon_fp_vrecps_vrsqrts_qqq\")\n+(define_bypass 1 \"cortex_a8_neon_mcr_2_mcrr\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 1 \"cortex_a8_neon_mcr\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_vld3_vld4_all_lanes\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_vld3_vld4_lane\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_vld1_vld2_lane\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"cortex_a8_neon_vld3_vld4\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_vld2_4_regs\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_vld2_2_regs_vld1_vld2_all_lanes\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_vld1_3_4_regs\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 1 \"cortex_a8_neon_vld1_1_2_regs\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 0 \"cortex_a8_neon_ldr\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_bp_3cycle\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_bp_2cycle\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 1 \"cortex_a8_neon_bp_simple\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 9 \"cortex_a8_neon_fp_vrecps_vrsqrts_qqq\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"cortex_a8_neon_fp_vrecps_vrsqrts_ddd\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 9 \"cortex_a8_neon_fp_vmla_qqq_scalar\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"cortex_a8_neon_fp_vmla_ddd_scalar\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 9 \"cortex_a8_neon_fp_vmla_qqq\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"cortex_a8_neon_fp_vmla_ddd\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_fp_vmul_qqd\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"cortex_a8_neon_fp_vmul_ddd\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"cortex_a8_neon_fp_vsum\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_fp_vadd_qqq_vabs_qq\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"cortex_a8_neon_fp_vadd_ddd_vabs_dd\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_vsra_vrsra\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"cortex_a8_neon_vqshl_vrshl_vqrshl_qqq\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 0 \"cortex_a8_neon_vshl_ddd\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_shift_3\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_shift_2\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_shift_1\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"cortex_a8_neon_mul_qqd_32_scalar\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_mul_ddd_16_scalar_32_16_long_scalar\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"cortex_a8_neon_mla_qqq_32_qqd_32_scalar\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"cortex_a8_neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"cortex_a8_neon_mla_qqq_8_16\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"cortex_a8_neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"cortex_a8_neon_mul_qqq_8_16_32_ddd_32\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_vsma\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"cortex_a8_neon_vaba_qqq\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"cortex_a8_neon_vaba\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_vmov\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_vqneg_vqabs\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_int_5\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"cortex_a8_neon_int_4\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_int_3\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_int_2\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"cortex_a8_neon_int_1\"\n+               \"cortex_a8_neon_int_1,\\\n+               cortex_a8_neon_int_4,\\\n+               cortex_a8_neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mul_qqq_8_16_32_ddd_32,\\\n+               cortex_a8_neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               cortex_a8_neon_mla_qqq_8_16,\\\n+               cortex_a8_neon_fp_vadd_ddd_vabs_dd,\\\n+               cortex_a8_neon_fp_vadd_qqq_vabs_qq,\\\n+               cortex_a8_neon_fp_vmla_ddd,\\\n+               cortex_a8_neon_fp_vmla_qqq,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_ddd,\\\n+               cortex_a8_neon_fp_vrecps_vrsqrts_qqq\")\n "}, {"sha": "d449ff8a717d0cce036eb90de9367a6563582456", "filename": "gcc/config/arm/neon-schedgen.ml", "status": "modified", "additions": 119, "deletions": 79, "changes": 198, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4600a8d19780696f2f1cbc3ee2f8a1866278f49e/gcc%2Fconfig%2Farm%2Fneon-schedgen.ml", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4600a8d19780696f2f1cbc3ee2f8a1866278f49e/gcc%2Fconfig%2Farm%2Fneon-schedgen.ml", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fneon-schedgen.ml?ref=4600a8d19780696f2f1cbc3ee2f8a1866278f49e", "patch": "@@ -1,7 +1,6 @@\n (* Emission of the core of the Cortex-A8 NEON scheduling description.\n    Copyright (C) 2007, 2010 Free Software Foundation, Inc.\n    Contributed by CodeSourcery.\n-\n    This file is part of GCC.\n \n    GCC is free software; you can redistribute it and/or modify it under\n@@ -21,7 +20,14 @@\n \n (* This scheduling description generator works as follows.\n    - Each group of instructions has source and destination requirements\n-     specified.  The source requirements may be specified using\n+     specified and a list of cores supported. This is then filtered\n+     and per core scheduler descriptions are generated out.\n+     The reservations generated are prefixed by the name of the\n+     core and the check is performed on the basis of what the tuning\n+     string is. Running this will generate Neon scheduler descriptions\n+     for all cores supported.\n+\n+     The source requirements may be specified using\n      Source (the stage at which all source operands not otherwise\n      described are read), Source_m (the stage at which Rm operands are\n      read), Source_n (likewise for Rn) and Source_d (likewise for Rd).\n@@ -83,136 +89,154 @@ type reservation =\n | Ls of int\n | Fmul_then_fadd | Fmul_then_fadd_2\n \n+type core = CortexA8 | CortexA9\n+let allCores = [CortexA8]\n+let coreStr = function\n+    CortexA8 -> \"cortex_a8\"\n+  | CortexA9 -> \"cortex_a9\"\n+\n+let tuneStr = function\n+    CortexA8 -> \"cortexa8\"\n+   | CortexA9 -> \"cortexa9\"\n+\n+\n (* This table must be kept as short as possible by conflating\n    entries with the same availability behavior.\n \n    First components: instruction group names\n    Second components: availability requirements, in the order in which\n    they should appear in the comments in the .md file.\n    Third components: reservation info\n+   Fourth components: List of supported cores.\n *)\n let availability_table = [\n   (* NEON integer ALU instructions.  *)\n   (* vbit vbif vbsl vorr vbic vnot vcls vclz vcnt vadd vand vorr\n      veor vbic vorn ddd qqq *)\n-  \"neon_int_1\", [Source n2; Dest n3], ALU;\n+  \"neon_int_1\", [Source n2; Dest n3], ALU, allCores;\n   (* vadd vsub qqd vsub ddd qqq *)\n-  \"neon_int_2\", [Source_m n1; Source_n n2; Dest n3], ALU;\n+  \"neon_int_2\", [Source_m n1; Source_n n2; Dest n3], ALU, allCores;\n   (* vsum vneg dd qq vadd vsub qdd *)\n-  \"neon_int_3\", [Source n1; Dest n3], ALU;\n+  \"neon_int_3\", [Source n1; Dest n3], ALU, allCores;\n   (* vabs vceqz vcgez vcbtz vclez vcltz vadh vradh vsbh vrsbh dqq *)\n   (* vhadd vrhadd vqadd vtst ddd qqq *)\n-  \"neon_int_4\", [Source n2; Dest n4], ALU;\n+  \"neon_int_4\", [Source n2; Dest n4], ALU, allCores;\n   (* vabd qdd vhsub vqsub vabd vceq vcge vcgt vmax vmin vfmx vfmn ddd ddd *)\n-  \"neon_int_5\", [Source_m n1; Source_n n2; Dest n4], ALU;\n+  \"neon_int_5\", [Source_m n1; Source_n n2; Dest n4], ALU, allCores;\n   (* vqneg vqabs dd qq *)\n-  \"neon_vqneg_vqabs\", [Source n1; Dest n4], ALU;\n+  \"neon_vqneg_vqabs\", [Source n1; Dest n4], ALU, allCores;\n   (* vmov vmvn *)\n-  \"neon_vmov\", [Dest n3], ALU;\n+  \"neon_vmov\", [Dest n3], ALU, allCores;\n   (* vaba *)\n-  \"neon_vaba\", [Source_n n2; Source_m n1; Source_d n3; Dest n6], ALU;\n+  \"neon_vaba\", [Source_n n2; Source_m n1; Source_d n3; Dest n6], ALU, allCores;\n   \"neon_vaba_qqq\",\n-    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n6)], ALU_2cycle;\n+    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n6)], \n+   ALU_2cycle, allCores;\n   (* vsma *)\n-  \"neon_vsma\", [Source_m n1; Source_d n3; Dest n6], ALU;\n+  \"neon_vsma\", [Source_m n1; Source_d n3; Dest n6], ALU, allCores;\n \n   (* NEON integer multiply instructions.  *)\n   (* vmul, vqdmlh, vqrdmlh *)\n   (* vmul, vqdmul, qdd 16/8 long 32/16 long *)\n-  \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\", [Source n2; Dest n6], Mul;\n-  \"neon_mul_qqq_8_16_32_ddd_32\", [Source n2; Dest_n_after (1, n6)], Mul_2cycle;\n+  \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\", [Source n2; Dest n6], \n+   Mul, allCores;\n+  \"neon_mul_qqq_8_16_32_ddd_32\", [Source n2; Dest_n_after (1, n6)], \n+   Mul_2cycle, allCores;\n   (* vmul, vqdmul again *)\n   \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\",\n-    [Source_n n2; Source_m n1; Dest_n_after (1, n6)], Mul_2cycle;\n+    [Source_n n2; Source_m n1; Dest_n_after (1, n6)], Mul_2cycle, allCores;\n   (* vmla, vmls *)\n   \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\",\n-    [Source_n n2; Source_m n2; Source_d n3; Dest n6], Mul;\n+    [Source_n n2; Source_m n2; Source_d n3; Dest n6], Mul, allCores;\n   \"neon_mla_qqq_8_16\",\n-    [Source_n n2; Source_m n2; Source_d n3; Dest_n_after (1, n6)], Mul_2cycle;\n+    [Source_n n2; Source_m n2; Source_d n3; Dest_n_after (1, n6)], \n+   Mul_2cycle, allCores;\n   \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\",\n-    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n6)], Mul_2cycle;\n+    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n6)], \n+   Mul_2cycle, allCores;\n   \"neon_mla_qqq_32_qqd_32_scalar\",\n-    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (3, n6)], Mul_4cycle;\n+    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (3, n6)], \n+   Mul_4cycle, allCores;\n   (* vmul, vqdmulh, vqrdmulh *)\n   (* vmul, vqdmul *)\n   \"neon_mul_ddd_16_scalar_32_16_long_scalar\",\n-    [Source_n n2; Source_m n1; Dest n6], Mul;\n+    [Source_n n2; Source_m n1; Dest n6], Mul, allCores;\n   \"neon_mul_qqd_32_scalar\",\n-    [Source_n n2; Source_m n1; Dest_n_after (3, n6)], Mul_4cycle;\n+    [Source_n n2; Source_m n1; Dest_n_after (3, n6)], Mul_4cycle, allCores;\n   (* vmla, vmls *)\n   (* vmla, vmla, vqdmla, vqdmls *)\n   \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\",\n-    [Source_n n2; Source_m n1; Source_d n3; Dest n6], Mul;\n+    [Source_n n2; Source_m n1; Source_d n3; Dest n6], Mul, allCores;\n \n   (* NEON integer shift instructions.  *)\n   (* vshr/vshl immediate, vshr_narrow, vshl_vmvh, vsli_vsri_ddd *)\n-  \"neon_shift_1\", [Source n1; Dest n3], Shift;\n-  (* vqshl, vrshr immediate; vqshr, vqmov, vrshr, vqrshr narrow;\n+  \"neon_shift_1\", [Source n1; Dest n3], Shift, allCores;\n+  (* vqshl, vrshr immediate; vqshr, vqmov, vrshr, vqrshr narrow, allCores;\n      vqshl_vrshl_vqrshl_ddd *)\n-  \"neon_shift_2\", [Source n1; Dest n4], Shift;\n+  \"neon_shift_2\", [Source n1; Dest n4], Shift, allCores;\n   (* vsli, vsri and vshl for qqq *)\n-  \"neon_shift_3\", [Source n1; Dest_n_after (1, n3)], Shift_2cycle;\n-  \"neon_vshl_ddd\", [Source n1; Dest n1], Shift;\n+  \"neon_shift_3\", [Source n1; Dest_n_after (1, n3)], Shift_2cycle, allCores;\n+  \"neon_vshl_ddd\", [Source n1; Dest n1], Shift, allCores;\n   \"neon_vqshl_vrshl_vqrshl_qqq\", [Source n1; Dest_n_after (1, n4)],\n-    Shift_2cycle;\n-  \"neon_vsra_vrsra\", [Source_m n1; Source_d n3; Dest n6], Shift;\n+    Shift_2cycle, allCores;\n+  \"neon_vsra_vrsra\", [Source_m n1; Source_d n3; Dest n6], Shift, allCores;\n \n   (* NEON floating-point instructions.  *)\n   (* vadd, vsub, vabd, vmul, vceq, vcge, vcgt, vcage, vcagt, vmax, vmin *)\n   (* vabs, vneg, vceqz, vcgez, vcgtz, vclez, vcltz, vrecpe, vrsqrte, vcvt *)\n-  \"neon_fp_vadd_ddd_vabs_dd\", [Source n2; Dest n5], Fadd;\n+  \"neon_fp_vadd_ddd_vabs_dd\", [Source n2; Dest n5], Fadd, allCores;\n   \"neon_fp_vadd_qqq_vabs_qq\", [Source n2; Dest_n_after (1, n5)],\n-    Fadd_2cycle;\n+    Fadd_2cycle, allCores;\n   (* vsum, fvmx, vfmn *)\n-  \"neon_fp_vsum\", [Source n1; Dest n5], Fadd;\n-  \"neon_fp_vmul_ddd\", [Source_n n2; Source_m n1; Dest n5], Fmul;\n+  \"neon_fp_vsum\", [Source n1; Dest n5], Fadd, allCores;\n+  \"neon_fp_vmul_ddd\", [Source_n n2; Source_m n1; Dest n5], Fmul, allCores;\n   \"neon_fp_vmul_qqd\", [Source_n n2; Source_m n1; Dest_n_after (1, n5)],\n-    Fmul_2cycle;\n+    Fmul_2cycle, allCores;\n   (* vmla, vmls *)\n   \"neon_fp_vmla_ddd\",\n-    [Source_n n2; Source_m n2; Source_d n3; Dest n9], Fmul_then_fadd;\n+    [Source_n n2; Source_m n2; Source_d n3; Dest n9], Fmul_then_fadd, allCores;\n   \"neon_fp_vmla_qqq\",\n     [Source_n n2; Source_m n2; Source_d n3; Dest_n_after (1, n9)],\n-    Fmul_then_fadd_2;\n+    Fmul_then_fadd_2, allCores;\n   \"neon_fp_vmla_ddd_scalar\",\n-    [Source_n n2; Source_m n1; Source_d n3; Dest n9], Fmul_then_fadd;\n+    [Source_n n2; Source_m n1; Source_d n3; Dest n9], Fmul_then_fadd, allCores;\n   \"neon_fp_vmla_qqq_scalar\",\n     [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n9)],\n-    Fmul_then_fadd_2;\n-  \"neon_fp_vrecps_vrsqrts_ddd\", [Source n2; Dest n9], Fmul_then_fadd;\n+    Fmul_then_fadd_2, allCores;\n+  \"neon_fp_vrecps_vrsqrts_ddd\", [Source n2; Dest n9], Fmul_then_fadd, allCores;\n   \"neon_fp_vrecps_vrsqrts_qqq\", [Source n2; Dest_n_after (1, n9)],\n-    Fmul_then_fadd_2;\n+    Fmul_then_fadd_2, allCores;\n \n   (* NEON byte permute instructions.  *)\n   (* vmov; vtrn and vswp for dd; vzip for dd; vuzp for dd; vrev; vext for dd *)\n-  \"neon_bp_simple\", [Source n1; Dest n2], Permute 1;\n-  (* vswp for qq; vext for qqq; vtbl with {Dn} or {Dn, Dn1};\n+  \"neon_bp_simple\", [Source n1; Dest n2], Permute 1, allCores;\n+  (* vswp for qq; vext for qqq; vtbl with {Dn} or {Dn, Dn1}, allCores;\n      similarly for vtbx *)\n-  \"neon_bp_2cycle\", [Source n1; Dest_n_after (1, n2)], Permute 2;\n+  \"neon_bp_2cycle\", [Source n1; Dest_n_after (1, n2)], Permute 2, allCores;\n   (* all the rest *)\n-  \"neon_bp_3cycle\", [Source n1; Dest_n_after (2, n2)], Permute 3;\n+  \"neon_bp_3cycle\", [Source n1; Dest_n_after (2, n2)], Permute 3, allCores;\n \n   (* NEON load/store instructions.  *)\n-  \"neon_ldr\", [Dest n1], Ls 1;\n-  \"neon_str\", [Source n1], Ls 1;\n-  \"neon_vld1_1_2_regs\", [Dest_n_after (1, n1)], Ls 2;\n-  \"neon_vld1_3_4_regs\", [Dest_n_after (2, n1)], Ls 3;\n-  \"neon_vld2_2_regs_vld1_vld2_all_lanes\", [Dest_n_after (1, n2)], Ls 2;\n-  \"neon_vld2_4_regs\", [Dest_n_after (2, n2)], Ls 3;\n-  \"neon_vld3_vld4\", [Dest_n_after (3, n2)], Ls 4;\n-  \"neon_vst1_1_2_regs_vst2_2_regs\", [Source n1], Ls 2;\n-  \"neon_vst1_3_4_regs\", [Source n1], Ls 3;\n-  \"neon_vst2_4_regs_vst3_vst4\", [Source n1], Ls 4;\n-  \"neon_vst3_vst4\", [Source n1], Ls 4;\n-  \"neon_vld1_vld2_lane\", [Source n1; Dest_n_after (2, n2)], Ls 3;\n-  \"neon_vld3_vld4_lane\", [Source n1; Dest_n_after (4, n2)], Ls 5;\n-  \"neon_vst1_vst2_lane\", [Source n1], Ls 2;\n-  \"neon_vst3_vst4_lane\", [Source n1], Ls 3;\n-  \"neon_vld3_vld4_all_lanes\", [Dest_n_after (1, n2)], Ls 3;\n+  \"neon_ldr\", [Dest n1], Ls 1, allCores;\n+  \"neon_str\", [Source n1], Ls 1, allCores;\n+  \"neon_vld1_1_2_regs\", [Dest_n_after (1, n1)], Ls 2, allCores;\n+  \"neon_vld1_3_4_regs\", [Dest_n_after (2, n1)], Ls 3, allCores;\n+  \"neon_vld2_2_regs_vld1_vld2_all_lanes\", [Dest_n_after (1, n2)], Ls 2, allCores;\n+  \"neon_vld2_4_regs\", [Dest_n_after (2, n2)], Ls 3, allCores;\n+  \"neon_vld3_vld4\", [Dest_n_after (3, n2)], Ls 4, allCores;\n+  \"neon_vst1_1_2_regs_vst2_2_regs\", [Source n1], Ls 2, allCores;\n+  \"neon_vst1_3_4_regs\", [Source n1], Ls 3, allCores;\n+  \"neon_vst2_4_regs_vst3_vst4\", [Source n1], Ls 4, allCores;\n+  \"neon_vst3_vst4\", [Source n1], Ls 4, allCores;\n+  \"neon_vld1_vld2_lane\", [Source n1; Dest_n_after (2, n2)], Ls 3, allCores;\n+  \"neon_vld3_vld4_lane\", [Source n1; Dest_n_after (4, n2)], Ls 5, allCores;\n+  \"neon_vst1_vst2_lane\", [Source n1], Ls 2, allCores;\n+  \"neon_vst3_vst4_lane\", [Source n1], Ls 3, allCores;\n+  \"neon_vld3_vld4_all_lanes\", [Dest_n_after (1, n2)], Ls 3, allCores;\n \n   (* NEON register transfer instructions.  *)\n-  \"neon_mcr\", [Dest n2], Permute 1;\n-  \"neon_mcr_2_mcrr\", [Dest n2], Permute 2;\n+  \"neon_mcr\", [Dest n2], Permute 1, allCores;\n+  \"neon_mcr_2_mcrr\", [Dest n2], Permute 2, allCores;\n   (* MRC instructions are in the .tpl file.  *)\n ]\n \n@@ -221,7 +245,7 @@ let availability_table = [\n    required.  (It is also possible that an entry in the table has no\n    source requirements.)  *)\n let calculate_sources =\n-  List.map (fun (name, avail, res) ->\n+  List.map (fun (name, avail, res, cores) ->\n               let earliest_stage =\n                 List.fold_left\n                   (fun cur -> fun info ->\n@@ -331,7 +355,7 @@ let pick_latency largest worst guards =\n    of one bypass from this producer to any particular consumer listed\n    in LATENCIES.)  Use a hash table to collate bypasses with the\n    same latency and guard.  *)\n-let collate_bypasses (producer_name, _, _, _) largest latencies =\n+let collate_bypasses (producer_name, _, _, _) largest latencies core =\n   let ht = Hashtbl.create 42 in\n   let keys = ref [] in\n     List.iter (\n@@ -350,7 +374,7 @@ let collate_bypasses (producer_name, _, _, _) largest latencies =\n               (if (try ignore (Hashtbl.find ht (guard, latency)); false\n                    with Not_found -> true) then\n                  keys := (guard, latency) :: !keys);\n-              Hashtbl.add ht (guard, latency) consumer\n+              Hashtbl.add ht (guard, latency) ((coreStr core) ^ \"_\" ^ consumer)\n             end\n     ) latencies;\n     (* The hash table now has bypasses collated so that ones with the\n@@ -372,7 +396,7 @@ let collate_bypasses (producer_name, _, _, _) largest latencies =\n    the output in such a way that all bypasses with the same producer\n    and latency are together, and so that bypasses with the worst-case\n    latency are ignored.  *)\n-let worst_case_latencies_and_bypasses =\n+let worst_case_latencies_and_bypasses core =\n   let rec f (worst_acc, bypasses_acc) prev xs =\n     match xs with\n       [] -> (worst_acc, bypasses_acc)\n@@ -400,7 +424,7 @@ let worst_case_latencies_and_bypasses =\n           (* Having got the largest latency, collect all bypasses for\n              this producer and filter out those with that larger\n              latency.  Record the others for later emission.  *)\n-          let bypasses = collate_bypasses producer largest latencies in\n+          let bypasses = collate_bypasses producer largest latencies core in\n             (* Go on to process remaining producers, having noted\n                the result for this one.  *)\n             f ((producer_name, producer_avail, largest,\n@@ -444,14 +468,18 @@ let write_comment producer avail =\n     in\n       f avail 0\n \n+\n (* Emit a define_insn_reservation for each producer.  The latency\n    written in will be its worst-case latency.  *)\n-let emit_insn_reservations =\n-  List.iter (\n+let emit_insn_reservations core =\n+  let corestring = coreStr core in\n+  let tunestring = tuneStr core\n+  in  List.iter (\n      fun (producer, avail, latency, reservation) ->\n         write_comment producer avail;\n-        Printf.printf \"(define_insn_reservation \\\"%s\\\" %d\\n\" producer latency;\n-        Printf.printf \"  (and (eq_attr \\\"tune\\\" \\\"cortexa8\\\")\\n\";\n+        Printf.printf \"(define_insn_reservation \\\"%s_%s\\\" %d\\n\" \n+            corestring producer latency;\n+            Printf.printf \"  (and (eq_attr \\\"tune\\\" \\\"%s\\\")\\n\" tunestring;\n         Printf.printf \"       (eq_attr \\\"neon_type\\\" \\\"%s\\\"))\\n\" producer;\n         let str =\n           match reservation with\n@@ -467,7 +495,7 @@ let emit_insn_reservations =\n \t  | Fmul_then_fadd -> \"fmul_then_fadd\"\n \t  | Fmul_then_fadd_2 -> \"fmul_then_fadd_2\"\n         in\n-          Printf.printf \"  \\\"cortex_a8_neon_%s\\\")\\n\\n\" str\n+          Printf.printf \"  \\\"%s_neon_%s\\\")\\n\\n\" corestring str\n     )\n \n (* Given a guard description, return the name of the C function to\n@@ -480,10 +508,12 @@ let guard_fn g =\n   | Guard_none -> assert false\n \n (* Emit a define_bypass for each bypass.  *)\n-let emit_bypasses =\n+let emit_bypasses core =\n   List.iter (\n       fun (producer, consumers, latency, guard) ->\n-        Printf.printf \"(define_bypass %d \\\"%s\\\"\\n\" latency producer;\n+        Printf.printf \"(define_bypass %d \\\"%s_%s\\\"\\n\" \n+\tlatency (coreStr core) producer;\n+\n         if guard = Guard_none then\n           Printf.printf \"               \\\"%s\\\")\\n\\n\" consumers\n         else\n@@ -493,11 +523,21 @@ let emit_bypasses =\n           end\n     )\n \n-(* Program entry point.  *)\n-let main =\n+\n+let calculate_per_core_availability_table core availability_table =\n   let table = calculate_sources availability_table in\n-  let worst_cases, bypasses = worst_case_latencies_and_bypasses table in\n-    emit_insn_reservations (List.rev worst_cases);\n+  let worst_cases, bypasses = worst_case_latencies_and_bypasses core table in\n+    emit_insn_reservations core (List.rev worst_cases);\n     Printf.printf \";; Exceptions to the default latencies.\\n\\n\";\n-    emit_bypasses bypasses\n+    emit_bypasses core bypasses\n+\n+let calculate_core_availability_table core availability_table =\n+let filter_core = List.filter (fun (_, _, _, cores) \n+\t\t\t\t   -> List.exists ((=) core) cores)\n+in calculate_per_core_availability_table core (filter_core availability_table)\n \n+\n+(* Program entry point.  *)\n+let main =\n+  List.map (fun core -> calculate_core_availability_table \n+\t\tcore availability_table) allCores"}]}